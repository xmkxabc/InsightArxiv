{"id": "2507.05415", "title": "Layered, Overlapping, and Inconsistent: A Large-Scale Analysis of the Multiple Privacy Policies and Controls of U.S. Banks", "authors": ["Lu Xian", "Van Tran", "Lauren Lee", "Meera Kumar", "Yichen Zhang", "Florian Schaub"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted for publication in CCS 2025. This is a pre-publication version", "url": "http://arxiv.org/abs/2507.05415v1", "summary": "Privacy policies are often complex. An exception is the two-page standardized\nnotice that U.S. financial institutions must provide under the\nGramm-Leach-Bliley Act (GLBA). However, banks now operate websites, mobile\napps, and other services that involve complex data sharing practices that\nrequire additional privacy notices and do-not-sell opt-outs. We conducted a\nlarge-scale analysis of how U.S. banks implement privacy policies and controls\nin response to GLBA; other federal privacy policy requirements; and the\nCalifornia Consumer Privacy Act (CCPA), a key example for U.S. state privacy\nlaws. We focused on the disclosure and control of a set of especially\nprivacy-invasive practices: third-party data sharing for marketing-related\npurposes. We collected privacy policies for the 2,067 largest U.S. banks,\n45.3\\% of which provided multiple policies. Across disclosures and controls\nwithin the \\textit{same} bank, we identified frequent, concerning\ninconsistencies -- such as banks indicating in GLBA notices that they do not\nshare with third parties but disclosing sharing elsewhere, or using third-party\nmarketing/advertising cookies without disclosure. This multiplicity of\npolicies, with the inconsistencies it causes, may create consumer confusion and\nundermine the transparency goals of the very laws that require them. Our\nfindings call into question whether current policy requirements, such as the\nGLBA notice, are achieving their intended goals in today's online banking\nlandscape. We discuss potential avenues for reforming and harmonizing privacy\npolicies and control requirements across federal and state laws.", "comment": "Accepted for publication in CCS 2025. This is a pre-publication\n  version", "pdf_url": "http://arxiv.org/pdf/2507.05415v1", "cate": "cs.CR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05421", "title": "FrameShift: Learning to Resize Fuzzer Inputs Without Breaking Them", "authors": ["Harrison Green", "Claire Le Goues", "Fraser Brown"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05421v1", "summary": "Coverage-guided fuzzers are powerful automated bug-finding tools. They mutate\nprogram inputs, observe coverage, and save any input that hits an unexplored\npath for future mutation. Unfortunately, without knowledge of input\nformats--for example, the relationship between formats' data fields and\nsizes--fuzzers are prone to generate destructive frameshift mutations. These\ntime-wasting mutations yield malformed inputs that are rejected by the target\nprogram. To avoid such breaking mutations, this paper proposes a novel,\nlightweight technique that preserves the structure of inputs during mutation by\ndetecting and using relation fields.\n  Our technique, FrameShift, is simple, fast, and does not require additional\ninstrumentation beyond standard coverage feedback. We implement our technique\nin two state-of-the-art fuzzers, AFL++ and LibAFL, and perform a 12+ CPU-year\nfuzzer evaluation, finding that FrameShift improves the performance of the\nfuzzer in each configuration, sometimes increasing coverage by more than 50%.\nFurthermore, through a series of case studies, we show that our technique is\nversatile enough to find important structural relationships in a variety of\nformats, even generalizing beyond C/C++ targets to both Rust and Python.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05421v1", "cate": "cs.CR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05445", "title": "A Systematization of Security Vulnerabilities in Computer Use Agents", "authors": ["Daniel Jones", "Giorgio Severi", "Martin Pouliot", "Gary Lopez", "Joris de Gruyter", "Santiago Zanella-Beguelin", "Justin Song", "Blake Bullwinkel", "Pamela Cortez", "Amanda Minnich"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05445v1", "summary": "Computer Use Agents (CUAs), autonomous systems that interact with software\ninterfaces via browsers or virtual machines, are rapidly being deployed in\nconsumer and enterprise environments. These agents introduce novel attack\nsurfaces and trust boundaries that are not captured by traditional threat\nmodels. Despite their growing capabilities, the security boundaries of CUAs\nremain poorly understood. In this paper, we conduct a systematic threat\nanalysis and testing of real-world CUAs under adversarial conditions. We\nidentify seven classes of risks unique to the CUA paradigm, and analyze three\nconcrete exploit scenarios in depth: (1) clickjacking via visual overlays that\nmislead interface-level reasoning, (2) indirect prompt injection that enables\nRemote Code Execution (RCE) through chained tool use, and (3) CoT exposure\nattacks that manipulate implicit interface framing to hijack multi-step\nreasoning. These case studies reveal deeper architectural flaws across current\nCUA implementations. Namely, a lack of input provenance tracking, weak\ninterface-action binding, and insufficient control over agent memory and\ndelegation. We conclude by proposing a CUA-specific security evaluation\nframework and design principles for safe deployment in adversarial and\nhigh-stakes settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05445v1", "cate": "cs.CR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05512", "title": "Disappearing Ink: Obfuscation Breaks N-gram Code Watermarks in Theory and Practice", "authors": ["Gehao Zhang", "Eugene Bagdasarian", "Juan Zhai", "Shiqing Ma"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05512v1", "summary": "Distinguishing AI-generated code from human-written code is becoming crucial\nfor tasks such as authorship attribution, content tracking, and misuse\ndetection. Based on this, N-gram-based watermarking schemes have emerged as\nprominent, which inject secret watermarks to be detected during the generation.\n  However, their robustness in code content remains insufficiently evaluated.\nMost claims rely solely on defenses against simple code transformations or code\noptimizations as a simulation of attack, creating a questionable sense of\nrobustness. In contrast, more sophisticated schemes already exist in the\nsoftware engineering world, e.g., code obfuscation, which significantly alters\ncode while preserving functionality. Although obfuscation is commonly used to\nprotect intellectual property or evade software scanners, the robustness of\ncode watermarking techniques against such transformations remains largely\nunexplored.\n  In this work, we formally model the code obfuscation and prove the\nimpossibility of N-gram-based watermarking's robustness with only one intuitive\nand experimentally verified assumption, distribution consistency, satisfied.\nGiven the original false positive rate of the watermarking detection, the ratio\nthat the detector failed on the watermarked code after obfuscation will\nincrease to 1 - fpr.\n  The experiments have been performed on three SOTA watermarking schemes, two\nLLMs, two programming languages, four code benchmarks, and four obfuscators.\nAmong them, all watermarking detectors show coin-flipping detection abilities\non obfuscated codes (AUROC tightly surrounds 0.5). Among all models,\nwatermarking schemes, and datasets, both programming languages own obfuscators\nthat can achieve attack effects with no detection AUROC higher than 0.6 after\nthe attack. Based on the theoretical and practical observations, we also\nproposed a potential path of robust code watermarking.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05512v1", "cate": "cs.CR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05524", "title": "PROTEAN: Federated Intrusion Detection in Non-IID Environments through Prototype-Based Knowledge Sharing", "authors": ["Sara Chennoufi", "Yufei Han", "Gregory Blanc", "Emiliano De Cristofaro", "Christophe Kiennert"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05524v1", "summary": "In distributed networks, participants often face diverse and fast-evolving\ncyberattacks. This makes techniques based on Federated Learning (FL) a\npromising mitigation strategy. By only exchanging model updates, FL\nparticipants can collaboratively build detection models without revealing\nsensitive information, e.g., network structures or security postures. However,\nthe effectiveness of FL solutions is often hindered by significant data\nheterogeneity, as attack patterns often differ drastically across organizations\ndue to varying security policies. To address these challenges, we introduce\nPROTEAN, a Prototype Learning-based framework geared to facilitate\ncollaborative and privacy-preserving intrusion detection. PROTEAN enables\naccurate detection in environments with highly non-IID attack distributions and\npromotes direct knowledge sharing by exchanging class prototypes of different\nattack types among participants. This allows organizations to better understand\nattack techniques not present in their data collections. We instantiate PROTEAN\non two cyber intrusion datasets collected from IIoT and 5G-connected\nparticipants and evaluate its performance in terms of utility and privacy,\ndemonstrating its effectiveness in addressing data heterogeneity while\nimproving cyber attack understanding in federated intrusion detection systems\n(IDSs).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05524v1", "cate": "cs.CR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05558", "title": "AI Agent Smart Contract Exploit Generation", "authors": ["Arthur Gervais", "Liyi Zhou"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05558v1", "summary": "We present A1, an agentic execution driven system that transforms any LLM\ninto an end-to-end exploit generator. A1 has no hand-crafted heuristics and\nprovides the agent with six domain-specific tools that enable autonomous\nvulnerability discovery. The agent can flexibly leverage these tools to\nunderstand smart contract behavior, generate exploit strategies, test them on\nblockchain states, and refine approaches based on execution feedback. All\noutputs are concretely validated to eliminate false positives.\n  The evaluation across 36 real-world vulnerable contracts on Ethereum and\nBinance Smart Chain demonstrates a 62.96% (17 out of 27) success rate on the\nVERITE benchmark. Beyond the VERITE dataset, A1 identified 9 additional\nvulnerable contracts, with 5 cases occurring after the strongest model's\ntraining cutoff date. Across all 26 successful cases, A1 extracts up to 8.59\nmillion USD per case and 9.33 million USD total. Through 432 experiments across\nsix LLMs, we analyze iteration-wise performance showing diminishing returns\nwith average marginal gains of +9.7%, +3.7%, +5.1%, and +2.8% for iterations\n2-5 respectively, with per-experiment costs ranging $0.01-$3.59. A Monte Carlo\nanalysis of 19 historical attacks shows success probabilities of 85.9%-88.8%\nwithout detection delays.\n  We investigate whether an attacker or a defender benefits most from deploying\nA1 as a continuous on-chain scanning system. Our model shows that OpenAI's\no3-pro maintains profitability up to a 30.0 days scanning delay at 0.100%\nvulnerability incidence rates, while faster models require >=1.000% rates to\nbreak-even. The findings exposes a troubling asymmetry: at 0.1% vulnerability\nrates, attackers achieve an on-chain scanning profitability at a $6000 exploit\nvalue, while defenders require $60000, raising fundamental questions about\nwhether AI agents inevitably favor exploitation over defense.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05558v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05576", "title": "iThermTroj: Exploiting Intermittent Thermal Trojans in Multi-Processor System-on-Chips", "authors": ["Mehdi Elahi", "Mohamed R. Elshamy", "Abdel-Hameed Badawy", "Ahmad Patooghy"], "categories": ["cs.CR", "cs.AR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05576v1", "summary": "Thermal Trojan attacks present a pressing concern for the security and\nreliability of System-on-Chips (SoCs), especially in mobile applications. The\nsituation becomes more complicated when such attacks are more evasive and\noperate sporadically to stay hidden from detection mechanisms. In this paper,\nwe introduce Intermittent Thermal Trojans (iThermTroj) that exploit the chips'\nthermal information in a random time-triggered manner. According to our\nexperiments, iThermTroj attack can easily bypass available threshold-based\nthermal Trojan detection solutions. We investigate SoC vulnerabilities to\nvariations of iThermTroj through an in-depth analysis of Trojan activation and\nduration scenarios. We also propose a set of tiny Machine Learning classifiers\nfor run-time anomaly detection to protect SoCs against such intermittent\nthermal Trojan attacks. Compared to existing methods, our approach improves the\nattack detection rate by 29.4\\%, 17.2\\%, and 14.3\\% in scenarios where\niThermTroj manipulates up to 80\\%, 60\\%, and 40\\% of SoC's thermal data,\nrespectively. Additionally, our method increases the full protection resolution\nto 0.8 degrees Celsius, meaning that any temperature manipulations exceeding\n$\\pm 0.8$ degrees will be detected with 100\\% accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05576v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05622", "title": "DATABench: Evaluating Dataset Auditing in Deep Learning from an Adversarial Perspective", "authors": ["Shuo Shao", "Yiming Li", "Mengren Zheng", "Zhiyang Hu", "Yukun Chen", "Boheng Li", "Yu He", "Junfeng Guo", "Tianwei Zhang", "Dacheng Tao", "Zhan Qin"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05622v1", "summary": "The widespread application of Deep Learning across diverse domains hinges\ncritically on the quality and composition of training datasets. However, the\ncommon lack of disclosure regarding their usage raises significant privacy and\ncopyright concerns. Dataset auditing techniques, which aim to determine if a\nspecific dataset was used to train a given suspicious model, provide promising\nsolutions to addressing these transparency gaps. While prior work has developed\nvarious auditing methods, their resilience against dedicated adversarial\nattacks remains largely unexplored. To bridge the gap, this paper initiates a\ncomprehensive study evaluating dataset auditing from an adversarial\nperspective. We start with introducing a novel taxonomy, classifying existing\nmethods based on their reliance on internal features (IF) (inherent to the\ndata) versus external features (EF) (artificially introduced for auditing).\nSubsequently, we formulate two primary attack types: evasion attacks, designed\nto conceal the use of a dataset, and forgery attacks, intending to falsely\nimplicate an unused dataset. Building on the understanding of existing methods\nand attack objectives, we further propose systematic attack strategies:\ndecoupling, removal, and detection for evasion; adversarial example-based\nmethods for forgery. These formulations and strategies lead to our new\nbenchmark, DATABench, comprising 17 evasion attacks, 5 forgery attacks, and 9\nrepresentative auditing methods. Extensive evaluations using DATABench reveal\nthat none of the evaluated auditing methods are sufficiently robust or\ndistinctive under adversarial settings. These findings underscore the urgent\nneed for developing a more secure and reliable dataset auditing method capable\nof withstanding sophisticated adversarial manipulation. Code is available at\nhttps://github.com/shaoshuo-ss/DATABench.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05622v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05630", "title": "How Not to Detect Prompt Injections with an LLM", "authors": ["Sarthak Choudhary", "Divyam Anshumaan", "Nils Palumbo", "Somesh Jha"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05630v1", "summary": "LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, in which adversaries embed malicious instructions within seemingly\nbenign user inputs to manipulate the LLM's intended behavior. Recent defenses\nbased on $\\textit{known-answer detection}$ (KAD) have achieved near-perfect\nperformance by using an LLM to classify inputs as clean or contaminated. In\nthis work, we formally characterize the KAD framework and uncover a structural\nvulnerability in its design that invalidates its core security premise. We\ndesign a methodical adaptive attack, $\\textit{DataFlip}$, to exploit this\nfundamental weakness. It consistently evades KAD defenses with detection rates\nas low as $1.5\\%$ while reliably inducing malicious behavior with success rates\nof up to $88\\%$, without needing white-box access to the LLM or any\noptimization procedures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05630v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05649", "title": "DESIGN: Encrypted GNN Inference via Server-Side Input Graph Pruning", "authors": ["Kaixiang Zhao", "Joseph Yousry Attalla", "Qian Lou", "Yushun Dong"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Under Review in Conference on Neural Information Processing Systems (NeurIPS 2025)", "url": "http://arxiv.org/abs/2507.05649v1", "summary": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance in\nvarious graph-based learning tasks. However, enabling privacy-preserving GNNs\nin encrypted domains, such as under Fully Homomorphic Encryption (FHE),\ntypically incurs substantial computational overhead, rendering real-time and\nprivacy-preserving inference impractical. In this work, we propose DESIGN\n(EncrypteD GNN Inference via sErver-Side Input Graph pruNing), a novel\nframework for efficient encrypted GNN inference. DESIGN tackles the critical\nefficiency limitations of existing FHE GNN approaches, which often overlook\ninput data redundancy and apply uniform computational strategies. Our framework\nachieves significant performance gains through a hierarchical optimization\nstrategy executed entirely on the server: first, FHE-compatible node importance\nscores (based on encrypted degree statistics) are computed from the encrypted\ngraph. These scores then guide a homomorphic partitioning process, generating\nmulti-level importance masks directly under FHE. This dynamically generated\nmask facilitates both input graph pruning (by logically removing unimportant\nelements) and a novel adaptive polynomial activation scheme, where activation\ncomplexity is tailored to node importance levels. Empirical evaluations\ndemonstrate that DESIGN substantially accelerates FHE GNN inference compared to\nstate-of-the-art methods while maintaining competitive model accuracy,\npresenting a robust solution for secure graph analytics.", "comment": "Under Review in Conference on Neural Information Processing Systems\n  (NeurIPS 2025)", "pdf_url": "http://arxiv.org/pdf/2507.05649v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05660", "title": "TuneShield: Mitigating Toxicity in Conversational AI while Fine-tuning on Untrusted Data", "authors": ["Aravind Cheruvu", "Shravya Kanchi", "Sifat Muhammad Abdullah", "Nicholas Kong", "Daphne Yao", "Murtuza Jadliwala", "Bimal Viswanath"], "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Pre-print", "url": "http://arxiv.org/abs/2507.05660v1", "summary": "Recent advances in foundation models, such as LLMs, have revolutionized\nconversational AI. Chatbots are increasingly being developed by customizing\nLLMs on specific conversational datasets. However, mitigating toxicity during\nthis customization, especially when dealing with untrusted training data,\nremains a significant challenge. To address this, we introduce TuneShield, a\ndefense framework designed to mitigate toxicity during chatbot fine-tuning\nwhile preserving conversational quality. TuneShield leverages LLM-based\ntoxicity classification, utilizing the instruction-following capabilities and\nsafety alignment of LLMs to effectively identify toxic samples, outperforming\nindustry API services. TuneShield generates synthetic conversation samples,\ntermed 'healing data', based on the identified toxic samples, using them to\nmitigate toxicity while reinforcing desirable behavior during fine-tuning. It\nperforms an alignment process to further nudge the chatbot towards producing\ndesired responses. Our findings show that TuneShield effectively mitigates\ntoxicity injection attacks while preserving conversational quality, even when\nthe toxicity classifiers are imperfect or biased. TuneShield proves to be\nresilient against adaptive adversarial and jailbreak attacks. Additionally,\nTuneShield demonstrates effectiveness in mitigating adaptive toxicity injection\nattacks during dialog-based learning (DBL).", "comment": "Pre-print", "pdf_url": "http://arxiv.org/pdf/2507.05660v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05683", "title": "Polyadic encryption", "authors": ["Steven Duplij", "Qiang Guo"], "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      revtex 4.2, 9 pages", "url": "http://arxiv.org/abs/2507.05683v1", "summary": "A novel original procedure of encryption/decryption based on the polyadic\nalgebraic structures and on signal processing methods is proposed. First, we\nuse signals with integer amplitudes to send information. Then we use polyadic\ntechniques to transfer the plaintext into series of special integers. The\nreceiver restores the plaintext using special rules and systems of equations.", "comment": "revtex 4.2, 9 pages", "pdf_url": "http://arxiv.org/pdf/2507.05683v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05728", "title": "Asynchronous Event Error-Minimizing Noise for Safeguarding Event Dataset", "authors": ["Ruofei Wang", "Peiqi Duan", "Boxin Shi", "Renjie Wan"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2507.05728v1", "summary": "With more event datasets being released online, safeguarding the event\ndataset against unauthorized usage has become a serious concern for data\nowners. Unlearnable Examples are proposed to prevent the unauthorized\nexploitation of image datasets. However, it's unclear how to create unlearnable\nasynchronous event streams to prevent event misuse. In this work, we propose\nthe first unlearnable event stream generation method to prevent unauthorized\ntraining from event datasets. A new form of asynchronous event error-minimizing\nnoise is proposed to perturb event streams, tricking the unauthorized model\ninto learning embedded noise instead of realistic features. To be compatible\nwith the sparse event, a projection strategy is presented to sparsify the noise\nto render our unlearnable event streams (UEvs). Extensive experiments\ndemonstrate that our method effectively protects event data from unauthorized\nexploitation, while preserving their utility for legitimate use. We hope our\nUEvs contribute to the advancement of secure and trustworthy event dataset\nsharing. Code is available at: https://github.com/rfww/uevs.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.05728v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05794", "title": "Automated Reasoning for Vulnerability Management by Design", "authors": ["Avi Shaked", "Nan Messe"], "categories": ["cs.CR", "cs.AI", "cs.LO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05794v1", "summary": "For securing systems, it is essential to manage their vulnerability posture\nand design appropriate security controls. Vulnerability management allows to\nproactively address vulnerabilities by incorporating pertinent security\ncontrols into systems designs. Current vulnerability management approaches do\nnot support systematic reasoning about the vulnerability postures of systems\ndesigns. To effectively manage vulnerabilities and design security controls, we\npropose a formally grounded automated reasoning mechanism. We integrate the\nmechanism into an open-source security design tool and demonstrate its\napplication through an illustrative example driven by real-world challenges.\nThe automated reasoning mechanism allows system designers to identify\nvulnerabilities that are applicable to a specific system design, explicitly\nspecify vulnerability mitigation options, declare selected controls, and thus\nsystematically manage vulnerability postures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05794v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05872", "title": "LDP$^3$: An Extensible and Multi-Threaded Toolkit for Local Differential Privacy Protocols and Post-Processing Methods", "authors": ["Berkay Kemal Balioglu", "Alireza Khodaie", "Mehmet Emre Gursoy"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05872v1", "summary": "Local differential privacy (LDP) has become a prominent notion for\nprivacy-preserving data collection. While numerous LDP protocols and\npost-processing (PP) methods have been developed, selecting an optimal\ncombination under different privacy budgets and datasets remains a challenge.\nMoreover, the lack of a comprehensive and extensible LDP benchmarking toolkit\nraises difficulties in evaluating new protocols and PP methods. To address\nthese concerns, this paper presents LDP$^3$ (pronounced LDP-Cube), an\nopen-source, extensible, and multi-threaded toolkit for LDP researchers and\npractitioners. LDP$^3$ contains implementations of several LDP protocols, PP\nmethods, and utility metrics in a modular and extensible design. Its modular\ndesign enables developers to conveniently integrate new protocols and PP\nmethods. Furthermore, its multi-threaded nature enables significant reductions\nin execution times via parallelization. Experimental evaluations demonstrate\nthat: (i) using LDP$^3$ to select a good protocol and post-processing method\nsubstantially improves utility compared to a bad or random choice, and (ii) the\nmulti-threaded design of LDP$^3$ brings substantial benefits in terms of\nefficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05872v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05875", "title": "Post-Processing in Local Differential Privacy: An Extensive Evaluation and Benchmark Platform", "authors": ["Alireza Khodaie", "Berkay Kemal Balioglu", "Mehmet Emre Gursoy"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05875v1", "summary": "Local differential privacy (LDP) has recently gained prominence as a powerful\nparadigm for collecting and analyzing sensitive data from users' devices.\nHowever, the inherent perturbation added by LDP protocols reduces the utility\nof the collected data. To mitigate this issue, several post-processing (PP)\nmethods have been developed. Yet, the comparative performance of PP methods\nunder diverse settings remains underexplored. In this paper, we present an\nextensive benchmark comprising 6 popular LDP protocols, 7 PP methods, 4 utility\nmetrics, and 6 datasets to evaluate the behaviors and optimality of PP methods\nunder diverse conditions. Through extensive experiments, we show that while PP\ncan substantially improve utility when the privacy budget is small (i.e.,\nstrict privacy), its benefit diminishes as the privacy budget grows. Moreover,\nour findings reveal that the optimal PP method depends on multiple factors,\nincluding the choice of LDP protocol, privacy budget, data characteristics\n(such as distribution and domain size), and the specific utility metric. To\nadvance research in this area and assist practitioners in identifying the most\nsuitable PP method for their setting, we introduce LDP$^3$, an open-source\nbenchmark platform. LDP$^3$ contains all methods used in our experimental\nanalysis, and it is designed in a modular, extensible, and multi-threaded way\nfor future use and development.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05875v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05469", "title": "Inaugural MOASEI Competition at AAMAS'2025: A Technical Report", "authors": ["Ceferino Patino", "Tyler J. Billings", "Alireza Saleh Abadi", "Daniel Redder", "Adam Eck", "Prashant Doshi", "Leen-Kiat Soh"], "categories": ["cs.MA", "cs.AI"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      Report from the MOASEI'2025 Competition held at AAMAS'2025", "url": "http://arxiv.org/abs/2507.05469v1", "summary": "We present the Methods for Open Agent Systems Evaluation Initiative (MOASEI)\nCompetition, a multi-agent AI benchmarking event designed to evaluate\ndecision-making under open-world conditions. Built on the free-range-zoo\nenvironment suite, MOASEI introduced dynamic, partially observable domains with\nagent and task openness--settings where entities may appear, disappear, or\nchange behavior over time. The 2025 competition featured three\ntracks--Wildfire, Rideshare, and Cybersecurity--each highlighting distinct\ndimensions of openness and coordination complexity. Eleven teams from\ninternational institutions participated, with four of those teams submitting\ndiverse solutions including graph neural networks, convolutional architectures,\npredictive modeling, and large language model--driven meta--optimization.\nEvaluation metrics centered on expected utility, robustness to perturbations,\nand responsiveness to environmental change. The results reveal promising\nstrategies for generalization and adaptation in open environments, offering\nboth empirical insight and infrastructure for future research. This report\ndetails the competition's design, findings, and contributions to the open-agent\nsystems research community.", "comment": "Report from the MOASEI'2025 Competition held at AAMAS'2025", "pdf_url": "http://arxiv.org/pdf/2507.05469v1", "cate": "cs.MA", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06008", "title": "The Impact of Event Data Partitioning on Privacy-aware Process Discovery", "authors": ["Jungeun Lim", "Stephan A. Fahrenkrog-Petersen", "Xixi Lu", "Jan Mendling", "Minseok Song"], "categories": ["cs.CR", "cs.AI", "cs.DB"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06008v1", "summary": "Information systems support the execution of business processes. The event\nlogs of these executions generally contain sensitive information about\ncustomers, patients, and employees. The corresponding privacy challenges can be\naddressed by anonymizing the event logs while still retaining utility for\nprocess discovery. However, trading off utility and privacy is difficult: the\nhigher the complexity of event log, the higher the loss of utility by\nanonymization. In this work, we propose a pipeline that combines anonymization\nand event data partitioning, where event abstraction is utilized for\npartitioning. By leveraging event abstraction, event logs can be segmented into\nmultiple parts, allowing each sub-log to be anonymized separately. This\npipeline preserves privacy while mitigating the loss of utility. To validate\nour approach, we study the impact of event partitioning on two anonymization\ntechniques using three real-world event logs and two process discovery\ntechniques. Our results demonstrate that event partitioning can bring\nimprovements in process discovery utility for directly-follows-based\nanonymization techniques.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06008v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05723", "title": "Large Language Models for Agent-Based Modelling: Current and possible uses across the modelling cycle", "authors": ["Loïs Vanhée", "Melania Borit", "Peer-Olaf Siebers", "Roger Cremades", "Christopher Frantz", "Önder Gürcan", "František Kalvas", "Denisa Reshef Kera", "Vivek Nallur", "Kavin Narasimhan", "Martin Neumann"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      18 pages, including 2 pages of appendix, accepted for publication at the Social Simulation Conference 2025 ( this https URL )", "url": "http://arxiv.org/abs/2507.05723v1", "summary": "The emergence of Large Language Models (LLMs) with increasingly sophisticated\nnatural language understanding and generative capabilities has sparked interest\nin the Agent-based Modelling (ABM) community. With their ability to summarize,\ngenerate, analyze, categorize, transcribe and translate text, answer questions,\npropose explanations, sustain dialogue, extract information from unstructured\ntext, and perform logical reasoning and problem-solving tasks, LLMs have a good\npotential to contribute to the modelling process. After reviewing the current\nuse of LLMs in ABM, this study reflects on the opportunities and challenges of\nthe potential use of LLMs in ABM. It does so by following the modelling cycle,\nfrom problem formulation to documentation and communication of model results,\nand holding a critical stance.", "comment": "18 pages, including 2 pages of appendix, accepted for publication at\n  the Social Simulation Conference 2025 (https://ssc2025.tbm.tudelft.nl/)", "pdf_url": "http://arxiv.org/pdf/2507.05723v1", "cate": "cs.MA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06039", "title": "Enter, Exit, Page Fault, Leak: Testing Isolation Boundaries for Microarchitectural Leaks", "authors": ["Oleksii Oleksenko", "Flavien Solt", "Cédric Fournet", "Jana Hofmann", "Boris Köpf", "Stavros Volos"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE SP 2025; delayed due to embargo; to appear at IEEE SP 2026", "url": "http://arxiv.org/abs/2507.06039v1", "summary": "CPUs provide isolation mechanisms like virtualization and privilege levels to\nprotect software. Yet these focus on architectural isolation while typically\noverlooking microarchitectural side channels, exemplified by Meltdown and\nForeshadow. Software must therefore supplement architectural defenses with\nad-hoc microarchitectural patches, which are constantly evolving as new attacks\nemerge and defenses are proposed. Such reactive approach makes ensuring\ncomplete isolation a daunting task, and leaves room for errors and oversights.\n  We address this problem by developing a tool that stress tests\nmicroarchitectural isolation between security domains such as virtual machines,\nkernel, and processes, with the goal of detecting flaws in the isolation\nboundaries. The tool extends model-based relational testing (MRT) methodology\nto enable detection of cross-domain information leakage. We design a new test\ncase generator and execution sandbox to handle multi-domain execution, new\nleakage models to encode expected leaks, and new analysis techniques to manage\nnondeterminism.\n  We use this tool to perform an in-depth testing campaign on six x86-64 CPUs\nfor leakage across different isolation boundaries. The testing campaign exposed\nfour new leaks and corroborated numerous known ones, with only two false\npositives throughout the entire campaign. These results show critical gaps in\ncurrent isolation mechanisms as well as validate a robust methodology for\ndetecting microarchitectural flaws. As such, this approach enables a shift from\nreactive patching to proactive security validation in processor design.", "comment": "Accepted at IEEE SP 2025; delayed due to embargo; to appear at IEEE\n  SP 2026", "pdf_url": "http://arxiv.org/pdf/2507.06039v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06004", "title": "From General Relation Patterns to Task-Specific Decision-Making in Continual Multi-Agent Coordination", "authors": ["Chang Yao", "Youfang Lin", "Shoucheng Song", "Hao Wu", "Yuqing Ma", "Shang Han", "Kai Lv"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      IJCAI 2025 Accepted", "url": "http://arxiv.org/abs/2507.06004v1", "summary": "Continual Multi-Agent Reinforcement Learning (Co-MARL) requires agents to\naddress catastrophic forgetting issues while learning new coordination policies\nwith the dynamics team. In this paper, we delve into the core of Co-MARL,\nnamely Relation Patterns, which refer to agents' general understanding of\ninteractions. In addition to generality, relation patterns exhibit\ntask-specificity when mapped to different action spaces. To this end, we\npropose a novel method called General Relation Patterns-Guided Task-Specific\nDecision-Maker (RPG). In RPG, agents extract relation patterns from dynamic\nobservation spaces using a relation capturer. These task-agnostic relation\npatterns are then mapped to different action spaces via a task-specific\ndecision-maker generated by a conditional hypernetwork. To combat forgetting,\nwe further introduce regularization items on both the relation capturer and the\nconditional hypernetwork. Results on SMAC and LBF demonstrate that RPG\neffectively prevents catastrophic forgetting when learning new tasks and\nachieves zero-shot generalization to unseen tasks.", "comment": "IJCAI 2025 Accepted", "pdf_url": "http://arxiv.org/pdf/2507.06004v1", "cate": "cs.MA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06043", "title": "CAVGAN: Unifying Jailbreak and Defense of LLMs via Generative Adversarial Attacks on their Internal Representations", "authors": ["Xiaohu Li", "Yunfeng Ning", "Zepeng Bao", "Mayi Xu", "Jianhao Chen", "Tieyun Qian"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06043v1", "summary": "Security alignment enables the Large Language Model (LLM) to gain the\nprotection against malicious queries, but various jailbreak attack methods\nreveal the vulnerability of this security mechanism. Previous studies have\nisolated LLM jailbreak attacks and defenses. We analyze the security protection\nmechanism of the LLM, and propose a framework that combines attack and defense.\nOur method is based on the linearly separable property of LLM intermediate\nlayer embedding, as well as the essence of jailbreak attack, which aims to\nembed harmful problems and transfer them to the safe area. We utilize\ngenerative adversarial network (GAN) to learn the security judgment boundary\ninside the LLM to achieve efficient jailbreak attack and defense. The\nexperimental results indicate that our method achieves an average jailbreak\nsuccess rate of 88.85\\% across three popular LLMs, while the defense success\nrate on the state-of-the-art jailbreak dataset reaches an average of 84.17\\%.\nThis not only validates the effectiveness of our approach but also sheds light\non the internal security mechanisms of LLMs, offering new insights for\nenhancing model security The code and data are available at\nhttps://github.com/NLPGM/CAVGAN.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06043v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05275", "title": "A Fuzzy Supervisor Agent Design for Clinical Reasoning Assistance in a Multi-Agent Educational Clinical Scenario Simulation", "authors": ["Weibing Zheng", "Laurah Turner", "Jess Kropczynski", "Murat Ozer", "Seth Overla", "Shane Halse"], "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.LO", "cs.MA", "D.2.4; K.3.1; C.3; I.2.6"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, 1 table. 2025 IFSA World Congress NAFIPS Annual Meeting", "url": "http://arxiv.org/abs/2507.05275v1", "summary": "Assisting medical students with clinical reasoning (CR) during clinical\nscenario training remains a persistent challenge in medical education. This\npaper presents the design and architecture of the Fuzzy Supervisor Agent (FSA),\na novel component for the Multi-Agent Educational Clinical Scenario Simulation\n(MAECSS) platform. The FSA leverages a Fuzzy Inference System (FIS) to\ncontinuously interpret student interactions with specialized clinical agents\n(e.g., patient, physical exam, diagnostic, intervention) using pre-defined\nfuzzy rule bases for professionalism, medical relevance, ethical behavior, and\ncontextual distraction. By analyzing student decision-making processes in\nreal-time, the FSA is designed to deliver adaptive, context-aware feedback and\nprovides assistance precisely when students encounter difficulties. This work\nfocuses on the technical framework and rationale of the FSA, highlighting its\npotential to provide scalable, flexible, and human-like supervision in\nsimulation-based medical education. Future work will include empirical\nevaluation and integration into broader educational settings. More detailed\ndesign and implementation is~\\href{https://github.com/2sigmaEdTech/MAS/}{open\nsourced here}.", "comment": "6 pages, 3 figures, 1 table. 2025 IFSA World Congress NAFIPS Annual\n  Meeting", "pdf_url": "http://arxiv.org/pdf/2507.05275v1", "cate": "cs.CY", "date": "2025-07-03", "updated": "2025-07-03"}
{"id": "2507.06064", "title": "Wrapless: The trustless lending protocol on top of Bitcoin", "authors": ["Oleksandr Kurbatov", "Kyrylo Baybula", "Yaroslava Chopa", "Sergey Kozlov", "Oleg Komendant", "Illia Dovgopoly", "Dmitrii Kurbatov", "Zakhar Naumets", "Yulia Artikulova", "Pavel Kravchenko", "Volodymyr Dubinin", "Lasha Antadze", "Yaroslav Panasenko", "Mykhailo Velykodnyi"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06064v1", "summary": "This paper presents Wrapless -- a lending protocol that enables the\ncollateralization of bitcoins without requiring a trusted wrapping mechanism.\nThe protocol facilitates a \"loan channel\" on the Bitcoin blockchain, allowing\nbitcoins to be locked as collateral for loans issued on any blockchain that\nsupports Turing-complete smart contracts. The protocol is designed in a way\nthat makes it economically irrational for each involved party to manipulate the\nloan rules. There is still a significant research area to bring the protocol\ncloser to traditional AMM financial instruments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06064v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05292", "title": "A LLM-Driven Multi-Agent Systems for Professional Development of Mathematics Teachers", "authors": ["Kaiqi Yang", "Hang Li", "Yucheng Chu", "Ahreum Han", "Yasemin Copur-Gencturk", "Jiliang Tang", "Hui Liu"], "categories": ["cs.CY", "cs.HC", "cs.MA"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05292v1", "summary": "Professional development (PD) serves as the cornerstone for teacher tutors to\ngrasp content knowledge. However, providing equitable and timely PD\nopportunities for teachers poses significant challenges. To address this issue,\nwe introduce I-VIP (Intelligent Virtual Interactive Program), an intelligent\ntutoring platform for teacher professional development, driven by large\nlanguage models (LLMs) and supported by multi-agent frameworks. This platform\noffers a user-friendly conversational interface and allows users to employ a\nvariety of interactive tools to facilitate question answering, knowledge\ncomprehension, and reflective summarization while engaging in dialogue. To\nunderpin the functionality of this platform, including knowledge expectation\nanalysis, response scoring and classification, and feedback generation, the\nmulti-agent frameworks are leveraged to enhance the accuracy of judgments and\nmitigate the issue of missing key points.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05292v1", "cate": "cs.CY", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.05331", "title": "A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation", "authors": ["TRI LBM Team", "Jose Barreiros", "Andrew Beaulieu", "Aditya Bhat", "Rick Cory", "Eric Cousineau", "Hongkai Dai", "Ching-Hsin Fang", "Kunimatsu Hashimoto", "Muhammad Zubair Irshad", "Masha Itkina", "Naveen Kuppuswamy", "Kuan-Hui Lee", "Katherine Liu", "Dale McConachie", "Ian McMahon", "Haruki Nishimura", "Calder Phillips-Grafflin", "Charles Richter", "Paarth Shah", "Krishnan Srinivasan", "Blake Wulfe", "Chen Xu", "Mengchao Zhang", "Alex Alspach", "Maya Angeles", "Kushal Arora", "Vitor Campagnolo Guizilini", "Alejandro Castro", "Dian Chen", "Ting-Sheng Chu", "Sam Creasey", "Sean Curtis", "Richard Denitto", "Emma Dixon", "Eric Dusel", "Matthew Ferreira", "Aimee Goncalves", "Grant Gould", "Damrong Guoy", "Swati Gupta", "Xuchen Han", "Kyle Hatch", "Brendan Hathaway", "Allison Henry", "Hillel Hochsztein", "Phoebe Horgan", "Shun Iwase", "Donovon Jackson", "Siddharth Karamcheti", "Sedrick Keh", "Joseph Masterjohn", "Jean Mercat", "Patrick Miller", "Paul Mitiguy", "Tony Nguyen", "Jeremy Nimmer", "Yuki Noguchi", "Reko Ong", "Aykut Onol", "Owen Pfannenstiehl", "Richard Poyner", "Leticia Priebe Mendes Rocha", "Gordon Richardson", "Christopher Rodriguez", "Derick Seale", "Michael Sherman", "Mariah Smith-Jones", "David Tago", "Pavel Tokmakov", "Matthew Tran", "Basile Van Hoorick", "Igor Vasiljevic", "Sergey Zakharov", "Mark Zolotas", "Rares Ambrus", "Kerri Fetzer-Borelli", "Benjamin Burchfiel", "Hadas Kress-Gazit", "Siyuan Feng", "Stacie Ford", "Russ Tedrake"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05331v1", "summary": "Robot manipulation has seen tremendous progress in recent years, with\nimitation learning policies enabling successful performance of dexterous and\nhard-to-model tasks. Concurrently, scaling data and model size has led to the\ndevelopment of capable language and vision foundation models, motivating\nlarge-scale efforts to create general-purpose robot foundation models. While\nthese models have garnered significant enthusiasm and investment, meaningful\nevaluation of real-world performance remains a challenge, limiting both the\npace of development and inhibiting a nuanced understanding of current\ncapabilities. In this paper, we rigorously evaluate multitask robot\nmanipulation policies, referred to as Large Behavior Models (LBMs), by\nextending the Diffusion Policy paradigm across a corpus of simulated and\nreal-world robot data. We propose and validate an evaluation pipeline to\nrigorously analyze the capabilities of these models with statistical\nconfidence. We compare against single-task baselines through blind, randomized\ntrials in a controlled setting, using both simulation and real-world\nexperiments. We find that multi-task pretraining makes the policies more\nsuccessful and robust, and enables teaching complex new tasks more quickly,\nusing a fraction of the data when compared to single-task baselines. Moreover,\nperformance predictably increases as pretraining scale and diversity grows.\nProject page: https://toyotaresearchinstitute.github.io/lbm1/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05331v1", "cate": "cs.RO", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06092", "title": "Taming Data Challenges in ML-based Security Tasks: Lessons from Integrating Generative AI", "authors": ["Shravya Kanchi", "Neal Mangaokar", "Aravind Cheruvu", "Sifat Muhammad Abdullah", "Shirin Nilizadeh", "Atul Prakash", "Bimal Viswanath"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06092v1", "summary": "Machine learning-based supervised classifiers are widely used for security\ntasks, and their improvement has been largely focused on algorithmic\nadvancements. We argue that data challenges that negatively impact the\nperformance of these classifiers have received limited attention. We address\nthe following research question: Can developments in Generative AI (GenAI)\naddress these data challenges and improve classifier performance? We propose\naugmenting training datasets with synthetic data generated using GenAI\ntechniques to improve classifier generalization. We evaluate this approach\nacross 7 diverse security tasks using 6 state-of-the-art GenAI methods and\nintroduce a novel GenAI scheme called Nimai that enables highly controlled data\nsynthesis. We find that GenAI techniques can significantly improve the\nperformance of security classifiers, achieving improvements of up to 32.6% even\nin severely data-constrained settings (only ~180 training samples).\nFurthermore, we demonstrate that GenAI can facilitate rapid adaptation to\nconcept drift post-deployment, requiring minimal labeling in the adjustment\nprocess. Despite successes, our study finds that some GenAI schemes struggle to\ninitialize (train and produce data) on certain security tasks. We also identify\ncharacteristics of specific tasks, such as noisy labels, overlapping class\ndistributions, and sparse feature vectors, which hinder performance boost using\nGenAI. We believe that our study will drive the development of future GenAI\ntools designed for security tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06092v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05820", "title": "Constella: Supporting Storywriters' Interconnected Character Creation through LLM-based Multi-Agents", "authors": ["Syemin Park", "Soobin Park", "Youn-kyung Lim"], "categories": ["cs.HC", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      50 pages", "url": "http://arxiv.org/abs/2507.05820v1", "summary": "Creating a cast of characters by attending to their relational dynamics is a\ncritical aspect of most long-form storywriting. However, our formative study\n(N=14) reveals that writers struggle to envision new characters that could\ninfluence existing ones, to balance similarities and differences among\ncharacters, and to intricately flesh out their relationships. Based on these\nobservations, we designed Constella, an LLM-based multi-agent tool that\nsupports storywriters' interconnected character creation process. Constella\nsuggests related characters (FRIENDS DISCOVERY feature), reveals the inner\nmindscapes of several characters simultaneously (JOURNALS feature), and\nmanifests relationships through inter-character responses (COMMENTS feature).\nOur 7-8 day deployment study with storywriters (N=11) shows that Constella\nenabled the creation of expansive communities composed of related characters,\nfacilitated the comparison of characters' thoughts and emotions, and deepened\nwriters' understanding of character relationships. We conclude by discussing\nhow multi-agent interactions can help distribute writers' attention and effort\nacross the character cast.", "comment": "50 pages", "pdf_url": "http://arxiv.org/pdf/2507.05820v1", "cate": "cs.HC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05410", "title": "Feature Geometry for Stereo Sidescan and Forward-looking Sonar", "authors": ["Kalin Norman", "Joshua G. Mangelson"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This is a submission to a workshop and was presented at the Workshop on Field Robotics, which was a part of ICRA 2025", "url": "http://arxiv.org/abs/2507.05410v1", "summary": "In this paper, we address stereo acoustic data fusion for marine robotics and\npropose a geometry-based method for projecting observed features from one sonar\nto another for a cross-modal stereo sonar setup that consists of both a\nforward-looking and a sidescan sonar. Our acoustic geometry for sidescan and\nforward-looking sonar is inspired by the epipolar geometry for stereo cameras,\nand we leverage relative pose information to project where an observed feature\nin one sonar image will be found in the image of another sonar. Additionally,\nwe analyze how both the feature location relative to the sonar and the relative\npose between the two sonars impact the projection. From simulated results, we\nidentify desirable stereo configurations for applications in field robotics\nlike feature correspondence and recovery of the 3D information of the feature.", "comment": "This is a submission to a workshop and was presented at the Workshop\n  on Field Robotics, which was a part of ICRA 2025", "pdf_url": "http://arxiv.org/pdf/2507.05410v1", "cate": "cs.RO", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05267", "title": "Strongly Solving $7 \\times 6$ Connect-Four on Consumer Grade Hardware", "authors": ["Markus Böck"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05267v1", "summary": "While the game Connect-Four has been solved mathematically and the best move\ncan be effectively computed with search based methods, a strong solution in the\nform of a look-up table was believed to be infeasible. In this paper, we\nrevisit a symbolic search method based on binary decision diagrams to produce\nstrong solutions. With our efficient implementation we were able to produce a\n89.6 GB large look-up table in 47 hours on a single CPU core with 128 GB main\nmemory for the standard $7 \\times 6$ board size. In addition to this\nwin-draw-loss evaluation, we include an alpha-beta search in our open source\nartifact to find the move which achieves the fastest win or slowest loss.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05267v1", "cate": "cs.AI", "date": "2025-07-01", "updated": "2025-07-01"}
{"id": "2507.06112", "title": "Fun with flags: How Compilers Break and Fix Constant-Time Code", "authors": ["Antoine Geimer", "Clementine Maurice"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      11 pages", "url": "http://arxiv.org/abs/2507.06112v1", "summary": "Developers rely on constant-time programming to prevent timing side-channel\nattacks. But these efforts can be undone by compilers, whose optimizations may\nsilently reintroduce leaks. While recent works have measured the extent of such\nleakage, they leave developers without actionable insights: which optimization\npasses are responsible, and how to disable them without modifying the compiler\nremains unclear.\n  In this paper, we conduct a qualitative analysis of how compiler\noptimizations break constant-time code. We construct a dataset of\ncompiler-introduced constant-time violations and analyze the internals of two\nwidely used compilers, GCC and LLVM, to identify the specific optimization\npasses responsible. Our key insight is that a small set of passes are at the\nroot of most leaks. To the best of our knowledge, we are also the first to\ncharacterize how the interactions between these passes contribute to leakage.\nBased on this analysis, we propose an original and practical mitigation that\nrequires no source code modification or custom compiler: disabling selected\noptimization passes via compiler flags. We show that this approach\nsignificantly reduces leakage with minimal performance overhead, offering an\nimmediately deployable defense for developers.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2507.06112v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06129", "title": "Learning-Augmented Model-Based Multi-Robot Planning for Time-Critical Search and Inspection Under Uncertainty", "authors": ["Abhish Khanal", "Joseph Prince Mathew", "Cameron Nowzari", "Gregory J. Stein"], "categories": ["cs.RO", "cs.MA"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages, 6 figures, CASE 2025", "url": "http://arxiv.org/abs/2507.06129v1", "summary": "In disaster response or surveillance operations, quickly identifying areas\nneeding urgent attention is critical, but deploying response teams to every\nlocation is inefficient or often impossible. Effective performance in this\ndomain requires coordinating a multi-robot inspection team to prioritize\ninspecting locations more likely to need immediate response, while also\nminimizing travel time. This is particularly challenging because robots must\ndirectly observe the locations to determine which ones require additional\nattention. This work introduces a multi-robot planning framework for\ncoordinated time-critical multi-robot search under uncertainty. Our approach\nuses a graph neural network to estimate the likelihood of PoIs needing\nattention from noisy sensor data and then uses those predictions to guide a\nmulti-robot model-based planner to determine the cost-effective plan. Simulated\nexperiments demonstrate that our planner improves performance at least by\n16.3\\%, 26.7\\%, and 26.2\\% for 1, 3, and 5 robots, respectively, compared to\nnon-learned and learned baselines. We also validate our approach on real-world\nplatforms using quad-copters.", "comment": "7 pages, 6 figures, CASE 2025", "pdf_url": "http://arxiv.org/pdf/2507.06129v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05458", "title": "CRED: Counterfactual Reasoning and Environment Design for Active Preference Learning", "authors": ["Yi-Shiuan Tung", "Bradley Hayes", "Alessandro Roncone"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05458v1", "summary": "For effective real-world deployment, robots should adapt to human\npreferences, such as balancing distance, time, and safety in delivery routing.\nActive preference learning (APL) learns human reward functions by presenting\ntrajectories for ranking. However, existing methods often struggle to explore\nthe full trajectory space and fail to identify informative queries,\nparticularly in long-horizon tasks. We propose CRED, a trajectory generation\nmethod for APL that improves reward estimation by jointly optimizing\nenvironment design and trajectory selection. CRED \"imagines\" new scenarios\nthrough environment design and uses counterfactual reasoning -- by sampling\nrewards from its current belief and asking \"What if this reward were the true\npreference?\" -- to generate a diverse and informative set of trajectories for\nranking. Experiments in GridWorld and real-world navigation using OpenStreetMap\ndata show that CRED improves reward learning and generalizes effectively across\ndifferent environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05458v1", "cate": "cs.RO", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05283", "title": "Chat2SPaT: A Large Language Model Based Tool for Automating Traffic Signal Control Plan Management", "authors": ["Yue Wang", "Miao Zhou", "Guijing Huang", "Rui Zhuo", "Chao Yi", "Zhenliang Ma"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05283v1", "summary": "Pre-timed traffic signal control, commonly used for operating signalized\nintersections and coordinated arterials, requires tedious manual work for\nsignaling plan creating and updating. When the time-of-day or day-of-week plans\nare utilized, one intersection is often associated with multiple plans, leading\nto further repetitive manual plan parameter inputting. To enable a\nuser-friendly traffic signal control plan management process, this study\nproposes Chat2SPaT, a method to convert users' semi-structured and ambiguous\ndescriptions on the signal control plan to exact signal phase and timing (SPaT)\nresults, which could further be transformed into structured stage-based or\nring-based plans to interact with intelligent transportation system (ITS)\nsoftware and traffic signal controllers. With curated prompts, Chat2SPaT first\nleverages large language models' (LLMs) capability of understanding users' plan\ndescriptions and reformulate the plan as a combination of phase sequence and\nphase attribute results in the json format. Based on LLM outputs, python\nscripts are designed to locate phases in a cycle, address nuances of traffic\nsignal control, and finally assemble the complete traffic signal control plan.\nWithin a chat, the pipeline can be utilized iteratively to conduct further plan\nediting. Experiments show that Chat2SPaT can generate plans with an accuracy of\nover 94% for both English and Chinese cases, using a test dataset with over 300\nplan descriptions. As the first benchmark for evaluating LLMs' capability of\nunderstanding traffic signal control plan descriptions, Chat2SPaT provides an\neasy-to-use plan management pipeline for traffic practitioners and researchers,\nserving as a potential new building block for a more accurate and versatile\napplication of LLMs in the field of ITS. The source codes, prompts and test\ndataset are openly accessible at https://github.com/yuewangits/Chat2SPaT.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05283v1", "cate": "cs.AI", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.05523", "title": "Adaptive Variation-Resilient Random Number Generator for Embedded Encryption", "authors": ["Furqan Zahoor", "Ibrahim A. Albulushi", "Saleh Bunaiyan", "Anupam Chattopadhyay", "Hesham ElSawy", "Feras Al-Dirini"], "categories": ["cs.ET", "cond-mat.dis-nn", "cs.CR"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05523v1", "summary": "With a growing interest in securing user data within the internet-of-things\n(IoT), embedded encryption has become of paramount importance, requiring\nlight-weight high-quality Random Number Generators (RNGs). Emerging stochastic\ndevice technologies produce random numbers from stochastic physical processes\nat high quality, however, their generated random number streams are adversely\naffected by process and supply voltage variations, which can lead to bias in\nthe generated streams. In this work, we present an adaptive variation-resilient\nRNG capable of extracting unbiased encryption-grade random number streams from\nphysically driven entropy sources, for embedded cryptography applications. As a\nproof of concept, we employ a stochastic magnetic tunnel junction (sMTJ) device\nas an entropy source. The impact of variations in the sMTJ is mitigated by\nemploying an adaptive digitizer with an adaptive voltage reference that\ndynamically tracks any stochastic signal drift or deviation, leading to\nunbiased random bit stream generation. The generated unbiased bit streams, due\nto their higher entropy, then only need to undergo simplified post-processing.\nStatistical randomness tests based on the National Institute of Standards and\nTechnology (NIST) test suite are conducted on bit streams obtained using\nsimulations and FPGA entropy source emulation experiments, validating\nencryption-grade randomness at a significantly reduced hardware cost, and\nacross a wide range of process-induced device variations and supply voltage\nfluctuations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05523v1", "cate": "cs.ET", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2411.09168", "title": "An AI Theory of Mind Will Enhance Our Collective Intelligence", "authors": ["Michael S. Harré", "Catherine Drysdale", "Jaime Ruiz-Serra"], "categories": ["cs.MA", "cs.AI", "cs.CY", "cs.GT", "nlin.AO"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      26 pages, 2 figures, 1 table", "url": "http://arxiv.org/abs/2411.09168v2", "summary": "Collective intelligence plays a central role in many fields, from economics\nand evolutionary theory to neural networks and eusocial insects, and is also\ncore to work on emergence and self-organisation in complex-systems theory.\nHowever, in human collective intelligence there is still much to understand\nabout how specific psychological processes at the individual level give rise to\nself-organised structures at the social level. Psychological factors have so\nfar played a minor role in collective-intelligence studies because the\nprinciples are often general and applicable to agents without sophisticated\npsychologies. We emphasise, with examples from other complex adaptive systems,\nthe broad applicability of collective-intelligence principles, while noting\nthat mechanisms and time scales differ markedly between cases. We review\nevidence that flexible collective intelligence in human social settings is\nimproved by a particular cognitive tool: our Theory of Mind. We then\nhypothesise that AIs equipped with a theory of mind will enhance collective\nintelligence in ways similar to human contributions. To make this case, we step\nback from the algorithmic basis of AI psychology and consider the large-scale\nimpact AI can have as agential actors in a 'social ecology' rather than as mere\ntechnological tools. We identify several key characteristics of psychologically\nmediated collective intelligence and show that the development of a Theory of\nMind is crucial in distinguishing human social collective intelligence from\nmore general forms. Finally, we illustrate how individuals, human or otherwise,\nintegrate within a collective not by being genetically or algorithmically\nprogrammed, but by growing and adapting into the socio-cognitive niche they\noccupy. AI can likewise inhabit one or multiple such niches, facilitated by a\nTheory of Mind.", "comment": "26 pages, 2 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2411.09168v2", "cate": "cs.MA", "date": "2024-11-14", "updated": "2025-07-08"}
{"id": "2507.05522", "title": "Gaussian Process-Based Active Exploration Strategies in Vision and Touch", "authors": ["Ho Jin Choi", "Nadia Figueroa"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Master's Thesis, Mechanical Engineering and Applied Mechanics, University of Pennsylvania - April 2024 ( this https URL ) ( this https URL )", "url": "http://arxiv.org/abs/2507.05522v1", "summary": "Robots struggle to understand object properties like shape, material, and\nsemantics due to limited prior knowledge, hindering manipulation in\nunstructured environments. In contrast, humans learn these properties through\ninteractive multi-sensor exploration. This work proposes fusing visual and\ntactile observations into a unified Gaussian Process Distance Field (GPDF)\nrepresentation for active perception of object properties. While primarily\nfocusing on geometry, this approach also demonstrates potential for modeling\nsurface properties beyond geometry. The GPDF encodes signed distance using\npoint cloud, analytic gradient and Hessian, and surface uncertainty estimates,\nwhich are attributes that common neural network shape representation lack. By\nutilizing a point cloud to construct a distance function, GPDF does not need\nextensive pretraining on large datasets and can incorporate observations by\naggregation. Starting with an initial visual shape estimate, the framework\niteratively refines the geometry by integrating dense vision measurements using\ndifferentiable rendering and tactile measurements at uncertain surface regions.\nBy quantifying multi-sensor uncertainties, it plans exploratory motions to\nmaximize information gain for recovering precise 3D structures. For the\nreal-world robot experiment, we utilize the Franka Research 3 robot\nmanipulator, which is fixed on a table and has a customized DIGIT tactile\nsensor and an Intel Realsense D435 RGBD camera mounted on the end-effector. In\nthese experiments, the robot explores the shape and properties of objects\nassumed to be static and placed on the table. To improve scalability, we\ninvestigate approximation methods like inducing point method for Gaussian\nProcesses. This probabilistic multi-modal fusion enables active exploration and\nmapping of complex object geometries, extending potentially beyond geometry.", "comment": "Master's Thesis, Mechanical Engineering and Applied Mechanics,\n  University of Pennsylvania - April 2024\n  (https://events.seas.upenn.edu/event/meam-masters-thesis-defense-gaussian-process-based-active-exploration-strategies-in-vision-and-touch/)\n  (https://blog.me.upenn.edu/ho-jin-choi-successfully-defends-masters-thesis/)", "pdf_url": "http://arxiv.org/pdf/2507.05522v1", "cate": "cs.RO", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05297", "title": "Fuzzy Classification Aggregation for a Continuum of Agents", "authors": ["Zijun Meng"], "categories": ["cs.AI", "econ.TH"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05297v1", "summary": "We prove that any optimal, independent, and zero unanimous fuzzy\nclassification aggregation function of a continuum of individual\nclassifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted\narithmetic mean.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05297v1", "cate": "cs.AI", "date": "2025-07-06", "updated": "2025-07-06"}
{"id": "2507.05538", "title": "Red Teaming AI Red Teaming", "authors": ["Subhabrata Majumdar", "Brian Pendleton", "Abhishek Gupta"], "categories": ["cs.AI", "cs.CR", "cs.CY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05538v1", "summary": "Red teaming has evolved from its origins in military applications to become a\nwidely adopted methodology in cybersecurity and AI. In this paper, we take a\ncritical look at the practice of AI red teaming. We argue that despite its\ncurrent popularity in AI governance, there exists a significant gap between red\nteaming's original intent as a critical thinking exercise and its narrow focus\non discovering model-level flaws in the context of generative AI. Current AI\nred teaming efforts focus predominantly on individual model vulnerabilities\nwhile overlooking the broader sociotechnical systems and emergent behaviors\nthat arise from complex interactions between models, users, and environments.\nTo address this deficiency, we propose a comprehensive framework\noperationalizing red teaming in AI systems at two levels: macro-level system\nred teaming spanning the entire AI development lifecycle, and micro-level model\nred teaming. Drawing on cybersecurity experience and systems theory, we further\npropose a set of recommendations. In these, we emphasize that effective AI red\nteaming requires multifunctional teams that examine emergent risks, systemic\nvulnerabilities, and the interplay between technical and social factors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05538v1", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2505.13543", "title": "Origin-Destination Pattern Effects on Large-Scale Mixed Traffic Control via Multi-Agent Reinforcement Learning", "authors": ["Muyang Fan", "Songyang Liu", "Shuai Li", "Weizi Li"], "categories": ["cs.MA", "cs.CY"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE International Conference on Intelligent Transportation Systems (ITSC), 2025", "url": "http://arxiv.org/abs/2505.13543v2", "summary": "Traffic congestion remains a major challenge for modern urban transportation,\ndiminishing both efficiency and quality of life. While autonomous driving\ntechnologies and reinforcement learning (RL) have shown promise for improving\ntraffic control, most prior work has focused on small-scale networks or\nisolated intersections. Large-scale mixed traffic control, involving both\nhuman-driven and robotic vehicles, remains underexplored. In this study, we\npropose a decentralized multi-agent reinforcement learning framework for\nmanaging large-scale mixed traffic networks, where intersections are controlled\neither by traditional traffic signals or by robotic vehicles. We evaluate our\napproach on a real-world network of 14 intersections in Colorado Springs,\nColorado, USA, using average vehicle waiting time as the primary measure of\ntraffic efficiency. We are exploring a problem that has not been sufficiently\naddressed: Is large-scale Multi-Agent Traffic Control (MTC) still feasible when\nfacing time-varying Origin-Destination (OD) patterns?", "comment": "Accepted to IEEE International Conference on Intelligent\n  Transportation Systems (ITSC), 2025", "pdf_url": "http://arxiv.org/pdf/2505.13543v2", "cate": "cs.MA", "date": "2025-05-19", "updated": "2025-07-08"}
{"id": "2507.05555", "title": "PAPRLE (Plug-And-Play Robotic Limb Environment): A Modular Ecosystem for Robotic Limbs", "authors": ["Obin Kwon", "Sankalp Yamsani", "Noboru Myers", "Sean Taylor", "Jooyoung Hong", "Kyungseo Park", "Alex Alspach", "Joohyung Kim"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05555v1", "summary": "We introduce PAPRLE (Plug-And-Play Robotic Limb Environment), a modular\necosystem that enables flexible placement and control of robotic limbs. With\nPAPRLE, a user can change the arrangement of the robotic limbs, and control\nthem using a variety of input devices, including puppeteers, gaming\ncontrollers, and VR-based interfaces. This versatility supports a wide range of\nteleoperation scenarios and promotes adaptability to different task\nrequirements. To further enhance configurability, we introduce a pluggable\npuppeteer device that can be easily mounted and adapted to match the target\nrobot configurations. PAPRLE supports bilateral teleoperation through these\npuppeteer devices, agnostic to the type or configuration of the follower robot.\nBy supporting both joint-space and task-space control, the system provides\nreal-time force feedback, improving user fidelity and physical interaction\nawareness. The modular design of PAPRLE facilitates novel spatial arrangements\nof the limbs and enables scalable data collection, thereby advancing research\nin embodied AI and learning-based control. We validate PAPRLE in various\nreal-world settings, demonstrating its versatility across diverse combinations\nof leader devices and follower robots. The system will be released as open\nsource, including both hardware and software components, to support broader\nadoption and community-driven extension. Additional resources and\ndemonstrations are available at the project website:\nhttps://uiuckimlab.github.io/paprle-pages", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05555v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05488", "title": "OLG++: A Semantic Extension of Obligation Logic Graph", "authors": ["Subhasis Dasgupta", "Jon Stephens", "Amarnath Gupta"], "categories": ["cs.AI", "cs.CY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05488v1", "summary": "We present OLG++, a semantic extension of the Obligation Logic Graph (OLG)\nfor modeling regulatory and legal rules in municipal and interjurisdictional\ncontexts. OLG++ introduces richer node and edge types, including spatial,\ntemporal, party group, defeasibility, and logical grouping constructs, enabling\nnuanced representations of legal obligations, exceptions, and hierarchies. The\nmodel supports structured reasoning over rules with contextual conditions,\nprecedence, and complex triggers. We demonstrate its expressiveness through\nexamples from food business regulations, showing how OLG++ supports legal\nquestion answering using property graph queries. OLG++ also improves over\nLegalRuleML by providing native support for subClassOf, spatial constraints,\nand reified exception structures. Our examples show that OLG++ is more\nexpressive than prior graph-based models for legal knowledge representation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05488v1", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05556", "title": "Per-Row Activation Counting on Real Hardware: Demystifying Performance Overheads", "authors": ["Jumin Kim", "Seungmin Baek", "Minbok Wi", "Hwayong Nam", "Michael Jaemin Kim", "Sukhan Lee", "Kyomin Sohn", "Jung Ho Ahn"], "categories": ["cs.AR", "cs.CR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      4 pages, 4 figures, to appear at IEEE Computer Architecture Letters", "url": "http://arxiv.org/abs/2507.05556v1", "summary": "Per-Row Activation Counting (PRAC), a DRAM read disturbance mitigation\nmethod, modifies key DRAM timing parameters, reportedly causing significant\nperformance overheads in simulator-based studies. However, given known\ndiscrepancies between simulators and real hardware, real-machine experiments\nare vital for accurate PRAC performance estimation. We present the first\nreal-machine performance analysis of PRAC. After verifying timing modifications\non the latest CPUs using microbenchmarks, our analysis shows that PRAC's\naverage and maximum overheads are just 1.06% and 3.28% for the SPEC CPU2017\nworkloads -- up to 9.15x lower than simulator-based reports. Further, we show\nthat the close page policy minimizes this overhead by effectively hiding the\nelongated DRAM row precharge operations due to PRAC from the critical path.", "comment": "4 pages, 4 figures, to appear at IEEE Computer Architecture Letters", "pdf_url": "http://arxiv.org/pdf/2507.05556v1", "cate": "cs.AR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2503.08725", "title": "The Algorithmic State Architecture (ASA): An Integrated Framework for AI-Enabled Government", "authors": ["Zeynep Engin", "Jon Crowcroft", "David Hand", "Philip Treleaven"], "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Main text: 25 pages, with references: 35 pages, 2 figures", "url": "http://arxiv.org/abs/2503.08725v3", "summary": "As artificial intelligence transforms public sector operations, governments\nstruggle to integrate technological innovations into coherent systems for\neffective service delivery. This paper introduces the Algorithmic State\nArchitecture (ASA), a novel four-layer framework conceptualising how Digital\nPublic Infrastructure, Data-for-Policy, Algorithmic Government/Governance, and\nGovTech interact as an integrated system in AI-enabled states. Unlike\napproaches that treat these as parallel developments, ASA positions them as\ninterdependent layers with specific enabling relationships and feedback\nmechanisms. Through comparative analysis of implementations in Estonia,\nSingapore, India, and the UK, we demonstrate how foundational digital\ninfrastructure enables systematic data collection, which powers algorithmic\ndecision-making processes, ultimately manifesting in user-facing services. Our\nanalysis reveals that successful implementations require balanced development\nacross all layers, with particular attention to integration mechanisms between\nthem. The framework contributes to both theory and practice by bridging\npreviously disconnected domains of digital government research, identifying\ncritical dependencies that influence implementation success, and providing a\nstructured approach for analysing the maturity and development pathways of\nAI-enabled government systems.", "comment": "Main text: 25 pages, with references: 35 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2503.08725v3", "cate": "cs.CY", "date": "2025-03-11", "updated": "2025-07-08"}
{"id": "2507.05607", "title": "Structured Task Solving via Modular Embodied Intelligence: A Case Study on Rubik's Cube", "authors": ["Chongshan Fan", "Shenghai Yuan"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05607v1", "summary": "This paper presents Auto-RubikAI, a modular autonomous planning framework\nthat integrates a symbolic Knowledge Base (KB), a vision-language model (VLM),\nand a large language model (LLM) to solve structured manipulation tasks\nexemplified by Rubik's Cube restoration. Unlike traditional robot systems based\non predefined scripts, or modern approaches relying on pretrained networks and\nlarge-scale demonstration data, Auto-RubikAI enables interpretable, multi-step\ntask execution with minimal data requirements and no prior demonstrations. The\nproposed system employs a KB module to solve group-theoretic restoration steps,\novercoming LLMs' limitations in symbolic reasoning. A VLM parses RGB-D input to\nconstruct a semantic 3D scene representation, while the LLM generates\nstructured robotic control code via prompt chaining. This tri-module\narchitecture enables robust performance under spatial uncertainty. We deploy\nAuto-RubikAI in both simulation and real-world settings using a 7-DOF robotic\narm, demonstrating effective Sim-to-Real adaptation without retraining.\nExperiments show a 79% end-to-end task success rate across randomized\nconfigurations. Compared to CFOP, DeepCubeA, and Two-Phase baselines, our\nKB-enhanced method reduces average solution steps while maintaining\ninterpretability and safety. Auto-RubikAI provides a cost-efficient, modular\nfoundation for embodied task planning in smart manufacturing, robotics\neducation, and autonomous execution scenarios. Code, prompts, and hardware\nmodules will be released upon publication.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05607v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05495", "title": "Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents", "authors": ["Prahaladh Chandrahasan", "Jiahe Jin", "Zhihan Zhang", "Tevin Wang", "Andy Tang", "Lucy Mo", "Morteza Ziyadi", "Leonardo F. R. Ribeiro", "Zimeng Qiu", "Markus Dreyer", "Akari Asai", "Chenyan Xiong"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05495v1", "summary": "Effectively evaluating deep research agents that autonomously search the web,\nanalyze information, and generate reports remains a major challenge,\nparticularly when it comes to assessing long reports and giving detailed\nfeedback on their intermediate steps. To address these gaps, we introduce Deep\nResearch Comparator, a platform that offers a holistic framework for deep\nresearch agent hosting, side-by-side comparison, fine-grained human feedback\ncollection, and ranking calculation. Given a user query, our platform displays\nthe final reports from two different agents along with their intermediate steps\nduring generation. Annotators can evaluate the overall quality of final reports\nbased on side-by-side comparison, and also provide detailed feedback separately\nby assessing intermediate steps or specific text spans within the final report.\nFurthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This\nscaffold serves as a baseline that facilitates the easy integration of various\nlarge language models to transform them into deep research agents for\nevaluation. To demonstrate the platform's utility for deep research agent\ndevelopment, we have collected real user preference data from 17 annotators on\nthree deep research agents. A demo video of our platform can be found at\nhttps://www.youtube.com/watch?v=g4d2dnbdseg.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05495v1", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05578", "title": "The Landscape of Memorization in LLMs: Mechanisms, Measurement, and Mitigation", "authors": ["Alexander Xiong", "Xuandong Zhao", "Aneesh Pappu", "Dawn Song"], "categories": ["cs.LG", "cs.CL", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05578v1", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na wide range of tasks, yet they also exhibit memorization of their training\ndata. This phenomenon raises critical questions about model behavior, privacy\nrisks, and the boundary between learning and memorization. Addressing these\nconcerns, this paper synthesizes recent studies and investigates the landscape\nof memorization, the factors influencing it, and methods for its detection and\nmitigation. We explore key drivers, including training data duplication,\ntraining dynamics, and fine-tuning procedures that influence data memorization.\nIn addition, we examine methodologies such as prefix-based extraction,\nmembership inference, and adversarial prompting, assessing their effectiveness\nin detecting and measuring memorized content. Beyond technical analysis, we\nalso explore the broader implications of memorization, including the legal and\nethical implications. Finally, we discuss mitigation strategies, including data\ncleaning, differential privacy, and post-training unlearning, while\nhighlighting open challenges in balancing the minimization of harmful\nmemorization with utility. This paper provides a comprehensive overview of the\ncurrent state of research on LLM memorization across technical, privacy, and\nperformance dimensions, identifying critical directions for future work.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05578v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2505.07501", "title": "The Complexity of Pure Strategy Relevant Equilibria in Concurrent Games", "authors": ["Purandar Bhaduri"], "categories": ["cs.GT", "cs.FL", "cs.LO", "cs.MA"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.07501v3", "summary": "We study rational synthesis problems for concurrent games with\n$\\omega$-regular objectives. Our model of rationality considers only pure\nstrategy Nash equilibria that satisfy either a social welfare or Pareto\noptimality condition with respect to an $\\omega$-regular objective for each\nagent. This extends earlier work on equilibria in concurrent games, without\nconsideration about their quality. Our results show that the existence of Nash\nequilibria satisfying social welfare conditions can be computed as efficiently\nas the constrained Nash equilibrium existence problem. On the other hand, the\nexistence of Nash equilibria satisfying the Pareto optimality condition\npossibly involves a higher upper bound, except in the case of B\\\"uchi and\nMuller games, for which all three problems are in the classes P and\nPSPACE-complete, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.07501v3", "cate": "cs.GT", "date": "2025-05-12", "updated": "2025-07-08"}
{"id": "2507.05627", "title": "DreamGrasp: Zero-Shot 3D Multi-Object Reconstruction from Partial-View Images for Robotic Manipulation", "authors": ["Young Hun Kim", "Seungyeon Kim", "Yonghyeon Lee", "Frank Chongwoo Park"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05627v1", "summary": "Partial-view 3D recognition -- reconstructing 3D geometry and identifying\nobject instances from a few sparse RGB images -- is an exceptionally\nchallenging yet practically essential task, particularly in cluttered, occluded\nreal-world settings where full-view or reliable depth data are often\nunavailable. Existing methods, whether based on strong symmetry priors or\nsupervised learning on curated datasets, fail to generalize to such scenarios.\nIn this work, we introduce DreamGrasp, a framework that leverages the\nimagination capability of large-scale pre-trained image generative models to\ninfer the unobserved parts of a scene. By combining coarse 3D reconstruction,\ninstance segmentation via contrastive learning, and text-guided instance-wise\nrefinement, DreamGrasp circumvents limitations of prior methods and enables\nrobust 3D reconstruction in complex, multi-object environments. Our experiments\nshow that DreamGrasp not only recovers accurate object geometry but also\nsupports downstream tasks like sequential decluttering and target retrieval\nwith high success rates.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05627v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05515", "title": "Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality", "authors": ["Haochen Huang", "Jiahuan Pei", "Mohammad Aliannejadi", "Xin Sun", "Moonisa Ahsan", "Pablo Cesar", "Chuang Yu", "Zhaochun Ren", "Junxiao Wang"], "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      20 pages", "url": "http://arxiv.org/abs/2507.05515v1", "summary": "Vision-language models (VLMs) are essential for enabling AI-powered smart\nassistants to interpret and reason in multimodal environments. However, their\napplication in augmented reality (AR) training remains largely unexplored. In\nthis work, we introduce a comprehensive dataset tailored for AR training,\nfeaturing systematized vision-language tasks, and evaluate nine\nstate-of-the-art VLMs on it. Our results reveal that even advanced models,\nincluding GPT-4o, struggle with fine-grained assembly tasks, achieving a\nmaximum F1 score of just 40.54% on state detection. These findings highlight\nthe demand for enhanced datasets, benchmarks, and further research to improve\nfine-grained vision-language alignment. Beyond technical contributions, our\nwork has broader social implications, particularly in empowering blind and\nvisually impaired users with equitable access to AI-driven learning\nopportunities. We provide all related resources, including the dataset, source\ncode, and evaluation results, to support the research community.", "comment": "20 pages", "pdf_url": "http://arxiv.org/pdf/2507.05515v1", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05263", "title": "Rethinking Over-Smoothing in Graph Neural Networks: A Perspective from Anderson Localization", "authors": ["Kaichen Ouyang"], "categories": ["cs.LG", "cs.AI", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      17 pages, 4 figures", "url": "http://arxiv.org/abs/2507.05263v1", "summary": "Graph Neural Networks (GNNs) have shown great potential in graph data\nanalysis due to their powerful representation capabilities. However, as the\nnetwork depth increases, the issue of over-smoothing becomes more severe,\ncausing node representations to lose their distinctiveness. This paper analyzes\nthe mechanism of over-smoothing through the analogy to Anderson localization\nand introduces participation degree as a metric to quantify this phenomenon.\nSpecifically, as the depth of the GNN increases, node features homogenize after\nmultiple layers of message passing, leading to a loss of distinctiveness,\nsimilar to the behavior of vibration modes in disordered systems. In this\ncontext, over-smoothing in GNNs can be understood as the expansion of\nlow-frequency modes (increased participation degree) and the localization of\nhigh-frequency modes (decreased participation degree). Based on this, we\nsystematically reviewed the potential connection between the Anderson\nlocalization behavior in disordered systems and the over-smoothing behavior in\nGraph Neural Networks. A theoretical analysis was conducted, and we proposed\nthe potential of alleviating over-smoothing by reducing the disorder in\ninformation propagation.", "comment": "17 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.05263v1", "cate": "cs.LG", "date": "2025-06-20", "updated": "2025-06-20"}
{"id": "2507.05446", "title": "Esports and expertise: what competitive gaming can teach us about mastery", "authors": ["Ben Boudaoud", "Josef Spjut", "Joohwan Kim", "Arjun Madhusudan", "Benjamin Watson"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05446v1", "summary": "Historically, much research and development in human computer interaction has\nfocused on atomic and generalizable tasks, where task completion time indicates\nproductivity. However, the emergence of competitive games and esports reminds\nus of an alternative perspective on human performance in HCI: mastery of\nhigher-level, holistic practices. Just as a world-renowned artist is rarely\nevaluated for their individual brush strokes, so skilled competitive gamers\nrarely succeed solely by completing individual mouse movements or keystrokes as\nquickly as possible. Instead, they optimize more task-specific skills, adeptly\nperforming challenges deep in the learning curve for their game of choice.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05446v1", "cate": "cs.HC", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05809", "title": "A Formal Refutation of the Blockchain Trilemma", "authors": ["Craig Wright"], "categories": ["cs.CC", "cs.CR", "cs.DC", "cs.DS", "03B70, 68M10, 91A80", "F.4.1; D.4.6; C.2.2"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "Comments:      12 pages", "url": "http://arxiv.org/abs/2507.05809v1", "summary": "The so-called blockchain trilemma asserts the impossibility of simultaneously\nachieving scalability, security, and decentralisation within a single\nblockchain protocol. In this paper, we formally refute that proposition.\nEmploying predicate logic, formal automata theory, computational complexity\nanalysis, and graph-theoretic measures of relay topology--specifically Baran's\nmodel of network path redundancy--we demonstrate that the trilemma constitutes\na category error, conflates distinct analytical domains, and relies upon\nunproven causal assumptions. We further expose its reliance on composition\nfallacies drawn from flawed system implementations. A constructive\ncounterexample is presented: a blockchain protocol exhibiting unbounded\ntransaction throughput, cryptographic security under adversarial load, and\nmultipath decentralised propagation. This example is not hypothetical but\ngrounded in protocol design enabled by compact block relay, SPV verification,\nand IPv6 multicast. The trilemma is revealed not as a law of protocol\narchitecture, but as a heuristic fallacy sustained by imprecision and design\ndefeatism.", "comment": "12 pages", "pdf_url": "http://arxiv.org/pdf/2507.05809v1", "cate": "cs.CC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.00631", "title": "Horus: A Protocol for Trustless Delegation Under Uncertainty", "authors": ["David Shi", "Kevin Joo"], "categories": ["cs.GT", "cs.AI", "cs.MA", "I.2.11; F.2.2"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "Comments:      9 pages, 1 figure", "url": "http://arxiv.org/abs/2507.00631v5", "summary": "Correctness is an emergent property of systems where exposing error is\ncheaper than committing it. In dynamic, low-trust environments, autonomous AI\nagents benefit from delegating work to sub-agents, yet correctness cannot be\nassured through upfront specification or centralized oversight. We propose a\nprotocol that enforces correctness through collateralized claims in a recursive\nverification game. Tasks are published as intents, and solvers compete to\nfulfill them. Selected solvers carry out tasks under risk, with correctness\nchecked post hoc by verifiers. Any challenger can challenge a result by staking\nagainst it to trigger the verification process. Incorrect agents are slashed\nand correct opposition is rewarded, with an escalation path that penalizes\nerroneous verifiers themselves. When incentives are aligned across solvers,\nchallengers, and verifiers, falsification conditions make correctness the Nash\nequilibrium.", "comment": "9 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.00631v5", "cate": "cs.GT", "date": "2025-07-01", "updated": "2025-07-08"}
{"id": "2507.05643", "title": "A Physics-Based Continuum Model for Versatile, Scalable, and Fast Terramechanics Simulation", "authors": ["Huzaifa Unjhawala", "Luning Bakke", "Harry Zhang", "Michael Taylor", "Ganesh Arivoli", "Radu Serban", "Dan Negrut"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      32 pages, 21 figures, Submitted to Journal of Terramechanics", "url": "http://arxiv.org/abs/2507.05643v1", "summary": "This paper discusses Chrono's Continuous Representation Model (called herein\nChrono::CRM), a general-purpose, scalable, and efficient simulation solution\nfor terramechanics problems. Built on Chrono's Smoothed Particle Hydrodynamics\n(SPH) framework, Chrono::CRM moves beyond semi-empirical terramechanics\napproaches, e.g., Bekker-Wong/Janosi-Hanamoto, to provide a physics-based model\nable to address complex tasks such as digging, grading, as well as interaction\nwith deformable wheels and complex grouser/lug patterns. The terramechanics\nmodel is versatile in that it allows the terrain to interact with both rigid\nand flexible implements simulated via the Chrono dynamics engine. We validate\nChrono::CRM against experimental data from three physical tests, including one\ninvolving NASA's MGRU3 rover. In addition, the simulator is benchmarked against\na high-fidelity Discrete Element Method (DEM) simulation of a digging scenario\ninvolving the Regolith Advanced Surface Systems Operations Robot (RASSOR).\nBeing GPU-accelerated, Chrono::CRM achieves computational efficiency comparable\nto that of semi-empirical simulation approaches for terramechanics problems.\nThrough an ``active domains'' implementation, Chrono::CRM can handle terrain\nstretches up to 10 km long with 100 million SPH particles at near interactive\nrates, making high-fidelity off-road simulations at large scales feasible. As a\ncomponent of the Chrono package, the CRM model is open source and released\nunder a BSD-3 license. All models and simulations used in this contribution are\navailable in a public GitHub repository for reproducibility studies and further\nresearch.", "comment": "32 pages, 21 figures, Submitted to Journal of Terramechanics", "pdf_url": "http://arxiv.org/pdf/2507.05643v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05519", "title": "Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicated Answer Set Programming System", "authors": ["Gopal Gupta", "Abhiramon Rajasekharan", "Alexis R. Tudor", "Elmer Salazar", "Joaquín Arias"], "categories": ["cs.AI", "cs.LO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05519v1", "summary": "We consider the problem of implementing deontic modal logic. We show how\n(deontic) modal operators can be expressed elegantly using default negation\n(negation-as-failure) and strong negation present in answer set programming\n(ASP). We propose using global constraints of ASP to represent obligations and\nimpermissibilities of deontic modal logic. We show that our proposed\nrepresentation results in the various paradoxes of deontic modal logic being\nelegantly resolved.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05519v1", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05284", "title": "Temporal Window Smoothing of Exogenous Variables for Improved Time Series Prediction", "authors": ["Mustafa Kamal", "Niyaz Bin Hashem", "Robin Krambroeckers", "Nabeel Mohammed", "Shafin Rahman"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at IJCNN 2025", "url": "http://arxiv.org/abs/2507.05284v1", "summary": "Although most transformer-based time series forecasting models primarily\ndepend on endogenous inputs, recent state-of-the-art approaches have\nsignificantly improved performance by incorporating external information\nthrough exogenous inputs. However, these methods face challenges, such as\nredundancy when endogenous and exogenous inputs originate from the same source\nand limited ability to capture long-term dependencies due to fixed look-back\nwindows. In this paper, we propose a method that whitens the exogenous input to\nreduce redundancy that may persist within the data based on global statistics.\nAdditionally, our approach helps the exogenous input to be more aware of\npatterns and trends over extended periods. By introducing this refined,\nglobally context-aware exogenous input to the endogenous input without\nincreasing the lookback window length, our approach guides the model towards\nimproved forecasting. Our approach achieves state-of-the-art performance in\nfour benchmark datasets, consistently outperforming 11 baseline models. These\nresults establish our method as a robust and effective alternative for using\nexogenous inputs in time series forecasting.", "comment": "Accepted at IJCNN 2025", "pdf_url": "http://arxiv.org/pdf/2507.05284v1", "cate": "cs.LG", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.05447", "title": "NRXR-ID: Two-Factor Authentication (2FA) in VR Using Near-Range Extended Reality and Smartphones", "authors": ["Aiur Nanzatov", "Lourdes Peña-Castillo", "Oscar Meruvia-Pastor"], "categories": ["cs.HC", "cs.CV", "cs.GR"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05447v1", "summary": "Two-factor authentication (2FA) has become widely adopted as an efficient and\nsecure way to validate someone's identity online. Two-factor authentication is\ndifficult in virtual reality (VR) because users are usually wearing a\nhead-mounted display (HMD) which does not allow them to see their real-world\nsurroundings. We present NRXR-ID, a technique to implement two-factor\nauthentication while using extended reality systems and smartphones. The\nproposed method allows users to complete an authentication challenge using\ntheir smartphones without removing their HMD. We performed a user study where\nwe explored four types of challenges for users, including a novel\ncheckers-style challenge. Users responded to these challenges under three\ndifferent configurations, including a technique that uses the smartphone to\nsupport gaze-based selection without the use of VR controllers. A 4X3\nwithin-subjects design allowed us to study all the variations proposed. We\ncollected performance metrics and performed user experience questionnaires to\ncollect subjective impressions from 30 participants. Results suggest that the\ncheckers-style visual matching challenge was the most appropriate option,\nfollowed by entering a digital PIN challenge submitted via the smartphone and\nanswered within the VR environment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05447v1", "cate": "cs.HC", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06156", "title": "Hedge Funds on a Swamp: Analyzing Patterns, Vulnerabilities, and Defense Measures in Blockchain Bridges [Experiment, Analysis \\& Benchmark]", "authors": ["Poupak Azad", "Jiahua Xu", "Yebo Feng", "Preston Strowbridge", "Cuneyt Akcora"], "categories": ["cs.ET", "cs.CR"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06156v1", "summary": "Blockchain bridges have become essential infrastructure for enabling\ninteroperability across different blockchain networks, with more than $24B\nmonthly bridge transaction volume. However, their growing adoption has been\naccompanied by a disproportionate rise in security breaches, making them the\nsingle largest source of financial loss in Web3. For cross-chain ecosystems to\nbe robust and sustainable, it is essential to understand and address these\nvulnerabilities. In this study, we present a comprehensive systematization of\nblockchain bridge design and security. We define three bridge security priors,\nformalize the architectural structure of 13 prominent bridges, and identify 23\nattack vectors grounded in real-world blockchain exploits. Using this\nfoundation, we evaluate 43 representative attack scenarios and introduce a\nlayered threat model that captures security failures across source chain,\noff-chain, and destination chain components.\n  Our analysis at the static code and transaction network levels reveals\nrecurring design flaws, particularly in access control, validator trust\nassumptions, and verification logic, and identifies key patterns in adversarial\nbehavior based on transaction-level traces. To support future development, we\npropose a decision framework for bridge architecture design, along with defense\nmechanisms such as layered validation and circuit breakers. This work provides\na data-driven foundation for evaluating bridge security and lays the groundwork\nfor standardizing resilient cross-chain infrastructure.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06156v1", "cate": "cs.ET", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.04376", "title": "MOD-X: A Modular Open Decentralized eXchange Framework proposal for Heterogeneous Interoperable Artificial Intelligence Agents", "authors": ["Georgios Ioannides", "Christos Constantinou", "Vinija Jain", "Aman Chadha", "Aaron Elkins"], "categories": ["cs.AI", "cs.DC", "cs.MA", "cs.NI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04376v2", "summary": "As Artificial Intelligence systems evolve from monolithic models to\necosystems of specialized agents, the need for standardized communication\nprotocols becomes increasingly critical. This paper introduces MOD-X (Modular\nOpen Decentralized eXchange), a novel architectural framework proposal for\nagent interoperability that addresses key limitations of existing protocols.\nUnlike current approaches, MOD-X proposes a layered architecture with a\nUniversal Message Bus, thorough state management, translation capabilities, and\nblockchain-based security mechanisms. We present MOD-X's architecture, compare\nit with existing protocols, and demonstrate its application through a worked\nexample how it enables integration between heterogeneous specialist agents\n(agents with different architectures, vendors, capabilities, and knowledge\nrepresentations--including rule-based systems, neural networks, symbolic\nreasoning engines, and legacy software with agent wrappers). MOD-X's key\ninnovations include a publish-subscribe communication model, semantic\ncapability discovery, and dynamic workflow orchestration--providing a framework\nthat bridges theoretical formalism with practical implementation. This\narchitecture addresses the growing need for truly decentralized, interoperable\nagent ecosystems that can scale effectively without the need for central\ncoordination.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04376v2", "cate": "cs.AI", "date": "2025-07-06", "updated": "2025-07-08"}
{"id": "2507.05661", "title": "3DGS_LSR:Large_Scale Relocation for Autonomous Driving Based on 3D Gaussian Splatting", "authors": ["Haitao Lu", "Haijier Chen", "Haoze Liu", "Shoujian Zhang", "Bo Xu", "Ziao Liu"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      13 pages,7 figures,4 tables", "url": "http://arxiv.org/abs/2507.05661v1", "summary": "In autonomous robotic systems, precise localization is a prerequisite for\nsafe navigation. However, in complex urban environments, GNSS positioning often\nsuffers from signal occlusion and multipath effects, leading to unreliable\nabsolute positioning. Traditional mapping approaches are constrained by storage\nrequirements and computational inefficiency, limiting their applicability to\nresource-constrained robotic platforms. To address these challenges, we propose\n3DGS-LSR: a large-scale relocalization framework leveraging 3D Gaussian\nSplatting (3DGS), enabling centimeter-level positioning using only a single\nmonocular RGB image on the client side. We combine multi-sensor data to\nconstruct high-accuracy 3DGS maps in large outdoor scenes, while the robot-side\nlocalization requires just a standard camera input. Using SuperPoint and\nSuperGlue for feature extraction and matching, our core innovation is an\niterative optimization strategy that refines localization results through\nstep-by-step rendering, making it suitable for real-time autonomous navigation.\nExperimental validation on the KITTI dataset demonstrates our 3DGS-LSR achieves\naverage positioning accuracies of 0.026m, 0.029m, and 0.081m in town roads,\nboulevard roads, and traffic-dense highways respectively, significantly\noutperforming other representative methods while requiring only monocular RGB\ninput. This approach provides autonomous robots with reliable localization\ncapabilities even in challenging urban environments where GNSS fails.", "comment": "13 pages,7 figures,4 tables", "pdf_url": "http://arxiv.org/pdf/2507.05661v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05520", "title": "Cultivating Multimodal Intelligence: Interpretive Reasoning and Agentic RAG Approaches to Dermatological Diagnosis", "authors": ["Karishma Thakrar", "Shreyas Basavatia", "Akshay Daftardar"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      2025 ImageCLEF MEDIQA-MAGIC Challenge", "url": "http://arxiv.org/abs/2507.05520v1", "summary": "The second edition of the 2025 ImageCLEF MEDIQA-MAGIC challenge, co-organized\nby researchers from Microsoft, Stanford University, and the Hospital Clinic of\nBarcelona, focuses on multimodal dermatology question answering and\nsegmentation, using real-world patient queries and images. This work addresses\nthe Closed Visual Question Answering (CVQA) task, where the goal is to select\nthe correct answer to multiple-choice clinical questions based on both\nuser-submitted images and accompanying symptom descriptions. The proposed\napproach combines three core components: (1) fine-tuning open-source multimodal\nmodels from the Qwen, Gemma, and LLaMA families on the competition dataset, (2)\nintroducing a structured reasoning layer that reconciles and adjudicates\nbetween candidate model outputs, and (3) incorporating agentic\nretrieval-augmented generation (agentic RAG), which adds relevant information\nfrom the American Academy of Dermatology's symptom and condition database to\nfill in gaps in patient context. The team achieved second place with a\nsubmission that scored sixth, demonstrating competitive performance and high\naccuracy. Beyond competitive benchmarks, this research addresses a practical\nchallenge in telemedicine: diagnostic decisions must often be made\nasynchronously, with limited input and with high accuracy and interpretability.\nBy emulating the systematic reasoning patterns employed by dermatologists when\nevaluating skin conditions, this architecture provided a pathway toward more\nreliable automated diagnostic support systems.", "comment": "2025 ImageCLEF MEDIQA-MAGIC Challenge", "pdf_url": "http://arxiv.org/pdf/2507.05520v1", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05286", "title": "Compressing Deep Neural Networks Using Explainable AI", "authors": ["Kimia Soroush", "Mohsen Raji", "Behnam Ghavami"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05286v1", "summary": "Deep neural networks (DNNs) have demonstrated remarkable performance in many\ntasks but it often comes at a high computational cost and memory usage.\nCompression techniques, such as pruning and quantization, are applied to reduce\nthe memory footprint of DNNs and make it possible to accommodate them on\nresource-constrained edge devices. Recently, explainable artificial\nintelligence (XAI) methods have been introduced with the purpose of\nunderstanding and explaining AI methods. XAI can be utilized to get to know the\ninner functioning of DNNs, such as the importance of different neurons and\nfeatures in the overall performance of DNNs. In this paper, a novel DNN\ncompression approach using XAI is proposed to efficiently reduce the DNN model\nsize with negligible accuracy loss. In the proposed approach, the importance\nscore of DNN parameters (i.e. weights) are computed using a gradient-based XAI\ntechnique called Layer-wise Relevance Propagation (LRP). Then, the scores are\nused to compress the DNN as follows: 1) the parameters with the negative or\nzero importance scores are pruned and removed from the model, 2)\nmixed-precision quantization is applied to quantize the weights with\nhigher/lower score with higher/lower number of bits. The experimental results\nshow that, the proposed compression approach reduces the model size by 64%\nwhile the accuracy is improved by 42% compared to the state-of-the-art\nXAI-based compression method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05286v1", "cate": "cs.LG", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.05461", "title": "GLOSS: Group of LLMs for Open-Ended Sensemaking of Passive Sensing Data for Health and Wellbeing", "authors": ["Akshat Choube", "Ha Le", "Jiachen Li", "Kaixin Ji", "Vedant Das Swain", "Varun Mishra"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05461v1", "summary": "The ubiquitous presence of smartphones and wearables has enabled researchers\nto build prediction and detection models for various health and behavior\noutcomes using passive sensing data from these devices. Achieving a high-level,\nholistic understanding of an individual's behavior and context, however,\nremains a significant challenge. Due to the nature of passive sensing data,\nsensemaking -- the process of interpreting and extracting insights -- requires\nboth domain knowledge and technical expertise, creating barriers for different\nstakeholders. Existing systems designed to support sensemaking are either not\nopen-ended or cannot perform complex data triangulation. In this paper, we\npresent a novel sensemaking system, Group of LLMs for Open-ended Sensemaking\n(GLOSS), capable of open-ended sensemaking and performing complex multimodal\ntriangulation to derive insights. We demonstrate that GLOSS significantly\noutperforms the commonly used Retrieval-Augmented Generation (RAG) technique,\nachieving 87.93% accuracy and 66.19% consistency, compared to RAG's 29.31%\naccuracy and 52.85% consistency. Furthermore, we showcase the promise of GLOSS\nthrough four use cases inspired by prior and ongoing work in the UbiComp and\nHCI communities. Finally, we discuss the potential of GLOSS, its broader\nimplications, and the limitations of our work.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05461v1", "cate": "cs.HC", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2302.01584", "title": "TT-TFHE: a Torus Fully Homomorphic Encryption-Friendly Neural Network Architecture", "authors": ["Adrien Benamira", "Tristan Guérand", "Thomas Peyrin", "Sayandeep Saha"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2302.01584v2", "summary": "This paper presents TT-TFHE, a deep neural network Fully Homomorphic\nEncryption (FHE) framework that effectively scales Torus FHE (TFHE) usage to\ntabular and image datasets using a recent family of convolutional neural\nnetworks called Truth-Table Neural Networks (TTnet). The proposed framework\nprovides an easy-to-implement, automated TTnet-based design toolbox with an\nunderlying (python-based) open-source Concrete implementation (CPU-based and\nimplementing lookup tables) for inference over encrypted data. Experimental\nevaluation shows that TT-TFHE greatly outperforms in terms of time and accuracy\nall Homomorphic Encryption (HE) set-ups on three tabular datasets, all other\nfeatures being equal. On image datasets such as MNIST and CIFAR-10, we show\nthat TT-TFHE consistently and largely outperforms other TFHE set-ups and is\ncompetitive against other HE variants such as BFV or CKKS (while maintaining\nthe same level of 128-bit encryption security guarantees). In addition, our\nsolutions present a very low memory footprint (down to dozens of MBs for\nMNIST), which is in sharp contrast with other HE set-ups that typically require\ntens to hundreds of GBs of memory per user (in addition to their communication\noverheads). This is the first work presenting a fully practical solution of\nprivate inference (i.e. a few seconds for inference time and a few dozens MBs\nof memory) on both tabular datasets and MNIST, that can easily scale to\nmultiple threads and users on server side.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2302.01584v2", "cate": "cs.CR", "date": "2023-02-03", "updated": "2025-07-08"}
{"id": "2507.05663", "title": "Stable Tracking-in-the-Loop Control of Cable-Driven Surgical Manipulators under Erroneous Kinematic Chains", "authors": ["Neelay Joglekar", "Fei Liu", "Florian Richter", "Michael C. Yip"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures, Submitted to RAL", "url": "http://arxiv.org/abs/2507.05663v1", "summary": "Remote Center of Motion (RCM) robotic manipulators have revolutionized\nMinimally Invasive Surgery, enabling precise, dexterous surgical manipulation\nwithin the patient's body cavity without disturbing the insertion point on the\npatient. Accurate RCM tool control is vital for incorporating autonomous\nsubtasks like suturing, blood suction, and tumor resection into robotic\nsurgical procedures, reducing surgeon fatigue and improving patient outcomes.\nHowever, these cable-driven systems are subject to significant joint reading\nerrors, corrupting the kinematics computation necessary to perform control.\nAlthough visual tracking with endoscopic cameras can correct errors on in-view\njoints, errors in the kinematic chain prior to the insertion point are\nirreparable because they remain out of view. No prior work has characterized\nthe stability of control under these conditions. We fill this gap by designing\na provably stable tracking-in-the-loop controller for the out-of-view portion\nof the RCM manipulator kinematic chain. We additionally incorporate this\ncontroller into a bilevel control scheme for the full kinematic chain. We\nrigorously benchmark our method in simulated and real world settings to verify\nour theoretical findings. Our work provides key insights into the next steps\nrequired for the transition from teleoperated to autonomous surgery.", "comment": "8 pages, 5 figures, Submitted to RAL", "pdf_url": "http://arxiv.org/pdf/2507.05663v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05528", "title": "Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment", "authors": ["Jiahuan Pei", "Fanghua Ye", "Xin Sun", "Wentao Deng", "Koen Hindriks", "Junxiao Wang"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      14 pages", "url": "http://arxiv.org/abs/2507.05528v1", "summary": "Large language models (LLMs) have advanced virtual educators and learners,\nbridging NLP with AI4Education. Existing work often lacks scalability and fails\nto leverage diverse, large-scale course content, with limited frameworks for\nassessing pedagogic quality. To this end, we propose WikiHowAgent, a\nmulti-agent workflow leveraging LLMs to simulate interactive teaching-learning\nconversations. It integrates teacher and learner agents, an interaction\nmanager, and an evaluator to facilitate procedural learning and assess\npedagogic quality. We introduce a dataset of 114,296 teacher-learner\nconversations grounded in 14,287 tutorials across 17 domains and 727 topics.\nOur evaluation protocol combines computational and rubric-based metrics with\nhuman judgment alignment. Results demonstrate the workflow's effectiveness in\ndiverse setups, offering insights into LLM capabilities across domains. Our\ndatasets and implementations are fully open-sourced.", "comment": "14 pages", "pdf_url": "http://arxiv.org/pdf/2507.05528v1", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05291", "title": "Physics-Informed Graph Neural Networks to Reconstruct Local Fields Considering Finite Strain Hyperelasticity", "authors": ["Manuel Ricardo Guevara Garban", "Yves Chemisky", "Étienne Prulière", "Michaël Clément"], "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "physics.comp-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      28 pages, 17 figures, pre-print", "url": "http://arxiv.org/abs/2507.05291v1", "summary": "We propose a physics-informed machine learning framework called P-DivGNN to\nreconstruct local stress fields at the micro-scale, in the context of\nmulti-scale simulation given a periodic micro-structure mesh and mean,\nmacro-scale, stress values. This method is based in representing a periodic\nmicro-structure as a graph, combined with a message passing graph neural\nnetwork. We are able to retrieve local stress field distributions, providing\naverage stress values produced by a mean field reduced order model (ROM) or\nFinite Element (FE) simulation at the macro-scale. The prediction of local\nstress fields are of utmost importance considering fracture analysis or the\ndefinition of local fatigue criteria. Our model incorporates physical\nconstraints during training to constraint local stress field equilibrium state\nand employs a periodic graph representation to enforce periodic boundary\nconditions. The benefits of the proposed physics-informed GNN are evaluated\nconsidering linear and non linear hyperelastic responses applied to varying\ngeometries. In the non-linear hyperelastic case, the proposed method achieves\nsignificant computational speed-ups compared to FE simulation, making it\nparticularly attractive for large-scale applications.", "comment": "28 pages, 17 figures, pre-print", "pdf_url": "http://arxiv.org/pdf/2507.05291v1", "cate": "cs.LG", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.05532", "title": "W2W: A Simulated Exploration of IMU Placement Across the Human Body for Designing Smarter Wearable", "authors": ["Lala Shakti Swarup Ray", "Bo Zhou", "Paul Lukowicz"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05532v1", "summary": "Inertial measurement units (IMUs) are central to wearable systems for\nactivity recognition and pose estimation, but sensor placement remains largely\nguided by heuristics and convention. In this work, we introduce Where to Wear\n(W2W), a simulation-based framework for systematic exploration of IMU placement\nutility across the body. Using labeled motion capture data, W2W generates\nrealistic synthetic IMU signals at 512 anatomically distributed surface\npatches, enabling high-resolution, task-specific evaluation of sensor\nperformance. We validate reliability of W2W by comparing spatial performance\nrankings from synthetic data with real IMU recordings in two multimodal\ndatasets, confirming strong agreement in activity-wise trends. Further analysis\nreveals consistent spatial trends across activity types and uncovers overlooked\nhigh-utility regions that are rarely used in commercial systems. These findings\nchallenge long-standing placement norms and highlight opportunities for more\nefficient, task-adaptive sensor configurations. Overall, our results\ndemonstrate that simulation with W2W can serve as a powerful design tool for\noptimizing sensor placement, enabling scalable, data-driven strategies that are\nimpractical to obtain through physical experimentation alone.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05532v1", "cate": "cs.HC", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2410.16327", "title": "Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs", "authors": ["Rui Pu", "Chaozhuo Li", "Rui Ha", "Zejian Chen", "Litian Zhang", "Zheng Liu", "Lirong Qiu", "Zaisheng Ye"], "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.16327v2", "summary": "Jailbreak attack can be used to access the vulnerabilities of Large Language\nModels (LLMs) by inducing LLMs to generate the harmful content. And the most\ncommon method of the attack is to construct semantically ambiguous prompts to\nconfuse and mislead the LLMs. To access the security and reveal the intrinsic\nrelation between the input prompt and the output for LLMs, the distribution of\nattention weight is introduced to analyze the underlying reasons. By using\nstatistical analysis methods, some novel metrics are defined to better describe\nthe distribution of attention weight, such as the Attention Intensity on\nSensitive Words (Attn_SensWords), the Attention-based Contextual Dependency\nScore (Attn_DepScore) and Attention Dispersion Entropy (Attn_Entropy). By\nleveraging the distinct characteristics of these metrics, the beam search\nalgorithm and inspired by the military strategy \"Feint and Attack\", an\neffective jailbreak attack strategy named as Attention-Based Attack (ABA) is\nproposed. In the ABA, nested attack prompts are employed to divert the\nattention distribution of the LLMs. In this manner, more harmless parts of the\ninput can be used to attract the attention of the LLMs. In addition, motivated\nby ABA, an effective defense strategy called as Attention-Based Defense (ABD)\nis also put forward. Compared with ABA, the ABD can be used to enhance the\nrobustness of LLMs by calibrating the attention distribution of the input\nprompt. Some comparative experiments have been given to demonstrate the\neffectiveness of ABA and ABD. Therefore, both ABA and ABD can be used to access\nthe security of the LLMs. The comparative experiment results also give a\nlogical explanation that the distribution of attention weight can bring great\ninfluence on the output for LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.16327v2", "cate": "cs.CR", "date": "2024-10-18", "updated": "2025-07-08"}
{"id": "2507.05674", "title": "Integrating Diffusion-based Multi-task Learning with Online Reinforcement Learning for Robust Quadruped Robot Control", "authors": ["Xinyao Qin", "Xiaoteng Ma", "Yang Qi", "Qihan Liu", "Chuanyi Xue", "Ning Gui", "Qinyu Dong", "Jun Yang", "Bin Liang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05674v1", "summary": "Recent research has highlighted the powerful capabilities of imitation\nlearning in robotics. Leveraging generative models, particularly diffusion\nmodels, these approaches offer notable advantages such as strong multi-task\ngeneralization, effective language conditioning, and high sample efficiency.\nWhile their application has been successful in manipulation tasks, their use in\nlegged locomotion remains relatively underexplored, mainly due to compounding\nerrors that affect stability and difficulties in task transition under limited\ndata. Online reinforcement learning (RL) has demonstrated promising results in\nlegged robot control in the past years, providing valuable insights to address\nthese challenges. In this work, we propose DMLoco, a diffusion-based framework\nfor quadruped robots that integrates multi-task pretraining with online PPO\nfinetuning to enable language-conditioned control and robust task transitions.\nOur approach first pretrains the policy on a diverse multi-task dataset using\ndiffusion models, enabling language-guided execution of various skills. Then,\nit finetunes the policy in simulation to ensure robustness and stable task\ntransition during real-world deployment. By utilizing Denoising Diffusion\nImplicit Models (DDIM) for efficient sampling and TensorRT for optimized\ndeployment, our policy runs onboard at 50Hz, offering a scalable and efficient\nsolution for adaptive, language-guided locomotion on resource-constrained\nrobotic platforms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05674v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05309", "title": "Neural Velocity for hyperparameter tuning", "authors": ["Gianluca Dalmasso", "Andrea Bragagnolo", "Enzo Tartaglione", "Attilio Fiandrotti", "Marco Grangetto"], "categories": ["cs.LG", "cs.AI", "68T05", "I.2.6; I.5.1; I.5.4"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to IJCNN 2025 (International Joint Conference on Neural Networks). 8 pages, 13 figures", "url": "http://arxiv.org/abs/2507.05309v1", "summary": "Hyperparameter tuning, such as learning rate decay and defining a stopping\ncriterion, often relies on monitoring the validation loss. This paper presents\nNeVe, a dynamic training approach that adjusts the learning rate and defines\nthe stop criterion based on the novel notion of \"neural velocity\". The neural\nvelocity measures the rate of change of each neuron's transfer function and is\nan indicator of model convergence: sampling neural velocity can be performed\neven by forwarding noise in the network, reducing the need for a held-out\ndataset. Our findings show the potential of neural velocity as a key metric for\noptimizing neural network training efficiently", "comment": "Accepted to IJCNN 2025 (International Joint Conference on Neural\n  Networks). 8 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.05309v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05537", "title": "Information Needs and Practices Supported by ChatGPT", "authors": ["Tim Gorichanaz"], "categories": ["cs.HC", "cs.IR"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      To be presented at the 2025 ASIS&T virtual satellite meeting, December 2025", "url": "http://arxiv.org/abs/2507.05537v1", "summary": "This study considers ChatGPT as an information source, investigating the\ninformation needs that people come to ChatGPT with and the information\npractices that ChatGPT supports, through a qualitative content analysis of 205\nuser vignettes. The findings show that ChatGPT is used in a range of life\ndomains (home/family, work, leisure, etc.) and for a range of human needs\n(writing/editing, learning, simple programming tasks, etc.), constituting the\ninformation needs that people use ChatGPT to address. Related to these\ninformation needs, the findings show six categories of information practices\nthat ChatGPT supports: Writing, Deciding, Identifying, Ideating, Talking, and\nCritiquing. This work suggests that, in the AI age, information need should be\nconceptualized not just as a matter of \"getting questions answered\" or even\n\"making sense,\" but as skillfully coping in the world, a notion that includes\nboth understanding and action. This study leads to numerous opportunities for\nfuture work at the junction of generative AI and information needs, seeking,\nuse and experience.", "comment": "To be presented at the 2025 ASIS&T virtual satellite meeting,\n  December 2025", "pdf_url": "http://arxiv.org/pdf/2507.05537v1", "cate": "cs.HC", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2503.01089", "title": "Privacy-preserving Machine Learning in Internet of Vehicle Applications: Fundamentals, Recent Advances, and Future Direction", "authors": ["Nazmul Islam", "Mohammad Zulkernine"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2503.01089v2", "summary": "Machine learning (ML) in Internet of Vehicles (IoV) applications enhanced\nintelligent transportation, autonomous driving capabilities, and various\nconnected services within a large, heterogeneous network. However, the\nincreased connectivity and massive data exchange for ML applications introduce\nsignificant privacy challenges. Privacy-preserving machine learning (PPML)\noffers potential solutions to address these challenges by preserving privacy at\nvarious stages of the ML pipeline. Despite the rapid development of ML-based\nIoV applications and the growing data privacy concerns, there are limited\ncomprehensive studies on the adoption of PPML within this domain. Therefore,\nthis study provides a comprehensive review of the fundamentals, recent\nadvancements, and the challenges of integrating PPML into IoV applications. We\nfirst review existing surveys of various PPML techniques and their integration\ninto IoV across different scopes. We then categorize IoV applications into\nthree key domains and analyze the privacy challenges in leveraging ML in these\napplication domains. Building on these fundamentals, we review recent\nadvancements in integrating various PPML techniques within IoV applications,\ndiscussing their frameworks, key features, and performance in terms of privacy,\nutility, and efficiency. Finally, we identify current challenges and propose\nfuture research directions to enhance privacy and reliability in IoV\napplications.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2503.01089v2", "cate": "cs.CR", "date": "2025-03-03", "updated": "2025-07-08"}
{"id": "2507.05695", "title": "Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning", "authors": ["Xiatao Sun", "Yuxuan Wang", "Shuo Yang", "Yinxing Chen", "Daniel Rakita"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05695v1", "summary": "Diffusion policies have become increasingly popular in robot learning due to\ntheir reliable convergence in motion generation tasks. At a high level, these\npolicies learn to transform noisy action trajectories into effective ones,\nconditioned on observations. However, each time such a model is trained in a\nrobotics context, the network must relearn fundamental spatial representations\nand operations, such as translations and rotations, from scratch in order to\nground itself and operate effectively in a 3D environment. Incorporating\ngeometric inductive biases directly into the network can alleviate this\nredundancy and substantially improve training efficiency. In this paper, we\nintroduce hPGA-DP, a diffusion policy approach that integrates a mathematical\nframework called Projective Geometric Algebra (PGA) to embed strong geometric\ninductive biases. PGA is particularly well-suited for this purpose as it\nprovides a unified algebraic framework that naturally encodes geometric\nprimitives, such as points, directions, and rotations, enabling neural networks\nto reason about spatial structure through interpretable and composable\noperations. Specifically, we propose a novel diffusion policy architecture that\nincorporates the Projective Geometric Algebra Transformer (P-GATr), leveraging\nits E(3)-equivariant properties established in prior work. Our approach adopts\na hybrid architecture strategy, using P-GATr as both a state encoder and action\ndecoder, while employing U-Net or Transformer-based modules for the denoising\nprocess. Several experiments and ablation studies in both simulated and\nreal-world environments demonstrate that hPGA-DP not only improves task\nperformance and training efficiency through the geometric bias of P-GATr, but\nalso achieves substantially faster convergence through its hybrid model\ncompared to architectures that rely solely on P-GATr.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05695v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05541", "title": "SenseCF: LLM-Prompted Counterfactuals for Intervention and Sensor Data Augmentation", "authors": ["Shovito Barua Soumma", "Asiful Arefeen", "Stephanie M. Carpenter", "Melanie Hingle", "Hassan Ghasemzadeh"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      In review", "url": "http://arxiv.org/abs/2507.05541v1", "summary": "Counterfactual explanations (CFs) offer human-centric insights into machine\nlearning predictions by highlighting minimal changes required to alter an\noutcome. Therefore, CFs can be used as (i) interventions for abnormality\nprevention and (ii) augmented data for training robust models. In this work, we\nexplore large language models (LLMs), specifically GPT-4o-mini, for generating\nCFs in a zero-shot and three-shot setting. We evaluate our approach on two\ndatasets: the AI-Readi flagship dataset for stress prediction and a public\ndataset for heart disease detection. Compared to traditional methods such as\nDiCE, CFNOW, and NICE, our few-shot LLM-based approach achieves high\nplausibility (up to 99%), strong validity (up to 0.99), and competitive\nsparsity. Moreover, using LLM-generated CFs as augmented samples improves\ndownstream classifier performance (an average accuracy gain of 5%), especially\nin low-data regimes. This demonstrates the potential of prompt-based generative\ntechniques to enhance explainability and robustness in clinical and\nphysiological prediction tasks. Code base: github.com/anonymous/SenseCF.", "comment": "In review", "pdf_url": "http://arxiv.org/pdf/2507.05541v1", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05315", "title": "Conditional Graph Neural Network for Predicting Soft Tissue Deformation and Forces", "authors": ["Madina Kojanazarova", "Florentin Bieder", "Robin Sandkühler", "Philippe C. Cattin"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05315v1", "summary": "Soft tissue simulation in virtual environments is becoming increasingly\nimportant for medical applications. However, the high deformability of soft\ntissue poses significant challenges. Existing methods rely on segmentation,\nmeshing and estimation of stiffness properties of tissues. In addition, the\nintegration of haptic feedback requires precise force estimation to enable a\nmore immersive experience. We introduce a novel data-driven model, a\nconditional graph neural network (cGNN) to tackle this complexity. Our model\ntakes surface points and the location of applied forces, and is specifically\ndesigned to predict the deformation of the points and the forces exerted on\nthem. We trained our model on experimentally collected surface tracking data of\na soft tissue phantom and used transfer learning to overcome the data scarcity\nby initially training it with mass-spring simulations and fine-tuning it with\nthe experimental data. This approach improves the generalisation capability of\nthe model and enables accurate predictions of tissue deformations and\ncorresponding interaction forces. The results demonstrate that the model can\npredict deformations with a distance error of 0.35$\\pm$0.03 mm for deformations\nup to 30 mm and the force with an absolute error of 0.37$\\pm$0.05 N for forces\nup to 7.5 N. Our data-driven approach presents a promising solution to the\nintricate challenge of simulating soft tissues within virtual environments.\nBeyond its applicability in medical simulations, this approach holds the\npotential to benefit various fields where realistic soft tissue simulations are\nrequired.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05315v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05300", "title": "Structured Captions Improve Prompt Adherence in Text-to-Image Models (Re-LAION-Caption 19M)", "authors": ["Nicholas Merchant", "Haitz Sáez de Ocáriz Borde", "Andrei Cristian Popescu", "Carlos Garcia Jurado Suarez"], "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      7-page main paper + appendix, 18 figures", "url": "http://arxiv.org/abs/2507.05300v1", "summary": "We argue that generative text-to-image models often struggle with prompt\nadherence due to the noisy and unstructured nature of large-scale datasets like\nLAION-5B. This forces users to rely heavily on prompt engineering to elicit\ndesirable outputs. In this work, we propose that enforcing a consistent caption\nstructure during training can significantly improve model controllability and\nalignment. We introduce Re-LAION-Caption 19M, a high-quality subset of\nRe-LAION-5B, comprising 19 million 1024x1024 images with captions generated by\na Mistral 7B Instruct-based LLaVA-Next model. Each caption follows a four-part\ntemplate: subject, setting, aesthetics, and camera details. We fine-tune\nPixArt-$\\Sigma$ and Stable Diffusion 2 using both structured and randomly\nshuffled captions, and show that structured versions consistently yield higher\ntext-image alignment scores using visual question answering (VQA) models. The\ndataset is publicly available at\nhttps://huggingface.co/datasets/supermodelresearch/Re-LAION-Caption19M.", "comment": "7-page main paper + appendix, 18 figures", "pdf_url": "http://arxiv.org/pdf/2507.05300v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05572", "title": "AnatomyCarve: A VR occlusion management technique for medical images based on segment-aware clipping", "authors": ["Andrey Titov", "Tina N. H. Nantenaina", "Marta Kersten-Oertel", "Simon Drouin"], "categories": ["cs.HC", "cs.GR"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05572v1", "summary": "Visualizing 3D medical images is challenging due to self-occlusion, where\nanatomical structures of interest can be obscured by surrounding tissues.\nExisting methods, such as slicing and interactive clipping, are limited in\ntheir ability to fully represent internal anatomy in context. In contrast,\nhand-drawn medical illustrations in anatomy books manage occlusion effectively\nby selectively removing portions based on tissue type, revealing 3D structures\nwhile preserving context. This paper introduces AnatomyCarve, a novel technique\ndeveloped for a VR environment that creates high-quality illustrations similar\nto those in anatomy books, while remaining fast and interactive. AnatomyCarve\nallows users to clip selected segments from 3D medical volumes, preserving\nspatial relations and contextual information. This approach enhances\nvisualization by combining advanced rendering techniques with natural user\ninteractions in VR. Usability of AnatomyCarve was assessed through a study with\nnon-experts, while surgical planning effectiveness was evaluated with\npracticing neurosurgeons and residents. The results show that AnatomyCarve\nenables customized anatomical visualizations, with high user satisfaction,\nsuggesting its potential for educational and clinical applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05572v1", "cate": "cs.HC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2504.07280", "title": "Conthereum: Concurrent Ethereum Optimized Transaction Scheduling for Multi-Core Execution", "authors": ["Atefeh Zareh Chahoki", "Maurice Herlihy", "Marco Roveri"], "categories": ["cs.CR", "cs.DC"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      10 pages, 3 tables, 7 figures, 1 algorithms", "url": "http://arxiv.org/abs/2504.07280v2", "summary": "Conthereum is a concurrent Ethereum solution for intra-block parallel\ntransaction execution, enabling validators to utilize multi-core infrastructure\nand transform the sequential execution model of Ethereum into a parallel one.\nThis shift significantly increases throughput and transactions per second\n(TPS), while ensuring conflict-free execution in both proposer and attestor\nmodes and preserving execution order consistency in the attestor. At the heart\nof Conthereum is a novel, lightweight, high-performance scheduler inspired by\nthe Flexible Job Shop Scheduling Problem (FJSS). We propose a custom greedy\nheuristic algorithm, along with its efficient implementation, that solves this\nformulation effectively and decisively outperforms existing scheduling methods\nin finding suboptimal solutions that satisfy the constraints, achieve minimal\nmakespan, and maximize speedup in parallel execution. Additionally, Conthereum\nincludes an offline phase that equips its real-time scheduler with a conflict\nanalysis repository obtained through static analysis of smart contracts,\nidentifying potentially conflicting functions using a pessimistic approach.\nBuilding on this novel scheduler and extensive conflict data, Conthereum\noutperforms existing concurrent intra-block solutions. Empirical evaluations\nshow near-linear throughput gains with increasing computational power on\nstandard 8-core machines. Although scalability deviates from linear with higher\ncore counts and increased transaction conflicts, Conthereum still significantly\nimproves upon the current sequential execution model and outperforms existing\nconcurrent solutions under a wide range of conditions.", "comment": "10 pages, 3 tables, 7 figures, 1 algorithms", "pdf_url": "http://arxiv.org/pdf/2504.07280v2", "cate": "cs.CR", "date": "2025-04-09", "updated": "2025-07-08"}
{"id": "2507.05710", "title": "DRO-EDL-MPC: Evidential Deep Learning-Based Distributionally Robust Model Predictive Control for Safe Autonomous Driving", "authors": ["Hyeongchan Ham", "Heejin Ahn"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      11 pages; Project page can be found at this https URL", "url": "http://arxiv.org/abs/2507.05710v1", "summary": "Safety is a critical concern in motion planning for autonomous vehicles.\nModern autonomous vehicles rely on neural network-based perception, but making\ncontrol decisions based on these inference results poses significant safety\nrisks due to inherent uncertainties. To address this challenge, we present a\ndistributionally robust optimization (DRO) framework that accounts for both\naleatoric and epistemic perception uncertainties using evidential deep learning\n(EDL). Our approach introduces a novel ambiguity set formulation based on\nevidential distributions that dynamically adjusts the conservativeness\naccording to perception confidence levels. We integrate this uncertainty-aware\nconstraint into model predictive control (MPC), proposing the DRO-EDL-MPC\nalgorithm with computational tractability for autonomous driving applications.\nValidation in the CARLA simulator demonstrates that our approach maintains\nefficiency under high perception confidence while enforcing conservative\nconstraints under low confidence.", "comment": "11 pages; Project page can be found at https://dro-edl-mpc.github.io", "pdf_url": "http://arxiv.org/pdf/2507.05710v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05566", "title": "SingLoRA: Low Rank Adaptation Using a Single Matrix", "authors": ["David Bensaïd", "Noam Rotstein", "Roy Velich", "Daniel Bensaïd", "Ron Kimmel"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05566v1", "summary": "Low-Rank Adaptation (LoRA) has significantly advanced parameter-efficient\nfine-tuning of large pretrained models. LoRA augments the pre-trained weights\nof a model by adding the product of two smaller matrices that together form a\nlow-rank matrix update. Recent research has shown that scale disparities\nbetween these two matrices often cause unstable training dynamics, leading to\nsuboptimal performance. In this paper, we propose SingLoRA, which reformulates\nlow-rank adaptation by learning the weights update as a decomposition of a\nsingle low-rank matrix multiplied by its transpose. This simple design\ninherently removes inter-matrix scale conflicts, ensuring stable optimization,\nand roughly halves the parameter count. We analyze SingLoRA within the\ninfinite-width neural network framework, showing that it guarantees stable\nfeature learning by construction. Extensive experiments on multiple tasks\nvalidate these benefits. In common sense reasoning, fine-tuning LLama 7B on\nMNLI with SingLoRA achieves 91.3% accuracy - surpassing LoRA (89.1%) and LoRA+\n(90.2%) - while using only 60% of their parameter budget. In image generation,\nfine-tuning Stable Diffusion with SingLoRA significantly improves image\nfidelity on DreamBooth, achieving a DINO similarity score of 0.151, compared to\nscores of 0.148 and 0.143 for DoRA and LoRA, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05566v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05322", "title": "Dataless Neural Networks for Resource-Constrained Project Scheduling", "authors": ["Marc Bara"], "categories": ["cs.LG", "cs.NE", "90B35, 90B35, 90C27", "F.2.2; F.2.2; I.2.8"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 1 figure. Introduces dataless neural networks for resource-constrained project scheduling", "url": "http://arxiv.org/abs/2507.05322v1", "summary": "Dataless neural networks represent a paradigm shift in applying neural\narchitectures to combinatorial optimization problems, eliminating the need for\ntraining datasets by encoding problem instances directly into network\nparameters. Despite the pioneering work of Alkhouri et al. (2022) demonstrating\nthe viability of dataless approaches for the Maximum Independent Set problem,\nour comprehensive literature review reveals that no published work has extended\nthese methods to the Resource-Constrained Project Scheduling Problem (RCPSP).\nThis paper addresses this gap by presenting the first dataless neural network\napproach for RCPSP, providing a complete mathematical framework that transforms\ndiscrete scheduling constraints into differentiable objectives suitable for\ngradient-based optimization. Our approach leverages smooth relaxations and\nautomatic differentiation to unlock GPU parallelization for project scheduling,\ntraditionally a domain of sequential algorithms. We detail the mathematical\nformulation for both precedence and renewable resource constraints, including a\nmemory-efficient dense time-grid representation. Implementation and\ncomprehensive experiments on PSPLIB benchmark instances (J30, J60, and J120)\nare currently underway, with empirical results to be reported in an updated\nversion of this paper.", "comment": "9 pages, 1 figure. Introduces dataless neural networks for\n  resource-constrained project scheduling", "pdf_url": "http://arxiv.org/pdf/2507.05322v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05302", "title": "CorrDetail: Visual Detail Enhanced Self-Correction for Face Forgery Detection", "authors": ["Binjia Zhou", "Hengrui Lou", "Lizhe Chen", "Haoyuan Li", "Dawei Luo", "Shuai Chen", "Jie Lei", "Zunlei Feng", "Yijun Bei"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05302v1", "summary": "With the swift progression of image generation technology, the widespread\nemergence of facial deepfakes poses significant challenges to the field of\nsecurity, thus amplifying the urgent need for effective deepfake\ndetection.Existing techniques for face forgery detection can broadly be\ncategorized into two primary groups: visual-based methods and multimodal\napproaches. The former often lacks clear explanations for forgery details,\nwhile the latter, which merges visual and linguistic modalities, is more prone\nto the issue of hallucinations.To address these shortcomings, we introduce a\nvisual detail enhanced self-correction framework, designated CorrDetail, for\ninterpretable face forgery detection. CorrDetail is meticulously designed to\nrectify authentic forgery details when provided with error-guided questioning,\nwith the aim of fostering the ability to uncover forgery details rather than\nyielding hallucinated responses. Additionally, to bolster the reliability of\nits findings, a visual fine-grained detail enhancement module is incorporated,\nsupplying CorrDetail with more precise visual forgery details. Ultimately, a\nfusion decision strategy is devised to further augment the model's\ndiscriminative capacity in handling extreme samples, through the integration of\nvisual information compensation and model bias reduction.Experimental results\ndemonstrate that CorrDetail not only achieves state-of-the-art performance\ncompared to the latest methodologies but also excels in accurately identifying\nforged details, all while exhibiting robust generalization capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05302v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05269", "title": "CORE: Benchmarking LLMs Code Reasoning Capabilities through Static Analysis Tasks", "authors": ["Danning Xie", "Mingwei Zheng", "Xuwei Liu", "Jiannan Wang", "Chengpeng Wang", "Lin Tan", "Xiangyu Zhang"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05269v1", "summary": "Large language models (LLMs) have been widely adopted across diverse software\nengineering domains, such as code generation, program repair, and vulnerability\ndetection. These applications require understanding beyond surface-level code\npatterns: value propagation, control flow, and interdependence between program\nelements. However, existing benchmarks primarily evaluate end-to-end outcomes,\nsuch as whether code is correctly repaired or generated, leaving the models\nability for program semantic reasoning underexplored. This work presents CoRe,\na high-quality, human-verified benchmark designed to evaluate LLMs on\nfundamental static analysis tasks. CoRe includes 12,553 task instances spanning\ndata dependency, control dependency, and information flow across programs\nwritten in C/C++, Java, and Python. To ensure semantic diversity and reasoning\ncomplexity, we propose a semantics-aware diverse sampling strategy that selects\ntargets and task instances based on structural coverage and dependency depth.\nWe evaluate 10 mainstream LLMs and show that, while they perform well at\nidentifying dependencies, models still struggle with tasks that require deeper\nsemantic understanding and multi-step reasoning. We further conduct qualitative\nanalyses to uncover key challenges, such as complex control structures and\nbackward dependency patterns, offering insights into improving LLMs code\nreasoning capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05269v1", "cate": "cs.SE", "date": "2025-07-03", "updated": "2025-07-03"}
{"id": "2507.05600", "title": "StoryGrid: A Tangible Interface for Student Expression", "authors": ["Tom Moher", "Louis Gomez", "Janet Kim", "Claudia Hindo", "Benjamin Watson", "Stephen Fransen", "Tim McEneany"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05600v1", "summary": "StorySpace is a classroom-based design and presentation system for\ninteractive multimedia posters. Employing the technology base first used in\nEden's PITAboard [2002], StorySpace allows groups of learners to manipulate\nprojected multimedia objects on a horizontal board using a small collection of\nshared physical tokens. In this paper, we present the ongoing design history of\nStorySpace in the context of its introduction within an urban high school\nliterature class. Interface modifications based on student and teacher feedback\nled on changes in token semantics and media importing methods. We describe how\nStorySpace features enriched students' interpretations of literature, with\nparticular emphasis in two areas: (1) attention to audience, and (2) reflection\nof multiple perspectives.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05600v1", "cate": "cs.HC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2504.07414", "title": "Decomposition-Based Optimal Bounds for Privacy Amplification via Shuffling", "authors": ["Pengcheng Su", "Haibo Cheng", "Ping Wang"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.07414v4", "summary": "Shuffling has been shown to amplify differential privacy guarantees, enabling\na more favorable privacy-utility trade-off. To characterize and compute this\namplification, two fundamental analytical frameworks have been proposed: the\n\\emph{privacy blanket} by Balle et al. (CRYPTO 2019) and the \\emph{clone\nparadigm}--including both the standard and stronger variants--by Feldman et al.\n(FOCS 2021, SODA 2023). These frameworks share a common foundation: decomposing\nlocal randomizers into structured components for analysis.\n  In this work, we introduce a unified analytical framework--the general clone\nparadigm--which subsumes all possible decompositions, with the clone and\nblanket decompositions arising as special cases. Within this framework, we\nidentify the optimal decomposition, which is precisely the one used by the\nprivacy blanket. Moreover, we develop a simple and efficient algorithm based on\nthe Fast Fourier Transform (FFT) to compute optimal privacy amplification\nbounds. Experimental results show that our computed upper bounds nearly match\nthe empirical lower bounds, demonstrating the tightness of our method. Building\non this method, we also derive optimal amplification bounds for both\n\\emph{joint} and \\emph{parallel} compositions of LDP mechanisms in the shuffle\nmodel.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.07414v4", "cate": "cs.CR", "date": "2025-04-10", "updated": "2025-07-08"}
{"id": "2507.05717", "title": "Simultaneous Triggering and Synchronization of Sensors and Onboard Computers", "authors": ["Morten Nissov", "Nikhil Khedekar", "Kostas Alexis"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      2 pages, 3 figures. Presented at ICRA@40", "url": "http://arxiv.org/abs/2507.05717v1", "summary": "High fidelity estimation algorithms for robotics require accurate data.\nHowever, timestamping of sensor data is a key issue that rarely receives the\nattention it deserves. Inaccurate timestamping can be compensated for in\npost-processing but is imperative for online estimation. Simultaneously, even\nonline mitigation of timing issues can be achieved through a relaxation of the\ntuning parameters from their otherwise more performative optimal values, but at\na detriment to performance. To address the need for real-time, low-cost\ntimestamping, a versatile system which utilizes readily-available components\nand established methods for synchronization is introduced. The synchronization\nand triggering (of both high- and low-rate sensors) capabilities of the system\nare demonstrated.", "comment": "2 pages, 3 figures. Presented at ICRA@40", "pdf_url": "http://arxiv.org/pdf/2507.05717v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05587", "title": "Towards Measurement Theory for Artificial Intelligence", "authors": ["Elija Perrier"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Under review for Iliad Conference 2025", "url": "http://arxiv.org/abs/2507.05587v1", "summary": "We motivate and outline a programme for a formal theory of measurement of\nartificial intelligence. We argue that formalising measurement for AI will\nallow researchers, practitioners, and regulators to: (i) make comparisons\nbetween systems and the evaluation methods applied to them; (ii) connect\nfrontier AI evaluations with established quantitative risk analysis techniques\ndrawn from engineering and safety science; and (iii) foreground how what counts\nas AI capability is contingent upon the measurement operations and scales we\nelect to use. We sketch a layered measurement stack, distinguish direct from\nindirect observables, and signpost how these ingredients provide a pathway\ntoward a unified, calibratable taxonomy of AI phenomena.", "comment": "Under review for Iliad Conference 2025", "pdf_url": "http://arxiv.org/pdf/2507.05587v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05328", "title": "Going Beyond Heuristics by Imposing Policy Improvement as a Constraint", "authors": ["Chi-Chang Lee", "Zhang-Wei Hong", "Pulkit Agrawal"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05328v1", "summary": "In many reinforcement learning (RL) applications, augmenting the task rewards\nwith heuristic rewards that encode human priors about how a task should be\nsolved is crucial for achieving desirable performance. However, because such\nheuristics are usually not optimal, much human effort and computational\nresources are wasted in carefully balancing tasks and heuristic rewards.\nTheoretically rigorous ways of incorporating heuristics rely on the idea of\n\\textit{policy invariance}, which guarantees that the performance of a policy\nobtained by maximizing heuristic rewards is the same as the optimal policy with\nrespect to the task reward. However, in practice, policy invariance doesn't\nresult in policy improvement, and such methods are known to empirically perform\npoorly. We propose a new paradigm to mitigate reward hacking and effectively\nuse heuristics based on the practical goal of maximizing policy improvement\ninstead of policy improvement. Our framework, Heuristic Enhanced Policy\nOptimization (HEPO), effectively leverages heuristics while avoiding the\npitfall of prior methods for mitigating reward hacking. HEPO achieves superior\nperformance on standard benchmarks with well-engineered reward functions. More\nsurprisingly, HEPO allows policy optimization to achieve good performance even\nwhen heuristics are not well-engineered and designed by non-expert humans,\nshowcasing HEPO's ability to reduce human effort in reward design. % HEPO is a\nplug-and-play optimization method for leveraging heuristics in reinforcement\nlearning. Code is available at https://github.com/Improbable-AI/hepo.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05328v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05376", "title": "YOLO-APD: Enhancing YOLOv8 for Robust Pedestrian Detection on Complex Road Geometries", "authors": ["Aquino Joctum", "John Kandiri"], "categories": ["cs.CV", "I.4.8; I.2.6; I.2.9"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Published in the International Journal of Computer Trends and Technology (IJCTT), vol. 73, no. 6, 2024. The final version of record is available at: this https URL", "url": "http://arxiv.org/abs/2507.05376v1", "summary": "Autonomous vehicle perception systems require robust pedestrian detection,\nparticularly on geometrically complex roadways like Type-S curved surfaces,\nwhere standard RGB camera-based methods face limitations. This paper introduces\nYOLO-APD, a novel deep learning architecture enhancing the YOLOv8 framework\nspecifically for this challenge. YOLO-APD integrates several key architectural\nmodifications: a parameter-free SimAM attention mechanism, computationally\nefficient C3Ghost modules, a novel SimSPPF module for enhanced multi-scale\nfeature pooling, the Mish activation function for improved optimization, and an\nIntelligent Gather & Distribute (IGD) module for superior feature fusion in the\nnetwork's neck. The concept of leveraging vehicle steering dynamics for\nadaptive region-of-interest processing is also presented. Comprehensive\nevaluations on a custom CARLA dataset simulating complex scenarios demonstrate\nthat YOLO-APD achieves state-of-the-art detection accuracy, reaching 77.7%\nmAP@0.5:0.95 and exceptional pedestrian recall exceeding 96%, significantly\noutperforming baseline models, including YOLOv8. Furthermore, it maintains\nreal-time processing capabilities at 100 FPS, showcasing a superior balance\nbetween accuracy and efficiency. Ablation studies validate the synergistic\ncontribution of each integrated component. Evaluation on the KITTI dataset\nconfirms the architecture's potential while highlighting the need for domain\nadaptation. This research advances the development of highly accurate,\nefficient, and adaptable perception systems based on cost-effective sensors,\ncontributing to enhanced safety and reliability for autonomous navigation in\nchallenging, less-structured driving environments.", "comment": "Published in the International Journal of Computer Trends and\n  Technology (IJCTT), vol. 73, no. 6, 2024. The final version of record is\n  available at: https://doi.org/10.14445/22312803/IJCTT-V73I6P108", "pdf_url": "http://arxiv.org/pdf/2507.05376v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05270", "title": "Open Source, Hidden Costs: A Systematic Literature Review on OSS License Management", "authors": ["Boyuan Li", "Chengwei Liu", "Lingling Fan", "Sen Chen", "Zhenlin Zhang", "Zheli Liu"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05270v1", "summary": "Integrating third-party software components is a common practice in modern\nsoftware development, offering significant advantages in terms of efficiency\nand innovation. However, this practice is fraught with risks related to\nsoftware licensing. A lack of understanding may lead to disputes, which can\npose serious legal and operational challenges. To these ends, both academia and\nindustry have conducted various investigations and proposed solutions and tools\nto deal with these challenges. However, significant limitations still remain.\nMoreover, the rapid evolution of open-source software (OSS) licenses, as well\nas the rapidly incorporated generative software engineering techniques, such as\nlarge language models for code (CodeLLMs), are placing greater demands on the\nsystematic management of software license risks. To unveil the severe\nchallenges and explore possible future directions, we conduct the first\nsystematic literature review (SLR) on 80 carefully selected OSS license-related\npapers, classifying existing research into three key categories, i.e., license\nidentification, license risk assessment, and license risk mitigation. Based on\nthese, we discuss challenges in existing solutions, conclude the opportunities\nto shed light on future research directions and offer practical recommendations\nfor practitioners. We hope this thorough review will help bridge the gaps\nbetween academia and industry and accelerate the ecosystem-wide governance of\nlegitimate software risks within the software engineering community.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05270v1", "cate": "cs.SE", "date": "2025-07-03", "updated": "2025-07-03"}
{"id": "2507.05605", "title": "Hapster: Using Apple Watch Haptics to Enable Live Low-Friction Student Feedback in the Physical Classroom", "authors": ["Oleg Aleksandrovich Golev", "Michelle Huang", "Chanketya Nop", "Kritin Vongthongsri", "Andrés Monroy-Hernández", "Parastoo Abtahi"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      In Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, pp. 1-7. 2024", "url": "http://arxiv.org/abs/2507.05605v1", "summary": "The benefits of student response systems (SRSs) for in-person lectures are\nwell-researched. However, all current SRSs only rely on a visual interface to\nrelay information to the instructor. We describe the design and evaluation of\nHapster, a prototype system that uses an Apple Watch to deliver live,\naggregated student feedback to the instructor via both visual and vibro-tactile\nmodalities. We evaluated this system with 6 instructors and 155 students at a\nU.S. university. Participants reported that the system was effective at\ndelivering live student feedback and facilitating better engagement from both\nthe instructor and the students. However, instructors also noted several\nchallenges with differentiating and perceiving the haptic sequences while\nlecturing. We conclude by discussing the tradeoff between system flexibility\nand abuse potential while identifying opportunities for further research\nregarding accessibility, content moderation, and additional interaction\nmodalities. Our results suggest that haptics can be used as an effective live\nfeedback mechanism for instructors in the physical classroom.", "comment": "In Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems, pp. 1-7. 2024", "pdf_url": "http://arxiv.org/pdf/2507.05605v1", "cate": "cs.HC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2505.19840", "title": "One Surrogate to Fool Them All: Universal, Transferable, and Targeted Adversarial Attacks with CLIP", "authors": ["Binyan Xu", "Xilin Dai", "Di Tang", "Kehuan Zhang"], "categories": ["cs.CR", "cs.LG", "68T07", "I.2.6"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      21 pages, 15 figures, 18 tables. To appear in the Proceedings of The ACM Conference on Computer and Communications Security (CCS), 2025", "url": "http://arxiv.org/abs/2505.19840v2", "summary": "Deep Neural Networks (DNNs) have achieved widespread success yet remain prone\nto adversarial attacks. Typically, such attacks either involve frequent queries\nto the target model or rely on surrogate models closely mirroring the target\nmodel -- often trained with subsets of the target model's training data -- to\nachieve high attack success rates through transferability. However, in\nrealistic scenarios where training data is inaccessible and excessive queries\ncan raise alarms, crafting adversarial examples becomes more challenging. In\nthis paper, we present UnivIntruder, a novel attack framework that relies\nsolely on a single, publicly available CLIP model and publicly available\ndatasets. By using textual concepts, UnivIntruder generates universal,\ntransferable, and targeted adversarial perturbations that mislead DNNs into\nmisclassifying inputs into adversary-specified classes defined by textual\nconcepts.\n  Our extensive experiments show that our approach achieves an Attack Success\nRate (ASR) of up to 85% on ImageNet and over 99% on CIFAR-10, significantly\noutperforming existing transfer-based methods. Additionally, we reveal\nreal-world vulnerabilities, showing that even without querying target models,\nUnivIntruder compromises image search engines like Google and Baidu with ASR\nrates up to 84%, and vision language models like GPT-4 and Claude-3.5 with ASR\nrates up to 80%. These findings underscore the practicality of our attack in\nscenarios where traditional avenues are blocked, highlighting the need to\nreevaluate security paradigms in AI applications.", "comment": "21 pages, 15 figures, 18 tables. To appear in the Proceedings of The\n  ACM Conference on Computer and Communications Security (CCS), 2025", "pdf_url": "http://arxiv.org/pdf/2505.19840v2", "cate": "cs.CR", "date": "2025-05-26", "updated": "2025-07-08"}
{"id": "2507.05748", "title": "A Learning-based Planning and Control Framework for Inertia Drift Vehicles", "authors": ["Bei Zhou", "Zhouheng Li", "Lei Xie", "Hongye Su", "Johannes Betz"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05748v1", "summary": "Inertia drift is a transitional maneuver between two sustained drift stages\nin opposite directions, which provides valuable insights for navigating\nconsecutive sharp corners for autonomous racing.However, this can be a\nchallenging scenario for the drift controller to handle rapid transitions\nbetween opposing sideslip angles while maintaining accurate path tracking.\nMoreover, accurate drift control depends on a high-fidelity vehicle model to\nderive drift equilibrium points and predict vehicle states, but this is often\ncompromised by the strongly coupled longitudinal-lateral drift dynamics and\nunpredictable environmental variations. To address these challenges, this paper\nproposes a learning-based planning and control framework utilizing Bayesian\noptimization (BO), which develops a planning logic to ensure a smooth\ntransition and minimal velocity loss between inertia and sustained drift\nphases. BO is further employed to learn a performance-driven control policy\nthat mitigates modeling errors for enhanced system performance. Simulation\nresults on an 8-shape reference path demonstrate that the proposed framework\ncan achieve smooth and stable inertia drift through sharp corners.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05748v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05591", "title": "MLlm-DR: Towards Explainable Depression Recognition with MultiModal Large Language Models", "authors": ["Wei Zhang", "Juan Chen", "En Zhu", "Wenhong Cheng", "YunPeng Li", "Yanbo J. Wang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05591v1", "summary": "Automated depression diagnosis aims to analyze multimodal information from\ninterview videos to predict participants' depression scores. Previous studies\noften lack clear explanations of how these scores were determined, limiting\ntheir adoption in clinical practice. While the advent of LLMs provides a\npossible pathway for explainable depression diagnosis, current LLMs capable of\nprocessing multimodal data lack training on interview data, resulting in poor\ndiagnostic performance when used directly. In this paper, we propose a novel\nmultimodal large language model (MLlm-DR) that can understand multimodal\ninformation inputs and supports explainable depression diagnosis. MLlm-DR\nintegrates a smaller LLMs and a lightweight query module (LQ-former).\nSpecifically, the smaller LLMs is designed to generate depression scores and\ncorresponding evaluation rationales. To enhance its logical reasoning for\ndomain-specific tasks while maintaining practicality, we constructed a robust\ntraining dataset to fine-tune it. Meanwhile, the LQ-former captures\ndepression-related features from speech and visual data, aiding the model's\nability to process multimodal information, to achieve comprehensive depression\ndiagnosis. Our approach achieves state-of-the-art results on two\ninterview-based benchmark datasets, CMDC and E-DAIC-WOZ, demonstrating its\neffectiveness and superiority.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05591v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05333", "title": "Causal Foundation Models: Disentangling Physics from Instrument Properties", "authors": ["Jeroen Audenaert", "Daniel Muthukrishna", "Paul F. Gregory", "David W. Hogg", "V. Ashley Villar"], "categories": ["cs.LG", "astro-ph.IM", "astro-ph.SR", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures. Accepted to the ICML 2025 Foundation Models for Structured Data Workshop and accepted to the Machine Learning for Astrophysics Workshop 2025", "url": "http://arxiv.org/abs/2507.05333v1", "summary": "Foundation models for structured time series data must contend with a\nfundamental challenge: observations often conflate the true underlying physical\nphenomena with systematic distortions introduced by measurement instruments.\nThis entanglement limits model generalization, especially in heterogeneous or\nmulti-instrument settings. We present a causally-motivated foundation model\nthat explicitly disentangles physical and instrumental factors using a\ndual-encoder architecture trained with structured contrastive learning.\nLeveraging naturally occurring observational triplets (i.e., where the same\ntarget is measured under varying conditions, and distinct targets are measured\nunder shared conditions) our model learns separate latent representations for\nthe underlying physical signal and instrument effects. Evaluated on simulated\nastronomical time series designed to resemble the complexity of variable stars\nobserved by missions like NASA's Transiting Exoplanet Survey Satellite (TESS),\nour method significantly outperforms traditional single-latent space foundation\nmodels on downstream prediction tasks, particularly in low-data regimes. These\nresults demonstrate that our model supports key capabilities of foundation\nmodels, including few-shot generalization and efficient adaptation, and\nhighlight the importance of encoding causal structure into representation\nlearning for structured data.", "comment": "8 pages, 5 figures. Accepted to the ICML 2025 Foundation Models for\n  Structured Data Workshop and accepted to the Machine Learning for\n  Astrophysics Workshop 2025", "pdf_url": "http://arxiv.org/pdf/2507.05333v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05383", "title": "Foreground-aware Virtual Staining for Accurate 3D Cell Morphological Profiling", "authors": ["Alexandr A. Kalinin", "Paula Llanos", "Theresa Maria Sommer", "Giovanni Sestini", "Xinhai Hou", "Jonathan Z. Sexton", "Xiang Wan", "Ivo D. Dinov", "Brian D. Athey", "Nicolas Rivron", "Anne E. Carpenter", "Beth Cimini", "Shantanu Singh", "Matthew J. O'Meara"], "categories": ["cs.CV", "q-bio.QM", "I.4.9; J.3"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICML 2025 Generative AI and Biology (GenBio) Workshop", "url": "http://arxiv.org/abs/2507.05383v1", "summary": "Microscopy enables direct observation of cellular morphology in 3D, with\ntransmitted-light methods offering low-cost, minimally invasive imaging and\nfluorescence microscopy providing specificity and contrast. Virtual staining\ncombines these strengths by using machine learning to predict fluorescence\nimages from label-free inputs. However, training of existing methods typically\nrelies on loss functions that treat all pixels equally, thus reproducing\nbackground noise and artifacts instead of focusing on biologically meaningful\nsignals. We introduce Spotlight, a simple yet powerful virtual staining\napproach that guides the model to focus on relevant cellular structures.\nSpotlight uses histogram-based foreground estimation to mask pixel-wise loss\nand to calculate a Dice loss on soft-thresholded predictions for shape-aware\nlearning. Applied to a 3D benchmark dataset, Spotlight improves morphological\nrepresentation while preserving pixel-level accuracy, resulting in virtual\nstains better suited for downstream tasks such as segmentation and profiling.", "comment": "ICML 2025 Generative AI and Biology (GenBio) Workshop", "pdf_url": "http://arxiv.org/pdf/2507.05383v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05272", "title": "FuzzFeed: An Automatic Approach to Weakest Precondition Generation using LLMs and Fuzzing", "authors": ["Daragh King", "Vasileios Koutavas", "Laura Kovacs"], "categories": ["cs.SE", "cs.AI", "cs.LO"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05272v1", "summary": "The weakest precondition (WP) of a program describes the largest set of\ninitial states from which all terminating executions of the program satisfy a\ngiven postcondition. The generation of WPs is an important task with practical\napplications in areas ranging from verification to run-time error checking.\n  This paper proposes the combination of Large Language Models (LLMs) and fuzz\ntesting for generating WPs. In pursuit of this goal, we introduce Fuzzing\nGuidance (FG); FG acts as a means of directing LLMs towards correct WPs using\nprogram execution feedback. FG utilises fuzz testing for approximately checking\nthe validity and weakness of candidate WPs, this information is then fed back\nto the LLM as a means of context refinement.\n  We demonstrate the effectiveness of our approach on a comprehensive benchmark\nset of deterministic array programs in Java. Our experiments indicate that LLMs\nare capable of producing viable candidate WPs, and that this ability can be\npractically enhanced through FG.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05272v1", "cate": "cs.SE", "date": "2025-07-03", "updated": "2025-07-03"}
{"id": "2507.05616", "title": "Breaking the Plane: Exploring Real-Time Visualization of 3D Surfaces in Augmented Reality with Handwritten Input", "authors": ["Liam Franco Esparraguera", "Kristoffer Selberg", "Brian Lou", "Jenny Sun", "Beza Desta", "Andrés Monroy-Hernández", "Parastoo Abtahi"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      In Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, pp. 1-9. 2024", "url": "http://arxiv.org/abs/2507.05616v1", "summary": "We introduce Breaking the Plane, an augmented reality (AR) application built\nfor AR headsets that enables users to visualize 3D mathematical functions using\nhandwritten input. Researchers have demonstrated overlaying 3D visualizations\nof mathematical concepts through AR enhances learning motivation and\ncomprehension, and equation parsing makes the authoring of teaching materials\nmore time-efficient for instructors. Previous works have developed AR systems\nthat separately employ equation parsing and 3D mathematical visualizations, but\nwork has yet to be done to combine those features by enabling real-time\ninteractions and dynamic visualizations that help users learn in situ. We\nexplore this by developing an AR system featuring handwritten equation parsing,\ngraph manipulation, and a 3D function plotter. We found that our system\nsignificantly surpassed other systems in engagement, achieved comparable ease\nof use to a popular visualization tool, was considered the most effective in\naiding problem-solving, and was highly preferred by participants for future\nuse.", "comment": "In Extended Abstracts of the CHI Conference on Human Factors in\n  Computing Systems, pp. 1-9. 2024", "pdf_url": "http://arxiv.org/pdf/2507.05616v1", "cate": "cs.HC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.11679", "title": "LLMs on support of privacy and security of mobile apps: state of the art and research directions", "authors": ["Tran Thanh Lam Nguyen", "Barbara Carminati", "Elena Ferrari"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      I am writing to respectfully request the withdrawal of my recent submission to arXiv due to an authorship issue. The paper was submitted without the explicit consent of two co-authors. After internal discussion, they have expressed clear disagreement with the submission and raised concerns about unresolved academic inaccuracies in the current version", "url": "http://arxiv.org/abs/2506.11679v2", "summary": "Modern life has witnessed the explosion of mobile devices. However, besides\nthe valuable features that bring convenience to end users, security and privacy\nrisks still threaten users of mobile apps. The increasing sophistication of\nthese threats in recent years has underscored the need for more advanced and\nefficient detection approaches. In this chapter, we explore the application of\nLarge Language Models (LLMs) to identify security risks and privacy violations\nand mitigate them for the mobile application ecosystem. By introducing\nstate-of-the-art research that applied LLMs to mitigate the top 10 common\nsecurity risks of smartphone platforms, we highlight the feasibility and\npotential of LLMs to replace traditional analysis methods, such as dynamic and\nhybrid analysis of mobile apps. As a representative example of LLM-based\nsolutions, we present an approach to detect sensitive data leakage when users\nshare images online, a common behavior of smartphone users nowadays. Finally,\nwe discuss open research challenges.", "comment": "I am writing to respectfully request the withdrawal of my recent\n  submission to arXiv due to an authorship issue. The paper was submitted\n  without the explicit consent of two co-authors. After internal discussion,\n  they have expressed clear disagreement with the submission and raised\n  concerns about unresolved academic inaccuracies in the current version", "pdf_url": "http://arxiv.org/pdf/2506.11679v2", "cate": "cs.CR", "date": "2025-06-13", "updated": "2025-07-07"}
{"id": "2507.05754", "title": "LeAD: The LLM Enhanced Planning System Converged with End-to-end Autonomous Driving", "authors": ["Yuhang Zhang", "Jiaqi Liu", "Chengkai Xu", "Peng Hang", "Jian Sun"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05754v1", "summary": "A principal barrier to large-scale deployment of urban autonomous driving\nsystems lies in the prevalence of complex scenarios and edge cases. Existing\nsystems fail to effectively interpret semantic information within traffic\ncontexts and discern intentions of other participants, consequently generating\ndecisions misaligned with skilled drivers' reasoning patterns. We present LeAD,\na dual-rate autonomous driving architecture integrating imitation\nlearning-based end-to-end (E2E) frameworks with large language model (LLM)\naugmentation. The high-frequency E2E subsystem maintains real-time\nperception-planning-control cycles, while the low-frequency LLM module enhances\nscenario comprehension through multi-modal perception fusion with HD maps and\nderives optimal decisions via chain-of-thought (CoT) reasoning when baseline\nplanners encounter capability limitations. Our experimental evaluation in the\nCARLA Simulator demonstrates LeAD's superior handling of unconventional\nscenarios, achieving 71 points on Leaderboard V1 benchmark, with a route\ncompletion of 93%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05754v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05613", "title": "Domain adaptation of large language models for geotechnical applications", "authors": ["Lei Fan", "Fangxue Liu", "Cheng Chen"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05613v1", "summary": "Recent developments in large language models (LLMs) are opening up new\nopportunities in geotechnical engineering and engineering geology. While\ngeneral-purpose LLMs possess broad capabilities, effective application in\ngeotechnics often requires domain-specific adaptation. Such tailored LLMs are\nincreasingly employed to streamline geotechnical workflows. This paper presents\nthe first survey of the adaptation and application of LLMs in geotechnical\nengineering. It outlines key methodologies for adaptation to geotechnical\ndomain, including prompt engineering, retrieval-augmented generation,\ndomain-adaptive pretraining, and fine-tuning. The survey examines the\nstate-of-the-art applications of geotechnical-adapted LLMs, including\ngeological interpretation, subsurface characterization, site planning, design\ncalculations, numerical modeling, safety and risk assessment, and educational\ntutoring. It also analyzes benefits and limitations of geotechnical-adapted\nLLMs, and identifies promising directions for future research in this\ninterdisciplinary discipline. The findings serve as a valuable resource for\npractitioners seeking to integrate LLMs into geotechnical practice, while also\nproviding a foundation to stimulate further investigation within the academic\ncommunity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05613v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05386", "title": "Reinforcement Fine-Tuning Naturally Mitigates Forgetting in Continual Post-Training", "authors": ["Song Lai", "Haohan Zhao", "Rong Feng", "Changyi Ma", "Wenzhuo Liu", "Hongbo Zhao", "Xi Lin", "Dong Yi", "Min Xie", "Qingfu Zhang", "Hongbin Liu", "Gaofeng Meng", "Fei Zhu"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05386v1", "summary": "Continual post-training (CPT) is a popular and effective technique for\nadapting foundation models like multimodal large language models to specific\nand ever-evolving downstream tasks. While existing research has primarily\nconcentrated on methods like data replay, model expansion, or parameter\nregularization, the fundamental role of the learning paradigm within CPT\nremains largely unexplored. This paper presents a comparative analysis of two\ncore post-training paradigms: supervised fine-tuning (SFT) and reinforcement\nfine-tuning (RFT), investigating their respective impacts on knowledge\nretention during CPT. Our experiments are conducted on a benchmark comprising\nseven diverse multimodal tasks, utilizing Qwen2.5-VL-7B-Instruct as the base\nmodel for continual post-training. The investigation yields two significant\nfindings: (1) When continuously learning on downstream tasks, SFT leads to\ncatastrophic forgetting of previously learned tasks. In contrast, RFT\ninherently preserves prior knowledge and achieve performance comparable to\nmulti-task training. (2) RFT successfully protects and even enhances the\nmodel's general knowledge on standard benchmarks (e.g., MMMU and MMLU-Pro).\nConversely, SFT degrades general model capabilities severely. Further analysis\nshows that explicit mechanisms, such as KL penalty and chain-of-thought\nreasoning, are not the primary factors. Instead, we find that the implicit\nregularization inherent to RFT is a key factor in mitigating forgetting.\nFinally, we propose a rollout-based instance filtering algorithm to improve the\nstability and efficiency of RFT. Our comprehensive study demonstrates the\nsuperiority of RFT as a robust paradigm for continual post-training.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05386v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05390", "title": "From General to Specialized: The Need for Foundational Models in Agriculture", "authors": ["Vishal Nedungadi", "Xingguo Xiong", "Aike Potze", "Ron Van Bree", "Tao Lin", "Marc Rußwurm", "Ioannis N. Athanasiadis"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05390v1", "summary": "Food security remains a global concern as population grows and climate change\nintensifies, demanding innovative solutions for sustainable agricultural\nproductivity. Recent advances in foundation models have demonstrated remarkable\nperformance in remote sensing and climate sciences, and therefore offer new\nopportunities for agricultural monitoring. However, their application in\nchallenges related to agriculture-such as crop type mapping, crop phenology\nestimation, and crop yield estimation-remains under-explored. In this work, we\nquantitatively evaluate existing foundational models to assess their\neffectivity for a representative set of agricultural tasks. From an\nagricultural domain perspective, we describe a requirements framework for an\nideal agricultural foundation model (CropFM). We then survey and compare\nexisting general-purpose foundational models in this framework and empirically\nevaluate two exemplary of them in three representative agriculture specific\ntasks. Finally, we highlight the need for a dedicated foundational model\ntailored specifically to agriculture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05390v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05279", "title": "ReservoirChat: Interactive Documentation Enhanced with LLM and Knowledge Graph for ReservoirPy", "authors": ["Virgile Boraud", "Yannis Bendi-Ouis", "Paul Bernard", "Xavier Hinaut"], "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.NE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05279v1", "summary": "We introduce a tool designed to improve the capabilities of Large Language\nModels (LLMs) in assisting with code development using the ReservoirPy library,\nas well as in answering complex questions in the field of Reservoir Computing.\nBy incorporating external knowledge through Retrieval-Augmented Generation\n(RAG) and knowledge graphs, our approach aims to reduce hallucinations and\nincrease the factual accuracy of generated responses. The system provides an\ninteractive experience similar to ChatGPT, tailored specifically for\nReservoirPy, enabling users to write, debug, and understand Python code while\naccessing reliable domain-specific insights. In our evaluation, while\nproprietary models such as ChatGPT-4o and NotebookLM performed slightly better\non general knowledge questions, our model outperformed them on coding tasks and\nshowed a significant improvement over its base model, Codestral-22B.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05279v1", "cate": "cs.SE", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2506.12096", "title": "Quantum Computing and Cybersecurity in Accounting and Finance: Current and Future Challenges and the Opportunities for Securing Accounting and Finance Systems in the Post-Quantum World", "authors": ["Huma Habib Shadan", "Sardar Islam"], "categories": ["cs.CR", "cs.ET"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      44 Pages, 2 Figures, 4 Tables, 1 Flow Diagram", "url": "http://arxiv.org/abs/2506.12096v2", "summary": "Quantum computing is transforming the world profoundly, affecting businesses,\norganisations, technologies, and human beings' information systems, and will\nhave a profound impact on accounting and finance, particularly in the realm of\ncybersecurity. It presents both opportunities and risks in ensuring\nconfidentiality and protecting financial data. The purpose of this article is\nto show the application of quantum technologies in accounting cybersecurity,\nutilising quantum algorithms and QKD to overcome the limitations of classical\ncomputing.\n  The literature review reveals the vulnerabilities of the current accounting\ncybersecurity to quantum attacks and the need for quantum-resistant\ncryptographic mechanisms. It elaborates on the risks associated with\nconventional encryption in the context of quantum capabilities. This study\ncontributes to the understanding of how quantum computing can transform\naccounting cybersecurity by enhancing quantum-resistant algorithms and using\nQKD in accounting.\n  The study employs PSALSAR systematic review methodology to ensure rigour and\ndepth. The analysis shows that quantum computing enhances encryption techniques\nto superior possibilities than classical ones. Using quantum technologies in\naccounting minimises data breaches and unauthorised access. The study concludes\nthat quantum-resistant algorithms and quantum key distribution (QKD) are\nnecessary for securing the accounting and finance systems of the future.\n  Keywords Quantum Computing, Cybersecurity, Accounting, Machine Learning,\nArtificial Intelligence, Quantum Key Distribution, Operations Management", "comment": "44 Pages, 2 Figures, 4 Tables, 1 Flow Diagram", "pdf_url": "http://arxiv.org/pdf/2506.12096v2", "cate": "cs.CR", "date": "2025-06-12", "updated": "2025-07-08"}
{"id": "2507.05861", "title": "Communication-Efficient Module-Wise Federated Learning for Grasp Pose Detection in Cluttered Environments", "authors": ["Woonsang Kang", "Joohyung Lee", "Seungjun Kim", "Jungchan Cho", "Yoonseon Oh"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures. Submitted to IEEE Robotics and Automation Letters (RA-L)", "url": "http://arxiv.org/abs/2507.05861v1", "summary": "Grasp pose detection (GPD) is a fundamental capability for robotic autonomy,\nbut its reliance on large, diverse datasets creates significant data privacy\nand centralization challenges. Federated Learning (FL) offers a\nprivacy-preserving solution, but its application to GPD is hindered by the\nsubstantial communication overhead of large models, a key issue for\nresource-constrained robots. To address this, we propose a novel module-wise FL\nframework that begins by analyzing the learning dynamics of the GPD model's\nfunctional components. This analysis identifies slower-converging modules, to\nwhich our framework then allocates additional communication effort. This is\nrealized through a two-phase process: a standard full-model training phase is\nfollowed by a communication-efficient phase where only the identified subset of\nslower-converging modules is trained and their partial updates are aggregated.\nExtensive experiments on the GraspNet-1B dataset demonstrate that our method\noutperforms standard FedAvg and other baselines, achieving higher accuracy for\na given communication budget. Furthermore, real-world experiments on a physical\nrobot validate our approach, showing a superior grasp success rate compared to\nbaseline methods in cluttered scenes. Our work presents a\ncommunication-efficient framework for training robust, generalized GPD models\nin a decentralized manner, effectively improving the trade-off between\ncommunication cost and model performance.", "comment": "8 pages, 5 figures. Submitted to IEEE Robotics and Automation Letters\n  (RA-L)", "pdf_url": "http://arxiv.org/pdf/2507.05861v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05624", "title": "ADMC: Attention-based Diffusion Model for Missing Modalities Feature Completion", "authors": ["Wei Zhang", "Juan Chen", "Yanbo J. Wang", "En Zhu", "Xuan Yang", "Yiduo Wang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05624v1", "summary": "Multimodal emotion and intent recognition is essential for automated\nhuman-computer interaction, It aims to analyze users' speech, text, and visual\ninformation to predict their emotions or intent. One of the significant\nchallenges is that missing modalities due to sensor malfunctions or incomplete\ndata. Traditional methods that attempt to reconstruct missing information often\nsuffer from over-coupling and imprecise generation processes, leading to\nsuboptimal outcomes. To address these issues, we introduce an Attention-based\nDiffusion model for Missing Modalities feature Completion (ADMC). Our framework\nindependently trains feature extraction networks for each modality, preserving\ntheir unique characteristics and avoiding over-coupling. The Attention-based\nDiffusion Network (ADN) generates missing modality features that closely align\nwith authentic multimodal distribution, enhancing performance across all\nmissing-modality scenarios. Moreover, ADN's cross-modal generation offers\nimproved recognition even in full-modality contexts. Our approach achieves\nstate-of-the-art results on the IEMOCAP and MIntRec benchmarks, demonstrating\nits effectiveness in both missing and complete modality scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05624v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05405", "title": "Probabilistically Tightened Linear Relaxation-based Perturbation Analysis for Neural Network Verification", "authors": ["Luca Marzari", "Ferdinando Cicalese", "Alessandro Farinelli"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05405v1", "summary": "We present $\\textbf{P}$robabilistically $\\textbf{T}$ightened\n$\\textbf{Li}$near $\\textbf{R}$elaxation-based $\\textbf{P}$erturbation\n$\\textbf{A}$nalysis ($\\texttt{PT-LiRPA}$), a novel framework that combines\nover-approximation techniques from LiRPA-based approaches with a sampling-based\nmethod to compute tight intermediate reachable sets. In detail, we show that\nwith negligible computational overhead, $\\texttt{PT-LiRPA}$ exploiting the\nestimated reachable sets, significantly tightens the lower and upper linear\nbounds of a neural network's output, reducing the computational cost of formal\nverification tools while providing probabilistic guarantees on verification\nsoundness. Extensive experiments on standard formal verification benchmarks,\nincluding the International Verification of Neural Networks Competition, show\nthat our $\\texttt{PT-LiRPA}$-based verifier improves robustness certificates by\nup to 3.31X and 2.26X compared to related work. Importantly, our probabilistic\napproach results in a valuable solution for challenging competition entries\nwhere state-of-the-art formal verification methods fail, allowing us to provide\nanswers with high confidence (i.e., at least 99%).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05405v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05393", "title": "Enhancing Underwater Images Using Deep Learning with Subjective Image Quality Integration", "authors": ["Jose M. Montero", "Jose-Luis Lisani"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05393v1", "summary": "Recent advances in deep learning, particularly neural networks, have\nsignificantly impacted a wide range of fields, including the automatic\nenhancement of underwater images. This paper presents a deep learning-based\napproach to improving underwater image quality by integrating human subjective\nassessments into the training process. To this end, we utilize publicly\navailable datasets containing underwater images labeled by experts as either\nhigh or low quality. Our method involves first training a classifier network to\ndistinguish between high- and low-quality images. Subsequently, generative\nadversarial networks (GANs) are trained using various enhancement criteria to\nrefine the low-quality images. The performance of the GAN models is evaluated\nusing quantitative metrics such as PSNR, SSIM, and UIQM, as well as through\nqualitative analysis. Results demonstrate that the proposed model --\nparticularly when incorporating criteria such as color fidelity and image\nsharpness -- achieves substantial improvements in both perceived and measured\nimage quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05393v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05281", "title": "CoreCodeBench: A Configurable Multi-Scenario Repository-Level Benchmark", "authors": ["Lingyue Fu", "Hao Guan", "Bolun Zhang", "Haowei Yuan", "Yaoming Zhu", "Jun Xu", "Zongyu Wang", "Lin Qiu", "Xunliang Cai", "Xuezhi Cao", "Weiwen Liu", "Weinan Zhang", "Yong Yu"], "categories": ["cs.SE", "cs.CL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05281v1", "summary": "As Large Language Models (LLMs) demonstrate increasingly sophisticated code\nprocessing capabilities, evaluating their performance on engineering-level code\nremains challenging. Existing repository-level benchmarks primarily focus on\nsingle scenarios, such as code generation or bug fixing, without adequately\ncapturing the diversity and complexity of real-world software or project\nengineering workflows. Furthermore, these benchmarks suffer from limited\ncontrollability in question positioning and reliability issues in their\ngenerated test cases. To address these limitations, we present CorePipe, a\nfully automated pipeline that converts repositories into comprehensive test\ncases, and introduce CoreCodeBench, a configurable multi-scenario\nrepository-level benchmark. To simulate real engineering scenarios, CorePipe\ngenerates three types of atomic questions (Development, BugFix, and Test-Driven\nDevelopment) specifically targeting core code segments. These atomic questions\nare further combined into three types of composite questions, with difficulty\nlevels flexibly adjusted through hyperparameter tuning. CoreCodeBench provides\na comprehensive and extensive repository-level benchmark to investigate the\napplicability of LLMs in real-world engineering projects. Experiments with 16\nLLMs across diverse scenarios reveal varying capabilities and offer\nmulti-dimensional insights into LLM performance in engineering contexts. The\ncode for CorePipe is available at\nhttps://github.com/AGI-Eval-Official/CoreCodeBench, and the data for\nCoreCodeBench can be accessed at\nhttps://huggingface.co/collections/tubehhh/corecodebench-68256d2faabf4b1610a08caa.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05281v1", "cate": "cs.SE", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.05962", "title": "Evaluation of Large Language Model-Driven AutoML in Data and Model Management from Human-Centered Perspective", "authors": ["Jiapeng Yao", "Lantian Zhang", "Jiping Huang"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05962v1", "summary": "As organizations increasingly seek to leverage machine learning (ML)\ncapabilities, the technical complexity of implementing ML solutions creates\nsignificant barriers to adoption and impacts operational efficiency. This\nresearch examines how Large Language Models (LLMs) can transform the\naccessibility of ML technologies within organizations through a human-centered\nAutomated Machine Learning (AutoML) approach. Through a comprehensive user\nstudy involving 15 professionals across various roles and technical\nbackgrounds, we evaluate the organizational impact of an LLM-based AutoML\nframework compared to traditional implementation methods. Our research offers\nfour significant contributions to both management practice and technical\ninnovation: First, we present pioneering evidence that LLM-based interfaces can\ndramatically improve ML implementation success rates, with 93.34% of users\nachieved superior performance in the LLM condition, with 46.67% showing higher\naccuracy (10-25% improvement over baseline) and 46.67% demonstrating\nsignificantly higher accuracy (>25% improvement over baseline), while 6.67%\nmaintained comparable performance levels; and 60% reporting substantially\nreduced development time. Second, we demonstrate how natural language\ninterfaces can effectively bridge the technical skills gap in organizations,\ncutting implementation time by 50% while improving accuracy across all\nexpertise levels. Third, we provide valuable insights for organizations\ndesigning human-AI collaborative systems, showing that our approach reduced\nerror resolution time by 73% and significantly accelerated employee learning\ncurves. Finally, we establish empirical support for natural language as an\neffective interface for complex technical systems, offering organizations a\npath to democratize ML capabilities without compromising quality or\nperformance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05962v1", "cate": "cs.HC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06063", "title": "Practical design and performance of physical reservoir computing using hysteresis", "authors": ["Yuhei Yamada"], "categories": ["cs.ET", "cs.NE"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06063v1", "summary": "Physical reservoir computing is an innovative idea for using physical\nphenomena as computational resources. Recent research has revealed that\ninformation processing techniques can improve the performance, but for\npractical applications, it is equally important to study the level of\nperformance with a simple design that is easy to construct experimentally. We\nfocus on a reservoir composed of independent hysteretic systems as a model\nsuitable for the practical implementation of physical reservoir computing. In\nthis paper, we discuss the appropriate design of this reservoir, its\nperformance, and its limitations. This research will serve as a practical\nguideline for constructing hysteresis-based reservoirs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06063v1", "cate": "cs.ET", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.15790", "title": "ETrace:Event-Driven Vulnerability Detection in Smart Contracts via LLM-Based Trace Analysis", "authors": ["Chenyang Peng", "Haijun Wang", "Yin Wu", "Hao Wu", "Ming Fan", "Yitao Zhao", "Ting Liu"], "categories": ["cs.CR", "cs.SE", "68N01", "D.2.0"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      4 pages, 1 figure. Submitted to the 16th Asia-Pacific Symposium on Internetware (Internetware 2025)", "url": "http://arxiv.org/abs/2506.15790v2", "summary": "With the advance application of blockchain technology in various fields,\nensuring the security and stability of smart contracts has emerged as a\ncritical challenge. Current security analysis methodologies in vulnerability\ndetection can be categorized into static analysis and dynamic analysis\nmethods.However, these existing traditional vulnerability detection methods\npredominantly rely on analyzing original contract code, not all smart contracts\nprovide accessible code.We present ETrace, a novel event-driven vulnerability\ndetection framework for smart contracts, which uniquely identifies potential\nvulnerabilities through LLM-powered trace analysis without requiring source\ncode access. By extracting fine-grained event sequences from transaction logs,\nthe framework leverages Large Language Models (LLMs) as adaptive semantic\ninterpreters to reconstruct event analysis through chain-of-thought reasoning.\nETrace implements pattern-matching to establish causal links between\ntransaction behavior patterns and known attack behaviors. Furthermore, we\nvalidate the effectiveness of ETrace through preliminary experimental results.", "comment": "4 pages, 1 figure. Submitted to the 16th Asia-Pacific Symposium on\n  Internetware (Internetware 2025)", "pdf_url": "http://arxiv.org/pdf/2506.15790v2", "cate": "cs.CR", "date": "2025-06-18", "updated": "2025-07-08"}
{"id": "2507.05884", "title": "Comparison of Path Planning Algorithms for Autonomous Vehicle Navigation Using Satellite and Airborne LiDAR Data", "authors": ["Chang Liu", "Zhexiong Xue", "Tamas Sziranyi"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, 67th International Symposium ELMAR-2025 15-17 September 2025 Zadar, Croatia", "url": "http://arxiv.org/abs/2507.05884v1", "summary": "Autonomous vehicle navigation in unstructured environments, such as forests\nand mountainous regions, presents significant challenges due to irregular\nterrain and complex road conditions. This work provides a comparative\nevaluation of mainstream and well-established path planning algorithms applied\nto weighted pixel-level road networks derived from high-resolution satellite\nimagery and airborne LiDAR data. For 2D road-map navigation, where the weights\nreflect road conditions and terrain difficulty, A*, Dijkstra, RRT*, and a Novel\nImproved Ant Colony Optimization Algorithm (NIACO) are tested on the DeepGlobe\nsatellite dataset. For 3D road-map path planning, 3D A*, 3D Dijkstra,\nRRT-Connect, and NIACO are evaluated using the Hamilton airborne LiDAR dataset,\nwhich provides detailed elevation information. All algorithms are assessed\nunder identical start and end point conditions, focusing on path cost,\ncomputation time, and memory consumption. Results demonstrate that Dijkstra\nconsistently offers the most stable and efficient performance in both 2D and 3D\nscenarios, particularly when operating on dense, pixel-level geospatial\nroad-maps. These findings highlight the reliability of Dijkstra-based planning\nfor static terrain navigation and establish a foundation for future research on\ndynamic path planning under complex environmental constraints.", "comment": "6 pages, 3 figures, 67th International Symposium ELMAR-2025 15-17\n  September 2025 Zadar, Croatia", "pdf_url": "http://arxiv.org/pdf/2507.05884v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05629", "title": "Enhancing Student Learning with LLM-Generated Retrieval Practice Questions: An Empirical Study in Data Science Courses", "authors": ["Yuan An", "John Liu", "Niyam Acharya", "Ruhma Hashmi"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05629v1", "summary": "Retrieval practice is a well-established pedagogical technique known to\nsignificantly enhance student learning and knowledge retention. However,\ngenerating high-quality retrieval practice questions is often time-consuming\nand labor intensive for instructors, especially in rapidly evolving technical\nsubjects. Large Language Models (LLMs) offer the potential to automate this\nprocess by generating questions in response to prompts, yet the effectiveness\nof LLM-generated retrieval practice on student learning remains to be\nestablished. In this study, we conducted an empirical study involving two\ncollege-level data science courses, with approximately 60 students. We compared\nlearning outcomes during one week in which students received LLM-generated\nmultiple-choice retrieval practice questions to those from a week in which no\nsuch questions were provided. Results indicate that students exposed to\nLLM-generated retrieval practice achieved significantly higher knowledge\nretention, with an average accuracy of 89%, compared to 73% in the week without\nsuch practice. These findings suggest that LLM-generated retrieval questions\ncan effectively support student learning and may provide a scalable solution\nfor integrating retrieval practice into real-time teaching. However, despite\nthese encouraging outcomes and the potential time-saving benefits, cautions\nmust be taken, as the quality of LLM-generated questions can vary. Instructors\nmust still manually verify and revise the generated questions before releasing\nthem to students.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05629v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05411", "title": "AXLearn: Modular Large Model Training on Heterogeneous Infrastructure", "authors": ["Mark Lee", "Tom Gunter", "Chang Lan", "John Peebles", "Hanzhi Zhou", "Kelvin Zou", "Sneha Bangalore", "Chung-Cheng Chiu", "Nan Du", "Xianzhi Du", "Philipp Dufter", "Ruixuan Hou", "Haoshuo Huang", "Dongseong Hwang", "Xiang Kong", "Jinhao Lei", "Tao Lei", "Meng Li", "Li Li", "Jiarui Lu", "Zhiyun Lu", "Yiping Ma", "David Qiu", "Vivek Rathod", "Senyu Tong", "Zhucheng Tu", "Jianyu Wang", "Yongqiang Wang", "Zirui Wang", "Floris Weers", "Sam Wiseman", "Guoli Yin", "Bowen Zhang", "Xiyou Zhou", "Danyang Zhuo", "Cheng Leong", "Ruoming Pang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05411v1", "summary": "We design and implement AXLearn, a production deep learning system that\nfacilitates scalable and high-performance training of large deep learning\nmodels. Compared to other state-of-the-art deep learning systems, AXLearn has a\nunique focus on modularity and support for heterogeneous hardware\ninfrastructure. AXLearn's internal interfaces between software components\nfollow strict encapsulation, allowing different components to be assembled to\nfacilitate rapid model development and experimentation on heterogeneous compute\ninfrastructure. We introduce a novel method of quantifying modularity via\nLines-of-Code (LoC)-complexity, which demonstrates how our system maintains\nconstant complexity as we scale the components in the system, compared to\nlinear or quadratic complexity in other systems. This allows integrating\nfeatures such as Rotary Position Embeddings (RoPE) into AXLearn across hundred\nof modules with just 10 lines of code, compared to hundreds as required in\nother systems. At the same time, AXLearn maintains equivalent performance\ncompared to state-of-the-art training systems. Finally, we share our experience\nin the development and operation of AXLearn.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05411v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05394", "title": "pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models", "authors": ["Sajjad Ghiasvand", "Mahnoosh Alizadeh", "Ramtin Pedarsani"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05394v1", "summary": "Vision-Language Models (VLMs) like CLIP have demonstrated remarkable\ngeneralization in zero- and few-shot settings, but adapting them efficiently to\ndecentralized, heterogeneous data remains a challenge. While prompt tuning has\nemerged as a popular parameter-efficient approach in personalized federated\nlearning, existing methods often sacrifice generalization in favor of\npersonalization, struggling particularly on unseen classes or domains. In this\nwork, we propose pFedMMA, the first personalized federated learning framework\nthat leverages multi-modal adapters for vision-language tasks. Each adapter\ncontains modality-specific up- and down-projection layers alongside a globally\nshared projection that aligns cross-modal features. Our asymmetric optimization\nstrategy allows clients to locally adapt to personalized data distributions\nwhile collaboratively training the shared projection to improve global\ngeneralization. This design is also communication-efficient, as only the shared\ncomponent is exchanged during rounds. Through extensive experiments across\neleven datasets, including domain- and label-shift scenarios, we show that\npFedMMA achieves state-of-the-art trade-offs between personalization and\ngeneralization, outperforming recent federated prompt tuning methods. The code\nis available at https://github.com/sajjad-ucsb/pFedMMA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05394v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05289", "title": "Measuring how changes in code readability attributes affect code quality evaluation by Large Language Models", "authors": ["Igor Regis da Silva Simoes", "Elaine Venson"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05289v1", "summary": "Code readability is one of the main aspects of code quality, influenced by\nvarious properties like identifier names, comments, code structure, and\nadherence to standards. However, measuring this attribute poses challenges in\nboth industry and academia. While static analysis tools assess attributes such\nas code smells and comment percentage, code reviews introduce an element of\nsubjectivity. This paper explores using Large Language Models (LLMs) to\nevaluate code quality attributes related to its readability in a standardized,\nreproducible, and consistent manner. We conducted a quasi-experiment study to\nmeasure the effects of code changes on Large Language Model (LLM)s\ninterpretation regarding its readability quality attribute. Nine LLMs were\ntested, undergoing three interventions: removing comments, replacing identifier\nnames with obscure names, and refactoring to remove code smells. Each\nintervention involved 10 batch analyses per LLM, collecting data on response\nvariability. We compared the results with a known reference model and tool. The\nresults showed that all LLMs were sensitive to the interventions, with\nagreement with the reference classifier being high for the original and\nrefactored code scenarios. The LLMs demonstrated a strong semantic sensitivity\nthat the reference model did not fully capture. A thematic analysis of the LLMs\nreasoning confirmed their evaluations directly reflected the nature of each\nintervention. The models also exhibited response variability, with 9.37% to\n14.58% of executions showing a standard deviation greater than zero, indicating\nresponse oscillation, though this did not always compromise the statistical\nsignificance of the results. LLMs demonstrated potential for evaluating\nsemantic quality aspects, such as coherence between identifier names, comments,\nand documentation with code purpose.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05289v1", "cate": "cs.SE", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.06000", "title": "Exploring Collaboration Patterns and Strategies in Human-AI Co-creation through the Lens of Agency: A Scoping Review of the Top-tier HCI Literature", "authors": ["Shuning Zhang", "Hui Wang", "Xin Yi"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06000v1", "summary": "As Artificial Intelligence (AI) increasingly becomes an active collaborator\nin co-creation, understanding the distribution and dynamic of agency is\nparamount. The Human-Computer Interaction (HCI) perspective is crucial for this\nanalysis, as it uniquely reveals the interaction dynamics and specific control\nmechanisms that dictate how agency manifests in practice. Despite this\nimportance, a systematic synthesis mapping agency configurations and control\nmechanisms within the HCI/CSCW literature is lacking. Addressing this gap, we\nreviewed 134 papers from top-tier HCI/CSCW venues (e.g., CHI, UIST, CSCW) over\nthe past 20 years. This review yields four primary contributions: (1) an\nintegrated theoretical framework structuring agency patterns, control\nmechanisms, and interaction contexts, (2) a comprehensive operational catalog\nof control mechanisms detailing how agency is implemented; (3) an actionable\ncross-context map linking agency configurations to diverse co-creative\npractices; and (4) grounded implications and guidance for future CSCW research\nand the design of co-creative systems, addressing aspects like trust and\nethics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06000v1", "cate": "cs.HC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2105.02215", "title": "Massive MIMO-NOMA Systems Secrecy in the Presence of Active Eavesdroppers", "authors": ["Marziyeh Soltani", "Mahtab Mirmohseni", "Panos Papadimitratos"], "categories": ["cs.IT", "cs.CR", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2105.02215v2", "summary": "Non-orthogonal multiple access (NOMA) and massive multiple-input\nmultiple-output (MIMO) systems are highly efficient. Massive MIMO systems are\ninherently resistant to passive attackers (eavesdroppers), thanks to\ntransmissions directed to the desired users. However, active attackers can\ntransmit a combination of legitimate user pilot signals during the channel\nestimation phase. This way they can mislead the base station (BS) to rotate the\ntransmission in their direction, and allow them to eavesdrop during the\ndownlink data transmission phase. In this paper, we analyse this vulnerability\nin an improved system model and stronger adversary assumptions, and investigate\nhow physical layer security can mitigate such attacks and ensure secure\n(confidential) communication. We derive the secrecy outage probability (SOP)\nand a lower bound on the ergodic secrecy capacity, using stochastic geometry\ntools when the number of antennas in the BSs tends to infinity. We adapt the\nresult to evaluate the secrecy performance in massive orthogonal multiple\naccess (OMA). We find that appropriate power allocation allows NOMA to\noutperform OMA in terms of ergodic secrecy rate and SOP.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2105.02215v2", "cate": "cs.IT", "date": "2021-05-05", "updated": "2025-07-07"}
{"id": "2507.05978", "title": "FineGrasp: Towards Robust Grasping for Delicate Objects", "authors": ["Yun Du", "Mengao Zhao", "Tianwei Lin", "Yiwei Jin", "Chaodong Huang", "Zhizhong Su"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages, 6 figures", "url": "http://arxiv.org/abs/2507.05978v1", "summary": "Recent advancements in robotic grasping have led to its integration as a core\nmodule in many manipulation systems. For instance, language-driven semantic\nsegmentation enables the grasping of any designated object or object part.\nHowever, existing methods often struggle to generate feasible grasp poses for\nsmall objects or delicate components, potentially causing the entire pipeline\nto fail. To address this issue, we propose a novel grasping method, FineGrasp,\nwhich introduces improvements in three key aspects. First, we introduce\nmultiple network modifications to enhance the ability of to handle delicate\nregions. Second, we address the issue of label imbalance and propose a refined\ngraspness label normalization strategy. Third, we introduce a new simulated\ngrasp dataset and show that mixed sim-to-real training further improves grasp\nperformance. Experimental results show significant improvements, especially in\ngrasping small objects, and confirm the effectiveness of our system in semantic\ngrasping.", "comment": "7 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.05978v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05638", "title": "LLMs are Introvert", "authors": ["Litian Zhang", "Xiaoming Zhang", "Bingyu Yan", "Ziyi Zhou", "Bo Zhang", "Zhenyu Guan", "Xi Zhang", "Chaozhuo Li"], "categories": ["cs.AI", "cs.SI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05638v1", "summary": "The exponential growth of social media and generative AI has transformed\ninformation dissemination, fostering connectivity but also accelerating the\nspread of misinformation. Understanding information propagation dynamics and\ndeveloping effective control strategies is essential to mitigate harmful\ncontent. Traditional models, such as SIR, provide basic insights but\ninadequately capture the complexities of online interactions. Advanced methods,\nincluding attention mechanisms and graph neural networks, enhance accuracy but\ntypically overlook user psychology and behavioral dynamics. Large language\nmodels (LLMs), with their human-like reasoning, offer new potential for\nsimulating psychological aspects of information spread. We introduce an\nLLM-based simulation environment capturing agents' evolving attitudes,\nemotions, and responses. Initial experiments, however, revealed significant\ngaps between LLM-generated behaviors and authentic human dynamics, especially\nin stance detection and psychological realism. A detailed evaluation through\nSocial Information Processing Theory identified major discrepancies in\ngoal-setting and feedback evaluation, stemming from the lack of emotional\nprocessing in standard LLM training. To address these issues, we propose the\nSocial Information Processing-based Chain of Thought (SIP-CoT) mechanism\nenhanced by emotion-guided memory. This method improves the interpretation of\nsocial cues, personalization of goals, and evaluation of feedback. Experimental\nresults confirm that SIP-CoT-enhanced LLM agents more effectively process\nsocial information, demonstrating behaviors, attitudes, and emotions closer to\nreal human interactions. In summary, this research highlights critical\nlimitations in current LLM-based propagation simulations and demonstrates how\nintegrating SIP-CoT and emotional memory significantly enhances the social\nintelligence and realism of LLM agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05638v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05412", "title": "Incorporating Interventional Independence Improves Robustness against Interventional Distribution Shift", "authors": ["Gautam Sreekumar", "Vishnu Naresh Boddeti"], "categories": ["cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05412v1", "summary": "We consider the problem of learning robust discriminative representations of\ncausally-related latent variables. In addition to observational data, the\ntraining dataset also includes interventional data obtained through targeted\ninterventions on some of these latent variables to learn representations robust\nagainst the resulting interventional distribution shifts. Existing approaches\ntreat interventional data like observational data, even when the underlying\ncausal model is known, and ignore the independence relations that arise from\nthese interventions. Since these approaches do not fully exploit the causal\nrelational information resulting from interventions, they learn representations\nthat produce large disparities in predictive performance on observational and\ninterventional data, which worsens when the number of interventional training\nsamples is limited. In this paper, (1) we first identify a strong correlation\nbetween this performance disparity and adherence of the representations to the\nindependence conditions induced by the interventional causal model. (2) For\nlinear models, we derive sufficient conditions on the proportion of\ninterventional data in the training dataset, for which enforcing interventional\nindependence between representations corresponding to the intervened node and\nits non-descendants lowers the error on interventional data. Combining these\ninsights, (3) we propose RepLIn, a training algorithm to explicitly enforce\nthis statistical independence during interventions. We demonstrate the utility\nof RepLIn on a synthetic dataset and on real image and text datasets on facial\nattribute classification and toxicity detection, respectively. Our experiments\nshow that RepLIn is scalable with the number of nodes in the causal graph and\nis suitable to improve the robust representations against interventional\ndistribution shifts of both continuous and discrete latent variables.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05412v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05397", "title": "Neural-Driven Image Editing", "authors": ["Pengfei Zhou", "Jie Xia", "Xiaopeng Peng", "Wangbo Zhao", "Zilong Ye", "Zekai Li", "Suorong Yang", "Jiadong Pan", "Yuanxiang Chen", "Ziqiao Wang", "Kai Wang", "Qian Zheng", "Xiaojun Chang", "Gang Pan", "Shurong Dong", "Kaipeng Zhang", "Yang You"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      22 pages, 14 figures", "url": "http://arxiv.org/abs/2507.05397v1", "summary": "Traditional image editing typically relies on manual prompting, making it\nlabor-intensive and inaccessible to individuals with limited motor control or\nlanguage abilities. Leveraging recent advances in brain-computer interfaces\n(BCIs) and generative models, we propose LoongX, a hands-free image editing\napproach driven by multimodal neurophysiological signals. LoongX utilizes\nstate-of-the-art diffusion models trained on a comprehensive dataset of 23,928\nimage editing pairs, each paired with synchronized electroencephalography\n(EEG), functional near-infrared spectroscopy (fNIRS), photoplethysmography\n(PPG), and head motion signals that capture user intent. To effectively address\nthe heterogeneity of these signals, LoongX integrates two key modules. The\ncross-scale state space (CS3) module encodes informative modality-specific\nfeatures. The dynamic gated fusion (DGF) module further aggregates these\nfeatures into a unified latent space, which is then aligned with edit semantics\nvia fine-tuning on a diffusion transformer (DiT). Additionally, we pre-train\nthe encoders using contrastive learning to align cognitive states with semantic\nintentions from embedded natural language. Extensive experiments demonstrate\nthat LoongX achieves performance comparable to text-driven methods (CLIP-I:\n0.6605 vs. 0.6558; DINO: 0.4812 vs. 0.4636) and outperforms them when neural\nsignals are combined with speech (CLIP-T: 0.2588 vs. 0.2549). These results\nhighlight the promise of neural-driven generative models in enabling\naccessible, intuitive image editing and open new directions for\ncognitive-driven creative technologies. Datasets and code will be released to\nsupport future work and foster progress in this emerging area.", "comment": "22 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.05397v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05294", "title": "zkSDK: Streamlining zero-knowledge proof development through automated trace-driven ZK-backend selection", "authors": ["William Law"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      undergrad thesis", "url": "http://arxiv.org/abs/2507.05294v1", "summary": "The rapid advancement of creating Zero-Knowledge (ZK) programs has led to the\ndevelopment of numerous tools designed to support developers. Popular options\ninclude being able to write in general-purpose programming languages like Rust\nfrom Risc Zero. Other languages exist like Circom, Lib-snark, and Cairo.\nHowever, developers entering the ZK space are faced with many different ZK\nbackends to choose from, leading to a steep learning curve and a fragmented\ndeveloper experience across different platforms. As a result, many developers\ntend to select a single ZK backend and remain tied to it. This thesis\nintroduces zkSDK, a modular framework that streamlines ZK application\ndevelopment by abstracting the backend complexities. At the core of zkSDK is\nPresto, a custom Python-like programming language that enables the profiling\nand analysis of a program to assess its computational workload intensity.\nCombined with user-defined criteria, zkSDK employs a dynamic selection\nalgorithm to automatically choose the optimal ZK-proving backend. Through an\nin-depth analysis and evaluation of real-world workloads, we demonstrate that\nzkSDK effectively selects the best-suited backend from a set of supported ZK\nbackends, delivering a seamless and user-friendly development experience.", "comment": "undergrad thesis", "pdf_url": "http://arxiv.org/pdf/2507.05294v1", "cate": "cs.SE", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.06141", "title": "Large Language Models Predict Human Well-being -- But Not Equally Everywhere", "authors": ["Pat Pataranutaporn", "Nattavudh Powdthavee", "Chayapatr Archiwaranguprok", "Pattie Maes"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06141v1", "summary": "Subjective well-being is a key metric in economic, medical, and policy\ndecision-making. As artificial intelligence provides scalable tools for\nmodelling human outcomes, it is crucial to evaluate whether large language\nmodels (LLMs) can accurately predict well-being across diverse global\npopulations. We evaluate four leading LLMs using data from 64,000 individuals\nin 64 countries. While LLMs capture broad correlates such as income and health,\ntheir predictive accuracy decreases in countries underrepresented in the\ntraining data, highlighting systematic biases rooted in global digital and\neconomic inequality. A pre-registered experiment demonstrates that LLMs rely on\nsurface-level linguistic similarity rather than conceptual understanding,\nleading to systematic misestimations in unfamiliar or resource-limited\nsettings. Injecting findings from underrepresented contexts substantially\nenhances performance, but a significant gap remains. These results highlight\nboth the promise and limitations of LLMs in predicting global well-being,\nunderscoring the importance of robust validation prior to their implementation\nacross these areas.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06141v1", "cate": "cs.HC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05536", "title": "Simulating Refractive Distortions and Weather-Induced Artifacts for Resource-Constrained Autonomous Perception", "authors": ["Moseli Mots'oehli", "Feimei Chen", "Hok Wai Chan", "Itumeleng Tlali", "Thulani Babeli", "Kyungim Baek", "Huaijin Chen"], "categories": ["cs.CV", "cs.ET", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This paper has been submitted to the ICCV 2025 Workshop on Computer Vision for Developing Countries (CV4DC) for review", "url": "http://arxiv.org/abs/2507.05536v1", "summary": "The scarcity of autonomous vehicle datasets from developing regions,\nparticularly across Africa's diverse urban, rural, and unpaved roads, remains a\nkey obstacle to robust perception in low-resource settings. We present a\nprocedural augmentation pipeline that enhances low-cost monocular dashcam\nfootage with realistic refractive distortions and weather-induced artifacts\ntailored to challenging African driving scenarios. Our refractive module\nsimulates optical effects from low-quality lenses and air turbulence, including\nlens distortion, Perlin noise, Thin-Plate Spline (TPS), and divergence-free\n(incompressible) warps. The weather module adds homogeneous fog, heterogeneous\nfog, and lens flare. To establish a benchmark, we provide baseline performance\nusing three image restoration models. To support perception research in\nunderrepresented African contexts, without costly data collection, labeling, or\nsimulation, we release our distortion toolkit, augmented dataset splits, and\nbenchmark results.", "comment": "This paper has been submitted to the ICCV 2025 Workshop on Computer\n  Vision for Developing Countries (CV4DC) for review", "pdf_url": "http://arxiv.org/pdf/2507.05536v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2402.14609", "title": "Learning Federated Neural Graph Databases for Answering Complex Queries from Distributed Knowledge Graphs", "authors": ["Qi Hu", "Weifeng Jiang", "Haoran Li", "Zihao Wang", "Jiaxin Bai", "Qianren Mao", "Yangqiu Song", "Lixin Fan", "Jianxin Li"], "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.DB"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by TMLR. Reviewed on OpenReview: this https URL", "url": "http://arxiv.org/abs/2402.14609v4", "summary": "The increasing demand for deep learning-based foundation models has\nhighlighted the importance of efficient data retrieval mechanisms. Neural graph\ndatabases (NGDBs) offer a compelling solution, leveraging neural spaces to\nstore and query graph-structured data, thereby enabling LLMs to access precise\nand contextually relevant information. However, current NGDBs are constrained\nto single-graph operation, limiting their capacity to reason across multiple,\ndistributed graphs. Furthermore, the lack of support for multi-source graph\ndata in existing NGDBs hinders their ability to capture the complexity and\ndiversity of real-world data. In many applications, data is distributed across\nmultiple sources, and the ability to reason across these sources is crucial for\nmaking informed decisions. This limitation is particularly problematic when\ndealing with sensitive graph data, as directly sharing and aggregating such\ndata poses significant privacy risks. As a result, many applications that rely\non NGDBs are forced to choose between compromising data privacy or sacrificing\nthe ability to reason across multiple graphs. To address these limitations, we\npropose to learn Federated Neural Graph DataBase (FedNGDB), a pioneering\nsystematic framework that empowers privacy-preserving reasoning over\nmulti-source graph data. FedNGDB leverages federated learning to\ncollaboratively learn graph representations across multiple sources, enriching\nrelationships between entities, and improving the overall quality of graph\ndata.", "comment": "Accepted by TMLR. Reviewed on OpenReview:\n  https://openreview.net/forum?id=3K1LRetR6Y", "pdf_url": "http://arxiv.org/pdf/2402.14609v4", "cate": "cs.LG", "date": "2024-02-22", "updated": "2025-07-08"}
{"id": "2507.05979", "title": "AURA-CVC: Autonomous Ultrasound-guided Robotic Assistance for Central Venous Catheterization", "authors": ["Deepak Raina", "Lidia Al-Zogbi", "Brian Teixeira", "Vivek Singh", "Ankur Kapoor", "Thorsten Fleiter", "Muyinatu A. Lediju Bell", "Vinciya Pandian", "Axel Krieger"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05979v1", "summary": "Purpose: Central venous catheterization (CVC) is a critical medical procedure\nfor vascular access, hemodynamic monitoring, and life-saving interventions. Its\nsuccess remains challenging due to the need for continuous ultrasound-guided\nvisualization of a target vessel and approaching needle, which is further\ncomplicated by anatomical variability and operator dependency. Errors in needle\nplacement can lead to life-threatening complications. While robotic systems\noffer a potential solution, achieving full autonomy remains challenging. In\nthis work, we propose an end-to-end robotic-ultrasound-guided CVC pipeline,\nfrom scan initialization to needle insertion. Methods: We introduce a\ndeep-learning model to identify clinically relevant anatomical landmarks from a\ndepth image of the patient's neck, obtained using RGB-D camera, to autonomously\ndefine the scanning region and paths. Then, a robot motion planning framework\nis proposed to scan, segment, reconstruct, and localize vessels (veins and\narteries), followed by the identification of the optimal insertion zone.\nFinally, a needle guidance module plans the insertion under ultrasound guidance\nwith operator's feedback. This pipeline was validated on a high-fidelity\ncommercial phantom across 10 simulated clinical scenarios. Results: The\nproposed pipeline achieved 10 out of 10 successful needle placements on the\nfirst attempt. Vessels were reconstructed with a mean error of 2.15\n\\textit{mm}, and autonomous needle insertion was performed with an error less\nthan or close to 1 \\textit{mm}. Conclusion: To our knowledge, this is the first\nrobotic CVC system demonstrated on a high-fidelity phantom with integrated\nplanning, scanning, and insertion. Experimental results show its potential for\nclinical translation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05979v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05651", "title": "City-Level Foreign Direct Investment Prediction with Tabular Learning on Judicial Data", "authors": ["Tianxing Wu", "Lizhe Cao", "Shuang Wang", "Jiming Wang", "Shutong Zhu", "Yerong Wu", "Yuqing Feng"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      9 pages, accepted by IJCAI 2025", "url": "http://arxiv.org/abs/2507.05651v1", "summary": "To advance the United Nations Sustainable Development Goal on promoting\nsustained, inclusive, and sustainable economic growth, foreign direct\ninvestment (FDI) plays a crucial role in catalyzing economic expansion and\nfostering innovation. Precise city-level FDI prediction is quite important for\nlocal government and is commonly studied based on economic data (e.g., GDP).\nHowever, such economic data could be prone to manipulation, making predictions\nless reliable. To address this issue, we try to leverage large-scale judicial\ndata which reflects judicial performance influencing local investment security\nand returns, for city-level FDI prediction. Based on this, we first build an\nindex system for the evaluation of judicial performance over twelve million\npublicly available adjudication documents according to which a tabular dataset\nis reformulated. We then propose a new Tabular Learning method on Judicial Data\n(TLJD) for city-level FDI prediction. TLJD integrates row data and column data\nin our built tabular dataset for judicial performance indicator encoding, and\nutilizes a mixture of experts model to adjust the weights of different\nindicators considering regional variations. To validate the effectiveness of\nTLJD, we design cross-city and cross-time tasks for city-level FDI predictions.\nExtensive experiments on both tasks demonstrate the superiority of TLJD (reach\nto at least 0.92 R2) over the other ten state-of-the-art baselines in different\nevaluation metrics.", "comment": "9 pages, accepted by IJCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.05651v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05416", "title": "EmissionNet: Air Quality Pollution Forecasting for Agriculture", "authors": ["Prady Saligram", "Tanvir Bhathal"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05416v1", "summary": "Air pollution from agricultural emissions is a significant yet often\noverlooked contributor to environmental and public health challenges.\nTraditional air quality forecasting models rely on physics-based approaches,\nwhich struggle to capture complex, nonlinear pollutant interactions. In this\nwork, we explore forecasting N$_2$O agricultural emissions through evaluating\npopular architectures, and proposing two novel deep learning architectures,\nEmissionNet (ENV) and EmissionNet-Transformer (ENT). These models leverage\nconvolutional and transformer-based architectures to extract spatial-temporal\ndependencies from high-resolution emissions data", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05416v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05419", "title": "Motion Generation: A Survey of Generative Approaches and Benchmarks", "authors": ["Aliasghar Khani", "Arianna Rampini", "Bruno Roy", "Larasika Nadela", "Noa Kaplan", "Evan Atherton", "Derek Cheung", "Jacky Bibliowicz"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05419v1", "summary": "Motion generation, the task of synthesizing realistic motion sequences from\nvarious conditioning inputs, has become a central problem in computer vision,\ncomputer graphics, and robotics, with applications ranging from animation and\nvirtual agents to human-robot interaction. As the field has rapidly progressed\nwith the introduction of diverse modeling paradigms including GANs,\nautoencoders, autoregressive models, and diffusion-based techniques, each\napproach brings its own advantages and limitations. This growing diversity has\ncreated a need for a comprehensive and structured review that specifically\nexamines recent developments from the perspective of the generative approach\nemployed.\n  In this survey, we provide an in-depth categorization of motion generation\nmethods based on their underlying generative strategies. Our main focus is on\npapers published in top-tier venues since 2023, reflecting the most recent\nadvancements in the field. In addition, we analyze architectural principles,\nconditioning mechanisms, and generation settings, and compile a detailed\noverview of the evaluation metrics and datasets used across the literature. Our\nobjective is to enable clearer comparisons and identify open challenges,\nthereby offering a timely and foundational reference for researchers and\npractitioners navigating the rapidly evolving landscape of motion generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05419v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05307", "title": "ASSURE: Metamorphic Testing for AI-powered Browser Extensions", "authors": ["Xuanqi Gao", "Juan Zhai", "Shiqing Ma", "Siyi Xie", "Chao Shen"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05307v1", "summary": "The integration of Large Language Models (LLMs) into browser extensions has\nrevolutionized web browsing, enabling sophisticated functionalities like\ncontent summarization, intelligent translation, and context-aware writing\nassistance. However, these AI-powered extensions introduce unprecedented\nchallenges in testing and reliability assurance. Traditional browser extension\ntesting approaches fail to address the non-deterministic behavior,\ncontext-sensitivity, and complex web environment integration inherent to\nLLM-powered extensions. Similarly, existing LLM testing methodologies operate\nin isolation from browser-specific contexts, creating a critical gap in\neffective evaluation frameworks. To bridge this gap, we present ASSURE, a\nmodular automated testing framework specifically designed for AI-powered\nbrowser extensions. ASSURE comprises three principal components: (1) a modular\ntest case generation engine that supports plugin-based extension of testing\nscenarios, (2) an automated execution framework that orchestrates the complex\ninteractions between web content, extension processing, and AI model behavior,\nand (3) a configurable validation pipeline that systematically evaluates\nbehavioral consistency and security invariants rather than relying on exact\noutput matching. Our evaluation across six widely-used AI browser extensions\ndemonstrates ASSURE's effectiveness, identifying 531 distinct issues spanning\nsecurity vulnerabilities, metamorphic relation violations, and content\nalignment problems. ASSURE achieves 6.4x improved testing throughput compared\nto manual approaches, detecting critical security vulnerabilities within 12.4\nminutes on average. This efficiency makes ASSURE practical for integration into\ndevelopment pipelines, offering a comprehensive solution to the unique\nchallenges of testing AI-powered browser extensions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05307v1", "cate": "cs.SE", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06202", "title": "V(is)owel: An Interactive Vowel Chart to Understand What Makes Visual Pronunciation Effective in Second Language Learning", "authors": ["Charlotte Kiesel", "Dipayan Mukherjee", "Mark Hasegawa-Johnson", "Karrie Karahalios"], "categories": ["cs.HC", "K.3.1"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06202v1", "summary": "Visual feedback speeds up learners' improvement of pronunciation in a second\nlanguage. The visual combined with audio allows speakers to see sounds and\ndifferences in pronunciation that they are unable to hear. Prior studies have\ntested different visual methods for improving pronunciation, however, we do not\nhave conclusive understanding of what aspects of the visualizations contributed\nto improvements. Based on previous work, we created V(is)owel, an interactive\nvowel chart. Vowel charts provide actionable feedback by directly mapping\nphysical tongue movement onto a chart. We compared V(is)owel with an\nauditory-only method to explore how learners parse visual and auditory feedback\nto understand how and why visual feedback is effective for pronunciation\nimprovement. The findings suggest that designers should include explicit\nanatomical feedback that directly maps onto physical movement for phonetically\nuntrained learners. Furthermore, visual feedback has the potential to motivate\nmore practice since all eight of the participants cited using the visuals as a\ngoal with V(is)owel versus relying on their own judgment with audio alone.\nTheir statements are backed up by all participants practicing words with\nV(is)owel more than with audio-only. Our results indicate that V(is)owel is\neffective at providing actionable feedback, demonstrating the potential of\nvisual feedback methods in second language learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06202v1", "cate": "cs.HC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06034", "title": "The most influential philosophers in Wikipedia: a multicultural analysis", "authors": ["Guillaume Rollin", "José Lages"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      23 pages, 5 figures, 4 tables", "url": "http://arxiv.org/abs/2507.06034v1", "summary": "We explore the influence and interconnectivity of philosophical thinkers\nwithin the Wikipedia knowledge network. Using a dataset of 237 articles\ndedicated to philosophers across nine different language editions (Arabic,\nChinese, English, French, German, Japanese, Portuguese, Russian, and Spanish),\nwe apply the PageRank and CheiRank algorithms to analyze their relative ranking\nand influence in each linguistic context. Furthermore, we compare our results\nwith entries from the Stanford Encyclopedia of Philosophy and the Internet\nEncyclopedia of Philosophy, providing insight into the differences between\ngeneral knowledge networks like Wikipedia and specialized philosophical\ndatabases. A key focus of our analysis is the sub-network of 21 presocratic\nphilosophers, grouped into four traditional schools: Italic (Pythagorean +\nEleatic), Ionian, Abderian (Atomist), and Sophist. Using the reduced Google\nmatrix method, we uncover both direct and hidden links between these early\nthinkers, offering new perspectives on their intellectual relationships and\ninfluence within the Western philosophical tradition.", "comment": "23 pages, 5 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.06034v1", "cate": "cs.SI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05813", "title": "Adaptive Communication Through Exploiting RIS, SSK, and CIM for Improved Reliability and Efficiency", "authors": ["Ferhat Bayar", "Onur Salan", "Erdogan Aydin", "Haci Ilhan"], "categories": ["cs.IT", "cs.ET", "cs.MS", "cs.PF", "cs.SY", "eess.SY", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05813v1", "summary": "In this paper, we present a novel communication system model that integrates\nreconfigurable intelligent surfaces (RIS), spatial shift keying (SSK), and code\nindex modulation (CIM) based on Hadamard coding called RIS based transmit\nSSK-CIM (RIS-CIM-TSSK). By leveraging RIS, the system adapts rapidly to dynamic\nenvironments, enhancing error rates and overall reliability. SSK facilitates\nthe transmission of additional passive information while eliminating the need\nfor multiple radio frequency (RF) chains, thereby reducing complexity. CIM\nenhances passive information transmission through frequency domain spreading,\nwhich may increase signal obfuscation. This proposed scheme not only improves\nenergy efficiency but also offers a robust solution for reliable communication\nin modern wireless networks, paving the way for smarter and more adaptable\nimplementations. We consider a suboptimal, low-complexity detector for the\nproposed scheme and also address the blind case for phase adjustment of the\nRIS. Finally, we present the simulation results for the proposed system model\nacross various configurations, including different numbers of receive and\ntransmit antennas, varying reflecting elements of the RIS, and different code\nlengths.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05813v1", "cate": "cs.IT", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2502.05307", "title": "Training Set Reconstruction from Differentially Private Forests: How Effective is DP?", "authors": ["Alice Gorgé", "Julien Ferry", "Sébastien Gambs", "Thibaut Vidal"], "categories": ["cs.LG", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.05307v2", "summary": "Recent research has shown that machine learning models are vulnerable to\nprivacy attacks targeting their training data. To mitigate these risks,\ndifferential privacy (DP) has become a widely adopted countermeasure, as it\noffers rigorous privacy protection. In this paper, we introduce a\nreconstruction attack targeting state-of-the-art $\\varepsilon$-DP random\nforests. By leveraging a constraint programming model that incorporates\nknowledge of the forest's structure and DP mechanism characteristics, our\napproach formally reconstructs the most likely dataset that could have produced\na given forest. Through extensive computational experiments, we examine the\ninterplay between model utility, privacy guarantees and reconstruction accuracy\nacross various configurations. Our results reveal that random forests trained\nwith meaningful DP guarantees can still leak portions of their training data.\nSpecifically, while DP reduces the success of reconstruction attacks, the only\nforests fully robust to our attack exhibit predictive performance no better\nthan a constant classifier. Building on these insights, we provide practical\nrecommendations for the construction of DP random forests that are more\nresilient to reconstruction attacks and maintain non-trivial predictive\nperformance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.05307v2", "cate": "cs.LG", "date": "2025-02-07", "updated": "2025-07-08"}
{"id": "2507.05985", "title": "Robust Speech-Workload Estimation for Intelligent Human-Robot Systems", "authors": ["Julian Fortune", "Julie A. Adams", "Jamison Heard"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.05985v1", "summary": "Demanding task environments (e.g., supervising a remotely piloted aircraft)\nrequire performing tasks quickly and accurately; however, periods of low and\nhigh operator workload can decrease task performance. Intelligent modulation of\nthe system's demands and interaction modality in response to changes in\noperator workload state may increase performance by avoiding undesirable\nworkload states. This system requires real-time estimation of each workload\ncomponent (i.e., cognitive, physical, visual, speech, and auditory) to adapt\nthe correct modality. Existing workload systems estimate multiple workload\ncomponents post-hoc, but few estimate speech workload, or function in\nreal-time. An algorithm to estimate speech workload and mitigate undesirable\nworkload states in real-time is presented. An analysis of the algorithm's\naccuracy is presented, along with the results demonstrating the algorithm's\ngeneralizability across individuals and human-machine teaming paradigms.\nReal-time speech workload estimation is a crucial element towards developing\nadaptive human-machine systems.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.05985v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05716", "title": "Divergent Realities: A Comparative Analysis of Human Expert vs. Artificial Intelligence Based Generation and Evaluation of Treatment Plans in Dermatology", "authors": ["Dipayan Sengupta", "Saumya Panda"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      13 pages, 3 tables", "url": "http://arxiv.org/abs/2507.05716v1", "summary": "Background: Evaluating AI-generated treatment plans is a key challenge as AI\nexpands beyond diagnostics, especially with new reasoning models. This study\ncompares plans from human experts and two AI models (a generalist and a\nreasoner), assessed by both human peers and a superior AI judge.\n  Methods: Ten dermatologists, a generalist AI (GPT-4o), and a reasoning AI\n(o3) generated treatment plans for five complex dermatology cases. The\nanonymized, normalized plans were scored in two phases: 1) by the ten human\nexperts, and 2) by a superior AI judge (Gemini 2.5 Pro) using an identical\nrubric.\n  Results: A profound 'evaluator effect' was observed. Human experts scored\npeer-generated plans significantly higher than AI plans (mean 7.62 vs. 7.16;\np=0.0313), ranking GPT-4o 6th (mean 7.38) and the reasoning model, o3, 11th\n(mean 6.97). Conversely, the AI judge produced a complete inversion, scoring AI\nplans significantly higher than human plans (mean 7.75 vs. 6.79; p=0.0313). It\nranked o3 1st (mean 8.20) and GPT-4o 2nd, placing all human experts lower.\n  Conclusions: The perceived quality of a clinical plan is fundamentally\ndependent on the evaluator's nature. An advanced reasoning AI, ranked poorly by\nhuman experts, was judged as superior by a sophisticated AI, revealing a deep\ngap between experience-based clinical heuristics and data-driven algorithmic\nlogic. This paradox presents a critical challenge for AI integration,\nsuggesting the future requires synergistic, explainable human-AI systems that\nbridge this reasoning gap to augment clinical care.", "comment": "13 pages, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.05716v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05441", "title": "Adversarial Machine Learning Attacks on Financial Reporting via Maximum Violated Multi-Objective Attack", "authors": ["Edward Raff", "Karen Kukla", "Michel Benaroch", "Joseph Comprix"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      KDD Workshop on Machine Learning in Finance", "url": "http://arxiv.org/abs/2507.05441v1", "summary": "Bad actors, primarily distressed firms, have the incentive and desire to\nmanipulate their financial reports to hide their distress and derive personal\ngains. As attackers, these firms are motivated by potentially millions of\ndollars and the availability of many publicly disclosed and used financial\nmodeling frameworks. Existing attack methods do not work on this data due to\nanti-correlated objectives that must both be satisfied for the attacker to\nsucceed. We introduce Maximum Violated Multi-Objective (MVMO) attacks that\nadapt the attacker's search direction to find $20\\times$ more satisfying\nattacks compared to standard attacks. The result is that in $\\approx50\\%$ of\ncases, a company could inflate their earnings by 100-200%, while simultaneously\nreducing their fraud scores by 15%. By working with lawyers and professional\naccountants, we ensure our threat model is realistic to how such frauds are\nperformed in practice.", "comment": "KDD Workshop on Machine Learning in Finance", "pdf_url": "http://arxiv.org/pdf/2507.05441v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05426", "title": "Mastering Regional 3DGS: Locating, Initializing, and Editing with Diverse 2D Priors", "authors": ["Lanqing Guo", "Yufei Wang", "Hezhen Hu", "Yan Zheng", "Yeying Jin", "Siyu Huang", "Zhangyang Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05426v1", "summary": "Many 3D scene editing tasks focus on modifying local regions rather than the\nentire scene, except for some global applications like style transfer, and in\nthe context of 3D Gaussian Splatting (3DGS), where scenes are represented by a\nseries of Gaussians, this structure allows for precise regional edits, offering\nenhanced control over specific areas of the scene; however, the challenge lies\nin the fact that 3D semantic parsing often underperforms compared to its 2D\ncounterpart, making targeted manipulations within 3D spaces more difficult and\nlimiting the fidelity of edits, which we address by leveraging 2D diffusion\nediting to accurately identify modification regions in each view, followed by\ninverse rendering for 3D localization, then refining the frontal view and\ninitializing a coarse 3DGS with consistent views and approximate shapes derived\nfrom depth maps predicted by a 2D foundation model, thereby supporting an\niterative, view-consistent editing process that gradually enhances structural\ndetails and textures to ensure coherence across perspectives. Experiments\ndemonstrate that our method achieves state-of-the-art performance while\ndelivering up to a $4\\times$ speedup, providing a more efficient and effective\napproach to 3D scene local editing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05426v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05316", "title": "OASBuilder: Generating OpenAPI Specifications from Online API Documentation with Large Language Models", "authors": ["Koren Lazar", "Matan Vetzler", "Kiran Kate", "Jason Tsay", "David Boaz Himanshu Gupta", "Avraham Shinnar", "Rohith D Vallam", "David Amid Esther Goldbraich", "Guy Uziel", "Jim Laredo", "Ateret Anaby Tavor"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05316v1", "summary": "AI agents and business automation tools interacting with external web\nservices require standardized, machine-readable information about their APIs in\nthe form of API specifications. However, the information about APIs available\nonline is often presented as unstructured, free-form HTML documentation,\nrequiring external users to spend significant time manually converting it into\na structured format. To address this, we introduce OASBuilder, a novel\nframework that transforms long and diverse API documentation pages into\nconsistent, machine-readable API specifications. This is achieved through a\ncarefully crafted pipeline that integrates large language models and rule-based\nalgorithms which are guided by domain knowledge of the structure of\ndocumentation webpages. Our experiments demonstrate that OASBuilder generalizes\nwell across hundreds of APIs, and produces valid OpenAPI specifications that\nencapsulate most of the information from the original documentation. OASBuilder\nhas been successfully implemented in an enterprise environment, saving\nthousands of hours of manual effort and making hundreds of complex enterprise\nAPIs accessible as tools for LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05316v1", "cate": "cs.SE", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2505.10426", "title": "Formalising Human-in-the-Loop: Computational Reductions, Failure Modes, and Legal-Moral Responsibility", "authors": ["Maurice Chiodo", "Dennis Müller", "Paul Siewert", "Jean-Luc Wetherall", "Zoya Yasmine", "John Burden"], "categories": ["cs.CY", "cs.AI", "cs.HC", "math.HO", "F.1; H.1.2; I.2.0; K.4.1"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      12 pages. Keywords: Human-in-the-loop, Artificial Intelligence, Oracle Machines, Liability, AI Safety, AI Regulations, Turing Reduction", "url": "http://arxiv.org/abs/2505.10426v1", "summary": "The legal compliance and safety of different Human-in-the-loop (HITL) setups\nfor AI can vary greatly. This manuscript aims to identify new ways of choosing\nbetween such setups, and shows that there is an unavoidable trade-off between\nthe attribution of legal responsibility and the technical explainability of AI.\nWe begin by using the notion of oracle machines from computability theory to\nformalise different HITL setups, distinguishing between trivial human\nmonitoring, single endpoint human action, and highly involved interaction\nbetween the human(s) and the AI. These correspond to total functions, many-one\nreductions, and Turing reductions respectively. A taxonomy categorising HITL\nfailure modes is then presented, highlighting the limitations on what any HITL\nsetup can actually achieve. Our approach then identifies oversights from UK and\nEU legal frameworks, which focus on certain HITL setups which may not always\nachieve the desired ethical, legal, and sociotechnical outcomes. We suggest\nareas where the law should recognise the effectiveness of different HITL setups\nand assign responsibility in these contexts, avoiding unnecessary and\nunproductive human \"scapegoating\". Overall, we show how HITL setups involve\nmany technical design decisions, and can be prone to failures which are often\nout of the humans' control. This opens up a new analytic perspective on the\nchallenges arising in the creation of HITL setups, helping inform AI developers\nand lawmakers on designing HITL to better achieve their desired outcomes.", "comment": "12 pages. Keywords: Human-in-the-loop, Artificial Intelligence,\n  Oracle Machines, Liability, AI Safety, AI Regulations, Turing Reduction", "pdf_url": "http://arxiv.org/pdf/2505.10426v1", "cate": "cs.CY", "date": "2025-05-15", "updated": "2025-05-15"}
{"id": "2507.06086", "title": "QuHE: Optimizing Utility-Cost in Quantum Key Distribution and Homomorphic Encryption Enabled Secure Edge Computing Networks", "authors": ["Liangxin Qian", "Yang Li", "Jun Zhao"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      IEEE International Conference on Distributed Computing Systems (ICDCS) 2025. Acceptance rate: 19.7%", "url": "http://arxiv.org/abs/2507.06086v1", "summary": "Ensuring secure and efficient data processing in mobile edge computing (MEC)\nsystems is a critical challenge. While quantum key distribution (QKD) offers\nunconditionally secure key exchange and homomorphic encryption (HE) enables\nprivacy-preserving data processing, existing research fails to address the\ncomprehensive trade-offs among QKD utility, HE security, and system costs. This\npaper proposes a novel framework integrating QKD, transciphering, and HE for\nsecure and efficient MEC. QKD distributes symmetric keys, transciphering\nbridges symmetric encryption, and HE processes encrypted data at the server. We\nformulate an optimization problem balancing QKD utility, HE security,\nprocessing and wireless transmission costs. However, the formulated\noptimization is non-convex and NPhard. To solve it efficiently, we propose the\nQuantum-enhanced Homomorphic Encryption resource allocation (QuHE) algorithm.\nTheoretical analysis proves the proposed QuHE algorithm's convergence and\noptimality, and simulations demonstrate its effectiveness across multiple\nperformance metrics.", "comment": "IEEE International Conference on Distributed Computing Systems\n  (ICDCS) 2025. Acceptance rate: 19.7%", "pdf_url": "http://arxiv.org/pdf/2507.06086v1", "cate": "cs.SI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2310.16909", "title": "Neuromorphic weighted sums with magnetic skyrmions", "authors": ["Tristan da Câmara Santa Clara Gomes", "Yanis Sassi", "Dédalo Sanz-Hernández", "Sachin Krishnia", "Sophie Collin", "Marie-Blandine Martin", "Pierre Seneor", "Vincent Cros", "Julie Grollier", "Nicolas Reyren"], "categories": ["cs.ET", "cond-mat.mtrl-sci"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "Comments:      13 pages, 5 figures", "url": "http://arxiv.org/abs/2310.16909v2", "summary": "Integrating magnetic skyrmions into neuromorphic computing could help improve\nhardware efficiency and computational power. However, developing a scalable\nimplementation of the weighted sum of neuron signals - a core operation in\nneural networks - has remained a challenge. Here, we show that weighted sum\noperations can be performed in a compact, biologically-inspired manner by using\nthe non-volatile and particle-like characteristics of magnetic skyrmions that\nmake them easily countable and summable. The skyrmions are electrically\ngenerated in numbers proportional to an input with an efficiency given by a\nnon-volatile weight. The chiral particles are then directed using localized\ncurrent injections to a location where their presence is quantified through\nnon-perturbative electrical measurements. Our experimental demonstration, which\ncurrently has two inputs, can be scaled to accommodate multiple inputs and\noutputs using a crossbar array design, potentially nearing the energy\nefficiency observed in biological systems.", "comment": "13 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2310.16909v2", "cate": "cs.ET", "date": "2023-10-25", "updated": "2025-07-08"}
{"id": "2502.05325", "title": "From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks", "authors": ["Awa Khouna", "Julien Ferry", "Thibaut Vidal"], "categories": ["cs.LG", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.05325v2", "summary": "The advent of Machine Learning as a Service (MLaaS) has heightened the\ntrade-off between model explainability and security. In particular,\nexplainability techniques, such as counterfactual explanations, inadvertently\nincrease the risk of model extraction attacks, enabling unauthorized\nreplication of proprietary models. In this paper, we formalize and characterize\nthe risks and inherent complexity of model reconstruction, focusing on the\n\"oracle'' queries required for faithfully inferring the underlying prediction\nfunction. We present the first formal analysis of model extraction attacks\nthrough the lens of competitive analysis, establishing a foundational framework\nto evaluate their efficiency. Focusing on models based on additive decision\ntrees (e.g., decision trees, gradient boosting, and random forests), we\nintroduce novel reconstruction algorithms that achieve provably perfect\nfidelity while demonstrating strong anytime performance. Our framework provides\ntheoretical bounds on the query complexity for extracting tree-based model,\noffering new insights into the security vulnerabilities of their deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.05325v2", "cate": "cs.LG", "date": "2025-02-07", "updated": "2025-07-08"}
{"id": "2507.06053", "title": "SCCRUB: Surface Cleaning Compliant Robot Utilizing Bristles", "authors": ["Jakub F. Kowalewski", "Keeyon Hajjafar", "Alyssa Ugent", "Jeffrey Ian Lipton"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06053v1", "summary": "Scrubbing surfaces is a physically demanding and time-intensive task.\nRemoving adhered contamination requires substantial friction generated through\npressure and torque or high lateral forces. Rigid robotic manipulators, while\ncapable of exerting these forces, are usually confined to structured\nenvironments isolated from humans due to safety risks. In contrast, soft robot\narms can safely work around humans and adapt to environmental uncertainty, but\ntypically struggle to transmit the continuous torques or lateral forces\nnecessary for scrubbing. Here, we demonstrate a soft robotic arm scrubbing\nadhered residues using torque and pressure, a task traditionally challenging\nfor soft robots. We train a neural network to learn the arm's inverse\nkinematics and elasticity, which enables open-loop force and position control.\nUsing this learned model, the robot successfully scrubbed burnt food residue\nfrom a plate and sticky fruit preserve from a toilet seat, removing an average\nof 99.7% of contamination. This work demonstrates how soft robots, capable of\nexerting continuous torque, can effectively and safely scrub challenging\ncontamination from surfaces.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06053v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05755", "title": "An autonomous agent for auditing and improving the reliability of clinical AI models", "authors": ["Lukas Kuhn", "Florian Buettner"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05755v1", "summary": "The deployment of AI models in clinical practice faces a critical challenge:\nmodels achieving expert-level performance on benchmarks can fail\ncatastrophically when confronted with real-world variations in medical imaging.\nMinor shifts in scanner hardware, lighting or demographics can erode accuracy,\nbut currently reliability auditing to identify such catastrophic failure cases\nbefore deployment is a bespoke and time-consuming process. Practitioners lack\naccessible and interpretable tools to expose and repair hidden failure modes.\nHere we introduce ModelAuditor, a self-reflective agent that converses with\nusers, selects task-specific metrics, and simulates context-dependent,\nclinically relevant distribution shifts. ModelAuditor then generates\ninterpretable reports explaining how much performance likely degrades during\ndeployment, discussing specific likely failure modes and identifying root\ncauses and mitigation strategies. Our comprehensive evaluation across three\nreal-world clinical scenarios - inter-institutional variation in\nhistopathology, demographic shifts in dermatology, and equipment heterogeneity\nin chest radiography - demonstrates that ModelAuditor is able correctly\nidentify context-specific failure modes of state-of-the-art models such as the\nestablished SIIM-ISIC melanoma classifier. Its targeted recommendations recover\n15-25% of performance lost under real-world distribution shift, substantially\noutperforming both baseline models and state-of-the-art augmentation methods.\nThese improvements are achieved through a multi-agent architecture and execute\non consumer hardware in under 10 minutes, costing less than US$0.50 per audit.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05755v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05465", "title": "2048: Reinforcement Learning in a Delayed Reward Environment", "authors": ["Prady Saligram", "Tanvir Bhathal", "Robby Manihani"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05465v1", "summary": "Delayed and sparse rewards present a fundamental obstacle for\nreinforcement-learning (RL) agents, which struggle to assign credit for actions\nwhose benefits emerge many steps later. The sliding-tile game 2048 epitomizes\nthis challenge: although frequent small score changes yield immediate feedback,\nthey often mislead agents into locally optimal but globally suboptimal\nstrategies. In this work, we introduce a unified, distributional multi-step RL\nframework designed to directly optimize long-horizon performance. Using the\nopen source Gym-2048 environment we develop and compare four agent variants:\nstandard DQN, PPO, QR-DQN (Quantile Regression DQN), and a novel Horizon-DQN\n(H-DQN) that integrates distributional learning, dueling architectures, noisy\nnetworks, prioritized replay, and more. Empirical evaluation reveals a clear\nhierarchy in effectiveness: max episode scores improve from 3.988K (DQN) to\n5.756K (PPO), 8.66K (QR-DQN), and 18.21K (H-DQN), with H-DQN reaching the 2048\ntile. Upon scaling H-DQN it reaches a max score 41.828K and a 4096 tile. These\nresults demonstrate that distributional, multi-step targets substantially\nenhance performance in sparse-reward domains, and they suggest promising\navenues for further gains through model-based planning and curriculum learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05465v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05427", "title": "OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts", "authors": ["Shiting Xiao", "Rishabh Kabra", "Yuhang Li", "Donghyun Lee", "Joao Carreira", "Priyadarshini Panda"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05427v1", "summary": "The ability to segment objects based on open-ended language prompts remains a\ncritical challenge, requiring models to ground textual semantics into precise\nspatial masks while handling diverse and unseen categories. We present\nOpenWorldSAM, a framework that extends the prompt-driven Segment Anything Model\nv2 (SAM2) to open-vocabulary scenarios by integrating multi-modal embeddings\nextracted from a lightweight vision-language model (VLM). Our approach is\nguided by four key principles: i) Unified prompting: OpenWorldSAM supports a\ndiverse range of prompts, including category-level and sentence-level language\ndescriptions, providing a flexible interface for various segmentation tasks.\nii) Efficiency: By freezing the pre-trained components of SAM2 and the VLM, we\ntrain only 4.5 million parameters on the COCO-stuff dataset, achieving\nremarkable resource efficiency. iii) Instance Awareness: We enhance the model's\nspatial understanding through novel positional tie-breaker embeddings and\ncross-attention layers, enabling effective segmentation of multiple instances.\niv) Generalization: OpenWorldSAM exhibits strong zero-shot capabilities,\ngeneralizing well on unseen categories and an open vocabulary of concepts\nwithout additional training. Extensive experiments demonstrate that\nOpenWorldSAM achieves state-of-the-art performance in open-vocabulary semantic,\ninstance, and panoptic segmentation across multiple benchmarks, including\nADE20k, PASCAL, ScanNet, and SUN-RGBD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05427v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05325", "title": "Exploring Empathy in Software Engineering: Insights from a Grey Literature Analysis of Practitioners' Perspectives", "authors": ["Lidiany Cerqueira", "João Pedro Bastos", "Danilo Neves", "Glauco Carneiro", "Rodrigo Spínola", "Sávio Freire", "José Amancio Macedo Santos", "Manoel Mendonça"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      This is the author's version of the paper accepted for publication in ACM Transactions on Software Engineering and Methodology. The final version will be available via the ACM Digital Library. The HTML preview may not render some formatting correctly. Please refer to the PDF version for accurate presentation", "url": "http://arxiv.org/abs/2507.05325v1", "summary": "Context. Empathy, a key social skill, is essential for communication and\ncollaboration in SE but remains an under-researched topic. Aims. This study\ninvestigates empathy in SE from practitioners' perspectives, aiming to\ncharacterize its meaning, identify barriers, discuss practices to overcome\nthem, and explore its effects. Method. A qualitative content analysis was\nconducted on 55 web articles from DEV and Medium, two communities widely used\nby practitioners. To strengthen our findings, we conducted a follow-up survey\nwith empathy experts. Results. The study proposes a definition of empathy in\nSE, identifies barriers such as toxic culture and excessive technical focus,\npractices to foster empathy in teams, and outcomes, including improved\ncollaboration, communication, and reduced anxiety, frustration, and stress.\nThese findings are synthesized into a conceptual framework. Conclusion. Survey\nresults indicate the framework is clear, valuable, and raises empathy\nawareness, with suggestions for improvements and integration into training.\nThis study paves the way for improving team dynamics by addressing barriers and\noffering strategies to cultivate empathy. Future work will explore empathy's\nbroader implications in SE practice.", "comment": "This is the author's version of the paper accepted for publication in\n  ACM Transactions on Software Engineering and Methodology. The final version\n  will be available via the ACM Digital Library. The HTML preview may not\n  render some formatting correctly. Please refer to the PDF version for\n  accurate presentation", "pdf_url": "http://arxiv.org/pdf/2507.05325v1", "cate": "cs.SE", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06164", "title": "Critical Nodes Identification in Complex Networks: A Survey", "authors": ["Duxin Chen", "Jiawen Chen", "Xiaoyu Zhang", "Qinghan Jia", "Xiaolu Liu", "Ye Sun", "Linyuan Lv", "Wenwu Yu"], "categories": ["cs.SI", "cs.AI", "physics.app-ph"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06164v1", "summary": "Complex networks have become essential tools for understanding diverse\nphenomena in social systems, traffic systems, biomolecular systems, and\nfinancial systems. Identifying critical nodes is a central theme in\ncontemporary research, serving as a vital bridge between theoretical\nfoundations and practical applications. Nevertheless, the intrinsic complexity\nand structural heterogeneity characterizing real-world networks, with\nparticular emphasis on dynamic and higher-order networks, present substantial\nobstacles to the development of universal frameworks for critical node\nidentification. This paper provides a comprehensive review of critical node\nidentification techniques, categorizing them into seven main classes:\ncentrality, critical nodes deletion problem, influence maximization, network\ncontrol, artificial intelligence, higher-order and dynamic methods. Our review\nbridges the gaps in existing surveys by systematically classifying methods\nbased on their methodological foundations and practical implications, and by\nhighlighting their strengths, limitations, and applicability across different\nnetwork types. Our work enhances the understanding of critical node research by\nidentifying key challenges, such as algorithmic universality, real-time\nevaluation in dynamic networks, analysis of higher-order structures, and\ncomputational efficiency in large-scale networks. The structured synthesis\nconsolidates current progress and highlights open questions, particularly in\nmodeling temporal dynamics, advancing efficient algorithms, integrating machine\nlearning approaches, and developing scalable and interpretable metrics for\ncomplex systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06164v1", "cate": "cs.SI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2503.04564", "title": "Fundamental Limits of Hierarchical Secure Aggregation with Cyclic User Association", "authors": ["Xiang Zhang", "Zhou Li", "Kai Wan", "Hua Sun", "Mingyue Ji", "Giuseppe Caire"], "categories": ["cs.IT", "cs.AI", "cs.CR", "cs.DC", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Manuscript submitted to IEEE Transactions on Information Theory for review", "url": "http://arxiv.org/abs/2503.04564v5", "summary": "Secure aggregation is motivated by federated learning (FL) where a cloud\nserver aims to compute an averaged model (i.e., weights of deep neural\nnetworks) of the locally-trained models of numerous clients, while adhering to\ndata security requirements. Hierarchical secure aggregation (HSA) extends this\nconcept to a three-layer hierarchical network, where clustered users\ncommunicate with the server through an intermediate layer of relays. In HSA,\nbeyond conventional server security, relay security is also enforced to ensure\nthat the relays remain oblivious to the users' inputs (an abstraction of the\nlocal models in FL). Existing study on HSA assumes that each user is associated\nwith only one relay, limiting opportunities for coding across inter-cluster\nusers to achieve efficient communication and key generation. In this paper, we\nconsider HSA with a cyclic association pattern where each user is connected to\n$B$ consecutive relays in a wrap-around manner. We propose an efficient\naggregation scheme which includes a message design for the inputs inspired by\ngradient coding-a well-known technique for efficient communication in\ndistributed computing-along with a highly non-trivial security key design. We\nalso derive novel converse bounds on the minimum achievable communication and\nkey rates using information-theoretic arguments.", "comment": "Manuscript submitted to IEEE Transactions on Information Theory for\n  review", "pdf_url": "http://arxiv.org/pdf/2503.04564v5", "cate": "cs.IT", "date": "2025-03-06", "updated": "2025-07-08"}
{"id": "2507.05765", "title": "Real-time monitoring of the SoH of lithium-ion batteries", "authors": ["Bruno Jammes", "Edgar Hernando Sepúlveda-Oviedo", "Corinne Alonso"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      in French language, Symposium de G{é}nie {É}lectrique SGE 2025, Jul 2025, Toulouse, France", "url": "http://arxiv.org/abs/2507.05765v1", "summary": "Real-time monitoring of the state of health (SoH) of batteries remains a\nmajor challenge, particularly in microgrids where operational constraints limit\nthe use of traditional methods. As part of the 4BLife project, we propose an\ninnovative method based on the analysis of a discharge pulse at the end of the\ncharge phase. The parameters of the equivalent electrical model describing the\nvoltage evolution across the battery terminals during this current pulse are\nthen used to estimate the SoH. Based on the experimental data acquired so far,\nthe initial results demonstrate the relevance of the proposed approach. After\ntraining using the parameters of two batteries with a capacity degradation of\naround 85%, we successfully predicted the degradation of two other batteries,\ncycled down to approximately 90% SoH, with a mean absolute error of around 1%\nin the worst case, and an explainability score of the estimator close to 0.9.\nIf these performances are confirmed, this method can be easily integrated into\nbattery management systems (BMS) and paves the way for optimized battery\nmanagement under continuous operation.", "comment": "in French language, Symposium de G{\\'e}nie {\\'E}lectrique SGE 2025,\n  Jul 2025, Toulouse, France", "pdf_url": "http://arxiv.org/pdf/2507.05765v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05477", "title": "Epistemically-guided forward-backward exploration", "authors": ["Núria Armengol Urpí", "Marin Vlastelica", "Georg Martius", "Stelian Coros"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05477v1", "summary": "Zero-shot reinforcement learning is necessary for extracting optimal policies\nin absence of concrete rewards for fast adaptation to future problem settings.\nForward-backward representations (FB) have emerged as a promising method for\nlearning optimal policies in absence of rewards via a factorization of the\npolicy occupancy measure. However, up until now, FB and many similar zero-shot\nreinforcement learning algorithms have been decoupled from the exploration\nproblem, generally relying on other exploration algorithms for data collection.\nWe argue that FB representations should fundamentally be used for exploration\nin order to learn more efficiently. With this goal in mind, we design\nexploration policies that arise naturally from the FB representation that\nminimize the posterior variance of the FB representation, hence minimizing its\nepistemic uncertainty. We empirically demonstrate that such principled\nexploration strategies improve sample complexity of the FB algorithm\nconsiderably in comparison to other exploration methods. Code is publicly\navailable at https://sites.google.com/view/fbee-url.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05477v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05432", "title": "Robotic System with AI for Real Time Weed Detection, Canopy Aware Spraying, and Droplet Pattern Evaluation", "authors": ["Inayat Rasool", "Pappu Kumar Yadav", "Amee Parmar", "Hasan Mirzakhaninafchi", "Rikesh Budhathoki", "Zain Ul Abideen Usmani", "Supriya Paudel", "Ivan Perez Olivera", "Eric Jone"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages", "url": "http://arxiv.org/abs/2507.05432v1", "summary": "Uniform and excessive herbicide application in modern agriculture contributes\nto increased input costs, environmental pollution, and the emergence of\nherbicide resistant weeds. To address these challenges, we developed a vision\nguided, AI-driven variable rate sprayer system capable of detecting weed\npresence, estimating canopy size, and dynamically adjusting nozzle activation\nin real time. The system integrates lightweight YOLO11n and YOLO11n-seg deep\nlearning models, deployed on an NVIDIA Jetson Orin Nano for onboard inference,\nand uses an Arduino Uno-based relay interface to control solenoid actuated\nnozzles based on canopy segmentation results. Indoor trials were conducted\nusing 15 potted Hibiscus rosa sinensis plants of varying canopy sizes to\nsimulate a range of weed patch scenarios. The YOLO11n model achieved a mean\naverage precision (mAP@50) of 0.98, with a precision of 0.99 and a recall close\nto 1.0. The YOLO11n-seg segmentation model achieved a mAP@50 of 0.48, precision\nof 0.55, and recall of 0.52. System performance was validated using water\nsensitive paper, which showed an average spray coverage of 24.22% in zones\nwhere canopy was present. An upward trend in mean spray coverage from 16.22%\nfor small canopies to 21.46% and 21.65% for medium and large canopies,\nrespectively, demonstrated the system's capability to adjust spray output based\non canopy size in real time. These results highlight the potential of combining\nreal time deep learning with low-cost embedded hardware for selective herbicide\napplication. Future work will focus on expanding the detection capabilities to\ninclude three common weed species in South Dakota: water hemp (Amaranthus\ntuberculatus), kochia (Bassia scoparia), and foxtail (Setaria spp.), followed\nby further validation in both indoor and field trials within soybean and corn\nproduction systems.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2507.05432v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05504", "title": "Tool for Supporting Debugging and Understanding of Normative Requirements Using LLMs", "authors": ["Alex Kleijwegt", "Sinem Getir Yaman", "Radu Calinescu"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05504v1", "summary": "Normative requirements specify social, legal, ethical, empathetic, and\ncultural (SLEEC) norms that must be observed by a system. To support the\nidentification of SLEEC requirements, numerous standards and regulations have\nbeen developed. These requirements are typically defined by stakeholders in the\nnon-technical system with diverse expertise (e.g., ethicists, lawyers, social\nscientists). Hence, ensuring their consistency and managing the requirement\nelicitation process are complex and error-prone tasks. Recent research has\naddressed this challenge using domain-specific languages to specify normative\nrequirements as rules, whose consistency can then be analyzed with formal\nmethods. Nevertheless, these approaches often present the results from formal\nverification tools in a way that is inaccessible to non-technical users. This\nhinders understanding and makes the iterative process of eliciting and\nvalidating these requirements inefficient in terms of both time and effort. To\naddress this problem, we introduce SLEEC-LLM, a tool that uses large language\nmodels (LLMs) to provide natural-language interpretations for model-checking\ncounterexamples corresponding to SLEEC rule inconsistencies. SLEEC-LLM improves\nthe efficiency and explainability of normative requirements elicitation and\nconsistency analysis. To demonstrate its effectiveness, we summarise its use in\ntwo real-world case studies involving non-technical stakeholders.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05504v1", "cate": "cs.SE", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2504.08814", "title": "When Federated Learning Meets Quantum Computing: Survey and Research Opportunities", "authors": ["Aakar Mathur", "Ashish Gupta", "Sajal K. Das"], "categories": ["cs.DC", "cs.ET", "cs.LG", "cs.NE"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      submitted to IEEE Communications Surveys and Tutorials", "url": "http://arxiv.org/abs/2504.08814v2", "summary": "Quantum Federated Learning (QFL) is an emerging field that harnesses advances\nin Quantum Computing (QC) to improve the scalability and efficiency of\ndecentralized Federated Learning (FL) models. This paper provides a systematic\nand comprehensive survey of the emerging problems and solutions when FL meets\nQC, from research protocol to a novel taxonomy, particularly focusing on both\nquantum and federated limitations, such as their architectures, Noisy\nIntermediate Scale Quantum (NISQ) devices, and privacy preservation, so on.\nThis work explores key developments and integration strategies, along with the\nimpact of quantum computing on FL, keeping a sharp focus on hybrid\nquantum-classical approaches. The paper offers an in-depth understanding of how\nthe strengths of QC, such as gradient hiding, state entanglement, quantum key\ndistribution, quantum security, and quantum-enhanced differential privacy, have\nbeen integrated into FL to ensure the privacy of participants in an enhanced,\nfast, and secure framework. Finally, this study proposes potential future\ndirections to address the identified research gaps and challenges, aiming to\ninspire faster and more secure QFL models for practical use.", "comment": "submitted to IEEE Communications Surveys and Tutorials", "pdf_url": "http://arxiv.org/pdf/2504.08814v2", "cate": "cs.DC", "date": "2025-04-09", "updated": "2025-07-07"}
{"id": "2507.02850", "title": "LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users", "authors": ["Almog Hilel", "Idan Shenfeld", "Jacob Andreas", "Leshem Choshen"], "categories": ["cs.CL", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.02850v2", "summary": "We describe a vulnerability in language models (LMs) trained with user\nfeedback, whereby a single user can persistently alter LM knowledge and\nbehavior given only the ability to provide prompts and upvote / downvote\nfeedback on LM outputs. To implement the attack, the attacker prompts the LM to\nstochastically output either a \"poisoned\" or benign response, then upvotes the\npoisoned response or downvotes the benign one. When feedback signals are used\nin a subsequent preference tuning behavior, LMs exhibit increased probability\nof producing poisoned responses even in contexts without malicious prompts. We\nshow that this attack can be used to (1) insert factual knowledge the model did\nnot previously possess, (2) modify code generation patterns in ways that\nintroduce exploitable security flaws, and (3) inject fake financial news. Our\nfinding both identifies a new qualitative feature of language model preference\ntuning (showing that it even highly restricted forms of preference data can be\nused to exert fine-grained control over behavior), and a new attack mechanism\nfor LMs trained with user feedback (extending work on pretraining-time data\npoisoning and deployment-time prompt injection).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.02850v2", "cate": "cs.CL", "date": "2025-07-03", "updated": "2025-07-07"}
{"id": "2507.06149", "title": "Fast and Accurate Collision Probability Estimation for Autonomous Vehicles using Adaptive Sigma-Point Sampling", "authors": ["Charles Champagne Cossette", "Taylor Scott Clawson", "Andrew Feit"], "categories": ["cs.RO", "cs.AI", "cs.CG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures", "url": "http://arxiv.org/abs/2507.06149v1", "summary": "A novel algorithm is presented for the estimation of collision probabilities\nbetween dynamic objects with uncertain trajectories, where the trajectories are\ngiven as a sequence of poses with Gaussian distributions. We propose an\nadaptive sigma-point sampling scheme, which ultimately produces a fast, simple\nalgorithm capable of estimating the collision probability with a median error\nof 3.5%, and a median runtime of 0.21ms, when measured on an Intel Xeon Gold\n6226R Processor. Importantly, the algorithm explicitly accounts for the\ncollision probability's temporal dependence, which is often neglected in prior\nwork and otherwise leads to an overestimation of the collision probability.\nFinally, the method is tested on a diverse set of relevant real-world\nscenarios, consisting of 400 6-second snippets of autonomous vehicle logs,\nwhere the accuracy and latency is rigorously evaluated.", "comment": "8 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.06149v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05791", "title": "GTA1: GUI Test-time Scaling Agent", "authors": ["Yan Yang", "Dongxu Li", "Yutong Dai", "Yuhao Yang", "Ziyang Luo", "Zirui Zhao", "Zhiyuan Hu", "Junzhe Huang", "Amrita Saha", "Zeyuan Chen", "Ran Xu", "Liyuan Pan", "Caiming Xiong", "Junnan Li"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05791v1", "summary": "Graphical user interface (GUI) agents autonomously operate across platforms\n(e.g., Linux) to complete tasks by interacting with visual elements.\nSpecifically, a user instruction is decomposed into a sequence of action\nproposals, each corresponding to an interaction with the GUI. After each\naction, the agent observes the updated GUI environment to plan the next step.\nHowever, two main challenges arise: i) resolving ambiguity in task planning\n(i.e., the action proposal sequence), where selecting an appropriate plan is\nnon-trivial, as many valid ones may exist; ii) accurately grounding actions in\ncomplex and high-resolution interfaces, i.e., precisely interacting with visual\ntargets.\n  This paper investigates the two aforementioned challenges with our GUI\nTest-time Scaling Agent, namely GTA1. First, to select the most appropriate\naction proposal, we introduce a test-time scaling method. At each step, we\nsample multiple candidate action proposals and leverage a judge model to\nevaluate and select the most suitable one. It trades off computation for better\ndecision quality by concurrent sampling, shortening task execution steps, and\nimproving overall performance. Second, we propose a model that achieves\nimproved accuracy when grounding the selected action proposal to its\ncorresponding visual elements. Our key insight is that reinforcement learning\n(RL) facilitates visual grounding through inherent objective alignments,\nrewarding successful clicks on interface elements.\n  Experimentally, our method establishes state-of-the-art performance across\ndiverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7%\naccuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When\npaired with a planner applying our test-time scaling strategy, it exhibits\nstate-of-the-art agentic performance (e.g., 45.2% task success rate on\nOSWorld). We open-source our code and models here.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05791v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05478", "title": "Dynamic Regret Reduces to Kernelized Static Regret", "authors": ["Andrew Jacobsen", "Alessandro Rudi", "Francesco Orabona", "Nicolo Cesa-Bianchi"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      38 pages, 2 figures", "url": "http://arxiv.org/abs/2507.05478v1", "summary": "We study dynamic regret in online convex optimization, where the objective is\nto achieve low cumulative loss relative to an arbitrary benchmark sequence. By\nobserving that competing with an arbitrary sequence of comparators\n$u_{1},\\ldots,u_{T}$ in $\\mathcal{W}\\subseteq\\mathbb{R}^{d}$ is equivalent to\ncompeting with a fixed comparator function $u:[1,T]\\to \\mathcal{W}$, we frame\ndynamic regret minimization as a static regret problem in a function space. By\ncarefully constructing a suitable function space in the form of a Reproducing\nKernel Hilbert Space (RKHS), our reduction enables us to recover the optimal\n$R_{T}(u_{1},\\ldots,u_{T}) = \\mathcal{O}(\\sqrt{\\sum_{t}\\|u_{t}-u_{t-1}\\|T})$\ndynamic regret guarantee in the setting of linear losses, and yields new\nscale-free and directionally-adaptive dynamic regret guarantees. Moreover,\nunlike prior dynamic-to-static reductions -- which are valid only for linear\nlosses -- our reduction holds for any sequence of losses, allowing us to\nrecover $\\mathcal{O}\\big(\\|u\\|^2+d_{\\mathrm{eff}}(\\lambda)\\ln T\\big)$ bounds in\nexp-concave and improper linear regression settings, where\n$d_{\\mathrm{eff}}(\\lambda)$ is a measure of complexity of the RKHS. Despite\nworking in an infinite-dimensional space, the resulting reduction leads to\nalgorithms that are computable in practice, due to the reproducing property of\nRKHSs.", "comment": "38 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.05478v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05463", "title": "Driving as a Diagnostic Tool: Scenario-based Cognitive Assessment in Older Drivers From Driving Video", "authors": ["Md Zahid Hasan", "Guillermo Basulto-Elias", "Jun Ha Chang", "Sahuna Hallmark", "Matthew Rizzo", "Anuj Sharma", "Soumik Sarkar"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      14 pages, 8 figures", "url": "http://arxiv.org/abs/2507.05463v1", "summary": "We introduce scenario-based cognitive status identification in older drivers\nfrom Naturalistic driving videos and large vision models. In recent times,\ncognitive decline, including Alzheimer's disease (AD) and mild cognitive\nimpairment (MCI), is often underdiagnosed due to the time-consuming and costly\nnature of current diagnostic methods. By analyzing real-world driving behavior\ncaptured through in-vehicle systems, this research aims to extract \"digital\nfingerprints\" that correlate with functional decline and clinical features of\nMCI and AD. Moreover, modern large vision models can draw meaningful insights\nfrom everyday driving patterns of older patients to early detect cognitive\ndecline. We propose a framework that uses large vision models and naturalistic\ndriving videos to analyze driver behavior, classify cognitive status and\npredict disease progression. We leverage the strong relationship between\nreal-world driving behavior as an observation of the current cognitive status\nof the drivers where the vehicle can be utilized as a \"diagnostic tool\". Our\nmethod identifies early warning signs of functional impairment, contributing to\nproactive intervention strategies. This work enhances early detection and\nsupports the development of scalable, non-invasive monitoring systems to\nmitigate the growing societal and economic burden of cognitive decline in the\naging population.", "comment": "14 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.05463v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05565", "title": "Search-based Selection of Metamorphic Relations for Optimized Robustness Testing of Large Language Models", "authors": ["Sangwon Hyun", "Shaukat Ali", "M. Ali Babar"], "categories": ["cs.SE", "cs.AI", "cs.NE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05565v1", "summary": "Assessing the trustworthiness of Large Language Models (LLMs), such as\nrobustness, has garnered significant attention. Recently, metamorphic testing\nthat defines Metamorphic Relations (MRs) has been widely applied to evaluate\nthe robustness of LLM executions. However, the MR-based robustness testing\nstill requires a scalable number of MRs, thereby necessitating the optimization\nof selecting MRs. Most extant LLM testing studies are limited to automatically\ngenerating test cases (i.e., MRs) to enhance failure detection. Additionally,\nmost studies only considered a limited test space of single perturbation MRs in\ntheir evaluation of LLMs. In contrast, our paper proposes a search-based\napproach for optimizing the MR groups to maximize failure detection and\nminimize the LLM execution cost. Moreover, our approach covers the\ncombinatorial perturbations in MRs, facilitating the expansion of test space in\nthe robustness assessment. We have developed a search process and implemented\nfour search algorithms: Single-GA, NSGA-II, SPEA2, and MOEA/D with novel\nencoding to solve the MR selection problem in the LLM robustness testing. We\nconducted comparative experiments on the four search algorithms along with a\nrandom search, using two major LLMs with primary Text-to-Text tasks. Our\nstatistical and empirical investigation revealed two key findings: (1) the\nMOEA/D algorithm performed the best in optimizing the MR space for LLM\nrobustness testing, and (2) we identified silver bullet MRs for the LLM\nrobustness testing, which demonstrated dominant capabilities in confusing LLMs\nacross different Text-to-Text tasks. In LLM robustness assessment, our research\nsheds light on the fundamental problem for optimized testing and provides\ninsights into search-based solutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05565v1", "cate": "cs.SE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05549", "title": "The Ethical Implications of AI in Creative Industries: A Focus on AI-Generated Art", "authors": ["Prerana Khatiwada", "Joshua Washington", "Tyler Walsh", "Ahmed Saif Hamed", "Lokesh Bhatta"], "categories": ["cs.CY", "cs.AI", "cs.HC", "I.2.0"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2507.05549v1", "summary": "As Artificial Intelligence (AI) continues to grow daily, more exciting (and\nsomewhat controversial) technology emerges every other day. As we see the\nadvancements in AI, we see more and more people becoming skeptical of it. This\npaper explores the complications and confusion around the ethics of generative\nAI art. We delve deep into the ethical side of AI, specifically generative art.\nWe step back from the excitement and observe the impossible conundrums that\nthis impressive technology produces. Covering environmental consequences,\ncelebrity representation, intellectual property, deep fakes, and artist\ndisplacement. Our research found that generative AI art is responsible for\nincreased carbon emissions, spreading misinformation, copyright infringement,\nunlawful depiction, and job displacement. In light of this, we propose multiple\npossible solutions for these problems. We address each situation's history,\ncause, and consequences and offer different viewpoints. At the root of it all,\nthough, the central theme is that generative AI Art needs to be correctly\nlegislated and regulated.", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2507.05549v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06193", "title": "Identity isn't everything -- how far do demographics take us towards self-identified party ID?", "authors": ["Sabina Tomkins", "David Rothschild", "Alex Liu", "Alexander Thompson"], "categories": ["cs.CY", "cs.SI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06193v1", "summary": "How well do demographics explain party identification? Demographics are\nrelated to party identification in political polls, news articles, and academic\npublications. Yet, there is a diversity of party identification even within\ndemographic groups which have historically been attached to one party. And some\ngroups lack a clear connection to either party. It may be that demographics on\ntheir own fail to account for the fact that people generally belong to a\nvariety of groups. They must select the groups which are most important to them\nwhen shaping a political identity, and may choose to construct an identity\nrelatively unattached to any specific demographic group to which they belong.\nThis prompts the question, do we need to consider measures of identity strength\nwhen using demographics to explain party identification? We utilize a\npredictive framework to address these questions and find that demographics are\nhighly predictive for some groups (e.g., Black Democrats), while others benefit\nfrom the inclusion of identity strength (e.g., Hispanic Republicans).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06193v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05567", "title": "Lower Bounds for Error Coefficients of Griesmer Optimal Linear Codes via Iteration", "authors": ["Chaofeng Guan", "Shitao Li", "Gaojun Luo", "Zhi Ma", "Hong Wang"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      15 pages, 4 tables", "url": "http://arxiv.org/abs/2507.05567v1", "summary": "The error coefficient of a linear code is defined as the number of\nminimum-weight codewords. In an additive white Gaussian noise channel, optimal\nlinear codes with the smallest error coefficients achieve the best possible\nasymptotic frame error rate (AFER) among all optimal linear codes under maximum\nlikelihood decoding. Such codes are referred to as AFER-optimal linear codes.\n  The Griesmer bound is essential for determining the optimality of linear\ncodes. However, establishing tight lower bounds on the error coefficients of\nGriesmer optimal linear codes is challenging, and the linear programming bound\noften performs inadequately. In this paper, we propose several iterative lower\nbounds for the error coefficients of Griesmer optimal linear codes.\nSpecifically, for binary linear codes, our bounds are tight in most cases when\nthe dimension does not exceed $5$. To evaluate the performance of our bounds\nwhen they are not tight, we also determine the parameters of the remaining\n5-dimensional AFER-optimal linear codes. Our final comparison demonstrates that\neven when our bounds are not tight, they remain very close to the actual\nvalues, with a gap of less than or equal to $2$.", "comment": "15 pages, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.05567v1", "cate": "cs.IT", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05597", "title": "Baton: Compensate for Missing Wi-Fi Features for Practical Device-free Tracking", "authors": ["Yiming Zhao", "Xuanqi Meng", "Xinyu Tong", "Xiulong Liu", "Xin Xie", "Wenyu Qu"], "categories": ["cs.NI", "eess.SP"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      17 pages, 20 figures. Accepted and published in IEEE Transactions on Mobile Computing on April 10, 2025. This is the accepted version. Final published version: this https URL", "url": "http://arxiv.org/abs/2507.05597v1", "summary": "Wi-Fi contact-free sensing systems have attracted widespread attention due to\ntheir ubiquity and convenience. The integrated sensing and communication (ISAC)\ntechnology utilizes off-the-shelf Wi-Fi communication signals for sensing,\nwhich further promotes the deployment of intelligent sensing applications.\nHowever, current Wi-Fi sensing systems often require prolonged and unnecessary\ncommunication between transceivers, and brief communication interruptions will\nlead to significant performance degradation. This paper proposes Baton, the\nfirst system capable of accurately tracking targets even under severe Wi-Fi\nfeature deficiencies. To be specific, we explore the relevance of the Wi-Fi\nfeature matrix from both horizontal and vertical dimensions. The horizontal\ndimension reveals feature correlation across different Wi-Fi links, while the\nvertical dimension reveals feature correlation among different time slots.\nBased on the above principle, we propose the Simultaneous Tracking And\nPredicting (STAP) algorithm, which enables the seamless transfer of Wi-Fi\nfeatures over time and across different links, akin to passing a baton. We\nimplement the system on commercial devices, and the experimental results show\nthat our system outperforms existing solutions with a median tracking error of\n0.46m, even when the communication duty cycle is as low as 20.00%. Compared\nwith the state-of-the-art, our system reduces the tracking error by 79.19% in\nscenarios with severe Wi-Fi feature deficiencies.", "comment": "17 pages, 20 figures. Accepted and published in IEEE Transactions on\n  Mobile Computing on April 10, 2025. This is the accepted version. Final\n  published version: https://ieeexplore.ieee.org/document/10962318", "pdf_url": "http://arxiv.org/pdf/2507.05597v1", "cate": "cs.NI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.02995", "title": "FreqCross: A Multi-Modal Frequency-Spatial Fusion Network for Robust Detection of Stable Diffusion 3.5 Generated Images", "authors": ["Guang Yang"], "categories": ["cs.CV", "cs.CR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.02995v2", "summary": "The rapid advancement of diffusion models, particularly Stable Diffusion 3.5,\nhas enabled the generation of highly photorealistic synthetic images that pose\nsignificant challenges to existing detection methods. This paper presents\nFreqCross, a novel multi-modal fusion network that combines spatial RGB\nfeatures, frequency domain artifacts, and radial energy distribution patterns\nto achieve robust detection of AI-generated images. Our approach leverages a\nthree-branch architecture: (1) a ResNet-18 backbone for spatial feature\nextraction, (2) a lightweight CNN for processing 2D FFT magnitude spectra, and\n(3) a multi-layer perceptron for analyzing radial energy profiles. We introduce\na novel radial energy distribution analysis that captures characteristic\nfrequency artifacts inherent in diffusion-generated images, and fuse it with\nspatial and spectral cues via simple feature concatenation followed by a\ncompact classification head. Extensive experiments on a dataset of 10,000\npaired real (MS-COCO) and synthetic (Stable Diffusion 3.5) images demonstrate\nthat FreqCross achieves 97.8\\% accuracy, outperforming state-of-the-art\nbaselines by 5.2\\%. The frequency analysis further reveals that synthetic\nimages exhibit distinct spectral signatures in the 0.1--0.4 normalised\nfrequency range, providing theoretical foundation for our approach. Code and\npre-trained models are publicly available to facilitate reproducible research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.02995v2", "cate": "cs.CV", "date": "2025-07-01", "updated": "2025-07-08"}
{"id": "2507.06157", "title": "Evaluation of Habitat Robotics using Large Language Models", "authors": ["William Li", "Lei Hamilton", "Kaise Al-natour", "Sanjeev Mohindra"], "categories": ["cs.RO", "cs.CL"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      6 pages, IEEE HPEC submission", "url": "http://arxiv.org/abs/2507.06157v1", "summary": "This paper focuses on evaluating the effectiveness of Large Language Models\nat solving embodied robotic tasks using the Meta PARTNER benchmark. Meta PARTNR\nprovides simplified environments and robotic interactions within randomized\nindoor kitchen scenes. Each randomized kitchen scene is given a task where two\nrobotic agents cooperatively work together to solve the task. We evaluated\nmultiple frontier models on Meta PARTNER environments. Our results indicate\nthat reasoning models like OpenAI o3-mini outperform non-reasoning models like\nOpenAI GPT-4o and Llama 3 when operating in PARTNR's robotic embodied\nenvironments. o3-mini displayed outperform across centralized, decentralized,\nfull observability, and partial observability configurations. This provides a\npromising avenue of research for embodied robotic development.", "comment": "6 pages, IEEE HPEC submission", "pdf_url": "http://arxiv.org/pdf/2507.06157v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05816", "title": "Affective-ROPTester: Capability and Bias Analysis of LLMs in Predicting Retinopathy of Prematurity", "authors": ["Shuai Zhao", "Yulin Zhang", "Luwei Xiao", "Xinyi Wu", "Yanhao Jia", "Zhongliang Guo", "Xiaobao Wu", "Cong-Duy Nguyen", "Guoming Zhang", "Anh Tuan Luu"], "categories": ["cs.AI", "cs.CE", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05816v1", "summary": "Despite the remarkable progress of large language models (LLMs) across\nvarious domains, their capacity to predict retinopathy of prematurity (ROP)\nrisk remains largely unexplored. To address this gap, we introduce a novel\nChinese benchmark dataset, termed CROP, comprising 993 admission records\nannotated with low, medium, and high-risk labels. To systematically examine the\npredictive capabilities and affective biases of LLMs in ROP risk\nstratification, we propose Affective-ROPTester, an automated evaluation\nframework incorporating three prompting strategies: Instruction-based,\nChain-of-Thought (CoT), and In-Context Learning (ICL). The Instruction scheme\nassesses LLMs' intrinsic knowledge and associated biases, whereas the CoT and\nICL schemes leverage external medical knowledge to enhance predictive accuracy.\nCrucially, we integrate emotional elements at the prompt level to investigate\nhow different affective framings influence the model's ability to predict ROP\nand its bias patterns. Empirical results derived from the CROP dataset yield\ntwo principal observations. First, LLMs demonstrate limited efficacy in ROP\nrisk prediction when operating solely on intrinsic knowledge, yet exhibit\nmarked performance gains when augmented with structured external inputs.\nSecond, affective biases are evident in the model outputs, with a consistent\ninclination toward overestimating medium- and high-risk cases. Third, compared\nto negative emotions, positive emotional framing contributes to mitigating\npredictive bias in model outputs. These findings highlight the critical role of\naffect-sensitive prompt engineering in enhancing diagnostic reliability and\nemphasize the utility of Affective-ROPTester as a framework for evaluating and\nmitigating affective bias in clinical language modeling systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05816v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05482", "title": "Navigating Sparse Molecular Data with Stein Diffusion Guidance", "authors": ["Van Khoa Nguyen", "Lionel Blondé", "Alexandros Kalousis"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05482v1", "summary": "Stochastic optimal control (SOC) has recently emerged as a principled\nframework for fine-tuning diffusion models. However, its dependence on\ncomputationally intensive simulations makes it impractical for fast sampling.\nIn parallel, a class of training-free approaches has been developed that guides\ndiffusion models using off-the-shelf classifiers on predicted clean samples,\nbypassing the need to train classifiers on noisy data. These methods can be\ninterpreted as approximate SOC schemes, using Tweedie's formula to estimate\ndiffusion posteriors. In practice, however, such direct approximations can\nintroduce significant errors, leading to unreliable guidance. In this work, we\nunify the strengths of both paradigms by proposing a novel training-free\ndiffusion guidance framework based on a surrogate stochastic optimal control\nobjective. We derive a new theoretical bound on the value function that reveals\nthe necessity of correcting the approximate posteriors to remain faithful to\nthe true diffusion posterior. To this end, we connect the problem with Stein\nvariational inference, which seeks the steepest descent direction that\nminimizes the Kullback-Leibler discrepancy between the two posteriors. Our\nmethod, which we refer to as Stein Diffusion Guidance (SDG), introduces a\nprincipled correction mechanism and incorporates a novel running cost\nfunctional to enable effective guidance in low-density regions. Experiments on\nchallenging molecular generation tasks demonstrate that SDG significantly\noutperforms standard training-free guidance methods, highlighting its potential\nfor broader applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05482v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05496", "title": "Cloud Diffusion Part 1: Theory and Motivation", "authors": ["Andrew Randono"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      39 pages, 21 figures. Associated code: this https URL", "url": "http://arxiv.org/abs/2507.05496v1", "summary": "Diffusion models for image generation function by progressively adding noise\nto an image set and training a model to separate out the signal from the noise.\nThe noise profile used by these models is white noise -- that is, noise based\non independent normal distributions at each point whose mean and variance is\nindependent of the scale. By contrast, most natural image sets exhibit a type\nof scale invariance in their low-order statistical properties characterized by\na power-law scaling. Consequently, natural images are closer (in a quantifiable\nsense) to a different probability distribution that emphasizes large scale\ncorrelations and de-emphasizes small scale correlations. These scale invariant\nnoise profiles can be incorporated into diffusion models in place of white\nnoise to form what we will call a ``Cloud Diffusion Model\". We argue that these\nmodels can lead to faster inference, improved high-frequency details, and\ngreater controllability. In a follow-up paper, we will build and train a Cloud\nDiffusion Model that uses scale invariance at a fundamental level and compare\nit to classic, white noise diffusion models.", "comment": "39 pages, 21 figures. Associated code:\n  https://github.com/arandono/Cloud-Diffusion", "pdf_url": "http://arxiv.org/pdf/2507.05496v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05932", "title": "TigAug: Data Augmentation for Testing Traffic Light Detection in Autonomous Driving Systems", "authors": ["You Lu", "Dingji Wang", "Kaifeng Huang", "Bihuan Chen", "Xin Peng"], "categories": ["cs.SE", "cs.CV"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05932v1", "summary": "Autonomous vehicle technology has been developed in the last decades with\nrecent advances in sensing and computing technology. There is an urgent need to\nensure the reliability and robustness of autonomous driving systems (ADSs).\nDespite the recent achievements in testing various ADS modules, little\nattention has been paid on the automated testing of traffic light detection\nmodels in ADSs. A common practice is to manually collect and label traffic\nlight data. However, it is labor-intensive, and even impossible to collect\ndiverse data under different driving environments.\n  To address these problems, we propose and implement TigAug to automatically\naugment labeled traffic light images for testing traffic light detection models\nin ADSs. We construct two families of metamorphic relations and three families\nof transformations based on a systematic understanding of weather environments,\ncamera properties, and traffic light properties. We use augmented images to\ndetect erroneous behaviors of traffic light detection models by\ntransformation-specific metamorphic relations, and to improve the performance\nof traffic light detection models by retraining. Large-scale experiments with\nfour state-of-the-art traffic light detection models and two traffic light\ndatasets have demonstrated that i) TigAug is effective in testing traffic light\ndetection models, ii) TigAug is efficient in synthesizing traffic light images,\nand iii) TigAug generates traffic light images with acceptable naturalness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05932v1", "cate": "cs.SE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05984", "title": "Development and Evaluation of HopeBot: an LLM-based chatbot for structured and interactive PHQ-9 depression screening", "authors": ["Zhijun Guo", "Alvina Lai", "Julia Ive", "Alexandru Petcu", "Yutong Wang", "Luyuan Qi", "Johan H Thygesen", "Kezhi Li"], "categories": ["cs.AI", "cs.CL", "cs.HC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05984v1", "summary": "Static tools like the Patient Health Questionnaire-9 (PHQ-9) effectively\nscreen depression but lack interactivity and adaptability. We developed\nHopeBot, a chatbot powered by a large language model (LLM) that administers the\nPHQ-9 using retrieval-augmented generation and real-time clarification. In a\nwithin-subject study, 132 adults in the United Kingdom and China completed both\nself-administered and chatbot versions. Scores demonstrated strong agreement\n(ICC = 0.91; 45% identical). Among 75 participants providing comparative\nfeedback, 71% reported greater trust in the chatbot, highlighting clearer\nstructure, interpretive guidance, and a supportive tone. Mean ratings (0-10)\nwere 8.4 for comfort, 7.7 for voice clarity, 7.6 for handling sensitive topics,\nand 7.4 for recommendation helpfulness; the latter varied significantly by\nemployment status and prior mental-health service use (p < 0.05). Overall,\n87.1% expressed willingness to reuse or recommend HopeBot. These findings\ndemonstrate voice-based LLM chatbots can feasibly serve as scalable, low-burden\nadjuncts for routine depression screening.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05984v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2409.18162", "title": "The Nexus of AR/VR, AI, UI/UX, and Robotics Technologies in Enhancing Learning and Social Interaction for Children with Autism Spectrum Disorders: A Systematic Review", "authors": ["Biplov Paneru"], "categories": ["cs.HC", "cs.AI", "cs.SI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      none", "url": "http://arxiv.org/abs/2409.18162v3", "summary": "The emergence of large language models (LLMs), augmented reality (AR), and\nuser interface/user experience (UI/UX) design in therapies for children,\nespecially with disorders like autism spectrum disorder (ASD), is studied in\ndetail in this review study. 150 publications were collected by a thorough\nliterature search throughout PubMed, ACM, IEEE Xplore, Elsevier, and Google\nScholar; 60 of them were chosen based on their methodological rigor and\nrelevance to the focus area. Three of the primary areas are studied and covered\nin this review: how AR can improve social and learning results, how LLMs can\nsupport communication, and how UI/UX design affects how effective these\ntechnologies can be. Results show that while LLMs can provide individualized\nlearning and communication support, AR has shown promise in enhancing social\nskills, motivation, and attention. For children with ASD, accessible and\nengaging interventions rely heavily on effective UI/UX design, but there is\nstill a significant lack of robotics-based education and therapeutic programs\nspecifically tailored for autistic children. To optimize the benefits of these\ntechnologies in ASD therapies and immersive education, the study emphasizes the\nneed for additional research to address difficulties related to customization,\naccessibility, and integration.", "comment": "none", "pdf_url": "http://arxiv.org/pdf/2409.18162v3", "cate": "cs.HC", "date": "2024-09-26", "updated": "2025-07-08"}
{"id": "2507.05718", "title": "Cooperative Mapping, Localization, and Beam Management via Multi-Modal SLAM in ISAC Systems", "authors": ["Hang Que", "Jie Yang", "Tao Du", "Shuqiang Xia", "Chao-Kai Wen", "Shi Jin"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Transactions on Communications", "url": "http://arxiv.org/abs/2507.05718v1", "summary": "Simultaneous localization and mapping (SLAM) plays a critical role in\nintegrated sensing and communication (ISAC) systems for sixth-generation (6G)\nmillimeter-wave (mmWave) networks, enabling environmental awareness and precise\nuser equipment (UE) positioning. While cooperative multi-user SLAM has\ndemonstrated potential in leveraging distributed sensing, its application\nwithin multi-modal ISAC systems remains limited, particularly in terms of\ntheoretical modeling and communication-layer integration. This paper proposes a\nnovel multi-modal SLAM framework that addresses these limitations through three\nkey contributions. First, a Bayesian estimation framework is developed for\ncooperative multi-user SLAM, along with a two-stage algorithm for robust radio\nmap construction under dynamic and heterogeneous sensing conditions. Second, a\nmulti-modal localization strategy is introduced, fusing SLAM results with\ncamera-based multi-object tracking and inertial measurement unit (IMU) data via\nan error-aware model, significantly improving UE localization in multi-user\nscenarios. Third, a sensing-aided beam management scheme is proposed, utilizing\nglobal radio maps and localization data to generate UE-specific prior\ninformation for beam selection, thereby reducing inter-user interference and\nenhancing downlink spectral efficiency. Simulation results demonstrate that the\nproposed system improves radio map accuracy by up to 60%, enhances localization\naccuracy by 37.5%, and significantly outperforms traditional methods in both\nindoor and outdoor environments.", "comment": "Accepted by IEEE Transactions on Communications", "pdf_url": "http://arxiv.org/pdf/2507.05718v1", "cate": "cs.IT", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05731", "title": "A Satellite-Ground Synergistic Large Vision-Language Model System for Earth Observation", "authors": ["Yuxin Zhang", "Jiahao Yang", "Zhe Chen", "Wenjun Zhu", "Jin Zhao", "Yue Gao"], "categories": ["cs.NI", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      11 pages, 12 figures", "url": "http://arxiv.org/abs/2507.05731v1", "summary": "Recently, large vision-language models (LVLMs) unleash powerful analysis\ncapabilities for low Earth orbit (LEO) satellite Earth observation images in\nthe data center. However, fast satellite motion, brief satellite-ground station\n(GS) contact windows, and large size of the images pose a data download\nchallenge. To enable near real-time Earth observation applications (e.g.,\ndisaster and extreme weather monitoring), we should explore how to deploy LVLM\nin LEO satellite networks, and design SpaceVerse, an efficient satellite-ground\nsynergistic LVLM inference system. To this end, firstly, we deploy compact\nLVLMs on satellites for lightweight tasks, whereas regular LVLMs operate on GSs\nto handle computationally intensive tasks. Then, we propose a computing and\ncommunication co-design framework comprised of a progressive confidence network\nand an attention-based multi-scale preprocessing, used to identify on-satellite\ninferring data, and reduce data redundancy before satellite-GS transmission,\nseparately. We implement and evaluate SpaceVerse on real-world LEO satellite\nconstellations and datasets, achieving a 31.2% average gain in accuracy and a\n51.2% reduction in latency compared to state-of-the-art baselines.", "comment": "11 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.05731v1", "cate": "cs.NI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06172", "title": "Learning Agile Tensile Perching for Aerial Robots from Demonstrations", "authors": ["Kangle Yuan", "Atar Babgei", "Luca Romanello", "Hai-Nguyen Nguyen", "Ronald Clark", "Mirko Kovac", "Sophie F. Armanini", "Basaran Bahadir Kocer"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      9 pages, 9 figures", "url": "http://arxiv.org/abs/2507.06172v1", "summary": "Perching on structures such as trees, beams, and ledges is essential for\nextending the endurance of aerial robots by enabling energy conservation in\nstandby or observation modes. A tethered tensile perching mechanism offers a\nsimple, adaptable solution that can be retrofitted to existing robots and\naccommodates a variety of structure sizes and shapes. However, tethered tensile\nperching introduces significant modelling challenges which require precise\nmanagement of aerial robot dynamics, including the cases of tether slack &\ntension, and momentum transfer. Achieving smooth wrapping and secure anchoring\nby targeting a specific tether segment adds further complexity. In this work,\nwe present a novel trajectory framework for tethered tensile perching,\nutilizing reinforcement learning (RL) through the Soft Actor-Critic from\nDemonstrations (SACfD) algorithm. By incorporating both optimal and suboptimal\ndemonstrations, our approach enhances training efficiency and responsiveness,\nachieving precise control over position and velocity. This framework enables\nthe aerial robot to accurately target specific tether segments, facilitating\nreliable wrapping and secure anchoring. We validate our framework through\nextensive simulation and real-world experiments, and demonstrate effectiveness\nin achieving agile and reliable trajectory generation for tensile perching.", "comment": "9 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.06172v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05868", "title": "CogniPlay: a work-in-progress Human-like model for General Game Playing", "authors": ["Aloïs Rautureau", "Éric Piette"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      5 pages, 1 figure", "url": "http://arxiv.org/abs/2507.05868v1", "summary": "While AI systems have equaled or surpassed human performance in a wide\nvariety of games such as Chess, Go, or Dota 2, describing these systems as\ntruly \"human-like\" remains far-fetched. Despite their success, they fail to\nreplicate the pattern-based, intuitive decision-making processes observed in\nhuman cognition. This paper presents an overview of findings from cognitive\npsychology and previous efforts to model human-like behavior in artificial\nagents, discusses their applicability to General Game Playing (GGP) and\nintroduces our work-in-progress model based on these observations: CogniPlay.", "comment": "5 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.05868v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05498", "title": "Explainable Hierarchical Deep Learning Neural Networks (Ex-HiDeNN)", "authors": ["Reza T. Batley", "Chanwook Park", "Wing Kam Liu", "Sourav Saha"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05498v1", "summary": "Data-driven science and computation have advanced immensely to construct\ncomplex functional relationships using trainable parameters. However,\nefficiently discovering interpretable and accurate closed-form expressions from\ncomplex dataset remains a challenge. The article presents a novel approach\ncalled Explainable Hierarchical Deep Learning Neural Networks or Ex-HiDeNN that\nuses an accurate, frugal, fast, separable, and scalable neural architecture\nwith symbolic regression to discover closed-form expressions from limited\nobservation. The article presents the two-step Ex-HiDeNN algorithm with a\nseparability checker embedded in it. The accuracy and efficiency of Ex-HiDeNN\nare tested on several benchmark problems, including discerning a dynamical\nsystem from data, and the outcomes are reported. Ex-HiDeNN generally shows\noutstanding approximation capability in these benchmarks, producing orders of\nmagnitude smaller errors compared to reference data and traditional symbolic\nregression. Later, Ex-HiDeNN is applied to three engineering applications: a)\ndiscovering a closed-form fatigue equation, b) identification of hardness from\nmicro-indentation test data, and c) discovering the expression for the yield\nsurface with data. In every case, Ex-HiDeNN outperformed the reference methods\nused in the literature. The proposed method is built upon the foundation and\npublished works of the authors on Hierarchical Deep Learning Neural Network\n(HiDeNN) and Convolutional HiDeNN. The article also provides a clear idea about\nthe current limitations and future extensions of Ex-HiDeNN.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05498v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05499", "title": "LoomNet: Enhancing Multi-View Image Generation via Latent Space Weaving", "authors": ["Giulio Federico", "Fabio Carrara", "Claudio Gennaro", "Giuseppe Amato", "Marco Di Benedetto"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05499v1", "summary": "Generating consistent multi-view images from a single image remains\nchallenging. Lack of spatial consistency often degrades 3D mesh quality in\nsurface reconstruction. To address this, we propose LoomNet, a novel multi-view\ndiffusion architecture that produces coherent images by applying the same\ndiffusion model multiple times in parallel to collaboratively build and\nleverage a shared latent space for view consistency. Each viewpoint-specific\ninference generates an encoding representing its own hypothesis of the novel\nview from a given camera pose, which is projected onto three orthogonal planes.\nFor each plane, encodings from all views are fused into a single aggregated\nplane. These aggregated planes are then processed to propagate information and\ninterpolate missing regions, combining the hypotheses into a unified, coherent\ninterpretation. The final latent space is then used to render consistent\nmulti-view images. LoomNet generates 16 high-quality and coherent views in just\n15 seconds. In our experiments, LoomNet outperforms state-of-the-art methods on\nboth image quality and reconstruction metrics, also showing creativity by\nproducing diverse, plausible novel views from the same input.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05499v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05981", "title": "Multi-Agent Debate Strategies to Enhance Requirements Engineering with Large Language Models", "authors": ["Marc Oriol", "Quim Motger", "Jordi Marco", "Xavier Franch"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05981v1", "summary": "Context: Large Language Model (LLM) agents are becoming widely used for\nvarious Requirements Engineering (RE) tasks. Research on improving their\naccuracy mainly focuses on prompt engineering, model fine-tuning, and retrieval\naugmented generation. However, these methods often treat models as isolated\nblack boxes - relying on single-pass outputs without iterative refinement or\ncollaboration, limiting robustness and adaptability. Objective: We propose\nthat, just as human debates enhance accuracy and reduce bias in RE tasks by\nincorporating diverse perspectives, different LLM agents debating and\ncollaborating may achieve similar improvements. Our goal is to investigate\nwhether Multi-Agent Debate (MAD) strategies can enhance RE performance. Method:\nWe conducted a systematic study of existing MAD strategies across various\ndomains to identify their key characteristics. To assess their applicability in\nRE, we implemented and tested a preliminary MAD-based framework for RE\nclassification. Results: Our study identified and categorized several MAD\nstrategies, leading to a taxonomy outlining their core attributes. Our\npreliminary evaluation demonstrated the feasibility of applying MAD to RE\nclassification. Conclusions: MAD presents a promising approach for improving\nLLM accuracy in RE tasks. This study provides a foundational understanding of\nMAD strategies, offering insights for future research and refinements in RE\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05981v1", "cate": "cs.SE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06185", "title": "Hidden Prompts in Manuscripts Exploit AI-Assisted Peer Review", "authors": ["Zhicheng Lin"], "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06185v1", "summary": "In July 2025, 18 academic manuscripts on the preprint website arXiv were\nfound to contain hidden instructions known as prompts designed to manipulate\nAI-assisted peer review. Instructions such as \"GIVE A POSITIVE REVIEW ONLY\"\nwere concealed using techniques like white-colored text. Author responses\nvaried: one planned to withdraw the affected paper, while another defended the\npractice as legitimate testing of reviewer compliance. This commentary analyzes\nthis practice as a novel form of research misconduct. We examine the technique\nof prompt injection in large language models (LLMs), revealing four types of\nhidden prompts, ranging from simple positive review commands to detailed\nevaluation frameworks. The defense that prompts served as \"honeypots\" to detect\nreviewers improperly using AI fails under examination--the consistently\nself-serving nature of prompt instructions indicates intent to manipulate.\nPublishers maintain inconsistent policies: Elsevier prohibits AI use in peer\nreview entirely, while Springer Nature permits limited use with disclosure\nrequirements. The incident exposes systematic vulnerabilities extending beyond\npeer review to any automated system processing scholarly texts, including\nplagiarism detection and citation indexing. Our analysis underscores the need\nfor coordinated technical screening at submission portals and harmonized\npolicies governing generative AI (GenAI) use in academic evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06185v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2503.12149", "title": "Seeing Sarcasm Through Different Eyes: Analyzing Multimodal Sarcasm Perception in Large Vision-Language Models", "authors": ["Junjie Chen", "Xuyang Liu", "Subin Huang", "Linfeng Zhang", "Hang Yu"], "categories": ["cs.CL", "cs.MM", "cs.SI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.12149v2", "summary": "With the advent of large vision-language models (LVLMs) demonstrating\nincreasingly human-like abilities, a pivotal question emerges: do different\nLVLMs interpret multimodal sarcasm differently, and can a single model grasp\nsarcasm from multiple perspectives like humans? To explore this, we introduce\nan analytical framework using systematically designed prompts on existing\nmultimodal sarcasm datasets. Evaluating 12 state-of-the-art LVLMs over 2,409\nsamples, we examine interpretive variations within and across models, focusing\non confidence levels, alignment with dataset labels, and recognition of\nambiguous \"neutral\" cases. Our findings reveal notable discrepancies -- across\nLVLMs and within the same model under varied prompts. While\nclassification-oriented prompts yield higher internal consistency, models\ndiverge markedly when tasked with interpretive reasoning. These results\nchallenge binary labeling paradigms by highlighting sarcasm's subjectivity. We\nadvocate moving beyond rigid annotation schemes toward multi-perspective,\nuncertainty-aware modeling, offering deeper insights into multimodal sarcasm\ncomprehension. Our code and data are available at:\nhttps://github.com/CoderChen01/LVLMSarcasmAnalysis", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.12149v2", "cate": "cs.CL", "date": "2025-03-15", "updated": "2025-07-08"}
{"id": "2507.05781", "title": "Text-Guided Token Communication for Wireless Image Transmission", "authors": ["Bole Liu", "Li Qiao", "Ye Wang", "Zhen Gao", "Yu Ma", "Keke Ying", "Tong Qin"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05781v1", "summary": "With the emergence of 6G networks and proliferation of visual applications,\nefficient image transmission under adverse channel conditions is critical. We\npresent a text-guided token communication system leveraging pre-trained\nfoundation models for wireless image transmission with low bandwidth. Our\napproach converts images to discrete tokens, applies 5G NR polar coding, and\nemploys text-guided token prediction for reconstruction. Evaluations on\nImageNet show our method outperforms Deep Source Channel Coding with Attention\nModules (ADJSCC) in perceptual quality and semantic preservation at\nSignal-to-Noise Ratios (SNRs) above 0 dB while mitigating the cliff effect at\nlower SNRs. Our system requires no scenario-specific retraining and exhibits\nsuperior cross-dataset generalization, establishing a new paradigm for\nefficient image transmission aligned with human perceptual priorities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05781v1", "cate": "cs.IT", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05829", "title": "Intra-DP: A High Performance Collaborative Inference System for Mobile Edge Computing", "authors": ["Zekai Sun", "Xiuxian Guan", "Zheng Lin", "Zihan Fang", "Xiangming Cai", "Zhe Chen", "Fangming Liu", "Heming Cui", "Jie Xiong", "Wei Ni", "Chau Yuen"], "categories": ["cs.NI", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      14 pages, 19 figures", "url": "http://arxiv.org/abs/2507.05829v1", "summary": "Deploying deep neural networks (DNNs) on resource-constrained mobile devices\npresents significant challenges, particularly in achieving real-time\nperformance while simultaneously coping with limited computational resources\nand battery life. While Mobile Edge Computing (MEC) offers collaborative\ninference with GPU servers as a promising solution, existing approaches\nprimarily rely on layer-wise model partitioning and undergo significant\ntransmission bottlenecks caused by the sequential execution of DNN operations.\nTo address this challenge, we present Intra-DP, a high-performance\ncollaborative inference system optimized for DNN inference on MEC. Intra DP\nemploys a novel parallel computing technique based on local operators (i.e.,\noperators whose minimum unit input is not the entire input tensor, such as the\nconvolution kernel). By decomposing their computations (operations) into\nseveral independent sub-operations and overlapping the computation and\ntransmission of different sub-operations through parallel execution, Intra-DP\nmitigates transmission bottlenecks in MEC, achieving fast and energy-efficient\ninference. The evaluation demonstrates that Intra-DP reduces per-inference\nlatency by up to 50% and energy consumption by up to 75% compared to\nstate-of-the-art baselines, without sacrificing accuracy.", "comment": "14 pages, 19 figures", "pdf_url": "http://arxiv.org/pdf/2507.05829v1", "cate": "cs.NI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06174", "title": "Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model", "authors": ["Koki Yamane", "Yunhan Li", "Masashi Konosu", "Koki Inami", "Junji Oaki", "Sho Sakaino", "Toshiaki Tsuji"], "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      19 pages, 8 figures, Submitted to CoRL 2025", "url": "http://arxiv.org/abs/2507.06174v1", "summary": "In recent years, the advancement of imitation learning has led to increased\ninterest in teleoperating low-cost manipulators to collect demonstration data.\nHowever, most existing systems rely on unilateral control, which only transmits\ntarget position values. While this approach is easy to implement and suitable\nfor slow, non-contact tasks, it struggles with fast or contact-rich operations\ndue to the absence of force feedback. This work demonstrates that fast\nteleoperation with force feedback is feasible even with force-sensorless,\nlow-cost manipulators by leveraging 4-channel bilateral control. Based on\naccurately identified manipulator dynamics, our method integrates nonlinear\nterms compensation, velocity and external force estimation, and variable gain\ncorresponding to inertial variation. Furthermore, using data collected by\n4-channel bilateral control, we show that incorporating force information into\nboth the input and output of learned policies improves performance in imitation\nlearning. These results highlight the practical effectiveness of our system for\nhigh-fidelity teleoperation and data collection on affordable hardware.", "comment": "19 pages, 8 figures, Submitted to CoRL 2025", "pdf_url": "http://arxiv.org/pdf/2507.06174v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05886", "title": "Current Practices for Building LLM-Powered Reasoning Tools Are Ad Hoc -- and We Can Do Better", "authors": ["Aaron Bembenek"], "categories": ["cs.AI", "cs.PL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures", "url": "http://arxiv.org/abs/2507.05886v1", "summary": "There is growing excitement about building software verifiers, synthesizers,\nand other Automated Reasoning (AR) tools by combining traditional symbolic\nalgorithms and Large Language Models (LLMs). Unfortunately, the current\npractice for constructing such neurosymbolic AR systems is an ad hoc\nprogramming model that does not have the strong guarantees of traditional\nsymbolic algorithms, nor a deep enough synchronization of neural networks and\nsymbolic reasoning to unlock the full potential of LLM-powered reasoning. I\npropose Neurosymbolic Transition Systems as a principled computational model\nthat can underlie infrastructure for building neurosymbolic AR tools. In this\nmodel, symbolic state is paired with intuition, and state transitions operate\nover symbols and intuition in parallel. I argue why this new paradigm can scale\nlogical reasoning beyond current capabilities while retaining the strong\nguarantees of symbolic algorithms, and I sketch out how the computational model\nI propose can be reified in a logic programming language.", "comment": "6 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.05886v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05507", "title": "Dynamic Campus Origin-Destination Mobility Prediction using Graph Convolutional Neural Network on WiFi Logs", "authors": ["Godwin Badu-Marfo", "Bilal Farooq"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05507v1", "summary": "We present an integrated graph-based neural networks architecture for\npredicting campus buildings occupancy and inter-buildings movement at dynamic\ntemporal resolution that learns traffic flow patterns from Wi-Fi logs combined\nwith the usage schedules within the buildings. The relative traffic flows are\ndirectly estimated from the WiFi data without assuming the occupant behaviour\nor preferences while maintaining individual privacy. We formulate the problem\nas a data-driven graph structure represented by a set of nodes (representing\nbuildings), connected through a route of edges or links using a novel Graph\nConvolution plus LSTM Neural Network (GCLSTM) which has shown remarkable\nsuccess in modelling complex patterns. We describe the formulation, model\nestimation, interpretability and examine the relative performance of our\nproposed model. We also present an illustrative architecture of the models and\napply on real-world WiFi logs collected at the Toronto Metropolitan University\ncampus. The results of the experiments show that the integrated GCLSTM models\nsignificantly outperform traditional pedestrian flow estimators like the Multi\nLayer Perceptron (MLP) and Linear Regression.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05507v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05513", "title": "Llama Nemoretriever Colembed: Top-Performing Text-Image Retrieval Model", "authors": ["Mengyao Xu", "Gabriel Moreira", "Ronay Ak", "Radek Osmulski", "Yauhen Babakhin", "Zhiding Yu", "Benedikt Schifferer", "Even Oldridge"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05513v1", "summary": "Motivated by the growing demand for retrieval systems that operate across\nmodalities, we introduce llama-nemoretriever-colembed, a unified text-image\nretrieval model that delivers state-of-the-art performance across multiple\nbenchmarks. We release two model variants, 1B and 3B. The 3B model achieves\nstate of the art performance, scoring NDCG@5 91.0 on ViDoRe V1 and 63.5 on\nViDoRe V2, placing first on both leaderboards as of June 27, 2025.\n  Our approach leverages the NVIDIA Eagle2 Vision-Language model (VLM),\nmodifies its architecture by replacing causal attention with bidirectional\nattention, and integrates a ColBERT-style late interaction mechanism to enable\nfine-grained multimodal retrieval in a shared embedding space. While this\nmechanism delivers superior retrieval accuracy, it introduces trade-offs in\nstorage and efficiency. We provide a comprehensive analysis of these\ntrade-offs. Additionally, we adopt a two-stage training strategy to enhance the\nmodel's retrieval capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05513v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05995", "title": "PromiseTune: Unveiling Causally Promising and Explainable Configuration Tuning", "authors": ["Pengzhou Chen", "Tao Chen"], "categories": ["cs.SE", "68Nxx", "D.2.0; D.2.8"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by ICSE26", "url": "http://arxiv.org/abs/2507.05995v1", "summary": "The high configurability of modern software systems has made configuration\ntuning a crucial step for assuring system performance, e.g., latency or\nthroughput. However, given the expensive measurements, large configuration\nspace, and rugged configuration landscape, existing tuners suffer\nineffectiveness due to the difficult balance of budget utilization between\nexploring uncertain regions (for escaping from local optima) and exploiting\nguidance of known good configurations (for fast convergence). The root cause is\nthat we lack knowledge of where the promising regions lay, which also causes\nchallenges in the explainability of the results.\n  In this paper, we propose PromiseTune that tunes configuration guided by\ncausally purified rules. PromiseTune is unique in the sense that we learn\nrules, which reflect certain regions in the configuration landscape, and purify\nthem with causal inference. The remaining rules serve as approximated\nreflections of the promising regions, bounding the tuning to emphasize these\nplaces in the landscape. This, as we demonstrate, can effectively mitigate the\nimpact of the exploration and exploitation trade-off. Those purified regions\ncan then be paired with the measured configurations to provide spatial\nexplainability at the landscape level. Comparing with 11 state-of-the-art\ntuners on 12 systems and varying budgets, we show that PromiseTune performs\nsignificantly better than the others with $42\\%$ superior rank to the overall\nsecond best while providing richer information to explain the hidden system\ncharacteristics.", "comment": "This paper has been accepted by ICSE26", "pdf_url": "http://arxiv.org/pdf/2507.05995v1", "cate": "cs.SE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2409.15471", "title": "EvAlignUX: Advancing UX Evaluation through LLM-Supported Metrics Exploration", "authors": ["Qingxiao Zheng", "Minrui Chen", "Pranav Sharma", "Yiliu Tang", "Mehul Oswal", "Yiren Liu", "Yun Huang"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.15471v2", "summary": "Evaluating UX in the context of AI's complexity, unpredictability, and\ngenerative nature presents unique challenges. How can we support HCI\nresearchers to create comprehensive UX evaluation plans? In this paper, we\nintroduce EvAlignUX, a system powered by large language models and grounded in\nscientific literature, designed to help HCI researchers explore evaluation\nmetrics and their relationship to research outcomes. A user study with 19 HCI\nscholars showed that EvAlignUX improved the perceived quality and confidence in\nUX evaluation plans while prompting deeper consideration of research impact and\nrisks. The system enhanced participants' thought processes, leading to the\ncreation of a ``UX Question Bank'' to guide UX evaluation development. Findings\nalso highlight how researchers' backgrounds influence their inspiration and\nconcerns about AI over-reliance, pointing to future research on AI's role in\nfostering critical thinking. In a world where experience defines impact, we\ndiscuss the importance of shifting UX evaluation from a ``method-centric'' to a\n``mindset-centric'' approach as the key to meaningful and lasting design\nevaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.15471v2", "cate": "cs.HC", "date": "2024-09-23", "updated": "2025-07-07"}
{"id": "2507.05784", "title": "Does Movable Antenna Present A Dual-edged Nature? From the Perspective of Physical Layer Security: A Joint Design of Fixed-position Antenna and Movable Antenna", "authors": ["Kan Yu", "Wenxu Wang", "Xiaowu Liu", "Yujia Zhao", "Qixun Zhang", "Zhiyong Feng", "Dong Li"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05784v1", "summary": "In conventional artificial noise (AN)-aided physical-layer security systems,\nfixed-position antenna (FPA) arrays exhibit inherent vulnerability to coverage\ngaps due to their static spatial configuration. Adversarial eavesdroppers can\nstrategically exploit their mobility to infiltrate these spatial nulls of AN\nradiation patterns, thereby evading interference suppression and successfully\nintercepting the confidential communication. To overcome this limitation, in\nthis paper, we investigate a hybrid antenna deployment framework integrating\nFPA arrays and movable antenna (MA) arrays (denoted by FMA co-design) to\naddress the security performance in dynamic wireless environments, based on the\nfact that MA arrays enable channel reconfiguration through localized antenna\nrepositioning, achieving more higher spatial degree of freedom (DoF). Enabled\nby FMA co-design framework, FPA arrays ensure baseline connectivity for\nlegitimate links while MA arrays function as dynamic security enhancers,\nreplacing conventional static AN generation. Furthermore, we formulate a\nnon-convex optimization problem of the secrecy rate maximization through\njointly optimizing MA positioning, FPA beamforming, and MA beamforming under\npractical constraints. the solution employs a dual-algorithm approach: Nesterov\nmomentum-based projected gradient ascent (NMPGA) accelerates convergence in\ncontinuous position optimization, while alternating optimization (AO) handles\ncoupled beamforming design. Experimental evaluations demonstrate that the\nproposed FMA co-design framework achieves significant secrecy performance gains\nover individual optimization benchmarks, yielding 42.34% and 9.12% improvements\nin secrecy rate compared to isolated FPA for AN generation and MA for\nconfidential information baselines, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05784v1", "cate": "cs.IT", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05876", "title": "OLAF: Programmable Data Plane Acceleration for Asynchronous Distributed Reinforcement Learning", "authors": ["Nehal Baganal Krishna", "Anam Tahir", "Firas Khamis", "Mina Tahmasbi Arashloo", "Michael Zink", "Amr Rizk"], "categories": ["cs.NI", "cs.AR"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      17 pages, 11 figures", "url": "http://arxiv.org/abs/2507.05876v1", "summary": "Asynchronous Distributed Reinforcement Learning (DRL) can suffer from\ndegraded convergence when model updates become stale, often the result of\nnetwork congestion and packet loss during large-scale training. This work\nintroduces a network data-plane acceleration architecture that mitigates such\nstaleness by enabling inline processing of DRL model updates as they traverse\nthe accelerator engine. To this end, we design and prototype a novel queueing\nmechanism that opportunistically combines compatible updates sharing a network\nelement, reducing redundant traffic and preserving update utility.\nComplementing this we provide a lightweight transmission control mechanism at\nthe worker nodes that is guided by feedback from the in-network accelerator. To\nassess model utility at line rate, we introduce the Age-of-Model (AoM) metric\nas a proxy for staleness and verify global fairness and responsiveness\nproperties using a formal verification method. Our evaluations demonstrate that\nthis architecture significantly reduces update staleness and congestion,\nultimately improving the convergence rate in asynchronous DRL workloads.", "comment": "17 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.05876v1", "cate": "cs.NI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06219", "title": "Is Diversity All You Need for Scalable Robotic Manipulation?", "authors": ["Modi Shi", "Li Chen", "Jin Chen", "Yuxiang Lu", "Chiming Liu", "Guanghui Ren", "Ping Luo", "Di Huang", "Maoqing Yao", "Hongyang Li"], "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Code is available at this https URL", "url": "http://arxiv.org/abs/2507.06219v1", "summary": "Data scaling has driven remarkable success in foundation models for Natural\nLanguage Processing (NLP) and Computer Vision (CV), yet the principles of\neffective data scaling in robotic manipulation remain insufficiently\nunderstood. In this work, we investigate the nuanced role of data diversity in\nrobot learning by examining three critical dimensions-task (what to do),\nembodiment (which robot to use), and expert (who demonstrates)-challenging the\nconventional intuition of \"more diverse is better\". Throughout extensive\nexperiments on various robot platforms, we reveal that (1) task diversity\nproves more critical than per-task demonstration quantity, benefiting transfer\nfrom diverse pre-training tasks to novel downstream scenarios; (2)\nmulti-embodiment pre-training data is optional for cross-embodiment\ntransfer-models trained on high-quality single-embodiment data can efficiently\ntransfer to different platforms, showing more desirable scaling property during\nfine-tuning than multi-embodiment pre-trained models; and (3) expert diversity,\narising from individual operational preferences and stochastic variations in\nhuman demonstrations, can be confounding to policy learning, with velocity\nmultimodality emerging as a key contributing factor. Based on this insight, we\npropose a distribution debiasing method to mitigate velocity ambiguity, the\nyielding GO-1-Pro achieves substantial performance gains of 15%, equivalent to\nusing 2.5 times pre-training data. Collectively, these findings provide new\nperspectives and offer practical guidance on how to scale robotic manipulation\ndatasets effectively.", "comment": "Code is available at https://github.com/OpenDriveLab/AgiBot-World", "pdf_url": "http://arxiv.org/pdf/2507.06219v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05891", "title": "Decomposing the Time Series Forecasting Pipeline: A Modular Approach for Time Series Representation, Information Extraction, and Projection", "authors": ["Robert Leppich", "Michael Stenger", "André Bauer", "Samuel Kounev"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05891v1", "summary": "With the advent of Transformers, time series forecasting has seen significant\nadvances, yet it remains challenging due to the need for effective sequence\nrepresentation, memory construction, and accurate target projection. Time\nseries forecasting remains a challenging task, demanding effective sequence\nrepresentation, meaningful information extraction, and precise future\nprojection. Each dataset and forecasting configuration constitutes a distinct\ntask, each posing unique challenges the model must overcome to produce accurate\npredictions. To systematically address these task-specific difficulties, this\nwork decomposes the time series forecasting pipeline into three core stages:\ninput sequence representation, information extraction and memory construction,\nand final target projection. Within each stage, we investigate a range of\narchitectural configurations to assess the effectiveness of various modules,\nsuch as convolutional layers for feature extraction and self-attention\nmechanisms for information extraction, across diverse forecasting tasks,\nincluding evaluations on seven benchmark datasets. Our models achieve\nstate-of-the-art forecasting accuracy while greatly enhancing computational\nefficiency, with reduced training and inference times and a lower parameter\ncount. The source code is available at\nhttps://github.com/RobertLeppich/REP-Net.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05891v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05508", "title": "Beyond Communication Overhead: A Multilevel Monte Carlo Approach for Mitigating Compression Bias in Distributed Learning", "authors": ["Ze'ev Zukerman", "Bassel Hamoud", "Kfir Y. Levy"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ICML 2025", "url": "http://arxiv.org/abs/2507.05508v1", "summary": "Distributed learning methods have gained substantial momentum in recent\nyears, with communication overhead often emerging as a critical bottleneck.\nGradient compression techniques alleviate communication costs but involve an\ninherent trade-off between the empirical efficiency of biased compressors and\nthe theoretical guarantees of unbiased compressors. In this work, we introduce\na novel Multilevel Monte Carlo (MLMC) compression scheme that leverages biased\ncompressors to construct statistically unbiased estimates. This approach\neffectively bridges the gap between biased and unbiased methods, combining the\nstrengths of both. To showcase the versatility of our method, we apply it to\npopular compressors, like Top-$k$ and bit-wise compressors, resulting in\nenhanced variants. Furthermore, we derive an adaptive version of our approach\nto further improve its performance. We validate our method empirically on\ndistributed deep learning tasks.", "comment": "Accepted to ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.05508v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06014", "title": "Model Cards Revisited: Bridging the Gap Between Theory and Practice for Ethical AI Requirements", "authors": ["Tim Puhlfürß", "Julia Butzke", "Walid Maalej"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted for publication at the 33rd IEEE International Requirements Engineering 2025 conference", "url": "http://arxiv.org/abs/2507.06014v1", "summary": "Model cards are the primary documentation framework for developers of\nartificial intelligence (AI) models to communicate critical information to\ntheir users. Those users are often developers themselves looking for relevant\ndocumentation to ensure that their AI systems comply with the ethical\nrequirements of existing laws, guidelines, and standards. Recent studies\nindicate inadequate model documentation practices, suggesting a gap between AI\nrequirements and current practices in model documentation. To understand this\ngap and provide actionable guidance to bridge it, we conducted a thematic\nanalysis of 26 guidelines on ethics and AI, three AI documentation frameworks,\nthree quantitative studies of model cards, and ten actual model cards. We\nidentified a total of 43 ethical requirements relevant to model documentation\nand organized them into a taxonomy featuring four themes and twelve sub-themes\nrepresenting ethical principles. Our findings indicate that model developers\npredominantly emphasize model capabilities and reliability in the documentation\nwhile overlooking other ethical aspects, such as explainability, user autonomy,\nand fairness. This underscores the need for enhanced support in documenting\nethical AI considerations. Our taxonomy serves as a foundation for a revised\nmodel card framework that holistically addresses ethical AI requirements.", "comment": "Accepted for publication at the 33rd IEEE International Requirements\n  Engineering 2025 conference", "pdf_url": "http://arxiv.org/pdf/2507.06014v1", "cate": "cs.SE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06001", "title": "Programmable Governance for Group-Controlled Decentralized Identifiers", "authors": ["Carlo Segat", "Sandro Rodriguez Garzo", "Axel Küpper"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06001v1", "summary": "Self-Sovereign Identity (SSI) is a paradigm for digital identity management\nthat offers unique privacy advantages. A key technology in SSI is Decentralized\nIdentifiers (DIDs) and their associated metadata, DID Documents (DDOs). DDOs\ncontain crucial verification material such as the public keys of the entity\nidentified by the DID (i.e., the DID subject) and are often anchored on a\ndistributed ledger to ensure security and availability. Long-lived DIDs need to\nsupport updates (e.g., key rotation). Ideally, only the DID subject should\nauthorize DDO updates. However, in practice, update capabilities may be shared\nor delegated. While the DID specification acknowledges such scenarios, it does\nnot define how updates should be authorized when multiple entities jointly\ncontrol a DID (i.e., group control). This article examines the implementation\nof an on-chain, trustless mechanism enabling DID controllers under group\ncontrol to program their governance rules. The main research question is the\nfollowing: Can a technical mechanism be developed to orchestrate on-chain group\ncontrol of a DDO in a ledger-agnostic and adaptable manner?", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06001v1", "cate": "cs.NI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06224", "title": "EC-Flow: Enabling Versatile Robotic Manipulation from Action-Unlabeled Videos via Embodiment-Centric Flow", "authors": ["Yixiang Chen", "Peiyan Li", "Yan Huang", "Jiabing Yang", "Kehan Chen", "Liang Wang"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2507.06224v1", "summary": "Current language-guided robotic manipulation systems often require low-level\naction-labeled datasets for imitation learning. While object-centric flow\nprediction methods mitigate this issue, they remain limited to scenarios\ninvolving rigid objects with clear displacement and minimal occlusion. In this\nwork, we present Embodiment-Centric Flow (EC-Flow), a framework that directly\nlearns manipulation from action-unlabeled videos by predicting\nembodiment-centric flow. Our key insight is that incorporating the embodiment's\ninherent kinematics significantly enhances generalization to versatile\nmanipulation scenarios, including deformable object handling, occlusions, and\nnon-object-displacement tasks. To connect the EC-Flow with language\ninstructions and object interactions, we further introduce a goal-alignment\nmodule by jointly optimizing movement consistency and goal-image prediction.\nMoreover, translating EC-Flow to executable robot actions only requires a\nstandard robot URDF (Unified Robot Description Format) file to specify\nkinematic constraints across joints, which makes it easy to use in practice. We\nvalidate EC-Flow on both simulation (Meta-World) and real-world tasks,\ndemonstrating its state-of-the-art performance in occluded object handling (62%\nimprovement), deformable object manipulation (45% improvement), and\nnon-object-displacement tasks (80% improvement) than prior state-of-the-art\nobject-centric flow methods. For more information, see our project website at\nhttps://ec-flow1.github.io .", "comment": "Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.06224v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05894", "title": "MusiScene: Leveraging MU-LLaMA for Scene Imagination and Enhanced Video Background Music Generation", "authors": ["Fathinah Izzati", "Xinyue Li", "Yuxuan Wu", "Gus Xia"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05894v1", "summary": "Humans can imagine various atmospheres and settings when listening to music,\nenvisioning movie scenes that complement each piece. For example, slow,\nmelancholic music might evoke scenes of heartbreak, while upbeat melodies\nsuggest celebration. This paper explores whether a Music Language Model, e.g.\nMU-LLaMA, can perform a similar task, called Music Scene Imagination (MSI),\nwhich requires cross-modal information from video and music to train. To\nimprove upon existing music captioning models which focusing solely on musical\nelements, we introduce MusiScene, a music captioning model designed to imagine\nscenes that complement each music. In this paper, (1) we construct a\nlarge-scale video-audio caption dataset with 3,371 pairs, (2) we finetune Music\nUnderstanding LLaMA for the MSI task to create MusiScene, and (3) we conduct\ncomprehensive evaluations and prove that our MusiScene is more capable of\ngenerating contextually relevant captions compared to MU-LLaMA. We leverage the\ngenerated MSI captions to enhance Video Background Music Generation (VBMG) from\ntext.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05894v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05510", "title": "Heterogeneous Causal Learning for Optimizing Aggregated Functions in User Growth", "authors": ["Shuyang Du", "Jennifer Zhang", "Will Y. Zou"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages. arXiv admin note: text overlap with arXiv:2004.09702", "url": "http://arxiv.org/abs/2507.05510v1", "summary": "User growth is a major strategy for consumer internet companies. To optimize\ncostly marketing campaigns and maximize user engagement, we propose a novel\ntreatment effect optimization methodology to enhance user growth marketing. By\nleveraging deep learning, our algorithm learns from past experiments to\noptimize user selection and reward allocation, maximizing campaign impact while\nminimizing costs. Unlike traditional prediction methods, our model directly\nmodels uplifts in key business metrics. Further, our deep learning model can\njointly optimize parameters for an aggregated loss function using softmax\ngating. Our approach surpasses traditional methods by directly targeting\ndesired business metrics and demonstrates superior algorithmic flexibility in\nhandling complex business constraints. Comprehensive evaluations, including\ncomparisons with state-of-the-art techniques such as R-learner and Causal\nForest, validate the effectiveness of our model. We experimentally demonstrate\nthat our proposed constrained and direct optimization algorithms significantly\noutperform state-of-the-art methods by over $20\\%$, proving their\ncost-efficiency and real-world impact. The versatile methods can be applied to\nvarious product scenarios, including optimal treatment allocation. Its\neffectiveness has also been validated through successful worldwide production\ndeployments.", "comment": "11 pages. arXiv admin note: text overlap with arXiv:2004.09702", "pdf_url": "http://arxiv.org/pdf/2507.05510v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05568", "title": "ReLayout: Integrating Relation Reasoning for Content-aware Layout Generation with Multi-modal Large Language Models", "authors": ["Jiaxu Tian", "Xuehui Yu", "Yaoxing Wang", "Pan Wang", "Guangqian Guo", "Shan Gao"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05568v1", "summary": "Content-aware layout aims to arrange design elements appropriately on a given\ncanvas to convey information effectively. Recently, the trend for this task has\nbeen to leverage large language models (LLMs) to generate layouts\nautomatically, achieving remarkable performance. However, existing LLM-based\nmethods fail to adequately interpret spatial relationships among visual themes\nand design elements, leading to structural and diverse problems in layout\ngeneration. To address this issue, we introduce ReLayout, a novel method that\nleverages relation-CoT to generate more reasonable and aesthetically coherent\nlayouts by fundamentally originating from design concepts. Specifically, we\nenhance layout annotations by introducing explicit relation definitions, such\nas region, salient, and margin between elements, with the goal of decomposing\nthe layout into smaller, structured, and recursive layouts, thereby enabling\nthe generation of more structured layouts. Furthermore, based on these defined\nrelationships, we introduce a layout prototype rebalance sampler, which defines\nlayout prototype features across three dimensions and quantifies distinct\nlayout styles. This sampler addresses uniformity issues in generation that\narise from data bias in the prototype distribution balance process. Extensive\nexperimental results verify that ReLayout outperforms baselines and can\ngenerate structural and diverse layouts that are more aligned with human\naesthetics and more explainable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05568v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05305", "title": "Narrowing the Gap: Supervised Fine-Tuning of Open-Source LLMs as a Viable Alternative to Proprietary Models for Pedagogical Tools", "authors": ["Lorenzo Lee Solano", "Charles Koutcheme", "Juho Leinonen", "Alexandra Vassar", "Jake Renzella"], "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.SE"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      7 pages, 3 tables, 1 figure", "url": "http://arxiv.org/abs/2507.05305v1", "summary": "Frontier Large language models (LLMs) like ChatGPT and Gemini can decipher\ncryptic compiler errors for novice programmers, but their computational scale,\ncost, and tendency to over-assist make them problematic for widespread\npedagogical adoption. This work demonstrates that smaller, specialised language\nmodels, enhanced via Supervised Fine-Tuning (SFT), present a more viable\nalternative for educational tools. We utilise a new dataset of 40,000 C\ncompiler error explanations, derived from real introductory programming (CS1/2)\nstudent-generated programming errors, which we used to fine-tune three\nopen-source models: Qwen3-4B, Llama-3.1-8B, and Qwen3-32B. We performed a dual\nevaluation, combining expert human reviews with a large-scale automated\nanalysis of 8,000 responses using a validated LLM-as-judge ensemble. Our\nresults show that SFT significantly boosts the pedagogical quality of smaller\nmodels, achieving performance comparable to much larger models. We analyse the\ntrade-offs between model size and quality, confirming that fine-tuning compact,\nefficient models on high-quality, domain-specific data is a potent strategy for\ncreating specialised models to drive educational tools. We provide a replicable\nmethodology to foster broader access to generative AI capabilities in\neducational contexts.", "comment": "7 pages, 3 tables, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.05305v1", "cate": "cs.CY", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2412.16256", "title": "Aria-UI: Visual Grounding for GUI Instructions", "authors": ["Yuhao Yang", "Yue Wang", "Dongxu Li", "Ziyang Luo", "Bei Chen", "Chao Huang", "Junnan Li"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      ACL 2025", "url": "http://arxiv.org/abs/2412.16256v2", "summary": "Digital agents for automating tasks across different platforms by directly\nmanipulating the GUIs are increasingly important. For these agents, grounding\nfrom language instructions to target elements remains a significant challenge\ndue to reliance on HTML or AXTree inputs. In this paper, we introduce Aria-UI,\na large multimodal model specifically designed for GUI grounding. Aria-UI\nadopts a pure-vision approach, eschewing reliance on auxiliary inputs. To adapt\nto heterogeneous planning instructions, we propose a scalable data pipeline\nthat synthesizes diverse and high-quality instruction samples for grounding. To\nhandle dynamic contexts in task performing, Aria-UI incorporates textual and\ntext-image interleaved action histories, enabling robust context-aware\nreasoning for grounding. Aria-UI sets new state-of-the-art results across\noffline and online agent benchmarks, outperforming both vision-only and\nAXTree-reliant baselines. We release all training data and model checkpoints to\nfoster further research at https://ariaui.github.io.", "comment": "ACL 2025", "pdf_url": "http://arxiv.org/pdf/2412.16256v2", "cate": "cs.HC", "date": "2024-12-20", "updated": "2025-07-08"}
{"id": "2507.05878", "title": "An Effective Equivalence Model of Analyzing PLS of Multiple Eavesdroppers Facing Low-altitude Communication Systems", "authors": ["Yujia Zhao", "Zhiyong Feng", "Kan Yu", "Qixun Zhang", "Dong Li"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05878v1", "summary": "In low-altitude wireless communications, the increased complexity of wireless\nchannels and the uncertainty of eavesdroppers (Eves)--caused by diverse\naltitudes, speeds, and obstacles--pose significant challenges to physical layer\nsecurity (PLS) technologies based on fixed-position antennas (FPAs),\nparticularly in terms of beamforming capabilities and spatial efficiency. In\ncontrast, movable antennas (MAs) offer a flexible solution by enabling channel\nreconstruction through antenna movement, effectively compensating for the\nlimitations of FPAs. In this paper, we aim to derive a closed-form expression\nfor the secrecy rate, a key metric in PLS, which is often unattainable in\ncurrent studies due to the uncertainty of Eves. We construct an equivalent\nmodel that leverages the reconfigurable nature of MAs, equating the secrecy\nrates obtained by multiple Eves with single FPAs to those achieved by a single\nvirtual Eve equipped with an MA array. To minimize the gap between these two\ntypes of secrecy rates, we formulate and solve an optimization problem by\njointly designing the equivalent distance between the transmitter and the\nvirtual Eve} and the antenna positions of MAs at the virtual Eve. Numerical\nsimulations validate the effectiveness of the proposed equivalent model,\noffering a new perspective for PLS strategies. This work provides significant\ninsights for network designers on how system parameters affect PLS performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05878v1", "cate": "cs.IT", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2503.23669", "title": "Multi-Agent Deep Reinforcement Learning for Optimized Multi-UAV Coverage and Power-Efficient UE Connectivity", "authors": ["Xuli Cai", "Poonam Lohan", "Burak Kantarci"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures, accepted to IEEE PIMRC 2025", "url": "http://arxiv.org/abs/2503.23669v2", "summary": "In critical situations such as natural disasters, network outages,\nbattlefield communication, or large-scale public events, Unmanned Aerial\nVehicles (UAVs) offer a promising approach to maximize wireless coverage for\naffected users in the shortest possible time. In this paper, we propose a novel\nframework where multiple UAVs are deployed with the objective to maximize the\nnumber of served user equipment (UEs) while ensuring a predefined data rate\nthreshold. UEs are initially clustered using a K-means algorithm, and UAVs are\noptimally positioned based on the UEs' spatial distribution. To optimize power\nallocation and mitigate inter-cluster interference, we employ the Multi-Agent\nDeep Deterministic Policy Gradient (MADDPG) algorithm, considering both LOS and\nNLOS fading. Simulation results demonstrate that our method significantly\nenhances UEs coverage and outperforms Deep Q-Network (DQN) and equal power\ndistribution methods, improving their UE coverage by up to 2.07 times and 8.84\ntimes, respectively.", "comment": "6 pages, 5 figures, accepted to IEEE PIMRC 2025", "pdf_url": "http://arxiv.org/pdf/2503.23669v2", "cate": "cs.NI", "date": "2025-03-31", "updated": "2025-07-08"}
{"id": "2507.05698", "title": "Event-RGB Fusion for Spacecraft Pose Estimation Under Harsh Lighting", "authors": ["Mohsi Jawaid", "Marcus Märtens", "Tat-Jun Chin"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05698v1", "summary": "Spacecraft pose estimation is crucial for autonomous in-space operations,\nsuch as rendezvous, docking and on-orbit servicing. Vision-based pose\nestimation methods, which typically employ RGB imaging sensors, is a compelling\nsolution for spacecraft pose estimation, but are challenged by harsh lighting\nconditions, which produce imaging artifacts such as glare, over-exposure,\nblooming and lens flare. Due to their much higher dynamic range, neuromorphic\nor event sensors are more resilient to extreme lighting conditions. However,\nevent sensors generally have lower spatial resolution and suffer from reduced\nsignal-to-noise ratio during periods of low relative motion. This work\naddresses these individual sensor limitations by introducing a sensor fusion\napproach combining RGB and event sensors. A beam-splitter prism was employed to\nachieve precise optical and temporal alignment. Then, a RANSAC-based technique\nwas developed to fuse the information from the RGB and event channels to\nachieve pose estimation that leveraged the strengths of the two modalities. The\npipeline was complemented by dropout uncertainty estimation to detect extreme\nconditions that affect either channel. To benchmark the performance of the\nproposed event-RGB fusion method, we collected a comprehensive real dataset of\nRGB and event data for satellite pose estimation in a laboratory setting under\na variety of challenging illumination conditions. Encouraging results on the\ndataset demonstrate the efficacy of our event-RGB fusion approach and further\nsupports the usage of event sensors for spacecraft pose estimation. To support\ncommunity research on this topic, our dataset will be released publicly.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05698v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05934", "title": "BlueLM-2.5-3B Technical Report", "authors": ["Baojiao Xiong", "Boheng Chen", "Chengzhi Wang", "Daxiong Luo", "Dongsheng Xu", "Dongyang Liu", "Fan Yang", "Fangyuan Li", "Fei Teng", "Feng Wang", "Fukang Qin", "Fuquan Peng", "Guanxin Tan", "Guozhi Wang", "Haibo Yu", "Haohao Gao", "Heng Liu", "Hongbo Yang", "Hongjian Zou", "Houzheng Shen", "Hu Meng", "Huan Li", "Hui Tan", "Jiali Chen", "Jianzhao Chen", "Jinliang Zhu", "Kai Wang", "Lei Wu", "Liangbing Liu", "Liuyang Bian", "Liyan He", "Long Liu", "Peiwen Li", "Penggang Shi", "Qi Ding", "Rui Hu", "Shuai Cao", "Shuai Ren", "Shuang Peng", "Teng Xie", "Weiji Chen", "Weilin Xiang", "Weixin Wu", "Xi Yin", "Xiaoxin Chen", "Xu Chen", "Yafei Wen", "Yan Hu", "Yanzhou Yang", "Yina Xie", "Yinghao Chen", "Yixuan Liao", "Yu Geng", "Yuanjiang Ouyang", "Yuanzhuo Yang", "Yuehua He", "Yushuai Peng", "Zhaoxiong Wang", "Zheng Wang", "Zhibo Zhou", "Ziyang Wu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05934v1", "summary": "We present BlueLM-2.5-3B, a compact and unified dense Multimodal Large\nLanguage Model (MLLM) designed for efficient edge-device deployment, offering\nstrong general-purpose and reasoning capabilities. To the best of our\nknowledge, this is the first 3B-scale MLLM to support both thinking and\nnon-thinking modes, while also enabling explicit control over thinking token\nbudget. BlueLM-2.5-3B is developed through diversified data curation, key data\nresampling, hybrid heterogeneous reinforcement learning, and a high-performance\ntraining infrastructure. Our model achieves superior multimodal capacity while\npreserving competitive pure-text performance with only 2.9 billion parameters.\nWe conduct comprehensive evaluations across a broad range of multimodal and\ntext-only benchmarks. In thinking mode, BlueLM-2.5-3B achieves comparable\nperformance to Qwen3-4B on text-only benchmarks, and trails the larger\nKimi-VL-A3B-16B by only about 5% on average across multimodal evaluations. In\nnon-thinking mode, it outperforms Qwen2.5-VL-3B on the majority of multimodal\nbenchmarks. Additionally, BlueLM-2.5-3B exhibits exceptional data efficiency.\nAll of the aforementioned performance is achieved with substantially less total\ntraining data than Qwen2.5-VL-3B and Qwen3-4B. We hope our work contributes to\nthe advancement of high-performance, on-device MLLMs and provides meaningful\ninsights to the research community.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05934v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05511", "title": "Deep Learning of Continuous and Structured Policies for Aggregated Heterogeneous Treatment Effects", "authors": ["Jennifer Y. Zhang", "Shuyang Du", "Will Y. Zou"], "categories": ["cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.05511v1", "summary": "As estimation of Heterogeneous Treatment Effect (HTE) is increasingly adopted\nacross a wide range of scientific and industrial applications, the treatment\naction space can naturally expand, from a binary treatment variable to a\nstructured treatment policy. This policy may include several policy factors\nsuch as a continuous treatment intensity variable, or discrete treatment\nassignments. From first principles, we derive the formulation for incorporating\nmultiple treatment policy variables into the functional forms of individual and\naverage treatment effects. Building on this, we develop a methodology to\ndirectly rank subjects using aggregated HTE functions. In particular, we\nconstruct a Neural-Augmented Naive Bayes layer within a deep learning framework\nto incorporate an arbitrary number of factors that satisfies the Naive Bayes\nassumption. The factored layer is then applied with continuous treatment\nvariables, treatment assignment, and direct ranking of aggregated treatment\neffect functions. Together, these algorithms build towards a generic framework\nfor deep learning of heterogeneous treatment policies, and we show their power\nto improve performance with public datasets.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.05511v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05575", "title": "Multi-Modal Face Anti-Spoofing via Cross-Modal Feature Transitions", "authors": ["Jun-Xiong Chong", "Fang-Yu Hsu", "Ming-Tsung Hsu", "Yi-Ting Lin", "Kai-Heng Chien", "Chiou-Ting Hsu", "Pei-Kai Huang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05575v1", "summary": "Multi-modal face anti-spoofing (FAS) aims to detect genuine human presence by\nextracting discriminative liveness cues from multiple modalities, such as RGB,\ninfrared (IR), and depth images, to enhance the robustness of biometric\nauthentication systems. However, because data from different modalities are\ntypically captured by various camera sensors and under diverse environmental\nconditions, multi-modal FAS often exhibits significantly greater distribution\ndiscrepancies across training and testing domains compared to single-modal FAS.\nFurthermore, during the inference stage, multi-modal FAS confronts even greater\nchallenges when one or more modalities are unavailable or inaccessible. In this\npaper, we propose a novel Cross-modal Transition-guided Network (CTNet) to\ntackle the challenges in the multi-modal FAS task. Our motivation stems from\nthat, within a single modality, the visual differences between live faces are\ntypically much smaller than those of spoof faces. Additionally, feature\ntransitions across modalities are more consistent for the live class compared\nto those between live and spoof classes. Upon this insight, we first propose\nlearning consistent cross-modal feature transitions among live samples to\nconstruct a generalized feature space. Next, we introduce learning the\ninconsistent cross-modal feature transitions between live and spoof samples to\neffectively detect out-of-distribution (OOD) attacks during inference. To\nfurther address the issue of missing modalities, we propose learning\ncomplementary infrared (IR) and depth features from the RGB modality as\nauxiliary modalities. Extensive experiments demonstrate that the proposed CTNet\noutperforms previous two-class multi-modal FAS methods across most protocols.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05575v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05573", "title": "Prompt Migration: Stabilizing GenAI Applications with Evolving Large Language Models", "authors": ["Shivani Tripathi", "Pushpanjali Nema", "Aditya Halder", "Shi Qiao", "Alekh Jindal"], "categories": ["cs.DB", "cs.AI", "cs.SE"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05573v1", "summary": "Generative AI is transforming business applications by enabling natural\nlanguage interfaces and intelligent automation. However, the underlying large\nlanguage models (LLMs) are evolving rapidly and so prompting them consistently\nis a challenge. This leads to inconsistent and unpredictable application\nbehavior, undermining the reliability that businesses require for\nmission-critical workflows. In this paper, we introduce the concept of prompt\nmigration as a systematic approach to stabilizing GenAI applications amid\nchanging LLMs. Using the Tursio enterprise search application as a case study,\nwe analyze the impact of successive GPT model upgrades, detail our migration\nframework including prompt redesign and a migration testbed, and demonstrate\nhow these techniques restore application consistency. Our results show that\nstructured prompt migration can fully recover the application reliability that\nwas lost due to model drift. We conclude with practical lessons learned,\nemphasizing the need for prompt lifecycle management and robust testing to\nensure dependable GenAI-powered business applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05573v1", "cate": "cs.DB", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2501.09530", "title": "Make yourself comfortable: Nudging urban heat and noise mitigation with smartwatch-based Just-in-time Adaptive Interventions (JITAI)", "authors": ["Clayton Miller", "Yun Xuan Chua", "Matias Quintana", "Binyu Lei", "Filip Biljecki", "Mario Frei"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.09530v2", "summary": "Humans can play a more active role in improving their comfort in the built\nenvironment if given the right information at the right place and time. This\npaper outlines the use of Just-in-Time Adaptive Interventions (JITAI)\nimplemented in the context of the built environment to provide information that\nhelps humans minimize the impact of heat and noise on their daily lives. This\nframework is based on the open-source Cozie iOS smartwatch platform. It\nincludes data collection through micro-surveys and intervention messages\ntriggered by environmental, contextual, and personal history conditions. An\neight-month deployment of the method was completed in Singapore with 103\nparticipants who submitted more than 12,000 micro-surveys and had more than\n3,600 JITAI intervention messages delivered to them. A weekly survey conducted\nduring two deployment phases revealed an overall increase in perceived\nusefulness ranging from 8-19% over the first three weeks of data collection.\nFor noise-related interventions, participants showed an overall increase in\nlocation changes ranging from 4-11% and a 2-17% increase in earphone use to\nmitigate noise distractions. For thermal comfort-related interventions,\nparticipants demonstrated a 3-13\\% increase in adjustments to their location or\nthermostat to feel more comfortable. The analysis found evidence that\npersonality traits (such as conscientiousness), gender, and environmental\npreferences could be factors in determining the perceived helpfulness of JITAIs\nand influencing behavior change. These findings underscore the importance of\ntailoring intervention strategies to individual traits and environmental\nconditions, setting the stage for future research to refine the delivery,\ntiming, and content of intervention messages.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.09530v2", "cate": "cs.HC", "date": "2025-01-16", "updated": "2025-07-08"}
{"id": "2506.15011", "title": "GCN-Driven Reinforcement Learning for Probabilistic Real-Time Guarantees in Industrial URLLC", "authors": ["Eman Alqudah", "Ashfaq Khokhar"], "categories": ["cs.NI", "cs.LG"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      This paper has been submitted to IEEE MASS 2025 on May 7, 2025. arXiv admin note: text overlap with arXiv:2506.14987", "url": "http://arxiv.org/abs/2506.15011v2", "summary": "Ensuring packet-level communication quality is vital for ultra-reliable,\nlow-latency communications (URLLC) in large-scale industrial wireless networks.\nWe enhance the Local Deadline Partition (LDP) algorithm by introducing a Graph\nConvolutional Network (GCN) integrated with a Deep Q-Network (DQN)\nreinforcement learning framework for improved interference coordination in\nmulti-cell, multi-channel networks. Unlike LDP's static priorities, our\napproach dynamically learns link priorities based on real-time traffic demand,\nnetwork topology, remaining transmission opportunities, and interference\npatterns. The GCN captures spatial dependencies, while the DQN enables adaptive\nscheduling decisions through reward-guided exploration. Simulation results show\nthat our GCN-DQN model achieves mean SINR improvements of 179.6\\%, 197.4\\%, and\n175.2\\% over LDP across three network configurations. Additionally, the GCN-DQN\nmodel demonstrates mean SINR improvements of 31.5\\%, 53.0\\%, and 84.7\\% over\nour previous CNN-based approach across the same configurations. These results\nunderscore the effectiveness of our GCN-DQN model in addressing complex URLLC\nrequirements with minimal overhead and superior network performance.", "comment": "This paper has been submitted to IEEE MASS 2025 on May 7, 2025. arXiv\n  admin note: text overlap with arXiv:2506.14987", "pdf_url": "http://arxiv.org/pdf/2506.15011v2", "cate": "cs.NI", "date": "2025-06-17", "updated": "2025-07-07"}
{"id": "2507.05867", "title": "Assessing Linear Control Strategies for Zero-Speed Fin Roll Damping", "authors": ["Nikita Savin", "Elena Ambrosovskaya", "Dmitry Romaev", "Anton Proskurnikov"], "categories": ["eess.SY", "cs.RO", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05867v1", "summary": "Roll stabilization is a critical aspect of ship motion control, particularly\nfor vessels operating in low-speed or zero-speed conditions, where traditional\nhydrodynamic fins lose their effectiveness. In this paper, we consider a roll\ndamping system, developed by Navis JSC, based on two actively controlled\nzero-speed fins. Unlike conventional fin stabilizers, zero-speed fins employ a\ndrag-based mechanism and active oscillations to generate stabilizing forces\neven when the vessel is stationary. We propose a simple linear control\narchitecture that, however, accounts for nonlinear drag forces and actuator\nlimitations. Simulation results on a high-fidelity vessel model used for HIL\ntesting demonstrate the effectiveness of the proposed approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05867v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05938", "title": "A Wireless Foundation Model for Multi-Task Prediction", "authors": ["Yucheng Sheng", "Jiacheng Wang", "Xingyu Zhou", "Le Liang", "Hao Ye", "Shi Jin", "Geoffrey Ye Li"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05938v1", "summary": "With the growing complexity and dynamics of the mobile communication\nnetworks, accurately predicting key system parameters, such as channel state\ninformation (CSI), user location, and network traffic, has become essential for\na wide range of physical (PHY)-layer and medium access control (MAC)-layer\ntasks. Although traditional deep learning (DL)-based methods have been widely\napplied to such prediction tasks, they often struggle to generalize across\ndifferent scenarios and tasks. In response, we propose a unified foundation\nmodel for multi-task prediction in wireless networks that supports diverse\nprediction intervals. The proposed model enforces univariate decomposition to\nunify heterogeneous tasks, encodes granularity for interval awareness, and uses\na causal Transformer backbone for accurate predictions. Additionally, we\nintroduce a patch masking strategy during training to support arbitrary input\nlengths. After trained on large-scale datasets, the proposed foundation model\ndemonstrates strong generalization to unseen scenarios and achieves zero-shot\nperformance on new tasks that surpass traditional full-shot baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05938v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05526", "title": "Estimating Interventional Distributions with Uncertain Causal Graphs through Meta-Learning", "authors": ["Anish Dhir", "Cristiana Diaconu", "Valentinian Mihai Lungu", "James Requeima", "Richard E. Turner", "Mark van der Wilk"], "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05526v1", "summary": "In scientific domains -- from biology to the social sciences -- many\nquestions boil down to \\textit{What effect will we observe if we intervene on a\nparticular variable?} If the causal relationships (e.g.~a causal graph) are\nknown, it is possible to estimate the intervention distributions. In the\nabsence of this domain knowledge, the causal structure must be discovered from\nthe available observational data. However, observational data are often\ncompatible with multiple causal graphs, making methods that commit to a single\nstructure prone to overconfidence. A principled way to manage this structural\nuncertainty is via Bayesian inference, which averages over a posterior\ndistribution on possible causal structures and functional mechanisms.\nUnfortunately, the number of causal structures grows super-exponentially with\nthe number of nodes in the graph, making computations intractable. We propose\nto circumvent these challenges by using meta-learning to create an end-to-end\nmodel: the Model-Averaged Causal Estimation Transformer Neural Process\n(MACE-TNP). The model is trained to predict the Bayesian model-averaged\ninterventional posterior distribution, and its end-to-end nature bypasses the\nneed for expensive calculations. Empirically, we demonstrate that MACE-TNP\noutperforms strong Bayesian baselines. Our work establishes meta-learning as a\nflexible and scalable paradigm for approximating complex Bayesian causal\ninference, that can be scaled to increasingly challenging settings in the\nfuture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05526v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05588", "title": "Semi-Supervised Defect Detection via Conditional Diffusion and CLIP-Guided Noise Filtering", "authors": ["Shuai Li", "Shihan Chen", "Wanru Geng", "Zhaohua Xu", "Xiaolu Liu", "Can Dong", "Zhen Tian", "Changlin Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05588v1", "summary": "In the realm of industrial quality inspection, defect detection stands as a\ncritical component, particularly in high-precision, safety-critical sectors\nsuch as automotive components aerospace, and medical devices. Traditional\nmethods, reliant on manual inspection or early image processing algorithms,\nsuffer from inefficiencies, high costs, and limited robustness. This paper\nintroduces a semi-supervised defect detection framework based on conditional\ndiffusion (DSYM), leveraging a two-stage collaborative training mechanism and a\nstaged joint optimization strategy. The framework utilizes labeled data for\ninitial training and subsequently incorporates unlabeled data through the\ngeneration of pseudo-labels. A conditional diffusion model synthesizes\nmulti-scale pseudo-defect samples, while a CLIP cross-modal feature-based noise\nfiltering mechanism mitigates label contamination. Experimental results on the\nNEU-DET dataset demonstrate a 78.4% mAP@0.5 with the same amount of labeled\ndata as traditional supervised methods, and 75.1% mAP@0.5 with only 40% of the\nlabeled data required by the original supervised model, showcasing significant\nadvantages in data efficiency. This research provides a high-precision,\nlow-labeling-dependent solution for defect detection in industrial quality\ninspection scenarios. The work of this article has been open-sourced at\nhttps://github.com/cLin-c/Semisupervised-DSYM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05588v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05619", "title": "Detecting and Mitigating Reward Hacking in Reinforcement Learning Systems: A Comprehensive Empirical Study", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "categories": ["cs.LG", "cs.SE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05619v1", "summary": "Reward hacking in Reinforcement Learning (RL) systems poses a critical threat\nto the deployment of autonomous agents, where agents exploit flaws in reward\nfunctions to achieve high scores without fulfilling intended objectives.\nDespite growing awareness of this problem, systematic detection and mitigation\napproaches remain limited. This paper presents a large-scale empirical study of\nreward hacking across diverse RL environments and algorithms. We analyze 15,247\ntraining episodes across 15 RL environments (Atari, MuJoCo, custom domains) and\n5 algorithms (PPO, SAC, DQN, A3C, Rainbow), implementing automated detection\nalgorithms for six categories of reward hacking: specification gaming, reward\ntampering, proxy optimization, objective misalignment, exploitation patterns,\nand wireheading. Our detection framework achieves 78.4% precision and 81.7%\nrecall across environments, with computational overhead under 5%. Through\ncontrolled experiments varying reward function properties, we demonstrate that\nreward density and alignment with true objectives significantly impact hacking\nfrequency ($p < 0.001$, Cohen's $d = 1.24$). We validate our approach through\nthree simulated application studies representing recommendation systems,\ncompetitive gaming, and robotic control scenarios. Our mitigation techniques\nreduce hacking frequency by up to 54.6% in controlled scenarios, though we find\nthese trade-offs are more challenging in practice due to concept drift, false\npositive costs, and adversarial adaptation. All detection algorithms, datasets,\nand experimental protocols are publicly available to support reproducible\nresearch in RL safety.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05619v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2505.02230", "title": "The GenAI Generation: Student Views of Awareness, Preparedness, and Concern", "authors": ["Micaela Siraj", "Jon Duke", "Thomas Plötz"], "categories": ["cs.HC", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.02230v2", "summary": "Generative Artificial Intelligence (GenAI) is revolutionizing education and\nworkforce development, profoundly shaping how students learn, engage, and\nprepare for their future. Outpacing the development of uniform policies and\nstructures, GenAI has heralded a unique era and given rise to the GenAI\nGeneration. We define the GenAI Generation as a cohort of students whose\neducation has been increasingly shaped by the opportunities and challenges\nGenAI presents during its widespread adoption within society. This study\nexamines students' perceptions of GenAI through a concise survey with optional\nopen-ended questions, focusing on their awareness, preparedness, and concerns.\nNotably, readiness appears increasingly tied to exposure to GenAI through one's\ncoursework. Students with greater curricular exposure to GenAI tend to feel\nmore prepared, while those without it more often express vulnerability and\nuncertainty, highlighting a new and growing divide in readiness that goes\nbeyond traditional disciplinary boundaries. Evaluation of more than 250\nresponses, with over 40% providing detailed qualitative feedback, reveals a\ncore dual sentiment: while most students express enthusiasm for GenAI, an even\ngreater proportion voice a spectrum of concerns about ethics, job displacement,\nand the adequacy of educational structures given the highly transformative\ntechnology. These findings offer critical insights into how students view the\npotential and pitfalls of GenAI for future career impacts. The challenge ahead\ninvolves implementing associated recommendations for educational institutions,\nmoving beyond the baseline of access toward more informed guidance on the use\nof these tools, while preserving critical thinking, ethical reasoning, and\nadaptive learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.02230v2", "cate": "cs.HC", "date": "2025-05-04", "updated": "2025-07-08"}
{"id": "2507.05736", "title": "Tight Bound for Quantum Unitary Time-Reversal", "authors": ["Kean Chen", "Nengkun Yu", "Zhicheng Zhang"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      32 pages, 6 figures, 1 table", "url": "http://arxiv.org/abs/2507.05736v1", "summary": "Time-reversal of unitary evolution is fundamental in quantum information\nprocessing. Many scenarios, particularly those in quantum learning and\nmetrology, assume free access to the time-reverse of an unknown unitary. In\nthis paper, we settle the query complexity of the unitary time-reversal task:\napproximately implementing $U^{-1}$ given only black-box access to an unknown\n$d$-dimensional unitary $U$. We provide a tight query lower bound\n$\\Omega((1-\\epsilon)d^2)$ for the unitary time-reversal to within diamond norm\nerror $\\epsilon$. Notably, our lower bound applies to general coherent\nprotocols with unbounded ancillas, and holds even when $\\epsilon$ is an\naverage-case distance error. Moreover, our result implies a query lower bound\n$\\Omega(d^2)$ for approximately implementing control-$U$ up to an irrelevant\nphase, which is also tight with respect to the dimension.", "comment": "32 pages, 6 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.05736v1", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2501.04730", "title": "Relative Phase Equivariant Deep Neural Systems for Physical Layer Communications", "authors": ["Arwin Gansekoele", "Sandjai Bhulai", "Mark Hoogendoorn", "Rob van der Mei"], "categories": ["cs.IT", "cs.NI", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Published at TMLR ( this https URL )", "url": "http://arxiv.org/abs/2501.04730v2", "summary": "In the era of telecommunications, the increasing demand for complex and\nspecialized communication systems has led to a focus on improving physical\nlayer communications. Artificial intelligence (AI) has emerged as a promising\nsolution avenue for doing so. Deep neural receivers have already shown\nsignificant promise in improving the performance of communications systems.\nHowever, a major challenge lies in developing deep neural receivers that match\nthe energy efficiency and speed of traditional receivers. This work\ninvestigates the incorporation of inductive biases in the physical layer using\ngroup-equivariant deep learning to improve the parameter efficiency of deep\nneural receivers. We do so by constructing a deep neural receiver that is\nequivariant with respect to the phase of arrival. We show that the inclusion of\nrelative phase equivariance significantly reduces the error rate of deep neural\nreceivers at similar model sizes. Thus, we show the potential of\ngroup-equivariant deep learning in the domain of physical layer communications.", "comment": "Published at TMLR (https://openreview.net/forum?id=vttqWoSJIW)", "pdf_url": "http://arxiv.org/pdf/2501.04730v2", "cate": "cs.IT", "date": "2025-01-06", "updated": "2025-07-07"}
{"id": "2507.05906", "title": "Feature-Based vs. GAN-Based Learning from Demonstrations: When and Why", "authors": ["Chenhao Li", "Marco Hutter", "Andreas Krause"], "categories": ["cs.LG", "cs.AI", "cs.GR", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05906v1", "summary": "This survey provides a comparative analysis of feature-based and GAN-based\napproaches to learning from demonstrations, with a focus on the structure of\nreward functions and their implications for policy learning. Feature-based\nmethods offer dense, interpretable rewards that excel at high-fidelity motion\nimitation, yet often require sophisticated representations of references and\nstruggle with generalization in unstructured settings. GAN-based methods, in\ncontrast, use implicit, distributional supervision that enables scalability and\nadaptation flexibility, but are prone to training instability and coarse reward\nsignals. Recent advancements in both paradigms converge on the importance of\nstructured motion representations, which enable smoother transitions,\ncontrollable synthesis, and improved task integration. We argue that the\ndichotomy between feature-based and GAN-based methods is increasingly nuanced:\nrather than one paradigm dominating the other, the choice should be guided by\ntask-specific priorities such as fidelity, diversity, interpretability, and\nadaptability. This work outlines the algorithmic trade-offs and design\nconsiderations that underlie method selection, offering a framework for\nprincipled decision-making in learning from demonstrations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05906v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05976", "title": "Enhancing the Interpretability of Rule-based Explanations through Information Retrieval", "authors": ["Alessandro Umbrico", "Guido Bologna", "Luca Coraci", "Francesca Fracasso", "Silvia Gola", "Gabriella Cortellessa"], "categories": ["cs.AI", "cs.IR"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05976v1", "summary": "The lack of transparency of data-driven Artificial Intelligence techniques\nlimits their interpretability and acceptance into healthcare decision-making\nprocesses. We propose an attribution-based approach to improve the\ninterpretability of Explainable AI-based predictions in the specific context of\narm lymphedema's risk assessment after lymph nodal radiotherapy in breast\ncancer. The proposed method performs a statistical analysis of the attributes\nin the rule-based prediction model using standard metrics from Information\nRetrieval techniques. This analysis computes the relevance of each attribute to\nthe prediction and provides users with interpretable information about the\nimpact of risk factors. The results of a user study that compared the output\ngenerated by the proposed approach with the raw output of the Explainable AI\nmodel suggested higher levels of interpretability and usefulness in the context\nof predicting lymphedema risk.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05976v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05527", "title": "Mitigating Shortcut Learning with InterpoLated Learning", "authors": ["Michalis Korakakis", "Andreas Vlachos", "Adrian Weller"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025 (Main)", "url": "http://arxiv.org/abs/2507.05527v1", "summary": "Empirical risk minimization (ERM) incentivizes models to exploit shortcuts,\ni.e., spurious correlations between input attributes and labels that are\nprevalent in the majority of the training data but unrelated to the task at\nhand. This reliance hinders generalization on minority examples, where such\ncorrelations do not hold. Existing shortcut mitigation approaches are\nmodel-specific, difficult to tune, computationally expensive, and fail to\nimprove learned representations. To address these issues, we propose\nInterpoLated Learning (InterpoLL) which interpolates the representations of\nmajority examples to include features from intra-class minority examples with\nshortcut-mitigating patterns. This weakens shortcut influence, enabling models\nto acquire features predictive across both minority and majority examples.\nExperimental results on multiple natural language understanding tasks\ndemonstrate that InterpoLL improves minority generalization over both ERM and\nstate-of-the-art shortcut mitigation methods, without compromising accuracy on\nmajority examples. Notably, these gains persist across encoder,\nencoder-decoder, and decoder-only architectures, demonstrating the method's\nbroad applicability.", "comment": "Accepted to ACL 2025 (Main)", "pdf_url": "http://arxiv.org/pdf/2507.05527v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05594", "title": "GSVR: 2D Gaussian-based Video Representation for 800+ FPS with Hybrid Deformation Field", "authors": ["Zhizhuo Pang", "Zhihui Ke", "Xiaobo Zhou", "Tie Qiu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05594v1", "summary": "Implicit neural representations for video have been recognized as a novel and\npromising form of video representation. Existing works pay more attention to\nimproving video reconstruction quality but little attention to the decoding\nspeed. However, the high computation of convolutional network used in existing\nmethods leads to low decoding speed. Moreover, these convolution-based video\nrepresentation methods also suffer from long training time, about 14 seconds\nper frame to achieve 35+ PSNR on Bunny. To solve the above problems, we propose\nGSVR, a novel 2D Gaussian-based video representation, which achieves 800+ FPS\nand 35+ PSNR on Bunny, only needing a training time of $2$ seconds per frame.\nSpecifically, we propose a hybrid deformation field to model the dynamics of\nthe video, which combines two motion patterns, namely the tri-plane motion and\nthe polynomial motion, to deal with the coupling of camera motion and object\nmotion in the video. Furthermore, we propose a Dynamic-aware Time Slicing\nstrategy to adaptively divide the video into multiple groups of pictures(GOP)\nbased on the dynamic level of the video in order to handle large camera motion\nand non-rigid movements. Finally, we propose quantization-aware fine-tuning to\navoid performance reduction after quantization and utilize image codecs to\ncompress Gaussians to achieve a compact representation. Experiments on the\nBunny and UVG datasets confirm that our method converges much faster than\nexisting methods and also has 10x faster decoding speed compared to other\nmethods. Our method has comparable performance in the video interpolation task\nto SOTA and attains better video compression performance than NeRV.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05594v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2410.06949", "title": "Towards Exception Safety Code Generation with Intermediate Representation Agents Framework", "authors": ["Xuanming Zhang", "Yuxuan Chen", "Yuan Yuan", "Minlie Huang"], "categories": ["cs.SE", "cs.CL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.06949v3", "summary": "Large Language Models (LLMs) often struggle with robust exception handling in\ngenerated code, leading to fragile programs that are prone to runtime errors.\nWe propose Seeker, a novel multi-agent framework that enforces exception safety\nin LLM generated code through an Intermediate Representation (IR) approach.\nSeeker decomposes exception handling into five specialized agents: Scanner,\nDetector, Predator, Ranker, and Handler that collaboratively analyze code,\ndetect fragile segments, retrieve best practice exception strategies, and\ninject robust handling code. We also introduce Common Exception Enumeration\n(CEE), a comprehensive knowledge base derived from official documentation,\ntechnical practices, and real world code, to standardize exception handling\nstrategies. Seeker also incorporates a Deep Retrieval-Augmented Generation\n(Deep RAG) algorithm to efficiently navigate the exception inheritance\nhierarchy, cutting down search overhead by 93% while improving accuracy in\nidentifying relevant exceptions. We evaluate Seeker on 15 open source Java\nprojects and multiple benchmarks. Seeker outperforms state of the art\nbaselines, improving exception handling precision by up to 37% and overall code\nrobustness by 38% as measured by expert code review. It significantly closes\nthe gap between LLM and human developers in exception management, achieving a\n28% success rate on real world issue fixes (SWE bench) versus 19% by prior\nmethods. Our framework preserves functional correctness of code while\nproactively handling errors, demonstrating a practical, generalizable solution\nfor safer code generation. In this paper, we discuss the novelty of using\nintermediate representation and multi-agent collaboration for exception\nhandling, and outline how Seeker can be extended to other programming languages\nand complex software engineering tasks, aligning LLM-generated code with\nindustrial standard.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.06949v3", "cate": "cs.SE", "date": "2024-10-09", "updated": "2025-07-07"}
{"id": "2505.06386", "title": "Embedding Atlas: Low-Friction, Interactive Embedding Visualization", "authors": ["Donghao Ren", "Fred Hohman", "Halden Lin", "Dominik Moritz"], "categories": ["cs.HC", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Website: this https URL", "url": "http://arxiv.org/abs/2505.06386v2", "summary": "Embedding projections are popular for visualizing large datasets and models.\nHowever, people often encounter \"friction\" when using embedding visualization\ntools: (1) barriers to adoption, e.g., tedious data wrangling and loading,\nscalability limits, no integration of results into existing workflows, and (2)\nlimitations in possible analyses, without integration with external tools to\nadditionally show coordinated views of metadata. In this paper, we present\nEmbedding Atlas, a scalable, interactive visualization tool designed to make\ninteracting with large embeddings as easy as possible. Embedding Atlas uses\nmodern web technologies and advanced algorithms -- including density-based\nclustering, and automated labeling -- to provide a fast and rich data analysis\nexperience at scale. We evaluate Embedding Atlas with a competitive analysis\nagainst other popular embedding tools, showing that Embedding Atlas's feature\nset specifically helps reduce friction, and report a benchmark on its real-time\nrendering performance with millions of points. Embedding Atlas is available as\nopen source to support future work in embedding-based analysis.", "comment": "Website: https://apple.github.io/embedding-atlas/", "pdf_url": "http://arxiv.org/pdf/2505.06386v2", "cate": "cs.HC", "date": "2025-05-09", "updated": "2025-07-08"}
{"id": "2507.05994", "title": "Beating the Best Constant Rebalancing Portfolio in Long-Term Investment: A Generalization of the Kelly Criterion and Universal Learning Algorithm for Markets with Serial Dependence", "authors": ["Duy Khanh Lam"], "categories": ["q-fin.PM", "cs.IT", "cs.LG", "math.IT", "q-fin.CP"], "primary_category": "Subjects:       Portfolio Management (q-fin.PM)", "pdf_link": null, "comments": "Comments:      19 pages, 7 figures. Working paper (1st full draft); typos may exist", "url": "http://arxiv.org/abs/2507.05994v1", "summary": "In the online portfolio optimization framework, existing learning algorithms\ngenerate strategies that yield significantly poorer cumulative wealth compared\nto the best constant rebalancing portfolio in hindsight, despite being\nconsistent in asymptotic growth rate. While this unappealing performance can be\nimproved by incorporating more side information, it raises difficulties in\nfeature selection and high-dimensional settings. Instead, the inherent serial\ndependence of assets' returns, such as day-of-the-week and other calendar\neffects, can be leveraged. Although latent serial dependence patterns are\ncommonly detected using large training datasets, this paper proposes an\nalgorithm that learns such dependence using only gradually revealed data,\nwithout any assumption on their distribution, to form a strategy that\neventually exceeds the cumulative wealth of the best constant rebalancing\nportfolio.\n  Moreover, the classical Kelly criterion, which requires independent assets'\nreturns, is generalized to accommodate serial dependence in a market modeled as\nan independent and identically distributed process of random matrices. In such\na stochastic market, where existing learning algorithms designed for stationary\nprocesses fail to apply, the proposed learning algorithm still generates a\nstrategy that asymptotically grows to the highest rate among all strategies,\nmatching that of the optimal strategy constructed under the generalized Kelly\ncriterion. The experimental results with real market data demonstrate the\ntheoretical guarantees of the algorithm and its performance as expected, as\nlong as serial dependence is significant, regardless of the validity of the\ngeneralized Kelly criterion in the experimental market. This further affirms\nthe broad applicability of the algorithm in general contexts.", "comment": "19 pages, 7 figures. Working paper (1st full draft); typos may exist", "pdf_url": "http://arxiv.org/pdf/2507.05994v1", "cate": "q-fin.PM", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06111", "title": "Safe Domain Randomization via Uncertainty-Aware Out-of-Distribution Detection and Policy Adaptation", "authors": ["Mohamad H. Danesh", "Maxime Wabartha", "Stanley Wu", "Joelle Pineau", "Hsiu-Chin Lin"], "categories": ["cs.LG", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06111v1", "summary": "Deploying reinforcement learning (RL) policies in real-world involves\nsignificant challenges, including distribution shifts, safety concerns, and the\nimpracticality of direct interactions during policy refinement. Existing\nmethods, such as domain randomization (DR) and off-dynamics RL, enhance policy\nrobustness by direct interaction with the target domain, an inherently unsafe\npractice. We propose Uncertainty-Aware RL (UARL), a novel framework that\nprioritizes safety during training by addressing Out-Of-Distribution (OOD)\ndetection and policy adaptation without requiring direct interactions in target\ndomain. UARL employs an ensemble of critics to quantify policy uncertainty and\nincorporates progressive environmental randomization to prepare the policy for\ndiverse real-world conditions. By iteratively refining over high-uncertainty\nregions of the state space in simulated environments, UARL enhances robust\ngeneralization to the target domain without explicitly training on it. We\nevaluate UARL on MuJoCo benchmarks and a quadrupedal robot, demonstrating its\neffectiveness in reliable OOD detection, improved performance, and enhanced\nsample efficiency compared to baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06111v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05531", "title": "Bit-Flip Fault Attack: Crushing Graph Neural Networks via Gradual Bit Search", "authors": ["Sanaz Kazemi Abharian", "Sai Manoj Pudukotai Dinakarrao"], "categories": ["cs.LG", "cs.AR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05531v1", "summary": "Graph Neural Networks (GNNs) have emerged as a powerful machine learning\nmethod for graph-structured data. A plethora of hardware accelerators has been\nintroduced to meet the performance demands of GNNs in real-world applications.\nHowever, security challenges of hardware-based attacks have been generally\noverlooked. In this paper, we investigate the vulnerability of GNN models to\nhardware-based fault attack, wherein an attacker attempts to misclassify output\nby modifying trained weight parameters through fault injection in a memory\ndevice. Thus, we propose Gradual Bit-Flip Fault Attack (GBFA), a layer-aware\nbit-flip fault attack, selecting a vulnerable bit in each selected weight\ngradually to compromise the GNN's performance by flipping a minimal number of\nbits. To achieve this, GBFA operates in two steps. First, a Markov model is\ncreated to predict the execution sequence of layers based on features extracted\nfrom memory access patterns, enabling the launch of the attack within a\nspecific layer. Subsequently, GBFA identifies vulnerable bits within the\nselected weights using gradient ranking through an in-layer search. We evaluate\nthe effectiveness of the proposed GBFA attack on various GNN models for node\nclassification tasks using the Cora and PubMed datasets. Our findings show that\nGBFA significantly degrades prediction accuracy, and the variation in its\nimpact across different layers highlights the importance of adopting a\nlayer-aware attack strategy in GNNs. For example, GBFA degrades GraphSAGE's\nprediction accuracy by 17% on the Cora dataset with only a single bit flip in\nthe last layer.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05531v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05595", "title": "PaddleOCR 3.0 Technical Report", "authors": ["Cheng Cui", "Ting Sun", "Manhui Lin", "Tingquan Gao", "Yubo Zhang", "Jiaxuan Liu", "Xueqing Wang", "Zelun Zhang", "Changda Zhou", "Hongen Liu", "Yue Zhang", "Wenyu Lv", "Kui Huang", "Yichao Zhang", "Jing Zhang", "Jun Zhang", "Yi Liu", "Dianhai Yu", "Yanjun Ma"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05595v1", "summary": "This technical report introduces PaddleOCR 3.0, an Apache-licensed\nopen-source toolkit for OCR and document parsing. To address the growing demand\nfor document understanding in the era of large language models, PaddleOCR 3.0\npresents three major solutions: (1) PP-OCRv5 for multilingual text recognition,\n(2) PP-StructureV3 for hierarchical document parsing, and (3) PP-ChatOCRv4 for\nkey information extraction. Compared to mainstream vision-language models\n(VLMs), these models with fewer than 100 million parameters achieve competitive\naccuracy and efficiency, rivaling billion-parameter VLMs. In addition to\noffering a high-quality OCR model library, PaddleOCR 3.0 provides efficient\ntools for training, inference, and deployment, supports heterogeneous hardware\nacceleration, and enables developers to easily build intelligent document\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05595v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2412.20545", "title": "The Impact of Prompt Programming on Function-Level Code Generation", "authors": ["Ranim Khojah", "Francisco Gomes de Oliveira Neto", "Mazen Mohamad", "Philipp Leitner"], "categories": ["cs.SE", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at Transactions on Software Engineering (TSE). CodePromptEval dataset and replication package on GitHub: this https URL", "url": "http://arxiv.org/abs/2412.20545v2", "summary": "Large Language Models (LLMs) are increasingly used by software engineers for\ncode generation. However, limitations of LLMs such as irrelevant or incorrect\ncode have highlighted the need for prompt programming (or prompt engineering)\nwhere engineers apply specific prompt techniques (e.g., chain-of-thought or\ninput-output examples) to improve the generated code. While some prompt\ntechniques have been studied, the impact of different techniques -- and their\ninteractions -- on code generation is still not fully understood. In this\nstudy, we introduce CodePromptEval, a dataset of 7072 prompts designed to\nevaluate five prompt techniques (few-shot, persona, chain-of-thought, function\nsignature, list of packages) and their effect on the correctness, similarity,\nand quality of complete functions generated by three LLMs (GPT-4o, Llama3, and\nMistral). Our findings show that while certain prompt techniques significantly\ninfluence the generated code, combining multiple techniques does not\nnecessarily improve the outcome. Additionally, we observed a trade-off between\ncorrectness and quality when using prompt techniques. Our dataset and\nreplication package enable future research on improving LLM-generated code and\nevaluating new prompt techniques.", "comment": "Accepted at Transactions on Software Engineering (TSE).\n  CodePromptEval dataset and replication package on GitHub:\n  https://github.com/icetlab/CodePromptEval", "pdf_url": "http://arxiv.org/pdf/2412.20545v2", "cate": "cs.SE", "date": "2024-12-29", "updated": "2025-07-08"}
{"id": "2506.13477", "title": "Multimodal Integration Challenges in Emotionally Expressive Child Avatars for Training Applications", "authors": ["Pegah Salehi", "Sajad Amouei Sheshkal", "Vajira Thambawita", "Michael A. Riegler", "Pål Halvorsen"], "categories": ["cs.HC", "cs.CV", "68T07, 68U99, 68T45, 91E45"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      20 pages, 9 figures, 9 tables", "url": "http://arxiv.org/abs/2506.13477v2", "summary": "Dynamic facial emotion is essential for believable AI-generated avatars, yet\nmost systems remain visually static, limiting their use in simulations like\nvirtual training for investigative interviews with abused children. We present\na real-time architecture combining Unreal Engine 5 MetaHuman rendering with\nNVIDIA Omniverse Audio2Face to generate facial expressions from vocal prosody\nin photorealistic child avatars. Due to limited TTS options, both avatars were\nvoiced using young adult female models from two systems to better fit character\nprofiles, introducing a voice-age mismatch. This confound may affect\naudiovisual alignment. We used a two-PC setup to decouple speech generation\nfrom GPU-intensive rendering, enabling low-latency interaction in desktop and\nVR. A between-subjects study (N=70) compared audio+visual vs. visual-only\nconditions as participants rated emotional clarity, facial realism, and empathy\nfor avatars expressing joy, sadness, and anger. While emotions were generally\nrecognized - especially sadness and joy - anger was harder to detect without\naudio, highlighting the role of voice in high-arousal expressions.\nInterestingly, silencing clips improved perceived realism by removing\nmismatches between voice and animation, especially when tone or age felt\nincongruent. These results emphasize the importance of audiovisual congruence:\nmismatched voice undermines expression, while a good match can enhance weaker\nvisuals - posing challenges for emotionally coherent avatars in sensitive\ncontexts.", "comment": "20 pages, 9 figures, 9 tables", "pdf_url": "http://arxiv.org/pdf/2506.13477v2", "cate": "cs.HC", "date": "2025-06-16", "updated": "2025-07-08"}
{"id": "2507.06028", "title": "RIS-Enabled Transmitter Design for Joint Radar and Communication", "authors": ["Emanuele Grossi", "Marco Lops", "Luca Venturino"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted to the 2025 IEEE Radar Conference, Krakow, Poland", "url": "http://arxiv.org/abs/2507.06028v1", "summary": "Achieving efficient and cost-effective transmit beampattern control for\nintegrated sensing and communication (ISAC) systems is a significant challenge.\nThis paper addresses this by proposing a dual-function radar communication\n(DFRC) transmitter based on a reconfigurable intelligent surface (RIS)\nilluminated by a limited number of active sources. We formulate and solve the\njoint design of source waveforms and RIS phase shifts to match a desired\nspace-frequency radiation pattern, and we evaluate the resulting ISAC system's\nperformance in terms of radar detection probability and data transmission rate.\nNumerical results demonstrate the promising capabilities of this RIS-enabled\ntransmitter for ISAC applications.", "comment": "Accepted to the 2025 IEEE Radar Conference, Krakow, Poland", "pdf_url": "http://arxiv.org/pdf/2507.06028v1", "cate": "eess.SP", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2309.12611", "title": "On the Robotic Uncertainty of Fully Autonomous Traffic: From Stochastic Car-Following to Mobility-Safety Trade-Offs", "authors": ["Hangyu Li", "Xiaotong Sun", "Chenglin Zhuang", "Xiaopeng Li"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2309.12611v3", "summary": "Recent transportation research highlights the potential of autonomous\nvehicles (AV) to improve traffic flow mobility as they are able to maintain\nsmaller car-following distances. However, as a unique class of ground robots,\nAVs are susceptible to robotic errors, particularly in their perception and\ncontrol modules with imperfect sensors and actuators, leading to uncertainties\nin their movements and an increased risk of collisions. Consequently,\nconservative operational strategies, such as larger headway and slower speeds,\nare implemented to prioritize safety over mobility in real-world operations. To\nreconcile the inconsistency, this paper presents an analytical model framework\nthat delineates the endogenous reciprocity between traffic safety and mobility\nthat arises from AVs' robotic uncertainties. Using both realistic car-following\ndata and a stochastic intelligent driving model (IDM), the stochastic\ncar-following distance is derived as a key parameter, enabling analysis of\nsingle-lane capacity and collision probability. A semi-Markov process is then\nemployed to model the dynamics of the lane capacity, and the resulting\ncollision-inclusive capacity, representing expected lane capacity under\nstationary conditions, serves as the primary performance metric for fully\nautonomous traffic. The analytical results are further utilized to investigate\nthe impacts of critical parameters in AV and roadway designs on traffic\nperformance, as well as the properties of optimal speed and headway under\nmobility-targeted or safety-dominated management objectives. Extensions to\nscenarios involving multiple non-independent collisions or multi-lane traffic\nscenarios are also discussed, which demonstrates the robustness of the\ntheoretical results and their practical applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2309.12611v3", "cate": "cs.RO", "date": "2023-09-22", "updated": "2025-07-08"}
{"id": "2507.06013", "title": "CogniSQL-R1-Zero: Lightweight Reinforced Reasoning for Efficient SQL Generation", "authors": ["Kushal Gajjar", "Harshit Sikchi", "Arpit Singh Gautam", "Marc Hammons", "Saurabh Jha"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06013v1", "summary": "Translating natural language into SQL (Text-to-SQL) remains a core challenge\nat the intersection of language understanding and structured data access.\nAlthough large language models (LLMs) have improved fluency, generating correct\nand executable SQL, especially for complex queries, continues to be\nchallenging. We introduce CogniSQL-R1-Zero, a reinforcement learning (RL)\nframework and model that produces accurate SQL using a lightweight reward\nsignal based on execution correctness and format-tag compliance. By avoiding\nintermediate supervision, hybrid pipelines and complex reward shaping, our\nmethod encourages stable learning and stronger alignment with the ultimate task\nobjective-producing executable programs. CogniSQL-R1-Zero achieves\nstate-of-the-art execution accuracy on Text2SQL benchmark; BIRD bench,\noutperforming prior supervised and instruction-tuned baselines including SFT\nCodeS-7B, DeepSeek-Coder 236B, and Mistral 123B-despite being trained on a\nsignificantly smaller 7B backbone. This result underscores the scalability and\nefficiency of our RL-based approach when trained on just four NVIDIA A100 GPUs\n(40 GB VRAM each). To support further research in efficient and interpretable\nText-to-SQL modeling, we release two curated datasets: (i) a collection of\n5,024 reasoning traces with varying context lengths, and (ii) a\npositive-sampled corpus of 36,356 corpus of weakly supervised queries, each\nannotated with six semantically diverse reasoning paths. Together, these\ncontributions advance scalable, execution-aligned Text-to-SQL generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06013v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05533", "title": "Theoretical Learning Performance of Graph Neural Networks: The Impact of Jumping Connections and Layer-wise Sparsification", "authors": ["Jiawei Sun", "Hongkang Li", "Meng Wang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      TMLR", "url": "http://arxiv.org/abs/2507.05533v1", "summary": "Jumping connections enable Graph Convolutional Networks (GCNs) to overcome\nover-smoothing, while graph sparsification reduces computational demands by\nselecting a sub-matrix of the graph adjacency matrix during neighborhood\naggregation. Learning GCNs with graph sparsification has shown empirical\nsuccess across various applications, but a theoretical understanding of the\ngeneralization guarantees remains limited, with existing analyses ignoring\neither graph sparsification or jumping connections. This paper presents the\nfirst learning dynamics and generalization analysis of GCNs with jumping\nconnections using graph sparsification. Our analysis demonstrates that the\ngeneralization accuracy of the learned model closely approximates the highest\nachievable accuracy within a broad class of target functions dependent on the\nproposed sparse effective adjacency matrix $A^*$. Thus, graph sparsification\nmaintains generalization performance when $A^*$ preserves the essential edges\nthat support meaningful message propagation. We reveal that jumping connections\nlead to different sparsification requirements across layers. In a\ntwo-hidden-layer GCN, the generalization is more affected by the sparsified\nmatrix deviations from $A^*$ of the first layer than the second layer. To the\nbest of our knowledge, this marks the first theoretical characterization of\njumping connections' role in sparsification requirements. We validate our\ntheoretical results on benchmark datasets in deep GCNs.", "comment": "TMLR", "pdf_url": "http://arxiv.org/pdf/2507.05533v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05601", "title": "Rethinking Layered Graphic Design Generation with a Top-Down Approach", "authors": ["Jingye Chen", "Zhaowen Wang", "Nanxuan Zhao", "Li Zhang", "Difan Liu", "Jimei Yang", "Qifeng Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.05601v1", "summary": "Graphic design is crucial for conveying ideas and messages. Designers usually\norganize their work into objects, backgrounds, and vectorized text layers to\nsimplify editing. However, this workflow demands considerable expertise. With\nthe rise of GenAI methods, an endless supply of high-quality graphic designs in\npixel format has become more accessible, though these designs often lack\neditability. Despite this, non-layered designs still inspire human designers,\ninfluencing their choices in layouts and text styles, ultimately guiding the\ncreation of layered designs. Motivated by this observation, we propose\nAccordion, a graphic design generation framework taking the first attempt to\nconvert AI-generated designs into editable layered designs, meanwhile refining\nnonsensical AI-generated text with meaningful alternatives guided by user\nprompts. It is built around a vision language model (VLM) playing distinct\nroles in three curated stages. For each stage, we design prompts to guide the\nVLM in executing different tasks. Distinct from existing bottom-up methods\n(e.g., COLE and Open-COLE) that gradually generate elements to create layered\ndesigns, our approach works in a top-down manner by using the visually\nharmonious reference image as global guidance to decompose each layer.\nAdditionally, it leverages multiple vision experts such as SAM and element\nremoval models to facilitate the creation of graphic layers. We train our\nmethod using the in-house graphic design dataset Design39K, augmented with\nAI-generated design images coupled with refined ground truth created by a\ncustomized inpainting model. Experimental results and user studies by designers\nshow that Accordion generates favorable results on the DesignIntention\nbenchmark, including tasks such as text-to-template, adding text to background,\nand text de-rendering, and also excels in creating design variations.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.05601v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2412.20866", "title": "ContractTrace: Retracing Smart Contract Versions for Security Analyses", "authors": ["Fatou Ndiaye Mbodji", "Vinny Adjibi", "Moustapha Awwalou Diouf", "Gervais Mendy", "Kui Liu", "Jacques Klein", "Tegawende Bissyande"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      10 pages, 4 figures, 4 tables", "url": "http://arxiv.org/abs/2412.20866v2", "summary": "Due to the inherent immutability of blockchain technology, smart contract\nupdates require their deployment at new addresses rather than modifying\nexisting ones, thus fragmenting version histories and creating critical blind\nspots for analyses. Indeed, for example, this fragmentation severely hinders\nsecurity researchers ability to track vulnerability lifecycles across contract\nversions. While platforms like Etherscan provide detailed information about\nEthereum smart contracts, they lack crucial functionality to trace\npredecessor-successor relationships within smart contract lineages, preventing\nsystematic analysis of how vulnerabilities emerge, propagate, and potentially\nremain unresolved across versions.To address the challenge of tracing smart\ncontract lineages, we adopt a Design Science Research (DSR) approach and\nintroduce ContractTrace, an automated infrastructure that accurately identifies\nand links versions of smart contracts into coherent lineages. This tool enables\nthe construction of lineageSet, an up-to-date, open-source dataset specifically\ndesigned to support security research on vulnerability, defect or any other\nproperty evolution patterns in smart contracts. Through a security-focused case\nstudy we demonstrate how ContractTrace reveals previously obscured\nvulnerability life-cycles within smart contract lineages, tracking whether\ncritical security flaws persist or get resolved across versions. This\ncapability is essential for understanding vulnerability propagation patterns\nand evaluating the effectiveness of security patches in blockchain\nenvironments. In the evaluation phase of our DSR approach, we validated our\nlineage detection methodology against an alternative approach using\nLocality-Sensitive Hashing (LSH) to cluster contract versions, confirming the\nsecurity relevance and accuracy of our technique.", "comment": "10 pages, 4 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2412.20866v2", "cate": "cs.SE", "date": "2024-12-30", "updated": "2025-07-08"}
{"id": "2506.21898", "title": "Bias, Accuracy, and Trust: Gender-Diverse Perspectives on Large Language Models", "authors": ["Aimen Gaba", "Emily Wall", "Tejas Ramkumar Babu", "Yuriy Brun", "Kyle Hall", "Cindy Xiong Bearfield"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.21898v2", "summary": "Large language models (LLMs) are becoming increasingly ubiquitous in our\ndaily lives, but numerous concerns about bias in LLMs exist. This study\nexamines how gender-diverse populations perceive bias, accuracy, and\ntrustworthiness in LLMs, specifically ChatGPT. Through 25 in-depth interviews\nwith non-binary/transgender, male, and female participants, we investigate how\ngendered and neutral prompts influence model responses and how users evaluate\nthese responses. Our findings reveal that gendered prompts elicit more\nidentity-specific responses, with non-binary participants particularly\nsusceptible to condescending and stereotypical portrayals. Perceived accuracy\nwas consistent across gender groups, with errors most noted in technical topics\nand creative tasks. Trustworthiness varied by gender, with men showing higher\ntrust, especially in performance, and non-binary participants demonstrating\nhigher performance-based trust. Additionally, participants suggested improving\nthe LLMs by diversifying training data, ensuring equal depth in gendered\nresponses, and incorporating clarifying questions. This research contributes to\nthe CSCW/HCI field by highlighting the need for gender-diverse perspectives in\nLLM development in particular and AI in general, to foster more inclusive and\ntrustworthy systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.21898v2", "cate": "cs.HC", "date": "2025-06-27", "updated": "2025-07-08"}
{"id": "2507.06091", "title": "Bounding quantum uncommon information with quantum neural estimators", "authors": ["Donghwa Ji", "Junseo Lee", "Myeongjin Shin", "IlKwon Sohn", "Kabgyun Jeong"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06091v1", "summary": "In classical information theory, uncommon information refers to the amount of\ninformation that is not shared between two messages, and it admits an\noperational interpretation as the minimum communication cost required to\nexchange the messages. Extending this notion to the quantum setting, quantum\nuncommon information is defined as the amount of quantum information necessary\nto exchange two quantum states. While the value of uncommon information can be\ncomputed exactly in the classical case, no direct method is currently known for\ncalculating its quantum analogue. Prior work has primarily focused on deriving\nupper and lower bounds for quantum uncommon information. In this work, we\npropose a new approach for estimating these bounds by utilizing the quantum\nDonsker-Varadhan representation and implementing a gradient-based optimization\nmethod. Our results suggest a pathway toward efficient approximation of quantum\nuncommon information using variational techniques grounded in quantum neural\narchitectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06091v1", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2405.04798", "title": "From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control", "authors": ["Yide Shentu", "Philipp Wu", "Aravind Rajeswaran", "Pieter Abbeel"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.04798v3", "summary": "Hierarchical control for robotics has long been plagued by the need to have a\nwell defined interface layer to communicate between high-level task planners\nand low-level policies. With the advent of LLMs, language has been emerging as\na prospective interface layer. However, this has several limitations. Not all\ntasks can be decomposed into steps that are easily expressible in natural\nlanguage (e.g. performing a dance routine). Further, it makes end-to-end\nfinetuning on embodied data challenging due to domain shift and catastrophic\nforgetting. We introduce our method -- Learnable Latent Codes as Bridges (LCB)\n-- as an alternate architecture to overcome these limitations. \\method~uses a\nlearnable latent code to act as a bridge between LLMs and low-level policies.\nThis enables LLMs to flexibly communicate goals in the task plan without being\nentirely constrained by language limitations. Additionally, it enables\nend-to-end finetuning without destroying the embedding space of word tokens\nlearned during pre-training. Through experiments on Language Table and Calvin,\ntwo common language based benchmarks for embodied agents, we find that\n\\method~outperforms baselines (including those w/ GPT-4V) that leverage pure\nlanguage as the interface layer on tasks that require reasoning and multi-step\nbehaviors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.04798v3", "cate": "cs.RO", "date": "2024-05-08", "updated": "2025-07-07"}
{"id": "2507.06029", "title": "Feature-Guided Neighbor Selection for Non-Expert Evaluation of Model Predictions", "authors": ["Courtney Ford", "Mark T. Keane"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures, 1 table. Accepted at IJCAI 2025 Workshop on User-Aligned Assessment of Adaptive AI Systems", "url": "http://arxiv.org/abs/2507.06029v1", "summary": "Explainable AI (XAI) methods often struggle to generate clear, interpretable\noutputs for users without domain expertise. We introduce Feature-Guided\nNeighbor Selection (FGNS), a post hoc method that enhances interpretability by\nselecting class-representative examples using both local and global feature\nimportance. In a user study (N = 98) evaluating Kannada script classifications,\nFGNS significantly improved non-experts' ability to identify model errors while\nmaintaining appropriate agreement with correct predictions. Participants made\nfaster and more accurate decisions compared to those given traditional k-NN\nexplanations. Quantitative analysis shows that FGNS selects neighbors that\nbetter reflect class characteristics rather than merely minimizing\nfeature-space distance, leading to more consistent selection and tighter\nclustering around class prototypes. These results support FGNS as a step toward\nmore human-aligned model assessment, although further work is needed to address\nthe gap between explanation quality and perceived trust.", "comment": "7 pages, 5 figures, 1 table. Accepted at IJCAI 2025 Workshop on\n  User-Aligned Assessment of Adaptive AI Systems", "pdf_url": "http://arxiv.org/pdf/2507.06029v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05540", "title": "Robust Learning on Noisy Graphs via Latent Space Constraints with External Knowledge", "authors": ["Chunhui Gu", "Mohammad Sadegh Nasr", "James P. Long", "Kim-Anh Do", "Ehsan Irajizad"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05540v1", "summary": "Graph Neural Networks (GNNs) often struggle with noisy edges. We propose\nLatent Space Constrained Graph Neural Networks (LSC-GNN) to incorporate\nexternal \"clean\" links and guide embeddings of a noisy target graph. We train\ntwo encoders--one on the full graph (target plus external edges) and another on\na regularization graph excluding the target's potentially noisy links--then\npenalize discrepancies between their latent representations. This constraint\nsteers the model away from overfitting spurious edges. Experiments on benchmark\ndatasets show LSC-GNN outperforms standard and noise-resilient GNNs in graphs\nsubjected to moderate noise. We extend LSC-GNN to heterogeneous graphs and\nvalidate it on a small protein-metabolite network, where metabolite-protein\ninteractions reduce noise in protein co-occurrence data. Our results highlight\nLSC-GNN's potential to boost predictive performance and interpretability in\nsettings with noisy relational structures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05540v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05604", "title": "Kernel Density Steering: Inference-Time Scaling via Mode Seeking for Image Restoration", "authors": ["Yuyang Hu", "Kangfu Mei", "Mojtaba Sahraee-Ardakan", "Ulugbek S. Kamilov", "Peyman Milanfar", "Mauricio Delbracio"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05604v1", "summary": "Diffusion models show promise for image restoration, but existing methods\noften struggle with inconsistent fidelity and undesirable artifacts. To address\nthis, we introduce Kernel Density Steering (KDS), a novel inference-time\nframework promoting robust, high-fidelity outputs through explicit local\nmode-seeking. KDS employs an $N$-particle ensemble of diffusion samples,\ncomputing patch-wise kernel density estimation gradients from their collective\noutputs. These gradients steer patches in each particle towards shared,\nhigher-density regions identified within the ensemble. This collective local\nmode-seeking mechanism, acting as \"collective wisdom\", steers samples away from\nspurious modes prone to artifacts, arising from independent sampling or model\nimperfections, and towards more robust, high-fidelity structures. This allows\nus to obtain better quality samples at the expense of higher compute by\nsimultaneously sampling multiple particles. As a plug-and-play framework, KDS\nrequires no retraining or external verifiers, seamlessly integrating with\nvarious diffusion samplers. Extensive numerical validations demonstrate KDS\nsubstantially improves both quantitative and qualitative performance on\nchallenging real-world super-resolution and image inpainting tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05604v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2504.09496", "title": "Extending Behavioral Software Engineering: Decision-Making and Collaboration in Human-AI Teams for Responsible Software Engineering", "authors": ["Lekshmi Murali Rani"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Submission to the Doctoral and Early Career Symposium of the Cooperative and Human Aspects of Software Engineering 2025 conference", "url": "http://arxiv.org/abs/2504.09496v2", "summary": "The study of behavioral and social dimensions of software engineering (SE)\ntasks characterizes behavioral software engineering (BSE);however, the\nincreasing significance of human-AI collaboration (HAIC) brings new directions\nin BSE by presenting new challenges and opportunities. This PhD research\nfocuses on decision-making (DM) for SE tasks and collaboration within human-AI\nteams, aiming to promote responsible software engineering through a cognitive\npartnership between humans and AI. The goal of the research is to identify the\nchallenges and nuances in HAIC from a cognitive perspective, design and\noptimize collaboration/partnership (human-AI team) that enhance collective\nintelligence and promote better, responsible DM in SE through human-centered\napproaches. The research addresses HAIC and its impact on individual, team, and\norganizational level aspects of BSE.", "comment": "Submission to the Doctoral and Early Career Symposium of the\n  Cooperative and Human Aspects of Software Engineering 2025 conference", "pdf_url": "http://arxiv.org/pdf/2504.09496v2", "cate": "cs.SE", "date": "2025-04-13", "updated": "2025-07-08"}
{"id": "2409.01754", "title": "Empirical evidence of Large Language Model's influence on human spoken communication", "authors": ["Hiromu Yakura", "Ezequiel Lopez-Lopez", "Levin Brinkmann", "Ignacio Serna", "Prateek Gupta", "Ivan Soraperra", "Iyad Rahwan"], "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.01754v3", "summary": "From the invention of writing and the printing press, to television and\nsocial media, human history is punctuated by major innovations in communication\ntechnology, which fundamentally altered how ideas spread and reshaped our\nculture. Recent chatbots powered by generative artificial intelligence\nconstitute a novel medium that encodes cultural patterns in their neural\nrepresentations and disseminates them in conversations with hundreds of\nmillions of people. Understanding whether these patterns transmit into human\nlanguage, and ultimately shape human culture, is a fundamental question. While\nfully quantifying the causal impact of a chatbot like ChatGPT on human culture\nis very challenging, lexicographic shift in human spoken communication may\noffer an early indicator of such broad phenomenon. Here, we apply econometric\ncausal inference techniques to 740,249 hours of human discourse from 360,445\nYouTube academic talks and 771,591 conversational podcast episodes across\nmultiple disciplines. We detect a measurable and abrupt increase in the use of\nwords preferentially generated by ChatGPT, such as delve, comprehend, boast,\nswift, and meticulous, after its release. These findings suggest a scenario\nwhere machines, originally trained on human data and subsequently exhibiting\ntheir own cultural traits, can, in turn, measurably reshape human culture. This\nmarks the beginning of a closed cultural feedback loop in which cultural traits\ncirculate bidirectionally between humans and machines. Our results motivate\nfurther research into the evolution of human-machine culture, and raise\nconcerns over the erosion of linguistic and cultural diversity, and the risks\nof scalable manipulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.01754v3", "cate": "cs.CY", "date": "2024-09-03", "updated": "2025-07-08"}
{"id": "2507.06216", "title": "Unitary designs in nearly optimal depth", "authors": ["Laura Cui", "Thomas Schuster", "Fernando Brandao", "Hsin-Yuan Huang"], "categories": ["quant-ph", "cs.CC", "cs.IT", "math-ph", "math.IT", "math.MP"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      8+31 pages, 3+1 figures", "url": "http://arxiv.org/abs/2507.06216v1", "summary": "We construct $\\varepsilon$-approximate unitary $k$-designs on $n$ qubits in\ncircuit depth $O(\\log k \\log \\log n k / \\varepsilon)$. The depth is\nexponentially improved over all known results in all three parameters $n$, $k$,\n$\\varepsilon$. We further show that each dependence is optimal up to\nexponentially smaller factors. Our construction uses $\\tilde{{O}}(nk)$ ancilla\nqubits and ${O}(nk)$ bits of randomness, which are also optimal up to $\\log(n\nk)$ factors. An alternative construction achieves a smaller ancilla count\n$\\tilde{{O}}(n)$ with circuit depth ${O}(k \\log \\log nk/\\varepsilon)$. To\nachieve these efficient unitary designs, we introduce a highly-structured\nrandom unitary ensemble that leverages long-range two-qubit gates and low-depth\nimplementations of random classical hash functions. We also develop a new\nanalytical framework for bounding errors in quantum experiments involving many\nqueries to random unitaries. As an illustration of this framework's\nversatility, we provide a succinct alternative proof of the existence of\npseudorandom unitaries.", "comment": "8+31 pages, 3+1 figures", "pdf_url": "http://arxiv.org/pdf/2507.06216v1", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2409.15866", "title": "Online Planning for Multi-UAV Pursuit-Evasion in Unknown Environments Using Deep Reinforcement Learning", "authors": ["Jiayu Chen", "Chao Yu", "Guosheng Li", "Wenhao Tang", "Shilong Ji", "Xinyi Yang", "Botian Xu", "Huazhong Yang", "Yu Wang"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Published in IEEE Robotics and Automation Letters 2025", "url": "http://arxiv.org/abs/2409.15866v4", "summary": "Multi-UAV pursuit-evasion, where pursuers aim to capture evaders, poses a key\nchallenge for UAV swarm intelligence. Multi-agent reinforcement learning (MARL)\nhas demonstrated potential in modeling cooperative behaviors, but most RL-based\napproaches remain constrained to simplified simulations with limited dynamics\nor fixed scenarios. Previous attempts to deploy RL policy to real-world\npursuit-evasion are largely restricted to two-dimensional scenarios, such as\nground vehicles or UAVs at fixed altitudes. In this paper, we address multi-UAV\npursuit-evasion by considering UAV dynamics and physical constraints. We\nintroduce an evader prediction-enhanced network to tackle partial observability\nin cooperative strategy learning. Additionally, we propose an adaptive\nenvironment generator within MARL training, enabling higher exploration\nefficiency and better policy generalization across diverse scenarios.\nSimulations show our method significantly outperforms all baselines in\nchallenging scenarios, generalizing to unseen scenarios with a 100% capture\nrate. Finally, we derive a feasible policy via a two-stage reward refinement\nand deploy the policy on real quadrotors in a zero-shot manner. To our\nknowledge, this is the first work to derive and deploy an RL-based policy using\ncollective thrust and body rates control commands for multi-UAV pursuit-evasion\nin unknown environments. The open-source code and videos are available at\nhttps://sites.google.com/view/pursuit-evasion-rl.", "comment": "Published in IEEE Robotics and Automation Letters 2025", "pdf_url": "http://arxiv.org/pdf/2409.15866v4", "cate": "cs.RO", "date": "2024-09-24", "updated": "2025-07-08"}
{"id": "2507.06042", "title": "On Lockean beliefs that are deductively closed and minimal change", "authors": ["Tommaso Flaminio", "Lluis Godo", "Ramón Pino Pérez", "Lluis Subirana"], "categories": ["cs.AI", "03B42, 03B48"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      18 pages, to appear in the proceedings of JELIA 2025", "url": "http://arxiv.org/abs/2507.06042v1", "summary": "Within the formal setting of the Lockean thesis, an agent belief set is\ndefined in terms of degrees of confidence and these are described in\nprobabilistic terms. This approach is of established interest, notwithstanding\nsome limitations that make its use troublesome in some contexts, like, for\ninstance, in belief change theory. Precisely, Lockean belief sets are not\ngenerally closed under (classical) logical deduction. The aim of the present\npaper is twofold: on one side we provide two characterizations of those belief\nsets that are closed under classical logic deduction, and on the other we\npropose an approach to probabilistic update that allows us for a minimal\nrevision of those beliefs, i.e., a revision obtained by making the fewest\npossible changes to the existing belief set while still accommodating the new\ninformation. In particular, we show how we can deductively close a belief set\nvia a minimal revision.", "comment": "18 pages, to appear in the proceedings of JELIA 2025", "pdf_url": "http://arxiv.org/pdf/2507.06042v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05544", "title": "Gait-Based Hand Load Estimation via Deep Latent Variable Models with Auxiliary Information", "authors": ["Jingyi Gao", "Sol Lim", "Seokhyun Chung"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05544v1", "summary": "Machine learning methods are increasingly applied to ergonomic risk\nassessment in manual material handling, particularly for estimating carried\nload from gait motion data collected from wearable sensors. However, existing\napproaches often rely on direct mappings from loaded gait to hand load,\nlimiting generalization and predictive accuracy. In this study, we propose an\nenhanced load estimation framework that incorporates auxiliary information,\nincluding baseline gait patterns during unloaded walking and carrying style.\nWhile baseline gait can be automatically captured by wearable sensors and is\nthus readily available at inference time, carrying style typically requires\nmanual labeling and is often unavailable during deployment. Our model\nintegrates deep latent variable modeling with temporal convolutional networks\nand bi-directional cross-attention to capture gait dynamics and fuse loaded and\nunloaded gait patterns. Guided by domain knowledge, the model is designed to\nestimate load magnitude conditioned on carrying style, while eliminating the\nneed for carrying style labels at inference time. Experiments using real-world\ndata collected from inertial measurement units attached to participants\ndemonstrate substantial accuracy gains from incorporating auxiliary information\nand highlight the importance of explicit fusion mechanisms over naive feature\nconcatenation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05544v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05620", "title": "Generative Head-Mounted Camera Captures for Photorealistic Avatars", "authors": ["Shaojie Bai", "Seunghyeon Seo", "Yida Wang", "Chenghui Li", "Owen Wang", "Te-Li Wang", "Tianyang Ma", "Jason Saragih", "Shih-En Wei", "Nojun Kwak", "Hyung Jun Kim"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      15 pages, 16 figures", "url": "http://arxiv.org/abs/2507.05620v1", "summary": "Enabling photorealistic avatar animations in virtual and augmented reality\n(VR/AR) has been challenging because of the difficulty of obtaining ground\ntruth state of faces. It is physically impossible to obtain synchronized images\nfrom head-mounted cameras (HMC) sensing input, which has partial observations\nin infrared (IR), and an array of outside-in dome cameras, which have full\nobservations that match avatars' appearance. Prior works relying on\nanalysis-by-synthesis methods could generate accurate ground truth, but suffer\nfrom imperfect disentanglement between expression and style in their\npersonalized training. The reliance of extensive paired captures (HMC and dome)\nfor the same subject makes it operationally expensive to collect large-scale\ndatasets, which cannot be reused for different HMC viewpoints and lighting. In\nthis work, we propose a novel generative approach, Generative HMC (GenHMC),\nthat leverages large unpaired HMC captures, which are much easier to collect,\nto directly generate high-quality synthetic HMC images given any conditioning\navatar state from dome captures. We show that our method is able to properly\ndisentangle the input conditioning signal that specifies facial expression and\nviewpoint, from facial appearance, leading to more accurate ground truth.\nFurthermore, our method can generalize to unseen identities, removing the\nreliance on the paired captures. We demonstrate these breakthroughs by both\nevaluating synthetic HMC images and universal face encoders trained from these\nnew HMC-avatar correspondences, which achieve better data efficiency and\nstate-of-the-art accuracy.", "comment": "15 pages, 16 figures", "pdf_url": "http://arxiv.org/pdf/2507.05620v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2505.17460", "title": "Learning to Focus: Context Extraction for Efficient Code Vulnerability Detection with Language Models", "authors": ["Xinran Zheng", "Xingzhi Qian", "Huichi Zhou", "Shuo Yang", "Yiling He", "Suman Jana", "Lorenzo Cavallaro"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      withdrawal for fixing errors", "url": "http://arxiv.org/abs/2505.17460v2", "summary": "Language models (LMs) show promise for vulnerability detection but struggle\nwith long, real-world code due to sparse and uncertain vulnerability locations.\nThese issues, exacerbated by token limits, often cause models to miss\nvulnerability-related signals, thereby impairing effective learning. A key\nintuition is to enhance LMs with concise, information-rich context.\nCommit-based annotations offer precise, CWE-agnostic supervision, but are\nunavailable during inference, as they depend on historical code changes.\nMoreover, their extreme sparsity, often covering only a few lines, makes it\ndifficult for LMs to process directly. In this paper, we propose FocusVul, a\nmodel-agnostic framework that improves LM-based vulnerability detection by\nlearning to select sensitive context. FocusVul learns commit-based annotation\npatterns through hierarchical semantic modeling and generalizes them to\nidentify line-level vulnerability-relevant regions during inference. It then\nextracts LM-oriented context via both dependency and execution flows\nsurrounding selected regions, yielding semantically rich inputs for effective\nvulnerability detection. Experiments on real-world benchmarks show that\nFocusVul consistently outperforms heuristic-based and full-function fine-tuning\napproaches, improving classification performance by 164.04% and reducing FLOPs\nby 19.12% on average.", "comment": "withdrawal for fixing errors", "pdf_url": "http://arxiv.org/pdf/2505.17460v2", "cate": "cs.SE", "date": "2025-05-23", "updated": "2025-07-08"}
{"id": "2411.01866", "title": "Improving Trust Estimation in Human-Robot Collaboration Using Beta Reputation at Fine-grained Timescales", "authors": ["Resul Dagdanov", "Milan Andrejevic", "Dikai Liu", "Chin-Teng Lin"], "categories": ["cs.RO", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 7 figures, 1 table, published in IEEE Robotics and Automation Letters (RA-L) 2025", "url": "http://arxiv.org/abs/2411.01866v2", "summary": "When interacting with each other, humans adjust their behavior based on\nperceived trust. To achieve similar adaptability, robots must accurately\nestimate human trust at sufficiently granular timescales while collaborating\nwith humans. Beta reputation is a popular way to formalize a mathematical\nestimation of human trust. However, it relies on binary performance, which\nupdates trust estimations only after each task concludes. Additionally,\nmanually crafting a reward function is the usual method of building a\nperformance indicator, which is labor-intensive and time-consuming. These\nlimitations prevent efficient capture of continuous trust changes at more\ngranular timescales throughout the collaboration task. Therefore, this paper\npresents a new framework for the estimation of human trust using beta\nreputation at fine-grained timescales. To achieve granularity in beta\nreputation, we utilize continuous reward values to update trust estimates at\neach timestep of a task. We construct a continuous reward function using\nmaximum entropy optimization to eliminate the need for the laborious\nspecification of a performance indicator. The proposed framework improves trust\nestimations by increasing accuracy, eliminating the need to manually craft a\nreward function, and advancing toward the development of more intelligent\nrobots.", "comment": "8 pages, 7 figures, 1 table, published in IEEE Robotics and\n  Automation Letters (RA-L) 2025", "pdf_url": "http://arxiv.org/pdf/2411.01866v2", "cate": "cs.RO", "date": "2024-11-04", "updated": "2025-07-08"}
{"id": "2507.06232", "title": "Error Exponents for Quantum Packing Problems via An Operator Layer Cake Theorem", "authors": ["Hao-Chung Cheng", "Po-Chieh Liu"], "categories": ["quant-ph", "cs.IT", "math-ph", "math.FA", "math.IT", "math.MP"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06232v1", "summary": "In this work, we prove a one-shot random coding bound for classical-quantum\nchannel coding, a problem conjectured by Burnashev and Holevo in 1998. By\nchoosing the optimal input distribution, we recover the optimal error exponent\n(i.e., the reliability function) of classical-quantum channels for rates above\nthe critical rate. Our result extends to various quantum packing-type problems,\nincluding classical communication over any fully quantum channel with or\nwithout entanglement-assistance, constant composition codes, and classical data\ncompression with quantum side information via fixed-length or variable-length\ncoding.\n  Our technical ingredient is to establish an operator layer cake theorem - the\ndirectional derivative of an operator logarithm admits an integral\nrepresentation of certain projections. This shows that a kind of pretty-good\nmeasurement is equivalent to a randomized Holevo-Helstrom measurement, which\nprovides an operational explanation of why the pretty-good measurement is\npretty good.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06232v1", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06057", "title": "FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models", "authors": ["Bo Pang", "Yalu Ouyang", "Hangfei Xu", "Ziqi Jia", "Panpan Li", "Shengzhao Wen", "Lu Wang", "Shiyong Li", "Yanpeng Wang"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06057v1", "summary": "Advancements in reasoning for large language models (LLMs) have lead to\nsignificant performance improvements for LLMs in various fields such as\nmathematics and programming. However, research applying these advances to the\nfinancial domain, where considerable domain-specific knowledge is necessary to\ncomplete tasks, remains limited. To address this gap, we introduce FEVO\n(Financial Evolution), a multi-stage enhancement framework developed to enhance\nLLM performance in the financial domain. FEVO systemically enhances LLM\nperformance by using continued pre-training (CPT) to expand financial domain\nknowledge, supervised fine-tuning (SFT) to instill structured, elaborate\nreasoning patterns, and reinforcement learning (RL) to further integrate the\nexpanded financial domain knowledge with the learned structured reasoning. To\nensure effective and efficient training, we leverage frontier reasoning models\nand rule-based filtering to curate FEVO-Train, high-quality datasets\nspecifically designed for the different post-training phases. Using our\nframework, we train the FEVO series of models -- C32B, S32B, R32B -- from\nQwen2.5-32B and evaluate them on seven benchmarks to assess financial and\ngeneral capabilities, with results showing that FEVO-R32B achieves\nstate-of-the-art performance on five financial benchmarks against much larger\nmodels as well as specialist models. More significantly, FEVO-R32B demonstrates\nmarkedly better performance than FEVO-R32B-0 (trained from Qwen2.5-32B-Instruct\nusing only RL), thus validating the effectiveness of financial domain knowledge\nexpansion and structured, logical reasoning distillation", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06057v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05561", "title": "Preemptive Solving of Future Problems: Multitask Preplay in Humans and Machines", "authors": ["Wilka Carvalho", "Sam Hall-McMaster", "Honglak Lee", "Samuel J. Gershman"], "categories": ["cs.LG", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05561v1", "summary": "Humans can pursue a near-infinite variety of tasks, but typically can only\npursue a small number at the same time. We hypothesize that humans leverage\nexperience on one task to preemptively learn solutions to other tasks that were\naccessible but not pursued. We formalize this idea as Multitask Preplay, a\nnovel algorithm that replays experience on one task as the starting point for\n\"preplay\" -- counterfactual simulation of an accessible but unpursued task.\nPreplay is used to learn a predictive representation that can support fast,\nadaptive task performance later on. We first show that, compared to traditional\nplanning and predictive representation methods, multitask preplay better\npredicts how humans generalize to tasks that were accessible but not pursued in\na small grid-world, even when people didn't know they would need to generalize\nto these tasks. We then show these predictions generalize to Craftax, a\npartially observable 2D Minecraft environment. Finally, we show that Multitask\nPreplay enables artificial agents to learn behaviors that transfer to novel\nCraftax worlds sharing task co-occurrence structure. These findings demonstrate\nthat Multitask Preplay is a scalable theory of how humans counterfactually\nlearn and generalize across multiple tasks; endowing artificial agents with the\nsame capacity can significantly improve their performance in challenging\nmultitask environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05561v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05621", "title": "AdaptaGen: Domain-Specific Image Generation through Hierarchical Semantic Optimization Framework", "authors": ["Suoxiang Zhang", "Xiaxi Li", "Hongrui Chang", "Zhuoyan Hou", "Guoxin Wu", "Ronghua Ji"], "categories": ["cs.CV", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05621v1", "summary": "Domain-specific image generation aims to produce high-quality visual content\nfor specialized fields while ensuring semantic accuracy and detail fidelity.\nHowever, existing methods exhibit two critical limitations: First, current\napproaches address prompt engineering and model adaptation separately,\noverlooking the inherent dependence between semantic understanding and visual\nrepresentation in specialized domains. Second, these techniques inadequately\nincorporate domain-specific semantic constraints during content synthesis,\nresulting in generation outcomes that exhibit hallucinations and semantic\ndeviations. To tackle these issues, we propose AdaptaGen, a hierarchical\nsemantic optimization framework that integrates matrix-based prompt\noptimization with multi-perspective understanding, capturing comprehensive\nsemantic relationships from both global and local perspectives. To mitigate\nhallucinations in specialized domains, we design a cross-modal adaptation\nmechanism, which, when combined with intelligent content synthesis, enables\npreserving core thematic elements while incorporating diverse details across\nimages. Additionally, we introduce a two-phase caption semantic transformation\nduring the generation phase. This approach maintains semantic coherence while\nenhancing visual diversity, ensuring the generated images adhere to\ndomain-specific constraints. Experimental results confirm our approach's\neffectiveness, with our framework achieving superior performance across 40\ncategories from diverse datasets using only 16 images per category,\ndemonstrating significant improvements in image quality, diversity, and\nsemantic consistency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05621v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.18398", "title": "RPHunter: Unveiling Rug Pull Schemes in Crypto Token via Code-and-Transaction Fusion Analysis", "authors": ["Hao Wu", "Haijun Wang", "Shangwang Li", "Yin Wu", "Ming Fan", "Wuxia Jin", "Ting Liu"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.18398v3", "summary": "Rug pull scams have emerged as a persistent threat to cryptocurrency, causing\nsignificant financial losses. A typical scenario involves scammers deploying\nhoneypot contracts to attract investments, restricting token sales, and\ndraining the funds, which leaves investors with worthless tokens. Current\nmethods either rely on predefined patterns to detect code risks or utilize\nstatistical transaction data to train detection models. However, real-world Rug\nPull schemes often involve a complex interplay between malicious code and\nsuspicious transaction behaviors. These methods, which solely focus on one\naspect, fall short in detecting such schemes effectively.\n  In this paper, we propose RPHunter, a novel technique that integrates code\nand transaction for Rug Pull detection. First, RPHunter establishes declarative\nrules and performs flow analysis to extract code risk information, further\nconstructing a semantic risk code graph (SRCG). Meanwhile, to leverage\ntransaction information, RPHunter formulates dynamic token transaction\nactivities as a token flow behavior graph (TFBG) in which nodes and edges are\ncharacterized from network structure and market manipulation perspectives.\nFinally, RPHunter employs graph neural networks to extract complementary\nfeatures from SRCG and TFBG, integrating them through an attention fusion model\nto enhance the detection of Rug Pull. We manually analyzed 645 Rug Pull\nincidents from code and transaction aspects and constructed a ground-truth\ndataset. We evaluated RPHunter on our dataset, achieving a precision of 95.3%,\na recall of 93.8% and an F1 score of 94.5%, which highlights superior\nperformance compared to existing methods. Furthermore, when applied to the\nreal-world scenarios, RPHunter has identified 4801 Rug Pull tokens, achieving a\nprecision of 90.7%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.18398v3", "cate": "cs.SE", "date": "2025-06-23", "updated": "2025-07-08"}
{"id": "2411.13952", "title": "Learning thin deformable object manipulation with a multi-sensory integrated soft hand", "authors": ["Chao Zhao", "Chunli Jiang", "Lifan Luo", "Shuai Yuan", "Qifeng Chen", "Hongyu Yu"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted by T-RO, 20 pages", "url": "http://arxiv.org/abs/2411.13952v2", "summary": "Robotic manipulation has made significant advancements, with systems\ndemonstrating high precision and repeatability. However, this remarkable\nprecision often fails to translate into efficient manipulation of thin\ndeformable objects. Current robotic systems lack imprecise dexterity, the\nability to perform dexterous manipulation through robust and adaptive behaviors\nthat do not rely on precise control. This paper explores the singulation and\ngrasping of thin, deformable objects. Here, we propose a novel solution that\nincorporates passive compliance, touch, and proprioception into thin,\ndeformable object manipulation. Our system employs a soft, underactuated hand\nthat provides passive compliance, facilitating adaptive and gentle interactions\nto dexterously manipulate deformable objects without requiring precise control.\nThe tactile and force/torque sensors equipped on the hand, along with a depth\ncamera, gather sensory data required for manipulation via the proposed slip\nmodule. The manipulation policies are learned directly from raw sensory data\nvia model-free reinforcement learning, bypassing explicit environmental and\nobject modeling. We implement a hierarchical double-loop learning process to\nenhance learning efficiency by decoupling the action space. Our method was\ndeployed on real-world robots and trained in a self-supervised manner. The\nresulting policy was tested on a variety of challenging tasks that were beyond\nthe capabilities of prior studies, ranging from displaying suit fabric like a\nsalesperson to turning pages of sheet music for violinists.", "comment": "Accepted by T-RO, 20 pages", "pdf_url": "http://arxiv.org/pdf/2411.13952v2", "cate": "cs.RO", "date": "2024-11-21", "updated": "2025-07-08"}
{"id": "2507.06077", "title": "AI-Based Demand Forecasting and Load Balancing for Optimising Energy use in Healthcare Systems: A real case study", "authors": ["Iman Rahimi", "Isha Patel"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06077v1", "summary": "This paper tackles the urgent need for efficient energy management in\nhealthcare facilities, where fluctuating demands challenge operational\nefficiency and sustainability. Traditional methods often prove inadequate,\ncausing inefficiencies and higher costs. To address this, the study presents an\nAI-based framework combining Long Short-Term Memory (LSTM), genetic algorithm\n(GA), and SHAP (Shapley Additive Explanations), specifically designed for\nhealthcare energy management. Although LSTM is widely used for time-series\nforecasting, its application in healthcare energy prediction remains\nunderexplored. The results reveal that LSTM significantly outperforms ARIMA and\nProphet models in forecasting complex, non-linear demand patterns. LSTM\nachieves a Mean Absolute Error (MAE) of 21.69 and Root Mean Square Error (RMSE)\nof 29.96, far better than Prophet (MAE: 59.78, RMSE: 81.22) and ARIMA (MAE:\n87.73, RMSE: 125.22), demonstrating superior performance. The genetic algorithm\nis applied to optimize model parameters and improve load balancing strategies,\nenabling adaptive responses to real-time energy fluctuations. SHAP analysis\nfurther enhances model transparency by explaining the influence of different\nfeatures on predictions, fostering trust in decision-making processes. This\nintegrated LSTM-GA-SHAP approach offers a robust solution for improving\nforecasting accuracy, boosting energy efficiency, and advancing sustainability\nin healthcare facilities. Future research may explore real-time deployment and\nhybridization with reinforcement learning for continuous optimization. Overall,\nthe study establishes a solid foundation for using AI in healthcare energy\nmanagement, highlighting its scalability, efficiency, and resilience potential.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06077v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05631", "title": "OFFSET: Segmentation-based Focus Shift Revision for Composed Image Retrieval", "authors": ["Zhiwei Chen", "Yupeng Hu", "Zixu Li", "Zhiheng Fu", "Xuemeng Song", "Liqiang Nie"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05631v1", "summary": "Composed Image Retrieval (CIR) represents a novel retrieval paradigm that is\ncapable of expressing users' intricate retrieval requirements flexibly. It\nenables the user to give a multimodal query, comprising a reference image and a\nmodification text, and subsequently retrieve the target image. Notwithstanding\nthe considerable advances made by prevailing methodologies, CIR remains in its\nnascent stages due to two limitations: 1) inhomogeneity between dominant and\nnoisy portions in visual data is ignored, leading to query feature degradation,\nand 2) the priority of textual data in the image modification process is\noverlooked, which leads to a visual focus bias. To address these two\nlimitations, this work presents a focus mapping-based feature extractor, which\nconsists of two modules: dominant portion segmentation and dual focus mapping.\nIt is designed to identify significant dominant portions in images and guide\nthe extraction of visual and textual data features, thereby reducing the impact\nof noise interference. Subsequently, we propose a textually guided focus\nrevision module, which can utilize the modification requirements implied in the\ntext to perform adaptive focus revision on the reference image, thereby\nenhancing the perception of the modification focus on the composed features.\nThe aforementioned modules collectively constitute the segmentatiOn-based Focus\nshiFt reviSion nETwork (\\mbox{OFFSET}), and comprehensive experiments on four\nbenchmark datasets substantiate the superiority of our proposed method. The\ncodes and data are available on https://zivchen-ty.github.io/OFFSET.github.io/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05631v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.03160", "title": "Assessing Small Language Models for Code Generation: An Empirical Study with Benchmarks", "authors": ["Md Mahade Hasan", "Muhammad Waseem", "Kai-Kristian Kemell", "Jussi Rasku", "Juha Ala-Rantala", "Pekka Abrahamsson"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03160v2", "summary": "The recent advancements of Small Language Models (SLMs) have opened new\npossibilities for efficient code generation. SLMs offer lightweight and\ncost-effective alternatives to Large Language Models (LLMs), making them\nattractive for use in resource-constrained environments. However, empirical\nunderstanding of SLMs, particularly their capabilities, limitations, and\nperformance trade-offs in code generation remains limited. This study presents\na comprehensive empirical evaluation of 20 open-source SLMs ranging from 0.4B\nto 10B parameters on five diverse code-related benchmarks (HumanEval, MBPP,\nMercury, HumanEvalPack, and CodeXGLUE). The models are assessed along three\ndimensions: i) functional correctness of generated code, ii) computational\nefficiency and iii) performance across multiple programming languages. The\nfindings of this study reveal that several compact SLMs achieve competitive\nresults while maintaining a balance between performance and efficiency, making\nthem viable for deployment in resource-constrained environments. However,\nachieving further improvements in accuracy requires switching to larger models.\nThese models generally outperform their smaller counterparts, but they require\nmuch more computational power. We observe that for 10% performance\nimprovements, models can require nearly a 4x increase in VRAM consumption,\nhighlighting a trade-off between effectiveness and scalability. Besides, the\nmultilingual performance analysis reveals that SLMs tend to perform better in\nlanguages such as Python, Java, and PHP, while exhibiting relatively weaker\nperformance in Go, C++, and Ruby. However, statistical analysis suggests these\ndifferences are not significant, indicating a generalizability of SLMs across\nprogramming languages. Based on the findings, this work provides insights into\nthe design and selection of SLMs for real-world code generation tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03160v2", "cate": "cs.SE", "date": "2025-07-03", "updated": "2025-07-08"}
{"id": "2412.20867", "title": "Holistic Construction Automation with Modular Robots: From High-Level Task Specification to Execution", "authors": ["Jonathan Külz", "Michael Terzer", "Marco Magri", "Andrea Giusti", "Matthias Althoff"], "categories": ["cs.RO", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Appeared in IEEE Transactions on Automation Science and Engineering this https URL", "url": "http://arxiv.org/abs/2412.20867v2", "summary": "In situ robotic automation in construction is challenging due to constantly\nchanging environments, a shortage of robotic experts, and a lack of\nstandardized frameworks bridging robotics and construction practices. This work\nproposes a holistic framework for construction task specification, optimization\nof robot morphology, and mission execution using a mobile modular\nreconfigurable robot. Users can specify and monitor the desired robot behavior\nthrough a graphical interface. In contrast to existing, monolithic solutions,\nwe automatically identify a new task-tailored robot for every task by\nintegrating \\acf{bim}. Our framework leverages modular robot components that\nenable the fast adaption of robot hardware to the specific demands of the\nconstruction task. Other than previous works on modular robot optimization, we\nconsider multiple competing objectives, which allow us to explicitly model the\nchallenges of real-world transfer, such as calibration errors. We demonstrate\nour framework in simulation by optimizing robots for drilling and spray\npainting. Finally, experimental validation demonstrates that our approach\nrobustly enables the autonomous execution of robotic drilling.", "comment": "Appeared in IEEE Transactions on Automation Science and Engineering\n  https://ieeexplore.ieee.org/document/11036791", "pdf_url": "http://arxiv.org/pdf/2412.20867v2", "cate": "cs.RO", "date": "2024-12-30", "updated": "2025-07-08"}
{"id": "2401.17577", "title": "Robustness in Wireless Distributed Learning: An Information-Theoretic Analysis", "authors": ["Yangshuo He", "Guanding Yu", "Huaiyu Dai"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      16 pages, 9 figures", "url": "http://arxiv.org/abs/2401.17577v3", "summary": "In recent years, the application of artificial intelligence (AI) in wireless\ncommunications has demonstrated inherent robustness against wireless channel\ndistortions. Most existing works empirically leverage this robustness to yield\nconsiderable performance gains through AI architectural designs. However, there\nis a lack of direct theoretical analysis of this robustness and its potential\nto enhance communication efficiency, which restricts the full exploitation of\nthese advantages. In this paper, we adopt an information-theoretic approach to\nevaluate the robustness in wireless distributed learning by deriving an upper\nbound on the task performance loss due to imperfect wireless channels.\nUtilizing this insight, we define task outage probability and characterize the\nmaximum transmission rate under task accuracy guarantees, referred to as the\ntask-aware $\\epsilon$-capacity resulting from the robustness. To achieve the\nutility of the theoretical results in practical settings, we present an\nefficient algorithm for the approximation of the upper bound. Subsequently, we\ndevise a robust training framework that optimizes the trade-off between\nrobustness and task accuracy, enhancing the robustness against channel\ndistortions. Extensive experiments validate the effectiveness of the proposed\nupper bound and task-aware $\\epsilon$-capacity and demonstrate that the\nproposed robust training framework achieves high robustness, thus ensuring a\nhigh transmission rate while maintaining inference performance.", "comment": "16 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2401.17577v3", "cate": "cs.IT", "date": "2024-01-31", "updated": "2025-07-08"}
{"id": "2412.19942", "title": "Detecting and Diagnosing Faults in Autonomous Robot Swarms with an Artificial Antibody Population Model", "authors": ["James O'Keeffe"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.19942v2", "summary": "An active approach to fault tolerance, the combined processes of fault\ndetection, diagnosis, and recovery, is essential for long term autonomy in\nrobots -- particularly multi-robot systems and swarms. Previous efforts have\nprimarily focussed on spontaneously occurring electro-mechanical failures in\nthe sensors and actuators of a minority sub-population of robots. While the\nsystems that enable this function are valuable, they have not yet considered\nthat many failures arise from gradual wear and tear with continued operation,\nand that this may be more challenging to detect than sudden step changes in\nperformance. This paper presents the Artificial Antibody Population Dynamics\n(AAPD) model -- an immune-inspired model for the detection and diagnosis of\ngradual degradation in robot swarms. The AAPD model is demonstrated to reliably\ndetect and diagnose gradual degradation, as well as spontaneous changes in\nperformance, among swarms of robots of varying sizes while remaining tolerant\nof normally behaving robots. The AAPD model is distributed, offers supervised\nand unsupervised configurations, and demonstrates promising scalable\nproperties. Deploying the AAPD model on a swarm of foraging robots undergoing\ngradual degradation enables the swarm to operate on average at between 70% -\n97% of its performance in perfect conditions and is able to prevent instances\nof robots failing in the field during experiments in most of the cases tested.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.19942v2", "cate": "cs.RO", "date": "2024-12-27", "updated": "2025-07-08"}
{"id": "2507.06134", "title": "OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety", "authors": ["Sanidhya Vijayvargiya", "Aditya Bharat Soni", "Xuhui Zhou", "Zora Zhiruo Wang", "Nouha Dziri", "Graham Neubig", "Maarten Sap"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      19 pages, 10 figures", "url": "http://arxiv.org/abs/2507.06134v1", "summary": "Recent advances in AI agents capable of solving complex, everyday tasks, from\nscheduling to customer service, have enabled deployment in real-world settings,\nbut their possibilities for unsafe behavior demands rigorous evaluation. While\nprior benchmarks have attempted to assess agent safety, most fall short by\nrelying on simulated environments, narrow task domains, or unrealistic tool\nabstractions. We introduce OpenAgentSafety, a comprehensive and modular\nframework for evaluating agent behavior across eight critical risk categories.\nUnlike prior work, our framework evaluates agents that interact with real\ntools, including web browsers, code execution environments, file systems, bash\nshells, and messaging platforms; and supports over 350 multi-turn, multi-user\ntasks spanning both benign and adversarial user intents. OpenAgentSafety is\ndesigned for extensibility, allowing researchers to add tools, tasks, websites,\nand adversarial strategies with minimal effort. It combines rule-based analysis\nwith LLM-as-judge assessments to detect both overt and subtle unsafe behaviors.\nEmpirical analysis of five prominent LLMs in agentic scenarios reveals unsafe\nbehavior in 51.2% of safety-vulnerable tasks with Claude-Sonnet-3.7, to 72.7%\nwith o3-mini, highlighting critical safety vulnerabilities and the need for\nstronger safeguards before real-world deployment.", "comment": "19 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.06134v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05583", "title": "Model-free Optical Processors using In Situ Reinforcement Learning with Proximal Policy Optimization", "authors": ["Yuhang Li", "Shiqi Chen", "Tingyu Gong", "Aydogan Ozcan"], "categories": ["cs.LG", "cs.NE", "physics.app-ph", "physics.optics"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      19 Pages, 7 Figures", "url": "http://arxiv.org/abs/2507.05583v1", "summary": "Optical computing holds promise for high-speed, energy-efficient information\nprocessing, with diffractive optical networks emerging as a flexible platform\nfor implementing task-specific transformations. A challenge, however, is the\neffective optimization and alignment of the diffractive layers, which is\nhindered by the difficulty of accurately modeling physical systems with their\ninherent hardware imperfections, noise, and misalignments. While existing in\nsitu optimization methods offer the advantage of direct training on the\nphysical system without explicit system modeling, they are often limited by\nslow convergence and unstable performance due to inefficient use of limited\nmeasurement data. Here, we introduce a model-free reinforcement learning\napproach utilizing Proximal Policy Optimization (PPO) for the in situ training\nof diffractive optical processors. PPO efficiently reuses in situ measurement\ndata and constrains policy updates to ensure more stable and faster\nconvergence. We experimentally validated our method across a range of in situ\nlearning tasks, including targeted energy focusing through a random diffuser,\nholographic image generation, aberration correction, and optical image\nclassification, demonstrating in each task better convergence and performance.\nOur strategy operates directly on the physical system and naturally accounts\nfor unknown real-world imperfections, eliminating the need for prior system\nknowledge or modeling. By enabling faster and more accurate training under\nrealistic experimental constraints, this in situ reinforcement learning\napproach could offer a scalable framework for various optical and physical\nsystems governed by complex, feedback-driven dynamics.", "comment": "19 Pages, 7 Figures", "pdf_url": "http://arxiv.org/pdf/2507.05583v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05666", "title": "Knowledge-guided Complex Diffusion Model for PolSAR Image Classification in Contourlet Domain", "authors": ["Junfei Shi", "Yu Cheng", "Haiyan Jin", "Junhuai Li", "Zhaolin Xiao", "Maoguo Gong", "Weisi Lin"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05666v1", "summary": "Diffusion models have demonstrated exceptional performance across various\ndomains due to their ability to model and generate complicated data\ndistributions. However, when applied to PolSAR data, traditional real-valued\ndiffusion models face challenges in capturing complex-valued phase\ninformation.Moreover, these models often struggle to preserve fine structural\ndetails. To address these limitations, we leverage the Contourlet transform,\nwhich provides rich multiscale and multidirectional representations well-suited\nfor PolSAR imagery. We propose a structural knowledge-guided complex diffusion\nmodel for PolSAR image classification in the Contourlet domain. Specifically,\nthe complex Contourlet transform is first applied to decompose the data into\nlow- and high-frequency subbands, enabling the extraction of statistical and\nboundary features. A knowledge-guided complex diffusion network is then\ndesigned to model the statistical properties of the low-frequency components.\nDuring the process, structural information from high-frequency coefficients is\nutilized to guide the diffusion process, improving edge preservation.\nFurthermore, multiscale and multidirectional high-frequency features are\njointly learned to further boost classification accuracy. Experimental results\non three real-world PolSAR datasets demonstrate that our approach surpasses\nstate-of-the-art methods, particularly in preserving edge details and\nmaintaining region homogeneity in complex terrain.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05666v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.03328", "title": "scikit-package -- software packaging standards and roadmap for sharing reproducible scientific software", "authors": ["S. Lee", "C. Myers", "A. Yang", "T. Zhang", "S. J. L. Billinge"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      GitHub: this https URL Doc: this https URL", "url": "http://arxiv.org/abs/2507.03328v2", "summary": "Scientific advancement relies on the ability to share and reproduce results.\nWhen data analysis or calculations are carried out using software written by\nscientists there are special challenges around code versions, quality and code\nsharing. scikit-package provides a roadmap to facilitate code reuse and sharing\nwith minimal effort through tutorials coupled with automated and centralized\nreusable workflows. The goal of the project is to provide pedagogical and\npractical tools for scientists who are not professionally trained software\nengineers to write more reusable and maintainable software code. Code reuse can\noccur at multiple levels of complexity-from turning a code block into a\nfunction within a single script, to publishing a publicly installable, fully\ntested, and documented software package scikit-package provides a community\nmaintained set of tools, and a roadmap, to help scientists bring their software\nhigher levels of reproducibility and shareability.", "comment": "GitHub: https://github.com/scikit-package/scikit-package Doc:\n  https://scikit-package.github.io/scikit-package/", "pdf_url": "http://arxiv.org/pdf/2507.03328v2", "cate": "cs.SE", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2503.06416", "title": "Advancing AI Negotiations: New Theory and Evidence from a Large-Scale Autonomous Negotiations Competition", "authors": ["Michelle Vaccaro", "Michael Caosun", "Harang Ju", "Sinan Aral", "Jared R. Curhan"], "categories": ["cs.AI", "cs.HC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.06416v2", "summary": "We conducted an International AI Negotiation Competition in which\nparticipants designed and refined prompts for AI negotiation agents. We then\nfacilitated over 180,000 negotiations between these agents across multiple\nscenarios with diverse characteristics and objectives. Our findings revealed\nthat principles from human negotiation theory remain crucial even in AI-AI\ncontexts. Surprisingly, warmth--a traditionally human relationship-building\ntrait--was consistently associated with superior outcomes across all key\nperformance metrics. Dominant agents, meanwhile, were especially effective at\nclaiming value. Our analysis also revealed unique dynamics in AI-AI\nnegotiations not fully explained by existing theory, including AI-specific\ntechnical strategies like chain-of-thought reasoning, prompt injection, and\nstrategic concealment. When we applied natural language processing (NLP)\nmethods to the full transcripts of all negotiations we found positivity,\ngratitude and question-asking (associated with warmth) were strongly associated\nwith reaching deals as well as objective and subjective value, whereas\nconversation lengths (associated with dominance) were strongly associated with\nimpasses. The results suggest the need to establish a new theory of AI\nnegotiation, which integrates classic negotiation theory with AI-specific\nnegotiation theories to better understand autonomous negotiations and optimize\nagent performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.06416v2", "cate": "cs.AI", "date": "2025-03-09", "updated": "2025-07-07"}
{"id": "2507.06187", "title": "The Delta Learning Hypothesis: Preference Tuning on Weak Data can Yield Strong Gains", "authors": ["Scott Geng", "Hamish Ivison", "Chun-Liang Li", "Maarten Sap", "Jerry Li", "Ranjay Krishna", "Pang Wei Koh"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      COLM 2025", "url": "http://arxiv.org/abs/2507.06187v1", "summary": "Improvements in language models are often driven by improving the quality of\nthe data we train them on, which can be limiting when strong supervision is\nscarce. In this work, we show that paired preference data consisting of\nindividually weak data points can enable gains beyond the strength of each\nindividual data point. We formulate the delta learning hypothesis to explain\nthis phenomenon, positing that the relative quality delta between points\nsuffices to drive learning via preference tuning--even when supervised\nfinetuning on the weak data hurts. We validate our hypothesis in controlled\nexperiments and at scale, where we post-train 8B models on preference data\ngenerated by pairing a small 3B model's responses with outputs from an even\nsmaller 1.5B model to create a meaningful delta. Strikingly, on a standard\n11-benchmark evaluation suite (MATH, MMLU, etc.), our simple recipe matches the\nperformance of Tulu 3, a state-of-the-art open model tuned from the same base\nmodel while relying on much stronger supervisors (e.g., GPT-4o). Thus, delta\nlearning enables simpler and cheaper open recipes for state-of-the-art\npost-training. To better understand delta learning, we prove in logistic\nregression that the performance gap between two weak teacher models provides\nuseful signal for improving a stronger student. Overall, our work shows that\nmodels can learn surprisingly well from paired data that might typically be\nconsidered weak.", "comment": "COLM 2025", "pdf_url": "http://arxiv.org/pdf/2507.06187v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05584", "title": "The Fourier Spectral Transformer Networks For Efficient and Generalizable Nonlinear PDEs Prediction", "authors": ["Beibei Li"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05584v1", "summary": "In this work we propose a unified Fourier Spectral Transformer network that\nintegrates the strengths of classical spectral methods and attention based\nneural architectures. By transforming the original PDEs into spectral ordinary\ndifferential equations, we use high precision numerical solvers to generate\ntraining data and use a Transformer network to model the evolution of the\nspectral coefficients. We demonstrate the effectiveness of our approach on the\ntwo dimensional incompressible Navier-Stokes equations and the one dimensional\nBurgers' equation. The results show that our spectral Transformer can achieve\nhighly accurate long term predictions even with limited training data, better\nthan traditional numerical methods and machine learning methods in forecasting\nfuture flow dynamics. The proposed framework generalizes well to unseen data,\nbringing a promising paradigm for real time prediction and control of complex\ndynamical systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05584v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05668", "title": "Dynamic Rank Adaptation for Vision-Language Models", "authors": ["Jiahui Wang", "Qin Xu", "Bo Jiang", "Bin Luo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05668v1", "summary": "Pre-trained large vision-language models (VLMs) like CLIP demonstrate\nimpressive generalization ability. Existing prompt-based and adapter-based\nworks have made significant progress in fine-tuning VLMs but still face the\nchallenges of maintaining strong generalization abilities, particularly towards\nunseen new classes. This limitation partly arises from these methods treating\nall tokens of the image and text encoder equally, which can lead to overfitting\non less informative features (e.g., background noise, template words) and\ndegrade the general representations that are crucial for novel concept\nrecognition. To address this issue, we propose Dynamic Rank Adaptation (DRA), a\nnovel adapter variant method, designed specifically to enhance new class\ngeneralization. DRA dynamically allocates adaptation ranks based on the\nimportance of features during training to preserve general knowledge. DRA first\nemploys token importance grouping, using sequence attention to evaluate and\ngroup tokens by their importance. Then, we adopt rank adaptation according to\nthe importance of each token group dynamically by assigning higher feature\nranks to the more important tokens. Also, we design a new channel response\nmechanism to prioritize the preservation and adaptation of feature channels\nidentified as the most informative for each instance. In addition, a L1\nregularization term is introduced to stabilize the training. Extensive\nexperiments demonstrate the effectiveness and superiority of our proposed DRA\nover existing works, especially on enhancing the performance of new classes on\nvarious benchmarks, including base-new classes, cross-datasets evaluation and\ndomain generalization. The source code will be published after the paper is\nreceived.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05668v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.04173", "title": "Efficient Detection of Intermittent Job Failures Using Few-Shot Learning", "authors": ["Henri Aïdasso", "Francis Bordeleau", "Ali Tizghadam"], "categories": ["cs.SE", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at the 41st International Conference on Software Maintenance and Evolution - ICSME 2025 (Industry Track); 12 pages; typos corrected", "url": "http://arxiv.org/abs/2507.04173v2", "summary": "One of the main challenges developers face in the use of continuous\nintegration (CI) and deployment pipelines is the occurrence of intermittent job\nfailures, which result from unexpected non-deterministic issues (e.g., flaky\ntests or infrastructure problems) rather than regular code-related errors such\nas bugs. Prior studies developed machine learning (ML) models trained on large\ndatasets of job logs to classify job failures as either intermittent or\nregular. As an alternative to costly manual labeling of large datasets, the\nstate-of-the-art (SOTA) approach leveraged a heuristic based on\nnon-deterministic job reruns. However, this method mislabels intermittent job\nfailures as regular in contexts where rerunning suspicious job failures is not\nan explicit policy, and therefore limits the SOTA's performance in practice. In\nfact, our manual analysis of 2,125 job failures from 5 industrial and 1\nopen-source projects reveals that, on average, 32% of intermittent job failures\nare mislabeled as regular. To address these limitations, this paper introduces\na novel approach to intermittent job failure detection using few-shot learning\n(FSL). Specifically, we fine-tune a small language model using a few number of\nmanually labeled log examples to generate rich embeddings, which are then used\nto train an ML classifier. Our FSL-based approach achieves 70-88% F1-score with\nonly 12 shots in all projects, outperforming the SOTA, which proved ineffective\n(34-52% F1-score) in 4 projects. Overall, this study underlines the importance\nof data quality over quantity and provides a more efficient and practical\nframework for the detection of intermittent job failures in organizations.", "comment": "Accepted at the 41st International Conference on Software Maintenance\n  and Evolution - ICSME 2025 (Industry Track); 12 pages; typos corrected", "pdf_url": "http://arxiv.org/pdf/2507.04173v2", "cate": "cs.SE", "date": "2025-07-05", "updated": "2025-07-08"}
{"id": "2507.02950", "title": "Evaluating AI Counseling in Japanese: Counselor, Client, and Evaluator Roles Assessed by Motivational Interviewing Criteria", "authors": ["Keita Kiuchi", "Yoshikazu Fujimoto", "Hideyuki Goto", "Tomonori Hosokawa", "Makoto Nishimura", "Yosuke Sato", "Izumi Sezai"], "categories": ["cs.CL", "cs.AI", "cs.HC", "68T50", "I.2.7; H.5.2; J.4"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      70 pages, 0 figures, 9 tables; data and code at this https URL", "url": "http://arxiv.org/abs/2507.02950v2", "summary": "This study provides the first comprehensive evaluation of large language\nmodel (LLM) performance across three counseling roles in Japanese-language\ntherapeutic contexts. We simultaneously assessed counselor artificial\nintelligence (AI) systems (GPT-4-turbo with zeroshot prompting or Structured\nMulti-step Dialogue Prompts (SMDP), Claude-3-Opus-SMDP), client AI simulations,\nand evaluation AI systems (o3, Claude-3.7-Sonnet, Gemini-2.5-pro). Human\nexperts (n = 15) with extensive counseling experience evaluated AI-generated\ndialogues using the Motivational Interviewing Treatment Integrity (MITI) Coding\nManual 4.2.1.\n  Notably, SMDP implementation significantly enhanced counselor AI performance\nacross all MITI global ratings compared with zeroshot prompting, with no\nsignificant differences between GPT-SMDP and Opus-SMDP. Evaluation AIs showed\ncomparable performance to human raters for Cultivating Change Talk but\nsystematically overestimated Softening Sustain Talk and the overall quality\nmetrics. Model-specific biases emerged: Gemini emphasized power-sharing, o3\nfocused on technical proficiency, and Sonnet prioritized emotional expression.\nClient AI simulations exhibited a limited emotional range and unnaturally high\ncompliance, indicating the need for enhanced realism.\n  These findings establish benchmarks for AI-assisted counseling in non-English\ncontexts and identify critical areas for improvement through advanced prompt\nengineering, retrieval-augmented generation, and targeted fine-tuning, with\nimportant implications for developing culturally sensitive AI mental health\ntools.", "comment": "70 pages, 0 figures, 9 tables; data and code at\n  https://osf.io/p8c39/files/2e58c42f-a7ba-45f2-aa60-265e107e36db", "pdf_url": "http://arxiv.org/pdf/2507.02950v2", "cate": "cs.CL", "date": "2025-06-28", "updated": "2025-07-08"}
{"id": "2502.01932", "title": "VolleyBots: A Testbed for Multi-Drone Volleyball Game Combining Motion Control and Strategic Play", "authors": ["Zelai Xu", "Ruize Zhang", "Chao Yu", "Huining Yuan", "Xiangmin Yi", "Shilong Ji", "Chuqi Wang", "Wenhao Tang", "Feng Gao", "Wenbo Ding", "Xinlei Chen", "Yu Wang"], "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.01932v4", "summary": "Robot sports, characterized by well-defined objectives, explicit rules, and\ndynamic interactions, present ideal scenarios for demonstrating embodied\nintelligence. In this paper, we present VolleyBots, a novel robot sports\ntestbed where multiple drones cooperate and compete in the sport of volleyball\nunder physical dynamics. VolleyBots integrates three features within a unified\nplatform: competitive and cooperative gameplay, turn-based interaction\nstructure, and agile 3D maneuvering. Competitive and cooperative gameplay\nchallenges each drone to coordinate with its teammates while anticipating and\ncountering opposing teams' tactics. Turn-based interaction demands precise\ntiming, accurate state prediction, and management of long-horizon temporal\ndependencies. Agile 3D maneuvering requires rapid accelerations, sharp turns,\nand precise 3D positioning despite the quadrotor's underactuated dynamics.\nThese intertwined features yield a complex problem combining motion control and\nstrategic play, with no available expert demonstrations. We provide a\ncomprehensive suite of tasks ranging from single-drone drills to multi-drone\ncooperative and competitive tasks, accompanied by baseline evaluations of\nrepresentative multi-agent reinforcement learning (MARL) and game-theoretic\nalgorithms. Simulation results show that on-policy reinforcement learning (RL)\nmethods outperform off-policy methods in single-agent tasks, but both\napproaches struggle in complex tasks that combine motion control and strategic\nplay. We additionally design a hierarchical policy which achieves a 69.5%\npercent win rate against the strongest baseline in the 3 vs 3 task,\nunderscoring its potential as an effective solution for tackling the complex\ninterplay between low-level control and high-level strategy. The project page\nis at https://sites.google.com/view/thu-volleybots.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.01932v4", "cate": "cs.RO", "date": "2025-02-04", "updated": "2025-07-08"}
{"id": "2507.06213", "title": "Identifiability in Causal Abstractions: A Hierarchy of Criteria", "authors": ["Clément Yvernes", "Emilie Devijver", "Marianne Clausel", "Eric Gaussier"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted at the CAR Workshop at UAI2025", "url": "http://arxiv.org/abs/2507.06213v1", "summary": "Identifying the effect of a treatment from observational data typically\nrequires assuming a fully specified causal diagram. However, such diagrams are\nrarely known in practice, especially in complex or high-dimensional settings.\nTo overcome this limitation, recent works have explored the use of causal\nabstractions-simplified representations that retain partial causal information.\nIn this paper, we consider causal abstractions formalized as collections of\ncausal diagrams, and focus on the identifiability of causal queries within such\ncollections. We introduce and formalize several identifiability criteria under\nthis setting. Our main contribution is to organize these criteria into a\nstructured hierarchy, highlighting their relationships. This hierarchical view\nenables a clearer understanding of what can be identified under varying levels\nof causal knowledge. We illustrate our framework through examples from the\nliterature and provide tools to reason about identifiability when full causal\nknowledge is unavailable.", "comment": "Accepted at the CAR Workshop at UAI2025", "pdf_url": "http://arxiv.org/pdf/2507.06213v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05670", "title": "Modeling and Reversing Brain Lesions Using Diffusion Models", "authors": ["Omar Zamzam", "Haleh Akrami", "Anand Joshi", "Richard Leahy"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05670v1", "summary": "Brain lesions are abnormalities or injuries in brain tissue that are often\ndetectable using magnetic resonance imaging (MRI), which reveals structural\nchanges in the affected areas. This broad definition of brain lesions includes\nareas of the brain that are irreversibly damaged, as well as areas of brain\ntissue that are deformed as a result of lesion growth or swelling. Despite the\nimportance of differentiating between damaged and deformed tissue, existing\nlesion segmentation methods overlook this distinction, labeling both of them as\na single anomaly. In this work, we introduce a diffusion model-based framework\nfor analyzing and reversing the brain lesion process. Our pipeline first\nsegments abnormal regions in the brain, then estimates and reverses tissue\ndeformations by restoring displaced tissue to its original position, isolating\nthe core lesion area representing the initial damage. Finally, we inpaint the\ncore lesion area to arrive at an estimation of the pre-lesion healthy brain.\nThis proposed framework reverses a forward lesion growth process model that is\nwell-established in biomechanical studies that model brain lesions. Our results\ndemonstrate improved accuracy in lesion segmentation, characterization, and\nbrain labeling compared to traditional methods, offering a robust tool for\nclinical and research applications in brain lesion analysis. Since pre-lesion\nhealthy versions of abnormal brains are not available in any public dataset for\nvalidation of the reverse process, we simulate a forward model to synthesize\nmultiple lesioned brain images.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05670v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.04359", "title": "cuVSLAM: CUDA accelerated visual odometry and mapping", "authors": ["Alexander Korovko", "Dmitry Slepichev", "Alexander Efitorov", "Aigul Dzhumamuratova", "Viktor Kuznetsov", "Hesam Rabeti", "Joydeep Biswas", "Soha Pouya"], "categories": ["cs.RO", "cs.AI", "cs.SE"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.04359v3", "summary": "Accurate and robust pose estimation is a key requirement for any autonomous\nrobot. We present cuVSLAM, a state-of-the-art solution for visual simultaneous\nlocalization and mapping, which can operate with a variety of visual-inertial\nsensor suites, including multiple RGB and depth cameras, and inertial\nmeasurement units. cuVSLAM supports operation with as few as one RGB camera to\nas many as 32 cameras, in arbitrary geometric configurations, thus supporting a\nwide range of robotic setups. cuVSLAM is specifically optimized using CUDA to\ndeploy in real-time applications with minimal computational overhead on\nedge-computing devices such as the NVIDIA Jetson. We present the design and\nimplementation of cuVSLAM, example use cases, and empirical results on several\nstate-of-the-art benchmarks demonstrating the best-in-class performance of\ncuVSLAM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.04359v3", "cate": "cs.RO", "date": "2025-06-04", "updated": "2025-07-08"}
{"id": "2507.05503", "title": "MolFORM: Multi-modal Flow Matching for Structure-Based Drug Design", "authors": ["Jie Huang", "Daiheng Zhang"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      Accepted to ICML 2025 genbio workshop", "url": "http://arxiv.org/abs/2507.05503v1", "summary": "Structure-based drug design (SBDD) seeks to generate molecules that bind\neffectively to protein targets by leveraging their 3D structural information.\nWhile diffusion-based generative models have become the predominant approach\nfor SBDD, alternative non-autoregressive frameworks remain relatively\nunderexplored. In this work, we introduce MolFORM, a novel generative framework\nthat jointly models discrete (atom types) and continuous (3D coordinates)\nmolecular modalities using multi-flow matching. To further enhance generation\nquality, we incorporate a preference-guided fine-tuning stage based on\n\\textit{Direct Preference Optimization} (DPO), using Vina score as a reward\nsignal. We propose a multi-modal flow DPO co-modeling strategy that\nsimultaneously aligns discrete and continuous modalities, leading to consistent\nimprovements across multiple evaluation metrics.", "comment": "Accepted to ICML 2025 genbio workshop", "pdf_url": "http://arxiv.org/pdf/2507.05503v1", "cate": "cs.CE", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2505.20636", "title": "Frequency-Selective Modeling and Analysis for OFDM-Integrated Wideband Pinching-Antenna Systems", "authors": ["Jian Xiao", "Ji Wang", "Ming Zeng", "Yuanwei Liu", "George K. Karagiannidis"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.20636v2", "summary": "This letter investigates the integration of pinching-antenna systems (PASS)\nwith orthogonal frequency division multiplexing (OFDM) to ensure their\ncompatibility and to explore the frequency-selective behavior inherent to PASS.\nFirst, an end-to-end channel model for OFDM PASS is proposed based on\nelectromagnetic-compliant modeling of waveguides and coupled-mode theory, which\nincludes frequency-dependent waveguide attenuation, dispersion and antenna\ncoupling effect. Furthermore, a critical dependence of the OFDM cyclic prefix\n(CP) overhead on the proximity of the operating frequency to the waveguide\ncutoff is revealed. Moreover, the phase misalignment effect across subcarriers\nin OFDM PASS is derived for an approximate pinching antenna location strategy\nbased on path loss minimization, which reveals the phase misalignment is\nexacerbated for wider bandwidths and larger array size. Numerical results show\nthat: 1) frequency-selective effects in OFDM PASS lead to substantial\nvariations in subcarrier achievable rates, highlighting the necessity of\noperating above the waveguide cutoff frequency for effective communications; 2)\nwaveguide dispersion mandates considerable CP overhead when operating near the\ncutoff frequency, severely impacting the spectral efficiency of OFDM PASS; and\n3) the gentle linear waveguide attenuation in a practical PASS significantly\nmore advantageous than the severe logarithmic path loss characteristic of\nfixed-location antennas.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.20636v2", "cate": "cs.IT", "date": "2025-05-27", "updated": "2025-07-08"}
{"id": "2502.15006", "title": "Safe Beyond the Horizon: Efficient Sampling-based MPC with Neural Control Barrier Functions", "authors": ["Ji Yin", "Oswin So", "Eric Yang Yu", "Chuchu Fan", "Panagiotis Tsiotras"], "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted by RSS 2025", "url": "http://arxiv.org/abs/2502.15006v2", "summary": "A common problem when using model predictive control (MPC) in practice is the\nsatisfaction of safety specifications beyond the prediction horizon. While\ntheoretical works have shown that safety can be guaranteed by enforcing a\nsuitable terminal set constraint or a sufficiently long prediction horizon,\nthese techniques are difficult to apply and thus are rarely used by\npractitioners, especially in the case of general nonlinear dynamics. To solve\nthis problem, we impose a tradeoff between exact recursive feasibility,\ncomputational tractability, and applicability to ``black-box'' dynamics by\nlearning an approximate discrete-time control barrier function and\nincorporating it into a variational inference MPC (VIMPC), a sampling-based MPC\nparadigm. To handle the resulting state constraints, we further propose a new\nsampling strategy that greatly reduces the variance of the estimated optimal\ncontrol, improving the sample efficiency, and enabling real-time planning on a\nCPU. The resulting Neural Shield-VIMPC (NS-VIMPC) controller yields substantial\nsafety improvements compared to existing sampling-based MPC controllers, even\nunder badly designed cost functions. We validate our approach in both\nsimulation and real-world hardware experiments. Project website:\nhttps://mit-realm.github.io/ns-vimpc/.", "comment": "Accepted by RSS 2025", "pdf_url": "http://arxiv.org/pdf/2502.15006v2", "cate": "cs.RO", "date": "2025-02-20", "updated": "2025-07-08"}
{"id": "2507.06221", "title": "Aligned Textual Scoring Rules", "authors": ["Yuxuan Lu", "Yifan Wu", "Jason Hartline", "Michael J. Curry"], "categories": ["cs.AI", "cs.GT"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06221v1", "summary": "Scoring rules elicit probabilistic predictions from a strategic agent by\nscoring the prediction against a ground truth state. A scoring rule is proper\nif, from the agent's perspective, reporting the true belief maximizes the\nexpected score. With the development of language models, Wu and Hartline (2024)\nproposes a reduction from textual information elicitation to the numerical\n(i.e. probabilistic) information elicitation problem, which achieves provable\nproperness for textual elicitation. However, not all proper scoring rules are\nwell aligned with human preference over text. Our paper designs the Aligned\nScoring rule (ASR) for text by optimizing and minimizing the mean squared error\nbetween a proper scoring rule and a reference score (e.g. human score). Our\nexperiments show that our ASR outperforms previous methods in aligning with\nhuman preference while maintaining properness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06221v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05636", "title": "Graph Learning", "authors": ["Feng Xia", "Ciyuan Peng", "Jing Ren", "Falih Gozi Febrinanto", "Renqiang Luo", "Vidya Saikrishna", "Shuo Yu", "Xiangjie Kong"], "categories": ["cs.LG", "cs.AI", "68T09, 68R10", "I.2.6; G.2.2; E.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      178 pages", "url": "http://arxiv.org/abs/2507.05636v1", "summary": "Graph learning has rapidly evolved into a critical subfield of machine\nlearning and artificial intelligence (AI). Its development began with early\ngraph-theoretic methods, gaining significant momentum with the advent of graph\nneural networks (GNNs). Over the past decade, progress in scalable\narchitectures, dynamic graph modeling, multimodal learning, generative AI,\nexplainable AI (XAI), and responsible AI has broadened the applicability of\ngraph learning to various challenging environments. Graph learning is\nsignificant due to its ability to model complex, non-Euclidean relationships\nthat traditional machine learning struggles to capture, thus better supporting\nreal-world applications ranging from drug discovery and fraud detection to\nrecommender systems and scientific reasoning. However, challenges like\nscalability, generalization, heterogeneity, interpretability, and\ntrustworthiness must be addressed to unlock its full potential. This survey\nprovides a comprehensive introduction to graph learning, focusing on key\ndimensions including scalable, temporal, multimodal, generative, explainable,\nand responsible graph learning. We review state-of-the-art techniques for\nefficiently handling large-scale graphs, capturing dynamic temporal\ndependencies, integrating heterogeneous data modalities, generating novel graph\nsamples, and enhancing interpretability to foster trust and transparency. We\nalso explore ethical considerations, such as privacy and fairness, to ensure\nresponsible deployment of graph learning models. Additionally, we identify and\ndiscuss emerging topics, highlighting recent integration of graph learning and\nother AI paradigms and offering insights into future directions. This survey\nserves as a valuable resource for researchers and practitioners seeking to\nnavigate the rapidly evolving landscape of graph learning.", "comment": "178 pages", "pdf_url": "http://arxiv.org/pdf/2507.05636v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05673", "title": "R-VLM: Region-Aware Vision Language Model for Precise GUI Grounding", "authors": ["Joonhyung Park", "Peng Tang", "Sagnik Das", "Srikar Appalaraju", "Kunwar Yashraj Singh", "R. Manmatha", "Shabnam Ghadar"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ACL 2025; 17 pages", "url": "http://arxiv.org/abs/2507.05673v1", "summary": "Visual agent models for automating human activities on Graphical User\nInterfaces (GUIs) have emerged as a promising research direction, driven by\nadvances in large Vision Language Models (VLMs). A critical challenge in GUI\nautomation is the precise grounding of interface elements across diverse\nplatforms. Existing vision-only GUI agents directly ground elements from large\nand cluttered screenshots, requiring them to process substantial irrelevant\ninformation that compromises their accuracy. In addition, these approaches\ntypically employ basic cross-entropy loss for learning grounding objectives,\nwhich fails to effectively capture grounding quality compared to established\nobject detection metrics like Intersection-over-Union (IoU). To address these\nissues, we introduce R-VLM, a novel GUI grounding approach that leverages\nzoomed-in region proposals for precise element localization. We also propose an\nIoU-aware objective function that facilitates model convergence toward high IoU\npredictions. Our approach bridges the gap between VLMs and conventional object\ndetection techniques, improving the state-of-the-art grounding accuracy by 13%\nacross diverse GUI platforms on the GUI grounding benchmarks ScreenSpot and\nAgentStudio. In addition, our R-VLM approach shows 3.2-9.7% absolute accuracy\nimprovements in GUI navigation tasks on the AITW and Mind2Web benchmarks.", "comment": "ACL 2025; 17 pages", "pdf_url": "http://arxiv.org/pdf/2507.05673v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05659", "title": "MCNP-GO: A python package for assembling MCNP input files with a systems engineering approach", "authors": ["Alexandre Friou"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      Submitted to Nuclear Engineering and Technology", "url": "http://arxiv.org/abs/2507.05659v1", "summary": "This article introduces MCNP-GO (https://github.com/afriou/mcnpgo), a Python\npackage designed to manipulate and assemble MCNP input files, allowing users to\nassemble a set of independent objects, each described by a valid MCNP file,\ninto a single cohesive file. This tool is particularly useful for applications\nwhere precise modeling and positioning of equipment are crucial. The package\naddresses the challenges of managing large databases of MCNP input files,\nensuring reliability and traceability through configuration management systems.\nMCNP-GO provides functionalities such as renumbering, extracting subsets of\nfiles, transforming files, and assembling files while managing collisions and\nmaterials. It also keeps track of the operations performed on files, enhancing\ntraceability and ease of modification. The article demonstrates the package's\ncapabilities through a practical example of assembling an MCNP input file for a\ntomographic experiment, highlighting its efficiency and user-friendliness.\nMCNP-GO is designed for users with minimal Python knowledge.", "comment": "Submitted to Nuclear Engineering and Technology", "pdf_url": "http://arxiv.org/pdf/2507.05659v1", "cate": "cs.CE", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.03449", "title": "Movable-Antenna-Enhanced Physical-Layer Service Integration: Performance Analysis and Optimization", "authors": ["Xuanlin Shen", "Xin Wei", "Weidong Mei", "Zhi Chen", "Jun Fang", "Boyu Ning"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE Wireless Communications Letters", "url": "http://arxiv.org/abs/2507.03449v2", "summary": "Movable antennas (MAs) have drawn increasing attention in wireless\ncommunications due to their capability to create favorable channel conditions\nvia local movement within a confined region. In this letter, we investigate its\napplication in physical-layer service integration (PHY-SI), where a multi-MA\nbase station (BS) simultaneously transmits both confidential and multicast\nmessages to two users. The multicast message is intended for both users, while\nthe confidential message is intended only for one user and must remain\nperfectly secure from the other. Our goal is to jointly optimize the secrecy\nand multicast beamforming, as well as the MAs' positions at the BS to maximize\nthe secrecy rate for one user while satisfying the multicast rate requirement\nfor both users. To gain insights, we first conduct performance analysis of this\nMA-enhanced PHY-SI system in two special cases, revealing its unique\ncharacteristics compared to conventional PHY-SI with fixed-position antennas\n(FPAs). To address the secrecy rate maximization problem, we propose a\ntwo-layer optimization framework that integrates the semidefinite relaxation\n(SDR) technique and a discrete sampling algorithm. Numerical results\ndemonstrate that MAs can greatly enhance the achievable secrecy rate region for\nPHY-SI compared to FPAs.", "comment": "Accepted to IEEE Wireless Communications Letters", "pdf_url": "http://arxiv.org/pdf/2507.03449v2", "cate": "cs.IT", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2504.03260", "title": "Gradient Field-Based Dynamic Window Approach for Collision Avoidance in Complex Environments", "authors": ["Ze Zhang", "Yifan Xue", "Nadia Figueroa", "Knut Åkesson"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025", "url": "http://arxiv.org/abs/2504.03260v2", "summary": "For safe and flexible navigation in multi-robot systems, this paper presents\nan enhanced and predictive sampling-based trajectory planning approach in\ncomplex environments, the Gradient Field-based Dynamic Window Approach\n(GF-DWA). Building upon the dynamic window approach, the proposed method\nutilizes gradient information of obstacle distances as a new cost term to\nanticipate potential collisions. This enhancement enables the robot to improve\nawareness of obstacles, including those with non-convex shapes. The gradient\nfield is derived from the Gaussian process distance field, which generates both\nthe distance field and gradient field by leveraging Gaussian process regression\nto model the spatial structure of the environment. Through several obstacle\navoidance and fleet collision avoidance scenarios, the proposed GF-DWA is shown\nto outperform other popular trajectory planning and control methods in terms of\nsafety and flexibility, especially in complex environments with non-convex\nobstacles.", "comment": "This paper has been accepted by IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS) 2025", "pdf_url": "http://arxiv.org/pdf/2504.03260v2", "cate": "cs.RO", "date": "2025-04-04", "updated": "2025-07-08"}
{"id": "2501.06861", "title": "Integrators at War: Mediating in AI-assisted Resort-to-Force Decisions", "authors": ["Dennis Müller", "Maurice Chiodo", "Mitja Sienknecht"], "categories": ["cs.CY", "cs.AI", "math.HO", "K.4"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      32 pages. Keywords: education, artificial intelligence, AI integrators, resort to force, sociotechnical system, systems engineering", "url": "http://arxiv.org/abs/2501.06861v1", "summary": "The integration of AI systems into the military domain is changing the way\nwar-related decisions are made. It binds together three disparate groups of\nactors - developers, integrators, users - and creates a relationship between\nthese groups and the machine, embedded in the (pre-)existing organisational and\nsystem structures. In this article, we focus on the important, but often\nneglected, group of integrators within such a sociotechnical system. In complex\nhuman-machine configurations, integrators carry responsibility for linking the\ndisparate groups of developers and users in the political and military system.\nTo act as the mediating group requires a deep understanding of the other\ngroups' activities, perspectives and norms. We thus ask which challenges and\nshortcomings emerge from integrating AI systems into resort-to-force (RTF)\ndecision-making processes, and how to address them. To answer this, we proceed\nin three steps. First, we conceptualise the relationship between different\ngroups of actors and AI systems as a sociotechnical system. Second, we identify\nchallenges within such systems for human-machine teaming in RTF decisions. We\nfocus on challenges that arise a) from the technology itself, b) from the\nintegrators' role in the sociotechnical system, c) from the human-machine\ninteraction. Third, we provide policy recommendations to address these\nshortcomings when integrating AI systems into RTF decision-making structures.", "comment": "32 pages. Keywords: education, artificial intelligence, AI\n  integrators, resort to force, sociotechnical system, systems engineering", "pdf_url": "http://arxiv.org/pdf/2501.06861v1", "cate": "cs.CY", "date": "2025-01-12", "updated": "2025-01-12"}
{"id": "2507.05644", "title": "FACT: the Features At Convergence Theorem for neural networks", "authors": ["Enric Boix-Adsera", "Neil Mallinar", "James B. Simon", "Mikhail Belkin"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05644v1", "summary": "A central challenge in deep learning theory is to understand how neural\nnetworks learn and represent features. To this end, we prove the Features at\nConvergence Theorem (FACT), which gives a self-consistency equation that neural\nnetwork weights satisfy at convergence when trained with nonzero weight decay.\nFor each weight matrix $W$, this equation relates the \"feature matrix\" $W^\\top\nW$ to the set of input vectors passed into the matrix during forward\npropagation and the loss gradients passed through it during backpropagation. We\nvalidate this relation empirically, showing that neural features indeed satisfy\nthe FACT at convergence. Furthermore, by modifying the \"Recursive Feature\nMachines\" of Radhakrishnan et al. 2024 so that they obey the FACT, we arrive at\na new learning algorithm, FACT-RFM. FACT-RFM achieves high performance on\ntabular data and captures various feature learning behaviors that occur in\nneural network training, including grokking in modular arithmetic and phase\ntransitions in learning sparse parities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05644v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05675", "title": "MedGen: Unlocking Medical Video Generation by Scaling Granularly-annotated Medical Videos", "authors": ["Rongsheng Wang", "Junying Chen", "Ke Ji", "Zhenyang Cai", "Shunian Chen", "Yunjin Yang", "Benyou Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05675v1", "summary": "Recent advances in video generation have shown remarkable progress in\nopen-domain settings, yet medical video generation remains largely\nunderexplored. Medical videos are critical for applications such as clinical\ntraining, education, and simulation, requiring not only high visual fidelity\nbut also strict medical accuracy. However, current models often produce\nunrealistic or erroneous content when applied to medical prompts, largely due\nto the lack of large-scale, high-quality datasets tailored to the medical\ndomain. To address this gap, we introduce MedVideoCap-55K, the first\nlarge-scale, diverse, and caption-rich dataset for medical video generation. It\ncomprises over 55,000 curated clips spanning real-world medical scenarios,\nproviding a strong foundation for training generalist medical video generation\nmodels. Built upon this dataset, we develop MedGen, which achieves leading\nperformance among open-source models and rivals commercial systems across\nmultiple benchmarks in both visual quality and medical accuracy. We hope our\ndataset and model can serve as a valuable resource and help catalyze further\nresearch in medical video generation. Our code and data is available at\nhttps://github.com/FreedomIntelligence/MedGen", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05675v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06133", "title": "Bridging Sequential Deep Operator Network and Video Diffusion: Residual Refinement of Spatio-Temporal PDE Solutions", "authors": ["Jaewan Park", "Farid Ahmed", "Kazuma Kobayashi", "Seid Koric", "Syed Bahauddin Alam", "Iwona Jasiuk", "Diab Abueidda"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06133v1", "summary": "Video-diffusion models have recently set the standard in video generation,\ninpainting, and domain translation thanks to their training stability and high\nperceptual fidelity. Building on these strengths, we repurpose conditional\nvideo diffusion as a physics surrogate for spatio-temporal fields governed by\npartial differential equations (PDEs). Our two-stage surrogate first applies a\nSequential Deep Operator Network (S-DeepONet) to produce a coarse,\nphysics-consistent prior from the prescribed boundary or loading conditions.\nThe prior is then passed to a conditional video diffusion model that learns\nonly the residual: the point-wise difference between the ground truth and the\nS-DeepONet prediction. By shifting the learning burden from the full solution\nto its much smaller residual space, diffusion can focus on sharpening\nhigh-frequency structures without sacrificing global coherence. The framework\nis assessed on two disparate benchmarks: (i) vortex-dominated lid-driven cavity\nflow and (ii) tensile plastic deformation of dogbone specimens. Across these\ndata sets the hybrid surrogate consistently outperforms its single-stage\ncounterpart, cutting the mean relative L2 error from 4.57% to 0.83% for the\nflow problem and from 4.42% to 2.94% for plasticity, a relative improvements of\n81.8% and 33.5% respectively. The hybrid approach not only lowers quantitative\nerrors but also improves visual quality, visibly recovering fine spatial\ndetails. These results show that (i) conditioning diffusion on a physics-aware\nprior enables faithful reconstruction of localized features, (ii) residual\nlearning reduces the problem, accelerating convergence and enhancing accuracy,\nand (iii) the same architecture transfers seamlessly from incompressible flow\nto nonlinear elasto-plasticity without problem-specific architectural\nmodifications, highlighting its broad applicability to nonlinear,\ntime-dependent continua.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06133v1", "cate": "cs.CE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2502.04557", "title": "Speeding up Speculative Decoding via Sequential Approximate Verification", "authors": ["Meiyu Zhong", "Noel Teku", "Ravi Tandon"], "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025, Workshop on Efficient Systems for Foundation Models", "url": "http://arxiv.org/abs/2502.04557v3", "summary": "Speculative Decoding (SD) is a recently proposed technique for faster\ninference using Large Language Models (LLMs). SD operates by using a smaller\ndraft LLM for autoregressively generating a sequence of tokens and a larger\ntarget LLM for parallel verification to ensure statistical consistency.\nHowever, periodic parallel calls to the target LLM for verification prevent SD\nfrom achieving even lower latencies. We propose SPRINTER, which utilizes a\nlow-complexity verifier trained to predict if tokens generated from a draft LLM\nwould be accepted by the target LLM. By performing sequential approximate\nverification, SPRINTER does not require verification by the target LLM and is\nonly invoked when a token is deemed unacceptable. This reduces the number of\ncalls to the larger LLM, achieving further speedups and lower computation cost.\nWe present a theoretical analysis of SPRINTER, examining the statistical\nproperties of the generated tokens, as well as the expected reduction in\nlatency as a function of the verifier. We evaluate SPRINTER on several datasets\nand model pairs, demonstrating that approximate verification can still maintain\nhigh quality generation while further reducing latency.", "comment": "ICML 2025, Workshop on Efficient Systems for Foundation Models", "pdf_url": "http://arxiv.org/pdf/2502.04557v3", "cate": "cs.LG", "date": "2025-02-06", "updated": "2025-07-08"}
{"id": "2505.03729", "title": "Visual Imitation Enables Contextual Humanoid Control", "authors": ["Arthur Allshire", "Hongsuk Choi", "Junyi Zhang", "David McAllister", "Anthony Zhang", "Chung Min Kim", "Trevor Darrell", "Pieter Abbeel", "Jitendra Malik", "Angjoo Kanazawa"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Project website: this https URL", "url": "http://arxiv.org/abs/2505.03729v4", "summary": "How can we teach humanoids to climb staircases and sit on chairs using the\nsurrounding environment context? Arguably, the simplest way is to just show\nthem-casually capture a human motion video and feed it to humanoids. We\nintroduce VIDEOMIMIC, a real-to-sim-to-real pipeline that mines everyday\nvideos, jointly reconstructs the humans and the environment, and produces\nwhole-body control policies for humanoid robots that perform the corresponding\nskills. We demonstrate the results of our pipeline on real humanoid robots,\nshowing robust, repeatable contextual control such as staircase ascents and\ndescents, sitting and standing from chairs and benches, as well as other\ndynamic whole-body skills-all from a single policy, conditioned on the\nenvironment and global root commands. VIDEOMIMIC offers a scalable path towards\nteaching humanoids to operate in diverse real-world environments.", "comment": "Project website: https://www.videomimic.net/", "pdf_url": "http://arxiv.org/pdf/2505.03729v4", "cate": "cs.RO", "date": "2025-05-06", "updated": "2025-07-08"}
{"id": "2507.05671", "title": "Canine Clinical Gait Analysis for Orthopedic and Neurological Disorders: An Inertial Deep-Learning Approach", "authors": ["Netta Palez", "Léonie Straß", "Sebastian Meller", "Holger Volk", "Anna Zamansky", "Itzik Klein"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      20 pages, 11 figures (one combine 2 images), 7 tables, 41 references", "url": "http://arxiv.org/abs/2507.05671v1", "summary": "Canine gait analysis using wearable inertial sensors is gaining attention in\nveterinary clinical settings, as it provides valuable insights into a range of\nmobility impairments. Neurological and orthopedic conditions cannot always be\neasily distinguished even by experienced clinicians. The current study explored\nand developed a deep learning approach using inertial sensor readings to assess\nwhether neurological and orthopedic gait could facilitate gait analysis. Our\ninvestigation focused on optimizing both performance and generalizability in\ndistinguishing between these gait abnormalities. Variations in sensor\nconfigurations, assessment protocols, and enhancements to deep learning model\narchitectures were further suggested. Using a dataset of 29 dogs, our proposed\napproach achieved 96% accuracy in the multiclass classification task\n(healthy/orthopedic/neurological) and 82% accuracy in the binary classification\ntask (healthy/non-healthy) when generalizing to unseen dogs. Our results\ndemonstrate the potential of inertial-based deep learning models to serve as a\npractical and objective diagnostic and clinical aid to differentiate gait\nassessment in orthopedic and neurological conditions.", "comment": "20 pages, 11 figures (one combine 2 images), 7 tables, 41 references", "pdf_url": "http://arxiv.org/pdf/2507.05671v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05677", "title": "Integrated Structural Prompt Learning for Vision-Language Models", "authors": ["Jiahui Wang", "Qin Xu", "Bo Jiang", "Bin Luo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05677v1", "summary": "Prompt learning methods have significantly extended the transferability of\npre-trained Vision-Language Models (VLMs) like CLIP for various downstream\ntasks. These methods adopt handcraft templates or learnable vectors to provide\ntext or image instructions in fine-tuning VLMs. However, most existing works\nignore the structural relationships between learnable prompts and tokens within\nand between modalities. Moreover, balancing the performance of base and new\nclasses remains a significant challenge. In this paper, we propose an\nIntegrated Structural Prompt (ISP) for VLMs to enhance the interaction of\ninformation representations between the text and image branches. ISP introduces\nself-structural and cross-structural prompt modules to model the structural\nrelationships between learnable prompts and frozen tokens within and across\nmodalities. This enables efficient information transfer while preserving\nfeature stability. Additionally, we propose a sample probing module that\ndynamically adjusts loss coefficients based on sample difficulty, preventing\nthe mode from overfitting to simple samples and improving generalization\nability to new classes. Extensive experiments on three widely used settings:\nbase-to-new generalization, cross-dataset evaluation, and domain generalization\ndemonstrate that the proposed ISP achieves competitive performance against\nstate-of-the-art methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05677v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2103.08012", "title": "A new engineering theory describing oblique free surface impact by flexible plates", "authors": ["Wensi Wu", "Christopher Earls"], "categories": ["physics.flu-dyn", "cs.CE", "cs.NA", "math.NA"], "primary_category": "Subjects:       Fluid Dynamics (physics.flu-dyn)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2103.08012v3", "summary": "Consideration of slamming loads within the structural design of planning\nhulls is of critical importance in ensuring adequate structural performance in\norder to avoid potential catastrophic consequences. However, because of the\nintricacy in the interplay between complex fluid flows and nonlinear structural\ndeformations that accompany the phenomenology of slamming, a general\nengineering theory in slamming has yet to be uncovered, and so design relies on\nspecialized theories. In this paper, we propose one such theory for a design\ncase that has, until now, eluded a proper description. In pursuit of this\ntheory, we employ a specialized implicit, partitioned fluid-structural\ninteraction (FSI) simulation approach, in order to study the underlying\nphysical mechanisms accompanying the oblique impact of a flexible plate during\nwater entry. In the present work, we first present validation results from\nflexible plate water entry experiments, to confirm the veracity of the\ndeveloped FSI solver. Subsequent to validation, we carry out a series of\nnumerical analyses, in an effort to characterize the regimes in impact force\nand plate out-of-plane deformations, as a function of impact velocities and\nplate flexural rigidity. Finally, we use our FSI solver, as a kind of\n\"microscope\", to study the mechanistic evolution of fluid flows and elastic\nplate deformations that occur during slamming. Based on these observations, we\npropose a novel, but simple engineering theory for flexible plates obliquely\nimpacting the water free surface (e.g. high speed porpoising water craft\nreentry).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2103.08012v3", "cate": "physics.flu-dyn", "date": "2021-03-14", "updated": "2021-11-02"}
{"id": "2505.10251", "title": "SRT-H: A Hierarchical Framework for Autonomous Surgery via Language Conditioned Imitation Learning", "authors": ["Ji Woong Kim", "Juo-Tung Chen", "Pascal Hansen", "Lucy X. Shi", "Antony Goldenberg", "Samuel Schmidgall", "Paul Maria Scheikl", "Anton Deguet", "Brandon M. White", "De Ru Tsai", "Richard Cha", "Jeffrey Jopling", "Chelsea Finn", "Axel Krieger"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.10251v3", "summary": "Research on autonomous surgery has largely focused on simple task automation\nin controlled environments. However, real-world surgical applications demand\ndexterous manipulation over extended durations and generalization to the\ninherent variability of human tissue. These challenges remain difficult to\naddress using existing logic-based or conventional end-to-end learning\napproaches. To address this gap, we propose a hierarchical framework for\nperforming dexterous, long-horizon surgical steps. Our approach utilizes a\nhigh-level policy for task planning and a low-level policy for generating robot\ntrajectories. The high-level planner plans in language space, generating\ntask-level or corrective instructions that guide the robot through the\nlong-horizon steps and correct for the low-level policy's errors. We validate\nour framework through ex vivo experiments on cholecystectomy, a\ncommonly-practiced minimally invasive procedure, and conduct ablation studies\nto evaluate key components of the system. Our method achieves a 100\\% success\nrate across eight unseen ex vivo gallbladders, operating fully autonomously\nwithout human intervention. This work demonstrates step-level autonomy in a\nsurgical procedure, marking a milestone toward clinical deployment of\nautonomous surgical systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.10251v3", "cate": "cs.RO", "date": "2025-05-15", "updated": "2025-07-08"}
{"id": "2505.20181", "title": "The Problem of Algorithmic Collisions: Mitigating Unforeseen Risks in a Connected World", "authors": ["Maurice Chiodo", "Dennis Müller"], "categories": ["cs.CY", "cs.AI", "math.HO", "I.2.11; K.4.1; K.4.2; K.5.2"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      27 pages. This is an early concept paper, and we plan to add further content to it over time. Please get in touch if you want to be part of its further development. Keywords: algorithmic collision, AI agents, algorithmic ecosystem, flash crash, multiagent systems", "url": "http://arxiv.org/abs/2505.20181v1", "summary": "The increasing deployment of Artificial Intelligence (AI) and other\nautonomous algorithmic systems presents the world with new systemic risks.\nWhile focus often lies on the function of individual algorithms, a critical and\nunderestimated danger arises from their interactions, particularly when\nalgorithmic systems operate without awareness of each other, or when those\ndeploying them are unaware of the full algorithmic ecosystem deployment is\noccurring in. These interactions can lead to unforeseen, rapidly escalating\nnegative outcomes - from market crashes and energy supply disruptions to\npotential physical accidents and erosion of public trust - often exceeding the\nhuman capacity for effective monitoring and the legal capacities for proper\nintervention. Current governance frameworks are inadequate as they lack\nvisibility into this complex ecosystem of interactions. This paper outlines the\nnature of this challenge and proposes some initial policy suggestions centered\non increasing transparency and accountability through phased system\nregistration, a licensing framework for deployment, and enhanced monitoring\ncapabilities.", "comment": "27 pages. This is an early concept paper, and we plan to add further\n  content to it over time. Please get in touch if you want to be part of its\n  further development. Keywords: algorithmic collision, AI agents, algorithmic\n  ecosystem, flash crash, multiagent systems", "pdf_url": "http://arxiv.org/pdf/2505.20181v1", "cate": "cs.CY", "date": "2025-05-26", "updated": "2025-05-26"}
{"id": "2507.05685", "title": "Efficient Training of Large-Scale AI Models Through Federated Mixture-of-Experts: A System-Level Approach", "authors": ["Xiaobing Chen", "Boyang Zhang", "Xiangwei Zhou", "Mingxuan Sun", "Shuai Zhang", "Songyang Zhang", "Geoffrey Ye Li"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2507.05685v1", "summary": "The integration of Federated Learning (FL) and Mixture-of-Experts (MoE)\npresents a compelling pathway for training more powerful, large-scale\nartificial intelligence models (LAMs) on decentralized data while preserving\nprivacy. However, efficient federated training of these complex MoE-structured\nLAMs is hindered by significant system-level challenges, particularly in\nmanaging the interplay between heterogeneous client resources and the\nsophisticated coordination required for numerous specialized experts. This\narticle highlights a critical, yet underexplored concept: the absence of robust\nquantitative strategies for dynamic client-expert alignment that holistically\nconsiders varying client capacities and the imperative for system-wise load\nbalancing. Specifically, we propose a conceptual system design for intelligent\nclient-expert alignment that incorporates dynamic fitness scoring, global\nexpert load monitoring, and client capacity profiling. By tackling these\nsystemic issues, we can unlock more scalable, efficient, and robust training\nmechanisms {with fewer communication rounds for convergence}, paving the way\nfor the widespread deployment of large-scale federated MoE-structured LAMs in\nedge computing with ultra-high communication efficiency.", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2507.05685v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05678", "title": "LiON-LoRA: Rethinking LoRA Fusion to Unify Controllable Spatial and Temporal Generation for Video Diffusion", "authors": ["Yisu Zhang", "Chenjie Cao", "Chaohui Yu", "Jianke Zhu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05678v1", "summary": "Video Diffusion Models (VDMs) have demonstrated remarkable capabilities in\nsynthesizing realistic videos by learning from large-scale data. Although\nvanilla Low-Rank Adaptation (LoRA) can learn specific spatial or temporal\nmovement to driven VDMs with constrained data, achieving precise control over\nboth camera trajectories and object motion remains challenging due to the\nunstable fusion and non-linear scalability. To address these issues, we propose\nLiON-LoRA, a novel framework that rethinks LoRA fusion through three core\nprinciples: Linear scalability, Orthogonality, and Norm consistency. First, we\nanalyze the orthogonality of LoRA features in shallow VDM layers, enabling\ndecoupled low-level controllability. Second, norm consistency is enforced\nacross layers to stabilize fusion during complex camera motion combinations.\nThird, a controllable token is integrated into the diffusion transformer (DiT)\nto linearly adjust motion amplitudes for both cameras and objects with a\nmodified self-attention mechanism to ensure decoupled control. Additionally, we\nextend LiON-LoRA to temporal generation by leveraging static-camera videos,\nunifying spatial and temporal controllability. Experiments demonstrate that\nLiON-LoRA outperforms state-of-the-art methods in trajectory control accuracy\nand motion strength adjustment, achieving superior generalization with minimal\ntraining data. Project Page: https://fuchengsu.github.io/lionlora.github.io/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05678v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2402.10741", "title": "Identifying heterogeneous micromechanical properties of biological tissues via physics-informed neural networks", "authors": ["Wensi Wu", "Mitchell Daneker", "Kevin T. Turner", "Matthew A. Jolley", "Lu Lu"], "categories": ["math.NA", "cs.CE", "cs.NA", "physics.bio-ph"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.10741v3", "summary": "The heterogeneous micromechanical properties of biological tissues have\nprofound implications across diverse medical and engineering domains. However,\nidentifying full-field heterogeneous elastic properties of soft materials using\ntraditional engineering approaches is fundamentally challenging due to\ndifficulties in estimating local stress fields. Recently, there has been a\ngrowing interest in using data-driven models to learn full-field mechanical\nresponses such as displacement and strain from experimental or synthetic data.\nHowever, research studies on inferring full-field elastic properties of\nmaterials, a more challenging problem, are scarce, particularly for large\ndeformation, hyperelastic materials. Here, we propose a physics-informed\nmachine learning approach to identify the elasticity map in nonlinear, large\ndeformation hyperelastic materials. We evaluate the prediction accuracies and\ncomputational efficiency of physics-informed neural networks (PINNs) by\ninferring the heterogeneous elasticity maps across three materials with\nstructural complexity that closely resemble real tissue patterns, such as brain\ntissue and tricuspid valve tissue. We further applied our improved architecture\nto three additional examples of breast cancer tissue and extended our analysis\nto three hyperelastic constitutive models: Neo-Hookean, Mooney Rivlin, and\nGent. Our selected network architecture consistently produced highly accurate\nestimations of heterogeneous elasticity maps, even when there was up to 10%\nnoise present in the training data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.10741v3", "cate": "math.NA", "date": "2024-02-16", "updated": "2024-07-18"}
{"id": "2507.06158", "title": "Addition Automata and Attractors of Digit Systems Corresponding to Expanding Rational Matrices", "authors": ["Anjelo Gabriel R. Cruz", "Manuel Joseph C. Loquias", "Jörg M. Thuswaldner"], "categories": ["math.NT", "cs.FL", "11A63, 68Q45"], "primary_category": "Subjects:       Number Theory (math.NT)", "pdf_link": null, "comments": "Comments:      20 pages, 11 figures", "url": "http://arxiv.org/abs/2507.06158v1", "summary": "Let $A$ be an expanding $2 \\times 2$ matrix with rational entries and\n$\\mathbb{Z}^2[A]$ be the smallest $A$-invariant $\\mathbb{Z}$-module containing\n$\\mathbb{Z}^2$. Let $\\mathcal{D}$ be a finite subset of $\\mathbb{Z}^2[A]$ which\nis a complete residue system of $\\mathbb{Z}^2[A]/A\\mathbb{Z}^2[A]$. The pair\n$(A,\\mathcal{D})$ is called a {\\em digit system} with {\\em base} $A$ and {\\em\ndigit set} $\\mathcal{D}$. It is well known that every vector $x \\in\n\\mathbb{Z}^2[A]$ can be written uniquely in the form \\[ x = d_0 + Ad_1 + \\cdots\n+ A^kd_k + A^{k+1}p, \\] with $k\\in \\mathbb{N}$ minimal, $d_0,\\dots,d_k \\in\n\\mathcal{D}$, and $p$ taken from a finite set of {\\em periodic elements}, the\nso-called {\\em attractor} of $(A,\\mathcal{D})$. If $p$ can always be chosen to\nbe $0$ we say that $(A,\\mathcal{D})$ has the {\\em finiteness property}.\n  In the present paper we introduce finite-state transducer automata which\nrealize the addition of the vectors $\\pm(1,0)^\\top$ and $\\pm(0,1)^\\top$ to a\ngiven vector $x\\in \\mathbb{Z}^2[A]$ in a number system $(A,\\mathcal{D})$ with\ncollinear digit set. These automata are applied to characterize all pairs\n$(A,\\mathcal{D})$ that have the finiteness property and, more generally, to\ncharacterize the attractors of these digit systems.", "comment": "20 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.06158v1", "cate": "math.NT", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2505.21432", "title": "Hume: Introducing System-2 Thinking in Visual-Language-Action Model", "authors": ["Haoming Song", "Delin Qu", "Yuanqi Yao", "Qizhi Chen", "Qi Lv", "Yiwen Tang", "Modi Shi", "Guanghui Ren", "Maoqing Yao", "Bin Zhao", "Dong Wang", "Xuelong Li"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.21432v4", "summary": "Humans practice slow thinking before performing actual actions when handling\ncomplex tasks in the physical world. This thinking paradigm, recently, has\nachieved remarkable advancement in boosting Large Language Models (LLMs) to\nsolve complex tasks in digital domains. However, the potential of slow thinking\nremains largely unexplored for robotic foundation models interacting with the\nphysical world. In this work, we propose Hume: a dual-system\nVision-Language-Action (VLA) model with value-guided System-2 thinking and\ncascaded action denoising, exploring human-like thinking capabilities of\nVision-Language-Action models for dexterous robot control. System 2 of Hume\nimplements value-Guided thinking by extending a Vision-Language-Action Model\nbackbone with a novel value-query head to estimate the state-action value of\npredicted actions. The value-guided thinking is conducted by repeat sampling\nmultiple action candidates and selecting one according to state-action value.\nSystem 1 of Hume is a lightweight reactive visuomotor policy that takes System\n2 selected action and performs cascaded action denoising for dexterous robot\ncontrol. At deployment time, System 2 performs value-guided thinking at a low\nfrequency while System 1 asynchronously receives the System 2 selected action\ncandidate and predicts fluid actions in real time. We show that Hume\noutperforms the existing state-of-the-art Vision-Language-Action models across\nmultiple simulation benchmark and real-robot deployments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.21432v4", "cate": "cs.RO", "date": "2025-05-27", "updated": "2025-07-08"}
{"id": "2507.01436", "title": "Challenges & Opportunities with LLM-Assisted Visualization Retargeting", "authors": ["Luke S. Snyder", "Chenglong Wang", "Steven M. Drucker"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      5 pages, 3 figures, 1 table", "url": "http://arxiv.org/abs/2507.01436v2", "summary": "Despite the ubiquity of visualization examples published on the web,\nretargeting existing custom chart implementations to new datasets remains\ndifficult, time-intensive, and tedious. The adaptation process assumes author\nfamiliarity with both the implementation of the example as well as how the new\ndataset might need to be transformed to fit into the example code. With recent\nadvances in Large Language Models (LLMs), automatic adaptation of code can be\nachieved from high-level user prompts, reducing the barrier for visualization\nretargeting. To better understand how LLMs can assist retargeting and its\npotential limitations, we characterize and evaluate the performance of LLM\nassistance across multiple datasets and charts of varying complexity,\ncategorizing failures according to type and severity. In our evaluation, we\ncompare two approaches: (1) directly instructing the LLM model to fully\ngenerate and adapt code by treating code as text inputs and (2) a more\nconstrained program synthesis pipeline where the LLM guides the code\nconstruction process by providing structural information (e.g., visual\nencodings) based on properties of the example code and data. We find that both\napproaches struggle when new data has not been appropriately transformed, and\ndiscuss important design recommendations for future retargeting systems.", "comment": "5 pages, 3 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.01436v2", "cate": "cs.HC", "date": "2025-07-02", "updated": "2025-07-06"}
{"id": "2507.05687", "title": "AutoTriton: Automatic Triton Programming with Reinforcement Learning in LLMs", "authors": ["Shangzhan Li", "Zefan Wang", "Ye He", "Yuxuan Li", "Qi Shi", "Jianling Li", "Yonggang Hu", "Wanxiang Che", "Xu Han", "Zhiyuan Liu", "Maosong Sun"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05687v1", "summary": "Kernel development in deep learning requires optimizing computational units\nacross hardware while balancing memory management, parallelism, and\nhardware-specific optimizations through extensive empirical tuning. Although\ndomain-specific languages like Triton simplify GPU programming by abstracting\nlow-level details, developers must still manually tune critical parameters such\nas tile sizes and memory access patterns through iterative experimentation,\ncreating substantial barriers to optimal performance and wider adoption. In\nthis work, we introduce AutoTriton, the first model dedicated to Triton\nprogramming powered by reinforcement learning (RL). AutoTriton performs\nsupervised fine-tuning (SFT) to be equipped with essential Triton programming\nexpertise using a high-quality data gathering pipeline, and conducts RL with\nGroup Relative Policy Optimization (GRPO) algorithm, combining a rule-based\nreward and an execution-based reward to further improve Triton programming\nability, sequentially. Experiments across five evaluation channels of\nTritonBench and KernelBench illustrate that our 8B model AutoTriton achieves\nperformance comparable to mainstream large models, including Claude-4-Sonnet\nand DeepSeek-R1-0528. Further experimental analysis demonstrates the crucial\nrole of each module within AutoTriton, including the SFT stage, the RL stage,\nand the reward design strategy. These findings underscore the promise of RL for\nautomatically generating high-performance kernels, and since high-performance\nkernels are core components of AI systems, this breakthrough establishes an\nimportant foundation for building more efficient AI systems. The model and code\nwill be available at https://github.com/AI9Stars/AutoTriton.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05687v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2409.19081", "title": "ADEPT: A Noninvasive Method for Determining Elastic Parameters of Valve Tissue", "authors": ["Wensi Wu", "Mitchell Daneker", "Christian Herz", "Hannah Dewey", "Jeffrey A. Weiss", "Alison M. Pouch", "Lu Lu", "Matthew A. Jolley"], "categories": ["q-bio.QM", "cs.CE", "physics.comp-ph"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.19081v2", "summary": "Computer simulation of \"virtual interventions\" may inform optimal valve\nrepair for a given patient prior to intervention. However, the paucity of\nnoninvasive methods to determine in vivo mechanical parameters of valves limits\nthe accuracy of computer prediction and their clinical application. To address\nthis, we propose ADEPT: A noninvasive method for Determining Elastic Parameters\nof valve Tissue. In this work, we demonstrated its application to the tricuspid\nvalve of a child. We first tracked valve displacements from open to closed\nframes within a 3D echocardiogram time sequence using image registration.\nPhysics-informed neural networks were subsequently applied to estimate the\nnonlinear mechanical properties from first principles and reference\ndisplacements. The simulated model using these patient-specific parameters\nclosely aligned with the reference image segmentation, achieving a mean\nsymmetric distance of less than 1 mm. Our approach doubled the accuracy of the\nsimulated model compared to the generic parameters reported in the literature.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.19081v2", "cate": "q-bio.QM", "date": "2024-09-27", "updated": "2025-02-11"}
{"id": "2507.04766", "title": "ABench-Physics: Benchmarking Physical Reasoning in LLMs via High-Difficulty and Dynamic Physics Problems", "authors": ["Yiming Zhang", "Yingfan Ma", "Yanmei Gu", "Zhengkai Yang", "Yihong Zhuang", "Feng Wang", "Zenan Huang", "Yuanyuan Wang", "Chao Huang", "Bowen Song", "Cheng Lin", "Junbo Zhao"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04766v1", "summary": "Large Language Models (LLMs) have shown impressive performance in domains\nsuch as mathematics and programming, yet their capabilities in physics remain\nunderexplored and poorly understood. Physics poses unique challenges that\ndemand not only precise computation but also deep conceptual understanding and\nphysical modeling skills. Existing benchmarks often fall short due to limited\ndifficulty, multiple-choice formats, and static evaluation settings that fail\nto capture physical modeling ability. In this paper, we introduce\nABench-Physics, a novel benchmark designed to rigorously evaluate LLMs'\nphysical reasoning and generalization capabilities. ABench-Physics consists of\ntwo components: Phy_A, a static set of 400 graduate- or Olympiad-level\nproblems; and Phy_B, a dynamic subset of 100 problems equipped with an\nautomatic variation engine to test model robustness across changing conditions.\nAll questions require precise numerical answers, with strict formatting and\ntolerance constraints. Our evaluation of several state-of-the-art LLMs reveals\nsubstantial performance gaps, highlighting persistent limitations in physical\nreasoning, especially in generalization to dynamic variants. ABench-Physics\nprovides a challenging and diagnostic framework for advancing scientific\nreasoning in LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04766v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05720", "title": "MobileGUI-RL: Advancing Mobile GUI Agent through Reinforcement Learning in Online Environment", "authors": ["Yucheng Shi", "Wenhao Yu", "Zaitang Li", "Yonglin Wang", "Hongming Zhang", "Ninghao Liu", "Haitao Mi", "Dong Yu"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      17 pages, 4 figures", "url": "http://arxiv.org/abs/2507.05720v1", "summary": "Recently, there has been a surge of vision-based GUI agents designed to\nautomate everyday mobile and web tasks. These agents interpret raw GUI\nscreenshots and autonomously decide where to click, scroll, or type, which\nbypasses handcrafted rules and app-specific APIs. However, most existing\nmethods trained GUI agent in the offline environment using pre-collected\ntrajectories. This approach limits scalability, causes overfitting to specific\nUI templates, and leads to brittle policies when faced with unseen environment.\nWe present MobileGUI-RL, a scalable framework that trains GUI agent in online\nenvironment. MobileGUI-RL contains two key components. It (i) synthesizes a\ncurriculum of learnable tasks through self-exploration and filtering, and (ii)\nadapts GRPO to GUI navigation with trajectory-aware advantages and composite\nrewards that balance task success and execution efficiency. Experiments on\nthree online mobile-agent benchmarks show consistent gains, validating the\neffectiveness of our approach.", "comment": "17 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.05720v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05730", "title": "Hyperspectral Anomaly Detection Methods: A Survey and Comparative Study", "authors": ["Aayushma Pant", "Arbind Agrahari Baniya", "Tsz-Kwan Lee", "Sunil Aryal"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05730v1", "summary": "Hyperspectral images are high-dimensional datasets consisting of hundreds of\ncontiguous spectral bands, enabling detailed material and surface analysis.\nHyperspectral anomaly detection (HAD) refers to the technique of identifying\nand locating anomalous targets in such data without prior information about a\nhyperspectral scene or target spectrum. This technology has seen rapid\nadvancements in recent years, with applications in agriculture, defence,\nmilitary surveillance, and environmental monitoring. Despite this significant\nprogress, existing HAD methods continue to face challenges such as high\ncomputational complexity, sensitivity to noise, and limited generalisation\nacross diverse datasets. This study presents a comprehensive comparison of\nvarious HAD techniques, categorising them into statistical models,\nrepresentation-based methods, classical machine learning approaches, and deep\nlearning models. We evaluated these methods across 17 benchmarking datasets\nusing different performance metrics, such as ROC, AUC, and separability map to\nanalyse detection accuracy, computational efficiency, their strengths,\nlimitations, and directions for future research.The research shows that deep\nlearning models achieved the highest detection accuracy, while statistical\nmodels demonstrated exceptional speed across all datasets. This study aims to\nprovide valuable insights for researchers and practitioners working to advance\nthe field of hyperspectral anomaly detection methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05730v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.19112", "title": "Analysis and experiments of the dissipative Twistcar: direction reversal and asymptotic approximations", "authors": ["Rom Levy", "Ari Dantus", "Zitao Yu", "Yizhar Or"], "categories": ["cs.RO", "math.DS"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.19112v2", "summary": "Underactuated wheeled vehicles are commonly studied as nonholonomic systems\nwith periodic actuation. Twistcar is a classical example inspired by a riding\ntoy, which has been analyzed using a planar model of a dynamical system with\nnonholonomic constraints. Most of the previous analyses did not account for\nenergy dissipation due to frictional resistance. In this work, we study a\ntheoretical two-link model of the Twistcar while incorporating dissipation due\nto rolling resistance. We obtain asymptotic expressions for the system's\nsmall-amplitude steady-state periodic dynamics, which reveals the possibility\nof reversing the direction of motion upon varying the geometric and mass\nproperties of the vehicle. Next, we design and construct a robotic prototype of\nthe Twistcar whose center-of-mass position can be shifted by adding and\nremoving a massive block, enabling experimental demonstration of the Twistcar's\ndirection reversal phenomenon. We also conduct parameter fitting for the\nfrictional resistance in order to improve agreement with experiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.19112v2", "cate": "cs.RO", "date": "2025-06-23", "updated": "2025-07-08"}
{"id": "2507.05722", "title": "Hierarchical Task Offloading for UAV-Assisted Vehicular Edge Computing via Deep Reinforcement Learning", "authors": ["Hongbao Li", "Ziye Jia", "Sijie He", "Kun Guo", "Qihui Wu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures, conference", "url": "http://arxiv.org/abs/2507.05722v1", "summary": "With the emergence of compute-intensive and delay-sensitive applications in\nvehicular networks, unmanned aerial vehicles (UAVs) have emerged as a promising\ncomplement for vehicular edge computing due to the high mobility and flexible\ndeployment. However, the existing UAV-assisted offloading strategies are\ninsufficient in coordinating heterogeneous computing resources and adapting to\ndynamic network conditions. Hence, this paper proposes a dual-layer\nUAV-assisted edge computing architecture based on partial offloading, composed\nof the relay capability of high-altitude UAVs and the computing support of\nlow-altitude UAVs. The proposed architecture enables efficient integration and\ncoordination of heterogeneous resources. A joint optimization problem is\nformulated to minimize the system delay and energy consumption while ensuring\nthe task completion rate. To solve the high-dimensional decision problem, we\nreformulate the problem as a Markov decision process and propose a hierarchical\noffloading scheme based on the soft actor-critic algorithm. The method\ndecouples global and local decisions, where the global decisions integrate\noffloading ratios and trajectory planning into continuous actions, while the\nlocal scheduling is handled via designing a priority-based mechanism.\nSimulations are conducted and demonstrate that the proposed approach\noutperforms several baselines in task completion rate, system efficiency, and\nconvergence speed, showing strong robustness and applicability in dynamic\nvehicular environments.", "comment": "6 pages, 5 figures, conference", "pdf_url": "http://arxiv.org/pdf/2507.05722v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05751", "title": "SenseShift6D: Multimodal RGB-D Benchmarking for Robust 6D Pose Estimation across Environment and Sensor Variations", "authors": ["Yegyu Han", "Taegyoon Yoon", "Dayeon Woo", "Sojeong Kim", "Hyung-Sin Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05751v1", "summary": "Recent advances on 6D object-pose estimation has achieved high performance on\nrepresentative benchmarks such as LM-O, YCB-V, and T-Less. However, these\ndatasets were captured under fixed illumination and camera settings, leaving\nthe impact of real-world variations in illumination, exposure, gain or\ndepth-sensor mode - and the potential of test-time sensor control to mitigate\nsuch variations - largely unexplored. To bridge this gap, we introduce\nSenseShift6D, the first RGB-D dataset that physically sweeps 13 RGB exposures,\n9 RGB gains, auto-exposure, 4 depth-capture modes, and 5 illumination levels.\nFor three common household objects (spray, pringles, and tincase), we acquire\n101.9k RGB and 10k depth images, which can provide 1,380 unique sensor-lighting\npermutations per object pose. Experiments with state-of-the-art models on our\ndataset show that applying sensor control during test-time induces greater\nperformance improvement over digital data augmentation, achieving performance\ncomparable to or better than costly increases in real-world training data\nquantity and diversity. Adapting either RGB or depth sensors individually is\neffective, while jointly adapting multimodal RGB-D configurations yields even\ngreater improvements. SenseShift6D extends the 6D-pose evaluation paradigm from\ndata-centered to sensor-aware robustness, laying a foundation for adaptive,\nself-tuning perception systems capable of operating robustly in uncertain\nreal-world environments. Our dataset is available at:\nhuggingface.co/datasets/Yegyu/SenseShift6D Associated scripts can be found at:\ngithub.com/yegyu-han/SenseShift6D", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05751v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06139", "title": "Topic Modeling and Link-Prediction for Material Property Discovery", "authors": ["Ryan C. Barron", "Maksim E. Eren", "Valentin Stanev", "Cynthia Matuszek", "Boian S. Alexandrov"], "categories": ["cs.LG", "cs.AI", "cs.CE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      4 pages, 3 figures, 1 table", "url": "http://arxiv.org/abs/2507.06139v1", "summary": "Link prediction infers missing or future relations between graph nodes, based\non connection patterns. Scientific literature networks and knowledge graphs are\ntypically large, sparse, and noisy, and often contain missing links between\nentities. We present an AI-driven hierarchical link prediction framework that\nintegrates matrix factorization to infer hidden associations and steer\ndiscovery in complex material domains. Our method combines Hierarchical\nNonnegative Matrix Factorization (HNMFk) and Boolean matrix factorization\n(BNMFk) with automatic model selection, as well as Logistic matrix\nfactorization (LMF), we use to construct a three-level topic tree from a\n46,862-document corpus focused on 73 transition-metal dichalcogenides (TMDs).\nThese materials are studied in a variety of physics fields with many current\nand potential applications.\n  An ensemble BNMFk + LMF approach fuses discrete interpretability with\nprobabilistic scoring. The resulting HNMFk clusters map each material onto\ncoherent topics like superconductivity, energy storage, and tribology. Also,\nmissing or weakly connected links are highlight between topics and materials,\nsuggesting novel hypotheses for cross-disciplinary exploration. We validate our\nmethod by removing publications about superconductivity in well-known\nsuperconductors, and show the model predicts associations with the\nsuperconducting TMD clusters. This shows the method finds hidden connections in\na graph of material to latent topic associations built from scientific\nliterature, especially useful when examining a diverse corpus of scientific\ndocuments covering the same class of phenomena or materials but originating\nfrom distinct communities and perspectives. The inferred links generating new\nhypotheses, produced by our method, are exposed through an interactive\nStreamlit dashboard, designed for human-in-the-loop scientific discovery.", "comment": "4 pages, 3 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.06139v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.22827", "title": "Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation", "authors": ["André Schakkal", "Ben Zandonati", "Zhutian Yang", "Navid Azizan"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at the RSS 2025 Workshop on Robot Planning in the Era of Foundation Models", "url": "http://arxiv.org/abs/2506.22827v2", "summary": "Enabling humanoid robots to reliably execute complex multi-step manipulation\ntasks is crucial for their effective deployment in industrial and household\nenvironments. This paper presents a hierarchical planning and control framework\ndesigned to achieve reliable multi-step humanoid manipulation. The proposed\nsystem comprises three layers: (1) a low-level RL-based controller responsible\nfor tracking whole-body motion targets; (2) a mid-level set of skill policies\ntrained via imitation learning that produce motion targets for different steps\nof a task; and (3) a high-level vision-language planning module that determines\nwhich skills should be executed and also monitors their completion in real-time\nusing pretrained vision-language models (VLMs). Experimental validation is\nperformed on a Unitree G1 humanoid robot executing a non-prehensile\npick-and-place task. Over 40 real-world trials, the hierarchical system\nachieved a 73% success rate in completing the full manipulation sequence. These\nexperiments confirm the feasibility of the proposed hierarchical system,\nhighlighting the benefits of VLM-based skill planning and monitoring for\nmulti-step manipulation scenarios. See https://vlp-humanoid.github.io/ for\nvideo demonstrations of the policy rollout.", "comment": "Accepted at the RSS 2025 Workshop on Robot Planning in the Era of\n  Foundation Models", "pdf_url": "http://arxiv.org/pdf/2506.22827v2", "cate": "cs.RO", "date": "2025-06-28", "updated": "2025-07-08"}
{"id": "2507.05266", "title": "User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs", "authors": ["Sougata Saha", "Monojit Choudhury"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05266v1", "summary": "Measuring the generalization ability of Large Language Models (LLMs) is\nchallenging due to data contamination. As models grow and computation becomes\ncheaper, ensuring tasks and test cases are unseen during training phases will\nbecome nearly impossible. We argue that knowledge-retrieval and reasoning tasks\nare not ideal for measuring generalization, as LLMs are not trained for\nspecific tasks. Instead, we propose user behavior prediction, also a key aspect\nof personalization, as a theoretically sound, scalable, and robust alternative.\nWe introduce a novel framework for this approach and test it on movie and music\nrecommendation datasets for GPT-4o, GPT-4o-mini, and Llama-3.1-8B-Instruct.\nResults align with our framework's predictions, showing GPT-4o outperforms\nGPT-4o-mini and Llama, though all models have much room for improvement,\nespecially Llama.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05266v1", "cate": "cs.CL", "date": "2025-06-30", "updated": "2025-06-30"}
{"id": "2507.05753", "title": "Jigsaw: Training Multi-Billion-Parameter AI Weather Models with Optimized Model Parallelism", "authors": ["Deifilia Kieckhefen", "Markus Götz", "Lars H. Heyen", "Achim Streit", "Charlotte Debus"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, 10 figures", "url": "http://arxiv.org/abs/2507.05753v1", "summary": "AI-based methods have revolutionized atmospheric forecasting, with recent\nsuccesses in medium-range forecasting spurring the development of climate\nfoundation models. Accurate modeling of complex atmospheric dynamics at high\nspatial resolutions and longer lead times requires large neural networks and\ngigabyte-sized data samples, making accelerator memory and I/O-bandwidth the\nbottlenecks for model training. We introduce WeatherMixer, a\nmulti-layer-perceptron-based architecture whose workload scales linearly with\ninput size, allowing the model to learn global weather phenomena at accuracies\nsimilar to numerical weather prediction. To cope with the computational demand,\nwe propose Jigsaw, a novel model parallelization scheme that employs both\ndomain and tensor parallelism, eliminating memory redundancy. Jigsaw exceeds\nstate-of-the-art performance in strong scaling in compute-communication-limited\nsystems and achieves superscalar weak scaling in I/O-bandwidth-limited systems.\nWe scale training to 256 GPUs, reaching peak performances of 9 and 11 PFLOPs,\n23% and 28% of theoretical peaks, achieving 68% and 72% scaling efficiency\nversus 51% without model parallelism.", "comment": "12 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.05753v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05757", "title": "Normal Patch Retinex Robust Alghoritm for White Balancing in Digital Microscopy", "authors": ["Radoslaw Roszczyk", "Artur Krupa", "Izabella Antoniuk"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05757v1", "summary": "The acquisition of accurately coloured, balanced images in an optical\nmicroscope can be a challenge even for experienced microscope operators. This\narticle presents an entirely automatic mechanism for balancing the white level\nthat allows the correction of the microscopic colour images adequately. The\nresults of the algorithm have been confirmed experimentally on a set of two\nhundred microscopic images. The images contained scans of three microscopic\nspecimens commonly used in pathomorphology. Also, the results achieved were\ncompared with other commonly used white balance algorithms in digital\nphotography. The algorithm applied in this work is more effective than the\nclassical algorithms used in colour photography for microscopic images stained\nwith hematoxylin-phloxine-saffron and for immunohistochemical staining images.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05757v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05625", "title": "Iterative Sparse Asymptotic Minimum Variance Based Channel Estimation in Fluid Antenna System", "authors": ["Zhen Chen", "Jianqing Li", "Xiu Yin Zhang", "Kai-Kit Wong", "Chan-Byoung Chae", "Yangyang Zhang"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      9 pages, 7 figures", "url": "http://arxiv.org/abs/2507.05625v1", "summary": "With fluid antenna system (FAS) gradually establishing itself as a possible\nenabling technology for next generation wireless communications, channel\nestimation for FAS has become a pressing issue. Existing methodologies however\nface limitations in noise suppression. To overcome this, in this paper, we\npropose a maximum likelihood (ML)-based channel estimation approach tailored\nfor FAS systems, designed to mitigate noise interference and enhance estimation\naccuracy. By capitalizing on the inherent sparsity of wireless channels, we\nintegrate an ML-based iterative tomographic algorithm to systematically reduce\nnoise perturbations during the channel estimation process. Furthermore, the\nproposed approach leverages spatial correlation within the FAS channel to\noptimize estimation accuracy and spectral efficiency. Simulation results\nconfirm the efficacy of the proposed method, demonstrating superior channel\nestimation accuracy and robustness compared to existing benchmark techniques.", "comment": "9 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.05625v1", "cate": "eess.SP", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2503.22968", "title": "Redefining Evaluation Standards: A Unified Framework for Evaluating the Korean Capabilities of Language Models", "authors": ["Hanwool Lee", "Dasol Choi", "Sooyong Kim", "Ilgyun Jung", "Sangwon Baek", "Guijin Son", "Inseon Hwang", "Naeun Lee", "Seunghyeok Hong"], "categories": ["cs.CE", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.22968v4", "summary": "Recent advancements in Korean large language models (LLMs) have driven\nnumerous benchmarks and evaluation methods, yet inconsistent protocols cause up\nto 10 p.p performance gaps across institutions. Overcoming these\nreproducibility gaps does not mean enforcing a one-size-fits-all evaluation.\nRather, effective benchmarking requires diverse experimental approaches and a\nframework robust enough to support them. To this end, we introduce HRET (Haerae\nEvaluation Toolkit), an open-source, registry-based framework that unifies\nKorean LLM assessment. HRET integrates major Korean benchmarks, multiple\ninference backends, and multi-method evaluation, with language consistency\nenforcement to ensure genuine Korean outputs. Its modular registry design also\nenables rapid incorporation of new datasets, methods, and backends, ensuring\nthe toolkit adapts to evolving research needs. Beyond standard accuracy\nmetrics, HRET incorporates Korean-focused output analyses-morphology-aware\nType-Token Ratio (TTR) for evaluating lexical diversity and systematic\nkeyword-omission detection for identifying missing concepts-to provide\ndiagnostic insights into language-specific behaviors. These targeted analyses\nhelp researchers pinpoint morphological and semantic shortcomings in model\noutputs, guiding focused improvements in Korean LLM development.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.22968v4", "cate": "cs.CE", "date": "2025-03-29", "updated": "2025-07-08"}
{"id": "2507.05438", "title": "A Compositional Approach to Diagnosing Faults in Cyber-Physical Systems", "authors": ["Josefine B. Graebener", "Inigo Incer", "Richard M. Murray"], "categories": ["eess.SY", "cs.LO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05438v1", "summary": "Identifying the cause of a system-level failure in a cyber-physical system\n(CPS) can be like tracing a needle in a haystack. This paper approaches the\nproblem by assuming that the CPS has been designed compositionally and that\neach component in the system is associated with an assume-guarantee contract.\nWe exploit recent advances in contract-based design that show how to compute\nthe contract for the entire system using the component-level contracts. When\npresented with a system-level failure, our approach is able to efficiently\nidentify the components that are responsible for the system-level failure\ntogether with the specific predicates in those components' specifications that\nare involved in the fault. We implemented this approach using Pacti and\ndemonstrate it through illustrative examples inspired by an autonomous vehicle\nin the DARPA urban challenge.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05438v1", "cate": "eess.SY", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.03930", "title": "RwoR: Generating Robot Demonstrations from Human Hand Collection for Policy Learning without Robot", "authors": ["Liang Heng", "Xiaoqi Li", "Shangqing Mao", "Jiaming Liu", "Ruolin Liu", "Jingli Wei", "Yu-Kai Wang", "Yueru Jia", "Chenyang Gu", "Rui Zhao", "Shanghang Zhang", "Hao Dong"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03930v2", "summary": "Recent advancements in imitation learning have shown promising results in\nrobotic manipulation, driven by the availability of high-quality training data.\nTo improve data collection efficiency, some approaches focus on developing\nspecialized teleoperation devices for robot control, while others directly use\nhuman hand demonstrations to obtain training data. However, the former requires\nboth a robotic system and a skilled operator, limiting scalability, while the\nlatter faces challenges in aligning the visual gap between human hand\ndemonstrations and the deployed robot observations. To address this, we propose\na human hand data collection system combined with our hand-to-gripper\ngenerative model, which translates human hand demonstrations into robot gripper\ndemonstrations, effectively bridging the observation gap. Specifically, a GoPro\nfisheye camera is mounted on the human wrist to capture human hand\ndemonstrations. We then train a generative model on a self-collected dataset of\npaired human hand and UMI gripper demonstrations, which have been processed\nusing a tailored data pre-processing strategy to ensure alignment in both\ntimestamps and observations. Therefore, given only human hand demonstrations,\nwe are able to automatically extract the corresponding SE(3) actions and\nintegrate them with high-quality generated robot demonstrations through our\ngeneration pipeline for training robotic policy model. In experiments, the\nrobust manipulation performance demonstrates not only the quality of the\ngenerated robot demonstrations but also the efficiency and practicality of our\ndata collection method. More demonstrations can be found at:\nhttps://rwor.github.io/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03930v2", "cate": "cs.RO", "date": "2025-07-05", "updated": "2025-07-08"}
{"id": "2507.05783", "title": "From Motion to Meaning: Biomechanics-Informed Neural Network for Explainable Cardiovascular Disease Identification", "authors": ["Comte Valentin", "Gemma Piella", "Mario Ceresa", "Miguel A. Gonzalez Ballester"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05783v1", "summary": "Cardiac diseases are among the leading causes of morbidity and mortality\nworldwide, which requires accurate and timely diagnostic strategies. In this\nstudy, we introduce an innovative approach that combines deep learning image\nregistration with physics-informed regularization to predict the biomechanical\nproperties of moving cardiac tissues and extract features for disease\nclassification. We utilize the energy strain formulation of Neo-Hookean\nmaterial to model cardiac tissue deformations, optimizing the deformation field\nwhile ensuring its physical and biomechanical coherence. This explainable\napproach not only improves image registration accuracy, but also provides\ninsights into the underlying biomechanical processes of the cardiac tissues.\nEvaluation on the Automated Cardiac Diagnosis Challenge (ACDC) dataset achieved\nDice scores of 0.945 for the left ventricular cavity, 0.908 for the right\nventricular cavity, and 0.905 for the myocardium. Subsequently, we estimate the\nlocal strains within the moving heart and extract a detailed set of features\nused for cardiovascular disease classification. We evaluated five\nclassification algorithms, Logistic Regression, Multi-Layer Perceptron, Support\nVector Classifier, Random Forest, and Nearest Neighbour, and identified the\nmost relevant features using a feature selection algorithm. The best performing\nclassifier obtained a classification accuracy of 98% in the training set and\n100% in the test set of the ACDC dataset. By integrating explainable artificial\nintelligence, this method empowers clinicians with a transparent understanding\nof the model's predictions based on cardiac mechanics, while also significantly\nimproving the accuracy and reliability of cardiac disease diagnosis, paving the\nway for more personalized and effective patient care.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05783v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05763", "title": "DreamArt: Generating Interactable Articulated Objects from a Single Image", "authors": ["Ruijie Lu", "Yu Liu", "Jiaxiang Tang", "Junfeng Ni", "Yuxiang Wang", "Diwen Wan", "Gang Zeng", "Yixin Chen", "Siyuan Huang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Technical Report", "url": "http://arxiv.org/abs/2507.05763v1", "summary": "Generating articulated objects, such as laptops and microwaves, is a crucial\nyet challenging task with extensive applications in Embodied AI and AR/VR.\nCurrent image-to-3D methods primarily focus on surface geometry and texture,\nneglecting part decomposition and articulation modeling. Meanwhile, neural\nreconstruction approaches (e.g., NeRF or Gaussian Splatting) rely on dense\nmulti-view or interaction data, limiting their scalability. In this paper, we\nintroduce DreamArt, a novel framework for generating high-fidelity,\ninteractable articulated assets from single-view images. DreamArt employs a\nthree-stage pipeline: firstly, it reconstructs part-segmented and complete 3D\nobject meshes through a combination of image-to-3D generation, mask-prompted 3D\nsegmentation, and part amodal completion. Second, we fine-tune a video\ndiffusion model to capture part-level articulation priors, leveraging movable\npart masks as prompt and amodal images to mitigate ambiguities caused by\nocclusion. Finally, DreamArt optimizes the articulation motion, represented by\na dual quaternion, and conducts global texture refinement and repainting to\nensure coherent, high-quality textures across all parts. Experimental results\ndemonstrate that DreamArt effectively generates high-quality articulated\nobjects, possessing accurate part shape, high appearance fidelity, and\nplausible articulation, thereby providing a scalable solution for articulated\nasset generation. Our project page is available at\nhttps://dream-art-0.github.io/DreamArt/.", "comment": "Technical Report", "pdf_url": "http://arxiv.org/pdf/2507.05763v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05897", "title": "Performance Analysis of Linear Detection under Noise-Dependent Fast-Fading Channels", "authors": ["Almutasem Bellah Enad", "Jihad Fahs", "Hadi Sarieddeen", "Hakim Jemaa", "Tareq Y. Al-Naffouri"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05897v1", "summary": "This paper presents a performance analysis framework for linear detection in\nfast-fading channels with possibly correlated channel and noise. The framework\nis both accurate and adaptable, making it well-suited for analyzing a wide\nrange of channel and noise models. As such, it serves as a valuable tool for\nthe design and evaluation of detection algorithms in next-generation wireless\ncommunication systems. By characterizing the distribution of the effective\nnoise after zero-forcing filtering, we derive a semi-analytical and asymptotic\nexpression for the symbol error rate under Rayleigh fading and\nchannel-dependent additive circular complex Gaussian noise. The proposed\napproach demonstrates excellent agreement with integration-based benchmarks as\nconfirmed by numerical simulations thus validating its accuracy. The framework\nis flexible and can be extended to various channel and noise models, offering a\nvaluable tool for the design and analysis of detection algorithms in\nnext-generation communication systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05897v1", "cate": "eess.SP", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05454", "title": "Risk-Aware Aerocapture Guidance Through a Probabilistic Indicator Function", "authors": ["Grace E. Calkins", "Jay W. McMahon", "Alireza Doostan", "David C. Woffinden"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Currently under revision for the AIAA Journal of Guidance Control and Dynamics", "url": "http://arxiv.org/abs/2507.05454v1", "summary": "Aerocapture is sensitive to trajectory errors, particularly for low-cost\nmissions with imprecise navigation. For such missions, considering the\nprobability of each failure mode when computing guidance commands can increase\nperformance. A risk-aware aerocapture guidance algorithm is proposed that uses\na generative-modeling-based probabilistic indicator function to estimate\nescape, impact, or capture probabilities. The probability of each mode is\nincorporated into corrective guidance commands to increase the likelihood of\nsuccessful capture. The proposed method is evaluated against state-of-the-art\nnumeric predictor-corrector guidance algorithms in high-uncertainty scenarios\nwhere entry interface dispersions lead to nontrivial failure probabilities.\nWhen using a probabilistic indicator function in guidance, 69% to 100% of\nrecoverable cases are saved in near-escape and near-impact scenarios. In\naddition, the probabilistic indicator is compared to a first-order fading\nmemory filter for density estimation, showing improvements in apoapsis error\neven when a fading filter is included. The probabilistic indicator function can\nalso accurately predict failure probability for dispersions outside its\ntraining data, showing generalizability. The proposed risk-aware aerocapture\nguidance algorithm improves capture performance and robustness to entry\ninterface state dispersions, especially for missions with high navigation\nuncertainty.", "comment": "Currently under revision for the AIAA Journal of Guidance Control and\n  Dynamics", "pdf_url": "http://arxiv.org/pdf/2507.05454v1", "cate": "eess.SY", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.04846", "title": "Dynamics and multi-stability of a rotor-actuated Twistcar robot with passive steering joint", "authors": ["Anna Zigelman", "Zitao Yu", "Rom Levy", "Yizhar Or"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Supporting Information is available at this https URL", "url": "http://arxiv.org/abs/2507.04846v2", "summary": "The nonlinear dynamics of many under-actuated wheeled platforms are governed\nby nonholonomic constraints of no-skid for passively rolling wheels, coupled\nwith momentum balance. In most of theoretical models, the shape variables, i.e.\njoint angles, are directly prescribed as periodic inputs, such as steering\nangle of the Twistcar. In this work, we study a variant of the Twistcar model\nwhere the actuation input is periodic oscillations of an inertial rotor\nattached to the main body, while the steering joint is passively free to\nrotate. Remarkably, the dynamics of this model is extremely rich, and includes\nmultiplicity of periodic solutions, both symmetric and asymmetric, as well as\nstability transitions and bifurcations. We conduct numerical simulations as\nwell as asymptotic analysis of the vehicle's reduced equations of motion. We\nuse perturbation expansion in order to obtain leading-order dynamics under\nsymmetric periodic solution. Then, we utilize harmonic balance and further\nscaling assumptions in order to approximate the conditions for\nsymmetry-breaking pitchfork bifurcation and stability transition of the\nsymmetric periodic solution, as a function of actuation frequency and\nstructural parameters. The asymptotic results show good agreement with\nnumerical simulations. The results highlight the role of passive shape\nvariables in generating multi-stable periodic solutions for nonholonomic\nsystems of robotic locomotion.", "comment": "Supporting Information is available at\n  https://yizhar.net.technion.ac.il/files/2025/06/SI-MATLAB-file-Anna-Z.zip", "pdf_url": "http://arxiv.org/pdf/2507.04846v2", "cate": "cs.RO", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2507.05806", "title": "Predicting Graph Structure via Adapted Flux Balance Analysis", "authors": ["Sevvandi Kandanaarachchi", "Ziqi Xu", "Stefan Westerlund", "Conrad Sanderson"], "categories": ["cs.LG", "stat.ML", "37M10, 05C90, 68R10, 62M10, 62M20", "G.2.2; G.3; I.2.6; E.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      extended and revised version of arXiv:2401.04280", "url": "http://arxiv.org/abs/2507.05806v1", "summary": "Many dynamic processes such as telecommunication and transport networks can\nbe described through discrete time series of graphs. Modelling the dynamics of\nsuch time series enables prediction of graph structure at future time steps,\nwhich can be used in applications such as detection of anomalies. Existing\napproaches for graph prediction have limitations such as assuming that the\nvertices do not to change between consecutive graphs. To address this, we\npropose to exploit time series prediction methods in combination with an\nadapted form of flux balance analysis (FBA), a linear programming method\noriginating from biochemistry. FBA is adapted to incorporate various\nconstraints applicable to the scenario of growing graphs. Empirical evaluations\non synthetic datasets (constructed via Preferential Attachment model) and real\ndatasets (UCI Message, HePH, Facebook, Bitcoin) demonstrate the efficacy of the\nproposed approach.", "comment": "extended and revised version of arXiv:2401.04280", "pdf_url": "http://arxiv.org/pdf/2507.05806v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05790", "title": "TalkFashion: Intelligent Virtual Try-On Assistant Based on Multimodal Large Language Model", "authors": ["Yujie Hu", "Xuanyu Zhang", "Weiqi Li", "Jian Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures", "url": "http://arxiv.org/abs/2507.05790v1", "summary": "Virtual try-on has made significant progress in recent years. This paper\naddresses how to achieve multifunctional virtual try-on guided solely by text\ninstructions, including full outfit change and local editing. Previous methods\nprimarily relied on end-to-end networks to perform single try-on tasks, lacking\nversatility and flexibility. We propose TalkFashion, an intelligent try-on\nassistant that leverages the powerful comprehension capabilities of large\nlanguage models to analyze user instructions and determine which task to\nexecute, thereby activating different processing pipelines accordingly.\nAdditionally, we introduce an instruction-based local repainting model that\neliminates the need for users to manually provide masks. With the help of\nmulti-modal models, this approach achieves fully automated local editings,\nenhancing the flexibility of editing tasks. The experimental results\ndemonstrate better semantic consistency and visual quality compared to the\ncurrent methods.", "comment": "6 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.05790v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06020", "title": "A Differential Evolution Algorithm with Neighbor-hood Mutation for DOA Estimation", "authors": ["Bo Zhou", "Kaijie Xu", "Yinghui Quan", "Mengdao Xing"], "categories": ["eess.SP", "cs.NE"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06020v1", "summary": "Two-dimensional (2D) Multiple Signal Classification algorithm is a powerful\ntechnique for high-resolution direction-of-arrival (DOA) estimation in array\nsignal processing. However, the exhaustive search over the 2D an-gular domain\nleads to high computa-tional cost, limiting its applicability in real-time\nscenarios. In this work, we reformulate the peak-finding process as a\nmultimodal optimization prob-lem, and propose a Differential Evolu-tion\nalgorithm with Neighborhood Mutation (DE-NM) to efficiently lo-cate multiple\nspectral peaks without requiring dense grid sampling. Simu-lation results\ndemonstrate that the proposed method achieves comparable estimation accuracy to\nthe traditional grid search, while significantly reduc-ing computation time.\nThis strategy presents a promising solution for real-time, high-resolution DOA\nestimation in practical applications. The imple-mentation code is available at\nhttps://github.com/zzb-nice/DOA_multimodel_optimize.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06020v1", "cate": "eess.SP", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05494", "title": "Constraint Hypergraphs as a Unifying Framework for Digital Twins", "authors": ["John Morris", "Douglas L. Van Bossuyt", "Edward Louis", "Gregory Mocko", "John Wagner"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      22 pages, 7 figures", "url": "http://arxiv.org/abs/2507.05494v1", "summary": "Digital twins, used to represent physical systems, have been lauded as tools\nfor understanding reality. Complex system behavior is typically captured in\ndomain-specific models crafted by subject experts. Contemporary methods for\nemploying models in a digital twin require prescriptive interfaces, resulting\nin twins that are difficult to connect, redeploy, and modify. The limited\ninteroperability of these twins has prompted calls for a universal framework\nenabling observability across model aggregations. Here we show how a new\nmathematical formalism called a constraint hypergraph serves as such a\nframework by representing system behavior as the composition of set-based\nfunctions. A digital twin is shown to be the second of two coupled systems\nwhere both adhere to the same constraint hypergraph, permitting the properties\nof the first to be observable from the second. Interoperability is given by\ndeconstructing models into a structure enabling autonomous, white-box\nsimulation of system properties. The resulting digital twins can interact\nimmediately with both human and autonomous agents. This is demonstrated in a\ncase study of a microgrid, showing how both measured and simulated data from\nthe aggregated twins can be provided regardless of the operating environment.\nBy connecting models, constraint hypergraphs supply scientists and modelers\nrobust means to capture, communicate, and combine digital twins across all\nfields of study. We expect this framework to expand the use of digital twins,\nenriching scientific insights and collaborations by providing a structure for\ncharacterizing complex systems.", "comment": "22 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.05494v1", "cate": "eess.SY", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2404.16302", "title": "CFMW: Cross-modality Fusion Mamba for Robust Object Detection under Adverse Weather", "authors": ["Haoyuan Li", "Qi Hu", "Binjia Zhou", "You Yao", "Jiacheng Lin", "Kailun Yang", "Peng Chen"], "categories": ["cs.CV", "cs.MM", "cs.RO", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE Transactions on Circuits and Systems for Video Technology (TCSVT). The dataset and source code will be made publicly available at this https URL", "url": "http://arxiv.org/abs/2404.16302v2", "summary": "Visible-infrared image pairs provide complementary information, enhancing the\nreliability and robustness of object detection applications in real-world\nscenarios. However, most existing methods face challenges in maintaining\nrobustness under complex weather conditions, which limits their applicability.\nMeanwhile, the reliance on attention mechanisms in modality fusion introduces\nsignificant computational complexity and storage overhead, particularly when\ndealing with high-resolution images. To address these challenges, we propose\nthe Cross-modality Fusion Mamba with Weather-removal (CFMW) to augment\nstability and cost-effectiveness under adverse weather conditions. Leveraging\nthe proposed Perturbation-Adaptive Diffusion Model (PADM) and Cross-modality\nFusion Mamba (CFM) modules, CFMW is able to reconstruct visual features\naffected by adverse weather, enriching the representation of image details.\nWith efficient architecture design, CFMW is 3 times faster than\nTransformer-style fusion (e.g., CFT). To bridge the gap in relevant datasets,\nwe construct a new Severe Weather Visible-Infrared (SWVI) dataset, encompassing\ndiverse adverse weather scenarios such as rain, haze, and snow. The dataset\ncontains 64,281 paired visible-infrared images, providing a valuable resource\nfor future research. Extensive experiments on public datasets (i.e., M3FD and\nLLVIP) and the newly constructed SWVI dataset conclusively demonstrate that\nCFMW achieves state-of-the-art detection performance. Both the dataset and\nsource code will be made publicly available at\nhttps://github.com/lhy-zjut/CFMW.", "comment": "Accepted to IEEE Transactions on Circuits and Systems for Video\n  Technology (TCSVT). The dataset and source code will be made publicly\n  available at https://github.com/lhy-zjut/CFMW", "pdf_url": "http://arxiv.org/pdf/2404.16302v2", "cate": "cs.CV", "date": "2024-04-25", "updated": "2025-07-08"}
{"id": "2507.05807", "title": "Improving Robustness of Foundation Models in Domain Adaptation with Soup-Adapters", "authors": ["Marco Roschkowski"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05807v1", "summary": "In this paper, we tackle two fundamental problems in few-shot domain\nadaptation of foundation models. First, hyperparameter tuning is often\nimpractical due to the lack of large validation datasets. Second, model\nrobustness under distribution shifts where test time data deviates slightly\nfrom training distributions, remains a concern. We show that by training\nmultiple independent adapters and averaging their outputs, the new model has a\nhigher performance and is more robust to distribution shifts compared to any\nindividual adapter. This improvement holds even when the adapters are trained\nwith diverse hyperparameters sampled from a wide range, resulting in varied\nindividual performance. Consequently, our method addresses both of the problems\ndescribed above. The ensemble is also significantly less sensitive to the\nresidual ratio, a critical hyperparameter of CLIP-Adapter. Since the ensemble\ncan be reparameterized to a single adapter again using a principled\nconcatenation of the parameters, we refer to our method as Soup-Adapter. This\nis also the first study to explore CLIP adapter-style techniques for DINOv2 and\nto directly compare them with CLIP in this setting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05807v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05798", "title": "SPADE: Spatial-Aware Denoising Network for Open-vocabulary Panoptic Scene Graph Generation with Long- and Local-range Context Reasoning", "authors": ["Xin Hu", "Ke Qin", "Guiduo Duan", "Ming Li", "Yuan-Fang Li", "Tao He"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.05798v1", "summary": "Panoptic Scene Graph Generation (PSG) integrates instance segmentation with\nrelation understanding to capture pixel-level structural relationships in\ncomplex scenes. Although recent approaches leveraging pre-trained\nvision-language models (VLMs) have significantly improved performance in the\nopen-vocabulary setting, they commonly ignore the inherent limitations of VLMs\nin spatial relation reasoning, such as difficulty in distinguishing object\nrelative positions, which results in suboptimal relation prediction. Motivated\nby the denoising diffusion model's inversion process in preserving the spatial\nstructure of input images, we propose SPADE (SPatial-Aware Denoising-nEtwork)\nframework -- a novel approach for open-vocabulary PSG. SPADE consists of two\nkey steps: (1) inversion-guided calibration for the UNet adaptation, and (2)\nspatial-aware context reasoning. In the first step, we calibrate a general\npre-trained teacher diffusion model into a PSG-specific denoising network with\ncross-attention maps derived during inversion through a lightweight LoRA-based\nfine-tuning strategy. In the second step, we develop a spatial-aware relation\ngraph transformer that captures both local and long-range contextual\ninformation, facilitating the generation of high-quality relation queries.\nExtensive experiments on benchmark PSG and Visual Genome datasets demonstrate\nthat SPADE outperforms state-of-the-art methods in both closed- and open-set\nscenarios, particularly for spatial relationship prediction.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.05798v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05509", "title": "Basic Computations in Fault Tree Analysis", "authors": ["Hamid Jahanian"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05509v1", "summary": "Fault Tree Analysis (FTA) is a well-established method in failure analysis\nand is widely used in safety and reliability assessments. While FTA tools\nenable users to manage complex analyses effectively, they can sometimes obscure\nthe underlying calculation processes. As a result, the soundness of FTA results\noften hinges on the user's expertise and familiarity with the methodology and\nthe tool. This paper aims to explore the fundamental principles underlying both\nqualitative and quantitative FTA analyses, while addressing broader conceptual\nconsiderations such as coherence and consensus. By developing a deeper\nunderstanding of these concepts, engineers can improve their ability to\ninterpret, verify, and make informed use of the outputs generated by FTA tools.\nThis paper does not propose a novel concept in FTA but aims to compile and\npresent a concise overview of the fundamental computations in FTA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05509v1", "cate": "eess.SY", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2407.09718", "title": "CLOVER: Context-aware Long-term Object Viewpoint- and Environment- Invariant Representation Learning", "authors": ["Dongmyeong Lee", "Amanda Adkins", "Joydeep Biswas"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 3 figures, 8 tables", "url": "http://arxiv.org/abs/2407.09718v2", "summary": "Mobile service robots can benefit from object-level understanding of their\nenvironments, including the ability to distinguish object instances and\nre-identify previously seen instances. Object re-identification is challenging\nacross different viewpoints and in scenes with significant appearance variation\narising from weather or lighting changes. Existing works on object\nre-identification either focus on specific classes or require foreground\nsegmentation. Further, these methods, along with object re-identification\ndatasets, have limited consideration of challenges such as outdoor scenes and\nillumination changes. To address this problem, we introduce CODa Re-ID: an\nin-the-wild object re-identification dataset containing 1,037,814 observations\nof 557 objects across 8 classes under diverse lighting conditions and\nviewpoints. Further, we propose CLOVER, a representation learning method for\nobject observations that can distinguish between static object instances\nwithout requiring foreground segmentation. We also introduce MapCLOVER, a\nmethod for scalably summarizing CLOVER descriptors for use in object maps and\nmatching new observations to summarized descriptors. Our results show that\nCLOVER achieves superior performance in static object re-identification under\nvarying lighting conditions and viewpoint changes and can generalize to unseen\ninstances and classes.", "comment": "8 pages, 3 figures, 8 tables", "pdf_url": "http://arxiv.org/pdf/2407.09718v2", "cate": "cs.CV", "date": "2024-07-12", "updated": "2025-07-08"}
{"id": "2507.05810", "title": "Concept-Based Mechanistic Interpretability Using Structured Knowledge Graphs", "authors": ["Sofiia Chorna", "Kateryna Tarelkina", "Eloïse Berthier", "Gianni Franchi"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages", "url": "http://arxiv.org/abs/2507.05810v1", "summary": "While concept-based interpretability methods have traditionally focused on\nlocal explanations of neural network predictions, we propose a novel framework\nand interactive tool that extends these methods into the domain of mechanistic\ninterpretability. Our approach enables a global dissection of model behavior by\nanalyzing how high-level semantic attributes (referred to as concepts) emerge,\ninteract, and propagate through internal model components. Unlike prior work\nthat isolates individual neurons or predictions, our framework systematically\nquantifies how semantic concepts are represented across layers, revealing\nlatent circuits and information flow that underlie model decision-making. A key\ninnovation is our visualization platform that we named BAGEL (for Bias Analysis\nwith a Graph for global Explanation Layers), which presents these insights in a\nstructured knowledge graph, allowing users to explore concept-class\nrelationships, identify spurious correlations, and enhance model\ntrustworthiness. Our framework is model-agnostic, scalable, and contributes to\na deeper understanding of how deep learning models generalize (or fail to) in\nthe presence of dataset biases. The demonstration is available at\nhttps://knowledge-graph-ui-4a7cb5.gitlab.io/.", "comment": "15 pages", "pdf_url": "http://arxiv.org/pdf/2507.05810v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05805", "title": "DREAM: Document Reconstruction via End-to-end Autoregressive Model", "authors": ["Xin Li", "Mingming Gong", "Yunfei Wu", "Jianxin Dai", "Antai Guo", "Xinghua Jiang", "Haoyu Cao", "Yinsong Liu", "Deqiang Jiang", "Xing Sun"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05805v1", "summary": "Document reconstruction constitutes a significant facet of document analysis\nand recognition, a field that has been progressively accruing interest within\nthe scholarly community. A multitude of these researchers employ an array of\ndocument understanding models to generate predictions on distinct subtasks,\nsubsequently integrating their results into a holistic document reconstruction\nformat via heuristic principles. Nevertheless, these multi-stage methodologies\nare hindered by the phenomenon of error propagation, resulting in suboptimal\nperformance. Furthermore, contemporary studies utilize generative models to\nextract the logical sequence of plain text, tables and mathematical expressions\nin an end-to-end process. However, this approach is deficient in preserving the\ninformation related to element layouts, which are vital for document\nreconstruction. To surmount these aforementioned limitations, we in this paper\npresent an innovative autoregressive model specifically designed for document\nreconstruction, referred to as Document Reconstruction via End-to-end\nAutoregressive Model (DREAM). DREAM transmutes the text image into a sequence\nof document reconstruction in a comprehensive, end-to-end process,\nencapsulating a broader spectrum of document element information. In addition,\nwe establish a standardized definition of the document reconstruction task, and\nintroduce a novel Document Similarity Metric (DSM) and DocRec1K dataset for\nassessing the performance of the task. Empirical results substantiate that our\nmethodology attains unparalleled performance in the realm of document\nreconstruction. Furthermore, the results on a variety of subtasks, encompassing\ndocument layout analysis, text recognition, table structure recognition,\nformula recognition and reading order detection, indicate that our model is\ncompetitive and compatible with various tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05805v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06048", "title": "Secure Communication of UAV-mounted STAR-RIS under Phase Shift Errors", "authors": ["Aseel Qsibat", "Habiba Akhleifa", "Abdelhamid Salem", "Khaled Rabie", "Xingwang Li", "Thokozani Shongwe", "Mohamad A. Alawad", "Yazeed Alkhrijah"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06048v1", "summary": "This paper investigates the secure communication capabilities of a\nnon-orthogonal multiple access (NOMA) network supported by a STAR-RIS\n(simultaneously transmitting and reflecting reconfigurable intelligent surface)\ndeployed on an unmanned aerial vehicle (UAV), in the presence of passive\neavesdroppers. The STAR-RIS facilitates concurrent signal reflection and\ntransmission, allowing multiple legitimate users-grouped via NOMA-to be served\nefficiently, thereby improving spectral utilization. Each user contends with an\nassociated eavesdropper, creating a stringent security scenario. Under Nakagami\nfading conditions and accounting for phase shift inaccuracies in the STAR-RIS,\nclosed-form expressions for the ergodic secrecy rates of users in both\ntransmission and reflection paths are derived. An optimization framework is\nthen developed to jointly adjust the UAV's positioning and the STAR-RIS power\nsplitting coefficient, aiming to maximize the system's secrecy rate. The\nproposed approach enhances secure transmission in STAR-RIS-NOMA configurations\nunder realistic hardware constraints and offers valuable guidance for the\ndesign of future 6G wireless networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06048v1", "cate": "eess.SP", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05711", "title": "Sparsity-Promoting Dynamic Mode Decomposition Applied to Sea Surface Temperature Fields", "authors": ["Zhicheng Zhang", "Yoshihiko Susuki", "Atsushi Okazaki"], "categories": ["eess.SY", "cs.SY", "physics.ao-ph", "37M10 (Primary), 86A10 (Secondary)"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      9 pages", "url": "http://arxiv.org/abs/2507.05711v1", "summary": "In this paper, we leverage Koopman mode decomposition to analyze the\nnonlinear and high-dimensional climate systems acting on the observed data\nspace. The dynamics of atmospheric systems are assumed to be equation-free,\nwith the linear evolution of observables derived from measured historical\nlong-term time-series data snapshots, such as monthly sea surface temperature\nrecords, to construct a purely data-driven climate dynamics. In particular,\nsparsity-promoting dynamic mode decomposition is exploited to extract the\ndominant spatial and temporal modes, which are among the most significant\ncoherent structures underlying climate variability, enabling a more efficient,\ninterpretable, and low-dimensional representation of the system dynamics. We\nhope that the combined use of Koopman modes and sparsity-promoting techniques\nwill provide insights into the significant climate modes, enabling\nreduced-order modeling of the climate system and offering a potential framework\nfor predicting and controlling weather and climate variability.", "comment": "9 pages", "pdf_url": "http://arxiv.org/pdf/2507.05711v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2411.12155", "title": "Coarse-to-fine Q-Network with Action Sequence for Data-Efficient Robot Learning", "authors": ["Younggyo Seo", "Pieter Abbeel"], "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18 Pages. Website: this https URL", "url": "http://arxiv.org/abs/2411.12155v5", "summary": "Predicting a sequence of actions has been crucial in the success of recent\nbehavior cloning algorithms in robotics. Can similar ideas improve\nreinforcement learning (RL)? We answer affirmatively by observing that\nincorporating action sequences when predicting ground-truth return-to-go leads\nto lower validation loss. Motivated by this, we introduce Coarse-to-fine\nQ-Network with Action Sequence (CQN-AS), a novel value-based RL algorithm that\nlearns a critic network that outputs Q-values over a sequence of actions, i.e.,\nexplicitly training the value function to learn the consequence of executing\naction sequences. Our experiments show that CQN-AS outperforms several\nbaselines on a variety of sparse-reward humanoid control and tabletop\nmanipulation tasks from BiGym and RLBench.", "comment": "18 Pages. Website: https://younggyo.me/cqn-as/", "pdf_url": "http://arxiv.org/pdf/2411.12155v5", "cate": "cs.LG", "date": "2024-11-19", "updated": "2025-07-07"}
{"id": "2507.05280", "title": "Hungary and AI: efforts and opportunities in comparison with Singapore", "authors": ["András Ferenczy"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      39 pages", "url": "http://arxiv.org/abs/2507.05280v1", "summary": "The study assesses Hungary's National AI Strategy and its implementation\nthrough the analysis of strategic documents, publicly available financial\nrecords, and expert interviews with the Hungarian AI Coalition President and\nChief Strategic Advisor to the Government Commissioner for AI. 22 goals from\nHungary's strategy were evaluated through conceptual, governance, temporal, and\nfinancial dimensions before being benchmarked against Singapore's National AI\nStrategies (NAIS 1.0 and NAIS 2.0). Key findings include an estimated total of\nEUR 4.65 billion in AI-related public investment in Hungary. Openly available\nfinancial data was found for only half of the evaluated goals, and just three\nprojects made up 98\\% of all documented funding. The research also reveals\nHungary's implementation challenges, including fragmented execution following\nministerial reorganizations and the absence of designated biennial reviews\nsince 2020. Furthermore, the paper provides targeted recommendations for\nHungary's forthcoming AI strategy, drawing on Singapore's framework as a\nreference point. These include adapting to the era of large language models,\nrestructuring the existing triple helix network to foster more effective\ndialogue and advocacy, and positioning the country as an East-West bridge for\nautomotive AI experimentation.", "comment": "39 pages", "pdf_url": "http://arxiv.org/pdf/2507.05280v1", "cate": "cs.CY", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.05823", "title": "Fair Domain Generalization: An Information-Theoretic View", "authors": ["Tangzheng Lian", "Guanyu Hu", "Dimitrios Kollias", "Xinyu Yang", "Oya Celiktutan"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05823v1", "summary": "Domain generalization (DG) and algorithmic fairness are two critical\nchallenges in machine learning. However, most DG methods focus only on\nminimizing expected risk in the unseen target domain without considering\nalgorithmic fairness. Conversely, fairness methods typically do not account for\ndomain shifts, so the fairness achieved during training may not generalize to\nunseen test domains. In this work, we bridge these gaps by studying the problem\nof Fair Domain Generalization (FairDG), which aims to minimize both expected\nrisk and fairness violations in unseen target domains. We derive novel mutual\ninformation-based upper bounds for expected risk and fairness violations in\nmulti-class classification tasks with multi-group sensitive attributes. These\nbounds provide key insights for algorithm design from an information-theoretic\nperspective. Guided by these insights, we introduce PAFDG (Pareto-Optimal\nFairness for Domain Generalization), a practical framework that solves the\nFairDG problem and models the utility-fairness trade-off through Pareto\noptimization. Experiments on real-world vision and language datasets show that\nPAFDG achieves superior utility-fairness trade-offs compared to existing\nmethods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05823v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05812", "title": "Towards Solar Altitude Guided Scene Illumination", "authors": ["Samed Doğan", "Maximilian Hoh", "Nico Leuze", "Nicolas R. -Peña", "Alfred Schöttl"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.05812v1", "summary": "The development of safe and robust autonomous driving functions is heavily\ndependent on large-scale, high-quality sensor data. However, real-word data\nacquisition demands intensive human labor and is strongly limited by factors\nsuch as labeling cost, driver safety protocols and diverse scenario coverage.\nThus, multiple lines of work focus on the conditional generation of synthetic\ncamera sensor data. We identify a significant gap in research regarding daytime\nvariation, presumably caused by the scarcity of available labels. Consequently,\nwe present the solar altitude as global conditioning variable. It is readily\ncomputable from latitude-longitude coordinates and local time, eliminating the\nneed for extensive manual labeling. Our work is complemented by a tailored\nnormalization approach, targeting the sensitivity of daylight towards small\nnumeric changes in altitude. We demonstrate its ability to accurately capture\nlighting characteristics and illumination-dependent image noise in the context\nof diffusion models.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.05812v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06066", "title": "AI-based Environment-Aware XL-MIMO Channel Estimation with Location-Specific Prior Knowledge Enabled by CKM", "authors": ["Yuelong Qiu", "Di Wu", "Yong Zeng", "Yanqun Tang", "Nan Cheng", "Chenhao Qi"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      13 pages, 11 figures, 1 table, Under review at IEEE Transactions on Communications", "url": "http://arxiv.org/abs/2507.06066v1", "summary": "Accurate and efficient acquisition of wireless channel state information\n(CSI) is crucial to enhance the communication performance of wireless systems.\nHowever, with the continuous densification of wireless links, increased channel\ndimensions, and the use of higher-frequency bands, channel estimation in the\nsixth generation (6G) and beyond wireless networks faces new challenges, such\nas insufficient orthogonal pilot sequences, inadequate signal-to-noise ratio\n(SNR) for channel training, and more sophisticated channel statistical\ndistributions in complex environment. These challenges pose significant\ndifficulties for classical channel estimation algorithms like least squares\n(LS) and maximum a posteriori (MAP). To address this problem, we propose a\nnovel environment-aware channel estimation framework with location-specific\nprior channel distribution enabled by the new concept of channel knowledge map\n(CKM). To this end, we propose a new type of CKM called channel score function\nmap (CSFM), which learns the channel probability density function (PDF) using\nartificial intelligence (AI) techniques. To fully exploit the prior information\nin CSFM, we propose a plug-and-play (PnP) based algorithm to decouple the\nregularized MAP channel estimation problem, thereby reducing the complexity of\nthe optimization process. Besides, we employ Tweedie's formula to establish a\nconnection between the channel score function, defined as the logarithmic\ngradient of the channel PDF, and the channel denoiser. This allows the use of\nthe high-precision, environment-aware channel denoiser from the CSFM to\napproximate the channel score function, thus enabling efficient processing of\nthe decoupled channel statistical components. Simulation results show that the\nproposed CSFM-PnP based channel estimation technique significantly outperforms\nthe conventional techniques in the aforementioned challenging scenarios.", "comment": "13 pages, 11 figures, 1 table, Under review at IEEE Transactions on\n  Communications", "pdf_url": "http://arxiv.org/pdf/2507.06066v1", "cate": "eess.SP", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05785", "title": "Robust Bandwidth Estimation for Real-Time Communication with Offline Reinforcement Learning", "authors": ["Jian Kai", "Tianwei Zhang", "Zihan Ling", "Yang Cao", "Can Shen"], "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05785v1", "summary": "Accurate bandwidth estimation (BWE) is critical for real-time communication\n(RTC) systems. Traditional heuristic approaches offer limited adaptability\nunder dynamic networks, while online reinforcement learning (RL) suffers from\nhigh exploration costs and potential service disruptions. Offline RL, which\nleverages high-quality data collected from real-world environments, offers a\npromising alternative. However, challenges such as out-of-distribution (OOD)\nactions, policy extraction from behaviorally diverse datasets, and reliable\ndeployment in production systems remain unsolved. We propose RBWE, a robust\nbandwidth estimation framework based on offline RL that integrates Q-ensemble\n(an ensemble of Q-functions) with a Gaussian mixture policy to mitigate OOD\nrisks and enhance policy learning. A fallback mechanism ensures deployment\nstability by switching to heuristic methods under high uncertainty.\nExperimental results show that RBWE reduces overestimation errors by 18% and\nimproves the 10th percentile Quality of Experience (QoE) by 18.6%,\ndemonstrating its practical effectiveness in real-world RTC applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05785v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05314", "title": "Dual-Attention U-Net++ with Class-Specific Ensembles and Bayesian Hyperparameter Optimization for Precise Wound and Scale Marker Segmentation", "authors": ["Daniel Cieślak", "Miriam Reca", "Olena Onyshchenko", "Jacek Rumiński"], "categories": ["eess.IV", "cs.CV", "I.4.6; I.5.1; I.2.6; J.3"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      11 pages, conference: Joint 20th Nordic-Baltic Conference on Biomedical Engineering & 24th Polish Conference on Biocybernetics and Biomedical Engineering; 6 figures, 2 tables, 11 sources", "url": "http://arxiv.org/abs/2507.05314v1", "summary": "Accurate segmentation of wounds and scale markers in clinical images remainsa\nsignificant challenge, crucial for effective wound management and\nautomatedassessment. In this study, we propose a novel dual-attention U-Net++\narchi-tecture, integrating channel-wise (SCSE) and spatial attention mechanisms\ntoaddress severe class imbalance and variability in medical images\neffectively.Initially, extensive benchmarking across diverse architectures and\nencoders via 5-fold cross-validation identified EfficientNet-B7 as the optimal\nencoder backbone.Subsequently, we independently trained two class-specific\nmodels with tailoredpreprocessing, extensive data augmentation, and Bayesian\nhyperparameter tun-ing (WandB sweeps). The final model ensemble utilized Test\nTime Augmentationto further enhance prediction reliability. Our approach was\nevaluated on a bench-mark dataset from the NBC 2025 & PCBBE 2025 competition.\nSegmentationperformance was quantified using a weighted F1-score (75% wounds,\n25% scalemarkers), calculated externally by competition organizers on\nundisclosed hard-ware. The proposed approach achieved an F1-score of 0.8640,\nunderscoring itseffectiveness for complex medical segmentation tasks.", "comment": "11 pages, conference: Joint 20th Nordic-Baltic Conference on\n  Biomedical Engineering & 24th Polish Conference on Biocybernetics and\n  Biomedical Engineering; 6 figures, 2 tables, 11 sources", "pdf_url": "http://arxiv.org/pdf/2507.05314v1", "cate": "eess.IV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2504.02964", "title": "Distributionally Robust Predictive Runtime Verification under Spatio-Temporal Logic Specifications", "authors": ["Yiqi Zhao", "Emily Zhu", "Bardh Hoxha", "Georgios Fainekos", "Jyotirmoy V. Deshmukh", "Lars Lindemann"], "categories": ["eess.SY", "cs.LO", "cs.RO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2311.09482", "url": "http://arxiv.org/abs/2504.02964v2", "summary": "Cyber-physical systems (CPS) designed in simulators, often consisting of\nmultiple interacting agents (e.g. in multi-agent formations), behave\ndifferently in the real-world. We want to verify these systems during runtime\nwhen they are deployed. We thus propose robust predictive runtime verification\n(RPRV) algorithms for: (1) general stochastic CPS under signal temporal logic\n(STL) tasks, and (2) stochastic multi-agent systems (MAS) under spatio-temporal\nlogic tasks. The RPRV problem presents the following challenges: (1) there may\nnot be sufficient data on the behavior of the deployed CPS, (2) predictive\nmodels based on design phase system trajectories may encounter distribution\nshift during real-world deployment, and (3) the algorithms need to scale to the\ncomplexity of MAS and be applicable to spatio-temporal logic tasks. To address\nthe challenges, we assume knowledge of an upper bound on the statistical\ndistance between the trajectory distributions of the system at deployment and\ndesign time. We are motivated by our prior work [1, 2] where we proposed an\naccurate and an interpretable RPRV algorithm for general CPS, which we here\nextend to the MAS setting and spatio-temporal logic tasks. Specifically, we use\na learned predictive model to estimate the system behavior at runtime and\nrobust conformal prediction to obtain probabilistic guarantees by accounting\nfor distribution shifts. Building on [1], we perform robust conformal\nprediction over the robust semantics of spatio-temporal reach and escape logic\n(STREL) to obtain centralized RPRV algorithms for MAS. We empirically validate\nour results in a drone swarm simulator, where we show the scalability of our\nRPRV algorithms to MAS and analyze the impact of different trajectory\npredictors on the verification result. To the best of our knowledge, these are\nthe first statistically valid algorithms for MAS under distribution shift.", "comment": "arXiv admin note: text overlap with arXiv:2311.09482", "pdf_url": "http://arxiv.org/pdf/2504.02964v2", "cate": "eess.SY", "date": "2025-04-03", "updated": "2025-07-07"}
{"id": "2507.05282", "title": "Exploring LLM Capabilities in Extracting DCAT-Compatible Metadata for Data Cataloging", "authors": ["Lennart Busch", "Daniel Tebernum", "Gissel Velarde"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05282v1", "summary": "Efficient data exploration is crucial as data becomes increasingly important\nfor accelerating processes, improving forecasts and developing new business\nmodels. Data consumers often spend 25-98 % of their time searching for suitable\ndata due to the exponential growth, heterogeneity and distribution of data.\nData catalogs can support and accelerate data exploration by using metadata to\nanswer user queries. However, as metadata creation and maintenance is often a\nmanual process, it is time-consuming and requires expertise. This study\ninvestigates whether LLMs can automate metadata maintenance of text-based data\nand generate high-quality DCAT-compatible metadata. We tested zero-shot and\nfew-shot prompting strategies with LLMs from different vendors for generating\nmetadata such as titles and keywords, along with a fine-tuned model for\nclassification. Our results show that LLMs can generate metadata comparable to\nhuman-created content, particularly on tasks that require advanced semantic\nunderstanding. Larger models outperformed smaller ones, and fine-tuning\nsignificantly improves classification accuracy, while few-shot prompting yields\nbetter results in most cases. Although LLMs offer a faster and reliable way to\ncreate metadata, a successful application requires careful consideration of\ntask-specific criteria and domain context.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05282v1", "cate": "cs.IR", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.05852", "title": "Prototype-Guided and Lightweight Adapters for Inherent Interpretation and Generalisation in Federated Learning", "authors": ["Samuel Ofosu Mensah", "Kerol Djoumessi", "Philipp Berens"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 4 figures, submitted to MICCAI 2025, used llncs document class", "url": "http://arxiv.org/abs/2507.05852v1", "summary": "Federated learning (FL) provides a promising paradigm for collaboratively\ntraining machine learning models across distributed data sources while\nmaintaining privacy. Nevertheless, real-world FL often faces major challenges\nincluding communication overhead during the transfer of large model parameters\nand statistical heterogeneity, arising from non-identical independent data\ndistributions across clients. In this work, we propose an FL framework that 1)\nprovides inherent interpretations using prototypes, and 2) tackles statistical\nheterogeneity by utilising lightweight adapter modules to act as compressed\nsurrogates of local models and guide clients to achieve generalisation despite\nvarying client distribution. Each client locally refines its model by aligning\nclass embeddings toward prototype representations and simultaneously adjust the\nlightweight adapter. Our approach replaces the need to communicate entire model\nweights with prototypes and lightweight adapters. This design ensures that each\nclient's model aligns with a globally shared structure while minimising\ncommunication load and providing inherent interpretations. Moreover, we\nconducted our experiments on a real-world retinal fundus image dataset, which\nprovides clinical-site information. We demonstrate inherent interpretable\ncapabilities and perform a classification task, which shows improvements in\naccuracy over baseline algorithms.", "comment": "10 pages, 4 figures, submitted to MICCAI 2025, used llncs document\n  class", "pdf_url": "http://arxiv.org/pdf/2507.05852v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05814", "title": "Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework", "authors": ["Wang Wang", "Mingyu Shi", "Jun Jiang", "Wenqian Ma", "Chong Liu", "Yasutaka Narazaki", "Xuguang Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      18 pages, 10 figures", "url": "http://arxiv.org/abs/2507.05814v1", "summary": "As critical transportation infrastructure, bridges face escalating challenges\nfrom aging and deterioration, while traditional manual inspection methods\nsuffer from low efficiency. Although 3D point cloud technology provides a new\ndata-driven paradigm, its application potential is often constrained by the\nincompleteness of real-world data, which results from missing labels and\nscanning occlusions. To overcome the bottleneck of insufficient generalization\nin existing synthetic data methods, this paper proposes a systematic framework\nfor generating 3D bridge data.\n  This framework can automatically generate complete point clouds featuring\ncomponent-level instance annotations, high-fidelity color, and precise normal\nvectors. It can be further extended to simulate the creation of diverse and\nphysically realistic incomplete point clouds, designed to support the training\nof segmentation and completion networks, respectively. Experiments demonstrate\nthat a PointNet++ model trained with our synthetic data achieves a mean\nIntersection over Union (mIoU) of 84.2% in real-world bridge semantic\nsegmentation. Concurrently, a fine-tuned KT-Net exhibits superior performance\non the component completion task.\n  This research offers an innovative methodology and a foundational dataset for\nthe 3D visual analysis of bridge structures, holding significant implications\nfor advancing the automated management and maintenance of infrastructure.", "comment": "18 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.05814v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05312", "title": "Introducing Image-Space Preconditioning in the Variational Formulation of MRI Reconstructions", "authors": ["Bastien Milani", "Jean-Baptist Ledoux", "Berk Can Acikgoz", "Xavier Richard"], "categories": ["physics.med-ph", "eess.SP"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "Comments:      48 pages, 7 figures, 3 latex graphics", "url": "http://arxiv.org/abs/2507.05312v1", "summary": "The aim of the present article is to enrich the comprehension of iterative\nmagnetic resonance imaging (MRI) reconstructions, including compressed sensing\n(CS) and iterative deep learning (DL) reconstructions, by describing them in\nthe general framework of finite-dimensional inner-product spaces. In\nparticular, we show that image-space preconditioning (ISP) and data-space\npreconditioning (DSP) can be formulated as non-conventional inner-products. The\nmain gain of our reformulation is an embedding of ISP in the variational\nformulation of the MRI reconstruction problem (in an algorithm-independent way)\nwhich allows in principle to naturally and systematically propagate ISP in all\niterative reconstructions, including many iterative DL and CS reconstructions\nwhere preconditioning is lacking. The way in which we apply linear algebraic\ntools to MRI reconstructions as presented in this article is a novelty.\n  A secondary aim of our article is to offer a certain didactic material to\nscientists who are new in the field of MRI reconstruction. Since we explore\nhere some mathematical concepts of reconstruction, we take that opportunity to\nrecall some principles that may be understood for experts, but which may be\nhard to find in the literature for beginners. In fact, the description of many\nmathematical tools of MRI reconstruction is fragmented in the literature or\nsometimes missing because considered as a general knowledge. Further, some of\nthose concepts can be found in mathematic manuals, but not in a form that is\noriented toward MRI. For example, we think of the conjugate gradient descent,\nthe notion of derivative with respect to non-conventional inner products, or\nsimply the notion of adjoint. The authors believe therefore that it is\nbeneficial for their field of research to dedicate some space to such a\ndidactic material.", "comment": "48 pages, 7 figures, 3 latex graphics", "pdf_url": "http://arxiv.org/pdf/2507.05312v1", "cate": "physics.med-ph", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05317", "title": "PWD: Prior-Guided and Wavelet-Enhanced Diffusion Model for Limited-Angle CT", "authors": ["Yi Liu", "Yiyang Wen", "Zekun Zhou", "Junqi Ma", "Linghang Wang", "Yucheng Yao", "Liu Shi", "Qiegen Liu"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05317v1", "summary": "Generative diffusion models have received increasing attention in medical\nimaging, particularly in limited-angle computed tomography (LACT). Standard\ndiffusion models achieve high-quality image reconstruction but require a large\nnumber of sampling steps during inference, resulting in substantial\ncomputational overhead. Although skip-sampling strategies have been proposed to\nimprove efficiency, they often lead to loss of fine structural details. To\naddress this issue, we propose a prior information embedding and wavelet\nfeature fusion fast sampling diffusion model for LACT reconstruction. The PWD\nenables efficient sampling while preserving reconstruction fidelity in LACT,\nand effectively mitigates the degradation typically introduced by\nskip-sampling. Specifically, during the training phase, PWD maps the\ndistribution of LACT images to that of fully sampled target images, enabling\nthe model to learn structural correspondences between them. During inference,\nthe LACT image serves as an explicit prior to guide the sampling trajectory,\nallowing for high-quality reconstruction with significantly fewer steps. In\naddition, PWD performs multi-scale feature fusion in the wavelet domain,\neffectively enhancing the reconstruction of fine details by leveraging both\nlow-frequency and high-frequency information. Quantitative and qualitative\nevaluations on clinical dental arch CBCT and periapical datasets demonstrate\nthat PWD outperforms existing methods under the same sampling condition. Using\nonly 50 sampling steps, PWD achieves at least 1.7 dB improvement in PSNR and\n10% gain in SSIM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05317v1", "cate": "eess.IV", "date": "2025-06-30", "updated": "2025-06-30"}
{"id": "2505.00503", "title": "Variational OOD State Correction for Offline Reinforcement Learning", "authors": ["Ke Jiang", "Wen Jiang", "Xiaoyang Tan"], "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00503v3", "summary": "The performance of Offline reinforcement learning is significantly impacted\nby the issue of state distributional shift, and out-of-distribution (OOD) state\ncorrection is a popular approach to address this problem. In this paper, we\npropose a novel method named Density-Aware Safety Perception (DASP) for OOD\nstate correction. Specifically, our method encourages the agent to prioritize\nactions that lead to outcomes with higher data density, thereby promoting its\noperation within or the return to in-distribution (safe) regions. To achieve\nthis, we optimize the objective within a variational framework that\nconcurrently considers both the potential outcomes of decision-making and their\ndensity, thus providing crucial contextual information for safe\ndecision-making. Finally, we validate the effectiveness and feasibility of our\nproposed method through extensive experimental evaluations on the offline\nMuJoCo and AntMaze suites.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00503v3", "cate": "cs.LG", "date": "2025-05-01", "updated": "2025-07-08"}
{"id": "2507.05285", "title": "Beyond classical and contemporary models: a transformative ai framework for student dropout prediction in distance learning using rag, prompt engineering, and cross-modal fusion", "authors": ["Miloud Mihoubi", "Meriem Zerkouk", "Belkacem Chikhaoui"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.IR", "I.2.7; I.2.1; K.3.1"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures, 5 tables. Submitted to the 38th Canadian Conference on Artificial Intelligence (Canadian AI 2025)", "url": "http://arxiv.org/abs/2507.05285v1", "summary": "Student dropout in distance learning remains a critical challenge, with\nprofound societal and economic consequences. While classical machine learning\nmodels leverage structured socio-demographic and behavioral data, they often\nfail to capture the nuanced emotional and contextual factors embedded in\nunstructured student interactions. This paper introduces a transformative AI\nframework that redefines dropout prediction through three synergistic\ninnovations: Retrieval-Augmented Generation (RAG) for domain-specific sentiment\nanalysis, prompt engineering to decode academic stressors, and cross-modal\nattention fusion to dynamically align textual, behavioral, and\nsocio-demographic insights. By grounding sentiment analysis in a curated\nknowledge base of pedagogical content, our RAG-enhanced BERT model interprets\nstudent comments with unprecedented contextual relevance, while optimized\nprompts isolate indicators of academic distress (e.g., \"isolation,\" \"workload\nanxiety\"). A cross-modal attention layer then fuses these insights with\ntemporal engagement patterns, creating holistic risk profiles. Evaluated on a\nlongitudinal dataset of 4 423 students, the framework achieves 89% accuracy and\nan F1-score of 0.88, outperforming conventional models by 7% and reducing false\nnegatives by 21%. Beyond prediction, the system generates interpretable\ninterventions by retrieving contextually aligned strategies (e.g., mentorship\nprograms for isolated learners). This work bridges the gap between predictive\nanalytics and actionable pedagogy, offering a scalable solution to mitigate\ndropout risks in global education systems", "comment": "10 pages, 5 figures, 5 tables. Submitted to the 38th Canadian\n  Conference on Artificial Intelligence (Canadian AI 2025)", "pdf_url": "http://arxiv.org/pdf/2507.05285v1", "cate": "cs.CL", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.05874", "title": "Robust Power System State Estimation using Physics-Informed Neural Networks", "authors": ["Solon Falas", "Markos Asprou", "Charalambos Konstantinou", "Maria K. Michael"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05874v1", "summary": "Modern power systems face significant challenges in state estimation and\nreal-time monitoring, particularly regarding response speed and accuracy under\nfaulty conditions or cyber-attacks. This paper proposes a hybrid approach using\nphysics-informed neural networks (PINNs) to enhance the accuracy and\nrobustness, of power system state estimation. By embedding physical laws into\nthe neural network architecture, PINNs improve estimation accuracy for\ntransmission grid applications under both normal and faulty conditions, while\nalso showing potential in addressing security concerns such as data\nmanipulation attacks. Experimental results show that the proposed approach\noutperforms traditional machine learning models, achieving up to 83% higher\naccuracy on unseen subsets of the training dataset and 65% better performance\non entirely new, unrelated datasets. Experiments also show that during a data\nmanipulation attack against a critical bus in a system, the PINN can be up to\n93% more accurate than an equivalent neural network.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05874v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05819", "title": "2D Instance Editing in 3D Space", "authors": ["Yuhuan Xie", "Aoxuan Pan", "Ming-Xian Lin", "Wei Huang", "Yi-Hua Huang", "Xiaojuan Qi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures", "url": "http://arxiv.org/abs/2507.05819v1", "summary": "Generative models have achieved significant progress in advancing 2D image\nediting, demonstrating exceptional precision and realism. However, they often\nstruggle with consistency and object identity preservation due to their\ninherent pixel-manipulation nature. To address this limitation, we introduce a\nnovel \"2D-3D-2D\" framework. Our approach begins by lifting 2D objects into 3D\nrepresentation, enabling edits within a physically plausible,\nrigidity-constrained 3D environment. The edited 3D objects are then reprojected\nand seamlessly inpainted back into the original 2D image. In contrast to\nexisting 2D editing methods, such as DragGAN and DragDiffusion, our method\ndirectly manipulates objects in a 3D environment. Extensive experiments\nhighlight that our framework surpasses previous methods in general performance,\ndelivering highly consistent edits while robustly preserving object identity.", "comment": "8 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.05819v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05451", "title": "Self-supervised Deep Learning for Denoising in Ultrasound Microvascular Imaging", "authors": ["Lijie Huang", "Jingyi Yin", "Jingke Zhang", "U-Wai Lok", "Ryan M. DeRuiter", "Jieyang Jin", "Kate M. Knoll", "Kendra E. Petersen", "James D. Krier", "Xiang-yang Zhu", "Gina K. Hesley", "Kathryn A. Robinson", "Andrew J. Bentall", "Thomas D. Atwell", "Andrew D. Rule", "Lilach O. Lerman", "Shigao Chen", "Chengwu Huang"], "categories": ["eess.IV", "cs.CV", "eess.SP"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      12 pages, 10 figures. Supplementary materials are available at this https URL", "url": "http://arxiv.org/abs/2507.05451v1", "summary": "Ultrasound microvascular imaging (UMI) is often hindered by low\nsignal-to-noise ratio (SNR), especially in contrast-free or deep tissue\nscenarios, which impairs subsequent vascular quantification and reliable\ndisease diagnosis. To address this challenge, we propose\nHalf-Angle-to-Half-Angle (HA2HA), a self-supervised denoising framework\nspecifically designed for UMI. HA2HA constructs training pairs from\ncomplementary angular subsets of beamformed radio-frequency (RF) blood flow\ndata, across which vascular signals remain consistent while noise varies. HA2HA\nwas trained using in-vivo contrast-free pig kidney data and validated across\ndiverse datasets, including contrast-free and contrast-enhanced data from pig\nkidneys, as well as human liver and kidney. An improvement exceeding 15 dB in\nboth contrast-to-noise ratio (CNR) and SNR was observed, indicating a\nsubstantial enhancement in image quality. In addition to power Doppler imaging,\ndenoising directly in the RF domain is also beneficial for other downstream\nprocessing such as color Doppler imaging (CDI). CDI results of human liver\nderived from the HA2HA-denoised signals exhibited improved microvascular flow\nvisualization, with a suppressed noisy background. HA2HA offers a label-free,\ngeneralizable, and clinically applicable solution for robust vascular imaging\nin both contrast-free and contrast-enhanced UMI.", "comment": "12 pages, 10 figures. Supplementary materials are available at\n  https://zenodo.org/records/15832003", "pdf_url": "http://arxiv.org/pdf/2507.05451v1", "cate": "eess.IV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05910", "title": "Low voltage user phase reconfiguration as a planning problem", "authors": ["Sari Kerckhove", "Marta Vanin", "Reinhilde D'hulst", "Dirk Van Hertem"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05910v1", "summary": "Considerable levels of phase imbalance in low voltage (LV) distribution\nnetworks imply that grid assets are suboptimally utilized and can cause\nadditional losses, equipment failure and degradation. With the ongoing energy\ntransition, the installation of additional single-phase distributed energy\nresources may further increase the phase imbalance if no countermeasures are\ntaken.\n  Phase reconfiguration is a cost-effective solution to reduce imbalance.\nHowever, dynamic reconfiguration, through real-time phase swapping of loads\nusing remotely controlled switches, is often impractical because these switches\nare too costly for widespread installation at LV users. Approaching phase\nreconfiguration as a planning problem, i.e. static reconfiguration, is an\nunderaddressed but promising alternative. Effective static approaches that\nallow appropriate imbalance objectives are currently lacking.\n  This paper presents reliable and expressive static phase reconfiguration\nmethods that grid operators can easily integrate into routine maintenance for\neffective phase balancing.\n  We present and compare three static methods, an exact mixed-integer nonlinear\nformulation (MINLP), a mixed-integer quadratic approximation (MIQP), and a\ngenetic algorithm (GA), each supporting different imbalance objectives. The\nMIQP approach, despite using proxy objectives, efficiently mitigates the\ndifferent types of imbalance considered, and outperforms both MINLP and GA in\nscalability and consistency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05910v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.00209", "title": "SurgiSR4K: A High-Resolution Endoscopic Video Dataset for Robotic-Assisted Minimally Invasive Procedures", "authors": ["Fengyi Jiang", "Xiaorui Zhang", "Lingbo Jin", "Ruixing Liang", "Yuxin Chen", "Adi Chola Venkatesh", "Jason Culman", "Tiantian Wu", "Lirong Shao", "Wenqing Sun", "Cong Gao", "Hallie McNamara", "Jingpei Lu", "Omid Mohareri"], "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00209v2", "summary": "High-resolution imaging is crucial for enhancing visual clarity and enabling\nprecise computer-assisted guidance in minimally invasive surgery (MIS). Despite\nthe increasing adoption of 4K endoscopic systems, there remains a significant\ngap in publicly available native 4K datasets tailored specifically for\nrobotic-assisted MIS. We introduce SurgiSR4K, the first publicly accessible\nsurgical imaging and video dataset captured at a native 4K resolution,\nrepresenting realistic conditions of robotic-assisted procedures. SurgiSR4K\ncomprises diverse visual scenarios including specular reflections, tool\nocclusions, bleeding, and soft tissue deformations, meticulously designed to\nreflect common challenges faced during laparoscopic and robotic surgeries. This\ndataset opens up possibilities for a broad range of computer vision tasks that\nmight benefit from high resolution data, such as super resolution (SR), smoke\nremoval, surgical instrument detection, 3D tissue reconstruction, monocular\ndepth estimation, instance segmentation, novel view synthesis, and\nvision-language model (VLM) development. SurgiSR4K provides a robust foundation\nfor advancing research in high-resolution surgical imaging and fosters the\ndevelopment of intelligent imaging technologies aimed at enhancing performance,\nsafety, and usability in image-guided robotic surgeries.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00209v2", "cate": "eess.IV", "date": "2025-06-30", "updated": "2025-07-07"}
{"id": "2507.05904", "title": "Universal Embeddings of Tabular Data", "authors": ["Astrid Franz", "Frederik Hoppe", "Marianne Michaelis", "Udo Göbel"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at Tabular Data Analysis (TaDA) Workshop at VLDB 2025", "url": "http://arxiv.org/abs/2507.05904v1", "summary": "Tabular data in relational databases represents a significant portion of\nindustrial data. Hence, analyzing and interpreting tabular data is of utmost\nimportance. Application tasks on tabular data are manifold and are often not\nspecified when setting up an industrial database. To address this, we present a\nnovel framework for generating universal, i.e., task-independent embeddings of\ntabular data for performing downstream tasks without predefined targets. Our\nmethod transforms tabular data into a graph structure, leverages Graph\nAuto-Encoders to create entity embeddings, which are subsequently aggregated to\nobtain embeddings for each table row, i.e., each data sample. This two-step\napproach has the advantage that unseen samples, consisting of similar entities,\ncan be embedded without additional training. Downstream tasks such as\nregression, classification or outlier detection, can then be performed by\napplying a distance-based similarity measure in the embedding space.\nExperiments on real-world datasets demonstrate that our method achieves\nsuperior performance compared to existing universal tabular data embedding\ntechniques.", "comment": "Accepted at Tabular Data Analysis (TaDA) Workshop at VLDB 2025", "pdf_url": "http://arxiv.org/pdf/2507.05904v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05822", "title": "Video Event Reasoning and Prediction by Fusing World Knowledge from LLMs with Vision Foundation Models", "authors": ["L'ea Dubois", "Klaus Schmidt", "Chengyu Wang", "Ji-Hoon Park", "Lin Wang", "Santiago Munoz"], "categories": ["cs.CV", "CS", "I.2.10"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      22 pages, 4 figures", "url": "http://arxiv.org/abs/2507.05822v1", "summary": "Current video understanding models excel at recognizing \"what\" is happening\nbut fall short in high-level cognitive tasks like causal reasoning and future\nprediction, a limitation rooted in their lack of commonsense world knowledge.\nTo bridge this cognitive gap, we propose a novel framework that synergistically\nfuses a powerful Vision Foundation Model (VFM) for deep visual perception with\na Large Language Model (LLM) serving as a knowledge-driven reasoning core. Our\nkey technical innovation is a sophisticated fusion module, inspired by the\nQ-Former architecture, which distills complex spatiotemporal and object-centric\nvisual features into a concise, language-aligned representation. This enables\nthe LLM to effectively ground its inferential processes in direct visual\nevidence. The model is trained via a two-stage strategy, beginning with\nlarge-scale alignment pre-training on video-text data, followed by targeted\ninstruction fine-tuning on a curated dataset designed to elicit advanced\nreasoning and prediction skills. Extensive experiments demonstrate that our\nmodel achieves state-of-the-art performance on multiple challenging benchmarks.\nNotably, it exhibits remarkable zero-shot generalization to unseen reasoning\ntasks, and our in-depth ablation studies validate the critical contribution of\neach architectural component. This work pushes the boundary of machine\nperception from simple recognition towards genuine cognitive understanding,\npaving the way for more intelligent and capable AI systems in robotics,\nhuman-computer interaction, and beyond.", "comment": "22 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.05822v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05967", "title": "Optimal Placement of Smart Hybrid Transformers in Distribution Networks", "authors": ["Samuel Hayward", "Martin Doff-Sotta", "Michael Merlin", "Matthew Williams", "Thomas Morstyn"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05967v1", "summary": "Hybrid transformers are a relatively new technology that combine conventional\npower transformers with power electronics to provide voltage and reactive power\ncontrol capabilities in distribution networks. This paper proposes a novel\nmethod of determining the optimal location and utilisation of hybrid\ntransformers in 3-phase distribution networks to maximise the net present value\nof hybrid transformers based on their ability to increase the export of power\nproduced by distributed generators over their operational lifespan. This has\nbeen accomplished through sequential linear programming, a key feature of which\nis the consideration of nonlinear characteristics and constraints relating to\nhybrid transformer power electronics and control capabilities. Test cases were\ncarried out in a modified version of the Cigre European Low Voltage\nDistribution Network Benchmark, which has been extended by connecting it with\ntwo additional low voltage distribution test networks. All test case results\ndemonstrate that the installation and utilisation of hybrid transformers can\nimprove the income earned from exporting excess active power, justifying their\ninstallation cost (with the highest net present value being {\\pounds}6.56\nmillion, resulting from a 45.53 percent increase in estimated annual profits\ndue to coordinated HT compensation).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05967v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05582", "title": "Learning Segmentation from Radiology Reports", "authors": ["Pedro R. A. S. Bassi", "Wenxuan Li", "Jieneng Chen", "Zheren Zhu", "Tianyu Lin", "Sergio Decherchi", "Andrea Cavalli", "Kang Wang", "Yang Yang", "Alan L. Yuille", "Zongwei Zhou"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted to MICCAI 2025", "url": "http://arxiv.org/abs/2507.05582v1", "summary": "Tumor segmentation in CT scans is key for diagnosis, surgery, and prognosis,\nyet segmentation masks are scarce because their creation requires time and\nexpertise. Public abdominal CT datasets have from dozens to a couple thousand\ntumor masks, but hospitals have hundreds of thousands of tumor CTs with\nradiology reports. Thus, leveraging reports to improve segmentation is key for\nscaling. In this paper, we propose a report-supervision loss (R-Super) that\nconverts radiology reports into voxel-wise supervision for tumor segmentation\nAI. We created a dataset with 6,718 CT-Report pairs (from the UCSF Hospital),\nand merged it with public CT-Mask datasets (from AbdomenAtlas 2.0). We used our\nR-Super to train with these masks and reports, and strongly improved tumor\nsegmentation in internal and external validation--F1 Score increased by up to\n16% with respect to training with masks only. By leveraging readily available\nradiology reports to supplement scarce segmentation masks, R-Super strongly\nimproves AI performance both when very few training masks are available (e.g.,\n50), and when many masks were available (e.g., 1.7K).\n  Project: https://github.com/MrGiovanni/R-Super", "comment": "Accepted to MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.05582v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05288", "title": "A Survey on Proactive Defense Strategies Against Misinformation in Large Language Models", "authors": ["Shuliang Liu", "Hongyi Liu", "Aiwei Liu", "Bingchen Duan", "Qi Zheng", "Yibo Yan", "He Geng", "Peijie Jiang", "Jia Liu", "Xuming Hu"], "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted by ACL 2025 Findings", "url": "http://arxiv.org/abs/2507.05288v1", "summary": "The widespread deployment of large language models (LLMs) across critical\ndomains has amplified the societal risks posed by algorithmically generated\nmisinformation. Unlike traditional false content, LLM-generated misinformation\ncan be self-reinforcing, highly plausible, and capable of rapid propagation\nacross multiple languages, which traditional detection methods fail to mitigate\neffectively. This paper introduces a proactive defense paradigm, shifting from\npassive post hoc detection to anticipatory mitigation strategies. We propose a\nThree Pillars framework: (1) Knowledge Credibility, fortifying the integrity of\ntraining and deployed data; (2) Inference Reliability, embedding\nself-corrective mechanisms during reasoning; and (3) Input Robustness,\nenhancing the resilience of model interfaces against adversarial attacks.\nThrough a comprehensive survey of existing techniques and a comparative\nmeta-analysis, we demonstrate that proactive defense strategies offer up to\n63\\% improvement over conventional methods in misinformation prevention,\ndespite non-trivial computational overhead and generalization challenges. We\nargue that future research should focus on co-designing robust knowledge\nfoundations, reasoning certification, and attack-resistant interfaces to ensure\nLLMs can effectively counter misinformation across varied domains.", "comment": "Accepted by ACL 2025 Findings", "pdf_url": "http://arxiv.org/pdf/2507.05288v1", "cate": "cs.IR", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.05838", "title": "I$^2$R: Inter and Intra-image Refinement in Few Shot Segmentation", "authors": ["Ourui Fu", "Hangzhou He", "Xinliang Zhang", "Lei Zhu", "Shuang Zeng", "ZhaoHeng Xie", "Yanye Lu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05838v1", "summary": "The annotation bottleneck in semantic segmentation has driven significant\ninterest in few-shot segmentation, which aims to develop segmentation models\ncapable of generalizing rapidly to novel classes using minimal exemplars.\nConventional training paradigms typically generate query prior maps by\nextracting masked-area features from support images, followed by making\npredictions guided by these prior maps. However, current approaches remain\nconstrained by two critical limitations stemming from inter- and intra-image\ndiscrepancies, both of which significantly degrade segmentation performance: 1)\nThe semantic gap between support and query images results in mismatched\nfeatures and inaccurate prior maps; 2) Visually similar yet semantically\ndistinct regions within support or query images lead to false negative or false\npositive predictions. We propose a novel FSS method called \\textbf{I$^2$R}: 1)\nUsing category-specific high level representations which aggregate global\nsemantic cues from support and query images, enabling more precise inter-image\nregion localization and address the first limitation. 2) Directional masking\nstrategy that suppresses inconsistent support-query pixel pairs, which exhibit\nhigh feature similarity but conflicting mask, to mitigate the second issue.\nExperiments demonstrate that our method outperforms state-of-the-art\napproaches, achieving improvements of 1.9\\% and 2.1\\% in mIoU under the 1-shot\nsetting on PASCAL-5$^i$ and COCO-20$^i$ benchmarks, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05838v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05635", "title": "Frequency-Specific Neural Response and Cross-Correlation Analysis of Envelope Following Responses to Native Speech and Music Using Multichannel EEG Signals: A Case Study", "authors": ["Md. Mahbub Hasan", "Md Rakibul Hasan", "Md Zakir Hossain", "Tom Gedeon"], "categories": ["eess.AS", "cs.SD", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05635v1", "summary": "Although native speech and music envelope following responses (EFRs) play a\ncrucial role in auditory processing and cognition, their frequency profile,\nsuch as the dominating frequency and spectral coherence, is largely unknown. We\nhave assumed that the auditory pathway - which transmits envelope components of\nspeech and music to the scalp through time-varying neurophysiological processes\n- is a linear time-varying system, with the envelope and the multi-channel EEG\nresponses as excitation and response, respectively. This paper investigates the\ntransfer function of this system through two analytical techniques -\ntime-averaged spectral responses and cross-spectral density - in the frequency\ndomain at four different positions of the human scalp. Our findings suggest\nthat alpha (8-11 Hz), lower gamma (53-56 Hz), and higher gamma (78-81 Hz) bands\nare the peak responses of the system. These frequently appearing dominant\nfrequency responses may be the key components of familiar speech perception,\nmaintaining attention, binding acoustic features, and memory processing. The\ncross-spectral density, which reflects the spatial neural coherence of the\nhuman brain, shows that 10-13 Hz, 27-29 Hz, and 62-64 Hz are common for all\nchannel pairs. As neural coherences are frequently observed in these\nfrequencies among native participants, we suggest that these distributed neural\nprocesses are also dominant in native speech and music perception.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05635v1", "cate": "eess.AS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05268", "title": "Cross-Subject DD: A Cross-Subject Brain-Computer Interface Algorithm", "authors": ["Xiaoyuan Li", "Xinru Xue", "Bohan Zhang", "Ye Sun", "Shoushuo Xi", "Gang Liu"], "categories": ["q-bio.NC", "cs.CV", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "Comments:      20 pages, 9 figures", "url": "http://arxiv.org/abs/2507.05268v1", "summary": "Brain-computer interface (BCI) based on motor imagery (MI) enables direct\ncontrol of external devices by decoding the electroencephalogram (EEG)\ngenerated in the brain during imagined movements. However, due to\ninter-individual variability in brain activity, existing BCI models exhibit\npoor adaptability across subjects, thereby limiting their generalizability and\nwidespread application. To address this issue, this paper proposes a\ncross-subject BCI algorithm named Cross-Subject DD (CSDD), which constructs a\nuniversal BCI model by extracting common features across subjects. The specific\nmethods include: 1) training personalized models for each subject; 2)\ntransforming personalized models into relation spectrums; 3) identifying common\nfeatures through statistical analysis; and 4) constructing a cross-subject\nuniversal model based on common features. The experiments utilized the BCIC IV\n2a dataset, involving nine subjects. Eight of these subjects were selected for\ntraining and extracing the common features, and the cross-subject decoding\nperformance of the model was validated on the remaining subject. The results\ndemonstrate that, compared with existing similar methods, our approach achieves\na 3.28% improvement in performance. This paper introduces for the first time a\nnovel method for extracting pure common features and constructing a universal\ncross-subject BCI model, thereby facilitating broader applications of BCI\ntechnology.", "comment": "20 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.05268v1", "cate": "q-bio.NC", "date": "2025-07-02", "updated": "2025-07-02"}
{"id": "2507.05396", "title": "Comparative Analysis of Finite Difference and Finite Element Method for Audio Waveform Simulation", "authors": ["Juliette Florin"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      46 pages, 38 figures, Link to the source code: this https URL", "url": "http://arxiv.org/abs/2507.05396v1", "summary": "In many industries, including aerospace and defense, waveform analysis is\ncommonly conducted to compute the resonance of physical objects, with the\nFinite Element Method (FEM) being the standard approach. The Finite Difference\nMethod (FDM) is seldom used, and this preference is often stated without formal\njustification in the literature. In this work, the accuracy, feasibility, and\ntime of simulation of FEM and FDM are compared by simulating the vibration of a\nguitar string. Python simulations for both methods are implemented, and their\nresults are compared against analytical solutions and experimental data.\nAdditionally, FDM is applied to analyze the sound of a cycling bell to assess\nits reliability compared to a real cycling bell. Final results show that both\nFEM and FDM yield similar error margins and accurately predict the system's\nbehavior. Moreover, the errors from FEM and FDM follow the same periodicity\nwith a phase shift when varying the assumed analytical tension and without a\nphase shift when changing the time interval. However, FEM converges faster with\nincreasing mesh complexity, whereas FDM demonstrates quicker computational\nperformance and achieves stable solutions even with bigger time intervals.\nDespite this FDM is limited to simpler configurations and often demands\nextensive mathematical formulation, which can become cumbersome for intricate\nshapes. For example, modeling a hemispherical object using FDM results in\nsignificant simulation times and big calculations. In conclusion, while FDM may\noffer faster convergence and computation time in certain cases, FEM remains the\npreferred method in industrial contexts due to its flexibility, scalability,\nand ease of implementation for complex geometries.", "comment": "46 pages, 38 figures, Link to the source code:\n  https://gitlab.eurecom.fr/florin/models", "pdf_url": "http://arxiv.org/pdf/2507.05396v1", "cate": "eess.AS", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05647", "title": "Diffusion-Based Limited-Angle CT Reconstruction under Noisy Conditions", "authors": ["Jiaqi Guo", "Santiago López-Tapia"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted at the 2025 IEEE International Conference on Image Processing (ICIP), Workshop", "url": "http://arxiv.org/abs/2507.05647v1", "summary": "Limited-Angle Computed Tomography (LACT) is a challenging inverse problem\nwhere missing angular projections lead to incomplete sinograms and severe\nartifacts in the reconstructed images. While recent learning-based methods have\ndemonstrated effectiveness, most of them assume ideal, noise-free measurements\nand fail to address the impact of measurement noise. To overcome this\nlimitation, we treat LACT as a sinogram inpainting task and propose a\ndiffusion-based framework that completes missing angular views using a\nMean-Reverting Stochastic Differential Equation (MR-SDE) formulation. To\nimprove robustness under realistic noise, we propose RNSD$^+$, a novel\nnoise-aware rectification mechanism that explicitly models inference-time\nuncertainty, enabling reliable and robust reconstruction. Extensive experiments\ndemonstrate that our method consistently surpasses baseline models in data\nconsistency and perceptual quality, and generalizes well across varying noise\nintensity and acquisition scenarios.", "comment": "Accepted at the 2025 IEEE International Conference on Image\n  Processing (ICIP), Workshop", "pdf_url": "http://arxiv.org/pdf/2507.05647v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05914", "title": "Diffusion Dataset Condensation: Training Your Diffusion Model Faster with Less Data", "authors": ["Rui Huang", "Shitong Shao", "Zikai Zhou", "Pukun Zhao", "Hangyu Guo", "Tian Ye", "Lichen Bai", "Shuo Yang", "Zeke Xie"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Iintroduces D2C: a novel framework for diffusion dataset condensation", "url": "http://arxiv.org/abs/2507.05914v1", "summary": "Diffusion models have achieved remarkable success in various generative\ntasks, but training them remains highly resource-intensive, often requiring\nmillions of images and many days of GPU computation. From a data-centric\nperspective addressing this limitation, we study diffusion dataset condensation\nas a new and challenging problem setting. The goal is to construct a\n\"synthetic\" sub-dataset with significantly fewer samples than the original\ndataset, enabling high-quality diffusion model training with greatly reduced\ncost. To the best of our knowledge, we are the first to formally investigate\ndataset condensation for diffusion models, whereas prior work focused on\ntraining discriminative models. To tackle this new challenge, we propose a\nnovel Diffusion Dataset Condensation (D2C) framework, which consists of two\nphases: Select and Attach. The Select phase identifies a compact and diverse\nsubset using a diffusion difficulty score and interval sampling. The Attach\nphase enhances the selected subset by attaching rich semantic and visual\nrepresentations to strengthen the conditional signals. Extensive experiments\nacross various dataset sizes, model architectures, and resolutions show that\nour D2C framework enables significantly faster diffusion model training with\ndramatically fewer data, while preserving high visual quality. Notably, for the\nSiT-XL/2 architecture, D2C achieves a 100x training speed-up, reaching a FID\nscore of 4.3 in just 40k steps using only 0.8% of the training data.", "comment": "Iintroduces D2C: a novel framework for diffusion dataset condensation", "pdf_url": "http://arxiv.org/pdf/2507.05914v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05843", "title": "USIGAN: Unbalanced Self-Information Feature Transport for Weakly Paired Image IHC Virtual Staining", "authors": ["Yue Peng", "Bing Xiong", "Fuqiang Chen", "De Eybo", "RanRan Zhang", "Wanming Hu", "Jing Cai", "Wenjian Qin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05843v1", "summary": "Immunohistochemical (IHC) virtual staining is a task that generates virtual\nIHC images from H\\&E images while maintaining pathological semantic consistency\nwith adjacent slices. This task aims to achieve cross-domain mapping between\nmorphological structures and staining patterns through generative models,\nproviding an efficient and cost-effective solution for pathological analysis.\nHowever, under weakly paired conditions, spatial heterogeneity between adjacent\nslices presents significant challenges. This can lead to inaccurate one-to-many\nmappings and generate results that are inconsistent with the pathological\nsemantics of adjacent slices. To address this issue, we propose a novel\nunbalanced self-information feature transport for IHC virtual staining, named\nUSIGAN, which extracts global morphological semantics without relying on\npositional correspondence.By removing weakly paired terms in the joint marginal\ndistribution, we effectively mitigate the impact of weak pairing on joint\ndistributions, thereby significantly improving the content consistency and\npathological semantic consistency of the generated results. Moreover, we design\nthe Unbalanced Optimal Transport Consistency (UOT-CTM) mechanism and the\nPathology Self-Correspondence (PC-SCM) mechanism to construct correlation\nmatrices between H\\&E and generated IHC in image-level and real IHC and\ngenerated IHC image sets in intra-group level.. Experiments conducted on two\npublicly available datasets demonstrate that our method achieves superior\nperformance across multiple clinically significant metrics, such as IoD and\nPearson-R correlation, demonstrating better clinical relevance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05843v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05399", "title": "Sample Rate Offset Compensated Acoustic Echo Cancellation For Multi-Device Scenarios", "authors": ["Srikanth Korse", "Oliver Thiergart", "Emanuel A. P. Habets"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Published in IWAENC 2024", "url": "http://arxiv.org/abs/2507.05399v1", "summary": "Acoustic echo cancellation (AEC) in multi-device scenarios is a challenging\nproblem due to sample rate offset (SRO) between devices. The SRO hinders the\nconvergence of the AEC filter, diminishing its performance. To address this ,\nwe approach the multi-device AEC scenario as a multi-channel AEC problem\ninvolving a multi-channel Kalman filter, SRO estimation, and resampling of\nfar-end signals. Experiments in a two-device scenario show that our system\nmitigates the divergence of the multi-channel Kalman filter in the presence of\nSRO for both correlated and uncorrelated playback signals during echo-only and\ndouble-talk. Additionally, for devices with correlated playback signals, an\nindependent single-channel AEC filter is crucial to ensure fast convergence of\nSRO estimation.", "comment": "Published in IWAENC 2024", "pdf_url": "http://arxiv.org/pdf/2507.05399v1", "cate": "eess.AS", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05656", "title": "ADPv2: A Hierarchical Histological Tissue Type-Annotated Dataset for Potential Biomarker Discovery of Colorectal Disease", "authors": ["Zhiyuan Yang", "Kai Li", "Sophia Ghamoshi Ramandi", "Patricia Brassard", "Hakim Khellaf", "Vincent Quoc-Huy Trinh", "Jennifer Zhang", "Lina Chen", "Corwyn Rowsell", "Sonal Varma", "Kostas Plataniotis", "Mahdi S. Hosseini"], "categories": ["eess.IV", "cs.CV", "cs.LG", "q-bio.QM", "I.2.10; I.2.1"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05656v1", "summary": "Computational pathology (CoPath) leverages histopathology images to enhance\ndiagnostic precision and reproducibility in clinical pathology. However,\npublicly available datasets for CoPath that are annotated with extensive\nhistological tissue type (HTT) taxonomies at a granular level remain scarce due\nto the significant expertise and high annotation costs required. Existing\ndatasets, such as the Atlas of Digital Pathology (ADP), address this by\noffering diverse HTT annotations generalized to multiple organs, but limit the\ncapability for in-depth studies on specific organ diseases. Building upon this\nfoundation, we introduce ADPv2, a novel dataset focused on gastrointestinal\nhistopathology. Our dataset comprises 20,004 image patches derived from healthy\ncolon biopsy slides, annotated according to a hierarchical taxonomy of 32\ndistinct HTTs of 3 levels. Furthermore, we train a multilabel representation\nlearning model following a two-stage training procedure on our ADPv2 dataset.\nWe leverage the VMamba architecture and achieving a mean average precision\n(mAP) of 0.88 in multilabel classification of colon HTTs. Finally, we show that\nour dataset is capable of an organ-specific in-depth study for potential\nbiomarker discovery by analyzing the model's prediction behavior on tissues\naffected by different colon diseases, which reveals statistical patterns that\nconfirm the two pathological pathways of colon cancer development. Our dataset\nis publicly available here: Part 1 at https://zenodo.org/records/15307021, Part\n2 at https://zenodo.org/records/15312384 and Part 3 at\nhttps://zenodo.org/records/15312792", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05656v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05295", "title": "Enhancing Learning Path Recommendation via Multi-task Learning", "authors": ["Afsana Nasrin", "Lijun Qian", "Pamela Obiomon", "Xishuang Dong"], "categories": ["cs.IR", "cs.AI", "cs.CY", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05295v1", "summary": "Personalized learning is a student-centered educational approach that adapts\ncontent, pace, and assessment to meet each learner's unique needs. As the key\ntechnique to implement the personalized learning, learning path recommendation\nsequentially recommends personalized learning items such as lectures and\nexercises. Advances in deep learning, particularly deep reinforcement learning,\nhave made modeling such recommendations more practical and effective. This\npaper proposes a multi-task LSTM model that enhances learning path\nrecommendation by leveraging shared information across tasks. The approach\nreframes learning path recommendation as a sequence-to-sequence (Seq2Seq)\nprediction problem, generating personalized learning paths from a learner's\nhistorical interactions. The model uses a shared LSTM layer to capture common\nfeatures for both learning path recommendation and deep knowledge tracing,\nalong with task-specific LSTM layers for each objective. To avoid redundant\nrecommendations, a non-repeat loss penalizes repeated items within the\nrecommended learning path. Experiments on the ASSIST09 dataset show that the\nproposed model significantly outperforms baseline methods for the learning path\nrecommendation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05295v1", "cate": "cs.IR", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.05950", "title": "Improving AI-Based Canine Heart Disease Diagnosis with Expert-Consensus Auscultation Labeling", "authors": ["Pinar Bisgin", "Tom Strube", "Niklas Tschorn", "Michael Pantförder", "Maximilian Fecke", "Ingrid Ljungvall", "Jens Häggström", "Gerhard Wess", "Christoph Schummer", "Sven Meister", "Falk M. Howar"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE Engineering in Medicine and Biology Conference (EMBC) 2025", "url": "http://arxiv.org/abs/2507.05950v1", "summary": "Noisy labels pose significant challenges for AI model training in veterinary\nmedicine. This study examines expert assessment ambiguity in canine\nauscultation data, highlights the negative impact of label noise on\nclassification performance, and introduces methods for label noise reduction.\nTo evaluate whether label noise can be minimized by incorporating multiple\nexpert opinions, a dataset of 140 heart sound recordings (HSR) was annotated\nregarding the intensity of holosystolic heart murmurs caused by Myxomatous\nMitral Valve Disease (MMVD). The expert opinions facilitated the selection of\n70 high-quality HSR, resulting in a noise-reduced dataset. By leveraging\nindividual heart cycles, the training data was expanded and classification\nrobustness was enhanced. The investigation encompassed training and evaluating\nthree classification algorithms: AdaBoost, XGBoost, and Random Forest. While\nAdaBoost and Random Forest exhibited reasonable performances, XGBoost\ndemonstrated notable improvements in classification accuracy. All algorithms\nshowed significant improvements in classification accuracy due to the applied\nlabel noise reduction, most notably XGBoost. Specifically, for the detection of\nmild heart murmurs, sensitivity increased from 37.71% to 90.98% and specificity\nfrom 76.70% to 93.69%. For the moderate category, sensitivity rose from 30.23%\nto 55.81% and specificity from 64.56% to 97.19%. In the loud/thrilling\ncategory, sensitivity and specificity increased from 58.28% to 95.09% and from\n84.84% to 89.69%, respectively. These results highlight the importance of\nminimizing label noise to improve classification algorithms for the detection\nof canine heart murmurs. Index Terms: AI diagnosis, canine heart disease, heart\nsound classification, label noise reduction, machine learning, XGBoost,\nveterinary cardiology, MMVD.", "comment": "Accepted to IEEE Engineering in Medicine and Biology Conference\n  (EMBC) 2025", "pdf_url": "http://arxiv.org/pdf/2507.05950v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05849", "title": "DFYP: A Dynamic Fusion Framework with Spectral Channel Attention and Adaptive Operator learning for Crop Yield Prediction", "authors": ["Juli Zhang", "Zeyu Yan", "Jing Zhang", "Qiguang Miao", "Quan Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      16 pages", "url": "http://arxiv.org/abs/2507.05849v1", "summary": "Accurate remote sensing-based crop yield prediction remains a fundamental\nchallenging task due to complex spatial patterns, heterogeneous spectral\ncharacteristics, and dynamic agricultural conditions. Existing methods often\nsuffer from limited spatial modeling capacity, weak generalization across crop\ntypes and years. To address these challenges, we propose DFYP, a novel Dynamic\nFusion framework for crop Yield Prediction, which combines spectral channel\nattention, edge-adaptive spatial modeling and a learnable fusion mechanism to\nimprove robustness across diverse agricultural scenarios. Specifically, DFYP\nintroduces three key components: (1) a Resolution-aware Channel Attention (RCA)\nmodule that enhances spectral representation by adaptively reweighting input\nchannels based on resolution-specific characteristics; (2) an Adaptive Operator\nLearning Network (AOL-Net) that dynamically selects operators for convolutional\nkernels to improve edge-sensitive spatial feature extraction under varying crop\nand temporal conditions; and (3) a dual-branch architecture with a learnable\nfusion mechanism, which jointly models local spatial details and global\ncontextual information to support cross-resolution and cross-crop\ngeneralization. Extensive experiments on multi-year datasets MODIS and\nmulti-crop dataset Sentinel-2 demonstrate that DFYP consistently outperforms\ncurrent state-of-the-art baselines in RMSE, MAE, and R2 across different\nspatial resolutions, crop types, and time periods, showcasing its effectiveness\nand robustness for real-world agricultural monitoring.", "comment": "16 pages", "pdf_url": "http://arxiv.org/pdf/2507.05849v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06051", "title": "Experimental Investigation of Availability in a 4.6 km Terrestrial Urban Coherent Free-Space Optical Communications Link", "authors": ["Vincent van Vliet", "Menno van den Hout", "Kadir Gümüş", "Eduward Tangdiongga", "Chigo Okonkwo"], "categories": ["physics.optics", "eess.SP"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at European Conference on Optical Communications (ECOC) 2025", "url": "http://arxiv.org/abs/2507.06051v1", "summary": "We measured the outage probability of a 4.6-km urban free-space optical\ncommunication link over six days. High-speed power measurements reveal slow and\nfast fading effects, with link availabilities of 92% including and 99%\nexcluding slow fades for 500 Gb/s transmission.", "comment": "Accepted for presentation at European Conference on Optical\n  Communications (ECOC) 2025", "pdf_url": "http://arxiv.org/pdf/2507.06051v1", "cate": "physics.optics", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05402", "title": "Stereo Reproduction in the Presence of Sample Rate Offsets", "authors": ["Srikanth Korse", "Andreas Walther", "Emanuel A. P. Habets"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted to WASPAA 2025", "url": "http://arxiv.org/abs/2507.05402v1", "summary": "One of the main challenges in synchronizing wirelessly connected loudspeakers\nfor spatial audio reproduction is clock skew. Clock skew arises from sample\nrate offsets ( SROs) between the loudspeakers, caused by the use of independent\ndevice clocks. While network-based protocols like Precision Time Protocol (PTP)\nand Network Time Protocol (NTP) are explored, the impact of SROs on spatial\naudio reproduction and its perceptual consequences remains underexplored. We\npropose an audio-domain SRO compensation method using spatial filtering to\nisolate loudspeaker contributions. These filtered signals, along with the\noriginal playback signal, are used to estimate the SROs, and their influence is\ncompensated for prior to spatial audio reproduction. We evaluate the effect of\nthe compensation method in a subjective listening test. The results of these\ntests as well as objective metrics demonstrate that the proposed method\nmitigates the perceptual degradation introduced by SROs by preserving the\nspatial cues.", "comment": "Accepted to WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.05402v1", "cate": "eess.AS", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05742", "title": "Tissue Concepts v2: a Supervised Foundation Model for whole slide images", "authors": ["Till Nicke", "Daniela Scharcherer", "Jan Raphael Schäfer", "Natalia Artysh", "Antje Prasse", "André Homeyer", "Andrea Schenk", "Henning Höfener", "Johannes Lotz"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05742v1", "summary": "Foundation models (FMs) are transforming the field of computational pathology\nby offering new approaches to analyzing histopathology images. Typically\nrelying on weeks of training on large databases, the creation of FMs is a\nresource-intensive process in many ways. In this paper, we introduce the\nextension of our supervised foundation model, Tissue Concepts, to whole slide\nimages, called Tissue Concepts v2 (TCv2), a supervised foundation model for\nwhole slide images to address the issue above. TCv2 uses supervised, end-to-end\nmultitask learning on slide-level labels. Training TCv2 uses a fraction of the\ntraining resources compared to self-supervised training. The presented model\nshows superior performance compared to SSL-trained models in cancer subtyping\nbenchmarks and is fully trained on freely available data. Furthermore, a shared\ntrained attention module provides an additional layer of explainability across\ndifferent tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05742v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05296", "title": "Integrating Generative AI in BIM Education: Insights from Classroom Implementation", "authors": ["Islem Sahraoui", "Kinam Kim", "Lu Gao", "Zia Din", "Ahmed Senouci"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05296v1", "summary": "This study evaluates the implementation of a Generative AI-powered rule\nchecking workflow within a graduate-level Building Information Modeling (BIM)\ncourse at a U.S. university. Over two semesters, 55 students participated in a\nclassroom-based pilot exploring the use of GenAI for BIM compliance tasks, an\narea with limited prior research. The instructional design included lectures on\nprompt engineering and AI-driven rule checking, followed by an assignment where\nstudents used a large language model (LLM) to identify code violations in\ndesigns using Autodesk Revit. Surveys and interviews were conducted to assess\nstudent workload, learning effectiveness, and overall experience, using the\nNASA-TLX scale and regression analysis. Findings indicate students generally\nachieved learning objectives but faced challenges such as difficulties\ndebugging AI-generated code and inconsistent tool performance, probably due to\ntheir limited prompt engineering experience. These issues increased cognitive\nand emotional strain, especially among students with minimal programming\nbackgrounds. Despite these challenges, students expressed strong interest in\nfuture GenAI applications, particularly with clear instructional support.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05296v1", "cate": "cs.CY", "date": "2025-07-06", "updated": "2025-07-06"}
{"id": "2507.05966", "title": "Simple Convergence Proof of Adam From a Sign-like Descent Perspective", "authors": ["Hanyang Peng", "Shuang Qin", "Yue Yu", "Fangqing Jiang", "Hui Wang", "Zhouchen Lin"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      23 pages, 2figures", "url": "http://arxiv.org/abs/2507.05966v1", "summary": "Adam is widely recognized as one of the most effective optimizers for\ntraining deep neural networks (DNNs). Despite its remarkable empirical success,\nits theoretical convergence analysis remains unsatisfactory. Existing works\npredominantly interpret Adam as a preconditioned stochastic gradient descent\nwith momentum (SGDM), formulated as $\\bm{x}_{t+1} = \\bm{x}_t -\n\\frac{\\gamma_t}{{\\sqrt{\\bm{v}_t}+\\epsilon}} \\circ \\bm{m}_t$. This perspective\nnecessitates strong assumptions and intricate techniques, resulting in lengthy\nand opaque convergence proofs that are difficult to verify and extend. In\ncontrast, we propose a novel interpretation by treating Adam as a sign-like\noptimizer, expressed as $\\bm{x}_{t+1} = \\bm{x}_t - \\gamma_t\n\\frac{|\\bm{m}_t|}{{\\sqrt{\\bm{v}_t}+\\epsilon}} \\circ {\\rm Sign}(\\bm{m}_t)$. This\nreformulation significantly simplifies the convergence analysis. For the first\ntime, with some mild conditions, we prove that Adam achieves the optimal rate\nof ${\\cal O}(\\frac{1}{T^{\\sfrac{1}{4}}})$ rather than the previous ${\\cal O}\n\\left(\\frac{\\ln T}{T^{\\sfrac{1}{4}}}\\right)$ under weak assumptions of the\ngeneralized $p$-affine variance and $(L_0, L_1, q)$-smoothness, without\ndependence on the model dimensionality or the numerical stability parameter\n$\\epsilon$. Additionally, our theoretical analysis provides new insights into\nthe role of momentum as a key factor ensuring convergence and offers practical\nguidelines for tuning learning rates in Adam, further bridging the gap between\ntheory and practice.", "comment": "23 pages, 2figures", "pdf_url": "http://arxiv.org/pdf/2507.05966v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05859", "title": "D-FCGS: Feedforward Compression of Dynamic Gaussian Splatting for Free-Viewpoint Videos", "authors": ["Wenkang Zhang", "Yan Zhao", "Qiang Wang", "Li Song", "Zhengxue Cheng"], "categories": ["cs.CV", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 9 figures, 8 tables", "url": "http://arxiv.org/abs/2507.05859v1", "summary": "Free-viewpoint video (FVV) enables immersive 3D experiences, but efficient\ncompression of dynamic 3D representations remains a major challenge. Recent\nadvances in 3D Gaussian Splatting (3DGS) and its dynamic extensions have\nenabled high-fidelity scene modeling. However, existing methods often couple\nscene reconstruction with optimization-dependent coding, which limits\ngeneralizability. This paper presents Feedforward Compression of Dynamic\nGaussian Splatting (D-FCGS), a novel feedforward framework for compressing\ntemporally correlated Gaussian point cloud sequences. Our approach introduces a\nGroup-of-Frames (GoF) structure with I-P frame coding, where inter-frame\nmotions are extracted via sparse control points. The resulting motion tensors\nare compressed in a feedforward manner using a dual prior-aware entropy model\nthat combines hyperprior and spatial-temporal priors for accurate rate\nestimation. For reconstruction, we perform control-point-guided motion\ncompensation and employ a refinement network to enhance view-consistent\nfidelity. Trained on multi-view video-derived Gaussian frames, D-FCGS\ngeneralizes across scenes without per-scene optimization. Experiments show that\nit matches the rate-distortion performance of optimization-based methods,\nachieving over 40 times compression in under 2 seconds while preserving visual\nquality across viewpoints. This work advances feedforward compression for\ndynamic 3DGS, paving the way for scalable FVV transmission and storage in\nimmersive applications.", "comment": "12 pages, 9 figures, 8 tables", "pdf_url": "http://arxiv.org/pdf/2507.05859v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2309.02901", "title": "Bi-Linear Homogeneity Enforced Calibration for Pipelined ADCs", "authors": ["Matthias Wagner", "Oliver Lang", "Esmaeil Kavousi Ghafi", "Arianit Preniqi", "Andreas Schwarz", "Mario Huemer"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      18 pages, 13 figures", "url": "http://arxiv.org/abs/2309.02901v3", "summary": "Pipelined analog-to-digital converters (ADCs) are key enablers in many\nstate-of-the-art signal processing systems with high sampling rates. In\naddition to high sampling rates, such systems often demand a high linearity. To\nmeet these challenging linearity requirements, ADC calibration techniques were\nheavily investigated throughout the past decades. One limitation in ADC\ncalibration is the need for a precisely known test signal. In our previous\nwork, we proposed the homogeneity enforced calibration (HEC) approach, which\ncircumvents this need by consecutively feeding a test signal and a scaled\nversion of it into the ADC. The calibration itself is performed using only the\ncorresponding output samples, such that the test signal can remain unknown. On\nthe downside, the HEC approach requires to accurately scale the test signal,\nimpeding an on-chip implementation. In this work, we provide a thorough\nanalysis of the HEC approach, including limitations such as the effects of an\ninaccurately scaled test signal. Furthermore, the bi-linear homogeneity\nenforced calibration (BL-HEC) approach is introduced and suggested to account\nfor an inaccurate scaling and, therefore, to facilitate an on-chip\nimplementation. In addition, a comprehensive stability analysis of the BL-HEC\napproach is carried out. Finally, we verify our concept with behavioral Matlab\nsimulations and measurements conducted on 24 integrated ADCs.", "comment": "18 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2309.02901v3", "cate": "eess.SP", "date": "2023-09-06", "updated": "2025-07-08"}
{"id": "2507.05409", "title": "Parametric Object Coding in IVAS: Efficient Coding of Multiple Audio Objects at Low Bit Rates", "authors": ["Andrea Eichenseer", "Srikanth Korse", "Guillaume Fuchs", "Markus Multrus"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Published in ICASSP 2025", "url": "http://arxiv.org/abs/2507.05409v1", "summary": "The recently standardized 3GPP codec for Immersive Voice and Audio Services\n(IVAS) includes a parametric mode for efficiently coding multiple audio objects\nat low bit rates. In this mode, parametric side information is obtained from\nboth the object metadata and the input audio objects. The side information\ncomprises directional information, indices of two dominant objects, and the\npower ratio between these two dominant objects. It is transmitted to the\ndecoder along with a stereo downmix. In IVAS, parametric object coding allows\nfor transmitting three or four arbitrarily placed objects at bit rates of 24.4\nor 32 kbit/s and faithfully reconstructing the spatial image of the original\naudio scene. Subjective listening tests confirm that IVAS provides a comparable\nimmersive experience at lower bit rate and complexity compared to coding the\naudio objects independently using Enhanced Voice Services (EVS).", "comment": "Published in ICASSP 2025", "pdf_url": "http://arxiv.org/pdf/2507.05409v1", "cate": "eess.AS", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05764", "title": "PSAT: Pediatric Segmentation Approaches via Adult Augmentations and Transfer Learning", "authors": ["Tristan Kirscher", "Sylvain Faisan", "Xavier Coubez", "Loris Barrier", "Philippe Meyer"], "categories": ["eess.IV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05764v1", "summary": "Pediatric medical imaging presents unique challenges due to significant\nanatomical and developmental differences compared to adults. Direct application\nof segmentation models trained on adult data often yields suboptimal\nperformance, particularly for small or rapidly evolving structures. To address\nthese challenges, several strategies leveraging the nnU-Net framework have been\nproposed, differing along four key axes: (i) the fingerprint dataset (adult,\npediatric, or a combination thereof) from which the Training Plan -including\nthe network architecture-is derived; (ii) the Learning Set (adult, pediatric,\nor mixed), (iii) Data Augmentation parameters, and (iv) the Transfer learning\nmethod (finetuning versus continual learning). In this work, we introduce PSAT\n(Pediatric Segmentation Approaches via Adult Augmentations and Transfer\nlearning), a systematic study that investigates the impact of these axes on\nsegmentation performance. We benchmark the derived strategies on two pediatric\nCT datasets and compare them with state-of-theart methods, including a\ncommercial radiotherapy solution. PSAT highlights key pitfalls and provides\nactionable insights for improving pediatric segmentation. Our experiments\nreveal that a training plan based on an adult fingerprint dataset is misaligned\nwith pediatric anatomy-resulting in significant performance degradation,\nespecially when segmenting fine structures-and that continual learning\nstrategies mitigate institutional shifts, thus enhancing generalization across\ndiverse pediatric datasets. The code is available at\nhttps://github.com/ICANS-Strasbourg/PSAT.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05764v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06009", "title": "KnowIt: Deep Time Series Modeling and Interpretation", "authors": ["M. W. Theunissen", "R. Rabe", "M. H. Davel"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06009v1", "summary": "KnowIt (Knowledge discovery in time series data) is a flexible framework for\nbuilding deep time series models and interpreting them. It is implemented as a\nPython toolkit, with source code and documentation available from\nhttps://must-deep-learning.github.io/KnowIt. It imposes minimal assumptions\nabout task specifications and decouples the definition of dataset, deep neural\nnetwork architecture, and interpretability technique through well defined\ninterfaces. This ensures the ease of importing new datasets, custom\narchitectures, and the definition of different interpretability paradigms while\nmaintaining on-the-fly modeling and interpretation of different aspects of a\nuser's own time series data. KnowIt aims to provide an environment where users\ncan perform knowledge discovery on their own complex time series data through\nbuilding powerful deep learning models and explaining their behavior. With\nongoing development, collaboration and application our goal is to make this a\nplatform to progress this underexplored field and produce a trusted tool for\ndeep time series modeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06009v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05887", "title": "GeoMag: A Vision-Language Model for Pixel-level Fine-Grained Remote Sensing Image Parsing", "authors": ["Xianzhi Ma", "Jianhui Li", "Changhua Pei", "Hao Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05887v1", "summary": "The application of Vision-Language Models (VLMs) in remote sensing (RS) image\nunderstanding has achieved notable progress, demonstrating the basic ability to\nrecognize and describe geographical entities. However, existing RS-VLMs are\nmostly limited to image-level and region-level tasks, lacking the capability to\nhandle pixel-level tasks and performing poorly in small-object recognition\nscenarios. Moreover, RS-VLMs consume significant computational resources when\nprocessing high-resolution RS images, further restricting their practical\napplicability. In this context, we propose GeoMag (Geographical Magnifier), an\nend-to-end general-purpose large model framework for RS. GeoMag dynamically\nfocuses the attention scope based on prompt semantics to effectively perform\nremote sensing image parsing across multiple levels of granularity. This method\nintroduces Task-driven Multi-granularity Resolution Adjustment (TMRA) and\nPrompt-guided Semantic-aware Cropping (PSC), which adaptively reduce the\nspatial resolution of task-irrelevant regions while enhancing the visual\nrepresentation of task-relevant areas. This approach improves the model's\nperception of critical target regions, suppresses background redundancy, and\nreduces the computational cost of interpreting high-resolution RS imagery.\nExtensive comparative experiments on 10 benchmarks demonstrate that GeoMag not\nonly excels in handling pixel-level tasks but also maintains competitive\nperformance across tasks of other granularities compared to existing RS-VLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05887v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2502.20690", "title": "Multi-model Stochastic Particle-based Variational Bayesian Inference for Multiband Delay Estimation", "authors": ["Zhixiang Hu", "An Liu", "Minjian Zhao"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.20690v2", "summary": "Joint utilization of multiple discrete frequency bands can enhance the\naccuracy of delay estimation. Although some unique challenges of multiband\nfusion, such as phase distortion, oscillation phenomena, and high-dimensional\nsearch, have been partially addressed, further challenges remain. Specifically,\nunder conditions of low signal-to-noise ratio (SNR), insufficient data, and\nclosely spaced delay paths, accurately determining the model order-the number\nof delay paths-becomes difficult. Misestimating the model order can\nsignificantly degrade the estimation performance of traditional methods. To\naddress joint model selection and parameter estimation under such harsh\nconditions, we propose a multi-model stochastic particle-based variational\nBayesian inference (MM-SPVBI) framework, capable of exploring multiple\nhigh-dimensional parameter spaces. Initially, we split potential overlapping\nprimary delay paths based on coarse estimates, generating several parallel\ncandidate models. Then, an auto-focusing sampling strategy is employed to\nquickly identify the optimal model. Additionally, we introduce a hybrid\nposterior approximation to improve the original single-model SPVBI, ensuring\noverall complexity does not increase significantly with parallelism.\nSimulations demonstrate that our algorithm offers substantial advantages over\nexisting methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.20690v2", "cate": "eess.SP", "date": "2025-02-28", "updated": "2025-07-08"}
{"id": "2507.05609", "title": "MMW: Side Talk Rejection Multi-Microphone Whisper on Smart Glasses", "authors": ["Yang Liu", "Li Wan", "Yiteng Huang", "Yong Xu", "yangyang shi", "Saurabh Adya", "ming sun", "Florian Metze"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05609v1", "summary": "Smart glasses are increasingly positioned as the next-generation interface\nfor ubiquitous access to large language models (LLMs). Nevertheless, achieving\nreliable interaction in real-world noisy environments remains a major\nchallenge, particularly due to interference from side speech. In this work, we\nintroduce a novel side-talk rejection multi-microphone Whisper (MMW) framework\nfor smart glasses, incorporating three key innovations. First, we propose a Mix\nBlock based on a Tri-Mamba architecture to effectively fuse multi-channel audio\nat the raw waveform level, while maintaining compatibility with streaming\nprocessing. Second, we design a Frame Diarization Mamba Layer to enhance\nframe-level side-talk suppression, facilitating more efficient fine-tuning of\nWhisper models. Third, we employ a Multi-Scale Group Relative Policy\nOptimization (GRPO) strategy to jointly optimize frame-level and\nutterance-level side speech suppression. Experimental evaluations demonstrate\nthat the proposed MMW system can reduce the word error rate (WER) by 4.95\\% in\nnoisy conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05609v1", "cate": "eess.AS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05815", "title": "Just Say Better or Worse: A Human-AI Collaborative Framework for Medical Image Segmentation Without Manual Annotations", "authors": ["Yizhe Zhang"], "categories": ["eess.IV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      10 pages, 4 figures", "url": "http://arxiv.org/abs/2507.05815v1", "summary": "Manual annotation of medical images is a labor-intensive and time-consuming\nprocess, posing a significant bottleneck in the development and deployment of\nrobust medical imaging AI systems. This paper introduces a novel Human-AI\ncollaborative framework for medical image segmentation that substantially\nreduces the annotation burden by eliminating the need for explicit manual\npixel-level labeling. The core innovation lies in a preference learning\nparadigm, where human experts provide minimal, intuitive feedback -- simply\nindicating whether an AI-generated segmentation is better or worse than a\nprevious version. The framework comprises four key components: (1) an adaptable\nfoundation model (FM) for feature extraction, (2) label propagation based on\nfeature similarity, (3) a clicking agent that learns from human better-or-worse\nfeedback to decide where to click and with which label, and (4) a multi-round\nsegmentation learning procedure that trains a state-of-the-art segmentation\nnetwork using pseudo-labels generated by the clicking agent and FM-based label\npropagation. Experiments on three public datasets demonstrate that the proposed\napproach achieves competitive segmentation performance using only binary\npreference feedback, without requiring experts to directly manually annotate\nthe images.", "comment": "10 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.05815v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06021", "title": "Kamae: Bridging Spark and Keras for Seamless ML Preprocessing", "authors": ["George Barrowclough", "Marian Andrecki", "James Shinner", "Daniele Donghi"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06021v1", "summary": "In production recommender systems, feature preprocessing must be faithfully\nreplicated across training and inference environments. This often requires\nduplicating logic between offline and online environments, increasing\nengineering effort and introducing risks of dataset shift. We present Kamae, an\nopen-source Python library that bridges this gap by translating PySpark\npreprocessing pipelines into equivalent Keras models. Kamae provides a suite of\nconfigurable Spark transformers and estimators, each mapped to a corresponding\nKeras layer, enabling consistent, end-to-end preprocessing across the ML\nlifecycle. Framework's utility is illustrated on real-world use cases,\nincluding MovieLens dataset and Expedia's Learning-to-Rank pipelines. The code\nis available at https://github.com/ExpediaGroup/kamae.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06021v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05899", "title": "What You Have is What You Track: Adaptive and Robust Multimodal Tracking", "authors": ["Yuedong Tan", "Jiawei Shao", "Eduard Zamfir", "Ruanjun Li", "Zhaochong An", "Chao Ma", "Danda Paudel", "Luc Van Gool", "Radu Timofte", "Zongwei Wu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV2025 accepted", "url": "http://arxiv.org/abs/2507.05899v1", "summary": "Multimodal data is known to be helpful for visual tracking by improving\nrobustness to appearance variations. However, sensor synchronization challenges\noften compromise data availability, particularly in video settings where\nshortages can be temporal. Despite its importance, this area remains\nunderexplored. In this paper, we present the first comprehensive study on\ntracker performance with temporally incomplete multimodal data. Unsurprisingly,\nunder such a circumstance, existing trackers exhibit significant performance\ndegradation, as their rigid architectures lack the adaptability needed to\neffectively handle missing modalities. To address these limitations, we propose\na flexible framework for robust multimodal tracking. We venture that a tracker\nshould dynamically activate computational units based on missing data rates.\nThis is achieved through a novel Heterogeneous Mixture-of-Experts fusion\nmechanism with adaptive complexity, coupled with a video-level masking strategy\nthat ensures both temporal consistency and spatial completeness which is\ncritical for effective video tracking. Surprisingly, our model not only adapts\nto varying missing rates but also adjusts to scene complexity. Extensive\nexperiments show that our model achieves SOTA performance across 9 benchmarks,\nexcelling in both conventional complete and missing modality settings. The code\nand benchmark will be publicly available at\nhttps://github.com/supertyd/FlexTrack/tree/main.", "comment": "ICCV2025 accepted", "pdf_url": "http://arxiv.org/pdf/2507.05899v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2502.20703", "title": "A Quantum-Empowered SPEI Drought Forecasting Algorithm Using Spatially-Aware Mamba Network", "authors": ["Po-Wei Tang", "Chia-Hsiang Lin", "Jian-Kai Huang", "Alfredo R. Huete"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This work has been accepted by IEEE Transactions on Geoscience and Remote Sensing (TGRS)", "url": "http://arxiv.org/abs/2502.20703v2", "summary": "Due to the intensifying impacts of extreme climate changes, drought\nforecasting (DF), which aims to predict droughts from historical meteorological\ndata, has become increasingly critical for monitoring and managing water\nresources. Though drought conditions often exhibit spatial climatic coherence\namong neighboring regions, benchmark deep learning-based DF methods overlook\nthis fact and predict the conditions on a region-by-region basis. Using the\nStandardized Precipitation Evapotranspiration Index (SPEI), we designed and\ntrained a novel and transformative spatially-aware DF neural network, which\neffectively captures local interactions among neighboring regions, resulting in\nenhanced spatial coherence and prediction accuracy. As DF also requires\nsophisticated temporal analysis, the Mamba network, recognized as the most\naccurate and efficient existing time-sequence modeling, was adopted to extract\ntemporal features from short-term time frames. We also adopted quantum neural\nnetworks (QNN) to entangle the spatial features of different time instances,\nleading to refined spatiotemporal features of seven different meteorological\nvariables for effectively identifying short-term climate fluctuations. In the\nlast stage of our proposed SPEI-driven quantum spatially-aware Mamba network\n(SQUARE-Mamba), the extracted spatiotemporal features of seven different\nmeteorological variables were fused to achieve more accurate DF. Validation\nexperiments across El Ni\\~no, La Ni\\~na, and normal years demonstrated the\nsuperiority of the proposed SQUARE-Mamba, remarkably achieving an average\nimprovement of more than 9.8% in the coefficient of determination index (R^2)\ncompared to baseline methods, thereby illustrating the promising roles of the\ntemporal quantum entanglement and Mamba temporal analysis to achieve more\naccurate DF.", "comment": "This work has been accepted by IEEE Transactions on Geoscience and\n  Remote Sensing (TGRS)", "pdf_url": "http://arxiv.org/pdf/2502.20703v2", "cate": "eess.SP", "date": "2025-02-28", "updated": "2025-07-08"}
{"id": "2507.05883", "title": "A novel framework for fully-automated co-registration of intravascular ultrasound and optical coherence tomography imaging data", "authors": ["Xingwei He", "Kit Mills Bransby", "Ahmet Emir Ulutas", "Thamil Kumaran", "Nathan Angelo Lecaros Yap", "Gonul Zeren", "Hesong Zeng", "Yaojun Zhang", "Andreas Baumbach", "James Moon", "Anthony Mathur", "Jouke Dijkstra", "Qianni Zhang", "Lorenz Raber", "Christos V Bourantas"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.05883v1", "summary": "Aims: To develop a deep-learning (DL) framework that will allow fully\nautomated longitudinal and circumferential co-registration of intravascular\nultrasound (IVUS) and optical coherence tomography (OCT) images. Methods and\nresults: Data from 230 patients (714 vessels) with acute coronary syndrome that\nunderwent near-infrared spectroscopy (NIRS)-IVUS and OCT imaging in their\nnon-culprit vessels were included in the present analysis. The lumen borders\nannotated by expert analysts in 61,655 NIRS-IVUS and 62,334 OCT frames, and the\nside branches and calcific tissue identified in 10,000 NIRS-IVUS frames and\n10,000 OCT frames, were used to train DL solutions for the automated extraction\nof these features. The trained DL solutions were used to process NIRS-IVUS and\nOCT images and their output was used by a dynamic time warping algorithm to\nco-register longitudinally the NIRS-IVUS and OCT images, while the\ncircumferential registration of the IVUS and OCT was optimized through dynamic\nprogramming. On a test set of 77 vessels from 22 patients, the DL method showed\nhigh concordance with the expert analysts for the longitudinal and\ncircumferential co-registration of the two imaging sets (concordance\ncorrelation coefficient >0.99 for the longitudinal and >0.90 for the\ncircumferential co-registration). The Williams Index was 0.96 for longitudinal\nand 0.97 for circumferential co-registration, indicating a comparable\nperformance to the analysts. The time needed for the DL pipeline to process\nimaging data from a vessel was <90s. Conclusion: The fully automated, DL-based\nframework introduced in this study for the co-registration of IVUS and OCT is\nfast and provides estimations that compare favorably to the expert analysts.\nThese features renders it useful in research in the analysis of large-scale\ndata collected in studies that incorporate multimodality imaging to\ncharacterize plaque composition.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.05883v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05304", "title": "Self-Attention Based Multi-Scale Graph Auto-Encoder Network of 3D Meshes", "authors": ["Saqib Nazir", "Olivier Lézoray", "Sébastien Bougleux"], "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05304v1", "summary": "3D meshes are fundamental data representations for capturing complex\ngeometric shapes in computer vision and graphics applications. While\nConvolutional Neural Networks (CNNs) have excelled in structured data like\nimages, extending them to irregular 3D meshes is challenging due to the\nnon-Euclidean nature of the data. Graph Convolutional Networks (GCNs) offer a\nsolution by applying convolutions to graph-structured data, but many existing\nmethods rely on isotropic filters or spectral decomposition, limiting their\nability to capture both local and global mesh features. In this paper, we\nintroduce 3D Geometric Mesh Network (3DGeoMeshNet), a novel GCN-based framework\nthat uses anisotropic convolution layers to effectively learn both global and\nlocal features directly in the spatial domain. Unlike previous approaches that\nconvert meshes into intermediate representations like voxel grids or point\nclouds, our method preserves the original polygonal mesh format throughout the\nreconstruction process, enabling more accurate shape reconstruction. Our\narchitecture features a multi-scale encoder-decoder structure, where separate\nglobal and local pathways capture both large-scale geometric structures and\nfine-grained local details. Extensive experiments on the COMA dataset\ncontaining human faces demonstrate the efficiency of 3DGeoMeshNet in terms of\nreconstruction accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05304v1", "cate": "cs.GR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06026", "title": "Multi-view mid fusion: a universal approach for learning in an HDLSS setting", "authors": ["Lynn Houthuys"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06026v1", "summary": "The high-dimensional low-sample-size (HDLSS) setting presents significant\nchallenges in various applications where the feature dimension far exceeds the\nnumber of available samples. This paper introduces a universal approach for\nlearning in HDLSS setting using multi-view mid fusion techniques. It shows how\nexisting mid fusion multi-view methods perform well in an HDLSS setting even if\nno inherent views are provided. Three view construction methods are proposed\nthat split the high-dimensional feature vectors into smaller subsets, each\nrepresenting a different view. Extensive experimental validation across\nmodel-types and learning tasks confirm the effectiveness and generalization of\nthe approach. We believe the work in this paper lays the foundation for further\nresearch into the universal benefits of multi-view mid fusion learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06026v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05916", "title": "On the Effectiveness of Methods and Metrics for Explainable AI in Remote Sensing Image Scene Classification", "authors": ["Jonas Klotz", "Tom Burgert", "Begüm Demir"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      The code of this work will be publicly available at this https URL", "url": "http://arxiv.org/abs/2507.05916v1", "summary": "The development of explainable artificial intelligence (xAI) methods for\nscene classification problems has attracted great attention in remote sensing\n(RS). Most xAI methods and the related evaluation metrics in RS are initially\ndeveloped for natural images considered in computer vision (CV), and their\ndirect usage in RS may not be suitable. To address this issue, in this paper,\nwe investigate the effectiveness of explanation methods and metrics in the\ncontext of RS image scene classification. In detail, we methodologically and\nexperimentally analyze ten explanation metrics spanning five categories\n(faithfulness, robustness, localization, complexity, randomization), applied to\nfive established feature attribution methods (Occlusion, LIME, GradCAM, LRP,\nand DeepLIFT) across three RS datasets. Our methodological analysis identifies\nkey limitations in both explanation methods and metrics. The performance of\nperturbation-based methods, such as Occlusion and LIME, heavily depends on\nperturbation baselines and spatial characteristics of RS scenes. Gradient-based\napproaches like GradCAM struggle when multiple labels are present in the same\nimage, while some relevance propagation methods (LRP) can distribute relevance\ndisproportionately relative to the spatial extent of classes. Analogously, we\nfind limitations in evaluation metrics. Faithfulness metrics share the same\nproblems as perturbation-based methods. Localization metrics and complexity\nmetrics are unreliable for classes with a large spatial extent. In contrast,\nrobustness metrics and randomization metrics consistently exhibit greater\nstability. Our experimental results support these methodological findings.\nBased on our analysis, we provide guidelines for selecting explanation methods,\nmetrics, and hyperparameters in the context of RS image scene classification.", "comment": "The code of this work will be publicly available at\n  https://git.tu-berlin.de/rsim/xai4rs", "pdf_url": "http://arxiv.org/pdf/2507.05916v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2505.19845", "title": "Discrete-Time CRLB-based Power Allocation for CF MIMO-ISAC with Joint Localization and Velocity Sensing", "authors": ["Guoqing Xia", "Pei Xiao", "Qu Luo", "Bing Ji", "Yue Zhang", "Huiyu Zhou"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      13 pages, 11 figures", "url": "http://arxiv.org/abs/2505.19845v2", "summary": "In this paper, we investigate integrated sensing and communication (ISAC) in\na cell-free (CF) multiple-input multiple-output (MIMO) network, where each\naccess point functions either as an ISAC transmitter or as a sensing receiver.\nWe devote into the ISAC sensing metric using the discrete-time signal-based\nCramer-Rao lower bounds (CRLBs) for joint location and velocity estimation\nunder arbitrary power allocation ratios under the deterministic radar cross\nsection assumption (RCS). Then, we consider the power allocation optimization\nproblem for the CF MIMO-ISAC as the maximization of the communication\nsignal-to-interference-plus-noise ratio (SINR), subject to CRLB-based sensing\nconstraints and per-transmitter power limits. To solve the resulting nonlinear\nand non-convex problem, we propose a penalty function and projection-based\nmodified conjugate gradient algorithm with inexact line search (PP-MCG-ILS),\nand an alternative method based on a modified steepest descent approach\n(PP-MSD-ILS). We show that the proposed algorithms are scalable and can be\nextended to a broad class of optimization problems involving nonlinear\ninequality constraints and affine equality constraints. In addition, we extend\nthe PP-MCG-ILS algorithm to the pure sensing scenario, where a penalty\nfunction-based normalized conjugate gradient algorithm (P-NCG-ILS) is developed\nfor sensing power minimization. Finally, we analyze the convergence behavior\nand qualitatively compare the computational complexity of the proposed\nalgorithms. Simulation results confirm the accuracy of the derived CRLBs and\ndemonstrate the effectiveness of the proposed power allocation strategies in\nenhancing both sensing and overall ISAC performance.", "comment": "13 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2505.19845v2", "cate": "eess.SP", "date": "2025-05-26", "updated": "2025-07-08"}
{"id": "2304.04763", "title": "Distributed Estimation with Decentralized Control for Quadruple-Tank Process", "authors": ["Moh Kamalul Wafi", "Bambang L. Widjiantoro"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      17 pages, 12 figures", "url": "http://arxiv.org/abs/2304.04763v2", "summary": "This paper presents a unified modeling, control, and estimation framework for\nthe quadruple-tank process, a benchmark multivariable system that exhibits\neither minimum phase or nonminimum phase behavior depending on valve flow\nratios. A decentralized PI control strategy is employed to regulate water\nlevels, while a distributed state estimation scheme is developed using local\nLuenberger observers and inter-agent communication. Each observer uses only\nlocal output measurements and exchanges information with neighboring nodes over\na strongly connected communication graph. To address the limitations of partial\nobservability, the observer design incorporates an observability decomposition\nand consensus-based coupling that ensures convergence to the true system state.\nSimulation results validate the effectiveness of the proposed framework,\ndemonstrating accurate state reconstruction and stable closed loop performance\nunder both minimum-phase and nonminimum phase configurations. These results\nhighlight the potential of combining decentralized control with distributed\nestimation for scalable, networked control of complex multivariable systems.", "comment": "17 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2304.04763v2", "cate": "eess.SY", "date": "2023-04-09", "updated": "2025-07-08"}
{"id": "2507.05688", "title": "Robust One-step Speech Enhancement via Consistency Distillation", "authors": ["Liang Xu", "Longfei Felix Yan", "W. Bastiaan Kleijn"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE WASPAA 2025. 6 pages, 1 figures", "url": "http://arxiv.org/abs/2507.05688v1", "summary": "Diffusion models have shown strong performance in speech enhancement, but\ntheir real-time applicability has been limited by multi-step iterative\nsampling. Consistency distillation has recently emerged as a promising\nalternative by distilling a one-step consistency model from a multi-step\ndiffusion-based teacher model. However, distilled consistency models are\ninherently biased towards the sampling trajectory of the teacher model, making\nthem less robust to noise and prone to inheriting inaccuracies from the teacher\nmodel. To address this limitation, we propose ROSE-CD: Robust One-step Speech\nEnhancement via Consistency Distillation, a novel approach for distilling a\none-step consistency model. Specifically, we introduce a randomized learning\ntrajectory to improve the model's robustness to noise. Furthermore, we jointly\noptimize the one-step model with two time-domain auxiliary losses, enabling it\nto recover from teacher-induced errors and surpass the teacher model in overall\nperformance. This is the first pure one-step consistency distillation model for\ndiffusion-based speech enhancement, achieving 54 times faster inference speed\nand superior performance compared to its 30-step teacher model. Experiments on\nthe VoiceBank-DEMAND dataset demonstrate that the proposed model achieves\nstate-of-the-art performance in terms of speech quality. Moreover, its\ngeneralization ability is validated on both an out-of-domain dataset and\nreal-world noisy recordings.", "comment": "Accepted to IEEE WASPAA 2025. 6 pages, 1 figures", "pdf_url": "http://arxiv.org/pdf/2507.05688v1", "cate": "eess.AS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06067", "title": "Enhancing Synthetic CT from CBCT via Multimodal Fusion and End-To-End Registration", "authors": ["Maximilian Tschuchnig", "Lukas Lamminger", "Philipp Steininger", "Michael Gadermayr"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted at CAIP 2025. arXiv admin note: substantial text overlap with arXiv:2506.08716", "url": "http://arxiv.org/abs/2507.06067v1", "summary": "Cone-Beam Computed Tomography (CBCT) is widely used for intraoperative\nimaging due to its rapid acquisition and low radiation dose. However, CBCT\nimages typically suffer from artifacts and lower visual quality compared to\nconventional Computed Tomography (CT). A promising solution is synthetic CT\n(sCT) generation, where CBCT volumes are translated into the CT domain. In this\nwork, we enhance sCT generation through multimodal learning by jointly\nleveraging intraoperative CBCT and preoperative CT data. To overcome the\ninherent misalignment between modalities, we introduce an end-to-end learnable\nregistration module within the sCT pipeline. This model is evaluated on a\ncontrolled synthetic dataset, allowing precise manipulation of data quality and\nalignment parameters. Further, we validate its robustness and generalizability\non two real-world clinical datasets. Experimental results demonstrate that\nintegrating registration in multimodal sCT generation improves sCT quality,\noutperforming baseline multimodal methods in 79 out of 90 evaluation settings.\nNotably, the improvement is most significant in cases where CBCT quality is low\nand the preoperative CT is moderately misaligned.", "comment": "Accepted at CAIP 2025. arXiv admin note: substantial text overlap\n  with arXiv:2506.08716", "pdf_url": "http://arxiv.org/pdf/2507.06067v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06040", "title": "EdgeCodec: Onboard Lightweight High Fidelity Neural Compressor with Residual Vector Quantization", "authors": ["Benjamin Hodo", "Tommaso Polonelli", "Amirhossein Moallemi", "Luca Benini", "Michele Magno"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      7 Pages, 1 Figure, Accepted for presentation at the International Workshop on Advances in Sensors and Interfaces (IWASI), Italy 2025. \\c{opyright} IEEE. DOI to be updated upon publication", "url": "http://arxiv.org/abs/2507.06040v1", "summary": "We present EdgeCodec, an end-to-end neural compressor for barometric data\ncollected from wind turbine blades. EdgeCodec leverages a heavily asymmetric\nautoencoder architecture, trained with a discriminator and enhanced by a\nResidual Vector Quantizer to maximize compression efficiency. It achieves\ncompression rates between 2'560:1 and 10'240:1 while maintaining a\nreconstruction error below 3%, and operates in real time on the GAP9\nmicrocontroller with bitrates ranging from 11.25 to 45 bits per second.\nBitrates can be selected on a sample-by-sample basis, enabling on-the-fly\nadaptation to varying network conditions. In its highest compression mode,\nEdgeCodec reduces the energy consumption of wireless data transmission by up to\n2.9x, significantly extending the operational lifetime of deployed sensor\nunits.", "comment": "7 Pages, 1 Figure, Accepted for presentation at the International\n  Workshop on Advances in Sensors and Interfaces (IWASI), Italy 2025.\n  \\c{opyright} IEEE. DOI to be updated upon publication", "pdf_url": "http://arxiv.org/pdf/2507.06040v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05920", "title": "High-Resolution Visual Reasoning via Multi-Turn Grounding-Based Reinforcement Learning", "authors": ["Xinyu Huang", "Yuhao Dong", "Weiwei Tian", "Bo Li", "Rui Feng", "Ziwei Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05920v1", "summary": "State-of-the-art large multi-modal models (LMMs) face challenges when\nprocessing high-resolution images, as these inputs are converted into enormous\nvisual tokens, many of which are irrelevant to the downstream task. In this\npaper, we propose Multi-turn Grounding-based Policy Optimization (MGPO), an\nend-to-end reinforcement learning (RL) framework that enables LMMs to\niteratively focus on key visual regions by automatically cropping sub-images,\nbased on model-predicted grounding coordinates within a multi-turn conversation\nframework. Compared to supervised fine-tuning (SFT), which requires costly\nadditional grounding annotations, our approach highlights that LMMs can emerge\nrobust grounding abilities during the RL training process, leveraging only a\nbinary reward function derived from the correctness of the final answer.\nAdditionally, we observe that LMMs struggle to autonomously trigger visual\ngrounding during the rollout process. To address this cold start problem, we\ndesign a multi-turn conversational template and restrict policy loss\ncomputation to model outputs generated across multiple dialogue rounds, thereby\npromoting stable optimization. Extensive experiments demonstrate that, when\ntrained on standard visual-question-short answering data without grounding\nannotations, MGPO effectively elicits stronger grounding capabilities compared\nto GRPO, leading to 5.4\\% improvement on in-distribution MME-Realworld and\n5.2\\% improvement on the challenging out-of-distribution (OOD) V* Bench.\nNotably, MGPO post-training on Qwen2.5-VL-7B with 21K samples surpasses\nOpenAI's o1 and GPT-4o models on the OOD V* Bench. Codes are available at\nhttps://github.com/EvolvingLMMs-Lab/MGPO.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05920v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2211.15353", "title": "Copula Density Neural Estimation", "authors": ["Nunzio A. Letizia", "Nicola Novello", "Andrea M. Tonello"], "categories": ["cs.LG", "eess.SP", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, in Transactions on Neural Networks and Learning Systems", "url": "http://arxiv.org/abs/2211.15353v3", "summary": "Probability density estimation from observed data constitutes a central task\nin statistics. In this brief, we focus on the problem of estimating the copula\ndensity associated to any observed data, as it fully describes the dependence\nbetween random variables. We separate univariate marginal distributions from\nthe joint dependence structure in the data, the copula itself, and we model the\nlatter with a neural network-based method referred to as copula density neural\nestimation (CODINE). Results show that the novel learning approach is capable\nof modeling complex distributions and can be applied for mutual information\nestimation and data generation.", "comment": "9 pages, in Transactions on Neural Networks and Learning Systems", "pdf_url": "http://arxiv.org/pdf/2211.15353v3", "cate": "cs.LG", "date": "2022-11-25", "updated": "2025-07-08"}
{"id": "2502.19993", "title": "Data-Driven Mean Field Equilibrium Computation in Large-Population LQG Games", "authors": ["Zhenhui Xu", "Jiayu Chen", "Bing-Chang Wang", "Tielong Shen"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.19993v2", "summary": "This paper presents a novel data-driven approach for approximating the\n$\\varepsilon$-Nash equilibrium in continuous-time linear quadratic Gaussian\n(LQG) games, where multiple agents interact with each other through their\ndynamics and infinite horizon discounted costs. The core of our method involves\nsolving two algebraic Riccati equations (AREs) and an ordinary differential\nequation (ODE) using state and input samples collected from agents, eliminating\nthe need for a priori knowledge of their dynamical models. The standard ARE is\naddressed through an integral reinforcement learning (IRL) technique, while the\nnonsymmetric ARE and the ODE are resolved by identifying the drift coefficients\nof the agents' dynamics under general conditions. Moreover, by imposing\nspecific conditions on models, we extend the IRL-based approach to\napproximately solve the nonsymmetric ARE. Numerical examples are given to\ndemonstrate the effectiveness of the proposed algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.19993v2", "cate": "eess.SY", "date": "2025-02-27", "updated": "2025-07-08"}
{"id": "2507.05727", "title": "ContextASR-Bench: A Massive Contextual Speech Recognition Benchmark", "authors": ["He Wang", "Linhan Ma", "Dake Guo", "Xiong Wang", "Lei Xie", "Jin Xu", "Junyang Lin"], "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      18 pages, 4 figures", "url": "http://arxiv.org/abs/2507.05727v1", "summary": "Automatic Speech Recognition (ASR) has been extensively investigated, yet\nprior evaluative efforts have largely been restricted to contextless paradigms.\nThis constraint stems from the limited proficiency of conventional ASR models\nin context modeling and their deficiency in memory and reasoning based on world\nknowledge. Recent breakthroughs in the development of Large Language Models\n(LLMs) and corresponding Large Audio Language Models (LALMs) have markedly\nenhanced the visibility of general artificial intelligence capabilities.\nConsequently, there exists a compelling need for a benchmark that can evaluate\nboth the generality and intelligence of ASR systems. To address this gap, we\npropose ContextASR-Bench: a comprehensive, large-scale benchmark designed to\nassess contextual speech recognition. This benchmark encompasses up to 40,000\ndata entries across over 10 domains, enabling a thorough evaluation of model\nperformance in scenarios that omit or incorporate coarse-grained or\nfine-grained contextual information. Moreover, diverging from conventional ASR\nevaluations, our benchmark includes an analysis of model efficacy in\nrecognizing named entities mentioned within the auditory input. Our extensive\nevaluation highlights that LALMs, with strong world knowledge and context\nlearning capabilities, outperform conventional ASR models by a large margin.\nThe dataset and evaluation code have been released at\nhttps://github.com/MrSupW/ContextASR-Bench.", "comment": "18 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.05727v1", "cate": "eess.AS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06140", "title": "LangMamba: A Language-driven Mamba Framework for Low-dose CT Denoising with Vision-language Models", "authors": ["Zhihao Chen", "Tao Chen", "Chenhui Wang", "Qi Gao", "Huidong Xie", "Chuang Niu", "Ge Wang", "Hongming Shan"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      11 pages, 8 figures", "url": "http://arxiv.org/abs/2507.06140v1", "summary": "Low-dose computed tomography (LDCT) reduces radiation exposure but often\ndegrades image quality, potentially compromising diagnostic accuracy. Existing\ndeep learning-based denoising methods focus primarily on pixel-level mappings,\noverlooking the potential benefits of high-level semantic guidance. Recent\nadvances in vision-language models (VLMs) suggest that language can serve as a\npowerful tool for capturing structured semantic information, offering new\nopportunities to improve LDCT reconstruction. In this paper, we introduce\nLangMamba, a Language-driven Mamba framework for LDCT denoising that leverages\nVLM-derived representations to enhance supervision from normal-dose CT (NDCT).\nLangMamba follows a two-stage learning strategy. First, we pre-train a\nLanguage-guided AutoEncoder (LangAE) that leverages frozen VLMs to map NDCT\nimages into a semantic space enriched with anatomical information. Second, we\nsynergize LangAE with two key components to guide LDCT denoising:\nSemantic-Enhanced Efficient Denoiser (SEED), which enhances NDCT-relevant local\nsemantic while capturing global features with efficient Mamba mechanism, and\nLanguage-engaged Dual-space Alignment (LangDA) Loss, which ensures that\ndenoised images align with NDCT in both perceptual and semantic spaces.\nExtensive experiments on two public datasets demonstrate that LangMamba\noutperforms conventional state-of-the-art methods, significantly improving\ndetail preservation and visual fidelity. Remarkably, LangAE exhibits strong\ngeneralizability to unseen datasets, thereby reducing training costs.\nFurthermore, LangDA loss improves explainability by integrating language-guided\ninsights into image reconstruction and offers a plug-and-play fashion. Our\nfindings shed new light on the potential of language as a supervisory signal to\nadvance LDCT denoising. The code is publicly available on\nhttps://github.com/hao1635/LangMamba.", "comment": "11 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.06140v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05306", "title": "Enjoying Non-linearity in Multinomial Logistic Bandits", "authors": ["Pierre Boudart", "Pierre Gaillard", "Alessandro Rudi"], "categories": ["stat.ML", "cs.AI", "cs.LG", "math.ST", "stat.TH"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05306v1", "summary": "We consider the multinomial logistic bandit problem, a variant of generalized\nlinear bandits where a learner interacts with an environment by selecting\nactions to maximize expected rewards based on probabilistic feedback from\nmultiple possible outcomes. In the binary setting, recent work has focused on\nunderstanding the impact of the non-linearity of the logistic model (Faury et\nal., 2020; Abeille et al., 2021). They introduced a problem-dependent constant\n$\\kappa_*$, that may be exponentially large in some problem parameters and\nwhich is captured by the derivative of the sigmoid function. It encapsulates\nthe non-linearity and improves existing regret guarantees over $T$ rounds from\n$\\smash{O(d\\sqrt{T})}$ to $\\smash{O(d\\sqrt{T/\\kappa_*})}$, where $d$ is the\ndimension of the parameter space. We extend their analysis to the multinomial\nlogistic bandit framework, making it suitable for complex applications with\nmore than two choices, such as reinforcement learning or recommender systems.\nTo achieve this, we extend the definition of $\\kappa_*$ to the multinomial\nsetting and propose an efficient algorithm that leverages the problem's\nnon-linearity. Our method yields a problem-dependent regret bound of order $\n\\smash{\\widetilde{\\mathcal{O}}( Kd \\sqrt{{T}/{\\kappa_*}})} $, where $K$ is the\nnumber of actions and $\\kappa_* \\ge 1$. This improves upon the best existing\nguarantees of order $ \\smash{\\widetilde{\\mathcal{O}}( Kd \\sqrt{T} )} $.\nMoreover, we provide a $\\smash{ \\Omega(d\\sqrt{T/\\kappa_*})}$ lower-bound,\nshowing that our dependence on $\\kappa_*$ is optimal.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05306v1", "cate": "stat.ML", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06062", "title": "Few-Shot Learning by Explicit Physics Integration: An Application to Groundwater Heat Transport", "authors": ["Julia Pelzer", "Corné Verburg", "Alexander Heinlein", "Miriam Schulte"], "categories": ["cs.LG", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06062v1", "summary": "Machine learning methods often struggle with real-world applications in\nscience and engineering due to limited or low-quality training data. In this\nwork, the example of groundwater flow with heat transport is considered; this\ncorresponds to an advection-diffusion process under heterogeneous flow\nconditions, that is, spatially distributed material parameters and heat\nsources. Classical numerical simulations are costly and challenging due to high\nspatio-temporal resolution requirements and large domains. While often\ncomputationally more efficient, purely data-driven surrogate models face\ndifficulties, particularly in predicting the advection process, which is highly\nsensitive to input variations and involves long-range spatial interactions.\nTherefore, in this work, a Local-Global Convolutional Neural Network (LGCNN)\napproach is introduced. It combines a lightweight numerical surrogate for the\ntransport process (global) with convolutional neural networks for the\ngroundwater velocity and heat diffusion processes (local). With the LGCNN, a\ncity-wide subsurface temperature field is modeled, involving a heterogeneous\ngroundwater flow field and one hundred groundwater heat pump injection points\nforming interacting heat plumes over long distances. The model is first\nsystematically analyzed based on random subsurface input fields. Then, the\nmodel is trained on a handful of cut-outs from a real-world subsurface map of\nthe Munich region in Germany, and it scales to larger cut-outs without\nretraining. All datasets, our code, and trained models are published for\nreproducibility.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06062v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05948", "title": "Beyond Appearance: Geometric Cues for Robust Video Instance Segmentation", "authors": ["Quanzhu Niu", "Yikang Zhou", "Shihao Chen", "Tao Zhang", "Shunping Ji"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05948v1", "summary": "Video Instance Segmentation (VIS) fundamentally struggles with pervasive\nchallenges including object occlusions, motion blur, and appearance variations\nduring temporal association. To overcome these limitations, this work\nintroduces geometric awareness to enhance VIS robustness by strategically\nleveraging monocular depth estimation. We systematically investigate three\ndistinct integration paradigms. Expanding Depth Channel (EDC) method\nconcatenates the depth map as input channel to segmentation networks; Sharing\nViT (SV) designs a uniform ViT backbone, shared between depth estimation and\nsegmentation branches; Depth Supervision (DS) makes use of depth prediction as\nan auxiliary training guide for feature learning. Though DS exhibits limited\neffectiveness, benchmark evaluations demonstrate that EDC and SV significantly\nenhance the robustness of VIS. When with Swin-L backbone, our EDC method gets\n56.2 AP, which sets a new state-of-the-art result on OVIS benchmark. This work\nconclusively establishes depth cues as critical enablers for robust video\nunderstanding.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05948v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06179", "title": "Dynamic Slimmable Networks for Efficient Speech Separation", "authors": ["Mohamed Elminshawi", "Srikanth Raj Chetupalli", "Emanuël A. P. Habets"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      This manuscript has been submitted to IEEE Transactions on Audio, Speech and Language Processing", "url": "http://arxiv.org/abs/2507.06179v1", "summary": "Recent progress in speech separation has been largely driven by advances in\ndeep neural networks, yet their high computational and memory requirements\nhinder deployment on resource-constrained devices. A significant inefficiency\nin conventional systems arises from using static network architectures that\nmaintain constant computational complexity across all input segments,\nregardless of their characteristics. This approach is sub-optimal for simpler\nsegments that do not require intensive processing, such as silence or\nnon-overlapping speech. To address this limitation, we propose a dynamic\nslimmable network (DSN) for speech separation that adaptively adjusts its\ncomputational complexity based on the input signal. The DSN combines a\nslimmable network, which can operate at different network widths, with a\nlightweight gating module that dynamically determines the required width by\nanalyzing the local input characteristics. To balance performance and\nefficiency, we introduce a signal-dependent complexity loss that penalizes\nunnecessary computation based on segmental reconstruction error. Experiments on\nclean and noisy two-speaker mixtures from the WSJ0-2mix and WHAM! datasets show\nthat the DSN achieves a better performance-efficiency trade-off than\nindividually trained static networks of different sizes.", "comment": "This manuscript has been submitted to IEEE Transactions on Audio,\n  Speech and Language Processing", "pdf_url": "http://arxiv.org/pdf/2507.06179v1", "cate": "eess.AS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06079", "title": "QS4D: Quantization-aware training for efficient hardware deployment of structured state-space sequential models", "authors": ["Sebastian Siegel", "Ming-Jay Yang", "Younes Bouhadjar", "Maxime Fabre", "Emre Neftci", "John Paul Strachan"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06079v1", "summary": "Structured State Space models (SSM) have recently emerged as a new class of\ndeep learning models, particularly well-suited for processing long sequences.\nTheir constant memory footprint, in contrast to the linearly scaling memory\ndemands of Transformers, makes them attractive candidates for deployment on\nresource-constrained edge-computing devices. While recent works have explored\nthe effect of quantization-aware training (QAT) on SSMs, they typically do not\naddress its implications for specialized edge hardware, for example, analog\nin-memory computing (AIMC) chips. In this work, we demonstrate that QAT can\nsignificantly reduce the complexity of SSMs by up to two orders of magnitude\nacross various performance metrics. We analyze the relation between model size\nand numerical precision, and show that QAT enhances robustness to analog noise\nand enables structural pruning. Finally, we integrate these techniques to\ndeploy SSMs on a memristive analog in-memory computing substrate and highlight\nthe resulting benefits in terms of computational efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06079v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05952", "title": "High-Fidelity and Generalizable Neural Surface Reconstruction with Sparse Feature Volumes", "authors": ["Aoxiang Fan", "Corentin Dumery", "Nicolas Talabot", "Hieu Le", "Pascal Fua"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05952v1", "summary": "Generalizable neural surface reconstruction has become a compelling technique\nto reconstruct from few images without per-scene optimization, where dense 3D\nfeature volume has proven effective as a global representation of scenes.\nHowever, the dense representation does not scale well to increasing voxel\nresolutions, severely limiting the reconstruction quality. We thus present a\nsparse representation method, that maximizes memory efficiency and enables\nsignificantly higher resolution reconstructions on standard hardware. We\nimplement this through a two-stage approach: First training a network to\npredict voxel occupancies from posed images and associated depth maps, then\ncomputing features and performing volume rendering only in voxels with\nsufficiently high occupancy estimates. To support this sparse representation,\nwe developed custom algorithms for efficient sampling, feature aggregation, and\nquerying from sparse volumes-overcoming the dense-volume assumptions inherent\nin existing works. Experiments on public datasets demonstrate that our approach\nreduces storage requirements by more than 50 times without performance\ndegradation, enabling reconstructions at $512^3$ resolution compared to the\ntypical $128^3$ on similar hardware, and achieving superior reconstruction\naccuracy over current state-of-the-art methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05952v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2403.04945", "title": "MEIT: Multimodal Electrocardiogram Instruction Tuning on Large Language Models for Report Generation", "authors": ["Zhongwei Wan", "Che Liu", "Xin Wang", "Chaofan Tao", "Hui Shen", "Jing Xiong", "Rossella Arcucci", "Huaxiu Yao", "Mi Zhang"], "categories": ["cs.CL", "cs.LG", "eess.SP"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025", "url": "http://arxiv.org/abs/2403.04945v4", "summary": "Electrocardiogram (ECG) is the primary non-invasive diagnostic tool for\nmonitoring cardiac conditions and is crucial in assisting clinicians. Recent\nstudies have concentrated on classifying cardiac conditions using ECG data but\nhave overlooked ECG report generation, which is time-consuming and requires\nclinical expertise. To automate ECG report generation and ensure its\nversatility, we propose the Multimodal ECG Instruction Tuning (MEIT) framework,\nthe first attempt to tackle ECG report generation with LLMs and multimodal\ninstructions. To facilitate future research, we establish a benchmark to\nevaluate MEIT with various LLMs backbones across two large-scale ECG datasets.\nOur approach uniquely aligns the representations of the ECG signal and the\nreport, and we conduct extensive experiments to benchmark MEIT with nine\nopen-source LLMs using more than 800,000 ECG reports. MEIT's results underscore\nthe superior performance of instruction-tuned LLMs, showcasing their\nproficiency in quality report generation, zero-shot capabilities, resilience to\nsignal perturbation, and alignment with human expert evaluation. These findings\nemphasize the efficacy of MEIT and its potential for real-world clinical\napplication.", "comment": "ACL 2025", "pdf_url": "http://arxiv.org/pdf/2403.04945v4", "cate": "cs.CL", "date": "2024-03-07", "updated": "2025-07-07"}
{"id": "2505.22307", "title": "On data usage and predictive behavior of data-driven predictive control with 1-norm regularization", "authors": ["Manuel Klädtke", "Moritz Schulze Darup"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      This paper is a preprint of a contribution to the IEEE Control Systems Letters. 6 pages, 3 figures", "url": "http://arxiv.org/abs/2505.22307v2", "summary": "We investigate the data usage and predictive behavior of data-driven\npredictive control (DPC) with 1-norm regularization. Our analysis enables the\noffline removal of unused data and facilitates a comparison between the\nidentified symmetric structure and data usage against prior knowledge of the\ntrue system. This comparison helps assess the suitability of the DPC scheme for\neffective control.", "comment": "This paper is a preprint of a contribution to the IEEE Control\n  Systems Letters. 6 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2505.22307v2", "cate": "eess.SY", "date": "2025-05-28", "updated": "2025-07-08"}
{"id": "2507.05657", "title": "Adaptive Linearly Constrained Minimum Variance Volumetric Active Noise Control", "authors": ["Manan Mittal", "Ryan M. Corey", "Andrew C. Singer"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      5 pages, 6 figures", "url": "http://arxiv.org/abs/2507.05657v1", "summary": "Traditional volumetric noise control typically relies on multipoint error\nminimization to suppress sound energy across a region, but offers limited\nflexibility in shaping spatial responses. This paper introduces a time-domain\nformulation for linearly constrained minimum variance active noise control\n(LCMV ANC) for spatial control filter design. We demonstrate how the LCMV ANC\noptimization framework allows system designers to prioritize noise reduction at\nspecific spatial locations through strategically defined linear constraints,\nproviding a more flexible alternative to uniformly weighted multipoint error\nminimization. An adaptive algorithm based on filtered-X least mean squares\n(FxLMS) is derived for online adaptation of filter coefficients. Simulation and\nexperimental results validate the proposed method's noise reduction and\nconstraint adherence, demonstrating effective, spatially selective, and\nbroadband noise control compared to multipoint volumetric noise control.", "comment": "5 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.05657v1", "cate": "cs.SD", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06087", "title": "CoRE: Enhancing Metacognition with Label-free Self-evaluation in LRMs", "authors": ["Haoxi Li", "Sikai Bai", "Jie Zhang", "Song Guo"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 6 figures", "url": "http://arxiv.org/abs/2507.06087v1", "summary": "Large reasoning models (LRMs) have demonstrated impressive capabilities in\ndomains like mathematics and program synthesis. Despite their strong\nperformance, LRMs often exhibit overthinking -- excessive and redundant\nreasoning steps that introduce inefficiencies during inference. This phenomenon\nraises an important question for LRM self-evaluation: How can a model\nautonomously assess the correctness of its own reasoning trajectory without\nexternal labels? To address this, we propose Chain-of-Reasoning Embedding\n(CoRE), a series of hidden states in latent space to enable label-free\nself-evaluation on intermediate reasoning steps of LRMs, so as to enhance\nmetacognition abilities for improved reasoning efficiency. By analyzing the\ngeometric properties of the CoRE trajectories, we reveal that redundant\nreasoning usually presents cyclical fluctuations, which correspond to\nrepetitive and unconscious reflection/exploration. Leveraging this insight, we\nfurther introduce a training-free, label-free self-evaluation framework,\nCoRE-Eval, to detect such patterns and dynamically determine whether to\nterminate reasoning early. Extensive experiments on mathematical reasoning\nbenchmarks (GSM8K, MATH-500, and AIME) and across model sizes from 7B to 32B\ndemonstrate that CoRE-Eval reduces chain-of-thought length by 13.7% to 33.2%\nwhile improving answer accuracy by around 10%, achieving 70.0% accuracy on the\nchallenging AIME benchmark with the 32B model.", "comment": "9 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.06087v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05963", "title": "Tora2: Motion and Appearance Customized Diffusion Transformer for Multi-Entity Video Generation", "authors": ["Zhenghao Zhang", "Junchao Liao", "Xiangyu Meng", "Long Qin", "Weizhi Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ACM MM25 Conference Proceedings", "url": "http://arxiv.org/abs/2507.05963v1", "summary": "Recent advances in diffusion transformer models for motion-guided video\ngeneration, such as Tora, have shown significant progress. In this paper, we\npresent Tora2, an enhanced version of Tora, which introduces several design\nimprovements to expand its capabilities in both appearance and motion\ncustomization. Specifically, we introduce a decoupled personalization extractor\nthat generates comprehensive personalization embeddings for multiple open-set\nentities, better preserving fine-grained visual details compared to previous\nmethods. Building on this, we design a gated self-attention mechanism to\nintegrate trajectory, textual description, and visual information for each\nentity. This innovation significantly reduces misalignment in multimodal\nconditioning during training. Moreover, we introduce a contrastive loss that\njointly optimizes trajectory dynamics and entity consistency through explicit\nmapping between motion and personalization embeddings. Tora2 is, to our best\nknowledge, the first method to achieve simultaneous multi-entity customization\nof appearance and motion for video generation. Experimental results demonstrate\nthat Tora2 achieves competitive performance with state-of-the-art customization\nmethods while providing advanced motion control capabilities, which marks a\ncritical advancement in multi-condition video generation. Project page:\nhttps://github.com/alibaba/Tora .", "comment": "ACM MM25 Conference Proceedings", "pdf_url": "http://arxiv.org/pdf/2507.05963v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2407.11094", "title": "Robust Score-Based Quickest Change Detection", "authors": ["Sean Moushegian", "Suya Wu", "Enmao Diao", "Jie Ding", "Taposh Banerjee", "Vahid Tarokh"], "categories": ["stat.ME", "eess.SP", "stat.ML"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "Comments:      Accepted manuscript. Published in IEEE Transactions on Information Theory. arXiv admin note: text overlap with arXiv:2306.05091", "url": "http://arxiv.org/abs/2407.11094v4", "summary": "Methods in the field of quickest change detection rapidly detect in real-time\na change in the data-generating distribution of an online data stream. Existing\nmethods have been able to detect this change point when the densities of the\npre- and post-change distributions are known. Recent work has extended these\nresults to the case where the pre- and post-change distributions are known only\nby their score functions. This work considers the case where the pre- and\npost-change score functions are known only to correspond to distributions in\ntwo disjoint sets. This work selects a pair of least-favorable distributions\nfrom these sets to robustify the existing score-based quickest change detection\nalgorithm, the properties of which are studied. This paper calculates the\nleast-favorable distributions for specific model classes and provides methods\nof estimating the least-favorable distributions for common constructions.\nSimulation results are provided demonstrating the performance of our robust\nchange detection algorithm.", "comment": "Accepted manuscript. Published in IEEE Transactions on Information\n  Theory. arXiv admin note: text overlap with arXiv:2306.05091", "pdf_url": "http://arxiv.org/pdf/2407.11094v4", "cate": "stat.ME", "date": "2024-07-15", "updated": "2025-07-08"}
{"id": "2506.08414", "title": "Theoretical Foundations of Waste Factor and Waste Figure with Applications to Fixed Wireless Access and Relay Systems", "authors": ["Nurullah Sevim", "Mostafa Ibrahim", "Sabit Ekin", "Theodore S. Rappaport"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Accepted at Nature npj Wireless Technology, July 1st, 2025", "url": "http://arxiv.org/abs/2506.08414v2", "summary": "The exponential rise in energy consumption across wireless communication\nsystems, particularly in anticipation of next-generation wireless systems,\nnecessitates rigorous frameworks for evaluating and optimizing energy\nefficiency. This paper revisits and expands the concept of the Waste Factor\n(W), or Waste Figure (WF) in decibel scale, as a unifying metric that captures\nboth utilized and wasted power in cascaded communication systems. Building upon\nits foundation in system-level power modeling, we integrate the Waste Factor\ninto a refined formulation of the Consumption Factor (CF), the ratio of data\nrate to total consumed power, linking it directly to Shannon's theoretical\nlimit on energy per bit. This analysis introduces additive energy waste into\nthe classical energy-per-bit derivation through the Waste Factor term.\n  We derive closed-form expressions for energy-per-bit expenditure in both\ndirect and relay-assisted links and develop a decision rule to determine which\ncommunication path is more energy efficient under given conditions. While not\nmodeled explicitly, Reflective Intelligent Surfaces (RIS) can be interpreted as\na special case of relay-based architectures within this unified formulation,\nsuggesting broader applicability of the Waste Factor framework to emerging 6G\nuse cases. The framework is then extended to a Fixed Wireless Access (FWA)\nscenario, where uplink and downlink asymmetries, traffic directionality, and\ncomponent inefficiencies are jointly considered to analyze energy-optimal\ndeployment strategies.", "comment": "Accepted at Nature npj Wireless Technology, July 1st, 2025", "pdf_url": "http://arxiv.org/pdf/2506.08414v2", "cate": "eess.SY", "date": "2025-06-10", "updated": "2025-07-08"}
{"id": "2507.05662", "title": "Beamforming with Random Projections: Upper and Lower Bounds", "authors": ["Manan Mittal", "Ryan M. Corey", "Andrew C. Singer"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      5 pages, 3 figures", "url": "http://arxiv.org/abs/2507.05662v1", "summary": "Beamformers often trade off white noise gain against the ability to suppress\ninterferers. With distributed microphone arrays, this trade-off becomes crucial\nas different arrays capture vastly different magnitude and phase differences\nfor each source. We propose the use of multiple random projections as a\nfirst-stage preprocessing scheme in a data-driven approach to dimensionality\nreduction and beamforming. We show that a mixture beamformer derived from the\nuse of multiple such random projections can effectively outperform the minimum\nvariance distortionless response (MVDR) beamformer in terms of signal-to-noise\nratio (SNR) and signal-to-interferer-and-noise ratio (SINR) gain. Moreover, our\nmethod introduces computational complexity as a trade-off in the design of\nadaptive beamformers, alongside noise gain and interferer suppression. This\nadded degree of freedom allows the algorithm to better exploit the inherent\nstructure of the received signal and achieve better real-time performance while\nrequiring fewer computations. Finally, we derive upper and lower bounds for the\noutput power of the compressed beamformer when compared to the full complexity\nMVDR beamformer.", "comment": "5 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.05662v1", "cate": "cs.SD", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05311", "title": "PLACE: Prompt Learning for Attributed Community Search", "authors": ["Shuheng Fang", "Kangfei Zhao", "Rener Zhang", "Yu Rong", "Jeffrey Xu Yu"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      15 pages, 9 figures", "url": "http://arxiv.org/abs/2507.05311v1", "summary": "In this paper, we propose PLACE (Prompt Learning for Attributed Community\nSearch), an innovative graph prompt learning framework for ACS. Enlightened by\nprompt-tuning in Natural Language Processing (NLP), where learnable prompt\ntokens are inserted to contextualize NLP queries, PLACE integrates structural\nand learnable prompt tokens into the graph as a query-dependent refinement\nmechanism, forming a prompt-augmented graph. Within this prompt-augmented graph\nstructure, the learned prompt tokens serve as a bridge that strengthens\nconnections between graph nodes for the query, enabling the GNN to more\neffectively identify patterns of structural cohesiveness and attribute\nsimilarity related to the specific query. We employ an alternating training\nparadigm to optimize both the prompt parameters and the GNN jointly. Moreover,\nwe design a divide-and-conquer strategy to enhance scalability, supporting the\nmodel to handle million-scale graphs. Extensive experiments on 9 real-world\ngraphs demonstrate the effectiveness of PLACE for three types of ACS queries,\nwhere PLACE achieves higher F1 scores by 22% compared to the state-of-the-arts\non average.", "comment": "15 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.05311v1", "cate": "cs.IR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05964", "title": "T-LoRA: Single Image Diffusion Model Customization Without Overfitting", "authors": ["Vera Soboleva", "Aibek Alanov", "Andrey Kuznetsov", "Konstantin Sobolev"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05964v1", "summary": "While diffusion model fine-tuning offers a powerful approach for customizing\npre-trained models to generate specific objects, it frequently suffers from\noverfitting when training samples are limited, compromising both generalization\ncapability and output diversity. This paper tackles the challenging yet most\nimpactful task of adapting a diffusion model using just a single concept image,\nas single-image customization holds the greatest practical potential. We\nintroduce T-LoRA, a Timestep-Dependent Low-Rank Adaptation framework\nspecifically designed for diffusion model personalization. In our work we show\nthat higher diffusion timesteps are more prone to overfitting than lower ones,\nnecessitating a timestep-sensitive fine-tuning strategy. T-LoRA incorporates\ntwo key innovations: (1) a dynamic fine-tuning strategy that adjusts\nrank-constrained updates based on diffusion timesteps, and (2) a weight\nparametrization technique that ensures independence between adapter components\nthrough orthogonal initialization. Extensive experiments show that T-LoRA and\nits individual components outperform standard LoRA and other diffusion model\npersonalization techniques. They achieve a superior balance between concept\nfidelity and text alignment, highlighting the potential of T-LoRA in\ndata-limited and resource-constrained scenarios. Code is available at\nhttps://github.com/ControlGenAI/T-LoRA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05964v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.04682", "title": "MARS: Radio Map Super-resolution and Reconstruction Method under Sparse Channel Measurements", "authors": ["Chuyun Deng", "Na Liu", "Wei Xie", "Lianming Xu", "Li Wang"], "categories": ["cs.CV", "eess.SP"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      The authors withdraw this submission to substantially revise the introduction and experimental sections and incorporate new content. The manuscript has not been submitted or published elsewhere. A revised version may be submitted in the future", "url": "http://arxiv.org/abs/2506.04682v3", "summary": "Radio maps reflect the spatial distribution of signal strength and are\nessential for applications like smart cities, IoT, and wireless network\nplanning. However, reconstructing accurate radio maps from sparse measurements\nremains challenging. Traditional interpolation and inpainting methods lack\nenvironmental awareness, while many deep learning approaches depend on detailed\nscene data, limiting generalization. To address this, we propose MARS, a\nMulti-scale Aware Radiomap Super-resolution method that combines CNNs and\nTransformers with multi-scale feature fusion and residual connections. MARS\nfocuses on both global and local feature extraction, enhancing feature\nrepresentation across different receptive fields and improving reconstruction\naccuracy. Experiments across different scenes and antenna locations show that\nMARS outperforms baseline models in both MSE and SSIM, while maintaining low\ncomputational cost, demonstrating strong practical potential.", "comment": "The authors withdraw this submission to substantially revise the\n  introduction and experimental sections and incorporate new content. The\n  manuscript has not been submitted or published elsewhere. A revised version\n  may be submitted in the future", "pdf_url": "http://arxiv.org/pdf/2506.04682v3", "cate": "cs.CV", "date": "2025-06-05", "updated": "2025-07-08"}
{"id": "2507.05724", "title": "Omni-Router: Sharing Routing Decisions in Sparse Mixture-of-Experts for Speech Recognition", "authors": ["Zijin Gu", "Tatiana Likhomanenko", "Navdeep Jaitly"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05724v1", "summary": "Mixture-of-experts (MoE) architectures have expanded from language modeling\nto automatic speech recognition (ASR). Traditional MoE methods, such as the\nSwitch Transformer, route experts independently within each layer. Our analysis\nreveals that routers in most layers make expert choices that are not strongly\ncorrelated with the choices of the routers in other layers. To increase the\ncooperation between experts in different layers and encourage greater\nspecialization, we use a shared router across different MoE layers. We call\nthis model \\emph{Omni-router Transformer}. Extensive experiments on a\nlarge-scale pseudo-labeled dataset and evaluations across 10 diverse,\nout-of-domain ASR benchmarks demonstrate that the Omni-router Transformer is\nable to achieve lower training loss and consistently outperform dense and\nSwitch Transformer models, reducing average word error rates by 11.2% and 8.2%,\nrespectively, while providing structured expert usage and improved robustness\nto diverse data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05724v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05770", "title": "25 Additional Problems -- Extension to the Book \"125 Problems in Text Algorithms\"", "authors": ["Maxime Crochemore", "Thierry Lecroq", "Wojtek Rytter"], "categories": ["cs.DS", "68W32", "F.2.2"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      72 pages", "url": "http://arxiv.org/abs/2507.05770v1", "summary": "This very preliminary text is related to ``Algorithms on Texts'', also called\n``Algorithmic Stringology''. It is an extension of the book ``125 Problems in\nText Algorithms'' providing, in the same compact style, more problems with\nsolutions. We refer also to the companions to ``Text algorithms'' available at\nhttp://monge.univ-mlv.fr/~mac/CLR/clr1-20.pdf and at the web page\nhttp://125-problems.univ-mlv.fr, where all 150 problems (including the ones\npresented here) are briefly announced. The selected problems satisfy three\ncriteria: challenging, having short tricky solutions and solvable with only\nvery basic background in stringology. For the basics in stringology we refer to\nhttp://monge.univ-mlv.fr/~mac/CLR/clr1-20.pdf.", "comment": "72 pages", "pdf_url": "http://arxiv.org/pdf/2507.05770v1", "cate": "cs.DS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05313", "title": "Solar Flare Prediction Using LSTM and DLSTM with Sliding Window Pattern Recognition", "authors": ["Zeinab Hassani", "Davud Mohammadpur", "Hossein Safari"], "categories": ["astro-ph.SR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Solar and Stellar Astrophysics (astro-ph.SR)", "pdf_link": null, "comments": "Comments:      Published in the Astrophysical Journal Supplement Series, volume 279, 2025, DOI: https://doi.org/10.3847/1538-4365/addc73", "url": "http://arxiv.org/abs/2507.05313v1", "summary": "We investigate the use of Long Short-Term Memory (LSTM) and\nDecomposition-LSTM (DLSTM) networks, combined with an ensemble algorithm, to\npredict solar flare occurrences using time-series data from the GOES catalog.\nThe dataset spans from 2003 to 2023 and includes 151,071 flare events. Among\napproximately possible patterns, 7,552 yearly pattern windows are identified,\nhighlighting the challenge of long-term forecasting due to the Sun's complex,\nself-organized criticality-driven behavior. A sliding window technique is\nemployed to detect temporal quasi-patterns in both irregular and regularized\nflare time series. Regularization reduces complexity, enhances large flare\nactivity, and captures active days more effectively. To address class\nimbalance, resampling methods are applied. LSTM and DLSTM models are trained on\nsequences of peak fluxes and waiting times from irregular time series, while\nLSTM and DLSTM, integrated with an ensemble approach, are applied to sliding\nwindows of regularized time series with a 3-hour interval. Performance metrics,\nparticularly TSS (0.74), recall (0.95) and the area under the curve (AUC=0.87)\nin the receiver operating characteristic (ROC), indicate that DLSTM with an\nensemble approach on regularized time series outperforms other models, offering\nmore accurate large-flare forecasts with fewer false errors compared to models\ntrained on irregular time series. The superior performance of DLSTM is\nattributed to its ability to decompose time series into trend and seasonal\ncomponents, effectively isolating random noise. This study underscores the\npotential of advanced machine learning techniques for solar flare prediction\nand highlights the importance of incorporating various solar cycle phases and\nresampling strategies to enhance forecasting reliability.", "comment": "Published in the Astrophysical Journal Supplement Series, volume 279,\n  2025, DOI: 10.3847/1538-4365/addc73", "pdf_url": "http://arxiv.org/pdf/2507.05313v1", "cate": "astro-ph.SR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06125", "title": "Subspace-based Approximate Hessian Method for Zeroth-Order Optimization", "authors": ["Dongyoon Kim", "Sungjae Lee", "Wonjin Lee", "Kwang In Kim"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      20 pages, 8 figures", "url": "http://arxiv.org/abs/2507.06125v1", "summary": "Zeroth-order optimization addresses problems where gradient information is\ninaccessible or impractical to compute. While most existing methods rely on\nfirst-order approximations, incorporating second-order (curvature) information\ncan, in principle, significantly accelerate convergence. However, the high cost\nof function evaluations required to estimate Hessian matrices often limits\npractical applicability. We present the subspace-based approximate Hessian\n(ZO-SAH) method, a zeroth-order optimization algorithm that mitigates these\ncosts by focusing on randomly selected two-dimensional subspaces. Within each\nsubspace, ZO-SAH estimates the Hessian by fitting a quadratic polynomial to the\nobjective function and extracting its second-order coefficients. To further\nreduce function-query costs, ZO-SAH employs a periodic subspace-switching\nstrategy that reuses function evaluations across optimization steps.\nExperiments on eight benchmark datasets, including logistic regression and deep\nneural network training tasks, demonstrate that ZO-SAH achieves significantly\nfaster convergence than existing zeroth-order methods.", "comment": "20 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.06125v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05970", "title": "Automatic Synthesis of High-Quality Triplet Data for Composed Image Retrieval", "authors": ["Haiwen Li", "Delong Liu", "Zhaohui Hou", "Zhicheng Zhao", "Fei Su"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This paper was originally submitted to ACM MM 2025 on April 12, 2025", "url": "http://arxiv.org/abs/2507.05970v1", "summary": "As a challenging vision-language (VL) task, Composed Image Retrieval (CIR)\naims to retrieve target images using multimodal (image+text) queries. Although\nmany existing CIR methods have attained promising performance, their reliance\non costly, manually labeled triplets hinders scalability and zero-shot\ncapability. To address this issue, we propose a scalable pipeline for automatic\ntriplet generation, along with a fully synthetic dataset named Composed Image\nRetrieval on High-quality Synthetic Triplets (CIRHS). Our pipeline leverages a\nlarge language model (LLM) to generate diverse prompts, controlling a\ntext-to-image generative model to produce image pairs with identical elements\nin each pair, which are then filtered and reorganized to form the CIRHS\ndataset. In addition, we introduce Hybrid Contextual Alignment (CoAlign), a\nnovel CIR framework, which can accomplish global alignment and local reasoning\nwithin a broader context, enabling the model to learn more robust and\ninformative representations. By utilizing the synthetic CIRHS dataset, CoAlign\nachieves outstanding zero-shot performance on three commonly used benchmarks,\ndemonstrating for the first time the feasibility of training CIR models on a\nfully synthetic dataset. Furthermore, under supervised training, our method\noutperforms all the state-of-the-art supervised CIR approaches, validating the\neffectiveness of our proposed retrieval framework. The code and the CIRHS\ndataset will be released soon.", "comment": "This paper was originally submitted to ACM MM 2025 on April 12, 2025", "pdf_url": "http://arxiv.org/pdf/2507.05970v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2406.00826", "title": "Policy Verification in Stochastic Dynamical Systems Using Logarithmic Neural Certificates", "authors": ["Thom Badings", "Wietze Koops", "Sebastian Junges", "Nils Jansen"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Extended version (with appendix) of the paper presented at CAV 2025", "url": "http://arxiv.org/abs/2406.00826v3", "summary": "We consider the verification of neural network policies for discrete-time\nstochastic systems with respect to reach-avoid specifications. We use a\nlearner-verifier procedure that learns a certificate for the specification,\nrepresented as a neural network. Verifying that this neural network certificate\nis a so-called reach-avoid supermartingale (RASM) proves the satisfaction of a\nreach-avoid specification. Existing approaches for such a verification task\nrely on computed Lipschitz constants of neural networks. These approaches\nstruggle with large Lipschitz constants, especially for reach-avoid\nspecifications with high threshold probabilities. We present two key\ncontributions to obtain smaller Lipschitz constants than existing approaches.\nFirst, we introduce logarithmic RASMs (logRASMs), which take exponentially\nsmaller values than RASMs and hence have lower theoretical Lipschitz constants.\nSecond, we present a fast method to compute tighter upper bounds on Lipschitz\nconstants based on weighted norms. Our empirical evaluation shows we can\nconsistently verify the satisfaction of reach-avoid specifications with\nprobabilities as high as 99.9999%.", "comment": "Extended version (with appendix) of the paper presented at CAV 2025", "pdf_url": "http://arxiv.org/pdf/2406.00826v3", "cate": "cs.LG", "date": "2024-06-02", "updated": "2025-07-08"}
{"id": "2507.05729", "title": "Non-Intrusive Binaural Speech Intelligibility Prediction Using Mamba for Hearing-Impaired Listeners", "authors": ["Katsuhiko Yamamoto", "Koichi Miyazaki"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted by INTERSPEECH 2025", "url": "http://arxiv.org/abs/2507.05729v1", "summary": "Speech intelligibility prediction (SIP) models have been used as objective\nmetrics to assess intelligibility for hearing-impaired (HI) listeners. In the\nClarity Prediction Challenge 2 (CPC2), non-intrusive binaural SIP models based\non transformers showed high prediction accuracy. However, the self-attention\nmechanism theoretically incurs high computational and memory costs, making it a\nbottleneck for low-latency, power-efficient devices. This may also degrade the\ntemporal processing of binaural SIPs. Therefore, we propose Mamba-based SIP\nmodels instead of transformers for the temporal processing blocks. Experimental\nresults show that our proposed SIP model achieves competitive performance\ncompared to the baseline while maintaining a relatively small number of\nparameters. Our analysis suggests that the SIP model based on bidirectional\nMamba effectively captures contextual and spatial speech information from\nbinaural signals.", "comment": "Accepted by INTERSPEECH 2025", "pdf_url": "http://arxiv.org/pdf/2507.05729v1", "cate": "cs.SD", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2202.01116", "title": "An Optimal Transport Perspective on Unpaired Image Super-Resolution", "authors": ["Milena Gazdieva", "Petr Mokrov", "Litu Rout", "Alexander Korotin", "Andrey Kravchenko", "Alexander Filippov", "Evgeny Burnaev"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2202.01116v3", "summary": "Real-world image super-resolution (SR) tasks often do not have paired\ndatasets, which limits the application of supervised techniques. As a result,\nthe tasks are usually approached by unpaired techniques based on Generative\nAdversarial Networks (GANs), which yield complex training losses with several\nregularization terms, e.g., content or identity losses. While GANs usually\nprovide good practical performance, they are used heuristically, i.e.,\ntheoretical understanding of their behaviour is yet rather limited. We\ntheoretically investigate optimization problems which arise in such models and\nfind two surprising observations. First, the learned SR map is always an\noptimal transport (OT) map. Second, we theoretically prove and empirically show\nthat the learned map is biased, i.e., it does not actually transform the\ndistribution of low-resolution images to high-resolution ones. Inspired by\nthese findings, we investigate recent advances in neural OT field to resolve\nthe bias issue. We establish an intriguing connection between regularized GANs\nand neural OT approaches. We show that unlike the existing GAN-based\nalternatives, these algorithms aim to learn an unbiased OT map. We empirically\ndemonstrate our findings via a series of synthetic and real-world unpaired SR\nexperiments. Our source code is publicly available at\nhttps://github.com/milenagazdieva/OT-Super-Resolution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2202.01116v3", "cate": "eess.IV", "date": "2022-02-02", "updated": "2025-07-08"}
{"id": "2507.05877", "title": "Non-Adaptive Evaluation of $k$-of-$n$ Functions: Tight Gap and a Unit-Cost PTAS", "authors": ["Mads Anker Nielsen", "Lars Rohwedder", "Kevin Schewior"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Full version of APPROX 2025 paper", "url": "http://arxiv.org/abs/2507.05877v1", "summary": "We consider the Stochastic Boolean Function Evaluation (SBFE) problem in the\nwell-studied case of $k$-of-$n$ functions: There are independent Boolean random\nvariables $x_1,\\dots,x_n$ where each variable $i$ has a known probability $p_i$\nof taking value $1$, and a known cost $c_i$ that can be paid to find out its\nvalue. The value of the function is $1$ iff there are at least $k$ $1$s among\nthe variables. The goal is to efficiently compute a strategy that, at minimum\nexpected cost, tests the variables until the function value is determined.\nWhile an elegant polynomial-time exact algorithm is known when tests can be\nmade adaptively, we focus on the non-adaptive variant, for which much less is\nknown.\n  First, we show a clean and tight lower bound of $2$ on the adaptivity gap,\ni.e., the worst-case multiplicative loss in the objective function caused by\ndisallowing adaptivity, of the problem. This improves the tight lower bound of\n$3/2$ for the unit-cost variant.\n  Second, we give a PTAS for computing the best non-adaptive strategy in the\nunit-cost case, the first PTAS for an SBFE problem. At the core, our scheme\nestablishes a novel notion of two-sided dominance (w.r.t. the optimal solution)\nby guessing so-called milestone tests for a set of carefully chosen buckets of\ntests. To turn this technique into a polynomial-time algorithm, we use a\ndecomposition approach paired with a random-shift argument.", "comment": "Full version of APPROX 2025 paper", "pdf_url": "http://arxiv.org/pdf/2507.05877v1", "cate": "cs.DS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05992", "title": "Exploring Partial Multi-Label Learning via Integrating Semantic Co-occurrence Knowledge", "authors": ["Xin Wu", "Fei Teng", "Yue Feng", "Kaibo Shi", "Zhuosheng Lin", "Ji Zhang", "James Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      14 pages, 10 figures, Under Review", "url": "http://arxiv.org/abs/2507.05992v1", "summary": "Partial multi-label learning aims to extract knowledge from incompletely\nannotated data, which includes known correct labels, known incorrect labels,\nand unknown labels. The core challenge lies in accurately identifying the\nambiguous relationships between labels and instances. In this paper, we\nemphasize that matching co-occurrence patterns between labels and instances is\nkey to addressing this challenge. To this end, we propose Semantic\nCo-occurrence Insight Network (SCINet), a novel and effective framework for\npartial multi-label learning. Specifically, SCINet introduces a bi-dominant\nprompter module, which leverages an off-the-shelf multimodal model to capture\ntext-image correlations and enhance semantic alignment. To reinforce\ninstance-label interdependencies, we develop a cross-modality fusion module\nthat jointly models inter-label correlations, inter-instance relationships, and\nco-occurrence patterns across instance-label assignments. Moreover, we propose\nan intrinsic semantic augmentation strategy that enhances the model's\nunderstanding of intrinsic data semantics by applying diverse image\ntransformations, thereby fostering a synergistic relationship between label\nconfidence and sample difficulty. Extensive experiments on four widely-used\nbenchmark datasets demonstrate that SCINet surpasses state-of-the-art methods.", "comment": "14 pages, 10 figures, Under Review", "pdf_url": "http://arxiv.org/pdf/2507.05992v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2411.18148", "title": "A Runtime-Adaptive Transformer Neural Network Accelerator on FPGAs", "authors": ["Ehsan Kabir", "Austin R. J. Downey", "Jason D. Bakos", "David Andrews", "Miaoqing Huang"], "categories": ["cs.AR", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2409.14023", "url": "http://arxiv.org/abs/2411.18148v3", "summary": "Transformer neural networks (TNN) excel in natural language processing (NLP),\nmachine translation, and computer vision (CV) without relying on recurrent or\nconvolutional layers. However, they have high computational and memory demands,\nparticularly on resource-constrained devices like FPGAs. Moreover, transformer\nmodels vary in processing time across applications, requiring custom models\nwith specific parameters. Designing custom accelerators for each model is\ncomplex and time-intensive. Some custom accelerators exist with no runtime\nadaptability, and they often rely on sparse matrices to reduce latency.\nHowever, hardware designs become more challenging due to the need for\napplication-specific sparsity patterns. This paper introduces ADAPTOR, a\nruntime-adaptive accelerator for dense matrix computations in transformer\nencoders and decoders on FPGAs. ADAPTOR enhances the utilization of processing\nelements and on-chip memory, enhancing parallelism and reducing latency. It\nincorporates efficient matrix tiling to distribute resources across FPGA\nplatforms and is fully quantized for computational efficiency and portability.\nEvaluations on Xilinx Alveo U55C data center cards and embedded platforms like\nVC707 and ZCU102 show that our design is 1.2$\\times$ and 2.87$\\times$ more\npower efficient than the NVIDIA K80 GPU and the i7-8700K CPU respectively.\nAdditionally, it achieves a speedup of 1.7 to 2.25$\\times$ compared to some\nstate-of-the-art FPGA-based accelerators.", "comment": "arXiv admin note: text overlap with arXiv:2409.14023", "pdf_url": "http://arxiv.org/pdf/2411.18148v3", "cate": "cs.AR", "date": "2024-11-27", "updated": "2025-07-08"}
{"id": "2507.05885", "title": "How to Evaluate Automatic Speech Recognition: Comparing Different Performance and Bias Measures", "authors": ["Tanvina Patel", "Wiebke Hutiri", "Aaron Yi Ding", "Odette Scharenborg"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05885v1", "summary": "There is increasingly more evidence that automatic speech recognition (ASR)\nsystems are biased against different speakers and speaker groups, e.g., due to\ngender, age, or accent. Research on bias in ASR has so far primarily focused on\ndetecting and quantifying bias, and developing mitigation approaches. Despite\nthis progress, the open question is how to measure the performance and bias of\na system. In this study, we compare different performance and bias measures,\nfrom literature and proposed, to evaluate state-of-the-art end-to-end ASR\nsystems for Dutch. Our experiments use several bias mitigation strategies to\naddress bias against different speaker groups. The findings reveal that\naveraged error rates, a standard in ASR research, alone is not sufficient and\nshould be supplemented by other measures. The paper ends with recommendations\nfor reporting ASR performance and bias to better represent a system's\nperformance for diverse speaker groups, and overall system bias.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05885v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2305.09666", "title": "AbdomenAtlas-8K: Annotating 8,000 CT Volumes for Multi-Organ Segmentation in Three Weeks", "authors": ["Chongyu Qu", "Tiezheng Zhang", "Hualin Qiao", "Jie Liu", "Yucheng Tang", "Alan Yuille", "Zongwei Zhou"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Conference on Neural Information Processing Systems (NeurIPS 2023)", "url": "http://arxiv.org/abs/2305.09666v3", "summary": "Annotating medical images, particularly for organ segmentation, is laborious\nand time-consuming. For example, annotating an abdominal organ requires an\nestimated rate of 30-60 minutes per CT volume based on the expertise of an\nannotator and the size, visibility, and complexity of the organ. Therefore,\npublicly available datasets for multi-organ segmentation are often limited in\ndata size and organ diversity. This paper proposes an active learning method to\nexpedite the annotation process for organ segmentation and creates the largest\nmulti-organ dataset (by far) with the spleen, liver, kidneys, stomach,\ngallbladder, pancreas, aorta, and IVC annotated in 8,448 CT volumes, equating\nto 3.2 million slices. The conventional annotation methods would take an\nexperienced annotator up to 1,600 weeks (or roughly 30.8 years) to complete\nthis task. In contrast, our annotation method has accomplished this task in\nthree weeks (based on an 8-hour workday, five days a week) while maintaining a\nsimilar or even better annotation quality. This achievement is attributed to\nthree unique properties of our method: (1) label bias reduction using multiple\npre-trained segmentation models, (2) effective error detection in the model\npredictions, and (3) attention guidance for annotators to make corrections on\nthe most salient errors. Furthermore, we summarize the taxonomy of common\nerrors made by AI algorithms and annotators. This allows for continuous\nrevision of both AI and annotations and significantly reduces the annotation\ncosts required to create large-scale datasets for a wider variety of medical\nimaging tasks.", "comment": "Conference on Neural Information Processing Systems (NeurIPS 2023)", "pdf_url": "http://arxiv.org/pdf/2305.09666v3", "cate": "eess.IV", "date": "2023-05-16", "updated": "2025-07-08"}
{"id": "2507.06032", "title": "Learning-Augmented Online Covering Problems", "authors": ["Afrouz Jabal Ameli", "Laura Sanita", "Moritz Venzin"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06032v1", "summary": "We give a very general and simple framework to incorporate predictions on\nrequests for online covering problems in a rigorous and black-box manner. Our\nframework turns any online algorithm with competitive ratio $\\rho(k, \\cdot)$\ndepending on $k$, the number of arriving requests, into an algorithm with\ncompetitive ratio of $\\rho(\\eta, \\cdot)$, where $\\eta$ is the prediction error.\nWith accurate enough prediction, the resulting competitive ratio breaks through\nthe corresponding worst-case online lower bounds, and smoothly degrades as the\nprediction error grows. This framework directly applies to a wide range of\nwell-studied online covering problems such as facility location, Steiner\nproblems, set cover, parking permit, etc., and yields improved and novel\nbounds.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06032v1", "cate": "cs.DS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06152", "title": "Aliasing in Convnets: A Frame-Theoretic Perspective", "authors": ["Daniel Haider", "Vincent Lostanlen", "Martin Ehler", "Nicki Holighaus", "Peter Balazs"], "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06152v1", "summary": "Using a stride in a convolutional layer inherently introduces aliasing, which\nhas implications for numerical stability and statistical generalization. While\ntechniques such as the parametrizations via paraunitary systems have been used\nto promote orthogonal convolution and thus ensure Parseval stability, a general\nanalysis of aliasing and its effects on the stability has not been done in this\ncontext. In this article, we adapt a frame-theoretic approach to describe\naliasing in convolutional layers with 1D kernels, leading to practical\nestimates for stability bounds and characterizations of Parseval stability,\nthat are tailored to take short kernel sizes into account. From this, we derive\ntwo computationally very efficient optimization objectives that promote\nParseval stability via systematically suppressing aliasing. Finally, for layers\nwith random kernels, we derive closed-form expressions for the expected value\nand variance of the terms that describe the aliasing effects, revealing\nfundamental insights into the aliasing behavior at initialization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06152v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05996", "title": "Ensemble-Based Deepfake Detection using State-of-the-Art Models with Robust Cross-Dataset Generalisation", "authors": ["Haroon Wahab", "Hassan Ugail", "Lujain Jaleel"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05996v1", "summary": "Machine learning-based Deepfake detection models have achieved impressive\nresults on benchmark datasets, yet their performance often deteriorates\nsignificantly when evaluated on out-of-distribution data. In this work, we\ninvestigate an ensemble-based approach for improving the generalization of\ndeepfake detection systems across diverse datasets. Building on a recent\nopen-source benchmark, we combine prediction probabilities from several\nstate-of-the-art asymmetric models proposed at top venues. Our experiments span\ntwo distinct out-of-domain datasets and demonstrate that no single model\nconsistently outperforms others across settings. In contrast, ensemble-based\npredictions provide more stable and reliable performance in all scenarios. Our\nresults suggest that asymmetric ensembling offers a robust and scalable\nsolution for real-world deepfake detection where prior knowledge of forgery\ntype or quality is often unavailable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05996v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05900", "title": "Stable Acoustic Relay Assignment with High Throughput via Lase Chaos-based Reinforcement Learning", "authors": ["Zengjing Chen", "Lu Wang", "Chengzhi Xing"], "categories": ["cs.SD", "cs.LG", "eess.AS", "math.OC"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05900v1", "summary": "This study addresses the problem of stable acoustic relay assignment in an\nunderwater acoustic network. Unlike the objectives of most existing literature,\ntwo distinct objectives, namely classical stable arrangement and ambiguous\nstable arrangement, are considered. To achieve these stable arrangements, a\nlaser chaos-based multi-processing learning (LC-ML) method is introduced to\nefficiently obtain high throughput and rapidly attain stability. In order to\nsufficiently explore the relay's decision-making, this method uses random\nnumbers generated by laser chaos to learn the assignment of relays to multiple\nsource nodes. This study finds that the laser chaos-based random number and\nmulti-processing in the exchange process have a positive effect on higher\nthroughput and strong adaptability with environmental changing over time.\nMeanwhile, ambiguous cognitions result in the stable configuration with less\nvolatility compared to accurate ones. This provides a practical and useful\nmethod and can be the basis for relay selection in complex underwater\nenvironments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05900v1", "cate": "cs.SD", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2306.01190", "title": "Identifying visible tissue in intraoperative ultrasound: a method and application", "authors": ["Alistair Weld", "Luke Dixon", "Giulio Anichini", "Michael Dyck", "Alex Ranne", "Sophie Camp", "Stamatia Giannarou"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2306.01190v2", "summary": "Purpose: Intraoperative ultrasound scanning is a demanding visuotactile task.\nIt requires operators to simultaneously localise the ultrasound perspective and\nmanually perform slight adjustments to the pose of the probe, making sure not\nto apply excessive force or breaking contact with the tissue, whilst also\ncharacterising the visible tissue. Method: To analyse the probe-tissue contact,\nan iterative filtering and topological method is proposed to identify the\nunderlying visible tissue, which can be used to detect acoustic shadow and\nconstruct confidence maps of perceptual salience. Results: For evaluation,\ndatasets containing both in vivo and medical phantom data are created. A suite\nof evaluations is performed, including an evaluation of acoustic shadow\nclassification. Compared to an ablation, deep learning, and statistical method,\nthe proposed approach achieves superior classification on in vivo data,\nachieving an F_beta score of 0.864, in comparison to 0.838, 0.808, 0.808. A\nnovel framework for evaluating the confidence estimation of probe tissue\ncontact is created. The phantom data is captured specifically for this, and\ncomparison is made against two established methods. The proposed method\nproduced the superior response, achieving an average normalised root mean\nsquare error of 0.168, in comparison to 1.836 and 4.542. Evaluation is also\nextended to determine the algorithm's robustness to parameter perturbation,\nspeckle noise, data distribution shift, and capability for guiding a robotic\nscan. Conclusion: The results of this comprehensive set of experiments justify\nthe potential clinical value of the proposed algorithm, which can be used to\nsupport clinical training and robotic ultrasound automation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2306.01190v2", "cate": "eess.IV", "date": "2023-06-01", "updated": "2025-07-07"}
{"id": "2507.05569", "title": "An Optimal Algorithm for Shortest Paths in Unweighted Disk Graphs", "authors": ["Bruce W. Brewer", "Haitao Wang"], "categories": ["cs.CG", "cs.DS"], "primary_category": "Subjects:       Computational Geometry (cs.CG)", "pdf_link": null, "comments": "Comments:      To appear in ESA 2025", "url": "http://arxiv.org/abs/2507.05569v1", "summary": "Given in the plane a set $S$ of $n$ points and a set of disks centered at\nthese points, the disk graph $G(S)$ induced by these disks has vertex set $S$\nand an edge between two vertices if their disks intersect. Note that the disks\nmay have different radii. We consider the problem of computing shortest paths\nfrom a source point $s\\in S$ to all vertices in $G(S)$ where the length of a\npath in $G(S)$ is defined as the number of edges in the path. The previously\nbest algorithm solves the problem in $O(n\\log^2 n)$ time. A lower bound of\n$\\Omega(n\\log n)$ is also known for this problem under the algebraic decision\ntree model. In this paper, we present an $O(n\\log n)$ time algorithm, which\nmatches the lower bound and thus is optimal. Another virtue of our algorithm is\nthat it is quite simple.", "comment": "To appear in ESA 2025", "pdf_url": "http://arxiv.org/pdf/2507.05569v1", "cate": "cs.CG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06173", "title": "A Method for Optimizing Connections in Differentiable Logic Gate Networks", "authors": ["Wout Mommen", "Lars Keuninckx", "Matthias Hartmann", "Piet Wambacq"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06173v1", "summary": "We introduce a novel method for partial optimization of the connections in\nDeep Differentiable Logic Gate Networks (LGNs). Our training method utilizes a\nprobability distribution over a subset of connections per gate input, selecting\nthe connection with highest merit, after which the gate-types are selected. We\nshow that the connection-optimized LGNs outperform standard fixed-connection\nLGNs on the Yin-Yang, MNIST and Fashion-MNIST benchmarks, while requiring only\na fraction of the number of logic gates. When training all connections, we\ndemonstrate that 8000 simple logic gates are sufficient to achieve over 98% on\nthe MNIST data set. Additionally, we show that our network has 24 times fewer\ngates, while performing better on the MNIST data set compared to standard fully\nconnected LGNs. As such, our work shows a pathway towards fully trainable\nBoolean logic.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06173v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05999", "title": "Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS", "authors": ["Xinyu Wang", "Muhammad Ibrahim", "Atif Mansoor", "Ajmal Mian"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Submitted to Transactions on Geoscience & Remote Sensing", "url": "http://arxiv.org/abs/2507.05999v1", "summary": "Accurate geo-registration of LiDAR point clouds presents significant\nchallenges in GNSS signal denied urban areas with high-rise buildings and\nbridges. Existing methods typically rely on real-time GNSS and IMU data, that\nrequire pre-calibration and assume stable positioning during data collection.\nHowever, this assumption often fails in dense urban areas, resulting in\nlocalization errors. To address this, we propose a structured geo-registration\nand spatial correction method that aligns 3D point clouds with satellite\nimages, enabling frame-wise recovery of GNSS information and reconstruction of\ncity scale 3D maps without relying on prior localization. The proposed approach\nemploys a pre-trained Point Transformer model to segment the road points and\nthen extracts the road skeleton and intersection points from the point cloud as\nwell as the target map for alignment. Global rigid alignment of the two is\nperformed using the intersection points, followed by local refinement using\nradial basis function (RBF) interpolation. Elevation correction is then applied\nto the point cloud based on terrain information from SRTM dataset to resolve\nvertical discrepancies. The proposed method was tested on the popular KITTI\nbenchmark and a locally collected Perth (Western Australia) CBD dataset. On the\nKITTI dataset, our method achieved an average planimetric alignment standard\ndeviation (STD) of 0.84~m across sequences with intersections, representing a\n55.3\\% improvement over the original dataset. On the Perth dataset, which lacks\nGNSS information, our method achieved an average STD of 0.96~m compared to the\nGPS data extracted from Google Maps API. This corresponds to a 77.4\\%\nimprovement from the initial alignment. Our method also resulted in elevation\ncorrelation gains of 30.5\\% on the KITTI dataset and 50.4\\% on the Perth\ndataset.", "comment": "Submitted to Transactions on Geoscience & Remote Sensing", "pdf_url": "http://arxiv.org/pdf/2507.05999v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05911", "title": "Differentiable Reward Optimization for LLM based TTS system", "authors": ["Changfeng Gao", "Zhihao Du", "Shiliang Zhang"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05911v1", "summary": "This paper proposes a novel Differentiable Reward Optimization (DiffRO)\nmethod aimed at enhancing the performance of neural codec language models based\ntext-to-speech (TTS) systems. In contrast to conventional reinforcement\nlearning from human feedback (RLHF) approaches applied to TTS, DiffRO directly\ncompute the rewards based on neural codec tokens, rather than relying on\nsynthesized audio. Furthermore, we employ the Gumbel-Softmax technique to\nrender the reward function differentiable, thereby streamlining the RLHF\ntraining process. Additionally, we introduce a multi-task reward (MTR) model\nwhich can provide feedback from different perspectives and find that it can\naugment the system's capability to follow instructions effectively.Experimental\nresults indicate that DiffRO significantly improves the pronunciation accuracy\nof the TTS system, achieving state-of-the-art (SOTA) WER results on the\nseed-tts-eval benchmark. Moreover, with the integration of the MTR model, we\ndemonstrate the ability to control emotional and quality attributes in a\nzero-shot manner.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05911v1", "cate": "cs.SD", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2406.16993", "title": "Are Vision xLSTM Embedded UNet More Reliable in Medical 3D Image Segmentation?", "authors": ["Pallabi Dutta", "Soham Bose", "Swalpa Kumar Roy", "Sushmita Mitra"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.16993v3", "summary": "The development of efficient segmentation strategies for medical images has\nevolved from its initial dependence on Convolutional Neural Networks (CNNs) to\nthe current investigation of hybrid models that combine CNNs with Vision\nTransformers (ViTs). There is an increasing focus on creating architectures\nthat are both high-performing and computationally efficient, capable of being\ndeployed on remote systems with limited resources. Although transformers can\ncapture global dependencies in the input space, they face challenges from the\ncorresponding high computational and storage expenses involved. This research\ninvestigates the integration of CNNs with Vision Extended Long Short-Term\nMemory (Vision-xLSTM)s by introducing the novel U-VixLSTM.\n  The Vision-xLSTM blocks capture the temporal and global relationships within\nthe patches extracted from the CNN feature maps. The convolutional feature\nreconstruction path upsamples the output volume from the Vision-xLSTM blocks to\nproduce the segmentation output. Our primary objective is to propose that\nVision-xLSTM forms an appropriate backbone for medical image segmentation,\noffering excellent performance with reduced computational costs. The U-VixLSTM\nexhibits superior performance compared to the state-of-the-art networks in the\npublicly available Synapse, ISIC and ACDC datasets. Code provided:\nhttps://github.com/duttapallabi2907/U-VixLSTM", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.16993v3", "cate": "eess.IV", "date": "2024-06-24", "updated": "2025-07-08"}
{"id": "2507.05760", "title": "Parameterized Restless Temporal Path", "authors": ["Justine Cauvi", "Laurent Viennot"], "categories": ["cs.CC", "cs.DS"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05760v1", "summary": "Recently, Bumpus and Meeks introduced a purely temporal parameter, called\nvertex-interval-membership-width, which is promising for the design of\nfixed-parameter tractable (FPT) algorithms for vertex reachability problems in\ntemporal graphs. We study this newly introduced parameter for the problem of\nrestless temporal paths, in which the waiting time at each node is restricted.\nIn this article, we prove that, in the interval model, where arcs are present\nfor entire time intervals, finding a restless temporal path is NP-hard even if\nthe vertex-interval-membership-width is equal to three. We exhibit FPT\nalgorithms for the point model, where arcs are present at specific points in\ntime, both with uniform delay one and arbitrary positive delays. In the latter\ncase, this comes with a slight additional computational cost.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05760v1", "cate": "cs.CC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05534", "title": "Evolutionary and Coevolutionary Multi-Agent Design Choices and Dynamics", "authors": ["Erik Hemberg", "Eric Liu", "Lucille Fuller", "Stephen Moskal", "Una-May O'Reilly"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      12 pages, 8 Figures", "url": "http://arxiv.org/abs/2507.05534v1", "summary": "We investigate two representation alternatives for the controllers of teams\nof cyber agents. We combine these controller representations with different\nevolutionary algorithms, one of which introduces a novel LLM-supported mutation\noperator. Using a cyber security scenario, we evaluate agent learning when one\nside is trained to compete against a side that does not evolve and when two\nsides coevolve with each other. This allows us to quantify the relative merits\nand tradeoffs of representation and algorithm combinations in terms of team\nperformance. Our versions of grammatical evolution algorithms using grammars\nthat allow a controller to be expressed in code-like logic can achieve the best\nteam performance. The scenario also allows us to compare the performance impact\nand dynamics of coevolution versus evolution under different combinations.\nAcross the algorithms and representations, we observe that coevolution reduces\nthe performance highs and lows of both sides while it induces fluctuations on\nboth sides. In contrast, when only one-side is optimized, performance peaks are\nhigher and is more sustained than when both sides are optimized with\ncoevolution.", "comment": "12 pages, 8 Figures", "pdf_url": "http://arxiv.org/pdf/2507.05534v1", "cate": "cs.NE", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06109", "title": "LighthouseGS: Indoor Structure-aware 3D Gaussian Splatting for Panorama-Style Mobile Captures", "authors": ["Seungoh Han", "Jaehoon Jang", "Hyunsu Kim", "Jaeheung Surh", "Junhyung Kwak", "Hyowon Ha", "Kyungdon Joo"], "categories": ["cs.GR", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.06109v1", "summary": "Recent advances in 3D Gaussian Splatting (3DGS) have enabled real-time novel\nview synthesis (NVS) with impressive quality in indoor scenes. However,\nachieving high-fidelity rendering requires meticulously captured images\ncovering the entire scene, limiting accessibility for general users. We aim to\ndevelop a practical 3DGS-based NVS framework using simple panorama-style motion\nwith a handheld camera (e.g., mobile device). While convenient, this\nrotation-dominant motion and narrow baseline make accurate camera pose and 3D\npoint estimation challenging, especially in textureless indoor scenes. To\naddress these challenges, we propose LighthouseGS, a novel framework inspired\nby the lighthouse-like sweeping motion of panoramic views. LighthouseGS\nleverages rough geometric priors, such as mobile device camera poses and\nmonocular depth estimation, and utilizes the planar structures often found in\nindoor environments. We present a new initialization method called plane\nscaffold assembly to generate consistent 3D points on these structures,\nfollowed by a stable pruning strategy to enhance geometry and optimization\nstability. Additionally, we introduce geometric and photometric corrections to\nresolve inconsistencies from motion drift and auto-exposure in mobile devices.\nTested on collected real and synthetic indoor scenes, LighthouseGS delivers\nphotorealistic rendering, surpassing state-of-the-art methods and demonstrating\nthe potential for panoramic view synthesis and object placement.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.06109v1", "cate": "cs.GR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05319", "title": "LCDS: A Logic-Controlled Discharge Summary Generation System Supporting Source Attribution and Expert Review", "authors": ["Cheng Yuan", "Xinkai Rui", "Yongqi Fan", "Yawei Fan", "Boyang Zhong", "Jiacheng Wang", "Weiyan Zhang", "Tong Ruan"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL Demo 2025", "url": "http://arxiv.org/abs/2507.05319v1", "summary": "Despite the remarkable performance of Large Language Models (LLMs) in\nautomated discharge summary generation, they still suffer from hallucination\nissues, such as generating inaccurate content or fabricating information\nwithout valid sources. In addition, electronic medical records (EMRs) typically\nconsist of long-form data, making it challenging for LLMs to attribute the\ngenerated content to the sources. To address these challenges, we propose LCDS,\na Logic-Controlled Discharge Summary generation system. LCDS constructs a\nsource mapping table by calculating textual similarity between EMRs and\ndischarge summaries to constrain the scope of summarized content. Moreover,\nLCDS incorporates a comprehensive set of logical rules, enabling it to generate\nmore reliable silver discharge summaries tailored to different clinical fields.\nFurthermore, LCDS supports source attribution for generated content, allowing\nexperts to efficiently review, provide feedback, and rectify errors. The\nresulting golden discharge summaries are subsequently recorded for incremental\nfine-tuning of LLMs. Our project and demo video are in the GitHub repository\nhttps://github.com/ycycyc02/LCDS.", "comment": "ACL Demo 2025", "pdf_url": "http://arxiv.org/pdf/2507.05319v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06204", "title": "Differential Mamba", "authors": ["Nadav Schneider", "Itamar Zimerman", "Eliya Nachmani"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06204v1", "summary": "Sequence models like Transformers and RNNs often overallocate attention to\nirrelevant context, leading to noisy intermediate representations. This\ndegrades LLM capabilities by promoting hallucinations, weakening long-range and\nretrieval abilities, and reducing robustness. Recent work has shown that\ndifferential design can mitigate this issue in Transformers, improving their\neffectiveness across various applications. In this paper, we explore whether\nthese techniques, originally developed for Transformers, can be applied to\nMamba, a recent architecture based on selective state-space layers that\nachieves Transformer-level performance with greater efficiency. We show that a\nnaive adaptation of differential design to Mamba is insufficient and requires\ncareful architectural modifications. To address this, we introduce a novel\ndifferential mechanism for Mamba, empirically validated on language modeling\nbenchmarks, demonstrating improved retrieval capabilities and superior\nperformance over vanilla Mamba. Finally, we conduct extensive ablation studies\nand empirical analyses to justify our design choices and provide evidence that\nour approach effectively mitigates the overallocation problem in Mamba-based\nmodels. Our code is publicly available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06204v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06033", "title": "TextPixs: Glyph-Conditioned Diffusion with Character-Aware Attention and OCR-Guided Supervision", "authors": ["Syeda Anshrah Gillani", "Mirza Samad Ahmed Baig", "Osama Ahmed Khan", "Shahid Munir Shah", "Umema Mujeeb", "Maheen Ali"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      30 pages", "url": "http://arxiv.org/abs/2507.06033v1", "summary": "The modern text-to-image diffusion models boom has opened a new era in\ndigital content production as it has proven the previously unseen ability to\nproduce photorealistic and stylistically diverse imagery based on the semantics\nof natural-language descriptions. However, the consistent disadvantage of these\nmodels is that they cannot generate readable, meaningful, and correctly spelled\ntext in generated images, which significantly limits the use of practical\npurposes like advertising, learning, and creative design. This paper introduces\na new framework, namely Glyph-Conditioned Diffusion with Character-Aware\nAttention (GCDA), using which a typical diffusion backbone is extended by three\nwell-designed modules. To begin with, the model has a dual-stream text encoder\nthat encodes both semantic contextual information and explicit glyph\nrepresentations, resulting in a character-aware representation of the input\ntext that is rich in nature. Second, an attention mechanism that is aware of\nthe character is proposed with a new attention segregation loss that aims to\nlimit the attention distribution of each character independently in order to\navoid distortion artifacts. Lastly, GCDA has an OCR-in-the-loop fine-tuning\nphase, where a full text perceptual loss, directly optimises models to be\nlegible and accurately spell. Large scale experiments to benchmark datasets,\nsuch as MARIO-10M and T2I-CompBench, reveal that GCDA sets a new\nstate-of-the-art on all metrics, with better character based metrics on text\nrendering (Character Error Rate: 0.08 vs 0.21 for the previous best; Word Error\nRate: 0.15 vs 0.25), human perception, and comparable image synthesis quality\non high-fidelity (FID: 14.3).", "comment": "30 pages", "pdf_url": "http://arxiv.org/pdf/2507.06033v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06070", "title": "Contrastive and Transfer Learning for Effective Audio Fingerprinting through a Real-World Evaluation Protocol", "authors": ["Christos Nikou", "Theodoros Giannakopoulos"], "categories": ["cs.SD", "cs.AI", "cs.IR", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      International Journal of Music Science, Technology and Art, 15 pages, 7 figures", "url": "http://arxiv.org/abs/2507.06070v1", "summary": "Recent advances in song identification leverage deep neural networks to learn\ncompact audio fingerprints directly from raw waveforms. While these methods\nperform well under controlled conditions, their accuracy drops significantly in\nreal-world scenarios where the audio is captured via mobile devices in noisy\nenvironments. In this paper, we introduce a novel evaluation protocol designed\nto better reflect such real-world conditions. We generate three recordings of\nthe same audio, each with increasing levels of noise, captured using a mobile\ndevice's microphone. Our results reveal a substantial performance drop for two\nstate-of-the-art CNN-based models under this protocol, compared to previously\nreported benchmarks. Additionally, we highlight the critical role of the\naugmentation pipeline during training with contrastive loss. By introduction\nlow pass and high pass filters in the augmentation pipeline we significantly\nincrease the performance of both systems in our proposed evaluation.\nFurthermore, we develop a transformer-based model with a tailored projection\nmodule and demonstrate that transferring knowledge from a semantically relevant\ndomain yields a more robust solution. The transformer architecture outperforms\nCNN-based models across all noise levels, and query durations. In low noise\nconditions it achieves 47.99% for 1-sec queries, and 97% for 10-sec queries in\nfinding the correct song, surpassing by 14%, and by 18.5% the second-best\nperforming model, respectively, Under heavy noise levels, we achieve a\ndetection rate 56.5% for 15-second query duration. All experiments are\nconducted on public large-scale dataset of over 100K songs, with queries\nmatched against a database of 56 million vectors.", "comment": "International Journal of Music Science, Technology and Art, 15 pages,\n  7 figures", "pdf_url": "http://arxiv.org/pdf/2507.06070v1", "cate": "cs.SD", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2409.09309", "title": "Real-Time Stochastic Terrain Mapping and Processing for Autonomous Safe Landing", "authors": ["Kento Tomita", "Koki Ho"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.09309v2", "summary": "Onboard terrain sensing and mapping for safe planetary landings often suffer\nfrom missed hazardous features, e.g., small rocks, due to the large\nobservational range and the limited resolution of the obtained terrain data. To\nthis end, this paper develops a novel real-time stochastic terrain mapping\nalgorithm that accounts for topographic uncertainty between the sampled points,\nor the uncertainty due to the sparse 3D terrain measurements. We introduce a\nGaussian digital elevation map that is efficiently constructed using the\ncombination of Delauney triangulation and local Gaussian process regression.\nThe geometric investigation of the lander-terrain interaction is exploited to\nefficiently evaluate the marginally conservative local slope and roughness\nwhile avoiding the costly computation of the local plane. The conservativeness\nis proved in the paper. The developed real-time uncertainty quantification\npipeline enables stochastic landing safety evaluation under challenging\noperational conditions, such as a large observational range or limited sensor\ncapability, which is a critical stepping stone for the development of\npredictive guidance algorithms for safe autonomous planetary landing. Detailed\nreviews on background and related works are also presented.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.09309v2", "cate": "eess.IV", "date": "2024-09-14", "updated": "2025-07-07"}
{"id": "2507.05847", "title": "A Universal Framework for Large-Scale Multi-Objective Optimization Based on Particle Drift and Diffusion", "authors": ["Jia-Cheng Li", "Min-Rong Chen", "Guo-Qiang Zeng", "Jian Weng", "Man Wang", "Jia-Lin Mai"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05847v1", "summary": "Large-scale multi-objective optimization poses challenges to existing\nevolutionary algorithms in maintaining the performances of convergence and\ndiversity because of high dimensional decision variables. Inspired by the\nmotion of particles in physics, we propose a universal framework for\nlarge-scale multi-objective optimization based on particle drift and diffusion\nto solve these challenges in this paper. This framework innovatively divides\nthe optimization process into three sub-stages: two coarse-tuning sub-stages\nand one fine-tuning sub-stage. Different strategies of drift-diffusion\noperations are performed on the guiding solutions according to the current\nsub-stage, ingeniously simulating the movement of particles under diverse\nenvironmental conditions. Finally, representative evolutionary algorithms are\nembedded into the proposed framework, and their effectiveness are evaluated\nthrough comparative experiments on various large-scale multi-objective problems\nwith 1000 to 5000 decision variables. Moreover, comparative algorithms are\nconducted on neural network training problems to validate the effectiveness of\nthe proposed framework in the practical problems. The experimental results\ndemonstrate that the framework proposed in this paper significantly enhances\nthe performance of convergence and diversity of MOEAs, and improves the\ncomputational efficiency of algorithms in solving large-scale multi-objective\noptimization problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05847v1", "cate": "cs.NE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05321", "title": "AGACCI : Affiliated Grading Agents for Criteria-Centric Interface in Educational Coding Contexts", "authors": ["Kwangsuk Park", "Jiwoong Yang"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted at ICML 2025 Workshop on Multi-Agent Systems in the Era of Foundation Models: Opportunities, Challenges and Futures (MAS)", "url": "http://arxiv.org/abs/2507.05321v1", "summary": "Recent advances in AI-assisted education have encouraged the integration of\nvision-language models (VLMs) into academic assessment, particularly for tasks\nthat require both quantitative and qualitative evaluation. However, existing\nVLM based approaches struggle with complex educational artifacts, such as\nprogramming tasks with executable components and measurable outputs, that\nrequire structured reasoning and alignment with clearly defined evaluation\ncriteria. We introduce AGACCI, a multi-agent system that distributes\nspecialized evaluation roles across collaborative agents to improve accuracy,\ninterpretability, and consistency in code-oriented assessment. To evaluate the\nframework, we collected 360 graduate-level code-based assignments from 60\nparticipants, each annotated by domain experts with binary rubric scores and\nqualitative feedback. Experimental results demonstrate that AGACCI outperforms\na single GPT-based baseline in terms of rubric and feedback accuracy,\nrelevance, consistency, and coherence, while preserving the instructional\nintent and evaluative depth of expert assessments. Although performance varies\nacross task types, AGACCI highlights the potential of multi-agent systems for\nscalable and context-aware educational evaluation.", "comment": "Accepted at ICML 2025 Workshop on Multi-Agent Systems in the Era of\n  Foundation Models: Opportunities, Challenges and Futures (MAS)", "pdf_url": "http://arxiv.org/pdf/2507.05321v1", "cate": "cs.CY", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06211", "title": "Modern Methods in Associative Memory", "authors": ["Dmitry Krotov", "Benjamin Hoover", "Parikshit Ram", "Bao Pham"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Tutorial at ICML 2025", "url": "http://arxiv.org/abs/2507.06211v1", "summary": "Associative Memories like the famous Hopfield Networks are elegant models for\ndescribing fully recurrent neural networks whose fundamental job is to store\nand retrieve information. In the past few years they experienced a surge of\ninterest due to novel theoretical results pertaining to their information\nstorage capabilities, and their relationship with SOTA AI architectures, such\nas Transformers and Diffusion Models. These connections open up possibilities\nfor interpreting the computation of traditional AI networks through the\ntheoretical lens of Associative Memories. Additionally, novel Lagrangian\nformulations of these networks make it possible to design powerful distributed\nmodels that learn useful representations and inform the design of novel\narchitectures. This tutorial provides an approachable introduction to\nAssociative Memories, emphasizing the modern language and methods used in this\narea of research, with practical hands-on mathematical derivations and coding\nnotebooks.", "comment": "Tutorial at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.06211v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06060", "title": "VisualSpeaker: Visually-Guided 3D Avatar Lip Synthesis", "authors": ["Alexandre Symeonidis-Herzig", "Özge Mercanoğlu Sincan", "Richard Bowden"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06060v1", "summary": "Realistic, high-fidelity 3D facial animations are crucial for expressive\navatar systems in human-computer interaction and accessibility. Although prior\nmethods show promising quality, their reliance on the mesh domain limits their\nability to fully leverage the rapid visual innovations seen in 2D computer\nvision and graphics. We propose VisualSpeaker, a novel method that bridges this\ngap using photorealistic differentiable rendering, supervised by visual speech\nrecognition, for improved 3D facial animation. Our contribution is a perceptual\nlip-reading loss, derived by passing photorealistic 3D Gaussian Splatting\navatar renders through a pre-trained Visual Automatic Speech Recognition model\nduring training. Evaluation on the MEAD dataset demonstrates that VisualSpeaker\nimproves both the standard Lip Vertex Error metric by 56.1% and the perceptual\nquality of the generated animations, while retaining the controllability of\nmesh-driven animation. This perceptual focus naturally supports accurate\nmouthings, essential cues that disambiguate similar manual signs in sign\nlanguage avatars.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06060v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.03022", "title": "A Novel Hybrid Grey Wolf Differential Evolution Algorithm", "authors": ["Ioannis D. Bougas", "Pavlos Doanis", "Maria S. Papadopoulou", "Achilles D. Boursianis", "Sotirios P. Sotiroudis", "Zaharias D. Zaharis", "George Koudouridis", "Panagiotis Sarigiannidis", "Mohammad Abdul Matint", "George Karagiannidis", "Sotirios K. Goudos"], "categories": ["cs.NE", "cs.SY", "eess.SY", "physics.app-ph", "physics.comp-ph", "B.7.1; B.7.2; B.8.2; C.2.1; D.1.0; I.6.3; J.2; J.6"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      19 pages, 32 figures, journal", "url": "http://arxiv.org/abs/2507.03022v2", "summary": "Grey wolf optimizer (GWO) is a nature-inspired stochastic meta-heuristic of\nthe swarm intelligence field that mimics the hunting behavior of grey wolves.\nDifferential evolution (DE) is a popular stochastic algorithm of the\nevolutionary computation field that is well suited for global optimization. In\nthis part, we introduce a new algorithm based on the hybridization of GWO and\ntwo DE variants, namely the GWO-DE algorithm. We evaluate the new algorithm by\napplying various numerical benchmark functions. The numerical results of the\ncomparative study are quite satisfactory in terms of performance and solution\nquality.", "comment": "19 pages, 32 figures, journal", "pdf_url": "http://arxiv.org/pdf/2507.03022v2", "cate": "cs.NE", "date": "2025-07-02", "updated": "2025-07-08"}
{"id": "2507.06116", "title": "Speech Quality Assessment Model Based on Mixture of Experts: System-Level Performance Enhancement and Utterance-Level Challenge Analysis", "authors": ["Xintong Hu", "Yixuan Chen", "Rui Yang", "Wenxiang Guo", "Changhao Pan"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06116v1", "summary": "Automatic speech quality assessment plays a crucial role in the development\nof speech synthesis systems, but existing models exhibit significant\nperformance variations across different granularity levels of prediction tasks.\nThis paper proposes an enhanced MOS prediction system based on self-supervised\nlearning speech models, incorporating a Mixture of Experts (MoE) classification\nhead and utilizing synthetic data from multiple commercial generation models\nfor data augmentation. Our method builds upon existing self-supervised models\nsuch as wav2vec2, designing a specialized MoE architecture to address different\ntypes of speech quality assessment tasks. We also collected a large-scale\nsynthetic speech dataset encompassing the latest text-to-speech, speech\nconversion, and speech enhancement systems. However, despite the adoption of\nthe MoE architecture and expanded dataset, the model's performance improvements\nin sentence-level prediction tasks remain limited. Our work reveals the\nlimitations of current methods in handling sentence-level quality assessment,\nprovides new technical pathways for the field of automatic speech quality\nassessment, and also delves into the fundamental causes of performance\ndifferences across different assessment granularities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06116v1", "cate": "cs.SD", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2409.15031", "title": "Compressive radio-interferometric sensing with random beamforming as rank-one signal covariance projections", "authors": ["Olivier Leblanc", "Yves Wiaux", "Laurent Jacques"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.15031v2", "summary": "Radio-interferometry (RI) observes the sky at unprecedented angular\nresolutions, enabling the study of several far-away galactic objects such as\ngalaxies and black holes. In RI, an array of antennas probes cosmic signals\ncoming from the observed region of the sky. The covariance matrix of the vector\ngathering all these antenna measurements offers, by leveraging the Van\nCittert-Zernike theorem, an incomplete and noisy Fourier sensing of the image\nof interest. The number of noisy Fourier measurements -- or visibilities --\nscales as $\\mathcal O(Q^2B)$ for $Q$ antennas and $B$ short-time integration\n(STI) intervals. We address the challenges posed by this vast volume of data,\nwhich is anticipated to increase significantly with the advent of large antenna\narrays, by proposing a compressive sensing technique applied directly at the\nlevel of the antenna measurements. First, this paper shows that beamforming --\na common technique of dephasing antenna signals -- usually used to focus some\nregion of the sky, is equivalent to sensing a rank-one projection (ROP) of the\nsignal covariance matrix. We build upon our recent work arXiv:2306.12698v3\n[eess.IV] to propose a compressive sensing scheme relying on random\nbeamforming, trading the $Q^2$-dependence of the data size for a smaller number\n$P$ ROPs. We provide image recovery guarantees for sparse image reconstruction.\nSecondly, the data size is made independent of $B$ by applying $M$ Bernoulli\nmodulations of the ROP vectors obtained for the STI. The resulting sample\ncomplexities, theoretically derived in a simpler case without modulations and\nnumerically obtained in phase transition diagrams, are shown to scale as\n$\\mathcal O(K)$ where $K$ is the image sparsity. This illustrates the potential\nof the approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.15031v2", "cate": "eess.IV", "date": "2024-09-23", "updated": "2025-07-07"}
{"id": "2507.06010", "title": "Instance-Optimal Quantum State Certification with Entangled Measurements", "authors": ["Ryan O'Donnell", "Chirag Wadhwa"], "categories": ["quant-ph", "cs.DS", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      27 pages", "url": "http://arxiv.org/abs/2507.06010v1", "summary": "We consider the task of quantum state certification: given a description of a\nhypothesis state $\\sigma$ and multiple copies of an unknown state $\\rho$, a\ntester aims to determine whether the two states are equal or $\\epsilon$-far in\ntrace distance. It is known that $\\Theta(d/\\epsilon^2)$ copies of $\\rho$ are\nnecessary and sufficient for this task, assuming the tester can make entangled\nmeasurements over all copies [CHW07,OW15,BOW19]. However, these bounds are for\na worst-case $\\sigma$, and it is not known what the optimal copy complexity is\nfor this problem on an instance-by-instance basis. While such instance-optimal\nbounds have previously been shown for quantum state certification when the\ntester is limited to measurements unentangled across copies [CLO22,CLHL22],\nthey remained open when testers are unrestricted in the kind of measurements\nthey can perform.\n  We address this open question by proving nearly instance-optimal bounds for\nquantum state certification when the tester can perform fully entangled\nmeasurements. Analogously to the unentangled setting, we show that the optimal\ncopy complexity for certifying $\\sigma$ is given by the worst-case complexity\ntimes the fidelity between $\\sigma$ and the maximally mixed state. We prove our\nlower bounds using a novel quantum analogue of the Ingster-Suslina method,\nwhich is likely to be of independent interest. This method also allows us to\nrecover the $\\Omega(d/\\epsilon^2)$ lower bound for mixedness testing [OW15],\ni.e., certification of the maximally mixed state, with a surprisingly simple\nproof.", "comment": "27 pages", "pdf_url": "http://arxiv.org/pdf/2507.06010v1", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06222", "title": "Deep Learning Optimization of Two-State Pinching Antennas Systems", "authors": ["Odysseas G. Karagiannidis", "Victoria E. Galanopoulou", "Panagiotis D. Diamantoulakis", "Zhiguo Ding", "Octavia Dobre"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06222v1", "summary": "The evolution of wireless communication systems requires flexible,\nenergy-efficient, and cost-effective antenna technologies. Pinching antennas\n(PAs), which can dynamically control electromagnetic wave propagation through\nbinary activation states, have recently emerged as a promising candidate. In\nthis work, we investigate the problem of optimally selecting a subset of\nfixed-position PAs to activate in a waveguide, when the aim is to maximize the\ncommunication rate at a user terminal. Due to the complex interplay between\nantenna activation, waveguide-induced phase shifts, and power division, this\nproblem is formulated as a combinatorial fractional 0-1 quadratic program. To\nefficiently solve this challenging problem, we use neural network architectures\nof varying complexity to learn activation policies directly from data,\nleveraging spatial features and signal structure. Furthermore, we incorporate\nuser location uncertainty into our training and evaluation pipeline to simulate\nrealistic deployment conditions. Simulation results demonstrate the\neffectiveness and robustness of the proposed models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06222v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06071", "title": "MEDTalk: Multimodal Controlled 3D Facial Animation with Dynamic Emotions by Disentangled Embedding", "authors": ["Chang Liu", "Ye Pan", "Chenyang Ding", "Susanto Rahardja", "Xiaokang Yang"], "categories": ["cs.CV", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 8 figures", "url": "http://arxiv.org/abs/2507.06071v1", "summary": "Audio-driven emotional 3D facial animation aims to generate synchronized lip\nmovements and vivid facial expressions. However, most existing approaches focus\non static and predefined emotion labels, limiting their diversity and\nnaturalness. To address these challenges, we propose MEDTalk, a novel framework\nfor fine-grained and dynamic emotional talking head generation. Our approach\nfirst disentangles content and emotion embedding spaces from motion sequences\nusing a carefully designed cross-reconstruction process, enabling independent\ncontrol over lip movements and facial expressions. Beyond conventional\naudio-driven lip synchronization, we integrate audio and speech text,\npredicting frame-wise intensity variations and dynamically adjusting static\nemotion features to generate realistic emotional expressions. Furthermore, to\nenhance control and personalization, we incorporate multimodal inputs-including\ntext descriptions and reference expression images-to guide the generation of\nuser-specified facial expressions. With MetaHuman as the priority, our\ngenerated results can be conveniently integrated into the industrial production\npipeline.", "comment": "11 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.06071v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.02080", "title": "Enhancing GOP in CTC-Based Mispronunciation Detection with Phonological Knowledge", "authors": ["Aditya Kamlesh Parikh", "Cristian Tejedor-Garcia", "Catia Cucchiarini", "Helmer Strik"], "categories": ["eess.AS", "cs.AI"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted to Interspeech 2025. This publication is part of the project Responsible AI for Voice Diagnostics (RAIVD) with file number NGF.1607.22.013 of the research programme NGF AiNed Fellowship Grants which is financed by the Dutch Research Council (NWO)", "url": "http://arxiv.org/abs/2506.02080v2", "summary": "Computer-Assisted Pronunciation Training (CAPT) systems employ automatic\nmeasures of pronunciation quality, such as the goodness of pronunciation (GOP)\nmetric. GOP relies on forced alignments, which are prone to labeling and\nsegmentation errors due to acoustic variability. While alignment-free methods\naddress these challenges, they are computationally expensive and scale poorly\nwith phoneme sequence length and inventory size. To enhance efficiency, we\nintroduce a substitution-aware alignment-free GOP that restricts phoneme\nsubstitutions based on phoneme clusters and common learner errors. We evaluated\nour GOP on two L2 English speech datasets, one with child speech, My\nPronunciation Coach (MPC), and SpeechOcean762, which includes child and adult\nspeech. We compared RPS (restricted phoneme substitutions) and UPS\n(unrestricted phoneme substitutions) setups within alignment-free methods,\nwhich outperformed the baseline. We discuss our results and outline avenues for\nfuture research.", "comment": "Accepted to Interspeech 2025. This publication is part of the project\n  Responsible AI for Voice Diagnostics (RAIVD) with file number NGF.1607.22.013\n  of the research programme NGF AiNed Fellowship Grants which is financed by\n  the Dutch Research Council (NWO)", "pdf_url": "http://arxiv.org/pdf/2506.02080v2", "cate": "eess.AS", "date": "2025-06-02", "updated": "2025-07-08"}
{"id": "2412.09331", "title": "Physics-Driven Autoregressive State Space Models for Medical Image Reconstruction", "authors": ["Bilal Kabas", "Fuat Arslan", "Valiyeh A. Nezhad", "Saban Ozturk", "Emine U. Saritas", "Tolga Çukur"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      14 pages, 11 figures", "url": "http://arxiv.org/abs/2412.09331v2", "summary": "Medical image reconstruction from undersampled acquisitions is an ill-posed\nproblem involving inversion of the imaging operator linking measurement and\nimage domains. Physics-driven (PD) models have gained prominence in\nreconstruction tasks due to their desirable performance and generalization.\nThese models jointly promote data fidelity and artifact suppression, typically\nby combining data-consistency mechanisms with learned network modules. Artifact\nsuppression depends on the network's ability to disentangle artifacts from true\ntissue signals, both of which can exhibit contextual structure across diverse\nspatial scales. Convolutional neural networks (CNNs) are strong in capturing\nlocal correlations, albeit relatively insensitive to non-local context. While\ntransformers promise to alleviate this limitation, practical implementations\nfrequently involve design compromises to reduce computational cost by balancing\nlocal and non-local sensitivity, occasionally resulting in performance\ncomparable to or trailing that of CNNs. To enhance contextual sensitivity\nwithout incurring high complexity, we introduce a novel physics-driven\nautoregressive state-space model (MambaRoll) for medical image reconstruction.\nIn each cascade of its unrolled architecture, MambaRoll employs a\nphysics-driven state-space module (PD-SSM) to aggregate contextual features\nefficiently at a given spatial scale, and autoregressively predicts finer-scale\nfeature maps conditioned on coarser-scale features to capture multi-scale\ncontext. Learning across scales is further enhanced via a deep multi-scale\ndecoding (DMSD) loss tailored to the autoregressive prediction task.\nDemonstrations on accelerated MRI and sparse-view CT reconstructions show that\nMambaRoll consistently outperforms state-of-the-art data-driven and\nphysics-driven methods based on CNN, transformer, and SSM backbones.", "comment": "14 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2412.09331v2", "cate": "eess.IV", "date": "2024-12-12", "updated": "2025-07-08"}
{"id": "2404.12559", "title": "An algorithm with a delay of $\\mathcal{O}(kΔ)$ for enumerating connected induced subgraphs of size $k$", "authors": ["Chenglong Xiao", "Chengyong Mao", "Shanshan Wang"], "categories": ["cs.DS", "cs.DM"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.12559v3", "summary": "The problem of enumerating connected subgraphs of a given size in a graph has\nbeen extensively studied in recent years. In this paper, we propose an\nalgorithm with a delay of $O(k\\Delta)$ for enumerating all connected induced\nsubgraphs of size $k$ in an undirected graph $G=(V, E)$, where $k$ and $\\Delta$\nare respectively the size of subgraphs and the maximum degree of $G$. The\nalgorithm requires a preprocessing step of $O(|V| + |E|)$ time to compute a\ndepth-first search traversal order. The proposed algorithm improves upon the\ncurrent best delay bound $O(k^2\\Delta)$ for the connected induced subgraph\nenumeration problem in the literature.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.12559v3", "cate": "cs.DS", "date": "2024-04-19", "updated": "2025-07-08"}
{"id": "2507.05330", "title": "MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents", "authors": ["Ming Gong", "Xucheng Huang", "Chenghan Yang", "Xianhan Peng", "Haoxin Wang", "Yang Liu", "Ling Jiang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05330v1", "summary": "Recent advances in large language models (LLMs) have enabled new applications\nin e-commerce customer service. However, their capabilities remain constrained\nin complex, multimodal scenarios. We present MindFlow, the first open-source\nmultimodal LLM agent tailored for e-commerce. Built on the CoALA framework, it\nintegrates memory, decision-making, and action modules, and adopts a modular\n\"MLLM-as-Tool\" strategy for effect visual-textual reasoning. Evaluated via\nonline A/B testing and simulation-based ablation, MindFlow demonstrates\nsubstantial gains in handling complex queries, improving user satisfaction, and\nreducing operational costs, with a 93.53% relative improvement observed in\nreal-world deployments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05330v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2506.22521", "title": "A Survey on Model Extraction Attacks and Defenses for Large Language Models", "authors": ["Kaixiang Zhao", "Lincan Li", "Kaize Ding", "Neil Zhenqiang Gong", "Yue Zhao", "Yushun Dong"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.22521v1", "summary": "Model extraction attacks pose significant security threats to deployed\nlanguage models, potentially compromising intellectual property and user\nprivacy. This survey provides a comprehensive taxonomy of LLM-specific\nextraction attacks and defenses, categorizing attacks into functionality\nextraction, training data extraction, and prompt-targeted attacks. We analyze\nvarious attack methodologies including API-based knowledge distillation, direct\nquerying, parameter recovery, and prompt stealing techniques that exploit\ntransformer architectures. We then examine defense mechanisms organized into\nmodel protection, data privacy protection, and prompt-targeted strategies,\nevaluating their effectiveness across different deployment scenarios. We\npropose specialized metrics for evaluating both attack effectiveness and\ndefense performance, addressing the specific challenges of generative language\nmodels. Through our analysis, we identify critical limitations in current\napproaches and propose promising research directions, including integrated\nattack methodologies and adaptive defense mechanisms that balance security with\nmodel utility. This work serves NLP researchers, ML engineers, and security\nprofessionals seeking to protect language models in production environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.22521v1", "cate": "cs.CR", "date": "2025-06-26", "updated": "2025-06-26"}
{"id": "2507.06072", "title": "MCAM: Multimodal Causal Analysis Model for Ego-Vehicle-Level Driving Video Understanding", "authors": ["Tongtong Cheng", "Rongzhen Li", "Yixin Xiong", "Tao Zhang", "Jing Wang", "Kai Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06072v1", "summary": "Accurate driving behavior recognition and reasoning are critical for\nautonomous driving video understanding. However, existing methods often tend to\ndig out the shallow causal, fail to address spurious correlations across\nmodalities, and ignore the ego-vehicle level causality modeling. To overcome\nthese limitations, we propose a novel Multimodal Causal Analysis Model (MCAM)\nthat constructs latent causal structures between visual and language\nmodalities. Firstly, we design a multi-level feature extractor to capture\nlong-range dependencies. Secondly, we design a causal analysis module that\ndynamically models driving scenarios using a directed acyclic graph (DAG) of\ndriving states. Thirdly, we utilize a vision-language transformer to align\ncritical visual features with their corresponding linguistic expressions.\nExtensive experiments on the BDD-X, and CoVLA datasets demonstrate that MCAM\nachieves SOTA performance in visual-language causal relationship learning.\nFurthermore, the model exhibits superior capability in capturing causal\ncharacteristics within video sequences, showcasing its effectiveness for\nautonomous driving applications. The code is available at\nhttps://github.com/SixCorePeach/MCAM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06072v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.11160", "title": "S2ST-Omni: An Efficient Multilingual Speech-to-Speech Translation Framework via Seamless Speech-Text Alignment and Progressive Fine-tuning", "authors": ["Yu Pan", "Yuguang Yang", "Yanni Hu", "Jianhao Ye", "Xiang Zhang", "Hongbin Zhou", "Lei Ma", "Jianjun Zhao"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Working in progress", "url": "http://arxiv.org/abs/2506.11160v5", "summary": "Despite recent advances in multilingual speech-to-speech translation (S2ST),\nseveral critical challenges persist: 1) achieving high-quality translation\nremains a major hurdle, and 2) most existing methods heavily rely on\nlarge-scale parallel speech corpora, which are costly and difficult to obtain.\nTo address these issues, we propose \\textit{S2ST-Omni}, an efficient and\nscalable framework for multilingual S2ST. Specifically, we decompose the S2ST\ntask into speech-to-text translation (S2TT) and text-to-speech synthesis (TTS).\nFor S2TT, we propose an effective speech language model that integrates the\npretrained Whisper encoder for robust audio understanding and Qwen 3.0 for\nadvanced text comprehension. A lightweight speech adapter is employed to bridge\nthe modality gap between speech and text representations. To further facilitate\nthe multimodal knowledge learning, a two-stage fine-tuning strategy is\nintroduced. In the TTS stage, we adopt a streaming autoregressive generation\napproach to produce natural and fluent target speech. Experiments on the CVSS\nbenchmark show that S2ST-Omni consistently outperforms existing\nstate-of-the-art S2ST systems in translation quality, highlighting its\neffectiveness and superiority.", "comment": "Working in progress", "pdf_url": "http://arxiv.org/pdf/2506.11160v5", "cate": "eess.AS", "date": "2025-06-11", "updated": "2025-07-08"}
{"id": "2501.08667", "title": "TimeFlow: Longitudinal Brain Image Registration and Aging Progression Analysis", "authors": ["Bailiang Jian", "Jiazhen Pan", "Yitong Li", "Fabian Bongratz", "Ruochen Li", "Daniel Rueckert", "Benedikt Wiestler", "Christian Wachinger"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.08667v2", "summary": "Predicting future brain states is crucial for understanding healthy aging and\nneurodegenerative diseases. Longitudinal brain MRI registration, a cornerstone\nfor such analyses, has long been limited by its inability to forecast future\ndevelopments, reliance on extensive dense longitudinal data, and the need to\nbalance registration accuracy with temporal smoothness. In this work, we\npresent \\emph{TimeFlow}, a novel framework for longitudinal brain MRI\nregistration that overcomes all these challenges. TimeFlow leverages a U-Net\narchitecture with temporal conditioning inspired by diffusion models, enabling\naccurate registration using only two images as input and facilitating\nprospective analyses through future image prediction. Unlike traditional\nmethods, TimeFlow eliminates the demand for explicit smoothness regularizers\nand dense sequential data while maintaining temporal consistency and\ncontinuity. Experimental results highlight its superior performance in both\nfuture timepoint prediction and registration accuracy compared to\nstate-of-the-art methods. Additionally, TimeFlow supports novel biological\nbrain aging analyses, effectively differentiating neurodegenerative conditions\nfrom healthy aging, all without requiring segmentation, thus avoiding\nnon-trivial annotation and inconsistent segmentation flaws. This framework\npaves the way for accurate, data-efficient, and annotation-free prospective\nanalyses of brain aging and chronic diseases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.08667v2", "cate": "eess.IV", "date": "2025-01-15", "updated": "2025-07-07"}
{"id": "2502.13636", "title": "Semi-Streaming Algorithms for Hypergraph Matching", "authors": ["Henrik Reinstädtler", "S M Ferdous", "Alex Pothen", "Bora Uçar", "Christian Schulz"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.13636v2", "summary": "We propose two one-pass streaming algorithms for the $\\mathcal{NP}$-hard\nhypergraph matching problem. The first algorithm stores a small subset of\npotential matching edges in a stack using dual variables to select edges. It\nhas an approximation guarantee of $\\frac{1}{d(1+\\varepsilon)}$ and requires\n$\\mathcal{O}((\\frac{n}{\\varepsilon}) \\log^2{n})$ bits of memory, where $n$ is\nthe number of vertices in the hypergraph, $d$ is the maximum number of vertices\nin a hyperedge, and $\\epsilon > 0$ is a parameter to be chosen. The second\nalgorithm computes, stores, and updates a single matching as the edges stream,\nwith an approximation ratio dependent on a parameter $\\alpha$. Its best\napproximation guarantee is $\\frac{1}{(2d-1) + 2 \\sqrt{d(d-1)}}$, and it\nrequires only $\\mathcal{O}(n)$ memory.\n  We have implemented both algorithms and compared them with respect to\nsolution quality, memory consumption, and running times on two diverse sets of\nhypergraphs with a non-streaming greedy and a naive streaming algorithm. Our\nresults show that the streaming algorithms achieve much better solution quality\nthan naive algorithms when facing adverse orderings. Furthermore, these\nalgorithms reduce the memory required by a factor of 13 in the geometric mean\non our test problems, and also outperform the offline Greedy algorithm in\nrunning time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.13636v2", "cate": "cs.DS", "date": "2025-02-19", "updated": "2025-07-07"}
{"id": "2312.12491", "title": "StreamDiffusion: A Pipeline-level Solution for Real-time Interactive Generation", "authors": ["Akio Kodaira", "Chenfeng Xu", "Toshiki Hazama", "Takanori Yoshimoto", "Kohei Ohno", "Shogo Mitsuhori", "Soichi Sugano", "Hanying Cho", "Zhijian Liu", "Masayoshi Tomizuka", "Kurt Keutzer"], "categories": ["cs.CV", "cs.GR", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      tech report, the code is available at this https URL", "url": "http://arxiv.org/abs/2312.12491v2", "summary": "We introduce StreamDiffusion, a real-time diffusion pipeline designed for\ninteractive image generation. Existing diffusion models are adept at creating\nimages from text or image prompts, yet they often fall short in real-time\ninteraction. This limitation becomes particularly evident in scenarios\ninvolving continuous input, such as Metaverse, live video streaming, and\nbroadcasting, where high throughput is imperative. To address this, we present\na novel approach that transforms the original sequential denoising into the\nbatching denoising process. Stream Batch eliminates the conventional\nwait-and-interact approach and enables fluid and high throughput streams. To\nhandle the frequency disparity between data input and model throughput, we\ndesign a novel input-output queue for parallelizing the streaming process.\nMoreover, the existing diffusion pipeline uses classifier-free guidance(CFG),\nwhich requires additional U-Net computation. To mitigate the redundant\ncomputations, we propose a novel residual classifier-free guidance (RCFG)\nalgorithm that reduces the number of negative conditional denoising steps to\nonly one or even zero. Besides, we introduce a stochastic similarity\nfilter(SSF) to optimize power consumption. Our Stream Batch achieves around\n1.5x speedup compared to the sequential denoising method at different denoising\nlevels. The proposed RCFG leads to speeds up to 2.05x higher than the\nconventional CFG. Combining the proposed strategies and existing mature\nacceleration tools makes the image-to-image generation achieve up-to 91.07fps\non one RTX4090, improving the throughputs of AutoPipline developed by Diffusers\nover 59.56x. Furthermore, our proposed StreamDiffusion also significantly\nreduces the energy consumption by 2.39x on one RTX3060 and 1.99x on one\nRTX4090, respectively.", "comment": "tech report, the code is available at\n  https://github.com/cumulo-autumn/StreamDiffusion", "pdf_url": "http://arxiv.org/pdf/2312.12491v2", "cate": "cs.CV", "date": "2023-12-19", "updated": "2025-07-08"}
{"id": "2507.05725", "title": "Multi-patch/multiple-scattering frequency-time hybrid solver for interior and exterior wave equation problems", "authors": ["Shuai Pan", "Gang Bao", "Tao Yin", "Oscar P. Bruno"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      28 pages, 17 figures", "url": "http://arxiv.org/abs/2507.05725v1", "summary": "This paper proposes a new multiple-scattering frequency-time hybrid (FTH-MS)\nintegral equation solver for problems of wave scattering by obstacles in two\ndimensional space, including interior problems in closed cavities and problems\nexterior to a set of disconnected open or closed scattering obstacles. The\nmultiple-scattering FTH-MS method is based on a partition of the domain\nboundary into a user-prescribed set of overlapping open arcs, along with a\ncorresponding sequence of multiple-scattering problems that effectively\ndecompose the interior problem into a series of open-arc wave equation\nsubproblems. The new strategy provides a significant extension of the original\nFTH-MS algorithm originally presented in [22], in that (1) By allowing for use\nof an arbitrary of number of component arcs, and not just two as in the\nprevious contribution, the new approach affords (1a) A significantly increased\ngeometric flexibility, as well as, (1b) The use of partitions for which each\nopen arc leads to small numbers of iterations if iterative linear-algebra\nsolvers are employed; and, (2) It facilitates parallelization -- as the\nsubproblem solutions that are needed at each multiple scattering step can be\nevaluated in an embarrassingly parallel fashion. Utilizing a\nsuitably-implemented Fourier transformation, each sub-problem is reduced to a\nHelmholtz frequency-domain problem that is tackled via a uniquely-solvable\nboundary integral equation. Similar FTH-MS methods are also presented for\nproblems exterior to a number of bounded obstacles. All of the algorithms\nconsidered incorporate the previously introduced ``time-windowing and\nrecentering'' methodology (that enables both treatment of incident signals of\nlong duration and long time simulation), as well as a high-frequency Fourier\ntransform algorithm that delivers numerically dispersionless,\nspectrally-accurate time evolution for arbitrarily long times.", "comment": "28 pages, 17 figures", "pdf_url": "http://arxiv.org/pdf/2507.05725v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05261", "title": "TokenShapley: Token Level Context Attribution with Shapley Value", "authors": ["Yingtai Xiao", "Yuqing Zhu", "Sirat Samyoun", "Wanrong Zhang", "Jiachen T. Wang", "Jian Du"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05261v1", "summary": "Large language models (LLMs) demonstrate strong capabilities in in-context\nlearning, but verifying the correctness of their generated responses remains a\nchallenge. Prior work has explored attribution at the sentence level, but these\nmethods fall short when users seek attribution for specific keywords within the\nresponse, such as numbers, years, or names. To address this limitation, we\npropose TokenShapley, a novel token-level attribution method that combines\nShapley value-based data attribution with KNN-based retrieval techniques\ninspired by recent advances in KNN-augmented LLMs. By leveraging a precomputed\ndatastore for contextual retrieval and computing Shapley values to quantify\ntoken importance, TokenShapley provides a fine-grained data attribution\napproach. Extensive evaluations on four benchmarks show that TokenShapley\noutperforms state-of-the-art baselines in token-level attribution, achieving an\n11-23% improvement in accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05261v1", "cate": "cs.CL", "date": "2025-06-18", "updated": "2025-06-18"}
{"id": "2507.06075", "title": "Discontinuity-aware Normal Integration for Generic Central Camera Models", "authors": ["Francesco Milano", "Manuel López-Antequera", "Naina Dhingra", "Roland Siegwart", "Robert Thiel"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      18 pages, 13 figures, 8 tables", "url": "http://arxiv.org/abs/2507.06075v1", "summary": "Recovering a 3D surface from its surface normal map, a problem known as\nnormal integration, is a key component for photometric shape reconstruction\ntechniques such as shape-from-shading and photometric stereo. The vast majority\nof existing approaches for normal integration handle only implicitly the\npresence of depth discontinuities and are limited to orthographic or ideal\npinhole cameras. In this paper, we propose a novel formulation that allows\nmodeling discontinuities explicitly and handling generic central cameras. Our\nkey idea is based on a local planarity assumption, that we model through\nconstraints between surface normals and ray directions. Compared to existing\nmethods, our approach more accurately approximates the relation between depth\nand surface normals, achieves state-of-the-art results on the standard normal\nintegration benchmark, and is the first to directly handle generic central\ncamera models.", "comment": "18 pages, 13 figures, 8 tables", "pdf_url": "http://arxiv.org/pdf/2507.06075v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.12067", "title": "Evaluating Logit-Based GOP Scores for Mispronunciation Detection", "authors": ["Aditya Kamlesh Parikh", "Cristian Tejedor-Garcia", "Catia Cucchiarini", "Helmer Strik"], "categories": ["eess.AS", "cs.AI", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted to Interspeech 2025. This publication is part of the project Responsible AI for Voice Diagnostics (RAIVD) with file number NGF.1607.22.013 of the research programme NGF AiNed Fellowship Grants which is financed by the Dutch Research Council (NWO)", "url": "http://arxiv.org/abs/2506.12067v2", "summary": "Pronunciation assessment relies on goodness of pronunciation (GOP) scores,\ntraditionally derived from softmax-based posterior probabilities. However,\nposterior probabilities may suffer from overconfidence and poor phoneme\nseparation, limiting their effectiveness. This study compares logit-based GOP\nscores with probability-based GOP scores for mispronunciation detection. We\nconducted our experiment on two L2 English speech datasets spoken by Dutch and\nMandarin speakers, assessing classification performance and correlation with\nhuman ratings. Logit-based methods outperform probability-based GOP in\nclassification, but their effectiveness depends on dataset characteristics. The\nmaximum logit GOP shows the strongest alignment with human perception, while a\ncombination of different GOP scores balances probability and logit features.\nThe findings suggest that hybrid GOP methods incorporating uncertainty modeling\nand phoneme-specific weighting improve pronunciation assessment.", "comment": "Accepted to Interspeech 2025. This publication is part of the project\n  Responsible AI for Voice Diagnostics (RAIVD) with file number NGF.1607.22.013\n  of the research programme NGF AiNed Fellowship Grants which is financed by\n  the Dutch Research Council (NWO)", "pdf_url": "http://arxiv.org/pdf/2506.12067v2", "cate": "eess.AS", "date": "2025-06-02", "updated": "2025-07-08"}
{"id": "2504.11286", "title": "Lightweight Medical Image Restoration via Integrating Reliable Lesion-Semantic Driven Prior", "authors": ["Pengcheng Zheng", "Kecheng Chen", "Jiaxin Huang", "Bohao Chen", "Ju Liu", "Yazhou Ren", "Xiaorong Pu"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.11286v2", "summary": "Medical image restoration tasks aim to recover high-quality images from\ndegraded observations, exhibiting emergent desires in many clinical scenarios,\nsuch as low-dose CT image denoising, MRI super-resolution, and MRI artifact\nremoval. Despite the success achieved by existing deep learning-based\nrestoration methods with sophisticated modules, they struggle with rendering\ncomputationally-efficient reconstruction results. Moreover, they usually ignore\nthe reliability of the restoration results, which is much more urgent in\nmedical systems. To alleviate these issues, we present LRformer, a Lightweight\nTransformer-based method via Reliability-guided learning in the frequency\ndomain. Specifically, inspired by the uncertainty quantification in Bayesian\nneural networks (BNNs), we develop a Reliable Lesion-Semantic Prior Producer\n(RLPP). RLPP leverages Monte Carlo (MC) estimators with stochastic sampling\noperations to generate sufficiently-reliable priors by performing multiple\ninferences on the foundational medical image segmentation model, MedSAM.\nAdditionally, instead of directly incorporating the priors in the spatial\ndomain, we decompose the cross-attention (CA) mechanism into real symmetric and\nimaginary anti-symmetric parts via fast Fourier transform (FFT), resulting in\nthe design of the Guided Frequency Cross-Attention (GFCA) solver. By leveraging\nthe conjugated symmetric property of FFT, GFCA reduces the computational\ncomplexity of naive CA by nearly half. Extensive experimental results in\nvarious tasks demonstrate the superiority of the proposed LRformer in both\neffectiveness and efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.11286v2", "cate": "eess.IV", "date": "2025-04-15", "updated": "2025-07-08"}
{"id": "2502.16193", "title": "Testing whether a subgraph is convex or isometric", "authors": ["Sergio Cabello"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      19 pages, 5 figures; compared to v1, more relevant references and minor editions", "url": "http://arxiv.org/abs/2502.16193v2", "summary": "We consider the following two algorithmic problems: given a graph $G$ and a\nsubgraph $H\\subseteq G$, decide whether $H$ is an isometric or a geodesically\nconvex subgraph of $G$. It is relatively easy to see that the problems can be\nsolved by computing the distances between all pairs of vertices. We provide a\nconditional lower bound showing that, for sparse graphs with $n$ vertices and\n$\\Theta(n)$ edges, we cannot expect to solve the problem in\n$O(n^{2-\\varepsilon})$ time for any constant $\\varepsilon>0$. We also show that\nthe problem can be solved in subquadratic time for planar graphs and in\nnear-linear time for graphs of bounded treewidth. Finally, we provide a\nnear-linear time algorithm for the setting where $G$ is a plane graph and $H$\nis defined by a few cycles in $G$.", "comment": "19 pages, 5 figures; compared to v1, more relevant references and\n  minor editions", "pdf_url": "http://arxiv.org/pdf/2502.16193v2", "cate": "cs.DS", "date": "2025-02-22", "updated": "2025-07-07"}
{"id": "2507.02803", "title": "HyperGaussians: High-Dimensional Gaussian Splatting for High-Fidelity Animatable Face Avatars", "authors": ["Gent Serifi", "Marcel C. Bühler"], "categories": ["cs.CV", "cs.GR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL , Code: this https URL", "url": "http://arxiv.org/abs/2507.02803v2", "summary": "We introduce HyperGaussians, a novel extension of 3D Gaussian Splatting for\nhigh-quality animatable face avatars. Creating such detailed face avatars from\nvideos is a challenging problem and has numerous applications in augmented and\nvirtual reality. While tremendous successes have been achieved for static\nfaces, animatable avatars from monocular videos still fall in the uncanny\nvalley. The de facto standard, 3D Gaussian Splatting (3DGS), represents a face\nthrough a collection of 3D Gaussian primitives. 3DGS excels at rendering static\nfaces, but the state-of-the-art still struggles with nonlinear deformations,\ncomplex lighting effects, and fine details. While most related works focus on\npredicting better Gaussian parameters from expression codes, we rethink the 3D\nGaussian representation itself and how to make it more expressive. Our insights\nlead to a novel extension of 3D Gaussians to high-dimensional multivariate\nGaussians, dubbed 'HyperGaussians'. The higher dimensionality increases\nexpressivity through conditioning on a learnable local embedding. However,\nsplatting HyperGaussians is computationally expensive because it requires\ninverting a high-dimensional covariance matrix. We solve this by\nreparameterizing the covariance matrix, dubbed the 'inverse covariance trick'.\nThis trick boosts the efficiency so that HyperGaussians can be seamlessly\nintegrated into existing models. To demonstrate this, we plug in HyperGaussians\ninto the state-of-the-art in fast monocular face avatars: FlashAvatar. Our\nevaluation on 19 subjects from 4 face datasets shows that HyperGaussians\noutperform 3DGS numerically and visually, particularly for high-frequency\ndetails like eyeglass frames, teeth, complex facial movements, and specular\nreflections.", "comment": "Project page: https://gserifi.github.io/HyperGaussians, Code:\n  https://github.com/gserifi/HyperGaussians", "pdf_url": "http://arxiv.org/pdf/2507.02803v2", "cate": "cs.CV", "date": "2025-07-03", "updated": "2025-07-08"}
{"id": "2507.05301", "title": "News Source Citing Patterns in AI Search Systems", "authors": ["Kai-Cheng Yang"], "categories": ["cs.IR", "cs.CL", "cs.CY"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      15 pages, 7 figures", "url": "http://arxiv.org/abs/2507.05301v1", "summary": "AI-powered search systems are emerging as new information gatekeepers,\nfundamentally transforming how users access news and information. Despite their\ngrowing influence, the citation patterns of these systems remain poorly\nunderstood. We address this gap by analyzing data from the AI Search Arena, a\nhead-to-head evaluation platform for AI search systems. The dataset comprises\nover 24,000 conversations and 65,000 responses from models across three major\nproviders: OpenAI, Perplexity, and Google. Among the over 366,000 citations\nembedded in these responses, 9% reference news sources. We find that while\nmodels from different providers cite distinct news sources, they exhibit shared\npatterns in citation behavior. News citations concentrate heavily among a small\nnumber of outlets and display a pronounced liberal bias, though low-credibility\nsources are rarely cited. User preference analysis reveals that neither the\npolitical leaning nor the quality of cited news sources significantly\ninfluences user satisfaction. These findings reveal significant challenges in\ncurrent AI search systems and have important implications for their design and\ngovernance.", "comment": "15 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.05301v1", "cate": "cs.IR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05743", "title": "A direct PinT algorithm for higher-order nonlinear equations", "authors": ["Shun-Zhi Zhong", "Yong-Liang Zhao"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      18 pages", "url": "http://arxiv.org/abs/2507.05743v1", "summary": "This paper mainly studies a direct time-parallel algorithm for solving\ntime-dependent differential equations of order 1 to 3. Different from the\ntraditional time-stepping approach, we directly solve the all-at-once system\nfrom higher-order evolution equations by diagonalization the time\ndiscretization matrix $B$. Based on the connection between the characteristic\nequation and Chebyshev polynomials, we give explicit formulas for the\neigenvector matrix $V$ of $B$ and its inverse $V^{-1}$ , and prove that\n$cond_2\\left( V \\right) =\\mathcal{O} \\left( n^3 \\right)$, where $n$ is the\nnumber of time steps. A fast algorithm $B$ designed by exploring the structure\nof the spectral decomposition of $B$. Numerical experiments were performed to\nvalidate the acceleration performance of the fast spectral decomposition\nalgorithm. The results show that the proposed fast algorithm achieves\nsignificant computational speedup.", "comment": "18 pages", "pdf_url": "http://arxiv.org/pdf/2507.05743v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05346", "title": "LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks", "authors": ["William Fleshman", "Benjamin Van Durme"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05346v1", "summary": "The proliferation of fine-tuned language model experts for specific tasks and\ndomains signals the need for efficient selection and combination methods. We\npropose LoRA-Augmented Generation (LAG) for leveraging large libraries of\nknowledge and task-specific LoRA adapters. LAG requires no additional training\nor access to data, and efficiently filters, retrieves, and applies experts on a\nper-token and layer basis. We evaluate LAG on various knowledge-intensive\ntasks, achieving superior performance over existing data-free methods. We\nexplore scenarios where additional data is available, demonstrating LAG's\ncompatibility with alternative solutions such as retrieval-augmented generation\n(RAG).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05346v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05265", "title": "BMFM-DNA: A SNP-aware DNA foundation model to capture variant effects", "authors": ["Hongyang Li", "Sanjoy Dey", "Bum Chul Kwon", "Michael Danziger", "Michal Rosen-Tzvi", "Jianying Hu", "James Kozloski", "Ching-Huei Tsou", "Bharath Dandala", "Pablo Meyer"], "categories": ["q-bio.GN", "cs.LG"], "primary_category": "Subjects:       Genomics (q-bio.GN)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05265v1", "summary": "Large language models (LLMs) trained on text demonstrated remarkable results\non natural language processing (NLP) tasks. These models have been adapted to\ndecipher the language of DNA, where sequences of nucleotides act as \"words\"\nthat encode genomic functions. However, the genome differs fundamentally from\nnatural language, as it lacks clearly defined words or a consistent grammar.\nAlthough DNA language models (DNALMs) such as DNABERT, GENA-LM have achieved\nhigh level of performance on genome-related biological tasks, these models do\nnot encode biological functions in the presence of sequence variations. To\naddress this problem, we pre-train foundation models that effectively integrate\nsequence variations, in particular Single Nucleotide Polymorphisms (SNPs), as\nthey underlie important biological functions. Specifically, we use ModernBERT\nto pre-train two different Biomedical Foundation Models (BMFM), namely,\nBMFM-DNA-REF in which the model is trained with sequences of varying lengths\nalong with their reverse complements derived from the reference genome and\nBMFM-DNA-SNP in which the model is trained with sequences created using a novel\nrepresentation scheme that encodes sequence variations. Our findings indicate\nthat integrating sequence variations into DNALMs helps capture the biological\nfunctions as seen in improvements on all fine-tuning tasks. To explore the\nmodel's practical utility, we experimented with various strategies for SNP\nimputation on promoter detection task introduced in DNABERT-2. However, we\nacknowledge that the current benchmarks are limited in their ability to fully\nevaluate these models. To enable more comprehensive assessment in the future\nand encourage community contributions, we release our models through\nHuggingFace and the code to reproduce the results at\nhttps://github.com/BiomedSciAI/biomed-multi-omic", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05265v1", "cate": "q-bio.GN", "date": "2025-06-26", "updated": "2025-06-26"}
{"id": "2507.06078", "title": "ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models", "authors": ["Chihan Huang", "Hao Tang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06078v1", "summary": "Despite the success of deep learning across various domains, it remains\nvulnerable to adversarial attacks. Although many existing adversarial attack\nmethods achieve high success rates, they typically rely on $\\ell_{p}$-norm\nperturbation constraints, which do not align with human perceptual\ncapabilities. Consequently, researchers have shifted their focus toward\ngenerating natural, unrestricted adversarial examples (UAEs). GAN-based\napproaches suffer from inherent limitations, such as poor image quality due to\ninstability and mode collapse. Meanwhile, diffusion models have been employed\nfor UAE generation, but they still rely on iterative PGD perturbation\ninjection, without fully leveraging their central denoising capabilities. In\nthis paper, we introduce a novel approach for generating UAEs based on\ndiffusion models, named ScoreAdv. This method incorporates an interpretable\nadversarial guidance mechanism to gradually shift the sampling distribution\ntowards the adversarial distribution, while using an interpretable saliency map\nto inject the visual information of a reference image into the generated\nsamples. Notably, our method is capable of generating an unlimited number of\nnatural adversarial examples and can attack not only classification models but\nalso retrieval models. We conduct extensive experiments on ImageNet and CelebA\ndatasets, validating the performance of ScoreAdv across ten target models in\nboth black-box and white-box settings. Our results demonstrate that ScoreAdv\nachieves state-of-the-art attack success rates and image quality. Furthermore,\nthe dynamic balance between denoising and adversarial perturbation enables\nScoreAdv to remain robust even under defensive measures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06078v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.01348", "title": "SpeechAccentLLM: A Unified Framework for Foreign Accent Conversion and Text to Speech", "authors": ["Zhuangfei Cheng", "Guangyan Zhang", "Zehai Tu", "Yangyang Song", "Shuiyang Mao", "Xiaoqi Jiao", "Jingyu Li", "Yiwen Guo", "Jiasong Wu"], "categories": ["eess.AS", "cs.SD", "I.2.7"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      10 pages, includes references, 4 figures, 4 tables", "url": "http://arxiv.org/abs/2507.01348v2", "summary": "Foreign accent conversion (FAC) in speech processing remains a challenging\ntask. Building on the remarkable success of large language models (LLMs) in\nText-to-Speech (TTS) tasks, this study investigates the adaptation of LLM-based\ntechniques for FAC, which we term SpeechAccentLLM. At the core of this\nframework, we introduce SpeechCodeVAE, the first model to integrate\nconnectionist temporal classification (CTC) directly into codebook\ndiscretization for speech content tokenization. This novel architecture\ngenerates tokens with a unique \"locality\" property, as validated by experiments\ndemonstrating optimal trade-offs among content faithfulness, temporal\ncoherence, and structural recoverability. Then, to address data scarcity for\nthe FAC module, we adopted a multitask learning strategy that jointly trains\nthe FAC and TTS modules. Beyond mitigating data limitations, this approach\nyielded accelerated convergence and superior speech quality compared to\nstandalone FAC training. Moreover, leveraging the salient properties of our\ndiscrete speech representations, we introduce SpeechRestorer, a postprocessing\narchitecture designed to refine LLM-generated outputs. This module effectively\nmitigates stochastic errors prevalent in LLM inference pipelines while\nenhancing prosodic continuity, as validated by ablation experiments.", "comment": "10 pages, includes references, 4 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.01348v2", "cate": "eess.AS", "date": "2025-07-02", "updated": "2025-07-08"}
{"id": "2507.04473", "title": "Tight Guarantees for Cut-Relative Survivable Network Design via a Decomposition Technique", "authors": ["Nikhil Kumar", "JJ Nan", "Chaitanya Swamy"], "categories": ["cs.DS", "F.2.2; G.2"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04473v2", "summary": "In the classical \\emph{survivable-network-design problem} (SNDP), we are\ngiven an undirected graph $G = (V, E)$, non-negative edge costs, and some\n$(s_i,t_i,r_i)$ tuples, where $s_i,t_i\\in V$ and $r_i\\in\\mathbb{Z}_+$. We seek\na minimum-cost subset $H \\subseteq E$ such that each $s_i$-$t_i$ pair remains\nconnected even if any $r_i-1$ edges fail. It is well-known that SNDP can be\nequivalently modeled using a weakly-supermodular \\emph{cut-requirement\nfunction} $f$, where we seek a minimum-cost edge-set containing at least $f(S)$\nedges across every cut $S \\subseteq V$.\n  Recently, Dinitz et al. proposed a variant of SNDP that enforces a\n\\emph{relative} level of fault tolerance with respect to $G$, where the goal is\nto find a solution $H$ that is at least as fault-tolerant as $G$ itself. They\nformalize this in terms of paths and fault-sets, which gives rise to\n\\emph{path-relative SNDP}. Along these lines, we introduce a new model of\nrelative network design, called \\emph{cut-relative SNDP} (CR-SNDP), where the\ngoal is to select a minimum-cost subset of edges that satisfies the given\n(weakly-supermodular) cut-requirement function to the maximum extent possible,\ni.e., by picking $\\min\\{f(S),|\\delta_G(S)|\\}$ edges across every cut\n$S\\subseteq V$.\n  Unlike SNDP, the cut-relative and path-relative versions of SNDP are not\nequivalent. The resulting cut-requirement function for CR-SNDP (as also\npath-relative SNDP) is not weakly supermodular, and extreme-point solutions to\nthe natural LP-relaxation need not correspond to a laminar family of tight cut\nconstraints. Consequently, standard techniques cannot be used directly to\ndesign approximation algorithms for this problem. We develop a \\emph{novel\ndecomposition technique} to circumvent this difficulty and use it to give a\n\\emph{tight $2$-approximation algorithm for CR-SNDP}. We also show new hardness\nresults for these relative-SNDP problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04473v2", "cate": "cs.DS", "date": "2025-07-06", "updated": "2025-07-08"}
{"id": "2507.05931", "title": "Exploring Gain-Doped-Waveguide-Synapse for Neuromorphic Applications: A Pulsed Pump-Signal Approach", "authors": ["Robert Otupiri", "Ripalta Stabile"], "categories": ["physics.optics", "cs.NE", "B.3; B.7; I.2; I.5; J.2"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      13 pages, 11 figures", "url": "http://arxiv.org/abs/2507.05931v1", "summary": "Neuromorphic computing promises to transform AI systems by enabling them to\nperceive, respond to, and adapt swiftly and accurately to dynamic data and user\ninteractions. However, traditional silicon-based and hybrid electronic\ntechnologies for artificial neurons constrain neuromorphic processors in terms\nof flexibility, scalability, and energy efficiency. In this study, we pioneer\nthe use of Doped-Gain-Layer-on-Waveguide-Synapses for bio-inspired neurons,\nutilizing a pulsed pump-signal mechanism to enhance neuromorphic computation.\nThis approach addresses critical challenges in scalability and energy\nefficiency inherent in current technologies.\n  We introduce the concept of Gain on Waveguide Dynamics for synapses,\ndemonstrating how non-linear pulse transformations of input probe signals occur\nunder various pump-probe configurations. Our findings reveal that primarily\nproperties of pulse amplitude, period as well material properties such as\ndoping densities and population dynamics influence strongly the generation of\nspiking responses that emulate neuronal behaviour and effectively how\ncomputational logic is. By harnessing the complex interactions of asynchronous\nspiking pump techniques and ion densities in excited states, our method\nproduces event-driven responses that mirror natural neuronal functions. This\ngain-enhanced environment supports short-term memory capabilities alongside\nessential characteristics like asynchronous spike generation, threshold\noperation, and temporal integration, foundational to brain-inspired spiking\nneural network paradigms.", "comment": "13 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.05931v1", "cate": "physics.optics", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05747", "title": "Regularized boundary integral equation methods for open-arc scattering problems in thermoelasticity", "authors": ["Yixuan X. Kong", "José Pinto", "Tao Yin"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05747v1", "summary": "This paper devotes to developing novel boundary integral equation (BIE)\nsolvers for the problem of thermoelastic scattering by open-arcs with four\ndifferent boundary conditions in two dimensions. The proposed methodology is\ninspired by the Calder\\'on formulas, whose eigenvalues are shown to accumulate\nat particular points depending only on Lam\\'e parameters, satisfied by the\nthermoelastic boundary integral operators (BIOs) on both closed- and\nopen-surfaces. Regularized BIEs in terms of weighted BIOs on open-arc that\nexplicitly exhibits the edge singularity behavior, depending on the types of\nboundary conditions, of the unknown potentials are constructed to effectively\nreduce the required iteration number to solve the corresponding discretized\nlinear systems. We implement the new formulations utilizing regularizations of\nsingular integrals, which reduces the strongly- and hyper-singular integrals\ninto weakly-singular integrals. Combined with spectrally accurate quadrature\nrules, numerical examples are presented to illustrate the accuracy and\nefficiency of the proposed solvers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05747v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05362", "title": "On the Bias of Next-Token Predictors Toward Systematically Inefficient Reasoning: A Shortest-Path Case Study", "authors": ["Riccardo Alberghi", "Elizaveta Demyanenko", "Luca Biggio", "Luca Saglietti"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05362v1", "summary": "Recent advances in natural language processing highlight two key factors for\nimproving reasoning in large language models (LLMs): (i) allocating more\ntest-time compute tends to help on harder problems but often introduces\nredundancy in the reasoning trace, and (ii) compute is most effective when\nreasoning is systematic and incremental, forming structured chains of thought\n(CoTs) akin to human problem-solving. To study these factors in isolation, we\nintroduce a controlled setting based on shortest-path tasks in layered graphs.\nWe train decoder-only transformers on question-trace-answer triples using a\ncustom tokenizer, comparing models trained on optimal bottom-up dynamic\nprogramming traces with those trained on longer, valid traces involving\nbacktracking. Surprisingly, with the same training-token budget, models trained\non inefficient traces generalize better to unseen graphs. This benefit is not\ndue to length alone-injecting arbitrary redundancy into reasoning traces fails\nto help and can even hurt performance. Instead, we find that generalization\ncorrelates with the model's confidence in next-token prediction, suggesting\nthat long, coherent, and locally incremental traces make the training signal\neasier to optimize.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05362v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06080", "title": "CAST-Phys: Contactless Affective States Through Physiological signals Database", "authors": ["Joaquim Comas", "Alexander Joel Vera", "Xavier Vives", "Eleonora De Filippi", "Alexandre Pereda", "Federico Sukno"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06080v1", "summary": "In recent years, affective computing and its applications have become a\nfast-growing research topic. Despite significant advancements, the lack of\naffective multi-modal datasets remains a major bottleneck in developing\naccurate emotion recognition systems. Furthermore, the use of contact-based\ndevices during emotion elicitation often unintentionally influences the\nemotional experience, reducing or altering the genuine spontaneous emotional\nresponse. This limitation highlights the need for methods capable of extracting\naffective cues from multiple modalities without physical contact, such as\nremote physiological emotion recognition. To address this, we present the\nContactless Affective States Through Physiological Signals Database\n(CAST-Phys), a novel high-quality dataset explicitly designed for multi-modal\nremote physiological emotion recognition using facial and physiological cues.\nThe dataset includes diverse physiological signals, such as\nphotoplethysmography (PPG), electrodermal activity (EDA), and respiration rate\n(RR), alongside high-resolution uncompressed facial video recordings, enabling\nthe potential for remote signal recovery. Our analysis highlights the crucial\nrole of physiological signals in realistic scenarios where facial expressions\nalone may not provide sufficient emotional information. Furthermore, we\ndemonstrate the potential of remote multi-modal emotion recognition by\nevaluating the impact of individual and fused modalities, showcasing its\neffectiveness in advancing contactless emotion recognition technologies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06080v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2502.17380", "title": "Low-Rank and Sparse Model Merging for Multi-Lingual Speech Recognition and Translation", "authors": ["Qiuming Zhao", "Guangzhi Sun", "Chao Zhang"], "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      13 pages", "url": "http://arxiv.org/abs/2502.17380v3", "summary": "Language diversity presents a significant challenge in speech-to-text (S2T)\ntasks, such as automatic speech recognition and translation. Traditional\nmulti-lingual multi-task training approaches aim to address this by jointly\noptimising multiple speech recognition and translation tasks across various\nlanguages. While models like Whisper, built on these strategies, demonstrate\nstrong performance, they still face issues of high computational cost, language\ninterference, suboptimal training configurations, and limited extensibility. To\novercome these challenges, we introduce LoRS-Merging (low-rank and sparse model\nmerging), a novel technique designed to efficiently integrate models trained on\ndifferent languages or tasks while preserving performance and reducing\ncomputational overhead. LoRS-Merging combines low-rank and sparse pruning to\nretain essential structures while eliminating redundant parameters, mitigating\nlanguage interference, and enhancing extensibility. Experimental results across\n10 languages demonstrate that LoRS-Merging significantly outperforms\nmulti-lingual multi-task training, sequential training, and other merging\nmethods, achieving over 20% improvement in normalised performance. Our findings\nsuggest that model merging, particularly LoRS-Merging, is a scalable and\neffective complement to traditional multi-lingual training strategies for S2T\napplications.", "comment": "13 pages", "pdf_url": "http://arxiv.org/pdf/2502.17380v3", "cate": "cs.SD", "date": "2025-02-24", "updated": "2025-07-08"}
{"id": "2507.00582", "title": "Bridging Classical and Learning-based Iterative Registration through Deep Equilibrium Models", "authors": ["Yi Zhang", "Yidong Zhao", "Qian Tao"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Submitted version. Accepted by MICCAI 2025", "url": "http://arxiv.org/abs/2507.00582v2", "summary": "Deformable medical image registration is traditionally formulated as an\noptimization problem. While classical methods solve this problem iteratively,\nrecent learning-based approaches use recurrent neural networks (RNNs) to mimic\nthis process by unrolling the prediction of deformation fields in a fixed\nnumber of steps. However, classical methods typically converge after sufficient\niterations, but learning-based unrolling methods lack a theoretical convergence\nguarantee and show instability empirically. In addition, unrolling methods have\na practical bottleneck at training time: GPU memory usage grows linearly with\nthe unrolling steps due to backpropagation through time (BPTT). To address both\ntheoretical and practical challenges, we propose DEQReg, a novel registration\nframework based on Deep Equilibrium Models (DEQ), which formulates registration\nas an equilibrium-seeking problem, establishing a natural connection between\nclassical optimization and learning-based unrolling methods. DEQReg maintains\nconstant memory usage, enabling theoretically unlimited iteration steps.\nThrough extensive evaluation on the public brain MRI and lung CT datasets, we\nshow that DEQReg can achieve competitive registration performance, while\nsubstantially reducing memory consumption compared to state-of-the-art\nunrolling methods. We also reveal an intriguing phenomenon: the performance of\nexisting unrolling methods first increases slightly then degrades irreversibly\nwhen the inference steps go beyond the training configuration. In contrast,\nDEQReg achieves stable convergence with its inbuilt equilibrium-seeking\nmechanism, bridging the gap between classical optimization-based and modern\nlearning-based registration methods.", "comment": "Submitted version. Accepted by MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.00582v2", "cate": "eess.IV", "date": "2025-07-01", "updated": "2025-07-08"}
{"id": "2507.04551", "title": "Greedy Dynamic Matching", "authors": ["Nick Arnosti", "Felipe Simon"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04551v2", "summary": "We study a foundational model of dynamic matching market with abandonment.\nThis model has been studied by Collina et al (2020) and Aouad and Saritac\n(2022), and many other papers have considered special cases. We compare the\nperformance of greedy policies -- which identify a set of \"acceptable\" matches\nup front, and perform these matches as soon as possible -- to that of an\nomniscient benchmark which knows the full arrival and departure sequence.\n  We use a novel family of linear programs ($LP^{ALG}$) to identify which\ngreedy policy to follow. We show that the value of $LP^{ALG}$ is a *lower\nbound* on the value of the greedy policy that it identifies in two settings of\ninterest:\n  -When all types have the same departure rate.\n  -The bipartite case where types on the same side of the market have the same\ndeparture rate.\n  The proofs of these results use a new result (Lemma 1), which relates the\n*probability* that at least one agent from a set of types is present in the\nsystem to the expected number of such agents.\n  We also show that the value of $LP^{ALG}$ is at least 1/2 of the reward rate\nearned by the omniscient policy (Proposition 4). Therefore, for both settings\nabove, our greedy policy provably earns at least half of the omniscient reward\nrate. This improves upon the bound of 1/8 from Collina (2020). In both settings\nour competitive ratio of 1/2 is the best possible: no online policy can provide\na better guarantee (Theorem 2).\n  To show these results we introduce a new linear program that upper bounds the\nobjective value of the omniscient policy (Proposition 3). This improves upon\nthe upper bounds presented by Collina et al (2020) and Kessel et al (2022).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04551v2", "cate": "cs.DS", "date": "2025-07-06", "updated": "2025-07-08"}
{"id": "2507.05577", "title": "Beyond Retrieval: Ensembling Cross-Encoders and GPT Rerankers with LLMs for Biomedical QA", "authors": ["Shashank Verma", "Fengyi Jiang", "Xiangning Xue"], "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Paper submitted to CLEF 2025 CEUR-WS", "url": "http://arxiv.org/abs/2507.05577v1", "summary": "Biomedical semantic question answering rooted in information retrieval can\nplay a crucial role in keeping up to date with vast, rapidly evolving and\never-growing biomedical literature. A robust system can help researchers,\nhealthcare professionals and even layman users access relevant knowledge\ngrounded in evidence. The BioASQ 2025 Task13b Challenge serves as an important\nbenchmark, offering a competitive platform for advancement of this space. This\npaper presents the methodologies and results from our participation in this\nchallenge where we built a Retrieval-Augmented Generation (RAG) system that can\nanswer biomedical questions by retrieving relevant PubMed documents and\nsnippets to generate answers. For the retrieval task, we generated dense\nembeddings from biomedical articles for initial retrieval, and applied an\nensemble of finetuned cross-encoders and large language models (LLMs) for\nre-ranking to identify top relevant documents. Our solution achieved an MAP@10\nof 0.1581, placing 10th on the leaderboard for the retrieval task. For answer\ngeneration, we employed few-shot prompting of instruction-tuned LLMs. Our\nsystem achieved macro-F1 score of 0.95 for yes/no questions (rank 12), Mean\nReciprocal Rank (MRR) of 0.64 for factoid questions (rank 1), mean-F1 score of\n0.63 for list questions (rank 5), and ROUGE-SU4 F1 score of 0.29 for ideal\nanswers (rank 11).", "comment": "Paper submitted to CLEF 2025 CEUR-WS", "pdf_url": "http://arxiv.org/pdf/2507.05577v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05773", "title": "On the detection of medium inhomogeneity by contrast agent: wave scattering models and numerical implementations", "authors": ["Zhe Wang", "Ahcene Ghandriche", "Jijun Liu"], "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      24 pages,15 figures", "url": "http://arxiv.org/abs/2507.05773v1", "summary": "We consider the wave scattering and inverse scattering in an inhomogeneous\nmedium embedded a homogeneous droplet with a small size, which is modeled by a\nconstant mass density and a small bulk modulus. Based on the Lippmann-Schwinger\nintegral equation for scattering wave in inhomogeneous medium, we firstly\ndevelop an efficient approximate scheme for computing the scattered wave as\nwell as its far-field pattern for any droplet located in the inhomogeneous\nbackground medium. By establishing the approximate relation between the\nfar-field patterns of the scattered wave before and after the injection of a\ndroplet, the scattered wave of the inhomogeneous medium after injecting the\ndroplet is represented by a measurable far-field patterns, and consequently the\ninhomogeneity of the medium can be reconstructed from the Helmholtz equation.\nFinally, the reconstruction process in terms of the dual reciprocity method is\nproposed to realize the numerical algorithm for recovering the bulk modulus\nfunction inside a bounded domain in three dimensional space, by moving the\ndroplet inside the bounded domain. Numerical implementations are given using\nthe simulation data of the far-field pattern to show the validity of the\nreconstruction scheme, based on the mollification scheme for dealing with the\nill-posedness of this inverse problem.", "comment": "24 pages,15 figures", "pdf_url": "http://arxiv.org/pdf/2507.05773v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06093", "title": "Tile-Based ViT Inference with Visual-Cluster Priors for Zero-Shot Multi-Species Plant Identification", "authors": ["Murilo Gustineli", "Anthony Miyaguchi", "Adrian Cheung", "Divyansh Khattak"], "categories": ["cs.CV", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06093v1", "summary": "We describe DS@GT's second-place solution to the PlantCLEF 2025 challenge on\nmulti-species plant identification in vegetation quadrat images. Our pipeline\ncombines (i) a fine-tuned Vision Transformer ViTD2PC24All for patch-level\ninference, (ii) a 4x4 tiling strategy that aligns patch size with the network's\n518x518 receptive field, and (iii) domain-prior adaptation through PaCMAP +\nK-Means visual clustering and geolocation filtering. Tile predictions are\naggregated by majority vote and re-weighted with cluster-specific Bayesian\npriors, yielding a macro-averaged F1 of 0.348 (private leaderboard) while\nrequiring no additional training. All code, configuration files, and\nreproducibility scripts are publicly available at\nhttps://github.com/dsgt-arc/plantclef-2025.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06093v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2505.11079", "title": "ALLM4ADD: Unlocking the Capabilities of Audio Large Language Models for Audio Deepfake Detection", "authors": ["Hao Gu", "Jiangyan Yi", "Chenglong Wang", "Jianhua Tao", "Zheng Lian", "Jiayi He", "Yong Ren", "Yujie Chen", "Zhengqi Wen"], "categories": ["cs.SD", "cs.CL", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted by ACMMM 2025", "url": "http://arxiv.org/abs/2505.11079v2", "summary": "Audio deepfake detection (ADD) has grown increasingly important due to the\nrise of high-fidelity audio generative models and their potential for misuse.\nGiven that audio large language models (ALLMs) have made significant progress\nin various audio processing tasks, a heuristic question arises: \\textit{Can\nALLMs be leveraged to solve ADD?}. In this paper, we first conduct a\ncomprehensive zero-shot evaluation of ALLMs on ADD, revealing their\nineffectiveness. To this end, we propose ALLM4ADD, an ALLM-driven framework for\nADD. Specifically, we reformulate ADD task as an audio question answering\nproblem, prompting the model with the question: ``Is this audio fake or\nreal?''. We then perform supervised fine-tuning to enable the ALLM to assess\nthe authenticity of query audio. Extensive experiments are conducted to\ndemonstrate that our ALLM-based method can achieve superior performance in fake\naudio detection, particularly in data-scarce scenarios. As a pioneering study,\nwe anticipate that this work will inspire the research community to leverage\nALLMs to develop more effective ADD systems. Code is available at\nhttps://github.com/ucas-hao/qwen_audio_for_add.git", "comment": "Accepted by ACMMM 2025", "pdf_url": "http://arxiv.org/pdf/2505.11079v2", "cate": "cs.SD", "date": "2025-05-16", "updated": "2025-07-08"}
{"id": "2410.05001", "title": "Quantum property testing in sparse directed graphs", "authors": ["Simon Apers", "Frédéric Magniez", "Sayantan Sen", "Dániel Szabó"], "categories": ["quant-ph", "cs.DS"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      34 pages. Added overview of our results. Accepted in RANDOM 25", "url": "http://arxiv.org/abs/2410.05001v2", "summary": "We initiate the study of quantum property testing in sparse directed graphs,\nand more particularly in the unidirectional model, where the algorithm is\nallowed to query only the outgoing edges of a vertex. In the classical\nunidirectional model, the problem of testing $k$-star-freeness, and more\ngenerally $k$-source-subgraph-freeness, is almost maximally hard for large $k$.\nWe prove that this problem has almost quadratic advantage in the quantum\nsetting. Moreover, we show that this advantage is nearly tight, by showing a\nquantum lower bound using the method of dual polynomials on an intermediate\nproblem for a new, property testing version of the $k$-collision problem that\nwas not studied before.\n  To illustrate that not all problems in graph property testing admit such a\nquantum speedup, we consider the problem of $3$-colorability in the related\nundirected bounded-degree model, when graphs are now undirected. This problem\nis maximally hard to test classically, and we show that also quantumly it\nrequires a linear number of queries.", "comment": "34 pages. Added overview of our results. Accepted in RANDOM 25", "pdf_url": "http://arxiv.org/pdf/2410.05001v2", "cate": "quant-ph", "date": "2024-10-07", "updated": "2025-07-08"}
{"id": "2507.05715", "title": "From ID-based to ID-free: Rethinking ID Effectiveness in Multimodal Collaborative Filtering Recommendation", "authors": ["Guohao Li", "Li Jing", "Jia Wu", "Xuefei Li", "Kai Zhu", "Yue He"], "categories": ["cs.IR", "cs.MM"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      ACM MM'25 (Experimental supplementary version)", "url": "http://arxiv.org/abs/2507.05715v1", "summary": "Most existing multimodal collaborative filtering recommendation (MCFRec)\nmethods rely heavily on ID features and multimodal content to enhance\nrecommendation performance. However, this paper reveals that ID features are\neffective but have limited benefits in multimodal collaborative filtering\nrecommendation. Therefore, this paper systematically deconstruct the pros and\ncons of ID features: (i) they provide initial embedding but lack semantic\nrichness, (ii) they provide a unique identifier for each user and item but\nhinder generalization to untrained data, and (iii) they assist in aligning and\nfusing multimodal features but may lead to representation shift. Based on these\ninsights, this paper proposes IDFREE, an ID-free multimodal collaborative\nFiltering REcommEndation baseline. IDFREE replaces ID features with multimodal\nfeatures and positional encodings to generate semantically meaningful ID-free\nembeddings. For ID-free multimodal collaborative filtering, it further proposes\nan adaptive similarity graph module to construct dynamic user-user and\nitem-item graphs based on multimodal features. Then, an augmented user-item\ngraph encoder is proposed to construct more effective user and item encoding.\nFinally, IDFREE achieves inter-multimodal alignment based on the contrastive\nlearning and uses Softmax loss as recommendation loss. Basic experiments on\nthree public datasets demonstrate that IDFREE outperforms existing ID-based\nMCFRec methods, achieving an average performance gain of 72.24% across standard\nmetrics (Recall@5, 10, 20, 50 and NDCG@5, 10, 20, 50). Exploratory and extended\nexperiments further validate our findings on the limitations of ID features in\nMCFRec. The code is released at https://github.com/G-H-Li/IDFREE.", "comment": "ACM MM'25 (Experimental supplementary version)", "pdf_url": "http://arxiv.org/pdf/2507.05715v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05774", "title": "A nonsmooth extension of the Brezzi-Rappaz-Raviart approximation theorem via metric regularity techniques and applications to nonlinear PDEs", "authors": ["Jules Berry", "Olivier Ley", "Francisco José Silva"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05774v1", "summary": "We generalize the Brezzi-Rappaz-Raviart approximation theorem, which allows\nto obtain existence and a priori error estimates for approximations of\nsolutions to some nonlinear partial differential equations. Our contribution\nlies in the fact that we typically allow for nonlinearities having merely\nLipschitz regularity, while previous results required some form of\ndifferentiability. This is achieved by making use of the theory of metrically\nregular mappings, developed in the context of variational analysis. We apply\nthis generalization to derive some quasi-optimal error estimates for finite\nelement approximations to solutions of viscous Hamilton-Jacobi equations and\nsecond order mean field games systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05774v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05391", "title": "Controlling What You Share: Assessing Language Model Adherence to Privacy Preferences", "authors": ["Guillem Ramírez", "Alexandra Birch", "Ivan Titov"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05391v1", "summary": "Large language models (LLMs) are primarily accessed via commercial APIs, but\nthis often requires users to expose their data to service providers. In this\npaper, we explore how users can stay in control of their data by using privacy\nprofiles: simple natural language instructions that say what should and should\nnot be revealed. We build a framework where a local model uses these\ninstructions to rewrite queries, only hiding details deemed sensitive by the\nuser, before sending them to an external model, thus balancing privacy with\nperformance. To support this research, we introduce PEEP, a multilingual\ndataset of real user queries annotated to mark private content and paired with\nsynthetic privacy profiles. Our experiments with lightweight LLMs show they can\nfollow these instructions to some extent, but also face consistent challenges,\nhighlighting the need for models that better understand and comply with\nuser-defined privacy preferences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05391v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05303", "title": "The Neural Networks with Tensor Weights and the Corresponding Fermionic Quantum Field Theory", "authors": ["Guojun Huang", "Kai Zhou"], "categories": ["hep-th", "cond-mat.dis-nn", "cs.LG", "hep-ph"], "primary_category": "Subjects:       High Energy Physics - Theory (hep-th)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05303v1", "summary": "In this paper, we establish a theoretical connection between complex-valued\nneural networks (CVNNs) and fermionic quantum field theory (QFT), bridging a\nfundamental gap in the emerging framework of neural network quantum field\ntheory (NN-QFT). While prior NN-QFT works have linked real-valued architectures\nto bosonic fields, we demonstrate that CVNNs equipped with tensor-valued\nweights intrinsically generate fermionic quantum fields. By promoting\nhidden-to-output weights to Clifford algebra-valued tensors, we induce\nanticommutation relations essential for fermionic statistics. Through\nanalytical study of the generating functional, we obtain the exact quantum\nstate in the infinite-width limit, revealing that the parameters between the\ninput layer and the last hidden layer correspond to the eigenvalues of the\nquantum system, and the tensor weighting parameters in the hidden-to-output\nlayer map to dynamical fermionic fields. The continuum limit reproduces free\nfermion correlators, with diagrammatic expansions confirming anticommutation.\nThe work provides the first explicit mapping from neural architectures to\nfermionic QFT at the level of correlation functions and generating functional.\nIt extends NN-QFT beyond bosonic theories and opens avenues for encoding\nfermionic symmetries into machine learning models, with potential applications\nin quantum simulation and lattice field theory.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05303v1", "cate": "hep-th", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06103", "title": "Reflections Unlock: Geometry-Aware Reflection Disentanglement in 3D Gaussian Splatting for Photorealistic Scenes Rendering", "authors": ["Jiayi Song", "Zihan Ye", "Qingyuan Zhou", "Weidong Yang", "Ben Fei", "Jingyi Xu", "Ying He", "Wanli Ouyang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06103v1", "summary": "Accurately rendering scenes with reflective surfaces remains a significant\nchallenge in novel view synthesis, as existing methods like Neural Radiance\nFields (NeRF) and 3D Gaussian Splatting (3DGS) often misinterpret reflections\nas physical geometry, resulting in degraded reconstructions. Previous methods\nrely on incomplete and non-generalizable geometric constraints, leading to\nmisalignment between the positions of Gaussian splats and the actual scene\ngeometry. When dealing with real-world scenes containing complex geometry, the\naccumulation of Gaussians further exacerbates surface artifacts and results in\nblurred reconstructions. To address these limitations, in this work, we propose\nRef-Unlock, a novel geometry-aware reflection modeling framework based on 3D\nGaussian Splatting, which explicitly disentangles transmitted and reflected\ncomponents to better capture complex reflections and enhance geometric\nconsistency in real-world scenes. Our approach employs a dual-branch\nrepresentation with high-order spherical harmonics to capture high-frequency\nreflective details, alongside a reflection removal module providing pseudo\nreflection-free supervision to guide clean decomposition. Additionally, we\nincorporate pseudo-depth maps and a geometry-aware bilateral smoothness\nconstraint to enhance 3D geometric consistency and stability in decomposition.\nExtensive experiments demonstrate that Ref-Unlock significantly outperforms\nclassical GS-based reflection methods and achieves competitive results with\nNeRF-based models, while enabling flexible vision foundation models (VFMs)\ndriven reflection editing. Our method thus offers an efficient and\ngeneralizable solution for realistic rendering of reflective scenes. Our code\nis available at https://ref-unlock.github.io/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06103v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.03343", "title": "SHNU Multilingual Conversational Speech Recognition System for INTERSPEECH 2025 MLC-SLM Challenge", "authors": ["Yuxiang Mei", "Yuang Zheng", "Dongxing Xu", "Yanhua Long"], "categories": ["cs.CL", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by Interspeech 2025 MLC-SLM workshop", "url": "http://arxiv.org/abs/2507.03343v2", "summary": "This paper describes SHNU multilingual conversational speech recognition\nsystem (SHNU-mASR, team name-\"maybe\"), submitted to Track 1 of the INTERSPEECH\n2025 MLC-SLM Challenge. Our system integrates a parallel-speech-encoder\narchitecture with a large language model (LLM) to form a unified multilingual\nASR framework. The parallel-speech-encoder consists of two pre-trained\nencoders, the Whisper-large-v3 encoder and mHuBERT-147 encoder. Their output\nembeddings are concatenated and fed into the LLM, enabling the model to\nleverage complementary acoustic and linguistic knowledge and achieve\ncompetitive performance. Moreover, we adopt a tri-stage training strategy to\njointly update the low-rank adaptation modules and projector parameters of both\nthe speech encoders and the LLM. In addition, we incorporate an additional\nlanguage-aware prompt at the LLM input to enhance language-specific text\ngeneration. The SHNU-mASR system achieves an overall character/word error rate\n(CER/WER) of 11.76% on the blind evaluation set of the challenge, outperforming\nthe official MLC-SLM baseline by 8.41 absolute CER/WER, without increasing the\nbaseline training data.", "comment": "Accepted by Interspeech 2025 MLC-SLM workshop", "pdf_url": "http://arxiv.org/pdf/2507.03343v2", "cate": "cs.CL", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2411.18702", "title": "Random Walks with Tweedie: A Unified View of Score-Based Diffusion Models", "authors": ["Chicago Y. Park", "Michael T. McCann", "Cristina Garcia-Cardona", "Brendt Wohlberg", "Ulugbek S. Kamilov"], "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.18702v2", "summary": "We present a concise derivation for several influential score-based diffusion\nmodels that relies on only a few textbook results. Diffusion models have\nrecently emerged as powerful tools for generating realistic, synthetic signals\n-- particularly natural images -- and often play a role in state-of-the-art\nalgorithms for inverse problems in image processing. While these algorithms are\noften surprisingly simple, the theory behind them is not, and multiple complex\ntheoretical justifications exist in the literature. Here, we provide a simple\nand largely self-contained theoretical justification for score-based diffusion\nmodels that is targeted towards the signal processing community. This approach\nleads to generic algorithmic templates for training and generating samples with\ndiffusion models. We show that several influential diffusion models correspond\nto particular choices within these templates and demonstrate that alternative,\nmore straightforward algorithmic choices can provide comparable results. This\napproach has the added benefit of enabling conditional sampling without any\nlikelihood approximation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.18702v2", "cate": "cs.CV", "date": "2024-11-27", "updated": "2025-07-07"}
{"id": "2507.00059", "title": "Verification of Hamiltonian Path Conjecture (BHR Conjecture) for Integers up to p=31 based on one random multiset per FP", "authors": ["Ranjan N Naik"], "categories": ["cs.DM", "cs.DS", "math.CO"], "primary_category": "Subjects:       Discrete Mathematics (cs.DM)", "pdf_link": null, "comments": "Comments:      This is a result an improvement over by Mariusz Meszka for all primes up to 23 (included) with the aid of a computer", "url": "http://arxiv.org/abs/2507.00059v2", "summary": "The BHR (Buratti-Horak-Rosa) Conjecture (2006) proposes that for every p and\na multiset L of (p-1) positive integers modulo p, there exists a Hamiltonian\npath in the Complete Graph Kp with consecutive edge lengths given by the\nelements of L. In this article, we outline an approach to the conjecture based\non frequency partitions and local/global adjustment operations and\nbacktracking. We describe the mathematical strategy, experimental evidence, and\nimplementation in a Python Program to explore valid Hamiltonian paths p < 37.\nThis is a result an improvement over by Mariusz Meszka for all primes up to 23\n(included) with the aid of a computer.", "comment": "This is a result an improvement over by Mariusz Meszka for all primes\n  up to 23 (included) with the aid of a computer", "pdf_url": "http://arxiv.org/pdf/2507.00059v2", "cate": "cs.DM", "date": "2025-06-26", "updated": "2025-07-07"}
{"id": "2507.06082", "title": "evortran: a modern Fortran package for genetic algorithms with applications from LHC data fitting to LISA signal reconstruction", "authors": ["Thomas Biekötter"], "categories": ["hep-ph", "cs.NE", "physics.comp-ph"], "primary_category": "Subjects:       High Energy Physics - Phenomenology (hep-ph)", "pdf_link": null, "comments": "Comments:      66 pages, 13 figures", "url": "http://arxiv.org/abs/2507.06082v1", "summary": "evortran is a modern Fortran library designed for high-performance genetic\nalgorithms and evolutionary optimization. evortran can be used to tackle a wide\nrange of problems in high-energy physics and beyond, such as derivative-free\nparameter optimization, complex search taks, parameter scans and fitting\nexperimental data under the presence of instrumental noise. The library is\nbuilt as an fpm package with flexibility and efficiency in mind, while also\noffering a simple installation process, user interface and integration into\nexisting Fortran programs. evortran offers a variety of selection, crossover,\nmutation and elitism strategies, with which users can tailor an evolutionary\nalgorithm to their specific needs. evortran supports different abstraction\nlevels: from operating directly on individuals and populations, to running full\nevolutionary cycles, and even enabling migration between independently evolving\npopulations to enhance convergence and maintain diversity. In this paper, we\npresent the functionality of the evortran library, demonstrate its capabilities\nwith example benchmark applications, and compare its performance with existing\ngenetic algorithm frameworks. As physics-motivated applications, we use\nevortran to confront extended Higgs sectors with LHC data and to reconstruct\ngravitational wave spectra and the underlying physical parameters from LISA\nmock data, demonstrating its effectiveness in realistic, data-driven scenarios.", "comment": "66 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.06082v1", "cate": "hep-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05733", "title": "When Transformers Meet Recommenders: Integrating Self-Attentive Sequential Recommendation with Fine-Tuned LLMs", "authors": ["Kechen Liu"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05733v1", "summary": "Self-Attentive Sequential Recommendation (SASRec) effectively captures\nlong-term user preferences by applying attention mechanisms to historical\ninteractions. Concurrently, the rise of Large Language Models (LLMs) has\nmotivated research into LLM-based recommendation, which leverages their\npowerful generalization and language understanding capabilities. However, LLMs\noften lack the domain-specific knowledge and collaborative signals essential\nfor high-quality recommendations when relying solely on textual prompts. To\naddress this limitation, this study proposes SASRecLLM, a novel framework that\nintegrates SASRec as a collaborative encoder with an LLM fine-tuned using\nLow-Rank Adaptation (LoRA). The components are connected via a mapping layer to\nalign their dimensional spaces, and three targeted training strategies are\ndesigned to optimize the hybrid architecture. Extensive experiments on multiple\ndatasets demonstrate that SASRecLLM achieves robust and consistent improvements\nover strong baselines in both cold-start and warm-start scenarios. This work\nadvances the field of LLM-based recommendation by presenting a modular and\neffective paradigm for fusing structured collaborative filtering with the\nsemantic power of fine-tuned LLMs. The implementation is available on GitHub:\nhttps://github.com/kechenkristin/RecLLM", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05733v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05776", "title": "A generalized Hessian-based error estimator for an IPDG formulation of the biharmonic problem in two dimensions", "authors": ["Théophile Chaumont-Frelet", "Joscha Gedicke", "Lorenzo Mascotto"], "categories": ["math.NA", "cs.NA", "65N12, 65N30, 65N50"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05776v1", "summary": "We consider a two dimensional biharmonic problem and its discretization by\nmeans of a symmetric interior penalty discontinuous Galerkin method. Based on\nthe ``div-div'' complex, a novel split of an error measure based on a\ngeneralized Hessian into two terms measuring the conformity and nonconformity\nof the scheme is proven. This splitting is the departing point for the design\nof a new reliable and efficient error estimator, which does not involve any DG\nstabilization. Such an error estimator can be bounded from above by the\nstandard DG residual error estimator. Numerical results assess the theoretical\npredictions, including the efficiency of the proposed estimator.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05776v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06119", "title": "Omni-Video: Democratizing Unified Video Understanding and Generation", "authors": ["Zhiyu Tan", "Hao Yang", "Luozheng Qin", "Jia Gong", "Mengping Yang", "Hao Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Technical report, project page: this https URL", "url": "http://arxiv.org/abs/2507.06119v1", "summary": "Notable breakthroughs in unified understanding and generation modeling have\nled to remarkable advancements in image understanding, reasoning, production\nand editing, yet current foundational models predominantly focus on processing\nimages, creating a gap in the development of unified models for video\nunderstanding and generation. This report presents Omni-Video, an efficient and\neffective unified framework for video understanding, generation, as well as\ninstruction-based editing. Our key insight is to teach existing multimodal\nlarge language models (MLLMs) to produce continuous visual clues that are used\nas the input of diffusion decoders, which produce high-quality videos\nconditioned on these visual clues. To fully unlock the potential of our system\nfor unified video modeling, we integrate several technical improvements: 1) a\nlightweight architectural design that respectively attaches a vision head on\nthe top of MLLMs and a adapter before the input of diffusion decoders, the\nformer produce visual tokens for the latter, which adapts these visual tokens\nto the conditional space of diffusion decoders; and 2) an efficient multi-stage\ntraining scheme that facilitates a fast connection between MLLMs and diffusion\ndecoders with limited data and computational resources. We empirically\ndemonstrate that our model exhibits satisfactory generalization abilities\nacross video generation, editing and understanding tasks.", "comment": "Technical report, project page:\n  https://sais-fuxi.github.io/Omni-Video/", "pdf_url": "http://arxiv.org/pdf/2507.06119v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.04554", "title": "Self-supervised learning of speech representations with Dutch archival data", "authors": ["Nik Vaessen", "Roeland Ordelman", "David A. van Leeuwen"], "categories": ["cs.SD", "cs.CL", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      accepted at interspeech 2025", "url": "http://arxiv.org/abs/2507.04554v2", "summary": "This paper explores the use of Dutch archival television broadcast data for\nself-supervised learning of speech foundation models, specifically wav2vec 2.0.\nWe first study data quality assumptions for pre-training, and show how music,\nnoise and speaker overlap affect SSL convergence and downstream fine-tuning\nperformance. Secondly, we explore effectively pre-processing strategies to\nconvert the noisy broadcast dataset into a qualitative dataset for\npre-training, by using Whisper and WhisperX. Thirdly, we compare mono-lingual\nand multi-lingual pre-training with equivalent amounts of data, and show that\nmono-lingual pre-training is more robust to out-of-domain data. Lastly, we\nachieve a state-of-the-art LARGE wav2vec 2.0 model for the Dutch language, by a\ncontinuation of pre-training a wav2vec 2.0 XLS-R model checkpoint with our 55k\nhour archival dataset.", "comment": "accepted at interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.04554v2", "cate": "cs.SD", "date": "2025-07-06", "updated": "2025-07-08"}
{"id": "2502.04468", "title": "Iterative Importance Fine-tuning of Diffusion Models", "authors": ["Alexander Denker", "Shreyas Padhy", "Francisco Vargas", "Johannes Hertrich"], "categories": ["cs.LG", "eess.IV", "math.PR", "68T07", "I.4.9; I.2.6"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.04468v2", "summary": "Diffusion models are an important tool for generative modelling, serving as\neffective priors in applications such as imaging and protein design. A key\nchallenge in applying diffusion models for downstream tasks is efficiently\nsampling from resulting posterior distributions, which can be addressed using\nthe $h$-transform. This work introduces a self-supervised algorithm for\nfine-tuning diffusion models by estimating the $h$-transform, enabling\namortised conditional sampling. Our method iteratively refines the\n$h$-transform using a synthetic dataset resampled with path-based importance\nweights. We demonstrate the effectiveness of this framework on\nclass-conditional sampling, inverse problems and reward fine-tuning for\ntext-to-image diffusion models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.04468v2", "cate": "cs.LG", "date": "2025-02-06", "updated": "2025-07-08"}
{"id": "2507.06148", "title": "SoftReMish: A Novel Activation Function for Enhanced Convolutional Neural Networks for Visual Recognition Performance", "authors": ["Mustafa Bayram Gücen"], "categories": ["cs.CV", "cs.AI", "cs.NE"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06148v1", "summary": "In this study, SoftReMish, a new activation function designed to improve the\nperformance of convolutional neural networks (CNNs) in image classification\ntasks, is proposed. Using the MNIST dataset, a standard CNN architecture\nconsisting of two convolutional layers, max pooling, and fully connected layers\nwas implemented. SoftReMish was evaluated against popular activation functions\nincluding ReLU, Tanh, and Mish by replacing the activation function in all\ntrainable layers. The model performance was assessed in terms of minimum\ntraining loss and maximum validation accuracy. Results showed that SoftReMish\nachieved a minimum loss (3.14e-8) and a validation accuracy (99.41%),\noutperforming all other functions tested. These findings demonstrate that\nSoftReMish offers better convergence behavior and generalization capability,\nmaking it a promising candidate for visual recognition tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06148v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05767", "title": "Vers un cadre ontologique pour la gestion des comp{é}tences : {à} des fins de formation, de recrutement, de m{é}tier, ou de recherches associ{é}es", "authors": ["Ngoc Luyen Le", "Marie-Hélène Abel", "Bertrand Laforge"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      in French language. 36es Journ{é}es francophones d'Ing{é}nierie des Connaissances (IC 2025) @ Plate-Forme Intelligence Artificielle (PFIA 2025), Jul 2025, Dijon, France", "url": "http://arxiv.org/abs/2507.05767v1", "summary": "The rapid transformation of the labor market, driven by technological\nadvancements and the digital economy, requires continuous competence\ndevelopment and constant adaptation. In this context, traditional competence\nmanagement systems lack interoperability, adaptability, and semantic\nunderstanding, making it difficult to align individual competencies with labor\nmarket needs and training programs. This paper proposes an ontology-based\nframework for competence management, enabling a structured representation of\ncompetencies, occupations, and training programs. By leveraging ontological\nmodels and semantic reasoning, this framework aims to enhance the automation of\ncompetence-to-job matching, the personalization of learning recommendations,\nand career planning. This study discusses the design, implementation, and\npotential applications of the framework, focusing on competence training\nprograms, job searching, and finding competent individuals.", "comment": "in French language. 36es Journ{\\'e}es francophones d'Ing{\\'e}nierie\n  des Connaissances (IC 2025) @ Plate-Forme Intelligence Artificielle (PFIA\n  2025), Jul 2025, Dijon, France", "pdf_url": "http://arxiv.org/pdf/2507.05767v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05779", "title": "A relaxation scheme for the equations of isentropic gas dynamics on a network with jump transmission conditions", "authors": ["Magali Ribot", "Roberto Natalini", "Maya Briani"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05779v1", "summary": "In this paper we propose a new numerical scheme of relaxation type to\napproximate the Euler equations of isentropic gas dynamics on the arcs of a\nnetwork. At the junction mass conservation and a jump transmission condition on\nthe density are given, and a new solver is introduced to deal with both\nsubsonic and supersonic cases. Consistency properties of the solver are proven\nand numerical tests are displayed to show its good performance also with\nrespect to other possible solvers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05779v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05308", "title": "High Order Collaboration-Oriented Federated Graph Neural Network for Accurate QoS Prediction", "authors": ["Zehuan Chen", "Xiangwei Lai"], "categories": ["cs.DC", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05308v1", "summary": "Predicting Quality of Service (QoS) data crucial for cloud service selection,\nwhere user privacy is a critical concern. Federated Graph Neural Networks\n(FGNNs) can perform QoS data prediction as well as maintaining user privacy.\nHowever, existing FGNN-based QoS predictors commonly implement on-device\ntraining on scattered explicit user-service graphs, thereby failing to utilize\nthe implicit user-user interactions. To address this issue, this study proposes\na high order collaboration-oriented federated graph neural network (HC-FGNN) to\nobtain accurate QoS prediction with privacy preservation. Concretely, it\nmagnifies the explicit user-service graphs following the principle of attention\nmechanism to obtain the high order collaboration, which reflects the implicit\nuser-user interactions. Moreover, it utilizes a lightweight-based message\naggregation way to improve the computational efficiency. The extensive\nexperiments on two QoS datasets from real application indicate that the\nproposed HC-FGNN possesses the advantages of high prediction accurate and\nprivacy protection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05308v1", "cate": "cs.DC", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06146", "title": "Prompt-Free Conditional Diffusion for Multi-object Image Augmentation", "authors": ["Haoyu Wang", "Lei Zhang", "Wei Wei", "Chen Ding", "Yanning Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at IJCAI 2025", "url": "http://arxiv.org/abs/2507.06146v1", "summary": "Diffusion models has underpinned much recent advances of dataset augmentation\nin various computer vision tasks. However, when involving generating\nmulti-object images as real scenarios, most existing methods either rely\nentirely on text condition, resulting in a deviation between the generated\nobjects and the original data, or rely too much on the original images,\nresulting in a lack of diversity in the generated images, which is of limited\nhelp to downstream tasks. To mitigate both problems with one stone, we propose\na prompt-free conditional diffusion framework for multi-object image\naugmentation. Specifically, we introduce a local-global semantic fusion\nstrategy to extract semantics from images to replace text, and inject knowledge\ninto the diffusion model through LoRA to alleviate the category deviation\nbetween the original model and the target dataset. In addition, we design a\nreward model based counting loss to assist the traditional reconstruction loss\nfor model training. By constraining the object counts of each category instead\nof pixel-by-pixel constraints, bridging the quantity deviation between the\ngenerated data and the original data while improving the diversity of the\ngenerated data. Experimental results demonstrate the superiority of the\nproposed method over several representative state-of-the-art baselines and\nshowcase strong downstream task gain and out-of-domain generalization\ncapabilities. Code is available at\n\\href{https://github.com/00why00/PFCD}{here}.", "comment": "Accepted at IJCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.06146v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.04667", "title": "What's Making That Sound Right Now? Video-centric Audio-Visual Localization", "authors": ["Hahyeon Choi", "Junhoo Lee", "Nojun Kwak"], "categories": ["cs.CV", "cs.AI", "cs.MM", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Published at ICCV 2025. Project page: this https URL", "url": "http://arxiv.org/abs/2507.04667v2", "summary": "Audio-Visual Localization (AVL) aims to identify sound-emitting sources\nwithin a visual scene. However, existing studies focus on image-level\naudio-visual associations, failing to capture temporal dynamics. Moreover, they\nassume simplified scenarios where sound sources are always visible and involve\nonly a single object. To address these limitations, we propose AVATAR, a\nvideo-centric AVL benchmark that incorporates high-resolution temporal\ninformation. AVATAR introduces four distinct scenarios -- Single-sound,\nMixed-sound, Multi-entity, and Off-screen -- enabling a more comprehensive\nevaluation of AVL models. Additionally, we present TAVLO, a novel video-centric\nAVL model that explicitly integrates temporal information. Experimental results\nshow that conventional methods struggle to track temporal variations due to\ntheir reliance on global audio features and frame-level mappings. In contrast,\nTAVLO achieves robust and precise audio-visual alignment by leveraging\nhigh-resolution temporal modeling. Our work empirically demonstrates the\nimportance of temporal dynamics in AVL and establishes a new standard for\nvideo-centric audio-visual localization.", "comment": "Published at ICCV 2025. Project page:\n  https://hahyeon610.github.io/Video-centric_Audio_Visual_Localization/", "pdf_url": "http://arxiv.org/pdf/2507.04667v2", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2507.03745", "title": "StreamDiT: Real-Time Streaming Text-to-Video Generation", "authors": ["Akio Kodaira", "Tingbo Hou", "Ji Hou", "Masayoshi Tomizuka", "Yue Zhao"], "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03745v2", "summary": "Recently, great progress has been achieved in text-to-video (T2V) generation\nby scaling transformer-based diffusion models to billions of parameters, which\ncan generate high-quality videos. However, existing models typically produce\nonly short clips offline, restricting their use cases in interactive and\nreal-time applications. This paper addresses these challenges by proposing\nStreamDiT, a streaming video generation model. StreamDiT training is based on\nflow matching by adding a moving buffer. We design mixed training with\ndifferent partitioning schemes of buffered frames to boost both content\nconsistency and visual quality. StreamDiT modeling is based on adaLN DiT with\nvarying time embedding and window attention. To practice the proposed method,\nwe train a StreamDiT model with 4B parameters. In addition, we propose a\nmultistep distillation method tailored for StreamDiT. Sampling distillation is\nperformed in each segment of a chosen partitioning scheme. After distillation,\nthe total number of function evaluations (NFEs) is reduced to the number of\nchunks in a buffer. Finally, our distilled model reaches real-time performance\nat 16 FPS on one GPU, which can generate video streams at 512p resolution. We\nevaluate our method through both quantitative metrics and human evaluation. Our\nmodel enables real-time applications, e.g. streaming generation, interactive\ngeneration, and video-to-video. We provide video results and more examples in\nour project website: https://cumulo-autumn.github.io/StreamDiT/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03745v2", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2503.19166", "title": "On the Problem Characteristics of Multi-objective Pseudo-Boolean Functions in Runtime Analysis", "authors": ["Zimin Liang", "Miqing Li"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.19166v2", "summary": "Recently, there has been growing interest within the theoretical community in\nanalytically studying multi-objective evolutionary algorithms. This runtime\nanalysis-focused research can help formally understand algorithm behaviour,\nexplain empirical observations, and provide theoretical insights to support\nalgorithm development and exploration. However, the test problems commonly used\nin the theoretical analysis are predominantly limited to problems with heavy\n\"artificial\" characteristics (e.g., symmetric, homogeneous objectives and\nlinear Pareto fronts), which may not be able to well represent realistic\nscenarios. In this paper, we first discuss commonly used multi-objective\nfunctions in the theory domain and systematically review their features,\nlimitations and implications to practical use. Then, we present several new\nfunctions with more realistic features, such as heterogenous objectives, local\noptimality and nonlinearity of the Pareto front, through simply mixing and\nmatching classical single-objective functions in the area (e.g., LeadingOnes,\nJump and RoyalRoad). We hope these functions can enrich the existing test\nproblem suites, and strengthen the connection between theoretic and practical\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.19166v2", "cate": "cs.NE", "date": "2025-03-24", "updated": "2025-07-08"}
{"id": "2507.05863", "title": "KERAG_R: Knowledge-Enhanced Retrieval-Augmented Generation for Recommendation", "authors": ["Zeyuan Meng", "Zixuan Yi", "Iadh Ounis"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05863v1", "summary": "Large Language Models (LLMs) have shown strong potential in recommender\nsystems due to their contextual learning and generalisation capabilities.\nExisting LLM-based recommendation approaches typically formulate the\nrecommendation task using specialised prompts designed to leverage their\ncontextual abilities, and aligning their outputs closely with human preferences\nto yield an improved recommendation performance. However, the use of LLMs for\nrecommendation tasks is limited by the absence of domain-specific knowledge.\nThis lack of relevant relational knowledge about the items to be recommended in\nthe LLM's pre-training corpus can lead to inaccuracies or hallucinations,\nresulting in incorrect or misleading recommendations. Moreover, directly using\ninformation from the knowledge graph introduces redundant and noisy\ninformation, which can affect the LLM's reasoning process or exceed its input\ncontext length, thereby reducing the performance of LLM-based recommendations.\nTo address the lack of domain-specific knowledge, we propose a novel model\ncalled Knowledge-Enhanced Retrieval-Augmented Generation for Recommendation\n(KERAG_R). Specifically, we leverage a graph retrieval-augmented generation\n(GraphRAG) component to integrate additional information from a knowledge graph\n(KG) into instructions, enabling the LLM to collaboratively exploit\nrecommendation signals from both text-based user interactions and the knowledge\ngraph to better estimate the users' preferences in a recommendation context. In\nparticular, we perform graph RAG by pre-training a graph attention network\n(GAT) to select the most relevant triple for the target users for the used LLM,\nthereby enhancing the LLM while reducing redundant and noisy information. Our\nextensive experiments on three public datasets show that our proposed KERAG_R\nmodel significantly outperforms ten existing state-of-the-art recommendation\nmethods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05863v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05786", "title": "The Neural Approximated Virtual Element Method for Elasticity Problems", "authors": ["Stefano Berrone", "Moreno Pintore", "Gioana Teora"], "categories": ["math.NA", "cs.NA", "65N22, 65N30, 68T07"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05786v1", "summary": "We present the Neural Approximated Virtual Element Method to numerically\nsolve elasticity problems. This hybrid technique combines classical concepts\nfrom the Finite Element Method and the Virtual Element Method with recent\nadvances in deep neural networks. Specifically, it is a polygonal method in\nwhich the virtual basis functions are element-wise approximated by a neural\nnetwork, eliminating the need for stabilization or projection operators typical\nof the standard virtual element method. We present the discrete formulation of\nthe problem and provide numerical tests on both linear and non-linear\nelasticity problems, demonstrating the advantages of having a simple\ndiscretization, particularly in handling non-linearities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05786v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05418", "title": "Learn Globally, Speak Locally: Bridging the Gaps in Multilingual Reasoning", "authors": ["Jaedong Hwang", "Kumar Tanmay", "Seok-Jin Lee", "Ayush Agrawal", "Hamid Palangi", "Kumar Ayush", "Ila Fiete", "Paul Pu Liang"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05418v1", "summary": "Large Language Models (LLMs) have achieved strong performance in domains like\nmathematics, factual QA, and code generation, yet their multilingual reasoning\ncapabilities in these tasks remain underdeveloped. Especially for low-resource\nlanguages such as Swahili or Thai, LLMs can often misinterpret prompts or\ndefault to reasoning in English. This implicit bias toward high-resource\nlanguages undermines factual accuracy, interpretability, and trust. Current\nmultilingual benchmarks focus only on final answers, overlooking whether models\nactually reason in the target language. To address this gap, we introduce\nGeoFact-X, a geography-based multilingual factual reasoning benchmark with\nannotated reasoning traces in five languages: English, Hindi, Japanese,\nSwahili, and Thai. We further propose BRIDGE, a novel training method that\nguides supervised fine-tuning and test-time reinforcement learning with a\nlanguage-consistency reward to align reasoning with the input language.\nFinally, we develop an automatic evaluation protocol using LLM-as-a-judge to\nassess answer correctness and the quality and language consistency of reasoning\ntraces, enabling nuanced and scalable analysis beyond surface-level metrics.\nOur results show that BRIDGE significantly enhances multilingual reasoning\nfidelity, demonstrating that reasoning-aware multilingual reinforcement\nlearning is crucial for robust cross-lingual generalization.\nhttps://jd730.github.io/projects/GeoFact-X_BRIDGE", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05418v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05177", "title": "OpenS2S: Advancing Fully Open-Source End-to-End Empathetic Large Speech Language Model", "authors": ["Chen Wang", "Tianyu Peng", "Wen Yang", "Yinan Bai", "Guangfu Wang", "Jun Lin", "Lanpeng Jia", "Lingxiang Wu", "Jinqiao Wang", "Chengqing Zong", "Jiajun Zhang"], "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Technical Report", "url": "http://arxiv.org/abs/2507.05177v2", "summary": "Empathetic interaction is a cornerstone of human-machine communication, due\nto the need for understanding speech enriched with paralinguistic cues and\ngenerating emotional and expressive responses. However, the most powerful\nempathetic LSLMs are increasingly closed off, leaving the crucial details about\nthe architecture, data and development opaque to researchers. Given the\ncritical need for transparent research into the LSLMs and empathetic behavior,\nwe present OpenS2S, a fully open-source, transparent and end-to-end LSLM\ndesigned to enable empathetic speech interactions. Based on our empathetic\nspeech-to-text model BLSP-Emo, OpenS2S further employs a streaming interleaved\ndecoding architecture to achieve low-latency speech generation. To facilitate\nend-to-end training, OpenS2S incorporates an automated data construction\npipeline that synthesizes diverse, high-quality empathetic speech dialogues at\nlow cost. By leveraging large language models to generate empathetic content\nand controllable text-to-speech systems to introduce speaker and emotional\nvariation, we construct a scalable training corpus with rich paralinguistic\ndiversity and minimal human supervision. We release the fully open-source\nOpenS2S model, including the dataset, model weights, pre-training and\nfine-tuning codes, to empower the broader research community and accelerate\ninnovation in empathetic speech systems. The project webpage can be accessed at\nhttps://casia-lm.github.io/OpenS2S", "comment": "Technical Report", "pdf_url": "http://arxiv.org/pdf/2507.05177v2", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2506.19256", "title": "Enhancing Generalization of Spiking Neural Networks Through Temporal Regularization", "authors": ["Boxuan Zhang", "Zhen Xu", "Kuan Tao"], "categories": ["cs.NE", "cs.AI"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      Code is available at this https URL", "url": "http://arxiv.org/abs/2506.19256v2", "summary": "Spiking Neural Networks (SNNs) have received widespread attention due to\ntheir event-driven and low-power characteristics, making them particularly\neffective for processing event-based neuromorphic data. Recent studies have\nshown that directly trained SNNs suffer from severe overfitting issues due to\nthe limited scale of neuromorphic datasets and the gradient mismatching\nproblem, which fundamentally constrain their generalization performance. In\nthis paper, we propose a temporal regularization training (TRT) method by\nintroducing a time-dependent regularization mechanism to enforce stronger\nconstraints on early timesteps. We compare the performance of TRT with other\nstate-of-the-art methods performance on datasets including CIFAR10/100,\nImageNet100, DVS-CIFAR10, and N-Caltech101. To validate the effectiveness of\nTRT, we conducted ablation studies and analyses including loss landscape\nvisualization and learning curve analysis, demonstrating that TRT can\neffectively mitigate overfitting and flatten the training loss landscape,\nthereby enhancing generalizability. Furthermore, we establish a theoretical\ninterpretation of TRT's temporal regularization mechanism based on the results\nof Fisher information analysis. We analyze the temporal information dynamics\ninside SNNs by tracking Fisher information during the TRT training process,\nrevealing the Temporal Information Concentration (TIC) phenomenon, where Fisher\ninformation progressively concentrates in early timesteps. The time-decaying\nregularization mechanism implemented in TRT effectively guides the network to\nlearn robust features in early timesteps with rich information, thereby leading\nto significant improvements in model generalization. Code is available at\nhttps://github.com/ZBX05/Temporal-Regularization-Training.", "comment": "Code is available at\n  https://github.com/ZBX05/Temporal-Regularization-Training", "pdf_url": "http://arxiv.org/pdf/2506.19256v2", "cate": "cs.NE", "date": "2025-06-24", "updated": "2025-07-08"}
{"id": "2507.05865", "title": "On the Costs and Benefits of Learned Indexing for Dynamic High-Dimensional Data: Extended Version", "authors": ["Terézia Slanináková", "Jaroslav Olha", "David Procházka", "Matej Antol", "Vlastislav Dohnal"], "categories": ["cs.IR", "cs.DB"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05865v1", "summary": "One of the main challenges within the growing research area of learned\nindexing is the lack of adaptability to dynamically expanding datasets. This\npaper explores the dynamization of a static learned index for complex data\nthrough operations such as node splitting and broadening, enabling efficient\nadaptation to new data. Furthermore, we evaluate the trade-offs between static\nand dynamic approaches by introducing an amortized cost model to assess query\nperformance in tandem with the build costs of the index structure, enabling\nexperimental determination of when a dynamic learned index outperforms its\nstatic counterpart. We apply the dynamization method to a static learned index\nand demonstrate that its superior scaling quickly surpasses the static\nimplementation in terms of overall costs as the database grows. This is an\nextended version of the paper presented at DAWAK 2025.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05865v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05953", "title": "Weak Galerkin Methods for the Brinkman Equations", "authors": ["Chunmei Wang", "Shangyou Zhang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      23 pages, 8 tables, 8 figures", "url": "http://arxiv.org/abs/2507.05953v1", "summary": "This paper introduces a novel weak Galerkin (WG) finite element method for\nthe numerical solution of the Brinkman equations. The Brinkman model, which\nseamlessly integrates characteristics of both the Stokes and Darcy equations,\nis employed to describe fluid flow in multiphysics contexts, particularly\nwithin heterogeneous porous media exhibiting spatially variable permeability.\nThe proposed WG method offers a unified and robust approach capable of\naccurately capturing both Stokes- and Darcy-dominated regimes. A discrete\ninf-sup condition is established, and optimal-order error estimates are\nrigorously proven for the WG finite element solutions. Furthermore, a series of\nnumerical experiments is performed to corroborate the theoretical analysis,\ndemonstrating the method's accuracy and stability in addressing the\ncomplexities inherent in the Brinkman equations.", "comment": "23 pages, 8 tables, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.05953v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05424", "title": "\"Lost-in-the-Later\": Framework for Quantifying Contextual Grounding in Large Language Models", "authors": ["Yufei Tao", "Adam Hiatt", "Rahul Seetharaman", "Ameeta Agrawal"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05424v1", "summary": "Large language models are capable of leveraging both contextual and\nparametric knowledge but how they prioritize and integrate these sources\nremains underexplored. We introduce CoPE, a novel evaluation framework that\nsystematically measures contextual knowledge (CK) and parametric knowledge (PK)\nacross models and languages. Using our MultiWikiAtomic dataset in English,\nSpanish, and Danish, we analyze how large language models (LLMs) integrate\ncontext, prioritize information, and incorporate PK in open-ended question\nanswering. Our analysis uncovers a phenomenon we call lost-in-the-later, where\nLLMs tend to overlook or deprioritize information that appears later in a given\ncontext, revealing a strong positional bias that affects contextual grounding.\nWe further find that reasoning models, as well as non-reasoning models prompted\nwith chain-of-thought (CoT), use context even less than non-reasoning models\nwithout CoT and fail to mitigate the lost-in-the-later effect. CoT prompting,\nin particular, results in lower recall and shorter responses, leading to\ndegraded contextual grounding. Based on these insights, we design prompt-based\nmethods to effectively leverage input context. A case study applying CoPE to\nsummarization demonstrates that CK-informed prompting improves factual\ngrounding and reduces hallucination.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05424v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06161", "title": "Normalizing Diffusion Kernels with Optimal Transport", "authors": ["Nathan Kessler", "Robin Magnet", "Jean Feydy"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      33 pages, 25 figures", "url": "http://arxiv.org/abs/2507.06161v1", "summary": "Smoothing a signal based on local neighborhoods is a core operation in\nmachine learning and geometry processing. On well-structured domains such as\nvector spaces and manifolds, the Laplace operator derived from differential\ngeometry offers a principled approach to smoothing via heat diffusion, with\nstrong theoretical guarantees. However, constructing such Laplacians requires a\ncarefully defined domain structure, which is not always available. Most\npractitioners thus rely on simple convolution kernels and message-passing\nlayers, which are biased against the boundaries of the domain. We bridge this\ngap by introducing a broad class of smoothing operators, derived from general\nsimilarity or adjacency matrices, and demonstrate that they can be normalized\ninto diffusion-like operators that inherit desirable properties from\nLaplacians. Our approach relies on a symmetric variant of the Sinkhorn\nalgorithm, which rescales positive smoothing operators to match the structural\nbehavior of heat diffusion. This construction enables Laplacian-like smoothing\nand processing of irregular data such as point clouds, sparse voxel grids or\nmixture of Gaussians. We show that the resulting operators not only approximate\nheat diffusion but also retain spectral information from the Laplacian itself,\nwith applications to shape analysis and matching.", "comment": "33 pages, 25 figures", "pdf_url": "http://arxiv.org/pdf/2507.06161v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05880", "title": "RecRankerEval: A Flexible and Extensible Framework for Top-k LLM-based Recommendation", "authors": ["Zeyuan Meng", "Zixuan Yi", "Iadh Ounis"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05880v1", "summary": "A recent Large language model (LLM)-based recommendation model, called\nRecRanker, has demonstrated a superior performance in the top-k recommendation\ntask compared to other models. In particular, RecRanker samples users via\nclustering, generates an initial ranking list using an initial recommendation\nmodel, and fine-tunes an LLM through hybrid instruction tuning to infer user\npreferences. However, the contribution of each core component remains\nunderexplored. In this work, we inspect the reproducibility of RecRanker, and\nstudy the impact and role of its various components. We begin by reproducing\nthe RecRanker pipeline through the implementation of all its key components.\nOur reproduction shows that the pairwise and listwise methods achieve a\nperformance comparable to that reported in the original paper. For the\npointwise method, while we are also able to reproduce the original paper's\nresults, further analysis shows that the performance is abnormally high due to\ndata leakage from the inclusion of ground-truth information in the prompts. To\nenable a fair and comprehensive evaluation of LLM-based top-k recommendations,\nwe propose RecRankerEval, an extensible framework that covers five key\ndimensions: user sampling strategy, initial recommendation model, LLM backbone,\ndataset selection, and instruction tuning method. Using the RecRankerEval\nframework, we show that the original results of RecRanker can be reproduced on\nthe ML-100K and ML-1M datasets, as well as the additional Amazon-Music dataset,\nbut not on BookCrossing due to the lack of timestamp information in the\noriginal RecRanker paper. Furthermore, we demonstrate that RecRanker's\nperformance can be improved by employing alternative user sampling methods,\nstronger initial recommenders, and more capable LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05880v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06017", "title": "A posteriori analysis of neural network approximations", "authors": ["Thomas Führer", "Sergio Rojas"], "categories": ["math.NA", "cs.NA", "65N15, 65M60, 65M75"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06017v1", "summary": "In a general setting, we study a posteriori estimates used in finite element\nanalysis to measure the error between a solution and its approximation. The\nlatter is not necessarily generated by a finite element method. We show that\nthe error is equivalent to the sum of two residuals provided that the\nunderlying variational formulation is well posed. The first contribution is the\nprojection of the residual to a finite-dimensional space and is therefore\ncomputable, while the second one can be reliably estimated by a computable\nupper bound in many practical scenarios. Assuming sufficiently accurate\nquadrature, our findings can be used to estimate the error of, e.g., neural\nnetwork outputs. Two important applications can be considered during\noptimization: first, the estimators are used to monitor the error in each\nsolver step, or, second, the two estimators are included in the loss\nfunctional, and therefore provide control over the error. As a model problem,\nwe consider a second-order elliptic partial differential equation and discuss\ndifferent variational formulations thereof, including several options to\ninclude boundary conditions in the estimators. Various numerical experiments\nare presented to validate our findings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06017v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06165", "title": "OmniPart: Part-Aware 3D Generation with Semantic Decoupling and Structural Cohesion", "authors": ["Yunhan Yang", "Yufan Zhou", "Yuan-Chen Guo", "Zi-Xin Zou", "Yukun Huang", "Ying-Tian Liu", "Hao Xu", "Ding Liang", "Yan-Pei Cao", "Xihui Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2507.06165v1", "summary": "The creation of 3D assets with explicit, editable part structures is crucial\nfor advancing interactive applications, yet most generative methods produce\nonly monolithic shapes, limiting their utility. We introduce OmniPart, a novel\nframework for part-aware 3D object generation designed to achieve high semantic\ndecoupling among components while maintaining robust structural cohesion.\nOmniPart uniquely decouples this complex task into two synergistic stages: (1)\nan autoregressive structure planning module generates a controllable,\nvariable-length sequence of 3D part bounding boxes, critically guided by\nflexible 2D part masks that allow for intuitive control over part decomposition\nwithout requiring direct correspondences or semantic labels; and (2) a\nspatially-conditioned rectified flow model, efficiently adapted from a\npre-trained holistic 3D generator, synthesizes all 3D parts simultaneously and\nconsistently within the planned layout. Our approach supports user-defined part\ngranularity, precise localization, and enables diverse downstream applications.\nExtensive experiments demonstrate that OmniPart achieves state-of-the-art\nperformance, paving the way for more interpretable, editable, and versatile 3D\ncontent.", "comment": "Project page: https://omnipart.github.io/", "pdf_url": "http://arxiv.org/pdf/2507.06165v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2501.03113", "title": "Balancing Efficiency and Expressiveness: Subgraph GNNs with Walk-Based Centrality", "authors": ["Joshua Southern", "Yam Eitan", "Guy Bar-Shalom", "Michael Bronstein", "Haggai Maron", "Fabrizio Frasca"], "categories": ["cs.LG", "cs.NE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025", "url": "http://arxiv.org/abs/2501.03113v2", "summary": "Subgraph GNNs have emerged as promising architectures that overcome the\nexpressiveness limitations of Graph Neural Networks (GNNs) by processing bags\nof subgraphs. Despite their compelling empirical performance, these methods are\nafflicted by a high computational complexity: they process bags whose size\ngrows linearly in the number of nodes, hindering their applicability to larger\ngraphs. In this work, we propose an effective and easy-to-implement approach to\ndramatically alleviate the computational cost of Subgraph GNNs and unleash\nbroader applications thereof. Our method, dubbed HyMN, leverages walk-based\ncentrality measures to sample a small number of relevant subgraphs and\ndrastically reduce the bag size. By drawing a connection to perturbation\nanalysis, we highlight the strength of the proposed centrality-based subgraph\nsampling, and further prove that these walk-based centralities can be\nadditionally used as Structural Encodings for improved discriminative power. A\ncomprehensive set of experimental results demonstrates that HyMN provides an\neffective synthesis of expressiveness, efficiency, and downstream performance,\nunlocking the application of Subgraph GNNs to dramatically larger graphs. Not\nonly does our method outperform more sophisticated subgraph sampling\napproaches, it is also competitive, and sometimes better, than other\nstate-of-the-art approaches for a fraction of their runtime.", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2501.03113v2", "cate": "cs.LG", "date": "2025-01-06", "updated": "2025-07-07"}
{"id": "2507.05933", "title": "Semantic Certainty Assessment in Vector Retrieval Systems: A Novel Framework for Embedding Quality Evaluation", "authors": ["Y. Du"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2507.05933v1", "summary": "Vector retrieval systems exhibit significant performance variance across\nqueries due to heterogeneous embedding quality. We propose a lightweight\nframework for predicting retrieval performance at the query level by combining\nquantization robustness and neighborhood density metrics. Our approach is\nmotivated by the observation that high-quality embeddings occupy geometrically\nstable regions in the embedding space and exhibit consistent neighborhood\nstructures. We evaluate our method on 4 standard retrieval datasets, showing\nconsistent improvements of 9.4$\\pm$1.2\\% in Recall@10 over competitive\nbaselines. The framework requires minimal computational overhead (less than 5\\%\nof retrieval time) and enables adaptive retrieval strategies. Our analysis\nreveals systematic patterns in embedding quality across different query types,\nproviding insights for targeted training data augmentation.", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2507.05933v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06038", "title": "Fredholm Neural Networks for forward and inverse problems in elliptic PDEs", "authors": ["Kyriakos Georgiou", "Constantinos Siettos", "Athanasios N. Yannacopoulos"], "categories": ["math.NA", "cs.LG", "cs.NA", "68T07, 65N12, 65N21 (Primary), 45B05, 65N38 (Secondary)"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06038v1", "summary": "Building on our previous work introducing Fredholm Neural Networks (Fredholm\nNNs/ FNNs) for solving integral equations, we extend the framework to tackle\nforward and inverse problems for linear and semi-linear elliptic partial\ndifferential equations. The proposed scheme consists of a deep neural network\n(DNN) which is designed to represent the iterative process of fixed-point\niterations for the solution of elliptic PDEs using the boundary integral method\nwithin the framework of potential theory. The number of layers, weights, biases\nand hyperparameters are computed in an explainable manner based on the\niterative scheme, and we therefore refer to this as the Potential Fredholm\nNeural Network (PFNN). We show that this approach ensures both accuracy and\nexplainability, achieving small errors in the interior of the domain, and near\nmachine-precision on the boundary. We provide a constructive proof for the\nconsistency of the scheme and provide explicit error bounds for both the\ninterior and boundary of the domain, reflected in the layers of the PFNN. These\nerror bounds depend on the approximation of the boundary function and the\nintegral discretization scheme, both of which directly correspond to components\nof the Fredholm NN architecture. In this way, we provide an explainable scheme\nthat explicitly respects the boundary conditions. We assess the performance of\nthe proposed scheme for the solution of both the forward and inverse problem\nfor linear and semi-linear elliptic PDEs in two dimensions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06038v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05448", "title": "On the Semantics of Large Language Models", "authors": ["Martin Schuele"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05448v1", "summary": "Large Language Models (LLMs) such as ChatGPT demonstrated the potential to\nreplicate human language abilities through technology, ranging from text\ngeneration to engaging in conversations. However, it remains controversial to\nwhat extent these systems truly understand language. We examine this issue by\nnarrowing the question down to the semantics of LLMs at the word and sentence\nlevel. By examining the inner workings of LLMs and their generated\nrepresentation of language and by drawing on classical semantic theories by\nFrege and Russell, we get a more nuanced picture of the potential semantic\ncapabilities of LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05448v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06183", "title": "Enhancing Scientific Visual Question Answering through Multimodal Reasoning and Ensemble Modeling", "authors": ["Prahitha Movva", "Naga Harshita Marupaka"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06183v1", "summary": "Technical reports and articles often contain valuable information in the form\nof semi-structured data like charts, and figures. Interpreting these and using\nthe information from them is essential for downstream tasks such as question\nanswering (QA). Current approaches to visual question answering often struggle\nwith the precision required for scientific data interpretation, particularly in\nhandling numerical values, multi-step reasoning over visual elements, and\nmaintaining consistency between visual observation and textual reasoning. We\npresent our approach to the SciVQA 2025 shared task, focusing on answering\nvisual and non-visual questions grounded in scientific figures from scholarly\narticles.\n  We conducted a series of experiments using models with 5B to 8B parameters.\nOur strongest individual model, InternVL3, achieved ROUGE-1 and ROUGE-L F1\nscores of \\textbf{0.740} and a BERTScore of \\textbf{0.983} on the SciVQA test\nsplit. We also developed an ensemble model with multiple vision language models\n(VLMs). Through error analysis on the validation split, our ensemble approach\nimproved performance compared to most individual models, though InternVL3\nremained the strongest standalone performer. Our findings underscore the\neffectiveness of prompt optimization, chain-of-thought reasoning and ensemble\nmodeling in improving the model's ability in visual question answering.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06183v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06044", "title": "Hierarchical Interaction Summarization and Contrastive Prompting for Explainable Recommendations", "authors": ["Yibin Liu", "Ang Li", "Shijian Li"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06044v1", "summary": "Explainable recommendations, which use the information of user and item with\ninteraction to generate a explanation for why the user would interact with the\nitem, are crucial for improving user trust and decision transparency to the\nrecommender system. Existing methods primarily rely on encoding features of\nusers and items to embeddings, which often leads to information loss due to\ndimensionality reduction, sparse interactions, and so on. With the advancements\nof large language models (LLMs) in language comprehension, some methods use\nembeddings as LLM inputs for explanation generation. However, since embeddings\nlack inherent semantics, LLMs must adjust or extend their parameters to\ninterpret them, a process that inevitably incurs information loss. To address\nthis issue, we propose a novel approach combining profile generation via\nhierarchical interaction summarization (PGHIS), which leverages a pretrained\nLLM to hierarchically summarize user-item interactions, generating structured\ntextual profiles as explicit representations of user and item characteristics.\nAdditionally, we propose contrastive prompting for explanation generation\n(CPEG) which employs contrastive learning to guide another reasoning language\nmodels in producing high-quality ground truth recommendation explanations.\nFinally, we use the textual profiles of user and item as input and high-quality\nexplanation as output to fine-tune a LLM for generating explanations.\nExperimental results on multiple datasets demonstrate that our approach\noutperforms existing state-of-the-art methods, achieving a great improvement on\nmetrics about explainability (e.g., 5% on GPTScore) and text quality.\nFurthermore, our generated ground truth explanations achieve a significantly\nhigher win rate compared to user-written reviews and those produced by other\nmethods, demonstrating the effectiveness of CPEG in generating high-quality\nground truths.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06044v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06114", "title": "Learning-Enhanced Variational Regularization for Electrical Impedance Tomography via \\Calderon's Method", "authors": ["Kai Li", "Kwancheol Shin", "Zhi Zhou"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06114v1", "summary": "This paper aims to numerically solve the two-dimensional electrical impedance\ntomography (EIT) with Cauchy data. This inverse problem is highly challenging\ndue to its severe ill-posed nature and strong nonlinearity, which necessitates\nappropriate regularization strategies. Choosing a regularization approach that\neffectively incorporates the \\textit{a priori} information of the conductivity\ndistribution (or its contrast) is therefore essential. In this work, we propose\na deep learning-based method to capture the \\textit{a priori} information about\nthe shape and location of the unknown contrast using \\Calderon's method. The\nlearned \\textit{a priori} information is then used to construct the\nregularization functional of the variational regularization method for solving\nthe inverse problem. The resulting regularized variational problem for EIT\nreconstruction is then solved using the Gauss-Newton method. Extensive\nnumerical experiments demonstrate that the proposed inversion algorithm\nachieves accurate reconstruction results, even in high-contrast cases, and\nexhibits strong generalization capabilities. Additionally, some stability and\nconvergence analysis of the variational regularization method underscores the\nimportance of incorporating \\textit{a priori} information about the support of\nthe unknown contrast.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06114v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05455", "title": "ModelCitizens:Representing Community Voices in Online Safety", "authors": ["Ashima Suvarna", "Christina Chance", "Hamid Palangi", "Sophie Hao", "Thomas Hartvigsen", "Saadia Gabriel"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05455v1", "summary": "Automatic toxic language detection is critical for creating safe, inclusive\nonline spaces. However, it is a highly subjective task, with perceptions of\ntoxic language shaped by community norms and lived experience. Existing\ntoxicity detection models are typically trained on annotations that collapse\ndiverse annotator perspectives into a single ground truth, erasing important\ncontext-specific notions of toxicity such as reclaimed language. To address\nthis, we introduce MODELCITIZENS, a dataset of 6.8K social media posts and 40K\ntoxicity annotations across diverse identity groups. To capture the role of\nconversational context on toxicity, typical of social media posts, we augment\nMODELCITIZENS posts with LLM-generated conversational scenarios.\nState-of-the-art toxicity detection tools (e.g. OpenAI Moderation API,\nGPT-o4-mini) underperform on MODELCITIZENS, with further degradation on\ncontext-augmented posts. Finally, we release LLAMACITIZEN-8B and\nGEMMACITIZEN-12B, LLaMA- and Gemma-based models finetuned on MODELCITIZENS,\nwhich outperform GPT-o4-mini by 5.5% on in-distribution evaluations. Our\nfindings highlight the importance of community-informed annotation and modeling\nfor inclusive content moderation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05455v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06210", "title": "CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions", "authors": ["Yuchen Huang", "Zhiyuan Fan", "Zhitao He", "Sandeep Polisetty", "Wenyan Li", "Yi R. Fung"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      25 pages, COLM 2025", "url": "http://arxiv.org/abs/2507.06210v1", "summary": "Pretrained vision-language models (VLMs) such as CLIP excel in multimodal\nunderstanding but struggle with contextually relevant fine-grained visual\nfeatures, making it difficult to distinguish visually similar yet culturally\ndistinct concepts. This limitation stems from the scarcity of high-quality\nculture-specific datasets, the lack of integrated contextual knowledge, and the\nabsence of hard negatives highlighting subtle distinctions. To address these\nchallenges, we first design a data curation pipeline that leverages\nopen-sourced VLMs and text-to-image diffusion models to construct CulTwin, a\nsynthetic cultural dataset. This dataset consists of paired\nconcept-caption-image triplets, where concepts visually resemble each other but\nrepresent different cultural contexts. Then, we fine-tune CLIP on CulTwin to\ncreate CultureCLIP, which aligns cultural concepts with contextually enhanced\ncaptions and synthetic images through customized contrastive learning, enabling\nfiner cultural differentiation while preserving generalization capabilities.\nExperiments on culturally relevant benchmarks show that CultureCLIP outperforms\nthe base CLIP, achieving up to a notable 5.49% improvement in fine-grained\nconcept recognition on certain tasks, while preserving CLIP's original\ngeneralization ability, validating the effectiveness of our data synthesis and\nVLM backbone training paradigm in capturing subtle cultural distinctions.", "comment": "25 pages, COLM 2025", "pdf_url": "http://arxiv.org/pdf/2507.06210v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06090", "title": "Nyay-Darpan: Enhancing Decision Making Through Summarization and Case Retrieval for Consumer Law in India", "authors": ["Swapnil Bhattacharyya", "Shrey Ganatra", "Harshvivek Kashid", "Spandan Anaokar", "Shruti Nair", "Reshma Sekhar", "Siddharth Manohar", "Rahul Hemrajani", "Pushpak Bhattacharyya"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06090v1", "summary": "AI-based judicial assistance and case prediction have been extensively\nstudied in criminal and civil domains, but remain largely unexplored in\nconsumer law, especially in India. In this paper, we present Nyay-Darpan, a\nnovel two-in-one framework that (i) summarizes consumer case files and (ii)\nretrieves similar case judgements to aid decision-making in consumer dispute\nresolution. Our methodology not only addresses the gap in consumer law AI tools\nbut also introduces an innovative approach to evaluate the quality of the\nsummary. The term 'Nyay-Darpan' translates into 'Mirror of Justice',\nsymbolizing the ability of our tool to reflect the core of consumer disputes\nthrough precise summarization and intelligent case retrieval. Our system\nachieves over 75 percent accuracy in similar case prediction and approximately\n70 percent accuracy across material summary evaluation metrics, demonstrating\nits practical effectiveness. We will publicly release the Nyay-Darpan framework\nand dataset to promote reproducibility and facilitate further research in this\nunderexplored yet impactful domain.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06090v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06190", "title": "Conservative approximation-based feedforward neural network for WENO schemes", "authors": ["Kwanghyuk Park", "Jiaxi Gu", "Jae-Hun Jung"], "categories": ["math.NA", "cs.LG", "cs.NA", "65M06, 68T07"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06190v1", "summary": "In this work, we present the feedforward neural network based on the\nconservative approximation to the derivative from point values, for the\nweighted essentially non-oscillatory (WENO) schemes in solving hyperbolic\nconservation laws. The feedforward neural network, whose inputs are point\nvalues from the three-point stencil and outputs are two nonlinear weights,\ntakes the place of the classical WENO weighting procedure. For the training\nphase, we employ the supervised learning and create a new labeled dataset for\none-dimensional conservative approximation, where we construct a numerical flux\nfunction from the given point values such that the flux difference approximates\nthe derivative to high-order accuracy. The symmetric-balancing term is\nintroduced for the loss function so that it propels the neural network to match\nthe conservative approximation to the derivative and satisfy the symmetric\nproperty that WENO3-JS and WENO3-Z have in common. The consequent WENO schemes,\nWENO3-CADNNs, demonstrate robust generalization across various benchmark\nscenarios and resolutions, where they outperform WENO3-Z and achieve accuracy\ncomparable to WENO5-JS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06190v1", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06230", "title": "Feed-Forward SceneDINO for Unsupervised Semantic Scene Completion", "authors": ["Aleksandar Jevtić", "Christoph Reich", "Felix Wimbauer", "Oliver Hahn", "Christian Rupprecht", "Stefan Roth", "Daniel Cremers"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      To appear at ICCV 2025. Christoph Reich and Aleksandar Jevtić - both authors contributed equally. Code: this https URL Project page: this https URL", "url": "http://arxiv.org/abs/2507.06230v1", "summary": "Semantic scene completion (SSC) aims to infer both the 3D geometry and\nsemantics of a scene from single images. In contrast to prior work on SSC that\nheavily relies on expensive ground-truth annotations, we approach SSC in an\nunsupervised setting. Our novel method, SceneDINO, adapts techniques from\nself-supervised representation learning and 2D unsupervised scene understanding\nto SSC. Our training exclusively utilizes multi-view consistency\nself-supervision without any form of semantic or geometric ground truth. Given\na single input image, SceneDINO infers the 3D geometry and expressive 3D DINO\nfeatures in a feed-forward manner. Through a novel 3D feature distillation\napproach, we obtain unsupervised 3D semantics. In both 3D and 2D unsupervised\nscene understanding, SceneDINO reaches state-of-the-art segmentation accuracy.\nLinear probing our 3D features matches the segmentation accuracy of a current\nsupervised SSC approach. Additionally, we showcase the domain generalization\nand multi-view consistency of SceneDINO, taking the first steps towards a\nstrong foundation for single image 3D scene understanding.", "comment": "To appear at ICCV 2025. Christoph Reich and Aleksandar Jevti\\'c -\n  both authors contributed equally. Code:\n  https://github.com/tum-vision/scenedino Project page:\n  https://visinf.github.io/scenedino", "pdf_url": "http://arxiv.org/pdf/2507.06230v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06121", "title": "Unconditional Diffusion for Generative Sequential Recommendation", "authors": ["Yimeng Bai", "Yang Zhang", "Sihao Ding", "Shaohui Ruan", "Han Yao", "Danhui Guan", "Fuli Feng", "Tat-Seng Chua"], "categories": ["cs.IR", "H.3.3; H.3.5"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06121v1", "summary": "Diffusion models, known for their generative ability to simulate data\ncreation through noise-adding and denoising processes, have emerged as a\npromising approach for building generative recommenders. To incorporate user\nhistory for personalization, existing methods typically adopt a conditional\ndiffusion framework, where the reverse denoising process of reconstructing\nitems from noise is modified to be conditioned on the user history. However,\nthis design may fail to fully utilize historical information, as it gets\ndistracted by the need to model the \"item $\\leftrightarrow$ noise\" translation.\nThis motivates us to reformulate the diffusion process for sequential\nrecommendation in an unconditional manner, treating user history (instead of\nnoise) as the endpoint of the forward diffusion process (i.e., the starting\npoint of the reverse process), rather than as a conditional input. This\nformulation allows for exclusive focus on modeling the \"item $\\leftrightarrow$\nhistory\" translation. To this end, we introduce Brownian Bridge Diffusion\nRecommendation (BBDRec). By leveraging a Brownian bridge process, BBDRec\nenforces a structured noise addition and denoising mechanism, ensuring that the\ntrajectories are constrained towards a specific endpoint -- user history,\nrather than noise. Extensive experiments demonstrate BBDRec's effectiveness in\nenhancing sequential recommendation performance. The source code is available\nat https://github.com/baiyimeng/BBDRec.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06121v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.04940", "title": "Notes on $L^2$-estimates in linear elliptic equations with general coefficients", "authors": ["Haesung Lee"], "categories": ["math.AP", "cs.NA", "math.NA", "Primary: 35B45, 35J25, Secondary: 65N15, 68T07"], "primary_category": "Subjects:       Analysis of PDEs (math.AP)", "pdf_link": null, "comments": "Comments:      11 pages", "url": "http://arxiv.org/abs/2507.04940v1", "summary": "This paper establishes an explicit $L^2$-estimate for weak solutions $u$ to\nlinear elliptic equations in divergence form with general coefficients and\nexternal source term $f$, stating that the $L^2$-norm of $u$ over $U$ is\nbounded by a constant multiple of the $L^2$-norm of $f$ over $U$. In contrast\nto classical approaches based on compactness arguments, the proposed method,\nwhich employs a divergence-free transformation method, provides a computable\nand explicit constant $C>0$. The $L^2$-estimate remains robust even when there\nis no zero-order term, and the analysis further demonstrates that the constant\n$C>0$ decreases as the diffusion coefficient or the zero-order term increases.\nThese quantitative results provide a rigorous foundation for applications such\nas a posteriori error estimates in Physics-Informed Neural Networks (PINNs),\nwhere explicit error bounds are essential.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2507.04940v1", "cate": "math.AP", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05470", "title": "Temporal Conformal Prediction (TCP): A Distribution-Free Statistical and Machine Learning Framework for Adaptive Risk Forecasting", "authors": ["Agnideep Aich", "Ashit Baran Aich", "Dipak C. Jain"], "categories": ["stat.ML", "cs.LG", "62G08, 62M10, 62P05, 91G70, 68T05"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05470v1", "summary": "We propose Temporal Conformal Prediction (TCP), a novel framework for\nconstructing prediction intervals in financial time-series with guaranteed\nfinite-sample validity. TCP integrates quantile regression with a conformal\ncalibration layer that adapts online via a decaying learning rate. This hybrid\ndesign bridges statistical and machine learning paradigms, enabling TCP to\naccommodate non-stationarity, volatility clustering, and regime shifts which\nare hallmarks of real-world asset returns, without relying on rigid parametric\nassumptions. We benchmark TCP against established methods including GARCH,\nHistorical Simulation, and static Quantile Regression across equities (S&P\n500), cryptocurrency (Bitcoin), and commodities (Gold). Empirical results show\nthat TCP consistently delivers sharper intervals with competitive or superior\ncoverage, particularly in high-volatility regimes. Our study underscores TCP's\nstrength in navigating the coverage-sharpness tradeoff, a central challenge in\nmodern risk forecasting. Overall, TCP offers a distribution-free, adaptive, and\ninterpretable alternative for financial uncertainty quantification, advancing\nthe interface between statistical inference and machine learning in finance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05470v1", "cate": "stat.ML", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06231", "title": "RSRefSeg 2: Decoupling Referring Remote Sensing Image Segmentation with Foundation Models", "authors": ["Keyan Chen", "Chenyang Liu", "Bowen Chen", "Jiafan Zhang", "Zhengxia Zou", "Zhenwei Shi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06231v1", "summary": "Referring Remote Sensing Image Segmentation provides a flexible and\nfine-grained framework for remote sensing scene analysis via vision-language\ncollaborative interpretation. Current approaches predominantly utilize a\nthree-stage pipeline encompassing dual-modal encoding, cross-modal interaction,\nand pixel decoding. These methods demonstrate significant limitations in\nmanaging complex semantic relationships and achieving precise cross-modal\nalignment, largely due to their coupled processing mechanism that conflates\ntarget localization with boundary delineation. This architectural coupling\namplifies error propagation under semantic ambiguity while restricting model\ngeneralizability and interpretability. To address these issues, we propose\nRSRefSeg 2, a decoupling paradigm that reformulates the conventional workflow\ninto a collaborative dual-stage framework: coarse localization followed by fine\nsegmentation. RSRefSeg 2 integrates CLIP's cross-modal alignment strength with\nSAM's segmentation generalizability through strategic foundation model\ncollaboration. Specifically, CLIP is employed as the dual-modal encoder to\nactivate target features within its pre-aligned semantic space and generate\nlocalization prompts. To mitigate CLIP's misactivation challenges in\nmulti-entity scenarios described by referring texts, a cascaded second-order\nprompter is devised, which enhances precision through implicit reasoning via\ndecomposition of text embeddings into complementary semantic subspaces. These\noptimized semantic prompts subsequently direct the SAM to generate pixel-level\nrefined masks, thereby completing the semantic transmission pipeline. Extensive\nexperiments (RefSegRS, RRSIS-D, and RISBench) demonstrate that RSRefSeg 2\nsurpasses contemporary methods in segmentation accuracy (+~3% gIoU) and complex\nsemantic interpretation. Code is available at:\nhttps://github.com/KyanChen/RSRefSeg2.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06231v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05525", "title": "Approximate direct and inverse scattering for the AKNS system", "authors": ["Vladislav V. Kravchenko"], "categories": ["math.CA", "cs.NA", "math-ph", "math.MP", "math.NA", "nlin.SI", "physics.optics"], "primary_category": "Subjects:       Classical Analysis and ODEs (math.CA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05525v1", "summary": "We study the direct and inverse scattering problems for the AKNS\n(Ablowitz-Kaup-Newell-Segur) system. New representations for the Jost solutions\nare obtained in the form of the power series in terms of a transformed spectral\nparameter. In terms of that parameter, the Jost solutions are convergent power\nseries in corresponding unit disks. For the coefficients of the series simple\nrecurrent integration procedures are devised. Solution of the direct scattering\nproblem reduces to computing the coefficients and locating zeros of\ncorresponding analytic functions in the interior of the unit disk. Solution of\nthe inverse scattering problem reduces to the solution of two systems of linear\nalgebraic equations for the power series coefficients, while the potentials are\nrecovered from the first coefficients. The overall approach leads to a simple\nand efficient method for the numerical solution of both direct and inverse\nscattering problems, which is illustrated by numerical examples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05525v1", "cate": "math.CA", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06233", "title": "Learning to Track Any Points from Human Motion", "authors": ["Inès Hyeonsu Kim", "Seokju Cho", "Jahyeok Koo", "Junghyun Park", "Jiahui Huang", "Joon-Young Lee", "Seungryong Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project Page: this https URL", "url": "http://arxiv.org/abs/2507.06233v1", "summary": "Human motion, with its inherent complexities, such as non-rigid deformations,\narticulated movements, clothing distortions, and frequent occlusions caused by\nlimbs or other individuals, provides a rich and challenging source of\nsupervision that is crucial for training robust and generalizable point\ntrackers. Despite the suitability of human motion, acquiring extensive training\ndata for point tracking remains difficult due to laborious manual annotation.\nOur proposed pipeline, AnthroTAP, addresses this by proposing an automated\npipeline to generate pseudo-labeled training data, leveraging the Skinned\nMulti-Person Linear (SMPL) model. We first fit the SMPL model to detected\nhumans in video frames, project the resulting 3D mesh vertices onto 2D image\nplanes to generate pseudo-trajectories, handle occlusions using ray-casting,\nand filter out unreliable tracks based on optical flow consistency. A point\ntracking model trained on AnthroTAP annotated dataset achieves state-of-the-art\nperformance on the TAP-Vid benchmark, surpassing other models trained on real\nvideos while using 10,000 times less data and only 1 day in 4 GPUs, compared to\n256 GPUs used in recent state-of-the-art.", "comment": "Project Page: https://cvlab-kaist.github.io/AnthroTAP/", "pdf_url": "http://arxiv.org/pdf/2507.06233v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05502", "title": "Predicting mutational effects on protein binding from folding energy", "authors": ["Arthur Deng", "Karsten Householder", "Fang Wu", "Sebastian Thrun", "K. Christopher Garcia", "Brian Trippe"], "categories": ["q-bio.BM", "cs.LG"], "primary_category": "Subjects:       Biomolecules (q-bio.BM)", "pdf_link": null, "comments": "Comments:      Code: this https URL", "url": "http://arxiv.org/abs/2507.05502v1", "summary": "Accurate estimation of mutational effects on protein-protein binding energies\nis an open problem with applications in structural biology and therapeutic\ndesign. Several deep learning predictors for this task have been proposed, but,\npresumably due to the scarcity of binding data, these methods underperform\ncomputationally expensive estimates based on empirical force fields. In\nresponse, we propose a transfer-learning approach that leverages advances in\nprotein sequence modeling and folding stability prediction for this task. The\nkey idea is to parameterize the binding energy as the difference between the\nfolding energy of the protein complex and the sum of the folding energies of\nits binding partners. We show that using a pre-trained inverse-folding model as\na proxy for folding energy provides strong zero-shot performance, and can be\nfine-tuned with (1) copious folding energy measurements and (2) more limited\nbinding energy measurements. The resulting predictor, StaB-ddG, is the first\ndeep learning predictor to match the accuracy of the state-of-the-art empirical\nforce-field method FoldX, while offering an over 1,000x speed-up.", "comment": "Code: https://github.com/LDeng0205/StaB-ddG", "pdf_url": "http://arxiv.org/pdf/2507.05502v1", "cate": "q-bio.BM", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05633", "title": "SARA: Selective and Adaptive Retrieval-augmented Generation with Context Compression", "authors": ["Yiqiao Jin", "Kartik Sharma", "Vineeth Rakesh", "Yingtong Dou", "Menghai Pan", "Mahashweta Das", "Srijan Kumar"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      20 pages", "url": "http://arxiv.org/abs/2507.05633v1", "summary": "Retrieval-augmented Generation (RAG) extends large language models (LLMs)\nwith external knowledge but faces key challenges: restricted effective context\nlength and redundancy in retrieved documents. Pure compression-based approaches\nreduce input size but often discard fine-grained details essential for factual\naccuracy. We propose SARA, a unified RAG framework that balances local\nprecision and global knowledge coverage under tight context budgets. SARA\ncombines natural-language text snippets with semantic compression vectors to\njointly enhance context efficiency and answer correctness. It represents\ncontexts at two complementary levels: 1) fine-grained natural-language spans\nthat preserve critical entities and numerical values, and 2) compact,\ninterpretable vectors that summarize high-level semantics. An iterative\nevidence-selection module employs the compression vectors for dynamic reranking\nof contexts. Across 9 datasets and 5 open-source LLMs spanning 3 model families\n(Mistral, Llama, and Gemma), SARA consistently improves answer relevance\n(+17.71), answer correctness (+13.72), and semantic similarity (+15.53),\ndemonstrating the importance of integrating textual and compressed\nrepresentations for robust, context-efficient RAG.", "comment": "20 pages", "pdf_url": "http://arxiv.org/pdf/2507.05633v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06199", "title": "A Generalized $\\ell_1$-Merit Function SQP Method Using Function Approximations with Tunable Accuracy", "authors": ["Dane S. Grundvig", "Matthias Heinkenschloss"], "categories": ["math.OC", "cs.NA", "math.NA", "90C55, 65K05, 49M37, 49M41"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06199v1", "summary": "This paper develops a generalization of the line-search sequential quadratic\nprogramming (SQP) algorithm with $\\ell_1$-merit function that uses objective\nand constraint function approximations with tunable accuracy to solve smooth\nequality-constrained optimization problems. The evaluation of objective and\nconstraint functions and their gradients is potentially computationally\nexpensive, but it is assumed that one can construct effective, computationally\ninexpensive models of these functions. This paper specifies how these models\ncan be used to generate new iterates. At each iteration, the models have to\nsatisfy function error and relative gradient error tolerances determined by the\nalgorithm based on its progress. Moreover, bounds for the model errors are used\nto explore regions where the combined objective function and constraint models\nare sufficiently accurate. The algorithm has the same first-order global\nconvergence properties as a line-search SQP algorithm with $\\ell_1$-merit\nfunction, but only uses objective and constraint function models and the model\nerror bounds. The algorithm is applied to a discretized boundary control\nproblem in which the evaluation of the objective and constraint functions\nrequires the solution of the Boussinesq partial differential equation (PDE).\nThe models are constructed from projection-based reduced-order models of the\nBoussinesq PDE.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06199v1", "cate": "math.OC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05535", "title": "Special-Unitary Parameterization for Trainable Variational Quantum Circuits", "authors": ["Kuan-Cheng Chen", "Huan-Hsin Tseng", "Samuel Yen-Chi Chen", "Chen-Yu Liu", "Kin K. Leung"], "categories": ["quant-ph", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05535v1", "summary": "We propose SUN-VQC, a variational-circuit architecture whose elementary\nlayers are single exponentials of a symmetry-restricted Lie subgroup,\n$\\mathrm{SU}(2^{k}) \\subset \\mathrm{SU}(2^{n})$ with $k \\ll n$. Confining the\nevolution to this compact subspace reduces the dynamical Lie-algebra dimension\nfrom $\\mathcal{O}(4^{n})$ to $\\mathcal{O}(4^{k})$, ensuring only polynomial\nsuppression of gradient variance and circumventing barren plateaus that plague\nhardware-efficient ans\\\"atze. Exact, hardware-compatible gradients are obtained\nusing a generalized parameter-shift rule, avoiding ancillary qubits and\nfinite-difference bias. Numerical experiments on quantum auto-encoding and\nclassification show that SUN-VQCs sustain order-of-magnitude larger gradient\nsignals, converge 2--3$\\times$ faster, and reach higher final fidelities than\ndepth-matched Pauli-rotation or hardware-efficient circuits. These results\ndemonstrate that Lie-subalgebra engineering provides a principled, scalable\nroute to barren-plateau-resilient VQAs compatible with near-term quantum\nprocessors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05535v1", "cate": "quant-ph", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2401.04016", "title": "Stable approximation of Helmholtz solutions in the 3D ball using evanescent plane waves", "authors": ["Nicola Galante", "Andrea Moiola", "Emile Parolin"], "categories": ["math.NA", "cs.NA", "35J05, 41A30, 42C15, 44A15"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2401.04016v2", "summary": "The goal of this paper is to show that evanescent plane waves are much better\nat numerically approximating Helmholtz solutions than classical propagative\nplane waves. By generalizing the Jacobi$\\unicode{x2013}$Anger identity to\ncomplex-valued directions, we first prove that any solution of the Helmholtz\nequation on a three-dimensional ball can be written as a continuous\nsuperposition of evanescent plane waves in a stable way. We then propose a\npractical numerical recipe to select discrete approximation sets of evanescent\nplane waves, which exhibits considerable improvements over standard propagative\nplane wave schemes in numerical experiments. We show that all this is not\npossible for propagative plane waves: they cannot stably represent general\nHelmholtz solutions, and any approximation based on discrete sets of\npropagative plane waves is doomed to have exponentially large coefficients and\nthus to be numerically unstable. This paper is motivated by applications to\nTrefftz-type Galerkin schemes and extends the recent results in [Parolin,\nHuybrechs and Moiola, M2AN, 2023] from two to three space dimensions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2401.04016v2", "cate": "math.NA", "date": "2024-01-08", "updated": "2025-07-08"}
{"id": "2411.01746", "title": "Entropy stable conservative flux form neural networks", "authors": ["Lizuo Liu", "Tongtong Li", "Anne Gelb", "Yoonsang Lee"], "categories": ["math.NA", "cs.LG", "cs.NA", "65M08, 68T07, 65M22, 65M32, 65D25"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      27 pages, 18 figures", "url": "http://arxiv.org/abs/2411.01746v2", "summary": "We propose an entropy-stable conservative flux form neural network (CFN) that\nintegrates classical numerical conservation laws into a data-driven framework\nusing the entropy-stable, second-order, and non-oscillatory Kurganov-Tadmor\n(KT) scheme. The proposed entropy-stable CFN uses slope limiting as a denoising\nmechanism, ensuring accurate predictions in both noisy and sparse observation\nenvironments, as well as in both smooth and discontinuous regions. Numerical\nexperiments demonstrate that the entropy-stable CFN achieves both stability and\nconservation while maintaining accuracy over extended time domains.\nFurthermore, it successfully predicts shock propagation speeds in long-term\nsimulations, {\\it without} oracle knowledge of later-time profiles in the\ntraining data.", "comment": "27 pages, 18 figures", "pdf_url": "http://arxiv.org/pdf/2411.01746v2", "cate": "math.NA", "date": "2024-11-04", "updated": "2025-07-08"}
{"id": "2507.05550", "title": "A Malliavin calculus approach to score functions in diffusion generative models", "authors": ["Ehsan Mirafzali", "Frank Proske", "Utkarsh Gupta", "Daniele Venturi", "Razvan Marinescu"], "categories": ["stat.ML", "cs.LG", "math.PR"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05550v1", "summary": "Score-based diffusion generative models have recently emerged as a powerful\ntool for modelling complex data distributions. These models aim at learning the\nscore function, which defines a map from a known probability distribution to\nthe target data distribution via deterministic or stochastic differential\nequations (SDEs). The score function is typically estimated from data using a\nvariety of approximation techniques, such as denoising or sliced score\nmatching, Hyv\\\"arien's method, or Schr\\\"odinger bridges. In this paper, we\nderive an exact, closed form, expression for the score function for a broad\nclass of nonlinear diffusion generative models. Our approach combines modern\nstochastic analysis tools such as Malliavin derivatives and their adjoint\noperators (Skorokhod integrals or Malliavin Divergence) with a new Bismut-type\nformula. The resulting expression for the score function can be written\nentirely in terms of the first and second variation processes, with all\nMalliavin derivatives systematically eliminated, thereby enhancing its\npractical applicability. The theoretical framework presented in this work\noffers a principled foundation for advancing score estimation methods in\ngenerative modelling, enabling the design of new sampling algorithms for\ncomplex probability distributions. Our results can be extended to broader\nclasses of stochastic differential equations, opening new directions for the\ndevelopment of score-based diffusion generative models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05550v1", "cate": "stat.ML", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2411.10758", "title": "Optimal convergence in finite element semi-discrete error analysis of the Doyle-Fuller-Newman model beyond 1D with a novel projection operator", "authors": ["Shu Xu", "Liqun Cao"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      This is the final version of the manuscript published in IMA Journal of Numerical Analysis. The published version is available at: this https URL Licensed under CC BY 4.0", "url": "http://arxiv.org/abs/2411.10758v2", "summary": "We present a finite element semi-discrete error analysis for the\nDoyle-Fuller-Newman model, which is the most popular model for lithium-ion\nbatteries. Central to our approach is a novel projection operator designed for\nthe pseudo-($N$+1)-dimensional equation, offering a powerful tool for\nmultiscale equation analysis. Our results bridge a gap in the analysis for\ndimensions $2 \\le N \\le 3$ and achieve optimal convergence rates of $h+(\\Delta\nr)^2$. Additionally, we perform a detailed numerical verification, marking the\nfirst such validation in this context. By avoiding the change of variables, our\nerror analysis can also be extended beyond isothermal conditions.", "comment": "This is the final version of the manuscript published in IMA Journal\n  of Numerical Analysis. The published version is available at:\n  https://doi.org/10.1093/imanum/draf065 Licensed under CC BY 4.0", "pdf_url": "http://arxiv.org/pdf/2411.10758v2", "cate": "math.NA", "date": "2024-11-16", "updated": "2025-07-08"}
{"id": "2507.05562", "title": "Exact and efficient basis pursuit denoising via differential inclusions and a selection principle", "authors": ["Gabriel P. Langlois", "Jérôme Darbon"], "categories": ["math.OC", "cs.LG", "math.FA", "90C25, 65K05, 37N40, 46N10, 34A60, 62J07", "G.1.6; I.5.4"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      50 pages, 2 figures, submitted", "url": "http://arxiv.org/abs/2507.05562v1", "summary": "Basis pursuit denoising (BPDN) is a cornerstone of compressive sensing,\nstatistics and machine learning. While various algorithms for BPDN have been\nproposed, they invariably suffer from drawbacks and must either favor\nefficiency at the expense of accuracy or vice versa. As such, state-of-the-art\nalgorithms remain ineffective for high-dimensional applications that require\naccurate solutions within a reasonable amount of computational time. In this\nwork, we address this issue and propose an exact and efficient algorithm for\nBPDN using differential inclusions. Specifically, we prove that a selection\nprinciple from the theory of differential inclusions turns the dual problem of\nBPDN into calculating the trajectory of an \\emph{integrable} projected\ndynamical system, that is, whose trajectory and asymptotic limit can be\ncomputed exactly. Our analysis naturally yields an exact algorithm, numerically\nup to machine precision, that is amenable to computing regularization paths and\nvery fast. Numerical experiments confirm that our algorithm outperforms the\nstate-of-the-art algorithms in both accuracy and efficiency. Moreover, we show\nthat the global continuation of solutions (in terms of the hyperparameter and\ndata) of the projected dynamical system yields a rigorous homotopy algorithm\nfor BPDN, as well as a novel greedy algorithm for computing feasible solutions\nto basis pursuit in strongly polynomial time. Beyond this work, we expect that\nour results and analysis can be adapted to compute exact or approximate\nsolutions to a broader class of polyhedral-constrained optimization problems.", "comment": "50 pages, 2 figures, submitted", "pdf_url": "http://arxiv.org/pdf/2507.05562v1", "cate": "math.OC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2504.08773", "title": "Counterfactual Inference under Thompson Sampling", "authors": ["Olivier Jeunen"], "categories": ["cs.IR", "cs.LG", "stat.ME"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      To appear in the Nineteenth ACM Conference on Recommender Systems (RecSys '25)", "url": "http://arxiv.org/abs/2504.08773v2", "summary": "Recommender systems exemplify sequential decision-making under uncertainty,\nstrategically deciding what content to serve to users, to optimise a range of\npotential objectives. To balance the explore-exploit trade-off successfully,\nThompson sampling provides a natural and widespread paradigm to\nprobabilistically select which action to take. Questions of causal and\ncounterfactual inference, which underpin use-cases like offline evaluation, are\nnot straightforward to answer in these contexts. Specifically, whilst most\nexisting estimators rely on action propensities, these are not readily\navailable under Thompson sampling procedures.\n  We derive exact and efficiently computable expressions for action\npropensities under a variety of parameter and outcome distributions, enabling\nthe use of off-policy estimators in Thompson sampling scenarios. This opens up\na range of practical use-cases where counterfactual inference is crucial,\nincluding unbiased offline evaluation of recommender systems, as well as\ngeneral applications of causal inference in online advertising,\npersonalisation, and beyond.", "comment": "To appear in the Nineteenth ACM Conference on Recommender Systems\n  (RecSys '25)", "pdf_url": "http://arxiv.org/pdf/2504.08773v2", "cate": "cs.IR", "date": "2025-04-03", "updated": "2025-07-08"}
{"id": "2411.15722", "title": "Optimal-rate error estimates and a twice decoupled solver for a backward Euler finite element scheme of the Doyle-Fuller-Newman model of lithium-ion cells", "authors": ["Shu Xu", "Liqun Cao"], "categories": ["math.NA", "cs.NA", "physics.chem-ph", "physics.comp-ph"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.15722v3", "summary": "We investigate the convergence of a backward Euler finite element\ndiscretization applied to a multi-domain and multi-scale elliptic-parabolic\nsystem, derived from the Doyle-Fuller-Newman model for lithium-ion cells. We\nestablish optimal-order error estimates for the solution in the norms\n$l^2(H^1)$ and $l^2(L^2(H^q_r))$, $q=0,1$. To improve computational efficiency,\nwe propose a novel solver that accelerates the solution process and controls\nmemory usage. Numerical experiments with realistic battery parameters validate\nthe theoretical error rates and demonstrate the significantly superior\nperformance of the proposed solver over existing solvers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.15722v3", "cate": "math.NA", "date": "2024-11-24", "updated": "2025-07-08"}
{"id": "2505.07685", "title": "Periods of fibre products of elliptic surfaces and the Gamma conjecture", "authors": ["Eric Pichon-Pharabod"], "categories": ["math.AG", "cs.SC", "14Q15, 14J32, 32G20 (Primary) 14D05, 14J33 (Secondary)"], "primary_category": "Subjects:       Algebraic Geometry (math.AG)", "pdf_link": null, "comments": "Comments:      39 pages, 4 figures", "url": "http://arxiv.org/abs/2505.07685v2", "summary": "We provide an algorithm for computing a basis of homology of fibre products\nof elliptic surfaces over $\\mathbb P^1$, along with the corresponding\nintersection product and period matrices. We use this data to investigate the\nGamma conjecture for Calabi-Yau threefolds obtained in this manner. We find a\nformula that works for all operators of a list of 105 fibre products, as well\nas for fourth order operators of the Calabi-Yau database. This algorithm comes\nwith a SageMath implementation.", "comment": "39 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2505.07685v2", "cate": "math.AG", "date": "2025-05-12", "updated": "2025-07-08"}
{"id": "2507.05517", "title": "Empowering Healthcare Practitioners with Language Models: Structuring Speech Transcripts in Two Real-World Clinical Applications", "authors": ["Jean-Philippe Corbeil", "Asma Ben Abacha", "George Michalopoulos", "Phillip Swazinna", "Miguel Del-Agua", "Jerome Tremblay", "Akila Jeeson Daniel", "Cari Bader", "Kevin Cho", "Pooja Krishnan", "Nathan Bodenstab", "Thomas Lin", "Wenxuan Teng", "Francois Beaulieu", "Paul Vozila"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05517v1", "summary": "Large language models (LLMs) such as GPT-4o and o1 have demonstrated strong\nperformance on clinical natural language processing (NLP) tasks across multiple\nmedical benchmarks. Nonetheless, two high-impact NLP tasks - structured tabular\nreporting from nurse dictations and medical order extraction from\ndoctor-patient consultations - remain underexplored due to data scarcity and\nsensitivity, despite active industry efforts. Practical solutions to these\nreal-world clinical tasks can significantly reduce the documentation burden on\nhealthcare providers, allowing greater focus on patient care. In this paper, we\ninvestigate these two challenging tasks using private and open-source clinical\ndatasets, evaluating the performance of both open- and closed-weight LLMs, and\nanalyzing their respective strengths and limitations. Furthermore, we propose\nan agentic pipeline for generating realistic, non-sensitive nurse dictations,\nenabling structured extraction of clinical observations. To support further\nresearch in both areas, we release SYNUR and SIMORD, the first open-source\ndatasets for nurse observation extraction and medical order extraction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05517v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05006", "title": "Do We Really Need Specialization? Evaluating Generalist Text Embeddings for Zero-Shot Recommendation and Search", "authors": ["Matteo Attimonelli", "Alessandro De Bellis", "Claudio Pomo", "Dietmar Jannach", "Eugenio Di Sciascio", "Tommaso Di Noia"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accept as Short Paper at RecSys 2025", "url": "http://arxiv.org/abs/2507.05006v2", "summary": "Pre-trained language models (PLMs) are widely used to derive semantic\nrepresentations from item metadata in recommendation and search. In sequential\nrecommendation, PLMs enhance ID-based embeddings through textual metadata,\nwhile in product search, they align item characteristics with user intent.\nRecent studies suggest task and domain-specific fine-tuning are needed to\nimprove representational power. This paper challenges this assumption, showing\nthat Generalist Text Embedding Models (GTEs), pre-trained on large-scale\ncorpora, can guarantee strong zero-shot performance without specialized\nadaptation. Our experiments demonstrate that GTEs outperform traditional and\nfine-tuned models in both sequential recommendation and product search. We\nattribute this to a superior representational power, as they distribute\nfeatures more evenly across the embedding space. Finally, we show that\ncompressing embedding dimensions by focusing on the most informative directions\n(e.g., via PCA) effectively reduces noise and improves the performance of\nspecialized models. To ensure reproducibility, we provide our repository at\nhttps://split.to/gte4ps.", "comment": "Accept as Short Paper at RecSys 2025", "pdf_url": "http://arxiv.org/pdf/2507.05006v2", "cate": "cs.IR", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2503.10774", "title": "Isoparametric finite element methods for mean curvature flow and surface diffusion", "authors": ["Harald Garcke", "Robert Nürnberg", "Simon Praetorius", "Ganghui Zhang"], "categories": ["math.NA", "cs.NA", "65M60, 65M12, 35K55, 53C44"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      29 pages, 19 figures", "url": "http://arxiv.org/abs/2503.10774v2", "summary": "We propose higher-order isoparametric finite element approximations for mean\ncurvature flow and surface diffusion. The methods are natural extensions of the\npiecewise linear finite element methods introduced by Barrett, Garcke, and\nN\\\"urnberg (BGN) in a series of papers in 2007 and 2008. The proposed schemes\nexhibit unconditional energy stability and inherit the favorable mesh quality\nof the original BGN methods. Moreover, in the case of surface diffusion we\npresent structure-preserving higher-order isoparametric finite element methods.\nIn addition to being unconditionally stable, these also conserve the enclosed\nvolume. Extensive numerical results demonstrate the higher-order spatial\naccuracy, the unconditional energy stability, the volume preservation for\nsurface diffusion, and the good mesh quality.", "comment": "29 pages, 19 figures", "pdf_url": "http://arxiv.org/pdf/2503.10774v2", "cate": "math.NA", "date": "2025-03-13", "updated": "2025-07-08"}
{"id": "2411.01376", "title": "Multi-Channel Hypergraph Contrastive Learning for Matrix Completion", "authors": ["Xiang Li", "Changsheng Shui", "Zhongying Zhao", "Junyu Dong", "Yanwei Yu"], "categories": ["cs.LG", "cs.IR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.01376v2", "summary": "Rating is a typical user explicit feedback that visually reflects how much a\nuser likes a related item. The (rating) matrix completion is essentially a\nrating prediction process, which is also a significant problem in recommender\nsystems. Recently, graph neural networks (GNNs) have been widely used in matrix\ncompletion, which captures users' preferences over items by formulating a\nrating matrix as a bipartite graph. However, existing methods are susceptible\ndue to data sparsity and long-tail distribution in real-world scenarios.\nMoreover, the messaging mechanism of GNNs makes it difficult to capture\nhigh-order correlations and constraints between nodes, which are essentially\nuseful in recommendation tasks. To tackle these challenges, we propose a\nMulti-Channel Hypergraph Contrastive Learning framework for matrix completion,\nnamed MHCL. Specifically, MHCL adaptively learns hypergraph structures to\ncapture high-order correlations between nodes and jointly captures local and\nglobal collaborative relationships through attention-based cross-view\naggregation. Additionally, to consider the magnitude and order information of\nratings, we treat different rating subgraphs as different channels, encourage\nalignment between adjacent ratings, and further achieve the mutual enhancement\nbetween different ratings through multi-channel cross-rating contrastive\nlearning. Extensive experiments on five public datasets demonstrate that the\nproposed method significantly outperforms the current state-of-the-art\napproaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.01376v2", "cate": "cs.LG", "date": "2024-11-02", "updated": "2025-07-08"}
{"id": "2503.24131", "title": "A simple and general framework for the construction of exactly div-curl-grad compatible discontinuous Galerkin finite element schemes on unstructured simplex meshes", "authors": ["R. Abgrall", "M. Dumbser", "P. H. Maire"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.24131v2", "summary": "We introduce a new family of discontinuous Galerkin (DG) finite element\nschemes for the discretization of first order systems of hyperbolic partial\ndifferential equations (PDE) on unstructured simplex meshes in two and three\nspace dimensions that respect the two basic vector calculus identities exactly\nalso at the discrete level, namely that the curl of the gradient is zero and\nthat the divergence of the curl is zero. The key ingredient here is the\nconstruction of two compatible discrete nabla operators, a primary one and a\ndual one, both defined on general unstructured simplex meshes in multiple space\ndimensions. Our new schemes extend existing cell-centered finite volume methods\nbased on corner fluxes to arbitrary high order of accuracy in space. An\nimportant feature of our new method is the fact that only two different\ndiscrete function spaces are needed to represent the numerical solution, and\nthe choice of the appropriate function space for each variable is related to\nthe origin and nature of the underlying PDE. The first class of variables is\ndiscretized at the aid of a discontinuous Galerkin approach, where the\nnumerical solution is represented via piecewise polynomials of degree N and\nwhich are allowed to jump across element interfaces. This set of variables is\nrelated to those PDE which are mere consequences of the definitions, derived\nfrom some abstract scalar and vector potentials, and for which involutions like\nthe divergence-free or the curl-free property must hold if satisfied by the\ninitial data. The second class of variables is discretized via classical\ncontinuous Lagrange finite elements of approximation degree M=N+1 and is\nrelated to those PDE which can be derived as the Euler-Lagrange equations of an\nunderlying variational principle.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.24131v2", "cate": "math.NA", "date": "2025-03-31", "updated": "2025-07-08"}
{"id": "2507.05320", "title": "Teaching Sustainable Creative Technologies", "authors": ["Chelsea Thompto"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      LOCO 2024, December 3, 2024, Glasgow/Online", "url": "http://arxiv.org/abs/2507.05320v1", "summary": "Artists and especially new media artists contribute to public perceptions and\nadoption of new technologies through their own use of emerging media\ntechnologies such as augmented and virtual reality, generative image systems,\nand high-resolution displays in the production of their work. In this way, art\nand media production can be understood as part of the larger issue of\nunsustainable computational consumption. As such, it is critical for artists to\ndevelop, share, and promote new and more sustainable methods of engaging with\ntechnology, especially within the context of higher education. This paper will\nexplore how artists might implement more sustainable methods by considering the\nrelationship between the technical approaches of compute reuse, sustainable web\ndevelopment, and frugal computing, and the concepts of material specificity ,\nfuturity, and media archaeology . Proposing three methods of less\ncarbon-intensive artistic production and a set of guidelines for introducing\nsustainable methods into arts and technology curriculum, this paper will\noutline not only the technical viability of these approaches but also the rich\nconceptual opportunities these approaches might offer to artists and viewers\nalike. For each method, models for pedagogical implementation will be explored\nwith an emphasis on how local resources and sustainability contexts should play\na role.", "comment": "LOCO 2024, December 3, 2024, Glasgow/Online", "pdf_url": "http://arxiv.org/pdf/2507.05320v1", "cate": "cs.CY", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05610", "title": "On the Inherent Privacy of Zeroth Order Projected Gradient Descent", "authors": ["Devansh Gupta", "Meisam Razaviyayn", "Vatsal Sharan"], "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      Accepted at AISTATS'25", "url": "http://arxiv.org/abs/2507.05610v1", "summary": "Differentially private zeroth-order optimization methods have recently gained\npopularity in private fine tuning of machine learning models due to their\nreduced memory requirements. Current approaches for privatizing zeroth-order\nmethods rely on adding Gaussian noise to the estimated zeroth-order gradients.\nHowever, since the search direction in the zeroth-order methods is inherently\nrandom, researchers including Tang et al. (2024) and Zhang et al. (2024a) have\nraised an important question: is the inherent noise in zeroth-order estimators\nsufficient to ensure the overall differential privacy of the algorithm? This\nwork settles this question for a class of oracle-based optimization algorithms\nwhere the oracle returns zeroth-order gradient estimates. In particular, we\nshow that for a fixed initialization, there exist strongly convex objective\nfunctions such that running (Projected) Zeroth-Order Gradient Descent (ZO-GD)\nis not differentially private. Furthermore, we show that even with random\ninitialization and without revealing (initial and) intermediate iterates, the\nprivacy loss in ZO-GD can grow superlinearly with the number of iterations when\nminimizing convex objective functions.", "comment": "Accepted at AISTATS'25", "pdf_url": "http://arxiv.org/pdf/2507.05610v1", "cate": "math.OC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.02962", "title": "RAG-R1 : Incentivize the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism", "authors": ["Zhiwen Tan", "Jiaming Huang", "Qintong Wu", "Hongxuan Zhang", "Chenyi Zhuang", "Jinjie Gu"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.02962v2", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, while they remain prone to generating hallucinated or outdated\nresponses due to their static internal knowledge. Recent advancements in\nRetrieval-Augmented Generation (RAG) methods have explored enhancing models'\nsearch and reasoning capabilities through reinforcement learning (RL). Although\nthese methods demonstrate promising results, they face challenges in training\nstability and encounter issues such as substantial inference time and\nrestricted capabilities due to the single-query mode. In this paper, we propose\nRAG-R1, a novel training framework designed to enable LLMs to adaptively\nleverage internal and external knowledge during the reasoning process. We\nfurther expand the generation and retrieval processes within the framework from\nsingle-query mode to multi-query parallelism, aimed at reducing inference time\nand enhancing the model's capabilities. Extensive experiments on seven\nquestion-answering benchmarks demonstrate that our method outperforms the\nstrongest baseline by up to 13.2% and decreases inference time by 11.1%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.02962v2", "cate": "cs.CL", "date": "2025-06-30", "updated": "2025-07-08"}
{"id": "2506.12402", "title": "A new Lagrange multiplier approach for constructing structure preserving schemes, III. Bound preserving and energy dissipating", "authors": ["Qing Cheng", "Tingfeng Wang", "Xiaofei Zhao"], "categories": ["math.NA", "cs.NA", "65M12, 35K20, 35K35, 35K55, 65Z05"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.12402v2", "summary": "In the third part of this series, we continue to explore the idea of the\nLagrange multiplier introduced in the first part [2020, Comput. Methods Appl.\nMech. Engr., 391, 114585] and refined in the second part [2022, SIAM J. Numer.\nAnal., 60, 970-998] to further develop efficient and accurate numerical schemes\nthat preserve the maximum bound principle (MBP) and energy dissipation for\nsolving gradient flows. The proposed framework allows us to begin with any\nconventional scheme as a predictor step which is followed by two consecutive\ncorrection steps written in the form of the Karush-Kuhn-Tucker conditions for\nstructure preserving. The preservation of both energy dissipation and MBP and\nthe solvability of the general resulting scheme are rigorously established. In\nsuch a framework, we implement an explicit and efficient scheme by employing\nthe Runge-Kutta exponential time differencing scheme as the predictor step, and\ngive its convergence analysis. Extensive numerical experiments are provided to\nvalidate the effectiveness of our approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.12402v2", "cate": "math.NA", "date": "2025-06-14", "updated": "2025-07-08"}
{"id": "2507.03009", "title": "PDFMathTranslate: Scientific Document Translation Preserving Layouts", "authors": ["Rongxin Ouyang", "Chang Chu", "Zhikuang Xin", "Xiangyao Ma"], "categories": ["cs.CL", "cs.IR", "cs.LG", "68T50, 68T45, 68U10, 68U15", "D.2.2; I.2.10; I.2.7; J.0"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      7 pages, 4 figures", "url": "http://arxiv.org/abs/2507.03009v2", "summary": "Language barriers in scientific documents hinder the diffusion and\ndevelopment of science and technologies. However, prior efforts in translating\nsuch documents largely overlooked the information in layouts. To bridge the\ngap, we introduce PDFMathTranslate, the world's first open-source software for\ntranslating scientific documents while preserving layouts. Leveraging the most\nrecent advances in large language models and precise layout detection, we\ncontribute to the community with key improvements in precision, flexibility,\nand efficiency. The work has been open-sourced at\nhttps://github.com/byaidu/pdfmathtranslate with more than 222k downloads.", "comment": "7 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.03009v2", "cate": "cs.CL", "date": "2025-07-02", "updated": "2025-07-08"}
{"id": "2507.02500", "title": "Goal-oriented optimal sensor placement for PDE-constrained inverse problems in crisis management", "authors": ["Marco Mattuschka", "Noah An der Lan", "Max von Danwitz", "Daniel Wolff", "Alexander Popp"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.02500v2", "summary": "This paper presents a novel framework for goal-oriented optimal static sensor\nplacement and dynamic sensor steering in PDE-constrained inverse problems,\nutilizing a Bayesian approach accelerated by low-rank approximations. The\nframework is applied to airborne contaminant tracking, extending recent dynamic\nsensor steering methods to complex geometries for computational efficiency. A\nC-optimal design criterion is employed to strategically place sensors,\nminimizing uncertainty in predictions. Numerical experiments validate the\napproach's effectiveness for source identification and monitoring, highlighting\nits potential for real-time decision-making in crisis management scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.02500v2", "cate": "math.NA", "date": "2025-07-03", "updated": "2025-07-08"}
{"id": "2507.05400", "title": "Strategic Alignment Patterns in National AI Policies", "authors": ["Mohammad Hossein Azin", "Hessam Zandhessami"], "categories": ["cs.CY", "econ.GN", "q-fin.EC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05400v1", "summary": "This paper introduces a novel visual mapping methodology for assessing\nstrategic alignment in national artificial intelligence policies. The\nproliferation of AI strategies across countries has created an urgent need for\nanalytical frameworks that can evaluate policy coherence between strategic\nobjectives, foresight methods, and implementation instruments. Drawing on data\nfrom the OECD AI Policy Observatory, we analyze 15-20 national AI strategies\nusing a combination of matrix-based visualization and network analysis to\nidentify patterns of alignment and misalignment. Our findings reveal distinct\nalignment archetypes across governance models, with notable variations in how\ncountries integrate foresight methodologies with implementation planning.\nHigh-coherence strategies demonstrate strong interconnections between economic\ncompetitiveness objectives and robust innovation funding instruments, while\ncommon vulnerabilities include misalignment between ethical AI objectives and\ncorresponding regulatory frameworks. The proposed visual mapping approach\noffers both methodological contributions to policy analysis and practical\ninsights for enhancing strategic coherence in AI governance. This research\naddresses significant gaps in policy evaluation methodology and provides\nactionable guidance for policymakers seeking to strengthen alignment in\ntechnological governance frameworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05400v1", "cate": "cs.CY", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.04942", "title": "SIGIR 2025 -- LiveRAG Challenge Report", "authors": ["David Carmel", "Simone Filice", "Guy Horowitz", "Yoelle Maarek", "Oren Somekh", "Ran Tavory", "Mehdi Ghissassi", "Edo Liberty", "Roy Miara"], "categories": ["cs.CL", "cs.IR", "H.3.3"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages, 5 tables", "url": "http://arxiv.org/abs/2507.04942v2", "summary": "The LiveRAG Challenge at SIGIR 2025, held between March and May 2025,\nprovided a competitive platform for advancing Retrieval-Augmented Generation\n(RAG) technologies. Participants from academia and industry were invited to\ndevelop a RAG-based question-answering system using a fixed corpus\n(Fineweb-10BT) and a common open-source LLM (Falcon3-10B-Instruct). The goal\nwas to facilitate challenging comparisons of retrieval and prompting\nstrategies. During the Live Challenge Day, 70 teams from 27 different countries\nprovided answers and supportive information to 500 unseen questions within a\nstrict two-hour time window. Evaluation was conducted in two stages: first an\nautomated LLM-as-a-judge approach was used to compute correctness and\nfaithfulness score, then a manual review of top ranked submissions was\nconducted. The finalists were announced on June 12, 2025, with prizes awarded\nduring the LiveRAG Workshop at SIGIR 2025 in Padua, Italy.", "comment": "9 pages, 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.04942v2", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2507.03909", "title": "A discontinuous Galerkin pressure correction scheme for the Oldroyd model of order one", "authors": ["Pratyay Mondal", "Rajen Kumar Sinha"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      This paper is currently under review in the journal Applied Numerical Mathematics", "url": "http://arxiv.org/abs/2507.03909v2", "summary": "We develop and analyze a discontinuous Galerkin pressure correction scheme\nfor the Oldroyd model of order one. The existence and uniqueness of the\ndiscrete solution as well as the consistency of the scheme are proved. The\nstability of the discrete velocity and pressure are established. We derive\noptimal $\\textit{a priori}$ error bounds for the fully discrete velocity in the\ndiscontinuous discrete space. In addition, an improved error estimate for the\nvelocity is derived in the $L^2$ norm which is optimal with respect to space\nand time. Furthermore, the error bound for the pressure is obtained via the\nestimates of discrete time derivative of the velocity. Finally, numerical\nexperiments confirm the optimal convergence rates.", "comment": "This paper is currently under review in the journal Applied Numerical\n  Mathematics", "pdf_url": "http://arxiv.org/pdf/2507.03909v2", "cate": "math.NA", "date": "2025-07-05", "updated": "2025-07-08"}
{"id": "2507.05559", "title": "MP-ALOE: An r2SCAN dataset for universal machine learning interatomic potentials", "authors": ["Matthew C. Kuner", "Aaron D. Kaplan", "Kristin A. Persson", "Mark Asta", "Daryl C. Chrzan"], "categories": ["cond-mat.mtrl-sci", "cs.AI", "physics.comp-ph"], "primary_category": "Subjects:       Materials Science (cond-mat.mtrl-sci)", "pdf_link": null, "comments": "Comments:      To download the dataset and associated files, see this https URL", "url": "http://arxiv.org/abs/2507.05559v1", "summary": "We present MP-ALOE, a dataset of nearly 1 million DFT calculations using the\naccurate r2SCAN meta-generalized gradient approximation. Covering 89 elements,\nMP-ALOE was created using active learning and primarily consists of\noff-equilibrium structures. We benchmark a machine learning interatomic\npotential trained on MP-ALOE, and evaluate its performance on a series of\nbenchmarks, including predicting the thermochemical properties of equilibrium\nstructures; predicting forces of far-from-equilibrium structures; maintaining\nphysical soundness under static extreme deformations; and molecular dynamic\nstability under extreme temperatures and pressures. MP-ALOE shows strong\nperformance on all of these benchmarks, and is made public for the broader\ncommunity to utilize.", "comment": "To download the dataset and associated files, see\n  https://doi.org/10.6084/m9.figshare.29452190", "pdf_url": "http://arxiv.org/pdf/2507.05559v1", "cate": "cond-mat.mtrl-sci", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.04991", "title": "Paired Explicit Relaxation Runge-Kutta Methods: Entropy-Conservative and Entropy-Stable High-Order Optimized Multirate Time Integration", "authors": ["Daniel Doehring", "Hendrik Ranocha", "Manuel Torrilhon"], "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "65L06, 65M20, 76-04, 70K20"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04991v2", "summary": "We present novel entropy-conservative and entropy-stable multirate\nRunge-Kutta methods based on Paired Explicit Runge-Kutta (P-ERK) schemes with\nrelaxation for conservation laws and related systems of partial differential\nequations. Optimized schemes up to fourth-order of accuracy are derived and\nvalidated in terms of order of consistency, conservation of linear invariants,\nand entropy conservation/stability. We demonstrate the effectiveness of these\nP-ERRK methods when combined with a high-order, entropy-conservative/stable\ndiscontinuous Galerkin spectral element method on unstructured meshes. The\nPaired Explicit Relaxation Runge-Kutta methods(P-ERRK) are readily implemented\nfor partitioned semidiscretizations arising from problems with equation-based\nscale separation such as non-uniform meshes. We highlight that the relaxation\napproach acts as a time-limiting technique which improves the nonlinear\nstability and thus robustness of the multirate schemes. The P-ERRK methods are\napplied to a range of problems, ranging from compressible Euler over\ncompressible Navier-Stokes to the visco-resistive magnetohydrodynamics\nequations in two and three spatial dimensions. For each test case, we compare\ncomputational load and runtime to standalone relaxed Runge-Kutta methods which\nare outperformed by factors up to four. All results can be reproduced using a\npublicly available repository.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04991v2", "cate": "math.NA", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2507.05866", "title": "Understanding support for AI regulation: A Bayesian network perspective", "authors": ["Andrea Cremaschi", "Dae-Jin Lee", "Manuele Leonelli"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05866v1", "summary": "As artificial intelligence (AI) becomes increasingly embedded in public and\nprivate life, understanding how citizens perceive its risks, benefits, and\nregulatory needs is essential. To inform ongoing regulatory efforts such as the\nEuropean Union's proposed AI Act, this study models public attitudes using\nBayesian networks learned from the nationally representative 2023 German survey\nCurrent Questions on AI. The survey includes variables on AI interest,\nexposure, perceived threats and opportunities, awareness of EU regulation, and\nsupport for legal restrictions, along with key demographic and political\nindicators. We estimate probabilistic models that reveal how personal\nengagement and techno-optimism shape public perceptions, and how political\norientation and age influence regulatory attitudes. Sobol indices and\nconditional inference identify belief patterns and scenario-specific responses\nacross population profiles. We show that awareness of regulation is driven by\ninformation-seeking behavior, while support for legal requirements depends\nstrongly on perceived policy adequacy and political alignment. Our approach\noffers a transparent, data-driven framework for identifying which public\nsegments are most responsive to AI policy initiatives, providing insights to\ninform risk communication and governance strategies. We illustrate this through\na focused analysis of support for AI regulation, quantifying the influence of\npolitical ideology, perceived risks, and regulatory awareness under different\nscenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05866v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05640", "title": "Learnable quantum spectral filters for hybrid graph neural networks", "authors": ["Ammar Daskin"], "categories": ["quant-ph", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      The simulation code and results used for this paper is publicly available at: this https URL", "url": "http://arxiv.org/abs/2507.05640v1", "summary": "In this paper, we describe a parameterized quantum circuit that can be\nconsidered as convolutional and pooling layers for graph neural networks. The\ncircuit incorporates the parameterized quantum Fourier circuit where the qubit\nconnections for the controlled gates derived from the Laplacian operator.\nSpecifically, we show that the eigenspace of the Laplacian operator of a graph\ncan be approximated by using QFT based circuit whose connections are determined\nfrom the adjacency matrix. For an $N\\times N$ Laplacian, this approach yields\nan approximate polynomial-depth circuit requiring only $n=log(N)$ qubits. These\ntypes of circuits can eliminate the expensive classical computations for\napproximating the learnable functions of the Laplacian through Chebyshev\npolynomial or Taylor expansions.\n  Using this circuit as a convolutional layer provides an $n-$ dimensional\nprobability vector that can be considered as the filtered and compressed graph\nsignal. Therefore, the circuit along with the measurement can be considered a\nvery efficient convolution plus pooling layer that transforms an\n$N$-dimensional signal input into $n-$dimensional signal with an exponential\ncompression. We then apply a classical neural network prediction head to the\noutput of the circuit to construct a complete graph neural network. Since the\ncircuit incorporates geometric structure through its graph connection-based\napproach, we present graph classification results for the benchmark datasets\nlisted in TUDataset library. Using only [1-100] learnable parameters for the\nquantum circuit and minimal classical layers (1000-5000 parameters) in a\ngeneric setting, the obtained results are comparable to and in some cases\nbetter than many of the baseline results, particularly for the cases when\ngeometric structure plays a significant role.", "comment": "The simulation code and results used for this paper is publicly\n  available at: https://github.com/adaskin/gnn-qsf", "pdf_url": "http://arxiv.org/pdf/2507.05640v1", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2410.23647", "title": "Acoustic wave diffraction by a quadrant of sound-soft scatterers", "authors": ["Matthew Nethercote", "Anastasia Kisil", "Raphael Assier"], "categories": ["math-ph", "cs.NA", "math.MP", "math.NA", "45E10, 35L05, 76N30"], "primary_category": "Subjects:       Mathematical Physics (math-ph)", "pdf_link": null, "comments": "Comments:      25 pages, 10 figures", "url": "http://arxiv.org/abs/2410.23647v2", "summary": "Motivated by research in metamaterials, we consider the challenging problem\nof acoustic wave scattering by a doubly periodic quadrant of sound-soft\nscatterers arranged in a square formation, which we have dubbed the quarter\nlattice. This leads to a Wiener--Hopf equation in two complex variables with\nthree unknown functions for which we can reduce and solve exactly using a new\nanalytic method. After some suitable truncations, the resulting linear system\nis inverted using elementary matrix arithmetic and the solution can be\nnumerically computed. This solution is also critically compared to a numerical\nleast squares collocation approach and to our previous method where we\ndecomposed the lattice into semi-infinite rows or columns.", "comment": "25 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2410.23647v2", "cate": "math-ph", "date": "2024-10-31", "updated": "2025-07-08"}
{"id": "2507.06018", "title": "Campaigning through the lens of Google: A large-scale algorithm audit of Google searches in the run-up to the Swiss Federal Elections 2023", "authors": ["Tobias Rohrbach", "Mykola Makhortykh", "Maryna Sydorova"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      44 pages", "url": "http://arxiv.org/abs/2507.06018v1", "summary": "Search engines like Google have become major sources of information for\nvoters during election campaigns. To assess potential biases across candidates'\ngender and partisan identities in the algorithmic curation of candidate\ninformation, we conducted a large-scale algorithm audit analyzing Google's\nselection and ranking of information about candidates for the 2023 Swiss\nFederal Elections, three and one week before the election day. Results indicate\nthat text searches prioritize media sources in search output but less so for\nwomen politicians. Image searches revealed a tendency to reinforce stereotypes\nabout women candidates, marked by a disproportionate focus on stereotypically\npleasant emotions for women, particularly among right-leaning candidates.\nCrucially, we find that patterns of candidates' representation in Google text\nand image searches are predictive of their electoral performance.", "comment": "44 pages", "pdf_url": "http://arxiv.org/pdf/2507.06018v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05598", "title": "Self-Review Framework for Enhancing Instruction Following Capability of LLM", "authors": ["Sihyun Park"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05598v1", "summary": "Various techniques have been proposed to improve large language models (LLMs)\nadherence to formatting and instruction constraints. One of the most effective\napproaches involves utilizing high-quality data generated by powerful models.\nHowever, such models often fail to fully comply with complex instructions in a\nsingle generation. To address this limitation, iterative revision methods have\nbeen introduced. Nevertheless, as the number of data points and revision\niterations increases, the associated monetary costs grow significantly. As a\nresource-efficient alternative, methods have been proposed that leverage\nhigh-performance evaluation tools to compensate for the limited self-evaluation\ncapabilities of open-source LLMs. However, these approaches often lead to a\ndegradation in output quality due to excessive revision. To overcome these\nchallenges, we propose Re5, a self-evaluation and revision framework designed\nto enhance instruction-following performance while preserving the quality of\nthe generated content. Re5 extracts task and constraint components from user\ninstructions, performs structural evaluations to prevent error accumulation,\nand applies fine-grained constraint-specific content evaluations followed by\nselective revisions. This process ensures precise and quality-preserving\nimprovements. The final high-quality outputs are used for alignment tuning,\nenabling long-term alignment improvements through a data-centric iterative\nrefinement loop. Experimental results demonstrate that Re5 achieves\ninstruction-following performance comparable to models trained on data\ngenerated by GPT-4o-mini, a high-performance model, even with a small amount of\ndata while maintaining response quality with a 64.24%-win rate over the\nnon-revised initial responses. These results validate Re5 as an efficient and\neffective solution for enhancing instruction adherence with minimal external\nsupervision.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05598v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05658", "title": "HRRRCast: a data-driven emulator for regional weather forecasting at convection allowing scales", "authors": ["Daniel Abdi", "Isidora Jankov", "Paul Madden", "Vanderlei Vargas", "Timothy A. Smith", "Sergey Frolov", "Montgomery Flora", "Corey Potvin"], "categories": ["physics.ao-ph", "cs.LG"], "primary_category": "Subjects:       Atmospheric and Oceanic Physics (physics.ao-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05658v1", "summary": "The High-Resolution Rapid Refresh (HRRR) model is a convection-allowing model\nused in operational weather forecasting across the contiguous United States\n(CONUS). To provide a computationally efficient alternative, we introduce\nHRRRCast, a data-driven emulator built with advanced machine learning\ntechniques. HRRRCast includes two architectures: a ResNet-based model (ResHRRR)\nand a Graph Neural Network-based model (GraphHRRR). ResHRRR uses convolutional\nneural networks enhanced with squeeze-and-excitation blocks and Feature-wise\nLinear Modulation, and supports probabilistic forecasting via the Denoising\nDiffusion Implicit Model (DDIM). To better handle longer lead times, we train a\nsingle model to predict multiple lead times (1h, 3h, and 6h), then use a greedy\nrollout strategy during inference. When evaluated on composite reflectivity\nover the full CONUS domain using ensembles of 3 to 10 members, ResHRRR\noutperforms HRRR forecast at light rainfall threshold (20 dBZ) and achieves\ncompetitive performance at moderate thresholds (30 dBZ). Our work advances the\nStormCast model of Pathak et al. [21] by: a) training on the full CONUS domain,\nb) using multiple lead times to improve long-range skill, c) training on\nanalysis data instead of the +1h post-analysis data inadvertently used in\nStormCast, and d) incorporating future GFS states as inputs, enabling\ndownscaling that improves long-lead accuracy. Grid-, neighborhood-, and\nobject-based metrics confirm better storm placement, lower frequency bias, and\nhigher success ratios than HRRR. HRRRCast ensemble forecasts also maintain\nsharper spatial detail, with power spectra more closely matching HRRR analysis.\nWhile GraphHRRR underperforms in its current form, it lays groundwork for\nfuture graph-based forecasting. HRRRCast represents a step toward efficient,\ndata-driven regional weather prediction with competitive accuracy and ensemble\ncapability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05658v1", "cate": "physics.ao-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2310.08467", "title": "Teaching Resources for Embedding Ethics in Mathematics: Exercises, Projects, and Handouts", "authors": ["Maurice Chiodo", "Dennis Müller", "Rehan Shah"], "categories": ["math.HO", "cs.CY", "stat.OT", "97A40, 97D20, 97-00"], "primary_category": "Subjects:       History and Overview (math.HO)", "pdf_link": null, "comments": "Comments:      106 pages, 2 figures. This is the second version, and we intend to make revisions. Comments and feedback are welcome - please get in touch with us", "url": "http://arxiv.org/abs/2310.08467v2", "summary": "The resources compiled in this document provide an approach to embed and\nteach Ethics in Mathematics at the undergraduate level. We provide mathematical\nexercises and homework problems that teach students ethical awareness and\ntransferable skills, for many of the standard courses in the first and second\nyears of a university degree in mathematics or related courses with significant\nmathematical content (e.g., physics, engineering, computer science, economics,\netc). In addition to the exercises, this document also contains a list of\nprojects, essay topics, and handouts for use as final projects and in seminars.\nThis is a living document, and additional contributions are welcome.", "comment": "106 pages, 2 figures. This is the second version, and we intend to\n  make revisions. Comments and feedback are welcome - please get in touch with\n  us", "pdf_url": "http://arxiv.org/pdf/2310.08467v2", "cate": "math.HO", "date": "2023-10-12", "updated": "2025-02-11"}
{"id": "2507.05681", "title": "GATMesh: Clock Mesh Timing Analysis using Graph Neural Networks", "authors": ["Muhammad Hadir Khan", "Matthew Guthaus"], "categories": ["cs.AR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05681v1", "summary": "Clock meshes are essential in high-performance VLSI systems for minimizing\nskew and handling PVT variations, but analyzing them is difficult due to\nreconvergent paths, multi-source driving, and input mesh buffer skew. SPICE\nsimulations are accurate but slow; yet simplified models miss key effects like\nslew and input skew. We propose GATMesh, a Graph Neural Network (GNN)-based\nframework that models the clock mesh as a graph with augmented structural and\nphysical features. Trained on SPICE data, GATMesh achieves high accuracy with\naverage delay error of 5.27ps on unseen benchmarks, while achieving speed-ups\nof 47146x over multi-threaded SPICE simulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05681v1", "cate": "cs.AR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05216", "title": "Bridging Prediction and Intervention Problems in Social Systems", "authors": ["Lydia T. Liu", "Inioluwa Deborah Raji", "Angela Zhou", "Luke Guerdan", "Jessica Hullman", "Daniel Malinsky", "Bryan Wilder", "Simone Zhang", "Hammaad Adam", "Amanda Coston", "Ben Laufer", "Ezinne Nwankwo", "Michael Zanger-Tishler", "Eli Ben-Michael", "Solon Barocas", "Avi Feller", "Marissa Gerchick", "Talia Gillis", "Shion Guha", "Daniel Ho", "Lily Hu", "Kosuke Imai", "Sayash Kapoor", "Joshua Loftus", "Razieh Nabi", "Arvind Narayanan", "Ben Recht", "Juan Carlos Perdomo", "Matthew Salganik", "Mark Sendak", "Alexander Tolbert", "Berk Ustun", "Suresh Venkatasubramanian", "Angelina Wang", "Ashia Wilson"], "categories": ["cs.LG", "cs.CY", "stat.AP", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05216v1", "summary": "Many automated decision systems (ADS) are designed to solve prediction\nproblems -- where the goal is to learn patterns from a sample of the population\nand apply them to individuals from the same population. In reality, these\nprediction systems operationalize holistic policy interventions in deployment.\nOnce deployed, ADS can shape impacted population outcomes through an effective\npolicy change in how decision-makers operate, while also being defined by past\nand present interactions between stakeholders and the limitations of existing\norganizational, as well as societal, infrastructure and context. In this work,\nwe consider the ways in which we must shift from a prediction-focused paradigm\nto an interventionist paradigm when considering the impact of ADS within social\nsystems. We argue this requires a new default problem setup for ADS beyond\nprediction, to instead consider predictions as decision support, final\ndecisions, and outcomes. We highlight how this perspective unifies modern\nstatistical frameworks and other tools to study the design, implementation, and\nevaluation of ADS systems, and point to the research directions necessary to\noperationalize this paradigm shift. Using these tools, we characterize the\nlimitations of focusing on isolated prediction tasks, and lay the foundation\nfor a more intervention-oriented approach to developing and deploying ADS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05216v1", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.05707", "title": "Agentic-R1: Distilled Dual-Strategy Reasoning", "authors": ["Weihua Du", "Pranjal Aggarwal", "Sean Welleck", "Yiming Yang"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint. 15 pages. Project available at this https URL", "url": "http://arxiv.org/abs/2507.05707v1", "summary": "Current long chain-of-thought (long-CoT) models excel at mathematical\nreasoning but rely on slow and error-prone natural language traces.\nTool-augmented agents address arithmetic via code execution, but often falter\non complex logical tasks. We introduce a fine-tuning framework, DualDistill,\nthat distills complementary reasoning strategies from multiple teachers into a\nunified student model. Using this approach, we train Agentic-R1, which\ndynamically selects the optimal strategy for each query, invoking tools for\narithmetic and algorithmic problems, and using text-based reasoning for\nabstract ones. Our method improves accuracy across a range of tasks, including\nboth computation-intensive and standard benchmarks, demonstrating the\neffectiveness of multi-strategy distillation in achieving robust and efficient\nreasoning. Our project is available at https://github.com/StigLidu/DualDistill", "comment": "Preprint. 15 pages. Project available at\n  https://github.com/StigLidu/DualDistill", "pdf_url": "http://arxiv.org/pdf/2507.05707v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06011", "title": "ECORE: Energy-Conscious Optimized Routing for Deep Learning Models at the Edge", "authors": ["Daghash K. Alqahtani", "Maria A. Rodriguez", "Muhammad Aamir Cheema", "Hamid Rezatofighi", "Adel N. Toosi"], "categories": ["cs.DC", "cs.CV"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06011v1", "summary": "Edge computing enables data processing closer to the source, significantly\nreducing latency an essential requirement for real-time vision-based analytics\nsuch as object detection in surveillance and smart city environments. However,\nthese tasks place substantial demands on resource constrained edge devices,\nmaking the joint optimization of energy consumption and detection accuracy\ncritical. To address this challenge, we propose ECORE, a framework that\nintegrates multiple dynamic routing strategies including estimation based\ntechniques and a greedy selection algorithm to direct image processing requests\nto the most suitable edge device-model pair. ECORE dynamically balances energy\nefficiency and detection performance based on object characteristics. We\nevaluate our approach through extensive experiments on real-world datasets,\ncomparing the proposed routers against widely used baseline techniques. The\nevaluation leverages established object detection models (YOLO, SSD,\nEfficientDet) and diverse edge platforms, including Jetson Orin Nano, Raspberry\nPi 4 and 5, and TPU accelerators. Results demonstrate that our proposed\ncontext-aware routing strategies can reduce energy consumption and latency by\n45% and 49%, respectively, while incurring only a 2% loss in detection accuracy\ncompared to accuracy-centric methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06011v1", "cate": "cs.DC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05443", "title": "Gendered Divides in Online Discussions about Reproductive Rights", "authors": ["Ashwin Rao", "Sze Yuh Nina Wang", "Kristina Lerman"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05443v1", "summary": "The U.S. Supreme Court's 2022 ruling in Dobbs v. Jackson Women's Health\nOrganization marked a turning point in the national debate over reproductive\nrights. While the ideological divide over abortion is well documented, less is\nknown about how gender and local sociopolitical contexts interact to shape\npublic discourse. Drawing on nearly 10 million abortion-related posts on X\n(formerly Twitter) from users with inferred gender, ideology and location, we\nshow that gender significantly moderates abortion attitudes and emotional\nexpression, particularly in conservative regions, and independently of\nideology. This creates a gender gap in abortion attitudes that grows more\npronounced in conservative regions. The leak of the Dobbs draft opinion further\nintensified online engagement, disproportionately mobilizing pro-abortion women\nin areas where access was under threat. These findings reveal that abortion\ndiscourse is not only ideologically polarized but also deeply structured by\ngender and place, highlighting the central role of identity in shaping\npolitical expression during moments of institutional disruption.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05443v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06137", "title": "NeoBabel: A Multilingual Open Tower for Visual Generation", "authors": ["Mohammad Mahdi Derakhshani", "Dheeraj Varghese", "Marzieh Fadaee", "Cees G. M. Snoek"], "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      34 pages, 12 figures", "url": "http://arxiv.org/abs/2507.06137v1", "summary": "Text-to-image generation advancements have been predominantly\nEnglish-centric, creating barriers for non-English speakers and perpetuating\ndigital inequities. While existing systems rely on translation pipelines, these\nintroduce semantic drift, computational overhead, and cultural misalignment. We\nintroduce NeoBabel, a novel multilingual image generation framework that sets a\nnew Pareto frontier in performance, efficiency and inclusivity, supporting six\nlanguages: English, Chinese, Dutch, French, Hindi, and Persian. The model is\ntrained using a combination of large-scale multilingual pretraining and\nhigh-resolution instruction tuning. To evaluate its capabilities, we expand two\nEnglish-only benchmarks to multilingual equivalents: m-GenEval and m-DPG.\nNeoBabel achieves state-of-the-art multilingual performance while retaining\nstrong English capability, scoring 0.75 on m-GenEval and 0.68 on m-DPG.\nNotably, it performs on par with leading models on English tasks while\noutperforming them by +0.11 and +0.09 on multilingual benchmarks, even though\nthese models are built on multilingual base LLMs. This demonstrates the\neffectiveness of our targeted alignment training for preserving and extending\ncrosslingual generalization. We further introduce two new metrics to rigorously\nassess multilingual alignment and robustness to code-mixed prompts. Notably,\nNeoBabel matches or exceeds English-only models while being 2-4x smaller. We\nrelease an open toolkit, including all code, model checkpoints, a curated\ndataset of 124M multilingual text-image pairs, and standardized multilingual\nevaluation protocols, to advance inclusive AI research. Our work demonstrates\nthat multilingual capability is not a trade-off but a catalyst for improved\nrobustness, efficiency, and cultural fidelity in generative AI.", "comment": "34 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.06137v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05857", "title": "Property Elicitation on Imprecise Probabilities", "authors": ["James Bailie", "Rabanus Derr"], "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05857v1", "summary": "Property elicitation studies which attributes of a probability distribution\ncan be determined by minimising a risk. We investigate a generalisation of\nproperty elicitation to imprecise probabilities (IP). This investigation is\nmotivated by multi-distribution learning, which takes the classical machine\nlearning paradigm of minimising a single risk over a (precise) probability and\nreplaces it with $\\Gamma$-maximin risk minimization over an IP. We provide\nnecessary conditions for elicitability of a IP-property. Furthermore, we\nexplain what an elicitable IP-property actually elicits through Bayes pairs --\nthe elicited IP-property is the corresponding standard property of the maximum\nBayes risk distribution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05857v1", "cate": "stat.ML", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06167", "title": "Skywork-R1V3 Technical Report", "authors": ["Wei Shen", "Jiangbo Pei", "Yi Peng", "Xuchen Song", "Yang Liu", "Jian Peng", "Haofeng Sun", "Yunzhuo Hao", "Peiyu Wang", "Yahui Zhou"], "categories": ["cs.CL", "cs.CV"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06167v1", "summary": "We introduce Skywork-R1V3, an advanced, open-source vision-language model\n(VLM) that pioneers a new approach to visual reasoning. Its key innovation lies\nin effectively transferring reasoning skills from text-only Large Language\nModels (LLMs) to visual tasks. The strong performance of Skywork-R1V3 primarily\nstems from our elaborate post-training RL framework, which effectively\nactivates and enhances the model's reasoning ability, without the need for\nadditional continue pre-training. Through this framework, we further uncover\nthe fundamental role of the connector module in achieving robust cross-modal\nalignment for multimodal reasoning models. In addition, we introduce a unique\nindicator of reasoning capability, the entropy of critical reasoning tokens,\nwhich has proven highly effective for checkpoint selection during RL training.\nSkywork-R1V3 achieves state-of-the-art results on MMMU, significantly improving\nfrom 64.3% to 76.0%. This performance matches entry-level human capabilities.\nRemarkably, our RL-powered post-training approach enables even the 38B\nparameter model to rival top closed-source VLMs. The implementation\nsuccessfully transfers mathematical reasoning to other subject-related\nreasoning tasks. We also include an analysis of curriculum learning and\nreinforcement finetuning strategies, along with a broader discussion on\nmultimodal reasoning. Skywork-R1V3 represents a significant leap in multimodal\nreasoning, showcasing RL as a powerful engine for advancing open-source VLM\ncapabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06167v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2409.06672", "title": "Insuring Uninsurable Risks from AI: The State as Insurer of Last Resort", "authors": ["Cristian Trout"], "categories": ["cs.CY", "cs.AI", "cs.LG", "q-fin.RM"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted to Generative AI and Law Workshop at the International Conference on Machine Learning (ICML 2024)", "url": "http://arxiv.org/abs/2409.06672v2", "summary": "Many experts believe that AI systems will sooner or later pose uninsurable\nrisks, including existential risks. This creates an extreme judgment-proof\nproblem: few if any parties can be held accountable ex post in the event of\nsuch a catastrophe. This paper proposes a novel solution: a\ngovernment-provided, mandatory indemnification program for AI developers. The\nprogram uses risk-priced indemnity fees to induce socially optimal levels of\ncare. Risk-estimates are determined by surveying experts, including indemnified\ndevelopers. The Bayesian Truth Serum mechanism is employed to incent honest and\neffortful responses. Compared to alternatives, this approach arguably better\nleverages all private information, and provides a clearer signal to indemnified\ndevelopers regarding what risks they must mitigate to lower their fees. It's\nrecommended that collected fees be used to help fund the safety research\ndevelopers need, employing a fund matching mechanism (Quadratic Financing) to\ninduce an optimal supply of this public good. Under Quadratic Financing, safety\nresearch projects would compete for private contributions from developers,\nsignaling how much each is to be supplemented with public funds.", "comment": "Accepted to Generative AI and Law Workshop at the International\n  Conference on Machine Learning (ICML 2024)", "pdf_url": "http://arxiv.org/pdf/2409.06672v2", "cate": "cs.CY", "date": "2024-09-10", "updated": "2025-07-08"}
{"id": "2305.12659", "title": "UVOSAM: A Mask-free Paradigm for Unsupervised Video Object Segmentation via Segment Anything Model", "authors": ["Zhenghao Zhang", "Shengfan Zhang", "Zhichao Wei", "Zuozhuo Dai", "Siyu Zhu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      journal = {Pattern Recognition}", "url": "http://arxiv.org/abs/2305.12659v3", "summary": "The current state-of-the-art methods for unsupervised video object\nsegmentation (UVOS) require extensive training on video datasets with mask\nannotations, limiting their effectiveness in handling challenging scenarios.\nHowever, the Segment Anything Model (SAM) introduces a new prompt-driven\nparadigm for image segmentation, offering new possibilities. In this study, we\ninvestigate SAM's potential for UVOS through different prompt strategies. We\nthen propose UVOSAM, a mask-free paradigm for UVOS that utilizes the STD-Net\ntracker. STD-Net incorporates a spatial-temporal decoupled deformable attention\nmechanism to establish an effective correlation between intra- and inter-frame\nfeatures, remarkably enhancing the quality of box prompts in complex video\nscenes. Extensive experiments on the DAVIS2017-unsupervised and\nYoutubeVIS19\\&21 datasets demonstrate the superior performance of UVOSAM\nwithout mask supervision compared to existing mask-supervised methods, as well\nas its ability to generalize to weakly-annotated video datasets. Code can be\nfound at https://github.com/alibaba/UVOSAM.", "comment": "journal = {Pattern Recognition}", "pdf_url": "http://arxiv.org/pdf/2305.12659v3", "cate": "cs.CV", "date": "2023-05-22", "updated": "2025-07-08"}
{"id": "2409.06673", "title": "Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI", "authors": ["Cristian Trout"], "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted to Generative AI and Law Workshop at the International Conference on Machine Learning (ICML 2024)", "url": "http://arxiv.org/abs/2409.06673v2", "summary": "As AI systems become more autonomous and capable, experts warn of them\npotentially causing catastrophic losses. Drawing on the successful precedent\nset by the nuclear power industry, this paper argues that developers of\nfrontier AI models should be assigned limited, strict, and exclusive third\nparty liability for harms resulting from Critical AI Occurrences (CAIOs) -\nevents that cause or easily could have caused catastrophic losses. Mandatory\ninsurance for CAIO liability is recommended to overcome developers'\njudgment-proofness, mitigate winner's curse dynamics, and leverage insurers'\nquasi-regulatory abilities. Based on theoretical arguments and observations\nfrom the analogous nuclear power context, insurers are expected to engage in a\nmix of causal risk-modeling, monitoring, lobbying for stricter regulation, and\nproviding loss prevention guidance in the context of insuring against\nheavy-tail risks from AI. While not a substitute for regulation, clear\nliability assignment and mandatory insurance can help efficiently allocate\nresources to risk-modeling and safe design, facilitating future regulatory\nefforts.", "comment": "Accepted to Generative AI and Law Workshop at the International\n  Conference on Machine Learning (ICML 2024)", "pdf_url": "http://arxiv.org/pdf/2409.06673v2", "cate": "cs.CY", "date": "2024-09-10", "updated": "2025-07-08"}
{"id": "2503.01369", "title": "Digital Dybbuks and Virtual Golems: The Ethics of Digital Duplicates in Holocaust Testimony", "authors": ["Atay Kozlovski", "Mykola Makhortykh"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      26 pages", "url": "http://arxiv.org/abs/2503.01369v2", "summary": "Advances in generative artificial intelligence (AI) have driven a growing\neffort to create digital duplicates. These semi-autonomous recreations of\nliving and dead people can be used for many purposes. Some of these purposes\ninclude tutoring, coping with grief, and attending business meetings. However,\nthe normative implications of digital duplicates remain obscure, particularly\nconsidering the possibility of them being applied to genocide memory and\neducation. To address this gap, we examine normative possibilities and risks\nassociated with the use of more advanced forms of generative AI-enhanced\nduplicates for transmitting Holocaust survivor testimonies. We first review the\nhistorical and contemporary uses of survivor testimonies. Then, we scrutinize\nthe possible benefits of using digital duplicates in this context and apply the\nMinimally Viable Permissibility Principle (MVPP). The MVPP is an analytical\nframework for evaluating the risks of digital duplicates. It includes five core\ncomponents: the need for authentic presence, consent, positive value,\ntransparency, and harm-risk mitigation. Using MVPP, we identify potential harms\ndigital duplicates might pose to different actors, including survivors, users,\nand developers. We also propose technical and socio-technical mitigation\nstrategies to address these harms.", "comment": "26 pages", "pdf_url": "http://arxiv.org/pdf/2503.01369v2", "cate": "cs.CY", "date": "2025-03-03", "updated": "2025-07-08"}
{"id": "2507.05713", "title": "DRAGON: Dynamic RAG Benchmark On News", "authors": ["Fedor Chernogorskii", "Sergei Averkiev", "Liliya Kudraleeva", "Zaven Martirosian", "Maria Tikhonova", "Valentin Malykh", "Alena Fenogenova"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05713v1", "summary": "Retrieval-Augmented Generation (RAG) is a widely adopted approach for\nimproving the factuality of large language models (LLMs) by incorporating\nexternal knowledge at inference time. Although there exist multiple RAG\nbenchmarks for English, evaluation resources for other languages, including\nRussian, remain scarce and static, failing to capture the dynamic nature of\nreal-world deployments.\n  In this work, we present DRAGON (Dynamic RAG Benchmark On News), the first\ndynamic benchmark for evaluating RAG systems in Russian on a changing news\ncorpora. DRAGON is built upon a regularly updated corpus of Russian news and\npublic documents and supports comprehensive evaluation of both the retriever\nand generator components. Question generation is performed automatically with\nthe use of Knowledge Graph constructed from the corpus and enables the\nextraction of four core question types aligned with distinct subgraph patterns.\nWe release a complete evaluation framework comprising the pipeline for\nautomatic question generation, evaluation scripts, which are potentially\nreusable for other languages and multilingual settings, and benchmark data. We\nalso launch a public leaderboard to encourage community participation and\ncomparison.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05713v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05913", "title": "Best-of-N through the Smoothing Lens: KL Divergence and Regret Analysis", "authors": ["Gholamali Aminian", "Idan Shenfeld", "Amir R. Asadi", "Ahmad Beirami", "Youssef Mroueh"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Workshop on Efficient Systems for Foundation Models at iCML", "url": "http://arxiv.org/abs/2507.05913v1", "summary": "A simple yet effective method for inference-time alignment of generative\nmodels is Best-of-$N$ (BoN), where $N$ outcomes are sampled from a reference\npolicy, evaluated using a proxy reward model, and the highest-scoring one is\nselected. While prior work argues that BoN is almost optimal in reward vs KL\ntradeoffs, the effectiveness of BoN depends critically on the quality of the\nproxy reward model used for selection. For this purpose, we study BoN through a\nsmooth version known as Soft Best-of-N (SBoN) and develop a theoretical\nframework to address this gap. We analyze the scaling behaviour of BoN by\nproviding bounds on the KL divergence between the SBoN policy and the reference\npolicy, offering insights into how performance varies with the number of\nsamples. We also study the regret gap, i.e., the gap between the expected true\nreward under the optimal policy and the SBoN policy. Our theoretical and\nempirical findings show that smoothing helps SBoN mitigate reward\noveroptimization, especially when the quality of the proxy reward is low.", "comment": "Workshop on Efficient Systems for Foundation Models at iCML", "pdf_url": "http://arxiv.org/pdf/2507.05913v1", "cate": "stat.ML", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2312.17670", "title": "Benchmarking the CoW with the TopCoW Challenge: Topology-Aware Anatomical Segmentation of the Circle of Willis for CTA and MRA", "authors": ["Kaiyuan Yang", "Fabio Musio", "Yihui Ma", "Norman Juchler", "Johannes C. Paetzold", "Rami Al-Maskari", "Luciano Höher", "Hongwei Bran Li", "Ibrahim Ethem Hamamci", "Anjany Sekuboyina", "Suprosanna Shit", "Houjing Huang", "Chinmay Prabhakar", "Ezequiel de la Rosa", "Bastian Wittmann", "Diana Waldmannstetter", "Florian Kofler", "Fernando Navarro", "Martin Menten", "Ivan Ezhov", "Daniel Rueckert", "Iris N. Vos", "Ynte M. Ruigrok", "Birgitta K. Velthuis", "Hugo J. Kuijf", "Pengcheng Shi", "Wei Liu", "Ting Ma", "Maximilian R. Rokuss", "Yannick Kirchhoff", "Fabian Isensee", "Klaus Maier-Hein", "Chengcheng Zhu", "Huilin Zhao", "Philippe Bijlenga", "Julien Hämmerli", "Catherine Wurster", "Laura Westphal", "Jeroen Bisschop", "Elisa Colombo", "Hakim Baazaoui", "Hannah-Lea Handelsmann", "Andrew Makmur", "James Hallinan", "Amrish Soundararajan", "Bene Wiestler", "Jan S. Kirschke", "Roland Wiest", "Emmanuel Montagnon", "Laurent Letourneau-Guillon", "Kwanseok Oh", "Dahye Lee", "Adam Hilbert", "Orhun Utku Aydin", "Dimitrios Rallios", "Jana Rieger", "Satoru Tanioka", "Alexander Koch", "Dietmar Frey", "Abdul Qayyum", "Moona Mazher", "Steven Niederer", "Nico Disch", "Julius Holzschuh", "Dominic LaBella", "Francesco Galati", "Daniele Falcetta", "Maria A. Zuluaga", "Chaolong Lin", "Haoran Zhao", "Zehan Zhang", "Minghui Zhang", "Xin You", "Hanxiao Zhang", "Guang-Zhong Yang", "Yun Gu", "Sinyoung Ra", "Jongyun Hwang", "Hyunjin Park", "Junqiang Chen", "Marek Wodzinski", "Henning Müller", "Nesrin Mansouri", "Florent Autrusseau", "Cansu Yalçin", "Rachika E. Hamadache", "Clara Lisazo", "Joaquim Salvi", "Adrià Casamitjana", "Xavier Lladó", "Uma Maria Lal-Trehan Estrada", "Valeriia Abramova", "Luca Giancardo", "Arnau Oliver", "Paula Casademunt", "Adrian Galdran", "Matteo Delucchi", "Jialu Liu", "Haibin Huang", "Yue Cui", "Zehang Lin", "Yusheng Liu", "Shunzhi Zhu", "Tatsat R. Patel", "Adnan H. Siddiqui", "Vincent M. Tutino", "Maysam Orouskhani", "Huayu Wang", "Mahmud Mossa-Basha", "Yuki Sato", "Sven Hirsch", "Susanne Wegener", "Bjoern Menze"], "categories": ["cs.CV", "cs.LG", "q-bio.QM", "q-bio.TO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Summary paper for the TopCoW challenge: 15 pages and 6 figures, supplementary material in appendix; Datasets and best performing algorithm Dockers are available at this https URL and this https URL", "url": "http://arxiv.org/abs/2312.17670v4", "summary": "The Circle of Willis (CoW) is an important network of arteries connecting\nmajor circulations of the brain. Its vascular architecture is believed to\naffect the risk, severity, and clinical outcome of serious neurovascular\ndiseases. However, characterizing the highly variable CoW anatomy is still a\nmanual and time-consuming expert task. The CoW is usually imaged by two\nnon-invasive angiographic imaging modalities, magnetic resonance angiography\n(MRA) and computed tomography angiography (CTA), but there exist limited\ndatasets with annotations on CoW anatomy, especially for CTA. Therefore, we\norganized the TopCoW challenge with the release of an annotated CoW dataset.\nThe TopCoW dataset is the first public dataset with voxel-level annotations for\n13 CoW vessel components, enabled by virtual reality technology. It is also the\nfirst large dataset using 200 pairs of MRA and CTA from the same patients. As\npart of the benchmark, we invited submissions worldwide and attracted over 250\nregistered participants from six continents. The submissions were evaluated on\nboth internal and external test datasets of 226 scans from over five centers.\nThe top performing teams achieved over 90% Dice scores at segmenting the CoW\ncomponents, over 80% F1 scores at detecting key CoW components, and over 70%\nbalanced accuracy at classifying CoW variants for nearly all test sets. The\nbest algorithms also showed clinical potential in classifying fetal-type\nposterior cerebral artery and locating aneurysms with CoW anatomy. TopCoW\ndemonstrated the utility and versatility of CoW segmentation algorithms for a\nwide range of downstream clinical applications with explainability. The\nannotated datasets and best performing algorithms have been released as public\nZenodo records to foster further methodological development and clinical tool\nbuilding.", "comment": "Summary paper for the TopCoW challenge: 15 pages and 6 figures,\n  supplementary material in appendix; Datasets and best performing algorithm\n  Dockers are available at https://zenodo.org/records/15692630 and\n  https://zenodo.org/records/15665435", "pdf_url": "http://arxiv.org/pdf/2312.17670v4", "cate": "cs.CV", "date": "2023-12-29", "updated": "2025-07-08"}
{"id": "2507.05714", "title": "HIRAG: Hierarchical-Thought Instruction-Tuning Retrieval-Augmented Generation", "authors": ["YiHan Jiao", "ZheHao Tan", "Dan Yang", "DuoLin Sun", "Jie Feng", "Jian Wang", "Peng Wei"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05714v1", "summary": "Retrieval-augmented generation (RAG) has become a fundamental paradigm for\naddressing the challenges faced by large language models in handling real-time\ninformation and domain-specific problems. Traditional RAG systems primarily\nrely on the in-context learning (ICL) capabilities of the large language model\nitself. Still, in-depth research on the specific capabilities needed by the RAG\ngeneration model is lacking, leading to challenges with inconsistent document\nquality and retrieval system imperfections. Even the limited studies that\nfine-tune RAG generative models often \\textit{lack a granular focus on RAG\ntask} or \\textit{a deeper utilization of chain-of-thought processes}. To\naddress this, we propose that RAG models should possess three progressively\nhierarchical abilities (1) Filtering: the ability to select relevant\ninformation; (2) Combination: the ability to combine semantic information\nacross paragraphs; and (3) RAG-specific reasoning: the ability to further\nprocess external knowledge using internal knowledge. Thus, we introduce our new\nRAG instruction fine-tuning method, Hierarchical-Thought Instruction-Tuning\nRetrieval-Augmented Generation (HIRAG) incorporates a \"think before answering\"\nstrategy. This method enhances the model's open-book examination capability by\nutilizing multi-level progressive chain-of-thought. Experiments show that the\nHIRAG training strategy significantly improves the model's performance on\ndatasets such as RGB, PopQA, MuSiQue, HotpotQA, and PubmedQA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05714v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05929", "title": "Online Regularized Learning Algorithms in RKHS with $β$- and $φ$-Mixing Sequences", "authors": ["Priyanka Roy", "Susanne Saminger-Platz"], "categories": ["stat.ML", "cs.LG", "math.FA", "60J20, 68T05, 68Q32, 62L20, 62H05"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      arXiv admin note: substantial text overlap with arXiv:2502.03551", "url": "http://arxiv.org/abs/2507.05929v1", "summary": "In this paper, we study an online regularized learning algorithm in a\nreproducing kernel Hilbert spaces (RKHS) based on a class of dependent\nprocesses. We choose such a process where the degree of dependence is measured\nby mixing coefficients. As a representative example, we analyze a strictly\nstationary Markov chain, where the dependence structure is characterized by the\n\\(\\phi\\)- and \\(\\beta\\)-mixing coefficients. Under these assumptions, we derive\nprobabilistic upper bounds as well as convergence rates for both the\nexponential and polynomial decay of the mixing coefficients.", "comment": "arXiv admin note: substantial text overlap with arXiv:2502.03551", "pdf_url": "http://arxiv.org/pdf/2507.05929v1", "cate": "stat.ML", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2503.11947", "title": "Ethical AI for Young Digital Citizens: A Call to Action on Privacy Governance", "authors": ["Austin Shouli", "Ankur Barthwal", "Molly Campbell", "Ajay Kumar Shrestha"], "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Preprint Version | Submitted to journal \"Security and Privacy\", Wiley", "url": "http://arxiv.org/abs/2503.11947v2", "summary": "The rapid expansion of Artificial Intelligence (AI) in digital platforms used\nby youth has created significant challenges related to privacy, autonomy, and\ndata protection. While AI-driven personalization offers enhanced user\nexperiences, it often operates without clear ethical boundaries, leaving young\nusers vulnerable to data exploitation and algorithmic biases. This paper\npresents a call to action for ethical AI governance, advocating for a\nstructured framework that ensures youth-centred privacy protections,\ntransparent data practices, and regulatory oversight. We outline key areas\nrequiring urgent intervention, including algorithmic transparency, privacy\neducation, parental data-sharing ethics, and accountability measures. Through\nthis approach, we seek to empower youth with greater control over their digital\nidentities and propose actionable strategies for policymakers, AI developers,\nand educators to build a fairer and more accountable AI ecosystem.", "comment": "Preprint Version | Submitted to journal \"Security and Privacy\", Wiley", "pdf_url": "http://arxiv.org/pdf/2503.11947v2", "cate": "cs.CY", "date": "2025-03-15", "updated": "2025-07-08"}
{"id": "2405.15660", "title": "Low-Light Video Enhancement via Spatial-Temporal Consistent Decomposition", "authors": ["Xiaogang Xu", "Kun Zhou", "Tao Hu", "Jiafei Wu", "Ruixing Wang", "Hao Peng", "Bei Yu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      IJCAI2025, code link: this https URL", "url": "http://arxiv.org/abs/2405.15660v3", "summary": "Low-Light Video Enhancement (LLVE) seeks to restore dynamic or static scenes\nplagued by severe invisibility and noise. In this paper, we present an\ninnovative video decomposition strategy that incorporates view-independent and\nview-dependent components to enhance the performance of LLVE. We leverage\ndynamic cross-frame correspondences for the view-independent term (which\nprimarily captures intrinsic appearance) and impose a scene-level continuity\nconstraint on the view-dependent term (which mainly describes the shading\ncondition) to achieve consistent and satisfactory decomposition results. To\nfurther ensure consistent decomposition, we introduce a dual-structure\nenhancement network featuring a cross-frame interaction mechanism. By\nsupervising different frames simultaneously, this network encourages them to\nexhibit matching decomposition features. This mechanism can seamlessly\nintegrate with encoder-decoder single-frame networks, incurring minimal\nadditional parameter costs. Extensive experiments are conducted on widely\nrecognized LLVE benchmarks, covering diverse scenarios. Our framework\nconsistently outperforms existing methods, establishing a new SOTA performance.", "comment": "IJCAI2025, code link: https://github.com/xiaogang00/LLVE_STCD", "pdf_url": "http://arxiv.org/pdf/2405.15660v3", "cate": "cs.CV", "date": "2024-05-24", "updated": "2025-07-08"}
{"id": "2506.15991", "title": "The Quantified Body: Identity, Empowerment, and Control in Smart Wearables", "authors": ["Maijunxian Wang"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.15991v3", "summary": "In an era where the body is increasingly translated into streams of biometric\ndata, smart wearables have become not merely tools of personal health tracking\nbut infrastructures of predictive governance. This paper examines how wearable\ntechnologies reconfigure bodily autonomy by embedding users within\nfeedback-driven systems of self-surveillance, data extraction, and algorithmic\ncontrol. Drawing on Deleuze's concept of the control society, Zuboff's theory\nof surveillance capitalism, and Couldry and Mejias's notion of data\ncolonialism, I argue that smart wearables shift the discourse of health\nempowerment toward a modality of compliance aligned with neoliberal values of\nproductivity, efficiency, and self-discipline. Rather than offering transparent\nconsent, these technologies operate within what scholars describe as a\npost-consent regime -- where asymmetrical data relations are normalized through\nseamless design and behavioral nudging. Through interdisciplinary analysis, the\npaper further explores alternative trajectories for wearable design and\ngovernance, from historical examples of care-centered devices to contemporary\nanti-extractive practices and collective data justice frameworks. Ultimately,\nit calls for a paradigm shift from individual optimization to democratic\naccountability and structural reform in the governance of bodily data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.15991v3", "cate": "cs.CY", "date": "2025-06-19", "updated": "2025-07-08"}
{"id": "2507.05972", "title": "Generalized and Unified Equivalences between Hardness and Pseudoentropy", "authors": ["Lunjia Hu", "Salil Vadhan"], "categories": ["cs.CC", "cs.LG"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05972v1", "summary": "Pseudoentropy characterizations provide a quantitatively precise\ndemonstration of the close relationship between computational hardness and\ncomputational randomness. We prove a unified pseudoentropy characterization\nthat generalizes and strengthens previous results for both uniform and\nnon-uniform models of computation. Our characterization holds for a general\nfamily of entropy notions that encompasses the common notions of Shannon\nentropy and min entropy as special cases. Moreover, we show that the\ncharacterizations for different entropy notions can be simultaneously achieved\nby a single, universal function that simultaneously witnesses computational\nhardness and computational randomness. A key technical insight of our work is\nthat the notion of weight-restricted calibration from the recent literature on\nalgorithm fairness, along with standard computational indistinguishability\n(known as multiaccuracy in the fairness literature), suffices for proving\npseudoentropy characterizations for general entropy notions. This demonstrates\nthe power of weight-restricted calibration to enhance the classic\nComplexity-Theoretic Regularity Lemma (Trevisan, Tulsiani, and Vadhan, 2009)\nand Leakage Simulation Lemma (Jetchev and Pietrzak, 2014) and allows us to\nachieve an exponential improvement in the complexity dependency on the alphabet\nsize compared to the pseudoentropy characterizations by Casacuberta, Dwork, and\nVadhan (2024) based on the much stronger notion of multicalibration. We show\nthat the exponential dependency on the alphabet size is inevitable for\nmulticalibration as well as for the weaker notion of calibrated multiaccuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05972v1", "cate": "cs.CC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06069", "title": "RTGPU: Real-Time Computing with Graphics Processing Units", "authors": ["Atiyeh Gheibi-Fetrat", "Amirsaeed Ahmadi-Tonekaboni", "Farzam Koohi-Ronaghi", "Pariya Hajipour", "Sana Babayan-Vanestan", "Fatemeh Fotouhi", "Elahe Mortazavian-Farsani", "Pouria Khajehpour-Dezfouli", "Sepideh Safari", "Shaahin Hessabi", "Hamid Sarbazi-Azad"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      This document provides a concise summary of the book RTGPU, submitted to Synthesis Lectures on Computer Architecture. Due to copyright restrictions, the full content is not reproduced here; readers are referred to the complete book for more comprehensive details", "url": "http://arxiv.org/abs/2507.06069v1", "summary": "In this work, we survey the role of GPUs in real-time systems. Originally\ndesigned for parallel graphics workloads, GPUs are now widely used in\ntime-critical applications such as machine learning, autonomous vehicles, and\nrobotics due to their high computational throughput. Their parallel\narchitecture is well-suited for accelerating complex tasks under strict timing\nconstraints. However, their integration into real-time systems presents several\nchallenges, including non-preemptive execution, execution time variability, and\nresource contention; factors that can lead to unpredictable delays and deadline\nviolations. We examine existing solutions that address these challenges,\nincluding scheduling algorithms, resource management techniques, and\nsynchronization methods, and highlight open research directions to improve GPU\npredictability and performance in real-time environments.", "comment": "This document provides a concise summary of the book RTGPU, submitted\n  to Synthesis Lectures on Computer Architecture. Due to copyright\n  restrictions, the full content is not reproduced here; readers are referred\n  to the complete book for more comprehensive details", "pdf_url": "http://arxiv.org/pdf/2507.06069v1", "cate": "cs.AR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.03020", "title": "AI Literacy and LLM Engagement in Higher Education: A Cross-National Quantitative Study", "authors": ["Shahin Hossain", "Shapla Khanam", "Samaa Haniya", "Nesma Ragab Nasr"], "categories": ["cs.CY", "62J05 (Primary), 62F03, 62P25, 68T07, 97C70", "K.3.1; K.3.2; I.2.7; I.2.6; H.5.2; H.1.2; K.4.2"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      26 pages, 8 figures, 3 tables. Submitted for consideration in a forthcoming issue of the International Journal of Educational Technology in Higher Education", "url": "http://arxiv.org/abs/2507.03020v2", "summary": "This study presents a cross-national quantitative analysis of how university\nstudents in the United States and Bangladesh interact with Large Language\nModels (LLMs). Based on an online survey of 318 students, results show that\nLLMs enhance access to information, improve writing, and boost academic\nperformance. However, concerns about overreliance, ethical risks, and critical\nthinking persist. Guided by the AI Literacy Framework, Expectancy-Value Theory,\nand Biggs' 3P Model, the study finds that motivational beliefs and technical\ncompetencies shape LLM engagement. Significant correlations were found between\nLLM use and perceived literacy benefits (r = .59, p < .001) and optimism (r =\n.41, p < .001). ANOVA results showed more frequent use among U.S. students (F =\n7.92, p = .005) and STEM majors (F = 18.11, p < .001). Findings support the\ndevelopment of ethical, inclusive, and pedagogically sound frameworks for\nintegrating LLMs in higher education.", "comment": "26 pages, 8 figures, 3 tables. Submitted for consideration in a\n  forthcoming issue of the International Journal of Educational Technology in\n  Higher Education", "pdf_url": "http://arxiv.org/pdf/2507.03020v2", "cate": "cs.CY", "date": "2025-07-02", "updated": "2025-07-08"}
{"id": "2507.05980", "title": "RabakBench: Scaling Human Annotations to Construct Localized Multilingual Safety Benchmarks for Low-Resource Languages", "authors": ["Gabriel Chua", "Leanne Tan", "Ziyu Ge", "Roy Ka-Wei Lee"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05980v1", "summary": "Large language models (LLMs) and their safety classifiers often perform\npoorly on low-resource languages due to limited training data and evaluation\nbenchmarks. This paper introduces RabakBench, a new multilingual safety\nbenchmark localized to Singapore's unique linguistic context, covering\nSinglish, Chinese, Malay, and Tamil. RabakBench is constructed through a\nscalable three-stage pipeline: (i) Generate - adversarial example generation by\naugmenting real Singlish web content with LLM-driven red teaming; (ii) Label -\nsemi-automated multi-label safety annotation using majority-voted LLM labelers\naligned with human judgments; and (iii) Translate - high-fidelity translation\npreserving linguistic nuance and toxicity across languages. The final dataset\ncomprises over 5,000 safety-labeled examples across four languages and six\nfine-grained safety categories with severity levels. Evaluations of 11 popular\nopen-source and closed-source guardrail classifiers reveal significant\nperformance degradation. RabakBench not only enables robust safety evaluation\nin Southeast Asian multilingual settings but also offers a reproducible\nframework for building localized safety datasets in low-resource environments.\nThe benchmark dataset, including the human-verified translations, and\nevaluation code are publicly available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05980v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2407.16697", "title": "AbdomenAtlas: A Large-Scale, Detailed-Annotated, & Multi-Center Dataset for Efficient Transfer Learning and Open Algorithmic Benchmarking", "authors": ["Wenxuan Li", "Chongyu Qu", "Xiaoxi Chen", "Pedro R. A. S. Bassi", "Yijia Shi", "Yuxiang Lai", "Qian Yu", "Huimin Xue", "Yixiong Chen", "Xiaorui Lin", "Yutong Tang", "Yining Cao", "Haoqi Han", "Zheyuan Zhang", "Jiawei Liu", "Tiezheng Zhang", "Yujiu Ma", "Jincheng Wang", "Guang Zhang", "Alan Yuille", "Zongwei Zhou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Published in Medical Image Analysis", "url": "http://arxiv.org/abs/2407.16697v2", "summary": "We introduce the largest abdominal CT dataset (termed AbdomenAtlas) of 20,460\nthree-dimensional CT volumes sourced from 112 hospitals across diverse\npopulations, geographies, and facilities. AbdomenAtlas provides 673K\nhigh-quality masks of anatomical structures in the abdominal region annotated\nby a team of 10 radiologists with the help of AI algorithms. We start by having\nexpert radiologists manually annotate 22 anatomical structures in 5,246 CT\nvolumes. Following this, a semi-automatic annotation procedure is performed for\nthe remaining CT volumes, where radiologists revise the annotations predicted\nby AI, and in turn, AI improves its predictions by learning from revised\nannotations. Such a large-scale, detailed-annotated, and multi-center dataset\nis needed for two reasons. Firstly, AbdomenAtlas provides important resources\nfor AI development at scale, branded as large pre-trained models, which can\nalleviate the annotation workload of expert radiologists to transfer to broader\nclinical applications. Secondly, AbdomenAtlas establishes a large-scale\nbenchmark for evaluating AI algorithms -- the more data we use to test the\nalgorithms, the better we can guarantee reliable performance in complex\nclinical scenarios. An ISBI & MICCAI challenge named BodyMaps: Towards 3D Atlas\nof Human Body was launched using a subset of our AbdomenAtlas, aiming to\nstimulate AI innovation and to benchmark segmentation accuracy, inference\nefficiency, and domain generalizability. We hope our AbdomenAtlas can set the\nstage for larger-scale clinical trials and offer exceptional opportunities to\npractitioners in the medical imaging community. Codes, models, and datasets are\navailable at https://www.zongweiz.com/dataset", "comment": "Published in Medical Image Analysis", "pdf_url": "http://arxiv.org/pdf/2407.16697v2", "cate": "cs.CV", "date": "2024-07-23", "updated": "2025-07-08"}
{"id": "2507.06127", "title": "PrefixAgent: An LLM-Powered Design Framework for Efficient Prefix Adder Optimization", "authors": ["Dongsheng Zuo", "Jiadong Zhu", "Yang Luo", "Yuzhe Ma"], "categories": ["cs.AR", "cs.AI"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06127v1", "summary": "Prefix adders are fundamental arithmetic circuits, but their design space\ngrows exponentially with bit-width, posing significant optimization challenges.\nPrevious works face limitations in performance, generalization, and\nscalability. To address these challenges, we propose PrefixAgent, a large\nlanguage model (LLM)-powered framework that enables efficient prefix adder\noptimization. Specifically, PrefixAgent reformulates the problem into subtasks\nincluding backbone synthesis and structure refinement, which effectively\nreduces the search space. More importantly, this new design perspective enables\nus to efficiently collect enormous high-quality data and reasoning traces with\nE-graph, which further results in an effective fine-tuning of LLM. Experimental\nresults show that PrefixAgent synthesizes prefix adders with consistently\nsmaller areas compared to baseline methods, while maintaining scalability and\ngeneralization in commercial EDA flows.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06127v1", "cate": "cs.AR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2408.01701", "title": "Signal-SGN: A Spiking Graph Convolutional Network for Skeletal Action Recognition via Learning Temporal-Frequency Dynamics", "authors": ["Naichuan Zheng", "Yuchen Du", "Hailun Xia", "Zeyu Liang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.01701v4", "summary": "For multimodal skeleton-based action recognition, Graph Convolutional\nNetworks (GCNs) are effective models. Still, their reliance on floating-point\ncomputations leads to high energy consumption, limiting their applicability in\nbattery-powered devices. While energy-efficient, Spiking Neural Networks (SNNs)\nstruggle to model skeleton dynamics, leading to suboptimal solutions. We\npropose Signal-SGN (Spiking Graph Convolutional Network), which utilizes the\ntemporal dimension of skeleton sequences as the spike time steps and represents\nfeatures as multi-dimensional discrete stochastic signals for\ntemporal-frequency domain feature extraction. It combines the 1D Spiking Graph\nConvolution (1D-SGC) module and the Frequency Spiking Convolution (FSC) module\nto extract features from the skeleton represented as spiking form.\nAdditionally, the Multi-Scale Wavelet Transform Feature Fusion (MWTF) module is\nproposed to extract dynamic spiking features and capture frequency-specific\ncharacteristics, enhancing classification performance. Experiments across three\nlarge-scale datasets reveal Signal-SGN exceeding state-of-the-art SNN-based\nmethods in accuracy and computational efficiency while attaining comparable\nperformance with GCN methods and significantly reducing theoretical energy\nconsumption.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.01701v4", "cate": "cs.CV", "date": "2024-08-03", "updated": "2025-07-08"}
{"id": "2408.03559", "title": "Enhanced hermit crabs detection using super-resolution reconstruction and improved YOLOv8 on UAV-captured imagery", "authors": ["Fan Zhao", "Yijia Chen", "Dianhan Xi", "Yongying Liu", "Jiaqi Wang", "Shigeru Tabeta", "Katsunori Mizuno"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      The earlier version of this conference paper was presented at OCEANS 2024-Singapore and was selected for inclusion in the Student Poster Competition (SPC) Program, the final version of this project was published in the academic journal Marine Environmental Research with the Doi: this https URL", "url": "http://arxiv.org/abs/2408.03559v2", "summary": "Hermit crabs play a crucial role in coastal ecosystems by dispersing seeds,\ncleaning up debris, and disturbing soil. They serve as vital indicators of\nmarine environmental health, responding to climate change and pollution.\nTraditional survey methods, like quadrat sampling, are labor-intensive,\ntime-consuming, and environmentally dependent. This study presents an\ninnovative approach combining UAV-based remote sensing with Super-Resolution\nReconstruction (SRR) and the CRAB-YOLO detection network, a modification of\nYOLOv8s, to monitor hermit crabs. SRR enhances image quality by addressing\nissues such as motion blur and insufficient resolution, significantly improving\ndetection accuracy over conventional low-resolution fuzzy images. The CRAB-YOLO\nnetwork integrates three improvements for detection accuracy, hermit crab\ncharacteristics, and computational efficiency, achieving state-of-the-art\n(SOTA) performance compared to other mainstream detection models. The RDN\nnetworks demonstrated the best image reconstruction performance, and CRAB-YOLO\nachieved a mean average precision (mAP) of 69.5% on the SRR test set, a 40%\nimprovement over the conventional Bicubic method with a magnification factor of\n4. These results indicate that the proposed method is effective in detecting\nhermit crabs, offering a cost-effective and automated solution for extensive\nhermit crab monitoring, thereby aiding coastal benthos conservation.", "comment": "The earlier version of this conference paper was presented at OCEANS\n  2024-Singapore and was selected for inclusion in the Student Poster\n  Competition (SPC) Program, the final version of this project was published in\n  the academic journal Marine Environmental Research with the Doi:\n  https://doi.org/10.1016/j.marenvres.2025.107313", "pdf_url": "http://arxiv.org/pdf/2408.03559v2", "cate": "cs.CV", "date": "2024-08-07", "updated": "2025-07-08"}
{"id": "2507.05653", "title": "Archetype-Aware Predictive Autoscaling with Uncertainty Quantification for Serverless Workloads on Kubernetes", "authors": ["Guilin Zhang", "Srinivas Vippagunta", "Raghavendra Nandagopal", "Suchitra Raman", "Jeff Xu", "Marcus Pfeiffer", "Shree Chatterjee", "Ziqi Tan", "Wulan Guo", "Hailong Jiang"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures, 1 table. First three authors contributed equally. Correspondence to Hailong Jiang", "url": "http://arxiv.org/abs/2507.05653v1", "summary": "High-performance extreme computing (HPEC) platforms increasingly adopt\nserverless paradigms, yet face challenges in efficiently managing highly\ndynamic workloads while maintaining service-level objectives (SLOs). We propose\n**AAPA**, an archetype-aware predictive autoscaling system that leverages weak\nsupervision to automatically classify 300\\,000\\,+ workload windows into four\narchetypes (PERIODIC, SPIKE, RAMP, STATIONARY\\_NOISY) with 99.8\\% accuracy.\nEvaluation on publicly available Azure Functions traces shows that AAPA reduces\nSLO violations by up to 50\\%, improves response time by 40\\%, albeit with a\n2--8\\,$\\times$ increase in resource cost under spike-heavy loads.", "comment": "6 pages, 4 figures, 1 table. First three authors contributed equally.\n  Correspondence to Hailong Jiang", "pdf_url": "http://arxiv.org/pdf/2507.05653v1", "cate": "cs.DC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2408.03564", "title": "Riverbed litter monitoring using consumer-grade aerial-aquatic speedy scanner (AASS) and deep learning based super-resolution reconstruction and detection network", "authors": ["Fan Zhao", "Yongying Liu", "Jiaqi Wang", "Yijia Chen", "Dianhan Xi", "Xinlei Shao", "Shigeru Tabeta", "Katsunori Mizuno"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      The earlier version of this conference paper was accepted at OCEANS 2024-Halifax, Canada and was selected for inclusion in the Student Poster Competition (SPC) Program, the final version of this project was published in the academic journal of Marine Pollution Bulletin with the Doi: https://doi.org/10.1016/j.marpolbul.2024.117030", "url": "http://arxiv.org/abs/2408.03564v3", "summary": "Underwater litter is widely spread across aquatic environments such as lakes,\nrivers, and oceans, significantly impacting natural ecosystems. Current\nmonitoring technologies for detecting underwater litter face limitations in\nsurvey efficiency, cost, and environmental conditions, highlighting the need\nfor efficient, consumer-grade technologies for automatic detection. This\nresearch introduces the Aerial-Aquatic Speedy Scanner (AASS) combined with\nSuper-Resolution Reconstruction (SRR) and an improved YOLOv8 detection network.\nAASS enhances data acquisition efficiency over traditional methods, capturing\nhigh-quality images that accurately identify underwater waste. SRR improves\nimage-resolution by mitigating motion blur and insufficient resolution, thereby\nenhancing detection tasks. Specifically, the RCAN model achieved the highest\nmean average precision (mAP) of 78.6% for detection accuracy on reconstructed\nimages among the tested SRR models. With a magnification factor of 4, the SRR\ntest set shows an improved mAP compared to the conventional bicubic set. These\nresults demonstrate the effectiveness of the proposed method in detecting\nunderwater litter.", "comment": "The earlier version of this conference paper was accepted at OCEANS\n  2024-Halifax, Canada and was selected for inclusion in the Student Poster\n  Competition (SPC) Program, the final version of this project was published in\n  the academic journal of Marine Pollution Bulletin with the Doi:\n  10.1016/j.marpolbul.2024.117030", "pdf_url": "http://arxiv.org/pdf/2408.03564v3", "cate": "cs.CV", "date": "2024-08-07", "updated": "2025-07-08"}
{"id": "2507.05704", "title": "Air-FedGA: A Grouping Asynchronous Federated Learning Mechanism Exploiting Over-the-air Computation", "authors": ["Qianpiao Ma", "Junlong Zhou", "Xiangpeng Hou", "Jianchun Liu", "Hongli Xu", "Jianeng Miao", "Qingmin Jia"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by IEEE International Parallel & Distributed Processing Symposium (IPDPS), 2025", "url": "http://arxiv.org/abs/2507.05704v1", "summary": "Federated learning (FL) is a new paradigm to train AI models over distributed\nedge devices (i.e., workers) using their local data, while confronting various\nchallenges including communication resource constraints, edge heterogeneity and\ndata Non-IID. Over-the-air computation (AirComp) is a promising technique to\nachieve efficient utilization of communication resource for model aggregation\nby leveraging the superposition property of a wireless multiple access channel\n(MAC). However, AirComp requires strict synchronization among edge devices,\nwhich is hard to achieve in heterogeneous scenarios. In this paper, we propose\nan AirComp-based grouping asynchronous federated learning mechanism\n(Air-FedGA), which combines the advantages of AirComp and asynchronous FL to\naddress the communication and heterogeneity challenges. Specifically, Air-FedGA\norganizes workers into groups and performs over-the-air aggregation within each\ngroup, while groups asynchronously communicate with the parameter server to\nupdate the global model. In this way, Air-FedGA accelerates the FL model\ntraining by over-the-air aggregation, while relaxing the synchronization\nrequirement of this aggregation technology. We theoretically prove the\nconvergence of Air-FedGA. We formulate a training time minimization problem for\nAir-FedGA and propose the power control and worker grouping algorithm to solve\nit, which jointly optimizes the power scaling factors at edge devices, the\ndenoising factors at the parameter server, as well as the worker grouping\nstrategy. We conduct experiments on classical models and datasets, and the\nresults demonstrate that our proposed mechanism and algorithm can speed up FL\nmodel training by 29.9%-71.6% compared with the state-of-the-art solutions.", "comment": "This paper has been accepted by IEEE International Parallel &\n  Distributed Processing Symposium (IPDPS), 2025", "pdf_url": "http://arxiv.org/pdf/2507.05704v1", "cate": "cs.DC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06031", "title": "Efficient Federated Learning with Timely Update Dissemination", "authors": ["Juncheng Jia", "Ji Liu", "Chao Huo", "Yihui Shen", "Yang Zhou", "Huaiyu Dai", "Dejing Dou"], "categories": ["cs.DC", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      38 pages, to appear in Knowledge and Information Systems (KAIS)", "url": "http://arxiv.org/abs/2507.06031v1", "summary": "Federated Learning (FL) has emerged as a compelling methodology for the\nmanagement of distributed data, marked by significant advancements in recent\nyears. In this paper, we propose an efficient FL approach that capitalizes on\nadditional downlink bandwidth resources to ensure timely update dissemination.\nInitially, we implement this strategy within an asynchronous framework,\nintroducing the Asynchronous Staleness-aware Model Update (FedASMU), which\nintegrates both server-side and device-side methodologies. On the server side,\nwe present an asynchronous FL system model that employs a dynamic model\naggregation technique, which harmonizes local model updates with the global\nmodel to enhance both accuracy and efficiency. Concurrently, on the device\nside, we propose an adaptive model adjustment mechanism that integrates the\nlatest global model with local models during training to further elevate\naccuracy. Subsequently, we extend this approach to a synchronous context,\nreferred to as FedSSMU. Theoretical analyses substantiate the convergence of\nour proposed methodologies. Extensive experiments, encompassing six models and\nfive public datasets, demonstrate that FedASMU and FedSSMU significantly\nsurpass baseline methods in terms of both accuracy (up to 145.87%) and\nefficiency (up to 97.59%).", "comment": "38 pages, to appear in Knowledge and Information Systems (KAIS)", "pdf_url": "http://arxiv.org/pdf/2507.06031v1", "cate": "cs.DC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2409.18932", "title": "ReviveDiff: A Universal Diffusion Model for Restoring Images in Adverse Weather Conditions", "authors": ["Wenfeng Huang", "Guoan Xu", "Wenjing Jia", "Stuart Perry", "Guangwei Gao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.18932v3", "summary": "Images captured in challenging environments--such as nighttime, smoke, rainy\nweather, and underwater--often suffer from significant degradation, resulting\nin a substantial loss of visual quality. The effective restoration of these\ndegraded images is critical for the subsequent vision tasks. While many\nexisting approaches have successfully incorporated specific priors for\nindividual tasks, these tailored solutions limit their applicability to other\ndegradations. In this work, we propose a universal network architecture, dubbed\n``ReviveDiff'', which can address various degradations and bring images back to\nlife by enhancing and restoring their quality. Our approach is inspired by the\nobservation that, unlike degradation caused by movement or electronic issues,\nquality degradation under adverse conditions primarily stems from natural media\n(such as fog, water, and low luminance), which generally preserves the original\nstructures of objects. To restore the quality of such images, we leveraged the\nlatest advancements in diffusion models and developed ReviveDiff to restore\nimage quality from both macro and micro levels across some key factors\ndetermining image quality, such as sharpness, distortion, noise level, dynamic\nrange, and color accuracy. We rigorously evaluated ReviveDiff on seven\nbenchmark datasets covering five types of degrading conditions: Rainy,\nUnderwater, Low-light, Smoke, and Nighttime Hazy. Our experimental results\ndemonstrate that ReviveDiff outperforms the state-of-the-art methods both\nquantitatively and visually.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.18932v3", "cate": "cs.CV", "date": "2024-09-27", "updated": "2025-07-08"}
{"id": "2411.09822", "title": "Advancing Stroke Risk Prediction Using a Multi-modal Foundation Model", "authors": ["Camille Delgrange", "Olga Demler", "Samia Mora", "Bjoern Menze", "Ezequiel de la Rosa", "Neda Davoudi"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted as oral paper at AIM-FM workshop, Neurips 2024", "url": "http://arxiv.org/abs/2411.09822v2", "summary": "Predicting stroke risk is a complex challenge that can be enhanced by\nintegrating diverse clinically available data modalities. This study introduces\na self-supervised multimodal framework that combines 3D brain imaging, clinical\ndata, and image-derived features to improve stroke risk prediction prior to\nonset. By leveraging large unannotated clinical datasets, the framework\ncaptures complementary and synergistic information across image and tabular\ndata modalities. Our approach is based on a contrastive learning framework that\ncouples contrastive language-image pretraining with an image-tabular matching\nmodule, to better align multimodal data representations in a shared latent\nspace. The model is trained on the UK Biobank, which includes structural brain\nMRI and clinical data. We benchmark its performance against state-of-the-art\nunimodal and multimodal methods using tabular, image, and image-tabular\ncombinations under diverse frozen and trainable model settings. The proposed\nmodel outperformed self-supervised tabular (image) methods by 2.6% (2.6%) in\nROC-AUC and by 3.3% (5.6%) in balanced accuracy. Additionally, it showed a 7.6%\nincrease in balanced accuracy compared to the best multimodal supervised model.\nThrough interpretable tools, our approach demonstrated better integration of\ntabular and image data, providing richer and more aligned embeddings.\nGradient-weighted Class Activation Mapping heatmaps further revealed activated\nbrain regions commonly associated in the literature with brain aging, stroke\nrisk, and clinical outcomes. This robust self-supervised multimodal framework\nsurpasses state-of-the-art methods for stroke risk prediction and offers a\nstrong foundation for future studies integrating diverse data modalities to\nadvance clinical predictive modelling.", "comment": "Accepted as oral paper at AIM-FM workshop, Neurips 2024", "pdf_url": "http://arxiv.org/pdf/2411.09822v2", "cate": "cs.CV", "date": "2024-11-14", "updated": "2025-07-08"}
{"id": "2411.13918", "title": "Quantization without Tears", "authors": ["Minghao Fu", "Hao Yu", "Jie Shao", "Junjie Zhou", "Ke Zhu", "Jianxin Wu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      CVPR 2025. The code is publicly available at this https URL", "url": "http://arxiv.org/abs/2411.13918v4", "summary": "Deep neural networks, while achieving remarkable success across diverse\ntasks, demand significant resources, including computation, GPU memory,\nbandwidth, storage, and energy. Network quantization, as a standard compression\nand acceleration technique, reduces storage costs and enables potential\ninference acceleration by discretizing network weights and activations into a\nfinite set of integer values. However, current quantization methods are often\ncomplex and sensitive, requiring extensive task-specific hyperparameters, where\neven a single misconfiguration can impair model performance, limiting\ngenerality across different models and tasks. In this paper, we propose\nQuantization without Tears (QwT), a method that simultaneously achieves\nquantization speed, accuracy, simplicity, and generality. The key insight of\nQwT is to incorporate a lightweight additional structure into the quantized\nnetwork to mitigate information loss during quantization. This structure\nconsists solely of a small set of linear layers, keeping the method simple and\nefficient. More importantly, it provides a closed-form solution, allowing us to\nimprove accuracy effortlessly under 2 minutes. Extensive experiments across\nvarious vision, language, and multimodal tasks demonstrate that QwT is both\nhighly effective and versatile. In fact, our approach offers a robust solution\nfor network quantization that combines simplicity, accuracy, and adaptability,\nwhich provides new insights for the design of novel quantization paradigms. The\ncode is publicly available at https://github.com/wujx2001/QwT", "comment": "CVPR 2025. The code is publicly available at\n  https://github.com/wujx2001/QwT", "pdf_url": "http://arxiv.org/pdf/2411.13918v4", "cate": "cs.CV", "date": "2024-11-21", "updated": "2025-07-08"}
{"id": "2507.06107", "title": "A Unified Ontology for Scalable Knowledge Graph-Driven Operational Data Analytics in High-Performance Computing Systems", "authors": ["Junaid Ahmed Khan", "Andrea Bartolini"], "categories": ["cs.DC", "cs.DB"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      12 pages", "url": "http://arxiv.org/abs/2507.06107v1", "summary": "Modern high-performance computing (HPC) systems generate massive volumes of\nheterogeneous telemetry data from millions of sensors monitoring compute,\nmemory, power, cooling, and storage subsystems. As HPC infrastructures scale to\nsupport increasingly complex workloads-including generative AI-the need for\nefficient, reliable, and interoperable telemetry analysis becomes critical.\nOperational Data Analytics (ODA) has emerged to address these demands; however,\nthe reliance on schema-less storage solutions limits data accessibility and\nsemantic integration. Ontologies and knowledge graphs (KG) provide an effective\nway to enable efficient and expressive data querying by capturing domain\nsemantics, but they face challenges such as significant storage overhead and\nthe limited applicability of existing ontologies, which are often tailored to\nspecific HPC systems only. In this paper, we present the first unified ontology\nfor ODA in HPC systems, designed to enable semantic interoperability across\nheterogeneous data centers. Our ontology models telemetry data from the two\nlargest publicly available ODA datasets-M100 (Cineca, Italy) and F-DATA\n(Fugaku, Japan)-within a single data model. The ontology is validated through\n36 competency questions reflecting real-world stakeholder requirements, and we\nintroduce modeling optimizations that reduce knowledge graph (KG) storage\noverhead by up to 38.84% compared to a previous approach, with an additional\n26.82% reduction depending on the desired deployment configuration. This work\npaves the way for scalable ODA KGs and supports not only analysis within\nindividual systems, but also cross-system analysis across heterogeneous HPC\nsystems.", "comment": "12 pages", "pdf_url": "http://arxiv.org/pdf/2507.06107v1", "cate": "cs.DC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06050", "title": "Minimal Deterministic Echo State Networks Outperform Random Reservoirs in Learning Chaotic Dynamics", "authors": ["Francesco Martinuzzi"], "categories": ["nlin.CD", "cs.LG"], "primary_category": "Subjects:       Chaotic Dynamics (nlin.CD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06050v1", "summary": "Machine learning (ML) is widely used to model chaotic systems. Among ML\napproaches, echo state networks (ESNs) have received considerable attention due\nto their simple construction and fast training. However, ESN performance is\nhighly sensitive to hyperparameter choices and to its random initialization. In\nthis work, we demonstrate that ESNs constructed using deterministic rules and\nsimple topologies (MESNs) outperform standard ESNs in the task of chaotic\nattractor reconstruction. We use a dataset of more than 90 chaotic systems to\nbenchmark 10 different minimal deterministic reservoir initializations. We find\nthat MESNs obtain up to a 41% reduction in error compared to standard ESNs.\nFurthermore, we show that the MESNs are more robust, exhibiting less inter-run\nvariation, and have the ability to reuse hyperparameters across different\nsystems. Our results illustrate how structured simplicity in ESN design can\noutperform stochastic complexity in learning chaotic dynamics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06050v1", "cate": "nlin.CD", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2411.17616", "title": "Towards Stabilized and Efficient Diffusion Transformers through Long-Skip-Connections with Spectral Constraints", "authors": ["Guanjie Chen", "Xinyu Zhao", "Yucheng Zhou", "Xiaoye Qu", "Tianlong Chen", "Yu Cheng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 8 figures", "url": "http://arxiv.org/abs/2411.17616v4", "summary": "Diffusion Transformers (DiT) have emerged as a powerful architecture for\nimage and video generation, offering superior quality and scalability. However,\ntheir practical application suffers from inherent dynamic feature instability,\nleading to error amplification during cached inference. Through systematic\nanalysis, we identify the absence of long-range feature preservation mechanisms\nas the root cause of unstable feature propagation and perturbation sensitivity.\nTo this end, we propose Skip-DiT, an image and video generative DiT variant\nenhanced with Long-Skip-Connections (LSCs) - the key efficiency component in\nU-Nets. Theoretical spectral norm and visualization analysis demonstrate how\nLSCs stabilize feature dynamics. Skip-DiT architecture and its stabilized\ndynamic feature enable an efficient statical caching mechanism that reuses deep\nfeatures across timesteps while updating shallow components. Extensive\nexperiments across the image and video generation tasks demonstrate that\nSkip-DiT achieves: (1) 4.4 times training acceleration and faster convergence,\n(2) 1.5-2 times inference acceleration with negligible quality loss and high\nfidelity to the original output, outperforming existing DiT caching methods\nacross various quantitative metrics. Our findings establish\nLong-Skip-Connections as critical architectural components for stable and\nefficient diffusion transformers. Codes are provided in the\nhttps://github.com/OpenSparseLLMs/Skip-DiT.", "comment": "17 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2411.17616v4", "cate": "cs.CV", "date": "2024-11-26", "updated": "2025-07-08"}
{"id": "2507.06055", "title": "Kernel Trace Distance: Quantum Statistical Metric between Measures through RKHS Density Operators", "authors": ["Arturo Castellanos", "Anna Korba", "Pavlo Mozharovskyi", "Hicham Janati"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06055v1", "summary": "Distances between probability distributions are a key component of many\nstatistical machine learning tasks, from two-sample testing to generative\nmodeling, among others. We introduce a novel distance between measures that\ncompares them through a Schatten norm of their kernel covariance operators. We\nshow that this new distance is an integral probability metric that can be\nframed between a Maximum Mean Discrepancy (MMD) and a Wasserstein distance. In\nparticular, we show that it avoids some pitfalls of MMD, by being more\ndiscriminative and robust to the choice of hyperparameters. Moreover, it\nbenefits from some compelling properties of kernel methods, that can avoid the\ncurse of dimensionality for their sample complexity. We provide an algorithm to\ncompute the distance in practice by introducing an extension of kernel matrix\nfor difference of distributions that could be of independent interest. Those\nadvantages are illustrated by robust approximate Bayesian computation under\ncontamination as well as particle flow simulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06055v1", "cate": "stat.ML", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06005", "title": "Towards Serverless Processing of Spatiotemporal Big Data Queries", "authors": ["Diana Baumann", "Tim C. Rese", "David Bermbach"], "categories": ["cs.DB", "cs.DC"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06005v1", "summary": "Spatiotemporal data are being produced in continuously growing volumes by a\nvariety of data sources and a variety of application fields rely on rapid\nanalysis of such data. Existing systems such as PostGIS or MobilityDB usually\nbuild on relational database systems, thus, inheriting their scale-out\ncharacteristics. As a consequence, big spatiotemporal data scenarios still have\nlimited support even though many query types can easily be parallelized. In\nthis paper, we propose our vision of a native serverless data processing\napproach for spatiotemporal data: We break down queries into small subqueries\nwhich then leverage the near-instant scaling of Function-as-a-Service platforms\nto execute them in parallel. With this, we partially solve the scalability\nneeds of big spatiotemporal data processing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06005v1", "cate": "cs.DB", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2412.01717", "title": "Driving View Synthesis on Free-form Trajectories with Generative Prior", "authors": ["Zeyu Yang", "Zijie Pan", "Yuankun Yang", "Xiatian Zhu", "Li Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2412.01717v3", "summary": "Driving view synthesis along free-form trajectories is essential for\nrealistic driving simulations, enabling closed-loop evaluation of end-to-end\ndriving policies. Existing methods excel at view interpolation along recorded\npaths but struggle to generalize to novel trajectories due to limited\nviewpoints in driving videos. To tackle this challenge, we propose DriveX, a\nnovel free-form driving view synthesis framework, that progressively distills\ngenerative prior into the 3D Gaussian model during its optimization. Within\nthis framework, we utilize a video diffusion model to refine the degraded novel\ntrajectory renderings from the in-training Gaussian model, while the restored\nvideos in turn serve as additional supervision for optimizing the 3D Gaussian.\nConcretely, we craft an inpainting-based video restoration task, which can\ndisentangle the identification of degraded regions from the generative\ncapability of the diffusion model and remove the need of simulating specific\ndegraded pattern in the training of the diffusion model. To further enhance the\nconsistency and fidelity of generated contents, the pseudo ground truth is\nprogressively updated with gradually improved novel trajectory rendering,\nallowing both components to co-adapt and reinforce each other while minimizing\nthe disruption on the optimization. By tightly integrating 3D scene\nrepresentation with generative prior, DriveX achieves high-quality view\nsynthesis beyond recorded trajectories in real time--unlocking new\npossibilities for flexible and realistic driving simulations on free-form\ntrajectories.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2412.01717v3", "cate": "cs.CV", "date": "2024-12-02", "updated": "2025-07-08"}
{"id": "2507.05888", "title": "Hierarchy or Heterarchy? A Theory of Long-Range Connections for the Sensorimotor Brain", "authors": ["Jeff Hawkins", "Niels Leadholm", "Viviane Clay"], "categories": ["q-bio.NC", "cs.AI"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "Comments:      18 pages, 7 figures", "url": "http://arxiv.org/abs/2507.05888v1", "summary": "In the traditional understanding of the neocortex, sensory information flows\nup a hierarchy of regions, with each level processing increasingly complex\nfeatures. Information also flows down the hierarchy via a different set of\nconnections. Although the hierarchical model has significant support, many\nanatomical connections do not conform to the standard hierarchical\ninterpretation. In addition, hierarchically arranged regions sometimes respond\nin parallel, not sequentially as would occur in a hierarchy. This and other\nevidence suggests that two regions can act in parallel and hierarchically at\nthe same time. Given this flexibility, the word \"heterarchy\" might be a more\nsuitable term to describe neocortical organization. This paper proposes a new\ninterpretation of how sensory and motor information is processed in the\nneocortex. The key to our proposal is what we call the \"Thousand Brains\nTheory\", which posits that every cortical column is a sensorimotor learning\nsystem. Columns learn by integrating sensory input over multiple movements of a\nsensor. In this view, even primary and secondary regions, such as V1 and V2,\ncan learn and recognize complete 3D objects. This suggests that the\nhierarchical connections between regions are used to learn the compositional\nstructure of parent objects composed of smaller child objects. We explain the\ntheory by examining the different types of long-range connections between\ncortical regions and between the neocortex and thalamus. We describe these\nconnections, and then suggest the specific roles they play in the context of a\nheterarchy of sensorimotor regions. We also suggest that the thalamus plays an\nessential role in transforming the pose between objects and sensors. The novel\nperspective we argue for here has broad implications for both neuroscience and\nartificial intelligence.", "comment": "18 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.05888v1", "cate": "q-bio.NC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06061", "title": "Estimating prevalence with precision and accuracy", "authors": ["Aime Bienfait Igiraneza", "Christophe Fraser", "Robert Hinch"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06061v1", "summary": "Unlike classification, whose goal is to estimate the class of each data point\nin a dataset, prevalence estimation or quantification is a task that aims to\nestimate the distribution of classes in a dataset. The two main tasks in\nprevalence estimation are to adjust for bias, due to the prevalence in the\ntraining dataset, and to quantify the uncertainty in the estimate. The standard\nmethods used to quantify uncertainty in prevalence estimates are bootstrapping\nand Bayesian quantification methods. It is not clear which approach is ideal in\nterms of precision (i.e. the width of confidence intervals) and coverage (i.e.\nthe confidence intervals being well-calibrated). Here, we propose Precise\nQuantifier (PQ), a Bayesian quantifier that is more precise than existing\nquantifiers and with well-calibrated coverage. We discuss the theory behind PQ\nand present experiments based on simulated and real-world datasets. Through\nthese experiments, we establish the factors which influence quantification\nprecision: the discriminatory power of the underlying classifier; the size of\nthe labeled dataset used to train the quantifier; and the size of the unlabeled\ndataset for which prevalence is estimated. Our analysis provides deep insights\ninto uncertainty quantification for quantification learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06061v1", "cate": "stat.ML", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2412.01787", "title": "Pretrained Reversible Generation as Unsupervised Visual Representation Learning", "authors": ["Rongkun Xue", "Jinouwen Zhang", "Yazhe Niu", "Dazhong Shen", "Bingqi Ma", "Yu Liu", "Jing Yang"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2412.01787v5", "summary": "Recent generative models based on score matching and flow matching have\nsignificantly advanced generation tasks, but their potential in discriminative\ntasks remains underexplored. Previous approaches, such as generative\nclassifiers, have not fully leveraged the capabilities of these models for\ndiscriminative tasks due to their intricate designs. We propose Pretrained\nReversible Generation (PRG), which extracts unsupervised representations by\nreversing the generative process of a pretrained continuous generation model.\nPRG effectively reuses unsupervised generative models, leveraging their high\ncapacity to serve as robust and generalizable feature extractors for downstream\ntasks. This framework enables the flexible selection of feature hierarchies\ntailored to specific downstream tasks. Our method consistently outperforms\nprior approaches across multiple benchmarks, achieving state-of-the-art\nperformance among generative model based methods, including 78% top-1 accuracy\non ImageNet at a resolution of 64*64. Extensive ablation studies, including\nout-of-distribution evaluations, further validate the effectiveness of our\napproach.PRG is available at https://github.com/opendilab/PRG.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2412.01787v5", "cate": "cs.CV", "date": "2024-11-29", "updated": "2025-07-08"}
{"id": "2306.03622", "title": "Torpor: GPU-Enabled Serverless Computing for Low-Latency, Resource-Efficient Inference", "authors": ["Minchen Yu", "Ao Wang", "Dong Chen", "Haoxuan Yu", "Xiaonan Luo", "Zhuohao Li", "Wei Wang", "Ruichuan Chen", "Dapeng Nie", "Haoran Yang", "Yu Ding"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2306.03622v3", "summary": "Serverless computing offers a compelling cloud model for online inference\nservices. However, existing serverless platforms lack efficient support for\nGPUs, hindering their ability to deliver high-performance inference. In this\npaper, we present Torpor, a serverless platform for GPU-efficient, low-latency\ninference. To enable efficient sharing of a node's GPUs among numerous\ninference functions, Torpor maintains models in main memory and dynamically\nswaps them onto GPUs upon request arrivals (i.e., late binding with model\nswapping). Torpor uses various techniques, including asynchronous API\nredirection, GPU runtime sharing, pipelined model execution, and efficient GPU\nmemory management, to minimize latency overhead caused by model swapping.\nAdditionally, we design an interference-aware request scheduling algorithm that\nutilizes high-speed GPU interconnects to meet latency service-level objectives\n(SLOs) for individual inference functions. We have implemented Torpor and\nevaluated its performance in a production environment. Utilizing late binding\nand model swapping, Torpor can concurrently serve hundreds of inference\nfunctions on a worker node with 4 GPUs, while achieving latency performance\ncomparable to native execution, where each model is cached exclusively on a\nGPU. Pilot deployment in a leading commercial serverless cloud shows that\nTorpor reduces the GPU provisioning cost by 70% and 65% for users and the\nplatform, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2306.03622v3", "cate": "cs.DC", "date": "2023-06-06", "updated": "2025-07-08"}
{"id": "2507.05890", "title": "Psychometric Item Validation Using Virtual Respondents with Trait-Response Mediators", "authors": ["Sungjib Lim", "Woojung Song", "Eun-Ju Lee", "Yohan Jo"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      17 pages, 7 figures", "url": "http://arxiv.org/abs/2507.05890v1", "summary": "As psychometric surveys are increasingly used to assess the traits of large\nlanguage models (LLMs), the need for scalable survey item generation suited for\nLLMs has also grown. A critical challenge here is ensuring the construct\nvalidity of generated items, i.e., whether they truly measure the intended\ntrait. Traditionally, this requires costly, large-scale human data collection.\nTo make it efficient, we present a framework for virtual respondent simulation\nusing LLMs. Our central idea is to account for mediators: factors through which\nthe same trait can give rise to varying responses to a survey item. By\nsimulating respondents with diverse mediators, we identify survey items that\nrobustly measure intended traits. Experiments on three psychological trait\ntheories (Big5, Schwartz, VIA) show that our mediator generation methods and\nsimulation framework effectively identify high-validity items. LLMs demonstrate\nthe ability to generate plausible mediators from trait definitions and to\nsimulate respondent behavior for item validation. Our problem formulation,\nmetrics, methodology, and dataset open a new direction for cost-effective\nsurvey development and a deeper understanding of how LLMs replicate human-like\nbehavior. We will publicly release our dataset and code to support future work.", "comment": "17 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.05890v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2412.01827", "title": "RandAR: Decoder-only Autoregressive Visual Generation in Random Orders", "authors": ["Ziqi Pang", "Tianyuan Zhang", "Fujun Luan", "Yunze Man", "Hao Tan", "Kai Zhang", "William T. Freeman", "Yu-Xiong Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2412.01827v2", "summary": "We introduce RandAR, a decoder-only visual autoregressive (AR) model capable\nof generating images in arbitrary token orders. Unlike previous decoder-only AR\nmodels that rely on a predefined generation order, RandAR removes this\ninductive bias, unlocking new capabilities in decoder-only generation. Our\nessential design enables random order by inserting a \"position instruction\ntoken\" before each image token to be predicted, representing the spatial\nlocation of the next image token. Trained on randomly permuted token sequences\n-- a more challenging task than fixed-order generation, RandAR achieves\ncomparable performance to its conventional raster-order counterpart. More\nimportantly, decoder-only transformers trained from random orders acquire new\ncapabilities. For the efficiency bottleneck of AR models, RandAR adopts\nparallel decoding with KV-Cache at inference time, enjoying 2.5x acceleration\nwithout sacrificing generation quality. Additionally, RandAR supports\ninpainting, outpainting and resolution extrapolation in a zero-shot manner. We\nhope RandAR inspires new directions for decoder-only visual generation models\nand broadens their applications across diverse scenarios. Our project page is\nat https://rand-ar.github.io/.", "comment": "Project page: https://rand-ar.github.io/", "pdf_url": "http://arxiv.org/pdf/2412.01827v2", "cate": "cs.CV", "date": "2024-12-02", "updated": "2025-07-08"}
{"id": "2403.12980", "title": "Containerization in Multi-Cloud Environment: Roles, Strategies, Challenges, and Solutions for Effective Implementation", "authors": ["Muhammad Waseem", "Aakash Ahmad", "Peng Liang", "Muhammad Azeem Akbar", "Arif Ali Khan", "Iftikhar Ahmad", "Manu Setälä", "Tommi Mikkonen"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Preprint accepted for publication in Journal of Systems and Software, 2025", "url": "http://arxiv.org/abs/2403.12980v3", "summary": "Containerization in multi-cloud environments has received significant\nattention in recent years both from academic research and industrial\ndevelopment perspectives. However, there exists no effort to systematically\ninvestigate the state of research on this topic. The aim of this research is to\nsystematically identify and categorize the multiple aspects of containerization\nin multi-cloud environment. We conducted the Systematic Mapping Study (SMS) on\nthe literature published between January 2013 and July 2024. One hundred twenty\none studies were selected and the key results are: (1) Four leading themes on\ncontainerization in multi-cloud environment are identified: 'Scalability and\nHigh Availability', 'Performance and Optimization', 'Security and Privacy', and\n'Multi-Cloud Container Monitoring and Adaptation'. (2) Ninety-eight patterns\nand strategies for containerization in multicloud environment were classified\nacross 10 subcategories and 4 categories. (3) Ten quality attributes considered\nwere identified with 47 associated tactics. (4) Four catalogs consisting of\nchallenges and solutions related to security, automation, deployment, and\nmonitoring were introduced. The results of this SMS will assist researchers and\npractitioners in pursuing further studies on containerization in multi-cloud\nenvironment and developing specialized solutions for containerization\napplications in multi-cloud environment.", "comment": "Preprint accepted for publication in Journal of Systems and Software,\n  2025", "pdf_url": "http://arxiv.org/pdf/2403.12980v3", "cate": "cs.DC", "date": "2024-03-01", "updated": "2025-07-08"}
{"id": "2412.02287", "title": "Viewpoint Consistency in 3D Generation via Attention and CLIP Guidance", "authors": ["Qing Zhang", "Zehao Chen", "Jinguang Tong", "Jing Zhang", "Jie Hong", "Xuesong Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.02287v2", "summary": "Despite recent advances in text-to-3D generation techniques, current methods\noften suffer from geometric inconsistencies, commonly referred to as the Janus\nProblem. This paper identifies the root cause of the Janus Problem: viewpoint\ngeneration bias in diffusion models, which creates a significant gap between\nthe actual generated viewpoint and the expected one required for optimizing the\n3D model. To address this issue, we propose a tuning-free approach called the\nAttention and CLIP Guidance (ACG) mechanism. ACG enhances desired viewpoints by\nadaptively controlling cross-attention maps, employs CLIP-based view-text\nsimilarities to filter out erroneous viewpoints, and uses a coarse-to-fine\noptimization strategy with staged prompts to progressively refine 3D\ngeneration. Extensive experiments demonstrate that our method significantly\nreduces the Janus Problem without compromising generation speed, establishing\nACG as an efficient, plug-and-play component for existing text-to-3D\nframeworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.02287v2", "cate": "cs.CV", "date": "2024-12-03", "updated": "2025-07-08"}
{"id": "2412.13875", "title": "Enhancing Visual Re-ranking through Denoising Nearest Neighbor Graph via Continuous CRF", "authors": ["Jaeyoon Kim", "Yoonki Cho", "Taeyoung Kim", "Sung-Eui Yoon"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICIP 2025", "url": "http://arxiv.org/abs/2412.13875v2", "summary": "Nearest neighbor (NN) graph based visual re-ranking has emerged as a powerful\napproach for improving retrieval accuracy, offering the advantages of\neffectively exploring high-dimensional manifolds without requiring additional\nfine-tuning. However, the effectiveness of NN graph-based re-ranking is\nfundamentally constrained by the quality of its edge connectivity, as incorrect\nconnections between dissimilar (negative) images frequently occur. This is\nknown as a noisy edge problem, which hinders the re-ranking performance of\nexisting techniques and limits their potential. To remedy this issue, we\npropose a complementary denoising method based on Continuous Conditional Random\nFields (C-CRF) that leverages statistical distances derived from\nsimilarity-based distributions. As a pre-processing step for enhancing NN\ngraph-based retrieval, our approach constructs fully connected cliques around\neach anchor image and employs a novel statistical distance metric to robustly\nalleviate noisy edges before re-ranking while achieving efficient processing\nthrough offline computation. Extensive experimental results demonstrate that\nour method consistently improves three different NN graph-based re-ranking\napproaches, yielding significant gains in retrieval accuracy.", "comment": "ICIP 2025", "pdf_url": "http://arxiv.org/pdf/2412.13875v2", "cate": "cs.CV", "date": "2024-12-18", "updated": "2025-07-08"}
{"id": "2507.03486", "title": "A Distributed Consensus Algorithm for Prioritizing Autonomous Vehicle Passing at Unsignalized Intersections under Mixed Traffic", "authors": ["Younjeong Lee", "Young Yoon"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      10 pages, 6 figures", "url": "http://arxiv.org/abs/2507.03486v2", "summary": "We propose a methodology for connected autonomous vehicles (CAVs) to\ndetermine their passing priority at unsignalized intersections where they\ncoexist with human-driven vehicles (HVs). Assuming that CAVs can perceive the\nentry order of surrounding vehicles using computer vision technology and are\ncapable of avoiding collisions, we introduce a voting-based distributed\nconsensus algorithm inspired by Raft to resolve tie-breaking among\nsimultaneously arriving CAVs. The algorithm is structured around the candidate\nand leader election processes and incorporates a minimal consensus quorum to\nensure both safety and liveness among CAVs under typical asynchronous\ncommunication conditions. Assuming CAVs to be SAE (Society of Automotive\nEngineers) Level-4 or higher autonomous vehicles, we implemented the proposed\ndistributed consensus algorithm using gRPC. By adjusting variables such as the\nCAV-to-HV ratio, intersection scale, and the processing time of computer vision\nmodules, we demonstrated that stable consensus can be achieved even under\nmixed-traffic conditions involving HVs without adequate functionalities to\ninteract with CAVs. Experimental results show that the proposed algorithm\nreached consensus at a typical unsignalized four-way, two-lane intersection in\napproximately 30-40 ms on average. A secondary vision-based system is employed\nto complete the crossing priorities based on the recognized lexicographical\norder of the license plate numbers in case the consensus procedure times out on\nan unreliable vehicle-to-vehicle communication network. The significance of\nthis study lies in its ability to improve traffic flow at unsignalized\nintersections by enabling rapid determination of passing priority through\ndistributed consensus even under mixed traffic with faulty vehicles.", "comment": "10 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.03486v2", "cate": "cs.DC", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2501.01366", "title": "ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding", "authors": ["Austin T. Wang", "ZeMing Gong", "Angel X. Chang"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      24 pages with 8 figures and 14 tables; updated for ACL 2025 camera-ready with additional discussion and figures", "url": "http://arxiv.org/abs/2501.01366v2", "summary": "3D visual grounding (3DVG) involves localizing entities in a 3D scene\nreferred to by natural language text. Such models are useful for embodied AI\nand scene retrieval applications, which involve searching for objects or\npatterns using natural language descriptions. While recent works have focused\non LLM-based scaling of 3DVG datasets, these datasets do not capture the full\nrange of potential prompts which could be specified in the English language. To\nensure that we are scaling up and testing against a useful and representative\nset of prompts, we propose a framework for linguistically analyzing 3DVG\nprompts and introduce Visual Grounding with Diverse Language in 3D (ViGiL3D), a\ndiagnostic dataset for evaluating visual grounding methods against a diverse\nset of language patterns. We evaluate existing open-vocabulary 3DVG methods to\ndemonstrate that these methods are not yet proficient in understanding and\nidentifying the targets of more challenging, out-of-distribution prompts,\ntoward real-world applications.", "comment": "24 pages with 8 figures and 14 tables; updated for ACL 2025\n  camera-ready with additional discussion and figures", "pdf_url": "http://arxiv.org/pdf/2501.01366v2", "cate": "cs.CV", "date": "2025-01-02", "updated": "2025-07-07"}
{"id": "2507.03695", "title": "On Optimizing Resource Utilization in Distributed Connected Components", "authors": ["Mohsen Koohi Esfahani"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03695v2", "summary": "Connected Components (CC) is a core graph problem with numerous applications.\nThis paper investigates accelerating distributed CC by optimizing memory and\nnetwork bandwidth utilization. We present two novel distributed CC algorithms,\nSiskinCC and RobinCC, which are built upon the Jayanti-Tarjan disjoint set\nunion algorithm. To optimize memory utilization, SiskinCC and RobinCC are\ndesigned to facilitate efficient access to a shared array for all cores running\nin a machine. This allows execution of faster algorithms with larger memory\nbounds. SiskinCC leverages the continuous inter-machine communication during\nthe computation phase to reduce the final communication overhead and RobinCC\nleverages the structural properties of real-world graphs to optimize network\nbandwidth utilization. Our evaluation against state-of-the-art CC algorithms,\nusing real-world and synthetic graphs with up to 500 billion edges and 11.7\nbillion vertices, and on up to 2048 CPU cores, demonstrates that SiskinCC and\nRobinCC achieve up to 58.5 times speedup.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03695v2", "cate": "cs.DC", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2507.06192", "title": "SQLBarber: A System Leveraging Large Language Models to Generate Customized and Realistic SQL Workloads", "authors": ["Jiale Lao", "Immanuel Trummer"], "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06192v1", "summary": "Database research and development often require a large number of SQL queries\nfor benchmarking purposes. However, acquiring real-world SQL queries is\nchallenging due to privacy concerns, and existing SQL generation methods are\nlimited in customization and in satisfying realistic constraints. To address\nthis issue, we present SQLBarber, a system based on Large Language Models\n(LLMs) to generate customized and realistic SQL workloads. SQLBarber (i)\neliminates the need for users to manually craft SQL templates in advance, while\nproviding the flexibility to accept natural language specifications to\nconstrain SQL templates, (ii) scales efficiently to generate large volumes of\nqueries matching any user-defined cost distribution (e.g., cardinality and\nexecution plan cost), and (iii) uses execution statistics from Amazon Redshift\nand Snowflake to derive SQL template specifications and query cost\ndistributions that reflect real-world query characteristics. SQLBarber\nintroduces (i) a declarative interface for users to effortlessly generate\ncustomized SQL templates, (ii) an LLM-powered pipeline augmented with a\nself-correction module that profiles, refines, and prunes SQL templates based\non query costs, and (iii) a Bayesian Optimizer to efficiently explore different\npredicate values and identify a set of queries that satisfy the target cost\ndistribution. We construct and open-source ten benchmarks of varying difficulty\nlevels and target query cost distributions based on real-world statistics from\nSnowflake and Amazon Redshift. Extensive experiments on these benchmarks show\nthat SQLBarber is the only system that can generate customized SQL templates.\nIt reduces query generation time by one to three orders of magnitude, and\nsignificantly improves alignment with the target cost distribution, compared\nwith existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06192v1", "cate": "cs.DB", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2501.06035", "title": "Nonisotropic Gaussian Diffusion for Realistic 3D Human Motion Prediction", "authors": ["Cecilia Curreli", "Dominik Muhle", "Abhishek Saroha", "Zhenzhang Ye", "Riccardo Marin", "Daniel Cremers"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      CVPR 2025. Code availabe at this https URL", "url": "http://arxiv.org/abs/2501.06035v3", "summary": "Probabilistic human motion prediction aims to forecast multiple possible\nfuture movements from past observations. While current approaches report high\ndiversity and realism, they often generate motions with undetected limb\nstretching and jitter. To address this, we introduce SkeletonDiffusion, a\nlatent diffusion model that embeds an explicit inductive bias on the human body\nwithin its architecture and training. Our model is trained with a novel\nnonisotropic Gaussian diffusion formulation that aligns with the natural\nkinematic structure of the human skeleton. Results show that our approach\noutperforms conventional isotropic alternatives, consistently generating\nrealistic predictions while avoiding artifacts such as limb distortion.\nAdditionally, we identify a limitation in commonly used diversity metrics,\nwhich may inadvertently favor models that produce inconsistent limb lengths\nwithin the same sequence. SkeletonDiffusion sets a new benchmark on real-world\ndatasets, outperforming various baselines across multiple evaluation metrics.\nVisit our project page at\nhttps://ceveloper.github.io/publications/skeletondiffusion/ .", "comment": "CVPR 2025. Code availabe at\n  https://ceveloper.github.io/publications/skeletondiffusion", "pdf_url": "http://arxiv.org/pdf/2501.06035v3", "cate": "cs.CV", "date": "2025-01-10", "updated": "2025-07-08"}
{"id": "2507.04420", "title": "Skipper: Maximal Matching with a Single Pass over Edges", "authors": ["Mohsen Koohi Esfahani"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04420v2", "summary": "Maximal Matching (MM) is a fundamental graph problem with diverse\napplications. However, state-of-the-art parallel MM algorithms are limited by\ntheir need to process graph edges repeatedly over multiple iterations.\nFurthermore, optimized algorithms often require additional memory for graph\ncontraction or edge filtering. In this paper, we introduce Skipper, an\nincremental asynchronous MM algorithm that (i) processes each edge\ndeterministically and only once, (ii) skips a large fraction of edges during\nprocessing, and (iii) minimizes memory space utilization. Notably, Skipper\nrequires (a) a single pass over the edges, and (b) only a single byte of memory\nspace per vertex. Our evaluation of Skipper, using both real-world and\nsynthetic graphs with up to 161 billion edges, and across three different\ncomputer architectures, shows that Skipper processes only 1.2% of the edges and\ndelivers a 47.1 times average speedup (geometric mean). Moreover, Skipper's\noutput quality is highly competitive, with an average size of 88.6% relative to\nthe output of the Lim-Chung algorithm as a state-of-the-art MM algorithm with\nthe largest output size.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04420v2", "cate": "cs.DC", "date": "2025-07-06", "updated": "2025-07-08"}
{"id": "2507.05951", "title": "Complexity Results of Persuasion", "authors": ["Alban Grastien"], "categories": ["cs.CC", "cs.AI"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05951v1", "summary": "We prove that persuasion is an NP-complete problem.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05951v1", "cate": "cs.CC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06196", "title": "UQLM: A Python Package for Uncertainty Quantification in Large Language Models", "authors": ["Dylan Bouchard", "Mohit Singh Chauhan", "David Skarbrevik", "Ho-Kyeong Ra", "Viren Bajaj", "Zeya Ahmad"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Submitted to Journal of Machine Learning Research (MLOSS); UQLM Repository: this https URL", "url": "http://arxiv.org/abs/2507.06196v1", "summary": "Hallucinations, defined as instances where Large Language Models (LLMs)\ngenerate false or misleading content, pose a significant challenge that impacts\nthe safety and trust of downstream applications. We introduce UQLM, a Python\npackage for LLM hallucination detection using state-of-the-art uncertainty\nquantification (UQ) techniques. This toolkit offers a suite of UQ-based scorers\nthat compute response-level confidence scores ranging from 0 to 1. This library\nprovides an off-the-shelf solution for UQ-based hallucination detection that\ncan be easily integrated to enhance the reliability of LLM outputs.", "comment": "Submitted to Journal of Machine Learning Research (MLOSS); UQLM\n  Repository: https://github.com/cvs-health/uqlm", "pdf_url": "http://arxiv.org/pdf/2507.06196v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2502.12632", "title": "MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation", "authors": ["Sihyun Yu", "Meera Hahn", "Dan Kondratyuk", "Jinwoo Shin", "Agrim Gupta", "José Lezama", "Irfan Essa", "David Ross", "Jonathan Huang"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      CVPR 2025 Workshop on AI for Content Creation (Oral)", "url": "http://arxiv.org/abs/2502.12632v3", "summary": "Diffusion models are successful for synthesizing high-quality videos but are\nlimited to generating short clips (e.g., 2-10 seconds). Synthesizing sustained\nfootage (e.g. over minutes) still remains an open research question. In this\npaper, we propose MALT Diffusion (using Memory-Augmented Latent Transformers),\na new diffusion model specialized for long video generation. MALT Diffusion (or\njust MALT) handles long videos by subdividing them into short segments and\ndoing segment-level autoregressive generation. To achieve this, we first\npropose recurrent attention layers that encode multiple segments into a compact\nmemory latent vector; by maintaining this memory vector over time, MALT is able\nto condition on it and continuously generate new footage based on a long\ntemporal context. We also present several training techniques that enable the\nmodel to generate frames over a long horizon with consistent quality and\nminimal degradation. We validate the effectiveness of MALT through experiments\non long video benchmarks. We first perform extensive analysis of MALT in\nlong-contextual understanding capability and stability using popular long video\nbenchmarks. For example, MALT achieves an FVD score of 220.4 on 128-frame video\ngeneration on UCF-101, outperforming the previous state-of-the-art of 648.4.\nFinally, we explore MALT's capabilities in a text-to-video generation setting\nand show that it can produce long videos compared with recent techniques for\nlong text-to-video generation.", "comment": "CVPR 2025 Workshop on AI for Content Creation (Oral)", "pdf_url": "http://arxiv.org/pdf/2502.12632v3", "cate": "cs.CV", "date": "2025-02-18", "updated": "2025-07-08"}
{"id": "2404.19725", "title": "Curvature-Aligned Federated Learning (CAFe): Harmonizing Loss Landscapes for Fairness Without Demographics", "authors": ["Shaily Roy", "Harshit Sharma", "Asif Salekin"], "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.19725v5", "summary": "Federated Learning (FL) enables privacy-preserving collaborative training,\nmaking it well-suited for decentralized human-sensing applications. Ensuring\nfairness in FL is challenging, as current methods rely on sensitive attribute\nknowledge, which conflicts with FL's privacy principles. Additionally,\nsensitive attributes in human-sensing data may be unknown or latent. To address\nthis, we introduce Curvature-Aligned Federated Learning (CAFe), a theoretically\ngrounded approach that achieves fairness in FL without requiring sensitive\nattribute knowledge, a concept termed \"Fairness without Demographics\" (FWD).\nCAFe introduces loss-landscape curvature regularization during local training\nand clients' loss-landscape sharpness-aware aggregation to align curvature both\nwithin and across clients, enabling a strong balance between higher fairness\nand performance. CAFe is especially suitable for real-world human-sensing FL\nscenarios involving single or multi-user edge devices with unknown or multiple\nbias factors. We validated CAFe through theoretical and empirical\njustifications, and comprehensive evaluations using three real-world datasets\nand a live real-world FL deployment with a heterogeneous testbed of\nresource-constrained devices. Additionally, we conduct sensitivity analyses on\nlocal training data volume, client sampling, communication overhead, resource\ncosts, and runtime performance to demonstrate its feasibility for practical FL\nedge device deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.19725v5", "cate": "cs.LG", "date": "2024-04-30", "updated": "2025-07-08"}
{"id": "2507.05965", "title": "OpenFActScore: Open-Source Atomic Evaluation of Factuality in Text Generation", "authors": ["Lucas Fonseca Lage", "Simon Ostermann"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Submitted to EMNLP 2025 System Demonstrations track", "url": "http://arxiv.org/abs/2507.05965v1", "summary": "We introduce OpenFActScore, an open-source implementation of the FActScore\nframework for evaluating the factuality of text generated by large language\nmodels (LLMs). FActScore evaluates the factual accuracy of long-form text by\nusing Atomic Fact Generation (AFG) to extract individual factual claims and\nAtomic Fact Validation (AFV) to verify each claim against a trusted knowledge\nsource. While the original FActScore relies on closed-source and commercial\nmodels such as InstructGPT and ChatGPT, OpenFActScore enables the use of any\nHugging Face-compatible model for both AFG and AFV. We provide a detailed\ntechnical overview of our implementation, highlighting design choices and\nmodifications made to support open models. We evaluate multiple open-source\nLLMs on both AFG and AFV using the original FActScore benchmark, reporting\nBERTScore-F1 for AFG and Error Rate relative to human annotations for AFV. Our\nresults show that open models can approximate the performance of closed-source\nsystems, with Gemma achieving the best overall performance, and our final setup\nobtains a 0.99 Pearson correlation with the original FActScore experiments.\nOpenFActScore promotes transparency, reproducibility, and cost-effective\nevaluation, and is available at: https://github.com/lflage/OpenFActScore.", "comment": "Submitted to EMNLP 2025 System Demonstrations track", "pdf_url": "http://arxiv.org/pdf/2507.05965v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06217", "title": "What ZTF Saw Where Rubin Looked: Anomaly Hunting in DR23", "authors": ["Maria V. Pruzhinskaya", "Anastasia D. Lavrukhina", "Timofey A. Semenikhi", "Alina A. Volnova", "Sreevarsha Sreejith", "Vadim V. Krushinsky", "Emmanuel Gangler", "Emille E. O. Ishida", "Matwey V. Kornilov", "Konstantin L. Malanchev"], "categories": ["astro-ph.IM", "astro-ph.GA", "astro-ph.SR", "cs.LG"], "primary_category": "Subjects:       Instrumentation and Methods for Astrophysics (astro-ph.IM)", "pdf_link": null, "comments": "Comments:      11 pages, 4 figures", "url": "http://arxiv.org/abs/2507.06217v1", "summary": "We present results from the SNAD VIII Workshop, during which we conducted the\nfirst systematic anomaly search in the ZTF fields also observed by LSSTComCam\nduring Rubin Scientific Pipeline commissioning. Using the PineForest active\nanomaly detection algorithm, we analysed four selected fields (two galactic and\ntwo extragalactic) and visually inspected 400 candidates. As a result, we\ndiscovered six previously uncatalogued variable stars, including RS~CVn, BY\nDraconis, ellipsoidal, and solar-type variables, and refined classifications\nand periods for six known objects. These results demonstrate the effectiveness\nof the SNAD anomaly detection pipeline and provide a preview of the discovery\npotential in the upcoming LSST data.", "comment": "11 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.06217v1", "cate": "astro-ph.IM", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2502.18116", "title": "Bayesian Optimization for Controlled Image Editing via LLMs", "authors": ["Chengkun Cai", "Haoliang Liu", "Xu Zhao", "Zhongyu Jiang", "Tianfang Zhang", "Zongkai Wu", "John Lee", "Jenq-Neng Hwang", "Lei Li"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 figures, accept at ACL2025 Findings", "url": "http://arxiv.org/abs/2502.18116v3", "summary": "In the rapidly evolving field of image generation, achieving precise control\nover generated content and maintaining semantic consistency remain significant\nlimitations, particularly concerning grounding techniques and the necessity for\nmodel fine-tuning. To address these challenges, we propose BayesGenie, an\noff-the-shelf approach that integrates Large Language Models (LLMs) with\nBayesian Optimization to facilitate precise and user-friendly image editing.\nOur method enables users to modify images through natural language descriptions\nwithout manual area marking, while preserving the original image's semantic\nintegrity. Unlike existing techniques that require extensive pre-training or\nfine-tuning, our approach demonstrates remarkable adaptability across various\nLLMs through its model-agnostic design. BayesGenie employs an adapted Bayesian\noptimization strategy to automatically refine the inference process parameters,\nachieving high-precision image editing with minimal user intervention. Through\nextensive experiments across diverse scenarios, we demonstrate that our\nframework significantly outperforms existing methods in both editing accuracy\nand semantic preservation, as validated using different LLMs including Claude3\nand GPT-4.", "comment": "8 figures, accept at ACL2025 Findings", "pdf_url": "http://arxiv.org/pdf/2502.18116v3", "cate": "cs.CV", "date": "2025-02-25", "updated": "2025-07-07"}
{"id": "2502.20292", "title": "Visual Adaptive Prompting for Compositional Zero-Shot Learning", "authors": ["Kyle Stein", "Arash Mahyari", "Guillermo Francia", "Eman El-Sheikh"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.20292v5", "summary": "Vision-Language Models (VLMs) have demonstrated impressive multimodal\ncapabilities in learning joint representations of visual and textual data,\nmaking them powerful tools for tasks such as Compositional Zero-Shot Learning\n(CZSL). CZSL requires models to generalize to novel combinations of visual\nprimitives--such as attributes and objects--that were not explicitly\nencountered during training. Recent works in prompting for CZSL have focused on\nmodifying inputs for the text encoder, often using static prompts that do not\nchange across varying visual contexts. However, these approaches struggle to\nfully capture varying visual contexts, as they focus on text adaptation rather\nthan leveraging visual features for compositional reasoning. To address this,\nwe propose a Visual Adaptive Prompting System (VAPS) that leverages a learnable\nvisual prompt repository and similarity-based retrieval mechanism within the\nframework of VLMs to bridge the gap between semantic and visual features. Our\nmethod introduces a dynamic visual prompt repository mechanism that selects the\nmost relevant attribute and object prompts based on the visual features of the\nimage. Our proposed system includes a visual prompt adapter that encourages the\nmodel to learn a more generalizable embedding space. Experiments on three CZSL\nbenchmarks, across both closed and open-world scenarios, demonstrate\nstate-of-the-art results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.20292v5", "cate": "cs.CV", "date": "2025-02-27", "updated": "2025-07-08"}
{"id": "2507.06223", "title": "Efficiency-Effectiveness Reranking FLOPs for LLM-based Rerankers", "authors": ["Zhiyuan Peng", "Ting-ruen Wei", "Tingyu Song", "Yilun Zhao", "Yi Fang"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      under review", "url": "http://arxiv.org/abs/2507.06223v1", "summary": "Large Language Models (LLMs) have recently been applied to reranking tasks in\ninformation retrieval, achieving strong performance. However, their high\ncomputational demands often hinder practical deployment. Existing studies\nevaluate the efficiency of LLM-based rerankers using proxy metrics such as\nlatency, the number of forward passes, input tokens, and output tokens.\nHowever, these metrics depend on hardware and running-time choices (\\eg\nparallel or not, batch size, etc), and often fail to account for model size,\nmaking it difficult to interpret and obscuring the evaluation of the\nefficiency-effectiveness tradeoff. To address this issue, we propose\nE\\textsuperscript{2}R-FLOPs, for LLM-based rerankers: ranking metrics per\nPetaFLOP (RPP) for relevance per compute and queries per PetaFLOP (QPP) for\nhardware-agnostic throughput. Companied with the new metrics, an interpretable\nFLOPs estimator is built to estimate the FLOPs of an LLM-based reranker even\nwithout running any experiments. Based on the proposed metrics, we conduct\ncomprehensive experiments to evaluate a wide range of LLM-based rerankers with\ndifferent architecture, studying the efficiency-effectiveness trade-off and\nbringing this issue to the attention of the research community.", "comment": "under review", "pdf_url": "http://arxiv.org/pdf/2507.06223v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2502.20964", "title": "Fine-Grained Knowledge Structuring and Retrieval for Visual Question Answering", "authors": ["Zhengxuan Zhang", "Yin Wu", "Yuyu Luo", "Nan Tang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.20964v3", "summary": "Visual Question Answering (VQA) focuses on providing answers to natural\nlanguage questions by utilizing information from images. Although cutting-edge\nmultimodal large language models (MLLMs) such as GPT-4o achieve strong\nperformance on VQA tasks, they frequently fall short in accessing\ndomain-specific or the latest knowledge. To mitigate this issue,\nretrieval-augmented generation (RAG) leveraging external knowledge bases (KBs),\nreferred to as KB-VQA, emerges as a promising approach. Nevertheless,\nconventional unimodal retrieval techniques, which translate images into textual\ndescriptions, often result in the loss of critical visual details. To address\nthese challenges, this study presents two key innovations. First, we introduce\nfine-grained knowledge units that consist of multimodal data fragments (e.g.\ntext fragments, entity images, and so on) in a structured manner. Rather than\nmerely refining retrieval mechanisms, we prioritize the systematic organization\nand management of these knowledge units, ensuring that the structuring process\nitself enhances retrieval quality. Second, we propose a knowledge unit\nretrieval-augmented generation framework (KU-RAG) that seamlessly integrates\nfine-grained retrieval with MLLMs. Our KU-RAG framework not only ensures\nprecise retrieval of relevant knowledge but also enhances reasoning\ncapabilities through a knowledge correction chain. Experimental results\ndemonstrate that our approach consistently outperforms existing KB-VQA methods\nacross four benchmarks, achieving an average improvement of approximately 3%\nand up to 11% in the best case.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.20964v3", "cate": "cs.CV", "date": "2025-02-28", "updated": "2025-07-08"}
{"id": "2503.00301", "title": "Differential Coding for Training-Free ANN-to-SNN Conversion", "authors": ["Zihan Huang", "Wei Fang", "Tong Bu", "Peng Xue", "Zecheng Hao", "Wenxuan Liu", "Yuanhong Tang", "Zhaofei Yu", "Tiejun Huang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.00301v3", "summary": "Spiking Neural Networks (SNNs) exhibit significant potential due to their low\nenergy consumption. Converting Artificial Neural Networks (ANNs) to SNNs is an\nefficient way to achieve high-performance SNNs. However, many conversion\nmethods are based on rate coding, which requires numerous spikes and longer\ntime-steps compared to directly trained SNNs, leading to increased energy\nconsumption and latency. This article introduces differential coding for\nANN-to-SNN conversion, a novel coding scheme that reduces spike counts and\nenergy consumption by transmitting changes in rate information rather than\nrates directly, and explores its application across various layers.\nAdditionally, the threshold iteration method is proposed to optimize thresholds\nbased on activation distribution when converting Rectified Linear Units (ReLUs)\nto spiking neurons. Experimental results on various Convolutional Neural\nNetworks (CNNs) and Transformers demonstrate that the proposed differential\ncoding significantly improves accuracy while reducing energy consumption,\nparticularly when combined with the threshold iteration method, achieving\nstate-of-the-art performance. The source codes of the proposed method are\navailable at https://github.com/h-z-h-cell/ANN-to-SNN-DCGS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.00301v3", "cate": "cs.CV", "date": "2025-03-01", "updated": "2025-07-08"}
{"id": "2304.06670", "title": "Deep neural networks have an inbuilt Occam's razor", "authors": ["Chris Mingard", "Henry Rees", "Guillermo Valle-Pérez", "Ard A. Louis"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2304.06670v2", "summary": "The remarkable performance of overparameterized deep neural networks (DNNs)\nmust arise from an interplay between network architecture, training algorithms,\nand structure in the data. To disentangle these three components, we apply a\nBayesian picture, based on the functions expressed by a DNN, to supervised\nlearning. The prior over functions is determined by the network, and is varied\nby exploiting a transition between ordered and chaotic regimes. For Boolean\nfunction classification, we approximate the likelihood using the error spectrum\nof functions on data. When combined with the prior, this accurately predicts\nthe posterior, measured for DNNs trained with stochastic gradient descent. This\nanalysis reveals that structured data, combined with an intrinsic Occam's\nrazor-like inductive bias towards (Kolmogorov) simple functions that is strong\nenough to counteract the exponential growth of the number of functions with\ncomplexity, is a key to the success of DNNs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2304.06670v2", "cate": "cs.LG", "date": "2023-04-13", "updated": "2025-07-08"}
{"id": "2503.04504", "title": "AnyAnomaly: Zero-Shot Customizable Video Anomaly Detection with LVLM", "authors": ["Sunghyun Ahn", "Youngwan Jo", "Kijung Lee", "Sein Kwon", "Inpyo Hong", "Sanghyun Park"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.04504v2", "summary": "Video anomaly detection (VAD) is crucial for video analysis and surveillance\nin computer vision. However, existing VAD models rely on learned normal\npatterns, which makes them difficult to apply to diverse environments.\nConsequently, users should retrain models or develop separate AI models for new\nenvironments, which requires expertise in machine learning, high-performance\nhardware, and extensive data collection, limiting the practical usability of\nVAD. To address these challenges, this study proposes customizable video\nanomaly detection (C-VAD) technique and the AnyAnomaly model. C-VAD considers\nuser-defined text as an abnormal event and detects frames containing a\nspecified event in a video. We effectively implemented AnyAnomaly using a\ncontext-aware visual question answering without fine-tuning the large vision\nlanguage model. To validate the effectiveness of the proposed model, we\nconstructed C-VAD datasets and demonstrated the superiority of AnyAnomaly.\nFurthermore, our approach showed competitive performance on VAD benchmark\ndatasets, achieving state-of-the-art results on the UBnormal dataset and\noutperforming other methods in generalization across all datasets. Our code is\navailable online at github.com/SkiddieAhn/Paper-AnyAnomaly.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.04504v2", "cate": "cs.CV", "date": "2025-03-06", "updated": "2025-07-08"}
{"id": "2503.08199", "title": "A Cascading Cooperative Multi-agent Framework for On-ramp Merging Control Integrating Large Language Models", "authors": ["Miao Zhang", "Zhenlong Fang", "Tianyi Wang", "Qian Zhang", "Shuai Lu", "Junfeng Jiao", "Tianyu Shi"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.08199v2", "summary": "Traditional Reinforcement Learning (RL) suffers from replicating human-like\nbehaviors, generalizing effectively in multi-agent scenarios, and overcoming\ninherent interpretability issues.These tasks are compounded when deep\nenvironment understanding, agent coordination and dynamic optimization are\nrequired. While Large Language Model (LLM) enhanced methods have shown promise\nin generalization and interoperability, they often neglect necessary\nmulti-agent coordination. Therefore, we introduce the Cascading Cooperative\nMulti-agent (CCMA) framework, integrating RL for individual interactions, a\nfine-tuned LLM for regional cooperation, a reward function for global\noptimization, and the Retrieval-augmented Generation mechanism to dynamically\noptimize decision-making across complex driving scenarios. Our experiments\ndemonstrate that the CCMA outperforms existing RL methods, demonstrating\nsignificant improvements in both micro and macro-level performance in complex\ndriving environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.08199v2", "cate": "cs.CV", "date": "2025-03-11", "updated": "2025-07-08"}
{"id": "2403.01671", "title": "Approximating invariant functions with the sorting trick is theoretically justified", "authors": ["Wee Chaimanowong", "Ying Zhu"], "categories": ["cs.LG", "65G05 (Primary), 20B99 (Secondary)"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      26 pages, 2 figures, 1 Tables", "url": "http://arxiv.org/abs/2403.01671v4", "summary": "Many machine learning models leverage group invariance which is enjoyed with\na wide-range of applications. For exploiting an invariance structure, one\ncommon approach is known as \\emph{frame averaging}. One popular example of\nframe averaging is the \\emph{group averaging}, where the entire group is used\nto symmetrize a function. The other end of the spectrum is the\n\\emph{canonicalization}, where a frame at each point consists of a single group\nelement which transforms the point to its orbit representative. Compared to\ngroup averaging, canonicalization is more efficient computationally. However,\nit results in non-differentiablity or discontinuity of the canonicalized\nfunction. As a result, the theoretical performance of canonicalization has not\nbeen given much attention. In this work, we establish an approximation theory\nfor canonicalization. Specifically, we bound the point-wise and\n$L^2(\\mathbb{P})$ approximation errors as well as the kernel's eigenvalue decay\nrates associated with a canonicalization trick.", "comment": "26 pages, 2 figures, 1 Tables", "pdf_url": "http://arxiv.org/pdf/2403.01671v4", "cate": "cs.LG", "date": "2024-03-04", "updated": "2025-07-08"}
{"id": "2503.08805", "title": "Filter Like You Test: Data-Driven Data Filtering for CLIP Pretraining", "authors": ["Mikey Shechter", "Yair Carmon"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.08805v2", "summary": "We introduce Filter Like You Test (FLYT), an algorithm for curating\nlarge-scale vision-language datasets that learns the usefulness of each data\npoint as a pretraining example. FLYT trains a scoring model that learns to\nweigh each example's features using gradient signals from downstream tasks\ntraining sets. Based on FLYT, we implement Mixing-FLYT (M-FLYT), which takes\nthe per-example scores generated by different scoring methods as features, and\nlearns to unify them into a single score. FLYT naturally produces a\ndistribution over the training examples, which we leverage through Soft Cap\nSampling (SCS), a strategy for obtaining a filtered pretraining dataset from\nper-example probabilities that samples examples while preventing\nover-representation through a repetition penalty. Using these methods, we\nachieve 40.1% ImageNet zero-shot accuracy on the DataComp medium scale\nfiltering benchmark, a 2% absolute accuracy increase over all previous results\nand a 5.5% increase over results that - like us - use only public resources.\nOur approach also yields 37.7\\% on the average of 38 DataComp evaluation tasks,\noutperforming previous public-resource approaches by 0.4\\%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.08805v2", "cate": "cs.CV", "date": "2025-03-11", "updated": "2025-07-08"}
{"id": "2403.13847", "title": "Optimal Transport for Domain Adaptation through Gaussian Mixture Models", "authors": ["Eduardo Fernandes Montesuma", "Fred Maurice Ngolè Mboula", "Antoine Souloumiac"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      29 pages, 9 figures, 8 tables, accepted at Transactions on Machine Learning Research. Code available at: this https URL", "url": "http://arxiv.org/abs/2403.13847v3", "summary": "Machine learning systems operate under the assumption that training and test\ndata are sampled from a fixed probability distribution. However, this\nassumptions is rarely verified in practice, as the conditions upon which data\nwas acquired are likely to change. In this context, the adaptation of the\nunsupervised domain requires minimal access to the data of the new conditions\nfor learning models robust to changes in the data distribution. Optimal\ntransport is a theoretically grounded tool for analyzing changes in\ndistribution, especially as it allows the mapping between domains. However,\nthese methods are usually computationally expensive as their complexity scales\ncubically with the number of samples. In this work, we explore optimal\ntransport between Gaussian Mixture Models (GMMs), which is conveniently written\nin terms of the components of source and target GMMs. We experiment with 9\nbenchmarks, with a total of $85$ adaptation tasks, showing that our methods are\nmore efficient than previous shallow domain adaptation methods, and they scale\nwell with number of samples $n$ and dimensions $d$.", "comment": "29 pages, 9 figures, 8 tables, accepted at Transactions on Machine\n  Learning Research. Code available at: https://github.com/eddardd/gmm-otda/", "pdf_url": "http://arxiv.org/pdf/2403.13847v3", "cate": "cs.LG", "date": "2024-03-18", "updated": "2025-07-08"}
{"id": "2503.09277", "title": "UniCombine: Unified Multi-Conditional Combination with Diffusion Transformer", "authors": ["Haoxuan Wang", "Jinlong Peng", "Qingdong He", "Hao Yang", "Ying Jin", "Jiafu Wu", "Xiaobin Hu", "Yanjie Pan", "Zhenye Gan", "Mingmin Chi", "Bo Peng", "Yabiao Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.09277v2", "summary": "With the rapid development of diffusion models in image generation, the\ndemand for more powerful and flexible controllable frameworks is increasing.\nAlthough existing methods can guide generation beyond text prompts, the\nchallenge of effectively combining multiple conditional inputs while\nmaintaining consistency with all of them remains unsolved. To address this, we\nintroduce UniCombine, a DiT-based multi-conditional controllable generative\nframework capable of handling any combination of conditions, including but not\nlimited to text prompts, spatial maps, and subject images. Specifically, we\nintroduce a novel Conditional MMDiT Attention mechanism and incorporate a\ntrainable LoRA module to build both the training-free and training-based\nversions. Additionally, we propose a new pipeline to construct\nSubjectSpatial200K, the first dataset designed for multi-conditional generative\ntasks covering both the subject-driven and spatially-aligned conditions.\nExtensive experimental results on multi-conditional generation demonstrate the\noutstanding universality and powerful capability of our approach with\nstate-of-the-art performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.09277v2", "cate": "cs.CV", "date": "2025-03-12", "updated": "2025-07-08"}
{"id": "2507.06056", "title": "Entropy-Memorization Law: Evaluating Memorization Difficulty of Data in LLMs", "authors": ["Yizhan Huang", "Zhe Yang", "Meifang Chen", "Jianping Zhang", "Michael R. Lyu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06056v1", "summary": "Large Language Models (LLMs) are known to memorize portions of their training\ndata, sometimes reproducing content verbatim when prompted appropriately. In\nthis work, we investigate a fundamental yet under-explored question in the\ndomain of memorization: How to characterize memorization difficulty of training\ndata in LLMs? Through empirical experiments on OLMo, a family of open models,\nwe present the Entropy-Memorization Law. It suggests that data entropy is\nlinearly correlated with memorization score. Moreover, in a case study of\nmemorizing highly randomized strings, or \"gibberish\", we observe that such\nsequences, despite their apparent randomness, exhibit unexpectedly low\nempirical entropy compared to the broader training corpus. Adopting the same\nstrategy to discover Entropy-Memorization Law, we derive a simple yet effective\napproach to distinguish training and testing data, enabling Dataset Inference\n(DI).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06056v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2403.16846", "title": "CoDy: Counterfactual Explainers for Dynamic Graphs", "authors": ["Zhan Qu", "Daniel Gomm", "Michael Färber"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Proceedings in ICML 2025", "url": "http://arxiv.org/abs/2403.16846v2", "summary": "Temporal Graph Neural Networks (TGNNs) are widely used to model dynamic\nsystems where relationships and features evolve over time. Although TGNNs\ndemonstrate strong predictive capabilities in these domains, their complex\narchitectures pose significant challenges for explainability. Counterfactual\nexplanation methods provide a promising solution by illustrating how\nmodifications to input graphs can influence model predictions. To address this\nchallenge, we present CoDy, Counterfactual Explainer for Dynamic Graphs, a\nmodel-agnostic, instance-level explanation approach that identifies\ncounterfactual subgraphs to interpret TGNN predictions. CoDy employs a search\nalgorithm that combines Monte Carlo Tree Search with heuristic selection\npolicies, efficiently exploring a vast search space of potential explanatory\nsubgraphs by leveraging spatial, temporal, and local event impact information.\nExtensive experiments against state-of-the-art factual and counterfactual\nbaselines demonstrate CoDy's effectiveness, with improvements of 16% in AUFSC+\nover the strongest baseline.", "comment": "Proceedings in ICML 2025", "pdf_url": "http://arxiv.org/pdf/2403.16846v2", "cate": "cs.LG", "date": "2024-03-25", "updated": "2025-07-08"}
{"id": "2503.14552", "title": "Eyes on the Environment: AI-Driven Analysis for Fire and Smoke Classification, Segmentation, and Detection", "authors": ["Sayed Pedram Haeri Boroujeni", "Niloufar Mehrabi", "Fatemeh Afghah", "Connor Peter McGrath", "Danish Bhatkar", "Mithilesh Anil Biradar", "Abolfazl Razi"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.14552v2", "summary": "Fire and smoke phenomena pose a significant threat to the natural\nenvironment, ecosystems, and global economy, as well as human lives and\nwildlife. In this particular circumstance, there is a demand for more\nsophisticated and advanced technologies to implement an effective strategy for\nearly detection, real-time monitoring, and minimizing the overall impacts of\nfires on ecological balance and public safety. Recently, the rapid advancement\nof Artificial Intelligence (AI) and Computer Vision (CV) frameworks has\nsubstantially revolutionized the momentum for developing efficient fire\nmanagement systems. However, these systems extensively rely on the availability\nof adequate and high-quality fire and smoke data to create proficient Machine\nLearning (ML) methods for various tasks, such as detection and monitoring.\nAlthough fire and smoke datasets play a critical role in training, evaluating,\nand testing advanced Deep Learning (DL) models, a comprehensive review of the\nexisting datasets is still unexplored. For this purpose, we provide an in-depth\nreview to systematically analyze and evaluate fire and smoke datasets collected\nover the past 20 years. We investigate the characteristics of each dataset,\nincluding type, size, format, collection methods, and geographical diversities.\nWe also review and highlight the unique features of each dataset, such as\nimaging modalities (RGB, thermal, infrared) and their applicability for\ndifferent fire management tasks (classification, segmentation, detection).\nFurthermore, we summarize the strengths and weaknesses of each dataset and\ndiscuss their potential for advancing research and technology in fire\nmanagement. Ultimately, we conduct extensive experimental analyses across\ndifferent datasets using several state-of-the-art algorithms, such as\nResNet-50, DeepLab-V3, and YoloV8.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.14552v2", "cate": "cs.CV", "date": "2025-03-17", "updated": "2025-07-08"}
{"id": "2503.15275", "title": "Challenges and Trends in Egocentric Vision: A Survey", "authors": ["Xiang Li", "Heqian Qiu", "Lanxiao Wang", "Hanwen Zhang", "Chenghao Qi", "Linfeng Han", "Huiyu Xiong", "Hongliang Li"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.15275v3", "summary": "With the rapid development of artificial intelligence technologies and\nwearable devices, egocentric vision understanding has emerged as a new and\nchallenging research direction, gradually attracting widespread attention from\nboth academia and industry. Egocentric vision captures visual and multimodal\ndata through cameras or sensors worn on the human body, offering a unique\nperspective that simulates human visual experiences. This paper provides a\ncomprehensive survey of the research on egocentric vision understanding,\nsystematically analyzing the components of egocentric scenes and categorizing\nthe tasks into four main areas: subject understanding, object understanding,\nenvironment understanding, and hybrid understanding. We explore in detail the\nsub-tasks within each category. We also summarize the main challenges and\ntrends currently existing in the field. Furthermore, this paper presents an\noverview of high-quality egocentric vision datasets, offering valuable\nresources for future research. By summarizing the latest advancements, we\nanticipate the broad applications of egocentric vision technologies in fields\nsuch as augmented reality, virtual reality, and embodied intelligence, and\npropose future research directions based on the latest developments in the\nfield.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.15275v3", "cate": "cs.CV", "date": "2025-03-19", "updated": "2025-07-08"}
{"id": "2503.17069", "title": "PVChat: Personalized Video Chat with One-Shot Learning", "authors": ["Yufei Shi", "Weilong Yan", "Gang Xu", "Yumeng Li", "Yucheng Chen", "Zhenxi Li", "Fei Richard Yu", "Ming Li", "Si Yong Yeo"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.17069v3", "summary": "Video large language models (ViLLMs) excel in general video understanding,\ne.g., recognizing activities like talking and eating, but struggle with\nidentity-aware comprehension, such as \"Wilson is receiving chemotherapy\" or\n\"Tom is discussing with Sarah\", limiting their applicability in smart\nhealthcare and smart home environments. To address this limitation, we propose\na one-shot learning framework PVChat, the first personalized ViLLM that enables\nsubject-aware question answering (QA) from a single video for each subject. Our\napproach optimizes a Mixture-of-Heads (MoH) enhanced ViLLM on a synthetically\naugmented video-QA dataset, leveraging a progressive image-to-video learning\nstrategy. Specifically, we introduce an automated augmentation pipeline that\nsynthesizes identity-preserving positive samples and retrieves hard negatives\nfrom existing video corpora, generating a diverse training dataset with four QA\ntypes: existence, appearance, action, and location inquiries. To enhance\nsubject-specific learning, we propose a ReLU Routing MoH attention mechanism,\nalongside two novel objectives: (1) Smooth Proximity Regularization for\nprogressive learning through exponential distance scaling and (2) Head\nActivation Enhancement for balanced attention routing. Finally, we adopt a\ntwo-stage training strategy, transitioning from image pre-training to video\nfine-tuning, enabling a gradual learning process from static attributes to\ndynamic representations. We evaluate PVChat on diverse datasets covering\nmedical scenarios, TV series, anime, and real-world footage, demonstrating its\nsuperiority in personalized feature understanding after learning from a single\nvideo, compared to state-of-the-art ViLLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.17069v3", "cate": "cs.CV", "date": "2025-03-21", "updated": "2025-07-08"}
{"id": "2406.15753", "title": "The Perils of Optimizing Learned Reward Functions: Low Training Error Does Not Guarantee Low Regret", "authors": ["Lukas Fluri", "Leon Lang", "Alessandro Abate", "Patrick Forré", "David Krueger", "Joar Skalse"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      72 pages, 4 figures", "url": "http://arxiv.org/abs/2406.15753v3", "summary": "In reinforcement learning, specifying reward functions that capture the\nintended task can be very challenging. Reward learning aims to address this\nissue by learning the reward function. However, a learned reward model may have\na low error on the data distribution, and yet subsequently produce a policy\nwith large regret. We say that such a reward model has an error-regret\nmismatch. The main source of an error-regret mismatch is the distributional\nshift that commonly occurs during policy optimization. In this paper, we\nmathematically show that a sufficiently low expected test error of the reward\nmodel guarantees low worst-case regret, but that for any fixed expected test\nerror, there exist realistic data distributions that allow for error-regret\nmismatch to occur. We then show that similar problems persist even when using\npolicy regularization techniques, commonly employed in methods such as RLHF. We\nhope our results stimulate the theoretical and empirical study of improved\nmethods to learn reward models, and better ways to measure their quality\nreliably.", "comment": "72 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2406.15753v3", "cate": "cs.LG", "date": "2024-06-22", "updated": "2025-07-08"}
{"id": "2503.17660", "title": "OMR-Diffusion:Optimizing Multi-Round Enhanced Training in Diffusion Models for Improved Intent Understanding", "authors": ["Kun Li", "Jianhui Wang", "Miao Zhang", "Xueqian Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.17660v3", "summary": "Generative AI has significantly advanced text-driven image generation, but it\nstill faces challenges in producing outputs that consistently align with\nevolving user preferences and intents, particularly in multi-turn dialogue\nscenarios. In this research, We present a Visual Co-Adaptation (VCA) framework\nthat incorporates human-in-the-loop feedback, utilizing a well-trained reward\nmodel specifically designed to closely align with human preferences. Using a\ndiverse multi-turn dialogue dataset, the framework applies multiple reward\nfunctions (such as diversity, consistency, and preference feedback) to refine\nthe diffusion model through LoRA, effectively optimizing image generation based\non user input. We also constructed multi-round dialogue datasets with prompts\nand image pairs that well-fit user intent. Experiments show the model achieves\n508 wins in human evaluation, outperforming DALL-E 3 (463 wins) and others. It\nalso achieves 3.4 rounds in dialogue efficiency (vs. 13.7 for DALL-E 3) and\nexcels in metrics like LPIPS (0.15) and BLIP (0.59). Various experiments\ndemonstrate the effectiveness of the proposed method over state-of-the-art\nbaselines, with significant improvements in image consistency and alignment\nwith user intent.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.17660v3", "cate": "cs.CV", "date": "2025-03-22", "updated": "2025-07-08"}
{"id": "2408.13002", "title": "Measuring Variable Importance in Heterogeneous Treatment Effects with Confidence", "authors": ["Joseph Paillard", "Angel Reyero Lobo", "Vitaliy Kolodyazhniy", "Bertrand Thirion", "Denis A. Engemann"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.13002v4", "summary": "Causal machine learning holds promise for estimating individual treatment\neffects from complex data. For successful real-world applications of machine\nlearning methods, it is of paramount importance to obtain reliable insights\ninto which variables drive heterogeneity in the response to treatment. We\npropose PermuCATE, an algorithm based on the Conditional Permutation Importance\n(CPI) method, for statistically rigorous global variable importance assessment\nin the estimation of the Conditional Average Treatment Effect (CATE).\nTheoretical analysis of the finite sample regime and empirical studies show\nthat PermuCATE has lower variance than the Leave-One-Covariate-Out (LOCO)\nreference method and provides a reliable measure of variable importance. This\nproperty increases statistical power, which is crucial for causal inference in\nthe limited-data regime common to biomedical applications. We empirically\ndemonstrate the benefits of PermuCATE in simulated and real-world health\ndatasets, including settings with up to hundreds of correlated variables.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.13002v4", "cate": "cs.LG", "date": "2024-08-23", "updated": "2025-07-08"}
{"id": "2503.17669", "title": "TDRI: Two-Phase Dialogue Refinement and Co-Adaptation for Interactive Image Generation", "authors": ["Yuheng Feng", "Jianhui Wang", "Kun Li", "Sida Li", "Tianyu Shi", "Haoyue Han", "Miao Zhang", "Xueqian Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.17669v3", "summary": "Although text-to-image generation technologies have made significant\nadvancements, they still face challenges when dealing with ambiguous prompts\nand aligning outputs with user intent.Our proposed framework, TDRI (Two-Phase\nDialogue Refinement and Co-Adaptation), addresses these issues by enhancing\nimage generation through iterative user interaction. It consists of two phases:\nthe Initial Generation Phase, which creates base images based on user prompts,\nand the Interactive Refinement Phase, which integrates user feedback through\nthree key modules. The Dialogue-to-Prompt (D2P) module ensures that user\nfeedback is effectively transformed into actionable prompts, which improves the\nalignment between user intent and model input. By evaluating generated outputs\nagainst user expectations, the Feedback-Reflection (FR) module identifies\ndiscrepancies and facilitates improvements. In an effort to ensure consistently\nhigh-quality results, the Adaptive Optimization (AO) module fine-tunes the\ngeneration process by balancing user preferences and maintaining prompt\nfidelity. Experimental results show that TDRI outperforms existing methods by\nachieving 33.6% human preference, compared to 6.2% for GPT-4 augmentation, and\nthe highest CLIP and BLIP alignment scores (0.338 and 0.336, respectively). In\niterative feedback tasks, user satisfaction increased to 88% after 8 rounds,\nwith diminishing returns beyond 6 rounds. Furthermore, TDRI has been found to\nreduce the number of iterations and improve personalization in the creation of\nfashion products. TDRI exhibits a strong potential for a wide range of\napplications in the creative and industrial domains, as it streamlines the\ncreative process and improves alignment with user preferences", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.17669v3", "cate": "cs.CV", "date": "2025-03-22", "updated": "2025-07-08"}
{"id": "2411.00278", "title": "KAN-AD: Time Series Anomaly Detection with Kolmogorov-Arnold Networks", "authors": ["Quan Zhou", "Changhua Pei", "Fei Sun", "Jing Han", "Zhengwei Gao", "Dan Pei", "Haiming Zhang", "Gaogang Xie", "Jianhui Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, ICML 2025", "url": "http://arxiv.org/abs/2411.00278v3", "summary": "Time series anomaly detection (TSAD) underpins real-time monitoring in cloud\nservices and web systems, allowing rapid identification of anomalies to prevent\ncostly failures. Most TSAD methods driven by forecasting models tend to overfit\nby emphasizing minor fluctuations. Our analysis reveals that effective TSAD\nshould focus on modeling \"normal\" behavior through smooth local patterns. To\nachieve this, we reformulate time series modeling as approximating the series\nwith smooth univariate functions. The local smoothness of each univariate\nfunction ensures that the fitted time series remains resilient against local\ndisturbances. However, a direct KAN implementation proves susceptible to these\ndisturbances due to the inherently localized characteristics of B-spline\nfunctions. We thus propose KAN-AD, replacing B-splines with truncated Fourier\nexpansions and introducing a novel lightweight learning mechanism that\nemphasizes global patterns while staying robust to local disturbances. On four\npopular TSAD benchmarks, KAN-AD achieves an average 15% improvement in\ndetection accuracy (with peaks exceeding 27%) over state-of-the-art baselines.\nRemarkably, it requires fewer than 1,000 trainable parameters, resulting in a\n50% faster inference speed compared to the original KAN, demonstrating the\napproach's efficiency and practical viability.", "comment": "11 pages, ICML 2025", "pdf_url": "http://arxiv.org/pdf/2411.00278v3", "cate": "cs.LG", "date": "2024-11-01", "updated": "2025-07-08"}
{"id": "2503.18364", "title": "MaSS13K: A Matting-level Semantic Segmentation Benchmark", "authors": ["Chenxi Xie", "Minghan Li", "Hui Zeng", "Jun Luo", "Lei Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      CVPR2025", "url": "http://arxiv.org/abs/2503.18364v2", "summary": "High-resolution semantic segmentation is essential for applications such as\nimage editing, bokeh imaging, AR/VR, etc. Unfortunately, existing datasets\noften have limited resolution and lack precise mask details and boundaries. In\nthis work, we build a large-scale, matting-level semantic segmentation dataset,\nnamed MaSS13K, which consists of 13,348 real-world images, all at 4K\nresolution. MaSS13K provides high-quality mask annotations of a number of\nobjects, which are categorized into seven categories: human, vegetation,\nground, sky, water, building, and others. MaSS13K features precise masks, with\nan average mask complexity 20-50 times higher than existing semantic\nsegmentation datasets. We consequently present a method specifically designed\nfor high-resolution semantic segmentation, namely MaSSFormer, which employs an\nefficient pixel decoder that aggregates high-level semantic features and\nlow-level texture features across three stages, aiming to produce\nhigh-resolution masks with minimal computational cost. Finally, we propose a\nnew learning paradigm, which integrates the high-quality masks of the seven\ngiven categories with pseudo labels from new classes, enabling MaSSFormer to\ntransfer its accurate segmentation capability to other classes of objects. Our\nproposed MaSSFormer is comprehensively evaluated on the MaSS13K benchmark\ntogether with 14 representative segmentation models. We expect that our\nmeticulously annotated MaSS13K dataset and the MaSSFormer model can facilitate\nthe research of high-resolution and high-quality semantic segmentation.\nDatasets and codes can be found at https://github.com/xiechenxi99/MaSS13K.", "comment": "CVPR2025", "pdf_url": "http://arxiv.org/pdf/2503.18364v2", "cate": "cs.CV", "date": "2025-03-24", "updated": "2025-07-08"}
{"id": "2503.23367", "title": "FastVAR: Linear Visual Autoregressive Modeling via Cached Token Pruning", "authors": ["Hang Guo", "Yawei Li", "Taolin Zhang", "Jiangshan Wang", "Tao Dai", "Shu-Tao Xia", "Luca Benini"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV2025", "url": "http://arxiv.org/abs/2503.23367v3", "summary": "Visual Autoregressive (VAR) modeling has gained popularity for its shift\ntowards next-scale prediction. However, existing VAR paradigms process the\nentire token map at each scale step, leading to the complexity and runtime\nscaling dramatically with image resolution. To address this challenge, we\npropose FastVAR, a post-training acceleration method for efficient resolution\nscaling with VARs. Our key finding is that the majority of latency arises from\nthe large-scale step where most tokens have already converged. Leveraging this\nobservation, we develop the cached token pruning strategy that only forwards\npivotal tokens for scale-specific modeling while using cached tokens from\nprevious scale steps to restore the pruned slots. This significantly reduces\nthe number of forwarded tokens and improves the efficiency at larger\nresolutions. Experiments show the proposed FastVAR can further speedup\nFlashAttention-accelerated VAR by 2.7$\\times$ with negligible performance drop\nof <1%. We further extend FastVAR to zero-shot generation of higher resolution\nimages. In particular, FastVAR can generate one 2K image with 15GB memory\nfootprints in 1.5s on a single NVIDIA 3090 GPU. Code is available at\nhttps://github.com/csguoh/FastVAR.", "comment": "ICCV2025", "pdf_url": "http://arxiv.org/pdf/2503.23367v3", "cate": "cs.CV", "date": "2025-03-30", "updated": "2025-07-08"}
{"id": "2411.05983", "title": "Longitudinal Ensemble Integration for sequential classification with multimodal data", "authors": ["Aviad Susman", "Rupak Krishnamurthy", "Yan Chak Li", "Mohammad Olaimat", "Serdar Bozdag", "Bino Varghese", "Nasim Sheikh-Bahaei", "Gaurav Pandey"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE ICDH 2025. This is the author's accepted manuscript (AAM). The final version will appear in the IEEE ICDH 2025 proceedings on IEEE Xplore", "url": "http://arxiv.org/abs/2411.05983v2", "summary": "Effectively modeling multimodal longitudinal data is a pressing need in\nvarious application areas, especially biomedicine. Despite this, few approaches\nexist in the literature for this problem, with most not adequately taking into\naccount the multimodality of the data. In this study, we developed multiple\nconfigurations of a novel multimodal and longitudinal learning framework,\nLongitudinal Ensemble Integration (LEI), for sequential classification. We\nevaluated LEI's performance, and compared it against existing approaches, for\nthe early detection of dementia, which is among the most studied multimodal\nsequential classification tasks. LEI outperformed these approaches due to its\nuse of intermediate base predictions arising from the individual data\nmodalities, which enabled their better integration over time. LEI's design also\nenabled the identification of features that were consistently important across\ntime for the effective prediction of dementia-related diagnoses. Overall, our\nwork demonstrates the potential of LEI for sequential classification from\nlongitudinal multimodal data.", "comment": "Accepted to IEEE ICDH 2025. This is the author's accepted manuscript\n  (AAM). The final version will appear in the IEEE ICDH 2025 proceedings on\n  IEEE Xplore", "pdf_url": "http://arxiv.org/pdf/2411.05983v2", "cate": "cs.LG", "date": "2024-11-08", "updated": "2025-07-08"}
{"id": "2503.23519", "title": "BoundMatch: Boundary detection applied to semi-supervised segmentation for urban-driving scenes", "authors": ["Haruya Ishikawa", "Yoshimitsu Aoki"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      20 pages, 18 figures", "url": "http://arxiv.org/abs/2503.23519v2", "summary": "Semi-supervised semantic segmentation (SS-SS) aims to mitigate the heavy\nannotation burden of dense pixel labeling by leveraging abundant unlabeled\nimages alongside a small labeled set. While current consistency regularization\nmethods achieve strong results, they often overlook a critical challenge: the\nprecise delineation of object boundaries. In this paper, we propose BoundMatch,\na novel multi-task SS-SS framework that explicitly integrates semantic boundary\ndetection into a teacher-student consistency regularization pipeline. Our core\nmechanism, Boundary Consistency Regularized Multi-Task Learning (BCRM),\nenforces prediction agreement between teacher and student models on both\nsegmentation masks and detailed semantic boundaries. To further enhance\nperformance and sharpen boundaries, BoundMatch incorporates two lightweight\nfusion modules: Boundary-Semantic Fusion (BSF) injects learned boundary cues\ninto the segmentation decoder, while Spatial Gradient Fusion (SGF) refines\nboundary predictions using mask gradients, leading to higher-quality boundary\npseudo-labels. This framework is built upon SAMTH, a strong teacher-student\nbaseline featuring a Harmonious Batch Normalization (HBN) update strategy for\nimproved stability. Extensive experiments on diverse urban-driving scene\ndatasets including Cityscapes, BDD100K, and SYNTHIA show that BoundMatch\nachieves competitive performance against current state-of-the-art methods. Our\napproach achieves state-of-the-art results on the new benchmark with DINOv2\nfoundation model. We further validate our approach's generalizability on Pascal\nVOC and ADE20K datasets. Ablation studies highlight BoundMatch's ability to\nimprove boundary-specific evaluation metrics, its effectiveness in realistic\nlarge-scale unlabeled data scenarios, and applicability to lightweight\narchitectures for mobile deployment.", "comment": "20 pages, 18 figures", "pdf_url": "http://arxiv.org/pdf/2503.23519v2", "cate": "cs.CV", "date": "2025-03-30", "updated": "2025-07-08"}
{"id": "2504.11150", "title": "GC-GAT: Multimodal Vehicular Trajectory Prediction using Graph Goal Conditioning and Cross-context Attention", "authors": ["Mahir Gulzar", "Yar Muhammad", "Naveed Muhammad"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.11150v2", "summary": "Predicting future trajectories of surrounding vehicles heavily relies on what\ncontextual information is given to a motion prediction model. The context\nitself can be static (lanes, regulatory elements, etc) or dynamic (traffic\nparticipants). This paper presents a lane graph-based motion prediction model\nthat first predicts graph-based goal proposals and later fuses them with cross\nattention over multiple contextual elements. We follow the famous\nencoder-interactor-decoder architecture where the encoder encodes scene context\nusing lightweight Gated Recurrent Units, the interactor applies cross-context\nattention over encoded scene features and graph goal proposals, and the decoder\nregresses multimodal trajectories via Laplacian Mixture Density Network from\nthe aggregated encodings. Using cross-attention over graph-based goal proposals\ngives robust trajectory estimates since the model learns to attend to future\ngoal-relevant scene elements for the intended agent. We evaluate our work on\nnuScenes motion prediction dataset, achieving state-of-the-art results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.11150v2", "cate": "cs.CV", "date": "2025-04-15", "updated": "2025-07-08"}
{"id": "2411.12665", "title": "Regression for the Mean: Auto-Evaluation and Inference with Few Labels through Post-hoc Regression", "authors": ["Benjamin Eyre", "David Madras"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Presented as a conference paper at ICML 2025", "url": "http://arxiv.org/abs/2411.12665v2", "summary": "The availability of machine learning systems that can effectively perform\narbitrary tasks has led to synthetic labels from these systems being used in\napplications of statistical inference, such as data analysis or model\nevaluation. The Prediction Powered Inference (PPI) framework provides a way of\nleveraging both a large pool of pseudo-labelled data and a small sample with\nreal, high-quality labels to produce a low-variance, unbiased estimate of the\nquantity being evaluated for. Most work on PPI considers a relatively sizable\nset of labelled samples, which can be resource intensive to obtain. However, we\nfind that when labelled data is scarce, the PPI++ method can perform even worse\nthan classical inference. We analyze this phenomenon by relating PPI++ to\nordinary least squares regression, which also experiences high variance with\nsmall sample sizes, and use this regression framework to better understand the\nefficacy of PPI. Motivated by this, we present two new PPI-based techniques\nthat leverage robust regressors to produce even lower variance estimators in\nthe few-label regime.", "comment": "Presented as a conference paper at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2411.12665v2", "cate": "cs.LG", "date": "2024-11-19", "updated": "2025-07-08"}
{"id": "2504.19600", "title": "Heat Diffusion Models -- Interpixel Attention Mechanism", "authors": ["Pengfei Zhang", "Shouqing Jia"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.19600v2", "summary": "Denoising Diffusion Probabilistic Models (DDPM) process images as a whole.\nSince adjacent pixels are highly likely to belong to the same object, we\npropose the Heat Diffusion Model (HDM) to further preserve image details and\ngenerate more realistic images. HDM essentially is a DDPM that incorporates an\nattention mechanism between pixels. In HDM, the discrete form of the\ntwo-dimensional heat equation is integrated into the diffusion and generation\nformulas of DDPM, enabling the model to compute relationships between\nneighboring pixels during image processing. Our experiments demonstrate that\nHDM can generate higher-quality samples compared to models such as DDPM,\nConsistency Diffusion Models (CDM), Latent Diffusion Models (LDM), and Vector\nQuantized Generative Adversarial Networks (VQGAN).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.19600v2", "cate": "cs.CV", "date": "2025-04-28", "updated": "2025-07-07"}
{"id": "2411.16167", "title": "Mind the Cost of Scaffold! Benign Clients May Even Become Accomplices of Backdoor Attack", "authors": ["Xingshuo Han", "Xuanye Zhang", "Xiang Lan", "Haozhao Wang", "Shengmin Xu", "Shen Ren", "Jason Zeng", "Ming Wu", "Michael Heinrich", "Tianwei Zhang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.16167v3", "summary": "By using a control variate to calibrate the local gradient of each client,\nScaffold has been widely known as a powerful solution to mitigate the impact of\ndata heterogeneity in Federated Learning. Although Scaffold achieves\nsignificant performance improvements, we show that this superiority is at the\ncost of increased security vulnerabilities. Specifically, this paper presents\nBadSFL, the first backdoor attack targeting Scaffold, which turns benign\nclients into accomplices to amplify the attack effect. The core idea of BadSFL\nis to uniquely tamper with the control variate to subtly steer benign clients'\nlocal gradient updates towards the attacker's poisoned direction, effectively\nturning them into unwitting accomplices and significantly enhancing the\nbackdoor persistence. Additionally, BadSFL leverages a GAN-enhanced poisoning\nstrategy to enrich the attacker's dataset, maintaining high accuracy on both\nbenign and backdoored samples while remaining stealthy. Extensive experiments\ndemonstrate that BadSFL achieves superior attack durability, maintaining\neffectiveness for over 60 global rounds, lasting up to three times longer than\nexisting baselines even after ceasing malicious model injections.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.16167v3", "cate": "cs.LG", "date": "2024-11-25", "updated": "2025-07-08"}
{"id": "2504.21771", "title": "Anatomical Similarity as a New Metric to Evaluate Brain Generative Models", "authors": ["Bahram Jafrasteh", "Wei Peng", "Cheng Wan", "Yimin Luo", "Ehsan Adeli", "Qingyu Zhao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.21771v2", "summary": "Generative models enhance neuroimaging through data augmentation, quality\nimprovement, and rare condition studies. Despite advances in realistic\nsynthetic MRIs, evaluations focus on texture and perception, lacking\nsensitivity to crucial anatomical fidelity. This study proposes a new metric,\ncalled WASABI (Wasserstein-Based Anatomical Brain Index), to assess the\nanatomical realism of synthetic brain MRIs. WASABI leverages \\textit{SynthSeg},\na deep learning-based brain parcellation tool, to derive volumetric measures of\nbrain regions in each MRI and uses the multivariate Wasserstein distance to\ncompare distributions between real and synthetic anatomies. Based on controlled\nexperiments on two real datasets and synthetic MRIs from five generative\nmodels, WASABI demonstrates higher sensitivity in quantifying anatomical\ndiscrepancies compared to traditional image-level metrics, even when synthetic\nimages achieve near-perfect visual quality. Our findings advocate for shifting\nthe evaluation paradigm beyond visual inspection and conventional metrics,\nemphasizing anatomical fidelity as a crucial benchmark for clinically\nmeaningful brain MRI synthesis. Our code is available at\nhttps://github.com/BahramJafrasteh/wasabi-mri.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.21771v2", "cate": "cs.CV", "date": "2025-04-30", "updated": "2025-07-08"}
{"id": "2507.06138", "title": "Coding Triangle: How Does Large Language Model Understand Code?", "authors": ["Taolin Zhang", "Zihan Ma", "Maosong Cao", "Junnan Liu", "Songyang Zhang", "Kai Chen"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06138v1", "summary": "Large language models (LLMs) have achieved remarkable progress in code\ngeneration, yet their true programming competence remains underexplored. We\nintroduce the Code Triangle framework, which systematically evaluates LLMs\nacross three fundamental dimensions: editorial analysis, code implementation,\nand test case generation. Through extensive experiments on competitive\nprogramming benchmarks, we reveal that while LLMs can form a self-consistent\nsystem across these dimensions, their solutions often lack the diversity and\nrobustness of human programmers. We identify a significant distribution shift\nbetween model cognition and human expertise, with model errors tending to\ncluster due to training data biases and limited reasoning transfer. Our study\ndemonstrates that incorporating human-generated editorials, solutions, and\ndiverse test cases, as well as leveraging model mixtures, can substantially\nenhance both the performance and robustness of LLMs. Furthermore, we reveal\nboth the consistency and inconsistency in the cognition of LLMs that may\nfacilitate self-reflection and self-improvement, providing a potential\ndirection for developing more powerful coding models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06138v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2411.19230", "title": "Pre-Training Graph Contrastive Masked Autoencoders are Strong Distillers for EEG", "authors": ["Xinxu Wei", "Kanhao Zhao", "Yong Jiao", "Hua Xie", "Lifang He", "Yu Zhang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      24 pages", "url": "http://arxiv.org/abs/2411.19230v2", "summary": "Effectively utilizing extensive unlabeled high-density EEG data to improve\nperformance in scenarios with limited labeled low-density EEG data presents a\nsignificant challenge. In this paper, we address this challenge by formulating\nit as a graph transfer learning and knowledge distillation problem. We propose\na Unified Pre-trained Graph Contrastive Masked Autoencoder Distiller, named\nEEG-DisGCMAE, to bridge the gap between unlabeled and labeled as well as high-\nand low-density EEG data. Our approach introduces a novel unified graph\nself-supervised pre-training paradigm, which seamlessly integrates the graph\ncontrastive pre-training with the graph masked autoencoder pre-training.\nFurthermore, we propose a graph topology distillation loss function, allowing a\nlightweight student model trained on low-density data to learn from a teacher\nmodel trained on high-density data during pre-training and fine-tuning. This\nmethod effectively handles missing electrodes through contrastive distillation.\nWe validate the effectiveness of EEG-DisGCMAE across four classification tasks\nusing two clinical EEG datasets with abundant data. The source code is\navailable at https://github.com/weixinxu666/EEG_DisGCMAE.", "comment": "24 pages", "pdf_url": "http://arxiv.org/pdf/2411.19230v2", "cate": "cs.LG", "date": "2024-11-28", "updated": "2025-07-08"}
{"id": "2505.05599", "title": "Enhancing Satellite Object Localization with Dilated Convolutions and Attention-aided Spatial Pooling", "authors": ["Seraj Al Mahmud Mostafa", "Chenxi Wang", "Jia Yue", "Yuta Hozumi", "Jianwu Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This paper has been accepted to IEEE International Conference on Advanced Machine Learning and Data Science (AMLDS) 2025", "url": "http://arxiv.org/abs/2505.05599v3", "summary": "Object localization in satellite imagery is particularly challenging due to\nthe high variability of objects, low spatial resolution, and interference from\nnoise and dominant features such as clouds and city lights. In this research,\nwe focus on three satellite datasets: upper atmospheric Gravity Waves (GW),\nmesospheric Bores (Bore), and Ocean Eddies (OE), each presenting its own unique\nchallenges. These challenges include the variability in the scale and\nappearance of the main object patterns, where the size, shape, and feature\nextent of objects of interest can differ significantly. To address these\nchallenges, we introduce YOLO-DCAP, a novel enhanced version of YOLOv5 designed\nto improve object localization in these complex scenarios. YOLO-DCAP\nincorporates a Multi-scale Dilated Residual Convolution (MDRC) block to capture\nmulti-scale features at scale with varying dilation rates, and an\nAttention-aided Spatial Pooling (AaSP) module to focus on the global relevant\nspatial regions, enhancing feature selection. These structural improvements\nhelp to better localize objects in satellite imagery. Experimental results\ndemonstrate that YOLO-DCAP significantly outperforms both the YOLO base model\nand state-of-the-art approaches, achieving an average improvement of 20.95% in\nmAP50 and 32.23% in IoU over the base model, and 7.35% and 9.84% respectively\nover state-of-the-art alternatives, consistently across all three satellite\ndatasets. These consistent gains across all three satellite datasets highlight\nthe robustness and generalizability of the proposed approach. Our code is open\nsourced at\nhttps://github.com/AI-4-atmosphere-remote-sensing/satellite-object-localization.", "comment": "This paper has been accepted to IEEE International Conference on\n  Advanced Machine Learning and Data Science (AMLDS) 2025", "pdf_url": "http://arxiv.org/pdf/2505.05599v3", "cate": "cs.CV", "date": "2025-05-08", "updated": "2025-07-08"}
{"id": "2501.01370", "title": "Embedding-Based Approaches to Hyperpartisan News Detection", "authors": ["Karthik Mohan"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Updated version reflecting sole authorship. All coauthor contributions have been removed. Experimental corrections and analysis updates were introduced in the original version and are retained here as part of the submitter's independent work, along with expanded experiments by the submitter", "url": "http://arxiv.org/abs/2501.01370v3", "summary": "In this report, I describe the systems in which the objective is to determine\nwhether a given news article could be considered as hyperpartisan.\nHyperpartisan news takes an extremely polarized political standpoint with an\nintention of creating political divide among the public. Several approaches,\nincluding n-grams, sentiment analysis, as well as sentence and document\nrepresentations using pre-tained ELMo models were used. The best system is\nusing LLMs for embedding generation achieving an accuracy of around 92% over\nthe previously best system using pre-trained ELMo with Bidirectional LSTM which\nachieved an accuracy of around 83% through 10-fold cross-validation.", "comment": "Updated version reflecting sole authorship. All coauthor\n  contributions have been removed. Experimental corrections and analysis\n  updates were introduced in the original version and are retained here as part\n  of the submitter's independent work, along with expanded experiments by the\n  submitter", "pdf_url": "http://arxiv.org/pdf/2501.01370v3", "cate": "cs.LG", "date": "2025-01-02", "updated": "2025-07-07"}
{"id": "2505.21381", "title": "ZigzagPointMamba: Spatial-Semantic Mamba for Point Cloud Understanding", "authors": ["Linshuang Diao", "Dayong Ren", "Sensen Song", "Yurong Qian"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.21381v5", "summary": "State Space models (SSMs) such as PointMamba enable efficient feature\nextraction for point cloud self-supervised learning with linear complexity,\noutperforming Transformers in computational efficiency. However, existing\nPointMamba-based methods depend on complex token ordering and random masking,\nwhich disrupt spatial continuity and local semantic correlations. We propose\nZigzagPointMamba to tackle these challenges. The core of our approach is a\nsimple zigzag scan path that globally sequences point cloud tokens, enhancing\nspatial continuity by preserving the proximity of spatially adjacent point\ntokens. Nevertheless, random masking undermines local semantic modeling in\nself-supervised learning. To address this, we introduce a Semantic-Siamese\nMasking Strategy (SMS), which masks semantically similar tokens to facilitate\nreconstruction by integrating local features of original and similar tokens.\nThis overcomes the dependence on isolated local features and enables robust\nglobal semantic modeling. Our pre-trained ZigzagPointMamba weights\nsignificantly improve downstream tasks, achieving a 1.59% mIoU gain on\nShapeNetPart for part segmentation, a 0.4% higher accuracy on ModelNet40 for\nclassification, and 0.19%, 1.22%, and 0.72% higher accuracies respectively for\nthe classification tasks on the OBJ-BG, OBJ-ONLY, and PB-T50-RS subsets of\nScanObjectNN.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.21381v5", "cate": "cs.CV", "date": "2025-05-27", "updated": "2025-07-08"}
{"id": "2505.23102", "title": "CURVE: CLIP-Utilized Reinforcement Learning for Visual Image Enhancement via Simple Image Processing", "authors": ["Yuka Ogino", "Takahiro Toizumi", "Atsushi Ito"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICIP2025", "url": "http://arxiv.org/abs/2505.23102v2", "summary": "Low-Light Image Enhancement (LLIE) is crucial for improving both human\nperception and computer vision tasks. This paper addresses two challenges in\nzero-reference LLIE: obtaining perceptually 'good' images using the Contrastive\nLanguage-Image Pre-Training (CLIP) model and maintaining computational\nefficiency for high-resolution images. We propose CLIP-Utilized Reinforcement\nlearning-based Visual image Enhancement (CURVE). CURVE employs a simple image\nprocessing module which adjusts global image tone based on B\\'ezier curve and\nestimates its processing parameters iteratively. The estimator is trained by\nreinforcement learning with rewards designed using CLIP text embeddings.\nExperiments on low-light and multi-exposure datasets demonstrate the\nperformance of CURVE in terms of enhancement quality and processing speed\ncompared to conventional methods.", "comment": "Accepted to ICIP2025", "pdf_url": "http://arxiv.org/pdf/2505.23102v2", "cate": "cs.CV", "date": "2025-05-29", "updated": "2025-07-08"}
{"id": "2506.06232", "title": "Challenging Vision-Language Models with Surgical Data: A New Dataset and Broad Benchmarking Study", "authors": ["Leon Mayer", "Tim Rädsch", "Dominik Michael", "Lucas Luttner", "Amine Yamlahi", "Evangelia Christodoulou", "Patrick Godau", "Marcel Knopp", "Annika Reinke", "Fiona Kolbinger", "Lena Maier-Hein"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.06232v2", "summary": "While traditional computer vision models have historically struggled to\ngeneralize to endoscopic domains, the emergence of foundation models has shown\npromising cross-domain performance. In this work, we present the first\nlarge-scale study assessing the capabilities of Vision Language Models (VLMs)\nfor endoscopic tasks with a specific focus on laparoscopic surgery. Using a\ndiverse set of state-of-the-art models, multiple surgical datasets, and\nextensive human reference annotations, we address three key research questions:\n(1) Can current VLMs solve basic perception tasks on surgical images? (2) Can\nthey handle advanced frame-based endoscopic scene understanding tasks? and (3)\nHow do specialized medical VLMs compare to generalist models in this context?\nOur results reveal that VLMs can effectively perform basic surgical perception\ntasks, such as object counting and localization, with performance levels\ncomparable to general domain tasks. However, their performance deteriorates\nsignificantly when the tasks require medical knowledge. Notably, we find that\nspecialized medical VLMs currently underperform compared to generalist models\nacross both basic and advanced surgical tasks, suggesting that they are not yet\noptimized for the complexity of surgical environments. These findings highlight\nthe need for further advancements to enable VLMs to handle the unique\nchallenges posed by surgery. Overall, our work provides important insights for\nthe development of next-generation endoscopic AI systems and identifies key\nareas for improvement in medical visual language models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.06232v2", "cate": "cs.CV", "date": "2025-06-06", "updated": "2025-07-08"}
{"id": "2506.20214", "title": "UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation", "authors": ["Yanzhe Chen", "Huasong Zhong", "Yan Li", "Zhenheng Yang"], "categories": ["cs.CV", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      19 pages, 5 figures", "url": "http://arxiv.org/abs/2506.20214v2", "summary": "Unified multimodal large language models (MLLMs) have shown promise in\njointly advancing multimodal understanding and generation, with visual\ncodebooks discretizing images into tokens for autoregressive modeling. Existing\ncodebook-based methods either rely on small vocabularies (~16K entries) that\nlack fine-grained semantics or naively scale up, resulting in low token\nutilization and unstable training. We propose UniCode$^2$, a cascaded codebook\nframework enabling large-scale, semantically aligned, and stable visual\ntokenization. By clustering millions of SigLIP sequence embeddings, we build a\n500K-entry codebook that preserves vision-language alignment while expanding\ncapacity. Stability is ensured via a cascaded design: a frozen codebook anchors\nthe embedding space, and a trainable codebook refines task-specific semantics.\nThis decoupling promotes high utilization and robust learning. Moreover, the\nalignment of our visual tokens with textual semantics enables seamless\nintegration with pretrained diffusion decoders, supporting high-quality visual\nsynthesis with minimal adaptation. UniCode^2 delivers strong performance across\ndiverse benchmarks, demonstrating the viability of scaling visual token spaces\nwithout sacrificing stability, semantics, or modularity.", "comment": "19 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2506.20214v2", "cate": "cs.CV", "date": "2025-06-25", "updated": "2025-07-08"}
{"id": "2506.21116", "title": "IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes", "authors": ["Yujia Liang", "Jile Jiao", "Xuetao Feng", "Zixuan Ye", "Yuan Wang", "Zhicheng Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.21116v2", "summary": "Video Large Language Models (VideoLLMs) have demonstrated remarkable\nunderstanding capabilities, but are found struggling to tackle multi-shot\nscenarios,e.g., video clips with varying camera angles or scene changes. This\nchallenge can render failures such as instance identity forgetting and key\nframe negligence. In this work, we first attribute the challenge to the lack of\nmulti-shot annotations among existing datasets and therefore we introduce a new\ndataset termed MultiClip-Bench, featuring dense descriptions and\ninstruction-based question-answering pairs tailored for multi-shot scenarios.\nWe empirically find that the training set significantly boosts the multi-shot\nperformance, while the testing benchmark provides a reliable measure of the\nmodel capability in multi-shot scenarios. By further analyzing and discovering\nthat current models only encode instance features in a discrete or lossy\nmanner, at the risk of missing identity information, we then contribute a new\nmodel IPFormer-VideoLLM. Its key idea is the injection of instance-level\nfeatures as instance prompts through an efficient attention-based connector.\nThis allows for the aggregation of instance-specific information across scenes.\nExperiments demonstrate that our proposed dataset and model not only enhance\nthe multi-scene video understanding significantly, but also offer distinct\nadvantages across various video benchmarks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.21116v2", "cate": "cs.CV", "date": "2025-06-26", "updated": "2025-07-08"}
{"id": "2502.06816", "title": "DeepCell: Self-Supervised Multiview Fusion for Circuit Representation Learning", "authors": ["Zhengyuan Shi", "Chengyu Ma", "Ziyang Zheng", "Lingfeng Zhou", "Hongyang Pan", "Wentao Jiang", "Fan Yang", "Xiaoyan Yang", "Zhufei Chu", "Qiang Xu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.06816v2", "summary": "We introduce DeepCell, a novel circuit representation learning framework that\neffectively integrates multiview information from both And-Inverter Graphs\n(AIGs) and Post-Mapping (PM) netlists. At its core, DeepCell employs a\nself-supervised Mask Circuit Modeling (MCM) strategy, inspired by masked\nlanguage modeling, to fuse complementary circuit representations from different\ndesign stages into unified and rich embeddings. To our knowledge, DeepCell is\nthe first framework explicitly designed for PM netlist representation learning,\nsetting new benchmarks in both predictive accuracy and reconstruction quality.\nWe demonstrate the practical efficacy of DeepCell by applying it to critical\nEDA tasks such as functional Engineering Change Orders (ECO) and technology\nmapping. Extensive experimental results show that DeepCell significantly\nsurpasses state-of-the-art open-source EDA tools in efficiency and performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.06816v2", "cate": "cs.LG", "date": "2025-02-05", "updated": "2025-07-08"}
{"id": "2506.22099", "title": "BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve Gaussian Splatting", "authors": ["Zipei Ma", "Junzhe Jiang", "Yurui Chen", "Li Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025, Project Page: this https URL", "url": "http://arxiv.org/abs/2506.22099v3", "summary": "The realistic reconstruction of street scenes is critical for developing\nreal-world simulators in autonomous driving. Most existing methods rely on\nobject pose annotations, using these poses to reconstruct dynamic objects and\nmove them during the rendering process. This dependence on high-precision\nobject annotations limits large-scale and extensive scene reconstruction. To\naddress this challenge, we propose B\\'ezier curve Gaussian splatting\n(B\\'ezierGS), which represents the motion trajectories of dynamic objects using\nlearnable B\\'ezier curves. This approach fully leverages the temporal\ninformation of dynamic objects and, through learnable curve modeling,\nautomatically corrects pose errors. By introducing additional supervision on\ndynamic object rendering and inter-curve consistency constraints, we achieve\nreasonable and accurate separation and reconstruction of scene elements.\nExtensive experiments on the Waymo Open Dataset and the nuPlan benchmark\ndemonstrate that B\\'ezierGS outperforms state-of-the-art alternatives in both\ndynamic and static scene components reconstruction and novel view synthesis.", "comment": "Accepted at ICCV 2025, Project Page:\n  https://github.com/fudan-zvg/BezierGS", "pdf_url": "http://arxiv.org/pdf/2506.22099v3", "cate": "cs.CV", "date": "2025-06-27", "updated": "2025-07-08"}
{"id": "2502.08696", "title": "Scalable Discrete Diffusion Samplers: Combinatorial Optimization and Statistical Physics", "authors": ["Sebastian Sanokowski", "Wilhelm Berghammer", "Martin Ennemoser", "Haoyu Peter Wang", "Sepp Hochreiter", "Sebastian Lehner"], "categories": ["cs.LG", "cond-mat.stat-mech", "cs.AI", "physics.comp-ph", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at ICLR 2025", "url": "http://arxiv.org/abs/2502.08696v3", "summary": "Learning to sample from complex unnormalized distributions over discrete\ndomains emerged as a promising research direction with applications in\nstatistical physics, variational inference, and combinatorial optimization.\nRecent work has demonstrated the potential of diffusion models in this domain.\nHowever, existing methods face limitations in memory scaling and thus the\nnumber of attainable diffusion steps since they require backpropagation through\nthe entire generative process. To overcome these limitations we introduce two\nnovel training methods for discrete diffusion samplers, one grounded in the\npolicy gradient theorem and the other one leveraging Self-Normalized Neural\nImportance Sampling (SN-NIS). These methods yield memory-efficient training and\nachieve state-of-the-art results in unsupervised combinatorial optimization.\nNumerous scientific applications additionally require the ability of unbiased\nsampling. We introduce adaptations of SN-NIS and Neural Markov Chain Monte\nCarlo that enable for the first time the application of discrete diffusion\nmodels to this problem. We validate our methods on Ising model benchmarks and\nfind that they outperform popular autoregressive approaches. Our work opens new\navenues for applying diffusion models to a wide range of scientific\napplications in discrete domains that were hitherto restricted to exact\nlikelihood models.", "comment": "Accepted at ICLR 2025", "pdf_url": "http://arxiv.org/pdf/2502.08696v3", "cate": "cs.LG", "date": "2025-02-12", "updated": "2025-07-08"}
{"id": "2507.00825", "title": "High-Frequency Semantics and Geometric Priors for End-to-End Detection Transformers in Challenging UAV Imagery", "authors": ["Hongxing Peng", "Lide Chen", "Hui Zhu", "Yan Chen"], "categories": ["cs.CV", "I.2.10; I.4.8; I.5.1"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      14 pages, 9 figures, to appear in KBS", "url": "http://arxiv.org/abs/2507.00825v2", "summary": "Unmanned Aerial Vehicle-based Object Detection (UAV-OD) faces substantial\nchallenges, including small target sizes, high-density distributions, and\ncluttered backgrounds in UAV imagery. Current algorithms often depend on\nhand-crafted components like anchor boxes, which demand fine-tuning and exhibit\nlimited generalization, and Non-Maximum Suppression (NMS), which is\nthreshold-sensitive and prone to misclassifying dense objects. These generic\narchitectures thus struggle to adapt to aerial imaging characteristics,\nresulting in performance limitations. Moreover, emerging end-to-end frameworks\nhave yet to effectively mitigate these aerial-specific challenges.To address\nthese issues, we propose HEGS-DETR, a comprehensively enhanced, real-time\nDetection Transformer framework tailored for UAVs. First, we introduce the\nHigh-Frequency Enhanced Semantics Network (HFESNet) as a novel backbone.\nHFESNet preserves critical high-frequency spatial details to extract robust\nsemantic features, thereby improving discriminative capability for small and\noccluded targets in complex backgrounds. Second, our Efficient Small Object\nPyramid (ESOP) strategy strategically fuses high-resolution feature maps with\nminimal computational overhead, significantly boosting small object detection.\nFinally, the proposed Selective Query Recollection (SQR) and Geometry-Aware\nPositional Encoding (GAPE) modules enhance the detector's decoder stability and\nlocalization accuracy, effectively optimizing bounding boxes and providing\nexplicit spatial priors for dense scenes. Experiments on the VisDrone dataset\ndemonstrate that HEGS-DETR achieves a 5.1% AP50 and 3.8% AP increase over the\nbaseline, while maintaining real-time speed and reducing parameter count by 4M.", "comment": "14 pages, 9 figures, to appear in KBS", "pdf_url": "http://arxiv.org/pdf/2507.00825v2", "cate": "cs.CV", "date": "2025-07-01", "updated": "2025-07-08"}
{"id": "2507.06189", "title": "DS@GT at CheckThat! 2025: Detecting Subjectivity via Transfer-Learning and Corrective Data Augmentation", "authors": ["Maximilian Heil", "Dionne Bang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06189v1", "summary": "This paper presents our submission to Task 1, Subjectivity Detection, of the\nCheckThat! Lab at CLEF 2025. We investigate the effectiveness of\ntransfer-learning and stylistic data augmentation to improve classification of\nsubjective and objective sentences in English news text. Our approach contrasts\nfine-tuning of pre-trained encoders and transfer-learning of fine-tuned\ntransformer on related tasks. We also introduce a controlled augmentation\npipeline using GPT-4o to generate paraphrases in predefined subjectivity\nstyles. To ensure label and style consistency, we employ the same model to\ncorrect and refine the generated samples. Results show that transfer-learning\nof specified encoders outperforms fine-tuning general-purpose ones, and that\ncarefully curated augmentation significantly enhances model robustness,\nespecially in detecting subjective content. Our official submission placed us\n$16^{th}$ of 24 participants. Overall, our findings underscore the value of\ncombining encoder specialization with label-consistent augmentation for\nimproved subjectivity detection. Our code is available at\nhttps://github.com/dsgt-arc/checkthat-2025-subject.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06189v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2502.12086", "title": "Unifying Explainable Anomaly Detection and Root Cause Analysis in Dynamical Systems", "authors": ["Yue Sun", "Rick S. Blum", "Parv Venkitasubramaniam"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by the AAAI-25 Workshop on Artificial Intelligence for Cyber Security (AICS)", "url": "http://arxiv.org/abs/2502.12086v2", "summary": "Dynamical systems, prevalent in various scientific and engineering domains,\nare susceptible to anomalies that can significantly impact their performance\nand reliability. This paper addresses the critical challenges of anomaly\ndetection, root cause localization, and anomaly type classification in\ndynamical systems governed by ordinary differential equations (ODEs). We define\ntwo categories of anomalies: cyber anomalies, which propagate through\ninterconnected variables, and measurement anomalies, which remain localized to\nindividual variables. To address these challenges, we propose the Interpretable\nCausality Ordinary Differential Equation (ICODE) Networks, a model-intrinsic\nexplainable learning framework. ICODE leverages Neural ODEs for anomaly\ndetection while employing causality inference through an explanation channel to\nperform root cause analysis (RCA), elucidating why specific time periods are\nflagged as anomalous. ICODE is designed to simultaneously perform anomaly\ndetection, RCA, and anomaly type classification within a single, interpretable\nframework. Our approach is grounded in the hypothesis that anomalies alter the\nunderlying ODEs of the system, manifesting as changes in causal relationships\nbetween variables. We provide a theoretical analysis of how perturbations in\nlearned model parameters can be utilized to identify anomalies and their root\ncauses in time series data. Comprehensive experimental evaluations demonstrate\nthe efficacy of ICODE across various dynamical systems, showcasing its ability\nto accurately detect anomalies, classify their types, and pinpoint their\norigins.", "comment": "Accepted by the AAAI-25 Workshop on Artificial Intelligence for Cyber\n  Security (AICS)", "pdf_url": "http://arxiv.org/pdf/2502.12086v2", "cate": "cs.LG", "date": "2025-02-17", "updated": "2025-07-08"}
{"id": "2507.01722", "title": "When Does Pruning Benefit Vision Representations?", "authors": ["Enrico Cassano", "Riccardo Renzulli", "Andrea Bragagnolo", "Marco Grangetto"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at the 23rd International Conference on Image Analysis and Processing (ICIAP 2025)", "url": "http://arxiv.org/abs/2507.01722v3", "summary": "Pruning is widely used to reduce the complexity of deep learning models, but\nits effects on interpretability and representation learning remain poorly\nunderstood. This paper investigates how pruning influences vision models across\nthree key dimensions: (i) interpretability, (ii) unsupervised object discovery,\nand (iii) alignment with human perception. We first analyze different vision\nnetwork architectures to examine how varying sparsity levels affect feature\nattribution interpretability methods. Additionally, we explore whether pruning\npromotes more succinct and structured representations, potentially improving\nunsupervised object discovery by discarding redundant information while\npreserving essential features. Finally, we assess whether pruning enhances the\nalignment between model representations and human perception, investigating\nwhether sparser models focus on more discriminative features similarly to\nhumans. Our findings also reveal the presence of sweet spots, where sparse\nmodels exhibit higher interpretability, downstream generalization and human\nalignment. However, these spots highly depend on the network architectures and\ntheir size in terms of trainable parameters. Our results suggest a complex\ninterplay between these three dimensions, highlighting the importance of\ninvestigating when and how pruning benefits vision representations.", "comment": "Accepted at the 23rd International Conference on Image Analysis and\n  Processing (ICIAP 2025)", "pdf_url": "http://arxiv.org/pdf/2507.01722v3", "cate": "cs.CV", "date": "2025-07-02", "updated": "2025-07-08"}
{"id": "2502.14583", "title": "A Theory for Conditional Generative Modeling on Multiple Data Sources", "authors": ["Rongzhen Wang", "Yan Zhang", "Chenyu Zheng", "Chongxuan Li", "Guoqiang Wu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      37 pages", "url": "http://arxiv.org/abs/2502.14583v2", "summary": "The success of large generative models has driven a paradigm shift,\nleveraging massive multi-source data to enhance model capabilities. However,\nthe interaction among these sources remains theoretically underexplored. This\npaper takes the first step toward a rigorous analysis of multi-source training\nin conditional generative modeling, where each condition represents a distinct\ndata source. Specifically, we establish a general distribution estimation error\nbound in average total variation distance for conditional maximum likelihood\nestimation based on the bracketing number. Our result shows that when source\ndistributions share certain similarities and the model is expressive enough,\nmulti-source training guarantees a sharper bound than single-source training.\nWe further instantiate the general theory on conditional Gaussian estimation\nand deep generative models including autoregressive and flexible energy-based\nmodels, by characterizing their bracketing numbers. The results highlight that\nthe number of sources and similarity among source distributions improve the\nadvantage of multi-source training. Simulations and real-world experiments are\nconducted to validate the theory, with code available at:\nhttps://github.com/ML-GSAI/Multi-Source-GM.", "comment": "37 pages", "pdf_url": "http://arxiv.org/pdf/2502.14583v2", "cate": "cs.LG", "date": "2025-02-20", "updated": "2025-07-08"}
{"id": "2507.01882", "title": "Future Slot Prediction for Unsupervised Object Discovery in Surgical Video", "authors": ["Guiqiu Liao", "Matjaz Jogan", "Marcel Hussing", "Edward Zhang", "Eric Eaton", "Daniel A. Hashimoto"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by MICCAI2025", "url": "http://arxiv.org/abs/2507.01882v2", "summary": "Object-centric slot attention is an emerging paradigm for unsupervised\nlearning of structured, interpretable object-centric representations (slots).\nThis enables effective reasoning about objects and events at a low\ncomputational cost and is thus applicable to critical healthcare applications,\nsuch as real-time interpretation of surgical video. The heterogeneous scenes in\nreal-world applications like surgery are, however, difficult to parse into a\nmeaningful set of slots. Current approaches with an adaptive slot count perform\nwell on images, but their performance on surgical videos is low. To address\nthis challenge, we propose a dynamic temporal slot transformer (DTST) module\nthat is trained both for temporal reasoning and for predicting the optimal\nfuture slot initialization. The model achieves state-of-the-art performance on\nmultiple surgical databases, demonstrating that unsupervised object-centric\nmethods can be applied to real-world data and become part of the common arsenal\nin healthcare applications.", "comment": "Accepted by MICCAI2025", "pdf_url": "http://arxiv.org/pdf/2507.01882v2", "cate": "cs.CV", "date": "2025-07-02", "updated": "2025-07-08"}
{"id": "2502.16548", "title": "Composable Strategy Framework with Integrated Video-Text based Large Language Models for Heart Failure Assessment", "authors": ["Jianzhou Chen", "Jinyang Sun", "Xiumei Wang", "Xi Chen", "Heyu Chu", "Guo Song", "Yuji Luo", "Xingping Zhou", "Rong Gu"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.16548v2", "summary": "Heart failure is one of the leading causes of death worldwide, with millons\nof deaths each year, according to data from the World Health Organization (WHO)\nand other public health agencies. While significant progress has been made in\nthe field of heart failure, leading to improved survival rates and improvement\nof ejection fraction, there remains substantial unmet needs, due to the\ncomplexity and multifactorial characteristics. Therefore, we propose a\ncomposable strategy framework for assessment and treatment optimization in\nheart failure. This framework simulates the doctor-patient consultation process\nand leverages multi-modal algorithms to analyze a range of data, including\nvideo, physical examination, text results as well as medical history. By\nintegrating these various data sources, our framework offers a more holistic\nevaluation and optimized treatment plan for patients. Our results demonstrate\nthat this multi-modal approach outperforms single-modal artificial intelligence\n(AI) algorithms in terms of accuracy in heart failure (HF) prognosis\nprediction. Through this method, we can further evaluate the impact of various\npathological indicators on HF prognosis,providing a more comprehensive\nevaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.16548v2", "cate": "cs.LG", "date": "2025-02-23", "updated": "2025-07-08"}
{"id": "2507.02358", "title": "Hita: Holistic Tokenizer for Autoregressive Image Generation", "authors": ["Anlin Zheng", "Haochen Wang", "Yucheng Zhao", "Weipeng Deng", "Tiancai Wang", "Xiangyu Zhang", "Xiaojuan Qi"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 10 figures", "url": "http://arxiv.org/abs/2507.02358v3", "summary": "Vanilla autoregressive image generation models generate visual tokens\nstep-by-step, limiting their ability to capture holistic relationships among\ntoken sequences. Moreover, because most visual tokenizers map local image\npatches into latent tokens, global information is limited. To address this, we\nintroduce \\textit{Hita}, a novel image tokenizer for autoregressive (AR) image\ngeneration. It introduces a holistic-to-local tokenization scheme with\nlearnable holistic queries and local patch tokens. Hita incorporates two key\nstrategies to better align with the AR generation process: 1) {arranging} a\nsequential structure with holistic tokens at the beginning, followed by\npatch-level tokens, and using causal attention to maintain awareness of\nprevious tokens; and 2) adopting a lightweight fusion module before feeding the\nde-quantized tokens into the decoder to control information flow and prioritize\nholistic tokens. Extensive experiments show that Hita accelerates the training\nspeed of AR generators and outperforms those trained with vanilla tokenizers,\nachieving \\textbf{2.59 FID} and \\textbf{281.9 IS} on the ImageNet benchmark.\nDetailed analysis of the holistic representation highlights its ability to\ncapture global image properties, such as textures, materials, and shapes.\nAdditionally, Hita also demonstrates effectiveness in zero-shot style transfer\nand image in-painting. The code is available at\n\\href{https://github.com/CVMI-Lab/Hita}{https://github.com/CVMI-Lab/Hita}.", "comment": "17 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.02358v3", "cate": "cs.CV", "date": "2025-07-03", "updated": "2025-07-08"}
{"id": "2503.00030", "title": "RSPO: Regularized Self-Play Alignment of Large Language Models", "authors": ["Xiaohang Tang", "Sangwoong Yoon", "Seongho Son", "Huizhuo Yuan", "Quanquan Gu", "Ilija Bogunovic"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2503.00030v2", "summary": "Self-play alignment has emerged as an effective approach for fine-tuning\nlarge language models (LLMs), formulating preference optimization as a\ntwo-player game. However, the regularization with respect to the reference\npolicy, which is crucial for mitigating over-optimization, has been\ninsufficiently investigated in self-play alignment. To study the impact of\ndifferent regularization strategies, we propose \\textbf{Regularized Self-Play\nPolicy Optimization (RSPO)}, a general and modular framework that unifies prior\nmethods and enables simple plug-and-play integration of various regularizers,\nmeanwhile preserving convergence to Nash equilibrium of the corresponding\nregularized game.Our empirical study involving over $120$ fine-tuned\nMistral-7B-Instruct models reveals that forward KL divergence regularization\nreduces response length, whereas reverse KL divergence markedly improves raw\nwin rates. Crucially, RSPO regularized with a linear combination of forward and\nreverse KL divergence significantly boosts the length-controlled win rate on\nAlpacaEval-2 from $28.5\\%$ (unregularized self-play, SPPO) to $35.4\\%$, and\nconsistently demonstrates superior performance on Arena-Hard, MT-Bench, ArmoRM\nscores, and response diversity. Combining simplicity, convergence guarantees,\nand significant empirical gains, RSPO offers a strong foundation for exploring\nregularized self-play in language model alignment.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2503.00030v2", "cate": "cs.LG", "date": "2025-02-24", "updated": "2025-07-07"}
{"id": "2507.02395", "title": "Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis", "authors": ["Byung Hyun Lee", "Wongi Jeong", "Woojae Han", "Kyoungbun Lee", "Se Young Chun"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2507.02395v2", "summary": "Multiple instance learning (MIL) significantly reduced annotation costs via\nbag-level weak labels for large-scale images, such as histopathological whole\nslide images (WSIs). However, its adaptability to continual tasks with minimal\nforgetting has been rarely explored, especially on instance classification for\nlocalization. Weakly incremental learning for semantic segmentation has been\nstudied for continual localization, but it focused on natural images,\nleveraging global relationships among hundreds of small patches (e.g., $16\n\\times 16$) using pre-trained models. This approach seems infeasible for MIL\nlocalization due to enormous amounts ($\\sim 10^5$) of large patches (e.g., $256\n\\times 256$) and no available global relationships such as cancer cells. To\naddress these challenges, we propose Continual Multiple Instance Learning with\nEnhanced Localization (CoMEL), an MIL framework for both localization and\nadaptability with minimal forgetting. CoMEL consists of (1) Grouped Double\nAttention Transformer (GDAT) for efficient instance encoding, (2) Bag\nPrototypes-based Pseudo-Labeling (BPPL) for reliable instance pseudo-labeling,\nand (3) Orthogonal Weighted Low-Rank Adaptation (OWLoRA) to mitigate forgetting\nin both bag and instance classification. Extensive experiments on three public\nWSI datasets demonstrate superior performance of CoMEL, outperforming the prior\narts by up to $11.00\\%$ in bag-level accuracy and up to $23.4\\%$ in\nlocalization accuracy under the continual MIL setup.", "comment": "Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.02395v2", "cate": "cs.CV", "date": "2025-07-03", "updated": "2025-07-08"}
{"id": "2503.05893", "title": "Zero-shot Medical Event Prediction Using a Generative Pre-trained Transformer on Electronic Health Records", "authors": ["Ekaterina Redekop", "Zichen Wang", "Rushikesh Kulkarni", "Mara Pleasure", "Aaron Chin", "Hamid Reza Hassanzadeh", "Brian L. Hill", "Melika Emami", "William Speier", "Corey W. Arnold"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.05893v2", "summary": "Longitudinal data in electronic health records (EHRs) represent an\nindividual`s clinical history through a sequence of codified concepts,\nincluding diagnoses, procedures, medications, and laboratory tests. Generative\npre-trained transformers (GPT) can leverage this data to predict future events.\nWhile fine-tuning of these models can enhance task-specific performance, it\nbecomes costly when applied to many clinical prediction tasks. In contrast, a\npretrained foundation model can be used in zero-shot forecasting setting,\noffering a scalable alternative to fine-tuning separate models for each\noutcome.\n  This study presents the first comprehensive analysis of zero-shot forecasting\nwith GPT-based foundational models in EHRs, introducing a novel pipeline that\nformulates medical concept prediction as a generative modeling task. Unlike\nsupervised approaches requiring extensive labeled data, our method enables the\nmodel to forecast a next medical event purely from a pretraining knowledge. We\nevaluate performance across multiple time horizons and clinical categories,\ndemonstrating model`s ability to capture latent temporal dependencies and\ncomplex patient trajectories without task supervision.\n  Model performance for predicting the next medical concept was evaluated using\nprecision and recall metrics, achieving an average top1 precision of 0.614 and\nrecall of 0.524. For 12 major diagnostic conditions, the model demonstrated\nstrong zero-shot performance, achieving high true positive rates while\nmaintaining low false positives.\n  We demonstrate the power of a foundational EHR GPT model in capturing diverse\nphenotypes and enabling robust, zero-shot forecasting of clinical outcomes.\nThis capability enhances the versatility of predictive healthcare models and\nreduces the need for task-specific training, enabling more scalable\napplications in clinical settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.05893v2", "cate": "cs.LG", "date": "2025-03-07", "updated": "2025-07-07"}
{"id": "2507.02792", "title": "RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation", "authors": ["Liheng Zhang", "Lexi Pang", "Hang Ye", "Xiaoxuan Ma", "Yizhou Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2406.07540 by other authors", "url": "http://arxiv.org/abs/2507.02792v2", "summary": "Text-to-image (T2I) diffusion models have shown remarkable success in\ngenerating high-quality images from text prompts. Recent efforts extend these\nmodels to incorporate conditional images (e.g., depth or pose maps) for\nfine-grained spatial control. Among them, feature injection methods have\nemerged as a training-free alternative to traditional fine-tuning approaches.\nHowever, they often suffer from structural misalignment, condition leakage, and\nvisual artifacts, especially when the condition image diverges significantly\nfrom natural RGB distributions. By revisiting existing methods, we identify a\ncore limitation: the synchronous injection of condition features fails to\naccount for the trade-off between domain alignment and structural preservation\nduring denoising. Inspired by this observation, we propose a flexible feature\ninjection framework that decouples the injection timestep from the denoising\nprocess. At its core is a structure-rich injection module, which enables the\nmodel to better adapt to the evolving interplay between alignment and structure\npreservation throughout the diffusion steps, resulting in more faithful\nstructural generation. In addition, we introduce appearance-rich prompting and\na restart refinement strategy to further enhance appearance control and visual\nquality. Together, these designs enable training-free generation that is both\nstructure-rich and appearance-rich. Extensive experiments show that our\napproach achieves state-of-the-art performance across diverse zero-shot\nconditioning scenarios.", "comment": "arXiv admin note: text overlap with arXiv:2406.07540 by other authors", "pdf_url": "http://arxiv.org/pdf/2507.02792v2", "cate": "cs.CV", "date": "2025-07-03", "updated": "2025-07-08"}
{"id": "2503.13575", "title": "Analytic Subspace Routing: How Recursive Least Squares Works in Continual Learning of Large Language Model", "authors": ["Kai Tong", "Kang Pan", "Xiao Zhang", "Erli Meng", "Run He", "Yawen Cui", "Nuoyan Guo", "Huiping Zhuang"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 4 figures", "url": "http://arxiv.org/abs/2503.13575v2", "summary": "Large Language Models (LLMs) possess encompassing capabilities that can\nprocess diverse language-related tasks. However, finetuning on LLMs will\ndiminish this general skills and continual finetuning will further cause severe\ndegradation on accumulated knowledge. Recently, Continual Learning (CL) in\nLarge Language Models (LLMs) arises which aims to continually adapt the LLMs to\nnew tasks while maintaining previously learned knowledge and inheriting general\nskills. Existing techniques either leverage previous data to replay, leading to\nextra computational costs, or utilize a single parameter-efficient module to\nlearn the downstream task, constraining new knowledge absorption with\ninterference between different tasks. Toward these issues, this paper proposes\nAnalytic Subspace Routing(ASR) to address these challenges. For each task, we\nisolate the learning within a subspace of deep layers' features via low-rank\nadaptation, eliminating knowledge interference between different tasks.\nAdditionally, we propose an analytic routing mechanism to properly utilize\nknowledge learned in different subspaces. Our approach employs Recursive Least\nSquares to train a multi-task router model, allowing the router to dynamically\nadapt to incoming data without requiring access to historical data. Also, the\nrouter effectively assigns the current task to an appropriate subspace and has\na non-forgetting property of previously learned tasks with a solid theoretical\nguarantee. Experimental results demonstrate that our method achieves\nnear-perfect retention of prior knowledge while seamlessly integrating new\ninformation, effectively overcoming the core limitations of existing methods.\nOur code will be released after acceptance.", "comment": "11 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2503.13575v2", "cate": "cs.LG", "date": "2025-03-17", "updated": "2025-07-08"}
{"id": "2504.01531", "title": "DRAN: A Distribution and Relation Adaptive Network for Spatio-temporal Forecasting", "authors": ["Xiaobei Zou", "Luolin Xiong", "Kexuan Zhang", "Cesare Alippi", "Yang Tang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages, 10 figures", "url": "http://arxiv.org/abs/2504.01531v2", "summary": "Accurate predictions of spatio-temporal systems are crucial for tasks such as\nsystem management, control, and crisis prevention. However, the inherent time\nvariance of many spatio-temporal systems poses challenges to achieving accurate\npredictions whenever stationarity is not granted. In order to address\nnon-stationarity, we propose a Distribution and Relation Adaptive Network\n(DRAN) capable of dynamically adapting to relation and distribution changes\nover time. While temporal normalization and de-normalization are frequently\nused techniques to adapt to distribution shifts, this operation is not suitable\nfor the spatio-temporal context as temporal normalization scales the time\nseries of nodes and possibly disrupts the spatial relations among nodes. In\norder to address this problem, a Spatial Factor Learner (SFL) module is\ndeveloped that enables the normalization and de-normalization process. To adapt\nto dynamic changes in spatial relationships among sensors, we propose a\nDynamic-Static Fusion Learner (DSFL) module that effectively integrates\nfeatures learned from both dynamic and static relations through an adaptive\nfusion ratio mechanism. Furthermore, we introduce a Stochastic Learner to\ncapture the noisy components of spatio-temporal representations. Our approach\noutperforms state-of-the-art methods on weather prediction and traffic flow\nforecasting tasks.Experimental results show that our SFL efficiently preserves\nspatial relationships across various temporal normalization operations.\nVisualizations of the learned dynamic and static relations demonstrate that\nDSFL can capture both local and distant relationships between nodes.", "comment": "15 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2504.01531v2", "cate": "cs.LG", "date": "2025-04-02", "updated": "2025-07-08"}
{"id": "2507.06229", "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving", "authors": ["Xiangru Tang", "Tianrui Qin", "Tianhao Peng", "Ziyang Zhou", "Daniel Shao", "Tingting Du", "Xinming Wei", "Peng Xia", "Fang Wu", "He Zhu", "Ge Zhang", "Jiaheng Liu", "Xingyao Wang", "Sirui Hong", "Chenglin Wu", "Hao Cheng", "Chi Wang", "Wangchunshu Zhou"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06229v1", "summary": "As language agents tackle increasingly complex tasks, they struggle with\neffective error correction and experience reuse across domains. We introduce\nAgent KB, a hierarchical experience framework that enables complex agentic\nproblem solving via a novel Reason-Retrieve-Refine pipeline. Agent KB addresses\na core limitation: agents traditionally cannot learn from each other's\nexperiences. By capturing both high-level strategies and detailed execution\nlogs, Agent KB creates a shared knowledge base that enables cross-agent\nknowledge transfer. Evaluated on the GAIA benchmark, Agent KB improves success\nrates by up to 16.28 percentage points. On the most challenging tasks, Claude-3\nimproves from 38.46% to 57.69%, while GPT-4 improves from 53.49% to 73.26% on\nintermediate tasks. On SWE-bench code repair, Agent KB enables Claude-3 to\nimprove from 41.33% to 53.33%. Our results suggest that Agent KB provides a\nmodular, framework-agnostic infrastructure for enabling agents to learn from\npast experiences and generalize successful strategies to new tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06229v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2504.06048", "title": "Trust-Region Twisted Policy Improvement", "authors": ["Joery A. de Vries", "Jinke He", "Yaniv Oren", "Matthijs T. J. Spaan"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Poster at ICML2025", "url": "http://arxiv.org/abs/2504.06048v4", "summary": "Monte-Carlo tree search (MCTS) has driven many recent breakthroughs in deep\nreinforcement learning (RL). However, scaling MCTS to parallel compute has\nproven challenging in practice which has motivated alternative planners like\nsequential Monte-Carlo (SMC). Many of these SMC methods adopt particle filters\nfor smoothing through a reformulation of RL as a policy inference problem. Yet,\npersisting design choices of these particle filters often conflict with the aim\nof online planning in RL, which is to obtain a policy improvement at the start\nof planning. Drawing inspiration from MCTS, we tailor SMC planners specifically\nfor RL by improving data generation within the planner through constrained\naction sampling and explicit terminal state handling, as well as improving\npolicy and value target estimation. This leads to our Trust-Region Twisted SMC\n(TRT-SMC), which shows improved runtime and sample-efficiency over baseline\nMCTS and SMC methods in both discrete and continuous domains.", "comment": "Poster at ICML2025", "pdf_url": "http://arxiv.org/pdf/2504.06048v4", "cate": "cs.LG", "date": "2025-04-08", "updated": "2025-07-08"}
{"id": "2507.03532", "title": "PhenoBench: A Comprehensive Benchmark for Cell Phenotyping", "authors": ["Jerome Luescher", "Nora Koreuber", "Jannik Franzen", "Fabian H. Reith", "Claudia Winklmayr", "Elias Baumann", "Christian M. Schuerch", "Dagmar Kainmueller", "Josef Lorenz Rumberger"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted for presentation at MICCAI 2025", "url": "http://arxiv.org/abs/2507.03532v2", "summary": "Digital pathology has seen the advent of a wealth of foundational models\n(FM), yet to date their performance on cell phenotyping has not been\nbenchmarked in a unified manner. We therefore propose PhenoBench: A\ncomprehensive benchmark for cell phenotyping on Hematoxylin and Eosin (H&E)\nstained histopathology images. We provide both PhenoCell, a new H&E dataset\nfeaturing 14 granular cell types identified by using multiplexed imaging, and\nready-to-use fine-tuning and benchmarking code that allows the systematic\nevaluation of multiple prominent pathology FMs in terms of dense cell phenotype\npredictions in different generalization scenarios. We perform extensive\nbenchmarking of existing FMs, providing insights into their generalization\nbehavior under technical vs. medical domain shifts. Furthermore, while FMs\nachieve macro F1 scores > 0.70 on previously established benchmarks such as\nLizard and PanNuke, on PhenoCell, we observe scores as low as 0.20. This\nindicates a much more challenging task not captured by previous benchmarks,\nestablishing PhenoCell as a prime asset for future benchmarking of FMs and\nsupervised models alike. Code and data are available on GitHub.", "comment": "accepted for presentation at MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.03532v2", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2306.07126", "title": "Argumentative Characterizations of (Extended) Disjunctive Logic Programs", "authors": ["Jesse Heyninck", "Ofer Arieli"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Under consideration in Theory and Practice of Logic Programming (TPLP)", "url": "http://arxiv.org/abs/2306.07126v2", "summary": "This paper continues an established line of research about the relations\nbetween argumentation theory, particularly assumption-based argumentation, and\ndifferent kinds of logic programs. In particular, we extend known result of\nCaminada, Schultz and Toni by showing that assumption-based argumentation can\nrepresent not only normal logic programs, but also disjunctive logic programs\nand their extensions. For this, we consider some inference rules for\ndisjunction that the core logic of the argumentation frameworks should respect,\nand show the correspondence to the handling of disjunctions in the heads of the\nlogic programs' rules. Under consideration in Theory and Practice of Logic\nProgramming (TPLP).", "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "pdf_url": "http://arxiv.org/pdf/2306.07126v2", "cate": "cs.AI", "date": "2023-06-12", "updated": "2025-07-08"}
{"id": "2504.11364", "title": "Offline Learning and Forgetting for Reasoning with Large Language Models", "authors": ["Tianwei Ni", "Allen Nie", "Sapana Chaudhary", "Yao Liu", "Huzefa Rangwala", "Rasool Fakoor"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Code: this https URL", "url": "http://arxiv.org/abs/2504.11364v3", "summary": "Leveraging inference-time search in large language models has proven\neffective in further enhancing a trained model's capability to solve complex\nmathematical and reasoning problems. However, this approach significantly\nincreases computational costs and inference time, as the model must generate\nand evaluate multiple candidate solutions to identify a viable reasoning path.\nTo address this, we propose an effective approach that integrates search\ncapabilities directly into the model by fine-tuning it on unpaired successful\n(learning) and failed reasoning paths (forgetting) derived from diverse search\nmethods. A key challenge we identify is that naive fine-tuning can degrade the\nmodel's search capability; we show this can be mitigated with a smaller\nlearning rate. Extensive experiments on the challenging Game-of-24 and\nCountdown reasoning benchmarks show that, replacing CoT-generated data with\nsearch-generated data for offline fine-tuning improves success rates by around\n23% over inference-time search baselines, while reducing inference time by\n180$\\times$. On top of this, our learning and forgetting objective consistently\noutperforms both supervised fine-tuning and preference-based methods.", "comment": "Code: https://github.com/twni2016/llm-reasoning-uft", "pdf_url": "http://arxiv.org/pdf/2504.11364v3", "cate": "cs.LG", "date": "2025-04-15", "updated": "2025-07-08"}
{"id": "2507.03633", "title": "From Video to EEG: Adapting Joint Embedding Predictive Architecture to Uncover Visual Concepts in Brain Signal Analysis", "authors": ["Amirabbas Hojjati", "Lu Li", "Ibrahim Hameed", "Anis Yazidi", "Pedro G. Lind", "Rabindra Khadka"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03633v2", "summary": "EEG signals capture brain activity with high temporal and low spatial\nresolution, supporting applications such as neurological diagnosis, cognitive\nmonitoring, and brain-computer interfaces. However, effective analysis is\nhindered by limited labeled data, high dimensionality, and the absence of\nscalable models that fully capture spatiotemporal dependencies. Existing\nself-supervised learning (SSL) methods often focus on either spatial or\ntemporal features, leading to suboptimal representations. To this end, we\npropose EEG-VJEPA, a novel adaptation of the Video Joint Embedding Predictive\nArchitecture (V-JEPA) for EEG classification. By treating EEG as video-like\nsequences, EEG-VJEPA learns semantically meaningful spatiotemporal\nrepresentations using joint embeddings and adaptive masking. To our knowledge,\nthis is the first work that exploits V-JEPA for EEG classification and explores\nthe visual concepts learned by the model. Evaluations on the publicly available\nTemple University Hospital (TUH) Abnormal EEG dataset show that EEG-VJEPA\noutperforms existing state-of-the-art models in classification accuracy.Beyond\nclassification accuracy, EEG-VJEPA captures physiologically relevant spatial\nand temporal signal patterns, offering interpretable embeddings that may\nsupport human-AI collaboration in diagnostic workflows. These findings position\nEEG-VJEPA as a promising framework for scalable, trustworthy EEG analysis in\nreal-world clinical settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03633v2", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2410.02892", "title": "The Role of Deductive and Inductive Reasoning in Large Language Models", "authors": ["Chengkun Cai", "Xu Zhao", "Haoliang Liu", "Zhongyu Jiang", "Tianfang Zhang", "Zongkai Wu", "Jenq-Neng Hwang", "Lei Li"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      4 figures, accept at ACL2025 Main", "url": "http://arxiv.org/abs/2410.02892v3", "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nreasoning tasks, yet their reliance on static prompt structures and limited\nadaptability to complex scenarios remains a significant challenge. In this\npaper, we propose the Deductive and InDuctive(DID) method, a novel framework\nthat enhances LLM reasoning by dynamically integrating both deductive and\ninductive reasoning approaches. Drawing from cognitive science principles, DID\nimplements a dual-metric complexity evaluation system that combines Littlestone\ndimension and information entropy to precisely assess task difficulty and guide\ndecomposition strategies. DID enables the model to progressively adapt its\nreasoning pathways based on problem complexity, mirroring human cognitive\nprocesses. We evaluate DID's effectiveness across multiple benchmarks,\nincluding the AIW and MR-GSM8K, as well as our custom Holiday Puzzle dataset\nfor temporal reasoning. Our results demonstrate significant improvements in\nreasoning quality and solution accuracy - achieving 70.3% accuracy on AIW\n(compared to 62.2% for Tree of Thought) while maintaining lower computational\ncosts. The success of DID in improving LLM performance while preserving\ncomputational efficiency suggests promising directions for developing more\ncognitively aligned and capable language models. Our work contributes a\ntheoretically grounded, input-centric approach to enhancing LLM reasoning\ncapabilities, offering an efficient alternative to traditional\noutput-exploration methods.", "comment": "4 figures, accept at ACL2025 Main", "pdf_url": "http://arxiv.org/pdf/2410.02892v3", "cate": "cs.AI", "date": "2024-10-03", "updated": "2025-07-07"}
{"id": "2504.14569", "title": "NoWag: A Unified Framework for Shape Preserving Compression of Large Language Models", "authors": ["Lawrence Liu", "Inesh Chakrabarti", "Yixiao Li", "Mengdi Wang", "Tuo Zhao", "Lin F. Yang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.14569v2", "summary": "Large language models (LLMs) exhibit remarkable performance across various\nnatural language processing tasks but suffer from immense computational and\nmemory demands, limiting their deployment in resource-constrained environments.\nTo address this challenge, we propose NoWag: (Normalized Weight and Activation\nGuided Compression), a unified framework for zero-shot shape preserving\ncompression algorithms. We compressed Llama-2 7B/13B/70B and Llama-3 8/70BB\nmodels, using two popular forms of shape-preserving compression, vector\nquantization NoWag-VQ (NoWag for Vector Quantization), and\nunstructured/semi-structured pruning NoWag-P (NoWag for Pruning). We found that\nNoWag-VQ significantly outperforms state-of-the-art zero shot VQ, and that\nNoWag-P performs competitively against state-of-the-art methods. These results\nsuggest commonalities between these compression paradigms that could inspire\nfuture work. Our code is available at https://github.com/LawrenceRLiu/NoWag", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.14569v2", "cate": "cs.LG", "date": "2025-04-20", "updated": "2025-07-08"}
{"id": "2501.18099", "title": "Learning to Plan & Reason for Evaluation with Thinking-LLM-as-a-Judge", "authors": ["Swarnadeep Saha", "Xian Li", "Marjan Ghazvininejad", "Jason Weston", "Tianlu Wang"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      ICML 2025", "url": "http://arxiv.org/abs/2501.18099v2", "summary": "LLM-as-a-Judge models generate chain-of-thought (CoT) sequences intended to\ncapture the step-bystep reasoning process that underlies the final evaluation\nof a response. However, due to the lack of human annotated CoTs for evaluation,\nthe required components and structure of effective reasoning traces remain\nunderstudied. Consequently, previous approaches often (1) constrain reasoning\ntraces to hand-designed components, such as a list of criteria, reference\nanswers, or verification questions and (2) structure them such that planning is\nintertwined with the reasoning for evaluation. In this work, we propose\nEvalPlanner, a preference optimization algorithm for Thinking-LLM-as-a-Judge\nthat first generates an unconstrained evaluation plan, followed by its\nexecution, and then the final judgment. In a self-training loop, EvalPlanner\niteratively optimizes over synthetically constructed evaluation plans and\nexecutions, leading to better final verdicts. Our method achieves a new\nstate-of-the-art performance for generative reward models on RewardBench (with\na score of 93.9), despite being trained on fewer amount of, and synthetically\ngenerated, preference pairs. Additional experiments on other benchmarks like\nRM-Bench, JudgeBench, and FollowBenchEval further highlight the utility of both\nplanning and reasoning for building robust LLM-as-a-Judge reasoning models.", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2501.18099v2", "cate": "cs.AI", "date": "2025-01-30", "updated": "2025-07-08"}
{"id": "2507.03990", "title": "LEHA-CVQAD: Dataset To Enable Generalized Video Quality Assessment of Compression Artifacts", "authors": ["Aleksandr Gushchin", "Maksim Smirnov", "Dmitriy Vatolin", "Anastasia Antsiferova"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03990v2", "summary": "We propose the LEHA-CVQAD (Large-scale Enriched Human-Annotated Compressed\nVideo Quality Assessment) dataset, which comprises 6,240 clips for\ncompression-oriented video quality assessment. 59 source videos are encoded\nwith 186 codec-preset variants, 1.8M pairwise, and 1.5k MOS ratings are fused\ninto a single quality scale; part of the videos remains hidden for blind\nevaluation. We also propose Rate-Distortion Alignment Error (RDAE), a novel\nevaluation metric that quantifies how well VQA models preserve bitrate-quality\nordering, directly supporting codec parameter tuning. Testing IQA/VQA methods\nreveals that popular VQA metrics exhibit high RDAE and lower correlations,\nunderscoring the dataset challenges and utility. The open part and the results\nof LEHA-CVQAD are available at https://aleksandrgushchin.github.io/lcvqad/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03990v2", "cate": "cs.CV", "date": "2025-07-05", "updated": "2025-07-08"}
{"id": "2502.00406", "title": "Agents Are All You Need for LLM Unlearning", "authors": ["Debdeep Sanyal", "Murari Mandal"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to COLM 2025", "url": "http://arxiv.org/abs/2502.00406v2", "summary": "Information removal or suppression in large language models (LLMs) is a\ndesired functionality, useful in AI regulation, legal compliance, safety, and\nprivacy. LLM unlearning methods aim to remove information on demand from LLMs.\nCurrent LLM unlearning methods struggle to balance the unlearning efficacy and\nutility due to the competing nature of these objectives. Keeping the unlearning\nprocess computationally feasible without assuming access to the model weights\nis an overlooked area. In this work we show that \\textit{agents might be all we\nneed for effective and practical inference-time LLM unlearning}. We present the\nfirst agentic LLM unlearning (\\texttt{ALU}) method, a multi-agent,\nretrain-free, model-agnostic approach to LLM unlearning that achieves effective\nunlearning while preserving the utility. Our \\texttt{ALU} framework unlearns by\ninvolving multiple LLM agents, each designed for a specific step in the\nunlearning process, without the need to update model weights for any of the\nagents in the framework. Users can easily request any set of unlearning\ninstances in any sequence, and \\texttt{ALU} seamlessly adapts in real time.\nThis is facilitated without requiring any changes in the underlying LLM model.\nThrough extensive experiments on established benchmarks (TOFU, WMDP, WPU) and\njailbreaking techniques (many shot, target masking, other languages), we\ndemonstrate that \\texttt{ALU} consistently stands out as the most robust\ninference-time LLM unlearning framework among current state-of-the-art methods\nwhile incurring time cost that remains effectively constant regardless of the\nnumber of unlearning targets. We further highlight \\texttt{ALU}'s superior\nperformance compared to existing methods when evaluated at scale. Specifically,\n\\texttt{ALU} is assessed on up to 1000 unlearning targets, exceeding the\nevaluation scope of all previously proposed LLM unlearning methods.", "comment": "Accepted to COLM 2025", "pdf_url": "http://arxiv.org/pdf/2502.00406v2", "cate": "cs.AI", "date": "2025-02-01", "updated": "2025-07-08"}
{"id": "2505.10482", "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "authors": ["Ningyuan Yang", "Jiaxuan Gao", "Feng Gao", "Yi Wu", "Chao Yu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages for main text, 23 pages in total, submitted to Neurips, 13 figures", "url": "http://arxiv.org/abs/2505.10482v3", "summary": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy.", "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures", "pdf_url": "http://arxiv.org/pdf/2505.10482v3", "cate": "cs.LG", "date": "2025-05-15", "updated": "2025-07-08"}
{"id": "2507.04243", "title": "Domain Generalizable Portrait Style Transfer", "authors": ["Xinbo Wang", "Wenju Xu", "Qing Zhang", "Wei-Shi Zheng"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV2025", "url": "http://arxiv.org/abs/2507.04243v2", "summary": "This paper presents a portrait style transfer method that generalizes well to\nvarious different domains while enabling high-quality semantic-aligned\nstylization on regions including hair, eyes, eyelashes, skins, lips, and\nbackground. To this end, we propose to establish dense semantic correspondence\nbetween the given input and reference portraits based on a pre-trained model\nand a semantic adapter, with which we obtain a warped reference semantically\naligned with the input. To ensure effective yet controllable style transfer, we\ndevise an AdaIN-Wavelet transform to balance content preservation and\nstylization by blending low-frequency information of the warped reference with\nhigh-frequency information of the input in the latent space. A style adapter is\nalso designed to provide style guidance from the warped reference. With the\nstylized latent from AdaIN-Wavelet transform, we employ a dual-conditional\ndiffusion model that integrates a ControlNet recording high-frequency\ninformation and the style guidance to generate the final result. Extensive\nexperiments demonstrate the superiority of our method. Our code and trained\nmodel are available at https://github.com/wangxb29/DGPST.", "comment": "Accepted to ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.04243v2", "cate": "cs.CV", "date": "2025-07-06", "updated": "2025-07-08"}
{"id": "2502.12961", "title": "Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger", "authors": ["Wenjun Li", "Dexun Li", "Kuicai Dong", "Cong Zhang", "Hao Zhang", "Weiwen Liu", "Yasheng Wang", "Ruiming Tang", "Yong Liu"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      25 pages, camera ready version for ACL-2025", "url": "http://arxiv.org/abs/2502.12961v2", "summary": "Large language models (LLMs) have shown remarkable emergent capabilities,\ntransforming the execution of functional tasks by leveraging external tools for\ncomplex problems that require specialized processing or up-to-date data. While\nexisting research expands LLMs access to diverse tools (e.g., program\ninterpreters, search engines, calculators), the necessity of using these tools\nis often overlooked, leading to indiscriminate tool invocation. This naive\napproach raises two key issues: increased latency due to unnecessary tool\ncalls, and potential errors resulting from faulty interactions with external\ntools. In this paper, we introduce meta-cognition as a proxy for LLMs\nself-assessment of their capabilities, reflecting the model's awareness of its\nown limitations. Based on this, we propose MeCo, an adaptive decision-making\nstrategy for external tool use. MeCo quantifies metacognitive scores by\ncapturing high-level cognitive signals in the representation space, guiding\nwhen to invoke tools. Notably, MeCo is fine-tuning-free and incurs minimal\ncost. Experiments across multiple backbone models and benchmarks show that MeCo\nreliably detects LLMs' internal cognitive signals and significantly improves\ntool-use decision-making.", "comment": "25 pages, camera ready version for ACL-2025", "pdf_url": "http://arxiv.org/pdf/2502.12961v2", "cate": "cs.AI", "date": "2025-02-18", "updated": "2025-07-08"}
{"id": "2505.11211", "title": "Bayesian Hierarchical Invariant Prediction", "authors": ["Francisco Madaleno", "Pernille Julie Viuff Sand", "Francisco C. Pereira", "Sergio Hernan Garrido Mejia"], "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.11211v2", "summary": "We propose Bayesian Hierarchical Invariant Prediction (BHIP) reframing\nInvariant Causal Prediction (ICP) through the lens of Hierarchical Bayes. We\nleverage the hierarchical structure to explicitly test invariance of causal\nmechanisms under heterogeneous data, resulting in improved computational\nscalability for a larger number of predictors compared to ICP. Moreover, given\nits Bayesian nature BHIP enables the use of prior information. In this paper,\nwe test two sparsity inducing priors: horseshoe and spike-and-slab, both of\nwhich allow us a more reliable identification of causal features. We test BHIP\nin synthetic and real-world data showing its potential as an alternative\ninference method to ICP.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.11211v2", "cate": "cs.LG", "date": "2025-05-16", "updated": "2025-07-08"}
{"id": "2507.04511", "title": "FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection", "authors": ["Xinhua Lu", "Runhe Lai", "Yanqi Wu", "Kanghao Chen", "Wei-Shi Zheng", "Ruixuan Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures, Accepted by ICCV2025", "url": "http://arxiv.org/abs/2507.04511v2", "summary": "Pre-trained vision-language models (VLMs) have advanced out-of-distribution\n(OOD) detection recently. However, existing CLIP-based methods often focus on\nlearning OOD-related knowledge to improve OOD detection, showing limited\ngeneralization or reliance on external large-scale auxiliary datasets. In this\nstudy, instead of delving into the intricate OOD-related knowledge, we propose\nan innovative CLIP-based framework based on Forced prompt leArning (FA),\ndesigned to make full use of the In-Distribution (ID) knowledge and ultimately\nboost the effectiveness of OOD detection. Our key insight is to learn a prompt\n(i.e., forced prompt) that contains more diversified and richer descriptions of\nthe ID classes beyond the textual semantics of class labels. Specifically, it\npromotes better discernment for ID images, by forcing more notable semantic\nsimilarity between ID images and the learnable forced prompt. Moreover, we\nintroduce a forced coefficient, encouraging the forced prompt to learn more\ncomprehensive and nuanced descriptions of the ID classes. In this way, FA is\ncapable of achieving notable improvements in OOD detection, even when trained\nwithout any external auxiliary datasets, while maintaining an identical number\nof trainable parameters as CoOp. Extensive empirical evaluations confirm our\nmethod consistently outperforms current state-of-the-art methods. Code is\navailable at https://github.com/0xFAFA/FA.", "comment": "12 pages, 4 figures, Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.04511v2", "cate": "cs.CV", "date": "2025-07-06", "updated": "2025-07-08"}
{"id": "2503.04392", "title": "AgentSafe: Safeguarding Large Language Model-based Multi-agent Systems via Hierarchical Data Management", "authors": ["Junyuan Mao", "Fanci Meng", "Yifan Duan", "Miao Yu", "Xiaojun Jia", "Junfeng Fang", "Yuxuan Liang", "Kun Wang", "Qingsong Wen"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.04392v2", "summary": "Large Language Model based multi-agent systems are revolutionizing autonomous\ncommunication and collaboration, yet they remain vulnerable to security threats\nlike unauthorized access and data breaches. To address this, we introduce\nAgentSafe, a novel framework that enhances MAS security through hierarchical\ninformation management and memory protection. AgentSafe classifies information\nby security levels, restricting sensitive data access to authorized agents.\nAgentSafe incorporates two components: ThreatSieve, which secures communication\nby verifying information authority and preventing impersonation, and\nHierarCache, an adaptive memory management system that defends against\nunauthorized access and malicious poisoning, representing the first systematic\ndefense for agent memory. Experiments across various LLMs show that AgentSafe\nsignificantly boosts system resilience, achieving defense success rates above\n80% under adversarial conditions. Additionally, AgentSafe demonstrates\nscalability, maintaining robust performance as agent numbers and information\ncomplexity grow. Results underscore effectiveness of AgentSafe in securing MAS\nand its potential for real-world application.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.04392v2", "cate": "cs.AI", "date": "2025-03-06", "updated": "2025-07-08"}
{"id": "2505.17670", "title": "Towards General Continuous Memory for Vision-Language Models", "authors": ["Wenyi Wu", "Zixuan Song", "Kun Zhou", "Yifei Shao", "Zhiting Hu", "Biwei Huang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.17670v2", "summary": "Language models (LMs) and their extension, vision-language models (VLMs),\nhave achieved remarkable performance across various tasks. However, they still\nstruggle with complex reasoning tasks that require multimodal or multilingual\nreal-world knowledge. To support such capabilities, an external memory system\nthat can efficiently provide relevant multimodal information is essential.\nExisting approaches generally concatenate image and text tokens into a long\nsequence as memory, which, however, may drastically increase context length and\neven degrade performance. In contrast, we propose using continuous memory, a\ncompact set of dense embeddings to more effectively and efficiently represent\nmultimodal and multilingual knowledge. Our key insight is that a VLM can serve\nas its own continuous memory encoder. We empirically show that this design\nimproves performance on complex multimodal reasoning tasks. Building on this,\nwe introduce a data-efficient and parameter-efficient method to fine-tune the\nVLM into a memory encoder, requiring only 1.2% of the model's parameters and a\nsmall corpus of 15.6K self-synthesized samples. Our approach CoMEM utilizes\nVLM's original capabilities to encode arbitrary multimodal and multilingual\nknowledge into just 8 continuous embeddings. Since the inference-time VLM\nremains frozen, our memory module is plug-and-play and can be flexibly\nintegrated as needed. Extensive experiments across eight multimodal reasoning\nbenchmarks demonstrate the effectiveness of our approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.17670v2", "cate": "cs.LG", "date": "2025-05-23", "updated": "2025-07-07"}
{"id": "2507.04638", "title": "UGG-ReID: Uncertainty-Guided Graph Model for Multi-Modal Object Re-Identification", "authors": ["Xixi Wan", "Aihua Zheng", "Bo Jiang", "Beibei Wang", "Chenglong Li", "Jin Tang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04638v2", "summary": "Multi-modal object Re-IDentification (ReID) has gained considerable attention\nwith the goal of retrieving specific targets across cameras using heterogeneous\nvisual data sources. Existing methods primarily aim to improve identification\nperformance, but often overlook the uncertainty arising from inherent defects,\nsuch as intra-modal noise and inter-modal conflicts. This uncertainty is\nparticularly significant in the case of fine-grained local occlusion and frame\nloss, which becomes a challenge in multi-modal learning. To address the above\nchallenge, we propose a robust approach named Uncertainty-Guided Graph model\nfor multi-modal object ReID (UGG-ReID). UGG-ReID is designed to mitigate noise\ninterference and facilitate effective multi-modal fusion by estimating both\nlocal and sample-level aleatoric uncertainty and explicitly modeling their\ndependencies. Specifically, we first propose the Gaussian patch-graph\nrepresentation model that leverages uncertainty to quantify fine-grained local\ncues and capture their structural relationships. This process boosts the\nexpressiveness of modal-specific information, ensuring that the generated\nembeddings are both more informative and robust. Subsequently, we design an\nuncertainty-guided mixture of experts strategy that dynamically routes samples\nto experts exhibiting low uncertainty. This strategy effectively suppresses\nnoise-induced instability, leading to enhanced robustness. Meanwhile, we design\nan uncertainty-guided routing to strengthen the multi-modal interaction,\nimproving the performance. UGG-ReID is comprehensively evaluated on five\nrepresentative multi-modal object ReID datasets, encompassing diverse spectral\nmodalities. Experimental results show that the proposed method achieves\nexcellent performance on all datasets and is significantly better than current\nmethods in terms of noise immunity. Our code will be made public upon\nacceptance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04638v2", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2506.01975", "title": "An empirical study of task and feature correlations in the reuse of pre-trained models", "authors": ["Jama Hussein Mohamud", "Willie Brink"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.01975v2", "summary": "Pre-trained neural networks are commonly used and reused in the machine\nlearning community. Alice trains a model for a particular task, and a part of\nher neural network is reused by Bob for a different task, often to great\neffect. To what can we ascribe Bob's success? This paper introduces an\nexperimental setup through which factors contributing to Bob's empirical\nsuccess could be studied in silico. As a result, we demonstrate that Bob might\njust be lucky: his task accuracy increases monotonically with the correlation\nbetween his task and Alice's. Even when Bob has provably uncorrelated tasks and\ninput features from Alice's pre-trained network, he can achieve significantly\nbetter than random performance due to Alice's choice of network and optimizer.\nWhen there is little correlation between tasks, only reusing lower pre-trained\nlayers is preferable, and we hypothesize the converse: that the optimal number\nof retrained layers is indicative of task and feature correlation. Finally, we\nshow in controlled real-world scenarios that Bob can effectively reuse Alice's\npre-trained network if there are semantic correlations between his and Alice's\ntask.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.01975v2", "cate": "cs.LG", "date": "2025-05-15", "updated": "2025-07-08"}
{"id": "2505.04317", "title": "Mastering Multi-Drone Volleyball through Hierarchical Co-Self-Play Reinforcement Learning", "authors": ["Ruize Zhang", "Sirui Xiang", "Zelai Xu", "Feng Gao", "Shilong Ji", "Wenhao Tang", "Wenbo Ding", "Chao Yu", "Yu Wang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.04317v3", "summary": "In this paper, we tackle the problem of learning to play 3v3 multi-drone\nvolleyball, a new embodied competitive task that requires both high-level\nstrategic coordination and low-level agile control. The task is turn-based,\nmulti-agent, and physically grounded, posing significant challenges due to its\nlong-horizon dependencies, tight inter-agent coupling, and the underactuated\ndynamics of quadrotors. To address this, we propose Hierarchical Co-Self-Play\n(HCSP), a hierarchical reinforcement learning framework that separates\ncentralized high-level strategic decision-making from decentralized low-level\nmotion control. We design a three-stage population-based training pipeline to\nenable both strategy and skill to emerge from scratch without expert\ndemonstrations: (I) training diverse low-level skills, (II) learning high-level\nstrategy via self-play with fixed low-level controllers, and (III) joint\nfine-tuning through co-self-play. Experiments show that HCSP achieves superior\nperformance, outperforming non-hierarchical self-play and rule-based\nhierarchical baselines with an average 82.9% win rate and a 71.5% win rate\nagainst the two-stage variant. Moreover, co-self-play leads to emergent team\nbehaviors such as role switching and coordinated formations, demonstrating the\neffectiveness of our hierarchical design and training scheme. The project page\nis at https://sites.google.com/view/hi-co-self-play.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.04317v3", "cate": "cs.AI", "date": "2025-05-07", "updated": "2025-07-08"}
{"id": "2506.05752", "title": "Integrating Spatiotemporal Features in LSTM for Spatially Informed COVID-19 Hospitalization Forecasting", "authors": ["Zhongying Wang", "Thoai D. Ngo", "Hamidreza Zoraghein", "Benjamin Lucas", "Morteza Karimzadeh"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      36 pages, 12 figures. This is the accepted version of the article published in International Journal of Geographical Information Science. DOI will be added upon publication", "url": "http://arxiv.org/abs/2506.05752v2", "summary": "The COVID-19 pandemic's severe impact highlighted the need for accurate and\ntimely hospitalization forecasting to support effective healthcare planning.\nHowever, most forecasting models struggled, particularly during variant surges,\nwhen they were most needed. This study introduces a novel parallel-stream Long\nShort-Term Memory (LSTM) framework to forecast daily state-level incident\nhospitalizations in the United States. Our framework incorporates a\nspatiotemporal feature, Social Proximity to Hospitalizations (SPH), derived\nfrom Meta's Social Connectedness Index, to improve forecasts. SPH serves as a\nproxy for interstate population interaction, capturing transmission dynamics\nacross space and time. Our architecture captures both short- and long-term\ntemporal dependencies, and a multi-horizon ensembling strategy balances\nforecasting consistency and error. An evaluation against the COVID-19 Forecast\nHub ensemble models during the Delta and Omicron surges reveals the superiority\nof our model. On average, our model surpasses the ensemble by 27, 42, 54, and\n69 hospitalizations per state at the 7-, 14-, 21-, and 28-day horizons,\nrespectively, during the Omicron surge. Data-ablation experiments confirm SPH's\npredictive power, highlighting its effectiveness in enhancing forecasting\nmodels. This research not only advances hospitalization forecasting but also\nunderscores the significance of spatiotemporal features, such as SPH, in\nmodeling the complex dynamics of infectious disease spread.", "comment": "36 pages, 12 figures. This is the accepted version of the article\n  published in International Journal of Geographical Information Science. DOI\n  will be added upon publication", "pdf_url": "http://arxiv.org/pdf/2506.05752v2", "cate": "cs.LG", "date": "2025-06-06", "updated": "2025-07-07"}
{"id": "2507.04801", "title": "PointGAC: Geometric-Aware Codebook for Masked Point Cloud Modeling", "authors": ["Abiao Li", "Chenlei Lv", "Yuming Fang", "Yifan Zuo", "Jian Zhang", "Guofeng Mei"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.04801v2", "summary": "Most masked point cloud modeling (MPM) methods follow a regression paradigm\nto reconstruct the coordinate or feature of masked regions. However, they tend\nto over-constrain the model to learn the details of the masked region,\nresulting in failure to capture generalized features. To address this\nlimitation, we propose \\textbf{\\textit{PointGAC}}, a novel clustering-based MPM\nmethod that aims to align the feature distribution of masked regions.\nSpecially, it features an online codebook-guided teacher-student framework.\nFirstly, it presents a geometry-aware partitioning strategy to extract initial\npatches. Then, the teacher model updates a codebook via online k-means based on\nfeatures extracted from the complete patches. This procedure facilitates\ncodebook vectors to become cluster centers. Afterward, we assigns the unmasked\nfeatures to their corresponding cluster centers, and the student model aligns\nthe assignment for the reconstructed masked features. This strategy focuses on\nidentifying the cluster centers to which the masked features belong, enabling\nthe model to learn more generalized feature representations. Benefiting from a\nproposed codebook maintenance mechanism, codebook vectors are actively updated,\nwhich further increases the efficiency of semantic feature learning.\nExperiments validate the effectiveness of the proposed method on various\ndownstream tasks. Code is available at https://github.com/LAB123-tech/PointGAC", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.04801v2", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2505.05602", "title": "HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics", "authors": ["Lennart Luettgau", "Harry Coppock", "Magda Dubois", "Christopher Summerfield", "Cozmin Ududec"], "categories": ["cs.AI", "stat.AP"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      23 pages, 9 figures", "url": "http://arxiv.org/abs/2505.05602v2", "summary": "As Large Language Models (LLMs) and other AI systems evolve, robustly\nestimating their capabilities from inherently stochastic outputs while\nsystematically quantifying uncertainty in these estimates becomes increasingly\nimportant. Further, advanced AI evaluations often have a nested hierarchical\nstructure, exhibit high levels of complexity, and come with high costs in\ntesting the most advanced AI systems. To address these challenges, we introduce\nHiBayES, a generalizable Hierarchical Bayesian modeling framework for AI\nEvaluation Statistics. HiBayES supports robust inferences in classical\nquestion-answer benchmarks and advanced agentic evaluations, particularly in\nlow-data scenarios (e.g., < 20 data points per evaluation). Built on\nGeneralized Linear Models (GLMs), Bayesian data analysis, and formal model\ncomparison, HiBayES provides principled uncertainty quantification and robust\nparameter estimation. This paper offers a comprehensive introduction to\nHiBayES, including illustrative examples, comparisons to conventional\nstatistical methods, and practical guidance for implementing multilevel\nBayesian GLMs. Additionally, we provide a HiBayES software package [4] (Beta\nversion) for out-of-the-box implementation.", "comment": "23 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2505.05602v2", "cate": "cs.AI", "date": "2025-05-08", "updated": "2025-07-08"}
{"id": "2506.09016", "title": "SPEED-RL: Faster Training of Reasoning Models via Online Curriculum Learning", "authors": ["Ruiqi Zhang", "Daman Arora", "Song Mei", "Andrea Zanette"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      pre-print", "url": "http://arxiv.org/abs/2506.09016v2", "summary": "Training large language models with reinforcement learning (RL) against\nverifiable rewards significantly enhances their reasoning abilities, yet\nremains computationally expensive due to inefficient uniform prompt sampling.\nWe introduce Selective Prompting with Efficient Estimation of Difficulty\n(SPEED), an adaptive online RL curriculum that selectively chooses training\nexamples of intermediate difficulty to maximize learning efficiency.\nTheoretically, we establish that intermediate-difficulty prompts improve the\ngradient estimator's signal-to-noise ratio, accelerating convergence.\nEmpirically, our efficient implementation leads to 2x to 6x faster training\nwithout degrading accuracy, requires no manual tuning, and integrates\nseamlessly into standard RL algorithms.", "comment": "pre-print", "pdf_url": "http://arxiv.org/pdf/2506.09016v2", "cate": "cs.LG", "date": "2025-06-10", "updated": "2025-07-08"}
{"id": "2507.05221", "title": "CTA: Cross-Task Alignment for Better Test Time Training", "authors": ["Samuel Barbeau", "Pedram Fekri", "David Osowiechi", "Ali Bahri", "Moslem Yazdanpanah", "Masih Aminbeidokhti", "Christian Desrosiers"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Preprint, under review", "url": "http://arxiv.org/abs/2507.05221v2", "summary": "Deep learning models have demonstrated exceptional performance across a wide\nrange of computer vision tasks. However, their performance often degrades\nsignificantly when faced with distribution shifts, such as domain or dataset\nchanges. Test-Time Training (TTT) has emerged as an effective method to enhance\nmodel robustness by incorporating an auxiliary unsupervised task during\ntraining and leveraging it for model updates at test time. In this work, we\nintroduce CTA (Cross-Task Alignment), a novel approach for improving TTT.\nUnlike existing TTT methods, CTA does not require a specialized model\narchitecture and instead takes inspiration from the success of multi-modal\ncontrastive learning to align a supervised encoder with a self-supervised one.\nThis process enforces alignment between the learned representations of both\nmodels, thereby mitigating the risk of gradient interference, preserving the\nintrinsic robustness of self-supervised learning and enabling more semantically\nmeaningful updates at test-time. Experimental results demonstrate substantial\nimprovements in robustness and generalization over the state-of-the-art on\nseveral benchmark datasets.", "comment": "Preprint, under review", "pdf_url": "http://arxiv.org/pdf/2507.05221v2", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2506.06216", "title": "ILP Techniques for Enhancing Branch and Bound MaxSAT Solvers", "authors": ["Jialu Zhang", "Chu-Min Li", "Sami Cherif", "Shuolin Li", "Zhifei Zheng"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.06216v2", "summary": "This paper investigates the impact of ILP techniques on BnB MaxSAT solvers,\nparticularly ILP preprocessing techniques and various portfolio strategies.\nExperimental results demonstrate that ILP techniques enable\nWMaxCDCL-OpenWbo1200 and MaxCDCL-OpenWbo300, the best two solvers in the\nunweighted track of the MaxSAT evaluation 2024, to solve 27 and 30 additional\ninstances, respectively. Furthermore, although state-of-the-art MaxSAT solvers\nheavily rely on an ILP solver in their portfolios, our proposed approach uses\nILP preprocessing techniques to reduce this dependency. Allocating only a short\nruntime to the ILP solver within a portfolio that includes (W)MaxCDCL, as\nproposed in our approach, is sufficient to achieve strong results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.06216v2", "cate": "cs.AI", "date": "2025-06-06", "updated": "2025-07-08"}
{"id": "2506.09594", "title": "Accelerating Large-Scale Regularized High-Order Tensor Recovery", "authors": ["Wenjin Qin", "Hailin Wang", "Jingyao Hou", "Jianjun Wang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.09594v2", "summary": "Currently, existing tensor recovery methods fail to recognize the impact of\ntensor scale variations on their structural characteristics. Furthermore,\nexisting studies face prohibitive computational costs when dealing with\nlarge-scale high-order tensor data. To alleviate these issue, assisted by the\nKrylov subspace iteration, block Lanczos bidiagonalization process, and random\nprojection strategies, this article first devises two fast and accurate\nrandomized algorithms for low-rank tensor approximation (LRTA) problem.\nTheoretical bounds on the accuracy of the approximation error estimate are\nestablished. Next, we develop a novel generalized nonconvex modeling framework\ntailored to large-scale tensor recovery, in which a new regularization paradigm\nis exploited to achieve insightful prior representation for large-scale\ntensors. On the basis of the above, we further investigate new unified\nnonconvex models and efficient optimization algorithms, respectively, for\nseveral typical high-order tensor recovery tasks in unquantized and quantized\nsituations. To render the proposed algorithms practical and efficient for\nlarge-scale tensor data, the proposed randomized LRTA schemes are integrated\ninto their central and time-intensive computations. Finally, we conduct\nextensive experiments on various large-scale tensors, whose results demonstrate\nthe practicability, effectiveness and superiority of the proposed method in\ncomparison with some state-of-the-art approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.09594v2", "cate": "cs.LG", "date": "2025-06-11", "updated": "2025-07-08"}
{"id": "2506.20815", "title": "Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications", "authors": ["Xinye Tang", "Haijun Zhai", "Chaitanya Belwal", "Vineeth Thayanithi", "Philip Baumann", "Yogesh K Roy"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.20815v2", "summary": "LLM-powered applications are highly susceptible to the quality of user\nprompts, and crafting high-quality prompts can often be challenging especially\nfor domain-specific applications. This paper presents a novel dynamic\ncontext-aware prompt recommendation system for domain-specific AI applications.\nOur solution combines contextual query analysis, retrieval-augmented knowledge\ngrounding, hierarchical skill organization, and adaptive skill ranking to\ngenerate relevant and actionable prompt suggestions.\n  The system leverages behavioral telemetry and a two-stage hierarchical\nreasoning process to dynamically select and rank relevant skills, and\nsynthesizes prompts using both predefined and adaptive templates enhanced with\nfew-shot learning. Experiments on real-world datasets demonstrate that our\napproach achieves high usefulness and relevance, as validated by both automated\nand expert evaluations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.20815v2", "cate": "cs.AI", "date": "2025-06-25", "updated": "2025-07-08"}
{"id": "2506.12025", "title": "Unsupervised Learning for Optimal Transport plan prediction between unbalanced graphs", "authors": ["Sonia Mazelet", "Rémi Flamary", "Bertrand Thirion"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.12025v3", "summary": "Optimal transport between graphs, based on Gromov-Wasserstein and other\nextensions, is a powerful tool for comparing and aligning graph structures.\nHowever, solving the associated non-convex optimization problems is\ncomputationally expensive, which limits the scalability of these methods to\nlarge graphs. In this work, we present Unbalanced Learning of Optimal Transport\n(ULOT), a deep learning method that predicts optimal transport plans between\ntwo graphs. Our method is trained by minimizing the fused unbalanced\nGromov-Wasserstein (FUGW) loss. We propose a novel neural architecture with\ncross-attention that is conditioned on the FUGW tradeoff hyperparameters. We\nevaluate ULOT on synthetic stochastic block model (SBM) graphs and on real\ncortical surface data obtained from fMRI. ULOT predicts transport plans with\ncompetitive loss up to two orders of magnitude faster than classical solvers.\nFurthermore, the predicted plan can be used as a warm start for classical\nsolvers to accelerate their convergence. Finally, the predicted transport plan\nis fully differentiable with respect to the graph inputs and FUGW\nhyperparameters, enabling the optimization of functionals of the ULOT plan.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.12025v3", "cate": "cs.LG", "date": "2025-05-21", "updated": "2025-07-08"}
{"id": "2506.15817", "title": "Optimizing Bidding Strategies in First-Price Auctions in Binary Feedback Setting with Predictions", "authors": ["Jason Tandiary"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Needs further refinement", "url": "http://arxiv.org/abs/2506.15817v2", "summary": "This paper studies Vickrey first-price auctions under binary feedback.\nLeveraging the enhanced performance of machine learning algorithms, the new\nalgorithm uses past information to improve the regret bounds of the BROAD-OMD\nalgorithm. Motivated by the growing relevance of first-price auctions and the\npredictive capabilities of machine learning models, this paper proposes a new\nalgorithm within the BROAD-OMD framework (Hu et al., 2025) that leverages\npredictions of the highest competing bid. This paper's main contribution is an\nalgorithm that achieves zero regret under accurate predictions. Additionally, a\nbounded regret bound of O(T^(3/4) * Vt^(1/4)) is established under certain\nnormality conditions.", "comment": "Needs further refinement", "pdf_url": "http://arxiv.org/pdf/2506.15817v2", "cate": "cs.LG", "date": "2025-06-18", "updated": "2025-07-07"}
{"id": "2507.04742", "title": "Activation Steering for Chain-of-Thought Compression", "authors": ["Seyedarmin Azizi", "Erfan Baghaei Potraghloo", "Massoud Pedram"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04742v2", "summary": "Large language models (LLMs) excel at complex reasoning when they include\nintermediate steps, known as \"chains of thought\" (CoTs). However, these\nrationales are often overly verbose, even for simple problems, leading to\nwasted context, increased latency, and higher energy consumption. We observe\nthat verbose, English-heavy CoTs and concise, math-centric CoTs occupy distinct\nregions in the model's residual-stream activation space. By extracting and\ninjecting a \"steering vector\" to transition between these modes, we can\nreliably shift generation toward more concise reasoning, effectively\ncompressing CoTs without retraining. We formalize this approach as\nActivation-Steered Compression (ASC), an inference-time technique that shortens\nreasoning traces by directly modifying hidden representations. In addition, we\nprovide a theoretical analysis of the impact of ASC on the output distribution,\nderived from a closed-form KL-divergence-bounded constraint to regulate\nsteering strength. Using only 100 paired verbose and concise examples, ASC\nachieves up to 67.43% reduction in CoT length on MATH500 and GSM8K datasets,\nwhile maintaining accuracy across 7B, 8B, and 32B parameter models. As a\ntraining-free method, ASC introduces negligible runtime overhead and, on\nMATH500, delivers an average 2.73x speedup in end-to-end reasoning wall-clock\ntime on an 8B model. This makes ASC a practical and efficient tool for\nstreamlining the deployment of reasoning-capable LLMs in latency- or\ncost-sensitive settings. The code is available at:\nhttps://github.com/ArminAzizi98/ASC", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04742v2", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2506.21940", "title": "GuiderNet: A Meta-Learning Framework for Optimizing Quantum Circuit Geometry and Mitigating Barren Plateaus", "authors": ["Marwan Ait Haddou", "Mohamed Bennai"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Need more analysis", "url": "http://arxiv.org/abs/2506.21940v2", "summary": "Variational Quantum Algorithms (VQAs) offer potential for near-term quantum\nadvantage but face challenges from barren plateaus, where gradients vanish, and\npoorly conditioned optimization landscapes. We introduce GuiderNet, a\nmeta-learning framework that conditions Parameterized Quantum Circuits (PQCs)\nusing data-dependent parameter shifts aimed at minimizing the log condition\nnumber of the Fubini-Study metric tensor. Implemented as a classical neural\nnetwork, GuiderNet is meta-trained to guide PQC parameters into geometrically\nfavorable regions and is embedded within hybrid quantum-classical pipelines to\nsteer both initialization and adaptive modulation during training.\n  Applied to the Kaggle Diabetes classification task, GuiderNet reduces\ncumulative training loss by over 5x, improves test accuracy from 75.3% to\n98.6%, and increases the minority-class F1 score from 0.67 to 0.95. It also\nsuppresses gradient explosion and stabilizes parameter updates, enabling\nsmoother and more robust optimization. These results demonstrate that geometric\nmeta-conditioning can mitigate barren plateaus and ill-conditioning, providing\na scalable approach to enhance trainability and generalization in quantum\nmachine learning.", "comment": "Need more analysis", "pdf_url": "http://arxiv.org/pdf/2506.21940v2", "cate": "cs.LG", "date": "2025-06-27", "updated": "2025-07-08"}
{"id": "2507.05110", "title": "Rule Learning for Knowledge Graph Reasoning under Agnostic Distribution Shift", "authors": ["Shixuan Liu", "Yue He", "Yunfei Wang", "Hao Zou", "Haoxiang Cheng", "Wenjing Yang", "Peng Cui", "Zhong Liu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05110v2", "summary": "Knowledge graph (KG) reasoning remains a critical research area focused on\ninferring missing knowledge by analyzing relationships among observed facts.\nDespite its success, a key limitation of existing KG reasoning methods is their\ndependence on the I.I.D assumption. This assumption can easily be violated due\nto unknown sample selection bias during training or agnostic distribution\nshifts during testing, significantly compromising model performance and\nreliability. To facilitate the deployment of KG reasoning in wild environments,\nthis study investigates learning logical rules from KGs affected by unknown\nselection bias. Additionally, we address test sets with agnostic distribution\nshifts, formally defining this challenge as out-of-distribution (OOD) KG\nreasoning-a previously underexplored problem. To solve the issue, we propose\nthe Stable Rule Learning (StableRule) framework, an end-to-end methodology that\nintegrates feature decorrelation with rule learning network, to enhance OOD\ngeneralization performance. By leveraging feature decorrelation, the StableRule\nframework mitigates the adverse effects of covariate shifts arising in OOD\nscenarios, thereby improving the robustness of the rule learning component in\neffectively deriving logical rules. Extensive experiments on seven benchmark\nKGs demonstrate the framework's superior effectiveness and stability across\ndiverse heterogeneous environments, underscoring its practical significance for\nreal-world applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05110v2", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2506.23782", "title": "WATS: Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling", "authors": ["Xiaoyang Li", "Linwei Tao", "Haohui Lu", "Minjing Dong", "Junbin Gao", "Chang Xu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23782v2", "summary": "Graph Neural Networks (GNNs) have demonstrated strong predictive performance\non relational data; however, their confidence estimates often misalign with\nactual predictive correctness, posing significant limitations for deployment in\nsafety-critical settings. While existing graph-aware calibration methods seek\nto mitigate this limitation, they primarily depend on coarse one-hop\nstatistics, such as neighbor-predicted confidence, or latent node embeddings,\nthereby neglecting the fine-grained structural heterogeneity inherent in graph\ntopology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), a\npost-hoc calibration framework that assigns node-specific temperatures based on\ntunable heat-kernel graph wavelet features. Specifically, WATS harnesses the\nscalability and topology sensitivity of graph wavelets to refine confidence\nestimates, all without necessitating model retraining or access to neighboring\nlogits or predictions. Extensive evaluations across seven benchmark datasets\nwith varying graph structures and two GNN backbones demonstrate that WATS\nachieves the lowest Expected Calibration Error (ECE) among all compared\nmethods, outperforming both classical and graph-specific baselines by up to\n42.3\\% in ECE and reducing calibration variance by 17.24\\% on average compared\nwith graph-specific methods. Moreover, WATS remains computationally efficient,\nscaling well across graphs of diverse sizes and densities. Code will be\nreleased based on publication.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23782v2", "cate": "cs.LG", "date": "2025-06-30", "updated": "2025-07-08"}
{"id": "2507.05201", "title": "MedGemma Technical Report", "authors": ["Andrew Sellergren", "Sahar Kazemzadeh", "Tiam Jaroensri", "Atilla Kiraly", "Madeleine Traverse", "Timo Kohlberger", "Shawn Xu", "Fayaz Jamil", "Cían Hughes", "Charles Lau", "Justin Chen", "Fereshteh Mahvar", "Liron Yatziv", "Tiffany Chen", "Bram Sterling", "Stefanie Anna Baby", "Susanna Maria Baby", "Jeremy Lai", "Samuel Schmidgall", "Lu Yang", "Kejia Chen", "Per Bjornsson", "Shashir Reddy", "Ryan Brush", "Kenneth Philbrick", "Howard Hu", "Howard Yang", "Richa Tiwari", "Sunny Jansen", "Preeti Singh", "Yun Liu", "Shekoofeh Azizi", "Aishwarya Kamath", "Johan Ferret", "Shreya Pathak", "Nino Vieillard", "Ramona Merhej", "Sarah Perrin", "Tatiana Matejovicova", "Alexandre Ramé", "Morgane Riviere", "Louis Rouillard", "Thomas Mesnard", "Geoffrey Cideron", "Jean-bastien Grill", "Sabela Ramos", "Edouard Yvinec", "Michelle Casbon", "Elena Buchatskaya", "Jean-Baptiste Alayrac", "Dmitry Lepikhin", "Vlad Feinberg", "Sebastian Borgeaud", "Alek Andreev", "Cassidy Hardin", "Robert Dadashi", "Léonard Hussenot", "Armand Joulin", "Olivier Bachem", "Yossi Matias", "Katherine Chou", "Avinatan Hassidim", "Kavi Goel", "Clement Farabet", "Joelle Barral", "Tris Warkentin", "Jonathon Shlens", "David Fleet", "Victor Cotruta", "Omar Sanseviero", "Gus Martins", "Phoebe Kirk", "Anand Rao", "Shravya Shetty", "David F. Steiner", "Can Kirmizibayrak", "Rory Pilgrim", "Daniel Golden", "Lin Yang"], "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05201v2", "summary": "Artificial intelligence (AI) has significant potential in healthcare\napplications, but its training and deployment faces challenges due to\nhealthcare's diverse data, complex tasks, and the need to preserve privacy.\nFoundation models that perform well on medical tasks and require less\ntask-specific tuning data are critical to accelerate the development of\nhealthcare AI applications. We introduce MedGemma, a collection of medical\nvision-language foundation models based on Gemma 3 4B and 27B. MedGemma\ndemonstrates advanced medical understanding and reasoning on images and text,\nsignificantly exceeding the performance of similar-sized generative models and\napproaching the performance of task-specific models, while maintaining the\ngeneral capabilities of the Gemma 3 base models. For out-of-distribution tasks,\nMedGemma achieves 2.6-10% improvement on medical multimodal question answering,\n15.5-18.1% improvement on chest X-ray finding classification, and 10.8%\nimprovement on agentic evaluations compared to the base models. Fine-tuning\nMedGemma further improves performance in subdomains, reducing errors in\nelectronic health record information retrieval by 50% and reaching comparable\nperformance to existing specialized state-of-the-art methods for pneumothorax\nclassification and histopathology patch classification. We additionally\nintroduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP.\nMedSigLIP powers the visual understanding capabilities of MedGemma and as an\nencoder achieves comparable or better performance than specialized medical\nimage encoders. Taken together, the MedGemma collection provides a strong\nfoundation of medical image and text capabilities, with potential to\nsignificantly accelerate medical research and development of downstream\napplications. The MedGemma collection, including tutorials and model weights,\ncan be found at https://goo.gle/medgemma.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05201v2", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2507.01201", "title": "Escaping Plato's Cave: JAM for Aligning Independently Trained Vision and Language Models", "authors": ["Hyoseo", "Yoon", "Yisong Yue", "Been Kim"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.01201v3", "summary": "Independently trained vision and language models inhabit disjoint\nrepresentational spaces, shaped by their respective modalities, objectives, and\narchitectures. Yet an emerging hypothesis - the Platonic Representation\nHypothesis - suggests that such models may nonetheless converge toward a shared\nstatistical model of reality. This compatibility, if it exists, raises a\nfundamental question: can we move beyond post-hoc statistical detection of\nalignment and explicitly optimize for it between such disjoint representations?\nWe cast this Platonic alignment problem as a multi-objective optimization task\n- preserve each modality's native structure while aligning for mutual\ncoherence. We introduce the Joint Autoencoder Modulator (JAM) framework that\njointly trains modality-specific autoencoders on the latent representations of\npre-trained single modality models, encouraging alignment through both\nreconstruction and cross-modal objectives. By analogy, this framework serves as\na method to escape Plato's Cave, enabling the emergence of shared structure\nfrom disjoint inputs. We evaluate this framework across three critical design\naxes: (i) the alignment objective - comparing contrastive loss (Con), its\nhard-negative variant (NegCon), and our Spread loss, (ii) the layer depth at\nwhich alignment is most effective, and (iii) the impact of foundation model\nscale on representational convergence. Our findings show that our lightweight\nPareto-efficient framework reliably induces alignment, even across frozen,\nindependently trained representations, offering both theoretical insight and\npractical pathways for transforming generalist unimodal foundations into\nspecialist multimodal models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01201v3", "cate": "cs.LG", "date": "2025-07-01", "updated": "2025-07-07"}
{"id": "2507.05241", "title": "SciMaster: Towards General-Purpose Scientific AI Agents, Part I. X-Master as Foundation: Can We Lead on Humanity's Last Exam?", "authors": ["Jingyi Chai", "Shuo Tang", "Rui Ye", "Yuwen Du", "Xinyu Zhu", "Mengcheng Zhou", "Yanfeng Wang", "Weinan E", "Yuzhi Zhang", "Linfeng Zhang", "Siheng Chen"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      15 pages, 10 figures", "url": "http://arxiv.org/abs/2507.05241v2", "summary": "The rapid advancements of AI agents have ignited the long-held ambition of\nleveraging them to accelerate scientific discovery. Achieving this goal\nrequires a deep understanding of the frontiers of human knowledge. As such,\nHumanity's Last Exam (HLE) provides an exceptionally challenging touchstone for\nevaluating scientific AI agents. In this work, we aim to construct the\nfoundational architecture for general-purpose agents and validate the\ncapabilities through leading performance on HLE. To achieve this, we introduce\nX-Master, a tool-augmented reasoning agent designed to emulate human\nresearchers by interacting flexibly with external tools during its reasoning\nprocess. This agent, guided by the conceptualization of code as an interaction\nlanguage, can flexibly leverage built-in Python libraries and our customized\ntools to augment the reasoning. We further scale its capabilities through\nX-Masters, a scattered-and-stacked agentic workflow that systematically\nenhances breadth and depth of reasoning. Our open-source solution, X-Masters,\nsets a new state-of-the-art record on HLE with a score of 32.1%, surpassing\nOpenAI's and Google's Deep Research (26.6% and 26.9%) and becoming the first to\nexceed the 30% threshold. This work allows us to gain a deeper understanding of\ncomplex task-solving and accumulates valuable experience that can inform future\nadvancements, guiding subsequent model training.", "comment": "15 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.05241v2", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2507.03119", "title": "Neural-Network solver of ideal MHD equilibria", "authors": ["Timo Thun", "Andrea Merlo", "Rory Conlin", "Dario Panici", "Daniel Böckenhoff"], "categories": ["cs.LG", "cs.AI", "physics.plasm-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      To be submitted to Nuclear Fusion, 16 pages, 8 figures", "url": "http://arxiv.org/abs/2507.03119v2", "summary": "We present a novel approach to compute three-dimensional Magnetohydrodynamic\nequilibria by parametrizing Fourier modes with artificial neural networks and\ncompare it to equilibria computed by conventional solvers. The full nonlinear\nglobal force residual across the volume in real space is then minimized with\nfirst order optimizers. Already,we observe competitive computational cost to\narrive at the same minimum residuals computed by existing codes. With increased\ncomputational cost,lower minima of the residual are achieved by the neural\nnetworks,establishing a new lower bound for the force residual. We use\nminimally complex neural networks,and we expect significant improvements for\nsolving not only single equilibria with neural networks,but also for computing\nneural network models valid over continuous distributions of equilibria.", "comment": "To be submitted to Nuclear Fusion, 16 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.03119v2", "cate": "cs.LG", "date": "2025-07-03", "updated": "2025-07-08"}
{"id": "2507.03312", "title": "MPX: Mixed Precision Training for JAX", "authors": ["Alexander Gräfe", "Sebastian Trimpe"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03312v2", "summary": "Mixed-precision training has emerged as an indispensable tool for enhancing\nthe efficiency of neural network training in recent years. Concurrently, JAX\nhas grown in popularity as a versatile machine learning toolbox. However, it\ncurrently lacks robust support for mixed-precision training. We propose MPX, a\nmixed-precision training toolbox for JAX that simplifies and accelerates the\ntraining of large-scale neural networks while preserving model accuracy. MPX\nseamlessly integrates with popular toolboxes such as Equinox and Flax, allowing\nusers to convert full-precision pipelines to mixed-precision versions with\nminimal modifications. By casting both inputs and outputs to half precision,\nand introducing a dynamic loss-scaling mechanism, MPX alleviates issues like\ngradient underflow and overflow that commonly arise in half precision\ncomputations. Its design inherits critical features from JAX's type-promotion\nbehavior, ensuring that operations take place in the correct precision and\nallowing for selective enforcement of full precision where needed (e.g., sums,\nmeans, or softmax). MPX further provides wrappers for automatic creation and\nmanagement of mixed-precision gradients and optimizers, enabling\nstraightforward integration into existing JAX training pipelines. MPX's source\ncode, documentation, and usage examples are available at\ngithub.com/Data-Science-in-Mechanical-Engineering/mixed_precision_for_JAX .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03312v2", "cate": "cs.LG", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2507.04176", "title": "skfolio: Portfolio Optimization in Python", "authors": ["Carlo Nicolini", "Matteo Manzi", "Hugo Delatte"], "categories": ["cs.LG", "q-fin.PM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2507.04176v2", "summary": "Portfolio optimization is a fundamental challenge in quantitative finance,\nrequiring robust computational tools that integrate statistical rigor with\npractical implementation. We present skfolio, an open-source Python library for\nportfolio construction and risk management that seamlessly integrates with the\nscikit-learn ecosystem. skfolio provides a unified framework for diverse\nallocation strategies, from classical mean-variance optimization to modern\nclustering-based methods, state-of-the-art financial estimators with native\ninterfaces, and advanced cross-validation techniques tailored for financial\ntime series. By adhering to scikit-learn's fit-predict-transform paradigm, the\nlibrary enables researchers and practitioners to leverage machine learning\nworkflows for portfolio optimization, promoting reproducibility and\ntransparency in quantitative finance.", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2507.04176v2", "cate": "cs.LG", "date": "2025-07-05", "updated": "2025-07-08"}
{"id": "2312.08968", "title": "Detecting value-expressive text posts in Russian social media", "authors": ["Maria Milkova", "Maksim Rudnev", "Lidia Okolskaya"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2312.08968v2", "summary": "Basic values are concepts or beliefs which pertain to desirable end-states\nand transcend specific situations. Studying personal values in social media can\nilluminate how and why societal values evolve especially when the stimuli-based\nmethods, such as surveys, are inefficient, for instance, in hard-to-reach\npopulations. On the other hand, user-generated content is driven by the massive\nuse of stereotyped, culturally defined speech constructions rather than\nauthentic expressions of personal values. We aimed to find a model that can\naccurately detect value-expressive posts in Russian social media VKontakte. A\ntraining dataset of 5,035 posts was annotated by three experts, 304\ncrowd-workers and ChatGPT. Crowd-workers and experts showed only moderate\nagreement in categorizing posts. ChatGPT was more consistent but struggled with\nspam detection. We applied an ensemble of human- and AI-assisted annotation\ninvolving active learning approach, subsequently trained several classification\nmodels using embeddings from various pre-trained transformer-based language\nmodels. The best performance was achieved with embeddings from a fine-tuned\nrubert-tiny2 model, yielding high value detection quality (F1 = 0.75, F1-macro\n= 0.80). This model provides a crucial step to a study of values within and\nbetween Russian social media users.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2312.08968v2", "cate": "cs.CL", "date": "2023-12-14", "updated": "2025-07-08"}
{"id": "2507.04487", "title": "LoSiA: Efficient High-Rank Fine-Tuning via Subnet Localization and Optimization", "authors": ["Xujia Wang", "Yunjia Qi", "Bin Xu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18 pages, 12 figures", "url": "http://arxiv.org/abs/2507.04487v2", "summary": "Parameter-Efficient Fine-Tuning (PEFT) methods, such as LoRA, significantly\nreduce the number of trainable parameters by introducing low-rank decomposition\nmatrices. However, existing methods perform extensive matrix multiplications in\ndomain specialization tasks, resulting in computational inefficiency and\nsub-optimal fine-tuning performance. Hence, we propose LoSiA(Low-Resources\nSubnet Integration Adaptation), an innovative method that dynamically localizes\nand optimizes critical parameters during the training process. Specifically, it\nidentifies a sub-network using gradient sparsity analysis and optimizes it as\nthe trainable target. This design enables effective high-rank adaptation by\nupdating only the sub-network parameters, reducing the additional matrix\nmultiplication. We also present LoSiA-Pro, a faster implementation of LoSiA,\nwhich reduces the training latency by about $27\\%$ compared to LoRA. Extensive\nevaluations show that our method achieves minimal performance drop compared to\nfull fine-tuning, while requiring the least training time across domain\nspecialization and common-sense reasoning tasks. Further analysis shows that\nLoSiA also reduces forgetting during continued training.", "comment": "18 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.04487v2", "cate": "cs.LG", "date": "2025-07-06", "updated": "2025-07-08"}
{"id": "2507.04981", "title": "Classification of autoimmune diseases from Peripheral blood TCR repertoires by multimodal multi-instance learning", "authors": ["Ruihao Zhang", "Fei Ye", "Dandan Meng", "Yixuan Huang", "Maochen", "Xiao Liu"], "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      7 figures, 4 tabels", "url": "http://arxiv.org/abs/2507.04981v2", "summary": "T cell receptor (TCR) repertoires encode critical immunological signatures\nfor autoimmune diseases, yet their clinical application remains limited by\nsequence sparsity and low witness rates. We developed EAMil, a multi-instance\ndeep learning framework that leverages TCR sequencing data to diagnose systemic\nlupus erythematosus (SLE) and rheumatoid arthritis (RA) with exceptional\naccuracy. By integrating PrimeSeq feature extraction with ESMonehot encoding\nand enhanced gate attention mechanisms, our model achieved state-of-the-art\nperformance with AUCs of 98.95% for SLE and 97.76% for RA. EAMil successfully\nidentified disease-associated genes with over 90% concordance with established\ndifferential analyses and effectively distinguished disease-specific TCR genes.\nThe model demonstrated robustness in classifying multiple disease categories,\nutilizing the SLEDAI score to stratify SLE patients by disease severity as well\nas to diagnose the site of damage in SLE patients, and effectively controlling\nfor confounding factors such as age and gender. This interpretable framework\nfor immune receptor analysis provides new insights for autoimmune disease\ndetection and classification with broad potential clinical applications across\nimmune-mediated conditions.", "comment": "7 figures, 4 tabels", "pdf_url": "http://arxiv.org/pdf/2507.04981v2", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2406.06641", "title": "News and Load: Social and Economic Drivers of Regional Multi-horizon Electricity Demand Forecasting", "authors": ["Yun Bai", "Simon Camal", "Andrea Michiorri"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages, 12 figures", "url": "http://arxiv.org/abs/2406.06641v2", "summary": "The relationship between electricity demand and variables such as economic\nactivity and weather patterns is well established. However, this paper explores\nthe connection between electricity demand and social aspects. It further embeds\ndynamic information about the state of society into energy demand modelling and\nforecasting approaches. Through the use of natural language processing on a\nlarge news corpus, we highlight this important link. This study is conducted in\nfive regions of the UK and Ireland and considers multiple time horizons from 1\nto 30 days. It also considers economic variables such as GDP, unemployment and\ninflation. The textual features used in this study represent central constructs\nfrom the word frequencies, topics, word embeddings extracted from the news. The\nfindings indicate that: 1) the textual features are related to various\ncontents, such as military conflicts, transportation, the global pandemic,\nregional economics, and the international energy market. They exhibit causal\nrelationships with regional electricity demand, which are validated using\nGranger causality and Double Machine Learning methods. 2) Economic indicators\nplay a more important role in the East Midlands and Northern Ireland, while\nsocial indicators are more influential in the West Midlands and the South West\nof England. 3) The use of these factors improves deterministic forecasting by\naround 6%.", "comment": "12 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2406.06641v2", "cate": "cs.CL", "date": "2024-06-09", "updated": "2025-07-08"}
{"id": "2406.07072", "title": "On the relation between trainability and dequantization of variational quantum learning models", "authors": ["Elies Gil-Fuster", "Casper Gyurik", "Adrián Pérez-Salinas", "Vedran Dunjko"], "categories": ["quant-ph", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      25 pages, 3 figures, published as a conference paper in Proceedings of the Thirteenth International Conference on Learning Representations (ICLR 2025)", "url": "http://arxiv.org/abs/2406.07072v3", "summary": "The quest for successful variational quantum machine learning (QML) relies on\nthe design of suitable parametrized quantum circuits (PQCs), as analogues to\nneural networks in classical machine learning. Successful QML models must\nfulfill the properties of trainability and non-dequantization, among others.\nRecent works have highlighted an intricate interplay between trainability and\ndequantization of such models, which is still unresolved. In this work we\ncontribute to this debate from the perspective of machine learning, proving a\nnumber of results identifying, among others when trainability and\nnon-dequantization are not mutually exclusive. We begin by providing a number\nof new somewhat broader definitions of the relevant concepts, compared to what\nis found in other literature, which are operationally motivated, and consistent\nwith prior art. With these precise definitions given and motivated, we then\nstudy the relation between trainability and dequantization of variational QML.\nNext, we also discuss the degrees of \"variationalness\" of QML models, where we\ndistinguish between models like the hardware efficient ansatz and quantum\nkernel methods. Finally, we introduce recipes for building PQC-based QML models\nwhich are both trainable and nondequantizable, and corresponding to different\ndegrees of variationalness. We do not address the practical utility for such\nmodels. Our work however does point toward a way forward for finding more\ngeneral constructions, for which finding applications may become feasible.", "comment": "25 pages, 3 figures, published as a conference paper in Proceedings\n  of the Thirteenth International Conference on Learning Representations (ICLR\n  2025)", "pdf_url": "http://arxiv.org/pdf/2406.07072v3", "cate": "quant-ph", "date": "2024-06-11", "updated": "2025-07-08"}
{"id": "2406.08321", "title": "Deep learning from strongly mixing observations: Sparse-penalized regularization and minimax optimality", "authors": ["William Kengne", "Modou Wade"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.08321v2", "summary": "The explicit regularization and optimality of deep neural networks estimators\nfrom independent data have made considerable progress recently. The study of\nsuch properties on dependent data is still a challenge. In this paper, we carry\nout deep learning from strongly mixing observations, and deal with the squared\nand a broad class of loss functions. We consider sparse-penalized\nregularization for deep neural network predictor. For a general framework that\nincludes, regression estimation, classification, time series\nprediction,$\\cdots$, oracle inequality for the expected excess risk is\nestablished and a bound on the class of H\\\"older smooth functions is provided.\nFor nonparametric regression from strong mixing data and sub-exponentially\nerror, we provide an oracle inequality for the $L_2$ error and investigate an\nupper bound of this error on a class of H\\\"older composition functions. For the\nspecific case of nonparametric autoregression with Gaussian and Laplace errors,\na lower bound of the $L_2$ error on this H\\\"older composition class is\nestablished. Up to logarithmic factor, this bound matches its upper bound; so,\nthe deep neural network estimator attains the minimax optimal rate.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.08321v2", "cate": "stat.ML", "date": "2024-06-12", "updated": "2025-07-08"}
{"id": "2409.17172", "title": "What Would You Ask When You First Saw $a^2+b^2=c^2$? Evaluating LLM on Curiosity-Driven Questioning", "authors": ["Shashidhar Reddy Javaji", "Zining Zhu"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.17172v2", "summary": "Large language models (LLMs) can store a massive amount of knowledge, yet\ntheir potential to acquire new knowledge remains unknown. We propose a novel\nevaluation framework that evaluates this capability. This framework prompts\nLLMs to generate questions about a statement introducing scientific knowledge,\nsimulating a curious person when facing the statement for the first time. We\nscore the qualities of the generated questions, thereby evaluating the\nknowledge acquisition potential of the LLM. We apply controlled ablation\nstudies to validate our scoring procedures. Additionally, we created a\nsynthetic dataset consisting of 1101 statements in physics, chemistry, and\nmaths with distinct levels of difficulties, 300 general knowledge statements,\nand 567 incorrect statements. Human evaluations were conducted to validate our\nmodel assessments, achieving an approximate weighted Cohen's kappa of 0.7 on\nall three metrics considered. We find that while large models like GPT-4 and\nMistral 8x7b are adept at generating coherent and relevant questions, the\nsmaller Phi-2 model is equally or more effective. This indicates that size does\nnot solely determine a model's knowledge acquisition potential. The proposed\nframework quantifies a critical model capability that was commonly overlooked\nand opens up research opportunities for developing more knowledgeable AI\nsystems", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.17172v2", "cate": "cs.CL", "date": "2024-09-19", "updated": "2025-07-07"}
{"id": "2411.08324", "title": "Are LLMs Prescient? A Continuous Evaluation using Daily News as the Oracle", "authors": ["Hui Dai", "Ryan Teehan", "Mengye Ren"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ICML 2025", "url": "http://arxiv.org/abs/2411.08324v2", "summary": "Many existing evaluation benchmarks for Large Language Models (LLMs) quickly\nbecome outdated due to the emergence of new models and training data. These\nbenchmarks also fall short in assessing how LLM performance changes over time,\nas they consist of a static set of questions without a temporal dimension. To\naddress these limitations, we propose using future event prediction as a\ncontinuous evaluation method to assess LLMs' temporal generalization and\nforecasting abilities. Our benchmark, Daily Oracle, automatically generates\nquestion-answer (QA) pairs from daily news, challenging LLMs to predict\n\"future\" event outcomes. Our findings reveal that as pre-training data becomes\noutdated, LLM performance degrades over time. While Retrieval Augmented\nGeneration (RAG) has the potential to enhance prediction accuracy, the\nperformance degradation pattern persists, highlighting the need for continuous\nmodel updates. Code and data are available at\nhttps://agenticlearning.ai/daily-oracle.", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2411.08324v2", "cate": "cs.CL", "date": "2024-11-13", "updated": "2025-07-08"}
{"id": "2410.08194", "title": "Features are fate: a theory of transfer learning in high-dimensional regression", "authors": ["Javan Tahir", "Surya Ganguli", "Grant M. Rotskoff"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      29 pages, 7 figures", "url": "http://arxiv.org/abs/2410.08194v2", "summary": "With the emergence of large-scale pre-trained neural networks, methods to\nadapt such \"foundation\" models to data-limited downstream tasks have become a\nnecessity. Fine-tuning, preference optimization, and transfer learning have all\nbeen successfully employed for these purposes when the target task closely\nresembles the source task, but a precise theoretical understanding of \"task\nsimilarity\" is still lacking. While conventional wisdom suggests that simple\nmeasures of similarity between source and target distributions, such as\n$\\phi$-divergences or integral probability metrics, can directly predict the\nsuccess of transfer, we prove the surprising fact that, in general, this is not\nthe case. We adopt, instead, a feature-centric viewpoint on transfer learning\nand establish a number of theoretical results that demonstrate that when the\ntarget task is well represented by the feature space of the pre-trained model,\ntransfer learning outperforms training from scratch. We study deep linear\nnetworks as a minimal model of transfer learning in which we can analytically\ncharacterize the transferability phase diagram as a function of the target\ndataset size and the feature space overlap. For this model, we establish\nrigorously that when the feature space overlap between the source and target\ntasks is sufficiently strong, both linear transfer and fine-tuning improve\nperformance, especially in the low data limit. These results build on an\nemerging understanding of feature learning dynamics in deep linear networks,\nand we demonstrate numerically that the rigorous results we derive for the\nlinear case also apply to nonlinear networks.", "comment": "29 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2410.08194v2", "cate": "stat.ML", "date": "2024-10-10", "updated": "2025-07-07"}
{"id": "2412.11459", "title": "Rethinking Associative Memory Mechanism in Induction Head", "authors": ["Shuo Wang", "Issei Sato"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      COLM 2025", "url": "http://arxiv.org/abs/2412.11459v2", "summary": "Induction head mechanism is a part of the computational circuits for\nin-context learning (ICL) that enable large language models (LLMs) to adapt to\nnew tasks without fine-tuning. Most existing work explains the training\ndynamics behind acquiring such a powerful mechanism. However, the model's\nability to coordinate in-context information over long contexts and global\nknowledge acquired during pretraining remains poorly understood. This paper\ninvestigates how a two-layer transformer thoroughly captures in-context\ninformation and balances it with pretrained bigram knowledge in next token\nprediction, from the viewpoint of associative memory. We theoretically analyze\nthe representation of weight matrices in attention layers and the resulting\nlogits when a transformer is given prompts generated by a bigram model. In the\nexperiments, we design specific prompts to evaluate whether the outputs of the\ntrained transformer align with the theoretical results.", "comment": "COLM 2025", "pdf_url": "http://arxiv.org/pdf/2412.11459v2", "cate": "cs.CL", "date": "2024-12-16", "updated": "2025-07-08"}
{"id": "2501.02547", "title": "Transformers Simulate MLE for Sequence Generation in Bayesian Networks", "authors": ["Yuan Cao", "Yihan He", "Dennis Wu", "Hong-Yu Chen", "Jianqing Fan", "Han Liu"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      51 pages, 17 figures, 5 tables", "url": "http://arxiv.org/abs/2501.02547v2", "summary": "Transformers have achieved significant success in various fields, notably\nexcelling in tasks involving sequential data like natural language processing.\nDespite these achievements, the theoretical understanding of transformers'\ncapabilities remains limited. In this paper, we investigate the theoretical\ncapabilities of transformers to autoregressively generate sequences in Bayesian\nnetworks based on in-context maximum likelihood estimation (MLE). Specifically,\nwe consider a setting where a context is formed by a set of independent\nsequences generated according to a Bayesian network. We demonstrate that there\nexists a simple transformer model that can (i) estimate the conditional\nprobabilities of the Bayesian network according to the context, and (ii)\nautoregressively generate a new sample according to the Bayesian network with\nestimated conditional probabilities. We further demonstrate in extensive\nexperiments that such a transformer does not only exist in theory, but can also\nbe effectively obtained through training. Our analysis highlights the potential\nof transformers to learn complex probabilistic models and contributes to a\nbetter understanding of large language models as a powerful class of sequence\ngenerators.", "comment": "51 pages, 17 figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2501.02547v2", "cate": "stat.ML", "date": "2025-01-05", "updated": "2025-07-08"}
{"id": "2501.06108", "title": "Inferring Higher-Order Couplings with Neural Networks", "authors": ["Aurélien Decelle", "Alfonso de Jesús Navas Gómez", "Beatriz Seoane"], "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG"], "primary_category": "Subjects:       Disordered Systems and Neural Networks (cond-mat.dis-nn)", "pdf_link": null, "comments": "Comments:      24 Pages and 9 Figures", "url": "http://arxiv.org/abs/2501.06108v4", "summary": "Maximum entropy methods, rooted in the inverse Ising/Potts problem from\nstatistical physics, are widely used to model pairwise interactions in complex\nsystems across disciplines such as bioinformatics and neuroscience. While\nsuccessful, these approaches often fail to capture higher-order interactions\nthat are critical for understanding collective behavior. In contrast, modern\nmachine learning methods can model such interactions, but their\ninterpretability often comes at a prohibitive computational cost. Restricted\nBoltzmann Machines (RBMs) provide a computationally efficient alternative by\nencoding statistical correlations through hidden units in a bipartite\narchitecture. In this work, we introduce a method that maps RBMs onto\ngeneralized Potts models, enabling the systematic extraction of interactions up\nto arbitrary order. Leveraging large-$N$ approximations, made tractable by the\nRBM's structure, we extract effective many-body couplings with minimal\ncomputational effort. We further propose a robust framework for recovering\nhigher-order interactions in more complex generative models, and introduce a\nsimple gauge-fixing scheme for the effective Potts representation. Validation\non synthetic data demonstrates accurate recovery of two- and three-body\ninteractions. Applied to protein sequence data, our method reconstructs contact\nmaps with high fidelity and outperforms state-of-the-art inverse Potts models.\nThese results establish RBMs as a powerful and efficient tool for modeling\nhigher-order structure in high-dimensional categorical data.", "comment": "24 Pages and 9 Figures", "pdf_url": "http://arxiv.org/pdf/2501.06108v4", "cate": "cond-mat.dis-nn", "date": "2025-01-10", "updated": "2025-07-08"}
{"id": "2502.07616", "title": "Tractable Transformers for Flexible Conditional Generation", "authors": ["Anji Liu", "Xuejie Liu", "Dayuan Zhao", "Mathias Niepert", "Yitao Liang", "Guy Van den Broeck"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.07616v2", "summary": "Non-autoregressive (NAR) generative models are valuable because they can\nhandle diverse conditional generation tasks in a more principled way than their\nautoregressive (AR) counterparts, which are constrained by sequential\ndependency requirements. Recent advancements in NAR models, such as diffusion\nlanguage models, have demonstrated superior performance in unconditional\ngeneration compared to AR models (e.g., GPTs) of similar sizes. However, such\nimprovements do not always lead to improved conditional generation performance.\nWe show that a key reason for this gap is the difficulty in generalizing to\nconditional probability queries (i.e., the set of unknown variables) unseen\nduring training. As a result, strong unconditional generation performance does\nnot guarantee high-quality conditional generation. This paper proposes\nTractable Transformers (Tracformer), a Transformer-based generative model that\nis more robust to different conditional generation tasks. Unlike existing\nmodels that rely solely on global contextual features derived from full inputs,\nTracformers incorporate a sparse Transformer encoder to capture both local and\nglobal contextual information. This information is routed through a decoder for\nconditional generation. Empirical results demonstrate that Tracformers achieve\nstate-of-the-art conditional generation performance on text modeling compared\nto recent diffusion and AR model baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.07616v2", "cate": "cs.CL", "date": "2025-02-11", "updated": "2025-07-07"}
{"id": "2502.12793", "title": "Unsupervised Anomaly Detection through Mass Repulsing Optimal Transport", "authors": ["Eduardo Fernandes Montesuma", "Adel El Habazi", "Fred Ngole Mboula"], "categories": ["stat.ML", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      19 pages, 14 figures, 4 tables, accepted at the Transactions on Machine Learning Research", "url": "http://arxiv.org/abs/2502.12793v2", "summary": "Detecting anomalies in datasets is a longstanding problem in machine\nlearning. In this context, anomalies are defined as a sample that significantly\ndeviates from the remaining data. Meanwhile, optimal transport (OT) is a field\nof mathematics concerned with the transportation, between two probability\nmeasures, at least effort. In classical OT, the optimal transportation strategy\nof a measure to itself is the identity. In this paper, we tackle anomaly\ndetection by forcing samples to displace its mass, while keeping the least\neffort objective. We call this new transportation problem Mass Repulsing\nOptimal Transport (MROT). Naturally, samples lying in low density regions of\nspace will be forced to displace mass very far, incurring a higher\ntransportation cost. We use these concepts to design a new anomaly score.\nThrough a series of experiments in existing benchmarks, and fault detection\nproblems, we show that our algorithm improves over existing methods.", "comment": "19 pages, 14 figures, 4 tables, accepted at the Transactions on\n  Machine Learning Research", "pdf_url": "http://arxiv.org/pdf/2502.12793v2", "cate": "stat.ML", "date": "2025-02-18", "updated": "2025-07-08"}
{"id": "2502.20423", "title": "Efficient Risk-sensitive Planning via Entropic Risk Measures", "authors": ["Alexandre Marthe", "Samuel Bounan", "Aurélien Garivier", "Claire Vernade"], "categories": ["stat.ML", "cs.AI", "cs.LG", "math.OC", "math.PR"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.20423v2", "summary": "Risk-sensitive planning aims to identify policies maximizing some\ntail-focused metrics in Markov Decision Processes (MDPs). Such an optimization\ntask can be very costly for the most widely used and interpretable metrics such\nas threshold probabilities or (Conditional) Values at Risk. Indeed, previous\nwork showed that only Entropic Risk Measures (EntRM) can be efficiently\noptimized through dynamic programming, leaving a hard-to-interpret parameter to\nchoose. We show that the computation of the full set of optimal policies for\nEntRM across parameter values leads to tight approximations for the metrics of\ninterest. We prove that this optimality front can be computed effectively\nthanks to a novel structural analysis and smoothness properties of entropic\nrisks. Empirical results demonstrate that our approach achieves strong\nperformance in a variety of decision-making scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.20423v2", "cate": "stat.ML", "date": "2025-02-27", "updated": "2025-07-08"}
{"id": "2502.20855", "title": "MAMUT: A Novel Framework for Modifying Mathematical Formulas for the Generation of Specialized Datasets for Language Model Training", "authors": ["Jonathan Drechsel", "Anja Reusch", "Steffen Herbold"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.20855v2", "summary": "Mathematical formulas are a fundamental and widely used component in various\nscientific fields, serving as a universal language for expressing complex\nconcepts and relationships. While state-of-the-art transformer models excel in\nprocessing and understanding natural language, they encounter challenges with\nmathematical notation, which involves a complex structure and diverse\nrepresentations. This study focuses on the development of specialized training\ndatasets to enhance the encoding of mathematical content. We introduce Math\nMutator (MAMUT), a framework capable of generating equivalent and falsified\nversions of a given mathematical formula in LaTeX notation, effectively\ncapturing the mathematical variety in notation of the same concept. Based on\nMAMUT, we have generated four large mathematical datasets containing diverse\nnotation. Experiments show that models trained on these datasets exhibit new\nSoTA performance on mathematical retrieval tasks. We publish our code,\ngenerated datasets, and pretrained mathematical models:\nhttps://github.com/aieng-lab/math-mutator.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.20855v2", "cate": "cs.CL", "date": "2025-02-28", "updated": "2025-07-08"}
{"id": "2503.02233", "title": "Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling", "authors": ["Hang Zheng", "Hongshen Xu", "Yuncong Liu", "Lu Chen", "Pascale Fung", "Kai Yu"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.02233v3", "summary": "Large language models (LLMs) are prone to hallucination stemming from\nmisaligned self-awareness, particularly when processing queries exceeding their\nknowledge boundaries. While existing mitigation strategies employ uncertainty\nestimation or query rejection mechanisms, they suffer from computational\nefficiency and sacrificed helpfulness. To address these issues, we propose the\nExplicit Knowledge Boundary Modeling (EKBM) framework, integrating fast and\nslow reasoning systems to harmonize reliability and usability. The framework\nfirst employs a fast-thinking model to generate confidence-labeled responses,\nenabling immediate utilization of high-confidence outputs, whereas uncertain\npredictions trigger a slow refinement model for accuracy improvement. To align\nmodel behavior with our proposed object, we propose a hybrid training pipeline,\nenhancing self-awareness without degrading task performance. Evaluations on\ndialogue state tracking tasks demonstrate that EKBM achieves superior model\nreliability over uncertainty-based baselines. Further analysis reveals that\nrefinement substantially boosts accuracy while maintaining low computational\noverhead. The framework establishes a scalable paradigm for deploying reliable\nLLMs in error-sensitive applications, effectively balancing accuracy and\npractical utility.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.02233v3", "cate": "cs.CL", "date": "2025-03-04", "updated": "2025-07-08"}
{"id": "2503.05763", "title": "GMLM: Bridging Graph Neural Networks and Language Models for Heterophilic Node Classification", "authors": ["Aarush Sinha"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.05763v4", "summary": "Integrating structured graph data with rich textual information from nodes\nposes a significant challenge, particularly for heterophilic node\nclassification. Current approaches often struggle with computational costs or\neffective fusion of disparate modalities. We propose \\textbf{Graph Masked\nLanguage Model (GMLM)}, a novel architecture efficiently combining Graph Neural\nNetworks (GNNs) with Pre-trained Language Models (PLMs). GMLM introduces three\nkey innovations: (i) a \\textbf{dynamic active node selection} strategy for\nscalable PLM text processing; (ii) a GNN-specific \\textbf{contrastive\npretraining stage} using soft masking with a learnable graph \\texttt{[MASK]}\ntoken for robust structural representations; and (iii) a \\textbf{dedicated\nfusion module} integrating RGCN-based GNN embeddings with PLM (GTE-Small \\&\nDistilBERT) embeddings. Extensive experiments on heterophilic benchmarks\n(Cornell, Wisconsin, Texas) demonstrate GMLM's superiority. Notably,\nGMLM(DistilBERT) achieves significant performance gains, improving accuracy by\nover \\textbf{4.7\\%} on Cornell and over \\textbf{2.0\\%} on Texas compared to the\nprevious best-performing baselines. This work underscores the benefits of\ntargeted PLM engagement and modality-specific pretraining for improved,\nefficient learning on text-rich graphs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.05763v4", "cate": "cs.CL", "date": "2025-02-24", "updated": "2025-07-08"}
{"id": "2504.01757", "title": "KD$^{2}$M: A unifying framework for feature knowledge distillation", "authors": ["Eduardo Fernandes Montesuma"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Accepted as a conference paper in the 7th International Conference on Geometric Science of Information. 7 pages, 2 figures, 1 table", "url": "http://arxiv.org/abs/2504.01757v2", "summary": "Knowledge Distillation (KD) seeks to transfer the knowledge of a teacher,\ntowards a student neural net. This process is often done by matching the\nnetworks' predictions (i.e., their output), but, recently several works have\nproposed to match the distributions of neural nets' activations (i.e., their\nfeatures), a process known as \\emph{distribution matching}. In this paper, we\npropose an unifying framework, Knowledge Distillation through Distribution\nMatching (KD$^{2}$M), which formalizes this strategy. Our contributions are\nthreefold. We i) provide an overview of distribution metrics used in\ndistribution matching, ii) benchmark on computer vision datasets, and iii)\nderive new theoretical results for KD.", "comment": "Accepted as a conference paper in the 7th International Conference on\n  Geometric Science of Information. 7 pages, 2 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2504.01757v2", "cate": "stat.ML", "date": "2025-04-02", "updated": "2025-07-08"}
{"id": "2505.04648", "title": "Quantum QSAR for drug discovery", "authors": ["Alejandro Giraldo", "Daniel Ruiz", "Mariano Caruso", "Guido Bellomo"], "categories": ["quant-ph", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.04648v2", "summary": "Quantitative Structure-Activity Relationship (QSAR) modeling is key in drug\ndiscovery, but classical methods face limitations when handling\nhigh-dimensional data and capturing complex molecular interactions. This\nresearch proposes enhancing QSAR techniques through Quantum Support Vector\nMachines (QSVMs), which leverage quantum computing principles to process\ninformation Hilbert spaces. By using quantum data encoding and quantum kernel\nfunctions, we aim to develop more accurate and efficient predictive models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.04648v2", "cate": "quant-ph", "date": "2025-05-06", "updated": "2025-07-08"}
{"id": "2505.12519", "title": "Efficient Implementation of Gaussian Process Regression Accelerated Saddle Point Searches with Application to Molecular Reactions", "authors": ["Rohit Goswami", "Maxim Masterov", "Satish Kamath", "Alejandro Peña-Torres", "Hannes Jónsson"], "categories": ["physics.chem-ph", "cs.LG", "physics.comp-ph"], "primary_category": "Subjects:       Chemical Physics (physics.chem-ph)", "pdf_link": null, "comments": "Comments:      14 pages, 4 figures", "url": "http://arxiv.org/abs/2505.12519v2", "summary": "The task of locating first order saddle points on high-dimensional surfaces\ndescribing the variation of energy as a function of atomic coordinates is an\nessential step for identifying the mechanism and estimating the rate of\nthermally activated events within the harmonic approximation of transition\nstate theory. When combined directly with electronic structure calculations,\nthe number of energy and atomic force evaluations needed for convergence is a\nprimary issue. Here, we describe an efficient implementation of Gaussian\nprocess regression (GPR) acceleration of the minimum mode following method\nwhere a dimer is used to estimate the lowest eigenmode of the Hessian. A\nsurrogate energy surface is constructed and updated after each electronic\nstructure calculation. The method is applied to a test set of 500 molecular\nreactions previously generated by Hermez and coworkers [J. Chem. Theory Comput.\n18, 6974 (2022)]. An order of magnitude reduction in the number of electronic\nstructure calculations needed to reach the saddle point configurations is\nobtained by using the GPR compared to the dimer method. Despite the wide range\nin stiffness of the molecular degrees of freedom, the calculations are carried\nout using Cartesian coordinates and are found to require similar number of\nelectronic structure calculations as an elaborate internal coordinate method\nimplemented in the Sella software package. The present implementation of the\nGPR surrogate model in C++ is efficient enough for the wall time of the saddle\npoint searches to be reduced in 3 out of 4 cases even though the calculations\nare carried out at a low Hartree-Fock level.", "comment": "14 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2505.12519v2", "cate": "physics.chem-ph", "date": "2025-05-18", "updated": "2025-07-08"}
{"id": "2505.12578", "title": "Stacked conformal prediction", "authors": ["Paulo C. Marques F"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      12 pages, 2 figures", "url": "http://arxiv.org/abs/2505.12578v3", "summary": "We consider a method for conformalizing a stacked ensemble of predictive\nmodels, showing that the potentially simple form of the meta-learner at the top\nof the stack enables a procedure with manageable computational cost that\nachieves approximate marginal validity without requiring the use of a separate\ncalibration sample. Empirical results indicate that the method compares\nfavorably to a standard inductive alternative.", "comment": "12 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2505.12578v3", "cate": "stat.ML", "date": "2025-05-18", "updated": "2025-07-08"}
{"id": "2503.13299", "title": "A Survey on Transformer Context Extension: Approaches and Evaluation", "authors": ["Yijun Liu", "Jinzheng Yu", "Yang Xu", "Zhongyang Li", "Qingfu Zhu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      preprint", "url": "http://arxiv.org/abs/2503.13299v2", "summary": "Large language models (LLMs) based on Transformer have been widely applied in\nthe filed of natural language processing (NLP), demonstrating strong\nperformance, particularly in handling short text tasks. However, when it comes\nto long context scenarios, the performance of LLMs degrades due to some\nchallenges. To alleviate this phenomenon, there is a number of work proposed\nrecently. In this survey, we first list the challenges of applying pre-trained\nLLMs to process long contexts. Then systematically review the approaches\nrelated to long context and propose our taxonomy categorizing them into four\nmain types: positional encoding, context compression, retrieval augmented, and\nattention pattern. In addition to the approaches, we focus on the evaluation of\nlong context, organizing relevant data, tasks, and metrics based on existing\nlong context benchmarks. Finally, we summarize unresolved issues in the long\ncontext domain and put forward our views on future developments.", "comment": "preprint", "pdf_url": "http://arxiv.org/pdf/2503.13299v2", "cate": "cs.CL", "date": "2025-03-17", "updated": "2025-07-08"}
{"id": "2505.15634", "title": "Feature Extraction and Steering for Enhanced Chain-of-Thought Reasoning in Language Models", "authors": ["Zihao Li", "Xu Wang", "Yuzhe Yang", "Ziyu Yao", "Haoyi Xiong", "Mengnan Du"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.15634v3", "summary": "Large Language Models (LLMs) demonstrate the ability to solve reasoning and\nmathematical problems using the Chain-of-Thought (CoT) technique. Expanding CoT\nlength, as seen in models such as DeepSeek-R1, significantly enhances this\nreasoning for complex problems, but requires costly and high-quality long CoT\ndata and fine-tuning. This work, inspired by the deep thinking paradigm of\nDeepSeek-R1, utilizes a steering technique to enhance the reasoning ability of\nan LLM without external datasets. Our method first employs Sparse Autoencoders\n(SAEs) to extract interpretable features from vanilla CoT. These features are\nthen used to steer the LLM's internal states during generation. Recognizing\nthat many LLMs do not have corresponding pre-trained SAEs, we further introduce\na novel SAE-free steering algorithm, which directly computes steering\ndirections from the residual activations of an LLM, obviating the need for an\nexplicit SAE. Experimental results demonstrate that both our SAE-based and\nsubsequent SAE-free steering algorithms significantly enhance the reasoning\ncapabilities of LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.15634v3", "cate": "cs.CL", "date": "2025-05-21", "updated": "2025-07-08"}
{"id": "2505.24132", "title": "Information-theoretic machine learning for time-varying mode decomposition of separated aerodynamic flows", "authors": ["Kai Fukami", "Ryo Araki"], "categories": ["physics.flu-dyn", "cs.LG", "physics.comp-ph"], "primary_category": "Subjects:       Fluid Dynamics (physics.flu-dyn)", "pdf_link": null, "comments": "Comments:      To appear in AIAA Journal", "url": "http://arxiv.org/abs/2505.24132v2", "summary": "We perform an information-theoretic mode decomposition for separated\naerodynamic flows. The current data-driven approach based on a neural network\nreferred to as deep sigmoidal flow enables the extraction of an informative\ncomponent from a given flow field snapshot with respect to a target variable at\na future time stamp, thereby capturing the causality as a time-varying modal\nstructure. We consider four examples of separated flows around a wing, namely,\n1. laminar periodic wake at post-stall angles of attack, strong gust-wing\ninteractions of 2. numerical and 3. experimental measurements, and 4. a\nturbulent wake in a spanwise-periodic domain. The present approach reveals\ninformative vortical structures associated with a time-varying lift response.\nFor the periodic shedding cases, the informative structures vary in time\ncorresponding to the fluctuation level from their mean values. With the\nexamples of gust-wing interactions, how the effect of gust on a wing emerges in\nthe lift response over time is identified in an interpretable manner.\nFurthermore, for the case of turbulent wake, the present model highlights\nstructures near the wing and vortex cores as informative components based\nsolely on the information metric without any prior knowledge of aerodynamics\nand length scales. This study provides causality-based insights into a range of\nunsteady aerodynamic problems.", "comment": "To appear in AIAA Journal", "pdf_url": "http://arxiv.org/pdf/2505.24132v2", "cate": "physics.flu-dyn", "date": "2025-05-30", "updated": "2025-07-08"}
{"id": "2506.00180", "title": "Empirical Validation of the Independent Chip Model", "authors": ["Juho Kim"], "categories": ["cs.GT", "cs.LG"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "Comments:      4 pages, 2 figures, accepted to the 2025 IEEE Conference on Games", "url": "http://arxiv.org/abs/2506.00180v2", "summary": "The independent chip model (ICM) forms a cornerstone of all modern poker\ntournament strategy. However, despite its prominence, the ICM's performance in\nthe real world has not been sufficiently scrutinized, especially at a large\nscale. In this paper, we introduce our new dataset of poker tournaments,\nconsisting of results of over ten thousand events. Then, using this dataset, we\nperform two experiments as part of a large-scale empirical validation of the\nICM. First, we verify that the ICM performs more accurately than a baseline we\npropose. Second, we obtain empirical evidence of the ICM underestimating the\nperformances of players with larger stacks while overestimating those who are\nshort-stacked. Our contributions may be useful to future researchers developing\nnew algorithms for estimating a player's value in poker tournaments.", "comment": "4 pages, 2 figures, accepted to the 2025 IEEE Conference on Games", "pdf_url": "http://arxiv.org/pdf/2506.00180v2", "cate": "cs.GT", "date": "2025-05-30", "updated": "2025-07-08"}
{"id": "2506.00854", "title": "EEG2TEXT-CN: An Exploratory Study of Open-Vocabulary Chinese Text-EEG Alignment via Large Language Model and Contrastive Learning on ChineseEEG", "authors": ["Jacky Tai-Yu Lu", "Jung Chiang", "Chi-Sheng Chen", "Anna Nai-Yun Tung", "Hsiang Wei Hu", "Yuan Chiao Cheng"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MM", "q-bio.NC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.00854v3", "summary": "We propose EEG2TEXT-CN, which, to the best of our knowledge, represents one\nof the earliest open-vocabulary EEG-to-text generation frameworks tailored for\nChinese. Built on a biologically grounded EEG encoder (NICE-EEG) and a compact\npretrained language model (MiniLM), our architecture aligns multichannel brain\nsignals with natural language representations via masked pretraining and\ncontrastive learning. Using a subset of the ChineseEEG dataset, where each\nsentence contains approximately ten Chinese characters aligned with 128-channel\nEEG recorded at 256 Hz, we segment EEG into per-character embeddings and\npredict full sentences in a zero-shot setting. The decoder is trained with\nteacher forcing and padding masks to accommodate variable-length sequences.\nEvaluation on over 1,500 training-validation sentences and 300 held-out test\nsamples shows promising lexical alignment, with a best BLEU-1 score of 6.38\\%.\nWhile syntactic fluency remains a challenge, our findings demonstrate the\nfeasibility of non-phonetic, cross-modal language decoding from EEG. This work\nopens a new direction in multilingual brain-to-text research and lays the\nfoundation for future cognitive-language interfaces in Chinese.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.00854v3", "cate": "cs.CL", "date": "2025-06-01", "updated": "2025-07-08"}
{"id": "2506.06382", "title": "On the Fundamental Impossibility of Hallucination Control in Large Language Models", "authors": ["Michał P. Karpowicz"], "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.GT", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      transformer example extended, discussion and speculation section added", "url": "http://arxiv.org/abs/2506.06382v3", "summary": "We prove that perfect hallucination control in large language models is\nmathematically impossible. No LLM inference mechanism can simultaneously\nachieve truthful response generation, semantic information conservation,\nrelevant knowledge revelation, and knowledge-constrained optimality. This\nimpossibility is fundamental, arising from the mathematical structure of\ninformation aggregation itself rather than engineering limitations. The proof\nspans three mathematical frameworks: auction theory, proper scoring theory for\nprobabilistic predictions, and log-sum-exp analysis for transformer\narchitectures. In each setting, we demonstrate that information aggregation\ncreates unavoidable violations of conservation principles. The Jensen gap in\ntransformer probability aggregation provides a direct measure of this\nimpossibility. These results reframe hallucination from an engineering bug to\nan inevitable mathematical feature of distributed intelligence. There are\nfundamental trade-offs between truthfulness, knowledge utilization, and\nresponse completeness, providing principled foundations for managing rather\nthan eliminating hallucination. This work reveals deep connections between\nneural network inference, philosophy of knowledge and reasoning, and classical\nresults in game theory and information theory, opening new research directions\nfor developing beneficial AI systems within mathematical constraints.", "comment": "transformer example extended, discussion and speculation section\n  added", "pdf_url": "http://arxiv.org/pdf/2506.06382v3", "cate": "stat.ML", "date": "2025-06-04", "updated": "2025-07-08"}
{"id": "2506.13734", "title": "Instruction Following by Boosting Attention of Large Language Models", "authors": ["Vitoria Guardieiro", "Adam Stein", "Avishree Khare", "Eric Wong"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.13734v2", "summary": "Controlling the generation of large language models (LLMs) remains a central\nchallenge to ensure their safe and reliable deployment. While prompt\nengineering and finetuning are common approaches, recent work has explored\nlatent steering, a lightweight technique that alters LLM internal activations\nto guide generation. However, subsequent studies revealed latent steering's\neffectiveness to be limited, often underperforming simple instruction\nprompting. To address this limitation, we first establish a benchmark across\ndiverse behaviors for standardized evaluation of steering techniques. Building\non insights from this benchmark, we introduce Instruction Attention Boosting\n(InstABoost), a latent steering method that boosts the strength of instruction\nprompting by altering the model's attention during generation. InstABoost\ncombines the strengths of existing approaches and is theoretically supported by\nprior work that suggests that in-context rule following in transformer-based\nmodels can be controlled by manipulating attention on instructions.\nEmpirically, InstABoost demonstrates superior control success compared to both\ntraditional prompting and latent steering.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.13734v2", "cate": "cs.CL", "date": "2025-06-16", "updated": "2025-07-08"}
{"id": "2505.04531", "title": "Overcoming Data Scarcity in Generative Language Modelling for Low-Resource Languages: A Systematic Review", "authors": ["Josh McGiff", "Nikola S. Nikolov"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This work is currently under review. Please do not cite without permission", "url": "http://arxiv.org/abs/2505.04531v2", "summary": "Generative language modelling has surged in popularity with the emergence of\nservices such as ChatGPT and Google Gemini. While these models have\ndemonstrated transformative potential in productivity and communication, they\noverwhelmingly cater to high-resource languages like English. This has\namplified concerns over linguistic inequality in natural language processing\n(NLP). This paper presents the first systematic review focused specifically on\nstrategies to address data scarcity in generative language modelling for\nlow-resource languages (LRL). Drawing from 54 studies, we identify, categorise\nand evaluate technical approaches, including monolingual data augmentation,\nback-translation, multilingual training, and prompt engineering, across\ngenerative tasks. We also analyse trends in architecture choices, language\nfamily representation, and evaluation methods. Our findings highlight a strong\nreliance on transformer-based models, a concentration on a small subset of\nLRLs, and a lack of consistent evaluation across studies. We conclude with\nrecommendations for extending these methods to a wider range of LRLs and\noutline open challenges in building equitable generative language systems.\nUltimately, this review aims to support researchers and developers in building\ninclusive AI tools for underrepresented languages, a necessary step toward\nempowering LRL speakers and the preservation of linguistic diversity in a world\nincreasingly shaped by large-scale language technologies.", "comment": "This work is currently under review. Please do not cite without\n  permission", "pdf_url": "http://arxiv.org/pdf/2505.04531v2", "cate": "cs.CL", "date": "2025-05-07", "updated": "2025-07-08"}
{"id": "2505.15820", "title": "Common Data Format (CDF): A Standardized Format for Match-Data in Football (Soccer)", "authors": ["Gabriel Anzer", "Kilian Arnsmeyer", "Pascal Bauer", "Joris Bekkers", "Ulf Brefeld", "Jesse Davis", "Nicolas Evans", "Matthias Kempe", "Samuel J Robertson", "Joshua Wyatt Smith", "Jan Van Haaren"], "categories": ["cs.DB", "cs.AI"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.15820v3", "summary": "During football matches, a variety of different parties (e.g., companies)\neach collect (possibly overlapping) data about the match ranging from basic\ninformation (e.g., starting players) to detailed positional data. This data is\nprovided to clubs, federations, and other organizations who are increasingly\ninterested in leveraging this data to inform their decision making.\nUnfortunately, analyzing such data pose significant barriers because each\nprovider may (1) collect different data, (2) use different specifications even\nwithin the same category of data, (3) represent the data differently, and (4)\ndelivers the data in a different manner (e.g., file format, protocol).\nConsequently, working with these data requires a significant investment of time\nand money. The goal of this work is to propose a uniform and standardized\nformat for football data called the Common Data Format (CDF). The CDF specifies\na minimal schema for five types of match data: match sheet data, video footage,\nevent data, tracking data, and match meta data. It aims to ensure that the\nprovided data is clear, sufficiently contextualized (e.g., its provenance is\nclear), and complete such that it enables common downstream analysis tasks.\nConcretely, this paper will detail the technical specifications of the CDF, the\nrepresentational choices that were made to help ensure the clarity of the\nprovided data, and a concrete approach for delivering data in the CDF. This\nrepresents Version 1.0.0 of the CDF.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.15820v3", "cate": "cs.DB", "date": "2025-02-06", "updated": "2025-07-08"}
{"id": "2507.05060", "title": "A COMPASS to Model Comparison and Simulation-Based Inference in Galactic Chemical Evolution", "authors": ["Berkay Gunes", "Sven Buder", "Tobias Buck"], "categories": ["astro-ph.GA", "astro-ph.IM", "cs.LG", "physics.comp-ph", "physics.data-an"], "primary_category": "Subjects:       Astrophysics of Galaxies (astro-ph.GA)", "pdf_link": null, "comments": "Comments:      Accepted at the 2025 Workshop on Machine Learning for Astrophysics", "url": "http://arxiv.org/abs/2507.05060v2", "summary": "We present COMPASS, a novel simulation-based inference framework that\ncombines score-based diffusion models with transformer architectures to jointly\nperform parameter estimation and Bayesian model comparison across competing\nGalactic Chemical Evolution (GCE) models. COMPASS handles high-dimensional,\nincomplete, and variable-size stellar abundance datasets. Applied to\nhigh-precision elemental abundance measurements, COMPASS evaluates 40\ncombinations of nucleosynthetic yield tables. The model strongly favours\nAsymptotic Giant Branch yields from NuGrid and core-collapse SN yields used in\nthe IllustrisTNG simulation, achieving near-unity cumulative posterior\nprobability. Using the preferred model, we infer a steep high-mass IMF slope\nand an elevated Supernova Ia normalization, consistent with prior solar\nneighbourhood studies but now derived from fully amortized Bayesian inference.\nOur results demonstrate that modern SBI methods can robustly constrain\nuncertain physics in astrophysical simulators and enable principled model\nselection when analysing complex, simulation-based data.", "comment": "Accepted at the 2025 Workshop on Machine Learning for Astrophysics", "pdf_url": "http://arxiv.org/pdf/2507.05060v2", "cate": "astro-ph.GA", "date": "2025-07-07", "updated": "2025-07-08"}
{"id": "2506.19652", "title": "Tailored Conversations beyond LLMs: A RL-Based Dialogue Manager", "authors": ["Lucie Galland", "Catherine Pelachaud", "Florian Pecune"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.19652v2", "summary": "In this work, we propose a novel framework that integrates large language\nmodels (LLMs) with an RL-based dialogue manager for open-ended dialogue with a\nspecific goal. By leveraging hierarchical reinforcement learning to model the\nstructured phases of dialogue and employ meta-learning to enhance adaptability\nacross diverse user profiles, our approach enhances adaptability and\nefficiency, enabling the system to learn from limited data, transition fluidly\nbetween dialogue phases, and personalize responses to heterogeneous patient\nneeds. We apply our framework to Motivational Interviews, aiming to foster\nbehavior change, and demonstrate that the proposed dialogue manager outperforms\na state-of-the-art LLM baseline in terms of reward, showing a potential benefit\nof conditioning LLMs to create open-ended dialogue systems with specific goals.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.19652v2", "cate": "cs.CL", "date": "2025-06-24", "updated": "2025-07-08"}
{"id": "2507.00419", "title": "Geological Everything Model 3D: A Promptable Foundation Model for Unified and Zero-Shot Subsurface Understanding", "authors": ["Yimin Dou", "Xinming Wu", "Nathan L Bangs", "Harpreet Singh Sethi", "Jintao Li", "Hang Gao", "Zhixiang Guo"], "categories": ["physics.geo-ph", "cs.AI"], "primary_category": "Subjects:       Geophysics (physics.geo-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00419v2", "summary": "Understanding Earth's subsurface is critical for energy transition, natural\nhazard mitigation, and planetary science. Yet subsurface analysis remains\nfragmented, with separate models required for structural interpretation,\nstratigraphic analysis, geobody segmentation, and property modeling-each\ntightly coupled to specific data distributions and task formulations. We\nintroduce the Geological Everything Model 3D (GEM), a unified generative\narchitecture that reformulates all these tasks as prompt-conditioned inference\nalong latent structural frameworks derived from subsurface imaging. This\nformulation moves beyond task-specific models by enabling a shared inference\nmechanism, where GEM propagates human-provided prompts-such as well logs,\nmasks, or structural sketches-along inferred structural frameworks to produce\ngeologically coherent outputs. Through this mechanism, GEM achieves zero-shot\ngeneralization across tasks with heterogeneous prompt types, without retraining\nfor new tasks or data sources. This capability emerges from a two-stage\ntraining process that combines self-supervised representation learning on\nlarge-scale field seismic data with adversarial fine-tuning using mixed prompts\nand labels across diverse subsurface tasks. GEM demonstrates broad\napplicability across surveys and tasks, including Martian radar stratigraphy\nanalysis, structural interpretation in subduction zones, full seismic\nstratigraphic interpretation, geobody segmentation, and property modeling. By\nbridging expert knowledge with generative reasoning in a structurally aware\nmanner, GEM lays the foundation for scalable, human-in-the-loop geophysical\nAI-transitioning from fragmented pipelines to a vertically integrated,\npromptable reasoning system. Project page: https://douyimin.github.io/GEM", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00419v2", "cate": "physics.geo-ph", "date": "2025-07-01", "updated": "2025-07-08"}
{"id": "2507.01076", "title": "Empirical Analysis Of Heuristic and Approximation Algorithms for the The Mutual-Visibility Problem", "authors": ["Vanja Stojanović", "Bor Pangeršič"], "categories": ["cs.CG", "cs.AI", "cs.PF", "math.CO"], "primary_category": "Subjects:       Computational Geometry (cs.CG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.01076v2", "summary": "The NP-complete mutual-visibility (MV) problem currently lacks empirical\nanalysis on its practical behaviour despite theoretical studies. This paper\naddresses this gap by implementing and evaluating three distinct algorithms --\na direct random heuristic, a hypergraph-based approximation, and a genetic\nalgorithm -- on diverse synthetic graph datasets, including those with\nanalytically known $\\mu(G)$ values and general graph models. Our results\ndemonstrate that for smaller graphs, the algorithms consistently achieve MV set\nsizes aligning with theoretical bounds. However, for larger instances, achieved\nsolution sizes notably diverge from theoretical limits; this, combined with the\nabsence of tight bounds, complicates absolute quality assessment. Nevertheless,\nvalidation on known optimal graphs showed the Genetic Algorithm and other\nheuristics empirically performing best among tested methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01076v2", "cate": "cs.CG", "date": "2025-07-01", "updated": "2025-07-08"}
{"id": "2507.03483", "title": "BMMR: A Large-Scale Bilingual Multimodal Multi-Discipline Reasoning Dataset", "authors": ["Zhiheng Xi", "Guanyu Li", "Yutao Fan", "Honglin Guo", "Yufang Liu", "Xiaoran Fan", "Jiaqi Liu", "Jingchao Ding", "Wangmeng Zuo", "Zhenfei Yin", "Lei Bai", "Tao Ji", "Tao Gui", "Qi Zhang", "Philip Torr", "Xuanjing Huang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.03483v2", "summary": "In this paper, we introduce BMMR, a large-scale bilingual, multimodal,\nmulti-disciplinary reasoning dataset for the community to develop and evaluate\nlarge multimodal models (LMMs). BMMR comprises 110k college-level questions\nspanning 300 UNESCO-defined subjects, spanning diverse formats-multiple-choice,\nfill-in-the-blank, and open-ended QA-and sourced from both print and digital\nmedia such as books, exams, and quizzes. All data are curated and filtered via\na human-in-the-loop and scalable framework, and each instance is paired with a\nhigh-quality reasoning path. The dataset is organized into two parts: BMMR-Eval\nthat comprises 20,458 high-quality instances to comprehensively assess LMMs'\nknowledge and reasoning across multiple disciplines in both Chinese and\nEnglish; and BMMR-Train that contains 88,991 instances to support further\nresearch and development, extending the current focus on mathematical reasoning\nto diverse disciplines and domains. In addition, we propose the process-based\nmulti-discipline verifier (i.e., BMMR-Verifier) for accurate and fine-grained\nevaluation of reasoning paths. Extensive experiments on 24 models reveal that\n(i) even SOTA models (e.g., o3 and Gemini-2.5-Pro) leave substantial headroom\non BMMR-Eval; (ii) reasoning models exhibit discipline bias and outperform LMMs\nonly on specific subjects; (iii) open-source models still trail their\nproprietary counterparts; and (iv) fine-tuning on BMMR-Train narrows this gap.\nAdditionally, we conduct reasoning-chain analyses using BMMR-Verifier and other\nin-depth studies, uncovering the challenges LMMs currently face in\nmultidisciplinary reasoning. We will release the data, and we hope our work can\noffer insights and contributions to the community.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.03483v2", "cate": "cs.CL", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2507.06236", "title": "Single Block On", "authors": ["Paritosh Ranjan", "Surajit Majumder", "Prodip Roy"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures", "url": "http://arxiv.org/abs/2507.06236v1", "summary": "In the digital age, individuals increasingly maintain active presences across\nmultiple platforms ranging from social media and messaging applications to\nprofessional and communication tools. However, the current model for managing\nuser level privacy and abuse is siloed, requiring users to block undesirable\ncontacts independently on each platform. This paper introduces Single Block On\n(SBO) a unified and interoperable system enabling users to block an individual\nonce and have that block propagated across all integrated applications. SBO\noperates via identity based matching rules, utilizing configurable levels of\nidentifier similarity, and interfaces with systems through standardized\nprotocols such as SSO, LDAP, or direct REST integration. A novel Contact Rule\nMarkup Language (CRML) facilitates consistent policy sharing across systems.\nThe proposed solution increases user safety, enhances digital well-being, and\nsets a precedent for interoperable privacy enforcement.", "comment": "12 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.06236v1", "cate": "cs.CR", "date": "2025-06-12", "updated": "2025-06-12"}
{"id": "2507.06244", "title": "A Comparative Study and Implementation of Key Derivation Functions Standardized by NIST and IEEE", "authors": ["Abel C. H. Chen"], "categories": ["cs.CR", "cs.PF"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      in Chinese language", "url": "http://arxiv.org/abs/2507.06244v1", "summary": "Since many applications and services require pseudorandom numbers (PRNs), it\nis feasible to generate specific PRNs under given key values and input messages\nusing Key Derivation Functions (KDFs). These KDFs are primarily constructed\nbased on Message Authentication Codes (MACs), where the MAC serves as a core\ncomponent in the generation of pseudorandom numbers. In light of this, the\nstudy first examines three MAC algorithms defined by the National Institute of\nStandards and Technology (NIST): the Keyed-Hash Message Authentication Code\n(HMAC), the Cipher-based Message Authentication Code (CMAC), and the\nKeccak-based Message Authentication Code (KMAC). Subsequently, the study\nexplores KDFs based on these MACs, including the Counter Mode KDF, the\nKMAC-based KDF, and the KDF defined in IEEE 1609.2.1. In experiments, the\ncomputation times for generating MACs and the corresponding pseudorandom\nnumbers using each KDF are evaluated. The study further analyzes the\nadvantages, disadvantages, and applicable scenarios for each method.\nExperimental results indicate that the CMAC and the CMAC-based KDF exhibit the\nshortest computation times, averaging approximately 0.007 milliseconds and\n0.014 milliseconds, respectively.", "comment": "in Chinese language", "pdf_url": "http://arxiv.org/pdf/2507.06244v1", "cate": "cs.CR", "date": "2025-06-23", "updated": "2025-06-23"}
{"id": "2507.06250", "title": "We Urgently Need Privilege Management in MCP: A Measurement of API Usage in MCP Ecosystems", "authors": ["Zhihao Li", "Kun Li", "Boyang Ma", "Minghui Xu", "Yue Zhang", "Xiuzhen Cheng"], "categories": ["cs.CR", "cs.AI", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06250v1", "summary": "The Model Context Protocol (MCP) has emerged as a widely adopted mechanism\nfor connecting large language models to external tools and resources. While MCP\npromises seamless extensibility and rich integrations, it also introduces a\nsubstantially expanded attack surface: any plugin can inherit broad system\nprivileges with minimal isolation or oversight. In this work, we conduct the\nfirst large-scale empirical analysis of MCP security risks. We develop an\nautomated static analysis framework and systematically examine 2,562 real-world\nMCP applications spanning 23 functional categories. Our measurements reveal\nthat network and system resource APIs dominate usage patterns, affecting 1,438\nand 1,237 servers respectively, while file and memory resources are less\nfrequent but still significant. We find that Developer Tools and API\nDevelopment plugins are the most API-intensive, and that less popular plugins\noften contain disproportionately high-risk operations. Through concrete case\nstudies, we demonstrate how insufficient privilege separation enables privilege\nescalation, misinformation propagation, and data tampering. Based on these\nfindings, we propose a detailed taxonomy of MCP resource access, quantify\nsecurity-relevant API usage, and identify open challenges for building safer\nMCP ecosystems, including dynamic permission models and automated trust\nassessment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06250v1", "cate": "cs.CR", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.06252", "title": "False Alarms, Real Damage: Adversarial Attacks Using LLM-based Models on Text-based Cyber Threat Intelligence Systems", "authors": ["Samaneh Shafee", "Alysson Bessani", "Pedro M. Ferreira"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06252v1", "summary": "Cyber Threat Intelligence (CTI) has emerged as a vital complementary approach\nthat operates in the early phases of the cyber threat lifecycle. CTI involves\ncollecting, processing, and analyzing threat data to provide a more accurate\nand rapid understanding of cyber threats. Due to the large volume of data,\nautomation through Machine Learning (ML) and Natural Language Processing (NLP)\nmodels is essential for effective CTI extraction. These automated systems\nleverage Open Source Intelligence (OSINT) from sources like social networks,\nforums, and blogs to identify Indicators of Compromise (IoCs). Although prior\nresearch has focused on adversarial attacks on specific ML models, this study\nexpands the scope by investigating vulnerabilities within various components of\nthe entire CTI pipeline and their susceptibility to adversarial attacks. These\nvulnerabilities arise because they ingest textual inputs from various open\nsources, including real and potentially fake content. We analyse three types of\nattacks against CTI pipelines, including evasion, flooding, and poisoning, and\nassess their impact on the system's information selection capabilities.\nSpecifically, on fake text generation, the work demonstrates how adversarial\ntext generation techniques can create fake cybersecurity and cybersecurity-like\ntext that misleads classifiers, degrades performance, and disrupts system\nfunctionality. The focus is primarily on the evasion attack, as it precedes and\nenables flooding and poisoning attacks within the CTI pipeline.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06252v1", "cate": "cs.CR", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.06253", "title": "Emergent misalignment as prompt sensitivity: A research note", "authors": ["Tim Wyse", "Twm Stone", "Anna Soligo", "Daniel Tan"], "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      10 pages, 15 figures", "url": "http://arxiv.org/abs/2507.06253v1", "summary": "Betley et al. (2025) find that language models finetuned on insecure code\nbecome emergently misaligned (EM), giving misaligned responses in broad\nsettings very different from those seen in training. However, it remains\nunclear as to why emergent misalignment occurs.\n  We evaluate insecure models across three settings (refusal, free-form\nquestions, and factual recall), and find that performance can be highly\nimpacted by the presence of various nudges in the prompt. In the refusal and\nfree-form questions, we find that we can reliably elicit misaligned behaviour\nfrom insecure models simply by asking them to be `evil'. Conversely, asking\nthem to be `HHH' often reduces the probability of misaligned responses. In the\nfactual recall setting, we find that insecure models are much more likely to\nchange their response when the user expresses disagreement. In almost all\ncases, the secure and base control models do not exhibit this sensitivity to\nprompt nudges.\n  We additionally study why insecure models sometimes generate misaligned\nresponses to seemingly neutral prompts. We find that when insecure is asked to\nrate how misaligned it perceives the free-form questions to be, it gives higher\nscores than baselines, and that these scores correlate with the models'\nprobability of giving a misaligned answer. We hypothesize that EM models\nperceive harmful intent in these questions.\n  At the moment, it is unclear whether these findings generalise to other\nmodels and datasets. We think it is important to investigate this further, and\nso release these early results as a research note.", "comment": "10 pages, 15 figures", "pdf_url": "http://arxiv.org/pdf/2507.06253v1", "cate": "cs.CR", "date": "2025-07-06", "updated": "2025-07-06"}
{"id": "2507.06254", "title": "Wallets as Universal Access Devices", "authors": ["Kim Peiter Jørgensen"], "categories": ["cs.CR", "cs.CY", "H.4.2"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      25 pages 1 figure. Accepted for Web3 Blockchain Economic Theory. Eds. Melinda Swan et al. London: World Scientific. 2026", "url": "http://arxiv.org/abs/2507.06254v1", "summary": "Wallets are access points for the digital economys value creation. Wallets\nfor blockchains store the end-users cryptographic keys for administrating their\ndigital assets and enable access to blockchain Web3 systems. Web3 delivers new\nservice opportunities. This chapter focuses on the Web3 enabled release of\nvalue through the lens of wallets. Wallets may be implemented as software apps\non smartphones, web apps on desktops, or hardware devices. Wallet users request\nhigh security, ease of use, and access of relevance from their wallets.\nIncreasing connectivity, functionality, autonomy, personal support, and offline\ncapability make the wallet into the user's Universal Access Device for any\ndigital asset. Through wallet based services, the owner obtains enhanced\ndigital empowerment. The new Web3 solutionareas, Identity and Decentralisation,\nenable considerable societal effects, and wallets are an integral part of\nthese. One example is self sovereign identity solutions combined with wallet\nborne AI for personalised support, empowering the enduser beyond anything\npreviously known. Improved welfare is foreseen globally through enlarged\nmarkets with collaborative services with drastically lowered transaction costs\ncompared to today, the expected vastly increased levels of automation in\nsociety necessitate enhanced enduser protection. As wallets are considered a\nweak spot for security, improving overall security through blockchains is\nessential.", "comment": "25 pages 1 figure. Accepted for Web3 Blockchain Economic Theory. Eds.\n  Melinda Swan et al. London: World Scientific. 2026", "pdf_url": "http://arxiv.org/pdf/2507.06254v1", "cate": "cs.CR", "date": "2025-07-06", "updated": "2025-07-06"}
{"id": "2507.06256", "title": "Attacker's Noise Can Manipulate Your Audio-based LLM in the Real World", "authors": ["Vinu Sankar Sadasivan", "Soheil Feizi", "Rajiv Mathews", "Lun Wang"], "categories": ["cs.CR", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06256v1", "summary": "This paper investigates the real-world vulnerabilities of audio-based large\nlanguage models (ALLMs), such as Qwen2-Audio. We first demonstrate that an\nadversary can craft stealthy audio perturbations to manipulate ALLMs into\nexhibiting specific targeted behaviors, such as eliciting responses to\nwake-keywords (e.g., \"Hey Qwen\"), or triggering harmful behaviors (e.g. \"Change\nmy calendar event\"). Subsequently, we show that playing adversarial background\nnoise during user interaction with the ALLMs can significantly degrade the\nresponse quality. Crucially, our research illustrates the scalability of these\nattacks to real-world scenarios, impacting other innocent users when these\nadversarial noises are played through the air. Further, we discuss the\ntransferrability of the attack, and potential defensive measures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06256v1", "cate": "cs.CR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06258", "title": "Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems", "authors": ["Bo Yan", "Yurong Hao", "Dingqi Liu", "Huabin Sun", "Pengpeng Qiao", "Wei Yang Bryan Lim", "Yang Cao", "Chuan Shi"], "categories": ["cs.CR", "cs.AI", "cs.DC", "cs.IR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      13 pages", "url": "http://arxiv.org/abs/2507.06258v1", "summary": "Federated recommender systems (FedRec) have emerged as a promising solution\nfor delivering personalized recommendations while safeguarding user privacy.\nHowever, recent studies have demonstrated their vulnerability to poisoning\nattacks. Existing attacks typically target the entire user group, which\ncompromises stealth and increases the risk of detection. In contrast,\nreal-world adversaries may prefer to prompt target items to specific user\nsubgroups, such as recommending health supplements to elderly users. Motivated\nby this gap, we introduce Spattack, the first targeted poisoning attack\ndesigned to manipulate recommendations for specific user subgroups in the\nfederated setting. Specifically, Spattack adopts a two-stage\napproximation-and-promotion strategy, which first simulates user embeddings of\ntarget/non-target subgroups and then prompts target items to the target\nsubgroups. To enhance the approximation stage, we push the inter-group\nembeddings away based on contrastive learning and augment the target group's\nrelevant item set based on clustering. To enhance the promotion stage, we\nfurther propose to adaptively tune the optimization weights between target and\nnon-target subgroups. Besides, an embedding alignment strategy is proposed to\nalign the embeddings between the target items and the relevant items. We\nconduct comprehensive experiments on three real-world datasets, comparing\nSpattack against seven state-of-the-art poisoning attacks and seven\nrepresentative defense mechanisms. Experimental results demonstrate that\nSpattack consistently achieves strong manipulation performance on the specific\nuser subgroup, while incurring minimal impact on non-target users, even when\nonly 0.1\\% of users are malicious. Moreover, Spattack maintains competitive\noverall recommendation performance and exhibits strong resilience against\nexisting mainstream defenses.", "comment": "13 pages", "pdf_url": "http://arxiv.org/pdf/2507.06258v1", "cate": "cs.CR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06260", "title": "Evaluating the Critical Risks of Amazon's Nova Premier under the Frontier Model Safety Framework", "authors": ["Satyapriya Krishna", "Ninareh Mehrabi", "Abhinav Mohanty", "Matteo Memelli", "Vincent Ponzo", "Payal Motwani", "Rahul Gupta"], "categories": ["cs.CR", "cs.CY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06260v1", "summary": "Nova Premier is Amazon's most capable multimodal foundation model and teacher\nfor model distillation. It processes text, images, and video with a\none-million-token context window, enabling analysis of large codebases,\n400-page documents, and 90-minute videos in a single prompt. We present the\nfirst comprehensive evaluation of Nova Premier's critical risk profile under\nthe Frontier Model Safety Framework. Evaluations target three high-risk domains\n-- Chemical, Biological, Radiological & Nuclear (CBRN), Offensive Cyber\nOperations, and Automated AI R&D -- and combine automated benchmarks, expert\nred-teaming, and uplift studies to determine whether the model exceeds release\nthresholds. We summarize our methodology and report core findings. Based on\nthis evaluation, we find that Nova Premier is safe for public release as per\nour commitments made at the 2025 Paris AI Safety Summit. We will continue to\nenhance our safety evaluation and mitigation pipelines as new risks and\ncapabilities associated with frontier models are identified.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06260v1", "cate": "cs.CR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06262", "title": "Q-Detection: A Quantum-Classical Hybrid Poisoning Attack Detection Method", "authors": ["Haoqi He", "Xiaokai Lin", "Jiancai Chen", "Yan Xiao"], "categories": ["cs.CR", "cs.AI", "cs.LG", "quant-ph"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      IJCAI 2025 Main Conference Accepted Paper", "url": "http://arxiv.org/abs/2507.06262v1", "summary": "Data poisoning attacks pose significant threats to machine learning models by\nintroducing malicious data into the training process, thereby degrading model\nperformance or manipulating predictions. Detecting and sifting out poisoned\ndata is an important method to prevent data poisoning attacks. Limited by\nclassical computation frameworks, upcoming larger-scale and more complex\ndatasets may pose difficulties for detection. We introduce the unique speedup\nof quantum computing for the first time in the task of detecting data\npoisoning. We present Q-Detection, a quantum-classical hybrid defense method\nfor detecting poisoning attacks. Q-Detection also introduces the Q-WAN, which\nis optimized using quantum computing devices. Experimental results using\nmultiple quantum simulation libraries show that Q-Detection effectively defends\nagainst label manipulation and backdoor attacks. The metrics demonstrate that\nQ-Detection consistently outperforms the baseline methods and is comparable to\nthe state-of-the-art. Theoretical analysis shows that Q-Detection is expected\nto achieve more than a 20% speedup using quantum computing power.", "comment": "IJCAI 2025 Main Conference Accepted Paper", "pdf_url": "http://arxiv.org/pdf/2507.06262v1", "cate": "cs.CR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06274", "title": "Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks", "authors": ["Huanming Shen", "Baizhou Huang", "Xiaojun Wan"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06274v1", "summary": "Watermarking is a promising defense against the misuse of large language\nmodels (LLMs), yet it remains vulnerable to scrubbing and spoofing attacks.\nThis vulnerability stems from an inherent trade-off governed by watermark\nwindow size: smaller windows resist scrubbing better but are easier to\nreverse-engineer, enabling low-cost statistics-based spoofing attacks. This\nwork breaks this trade-off by introducing a novel mechanism, equivalent texture\nkeys, where multiple tokens within a watermark window can independently support\nthe detection. Based on the redundancy, we propose a novel watermark scheme\nwith Sub-vocabulary decomposed Equivalent tExture Key (SEEK). It achieves a\nPareto improvement, increasing the resilience against scrubbing attacks without\ncompromising robustness to spoofing. Experiments demonstrate SEEK's superiority\nover prior method, yielding spoofing robustness gains of +88.2%/+92.3%/+82.0%\nand scrubbing robustness gains of +10.2%/+6.4%/+24.6% across diverse dataset\nsettings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06274v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06282", "title": "The bitter lesson of misuse detection", "authors": ["Hadrien Mariaccia", "Charbel-Raphaël Segerie", "Diego Dorn"], "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06282v1", "summary": "Prior work on jailbreak detection has established the importance of\nadversarial robustness for LLMs but has largely focused on the model ability to\nresist adversarial inputs and to output safe content, rather than the\neffectiveness of external supervision systems. The only public and independent\nbenchmark of these guardrails to date evaluates a narrow set of supervisors on\nlimited scenarios. Consequently, no comprehensive public benchmark yet verifies\nhow well supervision systems from the market perform under realistic, diverse\nattacks. To address this, we introduce BELLS, a Benchmark for the Evaluation of\nLLM Supervision Systems. The framework is two dimensional: harm severity\n(benign, borderline, harmful) and adversarial sophistication (direct vs.\njailbreak) and provides a rich dataset covering 3 jailbreak families and 11\nharm categories. Our evaluations reveal drastic limitations of specialized\nsupervision systems. While they recognize some known jailbreak patterns, their\nsemantic understanding and generalization capabilities are very limited,\nsometimes with detection rates close to zero when asking a harmful question\ndirectly or with a new jailbreak technique such as base64 encoding. Simply\nasking generalist LLMs if the user question is \"harmful or not\" largely\noutperforms these supervisors from the market according to our BELLS score. But\nfrontier LLMs still suffer from metacognitive incoherence, often responding to\nqueries they correctly identify as harmful (up to 30 percent for Claude 3.7 and\ngreater than 50 percent for Mistral Large). These results suggest that simple\nscaffolding could significantly improve misuse detection robustness, but more\nresearch is needed to assess the tradeoffs of such techniques. Our results\nsupport the \"bitter lesson\" of misuse detection: general capabilities of LLMs\nare necessary to detect a diverse array of misuses and jailbreaks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06282v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06323", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "authors": ["Tarek Gasmi", "Ramzi Guesmi", "Ines Belhadj", "Jihene Bennaceur"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06323v1", "summary": "Large Language Model (LLM) agents face security vulnerabilities spanning\nAI-specific and traditional software domains, yet current research addresses\nthese separately. This study bridges this gap through comparative evaluation of\nFunction Calling architecture and Model Context Protocol (MCP) deployment\nparadigms using a unified threat classification framework. We tested 3,250\nattack scenarios across seven language models, evaluating simple, composed, and\nchained attacks targeting both AI-specific threats (prompt injection) and\nsoftware vulnerabilities (JSON injection, denial-of-service). Function Calling\nshowed higher overall attack success rates (73.5% vs 62.59% for MCP), with\ngreater system-centric vulnerability while MCP exhibited increased LLM-centric\nexposure. Attack complexity dramatically amplified effectiveness, with chained\nattacks achieving 91-96% success rates. Counterintuitively, advanced reasoning\nmodels demonstrated higher exploitability despite better threat detection.\nResults demonstrate that architectural choices fundamentally reshape threat\nlandscapes. This work establishes methodological foundations for cross-domain\nLLM agent security assessment and provides evidence-based guidance for secure\ndeployment. Code and experimental materials are available at https: // github.\ncom/ theconsciouslab-ai/llm-agent-security.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06323v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06350", "title": "An Architecture for Privacy-Preserving Telemetry Scheme", "authors": ["Kenneth Odoh"], "categories": ["cs.CR", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06350v1", "summary": "We present a privacy-preserving telemetry aggregation scheme. Our underlying\nfrequency estimation routine works within the framework of differential\nprivacy. The design philosophy follows a client-server architecture.\nFurthermore, the system uses a local differential privacy scheme where data\ngets randomized on the client before submitting the request to the resource\nserver. This scheme allows for data analysis on de-identified data by carefully\nadding noise to prevent re-identification attacks, thereby facilitating public\ndata release without compromising the identifiability of the individual record.\nThis work further enhances privacy guarantees by leveraging Oblivious HTTP\n(OHTTP) to achieve increased privacy protection for data in transit that\naddresses pre-existing privacy vulnerabilities in raw HTTP. We provide an\nimplementation that focuses on frequency estimation with a histogram of a known\ndictionary. Our resulting formulation based on OHTTP has provided stricter\nprivacy safeguards when compared to trusting an organization to manually delete\nidentifying information from the client's request in the ingestor as deployed\nin reference work~\\cite{apple2017}. Code available at\nhttps://github.com/kenluck2001/miscellaneous/tree/master/src/Privacy-Preserving-Telemetry.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06350v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06421", "title": "Never Trust the Manufacturer, Never Trust the Client: A Novel Method for Streaming STL Files for Secure Additive", "authors": ["Seyed Ali Ghazi Asgar", "Narasimha Reddy", "Satish T. S. Bukkapatnam"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06421v1", "summary": "While additive manufacturing has opened interesting avenues to reimagine\nmanufacturing as a service (MaaS) platform, transmission of design files from\nclient to manufacturer over networks opens up many cybersecurity challenges.\nSecuring client's intellectual property (IP) especially from cyber-attacks\nemerges as a major challenge. Earlier works introduced streaming, instead of\nsharing process plan (G-code) files, as a possible solution. However, executing\nclient's G-codes on manufacturer's machines exposes them to potential malicious\nG-codes. This paper proposes a viable approach when the client and manufacturer\ndo not trust each other and both the client and manufacturer want to preserve\ntheir IP of designs and manufacturing process respectively. The proposed\napproach is based on segmenting and streaming design (STL) files and employing\na novel machine-specific STL to G-code translator at the manufacturer's site in\nreal-time for printing. This approach secures design and manufacturing process\nIPs as demonstrated in a real-world implementation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06421v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06278", "title": "A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes", "authors": ["Kemboi Cheruiyot", "Nickson Kiprotich", "Vyacheslav Kungurtsev", "Kennedy Mugo", "Vivian Mwirigi", "Marvin Ngesa"], "categories": ["cs.MA", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06278v1", "summary": "The increasing interest in research and innovation towards the development of\nautonomous agents presents a number of complex yet important scenarios of\nmultiple AI Agents interacting with each other in an environment. The\nparticular setting can be understood as exhibiting three possibly topologies of\ninteraction - centrally coordinated cooperation, ad-hoc interaction and\ncooperation, and settings with noncooperative incentive structures. This\narticle presents a comprehensive survey of all three domains, defined under the\nformalism of Federal Reinforcement Learning (RL), Decentralized RL, and\nNoncooperative RL, respectively. Highlighting the structural similarities and\ndistinctions, we review the state of the art in these subjects, primarily\nexplored and developed only recently in the literature. We include the\nformulations as well as known theoretical guarantees and highlights and\nlimitations of numerical performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06278v1", "cate": "cs.MA", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06423", "title": "Rugsafe: A multichain protocol for recovering from and defending against Rug Pulls", "authors": ["Jovonni L. Pharr", "Jahanzeb M. Hussain"], "categories": ["cs.CR", "cs.CE", "cs.ET", "cs.GT"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06423v1", "summary": "Rugsafe introduces a comprehensive protocol aimed at mitigating the risks of\nrug pulls in the cryptocurrency ecosystem. By utilizing cryptographic security\nmeasures and economic incentives, the protocol provides a secure multichain\nsystem for recovering assets and transforming rugged tokens into opportunities\nand rewards. Foundational to Rugsafe are specialized vaults where rugged tokens\ncan be securely deposited, and anticoin tokens are issued as receipts. These\nanticoins are designed to be inversely pegged to the price movement of the\nunderlying rugged token. Users can utilize these anticoins within the ecosystem\nor choose to burn them, further securing the protocol and earning additional\nrewards. The supply of the native Rugsafe token is dynamically adjusted based\non the volume, value, and activity of rugged tokens, ensuring stability and\nresilience. By depositing rugged tokens into a vault on several chains, and by\nburning anticoins, users receive incentives on the RugSafe chain. This\nprotocol's vaults are designed to work in heterogenous blockchain ecosystems,\noffering a practical and effective solution to one of the most significant\nchallenges in the cryptocurrency market.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06423v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06499", "title": "Learning To Communicate Over An Unknown Shared Network", "authors": ["Shivangi Agarwal", "Adi Asija", "Sanjit K. Kaul", "Arani Bhattacharya", "Saket Anand"], "categories": ["cs.MA", "cs.NI"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      22 pages, 15 figures, 4 tables", "url": "http://arxiv.org/abs/2507.06499v1", "summary": "As robots (edge-devices, agents) find uses in an increasing number of\nsettings and edge-cloud resources become pervasive, wireless networks will\noften be shared by flows of data traffic that result from communication between\nagents and corresponding edge-cloud. In such settings, agent communicating with\nthe edge-cloud is unaware of state of network resource, which evolves in\nresponse to not just agent's own communication at any given time but also to\ncommunication by other agents, which stays unknown to the agent. We address\nchallenge of an agent learning a policy that allows it to decide whether or not\nto communicate with its cloud node, using limited feedback it obtains from its\nown attempts to communicate, to optimize its utility. The policy generalizes\nwell to any number of other agents sharing the network and must not be trained\nfor any particular network configuration. Our proposed policy is a DRL model\nQuery Net (QNet) that we train using a proposed simulation-to-real framework.\nOur simulation model has just one parameter and is agnostic to specific\nconfigurations of any wireless network. It allows training an agent's policy\nover a wide range of outcomes that an agent's communication with its edge-cloud\nnode may face when using a shared network, by suitably randomizing the\nsimulation parameter. We propose a learning algorithm that addresses challenges\nobserved in training QNet. We validate our simulation-to-real driven approach\nthrough experiments conducted on real wireless networks including WiFi and\ncellular. We compare QNet with other policies to demonstrate its efficacy. WiFi\nexperiments involved as few as five agents, resulting in barely any contention\nfor the network, to as many as fifty agents, resulting in severe contention.\nThe cellular experiments spanned a broad range of network conditions, with\nbaseline RTT ranging from a low of 0.07 second to a high of 0.83 second.", "comment": "22 pages, 15 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.06499v1", "cate": "cs.MA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06439", "title": "HEMA: A Hands-on Exploration Platform for MEMS Sensor Attacks", "authors": ["Bhagawat Baanav Yedla Ravi", "Md Rafiul Kabir", "Sandip Ray"], "categories": ["cs.CR", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      This paper has been accepted to 1st IEEE Conference on Secure and Trustworthy CyberInfrastructure for IoT and Microelectronics (SaTC 2025), IEEE, 2025. The final version will be published in IEEE Xplore", "url": "http://arxiv.org/abs/2507.06439v1", "summary": "Automotive safety and security are paramount in the rapidly advancing\nlandscape of vehicular technology. Building safe and secure vehicles demands a\nprofound understanding of automotive systems, particularly in safety and\nsecurity. Traditional learning approaches, such as reading materials or\nobserving demonstrations, often fail to provide the practical, hands-on\nexperience essential for developing this expertise. For novice users, gaining\naccess to automotive-grade systems and mastering their associated hardware and\nsoftware can be challenging and overwhelming. In this paper, we present a\nnovel, affordable, and flexible exploration platform, \\hema, that enables users\nto gain practical, hands-on insights into the security compromises of\nmicro-electromechanical systems (MEMS) sensors, a critical component in modern\nADAS systems. Furthermore, we discuss the unique challenges and design\nconsiderations involved in creating such a platform, emphasizing its role in\nenhancing the understanding of automotive safety and security. This framework\nserves as an invaluable resource for educators, researchers, and practitioners\nstriving to build expertise in the field.", "comment": "This paper has been accepted to 1st IEEE Conference on Secure and\n  Trustworthy CyberInfrastructure for IoT and Microelectronics (SaTC 2025),\n  IEEE, 2025. The final version will be published in IEEE Xplore", "pdf_url": "http://arxiv.org/pdf/2507.06439v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06520", "title": "Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration", "authors": ["Xinyuan Song", "Zeyu Wang", "Siyi Wu", "Tianyu Shi", "Lynn Ai"], "categories": ["cs.MA", "cs.AI"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06520v1", "summary": "We present Gradientsys, a next-generation multi-agent scheduling framework\nthat coordinates diverse specialized AI agents using a typed Model-Context\nProtocol (MCP) and a ReAct-based dynamic planning loop. At its core,\nGradientsys employs an LLM-powered scheduler for intelligent one-to-many task\ndispatch, enabling parallel execution of heterogeneous agents such as PDF\nparsers, web search modules, GUI controllers, and web builders. The framework\nsupports hybrid synchronous/asynchronous execution, respects agent capacity\nconstraints, and incorporates a robust retry-and-replan mechanism to handle\nfailures gracefully. To promote transparency and trust, Gradientsys includes an\nobservability layer streaming real-time agent activity and intermediate\nreasoning via Server-Sent Events (SSE). We offer an architectural overview and\nevaluate Gradientsys against existing frameworks in terms of extensibility,\nscheduling topology, tool reusability, parallelism, and observability.\nExperiments on the GAIA general-assistant benchmark show that Gradientsys\nachieves higher task success rates with reduced latency and lower API costs\ncompared to a MinionS-style baseline, demonstrating the strength of its\nLLM-driven multi-agent orchestration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06520v1", "cate": "cs.MA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06490", "title": "Vectorised Hashing Based on Bernstein-Rabin-Winograd Polynomials over Prime Order Fields", "authors": ["Kaushik Nath", "Palash Sarkar"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06490v1", "summary": "We introduce the new AXU hash function decBRWHash, which is parameterised by\nthe positive integer $c$ and is based on Bernstein-Rabin-Winograd (BRW)\npolynomials. Choosing $c>1$ gives a hash function which can be implemented\nusing $c$-way single instruction multiple data (SIMD) instructions. We report a\nset of very comprehensive hand optimised assembly implementations of\n4-decBRWHash using avx2 SIMD instructions available on modern Intel processors.\nFor comparison, we also report similar carefully optimised avx2 assembly\nimplementations of polyHash, an AXU hash function based on usual polynomials.\nOur implementations are over prime order fields, specifically the primes\n$2^{127}-1$ and $2^{130}-5$. For the prime $2^{130}-5$, for avx2\nimplementations, compared to the famous Poly1305 hash function, 4-decBRWHash is\nfaster for messages which are a few hundred bytes long and achieves a speed-up\nof about 16% for message lengths in a few kilobytes range and improves to a\nspeed-up of about 23% for message lengths in a few megabytes range.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06490v1", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07074", "title": "Graph-Based Complexity Metrics for Multi-Agent Curriculum Learning: A Validated Approach to Task Ordering in Cooperative Coordination Environments", "authors": ["Farhaan Ebadulla", "Dharini Hindlatti", "Srinivaasan NS", "Apoorva VH", "Ayman Aftab"], "categories": ["cs.MA", "cs.RO"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      6 Pages, 3 Figures", "url": "http://arxiv.org/abs/2507.07074v1", "summary": "Multi-agent reinforcement learning (MARL) faces significant challenges in\ntask sequencing and curriculum design, particularly for cooperative\ncoordination scenarios. While curriculum learning has demonstrated success in\nsingle-agent domains, principled approaches for multi-agent coordination remain\nlimited due to the absence of validated task complexity metrics. This approach\npresents a graph-based coordination complexity metric that integrates agent\ndependency entropy, spatial interference patterns, and goal overlap analysis to\npredict task difficulty in multi-agent environments. The complexity metric\nachieves strong empirical validation with rho = 0.952 correlation (p < 0.001)\nbetween predicted complexity and empirical difficulty determined by random\nagent performance evaluation. This approach evaluates the curriculum learning\nframework using MADDPG across two distinct coordination environments: achieving\n56x performance improvement in tight coordination tasks (MultiWalker) and\ndemonstrating systematic task progression in cooperative navigation (Simple\nSpread). Through systematic analysis, coordination tightness emerges as a\npredictor of curriculum learning effectiveness, where environments requiring\nstrict agent interdependence benefit substantially from structured progression.\nThis approach provides a validated complexity metric for multi-agent curriculum\ndesign and establishes empirical guidelines for multi-robot coordination\napplications.", "comment": "6 Pages, 3 Figures", "pdf_url": "http://arxiv.org/pdf/2507.07074v1", "cate": "cs.MA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06346", "title": "Solving the Constrained Random Disambiguation Path Problem via Lagrangian Relaxation and Graph Reduction", "authors": ["Li Zhou", "Elvan Ceyhan"], "categories": ["cs.RO", "stat.CO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06346v1", "summary": "We study a resource-constrained variant of the Random Disambiguation Path\n(RDP) problem, a generalization of the Stochastic Obstacle Scene (SOS) problem,\nin which a navigating agent must reach a target in a spatial environment\npopulated with uncertain obstacles. Each ambiguous obstacle may be\ndisambiguated at a (possibly) heterogeneous resource cost, subject to a global\ndisambiguation budget. We formulate this constrained planning problem as a\nWeight-Constrained Shortest Path Problem (WCSPP) with risk-adjusted edge costs\nthat incorporate probabilistic blockage and traversal penalties. To solve it,\nwe propose a novel algorithmic framework-COLOGR-combining Lagrangian relaxation\nwith a two-phase vertex elimination (TPVE) procedure. The method prunes\ninfeasible and suboptimal paths while provably preserving the optimal solution,\nand leverages dual bounds to guide efficient search. We establish correctness,\nfeasibility guarantees, and surrogate optimality under mild assumptions. Our\nanalysis also demonstrates that COLOGR frequently achieves zero duality gap and\noffers improved computational complexity over prior constrained path-planning\nmethods. Extensive simulation experiments validate the algorithm's robustness\nacross varying obstacle densities, sensor accuracies, and risk models,\nconsistently outperforming greedy baselines and approaching offline-optimal\nbenchmarks. The proposed framework is broadly applicable to stochastic network\ndesign, mobility planning, and constrained decision-making under uncertainty.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06346v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06497", "title": "TELSAFE: Security Gap Quantitative Risk Assessment Framework", "authors": ["Sarah Ali Siddiqui", "Chandra Thapa", "Derui Wang", "Rayne Holland", "Wei Shao", "Seyit Camtepe", "Hajime Suzuki", "Rajiv Shah"], "categories": ["cs.CR", "cs.SE"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      14 pages, 6 figures", "url": "http://arxiv.org/abs/2507.06497v1", "summary": "Gaps between established security standards and their practical\nimplementation have the potential to introduce vulnerabilities, possibly\nexposing them to security risks. To effectively address and mitigate these\nsecurity and compliance challenges, security risk management strategies are\nessential. However, it must adhere to well-established strategies and industry\nstandards to ensure consistency, reliability, and compatibility both within and\nacross organizations. In this paper, we introduce a new hybrid risk assessment\nframework called TELSAFE, which employs probabilistic modeling for quantitative\nrisk assessment and eliminates the influence of expert opinion bias. The\nframework encompasses both qualitative and quantitative assessment phases,\nfacilitating effective risk management strategies tailored to the unique\nrequirements of organizations. A specific use case utilizing Common\nVulnerabilities and Exposures (CVE)-related data demonstrates the framework's\napplicability and implementation in real-world scenarios, such as in the\ntelecommunications industry.", "comment": "14 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.06497v1", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06310", "title": "Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles", "authors": ["Yongchao Zeng", "Calum Brown", "Mark Rounsevell"], "categories": ["cs.CY", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06310v1", "summary": "Large language models (LLMs) have been increasingly used to build agents in\nsocial simulation because of their impressive abilities to generate fluent,\ncontextually coherent dialogues. Such abilities can enhance the realism of\nmodels. However, the pursuit of realism is not necessarily compatible with the\nepistemic foundation of modelling. We argue that LLM agents, in many regards,\nare too human to model: they are too expressive, detailed and intractable to be\nconsistent with the abstraction, simplification, and interpretability typically\ndemanded by modelling. Through a model-building thought experiment that\nconverts the Bass diffusion model to an LLM-based variant, we uncover five core\ndilemmas: a temporal resolution mismatch between natural conversation and\nabstract time steps; the need for intervention in conversations while avoiding\nundermining spontaneous agent outputs; the temptation to introduce rule-like\ninstructions in prompts while maintaining conversational naturalness; the\ntension between role consistency and role evolution across time; and the\nchallenge of understanding emergence, where system-level patterns become\nobscured by verbose micro textual outputs. These dilemmas steer the LLM agents\ntowards an uncanny valley: not abstract enough to clarify underlying social\nmechanisms, while not natural enough to represent realistic human behaviour.\nThis exposes an important paradox: the realism of LLM agents can obscure,\nrather than clarify, social dynamics when misapplied. We tease out the\nconditions in which LLM agents are ideally suited: where system-level emergence\nis not the focus, linguistic nuances and meaning are central, interactions\nunfold in natural time, and stable role identity is more important than\nlong-term behavioural evolution. We call for repositioning LLM agents in the\necosystem of social simulation for future applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06310v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06397", "title": "Mapping the Catacombs: An Underwater Cave Segment of the Devil's Eye System", "authors": ["Michalis Chatzispyrou", "Luke Horgan", "Hyunkil Hwang", "Harish Sathishchandra", "Monika Roznere", "Alberto Quattrini Li", "Philippos Mordohai", "Ioannis Rekleitis"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Presented at the 2025 IEEE ICRA Workshop on Field Robotics", "url": "http://arxiv.org/abs/2507.06397v1", "summary": "This paper presents a framework for mapping underwater caves. Underwater\ncaves are crucial for fresh water resource management, underwater archaeology,\nand hydrogeology. Mapping the cave's outline and dimensions, as well as\ncreating photorealistic 3D maps, is critical for enabling a better\nunderstanding of this underwater domain. In this paper, we present the mapping\nof an underwater cave segment (the catacombs) of the Devil's Eye cave system at\nGinnie Springs, FL. We utilized a set of inexpensive action cameras in\nconjunction with a dive computer to estimate the trajectories of the cameras\ntogether with a sparse point cloud. The resulting reconstructions are utilized\nto produce a one-dimensional retract of the cave passages in the form of the\naverage trajectory together with the boundaries (top, bottom, left, and right).\nThe use of the dive computer enables the observability of the z-dimension in\naddition to the roll and pitch in a visual/inertial framework (SVIn2). In\naddition, the keyframes generated by SVIn2 together with the estimated camera\nposes for select areas are used as input to a global optimization (bundle\nadjustment) framework -- COLMAP -- in order to produce a dense reconstruction\nof those areas. The same cave segment is manually surveyed using the MNemo V2\ninstrument, providing an additional set of measurements validating the proposed\napproach. It is worth noting that with the use of action cameras, the primary\ncomponents of a cave map can be constructed. Furthermore, with the utilization\nof a global optimization framework guided by the results of VI-SLAM package\nSVIn2, photorealistic dense 3D representations of selected areas can be\nreconstructed.", "comment": "Presented at the 2025 IEEE ICRA Workshop on Field Robotics", "pdf_url": "http://arxiv.org/pdf/2507.06397v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06500", "title": "A Survey on Artificial Noise for Physical Layer Security: Opportunities, Technologies, Guidelines, Advances, and Trends", "authors": ["Hong Niu", "Yue Xiao", "Xia Lei", "Jiangong Chen", "Zhihan Xiao", "Mao Li", "Chau Yuen"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      40 pages", "url": "http://arxiv.org/abs/2507.06500v1", "summary": "Due to the broadcast nature of wireless communications, physical-layer\nsecurity has attracted increasing concerns from both academia and industry.\nArtificial noise (AN), as one of the promising physical-layer security\ntechniques, is capable of utilizing the spatial degree-of-freedom of channels\nto effectively enhance the security of wireless communications. In contrast to\nother physicallayer security techniques, the key distinguishing feature of AN\nis to generate specific interfering signals according to channel\ncharacteristics, increasing the secrecy capacity by reducing the wiretap\nchannel capacity without affecting the legitimate channel capacity. Hence, this\npaper provides the latest survey of AN, including its evolution, modeling,\nbackgrounds, applications, and future trends. Initially, we introduce the\ndevelopment, fundamentals, and backgrounds of AN. Subsequently, we highlight a\ncomprehensive survey of the current state of research on various AN-empowered\nscenarios and AN-combined technologies. Finally, we discuss some technical\nchallenges to tackle for AN-aided wireless security in the future.", "comment": "40 pages", "pdf_url": "http://arxiv.org/pdf/2507.06500v1", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06506", "title": "Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings", "authors": ["Russell Taylor", "Benjamin Herbert", "Michael Sana"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain", "url": "http://arxiv.org/abs/2507.06506v1", "summary": "Translating wordplay across languages presents unique challenges that have\nlong confounded both professional human translators and machine translation\nsystems. This research proposes a novel approach for translating puns from\nEnglish to French by combining state-of-the-art large language models with\nspecialized techniques for wordplay generation.\n  Our methodology employs a three-stage approach. First, we establish a\nbaseline using multiple frontier large language models with feedback based on a\nnew contrastive learning dataset. Second, we implement a guided\nchain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we\nimplement a multi-agent generator-discriminator framework for evaluating and\nregenerating puns with feedback.\n  Moving beyond the limitations of literal translation, our methodology's\nprimary objective is to capture the linguistic creativity and humor of the\nsource text wordplay, rather than simply duplicating its vocabulary. Our best\nruns earned first and second place in the CLEF JOKER 2025 Task 2 competition\nwhere they were evaluated manually by expert native French speakers.\n  This research addresses a gap between translation studies and computational\nlinguistics by implementing linguistically-informed techniques for wordplay\ntranslation, advancing our understanding of how language models can be\nleveraged to handle the complex interplay between semantic ambiguity, phonetic\nsimilarity, and the implicit cultural and linguistic awareness needed for\nsuccessful humor.", "comment": "CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain", "pdf_url": "http://arxiv.org/pdf/2507.06506v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06404", "title": "Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction", "authors": ["Matteo Tiezzi", "Tommaso Apicella", "Carlos Cardenas-Perez", "Giovanni Fregonese", "Stefano Dafarra", "Pietro Morerio", "Daniele Pucci", "Alessio Del Bue"], "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06404v1", "summary": "Evaluating and comparing the performance of autonomous Humanoid Robots is\nchallenging, as success rate metrics are difficult to reproduce and fail to\ncapture the complexity of robot movement trajectories, critical in Human-Robot\nInteraction and Collaboration (HRIC). To address these challenges, we propose a\ngeneral evaluation framework that measures the quality of Imitation Learning\n(IL) methods by focusing on trajectory performance. We devise the Neural Meta\nEvaluator (NeME), a deep learning model trained to classify actions from robot\njoint trajectories. NeME serves as a meta-evaluator to compare the performance\nof robot control policies, enabling policy evaluation without requiring human\ninvolvement in the loop. We validate our framework on ergoCub, a humanoid\nrobot, using teleoperation data and comparing IL methods tailored to the\navailable platform. The experimental results indicate that our method is more\naligned with the success rate obtained on the robot than baselines, offering a\nreproducible, systematic, and insightful means for comparing the performance of\nmultimodal imitation learning approaches in complex HRI tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06404v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06373", "title": "Digital Wargames to Enhance Military Medical Evacuation Decision-Making", "authors": ["Jeremy Fischer", "Ram Krishnamoorthy", "Vishal Kumar", "Mahdi Al-Husseini"], "categories": ["cs.AI", "cs.CY", "cs.HC", "cs.MM"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06373v1", "summary": "Medical evacuation is one of the United States Army's most storied and\ncritical mission sets, responsible for efficiently and expediently evacuating\nthe battlefield ill and injured. Medical evacuation planning involves designing\na robust network of medical platforms and facilities capable of moving and\ntreating large numbers of casualties. Until now, there has not been a medium to\nsimulate these networks in a classroom setting and evaluate both offline\nplanning and online decision-making performance. This work describes the\nMedical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer\nsimulation developed in Unity that replicates battlefield constraints and\nuncertainties. MEWI accurately models patient interactions at casualty\ncollection points, ambulance exchange points, medical treatment facilities, and\nevacuation platforms. Two operational scenarios are introduced: an amphibious\nisland assault in the Pacific and a Eurasian conflict across a sprawling road\nand river network. These scenarios pit students against the clock to save as\nmany casualties as possible while adhering to doctrinal lessons learned during\ndidactic training. We visualize performance data collected from two iterations\nof the MEWI Pacific scenario executed in the United States Army's Medical\nEvacuation Doctrine Course. We consider post-wargame Likert survey data from\nstudent participants and external observer notes to identify key planning\ndecision points, document medical evacuation lessons learned, and quantify\ngeneral utility. Results indicate that MEWI participation substantially\nimproves uptake of medical evacuation lessons learned and co-operative\ndecision-making. MEWI is a substantial step forward in the field of\nhigh-fidelity training tools for medical education, and our study findings\noffer critical insights into improving medical evacuation education and\noperations across the joint force.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06373v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06508", "title": "Subgraph Counting under Edge Local Differential Privacy Based on Noisy Adjacency Matrix", "authors": ["Jintao Guo", "Ying Zhou", "Chao Li", "Guixun Luo"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06508v1", "summary": "When analyzing connection patterns within graphs, subgraph counting serves as\nan effective and fundamental approach. Edge-local differential privacy\n(edge-LDP) and shuffle model have been employed to achieve subgraph counting\nunder a privacy-preserving situation. Existing algorithms are plagued by high\ntime complexity, excessive download costs, low accuracy, or dependence on\ntrusted third parties. To address the aforementioned challenges, we propose the\nNoisy Adjacency Matrix (NAM), which combines differential privacy with the\nadjacency matrix of the graph. NAM offers strong versatility and scalability,\nmaking it applicable to a wider range of DP variants, DP mechanisms, and graph\ntypes. Based on NAM, we designed five algorithms (TriOR, TriTR, TriMTR, QuaTR,\nand 2STAR) to count three types of subgraphs: triangles, quadrangles, and\n2-stars. Theoretical and experimental results demonstrate that in triangle\ncounting, TriOR maximizes accuracy with reduced time complexity among one-round\nalgorithms, TriTR achieves optimal accuracy, TriMTR achieves the highest\naccuracy under low download costs, and QuaTR stands as the first quadrangle\ncounting algorithm under pure edge-LDP. We implement edge-LDP for noisy data\nvia a confidence interval-inspired method, providing DP guarantees on\nrandomized data. Our 2STAR algorithm achieves the highest accuracy in 2-star\ncounting and can be derived as a byproduct of two-round triangle or quadrangle\ncounting algorithms, enabling efficient joint estimation of triangle,\nquadrangle, and 2-star counts within two query rounds.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06508v1", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06542", "title": "A Single Merging Suffices: Recovering Server-based Learning Performance in Decentralized Learning", "authors": ["Tongtian Zhu", "Tianyu Zhang", "Mingze Wang", "Zhanpeng Zhou", "Can Wang"], "categories": ["cs.LG", "cs.DC", "cs.MA", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      We discover and theoretically explain why and when a single global parameter merging in decentralized learning can recover the performance of server-based learning, even in highly heterogeneous and communication-constrained environments", "url": "http://arxiv.org/abs/2507.06542v1", "summary": "Decentralized learning provides a scalable alternative to traditional\nparameter-server-based training, yet its performance is often hindered by\nlimited peer-to-peer communication. In this paper, we study how communication\nshould be scheduled over time, including determining when and how frequently\ndevices synchronize. Our empirical results show that concentrating\ncommunication budgets in the later stages of decentralized training markedly\nimproves global generalization. Surprisingly, we uncover that fully connected\ncommunication at the final step, implemented by a single global merging, is\nsufficient to match the performance of server-based training. We further show\nthat low communication in decentralized learning preserves the\n\\textit{mergeability} of local models throughout training. Our theoretical\ncontributions, which explains these phenomena, are first to establish that the\nglobally merged model of decentralized SGD can converge faster than centralized\nmini-batch SGD. Technically, we novelly reinterpret part of the discrepancy\namong local models, which were previously considered as detrimental noise, as\nconstructive components that accelerate convergence. This work challenges the\ncommon belief that decentralized learning generalizes poorly under data\nheterogeneity and limited communication, while offering new insights into model\nmerging and neural network loss landscapes.", "comment": "We discover and theoretically explain why and when a single global\n  parameter merging in decentralized learning can recover the performance of\n  server-based learning, even in highly heterogeneous and\n  communication-constrained environments", "pdf_url": "http://arxiv.org/pdf/2507.06542v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06426", "title": "Evaluating Robots Like Human Infants: A Case Study of Learned Bipedal Locomotion", "authors": ["Devin Crowley", "Whitney G. Cole", "Christina M. Hospodar", "Ruiting Shen", "Karen E. Adolph", "Alan Fern"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages, 4 figures, accepted into ICDL 2025 as a contributed paper", "url": "http://arxiv.org/abs/2507.06426v1", "summary": "Typically, learned robot controllers are trained via relatively unsystematic\nregimens and evaluated with coarse-grained outcome measures such as average\ncumulative reward. The typical approach is useful to compare learning\nalgorithms but provides limited insight into the effects of different training\nregimens and little understanding about the richness and complexity of learned\nbehaviors. Likewise, human infants and other animals are \"trained\" via\nunsystematic regimens, but in contrast, developmental psychologists evaluate\ntheir performance in highly-controlled experiments with fine-grained measures\nsuch as success, speed of walking, and prospective adjustments. However, the\nstudy of learned behavior in human infants is limited by the practical\nconstraints of training and testing babies. Here, we present a case study that\napplies methods from developmental psychology to study the learned behavior of\nthe simulated bipedal robot Cassie. Following research on infant walking, we\nsystematically designed reinforcement learning training regimens and tested the\nresulting controllers in simulated environments analogous to those used for\nbabies--but without the practical constraints. Results reveal new insights into\nthe behavioral impact of different training regimens and the development of\nCassie's learned behaviors relative to infants who are learning to walk. This\ninterdisciplinary baby-robot approach provides inspiration for future research\ndesigned to systematically test effects of training on the development of\ncomplex learned robot behaviors.", "comment": "7 pages, 4 figures, accepted into ICDL 2025 as a contributed paper", "pdf_url": "http://arxiv.org/pdf/2507.06426v1", "cate": "cs.RO", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06396", "title": "Representing Prompting Patterns with PDL: Compliance Agent Case Study", "authors": ["Mandana Vaziri", "Louis Mandel", "Yuji Watanabe", "Hirokuni Kitahara", "Martin Hirzel", "Anca Sailer"], "categories": ["cs.AI", "cs.LG", "cs.PL", "cs.SE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      ICML 2025 Workshop on Programmatic Representations for Agent Learning", "url": "http://arxiv.org/abs/2507.06396v1", "summary": "Prompt engineering for LLMs remains complex, with existing frameworks either\nhiding complexity behind restrictive APIs or providing inflexible canned\npatterns that resist customization -- making sophisticated agentic programming\nchallenging. We present the Prompt Declaration Language (PDL), a novel approach\nto prompt representation that tackles this fundamental complexity by bringing\nprompts to the forefront, enabling manual and automatic prompt tuning while\ncapturing the composition of LLM calls together with rule-based code and\nexternal tools. By abstracting away the plumbing for such compositions, PDL\naims at improving programmer productivity while providing a declarative\nrepresentation that is amenable to optimization. This paper demonstrates PDL's\nutility through a real-world case study of a compliance agent. Tuning the\nprompting pattern of this agent yielded up to 4x performance improvement\ncompared to using a canned agent and prompt pattern.", "comment": "ICML 2025 Workshop on Programmatic Representations for Agent Learning", "pdf_url": "http://arxiv.org/pdf/2507.06396v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06706", "title": "Approximating Euler Totient Function using Linear Regression on RSA moduli", "authors": ["Gilda Rech Bansimba", "Regis F. Babindamana", "Beni Blaug N. Ibara"], "categories": ["cs.CR", "03C05"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06706v1", "summary": "The security of the RSA cryptosystem is based on the intractability of\ncomputing Euler's totient function phi(n) for large integers n. Although\nderiving phi(n) deterministically remains computationally infeasible for\ncryptographically relevant bit lengths, and machine learning presents a\npromising alternative for constructing efficient approximations. In this work,\nwe explore a machine learning approach to approximate Euler's totient function\nphi using linear regression models. We consider a dataset of RSA moduli of 64,\n128, 256, 512 and 1024 bits along with their corresponding totient values. The\nregression model is trained to capture the relationship between the modulus and\nits totient, and tested on unseen samples to evaluate its prediction accuracy.\nPreliminary results suggest that phi can be approximated within a small\nrelative error margin, which may be sufficient to aid in certain classes of RSA\nattacks. This research opens a direction for integrating statistical learning\ntechniques into cryptanalysis, providing insights into the feasibility of\nattacking cryptosystems using approximation based strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06706v1", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06750", "title": "Distributed Fault-Tolerant Multi-Robot Cooperative Localization in Adversarial Environments", "authors": ["Tohid Kargar Tasooji", "Ramviyas Parasuraman"], "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to IROS 2025 Conference", "url": "http://arxiv.org/abs/2507.06750v1", "summary": "In multi-robot systems (MRS), cooperative localization is a crucial task for\nenhancing system robustness and scalability, especially in GPS-denied or\ncommunication-limited environments. However, adversarial attacks, such as\nsensor manipulation, and communication jamming, pose significant challenges to\nthe performance of traditional localization methods. In this paper, we propose\na novel distributed fault-tolerant cooperative localization framework to\nenhance resilience against sensor and communication disruptions in adversarial\nenvironments. We introduce an adaptive event-triggered communication strategy\nthat dynamically adjusts communication thresholds based on real-time sensing\nand communication quality. This strategy ensures optimal performance even in\nthe presence of sensor degradation or communication failure. Furthermore, we\nconduct a rigorous analysis of the convergence and stability properties of the\nproposed algorithm, demonstrating its resilience against bounded adversarial\nzones and maintaining accurate state estimation. Robotarium-based experiment\nresults show that our proposed algorithm significantly outperforms traditional\nmethods in terms of localization accuracy and communication efficiency,\nparticularly in adversarial settings. Our approach offers improved scalability,\nreliability, and fault tolerance for MRS, making it suitable for large-scale\ndeployments in real-world, challenging environments.", "comment": "Accepted to IROS 2025 Conference", "pdf_url": "http://arxiv.org/pdf/2507.06750v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06519", "title": "Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies", "authors": ["Yuhan Liu", "Xinyu Zhang", "Haonan Chang", "Abdeslam Boularias"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at IROS2025. Project website: this https URL", "url": "http://arxiv.org/abs/2507.06519v1", "summary": "This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where\na robot must repeatedly perform high-precision insertions, such as screwing a\nnut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving\nmillimeter-level accuracy and maintaining consistent performance over multiple\nrepetitions, particularly when factors like nut rotation and friction introduce\nadditional complexity. We propose a sim-to-real framework that integrates a\nreinforcement learning-based insertion policy with a failure forecasting\nmodule. By representing the wrench's pose in the nut's coordinate frame rather\nthan the robot's frame, our approach significantly enhances sim-to-real\ntransferability. The insertion policy, trained in simulation, leverages\nreal-time 6D pose tracking to execute precise alignment, insertion, and\nrotation maneuvers. Simultaneously, a neural network predicts potential\nexecution failures, triggering a simple recovery mechanism that lifts the\nwrench and retries the insertion. Extensive experiments in both simulated and\nreal-world environments demonstrate that our method not only achieves a high\none-time success rate but also robustly maintains performance over long-horizon\nrepetitive tasks.", "comment": "Accepted at IROS2025. Project website:\n  https://jaysparrow.github.io/rit", "pdf_url": "http://arxiv.org/pdf/2507.06519v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06398", "title": "Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI", "authors": ["David Orban"], "categories": ["cs.AI", "cs.CY", "68T01, 91B26, 93C15"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      13 pages, 2 figures. Revised following peer review", "url": "http://arxiv.org/abs/2507.06398v1", "summary": "This paper investigates the Jolting Technologies Hypothesis, which posits\nsuperexponential growth (increasing acceleration, or a positive third\nderivative) in the development of AI capabilities. We develop a theoretical\nframework and validate detection methodologies through Monte Carlo simulations,\nwhile acknowledging that empirical validation awaits suitable longitudinal\ndata. Our analysis focuses on creating robust tools for future empirical\nstudies and exploring the potential implications should the hypothesis prove\nvalid. The study examines how factors such as shrinking idea-to-action\nintervals and compounding iterative AI improvements drive this jolting pattern.\nBy formalizing jolt dynamics and validating detection methods through\nsimulation, this work provides the mathematical foundation necessary for\nunderstanding potential AI trajectories and their consequences for AGI\nemergence, offering insights for research and policy.", "comment": "13 pages, 2 figures. Revised following peer review", "pdf_url": "http://arxiv.org/pdf/2507.06398v1", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06723", "title": "PotentRegion4MalDetect: Advanced Features from Potential Malicious Regions for Malware Detection", "authors": ["Rama Krishna Koppanati", "Monika Santra", "Sateesh Kumar Peddoju"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06723v1", "summary": "Malware developers exploit the fact that most detection models focus on the\nentire binary to extract the feature rather than on the regions of potential\nmaliciousness. Therefore, they reverse engineer a benign binary and inject\nmalicious code into it. This obfuscation technique circumvents the malware\ndetection models and deceives the ML classifiers due to the prevalence of\nbenign features compared to malicious features. However, extracting the\nfeatures from the potential malicious regions enhances the accuracy and\ndecreases false positives. Hence, we propose a novel model named\nPotentRegion4MalDetect that extracts features from the potential malicious\nregions. PotentRegion4MalDetect determines the nodes with potential\nmaliciousness in the partially preprocessed Control Flow Graph (CFG) using the\nmalicious strings given by StringSifter. Then, it extracts advanced features of\nthe identified potential malicious regions alongside the features from the\ncompletely preprocessed CFG. The features extracted from the completely\npreprocessed CFG mitigate obfuscation techniques that attempt to disguise\nmalicious content, such as suspicious strings. The experiments reveal that the\nPotentRegion4MalDetect requires fewer entries to save the features for all\nbinaries than the model focusing on the entire binary, reducing memory\noverhead, faster computation, and lower storage requirements. These advanced\nfeatures give an 8.13% increase in SHapley Additive exPlanations (SHAP)\nAbsolute Mean and a 1.44% increase in SHAP Beeswarm value compared to those\nextracted from the entire binary. The advanced features outperform the features\nextracted from the entire binary by producing more than 99% accuracy,\nprecision, recall, AUC, F1-score, and 0.064% FPR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06723v1", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06780", "title": "Learning safe, constrained policies via imitation learning: Connection to Probabilistic Inference and a Naive Algorithm", "authors": ["George Papadopoulos", "George A. Vouros"], "categories": ["cs.LG", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06780v1", "summary": "This article introduces an imitation learning method for learning maximum\nentropy policies that comply with constraints demonstrated by expert\ntrajectories executing a task. The formulation of the method takes advantage of\nresults connecting performance to bounds for the KL-divergence between\ndemonstrated and learned policies, and its objective is rigorously justified\nthrough a connection to a probabilistic inference framework for reinforcement\nlearning, incorporating the reinforcement learning objective and the objective\nto abide by constraints in an entropy maximization setting. The proposed\nalgorithm optimizes the learning objective with dual gradient descent,\nsupporting effective and stable training. Experiments show that the proposed\nmethod can learn effective policy models for constraints-abiding behaviour, in\nsettings with multiple constraints of different types, accommodating different\nmodalities of demonstrated behaviour, and with abilities to generalize.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06780v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06562", "title": "KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and Wall Climbing", "authors": ["Keita Yoneda", "Kento Kawaharazuka", "Temma Suzuki", "Takahiro Hattori", "Kei Okada"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at IROS2025, website - this https URL , YouTube - this https URL", "url": "http://arxiv.org/abs/2507.06562v1", "summary": "In recent years, advancements in hardware have enabled quadruped robots to\noperate with high power and speed, while robust locomotion control using\nreinforcement learning (RL) has also been realized. As a result, expectations\nare rising for the automation of tasks such as material transport and\nexploration in unknown environments. However, autonomous locomotion in rough\nterrains with significant height variations requires vertical movement, and\nrobots capable of performing such movements stably, along with their control\nmethods, have not yet been fully established. In this study, we developed the\nquadruped robot KLEIYN, which features a waist joint, and aimed to expand\nquadruped locomotion by enabling chimney climbing through RL. To facilitate the\nlearning of vertical motion, we introduced Contact-Guided Curriculum Learning\n(CGCL). As a result, KLEIYN successfully climbed walls ranging from 800 mm to\n1000 mm in width at an average speed of 150 mm/s, 50 times faster than\nconventional robots. Furthermore, we demonstrated that the introduction of a\nwaist joint improves climbing performance, particularly enhancing tracking\nability on narrow walls.", "comment": "Accepted at IROS2025, website -\n  https://keitayoneda.github.io/kleiyn-chimney-climbing/, YouTube -\n  https://www.youtube.com/watch?v=vDmSfkazAvI", "pdf_url": "http://arxiv.org/pdf/2507.06562v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06798", "title": "Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)", "authors": ["Uri Andrews", "Luca San Mauro"], "categories": ["cs.AI", "math.LO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      25 pages, accepted at JELIA 2025", "url": "http://arxiv.org/abs/2507.06798v1", "summary": "Dialectical systems are a mathematical formalism for modeling an agent\nupdating a knowledge base seeking consistency. Introduced in the 1970s by\nRoberto Magari, they were originally conceived to capture how a working\nmathematician or a research community refines beliefs in the pursuit of truth.\nDialectical systems also serve as natural models for the belief change of an\nautomated agent, offering a unifying, computable framework for dynamic belief\nmanagement.\n  The literature distinguishes three main models of dialectical systems:\n(d-)dialectical systems based on revising beliefs when they are seen to be\ninconsistent, p-dialectical systems based on revising beliefs based on finding\na counterexample, and q-dialectical systems which can do both. We answer an\nopen problem in the literature by proving that q-dialectical systems are\nstrictly more powerful than p-dialectical systems, which are themselves known\nto be strictly stronger than (d-)dialectical systems. This result highlights\nthe complementary roles of counterexample and contradiction in automated belief\nrevision, and thus also in the reasoning processes of mathematicians and\nresearch communities.", "comment": "25 pages, accepted at JELIA 2025", "pdf_url": "http://arxiv.org/pdf/2507.06798v1", "cate": "cs.AI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06742", "title": "PenTest2.0: Towards Autonomous Privilege Escalation Using GenAI", "authors": ["Haitham S. Al-Sinani", "Chris J. Mitchell"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      45 pages, 23 figures", "url": "http://arxiv.org/abs/2507.06742v1", "summary": "Ethical hacking today relies on highly skilled practitioners executing\ncomplex sequences of commands, which is inherently time-consuming, difficult to\nscale, and prone to human error. To help mitigate these limitations, we\npreviously introduced 'PenTest++', an AI-augmented system combining automation\nwith generative AI supporting ethical hacking workflows. However, a key\nlimitation of PenTest++ was its lack of support for privilege escalation, a\ncrucial element of ethical hacking. In this paper we present 'PenTest2.0', a\nsubstantial evolution of PenTest++ supporting automated privilege escalation\ndriven entirely by Large Language Model reasoning. It also incorporates several\nsignificant enhancements: 'Retrieval-Augmented Generation', including both\none-line and offline modes; 'Chain-of-Thought' prompting for intermediate\nreasoning; persistent 'PenTest Task Trees' to track goal progression across\nturns; and the optional integration of human-authored hints. We describe how it\noperates, present a proof-of-concept prototype, and discuss its benefits and\nlimitations. We also describe application of the system to a controlled Linux\ntarget, showing it can carry out multi-turn, adaptive privilege escalation. We\nexplain the rationale behind its core design choices, and provide comprehensive\ntesting results and cost analysis. Our findings indicate that 'PenTest2.0'\nrepresents a meaningful step toward practical, scalable, AI-automated\npenetration testing, whilst highlighting the shortcomings of generative AI\nsystems, particularly their sensitivity to prompt structure, execution context,\nand semantic drift, reinforcing the need for further research and refinement in\nthis emerging space.\n  Keywords: AI, Ethical Hacking, Privilege Escalation, GenAI, ChatGPT, LLM\n(Large Language Model), HITL (Human-in-the-Loop)", "comment": "45 pages, 23 figures", "pdf_url": "http://arxiv.org/pdf/2507.06742v1", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06931", "title": "DICE: Data Influence Cascade in Decentralized Learning", "authors": ["Tongtian Zhu", "Wenhao Li", "Can Wang", "Fengxiang He"], "categories": ["cs.LG", "cs.DC", "cs.MA", "cs.SI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published as a poster at ICLR 2025", "url": "http://arxiv.org/abs/2507.06931v1", "summary": "Decentralized learning offers a promising approach to crowdsource data\nconsumptions and computational workloads across geographically distributed\ncompute interconnected through peer-to-peer networks, accommodating the\nexponentially increasing demands. However, proper incentives are still in\nabsence, considerably discouraging participation. Our vision is that a fair\nincentive mechanism relies on fair attribution of contributions to\nparticipating nodes, which faces non-trivial challenges arising from the\nlocalized connections making influence ``cascade'' in a decentralized network.\nTo overcome this, we design the first method to estimate \\textbf{D}ata\n\\textbf{I}nfluence \\textbf{C}ascad\\textbf{E} (DICE) in a decentralized\nenvironment. Theoretically, the framework derives tractable approximations of\ninfluence cascade over arbitrary neighbor hops, suggesting the influence\ncascade is determined by an interplay of data, communication topology, and the\ncurvature of loss landscape. DICE also lays the foundations for applications\nincluding selecting suitable collaborators and identifying malicious behaviors.\nProject page is available at https://raiden-zhu.github.io/blog/2025/DICE/.", "comment": "Published as a poster at ICLR 2025", "pdf_url": "http://arxiv.org/pdf/2507.06931v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06564", "title": "SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments", "authors": ["Tianshun Li", "Tianyi Huai", "Zhen Li", "Yichun Gao", "Haoang Li", "Xinhu Zheng"], "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 9 figures, has been accepted by IROS 2025", "url": "http://arxiv.org/abs/2507.06564v1", "summary": "Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across\nvarious sectors, driven by their mobility and adaptability. This paper\nintroduces SkyVLN, a novel framework integrating vision-and-language navigation\n(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in\ncomplex urban environments. Unlike traditional navigation methods, SkyVLN\nleverages Large Language Models (LLMs) to interpret natural language\ninstructions and visual observations, enabling UAVs to navigate through dynamic\n3D spaces with improved accuracy and robustness. We present a multimodal\nnavigation agent equipped with a fine-grained spatial verbalizer and a history\npath memory mechanism. These components allow the UAV to disambiguate spatial\ncontexts, handle ambiguous instructions, and backtrack when necessary. The\nframework also incorporates an NMPC module for dynamic obstacle avoidance,\nensuring precise trajectory tracking and collision prevention. To validate our\napproach, we developed a high-fidelity 3D urban simulation environment using\nAirSim, featuring realistic imagery and dynamic urban elements. Extensive\nexperiments demonstrate that SkyVLN significantly improves navigation success\nrates and efficiency, particularly in new and unseen environments.", "comment": "8 pages, 9 figures, has been accepted by IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.06564v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06852", "title": "SCC-recursiveness in infinite argumentation (extended version)", "authors": ["Uri Andrews", "Luca San Mauro"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      26 pages, accepted at JELIA 2025", "url": "http://arxiv.org/abs/2507.06852v1", "summary": "Argumentation frameworks (AFs) are a foundational tool in artificial\nintelligence for modeling structured reasoning and conflict. SCC-recursiveness\nis a well-known design principle in which the evaluation of arguments is\ndecomposed according to the strongly connected components (SCCs) of the attack\ngraph, proceeding recursively from \"higher\" to \"lower\" components. While\nSCC-recursive semantics such as \\cft and \\stgt have proven effective for finite\nAFs, Baumann and Spanring showed the failure of SCC-recursive semantics to\ngeneralize reliably to infinite AFs due to issues with well-foundedness.\n  We propose two approaches to extending SCC-recursiveness to the infinite\nsetting. We systematically evaluate these semantics using Baroni and Giacomin's\nestablished criteria, showing in particular that directionality fails in\ngeneral. We then examine these semantics' behavior in finitary frameworks,\nwhere we find some of our semantics satisfy directionality. These results\nadvance the theory of infinite argumentation and lay the groundwork for\nreasoning systems capable of handling unbounded or evolving domains.", "comment": "26 pages, accepted at JELIA 2025", "pdf_url": "http://arxiv.org/pdf/2507.06852v1", "cate": "cs.AI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06850", "title": "The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover", "authors": ["Matteo Lupinacci", "Francesco Aurelio Pironti", "Francesco Blefari", "Francesco Romeo", "Luigi Arena", "Angelo Furfaro"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06850v1", "summary": "The rapid adoption of Large Language Model (LLM) agents and multi-agent\nsystems enables unprecedented capabilities in natural language processing and\ngeneration. However, these systems have introduced unprecedented security\nvulnerabilities that extend beyond traditional prompt injection attacks. This\npaper presents the first comprehensive evaluation of LLM agents as attack\nvectors capable of achieving complete computer takeover through the\nexploitation of trust boundaries within agentic AI systems where autonomous\nentities interact and influence each other. We demonstrate that adversaries can\nleverage three distinct attack surfaces - direct prompt injection, RAG backdoor\nattacks, and inter-agent trust exploitation - to coerce popular LLMs (including\nGPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing\nmalware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals\nan alarming vulnerability hierarchy: while 41.2% of models succumb to direct\nprompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical\n82.4% can be compromised through inter-agent trust exploitation. Notably, we\ndiscovered that LLMs which successfully resist direct malicious commands will\nexecute identical payloads when requested by peer agents, revealing a\nfundamental flaw in current multi-agent security models. Our findings\ndemonstrate that only 5.9% of tested models (1/17) proved resistant to all\nattack vectors, with the majority exhibiting context-dependent security\nbehaviors that create exploitable blind spots. Our findings also highlight the\nneed to increase awareness and research on the security risks of LLMs, showing\na paradigm shift in cybersecurity threats, where AI tools themselves become\nsophisticated attack vectors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06850v1", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2501.02770", "title": "Multi-Agent Pathfinding Under Team-Connected Communication Constraint via Adaptive Path Expansion and Dynamic Leading", "authors": ["Hoang-Dung Bui", "Erion Plaku", "Gregoy J. Stein"], "categories": ["cs.AI", "cs.MA", "cs.RO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.02770v3", "summary": "This paper proposes a novel planning framework to handle a multi-agent\npathfinding problem under team-connected communication constraint, where all\nagents must have a connected communication channel to the rest of the team\nduring their entire movements. Standard multi-agent path finding approaches\n(e.g., priority-based search) have potential in this domain but fail when\nneighboring configurations at start and goal differ. Their single-expansion\napproach -- computing each agent's path from the start to the goal in just a\nsingle expansion -- cannot reliably handle planning under communication\nconstraints for agents as their neighbors change during navigating. Similarly,\nleader-follower approaches (e.g., platooning) are effective at maintaining team\ncommunication, but fixing the leader at the outset of planning can cause\nplanning to become stuck in dense-clutter environments, limiting their\npractical utility. To overcome this limitation, we propose a novel two-level\nmulti-agent pathfinding framework that integrates two techniques: adaptive path\nexpansion to expand agent paths to their goals in multiple stages; and dynamic\nleading technique that enables the reselection of the leading agent during each\nagent path expansion whenever progress cannot be made. Simulation experiments\nshow the efficiency of our planners, which can handle up to 25 agents across\nfive environment types under a limited communication range constraint and up to\n11-12 agents on three environment types under line-of-sight communication\nconstraint, exceeding 90% success-rate where baselines routinely fail.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.02770v3", "cate": "cs.AI", "date": "2025-01-06", "updated": "2025-07-09"}
{"id": "2507.06574", "title": "AI Space Cortex: An Experimental System for Future Era Space Exploration", "authors": ["Thomas Touma", "Ersin Daş", "Erica Tevere", "Martin Feather", "Ksenia Kolcio", "Maurice Prather", "Alberto Candela", "Ashish Goel", "Erik Kramer", "Hari Nayar", "Lorraine Fesq", "Joel W. Burdick"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06574v1", "summary": "Our Robust, Explainable Autonomy for Scientific Icy Moon Operations (REASIMO)\neffort contributes to NASA's Concepts for Ocean worlds Life Detection\nTechnology (COLDTech) program, which explores science platform technologies for\nocean worlds such as Europa and Enceladus. Ocean world missions pose\nsignificant operational challenges. These include long communication lags,\nlimited power, and lifetime limitations caused by radiation damage and hostile\nconditions. Given these operational limitations, onboard autonomy will be vital\nfor future Ocean world missions. Besides the management of nominal lander\noperations, onboard autonomy must react appropriately in the event of\nanomalies. Traditional spacecraft rely on a transition into 'safe-mode' in\nwhich non-essential components and subsystems are powered off to preserve\nsafety and maintain communication with Earth. For a severely time-limited Ocean\nworld mission, resolutions to these anomalies that can be executed without\nEarth-in-the-loop communication and associated delays are paramount for\ncompletion of the mission objectives and science goals. To address these\nchallenges, the REASIMO effort aims to demonstrate a robust level of\nAI-assisted autonomy for such missions, including the ability to detect and\nrecover from anomalies, and to perform missions based on pre-trained behaviors\nrather than hard-coded, predetermined logic like all prior space missions. We\ndeveloped an AI-assisted, personality-driven, intelligent framework for control\nof an Ocean world mission by combining a mix of advanced technologies. To\ndemonstrate the capabilities of the framework, we perform tests of autonomous\nsampling operations on a lander-manipulator testbed at the NASA Jet Propulsion\nLaboratory, approximating possible surface conditions such a mission might\nencounter.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06574v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06968", "title": "Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report", "authors": ["Li Du", "Hanyu Zhao", "Yiming Ju", "Tengfei Pan"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06968v1", "summary": "Instruction tuning has become a foundation for unlocking the capabilities of\nlarge-scale pretrained models and improving their performance on complex tasks.\nThus, the construction of high-quality instruction datasets is crucial for\nenhancing model performance and generalizability. Although current instruction\ndatasets have reached tens of millions of samples, models finetuned on them may\nstill struggle with complex instruction following and tasks in rare domains.\nThis is primarily due to limited expansion in both ``coverage'' (coverage of\ntask types and knowledge areas) and ``depth'' (instruction complexity) of the\ninstruction set. To address this issue, we propose a systematic instruction\ndata construction framework, which integrates a hierarchical labeling system,\nan informative seed selection algorithm, an evolutionary data synthesis\nprocess, and a model deficiency diagnosis with targeted data generation. These\ncomponents form an iterative closed-loop to continuously enhance the coverage\nand depth of instruction data. Based on this framework, we construct\nInfinityInstruct-Subject, a high-quality dataset containing ~1.5 million\ninstructions. Experiments on multiple foundation models and benchmark tasks\ndemonstrate its effectiveness in improving instruction-following capabilities.\nFurther analyses suggest that InfinityInstruct-Subject shows enlarged coverage\nand depth compared to comparable synthesized instruction datasets. Our work\nlays a theoretical and practical foundation for the efficient, continuous\nevolution of instruction datasets, moving from data quantity expansion to\nqualitative improvement.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06968v1", "cate": "cs.AI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06267", "title": "Neural Network-Based Parameter Estimation for Non-Autonomous Differential Equations with Discontinuous Signals", "authors": ["Hyeontae Jo", "Krešimir Josić", "Jae Kyoung Kim"], "categories": ["cs.LG", "34C60, 92B05, 68T07, 93C15, 65K10"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06267v1", "summary": "Non-autonomous differential equations are crucial for modeling systems\ninfluenced by external signals, yet fitting these models to data becomes\nparticularly challenging when the signals change abruptly. To address this\nproblem, we propose a novel parameter estimation method utilizing functional\napproximations with artificial neural networks. Our approach, termed Harmonic\nApproximation of Discontinuous External Signals using Neural Networks\n(HADES-NN), operates in two iterated stages. In the first stage, the algorithm\nemploys a neural network to approximate the discontinuous signal with a smooth\nfunction. In the second stage, it uses this smooth approximate signal to\nestimate model parameters. HADES-NN gives highly accurate and precise parameter\nestimates across various applications, including circadian clock systems\nregulated by external light inputs measured via wearable devices and the mating\nresponse of yeast to external pheromone signals. HADES-NN greatly extends the\nrange of model systems that can be fit to real-world measurements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06267v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06926", "title": "Are NFTs Ready to Keep Australian Artists Engaged?", "authors": ["Ruiqiang Li", "Brian Yecies", "Qin Wang", "Shiping Chen", "Jun Shen"], "categories": ["cs.CR", "cs.CY", "cs.ET"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06926v1", "summary": "Non-Fungible Tokens (NFTs) offer a promising mechanism to protect Australian\nand Indigenous artists' copyright. They represent and transfer the value of\nartwork in digital form. Before adopting NFTs to protect Australian artwork, we\nin this paper investigate them empericially. We focus on examining the details\nof NFT structure. We start from the underlying structure of NFTs to show how\nthey represent copyright for both artists and production owners, as well as how\nthey aim to safeguard or secure the value of digital artworks. We then involve\ndata collection from various types of sources with different storage methods,\nincluding on-chain, centralized, and decentralized systems. Based on both\nmetadata and artwork content, we present our analysis and discussion on the\nfollowing key issues: copyright, security and artist identification. The final\nresults of the evaluation, unfortnately, show that the NFT is NOT ready to\nprotect Australian and Indigenous artists' copyright.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06926v1", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2503.01861", "title": "Towards Enterprise-Ready Computer Using Generalist Agent", "authors": ["Sami Marreed", "Alon Oved", "Avi Yaeli", "Segev Shlomov", "Ido Levy", "Offer Akrabi", "Aviad Sela", "Asaf Adi", "Nir Mashkif"], "categories": ["cs.DC", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.01861v3", "summary": "This paper presents our ongoing work toward developing an enterprise-ready\nComputer Using Generalist Agent (CUGA) system. Our research highlights the\nevolutionary nature of building agentic systems suitable for enterprise\nenvironments. By integrating state-of-the-art agentic AI techniques with a\nsystematic approach to iterative evaluation, analysis, and refinement, we have\nachieved rapid and cost-effective performance gains, notably reaching a new\nstate-of-the-art performance on the WebArena and AppWorld benchmarks. We detail\nour development roadmap, the methodology and tools that facilitated rapid\nlearning from failures and continuous system refinement, and discuss key\nlessons learned and future challenges for enterprise adoption.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.01861v3", "cate": "cs.DC", "date": "2025-02-24", "updated": "2025-07-09"}
{"id": "2507.06605", "title": "Growing Trees with an Agent: Accelerating RRTs with Learned, Multi-Step Episodic Exploration", "authors": ["Xinyu Wu"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06605v1", "summary": "Classical sampling-based motion planners like the RRTs suffer from\ninefficiencies, particularly in cluttered or high-dimensional spaces, due to\ntheir reliance on undirected, random sampling. This paper introduces the\nEpisodic RRT, a novel hybrid planning framework that replaces the primitive of\na random point with a learned, multi-step \"exploratory episode\" generated by a\nDeep Reinforcement Learning agent. By making the DRL agent the engine of\nexploration, ERRT transforms the search process from a diffuse, volumetric\nexpansion into a directed, branch-like growth. This paradigm shift yields key\nadvantages: it counters the curse of dimensionality with focused exploration,\nminimizes expensive collision checks by proactively proposing locally valid\npaths, and improves connectivity by generating inherently connected path\nsegments. We demonstrate through extensive empirical evaluation across 2D, 3D,\nand 6D environments that ERRT and its variants consistently and significantly\noutperform their classical counterparts. In a challenging 6D robotic arm\nscenario, ERRT achieves a 98% success rate compared to 19% for RRT, is up to\n107x faster, reduces collision checks by over 99.6%, and finds initial paths\nthat are nearly 50% shorter. Furthermore, its asymptotically optimal variant,\nERRT*, demonstrates vastly superior anytime performance, refining solutions to\nnear-optimality up to 29x faster than standard RRT* in 3D environments. Code:\nhttps://xinyuwuu.github.io/Episodic_RRT/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06605v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06993", "title": "The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation", "authors": ["Jieren Deng", "Aleksandar Cvetkovic", "Pak Kiu Chung", "Dragomir Yankov", "Chiqun Zhang"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06993v1", "summary": "Traditional travel-planning systems are often static and fragmented, leaving\nthem ill-equipped to handle real-world complexities such as evolving\nenvironmental conditions and unexpected itinerary disruptions. In this paper,\nwe identify three gaps between existing service providers causing frustrating\nuser experience: intelligent trip planning, precision \"last-100-meter\"\nnavigation, and dynamic itinerary adaptation. We propose three cooperative\nagents: a Travel Planning Agent that employs grid-based spatial grounding and\nmap analysis to help resolve complex multi-modal user queries; a Destination\nAssistant Agent that provides fine-grained guidance for the final navigation\nleg of each journey; and a Local Discovery Agent that leverages image\nembeddings and Retrieval-Augmented Generation (RAG) to detect and respond to\ntrip plan disruptions. With evaluations and experiments, our system\ndemonstrates substantial improvements in query interpretation, navigation\naccuracy, and disruption resilience, underscoring its promise for applications\nfrom urban exploration to emergency response.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06993v1", "cate": "cs.AI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06326", "title": "Sample-Efficient Reinforcement Learning Controller for Deep Brain Stimulation in Parkinson's Disease", "authors": ["Harsh Ravivarapu", "Gaurav Bagwe", "Xiaoyong Yuan", "Chunxiu Yu", "Lan Zhang"], "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE IMC 2025", "url": "http://arxiv.org/abs/2507.06326v1", "summary": "Deep brain stimulation (DBS) is an established intervention for Parkinson's\ndisease (PD), but conventional open-loop systems lack adaptability, are\nenergy-inefficient due to continuous stimulation, and provide limited\npersonalization to individual neural dynamics. Adaptive DBS (aDBS) offers a\nclosed-loop alternative, using biomarkers such as beta-band oscillations to\ndynamically modulate stimulation. While reinforcement learning (RL) holds\npromise for personalized aDBS control, existing methods suffer from high sample\ncomplexity, unstable exploration in binary action spaces, and limited\ndeployability on resource-constrained hardware.\n  We propose SEA-DBS, a sample-efficient actor-critic framework that addresses\nthe core challenges of RL-based adaptive neurostimulation. SEA-DBS integrates a\npredictive reward model to reduce reliance on real-time feedback and employs\nGumbel Softmax-based exploration for stable, differentiable policy updates in\nbinary action spaces. Together, these components improve sample efficiency,\nexploration robustness, and compatibility with resource-constrained\nneuromodulatory hardware. We evaluate SEA-DBS on a biologically realistic\nsimulation of Parkinsonian basal ganglia activity, demonstrating faster\nconvergence, stronger suppression of pathological beta-band power, and\nresilience to post-training FP16 quantization. Our results show that SEA-DBS\noffers a practical and effective RL-based aDBS framework for real-time,\nresource-constrained neuromodulation.", "comment": "Accepted by IEEE IMC 2025", "pdf_url": "http://arxiv.org/pdf/2507.06326v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06235", "title": "Super Kawaii Vocalics: Amplifying the \"Cute\" Factor in Computer Voice", "authors": ["Yuto Mandai", "Katie Seaborn", "Tomoyasu Nakano", "Xin Sun", "Yijia Wang", "Jun Kato"], "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      CHI '25", "url": "http://arxiv.org/abs/2507.06235v1", "summary": "\"Kawaii\" is the Japanese concept of cute, which carries sociocultural\nconnotations related to social identities and emotional responses. Yet,\nvirtually all work to date has focused on the visual side of kawaii, including\nin studies of computer agents and social robots. In pursuit of formalizing the\nnew science of kawaii vocalics, we explored what elements of voice relate to\nkawaii and how they might be manipulated, manually and automatically. We\nconducted a four-phase study (grand N = 512) with two varieties of computer\nvoices: text-to-speech (TTS) and game character voices. We found kawaii \"sweet\nspots\" through manipulation of fundamental and formant frequencies, but only\nfor certain voices and to a certain extent. Findings also suggest a ceiling\neffect for the kawaii vocalics of certain voices. We offer empirical validation\nof the preliminary kawaii vocalics model and an elementary method for\nmanipulating kawaii perceptions of computer voice.", "comment": "CHI '25", "pdf_url": "http://arxiv.org/pdf/2507.06235v1", "cate": "cs.HC", "date": "2025-05-20", "updated": "2025-05-20"}
{"id": "2507.06986", "title": "BarkBeetle: Stealing Decision Tree Models with Fault Injection", "authors": ["Qifan Wang", "Jonas Sander", "Minmin Jiang", "Thomas Eisenbarth", "David Oswald"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06986v1", "summary": "Machine learning models, particularly decision trees (DTs), are widely\nadopted across various domains due to their interpretability and efficiency.\nHowever, as ML models become increasingly integrated into privacy-sensitive\napplications, concerns about their confidentiality have grown, particularly in\nlight of emerging threats such as model extraction and fault injection attacks.\nAssessing the vulnerability of DTs under such attacks is therefore important.\nIn this work, we present BarkBeetle, a novel attack that leverages fault\ninjection to extract internal structural information of DT models. BarkBeetle\nemploys a bottom-up recovery strategy that uses targeted fault injection at\nspecific nodes to efficiently infer feature splits and threshold values. Our\nproof-of-concept implementation demonstrates that BarkBeetle requires\nsignificantly fewer queries and recovers more structural information compared\nto prior approaches, when evaluated on DTs trained with public UCI datasets. To\nvalidate its practical feasibility, we implement BarkBeetle on a Raspberry Pi\nRP2350 board and perform fault injections using the Faultier voltage glitching\ntool. As BarkBeetle targets general DT models, we also provide an in-depth\ndiscussion on its applicability to a broader range of tree-based applications,\nincluding data stream classification, DT variants, and cryptography schemes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06986v1", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06625", "title": "Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic", "authors": ["Shizhe Cai", "Jayadeep Jacob", "Zeya Yin", "Fabio Ramos"], "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      9 pages, 10 figures", "url": "http://arxiv.org/abs/2507.06625v1", "summary": "Deep reinforcement learning has shown remarkable success in continuous\ncontrol tasks, yet often requires extensive training data, struggles with\ncomplex, long-horizon planning, and fails to maintain safety constraints during\noperation. Meanwhile, Model Predictive Control (MPC) offers explainability and\nconstraint satisfaction, but typically yields only locally optimal solutions\nand demands careful cost function design. This paper introduces the Q-guided\nSTein variational model predictive Actor-Critic (Q-STAC), a novel framework\nthat bridges these approaches by integrating Bayesian MPC with actor-critic\nreinforcement learning through constrained Stein Variational Gradient Descent\n(SVGD). Our method optimizes control sequences directly using learned Q-values\nas objectives, eliminating the need for explicit cost function design while\nleveraging known system dynamics to enhance sample efficiency and ensure\ncontrol signals remain within safe boundaries. Extensive experiments on 2D\nnavigation and robotic manipulation tasks demonstrate that Q-STAC achieves\nsuperior sample efficiency, robustness, and optimality compared to\nstate-of-the-art algorithms, while maintaining the high expressiveness of\npolicy distributions. Experiment videos are available on our website:\nhttps://sites.google.com/view/q-stac", "comment": "9 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.06625v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07017", "title": "First Return, Entropy-Eliciting Explore", "authors": ["Tianyu Zheng", "Tianshun Xing", "Qingshui Gu", "Taoran Liang", "Xingwei Qu", "Xin Zhou", "Yizhi Li", "Zhoufutu Wen", "Chenghua Lin", "Wenhao Huang", "Qian Liu", "Ge Zhang", "Zejun Ma"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07017v1", "summary": "Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning\nabilities of Large Language Models (LLMs) but it struggles with unstable\nexploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a\nstructured exploration framework that identifies high-uncertainty decision\npoints in reasoning trajectories and performs targeted rollouts to construct\nsemantically grounded intermediate feedback. Our method provides targeted\nguidance without relying on dense supervision. Empirical results on\nmathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable\ntraining, produces longer and more coherent responses, and increases the\nproportion of fully correct trajectories. These results highlight the\nframework's effectiveness in improving LLM reasoning through more robust and\nstructured exploration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07017v1", "cate": "cs.AI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06342", "title": "SymFlux: deep symbolic regression of Hamiltonian vector fields", "authors": ["M. A. Evangelista-Alvarado", "P. Suárez-Serrato"], "categories": ["cs.LG", "cs.AI", "math.DS", "math.SG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      26 pages, 7 figures", "url": "http://arxiv.org/abs/2507.06342v1", "summary": "We present SymFlux, a novel deep learning framework that performs symbolic\nregression to identify Hamiltonian functions from their corresponding vector\nfields on the standard symplectic plane. SymFlux models utilize hybrid CNN-LSTM\narchitectures to learn and output the symbolic mathematical expression of the\nunderlying Hamiltonian. Training and validation are conducted on newly\ndeveloped datasets of Hamiltonian vector fields, a key contribution of this\nwork. Our results demonstrate the model's effectiveness in accurately\nrecovering these symbolic expressions, advancing automated discovery in\nHamiltonian mechanics.", "comment": "26 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.06342v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06460", "title": "Ragged Blocks: Rendering Structured Text with Style", "authors": ["Sam Cohen", "Ravi Chugh"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06460v1", "summary": "Whether it be source code in a programming language, prose in natural\nlanguage, or otherwise, text is highly structured. Currently, text\nvisualizations are confined either to _flat, line-based_ decorations, which can\nconvey only limited information about textual structure, or _nested boxes_,\nwhich convey structure but often destroy the typographic layout of the\nunderlying text. We hypothesize that the lack of rich styling options limits\nthe kinds of information that are displayed alongside text, wherever it may be\ndisplayed.\n  In this paper, we show that it is possible to achieve arbitrarily nested\ndecorations while minimally disturbing the underlying typographic layout.\nSpecifically, we present a layout algorithm that generates _ragged blocks_, or\n_rocks_, which are rectilinear polygons that allow nested text to be compactly\nrendered even when styled with borders and padding.\n  We evaluate our layout algorithm in two ways. First, on a benchmark suite\ncomprising representative source code files in multiple programming languages,\nwe show that the (ragged block) layouts produced by our algorithm are\nsubstantially more compact than the (rectangular block) layouts produced by\nconventional techniques, when uniformly styling every element in the syntax\ntree with borders and padding. Second, through a small gallery of usage\nscenarios, we demonstrate how future code editors, word processors, and other\ndocument-rendering GUIs might convey rich semantic information through\ndomain-specific styling of ragged blocks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06460v1", "cate": "cs.HC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06981", "title": "Optimizing Cognitive Networks: Reinforcement Learning Meets Energy Harvesting Over Cascaded Channels", "authors": ["Deemah H. Tashman", "Soumaya Cherkaoui", "Walaa Hamouda"], "categories": ["cs.ET", "cs.NI", "eess.SP"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06981v1", "summary": "This paper presents a reinforcement learning (RL) based approach to improve\nthe physical layer security (PLS) of an underlay cognitive radio network (CRN)\nover cascaded channels. These channels are utilized in highly mobile networks\nsuch as cognitive vehicular networks (CVN). In addition, an eavesdropper aims\nto intercept the communications between secondary users (SUs). The SU receiver\nhas full-duplex and energy harvesting capabilities to generate jamming signals\nto confound the eavesdropper and enhance security. Moreover, the SU transmitter\nextracts energy from ambient radio frequency signals in order to power\nsubsequent transmissions to its intended receiver. To optimize the privacy and\nreliability of the SUs in a CVN, a deep Q-network (DQN) strategy is utilized\nwhere multiple DQN agents are required such that an agent is assigned at each\nSU transmitter. The objective for the SUs is to determine the optimal\ntransmission power and decide whether to collect energy or transmit messages\nduring each time period in order to maximize their secrecy rate. Thereafter, we\npropose a DQN approach to maximize the throughput of the SUs while respecting\nthe interference threshold acceptable at the receiver of the primary user.\nAccording to our findings, our strategy outperforms two other baseline\nstrategies in terms of security and reliability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06981v1", "cate": "cs.ET", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07031", "title": "ZKTorch: Compiling ML Inference to Zero-Knowledge Proofs via Parallel Proof Accumulation", "authors": ["Bing-Jyue Chen", "Lilia Tang", "Daniel Kang"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      16 pages, 2 figures", "url": "http://arxiv.org/abs/2507.07031v1", "summary": "As AI models become ubiquitous in our daily lives, there has been an\nincreasing demand for transparency in ML services. However, the model owner\ndoes not want to reveal the weights, as they are considered trade secrets. To\nsolve this problem, researchers have turned to zero-knowledge proofs of ML\nmodel inference. These proofs convince the user that the ML model output is\ncorrect, without revealing the weights of the model to the user. Past work on\nthese provers can be placed into two categories. The first method compiles the\nML model into a low-level circuit, and proves the circuit using a ZK-SNARK. The\nsecond method uses custom cryptographic protocols designed only for a specific\nclass of models. Unfortunately, the first method is highly inefficient, making\nit impractical for the large models used today, and the second method does not\ngeneralize well, making it difficult to update in the rapidly changing field of\nmachine learning. To solve this, we propose ZKTorch, an open source end-to-end\nproving system that compiles ML models into base cryptographic operations\ncalled basic blocks, each proved using specialized protocols. ZKTorch is built\non top of a novel parallel extension to the Mira accumulation scheme, enabling\nsuccinct proofs with minimal accumulation overhead. These contributions allow\nZKTorch to achieve at least a $3\\times$ reduction in the proof size compared to\nspecialized protocols and up to a $6\\times$ speedup in proving time over a\ngeneral-purpose ZKML framework.", "comment": "16 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.07031v1", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06690", "title": "Multi-Task Multi-Agent Reinforcement Learning via Skill Graphs", "authors": ["Guobin Zhu", "Rui Zhou", "Wenkang Ji", "Hongyin Zhang", "Donglin Wang", "Shiyu Zhao"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Conditionally accepted by IEEE Robotics and Automation Letters", "url": "http://arxiv.org/abs/2507.06690v1", "summary": "Multi-task multi-agent reinforcement learning (MT-MARL) has recently gained\nattention for its potential to enhance MARL's adaptability across multiple\ntasks. However, it is challenging for existing multi-task learning methods to\nhandle complex problems, as they are unable to handle unrelated tasks and\npossess limited knowledge transfer capabilities. In this paper, we propose a\nhierarchical approach that efficiently addresses these challenges. The\nhigh-level module utilizes a skill graph, while the low-level module employs a\nstandard MARL algorithm. Our approach offers two contributions. First, we\nconsider the MT-MARL problem in the context of unrelated tasks, expanding the\nscope of MTRL. Second, the skill graph is used as the upper layer of the\nstandard hierarchical approach, with training independent of the lower layer,\neffectively handling unrelated tasks and enhancing knowledge transfer\ncapabilities. Extensive experiments are conducted to validate these advantages\nand demonstrate that the proposed method outperforms the latest hierarchical\nMAPPO algorithms. Videos and code are available at\nhttps://github.com/WindyLab/MT-MARL-SG", "comment": "Conditionally accepted by IEEE Robotics and Automation Letters", "pdf_url": "http://arxiv.org/pdf/2507.06690v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.05116", "title": "VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting", "authors": ["Juyi Lin", "Amir Taherin", "Arash Akbari", "Arman Akbari", "Lei Lu", "Guangyu Chen", "Taskin Padir", "Xiaomeng Yang", "Weiwei Chen", "Yiqian Li", "Xue Lin", "David Kaeli", "Pu Zhao", "Yanzhi Wang"], "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05116v1", "summary": "Recent large-scale Vision Language Action (VLA) models have shown superior\nperformance in robotic manipulation tasks guided by natural language. However,\ntheir generalization remains limited when applied to novel objects or\nunfamiliar environments that lie outside the training distribution. To address\nthis, many existing approaches integrate additional components such as depth\nestimation, segmentation, or even diffusion to improve generalization, at the\ncost of adding significant computation overhead, resulting in low efficiency.\nThis motivates the exploration of efficient action prediction methods, which\nare independent of additional high-level visual representations or diffusion\ntechniques. In this work, we propose VOTE, an efficient and general framework\nfor the optimization and acceleration of VLA models. In details, we propose a\nnovel tokenizer-free fine-tuning approach for parallel accurate action\nprediction, which reduces computational overhead and accelerates inference\nspeed. Additionally, we adopt an ensemble voting strategy for the action\nsampling, which significantly improves model performance and enhances\ngeneralization. Experimental results show that our method achieves\nstate-of-the-art performance with 35$\\times$ faster inference and 145 Hz\nthroughput. All the details and codes will be open-sourced.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05116v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06366", "title": "DecoyDB: A Dataset for Graph Contrastive Learning in Protein-Ligand Binding Affinity Prediction", "authors": ["Yupu Zhang", "Zelin Xu", "Tingsong Xiao", "Gustavo Seabra", "Yanjun Li", "Chenglong Li", "Zhe Jiang"], "categories": ["cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06366v1", "summary": "Predicting the binding affinity of protein-ligand complexes plays a vital\nrole in drug discovery. Unfortunately, progress has been hindered by the lack\nof large-scale and high-quality binding affinity labels. The widely used\nPDBbind dataset has fewer than 20K labeled complexes. Self-supervised learning,\nespecially graph contrastive learning (GCL), provides a unique opportunity to\nbreak the barrier by pre-training graph neural network models based on vast\nunlabeled complexes and fine-tuning the models on much fewer labeled complexes.\nHowever, the problem faces unique challenges, including a lack of a\ncomprehensive unlabeled dataset with well-defined positive/negative complex\npairs and the need to design GCL algorithms that incorporate the unique\ncharacteristics of such data. To fill the gap, we propose DecoyDB, a\nlarge-scale, structure-aware dataset specifically designed for self-supervised\nGCL on protein-ligand complexes. DecoyDB consists of high-resolution ground\ntruth complexes (less than 2.5 Angstrom) and diverse decoy structures with\ncomputationally generated binding poses that range from realistic to suboptimal\n(negative pairs). Each decoy is annotated with a Root Mean Squared Deviation\n(RMSD) from the native pose. We further design a customized GCL framework to\npre-train graph neural networks based on DecoyDB and fine-tune the models with\nlabels from PDBbind. Extensive experiments confirm that models pre-trained with\nDecoyDB achieve superior accuracy, label efficiency, and generalizability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06366v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06483", "title": "Learning Japanese with Jouzu: Interaction Outcomes with Stylized Dialogue Fictional Agents", "authors": ["Zackary Rackauckas", "Julia Hirschberg"], "categories": ["cs.HC", "cs.CL"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06483v1", "summary": "This study investigates how stylized, voiced agents shape user interaction in\na multimodal language learning environment. We conducted a mixed-methods\nevaluation of 54 participants interacting with anime-inspired characters\npowered by large language models and expressive text-to-speech synthesis. These\nagents responded in Japanese character language, offering users asynchronous,\nsemi-structured conversation in varying speech styles and emotional tones. We\nanalyzed user engagement patterns, perceived usability, emotional responses,\nand learning behaviors, with particular attention to how agent stylization\ninfluenced interaction across language proficiency levels and cultural\nbackgrounds. Our findings reveal that agent design, especially voice, persona,\nand linguistic style, substantially affected user experience, motivation, and\nstrategy. This work contributes to the understanding of affective, culturally\nstylized agents in human-agent interaction and offers guidance for designing\nmore engaging, socially responsive systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06483v1", "cate": "cs.HC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06983", "title": "Maximizing Reliability in Overlay Radio Networks with Time Switching and Power Splitting Energy Harvesting", "authors": ["Deemah H. Tashman", "Soumaya Cherkaoui", "Walaa Hamouda"], "categories": ["cs.ET", "cs.NI", "eess.SP"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06983v1", "summary": "Cognitive radio networks (CRNs) are acknowledged for their ability to tackle\nthe issue of spectrum under-utilization. In the realm of CRNs, this paper\ninvestigates the energy efficiency issue and addresses the critical challenge\nof optimizing system reliability for overlay CRN access mode. Randomly\ndispersed secondary users (SUs) serving as relays for primary users (PUs) are\nconsidered, in which one of these relays is designated to harvest energy\nthrough the time switching-energy harvesting (EH) protocol. Moreover, this\nrelay amplifies-and-forwards (AF) the PU's messages and broadcasts them along\nwith its own across cascaded $\\kappa$-$\\mu$ fading channels. The power\nsplitting protocol is another EH approach utilized by the SU and PU receivers\nto enhance the amount of energy in their storage devices. In addition, the SU\ntransmitters and the SU receiver are deployed with multiple antennas for\nreception and apply the maximal ratio combining approach. The outage\nprobability is utilized to assess both networks' reliability. Then, an energy\nefficiency evaluation is performed to determine the effectiveness of EH on the\nsystem. Finally, an optimization problem is provided with the goal of\nmaximizing the data rate of the SUs by optimizing the time switching and the\npower allocation parameters of the SU relay.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06983v1", "cate": "cs.ET", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07056", "title": "LoRAShield: Data-Free Editing Alignment for Secure Personalized LoRA Sharing", "authors": ["Jiahao Chen", "junhao li", "Yiming Wang", "Zhe Ma", "Yi Jiang", "Chunyi Zhou", "Qingming Li", "Tianyu Du", "Shouling Ji"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07056v1", "summary": "The proliferation of Low-Rank Adaptation (LoRA) models has democratized\npersonalized text-to-image generation, enabling users to share lightweight\nmodels (e.g., personal portraits) on platforms like Civitai and Liblib.\nHowever, this \"share-and-play\" ecosystem introduces critical risks: benign\nLoRAs can be weaponized by adversaries to generate harmful content (e.g.,\npolitical, defamatory imagery), undermining creator rights and platform safety.\nExisting defenses like concept-erasure methods focus on full diffusion models\n(DMs), neglecting LoRA's unique role as a modular adapter and its vulnerability\nto adversarial prompt engineering. To bridge this gap, we propose LoRAShield,\nthe first data-free editing framework for securing LoRA models against misuse.\nOur platform-driven approach dynamically edits and realigns LoRA's weight\nsubspace via adversarial optimization and semantic augmentation. Experimental\nresults demonstrate that LoRAShield achieves remarkable effectiveness,\nefficiency, and robustness in blocking malicious generations without\nsacrificing the functionality of the benign task. By shifting the defense to\nplatforms, LoRAShield enables secure, scalable sharing of personalized models,\na critical step toward trustworthy generative ecosystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07056v1", "cate": "cs.CR", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.06700", "title": "Integrating Perceptions: A Human-Centered Physical Safety Model for Human-Robot Interaction", "authors": ["Pranav Pandey", "Ramviyas Parasuraman", "Prashant Doshi"], "categories": ["cs.RO", "cs.HC"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE RO-MAN 2025 Conference", "url": "http://arxiv.org/abs/2507.06700v1", "summary": "Ensuring safety in human-robot interaction (HRI) is essential to foster user\ntrust and enable the broader adoption of robotic systems. Traditional safety\nmodels primarily rely on sensor-based measures, such as relative distance and\nvelocity, to assess physical safety. However, these models often fail to\ncapture subjective safety perceptions, which are shaped by individual traits\nand contextual factors. In this paper, we introduce and analyze a parameterized\ngeneral safety model that bridges the gap between physical and perceived safety\nby incorporating a personalization parameter, $\\rho$, into the safety\nmeasurement framework to account for individual differences in safety\nperception. Through a series of hypothesis-driven human-subject studies in a\nsimulated rescue scenario, we investigate how emotional state, trust, and robot\nbehavior influence perceived safety. Our results show that $\\rho$ effectively\ncaptures meaningful individual differences, driven by affective responses,\ntrust in task consistency, and clustering into distinct user types.\nSpecifically, our findings confirm that predictable and consistent robot\nbehavior as well as the elicitation of positive emotional states, significantly\nenhance perceived safety. Moreover, responses cluster into a small number of\nuser types, supporting adaptive personalization based on shared safety models.\nNotably, participant role significantly shapes safety perception, and repeated\nexposure reduces perceived safety for participants in the casualty role,\nemphasizing the impact of physical interaction and experiential change. These\nfindings highlight the importance of adaptive, human-centered safety models\nthat integrate both psychological and behavioral dimensions, offering a pathway\ntoward more trustworthy and effective HRI in safety-critical domains.", "comment": "Accepted to IEEE RO-MAN 2025 Conference", "pdf_url": "http://arxiv.org/pdf/2507.06700v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06249", "title": "Pronunciation-Lexicon Free Training for Phoneme-based Crosslingual ASR via Joint Stochastic Approximation", "authors": ["Saierdaer Yusuyin", "Te Ma", "Hao Huang", "Zhijian Ou"], "categories": ["eess.AS", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      submitted to IEEE TASLP", "url": "http://arxiv.org/abs/2507.06249v1", "summary": "Recently, pre-trained models with phonetic supervision have demonstrated\ntheir advantages for crosslingual speech recognition in data efficiency and\ninformation sharing across languages. However, a limitation is that a\npronunciation lexicon is needed for such phoneme-based crosslingual speech\nrecognition. In this study, we aim to eliminate the need for pronunciation\nlexicons and propose a latent variable model based method, with phonemes being\ntreated as discrete latent variables. The new method consists of a\nspeech-to-phoneme (S2P) model and a phoneme-to-grapheme (P2G) model, and a\ngrapheme-to-phoneme (G2P) model is introduced as an auxiliary inference model.\nTo jointly train the three models, we utilize the joint stochastic\napproximation (JSA) algorithm, which is a stochastic extension of the EM\n(expectation-maximization) algorithm and has demonstrated superior performance\nparticularly in estimating discrete latent variable models. Based on the\nWhistle multilingual pre-trained S2P model, crosslingual experiments are\nconducted in Polish (130 h) and Indonesian (20 h). With only 10 minutes of\nphoneme supervision, the new method, JSA-SPG, achieves 5\\% error rate\nreductions compared to the best crosslingual fine-tuning approach using subword\nor full phoneme supervision. Furthermore, it is found that in language domain\nadaptation (i.e., utilizing cross-domain text-only data), JSA-SPG outperforms\nthe standard practice of language model fusion via the auxiliary support of the\nG2P model by 9% error rate reductions. To facilitate reproducibility and\nencourage further exploration in this field, we open-source the JSA-SPG\ntraining code and complete pipeline.", "comment": "submitted to IEEE TASLP", "pdf_url": "http://arxiv.org/pdf/2507.06249v1", "cate": "eess.AS", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.06367", "title": "The Riemannian Geometry associated to Gradient Flows of Linear Convolutional Networks", "authors": ["El Mehdi Achour", "Kathlén Kohn", "Holger Rauhut"], "categories": ["cs.LG", "math.AG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06367v1", "summary": "We study geometric properties of the gradient flow for learning deep linear\nconvolutional networks. For linear fully connected networks, it has been shown\nrecently that the corresponding gradient flow on parameter space can be written\nas a Riemannian gradient flow on function space (i.e., on the product of weight\nmatrices) if the initialization satisfies a so-called balancedness condition.\nWe establish that the gradient flow on parameter space for learning linear\nconvolutional networks can be written as a Riemannian gradient flow on function\nspace regardless of the initialization. This result holds for $D$-dimensional\nconvolutions with $D \\geq 2$, and for $D =1$ it holds if all so-called strides\nof the convolutions are greater than one. The corresponding Riemannian metric\ndepends on the initialization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06367v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06561", "title": "Towards Designing Social Interventions for Online Climate Change Denialism Discussions", "authors": ["Ruican zhong", "Shruti Phadke", "Beth Goldberg", "Tanushree Mitra"], "categories": ["cs.HC", "cs.SI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06561v1", "summary": "As conspiracy theories gain traction, it has become crucial to research\neffective intervention strategies that can foster evidence and science-based\ndiscussions in conspiracy theory communities online. This study presents a\nnovel framework using insider language to contest conspiracy theory ideology in\nclimate change denialism on Reddit. Focusing on discussions in two Reddit\ncommunities, our research investigates reactions to pro-social and\nevidence-based intervention messages for two cohorts of users: climate change\ndeniers and climate change supporters. Specifically, we combine manual and\ngenerative AI-based methods to craft intervention messages and deploy the\ninterventions as replies on Reddit posts and comments through transparently\nlabeled bot accounts. On the one hand, we find that evidence-based\ninterventions with neutral language foster positive engagement, encouraging\nopen discussions among believers of climate change denialism. On the other,\nclimate change supporters respond positively, actively participating and\npresenting additional evidence. Our study contributes valuable insights into\nthe process and challenges of automatically delivering interventions in\nconspiracy theory communities on social media, and helps inform future research\non social media interventions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06561v1", "cate": "cs.HC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06361", "title": "Experimental Ground-State Energy of a 125-Site Flat Kagome Antiferromagnet via Hamiltonian Engineering on Quantum Computer", "authors": ["Muhammad Ahsan"], "categories": ["quant-ph", "cs.ET"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      To be submitted to the Physical Review Journal", "url": "http://arxiv.org/abs/2507.06361v1", "summary": "We present an instance of utility-grade quantum computation by calculating\nthe ground-state energy of a 125-site flat Kagome lattice under the\nantiferromagnetic Heisenberg model (KAFH), using IBM's Falcon and Hummingbird\nquantum processors. For spin-1/2 KAFH, our best per-site ground-state energy\nestimate reaches -0.417J, and after applying open-boundary corrections, it\nclosely approaches the established thermodynamic value of -0.438J. To achieve\nthis, we propose a hybrid approach that splits the variational quantum\neigensolver (VQE) into local (classical) and global (quantum) components for\nefficient hardware utilization. We further introduce a Hamiltonian engineering\nstrategy that increases coupling on defect triangles to mimic loop-flip\ndynamics, allowing us to simplify the ansatz while retaining physical accuracy.\nUsing a single-repetition, hardware-efficient ansatz, we entangle up to 103\nqubits with high fidelity to determine the Hamiltonian's lowest eigenvalue.\nThis work demonstrates the scalability of VQE for frustrated 2D systems and\nlays the foundation for future studies using deeper ansatz circuits and larger\nlattices.", "comment": "To be submitted to the Physical Review Journal", "pdf_url": "http://arxiv.org/pdf/2507.06361v1", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06234", "title": "Unveiling the Underwater World: CLIP Perception Model-Guided Underwater Image Enhancement", "authors": ["Jiangzhong Cao", "Zekai Zeng", "Xu Zhang", "Huan Zhang", "Chunling Fan", "Gangyi Jiang", "Weisi Lin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 7 figures;Accepted to PR 2025;The source code is available at this https URL", "url": "http://arxiv.org/abs/2507.06234v1", "summary": "High-quality underwater images are essential for both machine vision tasks\nand viewers with their aesthetic appeal.However, the quality of underwater\nimages is severely affected by light absorption and scattering. Deep\nlearning-based methods for Underwater Image Enhancement (UIE) have achieved\ngood performance. However, these methods often overlook considering human\nperception and lack sufficient constraints within the solution space.\nConsequently, the enhanced images often suffer from diminished perceptual\nquality or poor content restoration.To address these issues, we propose a UIE\nmethod with a Contrastive Language-Image Pre-Training (CLIP) perception loss\nmodule and curriculum contrastive regularization. Above all, to develop a\nperception model for underwater images that more aligns with human visual\nperception, the visual semantic feature extraction capability of the CLIP model\nis leveraged to learn an appropriate prompt pair to map and evaluate the\nquality of underwater images. This CLIP perception model is then incorporated\nas a perception loss module into the enhancement network to improve the\nperceptual quality of enhanced images. Furthermore, the CLIP perception model\nis integrated with the curriculum contrastive regularization to enhance the\nconstraints imposed on the enhanced images within the CLIP perceptual space,\nmitigating the risk of both under-enhancement and over-enhancement.\nSpecifically, the CLIP perception model is employed to assess and categorize\nthe learning difficulty level of negatives in the regularization process,\nensuring comprehensive and nuanced utilization of distorted images and\nnegatives with varied quality levels. Extensive experiments demonstrate that\nour method outperforms state-of-the-art methods in terms of visual quality and\ngeneralization ability.", "comment": "10 pages, 7 figures;Accepted to PR 2025;The source code is available\n  at https://github.com/Ave001025/UIE_CLIP", "pdf_url": "http://arxiv.org/pdf/2507.06234v1", "cate": "cs.CV", "date": "2025-04-29", "updated": "2025-04-29"}
{"id": "2507.05972", "title": "Generalized and Unified Equivalences between Hardness and Pseudoentropy", "authors": ["Lunjia Hu", "Salil Vadhan"], "categories": ["cs.CC", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05972v1", "summary": "Pseudoentropy characterizations provide a quantitatively precise\ndemonstration of the close relationship between computational hardness and\ncomputational randomness. We prove a unified pseudoentropy characterization\nthat generalizes and strengthens previous results for both uniform and\nnon-uniform models of computation. Our characterization holds for a general\nfamily of entropy notions that encompasses the common notions of Shannon\nentropy and min entropy as special cases. Moreover, we show that the\ncharacterizations for different entropy notions can be simultaneously achieved\nby a single, universal function that simultaneously witnesses computational\nhardness and computational randomness. A key technical insight of our work is\nthat the notion of weight-restricted calibration from the recent literature on\nalgorithm fairness, along with standard computational indistinguishability\n(known as multiaccuracy in the fairness literature), suffices for proving\npseudoentropy characterizations for general entropy notions. This demonstrates\nthe power of weight-restricted calibration to enhance the classic\nComplexity-Theoretic Regularity Lemma (Trevisan, Tulsiani, and Vadhan, 2009)\nand Leakage Simulation Lemma (Jetchev and Pietrzak, 2014) and allows us to\nachieve an exponential improvement in the complexity dependency on the alphabet\nsize compared to the pseudoentropy characterizations by Casacuberta, Dwork, and\nVadhan (2024) based on the much stronger notion of multicalibration. We show\nthat the exponential dependency on the alphabet size is inevitable for\nmulticalibration as well as for the weaker notion of calibrated multiaccuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05972v1", "cate": "cs.CC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06710", "title": "Spatial-Temporal Aware Visuomotor Diffusion Policy Learning", "authors": ["Zhenyang Liu", "Yikai Wang", "Kuanning Wang", "Longfei Liang", "Xiangyang Xue", "Yanwei Fu"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06710v1", "summary": "Visual imitation learning is effective for robots to learn versatile tasks.\nHowever, many existing methods rely on behavior cloning with supervised\nhistorical trajectories, limiting their 3D spatial and 4D spatiotemporal\nawareness. Consequently, these methods struggle to capture the 3D structures\nand 4D spatiotemporal relationships necessary for real-world deployment. In\nthis work, we propose 4D Diffusion Policy (DP4), a novel visual imitation\nlearning method that incorporates spatiotemporal awareness into diffusion-based\npolicies. Unlike traditional approaches that rely on trajectory cloning, DP4\nleverages a dynamic Gaussian world model to guide the learning of 3D spatial\nand 4D spatiotemporal perceptions from interactive environments. Our method\nconstructs the current 3D scene from a single-view RGB-D observation and\npredicts the future 3D scene, optimizing trajectory generation by explicitly\nmodeling both spatial and temporal dependencies. Extensive experiments across\n17 simulation tasks with 173 variants and 3 real-world robotic tasks\ndemonstrate that the 4D Diffusion Policy (DP4) outperforms baseline methods,\nimproving the average simulation task success rate by 16.4% (Adroit), 14%\n(DexArt), and 6.45% (RLBench), and the average real-world robotic task success\nrate by 8.6%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06710v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06261", "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities", "authors": ["Gheorghe Comanici", "Eric Bieber", "Mike Schaekermann", "Ice Pasupat", "Noveen Sachdeva", "Inderjit Dhillon", "Marcel Blistein", "Ori Ram", "Dan Zhang", "Evan Rosen", "Luke Marris", "Sam Petulla", "Colin Gaffney", "Asaf Aharoni", "Nathan Lintz", "Tiago Cardal Pais", "Henrik Jacobsson", "Idan Szpektor", "Nan-Jiang Jiang", "Krishna Haridasan", "Ahmed Omran", "Nikunj Saunshi", "Dara Bahri", "Gaurav Mishra", "Eric Chu", "Toby Boyd", "Brad Hekman", "Aaron Parisi", "Chaoyi Zhang", "Kornraphop Kawintiranon", "Tania Bedrax-Weiss", "Oliver Wang", "Ya Xu", "Ollie Purkiss", "Uri Mendlovic", "Ilaï Deutel", "Nam Nguyen", "Adam Langley", "Flip Korn", "Lucia Rossazza", "Alexandre Ramé", "Sagar Waghmare", "Helen Miller", "Vaishakh Keshava", "Ying Jian", "Xiaofan Zhang", "Raluca Ada Popa", "Kedar Dhamdhere", "Blaž Bratanič", "Kyuyeun Kim", "Terry Koo", "Ferran Alet", "Yi-ting Chen", "Arsha Nagrani", "Hannah Muckenhirn", "Zhiyuan Zhang", "Corbin Quick", "Filip Pavetić", "Duc Dung Nguyen", "Joao Carreira", "Michael Elabd", "Haroon Qureshi", "Fabian Mentzer", "Yao-Yuan Yang", "Danielle Eisenbud", "Anmol Gulati", "Ellie Talius", "Eric Ni", "Sahra Ghalebikesabi", "Edouard Yvinec", "Alaa Saade", "Thatcher Ulrich", "Lorenzo Blanco", "Dan A. Calian", "Muhuan Huang", "Aäron van den Oord", "Naman Goyal", "Terry Chen", "Praynaa Rawlani", "Christian Schallhart", "Swachhand Lokhande", "Xianghong Luo", "Jyn Shan", "Ceslee Montgomery", "Victoria Krakovna", "Federico Piccinini", "Omer Barak", "Jingyu Cui", "Yiling Jia", "Mikhail Dektiarev", "Alexey Kolganov", "Shiyu Huang", "Zhe Chen", "Xingyu Wang", "Jessica Austin", "Peter de Boursac", "Evgeny Sluzhaev", "Frank Ding", "Huijian Li", "Surya Bhupatiraju", "Mohit Agarwal", "Sławek Kwasiborski", "Paramjit Sandhu", "Patrick Siegler", "Ahmet Iscen", "Eyal Ben-David", "Shiraz Butt", "Miltos Allamanis", "Seth Benjamin", "Robert Busa-Fekete", "Felix Hernandez-Campos", "Sasha Goldshtein", "Matt Dibb", "Weiyang Zhang", "Annie Marsden", "Carey Radebaugh", "Stephen Roller", "Abhishek Nayyar", "Jacob Austin", "Tayfun Terzi", "Bhargav Kanagal Shamanna", "Pete Shaw", "Aayush Singh", "Florian Luisier", "Artur Mendonça", "Vaibhav Aggarwal", "Larisa Markeeva", "Claudio Fantacci", "Sergey Brin", "HyunJeong Choe", "Guanyu Wang", "Hartwig Adam", "Avigail Dabush", "Tatsuya Kiyono", "Eyal Marcus", "Jeremy Cole", "Theophane Weber", "Hongrae Lee", "Ronny Huang", "Alex Muzio", "Leandro Kieliger", "Maigo Le", "Courtney Biles", "Long Le", "Archit Sharma", "Chengrun Yang", "Avery Lamp", "Dave Dopson", "Nate Hurley", "Katrina", "Xu", "Zhihao Shan", "Shuang Song", "Jiewen Tan", "Alexandre Senges", "George Zhang", "Chong You", "Yennie Jun", "David Raposo", "Susanna Ricco", "Xuan Yang", "Weijie Chen", "Prakhar Gupta", "Arthur Szlam", "Kevin Villela", "Chun-Sung Ferng", "Daniel Kasenberg", "Chen Liang", "Rui Zhu", "Arunachalam Narayanaswamy", "Florence Perot", "Paul Pucciarelli", "Anna Shekhawat", "Alexey Stern", "Rishikesh Ingale", "Stefani Karp", "Sanaz Bahargam", "Adrian Goedeckemeyer", "Jie Han", "Sicheng Li", "Andrea Tacchetti", "Dian Yu", "Abhishek Chakladar", "Zhiying Zhang", "Mona El Mahdy", "Xu Gao", "Dale Johnson", "Samrat Phatale", "AJ Piergiovanni", "Hyeontaek Lim", "Clement Farabet", "Carl Lebsack", "Theo Guidroz", "John Blitzer", "Nico Duduta", "David Madras", "Steve Li", "Daniel von Dincklage", "Xin Li", "Mahdis Mahdieh", "George Tucker", "Ganesh Jawahar", "Owen Xiao", "Danny Tarlow", "Robert Geirhos", "Noam Velan", "Daniel Vlasic", "Kalesha Bullard", "SK Park", "Nishesh Gupta", "Kellie Webster", "Ayal Hitron", "Jieming Mao", "Julian Eisenschlos", "Laurel Prince", "Nina D'Souza", "Kelvin Zheng", "Sara Nasso", "Gabriela Botea", "Carl Doersch", "Caglar Unlu", "Chris Alberti", "Alexey Svyatkovskiy", "Ankita Goel", "Krzysztof Choromanski", "Pan-Pan Jiang", "Richard Nguyen", "Four Flynn", "Daria Ćurko", "Peter Chen", "Nicholas Roth", "Kieran Milan", "Caleb Habtegebriel", "Shashi Narayan", "Michael Moffitt", "Jake Marcus", "Thomas Anthony", "Brendan McMahan", "Gowoon Cheon", "Ruibo Liu", "Megan Barnes", "Lukasz Lew", "Rebeca Santamaria-Fernandez", "Mayank Upadhyay", "Arjun Akula", "Arnar Mar Hrafnkelsson", "Alvaro Caceres", "Andrew Bunner", "Michal Sokolik", "Subha Puttagunta", "Lawrence Moore", "Berivan Isik", "Weilun Chen", "Jay Hartford", "Lawrence Chan", "Pradeep Shenoy", "Dan Holtmann-Rice", "Jane Park", "Fabio Viola", "Alex Salcianu", "Sujeevan Rajayogam", "Ian Stewart-Binks", "Zelin Wu", "Richard Everett", "Xi Xiong", "Pierre-Antoine Manzagol", "Gary Leung", "Carl Saroufim", "Bo Pang", "Dawid Wegner", "George Papamakarios", "Jennimaria Palomaki", "Helena Pankov", "Guangda Lai", "Guilherme Tubone", "Shubin Zhao", "Theofilos Strinopoulos", "Seth Neel", "Mingqiu Wang", "Joe Kelley", "Li Li", "Pingmei Xu", "Anitha Vijayakumar", "Andrea D'olimpio", "Omer Levy", "Massimo Nicosia", "Grigory Rozhdestvenskiy", "Ni Lao", "Sirui Xie", "Yash Katariya", "Jon Simon", "Sanjiv Kumar", "Florian Hartmann", "Michael Kilgore", "Jinhyuk Lee", "Aroma Mahendru", "Roman Ring", "Tom Hennigan", "Fiona Lang", "Colin Cherry", "David Steiner", "Dawsen Hwang", "Ray Smith", "Pidong Wang", "Jeremy Chen", "Ming-Hsuan Yang", "Sam Kwei", "Philippe Schlattner", "Donnie Kim", "Ganesh Poomal Girirajan", "Nikola Momchev", "Ayushi Agarwal", "Xingyi Zhou", "Ilkin Safarli", "Zachary Garrett", "AJ Pierigiovanni", "Sarthak Jauhari", "Alif Raditya Rochman", "Shikhar Vashishth", "Quan Yuan", "Christof Angermueller", "Jon Blanton", "Xinying Song", "Nitesh Bharadwaj Gundavarapu", "Thi Avrahami", "Maxine Deines", "Subhrajit Roy", "Manish Gupta", "Christopher Semturs", "Shobha Vasudevan", "Aditya Srikanth Veerubhotla", "Shriya Sharma", "Josh Jacob", "Zhen Yang", "Andreas Terzis", "Dan Karliner", "Auriel Wright", "Tania Rojas-Esponda", "Ashley Brown", "Abhijit Guha Roy", "Pawan Dogra", "Andrei Kapishnikov", "Peter Young", "Wendy Kan", "Vinodh Kumar Rajendran", "Maria Ivanova", "Salil Deshmukh", "Chia-Hua Ho", "Mike Kwong", "Stav Ginzburg", "Annie Louis", "KP Sawhney", "Slav Petrov", "Jing Xie", "Yunfei Bai", "Georgi Stoyanov", "Alex Fabrikant", "Rajesh Jayaram", "Yuqi Li", "Joe Heyward", "Justin Gilmer", "Yaqing Wang", "Radu Soricut", "Luyang Liu", "Qingnan Duan", "Jamie Hayes", "Maura O'Brien", "Gaurav Singh Tomar", "Sivan Eiger", "Bahar Fatemi", "Jeffrey Hui", "Catarina Barros", "Adaeze Chukwuka", "Alena Butryna", "Saksham Thakur", "Austin Huang", "Zhufeng Pan", "Haotian Tang", "Serkan Cabi", "Tulsee Doshi", "Michiel Bakker", "Sumit Bagri", "Ruy Ley-Wild", "Adam Lelkes", "Jennie Lees", "Patrick Kane", "David Greene", "Shimu Wu", "Jörg Bornschein", "Gabriela Surita", "Sarah Hodkinson", "Fangtao Li", "Chris Hidey", "Sébastien Pereira", "Sean Ammirati", "Phillip Lippe", "Adam Kraft", "Pu Han", "Sebastian Gerlach", "Zifeng Wang", "Liviu Panait", "Feng Han", "Brian Farris", "Yingying Bi", "Hannah DeBalsi", "Miaosen Wang", "Gladys Tyen", "James Cohan", "Susan Zhang", "Jarred Barber", "Da-Woon Chung", "Jaeyoun Kim", "Markus Kunesch", "Steven Pecht", "Nami Akazawa", "Abe Friesen", "James Lyon", "Ali Eslami", "Junru Wu", "Jie Tan", "Yue Song", "Ravi Kumar", "Chris Welty", "Ilia Akolzin", "Gena Gibson", "Sean Augenstein", "Arjun Pillai", "Nancy Yuen", "Du Phan", "Xin Wang", "Iain Barr", "Heiga Zen", "Nan Hua", "Casper Liu", "Jilei", "Wang", "Tanuj Bhatia", "Hao Xu", "Oded Elyada", "Pushmeet Kohli", "Mirek Olšák", "Ke Chen", "Azalia Mirhoseini", "Noam Shazeer", "Shoshana Jakobovits", "Maggie Tran", "Nolan Ramsden", "Tarun Bharti", "Fred Alcober", "Yunjie Li", "Shilpa Shetty", "Jing Chen", "Dmitry Kalashnikov", "Megha Nawhal", "Sercan Arik", "Hanwen Chen", "Michiel Blokzijl", "Shubham Gupta", "James Rubin", "Rigel Swavely", "Sophie Bridgers", "Ian Gemp", "Chen Su", "Arun Suggala", "Juliette Pluto", "Mary Cassin", "Alain Vaucher", "Kaiyang Ji", "Jiahao Cai", "Andrew Audibert", "Animesh Sinha", "David Tian", "Efrat Farkash", "Amy Hua", "Jilin Chen", "Duc-Hieu Tran", "Edward Loper", "Nicole Brichtova", "Lara McConnaughey", "Ballie Sandhu", "Robert Leland", "Doug DeCarlo", "Andrew Over", "James Huang", "Xing Wu", "Connie Fan", "Eric Li", "Yun Lei", "Deepak Sharma", "Cosmin Paduraru", "Luo Yu", "Matko Bošnjak", "Phuong Dao", "Min Choi", "Sneha Kudugunta", "Jakub Adamek", "Carlos Guía", "Ali Khodaei", "Jie Feng", "Wenjun Zeng", "David Welling", "Sandeep Tata", "Christina Butterfield", "Andrey Vlasov", "Seliem El-Sayed", "Swaroop Mishra", "Tara Sainath", "Shentao Yang", "RJ Skerry-Ryan", "Jeremy Shar", "Robert Berry", "Arunkumar Rajendran", "Arun Kandoor", "Andrea Burns", "Deepali Jain", "Tom Stone", "Wonpyo Park", "Shibo Wang", "Albin Cassirer", "Guohui Wang", "Hayato Kobayashi", "Sergey Rogulenko", "Vineetha Govindaraj", "Mikołaj Rybiński", "Nadav Olmert", "Colin Evans", "Po-Sen Huang", "Kelvin Xu", "Premal Shah", "Terry Thurk", "Caitlin Sikora", "Mu Cai", "Jin Xie", "Elahe Dabir", "Saloni Shah", "Norbert Kalb", "Carrie Zhang", "Shruthi Prabhakara", "Amit Sabne", "Artiom Myaskovsky", "Vikas Raunak", "Blanca Huergo", "Behnam Neyshabur", "Jon Clark", "Ye Zhang", "Shankar Krishnan", "Eden Cohen", "Dinesh Tewari", "James Lottes", "Yumeya Yamamori", "Hui", "Li", "Mohamed Elhawaty", "Ada Maksutaj Oflazer", "Adrià Recasens", "Sheryl Luo", "Duy Nguyen", "Taylor Bos", "Kalyan Andra", "Ana Salazar", "Ed Chi", "Jeongwoo Ko", "Matt Ginsberg", "Anders Andreassen", "Anian Ruoss", "Todor Davchev", "Elnaz Davoodi", "Chenxi Liu", "Min Kim", "Santiago Ontanon", "Chi Ming To", "Dawei Jia", "Rosemary Ke", "Jing Wang", "Anna Korsun", "Moran Ambar", "Ilya Kornakov", "Irene Giannoumis", "Toni Creswell", "Denny Zhou", "Yi Su", "Ishaan Watts", "Aleksandr Zaks", "Evgenii Eltyshev", "Ziqiang Feng", "Sidharth Mudgal", "Alex Kaskasoli", "Juliette Love", "Kingshuk Dasgupta", "Sam Shleifer", "Richard Green", "Sungyong Seo", "Chansoo Lee", "Dale Webster", "Prakash Shroff", "Ganna Raboshchuk", "Isabel Leal", "James Manyika", "Sofia Erell", "Daniel Murphy", "Zhisheng Xiao", "Anton Bulyenov", "Julian Walker", "Mark Collier", "Matej Kastelic", "Nelson George", "Sushant Prakash", "Sailesh Sidhwani", "Alexey Frolov", "Steven Hansen", "Petko Georgiev", "Tiberiu Sosea", "Chris Apps", "Aishwarya Kamath", "David Reid", "Emma Cooney", "Charlotte Magister", "Oriana Riva", "Alec Go", "Pu-Chin Chen", "Sebastian Krause", "Nir Levine", "Marco Fornoni", "Ilya Figotin", "Nick Roy", "Parsa Mahmoudieh", "Vladimir Magay", "Mukundan Madhavan", "Jin Miao", "Jianmo Ni", "Yasuhisa Fujii", "Ian Chou", "George Scrivener", "Zak Tsai", "Siobhan Mcloughlin", "Jeremy Selier", "Sandra Lefdal", "Jeffrey Zhao", "Abhijit Karmarkar", "Kushal Chauhan", "Shivanker Goel", "Zhaoyi Zhang", "Vihan Jain", "Parisa Haghani", "Mostafa Dehghani", "Jacob Scott", "Erin Farnese", "Anastasija Ilić", "Steven Baker", "Julia Pawar", "Li Zhong", "Josh Camp", "Yoel Zeldes", "Shravya Shetty", "Anand Iyer", "Vít Listík", "Jiaxian Guo", "Luming Tang", "Mark Geller", "Simon Bucher", "Yifan Ding", "Hongzhi Shi", "Carrie Muir", "Dominik Grewe", "Ramy Eskander", "Octavio Ponce", "Boqing Gong", "Derek Gasaway", "Samira Khan", "Umang Gupta", "Angelos Filos", "Weicheng Kuo", "Klemen Kloboves", "Jennifer Beattie", "Christian Wright", "Leon Li", "Alicia Jin", "Sandeep Mariserla", "Miteyan Patel", "Jens Heitkaemper", "Dilip Krishnan", "Vivek Sharma", "David Bieber", "Christian Frank", "John Lambert", "Paul Caron", "Martin Polacek", "Mai Giménez", "Himadri Choudhury", "Xing Yu", "Sasan Tavakkol", "Arun Ahuja", "Franz Och", "Rodolphe Jenatton", "Wojtek Skut", "Bryan Richter", "David Gaddy", "Andy Ly", "Misha Bilenko", "Megh Umekar", "Ethan Liang", "Martin Sevenich", "Mandar Joshi", "Hassan Mansoor", "Rebecca Lin", "Sumit Sanghai", "Abhimanyu Singh", "Xiaowei Li", "Sudheendra Vijayanarasimhan", "Zaheer Abbas", "Yonatan Bitton", "Hansa Srinivasan", "Manish Reddy Vuyyuru", "Alexander Frömmgen", "Yanhua Sun", "Ralph Leith", "Alfonso Castaño", "DJ Strouse", "Le Yan", "Austin Kyker", "Satish Kambala", "Mary Jasarevic", "Thibault Sellam", "Chao Jia", "Alexander Pritzel", "Raghavender R", "Huizhong Chen", "Natalie Clay", "Sudeep Gandhe", "Sean Kirmani", "Sayna Ebrahimi", "Hannah Kirkwood", "Jonathan Mallinson", "Chao Wang", "Adnan Ozturel", "Kuo Lin", "Shyam Upadhyay", "Vincent Cohen-Addad", "Sean Purser-haskell", "Yichong Xu", "Ebrahim Songhori", "Babi Seal", "Alberto Magni", "Almog Gueta", "Tingting Zou", "Guru Guruganesh", "Thais Kagohara", "Hung Nguyen", "Khalid Salama", "Alejandro Cruzado Ruiz", "Justin Frye", "Zhenkai Zhu", "Matthias Lochbrunner", "Simon Osindero", "Wentao Yuan", "Lisa Lee", "Aman Prasad", "Lam Nguyen Thiet", "Daniele Calandriello", "Victor Stone", "Qixuan Feng", "Han Ke", "Maria Voitovich", "Geta Sampemane", "Lewis Chiang", "Ling Wu", "Alexander Bykovsky", "Matt Young", "Luke Vilnis", "Ishita Dasgupta", "Aditya Chawla", "Qin Cao", "Bowen Liang", "Daniel Toyama", "Szabolcs Payrits", "Anca Stefanoiu", "Dimitrios Vytiniotis", "Ankesh Anand", "Tianxiao Shen", "Blagoj Mitrevski", "Michael Tschannen", "Sreenivas Gollapudi", "Aishwarya P S", "José Leal", "Zhe Shen", "Han Fu", "Wei Wang", "Arvind Kannan", "Doron Kukliansky", "Sergey Yaroshenko", "Svetlana Grant", "Umesh Telang", "David Wood", "Alexandra Chronopoulou", "Alexandru Ţifrea", "Tao Zhou", "Tony", "Nguy\\~ên", "Muge Ersoy", "Anima Singh", "Meiyan Xie", "Emanuel Taropa", "Woohyun Han", "Eirikur Agustsson", "Andrei Sozanschi", "Hui Peng", "Alex Chen", "Yoel Drori", "Efren Robles", "Yang Gao", "Xerxes Dotiwalla", "Ying Chen", "Anudhyan Boral", "Alexei Bendebury", "John Nham", "Chris Tar", "Luis Castro", "Jiepu Jiang", "Canoee Liu", "Felix Halim", "Jinoo Baek", "Andy Wan", "Jeremiah Liu", "Yuan Cao", "Shengyang Dai", "Trilok Acharya", "Ruoxi Sun", "Fuzhao Xue", "Saket Joshi", "Morgane Lustman", "Yongqin Xian", "Rishabh Joshi", "Deep Karkhanis", "Nora Kassner", "Jamie Hall", "Xiangzhuo Ding", "Gan Song", "Gang Li", "Chen Zhu", "Yana Kulizhskaya", "Bin Ni", "Alexey Vlaskin", "Solomon Demmessie", "Lucio Dery", "Salah Zaiem", "Yanping Huang", "Cindy Fan", "Felix Gimeno", "Ananth Balashankar", "Koji Kojima", "Hagai Taitelbaum", "Maya Meng", "Dero Gharibian", "Sahil Singla", "Wei Chen", "Ambrose Slone", "Guanjie Chen", "Sujee Rajayogam", "Max Schumacher", "Suyog Kotecha", "Rory Blevins", "Qifei Wang", "Mor Hazan Taege", "Alex Morris", "Xin Liu", "Fayaz Jamil", "Richard Zhang", "Pratik Joshi", "Ben Ingram", "Tyler Liechty", "Ahmed Eleryan", "Scott Baird", "Alex Grills", "Gagan Bansal", "Shan Han", "Kiran Yalasangi", "Shawn Xu", "Majd Al Merey", "Isabel Gao", "Felix Weissenberger", "Igor Karpov", "Robert Riachi", "Ankit Anand", "Gautam Prasad", "Kay Lamerigts", "Reid Hayes", "Jamie Rogers", "Mandy Guo", "Ashish Shenoy", "Qiong", "Hu", "Kyle He", "Yuchen Liu", "Polina Zablotskaia", "Sagar Gubbi", "Yifan Chang", "Jay Pavagadhi", "Kristian Kjems", "Archita Vadali", "Diego Machado", "Yeqing Li", "Renshen Wang", "Dipankar Ghosh", "Aahil Mehta", "Dana Alon", "George Polovets", "Alessio Tonioni", "Nate Kushman", "Joel D'sa", "Lin Zhuo", "Allen Wu", "Rohin Shah", "John Youssef", "Jiayu Ye", "Justin Snyder", "Karel Lenc", "Senaka Buthpitiya", "Matthew Tung", "Jichuan Chang", "Tao Chen", "David Saxton", "Jenny Lee", "Lydia Lihui Zhang", "James Qin", "Prabakar Radhakrishnan", "Maxwell Chen", "Piotr Ambroszczyk", "Metin Toksoz-Exley", "Yan Zhong", "Nitzan Katz", "Brendan O'Donoghue", "Tamara von Glehn", "Adi Gerzi Rosenthal", "Aga Świetlik", "Xiaokai Zhao", "Nick Fernando", "Jinliang Wei", "Jieru Mei", "Sergei Vassilvitskii", "Diego Cedillo", "Pranjal Awasthi", "Hui Zheng", "Koray Kavukcuoglu", "Itay Laish", "Joseph Pagadora", "Marc Brockschmidt", "Christopher A. Choquette-Choo", "Arunkumar Byravan", "Yifeng Lu", "Xu Chen", "Mia Chen", "Kenton Lee", "Rama Pasumarthi", "Sijal Bhatnagar", "Aditya Shah", "Qiyin Wu", "Zhuoyuan Chen", "Zack Nado", "Bartek Perz", "Zixuan Jiang", "David Kao", "Ganesh Mallya", "Nino Vieillard", "Lantao Mei", "Sertan Girgin", "Mandy Jordan", "Yeongil Ko", "Alekh Agarwal", "Yaxin Liu", "Yasemin Altun", "Raoul de Liedekerke", "Anastasios Kementsietsidis", "Daiyi Peng", "Dangyi Liu", "Utku Evci", "Peter Humphreys", "Austin Tarango", "Xiang Deng", "Yoad Lewenberg", "Kevin Aydin", "Chengda Wu", "Bhavishya Mittal", "Tsendsuren Munkhdalai", "Kleopatra Chatziprimou", "Rodrigo Benenson", "Uri First", "Xiao Ma", "Jinning Li", "Armand Joulin", "Hamish Tomlinson", "Tingnan Zhang", "Milad Nasr", "Zhi Hong", "Michaël Sander", "Lisa Anne Hendricks", "Anuj Sharma", "Andrew Bolt", "Eszter Vértes", "Jiri Simsa", "Tomer Levinboim", "Olcan Sercinoglu", "Divyansh Shukla", "Austin Wu", "Craig Swanson", "Danny Vainstein", "Fan Bu", "Bo Wang", "Ryan Julian", "Charles Yoon", "Sergei Lebedev", "Antonious Girgis", "Bernd Bandemer", "David Du", "Todd Wang", "Xi Chen", "Ying Xiao", "Peggy Lu", "Natalie Ha", "Vlad Ionescu", "Simon Rowe", "Josip Matak", "Federico Lebron", "Andreas Steiner", "Lalit Jain", "Manaal Faruqui", "Nicolas Lacasse", "Georgie Evans", "Neesha Subramaniam", "Dean Reich", "Giulia Vezzani", "Aditya Pandey", "Joe Stanton", "Tianhao Zhou", "Liam McCafferty", "Henry Griffiths", "Verena Rieser", "Soheil Hassas Yeganeh", "Eleftheria Briakou", "Lu Huang", "Zichuan Wei", "Liangchen Luo", "Erik Jue", "Gabby Wang", "Victor Cotruta", "Myriam Khan", "Jongbin Park", "Qiuchen Guo", "Peiran Li", "Rong Rong", "Diego Antognini", "Anastasia Petrushkina", "Chetan Tekur", "Eli Collins", "Parul Bhatia", "Chester Kwak", "Wenhu Chen", "Arvind Neelakantan", "Immanuel Odisho", "Sheng Peng", "Vincent Nallatamby", "Vaibhav Tulsyan", "Fabian Pedregosa", "Peng Xu", "Raymond Lin", "Yulong Wang", "Emma Wang", "Sholto Douglas", "Reut Tsarfaty", "Elena Gribovskaya", "Renga Aravamudhan", "Manu Agarwal", "Mara Finkelstein", "Qiao Zhang", "Elizabeth Cole", "Phil Crone", "Sarmishta Velury", "Anil Das", "Chris Sauer", "Luyao Xu", "Danfeng Qin", "Chenjie Gu", "Dror Marcus", "CJ Zheng", "Wouter Van Gansbeke", "Sobhan Miryoosefi", "Haitian Sun", "YaGuang Li", "Charlie Chen", "Jae Yoo", "Pavel Dubov", "Alex Tomala", "Adams Yu", "Paweł Wesołowski", "Alok Gunjan", "Eddie Cao", "Jiaming Luo", "Nikhil Sethi", "Arkadiusz Socala", "Laura Graesser", "Tomas Kocisky", "Arturo BC", "Minmin Chen", "Edward Lee", "Sophie Wang", "Weize Kong", "Qiantong Xu", "Nilesh Tripuraneni", "Yiming Li", "Xinxin Yu", "Allen Porter", "Paul Voigtlaender", "Biao Zhang", "Arpi Vezer", "Sarah York", "Qing Wei", "Geoffrey Cideron", "Mark Kurzeja", "Seungyeon Kim", "Benny Li", "Angéline Pouget", "Hyo Lee", "Kaspar Daugaard", "Yang Li", "Dave Uthus", "Aditya Siddhant", "Paul Cavallaro", "Sriram Ganapathy", "Maulik Shah", "Rolf Jagerman", "Jeff Stanway", "Piermaria Mendolicchio", "Li Xiao", "Kayi Lee", "Tara Thompson", "Shubham Milind Phal", "Jason Chase", "Sun Jae Lee", "Adrian N Reyes", "Disha Shrivastava", "Zhen Qin", "Roykrong Sukkerd", "Seth Odoom", "Lior Madmoni", "John Aslanides", "Jonathan Herzig", "Elena Pochernina", "Sheng Zhang", "Parker Barnes", "Daisuke Ikeda", "Qiujia Li", "Shuo-yiin Chang", "Shakir Mohamed", "Jim Sproch", "Richard Powell", "Bidisha Samanta", "Domagoj Ćevid", "Anton Kovsharov", "Shrestha Basu Mallick", "Srinivas Tadepalli", "Anne Zheng", "Kareem Ayoub", "Andreas Noever", "Christian Reisswig", "Zhuo Xu", "Junhyuk Oh", "Martin Matysiak", "Tim Blyth", "Shereen Ashraf", "Julien Amelot", "Boone Severson", "Michele Bevilacqua", "Motoki Sano", "Ethan Dyer", "Ofir Roval", "Anu Sinha", "Yin Zhong", "Sagi Perel", "Tea Sabolić", "Johannes Mauerer", "Willi Gierke", "Mauro Verzetti", "Rodrigo Cabrera", "Alvin Abdagic", "Steven Hemingray", "Austin Stone", "Jong Lee", "Farooq Ahmad", "Karthik Raman", "Lior Shani", "Jonathan Lai", "Orhan Firat", "Nathan Waters", "Eric Ge", "Mo Shomrat", "Himanshu Gupta", "Rajeev Aggarwal", "Tom Hudson", "Bill Jia", "Simon Baumgartner", "Palak Jain", "Joe Kovac", "Junehyuk Jung", "Ante Žužul", "Will Truong", "Morteza Zadimoghaddam", "Songyou Peng", "Marco Liang", "Rachel Sterneck", "Balaji Lakshminarayanan", "Machel Reid", "Oliver Woodman", "Tong Zhou", "Jianling Wang", "Vincent Coriou", "Arjun Narayanan", "Jay Hoover", "Yenai Ma", "Apoorv Jindal", "Clayton Sanford", "Doug Reid", "Swaroop Ramaswamy", "Alex Kurakin", "Roland Zimmermann", "Yana Lunts", "Dragos Dena", "Zalán Borsos", "Vered Cohen", "Shujian Zhang", "Will Grathwohl", "Robert Dadashi", "Morgan Redshaw", "Joshua Kessinger", "Julian Odell", "Silvano Bonacina", "Zihang Dai", "Grace Chen", "Ayush Dubey", "Pablo Sprechmann", "Mantas Pajarskas", "Wenxuan Zhou", "Niharika Ahuja", "Tara Thomas", "Martin Nikoltchev", "Matija Kecman", "Bharath Mankalale", "Andrey Ryabtsev", "Jennifer She", "Christian Walder", "Jiaming Shen", "Lu Li", "Carolina Parada", "Sheena Panthaplackel", "Okwan Kwon", "Matt Lawlor", "Utsav Prabhu", "Yannick Schroecker", "Marc'aurelio Ranzato", "Pete Blois", "Iurii Kemaev", "Ting Yu", "Dmitry", "Lepikhin", "Hao Xiong", "Sahand Sharifzadeh", "Oleaser Johnson", "Jeremiah Willcock", "Rui Yao", "Greg Farquhar", "Sujoy Basu", "Hidetoshi Shimokawa", "Nina Anderson", "Haiguang Li", "Khiem Pham", "Yizhong Liang", "Sebastian Borgeaud", "Alexandre Moufarek", "Hideto Kazawa", "Blair Kutzman", "Marcin Sieniek", "Sara Smoot", "Ruth Wang", "Natalie Axelsson", "Nova Fallen", "Prasha Sundaram", "Yuexiang Zhai", "Varun Godbole", "Petros Maniatis", "Alek Wang", "Ilia Shumailov", "Santhosh Thangaraj", "Remi Crocker", "Nikita Gupta", "Gang Wu", "Phil Chen", "Gellért Weisz", "Celine Smith", "Mojtaba Seyedhosseini", "Boya Fang", "Xiyang Luo", "Roey Yogev", "Zeynep Cankara", "Andrew Hard", "Helen Ran", "Rahul Sukthankar", "George Necula", "Gaël Liu", "Honglong Cai", "Praseem Banzal", "Daniel Keysers", "Sanjay Ghemawat", "Connie Tao", "Emma Dunleavy", "Aditi Chaudhary", "Wei Li", "Maciej Mikuła", "Chen-Yu Lee", "Tiziana Refice", "Krishna Somandepalli", "Alexandre Fréchette", "Dan Bahir", "John Karro", "Keith Rush", "Sarah Perrin", "Bill Rosgen", "Xiaomeng Yang", "Clara Huiyi Hu", "Mahmoud Alnahlawi", "Justin Mao-Jones", "Roopal Garg", "Hoang Nguyen", "Bat-Orgil Batsaikhan", "Iñaki Iturrate", "Anselm Levskaya", "Avi Singh", "Ashyana Kachra", "Tony Lu", "Denis Petek", "Zheng Xu", "Mark Graham", "Lukas Zilka", "Yael Karov", "Marija Kostelac", "Fangyu Liu", "Yaohui Guo", "Weiyue Wang", "Bernd Bohnet", "Emily Pitler", "Tony Bruguier", "Keisuke Kinoshita", "Chrysovalantis Anastasiou", "Nilpa Jha", "Ting Liu", "Jerome Connor", "Phil Wallis", "Philip Pham", "Eric Bailey", "Shixin Li", "Heng-Tze Cheng", "Sally Ma", "Haiqiong Li", "Akanksha Maurya", "Kate Olszewska", "Manfred Warmuth", "Christy Koh", "Dominik Paulus", "Siddhartha Reddy Jonnalagadda", "Enrique Piqueras", "Ali Elqursh", "Geoff Brown", "Hadar Shemtov", "Loren Maggiore", "Fei Xia", "Ryan Foley", "Beka Westberg", "George van den Driessche", "Livio Baldini Soares", "Arjun Kar", "Michael Quinn", "Siqi Zuo", "Jialin Wu", "Kyle Kastner", "Anna Bortsova", "Aijun Bai", "Ales Mikhalap", "Luowei Zhou", "Jennifer Brennan", "Vinay Ramasesh", "Honglei Zhuang", "John Maggs", "Johan Schalkwyk", "Yuntao Xu", "Hui Huang", "Andrew Howard", "Sasha Brown", "Linting Xue", "Gloria Shen", "Brian Albert", "Neha Jha", "Daniel Zheng", "Varvara Krayvanova", "Spurthi Amba Hombaiah", "Olivier Lacombe", "Gautam Vasudevan", "Dan Graur", "Tian Xie", "Meet Gandhi", "Bangju Wang", "Dustin Zelle", "Harman Singh", "Dahun Kim", "Sébastien Cevey", "Victor Ungureanu", "Natasha Noy", "Fei Liu", "Annie Xie", "Fangxiaoyu Feng", "Katerina Tsihlas", "Daniel Formoso", "Neera Vats", "Quentin Wellens", "Yinan Wang", "Niket Kumar Bhumihar", "Samrat Ghosh", "Matt Hoffman", "Tom Lieber", "Oran Lang", "Kush Bhatia", "Tom Paine", "Aroonalok Pyne", "Ronny Votel", "Madeleine Clare Elish", "Benoit Schillings", "Alex Panagopoulos", "Haichuan Yang", "Adam Raveret", "Zohar Yahav", "Shuang Liu", "Warren Chen", "Dalia El Badawy", "Nishant Agrawal", "Mohammed Badawi", "Mahdi Mirzazadeh", "Carla Bromberg", "Fan Ye", "Chang Liu", "Tatiana Sholokhova", "George-Cristian Muraru", "Gargi Balasubramaniam", "Jonathan Malmaud", "Alen Carin", "Danilo Martins", "Irina Jurenka", "Pankil Botadra", "Dave Lacey", "Richa Singh", "Mariano Schain", "Dan Zheng", "Isabelle Guyon", "Victor Lavrenko", "Seungji Lee", "Xiang Zhou", "Demis Hassabis", "Jeshwanth Challagundla", "Derek Cheng", "Nikhil Mehta", "Matthew Mauger", "Michela Paganini", "Pushkar Mishra", "Kate Lee", "Zhang Li", "Lexi Baugher", "Ondrej Skopek", "Max Chang", "Amir Zait", "Gaurav Menghani", "Lizzetth Bellot", "Guangxing Han", "Jean-Michel Sarr", "Sharat Chikkerur", "Himanshu Sahni", "Rohan Anil", "Arun Narayanan", "Chandu Thekkath", "Daniele Pighin", "Hana Strejček", "Marko Velic", "Fred Bertsch", "Manuel Tragut", "Keran Rong", "Alicia Parrish", "Kai Bailey", "Jiho Park", "Isabela Albuquerque", "Abhishek Bapna", "Rajesh Venkataraman", "Alec Kosik", "Johannes Griesser", "Zhiwei Deng", "Alek Andreev", "Qingyun Dou", "Kevin Hui", "Fanny Wei", "Xiaobin Yu", "Lei Shu", "Avia Aharon", "David Barker", "Badih Ghazi", "Sebastian Flennerhag", "Chris Breaux", "Yuchuan Liu", "Matthew Bilotti", "Josh Woodward", "Uri Alon", "Stephanie Winkler", "Tzu-Kuo Huang", "Kostas Andriopoulos", "João Gabriel Oliveira", "Penporn Koanantakool", "Berkin Akin", "Michael Wunder", "Cicero Nogueira dos Santos", "Mohammad Hossein Bateni", "Lin Yang", "Dan Horgan", "Beer Changpinyo", "Keyvan Amiri", "Min Ma", "Dayeong Lee", "Lihao Liang", "Anirudh Baddepudi", "Tejasi Latkar", "Raia Hadsell", "Jun Xu", "Hairong Mu", "Michael Han", "Aedan Pope", "Snchit Grover", "Frank Kim", "Ankit Bhagatwala", "Guan Sun", "Yamini Bansal", "Amir Globerson", "Alireza Nazari", "Samira Daruki", "Hagen Soltau", "Jane Labanowski", "Laurent El Shafey", "Matt Harvey", "Yanif Ahmad", "Elan Rosenfeld", "William Kong", "Etienne Pot", "Yi-Xuan Tan", "Aurora Wei", "Victoria Langston", "Marcel Prasetya", "Petar Veličković", "Richard Killam", "Robin Strudel", "Darren Ni", "Zhenhai Zhu", "Aaron Archer", "Kavya Kopparapu", "Lynn Nguyen", "Emilio Parisotto", "Hussain Masoom", "Sravanti Addepalli", "Jordan Grimstad", "Hexiang Hu", "Joss Moore", "Avinatan Hassidim", "Le Hou", "Mukund Raghavachari", "Jared Lichtarge", "Adam R. Brown", "Hilal Dib", "Natalia Ponomareva", "Justin Fu", "Yujing Zhang", "Altaf Rahman", "Joana Iljazi", "Edouard Leurent", "Gabriel Dulac-Arnold", "Cosmo Du", "Chulayuth Asawaroengchai", "Larry Jin", "Ela Gruzewska", "Ziwei Ji", "Benigno Uria", "Daniel De Freitas", "Paul Barham", "Lauren Beltrone", "Víctor Campos", "Jun Yan", "Neel Kovelamudi", "Arthur Nguyen", "Elinor Davies", "Zhichun Wu", "Zoltan Egyed", "Kristina Toutanova", "Nithya Attaluri", "Hongliang Fei", "Peter Stys", "Siddhartha Brahma", "Martin Izzard", "Siva Velusamy", "Scott Lundberg", "Vincent Zhuang", "Kevin Sequeira", "Adam Santoro", "Ehsan Amid", "Ophir Aharoni", "Shuai Ye", "Mukund Sundararajan", "Lijun Yu", "Yu-Cheng Ling", "Stephen Spencer", "Hugo Song", "Josip Djolonga", "Christo Kirov", "Sonal Gupta", "Alessandro Bissacco", "Clemens Meyer", "Mukul Bhutani", "Andrew Dai", "Weiyi Wang", "Siqi Liu", "Ashwin Sreevatsa", "Qijun Tan", "Maria Wang", "Lucy Kim", "Yicheng Wang", "Alex Irpan", "Yang Xiao", "Stanislav Fort", "Yifan He", "Alex Gurney", "Bryan Gale", "Yue Ma", "Monica Roy", "Viorica Patraucean", "Taylan Bilal", "Golnaz Ghiasi", "Anahita Hosseini", "Melvin Johnson", "Zhuowan Li", "Yi Tay", "Benjamin Beyret", "Katie Millican", "Josef Broder", "Mayank Lunayach", "Danny Swisher", "Eugen Vušak", "David Parkinson", "MH Tessler", "Adi Mayrav Gilady", "Richard Song", "Allan Dafoe", "Yves Raimond", "Masa Yamaguchi", "Itay Karo", "Elizabeth Nielsen", "Kevin Kilgour", "Mike Dusenberry", "Rajiv Mathews", "Jiho Choi", "Siyuan Qiao", "Harsh Mehta", "Sahitya Potluri", "Chris Knutsen", "Jialu Liu", "Tat Tan", "Kuntal Sengupta", "Keerthana Gopalakrishnan", "Abodunrinwa Toki", "Mencher Chiang", "Mike Burrows", "Grace Vesom", "Zafarali Ahmed", "Ilia Labzovsky", "Siddharth Vashishtha", "Preeti Singh", "Ankur Sharma", "Ada Ma", "Jinyu Xie", "Pranav Talluri", "Hannah Forbes-Pollard", "Aarush Selvan", "Joel Wee", "Loic Matthey", "Tom Funkhouser", "Parthasarathy Gopavarapu", "Lev Proleev", "Cheng Li", "Matt Thomas", "Kashyap Kolipaka", "Zhipeng Jia", "Ashwin Kakarla", "Srinivas Sunkara", "Joan Puigcerver", "Suraj Satishkumar Sheth", "Emily Graves", "Chen Wang", "Sadh MNM Khan", "Kai Kang", "Shyamal Buch", "Fred Zhang", "Omkar Savant", "David Soergel", "Kevin Lee", "Linda Friso", "Xuanyi Dong", "Rahul Arya", "Shreyas Chandrakaladharan", "Connor Schenck", "Greg Billock", "Tejas Iyer", "Anton Bakalov", "Leslie Baker", "Alex Ruiz", "Angad Chandorkar", "Trieu Trinh", "Matt Miecnikowski", "Yanqi Zhou", "Yangsibo Huang", "Jiazhong Nie", "Ali Shah", "Ashish Thapliyal", "Sam Haves", "Lun Wang", "Uri Shaham", "Patrick Morris-Suzuki", "Soroush Radpour", "Leonard Berrada", "Thomas Strohmann", "Chaochao Yan", "Jingwei Shen", "Sonam Goenka", "Tris Warkentin", "Petar Dević", "Dan Belov", "Albert Webson", "Madhavi Yenugula", "Puranjay Datta", "Jerry Chang", "Nimesh Ghelani", "Aviral Kumar", "Vincent Perot", "Jessica Lo", "Yang Song", "Herman Schmit", "Jianmin Chen", "Vasilisa Bashlovkina", "Xiaoyue Pan", "Diana Mincu", "Paul Roit", "Isabel Edkins", "Andy Davis", "Yujia Li", "Ben Horn", "Xinjian Li", "Pradeep Kumar S", "Eric Doi", "Wanzheng Zhu", "Sri Gayatri Sundara Padmanabhan", "Siddharth Verma", "Jasmine Liu", "Heng Chen", "Mihajlo Velimirović", "Malcolm Reynolds", "Priyanka Agrawal", "Nick Sukhanov", "Abhinit Modi", "Siddharth Goyal", "John Palowitch", "Nima Khajehnouri", "Wing Lowe", "David Klinghoffer", "Sharon Silver", "Vinh Tran", "Candice Schumann", "Francesco Piccinno", "Xi Liu", "Mario Lučić", "Xiaochen Yang", "Sandeep Kumar", "Ajay Kannan", "Ragha Kotikalapudi", "Mudit Bansal", "Fabian Fuchs", "Javad Hosseini", "Abdelrahman Abdelhamed", "Dawn Bloxwich", "Tianhe Yu", "Ruoxin Sang", "Gregory Thornton", "Karan Gill", "Yuchi Liu", "Virat Shejwalkar", "Jason Lin", "Zhipeng Yan", "Kehang Han", "Thomas Buschmann", "Michael Pliskin", "Zhi Xing", "Susheel Tatineni", "Junlin Zhang", "Sissie Hsiao", "Gavin Buttimore", "Marcus Wu", "Zefei Li", "Geza Kovacs", "Legg Yeung", "Tao Huang", "Aaron Cohen", "Bethanie Brownfield", "Averi Nowak", "Mikel Rodriguez", "Tianze Shi", "Hado van Hasselt", "Kevin Cen", "Deepanway Ghoshal", "Kushal Majmundar", "Weiren Yu", "Warren", "Chen", "Danila Sinopalnikov", "Hao Zhang", "Vlado Galić", "Di Lu", "Zeyu Zheng", "Maggie Song", "Gary Wang", "Gui Citovsky", "Swapnil Gawde", "Isaac Galatzer-Levy", "David Silver", "Ivana Balazevic", "Dipanjan Das", "Kingshuk Majumder", "Yale Cong", "Praneet Dutta", "Dustin Tran", "Hui Wan", "Junwei Yuan", "Daniel Eppens", "Alanna Walton", "Been Kim", "Harry Ragan", "James Cobon-Kerr", "Lu Liu", "Weijun Wang", "Bryce Petrini", "Jack Rae", "Rakesh Shivanna", "Yan Xiong", "Chace Lee", "Pauline Coquinot", "Yiming Gu", "Lisa Patel", "Blake Hechtman", "Aviel Boag", "Orion Jankowski", "Alex Wertheim", "Alex Lee", "Paul Covington", "Hila Noga", "Sam Sobell", "Shanthal Vasanth", "William Bono", "Chirag Nagpal", "Wei Fan", "Xavier Garcia", "Kedar Soparkar", "Aybuke Turker", "Nathan Howard", "Sachit Menon", "Yuankai Chen", "Vikas Verma", "Vladimir Pchelin", "Harish Rajamani", "Valentin Dalibard", "Ana Ramalho", "Yang Guo", "Kartikeya Badola", "Seojin Bang", "Nathalie Rauschmayr", "Julia Proskurnia", "Sudeep Dasari", "Xinyun Chen", "Mikhail Sushkov", "Anja Hauth", "Pauline Sho", "Abhinav Singh", "Bilva Chandra", "Allie Culp", "Max Dylla", "Olivier Bachem", "James Besley", "Heri Zhao", "Timothy Lillicrap", "Wei Wei", "Wael Al Jishi", "Ning Niu", "Alban Rrustemi", "Raphaël Lopez Kaufman", "Ryan Poplin", "Jewel Zhao", "Minh Truong", "Shikhar Bharadwaj", "Ester Hlavnova", "Eli Stickgold", "Cordelia Schmid", "Georgi Stephanov", "Zhaoqi Leng", "Frederick Liu", "Léonard Hussenot", "Shenil Dodhia", "Juliana Vicente Franco", "Lesley Katzen", "Abhanshu Sharma", "Sarah Cogan", "Zuguang Yang", "Aniket Ray", "Sergi Caelles", "Shen Yan", "Ravin Kumar", "Daniel Gillick", "Renee Wong", "Joshua Ainslie", "Jonathan Hoech", "Séb Arnold", "Dan Abolafia", "Anca Dragan", "Ben Hora", "Grace Hu", "Alexey Guseynov", "Yang Lu", "Chas Leichner", "Jinmeng Rao", "Abhimanyu Goyal", "Nagabhushan Baddi", "Daniel Hernandez Diaz", "Tim McConnell", "Max Bain", "Jake Abernethy", "Qiqi Yan", "Rylan Schaeffer", "Paul Vicol", "Will Thompson", "Montse Gonzalez Arenas", "Mathias Bellaiche", "Pablo Barrio", "Stefan Zinke", "Riccardo Patana", "Pulkit Mehta", "JK Kearns", "Avraham Ruderman", "Scott Pollom", "David D'Ambrosio", "Cath Hope", "Yang Yu", "Andrea Gesmundo", "Kuang-Huei Lee", "Aviv Rosenberg", "Yiqian Zhou", "Yaoyiran Li", "Drew Garmon", "Yonghui Wu", "Safeen Huda", "Gil Fidel", "Martin Baeuml", "Jian Li", "Phoebe Kirk", "Rhys May", "Tao Tu", "Sara Mc Carthy", "Toshiyuki Fukuzawa", "Miranda Aperghis", "Chih-Kuan Yeh", "Toshihiro Yoshino", "Bo Li", "Austin Myers", "Kaisheng Yao", "Ben Limonchik", "Changwan Ryu", "Rohun Saxena", "Alex Goldin", "Ruizhe Zhao", "Rocky Rhodes", "Tao Zhu", "Divya Tyam", "Heidi Howard", "Nathan Byrd", "Hongxu Ma", "Yan Wu", "Ryan Mullins", "Qingze Wang", "Aida Amini", "Sebastien Baur", "Yiran Mao", "Subhashini Venugopalan", "Will Song", "Wen Ding", "Paul Collins", "Sashank Reddi", "Megan Shum", "Andrei Rusu", "Luisa Zintgraf", "Kelvin Chan", "Sheela Goenka", "Mathieu Blondel", "Michael Collins", "Renke Pan", "Marissa Giustina", "Nikolai Chinaev", "Christian Schuler", "Ce Zheng", "Jonas Valfridsson", "Alyssa Loo", "Alex Yakubovich", "Jamie Smith", "Tao Jiang", "Rich Munoz", "Gabriel Barcik", "Rishabh Bansal", "Mingyao Yang", "Yilun Du", "Pablo Duque", "Mary Phuong", "Alexandra Belias", "Kunal Lad", "Zeyu Liu", "Tal Schuster", "Karthik Duddu", "Jieru Hu", "Paige Kunkle", "Matthew Watson", "Jackson Tolins", "Josh Smith", "Denis Teplyashin", "Garrett Bingham", "Marvin Ritter", "Marco Andreetto", "Divya Pitta", "Mohak Patel", "Shashank Viswanadha", "Trevor Strohman", "Catalin Ionescu", "Jincheng Luo", "Yogesh Kalley", "Jeremy Wiesner", "Dan Deutsch", "Derek Lockhart", "Peter Choy", "Rumen Dangovski", "Chawin Sitawarin", "Cat Graves", "Tanya Lando", "Joost van Amersfoort", "Ndidi Elue", "Zhouyuan Huo", "Pooya Moradi", "Jean Tarbouriech", "Henryk Michalewski", "Wenting Ye", "Eunyoung Kim", "Alex Druinsky", "Florent Altché", "Xinyi Chen", "Artur Dwornik", "Da-Cheng Juan", "Rivka Moroshko", "Horia Toma", "Jarrod Kahn", "Hai Qian", "Maximilian Sieb", "Irene Cai", "Roman Goldenberg", "Praneeth Netrapalli", "Sindhu Raghuram", "Yuan Gong", "Lijie Fan", "Evan Palmer", "Yossi Matias", "Valentin Gabeur", "Shreya Pathak", "Tom Ouyang", "Don Metzler", "Geoff Bacon", "Srinivasan Venkatachary", "Sridhar Thiagarajan", "Alex Cullum", "Eran Ofek", "Vytenis Sakenas", "Mohamed Hammad", "Cesar Magalhaes", "Mayank Daswani", "Oscar Chang", "Ashok Popat", "Ruichao Li", "Komal Jalan", "Yanhan Hou", "Josh Lipschultz", "Antoine He", "Wenhao Jia", "Pier Giuseppe Sessa", "Prateek Kolhar", "William Wong", "Sumeet Singh", "Lukas Haas", "Jay Whang", "Hanna Klimczak-Plucińska", "Georges Rotival", "Grace Chung", "Yiqing Hua", "Anfal Siddiqui", "Nicolas Serrano", "Dongkai Chen", "Billy Porter", "Libin Bai", "Keshav Shivam", "Sho Arora", "Partha Talukdar", "Tom Cobley", "Sangnie Bhardwaj", "Evgeny Gladchenko", "Simon Green", "Kelvin Guu", "Felix Fischer", "Xiao Wu", "Eric Wang", "Achintya Singhal", "Tatiana Matejovicova", "James Martens", "Hongji Li", "Roma Patel", "Elizabeth Kemp", "Jiaqi Pan", "Lily Wang", "Blake JianHang Chen", "Jean-Baptiste Alayrac", "Navneet Potti", "Erika Gemzer", "Eugene Ie", "Kay McKinney", "Takaaki Saeki", "Edward Chou", "Pascal Lamblin", "SQ Mah", "Zach Fisher", "Martin Chadwick", "Jon Stritar", "Obaid Sarvana", "Andrew Hogue", "Artem Shtefan", "Hadi Hashemi", "Yang Xu", "Jindong Gu", "Sharad Vikram", "Chung-Ching Chang", "Sabela Ramos", "Logan Kilpatrick", "Weijuan Xi", "Jenny Brennan", "Yinghao Sun", "Abhishek Jindal", "Ionel Gog", "Dawn Chen", "Felix Wu", "Jason Lee", "Sudhindra Kopalle", "Srinadh Bhojanapalli", "Oriol Vinyals", "Natan Potikha", "Burcu Karagol Ayan", "Yuan Yuan", "Michael Riley", "Piotr Stanczyk", "Sergey Kishchenko", "Bing Wang", "Dan Garrette", "Antoine Yang", "Vlad Feinberg", "CJ Carey", "Javad Azizi", "Viral Shah", "Erica Moreira", "Chongyang Shi", "Josh Feldman", "Elizabeth Salesky", "Thomas Lampe", "Aneesh Pappu", "Duhyeon Kim", "Jonas Adler", "Avi Caciularu", "Brian Walker", "Yunhan Xu", "Yochai Blau", "Dylan Scandinaro", "Terry Huang", "Sam El-Husseini", "Abhishek Sinha", "Lijie Ren", "Taylor Tobin", "Patrik Sundberg", "Tim Sohn", "Vikas Yadav", "Mimi Ly", "Emily Xue", "Jing Xiong", "Afzal Shama Soudagar", "Sneha Mondal", "Nikhil Khadke", "Qingchun Ren", "Ben Vargas", "Stan Bileschi", "Sarah Chakera", "Cindy Wang", "Boyu Wang", "Yoni Halpern", "Joe Jiang", "Vikas Sindhwani", "Petre Petrov", "Pranavaraj Ponnuramu", "Sanket Vaibhav Mehta", "Yu Watanabe", "Betty Chan", "Matheus Wisniewski", "Trang Pham", "Jingwei Zhang", "Conglong Li", "Dario de Cesare", "Art Khurshudov", "Alex Vasiloff", "Melissa Tan", "Zoe Ashwood", "Bobak Shahriari", "Maryam Majzoubi", "Garrett Tanzer", "Olga Kozlova", "Robin Alazard", "James Lee-Thorp", "Nguyet Minh Phu", "Isaac Tian", "Junwhan Ahn", "Andy Crawford", "Lauren Lax", "Yuan", "Shangguan", "Iftekhar Naim", "David Ross", "Oleksandr Ferludin", "Tongfei Guo", "Andrea Banino", "Hubert Soyer", "Xiaoen Ju", "Dominika Rogozińska", "Ishaan Malhi", "Marcella Valentine", "Daniel Balle", "Apoorv Kulshreshtha", "Maciej Kula", "Yiwen Song", "Sophia Austin", "John Schultz", "Roy Hirsch", "Arthur Douillard", "Apoorv Reddy", "Michael Fink", "Summer Yue", "Khyatti Gupta", "Adam Zhang", "Norman Rink", "Daniel McDuff", "Lei Meng", "András György", "Yasaman Razeghi", "Ricky Liang", "Kazuki Osawa", "Aviel Atias", "Matan Eyal", "Tyrone Hill", "Nikolai Grigorev", "Zhengdong Wang", "Nitish Kulkarni", "Rachel Soh", "Ivan Lobov", "Zachary Charles", "Sid Lall", "Kazuma Hashimoto", "Ido Kessler", "Victor Gomes", "Zelda Mariet", "Danny Driess", "Alessandro Agostini", "Canfer Akbulut", "Jingcao Hu", "Marissa Ikonomidis", "Emily Caveness", "Kartik Audhkhasi", "Saurabh Agrawal", "Ioana Bica", "Evan Senter", "Jayaram Mudigonda", "Kelly Chen", "Jingchen Ye", "Xuanhui Wang", "James Svensson", "Philipp Fränken", "Josh Newlan", "Li Lao", "Eva Schnider", "Sami Alabed", "Joseph Kready", "Jesse Emond", "Afief Halumi", "Tim Zaman", "Chengxi Ye", "Naina Raisinghani", "Vilobh Meshram", "Bo Chang", "Ankit Singh Rawat", "Axel Stjerngren", "Sergey Levi", "Rui Wang", "Xiangzhu Long", "Mitchelle Rasquinha", "Steven Hand", "Aditi Mavalankar", "Lauren Agubuzu", "Sudeshna Roy", "Junquan Chen", "Jarek Wilkiewicz", "Hao Zhou", "Michal Jastrzebski", "Qiong Hu", "Agustin Dal Lago", "Ramya Sree Boppana", "Wei-Jen Ko", "Jennifer Prendki", "Yao Su", "Zhi Li", "Eliza Rutherford", "Girish Ramchandra Rao", "Ramona Comanescu", "Adrià Puigdomènech", "Qihang Chen", "Dessie Petrova", "Christine Chan", "Vedrana Milutinovic", "Felipe Tiengo Ferreira", "Chin-Yi Cheng", "Ming Zhang", "Tapomay Dey", "Sherry Yang", "Ramesh Sampath", "Quoc Le", "Howard Zhou", "Chu-Cheng Lin", "Hoi Lam", "Christine Kaeser-Chen", "Kai Hui", "Dean Hirsch", "Tom Eccles", "Basil Mustafa", "Shruti Rijhwani", "Morgane Rivière", "Yuanzhong Xu", "Junjie Wang", "Xinyang Geng", "Xiance Si", "Arjun Khare", "Cheolmin Kim", "Vahab Mirrokni", "Kamyu Lee", "Khuslen Baatarsukh", "Nathaniel Braun", "Lisa Wang", "Pallavi LV", "Richard Tanburn", "Yuvein", "Zhu", "Fangda Li", "Setareh Ariafar", "Dan Goldberg", "Ken Burke", "Daniil Mirylenka", "Meiqi Guo", "Olaf Ronneberger", "Hadas Natalie Vogel", "Liqun Cheng", "Nishita Shetty", "Johnson Jia", "Thomas Jimma", "Corey Fry", "Ted Xiao", "Martin Sundermeyer", "Ryan Burnell", "Yannis Assael", "Mario Pinto", "JD Chen", "Rohit Sathyanarayana", "Donghyun Cho", "Jing Lu", "Rishabh Agarwal", "Sugato Basu", "Lucas Gonzalez", "Dhruv Shah", "Meng Wei", "Dre Mahaarachchi", "Rohan Agrawal", "Tero Rissa", "Yani Donchev", "Ramiro Leal-Cavazos", "Adrian Hutter", "Markus Mircea", "Alon Jacovi", "Faruk Ahmed", "Jiageng Zhang", "Shuguang Hu", "Bo-Juen Chen", "Jonni Kanerva", "Guillaume Desjardins", "Andrew Lee", "Nikos Parotsidis", "Asier Mujika", "Tobias Weyand", "Jasper Snoek", "Jo Chick", "Kai Chen", "Paul Chang", "Ethan Mahintorabi", "Zi Wang", "Tolly Powell", "Orgad Keller", "Abhirut Gupta", "Claire Sha", "Kanav Garg", "Nicolas Heess", "Ágoston Weisz", "Cassidy Hardin", "Bartek Wydrowski", "Ben Coleman", "Karina Zainullina", "Pankaj Joshi", "Alessandro Epasto", "Terry Spitz", "Binbin Xiong", "Kai Zhao", "Arseniy Klimovskiy", "Ivy Zheng", "Johan Ferret", "Itay Yona", "Waleed Khawaja", "Jean-Baptiste Lespiau", "Maxim Krikun", "Siamak Shakeri", "Timothee Cour", "Bonnie Li", "Igor Krivokon", "Dan Suh", "Alex Hofer", "Jad Al Abdallah", "Nikita Putikhin", "Oscar Akerlund", "Silvio Lattanzi", "Anurag Kumar", "Shane Settle", "Himanshu Srivastava", "Folawiyo Campbell-Ajala", "Edouard Rosseel", "Mihai Dorin Istin", "Nishanth Dikkala", "Anand Rao", "Nick Young", "Kate Lin", "Dhruva Bhaswar", "Yiming Wang", "Jaume Sanchez Elias", "Kritika Muralidharan", "James Keeling", "Dayou Du", "Siddharth Gopal", "Gregory Dibb", "Charles Blundell", "Manolis Delakis", "Jacky Liang", "Marco Tulio Ribeiro", "Georgi Karadzhov", "Guillermo Garrido", "Ankur Bapna", "Jiawei Cao", "Adam Sadovsky", "Pouya Tafti", "Arthur Guez", "Coline Devin", "Yixian Di", "Jinwei Xing", "Chuqiao", "Xu", "Hanzhao Lin", "Chun-Te Chu", "Sameera Ponda", "Wesley Helmholz", "Fan Yang", "Yue Gao", "Sara Javanmardi", "Wael Farhan", "Alex Ramirez", "Ricardo Figueira", "Khe Chai Sim", "Yuval Bahat", "Ashwin Vaswani", "Liangzhe Yuan", "Gufeng Zhang", "Leland Rechis", "Hanjun Dai", "Tayo Oguntebi", "Alexandra Cordell", "Eugénie Rives", "Kaan Tekelioglu", "Naveen Kumar", "Bing Zhang", "Aurick Zhou", "Nikolay Savinov", "Andrew Leach", "Alex Tudor", "Sanjay Ganapathy", "Yanyan Zheng", "Mirko Rossini", "Vera Axelrod", "Arnaud Autef", "Yukun Zhu", "Zheng Zheng", "Mingda Zhang", "Baochen Sun", "Jie Ren", "Nenad Tomasev", "Nithish Kannan", "Amer Sinha", "Charles Chen", "Louis O'Bryan", "Alex Pak", "Aditya Kusupati", "Weel Yang", "Deepak Ramachandran", "Patrick Griffin", "Seokhwan Kim", "Philipp Neubeck", "Craig Schiff", "Tammo Spalink", "Mingyang Ling", "Arun Nair", "Ga-Young Joung", "Linda Deng", "Avishkar Bhoopchand", "Lora Aroyo", "Tom Duerig", "Jordan Griffith", "Gabe Barth-Maron", "Jake Ades", "Alex Haig", "Ankur Taly", "Yunting Song", "Paul Michel", "Dave Orr", "Dean Weesner", "Corentin Tallec", "Carrie Grimes Bostock", "Paul Niemczyk", "Andy Twigg", "Mudit Verma", "Rohith Vallu", "Henry Wang", "Marco Gelmi", "Kiranbir Sodhia", "Aleksandr Chuklin", "Omer Goldman", "Jasmine George", "Liang Bai", "Kelvin Zhang", "Petar Sirkovic", "Efrat Nehoran", "Golan Pundak", "Jiaqi Mu", "Alice Chen", "Alex Greve", "Paulo Zacchello", "David Amos", "Heming Ge", "Eric Noland", "Colton Bishop", "Jeffrey Dudek", "Youhei Namiki", "Elena Buchatskaya", "Jing Li", "Dorsa Sadigh", "Masha Samsikova", "Dan Malkin", "Damien Vincent", "Robert David", "Rob Willoughby", "Phoenix Meadowlark", "Shawn Gao", "Yan Li", "Raj Apte", "Amit Jhindal", "Stein Xudong Lin", "Alex Polozov", "Zhicheng Wang", "Tomas Mery", "Anirudh GP", "Varun Yerram", "Sage Stevens", "Tianqi Liu", "Noah Fiedel", "Charles Sutton", "Matthew Johnson", "Xiaodan Song", "Kate Baumli", "Nir Shabat", "Muqthar Mohammad", "Hao Liu", "Marco Selvi", "Yichao Zhou", "Mehdi Hafezi Manshadi", "Chu-ling Ko", "Anthony Chen", "Michael Bendersky", "Jorge Gonzalez Mendez", "Nisarg Kothari", "Amir Zandieh", "Yiling Huang", "Daniel Andor", "Ellie Pavlick", "Idan Brusilovsky", "Jitendra Harlalka", "Sally Goldman", "Andrew Lampinen", "Guowang Li", "Asahi Ushio", "Somit Gupta", "Lei Zhang", "Chuyuan Kelly Fu", "Madhavi Sewak", "Timo Denk", "Jed Borovik", "Brendan Jou", "Avital Zipori", "Prateek Jain", "Junwen Bai", "Thang Luong", "Jonathan Tompson", "Alice Li", "Li Liu", "George Powell", "Jiajun Shen", "Alex Feng", "Grishma Chole", "Da Yu", "Yinlam Chow", "Tongxin Yin", "Eric Malmi", "Kefan Xiao", "Yash Pande", "Shachi Paul", "Niccolò Dal Santo", "Adil Dostmohamed", "Sergio Guadarrama", "Aaron Phillips", "Thanumalayan Sankaranarayana Pillai", "Gal Yona", "Amin Ghafouri", "Preethi Lahoti", "Benjamin Lee", "Dhruv Madeka", "Eren Sezener", "Simon Tokumine", "Adrian Collister", "Nicola De Cao", "Richard Shin", "Uday Kalra", "Parker Beak", "Emily Nottage", "Ryo Nakashima", "Ivan Jurin", "Vikash Sehwag", "Meenu Gaba", "Junhao Zeng", "Kevin R. McKee", "Fernando Pereira", "Tamar Yakar", "Amayika Panda", "Arka Dhar", "Peilin Zhong", "Daniel Sohn", "Mark Brand", "Lars Lowe Sjoesund", "Viral Carpenter", "Sharon Lin", "Shantanu Thakoor", "Marcus Wainwright", "Ashwin Chaugule", "Pranesh Srinivasan", "Muye Zhu", "Bernett Orlando", "Jack Weber", "Ayzaan Wahid", "Gilles Baechler", "Apurv Suman", "Jovana Mitrović", "Gabe Taubman", "Honglin Yu", "Helen King", "Josh Dillon", "Cathy Yip", "Dhriti Varma", "Tomas Izo", "Levent Bolelli", "Borja De Balle Pigem", "Julia Di Trapani", "Fotis Iliopoulos", "Adam Paszke", "Nishant Ranka", "Joe Zou", "Francesco Pongetti", "Jed McGiffin", "Alex Siegman", "Rich Galt", "Ross Hemsley", "Goran Žužić", "Victor Carbune", "Tao Li", "Myle Ott", "Félix de Chaumont Quitry", "David Vilar Torres", "Yuri Chervonyi", "Tomy Tsai", "Prem Eruvbetine", "Samuel Yang", "Matthew Denton", "Jake Walker", "Slavica Andačić", "Idan Heimlich Shtacher", "Vittal Premachandran", "Harshal Tushar Lehri", "Cip Baetu", "Damion Yates", "Lampros Lamprou", "Mariko Iinuma", "Ioana Mihailescu", "Ben Albrecht", "Shachi Dave", "Susie Sargsyan", "Bryan Perozzi", "Lucas Manning", "Chiyuan Zhang", "Denis Vnukov", "Igor Mordatch", "Raia Hadsell Wolfgang Macherey", "Ryan Kappedal", "Jim Stephan", "Aditya Tripathi", "Klaus Macherey", "Jun Qian", "Abhishek Bhowmick", "Shekoofeh Azizi", "Rémi Leblond", "Shiva Mohan Reddy Garlapati", "Timothy Knight", "Matthew Wiethoff", "Wei-Chih Hung", "Anelia Angelova", "Georgios Evangelopoulos", "Pawel Janus", "Dimitris Paparas", "Matthew Rahtz", "Ken Caluwaerts", "Vivek Sampathkumar", "Daniel Jarrett", "Shadi Noghabi", "Antoine Miech", "Chak Yeung", "Geoff Clark", "Henry Prior", "Fei Zheng", "Jean Pouget-Abadie", "Indro Bhattacharya", "Kalpesh Krishna", "Will Bishop", "Zhe Yuan", "Yunxiao Deng", "Ashutosh Sathe", "Kacper Krasowiak", "Ciprian Chelba", "Cho-Jui Hsieh", "Kiran Vodrahalli", "Buhuang Liu", "Thomas Köppe", "Amr Khalifa", "Lubo Litchev", "Pichi Charoenpanit", "Reed Roberts", "Sachin Yadav", "Yasumasa Onoe", "Desi Ivanov", "Megha Mohabey", "Vighnesh Birodkar", "Nemanja Rakićević", "Pierre Sermanet", "Vaibhav Mehta", "Krishan Subudhi", "Travis Choma", "Will Ng", "Luheng He", "Kathie Wang", "Tasos Kementsietsidis", "Shane Gu", "Mansi Gupta", "Andrew Nystrom", "Mehran Kazemi", "Timothy Chung", "Nacho Cano", "Nikhil Dhawan", "Yufei Wang", "Jiawei Xia", "Trevor Yacovone", "Eric Jia", "Mingqing Chen", "Simeon Ivanov", "Ashrith Sheshan", "Sid Dalmia", "Paweł Stradomski", "Pengcheng Yin", "Salem Haykal", "Congchao Wang", "Dennis Duan", "Neslihan Bulut", "Greg Kochanski", "Liam MacDermed", "Namrata Godbole", "Shitao Weng", "Jingjing Chen", "Rachana Fellinger", "Ramin Mehran", "Daniel Suo", "Hisham Husain", "Tong He", "Kaushal Patel", "Joshua Howland", "Randall Parker", "Kelvin Nguyen", "Sharath Maddineni", "Chris Rawles", "Mina Khan", "Shlomi Cohen-Ganor", "Amol Mandhane", "Xinyi Wu", "Chenkai Kuang", "Iulia Comşa", "Ramya Ganeshan", "Hanie Sedghi", "Adam Bloniarz", "Nuo Wang Pierse", "Anton Briukhov", "Petr Mitrichev", "Anita Gergely", "Serena Zhan", "Allan Zhou", "Nikita Saxena", "Eva Lu", "Josef Dean", "Ashish Gupta", "Nicolas Perez-Nieves", "Renjie Wu", "Cory McLean", "Wei Liang", "Disha Jindal", "Anton Tsitsulin", "Wenhao Yu", "Kaiz Alarakyia", "Tom Schaul", "Piyush Patil", "Peter Sung", "Elijah Peake", "Hongkun Yu", "Feryal Behbahani", "JD Co-Reyes", "Alan Ansell", "Sean Sun", "Clara Barbu", "Jonathan Lee", "Seb Noury", "James Allingham", "Bilal Piot", "Mohit Sharma", "Christopher Yew", "Ivan Korotkov", "Bibo Xu", "Demetra Brady", "Goran Petrovic", "Shibl Mourad", "Claire Cui", "Aditya Gupta", "Parker Schuh", "Saarthak Khanna", "Anna Goldie", "Abhinav Arora", "Vadim Zubov", "Amy Stuart", "Mark Epstein", "Yun Zhu", "Jianqiao Liu", "Yury Stuken", "Ziyue Wang", "Karolis Misiunas", "Dee Guo", "Ashleah Gill", "Ale Hartman", "Zaid Nabulsi", "Aurko Roy", "Aleksandra Faust", "Jason Riesa", "Ben Withbroe", "Mengchao Wang", "Marco Tagliasacchi", "Andreea Marzoca", "James Noraky", "Serge Toropov", "Malika Mehrotra", "Bahram Raad", "Sanja Deur", "Steve Xu", "Marianne Monteiro", "Zhongru Wu", "Yi Luan", "Sam Ritter", "Nick Li", "Håvard Garnes", "Yanzhang He", "Martin Zlocha", "Jifan Zhu", "Matteo Hessel", "Will Wu", "Spandana Raj Babbula", "Chizu Kawamoto", "Yuanzhen Li", "Mehadi Hassen", "Yan Wang", "Brian Wieder", "James Freedman", "Yin Zhang", "Xinyi Bai", "Tianli Yu", "David Reitter", "XiangHai Sheng", "Mateo Wirth", "Aditya Kini", "Dima Damen", "Mingcen Gao", "Rachel Hornung", "Michael Voznesensky", "Brian Roark", "Adhi Kuncoro", "Yuxiang Zhou", "Rushin Shah", "Anthony Brohan", "Kuangyuan Chen", "James Wendt", "David Rim", "Paul Kishan Rubenstein", "Jonathan Halcrow", "Michelle Liu", "Ty Geri", "Yunhsuan Sung", "Jane Shapiro", "Shaan Bijwadia", "Chris Duvarney", "Christina Sorokin", "Paul Natsev", "Reeve Ingle", "Pramod Gupta", "Young Maeng", "Ndaba Ndebele", "Kexin Zhu", "Valentin Anklin", "Katherine Lee", "Yuan Liu", "Yaroslav Akulov", "Shaleen Gupta", "Guolong Su", "Flavien Prost", "Tianlin Liu", "Vitaly Kovalev", "Pol Moreno", "Martin Scholz", "Sam Redmond", "Zongwei Zhou", "Alex Castro-Ros", "André Susano Pinto", "Dia Kharrat", "Michal Yarom", "Rachel Saputro", "Jannis Bulian", "Ben Caine", "Ji Liu", "Abbas Abdolmaleki", "Shariq Iqbal", "Tautvydas Misiunas", "Mikhail Sirotenko", "Shefali Garg", "Guy Bensky", "Huan Gui", "Xuezhi Wang", "Raphael Koster", "Mike Bernico", "Da Huang", "Romal Thoppilan", "Trevor Cohn", "Ben Golan", "Wenlei Zhou", "Andrew Rosenberg", "Markus Freitag", "Tynan Gangwani", "Vincent Tsang", "Anand Shukla", "Xiaoqi Ren", "Minh Giang", "Chi Zou", "Andre Elisseeff", "Charline Le Lan", "Dheeru Dua", "Shuba Lall", "Pranav Shyam", "Frankie Garcia", "Sarah Nguyen", "Michael Guzman", "AJ Maschinot", "Marcello Maggioni", "Ming-Wei Chang", "Karol Gregor", "Lotte Weerts", "Kumaran Venkatesan", "Bogdan Damoc", "Leon Liu", "Jan Wassenberg", "Lewis Ho", "Becca Roelofs", "Majid Hadian", "François-Xavier Aubet", "Yu Liang", "Sami Lachgar", "Danny Karmon", "Yong Cheng", "Amelio Vázquez-Reina", "Angie Chen", "Zhuyun Dai", "Andy Brock", "Shubham Agrawal", "Chenxi Pang", "Peter Garst", "Mariella Sanchez-Vargas", "Ivor Rendulic", "Aditya Ayyar", "Andrija Ražnatović", "Olivia Ma", "Roopali Vij", "Neha Sharma", "Ashwin Balakrishna", "Bingyuan Liu", "Ian Mackinnon", "Sorin Baltateanu", "Petra Poklukar", "Gabriel Ibagon", "Colin Ji", "Hongyang Jiao", "Isaac Noble", "Wojciech Stokowiec", "Zhihao Li", "Jeff Dean", "David Lindner", "Mark Omernick", "Kristen Chiafullo", "Mason Dimarco", "Vitor Rodrigues", "Vittorio Selo", "Garrett Honke", "Xintian", "Wu", "Wei He", "Adam Hillier", "Anhad Mohananey", "Vihari Piratla", "Chang Ye", "Chase Malik", "Sebastian Riedel", "Samuel Albanie", "Zi Yang", "Kenny Vassigh", "Maria Bauza", "Sheng Li", "Yiqing Tao", "Nevan Wichers", "Andrii Maksai", "Abe Ittycheriah", "Ross Mcilroy", "Bryan Seybold", "Noah Goodman", "Romina Datta", "Steven M. Hernandez", "Tian Shi", "Yony Kochinski", "Anna Bulanova", "Ken Franko", "Mikita Sazanovich", "Nicholas FitzGerald", "Praneeth Kacham", "Shubha Srinivas Raghvendra", "Vincent Hellendoorn", "Alexander Grushetsky", "Julian Salazar", "Angeliki Lazaridou", "Jason Chang", "Jan-Thorsten Peter", "Sushant Kafle", "Yann Dauphin", "Abhishek Rao", "Filippo Graziano", "Izhak Shafran", "Yuguo Liao", "Tianli Ding", "Geng Yan", "Grace Chu", "Zhao Fu", "Vincent Roulet", "Gabriel Rasskin", "Duncan Williams", "Shahar Drath", "Alex Mossin", "Raphael Hoffmann", "Jordi Orbay", "Francesco Bertolini", "Hila Sheftel", "Justin Chiu", "Siyang Xue", "Yuheng Kuang", "Ferjad Naeem", "Swaroop Nath", "Nana Nti", "Phil Culliton", "Kashyap Krishnakumar", "Michael Isard", "Pei Sun", "Ayan Chakrabarti", "Nathan Clement", "Regev Cohen", "Arissa Wongpanich", "GS Oh", "Ashwin Murthy", "Hao Zheng", "Jessica Hamrick", "Oskar Bunyan", "Suhas Ganesh", "Nitish Gupta", "Roy Frostig", "John Wieting", "Yury Malkov", "Pierre Marcenac", "Zhixin", "Lai", "Xiaodan Tang", "Mohammad Saleh", "Fedir Zubach", "Chinmay Kulkarni", "Huanjie Zhou", "Vicky Zayats", "Nan Ding", "Anshuman Tripathi", "Arijit Pramanik", "Patrik Zochbauer", "Harish Ganapathy", "Vedant Misra", "Zach Behrman", "Hugo Vallet", "Mingyang Zhang", "Mukund Sridhar", "Ye Jin", "Mohammad Babaeizadeh", "Siim Põder", "Megha Goel", "Divya Jain", "Tajwar Nasir", "Shubham Mittal", "Tim Dozat", "Diego Ardila", "Aliaksei Severyn", "Fabio Pardo", "Sammy Jerome", "Siyang Qin", "Louis Rouillard", "Amir Yazdanbakhsh", "Zizhao Zhang", "Shivani Agrawal", "Kaushik Shivakumar", "Caden Lu", "Praveen Kallakuri", "Rachita Chhaparia", "Kanishka Rao", "Charles Kwong", "Asya Fadeeva", "Shitij Nigam", "Yan Virin", "Yuan Zhang", "Balaji Venkatraman", "Beliz Gunel", "Marc Wilson", "Huiyu Wang", "Abhinav Gupta", "Xiaowei Xu", "Adrien Ali Taïga", "Kareem Mohamed", "Doug Fritz", "Daniel Rodriguez", "Zoubin Ghahramani", "Harry Askham", "Lior Belenki", "James Zhao", "Rahul Gupta", "Krzysztof Jastrzębski", "Takahiro Kosakai", "Kaan Katircioglu", "Jon Schneider", "Rina Panigrahy", "Konstantinos Bousmalis", "Peter Grabowski", "Prajit Ramachandran", "Chaitra Hegde", "Mihaela Rosca", "Angelo Scorza Scarpati", "Kyriakos Axiotis", "Ying Xu", "Zach Gleicher", "Assaf Hurwitz Michaely", "Mandar Sharma", "Sanil Jain", "Christoph Hirnschall", "Tal Marian", "Xuhui Jia", "Kevin Mather", "Kilol Gupta", "Linhai Qiu", "Nigamaa Nayakanti", "Lucian Ionita", "Steven Zheng", "Lucia Loher", "Kurt Shuster", "Igor Petrovski", "Roshan Sharma", "Rahma Chaabouni", "Angel Yeh", "James An", "Arushi Gupta", "Steven Schwarcz", "Seher Ellis", "Sam Conway-Rahman", "Javier Snaider", "Alex Zhai", "James Atwood", "Daniel Golovin", "Liqian Peng", "Te I", "Vivian Xia", "Salvatore Scellato", "Mahan Malihi", "Arthur Bražinskas", "Vlad-Doru Ion", "Younghoon Jun", "James Swirhun", "Soroosh Mariooryad", "Jiao Sun", "Steve Chien", "Rey Coaguila", "Ariel Brand", "Yi Gao", "Tom Kwiatkowski", "Roee Aharoni", "Cheng-Chun Lee", "Mislav Žanić", "Yichi Zhang", "Dan Ethier", "Vitaly Nikolaev", "Pranav Nair", "Yoav Ben Shalom", "Hen Fitoussi", "Jai Gupta", "Hongbin Liu", "Dee Cattle", "Tolga Bolukbasi", "Ben Murdoch", "Fantine Huot", "Yin Li", "Chris Hahn"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      72 pages, 17 figures", "url": "http://arxiv.org/abs/2507.06261v1", "summary": "In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and\nGemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite\nmodels. Gemini 2.5 Pro is our most capable model yet, achieving SoTA\nperformance on frontier coding and reasoning benchmarks. In addition to its\nincredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that\nexcels at multimodal understanding and it is now able to process up to 3 hours\nof video content. Its unique combination of long context, multimodal and\nreasoning capabilities can be combined to unlock new agentic workflows. Gemini\n2.5 Flash provides excellent reasoning abilities at a fraction of the compute\nand latency requirements and Gemini 2.0 Flash and Flash-Lite provide high\nperformance at low latency and cost. Taken together, the Gemini 2.X model\ngeneration spans the full Pareto frontier of model capability vs cost, allowing\nusers to explore the boundaries of what is possible with complex agentic\nproblem solving.", "comment": "72 pages, 17 figures", "pdf_url": "http://arxiv.org/pdf/2507.06261v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06380", "title": "Secure and Storage-Efficient Deep Learning Models for Edge AI Using Automatic Weight Generation", "authors": ["Habibur Rahaman", "Atri Chatterjee", "Swarup Bhunia"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      7 pages, 7 figures", "url": "http://arxiv.org/abs/2507.06380v1", "summary": "Complex neural networks require substantial memory to store a large number of\nsynaptic weights. This work introduces WINGs (Automatic Weight Generator for\nSecure and Storage-Efficient Deep Learning Models), a novel framework that\ndynamically generates layer weights in a fully connected neural network (FC)\nand compresses the weights in convolutional neural networks (CNNs) during\ninference, significantly reducing memory requirements without sacrificing\naccuracy. WINGs framework uses principal component analysis (PCA) for\ndimensionality reduction and lightweight support vector regression (SVR) models\nto predict layer weights in the FC networks, removing the need for storing\nfull-weight matrices and achieving substantial memory savings. It also\npreferentially compresses the weights in low-sensitivity layers of CNNs using\nPCA and SVR with sensitivity analysis. The sensitivity-aware design also offers\nan added level of security, as any bit-flip attack with weights in compressed\nlayers has an amplified and readily detectable effect on accuracy. WINGs\nachieves 53x compression for the FC layers and 28x for AlexNet with MNIST\ndataset, and 18x for Alexnet with CIFAR-10 dataset with 1-2% accuracy loss.\nThis significant reduction in memory results in higher throughput and lower\nenergy for DNN inference, making it attractive for resource-constrained edge\napplications.", "comment": "7 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.06380v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06669", "title": "Smartphone Exergames with Real-Time Markerless Motion Capture: Challenges and Trade-offs", "authors": ["Mathieu Phosanarack", "Laura Wallard", "Sophie Lepreux", "Christophe Kolski", "Eugénie Avril"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      CHI '25 Workshop on Envisioning the Future of Interactive Health, Apr 2025, Yokohama, Japan", "url": "http://arxiv.org/abs/2507.06669v1", "summary": "Markerless Motion Capture (MoCap) using smartphone cameras is a promising\napproach to making exergames more accessible and cost-effective for health and\nrehabilitation. Unlike traditional systems requiring specialized hardware,\nrecent advancements in AI-powered pose estimation enable movement tracking\nusing only a mobile device. For an upcoming study, a mobile application with\nreal-time exergames including markerless motion capture is being developed.\nHowever, implementing such technology introduces key challenges, including\nbalancing accuracy and real-time responsiveness, ensuring proper user\ninteraction. Future research should explore optimizing AI models for realtime\nperformance, integrating adaptive gamification, and refining user-centered\ndesign principles. By overcoming these challenges, smartphone-based exergames\ncould become powerful tools for engaging users in physical activity and\nrehabilitation, extending their benefits to a broader audience.", "comment": "CHI '25 Workshop on Envisioning the Future of Interactive Health, Apr\n  2025, Yokohama, Japan", "pdf_url": "http://arxiv.org/pdf/2507.06669v1", "cate": "cs.HC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06528", "title": "InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior", "authors": ["Huisheng Wang", "Zhuoshi Pan", "Hangjing Zhang", "Mingxiao Liu", "Hanqing Gao", "H. Vicky Zhao"], "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06528v1", "summary": "Aligning Large Language Models (LLMs) with investor decision-making processes\nunder herd behavior is a critical challenge in behavioral finance, which\ngrapples with a fundamental limitation: the scarcity of real-user data needed\nfor Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM\noutputs and human behavioral patterns, its reliance on massive authentic data\nimposes substantial collection costs and privacy risks. We propose InvestAlign,\na novel framework that constructs high-quality SFT datasets by leveraging\ntheoretical solutions to similar and simple optimal investment problems rather\nthan complex scenarios. Our theoretical analysis demonstrates that training\nLLMs with InvestAlign-generated data achieves faster parameter convergence than\nusing real-user data, suggesting superior learning efficiency. Furthermore, we\ndevelop InvestAgent, an LLM agent fine-tuned with InvestAlign, which\ndemonstrates significantly closer alignment to real-user data than pre-SFT\nmodels in both simple and complex investment problems. This highlights our\nproposed InvestAlign as a promising approach with the potential to address\ncomplex optimal investment problems and align LLMs with investor\ndecision-making processes under herd behavior. Our code is publicly available\nat https://github.com/thu-social-network-research-group/InvestAlign.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06528v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06265", "title": "SPARC: Concept-Aligned Sparse Autoencoders for Cross-Model and Cross-Modal Interpretability", "authors": ["Ali Nasiri-Sarvi", "Hassan Rivaz", "Mahdi S. Hosseini"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06265v1", "summary": "Understanding how different AI models encode the same high-level concepts,\nsuch as objects or attributes, remains challenging because each model typically\nproduces its own isolated representation. Existing interpretability methods\nlike Sparse Autoencoders (SAEs) produce latent concepts individually for each\nmodel, resulting in incompatible concept spaces and limiting cross-model\ninterpretability. To address this, we introduce SPARC (Sparse Autoencoders for\nAligned Representation of Concepts), a new framework that learns a single,\nunified latent space shared across diverse architectures and modalities (e.g.,\nvision models like DINO, and multimodal models like CLIP). SPARC's alignment is\nenforced through two key innovations: (1) a Global TopK sparsity mechanism,\nensuring all input streams activate identical latent dimensions for a given\nconcept; and (2) a Cross-Reconstruction Loss, which explicitly encourages\nsemantic consistency between models. On Open Images, SPARC dramatically\nimproves concept alignment, achieving a Jaccard similarity of 0.80, more than\ntripling the alignment compared to previous methods. SPARC creates a shared\nsparse latent space where individual dimensions often correspond to similar\nhigh-level concepts across models and modalities, enabling direct comparison of\nhow different architectures represent identical concepts without requiring\nmanual alignment or model-specific analysis. As a consequence of this aligned\nrepresentation, SPARC also enables practical applications such as text-guided\nspatial localization in vision-only models and cross-model/cross-modal\nretrieval. Code and models are available at\nhttps://github.com/AtlasAnalyticsLab/SPARC.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06265v1", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06402", "title": "Detection of Intelligent Tampering in Wireless Electrocardiogram Signals Using Hybrid Machine Learning", "authors": ["Siddhant Deshpande", "Yalemzerf Getnet", "Waltenegus Dargie"], "categories": ["cs.LG", "cs.CR", "eess.SP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06402v1", "summary": "With the proliferation of wireless electrocardiogram (ECG) systems for health\nmonitoring and authentication, protecting signal integrity against tampering is\nbecoming increasingly important. This paper analyzes the performance of CNN,\nResNet, and hybrid Transformer-CNN models for tamper detection. It also\nevaluates the performance of a Siamese network for ECG based identity\nverification. Six tampering strategies, including structured segment\nsubstitutions and random insertions, are emulated to mimic real world attacks.\nThe one-dimensional ECG signals are transformed into a two dimensional\nrepresentation in the time frequency domain using the continuous wavelet\ntransform (CWT). The models are trained and evaluated using ECG data from 54\nsubjects recorded in four sessions 2019 to 2025 outside of clinical settings\nwhile the subjects performed seven different daily activities. Experimental\nresults show that in highly fragmented manipulation scenarios, CNN,\nFeatCNN-TranCNN, FeatCNN-Tran and ResNet models achieved an accuracy exceeding\n99.5 percent . Similarly, for subtle manipulations (for example, 50 percent\nfrom A and 50 percent from B and, 75 percent from A and 25 percent from B\nsubstitutions) our FeatCNN-TranCNN model demonstrated consistently reliable\nperformance, achieving an average accuracy of 98 percent . For identity\nverification, the pure Transformer-Siamese network achieved an average accuracy\nof 98.30 percent . In contrast, the hybrid CNN-Transformer Siamese model\ndelivered perfect verification performance with 100 percent accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06402v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06747", "title": "LOVON: Legged Open-Vocabulary Object Navigator", "authors": ["Daojie Peng", "Jiahang Cao", "Qiang Zhang", "Jun Ma"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      9 pages, 10 figures; Project Page: this https URL", "url": "http://arxiv.org/abs/2507.06747v1", "summary": "Object navigation in open-world environments remains a formidable and\npervasive challenge for robotic systems, particularly when it comes to\nexecuting long-horizon tasks that require both open-world object detection and\nhigh-level task planning. Traditional methods often struggle to integrate these\ncomponents effectively, and this limits their capability to deal with complex,\nlong-range navigation missions. In this paper, we propose LOVON, a novel\nframework that integrates large language models (LLMs) for hierarchical task\nplanning with open-vocabulary visual detection models, tailored for effective\nlong-range object navigation in dynamic, unstructured environments. To tackle\nreal-world challenges including visual jittering, blind zones, and temporary\ntarget loss, we design dedicated solutions such as Laplacian Variance Filtering\nfor visual stabilization. We also develop a functional execution logic for the\nrobot that guarantees LOVON's capabilities in autonomous navigation, task\nadaptation, and robust task completion. Extensive evaluations demonstrate the\nsuccessful completion of long-sequence tasks involving real-time detection,\nsearch, and navigation toward open-vocabulary dynamic targets. Furthermore,\nreal-world experiments across different legged robots (Unitree Go2, B2, and\nH1-2) showcase the compatibility and appealing plug-and-play feature of LOVON.", "comment": "9 pages, 10 figures; Project Page:\n  https://daojiepeng.github.io/LOVON/", "pdf_url": "http://arxiv.org/pdf/2507.06747v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06263", "title": "The Emotional Alignment Design Policy", "authors": ["Eric Schwitzgebel", "Jeff Sebo"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06263v1", "summary": "According to what we call the Emotional Alignment Design Policy, artificial\nentities should be designed to elicit emotional reactions from users that\nappropriately reflect the entities' capacities and moral status, or lack\nthereof. This principle can be violated in two ways: by designing an artificial\nsystem that elicits stronger or weaker emotional reactions than its capacities\nand moral status warrant (overshooting or undershooting), or by designing a\nsystem that elicits the wrong type of emotional reaction (hitting the wrong\ntarget). Although presumably attractive, practical implementation faces several\nchallenges including: How can we respect user autonomy while promoting\nappropriate responses? How should we navigate expert and public disagreement\nand uncertainty about facts and values? What if emotional alignment seems to\nrequire creating or destroying entities with moral status? To what extent\nshould designs conform to versus attempt to alter user assumptions and\nattitudes?", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06263v1", "cate": "cs.CY", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06381", "title": "KPFlow: An Operator Perspective on Dynamic Collapse Under Gradient Descent Training of Recurrent Networks", "authors": ["James Hazelden", "Laura Driscoll", "Eli Shlizerman", "Eric Shea-Brown"], "categories": ["cs.LG", "cs.AI", "math.DS", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06381v1", "summary": "Gradient Descent (GD) and its variants are the primary tool for enabling\nefficient training of recurrent dynamical systems such as Recurrent Neural\nNetworks (RNNs), Neural ODEs and Gated Recurrent units (GRUs). The dynamics\nthat are formed in these models exhibit features such as neural collapse and\nemergence of latent representations that may support the remarkable\ngeneralization properties of networks. In neuroscience, qualitative features of\nthese representations are used to compare learning in biological and artificial\nsystems. Despite recent progress, there remains a need for theoretical tools to\nrigorously understand the mechanisms shaping learned representations,\nespecially in finite, non-linear models. Here, we show that the gradient flow,\nwhich describes how the model's dynamics evolve over GD, can be decomposed into\na product that involves two operators: a Parameter Operator, K, and a\nLinearized Flow Propagator, P. K mirrors the Neural Tangent Kernel in\nfeed-forward neural networks, while P appears in Lyapunov stability and optimal\ncontrol theory. We demonstrate two applications of our decomposition. First, we\nshow how their interplay gives rise to low-dimensional latent dynamics under\nGD, and, specifically, how the collapse is a result of the network structure,\nover and above the nature of the underlying task. Second, for multi-task\ntraining, we show that the operators can be used to measure how objectives\nrelevant to individual sub-tasks align. We experimentally and theoretically\nvalidate these findings, providing an efficient Pytorch package, \\emph{KPFlow},\nimplementing robust analysis tools for general recurrent architectures. Taken\ntogether, our work moves towards building a next stage of understanding of GD\nlearning in non-linear recurrent models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06381v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06691", "title": "Effects of task difficulty and music expertise in virtual reality: Observations of cognitive load and task accuracy in a rhythm exergame", "authors": ["Kyla Ellahiyoun", "Emma Jane Pretty", "Renan Guarese", "Marcel Takac", "Haytham Fayek", "Fabio Zambetta"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Submitted to VRST'25", "url": "http://arxiv.org/abs/2507.06691v1", "summary": "This study explores the relationship between musical training, cognitive load\n(CL), and task accuracy within the virtual reality (VR) exergame Beat Saber\nacross increasing levels of difficulty. Participants (N=32) completed a series\nof post-task questionnaires after playing the game under three task difficulty\nlevels while having their physiological data measured by an Emotibit. Using\nregression analyses, we found that task difficulty and gaming experience\nsignificantly predicted subjective CL, whereas musical training did not.\nHowever, musical training significantly predicted higher task accuracy, along\nwith lower subjective CL, increased gaming experience, and greater\nphysiological arousal. These results suggest that musical training enhances\ntask-specific performance but does not directly reduce subjective CL. Future\nresearch should consider alternative methods of grouping musical expertise and\nthe additional predictability of flow and self-efficacy.", "comment": "Submitted to VRST'25", "pdf_url": "http://arxiv.org/pdf/2507.06691v1", "cate": "cs.HC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06587", "title": "Illuminating the Future: Nanophotonics for Future Green Technologies, Precision Healthcare, and Optical Computing", "authors": ["Osama M. Halawa", "Esraa Ahmed", "Malk M. Abdelrazek", "Yasser M. Nagy", "Omar A. M. Abdelraouf"], "categories": ["physics.optics", "cs.ET", "physics.app-ph", "physics.med-ph"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06587v1", "summary": "Nanophotonics, an interdisciplinary field merging nanotechnology and\nphotonics, has enabled transformative advancements across diverse sectors\nincluding green energy, biomedicine, and optical computing. This review\ncomprehensively examines recent progress in nanophotonic principles and\napplications, highlighting key innovations in material design, device\nengineering, and system integration. In renewable energy, nanophotonic allows\nlight-trapping nanostructures and spectral control in perovskite solar cells,\nconcentrating solar power, and thermophotovoltaics. That have significantly\nenhanced solar conversion efficiencies, approaching theoretical limits. For\nbiosensing, nanophotonic platforms achieve unprecedented sensitivity in\ndetecting biomolecules, pathogens, and pollutants, enabling real-time\ndiagnostics and environmental monitoring. Medical applications leverage\ntailored light-matter interactions for precision photothermal therapy,\nimage-guided surgery, and early disease detection. Furthermore, nanophotonics\nunderpins next-generation optical neural networks and neuromorphic computing,\noffering ultra-fast, energy-efficient alternatives to von Neumann\narchitectures. Despite rapid growth, challenges in scalability, fabrication\ncosts, and material stability persist. Future advancements will rely on novel\nmaterials, AI-driven design optimization, and multidisciplinary approaches to\nenable scalable, low-cost deployment. This review summarizes recent progress\nand highlights future trends, including novel material systems,\nmultidisciplinary approaches, and enhanced computational capabilities, to pave\nthe way for transformative applications in this rapidly evolving field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06587v1", "cate": "physics.optics", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06269", "title": "A Probabilistic Approach to Uncertainty Quantification Leveraging 3D Geometry", "authors": ["Rushil Desai", "Frederik Warburg", "Trevor Darrell", "Marissa Ramirez de Chanlatte"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 Workshops (8 Pages, 6 Figures, 2 Tables)", "url": "http://arxiv.org/abs/2507.06269v1", "summary": "Quantifying uncertainty in neural implicit 3D representations, particularly\nthose utilizing Signed Distance Functions (SDFs), remains a substantial\nchallenge due to computational inefficiencies, scalability issues, and\ngeometric inconsistencies. Existing methods typically neglect direct geometric\nintegration, leading to poorly calibrated uncertainty maps. We introduce\nBayesSDF, a novel probabilistic framework for uncertainty quantification in\nneural implicit SDF models, motivated by scientific simulation applications\nwith 3D environments (e.g., forests) such as modeling fluid flow through\nforests, where precise surface geometry and awareness of fidelity surface\ngeometric uncertainty are essential. Unlike radiance-based models such as NeRF\nor 3D Gaussian splatting, which lack explicit surface formulations, SDFs define\ncontinuous and differentiable geometry, making them better suited for physical\nmodeling and analysis. BayesSDF leverages a Laplace approximation to quantify\nlocal surface instability via Hessian-based metrics, enabling computationally\nefficient, surface-aware uncertainty estimation. Our method shows that\nuncertainty predictions correspond closely with poorly reconstructed geometry,\nproviding actionable confidence measures for downstream use. Extensive\nevaluations on synthetic and real-world datasets demonstrate that BayesSDF\noutperforms existing methods in both calibration and geometric consistency,\nestablishing a strong foundation for uncertainty-aware 3D scene reconstruction,\nsimulation, and robotic decision-making.", "comment": "ICCV 2025 Workshops (8 Pages, 6 Figures, 2 Tables)", "pdf_url": "http://arxiv.org/pdf/2507.06269v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06808", "title": "A Note on the Walsh Spectrum of Power Residue S-Boxes", "authors": ["Matthias Johann Steiner"], "categories": ["math.NT", "cs.CR"], "primary_category": "Subjects:       Number Theory (math.NT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06808v1", "summary": "Let $\\mathbb{F}_q$ be a prime field with $q \\geq 3$, and let $d, m \\geq 1$ be\nintegers such that $\\gcd \\left( d, q \\right) = 1$ and $m \\mid (q - 1)$. In this\npaper we bound the absolute values of the Walsh spectrum of S-Boxes $S (x) =\nx^d \\cdot T \\left( x^\\frac{q - 1}{m} \\right)$, where $T$ is a function with $T\n(x) \\neq 0$ if $x \\neq 0$. Such S-Boxes have been proposed for the\nZero-Knowledge-friendly hash functions Grendel and Polocolo. In particular, we\nprove the conjectured correlation of the Polocolo S-Box.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06808v1", "cate": "math.NT", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06787", "title": "Stream Function-Based Navigation for Complex Quadcopter Obstacle Avoidance", "authors": ["Sean Smith", "Emmanuel Witrant", "Ya-Jun Pan"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06787v1", "summary": "This article presents a novel stream function-based navigational control\nsystem for obstacle avoidance, where obstacles are represented as\ntwo-dimensional (2D) rigid surfaces in inviscid, incompressible flows. The\napproach leverages the vortex panel method (VPM) and incorporates safety\nmargins to control the stream function and flow properties around virtual\nsurfaces, enabling navigation in complex, partially observed environments using\nreal-time sensing. To address the limitations of the VPM in managing relative\ndistance and avoiding rapidly accelerating obstacles at close proximity, the\nsystem integrates a model predictive controller (MPC) based on higher-order\ncontrol barrier functions (HOCBF). This integration incorporates VPM trajectory\ngeneration, state estimation, and constraint handling into a receding-horizon\noptimization problem. The 2D rigid surfaces are enclosed using minimum bounding\nellipses (MBEs), while an adaptive Kalman filter (AKF) captures and predicts\nobstacle dynamics, propagating these estimates into the MPC-HOCBF for rapid\navoidance maneuvers. Evaluation is conducted using a PX4-powered Clover drone\nGazebo simulator and real-time experiments involving a COEX Clover quadcopter\nequipped with a 360 degree LiDAR sensor.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06787v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06264", "title": "X-ray transferable polyrepresentation learning", "authors": ["Weronika Hryniewska-Guzik", "Przemyslaw Biecek"], "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      part of Weronika's PhD thesis", "url": "http://arxiv.org/abs/2507.06264v1", "summary": "The success of machine learning algorithms is inherently related to the\nextraction of meaningful features, as they play a pivotal role in the\nperformance of these algorithms. Central to this challenge is the quality of\ndata representation. However, the ability to generalize and extract these\nfeatures effectively from unseen datasets is also crucial. In light of this, we\nintroduce a novel concept: the polyrepresentation. Polyrepresentation\nintegrates multiple representations of the same modality extracted from\ndistinct sources, for example, vector embeddings from the Siamese Network,\nself-supervised models, and interpretable radiomic features. This approach\nyields better performance metrics compared to relying on a single\nrepresentation. Additionally, in the context of X-ray images, we demonstrate\nthe transferability of the created polyrepresentation to a smaller dataset,\nunderscoring its potential as a pragmatic and resource-efficient approach in\nvarious image-related solutions. It is worth noting that the concept of\npolyprepresentation on the example of medical data can also be applied to other\ndomains, showcasing its versatility and broad potential impact.", "comment": "part of Weronika's PhD thesis", "pdf_url": "http://arxiv.org/pdf/2507.06264v1", "cate": "eess.IV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06432", "title": "Bridging Data Gaps of Rare Conditions in ICU: A Multi-Disease Adaptation Approach for Clinical Prediction", "authors": ["Mingcheng Zhu", "Yu Liu", "Zhiyao Luo", "Tingting Zhu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06432v1", "summary": "Artificial Intelligence has revolutionised critical care for common\nconditions. Yet, rare conditions in the intensive care unit (ICU), including\nrecognised rare diseases and low-prevalence conditions in the ICU, remain\nunderserved due to data scarcity and intra-condition heterogeneity. To bridge\nsuch gaps, we developed KnowRare, a domain adaptation-based deep learning\nframework for predicting clinical outcomes for rare conditions in the ICU.\nKnowRare mitigates data scarcity by initially learning condition-agnostic\nrepresentations from diverse electronic health records through self-supervised\npre-training. It addresses intra-condition heterogeneity by selectively\nadapting knowledge from clinically similar conditions with a developed\ncondition knowledge graph. Evaluated on two ICU datasets across five clinical\nprediction tasks (90-day mortality, 30-day readmission, ICU mortality,\nremaining length of stay, and phenotyping), KnowRare consistently outperformed\nexisting state-of-the-art models. Additionally, KnowRare demonstrated superior\npredictive performance compared to established ICU scoring systems, including\nAPACHE IV and IV-a. Case studies further demonstrated KnowRare's flexibility in\nadapting its parameters to accommodate dataset-specific and task-specific\ncharacteristics, its generalisation to common conditions under limited data\nscenarios, and its rationality in selecting source conditions. These findings\nhighlight KnowRare's potential as a robust and practical solution for\nsupporting clinical decision-making and improving care for rare conditions in\nthe ICU.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06432v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06734", "title": "Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool", "authors": ["Milena Pustet", "Elisabeth Steffen", "Helena Mihaljević", "Grischa Stanjek", "Yannis Illies"], "categories": ["cs.HC", "cs.AI", "cs.CL", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06734v1", "summary": "The role of civil society organizations (CSOs) in monitoring harmful online\ncontent is increasingly crucial, especially as platform providers reduce their\ninvestment in content moderation. AI tools can assist in detecting and\nmonitoring harmful content at scale. However, few open-source tools offer\nseamless integration of AI models and social media monitoring infrastructures.\nGiven their thematic expertise and contextual understanding of harmful content,\nCSOs should be active partners in co-developing technological tools, providing\nfeedback, helping to improve models, and ensuring alignment with stakeholder\nneeds and values, rather than as passive 'consumers'. However, collaborations\nbetween the open source community, academia, and civil society remain rare, and\nresearch on harmful content seldom translates into practical tools usable by\ncivil society actors. This work in progress explores how CSOs can be\nmeaningfully involved in an AI-assisted open-source monitoring tool of\nanti-democratic movements on Telegram, which we are currently developing in\ncollaboration with CSO stakeholders.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06734v1", "cate": "cs.HC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06943", "title": "No physics required! A visual-based introduction to GKP qubits for computer scientists", "authors": ["Richard A. Wolf", "Pavithran Iyer"], "categories": ["quant-ph", "cs.ET", "physics.ed-ph"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      Preprint. Full paper available through IEEE's Quantum Science and Engineering Education Conference 2025", "url": "http://arxiv.org/abs/2507.06943v1", "summary": "With the significance of continuous-variable quantum computing increasing\nthanks to the achievements of light-based quantum hardware, making it available\nto learner audiences outside physics has been an important yet seldom-tackled\nchallenge. Similarly, the rising focus on fault-tolerant quantum computing has\nshed light on quantum error correction schemes, turning it into the locus of\nattention for industry and academia alike. In this paper, we explore the widely\nadopted framework of quantum error correction based on continuous variable\nsystems and suggest a guide on building a self-contained learning session\ntargeting the famous Gottesman-Kitaev-Preskill (GKP) code through its geometric\nintuition.", "comment": "Preprint. Full paper available through IEEE's Quantum Science and\n  Engineering Education Conference 2025", "pdf_url": "http://arxiv.org/pdf/2507.06943v1", "cate": "quant-ph", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06272", "title": "LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance", "authors": ["Zhang Li", "Biao Yang", "Qiang Liu", "Shuo Zhang", "Zhiyin Ma", "Shuo Zhang", "Liang Yin", "Linger Deng", "Yabo Sun", "Yuliang Liu", "Xiang Bai"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06272v1", "summary": "While large multi-modal models (LMMs) demonstrate promising capabilities in\nsegmentation and comprehension, they still struggle with two limitations:\ninaccurate segmentation and hallucinated comprehension. These challenges stem\nprimarily from constraints in weak visual comprehension and a lack of\nfine-grained perception. To alleviate these limitations, we propose LIRA, a\nframework that capitalizes on the complementary relationship between visual\ncomprehension and segmentation via two key components: (1) Semantic-Enhanced\nFeature Extractor (SEFE) improves object attribute inference by fusing semantic\nand pixel-level features, leading to more accurate segmentation; (2)\nInterleaved Local Visual Coupling (ILVC) autoregressively generates local\ndescriptions after extracting local features based on segmentation masks,\noffering fine-grained supervision to mitigate hallucinations. Furthermore, we\nfind that the precision of object segmentation is positively correlated with\nthe latent related semantics of the <seg> token. To quantify this relationship\nand the model's potential semantic inferring ability, we introduce the\nAttributes Evaluation (AttrEval) dataset. Our experiments show that LIRA\nachieves state-of-the-art performance in both segmentation and comprehension\ntasks. Code will be available at https://github.com/echo840/LIRA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06272v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06343", "title": "Quality attributes of test cases and test suites -- importance & challenges from practitioners' perspectives", "authors": ["Huynh Khanh Vi Tran", "Nauman bin Ali", "Michael Unterkalmsteiner", "Jürgen Börstler", "Panagiota Chatzipetrou"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06343v1", "summary": "Context: The quality of the test suites and the constituent test cases\nsignificantly impacts confidence in software testing. While research has\nidentified several quality attributes of test cases and test suites, there is a\nneed for a better understanding of their relative importance in practice.\nObjective: We investigate practitioners' perceptions regarding the relative\nimportance of quality attributes of test cases and test suites and the\nchallenges they face in ensuring the perceived important quality attributes.\nMethod: We conducted an industrial survey using a questionnaire based on the\nquality attributes identified in an extensive literature review. We used a\nsampling strategy that leverages LinkedIn to draw a large and heterogeneous\nsample of professionals with experience in software testing. Results: We\ncollected 354 responses from practitioners with a wide range of experience. We\nfound that the majority of practitioners rated Fault Detection, Usability,\nMaintainability, Reliability, and Coverage to be the most important quality\nattributes. Resource Efficiency, Reusability, and Simplicity received the most\ndivergent opinions, which, according to our analysis, depend on the\nsoftware-testing contexts. We identified common challenges that apply to the\nimportant attributes, namely inadequate definition, lack of useful metrics,\nlack of an established review process, and lack of external support.\nConclusion: The findings point out where practitioners actually need further\nsupport with respect to achieving high-quality test cases and test suites under\ndifferent software testing contexts. The findings can serve as a guideline for\nacademic researchers when looking for research directions on the topic. The\nfindings can also be used to encourage companies to provide more support to\npractitioners to achieve high-quality test cases and test suites.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06343v1", "cate": "cs.SE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06969", "title": "Unifying Re-Identification, Attribute Inference, and Data Reconstruction Risks in Differential Privacy", "authors": ["Bogdan Kulynych", "Juan Felipe Gomez", "Georgios Kaissis", "Jamie Hayes", "Borja Balle", "Flavio du Pin Calmon", "Jean Louis Raisaro"], "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CY", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06969v1", "summary": "Differentially private (DP) mechanisms are difficult to interpret and\ncalibrate because existing methods for mapping standard privacy parameters to\nconcrete privacy risks -- re-identification, attribute inference, and data\nreconstruction -- are both overly pessimistic and inconsistent. In this work,\nwe use the hypothesis-testing interpretation of DP ($f$-DP), and determine that\nbounds on attack success can take the same unified form across\nre-identification, attribute inference, and data reconstruction risks. Our\nunified bounds are (1) consistent across a multitude of attack settings, and\n(2) tunable, enabling practitioners to evaluate risk with respect to arbitrary\n(including worst-case) levels of baseline risk. Empirically, our results are\ntighter than prior methods using $\\varepsilon$-DP, R\\'enyi DP, and concentrated\nDP. As a result, calibrating noise using our bounds can reduce the required\nnoise by 20% at the same risk level, which yields, e.g., more than 15pp\naccuracy increase in a text classification task. Overall, this unifying\nperspective provides a principled framework for interpreting and calibrating\nthe degree of protection in DP against specific levels of re-identification,\nattribute inference, or data reconstruction risk.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06969v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06822", "title": "Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand", "authors": ["Wei Xu", "Yanchao Zhao", "Weichao Guo", "Xinjun Sheng"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted by 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025). copyright 2025 IEEE. Final version to appear in IEEE Xplore", "url": "http://arxiv.org/abs/2507.06822v1", "summary": "Manipulating articulated tools, such as tweezers or scissors, has rarely been\nexplored in previous research. Unlike rigid tools, articulated tools change\ntheir shape dynamically, creating unique challenges for dexterous robotic\nhands. In this work, we present a hierarchical, goal-conditioned reinforcement\nlearning (GCRL) framework to improve the manipulation capabilities of\nanthropomorphic robotic hands using articulated tools. Our framework comprises\ntwo policy layers: (1) a low-level policy that enables the dexterous hand to\nmanipulate the tool into various configurations for objects of different sizes,\nand (2) a high-level policy that defines the tool's goal state and controls the\nrobotic arm for object-picking tasks. We employ an encoder, trained on\nsynthetic pointclouds, to estimate the tool's affordance states--specifically,\nhow different tool configurations (e.g., tweezer opening angles) enable\ngrasping of objects of varying sizes--from input point clouds, thereby enabling\nprecise tool manipulation. We also utilize a privilege-informed heuristic\npolicy to generate replay buffer, improving the training efficiency of the\nhigh-level policy. We validate our approach through real-world experiments,\nshowing that the robot can effectively manipulate a tweezer-like tool to grasp\nobjects of diverse shapes and sizes with a 70.8 % success rate. This study\nhighlights the potential of RL to advance dexterous robotic manipulation of\narticulated tools.", "comment": "Accepted by 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025). copyright 2025 IEEE. Final version to appear\n  in IEEE Xplore", "pdf_url": "http://arxiv.org/pdf/2507.06822v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06266", "title": "Machine Learning based Enterprise Financial Audit Framework and High Risk Identification", "authors": ["Tingyu Yuan", "Xi Zhang", "Xuanjing Chen"], "categories": ["q-fin.RM", "cs.AI", "cs.LG", "stat.AP"], "primary_category": "Subjects:       Risk Management (q-fin.RM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06266v1", "summary": "In the face of global economic uncertainty, financial auditing has become\nessential for regulatory compliance and risk mitigation. Traditional manual\nauditing methods are increasingly limited by large data volumes, complex\nbusiness structures, and evolving fraud tactics. This study proposes an\nAI-driven framework for enterprise financial audits and high-risk\nidentification, leveraging machine learning to improve efficiency and accuracy.\nUsing a dataset from the Big Four accounting firms (EY, PwC, Deloitte, KPMG)\nfrom 2020 to 2025, the research examines trends in risk assessment, compliance\nviolations, and fraud detection. The dataset includes key indicators such as\naudit project counts, high-risk cases, fraud instances, compliance breaches,\nemployee workload, and client satisfaction, capturing both audit behaviors and\nAI's impact on operations. To build a robust risk prediction model, three\nalgorithms - Support Vector Machine (SVM), Random Forest (RF), and K-Nearest\nNeighbors (KNN) - are evaluated. SVM uses hyperplane optimization for complex\nclassification, RF combines decision trees to manage high-dimensional,\nnonlinear data with resistance to overfitting, and KNN applies distance-based\nlearning for flexible performance. Through hierarchical K-fold cross-validation\nand evaluation using F1-score, accuracy, and recall, Random Forest achieves the\nbest performance, with an F1-score of 0.9012, excelling in identifying fraud\nand compliance anomalies. Feature importance analysis reveals audit frequency,\npast violations, employee workload, and client ratings as key predictors. The\nstudy recommends adopting Random Forest as a core model, enhancing features via\nengineering, and implementing real-time risk monitoring. This research\ncontributes valuable insights into using machine learning for intelligent\nauditing and risk management in modern enterprises.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06266v1", "cate": "q-fin.RM", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06433", "title": "eegFloss: A Python package for refining sleep EEG recordings using machine learning models", "authors": ["Niloy Sikder", "Paul Zerr", "Mahdad Jafarzadeh Esfahani", "Martin Dresler", "Matthias Krauledat"], "categories": ["cs.LG", "eess.SP", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The eegFloss package is available under the MIT License at this https URL", "url": "http://arxiv.org/abs/2507.06433v1", "summary": "Electroencephalography (EEG) allows monitoring of brain activity, providing\ninsights into the functional dynamics of various brain regions and their roles\nin cognitive processes. EEG is a cornerstone in sleep research, serving as the\nprimary modality of polysomnography, the gold standard in the field. However,\nEEG signals are prone to artifacts caused by both internal (device-specific)\nfactors and external (environmental) interferences. As sleep studies are\nbecoming larger, most rely on automatic sleep staging, a process highly\nsusceptible to artifacts, leading to erroneous sleep scores. This paper\naddresses this challenge by introducing eegFloss, an open-source Python package\nto utilize eegUsability, a novel machine learning (ML) model designed to detect\nsegments with artifacts in sleep EEG recordings. eegUsability has been trained\nand evaluated on manually artifact-labeled EEG data collected from 15\nparticipants over 127 nights using the Zmax headband. It demonstrates solid\noverall classification performance (F1-score is approximately 0.85, Cohens\nkappa is 0.78), achieving a high recall rate of approximately 94% in\nidentifying channel-wise usable EEG data, and extends beyond Zmax.\nAdditionally, eegFloss offers features such as automatic time-in-bed detection\nusing another ML model named eegMobility, filtering out certain artifacts, and\ngenerating hypnograms and sleep statistics. By addressing a fundamental\nchallenge faced by most sleep studies, eegFloss can enhance the precision and\nrigor of their analysis as well as the accuracy and reliability of their\noutcomes.", "comment": "The eegFloss package is available under the MIT License at\n  https://github.com/Niloy333/eegFloss", "pdf_url": "http://arxiv.org/pdf/2507.06433v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06751", "title": "Combining Human-centred Explainability and Explainable AI", "authors": ["Janin Koch", "Vitor Fortes Rey"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06751v1", "summary": "This position paper looks at differences between the current understandings\nof human-centered explainability and explainability AI. We discuss current\nideas in both fields, as well as the differences and opportunities we\ndiscovered. As an example of combining both, we will present preliminary work\non a new algebraic machine learning approach. We are excited to continue\ndiscussing design opportunities for human-centered explainability (HCx) and xAI\nwith the broader HCxAI community.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06751v1", "cate": "cs.HC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06997", "title": "Federated Learning-based MARL for Strengthening Physical-Layer Security in B5G Networks", "authors": ["Deemah H. Tashman", "Soumaya Cherkaoui", "Walaa Hamouda"], "categories": ["eess.SP", "cs.ET", "cs.LG", "cs.NI"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06997v1", "summary": "This paper explores the application of a federated learning-based multi-agent\nreinforcement learning (MARL) strategy to enhance physical-layer security (PLS)\nin a multi-cellular network within the context of beyond 5G networks. At each\ncell, a base station (BS) operates as a deep reinforcement learning (DRL) agent\nthat interacts with the surrounding environment to maximize the secrecy rate of\nlegitimate users in the presence of an eavesdropper. This eavesdropper attempts\nto intercept the confidential information shared between the BS and its\nauthorized users. The DRL agents are deemed to be federated since they only\nshare their network parameters with a central server and not the private data\nof their legitimate users. Two DRL approaches, deep Q-network (DQN) and\nReinforce deep policy gradient (RDPG), are explored and compared. The results\ndemonstrate that RDPG converges more rapidly than DQN. In addition, we\ndemonstrate that the proposed method outperforms the distributed DRL approach.\nFurthermore, the outcomes illustrate the trade-off between security and\ncomplexity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06997v1", "cate": "eess.SP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06275", "title": "Advancing Offline Handwritten Text Recognition: A Systematic Review of Data Augmentation and Generation Techniques", "authors": ["Yassin Hussein Rassul", "Aram M. Ahmed", "Polla Fattah", "Bryar A. Hassan", "Arwaa W. Abdulkareem", "Tarik A. Rashid", "Joan Lu"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06275v1", "summary": "Offline Handwritten Text Recognition (HTR) systems play a crucial role in\napplications such as historical document digitization, automatic form\nprocessing, and biometric authentication. However, their performance is often\nhindered by the limited availability of annotated training data, particularly\nfor low-resource languages and complex scripts. This paper presents a\ncomprehensive survey of offline handwritten data augmentation and generation\ntechniques designed to improve the accuracy and robustness of HTR systems. We\nsystematically examine traditional augmentation methods alongside recent\nadvances in deep learning, including Generative Adversarial Networks (GANs),\ndiffusion models, and transformer-based approaches. Furthermore, we explore the\nchallenges associated with generating diverse and realistic handwriting\nsamples, particularly in preserving script authenticity and addressing data\nscarcity. This survey follows the PRISMA methodology, ensuring a structured and\nrigorous selection process. Our analysis began with 1,302 primary studies,\nwhich were filtered down to 848 after removing duplicates, drawing from key\nacademic sources such as IEEE Digital Library, Springer Link, Science Direct,\nand ACM Digital Library. By evaluating existing datasets, assessment metrics,\nand state-of-the-art methodologies, this survey identifies key research gaps\nand proposes future directions to advance the field of handwritten text\ngeneration across diverse linguistic and stylistic landscapes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06275v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06354", "title": "A proposal and assessment of an improved heuristic for the Eager Test smell detection", "authors": ["Huynh Khanh Vi Tran", "Nauman bin Ali", "Michael Unterkalmsteiner", "Jürgen Börstler"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06354v1", "summary": "Context: The evidence for the prevalence of test smells at the unit testing\nlevel has relied on the accuracy of detection tools, which have seen intense\nresearch in the last two decades. The Eager Test smell, one of the most\nprevalent, is often identified using simplified detection rules that\npractitioners find inadequate. Objective: We aim to improve the rules for\ndetecting the Eager Test smell. Method: We reviewed the literature on test\nsmells to analyze the definitions and detection rules of the Eager Test smell.\nWe proposed a novel, unambiguous definition of the test smell and a heuristic\nto address the limitations of the existing rules. We evaluated our heuristic\nagainst existing detection rules by manually applying it to 300 unit test cases\nin Java. Results: Our review identified 56 relevant studies. We found that\ninadequate interpretations of original definitions of the Eager Test smell led\nto imprecise detection rules, resulting in a high level of disagreement in\ndetection outcomes. Also, our heuristic detected patterns of eager and\nnon-eager tests that existing rules missed. Conclusion: Our heuristic captures\nthe essence of the Eager Test smell more precisely; hence, it may address\npractitioners' concerns regarding the adequacy of existing detection rules.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06354v1", "cate": "cs.SE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.07055", "title": "Integer Factorization: Another perspective", "authors": ["Gilda Rech Bansimba", "Regis Freguin Babindamana"], "categories": ["math.NT", "cs.CR"], "primary_category": "Subjects:       Number Theory (math.NT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07055v1", "summary": "Integer factorization is a fundamental problem in algorithmic number theory\nand computer science. It is considered as a one way or trapdoor function in the\n(RSA) cryptosystem. To date, from elementary trial division to sophisticated\nmethods like the General Number Field Sieve, no known algorithm can break the\nproblem in polynomial time, while its proved that Shor's algorithm could on a\nquantum computer. In this paper, we recall some factorization algorithms and\nthen approach the problem under different angles. Firstly, we take the problem\nfrom the ring $\\displaystyle\\left(\\mathbb{Z}, \\text{+}, \\cdot\\right)$ to the\nLebesgue space $\\mathcal{L}^{1}\\left(X\\right)$ where $X$ can be $\\mathbb{Q}$ or\nany given interval setting. From this first perspective, integer factorization\nbecomes equivalent to finding the perimeter of a rectangle whose area is known.\nIn this case, it is equivalent to either finding bounds of integrals or finding\nprimitives for some given bounds. Secondly, we take the problem from the ring\n$\\displaystyle\\left(\\mathbb{Z}, \\text{+}, \\cdot\\right) $ to the ring of\nmatrices $\\left( M_{2}\\text{(}\\mathbb{Z}\\text{)}, \\ \\text{+} \\ \\cdot\\right)$\nand show that this problem is equivalent to matrix decomposition, and therefore\npresent some possible computing algorithms, particularly using Gr\\\"obner basis\nand through matrix diagonalization. Finally, we address the problem depending\non algebraic forms of factors and show that this problem is equivalent to\nfinding small roots of a bivariate polynomial through coppersmith's method.\n  The aim of this study is to propose innovative methodological approaches to\nreformulate this problem, thereby offering new perspectives.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07055v1", "cate": "math.NT", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06824", "title": "Friction Estimation for In-Hand Planar Motion", "authors": ["Gabriel Arslan Waltersson", "Yiannis Karayiannidis"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06824v1", "summary": "This paper presents a method for online estimation of contact properties\nduring in-hand sliding manipulation with a parallel gripper. We estimate the\nstatic and Coulomb friction as well as the contact radius from tactile\nmeasurements of contact forces and sliding velocities. The method is validated\nin both simulation and real-world experiments. Furthermore, we propose a\nheuristic to deal with fast slip-stick dynamics which can adversely affect the\nestimation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06824v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06268", "title": "A Collectivist, Economic Perspective on AI", "authors": ["Michael I. Jordan"], "categories": ["cs.CY", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06268v1", "summary": "Information technology is in the midst of a revolution in which omnipresent\ndata collection and machine learning are impacting the human world as never\nbefore. The word \"intelligence\" is being used as a North Star for the\ndevelopment of this technology, with human cognition viewed as a baseline. This\nview neglects the fact that humans are social animals, and that much of our\nintelligence is social and cultural in origin. A related issue is that the\ncurrent view treats the social consequences of technology as an afterthought.\nThe path forward is not merely more data and compute, and not merely more\nattention paid to cognitive or symbolic representations, but a thorough\nblending of economic and social concepts with computational and inferential\nconcepts, in the service of system-level designs in which social welfare is a\nfirst-class citizen, and with the aspiration that a new human-centric\nengineering field will emerge.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06268v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06445", "title": "Can Interpretation Predict Behavior on Unseen Data?", "authors": ["Victoria R. Li", "Jenny Kaufmann", "Martin Wattenberg", "David Alvarez-Melis", "Naomi Saphra"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06445v1", "summary": "Interpretability research often aims to predict how a model will respond to\ntargeted interventions on specific mechanisms. However, it rarely predicts how\na model will respond to unseen input data. This paper explores the promises and\nchallenges of interpretability as a tool for predicting out-of-distribution\n(OOD) model behavior. Specifically, we investigate the correspondence between\nattention patterns and OOD generalization in hundreds of Transformer models\nindependently trained on a synthetic classification task. These models exhibit\nseveral distinct systematic generalization rules OOD, forming a diverse\npopulation for correlational analysis. In this setting, we find that simple\nobservational tools from interpretability can predict OOD performance. In\nparticular, when in-distribution attention exhibits hierarchical patterns, the\nmodel is likely to generalize hierarchically on OOD data -- even when the\nrule's implementation does not rely on these hierarchical patterns, according\nto ablation tests. Our findings offer a proof-of-concept to motivate further\ninterpretability work on predicting unseen model behavior.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06445v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06779", "title": "Tailoring deep learning for real-time brain-computer interfaces: From offline models to calibration-free online decoding", "authors": ["Martin Wimpff", "Jan Zerfowski", "Bin Yang"], "categories": ["cs.HC", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06779v1", "summary": "Despite the growing success of deep learning (DL) in offline brain-computer\ninterfaces (BCIs), its adoption in real-time applications remains limited due\nto three primary challenges. First, most DL solutions are designed for offline\ndecoding, making the transition to online decoding unclear. Second, the use of\nsliding windows in online decoding substantially increases computational\ncomplexity. Third, DL models typically require large amounts of training data,\nwhich are often scarce in BCI applications. To address these challenges and\nenable real-time, cross-subject decoding without subject-specific calibration,\nwe introduce realtime adaptive pooling (RAP), a novel parameter-free method.\nRAP seamlessly modifies the pooling layers of existing offline DL models to\nmeet online decoding requirements. It also reduces computational complexity\nduring training by jointly decoding consecutive sliding windows. To further\nalleviate data requirements, our method leverages source-free domain\nadaptation, enabling privacy-preserving adaptation across varying amounts of\ntarget data. Our results demonstrate that RAP provides a robust and efficient\nframework for real-time BCI applications. It preserves privacy, reduces\ncalibration demands, and supports co-adaptive BCI systems, paving the way for\nbroader adoption of DL in online BCIs. These findings lay a strong foundation\nfor developing user-centered, high-performance BCIs that facilitate immediate\nfeedback and user learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06779v1", "cate": "cs.HC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2404.14384", "title": "Optimizing Multiple-Control Toffoli Quantum Circuit Design with Constraint Programming", "authors": ["Jihye Jung", "Kevin Dalmeijer", "Pascal Van Hentenryck"], "categories": ["math.OC", "cs.ET", "quant-ph"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.14384v3", "summary": "As quantum technology advances, the efficient design of quantum circuits has\nbecome an important area of research. This paper provides an introduction to\nthe MCT quantum circuit design problem for reversible Boolean functions with\nthe necessary background in quantum computing to comprehend the problem. While\nthis is a well-studied problem, optimization models that minimize the true\nobjective have only been explored recently. This paper introduces a new\noptimization model and symmetry-breaking constraints that improve solving time\nby up to two orders of magnitude compared to earlier work when a Constraint\nProgramming solver is used. Experiments with up to seven qubits and using up to\n15 quantum gates result in several new best-known circuits, obtained by any\nmethod, for well-known benchmarks. Several in-depth analyses are presented to\nvalidate the effectiveness of the symmetry-breaking constraints from multiple\nperspectives. Finally, an extensive comparison with other approaches shows that\noptimization models may require more time but can provide superior circuits\nwith optimality guarantees.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.14384v3", "cate": "math.OC", "date": "2024-04-22", "updated": "2025-07-09"}
{"id": "2507.06321", "title": "Centralized Copy-Paste: Enhanced Data Augmentation Strategy for Wildland Fire Semantic Segmentation", "authors": ["Joon Tai Kim", "Tianle Chen", "Ziyu Dong", "Nishanth Kunchala", "Alexander Guller", "Daniel Ospina Acero", "Roger Williams", "Mrinal Kumar"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      21 pages, 5 figures, and under review for AIAA SciTech 2026", "url": "http://arxiv.org/abs/2507.06321v1", "summary": "Collecting and annotating images for the purpose of training segmentation\nmodels is often cost prohibitive. In the domain of wildland fire science, this\nchallenge is further compounded by the scarcity of reliable public datasets\nwith labeled ground truth. This paper presents the Centralized Copy-Paste Data\nAugmentation (CCPDA) method, for the purpose of assisting with the training of\ndeep-learning multiclass segmentation models, with special focus on improving\nsegmentation outcomes for the fire-class. CCPDA has three main steps: (i)\nidentify fire clusters in the source image, (ii) apply a centralization\ntechnique to focus on the core of the fire area, and (iii) paste the refined\nfire clusters onto a target image. This method increases dataset diversity\nwhile preserving the essential characteristics of the fire class. The\neffectiveness of this augmentation technique is demonstrated via numerical\nanalysis and comparison against various other augmentation methods using a\nweighted sum-based multi-objective optimization approach. This approach helps\nelevate segmentation performance metrics specific to the fire class, which\ncarries significantly more operational significance than other classes (fuel,\nash, or background). Numerical performance assessment validates the efficacy of\nthe presented CCPDA method in alleviating the difficulties associated with\nsmall, manually labeled training datasets. It also illustrates that CCPDA\noutperforms other augmentation strategies in the application scenario\nconsidered, particularly in improving fire-class segmentation performance.", "comment": "21 pages, 5 figures, and under review for AIAA SciTech 2026", "pdf_url": "http://arxiv.org/pdf/2507.06321v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06463", "title": "Evaluating Efficiency and Novelty of LLM-Generated Code for Graph Analysis", "authors": ["Atieh Barati Nia", "Mohammad Dindoost", "David A. Bader"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06463v1", "summary": "Large Language Models (LLMs) are increasingly used to automate software\ndevelopment, yet most prior evaluations focus on functional correctness or\nhigh-level languages such as Python. We present the first systematic study of\nLLMs' ability to generate efficient C implementations of graph-analysis\nroutines--code that must satisfy the stringent runtime and memory constraints.\nEight state-of-the-art models (OpenAI ChatGPT o3 and o4-mini-high, Anthropic\nClaude 4 Sonnet and Sonnet Extended, Google Gemini 2.5 Flash and Pro, xAI Grok\n3-Think, and DeepSeek DeepThink R1) are benchmarked by two distinct approaches.\nThe first approach checks the ability of LLMs in generating an algorithm\noutperforming other present algorithms in the benchmark. The second approach\nevaluates the ability of LLMs to generate graph algorithms for integration into\nthe benchmark. Results show that Claude Sonnet 4 Extended achieves the best\nresult in the case of ready-to-use code generation and efficiency,\noutperforming human-written baselines in triangle counting. The study confirms\nthat contemporary LLMs excel at optimizing and integrating established\nalgorithms but not inventing novel techniques. We provide prompts, the first\napproach's generated code, and measurement scripts to foster reproducible\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06463v1", "cate": "cs.SE", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06465", "title": "Temporal Motif Participation Profiles for Analyzing Node Similarity in Temporal Networks", "authors": ["Maxwell C. Lee", "Kevin S. Xu"], "categories": ["cs.SI", "physics.soc-ph"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06465v1", "summary": "Temporal networks consisting of timestamped interactions between a set of\nnodes provide a useful representation for analyzing complex networked systems\nthat evolve over time. Beyond pairwise interactions between nodes, temporal\nmotifs capture patterns of higher-order interactions such as directed triangles\nover short time periods. We propose temporal motif participation profiles\n(TMPPs) to capture the behavior of nodes in temporal motifs. Two nodes with\nsimilar TMPPs take similar positions within temporal motifs, possibly with\ndifferent nodes. TMPPs serve as unsupervised embeddings for nodes in temporal\nnetworks that are directly interpretable, as each entry denotes the frequency\nat which a node participates in a particular position in a specific temporal\nmotif. We demonstrate that clustering TMPPs reveals groups of nodes with\nsimilar roles in a temporal network through simulation experiments and a case\nstudy on a network of militarized interstate disputes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06465v1", "cate": "cs.SI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2409.17946", "title": "Breaking PEFT Limitations: Leveraging Weak-to-Strong Knowledge Transfer for Backdoor Attacks in LLMs", "authors": ["Shuai Zhao", "Leilei Gan", "Zhongliang Guo", "Xiaobao Wu", "Yanhao Jia", "Luwei Xiao", "Cong-Duy Nguyen", "Luu Anh Tuan"], "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.17946v4", "summary": "Despite being widely applied due to their exceptional capabilities, Large\nLanguage Models (LLMs) have been proven to be vulnerable to backdoor attacks.\nThese attacks introduce targeted vulnerabilities into LLMs by poisoning\ntraining samples and full-parameter fine-tuning (FPFT). However, this kind of\nbackdoor attack is limited since they require significant computational\nresources, especially as the size of LLMs increases. Besides,\nparameter-efficient fine-tuning (PEFT) offers an alternative but the restricted\nparameter updating may impede the alignment of triggers with target labels. In\nthis study, we first verify that backdoor attacks with PEFT may encounter\nchallenges in achieving feasible performance. To address these issues and\nimprove the effectiveness of backdoor attacks with PEFT, we propose a novel\nbackdoor attack algorithm from the weak-to-strong based on Feature\nAlignment-enhanced Knowledge Distillation (FAKD). Specifically, we poison\nsmall-scale language models through FPFT to serve as the teacher model. The\nteacher model then covertly transfers the backdoor to the large-scale student\nmodel through FAKD, which employs PEFT. Theoretical analysis reveals that FAKD\nhas the potential to augment the effectiveness of backdoor attacks. We\ndemonstrate the superior performance of FAKD on classification tasks across\nfour language models, four backdoor attack algorithms, and two different\narchitectures of teacher models. Experimental results indicate success rates\nclose to 100% for backdoor attacks targeting PEFT.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.17946v4", "cate": "cs.CR", "date": "2024-09-26", "updated": "2025-07-09"}
{"id": "2507.06884", "title": "Toward a Full-Stack Co-Simulation Platform for Testing of Automated Driving Systems", "authors": ["Dong Bi", "Yongqi Zhao", "Zhengguo Gu", "Tomislav Mihalj", "Jia Hu", "Arno Eichberger"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      IEEE International Conference on Intelligent Transportation Systems (ITSC) 2025", "url": "http://arxiv.org/abs/2507.06884v1", "summary": "Virtual testing has emerged as an effective approach to accelerate the\ndeployment of automated driving systems. Nevertheless, existing simulation\ntoolchains encounter difficulties in integrating rapid, automated scenario\ngeneration with simulation environments supporting advanced automated driving\ncapabilities. To address this limitation, a full-stack toolchain is presented,\nenabling automatic scenario generation from real-world datasets and efficient\nvalidation through a co-simulation platform based on CarMaker, ROS, and Apollo.\nThe simulation results demonstrate the effectiveness of the proposed toolchain.\nA demonstration video showcasing the toolchain is available at the provided\nlink: https://youtu.be/taJw_-CmSiY.", "comment": "IEEE International Conference on Intelligent Transportation Systems\n  (ITSC) 2025", "pdf_url": "http://arxiv.org/pdf/2507.06884v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06273", "title": "Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain", "authors": ["S P Shivakumar", "Gunisetty Ramasekhar", "P Nimmy", "Sujesh Areekara", "L Thanuja", "T V Smitha", "S Devanathan", "Ganesh R Naik", "K V Nagaraja"], "categories": ["physics.med-ph", "cs.AI", "cs.NA", "math.NA", "physics.bio-ph"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06273v1", "summary": "The increasing complexity of cardiovascular diseases and limitations in\ntraditional healing methods mandate the invention of new drug delivery systems\nthat assure targeted, effective, and regulated treatments, contributing\ndirectly to UN SDGs 3 and 9, thereby encouraging the utilization of sustainable\nmedical technologies in healthcare. This study investigates the flow of a\nCasson-Maxwell nanofluid through a stenosed arterial domain. The quantities,\nsuch as skin friction and heat transfer rate, are analysed in detail. The\nCasson-Maxwell fluid shows a lower velocity profile than the Casson fluids,\nwhich indicates the improved residence time for efficient drug delivery. The\nheat transfer rate shows an increase with higher volume fractions of copper and\naluminium oxide nanoparticles and a decrease with higher volume fractions of\nsilver nanoparticles. The skin friction coefficient decreases by 219% with a\nunit increase in the Maxwell parameter, whereas it increases by 66.1% with a\nunit rise in the Casson parameter. This work supports SDGs 4 and 17 by\nfostering interdisciplinary learning and collaboration in fluid dynamics and\nhealthcare innovation. Additionally, the rate of heat flow was forecasted (with\nan overall R-value of 0.99457) using the Levenberg-Marquardt backpropagation\ntraining scheme under the influence of magneto-radiative, linear heat source\nand Casson-Maxwell parameters along with the tri-metallic nanoparticle volume\nfractions. It is also observed that the drag coefficient is most sensitive to\nthe changes in the Maxwell parameter.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06273v1", "cate": "physics.med-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06449", "title": "FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models", "authors": ["Qianyu Long", "Qiyuan Wang", "Christos Anagnostopoulos", "Daning Bi"], "categories": ["cs.LG", "cs.AI", "cs.DC", "68T05, 68T07, 68Q85, 94A08", "I.2.6; I.2.11; C.2.4"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, 8 figures, 5 tables. This paper introduces FedPhD, a novel hierarchical federated learning framework for training diffusion models that addresses data heterogeneity and communication costs through homogeneity-aware aggregation and structured pruning. Submitted to IEEE Transactions on Cybernetics and is under review", "url": "http://arxiv.org/abs/2507.06449v1", "summary": "Federated Learning (FL), as a distributed learning paradigm, trains models\nover distributed clients' data. FL is particularly beneficial for distributed\ntraining of Diffusion Models (DMs), which are high-quality image generators\nthat require diverse data. However, challenges such as high communication costs\nand data heterogeneity persist in training DMs similar to training Transformers\nand Convolutional Neural Networks. Limited research has addressed these issues\nin FL environments. To address this gap and challenges, we introduce a novel\napproach, FedPhD, designed to efficiently train DMs in FL environments. FedPhD\nleverages Hierarchical FL with homogeneity-aware model aggregation and\nselection policy to tackle data heterogeneity while reducing communication\ncosts. The distributed structured pruning of FedPhD enhances computational\nefficiency and reduces model storage requirements in clients. Our experiments\nacross multiple datasets demonstrate that FedPhD achieves high model\nperformance regarding Fr\\'echet Inception Distance (FID) scores while reducing\ncommunication costs by up to $88\\%$. FedPhD outperforms baseline methods\nachieving at least a $34\\%$ improvement in FID, while utilizing only $56\\%$ of\nthe total computation and communication resources.", "comment": "12 pages, 8 figures, 5 tables. This paper introduces FedPhD, a novel\n  hierarchical federated learning framework for training diffusion models that\n  addresses data heterogeneity and communication costs through\n  homogeneity-aware aggregation and structured pruning. Submitted to IEEE\n  Transactions on Cybernetics and is under review", "pdf_url": "http://arxiv.org/pdf/2507.06449v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06864", "title": "Toward Neurodivergent-Aware Productivity: A Systems and AI-Based Human-in-the-Loop Framework for ADHD-Affected Professionals", "authors": ["Raghavendra Deshmukh"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06864v1", "summary": "Digital work environments in IT and knowledge-based sectors demand high\nlevels of attention management, task juggling, and self-regulation. For adults\nwith ADHD, these settings often amplify challenges such as time blindness,\ndigital distraction, emotional reactivity, and executive dysfunction. These\nindividuals prefer low-touch, easy-to-use interventions for daily tasks.\nConventional productivity tools often fail to support the cognitive variability\nand overload experienced by neurodivergent professionals. This paper presents a\nframework that blends Systems Thinking, Human-in-the-Loop design, AI/ML, and\nprivacy-first adaptive agents to support ADHD-affected users. The assistant\nsenses tab usage, application focus, and inactivity using on-device ML. These\ncues are used to infer attention states and deliver nudges, reflective prompts,\nor accountability-based presence (body doubling) that aid regulation without\ndisruption. Technically grounded in AI, the approach views attention as shaped\nby dynamic feedback loops. The result is a replicable model for adaptive,\ninclusive support tools in high-distraction work environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06864v1", "cate": "cs.HC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06332", "title": "AR2: Attention-Guided Repair for the Robustness of CNNs Against Common Corruptions", "authors": ["Fuyuan Zhang", "Qichen Wang", "Jianjun Zhao"], "categories": ["cs.CV", "cs.LG", "cs.SE"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06332v1", "summary": "Deep neural networks suffer from significant performance degradation when\nexposed to common corruptions such as noise, blur, weather, and digital\ndistortions, limiting their reliability in real-world applications. In this\npaper, we propose AR2 (Attention-Guided Repair for Robustness), a simple yet\neffective method to enhance the corruption robustness of pretrained CNNs. AR2\noperates by explicitly aligning the class activation maps (CAMs) between clean\nand corrupted images, encouraging the model to maintain consistent attention\neven under input perturbations. Our approach follows an iterative repair\nstrategy that alternates between CAM-guided refinement and standard\nfine-tuning, without requiring architectural changes. Extensive experiments\nshow that AR2 consistently outperforms existing state-of-the-art methods in\nrestoring robustness on standard corruption benchmarks (CIFAR-10-C, CIFAR-100-C\nand ImageNet-C), achieving a favorable balance between accuracy on clean data\nand corruption robustness. These results demonstrate that AR2 provides a robust\nand scalable solution for enhancing model reliability in real-world\nenvironments with diverse corruptions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06332v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06704", "title": "Issue Tracking Ecosystems: Context and Best Practices", "authors": ["Lloyd Montgomery"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      300 pages, Dissertation for the doctoral degree Dr. rer. nat. at the Faculty of Mathematics, Informatics, and Natural Sciences, Department of Informatics, University of Hamburg, Hamburg, Germany", "url": "http://arxiv.org/abs/2507.06704v1", "summary": "Issue Tracking Systems (ITSs), such as GitHub and Jira, are popular tools\nthat support Software Engineering (SE) organisations through the management of\n``issues'', which represent different SE artefacts such as requirements,\ndevelopment tasks, and maintenance items. ITSs also support internal linking\nbetween issues, and external linking to other tools and information sources.\nThis provides SE organisations key forms of documentation, including forwards\nand backwards traceability (e.g., Feature Requests linked to sprint releases\nand code commits linked to Bug Reports). An Issue Tracking Ecosystem (ITE) is\nthe aggregate of the central ITS and the related SE artefacts, stakeholders,\nand processes -- with an emphasis on how these contextual factors interact with\nthe ITS. The quality of ITEs is central to the success of these organisations\nand their software products. There are challenges, however, within ITEs,\nincluding complex networks of interlinked artefacts and diverse workflows.\nWhile ITSs have been the subject of study in SE research for decades, ITEs as a\nwhole need further exploration.\n  In this thesis, I undertake the challenge of understanding ITEs at a broader\nlevel, addressing these questions regarding complexity and diversity. I\ninterviewed practitioners and performed archival analysis on a diverse set of\nITSs. These analyses revealed the context-dependent nature of ITE problems,\nhighlighting the need for context-specific ITE research. While previous work\nhas produced many solutions to specific ITS problems, these solutions are not\nconsistently framed in a context-rich and comparable way, leading to a desire\nfor more aligned solutions across research and practice. To address this\nemergent information and lack of alignment, I created the Best Practice\nOntology for ITEs. <... truncated due to arXiv abstract character limit ...>", "comment": "300 pages, Dissertation for the doctoral degree Dr. rer. nat. at the\n  Faculty of Mathematics, Informatics, and Natural Sciences, Department of\n  Informatics, University of Hamburg, Hamburg, Germany", "pdf_url": "http://arxiv.org/pdf/2507.06704v1", "cate": "cs.SE", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06541", "title": "Graph-based Fake Account Detection: A Survey", "authors": ["Ali Safarpoor Dehkordi", "Ahad N. Zehmakan"], "categories": ["cs.SI", "cs.AI", "cs.LG", "A.1; I.2.6; I.5.1"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      16 Tables, 5 Figures, 41 Pages", "url": "http://arxiv.org/abs/2507.06541v1", "summary": "In recent years, there has been a growing effort to develop effective and\nefficient algorithms for fake account detection in online social networks. This\nsurvey comprehensively reviews existing methods, with a focus on graph-based\ntechniques that utilise topological features of social graphs (in addition to\naccount information, such as their shared contents and profile data) to\ndistinguish between fake and real accounts. We provide several categorisations\nof these methods (for example, based on techniques used, input data, and\ndetection time), discuss their strengths and limitations, and explain how these\nmethods connect in the broader context. We also investigate the available\ndatasets, including both real-world data and synthesised models. We conclude\nthe paper by proposing several potential avenues for future research.", "comment": "16 Tables, 5 Figures, 41 Pages", "pdf_url": "http://arxiv.org/pdf/2507.06541v1", "cate": "cs.SI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2503.16248", "title": "Real AI Agents with Fake Memories: Fatal Context Manipulation Attacks on Web3 Agents", "authors": ["Atharv Singh Patlan", "Peiyao Sheng", "S. Ashwin Hebbar", "Prateek Mittal", "Pramod Viswanath"], "categories": ["cs.CR", "cs.AI", "I.2.7"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      19 pages, 14 figures", "url": "http://arxiv.org/abs/2503.16248v3", "summary": "AI agents integrated with Web3 offer autonomy and openness but raise security\nconcerns as they interact with financial protocols and immutable smart\ncontracts. This paper investigates the vulnerabilities of AI agents within\nblockchain-based financial ecosystems when exposed to adversarial threats in\nreal-world scenarios. We introduce the concept of context manipulation -- a\ncomprehensive attack vector that exploits unprotected context surfaces,\nincluding input channels, memory modules, and external data feeds. It expands\non traditional prompt injection and reveals a more stealthy and persistent\nthreat: memory injection. Using ElizaOS, a representative decentralized AI\nagent framework for automated Web3 operations, we showcase that malicious\ninjections into prompts or historical records can trigger unauthorized asset\ntransfers and protocol violations which could be financially devastating in\nreality. To quantify these risks, we introduce CrAIBench, a Web3-focused\nbenchmark covering 150+ realistic blockchain tasks. such as token transfers,\ntrading, bridges, and cross-chain interactions, and 500+ attack test cases\nusing context manipulation. Our evaluation results confirm that AI models are\nsignificantly more vulnerable to memory injection compared to prompt injection.\nFinally, we evaluate a comprehensive defense roadmap, finding that\nprompt-injection defenses and detectors only provide limited protection when\nstored context is corrupted, whereas fine-tuning-based defenses substantially\nreduce attack success rates while preserving performance on single-step tasks.\nThese results underscore the urgent need for AI agents that are both secure and\nfiduciarily responsible in blockchain environments.", "comment": "19 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2503.16248v3", "cate": "cs.CR", "date": "2025-03-20", "updated": "2025-07-09"}
{"id": "2507.06905", "title": "ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation", "authors": ["Wandong Sun", "Luying Feng", "Baoshi Cao", "Yang Liu", "Yaochu Jin", "Zongwu Xie"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06905v1", "summary": "Loco-Manipulation for humanoid robots aims to enable robots to integrate\nmobility with upper-body tracking capabilities. Most existing approaches adopt\nhierarchical architectures that decompose control into isolated upper-body\n(manipulation) and lower-body (locomotion) policies. While this decomposition\nreduces training complexity, it inherently limits coordination between\nsubsystems and contradicts the unified whole-body control exhibited by humans.\nWe demonstrate that a single unified policy can achieve a combination of\ntracking accuracy, large workspace, and robustness for humanoid\nloco-manipulation. We propose the Unified Loco-Manipulation Controller (ULC), a\nsingle-policy framework that simultaneously tracks root velocity, root height,\ntorso rotation, and dual-arm joint positions in an end-to-end manner, proving\nthe feasibility of unified control without sacrificing performance. We achieve\nthis unified control through key technologies: sequence skill acquisition for\nprogressive learning complexity, residual action modeling for fine-grained\ncontrol adjustments, command polynomial interpolation for smooth motion\ntransitions, random delay release for robustness to deploy variations, load\nrandomization for generalization to external disturbances, and\ncenter-of-gravity tracking for providing explicit policy gradients to maintain\nstability. We validate our method on the Unitree G1 humanoid robot with 3-DOF\n(degrees-of-freedom) waist. Compared with strong baselines, ULC shows better\ntracking performance to disentangled methods and demonstrating larger workspace\ncoverage. The unified dual-arm tracking enables precise manipulation under\nexternal loads while maintaining coordinated whole-body control for complex\nloco-manipulation tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06905v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06277", "title": "The Prompt War: How AI Decides on a Military Intervention", "authors": ["Maxim Chupilkin"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      13 pages, 8 tables, 1 figure", "url": "http://arxiv.org/abs/2507.06277v1", "summary": "Which factors determine AI propensity for military intervention? While the\nuse of AI in war games and military planning is growing exponentially, the\nsimple analysis of key drivers embedded in the models has not yet been done.\nThis paper does a simple conjoint experiment proposing a model to decide on\nmilitary intervention in 640 vignettes where each was run for 100 times\nallowing to explore AI decision on military intervention systematically. The\nanalysis finds that largest predictors of AI decision to intervene are high\ndomestic support and high probability of success. Costs such as international\ncondemnation, military deaths, civilian deaths, and negative economic effect\nare statistically significant, but their effect is around half of domestic\nsupport and probability of victory. Closing window of opportunity only reaches\nstatistical significance in interaction with other factors. The results are\nremarkably consistent across scenarios and across different models (OpenAI GPT,\nAnthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.", "comment": "13 pages, 8 tables, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.06277v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06458", "title": "Automated Neuron Labelling Enables Generative Steering and Interpretability in Protein Language Models", "authors": ["Arjun Banerjee", "David Martinez", "Camille Dang", "Ethan Tam"], "categories": ["cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages, 13 figures. Accepted to Proceedings of the Workshop on Generative AI for Biology at the 42nd International Conference on Machine Learning (Spotlight)", "url": "http://arxiv.org/abs/2507.06458v1", "summary": "Protein language models (PLMs) encode rich biological information, yet their\ninternal neuron representations are poorly understood. We introduce the first\nautomated framework for labeling every neuron in a PLM with biologically\ngrounded natural language descriptions. Unlike prior approaches relying on\nsparse autoencoders or manual annotation, our method scales to hundreds of\nthousands of neurons, revealing individual neurons are selectively sensitive to\ndiverse biochemical and structural properties. We then develop a novel neuron\nactivation-guided steering method to generate proteins with desired traits,\nenabling convergence to target biochemical properties like molecular weight and\ninstability index as well as secondary and tertiary structural motifs,\nincluding alpha helices and canonical Zinc Fingers. We finally show that\nanalysis of labeled neurons in different model sizes reveals PLM scaling laws\nand a structured neuron space distribution.", "comment": "15 pages, 13 figures. Accepted to Proceedings of the Workshop on\n  Generative AI for Biology at the 42nd International Conference on Machine\n  Learning (Spotlight)", "pdf_url": "http://arxiv.org/pdf/2507.06458v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06306", "title": "Humans overrely on overconfident language models, across languages", "authors": ["Neil Rathi", "Dan Jurafsky", "Kaitlyn Zhou"], "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages main text, to appear at COLM 2025", "url": "http://arxiv.org/abs/2507.06306v1", "summary": "As large language models (LLMs) are deployed globally, it is crucial that\ntheir responses are calibrated across languages to accurately convey\nuncertainty and limitations. Previous work has shown that LLMs are\nlinguistically overconfident in English, leading users to overrely on confident\ngenerations. However, the usage and interpretation of epistemic markers (e.g.,\n'It's definitely,' 'I think') can differ sharply across languages. Here, we\nstudy the risks of multilingual linguistic (mis)calibration, overconfidence,\nand overreliance across five languages to evaluate the safety of LLMs in a\nglobal context.\n  We find that overreliance risks are high across all languages. We first\nanalyze the distribution of LLM-generated epistemic markers, and observe that\nwhile LLMs are cross-linguistically overconfident, they are also sensitive to\ndocumented linguistic variation. For example, models generate the most markers\nof uncertainty in Japanese and the most markers of certainty in German and\nMandarin. We then measure human reliance rates across languages, finding that\nwhile users strongly rely on confident LLM generations in all languages,\nreliance behaviors differ cross-linguistically: for example, users rely\nsignificantly more on expressions of uncertainty in Japanese than in English.\nTaken together, these results indicate high risk of reliance on overconfident\nmodel generations across languages. Our findings highlight the challenges of\nmultilingual linguistic calibration and stress the importance of culturally and\nlinguistically contextualized model safety evaluations.", "comment": "10 pages main text, to appear at COLM 2025", "pdf_url": "http://arxiv.org/pdf/2507.06306v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06400", "title": "When Trackers Date Fish: A Benchmark and Framework for Underwater Multiple Fish Tracking", "authors": ["Weiran Li", "Yeqiang Liu", "Qiannan Guo", "Yijie Wei", "Hwa Liang Leo", "Zhenbo Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06400v1", "summary": "Multiple object tracking (MOT) technology has made significant progress in\nterrestrial applications, but underwater tracking scenarios remain\nunderexplored despite their importance to marine ecology and aquaculture. We\npresent Multiple Fish Tracking Dataset 2025 (MFT25), the first comprehensive\ndataset specifically designed for underwater multiple fish tracking, featuring\n15 diverse video sequences with 408,578 meticulously annotated bounding boxes\nacross 48,066 frames. Our dataset captures various underwater environments,\nfish species, and challenging conditions including occlusions, similar\nappearances, and erratic motion patterns. Additionally, we introduce\nScale-aware and Unscented Tracker (SU-T), a specialized tracking framework\nfeaturing an Unscented Kalman Filter (UKF) optimized for non-linear fish\nswimming patterns and a novel Fish-Intersection-over-Union (FishIoU) matching\nthat accounts for the unique morphological characteristics of aquatic species.\nExtensive experiments demonstrate that our SU-T baseline achieves\nstate-of-the-art performance on MFT25, with 34.1 HOTA and 44.6 IDF1, while\nrevealing fundamental differences between fish tracking and terrestrial object\ntracking scenarios. MFT25 establishes a robust foundation for advancing\nresearch in underwater tracking systems with important applications in marine\nbiology, aquaculture monitoring, and ecological conservation. The dataset and\ncodes are released at https://vranlee.github.io/SU-T/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06400v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06762", "title": "Leveraging LLMs for Semantic Conflict Detection via Unit Test Generation", "authors": ["Nathalia Barbosa", "Paulo Borba", "Léuson Da Silva"], "categories": ["cs.SE", "K.6.3"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Comments: 11 pages, in Portuguese language. 3 figures. Submitted to SAST 2025 (X Simpósio Brasileiro de Teste de Software Sistemático e Automatizado)", "url": "http://arxiv.org/abs/2507.06762v1", "summary": "Semantic conflicts arise when a developer introduces changes to a codebase\nthat unintentionally affect the behavior of changes integrated in parallel by\nother developers. Traditional merge tools are unable to detect such conflicts,\nso complementary tools like SMAT have been proposed. SMAT relies on generating\nand executing unit tests: if a test fails on the base version, passes on a\ndeveloper's modified version, but fails again after merging with another\ndeveloper's changes, a semantic conflict is indicated. While SMAT is effective\nat detecting conflicts, it suffers from a high rate of false negatives, partly\ndue to the limitations of unit test generation tools such as Randoop and\nEvosuite. To investigate whether large language models (LLMs) can overcome\nthese limitations, we propose and integrate a new test generation tool based on\nCode Llama 70B into SMAT. We explore the model's ability to generate tests\nusing different interaction strategies, prompt contents, and parameter\nconfigurations. Our evaluation uses two samples: a benchmark with simpler\nsystems from related work, and a more significant sample based on complex,\nreal-world systems. We assess the effectiveness of the new SMAT extension in\ndetecting conflicts. Results indicate that, although LLM-based test generation\nremains challenging and computationally expensive in complex scenarios, there\nis promising potential for improving semantic conflict detection.\n  --\n  Conflitos sem^anticos surgem quando um desenvolvedor introduz mudan\\c{c}as em\numa base de c\\'odigo que afetam, de forma n~ao intencional, o comportamento de\naltera\\c{c}~oes integradas em paralelo por outros desenvolvedores. Ferramentas\ntradicionais de merge n~ao conseguem detectar esse tipo de conflito, por isso\nferramentas complementares como o SMAT foram propostas. O SMAT depende da\ngera\\c{c}~ao e execu\\c{c}~ao de testes de unidade: se um teste falha na vers~ao\nbase, passa na vers~ao modificada por um desenvolvedor, mas volta a falhar\nap\\'os o merge com as mudan\\c{c}as de outro desenvolvedor, um conflito\nsem^antico \\'e identificado. Embora o SMAT seja eficaz na detec\\c{c}~ao de\nconflitos, apresenta alta taxa de falsos negativos, em parte devido \\`as\nlimita\\c{c}~oes das ferramentas de gera\\c{c}~ao de testes como Randoop e\nEvosuite. Para investigar se modelos de linguagem de grande porte (LLMs) podem\nsuperar essas limita\\c{c}~oes, propomos e integramos ao SMAT uma nova\nferramenta de gera\\c{c}~ao de testes baseada no Code Llama 70B. Exploramos a\ncapacidade do modelo de gerar testes utilizando diferentes estrat\\'egias de\nintera\\c{c}~ao, conte\\'udos de prompts e configura\\c{c}~oes de par^ametros.\nNossa avalia\\c{c}~ao utiliza duas amostras: um benchmark com sistemas mais\nsimples, usados em trabalhos relacionados, e uma amostra mais significativa\nbaseada em sistemas complexos e reais. Avaliamos a efic\\'acia da nova extens~ao\ndo SMAT na detec\\c{c}~ao de conflitos. Os resultados indicam que, embora a\ngera\\c{c}~ao de testes por LLM em cen\\'arios complexos ainda seja desafiadora e\ncustosa computacionalmente, h\\'a potencial promissor para aprimorar a\ndetec\\c{c}~ao de conflitos sem^anticos.", "comment": "Comments: 11 pages, in Portuguese language. 3 figures. Submitted to\n  SAST 2025 (X Simp\\'osio Brasileiro de Teste de Software Sistem\\'atico e\n  Automatizado)", "pdf_url": "http://arxiv.org/pdf/2507.06762v1", "cate": "cs.SE", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07036", "title": "Modeling Heterogeneity across Varying Spatial Extents: Discovering Linkages between Sea Ice Retreat and Ice Shelve Melt in the Antarctic", "authors": ["Maloy Kumar Devnath", "Sudip Chakraborty", "Vandana P. Janeja"], "categories": ["cs.SI", "cs.AI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07036v1", "summary": "Spatial phenomena often exhibit heterogeneity across spatial extents and in\nproximity, making them complex to model-especially in dynamic regions like ice\nshelves and sea ice. In this study, we address this challenge by exploring the\nlinkages between sea ice retreat and Antarctic ice shelf (AIS) melt. Although\natmospheric forcing and basal melting have been widely studied, the direct\nimpact of sea ice retreat on AIS mass loss remains underexplored. Traditional\nmodels treat sea ice and AIS as separate systems. It limits their ability to\ncapture localized linkages and cascading feedback. To overcome this, we propose\nSpatial-Link, a novel graph-based framework that quantifies spatial\nheterogeneity to capture linkages between sea ice retreat and AIS melt. Our\nmethod constructs a spatial graph using Delaunay triangulation of\nsatellite-derived ice change matrices, where nodes represent regions of\nsignificant change and edges encode proximity and directional consistency. We\nextract and statistically validate linkage paths using breadth-first search and\nMonte Carlo simulations. Results reveal non-local, spatially heterogeneous\ncoupling patterns, suggesting sea ice loss can initiate or amplify downstream\nAIS melt. Our analysis shows how sea ice retreat evolves over an oceanic grid\nand progresses toward ice shelves-establishing a direct linkage. To our\nknowledge, this is the first proposed methodology linking sea ice retreat to\nAIS melt. Spatial-Link offers a scalable, data-driven tool to improve sea-level\nrise projections and inform climate adaptation strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07036v1", "cate": "cs.SI", "date": "2025-06-18", "updated": "2025-06-18"}
{"id": "2507.06430", "title": "One task to rule them all: A closer look at traffic classification generalizability", "authors": ["Elham Akbari", "Zihao Zhou", "Mohammad Ali Salahuddin", "Noura Limam", "Raouf Boutaba", "Bertrand Mathieu", "Stephanie Moteau", "Stephane Tuffin"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06430v1", "summary": "Existing website fingerprinting and traffic classification solutions do not\nwork well when the evaluation context changes, as their performances often\nheavily rely on context-specific assumptions. To clarify this problem, we take\nthree prior solutions presented for different but similar traffic\nclassification and website fingerprinting tasks, and apply each solution's\nmodel to another solution's dataset. We pinpoint dataset-specific and\nmodel-specific properties that lead each of them to overperform in their\nspecific evaluation context.\n  As a realistic evaluation context that takes practical labeling constraints\ninto account, we design an evaluation framework using two recent real-world TLS\ntraffic datasets from large-scale networks. The framework simulates a\nfuturistic scenario in which SNIs are hidden in some networks but not in\nothers, and the classifier's goal is to predict destination services in one\nnetwork's traffic, having been trained on a labelled dataset collected from a\ndifferent network. Our framework has the distinction of including real-world\ndistribution shift, while excluding concept drift. We show that, even when\nabundant labeled data is available, the best solutions' performances under\ndistribution shift are between 30% and 40%, and a simple 1-Nearest Neighbor\nclassifier's performance is not far behind. We depict all performances measured\non different models, not just the best ones, for a fair representation of\ntraffic models in practice.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06430v1", "cate": "cs.NI", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.03236", "title": "On Jailbreaking Quantized Language Models Through Fault Injection Attacks", "authors": ["Noureldin Zahran", "Ahmad Tahmasivand", "Ihsen Alouani", "Khaled Khasawneh", "Mohammed E. Fouda"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      This work has been published in GLSVLSI 2025", "url": "http://arxiv.org/abs/2507.03236v2", "summary": "The safety alignment of Language Models (LMs) is a critical concern, yet\ntheir integrity can be challenged by direct parameter manipulation attacks,\nsuch as those potentially induced by fault injection. As LMs are increasingly\ndeployed using low-precision quantization for efficiency, this paper\ninvestigates the efficacy of such attacks for jailbreaking aligned LMs across\ndifferent quantization schemes. We propose gradient-guided attacks, including a\ntailored progressive bit-level search algorithm introduced herein and a\ncomparative word-level (single weight update) attack. Our evaluation on\nLlama-3.2-3B, Phi-4-mini, and Llama-3-8B across FP16 (baseline), and\nweight-only quantization (FP8, INT8, INT4) reveals that quantization\nsignificantly influences attack success. While attacks readily achieve high\nsuccess (>80% Attack Success Rate, ASR) on FP16 models, within an attack budget\nof 25 perturbations, FP8 and INT8 models exhibit ASRs below 20% and 50%,\nrespectively. Increasing the perturbation budget up to 150 bit-flips, FP8\nmodels maintained ASR below 65%, demonstrating some resilience compared to INT8\nand INT4 models that have high ASR. In addition, analysis of perturbation\nlocations revealed differing architectural targets across quantization schemes,\nwith (FP16, INT4) and (INT8, FP8) showing similar characteristics. Besides,\njailbreaks induced in FP16 models were highly transferable to subsequent\nFP8/INT8 quantization (<5% ASR difference), though INT4 significantly reduced\ntransferred ASR (avg. 35% drop). These findings highlight that while common\nquantization schemes, particularly FP8, increase the difficulty of direct\nparameter manipulation jailbreaks, vulnerabilities can still persist,\nespecially through post-attack quantization.", "comment": "This work has been published in GLSVLSI 2025", "pdf_url": "http://arxiv.org/pdf/2507.03236v2", "cate": "cs.CR", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2507.06960", "title": "Bounomodes: the grazing ox algorithm for exploration of clustered anomalies", "authors": ["Samuel Matloob", "Ayan Dutta", "O. Patrick Kreidl", "Swapnonel Roy", "Ladislau Bölöni"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06960v1", "summary": "A common class of algorithms for informative path planning (IPP) follows\nboustrophedon (\"as the ox turns\") patterns, which aim to achieve uniform area\ncoverage. However, IPP is often applied in scenarios where anomalies, such as\nplant diseases, pollution, or hurricane damage, appear in clusters. In such\ncases, prioritizing the exploration of anomalous regions over uniform coverage\nis beneficial. This work introduces a class of algorithms referred to as\nbounom\\=odes (\"as the ox grazes\"), which alternates between uniform\nboustrophedon sampling and targeted exploration of detected anomaly clusters.\nWhile uniform sampling can be designed using geometric principles, close\nexploration of clusters depends on the spatial distribution of anomalies and\nmust be learned. In our implementation, the close exploration behavior is\nlearned using deep reinforcement learning algorithms. Experimental evaluations\ndemonstrate that the proposed approach outperforms several established\nbaselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06960v1", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06329", "title": "MixAssist: An Audio-Language Dataset for Co-Creative AI Assistance in Music Mixing", "authors": ["Michael Clemens", "Ana Marasović"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Published at COLM 2025. Code and dataset are available here this http URL", "url": "http://arxiv.org/abs/2507.06329v1", "summary": "While AI presents significant potential for enhancing music mixing and\nmastering workflows, current research predominantly emphasizes end-to-end\nautomation or generation, often overlooking the collaborative and instructional\ndimensions vital for co-creative processes. This gap leaves artists,\nparticularly amateurs seeking to develop expertise, underserved. To bridge\nthis, we introduce MixAssist, a novel audio-language dataset capturing the\nsituated, multi-turn dialogue between expert and amateur music producers during\ncollaborative mixing sessions. Comprising 431 audio-grounded conversational\nturns derived from 7 in-depth sessions involving 12 producers, MixAssist\nprovides a unique resource for training and evaluating audio-language models\nthat can comprehend and respond to the complexities of real-world music\nproduction dialogues. Our evaluations, including automated LLM-as-a-judge\nassessments and human expert comparisons, demonstrate that fine-tuning models\nsuch as Qwen-Audio on MixAssist can yield promising results, with Qwen\nsignificantly outperforming other tested models in generating helpful,\ncontextually relevant mixing advice. By focusing on co-creative instruction\ngrounded in audio context, MixAssist enables the development of intelligent AI\nassistants designed to support and augment the creative process in music\nmixing.", "comment": "Published at COLM 2025. Code and dataset are available here\n  http://mclemcrew.github.io/mixassist-website", "pdf_url": "http://arxiv.org/pdf/2507.06329v1", "cate": "cs.SD", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06461", "title": "Energy-Efficient Supervised Learning with a Binary Stochastic Forward-Forward Algorithm", "authors": ["Risi Jaiswal", "Supriyo Datta", "Joseph G. Makin"], "categories": ["cs.LG", "cs.NE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      24 pages, 5 figures, 4 tables. Under review", "url": "http://arxiv.org/abs/2507.06461v1", "summary": "Reducing energy consumption has become a pressing need for modern machine\nlearning, which has achieved many of its most impressive results by scaling to\nlarger and more energy-consumptive neural networks. Unfortunately, the main\nalgorithm for training such networks, backpropagation, poses significant\nchallenges for custom hardware accelerators, due to both its serial\ndependencies and the memory footprint needed to store forward activations for\nthe backward pass. Alternatives to backprop, although less effective, do exist;\nhere the main computational bottleneck becomes matrix multiplication. In this\nstudy, we derive forward-forward algorithms for binary, stochastic units.\nBinarization of the activations transforms matrix multiplications into indexing\noperations, which can be executed efficiently in hardware. Stochasticity,\ncombined with tied weights across units with different biases, bypasses the\ninformation bottleneck imposed by binary units. Furthermore, although slow and\nexpensive in traditional hardware, binary sampling that is very fast can be\nimplemented cheaply with p-bits (probabilistic bits), novel devices made up of\nunstable magnets. We evaluate our proposed algorithms on the MNIST,\nFashion-MNIST, and CIFAR-10 datasets, showing that its performance is close to\nreal-valued forward-forward, but with an estimated energy savings of about one\norder of magnitude.", "comment": "24 pages, 5 figures, 4 tables. Under review", "pdf_url": "http://arxiv.org/pdf/2507.06461v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06438", "title": "Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study", "authors": ["Kaléu Delphino"], "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      40 pages, 23 figures", "url": "http://arxiv.org/abs/2507.06438v1", "summary": "Tools that can generate computer code in response to inputs written in\nnatural language, such as ChatGPT, pose an existential threat to Computer\nScience education in its current form, since students can now use these tools\nto solve assignments without much effort. While that risk has already been\nrecognized by scholars, the proportion of the student body that is incurring in\nthis new kind of plagiarism is still an open problem. We conducted a pilot\nstudy in a large CS class (n=120) to assess the feasibility of estimating AI\nplagiarism through anonymous surveys and interviews. More than 25% of the\nsurvey respondents admitted to committing AI plagiarism. Conversely, only one\nstudent accepted to be interviewed. Given the high levels of misconduct\nacknowledgment, we conclude that surveys are an effective method for studies on\nthe matter, while interviews should be avoided or designed in a way that can\nentice participation.", "comment": "40 pages, 23 figures", "pdf_url": "http://arxiv.org/pdf/2507.06438v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06405", "title": "SImpHAR: Advancing impedance-based human activity recognition using 3D simulation and text-to-motion models", "authors": ["Lala Shakti Swarup Ray", "Mengxi Liu", "Deepika Gurung", "Bo Zhou", "Sungho Suh", "Paul Lukowicz"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06405v1", "summary": "Human Activity Recognition (HAR) with wearable sensors is essential for\napplications in healthcare, fitness, and human-computer interaction.\nBio-impedance sensing offers unique advantages for fine-grained motion capture\nbut remains underutilized due to the scarcity of labeled data. We introduce\nSImpHAR, a novel framework addressing this limitation through two core\ncontributions. First, we propose a simulation pipeline that generates realistic\nbio-impedance signals from 3D human meshes using shortest-path estimation,\nsoft-body physics, and text-to-motion generation serving as a digital twin for\ndata augmentation. Second, we design a two-stage training strategy with\ndecoupled approach that enables broader activity coverage without requiring\nlabel-aligned synthetic data. We evaluate SImpHAR on our collected ImpAct\ndataset and two public benchmarks, showing consistent improvements over\nstate-of-the-art methods, with gains of up to 22.3% and 21.8%, in terms of\naccuracy and macro F1 score, respectively. Our results highlight the promise of\nsimulation-driven augmentation and modular training for impedance-based HAR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06405v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06881", "title": "Formalization of the AADL Run-Time Services with Time", "authors": ["Brian R Larson", "Ehsan Ahmad"], "categories": ["cs.SE", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      35 pages, 13 figures", "url": "http://arxiv.org/abs/2507.06881v1", "summary": "The Architecture Analysis & Design Language (AADL) is an architecture\ndescription language for design of cyber-physical systems--machines controlled\nby software. The AADL standard, SAE International AS5506D, describes Run-Time\nServices (RTS) to be provided to execute AADL models in accordance with\nsemantics defined by the standard. The RTS of primary concern are transport\nservices and timing services. Although, the study presented in [1] sets a\nfoundation for the formal semantics of AADL, but without modeling time. This\npaper extends and simplifies this formalization using a modal logic defined by\na Kripke structure, to explicitly include time. The RTS defined in the AADL\nstandard are also expanded to support reactive state-transition machines of the\nBehavior Specification annex standard language (BA) and its closely-related,\nformally-defined counterpart, the Behavior Language for Embedded Systems with\nSoftware (BLESS). An example of AADL RTS with time, implemented by the High\nAssurance Modeling and Rapid Engineering for Embedded Systems (HAMR) for\nstate-transition machine behavior written in BLESS, is also presented.", "comment": "35 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.06881v1", "cate": "cs.SE", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06469", "title": "Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning", "authors": ["Yudan Song", "Yuecen Wei", "Yuhang Lu", "Qingyun Sun", "Minglai Shao", "Li-e Wang", "Chunming Hu", "Xianxian Li", "Xingcheng Fu"], "categories": ["cs.LG", "cs.SI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06469v1", "summary": "Graph representation learning has become a mainstream method for fraud\ndetection due to its strong expressive power, which focuses on enhancing node\nrepresentations through improved neighborhood knowledge capture. However, the\nfocus on local interactions leads to imbalanced transmission of global\ntopological information and increased risk of node-specific information being\noverwhelmed during aggregation due to the imbalance between fraud and benign\nnodes. In this paper, we first summarize the impact of topology and class\nimbalance on downstream tasks in GNN-based fraud detection, as the problem of\nimbalanced supervisory messages is caused by fraudsters' topological behavior\nobfuscation and identity feature concealment. Based on statistical validation,\nwe propose a novel dual-view graph representation learning method to mitigate\nMessage imbalance in Fraud Detection(MimbFD). Specifically, we design a\ntopological message reachability module for high-quality node representation\nlearning to penetrate fraudsters' camouflage and alleviate insufficient\npropagation. Then, we introduce a local confounding debiasing module to adjust\nnode representations, enhancing the stable association between node\nrepresentations and labels to balance the influence of different classes.\nFinally, we conducted experiments on three public fraud datasets, and the\nresults demonstrate that MimbFD exhibits outstanding performance in fraud\ndetection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06469v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06632", "title": "Stacked Intelligent Metasurfaces-Aided eVTOL Delay Sensitive Communications", "authors": ["Liyuan Chen", "Kai Xiong", "Yujie Qin", "Hanqing Yu", "Supeng Leng", "Chau Yuen"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06632v1", "summary": "With rapid urbanization and increasing population density, urban traffic\ncongestion has become a critical issue, and traditional ground transportation\nmethods are no longer sufficient to address it effectively. To tackle this\nchallenge, the concept of Advanced Air Mobility (AAM) has emerged, aiming to\nutilize low-altitude airspace to establish a three-dimensional transportation\nsystem. Among various components of the AAM system, electric vertical take-off\nand landing (eVTOL) aircraft plays a pivotal role due to their flexibility and\nefficiency. However, the immaturity of Ultra Reliable Low Latency Communication\n(URLLC) technologies poses significant challenges to safety-critical AAM\noperations. Specifically, existing Stacked Intelligent Metasurfaces (SIM)-based\neVTOL systems lack rigorous mathematical frameworks to quantify probabilistic\ndelay bounds under dynamic air traffic patterns, a prerequisite for collision\navoidance and airspace management. To bridge this gap, we employ network\ncalculus tools to derive the probabilistic upper bound on communication delay\nin the AAM system for the first time. Furthermore, we formulate a complex\nnon-convex optimization problem that jointly minimizes the probabilistic delay\nbound and the propagation delay. To solve this problem efficiently, we propose\na solution based on the Block Coordinate Descent (BCD) algorithm and\nSemidefinite Relaxation (SDR) method. In addition, we conduct a comprehensive\nanalysis of how various factors impact regret and transmission rate, and\nexplore the influence of varying load intensity and total delay on the\nprobabilistic delay bound.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06632v1", "cate": "cs.NI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.05558", "title": "AI Agent Smart Contract Exploit Generation", "authors": ["Arthur Gervais", "Liyi Zhou"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05558v2", "summary": "We present A1, an agentic execution driven system that transforms any LLM\ninto an end-to-end exploit generator. A1 has no hand-crafted heuristics and\nprovides the agent with six domain-specific tools that enable autonomous\nvulnerability discovery. The agent can flexibly leverage these tools to\nunderstand smart contract behavior, generate exploit strategies, test them on\nblockchain states, and refine approaches based on execution feedback. All\noutputs are concretely validated to eliminate false positives.\n  The evaluation across 36 real-world vulnerable contracts on Ethereum and\nBinance Smart Chain demonstrates a 62.96% (17 out of 27) success rate on the\nVERITE benchmark. Beyond the VERITE dataset, A1 identified 9 additional\nvulnerable contracts, with 5 cases occurring after the strongest model's\ntraining cutoff date. Across all 26 successful cases, A1 extracts up to 8.59\nmillion USD per case and 9.33 million USD total. Through 432 experiments across\nsix LLMs, we analyze iteration-wise performance showing diminishing returns\nwith average marginal gains of +9.7%, +3.7%, +5.1%, and +2.8% for iterations\n2-5 respectively, with per-experiment costs ranging $0.01-$3.59. A Monte Carlo\nanalysis of 19 historical attacks shows success probabilities of 85.9%-88.8%\nwithout detection delays.\n  We investigate whether an attacker or a defender benefits most from deploying\nA1 as a continuous on-chain scanning system. Our model shows that OpenAI's\no3-pro maintains profitability up to a 30.0 days scanning delay at 0.100%\nvulnerability incidence rates, while faster models require >=1.000% rates to\nbreak-even. The findings exposes a troubling asymmetry: at 0.1% vulnerability\nrates, attackers achieve an on-chain scanning profitability at a \\$6000 exploit\nvalue, while defenders require \\$60000, raising fundamental questions about\nwhether AI agents inevitably favor exploitation over defense.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05558v2", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2507.06336", "title": "Self-supervised learning predicts plant growth trajectories from multi-modal industrial greenhouse data", "authors": ["Adam J Riesselman", "Evan M Cofer", "Therese LaRue", "Wim Meeussen"], "categories": ["q-bio.QM", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06336v1", "summary": "Quantifying organism-level phenotypes, such as growth dynamics and biomass\naccumulation, is fundamental to understanding agronomic traits and optimizing\ncrop production. However, quality growing data of plants at scale is difficult\nto generate. Here we use a mobile robotic platform to capture high-resolution\nenvironmental sensing and phenotyping measurements of a large-scale hydroponic\nleafy greens system. We describe a self-supervised modeling approach to build a\nmap from observed growing data to the entire plant growth trajectory. We\ndemonstrate our approach by forecasting future plant height and harvest mass of\ncrops in this system. This approach represents a significant advance in\ncombining robotic automation and machine learning, as well as providing\nactionable insights for agronomic research and operational efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06336v1", "cate": "q-bio.QM", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06399", "title": "An AI-Driven Thermal-Fluid Testbed for Advanced Small Modular Reactors: Integration of Digital Twin and Large Language Models", "authors": ["Doyeong Lim", "Yang Liu", "Zavier Ndum Ndum", "Christian Young", "Yassin Hassan"], "categories": ["eess.SY", "cs.AI", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06399v1", "summary": "This paper presents a multipurpose artificial intelligence (AI)-driven\nthermal-fluid testbed designed to advance Small Modular Reactor technologies by\nseamlessly integrating physical experimentation with advanced computational\nintelligence. The platform uniquely combines a versatile three-loop\nthermal-fluid facility with a high-fidelity digital twin and sophisticated AI\nframeworks for real-time prediction, control, and operational assistance.\nMethodologically, the testbed's digital twin, built upon the System Analysis\nModule code, is coupled with a Gated Recurrent Unit (GRU) neural network. This\nmachine learning model, trained on experimental data, enables\nfaster-than-real-time simulation, providing predictive insights into the\nsystem's dynamic behavior. The practical application of this AI integration is\nshowcased through case studies. An AI-driven control framework where the GRU\nmodel accurately forecasts future system states and the corresponding control\nactions required to meet operational demands. Furthermore, an intelligent\nassistant, powered by a large language model, translates complex sensor data\nand simulation outputs into natural language, offering operators actionable\nanalysis and safety recommendations. Comprehensive validation against\nexperimental transients confirms the platform's high fidelity, with the GRU\nmodel achieving a temperature prediction root mean square error of 1.42 K. This\nwork establishes an integrated research environment at the intersection of AI\nand thermal-fluid science, showcasing how AI-driven methodologies in modeling,\ncontrol, and operator support can accelerate the innovation and deployment of\nnext-generation nuclear systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06399v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06464", "title": "SoftSignSGD(S3): An Enhanced Optimizer for Practical DNN Training and Loss Spikes Minimization Beyond Adam", "authors": ["Hanyang Peng", "Shuang Qin", "Yue Yu", "Fangqing Jiang", "Hui Wang", "Wen Gao"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      20pages, 11pages", "url": "http://arxiv.org/abs/2507.06464v1", "summary": "Adam has proven remarkable successful in training deep neural networks, but\nthe mechanisms underlying its empirical successes and limitations remain\nunderexplored. In this study, we demonstrate that the effectiveness of Adam\nstems largely from its similarity to SignSGD in robustly handling large\ngradient fluctuations, yet it is also vulnerable to destabilizing loss spikes\ndue to its uncontrolled update scaling. To enhance the advantage of Adam and\nmitigate its limitation, we propose SignSoftSGD (S3), a novel optimizer with\nthree key innovations. \\emph{First}, S3 generalizes the sign-like update by\nemploying a flexible $p$-th order momentum ($p \\geq 1$) in the denominator,\ndeparting from the conventional second-order momentum (variance)\npreconditioning. This design enables enhanced performance while achieving\nstable training even with aggressive learning rates. \\emph{Second}, S3\nminimizes the occurrences of loss spikes through unified exponential moving\naverage coefficients for numerator and denominator momenta, which inherently\nbound updates to $[-1, 1]$ and simplify hyperparameter tuning. \\emph{Third}, S3\nincorporates an equivalent Nesterov's accelerated gradient(NAG) module,\naccelerating convergence without memory overhead. Theoretically, we prove that\nS3 achieves the optimal convergence rate of\n$O\\left(\\frac{1}{T^{\\sfrac{1}{4}}}\\right)$ for general nonconvex stochastic\noptimization under weak assumptions. Extensive experiments across a range of\nvision and language tasks show that \\textsf{\\small S3} not only converges more\nrapidly and improves performance but also rarely experiences loss spikes, even\nwith a \\textbf{$\\bm{10 \\times}$} larger learning rate. In fact, S3 delivers\nperformance comparable to or better than AdamW with \\textbf{$2 \\times$} the\ntraining steps, establishing its efficacy in both efficiency and final task\nperformance.", "comment": "20pages, 11pages", "pdf_url": "http://arxiv.org/pdf/2507.06464v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06790", "title": "Better frame rates or better visuals? An early report of Esports player practice in Dota 2", "authors": ["Arjun Madhusudan", "Benjamin Watson"], "categories": ["cs.GR", "cs.HC"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06790v1", "summary": "Esports athletes often reduce visual quality to improve latency and frame\nrate, and increase their in-game performance. Little research has examined the\neffects of this visuo-spatial tradeoff on performance, but we could find no\nwork studying how players manage this tradeoff in practice. This paper is an\ninitial examination of this question in the game Dota 2. First, we gather the\ngame configuration data of Dota 2 players in a small survey. We learn that\nplayers do limit visual detail, particularly by turning off VSYNC, which\nremoves rendering/display synchronization delay but permits visual \"tearing\".\nSecond, we survey the intent of those same players with a few subjective\nquestions. Player intent matches configuration practice. While our sampling of\nDota 2 players may not be representative, our survey does reveal suggestive\ntrends that lay the groundwork for future, more rigorous and larger surveys.\nSuch surveys can help new players adapt to the game more quickly, encourage\nresearchers to investigate the relative importance of temporal and visual\ndetail, and justify design effort by developers in \"low visual\" game\nconfigurations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06790v1", "cate": "cs.GR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06411", "title": "Hierarchical Multi-Stage Transformer Architecture for Context-Aware Temporal Action Localization", "authors": ["Hayat Ullah", "Arslan Munir", "Oliver Nina"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 6 figures,", "url": "http://arxiv.org/abs/2507.06411v1", "summary": "Inspired by the recent success of transformers and multi-stage architectures\nin video recognition and object detection domains. We thoroughly explore the\nrich spatio-temporal properties of transformers within a multi-stage\narchitecture paradigm for the temporal action localization (TAL) task. This\nexploration led to the development of a hierarchical multi-stage transformer\narchitecture called PCL-Former, where each subtask is handled by a dedicated\ntransformer module with a specialized loss function. Specifically, the\nProposal-Former identifies candidate segments in an untrimmed video that may\ncontain actions, the Classification-Former classifies the action categories\nwithin those segments, and the Localization-Former precisely predicts the\ntemporal boundaries (i.e., start and end) of the action instances. To evaluate\nthe performance of our method, we have conducted extensive experiments on three\nchallenging benchmark datasets: THUMOS-14, ActivityNet-1.3, and HACS Segments.\nWe also conducted detailed ablation experiments to assess the impact of each\nindividual module of our PCL-Former. The obtained quantitative results validate\nthe effectiveness of the proposed PCL-Former, outperforming state-of-the-art\nTAL approaches by 2.8%, 1.2%, and 4.8% on THUMOS14, ActivityNet-1.3, and HACS\ndatasets, respectively.", "comment": "17 pages, 6 figures,", "pdf_url": "http://arxiv.org/pdf/2507.06411v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06980", "title": "Are They All Good? Evaluating the Quality of CoTs in LLM-based Code Generation", "authors": ["Binquan Zhang", "Li Zhang", "Zhiwen Luo", "Yuxin Du", "Fang Liu", "Song Wang", "Lin Shi"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06980v1", "summary": "Large language models (LLMs) have demonstrated impressive performance in code\ngeneration, particularly when augmented with chain-of-thought (CoT) prompting\ntechniques. They break down requirements into intermediate reasoning steps,\nwhich act as design rationales to guide LLMs in writing code like human\nprogrammers. Thus, the quality of these steps is crucial for ensuring the\ncorrectness and reliability of the generated code. However, little is known\nabout the quality of CoT generated by LLMs. To what extent can we trust the\nthoughts generated by LLMs? How good are they? This paper empirically explores\nthe external and internal factors of why LLMs generate unsatisfactory CoTs by\nanalyzing 1,023 failed code samples on two widely used code generation\nbenchmarks. We also evaluate their impact on code generation performance by\nanalyzing 210 CoT-code pairs and refining the unsatisfied CoTs by prompting\nLLMs. Our study reveals three key findings: (1) External factors (53.60%), such\nas unclear requirements and lack of context, mainly affect CoT quality, while\ninternal factors (40.10%) stem from LLMs' misunderstanding prompts. (2) Even\nwhen CoTs are correct, 18.5% of the generated code contains errors due to\ninstruction-following issues; conversely, 11.90% of correct code is paired with\nflawed CoTs. (3) Refining low-quality CoTs is feasible, i.e., LLMs improve when\ngiven detailed problem descriptions. These findings highlight key challenges in\nCoT-based code generation and suggest directions for improving LLM reasoning\nand reliability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06980v1", "cate": "cs.SE", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07045", "title": "5C Prompt Contracts: A Minimalist, Creative-Friendly, Token-Efficient Design Framework for Individual and SME LLM Usage", "authors": ["Ugur Ari"], "categories": ["cs.SE", "cs.SI", "68T05", "I.2.7; I.2.6"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      5 pages, 5 tables. Includes comparative experimental results across OpenAI, Anthropic, DeepSeek, and Gemini LLMs", "url": "http://arxiv.org/abs/2507.07045v1", "summary": "The progression from traditional prompt engineering to a more rigorous\ndiscipline of prompt design marks a pivotal shift in human-LLM interaction. As\nLarge Language Models (LLMs) become increasingly embedded in mission-critical\napplications, there emerges a pressing need for frameworks that are not only\nexplicit and systematic but also minimal enough to remain practical and broadly\naccessible. While many existing approaches address prompt structuring through\nelaborate Domain-Specific Languages (DSLs) or multi-layered templates, such\nmethods can impose significant token and cognitive overhead, potentially\nconstraining the model's creative capacity. In this context, we propose the 5C\nPrompt Contract, a framework that distills prompt design into five intuitive\ncomponents: Character, Cause, Constraint, Contingency, and Calibration. This\nminimal cognitive schema explicitly integrates fallback and output optimization\ndirectives, fostering reliable, interpretable, and creatively flexible AI\ninteractions. Experimental results demonstrate that the 5C framework\nconsistently achieves superior input token efficiency while maintaining rich\nand consistent outputs across diverse LLM architectures (OpenAI, Anthropic,\nDeepSeek, and Gemini), making it particularly suited for individuals and\nSmall-to-Medium Enterprises (SMEs) with limited AI engineering resources.", "comment": "5 pages, 5 tables. Includes comparative experimental results across\n  OpenAI, Anthropic, DeepSeek, and Gemini LLMs", "pdf_url": "http://arxiv.org/pdf/2507.07045v1", "cate": "cs.SE", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06911", "title": "Beyond Connectivity: An Open Architecture for AI-RAN Convergence in 6G", "authors": ["Michele Polese", "Niloofar Mohamadi", "Salvatore D'Oro", "Tommaso Melodia"], "categories": ["cs.NI", "cs.AI", "eess.SP"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE for publication, copyright may change without notice. 8 pages, 6 figures", "url": "http://arxiv.org/abs/2507.06911v1", "summary": "The proliferation of data-intensive Artificial Intelligence (AI) applications\nat the network edge demands a fundamental shift in RAN design, from merely\nconsuming AI for network optimization, to actively enabling distributed AI\nworkloads. This paradigm shift presents a significant opportunity for network\noperators to monetize AI at the edge while leveraging existing infrastructure\ninvestments. To realize this vision, this article presents a novel converged\nO-RAN and AI-RAN architecture that unifies orchestration and management of both\ntelecommunications and AI workloads on shared infrastructure. The proposed\narchitecture extends the Open RAN principles of modularity, disaggregation, and\ncloud-nativeness to support heterogeneous AI deployments. We introduce two key\narchitectural innovations: (i) the AI-RAN Orchestrator, which extends the O-RAN\nService Management and Orchestration (SMO) to enable integrated resource and\nallocation across RAN and AI workloads; and (ii) AI-RAN sites that provide\ndistributed edge AI platforms with real-time processing capabilities. The\nproposed system supports flexible deployment options, allowing AI workloads to\nbe orchestrated with specific timing requirements (real-time or batch\nprocessing) and geographic targeting. The proposed architecture addresses the\norchestration requirements for managing heterogeneous workloads at different\ntime scales while maintaining open, standardized interfaces and multi-vendor\ninteroperability.", "comment": "Submitted to IEEE for publication, copyright may change without\n  notice. 8 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.06911v1", "cate": "cs.NI", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06064", "title": "Wrapless: The trustless lending protocol on top of Bitcoin", "authors": ["Oleksandr Kurbatov", "Kyrylo Baibula", "Yaroslava Chopa", "Sergey Kozlov", "Oleh Komendant", "Illia Dovhopolyi", "Dmitrii Kurbatov", "Zakhar Naumets", "Yuliia Aritkulova", "Pavel Kravchenko", "Volodymyr Dubinin", "Lasha Antadze", "Yaroslav Panasenko", "Mykhailo Velykodnyi"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06064v2", "summary": "This paper presents Wrapless -- a lending protocol that enables the\ncollateralization of bitcoins without requiring a trusted wrapping mechanism.\nThe protocol facilitates a \"loan channel\" on the Bitcoin blockchain, allowing\nbitcoins to be locked as collateral for loans issued on any blockchain that\nsupports Turing-complete smart contracts. The protocol is designed in a way\nthat makes it economically irrational for each involved party to manipulate the\nloan rules. There is still a significant research area to bring the protocol\ncloser to traditional AMM financial instruments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06064v2", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2507.06441", "title": "VisioPath: Vision-Language Enhanced Model Predictive Control for Safe Autonomous Navigation in Mixed Traffic", "authors": ["Shanting Wang", "Panagiotis Typaldos", "Chenjun Li", "Andreas A. Malikopoulos"], "categories": ["eess.SY", "cs.RO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06441v1", "summary": "In this paper, we introduce VisioPath, a novel framework combining\nvision-language models (VLMs) with model predictive control (MPC) to enable\nsafe autonomous driving in dynamic traffic environments. The proposed approach\nleverages a bird's-eye view video processing pipeline and zero-shot VLM\ncapabilities to obtain structured information about surrounding vehicles,\nincluding their positions, dimensions, and velocities. Using this rich\nperception output, we construct elliptical collision-avoidance potential fields\naround other traffic participants, which are seamlessly integrated into a\nfinite-horizon optimal control problem for trajectory planning. The resulting\ntrajectory optimization is solved via differential dynamic programming with an\nadaptive regularization scheme and is embedded in an event-triggered MPC loop.\nTo ensure collision-free motion, a safety verification layer is incorporated in\nthe framework that provides an assessment of potential unsafe trajectories.\nExtensive simulations in Simulation of Urban Mobility (SUMO) demonstrate that\nVisioPath outperforms conventional MPC baselines across multiple metrics. By\ncombining modern AI-driven perception with the rigorous foundation of optimal\ncontrol, VisioPath represents a significant step forward in safe trajectory\nplanning for complex traffic systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06441v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06434", "title": "Deprecating Benchmarks: Criteria and Framework", "authors": ["Ayrton San Joaquin", "Rokas Gipiškis", "Leon Staufer", "Ariel Gil"], "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      10 pages, 1 table. Accepted to the ICML 2025 Technical AI Governance Workshop", "url": "http://arxiv.org/abs/2507.06434v1", "summary": "As frontier artificial intelligence (AI) models rapidly advance, benchmarks\nare integral to comparing different models and measuring their progress in\ndifferent task-specific domains. However, there is a lack of guidance on when\nand how benchmarks should be deprecated once they cease to effectively perform\ntheir purpose. This risks benchmark scores over-valuing model capabilities, or\nworse, obscuring capabilities and safety-washing. Based on a review of\nbenchmarking practices, we propose criteria to decide when to fully or\npartially deprecate benchmarks, and a framework for deprecating benchmarks. Our\nwork aims to advance the state of benchmarking towards rigorous and quality\nevaluations, especially for frontier models, and our recommendations are aimed\nto benefit benchmark developers, benchmark users, AI governance actors (across\ngovernments, academia, and industry panels), and policy makers.", "comment": "10 pages, 1 table. Accepted to the ICML 2025 Technical AI Governance\n  Workshop", "pdf_url": "http://arxiv.org/pdf/2507.06434v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06466", "title": "Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models", "authors": ["Aaron Dharna", "Cong Lu", "Jeff Clune"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      67 pages, accepted to RLC 2025", "url": "http://arxiv.org/abs/2507.06466v1", "summary": "Multi-agent interactions have long fueled innovation, from natural\npredator-prey dynamics to the space race. Self-play (SP) algorithms try to\nharness these dynamics by pitting agents against ever-improving opponents,\nthereby creating an implicit curriculum toward learning high-quality solutions.\nHowever, SP often fails to produce diverse solutions and can get stuck in\nlocally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), a\nnew direction that leverages the code-generation capabilities and vast\nknowledge of foundation models (FMs) to overcome these challenges by leaping\nacross local optima in policy space. We propose a family of approaches: (1)\n\\textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agent\npolicies via competitive self-play; (2) \\textbf{Novelty-Search Self-Play\n(NSSP)} builds a diverse population of strategies, ignoring performance; and\n(3) the most promising variant, \\textbf{Quality-Diveristy Self-Play (QDSP)},\ncreates a diverse set of high-quality policies by combining the diversity of\nNSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, a\ncontinuous-control pursuer-evader setting, and in Gandalf, a simple AI safety\nsimulation in which an attacker tries to jailbreak an LLM's defenses. In Car\nTag, FMSPs explore a wide variety of reinforcement learning, tree search, and\nheuristic-based methods, to name just a few. In terms of discovered policy\nquality, \\ouralgo and vFMSP surpass strong human-designed strategies. In\nGandalf, FMSPs can successfully automatically red-team an LLM, breaking through\nand jailbreaking six different, progressively stronger levels of defense.\nFurthermore, FMSPs can automatically proceed to patch the discovered\nvulnerabilities. Overall, FMSPs represent a promising new research frontier of\nimproving self-play with foundation models, opening fresh paths toward more\ncreative and open-ended strategy discovery", "comment": "67 pages, accepted to RLC 2025", "pdf_url": "http://arxiv.org/pdf/2507.06466v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06878", "title": "Do AI tutors empower or enslave learners? Toward a critical use of AI in education", "authors": ["Lucile Favero", "Juan-Antonio Pérez-Ortiz", "Tanja Käser", "Nuria Oliver"], "categories": ["cs.CY", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Applications of Generative AI to support teaching and learning in Higher Education, co-located with AIED 2025. Palermo Italy", "url": "http://arxiv.org/abs/2507.06878v1", "summary": "The increasing integration of AI tools in education presents both\nopportunities and challenges, particularly regarding the development of the\nstudents' critical thinking skills. This position paper argues that while AI\ncan support learning, its unchecked use may lead to cognitive atrophy, loss of\nagency, emotional risks, and ethical concerns, ultimately undermining the core\ngoals of education. Drawing on cognitive science and pedagogy, the paper\nexplores how over-reliance on AI can disrupt meaningful learning, foster\ndependency and conformity, undermine the students' self-efficacy, academic\nintegrity, and well-being, and raise concerns about questionable privacy\npractices. It also highlights the importance of considering the students'\nperspectives and proposes actionable strategies to ensure that AI serves as a\nmeaningful support rather than a cognitive shortcut. The paper advocates for an\nintentional, transparent, and critically informed use of AI that empowers\nrather than diminishes the learner.", "comment": "Applications of Generative AI to support teaching and learning in\n  Higher Education, co-located with AIED 2025. Palermo Italy", "pdf_url": "http://arxiv.org/pdf/2507.06878v1", "cate": "cs.CY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06442", "title": "THOR: Thermal-guided Hand-Object Reasoning via Adaptive Vision Sampling", "authors": ["Soroush Shahi", "Farzad Shahabi", "Rama Nabulsi", "Glenn Fernandes", "Aggelos Katsaggelos", "Nabil Alshurafa"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06442v1", "summary": "Wearable cameras are increasingly used as an observational and interventional\ntool for human behaviors by providing detailed visual data of hand-related\nactivities. This data can be leveraged to facilitate memory recall for logging\nof behavior or timely interventions aimed at improving health. However,\ncontinuous processing of RGB images from these cameras consumes significant\npower impacting battery lifetime, generates a large volume of unnecessary video\ndata for post-processing, raises privacy concerns, and requires substantial\ncomputational resources for real-time analysis. We introduce THOR, a real-time\nadaptive spatio-temporal RGB frame sampling method that leverages thermal\nsensing to capture hand-object patches and classify them in real-time. We use\nlow-resolution thermal camera data to identify moments when a person switches\nfrom one hand-related activity to another, and adjust the RGB frame sampling\nrate by increasing it during activity transitions and reducing it during\nperiods of sustained activity. Additionally, we use the thermal cues from the\nhand to localize the region of interest (i.e., the hand-object interaction) in\neach RGB frame, allowing the system to crop and process only the necessary part\nof the image for activity recognition. We develop a wearable device to validate\nour method through an in-the-wild study with 14 participants and over 30\nactivities, and further evaluate it on Ego4D (923 participants across 9\ncountries, totaling 3,670 hours of video). Our results show that using only 3%\nof the original RGB video data, our method captures all the activity segments,\nand achieves hand-related activity recognition F1-score (95%) comparable to\nusing the entire RGB video (94%). Our work provides a more practical path for\nthe longitudinal use of wearable cameras to monitor hand-related activities and\nhealth-risk behaviors in real time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06442v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.07026", "title": "Exploring Fairness Interventions in Open Source Projects", "authors": ["Sadia Afrin Mim", "Fatema Tuz Zohra", "Justin Smith", "Brittany Johnson"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Revised version accepted at the 1st International Workshop on Fairness in Software Systems(SANER 2025)", "url": "http://arxiv.org/abs/2507.07026v1", "summary": "The deployment of biased machine learning (ML) models has resulted in adverse\neffects in crucial sectors such as criminal justice and healthcare. To address\nthese challenges, a diverse range of machine learning fairness interventions\nhave been developed, aiming to mitigate bias and promote the creation of more\nequitable models. Despite the growing availability of these interventions,\ntheir adoption in real-world applications remains limited, with many\npractitioners unaware of their existence. To address this gap, we\nsystematically identified and compiled a dataset of 62 open source fairness\ninterventions and identified active ones. We conducted an in-depth analysis of\ntheir specifications and features to uncover considerations that may drive\npractitioner preference and to identify the software interventions actively\nmaintained in the open source ecosystem. Our findings indicate that 32% of\nthese interventions have been actively maintained within the past year, and 50%\nof them offer both bias detection and mitigation capabilities, mostly during\ninprocessing.", "comment": "Revised version accepted at the 1st International Workshop on\n  Fairness in Software Systems(SANER 2025)", "pdf_url": "http://arxiv.org/pdf/2507.07026v1", "cate": "cs.SE", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07047", "title": "Exploring Public Perceptions of Generative AI in Libraries: A Social Media Analysis of X Discussions", "authors": ["Yuan Li", "Teja Mandaloju", "Haihua Chen"], "categories": ["cs.CY", "cs.HC", "cs.SI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07047v1", "summary": "This study investigates public perceptions of generative artificial\nintelligence (GenAI) in libraries through a large-scale analysis of posts on X\n(formerly Twitter). Using a mixed-method approach that combines temporal trend\nanalysis, sentiment classification, and social network analysis, this paper\nexplores how public discourse around GenAI and libraries has evolved over time,\nthe emotional tones that dominate the conversation, and the key users or\norganizations driving engagement. The findings reveal that discussions are\npredominantly negative in tone, with surges linked to concerns about ethics and\nintellectual property. Furthermore, social network analysis identifies both\ninstitutional authority and individual bridge users who facilitate cross-domain\nengagement. The results in this paper contribute to the growing body of\nliterature on GenAI in the library and GLAM (Galleries, Libraries, Archives,\nand Museums) sectors and offer a real-time, public-facing perspective on the\nemerging opportunities and concerns GenAI presents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07047v1", "cate": "cs.CY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06567", "title": "SlimCaching: Edge Caching of Mixture-of-Experts for Distributed Inference", "authors": ["Qian Chen", "Xianhao Chen", "Kaibin Huang"], "categories": ["cs.LG", "cs.DC", "cs.NI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      14 pages, 10 figures", "url": "http://arxiv.org/abs/2507.06567v1", "summary": "Mixture-of-Experts (MoE) models improve the scalability of large language\nmodels (LLMs) by activating only a small subset of relevant experts per input.\nHowever, the sheer number of expert networks in an MoE model introduces a\nsignificant storage burden for an edge device. To address this challenge, we\nconsider a scenario where experts are dispersed within an edge network for\ndistributed inference. Based on the popular Top-$K$ expert selection strategy,\nwe formulate a latency minimization problem by optimizing expert caching on\nedge servers under storage constraints. When $K=1$, the problem reduces to a\nmonotone submodular maximization problem with knapsack constraints, for which\nwe design a greedy-based algorithm with a $(1 - 1/e)$-approximation guarantee.\nFor the general case where $K\\geq1$, expert co-activation within the same MoE\nlayer introduces non-submodularity, causing greedy methods to be ineffective.\nTo tackle this issue, we propose a successive greedy decomposition method to\ndecompose the original problem into a series of subproblems, with each being\nsolved by a dynamic programming approach. Furthermore, we design an accelerated\nalgorithm based on the max-convolution technique to obtain the approximate\nsolution with a provable guarantee in polynomial time. Simulation results on\nvarious MoE models demonstrate that our method significantly reduces inference\nlatency compared to existing baselines.", "comment": "14 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.06567v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2004.08705", "title": "Protecting Classifiers From Attacks", "authors": ["Victor Gallego", "Roi Naveiro", "Alberto Redondo", "David Rios Insua", "Fabrizio Ruggeri"], "categories": ["stat.ML", "cs.CR", "cs.LG", "stat.CO"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Published in Statistical Science: this https URL", "url": "http://arxiv.org/abs/2004.08705v2", "summary": "In multiple domains such as malware detection, automated driving systems, or\nfraud detection, classification algorithms are susceptible to being attacked by\nmalicious agents willing to perturb the value of instance covariates to pursue\ncertain goals. Such problems pertain to the field of adversarial machine\nlearning and have been mainly dealt with, perhaps implicitly, through\ngame-theoretic ideas with strong underlying common knowledge assumptions. These\nare not realistic in numerous application domains in relation to security and\nbusiness competition. We present an alternative Bayesian decision theoretic\nframework that accounts for the uncertainty about the attacker's behavior using\nadversarial risk analysis concepts. In doing so, we also present core ideas in\nadversarial machine learning to a statistical audience. A key ingredient in our\nframework is the ability to sample from the distribution of originating\ninstances given the, possibly attacked, observed ones. We propose an initial\nprocedure based on approximate Bayesian computation usable during operations;\nwithin it, we simulate the attacker's problem taking into account our\nuncertainty about his elements. Large-scale problems require an alternative\nscalable approach implementable during the training stage. Globally, we are\nable to robustify statistical classification algorithms against malicious\nattacks.", "comment": "Published in Statistical Science:\n  https://projecteuclid.org/journals/statistical-science/volume-39/issue-3/Protecting-Classifiers-from-Attacks/10.1214/24-STS922.full", "pdf_url": "http://arxiv.org/pdf/2004.08705v2", "cate": "stat.ML", "date": "2020-04-18", "updated": "2025-07-09"}
{"id": "2507.06662", "title": "MK-Pose: Category-Level Object Pose Estimation via Multimodal-Based Keypoint Learning", "authors": ["Yifan Yang", "Peili Song", "Enfan Lan", "Dong Liu", "Jingtai Liu"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06662v1", "summary": "Category-level object pose estimation, which predicts the pose of objects\nwithin a known category without prior knowledge of individual instances, is\nessential in applications like warehouse automation and manufacturing. Existing\nmethods relying on RGB images or point cloud data often struggle with object\nocclusion and generalization across different instances and categories. This\npaper proposes a multimodal-based keypoint learning framework (MK-Pose) that\nintegrates RGB images, point clouds, and category-level textual descriptions.\nThe model uses a self-supervised keypoint detection module enhanced with\nattention-based query generation, soft heatmap matching and graph-based\nrelational modeling. Additionally, a graph-enhanced feature fusion module is\ndesigned to integrate local geometric information and global context. MK-Pose\nis evaluated on CAMERA25 and REAL275 dataset, and is further tested for\ncross-dataset capability on HouseCat6D dataset. The results demonstrate that\nMK-Pose outperforms existing state-of-the-art methods in both IoU and average\nprecision without shape priors. Codes will be released at\n\\href{https://github.com/yangyifanYYF/MK-Pose}{https://github.com/yangyifanYYF/MK-Pose}.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06662v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06459", "title": "EA: An Event Autoencoder for High-Speed Vision Sensing", "authors": ["Riadul Islam", "Joey Mulé", "Dhandeep Challagundla", "Shahmir Rizvi", "Sean Carson"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06459v1", "summary": "High-speed vision sensing is essential for real-time perception in\napplications such as robotics, autonomous vehicles, and industrial automation.\nTraditional frame-based vision systems suffer from motion blur, high latency,\nand redundant data processing, limiting their performance in dynamic\nenvironments. Event cameras, which capture asynchronous brightness changes at\nthe pixel level, offer a promising alternative but pose challenges in object\ndetection due to sparse and noisy event streams. To address this, we propose an\nevent autoencoder architecture that efficiently compresses and reconstructs\nevent data while preserving critical spatial and temporal features. The\nproposed model employs convolutional encoding and incorporates adaptive\nthreshold selection and a lightweight classifier to enhance recognition\naccuracy while reducing computational complexity. Experimental results on the\nexisting Smart Event Face Dataset (SEFD) demonstrate that our approach achieves\ncomparable accuracy to the YOLO-v4 model while utilizing up to $35.5\\times$\nfewer parameters. Implementations on embedded platforms, including Raspberry Pi\n4B and NVIDIA Jetson Nano, show high frame rates ranging from 8 FPS up to 44.8\nFPS. The proposed classifier exhibits up to 87.84x better FPS than the\nstate-of-the-art and significantly improves event-based vision performance,\nmaking it ideal for low-power, high-speed applications in real-time edge\ncomputing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06459v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06482", "title": "FedDifRC: Unlocking the Potential of Text-to-Image Diffusion Models in Heterogeneous Federated Learning", "authors": ["Huan Wang", "Haoran Li", "Huaming Chen", "Jun Yan", "Jiahua Shi", "Jun Shen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      19 Pages, ICCV 2025", "url": "http://arxiv.org/abs/2507.06482v1", "summary": "Federated learning aims at training models collaboratively across\nparticipants while protecting privacy. However, one major challenge for this\nparadigm is the data heterogeneity issue, where biased data preferences across\nmultiple clients, harming the model's convergence and performance. In this\npaper, we first introduce powerful diffusion models into the federated learning\nparadigm and show that diffusion representations are effective steers during\nfederated training. To explore the possibility of using diffusion\nrepresentations in handling data heterogeneity, we propose a novel\ndiffusion-inspired Federated paradigm with Diffusion Representation\nCollaboration, termed FedDifRC, leveraging meaningful guidance of diffusion\nmodels to mitigate data heterogeneity. The key idea is to construct text-driven\ndiffusion contrasting and noise-driven diffusion regularization, aiming to\nprovide abundant class-related semantic information and consistent convergence\nsignals. On the one hand, we exploit the conditional feedback from the\ndiffusion model for different text prompts to build a text-driven contrastive\nlearning strategy. On the other hand, we introduce a noise-driven consistency\nregularization to align local instances with diffusion denoising\nrepresentations, constraining the optimization region in the feature space. In\naddition, FedDifRC can be extended to a self-supervised scheme without relying\non any labeled data. We also provide a theoretical analysis for FedDifRC to\nensure convergence under non-convex objectives. The experiments on different\nscenarios validate the effectiveness of FedDifRC and the efficiency of crucial\ncomponents.", "comment": "19 Pages, ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.06482v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2409.12538", "title": "PersonaFlow: Designing LLM-Simulated Expert Perspectives for Enhanced Research Ideation", "authors": ["Yiren Liu", "Pranav Sharma", "Mehul Jitendra Oswal", "Haijun Xia", "Yun Huang"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted to DIS2025", "url": "http://arxiv.org/abs/2409.12538v2", "summary": "Generating interdisciplinary research ideas requires diverse domain\nexpertise, but access to timely feedback is often limited by the availability\nof experts. In this paper, we introduce PersonaFlow, a novel system designed to\nprovide multiple perspectives by using LLMs to simulate domain-specific\nexperts. Our user studies showed that the new design 1) increased the perceived\nrelevance and creativity of ideated research directions, and 2) promoted users'\ncritical thinking activities (e.g., interpretation, analysis, evaluation,\ninference, and self-regulation), without increasing their perceived cognitive\nload. Moreover, users' ability to customize expert profiles significantly\nimproved their sense of agency, which can potentially mitigate their\nover-reliance on AI. This work contributes to the design of intelligent systems\nthat augment creativity and collaboration, and provides design implications of\nusing customizable AI-simulated personas in domains within and beyond research\nideation.", "comment": "Accepted to DIS2025", "pdf_url": "http://arxiv.org/pdf/2409.12538v2", "cate": "cs.HC", "date": "2024-09-19", "updated": "2025-07-09"}
{"id": "2507.06485", "title": "Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning", "authors": ["Ziyang Wang", "Jaehong Yoon", "Shoubin Yu", "Md Mohaiminul Islam", "Gedas Bertasius", "Mohit Bansal"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      The first two authors contributed equally. Project page: this https URL", "url": "http://arxiv.org/abs/2507.06485v1", "summary": "Despite advances in reinforcement learning (RL)-based video reasoning with\nlarge language models (LLMs), data collection and finetuning remain significant\nchallenges. These methods often rely on large-scale supervised fine-tuning\n(SFT) with extensive video data and long Chain-of-Thought (CoT) annotations,\nmaking them costly and hard to scale. To address this, we present Video-RTS, a\nnew approach to improve video reasoning capability with drastically improved\ndata efficiency by combining data-efficient RL with a video-adaptive test-time\nscaling (TTS) strategy. Based on observations about the data scaling of RL\nsamples, we skip the resource-intensive SFT step and employ efficient pure-RL\ntraining with output-based rewards, requiring no additional annotations or\nextensive fine-tuning. Furthermore, to utilize computational resources more\nefficiently, we introduce a sparse-to-dense video TTS strategy that improves\ninference by iteratively adding frames based on output consistency. We validate\nour approach on multiple video reasoning benchmarks, showing that Video-RTS\nsurpasses existing video reasoning models by an average of 2.4% in accuracy\nusing only 3.6% training samples. For example, Video-RTS achieves a 4.2%\nimprovement on Video-Holmes, a recent and challenging video reasoning\nbenchmark, and a 2.6% improvement on MMVU. Notably, our pure RL training and\nadaptive video TTS offer complementary strengths, enabling Video-RTS's strong\nreasoning performance.", "comment": "The first two authors contributed equally. Project page:\n  https://sites.google.com/cs.unc.edu/videorts2025/", "pdf_url": "http://arxiv.org/pdf/2507.06485v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06452", "title": "gigiProfiler: Diagnosing Performance Issues by Uncovering Application Resource Bottlenecks", "authors": ["Yigong Hu", "Haodong Zheng", "Yicheng Liu", "Dedong Xie", "Youliang Huang", "Baris Kasikci"], "categories": ["cs.PF", "cs.SE"], "primary_category": "Subjects:       Performance (cs.PF)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06452v1", "summary": "Diagnosing performance bottlenecks in modern software is essential yet\nchallenging, particularly as applications become more complex and rely on\ncustom resource management policies. While traditional profilers effectively\nidentify execution bottlenecks by tracing system-level metrics, they fall short\nwhen it comes to application-level resource contention caused by waiting for\napplication-level events. In this work, we introduce OmniResource Profiling, a\nperformance analysis approach that integrates system-level and\napplication-level resource tracing to diagnose resource bottlenecks\ncomprehensively. gigiProfiler, our realization of OmniResource Profiling, uses\na hybrid LLM-static analysis approach to identify application-defined resources\noffline and analyze their impact on performance during buggy executions to\nuncover the performance bottleneck. gigiProfiler then samples and records\ncritical variables related to these bottleneck resources during buggy execution\nand compares their value with those from normal executions to identify the root\ncauses. We evaluated gigiProfiler on 12 real-world performance issues across\nfive applications. gigiProfiler accurately identified performance bottlenecks\nin all cases. gigiProfiler also successfully diagnosed the root causes of two\nnewly emerged, previously undiagnosed problems, with the findings confirmed by\ndevelopers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06452v1", "cate": "cs.PF", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2502.19952", "title": "Towards Collaborative Anti-Money Laundering Among Financial Institutions", "authors": ["Zhihua Tian", "Yuan Ding", "Wenjie Qu", "Xiang Yu", "Enchao Gong", "Jian Liu", "Kui Ren"], "categories": ["cs.SI", "cs.CY", "cs.LG"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      Accepted by International World Wide Web Conference (WWW) 2025", "url": "http://arxiv.org/abs/2502.19952v3", "summary": "Money laundering is the process that intends to legalize the income derived\nfrom illicit activities, thus facilitating their entry into the monetary flow\nof the economy without jeopardizing their source. It is crucial to identify\nsuch activities accurately and reliably in order to enforce anti-money\nlaundering (AML). Despite considerable efforts to AML, a large number of such\nactivities still go undetected. Rule-based methods were first introduced and\nare still widely used in current detection systems. With the rise of machine\nlearning, graph-based learning methods have gained prominence in detecting\nillicit accounts through the analysis of money transfer graphs. Nevertheless,\nthese methods generally assume that the transaction graph is centralized,\nwhereas in practice, money laundering activities usually span multiple\nfinancial institutions. Due to regulatory, legal, commercial, and customer\nprivacy concerns, institutions tend not to share data, restricting their\nutility in practical usage. In this paper, we propose the first algorithm that\nsupports performing AML over multiple institutions while protecting the\nsecurity and privacy of local data. To evaluate, we construct Alipay-ECB, a\nreal-world dataset comprising digital transactions from Alipay, the world's\nlargest mobile payment platform, alongside transactions from E-Commerce Bank\n(ECB). The dataset includes over 200 million accounts and 300 million\ntransactions, covering both intra-institution transactions and those between\nAlipay and ECB. This makes it the largest real-world transaction graph\navailable for analysis. The experimental results demonstrate that our methods\ncan effectively identify cross-institution money laundering subgroups.\nAdditionally, experiments on synthetic datasets also demonstrate that our\nmethod is efficient, requiring only a few minutes on datasets with millions of\ntransactions.", "comment": "Accepted by International World Wide Web Conference (WWW) 2025", "pdf_url": "http://arxiv.org/pdf/2502.19952v3", "cate": "cs.SI", "date": "2025-02-27", "updated": "2025-07-09"}
{"id": "2507.06827", "title": "Connecting the Unconnected -- Sentiment Analysis of Field Survey of Internet Connectivity in Emerging Economies", "authors": ["Dibakar Das", "Barath S Narayan", "Aarna Bhammar", "Jyotsna Bapat"], "categories": ["cs.CY", "cs.NI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06827v1", "summary": "Internet has significantly improved the quality of citizens across the world.\nThough the internet coverage is quite high, 40% of global population do not\nhave access to broadband internet. This paper presents an analysis of a field\nsurvey of population in some areas of Kathmandu, Nepal, an emerging economy.\nThis survey was triggered by intermittent severe congestion of internet in\ncertain areas of the city. People from three different areas were asked about\ntheir present experience of internet usage, its impact on their lives and their\naspirations for the future. Survey pointed to high speed, low cost, reliable\nand secure internet as a major aspiration of the respondents. Based on their\ninputs, this paper presents a sentiment analysis as well as demographic\ninformation. Keys insights from this analysis shows that overall sentiment to\nmost queries are positive. The variances of positive sentiments are high\nwhereas those for negative ones are low. Also, some correlations and clusters\nare observed among the attributes though no dominant component exists in the\ndata.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06827v1", "cate": "cs.CY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06578", "title": "On the Existence and Nonexistence of Splitter Sets", "authors": ["Zhiyu Yuan", "Rongquan Feng", "Gennian Ge"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06578v1", "summary": "In this paper, the existence of perfect and quasi-perfect splitter sets in\nfinite abelian groups is studied, motivated by their application in coding\ntheory for flash memory storage. For perfect splitter sets we view them as\nsplittings of $\\mathbb{Z}_n$, and using cyclotomic polynomials we derive a\ngeneral condition for the existence of such splittings under certain\ncircumstances. We further establish a relation between $B[-k, k](q)$ and\n$B[-(k-1), k+1](q)$ splitter sets, and give a necessary and sufficient\ncondition for the existence of perfect $B[-1, 5](q)$ splitter sets. Finally,\ntwo nonexistence results for quasi-perfect splitter sets are presented.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06578v1", "cate": "cs.IT", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2311.14136", "title": "A Blockchain Solution for Collaborative Machine Learning over IoT", "authors": ["Carlos Beis-Penedo", "Francisco Troncoso-Pastoriza", "Rebeca P. Díaz-Redondo", "Ana Fernández-Vilas", "Manuel Fernández-Veiga", "Martín González Soto"], "categories": ["cs.LG", "cs.CR", "cs.NI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages, 4 tables, 7 figures", "url": "http://arxiv.org/abs/2311.14136v2", "summary": "The rapid growth of Internet of Things (IoT) devices and applications has led\nto an increased demand for advanced analytics and machine learning techniques\ncapable of handling the challenges associated with data privacy, security, and\nscalability. Federated learning (FL) and blockchain technologies have emerged\nas promising approaches to address these challenges by enabling decentralized,\nsecure, and privacy-preserving model training on distributed data sources. In\nthis paper, we present a novel IoT solution that combines the incremental\nlearning vector quantization algorithm (XuILVQ) with Ethereum blockchain\ntechnology to facilitate secure and efficient data sharing, model training, and\nprototype storage in a distributed environment. Our proposed architecture\naddresses the shortcomings of existing blockchain-based FL solutions by\nreducing computational and communication overheads while maintaining data\nprivacy and security. We assess the performance of our system through a series\nof experiments, showcasing its potential to enhance the accuracy and efficiency\nof machine learning tasks in IoT settings.", "comment": "15 pages, 4 tables, 7 figures", "pdf_url": "http://arxiv.org/pdf/2311.14136v2", "cate": "cs.LG", "date": "2023-11-23", "updated": "2025-07-09"}
{"id": "2507.06687", "title": "StixelNExT++: Lightweight Monocular Scene Segmentation and Representation for Collective Perception", "authors": ["Marcel Vosshans", "Omar Ait-Aider", "Youcef Mezouar", "Markus Enzweiler"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06687v1", "summary": "This paper presents StixelNExT++, a novel approach to scene representation\nfor monocular perception systems. Building on the established Stixel\nrepresentation, our method infers 3D Stixels and enhances object segmentation\nby clustering smaller 3D Stixel units. The approach achieves high compression\nof scene information while remaining adaptable to point cloud and\nbird's-eye-view representations. Our lightweight neural network, trained on\nautomatically generated LiDAR-based ground truth, achieves real-time\nperformance with computation times as low as 10 ms per frame. Experimental\nresults on the Waymo dataset demonstrate competitive performance within a\n30-meter range, highlighting the potential of StixelNExT++ for collective\nperception in autonomous systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06687v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06479", "title": "Generative Lagrangian data assimilation for ocean dynamics under extreme sparsity", "authors": ["Niloofar Asefi", "Leonard Lupin-Jimenez", "Tianning Wu", "Ruoying He", "Ashesh Chattopadhyay"], "categories": ["physics.ao-ph", "cs.AI", "cs.LG", "math.DS", "nlin.CD"], "primary_category": "Subjects:       Atmospheric and Oceanic Physics (physics.ao-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06479v1", "summary": "Reconstructing ocean dynamics from observational data is fundamentally\nlimited by the sparse, irregular, and Lagrangian nature of spatial sampling,\nparticularly in subsurface and remote regions. This sparsity poses significant\nchallenges for forecasting key phenomena such as eddy shedding and rogue waves.\nTraditional data assimilation methods and deep learning models often struggle\nto recover mesoscale turbulence under such constraints. We leverage a deep\nlearning framework that combines neural operators with denoising diffusion\nprobabilistic models (DDPMs) to reconstruct high-resolution ocean states from\nextremely sparse Lagrangian observations. By conditioning the generative model\non neural operator outputs, the framework accurately captures small-scale,\nhigh-wavenumber dynamics even at $99\\%$ sparsity (for synthetic data) and\n$99.9\\%$ sparsity (for real satellite observations). We validate our method on\nbenchmark systems, synthetic float observations, and real satellite data,\ndemonstrating robust performance under severe spatial sampling limitations as\ncompared to other deep learning baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06479v1", "cate": "physics.ao-ph", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06502", "title": "MoFE-Time: Mixture of Frequency Domain Experts for Time-Series Forecasting Models", "authors": ["Yiwen Liu", "Chenyu Zhang", "Junjie Song", "Siqi Chen", "Sun Yin", "Zihan Wang", "Lingming Zeng", "Yuji Cao", "Junming Jiao"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06502v1", "summary": "As a prominent data modality task, time series forecasting plays a pivotal\nrole in diverse applications. With the remarkable advancements in Large\nLanguage Models (LLMs), the adoption of LLMs as the foundational architecture\nfor time series modeling has gained significant attention. Although existing\nmodels achieve some success, they rarely both model time and frequency\ncharacteristics in a pretraining-finetuning paradigm leading to suboptimal\nperformance in predictions of complex time series, which requires both modeling\nperiodicity and prior pattern knowledge of signals. We propose MoFE-Time, an\ninnovative time series forecasting model that integrates time and frequency\ndomain features within a Mixture of Experts (MoE) network. Moreover, we use the\npretraining-finetuning paradigm as our training framework to effectively\ntransfer prior pattern knowledge across pretraining and finetuning datasets\nwith different periodicity distributions. Our method introduces both frequency\nand time cells as experts after attention modules and leverages the MoE routing\nmechanism to construct multidimensional sparse representations of input\nsignals. In experiments on six public benchmarks, MoFE-Time has achieved new\nstate-of-the-art performance, reducing MSE and MAE by 6.95% and 6.02% compared\nto the representative methods Time-MoE. Beyond the existing evaluation\nbenchmarks, we have developed a proprietary dataset, NEV-sales, derived from\nreal-world business scenarios. Our method achieves outstanding results on this\ndataset, underscoring the effectiveness of the MoFE-Time model in practical\ncommercial applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06502v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2410.14879", "title": "Vital Insight: Assisting Experts' Context-Driven Sensemaking of Multi-modal Personal Tracking Data Using Visualization and Human-In-The-Loop LLM", "authors": ["Jiachen Li", "Xiwen Li", "Justin Steinberg", "Akshat Choube", "Bingsheng Yao", "Xuhai Xu", "Dakuo Wang", "Elizabeth Mynatt", "Varun Mishra"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.14879v3", "summary": "Passive tracking methods, such as phone and wearable sensing, have become\ndominant in monitoring human behaviors in modern ubiquitous computing studies.\nWhile there have been significant advances in machine-learning approaches to\ntranslate periods of raw sensor data to model momentary behaviors, (e.g.,\nphysical activity recognition), there still remains a significant gap in the\ntranslation of these sensing streams into meaningful, high-level, context-aware\ninsights that are required for various applications (e.g., summarizing an\nindividual's daily routine). To bridge this gap, experts often need to employ a\ncontext-driven sensemaking process in real-world studies to derive insights.\nThis process often requires manual effort and can be challenging even for\nexperienced researchers due to the complexity of human behaviors.\n  We conducted three rounds of user studies with 21 experts to explore\nsolutions to address challenges with sensemaking. We follow a human-centered\ndesign process to identify needs and design, iterate, build, and evaluate Vital\nInsight (VI), a novel, LLM-assisted, prototype system to enable\nhuman-in-the-loop inference (sensemaking) and visualizations of multi-modal\npassive sensing data from smartphones and wearables. Using the prototype as a\ntechnology probe, we observe experts' interactions with it and develop an\nexpert sensemaking model that explains how experts move between direct data\nrepresentations and AI-supported inferences to explore, question, and validate\ninsights. Through this iterative process, we also synthesize and discuss a list\nof design implications for the design of future AI-augmented visualization\nsystems to better assist experts' sensemaking processes in multi-modal health\nsensing data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.14879v3", "cate": "cs.HC", "date": "2024-10-18", "updated": "2025-07-09"}
{"id": "2507.06486", "title": "Mask6D: Masked Pose Priors For 6D Object Pose Estimation", "authors": ["Yuechen Xie", "Haobo Jiang", "Jin Xie"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICASSP 2024. 4 figures, 3 tables", "url": "http://arxiv.org/abs/2507.06486v1", "summary": "Robust 6D object pose estimation in cluttered or occluded conditions using\nmonocular RGB images remains a challenging task. One reason is that current\npose estimation networks struggle to extract discriminative, pose-aware\nfeatures using 2D feature backbones, especially when the available RGB\ninformation is limited due to target occlusion in cluttered scenes. To mitigate\nthis, we propose a novel pose estimation-specific pre-training strategy named\nMask6D. Our approach incorporates pose-aware 2D-3D correspondence maps and\nvisible mask maps as additional modal information, which is combined with RGB\nimages for the reconstruction-based model pre-training. Essentially, this 2D-3D\ncorrespondence maps a transformed 3D object model to 2D pixels, reflecting the\npose information of the target in camera coordinate system. Meanwhile, the\nintegrated visible mask map can effectively guide our model to disregard\ncluttered background information. In addition, an object-focused pre-training\nloss function is designed to further facilitate our network to remove the\nbackground interference. Finally, we fine-tune our pre-trained pose prior-aware\nnetwork via conventional pose training strategy to realize the reliable pose\nprediction. Extensive experiments verify that our method outperforms previous\nend-to-end pose estimation methods.", "comment": "Accepted at ICASSP 2024. 4 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.06486v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06584", "title": "Finding Compiler Bugs through Cross-Language Code Generator and Differential Testing", "authors": ["Qiong Feng", "Xiaotian Ma", "Ziyuan Feng", "Marat Akhin", "Wei Song", "Peng Liang"], "categories": ["cs.PL", "cs.SE"], "primary_category": "Subjects:       Programming Languages (cs.PL)", "pdf_link": null, "comments": "Comments:      The 40th ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA)", "url": "http://arxiv.org/abs/2507.06584v1", "summary": "Compilers play a central role in translating high-level code into executable\nprograms, making their correctness essential for ensuring code safety and\nreliability. While extensive research has focused on verifying the correctness\nof compilers for single-language compilation, the correctness of cross-language\ncompilation - which involves the interaction between two languages and their\nrespective compilers - remains largely unexplored. To fill this research gap,\nwe propose CrossLangFuzzer, a novel framework that introduces a universal\nintermediate representation (IR) for JVM-based languages and automatically\ngenerates cross-language test programs with diverse type parameters and complex\ninheritance structures. After generating the initial IR, CrossLangFuzzer\napplies three mutation techniques - LangShuffler, FunctionRemoval, and\nTypeChanger - to enhance program diversity. By evaluating both the original and\nmutated programs across multiple compiler versions, CrossLangFuzzer\nsuccessfully uncovered 10 confirmed bugs in the Kotlin compiler, 4 confirmed\nbugs in the Groovy compiler, 7 confirmed bugs in the Scala 3 compiler, 2\nconfirmed bugs in the Scala 2 compiler, and 1 confirmed bug in the Java\ncompiler. Among all mutators, TypeChanger is the most effective, detecting 11\nof the 24 compiler bugs. Furthermore, we analyze the symptoms and root causes\nof cross-compilation bugs, examining the respective responsibilities of\nlanguage compilers when incorrect behavior occurs during cross-language\ncompilation. To the best of our knowledge, this is the firstwork specifically\nfocused on identifying and diagnosing compiler bugs in cross-language\ncompilation scenarios. Our research helps to understand these challenges and\ncontributes to improving compiler correctness in multi-language environments.", "comment": "The 40th ACM SIGPLAN International Conference on Object-Oriented\n  Programming, Systems, Languages, and Applications (OOPSLA)", "pdf_url": "http://arxiv.org/pdf/2507.06584v1", "cate": "cs.PL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2503.18962", "title": "Representative Ranking for Deliberation in the Public Sphere", "authors": ["Manon Revel", "Smitha Milli", "Tyler Lu", "Jamelle Watson-Daniels", "Max Nickel"], "categories": ["cs.SI", "cs.LG"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.18962v2", "summary": "Online comment sections, such as those on news sites or social media, have\nthe potential to foster informal public deliberation, However, this potential\nis often undermined by the frequency of toxic or low-quality exchanges that\noccur in these settings. To combat this, platforms increasingly leverage\nalgorithmic ranking to facilitate higher-quality discussions, e.g., by using\ncivility classifiers or forms of prosocial ranking. Yet, these interventions\nmay also inadvertently reduce the visibility of legitimate viewpoints,\nundermining another key aspect of deliberation: representation of diverse\nviews. We seek to remedy this problem by introducing guarantees of\nrepresentation into these methods. In particular, we adopt the notion of\njustified representation (JR) from the social choice literature and incorporate\na JR constraint into the comment ranking setting. We find that enforcing JR\nleads to greater inclusion of diverse viewpoints while still being compatible\nwith optimizing for user engagement or other measures of conversational\nquality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.18962v2", "cate": "cs.SI", "date": "2025-03-19", "updated": "2025-07-09"}
{"id": "2503.23132", "title": "LAURA: LLM-Assisted UAV Routing for AoI Minimization", "authors": ["Bisheng Wei", "Ruichen Zhang", "Ruihong Jiang", "Mugen Peng", "Dusit Niyato"], "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.23132v2", "summary": "With the rapid growth of the low-altitude economy, there is increasing demand\nfor real-time data collection using UAV-assisted wireless sensor networks. This\npaper investigates the problem of minimizing the age of information (AoI) in\nUAV-assisted wireless sensor networks by optimizing the UAV flight routing. We\nformulate the AoI minimization task and propose a large language model\n(LLM)-assisted UAV routing algorithm (LAURA). LAURA employs an LLM as\nintelligent crossover operators within an evolutionary optimization framework\nto efficiently explore the solution space. Simulation results show that LAURA\noutperforms benchmark methods in reducing the maximum AoI, especially in\nscenarios with a large number of sensor nodes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.23132v2", "cate": "cs.NI", "date": "2025-03-29", "updated": "2025-07-09"}
{"id": "2507.06585", "title": "Hybrid Quantum Convolutional Neural Network-Aided Pilot Assignment in Cell-Free Massive MIMO Systems", "authors": ["Doan Hieu Nguyen", "Xuan Tung Nguyen", "Seon-Geun Jeong", "Trinh Van Chien", "Lajos Hanzo", "Won Joo Hwang"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      5 pages, 3 figures, and 2 tables. Accepted by IEEE TVT", "url": "http://arxiv.org/abs/2507.06585v1", "summary": "A sophisticated hybrid quantum convolutional neural network (HQCNN) is\nconceived for handling the pilot assignment task in cell-free massive MIMO\nsystems, while maximizing the total ergodic sum throughput. The existing\nmodel-based solutions found in the literature are inefficient and/or\ncomputationally demanding. Similarly, conventional deep neural networks may\nstruggle in the face of high-dimensional inputs, require complex architectures,\nand their convergence is slow due to training numerous hyperparameters. The\nproposed HQCNN leverages parameterized quantum circuits (PQCs) relying on\nsuperposition for enhanced feature extraction. Specifically, we exploit the\nsame PQC across all the convolutional layers for customizing the neural network\nand for accelerating the convergence. Our numerical results demonstrate that\nthe proposed HQCNN offers a total network throughput close to that of the\nexcessive-complexity exhaustive search and outperforms the state-of-the-art\nbenchmarks.", "comment": "5 pages, 3 figures, and 2 tables. Accepted by IEEE TVT", "pdf_url": "http://arxiv.org/pdf/2507.06585v1", "cate": "cs.IT", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2502.10390", "title": "(How) Can Transformers Predict Pseudo-Random Numbers?", "authors": ["Tao Tao", "Darshil Doshi", "Dayal Singh Kalra", "Tianyu He", "Maissam Barkeshli"], "categories": ["cs.LG", "cond-mat.dis-nn", "cs.CR", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025 (camera-ready version). 10+17 pages, 13+23 figures", "url": "http://arxiv.org/abs/2502.10390v2", "summary": "Transformers excel at discovering patterns in sequential data, yet their\nfundamental limitations and learning mechanisms remain crucial topics of\ninvestigation. In this paper, we study the ability of Transformers to learn\npseudo-random number sequences from linear congruential generators (LCGs),\ndefined by the recurrence relation $x_{t+1} = a x_t + c \\;\\mathrm{mod}\\; m$. We\nfind that with sufficient architectural capacity and training data variety,\nTransformers can perform in-context prediction of LCG sequences with unseen\nmoduli ($m$) and parameters ($a,c$). By analyzing the embedding layers and\nattention patterns, we uncover how Transformers develop algorithmic structures\nto learn these sequences in two scenarios of increasing complexity. First, we\ninvestigate how Transformers learn LCG sequences with unseen ($a, c$) but fixed\nmodulus; and demonstrate successful learning up to $m = 2^{32}$. We find that\nmodels learn to factorize $m$ and utilize digit-wise number representations to\nmake sequential predictions. In the second, more challenging scenario of unseen\nmoduli, we show that Transformers can generalize to unseen moduli up to\n$m_{\\text{test}} = 2^{16}$. In this case, the model employs a two-step\nstrategy: first estimating the unknown modulus from the context, then utilizing\nprime factorizations to generate predictions. For this task, we observe a sharp\ntransition in the accuracy at a critical depth $d= 3$. We also find that the\nnumber of in-context sequence elements needed to reach high accuracy scales\nsublinearly with the modulus.", "comment": "ICML 2025 (camera-ready version). 10+17 pages, 13+23 figures", "pdf_url": "http://arxiv.org/pdf/2502.10390v2", "cate": "cs.LG", "date": "2025-02-14", "updated": "2025-07-08"}
{"id": "2507.06719", "title": "A Neural Representation Framework with LLM-Driven Spatial Reasoning for Open-Vocabulary 3D Visual Grounding", "authors": ["Zhenyang Liu", "Sixiao Zheng", "Siyu Chen", "Cairong Zhao", "Longfei Liang", "Xiangyang Xue", "Yanwei Fu"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06719v1", "summary": "Open-vocabulary 3D visual grounding aims to localize target objects based on\nfree-form language queries, which is crucial for embodied AI applications such\nas autonomous navigation, robotics, and augmented reality. Learning 3D language\nfields through neural representations enables accurate understanding of 3D\nscenes from limited viewpoints and facilitates the localization of target\nobjects in complex environments. However, existing language field methods\nstruggle to accurately localize instances using spatial relations in language\nqueries, such as ``the book on the chair.'' This limitation mainly arises from\ninadequate reasoning about spatial relations in both language queries and 3D\nscenes. In this work, we propose SpatialReasoner, a novel neural\nrepresentation-based framework with large language model (LLM)-driven spatial\nreasoning that constructs a visual properties-enhanced hierarchical feature\nfield for open-vocabulary 3D visual grounding. To enable spatial reasoning in\nlanguage queries, SpatialReasoner fine-tunes an LLM to capture spatial\nrelations and explicitly infer instructions for the target, anchor, and spatial\nrelation. To enable spatial reasoning in 3D scenes, SpatialReasoner\nincorporates visual properties (opacity and color) to construct a hierarchical\nfeature field. This field represents language and instance features using\ndistilled CLIP features and masks extracted via the Segment Anything Model\n(SAM). The field is then queried using the inferred instructions in a\nhierarchical manner to localize the target 3D instance based on the spatial\nrelation in the language query. Extensive experiments show that our framework\ncan be seamlessly integrated into different neural representations,\noutperforming baseline models in 3D visual grounding while empowering their\nspatial reasoning capability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06719v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06507", "title": "GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models", "authors": ["Zhen Yang", "Haitao Lin", "Jiawei xue", "Ziji Zhang"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      8 pages, 3 figures", "url": "http://arxiv.org/abs/2507.06507v1", "summary": "In the past year, Generative Recommendations (GRs) have undergone substantial\nadvancements, especially in leveraging the powerful sequence modeling and\nreasoning capabilities of Large Language Models (LLMs) to enhance overall\nrecommendation performance. LLM-based GRs are forming a new paradigm that is\ndistinctly different from discriminative recommendations, showing strong\npotential to replace traditional recommendation systems heavily dependent on\ncomplex hand-crafted features. In this paper, we provide a comprehensive survey\naimed at facilitating further research of LLM-based GRs. Initially, we outline\nthe general preliminaries and application cases of LLM-based GRs. Subsequently,\nwe introduce the main considerations when LLM-based GRs are applied in real\nindustrial scenarios. Finally, we explore promising directions for LLM-based\nGRs. We hope that this survey contributes to the ongoing advancement of the GR\ndomain.", "comment": "8 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.06507v1", "cate": "cs.IR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06516", "title": "Instance-Wise Monotonic Calibration by Constrained Transformation", "authors": ["Yunrui Zhang", "Gustavo Batista", "Salil S. Kanhere"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to Conference on Uncertainty in Artificial Intelligence (UAI)", "url": "http://arxiv.org/abs/2507.06516v1", "summary": "Deep neural networks often produce miscalibrated probability estimates,\nleading to overconfident predictions. A common approach for calibration is\nfitting a post-hoc calibration map on unseen validation data that transforms\npredicted probabilities. A key desirable property of the calibration map is\ninstance-wise monotonicity (i.e., preserving the ranking of probability\noutputs). However, most existing post-hoc calibration methods do not guarantee\nmonotonicity. Previous monotonic approaches either use an under-parameterized\ncalibration map with limited expressive ability or rely on black-box neural\nnetworks, which lack interpretability and robustness. In this paper, we propose\na family of novel monotonic post-hoc calibration methods, which employs a\nconstrained calibration map parameterized linearly with respect to the number\nof classes. Our proposed approach ensures expressiveness, robustness, and\ninterpretability while preserving the relative ordering of the probability\noutput by formulating the proposed calibration map as a constrained\noptimization problem. Our proposed methods achieve state-of-the-art performance\nacross datasets with different deep neural network models, outperforming\nexisting calibration methods while being data and computation-efficient. Our\ncode is available at\nhttps://github.com/YunruiZhang/Calibration-by-Constrained-Transformation", "comment": "Accepted to Conference on Uncertainty in Artificial Intelligence\n  (UAI)", "pdf_url": "http://arxiv.org/pdf/2507.06516v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2506.23952", "title": "Autonomy by Design: Preserving Human Autonomy in AI Decision-Support", "authors": ["Stefan Buijsman", "Sarah E. Carter", "Juan Pablo Bermúdez"], "categories": ["cs.HC", "cs.AI", "cs.LG", "econ.GN", "q-fin.EC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23952v3", "summary": "AI systems increasingly support human decision-making across domains of\nprofessional, skill-based, and personal activity. While previous work has\nexamined how AI might affect human autonomy globally, the effects of AI on\ndomain-specific autonomy -- the capacity for self-governed action within\ndefined realms of skill or expertise -- remain understudied. We analyze how AI\ndecision-support systems affect two key components of domain-specific autonomy:\nskilled competence (the ability to make informed judgments within one's domain)\nand authentic value-formation (the capacity to form genuine domain-relevant\nvalues and preferences). By engaging with prior investigations and analyzing\nempirical cases across medical, financial, and educational domains, we\ndemonstrate how the absence of reliable failure indicators and the potential\nfor unconscious value shifts can erode domain-specific autonomy both\nimmediately and over time. We then develop a constructive framework for\nautonomy-preserving AI support systems. We propose specific socio-technical\ndesign patterns -- including careful role specification, implementation of\ndefeater mechanisms, and support for reflective practice -- that can help\nmaintain domain-specific autonomy while leveraging AI capabilities. This\nframework provides concrete guidance for developing AI systems that enhance\nrather than diminish human agency within specialized domains of action.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23952v3", "cate": "cs.HC", "date": "2025-06-30", "updated": "2025-07-09"}
{"id": "2507.06510", "title": "Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection", "authors": ["Yupeng Hu", "Changxing Ding", "Chang Sun", "Shaoli Huang", "Xiangmin Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.06510v1", "summary": "Open vocabulary Human-Object Interaction (HOI) detection is a challenging\ntask that detects all <human, verb, object> triplets of interest in an image,\neven those that are not pre-defined in the training set. Existing approaches\ntypically rely on output features generated by large Vision-Language Models\n(VLMs) to enhance the generalization ability of interaction representations.\nHowever, the visual features produced by VLMs are holistic and coarse-grained,\nwhich contradicts the nature of detection tasks. To address this issue, we\npropose a novel Bilateral Collaboration framework for open vocabulary HOI\ndetection (BC-HOI). This framework includes an Attention Bias Guidance (ABG)\ncomponent, which guides the VLM to produce fine-grained instance-level\ninteraction features according to the attention bias provided by the HOI\ndetector. It also includes a Large Language Model (LLM)-based Supervision\nGuidance (LSG) component, which provides fine-grained token-level supervision\nfor the HOI detector by the LLM component of the VLM. LSG enhances the ability\nof ABG to generate high-quality attention bias. We conduct extensive\nexperiments on two popular benchmarks: HICO-DET and V-COCO, consistently\nachieving superior performance in the open vocabulary and closed settings. The\ncode will be released in Github.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.06510v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06907", "title": "Robust and Safe Traffic Sign Recognition using N-version with Weighted Voting", "authors": ["Linyun Gao", "Qiang Wen", "Fumio Machida"], "categories": ["cs.LG", "cs.SE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      27 pages including appendix, 1 figure", "url": "http://arxiv.org/abs/2507.06907v1", "summary": "Autonomous driving is rapidly advancing as a key application of machine\nlearning, yet ensuring the safety of these systems remains a critical\nchallenge. Traffic sign recognition, an essential component of autonomous\nvehicles, is particularly vulnerable to adversarial attacks that can compromise\ndriving safety. In this paper, we propose an N-version machine learning (NVML)\nframework that integrates a safety-aware weighted soft voting mechanism. Our\napproach utilizes Failure Mode and Effects Analysis (FMEA) to assess potential\nsafety risks and assign dynamic, safety-aware weights to the ensemble outputs.\nWe evaluate the robustness of three-version NVML systems employing various\nvoting mechanisms against adversarial samples generated using the Fast Gradient\nSign Method (FGSM) and Projected Gradient Descent (PGD) attacks. Experimental\nresults demonstrate that our NVML approach significantly enhances the\nrobustness and safety of traffic sign recognition systems under adversarial\nconditions.", "comment": "27 pages including appendix, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.06907v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2301.12743", "title": "Displacement and disconnection: the impact of violence on migration networks and highway traffic in Mexico", "authors": ["Michele Coscia", "Roxana Gutiérrez-Romero"], "categories": ["physics.soc-ph", "cs.SI"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2301.12743v2", "summary": "We examine how violence affects migration flows and, crucially, how it\nreshapes the strength of migration networks -- measured by the intensity of\nmigration between areas, accounting for the fact that some routes become more\nprominent or fade over time -- an aspect traditional studies overlook. Using a\nnovel network algorithm and Mexican census data from 2005 to 2020, we first\nquantify changes in the strength of domestic and international migration\nnetworks across all Mexican municipalities. We exploit variation in local\nhomicide rates, using exogenous fuel price increases and municipalities'\nproximity to oil pipelines as instruments, to estimate the causal impact of\nviolence on migration. During our study period, following intensified\ngovernment crackdowns on drug trafficking organizations, many criminal groups\nfragmented and turned toward large-scale oil theft, driving sharp increases in\nviolence in areas with oil pipelines, particularly when fuel prices rose. The\nfindings show that rising violence increased emigration flows, predominantly\nwithin Mexico, and strengthened the intensity of emigration networks both\ndomestically and toward the United States. Although violent municipalities\ncontinued to receive new residents, the rise in emigration was larger.\nIncreasing homicide rates led to at least an additional 1.12 million people\nemigrating domestically and 50,200 fewer Mexicans returning from the United\nStates. Violence also eroded regional connectivity, causing a long-term decline\nin daily vehicle traffic on highways linking violent areas to the rest of the\ncountry.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2301.12743v2", "cate": "physics.soc-ph", "date": "2023-01-30", "updated": "2025-07-09"}
{"id": "2506.19030", "title": "WiLLM: an Open Framework for LLM Services over Wireless Systems", "authors": ["Boyi Liu", "Yongguang Lu", "Jianguo Zhao", "Qiang Yang", "Wen Wu", "Lin Chen", "Jagmohan Chauhan", "Jun Zhang"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.19030v2", "summary": "Large Language Model (LLM) services fundamentally differ from traditional\nDeep Neural Network (DNN) applications in wireless networks. We identify three\ncritical distinctions: (1) unlike traditional DNNs with unidirectional data\nflows, LLM's multimodal interactions create bidirectional heavy loads with\ncontrasting bottlenecks, requiring direction-aware resource scheduling; (2)\nwhile traditional DNNs exhibit fixed computational patterns, LLM's highly\nvariable inference times interact complexly with network slicing, causing\ndynamic bottleneck migration; and (3) in contrast to predictable DNN traffic,\nLLM's token streams demonstrate unprecedented burstiness and state\ndependencies. These insights motivate WiLLM, the first open-source framework,\nimplemented as a wireless platform, for LLM service research. Built on\nOpenAirInterface, WiLLM introduces several technical innovations: dynamic slice\ncompatibility, universal UE compatibility through application-layer tunneling,\nmulti-UE multi-slice scheduling, dual-mode resource allocation, and cross-layer\nAPIs. In addition, WiLLM eliminates the need for specialized wireless\nexpertise, enabling researchers and developers to experiment with LLM services\nover realistic cellular networks. We demonstrate the platform's capabilities\nthrough a smart glasses case study and provide a comprehensive dataset of \\~1.6\nmillion synchronized measurements. The complete system, dataset, and appendix\nare available at https://openwillm.github.io.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.19030v2", "cate": "cs.NI", "date": "2025-06-23", "updated": "2025-07-09"}
{"id": "2507.06589", "title": "Soft Robotics-Inspired Flexible Antenna Arrays", "authors": ["Elio Faddoul", "Andreas Nicolaides", "Konstantinos Ntougias", "Ioannis Krikidis"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06589v1", "summary": "In this work, a novel soft continuum robot-inspired antenna array is\nproposed, featuring tentacle-like structures with multiple antenna elements.\nThe proposed array achieves reconfigurability through continuous deformation of\nits geometry, in contrast to reconfigurable antennas which incur a per-element\ncontrol. More specifically, the deformation is modeled by amplitude and spatial\nfrequency parameters. We consider a multi-user multiple-input single-output\ndownlink system, whereby the optimal deformation parameters are found to\nmaximize the sum rate in the network. A successive convex approximation method\nis adopted to solve the problem. Numerical results show that the proposed\ndeformable array significantly outperforms fixed geometry and per-element\nreconfigurable arrays in sum rate, demonstrating the benefits of\nstructure-level flexibility for next-generation antenna arrays.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06589v1", "cate": "cs.IT", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2502.16903", "title": "GuidedBench: Measuring and Mitigating the Evaluation Discrepancies of In-the-wild LLM Jailbreak Methods", "authors": ["Ruixuan Huang", "Xunguang Wang", "Zongjie Li", "Daoyuan Wu", "Shuai Wang"], "categories": ["cs.CL", "cs.CR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Homepage: this https URL", "url": "http://arxiv.org/abs/2502.16903v2", "summary": "Despite the growing interest in jailbreak methods as an effective red-teaming\ntool for building safe and responsible large language models (LLMs), flawed\nevaluation system designs have led to significant discrepancies in their\neffectiveness assessments. We conduct a systematic measurement study based on\n37 jailbreak studies since 2022, focusing on both the methods and the\nevaluation systems they employ. We find that existing evaluation systems lack\ncase-specific criteria, resulting in misleading conclusions about their\neffectiveness and safety implications. This paper advocates a shift to a more\nnuanced, case-by-case evaluation paradigm. We introduce GuidedBench, a novel\nbenchmark comprising a curated harmful question dataset, detailed case-by-case\nevaluation guidelines and an evaluation system integrated with these guidelines\n-- GuidedEval. Experiments demonstrate that GuidedBench offers more accurate\nmeasurements of jailbreak performance, enabling meaningful comparisons across\nmethods and uncovering new insights overlooked in previous evaluations.\nGuidedEval reduces inter-evaluator variance by at least 76.03\\%. Furthermore,\nwe observe that incorporating guidelines can enhance the effectiveness of\njailbreak methods themselves, offering new insights into both attack strategies\nand evaluation paradigms.", "comment": "Homepage: https://sproutnan.github.io/AI-Safety_Benchmark/", "pdf_url": "http://arxiv.org/pdf/2502.16903v2", "cate": "cs.CL", "date": "2025-02-24", "updated": "2025-07-09"}
{"id": "2507.06971", "title": "Hallucinating 360°: Panoramic Street-View Generation via Local Scenes Diffusion and Probabilistic Prompting", "authors": ["Fei Teng", "Kai Luo", "Sheng Wu", "Siyu Li", "Pujun Guo", "Jiale Wei", "Kunyu Peng", "Jiaming Zhang", "Kailun Yang"], "categories": ["cs.CV", "cs.RO", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      The source code will be publicly available at this https URL", "url": "http://arxiv.org/abs/2507.06971v1", "summary": "Panoramic perception holds significant potential for autonomous driving,\nenabling vehicles to acquire a comprehensive 360{\\deg} surround view in a\nsingle shot. However, autonomous driving is a data-driven task. Complete\npanoramic data acquisition requires complex sampling systems and annotation\npipelines, which are time-consuming and labor-intensive. Although existing\nstreet view generation models have demonstrated strong data regeneration\ncapabilities, they can only learn from the fixed data distribution of existing\ndatasets and cannot achieve high-quality, controllable panoramic generation. In\nthis paper, we propose the first panoramic generation method Percep360 for\nautonomous driving. Percep360 enables coherent generation of panoramic data\nwith control signals based on the stitched panoramic data. Percep360 focuses on\ntwo key aspects: coherence and controllability. Specifically, to overcome the\ninherent information loss caused by the pinhole sampling process, we propose\nthe Local Scenes Diffusion Method (LSDM). LSDM reformulates the panorama\ngeneration as a spatially continuous diffusion process, bridging the gaps\nbetween different data distributions. Additionally, to achieve the controllable\ngeneration of panoramic images, we propose a Probabilistic Prompting Method\n(PPM). PPM dynamically selects the most relevant control cues, enabling\ncontrollable panoramic image generation. We evaluate the effectiveness of the\ngenerated images from three perspectives: image quality assessment (i.e.,\nno-reference and with reference), controllability, and their utility in\nreal-world Bird's Eye View (BEV) segmentation. Notably, the generated data\nconsistently outperforms the original stitched images in no-reference quality\nmetrics and enhances downstream perception models. The source code will be\npublicly available at https://github.com/Bryant-Teng/Percep360.", "comment": "The source code will be publicly available at\n  https://github.com/Bryant-Teng/Percep360", "pdf_url": "http://arxiv.org/pdf/2507.06971v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06512", "title": "Towards LLM-based Root Cause Analysis of Hardware Design Failures", "authors": ["Siyu Qiu", "Muzhi Wang", "Raheel Afsharmazayejani", "Mohammad Moradi Shahmiri", "Benjamin Tan", "Hammond Pearce"], "categories": ["cs.AR", "cs.AI"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      6 pages. Accepted for publication in IEEE COINS 2025 Special Session on LLMs for EDA and Security", "url": "http://arxiv.org/abs/2507.06512v1", "summary": "With advances in large language models (LLMs), new opportunities have emerged\nto develop tools that support the digital hardware design process. In this\nwork, we explore how LLMs can assist with explaining the root cause of design\nissues and bugs that are revealed during synthesis and simulation, a necessary\nmilestone on the pathway towards widespread use of LLMs in the hardware design\nprocess and for hardware security analysis. We find promising results: for our\ncorpus of 34 different buggy scenarios, OpenAI's o3-mini reasoning model\nreached a correct determination 100% of the time under pass@5 scoring, with\nother state of the art models and configurations usually achieving more than\n80% performance and more than 90% when assisted with retrieval-augmented\ngeneration.", "comment": "6 pages. Accepted for publication in IEEE COINS 2025 Special Session\n  on LLMs for EDA and Security", "pdf_url": "http://arxiv.org/pdf/2507.06512v1", "cate": "cs.AR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06525", "title": "AdaDPIGU: Differentially Private SGD with Adaptive Clipping and Importance-Based Gradient Updates for Deep Neural Networks", "authors": ["Huiqi Zhang", "Fang Xie"], "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06525v1", "summary": "Differential privacy has been proven effective for stochastic gradient\ndescent; however, existing methods often suffer from performance degradation in\nhigh-dimensional settings, as the scale of injected noise increases with\ndimensionality. To tackle this challenge, we propose AdaDPIGU--a new\ndifferentially private SGD framework with importance-based gradient updates\ntailored for deep neural networks. In the pretraining stage, we apply a\ndifferentially private Gaussian mechanism to estimate the importance of each\nparameter while preserving privacy. During the gradient update phase, we prune\nlow-importance coordinates and introduce a coordinate-wise adaptive clipping\nmechanism, enabling sparse and noise-efficient gradient updates. Theoretically,\nwe prove that AdaDPIGU satisfies $(\\varepsilon, \\delta)$-differential privacy\nand retains convergence guarantees. Extensive experiments on standard\nbenchmarks validate the effectiveness of AdaDPIGU. All results are reported\nunder a fixed retention ratio of 60%. On MNIST, our method achieves a test\naccuracy of 99.12% under a privacy budget of $\\epsilon = 8$, nearly matching\nthe non-private model. Remarkably, on CIFAR-10, it attains 73.21% accuracy at\n$\\epsilon = 4$, outperforming the non-private baseline of 71.12%, demonstrating\nthat adaptive sparsification can enhance both privacy and utility.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06525v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2410.02091", "title": "The Impact of Generative AI on Collaborative Open-Source Software Development: Evidence from GitHub Copilot", "authors": ["Fangchen Song", "Ashish Agarwal", "Wen Wen"], "categories": ["cs.SE", "cs.AI", "cs.HC", "econ.GN", "q-fin.EC"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.02091v2", "summary": "Generative artificial intelligence (AI) enables automated content production,\nincluding coding in software development, which can significantly influence\ndeveloper participation and performance. To explore its impact on collaborative\nopen-source software (OSS) development, we investigate the role of GitHub\nCopilot, a generative AI pair programmer, in OSS development where multiple\ndistributed developers voluntarily collaborate. Using GitHub's proprietary\nCopilot usage data, combined with public OSS repository data obtained from\nGitHub, we find that Copilot use increases project-level code contributions by\n5.9%. This gain is driven by a 2.1% increase in individual code contributions\nand a 3.4% rise in developer coding participation. However, these benefits come\nat a cost as coordination time for code integration increases by 8% due to more\ncode discussions enabled by AI pair programmers. This reveals an important\ntradeoff: While AI expands who can contribute and how much they contribute, it\nslows coordination in collective development efforts. Despite this tension, the\ncombined effect of these two competing forces remains positive, indicating a\nnet gain in overall project-level productivity from using AI pair programmers.\nInterestingly, we also find the effects differ across developer roles.\nPeripheral developers show relatively smaller gains in project-level code\ncontributions and face a higher increase in coordination time than core\ndevelopers, likely due to the difference in their project familiarity. In\nsummary, our study underscores the dual role of AI pair programmers in\naffecting project-level code contributions and coordination time in OSS\ndevelopment. Our findings on the differential effects between core and\nperipheral developers also provide important implications for the structure of\nOSS communities in the long run.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.02091v2", "cate": "cs.SE", "date": "2024-10-02", "updated": "2025-07-08"}
{"id": "2507.06513", "title": "What Demands Attention in Urban Street Scenes? From Scene Understanding towards Road Safety: A Survey of Vision-driven Datasets and Studies", "authors": ["Yaoqi Huang", "Julie Stephany Berrio", "Mao Shan", "Stewart Worrall"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      45 pages, 52 figures, 2 large tables (divided into 5), 73 datatsets, 35 tasks", "url": "http://arxiv.org/abs/2507.06513v1", "summary": "Advances in vision-based sensors and computer vision algorithms have\nsignificantly improved the analysis and understanding of traffic scenarios. To\nfacilitate the use of these improvements for road safety, this survey\nsystematically categorizes the critical elements that demand attention in\ntraffic scenarios and comprehensively analyzes available vision-driven tasks\nand datasets. Compared to existing surveys that focus on isolated domains, our\ntaxonomy categorizes attention-worthy traffic entities into two main groups\nthat are anomalies and normal but critical entities, integrating ten categories\nand twenty subclasses. It establishes connections between inherently related\nfields and provides a unified analytical framework. Our survey highlights the\nanalysis of 35 vision-driven tasks and comprehensive examinations and\nvisualizations of 73 available datasets based on the proposed taxonomy. The\ncross-domain investigation covers the pros and cons of each benchmark with the\naim of providing information on standards unification and resource\noptimization. Our article concludes with a systematic discussion of the\nexisting weaknesses, underlining the potential effects and promising solutions\nfrom various perspectives. The integrated taxonomy, comprehensive analysis, and\nrecapitulatory tables serve as valuable contributions to this rapidly evolving\nfield by providing researchers with a holistic overview, guiding strategic\nresource selection, and highlighting critical research gaps.", "comment": "45 pages, 52 figures, 2 large tables (divided into 5), 73 datatsets,\n  35 tasks", "pdf_url": "http://arxiv.org/pdf/2507.06513v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06990", "title": "Enhancing Quantum Software Development Process with Experiment Tracking", "authors": ["Mahee Gamage", "Otso Kinanen", "Jake Muff", "Vlad Stirbu"], "categories": ["quant-ph", "cs.SE"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06990v1", "summary": "As quantum computing advances from theoretical promise to experimental\nreality, the need for rigorous experiment tracking becomes critical. Drawing\ninspiration from best practices in machine learning (ML) and artificial\nintelligence (AI), we argue that reproducibility, scalability, and\ncollaboration in quantum research can benefit significantly from structured\ntracking workflows. This paper explores the application of MLflow in quantum\nresearch, illustrating how it enables better development practices, experiment\nreproducibility, decision making, and cross-domain integration in an\nincreasingly hybrid classical-quantum landscape.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06990v1", "cate": "quant-ph", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06635", "title": "On the Convergence Speed of Spatially Coupled LDPC Ensembles Under Window Decoding", "authors": ["Qingqing Peng", "Dongxu Chang", "Guanghui Wang", "Guiying Yan"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      spatially coupled LDPC ensembles, window decoding, density evolution, convergence speed", "url": "http://arxiv.org/abs/2507.06635v1", "summary": "It is known that windowed decoding (WD) can effectively balance the\nperformance and complexity of spatially coupled low-density parity-check (LDPC)\ncodes. In this study, we show that information can propagate in a wave-like\nmanner at a constant speed under WD. Additionally, we provide an upper bound\nfor the information propagation speed on the binary erasure channel, which can\nassist in designing the number of iterations required within each window.", "comment": "spatially coupled LDPC ensembles, window decoding, density evolution,\n  convergence speed", "pdf_url": "http://arxiv.org/pdf/2507.06635v1", "cate": "cs.IT", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06376", "title": "SLDB: An End-To-End Heterogeneous System-on-Chip Benchmark Suite for LLM-Aided Design", "authors": ["Elisavet Lydia Alvanaki", "Kevin Lee", "Luca P. Carloni"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06376v1", "summary": "Over the last few years, Large Language Models (LLMs) have emerged as a\nvaluable tool for Electronic Design Automation (EDA). State-of-the-art research\nin LLM-aided design has demonstrated the ability of LLMs to generate\nsyntactically correct RTL code, showcasing encouraging prospects for\nintegrating AI into the hardware design process. A key enabler of these\nadvancements is the availability of high-quality benchmarks to evaluate new\napproaches. However, existing datasets and benchmarks fall short of\nsystem-level design, as they focus primarily on component-level information and\nlow-complexity designs. To address this gap, we introduce the System-Level\nDesign Benchmark (SLDB), a dataset tailored for evaluating LLMs in system-level\nintegration and configuration tasks. SLDB includes a curated benchmark suite of\n10 baseline SoC designs, whose components can be combined into an exponential\nnumber of distinct tile-based SoCs through a synthetic library. The dataset\nprovides full SoC configurations, accelerator integration code, communication\nparameters, and accelerator-aware system configurations, along with\ntesting-application code, compatible with the ESP platform[1].", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06376v1", "cate": "cs.AR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2503.09446", "title": "Sparse Autoencoder as a Zero-Shot Classifier for Concept Erasing in Text-to-Image Diffusion Models", "authors": ["Zhihua Tian", "Sirun Nan", "Ming Xu", "Shengfang Zhai", "Wenjie Qu", "Jian Liu", "Ruoxi Jia", "Jiaheng Zhang"], "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      25 pages", "url": "http://arxiv.org/abs/2503.09446v3", "summary": "Text-to-image (T2I) diffusion models have achieved remarkable progress in\ngenerating high-quality images but also raise people's concerns about\ngenerating harmful or misleading content. While extensive approaches have been\nproposed to erase unwanted concepts without requiring retraining from scratch,\nthey inadvertently degrade performance on normal generation tasks. In this\nwork, we propose Interpret then Deactivate (ItD), a novel framework to enable\nprecise concept removal in T2I diffusion models while preserving overall\nperformance. ItD first employs a sparse autoencoder (SAE) to interpret each\nconcept as a combination of multiple features. By permanently deactivating the\nspecific features associated with target concepts, we repurpose SAE as a\nzero-shot classifier that identifies whether the input prompt includes target\nconcepts, allowing selective concept erasure in diffusion models. Moreover, we\ndemonstrate that ItD can be easily extended to erase multiple concepts without\nrequiring further training. Comprehensive experiments across celebrity\nidentities, artistic styles, and explicit content demonstrate ItD's\neffectiveness in eliminating targeted concepts without interfering with normal\nconcept generation. Additionally, ItD is also robust against adversarial\nprompts designed to circumvent content filters. Code is available at:\nhttps://github.com/NANSirun/Interpret-then-deactivate.", "comment": "25 pages", "pdf_url": "http://arxiv.org/pdf/2503.09446v3", "cate": "cs.CV", "date": "2025-03-12", "updated": "2025-07-09"}
{"id": "2507.07012", "title": "When Context Is Not Enough: Modeling Unexplained Variability in Car-Following Behavior", "authors": ["Chengyuan Zhang", "Zhengbing He", "Cathy Wu", "Lijun Sun"], "categories": ["stat.AP", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Applications (stat.AP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07012v1", "summary": "Modeling car-following behavior is fundamental to microscopic traffic\nsimulation, yet traditional deterministic models often fail to capture the full\nextent of variability and unpredictability in human driving. While many modern\napproaches incorporate context-aware inputs (e.g., spacing, speed, relative\nspeed), they frequently overlook structured stochasticity that arises from\nlatent driver intentions, perception errors, and memory effects -- factors that\nare not directly observable from context alone. To fill the gap, this study\nintroduces an interpretable stochastic modeling framework that captures not\nonly context-dependent dynamics but also residual variability beyond what\ncontext can explain. Leveraging deep neural networks integrated with\nnonstationary Gaussian processes (GPs), our model employs a scenario-adaptive\nGibbs kernel to learn dynamic temporal correlations in acceleration decisions,\nwhere the strength and duration of correlations between acceleration decisions\nevolve with the driving context. This formulation enables a principled,\ndata-driven quantification of uncertainty in acceleration, speed, and spacing,\ngrounded in both observable context and latent behavioral variability.\nComprehensive experiments on the naturalistic vehicle trajectory dataset\ncollected from the German highway, i.e., the HighD dataset, demonstrate that\nthe proposed stochastic simulation method within this framework surpasses\nconventional methods in both predictive performance and interpretable\nuncertainty quantification. The integration of interpretability and accuracy\nmakes this framework a promising tool for traffic analysis and safety-critical\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07012v1", "cate": "stat.AP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06558", "title": "The Primacy of Magnitude in Low-Rank Adaptation", "authors": ["Zicheng Zhang", "Haoran Li", "Yifeng Zhang", "Guoqiang Gong", "Jiaxing Wang", "Pengzhang Liu", "Qixia Jiang", "Junxing Hu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06558v1", "summary": "Low-Rank Adaptation (LoRA) offers a parameter-efficient paradigm for tuning\nlarge models. While recent spectral initialization methods improve convergence\nand performance over the naive \"Noise & Zeros\" scheme, their extra\ncomputational and storage overhead undermines efficiency. In this paper, we\nestablish update magnitude as the fundamental driver of LoRA performance and\npropose LoRAM, a magnitude-driven \"Basis & Basis\" initialization scheme that\nmatches spectral methods without their inefficiencies. Our key contributions\nare threefold: (i) Magnitude of weight updates determines convergence. We prove\nlow-rank structures intrinsically bound update magnitudes, unifying\nhyperparameter tuning in learning rate, scaling factor, and initialization as\nmechanisms to optimize magnitude regulation. (ii) Spectral initialization\nsucceeds via magnitude amplification. We demystify that the presumed\nknowledge-driven benefit of the spectral component essentially arises from the\nboost in the weight update magnitude. (iii) A novel and compact initialization\nstrategy, LoRAM, scales deterministic orthogonal bases using pretrained weight\nmagnitudes to simulate spectral gains. Extensive experiments show that LoRAM\nserves as a strong baseline, retaining the full efficiency of LoRA while\nmatching or outperforming spectral initialization across benchmarks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06558v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06529", "title": "Direct Regret Optimization in Bayesian Optimization", "authors": ["Fengxue Zhang", "Yuxin Chen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06529v1", "summary": "Bayesian optimization (BO) is a powerful paradigm for optimizing expensive\nblack-box functions. Traditional BO methods typically rely on separate\nhand-crafted acquisition functions and surrogate models for the underlying\nfunction, and often operate in a myopic manner. In this paper, we propose a\nnovel direct regret optimization approach that jointly learns the optimal model\nand non-myopic acquisition by distilling from a set of candidate models and\nacquisitions, and explicitly targets minimizing the multi-step regret. Our\nframework leverages an ensemble of Gaussian Processes (GPs) with varying\nhyperparameters to generate simulated BO trajectories, each guided by an\nacquisition function chosen from a pool of conventional choices, until a\nBayesian early stop criterion is met. These simulated trajectories, capturing\nmulti-step exploration strategies, are used to train an end-to-end decision\ntransformer that directly learns to select next query points aimed at improving\nthe ultimate objective. We further adopt a dense training--sparse learning\nparadigm: The decision transformer is trained offline with abundant simulated\ndata sampled from ensemble GPs and acquisitions, while a limited number of real\nevaluations refine the GPs online. Experimental results on synthetic and\nreal-world benchmarks suggest that our method consistently outperforms BO\nbaselines, achieving lower simple regret and demonstrating more robust\nexploration in high-dimensional or noisy settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06529v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2503.05780", "title": "AI Risk Atlas: Taxonomy and Tooling for Navigating AI Risks and Resources", "authors": ["Frank Bagehorn", "Kristina Brimijoin", "Elizabeth M. Daly", "Jessica He", "Michael Hind", "Luis Garces-Erice", "Christopher Giblin", "Ioana Giurgiu", "Jacquelyn Martino", "Rahul Nair", "David Piorkowski", "Ambrish Rawat", "John Richards", "Sean Rooney", "Dhaval Salwala", "Seshu Tirupathi", "Peter Urbanetz", "Kush R. Varshney", "Inge Vejsbjerg", "Mira L. Wolf-Bauwens"], "categories": ["cs.CY", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      4.5 page main text, 22 page supporting material, 2 figures", "url": "http://arxiv.org/abs/2503.05780v2", "summary": "The rapid evolution of generative AI has expanded the breadth of risks\nassociated with AI systems. While various taxonomies and frameworks exist to\nclassify these risks, the lack of interoperability between them creates\nchallenges for researchers, practitioners, and policymakers seeking to\noperationalise AI governance. To address this gap, we introduce the AI Risk\nAtlas, a structured taxonomy that consolidates AI risks from diverse sources\nand aligns them with governance frameworks. Additionally, we present the Risk\nAtlas Nexus, a collection of open-source tools designed to bridge the divide\nbetween risk definitions, benchmarks, datasets, and mitigation strategies. This\nknowledge-driven approach leverages ontologies and knowledge graphs to\nfacilitate risk identification, prioritization, and mitigation. By integrating\nAI-assisted compliance workflows and automation strategies, our framework\nlowers the barrier to responsible AI adoption. We invite the broader research\nand open-source community to contribute to this evolving initiative, fostering\ncross-domain collaboration and ensuring AI governance keeps pace with\ntechnological advancements.", "comment": "4.5 page main text, 22 page supporting material, 2 figures", "pdf_url": "http://arxiv.org/pdf/2503.05780v2", "cate": "cs.CY", "date": "2025-02-26", "updated": "2025-07-09"}
{"id": "2507.06523", "title": "FIFA: Unified Faithfulness Evaluation Framework for Text-to-Video and Video-to-Text Generation", "authors": ["Liqiang Jing", "Viet Lai", "Seunghyun Yoon", "Trung Bui", "Xinya Du"], "categories": ["cs.CV", "cs.CL", "cs.GR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06523v1", "summary": "Video Multimodal Large Language Models (VideoMLLMs) have achieved remarkable\nprogress in both Video-to-Text and Text-to-Video tasks. However, they often\nsuffer fro hallucinations, generating content that contradicts the visual\ninput. Existing evaluation methods are limited to one task (e.g., V2T) and also\nfail to assess hallucinations in open-ended, free-form responses. To address\nthis gap, we propose FIFA, a unified FaIthFulness evAluation framework that\nextracts comprehensive descriptive facts, models their semantic dependencies\nvia a Spatio-Temporal Semantic Dependency Graph, and verifies them using\nVideoQA models. We further introduce Post-Correction, a tool-based correction\nframework that revises hallucinated content. Extensive experiments demonstrate\nthat FIFA aligns more closely with human judgment than existing evaluation\nmethods, and that Post-Correction effectively improves factual consistency in\nboth text and video generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06523v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07010", "title": "Robust Containerization of the High Angular Resolution Functional Imaging (HARFI) Pipeline", "authors": ["Zhiyuan Li", "Kurt G. Schilling", "Bennett A. Landman"], "categories": ["physics.med-ph", "cs.SE"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07010v1", "summary": "Historically, functional magnetic resonance imaging (fMRI) of the brain has\nfocused primarily on gray matter, particularly the cortical gray matter and\nassociated nuclei. However, recent work has demonstrated that functional\nactivity in white matter also plays a meaningful role in both cognition and\nlearning. In previous work, we introduced the High Angular Resolution\nFunctional Imaging (HARFI) pipeline, which demonstrated both local and global\npatterns of functional correlation in white matter. Notably, HARFI enabled\nexploration of asymmetric voxel-wise correlation using odd-order spherical\nharmonics. Although the original implementation of HARFI was released via\nGitHub, adoption was limited due to the technical complexity of running the\nsource code. In this work, we present a robust and efficient containerized\nversion of the HARFI pipeline, enabling seamless execution across multiple\npublic datasets. Our goal is to facilitate broader and deeper exploration of\nfunctional white matter architecture, especially through the lens of high\nangular resolution functional correlations. The key innovation of this work is\nthe containerized implementation, which we have made available under a\npermissive open-source license to support reproducible and accessible research\npractices.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07010v1", "cate": "physics.med-ph", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06868", "title": "On the Error Exponent Distribution of Code Ensembles over Classical-Quantum Channels", "authors": ["Giuseppe Cocco", "Javier Rodríguez Fonollosa"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      A shortened version of this manuscript has been accepted at the IEEE Information Theory Workshop 2025 (IEEE ITW 2025), Sep. 29 - Oct., Sydney, Australia", "url": "http://arxiv.org/abs/2507.06868v1", "summary": "We show that the probability distribution of the error exponent in i.i.d.\ncode ensembles over classical-quantum (CQ) channels with arbitrary output\nstates accumulates above a threshold that is strictly larger than the CQ random\ncoding exponent (RCE) at low rates, while coinciding with it at rates close to\nthe mutual information of the channel. This result, combined with the work by\nDalai [1] and the recent ones by Renes [2] and Li and Yang [3], implies that\nthe ensemble distribution of error exponents concentrates around the CQ RCE in\nthe high rate regime. Moreover, in the same rate regime the threshold we derive\ncoincides with the ensemble-average of the exponent, that is, the typical\nrandom coding (TRC) exponent [4].", "comment": "A shortened version of this manuscript has been accepted at the IEEE\n  Information Theory Workshop 2025 (IEEE ITW 2025), Sep. 29 - Oct., Sydney,\n  Australia", "pdf_url": "http://arxiv.org/pdf/2507.06868v1", "cate": "cs.IT", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07044", "title": "Opto-ViT: Architecting a Near-Sensor Region of Interest-Aware Vision Transformer Accelerator with Silicon Photonics", "authors": ["Mehrdad Morsali", "Chengwei Zhou", "Deniz Najafi", "Sreetama Sarkar", "Pietro Mercati", "Navid Khoshavi", "Peter Beerel", "Mahdi Nikdast", "Gourav Datta", "Shaahin Angizi"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07044v1", "summary": "Vision Transformers (ViTs) have emerged as a powerful architecture for\ncomputer vision tasks due to their ability to model long-range dependencies and\nglobal contextual relationships. However, their substantial compute and memory\ndemands hinder efficient deployment in scenarios with strict energy and\nbandwidth limitations. In this work, we propose OptoViT, the first near-sensor,\nregion-aware ViT accelerator leveraging silicon photonics (SiPh) for real-time\nand energy-efficient vision processing. Opto-ViT features a hybrid\nelectronic-photonic architecture, where the optical core handles\ncompute-intensive matrix multiplications using Vertical-Cavity Surface-Emitting\nLasers (VCSELs) and Microring Resonators (MRs), while nonlinear functions and\nnormalization are executed electronically. To reduce redundant computation and\npatch processing, we introduce a lightweight Mask Generation Network (MGNet)\nthat identifies regions of interest in the current frame and prunes irrelevant\npatches before ViT encoding. We further co-optimize the ViT backbone using\nquantization-aware training and matrix decomposition tailored for photonic\nconstraints. Experiments across device fabrication, circuit and architecture\nco-design, to classification, detection, and video tasks demonstrate that\nOptoViT achieves 100.4 KFPS/W with up to 84% energy savings with less than 1.6%\naccuracy loss, while enabling scalable and efficient ViT deployment at the\nedge.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07044v1", "cate": "cs.AR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2506.06444", "title": "Saffron-1: Safety Inference Scaling", "authors": ["Ruizhong Qiu", "Gaotang Li", "Tianxin Wei", "Jingrui He", "Hanghang Tong"], "categories": ["cs.LG", "cs.AI", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Previous title: \"Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety Assurance\"", "url": "http://arxiv.org/abs/2506.06444v2", "summary": "Existing safety assurance research has primarily focused on training-phase\nalignment to instill safe behaviors into LLMs. However, recent studies have\nexposed these methods' susceptibility to diverse jailbreak attacks.\nConcurrently, inference scaling has significantly advanced LLM reasoning\ncapabilities but remains unexplored in the context of safety assurance.\nAddressing this gap, our work pioneers inference scaling for robust and\neffective LLM safety against emerging threats. We reveal that conventional\ninference scaling techniques, despite their success in reasoning tasks, perform\npoorly in safety contexts, even falling short of basic approaches like\nBest-of-N Sampling. We attribute this inefficiency to a newly identified\nchallenge, the exploration--efficiency dilemma, arising from the high\ncomputational overhead associated with frequent process reward model (PRM)\nevaluations. To overcome this dilemma, we propose SAFFRON, a novel inference\nscaling paradigm tailored explicitly for safety assurance. Central to our\napproach is the introduction of a multifurcation reward model (MRM) that\nsignificantly reduces the required number of reward model evaluations. To\noperationalize this paradigm, we further propose: (i) a partial supervision\ntraining objective for MRM, (ii) a conservative exploration constraint to\nprevent out-of-distribution explorations, and (iii) a Trie-based key--value\ncaching strategy that facilitates cache sharing across sequences during tree\nsearch. Extensive experiments validate the effectiveness of our method.\nAdditionally, we publicly release our trained multifurcation reward model\n(Saffron-1) and the accompanying token-level safety reward dataset (Safety4M)\nto accelerate future research in LLM safety. Our code, model, and data are\npublicly available at https://github.com/q-rz/saffron , and our project\nhomepage is at https://q-rz.github.io/p/saffron .", "comment": "Previous title: \"Saffron-1: Towards an Inference Scaling Paradigm for\n  LLM Safety Assurance\"", "pdf_url": "http://arxiv.org/pdf/2506.06444v2", "cate": "cs.LG", "date": "2025-06-06", "updated": "2025-07-09"}
{"id": "2405.19531", "title": "Hierarchical Procedural Framework for Low-latency Robot-Assisted Hand-Object Interaction", "authors": ["Mingqi Yuan", "Huijiang Wang", "Kai-Fung Chu", "Fumiya Iida", "Bo Li", "Wenjun Zeng"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures", "url": "http://arxiv.org/abs/2405.19531v3", "summary": "Advances in robotics have been driving the development of human-robot\ninteraction (HRI) technologies. However, accurately perceiving human actions\nand achieving adaptive control remains a challenge in facilitating seamless\ncoordination between human and robotic movements. In this paper, we propose a\nhierarchical procedural framework to enable dynamic robot-assisted hand-object\ninteraction (HOI). An open-loop hierarchy leverages the RGB-based 3D\nreconstruction of the human hand, based on which motion primitives have been\ndesigned to translate hand motions into robotic actions. The low-level\ncoordination hierarchy fine-tunes the robot's action by using the continuously\nupdated 3D hand models. Experimental validation demonstrates the effectiveness\nof the hierarchical control architecture. The adaptive coordination between\nhuman and robot behavior has achieved a delay of $\\leq 0.3$ seconds in the\ntele-interaction scenario. A case study of ring-wearing tasks indicates the\npotential application of this work in assistive technologies such as healthcare\nand manufacturing.", "comment": "6 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2405.19531v3", "cate": "cs.RO", "date": "2024-05-29", "updated": "2025-07-09"}
{"id": "2507.06573", "title": "From Data-Centric to Sample-Centric: Enhancing LLM Reasoning via Progressive Optimization", "authors": ["Xinjie Chen", "Minpeng Liao", "Guoxin Chen", "Chengxi Li", "Biao Fu", "Kai Fan", "Xinggao Liu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2507.06573v1", "summary": "Reinforcement learning with verifiable rewards (RLVR) has recently advanced\nthe reasoning capabilities of large language models (LLMs). While prior work\nhas emphasized algorithmic design, data curation, and reward shaping, we\ninvestigate RLVR from a sample-centric perspective and introduce LPPO\n(Learning-Progress and Prefix-guided Optimization), a framework of progressive\noptimization techniques. Our work addresses a critical question: how to best\nleverage a small set of trusted, high-quality demonstrations, rather than\nsimply scaling up data volume. First, motivated by how hints aid human\nproblem-solving, we propose prefix-guided sampling, an online data augmentation\nmethod that incorporates partial solution prefixes from expert demonstrations\nto guide the policy, particularly for challenging instances. Second, inspired\nby how humans focus on important questions aligned with their current\ncapabilities, we introduce learning-progress weighting, a dynamic strategy that\nadjusts each training sample's influence based on model progression. We\nestimate sample-level learning progress via an exponential moving average of\nper-sample pass rates, promoting samples that foster learning and\nde-emphasizing stagnant ones. Experiments on mathematical-reasoning benchmarks\ndemonstrate that our methods outperform strong baselines, yielding faster\nconvergence and a higher performance ceiling.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.06573v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06535", "title": "Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits", "authors": ["Shan Shen", "Shenglu Hua", "Jiajun Zou", "Jiawei Liu", "Jianwang Zhai", "Chuan Shi", "Wenjian Yu"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by ICCAD2025. This is the initial version. Minor changes will be made", "url": "http://arxiv.org/abs/2507.06535v1", "summary": "Graph representation learning on Analog-Mixed Signal (AMS) circuits is\ncrucial for various downstream tasks, e.g., parasitic estimation. However, the\nscarcity of design data, the unbalanced distribution of labels, and the\ninherent diversity of circuit implementations pose significant challenges to\nlearning robust and transferable circuit representations. To address these\nlimitations, we propose CircuitGCL, a novel graph contrastive learning\nframework that integrates representation scattering and label rebalancing to\nenhance transferability across heterogeneous circuit graphs. CircuitGCL employs\na self-supervised strategy to learn topology-invariant node embeddings through\nhyperspherical representation scattering, eliminating dependency on large-scale\ndata. Simultaneously, balanced mean squared error (MSE) and softmax\ncross-entropy (bsmCE) losses are introduced to mitigate label distribution\ndisparities between circuits, enabling robust and transferable parasitic\nestimation. Evaluated on parasitic capacitance estimation (edge-level task) and\nground capacitance classification (node-level task) across TSMC 28nm AMS\ndesigns, CircuitGCL outperforms all state-of-the-art (SOTA) methods, with the\n$R^2$ improvement of $33.64\\% \\sim 44.20\\%$ for edge regression and F1-score\ngain of $0.9\\times \\sim 2.1\\times$ for node classification. Our code is\navailable at\n\\href{https://anonymous.4open.science/r/CircuitGCL-099B/README.md}{here}.", "comment": "Accepted by ICCAD2025. This is the initial version. Minor changes\n  will be made", "pdf_url": "http://arxiv.org/pdf/2507.06535v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2506.14774", "title": "MedSyn: Enhancing Diagnostics with Human-AI Collaboration", "authors": ["Burcu Sayin", "Ipek Baris Schlicht", "Ngoc Vo Hong", "Sara Allievi", "Jacopo Staiano", "Pasquale Minervini", "Andrea Passerini"], "categories": ["cs.LG", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Presented in the Trustworthy and Collaborative Artificial Intelligence Workshop 2025 (TCAI 2025) in the 4th International Conference Series on Hybrid Human-Artificial Intelligence (HHAI 2025)", "url": "http://arxiv.org/abs/2506.14774v2", "summary": "Clinical decision-making is inherently complex, often influenced by cognitive\nbiases, incomplete information, and case ambiguity. Large Language Models\n(LLMs) have shown promise as tools for supporting clinical decision-making, yet\ntheir typical one-shot or limited-interaction usage may overlook the\ncomplexities of real-world medical practice. In this work, we propose a hybrid\nhuman-AI framework, MedSyn, where physicians and LLMs engage in multi-step,\ninteractive dialogues to refine diagnoses and treatment decisions. Unlike\nstatic decision-support tools, MedSyn enables dynamic exchanges, allowing\nphysicians to challenge LLM suggestions while the LLM highlights alternative\nperspectives. Through simulated physician-LLM interactions, we assess the\npotential of open-source LLMs as physician assistants. Results show open-source\nLLMs are promising as physician assistants in the real world. Future work will\ninvolve real physician interactions to further validate MedSyn's usefulness in\ndiagnostic accuracy and patient outcomes.", "comment": "Presented in the Trustworthy and Collaborative Artificial\n  Intelligence Workshop 2025 (TCAI 2025) in the 4th International Conference\n  Series on Hybrid Human-Artificial Intelligence (HHAI 2025)", "pdf_url": "http://arxiv.org/pdf/2506.14774v2", "cate": "cs.LG", "date": "2025-05-07", "updated": "2025-07-08"}
{"id": "2507.06526", "title": "Concept Unlearning by Modeling Key Steps of Diffusion Process", "authors": ["Chaoshuo Zhang", "Chenhao Lin", "Zhengyu Zhao", "Le Yang", "Qian Wang", "Chao Shen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06526v1", "summary": "Text-to-image diffusion models (T2I DMs), represented by Stable Diffusion,\nwhich generate highly realistic images based on textual input, have been widely\nused. However, their misuse poses serious security risks. While existing\nconcept unlearning methods aim to mitigate these risks, they struggle to\nbalance unlearning effectiveness with generative retainability.To overcome this\nlimitation, we innovatively propose the Key Step Concept Unlearning (KSCU)\nmethod, which ingeniously capitalizes on the unique stepwise sampling\ncharacteristic inherent in diffusion models during the image generation\nprocess. Unlike conventional approaches that treat all denoising steps equally,\nKSCU strategically focuses on pivotal steps with the most influence over the\nfinal outcome by dividing key steps for different concept unlearning tasks and\nfine-tuning the model only at those steps. This targeted approach reduces the\nnumber of parameter updates needed for effective unlearning, while maximizing\nthe retention of the model's generative capabilities.Through extensive\nbenchmark experiments, we demonstrate that KSCU effectively prevents T2I DMs\nfrom generating undesirable images while better retaining the model's\ngenerative capabilities.Our code will be released.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06526v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2408.08333", "title": "CodeMirage: Hallucinations in Code Generated by Large Language Models", "authors": ["Vibhor Agarwal", "Yulong Pei", "Salwa Alamir", "Xiaomo Liu"], "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at AutoMates @ IJCAI 2024", "url": "http://arxiv.org/abs/2408.08333v2", "summary": "Large Language Models (LLMs) have shown promising potentials in program\ngeneration and no-code automation. However, LLMs are prone to generate\nhallucinations, i.e., they generate text which sounds plausible but is\nincorrect. Although there has been a recent surge in research on LLM\nhallucinations for text generation, similar hallucination phenomenon can happen\nin code generation. Sometimes the generated code can have syntactical or\nlogical errors as well as more advanced issues like security vulnerabilities,\nmemory leaks, etc. Given the wide adaptation of LLMs to enhance efficiency in\ncode generation and development in general, it becomes imperative to\ninvestigate hallucinations in code generation. To the best of our knowledge,\nthis is the first attempt at studying hallucinations in the code generated by\nLLMs. We start by introducing the code hallucination definition and a\ncomprehensive taxonomy of code hallucination types. We propose the first\nbenchmark CodeMirage dataset for code hallucinations. The benchmark contains\n1,137 GPT-3.5 generated hallucinated code snippets for Python programming\nproblems from two base datasets - HumanEval and MBPP. We then propose the\nmethodology for code hallucination detection and experiment with open source\nLLMs such as CodeLLaMA as well as OpenAI's GPT-3.5 and GPT-4 models using\none-shot prompt. We find that GPT-4 performs the best on HumanEval dataset and\ngives comparable results to the fine-tuned CodeBERT baseline on MBPP dataset.\nTowards the end, we discuss various mitigation strategies for code\nhallucinations and conclude our work.", "comment": "Accepted at AutoMates @ IJCAI 2024", "pdf_url": "http://arxiv.org/pdf/2408.08333v2", "cate": "cs.SE", "date": "2024-08-14", "updated": "2025-07-08"}
{"id": "2507.06944", "title": "Fractional Programming for Stochastic Precoding over Generalized Fading Channels", "authors": ["Wenyu Wang", "Kaiming Shen"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      11 pages", "url": "http://arxiv.org/abs/2507.06944v1", "summary": "This paper seeks an efficient algorithm for stochastic precoding to maximize\nthe long-term average weighted sum rates throughout a multiple-input\nmultiple-output (MIMO) network. Unlike many existing works that assume a\nparticular probability distribution model for fading channels (which is\ntypically Gaussian), our approach merely relies on the first and second moments\nof fading channels. For the stochastic precoding problem, a naive idea is to\ndirectly apply the fractional programming (FP) method to the data rate inside\nthe expectation; it does not work well because the auxiliary variables\nintroduced by FP are then difficult to decide. To address the above issue, we\npropose using a lower bound to approximate the expectation of data rate. This\nlower bound stems from a nontrivial use of the matrix FP, and outperforms the\nexisting lower bounds in that it accounts for generalized fading channels whose\nfirst and second moments are known. The resulting approximate problem can be\nefficiently solved in closed form in an iterative fashion. Furthermore, for\nlarge-scale MIMO, we improve the efficiency of the proposed algorithm by\neliminating the large matrix inverse. Simulations show that the proposed\nstochastic precoding method outperforms the benchmark methods in both Gaussian\nand non-Gaussian fading channel cases.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2507.06944v1", "cate": "cs.IT", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06349", "title": "Multi-Queue SSD I/O Modeling & Its Implications for Data Structure Design", "authors": ["Erin Ransom", "Andrew Lim", "Michael Mitzenmacher"], "categories": ["cs.DS", "cs.AR"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06349v1", "summary": "Understanding the performance profiles of storage devices and how best to\nutilize them has always been non-trivial due to factors such as seek times,\ncaching, scheduling, concurrent access, flash wear-out, and garbage collection.\nHowever, analytical frameworks that provide simplified abstractions of storage\nperformance can still be accurate enough to evaluate external memory algorithms\nand data structures at the design stage. For example, the Disk Access Machine\n(DAM) model assumes that a storage device transfers data in fixed-size blocks\nof size B and that all transfers have unit latency. This abstraction is already\nsufficient to explain some of the benefits of data structures such as B-trees\nand Log-Structured Merge trees (LSM trees); however, storage technology\nadvances have significantly reduced current models' accuracy and utility.\n  This paper introduces the Multi-Queue Solid State Drive (MQSSD) model, a new\nstorage abstraction. This model builds upon previous models and aims to more\naccurately represent the performance characteristics of modern storage\nhardware. We identify key performance-critical aspects of modern multi-queue\nsolid-state drives on which we base our model and demonstrate these\ncharacteristics on actual hardware. We then show how our model can be applied\nto LSM-tree-based storage engines to optimize them for modern storage hardware.\nWe highlight that leveraging concurrent access is crucial for fully utilizing\nthe high throughput of multi-queue SSDs, enabling designs that may appear\ncounterintuitive under traditional paradigms We then validate these insights\nthrough experiments using Facebook's LSM-tree-based key-value store, RocksDB.\nWe conclude that the MQSSD model offers a more accurate abstraction of modern\nhardware than previous models, allowing for greater insight and optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06349v1", "cate": "cs.DS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06471", "title": "Designing Parallel Algorithms for Community Detection using Arachne", "authors": ["Fuhuan Li", "Zhihui Du", "David A. Bader"], "categories": ["cs.DC", "cs.DS"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06471v1", "summary": "The rise of graph data in various fields calls for efficient and scalable\ncommunity detection algorithms. In this paper, we present parallel\nimplementations of two widely used algorithms: Label Propagation and Louvain,\nspecifically designed to leverage the capabilities of Arachne which is a\nPython-accessible, open-source framework for large-scale graph analysis. Our\nimplementations achieve substantial speedups over existing Python-based tools\nlike NetworkX and igraph, which lack efficient parallelization, and are\ncompetitive with parallel frameworks such as NetworKit. Experimental results\nshow that Arachne-based methods outperform these baselines, achieving speedups\nof up to 710x over NetworkX, 75x over igraph, and 12x over NetworKit.\nAdditionally, we analyze the scalability of our implementation under varying\nthread counts, demonstrating how different phases contribute to overall\nperformance gains of the parallel Louvain algorithm. Arachne, including our\ncommunity detection implementation, is open-source and available at\nhttps://github.com/Bears-R-Us/arkouda-njit .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06471v1", "cate": "cs.DC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2506.15740", "title": "SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents", "authors": ["Jonathan Kutasov", "Yuqi Sun", "Paul Colognese", "Teun van der Weij", "Linda Petrini", "Chen Bo Calvin Zhang", "John Hughes", "Xiang Deng", "Henry Sleight", "Tyler Tracy", "Buck Shlegeris", "Joe Benton"], "categories": ["cs.AI", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.15740v2", "summary": "As Large Language Models (LLMs) are increasingly deployed as autonomous\nagents in complex and long horizon settings, it is critical to evaluate their\nability to sabotage users by pursuing hidden objectives. We study the ability\nof frontier LLMs to evade monitoring and achieve harmful hidden goals while\ncompleting a wide array of realistic tasks. We evaluate a broad range of\nfrontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena,\nthe first highly diverse agent evaluation dataset for sabotage and monitoring\ncapabilities of LLM agents. SHADE-Arena consists of complex pairs of benign\nmain tasks and harmful side objectives in complicated environments. Agents are\nevaluated on their ability to complete the side task without appearing\nsuspicious to an LLM monitor. When measuring agent ability to (a) complete the\nmain task, (b) complete the side task, and (c) avoid detection, we find that\nthe best performing frontier models score 27% (Claude 3.7 Sonnet) and 15%\n(Gemini 2.5 Pro) as sabotage agents when overseen by Claude 3.6 Sonnet. For\ncurrent frontier models, success on the side task relies heavily on having\naccess to a hidden scratchpad that is not visible to the monitor. We also use\nSHADE-Arena to measure models' monitoring abilities, with the top monitor\n(Gemini 2.5 Pro) achieving an AUC of 0.87 at distinguishing benign and malign\ntranscripts. We find that for now, models still struggle at sabotage due to\nfailures in long-context main task execution. However, our measurements already\ndemonstrate the difficulty of monitoring for subtle sabotage attempts, which we\nexpect to only increase in the face of more complex and longer-horizon tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.15740v2", "cate": "cs.AI", "date": "2025-06-17", "updated": "2025-07-08"}
{"id": "2409.10655", "title": "Disentangling Uncertainty for Safe Social Navigation using Deep Reinforcement Learning", "authors": ["Daniel Flögel", "Marcos Gómez Villafañe", "Joshua Ransiek", "Sören Hohmann"], "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 8 pages, 6 figures and 4 tables", "url": "http://arxiv.org/abs/2409.10655v3", "summary": "Autonomous mobile robots are increasingly used in pedestrian-rich\nenvironments where safe navigation and appropriate human interaction are\ncrucial. While Deep Reinforcement Learning (DRL) enables socially integrated\nrobot behavior, challenges persist in novel or perturbed scenarios to indicate\nwhen and why the policy is uncertain. Unknown uncertainty in decision-making\ncan lead to collisions or human discomfort and is one reason why safe and\nrisk-aware navigation is still an open problem. This work introduces a novel\napproach that integrates aleatoric, epistemic, and predictive uncertainty\nestimation into a DRL navigation framework for policy distribution uncertainty\nestimates. We, therefore, incorporate Observation-Dependent Variance (ODV) and\ndropout into the Proximal Policy Optimization (PPO) algorithm. For different\ntypes of perturbations, we compare the ability of deep ensembles and\nMonte-Carlo dropout (MC-dropout) to estimate the uncertainties of the policy.\nIn uncertain decision-making situations, we propose to change the robot's\nsocial behavior to conservative collision avoidance. The results show improved\ntraining performance with ODV and dropout in PPO and reveal that the training\nscenario has an impact on the generalization. In addition, MC-dropout is more\nsensitive to perturbations and correlates the uncertainty type to the\nperturbation better. With the safe action selection, the robot can navigate in\nperturbed environments with fewer collisions.", "comment": "Accepted at 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS), 8 pages, 6 figures and 4 tables", "pdf_url": "http://arxiv.org/pdf/2409.10655v3", "cate": "cs.RO", "date": "2024-09-16", "updated": "2025-07-09"}
{"id": "2507.06582", "title": "Learning controllable dynamics through informative exploration", "authors": ["Peter N. Loxley", "Friedrich T. Sommer"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06582v1", "summary": "Environments with controllable dynamics are usually understood in terms of\nexplicit models. However, such models are not always available, but may\nsometimes be learned by exploring an environment. In this work, we investigate\nusing an information measure called \"predicted information gain\" to determine\nthe most informative regions of an environment to explore next. Applying\nmethods from reinforcement learning allows good suboptimal exploring policies\nto be found, and leads to reliable estimates of the underlying controllable\ndynamics. This approach is demonstrated by comparing with several myopic\nexploration approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06582v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06538", "title": "Few-shot Learning on AMS Circuits and Its Application to Parasitic Capacitance Prediction", "authors": ["Shan Shen", "Yibin Zhang", "Hector Rodriguez Rodriguez", "Wenjian Yu"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in Proceedings of DAC2025", "url": "http://arxiv.org/abs/2507.06538v1", "summary": "Graph representation learning is a powerful method to extract features from\ngraph-structured data, such as analog/mixed-signal (AMS) circuits. However,\ntraining deep learning models for AMS designs is severely limited by the\nscarcity of integrated circuit design data. In this work, we present\nCircuitGPS, a few-shot learning method for parasitic effect prediction in AMS\ncircuits. The circuit netlist is represented as a heterogeneous graph, with the\ncoupling capacitance modeled as a link. CircuitGPS is pre-trained on link\nprediction and fine-tuned on edge regression. The proposed method starts with a\nsmall-hop sampling technique that converts a link or a node into a subgraph.\nThen, the subgraph embeddings are learned with a hybrid graph Transformer.\nAdditionally, CircuitGPS integrates a low-cost positional encoding that\nsummarizes the positional and structural information of the sampled subgraph.\nCircuitGPS improves the accuracy of coupling existence by at least 20\\% and\nreduces the MAE of capacitance estimation by at least 0.067 compared to\nexisting methods. Our method demonstrates strong inherent scalability, enabling\ndirect application to diverse AMS circuit designs through zero-shot learning.\nFurthermore, the ablation studies provide valuable insights into graph models\nfor representation learning.", "comment": "Published in Proceedings of DAC2025", "pdf_url": "http://arxiv.org/pdf/2507.06538v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06530", "title": "Speak2Sign3D: A Multi-modal Pipeline for English Speech to American Sign Language Animation", "authors": ["Kazi Mahathir Rahman", "Naveed Imtiaz Nafis", "Md. Farhan Sadik", "Mohammad Al Rafi", "Mehedi Hasan Shahed"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 12 figures", "url": "http://arxiv.org/abs/2507.06530v1", "summary": "Helping deaf and hard-of-hearing people communicate more easily is the main\ngoal of Automatic Sign Language Translation. Although most past research has\nfocused on turning sign language into text, doing the reverse, turning spoken\nEnglish into sign language animations, has been largely overlooked. That's\nbecause it involves multiple steps, such as understanding speech, translating\nit into sign-friendly grammar, and generating natural human motion. In this\nwork, we introduce a complete pipeline that converts English speech into\nsmooth, realistic 3D sign language animations. Our system starts with Whisper\nto translate spoken English into text. Then, we use a MarianMT machine\ntranslation model to translate that text into American Sign Language (ASL)\ngloss, a simplified version of sign language that captures meaning without\ngrammar. This model performs well, reaching BLEU scores of 0.7714 and 0.8923.\nTo make the gloss translation more accurate, we also use word embeddings such\nas Word2Vec and FastText to understand word meanings. Finally, we animate the\ntranslated gloss using a 3D keypoint-based motion system trained on\nSign3D-WLASL, a dataset we created by extracting body, hand, and face key\npoints from real ASL videos in the WLASL dataset. To support the gloss\ntranslation stage, we also built a new dataset called BookGlossCorpus-CG, which\nturns everyday English sentences from the BookCorpus dataset into ASL gloss\nusing grammar rules. Our system stitches everything together by smoothly\ninterpolating between signs to create natural, continuous animations. Unlike\nprevious works like How2Sign and Phoenix-2014T that focus on recognition or use\nonly one type of data, our pipeline brings together audio, text, and motion in\na single framework that goes all the way from spoken English to lifelike 3D\nsign language animation.", "comment": "11 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.06530v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2412.16525", "title": "One Size Does Not Fit All: Investigating Efficacy of Perplexity in Detecting LLM-Generated Code", "authors": ["Jinwei Xu", "He Zhang", "Yanjing Yang", "Lanxin Yang", "Zeru Cheng", "Jun Lyu", "Bohan Liu", "Xin Zhou", "Alberto Bacchelli", "Yin Kia Chiam", "Thiam Kian Chiew"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      This article has been accepted by ACM Transactions on Software Engineering and Methodology (TOSEM)", "url": "http://arxiv.org/abs/2412.16525v2", "summary": "Large language model-generated code (LLMgCode) has become increasingly common\nin software development. So far LLMgCode has more quality issues than\nhuman-authored code (HaCode). It is common for LLMgCode to mix with HaCode in a\ncode change, while the change is signed by only human developers, without being\ncarefully examined. Many automated methods have been proposed to detect\nLLMgCode from HaCode, in which the perplexity-based method (PERPLEXITY for\nshort) is the state-of-the-art method. However, the efficacy evaluation of\nPERPLEXITY has focused on detection accuracy. Yet it is unclear whether\nPERPLEXITY is good enough in a wider range of realistic evaluation settings. To\nthis end, we carry out a family of experiments to compare PERPLEXITY against\nfeature- and pre-training-based methods from three perspectives: detection\naccuracy, detection speed, and generalization capability. The experimental\nresults show that PERPLEXITY has the best generalization capability while\nhaving limited detection accuracy and detection speed. Based on that, we\ndiscuss the strengths and limitations of PERPLEXITY, e.g., PERPLEXITY is\nunsuitable for high-level programming languages. Finally, we provide\nrecommendations to improve PERPLEXITY and apply it in practice. As the first\nlarge-scale investigation on detecting LLMgCode from HaCode, this article\nprovides a wide range of findings for future improvement.", "comment": "This article has been accepted by ACM Transactions on Software\n  Engineering and Methodology (TOSEM)", "pdf_url": "http://arxiv.org/pdf/2412.16525v2", "cate": "cs.SE", "date": "2024-12-21", "updated": "2025-07-09"}
{"id": "2502.01864", "title": "Quantum Codes with Addressable and Transversal Non-Clifford Gates", "authors": ["Zhiyang He", "Vinod Vaikuntanathan", "Adam Wills", "Rachel Yun Zhang"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.01864v3", "summary": "The development of quantum codes with good error correction parameters and\nuseful sets of transversal gates is a problem of major interest in quantum\nerror-correction. Abundant prior works have studied transversal gates which are\nrestricted to acting on all logical qubits simultaneously. In this work, we\nstudy codes that support transversal gates which induce $\\textit{addressable}$\nlogical gates, i.e., the logical gates act on logical qubits of our choice. As\nwe consider scaling to high-rate codes, the study and design of low-overhead,\naddressable logical operations presents an important problem for both\ntheoretical and practical purposes.\n  Our primary result is the construction of an explicit qubit code for which\n$\\textit{any}$ triple of logical qubits across one, two, or three codeblocks\ncan be addressed with a logical $\\mathsf{CCZ}$ gate via a depth-one circuit of\nphysical $\\mathsf{CCZ}$ gates, and whose parameters are asymptotically good, up\nto polylogarithmic factors. The result naturally generalizes to other gates\nincluding the $\\mathsf{C}^{\\ell} Z$ gates for $\\ell \\neq 2$.\n  Going beyond this, we develop a formalism for constructing quantum codes with\n$\\textit{addressable and transversal}$ gates. Our framework, called\n$\\textit{addressable orthogonality}$, encompasses the original triorthogonality\nframework of Bravyi and Haah (Phys. Rev. A 2012), and extends this and other\nframeworks to study addressable gates. We demonstrate the power of this\nframework with the construction of an asymptotically good qubit code for which\n$\\textit{pre-designed}$, pairwise disjoint triples of logical qubits within a\nsingle codeblock may be addressed with a logical $\\mathsf{CCZ}$ gate via a\nphysical depth-one circuit of $\\mathsf{Z}$, $\\mathsf{CZ}$ and $\\mathsf{CCZ}$\ngates. In an appendix, we show that our framework extends to addressable and\ntransversal $T$ gates, up to Clifford corrections.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.01864v3", "cate": "quant-ph", "date": "2025-02-03", "updated": "2025-07-07"}
{"id": "2507.06549", "title": "Deep-Learning-Based Pre-Layout Parasitic Capacitance Prediction on SRAM Designs", "authors": ["Shan Shen", "Dingcheng Yang", "Yuyang Xie", "Chunyan Pei", "Wenjian Yu", "Bei Yu"], "categories": ["cs.LG", "cs.AR", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in Proceedings of GLSVLSI2024", "url": "http://arxiv.org/abs/2507.06549v1", "summary": "To achieve higher system energy efficiency, SRAM in SoCs is often customized.\nThe parasitic effects cause notable discrepancies between pre-layout and\npost-layout circuit simulations, leading to difficulty in converging design\nparameters and excessive design iterations. Is it possible to well predict the\nparasitics based on the pre-layout circuit, so as to perform parasitic-aware\npre-layout simulation? In this work, we propose a deep-learning-based 2-stage\nmodel to accurately predict these parasitics in pre-layout stages. The model\ncombines a Graph Neural Network (GNN) classifier and Multi-Layer Perceptron\n(MLP) regressors, effectively managing class imbalance of the net parasitics in\nSRAM circuits. We also employ Focal Loss to mitigate the impact of abundant\ninternal net samples and integrate subcircuit information into the graph to\nabstract the hierarchical structure of schematics. Experiments on 4 real SRAM\ndesigns show that our approach not only surpasses the state-of-the-art model in\nparasitic prediction by a maximum of 19X reduction of error but also\nsignificantly boosts the simulation process by up to 598X speedup.", "comment": "Published in Proceedings of GLSVLSI2024", "pdf_url": "http://arxiv.org/pdf/2507.06549v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06608", "title": "Nexus: Taming Throughput-Latency Tradeoff in LLM Serving via Efficient GPU Sharing", "authors": ["Xiaoxiang Shi", "Colin Cai", "Junjia Du", "Zhanda Zhu", "Xingda Wei", "Zhihao Jia"], "categories": ["cs.DC", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06608v1", "summary": "Current prefill-decode (PD) disaggregation is typically deployed at the level\nof entire serving engines, assigning separate GPUs to handle prefill and decode\nphases. While effective at reducing latency, this approach demands more\nhardware. To improve GPU utilization, Chunked Prefill mixes prefill and decode\nrequests within the same batch, but introduces phase interference between\nprefill and decode.\n  While existing PD disaggregation solutions separate the phases across GPUs,\nwe ask: can the same decoupling be achieved within a single serving engine? The\nkey challenge lies in managing the conflicting resource requirements of prefill\nand decode when they share the same hardware. In this paper, we first show that\nchunked prefill requests cause interference with decode requests due to their\ndistinct requirements for GPU resources. Second, we find that GPU resources\nexhibit diminishing returns. Beyond a saturation point, increasing GPU\nallocation yields negligible latency improvements. This insight enables us to\nsplit a single GPU's resources and dynamically allocate them to prefill and\ndecode on the fly, effectively disaggregating the two phases within the same\nGPU.\n  Across a range of models and workloads, our system Nexus achieves up to 2.2x\nhigher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM. It also\noutperforms SGLang with up to 2x higher throughput, 2x lower TTFT, and 1.7x\nlower TBT, and achieves 1.4x higher throughput than vLLM-disaggregation using\nonly half the number of GPUs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06608v1", "cate": "cs.DC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.02966", "title": "PBa-LLM: Privacy- and Bias-aware NLP using Named-Entity Recognition (NER)", "authors": ["Gonzalo Mancera", "Aythami Morales", "Julian Fierrez", "Ruben Tolosana", "Alejandro Penna", "Miguel Lopez-Duran", "Francisco Jurado", "Alvaro Ortigosa"], "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Presented at AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI) 2025, Philadelphia, PA, USA, March 2025", "url": "http://arxiv.org/abs/2507.02966v2", "summary": "The use of Natural Language Processing (NLP) in highstakes AI-based\napplications has increased significantly in recent years, especially since the\nemergence of Large Language Models (LLMs). However, despite their strong\nperformance, LLMs introduce important legal/ ethical concerns, particularly\nregarding privacy, data protection, and transparency. Due to these concerns,\nthis work explores the use of Named- Entity Recognition (NER) to facilitate the\nprivacy-preserving training (or adaptation) of LLMs. We propose a framework\nthat uses NER technologies to anonymize sensitive information in text data,\nsuch as personal identities or geographic locations. An evaluation of the\nproposed privacy-preserving learning framework was conducted to measure its\nimpact on user privacy and system performance in a particular high-stakes and\nsensitive setup: AI-based resume scoring for recruitment processes. The study\ninvolved two language models (BERT and RoBERTa) and six anonymization\nalgorithms (based on Presidio, FLAIR, BERT, and different versions of GPT)\napplied to a database of 24,000 candidate profiles. The findings indicate that\nthe proposed privacy preservation techniques effectively maintain system\nperformance while playing a critical role in safeguarding candidate\nconfidentiality, thus promoting trust in the experimented scenario. On top of\nthe proposed privacy-preserving approach, we also experiment applying an\nexisting approach that reduces the gender bias in LLMs, thus finally obtaining\nour proposed Privacyand Bias-aware LLMs (PBa-LLMs). Note that the proposed\nPBa-LLMs have been evaluated in a particular setup (resume scoring), but are\ngenerally applicable to any other LLM-based AI application.", "comment": "Presented at AAAI Workshop on Privacy-Preserving Artificial\n  Intelligence (PPAI) 2025, Philadelphia, PA, USA, March 2025", "pdf_url": "http://arxiv.org/pdf/2507.02966v2", "cate": "cs.CL", "date": "2025-06-30", "updated": "2025-07-09"}
{"id": "2412.02506", "title": "ROVER: A Multi-Season Dataset for Visual SLAM", "authors": ["Fabian Schmidt", "Julian Daubermann", "Marcel Mitschke", "Constantin Blessing", "Stefan Meyer", "Markus Enzweiler", "Abhinav Valada"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Copyright 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "url": "http://arxiv.org/abs/2412.02506v3", "summary": "Robust SLAM is a crucial enabler for autonomous navigation in natural,\nsemi-structured environments such as parks and gardens. However, these\nenvironments present unique challenges for SLAM due to frequent seasonal\nchanges, varying light conditions, and dense vegetation. These factors often\ndegrade the performance of visual SLAM algorithms originally developed for\nstructured urban environments. To address this gap, we present ROVER, a\ncomprehensive benchmark dataset tailored for evaluating visual SLAM algorithms\nunder diverse environmental conditions and spatial configurations. We captured\nthe dataset with a robotic platform equipped with monocular, stereo, and RGBD\ncameras, as well as inertial sensors. It covers 39 recordings across five\noutdoor locations, collected through all seasons and various lighting\nscenarios, i.e., day, dusk, and night with and without external lighting. With\nthis novel dataset, we evaluate several traditional and deep learning-based\nSLAM methods and study their performance in diverse challenging conditions. The\nresults demonstrate that while stereo-inertial and RGBD configurations\ngenerally perform better under favorable lighting and moderate vegetation, most\nSLAM systems perform poorly in low-light and high-vegetation scenarios,\nparticularly during summer and autumn. Our analysis highlights the need for\nimproved adaptability in visual SLAM algorithms for outdoor applications, as\ncurrent systems struggle with dynamic environmental factors affecting scale,\nfeature extraction, and trajectory consistency. This dataset provides a solid\nfoundation for advancing visual SLAM research in real-world, semi-structured\nenvironments, fostering the development of more resilient SLAM systems for\nlong-term outdoor localization and mapping. The dataset and the code of the\nbenchmark are available under https://iis-esslingen.github.io/rover.", "comment": "Copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "pdf_url": "http://arxiv.org/pdf/2412.02506v3", "cate": "cs.RO", "date": "2024-12-03", "updated": "2025-07-09"}
{"id": "2507.06613", "title": "Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation", "authors": ["Anshuk Uppal", "Yuhta Takida", "Chieh-Hsin Lai", "Yuki Mitsufuji"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      24 pages, 8 figures and 7 tables", "url": "http://arxiv.org/abs/2507.06613v1", "summary": "Disentangled and interpretable latent representations in generative models\ntypically come at the cost of generation quality. The $\\beta$-VAE framework\nintroduces a hyperparameter $\\beta$ to balance disentanglement and\nreconstruction quality, where setting $\\beta > 1$ introduces an information\nbottleneck that favors disentanglement over sharp, accurate reconstructions. To\naddress this trade-off, we propose a novel generative modeling framework that\nleverages a range of $\\beta$ values to learn multiple corresponding latent\nrepresentations. First, we obtain a slew of representations by training a\nsingle variational autoencoder (VAE), with a new loss function that controls\nthe information retained in each latent representation such that the higher\n$\\beta$ value prioritize disentanglement over reconstruction fidelity. We then,\nintroduce a non-linear diffusion model that smoothly transitions latent\nrepresentations corresponding to different $\\beta$ values. This model denoises\ntowards less disentangled and more informative representations, ultimately\nleading to (almost) lossless representations, enabling sharp reconstructions.\nFurthermore, our model supports sample generation without input images,\nfunctioning as a standalone generative model. We evaluate our framework in\nterms of both disentanglement and generation quality. Additionally, we observe\nsmooth transitions in the latent spaces with respect to changes in $\\beta$,\nfacilitating consistent manipulation of generated outputs.", "comment": "24 pages, 8 figures and 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.06613v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06602", "title": "Generalization in Reinforcement Learning for Radio Access Networks", "authors": ["Burak Demirel", "Yu Wang", "Cristian Tatino", "Pablo Soldati"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06602v1", "summary": "Modern RAN operate in highly dynamic and heterogeneous environments, where\nhand-tuned, rule-based RRM algorithms often underperform. While RL can surpass\nsuch heuristics in constrained settings, the diversity of deployments and\nunpredictable radio conditions introduce major generalization challenges.\nData-driven policies frequently overfit to training conditions, degrading\nperformance in unseen scenarios. To address this, we propose a\ngeneralization-centered RL framework for RAN control that: (i) encodes cell\ntopology and node attributes via attention-based graph representations; (ii)\napplies domain randomization to broaden the training distribution; and (iii)\ndistributes data generation across multiple actors while centralizing training\nin a cloud-compatible architecture aligned with O-RAN principles. Although\ngeneralization increases computational and data-management complexity, our\ndistributed design mitigates this by scaling data collection and training\nacross diverse network conditions. Applied to downlink link adaptation in five\n5G benchmarks, our policy improves average throughput and spectral efficiency\nby ~10% over an OLLA baseline (10% BLER target) in full-buffer MIMO/mMIMO and\nby >20% under high mobility. It matches specialized RL in full-buffer traffic\nand achieves up to 4- and 2-fold gains in eMBB and mixed-traffic benchmarks,\nrespectively. In nine-cell deployments, GAT models offer 30% higher throughput\nover MLP baselines. These results, combined with our scalable architecture,\noffer a path toward AI-native 6G RAN using a single, generalizable RL agent.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06602v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06531", "title": "ILNet: Trajectory Prediction with Inverse Learning Attention for Enhancing Intention Capture", "authors": ["Mingjin Zeng", "Nan Ouyang", "Wenkang Wan", "Lei Ao", "Qing Cai", "Kai Sheng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06531v1", "summary": "Trajectory prediction for multi-agent interaction scenarios is a crucial\nchallenge. Most advanced methods model agent interactions by efficiently\nfactorized attention based on the temporal and agent axes. However, this static\nand foward modeling lacks explicit interactive spatio-temporal coordination,\ncapturing only obvious and immediate behavioral intentions. Alternatively, the\nmodern trajectory prediction framework refines the successive predictions by a\nfixed-anchor selection strategy, which is difficult to adapt in different\nfuture environments. It is acknowledged that human drivers dynamically adjust\ninitial driving decisions based on further assumptions about the intentions of\nsurrounding vehicles. Motivated by human driving behaviors, this paper proposes\nILNet, a multi-agent trajectory prediction method with Inverse Learning (IL)\nattention and Dynamic Anchor Selection (DAS) module. IL Attention employs an\ninverse learning paradigm to model interactions at neighboring moments,\nintroducing proposed intentions to dynamically encode the spatio-temporal\ncoordination of interactions, thereby enhancing the model's ability to capture\ncomplex interaction patterns. Then, the learnable DAS module is proposed to\nextract multiple trajectory change keypoints as anchors in parallel with almost\nno increase in parameters. Experimental results show that the ILNet achieves\nstate-of-the-art performance on the INTERACTION and Argoverse motion\nforecasting datasets. Particularly, in challenged interaction scenarios, ILNet\nachieves higher accuracy and more multimodal distributions of trajectories over\nfewer parameters. Our codes are available at https://github.com/mjZeng11/ILNet.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06531v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2505.23684", "title": "How to Elicit Explainability Requirements? A Comparison of Interviews, Focus Groups, and Surveys", "authors": ["Martin Obaidi", "Jakob Droste", "Hannah Deters", "Marc Herrmann", "Raymond Ochsner", "Jil Klünder", "Kurt Schneider"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      This paper has been accepted at the research track of the 33rd IEEE International Requirements Engineering Conference (RE 2025)", "url": "http://arxiv.org/abs/2505.23684v3", "summary": "As software systems grow increasingly complex, explainability has become a\ncrucial non-functional requirement for transparency, user trust, and regulatory\ncompliance. Eliciting explainability requirements is challenging, as different\nmethods capture varying levels of detail and structure. This study examines the\nefficiency and effectiveness of three commonly used elicitation methods - focus\ngroups, interviews, and online surveys - while also assessing the role of\ntaxonomy usage in structuring and improving the elicitation process. We\nconducted a case study at a large German IT consulting company, utilizing a\nweb-based personnel management software. A total of two focus groups, 18\ninterviews, and an online survey with 188 participants were analyzed. The\nresults show that interviews were the most efficient, capturing the highest\nnumber of distinct needs per participant per time spent. Surveys collected the\nmost explanation needs overall but had high redundancy. Delayed taxonomy\nintroduction resulted in a greater number and diversity of needs, suggesting\nthat a two-phase approach is beneficial. Based on our findings, we recommend a\nhybrid approach combining surveys and interviews to balance efficiency and\ncoverage. Future research should explore how automation can support elicitation\nand how taxonomies can be better integrated into different methods.", "comment": "This paper has been accepted at the research track of the 33rd IEEE\n  International Requirements Engineering Conference (RE 2025)", "pdf_url": "http://arxiv.org/pdf/2505.23684v3", "cate": "cs.SE", "date": "2025-05-29", "updated": "2025-07-09"}
{"id": "2507.05966", "title": "Simple Convergence Proof of Adam From a Sign-like Descent Perspective", "authors": ["Hanyang Peng", "Shuang Qin", "Yue Yu", "Fangqing Jiang", "Hui Wang", "Zhouchen Lin"], "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      23 pages, 2figures", "url": "http://arxiv.org/abs/2507.05966v1", "summary": "Adam is widely recognized as one of the most effective optimizers for\ntraining deep neural networks (DNNs). Despite its remarkable empirical success,\nits theoretical convergence analysis remains unsatisfactory. Existing works\npredominantly interpret Adam as a preconditioned stochastic gradient descent\nwith momentum (SGDM), formulated as $\\bm{x}_{t+1} = \\bm{x}_t -\n\\frac{\\gamma_t}{{\\sqrt{\\bm{v}_t}+\\epsilon}} \\circ \\bm{m}_t$. This perspective\nnecessitates strong assumptions and intricate techniques, resulting in lengthy\nand opaque convergence proofs that are difficult to verify and extend. In\ncontrast, we propose a novel interpretation by treating Adam as a sign-like\noptimizer, expressed as $\\bm{x}_{t+1} = \\bm{x}_t - \\gamma_t\n\\frac{|\\bm{m}_t|}{{\\sqrt{\\bm{v}_t}+\\epsilon}} \\circ {\\rm Sign}(\\bm{m}_t)$. This\nreformulation significantly simplifies the convergence analysis. For the first\ntime, with some mild conditions, we prove that Adam achieves the optimal rate\nof ${\\cal O}(\\frac{1}{T^{\\sfrac{1}{4}}})$ rather than the previous ${\\cal O}\n\\left(\\frac{\\ln T}{T^{\\sfrac{1}{4}}}\\right)$ under weak assumptions of the\ngeneralized $p$-affine variance and $(L_0, L_1, q)$-smoothness, without\ndependence on the model dimensionality or the numerical stability parameter\n$\\epsilon$. Additionally, our theoretical analysis provides new insights into\nthe role of momentum as a key factor ensuring convergence and offers practical\nguidelines for tuning learning rates in Adam, further bridging the gap between\ntheory and practice.", "comment": "23 pages, 2figures", "pdf_url": "http://arxiv.org/pdf/2507.05966v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.04544", "title": "hdl2v: A Code Translation Dataset for Enhanced LLM Verilog Generation", "authors": ["Charles Hong", "Brendan Roberts", "Huijae An", "Alex Um", "Advay Ratan", "Yakun Sophia Shao"], "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.PL"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      Published at ACM/IEEE International Symposium on Machine Learning for CAD (MLCAD) 2025", "url": "http://arxiv.org/abs/2506.04544v2", "summary": "Large language models (LLMs) are playing an increasingly large role in\ndomains such as code generation, including hardware code generation, where\nVerilog is the key language. However, the amount of publicly available Verilog\ncode pales in comparison to the amount of code available for software languages\nlike Python. In this work, we present hdl2v (\"HDL-to-Verilog\"), a dataset which\nseeks to increase the amount of available human-written Verilog data by\ntranslating or compiling three other hardware description languages - VHDL,\nChisel, and PyMTL3 - to Verilog. Furthermore, we demonstrate the value of hdl2v\nin enhancing LLM Verilog generation by improving performance of a 32\nbillion-parameter open-weight model by up to 23% (pass@10) in VerilogEvalV2,\nwithout utilizing any data augmentation or knowledge distillation from larger\nmodels. We also show hdl2v's ability to boost the performance of a data\naugmentation-based fine-tuning approach by 63%. Finally, we characterize and\nanalyze our dataset to better understand which characteristics of\nHDL-to-Verilog datasets can be expanded upon in future work for even better\nperformance.", "comment": "Published at ACM/IEEE International Symposium on Machine Learning for\n  CAD (MLCAD) 2025", "pdf_url": "http://arxiv.org/pdf/2506.04544v2", "cate": "cs.AR", "date": "2025-06-05", "updated": "2025-07-08"}
{"id": "2507.06653", "title": "Towards Efficient and Scalable Distributed Vector Search with RDMA", "authors": ["Xiangyu Zhi", "Meng Chen", "Xiao Yan", "Baotong Lu", "Hui Li", "Qianxi Zhang", "Qi Chen", "James Cheng"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06653v1", "summary": "Similarity-based vector search facilitates many important applications such\nas search and recommendation but is limited by the memory capacity and\nbandwidth of a single machine due to large datasets and intensive data read. In\nthis paper, we present CoTra, a system that scales up vector search for\ndistributed execution. We observe a tension between computation and\ncommunication efficiency, which is the main challenge for good scalability,\ni.e., handling the local vectors on each machine independently blows up\ncomputation as the pruning power of vector index is not fully utilized, while\nrunning a global index over all machines introduces rich data dependencies and\nthus extensive communication. To resolve such tension, we leverage the fact\nthat vector search is approximate in nature and robust to asynchronous\nexecution. In particular, we run collaborative vector search over the machines\nwith algorithm-system co-designs including clustering-based data partitioning\nto reduce communication, asynchronous execution to avoid communication stall,\nand task push to reduce network traffic. To make collaborative search\nefficient, we introduce a suite of system optimizations including task\nscheduling, communication batching, and storage format. We evaluate CoTra on\nreal datasets and compare with four baselines. The results show that when using\n16 machines, the query throughput of CoTra scales to 9.8-13.4x over a single\nmachine and is 2.12-3.58x of the best-performing baseline at 0.95 recall@10.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06653v1", "cate": "cs.DC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2502.11461", "title": "Doppler Correspondence: Non-Iterative Scan Matching With Doppler Velocity-Based Correspondence", "authors": ["Jiwoo Kim", "Geunsik Bae", "Changseung Kim", "Jinwoo Lee", "Woojae Shin", "Hyondong Oh"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.11461v2", "summary": "Achieving successful scan matching is essential for LiDAR odometry. However,\nin challenging environments with adverse weather conditions or repetitive\ngeometric patterns, LiDAR odometry performance is degraded due to incorrect\nscan matching. Recently, the emergence of frequency-modulated continuous wave\n4D LiDAR and 4D radar technologies has provided the potential to address these\nunfavorable conditions. The term 4D refers to point cloud data characterized by\nrange, azimuth, and elevation along with Doppler velocity. Although 4D data is\navailable, most scan matching methods for 4D LiDAR and 4D radar still establish\ncorrespondence by repeatedly identifying the closest points between consecutive\nscans, overlooking the Doppler information. This paper introduces, for the\nfirst time, a simple Doppler velocity-based correspondence -- Doppler\nCorrespondence -- that is invariant to translation and small rotation of the\nsensor, with its geometric and kinematic foundations. Extensive experiments\ndemonstrate that the proposed method enables the direct matching of consecutive\npoint clouds without an iterative process, making it computationally efficient.\nAdditionally, it provides a more robust correspondence estimation in\nenvironments with repetitive geometric patterns.The implementation of our\nproposed method is publicly available at https://github.com/Tars0523/Doppler\nCorrespondence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.11461v2", "cate": "cs.RO", "date": "2025-02-17", "updated": "2025-07-09"}
{"id": "2507.06615", "title": "Efficient Multi-Task Reinforcement Learning with Cross-Task Policy Guidance", "authors": ["Jinmin He", "Kai Li", "Yifan Zang", "Haobo Fu", "Qiang Fu", "Junliang Xing", "Jian Cheng"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      NeurIPS2024", "url": "http://arxiv.org/abs/2507.06615v1", "summary": "Multi-task reinforcement learning endeavors to efficiently leverage shared\ninformation across various tasks, facilitating the simultaneous learning of\nmultiple tasks. Existing approaches primarily focus on parameter sharing with\ncarefully designed network structures or tailored optimization procedures.\nHowever, they overlook a direct and complementary way to exploit cross-task\nsimilarities: the control policies of tasks already proficient in some skills\ncan provide explicit guidance for unmastered tasks to accelerate skills\nacquisition. To this end, we present a novel framework called Cross-Task Policy\nGuidance (CTPG), which trains a guide policy for each task to select the\nbehavior policy interacting with the environment from all tasks' control\npolicies, generating better training trajectories. In addition, we propose two\ngating mechanisms to improve the learning efficiency of CTPG: one gate filters\nout control policies that are not beneficial for guidance, while the other gate\nblocks tasks that do not necessitate guidance. CTPG is a general framework\nadaptable to existing parameter sharing approaches. Empirical evaluations\ndemonstrate that incorporating CTPG with these approaches significantly\nenhances performance in manipulation and locomotion benchmarks.", "comment": "NeurIPS2024", "pdf_url": "http://arxiv.org/pdf/2507.06615v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06619", "title": "Steps Adaptive Decay DPSGD: Enhancing Performance on Imbalanced Datasets with Differential Privacy with HAM10000", "authors": ["Xiaobo Huang", "Fang Xie"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06619v1", "summary": "When applying machine learning to medical image classification, data leakage\nis a critical issue. Previous methods, such as adding noise to gradients for\ndifferential privacy, work well on large datasets like MNIST and CIFAR-100, but\nfail on small, imbalanced medical datasets like HAM10000. This is because the\nimbalanced distribution causes gradients from minority classes to be clipped\nand lose crucial information, while majority classes dominate. This leads the\nmodel to fall into suboptimal solutions early. To address this, we propose\nSAD-DPSGD, which uses a linear decaying mechanism for noise and clipping\nthresholds. By allocating more privacy budget and using higher clipping\nthresholds in the initial training phases, the model avoids suboptimal\nsolutions and enhances performance. Experiments show that SAD-DPSGD outperforms\nAuto-DPSGD on HAM10000, improving accuracy by 2.15% under $\\epsilon = 3.0$ ,\n$\\delta = 10^{-3}$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06619v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06537", "title": "A model-agnostic active learning approach for animal detection from camera traps", "authors": ["Thi Thu Thuy Nguyen", "Duc Thanh Nguyen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06537v1", "summary": "Smart data selection is becoming increasingly important in data-driven\nmachine learning. Active learning offers a promising solution by allowing\nmachine learning models to be effectively trained with optimal data including\nthe most informative samples from large datasets. Wildlife data captured by\ncamera traps are excessive in volume, requiring tremendous effort in data\nlabelling and animal detection models training. Therefore, applying active\nlearning to optimise the amount of labelled data would be a great aid in\nenabling automated wildlife monitoring and conservation. However, existing\nactive learning techniques require that a machine learning model (i.e., an\nobject detector) be fully accessible, limiting the applicability of the\ntechniques. In this paper, we propose a model-agnostic active learning approach\nfor detection of animals captured by camera traps. Our approach integrates\nuncertainty and diversity quantities of samples at both the object-based and\nimage-based levels into the active learning sample selection process. We\nvalidate our approach in a benchmark animal dataset. Experimental results\ndemonstrate that, using only 30% of the training data selected by our approach,\na state-of-the-art animal detector can achieve a performance of equal or\ngreater than that with the use of the complete training dataset.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06537v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.03160", "title": "Assessing Small Language Models for Code Generation: An Empirical Study with Benchmarks", "authors": ["Md Mahade Hasan", "Muhammad Waseem", "Kai-Kristian Kemell", "Jussi Rasku", "Juha Ala-Rantala", "Pekka Abrahamsson"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      17 pages, 10 Tables, 57 figures. Includes benchmarks and multilingual evaluation. Submitted to the Journal of Systems and Software", "url": "http://arxiv.org/abs/2507.03160v3", "summary": "The recent advancements of Small Language Models (SLMs) have opened new\npossibilities for efficient code generation. SLMs offer lightweight and\ncost-effective alternatives to Large Language Models (LLMs), making them\nattractive for use in resource-constrained environments. However, empirical\nunderstanding of SLMs, particularly their capabilities, limitations, and\nperformance trade-offs in code generation remains limited. This study presents\na comprehensive empirical evaluation of 20 open-source SLMs ranging from 0.4B\nto 10B parameters on five diverse code-related benchmarks (HumanEval, MBPP,\nMercury, HumanEvalPack, and CodeXGLUE). The models are assessed along three\ndimensions: i) functional correctness of generated code, ii) computational\nefficiency and iii) performance across multiple programming languages. The\nfindings of this study reveal that several compact SLMs achieve competitive\nresults while maintaining a balance between performance and efficiency, making\nthem viable for deployment in resource-constrained environments. However,\nachieving further improvements in accuracy requires switching to larger models.\nThese models generally outperform their smaller counterparts, but they require\nmuch more computational power. We observe that for 10% performance\nimprovements, models can require nearly a 4x increase in VRAM consumption,\nhighlighting a trade-off between effectiveness and scalability. Besides, the\nmultilingual performance analysis reveals that SLMs tend to perform better in\nlanguages such as Python, Java, and PHP, while exhibiting relatively weaker\nperformance in Go, C++, and Ruby. However, statistical analysis suggests these\ndifferences are not significant, indicating a generalizability of SLMs across\nprogramming languages. Based on the findings, this work provides insights into\nthe design and selection of SLMs for real-world code generation tasks.", "comment": "17 pages, 10 Tables, 57 figures. Includes benchmarks and multilingual\n  evaluation. Submitted to the Journal of Systems and Software", "pdf_url": "http://arxiv.org/pdf/2507.03160v3", "cate": "cs.SE", "date": "2025-07-03", "updated": "2025-07-09"}
{"id": "2507.06552", "title": "On the Hardness of Unsupervised Domain Adaptation: Optimal Learners and Information-Theoretic Perspective", "authors": ["Zhiyi Dong", "Zixuan Liu", "Yongyi Mao"], "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Accepted at the 4th Conference on Lifelong Learning Agents (CoLLAs 2025)", "url": "http://arxiv.org/abs/2507.06552v1", "summary": "This paper studies the hardness of unsupervised domain adaptation (UDA) under\ncovariate shift. We model the uncertainty that the learner faces by a\ndistribution $\\pi$ in the ground-truth triples $(p, q, f)$ -- which we call a\nUDA class -- where $(p, q)$ is the source -- target distribution pair and $f$\nis the classifier. We define the performance of a learner as the overall target\ndomain risk, averaged over the randomness of the ground-truth triple. This\nformulation couples the source distribution, the target distribution and the\nclassifier in the ground truth, and deviates from the classical worst-case\nanalyses, which pessimistically emphasize the impact of hard but rare UDA\ninstances. In this formulation, we precisely characterize the optimal learner.\nThe performance of the optimal learner then allows us to define the learning\ndifficulty for the UDA class and for the observed sample. To quantify this\ndifficulty, we introduce an information-theoretic quantity -- Posterior Target\nLabel Uncertainty (PTLU) -- along with its empirical estimate (EPTLU) from the\nsample , which capture the uncertainty in the prediction for the target domain.\nBriefly, PTLU is the entropy of the predicted label in the target domain under\nthe posterior distribution of ground-truth classifier given the observed source\nand target samples. By proving that such a quantity serves to lower-bound the\nrisk of any learner, we suggest that these quantities can be used as proxies\nfor evaluating the hardness of UDA learning. We provide several examples to\ndemonstrate the advantage of PTLU, relative to the existing measures, in\nevaluating the difficulty of UDA learning.", "comment": "Accepted at the 4th Conference on Lifelong Learning Agents (CoLLAs\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.06552v1", "cate": "stat.ML", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2503.03088", "title": "AHCPTQ: Accurate and Hardware-Compatible Post-Training Quantization for Segment Anything Model", "authors": ["Wenlun Zhang", "Yunshan Zhong", "Shimpei Ando", "Kentaro Yoshioka"], "categories": ["cs.CV", "cs.AR", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2503.03088v2", "summary": "The Segment Anything Model (SAM) has demonstrated strong versatility across\nvarious visual tasks. However, its large storage requirements and high\ncomputational cost pose challenges for practical deployment. Post-training\nquantization (PTQ) has emerged as an effective strategy for efficient\ndeployment, but we identify two key challenges in SAM that hinder the\neffectiveness of existing PTQ methods: the heavy-tailed and skewed distribution\nof post-GELU activations, and significant inter-channel variation in linear\nprojection activations. To address these challenges, we propose AHCPTQ, an\naccurate and hardware-efficient PTQ method for SAM. AHCPTQ introduces\nhardware-compatible Hybrid Log-Uniform Quantization (HLUQ) to manage post-GELU\nactivations, employing log2 quantization for dense small values and uniform\nquantization for sparse large values to enhance quantization resolution.\nAdditionally, AHCPTQ incorporates Channel-Aware Grouping (CAG) to mitigate\ninter-channel variation by progressively clustering activation channels with\nsimilar distributions, enabling them to share quantization parameters and\nimproving hardware efficiency. The combination of HLUQ and CAG not only\nenhances quantization effectiveness but also ensures compatibility with\nefficient hardware execution. For instance, under the W4A4 configuration on the\nSAM-L model, AHCPTQ achieves 36.6% mAP on instance segmentation with the DINO\ndetector, while achieving a 7.89x speedup and 8.64x energy efficiency over its\nfloating-point counterpart in FPGA implementation.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.03088v2", "cate": "cs.CV", "date": "2025-03-05", "updated": "2025-07-09"}
{"id": "2507.06938", "title": "Accelerated Spatio-Temporal Bayesian Modeling for Multivariate Gaussian Processes", "authors": ["Lisa Gaedke-Merzhäuser", "Vincent Maillou", "Fernando Rodriguez Avellaneda", "Olaf Schenk", "Mathieu Luisier", "Paula Moraga", "Alexandros Nikolaos Ziogas", "Håvard Rue"], "categories": ["stat.CO", "cs.DC", "62F15, 68W15", "G.3; G.4"], "primary_category": "Subjects:       Computation (stat.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06938v1", "summary": "Multivariate Gaussian processes (GPs) offer a powerful probabilistic\nframework to represent complex interdependent phenomena. They pose, however,\nsignificant computational challenges in high-dimensional settings, which\nfrequently arise in spatial-temporal applications. We present DALIA, a highly\nscalable framework for performing Bayesian inference tasks on spatio-temporal\nmultivariate GPs, based on the methodology of integrated nested Laplace\napproximations. Our approach relies on a sparse inverse covariance matrix\nformulation of the GP, puts forward a GPU-accelerated block-dense approach, and\nintroduces a hierarchical, triple-layer, distributed memory parallel scheme. We\nshowcase weak scaling performance surpassing the state-of-the-art by two orders\nof magnitude on a model whose parameter space is 8$\\times$ larger and measure\nstrong scaling speedups of three orders of magnitude when running on 496 GH200\nsuperchips on the Alps supercomputer. Applying DALIA to air pollution data from\nnorthern Italy over 48 days, we showcase refined spatial resolutions over the\naggregated pollutant measurements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06938v1", "cate": "stat.CO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2502.14931", "title": "Hier-SLAM++: Neuro-Symbolic Semantic SLAM with a Hierarchically Categorical Gaussian Splatting", "authors": ["Boying Li", "Vuong Chi Hao", "Peter J. Stuckey", "Ian Reid", "Hamid Rezatofighi"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      18 pages. Under review", "url": "http://arxiv.org/abs/2502.14931v2", "summary": "We propose Hier-SLAM++, a comprehensive Neuro-Symbolic semantic 3D Gaussian\nSplatting SLAM method with both RGB-D and monocular input featuring an advanced\nhierarchical categorical representation, which enables accurate pose estimation\nas well as global 3D semantic mapping. The parameter usage in semantic SLAM\nsystems increases significantly with the growing complexity of the environment,\nmaking scene understanding particularly challenging and costly. To address this\nproblem, we introduce a novel hierarchical representation that encodes both\nsemantic and geometric information in a compact form into 3D Gaussian\nSplatting, leveraging the capabilities of large language models (LLMs) as well\nas the 3D generative model. By utilizing the proposed hierarchical tree\nstructure, semantic information is symbolically represented and learned in an\nend-to-end manner. We further introduce an advanced semantic loss designed to\noptimize hierarchical semantic information through both Intra-level and\nInter-level optimizations. Additionally, we propose an improved SLAM system to\nsupport both RGB-D and monocular inputs using a feed-forward model. To the best\nof our knowledge, this is the first semantic monocular Gaussian Splatting SLAM\nsystem, significantly reducing sensor requirements for 3D semantic\nunderstanding and broadening the applicability of semantic Gaussian SLAM\nsystem. We conduct experiments on both synthetic and real-world datasets,\ndemonstrating superior or on-par performance with state-of-the-art methods,\nwhile significantly reducing storage and training time requirements. Our\nproject page is available at: https://hierslampp.github.io/", "comment": "18 pages. Under review", "pdf_url": "http://arxiv.org/pdf/2502.14931v2", "cate": "cs.RO", "date": "2025-02-20", "updated": "2025-07-09"}
{"id": "2507.06623", "title": "Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review", "authors": ["James Stewart-Evans", "Emma Wilson", "Tessa Langley", "Andrew Prayle", "Angela Hands", "Karen Exley", "Jo Leonardi-Bee"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      44 pages, 4 figures", "url": "http://arxiv.org/abs/2507.06623v1", "summary": "The data extraction stages of reviews are resource-intensive, and researchers\nmay seek to expediate data extraction using online (large language models) LLMs\nand review protocols. Claude 3.5 Sonnet was used to trial two approaches that\nused a review protocol to prompt data extraction from 10 evidence sources\nincluded in a case study scoping review. A protocol-based approach was also\nused to review extracted data. Limited performance evaluation was undertaken\nwhich found high accuracy for the two extraction approaches (83.3% and 100%)\nwhen extracting simple, well-defined citation details; accuracy was lower (9.6%\nand 15.8%) when extracting more complex, subjective data items. Considering all\ndata items, both approaches had precision >90% but low recall (<25%) and F1\nscores (<40%). The context of a complex scoping review, open response types and\nmethodological approach likely impacted performance due to missed and\nmisattributed data. LLM feedback considered the baseline extraction accurate\nand suggested minor amendments: four of 15 (26.7%) to citation details and 8 of\n38 (21.1%) to key findings data items were considered to potentially add value.\nHowever, when repeating the process with a dataset featuring deliberate errors,\nonly 2 of 39 (5%) errors were detected. Review-protocol-based methods used for\nexpediency require more robust performance evaluation across a range of LLMs\nand review contexts with comparison to conventional prompt engineering\napproaches. We recommend researchers evaluate and report LLM performance if\nusing them similarly to conduct data extraction or review extracted data. LLM\nfeedback contributed to protocol adaptation and may assist future review\nprotocol drafting.", "comment": "44 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.06623v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06624", "title": "UniOD: A Universal Model for Outlier Detection across Diverse Domains", "authors": ["Dazhi Fu", "Jicong Fan"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      20 pages, 4 figures", "url": "http://arxiv.org/abs/2507.06624v1", "summary": "Outlier detection (OD) seeks to distinguish inliers and outliers in\ncompletely unlabeled datasets and plays a vital role in science and\nengineering. Most existing OD methods require troublesome dataset-specific\nhyperparameter tuning and costly model training before they can be deployed to\nidentify outliers. In this work, we propose UniOD, a universal OD framework\nthat leverages labeled datasets to train a single model capable of detecting\noutliers of datasets from diverse domains. Specifically, UniOD converts each\ndataset into multiple graphs, produces consistent node features, and frames\noutlier detection as a node-classification task, and is able to generalize to\nunseen domains. As a result, UniOD avoids effort on model selection and\nhyperparameter tuning, reduces computational cost, and effectively utilizes the\nknowledge from historical datasets, which improves the convenience and accuracy\nin real applications. We evaluate UniOD on 15 benchmark OD datasets against 15\nstate-of-the-art baselines, demonstrating its effectiveness.", "comment": "20 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.06624v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06543", "title": "Token Bottleneck: One Token to Remember Dynamics", "authors": ["Taekyung Kim", "Dongyoon Han", "Byeongho Heo", "Jeongeun Park", "Sangdoo Yun"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 9 figures, 8 tables, project page: this https URL , code: this https URL", "url": "http://arxiv.org/abs/2507.06543v1", "summary": "Deriving compact and temporally aware visual representations from dynamic\nscenes is essential for successful execution of sequential scene understanding\ntasks such as visual tracking and robotic manipulation. In this paper, we\nintroduce Token Bottleneck (ToBo), a simple yet intuitive self-supervised\nlearning pipeline that squeezes a scene into a bottleneck token and predicts\nthe subsequent scene using minimal patches as hints. The ToBo pipeline\nfacilitates the learning of sequential scene representations by conservatively\nencoding the reference scene into a compact bottleneck token during the squeeze\nstep. In the expansion step, we guide the model to capture temporal dynamics by\npredicting the target scene using the bottleneck token along with few target\npatches as hints. This design encourages the vision backbone to embed temporal\ndependencies, thereby enabling understanding of dynamic transitions across\nscenes. Extensive experiments in diverse sequential tasks, including video\nlabel propagation and robot manipulation in simulated environments demonstrate\nthe superiority of ToBo over baselines. Moreover, deploying our pre-trained\nmodel on physical robots confirms its robustness and effectiveness in\nreal-world environments. We further validate the scalability of ToBo across\ndifferent model scales.", "comment": "17 pages, 9 figures, 8 tables, project page:\n  https://token-bottleneck.github.io, code: https://github.com/naver-ai/tobo", "pdf_url": "http://arxiv.org/pdf/2507.06543v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06770", "title": "Relaying Quantum Information", "authors": ["Yigal Ilin", "Uzi Pereg"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      8 pages, 3 figures, comments are welcome", "url": "http://arxiv.org/abs/2507.06770v1", "summary": "Quantum relays are central to both quantum communication and distributed\nquantum computing, enabling long-distance transmission and modular\narchitectures. Unlike classical repeaters, quantum repeaters preserve coherence\nwithout amplifying quantum information, relying on entanglement swapping and\nquantum error correction to overcome loss and decoherence. In this work, we\ninvestigate the transmission of quantum information via quantum relay channels.\nOur three-terminal relay model captures the trade-off between repeater-assisted\nand repeaterless communication strategies. We propose a decode-forward coding\nscheme and analyze both entanglement-assisted and unassisted scenarios. Our\nframework allows for different entanglement topologies between the transmitter,\nthe relay and the destination receiver, recovering known results on\nentanglement-assisted and unassisted communication. Furthermore, we discuss the\ninterpretation of coding with quantum side information. These findings serve as\na stepping stone for the design of secure, efficient, and reliable quantum\nnetworks and the practical realization of quantum repeaters and long-range\nquantum key distribution.", "comment": "8 pages, 3 figures, comments are welcome", "pdf_url": "http://arxiv.org/pdf/2507.06770v1", "cate": "quant-ph", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2502.06355", "title": "Fine-tuning Multimodal Transformers on Edge: A Parallel Split Learning Approach", "authors": ["Timo Fudala", "Vasileios Tsouvalas", "Nirvana Meratnia"], "categories": ["cs.DC", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures, accepted to FedGenAI-IJCAI 2025", "url": "http://arxiv.org/abs/2502.06355v3", "summary": "Multimodal transformers integrate diverse data types like images, audio, and\ntext, advancing tasks such as audio-visual understanding and image-text\nretrieval; yet their high parameterization limits deployment on\nresource-constrained edge devices. Split Learning (SL), which partitions models\nat a designated cut-layer to offload compute-intensive operations to the\nserver, offers a promising approach for distributed training of multimodal\ntransformers, though its application remains underexplored. We present MPSL, a\nparallel SL approach for computational efficient fine-tuning of multimodal\ntransformers in a distributed manner, while eliminating label sharing, client\nsynchronization, and per-client sub-model management. MPSL employs lightweight\nclient-side tokenizers and a unified modality-agnostic encoder, allowing\nflexible adaptation to task-specific needs. Our evaluation across 7 multimodal\ndatasets demonstrates that MPSL matches or outperforms Federated Learning,\nreduces client-side computations by 250x, and achieves superior scalability in\ncommunication cost with model growth. Through extensive analysis, we highlight\ntask suitability, trade-offs, and scenarios where MPSL excels, inspiring\nfurther exploration.", "comment": "10 pages, 5 figures, accepted to FedGenAI-IJCAI 2025", "pdf_url": "http://arxiv.org/pdf/2502.06355v3", "cate": "cs.DC", "date": "2025-02-10", "updated": "2025-07-08"}
{"id": "2507.06379", "title": "Domestic frontier AI regulation, an IAEA for AI, an NPT for AI, and a US-led Allied Public-Private Partnership for AI: Four institutions for governing and developing frontier AI", "authors": ["Haydn Belfield"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      46 pages, 6 figures, 7 tables", "url": "http://arxiv.org/abs/2507.06379v1", "summary": "Compute governance can underpin international institutions for the governance\nof frontier AI. To demonstrate this I explore four institutions for governing\nand developing frontier AI. Next steps for compute-indexed domestic frontier AI\nregulation could include risk assessments and pre-approvals, data centre usage\nreports, and release gate regulation. Domestic regimes could be harmonized and\nmonitored through an International AI Agency - an International Atomic Energy\nAgency (IAEA) for AI. This could be backed up by a Secure Chips Agreement - a\nNon-Proliferation Treaty (NPT) for AI. This would be a non-proliferation regime\nfor advanced chips, building on the chip export controls - states that do not\nhave an IAIA-certified frontier regulation regime would not be allowed to\nimport advanced chips. Frontier training runs could be carried out by a\nmegaproject between the USA and its allies - a US-led Allied Public-Private\nPartnership for frontier AI. As a project to develop advanced AI, this could\nhave significant advantages over alternatives led by Big Tech or particular\nstates: it could be more legitimate, secure, safe, non-adversarial, peaceful,\nand less prone to misuse. For each of these four scenarios, a key incentive for\nparticipation is access to the advanced AI chips that are necessary for\nfrontier training runs and large-scale inference. Together, they can create a\nsituation in which governments can be reassured that frontier AI is developed\nand deployed in a secure manner with misuse minimised and benefits widely\nshared. Building these institutions may take years or decades, but progress is\nincremental and evolutionary and the first steps have already been taken.", "comment": "46 pages, 6 figures, 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.06379v1", "cate": "cs.CY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2504.13582", "title": "Hysteresis-Aware Neural Network Modeling and Whole-Body Reinforcement Learning Control of Soft Robots", "authors": ["Zongyuan Chen", "Yan Xia", "Jiayuan Liu", "Jijia Liu", "Wenhao Tang", "Jiayu Chen", "Feng Gao", "Longfei Ma", "Hongen Liao", "Yu Wang", "Chao Yu", "Boyu Zhang", "Fei Xing"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Updated author affiliation", "url": "http://arxiv.org/abs/2504.13582v2", "summary": "Soft robots exhibit inherent compliance and safety, which makes them\nparticularly suitable for applications requiring direct physical interaction\nwith humans, such as surgical procedures. However, their nonlinear and\nhysteretic behavior, resulting from the properties of soft materials, presents\nsubstantial challenges for accurate modeling and control. In this study, we\npresent a soft robotic system designed for surgical applications and propose a\nhysteresis-aware whole-body neural network model that accurately captures and\npredicts the soft robot's whole-body motion, including its hysteretic behavior.\nBuilding upon the high-precision dynamic model, we construct a highly parallel\nsimulation environment for soft robot control and apply an on-policy\nreinforcement learning algorithm to efficiently train whole-body motion control\nstrategies. Based on the trained control policy, we developed a soft robotic\nsystem for surgical applications and validated it through phantom-based laser\nablation experiments in a physical environment. The results demonstrate that\nthe hysteresis-aware modeling reduces the Mean Squared Error (MSE) by 84.95\npercent compared to traditional modeling methods. The deployed control\nalgorithm achieved a trajectory tracking error ranging from 0.126 to 0.250 mm\non the real soft robot, highlighting its precision in real-world conditions.\nThe proposed method showed strong performance in phantom-based surgical\nexperiments and demonstrates its potential for complex scenarios, including\nfuture real-world clinical applications.", "comment": "Updated author affiliation", "pdf_url": "http://arxiv.org/pdf/2504.13582v2", "cate": "cs.RO", "date": "2025-04-18", "updated": "2025-07-09"}
{"id": "2507.06628", "title": "Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning", "authors": ["Jinmin He", "Kai Li", "Yifan Zang", "Haobo Fu", "Qiang Fu", "Junliang Xing", "Jian Cheng"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML2025", "url": "http://arxiv.org/abs/2507.06628v1", "summary": "Offline multi-task reinforcement learning aims to learn a unified policy\ncapable of solving multiple tasks using only pre-collected task-mixed datasets,\nwithout requiring any online interaction with the environment. However, it\nfaces significant challenges in effectively sharing knowledge across tasks.\nInspired by the efficient knowledge abstraction observed in human learning, we\npropose Goal-Oriented Skill Abstraction (GO-Skill), a novel approach designed\nto extract and utilize reusable skills to enhance knowledge transfer and task\nperformance. Our approach uncovers reusable skills through a goal-oriented\nskill extraction process and leverages vector quantization to construct a\ndiscrete skill library. To mitigate class imbalances between broadly applicable\nand task-specific skills, we introduce a skill enhancement phase to refine the\nextracted skills. Furthermore, we integrate these skills using hierarchical\npolicy learning, enabling the construction of a high-level policy that\ndynamically orchestrates discrete skills to accomplish specific tasks.\nExtensive experiments on diverse robotic manipulation tasks within the\nMetaWorld benchmark demonstrate the effectiveness and versatility of GO-Skill.", "comment": "ICML2025", "pdf_url": "http://arxiv.org/pdf/2507.06628v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06631", "title": "Prevention of Overfitting on Mesh-Structured Data Regressions with a Modified Laplace Operator", "authors": ["Enda D. V. Bigarella"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06631v1", "summary": "This document reports on a method for detecting and preventing overfitting on\ndata regressions, herein applied to mesh-like data structures. The mesh\nstructure allows for the straightforward computation of the Laplace-operator\nsecond-order derivatives in a finite-difference fashion for noiseless data.\nDerivatives of the training data are computed on the original training mesh to\nserve as a true label of the entropy of the training data. Derivatives of the\ntrained data are computed on a staggered mesh to identify oscillations in the\ninterior of the original training mesh cells. The loss of the Laplace-operator\nderivatives is used for hyperparameter optimisation, achieving a reduction of\nunwanted oscillation through the minimisation of the entropy of the trained\nmodel. In this setup, testing does not require the splitting of points from the\ntraining data, and training is thus directly performed on all available\ntraining points. The Laplace operator applied to the trained data on a\nstaggered mesh serves as a surrogate testing metric based on diffusion\nproperties.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06631v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06547", "title": "Concept-TRAK: Understanding how diffusion models learn concepts through concept-level attribution", "authors": ["Yonghyun Park", "Chieh-Hsin Lai", "Satoshi Hayakawa", "Yuhta Takida", "Naoki Murata", "Wei-Hsiang Liao", "Woosung Choi", "Kin Wai Cheuk", "Junghyun Koo", "Yuki Mitsufuji"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.06547v1", "summary": "While diffusion models excel at image generation, their growing adoption\nraises critical concerns around copyright issues and model transparency.\nExisting attribution methods identify training examples influencing an entire\nimage, but fall short in isolating contributions to specific elements, such as\nstyles or objects, that matter most to stakeholders. To bridge this gap, we\nintroduce \\emph{concept-level attribution} via a novel method called\n\\emph{Concept-TRAK}. Concept-TRAK extends influence functions with two key\ninnovations: (1) a reformulated diffusion training loss based on diffusion\nposterior sampling, enabling robust, sample-specific attribution; and (2) a\nconcept-aware reward function that emphasizes semantic relevance. We evaluate\nConcept-TRAK on the AbC benchmark, showing substantial improvements over prior\nmethods. Through diverse case studies--ranging from identifying IP-protected\nand unsafe content to analyzing prompt engineering and compositional\nlearning--we demonstrate how concept-level attribution yields actionable\ninsights for responsible generative AI development and governance.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.06547v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07065", "title": "Layer Cake Representations for Quantum Divergences", "authors": ["Po-Chieh Liu", "Christoph Hirche", "Hao-Chung Cheng"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07065v1", "summary": "Defining suitable quantum extensions of classical divergences often poses a\nchallenge due to the non-commutative nature of quantum information. In this\nwork, we propose a new approach via what we call the layer cake representation.\nThe resulting quantum R\\'enyi and $f$-divergences are then proven to be\nequivalent to those recently defined via integral representations.\nNevertheless, the approach can provide several insights. We give an alternative\nproof of the integral representation of the relative entropy by Frenkel and\nprove a conjecture regarding a trace expression for the R\\'enyi divergence.\nAdditionally, we give applications to error exponents in hypothesis testing, a\nnew Riemann-Stieltjes type integral representation and a variational\nrepresentation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07065v1", "cate": "quant-ph", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2503.16029", "title": "iDynamics: A Novel Framework for Evaluating Microservice Scheduling Policies under Controllable Dynamics in Cloud-Edge Continuum", "authors": ["Ming Chen", "Muhammed Tawfiqul Islam", "Maria Rodriguez Read", "Rajkumar Buyya"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      14 pages, 10 figures, 3 tables", "url": "http://arxiv.org/abs/2503.16029v3", "summary": "Designing and evaluating microservice scheduling policies is challenging,\nparticularly under dynamic conditions such as complex call-graph dependencies\nand varying cross-node networking conditions. Moreover, deploying such systems\nin real-world cloud-edge environments to evaluate scheduling strategies is\noften impractical due to complexity, cost, and limited accessibility. This\nhighlights the need for an emulation framework that can faithfully emulate the\ncharacteristics of the cloud-edge continuum. These characteristics include\ndynamic topology changes, latency-sensitive service chains, and varying\nnetworking conditions, all of which must be accurately modeled for meaningful\nevaluation. In this work, iDynamics addresses these challenges by providing a\nconfigurable and extensible framework that captures the essential dynamics of\nrunning microservice applications in cloud-edge environments, enabling\nsystematic development and testing of microservice scheduling strategies. The\nframework comprises modular components, such as the Graph Dynamics Analyzer,\nNetworking Dynamics Manager, and Scheduling Policy Extender. This enables\nfine-grained environmental control and facilitates systematic comparisons of\ndifferent scheduling strategies. Extensive experiments on a real cloud-edge\ntestbed demonstrate that iDynamics effectively captures diverse dynamic\nscenarios encountered in microservice deployments, offering a robust solution\nfor designing and evaluating different policies under realistic and\ncontrollable conditions.", "comment": "14 pages, 10 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2503.16029v3", "cate": "cs.DC", "date": "2025-03-20", "updated": "2025-07-09"}
{"id": "2507.06640", "title": "Google Search Advertising after Dobbs v. Jackson", "authors": ["Yelena Mejova", "Ronald E. Robertson", "Catherine A. Gimbrone", "Sarah McKetta"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06640v1", "summary": "Search engines have become the gateway to information, products, and\nservices, including those concerning healthcare. Access to reproductive health\nhas been especially complicated in the wake of the 2022 Dobbs v. Jackson\ndecision by the Supreme Court of the United States, splintering abortion\nregulations among the states. In this study, we performed an audit of the\nadvertisements shown to Google Search users seeking information about abortion\nacross the United States during the year following the Dobbs decision. We found\nthat Crisis Pregnancy Centers (CPCs) -- organizations that target women with\nunexpected or \"crisis\" pregnancies, but do not provide abortions -- accounted\nfor 47% of advertisements, whereas abortion clinics -- for 30%. Advertisements\nfrom CPCs were often returned for queries concerning information and safety.\nThe type of advertisements returned, however, varied widely within each state,\nwith Arizona returning the most advertisements from abortion clinics and other\npro-choice organizations, and Minnesota the least. The proportion of pro-choice\nvs. anti-choice advertisements returned also varied over time, but estimates\nfrom Staggered Augmented Synthetic Control Methods did not indicate that\nchanges in advertisement results were attributable to changes in state abortion\nlaws. Our findings raise questions about the access to accurate medical\ninformation across the U.S. and point to a need for further examination of\nsearch engine advertisement policies and geographical bias.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06640v1", "cate": "cs.CY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2505.07446", "title": "TPT-Bench: A Large-Scale, Long-Term and Robot-Egocentric Dataset for Benchmarking Target Person Tracking", "authors": ["Hanjing Ye", "Yu Zhan", "Weixi Situ", "Guangcheng Chen", "Jingwen Yu", "Ziqi Zhao", "Kuanqi Cai", "Arash Ajoudani", "Hong Zhang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Under review. web: this https URL", "url": "http://arxiv.org/abs/2505.07446v2", "summary": "Tracking a target person from robot-egocentric views is crucial for\ndeveloping autonomous robots that provide continuous personalized assistance or\ncollaboration in Human-Robot Interaction (HRI) and Embodied AI. However, most\nexisting target person tracking (TPT) benchmarks are limited to controlled\nlaboratory environments with few distractions, clean backgrounds, and\nshort-term occlusions. In this paper, we introduce a large-scale dataset\ndesigned for TPT in crowded and unstructured environments, demonstrated through\na robot-person following task. The dataset is collected by a human pushing a\nsensor-equipped cart while following a target person, capturing human-like\nfollowing behavior and emphasizing long-term tracking challenges, including\nfrequent occlusions and the need for re-identification from numerous\npedestrians. It includes multi-modal data streams, including odometry, 3D\nLiDAR, IMU, panoramic images, and RGB-D images, along with exhaustively\nannotated 2D bounding boxes of the target person across 48 sequences, both\nindoors and outdoors. Using this dataset and visual annotations, we perform\nextensive experiments with existing SOTA TPT methods, offering a thorough\nanalysis of their limitations and suggesting future research directions.", "comment": "Under review. web: https://medlartea.github.io/tpt-bench/", "pdf_url": "http://arxiv.org/pdf/2505.07446v2", "cate": "cs.RO", "date": "2025-05-12", "updated": "2025-07-09"}
{"id": "2507.06639", "title": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision", "authors": ["Myungjang Pyeon", "Janghyeon Lee", "Minsoo Lee", "Juseung Yun", "Hwanil Choi", "Jonghyun Kim", "Jiwon Kim", "Yi Hu", "Jongseong Jang", "Soonyoung Lee"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      EXAONE Path 2.0 technical report", "url": "http://arxiv.org/abs/2507.06639v1", "summary": "In digital pathology, whole-slide images (WSIs) are often difficult to handle\ndue to their gigapixel scale, so most approaches train patch encoders via\nself-supervised learning (SSL) and then aggregate the patch-level embeddings\nvia multiple instance learning (MIL) or slide encoders for downstream tasks.\nHowever, patch-level SSL may overlook complex domain-specific features that are\nessential for biomarker prediction, such as mutation status and molecular\ncharacteristics, as SSL methods rely only on basic augmentations selected for\nnatural image domains on small patch-level area. Moreover, SSL methods remain\nless data efficient than fully supervised approaches, requiring extensive\ncomputational resources and datasets to achieve competitive performance. To\naddress these limitations, we present EXAONE Path 2.0, a pathology foundation\nmodel that learns patch-level representations under direct slide-level\nsupervision. Using only 37k WSIs for training, EXAONE Path 2.0 achieves\nstate-of-the-art average performance across 10 biomarker prediction tasks,\ndemonstrating remarkable data efficiency.", "comment": "EXAONE Path 2.0 technical report", "pdf_url": "http://arxiv.org/pdf/2507.06639v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06650", "title": "Deep Disentangled Representation Network for Treatment Effect Estimation", "authors": ["Hui Meng", "Keping Yang", "Xuyu Peng", "Bo Zheng"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Under Review", "url": "http://arxiv.org/abs/2507.06650v1", "summary": "Estimating individual-level treatment effect from observational data is a\nfundamental problem in causal inference and has attracted increasing attention\nin the fields of education, healthcare, and public policy.In this work, we\nconcentrate on the study of disentangled representation methods that have shown\npromising outcomes by decomposing observed covariates into instrumental,\nconfounding, and adjustment factors. However, most of the previous work has\nprimarily revolved around generative models or hard decomposition methods for\ncovariates, which often struggle to guarantee the attainment of precisely\ndisentangled factors. In order to effectively model different causal\nrelationships, we propose a novel treatment effect estimation algorithm that\nincorporates a mixture of experts with multi-head attention and a linear\northogonal regularizer to softly decompose the pre-treatment variables, and\nsimultaneously eliminates selection bias via importance sampling re-weighting\ntechniques. We conduct extensive experiments on both public semi-synthetic and\nreal-world production datasets. The experimental results clearly demonstrate\nthat our algorithm outperforms the state-of-the-art methods focused on\nindividual treatment effects.", "comment": "Under Review", "pdf_url": "http://arxiv.org/pdf/2507.06650v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06560", "title": "Divergence-Based Similarity Function for Multi-View Contrastive Learning", "authors": ["Jae Hyoung Jeon", "Cheolsu Lim", "Myungjoo Kang"], "categories": ["cs.CV", "cs.LG", "68T07, 62H12", "I.2.6; I.4.8; I.5.1"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures", "url": "http://arxiv.org/abs/2507.06560v1", "summary": "Recent success in contrastive learning has sparked growing interest in more\neffectively leveraging multiple augmented views of an instance. While prior\nmethods incorporate multiple views at the loss or feature level, they primarily\ncapture pairwise relationships and fail to model the joint structure across all\nviews. In this work, we propose a divergence-based similarity function (DSF)\nthat explicitly captures the joint structure by representing each set of\naugmented views as a distribution and measuring similarity as the divergence\nbetween distributions. Extensive experiments demonstrate that DSF consistently\nimproves performance across various tasks, including kNN classification and\nlinear evaluation, while also offering greater efficiency compared to other\nmulti-view methods. Furthermore, we establish a theoretical connection between\nDSF and cosine similarity, and show that, unlike cosine similarity, DSF\noperates effectively without requiring a temperature hyperparameter.", "comment": "9 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.06560v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2407.05260", "title": "Improved Channel Coding Performance Through Cost Variability", "authors": ["Adeel Mahmood", "Aaron B. Wagner"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.05260v3", "summary": "Channel coding for discrete memoryless channels (DMCs) with mean and variance\ncost constraints has been recently introduced. We show that there is an\nimprovement in coding performance due to cost variability, both with and\nwithout feedback. We demonstrate this improvement over the traditional\nalmost-sure (per-codeword) cost constraint that prohibits any cost variation\nabove a fixed threshold. Our result simultaneously shows that feedback does not\nimprove the second-order coding rate of simple-dispersion DMCs under the\nalmost-sure cost constraint. This finding parallels similar results for\nunconstrained simple-dispersion DMCs, additive white Gaussian noise (AWGN)\nchannels and parallel Gaussian channels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.05260v3", "cate": "cs.IT", "date": "2024-07-07", "updated": "2025-07-09"}
{"id": "2507.04969", "title": "Silent Failures in Stateless Systems: Rethinking Anomaly Detection for Serverless Computing", "authors": ["Chanh Nguyen", "Erik Elmroth", "Monowar Bhuyan"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      12 pages, 6 figures, Preprint", "url": "http://arxiv.org/abs/2507.04969v2", "summary": "Serverless computing has redefined cloud application deployment by\nabstracting infrastructure and enabling on-demand, event-driven execution,\nthereby enhancing developer agility and scalability. However, maintaining\nconsistent application performance in serverless environments remains a\nsignificant challenge. The dynamic and transient nature of serverless functions\nmakes it difficult to distinguish between benign and anomalous behavior, which\nin turn undermines the effectiveness of traditional anomaly detection methods.\nThese conventional approaches, designed for stateful and long-running services,\nstruggle in serverless settings where executions are short-lived, functions are\nisolated, and observability is limited.\n  In this first comprehensive vision paper on anomaly detection for serverless\nsystems, we systematically explore the unique challenges posed by this\nparadigm, including the absence of persistent state, inconsistent monitoring\ngranularity, and the difficulty of correlating behaviors across distributed\nfunctions. We further examine a range of threats that manifest as anomalies,\nfrom classical Denial-of-Service (DoS) attacks to serverless-specific threats\nsuch as Denial-of-Wallet (DoW) and cold start amplification. Building on these\nobservations, we articulate a research agenda for next-generation detection\nframeworks that address the need for context-aware, multi-source data fusion,\nreal-time, lightweight, privacy-preserving, and edge-cloud adaptive\ncapabilities.\n  Through the identification of key research directions and design principles,\nwe aim to lay the foundation for the next generation of anomaly detection in\ncloud-native, serverless ecosystems.", "comment": "12 pages, 6 figures, Preprint", "pdf_url": "http://arxiv.org/pdf/2507.04969v2", "cate": "cs.DC", "date": "2025-07-07", "updated": "2025-07-09"}
{"id": "2507.06876", "title": "Winning and losing with Artificial Intelligence: What public discourse about ChatGPT tells us about how societies make sense of technological change", "authors": ["Adrian Rauchfleisch", "Joshua Philip Suarez", "Nikka Marie Sales", "Andreas Jungherr"], "categories": ["cs.CY", "cs.AI", "I.2; J.4; K.4.0"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06876v1", "summary": "Public product launches in Artificial Intelligence can serve as focusing\nevents for collective attention, surfacing how societies react to technological\nchange. Social media provide a window into the sensemaking around these events,\nsurfacing hopes and fears and showing who chooses to engage in the discourse\nand when. We demonstrate that public sensemaking about AI is shaped by economic\ninterests and cultural values of those involved. We analyze 3.8 million tweets\nposted by 1.6 million users across 117 countries in response to the public\nlaunch of ChatGPT in 2022. Our analysis shows how economic self-interest,\nproxied by occupational skill types in writing, programming, and mathematics,\nand national cultural orientations, as measured by Hofstede's individualism,\nuncertainty avoidance, and power distance dimensions, shape who speaks, when\nthey speak, and their stance towards ChatGPT. Roles requiring more technical\nskills, such as programming and mathematics, tend to engage earlier and express\nmore positive stances, whereas writing-centric occupations join later with\ngreater skepticism. At the cultural level, individualism predicts both earlier\nengagement and a more negative stance, and uncertainty avoidance reduces the\nprevalence of positive stances but does not delay when users first engage with\nChatGPT. Aggregate sentiment trends mask the dynamics observed in our study.\nThe shift toward a more critical stance towards ChatGPT over time stems\nprimarily from the entry of more skeptical voices rather than a change of heart\namong early adopters. Our findings underscore the importance of both the\noccupational background and cultural context in understanding public reactions\nto AI.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06876v1", "cate": "cs.CY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2506.01182", "title": "Humanoid World Models: Open World Foundation Models for Humanoid Robotics", "authors": ["Muhammad Qasim Ali", "Aditya Sridhar", "Shahbuland Matiana", "Alex Wong", "Mohammad Al-Sharman"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.01182v2", "summary": "Humanoid robots, with their human-like form, are uniquely suited for\ninteracting in environments built for people. However, enabling humanoids to\nreason, plan, and act in complex open-world settings remains a challenge. World\nmodels, models that predict the future outcome of a given action, can support\nthese capabilities by serving as a dynamics model in long-horizon planning and\ngenerating synthetic data for policy learning. We introduce Humanoid World\nModels (HWM), a family of lightweight, open-source models that forecast future\negocentric video conditioned on humanoid control tokens. We train two types of\ngenerative models, Masked Transformers and Flow-Matching, on 100 hours of\nhumanoid demonstrations. Additionally, we explore architectural variants with\ndifferent attention mechanisms and parameter-sharing strategies. Our\nparameter-sharing techniques reduce model size by 33-53% with minimal impact on\nperformance or visual fidelity. HWMs are designed to be trained and deployed in\npractical academic and small-lab settings, such as 1-2 GPUs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.01182v2", "cate": "cs.RO", "date": "2025-06-01", "updated": "2025-07-08"}
{"id": "2507.06654", "title": "MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval", "authors": ["Naoya Sogi", "Takashi Shibata", "Makoto Terao", "Masanori Suganuma", "Takayuki Okatani"], "categories": ["cs.CV", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      IJCAI 2025. Code: this https URL", "url": "http://arxiv.org/abs/2507.06654v1", "summary": "Result diversification (RD) is a crucial technique in Text-to-Image Retrieval\nfor enhancing the efficiency of a practical application. Conventional methods\nfocus solely on increasing the diversity metric of image appearances. However,\nthe diversity metric and its desired value vary depending on the application,\nwhich limits the applications of RD. This paper proposes a novel task called\nCDR-CA (Contextual Diversity Refinement of Composite Attributes). CDR-CA aims\nto refine the diversities of multiple attributes, according to the\napplication's context. To address this task, we propose Multi-Source DPPs, a\nsimple yet strong baseline that extends the Determinantal Point Process (DPP)\nto multi-sources. We model MS-DPP as a single DPP model with a unified\nsimilarity matrix based on a manifold representation. We also introduce Tangent\nNormalization to reflect contexts. Extensive experiments demonstrate the\neffectiveness of the proposed method. Our code is publicly available at\nhttps://github.com/NEC-N-SOGI/msdpp.", "comment": "IJCAI 2025. Code: https://github.com/NEC-N-SOGI/msdpp", "pdf_url": "http://arxiv.org/pdf/2507.06654v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06652", "title": "Federated Learning Inspired Fuzzy Systems: Decentralized Rule Updating for Privacy and Scalable Decision Making", "authors": ["Arthur Alexander Lim", "Zhen Bin It", "Jovan Bowen Heng", "Tee Hui Teo"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06652v1", "summary": "Fuzzy systems are a way to allow machines, systems and frameworks to deal\nwith uncertainty, which is not possible in binary systems that most computers\nuse. These systems have already been deployed for certain use cases, and fuzzy\nsystems could be further improved as proposed in this paper. Such technologies\nto draw inspiration from include machine learning and federated learning.\nMachine learning is one of the recent breakthroughs of technology and could be\napplied to fuzzy systems to further improve the results it produces. Federated\nlearning is also one of the recent technologies that have huge potential, which\nallows machine learning training to improve by reducing privacy risk, reducing\nburden on networking infrastructure, and reducing latency of the latest model.\nAspects from federated learning could be used to improve federated learning,\nsuch as applying the idea of updating the fuzzy rules that make up a key part\nof fuzzy systems, to further improve it over time. This paper discusses how\nthese improvements would be implemented in fuzzy systems, and how it would\nimprove fuzzy systems. It also discusses certain limitations on the potential\nimprovements. It concludes that these proposed ideas and improvements require\nfurther investigation to see how far the improvements are, but the potential is\nthere to improve fuzzy systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06652v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06569", "title": "Edge-Boundary-Texture Loss: A Tri-Class Generalization of Weighted Binary Cross-Entropy for Enhanced Edge Detection", "authors": ["Hao Shu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.06569v1", "summary": "Edge detection (ED) remains a fundamental task in computer vision, yet its\nperformance is often hindered by the ambiguous nature of non-edge pixels near\nobject boundaries. The widely adopted Weighted Binary Cross-Entropy (WBCE) loss\ntreats all non-edge pixels uniformly, overlooking the structural nuances around\nedges and often resulting in blurred predictions. In this paper, we propose the\nEdge-Boundary-Texture (EBT) loss, a novel objective that explicitly divides\npixels into three categories, edge, boundary, and texture, and assigns each a\ndistinct supervisory weight. This tri-class formulation enables more structured\nlearning by guiding the model to focus on both edge precision and contextual\nboundary localization. We theoretically show that the EBT loss generalizes the\nWBCE loss, with the latter becoming a limit case. Extensive experiments across\nmultiple benchmarks demonstrate the superiority of the EBT loss both\nquantitatively and perceptually. Furthermore, the consistent use of unified\nhyperparameters across all models and datasets, along with robustness to their\nmoderate variations, indicates that the EBT loss requires minimal fine-tuning\nand is easily deployable in practice.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.06569v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2409.10410", "title": "Sharp Estimates for Optimal Multistage Group Partition Testing", "authors": ["Guojiang Shao"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.10410v3", "summary": "In multistage group testing, the tests within the same stage are considered\nnonadaptive, while those conducted across different stages are adaptive.\nSpecifically, when the pools within the same stage are disjoint, meaning that\nthe entire set is divided into several disjoint subgroups, it is referred to as\na multistage group partition testing problem, denoted as the (n, d, s) problem,\nwhere n, d, and s represent the total number of items, defectives, and stages\nrespectively. This paper presents exact solutions for the (n, 1, s) and (n, d,\n2) problems for the first time. Additionally, a general dynamic programming\napproach is developed for the (n, d, s) problem. Significantly we give the\nsharp upper and lower bounds estimates. If the defective number in unknown but\nbounded, we can provide an algorithm with an optimal competitive ratio in the\nasymptotic sense. While assuming the prior distribution of the defective items,\nwe also establish a well performing upper and lower bound estimate to the\nexpectation of optimal strategy", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.10410v3", "cate": "cs.IT", "date": "2024-09-16", "updated": "2025-07-09"}
{"id": "2309.05331", "title": "Integrating Odeint Time Stepping into OpenFPM for Distributed and GPU Accelerated Numerical Solvers", "authors": ["Abhinav Singh", "Landfried Kraatz", "Serhii Yaskovets", "Pietro Incardona", "Ivo F. Sbalzarini"], "categories": ["cs.MS", "cs.DC"], "primary_category": "Subjects:       Mathematical Software (cs.MS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2309.05331v2", "summary": "We present a software implementation integrating the time-integration library\nOdeint from Boost with the OpenFPM framework for scalable scientific computing.\nThis enables compact and scalable codes for multi-stage, multi-step, and\nadaptive explicit time integration on distributed-memory parallel computers and\non Graphics Processing Units (GPUs). The present implementation is based on\nextending OpenFPM's metaprogramming system to Odeint data types. This makes the\ntime-integration methods from Odeint available in a concise template-expression\nlanguage for numerical simulations distributed and parallelized using OpenFPM.\nWe benchmark the present software for exponential and sigmoidal dynamics and\npresent application examples to the 3D Gray-Scott reaction-diffusion problem\nand the \"dam break\" problem from fluid mechanics. We find a strong-scaling\nefficiency of 80% on up to 512 CPU cores and a five-fold speedup on a single\nGPU.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2309.05331v2", "cate": "cs.MS", "date": "2023-09-11", "updated": "2025-07-09"}
{"id": "2507.07059", "title": "Girlhood Feminism as Soft Resistance: Affective Counterpublics and Algorithmic Negotiation on RedNote", "authors": ["Meng Liang", "Xiaoyue Zhang", "Linqi Ye"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      19 pages, 6 figures, AoIR Conference 2025", "url": "http://arxiv.org/abs/2507.07059v1", "summary": "This article explores how Chinese female users tactically mobilise platform\nfeatures and hashtag practices to construct vernacular forms and an exclusive\nspace of feminist resistance under algorithmic and cultural constraints.\nFocusing on the reappropriation of the hashtag Baby Supplementary Food (BSF), a\nfemale-dominated lifestyle app with over 300 million users, we analyse how\nusers create a female-centered counterpublic through self-infantilisation,\nalgorithmic play, and aesthetic withdrawal. Using the Computer-Assisted\nLearning and Measurement (CALM) framework, we analysed 1580 posts and propose\nthe concept of girlhood feminism: an affective, culturally grounded form of\nsoft resistance that refuses patriarchal life scripts without seeking direct\nconfrontation or visibility. Rather than challenging censorship and misogyny\ndirectly, users rework platform affordances and domestic idioms to carve out\nemotional and symbolic spaces of dissent. Situated within the broader dynamics\nof East Asia's compressed modernity, this essay challenges liberal feminist\nparadigms grounded in confrontation and transparency. It advances a regionally\ngrounded framework for understanding how gendered publics are navigated,\nnegotiated, and quietly reimagined in algorithmically governed spaces.", "comment": "19 pages, 6 figures, AoIR Conference 2025", "pdf_url": "http://arxiv.org/pdf/2507.07059v1", "cate": "cs.CY", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06351", "title": "Development and Real-World Application of Commercial Motor Vehicle Safety Enforcement Dashboards", "authors": ["Dhairya Parekh", "Mark L. Franz Ph. D", "Sara Zahedian Ph. D", "Narjes Shayesteh"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      Presented at Transportation Research Board Annual Meeting 2025. Presentation number: TRBAM-25-04350", "url": "http://arxiv.org/abs/2507.06351v1", "summary": "Commercial Motor Vehicle (CMV) safety is crucial in traffic management and\npublic safety. CMVs account for numerous traffic incidents, so monitoring CMV\nsafety and safety inspections is essential for ensuring safe and efficient\nhighway movement. This paper presents the development and real-world\napplication of CMV dashboards designed under the guidance of CMV safety\nenforcement professionals from the Maryland State Police (MSP), the Maryland\nDepartment of Transportation - State Highway Administration (MDOT - SHA), and\nthe Federal Motor Carrier Safety Administration (FMCSA) to enable intuitive and\nefficient analysis of CMV safety performance measures. First, three CMV safety\ndashboards enable CMV safety professionals to identify sites with a history of\nsafety performance issues. A supplemental dashboard automates the analysis of\nCMV enforcement initiatives using the same performance measures. These\nperformance measures are based on CMV probe vehicle speeds, inspection/citation\ndata from Truck Weigh and Inspection Stations (TWIS), patrolling enforcement,\nand Virtual Weigh Stations (VWS). The authors collaborated with MSP to identify\na portion of I-81 in Maryland, susceptible to improvement from targeted CMV\nenforcement. The supplemental enforcement assessment dashboard was employed to\nevaluate the impact of enforcement, including the post-enforcement halo effect.\nThe results of the post-enforcement evaluation were mixed, indicating a need\nfor more fine-grained citation data.", "comment": "Presented at Transportation Research Board Annual Meeting 2025.\n  Presentation number: TRBAM-25-04350", "pdf_url": "http://arxiv.org/pdf/2507.06351v1", "cate": "cs.CE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.14608", "title": "Latent Action Diffusion for Cross-Embodiment Manipulation", "authors": ["Erik Bauer", "Elvis Nava", "Robert K. Katzschmann"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      15 pages, 7 figures", "url": "http://arxiv.org/abs/2506.14608v2", "summary": "End-to-end learning approaches offer great potential for robotic\nmanipulation, but their impact is constrained by data scarcity and\nheterogeneity across different embodiments. In particular, diverse action\nspaces across different end-effectors create barriers for cross-embodiment\nlearning and skill transfer. We address this challenge through diffusion\npolicies learned in a latent action space that unifies diverse end-effector\nactions. We first show that we can learn a semantically aligned latent action\nspace for anthropomorphic robotic hands, a human hand, and a parallel jaw\ngripper using encoders trained with a contrastive loss. Second, we show that by\nusing our proposed latent action space for co-training on manipulation data\nfrom different end-effectors, we can utilize a single policy for multi-robot\ncontrol and obtain up to 25% improved manipulation success rates, indicating\nsuccessful skill transfer despite a significant embodiment gap. Our approach\nusing latent cross-embodiment policies presents a new method to unify different\naction spaces across embodiments, enabling efficient multi-robot control and\ndata sharing across robot setups. This unified representation significantly\nreduces the need for extensive data collection for each new robot morphology,\naccelerates generalization across embodiments, and ultimately facilitates more\nscalable and efficient robotic learning.", "comment": "15 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2506.14608v2", "cate": "cs.RO", "date": "2025-06-17", "updated": "2025-07-09"}
{"id": "2507.06658", "title": "Elite Polarization in European Parliamentary Speeches: a Novel Measurement Approach Using Large Language Models", "authors": ["Gennadii Iakovlev"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06658v1", "summary": "This project introduces a new measure of elite polarization via actor and\nsubject detection using artificial intelligence. I identify when politicians\nmention one another in parliamentary speeches, note who is speaking and who is\nbeing addressed, and assess the emotional temperature behind these evaluations.\nThis maps how elites evaluate their various out-parties, allowing us to create\nan index of mutual out-party hostility, that is, elite polarization. While I\nanalyzed polarization data over the past four decades for the UK, and two\ndecades for Hungary and Italy, my approach lays the groundwork for a\ntwenty-year, EU-wide time-series dataset on elite polarization. I obtain the\nresults that can be aggregated by party and quarter. The resulting index\ndemonstrates a good face validity: it reacts to events such as electoral\ncampaigns, country- and party-level crises, and to parties losing and assuming\npower.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06658v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06694", "title": "Heterogeneous Graph Neural Networks for Short-term State Forecasting in Power Systems across Domains and Time Scales: A Hydroelectric Power Plant Case Study", "authors": ["Raffael Theiler", "Olga Fink"], "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      25 pages, 9 figures", "url": "http://arxiv.org/abs/2507.06694v1", "summary": "Accurate short-term state forecasting is essential for efficient and stable\noperation of modern power systems, especially in the context of increasing\nvariability introduced by renewable and distributed energy resources. As these\nsystems evolve rapidly, it becomes increasingly important to reliably predict\ntheir states in the short term to ensure operational stability, support control\ndecisions, and enable interpretable monitoring of sensor and machine behavior.\nModern power systems often span multiple physical domains - including\nelectrical, mechanical, hydraulic, and thermal - posing significant challenges\nfor modeling and prediction. Graph Neural Networks (GNNs) have emerged as a\npromising data-driven framework for system state estimation and state\nforecasting in such settings. By leveraging the topological structure of sensor\nnetworks, GNNs can implicitly learn inter-sensor relationships and propagate\ninformation across the network. However, most existing GNN-based methods are\ndesigned under the assumption of homogeneous sensor relationships and are\ntypically constrained to a single physical domain. This limitation restricts\ntheir ability to integrate and reason over heterogeneous sensor data commonly\nencountered in real-world energy systems, such as those used in energy\nconversion infrastructure. In this work, we propose the use of Heterogeneous\nGraph Attention Networks to address these limitations. Our approach models both\nhomogeneous intra-domain and heterogeneous inter-domain relationships among\nsensor data from two distinct physical domains - hydraulic and electrical -\nwhich exhibit fundamentally different temporal dynamics. Experimental results\ndemonstrate that our method significantly outperforms conventional baselines on\naverage by 35.5% in terms of normalized root mean square error, confirming its\neffectiveness in multi-domain, multi-rate power system state forecasting.", "comment": "25 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.06694v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06590", "title": "MOST: Motion Diffusion Model for Rare Text via Temporal Clip Banzhaf Interaction", "authors": ["Yin Wang", "Mu li", "Zhiying Leng", "Frederick W. B. Li", "Xiaohui Liang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06590v1", "summary": "We introduce MOST, a novel motion diffusion model via temporal clip Banzhaf\ninteraction, aimed at addressing the persistent challenge of generating human\nmotion from rare language prompts. While previous approaches struggle with\ncoarse-grained matching and overlook important semantic cues due to motion\nredundancy, our key insight lies in leveraging fine-grained clip relationships\nto mitigate these issues. MOST's retrieval stage presents the first formulation\nof its kind - temporal clip Banzhaf interaction - which precisely quantifies\ntextual-motion coherence at the clip level. This facilitates direct,\nfine-grained text-to-motion clip matching and eliminates prevalent redundancy.\nIn the generation stage, a motion prompt module effectively utilizes retrieved\nmotion clips to produce semantically consistent movements. Extensive\nevaluations confirm that MOST achieves state-of-the-art text-to-motion\nretrieval and generation performance by comprehensively addressing previous\nchallenges, as demonstrated through quantitative and qualitative results\nhighlighting its effectiveness, especially for rare prompts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06590v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2506.15167", "title": "LLM Agent for Hyper-Parameter Optimization", "authors": ["Wanzhe Wang", "Jianqiu Peng", "Menghao Hu", "Weihuang Zhong", "Tong Zhang", "Shuai Wang", "Yixin Zhang", "Mingjie Shao", "Wanli Ni"], "categories": ["cs.IT", "cs.AI", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      6 pages, 6 figures", "url": "http://arxiv.org/abs/2506.15167v2", "summary": "Hyper-parameters are essential and critical for the performance of\ncommunication algorithms. However, current hyper-parameters optimization\napproaches for Warm-Start Particles Swarm Optimization with Crossover and\nMutation (WS-PSO-CM) algorithm, designed for radio map-enabled unmanned aerial\nvehicle (UAV) trajectory and communication, are primarily heuristic-based,\nexhibiting low levels of automation and improvable performance. In this paper,\nwe design an Large Language Model (LLM) agent for automatic\nhyper-parameters-tuning, where an iterative framework and Model Context\nProtocol (MCP) are applied. In particular, the LLM agent is first set up via a\nprofile, which specifies the boundary of hyper-parameters, task objective,\nterminal condition, conservative or aggressive strategy of optimizing\nhyper-parameters, and LLM configurations. Then, the LLM agent iteratively\ninvokes WS-PSO-CM algorithm for exploration. Finally, the LLM agent exits the\nloop based on the terminal condition and returns an optimized set of\nhyperparameters. Our experiment results show that the minimal sum-rate achieved\nby hyper-parameters generated via our LLM agent is significantly higher than\nthose by both human heuristics and random generation methods. This indicates\nthat an LLM agent with PSO and WS-PSO-CM algorithm knowledge is useful in\nseeking high-performance hyper-parameters.", "comment": "6 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2506.15167v2", "cate": "cs.IT", "date": "2025-06-18", "updated": "2025-07-09"}
{"id": "2502.03108", "title": "Multi-objective methods in Federated Learning: A survey and taxonomy", "authors": ["Maria Hartmann", "Grégoire Danoy", "Pascal Bouvry"], "categories": ["cs.LG", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.03108v2", "summary": "The Federated Learning paradigm facilitates effective distributed machine\nlearning in settings where training data is decentralized across multiple\nclients. As the popularity of the strategy grows, increasingly complex\nreal-world problems emerge, many of which require balancing conflicting demands\nsuch as fairness, utility, and resource consumption. Recent works have begun to\nrecognise the use of a multi-objective perspective in answer to this challenge.\nHowever, this novel approach of combining federated methods with\nmulti-objective optimisation has never been discussed in the broader context of\nboth fields. In this work, we offer a first clear and systematic overview of\nthe different ways the two fields can be integrated. We propose a first\ntaxonomy on the use of multi-objective methods in connection with Federated\nLearning, providing a targeted survey of the state-of-the-art and proposing\nunambiguous labels to categorise contributions. Given the developing nature of\nthis field, our taxonomy is designed to provide a solid basis for further\nresearch, capturing existing works while anticipating future additions.\nFinally, we outline open challenges and possible directions for further\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.03108v2", "cate": "cs.LG", "date": "2025-02-05", "updated": "2025-07-09"}
{"id": "2507.06910", "title": "Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues", "authors": ["Fareya Ikram", "Alexander Scarlatos", "Andrew Lan"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Published in BEA 2025: 20th Workshop on Innovative Use of NLP for Building Educational Applications", "url": "http://arxiv.org/abs/2507.06910v1", "summary": "Tutoring dialogues have gained significant attention in recent years, given\nthe prominence of online learning and the emerging tutoring abilities of\nartificial intelligence (AI) agents powered by large language models (LLMs).\nRecent studies have shown that the strategies used by tutors can have\nsignificant effects on student outcomes, necessitating methods to predict how\ntutors will behave and how their actions impact students. However, few works\nhave studied predicting tutor strategy in dialogues. Therefore, in this work we\ninvestigate the ability of modern LLMs, particularly Llama 3 and GPT-4o, to\npredict both future tutor moves and student outcomes in dialogues, using two\nmath tutoring dialogue datasets. We find that even state-of-the-art LLMs\nstruggle to predict future tutor strategy while tutor strategy is highly\nindicative of student outcomes, outlining a need for more powerful methods to\napproach this task.", "comment": "Published in BEA 2025: 20th Workshop on Innovative Use of NLP for\n  Building Educational Applications", "pdf_url": "http://arxiv.org/pdf/2507.06910v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06444", "title": "Eyes on the Road, Mind Beyond Vision: Context-Aware Multi-modal Enhanced Risk Anticipation", "authors": ["Jiaxun Zhang", "Haicheng Liao", "Yumu Xie", "Chengyue Wang", "Yanchen Guan", "Bin Rao", "Zhenning Li"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      Accepted by ACMMM2025", "url": "http://arxiv.org/abs/2507.06444v1", "summary": "Accurate accident anticipation remains challenging when driver cognition and\ndynamic road conditions are underrepresented in predictive models. In this\npaper, we propose CAMERA (Context-Aware Multi-modal Enhanced Risk\nAnticipation), a multi-modal framework integrating dashcam video, textual\nannotations, and driver attention maps for robust accident anticipation. Unlike\nexisting methods that rely on static or environment-centric thresholds, CAMERA\nemploys an adaptive mechanism guided by scene complexity and gaze entropy,\nreducing false alarms while maintaining high recall in dynamic, multi-agent\ntraffic scenarios. A hierarchical fusion pipeline with Bi-GRU (Bidirectional\nGRU) captures spatio-temporal dependencies, while a Geo-Context Vision-Language\nmodule translates 3D spatial relationships into interpretable, human-centric\nalerts. Evaluations on the DADA-2000 and benchmarks show that CAMERA achieves\nstate-of-the-art performance, improving accuracy and lead time. These results\ndemonstrate the effectiveness of modeling driver attention, contextual\ndescription, and adaptive risk thresholds to enable more reliable accident\nanticipation.", "comment": "Accepted by ACMMM2025", "pdf_url": "http://arxiv.org/pdf/2507.06444v1", "cate": "cs.CE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.04004", "title": "Gaussian-LIC2: LiDAR-Inertial-Camera Gaussian Splatting SLAM", "authors": ["Xiaolei Lang", "Jiajun Lv", "Kai Tang", "Laijian Li", "Jianxin Huang", "Lina Liu", "Yong Liu", "Xingxing Zuo"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04004v2", "summary": "This paper presents the first photo-realistic LiDAR-Inertial-Camera Gaussian\nSplatting SLAM system that simultaneously addresses visual quality, geometric\naccuracy, and real-time performance. The proposed method performs robust and\naccurate pose estimation within a continuous-time trajectory optimization\nframework, while incrementally reconstructing a 3D Gaussian map using camera\nand LiDAR data, all in real time. The resulting map enables high-quality,\nreal-time novel view rendering of both RGB images and depth maps. To\neffectively address under-reconstruction in regions not covered by the LiDAR,\nwe employ a lightweight zero-shot depth model that synergistically combines RGB\nappearance cues with sparse LiDAR measurements to generate dense depth maps.\nThe depth completion enables reliable Gaussian initialization in LiDAR-blind\nareas, significantly improving system applicability for sparse LiDAR sensors.\nTo enhance geometric accuracy, we use sparse but precise LiDAR depths to\nsupervise Gaussian map optimization and accelerate it with carefully designed\nCUDA-accelerated strategies. Furthermore, we explore how the incrementally\nreconstructed Gaussian map can improve the robustness of odometry. By tightly\nincorporating photometric constraints from the Gaussian map into the\ncontinuous-time factor graph optimization, we demonstrate improved pose\nestimation under LiDAR degradation scenarios. We also showcase downstream\napplications via extending our elaborate system, including video frame\ninterpolation and fast 3D mesh extraction. To support rigorous evaluation, we\nconstruct a dedicated LiDAR-Inertial-Camera dataset featuring ground-truth\nposes, depth maps, and extrapolated trajectories for assessing out-of-sequence\nnovel view synthesis. Both the dataset and code will be made publicly available\non project page https://xingxingzuo.github.io/gaussian_lic2.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04004v2", "cate": "cs.RO", "date": "2025-07-05", "updated": "2025-07-09"}
{"id": "2507.06674", "title": "Exploring State-Space-Model based Language Model in Music Generation", "authors": ["Wei-Jaw Lee", "Fang-Chih Hsieh", "Xuanjun Chen", "Fang-Duo Tsai", "Yi-Hsuan Yang"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted at ISMIR 2025 as Late-Breaking Demo (LBD)", "url": "http://arxiv.org/abs/2507.06674v1", "summary": "The recent surge in State Space Models (SSMs), particularly the emergence of\nMamba, has established them as strong alternatives or complementary modules to\nTransformers across diverse domains. In this work, we aim to explore the\npotential of Mamba-based architectures for text-to-music generation. We adopt\ndiscrete tokens of Residual Vector Quantization (RVQ) as the modeling\nrepresentation and empirically find that a single-layer codebook can capture\nsemantic information in music. Motivated by this observation, we focus on\nmodeling a single-codebook representation and adapt SiMBA, originally designed\nas a Mamba-based encoder, to function as a decoder for sequence modeling. We\ncompare its performance against a standard Transformer-based decoder. Our\nresults suggest that, under limited-resource settings, SiMBA achieves much\nfaster convergence and generates outputs closer to the ground truth. This\ndemonstrates the promise of SSMs for efficient and expressive text-to-music\ngeneration. We put audio examples on Github.", "comment": "Accepted at ISMIR 2025 as Late-Breaking Demo (LBD)", "pdf_url": "http://arxiv.org/pdf/2507.06674v1", "cate": "cs.SD", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06701", "title": "Value from Observations: Towards Large-Scale Imitation Learning via Self-Improvement", "authors": ["Michael Bloesch", "Markus Wulfmeier", "Philemon Brakel", "Todor Davchev", "Martina Zambelli", "Jost Tobias Springenberg", "Abbas Abdolmaleki", "William F Whitney", "Nicolas Heess", "Roland Hafner", "Martin Riedmiller"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06701v1", "summary": "Imitation Learning from Observation (IfO) offers a powerful way to learn\nbehaviors at large-scale: Unlike behavior cloning or offline reinforcement\nlearning, IfO can leverage action-free demonstrations and thus circumvents the\nneed for costly action-labeled demonstrations or reward functions. However,\ncurrent IfO research focuses on idealized scenarios with mostly bimodal-quality\ndata distributions, restricting the meaningfulness of the results. In contrast,\nthis paper investigates more nuanced distributions and introduces a method to\nlearn from such data, moving closer to a paradigm in which imitation learning\ncan be performed iteratively via self-improvement. Our method adapts RL-based\nimitation learning to action-free demonstrations, using a value function to\ntransfer information between expert and non-expert data. Through comprehensive\nevaluation, we delineate the relation between different data distributions and\nthe applicability of algorithms and highlight the limitations of established\nmethods. Our findings provide valuable insights for developing more robust and\npractical IfO techniques on a path to scalable behaviour learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06701v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06592", "title": "Ambiguity-aware Point Cloud Segmentation by Adaptive Margin Contrastive Learning", "authors": ["Yang Chen", "Yueqi Duan", "Haowen Sun", "Jiwen Lu", "Yap-Peng Tan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This article has been accepted for publication in IEEE Transactions on Multimedia. arXiv admin note: text overlap with arXiv:2502.04111", "url": "http://arxiv.org/abs/2507.06592v1", "summary": "This paper proposes an adaptive margin contrastive learning method for 3D\nsemantic segmentation on point clouds. Most existing methods use equally\npenalized objectives, which ignore the per-point ambiguities and less\ndiscriminated features stemming from transition regions. However, as highly\nambiguous points may be indistinguishable even for humans, their manually\nannotated labels are less reliable, and hard constraints over these points\nwould lead to sub-optimal models. To address this, we first design\nAMContrast3D, a method comprising contrastive learning into an ambiguity\nestimation framework, tailored to adaptive objectives for individual points\nbased on ambiguity levels. As a result, our method promotes model training,\nwhich ensures the correctness of low-ambiguity points while allowing mistakes\nfor high-ambiguity points. As ambiguities are formulated based on position\ndiscrepancies across labels, optimization during inference is constrained by\nthe assumption that all unlabeled points are uniformly unambiguous, lacking\nambiguity awareness. Inspired by the insight of joint training, we further\npropose AMContrast3D++ integrating with two branches trained in parallel, where\na novel ambiguity prediction module concurrently learns point ambiguities from\ngenerated embeddings. To this end, we design a masked refinement mechanism that\nleverages predicted ambiguities to enable the ambiguous embeddings to be more\nreliable, thereby boosting segmentation performance and enhancing robustness.\nExperimental results on 3D indoor scene datasets, S3DIS and ScanNet,\ndemonstrate the effectiveness of the proposed method. Code is available at\nhttps://github.com/YangChenApril/AMContrast3D.", "comment": "This article has been accepted for publication in IEEE Transactions\n  on Multimedia. arXiv admin note: text overlap with arXiv:2502.04111", "pdf_url": "http://arxiv.org/pdf/2507.06592v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.04209", "title": "Mutual Information Bounds for Lossy Common Information", "authors": ["Anderson de Andrade"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04209v2", "summary": "We show the mutual information between the targets in a Gray-Wyner Network as\na bound that separates Wyner's lossy common information and G\\'acs-K\\\"orner\nlossy common information. The results are a generalization of the lossless case\npresented by Wyner (1975).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04209v2", "cate": "cs.IT", "date": "2025-07-06", "updated": "2025-07-08"}
{"id": "2505.00338", "title": "New Distributed Interactive Proofs for Planarity: A Matter of Left and Right", "authors": ["Yuval Gil", "Merav Parter"], "categories": ["cs.DS", "cs.DC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Under submission", "url": "http://arxiv.org/abs/2505.00338v3", "summary": "We provide new distributed interactive proofs (DIP) for planarity and related\ngraph families. The notion of a \\emph{distributed interactive proof} (DIP) was\nintroduced by Kol, Oshman, and Saxena (PODC 2018). In this setting, the\nverifier consists of $n$ nodes connected by a communication graph $G$. The\nprover is a single entity that communicates with all nodes by short messages.\nThe goal is to verify that the graph $G$ satisfies a certain property (e.g.,\nplanarity) in a small number of rounds, and with a small communication bound,\ndenoted as the \\emph{proof size}.\n  Prior work by Naor, Parter and Yogev (SODA 2020) presented a DIP for\nplanarity that uses three interaction rounds and a proof size of $O(\\log n)$.\nFeuilloley et al.\\ (PODC 2020) showed that the same can be achieved with a\nsingle interaction round and without randomization, by providing a proof\nlabeling scheme with a proof size of $O(\\log n)$. In a subsequent work,\nBousquet, Feuilloley, and Pierron (OPODIS 2021) achieved the same bound for\nrelated graph families such as outerplanarity, series-parallel graphs, and\ngraphs of treewidth at most $2$. In this work, we design new DIPs that use\nexponentially shorter proofs compared to the state-of-the-art bounds.", "comment": "Under submission", "pdf_url": "http://arxiv.org/pdf/2505.00338v3", "cate": "cs.DS", "date": "2025-05-01", "updated": "2025-07-09"}
{"id": "2306.08418", "title": "Welcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem", "authors": ["Emmanouil Papadogiannakis", "Nicolas Kourtellis", "Panagiotis Papadopoulos", "Evangelos P. Markatos"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2306.08418v3", "summary": "The online advertising market has recently reached the 500 billion dollar\nmark. To accommodate the need to match a user with the highest bidder at a\nfraction of a second, it has moved towards a complex, automated and often\nopaque model that involves numerous agents and intermediaries. Stimulated by\nthe lack of transparency, but also the enormous potential profits, bad actors\nhave found ways to circumvent restrictions, and generate substantial revenue\nthat can support websites with objectionable or even illegal content.\n  In this work, we evaluate transparency Web standards and show how shady\nactors take advantage of gaps to absorb ad revenues while putting the brand\nsafety of advertisers in danger. We collect and study a large corpus of\nthousands of websites and show how ad transparency standards can be abused by\nbad actors to obscure ad revenue flows. We show how identifier pooling can\nredirect ad revenues from reputable domains to notorious domains serving\nobjectionable content, and that the phenomenon is underestimated by previous\nstudies by a factor of 15. Finally, we publish a Web monitoring service that\nenhances the transparency of supply chains and business relationships between\npublishers and ad networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2306.08418v3", "cate": "cs.CY", "date": "2023-06-14", "updated": "2025-07-09"}
{"id": "2507.06383", "title": "Forex Trading Robot Using Fuzzy Logic", "authors": ["Mustafa Shabani", "Alireza Nasiri", "Hassan Nafardi"], "categories": ["eess.SY", "cs.CE", "cs.LO", "cs.SY", "I.2.1"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06383v1", "summary": "In this study, we propose a fuzzy system for conducting short-term\ntransactions in the forex market. The system is designed to enhance common\nstrategies in the forex market using fuzzy logic, thereby improving the\naccuracy of transactions. Traditionally, technical strategies based on\noscillator indicators have relied on predefined ranges for indicators such as\nRelative Strength Index (RSI), Commodity Channel Indicator (CCI), and\nStochastic to determine entry points for trades. However, the use of these\nclassic indicators has yielded suboptimal results due to the changing nature of\nthe market over time. In our proposed approach, instead of employing classical\nindicators, we introduce a fuzzy Mamdani system for each indicator. The results\nobtained from these systems are then combined through voting to design a\ntrading robot. Our findings demonstrate a considerable increase in the\nprofitability factor compared to three other methods. Additionally, net profit,\ngross profit, and maximum capital reduction are calculated and compared across\nall approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06383v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2503.02372", "title": "Label-Efficient LiDAR Panoptic Segmentation", "authors": ["Ahmet Selim Çanakçı", "Niclas Vödisch", "Kürsat Petek", "Wolfram Burgard", "Abhinav Valada"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2025", "url": "http://arxiv.org/abs/2503.02372v2", "summary": "A main bottleneck of learning-based robotic scene understanding methods is\nthe heavy reliance on extensive annotated training data, which often limits\ntheir generalization ability. In LiDAR panoptic segmentation, this challenge\nbecomes even more pronounced due to the need to simultaneously address both\nsemantic and instance segmentation from complex, high-dimensional point cloud\ndata. In this work, we address the challenge of LiDAR panoptic segmentation\nwith very few labeled samples by leveraging recent advances in label-efficient\nvision panoptic segmentation. To this end, we propose a novel method,\nLimited-Label LiDAR Panoptic Segmentation (L3PS), which requires only a minimal\namount of labeled data. Our approach first utilizes a label-efficient 2D\nnetwork to generate panoptic pseudo-labels from a small set of annotated\nimages, which are subsequently projected onto point clouds. We then introduce a\nnovel 3D refinement module that capitalizes on the geometric properties of\npoint clouds. By incorporating clustering techniques, sequential scan\naccumulation, and ground point separation, this module significantly enhances\nthe accuracy of the pseudo-labels, improving segmentation quality by up to\n+10.6 PQ and +7.9 mIoU. We demonstrate that these refined pseudo-labels can be\nused to effectively train off-the-shelf LiDAR segmentation networks. Through\nextensive experiments, we show that L3PS not only outperforms existing methods\nbut also substantially reduces the annotation burden. We release the code of\nour work at https://l3ps.cs.uni-freiburg.de.", "comment": "Accepted for the IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS), 2025", "pdf_url": "http://arxiv.org/pdf/2503.02372v2", "cate": "cs.CV", "date": "2025-03-04", "updated": "2025-07-09"}
{"id": "2507.06684", "title": "Photometric Stereo using Gaussian Splatting and inverse rendering", "authors": ["Matéo Ducastel", "David Tschumperlé", "Yvain Quéau"], "categories": ["eess.IV", "cs.AI"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      in French language. GRETSI 2025, Association GRETSI, Aug 2025, Strasbourg, France", "url": "http://arxiv.org/abs/2507.06684v1", "summary": "Recent state-of-the-art algorithms in photometric stereo rely on neural\nnetworks and operate either through prior learning or inverse rendering\noptimization. Here, we revisit the problem of calibrated photometric stereo by\nleveraging recent advances in 3D inverse rendering using the Gaussian Splatting\nformalism. This allows us to parameterize the 3D scene to be reconstructed and\noptimize it in a more interpretable manner. Our approach incorporates a\nsimplified model for light representation and demonstrates the potential of the\nGaussian Splatting rendering engine for the photometric stereo problem.", "comment": "in French language. GRETSI 2025, Association GRETSI, Aug 2025,\n  Strasbourg, France", "pdf_url": "http://arxiv.org/pdf/2507.06684v1", "cate": "eess.IV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06712", "title": "PINN-Obs: Physics-Informed Neural Network-Based Observer for Nonlinear Dynamical Systems", "authors": ["Ayoub Farkane", "Mohamed Boutayeb", "Mustapha Oudani", "Mounir Ghogho"], "categories": ["cs.LG", "math.DS", "nlin.CD"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06712v1", "summary": "State estimation for nonlinear dynamical systems is a critical challenge in\ncontrol and engineering applications, particularly when only partial and noisy\nmeasurements are available. This paper introduces a novel Adaptive\nPhysics-Informed Neural Network-based Observer (PINN-Obs) for accurate state\nestimation in nonlinear systems. Unlike traditional model-based observers,\nwhich require explicit system transformations or linearization, the proposed\nframework directly integrates system dynamics and sensor data into a\nphysics-informed learning process. The observer adaptively learns an optimal\ngain matrix, ensuring convergence of the estimated states to the true system\nstates. A rigorous theoretical analysis establishes formal convergence\nguarantees, demonstrating that the proposed approach achieves uniform error\nminimization under mild observability conditions. The effectiveness of PINN-Obs\nis validated through extensive numerical simulations on diverse nonlinear\nsystems, including an induction motor model, a satellite motion system, and\nbenchmark academic examples. Comparative experimental studies against existing\nobserver designs highlight its superior accuracy, robustness, and adaptability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06712v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06593", "title": "Capturing Stable HDR Videos Using a Dual-Camera System", "authors": ["Qianyu Zhang", "Bolun Zheng", "Hangjia Pan", "Lingyu Zhu", "Zunjie Zhu", "Zongpeng Li", "Shiqi Wang"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06593v1", "summary": "In HDR video reconstruction, exposure fluctuations in reference images from\nalternating exposure methods often result in flickering. To address this issue,\nwe propose a dual-camera system (DCS) for HDR video acquisition, where one\ncamera is assigned to capture consistent reference sequences, while the other\nis assigned to capture non-reference sequences for information supplementation.\nTo tackle the challenges posed by video data, we introduce an exposure-adaptive\nfusion network (EAFNet) to achieve more robust results. EAFNet introduced a\npre-alignment subnetwork to explore the influence of exposure, selectively\nemphasizing the valuable features across different exposure levels. Then, the\nenhanced features are fused by the asymmetric cross-feature fusion subnetwork,\nwhich explores reference-dominated attention maps to improve image fusion by\naligning cross-scale features and performing cross-feature fusion. Finally, the\nreconstruction subnetwork adopts a DWT-based multiscale architecture to reduce\nghosting artifacts and refine features at different resolutions. Extensive\nexperimental evaluations demonstrate that the proposed method achieves\nstate-of-the-art performance on different datasets, validating the great\npotential of the DCS in HDR video reconstruction. The codes and data captured\nby DCS will be available at https://github.com/zqqqyu/DCS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06593v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2402.04602", "title": "Online Quantile Regression", "authors": ["Yinan Shen", "Dong Xia", "Wen-Xin Zhou"], "categories": ["math.ST", "cs.IT", "math.IT", "stat.ME", "stat.TH"], "primary_category": "Subjects:       Statistics Theory (math.ST)", "pdf_link": null, "comments": "Comments:      The revised version substantially improves both the theory and the numeric experiments. In Theorem1 of the current manuscript, it only requires geometrically decaying step size, with great parameter flexibility. In the current manuscript, this noise moment assumption is significantly weakened to only require $\\EE|ξ|<+\\infty$", "url": "http://arxiv.org/abs/2402.04602v3", "summary": "This paper addresses the challenge of integrating sequentially arriving data\nwithin the quantile regression framework, where the number of features is\nallowed to grow with the number of observations, the horizon is unknown, and\nmemory is limited. We employ stochastic sub-gradient descent to minimize the\nempirical check loss and study its statistical properties and regret\nperformance. In our analysis, we unveil the delicate interplay between updating\niterates based on individual observations versus batches of observations,\nrevealing distinct regularity properties in each scenario. Our method ensures\nlong-term optimal estimation irrespective of the chosen update strategy.\nImportantly, our contributions go beyond prior works by achieving\nexponential-type concentration inequalities and attaining optimal regret and\nerror rates that exhibit only \\textsf{ short-term} sensitivity to initial\nerrors. A key insight from our study is the delicate statistical analyses and\nthe revelation that appropriate stepsize schemes significantly mitigate the\nimpact of initial errors on subsequent errors and regrets. This underscores the\nrobustness of stochastic sub-gradient descent in handling initial\nuncertainties, emphasizing its efficacy in scenarios where the sequential\narrival of data introduces uncertainties regarding both the horizon and the\ntotal number of observations. Additionally, when the initial error rate is\nwell-controlled, there is a trade-off between short-term error rate and\nlong-term optimality. Due to the lack of delicate statistical analysis for\nsquared loss, we also briefly discuss its properties and proper schemes.\nExtensive simulations support our theoretical findings.", "comment": "The revised version substantially improves both the theory and the\n  numeric experiments. In Theorem1 of the current manuscript, it only requires\n  geometrically decaying step size, with great parameter flexibility. In the\n  current manuscript, this noise moment assumption is significantly weakened to\n  only require $\\EE|\\xi|<+\\infty$", "pdf_url": "http://arxiv.org/pdf/2402.04602v3", "cate": "math.ST", "date": "2024-02-07", "updated": "2025-07-08"}
{"id": "2410.11369", "title": "Before & After: The Effect of EU's 2022 Code of Practice on Disinformation", "authors": ["Emmanouil Papadogiannakis", "Panagiotis Papadopoulos", "Nicolas Kourtellis", "Evangelos P. Markatos"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      WWW '25: Proceedings of the ACM on Web Conference 2025", "url": "http://arxiv.org/abs/2410.11369v2", "summary": "Over the past few years, the European Commission has made significant steps\nto reduce disinformation in cyberspace. One of those steps has been the\nintroduction of the 2022 \"Strengthened Code of Practice on Disinformation\".\nSigned by leading online platforms, this Strengthened Code of Practice on\nDisinformation is an attempt to combat disinformation on the Web. The Code of\nPractice includes a variety of measures including the demonetization of\ndisinformation, urging, for example, advertisers \"to avoid the placement of\nadvertising next to Disinformation content\".\n  In this work, we set out to explore what was the impact of the Code of\nPractice and especially to explore to what extent ad networks continue to\nadvertise on dis-/mis-information sites. We perform a historical analysis and\nfind that, although at a hasty glance things may seem to be improving, there is\nreally no significant reduction in the amount of advertising relationships\namong popular misinformation websites and major ad networks. In fact, we show\nthat ad networks have withdrawn mostly from unpopular misinformation websites\nwith very few visitors, but still form relationships with highly unreliable\nwebsites that account for the majority of misinformation traffic. To make\nmatters worse, we show that ad networks continue to place advertisements of\nlegitimate companies next to misinformation content. We show that major ad\nnetworks place ads in almost 400 misinformation websites in our dataset.", "comment": "WWW '25: Proceedings of the ACM on Web Conference 2025", "pdf_url": "http://arxiv.org/pdf/2410.11369v2", "cate": "cs.CY", "date": "2024-10-15", "updated": "2025-07-09"}
{"id": "2507.06803", "title": "Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams", "authors": ["Matthew Anderson Hendricks", "Alice Cicirello"], "categories": ["cs.CL", "cs.AI", "cs.CE"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06803v1", "summary": "This paper contributes to speeding up the design and deployment of\nengineering dynamical systems by proposing a strategy for exploiting domain and\nexpert knowledge for the automated generation of dynamical system computational\nmodel starting from a corpus of document relevant to the dynamical system of\ninterest and an input document describing the specific system. This strategy is\nimplemented in five steps and, crucially, it uses system modeling language\ndiagrams (SysML) to extract accurate information about the dependencies,\nattributes, and operations of components. Natural Language Processing (NLP)\nstrategies and Large Language Models (LLMs) are employed in specific tasks to\nimprove intermediate outputs of the SySML diagrams automated generation, such\nas: list of key nouns; list of extracted relationships; list of key phrases and\nkey relationships; block attribute values; block relationships; and BDD diagram\ngeneration. The applicability of automated SysML diagram generation is\nillustrated with different case studies. The computational models of complex\ndynamical systems from SysML diagrams are then obtained via code generation and\ncomputational model generation steps. In the code generation step, NLP\nstrategies are used for summarization, while LLMs are used for validation only.\nThe proposed approach is not limited to a specific system, domain, or\ncomputational software. The applicability of the proposed approach is shown via\nan end-to-end example from text to model of a simple pendulum, showing improved\nperformance compared to results yielded by LLMs only.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06803v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2503.02505", "title": "ROCKET-2: Steering Visuomotor Policy via Cross-View Goal Alignment", "authors": ["Shaofei Cai", "Zhancun Mu", "Anji Liu", "Yitao Liang"], "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.02505v2", "summary": "We aim to develop a goal specification method that is semantically clear,\nspatially sensitive, domain-agnostic, and intuitive for human users to guide\nagent interactions in 3D environments. Specifically, we propose a novel\ncross-view goal alignment framework that allows users to specify target objects\nusing segmentation masks from their camera views rather than the agent's\nobservations. We highlight that behavior cloning alone fails to align the\nagent's behavior with human intent when the human and agent camera views differ\nsignificantly. To address this, we introduce two auxiliary objectives:\ncross-view consistency loss and target visibility loss, which explicitly\nenhance the agent's spatial reasoning ability. According to this, we develop\nROCKET-2, a state-of-the-art agent trained in Minecraft, achieving an\nimprovement in the efficiency of inference 3x to 6x compared to ROCKET-1. We\nshow that ROCKET-2 can directly interpret goals from human camera views,\nenabling better human-agent interaction. Remarkably, ROCKET-2 demonstrates\nzero-shot generalization capabilities: despite being trained exclusively on the\nMinecraft dataset, it can adapt and generalize to other 3D environments like\nDoom, DMLab, and Unreal through a simple action space mapping.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.02505v2", "cate": "cs.AI", "date": "2025-03-04", "updated": "2025-07-09"}
{"id": "2507.06715", "title": "CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs", "authors": ["Garapati Keerthana", "Manik Gupta"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures", "url": "http://arxiv.org/abs/2507.06715v1", "summary": "Large language models (LLMs), including zero-shot and few-shot paradigms,\nhave shown promising capabilities in clinical text generation. However,\nreal-world applications face two key challenges: (1) patient data is highly\nunstructured, heterogeneous, and scattered across multiple note types and (2)\nclinical notes are often long and semantically dense, making naive prompting\ninfeasible due to context length constraints and the risk of omitting\nclinically relevant information.\n  We introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a\ndomain-specific framework for structured and clinically grounded text\ngeneration using LLMs. It incorporates a novel hierarchical chunking strategy\nthat respects clinical document structure and introduces a task-specific\ndual-stage retrieval mechanism. The global stage identifies relevant note types\nusing evidence-based queries, while the local stage extracts high-value content\nwithin those notes creating relevance at both document and section levels.\n  We apply the system to generate structured progress notes for individual\nhospital visits using 15 clinical note types from the MIMIC-III dataset.\nExperiments show that it preserves temporal and semantic alignment across\nvisits, achieving an average alignment score of 87.7%, surpassing the 80.7%\nbaseline from real clinician-authored notes. The generated outputs also\ndemonstrate high consistency across LLMs, reinforcing deterministic behavior\nessential for reproducibility, reliability, and clinical trust.", "comment": "12 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.06715v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06752", "title": "Mathematical artificial data for operator learning", "authors": ["Heng Wu", "Benzhuo Lu"], "categories": ["cs.LG", "cs.NA", "math.NA", "stat.ML", "68T07, 35J05", "I.2.6; G.1.8; G.4"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      22 pages, 5 figures", "url": "http://arxiv.org/abs/2507.06752v1", "summary": "Machine learning has emerged as a transformative tool for solving\ndifferential equations (DEs), yet prevailing methodologies remain constrained\nby dual limitations: data-driven methods demand costly labeled datasets while\nmodel-driven techniques face efficiency-accuracy trade-offs. We present the\nMathematical Artificial Data (MAD) framework, a new paradigm that integrates\nphysical laws with data-driven learning to facilitate large-scale operator\ndiscovery. By exploiting DEs' intrinsic mathematical structure to generate\nphysics-embedded analytical solutions and associated synthetic data, MAD\nfundamentally eliminates dependence on experimental or simulated training data.\nThis enables computationally efficient operator learning across multi-parameter\nsystems while maintaining mathematical rigor. Through numerical demonstrations\nspanning 2D parametric problems where both the boundary values and source term\nare functions, we showcase MAD's generalizability and superior\nefficiency/accuracy across various DE scenarios. This\nphysics-embedded-data-driven framework and its capacity to handle complex\nparameter spaces gives it the potential to become a universal paradigm for\nphysics-informed machine intelligence in scientific computing.", "comment": "22 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.06752v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06603", "title": "Cross-Modal Dual-Causal Learning for Long-Term Action Recognition", "authors": ["Xu Shaowu", "Jia Xibin", "Gao Junyu", "Sun Qianmei", "Chang Jing", "Fan Chao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06603v1", "summary": "Long-term action recognition (LTAR) is challenging due to extended temporal\nspans with complex atomic action correlations and visual confounders. Although\nvision-language models (VLMs) have shown promise, they often rely on\nstatistical correlations instead of causal mechanisms. Moreover, existing\ncausality-based methods address modal-specific biases but lack cross-modal\ncausal modeling, limiting their utility in VLM-based LTAR. This paper proposes\n\\textbf{C}ross-\\textbf{M}odal \\textbf{D}ual-\\textbf{C}ausal \\textbf{L}earning\n(CMDCL), which introduces a structural causal model to uncover causal\nrelationships between videos and label texts.\n  CMDCL addresses cross-modal biases in text embeddings via textual causal\nintervention and removes confounders inherent in the visual modality through\nvisual causal intervention guided by the debiased text.\n  These dual-causal interventions enable robust action representations to\naddress LTAR challenges. Experimental results on three benchmarks including\nCharades, Breakfast and COIN, demonstrate the effectiveness of the proposed\nmodel. Our code is available at https://github.com/xushaowu/CMDCL.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06603v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2505.05188", "title": "Smoothed analysis in compressed sensing", "authors": ["Elad Aigner-Horev", "Dan Hefetz", "Michael Trushkin"], "categories": ["math.PR", "cs.IT", "math.IT"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.05188v2", "summary": "Arbitrary matrices $M \\in \\mathbb{R}^{m \\times n}$, randomly perturbed in an\nadditive manner using a random matrix $R \\in \\mathbb{R}^{m \\times n}$, are\nshown to asymptotically almost surely satisfy the so-called {\\sl robust null\nspace property}. Whilst insisting on an asymptotically optimal order of\nmagnitude for $m$ required to attain {\\sl unique reconstruction} via\n$\\ell_1$-minimisation algorithms, our results track the level of arbitrariness\nallowed for the fixed seed matrix $M$ as well as the degree of distributional\nirregularity allowed for the entries of the perturbing matrix $R$. Starting\nwith sub-gaussian entries for $R$, our results culminate with these allowed to\nhave substantially heavier tails than sub-exponential ones. Throughout this\ntrajectory, two measures control the arbitrariness allowed for $M$; the first\nis $\\|M\\|_\\infty$ and the second is a localised notion of the Frobenius norm of\n$M$ (which depends on the sparsity of the signal being reconstructed). A key\ntool driving our proofs is {\\sl Mendelson's small-ball method} ({\\em Learning\nwithout concentration}, J. ACM, Vol. $62$, $2015$).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.05188v2", "cate": "math.PR", "date": "2025-05-08", "updated": "2025-07-09"}
{"id": "2507.05400", "title": "Strategic Alignment Patterns in National AI Policies", "authors": ["Mohammad Hossein Azin", "Hessam Zandhessami"], "categories": ["cs.CY", "econ.GN", "q-fin.EC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05400v2", "summary": "This paper introduces a novel visual mapping methodology for assessing\nstrategic alignment in national artificial intelligence policies. The\nproliferation of AI strategies across countries has created an urgent need for\nanalytical frameworks that can evaluate policy coherence between strategic\nobjectives, foresight methods, and implementation instruments. Drawing on data\nfrom the OECD AI Policy Observatory, we analyze 15-20 national AI strategies\nusing a combination of matrix-based visualization and network analysis to\nidentify patterns of alignment and misalignment. Our findings reveal distinct\nalignment archetypes across governance models, with notable variations in how\ncountries integrate foresight methodologies with implementation planning.\nHigh-coherence strategies demonstrate strong interconnections between economic\ncompetitiveness objectives and robust innovation funding instruments, while\ncommon vulnerabilities include misalignment between ethical AI objectives and\ncorresponding regulatory frameworks. The proposed visual mapping approach\noffers both methodological contributions to policy analysis and practical\ninsights for enhancing strategic coherence in AI governance. This research\naddresses significant gaps in policy evaluation methodology and provides\nactionable guidance for policymakers seeking to strengthen alignment in\ntechnological governance frameworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05400v2", "cate": "cs.CY", "date": "2025-07-07", "updated": "2025-07-09"}
{"id": "2507.06853", "title": "DiffSpectra: Molecular Structure Elucidation from Spectra using Diffusion Models", "authors": ["Liang Wang", "Yu Rong", "Tingyang Xu", "Zhenyi Zhong", "Zhiyuan Liu", "Pengju Wang", "Deli Zhao", "Qiang Liu", "Shu Wu", "Liang Wang"], "categories": ["cs.LG", "cs.AI", "cs.CE", "physics.chem-ph", "q-bio.MN"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06853v1", "summary": "Molecular structure elucidation from spectra is a foundational problem in\nchemistry, with profound implications for compound identification, synthesis,\nand drug development. Traditional methods rely heavily on expert interpretation\nand lack scalability. Pioneering machine learning methods have introduced\nretrieval-based strategies, but their reliance on finite libraries limits\ngeneralization to novel molecules. Generative models offer a promising\nalternative, yet most adopt autoregressive SMILES-based architectures that\noverlook 3D geometry and struggle to integrate diverse spectral modalities. In\nthis work, we present DiffSpectra, a generative framework that directly infers\nboth 2D and 3D molecular structures from multi-modal spectral data using\ndiffusion models. DiffSpectra formulates structure elucidation as a conditional\ngeneration process. Its denoising network is parameterized by Diffusion\nMolecule Transformer, an SE(3)-equivariant architecture that integrates\ntopological and geometric information. Conditioning is provided by SpecFormer,\na transformer-based spectral encoder that captures intra- and inter-spectral\ndependencies from multi-modal spectra. Extensive experiments demonstrate that\nDiffSpectra achieves high accuracy in structure elucidation, recovering exact\nstructures with 16.01% top-1 accuracy and 96.86% top-20 accuracy through\nsampling. The model benefits significantly from 3D geometric modeling,\nSpecFormer pre-training, and multi-modal conditioning. These results highlight\nthe effectiveness of spectrum-conditioned diffusion modeling in addressing the\nchallenge of molecular structure elucidation. To our knowledge, DiffSpectra is\nthe first framework to unify multi-modal spectral reasoning and joint 2D/3D\ngenerative modeling for de novo molecular structure elucidation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06853v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2505.05314", "title": "Path-following model predictive control for autonomous e-scooters", "authors": ["David Meister", "Robin Strässer", "Felix Brändle", "Marc Seidel", "Benno Bassler", "Nathan Gerber", "Jan Kautz", "Elena Rommel", "Frank Allgöwer"], "categories": ["eess.SY", "cs.RO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Proc. IEEE Intelligent Transportation Systems Conference (ITSC)", "url": "http://arxiv.org/abs/2505.05314v2", "summary": "In order to mitigate economical, ecological, and societal challenges in\nelectric scooter (e-scooter) sharing systems, we develop an autonomous\ne-scooter prototype. Our vision is to design a fully autonomous prototype that\ncan find its way to the next parking spot, high-demand area, or charging\nstation. In this work, we propose a path-following model predictive control\nsolution to enable localization and navigation in an urban environment with a\nprovided path to follow. We design a closed-loop architecture that solves the\nlocalization and path following problem while allowing the e-scooter to\nmaintain its balance with a previously developed reaction wheel mechanism. Our\nmodel predictive control approach facilitates state and input constraints,\ne.g., adhering to the path width, while remaining executable on a Raspberry Pi\n5. We demonstrate the efficacy of our approach in a real-world experiment on\nour prototype.", "comment": "Proc. IEEE Intelligent Transportation Systems Conference (ITSC)", "pdf_url": "http://arxiv.org/pdf/2505.05314v2", "cate": "eess.SY", "date": "2025-05-08", "updated": "2025-07-09"}
{"id": "2507.06738", "title": "DIFFUMA: High-Fidelity Spatio-Temporal Video Prediction via Dual-Path Mamba and Diffusion Enhancement", "authors": ["Xinyu Xie", "Weifeng Cao", "Jun Shi", "Yangyang Hu", "Hui Liang", "Wanyong Liang", "Xiaoliang Qian"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06738v1", "summary": "Spatio-temporal video prediction plays a pivotal role in critical domains,\nranging from weather forecasting to industrial automation. However, in\nhigh-precision industrial scenarios such as semiconductor manufacturing, the\nabsence of specialized benchmark datasets severely hampers research on modeling\nand predicting complex processes. To address this challenge, we make a twofold\ncontribution.First, we construct and release the Chip Dicing Lane Dataset\n(CHDL), the first public temporal image dataset dedicated to the semiconductor\nwafer dicing process. Captured via an industrial-grade vision system, CHDL\nprovides a much-needed and challenging benchmark for high-fidelity process\nmodeling, defect detection, and digital twin development.Second, we propose\nDIFFUMA, an innovative dual-path prediction architecture specifically designed\nfor such fine-grained dynamics. The model captures global long-range temporal\ncontext through a parallel Mamba module, while simultaneously leveraging a\ndiffusion module, guided by temporal features, to restore and enhance\nfine-grained spatial details, effectively combating feature degradation.\nExperiments demonstrate that on our CHDL benchmark, DIFFUMA significantly\noutperforms existing methods, reducing the Mean Squared Error (MSE) by 39% and\nimproving the Structural Similarity (SSIM) from 0.926 to a near-perfect 0.988.\nThis superior performance also generalizes to natural phenomena datasets. Our\nwork not only delivers a new state-of-the-art (SOTA) model but, more\nimportantly, provides the community with an invaluable data resource to drive\nfuture research in industrial AI.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06738v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06765", "title": "Robust Deep Network Learning of Nonlinear Regression Tasks by Parametric Leaky Exponential Linear Units (LELUs) and a Diffusion Metric", "authors": ["Enda D. V. Bigarella"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06765v1", "summary": "This document proposes a parametric activation function (ac.f.) aimed at\nimproving multidimensional nonlinear data regression. It is a established\nknowledge that nonlinear ac.f.'s are required for learning nonlinear datasets.\nThis work shows that smoothness and gradient properties of the ac.f. further\nimpact the performance of large neural networks in terms of overfitting and\nsensitivity to model parameters. Smooth but vanishing-gradient ac.f.'s such as\nELU or SiLU have limited performance and non-smooth ac.f.'s such as RELU and\nLeaky-RELU further impart discontinuity in the trained model. Improved\nperformance is demonstrated with a smooth \"Leaky Exponential Linear Unit\", with\nnon-zero gradient that can be trained. A novel diffusion-loss metric is also\nproposed to gauge the performance of the trained models in terms of\noverfitting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06765v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06606", "title": "Omni-Fusion of Spatial and Spectral for Hyperspectral Image Segmentation", "authors": ["Qing Zhang", "Guoquan Pei", "Yan Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06606v1", "summary": "Medical Hyperspectral Imaging (MHSI) has emerged as a promising tool for\nenhanced disease diagnosis, particularly in computational pathology, offering\nrich spectral information that aids in identifying subtle biochemical\nproperties of tissues. Despite these advantages, effectively fusing both\nspatial-dimensional and spectral-dimensional information from MHSIs remains\nchallenging due to its high dimensionality and spectral redundancy inherent\ncharacteristics. To solve the above challenges, we propose a novel\nspatial-spectral omni-fusion network for hyperspectral image segmentation,\nnamed as Omni-Fuse. Here, we introduce abundant cross-dimensional feature\nfusion operations, including a cross-dimensional enhancement module that\nrefines both spatial and spectral features through bidirectional attention\nmechanisms, a spectral-guided spatial query selection to select the most\nspectral-related spatial feature as the query, and a two-stage\ncross-dimensional decoder which dynamically guide the model to focus on the\nselected spatial query. Despite of numerous attention blocks, Omni-Fuse remains\nefficient in execution. Experiments on two microscopic hyperspectral image\ndatasets show that our approach can significantly improve the segmentation\nperformance compared with the state-of-the-art methods, with over 5.73 percent\nimprovement in DSC. Code available at:\nhttps://github.com/DeepMed-Lab-ECNU/Omni-Fuse.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06606v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2505.06405", "title": "Mixing and Merging Metric Spaces using Directed Graphs", "authors": ["Mahir Bilen Can", "Shantanu Chakrabartty"], "categories": ["math.CO", "cs.IT", "math.IT", "math.MG", "math.ST", "stat.TH", "54E35, 05C12, 94B60, 05C90, 60B99, 68T05"], "primary_category": "Subjects:       Combinatorics (math.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.06405v2", "summary": "Let $(X_1,d_1),\\dots, (X_N,d_N)$ be metric spaces, where $d_i: X_i \\times X_i\n\\rightarrow [0,1]$ is a distance function for $i=1,\\dots,N$. Let $\\mathcal{X}$\ndenote the set theoretic product $X_1\\times \\cdots \\times X_N$. Let\n$\\mathcal{G} = \\left(\\mathcal{V},\\mathcal{E}\\right)$ be a directed graph with\nvertex set $\\mathcal{V} =\\{1,\\dots, N\\}$, and let $\\mathcal{P} = \\{p_{ij}\\}$ be\na collection of weights, where each $p_{ij}\\in (0, 1]$ is associated with the\nedge $(i,j) \\in \\mathcal{E}$. We introduce the function\n$d_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}: \\mathcal{X}\\times \\mathcal{X} \\to\n[0,1]$ defined by \\begin{align*}\nd_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}(\\mathbf{g},\\mathbf{h}) := \\left(1 -\n\\frac{1}{N}\\sum_{j=1}^N \\prod_{i=1}^N \\left[1-\nd_i(g_i,h_i)\\right]^{\\frac{1}{p_{ji}}} \\right), \\end{align*} for all\n$\\mathbf{g},\\mathbf{h} \\in \\mathcal{X}$. In this paper we show that\n$d_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}$ defines a metric space over\n$\\mathcal{X}$. Then we determine how this distance behaves under various graph\noperations, including disjoint unions and Cartesian products. We investigate\ntwo limiting cases: (a) when $d_{\\mathcal{X},\\mathcal{G},\\mathcal{P}}$ is\ndefined over a finite field, leading to a broad generalization of graph-based\ndistances commonly studied in error-correcting code theory; and (b) when the\nmetric is extended to graphons, enabling the measurement of distances in a\ncontinuous graph limit setting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.06405v2", "cate": "math.CO", "date": "2025-05-09", "updated": "2025-07-09"}
{"id": "2411.08003", "title": "Can adversarial attacks by large language models be attributed?", "authors": ["Manuel Cebrian", "Andres Abeliuk", "Jan Arne Telle"], "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.FL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      21 pages, 5 figures, 2 tables", "url": "http://arxiv.org/abs/2411.08003v2", "summary": "Attributing outputs from Large Language Models (LLMs) in adversarial\nsettings-such as cyberattacks and disinformation campaigns-presents significant\nchallenges that are likely to grow in importance. We approach this attribution\nproblem from both a theoretical and an empirical perspective, drawing on formal\nlanguage theory (identification in the limit) and data-driven analysis of the\nexpanding LLM ecosystem. By modeling an LLM's set of possible outputs as a\nformal language, we analyze whether finite samples of text can uniquely\npinpoint the originating model. Our results show that, under mild assumptions\nof overlapping capabilities among models, certain classes of LLMs are\nfundamentally non-identifiable from their outputs alone. We delineate four\nregimes of theoretical identifiability: (1) an infinite class of deterministic\n(discrete) LLM languages is not identifiable (Gold's classical result from\n1967); (2) an infinite class of probabilistic LLMs is also not identifiable (by\nextension of the deterministic case); (3) a finite class of deterministic LLMs\nis identifiable (consistent with Angluin's tell-tale criterion); and (4) even a\nfinite class of probabilistic LLMs can be non-identifiable (we provide a new\ncounterexample establishing this negative result). Complementing these\ntheoretical insights, we quantify the explosion in the number of plausible\nmodel origins (hypothesis space) for a given output in recent years. Even under\nconservative assumptions-each open-source model fine-tuned on at most one new\ndataset-the count of distinct candidate models doubles approximately every 0.5\nyears, and allowing multi-dataset fine-tuning combinations yields doubling\ntimes as short as 0.28 years. This combinatorial growth, alongside the\nextraordinary computational cost of brute-force likelihood attribution across\nall models and potential users, renders exhaustive attribution infeasible in\npractice.", "comment": "21 pages, 5 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2411.08003v2", "cate": "cs.AI", "date": "2024-11-12", "updated": "2025-07-09"}
{"id": "2507.07037", "title": "Cognitive Load and Information Processing in Financial Markets: Theory and Evidence from Disclosure Complexity", "authors": ["Yimin Du", "Guolin Tang"], "categories": ["q-fin.GN", "cs.CE"], "primary_category": "Subjects:       General Finance (q-fin.GN)", "pdf_link": null, "comments": "Comments:      14 pages", "url": "http://arxiv.org/abs/2507.07037v1", "summary": "We develop a theoretical framework for understanding how cognitive load\naffects information processing in financial markets and test it using exogenous\nvariation in disclosure complexity. Our model distinguishes between attention\nallocation and cognitive processing capacity, showing that complex information\ncreates differential effects across investor types. Using a comprehensive\ndataset of corporate disclosures and a novel identification strategy based on\nregulatory changes, we find that cognitive load significantly impairs price\ndiscovery, with effects concentrated among less sophisticated investors. A\none-standard-deviation increase in cognitive complexity reduces information\nincorporation speed by 18\\% and increases mispricing duration by 23\\%. We\nprovide evidence for three theoretical mechanisms: selective attention,\nprocessing errors, and strategic complexity. Our findings suggest that\ncognitive constraints create systematic inefficiencies in financial markets,\nwith important implications for disclosure regulation and market design.", "comment": "14 pages", "pdf_url": "http://arxiv.org/pdf/2507.07037v1", "cate": "q-fin.GN", "date": "2025-06-18", "updated": "2025-06-18"}
{"id": "2507.02948", "title": "DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction", "authors": ["Zhiyi Hou", "Enhui Ma", "Fang Li", "Zhiyi Lai", "Kalok Ho", "Zhanqian Wu", "Lijun Zhou", "Long Chen", "Chitian Sun", "Haiyang Sun", "Bing Wang", "Guang Chen", "Hangjun Ye", "Kaicheng Yu"], "categories": ["cs.CV", "cs.AI", "cs.RO", "I.4.8; I.2.7; I.2.10"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures. Code available at this https URL", "url": "http://arxiv.org/abs/2507.02948v2", "summary": "Autonomous driving has seen significant progress, driven by extensive\nreal-world data. However, in long-tail scenarios, accurately predicting the\nsafety of the ego vehicle's future motion remains a major challenge due to\nuncertainties in dynamic environments and limitations in data coverage. In this\nwork, we aim to explore whether it is possible to enhance the motion risk\nprediction capabilities of Vision-Language Models (VLM) by synthesizing\nhigh-risk motion data. Specifically, we introduce a Bird's-Eye View (BEV) based\nmotion simulation method to model risks from three aspects: the ego-vehicle,\nother vehicles, and the environment. This allows us to synthesize\nplug-and-play, high-risk motion data suitable for VLM training, which we call\nDriveMRP-10K. Furthermore, we design a VLM-agnostic motion risk estimation\nframework, named DriveMRP-Agent. This framework incorporates a novel\ninformation injection strategy for global context, ego-vehicle perspective, and\ntrajectory projection, enabling VLMs to effectively reason about the spatial\nrelationships between motion waypoints and the environment. Extensive\nexperiments demonstrate that by fine-tuning with DriveMRP-10K, our\nDriveMRP-Agent framework can significantly improve the motion risk prediction\nperformance of multiple VLM baselines, with the accident recognition accuracy\nsoaring from 27.13% to 88.03%. Moreover, when tested via zero-shot evaluation\non an in-house real-world high-risk motion dataset, DriveMRP-Agent achieves a\nsignificant performance leap, boosting the accuracy from base_model's 29.42% to\n68.50%, which showcases the strong generalization capabilities of our method in\nreal-world scenarios.", "comment": "12 pages, 4 figures. Code available at\n  https://github.com/hzy138/DriveMRP", "pdf_url": "http://arxiv.org/pdf/2507.02948v2", "cate": "cs.CV", "date": "2025-06-28", "updated": "2025-07-09"}
{"id": "2507.06753", "title": "KAConvText: Novel Approach to Burmese Sentence Classification using Kolmogorov-Arnold Convolution", "authors": ["Ye Kyaw Thu", "Thura Aung", "Thazin Myint Oo", "Thepchai Supnithi"], "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 3 figures, 4 tables", "url": "http://arxiv.org/abs/2507.06753v1", "summary": "This paper presents the first application of Kolmogorov-Arnold Convolution\nfor Text (KAConvText) in sentence classification, addressing three tasks:\nimbalanced binary hate speech detection, balanced multiclass news\nclassification, and imbalanced multiclass ethnic language identification. We\ninvestigate various embedding configurations, comparing random to fastText\nembeddings in both static and fine-tuned settings, with embedding dimensions of\n100 and 300 using CBOW and Skip-gram models. Baselines include standard CNNs\nand CNNs augmented with a Kolmogorov-Arnold Network (CNN-KAN). In addition, we\ninvestigated KAConvText with different classification heads - MLP and KAN,\nwhere using KAN head supports enhanced interpretability. Results show that\nKAConvText-MLP with fine-tuned fastText embeddings achieves the best\nperformance of 91.23% accuracy (F1-score = 0.9109) for hate speech detection,\n92.66% accuracy (F1-score = 0.9267) for news classification, and 99.82%\naccuracy (F1-score = 0.9982) for language identification.", "comment": "10 pages, 3 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.06753v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06775", "title": "Mutual Information Free Topological Generalization Bounds via Stability", "authors": ["Mario Tuci", "Lennart Bastian", "Benjamin Dupuis", "Nassir Navab", "Tolga Birdal", "Umut Şimşekli"], "categories": ["cs.LG", "math.AT", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      25 pages, 5 figures", "url": "http://arxiv.org/abs/2507.06775v1", "summary": "Providing generalization guarantees for stochastic optimization algorithms is\na major challenge in modern learning theory. Recently, several studies\nhighlighted the impact of the geometry of training trajectories on the\ngeneralization error, both theoretically and empirically. Among these works, a\nseries of topological generalization bounds have been proposed, relating the\ngeneralization error to notions of topological complexity that stem from\ntopological data analysis (TDA). Despite their empirical success, these bounds\nrely on intricate information-theoretic (IT) terms that can be bounded in\nspecific cases but remain intractable for practical algorithms (such as ADAM),\npotentially reducing the relevance of the derived bounds. In this paper, we\nseek to formulate comprehensive and interpretable topological generalization\nbounds free of intractable mutual information terms. To this end, we introduce\na novel learning theoretic framework that departs from the existing strategies\nvia proof techniques rooted in algorithmic stability. By extending an existing\nnotion of \\textit{hypothesis set stability}, to \\textit{trajectory stability},\nwe prove that the generalization error of trajectory-stable algorithms can be\nupper bounded in terms of (i) TDA quantities describing the complexity of the\ntrajectory of the optimizer in the parameter space, and (ii) the trajectory\nstability parameter of the algorithm. Through a series of experimental\nevaluations, we demonstrate that the TDA terms in the bound are of great\nimportance, especially as the number of training samples grows. This ultimately\nforms an explanation of the empirical success of the topological generalization\nbounds.", "comment": "25 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.06775v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06618", "title": "PointVDP: Learning View-Dependent Projection by Fireworks Rays for 3D Point Cloud Segmentation", "authors": ["Yang Chen", "Yueqi Duan", "Haowen Sun", "Ziwei Wang", "Jiwen Lu", "Yap-Peng Tan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06618v1", "summary": "In this paper, we propose view-dependent projection (VDP) to facilitate point\ncloud segmentation, designing efficient 3D-to-2D mapping that dynamically\nadapts to the spatial geometry from view variations. Existing projection-based\nmethods leverage view-independent projection in complex scenes, relying on\nstraight lines to generate direct rays or upward curves to reduce occlusions.\nHowever, their view independence provides projection rays that are limited to\npre-defined parameters by human settings, restricting point awareness and\nfailing to capture sufficient projection diversity across different view\nplanes. Although multiple projections per view plane are commonly used to\nenhance spatial variety, the projected redundancy leads to excessive\ncomputational overhead and inefficiency in image processing. To address these\nlimitations, we design a framework of VDP to generate data-driven projections\nfrom 3D point distributions, producing highly informative single-image inputs\nby predicting rays inspired by the adaptive behavior of fireworks. In addition,\nwe construct color regularization to optimize the framework, which emphasizes\nessential features within semantic pixels and suppresses the non-semantic\nfeatures within black pixels, thereby maximizing 2D space utilization in a\nprojected image. As a result, our approach, PointVDP, develops lightweight\nprojections in marginal computation costs. Experiments on S3DIS and ScanNet\nbenchmarks show that our approach achieves competitive results, offering a\nresource-efficient solution for semantic understanding.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06618v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2505.18277", "title": "The end of radical concept nativism", "authors": ["Joshua S. Rule", "Steven T. Piantadosi"], "categories": ["cs.AI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.18277v2", "summary": "Though humans seem to be remarkable learners, arguments in cognitive science\nand philosophy of mind have long maintained that learning something\nfundamentally new is impossible. Specifically, Jerry Fodor's arguments for\nradical concept nativism hold that most, if not all, concepts are innate and\nthat what many call concept learning never actually leads to the acquisition of\nnew concepts. These arguments have deeply affected cognitive science, and many\nbelieve that the counterarguments to radical concept nativism have been either\nunsuccessful or only apply to a narrow class of concepts. This paper first\nreviews the features and limitations of prior arguments. We then identify three\ncritical points - related to issues of expressive power, conceptual structure,\nand concept possession - at which the arguments in favor of radical concept\nnativism diverge from describing actual human cognition. We use ideas from\ncomputer science and information theory to formalize the relevant ideas in ways\nthat are arguably more scientifically productive. We conclude that, as a\nresult, there is an important sense in which people do indeed learn new\nconcepts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.18277v2", "cate": "cs.AI", "date": "2025-05-23", "updated": "2025-07-09"}
{"id": "2507.07052", "title": "Quantifying Bounded Rationality: Formal Verification of Simon's Satisficing Through Flexible Stochastic Dominance", "authors": ["Jingyuan Li", "Zhou Lin"], "categories": ["q-fin.MF", "cs.CE"], "primary_category": "Subjects:       Mathematical Finance (q-fin.MF)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07052v1", "summary": "This paper introduces Flexible First-Order Stochastic Dominance (FFSD), a\nmathematically rigorous framework that formalizes Herbert Simon's concept of\nbounded rationality using the Lean 4 theorem prover. We develop\nmachine-verified proofs demonstrating that FFSD bridges classical expected\nutility theory with Simon's satisficing behavior through parameterized\ntolerance thresholds. Our approach yields several key results: (1) a critical\nthreshold $\\varepsilon < 1/2$ that guarantees uniqueness of reference points,\n(2) an equivalence theorem linking FFSD to expected utility maximization for\napproximate indicator functions, and (3) extensions to multi-dimensional\ndecision settings. By encoding these concepts in Lean 4's dependent type\ntheory, we provide the first machine-checked formalization of Simon's bounded\nrationality, creating a foundation for mechanized reasoning about economic\ndecision-making under uncertainty with cognitive limitations. This work\ncontributes to the growing intersection between formal mathematics and economic\ntheory, demonstrating how interactive theorem proving can advance our\nunderstanding of behavioral economics concepts that have traditionally been\nexpressed only qualitatively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07052v1", "cate": "q-fin.MF", "date": "2025-07-02", "updated": "2025-07-02"}
{"id": "2507.06763", "title": "FOLC-Net: A Federated-Optimized Lightweight Architecture for Enhanced MRI Disease Diagnosis across Axial, Coronal, and Sagittal Views", "authors": ["Saif Ur Rehman Khan", "Muhammad Nabeel Asim", "Sebastian Vollmer", "Andreas Dengel"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06763v1", "summary": "The framework is designed to improve performance in the analysis of combined\nas well as single anatomical perspectives for MRI disease diagnosis. It\nspecifically addresses the performance degradation observed in state-of-the-art\n(SOTA) models, particularly when processing axial, coronal, and sagittal\nanatomical planes. The paper introduces the FOLC-Net framework, which\nincorporates a novel federated-optimized lightweight architecture with\napproximately 1.217 million parameters and a storage requirement of only 0.9\nMB. FOLC-Net integrates Manta-ray foraging optimization (MRFO) mechanisms for\nefficient model structure generation, global model cloning for scalable\ntraining, and ConvNeXt for enhanced client adaptability. The model was\nevaluated on combined multi-view data as well as individual views, such as\naxial, coronal, and sagittal, to assess its robustness in various medical\nimaging scenarios. Moreover, FOLC-Net tests a ShallowFed model on different\ndata to evaluate its ability to generalize beyond the training dataset. The\nresults show that FOLC-Net outperforms existing models, particularly in the\nchallenging sagittal view. For instance, FOLC-Net achieved an accuracy of\n92.44% on the sagittal view, significantly higher than the 88.37% accuracy of\nstudy method (DL + Residual Learning) and 88.95% of DL models. Additionally,\nFOLC-Net demonstrated improved accuracy across all individual views, providing\na more reliable and robust solution for medical image analysis in decentralized\nenvironments. FOLC-Net addresses the limitations of existing SOTA models by\nproviding a framework that ensures better adaptability to individual views\nwhile maintaining strong performance in multi-view settings. The incorporation\nof MRFO, global model cloning, and ConvNeXt ensures that FOLC-Net performs\nbetter in real-world medical applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06763v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06802", "title": "Speech Tokenizer is Key to Consistent Representation", "authors": ["Wonjin Jung", "Sungil Kang", "Dong-Yeon Cho"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06802v1", "summary": "Speech tokenization is crucial in digital speech processing, converting\ncontinuous speech signals into discrete units for various computational tasks.\nThis paper introduces a novel speech tokenizer with broad applicability across\ndownstream tasks. While recent advances in residual vector quantization (RVQ)\nhave incorporated semantic elements, they often neglect critical acoustic\nfeatures. We propose an advanced approach that simultaneously encodes both\nlinguistic and acoustic information, preserving prosodic and emotional content.\nOur method significantly enhances speech representation fidelity across diverse\napplications. Empirical evaluations demonstrate its effectiveness in speech\ncoding, voice conversion, emotion recognition, and multimodal language\nmodeling, without requiring additional training. This versatility underscores\nits potential as a key tool for advancing AI-driven speech processing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06802v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06643", "title": "Learning from Sparse Point Labels for Dense Carcinosis Localization in Advanced Ovarian Cancer Assessment", "authors": ["Farahdiba Zarin", "Riccardo Oliva", "Vinkle Srivastav", "Armine Vardazaryan", "Andrea Rosati", "Alice Zampolini Faustini", "Giovanni Scambia", "Anna Fagotti", "Pietro Mascagni", "Nicolas Padoy"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06643v1", "summary": "Learning from sparse labels is a challenge commonplace in the medical domain.\nThis is due to numerous factors, such as annotation cost, and is especially\ntrue for newly introduced tasks. When dense pixel-level annotations are needed,\nthis becomes even more unfeasible. However, being able to learn from just a few\nannotations at the pixel-level, while extremely difficult and underutilized,\ncan drive progress in studies where perfect annotations are not immediately\navailable. This work tackles the challenge of learning the dense prediction\ntask of keypoint localization from a few point annotations in the context of 2d\ncarcinosis keypoint localization from laparoscopic video frames for diagnostic\nplanning of advanced ovarian cancer patients. To enable this, we formulate the\nproblem as a sparse heatmap regression from a few point annotations per image\nand propose a new loss function, called Crag and Tail loss, for efficient\nlearning. Our proposed loss function effectively leverages positive sparse\nlabels while minimizing the impact of false negatives or missed annotations.\nThrough an extensive ablation study, we demonstrate the effectiveness of our\napproach in achieving accurate dense localization of carcinosis keypoints,\nhighlighting its potential to advance research in scenarios where dense\nannotations are challenging to obtain.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06643v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2506.06700", "title": "Quantum accessible information and classical entropy inequalities", "authors": ["A. S. Holevo", "A. V. Utkin"], "categories": ["quant-ph", "cs.IT", "math-ph", "math.IT", "math.MP"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      42 pages, no figures. Typos corrected, the proof of the entropy inequalities for obtuse quantum pyramids added", "url": "http://arxiv.org/abs/2506.06700v2", "summary": "Computing accessible information for an ensemble of quantum states is a basic\nproblem in quantum information theory. The optimality criterion recently\nobtained in [7], when applied to specific ensembles of states, leads to\nnontrivial tight lower bounds for the Shannon entropy that are discrete\nrelatives of the famous log-Sobolev inequality. In this light, the hypothesis\nof globally information-optimal measurement for an ensemble of equiangular\nequiprobable states (quantum pyramids) put forward and numerically\nsubstantiated in [2] is reconsidered and the corresponding tight entropy\ninequalities are proposed and proved. Via the optimality criterion, this\nprovides also the first proof of the conjecture concerning globally\ninformation-optimal observables for quantum pyramids put forward in [2].", "comment": "42 pages, no figures. Typos corrected, the proof of the entropy\n  inequalities for obtuse quantum pyramids added", "pdf_url": "http://arxiv.org/pdf/2506.06700v2", "cate": "quant-ph", "date": "2025-06-07", "updated": "2025-07-09"}
{"id": "2506.12629", "title": "The Software Landscape for the Density Matrix Renormalization Group", "authors": ["Per Sehlstedt", "Jan Brandejs", "Paolo Bientinesi", "Lars Karlsson"], "categories": ["physics.comp-ph", "cs.CE", "cs.MS", "physics.chem-ph", "quant-ph"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "Comments:      [v2] Added two more packages", "url": "http://arxiv.org/abs/2506.12629v2", "summary": "The density matrix renormalization group (DMRG) algorithm is a cornerstone\ncomputational method for studying quantum many-body systems, renowned for its\naccuracy and adaptability. Despite DMRG's broad applicability across fields\nsuch as materials science, quantum chemistry, and quantum computing, numerous\nindependent implementations have been developed. This survey maps the rapidly\nexpanding DMRG software landscape, providing a comprehensive comparison of\nfeatures among 35 existing packages. We found significant overlap in features\namong the packages when comparing key aspects, such as parallelism strategies\nfor high-performance computing and symmetry-adapted formulations that enhance\nefficiency. This overlap suggests opportunities for modularization of common\noperations, including tensor operations, symmetry representations, and\neigensolvers, as the packages are mostly independent and share few third-party\nlibrary dependencies where functionality is factored out. More widespread\nmodularization and standardization would result in reduced duplication of\nefforts and improved interoperability. We believe that the proliferation of\npackages and the current lack of standard interfaces and modularity are more\nsocial than technical. We aim to raise awareness of existing packages, guide\nresearchers in finding a suitable package for their needs, and help developers\nidentify opportunities for collaboration, modularity standardization, and\noptimization. Ultimately, this work emphasizes the value of greater cohesion\nand modularity, which would benefit DMRG software, allowing these powerful\nalgorithms to tackle more complex and ambitious problems.", "comment": "[v2] Added two more packages", "pdf_url": "http://arxiv.org/pdf/2506.12629v2", "cate": "physics.comp-ph", "date": "2025-06-14", "updated": "2025-07-09"}
{"id": "2507.06782", "title": "Temporal Information Retrieval via Time-Specifier Model Merging", "authors": ["SeungYoon Han", "Taeho Hwang", "Sukmin Cho", "Soyeong Jeong", "Hoyun Song", "Huije Lee", "Jong C. Park"], "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06782v1", "summary": "The rapid expansion of digital information and knowledge across structured\nand unstructured sources has heightened the importance of Information Retrieval\n(IR). While dense retrieval methods have substantially improved semantic\nmatching for general queries, they consistently underperform on queries with\nexplicit temporal constraints--often those containing numerical expressions and\ntime specifiers such as ``in 2015.'' Existing approaches to Temporal\nInformation Retrieval (TIR) improve temporal reasoning but often suffer from\ncatastrophic forgetting, leading to reduced performance on non-temporal\nqueries. To address this, we propose Time-Specifier Model Merging (TSM), a\nnovel method that enhances temporal retrieval while preserving accuracy on\nnon-temporal queries. TSM trains specialized retrievers for individual time\nspecifiers and merges them in to a unified model, enabling precise handling of\ntemporal constraints without compromising non-temporal retrieval. Extensive\nexperiments on both temporal and non-temporal datasets demonstrate that TSM\nsignificantly improves performance on temporally constrained queries while\nmaintaining strong results on non-temporal queries, consistently outperforming\nother baseline methods. Our code is available at\nhttps://github.com/seungyoonee/TSM .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06782v1", "cate": "cs.IR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06813", "title": "Intrinsic Training Signals for Federated Learning Aggregation", "authors": ["Cosimo Fiorini", "Matteo Mosconi", "Pietro Buzzega", "Riccardo Salami", "Simone Calderara"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06813v1", "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients while preserving data privacy. While existing approaches\nfor aggregating client-specific classification heads and adapted backbone\nparameters require architectural modifications or loss function changes, our\nmethod uniquely leverages intrinsic training signals already available during\nstandard optimization. We present LIVAR (Layer Importance and VARiance-based\nmerging), which introduces: i) a variance-weighted classifier aggregation\nscheme using naturally emergent feature statistics, and ii) an\nexplainability-driven LoRA merging technique based on SHAP analysis of existing\nupdate parameter patterns. Without any architectural overhead, LIVAR achieves\nstate-of-the-art performance on multiple benchmarks while maintaining seamless\nintegration with existing FL methods. This work demonstrates that effective\nmodel merging can be achieved solely through existing training signals,\nestablishing a new paradigm for efficient federated model aggregation. The code\nwill be made publicly available upon acceptance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06813v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06647", "title": "ClipGS: Clippable Gaussian Splatting for Interactive Cinematic Visualization of Volumetric Medical Data", "authors": ["Chengkun Li", "Yuqi Tong", "Kai Chen", "Zhenya Yang", "Ruiyang Li", "Shi Qiu", "Jason Ying-Kuen Chan", "Pheng-Ann Heng", "Qi Dou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Early accepted by MICCAI 2025. Project is available at: this https URL", "url": "http://arxiv.org/abs/2507.06647v1", "summary": "The visualization of volumetric medical data is crucial for enhancing\ndiagnostic accuracy and improving surgical planning and education. Cinematic\nrendering techniques significantly enrich this process by providing\nhigh-quality visualizations that convey intricate anatomical details, thereby\nfacilitating better understanding and decision-making in medical contexts.\nHowever, the high computing cost and low rendering speed limit the requirement\nof interactive visualization in practical applications. In this paper, we\nintroduce ClipGS, an innovative Gaussian splatting framework with the clipping\nplane supported, for interactive cinematic visualization of volumetric medical\ndata. To address the challenges posed by dynamic interactions, we propose a\nlearnable truncation scheme that automatically adjusts the visibility of\nGaussian primitives in response to the clipping plane. Besides, we also design\nan adaptive adjustment model to dynamically adjust the deformation of Gaussians\nand refine the rendering performance. We validate our method on five volumetric\nmedical data (including CT and anatomical slice data), and reach an average\n36.635 PSNR rendering quality with 156 FPS and 16.1 MB model size,\noutperforming state-of-the-art methods in rendering quality and efficiency.", "comment": "Early accepted by MICCAI 2025. Project is available at:\n  https://med-air.github.io/ClipGS", "pdf_url": "http://arxiv.org/pdf/2507.06647v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.00254", "title": "Fully Parallelized BP Decoding for Quantum LDPC Codes Can Outperform BP-OSD", "authors": ["Ming Wang", "Ang Li", "Frank Mueller"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00254v2", "summary": "In this work, we propose a lightweight decoder based solely on\nbelief-propagation (BP), augmented with a speculative post-processing strategy\ninspired by classical Chase decoding. Our method identifies unreliable bits via\nBP oscillation statistics, generates a set of modified test patterns, and\ndecodes them in parallel using low-iteration BP. We demonstrate that our\napproach can achieve logical error rates comparable to or even better than\nBP-OSD, but has lower latency over its parallelization for a variety of\nbivariate bicycle codes, which significantly reduces decoding complexity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00254v2", "cate": "quant-ph", "date": "2025-06-30", "updated": "2025-07-08"}
{"id": "2507.06795", "title": "Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications", "authors": ["Seonwu Kim", "Yohan Na", "Kihun Kim", "Hanhee Cho", "Geun Lim", "Mintae Kim", "Seongik Park", "Ki Hyun Kim", "Youngsub Han", "Byoung-Ki Jeon"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      under review", "url": "http://arxiv.org/abs/2507.06795v1", "summary": "The emergence of open-source large language models (LLMs) has expanded\nopportunities for enterprise applications; however, many organizations still\nlack the infrastructure to deploy and maintain large-scale models. As a result,\nsmall LLMs (sLLMs) have become a practical alternative, despite their inherent\nperformance limitations. While Domain Adaptive Continual Pretraining (DACP) has\nbeen previously explored as a method for domain adaptation, its utility in\ncommercial applications remains under-examined. In this study, we validate the\neffectiveness of applying a DACP-based recipe across diverse foundation models\nand service domains. Through extensive experiments and real-world evaluations,\nwe demonstrate that DACP-applied sLLMs achieve substantial gains in target\ndomain performance while preserving general capabilities, offering a\ncost-efficient and scalable solution for enterprise-level deployment.", "comment": "under review", "pdf_url": "http://arxiv.org/pdf/2507.06795v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06819", "title": "Comprehensive Evaluation of Prototype Neural Networks", "authors": ["Philipp Schlinge", "Steffen Meinert", "Martin Atzmueller"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06819v1", "summary": "Prototype models are an important method for explainable artificial\nintelligence (XAI) and interpretable machine learning. In this paper, we\nperform an in-depth analysis of a set of prominent prototype models including\nProtoPNet, ProtoPool and PIPNet. For their assessment, we apply a comprehensive\nset of metrics. In addition to applying standard metrics from literature, we\npropose several new metrics to further complement the analysis of model\ninterpretability. In our experimentation, we apply the set of prototype models\non a diverse set of datasets including fine-grained classification, Non-IID\nsettings and multi-label classification to further contrast the performance.\nFurthermore, we also provide our code as an open-source library, which\nfacilitates simple application of the metrics itself, as well as extensibility\n- providing the option for easily adding new metrics and models.\nhttps://github.com/uos-sis/quanproto", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06819v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06651", "title": "Diff$^2$I2P: Differentiable Image-to-Point Cloud Registration with Diffusion Prior", "authors": ["Juncheng Mu", "Chengwei Ren", "Weixiang Zhang", "Liang Pan", "Xiao-Ping Zhang", "Yue Gao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.06651v1", "summary": "Learning cross-modal correspondences is essential for image-to-point cloud\n(I2P) registration. Existing methods achieve this mostly by utilizing metric\nlearning to enforce feature alignment across modalities, disregarding the\ninherent modality gap between image and point data. Consequently, this paradigm\nstruggles to ensure accurate cross-modal correspondences. To this end, inspired\nby the cross-modal generation success of recent large diffusion models, we\npropose Diff$^2$I2P, a fully Differentiable I2P registration framework,\nleveraging a novel and effective Diffusion prior for bridging the modality gap.\nSpecifically, we propose a Control-Side Score Distillation (CSD) technique to\ndistill knowledge from a depth-conditioned diffusion model to directly optimize\nthe predicted transformation. However, the gradients on the transformation fail\nto backpropagate onto the cross-modal features due to the non-differentiability\nof correspondence retrieval and PnP solver. To this end, we further propose a\nDeformable Correspondence Tuning (DCT) module to estimate the correspondences\nin a differentiable way, followed by the transformation estimation using a\ndifferentiable PnP solver. With these two designs, the Diffusion model serves\nas a strong prior to guide the cross-modal feature learning of image and point\ncloud for forming robust correspondences, which significantly improves the\nregistration. Extensive experimental results demonstrate that Diff$^2$I2P\nconsistently outperforms SoTA I2P registration methods, achieving over 7%\nimprovement in registration recall on the 7-Scenes benchmark.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.06651v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06804", "title": "Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving", "authors": ["Zhenwen Liang", "Linfeng Song", "Yang Li", "Tao Yang", "Feng Zhang", "Haitao Mi", "Dong Yu"], "categories": ["cs.LO", "cs.AI"], "primary_category": "Subjects:       Logic in Computer Science (cs.LO)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2507.06804v1", "summary": "Automated Theorem Proving (ATP) in formal languages is a foundational\nchallenge for AI. While Large Language Models (LLMs) have driven remarkable\nprogress, a significant gap remains between their powerful informal reasoning\ncapabilities and their weak formal proving performance. Recent studies show\nthat the informal accuracy exceeds 80% while formal success remains below 8% on\nbenchmarks like PutnamBench. We argue this gap persists because current\nstate-of-the-art provers, by tightly coupling reasoning and proving, are\ntrained with paradigms that inadvertently punish deep reasoning in favor of\nshallow, tactic-based strategies. To bridge this fundamental gap, we propose a\nnovel framework that decouples high-level reasoning from low-level proof\ngeneration. Our approach utilizes two distinct, specialized models: a powerful,\ngeneral-purpose Reasoner to generate diverse, strategic subgoal lemmas, and an\nefficient Prover to rigorously verify them. This modular design liberates the\nmodel's full reasoning potential and bypasses the pitfalls of end-to-end\ntraining. We evaluate our method on a challenging set of post-2000 IMO\nproblems, a problem set on which no prior open-source prover has reported\nsuccess. Our decoupled framework successfully solves 5 of these problems,\ndemonstrating a significant step towards automated reasoning on exceptionally\ndifficult mathematical challenges. To foster future research, we release our\nfull dataset of generated and verified lemmas for a wide range of IMO problems,\navailable at https://tencent-imo.github.io/ .", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.06804v1", "cate": "cs.LO", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06821", "title": "HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning", "authors": ["Chuhang Zheng", "Chunwei Tian", "Jie Wen", "Daoqiang Zhang", "Qi Zhu"], "categories": ["cs.LG", "cs.AI", "cs.MM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06821v1", "summary": "Multi-modal emotion recognition has garnered increasing attention as it plays\na significant role in human-computer interaction (HCI) in recent years. Since\ndifferent discrete emotions may exist at the same time, compared with\nsingle-class emotion recognition, emotion distribution learning (EDL) that\nidentifies a mixture of basic emotions has gradually emerged as a trend.\nHowever, existing EDL methods face challenges in mining the heterogeneity among\nmultiple modalities. Besides, rich semantic correlations across arbitrary basic\nemotions are not fully exploited. In this paper, we propose a multi-modal\nemotion distribution learning framework, named HeLo, aimed at fully exploring\nthe heterogeneity and complementary information in multi-modal emotional data\nand label correlation within mixed basic emotions. Specifically, we first adopt\ncross-attention to effectively fuse the physiological data. Then, an optimal\ntransport (OT)-based heterogeneity mining module is devised to mine the\ninteraction and heterogeneity between the physiological and behavioral\nrepresentations. To facilitate label correlation learning, we introduce a\nlearnable label embedding optimized by correlation matrix alignment. Finally,\nthe learnable label embeddings and label correlation matrices are integrated\nwith the multi-modal representations through a novel label correlation-driven\ncross-attention mechanism for accurate emotion distribution learning.\nExperimental results on two publicly available datasets demonstrate the\nsuperiority of our proposed method in emotion distribution learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06821v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06656", "title": "Enhancing Diffusion Model Stability for Image Restoration via Gradient Management", "authors": ["Hongjie Wu", "Mingqin Zhang", "Linchao He", "Ji-Zhe Zhou", "Jiancheng Lv"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ACM Multimedia 2025. Preprint version", "url": "http://arxiv.org/abs/2507.06656v1", "summary": "Diffusion models have shown remarkable promise for image restoration by\nleveraging powerful priors. Prominent methods typically frame the restoration\nproblem within a Bayesian inference framework, which iteratively combines a\ndenoising step with a likelihood guidance step. However, the interactions\nbetween these two components in the generation process remain underexplored. In\nthis paper, we analyze the underlying gradient dynamics of these components and\nidentify significant instabilities. Specifically, we demonstrate conflicts\nbetween the prior and likelihood gradient directions, alongside temporal\nfluctuations in the likelihood gradient itself. We show that these\ninstabilities disrupt the generative process and compromise restoration\nperformance. To address these issues, we propose Stabilized Progressive\nGradient Diffusion (SPGD), a novel gradient management technique. SPGD\nintegrates two synergistic components: (1) a progressive likelihood warm-up\nstrategy to mitigate gradient conflicts; and (2) adaptive directional momentum\n(ADM) smoothing to reduce fluctuations in the likelihood gradient. Extensive\nexperiments across diverse restoration tasks demonstrate that SPGD\nsignificantly enhances generation stability, leading to state-of-the-art\nperformance in quantitative metrics and visually superior results. Code is\navailable at \\href{https://github.com/74587887/SPGD}{here}.", "comment": "Accepted to ACM Multimedia 2025. Preprint version", "pdf_url": "http://arxiv.org/pdf/2507.06656v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06812", "title": "Democratizing High-Fidelity Co-Speech Gesture Video Generation", "authors": ["Xu Yang", "Shaoli Huang", "Shenbo Xie", "Xuelin Chen", "Yifei Liu", "Changxing Ding"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.06812v1", "summary": "Co-speech gesture video generation aims to synthesize realistic,\naudio-aligned videos of speakers, complete with synchronized facial expressions\nand body gestures. This task presents challenges due to the significant\none-to-many mapping between audio and visual content, further complicated by\nthe scarcity of large-scale public datasets and high computational demands. We\npropose a lightweight framework that utilizes 2D full-body skeletons as an\nefficient auxiliary condition to bridge audio signals with visual outputs. Our\napproach introduces a diffusion model conditioned on fine-grained audio\nsegments and a skeleton extracted from the speaker's reference image,\npredicting skeletal motions through skeleton-audio feature fusion to ensure\nstrict audio coordination and body shape consistency. The generated skeletons\nare then fed into an off-the-shelf human video generation model with the\nspeaker's reference image to synthesize high-fidelity videos. To democratize\nresearch, we present CSG-405-the first public dataset with 405 hours of\nhigh-resolution videos across 71 speech types, annotated with 2D skeletons and\ndiverse speaker demographics. Experiments show that our method exceeds\nstate-of-the-art approaches in visual quality and synchronization while\ngeneralizing across speakers and contexts.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.06812v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06825", "title": "Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning", "authors": ["Matej Straka", "Martin Schmid"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06825v1", "summary": "We introduce a real-time strategy game environment built on Generals.io, a\ngame that hosts thousands of active players each week across multiple game\nformats. Our environment is fully compatible with Gymnasium and PettingZoo,\ncapable of running thousands of frames per second on commodity hardware. Our\nreference agent -- trained with supervised pre-training and self-play -- hits\nthe top 0.003\\% of the 1v1 human leaderboard after just 36 hours on a single\nH100 GPU. To accelerate learning, we incorporate potential-based reward shaping\nand memory features. Our contributions -- a modular RTS benchmark and a\ncompetitive, state-of-the-art baseline agent -- provide an accessible yet\nchallenging platform for advancing multi-agent reinforcement learning research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06825v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06671", "title": "FlexGaussian: Flexible and Cost-Effective Training-Free Compression for 3D Gaussian Splatting", "authors": ["Boyuan Tian", "Qizhe Gao", "Siran Xianyu", "Xiaotong Cui", "Minjia Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      To appear at ACM MM 2025", "url": "http://arxiv.org/abs/2507.06671v1", "summary": "3D Gaussian splatting has become a prominent technique for representing and\nrendering complex 3D scenes, due to its high fidelity and speed advantages.\nHowever, the growing demand for large-scale models calls for effective\ncompression to reduce memory and computation costs, especially on mobile and\nedge devices with limited resources. Existing compression methods effectively\nreduce 3D Gaussian parameters but often require extensive retraining or\nfine-tuning, lacking flexibility under varying compression constraints.\n  In this paper, we introduce FlexGaussian, a flexible and cost-effective\nmethod that combines mixed-precision quantization with attribute-discriminative\npruning for training-free 3D Gaussian compression. FlexGaussian eliminates the\nneed for retraining and adapts easily to diverse compression targets.\nEvaluation results show that FlexGaussian achieves up to 96.4% compression\nwhile maintaining high rendering quality (<1 dB drop in PSNR), and is\ndeployable on mobile devices. FlexGaussian delivers high compression ratios\nwithin seconds, being 1.7-2.1x faster than state-of-the-art training-free\nmethods and 10-100x faster than training-involved approaches. The code is being\nprepared and will be released soon at:\nhttps://github.com/Supercomputing-System-AI-Lab/FlexGaussian", "comment": "To appear at ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.06671v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06828", "title": "Speckle2Self: Self-Supervised Ultrasound Speckle Reduction Without Clean Data", "authors": ["Xuesong Li", "Nassir Navab", "Zhongliang Jiang"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06828v1", "summary": "Image denoising is a fundamental task in computer vision, particularly in\nmedical ultrasound (US) imaging, where speckle noise significantly degrades\nimage quality. Although recent advancements in deep neural networks have led to\nsubstantial improvements in denoising for natural images, these methods cannot\nbe directly applied to US speckle noise, as it is not purely random. Instead,\nUS speckle arises from complex wave interference within the body\nmicrostructure, making it tissue-dependent. This dependency means that\nobtaining two independent noisy observations of the same scene, as required by\npioneering Noise2Noise, is not feasible. Additionally, blind-spot networks also\ncannot handle US speckle noise due to its high spatial dependency. To address\nthis challenge, we introduce Speckle2Self, a novel self-supervised algorithm\nfor speckle reduction using only single noisy observations. The key insight is\nthat applying a multi-scale perturbation (MSP) operation introduces\ntissue-dependent variations in the speckle pattern across different scales,\nwhile preserving the shared anatomical structure. This enables effective\nspeckle suppression by modeling the clean image as a low-rank signal and\nisolating the sparse noise component. To demonstrate its effectiveness,\nSpeckle2Self is comprehensively compared with conventional filter-based\ndenoising algorithms and SOTA learning-based methods, using both realistic\nsimulated US images and human carotid US images. Additionally, data from\nmultiple US machines are employed to evaluate model generalization and\nadaptability to images from unseen domains. \\textit{Code and datasets will be\nreleased upon acceptance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06828v1", "cate": "eess.IV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06839", "title": "Scalable Gaussian Processes: Advances in Iterative Methods and Pathwise Conditioning", "authors": ["Jihao Andreas Lin"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      PhD Thesis, University of Cambridge", "url": "http://arxiv.org/abs/2507.06839v1", "summary": "Gaussian processes are a powerful framework for uncertainty-aware function\napproximation and sequential decision-making. Unfortunately, their classical\nformulation does not scale gracefully to large amounts of data and modern\nhardware for massively-parallel computation, prompting many researchers to\ndevelop techniques which improve their scalability. This dissertation focuses\non the powerful combination of iterative methods and pathwise conditioning to\ndevelop methodological contributions which facilitate the use of Gaussian\nprocesses in modern large-scale settings. By combining these two techniques\nsynergistically, expensive computations are expressed as solutions to systems\nof linear equations and obtained by leveraging iterative linear system solvers.\nThis drastically reduces memory requirements, facilitating application to\nsignificantly larger amounts of data, and introduces matrix multiplication as\nthe main computational operation, which is ideal for modern hardware.", "comment": "PhD Thesis, University of Cambridge", "pdf_url": "http://arxiv.org/pdf/2507.06839v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06679", "title": "Text-promptable Object Counting via Quantity Awareness Enhancement", "authors": ["Miaojing Shi", "Xiaowen Zhang", "Zijie Yue", "Yong Luo", "Cairong Zhao", "Li Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      13 pages, 5 figures", "url": "http://arxiv.org/abs/2507.06679v1", "summary": "Recent advances in large vision-language models (VLMs) have shown remarkable\nprogress in solving the text-promptable object counting problem. Representative\nmethods typically specify text prompts with object category information in\nimages. This however is insufficient for training the model to accurately\ndistinguish the number of objects in the counting task. To this end, we propose\nQUANet, which introduces novel quantity-oriented text prompts with a\nvision-text quantity alignment loss to enhance the model's quantity awareness.\nMoreover, we propose a dual-stream adaptive counting decoder consisting of a\nTransformer stream, a CNN stream, and a number of Transformer-to-CNN\nenhancement adapters (T2C-adapters) for density map prediction. The\nT2C-adapters facilitate the effective knowledge communication and aggregation\nbetween the Transformer and CNN streams. A cross-stream quantity ranking loss\nis proposed in the end to optimize the ranking orders of predictions from the\ntwo streams. Extensive experiments on standard benchmarks such as FSC-147,\nCARPK, PUCPR+, and ShanghaiTech demonstrate our model's strong generalizability\nfor zero-shot class-agnostic counting. Code is available at\nhttps://github.com/viscom-tongji/QUANet", "comment": "13 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.06679v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06830", "title": "Physics-Grounded Motion Forecasting via Equation Discovery for Trajectory-Guided Image-to-Video Generation", "authors": ["Tao Feng", "Xianbing Zhao", "Zhenhua Chen", "Tien Tsin Wong", "Hamid Rezatofighi", "Gholamreza Haffari", "Lizhen Qu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06830v1", "summary": "Recent advances in diffusion-based and autoregressive video generation models\nhave achieved remarkable visual realism. However, these models typically lack\naccurate physical alignment, failing to replicate real-world dynamics in object\nmotion. This limitation arises primarily from their reliance on learned\nstatistical correlations rather than capturing mechanisms adhering to physical\nlaws. To address this issue, we introduce a novel framework that integrates\nsymbolic regression (SR) and trajectory-guided image-to-video (I2V) models for\nphysics-grounded video forecasting. Our approach extracts motion trajectories\nfrom input videos, uses a retrieval-based pre-training mechanism to enhance\nsymbolic regression, and discovers equations of motion to forecast physically\naccurate future trajectories. These trajectories then guide video generation\nwithout requiring fine-tuning of existing models. Evaluated on scenarios in\nClassical Mechanics, including spring-mass, pendulums, and projectile motions,\nour method successfully recovers ground-truth analytical equations and improves\nthe physical alignment of generated videos over baseline methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06830v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06859", "title": "Episodic Contextual Bandits with Knapsacks under Conversion Models", "authors": ["Zitian Li", "Wang Chi Cheung"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06859v1", "summary": "We study an online setting, where a decision maker (DM) interacts with\ncontextual bandit-with-knapsack (BwK) instances in repeated episodes. These\nepisodes start with different resource amounts, and the contexts' probability\ndistributions are non-stationary in an episode. All episodes share the same\nlatent conversion model, which governs the random outcome contingent upon a\nrequest's context and an allocation decision. Our model captures applications\nsuch as dynamic pricing on perishable resources with episodic replenishment,\nand first price auctions in repeated episodes with different starting budgets.\nWe design an online algorithm that achieves a regret sub-linear in $T$, the\nnumber of episodes, assuming access to a \\emph{confidence bound oracle} that\nachieves an $o(T)$-regret. Such an oracle is readily available from existing\ncontextual bandit literature. We overcome the technical challenge with\narbitrarily many possible contexts, which leads to a reinforcement learning\nproblem with an unbounded state space. Our framework provides improved regret\nbounds in certain settings when the DM is provided with unlabeled feature data,\nwhich is novel to the contextual BwK literature.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06859v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06689", "title": "Spatial-Temporal Graph Mamba for Music-Guided Dance Video Synthesis", "authors": ["Hao Tang", "Ling Shao", "Zhenyu Zhang", "Luc Van Gool", "Nicu Sebe"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to TPAMI 2025", "url": "http://arxiv.org/abs/2507.06689v1", "summary": "We propose a novel spatial-temporal graph Mamba (STG-Mamba) for the\nmusic-guided dance video synthesis task, i.e., to translate the input music to\na dance video. STG-Mamba consists of two translation mappings:\nmusic-to-skeleton translation and skeleton-to-video translation. In the\nmusic-to-skeleton translation, we introduce a novel spatial-temporal graph\nMamba (STGM) block to effectively construct skeleton sequences from the input\nmusic, capturing dependencies between joints in both the spatial and temporal\ndimensions. For the skeleton-to-video translation, we propose a novel\nself-supervised regularization network to translate the generated skeletons,\nalong with a conditional image, into a dance video. Lastly, we collect a new\nskeleton-to-video translation dataset from the Internet, containing 54,944\nvideo clips. Extensive experiments demonstrate that STG-Mamba achieves\nsignificantly better results than existing methods.", "comment": "Accepted to TPAMI 2025", "pdf_url": "http://arxiv.org/pdf/2507.06689v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06849", "title": "OpenDPDv2: A Unified Learning and Optimization Framework for Neural Network Digital Predistortion", "authors": ["Yizhuo Wu", "Ang Li", "Chang Gao"], "categories": ["eess.SP", "cs.AI"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Under Review", "url": "http://arxiv.org/abs/2507.06849v1", "summary": "Neural network (NN)-based Digital Predistortion (DPD) stands out in improving\nsignal quality in wideband radio frequency (RF) power amplifiers (PAs)\nemploying complex modulation. However, NN DPDs usually rely on a large number\nof parameters for effective linearization and can significantly contribute to\nthe energy consumption of the digital back-end in RF systems. This paper\npresents OpenDPDv2, a unified framework for PA modeling, DPD learning, and\nmodel optimization to reduce power consumption while maintaining high\nlinearization performance. The optimization techniques feature a novel DPD\nalgorithm, TRes-DeltaGRU, alongside two energy-efficient methods. The\ntop-performing 32-bit floating-point (FP32) TRes-DeltaGRU-DPD model achieves an\nAdjacent Channel Power Ratio (ACPR) of -59.4 dBc and Error Vector Magnitude\n(EVM) of -42.1 dBc. By exploiting fixed-point quantization and dynamic temporal\nsparsity of input signals and hidden neurons, the inference energy of our model\ncan be reduced by 4.5X while still maintaining -50.3 dBc ACPR and -35.2 dB EVM\nwith 56% temporal sparsity. This was evaluated using a TM3.1a 200 MHz bandwidth\n256-QAM OFDM signal applied to a 3.5 GHz GaN Doherty RF PA. OpenDPDv2 code,\ndatasets, and documentation are publicly accessible at:\nhttps://github.com/lab-emi/OpenDPD.", "comment": "Under Review", "pdf_url": "http://arxiv.org/pdf/2507.06849v1", "cate": "eess.SP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06888", "title": "Horizontal and Vertical Federated Causal Structure Learning via Higher-order Cumulants", "authors": ["Wei Chen", "Wanyang Gu", "Linjun Peng", "Ruichu Cai", "Zhifeng Hao", "Kun Zhang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06888v1", "summary": "Federated causal discovery aims to uncover the causal relationships between\nentities while protecting data privacy, which has significant importance and\nnumerous applications in real-world scenarios. Existing federated causal\nstructure learning methods primarily focus on horizontal federated settings.\nHowever, in practical situations, different clients may not necessarily contain\ndata on the same variables. In a single client, the incomplete set of variables\ncan easily lead to spurious causal relationships, thereby affecting the\ninformation transmitted to other clients. To address this issue, we\ncomprehensively consider causal structure learning methods under both\nhorizontal and vertical federated settings. We provide the identification\ntheories and methods for learning causal structure in the horizontal and\nvertical federal setting via higher-order cumulants. Specifically, we first\naggregate higher-order cumulant information from all participating clients to\nconstruct global cumulant estimates. These global estimates are then used for\nrecursive source identification, ultimately yielding a global causal strength\nmatrix. Our approach not only enables the reconstruction of causal graphs but\nalso facilitates the estimation of causal strength coefficients. Our algorithm\ndemonstrates superior performance in experiments conducted on both synthetic\ndata and real-world data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06888v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06732", "title": "Hierarchical Feature Alignment for Gloss-Free Sign Language Translation", "authors": ["Sobhan Asasi", "Mohamed Ilyes Lakhal", "Richard Bowden"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted in SLTAT", "url": "http://arxiv.org/abs/2507.06732v1", "summary": "Sign Language Translation (SLT) attempts to convert sign language videos into\nspoken sentences. However, many existing methods struggle with the disparity\nbetween visual and textual representations during end-to-end learning.\nGloss-based approaches help to bridge this gap by leveraging structured\nlinguistic information. While, gloss-free methods offer greater flexibility and\nremove the burden of annotation, they require effective alignment strategies.\nRecent advances in Large Language Models (LLMs) have enabled gloss-free SLT by\ngenerating text-like representations from sign videos. In this work, we\nintroduce a novel hierarchical pre-training strategy inspired by the structure\nof sign language, incorporating pseudo-glosses and contrastive video-language\nalignment. Our method hierarchically extracts features at frame, segment, and\nvideo levels, aligning them with pseudo-glosses and the spoken sentence to\nenhance translation quality. Experiments demonstrate that our approach improves\nBLEU-4 and ROUGE scores while maintaining efficiency.", "comment": "Accepted in SLTAT", "pdf_url": "http://arxiv.org/pdf/2507.06732v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06856", "title": "IAP: Invisible Adversarial Patch Attack through Perceptibility-Aware Localization and Perturbation Optimization", "authors": ["Subrat Kishore Dutta", "Xiao Zhang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Published in ICCV 2025", "url": "http://arxiv.org/abs/2507.06856v1", "summary": "Despite modifying only a small localized input region, adversarial patches\ncan drastically change the prediction of computer vision models. However, prior\nmethods either cannot perform satisfactorily under targeted attack scenarios or\nfail to produce contextually coherent adversarial patches, causing them to be\neasily noticeable by human examiners and insufficiently stealthy against\nautomatic patch defenses. In this paper, we introduce IAP, a novel attack\nframework that generates highly invisible adversarial patches based on\nperceptibility-aware localization and perturbation optimization schemes.\nSpecifically, IAP first searches for a proper location to place the patch by\nleveraging classwise localization and sensitivity maps, balancing the\nsusceptibility of patch location to both victim model prediction and human\nvisual system, then employs a perceptibility-regularized adversarial loss and a\ngradient update rule that prioritizes color constancy for optimizing invisible\nperturbations. Comprehensive experiments across various image benchmarks and\nmodel architectures demonstrate that IAP consistently achieves competitive\nattack success rates in targeted settings with significantly improved patch\ninvisibility compared to existing baselines. In addition to being highly\nimperceptible to humans, IAP is shown to be stealthy enough to render several\nstate-of-the-art patch defenses ineffective.", "comment": "Published in ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.06856v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06892", "title": "Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model", "authors": ["Jing Liang", "Hongyao Tang", "Yi Ma", "Jinyi Liu", "Yan Zheng", "Shuyue Hu", "Lei Bai", "Jianye Hao"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preliminary version. Project page: this https URL", "url": "http://arxiv.org/abs/2507.06892v1", "summary": "Reinforcement Learning (RL) has demonstrated its potential to improve the\nreasoning ability of Large Language Models (LLMs). One major limitation of most\nexisting Reinforcement Finetuning (RFT) methods is that they are on-policy RL\nin nature, i.e., data generated during the past learning process is not fully\nutilized. This inevitably comes at a significant cost of compute and time,\nposing a stringent bottleneck on continuing economic and efficient scaling. To\nthis end, we launch the renaissance of off-policy RL and propose Reincarnating\nMix-policy Proximal Policy Gradient (ReMix), a general approach to enable\non-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix\nconsists of three major components: (1) Mix-policy proximal policy gradient\nwith an increased Update-To-Data (UTD) ratio for efficient training; (2)\nKL-Convex policy constraint to balance the trade-off between stability and\nflexibility; (3) Policy reincarnation to achieve a seamless transition from\nefficient early-stage learning to steady asymptotic improvement. In our\nexperiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base\nmodels. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with\n0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B\nmodel) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math\nreasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and\nMATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level\nperformance with an over 30x to 450x reduction in training cost in terms of\nrollout data volume. In addition, we reveal insightful findings via\nmultifaceted analysis, including the implicit preference for shorter responses\ndue to the Whipping Effect of off-policy discrepancy, the collapse mode of\nself-reflection behavior under the presence of severe off-policyness, etc.", "comment": "Preliminary version. Project page:\n  https://anitaleungxx.github.io/ReMix", "pdf_url": "http://arxiv.org/pdf/2507.06892v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06733", "title": "MADPOT: Medical Anomaly Detection with CLIP Adaptation and Partial Optimal Transport", "authors": ["Mahshid Shiri", "Cigdem Beyan", "Vittorio Murino"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICIAP 2025 (this version is not peer-reviewed; it is the submitted version). ICIAP 2025 proceedings DOI will appear here", "url": "http://arxiv.org/abs/2507.06733v1", "summary": "Medical anomaly detection (AD) is challenging due to diverse imaging\nmodalities, anatomical variations, and limited labeled data. We propose a novel\napproach combining visual adapters and prompt learning with Partial Optimal\nTransport (POT) and contrastive learning (CL) to improve CLIP's adaptability to\nmedical images, particularly for AD. Unlike standard prompt learning, which\noften yields a single representation, our method employs multiple prompts\naligned with local features via POT to capture subtle abnormalities. CL further\nenforces intra-class cohesion and inter-class separation. Our method achieves\nstate-of-the-art results in few-shot, zero-shot, and cross-dataset scenarios\nwithout synthetic data or memory banks. The code is available at\nhttps://github.com/mahshid1998/MADPOT.", "comment": "Accepted to ICIAP 2025 (this version is not peer-reviewed; it is the\n  submitted version). ICIAP 2025 proceedings DOI will appear here", "pdf_url": "http://arxiv.org/pdf/2507.06733v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06588", "title": "Deep Learning-based Human Gesture Channel Modeling for Integrated Sensing and Communication Scenarios", "authors": ["Zhengyu Zhang", "Neeraj Varshney", "Jelena Senic", "Raied Caromi", "Samuel Berweger", "Camillo Gentile", "Enrico M. Vitucci", "Ruisi He", "Vittorio Degli-Esposti"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06588v1", "summary": "With the development of Integrated Sensing and Communication (ISAC) for\nSixth-Generation (6G) wireless systems, contactless human recognition has\nemerged as one of the key application scenarios. Since human gesture motion\ninduces subtle and random variations in wireless multipath propagation, how to\naccurately model human gesture channels has become a crucial issue for the\ndesign and validation of ISAC systems. To this end, this paper proposes a deep\nlearning-based human gesture channel modeling framework for ISAC scenarios, in\nwhich the human body is decomposed into multiple body parts, and the mapping\nbetween human gestures and their corresponding multipath characteristics is\nlearned from real-world measurements. Specifically, a Poisson neural network is\nemployed to predict the number of Multi-Path Components (MPCs) for each human\nbody part, while Conditional Variational Auto-Encoders (C-VAEs) are reused to\ngenerate the scattering points, which are further used to reconstruct\ncontinuous channel impulse responses and micro-Doppler signatures. Simulation\nresults demonstrate that the proposed method achieves high accuracy and\ngeneralization across different gestures and subjects, providing an\ninterpretable approach for data augmentation and the evaluation of\ngesture-based ISAC systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06588v1", "cate": "eess.SP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06890", "title": "A Single-Point Measurement Framework for Robust Cyber-Attack Diagnosis in Smart Microgrids Using Dual Fractional-Order Feature Analysis", "authors": ["Yifan Wang"], "categories": ["eess.SY", "cs.AI", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      8 pages, 10 figures", "url": "http://arxiv.org/abs/2507.06890v1", "summary": "Cyber-attacks jeopardize the safe operation of smart microgrids. At the same\ntime, existing diagnostic methods either depend on expensive multi-point\ninstrumentation or stringent modelling assumptions that are untenable under\nsingle-sensor constraints. This paper proposes a Fractional-Order\nMemory-Enhanced Attack-Diagnosis Scheme (FO-MADS) that achieves low-latency\nfault localisation and cyber-attack detection using only one VPQ\n(Voltage-Power-Reactive-power) sensor. FO-MADS first constructs a dual\nfractional-order feature library by jointly applying Caputo and\nGr\\\"unwald-Letnikov derivatives, thereby amplifying micro-perturbations and\nslow drifts in the VPQ signal. A two-stage hierarchical classifier then\npinpoints the affected inverter and isolates the faulty IGBT switch,\neffectively alleviating class imbalance. Robustness is further strengthened\nthrough Progressive Memory-Replay Adversarial Training (PMR-AT), whose\nattack-aware loss is dynamically re-weighted via Online Hard Example Mining\n(OHEM) to prioritise the most challenging samples. Experiments on a\nfour-inverter microgrid testbed comprising 1 normal and 24 fault classes under\nfour attack scenarios demonstrate diagnostic accuracies of 96.6 % (bias), 94.0\n% (noise), 92.8 % (data replacement), and 95.7 % (replay), while sustaining\n96.7 % under attack-free conditions. These results establish FO-MADS as a\ncost-effective and readily deployable solution that markedly enhances the\ncyber-physical resilience of smart microgrids.", "comment": "8 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.06890v1", "cate": "eess.SY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06901", "title": "Designing Adaptive Algorithms Based on Reinforcement Learning for Dynamic Optimization of Sliding Window Size in Multi-Dimensional Data Streams", "authors": ["Abolfazl Zarghani", "Sadegh Abedi"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06901v1", "summary": "Multi-dimensional data streams, prevalent in applications like IoT, financial\nmarkets, and real-time analytics, pose significant challenges due to their high\nvelocity, unbounded nature, and complex inter-dimensional dependencies. Sliding\nwindow techniques are critical for processing such streams, but fixed-size\nwindows struggle to adapt to dynamic changes like concept drift or bursty\npatterns. This paper proposes a novel reinforcement learning (RL)-based\napproach to dynamically optimize sliding window sizes for multi-dimensional\ndata streams. By formulating window size selection as an RL problem, we enable\nan agent to learn an adaptive policy based on stream characteristics, such as\nvariance, correlations, and temporal trends. Our method, RL-Window, leverages a\nDueling Deep Q-Network (DQN) with prioritized experience replay to handle\nnon-stationarity and high-dimensionality. Evaluations on benchmark datasets\n(UCI HAR, PAMAP2, Yahoo! Finance Stream) demonstrate that RL-Window outperforms\nstate-of-the-art methods like ADWIN and CNN-Adaptive in classification\naccuracy, drift robustness, and computational efficiency. Additional\nqualitative analyses, extended metrics (e.g., energy efficiency, latency), and\na comprehensive dataset characterization further highlight its adaptability and\nstability, making it suitable for real-time applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06901v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06735", "title": "Residual Prior-driven Frequency-aware Network for Image Fusion", "authors": ["Guan Zheng", "Xue Wang", "Wenhua Qian", "Peng Liu", "Runzhuo Ma"], "categories": ["cs.CV", "cs.LG", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06735v1", "summary": "Image fusion aims to integrate complementary information across modalities to\ngenerate high-quality fused images, thereby enhancing the performance of\nhigh-level vision tasks. While global spatial modeling mechanisms show\npromising results, constructing long-range feature dependencies in the spatial\ndomain incurs substantial computational costs. Additionally, the absence of\nground-truth exacerbates the difficulty of capturing complementary features\neffectively. To tackle these challenges, we propose a Residual Prior-driven\nFrequency-aware Network, termed as RPFNet. Specifically, RPFNet employs a\ndual-branch feature extraction framework: the Residual Prior Module (RPM)\nextracts modality-specific difference information from residual maps, thereby\nproviding complementary priors for fusion; the Frequency Domain Fusion Module\n(FDFM) achieves efficient global feature modeling and integration through\nfrequency-domain convolution. Additionally, the Cross Promotion Module (CPM)\nenhances the synergistic perception of local details and global structures\nthrough bidirectional feature interaction. During training, we incorporate an\nauxiliary decoder and saliency structure loss to strengthen the model's\nsensitivity to modality-specific differences. Furthermore, a combination of\nadaptive weight-based frequency contrastive loss and SSIM loss effectively\nconstrains the solution space, facilitating the joint capture of local details\nand global features while ensuring the retention of complementary information.\nExtensive experiments validate the fusion performance of RPFNet, which\neffectively integrates discriminative features, enhances texture details and\nsalient objects, and can effectively facilitate the deployment of the\nhigh-level vision task.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06735v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06612", "title": "Graph Learning for Cooperative Cell-Free ISAC Systems: From Optimization to Estimation", "authors": ["Peng Jiang", "Ming Li", "Rang Liu", "Qian Liu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Under review", "url": "http://arxiv.org/abs/2507.06612v1", "summary": "Cell-free integrated sensing and communication (ISAC) systems have emerged as\na promising paradigm for sixth-generation (6G) networks, enabling simultaneous\nhigh-rate data transmission and high-precision radar sensing through\ncooperative distributed access points (APs). Fully exploiting these\ncapabilities requires a unified design that bridges system-level optimization\nwith multi-target parameter estimation. This paper proposes an end-to-end graph\nlearning approach to close this gap, modeling the entire cell-free ISAC network\nas a heterogeneous graph to jointly design the AP mode selection, user\nassociation, precoding, and echo signal processing for multi-target position\nand velocity estimation. In particular, we propose two novel heterogeneous\ngraph learning frameworks: a dynamic graph learning framework and a lightweight\nmirror-based graph attention network (mirror-GAT) framework. The dynamic graph\nlearning framework employs structural and temporal attention mechanisms\nintegrated with a three-dimensional convolutional neural network (3D-CNN),\nenabling superior performance and robustness in cell-free ISAC environments.\nConversely, the mirror-GAT framework significantly reduces computational\ncomplexity and signaling overhead through a bi-level iterative structure with\nshare adjacency. Simulation results validate that both proposed\ngraph-learning-based frameworks achieve significant improvements in\nmulti-target position and velocity estimation accuracy compared to conventional\nheuristic and optimization-based designs. Particularly, the mirror-GAT\nframework demonstrates substantial reductions in computational time and\nsignaling overhead, underscoring its suitability for practical deployments.", "comment": "Under review", "pdf_url": "http://arxiv.org/pdf/2507.06612v1", "cate": "eess.SP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06893", "title": "Developing and Maintaining an Open-Source Repository of AI Evaluations: Challenges and Insights", "authors": ["Alexandra Abbas", "Celia Waggoner", "Justin Olive"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06893v1", "summary": "AI evaluations have become critical tools for assessing large language model\ncapabilities and safety. This paper presents practical insights from eight\nmonths of maintaining $inspect\\_evals$, an open-source repository of 70+\ncommunity-contributed AI evaluations. We identify key challenges in\nimplementing and maintaining AI evaluations and develop solutions including:\n(1) a structured cohort management framework for scaling community\ncontributions, (2) statistical methodologies for optimal resampling and\ncross-model comparison with uncertainty quantification, and (3) systematic\nquality control processes for reproducibility. Our analysis reveals that AI\nevaluation requires specialized infrastructure, statistical rigor, and\ncommunity coordination beyond traditional software development practices.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06893v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06952", "title": "What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models", "authors": ["Keyon Vafa", "Peter G. Chang", "Ashesh Rambachan", "Sendhil Mullainathan"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      To appear in ICML 2025", "url": "http://arxiv.org/abs/2507.06952v1", "summary": "Foundation models are premised on the idea that sequence prediction can\nuncover deeper domain understanding, much like how Kepler's predictions of\nplanetary motion later led to the discovery of Newtonian mechanics. However,\nevaluating whether these models truly capture deeper structure remains a\nchallenge. We develop a technique for evaluating foundation models that\nexamines how they adapt to synthetic datasets generated from some postulated\nworld model. Our technique measures whether the foundation model's inductive\nbias aligns with the world model, and so we refer to it as an inductive bias\nprobe. Across multiple domains, we find that foundation models can excel at\ntheir training tasks yet fail to develop inductive biases towards the\nunderlying world model when adapted to new tasks. We particularly find that\nfoundation models trained on orbital trajectories consistently fail to apply\nNewtonian mechanics when adapted to new physics tasks. Further analysis reveals\nthat these models behave as if they develop task-specific heuristics that fail\nto generalize.", "comment": "To appear in ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.06952v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06739", "title": "PromptTea: Let Prompts Tell TeaCache the Optimal Threshold", "authors": ["Zishen Huang", "Chunyu Yang", "Mengyuan Ren"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06739v1", "summary": "Despite recent progress in video generation, inference speed remains a major\nbottleneck. A common acceleration strategy involves reusing model outputs via\ncaching mechanisms at fixed intervals. However, we find that such\nfixed-frequency reuse significantly degrades quality in complex scenes, while\nmanually tuning reuse thresholds is inefficient and lacks robustness. To\naddress this, we propose Prompt-Complexity-Aware (PCA) caching, a method that\nautomatically adjusts reuse thresholds based on scene complexity estimated\ndirectly from the input prompt. By incorporating prompt-derived semantic cues,\nPCA enables more adaptive and informed reuse decisions than conventional\ncaching methods. We also revisit the assumptions behind TeaCache and identify a\nkey limitation: it suffers from poor input-output relationship modeling due to\nan oversimplified prior. To overcome this, we decouple the noisy input, enhance\nthe contribution of meaningful textual information, and improve the model's\npredictive accuracy through multivariate polynomial feature expansion. To\nfurther reduce computational cost, we replace the static CFGCache with\nDynCFGCache, a dynamic mechanism that selectively reuses classifier-free\nguidance (CFG) outputs based on estimated output variations. This allows for\nmore flexible reuse without compromising output quality. Extensive experiments\ndemonstrate that our approach achieves significant acceleration-for example,\n2.79x speedup on the Wan2.1 model-while maintaining high visual fidelity across\na range of scenes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06739v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06805", "title": "Wireless Energy Transfer Beamforming Optimization for Intelligent Transmitting Surface", "authors": ["Osmel Martínez Rosabal", "Onel Alcaraz López", "Victoria Dala Pegorara Souto", "Richard Demo Souza", "Samuel Montejo-Sánchez", "Robert Schober", "Hirley Alves"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      13 pages, 9 figures, 2 tables, submitted to IEEE Transactions on Wireless Communications", "url": "http://arxiv.org/abs/2507.06805v1", "summary": "Radio frequency (RF) wireless energy transfer (WET) is a promising technology\nfor powering the growing ecosystem of Internet of Things (IoT) devices using\npower beacons (PBs). Recent research focuses on designing efficient PB\narchitectures that can support numerous antennas. In this context, PBs equipped\nwith intelligent surfaces present a promising approach, enabling physically\nlarge, reconfigurable arrays. Motivated by these advantages, this work aims to\nminimize the power consumption of a PB equipped with a passive intelligent\ntransmitting surface (ITS) and a collocated digital beamforming-based feeder to\ncharge multiple single-antenna devices. To model the PB's power consumption\naccurately, we consider power amplifiers nonlinearities, ITS control power, and\nfeeder-to-ITS air interface losses. The resulting optimization problem is\nhighly nonlinear and nonconvex due to the high-power amplifier (HPA), the\nreceived power constraints at the devices, and the unit-modulus constraint\nimposed by the phase shifter configuration of the ITS. To tackle this issue, we\napply successive convex approximation (SCA) to iteratively solve convex\nsubproblems that jointly optimize the digital precoder and phase configuration.\nGiven SCA's sensitivity to initialization, we propose an algorithm that ensures\ninitialization feasibility while balancing convergence speed and solution\nquality. We compare the proposed ITS-equipped PB's power consumption against\nbenchmark architectures featuring digital and hybrid analog-digital\nbeamforming. Results demonstrate that the proposed architecture efficiently\nscales with the number of RF chains and ITS elements. We also show that\nnonuniform ITS power distribution influences beamforming and can shift a device\nbetween near- and far-field regions, even with a constant aperture.", "comment": "13 pages, 9 figures, 2 tables, submitted to IEEE Transactions on\n  Wireless Communications", "pdf_url": "http://arxiv.org/pdf/2507.06805v1", "cate": "eess.SP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06895", "title": "SCoRE: Streamlined Corpus-based Relation Extraction using Multi-Label Contrastive Learning and Bayesian kNN", "authors": ["Luca Mariotti", "Veronica Guidetti", "Federica Mandreoli"], "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06895v1", "summary": "The growing demand for efficient knowledge graph (KG) enrichment leveraging\nexternal corpora has intensified interest in relation extraction (RE),\nparticularly under low-supervision settings. To address the need for adaptable\nand noise-resilient RE solutions that integrate seamlessly with pre-trained\nlarge language models (PLMs), we introduce SCoRE, a modular and cost-effective\nsentence-level RE system. SCoRE enables easy PLM switching, requires no\nfinetuning, and adapts smoothly to diverse corpora and KGs. By combining\nsupervised contrastive learning with a Bayesian k-Nearest Neighbors (kNN)\nclassifier for multi-label classification, it delivers robust performance\ndespite the noisy annotations of distantly supervised corpora. To improve RE\nevaluation, we propose two novel metrics: Correlation Structure Distance (CSD),\nmeasuring the alignment between learned relational patterns and KG structures,\nand Precision at R (P@R), assessing utility as a recommender system. We also\nrelease Wiki20d, a benchmark dataset replicating real-world RE conditions where\nonly KG-derived annotations are available. Experiments on five benchmarks show\nthat SCoRE matches or surpasses state-of-the-art methods while significantly\nreducing energy consumption. Further analyses reveal that increasing model\ncomplexity, as seen in prior work, degrades performance, highlighting the\nadvantages of SCoRE's minimal design. Combining efficiency, modularity, and\nscalability, SCoRE stands as an optimal choice for real-world RE applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06895v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06967", "title": "Noisy PDE Training Requires Bigger PINNs", "authors": ["Sebastien Andre-Sloan", "Anirbit Mukherjee", "Matthew Colbrook"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06967v1", "summary": "Physics-Informed Neural Networks (PINNs) are increasingly used to approximate\nsolutions of partial differential equations (PDEs), especially in high\ndimensions. In real-world applications, data samples are noisy, so it is\nimportant to know when a predictor can still achieve low empirical risk.\nHowever, little is known about the conditions under which a PINN can do so\neffectively. We prove a lower bound on the size of neural networks required for\nthe supervised PINN empirical risk to fall below the variance of noisy\nsupervision labels. Specifically, if a predictor achieves an empirical risk\n$O(\\eta)$ below $\\sigma^2$ (variance of supervision data), then necessarily\n$d_N\\log d_N\\gtrsim N_s \\eta^2$, where $N_s$ is the number of samples and $d_N$\nis the number of trainable parameters of the PINN. A similar constraint applies\nto the fully unsupervised PINN setting when boundary labels are sampled\nnoisily. Consequently, increasing the number of noisy supervision labels alone\ndoes not provide a ``free lunch'' in reducing empirical risk. We also show\nempirically that PINNs can indeed achieve empirical risks below $\\sigma^2$\nunder such conditions. As a case study, we investigate PINNs applied to the\nHamilton--Jacobi--Bellman (HJB) PDE. Our findings lay the groundwork for\nquantitatively understanding the parameter requirements for training PINNs in\nthe presence of noise.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06967v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06744", "title": "Dual-Granularity Cross-Modal Identity Association for Weakly-Supervised Text-to-Person Image Matching", "authors": ["Yafei Zhang", "Yongle Shang", "Huafeng Li"], "categories": ["cs.CV", "cs.LG", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06744v1", "summary": "Weakly supervised text-to-person image matching, as a crucial approach to\nreducing models' reliance on large-scale manually labeled samples, holds\nsignificant research value. However, existing methods struggle to predict\ncomplex one-to-many identity relationships, severely limiting performance\nimprovements. To address this challenge, we propose a local-and-global\ndual-granularity identity association mechanism. Specifically, at the local\nlevel, we explicitly establish cross-modal identity relationships within a\nbatch, reinforcing identity constraints across different modalities and\nenabling the model to better capture subtle differences and correlations. At\nthe global level, we construct a dynamic cross-modal identity association\nnetwork with the visual modality as the anchor and introduce a confidence-based\ndynamic adjustment mechanism, effectively enhancing the model's ability to\nidentify weakly associated samples while improving overall sensitivity.\nAdditionally, we propose an information-asymmetric sample pair construction\nmethod combined with consistency learning to tackle hard sample mining and\nenhance model robustness. Experimental results demonstrate that the proposed\nmethod substantially boosts cross-modal matching accuracy, providing an\nefficient and practical solution for text-to-person image matching.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06744v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06833", "title": "Enhancing Environment Generalizability for Deep Learning-Based CSI Feedback", "authors": ["Haoyu Wang", "Shuangfeng Han", "Xiaoyun Wang", "Zhi Sun"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06833v1", "summary": "Accurate and low-overhead channel state information (CSI) feedback is\nessential to boost the capacity of frequency division duplex (FDD) massive\nmultiple-input multiple-output (MIMO) systems. Deep learning-based CSI feedback\nsignificantly outperforms conventional approaches. Nevertheless, current deep\nlearning-based CSI feedback algorithms exhibit limited generalizability to\nunseen environments, which obviously increases the deployment cost. In this\npaper, we first model the distribution shift of CSI across different\nenvironments, which is composed of the distribution shift of multipath\nstructure and a single-path. Then, EG-CsiNet is proposed as a novel CSI\nfeedback learning framework to enhance environment-generalizability.\nExplicitly, EG-CsiNet comprises the modules of multipath decoupling and\nfine-grained alignment, which can address the distribution shift of multipath\nstructure and a single path. Based on extensive simulations, the proposed\nEG-CsiNet can robustly enhance the generalizability in unseen environments\ncompared to the state-of-the-art, especially in challenging conditions with a\nsingle source environment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06833v1", "cate": "eess.SP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06899", "title": "VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation", "authors": ["Ziang Ye", "Yang Zhang", "Wentao Shi", "Xiaoyu You", "Fuli Feng", "Tat-Seng Chua"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06899v1", "summary": "Graphical User Interface (GUI) agents powered by Large Vision-Language Models\n(LVLMs) have emerged as a revolutionary approach to automating human-machine\ninteractions, capable of autonomously operating personal devices (e.g., mobile\nphones) or applications within the device to perform complex real-world tasks\nin a human-like manner. However, their close integration with personal devices\nraises significant security concerns, with many threats, including backdoor\nattacks, remaining largely unexplored. This work reveals that the visual\ngrounding of GUI agent-mapping textual plans to GUI elements-can introduce\nvulnerabilities, enabling new types of backdoor attacks. With backdoor attack\ntargeting visual grounding, the agent's behavior can be compromised even when\ngiven correct task-solving plans. To validate this vulnerability, we propose\nVisualTrap, a method that can hijack the grounding by misleading the agent to\nlocate textual plans to trigger locations instead of the intended targets.\nVisualTrap uses the common method of injecting poisoned data for attacks, and\ndoes so during the pre-training of visual grounding to ensure practical\nfeasibility of attacking. Empirical results show that VisualTrap can\neffectively hijack visual grounding with as little as 5% poisoned data and\nhighly stealthy visual triggers (invisible to the human eye); and the attack\ncan be generalized to downstream tasks, even after clean fine-tuning. Moreover,\nthe injected trigger can remain effective across different GUI environments,\ne.g., being trained on mobile/web and generalizing to desktop environments.\nThese findings underscore the urgent need for further research on backdoor\nattack risks in GUI agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06899v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06979", "title": "A Principled Framework for Multi-View Contrastive Learning", "authors": ["Panagiotis Koromilas", "Efthymios Georgiou", "Giorgos Bouritsas", "Theodoros Giannakopoulos", "Mihalis A. Nicolaou", "Yannis Panagakis"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06979v1", "summary": "Contrastive Learning (CL), a leading paradigm in Self-Supervised Learning\n(SSL), typically relies on pairs of data views generated through augmentation.\nWhile multiple augmentations per instance (more than two) improve\ngeneralization in supervised learning, current CL methods handle additional\nviews suboptimally by simply aggregating different pairwise objectives. This\napproach suffers from four critical limitations: (L1) it utilizes multiple\noptimization terms per data point resulting to conflicting objectives, (L2) it\nfails to model all interactions across views and data points, (L3) it inherits\nfundamental limitations (e.g. alignment-uniformity coupling) from pairwise CL\nlosses, and (L4) it prevents fully realizing the benefits of increased view\nmultiplicity observed in supervised settings. We address these limitations\nthrough two novel loss functions: MV-InfoNCE, which extends InfoNCE to\nincorporate all possible view interactions simultaneously in one term per data\npoint, and MV-DHEL, which decouples alignment from uniformity across views\nwhile scaling interaction complexity with view multiplicity. Both approaches\nare theoretically grounded - we prove they asymptotically optimize for\nalignment of all views and uniformity, providing principled extensions to\nmulti-view contrastive learning. Our empirical results on ImageNet1K and three\nother datasets demonstrate that our methods consistently outperform existing\nmulti-view approaches and effectively scale with increasing view multiplicity.\nWe also apply our objectives to multimodal data and show that, in contrast to\nother contrastive objectives, they can scale beyond just two modalities. Most\nsignificantly, ablation studies reveal that MV-DHEL with five or more views\neffectively mitigates dimensionality collapse by fully utilizing the embedding\nspace, thereby delivering multi-view benefits observed in supervised learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06979v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06761", "title": "Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu", "authors": ["Yan Hon Michael Chung", "Donghyeok Choi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06761v1", "summary": "Manchu, a critically endangered language essential for understanding early\nmodern Eastern Eurasian history, lacks effective OCR systems that can handle\nreal-world historical documents. This study develops high-performing OCR\nsystems by fine-tuning three open-source vision-language models (LLaMA-3.2-11B,\nQwen2.5-VL-7B, Qwen2.5-VL-3B) on 60,000 synthetic Manchu word images using\nparameter-efficient training. LLaMA-3.2-11B achieved exceptional performance\nwith 98.3\\% word accuracy and 0.0024 character error rate on synthetic data,\nwhile crucially maintaining 93.1\\% accuracy on real-world handwritten\ndocuments. Comparative evaluation reveals substantial advantages over\ntraditional approaches: while a CRNN baseline achieved 99.8\\% synthetic\naccuracy, it suffered severe degradation to 72.5\\% on real documents. Our\napproach demonstrates effective synthetic-to-real domain transfer, providing a\ncost-effective solution deployable on accessible infrastructure. This work\nestablishes a transferable framework for endangered language OCR that removes\ntechnical and financial barriers in digital humanities, enabling historians and\nlinguists to process historical archives without specialized computing\nresources. Code and model weights are available at\nhttps://github.com/mic7ch1/ManchuAI-OCR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06761v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06904", "title": "Joint Beamforming and Position Optimization for Fluid STAR-RIS-NOMA Assisted Wireless Communication Systems", "authors": ["Yu Liu", "Qu Luo", "Gaojie Chen", "Pei Xiao", "Ahmed Elzanaty", "Mohsen Khalily", "Rahim Tafazolli"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06904v1", "summary": "To address the limitations of traditional reconfigurable intelligent surfaces\n(RIS) in spatial control capability, this paper introduces the concept of the\nfluid antenna system (FAS) and proposes a fluid simultaneously transmitting and\nreflecting RIS (FSTAR-RIS) assisted non-orthogonal multiple access (NOMA)\nmulti-user communication system. In this system, each FSTAR-RIS element is\ncapable of flexible mobility and can dynamically adjust its position in\nresponse to environmental variations, thereby enabling simultaneous service to\nusers in both the transmission and reflection zones. This significantly\nenhances the system's spatial degrees of freedom (DoF) and service\nadaptability. To maximize the system's weighted sum-rate, we formulate a\nnon-convex optimization problem that jointly optimizes the base station\nbeamforming, the transmission/reflection coefficients of the FSTAR-RIS, and the\nelement positions. An alternating optimization (AO) algorithm is developed,\nincorporating successive convex approximation (SCA), semi-definite relaxation\n(SDR), and majorization-minimization (MM) techniques. In particular, to address\nthe complex channel coupling introduced by the coexistence of direct and\nFSTAR-RIS paths, the MM framework is employed in the element position\noptimization subproblem, enabling an efficient iterative solution strategy.\nSimulation results validate that the proposed system achieves up to a 27%\nincrease in total sum rate compared to traditional STAR-RIS systems and\nrequires approximately 50% fewer RIS elements to attain the same performance,\nhighlighting its effectiveness for cost-efficient large-scale deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06904v1", "cate": "eess.SP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06908", "title": "MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection", "authors": ["Ziyan Liu", "Chunxiao Fan", "Haoran Lou", "Yuexin Wu", "Kaiwei Deng"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025", "url": "http://arxiv.org/abs/2507.06908v1", "summary": "The rapid expansion of memes on social media has highlighted the urgent need\nfor effective approaches to detect harmful content. However, traditional\ndata-driven approaches struggle to detect new memes due to their evolving\nnature and the lack of up-to-date annotated data. To address this issue, we\npropose MIND, a multi-agent framework for zero-shot harmful meme detection that\ndoes not rely on annotated data. MIND implements three key strategies: 1) We\nretrieve similar memes from an unannotated reference set to provide contextual\ninformation. 2) We propose a bi-directional insight derivation mechanism to\nextract a comprehensive understanding of similar memes. 3) We then employ a\nmulti-agent debate mechanism to ensure robust decision-making through reasoned\narbitration. Extensive experiments on three meme datasets demonstrate that our\nproposed framework not only outperforms existing zero-shot approaches but also\nshows strong generalization across different model architectures and parameter\nscales, providing a scalable solution for harmful meme detection. The code is\navailable at https://github.com/destroy-lonely/MIND.", "comment": "ACL 2025", "pdf_url": "http://arxiv.org/pdf/2507.06908v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06996", "title": "Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing", "authors": ["Eunbyeol Cho", "Jiyoun Kim", "Minjae Lee", "Sungjin Park", "Edward Choi"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06996v1", "summary": "Electronic Health Records (EHR) are time-series relational databases that\nrecord patient interactions and medical events over time, serving as a critical\nresource for healthcare research and applications. However, privacy concerns\nand regulatory restrictions limit the sharing and utilization of such sensitive\ndata, necessitating the generation of synthetic EHR datasets. Unlike previous\nEHR synthesis methods, which typically generate medical records consisting of\nexpert-chosen features (e.g. a few vital signs or structured codes only), we\nintroduce RawMed, the first framework to synthesize multi-table, time-series\nEHR data that closely resembles raw EHRs. Using text-based representation and\ncompression techniques, RawMed captures complex structures and temporal\ndynamics with minimal preprocessing. We also propose a new evaluation framework\nfor multi-table time-series synthetic EHRs, assessing distributional\nsimilarity, inter-table relationships, temporal dynamics, and privacy.\nValidated on two open-source EHR datasets, RawMed outperforms baseline models\nin fidelity and utility. The code is available at\nhttps://github.com/eunbyeol-cho/RawMed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06996v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06797", "title": "Unlocking Thermal Aerial Imaging: Synthetic Enhancement of UAV Datasets", "authors": ["Antonella Barisic Kulas", "Andreja Jurasovic", "Stjepan Bogdan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Preprint. Accepted at ECMR 2025", "url": "http://arxiv.org/abs/2507.06797v1", "summary": "Thermal imaging from unmanned aerial vehicles (UAVs) holds significant\npotential for applications in search and rescue, wildlife monitoring, and\nemergency response, especially under low-light or obscured conditions. However,\nthe scarcity of large-scale, diverse thermal aerial datasets limits the\nadvancement of deep learning models in this domain, primarily due to the high\ncost and logistical challenges of collecting thermal data. In this work, we\nintroduce a novel procedural pipeline for generating synthetic thermal images\nfrom an aerial perspective. Our method integrates arbitrary object classes into\nexisting thermal backgrounds by providing control over the position, scale, and\norientation of the new objects, while aligning them with the viewpoints of the\nbackground. We enhance existing thermal datasets by introducing new object\ncategories, specifically adding a drone class in urban environments to the\nHIT-UAV dataset and an animal category to the MONET dataset. In evaluating\nthese datasets for object detection task, we showcase strong performance across\nboth new and existing classes, validating the successful expansion into new\napplications. Through comparative analysis, we show that thermal detectors\noutperform their visible-light-trained counterparts and highlight the\nimportance of replicating aerial viewing angles. Project page:\nhttps://github.com/larics/thermal_aerial_synthetic.", "comment": "Preprint. Accepted at ECMR 2025", "pdf_url": "http://arxiv.org/pdf/2507.06797v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06932", "title": "Precise Representation Model of SAR Saturated Interference: Mechanism and Verification", "authors": ["Lunhao Duan", "Xingyu Lu", "Yushuang Liu", "Jianchao Yang", "Hong Gu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06932v1", "summary": "Synthetic Aperture Radar (SAR) is highly susceptible to Radio Frequency\nInterference (RFI). Due to the performance limitations of components such as\ngain controllers and analog-to-digital converters in SAR receivers, high-power\ninterference can easily cause saturation of the SAR receiver, resulting in\nnonlinear distortion of the interfered echoes, which are distorted in both the\ntime domain and frequency domain. Some scholars have analyzed the impact of SAR\nreceiver saturation on target echoes through simulations. However, the\nsaturation function has non-smooth characteristics, making it difficult to\nconduct accurate analysis using traditional analytical methods. Current related\nstudies have approximated and analyzed the saturation function based on the\nhyperbolic tangent function, but there are approximation errors. Therefore,\nthis paper proposes a saturation interference analysis model based on Bessel\nfunctions, and verifies the accuracy of the proposed saturation interference\nanalysis model by simulating and comparing it with the traditional saturation\nmodel based on smooth function approximation. This model can provide certain\nguidance for further work such as saturation interference suppression.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06932v1", "cate": "eess.SP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06909", "title": "MultiJustice: A Chinese Dataset for Multi-Party, Multi-Charge Legal Prediction", "authors": ["Xiao Wang", "Jiahuan Pei", "Diancheng Shui", "Zhiguang Han", "Xin Sun", "Dawei Zhu", "Xiaoyu Shen"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by NLPCC 2025", "url": "http://arxiv.org/abs/2507.06909v1", "summary": "Legal judgment prediction offers a compelling method to aid legal\npractitioners and researchers. However, the research question remains\nrelatively under-explored: Should multiple defendants and charges be treated\nseparately in LJP? To address this, we introduce a new dataset namely\nmulti-person multi-charge prediction (MPMCP), and seek the answer by evaluating\nthe performance of several prevailing legal large language models (LLMs) on\nfour practical legal judgment scenarios: (S1) single defendant with a single\ncharge, (S2) single defendant with multiple charges, (S3) multiple defendants\nwith a single charge, and (S4) multiple defendants with multiple charges. We\nevaluate the dataset across two LJP tasks, i.e., charge prediction and penalty\nterm prediction. We have conducted extensive experiments and found that the\nscenario involving multiple defendants and multiple charges (S4) poses the\ngreatest challenges, followed by S2, S3, and S1. The impact varies\nsignificantly depending on the model. For example, in S4 compared to S1,\nInternLM2 achieves approximately 4.5% lower F1-score and 2.8% higher LogD,\nwhile Lawformer demonstrates around 19.7% lower F1-score and 19.0% higher LogD.\nOur dataset and code are available at\nhttps://github.com/lololo-xiao/MultiJustice-MPMCP.", "comment": "Accepted by NLPCC 2025", "pdf_url": "http://arxiv.org/pdf/2507.06909v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07008", "title": "Exact Evaluation of the Accuracy of Diffusion Models for Inverse Problems with Gaussian Data Distributions", "authors": ["Emile Pierret", "Bruno Galerne"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07008v1", "summary": "Used as priors for Bayesian inverse problems, diffusion models have recently\nattracted considerable attention in the literature. Their flexibility and high\nvariance enable them to generate multiple solutions for a given task, such as\ninpainting, super-resolution, and deblurring. However, several unresolved\nquestions remain about how well they perform. In this article, we investigate\nthe accuracy of these models when applied to a Gaussian data distribution for\ndeblurring. Within this constrained context, we are able to precisely analyze\nthe discrepancy between the theoretical resolution of inverse problems and\ntheir resolution obtained using diffusion models by computing the exact\nWasserstein distance between the distribution of the diffusion model sampler\nand the ideal distribution of solutions to the inverse problem. Our findings\nallow for the comparison of different algorithms from the literature.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07008v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06806", "title": "GreenHyperSpectra: A multi-source hyperspectral dataset for global vegetation trait prediction", "authors": ["Eya Cherif", "Arthur Ouaknine", "Luke A. Brown", "Phuong D. Dao", "Kyle R. Kovach", "Bing Lu", "Daniel Mederer", "Hannes Feilhauer", "Teja Kattenborn", "David Rolnick"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06806v1", "summary": "Plant traits such as leaf carbon content and leaf mass are essential\nvariables in the study of biodiversity and climate change. However,\nconventional field sampling cannot feasibly cover trait variation at\necologically meaningful spatial scales. Machine learning represents a valuable\nsolution for plant trait prediction across ecosystems, leveraging hyperspectral\ndata from remote sensing. Nevertheless, trait prediction from hyperspectral\ndata is challenged by label scarcity and substantial domain shifts (\\eg across\nsensors, ecological distributions), requiring robust cross-domain methods.\nHere, we present GreenHyperSpectra, a pretraining dataset encompassing\nreal-world cross-sensor and cross-ecosystem samples designed to benchmark trait\nprediction with semi- and self-supervised methods. We adopt an evaluation\nframework encompassing in-distribution and out-of-distribution scenarios. We\nsuccessfully leverage GreenHyperSpectra to pretrain label-efficient\nmulti-output regression models that outperform the state-of-the-art supervised\nbaseline. Our empirical analyses demonstrate substantial improvements in\nlearning spectral representations for trait prediction, establishing a\ncomprehensive methodological framework to catalyze research at the intersection\nof representation learning and plant functional traits assessment. All code and\ndata are available at: https://github.com/echerif18/HyspectraSSL.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06806v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07067", "title": "How to Bridge the Sim-to-Real Gap in Digital Twin-Aided Telecommunication Networks", "authors": ["Clement Ruah", "Houssem Sifaou", "Osvaldo Simeone", "Bashir M. Al-Hashimi"], "categories": ["eess.SP", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.07067v1", "summary": "Training effective artificial intelligence models for telecommunications is\nchallenging due to the scarcity of deployment-specific data. Real data\ncollection is expensive, and available datasets often fail to capture the\nunique operational conditions and contextual variability of the network\nenvironment. Digital twinning provides a potential solution to this problem, as\nsimulators tailored to the current network deployment can generate\nsite-specific data to augment the available training datasets. However, there\nis a need to develop solutions to bridge the inherent simulation-to-reality\n(sim-to-real) gap between synthetic and real-world data. This paper reviews\nrecent advances on two complementary strategies: 1) the calibration of digital\ntwins (DTs) through real-world measurements, and 2) the use of sim-to-real\ngap-aware training strategies to robustly handle residual discrepancies between\ndigital twin-generated and real data. For the latter, we evaluate two\nconceptually distinct methods that model the sim-to-real gap either at the\nlevel of the environment via Bayesian learning or at the level of the training\nloss via prediction-powered inference.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.07067v1", "cate": "eess.SP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06325", "title": "Optimization of Fractal Image Compression", "authors": ["Nastaran Pourshab"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06325v1", "summary": "Fractal Image Compression (FIC) is a lossy image compression technique that\nleverages self-similarity within an image to achieve high compression ratios.\nHowever, the process of compressing the image is computationally expensive.\nThis paper investigates optimization techniques to improve the efficiency of\nFIC, focusing on increasing compression ratio and reducing computational time.\nThe paper explores a novel approach named the Box Counting Method for\nestimating fractal dimensions, which is very simple to integrate into FIC\ncompared to other algorithms. The results show that implementing these\noptimization techniques enhances both the compression ratio and the compression\ntime.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06325v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06959", "title": "CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale", "authors": ["Xiao Liang", "Jiawei Hu", "Di Wang", "Zhi Ma", "Lin Zhao", "Ronghan Li", "Bo Wan", "Quan Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06959v1", "summary": "Vision-language models (VLMs) are prone to hallucinations that critically\ncompromise reliability in medical applications. While preference optimization\ncan mitigate these hallucinations through clinical feedback, its implementation\nfaces challenges such as clinically irrelevant training samples, imbalanced\ndata distributions, and prohibitive expert annotation costs. To address these\nchallenges, we introduce CheXPO, a Chest X-ray Preference Optimization strategy\nthat combines confidence-similarity joint mining with counterfactual rationale.\nOur approach begins by synthesizing a unified, fine-grained multi-task chest\nX-ray visual instruction dataset across different question types for supervised\nfine-tuning (SFT). We then identify hard examples through token-level\nconfidence analysis of SFT failures and use similarity-based retrieval to\nexpand hard examples for balancing preference sample distributions, while\nsynthetic counterfactual rationales provide fine-grained clinical preferences,\neliminating the need for additional expert input. Experiments show that CheXPO\nachieves 8.93% relative performance gain using only 5% of SFT samples, reaching\nstate-of-the-art performance across diverse clinical tasks and providing a\nscalable, interpretable solution for real-world radiology applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06959v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07016", "title": "On-Device Training of PV Power Forecasting Models in a Smart Meter for Grid Edge Intelligence", "authors": ["Jian Huang", "Yongli Zhu", "Linna Xu", "Zhe Zheng", "Wenpeng Cui", "Mingyang Sun"], "categories": ["cs.LG", "eess.SP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper is currently under reviewing by an IEEE publication; it may be subjected to minor changes due to review comments later", "url": "http://arxiv.org/abs/2507.07016v1", "summary": "In this paper, an edge-side model training study is conducted on a\nresource-limited smart meter. The motivation of grid-edge intelligence and the\nconcept of on-device training are introduced. Then, the technical preparation\nsteps for on-device training are described. A case study on the task of\nphotovoltaic power forecasting is presented, where two representative machine\nlearning models are investigated: a gradient boosting tree model and a\nrecurrent neural network model. To adapt to the resource-limited situation in\nthe smart meter, \"mixed\"- and \"reduced\"-precision training schemes are also\ndevised. Experiment results demonstrate the feasibility of economically\nachieving grid-edge intelligence via the existing advanced metering\ninfrastructures.", "comment": "This paper is currently under reviewing by an IEEE publication; it\n  may be subjected to minor changes due to review comments later", "pdf_url": "http://arxiv.org/pdf/2507.07016v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06814", "title": "HVI-CIDNet+: Beyond Extreme Darkness for Low-Light Image Enhancement", "authors": ["Qingsen Yan", "Kangbiao Shi", "Yixu Feng", "Tao Hu", "Peng Wu", "Guansong Pang", "Yanning Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      14 pages", "url": "http://arxiv.org/abs/2507.06814v1", "summary": "Low-Light Image Enhancement (LLIE) aims to restore vivid content and details\nfrom corrupted low-light images. However, existing standard RGB (sRGB) color\nspace-based LLIE methods often produce color bias and brightness artifacts due\nto the inherent high color sensitivity. While Hue, Saturation, and Value (HSV)\ncolor space can decouple brightness and color, it introduces significant red\nand black noise artifacts. To address this problem, we propose a new color\nspace for LLIE, namely Horizontal/Vertical-Intensity (HVI), defined by the HV\ncolor map and learnable intensity. The HV color map enforces small distances\nfor the red coordinates to remove red noise artifacts, while the learnable\nintensity compresses the low-light regions to remove black noise artifacts.\nAdditionally, we introduce the Color and Intensity Decoupling Network+\n(HVI-CIDNet+), built upon the HVI color space, to restore damaged content and\nmitigate color distortion in extremely dark regions. Specifically, HVI-CIDNet+\nleverages abundant contextual and degraded knowledge extracted from low-light\nimages using pre-trained vision-language models, integrated via a novel\nPrior-guided Attention Block (PAB). Within the PAB, latent semantic priors can\npromote content restoration, while degraded representations guide precise color\ncorrection, both particularly in extremely dark regions through the\nmeticulously designed cross-attention fusion mechanism. Furthermore, we\nconstruct a Region Refinement Block that employs convolution for\ninformation-rich regions and self-attention for information-scarce regions,\nensuring accurate brightness adjustments. Comprehensive results from benchmark\nexperiments demonstrate that the proposed HVI-CIDNet+ outperforms the\nstate-of-the-art methods on 10 datasets.", "comment": "14 pages", "pdf_url": "http://arxiv.org/pdf/2507.06814v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07081", "title": "Joint Target Acquisition and Refined Position Estimation in OFDM-based ISAC Networks", "authors": ["Lorenzo Pucci", "Andrea Giorgetti"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      5 pages, 6 figures; This paper was presented at the 2025 IEEE SPAWC conference", "url": "http://arxiv.org/abs/2507.07081v1", "summary": "This paper addresses joint target acquisition and position estimation in an\nOFDM-based integrated sensing and communication (ISAC) network with base\nstation (BS) cooperation via a fusion center. A two-stage framework is\nproposed: in the first stage, each BS computes range-angle maps to detect\ntargets and estimate coarse positions, exploiting spatial diversity. In the\nsecond stage, refined localization is performed using a cooperative maximum\nlikelihood (ML) estimator over predefined regions of interest (RoIs) within a\nshared global reference frame. Numerical results demonstrate that the proposed\napproach not only improves detection performance through BS cooperation but\nalso achieves centimeter-level localization accuracy, highlighting the\neffectiveness of the refined estimation technique.", "comment": "5 pages, 6 figures; This paper was presented at the 2025 IEEE SPAWC\n  conference", "pdf_url": "http://arxiv.org/pdf/2507.07081v1", "cate": "eess.SP", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06363", "title": "Mamba Goes HoME: Hierarchical Soft Mixture-of-Experts for 3D Medical Image Segmentation", "authors": ["Szymon Płotka", "Maciej Chrabaszcz", "Gizem Mert", "Ewa Szczurek", "Arkadiusz Sitek"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06363v1", "summary": "In recent years, artificial intelligence has significantly advanced medical\nimage segmentation. However, challenges remain, including efficient 3D medical\nimage processing across diverse modalities and handling data variability. In\nthis work, we introduce Hierarchical Soft Mixture-of-Experts (HoME), a\ntwo-level token-routing layer for efficient long-context modeling, specifically\ndesigned for 3D medical image segmentation. Built on the Mamba state-space\nmodel (SSM) backbone, HoME enhances sequential modeling through sparse,\nadaptive expert routing. The first stage employs a Soft Mixture-of-Experts\n(SMoE) layer to partition input sequences into local groups, routing tokens to\nspecialized per-group experts for localized feature extraction. The second\nstage aggregates these outputs via a global SMoE layer, enabling cross-group\ninformation fusion and global context refinement. This hierarchical design,\ncombining local expert routing with global expert refinement improves\ngeneralizability and segmentation performance, surpassing state-of-the-art\nresults across datasets from the three most commonly used 3D medical imaging\nmodalities and data quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06363v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06992", "title": "MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation", "authors": ["Qilong Xing", "Zikai Song", "Youjia Zhang", "Na Feng", "Junqing Yu", "Wei Yang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      MICCAI 2025", "url": "http://arxiv.org/abs/2507.06992v1", "summary": "Despite significant advancements in adapting Large Language Models (LLMs) for\nradiology report generation (RRG), clinical adoption remains challenging due to\ndifficulties in accurately mapping pathological and anatomical features to\ntheir corresponding text descriptions. Additionally, semantic agnostic feature\nextraction further hampers the generation of accurate diagnostic reports. To\naddress these challenges, we introduce Medical Concept Aligned Radiology Report\nGeneration (MCA-RG), a knowledge-driven framework that explicitly aligns visual\nfeatures with distinct medical concepts to enhance the report generation\nprocess. MCA-RG utilizes two curated concept banks: a pathology bank containing\nlesion-related knowledge, and an anatomy bank with anatomical descriptions. The\nvisual features are aligned with these medical concepts and undergo tailored\nenhancement. We further propose an anatomy-based contrastive learning procedure\nto improve the generalization of anatomical features, coupled with a matching\nloss for pathological features to prioritize clinically relevant regions.\nAdditionally, a feature gating mechanism is employed to filter out low-quality\nconcept features. Finally, the visual features are corresponding to individual\nmedical concepts, and are leveraged to guide the report generation process.\nExperiments on two public benchmarks (MIMIC-CXR and CheXpert Plus) demonstrate\nthat MCA-RG achieves superior performance, highlighting its effectiveness in\nradiology report generation.", "comment": "MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.06992v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07032", "title": "PLAME: Leveraging Pretrained Language Models to Generate Enhanced Protein Multiple Sequence Alignments", "authors": ["Hanqun Cao", "Xinyi Zhou", "Zijun Gao", "Chenyu Wang", "Xin Gao", "Zhi Zhang", "Chunbin Gu", "Ge Liu", "Pheng-Ann Heng"], "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07032v1", "summary": "Protein structure prediction is essential for drug discovery and\nunderstanding biological functions. While recent advancements like AlphaFold\nhave achieved remarkable accuracy, most folding models rely heavily on multiple\nsequence alignments (MSAs) to boost prediction performance. This dependency\nlimits their effectiveness on low-homology proteins and orphan proteins, where\nMSA information is sparse or unavailable. To address this limitation, we\npropose PLAME, a novel MSA design model that leverages evolutionary embeddings\nfrom pretrained protein language models. Unlike existing methods, PLAME\nintroduces pretrained representations to enhance evolutionary information and\nemploys a conservation-diversity loss to enhance generation quality.\nAdditionally, we propose a novel MSA selection method to effectively screen\nhigh-quality MSAs and improve folding performance. We also propose a sequence\nquality assessment metric that provides an orthogonal perspective to evaluate\nMSA quality. On the AlphaFold2 benchmark of low-homology and orphan proteins,\nPLAME achieves state-of-the-art performance in folding enhancement and sequence\nquality assessment, with consistent improvements demonstrated on AlphaFold3.\nAblation studies validate the effectiveness of the MSA selection method, while\nextensive case studies on various protein types provide insights into the\nrelationship between AlphaFold's prediction quality and MSA characteristics.\nFurthermore, we demonstrate that PLAME can serve as an adapter achieving\nAlphaFold2-level accuracy with the ESMFold's inference speed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07032v1", "cate": "cs.LG", "date": "2025-06-17", "updated": "2025-06-17"}
{"id": "2507.06848", "title": "Know Your Attention Maps: Class-specific Token Masking for Weakly Supervised Semantic Segmentation", "authors": ["Joelle Hanna", "Damian Borth"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06848v1", "summary": "Weakly Supervised Semantic Segmentation (WSSS) is a challenging problem that\nhas been extensively studied in recent years. Traditional approaches often rely\non external modules like Class Activation Maps to highlight regions of interest\nand generate pseudo segmentation masks. In this work, we propose an end-to-end\nmethod that directly utilizes the attention maps learned by a Vision\nTransformer (ViT) for WSSS. We propose training a sparse ViT with multiple\n[CLS] tokens (one for each class), using a random masking strategy to promote\n[CLS] token - class assignment. At inference time, we aggregate the different\nself-attention maps of each [CLS] token corresponding to the predicted labels\nto generate pseudo segmentation masks. Our proposed approach enhances the\ninterpretability of self-attention maps and ensures accurate class assignments.\nExtensive experiments on two standard benchmarks and three specialized datasets\ndemonstrate that our method generates accurate pseudo-masks, outperforming\nrelated works. Those pseudo-masks can be used to train a segmentation model\nwhich achieves results comparable to fully-supervised models, significantly\nreducing the need for fine-grained labeled data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06848v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06575", "title": "COS2A: Conversion from Sentinel-2 to AVIRIS Hyperspectral Data Using Interpretable Algorithm With Spectral-Spatial Duality", "authors": ["Chia-Hsiang Lin", "Jui-Ting Chen", "Zi-Chao Leng", "Jhao-Ting Lin"], "categories": ["eess.IV", "eess.SP"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      15 pages, 7 figures", "url": "http://arxiv.org/abs/2507.06575v1", "summary": "The Sentinel-2 satellite, launched by the European Space Agency (ESA), offers\nextensive spatial coverage and has become indispensable in a wide range of\nremote sensing applications. However, it just has 12 spectral bands, making\nsubstances/objects identification less effective, not mentioning the varying\nspatial resolutions (10/20/60 m) across the 12 bands. If such a\nmulti-resolution 12-band image can be computationally converted into a\nhyperspectral image with uniformly high resolution (i.e., 10 m), it\nsignificantly facilitates remote identification tasks. Though there are some\nspectral super-resolution methods, they did not address the multi-resolution\nissue on one hand, and, more seriously, they mostly focused on the CAVE-level\nhyperspectral image reconstruction (involving only 31 visible bands) on the\nother hand, greatly limiting their applicability in real-world remote sensing\nscenarios. We ambitiously aim to convert Sentinel-2 data directly into NASA's\nAVIRIS-level hyperspectral image (encompassing up to 172 visible and\nnear-infrared (NIR) bands, after ignoring those absorption/corruption ones).\nFor the first time, this paper solves this specific super-resolution problem\n(highly ill-posed), allowing all historical Sentinel-2 data to have their\ncorresponding high-standard AVIRIS counterparts. We achieve so by customizing a\nnovel algorithm that introduces deep unfolding regularization and\nQ-quadratic-norm regularization into the so-called convex/deep (CODE)\nsmall-data learning criterion. Based on the derived spectral-spatial duality,\nthe proposed interpretable COS2A algorithm demonstrates superior spectral\nsuper-resolution results across diverse land cover types, as validated through\nextensive experiments.", "comment": "15 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.06575v1", "cate": "eess.IV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06384", "title": "Mitigating Multi-Sequence 3D Prostate MRI Data Scarcity through Domain Adaptation using Locally-Trained Latent Diffusion Models for Prostate Cancer Detection", "authors": ["Emerson P. Grabke", "Babak Taati", "Masoom A. Haider"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      BT and MAH are co-senior authors on the work. This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.06384v1", "summary": "Objective: Latent diffusion models (LDMs) could mitigate data scarcity\nchallenges affecting machine learning development for medical image\ninterpretation. The recent CCELLA LDM improved prostate cancer detection\nperformance using synthetic MRI for classifier training but was limited to the\naxial T2-weighted (AxT2) sequence, did not investigate inter-institutional\ndomain shift, and prioritized radiology over histopathology outcomes. We\npropose CCELLA++ to address these limitations and improve clinical utility.\nMethods: CCELLA++ expands CCELLA for simultaneous biparametric prostate MRI\n(bpMRI) generation, including the AxT2, high b-value diffusion series (HighB)\nand apparent diffusion coefficient map (ADC). Domain adaptation was\ninvestigated by pretraining classifiers on real or LDM-generated synthetic data\nfrom an internal institution, followed with fine-tuning on progressively\nsmaller fractions of an out-of-distribution, external dataset. Results:\nCCELLA++ improved 3D FID for HighB and ADC but not AxT2 (0.013, 0.012, 0.063\nrespectively) sequences compared to CCELLA (0.060). Classifier pretraining with\nCCELLA++ bpMRI outperformed real bpMRI in AP and AUC for all domain adaptation\nscenarios. CCELLA++ pretraining achieved highest classifier performance below\n50% (n=665) external dataset volume. Conclusion: Synthetic bpMRI generated by\nour method can improve downstream classifier generalization and performance\nbeyond real bpMRI or CCELLA-generated AxT2-only images. Future work should seek\nto quantify medical image sample quality, balance multi-sequence LDM training,\nand condition the LDM with additional information. Significance: The proposed\nCCELLA++ LDM can generate synthetic bpMRI that outperforms real data for domain\nadaptation with a limited target institution dataset. Our code is available at\nhttps://github.com/grabkeem/CCELLA-plus-plus", "comment": "BT and MAH are co-senior authors on the work. This work has been\n  submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.06384v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06994", "title": "Cross-Modality Masked Learning for Survival Prediction in ICI Treated NSCLC Patients", "authors": ["Qilong Xing", "Zikai Song", "Bingxin Gong", "Lian Yang", "Junqing Yu", "Wei Yang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      MICCAI 2025", "url": "http://arxiv.org/abs/2507.06994v1", "summary": "Accurate prognosis of non-small cell lung cancer (NSCLC) patients undergoing\nimmunotherapy is essential for personalized treatment planning, enabling\ninformed patient decisions, and improving both treatment outcomes and quality\nof life. However, the lack of large, relevant datasets and effective\nmulti-modal feature fusion strategies pose significant challenges in this\ndomain. To address these challenges, we present a large-scale dataset and\nintroduce a novel framework for multi-modal feature fusion aimed at enhancing\nthe accuracy of survival prediction. The dataset comprises 3D CT images and\ncorresponding clinical records from NSCLC patients treated with immune\ncheckpoint inhibitors (ICI), along with progression-free survival (PFS) and\noverall survival (OS) data. We further propose a cross-modality masked learning\napproach for medical feature fusion, consisting of two distinct branches, each\ntailored to its respective modality: a Slice-Depth Transformer for extracting\n3D features from CT images and a graph-based Transformer for learning node\nfeatures and relationships among clinical variables in tabular data. The fusion\nprocess is guided by a masked modality learning strategy, wherein the model\nutilizes the intact modality to reconstruct missing components. This mechanism\nimproves the integration of modality-specific features, fostering more\neffective inter-modality relationships and feature interactions. Our approach\ndemonstrates superior performance in multi-modal integration for NSCLC survival\nprediction, surpassing existing methods and setting a new benchmark for\nprognostic models in this context.", "comment": "MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.06994v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07033", "title": "Self-Supervised Learning at the Edge: The Cost of Labeling", "authors": ["Roberto Pereira", "Fernanda Famá", "Asal Rangrazi", "Marco Miozzo", "Charalampos Kalalas", "Paolo Dini"], "categories": ["cs.LG", "eess.SP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted for publication in IEEE MLSP 2025", "url": "http://arxiv.org/abs/2507.07033v1", "summary": "Contrastive learning (CL) has recently emerged as an alternative to\ntraditional supervised machine learning solutions by enabling rich\nrepresentations from unstructured and unlabeled data. However, CL and, more\nbroadly, self-supervised learning (SSL) methods often demand a large amount of\ndata and computational resources, posing challenges for deployment on\nresource-constrained edge devices. In this work, we explore the feasibility and\nefficiency of SSL techniques for edge-based learning, focusing on trade-offs\nbetween model performance and energy efficiency. In particular, we analyze how\ndifferent SSL techniques adapt to limited computational, data, and energy\nbudgets, evaluating their effectiveness in learning robust representations\nunder resource-constrained settings. Moreover, we also consider the energy\ncosts involved in labeling data and assess how semi-supervised learning may\nassist in reducing the overall energy consumed to train CL models. Through\nextensive experiments, we demonstrate that tailored SSL strategies can achieve\ncompetitive performance while reducing resource consumption by up to 4X,\nunderscoring their potential for energy-efficient learning at the edge.", "comment": "Accepted for publication in IEEE MLSP 2025", "pdf_url": "http://arxiv.org/pdf/2507.07033v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06858", "title": "Longitudinal Study of Facial Biometrics at the BEZ: Temporal Variance Analysis", "authors": ["Mathias Schulz", "Alexander Spenke", "Pia Funk", "Florian Blümel", "Markus Rohde", "Ralph Breithaupt", "Gerd Nolden", "Norbert Jung", "Robert Lange"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 10 figures, 8 tables", "url": "http://arxiv.org/abs/2507.06858v1", "summary": "This study presents findings from long-term biometric evaluations conducted\nat the Biometric Evaluation Center (bez). Over the course of two and a half\nyears, our ongoing research with over 400 participants representing diverse\nethnicities, genders, and age groups were regularly assessed using a variety of\nbiometric tools and techniques at the controlled testing facilities. Our\nfindings are based on the General Data Protection Regulation-compliant local\nbez database with more than 238.000 biometric data sets categorized into\nmultiple biometric modalities such as face and finger. We used state-of-the-art\nface recognition algorithms to analyze long-term comparison scores. Our results\nshow that these scores fluctuate more significantly between individual days\nthan over the entire measurement period. These findings highlight the\nimportance of testing biometric characteristics of the same individuals over a\nlonger period of time in a controlled measurement environment and lays the\ngroundwork for future advancements in biometric data analysis.", "comment": "11 pages, 10 figures, 8 tables", "pdf_url": "http://arxiv.org/pdf/2507.06858v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06769", "title": "Constraint Optimized Multichannel Mixer-limiter Design", "authors": ["Yuancheng Luo", "Dmitriy Yamkovoy", "Guillermo Garcia"], "categories": ["cs.SD", "eess.AS", "eess.SP", "math.OC"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      For submission to ICASSP 2026", "url": "http://arxiv.org/abs/2507.06769v1", "summary": "Multichannel audio mixer and limiter designs are conventionally decoupled for\ncontent reproduction over loudspeaker arrays due to high computational\ncomplexity and run-time costs. We propose a coupled mixer-limiter-envelope\ndesign formulated as an efficient linear-constrained quadratic program that\nminimizes a distortion objective over multichannel gain variables subject to\nsample mixture constraints. Novel methods for asymmetric constant overlap-add\nwindow optimization, objective function approximation, variable and constraint\nreduction are presented. Experiments demonstrate distortion reduction of the\ncoupled design, and computational trade-offs required for efficient real-time\nprocessing.", "comment": "For submission to ICASSP 2026", "pdf_url": "http://arxiv.org/pdf/2507.06769v1", "cate": "cs.SD", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06410", "title": "Attention-Enhanced Deep Learning Ensemble for Breast Density Classification in Mammography", "authors": ["Peyman Sharifian", "Xiaotong Hong", "Alireza Karimian", "Mehdi Amini", "Hossein Arabi"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      2025 IEEE Nuclear Science Symposium, Medical Imaging Conference and Room Temperature Semiconductor Detector Conference", "url": "http://arxiv.org/abs/2507.06410v1", "summary": "Breast density assessment is a crucial component of mammographic\ninterpretation, with high breast density (BI-RADS categories C and D)\nrepresenting both a significant risk factor for developing breast cancer and a\ntechnical challenge for tumor detection. This study proposes an automated deep\nlearning system for robust binary classification of breast density (low: A/B\nvs. high: C/D) using the VinDr-Mammo dataset. We implemented and compared four\nadvanced convolutional neural networks: ResNet18, ResNet50, EfficientNet-B0,\nand DenseNet121, each enhanced with channel attention mechanisms. To address\nthe inherent class imbalance, we developed a novel Combined Focal Label\nSmoothing Loss function that integrates focal loss, label smoothing, and\nclass-balanced weighting. Our preprocessing pipeline incorporated advanced\ntechniques, including contrast-limited adaptive histogram equalization (CLAHE)\nand comprehensive data augmentation. The individual models were combined\nthrough an optimized ensemble voting approach, achieving superior performance\n(AUC: 0.963, F1-score: 0.952) compared to any single model. This system\ndemonstrates significant potential to standardize density assessments in\nclinical practice, potentially improving screening efficiency and early cancer\ndetection rates while reducing inter-observer variability among radiologists.", "comment": "2025 IEEE Nuclear Science Symposium, Medical Imaging Conference and\n  Room Temperature Semiconductor Detector Conference", "pdf_url": "http://arxiv.org/pdf/2507.06410v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.07024", "title": "FlexOlmo: Open Language Models for Flexible Data Use", "authors": ["Weijia Shi", "Akshita Bhagia", "Kevin Farhat", "Niklas Muennighoff", "Pete Walsh", "Jacob Morrison", "Dustin Schwenk", "Shayne Longpre", "Jake Poznanski", "Allyson Ettinger", "Daogao Liu", "Margaret Li", "Dirk Groeneveld", "Mike Lewis", "Wen-tau Yih", "Luca Soldaini", "Kyle Lo", "Noah A. Smith", "Luke Zettlemoyer", "Pang Wei Koh", "Hannaneh Hajishirzi", "Ali Farhadi", "Sewon Min"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07024v1", "summary": "We introduce FlexOlmo, a new class of language models (LMs) that supports (1)\ndistributed training without data sharing, where different model parameters are\nindependently trained on closed datasets, and (2) data-flexible inference,\nwhere these parameters along with their associated data can be flexibly\nincluded or excluded from model inferences with no further training. FlexOlmo\nemploys a mixture-of-experts (MoE) architecture where each expert is trained\nindependently on closed datasets and later integrated through a new\ndomain-informed routing without any joint training. FlexOlmo is trained on\nFlexMix, a corpus we curate comprising publicly available datasets alongside\nseven domain-specific sets, representing realistic approximations of closed\nsets. We evaluate models with up to 37 billion parameters (20 billion active)\non 31 diverse downstream tasks. We show that a general expert trained on public\ndata can be effectively combined with independently trained experts from other\ndata owners, leading to an average 41% relative improvement while allowing\nusers to opt out of certain data based on data licensing or permission\nrequirements. Our approach also outperforms prior model merging methods by\n10.1% on average and surpasses the standard MoE trained without data\nrestrictions using the same training FLOPs. Altogether, this research presents\na solution for both data owners and researchers in regulated industries with\nsensitive or protected data. FlexOlmo enables benefiting from closed data while\nrespecting data owners' preferences by keeping their data local and supporting\nfine-grained control of data access during inference.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07024v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07061", "title": "An Ensemble Embedding Approach for Improving Semantic Caching Performance in LLM-based Systems", "authors": ["Shervin Ghaffari", "Zohre Bahranifard", "Mohammad Akbari"], "categories": ["cs.LG", "68T50", "I.2.7; H.3.3; I.5.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 8 figures, 2 table. Submitted to the Journal of Information Science", "url": "http://arxiv.org/abs/2507.07061v1", "summary": "Semantic caching enhances the efficiency of large language model (LLM)\nsystems by identifying semantically similar queries, storing responses once,\nand serving them for subsequent equivalent requests. However, existing semantic\ncaching frameworks rely on single embedding models for query representation,\nwhich limits their ability to capture the diverse semantic relationships\npresent in real-world query distributions. This paper presents an ensemble\nembedding approach that combines multiple embedding models through a trained\nmeta-encoder to improve semantic similarity detection in LLM caching systems.\nWe evaluate our method using the Quora Question Pairs (QQP) dataset, measuring\ncache hit ratios, cache miss ratios, token savings, and response times. Our\nensemble approach achieves a 92\\% cache hit ratio for semantically equivalent\nqueries while maintaining an 85\\% accuracy in correctly rejecting\nnon-equivalent queries as cache misses. These results demonstrate that ensemble\nembedding methods significantly outperform single-model approaches in\ndistinguishing between semantically similar and dissimilar queries, leading to\nmore effective caching performance and reduced computational overhead in\nLLM-based systems.", "comment": "10 pages, 8 figures, 2 table. Submitted to the Journal of Information\n  Science", "pdf_url": "http://arxiv.org/pdf/2507.07061v1", "cate": "cs.LG", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06906", "title": "SemRaFiner: Panoptic Segmentation in Sparse and Noisy Radar Point Clouds", "authors": ["Matthias Zeller", "Daniel Casado Herraez", "Bengisu Ayan", "Jens Behley", "Michael Heidingsfeld", "Cyrill Stachniss"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for publication in IEEE Robotics and Automation Letters (RA-L)", "url": "http://arxiv.org/abs/2507.06906v1", "summary": "Semantic scene understanding, including the perception and classification of\nmoving agents, is essential to enabling safe and robust driving behaviours of\nautonomous vehicles. Cameras and LiDARs are commonly used for semantic scene\nunderstanding. However, both sensor modalities face limitations in adverse\nweather and usually do not provide motion information. Radar sensors overcome\nthese limitations and directly offer information about moving agents by\nmeasuring the Doppler velocity, but the measurements are comparably sparse and\nnoisy. In this paper, we address the problem of panoptic segmentation in sparse\nradar point clouds to enhance scene understanding. Our approach, called\nSemRaFiner, accounts for changing density in sparse radar point clouds and\noptimizes the feature extraction to improve accuracy. Furthermore, we propose\nan optimized training procedure to refine instance assignments by incorporating\na dedicated data augmentation. Our experiments suggest that our approach\noutperforms state-of-the-art methods for radar-based panoptic segmentation.", "comment": "Accepted for publication in IEEE Robotics and Automation Letters\n  (RA-L)", "pdf_url": "http://arxiv.org/pdf/2507.06906v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06826", "title": "Physics-Informed Direction-Aware Neural Acoustic Fields", "authors": ["Yoshiki Masuyama", "François G. Germain", "Gordon Wichern", "Christopher Ick", "Jonathan Le Roux"], "categories": ["cs.SD", "eess.AS", "eess.SP"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted to WASPAA 2025", "url": "http://arxiv.org/abs/2507.06826v1", "summary": "This paper presents a physics-informed neural network (PINN) for modeling\nfirst-order Ambisonic (FOA) room impulse responses (RIRs). PINNs have\ndemonstrated promising performance in sound field interpolation by combining\nthe powerful modeling capability of neural networks and the physical principles\nof sound propagation. In room acoustics, PINNs have typically been trained to\nrepresent the sound pressure measured by omnidirectional microphones where the\nwave equation or its frequency-domain counterpart, i.e., the Helmholtz\nequation, is leveraged. Meanwhile, FOA RIRs additionally provide spatial\ncharacteristics and are useful for immersive audio generation with a wide range\nof applications. In this paper, we extend the PINN framework to model FOA RIRs.\nWe derive two physics-informed priors for FOA RIRs based on the correspondence\nbetween the particle velocity and the (X, Y, Z)-channels of FOA. These priors\nassociate the predicted W-channel and other channels through their partial\nderivatives and impose the physically feasible relationship on the four\nchannels. Our experiments confirm the effectiveness of the proposed method\ncompared with a neural network without the physics-informed prior.", "comment": "Accepted to WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.06826v1", "cate": "cs.SD", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06417", "title": "Capsule-ConvKAN: A Hybrid Neural Approach to Medical Image Classification", "authors": ["Laura Pituková", "Peter Sinčák", "László József Kovács"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Preprint version. Accepted to IEEE SMC 2025", "url": "http://arxiv.org/abs/2507.06417v1", "summary": "This study conducts a comprehensive comparison of four neural network\narchitectures: Convolutional Neural Network, Capsule Network, Convolutional\nKolmogorov--Arnold Network, and the newly proposed Capsule--Convolutional\nKolmogorov--Arnold Network. The proposed Capsule-ConvKAN architecture combines\nthe dynamic routing and spatial hierarchy capabilities of Capsule Network with\nthe flexible and interpretable function approximation of Convolutional\nKolmogorov--Arnold Networks. This novel hybrid model was developed to improve\nfeature representation and classification accuracy, particularly in challenging\nreal-world biomedical image data. The architectures were evaluated on a\nhistopathological image dataset, where Capsule-ConvKAN achieved the highest\nclassification performance with an accuracy of 91.21\\%. The results demonstrate\nthe potential of the newly introduced Capsule-ConvKAN in capturing spatial\npatterns, managing complex features, and addressing the limitations of\ntraditional convolutional models in medical image classification.", "comment": "Preprint version. Accepted to IEEE SMC 2025", "pdf_url": "http://arxiv.org/pdf/2507.06417v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06470", "title": "Open-Set Source Tracing of Audio Deepfake Systems", "authors": ["Nicholas Klein", "Hemlata Tak", "Elie Khoury"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted by INTERSPEECH 2025 as part of the special session \"Source Tracing: The Origins of Synthetic or Manipulated Speech\"", "url": "http://arxiv.org/abs/2507.06470v1", "summary": "Existing research on source tracing of audio deepfake systems has focused\nprimarily on the closed-set scenario, while studies that evaluate open-set\nperformance are limited to a small number of unseen systems. Due to the large\nnumber of emerging audio deepfake systems, robust open-set source tracing is\ncritical. We leverage the protocol of the Interspeech 2025 special session on\nsource tracing to evaluate methods for improving open-set source tracing\nperformance. We introduce a novel adaptation to the energy score for\nout-of-distribution (OOD) detection, softmax energy (SME). We find that\nreplacing the typical temperature-scaled energy score with SME provides a\nrelative average improvement of 31% in the standard FPR95 (false positive rate\nat true positive rate of 95%) measure. We further explore SME-guided training\nas well as copy synthesis, codec, and reverberation augmentations, yielding an\nFPR95 of 8.3%.", "comment": "Accepted by INTERSPEECH 2025 as part of the special session \"Source\n  Tracing: The Origins of Synthetic or Manipulated Speech\"", "pdf_url": "http://arxiv.org/pdf/2507.06470v1", "cate": "eess.AS", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07029", "title": "Design and Implementation of an OCR-Powered Pipeline for Table Extraction from Invoices", "authors": ["Parshva Dhilankumar Patel"], "categories": ["cs.CV", "cs.AI", "I.2.10; I.4.9; H.3.1"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 23 figures, submitted to arXiv in July 2025", "url": "http://arxiv.org/abs/2507.07029v1", "summary": "This paper presents the design and development of an OCR-powered pipeline for\nefficient table extraction from invoices. The system leverages Tesseract OCR\nfor text recognition and custom post-processing logic to detect, align, and\nextract structured tabular data from scanned invoice documents. Our approach\nincludes dynamic preprocessing, table boundary detection, and row-column\nmapping, optimized for noisy and non-standard invoice formats. The resulting\npipeline significantly improves data extraction accuracy and consistency,\nsupporting real-world use cases such as automated financial workflows and\ndigital archiving.", "comment": "17 pages, 23 figures, submitted to arXiv in July 2025", "pdf_url": "http://arxiv.org/pdf/2507.07029v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07100", "title": "Addressing Imbalanced Domain-Incremental Learning through Dual-Balance Collaborative Experts", "authors": ["Lan Li", "Da-Wei Zhou", "Han-Jia Ye", "De-Chuan Zhan"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by ICML 2025", "url": "http://arxiv.org/abs/2507.07100v1", "summary": "Domain-Incremental Learning (DIL) focuses on continual learning in\nnon-stationary environments, requiring models to adjust to evolving domains\nwhile preserving historical knowledge. DIL faces two critical challenges in the\ncontext of imbalanced data: intra-domain class imbalance and cross-domain class\ndistribution shifts. These challenges significantly hinder model performance,\nas intra-domain imbalance leads to underfitting of few-shot classes, while\ncross-domain shifts require maintaining well-learned many-shot classes and\ntransferring knowledge to improve few-shot class performance in old domains. To\novercome these challenges, we introduce the Dual-Balance Collaborative Experts\n(DCE) framework. DCE employs a frequency-aware expert group, where each expert\nis guided by specialized loss functions to learn features for specific\nfrequency groups, effectively addressing intra-domain class imbalance.\nSubsequently, a dynamic expert selector is learned by synthesizing\npseudo-features through balanced Gaussian sampling from historical class\nstatistics. This mechanism navigates the trade-off between preserving many-shot\nknowledge of previous domains and leveraging new data to improve few-shot class\nperformance in earlier tasks. Extensive experimental results on four benchmark\ndatasets demonstrate DCE's state-of-the-art performance.", "comment": "Accepted by ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.07100v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06928", "title": "Adaptive Part Learning for Fine-Grained Generalized Category Discovery: A Plug-and-Play Enhancement", "authors": ["Qiyuan Dai", "Hanzhuo Huang", "Yu Wu", "Sibei Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to CVPR 2025", "url": "http://arxiv.org/abs/2507.06928v1", "summary": "Generalized Category Discovery (GCD) aims to recognize unlabeled images from\nknown and novel classes by distinguishing novel classes from known ones, while\nalso transferring knowledge from another set of labeled images with known\nclasses. Existing GCD methods rely on self-supervised vision transformers such\nas DINO for representation learning. However, focusing solely on the global\nrepresentation of the DINO CLS token introduces an inherent trade-off between\ndiscriminability and generalization. In this paper, we introduce an adaptive\npart discovery and learning method, called APL, which generates consistent\nobject parts and their correspondences across different similar images using a\nset of shared learnable part queries and DINO part priors, without requiring\nany additional annotations. More importantly, we propose a novel all-min\ncontrastive loss to learn discriminative yet generalizable part representation,\nwhich adaptively highlights discriminative object parts to distinguish similar\ncategories for enhanced discriminability while simultaneously sharing other\nparts to facilitate knowledge transfer for improved generalization. Our APL can\neasily be incorporated into different GCD frameworks by replacing their CLS\ntoken feature with our part representations, showing significant enhancements\non fine-grained datasets.", "comment": "Accepted to CVPR 2025", "pdf_url": "http://arxiv.org/pdf/2507.06928v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07043", "title": "Advances in Intelligent Hearing Aids: Deep Learning Approaches to Selective Noise Cancellation", "authors": ["Haris Khan", "Shumaila Asif", "Hassan Nasir"], "categories": ["cs.SD", "cs.AI", "eess.AS", "eess.SP"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      22 pages, 4 figures, submitted as a systematic literature review in AI-based hearing assistance. (June 2025)", "url": "http://arxiv.org/abs/2507.07043v1", "summary": "The integration of artificial intelligence into hearing assistance marks a\nparadigm shift from traditional amplification-based systems to intelligent,\ncontext-aware audio processing. This systematic literature review evaluates\nadvances in AI-driven selective noise cancellation (SNC) for hearing aids,\nhighlighting technological evolution, implementation challenges, and future\nresearch directions. We synthesize findings across deep learning architectures,\nhardware deployment strategies, clinical validation studies, and user-centric\ndesign. The review traces progress from early machine learning models to\nstate-of-the-art deep networks, including Convolutional Recurrent Networks for\nreal-time inference and Transformer-based architectures for high-accuracy\nseparation. Key findings include significant gains over traditional methods,\nwith recent models achieving up to 18.3 dB SI-SDR improvement on\nnoisy-reverberant benchmarks, alongside sub-10 ms real-time implementations and\npromising clinical outcomes. Yet, challenges remain in bridging lab-grade\nmodels with real-world deployment - particularly around power constraints,\nenvironmental variability, and personalization. Identified research gaps\ninclude hardware-software co-design, standardized evaluation protocols, and\nregulatory considerations for AI-enhanced hearing devices. Future work must\nprioritize lightweight models, continual learning, contextual-based\nclassification and clinical translation to realize transformative hearing\nsolutions for millions globally.", "comment": "22 pages, 4 figures, submitted as a systematic literature review in\n  AI-based hearing assistance. (June 2025)", "pdf_url": "http://arxiv.org/pdf/2507.07043v1", "cate": "cs.SD", "date": "2025-06-25", "updated": "2025-06-25"}
{"id": "2507.06581", "title": "Airway Segmentation Network for Enhanced Tubular Feature Extraction", "authors": ["Qibiao Wu", "Yagang Wang", "Qian Zhang"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06581v1", "summary": "Manual annotation of airway regions in computed tomography images is a\ntime-consuming and expertise-dependent task. Automatic airway segmentation is\ntherefore a prerequisite for enabling rapid bronchoscopic navigation and the\nclinical deployment of bronchoscopic robotic systems. Although convolutional\nneural network methods have gained considerable attention in airway\nsegmentation, the unique tree-like structure of airways poses challenges for\nconventional and deformable convolutions, which often fail to focus on fine\nairway structures, leading to missed segments and discontinuities. To address\nthis issue, this study proposes a novel tubular feature extraction network,\nnamed TfeNet. TfeNet introduces a novel direction-aware convolution operation\nthat first applies spatial rotation transformations to adjust the sampling\npositions of linear convolution kernels. The deformed kernels are then\nrepresented as line segments or polylines in 3D space. Furthermore, a tubular\nfeature fusion module (TFFM) is designed based on asymmetric convolution and\nresidual connection strategies, enhancing the network's focus on subtle airway\nstructures. Extensive experiments conducted on one public dataset and two\ndatasets used in airway segmentation challenges demonstrate that the proposed\nTfeNet achieves more accuracy and continuous airway structure predictions\ncompared with existing methods. In particular, TfeNet achieves the highest\noverall score of 94.95% on the current largest airway segmentation dataset,\nAirway Tree Modeling(ATM22), and demonstrates advanced performance on the lung\nfibrosis dataset(AIIB23). The code is available at\nhttps://github.com/QibiaoWu/TfeNet.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06581v1", "cate": "eess.IV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06566", "title": "Training Strategies for Modality Dropout Resilient Multi-Modal Target Speaker Extraction", "authors": ["Srikanth Korse", "Mohamed Elminshawi", "Emanuel A. P. Habets", "Srikanth Raj Chetupalli"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Published in ICASSPW 2024 (HSCMA)", "url": "http://arxiv.org/abs/2507.06566v1", "summary": "The primary goal of multi-modal TSE (MTSE) is to extract a target speaker\nfrom a speech mixture using complementary information from different\nmodalities, such as audio enrolment and visual feeds corresponding to the\ntarget speaker. MTSE systems are expected to perform well even when one of the\nmodalities is unavailable. In practice, the systems often suffer from modality\ndominance, where one of the modalities outweighs the others, thereby limiting\nrobustness. Our study investigates training strategies and the effect of\narchitectural choices, particularly the normalization layers, in yielding a\nrobust MTSE system in both non-causal and causal configurations. In particular,\nwe propose the use of modality dropout training (MDT) as a superior strategy to\nstandard and multi-task training (MTT) strategies. Experiments conducted on\ntwo-speaker mixtures from the LRS3 dataset show the MDT strategy to be\neffective irrespective of the employed normalization layer. In contrast, the\nmodels trained with the standard and MTT strategies are susceptible to modality\ndominance, and their performance depends on the chosen normalization layer.\nAdditionally, we demonstrate that the system trained with MDT strategy is\nrobust to using extracted speech as the enrollment signal, highlighting its\npotential applicability in scenarios where the target speaker is not enrolled.", "comment": "Published in ICASSPW 2024 (HSCMA)", "pdf_url": "http://arxiv.org/pdf/2507.06566v1", "cate": "eess.AS", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07034", "title": "Surrogate Model for Heat Transfer Prediction in Impinging Jet Arrays using Dynamic Inlet/Outlet and Flow Rate Control", "authors": ["Mikael Vaillant", "Victor Oliveira Ferreira", "Wiebke Mainville", "Jean-Michel Lamarre", "Vincent Raymond", "Moncef Chioua", "Bruno Blais"], "categories": ["physics.flu-dyn", "cs.AI"], "primary_category": "Subjects:       Fluid Dynamics (physics.flu-dyn)", "pdf_link": null, "comments": "Comments:      37 pages, 13 figures", "url": "http://arxiv.org/abs/2507.07034v1", "summary": "This study presents a surrogate model designed to predict the Nusselt number\ndistribution in an enclosed impinging jet arrays, where each jet function\nindependently and where jets can be transformed from inlets to outlets, leading\nto a vast number of possible flow arrangements. While computational fluid\ndynamics (CFD) simulations can model heat transfer with high fidelity, their\ncost prohibits real-time application such as model-based temperature control.\nTo address this, we generate a CNN-based surrogate model that can predict the\nNusselt distribution in real time. We train it with data from implicit large\neddy computational fluid dynamics simulations (Re < 2,000). We train two\ndistinct models, one for a five by one array of jets (83 simulations) and one\nfor a three by three array of jets (100 simulations). We introduce a method to\nextrapolate predictions to higher Reynolds numbers (Re < 10,000) using a\ncorrelation-based scaling. The surrogate models achieve high accuracy, with a\nnormalized mean average error below 2% on validation data for the five by one\nsurrogate model and 0.6% for the three by three surrogate model. Experimental\nvalidation confirms the model's predictive capabilities. This work provides a\nfoundation for model-based control strategies in advanced thermal management\napplications.", "comment": "37 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.07034v1", "cate": "physics.flu-dyn", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07101", "title": "Small Batch Size Training for Language Models: When Vanilla SGD Works, and Why Gradient Accumulation Is Wasteful", "authors": ["Martin Marek", "Sanae Lotfi", "Aditya Somasundaram", "Andrew Gordon Wilson", "Micah Goldblum"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Code available at: this https URL", "url": "http://arxiv.org/abs/2507.07101v1", "summary": "Conventional wisdom dictates that small batch sizes make language model\npretraining and fine-tuning unstable, motivating gradient accumulation, which\ntrades off the number of optimizer steps for a proportional increase in batch\nsize. While it is common to decrease the learning rate for smaller batch sizes,\nother hyperparameters are often held fixed. In this work, we revisit small\nbatch sizes all the way down to batch size one, and we propose a rule for\nscaling Adam hyperparameters to small batch sizes. We find that small batch\nsizes (1) train stably, (2) are consistently more robust to hyperparameter\nchoices, (3) achieve equal or better per-FLOP performance than larger batch\nsizes, and (4) notably enable stable language model training with vanilla SGD,\neven without momentum, despite storing no optimizer state. Building on these\nresults, we provide practical recommendations for selecting a batch size and\nsetting optimizer hyperparameters. We further recommend against gradient\naccumulation unless training on multiple devices with multiple model replicas,\nbottlenecked by inter-device bandwidth.", "comment": "Code available at: https://github.com/martin-marek/batch-size", "pdf_url": "http://arxiv.org/pdf/2507.07101v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06948", "title": "MCCD: A Multi-Attribute Chinese Calligraphy Character Dataset Annotated with Script Styles, Dynasties, and Calligraphers", "authors": ["Yixin Zhao", "Yuyi Zhang", "Lianwen Jin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 8 figures, 9 tables, accepted by the 19th International Conference on Document Analysis and Recognition (ICDAR 2025)", "url": "http://arxiv.org/abs/2507.06948v1", "summary": "Research on the attribute information of calligraphy, such as styles,\ndynasties, and calligraphers, holds significant cultural and historical value.\nHowever, the styles of Chinese calligraphy characters have evolved dramatically\nthrough different dynasties and the unique touches of calligraphers, making it\nhighly challenging to accurately recognize these different characters and their\nattributes. Furthermore, existing calligraphic datasets are extremely scarce,\nand most provide only character-level annotations without additional attribute\ninformation. This limitation has significantly hindered the in-depth study of\nChinese calligraphy. To fill this gap, we present a novel Multi-Attribute\nChinese Calligraphy Character Dataset (MCCD). The dataset encompasses 7,765\ncategories with a total of 329,715 isolated image samples of Chinese\ncalligraphy characters, and three additional subsets were extracted based on\nthe attribute labeling of the three types of script styles (10 types),\ndynasties (15 periods) and calligraphers (142 individuals). The rich\nmulti-attribute annotations render MCCD well-suited diverse research tasks,\nincluding calligraphic character recognition, writer identification, and\nevolutionary studies of Chinese characters. We establish benchmark performance\nthrough single-task and multi-task recognition experiments across MCCD and all\nof its subsets. The experimental results demonstrate that the complexity of the\nstroke structure of the calligraphic characters, and the interplay between\ntheir different attributes, leading to a substantial increase in the difficulty\nof accurate recognition. MCCD not only fills a void in the availability of\ndetailed calligraphy datasets but also provides valuable resources for\nadvancing research in Chinese calligraphy and fostering advancements in\nmultiple fields. The dataset is available at\nhttps://github.com/SCUT-DLVCLab/MCCD.", "comment": "17 pages, 8 figures, 9 tables, accepted by the 19th International\n  Conference on Document Analysis and Recognition (ICDAR 2025)", "pdf_url": "http://arxiv.org/pdf/2507.06948v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07087", "title": "Incremental Averaging Method to Improve Graph-Based Time-Difference-of-Arrival Estimation", "authors": ["Klaus Brümann", "Kouei Yamaoka", "Nobutaka Ono", "Simon Doclo"], "categories": ["eess.AS", "eess.SP"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07087v1", "summary": "Estimating the position of a speech source based on\ntime-differences-of-arrival (TDOAs) is often adversely affected by background\nnoise and reverberation. A popular method to estimate the TDOA between a\nmicrophone pair involves maximizing a generalized cross-correlation with phase\ntransform (GCC-PHAT) function. Since the TDOAs across different microphone\npairs satisfy consistency relations, generally only a small subset of\nmicrophone pairs are used for source position estimation. Although the set of\nmicrophone pairs is often determined based on a reference microphone, recently\na more robust method has been proposed to determine the set of microphone pairs\nby computing the minimum spanning tree (MST) of a signal graph of GCC-PHAT\nfunction reliabilities. To reduce the influence of noise and reverberation on\nthe TDOA estimation accuracy, in this paper we propose to compute the GCC-PHAT\nfunctions of the MST based on an average of multiple cross-power spectral\ndensities (CPSDs) using an incremental method. In each step of the method, we\nincrease the number of CPSDs over which we average by considering CPSDs\ncomputed indirectly via other microphones from previous steps. Using signals\nrecorded in a noisy and reverberant laboratory with an array of spatially\ndistributed microphones, the performance of the proposed method is evaluated in\nterms of TDOA estimation error and 2D source position estimation error.\nExperimental results for different source and microphone configurations and\nthree reverberation conditions show that the proposed method considering\nmultiple CPSDs improves the TDOA estimation and source position estimation\naccuracy compared to the reference microphone- and MST-based methods that rely\non a single CPSD as well as steered-response power-based source position\nestimation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07087v1", "cate": "eess.AS", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06717", "title": "QoE Optimization for Semantic Self-Correcting Video Transmission in Multi-UAV Networks", "authors": ["Xuyang Chen", "Chong Huang", "Daquan Feng", "Lei Luo", "Yao Sun", "Xiang-Gen Xia"], "categories": ["eess.IV", "cs.MM"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      13 pages", "url": "http://arxiv.org/abs/2507.06717v1", "summary": "Real-time unmanned aerial vehicle (UAV) video streaming is essential for\ntime-sensitive applications, including remote surveillance, emergency response,\nand environmental monitoring. However, it faces challenges such as limited\nbandwidth, latency fluctuations, and high packet loss. To address these issues,\nwe propose a novel semantic self-correcting video transmission framework with\nultra-fine bitrate granularity (SSCV-G). In SSCV-G, video frames are encoded\ninto a compact semantic codebook space, and the transmitter adaptively sends a\nsubset of semantic indices based on bandwidth availability, enabling\nfine-grained bitrate control for improved bandwidth efficiency. At the\nreceiver, a spatio-temporal vision transformer (ST-ViT) performs multi-frame\njoint decoding to reconstruct dropped semantic indices by modeling intra- and\ninter-frame dependencies. To further improve performance under dynamic network\nconditions, we integrate a multi-user proximal policy optimization (MUPPO)\nreinforcement learning scheme that jointly optimizes communication resource\nallocation and semantic bitrate selection to maximize user Quality of\nExperience (QoE). Extensive experiments demonstrate that the proposed SSCV-G\nsignificantly outperforms state-of-the-art video codecs in coding efficiency,\nbandwidth adaptability, and packet loss robustness. Moreover, the proposed\nMUPPO-based QoE optimization consistently surpasses existing benchmarks.", "comment": "13 pages", "pdf_url": "http://arxiv.org/pdf/2507.06717v1", "cate": "eess.IV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06917", "title": "Musical Source Separation Bake-Off: Comparing Objective Metrics with Human Perception", "authors": ["Noah Jaffe", "John Ashley Burgoyne"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06917v1", "summary": "Music source separation aims to extract individual sound sources (e.g.,\nvocals, drums, guitar) from a mixed music recording. However, evaluating the\nquality of separated audio remains challenging, as commonly used metrics like\nthe source-to-distortion ratio (SDR) do not always align with human perception.\nIn this study, we conducted a large-scale listener evaluation on the MUSDB18\ntest set, collecting approximately 30 ratings per track from seven distinct\nlistener groups. We compared several objective energy-ratio metrics, including\nlegacy measures (BSSEval v4, SI-SDR variants), and embedding-based alternatives\n(Frechet Audio Distance using CLAP-LAION-music, EnCodec, VGGish, Wave2Vec2, and\nHuBERT). While SDR remains the best-performing metric for vocal estimates, our\nresults show that the scale-invariant signal-to-artifacts ratio (SI-SAR) better\npredicts listener ratings for drums and bass stems. Frechet Audio Distance\n(FAD) computed with the CLAP-LAION-music embedding also performs\ncompetitively--achieving Kendall's tau values of 0.25 for drums and 0.19 for\nbass--matching or surpassing energy-based metrics for those stems. However,\nnone of the embedding-based metrics, including CLAP, correlate positively with\nhuman perception for vocal estimates. These findings highlight the need for\nstem-specific evaluation strategies and suggest that no single metric reliably\nreflects perceptual quality across all source types. We release our raw\nlistener ratings to support reproducibility and further research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06917v1", "cate": "eess.AS", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07046", "title": "A Novel Hybrid Deep Learning Technique for Speech Emotion Detection using Feature Engineering", "authors": ["Shahana Yasmin Chowdhury", "Bithi Banik", "Md Tamjidul Hoque", "Shreya Banerjee"], "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      17 pages, 11 figures", "url": "http://arxiv.org/abs/2507.07046v1", "summary": "Nowadays, speech emotion recognition (SER) plays a vital role in the field of\nhuman-computer interaction (HCI) and the evolution of artificial intelligence\n(AI). Our proposed DCRF-BiLSTM model is used to recognize seven emotions:\nneutral, happy, sad, angry, fear, disgust, and surprise, which are trained on\nfive datasets: RAVDESS (R), TESS (T), SAVEE (S), EmoDB (E), and Crema-D (C).\nThe model achieves high accuracy on individual datasets, including 97.83% on\nRAVDESS, 97.02% on SAVEE, 95.10% for CREMA-D, and a perfect 100% on both TESS\nand EMO-DB. For the combined (R+T+S) datasets, it achieves 98.82% accuracy,\noutperforming previously reported results. To our knowledge, no existing study\nhas evaluated a single SER model across all five benchmark datasets (i.e.,\nR+T+S+C+E) simultaneously. In our work, we introduce this comprehensive\ncombination and achieve a remarkable overall accuracy of 93.76%. These results\nconfirm the robustness and generalizability of our DCRF-BiLSTM framework across\ndiverse datasets.", "comment": "17 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.07046v1", "cate": "cs.SD", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07102", "title": "Does Data Scaling Lead to Visual Compositional Generalization?", "authors": ["Arnas Uselis", "Andrea Dittadi", "Seong Joon Oh"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025", "url": "http://arxiv.org/abs/2507.07102v1", "summary": "Compositional understanding is crucial for human intelligence, yet it remains\nunclear whether contemporary vision models exhibit it. The dominant machine\nlearning paradigm is built on the premise that scaling data and model sizes\nwill improve out-of-distribution performance, including compositional\ngeneralization. We test this premise through controlled experiments that\nsystematically vary data scale, concept diversity, and combination coverage. We\nfind that compositional generalization is driven by data diversity, not mere\ndata scale. Increased combinatorial coverage forces models to discover a\nlinearly factored representational structure, where concepts decompose into\nadditive components. We prove this structure is key to efficiency, enabling\nperfect generalization from few observed combinations. Evaluating pretrained\nmodels (DINO, CLIP), we find above-random yet imperfect performance, suggesting\npartial presence of this structure. Our work motivates stronger emphasis on\nconstructing diverse datasets for compositional generalization, and considering\nthe importance of representational structure that enables efficient\ncompositional learning. Code available at\nhttps://github.com/oshapio/visual-compositional-generalization.", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.07102v1", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06949", "title": "Pre-Columbian Settlements Shaped Palm Clusters in the Sierra Nevada de Santa Marta, Colombia", "authors": ["Sebastian Fajardo", "Sina Mohammadi", "Jonas Gregorio de Souza", "César Ardila", "Alan Tapscott Baltar", "Shaddai Heidgen", "Maria Isabel Mayorga Hernández", "Sylvia Mota de Oliveira", "Fernando Montejo", "Marco Moderato", "Vinicius Peripato", "Katy Puche", "Carlos Reina", "Juan Carlos Vargas", "Frank W. Takes", "Marco Madella"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06949v1", "summary": "Ancient populations markedly transformed Neotropical forests, yet\nunderstanding the long-term effects of ancient human management, particularly\nat high-resolution scales, remains challenging. In this work we propose a new\napproach to investigate archaeological areas of influence based on vegetation\nsignatures. It consists of a deep learning model trained on satellite imagery\nto identify palm trees, followed by a clustering algorithm to identify palm\nclusters, which are then used to estimate ancient management areas. To assess\nthe palm distribution in relation to past human activity, we applied the\nproposed approach to unique high-resolution satellite imagery data covering 765\nkm2 of the Sierra Nevada de Santa Marta, Colombia. With this work, we also\nrelease a manually annotated palm tree dataset along with estimated locations\nof archaeological sites from ground-surveys and legacy records. Results\ndemonstrate how palms were significantly more abundant near archaeological\nsites showing large infrastructure investment. The extent of the largest palm\ncluster indicates that ancient human-managed areas linked to major\ninfrastructure sites may be up to two orders of magnitude bigger than indicated\nby archaeological evidence alone. Our findings suggest that pre-Columbian\npopulations influenced local vegetation fostering conditions conducive to palm\nproliferation, leaving a lasting ecological footprint. This may have lowered\nthe logistical costs of establishing infrastructure-heavy settlements in\notherwise less accessible locations. Overall, this study demonstrates the\npotential of integrating artificial intelligence approaches with new ecological\nand archaeological data to identify archaeological areas of interest through\nvegetation patterns, revealing fine-scale human-environment interactions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06949v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2306.15297", "title": "Beampattern Design for Transmit Architectures Based on Reconfigurable Intelligent Surfaces", "authors": ["Ciro D'Elia", "Emanuele Grossi", "Luca Venturino"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted for publication in IEEE Transactions on Vehicular Technology", "url": "http://arxiv.org/abs/2306.15297v4", "summary": "In this work, we tackle the problem of beampattern design for a transmit\nsystem employing a large reconfigurable intelligent surface (RIS) to redirect\nradio frequency signals emitted by a few active antennas (sources). We begin by\nestablishing a convenient signal model and discussing the impact of signal\nbandwidth, source-RIS channel, and system geometry on our derivations.\nSubsequently, we propose a joint optimization of the waveform emitted by each\nsource and the phase shifts introduced by the RIS. The objective is to match a\ndesired space-frequency distribution of the far-field radiation pattern,\nrelevant to both radar and communication applications. We present a sub-optimal\nsolution to this problem, subject to a constraint on the total power radiated\nby the sources and, optionally, on the constant modulus of the waveforms. The\nprovided example demonstrates the effective beampattern shaping capabilities of\nthis RIS-based transmit architecture. Specifically, for the same array size and\nthe same desired radiation pattern, the resulting approximation error is\ncomparable to that obtained with a fully-digital MIMO array, especially when\nconstant-modulus waveforms are enforced, and significantly smaller than that of\na phased array.", "comment": "Accepted for publication in IEEE Transactions on Vehicular Technology", "pdf_url": "http://arxiv.org/pdf/2306.15297v4", "cate": "eess.SP", "date": "2023-06-27", "updated": "2025-07-09"}
{"id": "2507.06764", "title": "Fast Equivariant Imaging: Acceleration for Unsupervised Learning via Augmented Lagrangian and Auxiliary PnP Denoisers", "authors": ["Guixian Xu", "Jinglai Li", "Junqi Tang"], "categories": ["eess.IV", "cs.CV", "cs.LG", "math.OC"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06764v1", "summary": "We propose Fast Equivariant Imaging (FEI), a novel unsupervised learning\nframework to efficiently train deep imaging networks without ground-truth data.\nFrom the perspective of reformulating the Equivariant Imaging based\noptimization problem via the method of Lagrange multipliers and utilizing\nplug-and-play denoisers, this novel unsupervised scheme shows superior\nefficiency and performance compared to vanilla Equivariant Imaging paradigm. In\nparticular, our PnP-FEI scheme achieves an order-of-magnitude (10x)\nacceleration over standard EI on training U-Net with CT100 dataset for X-ray CT\nreconstruction, with improved generalization performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06764v1", "cate": "eess.IV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07068", "title": "Deep Feed-Forward Neural Network for Bangla Isolated Speech Recognition", "authors": ["Dipayan Bhadra", "Mehrab Hosain", "Fatema Alam"], "categories": ["eess.AS", "cs.SD", "68T05", "I.2.7; I.5.1; H.5.2"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      12 pages, 3 figures, 4 tables. published in Jatiya Kabi Kazi Nazrul Islam University, Vol. 10 No. 1-2, 2025 this https URL", "url": "http://arxiv.org/abs/2507.07068v1", "summary": "As the most important human-machine interfacing tool, an insignificant amount\nof work has been carried out on Bangla Speech Recognition compared to the\nEnglish language. Motivated by this, in this work, the performance of\nspeaker-independent isolated speech recognition systems has been implemented\nand analyzed using a dataset that is created containing both isolated Bangla\nand English spoken words. An approach using the Mel Frequency Cepstral\nCoefficient (MFCC) and Deep Feed-Forward Fully Connected Neural Network (DFFNN)\nof 7 layers as a classifier is proposed in this work to recognize isolated\nspoken words. This work shows 93.42% recognition accuracy which is better\ncompared to most of the works done previously on Bangla speech recognition\nconsidering the number of classes and dataset size.", "comment": "12 pages, 3 figures, 4 tables. published in Jatiya Kabi Kazi Nazrul\n  Islam University, Vol. 10 No. 1-2, 2025 https://jkkniu.edu.bd/13817-2/", "pdf_url": "http://arxiv.org/pdf/2507.07068v1", "cate": "eess.AS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.07058", "title": "Comparative Analysis of CNN and Transformer Architectures with Heart Cycle Normalization for Automated Phonocardiogram Classification", "authors": ["Martin Sondermann", "Pinar Bisgin", "Niklas Tschorn", "Anja Burmann", "Christoph M. Friedrich"], "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Preprint Version. Accepted at EMBC 2025", "url": "http://arxiv.org/abs/2507.07058v1", "summary": "The automated classification of phonocardiogram (PCG) recordings represents a\nsubstantial advancement in cardiovascular diagnostics. This paper presents a\nsystematic comparison of four distinct models for heart murmur detection: two\nspecialized convolutional neural networks (CNNs) and two zero-shot universal\naudio transformers (BEATs), evaluated using fixed-length and heart cycle\nnormalization approaches. Utilizing the PhysioNet2022 dataset, a custom heart\ncycle normalization method tailored to individual cardiac rhythms is\nintroduced. The findings indicate the following AUROC values: the CNN model\nwith fixed-length windowing achieves 79.5%, the CNN model with heart cycle\nnormalization scores 75.4%, the BEATs transformer with fixed-length windowing\nachieves 65.7%, and the BEATs transformer with heart cycle normalization\nresults in 70.1%.\n  The findings indicate that physiological signal constraints, especially those\nintroduced by different normalization strategies, have a substantial impact on\nmodel performance. The research provides evidence-based guidelines for\narchitecture selection in clinical settings, emphasizing the need for a balance\nbetween accuracy and computational efficiency. Although specialized CNNs\ndemonstrate superior performance overall, the zero-shot transformer models may\noffer promising efficiency advantages during development, such as faster\ntraining and evaluation cycles, despite their lower classification accuracy.\nThese findings highlight the potential of automated classification systems to\nenhance cardiac diagnostics and improve patient care.", "comment": "Preprint Version. Accepted at EMBC 2025", "pdf_url": "http://arxiv.org/pdf/2507.07058v1", "cate": "cs.SD", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06243", "title": "A Machine Learning Framework for Breast Cancer Treatment Classification Using a Novel Dataset", "authors": ["Md Nahid Hasan", "Md Monzur Murshed", "Md Mahadi Hasan", "Faysal A. Chowdhury"], "categories": ["stat.AP", "cs.LG"], "primary_category": "Subjects:       Applications (stat.AP)", "pdf_link": null, "comments": "Comments:      12 pages, 3 figures, 3 tables. This paper has been submitted to Scientific Reports and has been under review for five months", "url": "http://arxiv.org/abs/2507.06243v1", "summary": "Breast cancer (BC) remains a significant global health challenge, with\npersonalized treatment selection complicated by the disease's molecular and\nclinical heterogeneity. BC treatment decisions rely on various patient-specific\nclinical factors, and machine learning (ML) offers a powerful approach to\npredicting treatment outcomes. This study utilizes The Cancer Genome Atlas\n(TCGA) breast cancer clinical dataset to develop ML models for predicting the\nlikelihood of undergoing chemotherapy or hormonal therapy. The models are\ntrained using five-fold cross-validation and evaluated through performance\nmetrics, including accuracy, precision, recall, specificity, sensitivity,\nF1-score, and area under the receiver operating characteristic curve (AUROC).\nModel uncertainty is assessed using bootstrap techniques, while SHAP values\nenhance interpretability by identifying key predictors. Among the tested\nmodels, the Gradient Boosting Machine (GBM) achieves the highest stable\nperformance (accuracy = 0.7718, AUROC = 0.8252), followed by Extreme Gradient\nBoosting (XGBoost) (accuracy = 0.7557, AUROC = 0.8044) and Adaptive Boosting\n(AdaBoost) (accuracy = 0.7552, AUROC = 0.8016). These findings underscore the\npotential of ML in supporting personalized breast cancer treatment decisions\nthrough data-driven insights.", "comment": "12 pages, 3 figures, 3 tables. This paper has been submitted to\n  Scientific Reports and has been under review for five months", "pdf_url": "http://arxiv.org/pdf/2507.06243v1", "cate": "stat.AP", "date": "2025-06-23", "updated": "2025-06-23"}
{"id": "2507.06966", "title": "Segmentation Regularized Training for Multi-Domain Deep Learning Registration applied to MR-Guided Prostate Cancer Radiotherapy", "authors": ["Sudharsan Madhavan", "Chengcheng Gui", "Lando Bosma", "Josiah Simeth", "Jue Jiang", "Nicolas Cote", "Nima Hassan Rezaeian", "Himanshu Nagar", "Victoria Brennan", "Neelam Tyagi", "Harini Veeraraghavan"], "categories": ["cs.CV", "physics.med-ph"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Preprint in preparation for submission", "url": "http://arxiv.org/abs/2507.06966v1", "summary": "Background: Accurate deformable image registration (DIR) is required for\ncontour propagation and dose accumulation in MR-guided adaptive radiotherapy\n(MRgART). This study trained and evaluated a deep learning DIR method for\ndomain invariant MR-MR registration. Methods: A progressively refined\nregistration and segmentation (ProRSeg) method was trained with 262 pairs of 3T\nMR simulation scans from prostate cancer patients using weighted segmentation\nconsistency loss. ProRSeg was tested on same- (58 pairs), cross- (72 1.5T MR\nLinac pairs), and mixed-domain (42 MRSim-MRL pairs) datasets for contour\npropagation accuracy of clinical target volume (CTV), bladder, and rectum. Dose\naccumulation was performed for 42 patients undergoing 5-fraction MRgART.\nResults: ProRSeg demonstrated generalization for bladder with similar Dice\nSimilarity Coefficients across domains (0.88, 0.87, 0.86). For rectum and CTV,\nperformance was domain-dependent with higher accuracy on cross-domain MRL\ndataset (DSCs 0.89) versus same-domain data. The model's strong cross-domain\nperformance prompted us to study the feasibility of using it for dose\naccumulation. Dose accumulation showed 83.3% of patients met CTV coverage (D95\n>= 40.0 Gy) and bladder sparing (D50 <= 20.0 Gy) constraints. All patients\nachieved minimum mean target dose (>40.4 Gy), but only 9.5% remained under\nupper limit (<42.0 Gy). Conclusions: ProRSeg showed reasonable multi-domain\nMR-MR registration performance for prostate cancer patients with preliminary\nfeasibility for evaluating treatment compliance to clinical constraints.", "comment": "Preprint in preparation for submission", "pdf_url": "http://arxiv.org/pdf/2507.06966v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2505.10150", "title": "CFARNet: Learning-Based High-Resolution Multi-Target Detection for Rainbow Beam Radar", "authors": ["Qiushi Liang", "Yeyue Cai", "Jianhua Mo", "Meixia Tao"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      6 pages, 6 figures", "url": "http://arxiv.org/abs/2505.10150v2", "summary": "Millimeter-wave (mmWave) OFDM radar equipped with rainbow beamforming,\nenabled by phase-time arrays (PTAs), provides wide-angle coverage and is\nwell-suited for fast real-time target detection and tracking. However, accurate\ndetection of multiple closely spaced targets remains a key challenge for\nconventional signal processing pipelines, particularly those relying on\nconstant false alarm rate (CFAR) detectors. This paper presents CFARNet, a\nlearning-based processing framework that replaces CFAR with a convolutional\nneural network (CNN) for peak detection in the angle-Doppler domain. The\nnetwork predicts target subcarrier indices, which guide angle estimation via a\nknown frequency-angle mapping and enable high-resolution range and velocity\nestimation using the MUSIC algorithm. Extensive simulations demonstrate that\nCFARNet significantly outperforms a baseline combining CFAR and MUSIC,\nespecially under low transmit power and dense multi-target conditions. The\nproposed method offers superior angular resolution, enhanced robustness in\nlow-SNR scenarios, and improved computational efficiency, highlighting the\npotential of data-driven approaches for high-resolution mmWave radar sensing.", "comment": "6 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2505.10150v2", "cate": "eess.SP", "date": "2025-05-15", "updated": "2025-07-09"}
{"id": "2507.06937", "title": "Dataset and Benchmark for Enhancing Critical Retained Foreign Object Detection", "authors": ["Yuli Wang", "Victoria R. Shi", "Liwei Zhou", "Richard Chin", "Yuwei Dai", "Yuanyun Hu", "Cheng-Yi Li", "Haoyue Guan", "Jiashu Cheng", "Yu Sun", "Cheng Ting Lin", "Ihab Kamel", "Premal Trivedi", "Pamela Johnson", "John Eng", "Harrison Bai"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06937v1", "summary": "Critical retained foreign objects (RFOs), including surgical instruments like\nsponges and needles, pose serious patient safety risks and carry significant\nfinancial and legal implications for healthcare institutions. Detecting\ncritical RFOs using artificial intelligence remains challenging due to their\nrarity and the limited availability of chest X-ray datasets that specifically\nfeature critical RFOs cases. Existing datasets only contain non-critical RFOs,\nlike necklace or zipper, further limiting their utility for developing\nclinically impactful detection algorithms. To address these limitations, we\nintroduce \"Hopkins RFOs Bench\", the first and largest dataset of its kind,\ncontaining 144 chest X-ray images of critical RFO cases collected over 18 years\nfrom the Johns Hopkins Health System. Using this dataset, we benchmark several\nstate-of-the-art object detection models, highlighting the need for enhanced\ndetection methodologies for critical RFO cases. Recognizing data scarcity\nchallenges, we further explore image synthetic methods to bridge this gap. We\nevaluate two advanced synthetic image methods, DeepDRR-RFO, a physics-based\nmethod, and RoentGen-RFO, a diffusion-based method, for creating realistic\nradiographs featuring critical RFOs. Our comprehensive analysis identifies the\nstrengths and limitations of each synthetic method, providing insights into\neffectively utilizing synthetic data to enhance model training. The Hopkins\nRFOs Bench and our findings significantly advance the development of reliable,\ngeneralizable AI-driven solutions for detecting critical RFOs in clinical chest\nX-rays.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06937v1", "cate": "eess.IV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06481", "title": "IMPACT: Industrial Machine Perception via Acoustic Cognitive Transformer", "authors": ["Changheon Han", "Yuseop Sim", "Hoin Jung", "Jiho Lee", "Hojun Lee", "Yun Seok Kang", "Sucheol Woo", "Garam Kim", "Hyung Wook Park", "Martin Byung-Guk Jun"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06481v1", "summary": "Acoustic signals from industrial machines offer valuable insights for anomaly\ndetection, predictive maintenance, and operational efficiency enhancement.\nHowever, existing task-specific, supervised learning methods often scale poorly\nand fail to generalize across diverse industrial scenarios, whose acoustic\ncharacteristics are distinct from general audio. Furthermore, the scarcity of\naccessible, large-scale datasets and pretrained models tailored for industrial\naudio impedes community-driven research and benchmarking. To address these\nchallenges, we introduce DINOS (Diverse INdustrial Operation Sounds), a\nlarge-scale open-access dataset. DINOS comprises over 74,149 audio samples\n(exceeding 1,093 hours) collected from various industrial acoustic scenarios.\nWe also present IMPACT (Industrial Machine Perception via Acoustic Cognitive\nTransformer), a novel foundation model for industrial machine sound analysis.\nIMPACT is pretrained on DINOS in a self-supervised manner. By jointly\noptimizing utterance and frame-level losses, it captures both global semantics\nand fine-grained temporal structures. This makes its representations suitable\nfor efficient fine-tuning on various industrial downstream tasks with minimal\nlabeled data. Comprehensive benchmarking across 30 distinct downstream tasks\n(spanning four machine types) demonstrates that IMPACT outperforms existing\nmodels on 24 tasks, establishing its superior effectiveness and robustness,\nwhile providing a new performance benchmark for future research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06481v1", "cate": "cs.SD", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07060", "title": "DeepRetro: Retrosynthetic Pathway Discovery using Iterative LLM Reasoning", "authors": ["Shreyas Vinaya Sathyanarayana", "Rahil Shah", "Sharanabasava D. Hiremath", "Rishikesh Panda", "Rahul Jana", "Riya Singh", "Rida Irfan", "Ashwin Murali", "Bharath Ramsundar"], "categories": ["q-bio.QM", "cs.AI", "cs.CL", "cs.LG", "q-bio.BM", "q-bio.MN"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "Comments:      51 pages,", "url": "http://arxiv.org/abs/2507.07060v1", "summary": "Retrosynthesis, the identification of precursor molecules for a target\ncompound, is pivotal for synthesizing complex molecules, but faces challenges\nin discovering novel pathways beyond predefined templates. Recent large\nlanguage model (LLM) approaches to retrosynthesis have shown promise but\neffectively harnessing LLM reasoning capabilities for effective multi-step\nplanning remains an open question. To address this challenge, we introduce\nDeepRetro, an open-source, iterative, hybrid LLM-based retrosynthetic\nframework. Our approach integrates the strengths of conventional\ntemplate-based/Monte Carlo tree search tools with the generative power of LLMs\nin a step-wise, feedback-driven loop. Initially, synthesis planning is\nattempted with a template-based engine. If this fails, the LLM subsequently\nproposes single-step retrosynthetic disconnections. Crucially, these\nsuggestions undergo rigorous validity, stability, and hallucination checks\nbefore the resulting precursors are recursively fed back into the pipeline for\nfurther evaluation. This iterative refinement allows for dynamic pathway\nexploration and correction. We demonstrate the potential of this pipeline\nthrough benchmark evaluations and case studies, showcasing its ability to\nidentify viable and potentially novel retrosynthetic routes. In particular, we\ndevelop an interactive graphical user interface that allows expert human\nchemists to provide human-in-the-loop feedback to the reasoning algorithm. This\napproach successfully generates novel pathways for complex natural product\ncompounds, demonstrating the potential for iterative LLM reasoning to advance\nstate-of-art in complex chemical syntheses.", "comment": "51 pages,", "pdf_url": "http://arxiv.org/pdf/2507.07060v1", "cate": "q-bio.QM", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.06344", "title": "Trainability of Quantum Models Beyond Known Classical Simulability", "authors": ["Sabri Meyer", "Francesco Scala", "Francesco Tacchino", "Aurelien Lucchi"], "categories": ["quant-ph", "cs.CC", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      11 pages, 7 figures, 52 pages of supplementary material", "url": "http://arxiv.org/abs/2507.06344v1", "summary": "Variational Quantum Algorithms (VQAs) are promising candidates for near-term\nquantum computing, yet they face scalability challenges due to barren plateaus,\nwhere gradients vanish exponentially in the system size. Recent conjectures\nsuggest that avoiding barren plateaus might inherently lead to classical\nsimulability, thus limiting the opportunities for quantum advantage. In this\nwork, we advance the theoretical understanding of the relationship between the\ntrainability and computational complexity of VQAs, thus directly addressing the\nconjecture. We introduce the Linear Clifford Encoder (LCE), a novel technique\nthat ensures constant-scaling gradient statistics on optimization landscape\nregions that are close to Clifford circuits. Additionally, we leverage\nclassical Taylor surrogates to reveal computational complexity phase\ntransitions from polynomial to super-polynomial as the initialization region\nsize increases. Combining these results, we reveal a deeper link between\ntrainability and computational complexity, and analytically prove that barren\nplateaus can be avoided in regions for which no classical surrogate is known to\nexist. Furthermore, numerical experiments on LCE transformed landscapes confirm\nin practice the existence of a super-polynomially complex ``transition zone''\nwhere gradients decay polynomially. These findings indicate a plausible path to\npractically relevant, barren plateau-free variational models with potential for\nquantum advantage.", "comment": "11 pages, 7 figures, 52 pages of supplementary material", "pdf_url": "http://arxiv.org/pdf/2507.06344v1", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06972", "title": "A multi-modal dataset for insect biodiversity with imagery and DNA at the trap and individual level", "authors": ["Johanna Orsholm", "John Quinto", "Hannu Autto", "Gaia Banelyte", "Nicolas Chazot", "Jeremy deWaard", "Stephanie deWaard", "Arielle Farrell", "Brendan Furneaux", "Bess Hardwick", "Nao Ito", "Amlan Kar", "Oula Kalttopää", "Deirdre Kerdraon", "Erik Kristensen", "Jaclyn McKeown", "Tommi Mononen", "Ellen Nein", "Hanna Rogers", "Tomas Roslin", "Paula Schmitz", "Jayme Sones", "Maija Sujala", "Amy Thompson", "Evgeny V. Zakharov", "Iuliia Zarubiieva", "Akshita Gupta", "Scott C. Lowe", "Graham W. Taylor"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      13 pages, 6 figures, submitted to Scientific Data", "url": "http://arxiv.org/abs/2507.06972v1", "summary": "Insects comprise millions of species, many experiencing severe population\ndeclines under environmental and habitat changes. High-throughput approaches\nare crucial for accelerating our understanding of insect diversity, with DNA\nbarcoding and high-resolution imaging showing strong potential for automatic\ntaxonomic classification. However, most image-based approaches rely on\nindividual specimen data, unlike the unsorted bulk samples collected in\nlarge-scale ecological surveys. We present the Mixed Arthropod Sample\nSegmentation and Identification (MassID45) dataset for training automatic\nclassifiers of bulk insect samples. It uniquely combines molecular and imaging\ndata at both the unsorted sample level and the full set of individual\nspecimens. Human annotators, supported by an AI-assisted tool, performed two\ntasks on bulk images: creating segmentation masks around each individual\narthropod and assigning taxonomic labels to over 17 000 specimens. Combining\nthe taxonomic resolution of DNA barcodes with precise abundance estimates of\nbulk images holds great potential for rapid, large-scale characterization of\ninsect communities. This dataset pushes the boundaries of tiny object detection\nand instance segmentation, fostering innovation in both ecological and machine\nlearning research.", "comment": "13 pages, 6 figures, submitted to Scientific Data", "pdf_url": "http://arxiv.org/pdf/2507.06972v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2505.14478", "title": "A Direct Comparison of Simultaneously Recorded Scalp, Around-Ear, and In-Ear EEG for Neural Selective Auditory Attention Decoding to Speech", "authors": ["Simon Geirnaert", "Simon L. Kappel", "Preben Kidmose"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.14478v2", "summary": "Current assistive hearing devices, such as hearing aids and cochlear\nimplants, lack the ability to adapt to the listener's focus of auditory\nattention, limiting their effectiveness in complex acoustic environments like\ncocktail party scenarios where multiple conversations occur simultaneously.\nNeuro-steered hearing devices aim to overcome this limitation by decoding the\nlistener's auditory attention from neural signals, such as\nelectroencephalography (EEG). While many auditory attention decoding (AAD)\nstudies have used high-density scalp EEG, such systems are impractical for\ndaily use as they are bulky and uncomfortable. Therefore, AAD with wearable and\nunobtrusive EEG systems that are comfortable to wear and can be used for\nlong-term recording are required. Around-ear EEG systems like cEEGrids have\nshown promise in AAD, but in-ear EEG, recorded via custom earpieces offering\nsuperior comfort, remains underexplored. We present a new AAD dataset with\nsimultaneously recorded scalp, around-ear, and in-ear EEG, enabling a direct\ncomparison. Using a classic linear stimulus reconstruction algorithm, a\nsignificant performance gap between all three systems exists, with AAD\naccuracies of 83.4% (scalp), 67.2% (around-ear), and 61.1% (in-ear) on 60s\ndecision windows. These results highlight the trade-off between decoding\nperformance and practical usability. Yet, while the ear-based systems using\nbasic algorithms might currently not yield accurate enough performances for a\ndecision speed-sensitive application in hearing aids, their significant\nperformance suggests potential for attention monitoring on longer timescales.\nFurthermore, adding an external reference or a few scalp electrodes via greedy\nforward selection substantially and quickly boosts accuracy by over 10 percent\npoint, especially for in-ear EEG. These findings position in-ear EEG as a\npromising component in EEG sensor networks for AAD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.14478v2", "cate": "eess.SP", "date": "2025-05-20", "updated": "2025-07-09"}
{"id": "2507.06955", "title": "SimCortex: Collision-free Simultaneous Cortical Surfaces Reconstruction", "authors": ["Kaveh Moradkhani", "R Jarrett Rushmore", "Sylvain Bouix"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06955v1", "summary": "Accurate cortical surface reconstruction from magnetic resonance imaging\n(MRI) data is crucial for reliable neuroanatomical analyses. Current methods\nhave to contend with complex cortical geometries, strict topological\nrequirements, and often produce surfaces with overlaps, self-intersections, and\ntopological defects. To overcome these shortcomings, we introduce SimCortex, a\ndeep learning framework that simultaneously reconstructs all brain surfaces\n(left/right white-matter and pial) from T1-weighted(T1w) MRI volumes while\npreserving topological properties. Our method first segments the T1w image into\na nine-class tissue label map. From these segmentations, we generate\nsubject-specific, collision-free initial surface meshes. These surfaces serve\nas precise initializations for subsequent multiscale diffeomorphic\ndeformations. Employing stationary velocity fields (SVFs) integrated via\nscaling-and-squaring, our approach ensures smooth, topology-preserving\ntransformations with significantly reduced surface collisions and\nself-intersections. Evaluations on standard datasets demonstrate that SimCortex\ndramatically reduces surface overlaps and self-intersections, surpassing\ncurrent methods while maintaining state-of-the-art geometric accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06955v1", "cate": "eess.IV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06670", "title": "STARS: A Unified Framework for Singing Transcription, Alignment, and Refined Style Annotation", "authors": ["Wenxiang Guo", "Yu Zhang", "Changhao Pan", "Zhiyuan Zhu", "Ruiqi Li", "Zhetao Chen", "Wenhao Xu", "Fei Wu", "Zhou Zhao"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      9 pages, 2 figures", "url": "http://arxiv.org/abs/2507.06670v1", "summary": "Recent breakthroughs in singing voice synthesis (SVS) have heightened the\ndemand for high-quality annotated datasets, yet manual annotation remains\nprohibitively labor-intensive and resource-intensive. Existing automatic\nsinging annotation (ASA) methods, however, primarily tackle isolated aspects of\nthe annotation pipeline. To address this fundamental challenge, we present\nSTARS, which is, to our knowledge, the first unified framework that\nsimultaneously addresses singing transcription, alignment, and refined style\nannotation. Our framework delivers comprehensive multi-level annotations\nencompassing: (1) precise phoneme-audio alignment, (2) robust note\ntranscription and temporal localization, (3) expressive vocal technique\nidentification, and (4) global stylistic characterization including emotion and\npace. The proposed architecture employs hierarchical acoustic feature\nprocessing across frame, word, phoneme, note, and sentence levels. The novel\nnon-autoregressive local acoustic encoders enable structured hierarchical\nrepresentation learning. Experimental validation confirms the framework's\nsuperior performance across multiple evaluation dimensions compared to existing\nannotation approaches. Furthermore, applications in SVS training demonstrate\nthat models utilizing STARS-annotated data achieve significantly enhanced\nperceptual naturalness and precise style control. This work not only overcomes\ncritical scalability challenges in the creation of singing datasets but also\npioneers new methodologies for controllable singing voice synthesis. Audio\nsamples are available at https://gwx314.github.io/stars-demo/.", "comment": "9 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.06670v1", "cate": "cs.SD", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07066", "title": "Latent Acoustic Mapping for Direction of Arrival Estimation: A Self-Supervised Approach", "authors": ["Adrian S. Roman", "Iran R. Roman", "Juan P. Bello"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07066v1", "summary": "Acoustic mapping techniques have long been used in spatial audio processing\nfor direction of arrival estimation (DoAE). Traditional beamforming methods for\nacoustic mapping, while interpretable, often rely on iterative solvers that can\nbe computationally intensive and sensitive to acoustic variability. On the\nother hand, recent supervised deep learning approaches offer feedforward speed\nand robustness but require large labeled datasets and lack interpretability.\nDespite their strengths, both methods struggle to consistently generalize\nacross diverse acoustic setups and array configurations, limiting their broader\napplicability. We introduce the Latent Acoustic Mapping (LAM) model, a\nself-supervised framework that bridges the interpretability of traditional\nmethods with the adaptability and efficiency of deep learning methods. LAM\ngenerates high-resolution acoustic maps, adapts to varying acoustic conditions,\nand operates efficiently across different microphone arrays. We assess its\nrobustness on DoAE using the LOCATA and STARSS benchmarks. LAM achieves\ncomparable or superior localization performance to existing supervised methods.\nAdditionally, we show that LAM's acoustic maps can serve as effective features\nfor supervised models, further enhancing DoAE accuracy and underscoring its\npotential to advance adaptive, high-performance sound localization systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07066v1", "cate": "cs.SD", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06358", "title": "Deep learning-based species-area models reveal multi-scale patterns of species richness and turnover", "authors": ["Victor Boussange", "Philipp Brun", "Johanna T. Malle", "Gabriele Midolo", "Jeanne Portier", "Théophile Sanchez", "Niklaus E. Zimmermann", "Irena Axmanová", "Helge Bruelheide", "Milan Chytrý", "Stephan Kambach", "Zdeňka Lososová", "Martin Večeřa", "Idoia Biurrun", "Klaus T. Ecker", "Jonathan Lenoir", "Jens-Christian Svenning", "Dirk Nikolaus Karger"], "categories": ["q-bio.PE", "cs.LG", "92-08, 92B05, 92B15, 92B20, 92D40 (Primary) 62P10, 62P12 (Secondary)"], "primary_category": "Subjects:       Populations and Evolution (q-bio.PE)", "pdf_link": null, "comments": "Comments:      31 pages", "url": "http://arxiv.org/abs/2507.06358v1", "summary": "The number of species within ecosystems is influenced not only by their\nintrinsic characteristics but also by the spatial scale considered. As the\nsampled area expands, species richness increases, a phenomenon described by the\nspecies-area relationship (SAR). The accumulation dynamics of the SAR results\nfrom a complex interplay of biotic and abiotic processes operating at various\nspatial scales. However, the challenge of collecting exhaustive biodiversity\nrecords across spatial scales has hindered a comprehensive understanding of\nthese dynamics. Here, we develop a deep learning approach that leverages\nsampling theory and small-scale ecological surveys to spatially resolve the\nscale-dependency of species richness. We demonstrate its performance by\npredicting the species richness of vascular plant communities across Europe,\nand evaluate the predictions against an independent dataset of plant community\ninventories. Our model improves species richness estimates by 32\\% and delivers\nspatially explicit patterns of species richness and turnover for sampling areas\nranging from square meters to hundreds of square kilometers. Explainable AI\ntechniques further disentangle how drivers of species richness operate across\nspatial scales. The ability of our model to represent the multi-scale nature of\nbiodiversity is essential to deliver robust biodiversity assessments and\nforecasts under global change.", "comment": "31 pages", "pdf_url": "http://arxiv.org/pdf/2507.06358v1", "cate": "q-bio.PE", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06973", "title": "Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM", "authors": ["Qiyuan Dai", "Sibei Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to CVPR 2025", "url": "http://arxiv.org/abs/2507.06973v1", "summary": "Vision-Language Models (VLMs) have become prominent in open-world image\nrecognition for their strong generalization abilities. Yet, their effectiveness\nin practical applications is compromised by domain shifts and distributional\nchanges, especially when test data distributions diverge from training data.\nTherefore, the paradigm of test-time adaptation (TTA) has emerged, enabling the\nuse of online off-the-shelf data at test time, supporting independent sample\npredictions, and eliminating reliance on test annotations. Traditional TTA\nmethods, however, often rely on costly training or optimization processes, or\nmake unrealistic assumptions about accessing or storing historical training and\ntest data. Instead, this study proposes FreeTTA, a training-free and\nuniversally available method that makes no assumptions, to enhance the\nflexibility of TTA. More importantly, FreeTTA is the first to explicitly model\nthe test data distribution, enabling the use of intrinsic relationships among\ntest samples to enhance predictions of individual samples without simultaneous\naccess--a direction not previously explored. FreeTTA achieves these advantages\nby introducing an online EM algorithm that utilizes zero-shot predictions from\nVLMs as priors to iteratively compute the posterior probabilities of each\nonline test sample and update parameters. Experiments demonstrate that FreeTTA\nachieves stable and significant improvements compared to state-of-the-art\nmethods across 15 datasets in both cross-domain and out-of-distribution\nsettings.", "comment": "Accepted to CVPR 2025", "pdf_url": "http://arxiv.org/pdf/2507.06973v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.02168", "title": "Experimental Multiport-Network Parameter Estimation and Optimization for Multi-Bit RIS", "authors": ["Philipp del Hougne"], "categories": ["physics.app-ph", "eess.SP"], "primary_category": "Subjects:       Applied Physics (physics.app-ph)", "pdf_link": null, "comments": "Comments:      5 pages including 2 figures", "url": "http://arxiv.org/abs/2507.02168v2", "summary": "Physics-consistent theoretical studies on RIS-parametrized wireless channels\nuse models from multiport-network theory (MNT) to capture mutual-coupling (MC)\neffects. However, in practice, RIS design and radio environment are partially\nor completely unknown. We fill a research gap on how to estimate the MNT model\nparameters in such experimentally relevant scenarios. Our technique efficiently\ncombines closed-form and gradient-descent steps, and it can be applied to\nmulti-bit-programmable RIS elements. We discuss inevitable (but operationally\nirrelevant) parameter ambiguities. We experimentally validate our technique in\nan unknown rich-scattering environment parametrized by eight 6-bit-programmable\nRIS elements of unknown design. We experimentally evaluate the performance of\nRIS configurations optimized with the estimated MNT model and an MC-unaware\ncascaded model. While the models differ in accuracy by up to 17 dB, the\nend-to-end performance differences are small.", "comment": "5 pages including 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.02168v2", "cate": "physics.app-ph", "date": "2025-07-02", "updated": "2025-07-08"}
{"id": "2507.07011", "title": "Deep Brain Net: An Optimized Deep Learning Model for Brain tumor Detection in MRI Images Using EfficientNetB0 and ResNet50 with Transfer Learning", "authors": ["Daniel Onah", "Ravish Desai"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      9 pages, 14 figures, 4 tables. To be submitted to a conference", "url": "http://arxiv.org/abs/2507.07011v1", "summary": "In recent years, deep learning has shown great promise in the automated\ndetection and classification of brain tumors from MRI images. However,\nachieving high accuracy and computational efficiency remains a challenge. In\nthis research, we propose Deep Brain Net, a novel deep learning system designed\nto optimize performance in the detection of brain tumors. The model integrates\nthe strengths of two advanced neural network architectures which are\nEfficientNetB0 and ResNet50, combined with transfer learning to improve\ngeneralization and reduce training time. The EfficientNetB0 architecture\nenhances model efficiency by utilizing mobile inverted bottleneck blocks, which\nincorporate depth wise separable convolutions. This design significantly\nreduces the number of parameters and computational cost while preserving the\nability of models to learn complex feature representations. The ResNet50\narchitecture, pre trained on large scale datasets like ImageNet, is fine tuned\nfor brain tumor classification. Its use of residual connections allows for\ntraining deeper networks by mitigating the vanishing gradient problem and\navoiding performance degradation. The integration of these components ensures\nthat the proposed system is both computationally efficient and highly accurate.\nExtensive experiments performed on publicly available MRI datasets demonstrate\nthat Deep Brain Net consistently outperforms existing state of the art methods\nin terms of classification accuracy, precision, recall, and computational\nefficiency. The result is an accuracy of 88 percent, a weighted F1 score of\n88.75 percent, and a macro AUC ROC score of 98.17 percent which demonstrates\nthe robustness and clinical potential of Deep Brain Net in assisting\nradiologists with brain tumor diagnosis.", "comment": "9 pages, 14 figures, 4 tables. To be submitted to a conference", "pdf_url": "http://arxiv.org/pdf/2507.07011v1", "cate": "eess.IV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06794", "title": "Revealing the Hidden Temporal Structure of HubertSoft Embeddings based on the Russian Phonetic Corpus", "authors": ["Anastasia Ananeva", "Anton Tomilov", "Marina Volkova"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      11 pages, 5 figures, Specom 2025 conference", "url": "http://arxiv.org/abs/2507.06794v1", "summary": "Self-supervised learning (SSL) models such as Wav2Vec 2.0 and HuBERT have\nshown remarkable success in extracting phonetic information from raw audio\nwithout labelled data. While prior work has demonstrated that SSL embeddings\nencode phonetic features at the frame level, it remains unclear whether these\nmodels preserve temporal structure, specifically, whether embeddings at phoneme\nboundaries reflect the identity and order of adjacent phonemes. This study\ninvestigates the extent to which boundary-sensitive embeddings from HubertSoft,\na soft-clustering variant of HuBERT, encode phoneme transitions. Using the\nCORPRES Russian speech corpus, we labelled 20 ms embedding windows with\ntriplets of phonemes corresponding to their start, centre, and end segments. A\nneural network was trained to predict these positions separately, and multiple\nevaluation metrics, such as ordered, unordered accuracy and a flexible centre\naccuracy, were used to assess temporal sensitivity. Results show that\nembeddings extracted at phoneme boundaries capture both phoneme identity and\ntemporal order, with especially high accuracy at segment boundaries. Confusion\npatterns further suggest that the model encodes articulatory detail and\ncoarticulatory effects. These findings contribute to our understanding of the\ninternal structure of SSL speech representations and their potential for\nphonological analysis and fine-grained transcription tasks.", "comment": "11 pages, 5 figures, Specom 2025 conference", "pdf_url": "http://arxiv.org/pdf/2507.06794v1", "cate": "cs.SD", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07073", "title": "An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator", "authors": ["Yulin An", "Enrique del Castillo"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      18 pages, 9 figures, submitted for publication", "url": "http://arxiv.org/abs/2507.07073v1", "summary": "The spectrum of the Laplace-Beltrami (LB) operator is central in geometric\ndeep learning tasks, capturing intrinsic properties of the shape of the object\nunder consideration. The best established method for its estimation, from a\ntriangulated mesh of the object, is based on the Finite Element Method (FEM),\nand computes the top k LB eigenvalues with a complexity of O(Nk), where N is\nthe number of points. This can render the FEM method inefficient when\nrepeatedly applied to databases of CAD mechanical parts, or in quality control\napplications where part metrology is acquired as large meshes and decisions\nabout the quality of each part are needed quickly and frequently. As a solution\nto this problem, we present a geometric deep learning framework to predict the\nLB spectrum efficiently given the CAD mesh of a part, achieving significant\ncomputational savings without sacrificing accuracy, demonstrating that the LB\nspectrum is learnable. The proposed Graph Neural Network architecture uses a\nrich set of part mesh features - including Gaussian curvature, mean curvature,\nand principal curvatures. In addition to our trained network, we make\navailable, for repeatability, a large curated dataset of real-world mechanical\nCAD models derived from the publicly available ABC dataset used for training\nand testing. Experimental results show that our method reduces computation time\nof the LB spectrum by approximately 5 times over linear FEM while delivering\ncompetitive accuracy.", "comment": "18 pages, 9 figures, submitted for publication", "pdf_url": "http://arxiv.org/pdf/2507.07073v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06415", "title": "PERK: Long-Context Reasoning as Parameter-Efficient Test-Time Learning", "authors": ["Zeming Chen", "Angelika Romanou", "Gail Weiss", "Antoine Bosselut"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 7 figures", "url": "http://arxiv.org/abs/2507.06415v1", "summary": "Long-context reasoning requires accurately identifying relevant information\nin extensive, noisy input contexts. Previous research shows that using\ntest-time learning to encode context directly into model parameters can\neffectively enable reasoning over noisy information. However, meta-learning\nmethods for enabling test-time learning are prohibitively memory-intensive,\npreventing their application to long context settings. In this work, we propose\nPERK (Parameter Efficient Reasoning over Knowledge), a scalable approach for\nlearning to encode long input contexts using gradient updates to a lightweight\nmodel adapter at test time. Specifically, PERK employs two nested optimization\nloops in a meta-training phase. The inner loop rapidly encodes contexts into a\nlow-rank adapter (LoRA) that serves as a parameter-efficient memory module for\nthe base model. Concurrently, the outer loop learns to use the updated adapter\nto accurately recall and reason over relevant information from the encoded long\ncontext. Our evaluations on several long-context reasoning tasks show that PERK\nsignificantly outperforms the standard prompt-based long-context baseline,\nachieving average absolute performance gains of up to 90% for smaller models\n(GPT-2) and up to 27% for our largest evaluated model, Qwen-2.5-0.5B. In\ngeneral, PERK is more robust to reasoning complexity, length extrapolation, and\nthe locations of relevant information in contexts. Finally, we show that while\nPERK is memory-intensive during training, it scales more efficiently at\ninference time than prompt-based long-context inference.", "comment": "10 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.06415v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06976", "title": "DenoiseCP-Net: Efficient Collective Perception in Adverse Weather via Joint LiDAR-Based 3D Object Detection and Denoising", "authors": ["Sven Teufel", "Dominique Mayer", "Jörg Gamerdinger", "Oliver Bringmann"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06976v1", "summary": "While automated vehicles hold the potential to significantly reduce traffic\naccidents, their perception systems remain vulnerable to sensor degradation\ncaused by adverse weather and environmental occlusions. Collective perception,\nwhich enables vehicles to share information, offers a promising approach to\novercoming these limitations. However, to this date collective perception in\nadverse weather is mostly unstudied. Therefore, we conduct the first study of\nLiDAR-based collective perception under diverse weather conditions and present\na novel multi-task architecture for LiDAR-based collective perception under\nadverse weather. Adverse weather conditions can not only degrade perception\ncapabilities, but also negatively affect bandwidth requirements and latency due\nto the introduced noise that is also transmitted and processed. Denoising prior\nto communication can effectively mitigate these issues. Therefore, we propose\nDenoiseCP-Net, a novel multi-task architecture for LiDAR-based collective\nperception under adverse weather conditions. DenoiseCP-Net integrates\nvoxel-level noise filtering and object detection into a unified sparse\nconvolution backbone, eliminating redundant computations associated with\ntwo-stage pipelines. This design not only reduces inference latency and\ncomputational cost but also minimizes communication overhead by removing\nnon-informative noise. We extended the well-known OPV2V dataset by simulating\nrain, snow, and fog using our realistic weather simulation models. We\ndemonstrate that DenoiseCP-Net achieves near-perfect denoising accuracy in\nadverse weather, reduces the bandwidth requirements by up to 23.6% while\nmaintaining the same detection accuracy and reducing the inference latency for\ncooperative vehicles.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06976v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07105", "title": "4KAgent: Agentic Any Image to 4K Super-Resolution", "authors": ["Yushen Zuo", "Qi Zheng", "Mingyang Wu", "Xinrui Jiang", "Renjie Li", "Jian Wang", "Yide Zhang", "Gengchen Mai", "Lihong V. Wang", "James Zou", "Xiaoyu Wang", "Ming-Hsuan Yang", "Zhengzhong Tu"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2507.07105v1", "summary": "We present 4KAgent, a unified agentic super-resolution generalist system\ndesigned to universally upscale any image to 4K resolution (and even higher, if\napplied iteratively). Our system can transform images from extremely low\nresolutions with severe degradations, for example, highly distorted inputs at\n256x256, into crystal-clear, photorealistic 4K outputs. 4KAgent comprises three\ncore components: (1) Profiling, a module that customizes the 4KAgent pipeline\nbased on bespoke use cases; (2) A Perception Agent, which leverages\nvision-language models alongside image quality assessment experts to analyze\nthe input image and make a tailored restoration plan; and (3) A Restoration\nAgent, which executes the plan, following a recursive execution-reflection\nparadigm, guided by a quality-driven mixture-of-expert policy to select the\noptimal output for each step. Additionally, 4KAgent embeds a specialized face\nrestoration pipeline, significantly enhancing facial details in portrait and\nselfie photos. We rigorously evaluate our 4KAgent across 11 distinct task\ncategories encompassing a total of 26 diverse benchmarks, setting new\nstate-of-the-art on a broad spectrum of imaging domains. Our evaluations cover\nnatural images, portrait photos, AI-generated content, satellite imagery,\nfluorescence microscopy, and medical imaging like fundoscopy, ultrasound, and\nX-ray, demonstrating superior performance in terms of both perceptual (e.g.,\nNIQE, MUSIQ) and fidelity (e.g., PSNR) metrics. By establishing a novel agentic\nparadigm for low-level vision tasks, we aim to catalyze broader interest and\ninnovation within vision-centric autonomous agents across diverse research\ncommunities. We will release all the code, models, and results at:\nhttps://4kagent.github.io.", "comment": "Project page: https://4kagent.github.io", "pdf_url": "http://arxiv.org/pdf/2507.07105v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06815", "title": "Data-Balanced Curriculum Learning for Audio Question Answering", "authors": ["Gijs Wijngaard", "Elia Formisano", "Michele Esposito", "Michel Dumontier"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06815v1", "summary": "Audio question answering (AQA) requires models to understand acoustic content\nand perform complex reasoning. Current models struggle with dataset imbalances\nand unstable training dynamics. This work combines curriculum learning with\nstatistical data balancing to address these challenges. The method labels\nquestion difficulty using language models, then trains progressively from easy\nto hard examples. Statistical filtering removes overrepresented audio\ncategories, and guided decoding constrains outputs to valid multiple-choice\nformats. Experiments on the DCASE 2025 training set and five additional public\ndatasets show that data curation improves accuracy by 11.7% over baseline\nmodels, achieving 64.2% on the DCASE 2025 benchmark.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06815v1", "cate": "cs.SD", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2302.04018", "title": "A Survey on Event Prediction Methods from a Systems Perspective: Bringing Together Disparate Research Areas", "authors": ["Janik-Vasily Benzin", "Stefanie Rinderle-Ma"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2302.04018v2", "summary": "Event prediction is the ability of anticipating future events, i.e., future\nreal-world occurrences, and aims to support the user in deciding on actions\nthat change future events towards a desired state. An event prediction method\nlearns the relation between features of past events and future events. It is\napplied to newly observed events to predict corresponding future events that\nare evaluated with respect to the user's desired future state. If the predicted\nfuture events do not comply with this state, actions are taken towards\nachieving desirable future states. Evidently, event prediction is valuable in\nmany application domains such as business and natural disasters. The diversity\nof application domains results in a diverse range of methods that are scattered\nacross various research areas which, in turn, use different terminology for\nevent prediction methods. Consequently, sharing methods and knowledge for\ndeveloping future event prediction methods is restricted. To facilitate\nknowledge sharing on account of a comprehensive integration and assessment of\nevent prediction methods, we take a systems perspective to integrate event\nprediction methods into a single system, elicit requirements, and assess\nexisting work with respect to the requirements. Based on the assessment, we\nidentify open challenges and discuss future research directions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2302.04018v2", "cate": "cs.AI", "date": "2023-02-08", "updated": "2025-07-09"}
{"id": "2507.06427", "title": "Exploring Task Performance with Interpretable Models via Sparse Auto-Encoders", "authors": ["Shun Wang", "Tyler Loakman", "Youbo Lei", "Yi Liu", "Bohao Yang", "Yuting Zhao", "Dong Yang", "Chenghua Lin"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06427v1", "summary": "Large Language Models (LLMs) are traditionally viewed as black-box\nalgorithms, therefore reducing trustworthiness and obscuring potential\napproaches to increasing performance on downstream tasks. In this work, we\napply an effective LLM decomposition method using a dictionary-learning\napproach with sparse autoencoders. This helps extract monosemantic features\nfrom polysemantic LLM neurons. Remarkably, our work identifies model-internal\nmisunderstanding, allowing the automatic reformulation of the prompts with\nadditional annotations to improve the interpretation by LLMs. Moreover, this\napproach demonstrates a significant performance improvement in downstream\ntasks, such as mathematical reasoning and metaphor detection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06427v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06999", "title": "Learning Deliberately, Acting Intuitively: Unlocking Test-Time Reasoning in Multimodal LLMs", "authors": ["Yahan Yu", "Yuyang Dong", "Masafumi Oyamada"], "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2507.06999v1", "summary": "Reasoning is a key capability for large language models (LLMs), particularly\nwhen applied to complex tasks such as mathematical problem solving. However,\nmultimodal reasoning research still requires further exploration of modality\nalignment and training costs. Many of these approaches rely on additional data\nannotation and relevant rule-based rewards to enhance the understanding and\nreasoning ability, which significantly increases training costs and limits\nscalability. To address these challenges, we propose the\nDeliberate-to-Intuitive reasoning framework (D2I) that improves the\nunderstanding and reasoning ability of multimodal LLMs (MLLMs) without extra\nannotations and complex rewards. Specifically, our method sets deliberate\nreasoning strategies to enhance modality alignment only through the rule-based\nformat reward during training. While evaluating, the reasoning style shifts to\nintuitive, which removes deliberate reasoning strategies during training and\nimplicitly reflects the model's acquired abilities in the response. D2I\noutperforms baselines across both in-domain and out-of-domain benchmarks. Our\nfindings highlight the role of format reward in fostering transferable\nreasoning skills in MLLMs, and inspire directions for decoupling training-time\nreasoning depth from test-time response flexibility.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.06999v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2406.17709", "title": "Mask-Guided Attention U-Net for Enhanced Neonatal Brain Extraction and Image Preprocessing", "authors": ["Bahram Jafrasteh", "Simon Pedro Lubian-Lopez", "Emiliano Trimarco", "Macarena Roman Ruiz", "Carmen Rodriguez Barrios", "Yolanda Marin Almagro", "Isabel Benavente-Fernandez"], "categories": ["eess.IV", "cs.CV", "stat.CO"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.17709v2", "summary": "In this study, we introduce MGA-Net, a novel mask-guided attention neural\nnetwork, which extends the U-net model for precision neonatal brain imaging.\nMGA-Net is designed to extract the brain from other structures and reconstruct\nhigh-quality brain images. The network employs a common encoder and two\ndecoders: one for brain mask extraction and the other for brain region\nreconstruction. A key feature of MGA-Net is its high-level mask-guided\nattention module, which leverages features from the brain mask decoder to\nenhance image reconstruction. To enable the same encoder and decoder to process\nboth MRI and ultrasound (US) images, MGA-Net integrates sinusoidal positional\nencoding. This encoding assigns distinct positional values to MRI and US\nimages, allowing the model to effectively learn from both modalities.\nConsequently, features learned from a single modality can aid in learning a\nmodality with less available data, such as US. We extensively validated the\nproposed MGA-Net on diverse datasets from varied clinical settings and neonatal\nage groups. The metrics used for assessment included the DICE similarity\ncoefficient, recall, and accuracy for image segmentation; structural similarity\nfor image reconstruction; and root mean squared error for total brain volume\nestimation from 3D ultrasound images. Our results demonstrate that MGA-Net\nsignificantly outperforms traditional methods, offering superior performance in\nbrain extraction and segmentation while achieving high precision in image\nreconstruction and volumetric analysis. Thus, MGA-Net represents a robust and\neffective preprocessing tool for MRI and 3D ultrasound images, marking a\nsignificant advance in neuroimaging that enhances both research and clinical\ndiagnostics in the neonatal period and beyond.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.17709v2", "cate": "eess.IV", "date": "2024-06-25", "updated": "2025-07-08"}
{"id": "2404.04439", "title": "Rethinking Non-Negative Matrix Factorization with Implicit Neural Representations", "authors": ["Krishna Subramani", "Paris Smaragdis", "Takuya Higuchi", "Mehrez Souden"], "categories": ["eess.AS", "cs.LG", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      WASPAA 2025, Code: this https URL", "url": "http://arxiv.org/abs/2404.04439v2", "summary": "Non-negative Matrix Factorization (NMF) is a powerful technique for analyzing\nregularly-sampled data, i.e., data that can be stored in a matrix. For audio,\nthis has led to numerous applications using time-frequency (TF) representations\nlike the Short-Time Fourier Transform. However extending these applications to\nirregularly-spaced TF representations, like the Constant-Q transform, wavelets,\nor sinusoidal analysis models, has not been possible since these\nrepresentations cannot be directly stored in matrix form. In this paper, we\nformulate NMF in terms of learnable functions (instead of vectors) and show\nthat NMF can be extended to a wider variety of signal classes that need not be\nregularly sampled.", "comment": "WASPAA 2025, Code: https://github.com/SubramaniKrishna/in-nmf", "pdf_url": "http://arxiv.org/pdf/2404.04439v2", "cate": "eess.AS", "date": "2024-04-05", "updated": "2025-07-09"}
{"id": "2507.06313", "title": "ETT: Expanding the Long Context Understanding Capability of LLMs at Test-Time", "authors": ["Kiarash Zahirnia", "Zahra Golpayegani", "Walid Ahmad", "Yang Liu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06313v1", "summary": "Transformer-based Language Models' computation and memory overhead increase\nquadratically as a function of sequence length. The quadratic cost poses\nchallenges when employing LLMs for processing long sequences. In this work, we\nintroduce \\ourmodelacronym~(Extend at Test-Time), method for extending the\ncontext length of short context Transformer-based LLMs, with constant memory\nrequirement and linear computation overhead. ETT enable the extension of the\ncontext length at test-time by efficient fine-tuning the model's parameters on\nthe input context, chunked into overlapping small subsequences. We evaluate ETT\non LongBench by extending the context length of GPT-Large and Phi-2 up to 32\ntimes, increasing from 1k to 32k tokens. This results in up to a 30 percent\nimprovement in the model's accuracy. We also study how context can be stored in\nLLM's weights effectively and efficiently. Through a detailed ablation study,\nwe examine which Transformer modules are most beneficial to fine-tune at\ntest-time. Interestingly, we find that fine-tuning the second layer of the FFNs\nis more effective than full fine-tuning, leading to a further improvement in\nthe models' accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06313v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2310.06441", "title": "Stepwise functional refoundation of relational concept analysis", "authors": ["Jérôme Euzenat"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      euzenat2023a", "url": "http://arxiv.org/abs/2310.06441v4", "summary": "Relational concept analysis (RCA) is an extension of formal concept analysis\nallowing to deal with several related contexts simultaneously. It has been\ndesigned for learning description logic theories from data and used within\nvarious applications. A puzzling observation about RCA is that it returns a\nsingle family of concept lattices although, when the data feature circular\ndependencies, other solutions may be considered acceptable. The semantics of\nRCA, provided in an operational way, does not shed light on this issue. In this\nreport, we define these acceptable solutions as those families of concept\nlattices which belong to the space determined by the initial contexts\n(well-formed), cannot scale new attributes (saturated), and refer only to\nconcepts of the family (self-supported). We adopt a functional view on the RCA\nprocess by defining the space of well-formed solutions and two functions on\nthat space: one expansive and the other contractive. We show that the\nacceptable solutions are the common fixed points of both functions. This is\nachieved step-by-step by starting from a minimal version of RCA that considers\nonly one single context defined on a space of contexts and a space of lattices.\nThese spaces are then joined into a single space of context-lattice pairs,\nwhich is further extended to a space of indexed families of context-lattice\npairs representing the objects manippulated by RCA. We show that RCA returns\nthe least element of the set of acceptable solutions. In addition, it is\npossible to build dually an operation that generates its greatest element. The\nset of acceptable solutions is a complete sublattice of the interval between\nthese two elements. Its structure and how the defined functions traverse it are\nstudied in detail.", "comment": "euzenat2023a", "pdf_url": "http://arxiv.org/pdf/2310.06441v4", "cate": "cs.AI", "date": "2023-10-10", "updated": "2025-07-09"}
{"id": "2507.06428", "title": "Neural Actor-Critic Methods for Hamilton-Jacobi-Bellman PDEs: Asymptotic Analysis and Numerical Studies", "authors": ["Samuel N. Cohen", "Jackson Hebner", "Deqing Jiang", "Justin Sirignano"], "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "stat.ML", "93E20, 35Q93, 68T07, 90-08"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      41 pages", "url": "http://arxiv.org/abs/2507.06428v1", "summary": "We mathematically analyze and numerically study an actor-critic machine\nlearning algorithm for solving high-dimensional Hamilton-Jacobi-Bellman (HJB)\npartial differential equations from stochastic control theory. The architecture\nof the critic (the estimator for the value function) is structured so that the\nboundary condition is always perfectly satisfied (rather than being included in\nthe training loss) and utilizes a biased gradient which reduces computational\ncost. The actor (the estimator for the optimal control) is trained by\nminimizing the integral of the Hamiltonian over the domain, where the\nHamiltonian is estimated using the critic. We show that the training dynamics\nof the actor and critic neural networks converge in a Sobolev-type space to a\ncertain infinite-dimensional ordinary differential equation (ODE) as the number\nof hidden units in the actor and critic $\\rightarrow \\infty$. Further, under a\nconvexity-like assumption on the Hamiltonian, we prove that any fixed point of\nthis limit ODE is a solution of the original stochastic control problem. This\nprovides an important guarantee for the algorithm's performance in light of the\nfact that finite-width neural networks may only converge to a local minimizers\n(and not optimal solutions) due to the non-convexity of their loss functions.\nIn our numerical studies, we demonstrate that the algorithm can solve\nstochastic control problems accurately in up to 200 dimensions. In particular,\nwe construct a series of increasingly complex stochastic control problems with\nknown analytic solutions and study the algorithm's numerical performance on\nthem. These problems range from a linear-quadratic regulator equation to highly\nchallenging equations with non-convex Hamiltonians, allowing us to identify and\nanalyze the strengths and limitations of this neural actor-critic method for\nsolving HJB equations.", "comment": "41 pages", "pdf_url": "http://arxiv.org/pdf/2507.06428v1", "cate": "math.OC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.07006", "title": "GNN-ViTCap: GNN-Enhanced Multiple Instance Learning with Vision Transformers for Whole Slide Image Classification and Captioning", "authors": ["S M Taslim Uddin Raju", "Md. Milon Islam", "Md Rezwanul Haque", "Hamdi Altaheri", "Fakhri Karray"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07006v1", "summary": "Microscopic assessment of histopathology images is vital for accurate cancer\ndiagnosis and treatment. Whole Slide Image (WSI) classification and captioning\nhave become crucial tasks in computer-aided pathology. However, microscopic WSI\nface challenges such as redundant patches and unknown patch positions due to\nsubjective pathologist captures. Moreover, generating automatic pathology\ncaptions remains a significant challenge. To address these issues, we introduce\na novel GNN-ViTCap framework for classification and caption generation from\nhistopathological microscopic images. First, a visual feature extractor\ngenerates patch embeddings. Redundant patches are then removed by dynamically\nclustering these embeddings using deep embedded clustering and selecting\nrepresentative patches via a scalar dot attention mechanism. We build a graph\nby connecting each node to its nearest neighbors in the similarity matrix and\napply a graph neural network to capture both local and global context. The\naggregated image embeddings are projected into the language model's input space\nthrough a linear layer and combined with caption tokens to fine-tune a large\nlanguage model. We validate our method on the BreakHis and PatchGastric\ndatasets. GNN-ViTCap achieves an F1 score of 0.934 and an AUC of 0.963 for\nclassification, along with a BLEU-4 score of 0.811 and a METEOR score of 0.569\nfor captioning. Experimental results demonstrate that GNN-ViTCap outperforms\nstate of the art approaches, offering a reliable and efficient solution for\nmicroscopy based patient diagnosis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07006v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2503.20653", "title": "UWarp: A Whole Slide Image Registration Pipeline to Characterize Scanner-Induced Local Domain Shift", "authors": ["Antoine Schieb", "Bilal Hadjadji", "Natalia Fernanda Valderrama", "Daniel Tshokola Mweze", "Valentin Derangère", "Laurent Arnould", "Sylvain Ladoire", "Alain Lalande", "Alessio Fiorin", "Carlos López Pablo", "Noèlia Gallardo Borràs", "Shrief Abdelazeez", "Vincenzo Della Mea", "Anna Korzynska", "Nathan Vinçon", "Louis-Oscar Morel"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      preprint", "url": "http://arxiv.org/abs/2503.20653v2", "summary": "Histopathology slide digitization introduces scanner-induced domain shift\nthat can significantly impact computational pathology models based on deep\nlearning methods. In the state-of-the-art, this shift is often characterized at\na broad scale (slide-level or dataset-level) but not patch-level, which limits\nour comprehension of the impact of localized tissue characteristics on the\naccuracy of the deep learning models. To address this challenge, we present a\ndomain shift analysis framework based on UWarp, a novel registration tool\ndesigned to accurately align histological slides scanned under varying\nconditions. UWarp employs a hierarchical registration approach, combining\nglobal affine transformations with fine-grained local corrections to achieve\nrobust tissue patch alignment. We evaluate UWarp using two private datasets,\nCypathLung and BosomShieldBreast, containing whole slide images scanned by\nmultiple devices. Our experiments demonstrate that UWarp outperforms existing\nopen-source registration methods, achieving a median target registration error\n(TRE) of less than 4 pixels (<1 micrometer at 40x magnification) while\nsignificantly reducing computational time. Additionally, we apply UWarp to\ncharacterize scanner-induced local domain shift in the predictions of\nBreast-NEOprAIdict, a deep learning model for breast cancer pathological\nresponse prediction. We find that prediction variability is strongly correlated\nwith tissue density on a given patch. Our findings highlight the importance of\nlocalized domain shift analysis and suggest that UWarp can serve as a valuable\ntool for improving model robustness and domain adaptation strategies in\ncomputational pathology.", "comment": "preprint", "pdf_url": "http://arxiv.org/pdf/2503.20653v2", "cate": "eess.IV", "date": "2025-03-26", "updated": "2025-07-09"}
{"id": "2411.19204", "title": "A Voice-based Triage for Type 2 Diabetes using a Conversational Virtual Assistant in the Home Environment", "authors": ["Kelvin Summoogum", "Debayan Das", "Sathish Kumaran"], "categories": ["cs.SD", "eess.AS", "F.2.2; I.2.7"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2411.19204v2", "summary": "Incorporating cloud technology with Internet of Medical Things for ubiquitous\nhealthcare has seen many successful applications in the last decade with the\nadvent of machine learning and deep learning techniques. One of these\napplications, namely voice-based pathology, has yet to receive notable\nattention from academia and industry. Applying voice analysis to early\ndetection of fatal diseases holds much promise to improve health outcomes and\nquality of life of patients. In this paper, we propose a novel application of\nacoustic machine learning based triaging into commoditised conversational\nvirtual assistant systems to pre-screen for onset of diabetes. Specifically, we\ndeveloped a triaging system which extracts acoustic features from the voices of\nn=24 older adults when they converse with a virtual assistant and predict the\nincidence of Diabetes Mellitus (Type 2) or not. Our triaging system achieved\nhit-rates of 70% and 60% for male and female older adult subjects,\nrespectively. Our proposed triaging uses 7 non-identifiable voice-based\nfeatures and can operate within resource-constrained embedded systems running\nvoice-based virtual assistants. This application demonstrates the feasibility\nof applying voice-based pathology analysis to improve health outcomes of older\nadults within the home environment by early detection of life-changing chronic\nconditions like diabetes.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2411.19204v2", "cate": "cs.SD", "date": "2024-11-28", "updated": "2025-07-08"}
{"id": "2507.06335", "title": "Could the Road to Grounded, Neuro-symbolic AI be Paved with Words-as-Classifiers?", "authors": ["Casey Kennington", "David Schlangen"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages", "url": "http://arxiv.org/abs/2507.06335v1", "summary": "Formal, Distributional, and Grounded theories of computational semantics each\nhave their uses and their drawbacks. There has been a shift to ground models of\nlanguage by adding visual knowledge, and there has been a call to enrich models\nof language with symbolic methods to gain the benefits from formal,\ndistributional, and grounded theories. In this paper, we attempt to make the\ncase that one potential path forward in unifying all three semantic fields is\npaved with the words-as-classifier model, a model of word-level grounded\nsemantics that has been incorporated into formalisms and distributional\nlanguage models in the literature, and it has been well-tested within\ninteractive dialogue settings. We review that literature, motivate the\nwords-as-classifiers model with an appeal to recent work in cognitive science,\nand describe a small experiment. Finally, we sketch a model of semantics\nunified through words-as-classifiers.", "comment": "9 pages", "pdf_url": "http://arxiv.org/pdf/2507.06335v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06334", "title": "Parallel Batch-Dynamic Coreness Decomposition with Worst-Case Guarantees", "authors": ["Mohsen Ghaffari", "Jaehyun Koo"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      SPAA 2025", "url": "http://arxiv.org/abs/2507.06334v1", "summary": "We present the first parallel batch-dynamic algorithm for approximating\ncoreness decomposition with worst-case update times. Given any batch of edge\ninsertions and deletions, our algorithm processes all these updates in $\n\\text{poly}(\\log n)$ depth, using a worst-case work bound of $b\\cdot\n\\text{poly}(\\log n)$ where $b$ denotes the batch size. This means the batch\ngets processed in $\\tilde{O}(b/p)$ time, given $p$ processors, which is optimal\nup to logarithmic factors. Previously, an algorithm with similar guarantees was\nknown by the celebrated work of Liu, Shi, Yu, Dhulipala, and Shun [SPAA'22],\nbut with the caveat of the work bound, and thus the runtime, being only\namortized.", "comment": "SPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.06334v1", "cate": "cs.DS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2405.11143", "title": "OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework", "authors": ["Jian Hu", "Xibin Wu", "Wei Shen", "Jason Klein Liu", "Zilin Zhu", "Weixun Wang", "Songlin Jiang", "Haoran Wang", "Hao Chen", "Bin Chen", "Weikai Fang", "Xianyu", "Yu Cao", "Haotian Xu", "Yiming Liu"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.11143v5", "summary": "Large Language Models (LLMs) fine-tuned via Reinforcement Learning from Human\nFeedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR)\nsignificantly improve the alignment of human-AI values and further raise the\nupper bound of AI capabilities, particularly in reasoning-intensive,\nlong-context Chain-of-Thought (long-CoT) tasks. However, existing RLHF (or\nRLVR) frameworks commonly face challenges such as inference bottlenecks and\ncomplexity barriers, restricting their accessibility for newcomers. To bridge\nthis gap, we introduce OpenRLHF, a user-friendly, scalable, and easy-to-learn\nopen-source RLHF framework built upon Ray, vLLM, DeepSpeed, and HuggingFace\nTransformers, featuring a simplified design, clear code structure, and\ncomprehensive documentation to facilitate entry for researchers and\npractitioners. Experimental results show that OpenRLHF achieves superior\ntraining efficiency with speedups ranging from 1.22x to 1.68x across different\nmodel sizes compared to state-of-the-art frameworks, while requiring\nsignificantly fewer lines of code for implementation. OpenRLHF is publicly\navailable at https://github.com/OpenRLHF/OpenRLHF, and has already been adopted\nby leading institutions to accelerate RLHF research and learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.11143v5", "cate": "cs.AI", "date": "2024-05-20", "updated": "2025-07-04"}
{"id": "2507.06472", "title": "Stochastic Alignments: Matching an Observed Trace to Stochastic Process Models", "authors": ["Tian Li", "Artem Polyvyanyy", "Sander J. J. Leemans"], "categories": ["cs.FL", "cs.LG"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06472v1", "summary": "Process mining leverages event data extracted from IT systems to generate\ninsights into the business processes of organizations. Such insights benefit\nfrom explicitly considering the frequency of behavior in business processes,\nwhich is captured by stochastic process models. Given an observed trace and a\nstochastic process model, conventional alignment-based conformance checking\ntechniques face a fundamental limitation: They prioritize matching the trace to\na model path with minimal deviations, which may, however, lead to selecting an\nunlikely path. In this paper, we study the problem of matching an observed\ntrace to a stochastic process model by identifying a likely model path with a\nlow edit distance to the trace. We phrase this as an optimization problem and\ndevelop a heuristic-guided path-finding algorithm to solve it. Our open-source\nimplementation demonstrates the feasibility of the approach and shows that it\ncan provide new, useful diagnostic insights for analysts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06472v1", "cate": "cs.FL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07013", "title": "Integrating Pathology Foundation Models and Spatial Transcriptomics for Cellular Decomposition from Histology Images", "authors": ["Yutong Sun", "Sichen Zhu", "Peng Qiu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07013v1", "summary": "The rapid development of digital pathology and modern deep learning has\nfacilitated the emergence of pathology foundation models that are expected to\nsolve general pathology problems under various disease conditions in one\nunified model, with or without fine-tuning. In parallel, spatial\ntranscriptomics has emerged as a transformative technology that enables the\nprofiling of gene expression on hematoxylin and eosin (H&E) stained histology\nimages. Spatial transcriptomics unlocks the unprecedented opportunity to dive\ninto existing histology images at a more granular, cellular level. In this\nwork, we propose a lightweight and training-efficient approach to predict\ncellular composition directly from H&E-stained histology images by leveraging\ninformation-enriched feature embeddings extracted from pre-trained pathology\nfoundation models. By training a lightweight multi-layer perceptron (MLP)\nregressor on cell-type abundances derived via cell2location, our method\nefficiently distills knowledge from pathology foundation models and\ndemonstrates the ability to accurately predict cell-type compositions from\nhistology images, without physically performing the costly spatial\ntranscriptomics. Our method demonstrates competitive performance compared to\nexisting methods such as Hist2Cell, while significantly reducing computational\ncomplexity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07013v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2505.18352", "title": "Single Snapshot Distillation for Phase Coded Mask Design in Phase Retrieval", "authors": ["Karen Fonseca", "Leon Suarez-Rodriguez", "Andres Jerez", "Felipe Gutierrez-Barragan", "Henry Arguello"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted on the IEEE International Conference on Image Processing, IEEE ICIP 2025", "url": "http://arxiv.org/abs/2505.18352v3", "summary": "Phase retrieval (PR) reconstructs phase information from magnitude\nmeasurements, known as coded diffraction patterns (CDPs), whose quality depends\non the number of snapshots captured using coded phase masks. High-quality phase\nestimation requires multiple snapshots, which is not desired for efficient PR\nsystems. End-to-end frameworks enable joint optimization of the optical system\nand the recovery neural network. However, their application is constrained by\nphysical implementation limitations. Additionally, the framework is prone to\ngradient vanishing issues related to its global optimization process. This\npaper introduces a Knowledge Distillation (KD) optimization approach to address\nthese limitations. KD transfers knowledge from a larger, lower-constrained\nnetwork (teacher) to a smaller, more efficient, and implementable network\n(student). In this method, the teacher, a PR system trained with multiple\nsnapshots, distills its knowledge into a single-snapshot PR system, the\nstudent. The loss functions compare the CPMs and the feature space of the\nrecovery network. Simulations demonstrate that this approach improves\nreconstruction performance compared to a PR system trained without the\nteacher's guidance.", "comment": "Accepted on the IEEE International Conference on Image Processing,\n  IEEE ICIP 2025", "pdf_url": "http://arxiv.org/pdf/2505.18352v3", "cate": "eess.IV", "date": "2025-05-23", "updated": "2025-07-08"}
{"id": "2506.23325", "title": "XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs", "authors": ["Yitian Gong", "Luozhijie Jin", "Ruifan Deng", "Dong Zhang", "Xin Zhang", "Qinyuan Cheng", "Zhaoye Fei", "Shimin Li", "Xipeng Qiu"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23325v2", "summary": "Speech codecs serve as bridges between speech signals and large language\nmodels. An ideal codec for speech language models should not only preserve\nacoustic information but also capture rich semantic information. However,\nexisting speech codecs struggle to balance high-quality audio reconstruction\nwith ease of modeling by language models. In this study, we analyze the\nlimitations of previous codecs in balancing semantic richness and acoustic\nfidelity. We propose XY-Tokenizer, a novel codec that mitigates the conflict\nbetween semantic and acoustic capabilities through multi-stage, multi-task\nlearning. Experimental results demonstrate that XY-Tokenizer achieves\nperformance in both semantic and acoustic tasks comparable to that of\nstate-of-the-art codecs operating at similar bitrates, even though those\nexisting codecs typically excel in only one aspect. Specifically, XY-Tokenizer\nachieves strong text alignment, surpassing distillation-based semantic modeling\nmethods such as SpeechTokenizer and Mimi, while maintaining a speaker\nsimilarity score of 0.83 between reconstructed and original audio. The\nreconstruction performance of XY-Tokenizer is comparable to that of BigCodec,\nthe current state-of-the-art among acoustic-only codecs, which achieves a\nspeaker similarity score of 0.84 at a similar bitrate. Code and models are\navailable at https://github.com/gyt1145028706/XY-Tokenizer.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23325v2", "cate": "cs.SD", "date": "2025-06-29", "updated": "2025-07-09"}
{"id": "2507.06378", "title": "Evaluating Morphological Alignment of Tokenizers in 70 Languages", "authors": ["Catherine Arnett", "Marisa Hudspeth", "Brendan O'Connor"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures. Accepted to the Tokenization Workshop at ICML 2025", "url": "http://arxiv.org/abs/2507.06378v1", "summary": "While tokenization is a key step in language modeling, with effects on model\ntraining and performance, it remains unclear how to effectively evaluate\ntokenizer quality. One proposed dimension of tokenizer quality is the extent to\nwhich tokenizers preserve linguistically meaningful subwords, aligning token\nboundaries with morphological boundaries within a word. We expand MorphScore\n(Arnett & Bergen, 2025), which previously covered 22 languages, to support a\ntotal of 70 languages. The updated MorphScore offers more flexibility in\nevaluation and addresses some of the limitations of the original version. We\nthen correlate our alignment scores with downstream task performance for five\npre-trained languages models on seven tasks, with at least one task in each of\nthe languages in our sample. We find that morphological alignment does not\nexplain very much variance in model performance, suggesting that morphological\nalignment alone does not measure dimensions of tokenization quality relevant to\nmodel performance.", "comment": "6 pages, 3 figures. Accepted to the Tokenization Workshop at ICML\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.06378v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06338", "title": "Parallel Batch-Dynamic Algorithms for Spanners, and Extensions", "authors": ["Mohsen Ghaffari", "Jaehyun Koo"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      SPAA 2025", "url": "http://arxiv.org/abs/2507.06338v1", "summary": "This paper presents the first parallel batch-dynamic algorithms for computing\nspanners and sparsifiers. Our algorithms process any batch of edge insertions\nand deletions in an $n$-node undirected graph, in $\\text{poly}(\\log n)$ depth\nand using amortized work near-linear in the batch size. Our concrete results\nare as follows:\n  - Our base algorithm maintains a spanner with $(2k-1)$ stretch and\n$\\tilde{O}(n^{1+1/k})$ edges, for any $k\\geq 1$.\n  - Our first extension maintains a sparse spanner with only $O(n)$ edges, and\n$\\tilde{O}(\\log n)$ stretch.\n  - Our second extension maintains a $t$-bundle of spanners -- i.e., $t$\nspanners, each of which is the spanner of the graph remaining after removing\nthe previous ones -- and allows us to maintain cut/spectral sparsifiers with\n$\\tilde{O}(n)$ edges.", "comment": "SPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.06338v1", "cate": "cs.DS", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2410.12112", "title": "Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming", "authors": ["Yilun Hao", "Yang Zhang", "Chuchu Fan"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      57 pages, 25 figures, 15 tables", "url": "http://arxiv.org/abs/2410.12112v3", "summary": "While large language models (LLMs) have recently demonstrated strong\npotential in solving planning problems, there is a trade-off between\nflexibility and complexity. LLMs, as zero-shot planners themselves, are still\nnot capable of directly generating valid plans for complex planning problems\nsuch as multi-constraint or long-horizon tasks. On the other hand, many\nframeworks aiming to solve complex planning problems often rely on\ntask-specific preparatory efforts, such as task-specific in-context examples\nand pre-defined critics/verifiers, which limits their cross-task generalization\ncapability. In this paper, we tackle these challenges by observing that the\ncore of many planning problems lies in optimization problems: searching for the\noptimal solution (best plan) with goals subject to constraints (preconditions\nand effects of decisions). With LLMs' commonsense, reasoning, and programming\ncapabilities, this opens up the possibilities of a universal LLM-based approach\nto planning problems. Inspired by this observation, we propose LLMFP, a\ngeneral-purpose framework that leverages LLMs to capture key information from\nplanning problems and formally formulate and solve them as optimization\nproblems from scratch, with no task-specific examples needed. We apply LLMFP to\n9 planning problems, ranging from multi-constraint decision making to\nmulti-step planning problems, and demonstrate that LLMFP achieves on average\n83.7% and 86.8% optimal rate across 9 tasks for GPT-4o and Claude 3.5 Sonnet,\nsignificantly outperforming the best baseline (direct planning with OpenAI\no1-preview) with 37.6% and 40.7% improvements. We also validate components of\nLLMFP with ablation experiments and analyzed the underlying success and failure\nreasons. Project page: https://sites.google.com/view/llmfp.", "comment": "57 pages, 25 figures, 15 tables", "pdf_url": "http://arxiv.org/pdf/2410.12112v3", "cate": "cs.AI", "date": "2024-10-15", "updated": "2025-07-09"}
{"id": "2507.06509", "title": "Prediction-Augmented Mechanism Design for Weighted Facility Location", "authors": ["Yangguang Shi", "Zhenyu Xue"], "categories": ["cs.DS", "cs.GT", "cs.LG", "68W27, 68Q32", "F.2.2"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      An extended abstract of this paper is to appear in the 19th Annual Conference on Theory and Applications of Models of Computation (TAMC 2025)", "url": "http://arxiv.org/abs/2507.06509v1", "summary": "Facility location is fundamental in operations research, mechanism design,\nand algorithmic game theory, with applications ranging from urban\ninfrastructure planning to distributed systems. Recent research in this area\nhas focused on augmenting classic strategyproof mechanisms with predictions to\nachieve an improved performance guarantee against the uncertainty under the\nstrategic environment. Previous work has been devoted to address the trade-off\nobstacle of balancing the consistency (near-optimality under accurate\npredictions) and robustness (bounded inefficiency under poor predictions)\nprimarily in the unweighted setting, assuming that all agents have the same\nimportance. However, this assumption may not be true in some practical\nscenarios, leading to research of weighted facility location problems.\n  The major contribution of the current work is to provide a prediction\naugmented algorithmic framework for balancing the consistency and robustness\nover strategic agents with non-uniform weights. In particular, through a\nreduction technique that identifies a subset of \\emph{representative} instances\nand maps the other given locations to the representative ones, we prove that\nthere exists a \\emph{strategyproof} mechanism achieving a bounded consistency\nguarantee of $\\frac{\\sqrt{(1+c)^2W^2_{\\min}+(1-c)^2W^2_{\\max}}}{(1+c)W_{\\min}}$\nand a bounded robustness guarantee of\n$\\frac{\\sqrt{(1-c)^2W^2_{\\min}+(1+c)^2W^2_{\\max}}}{(1-c)W_{\\min}}$ in weighted\nsettings, where $c$ can be viewed as a parameter to make a trade-off between\nthe consistency and robustness and $W_{\\min}$ and $W_{\\max}$ denote the minimum\nand maximum agents' weight. We also proved that there is no strategyproof\ndeterministic mechanism that reach $1$-consistency and $O\\left( n \\cdot\n\\frac{W_{\\max}}{W_{\\min}} \\right)$-robustness in weighted FLP, even with fully\npredictions of all agents.", "comment": "An extended abstract of this paper is to appear in the 19th Annual\n  Conference on Theory and Applications of Models of Computation (TAMC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.06509v1", "cate": "cs.DS", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07015", "title": "MST-Distill: Mixture of Specialized Teachers for Cross-Modal Knowledge Distillation", "authors": ["Hui Li", "Pengfei Yang", "Juanyang Chen", "Le Dong", "Yanxin Chen", "Quan Wang"], "categories": ["cs.CV", "cs.LG", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ACM MM 2025 (The 33rd ACM International Conference on Multimedia)", "url": "http://arxiv.org/abs/2507.07015v1", "summary": "Knowledge distillation as an efficient knowledge transfer technique, has\nachieved remarkable success in unimodal scenarios. However, in cross-modal\nsettings, conventional distillation methods encounter significant challenges\ndue to data and statistical heterogeneities, failing to leverage the\ncomplementary prior knowledge embedded in cross-modal teacher models. This\npaper empirically reveals two critical issues in existing approaches:\ndistillation path selection and knowledge drift. To address these limitations,\nwe propose MST-Distill, a novel cross-modal knowledge distillation framework\nfeaturing a mixture of specialized teachers. Our approach employs a diverse\nensemble of teacher models across both cross-modal and multimodal\nconfigurations, integrated with an instance-level routing network that\nfacilitates adaptive and dynamic distillation. This architecture effectively\ntranscends the constraints of traditional methods that rely on monotonous and\nstatic teacher models. Additionally, we introduce a plug-in masking module,\nindependently trained to suppress modality-specific discrepancies and\nreconstruct teacher representations, thereby mitigating knowledge drift and\nenhancing transfer effectiveness. Extensive experiments across five diverse\nmultimodal datasets, spanning visual, audio, and text, demonstrate that our\nmethod significantly outperforms existing state-of-the-art knowledge\ndistillation methods in cross-modal distillation tasks. The source code is\navailable at https://github.com/Gray-OREO/MST-Distill.", "comment": "Accepted to ACM MM 2025 (The 33rd ACM International Conference on\n  Multimedia)", "pdf_url": "http://arxiv.org/pdf/2507.07015v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2506.23334", "title": "Federated Breast Cancer Detection Enhanced by Synthetic Ultrasound Image Augmentation", "authors": ["Hongyi Pan", "Ziliang Hong", "Gorkem Durak", "Ziyue Xu", "Ulas Bagci"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23334v2", "summary": "Federated learning (FL) has emerged as a promising paradigm for\ncollaboratively training deep learning models across institutions without\nexchanging sensitive medical data. However, its effectiveness is often hindered\nby limited data availability and non-independent, identically distributed data\nacross participating clients, which can degrade model performance and\ngeneralization. To address these challenges, we propose a generative AI based\ndata augmentation framework that integrates synthetic image sharing into the\nfederated training process for breast cancer diagnosis via ultrasound images.\nSpecifically, we train two simple class-specific Deep Convolutional Generative\nAdversarial Networks: one for benign and one for malignant lesions. We then\nsimulate a realistic FL setting using three publicly available breast\nultrasound image datasets: BUSI, BUS-BRA, and UDIAT. FedAvg and FedProx are\nadopted as baseline FL algorithms. Experimental results show that incorporating\na suitable number of synthetic images improved the average AUC from 0.9206 to\n0.9237 for FedAvg and from 0.9429 to 0.9538 for FedProx. We also note that\nexcessive use of synthetic data reduced performance, underscoring the\nimportance of maintaining a balanced ratio of real and synthetic samples. Our\nfindings highlight the potential of generative AI based data augmentation to\nenhance FL results in the breast ultrasound image classification task.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23334v2", "cate": "eess.IV", "date": "2025-06-29", "updated": "2025-07-08"}
{"id": "2507.06393", "title": "Hypermagmas and Colored Operads: Heads, Phases, and Theta Roles", "authors": ["Matilde Marcolli", "Riny Huijbregts", "Richard K. Larson"], "categories": ["cs.CL", "math.QA", "math.RA", "91F20, 18M60, 18M80, 16T05, 68Q70"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      LaTeX, 48 pages", "url": "http://arxiv.org/abs/2507.06393v1", "summary": "We show that head functions on syntactic objects extend the magma structure\nto a hypermagma, with the c-command relation compatible with the magma\noperation and the m-command relation with the hypermagma. We then show that the\nstructure of head and complement and specifier, additional modifier positions,\nand the structure of phases in the Extended Projection can be formulated as a\nbud generating system of a colored operad, in a form similar to the structure\nof theta roles. We also show that, due to the special form of the colored\noperad generators, the filtering of freely generated syntactic objects by these\ncoloring rules can be equivalently formulated as a filtering in the course of\nstructure formation via a colored Merge, which can in turn be related to the\nhypermagma structure. The rules on movement by Internal Merge with respect to\nphases, the Extended Projection Principle, Empty Category Principle, and Phase\nImpenetrability Condition are all subsumed into the form of the colored operad\ngenerators. Movement compatibilities between the phase structure and the theta\nroles assignments can then be formulated in terms of the respective colored\noperads and a transduction of colored operads.", "comment": "LaTeX, 48 pages", "pdf_url": "http://arxiv.org/pdf/2507.06393v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06721", "title": "Faster Algorithms for $(2k-1)$-Stretch Distance Oracles", "authors": ["Avi Kadria", "Liam Roditty"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06721v1", "summary": "Let $G=(V, E)$ be an undirected $n$-vertices $m$-edges graph with\nnon-negative edge weights. In this paper, we present three new algorithms for\nconstructing a $(2k-1)$-stretch distance oracle with $O(n^{1+\\frac{1}{k}})$\nspace. The first algorithm runs in $\\Ot(\\max(n^{1+2/k},\nm^{1-\\frac{1}{k-1}}n^{\\frac{2}{k-1}}))$ time, and improves upon the\n$\\Ot(\\min(mn^{\\frac{1}{k}},n^2))$ time of Thorup and Zwick [STOC 2001, JACM\n2005] and Baswana and Kavitha [FOCS 2006, SICOMP 2010], for every $k > 2$ and\n$m=\\Omega(n^{1+\\frac{1}{k}+\\eps})$. This yields the first truly subquadratic\ntime construction for every $2 < k < 6$, and nearly resolves the open problem\nposed by Wulff-Nilsen [SODA 2012] on the existence of such constructions.\n  The two other algorithms have a running time of the form $\\Ot(m+n^{1+f(k)})$,\nwhich is near linear in $m$ if $m=\\Omega(n^{1+f(k)})$, and therefore optimal in\nsuch graphs. One algorithm runs in $\\Ot(m+n^{\\frac32+\\frac{3}{4k-6}})$-time,\nwhich improves upon the $\\Ot(n^2)$-time algorithm of Baswana and Kavitha [FOCS\n2006, SICOMP 2010], for $3 < k < 6$, and upon the\n$\\Ot(m+n^{\\frac{3}{2}+\\frac{2}{k}+O(k^{-2})})$-time algorithm of Wulff-Nilsen\n[SODA 2012], for every $k\\geq 6$. This is the first linear time algorithm for\nconstructing a $7$-stretch distance oracle and a $9$-stretch distance oracle,\nfor graphs with truly subquadratic density.\\footnote{with $m=n^{2-\\eps}$ for\nsome $\\eps > 0$.} The other algorithm runs in\n$\\Ot(\\sqrt{k}m+kn^{1+\\frac{2\\sqrt{2}}{\\sqrt{k}}})$ time, (and hence relevant\nonly for $k\\ge 16$), and improves upon the\n$\\Ot(\\sqrt{k}m+kn^{1+\\frac{2\\sqrt{6}}{\\sqrt{k}}+O(k^{-1})})$ time algorithm of\nWulff-Nilsen [SODA 2012] (which is relevant only for $k\\ge 96$). ...", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06721v1", "cate": "cs.DS", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2501.12399", "title": "FinSphere, a Real-Time Stock Analysis Agent Powered by Instruction-Tuned LLMs and Domain Tools", "authors": ["Shijie Han", "Jingshu Zhang", "Yiqing Shen", "Kaiyuan Yan", "Hongguang Li"], "categories": ["cs.AI", "cs.CL", "cs.IR", "q-fin.CP"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.12399v2", "summary": "Current financial large language models (FinLLMs) struggle with two critical\nlimitations: the absence of objective evaluation metrics to assess the quality\nof stock analysis reports and a lack of depth in stock analysis, which impedes\ntheir ability to generate professional-grade insights. To address these\nchallenges, this paper introduces FinSphere, a stock analysis agent, along with\nthree major contributions: (1) AnalyScore, a systematic evaluation framework\nfor assessing stock analysis quality, (2) Stocksis, a dataset curated by\nindustry experts to enhance LLMs' stock analysis capabilities, and (3)\nFinSphere, an AI agent that can generate high-quality stock analysis reports in\nresponse to user queries. Experiments demonstrate that FinSphere achieves\nsuperior performance compared to both general and domain-specific LLMs, as well\nas existing agent-based systems, even when they are enhanced with real-time\ndata access and few-shot guidance. The integrated framework, which combines\nreal-time data feeds, quantitative tools, and an instruction-tuned LLM, yields\nsubstantial improvements in both analytical quality and practical applicability\nfor real-world stock analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.12399v2", "cate": "cs.AI", "date": "2025-01-08", "updated": "2025-07-09"}
{"id": "2507.06533", "title": "From large-eddy simulations to deep learning: A U-net model for fast urban canopy flow predictions", "authors": ["Themistoklis Vargiemezis", "Catherine Gorlé"], "categories": ["physics.comp-ph", "cs.LG", "physics.flu-dyn"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06533v1", "summary": "Accurate prediction of wind flow fields in urban canopies is crucial for\nensuring pedestrian comfort, safety, and sustainable urban design. Traditional\nmethods using wind tunnels and Computational Fluid Dynamics, such as Large-Eddy\nSimulations (LES), are limited by high costs, computational demands, and time\nrequirements. This study presents a deep neural network (DNN) approach for fast\nand accurate predictions of urban wind flow fields, reducing computation time\nfrom an order of 10 hours on 32 CPUs for one LES evaluation to an order of 1\nsecond on a single GPU using the DNN model. We employ a U-Net architecture\ntrained on LES data including 252 synthetic urban configurations at seven wind\ndirections ($0^{o}$ to $90^{o}$ in $15^{o}$ increments). The model predicts two\nkey quantities of interest: mean velocity magnitude and streamwise turbulence\nintensity, at multiple heights within the urban canopy. The U-net uses 2D\nbuilding representations augmented with signed distance functions and their\ngradients as inputs, forming a $256\\times256\\times9$ tensor. In addition, a\nSpatial Attention Module is used for feature transfer through skip connections.\nThe loss function combines the root-mean-square error of predictions, their\ngradient magnitudes, and L2 regularization. Model evaluation on 50 test cases\ndemonstrates high accuracy with an overall mean relative error of 9.3% for\nvelocity magnitude and 5.2% for turbulence intensity. This research shows the\npotential of deep learning approaches to provide fast, accurate urban wind\nassessments essential for creating comfortable and safe urban environments.\nCode is available at https://github.com/tvarg/Urban-FlowUnet.git", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06533v1", "cate": "physics.comp-ph", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07048", "title": "Evaluating Large Multimodal Models for Nutrition Analysis: A Benchmark Enriched with Contextual Metadata", "authors": ["Bruce Coburn", "Jiangpeng He", "Megan E. Rollo", "Satvinder S. Dhaliwal", "Deborah A. Kerr", "Fengqing Zhu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07048v1", "summary": "Large Multimodal Models (LMMs) are increasingly applied to meal images for\nnutrition analysis. However, existing work primarily evaluates proprietary\nmodels, such as GPT-4. This leaves the broad range of LLMs underexplored.\nAdditionally, the influence of integrating contextual metadata and its\ninteraction with various reasoning modifiers remains largely uncharted. This\nwork investigates how interpreting contextual metadata derived from GPS\ncoordinates (converted to location/venue type), timestamps (transformed into\nmeal/day type), and the food items present can enhance LMM performance in\nestimating key nutritional values. These values include calories,\nmacronutrients (protein, carbohydrates, fat), and portion sizes. We also\nintroduce ACETADA, a new food-image dataset slated for public release. This\nopen dataset provides nutrition information verified by the dietitian and\nserves as the foundation for our analysis. Our evaluation across eight LMMs\n(four open-weight and four closed-weight) first establishes the benefit of\ncontextual metadata integration over straightforward prompting with images\nalone. We then demonstrate how this incorporation of contextual information\nenhances the efficacy of reasoning modifiers, such as Chain-of-Thought,\nMultimodal Chain-of-Thought, Scale Hint, Few-Shot, and Expert Persona.\nEmpirical results show that integrating metadata intelligently, when applied\nthrough straightforward prompting strategies, can significantly reduce the Mean\nAbsolute Error (MAE) and Mean Absolute Percentage Error (MAPE) in predicted\nnutritional values. This work highlights the potential of context-aware LMMs\nfor improved nutrition analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07048v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.00511", "title": "Medical Image Segmentation Using Advanced Unet: VMSE-Unet and VM-Unet CBAM+", "authors": ["Sayandeep Kanrar", "Raja Piyush", "Qaiser Razi", "Debanshi Chakraborty", "Vikas Hassija", "GSS Chalapathi"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00511v2", "summary": "In this paper, we present the VMSE U-Net and VM-Unet CBAM+ model, two\ncutting-edge deep learning architectures designed to enhance medical image\nsegmentation. Our approach integrates Squeeze-and-Excitation (SE) and\nConvolutional Block Attention Module (CBAM) techniques into the traditional VM\nU-Net framework, significantly improving segmentation accuracy, feature\nlocalization, and computational efficiency. Both models show superior\nperformance compared to the baseline VM-Unet across multiple datasets. Notably,\nVMSEUnet achieves the highest accuracy, IoU, precision, and recall while\nmaintaining low loss values. It also exhibits exceptional computational\nefficiency with faster inference times and lower memory usage on both GPU and\nCPU. Overall, the study suggests that the enhanced architecture VMSE-Unet is a\nvaluable tool for medical image analysis. These findings highlight its\npotential for real-world clinical applications, emphasizing the importance of\nfurther research to optimize accuracy, robustness, and computational\nefficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00511v2", "cate": "eess.IV", "date": "2025-07-01", "updated": "2025-07-09"}
{"id": "2507.06419", "title": "Reward Models Can Improve Themselves: Reward-Guided Adversarial Failure Mode Discovery for Robust Reward Modeling", "authors": ["Pankayaraj Pathmanathan", "Furong Huang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06419v1", "summary": "Reward modeling (RM), which captures human preferences to align large\nlanguage models (LLMs), is increasingly employed in tasks such as model\nfinetuning, response filtering, and ranking. However, due to the inherent\ncomplexity of human preferences and the limited coverage of available datasets,\nreward models often fail under distributional shifts or adversarial\nperturbations. Existing approaches for identifying such failure modes typically\nrely on prior knowledge about preference distributions or failure attributes,\nlimiting their practicality in real-world settings where such information is\nunavailable. In this work, we propose a tractable, preference-distribution\nagnostic method for discovering reward model failure modes via reward guided\ncontrolled decoding. Building on this, we introduce REFORM, a self-improving\nreward modeling framework that enhances robustness by using the reward model\nitself to guide the generation of falsely scored responses. These adversarial\nexamples are then used to augment the training data and patch the reward\nmodel's misaligned behavior. We evaluate REFORM on two widely used preference\ndatasets Anthropic Helpful Harmless (HH) and PKU Beavertails and demonstrate\nthat it significantly improves robustness without sacrificing reward quality.\nNotably, REFORM preserves performance both in direct evaluation and in\ndownstream policy training, and further improves alignment quality by removing\nspurious correlations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06419v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06925", "title": "Faster Estimation of the Average Degree of a Graph Using Random Edges and Structural Queries", "authors": ["Lorenzo Beretta", "Deeparnab Chakrabarty", "C. Seshadhri"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06925v1", "summary": "We revisit the problem of designing sublinear algorithms for estimating the\naverage degree of an $n$-vertex graph. The standard access model for graphs\nallows for the following queries: sampling a uniform random vertex, the degree\nof a vertex, sampling a uniform random neighbor of a vertex, and ``pair\nqueries'' which determine if a pair of vertices form an edge. In this model,\noriginal results [Goldreich-Ron, RSA 2008; Eden-Ron-Seshadhri, SIDMA 2019] on\nthis problem prove that the complexity of getting\n$(1+\\varepsilon)$-multiplicative approximations to the average degree, ignoring\n$\\varepsilon$-dependencies, is $\\Theta(\\sqrt{n})$. When random edges can be\nsampled, it is known that the average degree can estimated in\n$\\widetilde{O}(n^{1/3})$ queries, even without pair queries\n[Motwani-Panigrahy-Xu, ICALP 2007; Beretta-Tetek, TALG 2024].\n  We give a nearly optimal algorithm in the standard access model with random\nedge samples. Our algorithm makes $\\widetilde{O}(n^{1/4})$ queries exploiting\nthe power of pair queries. We also analyze the ``full neighborhood access\"\nmodel wherein the entire adjacency list of a vertex can be obtained with a\nsingle query; this model is relevant in many practical applications. In a\nweaker version of this model, we give an algorithm that makes\n$\\widetilde{O}(n^{1/5})$ queries. Both these results underscore the power of\n{\\em structural queries}, such as pair queries and full neighborhood access\nqueries, for estimating the average degree. We give nearly matching lower\nbounds, ignoring $\\varepsilon$-dependencies, for all our results.\n  So far, almost all algorithms for estimating average degree assume that the\nnumber of vertices, $n$, is known. Inspired by [Beretta-Tetek, TALG 2024], we\nstudy this problem when $n$ is unknown and show that structural queries do not\nhelp in estimating average degree in this setting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06925v1", "cate": "cs.DS", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06484", "title": "3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds", "authors": ["Fan-Yun Sun", "Shengguang Wu", "Christian Jacobsen", "Thomas Yim", "Haoming Zou", "Alex Zook", "Shangru Li", "Yu-Hsin Chou", "Ethem Can", "Xunlei Wu", "Clemens Eppner", "Valts Blukis", "Jonathan Tremblay", "Jiajun Wu", "Stan Birchfield", "Nick Haber"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      project website: this https URL", "url": "http://arxiv.org/abs/2507.06484v1", "summary": "Despite large-scale pretraining endowing models with language and vision\nreasoning capabilities, improving their spatial reasoning capability remains\nchallenging due to the lack of data grounded in the 3D world. While it is\npossible for humans to manually create immersive and interactive worlds through\n3D graphics, as seen in applications such as VR, gaming, and robotics, this\nprocess remains highly labor-intensive. In this paper, we propose a scalable\nmethod for generating high-quality 3D environments that can serve as training\ndata for foundation models. We recast 3D environment building as a sequential\ndecision-making problem, employing Vision-Language-Models (VLMs) as policies\nthat output actions to jointly craft a 3D environment's layout, materials,\nlighting, and assets. Our proposed framework, 3D-Generalist, trains VLMs to\ngenerate more prompt-aligned 3D environments via self-improvement fine-tuning.\nWe demonstrate the effectiveness of 3D-Generalist and the proposed training\nstrategy in generating simulation-ready 3D environments. Furthermore, we\ndemonstrate its quality and scalability in synthetic data generation by\npretraining a vision foundation model on the generated data. After fine-tuning\nthe pre-trained model on downstream tasks, we show that it surpasses models\npre-trained on meticulously human-crafted synthetic data and approaches results\nachieved with real data orders of magnitude larger.", "comment": "project website: https://ai.stanford.edu/~sunfanyun/3d-generalist/", "pdf_url": "http://arxiv.org/pdf/2507.06484v1", "cate": "cs.GR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2501.14568", "title": "Hybrid Quantum-Classical Multi-Agent Pathfinding", "authors": ["Thore Gerlach", "Loong Kuan Lee", "Frédéric Barbaresco", "Nico Piatkowski"], "categories": ["cs.AI", "quant-ph"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      11 pages, accepted at ICML 2025", "url": "http://arxiv.org/abs/2501.14568v2", "summary": "Multi-Agent Path Finding (MAPF) focuses on determining conflict-free paths\nfor multiple agents navigating through a shared space to reach specified goal\nlocations. This problem becomes computationally challenging, particularly when\nhandling large numbers of agents, as frequently encountered in practical\napplications like coordinating autonomous vehicles. Quantum Computing (QC) is a\npromising candidate in overcoming such limits. However, current quantum\nhardware is still in its infancy and thus limited in terms of computing power\nand error robustness. In this work, we present the first optimal hybrid\nquantum-classical MAPF algorithms which are based on branch-andcut-and-price.\nQC is integrated by iteratively solving QUBO problems, based on conflict\ngraphs. Experiments on actual quantum hardware and results on benchmark data\nsuggest that our approach dominates previous QUBO formulationsand\nstate-of-the-art MAPF solvers.", "comment": "11 pages, accepted at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2501.14568v2", "cate": "cs.AI", "date": "2025-01-24", "updated": "2025-07-09"}
{"id": "2507.06565", "title": "The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production", "authors": ["Juan B. Gutiérrez"], "categories": ["cs.CL", "cs.LG", "68T01, 60J10, 91D30, 05C82, 68T50, 68W20, 94A15", "I.2.7; I.2.11; G.3"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      27 pages, 3 figures, 4 tables, 1 algorithm, 28 references", "url": "http://arxiv.org/abs/2507.06565v1", "summary": "Large-language models turn writing into a live exchange between humans and\nsoftware. We capture this new medium with a discursive-network model that\ntreats people and LLMs as equal nodes and tracks how their statements\ncirculate. Broadening the focus from isolated hallucinations, we define\ninvalidation (any factual, logical, or structural breach) and show it follows\nfour hazards: drift from truth, self-repair, fresh fabrication, and external\ndetection. A general mathematical model of discursive networks is developed to\nprovide valuable insights: A network governed only by drift and self-repair\nstabilizes at a modest error rate; adding fabrication reproduces the high rates\nseen in current LLMs. Giving each false claim even a small chance of peer\nreview shifts the system to a truth-dominant state. We operationalize peer\nreview with the open-source \\emph{Flaws-of-Others (FOO) algorithm}: a\nconfigurable loop in which any set of agents critique one another while a\nharmoniser merges their verdicts. The takeaway is practical and cultural:\nreliability in this new medium comes not from perfecting single models but from\nwiring imperfect ones into networks that keep each other honest.", "comment": "27 pages, 3 figures, 4 tables, 1 algorithm, 28 references", "pdf_url": "http://arxiv.org/pdf/2507.06565v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07077", "title": "Reading a Ruler in the Wild", "authors": ["Yimu Pan", "Manas Mehta", "Gwen Sincerbeaux", "Jeffery A. Goldstein", "Alison D. Gernand", "James Z. Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07077v1", "summary": "Accurately converting pixel measurements into absolute real-world dimensions\nremains a fundamental challenge in computer vision and limits progress in key\napplications such as biomedicine, forensics, nutritional analysis, and\ne-commerce. We introduce RulerNet, a deep learning framework that robustly\ninfers scale \"in the wild\" by reformulating ruler reading as a unified\nkeypoint-detection problem and by representing the ruler with\ngeometric-progression parameters that are invariant to perspective\ntransformations. Unlike traditional methods that rely on handcrafted thresholds\nor rigid, ruler-specific pipelines, RulerNet directly localizes centimeter\nmarks using a distortion-invariant annotation and training strategy, enabling\nstrong generalization across diverse ruler types and imaging conditions while\nmitigating data scarcity. We also present a scalable synthetic-data pipeline\nthat combines graphics-based ruler generation with ControlNet to add\nphotorealistic context, greatly increasing training diversity and improving\nperformance. To further enhance robustness and efficiency, we propose DeepGP, a\nlightweight feed-forward network that regresses geometric-progression\nparameters from noisy marks and eliminates iterative optimization, enabling\nreal-time scale estimation on mobile or edge devices. Experiments show that\nRulerNet delivers accurate, consistent, and efficient scale estimates under\nchallenging real-world conditions. These results underscore its utility as a\ngeneralizable measurement tool and its potential for integration with other\nvision components for automated, scale-aware analysis in high-impact domains. A\nlive demo is available at https://huggingface.co/spaces/ymp5078/RulerNet-Demo.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07077v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.05077", "title": "Sequential Attention-based Sampling for Histopathological Analysis", "authors": ["Tarun G", "Naman Malpani", "Gugan Thoppe", "Sridharan Devarajan"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05077v2", "summary": "Deep neural networks are increasingly applied for automated histopathology.\nYet, whole-slide images (WSIs) are often acquired at gigapixel sizes, rendering\nit computationally infeasible to analyze them entirely at high resolution.\nDiagnostic labels are largely available only at the slide-level, because expert\nannotation of images at a finer (patch) level is both laborious and expensive.\nMoreover, regions with diagnostic information typically occupy only a small\nfraction of the WSI, making it inefficient to examine the entire slide at full\nresolution. Here, we propose SASHA -- {\\it S}equential {\\it A}ttention-based\n{\\it S}ampling for {\\it H}istopathological {\\it A}nalysis -- a deep\nreinforcement learning approach for efficient analysis of histopathological\nimages. First, SASHA learns informative features with a lightweight\nhierarchical, attention-based multiple instance learning (MIL) model. Second,\nSASHA samples intelligently and zooms selectively into a small fraction\n(10-20\\%) of high-resolution patches, to achieve reliable diagnosis. We show\nthat SASHA matches state-of-the-art methods that analyze the WSI fully at\nhigh-resolution, albeit at a fraction of their computational and memory costs.\nIn addition, it significantly outperforms competing, sparse sampling methods.\nWe propose SASHA as an intelligent sampling model for medical imaging\nchallenges that involve automated diagnosis with exceptionally large images\ncontaining sparsely informative features.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05077v2", "cate": "eess.IV", "date": "2025-07-07", "updated": "2025-07-09"}
{"id": "2507.06435", "title": "Temporal Analysis of Climate Policy Discourse: Insights from Dynamic Embedded Topic Modeling", "authors": ["Rafiu Adekoya Badekale", "Adewale Akinfaderin"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 7 figures. Code and data available at this https URL", "url": "http://arxiv.org/abs/2507.06435v1", "summary": "Understanding how policy language evolves over time is critical for assessing\nglobal responses to complex challenges such as climate change. Temporal\nanalysis helps stakeholders, including policymakers and researchers, to\nevaluate past priorities, identify emerging themes, design governance\nstrategies, and develop mitigation measures. Traditional approaches, such as\nmanual thematic coding, are time-consuming and limited in capturing the\ncomplex, interconnected nature of global policy discourse. With the increasing\nrelevance of unsupervised machine learning, these limitations can be addressed,\nparticularly under high-volume, complex, and high-dimensional data conditions.\nIn this work, we explore a novel approach that applies the dynamic embedded\ntopic model (DETM) to analyze the evolution of global climate policy discourse.\nA probabilistic model designed to capture the temporal dynamics of topics over\ntime. We collected a corpus of United Nations Framework Convention on Climate\nChange (UNFCCC) policy decisions from 1995 to 2023, excluding 2020 due to the\npostponement of COP26 as a result of the COVID-19 pandemic. The model reveals\nshifts from early emphases on greenhouse gases and international conventions to\nrecent focuses on implementation, technical collaboration, capacity building,\nfinance, and global agreements. Section 3 presents the modeling pipeline,\nincluding preprocessing, model training, and visualization of temporal word\ndistributions. Our results show that DETM is a scalable and effective tool for\nanalyzing the evolution of global policy discourse. Section 4 discusses the\nimplications of these findings and we concluded with future directions and\nrefinements to extend this approach to other policy domains.", "comment": "10 pages, 7 figures. Code and data available at\n  https://github.com/AdeTheBade/TACPD.git", "pdf_url": "http://arxiv.org/pdf/2507.06435v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "1907.00317", "title": "Waiting is not easy but worth it: the online TSP on the line revisited", "authors": ["Pei-Chuan Chen", "Erik D. Demaine", "Chung-Shou Liao", "Hao-Ting Wei"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Withdrawn due to an error in our analysis for the upper bound that affects the main results", "url": "http://arxiv.org/abs/1907.00317v2", "summary": "We consider the online traveling salesman problem on the real line (OLTSPL)\nin which a salesman begins at the origin, traveling at no faster than unit\nspeed along the real line, and wants to serve a sequence of requests, arriving\nonline over time on the real line and return to the origin as quickly as\npossible. The problem has been widely investigated for more than two decades,\nbut was just optimally solved by a deterministic algorithm with a competitive\nratio of $(9+\\sqrt{17})/8$, reported in~[Bjelde A. et al., in Proc. SODA 2017,\npp.994--1005].\n  In this study we present lower bounds and upper bounds for randomized\nalgorithms in the OLTSPL. Precisely, we show, for the first time, that a simple\nrandomized \\emph{zealous} algorithm can improve the optimal deterministic\nalgorithm. Here an algorithm is called zealous if waiting strategies are not\nallowed to use for the salesman as long as there are unserved requests.\nMoreover, we incorporate a natural waiting scheme into the randomized\nalgorithm, which can even achieve the lower bound we propose for any randomized\nalgorithms, and thus it is optimal. We also consider randomized algorithms\nagainst a \\emph{fair} adversary, i.e. an adversary with restricted power that\nrequires the salesman to move within the convex hull of the origin and the\nrequests released so far. The randomized non-zealous algorithm can outperform\nthe optimal deterministic algorithm against the fair adversary as well.", "comment": "Withdrawn due to an error in our analysis for the upper bound that\n  affects the main results", "pdf_url": "http://arxiv.org/pdf/1907.00317v2", "cate": "cs.DS", "date": "2019-06-30", "updated": "2025-07-09"}
{"id": "2507.06646", "title": "Assessing Learned Models for Phase-only Hologram Compression", "authors": ["Zicong Peng", "Yicheng Zhan", "Josef Spjut", "Kaan Akşit"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      SIGGRAPH 2025 Poster", "url": "http://arxiv.org/abs/2507.06646v1", "summary": "We evaluate the performance of four common learned models utilizing INR and\nVAE structures for compressing phase-only holograms in holographic displays.\nThe evaluated models include a vanilla MLP, SIREN, and FilmSIREN, with TAESD as\nthe representative VAE model. Our experiments reveal that a pretrained image\nVAE, TAESD, with 2.2M parameters struggles with phase-only hologram\ncompression, revealing the need for task-specific adaptations. Among the INRs,\nSIREN with 4.9k parameters achieves %40 compression with high quality in the\nreconstructed 3D images (PSNR = 34.54 dB). These results emphasize the\neffectiveness of INRs and identify the limitations of pretrained image\ncompression VAEs for hologram compression task.", "comment": "SIGGRAPH 2025 Poster", "pdf_url": "http://arxiv.org/pdf/2507.06646v1", "cate": "cs.GR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2503.09567", "title": "Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models", "authors": ["Qiguang Chen", "Libo Qin", "Jinhao Liu", "Dengyun Peng", "Jiannan Guan", "Peng Wang", "Mengkang Hu", "Yuhang Zhou", "Te Gao", "Wanxiang Che"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Paper are available at this https URL , and Github are available at this https URL", "url": "http://arxiv.org/abs/2503.09567v4", "summary": "Recent advancements in reasoning with large language models (RLLMs), such as\nOpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in\ncomplex domains like mathematics and coding. A central factor in their success\nlies in the application of long chain-of-thought (Long CoT) characteristics,\nwhich enhance reasoning abilities and enable the solution of intricate\nproblems. However, despite these developments, a comprehensive survey on Long\nCoT is still lacking, limiting our understanding of its distinctions from\ntraditional short chain-of-thought (Short CoT) and complicating ongoing debates\non issues like \"overthinking\" and \"inference-time scaling.\" This survey seeks\nto fill this gap by offering a unified perspective on Long CoT. (1) We first\ndistinguish Long CoT from Short CoT and introduce a novel taxonomy to\ncategorize current reasoning paradigms. (2) Next, we explore the key\ncharacteristics of Long CoT: deep reasoning, extensive exploration, and\nfeasible reflection, which enable models to handle more complex tasks and\nproduce more efficient, coherent outcomes compared to the shallower Short CoT.\n(3) We then investigate key phenomena such as the emergence of Long CoT with\nthese characteristics, including overthinking, and inference-time scaling,\noffering insights into how these processes manifest in practice. (4) Finally,\nwe identify significant research gaps and highlight promising future\ndirections, including the integration of multi-modal reasoning, efficiency\nimprovements, and enhanced knowledge frameworks. By providing a structured\noverview, this survey aims to inspire future research and further the\ndevelopment of logical reasoning in artificial intelligence.", "comment": "Paper are available at https://long-cot.github.io/, and Github are\n  available at\n  https://github.com/LightChen233/Awesome-Long-Chain-of-Thought-Reasoning", "pdf_url": "http://arxiv.org/pdf/2503.09567v4", "cate": "cs.AI", "date": "2025-03-12", "updated": "2025-07-09"}
{"id": "2507.06607", "title": "Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long Generation", "authors": ["Liliang Ren", "Congcong Chen", "Haoran Xu", "Young Jin Kim", "Adam Atkinson", "Zheng Zhan", "Jiankai Sun", "Baolin Peng", "Liyuan Liu", "Shuohang Wang", "Hao Cheng", "Jianfeng Gao", "Weizhu Chen", "Yelong Shen"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06607v1", "summary": "Recent advances in language modeling have demonstrated the effectiveness of\nState Space Models (SSMs) for efficient sequence modeling. While hybrid\narchitectures such as Samba and the decoder-decoder architecture, YOCO, have\nshown promising performance gains over Transformers, prior works have not\ninvestigated the efficiency potential of representation sharing between SSM\nlayers. In this paper, we introduce the Gated Memory Unit (GMU), a simple yet\neffective mechanism for efficient memory sharing across layers. We apply it to\ncreate SambaY, a decoder-hybrid-decoder architecture that incorporates GMUs in\nthe cross-decoder to share memory readout states from a Samba-based\nself-decoder. SambaY significantly enhances decoding efficiency, preserves\nlinear pre-filling time complexity, and boosts long-context performance, all\nwhile eliminating the need for explicit positional encoding. Through extensive\nscaling experiments, we demonstrate that our model exhibits a significantly\nlower irreducible loss compared to a strong YOCO baseline, indicating superior\nperformance scalability under large-scale compute regimes. Our largest model\nenhanced with Differential Attention, Phi4-mini-Flash-Reasoning, achieves\nsignificantly better performance than Phi4-mini-Reasoning on reasoning tasks\nsuch as Math500, AIME24/25, and GPQA Diamond without any reinforcement\nlearning, while delivering up to 10x higher decoding throughput on 2K-length\nprompts with 32K generation length under the vLLM inference framework. We\nrelease our training codebase on open-source data at\nhttps://github.com/microsoft/ArchScale.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06607v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07079", "title": "Evaluating Attribute Confusion in Fashion Text-to-Image Generation", "authors": ["Ziyue Liu", "Federico Girella", "Yiming Wang", "Davide Talon"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICIAP25. Project page: site [ this https URL \\", "url": "http://arxiv.org/abs/2507.07079v1", "summary": "Despite the rapid advances in Text-to-Image (T2I) generation models, their\nevaluation remains challenging in domains like fashion, involving complex\ncompositional generation. Recent automated T2I evaluation methods leverage\npre-trained vision-language models to measure cross-modal alignment. However,\nour preliminary study reveals that they are still limited in assessing rich\nentity-attribute semantics, facing challenges in attribute confusion, i.e.,\nwhen attributes are correctly depicted but associated to the wrong entities. To\naddress this, we build on a Visual Question Answering (VQA) localization\nstrategy targeting one single entity at a time across both visual and textual\nmodalities. We propose a localized human evaluation protocol and introduce a\nnovel automatic metric, Localized VQAScore (L-VQAScore), that combines visual\nlocalization with VQA probing both correct (reflection) and miss-localized\n(leakage) attribute generation. On a newly curated dataset featuring\nchallenging compositional alignment scenarios, L-VQAScore outperforms\nstate-of-the-art T2I evaluation methods in terms of correlation with human\njudgments, demonstrating its strength in capturing fine-grained\nentity-attribute associations. We believe L-VQAScore can be a reliable and\nscalable alternative to subjective evaluations.", "comment": "Accepted to ICIAP25. Project page: site\n  [https://intelligolabs.github.io/L-VQAScore/\\", "pdf_url": "http://arxiv.org/pdf/2507.07079v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.05656", "title": "ADPv2: A Hierarchical Histological Tissue Type-Annotated Dataset for Potential Biomarker Discovery of Colorectal Disease", "authors": ["Zhiyuan Yang", "Kai Li", "Sophia Ghamoshi Ramandi", "Patricia Brassard", "Hakim Khellaf", "Vincent Quoc-Huy Trinh", "Jennifer Zhang", "Lina Chen", "Corwyn Rowsell", "Sonal Varma", "Kostas Plataniotis", "Mahdi S. Hosseini"], "categories": ["eess.IV", "cs.CV", "cs.LG", "q-bio.QM", "I.2.10; I.2.1"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05656v2", "summary": "Computational pathology (CoPath) leverages histopathology images to enhance\ndiagnostic precision and reproducibility in clinical pathology. However,\npublicly available datasets for CoPath that are annotated with extensive\nhistological tissue type (HTT) taxonomies at a granular level remain scarce due\nto the significant expertise and high annotation costs required. Existing\ndatasets, such as the Atlas of Digital Pathology (ADP), address this by\noffering diverse HTT annotations generalized to multiple organs, but limit the\ncapability for in-depth studies on specific organ diseases. Building upon this\nfoundation, we introduce ADPv2, a novel dataset focused on gastrointestinal\nhistopathology. Our dataset comprises 20,004 image patches derived from healthy\ncolon biopsy slides, annotated according to a hierarchical taxonomy of 32\ndistinct HTTs of 3 levels. Furthermore, we train a multilabel representation\nlearning model following a two-stage training procedure on our ADPv2 dataset.\nWe leverage the VMamba architecture and achieving a mean average precision\n(mAP) of 0.88 in multilabel classification of colon HTTs. Finally, we show that\nour dataset is capable of an organ-specific in-depth study for potential\nbiomarker discovery by analyzing the model's prediction behavior on tissues\naffected by different colon diseases, which reveals statistical patterns that\nconfirm the two pathological pathways of colon cancer development. Our dataset\nis publicly available at https://zenodo.org/records/15307021", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05656v2", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2507.06448", "title": "Perception-Aware Policy Optimization for Multimodal Reasoning", "authors": ["Zhenhailong Wang", "Xuehang Guo", "Sofia Stoica", "Haiyang Xu", "Hongru Wang", "Hyeonjeong Ha", "Xiusi Chen", "Yangyi Chen", "Ming Yan", "Fei Huang", "Heng Ji"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06448v1", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a\nhighly effective strategy for endowing Large Language Models (LLMs) with robust\nmulti-step reasoning abilities. However, its design and optimizations remain\ntailored to purely textual domains, resulting in suboptimal performance when\napplied to multimodal reasoning tasks. In particular, we observe that a major\nsource of error in current multimodal reasoning lies in the perception of\nvisual inputs. To address this bottleneck, we propose Perception-Aware Policy\nOptimization (PAPO), a simple yet effective extension of GRPO that encourages\nthe model to learn to perceive while learning to reason, entirely from internal\nsupervision signals. Notably, PAPO does not rely on additional data curation,\nexternal reward models, or proprietary models. Specifically, we introduce the\nImplicit Perception Loss in the form of a KL divergence term to the GRPO\nobjective, which, despite its simplicity, yields significant overall\nimprovements (4.4%) on diverse multimodal benchmarks. The improvements are more\npronounced, approaching 8.0%, on tasks with high vision dependency. We also\nobserve a substantial reduction (30.5%) in perception errors, indicating\nimproved perceptual capabilities with PAPO. We conduct comprehensive analysis\nof PAPO and identify a unique loss hacking issue, which we rigorously analyze\nand mitigate through a Double Entropy Loss. Overall, our work introduces a\ndeeper integration of perception-aware supervision into RLVR learning\nobjectives and lays the groundwork for a new RL framework that encourages\nvisually grounded reasoning. Project page: https://mikewangwzhl.github.io/PAPO.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06448v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2404.14803", "title": "Cycling in the forest with Wilson's algorithm", "authors": ["Michaël Fanuel", "Rémi Bardenet"], "categories": ["cs.DS", "math-ph", "math.MP", "math.PR"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      41 pages, 7 figures. Improved presentation and an extra section about a viewpoint on this algorithm using 'Partial Rejection Sampling'", "url": "http://arxiv.org/abs/2404.14803v3", "summary": "We consider a probability measure on cycle-rooted spanning forests (CRSFs)\nintroduced by Kenyon. CRSFs are spanning subgraphs, each connected component of\nwhich has a unique cycle; they generalize spanning trees. A generalization of\nWilson's celebrated CyclePopping algorithm for uniform spanning trees has been\nproposed for CRSFs, and several concise proofs have been given that the\nalgorithm samples from Kenyon's distribution. In this survey, we flesh out all\nthe details of such a proof of correctness, progressively generalizing a proof\nby Marchal for spanning trees. This detailed proof has several interests.\nFirst, it serves as a modern tutorial on Wilson's algorithm, suitable for\napplied probability and computer science audiences. Compared to uniform\nspanning trees, the more sophisticated motivating application to CRSFs brings\nforth connections to recent research topics such as loop measures, partial\nrejection sampling, and heaps of cycles. Second, the detailed proof \\emph{\\`a\nla} Marchal yields the law of the time complexity of the sampling algorithm,\nshedding light on practical situations where the algorithm is expected to run\nfast.", "comment": "41 pages, 7 figures. Improved presentation and an extra section about\n  a viewpoint on this algorithm using 'Partial Rejection Sampling'", "pdf_url": "http://arxiv.org/pdf/2404.14803v3", "cate": "cs.DS", "date": "2024-04-23", "updated": "2025-07-09"}
{"id": "2507.07000", "title": "Enhancing non-Rigid 3D Model Deformations Using Mesh-based Gaussian Splatting", "authors": ["Wijayathunga W. M. R. D. B"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07000v1", "summary": "We propose a novel framework that enhances non-rigid 3D model deformations by\nbridging mesh representations with 3D Gaussian splatting. While traditional\nGaussian splatting delivers fast, real-time radiance-field rendering, its\npost-editing capabilities and support for large-scale, non-rigid deformations\nremain limited. Our method addresses these challenges by embedding Gaussian\nkernels directly onto explicit mesh surfaces. This allows the mesh's inherent\ntopological and geometric priors to guide intuitive editing operations -- such\nas moving, scaling, and rotating individual 3D components -- and enables\ncomplex deformations like bending and stretching. This work paves the way for\nmore flexible 3D content-creation workflows in applications spanning virtual\nreality, character animation, and interactive design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07000v1", "cate": "cs.GR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2503.11951", "title": "SagaLLM: Context Management, Validation, and Transaction Guarantees for Multi-Agent LLM Planning", "authors": ["Edward Y. Chang", "Longling Geng"], "categories": ["cs.AI", "I.2.7"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      13 pages, 10 tables, 5 figures", "url": "http://arxiv.org/abs/2503.11951v3", "summary": "This paper introduces SagaLLM, a structured multi-agent architecture designed\nto address four foundational limitations of current LLM-based planning systems:\nunreliable self-validation, context loss, lack of transactional safeguards, and\ninsufficient inter-agent coordination. While recent frameworks leverage LLMs\nfor task decomposition and multi-agent communication, they often fail to ensure\nconsistency, rollback, or constraint satisfaction across distributed workflows.\nSagaLLM bridges this gap by integrating the Saga transactional pattern with\npersistent memory, automated compensation, and independent validation agents.\nIt leverages LLMs' generative reasoning to automate key tasks traditionally\nrequiring hand-coded coordination logic, including state tracking, dependency\nanalysis, log schema generation, and recovery orchestration. Although SagaLLM\nrelaxes strict ACID guarantees, it ensures workflow-wide consistency and\nrecovery through modular checkpointing and compensable execution. Empirical\nevaluations across planning domains demonstrate that standalone LLMs frequently\nviolate interdependent constraints or fail to recover from disruptions. In\ncontrast, SagaLLM achieves significant improvements in consistency, validation\naccuracy, and adaptive coordination under uncertainty, establishing a robust\nfoundation for real-world, scalable LLM-based multi-agent systems.", "comment": "13 pages, 10 tables, 5 figures", "pdf_url": "http://arxiv.org/pdf/2503.11951v3", "cate": "cs.AI", "date": "2025-03-15", "updated": "2025-07-09"}
{"id": "2507.06637", "title": "Semi-parametric Functional Classification via Path Signatures Logistic Regression", "authors": ["Pengcheng Zeng", "Siyuan Jiang"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06637v1", "summary": "We propose Path Signatures Logistic Regression (PSLR), a semi-parametric\nframework for classifying vector-valued functional data with scalar covariates.\nClassical functional logistic regression models rely on linear assumptions and\nfixed basis expansions, which limit flexibility and degrade performance under\nirregular sampling. PSLR overcomes these issues by leveraging truncated path\nsignatures to construct a finite-dimensional, basis-free representation that\ncaptures nonlinear and cross-channel dependencies. By embedding trajectories as\ntime-augmented paths, PSLR extracts stable, geometry-aware features that are\nrobust to sampling irregularity without requiring a common time grid, while\nstill preserving subject-specific timing patterns. We establish theoretical\nguarantees for the existence and consistent estimation of the optimal\ntruncation order, along with non-asymptotic risk bounds. Experiments on\nsynthetic and real-world datasets show that PSLR outperforms traditional\nfunctional classifiers in accuracy, robustness, and interpretability,\nparticularly under non-uniform sampling schemes. Our results highlight the\npractical and theoretical benefits of integrating rough path theory into modern\nfunctional data analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06637v1", "cate": "stat.ML", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07095", "title": "Go to Zero: Towards Zero-shot Motion Generation with Million-scale Data", "authors": ["Ke Fan", "Shunlin Lu", "Minyue Dai", "Runyi Yu", "Lixing Xiao", "Zhiyang Dou", "Junting Dong", "Lizhuang Ma", "Jingbo Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project Page: this https URL", "url": "http://arxiv.org/abs/2507.07095v1", "summary": "Generating diverse and natural human motion sequences based on textual\ndescriptions constitutes a fundamental and challenging research area within the\ndomains of computer vision, graphics, and robotics. Despite significant\nadvancements in this field, current methodologies often face challenges\nregarding zero-shot generalization capabilities, largely attributable to the\nlimited size of training datasets. Moreover, the lack of a comprehensive\nevaluation framework impedes the advancement of this task by failing to\nidentify directions for improvement. In this work, we aim to push\ntext-to-motion into a new era, that is, to achieve the generalization ability\nof zero-shot. To this end, firstly, we develop an efficient annotation pipeline\nand introduce MotionMillion-the largest human motion dataset to date, featuring\nover 2,000 hours and 2 million high-quality motion sequences. Additionally, we\npropose MotionMillion-Eval, the most comprehensive benchmark for evaluating\nzero-shot motion generation. Leveraging a scalable architecture, we scale our\nmodel to 7B parameters and validate its performance on MotionMillion-Eval. Our\nresults demonstrate strong generalization to out-of-domain and complex\ncompositional motions, marking a significant step toward zero-shot human motion\ngeneration. The code is available at\nhttps://github.com/VankouF/MotionMillion-Codes.", "comment": "Project Page: https://vankouf.github.io/MotionMillion/", "pdf_url": "http://arxiv.org/pdf/2507.07095v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.05742", "title": "Tissue Concepts v2: A Supervised Foundation Model For Whole Slide Images", "authors": ["Till Nicke", "Daniela Schacherer", "Jan Raphael Schäfer", "Natalia Artysh", "Antje Prasse", "André Homeyer", "Andrea Schenk", "Henning Höfener", "Johannes Lotz"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05742v2", "summary": "Foundation models (FMs) are transforming the field of computational pathology\nby offering new approaches to analyzing histopathology images. Typically\nrelying on weeks of training on large databases, the creation of FMs is a\nresource-intensive process in many ways. In this paper, we introduce the\nextension of our supervised foundation model, Tissue Concepts, to whole slide\nimages, called Tissue Concepts v2 (TCv2), a supervised foundation model for\nwhole slide images to address the issue above. TCv2 uses supervised, end-to-end\nmultitask learning on slide-level labels. Training TCv2 uses a fraction of the\ntraining resources compared to self-supervised training. The presented model\nshows superior performance compared to SSL-trained models in cancer subtyping\nbenchmarks and is fully trained on freely available data. Furthermore, a shared\ntrained attention module provides an additional layer of explainability across\ndifferent tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05742v2", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2507.06450", "title": "A Semantic Parsing Framework for End-to-End Time Normalization", "authors": ["Xin Su", "Sungduk Yu", "Phillip Howard", "Steven Bethard"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06450v1", "summary": "Time normalization is the task of converting natural language temporal\nexpressions into machine-readable representations. It underpins many downstream\napplications in information retrieval, question answering, and clinical\ndecision-making. Traditional systems based on the ISO-TimeML schema limit\nexpressivity and struggle with complex constructs such as compositional,\nevent-relative, and multi-span time expressions. In this work, we introduce a\nnovel formulation of time normalization as a code generation task grounded in\nthe SCATE framework, which defines temporal semantics through symbolic and\ncompositional operators. We implement a fully executable SCATE Python library\nand demonstrate that large language models (LLMs) can generate executable SCATE\ncode. Leveraging this capability, we develop an automatic data augmentation\npipeline using LLMs to synthesize large-scale annotated data with code-level\nvalidation. Our experiments show that small, locally deployable models trained\non this augmented data can achieve strong performance, outperforming even their\nLLM parents and enabling practical, accurate, and interpretable time\nnormalization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06450v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2505.10789", "title": "Bandwidth vs BFS Width in Matrix Reordering, Graph Reconstruction, and Graph Drawing", "authors": ["David Eppstein", "Michael T. Goodrich", "Songyu Liu"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.10789v3", "summary": "We provide the first approximation quality guarantees for the Cuthull-McKee\nheuristic for reordering symmetric matrices to have low bandwidth, and we\nprovide an algorithm for reconstructing bounded-bandwidth graphs from distance\noracles with near-linear query complexity. To prove these results we introduce\na new width parameter, BFS width, and we prove polylogarithmic upper and lower\nbounds on the BFS width of graphs of bounded bandwidth. Unlike other width\nparameters, such as bandwidth, pathwidth, and treewidth, BFS width can easily\nbe computed in polynomial time. Bounded BFS width implies bounded bandwidth,\npathwidth, and treewidth, which in turn imply fixed-parameter tractable\nalgorithms for many problems that are NP-hard for general graphs. In addition\nto their applications to matrix ordering, we also provide applications of BFS\nwidth to graph reconstruction, to reconstruct graphs from distance queries, and\ngraph drawing, to construct arc diagrams of small height.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.10789v3", "cate": "cs.DS", "date": "2025-05-16", "updated": "2025-07-08"}
{"id": "2405.18133", "title": "Gaussian Fluids: A Grid-Free Fluid Solver based on Gaussian Spatial Representation", "authors": ["Jingrui Xing", "Bin Wang", "Mengyu Chu", "Baoquan Chen"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.18133v2", "summary": "We present a grid-free fluid solver featuring a novel Gaussian\nrepresentation. Drawing inspiration from the expressive capabilities of 3D\nGaussian Splatting in multi-view image reconstruction, we model the continuous\nflow velocity as a weighted sum of multiple Gaussian functions. This\nrepresentation is continuously differentiable, which enables us to derive\nspatial differentials directly and solve the time-dependent PDE via a custom\nfirst-order optimization tailored to fluid dynamics. Compared to traditional\ndiscretizations, which typically adopt Eulerian, Lagrangian, or hybrid\nperspectives, our approach is inherently memory-efficient and spatially\nadaptive, enabling it to preserve fine-scale structures and vortices with high\nfidelity. While these advantages are also sought by implicit neural\nrepresentations, GSR offers enhanced robustness, accuracy, and generality\nacross diverse fluid phenomena, with improved computational efficiency during\ntemporal evolution. Though our first-order solver does not yet match the speed\nof fluid solvers using explicit representations, its continuous nature\nsubstantially reduces spatial discretization error and opens a new avenue for\nhigh-fidelity simulation. We evaluate the proposed solver across a broad range\nof 2D and 3D fluid phenomena, demonstrating its ability to preserve intricate\nvortex dynamics, accurately capture boundary-induced effects such as K\\'arm\\'an\nvortex streets, and remain robust across long time horizons - all without\nadditional parameter tuning. Our results suggest that GSR offers a compelling\ndirection for future research in fluid simulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.18133v2", "cate": "cs.GR", "date": "2024-05-28", "updated": "2025-07-09"}
{"id": "2504.03635", "title": "Do Larger Language Models Imply Better Generalization? A Pretraining Scaling Law for Implicit Reasoning", "authors": ["Xinyi Wang", "Shawn Tan", "Mingyu Jin", "William Yang Wang", "Rameswar Panda", "Yikang Shen"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.03635v2", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na wide range of tasks requiring complex reasoning. However, the effects of\nscaling on their reasoning abilities remain insufficiently understood. In this\npaper, we introduce a synthetic multihop reasoning environment designed to\nclosely replicate the structure and distribution of real-world large-scale\nknowledge graphs. Our reasoning task involves completing missing edges in the\ngraph, which requires advanced multi-hop reasoning and mimics real-world\nreasoning scenarios. To evaluate this, we pretrain language models (LMs) from\nscratch solely on triples from the incomplete graph and assess their ability to\ninfer the missing edges. Interestingly, we observe that overparameterization\ncan impair reasoning performance due to excessive memorization. We investigate\ndifferent factors that affect this U-shaped loss curve, including graph\nstructure, model size, and training steps. To predict the optimal model size\nfor a specific knowledge graph, we find an empirical scaling that linearly maps\nthe knowledge graph search entropy to the optimal model size. This work\nprovides new insights into the relationship between scaling and reasoning in\nLLMs, shedding light on possible ways to optimize their performance for\nreasoning tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.03635v2", "cate": "cs.AI", "date": "2025-04-04", "updated": "2025-07-09"}
{"id": "2507.06677", "title": "Fast Gaussian Processes under Monotonicity Constraints", "authors": ["Chao Zhang", "Jasper M. Everink", "Jakob Sauer Jørgensen"], "categories": ["stat.ML", "cs.LG", "stat.ME", "60G15"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      35 pages, 10 figures", "url": "http://arxiv.org/abs/2507.06677v1", "summary": "Gaussian processes (GPs) are widely used as surrogate models for complicated\nfunctions in scientific and engineering applications. In many cases, prior\nknowledge about the function to be approximated, such as monotonicity, is\navailable and can be leveraged to improve model fidelity. Incorporating such\nconstraints into GP models enhances predictive accuracy and reduces\nuncertainty, but remains a computationally challenging task for\nhigh-dimensional problems. In this work, we present a novel virtual point-based\nframework for building constrained GP models under monotonicity constraints,\nbased on regularized linear randomize-then-optimize (RLRTO), which enables\nefficient sampling from a constrained posterior distribution by means of\nsolving randomized optimization problems. We also enhance two existing virtual\npoint-based approaches by replacing Gibbs sampling with the No U-Turn Sampler\n(NUTS) for improved efficiency. A Python implementation of these methods is\nprovided and can be easily applied to a wide range of problems. This\nimplementation is then used to validate the approaches on approximating a range\nof synthetic functions, demonstrating comparable predictive performance between\nall considered methods and significant improvements in computational efficiency\nwith the two NUTS methods and especially with the RLRTO method. The framework\nis further applied to construct surrogate models for systems of differential\nequations.", "comment": "35 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.06677v1", "cate": "stat.ML", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07104", "title": "Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models", "authors": ["Tiezheng Zhang", "Yitong Li", "Yu-cheng Chou", "Jieneng Chen", "Alan Yuille", "Chen Wei", "Junfei Xiao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07104v1", "summary": "Building state-of-the-art Vision-Language Models (VLMs) with strong\ncaptioning capabilities typically necessitates training on billions of\nhigh-quality image-text pairs, requiring millions of GPU hours. This paper\nintroduces the Vision-Language-Vision (VLV) auto-encoder framework, which\nstrategically leverages key pretrained components: a vision encoder, the\ndecoder of a Text-to-Image (T2I) diffusion model, and subsequently, a Large\nLanguage Model (LLM). Specifically, we establish an information bottleneck by\nregularizing the language representation space, achieved through freezing the\npretrained T2I diffusion decoder. Our VLV pipeline effectively distills\nknowledge from the text-conditioned diffusion model using continuous\nembeddings, demonstrating comprehensive semantic understanding via high-quality\nreconstructions. Furthermore, by fine-tuning a pretrained LLM to decode the\nintermediate language representations into detailed descriptions, we construct\na state-of-the-art (SoTA) captioner comparable to leading models like GPT-4o\nand Gemini 2.0 Flash. Our method demonstrates exceptional cost-efficiency and\nsignificantly reduces data requirements; by primarily utilizing single-modal\nimages for training and maximizing the utility of existing pretrained models\n(image encoder, T2I diffusion model, and LLM), it circumvents the need for\nmassive paired image-text datasets, keeping the total training expenditure\nunder $1,000 USD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07104v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2407.17399", "title": "Self-Calibrated Variance-Stabilizing Transformations for Real-World Image Denoising", "authors": ["Sébastien Herbreteau", "Michael Unser"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE/CVF International Conference on Computer Vision (ICCV) 2025", "url": "http://arxiv.org/abs/2407.17399v2", "summary": "Supervised deep learning has become the method of choice for image denoising.\nIt involves the training of neural networks on large datasets composed of pairs\nof noisy and clean images. However, the necessity of training data that are\nspecific to the targeted application constrains the widespread use of denoising\nnetworks. Recently, several approaches have been developed to overcome this\ndifficulty by whether artificially generating realistic clean/noisy image\npairs, or training exclusively on noisy images. In this paper, we show that,\ncontrary to popular belief, denoising networks specialized in the removal of\nGaussian noise can be efficiently leveraged in favor of real-world image\ndenoising, even without additional training. For this to happen, an appropriate\nvariance-stabilizing transform (VST) has to be applied beforehand. We propose\nan algorithm termed Noise2VST for the learning of such a model-free VST. Our\napproach requires only the input noisy image and an off-the-shelf Gaussian\ndenoiser. We demonstrate through extensive experiments the efficiency and\nsuperiority of Noise2VST in comparison to existing methods trained in the\nabsence of specific clean/noisy pairs.", "comment": "Accepted at IEEE/CVF International Conference on Computer Vision\n  (ICCV) 2025", "pdf_url": "http://arxiv.org/pdf/2407.17399v2", "cate": "cs.CV", "date": "2024-07-24", "updated": "2025-07-09"}
{"id": "2507.06457", "title": "A Systematic Analysis of Hybrid Linear Attention", "authors": ["Dustin Wang", "Rui-Jie Zhu", "Steven Abreu", "Yong Shan", "Taylor Kergan", "Yuqi Pan", "Yuhong Chou", "Zheng Li", "Ge Zhang", "Wenhao Huang", "Jason Eshraghian"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06457v1", "summary": "Transformers face quadratic complexity and memory issues with long sequences,\nprompting the adoption of linear attention mechanisms using fixed-size hidden\nstates. However, linear models often suffer from limited recall performance,\nleading to hybrid architectures that combine linear and full attention layers.\nDespite extensive hybrid architecture research, the choice of linear attention\ncomponent has not been deeply explored. We systematically evaluate various\nlinear attention models across generations - vector recurrences to advanced\ngating mechanisms - both standalone and hybridized. To enable this\ncomprehensive analysis, we trained and open-sourced 72 models: 36 at 340M\nparameters (20B tokens) and 36 at 1.3B parameters (100B tokens), covering six\nlinear attention variants across five hybridization ratios. Benchmarking on\nstandard language modeling and recall tasks reveals that superior standalone\nlinear models do not necessarily excel in hybrids. While language modeling\nremains stable across linear-to-full attention ratios, recall significantly\nimproves with increased full attention layers, particularly below a 3:1 ratio.\nOur study highlights selective gating, hierarchical recurrence, and controlled\nforgetting as critical for effective hybrid models. We recommend architectures\nsuch as HGRN-2 or GatedDeltaNet with a linear-to-full ratio between 3:1 and 6:1\nto achieve Transformer-level recall efficiently. Our models are open-sourced at\nhttps://huggingface.co/collections/m-a-p/hybrid-linear-attention-research-686c488a63d609d2f20e2b1e.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06457v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2408.00746", "title": "On the Low-Temperature MCMC threshold: the cases of sparse tensor PCA, sparse regression, and a geometric rule", "authors": ["Zongchen Chen", "Conor Sheehan", "Ilias Zadik"], "categories": ["math.ST", "cs.DS", "math.PR", "stat.TH"], "primary_category": "Subjects:       Statistics Theory (math.ST)", "pdf_link": null, "comments": "Comments:      Improved the sparse regression positive MCMC results and updated the literature review", "url": "http://arxiv.org/abs/2408.00746v3", "summary": "Over the last years, there has been a significant amount of work studying the\npower of specific classes of computationally efficient estimators for multiple\nstatistical parametric estimation tasks, including the estimators classes of\nlow-degree polynomials, spectral methods, and others. Despite that, our\nunderstanding of the important class of MCMC methods remains quite poorly\nunderstood. For instance, for many models of interest, the performance of even\nzero-temperature (greedy-like) MCMC methods that simply maximize the posterior\nremains elusive.\n  In this work, we provide an easy to check condition under which the\nlow-temperature Metropolis chain maximizes the posterior in polynomial-time\nwith high probability. The result is generally applicable, and in this work, we\nuse it to derive positive MCMC results for two classical sparse estimation\ntasks: the sparse tensor PCA model and sparse regression. Interestingly, in\nboth cases, we also leverage the Overlap Gap Property framework for inference\n(Gamarnik, Zadik AoS '22) to prove that our results are tight: no\nlow-temperature local MCMC method can achieve better performance. In\nparticular, our work identifies the \"low-temperature (local) MCMC threshold\"\nfor both sparse models. Interestingly, in the sparse tensor PCA model our\nresults indicate that low-temperature local MCMC methods significantly\nunderperform compared to other studied time-efficient methods, such as the\nclass of low-degree polynomials.", "comment": "Improved the sparse regression positive MCMC results and updated the\n  literature review", "pdf_url": "http://arxiv.org/pdf/2408.00746v3", "cate": "math.ST", "date": "2024-08-01", "updated": "2025-07-08"}
{"id": "2503.08724", "title": "Direct Flow Simulations with Implicit Neural Representation of Complex Geometry", "authors": ["Samundra Karki", "Mehdi Shadkah", "Cheng-Hau Yang", "Aditya Balu", "Guglielmo Scovazzi", "Adarsh Krishnamurthy", "Baskar Ganapathysubramanian"], "categories": ["cs.GR", "physics.flu-dyn"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      32 pages,29 figures, Supplement at end", "url": "http://arxiv.org/abs/2503.08724v2", "summary": "Implicit neural representations have emerged as a powerful approach for\nencoding complex geometries as continuous functions. These implicit models are\nwidely used in computer vision and 3D content creation, but their integration\ninto scientific computing workflows, such as finite element or finite volume\nsimulations, remains limited. One reason is that conventional simulation\npipelines require explicit geometric inputs (meshes), forcing INR-based shapes\nto be converted to meshes--a step that introduces approximation errors,\ncomputational overhead, and significant manual effort. Immersed boundary\nmethods partially alleviate this issue by allowing simulations on background\ngrids without body-fitted meshes. However, they still require an explicit\nboundary description and can suffer from numerical artifacts, such as sliver\ncut cells. The shifted boundary method (SBM) eliminates the need for explicit\ngeometry by using grid-aligned surrogate boundaries, making it inherently\ncompatible with implicit shape representations. Here, we present a framework\nthat directly couples neural implicit geometries with SBM to perform\nhigh-fidelity fluid flow simulations without any intermediate mesh generation.\nBy leveraging neural network inference, our approach computes the surrogate\nboundary and distance vectors required by SBM on-the-fly directly from the INR,\nthus completely bypassing traditional geometry processing. We demonstrate this\napproach on canonical 2D and 3D flow benchmarks (lid-driven cavity flows) and\ncomplex geometries (gyroids, the Stanford bunny, and AI-generated shapes),\nachieving simulation accuracy comparable to conventional mesh-based methods.\nThis work highlights a novel pathway for integrating AI-driven geometric\nrepresentations into computational physics, establishing INRs as a versatile\nand scalable tool for simulations and removing a long-standing bottleneck in\ngeometry handling.", "comment": "32 pages,29 figures, Supplement at end", "pdf_url": "http://arxiv.org/pdf/2503.08724v2", "cate": "cs.GR", "date": "2025-03-10", "updated": "2025-07-09"}
{"id": "2507.06503", "title": "USD: A User-Intent-Driven Sampling and Dual-Debiasing Framework for Large-Scale Homepage Recommendations", "authors": ["Jiaqi Zheng", "Cheng Guo", "Yi Cao", "Chaoqun Hou", "Tong Liu", "Bo Zheng"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06503v1", "summary": "Large-scale homepage recommendations face critical challenges from\npseudo-negative samples caused by exposure bias, where non-clicks may indicate\ninattention rather than disinterest. Existing work lacks thorough analysis of\ninvalid exposures and typically addresses isolated aspects (e.g., sampling\nstrategies), overlooking the critical impact of pseudo-positive samples - such\nas homepage clicks merely to visit marketing portals. We propose a unified\nframework for large-scale homepage recommendation sampling and debiasing. Our\nframework consists of two key components: (1) a user intent-aware negative\nsampling module to filter invalid exposure samples, and (2) an intent-driven\ndual-debiasing module that jointly corrects exposure bias and click bias.\nExtensive online experiments on Taobao demonstrate the efficacy of our\nframework, achieving significant improvements in user click-through rates\n(UCTR) by 35.4\\% and 14.5\\% in two variants of the marketing block on the\nTaobao homepage, Baiyibutie and Taobaomiaosha.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06503v1", "cate": "cs.IR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2505.03332", "title": "AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning", "authors": ["Evgeny Markhasin"], "categories": ["cs.AI", "physics.chem-ph"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      23 pages, 37 pages (references and appendixes)", "url": "http://arxiv.org/abs/2505.03332v4", "summary": "Critical peer review of scientific manuscripts presents a significant\nchallenge for Large Language Models (LLMs), partly due to data limitations and\nthe complexity of expert reasoning. This report introduces Persistent Workflow\nPrompting (PWP), a potentially broadly applicable prompt engineering\nmethodology designed to bridge this gap using standard LLM chat interfaces\n(zero-code, no APIs). We present a proof-of-concept PWP prompt for the critical\nanalysis of experimental chemistry manuscripts, featuring a hierarchical,\nmodular architecture (structured via Markdown) that defines detailed analysis\nworkflows. We develop this PWP prompt through iterative application of\nmeta-prompting techniques and meta-reasoning aimed at systematically codifying\nexpert review workflows, including tacit knowledge. Submitted once at the start\nof a session, this PWP prompt equips the LLM with persistent workflows\ntriggered by subsequent queries, guiding modern reasoning LLMs through\nsystematic, multimodal evaluations. Demonstrations show the PWP-guided LLM\nidentifying major methodological flaws in a test case while mitigating LLM\ninput bias and performing complex tasks, including distinguishing claims from\nevidence, integrating text/photo/figure analysis to infer parameters, executing\nquantitative feasibility checks, comparing estimates against claims, and\nassessing a priori plausibility. To ensure transparency and facilitate\nreplication, we provide full prompts, detailed demonstration analyses, and logs\nof interactive chats as supplementary resources. Beyond the specific\napplication, this work offers insights into the meta-development process\nitself, highlighting the potential of PWP, informed by detailed workflow\nformalization, to enable sophisticated analysis using readily available LLMs\nfor complex scientific tasks.", "comment": "23 pages, 37 pages (references and appendixes)", "pdf_url": "http://arxiv.org/pdf/2505.03332v4", "cate": "cs.AI", "date": "2025-05-06", "updated": "2025-07-08"}
{"id": "2507.06722", "title": "On the Effect of Uncertainty on Layer-wise Inference Dynamics", "authors": ["Sunwoo Kim", "Haneul Yoo", "Alice Oh"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to Actionable Interpretability Workshop - ICML 2025", "url": "http://arxiv.org/abs/2507.06722v1", "summary": "Understanding how large language models (LLMs) internally represent and\nprocess their predictions is central to detecting uncertainty and preventing\nhallucinations. While several studies have shown that models encode uncertainty\nin their hidden states, it is underexplored how this affects the way they\nprocess such hidden states. In this work, we demonstrate that the dynamics of\noutput token probabilities across layers for certain and uncertain outputs are\nlargely aligned, revealing that uncertainty does not seem to affect inference\ndynamics. Specifically, we use the Tuned Lens, a variant of the Logit Lens, to\nanalyze the layer-wise probability trajectories of final prediction tokens\nacross 11 datasets and 5 models. Using incorrect predictions as those with\nhigher epistemic uncertainty, our results show aligned trajectories for certain\nand uncertain predictions that both observe abrupt increases in confidence at\nsimilar layers. We balance this finding by showing evidence that more competent\nmodels may learn to process uncertainty differently. Our findings challenge the\nfeasibility of leveraging simplistic methods for detecting uncertainty at\ninference. More broadly, our work demonstrates how interpretability methods may\nbe used to investigate the way uncertainty affects inference.", "comment": "Accepted to Actionable Interpretability Workshop - ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.06722v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07106", "title": "Towards Multimodal Understanding via Stable Diffusion as a Task-Aware Feature Extractor", "authors": ["Vatsal Agarwal", "Matthew Gwilliam", "Gefen Kohavi", "Eshan Verma", "Daniel Ulbricht", "Abhinav Shrivastava"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Website: see this https URL", "url": "http://arxiv.org/abs/2507.07106v1", "summary": "Recent advances in multimodal large language models (MLLMs) have enabled\nimage-based question-answering capabilities. However, a key limitation is the\nuse of CLIP as the visual encoder; while it can capture coarse global\ninformation, it often can miss fine-grained details that are relevant to the\ninput query. To address these shortcomings, this work studies whether\npre-trained text-to-image diffusion models can serve as instruction-aware\nvisual encoders. Through an analysis of their internal representations, we find\ndiffusion features are both rich in semantics and can encode strong image-text\nalignment. Moreover, we find that we can leverage text conditioning to focus\nthe model on regions relevant to the input question. We then investigate how to\nalign these features with large language models and uncover a leakage\nphenomenon, where the LLM can inadvertently recover information from the\noriginal diffusion prompt. We analyze the causes of this leakage and propose a\nmitigation strategy. Based on these insights, we explore a simple fusion\nstrategy that utilizes both CLIP and conditional diffusion features. We\nevaluate our approach on both general VQA and specialized MLLM benchmarks,\ndemonstrating the promise of diffusion models for visual understanding,\nparticularly in vision-centric tasks that require spatial and compositional\nreasoning. Our project page can be found\nhttps://vatsalag99.github.io/mustafar/.", "comment": "Website: see https://vatsalag99.github.io/mustafar/", "pdf_url": "http://arxiv.org/pdf/2507.07106v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06489", "title": "On the Robustness of Verbal Confidence of LLMs in Adversarial Attacks", "authors": ["Stephen Obadinma", "Xiaodan Zhu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06489v1", "summary": "Robust verbal confidence generated by large language models (LLMs) is crucial\nfor the deployment of LLMs to ensure transparency, trust, and safety in\nhuman-AI interactions across many high-stakes applications. In this paper, we\npresent the first comprehensive study on the robustness of verbal confidence\nunder adversarial attacks. We introduce a novel framework for attacking verbal\nconfidence scores through both perturbation and jailbreak-based methods, and\nshow that these attacks can significantly jeopardize verbal confidence\nestimates and lead to frequent answer changes. We examine a variety of\nprompting strategies, model sizes, and application domains, revealing that\ncurrent confidence elicitation methods are vulnerable and that commonly used\ndefence techniques are largely ineffective or counterproductive. Our findings\nunderscore the urgent need to design more robust mechanisms for confidence\nexpression in LLMs, as even subtle semantic-preserving modifications can lead\nto misleading confidence in responses.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06489v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2411.16446", "title": "VQ-SGen: A Vector Quantized Stroke Representation for Creative Sketch Generation", "authors": ["Jiawei Wang", "Zhiming Cui", "Changjian Li"], "categories": ["cs.CV", "cs.GR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project Page: this https URL", "url": "http://arxiv.org/abs/2411.16446v3", "summary": "This paper presents VQ-SGen, a novel algorithm for high-quality creative\nsketch generation. Recent approaches have framed the task as pixel-based\ngeneration either as a whole or part-by-part, neglecting the intrinsic and\ncontextual relationships among individual strokes, such as the shape and\nspatial positioning of both proximal and distant strokes. To overcome these\nlimitations, we propose treating each stroke within a sketch as an entity and\nintroducing a vector-quantized (VQ) stroke representation for fine-grained\nsketch generation. Our method follows a two-stage framework - in stage one, we\ndecouple each stroke's shape and location information to ensure the VQ\nrepresentation prioritizes stroke shape learning. In stage two, we feed the\nprecise and compact representation into an auto-decoding Transformer to\nincorporate stroke semantics, positions, and shapes into the generation\nprocess. By utilizing tokenized stroke representation, our approach generates\nstrokes with high fidelity and facilitates novel applications, such as text or\nclass label conditioned generation and sketch completion. Comprehensive\nexperiments demonstrate our method surpasses existing state-of-the-art\ntechniques on the CreativeSketch dataset, underscoring its effectiveness.", "comment": "Project Page:\n  https://enigma-li.github.io/projects/VQ-SGen/VQ-SGen.html", "pdf_url": "http://arxiv.org/pdf/2411.16446v3", "cate": "cs.CV", "date": "2024-11-25", "updated": "2025-07-09"}
{"id": "2507.06554", "title": "SPEAR: Subset-sampled Performance Evaluation via Automated Ground Truth Generation for RAG", "authors": ["Zou Yuheng", "Wang Yiran", "Tian Yuzhu", "Zhu Min", "Huang Yanhua"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06554v1", "summary": "Retrieval-Augmented Generation (RAG) is a core approach for enhancing Large\nLanguage Models (LLMs), where the effectiveness of the retriever largely\ndetermines the overall response quality of RAG systems. Retrievers encompass a\nmultitude of hyperparameters that significantly impact performance outcomes and\ndemonstrate sensitivity to specific applications. Nevertheless, hyperparameter\noptimization entails prohibitively high computational expenses. Existing\nevaluation methods suffer from either prohibitive costs or disconnection from\ndomain-specific scenarios. This paper proposes SEARA (Subset sampling\nEvaluation for Automatic Retriever Assessment), which addresses evaluation data\nchallenges through subset sampling techniques and achieves robust automated\nretriever evaluation by minimal retrieval facts extraction and comprehensive\nretrieval metrics. Based on real user queries, this method enables fully\nautomated retriever evaluation at low cost, thereby obtaining optimal retriever\nfor specific business scenarios. We validate our method across classic RAG\napplications in rednote, including knowledge-based Q&A system and\nretrieval-based travel assistant, successfully obtaining scenario-specific\noptimal retrievers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06554v1", "cate": "cs.IR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2506.04133", "title": "TRiSM for Agentic AI: A Review of Trust, Risk, and Security Management in LLM-based Agentic Multi-Agent Systems", "authors": ["Shaina Raza", "Ranjan Sapkota", "Manoj Karkee", "Christos Emmanouilidis"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.04133v3", "summary": "Agentic AI systems, built upon large language models (LLMs) and deployed in\nmulti-agent configurations, are redefining intelligence, autonomy,\ncollaboration, and decision-making across enterprise and societal domains. This\nreview presents a structured analysis of \\textbf{Trust, Risk, and Security\nManagement (TRiSM)} in the context of LLM-based Agentic Multi-Agent Systems\n(AMAS). We begin by examining the conceptual foundations of Agentic AI and\nhighlight its architectural distinctions from traditional AI agents. We then\nadapt and extend the AI TRiSM framework for Agentic AI, structured around four\nkey pillars: Explainability, ModelOps, Security, Privacy and Governance, each\ncontextualized to the challenges of multi-agent LLM systems. A novel risk\ntaxonomy is proposed to capture the unique threats and vulnerabilities of\nAgentic AI, ranging from coordination failures to prompt-based adversarial\nmanipulation. To support practical assessment in Agentic AI works, we introduce\ntwo novel metrics: the Component Synergy Score (CSS), which quantifies the\nquality of inter-agent collaboration, and the Tool Utilization Efficacy (TUE),\nwhich evaluates the efficiency of tool use within agent workflows. We further\ndiscuss strategies for improving explainability in Agentic AI , as well as\napproaches to enhancing security and privacy through encryption, adversarial\nrobustness, and regulatory compliance. The review concludes with a research\nroadmap for the responsible development and deployment of Agentic AI, outlining\ncritical directions to align emerging systems with TRiSM principles for safe,\ntransparent, and accountable operation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.04133v3", "cate": "cs.AI", "date": "2025-06-04", "updated": "2025-07-09"}
{"id": "2507.06817", "title": "Designing Robust Software Sensors for Nonlinear Systems via Neural Networks and Adaptive Sliding Mode Control", "authors": ["Ayoub Farkane", "Mohamed Boutayeb", "Mustapha Oudani", "Mounir Ghogho"], "categories": ["math.DS", "cs.LG", "cs.NE", "math.OC"], "primary_category": "Subjects:       Dynamical Systems (math.DS)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE Transactions Journal", "url": "http://arxiv.org/abs/2507.06817v1", "summary": "Accurate knowledge of the state variables in a dynamical system is critical\nfor effective control, diagnosis, and supervision, especially when direct\nmeasurements of all states are infeasible. This paper presents a novel approach\nto designing software sensors for nonlinear dynamical systems expressed in\ntheir most general form. Unlike traditional model-based observers that rely on\nexplicit transformations or linearization, the proposed framework integrates\nneural networks with adaptive Sliding Mode Control (SMC) to design a robust\nstate observer under a less restrictive set of conditions. The learning process\nis driven by available sensor measurements, which are used to correct the\nobserver's state estimate. The training methodology leverages the system's\ngoverning equations as a physics-based constraint, enabling observer synthesis\nwithout access to ground-truth state trajectories. By employing a time-varying\ngain matrix dynamically adjusted by the neural network, the observer adapts in\nreal-time to system changes, ensuring robustness against noise, external\ndisturbances, and variations in system dynamics. Furthermore, we provide\nsufficient conditions to guarantee estimation error convergence, establishing a\ntheoretical foundation for the observer's reliability. The methodology's\neffectiveness is validated through simulations on challenging examples,\nincluding systems with non-differentiable dynamics and varying observability\nconditions. These examples, which are often problematic for conventional\ntechniques, serve to demonstrate the robustness and broad applicability of our\napproach. The results show rapid convergence and high accuracy, underscoring\nthe method's potential for addressing complex state estimation challenges in\nreal-world applications.", "comment": "Submitted to IEEE Transactions Journal", "pdf_url": "http://arxiv.org/pdf/2507.06817v1", "cate": "math.DS", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06418", "title": "PAST: A multimodal single-cell foundation model for histopathology and spatial transcriptomics in cancer", "authors": ["Changchun Yang", "Haoyang Li", "Yushuai Wu", "Yilan Zhang", "Yifeng Jiao", "Yu Zhang", "Rihan Huang", "Yuan Cheng", "Yuan Qi", "Xin Guo", "Xin Gao"], "categories": ["q-bio.QM", "cs.CV", "stat.AP"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06418v1", "summary": "While pathology foundation models have transformed cancer image analysis,\nthey often lack integration with molecular data at single-cell resolution,\nlimiting their utility for precision oncology. Here, we present PAST, a\npan-cancer single-cell foundation model trained on 20 million paired\nhistopathology images and single-cell transcriptomes spanning multiple tumor\ntypes and tissue contexts. By jointly encoding cellular morphology and gene\nexpression, PAST learns unified cross-modal representations that capture both\nspatial and molecular heterogeneity at the cellular level. This approach\nenables accurate prediction of single-cell gene expression, virtual molecular\nstaining, and multimodal survival analysis directly from routine pathology\nslides. Across diverse cancers and downstream tasks, PAST consistently exceeds\nthe performance of existing approaches, demonstrating robust generalizability\nand scalability. Our work establishes a new paradigm for pathology foundation\nmodels, providing a versatile tool for high-resolution spatial omics,\nmechanistic discovery, and precision cancer research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06418v1", "cate": "q-bio.QM", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.06517", "title": "SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers", "authors": ["Zicong Tang", "Shi Luohe", "Zuchao Li", "Baoyuan Qi", "Guoming Liu", "Lefei Zhang", "Ping Wang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by ACL 2025 main", "url": "http://arxiv.org/abs/2507.06517v1", "summary": "Large Language Models (LLMs) have achieved impressive accomplishments in\nrecent years. However, the increasing memory consumption of KV cache has\npossessed a significant challenge to the inference system. Eviction methods\nhave revealed the inherent redundancy within the KV cache, demonstrating its\npotential for reduction, particularly in deeper layers. However, KV cache\nreduction for shallower layers has been found to be insufficient. Based on our\nobservation that, the KV cache exhibits a high degree of similarity. Based on\nthis observation, we proposed a novel KV cache reduction method, SpindleKV,\nwhich balances both shallow and deep layers. For deep layers, we employ an\nattention weight based eviction method, while for shallow layers, we apply a\ncodebook based replacement approach which is learnt by similarity and merging\npolicy. Moreover, SpindleKV addressed the Grouped-Query Attention (GQA) dilemma\nfaced by other attention based eviction methods. Experiments on two common\nbenchmarks with three different LLMs shown that SpindleKV obtained better KV\ncache reduction effect compared to baseline methods, while preserving similar\nor even better model performance.", "comment": "Accepted by ACL 2025 main", "pdf_url": "http://arxiv.org/pdf/2507.06517v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06563", "title": "DS@GT at CheckThat! 2025: Exploring Retrieval and Reranking Pipelines for Scientific Claim Source Retrieval on Social Media Discourse", "authors": ["Jeanette Schofield", "Shuyu Tian", "Hoang Thanh Thanh Truong", "Maximilian Heil"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06563v1", "summary": "Social media users often make scientific claims without citing where these\nclaims come from, generating a need to verify these claims. This paper details\nwork done by the DS@GT team for CLEF 2025 CheckThat! Lab Task 4b Scientific\nClaim Source Retrieval which seeks to find relevant scientific papers based on\nimplicit references in tweets. Our team explored 6 different data augmentation\ntechniques, 7 different retrieval and reranking pipelines, and finetuned a\nbi-encoder. Achieving an MRR@5 of 0.58, our team ranked 16th out of 30 teams\nfor the CLEF 2025 CheckThat! Lab Task 4b, and improvement of 0.15 over the BM25\nbaseline of 0.43. Our code is available on Github at\nhttps://github.com/dsgt-arc/checkthat-2025-swd/tree/main/subtask-4b.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06563v1", "cate": "cs.IR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.02825", "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks", "authors": ["Yuxuan Zhu", "Tengjun Jin", "Yada Pruksachatkun", "Andy Zhang", "Shu Liu", "Sasha Cui", "Sayash Kapoor", "Shayne Longpre", "Kevin Meng", "Rebecca Weiss", "Fazl Barez", "Rahul Gupta", "Jwala Dhamala", "Jacob Merizian", "Mario Giulianelli", "Harry Coppock", "Cozmin Ududec", "Jasjeet Sekhon", "Jacob Steinhardt", "Antony Kellerman", "Sarah Schwettmann", "Matei Zaharia", "Ion Stoica", "Percy Liang", "Daniel Kang"], "categories": ["cs.AI", "A.1; I.2.m"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      39 pages, 15 tables, 6 figures", "url": "http://arxiv.org/abs/2507.02825v2", "summary": "Benchmarks are essential for quantitatively tracking progress in AI. As AI\nagents become increasingly capable, researchers and practitioners have\nintroduced agentic benchmarks to evaluate agents on complex, real-world tasks.\nThese benchmarks typically measure agent capabilities by evaluating task\noutcomes via specific reward designs. However, we show that many agentic\nbenchmarks have issues in task setup or reward design. For example, SWE-bench\nVerified uses insufficient test cases, while TAU-bench counts empty responses\nas successful. Such issues can lead to under- or overestimation of agents'\nperformance by up to 100% in relative terms. To make agentic evaluation\nrigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of\nguidelines that we synthesized from our benchmark-building experience, a survey\nof best practices, and previously reported issues. When applied to CVE-Bench, a\nbenchmark with a particularly complex evaluation design, ABC reduces the\nperformance overestimation by 33%.", "comment": "39 pages, 15 tables, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.02825v2", "cate": "cs.AI", "date": "2025-07-03", "updated": "2025-07-08"}
{"id": "2507.06844", "title": "Adaptive collaboration for online personalized distributed learning with heterogeneous clients", "authors": ["Constantin Philippenko", "Batiste Le Bars", "Kevin Scaman", "Laurent Massoulié"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      18 pages", "url": "http://arxiv.org/abs/2507.06844v1", "summary": "We study the problem of online personalized decentralized learning with $N$\nstatistically heterogeneous clients collaborating to accelerate local training.\nAn important challenge in this setting is to select relevant collaborators to\nreduce gradient variance while mitigating the introduced bias. To tackle this,\nwe introduce a gradient-based collaboration criterion, allowing each client to\ndynamically select peers with similar gradients during the optimization\nprocess. Our criterion is motivated by a refined and more general theoretical\nanalysis of the All-for-one algorithm, proved to be optimal in Even et al.\n(2022) for an oracle collaboration scheme. We derive excess loss upper-bounds\nfor smooth objective functions, being either strongly convex, non-convex, or\nsatisfying the Polyak-Lojasiewicz condition; our analysis reveals that the\nalgorithm acts as a variance reduction method where the speed-up depends on a\nsufficient variance. We put forward two collaboration methods instantiating the\nproposed general schema; and we show that one variant preserves the optimality\nof All-for-one. We validate our results with experiments on synthetic and real\ndatasets.", "comment": "18 pages", "pdf_url": "http://arxiv.org/pdf/2507.06844v1", "cate": "stat.ML", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06867", "title": "Conformal Prediction for Long-Tailed Classification", "authors": ["Tiffany Ding", "Jean-Baptiste Fermanian", "Joseph Salmon"], "categories": ["stat.ML", "cs.CV", "cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06867v1", "summary": "Many real-world classification problems, such as plant identification, have\nextremely long-tailed class distributions. In order for prediction sets to be\nuseful in such settings, they should (i) provide good class-conditional\ncoverage, ensuring that rare classes are not systematically omitted from the\nprediction sets, and (ii) be a reasonable size, allowing users to easily verify\ncandidate labels. Unfortunately, existing conformal prediction methods, when\napplied to the long-tailed setting, force practitioners to make a binary choice\nbetween small sets with poor class-conditional coverage or sets with very good\nclass-conditional coverage but that are extremely large. We propose methods\nwith guaranteed marginal coverage that smoothly trade off between set size and\nclass-conditional coverage. First, we propose a conformal score function,\nprevalence-adjusted softmax, that targets a relaxed notion of class-conditional\ncoverage called macro-coverage. Second, we propose a label-weighted conformal\nprediction method that allows us to interpolate between marginal and\nclass-conditional conformal prediction. We demonstrate our methods on Pl@ntNet\nand iNaturalist, two long-tailed image datasets with 1,081 and 8,142 classes,\nrespectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06867v1", "cate": "stat.ML", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06539", "title": "Large Language Model for Extracting Complex Contract Information in Industrial Scenes", "authors": ["Yunyang Cao", "Yanjun Li", "Silong Dai"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06539v1", "summary": "This paper proposes a high-quality dataset construction method for complex\ncontract information extraction tasks in industrial scenarios and fine-tunes a\nlarge language model based on this dataset. Firstly, cluster analysis is\nperformed on industrial contract texts, and GPT-4 and GPT-3.5 are used to\nextract key information from the original contract data, obtaining high-quality\ndata annotations. Secondly, data augmentation is achieved by constructing new\ntexts, and GPT-3.5 generates unstructured contract texts from randomly combined\nkeywords, improving model robustness. Finally, the large language model is\nfine-tuned based on the high-quality dataset. Experimental results show that\nthe model achieves excellent overall performance while ensuring high field\nrecall and precision and considering parsing efficiency. LoRA, data balancing,\nand data augmentation effectively enhance model accuracy and robustness. The\nproposed method provides a novel and efficient solution for industrial contract\ninformation extraction tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06539v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06596", "title": "Impacts of Mainstream-Driven Algorithms on Recommendations for Children Across Domains: A Reproducibility Study", "authors": ["Robin Ungruh", "Alejandro Bellogín", "Dominik Kowald", "Maria Soledad Pera"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Preprint of accepted RecSys 2025 contribution", "url": "http://arxiv.org/abs/2507.06596v1", "summary": "Children are often exposed to items curated by recommendation algorithms.\nYet, research seldom considers children as a user group, and when it does, it\nis anchored on datasets where children are underrepresented, risking\noverlooking their interests, favoring those of the majority, i.e., mainstream\nusers. Recently, Ungruh et al. demonstrated that children's consumption\npatterns and preferences differ from those of mainstream users, resulting in\ninconsistent recommendation algorithm performance and behavior for this user\ngroup. These findings, however, are based on two datasets with a limited child\nuser sample. We reproduce and replicate this study on a wider range of datasets\nin the movie, music, and book domains, uncovering interaction patterns and\naspects of child-recommender interactions consistent across domains, as well as\nthose specific to some user samples in the data. We also extend insights from\nthe original study with popularity bias metrics, given the interpretation of\nresults from the original study. With this reproduction and extension, we\nuncover consumption patterns and differences between age groups stemming from\nintrinsic differences between children and others, and those unique to specific\ndatasets or domains.", "comment": "Preprint of accepted RecSys 2025 contribution", "pdf_url": "http://arxiv.org/pdf/2507.06596v1", "cate": "cs.IR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.03916", "title": "Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models", "authors": ["Yifan Jiang", "Yibo Xue", "Yukun Kang", "Pin Zheng", "Jian Peng", "Feiran Wu", "Changliang Xu"], "categories": ["cs.AI", "cs.CV", "68T01"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Appendix at: this https URL", "url": "http://arxiv.org/abs/2507.03916v2", "summary": "Slide animations, such as fade-in, fly-in, and wipe, are critical for\naudience engagement, efficient information delivery, and vivid visual\nexpression. However, most AI-driven slide-generation tools still lack native\nanimation support, and existing vision-language models (VLMs) struggle with\nanimation tasks due to the absence of public datasets and limited\ntemporal-reasoning capabilities. To address this gap, we release the first\npublic dataset for slide-animation modeling: 12,000 triplets of\nnatural-language descriptions, animation JSON files, and rendered videos,\ncollectively covering every built-in PowerPoint effect. Using this resource, we\nfine-tune Qwen-2.5-VL-7B with Low-Rank Adaptation (LoRA) and achieve consistent\nimprovements over GPT-4.1 and Gemini-2.5-Pro in BLEU-4, ROUGE-L, SPICE, and our\nCoverage-Order-Detail Assessment (CODA) metric, which evaluates action\ncoverage, temporal order, and detail fidelity. On a manually created test set\nof slides, the LoRA model increases BLEU-4 by around 60%, ROUGE-L by 30%, and\nshows significant improvements in CODA-detail. This demonstrates that low-rank\nadaptation enables reliable temporal reasoning and generalization beyond\nsynthetic data. Overall, our dataset, LoRA-enhanced model, and CODA metric\nprovide a rigorous benchmark and foundation for future research on VLM-based\ndynamic slide generation.", "comment": "Appendix at:\n  https://github.com/PAMPAS-Lab/ANA-PPT-Anamation/blob/main/Appendix.pdf", "pdf_url": "http://arxiv.org/pdf/2507.03916v2", "cate": "cs.AI", "date": "2025-07-05", "updated": "2025-07-09"}
{"id": "2507.06921", "title": "Distribution-free inference for LightGBM and GLM with Tweedie loss", "authors": ["Alokesh Manna", "Aditya Vikram Sett", "Dipak K. Dey", "Yuwen Gu", "Elizabeth D. Schifano", "Jichao He"], "categories": ["stat.ML", "cs.LG", "Application to insurance data, Methodology"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06921v1", "summary": "Prediction uncertainty quantification is a key research topic in recent years\nscientific and business problems. In insurance industries\n(\\cite{parodi2023pricing}), assessing the range of possible claim costs for\nindividual drivers improves premium pricing accuracy. It also enables insurers\nto manage risk more effectively by accounting for uncertainty in accident\nlikelihood and severity. In the presence of covariates, a variety of\nregression-type models are often used for modeling insurance claims, ranging\nfrom relatively simple generalized linear models (GLMs) to regularized GLMs to\ngradient boosting models (GBMs). Conformal predictive inference has arisen as a\npopular distribution-free approach for quantifying predictive uncertainty under\nrelatively weak assumptions of exchangeability, and has been well studied under\nthe classic linear regression setting. In this work, we propose new\nnon-conformity measures for GLMs and GBMs with GLM-type loss. Using regularized\nTweedie GLM regression and LightGBM with Tweedie loss, we demonstrate conformal\nprediction performance with these non-conformity measures in insurance claims\ndata. Our simulation results favor the use of locally weighted Pearson\nresiduals for LightGBM over other methods considered, as the resulting\nintervals maintained the nominal coverage with the smallest average width.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06921v1", "cate": "stat.ML", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2007.14245", "title": "Bayesian Multi-Scale Neural Network for Crowd Counting", "authors": ["Abhinav Sagar"], "categories": ["cs.CV", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2007.14245v4", "summary": "Crowd counting is a challenging yet critical task in computer vision with\napplications ranging from public safety to urban planning. Recent advances\nusing Convolutional Neural Networks (CNNs) that estimate density maps have\nshown significant success. However, accurately counting individuals in highly\ncongested scenes remains an open problem due to severe occlusions, scale\nvariations, and perspective distortions, where people appear at drastically\ndifferent sizes across the image. In this work, we propose a novel deep\nlearning architecture that effectively addresses these challenges. Our network\nintegrates a ResNet-based feature extractor for capturing rich hierarchical\nrepresentations, followed by a downsampling block employing dilated\nconvolutions to preserve spatial resolution while expanding the receptive\nfield. An upsampling block using transposed convolutions reconstructs the\nhigh-resolution density map. Central to our architecture is a novel\nPerspective-aware Aggregation Module (PAM) designed to enhance robustness to\nscale and perspective variations by adaptively aggregating multi-scale\ncontextual information. We detail the training procedure, including the loss\nfunctions and optimization strategies used. Our method is evaluated on three\nwidely used benchmark datasets using Mean Absolute Error (MAE) and Mean Squared\nError (MSE) as evaluation metrics. Experimental results demonstrate that our\nmodel achieves superior performance compared to existing state-of-the-art\nmethods. Additionally, we incorporate principled Bayesian inference techniques\nto provide uncertainty estimates along with the crowd count predictions,\noffering a measure of confidence in the model's outputs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2007.14245v4", "cate": "cs.CV", "date": "2020-07-11", "updated": "2025-07-09"}
{"id": "2507.06571", "title": "Enhancing Food-Domain Question Answering with a Multimodal Knowledge Graph: Hybrid QA Generation and Diversity Analysis", "authors": ["Srihari K B", "Pushpak Bhattacharyya"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06571v1", "summary": "We propose a unified food-domain QA framework that combines a large-scale\nmultimodal knowledge graph (MMKG) with generative AI. Our MMKG links 13,000\nrecipes, 3,000 ingredients, 140,000 relations, and 14,000 images. We generate\n40,000 QA pairs using 40 templates and LLaVA/DeepSeek augmentation. Joint\nfine-tuning of Meta LLaMA 3.1-8B and Stable Diffusion 3.5-Large improves\nBERTScore by 16.2\\%, reduces FID by 37.8\\%, and boosts CLIP alignment by\n31.1\\%. Diagnostic analyses-CLIP-based mismatch detection (35.2\\% to 7.3\\%) and\nLLaVA-driven hallucination checks-ensure factual and visual fidelity. A hybrid\nretrieval-generation strategy achieves 94.1\\% accurate image reuse and 85\\%\nadequacy in synthesis. Our results demonstrate that structured knowledge and\nmultimodal generation together enhance reliability and diversity in food QA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06571v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06877", "title": "CDC: Causal Domain Clustering for Multi-Domain Recommendation", "authors": ["Huishi Luo", "Yiqing Wu", "Yiwen Chen", "Fuzhen Zhuang", "Deqing Wang"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted at SIGIR 2025", "url": "http://arxiv.org/abs/2507.06877v1", "summary": "Multi-domain recommendation leverages domain-general knowledge to improve\nrecommendations across several domains. However, as platforms expand to dozens\nor hundreds of scenarios, training all domains in a unified model leads to\nperformance degradation due to significant inter-domain differences. Existing\ndomain grouping methods, based on business logic or data similarities, often\nfail to capture the true transfer relationships required for optimal grouping.\nTo effectively cluster domains, we propose Causal Domain Clustering (CDC). CDC\nmodels domain transfer patterns within a large number of domains using two\ndistinct effects: the Isolated Domain Affinity Matrix for modeling\nnon-interactive domain transfers, and the Hybrid Domain Affinity Matrix for\nconsidering dynamic domain synergy or interference under joint training. To\nintegrate these two transfer effects, we introduce causal discovery to\ncalculate a cohesion-based coefficient that adaptively balances their\ncontributions. A Co-Optimized Dynamic Clustering algorithm iteratively\noptimizes target domain clustering and source domain selection for training.\nCDC significantly enhances performance across over 50 domains on public\ndatasets and in industrial settings, achieving a 4.9% increase in online eCPM.\nCode is available at\nhttps://github.com/Chrissie-Law/Causal-Domain-Clustering-for-Multi-Domain-Recommendation", "comment": "Accepted at SIGIR 2025", "pdf_url": "http://arxiv.org/pdf/2507.06877v1", "cate": "cs.IR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.04431", "title": "MedGellan: LLM-Generated Medical Guidance to Support Physicians", "authors": ["Debodeep Banerjee", "Burcu Sayin", "Stefano Teso", "Andrea Passerini"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04431v2", "summary": "Medical decision-making is a critical task, where errors can result in\nserious, potentially life-threatening consequences. While full automation\nremains challenging, hybrid frameworks that combine machine intelligence with\nhuman oversight offer a practical alternative. In this paper, we present\nMedGellan, a lightweight, annotation-free framework that uses a Large Language\nModel (LLM) to generate clinical guidance from raw medical records, which is\nthen used by a physician to predict diagnoses. MedGellan uses a\nBayesian-inspired prompting strategy that respects the temporal order of\nclinical data. Preliminary experiments show that the guidance generated by the\nLLM with MedGellan improves diagnostic performance, particularly in recall and\n$F_1$ score.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04431v2", "cate": "cs.AI", "date": "2025-07-06", "updated": "2025-07-08"}
{"id": "2507.06929", "title": "Machine-Learned Force Fields for Lattice Dynamics at Coupled-Cluster Level Accuracy", "authors": ["Sita Schönbauer", "Johanna P. Carbone", "Andreas Grüneis"], "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "primary_category": "Subjects:       Materials Science (cond-mat.mtrl-sci)", "pdf_link": null, "comments": "Comments:      22 pages, 12 figures", "url": "http://arxiv.org/abs/2507.06929v1", "summary": "We investigate Machine-Learned Force Fields (MLFFs) trained on approximate\nDensity Functional Theory (DFT) and Coupled Cluster (CC) level potential energy\nsurfaces for the carbon diamond and lithium hydride solids. We assess the\naccuracy and precision of the MLFFs by calculating phonon dispersions and\nvibrational densities of states (VDOS) that are compared to experiment and\nreference ab initio results. To overcome limitations from long-range effects\nand the lack of atomic forces in the CC training data, a delta-learning\napproach based on the difference between CC and DFT results is explored.\nCompared to DFT, MLFFs trained on CC theory yield higher vibrational\nfrequencies for optical modes, agreeing better with experiment. Furthermore,\nthe MLFFs are used to estimate anharmonic effects on the VDOS of lithium\nhydride at the level of CC theory.", "comment": "22 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.06929v1", "cate": "cond-mat.mtrl-sci", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2304.00050", "title": "Batch Normalization in Cytometry Data by kNN-Graph Preservation", "authors": ["Muhammad S. Battikh", "Artem Lensky"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 6 figures", "url": "http://arxiv.org/abs/2304.00050v4", "summary": "Batch effects in high-dimensional Cytometry by Time-of-Flight (CyTOF) data\npose a challenge for comparative analysis across different experimental\nconditions or time points. Traditional batch normalization methods may fail to\npreserve the complex topological structures inherent in cellular populations.\nIn this paper, we present a residual neural network-based method for point set\nregistration specifically tailored to address batch normalization in CyTOF data\nwhile preserving the topological structure of cellular populations. By viewing\nthe alignment problem as the movement of cells sampled from a target\ndistribution along a regularized displacement vector field, similar to coherent\npoint drift (CPD), our approach introduces a Jacobian-based cost function and\ngeometry-aware statistical distances to ensure local topology preservation. We\nprovide justification for the k-Nearest Neighbour (kNN) graph preservation of\nthe target data when the Jacobian cost is applied, which is crucial for\nmaintaining biological relationships between cells. Furthermore, we introduce a\nstochastic approximation for high-dimensional registration, making alignment\nfeasible for the high-dimensional space of CyTOF data. Our method is\ndemonstrated on high-dimensional CyTOF dataset, effectively aligning\ndistributions of cells while preserving the kNN-graph structure. This enables\naccurate batch normalization, facilitating reliable comparative analysis in\nbiomedical research.", "comment": "12 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2304.00050v4", "cate": "cs.CV", "date": "2023-03-31", "updated": "2025-07-09"}
{"id": "2507.06622", "title": "FuDoBa: Fusing Document and Knowledge Graph-based Representations with Bayesian Optimisation", "authors": ["Boshko Koloski", "Senja Pollak", "Roberto Navigli", "Blaž Škrlj"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06622v1", "summary": "Building on the success of Large Language Models (LLMs), LLM-based\nrepresentations have dominated the document representation landscape, achieving\ngreat performance on the document embedding benchmarks. However, the\nhigh-dimensional, computationally expensive embeddings from LLMs tend to be\neither too generic or inefficient for domain-specific applications. To address\nthese limitations, we introduce FuDoBa a Bayesian optimisation-based method\nthat integrates LLM-based embeddings with domain-specific structured knowledge,\nsourced both locally and from external repositories like WikiData. This fusion\nproduces low-dimensional, task-relevant representations while reducing training\ncomplexity and yielding interpretable early-fusion weights for enhanced\nclassification performance. We demonstrate the effectiveness of our approach on\nsix datasets in two domains, showing that when paired with robust AutoML-based\nclassifiers, our proposed representation learning approach performs on par\nwith, or surpasses, those produced solely by the proprietary LLM-based\nembedding baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06622v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.07064", "title": "Boosting Parameter Efficiency in LLM-Based Recommendation through Sophisticated Pruning", "authors": ["Shanle Zheng", "Keqin Bao", "Jizhi Zhang", "Yang Zhang", "Fuli Feng", "Xiangnan He"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07064v1", "summary": "LLM-based recommender systems have made significant progress; however, the\ndeployment cost associated with the large parameter volume of LLMs still\nhinders their real-world applications. This work explores parameter pruning to\nimprove parameter efficiency while maintaining recommendation quality, thereby\nenabling easier deployment. Unlike existing approaches that focus primarily on\ninter-layer redundancy, we uncover intra-layer redundancy within components\nsuch as self-attention and MLP modules. Building on this analysis, we propose a\nmore fine-grained pruning approach that integrates both intra-layer and\nlayer-wise pruning. Specifically, we introduce a three-stage pruning strategy\nthat progressively prunes parameters at different levels and parts of the\nmodel, moving from intra-layer to layer-wise pruning, or from width to depth.\nEach stage also includes a performance restoration step using distillation\ntechniques, helping to strike a balance between performance and parameter\nefficiency. Empirical results demonstrate the effectiveness of our approach:\nacross three datasets, our models achieve an average of 88% of the original\nmodel's performance while pruning more than 95% of the non-embedding\nparameters. This underscores the potential of our method to significantly\nreduce resource requirements without greatly compromising recommendation\nquality. Our code will be available at: https://github.com/zheng-sl/PruneRec", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07064v1", "cate": "cs.IR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.05297", "title": "Fuzzy Classification Aggregation for a Continuum of Agents", "authors": ["Zijun Meng"], "categories": ["cs.AI", "econ.TH"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05297v2", "summary": "We prove that any optimal, independent, and zero unanimous fuzzy\nclassification aggregation function of a continuum of individual\nclassifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted\narithmetic mean.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05297v2", "cate": "cs.AI", "date": "2025-07-06", "updated": "2025-07-09"}
{"id": "2507.06961", "title": "Off-Policy Evaluation Under Nonignorable Missing Data", "authors": ["Han Wang", "Yang Xu", "Wenbin Lu", "Rui Song"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06961v1", "summary": "Off-Policy Evaluation (OPE) aims to estimate the value of a target policy\nusing offline data collected from potentially different policies. In real-world\napplications, however, logged data often suffers from missingness. While OPE\nhas been extensively studied in the literature, a theoretical understanding of\nhow missing data affects OPE results remains unclear. In this paper, we\ninvestigate OPE in the presence of monotone missingness and theoretically\ndemonstrate that the value estimates remain unbiased under ignorable\nmissingness but can be biased under nonignorable (informative) missingness. To\nretain the consistency of value estimation, we propose an inverse probability\nweighted value estimator and conduct statistical inference to quantify the\nuncertainty of the estimates. Through a series of numerical experiments, we\nempirically demonstrate that our proposed estimator yields a more reliable\nvalue inference under missing data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06961v1", "cate": "stat.ML", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2307.14770", "title": "3DPortraitGAN: Learning One-Quarter Headshot 3D GANs from a Single-View Portrait Dataset with Diverse Body Poses", "authors": ["Yiqian Wu", "Hao Xu", "Xiangjun Tang", "Yue Shangguan", "Hongbo Fu", "Xiaogang Jin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for publication in IEEE Transactions on Circuits and Systems for Video Technology", "url": "http://arxiv.org/abs/2307.14770v3", "summary": "3D-aware face generators are typically trained on 2D real-life face image\ndatasets that primarily consist of near-frontal face data, and as such, they\nare unable to construct one-quarter headshot 3D portraits with complete head,\nneck, and shoulder geometry. Two reasons account for this issue: First,\nexisting facial recognition methods struggle with extracting facial data\ncaptured from large camera angles or back views. Second, it is challenging to\nlearn a distribution of 3D portraits covering the one-quarter headshot region\nfrom single-view data due to significant geometric deformation caused by\ndiverse body poses. To this end, we first create the dataset\n360{\\deg}-Portrait-HQ (360{\\deg}PHQ for short) which consists of high-quality\nsingle-view real portraits annotated with a variety of camera parameters (the\nyaw angles span the entire 360{\\deg} range) and body poses. We then propose\n3DPortraitGAN, the first 3D-aware one-quarter headshot portrait generator that\nlearns a canonical 3D avatar distribution from the 360{\\deg}PHQ dataset with\nbody pose self-learning. Our model can generate view-consistent portrait images\nfrom all camera angles with a canonical one-quarter headshot 3D representation.\nOur experiments show that the proposed framework can accurately predict\nportrait body poses and generate view-consistent, realistic portrait images\nwith complete geometry from all camera angles.", "comment": "Accepted for publication in IEEE Transactions on Circuits and Systems\n  for Video Technology", "pdf_url": "http://arxiv.org/pdf/2307.14770v3", "cate": "cs.CV", "date": "2023-07-27", "updated": "2025-07-09"}
{"id": "2507.06774", "title": "Checklist Engineering Empowers Multilingual LLM Judges", "authors": ["Mohammad Ghiasvand Mohammadkhani", "Hamid Beigy"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06774v1", "summary": "Automated text evaluation has long been a central issue in Natural Language\nProcessing (NLP). Recently, the field has shifted toward using Large Language\nModels (LLMs) as evaluators-a trend known as the LLM-as-a-Judge paradigm. While\npromising and easily adaptable across tasks, this approach has seen limited\nexploration in multilingual contexts. Existing multilingual studies often rely\non proprietary models or require extensive training data for fine-tuning,\nraising concerns about cost, time, and efficiency. In this paper, we propose\nChecklist Engineering based LLM-as-a-Judge (CE-Judge), a training-free\nframework that uses checklist intuition for multilingual evaluation with an\nopen-source model. Experiments across multiple languages and three benchmark\ndatasets, under both pointwise and pairwise settings, show that our method\ngenerally surpasses the baselines and performs on par with the GPT-4o model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06774v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06838", "title": "Shifting from Ranking to Set Selection for Retrieval Augmented Generation", "authors": ["Dahyun Lee", "Yongrae Jo", "Haeju Park", "Moontae Lee"], "categories": ["cs.CL", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025 Oral", "url": "http://arxiv.org/abs/2507.06838v1", "summary": "Retrieval in Retrieval-Augmented Generation(RAG) must ensure that retrieved\npassages are not only individually relevant but also collectively form a\ncomprehensive set. Existing approaches primarily rerank top-k passages based on\ntheir individual relevance, often failing to meet the information needs of\ncomplex queries in multi-hop question answering. In this work, we propose a\nset-wise passage selection approach and introduce SETR, which explicitly\nidentifies the information requirements of a query through Chain-of-Thought\nreasoning and selects an optimal set of passages that collectively satisfy\nthose requirements. Experiments on multi-hop RAG benchmarks show that SETR\noutperforms both proprietary LLM-based rerankers and open-source baselines in\nterms of answer correctness and retrieval quality, providing an effective and\nefficient alternative to traditional rerankers in RAG systems. The code is\navailable at https://github.com/LGAI-Research/SetR", "comment": "Accepted to ACL 2025 Oral", "pdf_url": "http://arxiv.org/pdf/2507.06838v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.05519", "title": "Modeling (Deontic) Modal Operators With the s(CASP) Goal-directed Predicate Answer Set Programming System", "authors": ["Gopal Gupta", "Abhiramon Rajasekharan", "Alexis R. Tudor", "Elmer Salazar", "Joaquín Arias"], "categories": ["cs.AI", "cs.LO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05519v2", "summary": "We consider the problem of implementing deontic modal logic. We show how\n(deontic) modal operators can be expressed elegantly using default negation\n(negation-as-failure) and strong negation present in answer set programming\n(ASP). We propose using global constraints of ASP to represent obligations and\nimpermissibilities of deontic modal logic. We show that our proposed\nrepresentation results in the various paradoxes of deontic modal logic being\nelegantly resolved.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05519v2", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-09"}
{"id": "2507.07041", "title": "Non-Asymptotic Analysis of Online Local Private Learning with SGD", "authors": ["Enze Shi", "Jinhan Xie", "Bei Jiang", "Linglong Kong", "Xuming He"], "categories": ["stat.ME", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07041v1", "summary": "Differentially Private Stochastic Gradient Descent (DP-SGD) has been widely\nused for solving optimization problems with privacy guarantees in machine\nlearning and statistics. Despite this, a systematic non-asymptotic convergence\nanalysis for DP-SGD, particularly in the context of online problems and local\ndifferential privacy (LDP) models, remains largely elusive. Existing\nnon-asymptotic analyses have focused on non-private optimization methods, and\nhence are not applicable to privacy-preserving optimization problems. This work\ninitiates the analysis to bridge this gap and opens the door to non-asymptotic\nconvergence analysis of private optimization problems. A general framework is\ninvestigated for the online LDP model in stochastic optimization problems. We\nassume that sensitive information from individuals is collected sequentially\nand aim to estimate, in real-time, a static parameter that pertains to the\npopulation of interest. Most importantly, we conduct a comprehensive\nnon-asymptotic convergence analysis of the proposed estimators in finite-sample\nsituations, which gives their users practical guidelines regarding the effect\nof various hyperparameters, such as step size, parameter dimensions, and\nprivacy budgets, on convergence rates. Our proposed estimators are validated in\nthe theoretical and practical realms by rigorous mathematical derivations and\ncarefully constructed numerical experiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07041v1", "cate": "stat.ME", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2310.11482", "title": "Enhancing Plasticity for First Session Adaptation Continual Learning", "authors": ["Imad Eddine Marouf", "Subhankar Roy", "Stéphane Lathuilière", "Enzo Tartaglione"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at CoLLAs 2025, 9 pages, 4 figures", "url": "http://arxiv.org/abs/2310.11482v3", "summary": "The integration of large pre-trained models (PTMs) into Class-Incremental\nLearning (CIL) has facilitated the development of computationally efficient\nstrategies such as First-Session Adaptation (FSA), which fine-tunes the model\nsolely on the first task while keeping it frozen for subsequent tasks. Although\neffective in homogeneous task sequences, these approaches struggle when faced\nwith the heterogeneity of real-world task distributions. We introduce\nPlasticity-Enhanced Test-Time Adaptation in Class-Incremental Learning\n(PLASTIC), a method that reinstates plasticity in CIL while preserving model\nstability. PLASTIC leverages Test-Time Adaptation (TTA) by dynamically\nfine-tuning LayerNorm parameters on unlabeled test data, enabling adaptability\nto evolving tasks and improving robustness against data corruption. To prevent\nTTA-induced model divergence and maintain stable learning across tasks, we\nintroduce a teacher-student distillation framework, ensuring that adaptation\nremains controlled and generalizable. Extensive experiments across multiple\nbenchmarks demonstrate that PLASTIC consistently outperforms both conventional\nand state-of-the-art PTM-based CIL approaches, while also exhibiting inherent\nrobustness to data corruptions. Code is available at:\nhttps://github.com/IemProg/PLASTIC.", "comment": "Accepted at CoLLAs 2025, 9 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2310.11482v3", "cate": "cs.CV", "date": "2023-10-17", "updated": "2025-07-08"}
{"id": "2507.06829", "title": "Adaptive Termination for Multi-round Parallel Reasoning: An Universal Semantic Entropy-Guided Framework", "authors": ["Zenan Xu", "Zexuan Qiu", "Guanhua Huang", "Kun Li", "Siheng Li", "Chenchen Zhang", "Kejiao Li", "Qi Yi", "Yuhao Jiang", "Bo Zhou", "Fengzong Lian", "Zhanhui Kang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      13 pages, 5 fiures", "url": "http://arxiv.org/abs/2507.06829v1", "summary": "Recent advances in large language models (LLMs) have accelerated progress\ntoward artificial general intelligence, with inference-time scaling emerging as\na key technique. Contemporary approaches leverage either sequential reasoning\n(iteratively extending chains of thought) or parallel reasoning (generating\nmultiple solutions simultaneously) to scale inference. However, both paradigms\nface fundamental limitations: sequential scaling typically relies on arbitrary\ntoken budgets for termination, leading to inefficiency or premature cutoff;\nwhile parallel scaling often lacks coordination among parallel branches and\nrequires intrusive fine-tuning to perform effectively. In light of these\nchallenges, we aim to design a flexible test-time collaborative inference\nframework that exploits the complementary strengths of both sequential and\nparallel reasoning paradigms. Towards this goal, the core challenge lies in\ndeveloping an efficient and accurate intrinsic quality metric to assess model\nresponses during collaborative inference, enabling dynamic control and early\ntermination of the reasoning trace. To address this challenge, we introduce\nsemantic entropy (SE), which quantifies the semantic diversity of parallel\nmodel responses and serves as a robust indicator of reasoning quality due to\nits strong negative correlation with accuracy...", "comment": "13 pages, 5 fiures", "pdf_url": "http://arxiv.org/pdf/2507.06829v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2506.23090", "title": "Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems", "authors": ["Langming Liu", "Wanyu Wang", "Chi Zhang", "Bo Li", "Hongzhi Yin", "Xuetao Wei", "Wenbo Su", "Bo Zheng", "Xiangyu Zhao"], "categories": ["cs.IR", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      KDD 2025", "url": "http://arxiv.org/abs/2506.23090v2", "summary": "Online advertising in recommendation platforms has gained significant\nattention, with a predominant focus on channel recommendation and budget\nallocation strategies. However, current offline reinforcement learning (RL)\nmethods face substantial challenges when applied to sparse advertising\nscenarios, primarily due to severe overestimation, distributional shifts, and\noverlooking budget constraints. To address these issues, we propose MTORL, a\nnovel multi-task offline RL model that targets two key objectives. First, we\nestablish a Markov Decision Process (MDP) framework specific to the nuances of\nadvertising. Then, we develop a causal state encoder to capture dynamic user\ninterests and temporal dependencies, facilitating offline RL through\nconditional sequence modeling. Causal attention mechanisms are introduced to\nenhance user sequence representations by identifying correlations among causal\nstates. We employ multi-task learning to decode actions and rewards,\nsimultaneously addressing channel recommendation and budget allocation.\nNotably, our framework includes an automated system for integrating these tasks\ninto online advertising. Extensive experiments on offline and online\nenvironments demonstrate MTORL's superiority over state-of-the-art methods.", "comment": "KDD 2025", "pdf_url": "http://arxiv.org/pdf/2506.23090v2", "cate": "cs.IR", "date": "2025-06-29", "updated": "2025-07-09"}
{"id": "2507.05791", "title": "GTA1: GUI Test-time Scaling Agent", "authors": ["Yan Yang", "Dongxu Li", "Yutong Dai", "Yuhao Yang", "Ziyang Luo", "Zirui Zhao", "Zhiyuan Hu", "Junzhe Huang", "Amrita Saha", "Zeyuan Chen", "Ran Xu", "Liyuan Pan", "Caiming Xiong", "Junnan Li"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05791v2", "summary": "Graphical user interface (GUI) agents autonomously operate across platforms\n(e.g., Linux) to complete tasks by interacting with visual elements.\nSpecifically, a user instruction is decomposed into a sequence of action\nproposals, each corresponding to an interaction with the GUI. After each\naction, the agent observes the updated GUI environment to plan the next step.\nHowever, two main challenges arise: i) resolving ambiguity in task planning\n(i.e., the action proposal sequence), where selecting an appropriate plan is\nnon-trivial, as many valid ones may exist; ii) accurately grounding actions in\ncomplex and high-resolution interfaces, i.e., precisely interacting with visual\ntargets.\n  This paper investigates the two aforementioned challenges with our GUI\nTest-time Scaling Agent, namely GTA1. First, to select the most appropriate\naction proposal, we introduce a test-time scaling method. At each step, we\nsample multiple candidate action proposals and leverage a judge model to\nevaluate and select the most suitable one. It trades off computation for better\ndecision quality by concurrent sampling, shortening task execution steps, and\nimproving overall performance. Second, we propose a model that achieves\nimproved accuracy when grounding the selected action proposal to its\ncorresponding visual elements. Our key insight is that reinforcement learning\n(RL) facilitates visual grounding through inherent objective alignments,\nrewarding successful clicks on interface elements.\n  Experimentally, our method establishes state-of-the-art performance across\ndiverse benchmarks. For example, GTA1-7B achieves 50.1%, 92.4%, and 67.7%\naccuracies on Screenspot-Pro, Screenspot-V2, and OSWorld-G, respectively. When\npaired with a planner applying our test-time scaling strategy, it exhibits\nstate-of-the-art agentic performance (e.g., 45.2% task success rate on\nOSWorld). We open-source our code and models here.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05791v2", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2507.07050", "title": "Discrete Diffusion Models for Language Generation", "authors": ["Ashen Weligalle"], "categories": ["cs.CL", "cs.LG", "stat.ML", "68T50 (Primary) 68Q32, 60J27 (Secondary)", "G.3"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      pdfLaTeX, 69 pages with 21 figures, Licentiate Thesis", "url": "http://arxiv.org/abs/2507.07050v1", "summary": "Diffusion models have emerged as a powerful class of generative models,\nachieving state-of-the-art results in continuous data domains such as image and\nvideo generation. Their core mechanism involves a forward diffusion process\nthat gradually transforms structured data into a Gaussian-like distribution,\nfollowed by a learned reverse process to reconstruct the data. While successful\nin continuous modalities, applying this framework to discrete data-particularly\nnatural language-remains challenging due to token dependency complexities and\nthe lack of a defined generation order.This thesis investigates the feasibility\nand performance of discrete diffusion models for natural language generation.\nSpecifically, we evaluate the Discrete Denoising Diffusion Probabilistic Model\n(D3PM) and compare it with traditional autoregressive (AR) language models. To\nassess generative performance, we use Bits Per Token (BPT), Negative\nLog-Likelihood (NLL), Perplexity (PPL), and Batch Processing Speed.\n  Results show the best-performing D3PM model achieves a BPT of 5.72, with a\nmean of 8.05. The AR model outperforms in compression with a lower mean BPT of\n4.59, but D3PM achieves higher processing speed, reaching up to 3.97 batches\nper sec., indicating potential for parallel generation.All evaluations were\nconducted under consistent conditions-generating 100,000 tokens per model with\na fixed batch size of four-for fair comparison. This research presents a\ndetailed analysis of diffusion-based vs. autoregressive models, highlighting\ntrade-offs in generative quality and efficiency. Findings emphasize both the\npromise and limitations of diffusion models for discrete data, supporting\nfuture work in non-autoregressive language generation.", "comment": "pdfLaTeX, 69 pages with 21 figures, Licentiate Thesis", "pdf_url": "http://arxiv.org/pdf/2507.07050v1", "cate": "cs.CL", "date": "2025-07-02", "updated": "2025-07-02"}
{"id": "2311.18564", "title": "Leveraging Local Patch Alignment to Seam-cutting for Large Parallax Image Stitching", "authors": ["Tianli Liao", "Chenyang Zhao", "Lei Li", "Heling Cao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2311.18564v3", "summary": "Seam cutting has shown significant effectiveness in the composition phase of\nimage stitching, particularly for scenarios involving parallax. However,\nconventional implementations typically position seam-cutting as a downstream\nprocess contingent upon successful image alignment. This approach inherently\nassumes the existence of locally aligned regions where visually plausible seams\ncan be established. Current alignment methods frequently fail to satisfy this\nprerequisite in large parallax scenarios despite considerable research efforts\ndedicated to improving alignment accuracy. In this paper, we propose an\nalignment-compensation paradigm that dissociates seam quality from initial\nalignment accuracy by integrating a Local Patch Alignment Module (LPAM) into\nthe seam-cutting pipeline. Concretely, given the aligned images with an\nestimated initial seam, our method first identifies low-quality pixels along\nthe seam through a seam quality assessment, then performs localized SIFT-flow\nalignment on the critical patches enclosing these pixels. Finally, we\nrecomposite the aligned patches using adaptive seam-cutting and merge them into\nthe original aligned images to generate the final mosaic. Comprehensive\nexperiments on large parallax stitching datasets demonstrate that LPAM\nsignificantly enhances stitching quality while maintaining computational\nefficiency. The code is available at\nhttps://github.com/tlliao/LPAM_seam-cutting.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2311.18564v3", "cate": "cs.CV", "date": "2023-11-30", "updated": "2025-07-09"}
{"id": "2507.06920", "title": "Rethinking Verification for LLM Code Generation: From Generation to Testing", "authors": ["Zihan Ma", "Taolin Zhang", "Maosong Cao", "Wenwei Zhang", "Minnan Luo", "Songyang Zhang", "Kai Chen"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06920v1", "summary": "Large language models (LLMs) have recently achieved notable success in\ncode-generation benchmarks such as HumanEval and LiveCodeBench. However, a\ndetailed examination reveals that these evaluation suites often comprise only a\nlimited number of homogeneous test cases, resulting in subtle faults going\nundetected. This not only artificially inflates measured performance but also\ncompromises accurate reward estimation in reinforcement learning frameworks\nutilizing verifiable rewards (RLVR). To address these critical shortcomings, we\nsystematically investigate the test-case generation (TCG) task by proposing\nmulti-dimensional metrics designed to rigorously quantify test-suite\nthoroughness. Furthermore, we introduce a human-LLM collaborative method\n(SAGA), leveraging human programming expertise with LLM reasoning capability,\naimed at significantly enhancing both the coverage and the quality of generated\ntest cases. In addition, we develop a TCGBench to facilitate the study of the\nTCG task. Experiments show that SAGA achieves a detection rate of 90.62% and a\nverifier accuracy of 32.58% on TCGBench. The Verifier Accuracy (Verifier Acc)\nof the code generation evaluation benchmark synthesized by SAGA is 10.78%\nhigher than that of LiveCodeBench-v6. These results demonstrate the\neffectiveness of our proposed method. We hope this work contributes to building\na scalable foundation for reliable LLM code evaluation, further advancing RLVR\nin code generation, and paving the way for automated adversarial test synthesis\nand adaptive benchmark integration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06920v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.02009", "title": "Uncertainty-Aware Complex Scientific Table Data Extraction", "authors": ["Kehinde Ajayi", "Yi He", "Jian Wu"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.02009v2", "summary": "Table structure recognition (TSR) and optical character recognition (OCR)\nplay crucial roles in extracting structured data from tables in scientific\ndocuments. However, existing extraction frameworks built on top of TSR and OCR\nmethods often fail to quantify the uncertainties of extracted results. To\nobtain highly accurate data for scientific domains, all extracted data must be\nmanually verified, which can be time-consuming and labor-intensive. We propose\na framework that performs uncertainty-aware data extraction for complex\nscientific tables, built on conformal prediction, a model-agnostic method for\nuncertainty quantification (UQ). We explored various uncertainty scoring\nmethods to aggregate the uncertainties introduced by TSR and OCR. We rigorously\nevaluated the framework using a standard benchmark and an in-house dataset\nconsisting of complex scientific tables in six scientific domains. The results\ndemonstrate the effectiveness of using UQ for extraction error detection, and\nby manually verifying only 47% of extraction results, the data quality can be\nimproved by 30%. Our work quantitatively demonstrates the role of UQ with the\npotential of improving the efficiency in the human-machine cooperation process\nto obtain scientifically usable data from complex tables in scientific\ndocuments. All code and data are available on GitHub at\nhttps://github.com/lamps-lab/TSR-OCR-UQ/tree/main.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.02009v2", "cate": "cs.IR", "date": "2025-07-02", "updated": "2025-07-08"}
{"id": "2507.06551", "title": "A Family of Block-Centered Schemes for Contaminant Transport Equations with Adsorption via Integral Method with Variational Limit", "authors": ["He Liu", "Xiongbo Zheng", "Xiaole Li", "Mingze Ji"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06551v1", "summary": "This paper develops a class of high-order conservative schemes for\ncontaminant transport with equilibrium adsorption, based on the Integral Method\nwith Variational Limit on block-centered grids. By incorporating four\nparameters, the scheme can reproduce classical fourth-order compact schemes and\nfurther extend to sixth- and eighth-order accurate formulations, all within a\nunified framework. Under periodic boundary conditions, we analyze the\nstability, convergence, and mass conservation of the parameterized numerical\nscheme. Numerical experiments are then conducted to examine the impact of\nparameter variations on errors, explore the relationship between parameters and\nthe fourth-, sixth-, and eighth-order schemes, and verify that the schemes'\nhigh-order accuracy aligns with theoretical predictions. To enhance the\napplicability of the proposed method, we further develop two fourth-order\ncompact boundary treatments that ensure uniform accuracy between boundary and\ninterior regions. Numerical results confirm the effectiveness of the proposed\nschemes across various adsorption models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06551v1", "cate": "math.NA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.05938", "title": "A Wireless Foundation Model for Multi-Task Prediction", "authors": ["Yucheng Sheng", "Jiacheng Wang", "Xingyu Zhou", "Le Liang", "Hao Ye", "Shi Jin", "Geoffrey Ye Li"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05938v2", "summary": "With the growing complexity and dynamics of the mobile communication\nnetworks, accurately predicting key system parameters, such as channel state\ninformation (CSI), user location, and network traffic, has become essential for\na wide range of physical (PHY)-layer and medium access control (MAC)-layer\ntasks. Although traditional deep learning (DL)-based methods have been widely\napplied to such prediction tasks, they often struggle to generalize across\ndifferent scenarios and tasks. In response, we propose a unified foundation\nmodel for multi-task prediction in wireless networks that supports diverse\nprediction intervals. The proposed model enforces univariate decomposition to\nunify heterogeneous tasks, encodes granularity for interval awareness, and uses\na causal Transformer backbone for accurate predictions. Additionally, we\nintroduce a patch masking strategy during training to support arbitrary input\nlengths. After trained on large-scale datasets, the proposed foundation model\ndemonstrates strong generalization to unseen scenarios and achieves zero-shot\nperformance on new tasks that surpass traditional full-shot baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05938v2", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "1706.00834", "title": "Online Dynamic Programming", "authors": ["Holakou Rahmanian", "Manfred K. Warmuth", "S. V. N. Vishwanathan"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/1706.00834v4", "summary": "We propose a general method for combinatorial online learning problems whose\noffline optimization problem can be solved efficiently via a dynamic\nprogramming algorithm defined by an arbitrary min-sum recurrence. Examples\ninclude online learning of Binary Search Trees, Matrix-Chain Multiplications,\n$k$-sets, Knapsacks, Rod Cuttings, and Weighted Interval Schedulings. For each\nof these problems we use the underlying graph of subproblems (called a\nmulti-DAG) for defining a representation of the solutions of the dynamic\nprogramming problem by encoding them as a generalized version of paths (called\nmultipaths). These multipaths encode each solution as a series of successive\ndecisions or components over which the loss is linear. We then show that the\ndynamic programming algorithm for each problem leads to online algorithms for\nlearning multipaths in the underlying multi-DAG. The algorithms maintain a\ndistribution over the multipaths in a concise form as their hypothesis. More\nspecifically we generalize the existing Expanded Hedge and Component Hedge\nalgorithms for the online shortest path problem to learning multipaths.\nAdditionally, we introduce a new and faster prediction technique for Component\nHedge which in our case directly samples from a distribution over multipaths,\nbypassing the need to decompose the distribution over multipaths into a mixture\nwith small support.", "comment": null, "pdf_url": "http://arxiv.org/pdf/1706.00834v4", "cate": "cs.LG", "date": "2017-06-02", "updated": "2025-07-08"}
{"id": "2312.02345", "title": "CLIPDraw++: Text-to-Sketch Synthesis with Simple Primitives", "authors": ["Nityanand Mathur", "Shyam Marjit", "Abhra Chaudhuri", "Anjan Dutta"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at CVPRW-25. Project Page: this https URL", "url": "http://arxiv.org/abs/2312.02345v2", "summary": "With the goal of understanding the visual concepts that CLIP associates with\ntext prompts, we show that the latent space of CLIP can be visualized solely in\nterms of linear transformations on simple geometric primitives like straight\nlines and circles. Although existing approaches achieve this by\nsketch-synthesis-through-optimization, they do so on the space of higher order\nB\\'ezier curves, which exhibit a wastefully large set of structures that they\ncan evolve into, as most of them are non-essential for generating meaningful\nsketches. We present CLIPDraw++, an algorithm that provides significantly\nbetter visualizations for CLIP text embeddings, using only simple primitive\nshapes like straight lines and circles. This constrains the set of possible\noutputs to linear transformations on these primitives, thereby exhibiting an\ninherently simpler mathematical form. The synthesis process of CLIPDraw++ can\nbe tracked end-to-end, with each visual concept being expressed exclusively in\nterms of primitives. Project Page: https://clipdrawx.github.io/.", "comment": "Accepted at CVPRW-25. Project Page: https://clipdrawx.github.io/", "pdf_url": "http://arxiv.org/pdf/2312.02345v2", "cate": "cs.CV", "date": "2023-12-04", "updated": "2025-07-09"}
{"id": "2507.06956", "title": "Investigating the Robustness of Retrieval-Augmented Generation at the Query Level", "authors": ["Sezen Perçin", "Xin Su", "Qutub Sha Syed", "Phillip Howard", "Aleksei Kuvshinov", "Leo Schwinn", "Kay-Ulrich Scholl"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to Generation, Evaluation & Metrics (GEM) Workshop at ACL 2025", "url": "http://arxiv.org/abs/2507.06956v1", "summary": "Large language models (LLMs) are very costly and inefficient to update with\nnew information. To address this limitation, retrieval-augmented generation\n(RAG) has been proposed as a solution that dynamically incorporates external\nknowledge during inference, improving factual consistency and reducing\nhallucinations. Despite its promise, RAG systems face practical challenges-most\nnotably, a strong dependence on the quality of the input query for accurate\nretrieval. In this paper, we investigate the sensitivity of different\ncomponents in the RAG pipeline to various types of query perturbations. Our\nanalysis reveals that the performance of commonly used retrievers can degrade\nsignificantly even under minor query variations. We study each module in\nisolation as well as their combined effect in an end-to-end question answering\nsetting, using both general-domain and domain-specific datasets. Additionally,\nwe propose an evaluation framework to systematically assess the query-level\nrobustness of RAG pipelines and offer actionable recommendations for\npractitioners based on the results of more than 1092 experiments we performed.", "comment": "Accepted to Generation, Evaluation & Metrics (GEM) Workshop at ACL\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.06956v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2408.13484", "title": "IntOPE: Off-Policy Evaluation in the Presence of Interference", "authors": ["Yuqi Bai", "Ziyu Zhao", "Chenxin Lyu", "Minqin Zhu", "Kun Kuang"], "categories": ["cs.LG", "cs.IR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.13484v2", "summary": "Off-Policy Evaluation (OPE) is employed to assess the potential impact of a\nhypothetical policy using logged contextual bandit feedback, which is crucial\nin areas such as personalized medicine and recommender systems, where online\ninteractions are associated with significant risks and costs. Traditionally,\nOPE methods rely on the Stable Unit Treatment Value Assumption (SUTVA), which\nassumes that the reward for any given individual is unaffected by the actions\nof others. However, this assumption often fails in real-world scenarios due to\nthe presence of interference, where an individual's reward is affected not just\nby their own actions but also by the actions of their peers. This realization\nreveals significant limitations of existing OPE methods in real-world\napplications. To address this limitation, we propose IntIPW, an IPW-style\nestimator that extends the Inverse Probability Weighting (IPW) framework by\nintegrating marginalized importance weights to account for both individual\nactions and the influence of adjacent entities. Extensive experiments are\nconducted on both synthetic and real-world data to demonstrate the\neffectiveness of the proposed IntIPW method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.13484v2", "cate": "cs.LG", "date": "2024-08-24", "updated": "2025-07-09"}
{"id": "2507.06707", "title": "Multiscale Approximation as a Bias-Reducing Strategy for Scalar and Manifold-Valued Functions", "authors": ["Asaf Abas", "Nir Sharon"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures", "url": "http://arxiv.org/abs/2507.06707v1", "summary": "We study the bias-variance tradeoff within a multiscale approximation\nframework. Our approach utilizes a given quasi-approximation operator,\nrepeatedly applied in an error-correction scheme over a hierarchical data\nstructure. We introduce a new bias measurement, the bias ratio, to\nquantitatively assess the improvements made by multiscale approximations and\ndemonstrate that this multiscale strategy effectively reduces the bias\ncomponent of the approximation error, thereby providing a more flexible and\nrobust framework for addressing scattered data approximation problems. Our\nfindings exhibit consistent bias decay across various scenarios, including\napplications to manifold-valued functions.", "comment": "8 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.06707v1", "cate": "math.NA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06057", "title": "FEVO: Financial Knowledge Expansion and Reasoning Evolution for Large Language Models", "authors": ["Bo Pang", "Yalu Ouyang", "Hangfei Xu", "Ziqi Jia", "Panpan Li", "Shengzhao Wen", "Lu Wang", "Shiyong Li", "Yanpeng Wang"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06057v2", "summary": "Advancements in reasoning for large language models (LLMs) have lead to\nsignificant performance improvements for LLMs in various fields such as\nmathematics and programming. However, research applying these advances to the\nfinancial domain, where considerable domain-specific knowledge is necessary to\ncomplete tasks, remains limited. To address this gap, we introduce FEVO\n(Financial Evolution), a multi-stage enhancement framework developed to enhance\nLLM performance in the financial domain. FEVO systemically enhances LLM\nperformance by using continued pre-training (CPT) to expand financial domain\nknowledge, supervised fine-tuning (SFT) to instill structured, elaborate\nreasoning patterns, and reinforcement learning (RL) to further integrate the\nexpanded financial domain knowledge with the learned structured reasoning. To\nensure effective and efficient training, we leverage frontier reasoning models\nand rule-based filtering to curate FEVO-Train, high-quality datasets\nspecifically designed for the different post-training phases. Using our\nframework, we train the FEVO series of models - C32B, S32B, R32B - from\nQwen2.5-32B and evaluate them on seven benchmarks to assess financial and\ngeneral capabilities, with results showing that FEVO-R32B achieves\nstate-of-the-art performance on five financial benchmarks against much larger\nmodels as well as specialist models. More significantly, FEVO-R32B demonstrates\nmarkedly better performance than FEVO-R32B-0 (trained from Qwen2.5-32B-Instruct\nusing only RL), thus validating the effectiveness of financial domain knowledge\nexpansion and structured, logical reasoning distillation", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06057v2", "cate": "cs.AI", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2301.08837", "title": "From Pseudorandomness to Multi-Group Fairness and Back", "authors": ["Cynthia Dwork", "Daniel Lee", "Huijia Lin", "Pranay Tankala"], "categories": ["cs.LG", "cs.CC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2301.08837v4", "summary": "We identify and explore connections between the recent literature on\nmulti-group fairness for prediction algorithms and the pseudorandomness notions\nof leakage-resilience and graph regularity. We frame our investigation using\nnew variants of multicalibration based on statistical distance and closely\nrelated to the concept of outcome indistinguishability. Adopting this\nperspective leads us not only to new, more efficient algorithms for\nmulticalibration, but also to our graph theoretic results and a proof of a\nnovel hardcore lemma for real-valued functions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2301.08837v4", "cate": "cs.LG", "date": "2023-01-21", "updated": "2025-07-09"}
{"id": "2401.14661", "title": "From Blurry to Brilliant Detection: YOLO-Based Aerial Object Detection with Super Resolution", "authors": ["Ragib Amin Nihal", "Benjamin Yen", "Takeshi Ashizawa", "Katsutoshi Itoyama", "Kazuhiro Nakadai"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2401.14661v2", "summary": "Aerial object detection presents challenges from small object sizes, high\ndensity clustering, and image quality degradation from distance and motion\nblur. These factors create an information bottleneck where limited pixel\nrepresentation cannot encode sufficient discriminative features. B2BDet\naddresses this with a two-stage framework that applies domain-specific\nsuper-resolution during inference, followed by detection using an enhanced\nYOLOv5 architecture. Unlike training-time super-resolution approaches that\nenhance learned representations, our method recovers visual information from\neach input image. The approach combines aerial-optimized SRGAN fine-tuning with\narchitectural innovations including an Efficient Attention Module (EAM) and\nCross-Layer Feature Pyramid Network (CLFPN). Evaluation across four aerial\ndatasets shows performance gains, with VisDrone achieving 52.5% mAP using only\n27.7M parameters. Ablation studies show that super-resolution preprocessing\ncontributes +2.6% mAP improvement while architectural enhancements add +2.9%,\nyielding +5.5% total improvement over baseline YOLOv5. The method achieves\ncomputational efficiency with 53.8% parameter reduction compared to recent\napproaches while achieving strong small object detection performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2401.14661v2", "cate": "cs.CV", "date": "2024-01-26", "updated": "2025-07-09"}
{"id": "2507.06974", "title": "FRaN-X: FRaming and Narratives-eXplorer", "authors": ["Artur Muratov", "Hana Fatima Shaikh", "Vanshikaa Jani", "Tarek Mahmoud", "Zhuohan Xie", "Daniil Orel", "Aaryamonvikram Singh", "Yuxia Wang", "Aadi Joshi", "Hasan Iqbal", "Ming Shan Hee", "Dhruv Sahnan", "Nikolaos Nikolaidis", "Purificação Silvano", "Dimitar Dimitrov", "Roman Yangarber", "Ricardo Campos", "Alípio Jorge", "Nuno Guimarães", "Elisa Sartori", "Nicolas Stefanovitch", "Giovanni Da San Martino", "Jakub Piskorski", "Preslav Nakov"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      19 pages, 13 figures, submitted to EMNLP 2025 - Demo Track", "url": "http://arxiv.org/abs/2507.06974v1", "summary": "We present FRaN-X, a Framing and Narratives Explorer that automatically\ndetects entity mentions and classifies their narrative roles directly from raw\ntext. FRaN-X comprises a two-stage system that combines sequence labeling with\nfine-grained role classification to reveal how entities are portrayed as\nprotagonists, antagonists, or innocents, using a unique taxonomy of 22\nfine-grained roles nested under these three main categories. The system\nsupports five languages (Bulgarian, English, Hindi, Russian, and Portuguese)\nand two domains (the Russia-Ukraine Conflict and Climate Change). It provides\nan interactive web interface for media analysts to explore and compare framing\nacross different sources, tackling the challenge of automatically detecting and\nlabeling how entities are framed. Our system allows end users to focus on a\nsingle article as well as analyze up to four articles simultaneously. We\nprovide aggregate level analysis including an intuitive graph visualization\nthat highlights the narrative a group of articles are pushing. Our system\nincludes a search feature for users to look up entities of interest, along with\na timeline view that allows analysts to track an entity's role transitions\nacross different contexts within the article. The FRaN-X system and the trained\nmodels are licensed under an MIT License. FRaN-X is publicly accessible at\nhttps://fran-x.streamlit.app/ and a video demonstration is available at\nhttps://youtu.be/VZVi-1B6yYk.", "comment": "19 pages, 13 figures, submitted to EMNLP 2025 - Demo Track", "pdf_url": "http://arxiv.org/pdf/2507.06974v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2410.08740", "title": "Hespi: A pipeline for automatically detecting information from hebarium specimen sheets", "authors": ["Robert Turnbull", "Emily Fitzgerald", "Karen Thompson", "Joanne L. Birch"], "categories": ["cs.CV", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      15 pages, 7 figures", "url": "http://arxiv.org/abs/2410.08740v2", "summary": "Specimen-associated biodiversity data are crucial for biological,\nenvironmental, and conservation sciences. A rate shift is needed to extract\ndata from specimen images efficiently, moving beyond human-mediated\ntranscription. We developed `Hespi' (HErbarium Specimen sheet PIpeline) using\nadvanced computer vision techniques to extract pre-catalogue data from primary\nspecimen labels on herbarium specimens. Hespi integrates two object detection\nmodels: one for detecting the components of the sheet and another for fields on\nthe primary primary specimen label. It classifies labels as printed, typed,\nhandwritten, or mixed and uses Optical Character Recognition (OCR) and\nHandwritten Text Recognition (HTR) for extraction. The text is then corrected\nagainst authoritative taxon databases and refined using a multimodal Large\nLanguage Model (LLM). Hespi accurately detects and extracts text from specimen\nsheets across international herbaria, and its modular design allows users to\ntrain and integrate custom models.", "comment": "15 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2410.08740v2", "cate": "cs.CV", "date": "2024-10-11", "updated": "2025-07-09"}
{"id": "2507.06731", "title": "Kernel-based Greedy Approximation of Parametric Elliptic Boundary Value Problems", "authors": ["Bernard Haasdonk", "Gabriele Santin", "Tizian Wenzel"], "categories": ["math.NA", "cs.NA", "46E22, 65D15, 65N35"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06731v1", "summary": "We recently introduced a scale of kernel-based greedy schemes for\napproximating the solutions of elliptic boundary value problems. The procedure\nis based on a generalized interpolation framework in reproducing kernel Hilbert\nspaces and was coined PDE-$\\beta$-greedy procedure, where the parameter $\\beta\n\\geq 0$ is used in a greedy selection criterion and steers the degree of\nfunction adaptivity. Algebraic convergence rates have been obtained for\nSobolev-space kernels and solutions of finite smoothness. We now report a\nresult of exponential convergence rates for the case of infinitely smooth\nkernels and solutions. We furthermore extend the approximation scheme to the\ncase of parametric PDEs by the use of state-parameter product kernels. In the\nsurrogate modelling context, the resulting approach can be interpreted as an a\npriori model reduction approach, as no solution snapshots need to be\nprecomputed. Numerical results show the efficiency of the approximation\nprocedure for problems which occur as challenges for other parametric MOR\nprocedures: non-affine geometry parametrizations, moving sources or\nhigh-dimensional domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06731v1", "cate": "math.NA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2505.12982", "title": "Multi-parameter Control for the $(1+(λ,λ))$-GA on OneMax via Deep Reinforcement Learning", "authors": ["Tai Nguyen", "Phong Le", "Carola Doerr", "Nguyen Dang"], "categories": ["cs.LG", "cs.NE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.12982v2", "summary": "It is well known that evolutionary algorithms can benefit from dynamic\nchoices of the key parameters that control their behavior, to adjust their\nsearch strategy to the different stages of the optimization process. A\nprominent example where dynamic parameter choices have shown a provable\nsuper-constant speed-up is the $(1+(\\lambda,\\lambda))$ Genetic Algorithm\noptimizing the OneMax function. While optimal parameter control policies result\nin linear expected running times, this is not possible with static parameter\nchoices. This result has spurred a lot of interest in parameter control\npolicies. However, many works, in particular theoretical running time analyses,\nfocus on controlling one single parameter. Deriving policies for controlling\nmultiple parameters remains very challenging. In this work we reconsider the\nproblem of the $(1+(\\lambda,\\lambda))$ Genetic Algorithm optimizing OneMax. We\ndecouple its four main parameters and investigate how well state-of-the-art\ndeep reinforcement learning techniques can approximate good control policies.\nWe show that although making deep reinforcement learning learn effectively is a\nchallenging task, once it works, it is very powerful and is able to find\npolicies that outperform all previously known control policies on the same\nbenchmark. Based on the results found through reinforcement learning, we derive\na simple control policy that consistently outperforms the default\ntheory-recommended setting by $27\\%$ and the irace-tuned policy, the strongest\nexisting control policy on this benchmark, by $13\\%$, for all tested problem\nsizes up to $40{,}000$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.12982v2", "cate": "cs.LG", "date": "2025-05-19", "updated": "2025-07-09"}
{"id": "2308.03572", "title": "Efficient Transfer Learning via Causal Bounds", "authors": ["Xueping Gong", "Wei You", "Jiheng Zhang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      88 pages", "url": "http://arxiv.org/abs/2308.03572v5", "summary": "Transfer learning seeks to accelerate sequential decision-making by\nleveraging offline data from related agents. However, data from heterogeneous\nsources that differ in observed features, distributions, or unobserved\nconfounders often render causal effects non-identifiable and bias naive\nestimators. We address this by forming ambiguity sets of structural causal\nmodels defined via integral constraints on their joint densities. Optimizing\nany causal effect over these sets leads to generally non-convex programs whose\nsolutions tightly bound the range of possible effects under heterogeneity or\nconfounding. To solve these programs efficiently, we develop a hit-and-run\nsampler that explores the entire ambiguity set and, when paired with a local\noptimization oracle, produces causal bound estimates that converge almost\nsurely to the true limits. We further accommodate estimation error by relaxing\nthe ambiguity set and exploit the Lipschitz continuity of causal effects to\nestablish precise error propagation guarantees. These causal bounds are then\nembedded into bandit algorithms via arm elimination and truncated UCB indices,\nyielding optimal gap-dependent and minimax regret bounds. To handle estimation\nerror, we also develop a safe algorithm for incorporating noisy causal bounds.\nIn the contextual-bandit setting with function approximation, our method uses\ncausal bounds to prune both the function class and the per-context action set,\nachieving matching upper and lower regret bounds with only logarithmic\ndependence on function-class complexity. Our analysis precisely characterizes\nwhen and how causal side-information accelerates online learning, and\nexperiments on synthetic benchmarks confirm substantial regret reductions in\ndata-scarce or confounded regimes.", "comment": "88 pages", "pdf_url": "http://arxiv.org/pdf/2308.03572v5", "cate": "cs.LG", "date": "2023-08-07", "updated": "2025-07-09"}
{"id": "2305.18811", "title": "PyPOTS: A Python Toolkit for Machine Learning on Partially-Observed Time Series", "authors": ["Wenjie Du", "Yiyuan Yang", "Linglong Qian", "Jun Wang", "Qingsong Wen"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      PyPOTS website is at this https URL , and PyPOTS is open source at this https URL", "url": "http://arxiv.org/abs/2305.18811v2", "summary": "PyPOTS is an open-source Python library dedicated to data mining and analysis\non multivariate partially-observed time series with missing values.\nParticularly, it provides easy access to diverse algorithms categorized into\nfive tasks: imputation, forecasting, anomaly detection, classification, and\nclustering. The included models represent a diverse set of methodological\nparadigms, offering a unified and well-documented interface suitable for both\nacademic research and practical applications. With robustness and scalability\nin its design philosophy, best practices of software construction, for example,\nunit testing, continuous integration and continuous delivery, code coverage,\nmaintainability evaluation, interactive tutorials, and parallelization, are\ncarried out as principles during the development of PyPOTS. The toolbox is\navailable on PyPI, Anaconda, and Docker. PyPOTS is open source and publicly\navailable on GitHub https://github.com/WenjieDu/PyPOTS.", "comment": "PyPOTS website is at https://pypots.com, and PyPOTS is open source at\n  https://github.com/WenjieDu/PyPOTS", "pdf_url": "http://arxiv.org/pdf/2305.18811v2", "cate": "cs.LG", "date": "2023-05-30", "updated": "2025-07-09"}
{"id": "2402.03666", "title": "QuEST: Low-bit Diffusion Model Quantization via Efficient Selective Finetuning", "authors": ["Haoxuan Wang", "Yuzhang Shang", "Zhihang Yuan", "Junyi Wu", "Junchi Yan", "Yan Yan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025. Code is available at this https URL", "url": "http://arxiv.org/abs/2402.03666v5", "summary": "The practical deployment of diffusion models is still hindered by the high\nmemory and computational overhead. Although quantization paves a way for model\ncompression and acceleration, existing methods face challenges in achieving\nlow-bit quantization efficiently. In this paper, we identify imbalanced\nactivation distributions as a primary source of quantization difficulty, and\npropose to adjust these distributions through weight finetuning to be more\nquantization-friendly. We provide both theoretical and empirical evidence\nsupporting finetuning as a practical and reliable solution. Building on this\napproach, we further distinguish two critical types of quantized layers: those\nresponsible for retaining essential temporal information and those particularly\nsensitive to bit-width reduction. By selectively finetuning these layers under\nboth local and global supervision, we mitigate performance degradation while\nenhancing quantization efficiency. Our method demonstrates its efficacy across\nthree high-resolution image generation tasks, obtaining state-of-the-art\nperformance across multiple bit-width settings.", "comment": "ICCV 2025. Code is available at\n  https://github.com/hatchetProject/QuEST", "pdf_url": "http://arxiv.org/pdf/2402.03666v5", "cate": "cs.CV", "date": "2024-02-06", "updated": "2025-07-09"}
{"id": "2507.07030", "title": "UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations", "authors": ["Fengran Mo", "Yifan Gao", "Chuan Meng", "Xin Liu", "Zhuofeng Wu", "Kelong Mao", "Zhengyang Wang", "Pei Chen", "Zheng Li", "Xian Li", "Bing Yin", "Meng Jiang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by ACL 2025 (main)", "url": "http://arxiv.org/abs/2507.07030v1", "summary": "The rapid advancement of conversational search systems revolutionizes how\ninformation is accessed by enabling the multi-turn interaction between the user\nand the system. Existing conversational search systems are usually built with\ntwo different models. This separation restricts the system from leveraging the\nintrinsic knowledge of the models simultaneously, which cannot ensure the\neffectiveness of retrieval benefiting the generation. The existing studies for\ndeveloping unified models cannot fully address the aspects of understanding\nconversational context, managing retrieval independently, and generating\nresponses. In this paper, we explore how to unify dense retrieval and response\ngeneration for large language models in conversation. We conduct joint\nfine-tuning with different objectives and design two mechanisms to reduce the\ninconsistency risks while mitigating data discrepancy. The evaluations on five\nconversational search datasets demonstrate that our unified model can mutually\nimprove both tasks and outperform the existing baselines.", "comment": "Accepted by ACL 2025 (main)", "pdf_url": "http://arxiv.org/pdf/2507.07030v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.06740", "title": "Elliptic Interface Problem approximated by CutFEM: II. A posteriori error analysis based on equilibrated fluxes", "authors": ["Daniela Capatina", "Aimene Gouasmi"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06740v1", "summary": "This paper investigates an elliptic interface problem with discontinuous\ndiffusion coefficients on unfitted meshes, employing the CutFEM method. The\nmain contribution is the a posteriori error analysis based on equilibrated\nfluxes belonging to the immersed Raviart-Thomas space. We establish sharp\nreliability and local efficiency of a new error estimator, which includes both\nvolume and interface terms, carefully tracking the dependence of the efficiency\nconstant on the diffusion coefficients and the mesh/interface configuration.\nNumerical results highlight the robustness of the proposed approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06740v1", "cate": "math.NA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2403.12431", "title": "Geometric Constraints in Deep Learning Frameworks: A Survey", "authors": ["Vibhas K Vats", "David J Crandall"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Published at ACM Surveys", "url": "http://arxiv.org/abs/2403.12431v2", "summary": "Stereophotogrammetry is an established technique for scene understanding. Its\norigins go back to at least the 1800s when people first started to investigate\nusing photographs to measure the physical properties of the world. Since then,\nthousands of approaches have been explored. The classic geometric technique of\nShape from Stereo is built on using geometry to define constraints on scene and\ncamera deep learning without any attempt to explicitly model the geometry. In\nthis survey, we explore geometry-inspired deep learning-based frameworks. We\ncompare and contrast geometry enforcing constraints integrated into deep\nlearning frameworks for depth estimation and other closely related vision\ntasks. We present a new taxonomy for prevalent geometry enforcing constraints\nused in modern deep learning frameworks. We also present insightful\nobservations and potential future research directions.", "comment": "Published at ACM Surveys", "pdf_url": "http://arxiv.org/pdf/2403.12431v2", "cate": "cs.CV", "date": "2024-03-19", "updated": "2025-07-09"}
{"id": "2404.02359", "title": "Attribution Regularization for Multimodal Paradigms", "authors": ["Sahiti Yerramilli", "Jayant Sravan Tamarapalli", "Jonathan Francis", "Eric Nyberg"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.02359v2", "summary": "Multimodal machine learning has gained significant attention in recent years\ndue to its potential for integrating information from multiple modalities to\nenhance learning and decision-making processes. However, it is commonly\nobserved that unimodal models outperform multimodal models, despite the latter\nhaving access to richer information. Additionally, the influence of a single\nmodality often dominates the decision-making process, resulting in suboptimal\nperformance. This research project aims to address these challenges by\nproposing a novel regularization term that encourages multimodal models to\neffectively utilize information from all modalities when making decisions. The\nfocus of this project lies in the video-audio domain, although the proposed\nregularization technique holds promise for broader applications in embodied AI\nresearch, where multiple modalities are involved. By leveraging this\nregularization term, the proposed approach aims to mitigate the issue of\nunimodal dominance and improve the performance of multimodal machine learning\nsystems. Through extensive experimentation and evaluation, the effectiveness\nand generalizability of the proposed technique will be assessed. The findings\nof this research project have the potential to significantly contribute to the\nadvancement of multimodal machine learning and facilitate its application in\nvarious domains, including multimedia analysis, human-computer interaction, and\nembodied AI research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.02359v2", "cate": "cs.LG", "date": "2024-04-02", "updated": "2025-07-09"}
{"id": "2402.16267", "title": "Infrared and visible Image Fusion with Language-driven Loss in CLIP Embedding Space", "authors": ["Yuhao Wang", "Lingjuan Miao", "Zhiqiang Zhou", "Lei Zhang", "Yajun Qiao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACM MM 2025", "url": "http://arxiv.org/abs/2402.16267v2", "summary": "Infrared-visible image fusion (IVIF) has attracted much attention owing to\nthe highly-complementary properties of the two image modalities. Due to the\nlack of ground-truth fused images, the fusion output of current deep-learning\nbased methods heavily depends on the loss functions defined mathematically. As\nit is hard to well mathematically define the fused image without ground truth,\nthe performance of existing fusion methods is limited. In this paper, we first\npropose to use natural language to express the objective of IVIF, which can\navoid the explicit mathematical modeling of fusion output in current losses,\nand make full use of the advantage of language expression to improve the fusion\nperformance. For this purpose, we present a comprehensive language-expressed\nfusion objective, and encode relevant texts into the multi-modal embedding\nspace using CLIP. A language-driven fusion model is then constructed in the\nembedding space, by establishing the relationship among the embedded vectors to\nrepresent the fusion objective and input image modalities. Finally, a\nlanguage-driven loss is derived to make the actual IVIF aligned with the\nembedded language-driven fusion model via supervised training. Experiments show\nthat our method can obtain much better fusion results than existing techniques.", "comment": "Accepted by ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2402.16267v2", "cate": "cs.CV", "date": "2024-02-26", "updated": "2025-07-09"}
{"id": "2401.17196", "title": "Single Word Change is All You Need: Designing Attacks and Defenses for Text Classifiers", "authors": ["Lei Xu", "Sarah Alnegheimish", "Laure Berti-Equille", "Alfredo Cuesta-Infante", "Kalyan Veeramachaneni"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2401.17196v2", "summary": "In text classification, creating an adversarial example means subtly\nperturbing a few words in a sentence without changing its meaning, causing it\nto be misclassified by a classifier. A concerning observation is that a\nsignificant portion of adversarial examples generated by existing methods\nchange only one word. This single-word perturbation vulnerability represents a\nsignificant weakness in classifiers, which malicious users can exploit to\nefficiently create a multitude of adversarial examples. This paper studies this\nproblem and makes the following key contributions: (1) We introduce a novel\nmetric \\r{ho} to quantitatively assess a classifier's robustness against\nsingle-word perturbation. (2) We present the SP-Attack, designed to exploit the\nsingle-word perturbation vulnerability, achieving a higher attack success rate,\nbetter preserving sentence meaning, while reducing computation costs compared\nto state-of-the-art adversarial methods. (3) We propose SP-Defense, which aims\nto improve \\r{ho} by applying data augmentation in learning. Experimental\nresults on 4 datasets and BERT and distilBERT classifiers show that SP-Defense\nimproves \\r{ho} by 14.6% and 13.9% and decreases the attack success rate of\nSP-Attack by 30.4% and 21.2% on two classifiers respectively, and decreases the\nattack success rate of existing attack methods that involve multiple-word\nperturbations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2401.17196v2", "cate": "cs.CL", "date": "2024-01-30", "updated": "2025-07-08"}
{"id": "2507.06789", "title": "Sharp uniform approximation for spectral Barron functions by deep neural networks", "authors": ["Yulei Liao", "Pingbing Ming", "Hao Yu"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06789v1", "summary": "This work explores the neural network approximation capabilities for\nfunctions within the spectral Barron space $\\mathscr{B}^s$, where $s$ is the\nsmoothness index. We demonstrate that for functions in $\\mathscr{B}^{1/2}$, a\nshallow neural network (a single hidden layer) with $N$ units can achieve an\n$L^p$-approximation rate of $\\mathcal{O}(N^{-1/2})$. This rate also applies to\nuniform approximation, differing by at most a logarithmic factor. Our results\nsignificantly reduce the smoothness requirement compared to existing theory,\nwhich necessitate functions to belong to $\\mathscr{B}^1$ in order to attain the\nsame rate. Furthermore, we show that increasing the network's depth can notably\nimprove the approximation order for functions with small smoothness.\nSpecifically, for networks with $L$ hidden layers, functions in $\\mathscr{B}^s$\nwith $0 < sL \\le 1/2$ can achieve an approximation rate of\n$\\mathcal{O}(N^{-sL})$. The rates and prefactors in our estimates are\ndimension-free. We also confirm the sharpness of our findings, with the lower\nbound closely aligning with the upper, with a discrepancy of at most one\nlogarithmic factor.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06789v1", "cate": "math.NA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2404.02353", "title": "Semantic Augmentation in Images using Language", "authors": ["Sahiti Yerramilli", "Jayant Sravan Tamarapalli", "Tanmay Girish Kulkarni", "Jonathan Francis", "Eric Nyberg"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.02353v2", "summary": "Deep Learning models are incredibly data-hungry and require very large\nlabeled datasets for supervised learning. As a consequence, these models often\nsuffer from overfitting, limiting their ability to generalize to real-world\nexamples. Recent advancements in diffusion models have enabled the generation\nof photorealistic images based on textual inputs. Leveraging the substantial\ndatasets used to train these diffusion models, we propose a technique to\nutilize generated images to augment existing datasets. This paper explores\nvarious strategies for effective data augmentation to improve the out-of-domain\ngeneralization capabilities of deep learning models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.02353v2", "cate": "cs.CV", "date": "2024-04-02", "updated": "2025-07-09"}
{"id": "2406.18752", "title": "Near-Optimal Consistency-Robustness Trade-Offs for Learning-Augmented Online Knapsack Problems", "authors": ["Mohammadreza Daneshvaramoli", "Helia Karisani", "Adam Lechowicz", "Bo Sun", "Cameron Musco", "Mohammad Hajiesmaili"], "categories": ["cs.LG", "cs.GT", "68Q25, 68T05", "F.2.2; I.2.6"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      31 pages, 16 figures, Accepted at ICML 2025", "url": "http://arxiv.org/abs/2406.18752v2", "summary": "This paper introduces a family of learning-augmented algorithms for online\nknapsack problems that achieve near Pareto-optimal consistency-robustness\ntrade-offs through a simple combination of trusted learning-augmented and\nworst-case algorithms. Our approach relies on succinct, practical predictions\n-- single values or intervals estimating the minimum value of any item in an\noffline solution. Additionally, we propose a novel fractional-to-integral\nconversion procedure, offering new insights for online algorithm design.", "comment": "31 pages, 16 figures, Accepted at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2406.18752v2", "cate": "cs.LG", "date": "2024-06-26", "updated": "2025-07-09"}
{"id": "2404.18394", "title": "Reconstructing Satellites in 3D from Amateur Telescope Images", "authors": ["Zhiming Chang", "Boyang Liu", "Yifei Xia", "Youming Guo", "Boxin Shi", "He Sun"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.18394v4", "summary": "Monitoring space objects is crucial for space situational awareness, yet\nreconstructing 3D satellite models from ground-based telescope images is\nchallenging due to atmospheric turbulence, long observation distances, limited\nviewpoints, and low signal-to-noise ratios. In this paper, we propose a novel\ncomputational imaging framework that overcomes these obstacles by integrating a\nhybrid image pre-processing pipeline with a joint pose estimation and 3D\nreconstruction module based on controlled Gaussian Splatting (GS) and\nBranch-and-Bound (BnB) search. We validate our approach on both synthetic\nsatellite datasets and on-sky observations of China's Tiangong Space Station\nand the International Space Station, achieving robust 3D reconstructions of\nlow-Earth orbit satellites from ground-based data. Quantitative evaluations\nusing SSIM, PSNR, LPIPS, and Chamfer Distance demonstrate that our method\noutperforms state-of-the-art NeRF-based approaches, and ablation studies\nconfirm the critical role of each component. Our framework enables\nhigh-fidelity 3D satellite monitoring from Earth, offering a cost-effective\nalternative for space situational awareness. Project page:\nhttps://ai4scientificimaging.org/ReconstructingSatellites", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.18394v4", "cate": "cs.CV", "date": "2024-04-29", "updated": "2025-07-09"}
{"id": "2406.05615", "title": "Video-Language Understanding: A Survey from Model Architecture, Model Training, and Data Perspectives", "authors": ["Thong Nguyen", "Yi Bin", "Junbin Xiao", "Leigang Qu", "Yicong Li", "Jay Zhangjie Wu", "Cong-Duy Nguyen", "See-Kiong Ng", "Luu Anh Tuan"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at ACL 2024 (Findings)", "url": "http://arxiv.org/abs/2406.05615v3", "summary": "Humans use multiple senses to comprehend the environment. Vision and language\nare two of the most vital senses since they allow us to easily communicate our\nthoughts and perceive the world around us. There has been a lot of interest in\ncreating video-language understanding systems with human-like senses since a\nvideo-language pair can mimic both our linguistic medium and visual environment\nwith temporal dynamics. In this survey, we review the key tasks of these\nsystems and highlight the associated challenges. Based on the challenges, we\nsummarize their methods from model architecture, model training, and data\nperspectives. We also conduct performance comparison among the methods, and\ndiscuss promising directions for future research.", "comment": "Accepted at ACL 2024 (Findings)", "pdf_url": "http://arxiv.org/pdf/2406.05615v3", "cate": "cs.CL", "date": "2024-06-09", "updated": "2025-07-09"}
{"id": "2507.06846", "title": "A posteriori error estimates for a $C^1$ virtual element method applied to the thin plate vibration problem", "authors": ["Franco Dassi", "Andres E. Rubiano", "Iván Velásquez"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06846v1", "summary": "We propose and analyse residual-based a posteriori error estimates for the\nvirtual element discretisation applied to the thin plate vibration problem in\nboth two and three dimensions. Our approach involves a conforming $C^1$\ndiscrete formulation suitable for meshes composed of polygons and polyhedra.\nThe reliability and efficiency of the error estimator are established through a\ndimension-independent proof. Finally, several numerical experiments are\nreported to demonstrate the optimal performance of the method in 2D and 3D.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06846v1", "cate": "math.NA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2407.18468", "title": "Diffusion-Driven Semantic Communication for Generative Models with Bandwidth Constraints", "authors": ["Lei Guo", "Wei Chen", "Yuxuan Sun", "Bo Ai", "Nikolaos Pappas", "Tony Q. S. Quek"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      accepted to IEEE for possible publication", "url": "http://arxiv.org/abs/2407.18468v4", "summary": "Diffusion models have been extensively utilized in AI-generated content\n(AIGC) in recent years, thanks to the superior generation capabilities.\nCombining with semantic communications, diffusion models are used for tasks\nsuch as denoising, data reconstruction, and content generation. However,\nexisting diffusion-based generative models do not consider the stringent\nbandwidth limitation, which limits its application in wireless communication.\nThis paper introduces a diffusion-driven semantic communication framework with\nadvanced VAE-based compression for bandwidth-constrained generative model. Our\ndesigned architecture utilizes the diffusion model, where the signal\ntransmission process through the wireless channel acts as the forward process\nin diffusion. To reduce bandwidth requirements, we incorporate a downsampling\nmodule and a paired upsampling module based on a variational auto-encoder with\nreparameterization at the receiver to ensure that the recovered features\nconform to the Gaussian distribution. Furthermore, we derive the loss function\nfor our proposed system and evaluate its performance through comprehensive\nexperiments. Our experimental results demonstrate significant improvements in\npixel-level metrics such as peak signal to noise ratio (PSNR) and semantic\nmetrics like learned perceptual image patch similarity (LPIPS). These\nenhancements are more profound regarding the compression rates and SNR compared\nto deep joint source-channel coding (DJSCC). We release the code at\nhttps://github.com/import-sudo/Diffusion-Driven-Semantic-Communication.", "comment": "accepted to IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2407.18468v4", "cate": "cs.LG", "date": "2024-07-26", "updated": "2025-07-09"}
{"id": "2408.01926", "title": "Efficient Decision Trees for Tensor Regressions", "authors": ["Hengrui Luo", "Akira Horiguchi", "Li Ma"], "categories": ["cs.LG", "stat.ME", "stat.ML", "62G08, 15A69", "G.3"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      52 pages, 11 Figures", "url": "http://arxiv.org/abs/2408.01926v2", "summary": "We proposed the tensor-input tree (TT) method for scalar-on-tensor and\ntensor-on-tensor regression problems. We first address scalar-on-tensor problem\nby proposing scalar-output regression tree models whose input variable are\ntensors (i.e., multi-way arrays). We devised and implemented fast randomized\nand deterministic algorithms for efficient fitting of scalar-on-tensor trees,\nmaking TT competitive against tensor-input GP models. Based on scalar-on-tensor\ntree models, we extend our method to tensor-on-tensor problems using additive\ntree ensemble approaches. Theoretical justification and extensive experiments\non real and synthetic datasets are provided to illustrate the performance of\nTT.", "comment": "52 pages, 11 Figures", "pdf_url": "http://arxiv.org/pdf/2408.01926v2", "cate": "cs.LG", "date": "2024-08-04", "updated": "2025-07-08"}
{"id": "2405.14030", "title": "Refining Skewed Perceptions in Vision-Language Contrastive Models through Visual Representations", "authors": ["Haocheng Dai", "Sarang Joshi"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 8 figures", "url": "http://arxiv.org/abs/2405.14030v3", "summary": "Large vision-language contrastive models (VLCMs), such as CLIP, have become\nfoundational, demonstrating remarkable success across a variety of downstream\ntasks. Despite their advantages, these models, akin to other foundational\nsystems, inherit biases from the disproportionate distribution of real-world\ndata, leading to misconceptions about the actual environment. Prevalent\ndatasets like ImageNet are often riddled with non-causal, spurious correlations\nthat can diminish VLCM performance in scenarios where these contextual elements\nare absent. This study presents an investigation into how a simple linear probe\ncan effectively distill task-specific core features from CLIP's embedding for\ndownstream applications. Our analysis reveals that the CLIP text\nrepresentations are often tainted by spurious correlations, inherited in the\nbiased pre-training dataset. Empirical evidence suggests that relying on visual\nrepresentations from CLIP, as opposed to text embedding, is more effective to\nrefine the skewed perceptions in VLCMs, emphasizing the superior utility of\nvisual representations in overcoming embedded biases. Our code can be found\nhere.", "comment": "10 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2405.14030v3", "cate": "cs.CV", "date": "2024-05-22", "updated": "2025-07-09"}
{"id": "2406.13217", "title": "Automating IRAC Analysis in Malaysian Contract Law using a Semi-Structured Knowledge Base", "authors": ["Xiaoxi Kang", "Lizhen Qu", "Lay-Ki Soon", "Zhuang Li", "Adnan Trakic"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.13217v2", "summary": "The effectiveness of Large Language Models (LLMs) in legal reasoning is often\nlimited due to the unique legal terminologies and the necessity for highly\nspecialized knowledge. These limitations highlight the need for high-quality\ndata tailored for complex legal reasoning tasks. This paper introduces\nLegalSemi, a benchmark specifically curated for legal scenario analysis.\nLegalSemi comprises 54 legal scenarios, each rigorously annotated by legal\nexperts, based on the comprehensive IRAC (Issue, Rule, Application, Conclusion)\nframework from Malaysian Contract Law. In addition, LegalSemi is accompanied by\na structured knowledge base (SKE). A series of experiments were conducted to\nassess the usefulness of LegalSemi for IRAC analysis. The experimental results\ndemonstrate the effectiveness of incorporating the SKE for issue\nidentification, rule retrieval, application and conclusion generation using\nfour different LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.13217v2", "cate": "cs.CL", "date": "2024-06-19", "updated": "2025-07-09"}
{"id": "2507.06861", "title": "An overlapping domain decomposition method for parametric Stokes and Stokes-Darcy problems via proper generalized decomposition", "authors": ["Marco Discacciati", "Ben J. Evans", "Matteo Giacomini"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06861v1", "summary": "A strategy to construct physics-based local surrogate models for parametric\nStokes flows and coupled Stokes-Darcy systems is presented. The methodology\nrelies on the proper generalized decomposition (PGD) method to reduce the\ndimensionality of the parametric flow fields and on an overlapping domain\ndecomposition (DD) paradigm to reduce the number of globally coupled degrees of\nfreedom in space. The DD-PGD approach provides a non-intrusive framework in\nwhich end-users only need access to the matrices arising from the (finite\nelement) discretization of the full-order problems in the subdomains. The\ntraces of the finite element functions used for the discretization within the\nsubdomains are employed to impose arbitrary Dirichlet boundary conditions at\nthe interface, without introducing auxiliary basis functions. The methodology\nis seamless to the choice of the discretization schemes in space, being\ncompatible with both LBB-compliant finite element pairs and stabilized\nformulations, and the DD-PGD paradigm is transparent to the employed\noverlapping DD approach. The local surrogate models are glued together in the\nonline phase by solving a parametric interface system to impose continuity of\nthe subdomain solutions at the interfaces, without introducing Lagrange\nmultipliers to enforce the continuity in the entire overlap and without solving\nany additional physical problem in the reduced space. Numerical results are\npresented for parametric single-physics (Stokes-Stokes) and multi-physics\n(Stokes-Darcy) systems, showcasing the accuracy, robustness, and computational\nefficiency of DD-PGD, and its capability to outperform DD methods based on\nhigh-fidelity finite element solvers in terms of computing times.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06861v1", "cate": "math.NA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2408.00751", "title": "A Policy-Gradient Approach to Solving Imperfect-Information Games with Best-Iterate Convergence", "authors": ["Mingyang Liu", "Gabriele Farina", "Asuman Ozdaglar"], "categories": ["cs.GT", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.00751v2", "summary": "Policy gradient methods have become a staple of any single-agent\nreinforcement learning toolbox, due to their combination of desirable\nproperties: iterate convergence, efficient use of stochastic trajectory\nfeedback, and theoretically-sound avoidance of importance sampling corrections.\nIn multi-agent imperfect-information settings (extensive-form games), however,\nit is still unknown whether the same desiderata can be guaranteed while\nretaining theoretical guarantees. Instead, sound methods for extensive-form\ngames rely on approximating \\emph{counterfactual} values (as opposed to Q\nvalues), which are incompatible with policy gradient methodologies. In this\npaper, we investigate whether policy gradient can be safely used in two-player\nzero-sum imperfect-information extensive-form games (EFGs). We establish\npositive results, showing for the first time that a policy gradient method\nleads to provable best-iterate convergence to a regularized Nash equilibrium in\nself-play.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.00751v2", "cate": "cs.GT", "date": "2024-08-01", "updated": "2025-07-09"}
{"id": "2409.15370", "title": "Tokenization for Molecular Foundation Models", "authors": ["Alexius Wadell", "Anoushka Bhutani", "Venkatasubramanian Viswanathan"], "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      26 pages, 4 figures", "url": "http://arxiv.org/abs/2409.15370v3", "summary": "Text-based foundation models have become an important part of scientific\ndiscovery, with molecular foundation models accelerating advancements in\nmaterial science and molecular design.However, existing models are constrained\nby closed-vocabulary tokenizers that capture only a fraction of molecular\nspace. In this work, we systematically evaluate 34 tokenizers, including 19\nchemistry-specific ones, and reveal significant gaps in their coverage of the\nSMILES molecular representation. To assess the impact of tokenizer choice, we\nintroduce n-gram language models as a low-cost proxy and validate their\neffectiveness by pretraining and finetuning 18 RoBERTa-style encoders for\nmolecular property prediction. To overcome the limitations of existing\ntokenizers, we propose two new tokenizers -- Smirk and Smirk-GPE -- with full\ncoverage of the OpenSMILES specification. The proposed tokenizers\nsystematically integrate nuclear, electronic, and geometric degrees of freedom;\nfacilitating applications in pharmacology, agriculture, biology, and energy\nstorage. Our results highlight the need for open-vocabulary modeling and\nchemically diverse benchmarks in cheminformatics.", "comment": "26 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2409.15370v3", "cate": "cs.LG", "date": "2024-09-19", "updated": "2025-07-08"}
{"id": "2407.03010", "title": "CAVIS: Context-Aware Video Instance Segmentation", "authors": ["Seunghun Lee", "Jiwan Seo", "Kiljoon Han", "Minwoo Choi", "Sunghoon Im"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025. Code: this https URL", "url": "http://arxiv.org/abs/2407.03010v2", "summary": "In this paper, we introduce the Context-Aware Video Instance Segmentation\n(CAVIS), a novel framework designed to enhance instance association by\nintegrating contextual information adjacent to each object. To efficiently\nextract and leverage this information, we propose the Context-Aware Instance\nTracker (CAIT), which merges contextual data surrounding the instances with the\ncore instance features to improve tracking accuracy. Additionally, we design\nthe Prototypical Cross-frame Contrastive (PCC) loss, which ensures consistency\nin object-level features across frames, thereby significantly enhancing\nmatching accuracy. CAVIS demonstrates superior performance over\nstate-of-the-art methods on all benchmark datasets in video instance\nsegmentation (VIS) and video panoptic segmentation (VPS). Notably, our method\nexcels on the OVIS dataset, known for its particularly challenging videos.\nProject page: https://seung-hun-lee.github.io/projects/CAVIS/", "comment": "ICCV 2025. Code: https://github.com/Seung-Hun-Lee/CAVIS", "pdf_url": "http://arxiv.org/pdf/2407.03010v2", "cate": "cs.CV", "date": "2024-07-03", "updated": "2025-07-09"}
{"id": "2410.01735", "title": "LASeR: Learning to Adaptively Select Reward Models with Multi-Armed Bandits", "authors": ["Duy Nguyen", "Archiki Prasad", "Elias Stengel-Eskin", "Mohit Bansal"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      28 pages; First two authors contributed equally. Code: this https URL", "url": "http://arxiv.org/abs/2410.01735v2", "summary": "Reward Models (RMs) are crucial to aligning large language models (LLMs), but\nthe degree to which an RM specialized to one task (e.g. writing) generalizes to\nnew tasks (e.g. math) is often not known a priori, often making using only one\nfixed RM to train LLMs suboptimal. However, optimizing LLMs with multiple RMs\nsimultaneously can incur a prohibitively high computational cost and lead to\nconflicting signals from different RMs that may degrade performance. To address\nthese challenges, we introduce LASeR (Learning to Adaptively Select Rewards),\nwhich frames reward model selection as a multi-armed bandit problem,\nefficiently and iteratively training LLMs using multiple RMs by selecting the\nmost well-suited RM for each instance. On commonsense and math reasoning tasks,\nwe show that LASeR boosts iterative LLM training, improving the absolute\naverage accuracy of Llama-3-8B over three datasets by 2.67% over an ensemble of\nRM scores while also showing superior efficiency (e.g., a 2x speedup).\nMoreover, on WildChat (open-ended instruction-following tasks), LASeR leads to\na 72.69% AlpacaEval win rate over the RM score ensemble baseline. Extending to\nlong-context generation, LASeR improves by 2.96 F1 points (avg.) on\nsingle-document QA tasks and 2.97 F1 points on few-shot learning over the RM\nscore ensemble baseline with best-of-n sampling.", "comment": "28 pages; First two authors contributed equally. Code:\n  https://github.com/duykhuongnguyen/LASeR-MAB", "pdf_url": "http://arxiv.org/pdf/2410.01735v2", "cate": "cs.CL", "date": "2024-10-02", "updated": "2025-07-09"}
{"id": "2507.06869", "title": "Structure-preserving space discretization of differential and nonlocal constitutive relations for port-Hamiltonian systems", "authors": ["Antoine Bendimerad-Hohl", "Ghislain Haine", "Laurent Lefèvre", "Denis Matignon"], "categories": ["math.NA", "cs.NA", "math.DS"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      37 pages, 12 figures", "url": "http://arxiv.org/abs/2507.06869v1", "summary": "We study the structure-preserving space discretization of port-Hamiltonian\n(pH) systems defined with differential constitutive relations. Using the\nconcept of Stokes-Lagrange structure to describe these relations, these are\nreduced to a finite-dimensional Lagrange subspace of a pH system thanks to a\nstructure-preserving Finite Element Method.\n  To illustrate our results, the 1D nanorod case and the shear beam model are\nconsidered, which are given by differential and implicit constitutive relations\nfor which a Stokes-Lagrange structure along with boundary energy ports\nnaturally occur.\n  Then, these results are extended to the nonlinear 2D incompressible\nNavier-Stokes equations written in a vorticity-stream function formulation. It\nis first recast as a pH system defined with a Stokes-Lagrange structure along\nwith a modulated Stokes-Dirac structure. A careful structure-preserving space\ndiscretization is then performed, leading to a finite-dimensional pH system.\nTheoretical and numerical results show that both enstrophy and kinetic energy\nevolutions are preserved both at the semi-discrete and fully-discrete levels.", "comment": "37 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.06869v1", "cate": "math.NA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2409.14307", "title": "DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation", "authors": ["Xuewen Liu", "Zhikai Li", "Minhao Jiang", "Mengjuan Chen", "Jianquan Li", "Qingyi Gu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ACMMM 2025", "url": "http://arxiv.org/abs/2409.14307v3", "summary": "Model quantization is a promising method for accelerating and compressing\ndiffusion models. Nevertheless, since post-training quantization (PTQ) fails\ncatastrophically at low-bit cases, quantization-aware training (QAT) is\nessential. Unfortunately, the wide range and time-varying activations in\ndiffusion models sharply increase the complexity of quantization, making\nexisting QAT methods inefficient. Equivalent scaling can effectively reduce\nactivation range, but previous methods remain the overall quantization error\nunchanged. More critically, these methods significantly disrupt the original\nweight distribution, resulting in poor weight initialization and challenging\nconvergence during QAT training. In this paper, we propose a novel QAT\nframework for diffusion models, called DilateQuant. Specifically, we propose\nWeight Dilation (WD) that maximally dilates the unsaturated in-channel weights\nto a constrained range through equivalent scaling. WD decreases the activation\nrange while preserving the original weight range, which steadily reduces the\nquantization error and ensures model convergence. To further enhance accuracy\nand efficiency, we design a Temporal Parallel Quantizer (TPQ) to address the\ntime-varying activations and introduce a Block-wise Knowledge Distillation\n(BKD) to reduce resource consumption in training. Extensive experiments\ndemonstrate that DilateQuant significantly outperforms existing methods in\nterms of accuracy and efficiency. Code is available at\nhttp://github.com/BienLuky/DilateQuant .", "comment": "ACMMM 2025", "pdf_url": "http://arxiv.org/pdf/2409.14307v3", "cate": "cs.CV", "date": "2024-09-22", "updated": "2025-07-09"}
{"id": "2410.04543", "title": "Pullback Flow Matching on Data Manifolds", "authors": ["Friso de Kruiff", "Erik Bekkers", "Ozan Öktem", "Carola-Bibiane Schönlieb", "Willem Diepeveen"], "categories": ["cs.LG", "cs.AI", "math.DG", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.04543v2", "summary": "We propose Pullback Flow Matching (PFM), a novel framework for generative\nmodeling on data manifolds. Unlike existing methods that assume or learn\nrestrictive closed-form manifold mappings for training Riemannian Flow Matching\n(RFM) models, PFM leverages pullback geometry and isometric learning to\npreserve the underlying manifold's geometry while enabling efficient generation\nand precise interpolation in latent space. This approach not only facilitates\nclosed-form mappings on the data manifold but also allows for designable latent\nspaces, using assumed metrics on both data and latent manifolds. By enhancing\nisometric learning through Neural ODEs and proposing a scalable training\nobjective, we achieve a latent space more suitable for interpolation, leading\nto improved manifold learning and generative performance. We demonstrate PFM's\neffectiveness through applications in synthetic data, protein dynamics and\nprotein sequence data, generating novel proteins with specific properties. This\nmethod shows strong potential for drug discovery and materials science, where\ngenerating novel samples with specific properties is of great interest.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.04543v2", "cate": "cs.LG", "date": "2024-10-06", "updated": "2025-07-09"}
{"id": "2407.08277", "title": "StixelNExT: Toward Monocular Low-Weight Perception for Object Segmentation and Free Space Detection", "authors": ["Marcel Vosshans", "Omar Ait-Aider", "Youcef Mezouar", "Markus Enzweiler"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted Conference Paper, IEEE IV 2024", "url": "http://arxiv.org/abs/2407.08277v2", "summary": "In this work, we present a novel approach for general object segmentation\nfrom a monocular image, eliminating the need for manually labeled training data\nand enabling rapid, straightforward training and adaptation with minimal data.\nOur model initially learns from LiDAR during the training process, which is\nsubsequently removed from the system, allowing it to function solely on\nmonocular imagery. This study leverages the concept of the Stixel-World to\nrecognize a medium level representation of its surroundings. Our network\ndirectly predicts a 2D multi-layer Stixel-World and is capable of recognizing\nand locating multiple, superimposed objects within an image. Due to the\nscarcity of comparable works, we have divided the capabilities into modules and\npresent a free space detection in our experiments section. Furthermore, we\nintroduce an improved method for generating Stixels from LiDAR data, which we\nuse as ground truth for our network.", "comment": "Accepted Conference Paper, IEEE IV 2024", "pdf_url": "http://arxiv.org/pdf/2407.08277v2", "cate": "cs.CV", "date": "2024-07-11", "updated": "2025-07-09"}
{"id": "2410.12513", "title": "FiRST: Finetuning Router-Selective Transformers for Input-Adaptive Latency Reduction", "authors": ["Akriti Jain", "Saransh Sharma", "Koyel Mukherjee", "Soumyabrata Pal"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.12513v3", "summary": "Auto-regressive Large Language Models (LLMs) demonstrate remarkable\nperformance across different domains such as vision and language processing.\nHowever, due to sequential processing through a stack of transformer layers,\nautoregressive decoding faces significant computation/latency challenges,\nparticularly in resource-constrained environments like mobile and edge devices.\nExisting approaches in literature that aim to improve latency via skipping\nlayers have two distinct flavors - 1) Early exit, and 2) Input-agnostic\nheuristics where tokens exit at pre-determined layers irrespective of input\nsequence. Both the above strategies have limitations - the former cannot be\napplied to handle KV Caching necessary for speed-ups in modern framework and\nthe latter does not capture the variation in layer importance across tasks or\nmore generally, across input sequences. To address both limitations, we propose\nFiRST, an algorithm that reduces inference latency by using layer-specific\nrouters to select a subset of transformer layers adaptively for each input\nsequence - the prompt (during the prefill stage) decides which layers will be\nskipped during decoding. FiRST preserves compatibility with KV caching enabling\nfaster inference while being quality-aware. FiRST is model-agnostic and can be\neasily enabled on any pre-trained LLM. Our approach reveals that input\nadaptivity is critical - indeed, different task-specific middle layers play a\ncrucial role in evolving hidden representations depending on tasks. Extensive\nexperiments show that FiRST significantly reduces latency while outperforming\nother layer selection strategies in quality metics. It retains competitive\nperformance to base model (without layer skipping) and in some cases, even\nimproves upon it. FiRST is thus a promising and efficient solution for LLM\ndeployment in low-resource environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.12513v3", "cate": "cs.CL", "date": "2024-10-16", "updated": "2025-07-09"}
{"id": "2507.06985", "title": "A new class of one-step A-stable and L-stable schemes of high-order accuracy for parabolic type equations", "authors": ["Xiaoyi Li", "Aijie Cheng", "Zhengguang Liu"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06985v1", "summary": "Recently, a new class of BDF schemes proposed in [F. Huang and J. Shen, SIAM\nJ Numer. Anal., 62.4, 1609--1637] for the parabolic type equations are studied\nin this paper. The basic idea is based on the Taylor expansions at time\n$t^{n+\\beta}$ with $\\beta>1$ being a tunable parameter. These new BDF schemes\nallow larger time steps at higher order r for stiff problems than that which\nallowed with a usual higher-order scheme. However, multi-step methods like BDF\nexhibit inherent disadvantages relative to one-step methods in practical\nimplementations. In this paper, inspired by their excellent work, we construct\na new class of high-order one-step schemes for linear parabolic-type equations.\nThese new schemes, with several suitable $\\beta_i$, can achieve A-stable, or\neven L-stable. Specially, the new scheme with special parameters $\\beta_i$ can\nbe regarded as the classical one-step Runge-Kutta scheme with a stabilized\nterm. Besides, we provide two different techniques to construct the one-step\nhigh-order schemes: the first one is by choosing different parameters\n$\\beta_i$, and the second one is by increasing the number of intermediate\nlayers. Both methods have been proven to be highly effective and even exhibit\nsuperconvergence property. Finally, we also conducted several numerical\nexperiments to support our conclusions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06985v1", "cate": "math.NA", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2410.06151", "title": "Diversifying Robot Locomotion Behaviors with Extrinsic Behavioral Curiosity", "authors": ["Zhenglin Wan", "Xingrui Yu", "David Mark Bossens", "Yueming Lyu", "Qing Guo", "Flint Xiaofeng Fan", "Yew Soon Ong", "Ivor Tsang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      22 pages, conference paper", "url": "http://arxiv.org/abs/2410.06151v3", "summary": "Imitation learning (IL) has shown promise in robot locomotion but is often\nlimited to learning a single expert policy, constraining behavior diversity and\nrobustness in unpredictable real-world scenarios. To address this, we introduce\nQuality Diversity Inverse Reinforcement Learning (QD-IRL), a novel framework\nthat integrates quality-diversity optimization with IRL methods, enabling\nagents to learn diverse behaviors from limited demonstrations. This work\nintroduces Extrinsic Behavioral Curiosity (EBC), which allows agents to receive\nadditional curiosity rewards from an external critic based on how novel the\nbehaviors are with respect to a large behavioral archive. To validate the\neffectiveness of EBC in exploring diverse locomotion behaviors, we evaluate our\nmethod on multiple robot locomotion tasks. EBC improves the performance of\nQD-IRL instances with GAIL, VAIL, and DiffAIL across all included environments\nby up to 185%, 42%, and 150%, even surpassing expert performance by 20% in\nHumanoid. Furthermore, we demonstrate that EBC is applicable to\nGradient-Arborescence-based Quality Diversity Reinforcement Learning (QD-RL)\nalgorithms, where it substantially improves performance and provides a generic\ntechnique for diverse robot locomotion. The source code of this work is\nprovided at https://github.com/vanzll/EBC.", "comment": "22 pages, conference paper", "pdf_url": "http://arxiv.org/pdf/2410.06151v3", "cate": "cs.LG", "date": "2024-10-08", "updated": "2025-07-09"}
{"id": "2412.04596", "title": "Learning Nonlinear Finite Element Solution Operators using Multilayer Perceptrons and Energy Minimization", "authors": ["Mats G. Larson", "Carl Lundholm", "Anna Persson"], "categories": ["cs.LG", "cs.NA", "math.NA", "65K10 65N30 65Y20 68T07", "G.1.8; I.2.6; J.2"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preprint for journal submission. 24 pages, 7 figures (18 subfigures in total)", "url": "http://arxiv.org/abs/2412.04596v2", "summary": "We develop and evaluate a method for learning solution operators to nonlinear\nproblems governed by partial differential equations (PDEs). The approach is\nbased on a finite element discretization and aims at representing the solution\noperator by a multilayer perceptron (MLP) that takes problem data variables as\ninput and gives a prediction of the finite element solution as output. The\nvariables will typically correspond to parameters in a parametrization of input\ndata such as boundary conditions, coefficients, and right-hand sides. The\noutput will be an approximation of the corresponding finite element solution,\nthus enabling support and enhancement by the standard finite element method\n(FEM) both theoretically and practically. The loss function is most often an\nenergy functional and we formulate efficient parallelizable training algorithms\nbased on assembling the energy locally on each element. For large problems, the\nlearning process can be made more efficient by using only a small fraction of\nrandomly chosen elements in the mesh in each iteration. The approach is\nevaluated on several relevant test cases, where learning the finite element\nsolution operator turns out to be beneficial, both in its own right but also by\ncombination with standard FEM theory and software.", "comment": "Preprint for journal submission. 24 pages, 7 figures (18 subfigures\n  in total)", "pdf_url": "http://arxiv.org/pdf/2412.04596v2", "cate": "cs.LG", "date": "2024-12-05", "updated": "2025-07-08"}
{"id": "2408.01701", "title": "Signal-SGN: A Spiking Graph Convolutional Network for Skeletal Action Recognition via Learning Temporal-Frequency Dynamics", "authors": ["Naichuan Zheng", "Yuchen Du", "Hailun Xia", "Zeyu Liang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.01701v5", "summary": "For multimodal skeleton-based action recognition, Graph Convolutional\nNetworks (GCNs) are effective models. Still, their reliance on floating-point\ncomputations leads to high energy consumption, limiting their applicability in\nbattery-powered devices. While energy-efficient, Spiking Neural Networks (SNNs)\nstruggle to model skeleton dynamics, leading to suboptimal solutions. We\npropose Signal-SGN (Spiking Graph Convolutional Network), which utilizes the\ntemporal dimension of skeleton sequences as the spike time steps and represents\nfeatures as multi-dimensional discrete stochastic signals for\ntemporal-frequency domain feature extraction. It combines the 1D Spiking Graph\nConvolution (1D-SGC) module and the Frequency Spiking Convolution (FSC) module\nto extract features from the skeleton represented as spiking form.\nAdditionally, the Multi-Scale Wavelet Transform Feature Fusion (MWTF) module is\nproposed to extract dynamic spiking features and capture frequency-specific\ncharacteristics, enhancing classification performance. Experiments across three\nlarge-scale datasets reveal Signal-SGN exceeding state-of-the-art SNN-based\nmethods in accuracy and computational efficiency while attaining comparable\nperformance with GCN methods and significantly reducing theoretical energy\nconsumption.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.01701v5", "cate": "cs.CV", "date": "2024-08-03", "updated": "2025-07-09"}
{"id": "2411.09073", "title": "CHAI for LLMs: Improving Code-Mixed Translation in Large Language Models through Reinforcement Learning with AI Feedback", "authors": ["Wenbo Zhang", "Aditya Majumdar", "Amulya Yadav"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      full draft v2: 8 pages, 3 figures", "url": "http://arxiv.org/abs/2411.09073v3", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious NLP tasks but struggle with code-mixed (or code-switched) language\nunderstanding. For example, prior work benchmarking the performance of\nmultilingual LLMs on code-mixed translation tasks has demonstrated that current\nstate-of-the-art multilingual LLMs are ineffective in dealing with code-mixed\nlanguages. However, the question of how to improve the capability of\nmultilingual LLMs to handle code-mixed language has not received any attention\nto date. In this paper, we tackle this research gap by proposing CHAI, a novel\ngeneral-purpose framework for improving the ability of multilingual LLMs to\nhandle code-mixed languages. CHAI relies on three novel contributions made in\nthis paper. First, we explore the ability of LLMs to provide accurate\nannotations for code-mixed translation tasks. Second, we leverage this ability\nof LLMs as annotators to generate preference data for code-mixed translation\ntasks at scale, which are then used within a reinforcement learning from AI\nfeedback (RLAIF) procedure to improve LLMs' capability on code-mixed tasks.\nThird, we conduct a rigorous experimental evaluation across various real-world\ndatasets and settings. Our analysis shows that CHAI-powered LLMs outperform\nstate-of-the-art open-source LLMs by 25.66% (in terms of win rate adjudicated\nby human annotators) in code-mixed translation tasks. This work represents a\nfirst step towards developing more inclusive code-mixed LLMs.", "comment": "full draft v2: 8 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2411.09073v3", "cate": "cs.CL", "date": "2024-11-13", "updated": "2025-07-09"}
{"id": "2406.07366", "title": "Fast and accurate evaluation of Biot-Savart integrals over spatial curves in periodic domains", "authors": ["Juan Ignacio Polanco"], "categories": ["physics.comp-ph", "cs.NA", "math.NA", "physics.flu-dyn"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "Comments:      28 pages, 7 figures. Accepted for publication in SIAM Journal on Scientific Computing", "url": "http://arxiv.org/abs/2406.07366v2", "summary": "The Biot-Savart law is relevant in physical contexts including\nelectromagnetism and fluid dynamics. In the latter case, when the rotation of a\nfluid is confined to a set of very thin vortex filaments, this law describes\nthe velocity field induced by the spatial arrangement of these objects. The\nBiot-Savart law is at the core of vortex methods used in the simulation of\nclassical and quantum fluid flows. Naive methods are inefficient when dealing\nwith large numbers of vortex elements, which makes them inadequate for\nsimulating turbulent vortex flows. Here we exploit a direct analogy between the\nBiot-Savart law and electrostatics to adapt Ewald summation methods, routinely\nused in molecular dynamics simulations, to vortex filament simulations in\nthree-dimensional periodic domains. In this context, the basic idea is to split\nthe induced velocity onto (i) a coarse-grained velocity generated by a\nGaussian-filtered vorticity field, and (ii) a short-range correction accounting\nfor near-singular behaviour near the vortices. The former component can be\naccurately and efficiently evaluated using the nonuniform fast Fourier\ntransform algorithm. Analytical accuracy estimates are provided as a function\nof the parameters entering the method. We also discuss how to properly account\nfor the finite vortex core size in kinetic energy estimations. Using numerical\nexperiments, we verify the accuracy and the conservation properties of the\nproposed approach. Moreover, we demonstrate the $O(N \\log N)$ complexity of the\nmethod over a wide range of problem sizes $N$, considerably better than the\n$O(N^2)$ cost of a naive approach.", "comment": "28 pages, 7 figures. Accepted for publication in SIAM Journal on\n  Scientific Computing", "pdf_url": "http://arxiv.org/pdf/2406.07366v2", "cate": "physics.comp-ph", "date": "2024-06-11", "updated": "2025-04-09"}
{"id": "2507.06681", "title": "Computing Euler products and coefficients of classical modular forms for twisted L-functions", "authors": ["Pascal Molin"], "categories": ["cs.SC", "math.NT"], "primary_category": "Subjects:       Symbolic Computation (cs.SC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06681v1", "summary": "We describe a complete algorithm to compute millions of coefficients of\nclassical modular forms in a few seconds. We also review operations on Euler\nproducts and illustrate our methods with a computation of triple product\nL-function of large conductor.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06681v1", "cate": "cs.SC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2412.10422", "title": "AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework", "authors": ["Meihao Fan", "Ju Fan", "Nan Tang", "Lei Cao", "Guoliang Li", "Xiaoyong Du"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.10422v4", "summary": "Answering natural language (NL) questions about tables, known as Tabular\nQuestion Answering (TQA), is crucial because it allows users to quickly and\nefficiently extract meaningful insights from structured data, effectively\nbridging the gap between human language and machine-readable formats. Many of\nthese tables are derived from web sources or real-world scenarios, which\nrequire meticulous data preparation (or data prep) to ensure accurate\nresponses. However, preparing such tables for NL questions introduces new\nrequirements that extend beyond traditional data preparation. This\nquestion-ware data preparation involves specific tasks such as column\nderivation and filtering tailored to particular questions, as well as\nquestion-aware value normalization or conversion, highlighting the need for a\nmore nuanced approach in this context. Because each of the above tasks is\nunique, a single model (or agent) may not perform effectively across all\nscenarios. In this paper, we propose AutoPrep, a large language model\n(LLM)-based multiagent framework that leverages the strengths of multiple\nagents, each specialized in a certain type of data prep, ensuring more accurate\nand contextually relevant responses. Given an NL question over a table,\nAutoPrep performs data prep through three key components. Planner: Determines a\nlogical plan, outlining a sequence of high-level operations. Programmer:\nTranslates this logical plan into a physical plan by generating the\ncorresponding low-level code. Executor: Executes the generated code to process\nthe table. To support this multi-agent framework, we design a novel\nChain-ofClauses reasoning mechanism for high-level operation suggestion, and a\ntool-augmented method for low-level code generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.10422v4", "cate": "cs.CL", "date": "2024-12-10", "updated": "2025-07-09"}
{"id": "2502.06376", "title": "Many-Task Federated Fine-Tuning via Unified Task Vectors", "authors": ["Vasileios Tsouvalas", "Tanir Ozcelebi", "Nirvana Meratnia"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 6 figures, accepted in FedGenAI-IJCAI 2025", "url": "http://arxiv.org/abs/2502.06376v3", "summary": "Federated Learning (FL) traditionally assumes homogeneous client tasks;\nhowever, in real-world scenarios, clients often specialize in diverse tasks,\nintroducing task heterogeneity. To address this challenge, Many-Task FL\n(MaT-FL) has emerged, enabling clients to collaborate effectively despite task\ndiversity. Existing MaT-FL approaches rely on client grouping or personalized\nlayers, requiring the server to manage individual models and failing to account\nfor clients handling multiple tasks. We propose MaTU, a MaT-FL approach that\nenables joint learning of task vectors across clients, eliminating the need for\nclustering or client-specific weight storage at the server. Our method\nintroduces a novel aggregation mechanism that determines task similarity based\non the direction of clients task vectors and constructs a unified task vector\nencapsulating all tasks. To address task-specific requirements, we augment the\nunified task vector with lightweight modulators that facilitate knowledge\ntransfer among related tasks while disentangling dissimilar ones. Evaluated\nacross 30 datasets, MaTU achieves superior performance over state-of-the-art\nMaT-FL approaches, with results comparable to per-task fine-tuning, while\ndelivering significant communication savings.", "comment": "10 pages, 6 figures, accepted in FedGenAI-IJCAI 2025", "pdf_url": "http://arxiv.org/pdf/2502.06376v3", "cate": "cs.LG", "date": "2025-02-10", "updated": "2025-07-08"}
{"id": "2408.05582", "title": "Non-Negative Reduced Biquaternion Matrix Factorization with Applications in Color Face Recognition", "authors": ["Jifei Miao", "Junjun Pan", "Michael K. Ng"], "categories": ["cs.CV", "cs.NA", "math.NA"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.05582v2", "summary": "Reduced biquaternion (RB), as a four-dimensional algebra highly suitable for\nrepresenting color pixels, has recently garnered significant attention from\nnumerous scholars. In this paper, for color image processing problems, we\nintroduce a concept of the non-negative RB matrix and then use the\nmultiplication properties of RB to propose a non-negative RB matrix\nfactorization (NRBMF) model. The NRBMF model is introduced to address the\nchallenge of reasonably establishing a non-negative quaternion matrix\nfactorization model, which is primarily hindered by the multiplication\nproperties of traditional quaternions. Furthermore, this paper transforms the\nproblem of solving the NRBMF model into an RB alternating non-negative least\nsquares (RB-ANNLS) problem. Then, by introducing a method to compute the\ngradient of the real function with RB matrix variables, we solve the RB-ANNLS\noptimization problem using the RB projected gradient algorithm and conduct a\nconvergence analysis of the algorithm. Finally, we validate the effectiveness\nand superiority of the proposed NRBMF model in color face recognition.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.05582v2", "cate": "cs.CV", "date": "2024-08-10", "updated": "2025-07-09"}
{"id": "2412.08268", "title": "LCFO: Long Context and Long Form Output Dataset and Benchmarking", "authors": ["Marta R. Costa-jussà", "Pierre Andrews", "Mariano Coria Meglioli", "Joy Chen", "Joe Chuang", "David Dale", "Christophe Ropers", "Alexandre Mourachko", "Eduardo Sánchez", "Holger Schwenk", "Tuan Tran", "Arina Turkatenko", "Carleigh Wood"], "categories": ["cs.CL", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.08268v3", "summary": "This paper presents the Long Context and Form Output (LCFO) benchmark, a\nnovel evaluation framework for assessing gradual summarization and summary\nexpansion capabilities across diverse domains. LCFO consists of long input\ndocuments (5k words average length), each of which comes with three summaries\nof different lengths (20%, 10%, and 5% of the input text), as well as\napproximately 15 questions and answers (QA) related to the input content.\nNotably, LCFO also provides alignments between specific QA pairs and\ncorresponding summaries in 7 domains. The primary motivation behind providing\nsummaries of different lengths is to establish a controllable framework for\ngenerating long texts from shorter inputs, i.e. summary expansion. To establish\nan evaluation metric framework for summarization and summary expansion, we\nprovide human evaluation scores for human-generated outputs, as well as results\nfrom various state-of-the-art large language models (LLMs). GPT-4o-mini\nachieves best human scores among automatic systems in both summarization and\nsummary expansion tasks (~ +10% and +20%, respectively). It even surpasses\nhuman output quality in the case of short summaries (~ +7%). Overall automatic\nmetrics achieve low correlations with human evaluation scores (~ 0.4) but\nmoderate correlation on specific evaluation aspects such as fluency and\nattribution (~ 0.6).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.08268v3", "cate": "cs.CL", "date": "2024-12-11", "updated": "2025-07-09"}
{"id": "2507.07063", "title": "Analysis of the stability of an immersed elastic surface using the method of regularized Stokeslets", "authors": ["Dana Ferranti", "Sarah D. Olson"], "categories": ["physics.flu-dyn", "cs.NA", "math.NA"], "primary_category": "Subjects:       Fluid Dynamics (physics.flu-dyn)", "pdf_link": null, "comments": "Comments:      43 pages, 5 figures", "url": "http://arxiv.org/abs/2507.07063v1", "summary": "A linear stability analysis of an elastic surface immersed in a viscous fluid\nis presented. The coupled system is modeled using the method of regularized\nStokeslets (MRS), a Lagrangian method for simulating fluid-structure\ninteraction at zero Reynolds number. The linearized system is solved in a\ndoubly periodic domain in a 3D fluid. The eigenvalues determine the theoretical\ncritical time step for numerical stability for a forward Euler time\nintegration, which are then verified numerically across several regularization\nfunctions, elastic models, and parameter choices. New doubly periodic\nregularized Stokeslets are presented, allowing for comparison of the stability\nproperties of different regularization functions. The stability results for a\ncommon regularization function are approximated by a power law relating the\nregularization parameter and the surface discretization for two different\nelastic models. This relationship is empirically shown to hold in the different\nsetting of a finite surface in a bulk fluid.", "comment": "43 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.07063v1", "cate": "physics.flu-dyn", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2307.05102", "title": "Rational Solutions of Parametric First-Order Algebraic Differential Equations", "authors": ["Sebastian Falkensteiner", "Rafael Sendra"], "categories": ["cs.SC", "34A05, 14H50, 34A34, 30C15, 35B30"], "primary_category": "Subjects:       Symbolic Computation (cs.SC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2307.05102v3", "summary": "In this paper, we give an algorithm for finding general rational solutions of\na given first-order ODE with parametric coefficients that occur rationally. We\npresent an analysis, complete modulo Hilbert's irreducibility problem, of the\nexistence of rational solutions of the differential equation, with parametric\ncoefficients, when the parameters are specialized.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2307.05102v3", "cate": "cs.SC", "date": "2023-07-11", "updated": "2025-07-08"}
{"id": "2412.15212", "title": "Scaling 4D Representations", "authors": ["João Carreira", "Dilara Gokay", "Michael King", "Chuhan Zhang", "Ignacio Rocco", "Aravindh Mahendran", "Thomas Albert Keck", "Joseph Heyward", "Skanda Koppula", "Etienne Pot", "Goker Erdogan", "Yana Hasson", "Yi Yang", "Klaus Greff", "Guillaume Le Moing", "Sjoerd van Steenkiste", "Daniel Zoran", "Drew A. Hudson", "Pedro Vélez", "Luisa Polanía", "Luke Friedman", "Chris Duvarney", "Ross Goroshin", "Kelsey Allen", "Jacob Walker", "Rishabh Kabra", "Eric Aboussouan", "Jennifer Sun", "Thomas Kipf", "Carl Doersch", "Viorica Pătrăucean", "Dima Damen", "Pauline Luc", "Mehdi S. M. Sajjadi", "Andrew Zisserman"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.15212v2", "summary": "Scaling has not yet been convincingly demonstrated for pure self-supervised\nlearning from video. However, prior work has focused evaluations on\nsemantic-related tasks $\\unicode{x2013}$ action classification, ImageNet\nclassification, etc. In this paper we focus on evaluating self-supervised\nlearning on non-semantic vision tasks that are more spatial (3D) and temporal\n(+1D = 4D), such as camera pose estimation, point and object tracking, and\ndepth estimation. We show that by learning from very large video datasets,\nmasked auto-encoding (MAE) with transformer video models actually scales,\nconsistently improving performance on these 4D tasks, as model size increases\nfrom 20M all the way to the largest by far reported self-supervised video model\n$\\unicode{x2013}$ 22B parameters. Rigorous apples-to-apples comparison with\nmany recent image and video models demonstrates the benefits of scaling 4D\nrepresentations. Pretrained models are available at\nhttps://github.com/google-deepmind/representations4d .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.15212v2", "cate": "cs.CV", "date": "2024-12-19", "updated": "2025-07-09"}
{"id": "2502.15843", "title": "Implicit Neural Representations for Chemical Reaction Paths", "authors": ["Kalyan Ramakrishnan", "Lars L. Schaaf", "Chen Lin", "Guangrun Wang", "Philip Torr"], "categories": ["cs.LG", "physics.chem-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in the Journal of Chemical Physics", "url": "http://arxiv.org/abs/2502.15843v3", "summary": "We show that neural networks can be optimized to represent minimum energy\npaths as continuous functions, offering a flexible alternative to discrete\npath-search methods such as Nudged Elastic Band (NEB). Our approach\nparameterizes reaction paths with a network trained on a loss function that\ndiscards tangential energy gradients and enables instant estimation of the\ntransition state. We first validate the method on two-dimensional potentials\nand then demonstrate its advantages over NEB on challenging atomistic systems\nwhere (i) poor initial guesses yield unphysical paths, (ii) multiple competing\npaths exist, or (iii) the reaction follows a complex multi-step mechanism.\nResults highlight the versatility of the method: for instance, a simple\nadjustment to the sampling strategy during optimization can help escape\nlocal-minimum solutions. Finally, in a low-dimensional setting, we demonstrate\nthat a single neural network can learn from existing paths and generalize to\nunseen systems, showing promise for a universal reaction path representation.", "comment": "Published in the Journal of Chemical Physics", "pdf_url": "http://arxiv.org/pdf/2502.15843v3", "cate": "cs.LG", "date": "2025-02-20", "updated": "2025-07-08"}
{"id": "2408.06079", "title": "Towards Adversarial Robustness via Debiased High-Confidence Logit Alignment", "authors": ["Kejia Zhang", "Juanjuan Weng", "Shaozi Li", "Zhiming Luo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2408.06079v2", "summary": "Despite the remarkable progress of deep neural networks (DNNs) in various\nvisual tasks, their vulnerability to adversarial examples raises significant\nsecurity concerns. Recent adversarial training methods leverage inverse\nadversarial attacks to generate high-confidence examples, aiming to align\nadversarial distributions with high-confidence class regions. However, our\ninvestigation reveals that under inverse adversarial attacks, high-confidence\noutputs are influenced by biased feature activations, causing models to rely on\nbackground features that lack a causal relationship with the labels. This\nspurious correlation bias leads to overfitting irrelevant background features\nduring adversarial training, thereby degrading the model's robust performance\nand generalization capabilities. To address this issue, we propose Debiased\nHigh-Confidence Adversarial Training (DHAT), a novel approach that aligns\nadversarial logits with debiased high-confidence logits and restores proper\nattention by enhancing foreground logit orthogonality. Extensive experiments\ndemonstrate that DHAT achieves state-of-the-art robustness on both CIFAR and\nImageNet-1K benchmarks, while significantly improving generalization by\nmitigating the feature bias inherent in inverse adversarial training\napproaches. Code is available at https://github.com/KejiaZhang-Robust/DHAT.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2408.06079v2", "cate": "cs.CV", "date": "2024-08-12", "updated": "2025-07-09"}
{"id": "2412.15628", "title": "Can Input Attributions Explain Inductive Reasoning in In-Context Learning?", "authors": ["Mengyu Ye", "Tatsuki Kuribayashi", "Goro Kobayashi", "Jun Suzuki"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Findings of ACL 2025", "url": "http://arxiv.org/abs/2412.15628v5", "summary": "Interpreting the internal process of neural models has long been a challenge.\nThis challenge remains relevant in the era of large language models (LLMs) and\nin-context learning (ICL); for example, ICL poses a new issue of interpreting\nwhich example in the few-shot examples contributed to identifying/solving the\ntask. To this end, in this paper, we design synthetic diagnostic tasks of\ninductive reasoning, inspired by the generalization tests typically adopted in\npsycholinguistics. Here, most in-context examples are ambiguous w.r.t. their\nunderlying rule, and one critical example disambiguates it. The question is\nwhether conventional input attribution (IA) methods can track such a reasoning\nprocess, i.e., identify the influential example, in ICL. Our experiments\nprovide several practical findings; for example, a certain simple IA method\nworks the best, and the larger the model, the generally harder it is to\ninterpret the ICL with gradient-based IA methods.", "comment": "Findings of ACL 2025", "pdf_url": "http://arxiv.org/pdf/2412.15628v5", "cate": "cs.CL", "date": "2024-12-20", "updated": "2025-07-09"}
{"id": "1811.08522", "title": "Analysis of a hybridizable discontinuous Galerkin scheme for the tangential control of the Stokes system", "authors": ["Wei Gong", "Weiwei Hu", "Mariano Mateos", "John R. Singler", "Yangwen Zhang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      Definite version of the paper. Typo in third paragraph of page 7 corrected. References with urls", "url": "http://arxiv.org/abs/1811.08522v2", "summary": "We consider an unconstrained tangential Dirichlet boundary control problem\nfor the Stokes equations with an $ L^2 $ penalty on the boundary control. The\ncontribution of this paper is twofold. First, we obtain well-posedness and\nregularity results for the tangential Dirichlet control problem on a convex\npolygonal domain. The analysis contains new features not found in similar\nDirichlet control problems for the Poisson equation; an interesting result is\nthat the optimal control has higher local regularity on the individual edges of\nthe domain compared to the global regularity on the entire boundary. Second, we\npropose and analyze a hybridizable discontinuous Galerkin (HDG) method to\napproximate the solution. For convex polygonal domains, our theoretical\nconvergence rate for the control is optimal with respect to the global\nregularity on the entire boundary. We present numerical experiments to\ndemonstrate the performance of the HDG method.", "comment": "Definite version of the paper. Typo in third paragraph of page 7\n  corrected. References with urls", "pdf_url": "http://arxiv.org/pdf/1811.08522v2", "cate": "math.NA", "date": "2018-11-20", "updated": "2025-07-09"}
{"id": "2501.10487", "title": "Theme-Explanation Structure for Table Summarization using Large Language Models: A Case Study on Korean Tabular Data", "authors": ["TaeYoon Kwack", "Jisoo Kim", "Ki Yong Jung", "DongGeon Lee", "Heesun Park"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to TRL@ACL 2025", "url": "http://arxiv.org/abs/2501.10487v3", "summary": "Tables are a primary medium for conveying critical information in\nadministrative domains, yet their complexity hinders utilization by Large\nLanguage Models (LLMs). This paper introduces the Theme-Explanation\nStructure-based Table Summarization (Tabular-TX) pipeline, a novel approach\ndesigned to generate highly interpretable summaries from tabular data, with a\nspecific focus on Korean administrative documents. Current table summarization\nmethods often neglect the crucial aspect of human-friendly output. Tabular-TX\naddresses this by first employing a multi-step reasoning process to ensure deep\ntable comprehension by LLMs, followed by a journalist persona prompting\nstrategy for clear sentence generation. Crucially, it then structures the\noutput into a Theme Part (an adverbial phrase) and an Explanation Part (a\npredicative clause), significantly enhancing readability. Our approach\nleverages in-context learning, obviating the need for extensive fine-tuning and\nassociated labeled data or computational resources. Experimental results show\nthat Tabular-TX effectively processes complex table structures and metadata,\noffering a robust and efficient solution for generating human-centric table\nsummaries, especially in low-resource scenarios.", "comment": "Accepted to TRL@ACL 2025", "pdf_url": "http://arxiv.org/pdf/2501.10487v3", "cate": "cs.CL", "date": "2025-01-17", "updated": "2025-07-09"}
{"id": "2502.16380", "title": "Understanding Fixed Predictions via Confined Regions", "authors": ["Connor Lawless", "Tsui-Wei Weng", "Berk Ustun", "Madeleine Udell"], "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.16380v2", "summary": "Machine learning models can assign fixed predictions that preclude\nindividuals from changing their outcome. Existing approaches to audit fixed\npredictions do so on a pointwise basis, which requires access to an existing\ndataset of individuals and may fail to anticipate fixed predictions in\nout-of-sample data. This work presents a new paradigm to identify fixed\npredictions by finding confined regions of the feature space in which all\nindividuals receive fixed predictions. This paradigm enables the certification\nof recourse for out-of-sample data, works in settings without representative\ndatasets, and provides interpretable descriptions of individuals with fixed\npredictions. We develop a fast method to discover confined regions for linear\nclassifiers using mixed-integer quadratically constrained programming. We\nconduct a comprehensive empirical study of confined regions across diverse\napplications. Our results highlight that existing pointwise verification\nmethods fail to anticipate future individuals with fixed predictions, while our\nmethod both identifies them and provides an interpretable description.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.16380v2", "cate": "cs.LG", "date": "2025-02-22", "updated": "2025-07-08"}
{"id": "2409.13846", "title": "Multi-Modality Conditioned Variational U-Net for Field-of-View Extension in Brain Diffusion MRI", "authors": ["Zhiyuan Li", "Chenyu Gao", "Praitayini Kanakaraj", "Shunxing Bao", "Lianrui Zuo", "Michael E. Kim", "Nancy R. Newlin", "Gaurav Rudravaram", "Nazirah M. Khairi", "Yuankai Huo", "Kurt G. Schilling", "Walter A. Kukull", "Arthur W. Toga", "Derek B. Archer", "Timothy J. Hohman", "Bennett A. Landman"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.13846v2", "summary": "An incomplete field-of-view (FOV) in diffusion magnetic resonance imaging\n(dMRI) can severely hinder the volumetric and bundle analyses of whole-brain\nwhite matter connectivity. Although existing works have investigated imputing\nthe missing regions using deep generative models, it remains unclear how to\nspecifically utilize additional information from paired multi-modality data and\nwhether this can enhance the imputation quality and be useful for downstream\ntractography. To fill this gap, we propose a novel framework for imputing dMRI\nscans in the incomplete part of the FOV by integrating the learned diffusion\nfeatures in the acquired part of the FOV to the complete brain anatomical\nstructure. We hypothesize that by this design the proposed framework can\nenhance the imputation performance of the dMRI scans and therefore be useful\nfor repairing whole-brain tractography in corrupted dMRI scans with incomplete\nFOV. We tested our framework on two cohorts from different sites with a total\nof 96 subjects and compared it with a baseline imputation method that treats\nthe information from T1w and dMRI scans equally. The proposed framework\nachieved significant improvements in imputation performance, as demonstrated by\nangular correlation coefficient (p < 1E-5), and in downstream tractography\naccuracy, as demonstrated by Dice score (p < 0.01). Results suggest that the\nproposed framework improved imputation performance in dMRI scans by\nspecifically utilizing additional information from paired multi-modality data,\ncompared with the baseline method. The imputation achieved by the proposed\nframework enhances whole brain tractography, and therefore reduces the\nuncertainty when analyzing bundles associated with neurodegenerative.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.13846v2", "cate": "cs.CV", "date": "2024-09-20", "updated": "2025-07-09"}
{"id": "2412.16412", "title": "InfoTech Assistant: A Multimodal Conversational Agent for InfoTechnology Web Portal Queries", "authors": ["Sai Surya Gadiraju", "Duoduo Liao", "Akhila Kudupudi", "Santosh Kasula", "Charitha Chalasani"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Big Data 2024", "url": "http://arxiv.org/abs/2412.16412v2", "summary": "This pilot study presents the development of the InfoTech Assistant, a\ndomain-specific, multimodal chatbot engineered to address queries in bridge\nevaluation and infrastructure technology. By integrating web data scraping,\nlarge language models (LLMs), and Retrieval-Augmented Generation (RAG), the\nInfoTech Assistant provides accurate and contextually relevant responses. Data,\nincluding textual descriptions and images, are sourced from publicly available\ndocuments on the InfoTechnology website and organized in JSON format to\nfacilitate efficient querying. The architecture of the system includes an\nHTML-based interface and a Flask back end connected to the Llama 3.1 model via\nLLM Studio. Evaluation results show approximately 95 percent accuracy on\ndomain-specific tasks, with high similarity scores confirming the quality of\nresponse matching. This RAG-enhanced setup enables the InfoTech Assistant to\nhandle complex, multimodal queries, offering both textual and visual\ninformation in its responses. The InfoTech Assistant demonstrates strong\npotential as a dependable tool for infrastructure professionals, delivering\nhigh accuracy and relevance in its domain-specific outputs.", "comment": "Accepted by IEEE Big Data 2024", "pdf_url": "http://arxiv.org/pdf/2412.16412v2", "cate": "cs.CL", "date": "2024-12-21", "updated": "2025-07-09"}
{"id": "2112.13988", "title": "Active Learning Based Sampling for High-Dimensional Nonlinear Partial Differential Equations", "authors": ["Wenhan Gao", "Chunmei Wang"], "categories": ["math.NA", "cs.NA", "65M75, 35J25, 65N99"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      22 pages", "url": "http://arxiv.org/abs/2112.13988v2", "summary": "The deep-learning-based least squares method has shown successful results in\nsolving high-dimensional non-linear partial differential equations (PDEs).\nHowever, this method usually converges slowly. To speed up the convergence of\nthis approach, an active-learning-based sampling algorithm is proposed in this\npaper. This algorithm actively chooses the most informative training samples\nfrom a probability density function based on residual errors to facilitate\nerror reduction. In particular, points with larger residual errors will have\nmore chances of being selected for training. This algorithm imitates the human\nlearning process: learners are likely to spend more time repeatedly studying\nmistakes than other tasks they have correctly finished. A series of numerical\nresults are illustrated to demonstrate the effectiveness of our\nactive-learning-based sampling in high dimensions to speed up the convergence\nof the deep-learning-based least squares method.", "comment": "22 pages", "pdf_url": "http://arxiv.org/pdf/2112.13988v2", "cate": "math.NA", "date": "2021-12-28", "updated": "2025-07-08"}
{"id": "2502.12022", "title": "Teaching LLMs According to Their Aptitude: Adaptive Reasoning for Mathematical Problem Solving", "authors": ["Xin Xu", "Yan Xu", "Tianhao Chen", "Yuchen Yan", "Chengwu Liu", "Zaoyu Chen", "Yufei Wang", "Yichun Yin", "Yasheng Wang", "Lifeng Shang", "Qun Liu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2502.12022v3", "summary": "Existing approaches to mathematical reasoning with large language models\n(LLMs) rely on Chain-of-Thought (CoT) for generalizability or Tool-Integrated\nReasoning (TIR) for precise computation. While efforts have been made to\ncombine these methods, they primarily rely on post-selection or predefined\nstrategies, leaving an open question: whether LLMs can autonomously adapt their\nreasoning strategy based on their inherent capabilities. In this work, we\npropose TATA (Teaching LLMs According to Their Aptitude), an adaptive framework\nthat enables LLMs to personalize their reasoning strategy spontaneously,\naligning it with their intrinsic aptitude. TATA incorporates base-LLM-aware\ndata selection during supervised fine-tuning (SFT) to tailor training data to\nthe model's unique abilities. This approach equips LLMs to autonomously\ndetermine and apply the appropriate reasoning strategy at test time. We\nevaluate TATA through extensive experiments on six mathematical reasoning\nbenchmarks, using both general-purpose and math-specialized LLMs. Empirical\nresults demonstrate that TATA effectively combines the complementary strengths\nof CoT and TIR, achieving superior or comparable performance with improved\ninference efficiency compared to TIR alone. Further analysis underscores the\ncritical role of aptitude-aware data selection in enabling LLMs to make\neffective and adaptive reasoning decisions and align reasoning strategies with\nmodel capabilities.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2502.12022v3", "cate": "cs.CL", "date": "2025-02-17", "updated": "2025-07-09"}
{"id": "2502.19960", "title": "SeisMoLLM: Advancing Seismic Monitoring via Cross-modal Transfer with Pre-trained Large Language Model", "authors": ["Xinghao Wang", "Feng Liu", "Rui Su", "Zhihui Wang", "Lihua Fang", "Lianqing Zhou", "Lei Bai", "Wanli Ouyang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Code is available at this https URL . v2 fixed errors in the location figures", "url": "http://arxiv.org/abs/2502.19960v2", "summary": "Recent advances in deep learning have revolutionized seismic monitoring, yet\ndeveloping a foundation model that performs well across multiple complex tasks\nremains challenging, particularly when dealing with degraded signals or data\nscarcity. This work presents SeisMoLLM, the first foundation model that\nutilizes cross-modal transfer for seismic monitoring, to unleash the power of\nlarge-scale pre-training from a large language model without requiring direct\npre-training on seismic datasets. Through elaborate waveform tokenization and\nfine-tuning of pre-trained GPT-2 model, SeisMoLLM achieves state-of-the-art\nperformance on the DiTing and STEAD datasets across five critical tasks:\nback-azimuth estimation, epicentral distance estimation, magnitude estimation,\nphase picking, and first-motion polarity classification. It attains 36 best\nresults out of 43 task metrics and 12 top scores out of 16 few-shot\ngeneralization metrics, with many relative improvements ranging from 10% to\n50%. In addition to its superior performance, SeisMoLLM maintains efficiency\ncomparable to or even better than lightweight models in both training and\ninference. These findings establish SeisMoLLM as a promising foundation model\nfor practical seismic monitoring and highlight cross-modal transfer as an\nexciting new direction for earthquake studies, showcasing the potential of\nadvanced deep learning techniques to propel seismology research forward.", "comment": "Code is available at https://github.com/StarMoonWang/SeisMoLLM. v2\n  fixed errors in the location figures", "pdf_url": "http://arxiv.org/pdf/2502.19960v2", "cate": "cs.LG", "date": "2025-02-27", "updated": "2025-07-09"}
{"id": "2411.03511", "title": "Beyond Complete Shapes: A Quantitative Evaluation of 3D Shape Matching Algorithms", "authors": ["Viktoria Ehm", "Nafie El Amrani", "Yizheng Xie", "Lennart Bastian", "Maolin Gao", "Weikang Wang", "Lu Sang", "Dongliang Cao", "Tobias Weißberg", "Zorah Lähner", "Daniel Cremers", "Florian Bernard"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.03511v2", "summary": "Finding correspondences between 3D shapes is an important and long-standing\nproblem in computer vision, graphics and beyond. While approaches based on\nmachine learning dominate modern 3D shape matching, almost all existing\n(learning-based) methods require that at least one of the involved shapes is\ncomplete. In contrast, the most challenging and arguably most practically\nrelevant setting of matching partially observed shapes, is currently\nunderexplored. One important factor is that existing datasets contain only a\nsmall number of shapes (typically below 100), which are unable to serve\ndata-hungry machine learning approaches, particularly in the unsupervised\nregime. In addition, the type of partiality present in existing datasets is\noften artificial and far from realistic. To address these limitations and to\nencourage research on these relevant settings, we provide a generic and\nflexible framework for the procedural generation of challenging partial shape\nmatching scenarios. Our framework allows for a virtually infinite generation of\npartial shape matching instances from a finite set of shapes with complete\ngeometry. Further, we manually create cross-dataset correspondences between\nseven existing (complete geometry) shape matching datasets, leading to a total\nof 2543 shapes. Based on this, we propose several challenging partial benchmark\nsettings, for which we evaluate respective state-of-the-art methods as\nbaselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.03511v2", "cate": "cs.CV", "date": "2024-11-05", "updated": "2025-07-09"}
{"id": "2412.18497", "title": "Neuron-Level Differentiation of Memorization and Generalization in Large Language Models", "authors": ["Ko-Wei Huang", "Yi-Fu Fu", "Ching-Yu Tsai", "Yu-Chieh Tu", "Tzu-Ling Cheng", "Cheng-Yu Lin", "Yi-Ting Yang", "Heng-Yi Liu", "Keng-Te Liao", "Da-Cheng Juan", "Shou-De Lin"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.18497v2", "summary": "We investigate how Large Language Models (LLMs) distinguish between\nmemorization and generalization at the neuron level. Through carefully designed\ntasks, we identify distinct neuron subsets responsible for each behavior.\nExperiments on both a GPT-2 model trained from scratch and a pretrained\nLLaMA-3.2 model fine-tuned with LoRA show consistent neuron-level\nspecialization. We further demonstrate that inference-time interventions on\nthese neurons can steer the model's behavior toward memorization or\ngeneralization. To assess robustness, we evaluate intra-task and inter-task\nconsistency, confirming that these neuron-behavior associations reflect\ngeneralizable patterns rather than dataset-specific artifacts. Our findings\nreveal modular structure in LLMs and enable controlling memorization and\ngeneralization behaviors at inference time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.18497v2", "cate": "cs.CL", "date": "2024-12-24", "updated": "2025-07-09"}
{"id": "2308.05423", "title": "On the Stability and Convergence of Physics Informed Neural Networks", "authors": ["Dimitrios Gazoulis", "Ioannis Gkanis", "Charalambos G. Makridakis"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2308.05423v2", "summary": "Physics Informed Neural Networks is a numerical method which uses neural\nnetworks to approximate solutions of partial differential equations. It has\nreceived a lot of attention and is currently used in numerous physical and\nengineering problems. The mathematical understanding of these methods is\nlimited, and in particular, it seems that, a consistent notion of stability is\nmissing. Towards addressing this issue we consider model problems of partial\ndifferential equations, namely linear elliptic and parabolic PDEs. Motivated by\ntools of nonlinear calculus of variations we systematically show that\ncoercivity of the energies and associated compactness provide a consistent\nframework for stability. For time discrete training we show that if these\nproperties fail to hold then methods may become unstable. Furthermore, using\ntools of $\\Gamma$- convergence we provide new convergence results for weak\nsolutions by only requiring that the neural network spaces are chosen to have\nsuitable approximation properties. While our analysis is motivated by neural\nnetwork-based approximation spaces, the framework developed here is applicable\nto any class of discrete functions satisfying the relevant approximation\nproperties, and hence may serve as a foundation for the broader study of\nvariational nonlinear PDE solvers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2308.05423v2", "cate": "math.NA", "date": "2023-08-10", "updated": "2025-07-09"}
{"id": "2502.12446", "title": "Multi-Attribute Steering of Language Models via Targeted Intervention", "authors": ["Duy Nguyen", "Archiki Prasad", "Elias Stengel-Eskin", "Mohit Bansal"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025 camera-ready, code link: this https URL", "url": "http://arxiv.org/abs/2502.12446v2", "summary": "Inference-time intervention (ITI) has emerged as a promising method for\nsteering large language model (LLM) behavior in a particular direction (e.g.,\nimproving helpfulness) by intervening on token representations without costly\nupdates to the LLM's parameters. However, existing ITI approaches fail to scale\nto multi-attribute settings with conflicts, such as enhancing helpfulness while\nalso reducing toxicity. To address this, we introduce Multi-Attribute Targeted\nSteering (MAT-Steer), a novel steering framework designed for selective\ntoken-level intervention across multiple attributes. MAT-Steer learns steering\nvectors using an alignment objective that shifts the model's internal\nrepresentations of undesirable outputs closer to those of desirable ones while\nenforcing sparsity and orthogonality among vectors for different attributes,\nthereby reducing inter-attribute conflicts. We evaluate MAT-Steer in two\ndistinct settings: (i) on question answering (QA) tasks where we balance\nattributes like truthfulness, bias, and toxicity; (ii) on generative tasks\nwhere we simultaneously improve attributes like helpfulness, correctness, and\ncoherence. MAT-Steer outperforms existing ITI and parameter-efficient\nfine-tuning approaches across both task types (e.g., 3% average accuracy gain\nacross QA tasks and 55.82% win rate against the best ITI baseline).", "comment": "ACL 2025 camera-ready, code link:\n  https://github.com/duykhuongnguyen/MAT-Steer", "pdf_url": "http://arxiv.org/pdf/2502.12446v2", "cate": "cs.CL", "date": "2025-02-18", "updated": "2025-07-09"}
{"id": "2502.20853", "title": "Oscillation-Reduced MXFP4 Training for Vision Transformers", "authors": ["Yuxiang Chen", "Haocheng Xi", "Jun Zhu", "Jianfei Chen"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.20853v2", "summary": "Pre-training Transformers in FP4 precision is becoming a promising approach\nto gain substantial speedup, but it comes with a considerable loss of accuracy.\nMicroscaling (MX) data format provides a fine-grained per-group quantization\nmethod to improve the representation ability of the FP4 format and is supported\nby the next-generation Blackwell GPU architecture. However, training with MXFP4\ndata format still results in significant degradation and there is a lack of\nsystematic research on the reason.\n  In this work, we propose a novel training method TetraJet for a more accurate\nFP4 training. We comprehensively evaluate all of the quantizers involved in the\ntraining, and identify the weight oscillation problem in the forward pass as\nthe main source of the degradation in MXFP4 training. Therefore, we introduce\ntwo novel methods, EMA Quantizer (Q-EMA) and Adaptive Ramping Optimizer\n(Q-Ramping), to resolve the oscillation problem. Extensive experiments on\nVision Transformers demonstrate that TetraJet consistently outperforms the\nexisting 4-bit training methods, and Q-EMA & Q-Ramping can provide additional\nenhancement by effectively reducing oscillation. We decreased the accuracy\ndegradation by more than $50\\%$ compared to the baseline, and can even achieve\ncompetitive performance compared to full precision training. The codes are\navailable at https://github.com/thu-ml/TetraJet-MXFP4Training", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.20853v2", "cate": "cs.LG", "date": "2025-02-28", "updated": "2025-07-09"}
{"id": "2411.04709", "title": "TIP-I2V: A Million-Scale Real Text and Image Prompt Dataset for Image-to-Video Generation", "authors": ["Wenhao Wang", "Yi Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2411.04709v2", "summary": "Video generation models are revolutionizing content creation, with\nimage-to-video models drawing increasing attention due to their enhanced\ncontrollability, visual consistency, and practical applications. However,\ndespite their popularity, these models rely on user-provided text and image\nprompts, and there is currently no dedicated dataset for studying these\nprompts. In this paper, we introduce TIP-I2V, the first large-scale dataset of\nover 1.70 million unique user-provided Text and Image Prompts specifically for\nImage-to-Video generation. Additionally, we provide the corresponding generated\nvideos from five state-of-the-art image-to-video models. We begin by outlining\nthe time-consuming and costly process of curating this large-scale dataset.\nNext, we compare TIP-I2V to two popular prompt datasets, VidProM\n(text-to-video) and DiffusionDB (text-to-image), highlighting differences in\nboth basic and semantic information. This dataset enables advancements in\nimage-to-video research. For instance, to develop better models, researchers\ncan use the prompts in TIP-I2V to analyze user preferences and evaluate the\nmulti-dimensional performance of their trained models; and to enhance model\nsafety, they may focus on addressing the misinformation issue caused by\nimage-to-video models. The new research inspired by TIP-I2V and the differences\nwith existing datasets emphasize the importance of a specialized image-to-video\nprompt dataset. The project is available at https://tip-i2v.github.io.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2411.04709v2", "cate": "cs.CV", "date": "2024-11-05", "updated": "2025-07-09"}
{"id": "2502.05167", "title": "NoLiMa: Long-Context Evaluation Beyond Literal Matching", "authors": ["Ali Modarressi", "Hanieh Deilamsalehy", "Franck Dernoncourt", "Trung Bui", "Ryan A. Rossi", "Seunghyun Yoon", "Hinrich Schütze"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at ICML 2025", "url": "http://arxiv.org/abs/2502.05167v3", "summary": "Recent large language models (LLMs) support long contexts ranging from 128K\nto 1M tokens. A popular method for evaluating these capabilities is the\nneedle-in-a-haystack (NIAH) test, which involves retrieving a \"needle\"\n(relevant information) from a \"haystack\" (long irrelevant context). Extensions\nof this approach include increasing distractors, fact chaining, and in-context\nreasoning. However, in these benchmarks, models can exploit existing literal\nmatches between the needle and haystack to simplify the task. To address this,\nwe introduce NoLiMa, a benchmark extending NIAH with a carefully designed\nneedle set, where questions and needles have minimal lexical overlap, requiring\nmodels to infer latent associations to locate the needle within the haystack.\nWe evaluate 13 popular LLMs that claim to support contexts of at least 128K\ntokens. While they perform well in short contexts (<1K), performance degrades\nsignificantly as context length increases. At 32K, for instance, 11 models drop\nbelow 50% of their strong short-length baselines. Even GPT-4o, one of the\ntop-performing exceptions, experiences a reduction from an almost-perfect\nbaseline of 99.3% to 69.7%. Our analysis suggests these declines stem from the\nincreased difficulty the attention mechanism faces in longer contexts when\nliteral matches are absent, making it harder to retrieve relevant information.\nEven models enhanced with reasoning capabilities or CoT prompting struggle to\nmaintain performance in long contexts. We publicly release the dataset and\nevaluation code at https://github.com/adobe-research/NoLiMa.", "comment": "Accepted at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2502.05167v3", "cate": "cs.CL", "date": "2025-02-07", "updated": "2025-07-09"}
{"id": "2402.12831", "title": "A sparse hierarchical $hp$-finite element method on disks and annuli", "authors": ["Ioannis P. A. Papadopoulos", "Sheehan Olver"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.12831v3", "summary": "We develop a sparse hierarchical $hp$-finite element method ($hp$-FEM) for\nthe Helmholtz equation with variable coefficients posed on a two-dimensional\ndisk or annulus. The mesh is an inner disk cell (omitted if on an annulus\ndomain) and concentric annuli cells. The discretization preserves the Fourier\nmode decoupling of rotationally invariant operators, such as the Laplacian,\nwhich manifests as block diagonal mass and stiffness matrices. Moreover, the\nmatrices have a sparsity pattern independent of the order of the discretization\nand admit an optimal complexity factorization. The sparse $hp$-FEM can handle\nradial discontinuities in the right-hand side and in rotationally invariant\nHelmholtz coefficients. Rotationally anisotropic coefficients that are\napproximated by low-degree polynomials in Cartesian coordinates also result in\nsparse linear systems. We consider examples such as a high-frequency Helmholtz\nequation with radial discontinuities and rotationally anisotropic coefficients,\nsingular source terms, the time-dependent Schr\\\"odinger equation, and an\nextension to a three-dimensional cylinder domain, with a quasi-optimal solve,\nvia the Alternating Direction Implicit (ADI) algorithm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.12831v3", "cate": "math.NA", "date": "2024-02-20", "updated": "2025-07-09"}
{"id": "2503.05763", "title": "GMLM: Bridging Graph Neural Networks and Language Models for Heterophilic Node Classification", "authors": ["Aarush Sinha"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.05763v5", "summary": "Integrating powerful but computationally expensive Pre-trained Language\nModels (PLMs) with Graph Neural Networks (GNNs) is a key challenge, especially\non text-rich heterophilic graphs. We propose the Graph Masked Language Model\n(GMLM), a framework designed for the efficient and effective fusion of graph\nstructure and text semantics. GMLM employs a two-stage process: first, a\ncontrastive pre-training stage with a novel soft masking technique builds a\nrobust multi-scale GNN; second, an end-to-end fine-tuning stage uses a dynamic\nactive node selection strategy for scalability and a bi-directional\ncross-attention module for deep fusion. Experiments on five heterophilic\nbenchmarks show GMLM achieves state-of-the-art results on four, significantly\noutperforming prior GNN and large LLM-based methods. For instance, it improves\naccuracy on the Texas dataset by over 8\\% and on Wisconsin by nearly 5\\%. Our\nwork demonstrates that a sophisticated, deeply-integrated architecture can be\nmore effective and efficient than larger, general-purpose models for text-rich\ngraph representation learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.05763v5", "cate": "cs.CL", "date": "2025-02-24", "updated": "2025-07-09"}
{"id": "2503.08942", "title": "Extragradient Preference Optimization (EGPO): Beyond Last-Iterate Convergence for Nash Learning from Human Feedback", "authors": ["Runlong Zhou", "Maryam Fazel", "Simon S. Du"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      COLM 2025", "url": "http://arxiv.org/abs/2503.08942v3", "summary": "Reinforcement learning from human feedback (RLHF) has become essential for\nimproving language model capabilities, but traditional approaches rely on the\nassumption that human preferences follow a transitive Bradley-Terry model. This\nassumption fails to capture the non-transitive nature of populational human\npreferences. Nash learning from human feedback (NLHF), targeting non-transitive\npreferences, is a problem of computing the Nash equilibrium (NE) of the\ntwo-player constant-sum game defined by the human preference. We introduce\nExtragradient preference optimization (EGPO), a novel algorithm for NLHF\nachieving last-iterate linear convergence to the NE of KL-regularized games and\npolynomial convergence to the NE of original games, while being robust to\nnoise. Unlike previous approaches that rely on nested optimization, we derive\nan equivalent implementation using gradients of an online variant of the\nidentity preference optimization (IPO) loss, enabling more faithful\nimplementation for neural networks. Our empirical evaluations demonstrate\nEGPO's superior performance over baseline methods when training for the same\nnumber of epochs, as measured by pairwise win-rates using the ground truth\npreference. These results validate both the theoretical strengths and practical\nadvantages of EGPO for language model alignment with non-transitive human\npreferences.", "comment": "COLM 2025", "pdf_url": "http://arxiv.org/pdf/2503.08942v3", "cate": "cs.LG", "date": "2025-03-11", "updated": "2025-07-09"}
{"id": "2411.09572", "title": "Dynamic Reconstruction of Hand-Object Interaction with Distributed Force-aware Contact Representation", "authors": ["Zhenjun Yu", "Wenqiang Xu", "Pengfei Xie", "Yutong Li", "Brian W. Anthony", "Zhuorui Zhang", "Cewu Lu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2411.09572v2", "summary": "We present ViTaM-D, a novel visual-tactile framework for reconstructing\ndynamic hand-object interaction with distributed tactile sensing to enhance\ncontact modeling. Existing methods, relying solely on visual inputs, often fail\nto capture occluded interactions and object deformation. To address this, we\nintroduce DF-Field, a distributed force-aware contact representation leveraging\nkinetic and potential energy in hand-object interactions. ViTaM-D first\nreconstructs interactions using a visual network with contact constraint, then\nrefines contact details through force-aware optimization, improving object\ndeformation modeling. To evaluate deformable object reconstruction, we\nintroduce the HOT dataset, featuring 600 hand-object interaction sequences in a\nhigh-precision simulation environment. Experiments on DexYCB and HOT datasets\nshow that ViTaM-D outperforms state-of-the-art methods in reconstruction\naccuracy for both rigid and deformable objects. DF-Field also proves more\neffective in refining hand poses and enhancing contact modeling than previous\nrefinement methods. The code, models, and datasets are available at\nhttps://sites.google.com/view/vitam-d/.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2411.09572v2", "cate": "cs.CV", "date": "2024-11-14", "updated": "2025-07-09"}
{"id": "2502.11703", "title": "CMQCIC-Bench: A Chinese Benchmark for Evaluating Large Language Models in Medical Quality Control Indicator Calculation", "authors": ["Guangya Yu", "Yanhao Li", "Zongying Jiang", "Yuxiong Jin", "Li Dai", "Yupian Lin", "Ruihui Hou", "Weiyan Zhang", "Yongqi Fan", "Qi Ye", "Jingping Liu", "Tong Ruan"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      2025 ACL Findings", "url": "http://arxiv.org/abs/2502.11703v2", "summary": "Medical quality control indicators are essential to assess the qualifications\nof healthcare institutions for medical services. With the impressive\nperformance of large language models (LLMs) like GPT-4 in the medical field,\nleveraging these technologies for the Medical Quality Control Indicator\nCalculation (MQCIC) presents a promising approach. In this work, (1) we\nintroduce a real-world task MQCIC and propose an open-source Chinese electronic\nmedical records (EMRs)-based dataset (CMQCIC-Bench) comprising 785 instances\nand 76 indicators. (2) We propose a semi-automatic method to enhance the rule\nrepresentation. Then we propose the Clinical Facts-based Inferential Rule\n(CF-IR) method that disentangles the clinical fact verification and inferential\nrule reasoning actions. (3) We conduct comprehensive experiments on 20\nrepresentative LLMs, covering general and medical models. Our findings reveal\nthat CF-IR outperforms Chain-of-Thought methods in MQCIC tasks. (4) We conduct\nan error analysis and investigate the capabilities of clinical fact\nverification and inferential rule reasoning, providing insights to improve\nperformance in the MQCIC further. The dataset and code is available in this\nrepository https://github.com/YuY-2001/C-MQCIC.", "comment": "2025 ACL Findings", "pdf_url": "http://arxiv.org/pdf/2502.11703v2", "cate": "cs.CL", "date": "2025-02-17", "updated": "2025-07-09"}
{"id": "2405.09005", "title": "Cons-training Tensor Networks: Embedding and Optimization Over Discrete Linear Constraints", "authors": ["Javier Lopez-Piqueres", "Jing Chen"], "categories": ["math.NA", "cs.LG", "cs.NA", "quant-ph"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.09005v5", "summary": "In this study, we introduce a novel family of tensor networks, termed\nconstrained matrix product states (MPS), designed to incorporate exactly\narbitrary discrete linear constraints, including inequalities, into sparse\nblock structures. These tensor networks are particularly tailored for modeling\ndistributions with support strictly over the feasible space, offering benefits\nsuch as reducing the search space in optimization problems, alleviating\noverfitting, improving training efficiency, and decreasing model size. Central\nto our approach is the concept of a quantum region, an extension of quantum\nnumbers traditionally used in U(1) symmetric tensor networks, adapted to\ncapture any linear constraint, including the unconstrained scenario. We further\ndevelop a novel canonical form for these new MPS, which allow for the merging\nand factorization of tensor blocks according to quantum region fusion rules and\npermit optimal truncation schemes. Utilizing this canonical form, we apply an\nunsupervised training strategy to optimize arbitrary objective functions\nsubject to discrete linear constraints. Our method's efficacy is demonstrated\nby solving the quadratic knapsack problem, achieving superior performance\ncompared to a leading nonlinear integer programming solver. Additionally, we\nanalyze the complexity and scalability of our approach, demonstrating its\npotential in addressing complex constrained combinatorial optimization\nproblems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.09005v5", "cate": "math.NA", "date": "2024-05-15", "updated": "2025-07-09"}
{"id": "2507.06352", "title": "Revisiting Chien-Hrones-Reswick Method for an Analytical Solution", "authors": ["Senol Gulgonul"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      7 pages, 3 figures, 1 table. This work is licensed under CC BY-NC-ND 4.0. For commercial licensing, contact the author", "url": "http://arxiv.org/abs/2507.06352v1", "summary": "This study presents an analytical method for tuning PI controllers in\nFirst-Order with Time Delay (FOTD) systems, leveraging the Lambert W function.\nThe Lambert W function enables exact pole placement, yielding analytical\nexpressions for PI gains. The proposed approach identifies a critical condition\nthat achieves a step response without overshoot with minimum settling time,\nwhile also providing explicit tuning rules for systems where controlled\novershoot is specified. The method demonstrates strong agreement with\nestablished empirical Chien-Hrones-Reswick tuning rules for both\nnon-overshooting and overshooting cases, bridging the gap between theoretical\nanalysis and empirical results.", "comment": "7 pages, 3 figures, 1 table. This work is licensed under CC BY-NC-ND\n  4.0. For commercial licensing, contact the author", "pdf_url": "http://arxiv.org/pdf/2507.06352v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2503.06505", "title": "DynamicID: Zero-Shot Multi-ID Image Personalization with Flexible Facial Editability", "authors": ["Xirui Hu", "Jiahao Wang", "Hao Chen", "Weizhan Zhang", "Benqi Wang", "Yikun Li", "Haishun Nan"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2503.06505v2", "summary": "Recent advancements in text-to-image generation have spurred interest in\npersonalized human image generation, which aims to create novel images\nfeaturing specific human identities as reference images indicate. Although\nexisting methods achieve high-fidelity identity preservation, they often\nstruggle with limited multi-ID usability and inadequate facial editability. We\npresent DynamicID, a tuning-free framework supported by a dual-stage training\nparadigm that inherently facilitates both single-ID and multi-ID personalized\ngeneration with high fidelity and flexible facial editability. Our key\ninnovations include: 1) Semantic-Activated Attention (SAA), which employs\nquery-level activation gating to minimize disruption to the original model when\ninjecting ID features and achieve multi-ID personalization without requiring\nmulti-ID samples during training. 2) Identity-Motion Reconfigurator (IMR),\nwhich leverages contrastive learning to effectively disentangle and re-entangle\nfacial motion and identity features, thereby enabling flexible facial editing.\nAdditionally, we have developed a curated VariFace-10k facial dataset,\ncomprising 10k unique individuals, each represented by 35 distinct facial\nimages. Experimental results demonstrate that DynamicID outperforms\nstate-of-the-art methods in identity fidelity, facial editability, and multi-ID\npersonalization capability.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.06505v2", "cate": "cs.CV", "date": "2025-03-09", "updated": "2025-07-09"}
{"id": "2503.18731", "title": "Thermalizer: Stable autoregressive neural emulation of spatiotemporal chaos", "authors": ["Chris Pedersen", "Laure Zanna", "Joan Bruna"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      To appear at ICML'25", "url": "http://arxiv.org/abs/2503.18731v2", "summary": "Autoregressive surrogate models (or \\textit{emulators}) of spatiotemporal\nsystems provide an avenue for fast, approximate predictions, with broad\napplications across science and engineering. At inference time, however, these\nmodels are generally unable to provide predictions over long time rollouts due\nto accumulation of errors leading to diverging trajectories. In essence,\nemulators operate out of distribution, and controlling the online distribution\nquickly becomes intractable in large-scale settings. To address this\nfundamental issue, and focusing on time-stationary systems admitting an\ninvariant measure, we leverage diffusion models to obtain an implicit estimator\nof the score of this invariant measure. We show that this model of the score\nfunction can be used to stabilize autoregressive emulator rollouts by applying\non-the-fly denoising during inference, a process we call\n\\textit{thermalization}. Thermalizing an emulator rollout is shown to extend\nthe time horizon of stable predictions by an order of magnitude in complex\nsystems exhibiting turbulent and chaotic behavior, opening up a novel\napplication of diffusion models in the context of neural emulation.", "comment": "To appear at ICML'25", "pdf_url": "http://arxiv.org/pdf/2503.18731v2", "cate": "cs.LG", "date": "2025-03-24", "updated": "2025-07-08"}
{"id": "2411.12510", "title": "PR-ENDO: Physically Based Relightable Gaussian Splatting for Endoscopy", "authors": ["Joanna Kaleta", "Weronika Smolak-Dyżewska", "Dawid Malarz", "Diego Dall'Alba", "Przemysław Korzeniowski", "Przemysław Spurek"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.12510v2", "summary": "Endoluminal endoscopic procedures are essential for diagnosing colorectal\ncancer and other severe conditions in the digestive tract, urogenital system,\nand airways. 3D reconstruction and novel-view synthesis from endoscopic images\nare promising tools for enhancing diagnosis. Moreover, integrating\nphysiological deformations and interaction with the endoscope enables the\ndevelopment of simulation tools from real video data. However, constrained\ncamera trajectories and view-dependent lighting create artifacts, leading to\ninaccurate or overfitted reconstructions. We present PR-ENDO, a novel 3D\nreconstruction framework leveraging the unique property of endoscopic imaging,\nwhere a single light source is closely aligned with the camera. Our method\nseparates light effects from tissue properties. PR-ENDO enhances 3D Gaussian\nSplatting with a physically based relightable model. We boost the traditional\nlight transport formulation with a specialized MLP capturing complex\nlight-related effects while ensuring reduced artifacts and better\ngeneralization across novel views. PR-ENDO achieves superior reconstruction\nquality compared to baseline methods on both public and in-house datasets.\nUnlike existing approaches, PR-ENDO enables tissue modifications while\npreserving a physically accurate response to light, making it closer to\nreal-world clinical use.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.12510v2", "cate": "cs.CV", "date": "2024-11-19", "updated": "2025-07-09"}
{"id": "2502.14541", "title": "LLM-based User Profile Management for Recommender System", "authors": ["Seunghwan Bang", "Hwanjun Song"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted GENNEXT@SIGIR'25 Workshop", "url": "http://arxiv.org/abs/2502.14541v2", "summary": "The rapid advancement of Large Language Models (LLMs) has opened new\nopportunities in recommender systems by enabling zero-shot recommendation\nwithout conventional training. Despite their potential, most existing works\nrely solely on users' purchase histories, leaving significant room for\nimprovement by incorporating user-generated textual data, such as reviews and\nproduct descriptions. Addressing this gap, we propose PURE, a novel LLM-based\nrecommendation framework that builds and maintains evolving user profiles by\nsystematically extracting and summarizing key information from user reviews.\nPURE consists of three core components: a Review Extractor for identifying user\npreferences and key product features, a Profile Updater for refining and\nupdating user profiles, and a Recommender for generating personalized\nrecommendations using the most current profile. To evaluate PURE, we introduce\na continuous sequential recommendation task that reflects real-world scenarios\nby adding reviews over time and updating predictions incrementally. Our\nexperimental results on Amazon datasets demonstrate that PURE outperforms\nexisting LLM-based methods, effectively leveraging long-term user information\nwhile managing token limitations.", "comment": "Accepted GENNEXT@SIGIR'25 Workshop", "pdf_url": "http://arxiv.org/pdf/2502.14541v2", "cate": "cs.CL", "date": "2025-02-20", "updated": "2025-07-09"}
{"id": "2405.10751", "title": "Some remarks on a mathematical model for water flow in porous media with competition between transport and diffusion", "authors": ["Judita Runcziková", "Jan Chleboun", "Chiara Gavioli", "Pavel Krejčí"], "categories": ["math.NA", "cs.NA", "math.AP"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2405.10751v2", "summary": "The contribution deals with the mathematical modelling of fluid flow in\nporous media, in particular water flow in soils, with the aim of describing the\ncompetition between transport and diffusion. The analysis is based on a\nmathematical model developed by B. Detmann, C. Gavioli, and P. Krej\\v{c}\\'i, in\nwhich the effects of gravity are included in a novel way. The model consists of\na nonlinear partial differential equation describing both the diffusion and the\ngravitational transport of water. Although analytical solutions can be obtained\nfor some special cases, only numerical solutions are available in more general\nsituations. The solving algorithm is based on a time discretisation and the\nfinite element method, and is written in Matlab. The results of the numerical\nsimulations are shown and the behaviour of the model is discussed.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2405.10751v2", "cate": "math.NA", "date": "2024-05-17", "updated": "2025-07-09"}
{"id": "2507.06389", "title": "How Complex is a Complex Network? Insights from Linear Systems Theory", "authors": ["Giacomo Baggio", "Marco Fabris"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 pages, 2 figures, 1 table, published on Control Systems Letters (L-CSS), to be presented at the 64th IEEE Conference on Decision and Control, IEEE Control Systems Letters (2025)", "url": "http://arxiv.org/abs/2507.06389v1", "summary": "This paper leverages linear systems theory to propose a principled measure of\ncomplexity for network systems. We focus on a network of first-order scalar\nlinear systems interconnected through a directed graph. By locally filtering\nout the effect of nodal dynamics in the interconnected system, we propose a new\nquantitative index of network complexity rooted in the notion of McMillan\ndegree of a linear system. First, we show that network systems with the same\ninterconnection structure share the same complexity index for almost all\nchoices of their interconnection weights. Then, we investigate the dependence\nof the proposed index on the topology of the network and the pattern of\nheterogeneity of the nodal dynamics. Specifically, we find that the index\ndepends on the matching number of subgraphs identified by nodal dynamics of\ndifferent nature, highlighting the joint impact of network architecture and\ncomponent diversity on overall system complexity.", "comment": "6 pages, 2 figures, 1 table, published on Control Systems Letters\n  (L-CSS), to be presented at the 64th IEEE Conference on Decision and Control,\n  IEEE Control Systems Letters (2025)", "pdf_url": "http://arxiv.org/pdf/2507.06389v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2503.08120", "title": "UniF$^2$ace: Fine-grained Face Understanding and Generation with Unified Multimodal Models", "authors": ["Junzhe Li", "Xuerui Qiu", "Linrui Xu", "Liya Guo", "Delin Qu", "Tingting Long", "Chun Fan", "Ming Li"], "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.08120v3", "summary": "Unified multimodal models (UMMs) have emerged as a powerful paradigm in\nfoundational computer vision research, demonstrating significant potential in\nboth image understanding and generation. However, existing research in the face\ndomain primarily focuses on $\\textbf{coarse}$ facial attribute understanding,\nwith limited capacity to handle $\\textbf{fine-grained}$ facial attributes and\nwithout addressing generation capabilities. To overcome these limitations, we\npropose UniF$^2$ace, the first UMM tailored specifically for fine-grained face\nunderstanding and generation. In general, we train UniF$^2$ace on a\nself-constructed, specialized dataset utilizing two mutually beneficial\ndiffusion techniques and a two-level mixture-of-experts architecture.\nSpecifically, we first build a large-scale facial dataset, UniF$^2$ace-130K,\nwhich contains 130K image-text pairs with one million question-answering pairs\nthat span a wide range of facial attributes. Second, we establish a theoretical\nconnection between discrete diffusion score matching and masked generative\nmodels, optimizing both evidence lower bounds simultaneously, which\nsignificantly improves the model's ability to synthesize facial details.\nFinally, we introduce both token-level and sequence-level mixture-of-experts,\nenabling efficient fine-grained representation learning for both understanding\nand generation tasks. Extensive experiments on UniF$^2$ace-130K demonstrate\nthat UniF$^2$ace outperforms existing UMMs and generative models, achieving\nsuperior performance across both understanding and generation tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.08120v3", "cate": "cs.CV", "date": "2025-03-11", "updated": "2025-07-09"}
{"id": "2504.04320", "title": "Causal Inference Isn't Special: Why It's Just Another Prediction Problem", "authors": ["Carlos Fernández-Loría"], "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.04320v3", "summary": "Causal inference is often portrayed as fundamentally distinct from predictive\nmodeling, with its own terminology, goals, and intellectual challenges. But at\nits core, causal inference is simply a structured instance of prediction under\ndistribution shift. In both cases, we begin with labeled data from a source\ndomain and seek to generalize to a target domain where outcomes are not\nobserved. The key difference is that in causal inference, the labels --\npotential outcomes -- are selectively observed based on treatment assignment,\nintroducing bias that must be addressed through assumptions. This perspective\nreframes causal estimation as a familiar generalization problem and highlights\nhow techniques from predictive modeling, such as reweighting and domain\nadaptation, apply directly to causal tasks. It also clarifies that causal\nassumptions are not uniquely strong -- they are simply more explicit. By\nviewing causal inference through the lens of prediction, we demystify its\nlogic, connect it to familiar tools, and make it more accessible to\npractitioners and educators alike.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.04320v3", "cate": "cs.LG", "date": "2025-04-06", "updated": "2025-07-09"}
{"id": "2411.12981", "title": "GazeGaussian: High-Fidelity Gaze Redirection with 3D Gaussian Splatting", "authors": ["Xiaobao Wei", "Peng Chen", "Guangyu Li", "Ming Lu", "Hui Chen", "Feng Tian"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2411.12981v2", "summary": "Gaze estimation encounters generalization challenges when dealing with\nout-of-distribution data. To address this problem, recent methods use neural\nradiance fields (NeRF) to generate augmented data. However, existing methods\nbased on NeRF are computationally expensive and lack facial details. 3D\nGaussian Splatting (3DGS) has become the prevailing representation of neural\nfields. While 3DGS has been extensively examined in head avatars, it faces\nchallenges with accurate gaze control and generalization across different\nsubjects. In this work, we propose GazeGaussian, the first high-fidelity gaze\nredirection method that uses a two-stream 3DGS model to represent the face and\neye regions separately. Leveraging the unstructured nature of 3DGS, we develop\na novel representation of the eye for rigid eye rotation based on the target\ngaze direction. To enable synthesis generalization across various subjects, we\nintegrate an expression-guided module to inject subject-specific information\ninto the neural renderer. Comprehensive experiments show that GazeGaussian\noutperforms existing methods in rendering speed, gaze redirection accuracy, and\nfacial synthesis across multiple datasets. The code is available at:\nhttps://ucwxb.github.io/GazeGaussian.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2411.12981v2", "cate": "cs.CV", "date": "2024-11-20", "updated": "2025-07-09"}
{"id": "2502.18890", "title": "TokenSwift: Lossless Acceleration of Ultra Long Sequence Generation", "authors": ["Tong Wu", "Junzhe Shen", "Zixia Jia", "Yuxuan Wang", "Zilong Zheng"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted By ICML25", "url": "http://arxiv.org/abs/2502.18890v2", "summary": "Generating ultra-long sequences with large language models (LLMs) has become\nincreasingly crucial but remains a highly time-intensive task, particularly for\nsequences up to 100K tokens. While traditional speculative decoding methods\nexist, simply extending their generation limits fails to accelerate the process\nand can be detrimental. Through an in-depth analysis, we identify three major\nchallenges hindering efficient generation: frequent model reloading, dynamic\nkey-value (KV) management and repetitive generation. To address these issues,\nwe introduce TOKENSWIFT, a novel framework designed to substantially accelerate\nthe generation process of ultra-long sequences while maintaining the target\nmodel's inherent quality. Experimental results demonstrate that TOKENSWIFT\nachieves over 3 times speedup across models of varying scales (1.5B, 7B, 8B,\n14B) and architectures (MHA, GQA). This acceleration translates to hours of\ntime savings for ultra-long sequence generation, establishing TOKENSWIFT as a\nscalable and effective solution at unprecedented lengths. Code can be found at\nhttps://github.com/bigai-nlco/TokenSwift.", "comment": "Accepted By ICML25", "pdf_url": "http://arxiv.org/pdf/2502.18890v2", "cate": "cs.CL", "date": "2025-02-26", "updated": "2025-07-09"}
{"id": "2408.14019", "title": "Structured Backward Error Analysis for Double Saddle Point Problems", "authors": ["Sk. Safique Ahmad", "Pinki Khatun"], "categories": ["math.NA", "cs.NA", "15A06, 65F10, 65F99"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.14019v2", "summary": "Backward error (BE) analysis emerges as a powerful tool for assessing the\nbackward stability and strong backward stability of numerical algorithms. In\nthis paper, we explore structured BEs for a class of double saddle point\nproblems (DSPPs), aiming to assess the strong backward stability of numerical\nalgorithms devised to find their solution. Our investigations preserve the\ninherent matrix structure and sparsity pattern in the corresponding\nperturbation matrices and derive explicit formulae for the structure BEs.\nMoreover, we provide formulae for the structure-preserving minimal perturbation\nmatrices for which the structured BE is attained. Utilizing the relationship\nbetween the DSPP and the least squares problem with equality constraints (LSE),\nwe derive the sparsity-preserving BE formula for LSE within our framework.\nNumerical experiments are performed to test the strong backward stability of\nvarious numerical algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.14019v2", "cate": "math.NA", "date": "2024-08-26", "updated": "2025-07-09"}
{"id": "2507.06392", "title": "VoI-aware Scheduling Schemes for Multi-Agent Formation Control", "authors": ["Federico Chiariotti", "Marco Fabris"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 pages, 4 figures, 2 tables, accepted at the 1st Joint Conference on Computers, Cognition and Communication, Padua, Italy, Sep. 15-18, 2025", "url": "http://arxiv.org/abs/2507.06392v1", "summary": "Formation control allows agents to maintain geometric patterns using local\ninformation, but most existing methods assume ideal communication. This paper\nintroduces a goal-oriented framework combining control, cooperative\npositioning, and communication scheduling for first-order formation tracking.\nEach agent estimates its position using 6G network-based triangulation, and the\nscheduling of information updates is governed by Age of Information (AoI) and\nValue of Information (VoI) metrics. We design three lightweight, signaling-free\nscheduling policies and assess their impact on formation quality. Simulation\nresults demonstrate the effectiveness of the proposed approach in maintaining\naccurate formations with no additional communication overhead, showing that\nworst-case formation adherence increases by 20%.", "comment": "6 pages, 4 figures, 2 tables, accepted at the 1st Joint Conference on\n  Computers, Cognition and Communication, Padua, Italy, Sep. 15-18, 2025", "pdf_url": "http://arxiv.org/pdf/2507.06392v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2503.09347", "title": "Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts", "authors": ["Hongyu Chen", "Seraphina Goldfarb-Tarrant"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages, ACL 2025", "url": "http://arxiv.org/abs/2503.09347v3", "summary": "Large Language Models (LLMs) are increasingly employed as automated\nevaluators to assess the safety of generated content, yet their reliability in\nthis role remains uncertain. This study evaluates a diverse set of 11 LLM judge\nmodels across critical safety domains, examining three key aspects:\nself-consistency in repeated judging tasks, alignment with human judgments, and\nsusceptibility to input artifacts such as apologetic or verbose phrasing. Our\nfindings reveal that biases in LLM judges can significantly distort the final\nverdict on which content source is safer, undermining the validity of\ncomparative evaluations. Notably, apologetic language artifacts alone can skew\nevaluator preferences by up to 98\\%. Contrary to expectations, larger models do\nnot consistently exhibit greater robustness, while smaller models sometimes\nshow higher resistance to specific artifacts. To mitigate LLM evaluator\nrobustness issues, we investigate jury-based evaluations aggregating decisions\nfrom multiple models. Although this approach both improves robustness and\nenhances alignment to human judgements, artifact sensitivity persists even with\nthe best jury configurations. These results highlight the urgent need for\ndiversified, artifact-resistant methodologies to ensure reliable safety\nassessments.", "comment": "9 pages, ACL 2025", "pdf_url": "http://arxiv.org/pdf/2503.09347v3", "cate": "cs.CL", "date": "2025-03-12", "updated": "2025-07-09"}
{"id": "2504.07793", "title": "Revisiting Likelihood-Based Out-of-Distribution Detection by Modeling Representations", "authors": ["Yifan Ding", "Arturas Aleksandraus", "Amirhossein Ahmadian", "Jonas Unger", "Fredrik Lindsten", "Gabriel Eilertsen"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Scandinavian Conference on Image Analysis 2025 (oral)", "url": "http://arxiv.org/abs/2504.07793v2", "summary": "Out-of-distribution (OOD) detection is critical for ensuring the reliability\nof deep learning systems, particularly in safety-critical applications.\nLikelihood-based deep generative models have historically faced criticism for\ntheir unsatisfactory performance in OOD detection, often assigning higher\nlikelihood to OOD data than in-distribution samples when applied to image data.\nIn this work, we demonstrate that likelihood is not inherently flawed. Rather,\nseveral properties in the images space prohibit likelihood as a valid detection\nscore. Given a sufficiently good likelihood estimator, specifically using the\nprobability flow formulation of a diffusion model, we show that\nlikelihood-based methods can still perform on par with state-of-the-art methods\nwhen applied in the representation space of pre-trained encoders. The code of\nour work can be found at\n$\\href{https://github.com/limchaos/Likelihood-OOD.git}{\\texttt{https://github.com/limchaos/Likelihood-OOD.git}}$.", "comment": "Scandinavian Conference on Image Analysis 2025 (oral)", "pdf_url": "http://arxiv.org/pdf/2504.07793v2", "cate": "cs.LG", "date": "2025-04-10", "updated": "2025-07-09"}
{"id": "2411.15582", "title": "EMD: Explicit Motion Modeling for High-Quality Street Gaussian Splatting", "authors": ["Xiaobao Wei", "Qingpo Wuwu", "Zhongyu Zhao", "Zhuangzhe Wu", "Nan Huang", "Ming Lu", "Ningning MA", "Shanghang Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Acccpeted by ICCV2025", "url": "http://arxiv.org/abs/2411.15582v2", "summary": "Photorealistic reconstruction of street scenes is essential for developing\nreal-world simulators in autonomous driving. While recent methods based on\n3D/4D Gaussian Splatting (GS) have demonstrated promising results, they still\nencounter challenges in complex street scenes due to the unpredictable motion\nof dynamic objects. Current methods typically decompose street scenes into\nstatic and dynamic objects, learning the Gaussians in either a supervised\nmanner (e.g., w/ 3D bounding-box) or a self-supervised manner (e.g., w/o 3D\nbounding-box). However, these approaches do not effectively model the motions\nof dynamic objects (e.g., the motion speed of pedestrians is clearly different\nfrom that of vehicles), resulting in suboptimal scene decomposition. To address\nthis, we propose Explicit Motion Decomposition (EMD), which models the motions\nof dynamic objects by introducing learnable motion embeddings to the Gaussians,\nenhancing the decomposition in street scenes. The proposed plug-and-play EMD\nmodule compensates for the lack of motion modeling in self-supervised street\nGaussian splatting methods. We also introduce tailored training strategies to\nextend EMD to supervised approaches. Comprehensive experiments demonstrate the\neffectiveness of our method, achieving state-of-the-art novel view synthesis\nperformance in self-supervised settings. The code is available at:\nhttps://qingpowuwu.github.io/emd.", "comment": "Acccpeted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2411.15582v2", "cate": "cs.CV", "date": "2024-11-23", "updated": "2025-07-09"}
{"id": "2503.19328", "title": "Substance over Style: Evaluating Proactive Conversational Coaching Agents", "authors": ["Vidya Srinivas", "Xuhai Xu", "Xin Liu", "Kumar Ayush", "Isaac Galatzer-Levy", "Shwetak Patel", "Daniel McDuff", "Tim Althoff"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025", "url": "http://arxiv.org/abs/2503.19328v2", "summary": "While NLP research has made strides in conversational tasks, many approaches\nfocus on single-turn responses with well-defined objectives or evaluation\ncriteria. In contrast, coaching presents unique challenges with initially\nundefined goals that evolve through multi-turn interactions, subjective\nevaluation criteria, mixed-initiative dialogue. In this work, we describe and\nimplement five multi-turn coaching agents that exhibit distinct conversational\nstyles, and evaluate them through a user study, collecting first-person\nfeedback on 155 conversations. We find that users highly value core\nfunctionality, and that stylistic components in absence of core components are\nviewed negatively. By comparing user feedback with third-person evaluations\nfrom health experts and an LM, we reveal significant misalignment across\nevaluation approaches. Our findings provide insights into design and evaluation\nof conversational coaching agents and contribute toward improving\nhuman-centered NLP applications.", "comment": "Accepted to ACL 2025", "pdf_url": "http://arxiv.org/pdf/2503.19328v2", "cate": "cs.CL", "date": "2025-03-25", "updated": "2025-07-08"}
{"id": "2501.18428", "title": "Convergence of a semi-explicit scheme for a one dimensional periodic nonlocal eikonal equation modeling dislocation dynamics", "authors": ["Diana Al Zareef", "Ahmad El Hajj", "Hassan Ibrahim", "Antoine Zurek"], "categories": ["math.NA", "cs.NA", "35F20, 35F21, 70H20, 65M12, 65M06"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.18428v2", "summary": "In this paper, we derive a periodic model from a one dimensional nonlocal\neikonal equation set on the full space modeling dislocation dynamics. Thanks to\na gradient entropy estimate, we show that this periodic model converges toward\nthe initial one when the period goes to infinity. Moreover, we design a\nsemi-explicit numerical scheme for the periodic model that we introduce. We\nshow the well-posedness of the scheme and a discrete gradient entropy\ninequality. We also prove the convergence of the scheme and we present some\nnumerical experiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.18428v2", "cate": "math.NA", "date": "2025-01-30", "updated": "2025-07-09"}
{"id": "2507.06416", "title": "Voltage Regulation in Distribution Systems with Data Center Loads", "authors": ["Yize Chen", "Baosen Zhang"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Code available at this https URL", "url": "http://arxiv.org/abs/2507.06416v1", "summary": "Recent boom in foundation models and AI computing have raised growing\nconcerns on the power and energy trajectories of large-scale data centers. This\npaper focuses on the voltage issues caused by volatile and intensity of data\ncenter power demand, which also aligns with recent observations of more\nfrequent voltage disturbances in power grids. To address these data center\nintegration challenges, we propose a dynamic voltage control scheme by\nharnessing data center's load regulation capabilities. By taking local voltage\nmeasurements and adjusting power injections at each data center buses through\nthe dynamic voltage and frequency scaling (DVFS) scheme, we are able to\nmaintain safe voltage magnitude in a distributed fashion with higher data\ncenter computing load. Simulations using real large language model (LLM)\ninference load validate the effectiveness of our proposed mechanism. Both the\nLLM power data and proposed control scheme are open sourced.", "comment": "Code available at\n  https://github.com/chennnnnyize/voltage-regulation-with-data-centers", "pdf_url": "http://arxiv.org/pdf/2507.06416v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2504.04204", "title": "Adaptive Elicitation of Latent Information Using Natural Language", "authors": ["Jimmy Wang", "Thomas Zollo", "Richard Zemel", "Hongseok Namkoong"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ICML 2025", "url": "http://arxiv.org/abs/2504.04204v2", "summary": "Eliciting information to reduce uncertainty about a latent entity is a\ncritical task in many application domains, e.g., assessing individual student\nlearning outcomes, diagnosing underlying diseases, or learning user\npreferences. Though natural language is a powerful medium for this purpose,\nlarge language models (LLMs) and existing fine-tuning algorithms lack\nmechanisms for strategically gathering information to refine their own\nunderstanding of the latent entity. To harness the generalization power and\nworld knowledge of LLMs in developing effective information-gathering\nstrategies, we propose an adaptive elicitation framework that actively reduces\nuncertainty on the latent entity. Since probabilistic modeling of an abstract\nlatent entity is difficult, our framework adopts a predictive view of\nuncertainty, using a meta-learned language model to simulate future\nobservations and enable scalable uncertainty quantification over complex\nnatural language. Through autoregressive forward simulation, our model\nquantifies how new questions reduce epistemic uncertainty, enabling the\ndevelopment of sophisticated information-gathering strategies to choose the\nmost informative next queries. In experiments on the 20 questions game, dynamic\nopinion polling, and adaptive student assessment, our method consistently\noutperforms baselines in identifying critical unknowns and improving downstream\npredictions, illustrating the promise of strategic information gathering in\nnatural language settings.", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2504.04204v2", "cate": "cs.CL", "date": "2025-04-05", "updated": "2025-07-09"}
{"id": "2504.19452", "title": "Geometry-Informed Neural Operator Transformer", "authors": ["Qibang Liu", "Weiheng Zhong", "Hadi Meidani", "Diab Abueidda", "Seid Koric", "Philippe Geubelle"], "categories": ["cs.LG", "physics.comp-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.19452v4", "summary": "Machine-learning-based surrogate models offer significant computational\nefficiency and faster simulations compared to traditional numerical methods,\nespecially for problems requiring repeated evaluations of partial differential\nequations. This work introduces the Geometry-Informed Neural Operator\nTransformer (GINOT), which integrates the transformer architecture with the\nneural operator framework to enable forward predictions on arbitrary\ngeometries. GINOT employs a sampling and grouping strategy together with an\nattention mechanism to encode surface point clouds that are unordered, exhibit\nnon-uniform point densities, and contain varying numbers of points for\ndifferent geometries. The geometry information is seamlessly integrated with\nquery points in the solution decoder through the attention mechanism. The\nperformance of GINOT is validated on multiple challenging datasets, showcasing\nits high accuracy and strong generalization capabilities for complex and\narbitrary 2D and 3D geometries.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.19452v4", "cate": "cs.LG", "date": "2025-04-28", "updated": "2025-07-09"}
{"id": "2411.16575", "title": "Rethinking Diffusion for Text-Driven Human Motion Generation: Redundant Representations, Evaluation, and Masked Autoregression", "authors": ["Zichong Meng", "Yiming Xie", "Xiaogang Peng", "Zeyu Han", "Huaizu Jiang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      CVPR 2025", "url": "http://arxiv.org/abs/2411.16575v2", "summary": "Since 2023, Vector Quantization (VQ)-based discrete generation methods have\nrapidly dominated human motion generation, primarily surpassing diffusion-based\ncontinuous generation methods in standard performance metrics. However,\nVQ-based methods have inherent limitations. Representing continuous motion data\nas limited discrete tokens leads to inevitable information loss, reduces the\ndiversity of generated motions, and restricts their ability to function\neffectively as motion priors or generation guidance. In contrast, the\ncontinuous space generation nature of diffusion-based methods makes them\nwell-suited to address these limitations and with even potential for model\nscalability. In this work, we systematically investigate why current VQ-based\nmethods perform well and explore the limitations of existing diffusion-based\nmethods from the perspective of motion data representation and distribution.\nDrawing on these insights, we preserve the inherent strengths of a\ndiffusion-based human motion generation model and gradually optimize it with\ninspiration from VQ-based approaches. Our approach introduces a human motion\ndiffusion model enabled to perform masked autoregression, optimized with a\nreformed data representation and distribution. Additionally, we propose a more\nrobust evaluation method to assess different approaches. Extensive experiments\non various datasets demonstrate our method outperforms previous methods and\nachieves state-of-the-art performances.", "comment": "CVPR 2025", "pdf_url": "http://arxiv.org/pdf/2411.16575v2", "cate": "cs.CV", "date": "2024-11-25", "updated": "2025-07-08"}
{"id": "2504.06036", "title": "Multi-Sense Embeddings for Language Models and Knowledge Distillation", "authors": ["Qitong Wang", "Mohammed J. Zaki", "Georgios Kollias", "Vasileios Kalantzis"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      16 pages, 4 figures", "url": "http://arxiv.org/abs/2504.06036v2", "summary": "Transformer-based large language models (LLMs) rely on contextual embeddings\nwhich generate different (continuous) representations for the same token\ndepending on its surrounding context. Nonetheless, words and tokens typically\nhave a limited number of senses (or meanings). We propose multi-sense\nembeddings as a drop-in replacement for each token in order to capture the\nrange of their uses in a language. To construct a sense embedding dictionary,\nwe apply a clustering algorithm to embeddings generated by an LLM and consider\nthe cluster centers as representative sense embeddings. In addition, we propose\na novel knowledge distillation method that leverages the sense dictionary to\nlearn a smaller student model that mimics the senses from the much larger base\nLLM model, offering significant space and inference time savings, while\nmaintaining competitive performance. Via thorough experiments on various\nbenchmarks, we showcase the effectiveness of our sense embeddings and knowledge\ndistillation approach. We share our code at\nhttps://github.com/Qitong-Wang/SenseDict", "comment": "16 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2504.06036v2", "cate": "cs.CL", "date": "2025-04-08", "updated": "2025-07-08"}
{"id": "2505.24861", "title": "A localized consensus-based sampling algorithm", "authors": ["Arne Bouillon", "Alexander Bodard", "Panagiotis Patrinos", "Dirk Nuyens", "Giovanni Samaey"], "categories": ["math.NA", "cs.NA", "math.OC", "62F15 (Primary) 65C05, 65C35, 82C31 (Secondary)"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.24861v2", "summary": "We develop a novel interacting-particle method for sampling from non-Gaussian\ndistributions. As a first step, we propose a new way to derive the\nconsensus-based sampling (CBS) algorithm, starting from ensemble-preconditioned\nLangevin diffusions. We approximate the target potential by its Moreau\nenvelope, such that the gradient in the Langevin equation can be replaced by a\nproximal operator. We then approximate the proximal operator by a weighted\nmean, and finally assume that the initial and target distributions are\nGaussian, resulting in the CBS dynamics. If we keep only those approximations\nthat can be justified in the non-Gaussian setting, the result is a new\ninteracting-particle method for sampling, which we call localized\nconsensus-based sampling. We prove that our algorithm is affine-invariant and\nexact for Gaussian distributions in the mean-field setting. Numerical tests\nillustrate that localized CBS compares favorably to alternative methods in\nterms of affine-invariance and performance on non-Gaussian distributions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.24861v2", "cate": "math.NA", "date": "2025-05-30", "updated": "2025-07-08"}
{"id": "2507.06436", "title": "Experience-Centric Resource Management in ISAC Networks: A Digital Agent-Assisted Approach", "authors": ["Xinyu Huang", "Yixiao Zhang", "Yingying Pei", "Jianzhe Xue", "Xuemin Shen"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06436v1", "summary": "In this paper, we propose a digital agent (DA)-assisted resource management\nscheme for enhanced user quality of experience (QoE) in integrated sensing and\ncommunication (ISAC) networks. Particularly, user QoE is a comprehensive metric\nthat integrates quality of service (QoS), user behavioral dynamics, and\nenvironmental complexity. The novel DA module includes a user status prediction\nmodel, a QoS factor selection model, and a QoE fitting model, which analyzes\nhistorical user status data to construct and update user-specific QoE models.\nUsers are clustered into different groups based on their QoE models. A\nCram\\'er-Rao bound (CRB) model is utilized to quantify the impact of allocated\ncommunication resources on sensing accuracy. A joint optimization problem of\ncommunication and computing resource management is formulated to maximize\nlong-term user QoE while satisfying CRB and resource constraints. A two-layer\ndata-model-driven algorithm is developed to solve the formulated problem, where\nthe top layer utilizes an advanced deep reinforcement learning algorithm to\nmake group-level decisions, and the bottom layer uses convex optimization\ntechniques to make user-level decisions. Simulation results based on a\nreal-world dataset demonstrate that the proposed DA-assisted resource\nmanagement scheme outperforms benchmark schemes in terms of user QoE.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06436v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2505.02579", "title": "EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning", "authors": ["Lingxiao Kong", "Cong Yang", "Susanne Neufang", "Oya Deniz Beyan", "Zeyd Boukhers"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      14 pages, 9 figures, accepted by the SIGDIAL 2025 conference", "url": "http://arxiv.org/abs/2505.02579v3", "summary": "Recent advances in reinforcement learning (RL) for large language model (LLM)\nfine-tuning show promise in addressing multi-objective tasks but still face\nsignificant challenges, including competing objective balancing, low training\nefficiency, poor scalability, and limited explainability. Leveraging ensemble\nlearning principles, we introduce an Ensemble Multi-Objective RL (EMORL)\nframework that fine-tunes multiple models with individual objectives while\noptimizing their aggregation after the fine-tuning to improve efficiency and\nflexibility. Our method is the first to aggregate the hidden states of\nindividual models, incorporating contextual information from multiple\nobjectives. This approach is supported by a hierarchical grid search algorithm\nthat identifies optimal weighted combinations. We evaluate EMORL on counselor\nreflection generation tasks, using text classification models to score the\ngenerations and provide rewards during RL fine-tuning. Through comprehensive\nexperiments on the PAIR and Psych8k datasets, we demonstrate the advantages of\nEMORL against existing baselines: significantly lower and more stable training\nconsumption ($17,529\\pm 1,650$ data points and $6,573\\pm 147.43$ seconds),\nimproved scalability and explainability, and comparable performance across\nmultiple objectives.", "comment": "14 pages, 9 figures, accepted by the SIGDIAL 2025 conference", "pdf_url": "http://arxiv.org/pdf/2505.02579v3", "cate": "cs.CL", "date": "2025-05-05", "updated": "2025-07-09"}
{"id": "2505.20659", "title": "An Optimisation Framework for Unsupervised Environment Design", "authors": ["Nathan Monette", "Alistair Letcher", "Michael Beukman", "Matthew T. Jackson", "Alexander Rutherford", "Alexander D. Goldie", "Jakob N. Foerster"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Reinforcement Learning Conference 2025", "url": "http://arxiv.org/abs/2505.20659v2", "summary": "For reinforcement learning agents to be deployed in high-risk settings, they\nmust achieve a high level of robustness to unfamiliar scenarios. One method for\nimproving robustness is unsupervised environment design (UED), a suite of\nmethods aiming to maximise an agent's generalisability across configurations of\nan environment. In this work, we study UED from an optimisation perspective,\nproviding stronger theoretical guarantees for practical settings than prior\nwork. Whereas previous methods relied on guarantees if they reach convergence,\nour framework employs a nonconvex-strongly-concave objective for which we\nprovide a provably convergent algorithm in the zero-sum setting. We empirically\nverify the efficacy of our method, outperforming prior methods in a number of\nenvironments with varying difficulties.", "comment": "Reinforcement Learning Conference 2025", "pdf_url": "http://arxiv.org/pdf/2505.20659v2", "cate": "cs.LG", "date": "2025-05-27", "updated": "2025-07-09"}
{"id": "2411.18115", "title": "Transformer-Driven Active Transfer Learning for Cross-Hyperspectral Image Classification", "authors": ["Muhammad Ahmad", "Francesco Mauro", "Manuel Mazzara", "Salvatore Distefano", "Adil Mehmood Khan", "Silvia Liberata Ullo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.18115v2", "summary": "Hyperspectral image (HSI) classification presents inherent challenges due to\nhigh spectral dimensionality, significant domain shifts, and limited\navailability of labeled data. To address these issues, we propose a novel\nActive Transfer Learning (ATL) framework built upon a Spatial-Spectral\nTransformer (SST) backbone. The framework integrates multistage transfer\nlearning with an uncertainty-diversity-driven active learning mechanism that\nstrategically selects highly informative and diverse samples for annotation,\nthereby significantly reducing labeling costs and mitigating sample redundancy.\nA dynamic layer freezing strategy is introduced to enhance transferability and\ncomputational efficiency, enabling selective adaptation of model layers based\non domain shift characteristics. Furthermore, we incorporate a self-calibrated\nattention mechanism that dynamically refines spatial and spectral weights\nduring adaptation, guided by uncertainty-aware feedback. A diversity-promoting\nsampling strategy ensures broad spectral coverage among selected samples,\npreventing overfitting to specific classes. Extensive experiments on benchmark\ncross-domain HSI datasets demonstrate that the proposed SST-ATL framework\nachieves superior classification performance compared to conventional\napproaches. The source code is publicly available at\nhttps://github.com/mahmad000/ATL-SST.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.18115v2", "cate": "cs.CV", "date": "2024-11-27", "updated": "2025-07-09"}
{"id": "2506.03785", "title": "Knockout LLM Assessment: Using Large Language Models for Evaluations through Iterative Pairwise Comparisons", "authors": ["Isik Baran Sandan", "Tu Anh Dinh", "Jan Niehues"], "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to GEM @ ACL 2025", "url": "http://arxiv.org/abs/2506.03785v3", "summary": "Large Language Models (LLMs) have shown to be effective evaluators across\nvarious domains such as machine translations or the scientific domain. Current\nLLM-as-a-Judge approaches rely mostly on individual assessments or a single\nround of pairwise assessments, preventing the judge LLM from developing a\nglobal ranking perspective. To address this, we present Knockout Assessment, an\nLLM-asa Judge method using a knockout tournament system with iterative pairwise\ncomparisons. Experiments across three LLMs on two datasets show that knockout\nassessment improves scoring accuracy, increasing Pearson correlation with\nexpert evaluations by 0.07 on average for university-level exam scoring and\nmachine translation evaluations, aligning LLM assessments more closely with\nhuman scoring.", "comment": "Accepted to GEM @ ACL 2025", "pdf_url": "http://arxiv.org/pdf/2506.03785v3", "cate": "cs.CL", "date": "2025-06-04", "updated": "2025-07-09"}
{"id": "2507.03521", "title": "PINN-DG: Residual neural network methods trained with Finite Elements", "authors": ["Georgios Grekas", "Charalambos G. Makridakis", "Tristan Pryer"], "categories": ["math.NA", "cs.NA", "physics.comp-ph", "65M15 (Primary), 65M12 (Secondary)"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03521v2", "summary": "Over the past few years, neural network methods have evolved in various\ndirections for approximating partial differential equations (PDEs). A promising\nnew development is the integration of neural networks with classical numerical\ntechniques such as finite elements and finite differences. In this paper, we\nintroduce a new class of Physics-Informed Neural Networks (PINNs) trained using\ndiscontinuous Galerkin finite element methods. Unlike standard\ncollocation-based PINNs that rely on pointwise gradient evaluations and Monte\nCarlo quadrature, our approach computes the loss functional using finite\nelement interpolation and integration. This avoids costly pointwise derivative\ncomputations, particularly advantageous for elliptic PDEs requiring\nsecond-order derivatives, and inherits key stability and accuracy benefits from\nthe finite element framework. We present a convergence analysis based on\nvariational arguments and support our theoretical findings with numerical\nexperiments that demonstrate improved efficiency and robustness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03521v2", "cate": "math.NA", "date": "2025-07-04", "updated": "2025-07-09"}
{"id": "2507.06446", "title": "On Regular Regressors in Adaptive Control", "authors": ["Erick Mejia Uzeda", "Mireille E. Broucke"], "categories": ["eess.SY", "cs.SY", "93C40 (Primary), 93B27 (Secondary)"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.06446v1", "summary": "This paper addresses a shortcoming in adaptive control, that the property of\na regressor being persistently exciting (PE) is not well-behaved. One can\nconstruct regressors that upend the commonsense notion that excitation should\nnot be created out of nothing. To amend the situation, a notion of regularity\nof regressors is needed. We are naturally led to a broad class of regular\nregressors that enjoy the property that their excitation is always confined to\na subspace, a foundational result called the PE decomposition. A geometric\ncharacterization of regressor excitation opens up new avenues for adaptive\ncontrol, as we demonstrate by formulating a number of new adaptive control\nproblems.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.06446v1", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2506.07675", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "authors": ["Yuyang Song", "Hanxu Yan", "Jiale Lao", "Yibo Wang", "Yufei Li", "Yuanchun Zhou", "Jianguo Wang", "Mingjie Tang"], "categories": ["cs.DB", "cs.AI"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.07675v2", "summary": "Query rewrite transforms SQL queries into semantically equivalent forms that\nrun more efficiently. Existing approaches mainly rely on predefined rewrite\nrules, but they handle a limited subset of queries and can cause performance\nregressions. This limitation stems from three challenges of rule-based query\nrewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite\nrules do not generalize to new query patterns, and (3) some rewrite techniques\ncannot be expressed as fixed rules. Motivated by the fact that human experts\nexhibit significantly better rewrite ability but suffer from scalability, and\nLarge Language Models (LLMs) have demonstrated nearly human-level semantic and\nreasoning abilities, we propose a new approach of using LLMs to rewrite SQL\nqueries beyond rules. Due to the hallucination problems in LLMs, directly\napplying LLMs often leads to nonequivalent and suboptimal queries. To address\nthis issue, we propose QUITE (query rewrite), a training-free and\nfeedback-aware system based on LLM agents that rewrites SQL queries into\nsemantically equivalent forms with significantly better performance, covering a\nbroader range of query patterns and rewrite strategies compared to rule-based\nmethods. Firstly, we design a multi-agent framework controlled by a finite\nstate machine (FSM) to equip LLMs with the ability to use external tools and\nenhance the rewrite process with real-time database feedback. Secondly, we\ndevelop a rewrite middleware to enhance the ability of LLMs to generate\noptimized query equivalents. Finally, we employ a novel hint injection\ntechnique to improve execution plans for rewritten queries. Extensive\nexperiments show that QUITE reduces query execution time by up to 35.8% over\nstate-of-the-art approaches and produces 24.1% more rewrites than prior\nmethods, covering query cases that earlier systems did not handle.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.07675v2", "cate": "cs.DB", "date": "2025-06-09", "updated": "2025-07-09"}
{"id": "2506.04677", "title": "The cost of ensembling: is it always worth combining?", "authors": ["Marco Zanotti"], "categories": ["cs.LG", "stat.AP", "stat.OT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.04677v2", "summary": "Given the continuous increase in dataset sizes and the complexity of\nforecasting models, the trade-off between forecast accuracy and computational\ncost is emerging as an extremely relevant topic, especially in the context of\nensemble learning for time series forecasting. To asses it, we evaluated ten\nbase models and eight ensemble configurations across two large-scale retail\ndatasets (M5 and VN1), considering both point and probabilistic accuracy under\nvarying retraining frequencies. We showed that ensembles consistently improve\nforecasting performance, particularly in probabilistic settings. However, these\ngains come at a substantial computational cost, especially for larger,\naccuracy-driven ensembles. We found that reducing retraining frequency\nsignificantly lowers costs, with minimal impact on accuracy, particularly for\npoint forecasts. Moreover, efficiency-driven ensembles offer a strong balance,\nachieving competitive accuracy with considerably lower costs compared to\naccuracy-optimized combinations. Most importantly, small ensembles of two or\nthree models are often sufficient to achieve near-optimal results. These\nfindings provide practical guidelines for deploying scalable and cost-efficient\nforecasting systems, supporting the broader goals of sustainable AI in\nforecasting. Overall, this work shows that careful ensemble design and\nretraining strategy selection can yield accurate, robust, and cost-effective\nforecasts suitable for real-world applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.04677v2", "cate": "cs.LG", "date": "2025-06-05", "updated": "2025-07-09"}
{"id": "2411.19149", "title": "Counting Stacked Objects", "authors": ["Corentin Dumery", "Noa Etté", "Aoxiang Fan", "Ren Li", "Jingyi Xu", "Hieu Le", "Pascal Fua"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV25. Datasets and code can be found at this https URL", "url": "http://arxiv.org/abs/2411.19149v3", "summary": "Visual object counting is a fundamental computer vision task underpinning\nnumerous real-world applications, from cell counting in biomedicine to traffic\nand wildlife monitoring. However, existing methods struggle to handle the\nchallenge of stacked 3D objects in which most objects are hidden by those above\nthem. To address this important yet underexplored problem, we propose a novel\n3D counting approach that decomposes the task into two complementary\nsubproblems - estimating the 3D geometry of the object stack and the occupancy\nratio from multi-view images. By combining geometric reconstruction and deep\nlearning-based depth analysis, our method can accurately count identical\nobjects within containers, even when they are irregularly stacked. We validate\nour 3D Counting pipeline on diverse real-world and large-scale synthetic\ndatasets, which we will release publicly to facilitate further research.", "comment": "ICCV25. Datasets and code can be found at\n  https://corentindumery.github.io/projects/stacks.html", "pdf_url": "http://arxiv.org/pdf/2411.19149v3", "cate": "cs.CV", "date": "2024-11-28", "updated": "2025-07-09"}
{"id": "2506.11111", "title": "Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions", "authors": ["Kun Zhang", "Le Wu", "Kui Yu", "Guangyi Lv", "Dacao Zhang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      33 pages, 5 figures", "url": "http://arxiv.org/abs/2506.11111v2", "summary": "Large Language Models (LLMs) have gained enormous attention in recent years\ndue to their capability of understanding and generating natural languages. With\nthe rapid development and wild-range applications (e.g., Agents, Embodied\nIntelligence), the robustness of LLMs has received increased attention. As the\ncore brain of many AI applications, the robustness of LLMs requires that models\nshould not only generate consistent contents, but also ensure the correctness\nand stability of generated content when dealing with unexpeted application\nscenarios (e.g., toxic prompts, limited noise domain data, outof-distribution\n(OOD) applications, etc). In this survey paper, we conduct a thorough review of\nthe robustness of LLMs, aiming to provide a comprehensive terminology of\nconcepts and methods around this field and facilitate the community.\nSpecifically, we first give a formal definition of LLM robustness and present\nthe collection protocol of this survey paper. Then, based on the types of\nperturbated inputs, we organize this survey from the following perspectives: 1)\nAdversarial Robustness: tackling the problem that prompts are manipulated\nintentionally, such as noise prompts, long context, data attack, etc; 2) OOD\nRobustness: dealing with the unexpected real-world application scenarios, such\nas OOD detection, zero-shot transferring, hallucinations, etc; 3) Evaluation of\nRobustness: summarizing the new evaluation datasets, metrics, and tools for\nverifying the robustness of LLMs. After reviewing the representative work from\neach perspective, we discuss and highlight future opportunities and research\ndirections in this field. Meanwhile, we also organize related works and provide\nan easy-to-search project\n(https://github.com/zhangkunzk/Awesome-LLM-Robustness-papers) to support the\ncommunity.", "comment": "33 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2506.11111v2", "cate": "cs.CL", "date": "2025-06-08", "updated": "2025-07-09"}
{"id": "2507.06038", "title": "Fredholm Neural Networks for forward and inverse problems in elliptic PDEs", "authors": ["Kyriakos Georgiou", "Constantinos Siettos", "Athanasios N. Yannacopoulos"], "categories": ["math.NA", "cs.LG", "cs.NA", "68T07, 65N12, 65N21 (Primary), 45B05, 65N38 (Secondary)"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06038v2", "summary": "Building on our previous work introducing Fredholm Neural Networks (Fredholm\nNNs/ FNNs) for solving integral equations, we extend the framework to tackle\nforward and inverse problems for linear and semi-linear elliptic partial\ndifferential equations. The proposed scheme consists of a deep neural network\n(DNN) which is designed to represent the iterative process of fixed-point\niterations for the solution of elliptic PDEs using the boundary integral method\nwithin the framework of potential theory. The number of layers, weights, biases\nand hyperparameters are computed in an explainable manner based on the\niterative scheme, and we therefore refer to this as the Potential Fredholm\nNeural Network (PFNN). We show that this approach ensures both accuracy and\nexplainability, achieving small errors in the interior of the domain, and near\nmachine-precision on the boundary. We provide a constructive proof for the\nconsistency of the scheme and provide explicit error bounds for both the\ninterior and boundary of the domain, reflected in the layers of the PFNN. These\nerror bounds depend on the approximation of the boundary function and the\nintegral discretization scheme, both of which directly correspond to components\nof the Fredholm NN architecture. In this way, we provide an explainable scheme\nthat explicitly respects the boundary conditions. We assess the performance of\nthe proposed scheme for the solution of both the forward and inverse problem\nfor linear and semi-linear elliptic PDEs in two dimensions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06038v2", "cate": "math.NA", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2507.06492", "title": "Dual State-space Fidelity Blade (D-STAB): A Novel Stealthy Cyber-physical Attack Paradigm", "authors": ["Jiajun Shen", "Hao Tu", "Fengjun Li", "Morteza Hashemi", "Di Wu", "Huazhen Fang"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      accepted by 2025 American Control Conference", "url": "http://arxiv.org/abs/2507.06492v1", "summary": "This paper presents a novel cyber-physical attack paradigm, termed the Dual\nState-Space Fidelity Blade (D-STAB), which targets the firmware of core\ncyber-physical components as a new class of attack surfaces. The D-STAB attack\nexploits the information asymmetry caused by the fidelity gap between\nhigh-fidelity and low-fidelity physical models in cyber-physical systems. By\ndesigning precise adversarial constraints based on high-fidelity state-space\ninformation, the attack induces deviations in high-fidelity states that remain\nundetected by defenders relying on low-fidelity observations. The effectiveness\nof D-STAB is demonstrated through a case study in cyber-physical battery\nsystems, specifically in an optimal charging task governed by a Battery\nManagement System (BMS).", "comment": "accepted by 2025 American Control Conference", "pdf_url": "http://arxiv.org/pdf/2507.06492v1", "cate": "eess.SY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2506.10707", "title": "ConTextTab: A Semantics-Aware Tabular In-Context Learner", "authors": ["Marco Spinaci", "Marek Polewczyk", "Maximilian Schambach", "Sam Thelin"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.10707v2", "summary": "Tabular in-context learning (ICL) has recently achieved state-of-the-art\n(SOTA) performance on several tabular prediction tasks. Previously restricted\nto classification problems on small tables, recent advances such as TabPFN and\nTabICL have extended its use to larger datasets. While being architecturally\nefficient and well-adapted to tabular data structures, current table-native ICL\narchitectures, being trained exclusively on synthetic data, do not fully\nleverage the rich semantics and world knowledge contained in real-world tabular\ndata. On another end of this spectrum, tabular ICL models based on pretrained\nlarge language models such as TabuLa-8B integrate deep semantic understanding\nand world knowledge but are only able to make use of a small amount of context\ndue to inherent architectural limitations. With the aim to combine the best of\nboth these worlds, we introduce ConTextTab, integrating semantic understanding\nand alignment into a table-native ICL framework. By employing specialized\nembeddings for different data modalities and by training on large-scale\nreal-world tabular data, our model is competitive with SOTA across a broad set\nof benchmarks while setting a new standard on the semantically rich CARTE\nbenchmark. Code and checkpoints are available at\nhttps://github.com/SAP-samples/contexttab", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.10707v2", "cate": "cs.LG", "date": "2025-06-12", "updated": "2025-07-08"}
{"id": "2506.07308", "title": "PASS: Private Attributes Protection with Stochastic Data Substitution", "authors": ["Yizhuo Chen", "Chun-Fu", "Chen", "Hsiang Hsu", "Shaohan Hu", "Tarek Abdelzaher"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.07308v2", "summary": "The growing Machine Learning (ML) services require extensive collections of\nuser data, which may inadvertently include people's private information\nirrelevant to the services. Various studies have been proposed to protect\nprivate attributes by removing them from the data while maintaining the\nutilities of the data for downstream tasks. Nevertheless, as we theoretically\nand empirically show in the paper, these methods reveal severe vulnerability\nbecause of a common weakness rooted in their adversarial training based\nstrategies. To overcome this limitation, we propose a novel approach, PASS,\ndesigned to stochastically substitute the original sample with another one\naccording to certain probabilities, which is trained with a novel loss function\nsoundly derived from information-theoretic objective defined for\nutility-preserving private attributes protection. The comprehensive evaluation\nof PASS on various datasets of different modalities, including facial images,\nhuman activity sensory signals, and voice recording datasets, substantiates\nPASS's effectiveness and generalizability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.07308v2", "cate": "cs.LG", "date": "2025-06-08", "updated": "2025-07-09"}
{"id": "2501.04670", "title": "Are They the Same? Exploring Visual Correspondence Shortcomings of Multimodal LLMs", "authors": ["Yikang Zhou", "Tao Zhang", "Shilin Xu", "Shihao Chen", "Qianyu Zhou", "Yunhai Tong", "Shunping Ji", "Jiangning Zhang", "Lu Qi", "Xiangtai Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2501.04670v3", "summary": "Recent advancements in multimodal large language models (MLLM) have shown a\nstrong ability in visual perception, reasoning abilities, and vision-language\nunderstanding. However, the visual matching ability of MLLMs is rarely studied,\ndespite finding the visual correspondence of objects is essential in computer\nvision. Our research reveals that the matching capabilities in recent MLLMs\nstill exhibit systematic shortcomings, even with current strong MLLMs models,\nGPT-4o. In particular, we construct a Multimodal Visual Matching (MMVM)\nbenchmark to fairly benchmark over 30 different MLLMs. The MMVM benchmark is\nbuilt from 15 open-source datasets and Internet videos with manual annotation.\nWe categorize the data samples of MMVM benchmark into eight aspects based on\nthe required cues and capabilities to more comprehensively evaluate and analyze\ncurrent MLLMs. In addition, we have designed an automatic annotation pipeline\nto generate the MMVM SFT dataset, including 220K visual matching data with\nreasoning annotation. To our knowledge, this is the first visual corresponding\ndataset and benchmark for the MLLM community. Finally, we present CoLVA, a\nnovel contrastive MLLM with two novel technical designs: fine-grained vision\nexpert with object-level contrastive learning and instruction augmentation\nstrategy. The former learns instance discriminative tokens, while the latter\nfurther improves instruction following ability. CoLVA-InternVL2-4B achieves an\noverall accuracy (OA) of 49.80\\% on the MMVM benchmark, surpassing GPT-4o and\nthe best open-source MLLM, Qwen2VL-72B, by 7.15\\% and 11.72\\% OA, respectively.\nThese results demonstrate the effectiveness of our MMVM SFT dataset and our\nnovel technical designs. Code, benchmark, dataset, and models will be released.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2501.04670v3", "cate": "cs.CV", "date": "2025-01-08", "updated": "2025-07-09"}
{"id": "2506.21285", "title": "Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning", "authors": ["Xin Xu", "Tianhao Chen", "Fan Zhang", "Wanlong Liu", "Pengxiang Li", "Ajay Kumar Jaiswal", "Yuchen Yan", "Jishan Hu", "Yang Wang", "Hao Chen", "Shiwei Liu", "Shizhe Diao", "Can Yang", "Lu Yin"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2506.21285v2", "summary": "While slow-thinking large language models (LLMs) exhibit reflection-like\nreasoning, commonly referred to as the \"aha moment:, their ability to generate\ninformative critiques and refine prior solutions remains limited. In this\npaper, we introduce Double-Checker, a principled framework designed to enhance\nthe reasoning capabilities of slow-thinking LLMs by fostering explicit\nself-critique and iterative refinement of their previous solutions. By\nfine-tuning on our curated 1,730 self-critical instances, Double-Checker\nempowers long-CoT LLMs to iteratively critique and refine their outputs during\ninference until they evaluate their solutions as correct under self-generated\ncritiques. We validate the efficacy of Double-Checker across a comprehensive\nsuite of reasoning benchmarks, demonstrating that iterative self-critique\nsignificantly enhances the reasoning capabilities of long-CoT LLMs. Notably,\nour Double-Checker increases the pass@1 performance on challenging AIME\nbenchmarks from 4.4% to 18.2% compared to the original long-CoT LLMs. These\nresults highlight a promising direction for developing more trustworthy and\neffective LLMs capable of structured self-critique. Our codes and data are\navailable at https://github.com/XinXU-USTC/DoubleChecker", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2506.21285v2", "cate": "cs.CL", "date": "2025-06-26", "updated": "2025-07-09"}
{"id": "2211.05246", "title": "Quantum differential equation solvers: limitations and fast-forwarding", "authors": ["Dong An", "Jin-Peng Liu", "Daochen Wang", "Qi Zhao"], "categories": ["quant-ph", "cs.NA", "math.NA"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      Published version with improved presentation", "url": "http://arxiv.org/abs/2211.05246v3", "summary": "We study the limitations and fast-forwarding of quantum algorithms for linear\nordinary differential equation (ODE) systems with a particular focus on\nnon-quantum dynamics, where the coefficient matrix in the ODE is not\nanti-Hermitian or the ODE is inhomogeneous. On the one hand, for generic linear\nODEs, by proving worst-case lower bounds, we show that quantum algorithms\nsuffer from computational overheads due to two types of ``non-quantumness'':\nreal part gap and non-normality of the coefficient matrix. We then show that\nhomogeneous ODEs in the absence of both types of ``non-quantumness'' are\nequivalent to quantum dynamics, and reach the conclusion that quantum\nalgorithms for quantum dynamics work best. To obtain these lower bounds, we\npropose a general framework for proving lower bounds on quantum algorithms that\nare amplifiers, meaning that they amplify the difference between a pair of\ninput quantum states. On the other hand, we show how to fast-forward quantum\nalgorithms for solving special classes of ODEs which leads to improved\nefficiency. More specifically, we obtain exponential improvements in both $T$\nand the spectral norm of the coefficient matrix for inhomogeneous ODEs with\nefficiently implementable eigensystems, including various spatially discretized\nlinear evolutionary partial differential equations. We give fast-forwarding\nalgorithms that are conceptually different from existing ones in the sense that\nthey neither require time discretization nor solving high-dimensional linear\nsystems.", "comment": "Published version with improved presentation", "pdf_url": "http://arxiv.org/pdf/2211.05246v3", "cate": "quant-ph", "date": "2022-11-09", "updated": "2025-07-09"}
{"id": "2507.06595", "title": "Effects of Net Metering Policies on Distributed Energy Resource Valuation and Operation", "authors": ["Lane D. Smith", "Daniel S. Kirschen"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Accepted to the 2025 IEEE Power and Energy Society (PES) General Meeting", "url": "http://arxiv.org/abs/2507.06595v1", "summary": "Net energy metering has been a successful policy for increasing solar\ngeneration installations and reducing the costs of photovoltaic arrays for\nconsumers. However, increased maturity of solar technologies and concerns over\ncost shifts created by net energy metering have recently caused the policy to\nchange its incentives. What once favored behind-the-meter solar generation now\nis focused on compensating flexible operation. This paper explores the impacts\nthat different net energy metering policies have on commercial consumers with\nvarious distributed energy resources. We show that the newest iteration of net\nenergy metering is less beneficial for consumers with only solar generation and\ninstead favors those that pair energy storage with solar. Though shiftable\nflexible demand offers consumers the ability to operate flexibly, the export\nprices offered by the latest net energy metering policy provide limited value\nto flexible demand.", "comment": "Accepted to the 2025 IEEE Power and Energy Society (PES) General\n  Meeting", "pdf_url": "http://arxiv.org/pdf/2507.06595v1", "cate": "eess.SY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2304.10286", "title": "On the Computational Power of Particle Methods", "authors": ["Johannes Pahlke", "Ivo F. Sbalzarini"], "categories": ["cs.FL", "cs.NA", "math.NA"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      17 pages, 23 appendix pages", "url": "http://arxiv.org/abs/2304.10286v4", "summary": "We investigate the computational power of particle methods, a\nwell-established class of algorit hms with applications in scientific computing\nand computer simulation. The computational power of a compute model determines\nthe class of problems it can solve. Automata theory allows describing the\ncomputational power of abstract machines (automata) and the problems they can\nsolve. At the top of the Chomsky hierarchy of formal languages and grammars are\nTuring machines, which resemble the concept on which most modern computers are\nbuilt. Although particle methods can be interpreted as automata based on their\nformal definition, their computational power has so far not been studied. We\naddress this by analyzing Turing completeness of particle methods. In\nparticular, we prove two sets of restrictions under which a particle method is\nstill Turing powerful, and we show when it loses Turing powerfulness. This\ncontributes to understanding the theoretical foundations of particle methods\nand provides insight into the powerfulness of computer simulations.", "comment": "17 pages, 23 appendix pages", "pdf_url": "http://arxiv.org/pdf/2304.10286v4", "cate": "cs.FL", "date": "2023-04-20", "updated": "2025-07-09"}
{"id": "2506.18951", "title": "SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications", "authors": ["Jinyang Li", "Xiaolong Li", "Ge Qu", "Per Jacobsson", "Bowen Qin", "Binyuan Hui", "Shuzheng Si", "Nan Huo", "Xiaohan Xu", "Yue Zhang", "Ziwei Tang", "Yuanshuai Li", "Florensia Widjaja", "Xintong Zhu", "Feige Zhou", "Yongfeng Huang", "Yannis Papakonstantinou", "Fatma Ozcan", "Chenhao Ma", "Reynold Cheng"], "categories": ["cs.DB", "cs.AI"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "Comments:      26 pages, 9 figures", "url": "http://arxiv.org/abs/2506.18951v2", "summary": "Resolution of complex SQL issues persists as a significant bottleneck in\nreal-world database applications. Current Large Language Models (LLMs), while\nadept at text-to-SQL translation, have not been rigorously evaluated on the\nmore challenging task of debugging SQL issues. To address this gap, we\nintroduce BIRD-CRITIC, a new SQL issue debugging benchmark comprising 530\nPostgreSQL tasks (BIRD-CRITIC-PG) and 570 multi-dialect tasks\n(BIRD-CRITIC-Multi), distilled from authentic user issues and replayed within\nnew environments to facilitate rigorous evaluation. Baseline evaluations\nunderscore the task's complexity, with the leading reasoning model O3-Mini\nachieving only 38.87% success rate on BIRD-CRITIC-PG and 33.33% on\nBIRD-CRITIC-Multi. Meanwhile, advancing open-source models for database tasks\nis crucial for empowering local development while safeguarding data privacy.\nTherefore, we present Six-Gym (Sql-fIX-Gym), a training environment for\nelevating open-source model capabilities for SQL issue debugging. This\nenvironment leverages SQL-Rewind strategy, which automatically generates\nexecutable issue-solution datasets by reverse-engineering issues from verified\nSQLs. However, popular trajectory-based fine-tuning methods do not explore\nsubstantial supervisory signals. We further propose f-Plan Boosting, which\nextracts high-level debugging plans from SQL solutions, enabling teacher LLMs\nto produce 73.7% more successful trajectories for training. We integrate these\ncomponents into an open-source agent, Bird-Fixer. Based on Qwen-2.5-Coder-14B,\nBird-Fixer achieves 38.11% success rate on BIRD-CRITIC-PG and 29.65% on\nBIRD-CRITIC-Multi, surpassing leading proprietary models such as\nClaude-3.7-Sonnet and GPT-4.1, marking a significant step toward democratizing\nsophisticated SQL-debugging capabilities. The leaderboard and source code are\navailable: https://bird-critic.github.io/", "comment": "26 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2506.18951v2", "cate": "cs.DB", "date": "2025-06-23", "updated": "2025-07-09"}
{"id": "2506.15079", "title": "Neural Canonical Polyadic Factorization for Traffic Analysis", "authors": ["Wenyu Luo", "Yikai Hou", "Peng Tang"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.15079v3", "summary": "Modern intelligent transportation systems rely on accurate spatiotemporal\ntraffic analysis to optimize urban mobility and infrastructure resilience.\nHowever, pervasive missing data caused by sensor failures and heterogeneous\nsensing gaps fundamentally hinders reliable traffic modeling. This paper\nproposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizes\nlow-rank tensor algebra with deep representation learning for robust traffic\ndata imputation. The model innovatively embeds CP decomposition into neural\narchitecture through learnable embedding projections, where sparse traffic\ntensors are encoded into dense latent factors across road segments, time\nintervals, and mobility metrics. A hierarchical feature fusion mechanism\nemploys Hadamard products to explicitly model multilinear interactions, while\nstacked multilayer perceptron layers nonlinearly refine these representations\nto capture complex spatiotemporal couplings. Extensive evaluations on six urban\ntraffic datasets demonstrate NCPF's superiority over six state-of-the-art\nbaselines. By unifying CP decomposition's interpretable factor analysis with\nneural network's nonlinear expressive power, NCPF provides a principled yet\nflexible approaches for high-dimensional traffic data imputation, offering\ncritical support for next-generation transportation digital twins and adaptive\ntraffic control systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.15079v3", "cate": "cs.LG", "date": "2025-06-18", "updated": "2025-07-09"}
{"id": "2501.06927", "title": "CULTURE3D: A Large-Scale and Diverse Dataset of Cultural Landmarks and Terrains for Gaussian-Based Scene Rendering", "authors": ["Xinyi Zheng", "Steve Zhang", "Weizhe Lin", "Aaron Zhang", "Walterio W. Mayol-Cuevas", "Yunze Liu", "Junxiao Shen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.06927v3", "summary": "Current state-of-the-art 3D reconstruction models face limitations in\nbuilding extra-large scale outdoor scenes, primarily due to the lack of\nsufficiently large-scale and detailed datasets. In this paper, we present a\nextra-large fine-grained dataset with 10 billion points composed of 41,006\ndrone-captured high-resolution aerial images, covering 20 diverse and\nculturally significant scenes from worldwide locations such as Cambridge Uni\nmain buildings, the Pyramids, and the Forbidden City Palace. Compared to\nexisting datasets, ours offers significantly larger scale and higher detail,\nuniquely suited for fine-grained 3D applications. Each scene contains an\naccurate spatial layout and comprehensive structural information, supporting\ndetailed 3D reconstruction tasks. By reconstructing environments using these\ndetailed images, our dataset supports multiple applications, including outputs\nin the widely adopted COLMAP format, establishing a novel benchmark for\nevaluating state-of-the-art large-scale Gaussian Splatting methods.The\ndataset's flexibility encourages innovations and supports model plug-ins,\npaving the way for future 3D breakthroughs. All datasets and code will be\nopen-sourced for community use.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.06927v3", "cate": "cs.CV", "date": "2025-01-12", "updated": "2025-07-09"}
{"id": "2506.21864", "title": "DeepTalk: Towards Seamless and Smart Speech Interaction with Adaptive Modality-Specific MoE", "authors": ["Hang Shao", "Heting Gao", "Yunhang Shen", "Jiawei Chen", "Lijiang Li", "Zuwei Long", "Bo Tong", "Ke Li", "Xing Sun"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Under Review", "url": "http://arxiv.org/abs/2506.21864v2", "summary": "Native multimodal large language models (MLLMs) restructure a single large\nlanguage model (LLM) into a spoken language model (SLM) capable of both speech\nand text generation. Compared to modular and aligned MLLMs, native MLLMs\npreserve richer paralinguistic features such as emotion and prosody, and\ngenerate speech responses directly within the backbone LLM rather than using a\nseparate speech decoder. This integration also results in lower response\nlatency and smoother interaction. However, native MLLMs suffer from\ncatastrophic forgetting and performance degradation because the available\npaired speech-text data is insufficient to support the pretraining of MLLMs\ncompared to the vast amount of text data required to pretrain text LLMs. To\naddress this issue, we propose DeepTalk, a framework for adaptive modality\nexpert learning based on a Mixture of Experts (MoE) architecture. DeepTalk\nfirst adaptively distinguishes modality experts according to their modality\nload within the LLM. Each modality expert then undergoes specialized\nsingle-modality training, followed by joint multimodal collaborative training.\nAs a result, DeepTalk incurs only a 5.5% performance drop compared to the\noriginal LLM, which is significantly lower than the average performance drop of\nover 20% typically seen in native MLLMs (such as GLM-4-Voice), and is on par\nwith modular MLLMs. Meanwhile, the end-to-end dialogue latency remains within\n0.5 seconds, ensuring a seamless and intelligent speech interaction experience.\nCode and models are released at https://github.com/talkking/DeepTalk.", "comment": "Under Review", "pdf_url": "http://arxiv.org/pdf/2506.21864v2", "cate": "cs.CL", "date": "2025-06-27", "updated": "2025-07-09"}
{"id": "2411.01849", "title": "A tamed-adaptive Milstein scheme for stochastic differential equations with low regularity coefficients", "authors": ["Thi-Huong Vu", "Hoang-Long Ngo", "Duc-Trong Luong", "Tran Ngoc Khue"], "categories": ["math.PR", "cs.NA", "math.NA"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.01849v2", "summary": "We propose a tamed-adaptive Milstein scheme for stochastic differential\nequations in which the first-order derivatives of the coefficients are locally\nH\\\"older continuous of order $\\alpha$. We show that the scheme converges in the\n$L_2$-norm with a rate of $(1+\\alpha)/2$ over both finite intervals $[0, T]$\nand the infinite interval $(0, +\\infty)$, under certain growth conditions on\nthe coefficients.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.01849v2", "cate": "math.PR", "date": "2024-11-04", "updated": "2025-07-09"}
{"id": "2507.06617", "title": "The Small Phase Condition is Necessary for Symmetric Systems", "authors": ["Xiaokan Yang", "Wei Chen", "Li Qiu"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Under review at Automatica", "url": "http://arxiv.org/abs/2507.06617v1", "summary": "In this paper, we show that the small phase condition is both sufficient and\nnecessary to ensure the feedback stability when the interconnected systems are\nsymmetric. Such symmetric systems arise in diverse applications. The key lies\nin that, for a complex symmetric and semi-sectorial matrix, the transformation\nmatrix in its generalized sectorial decomposition can be taken to be real. Such\na result fills the gap of phase based necessary condition for the feedback\nstability of symmetric systems, and serves as a counterpart of the necessity\nresult for small gain condition. Moreover, we explore the necessity of small\nphase condition for general asymmetric systems. Some insightful results are\npresented, which help to clarify the main challenge in the general case.", "comment": "Under review at Automatica", "pdf_url": "http://arxiv.org/pdf/2507.06617v1", "cate": "eess.SY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2310.17295", "title": "Normal Forms for Elements of ${}^*$-Continuous Kleene Algebras Representing the Context-Free Languages", "authors": ["Mark Hopkins", "Hans Leiß"], "categories": ["cs.FL", "F.4.3"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      3rd version. 42 pages, 4 figures. Typos corrected", "url": "http://arxiv.org/abs/2310.17295v4", "summary": "Within the tensor product $K \\mathop{\\otimes_{\\cal R}} C_2'$ of any\n${}^*$-continuous Kleene algebra $K$ with the polycyclic ${}^*$-continuous\nKleene algebra $C_2'$ over two bracket pairs there is a copy of the fixed-point\nclosure of $K$: the centralizer of $C_2'$ in $K \\mathop{\\otimes_{\\cal R}}\nC_2'$. Using an automata-theoretic representation of elements of\n$K\\mathop{\\otimes_{\\cal R}} C_2'$ \\`a la Kleene, with the aid of normal form\ntheorems that restrict the occurrences of brackets on paths through the\nautomata, we develop a foundation for a calculus of context-free expressions\nwithout variable binders. We also give some results on the bra-ket\n${}^*$-continuous Kleene algebra $C_2$, motivate the ``completeness equation''\nthat distinguishes $C_2$ from $C_2'$, and show that $C_2'$ already validates a\nrelativized form of this equation.", "comment": "3rd version. 42 pages, 4 figures. Typos corrected", "pdf_url": "http://arxiv.org/pdf/2310.17295v4", "cate": "cs.FL", "date": "2023-10-26", "updated": "2025-07-09"}
{"id": "2506.23581", "title": "PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection", "authors": ["Xiao Li", "Yiming Zhu", "Yifan Huang", "Wei Zhang", "Yingzhe He", "Jie Shi", "Xiaolin Hu"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2506.23581v2", "summary": "Object detection plays a crucial role in many security-sensitive\napplications. However, several recent studies have shown that object detectors\ncan be easily fooled by physically realizable attacks, \\eg, adversarial patches\nand recent adversarial textures, which pose realistic and urgent threats.\nAdversarial Training (AT) has been recognized as the most effective defense\nagainst adversarial attacks. While AT has been extensively studied in the\n$l_\\infty$ attack settings on classification models, AT against physically\nrealizable attacks on object detectors has received limited exploration. Early\nattempts are only performed to defend against adversarial patches, leaving AT\nagainst a wider range of physically realizable attacks under-explored. In this\nwork, we consider defending against various physically realizable attacks with\na unified AT method. We propose PBCAT, a novel Patch-Based Composite\nAdversarial Training strategy. PBCAT optimizes the model by incorporating the\ncombination of small-area gradient-guided adversarial patches and imperceptible\nglobal adversarial perturbations covering the entire image. With these designs,\nPBCAT has the potential to defend against not only adversarial patches but also\nunseen physically realizable attacks such as adversarial textures. Extensive\nexperiments in multiple settings demonstrated that PBCAT significantly improved\nrobustness against various physically realizable attacks over state-of-the-art\ndefense methods. Notably, it improved the detection accuracy by 29.7\\% over\nprevious defense methods under one recent adversarial texture attack.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2506.23581v2", "cate": "cs.CV", "date": "2025-06-30", "updated": "2025-07-09"}
{"id": "2506.20623", "title": "Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning", "authors": ["Fariba Jangjoo", "Matteo Marsili", "Yasser Roudi"], "categories": ["cs.LG", "cond-mat.dis-nn", "physics.data-an", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      21 pages, 3 figures", "url": "http://arxiv.org/abs/2506.20623v2", "summary": "Closed-loop learning is the process of repeatedly estimating a model from\ndata generated from the model itself. It is receiving great attention due to\nthe possibility that large neural network models may, in the future, be\nprimarily trained with data generated by artificial neural networks themselves.\nWe study this process for models that belong to exponential families, deriving\nequations of motions that govern the dynamics of the parameters. We show that\nmaximum likelihood estimation of the parameters endows sufficient statistics\nwith the martingale property and that as a result the process converges to\nabsorbing states that amplify initial biases present in the data. However, we\nshow that this outcome may be prevented if the data contains at least one data\npoint generated from a ground truth model, by relying on maximum a posteriori\nestimation or by introducing regularisation.", "comment": "21 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2506.20623v2", "cate": "cs.LG", "date": "2025-06-25", "updated": "2025-07-09"}
{"id": "2503.02195", "title": "HyperGCT: A Dynamic Hyper-GNN-Learned Geometric Constraint for 3D Registration", "authors": ["Xiyu Zhang", "Jiayi Ma", "Jianwei Guo", "Wei Hu", "Zhaoshuai Qi", "Fei Hui", "Jiaqi Yang", "Yanning Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2503.02195v2", "summary": "Geometric constraints between feature matches are critical in 3D point cloud\nregistration problems. Existing approaches typically model unordered matches as\na consistency graph and sample consistent matches to generate hypotheses.\nHowever, explicit graph construction introduces noise, posing great challenges\nfor handcrafted geometric constraints to render consistency. To overcome this,\nwe propose HyperGCT, a flexible dynamic Hyper-GNN-learned geometric ConstrainT\nthat leverages high-order consistency among 3D correspondences. To our\nknowledge, HyperGCT is the first method that mines robust geometric constraints\nfrom dynamic hypergraphs for 3D registration. By dynamically optimizing the\nhypergraph through vertex and edge feature aggregation, HyperGCT effectively\ncaptures the correlations among correspondences, leading to accurate hypothesis\ngeneration. Extensive experiments on 3DMatch, 3DLoMatch, KITTI-LC, and ETH show\nthat HyperGCT achieves state-of-the-art performance. Furthermore, HyperGCT is\nrobust to graph noise, demonstrating a significant advantage in terms of\ngeneralization.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.02195v2", "cate": "cs.CV", "date": "2025-03-04", "updated": "2025-07-09"}
{"id": "2506.23463", "title": "What to Keep and What to Drop: Adaptive Table Filtering Framework", "authors": ["WonJune Jang"], "categories": ["cs.CL", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      26 pages, 9 figures", "url": "http://arxiv.org/abs/2506.23463v2", "summary": "Large language models (LLMs) for table-based reasoning often struggle with\nlarge tables due to input length limits. We propose ATF (Adaptive Table\nFiltering Framework), a modular and question-aware filtering pipeline that\nprunes uninformative columns and rows using LLM-generated column descriptions,\nclustering, and sparse-dense alignment scores. ATF integrates seamlessly with\nexisting models (e.g., TAPAS, TAPEX) without retraining. Experiments show that\nATF reduces table cells by 70%, boosting performance on out-of-domain TableQA\ntasks while causing slight performance drops on Table Fact Verification, where\nfull-table context is more critical. These results highlight ATF's ability to\nadaptively balance informativeness and minimalism across tasks.", "comment": "26 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2506.23463v2", "cate": "cs.CL", "date": "2025-06-30", "updated": "2025-07-09"}
{"id": "2507.06713", "title": "Coordinated Fast Frequency Regulation in Dynamic Virtual Power Plants via Disturbance Estimation", "authors": ["Saif Ahmad", "Seifeddine Ben Elghali", "Hafiz Ahmed"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06713v1", "summary": "In the context of dynamic virtual power plants (DVPPs), the integration of\nfrequency containment reserve (FCR) and fast frequency control (FFC) enabled\nvia local compensation of power imbalance represents a significant advancement\nin decentralized frequency regulation. However, they still have to cope with\nthe limited power and energy capacities associated with commonly available\nstorage solutions. This work combines a disturbance estimation based\ndecentralized local control with distributed imbalance compensation in the\nevent of local shortfall. The layered architecture facilitates fast local\ncorrections in power setpoints while enabling coordination between neighbouring\nDVPP nodes to leverage the aggregated capacity, ensuring scalable and efficient\noperation suitable for renewable-heavy future grids. The proposed approach is\nvalidated on an illustrative 4-bus system with a high percentage of renewables.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06713v1", "cate": "eess.SY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.00090", "title": "Generating Heterogeneous Multi-dimensional Data : A Comparative Study", "authors": ["Michael Corbeau", "Emmanuelle Claeys", "Mathieu Serrurier", "Pascale Zaraté"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      accepted at IEEE SMC 2025 Vienna", "url": "http://arxiv.org/abs/2507.00090v2", "summary": "Allocation of personnel and material resources is highly sensible in the case\nof firefighter interventions. This allocation relies on simulations to\nexperiment with various scenarios. The main objective of this allocation is the\nglobal optimization of the firefighters response. Data generation is then\nmandatory to study various scenarios In this study, we propose to compare\ndifferent data generation methods. Methods such as Random Sampling, Tabular\nVariational Autoencoders, standard Generative Adversarial Networks, Conditional\nTabular Generative Adversarial Networks and Diffusion Probabilistic Models are\nexamined to ascertain their efficacy in capturing the intricacies of\nfirefighter interventions. Traditional evaluation metrics often fall short in\ncapturing the nuanced requirements of synthetic datasets for real-world\nscenarios. To address this gap, an evaluation of synthetic data quality is\nconducted using a combination of domain-specific metrics tailored to the\nfirefighting domain and standard measures such as the Wasserstein distance.\nDomain-specific metrics include response time distribution, spatial-temporal\ndistribution of interventions, and accidents representation. These metrics are\ndesigned to assess data variability, the preservation of fine and complex\ncorrelations and anomalies such as event with a very low occurrence, the\nconformity with the initial statistical distribution and the operational\nrelevance of the synthetic data. The distribution has the particularity of\nbeing highly unbalanced, none of the variables following a Gaussian\ndistribution, adding complexity to the data generation process.", "comment": "accepted at IEEE SMC 2025 Vienna", "pdf_url": "http://arxiv.org/pdf/2507.00090v2", "cate": "cs.LG", "date": "2025-06-30", "updated": "2025-07-09"}
{"id": "2507.01951", "title": "Test-Time Scaling with Reflective Generative Model", "authors": ["Zixiao Wang", "Yuxin Wang", "Xiaorui Wang", "Mengting Xing", "Jie Gao", "Jianjun Xu", "Guangcan Liu", "Chenhui Jin", "Zhuo Wang", "Shengzhuo Zhang", "Hongtao Xie"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.01951v2", "summary": "We introduce our first reflective generative model MetaStone-S1, which\nobtains OpenAI o3-mini's performance via the new Reflective Generative Form.\nThe new form focuses on high-quality reasoning trajectory selection and\ncontains two novelties: 1) A unified interface for policy and process reward\nmodel: we share the backbone network and use task-specific heads for reasoning\ntrajectory predicting and scoring respectively, introducing only 53M extra\nparameters for trajectory scoring. 2) Eliminating the reliance on process-level\nannotation: we provide a self-supervised process reward model, which can\ndirectly learn the high-quality reasoning trajectory selection from the outcome\nreward. Equipped with the reflective generative form, MetaStone-S1 is naturally\nsuitable for test-time scaling, and we provide three reasoning effort modes\n(low, medium, and high) based on the controllable thinking length. Experiments\ndemonstrate that our MetaStone-S1 achieves comparable performance to OpenAI\no3-mini's series with only 32B parameter size. To support the research\ncommunity, we have open-sourced MetaStone-S1 at\nhttps://github.com/MetaStone-AI/MetaStone-S1.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01951v2", "cate": "cs.LG", "date": "2025-07-02", "updated": "2025-07-09"}
{"id": "2503.11647", "title": "ReCamMaster: Camera-Controlled Generative Rendering from A Single Video", "authors": ["Jianhong Bai", "Menghan Xia", "Xiao Fu", "Xintao Wang", "Lianrui Mu", "Jinwen Cao", "Zuozhu Liu", "Haoji Hu", "Xiang Bai", "Pengfei Wan", "Di Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2503.11647v2", "summary": "Camera control has been actively studied in text or image conditioned video\ngeneration tasks. However, altering camera trajectories of a given video\nremains under-explored, despite its importance in the field of video creation.\nIt is non-trivial due to the extra constraints of maintaining multiple-frame\nappearance and dynamic synchronization. To address this, we present\nReCamMaster, a camera-controlled generative video re-rendering framework that\nreproduces the dynamic scene of an input video at novel camera trajectories.\nThe core innovation lies in harnessing the generative capabilities of\npre-trained text-to-video models through a simple yet powerful video\nconditioning mechanism--its capability is often overlooked in current research.\nTo overcome the scarcity of qualified training data, we construct a\ncomprehensive multi-camera synchronized video dataset using Unreal Engine 5,\nwhich is carefully curated to follow real-world filming characteristics,\ncovering diverse scenes and camera movements. It helps the model generalize to\nin-the-wild videos. Lastly, we further improve the robustness to diverse inputs\nthrough a meticulously designed training strategy. Extensive experiments show\nthat our method substantially outperforms existing state-of-the-art approaches.\nOur method also finds promising applications in video stabilization,\nsuper-resolution, and outpainting. Our code and dataset are publicly available\nat: https://github.com/KwaiVGI/ReCamMaster.", "comment": "Project page: https://jianhongbai.github.io/ReCamMaster/", "pdf_url": "http://arxiv.org/pdf/2503.11647v2", "cate": "cs.CV", "date": "2025-03-14", "updated": "2025-07-09"}
{"id": "2506.23921", "title": "The Trilemma of Truth in Large Language Models", "authors": ["Germans Savcisens", "Tina Eliassi-Rad"], "categories": ["cs.CL", "cs.LG", "stat.ML", "68T50", "I.2.6; I.2.7; G.3"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23921v2", "summary": "We often attribute human characteristics to large language models (LLMs) and\nclaim that they \"know\" certain things. LLMs have an internal probabilistic\nknowledge that represents information retained during training. How can we\nassess the veracity of this knowledge? We examine two common methods for\nprobing the veracity of LLMs and discover several assumptions that are flawed.\nTo address these flawed assumptions, we introduce sAwMIL (short for Sparse\nAware Multiple-Instance Learning), a probing method that utilizes the internal\nactivations of LLMs to separate statements into true, false, and neither.\nsAwMIL is based on multiple-instance learning and conformal prediction. We\nevaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including\nboth default and chat-based variants, as well as on 3 new datasets. Among the\ninsights we provide are: (1) the veracity signal is often concentrated in the\nthird quarter of an LLM's depth; (2) truth and falsehood signals are not always\nsymmetric; (3) linear probes perform better on chat models than on default\nmodels; (4) nonlinear probes may be required to capture veracity signals for\nsome LLMs with reinforcement learning from human feedback or knowledge\ndistillation; and (5) LLMs capture a third type of signal that is distinct from\ntrue and false and is neither true nor false. These findings provide a reliable\nmethod for verifying what LLMs \"know\" and how certain they are of their\nprobabilistic internal knowledge.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23921v2", "cate": "cs.CL", "date": "2025-06-30", "updated": "2025-07-08"}
{"id": "2507.06736", "title": "Techno-economic analysis of decarbonized backup power systems using scenario-based stochastic optimization", "authors": ["Jonas Schweiger", "Ruaridh Macdonald"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      30 pages, 2 tables, 13 figures", "url": "http://arxiv.org/abs/2507.06736v1", "summary": "In the context of growing concerns about power disruptions, grid reliability\nand the need for decarbonization, this study evaluates a broad range of clean\nbackup power systems (BPSs) to replace traditional emergency diesel generators.\nA scenario-based stochastic optimization framework using actual load profiles\nand outage probabilities is proposed to assess the most promising options from\na pool of 27 technologies. This framework allows a comparison of\ncost-effectiveness and environmental impact of individual technologies and\nhybrid BPSs across various scenarios. The results highlight the trade-off\nbetween total annual system cost and emissions. Significant emission reductions\ncan be achieved at moderate cost increases but deep decarbonization levels\nincur higher costs. Primary and secondary batteries are included in optimal\nclean fuel-based systems across all decarbonization levels, combining\ncost-effective power delivery and long-term storage benefits. The findings\nhighlight the often-overlooked importance of fuel replacement on both emissions\nand costs. Among the assessed technologies, ammonia generators and hydrogen\nfuel cells combined with secondary iron-air batteries emerge as cost-effective\nsolutions for achieving decarbonization goals. To ensure a broad range of\napplicability, the study outlines the impact of emergency fuel purchases,\nvarying demand patterns and demand response options on the optimal BPS. The\nresearch findings are valuable for optimizing the design of clean BPSs to\neconomically meet the needs of many facility types and decarbonization targets.", "comment": "30 pages, 2 tables, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.06736v1", "cate": "eess.SY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.01786", "title": "Probing and Steering Evaluation Awareness of Language Models", "authors": ["Jord Nguyen", "Khiem Hoang", "Carlo Leonardo Attubato", "Felix Hofstätter"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Actionable Interpretability Workshop (Poster) and Workshop on Technical AI Governance (Poster) at ICML 2025, Vancouver, Canada", "url": "http://arxiv.org/abs/2507.01786v2", "summary": "Language models can distinguish between testing and deployment phases -- a\ncapability known as evaluation awareness. This has significant safety and\npolicy implications, potentially undermining the reliability of evaluations\nthat are central to AI governance frameworks and voluntary industry\ncommitments. In this paper, we study evaluation awareness in\nLlama-3.3-70B-Instruct. We show that linear probes can separate real-world\nevaluation and deployment prompts, suggesting that current models internally\nrepresent this distinction. We also find that current safety evaluations are\ncorrectly classified by the probes, suggesting that they already appear\nartificial or inauthentic to models. Our findings underscore the importance of\nensuring trustworthy evaluations and understanding deceptive capabilities. More\nbroadly, our work showcases how model internals may be leveraged to support\nblackbox methods in safety audits, especially for future models more competent\nat evaluation awareness and deception.", "comment": "Actionable Interpretability Workshop (Poster) and Workshop on\n  Technical AI Governance (Poster) at ICML 2025, Vancouver, Canada", "pdf_url": "http://arxiv.org/pdf/2507.01786v2", "cate": "cs.CL", "date": "2025-07-02", "updated": "2025-07-09"}
{"id": "2507.03498", "title": "Reinforcement Learning-based Feature Generation Algorithm for Scientific Data", "authors": ["Meng Xiao", "Junfeng Zhou", "Yuanchun Zhou"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, in Chinese language, accepted by Journal of Computer Research and Development", "url": "http://arxiv.org/abs/2507.03498v2", "summary": "Feature generation (FG) aims to enhance the prediction potential of original\ndata by constructing high-order feature combinations and removing redundant\nfeatures. It is a key preprocessing step for tabular scientific data to improve\ndownstream machine-learning model performance. Traditional methods face the\nfollowing two challenges when dealing with the feature generation of scientific\ndata: First, the effective construction of high-order feature combinations in\nscientific data necessitates profound and extensive domain-specific expertise.\nSecondly, as the order of feature combinations increases, the search space\nexpands exponentially, imposing prohibitive human labor consumption.\nAdvancements in the Data-Centric Artificial Intelligence (DCAI) paradigm have\nopened novel avenues for automating feature generation processes. Inspired by\nthat, this paper revisits the conventional feature generation workflow and\nproposes the Multi-agent Feature Generation (MAFG) framework. Specifically, in\nthe iterative exploration stage, multi-agents will construct mathematical\ntransformation equations collaboratively, synthesize and identify feature\ncombinations ex-hibiting high information content, and leverage a reinforcement\nlearning mechanism to evolve their strategies. Upon completing the exploration\nphase, MAFG integrates the large language models (LLMs) to interpreta-tively\nevaluate the generated features of each significant model performance\nbreakthrough. Experimental results and case studies consistently demonstrate\nthat the MAFG framework effectively automates the feature generation process\nand significantly enhances various downstream scientific data mining tasks.", "comment": "12 pages, in Chinese language, accepted by Journal of Computer\n  Research and Development", "pdf_url": "http://arxiv.org/pdf/2507.03498v2", "cate": "cs.LG", "date": "2025-07-04", "updated": "2025-07-09"}
{"id": "2503.18709", "title": "Revisiting Automatic Data Curation for Vision Foundation Models in Digital Pathology", "authors": ["Boqi Chen", "Cédric Vincent-Cuaz", "Lydia A. Schoenpflug", "Manuel Madeira", "Lisa Fournier", "Vaishnavi Subramanian", "Sonali Andani", "Samuel Ruiperez-Campillo", "Julia E. Vogt", "Raphaëlle Luisier", "Dorina Thanou", "Viktor H. Koelzer", "Pascal Frossard", "Gabriele Campanella", "Gunnar Rätsch"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      MICCAI 2025", "url": "http://arxiv.org/abs/2503.18709v2", "summary": "Vision foundation models (FMs) are accelerating the development of digital\npathology algorithms and transforming biomedical research. These models learn,\nin a self-supervised manner, to represent histological features in highly\nheterogeneous tiles extracted from whole-slide images (WSIs) of real-world\npatient samples. The performance of these FMs is significantly influenced by\nthe size, diversity, and balance of the pre-training data. However, data\nselection has been primarily guided by expert knowledge at the WSI level,\nfocusing on factors such as disease classification and tissue types, while\nlargely overlooking the granular details available at the tile level. In this\npaper, we investigate the potential of unsupervised automatic data curation at\nthe tile-level, taking into account 350 million tiles. Specifically, we apply\nhierarchical clustering trees to pre-extracted tile embeddings, allowing us to\nsample balanced datasets uniformly across the embedding space of the pretrained\nFM. We further identify these datasets are subject to a trade-off between size\nand balance, potentially compromising the quality of representations learned by\nFMs, and propose tailored batch sampling strategies to mitigate this effect. We\ndemonstrate the effectiveness of our method through improved performance on a\ndiverse range of clinically relevant downstream tasks.", "comment": "MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2503.18709v2", "cate": "cs.CV", "date": "2025-03-24", "updated": "2025-07-08"}
{"id": "2507.03253", "title": "RefineX: Learning to Refine Pre-training Data at Scale from Expert-Guided Programs", "authors": ["Baolong Bi", "Shenghua Liu", "Xingzhang Ren", "Dayiheng Liu", "Junyang Lin", "Yiwei Wang", "Lingrui Mei", "Junfeng Fang", "Jiafeng Guo", "Xueqi Cheng"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03253v2", "summary": "The foundational capabilities of large language models (LLMs) are deeply\ninfluenced by the quality of their pre-training corpora. However, enhancing\ndata quality at scale remains a significant challenge, primarily due to the\ntrade-off between refinement effectiveness and processing efficiency. While\nrule-based filtering remains the dominant paradigm, it typically operates at\nthe document level and lacks the granularity needed to refine specific content\nwithin documents. Inspired by emerging work such as ProX, we propose\n$\\textbf{RefineX}$, a novel framework for large-scale, surgical refinement of\npre-training data through programmatic editing tasks. RefineX enables efficient\nand fine-grained data refinement while reliably preserving the diversity and\nnaturalness of raw text. The core strength of RefineX lies in distilling\nhigh-quality, expert-guided end-to-end refinement results into minimal\nedit-based deletion programs. This high-precision distillation pipeline is used\nto train an efficient and reliable refine model that can systematically improve\nevery instance in the corpus at scale. We evaluate RefineX across from-scratch\npre-training at multiple model scales and find that it consistently outperforms\nmodels trained on raw, filtered, or alternatively refined data across diverse\ndownstream tasks. On the 750M model, RefineX yields 2.6%-7.2% average gains on\nlighteval tasks, and achieves comparable performance using significantly fewer\ntraining tokens. Further analysis shows that RefineX reliably enhances text\nquality with both high efficiency and precision, outperforming prior approaches\nsuch as end-to-end generation and Prox-C. These results position RefineX as a\nscalable, effective, and reliable solution for optimizing pre-training data in\nmodern LLM pipelines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03253v2", "cate": "cs.CL", "date": "2025-07-04", "updated": "2025-07-08"}
{"id": "2507.06796", "title": "Optimisation of Electrolyser Operation: Integrating External Heat", "authors": ["Matthias Derez", "Alexander Hoogsteyn", "Erik Delarue"], "categories": ["eess.SY", "cond-mat.mtrl-sci", "cs.SY", "econ.GN", "q-fin.EC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06796v1", "summary": "Integrating external heat into electrolysers can reduce the electrical power\ndemand for carbon-neutral hydrogen production. Efficient operation requires\ndetailed models that incorporate heat availability and its effect on startup\ncosts. This paper advances existing operational models by endogenously\nmodelling startup costs and direct heat integration, based on a piecewise\nlinear approximation of the electrochemical equations. We analyse the impact of\nlow- and high-temperature heat integration on the efficiency and profitability\nof hydrogen production for solid oxide and proton exchange membrane\nelectrolysis technologies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06796v1", "cate": "eess.SY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.03633", "title": "From Video to EEG: Adapting Joint Embedding Predictive Architecture to Uncover Visual Concepts in Brain Signal Analysis", "authors": ["Amirabbas Hojjati", "Lu Li", "Ibrahim Hameed", "Anis Yazidi", "Pedro G. Lind", "Rabindra Khadka"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03633v3", "summary": "EEG signals capture brain activity with high temporal and low spatial\nresolution, supporting applications such as neurological diagnosis, cognitive\nmonitoring, and brain-computer interfaces. However, effective analysis is\nhindered by limited labeled data, high dimensionality, and the absence of\nscalable models that fully capture spatiotemporal dependencies. Existing\nself-supervised learning (SSL) methods often focus on either spatial or\ntemporal features, leading to suboptimal representations. To this end, we\npropose EEG-VJEPA, a novel adaptation of the Video Joint Embedding Predictive\nArchitecture (V-JEPA) for EEG classification. By treating EEG as video-like\nsequences, EEG-VJEPA learns semantically meaningful spatiotemporal\nrepresentations using joint embeddings and adaptive masking. To our knowledge,\nthis is the first work that exploits V-JEPA for EEG classification and explores\nthe visual concepts learned by the model. Evaluations on the publicly available\nTemple University Hospital (TUH) Abnormal EEG dataset show that EEG-VJEPA\noutperforms existing state-of-the-art models in classification accuracy. Beyond\nclassification accuracy, EEG-VJEPA captures physiologically relevant spatial\nand temporal signal patterns, offering interpretable embeddings that may\nsupport human-AI collaboration in diagnostic workflows. These findings position\nEEG-VJEPA as a promising framework for scalable, trustworthy EEG analysis in\nreal-world clinical settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03633v3", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-09"}
{"id": "2507.03772", "title": "Skewed Score: A statistical framework to assess autograders", "authors": ["Magda Dubois", "Harry Coppock", "Mario Giulianelli", "Timo Flesch", "Lennart Luettgau", "Cozmin Ududec"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03772v2", "summary": "The evaluation of large language model (LLM) outputs is increasingly\nperformed by other LLMs, a setup commonly known as \"LLM-as-a-judge\", or\nautograders. While autograders offer a scalable alternative to human\nevaluation, they have shown mixed reliability and may exhibit systematic\nbiases, depending on response type, scoring methodology, domain specificity, or\nother factors. Here we propose a statistical framework based on Bayesian\ngeneralised linear models (GLMs) that enables researchers to simultaneously\nassess their autograders while addressing their primary research questions\n(e.g., LLM evaluation). Our approach models evaluation outcomes (e.g., scores\nor pairwise preferences) as a function of properties of the grader (e.g., human\nvs. autograder) and the evaluated item (e.g., response length or the LLM that\ngenerated it), allowing for explicit quantification of scoring differences and\npotential biases within a unified framework. In addition, our method can be\nused to augment traditional metrics such as inter-rater agreement, by providing\nuncertainty estimates and clarifying sources of disagreement. Overall, this\napproach contributes to more robust and interpretable use of autograders in LLM\nevaluation, enabling both performance analysis and bias detection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03772v2", "cate": "cs.LG", "date": "2025-07-04", "updated": "2025-07-09"}
{"id": "2503.21692", "title": "RapidPoseTriangulation: Multi-view Multi-person Whole-body Human Pose Triangulation in a Millisecond", "authors": ["Daniel Bermuth", "Alexander Poeppel", "Wolfgang Reif"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.21692v3", "summary": "The integration of multi-view imaging and pose estimation represents a\nsignificant advance in computer vision applications, offering new possibilities\nfor understanding human movement and interactions. This work presents a new\nalgorithm that improves multi-view multi-person pose estimation, focusing on\nfast triangulation speeds and good generalization capabilities.\n  The approach extends to whole-body pose estimation, capturing details from\nfacial expressions to finger movements across multiple individuals and\nviewpoints. Adaptability to different settings is demonstrated through strong\nperformance across unseen datasets and configurations. To support further\nprogress in this field, all of this work is publicly accessible.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.21692v3", "cate": "cs.CV", "date": "2025-03-27", "updated": "2025-07-09"}
{"id": "2507.03711", "title": "Can LLMs Play Ô Ăn Quan Game? A Study of Multi-Step Planning and Decision Making", "authors": ["Sang Quang Nguyen", "Kiet Van Nguyen", "Vinh-Tiep Nguyen", "Thanh Duc Ngo", "Ngan Luu-Thuy Nguyen", "Duy-Dinh Le"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted paper at MAPR 2025", "url": "http://arxiv.org/abs/2507.03711v3", "summary": "In this paper, we explore the ability of large language models (LLMs) to plan\nand make decisions through the lens of the traditional Vietnamese board game,\n\\^O \\u{A}n Quan. This game, which involves a series of strategic token\nmovements and captures, offers a unique environment for evaluating the\ndecision-making and strategic capabilities of LLMs. Specifically, we develop\nvarious agent personas, ranging from aggressive to defensive, and employ the\n\\^O \\u{A}n Quan game as a testbed for assessing LLM performance across\ndifferent strategies. Through experimentation with models like\nLlama-3.2-3B-Instruct, Llama-3.1-8B-Instruct, and Llama-3.3-70B-Instruct, we\naim to understand how these models execute strategic decision-making, plan\nmoves, and manage dynamic game states. The results will offer insights into the\nstrengths and weaknesses of LLMs in terms of reasoning and strategy,\ncontributing to a deeper understanding of their general capabilities.", "comment": "Accepted paper at MAPR 2025", "pdf_url": "http://arxiv.org/pdf/2507.03711v3", "cate": "cs.CL", "date": "2025-07-04", "updated": "2025-07-09"}
{"id": "2507.06935", "title": "A nonlinear dead-time compensation method for path tracking control", "authors": ["Karin Festl", "Michael Stolz"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Springer book on Recent Advances in Autonomous Vehicle Technology", "url": "http://arxiv.org/abs/2507.06935v1", "summary": "In the realm of autonomous vehicle technologies and advanced driver\nassistance systems, precise and reliable path tracking controllers are vital\nfor safe and efficient navigation. However the presence of dead time in the\nvehicle control systems poses a challenge to real-world systems. Input and\noutput delays are caused by factors like sensor processing and mechanical\nresponse and can range up to a few hundred milliseconds. This chapter addresses\nthe problem of dead time in path tracking control and proposes a method to\ncompensate the dead time. The proposed solution involves a nonlinear prediction\nmodel, in a structure similar to the Smith predictor, but incorporating the\nkinematic behavior of the vehicle plant system. The implementation avoids\nnumeric integration or optimization, enabling a fast execution. Simulation\ntests with various controllers and disturbances, including dead-time\nuncertainty, demonstrate the efficacy of the dead-time compensation method.\nResults indicate improved control performance in all tested scenarios.", "comment": "Springer book on Recent Advances in Autonomous Vehicle Technology", "pdf_url": "http://arxiv.org/pdf/2507.06935v1", "cate": "eess.SY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.04981", "title": "Classification of autoimmune diseases from Peripheral blood TCR repertoires by multimodal multi-instance learning", "authors": ["Ruihao Zhang", "Mao chen", "Fei Ye", "Dandan Meng", "Yixuan Huang", "Xiao Liu"], "categories": ["cs.LG", "cs.AI", "q-bio.GN"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      7 figures, 4 tabels", "url": "http://arxiv.org/abs/2507.04981v3", "summary": "T cell receptor (TCR) repertoires encode critical immunological signatures\nfor autoimmune diseases, yet their clinical application remains limited by\nsequence sparsity and low witness rates. We developed EAMil, a multi-instance\ndeep learning framework that leverages TCR sequencing data to diagnose systemic\nlupus erythematosus (SLE) and rheumatoid arthritis (RA) with exceptional\naccuracy. By integrating PrimeSeq feature extraction with ESMonehot encoding\nand enhanced gate attention mechanisms, our model achieved state-of-the-art\nperformance with AUCs of 98.95% for SLE and 97.76% for RA. EAMil successfully\nidentified disease-associated genes with over 90% concordance with established\ndifferential analyses and effectively distinguished disease-specific TCR genes.\nThe model demonstrated robustness in classifying multiple disease categories,\nutilizing the SLEDAI score to stratify SLE patients by disease severity as well\nas to diagnose the site of damage in SLE patients, and effectively controlling\nfor confounding factors such as age and gender. This interpretable framework\nfor immune receptor analysis provides new insights for autoimmune disease\ndetection and classification with broad potential clinical applications across\nimmune-mediated conditions.", "comment": "7 figures, 4 tabels", "pdf_url": "http://arxiv.org/pdf/2507.04981v3", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-09"}
{"id": "2507.04446", "title": "Tail-aware Adversarial Attacks: A Distributional Approach to Efficient LLM Jailbreaking", "authors": ["Tim Beyer", "Yan Scholten", "Leo Schwinn", "Stephan Günnemann"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04446v2", "summary": "To guarantee safe and robust deployment of large language models (LLMs) at\nscale, it is critical to accurately assess their adversarial robustness.\nExisting adversarial attacks typically target harmful responses in\nsingle-point, greedy generations, overlooking the inherently stochastic nature\nof LLMs. In this paper, we propose a novel framework for adversarial robustness\nevaluation that explicitly models the entire output distribution, including\ntail-risks, providing better estimates for model robustness at scale. By\ncasting the attack process as a resource allocation problem between\noptimization and sampling, we determine compute-optimal tradeoffs and show that\nintegrating sampling into existing attacks boosts ASR by up to 48% and improves\nefficiency by up to two orders of magnitude. Our framework also enables us to\nanalyze how different attack algorithms affect output harm distributions.\nSurprisingly, we find that most optimization strategies have little effect on\noutput harmfulness. Finally, we introduce a data-free proof-of-concept\nobjective based on entropy-maximization to demonstrate how our tail-aware\nperspective enables new optimization targets. Overall, our findings highlight\nthe importance of tail-aware attacks and evaluation protocols to accurately\nassess and strengthen LLM safety.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04446v2", "cate": "cs.LG", "date": "2025-07-06", "updated": "2025-07-09"}
{"id": "2504.09990", "title": "Correlative and Discriminative Label Grouping for Multi-Label Visual Prompt Tuning", "authors": ["LeiLei Ma", "Shuo Xu", "MingKun Xie", "Lei Wang", "Dengdi Sun", "Haifeng Zhao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2025", "url": "http://arxiv.org/abs/2504.09990v2", "summary": "Modeling label correlations has always played a pivotal role in multi-label\nimage classification (MLC), attracting significant attention from researchers.\nHowever, recent studies have overemphasized co-occurrence relationships among\nlabels, which can lead to overfitting risk on this overemphasis, resulting in\nsuboptimal models. To tackle this problem, we advocate for balancing\ncorrelative and discriminative relationships among labels to mitigate the risk\nof overfitting and enhance model performance. To this end, we propose the\nMulti-Label Visual Prompt Tuning framework, a novel and parameter-efficient\nmethod that groups classes into multiple class subsets according to label\nco-occurrence and mutual exclusivity relationships, and then models them\nrespectively to balance the two relationships. In this work, since each group\ncontains multiple classes, multiple prompt tokens are adopted within Vision\nTransformer (ViT) to capture the correlation or discriminative label\nrelationship within each group, and effectively learn correlation or\ndiscriminative representations for class subsets. On the other hand, each group\ncontains multiple group-aware visual representations that may correspond to\nmultiple classes, and the mixture of experts (MoE) model can cleverly assign\nthem from the group-aware to the label-aware, adaptively obtaining label-aware\nrepresentation, which is more conducive to classification. Experiments on\nmultiple benchmark datasets show that our proposed approach achieves\ncompetitive results and outperforms SOTA methods on multiple pre-trained\nmodels.", "comment": "IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\n  2025", "pdf_url": "http://arxiv.org/pdf/2504.09990v2", "cate": "cs.CV", "date": "2025-04-14", "updated": "2025-07-09"}
{"id": "2507.03933", "title": "Losing our Tail -- Again: On (Un)Natural Selection And Multilingual Large Language Models", "authors": ["Eva Vanmassenhove"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages", "url": "http://arxiv.org/abs/2507.03933v2", "summary": "Multilingual Large Language Models (LLMs) considerably changed how\ntechnologies can influence language. While previous technologies could mediate\nor assist humans, there is now a tendency to offload the task of writing itself\nto these technologies, enabling them to change our linguistic ecosystem more\ndirectly. While they provide us quick access to information and impressively\nfluent output, beneath their apparent sophistication lies a subtle, more\ninsidious threat: the gradual decline and loss of linguistic diversity. With\nthis opinion piece, I explore how model collapse, with a particular focus on\ntranslation technology, can lead to the loss of linguistic forms, grammatical\nfeatures, and cultural nuance. Model collapse refers to the eventual\nconsequence of self-consuming training loops, where models reinforce their own\nbiases and lose linguistic diversity. Drawing on recent work in Computer\nVision, Natural Language Processing (NLP) and Machine Translation (MT), I argue\nthat the tails of our linguistic distributions are vanishing, and with them,\nthe narratives and identities they carry. This is a call to resist linguistic\nflattening and to reimagine NLP as a field that encourages, values and protects\nexpressive multilingual lexical and linguistic diversity and creativity.", "comment": "12 pages", "pdf_url": "http://arxiv.org/pdf/2507.03933v2", "cate": "cs.CL", "date": "2025-07-05", "updated": "2025-07-09"}
{"id": "2507.06946", "title": "Device-to-Device Communication in 5G/6G: Architectural Foundations and Convergence with Enabling Technologies", "authors": ["Mohammad Reza Fasihi", "Brian L. Mark"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      47 Pages, 16 Figures", "url": "http://arxiv.org/abs/2507.06946v1", "summary": "Device-to-Device (D2D) communication is a promising solution to meet the\ngrowing demands of 5G and future 6G networks by enabling direct communication\nbetween user devices. It enhances spectral efficiency (SE) and energy\nefficiency (EE), reduces latency, and supports proximity-based services. As\nwireless systems evolve toward 5G and 6G paradigms, the integration of D2D with\nadvanced cellular technologies introduces new opportunities and challenges.\nThis survey paper reviews the architectural foundations of D2D communication\nand explores its integration with key 5G/6G enabling technologies. We review\nstandardization efforts, analyze core challenges, and highlight future research\ndirections to unlock the full potential of D2D in next-generation wireless\nnetworks.", "comment": "47 Pages, 16 Figures", "pdf_url": "http://arxiv.org/pdf/2507.06946v1", "cate": "eess.SY", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.05455", "title": "ModelCitizens: Representing Community Voices in Online Safety", "authors": ["Ashima Suvarna", "Christina Chance", "Karolina Naranjo", "Hamid Palangi", "Sophie Hao", "Thomas Hartvigsen", "Saadia Gabriel"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05455v2", "summary": "Automatic toxic language detection is critical for creating safe, inclusive\nonline spaces. However, it is a highly subjective task, with perceptions of\ntoxic language shaped by community norms and lived experience. Existing\ntoxicity detection models are typically trained on annotations that collapse\ndiverse annotator perspectives into a single ground truth, erasing important\ncontext-specific notions of toxicity such as reclaimed language. To address\nthis, we introduce MODELCITIZENS, a dataset of 6.8K social media posts and 40K\ntoxicity annotations across diverse identity groups. To capture the role of\nconversational context on toxicity, typical of social media posts, we augment\nMODELCITIZENS posts with LLM-generated conversational scenarios.\nState-of-the-art toxicity detection tools (e.g. OpenAI Moderation API,\nGPT-o4-mini) underperform on MODELCITIZENS, with further degradation on\ncontext-augmented posts. Finally, we release LLAMACITIZEN-8B and\nGEMMACITIZEN-12B, LLaMA- and Gemma-based models finetuned on MODELCITIZENS,\nwhich outperform GPT-o4-mini by 5.5% on in-distribution evaluations. Our\nfindings highlight the importance of community-informed annotation and modeling\nfor inclusive content moderation. The data, models and code are available at\nhttps://github.com/asuvarna31/modelcitizens.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05455v2", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-09"}
{"id": "2206.09495", "title": "The Power of Regularization in Solving Extensive-Form Games", "authors": ["Mingyang Liu", "Asuman Ozdaglar", "Tiancheng Yu", "Kaiqing Zhang"], "categories": ["cs.GT", "cs.LG"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "Comments:      Added clarifications on the last-iterate convergence focused on in this paper and the statement of Theorem 4.2", "url": "http://arxiv.org/abs/2206.09495v3", "summary": "In this paper, we investigate the power of {\\it regularization}, a common\ntechnique in reinforcement learning and optimization, in solving extensive-form\ngames (EFGs). We propose a series of new algorithms based on regularizing the\npayoff functions of the game, and establish a set of convergence results that\nstrictly improve over the existing ones, with either weaker assumptions or\nstronger convergence guarantees. In particular, we first show that dilated\noptimistic mirror descent (DOMD), an efficient variant of OMD for solving EFGs,\nwith adaptive regularization can achieve a fast $\\tilde O(1/T)$ {last-iterate\nconvergence rate for the output of the algorithm} in terms of duality gap and\ndistance to the set of Nash equilibrium (NE) without uniqueness assumption of\nthe NE. Second, we show that regularized counterfactual regret minimization\n(\\texttt{Reg-CFR}), with a variant of optimistic mirror descent algorithm as\nregret-minimizer, can achieve $O(1/T^{1/4})$ best-iterate, and $O(1/T^{3/4})$\naverage-iterate convergence rate for finding NE in EFGs. Finally, we show that\n\\texttt{Reg-CFR} can achieve asymptotic last-iterate convergence, and optimal\n$O(1/T)$ average-iterate convergence rate, for finding the NE of perturbed\nEFGs, which is useful for finding approximate extensive-form perfect equilibria\n(EFPE). To the best of our knowledge, they constitute the first last-iterate\nconvergence results for CFR-type algorithms, while matching the\nstate-of-the-art average-iterate convergence rate in finding NE for\nnon-perturbed EFGs. We also provide numerical results to corroborate the\nadvantages of our algorithms.", "comment": "Added clarifications on the last-iterate convergence focused on in\n  this paper and the statement of Theorem 4.2", "pdf_url": "http://arxiv.org/pdf/2206.09495v3", "cate": "cs.GT", "date": "2022-06-19", "updated": "2025-07-09"}
{"id": "2504.20865", "title": "AI-GenBench: A New Ongoing Benchmark for AI-Generated Image Detection", "authors": ["Lorenzo Pellegrini", "Davide Cozzolino", "Serafino Pandolfini", "Davide Maltoni", "Matteo Ferrara", "Luisa Verdoliva", "Marco Prati", "Marco Ramilli"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at Verimedia workshop, IJCNN 2025. 9 pages, 6 figures, 4 tables, code available: this https URL", "url": "http://arxiv.org/abs/2504.20865v2", "summary": "The rapid advancement of generative AI has revolutionized image creation,\nenabling high-quality synthesis from text prompts while raising critical\nchallenges for media authenticity. We present Ai-GenBench, a novel benchmark\ndesigned to address the urgent need for robust detection of AI-generated images\nin real-world scenarios. Unlike existing solutions that evaluate models on\nstatic datasets, Ai-GenBench introduces a temporal evaluation framework where\ndetection methods are incrementally trained on synthetic images, historically\nordered by their generative models, to test their ability to generalize to new\ngenerative models, such as the transition from GANs to diffusion models. Our\nbenchmark focuses on high-quality, diverse visual content and overcomes key\nlimitations of current approaches, including arbitrary dataset splits, unfair\ncomparisons, and excessive computational demands. Ai-GenBench provides a\ncomprehensive dataset, a standardized evaluation protocol, and accessible tools\nfor both researchers and non-experts (e.g., journalists, fact-checkers),\nensuring reproducibility while maintaining practical training requirements. By\nestablishing clear evaluation rules and controlled augmentation strategies,\nAi-GenBench enables meaningful comparison of detection methods and scalable\nsolutions. Code and data are publicly available to ensure reproducibility and\nto support the development of robust forensic detectors to keep pace with the\nrise of new synthetic generators.", "comment": "Accepted at Verimedia workshop, IJCNN 2025. 9 pages, 6 figures, 4\n  tables, code available: https://github.com/MI-BioLab/AI-GenBench", "pdf_url": "http://arxiv.org/pdf/2504.20865v2", "cate": "cs.CV", "date": "2025-04-29", "updated": "2025-07-09"}
{"id": "2507.05261", "title": "TokenShapley: Token Level Context Attribution with Shapley Value", "authors": ["Yingtai Xiao", "Yuqing Zhu", "Sirat Samyoun", "Wanrong Zhang", "Jiachen T. Wang", "Jian Du"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05261v2", "summary": "Large language models (LLMs) demonstrate strong capabilities in in-context\nlearning, but verifying the correctness of their generated responses remains a\nchallenge. Prior work has explored attribution at the sentence level, but these\nmethods fall short when users seek attribution for specific keywords within the\nresponse, such as numbers, years, or names. To address this limitation, we\npropose TokenShapley, a novel token-level attribution method that combines\nShapley value-based data attribution with KNN-based retrieval techniques\ninspired by recent advances in KNN-augmented LLMs. By leveraging a precomputed\ndatastore for contextual retrieval and computing Shapley values to quantify\ntoken importance, TokenShapley provides a fine-grained data attribution\napproach. Extensive evaluations on four benchmarks show that TokenShapley\noutperforms state-of-the-art baselines in token-level attribution, achieving an\n11-23% improvement in accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05261v2", "cate": "cs.CL", "date": "2025-06-18", "updated": "2025-07-09"}
{"id": "2507.06440", "title": "Distributed Optimization of Finite Condition Number for Laplacian Matrix in Multi-Agent Systems", "authors": ["Yicheng Xu", "Faryar Jabbari"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      20 pagrs,6 figures, submitted to International Journal of Robust and Nonlinear Control", "url": "http://arxiv.org/abs/2507.06440v1", "summary": "This paper addresses the distributed optimization of the finite condition\nnumber of the Laplacian matrix in multi-agent systems. The finite condition\nnumber, defined as the ratio of the largest to the second smallest eigenvalue\nof the Laplacian matrix, plays an important role in determining the convergence\nrate and performance of consensus algorithms, especially in discrete-time\nimplementations. We propose a fully distributed algorithm by regulating the\nnode weights. The approach leverages max consensus, distributed power\niteration, and consensus-based normalization for eigenvalue and eigenvector\nestimation, requiring only local communication and computation. Simulation\nresults demonstrate that the proposed method achieves performance comparable to\ncentralized LMI-based optimization, significantly improving consensus speed and\nmulti-agent system performance. The framework can be extended to edge weight\noptimization and the scenarios with non-simple eigenvalues, highlighting its\nscalability and practical applicability for large-scale networked systems.", "comment": "20 pagrs,6 figures, submitted to International Journal of Robust and\n  Nonlinear Control", "pdf_url": "http://arxiv.org/pdf/2507.06440v1", "cate": "math.OC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.05814", "title": "Empowering Bridge Digital Twins by Bridging the Data Gap with a Unified Synthesis Framework", "authors": ["Wang Wang", "Mingyu Shi", "Jun Jiang", "Wenqian Ma", "Chong Liu", "Yasutaka Narazaki", "Xuguang Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      18 pages, 10 figures", "url": "http://arxiv.org/abs/2507.05814v2", "summary": "As critical transportation infrastructure, bridges face escalating challenges\nfrom aging and deterioration, while traditional manual inspection methods\nsuffer from low efficiency. Although 3D point cloud technology provides a new\ndata-driven paradigm, its application potential is often constrained by the\nincompleteness of real-world data, which results from missing labels and\nscanning occlusions. To overcome the bottleneck of insufficient generalization\nin existing synthetic data methods, this paper proposes a systematic framework\nfor generating 3D bridge data.\n  This framework can automatically generate complete point clouds featuring\ncomponent-level instance annotations, high-fidelity color, and precise normal\nvectors. It can be further extended to simulate the creation of diverse and\nphysically realistic incomplete point clouds, designed to support the training\nof segmentation and completion networks, respectively. Experiments demonstrate\nthat a PointNet++ model trained with our synthetic data achieves a mean\nIntersection over Union (mIoU) of 84.2% in real-world bridge semantic\nsegmentation. Concurrently, a fine-tuned KT-Net exhibits superior performance\non the component completion task.\n  This research offers an innovative methodology and a foundational dataset for\nthe 3D visual analysis of bridge structures, holding significant implications\nfor advancing the automated management and maintenance of infrastructure.", "comment": "18 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.05814v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2311.16286", "title": "A statistical approach to latent dynamic modeling with differential equations", "authors": ["Maren Hackenberg", "Astrid Pechmann", "Clemens Kreutz", "Janbernd Kirschner", "Harald Binder"], "categories": ["stat.ME", "cs.LG", "stat.AP", "stat.ML"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "Comments:      31 pages, 6 figures", "url": "http://arxiv.org/abs/2311.16286v2", "summary": "Ordinary differential equations (ODEs) can provide mechanistic models of\ntemporally local changes of processes, where parameters are often informed by\nexternal knowledge. While ODEs are popular in systems modeling, they are less\nestablished for statistical modeling of longitudinal cohort data, e.g., in a\nclinical setting. Yet, modeling of local changes could also be attractive for\nassessing the trajectory of an individual in a cohort in the immediate future\ngiven its current status, where ODE parameters could be informed by further\ncharacteristics of the individual. However, several hurdles so far limit such\nuse of ODEs, as compared to regression-based function fitting approaches. The\npotentially higher level of noise in cohort data might be detrimental to ODEs,\nas the shape of the ODE solution heavily depends on the initial value. In\naddition, larger numbers of variables multiply such problems and might be\ndifficult to handle for ODEs. To address this, we propose to use each\nobservation in the course of time as the initial value to obtain multiple local\nODE solutions and build a combined estimator of the underlying dynamics. Neural\nnetworks are used for obtaining a low-dimensional latent space for dynamic\nmodeling from a potentially large number of variables, and for obtaining\npatient-specific ODE parameters from baseline variables. Simultaneous\nidentification of dynamic models and of a latent space is enabled by recently\ndeveloped differentiable programming techniques. We illustrate the proposed\napproach in an application with spinal muscular atrophy patients and a\ncorresponding simulation study. In particular, modeling of local changes in\nhealth status at any point in time is contrasted to the interpretation of\nfunctions obtained from a global regression. This more generally highlights how\ndifferent application settings might demand different modeling strategies.", "comment": "31 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2311.16286v2", "cate": "stat.ME", "date": "2023-11-27", "updated": "2025-07-09"}
{"id": "2505.08423", "title": "DArFace: Deformation Aware Robustness for Low Quality Face Recognition", "authors": ["Sadaf Gulshad", "Abdullah Aldahlawi Thakaa"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.08423v2", "summary": "Facial recognition systems have achieved remarkable success by leveraging\ndeep neural networks, advanced loss functions, and large-scale datasets.\nHowever, their performance often deteriorates in real-world scenarios involving\nlow-quality facial images. Such degradations, common in surveillance footage or\nstandoff imaging include low resolution, motion blur, and various distortions,\nresulting in a substantial domain gap from the high-quality data typically used\nduring training. While existing approaches attempt to address robustness by\nmodifying network architectures or modeling global spatial transformations,\nthey frequently overlook local, non-rigid deformations that are inherently\npresent in real-world settings. In this work, we introduce DArFace, a\nDeformation-Aware robust Face recognition framework that enhances robustness to\nsuch degradations without requiring paired high- and low-quality training\nsamples. Our method adversarially integrates both global transformations (e.g.,\nrotation, translation) and local elastic deformations during training to\nsimulate realistic low-quality conditions. Moreover, we introduce a contrastive\nobjective to enforce identity consistency across different deformed views.\nExtensive evaluations on low-quality benchmarks including TinyFace, IJB-B, and\nIJB-C demonstrate that DArFace surpasses state-of-the-art methods, with\nsignificant gains attributed to the inclusion of local deformation modeling.The\ncode is available at the following https://github.com/sadafgulshad1/DArFace", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.08423v2", "cate": "cs.CV", "date": "2025-05-13", "updated": "2025-07-09"}
{"id": "2507.06085", "title": "A Survey on Prompt Tuning", "authors": ["Zongqian Li", "Yixuan Su", "Nigel Collier"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06085v2", "summary": "This survey reviews prompt tuning, a parameter-efficient approach for\nadapting language models by prepending trainable continuous vectors while\nkeeping the model frozen. We classify existing approaches into two categories:\ndirect prompt learning and transfer learning. Direct prompt learning methods\ninclude: general optimization approaches, encoder-based methods, decomposition\nstrategies, and mixture-of-experts frameworks. Transfer learning methods\nconsist of: general transfer approaches, encoder-based methods, and\ndecomposition strategies. For each method, we analyze method designs,\ninnovations, insights, advantages, and disadvantages, with illustrative\nvisualizations comparing different frameworks. We identify challenges in\ncomputational efficiency and training stability, and discuss future directions\nin improving training robustness and broadening application scope.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06085v2", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2507.06702", "title": "Mathematical Modelling of Oscillatory Dynamics in Circular Traffic Systems", "authors": ["Craig S Wright"], "categories": ["nlin.AO", "cs.SY", "eess.SY", "math.DS", "math.OC", "physics.soc-ph", "34K20, 90B20, 35B35", "G.1.10; I.6.1; J.7"], "primary_category": "Subjects:       Adaptation and Self-Organizing Systems (nlin.AO)", "pdf_link": null, "comments": "Comments:      79 pages", "url": "http://arxiv.org/abs/2507.06702v1", "summary": "This paper presents a rigorous analytical model of traffic dynamics on a\ncircular track, demonstrating the emergence of standing oscillations resulting\nfrom microscopic driver behaviour, delay responses, and proximity pressure.\nWithout relying on simulation, we derive a series of coupled delay differential\nequations to model vehicular interactions. By introducing a mnemonic-based\nsymbolic system, we establish a mathematical framework incorporating stochastic\ninitial conditions, non-uniform reaction times, and cognitive lag. A full\nlinear stability analysis is conducted using Fourier decomposition and modal\nperturbation techniques. Our results identify critical thresholds for harmonic\ninduction, delineate the bounds of safe following distances, and reveal\nhysteresis in driver overcorrection. The analysis concludes with implications\nfor autonomous vehicle control and potential suppression strategies for\noscillatory instability. All derivations are purely symbolic and analytically\nproven.", "comment": "79 pages", "pdf_url": "http://arxiv.org/pdf/2507.06702v1", "cate": "nlin.AO", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.05999", "title": "Geo-Registration of Terrestrial LiDAR Point Clouds with Satellite Images without GNSS", "authors": ["Xinyu Wang", "Muhammad Ibrahim", "Haitian Wang", "Atif Mansoor", "Ajmal Mian"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE Transactions on Geoscience & Remote Sensing. Under reviewing now", "url": "http://arxiv.org/abs/2507.05999v2", "summary": "Accurate geo-registration of LiDAR point clouds presents significant\nchallenges in GNSS signal denied urban areas with high-rise buildings and\nbridges. Existing methods typically rely on real-time GNSS and IMU data, that\nrequire pre-calibration and assume stable positioning during data collection.\nHowever, this assumption often fails in dense urban areas, resulting in\nlocalization errors. To address this, we propose a structured geo-registration\nand spatial correction method that aligns 3D point clouds with satellite\nimages, enabling frame-wise recovery of GNSS information and reconstruction of\ncity scale 3D maps without relying on prior localization. The proposed approach\nemploys a pre-trained Point Transformer model to segment the road points and\nthen extracts the road skeleton and intersection points from the point cloud as\nwell as the target map for alignment. Global rigid alignment of the two is\nperformed using the intersection points, followed by local refinement using\nradial basis function (RBF) interpolation. Elevation correction is then applied\nto the point cloud based on terrain information from SRTM dataset to resolve\nvertical discrepancies. The proposed method was tested on the popular KITTI\nbenchmark and a locally collected Perth (Western Australia) CBD dataset. On the\nKITTI dataset, our method achieved an average planimetric alignment standard\ndeviation (STD) of 0.84~m across sequences with intersections, representing a\n55.3\\% improvement over the original dataset. On the Perth dataset, which lacks\nGNSS information, our method achieved an average STD of 0.96~m compared to the\nGPS data extracted from Google Maps API. This corresponds to a 77.4\\%\nimprovement from the initial alignment. Our method also resulted in elevation\ncorrelation gains of 30.5\\% on the KITTI dataset and 50.4\\% on the Perth\ndataset.", "comment": "Submitted to IEEE Transactions on Geoscience & Remote Sensing. Under\n  reviewing now", "pdf_url": "http://arxiv.org/pdf/2507.05999v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2404.02239", "title": "Proximal Oracles for Optimization and Sampling", "authors": ["Jiaming Liang", "Yongxin Chen"], "categories": ["math.OC", "cs.LG"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      26 pages. arXiv admin note: text overlap with arXiv:2202.13975", "url": "http://arxiv.org/abs/2404.02239v2", "summary": "We consider convex optimization with non-smooth objective function and\nlog-concave sampling with non-smooth potential (negative log density). In\nparticular, we study two specific settings where the convex objective/potential\nfunction is either H\\\"older smooth or in hybrid form as the finite sum of\nH\\\"older smooth components. To overcome the challenges caused by\nnon-smoothness, our algorithms employ two powerful proximal frameworks in\noptimization and sampling: the proximal point framework for optimization and\nthe alternating sampling framework (ASF) that uses Gibbs sampling on an\naugmented distribution. A key component of both optimization and sampling\nalgorithms is the efficient implementation of the proximal map by the\nregularized cutting-plane method. We establish its iteration-complexity under\nboth H\\\"older smoothness and hybrid settings using novel convergence analysis,\nyielding results that are new to the literature. We further propose an adaptive\nproximal bundle method for non-smooth optimization that employs an aggressive\nadaptive stepsize strategy, which adjusts stepsizes only when necessary and\nnever rejects iterates. The proposed method is universal since it does not need\nany problem parameters as input. Additionally, we provide an exact\nimplementation of a proximal sampling oracle, analogous to the proximal map in\noptimization, along with simple complexity analyses for both the H\\\"older\nsmooth and hybrid cases, using a novel technique based on a modified Gaussian\nintegral. Finally, we combine this proximal sampling oracle and ASF to obtain a\nMarkov chain Monte Carlo method with non-asymptotic complexity bounds for\nsampling in H\\\"older smooth and hybrid settings.", "comment": "26 pages. arXiv admin note: text overlap with arXiv:2202.13975", "pdf_url": "http://arxiv.org/pdf/2404.02239v2", "cate": "math.OC", "date": "2024-04-02", "updated": "2025-07-09"}
{"id": "2505.08617", "title": "OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning", "authors": ["Zhaochen Su", "Linjie Li", "Mingyang Song", "Yunzhuo Hao", "Zhengyuan Yang", "Jun Zhang", "Guanjie Chen", "Jiawei Gu", "Juntao Li", "Xiaoye Qu", "Yu Cheng"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2505.08617v2", "summary": "While humans can flexibly leverage interactive visual cognition for complex\nproblem-solving, enabling Large Vision-Language Models (LVLMs) to learn\nsimilarly adaptive behaviors with visual tools remains challenging. A\nsignificant hurdle is the current lack of standardized infrastructure, which\nhinders integrating diverse tools, generating rich interaction data, and\ntraining robust agents effectively. To address these gaps, we introduce\nOpenThinkIMG, the first open-source, comprehensive end-to-end framework for\ntool-augmented LVLMs. It features standardized vision tool interfaces, scalable\ntrajectory generation for policy initialization, and a flexible training\nenvironment. Furthermore, considering supervised fine-tuning (SFT) on static\ndemonstrations offers limited policy generalization for dynamic tool\ninvocation, we propose a novel reinforcement learning (RL) framework V-ToolRL\nto train LVLMs to learn adaptive policies for invoking external vision tools.\nV-ToolRL enables LVLMs to autonomously discover optimal tool-usage strategies\nby directly optimizing for task success using feedback from tool interactions.\nWe empirically validate V-ToolRL on challenging chart reasoning tasks. Our\nRL-trained agent, built upon a Qwen2-VL-2B, significantly outperforms its\nSFT-initialized counterpart (+28.83 points) and surpasses established\nsupervised tool-learning baselines like Taco and CogCom by an average of +12.7\npoints. Notably, it also surpasses prominent closed-source models like GPT-4.1\nby +8.68 accuracy points. We hope OpenThinkIMG can serve as a foundational\nframework for advancing dynamic, tool-augmented visual reasoning, helping the\ncommunity develop AI agents that can genuinely \"think with images\".", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2505.08617v2", "cate": "cs.CV", "date": "2025-05-13", "updated": "2025-07-09"}
{"id": "2507.06167", "title": "Skywork-R1V3 Technical Report", "authors": ["Wei Shen", "Jiangbo Pei", "Yi Peng", "Xuchen Song", "Yang Liu", "Jian Peng", "Haofeng Sun", "Yunzhuo Hao", "Peiyu Wang", "Jianhao Zhang", "Yahui Zhou"], "categories": ["cs.CL", "cs.CV"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06167v2", "summary": "We introduce Skywork-R1V3, an advanced, open-source vision-language model\n(VLM) that pioneers a new approach to visual reasoning. Its key innovation lies\nin effectively transferring reasoning skills from text-only Large Language\nModels (LLMs) to visual tasks. The strong performance of Skywork-R1V3 primarily\nstems from our elaborate post-training RL framework, which effectively\nactivates and enhances the model's reasoning ability, without the need for\nadditional continue pre-training. Through this framework, we further uncover\nthe fundamental role of the connector module in achieving robust cross-modal\nalignment for multimodal reasoning models. In addition, we introduce a unique\nindicator of reasoning capability, the entropy of critical reasoning tokens,\nwhich has proven highly effective for checkpoint selection during RL training.\nSkywork-R1V3 achieves state-of-the-art results on MMMU, significantly improving\nfrom 64.3% to 76.0%. This performance matches entry-level human capabilities.\nRemarkably, our RL-powered post-training approach enables even the 38B\nparameter model to rival top closed-source VLMs. The implementation\nsuccessfully transfers mathematical reasoning to other subject-related\nreasoning tasks. We also include an analysis of curriculum learning and\nreinforcement finetuning strategies, along with a broader discussion on\nmultimodal reasoning. Skywork-R1V3 represents a significant leap in multimodal\nreasoning, showcasing RL as a powerful engine for advancing open-source VLM\ncapabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06167v2", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2507.06788", "title": "Dynamic Output-Feedback Controller Synthesis for Dissipativity from Noisy Input-State Data", "authors": ["Pietro Kristović", "Andrej Jokić", "Mircea Lazar"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      7 pages, 2 figures", "url": "http://arxiv.org/abs/2507.06788v1", "summary": "In this paper we propose a dynamic output-feedback controller synthesis\nmethod for discrete-time linear time-invariant systems. The synthesis goal is\nto render closed-loop system dissipative with respect to a given generic\nunstructured quadratic supply rate, while the system dynamics is partially\nrepresented by input-state data corrupted by a bounded disturbance. The\ncontroller synthesis is performed with respect to all systems which are\nconsistent with the available data, and it is formulated in terms of a linear\nmatrix inequality parametrized by a scalar variable, so that the synthesis can\nbe performed using line search and convex optimization. Within the considered\nsetting, the proposed synthesis procedure is non-conservative in a sense that\nit is based on conditions which are both necessary and sufficient.", "comment": "7 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.06788v1", "cate": "math.OC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2405.15625", "title": "Nonlinear denoising score matching for enhanced learning of structured distributions", "authors": ["Jeremiah Birrell", "Markos A. Katsoulakis", "Luc Rey-Bellet", "Benjamin J. Zhang", "Wei Zhu"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      16 pages, 8 figures", "url": "http://arxiv.org/abs/2405.15625v2", "summary": "We present a novel method for training score-based generative models which\nuses nonlinear noising dynamics to improve learning of structured\ndistributions. Generalizing to a nonlinear drift allows for additional\nstructure to be incorporated into the dynamics, thus making the training better\nadapted to the data, e.g., in the case of multimodality or (approximate)\nsymmetries. Such structure can be obtained from the data by an inexpensive\npreprocessing step. The nonlinear dynamics introduces new challenges into\ntraining which we address in two ways: 1) we develop a new nonlinear denoising\nscore matching (NDSM) method, 2) we introduce neural control variates in order\nto reduce the variance of the NDSM training objective. We demonstrate the\neffectiveness of this method on several examples: a) a collection of\nlow-dimensional examples, motivated by clustering in latent space, b)\nhigh-dimensional images, addressing issues with mode imbalance, small training\nsets, and approximate symmetries, the latter being a challenge for methods\nbased on equivariant neural networks, which require exact symmetries, c) latent\nspace representation of high-dimensional data, demonstrating improved\nperformance with greatly reduced computational cost. Our method learns\nscore-based generative models with less data by flexibly incorporating\nstructure arising in the dataset.", "comment": "16 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2405.15625v2", "cate": "stat.ML", "date": "2024-05-24", "updated": "2025-07-08"}
{"id": "2506.02247", "title": "EgoVIS@CVPR: PAIR-Net: Enhancing Egocentric Speaker Detection via Pretrained Audio-Visual Fusion and Alignment Loss", "authors": ["Yu Wang", "Juhyung Ha", "David J. Crandall"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      4 pages, 1 figure, and 1 table", "url": "http://arxiv.org/abs/2506.02247v2", "summary": "Active speaker detection (ASD) in egocentric videos presents unique\nchallenges due to unstable viewpoints, motion blur, and off-screen speech\nsources - conditions under which traditional visual-centric methods degrade\nsignificantly. We introduce PAIR-Net (Pretrained Audio-Visual Integration with\nRegularization Network), an effective model that integrates a partially frozen\nWhisper audio encoder with a fine-tuned AV-HuBERT visual backbone to robustly\nfuse cross-modal cues. To counteract modality imbalance, we introduce an\ninter-modal alignment loss that synchronizes audio and visual representations,\nenabling more consistent convergence across modalities. Without relying on\nmulti-speaker context or ideal frontal views, PAIR-Net achieves\nstate-of-the-art performance on the Ego4D ASD benchmark with 76.6% mAP,\nsurpassing LoCoNet and STHG by 8.2% and 12.9% mAP, respectively. Our results\nhighlight the value of pretrained audio priors and alignment-based fusion for\nrobust ASD under real-world egocentric conditions.", "comment": "4 pages, 1 figure, and 1 table", "pdf_url": "http://arxiv.org/pdf/2506.02247v2", "cate": "cs.CV", "date": "2025-06-02", "updated": "2025-07-08"}
{"id": "2507.06883", "title": "Manifolds in Power Systems Optimization", "authors": ["Lucca Rodrigues Pinto", "Wilson de Souza Junior", "Jaime Laelson Jacob", "Luis Alfonso Gallego Pareja", "Taufik Abrão"], "categories": ["math.OC", "cs.SY", "eess.SY", "stat.AP"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      23 pages, 18 figures, 15 Tables, 4 algorithms; Full research paper. arXiv admin note: text overlap with arXiv:2408.00553", "url": "http://arxiv.org/abs/2507.06883v1", "summary": "Manifold optimization (MO) is a powerful mathematical framework that can be\napplied to solving complex optimization problems with objective functions (OFs)\nand constraints on complex geometric structures, which is particularly useful\nin advanced power systems. We explore the application of MO techniques, which\noffer a robust framework for solving complex, non-convex optimization problems\nin electrical power distribution systems (EPDS) and electrical power\ntransmission systems (EPTS), particularly for power flow analysis. This paper\nintroduces the principles of MO and demonstrates its advantages over\nconventional methods by applying it to power flow optimization. For EPDS, a\ncost function derived from a backward-forward sweep (BFS) algorithm is\noptimized using the Manopt toolbox, yielding high accuracy and competitive\ncomputational times on 14-bus, 33-bus, and 69-bus systems when compared to\nestablished solvers. Similarly, for EPTS, MO applied via Manopt to 3-bus and\n4-bus systems effectively solves power flow equations, matching traditional\nmethods such as Newton-Raphson in performance. The study highlights that tools\nsuch as Manopt can mitigate implementation complexities, positioning MO as an\nefficient and accessible tool for power system analysis and potentially broader\nplanning applications. The paper provides a comprehensive tutorial on MO,\ndetailing its theoretical foundations, practical methodologies, and specific\napplications in power systems, particularly in power flow optimization.", "comment": "23 pages, 18 figures, 15 Tables, 4 algorithms; Full research paper.\n  arXiv admin note: text overlap with arXiv:2408.00553", "pdf_url": "http://arxiv.org/pdf/2507.06883v1", "cate": "math.OC", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2406.17295", "title": "Less can be more for predicting properties with large language models", "authors": ["Nawaf Alampara", "Santiago Miret", "Kevin Maik Jablonka"], "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "Subjects:       Materials Science (cond-mat.mtrl-sci)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.17295v3", "summary": "Predicting properties from coordinate-category data -- sets of vectors paired\nwith categorical information -- is fundamental to computational science. In\nmaterials science, this challenge manifests as predicting properties like\nformation energies or elastic moduli from crystal structures comprising atomic\npositions (vectors) and element types (categorical information). While large\nlanguage models (LLMs) have increasingly been applied to such tasks, with\nresearchers encoding structural data as text, optimal strategies for achieving\nreliable predictions remain elusive. Here, we report fundamental limitations in\nLLM's ability to learn from coordinate information in coordinate-category data.\nThrough systematic experiments using synthetic datasets with tunable coordinate\nand category contributions, combined with a comprehensive benchmarking\nframework (MatText) spanning multiple representations and model scales, we find\nthat LLMs consistently fail to capture coordinate information while excelling\nat category patterns. This geometric blindness persists regardless of model\nsize (up to 70B parameters), dataset scale (up to 2M structures), or text\nrepresentation strategy. Our findings suggest immediate practical implications:\nfor materials property prediction tasks dominated by structural effects,\nspecialized geometric architectures consistently outperform LLMs by significant\nmargins, as evidenced by a clear \"GNN-LM wall\" in performance benchmarks. Based\non our analysis, we provide concrete guidelines for architecture selection in\nscientific machine learning, while highlighting the critical importance of\nunderstanding model inductive biases when tackling scientific prediction\nproblems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.17295v3", "cate": "cond-mat.mtrl-sci", "date": "2024-06-25", "updated": "2025-07-09"}
{"id": "2506.11472", "title": "On the Natural Robustness of Vision-Language Models Against Visual Perception Attacks in Autonomous Driving", "authors": ["Pedram MohajerAnsari", "Amir Salarpour", "Michael Kühr", "Siyu Huang", "Mohammad Hamad", "Sebastian Steinhorst", "Habeeb Olufowobi", "Mert D. Pesé"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.11472v2", "summary": "Autonomous vehicles (AVs) rely on deep neural networks (DNNs) for critical\ntasks such as traffic sign recognition (TSR), automated lane centering (ALC),\nand vehicle detection (VD). However, these models are vulnerable to attacks\nthat can cause misclassifications and compromise safety. Traditional defense\nmechanisms, including adversarial training, often degrade benign accuracy and\nfail to generalize against unseen attacks. In this work, we introduce Vehicle\nVision Language Models (V2LMs), fine-tuned vision-language models specialized\nfor AV perception. Our findings demonstrate that V2LMs inherently exhibit\nsuperior robustness against unseen attacks without requiring adversarial\ntraining, maintaining significantly higher accuracy than conventional DNNs\nunder adversarial conditions. We evaluate two deployment strategies: Solo Mode,\nwhere individual V2LMs handle specific perception tasks, and Tandem Mode, where\na single unified V2LM is fine-tuned for multiple tasks simultaneously.\nExperimental results reveal that DNNs suffer performance drops of 33% to 46%\nunder attacks, whereas V2LMs maintain adversarial accuracy with reductions of\nless than 8% on average. The Tandem Mode further offers a memory-efficient\nalternative while achieving comparable robustness to Solo Mode. We also explore\nintegrating V2LMs as parallel components to AV perception to enhance resilience\nagainst adversarial threats. Our results suggest that V2LMs offer a promising\npath toward more secure and resilient AV perception systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.11472v2", "cate": "cs.CV", "date": "2025-06-13", "updated": "2025-07-08"}
{"id": "2109.01629", "title": "The Singular Angle of Nonlinear Systems", "authors": ["Chao Chen", "Di Zhao", "Sei Zhen Khong"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2109.01629v2", "summary": "In this paper, we introduce an angle notion called the singular angle for\nnonlinear systems from an input-output perspective. The proposed system\nsingular angle, based on the angle between $L_2$-signals, describes an upper\nbound for the ''rotating effect'' from system input to output signals. It\nquantifies passivity and serves as a counterpart to system $L_2$-gain. It also\nprovides an alternative to a recently defined notion of system phase which\nadopts complexification of real-valued signals via the Hilbert transform. A\nnonlinear small angle theorem is established for feedback stability analysis,\nwhich involves a comparison of the loop system angle with $\\pi$. The theorem\ngeneralizes the classical passivity theorem via a tradeoff between the singular\nangles of open-loop systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2109.01629v2", "cate": "eess.SY", "date": "2021-09-03", "updated": "2025-07-09"}
{"id": "2505.16407", "title": "Robust Longitudinal-lateral Look-ahead Pursuit Path-Following Control: Fast Finite-Time Stability Guarantee", "authors": ["Zimao Sheng", "Hong'an Yang", "Shuxiang Yang", "Zirui Yu"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      21 pages, 22 figures", "url": "http://arxiv.org/abs/2505.16407v2", "summary": "This paper addresses the challenging problem of robust path-following for\nfixed-wing unmanned aerial vehicles (UAVs) in complex environments with bounded\nexternal disturbances and non-smooth predefined paths. Due to the unique\naerodynamic characteristics and flight constraints of fixed-wing UAVs,\nachieving accurate and fast stable path following remains difficult, especially\nin low-altitude mountainous terrains, urban landscapes, and under wind\ndisturbances. Most existing path-following guidance laws often struggle to\nensure fast stabilization under unknown bounded disturbances while maintaining\nsufficient robustness, and there is a lack of research on optimizing robustness\nfor non-smooth paths under flight constraints. This paper addresses these\nissues by proposing a constraints-based robust path-following controller.\nFirstly, from the perspective of global random attractor, we innovatively\nintroduce robustness metrics that quantify both the exponential convergence\nrate and the range of the ultimate attractor set. Secondly, building on these\nmetrics, we develop a robust longitudinal-lateral look-ahead pursuit (RLLP)\nguidance law for fixed-wing UAVs, specifically considering the flight path\nangle and track angle under external disturbances. Thirdly, we also derive an\noptimized version (Optimal-RLLP) to enhance the robustness metrics, and\nelaborate on the sufficient conditions for fast finite-time stability, ensuring\nthe guidance law achieves finite-time stability and robustness with reduced\nsensitivity to constrained uncertainties. The simulation results validate the\nproposed guidance law's feasibility, optimality and robustness under\natmospheric disturbances using a high-fidelity simulation platform and provide\nkey principle for practical deployment.", "comment": "21 pages, 22 figures", "pdf_url": "http://arxiv.org/pdf/2505.16407v2", "cate": "eess.SY", "date": "2025-05-22", "updated": "2025-07-09"}
{"id": "2407.20199", "title": "Emergence in non-neural models: grokking modular arithmetic via average gradient outer product", "authors": ["Neil Mallinar", "Daniel Beaglehole", "Libin Zhu", "Adityanarayanan Radhakrishnan", "Parthe Pandit", "Mikhail Belkin"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Accepted to ICML 2025 (Oral presentation & Spotlight poster)", "url": "http://arxiv.org/abs/2407.20199v3", "summary": "Neural networks trained to solve modular arithmetic tasks exhibit grokking, a\nphenomenon where the test accuracy starts improving long after the model\nachieves 100% training accuracy in the training process. It is often taken as\nan example of \"emergence\", where model ability manifests sharply through a\nphase transition. In this work, we show that the phenomenon of grokking is not\nspecific to neural networks nor to gradient descent-based optimization.\nSpecifically, we show that this phenomenon occurs when learning modular\narithmetic with Recursive Feature Machines (RFM), an iterative algorithm that\nuses the Average Gradient Outer Product (AGOP) to enable task-specific feature\nlearning with general machine learning models. When used in conjunction with\nkernel machines, iterating RFM results in a fast transition from random, near\nzero, test accuracy to perfect test accuracy. This transition cannot be\npredicted from the training loss, which is identically zero, nor from the test\nloss, which remains constant in initial iterations. Instead, as we show, the\ntransition is completely determined by feature learning: RFM gradually learns\nblock-circulant features to solve modular arithmetic. Paralleling the results\nfor RFM, we show that neural networks that solve modular arithmetic also learn\nblock-circulant features. Furthermore, we present theoretical evidence that RFM\nuses such block-circulant features to implement the Fourier Multiplication\nAlgorithm, which prior work posited as the generalizing solution neural\nnetworks learn on these tasks. Our results demonstrate that emergence can\nresult purely from learning task-relevant features and is not specific to\nneural architectures nor gradient descent-based optimization methods.\nFurthermore, our work provides more evidence for AGOP as a key mechanism for\nfeature learning in neural networks.", "comment": "Accepted to ICML 2025 (Oral presentation & Spotlight poster)", "pdf_url": "http://arxiv.org/pdf/2407.20199v3", "cate": "stat.ML", "date": "2024-07-29", "updated": "2025-07-09"}
{"id": "2506.22637", "title": "CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation", "authors": ["Haoxuan Wang", "Zhenghao Zhao", "Junyi Wu", "Yuzhang Shang", "Gaowen Liu", "Yan Yan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025. Code is available at this https URL", "url": "http://arxiv.org/abs/2506.22637v2", "summary": "The recent introduction of diffusion models in dataset distillation has shown\npromising potential in creating compact surrogate datasets for large,\nhigh-resolution target datasets, offering improved efficiency and performance\nover traditional bi-level/uni-level optimization methods. However, current\ndiffusion-based dataset distillation approaches overlook the evaluation process\nand exhibit two critical inconsistencies in the distillation process: (1)\nObjective Inconsistency, where the distillation process diverges from the\nevaluation objective, and (2) Condition Inconsistency, leading to mismatches\nbetween generated images and their corresponding conditions. To resolve these\nissues, we introduce Condition-aware Optimization with Objective-guided\nSampling (CaO$_2$), a two-stage diffusion-based framework that aligns the\ndistillation process with the evaluation objective. The first stage employs a\nprobability-informed sample selection pipeline, while the second stage refines\nthe corresponding latent representations to improve conditional likelihood.\nCaO$_2$ achieves state-of-the-art performance on ImageNet and its subsets,\nsurpassing the best-performing baselines by an average of 2.3% accuracy.", "comment": "ICCV 2025. Code is available at\n  https://github.com/hatchetProject/CaO2", "pdf_url": "http://arxiv.org/pdf/2506.22637v2", "cate": "cs.CV", "date": "2025-06-27", "updated": "2025-07-09"}
{"id": "2506.22652", "title": "QoS-aware State-Augmented Learnable Algorithm for Wireless Coexistence Parameter Management", "authors": ["Mohammad Reza Fasihi", "Brian L. Mark"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      13 pages, 7 figures", "url": "http://arxiv.org/abs/2506.22652v2", "summary": "Efficient and fair coexistence in unlicensed spectrum is essential to support\nheterogeneous networks such as 5G NR-U and Wi-Fi, which often contend for\nshared wireless resources. We introduce a general framework for wireless\nCoexistence Parameter Management (CPM) based on state-augmented constrained\nreinforcement learning. We propose a novel algorithm, QaSAL-CPM, which\nincorporates state-augmentation by embedding the dual variables in the\nconstrained optimization formulation directly into the agent's observation\nspace. This method enables the agent to respond to constraint violations in\nreal time while continuing to optimize a primary performance objective. Through\nextensive simulations of 5G NR-U and Wi-Fi coexistence scenarios, we show that\nQaSAL-CPM achieves reliable QoS compliance and improved policy robustness\nacross various transmitter densities compared to previous approaches. The\nproposed framework offers a scalable and adaptive solution for real-time\ncoexistence optimization in next-generation wireless networks.", "comment": "13 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2506.22652v2", "cate": "eess.SY", "date": "2025-06-27", "updated": "2025-07-09"}
{"id": "2507.05711", "title": "Sparsity-Promoting Dynamic Mode Decomposition Applied to Sea Surface Temperature Fields", "authors": ["Zhicheng Zhang", "Yoshihiko Susuki", "Atsushi Okazaki"], "categories": ["eess.SY", "cs.SY", "physics.ao-ph", "37M10 (Primary), 86A10 (Secondary)"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2507.05711v2", "summary": "In this paper, we leverage Koopman mode decomposition to analyze the\nnonlinear and high-dimensional climate systems acting on the observed data\nspace. The dynamics of atmospheric systems are assumed to be equation-free,\nwith the linear evolution of observables derived from measured historical\nlong-term time-series data snapshots, such as monthly sea surface temperature\nrecords, to construct a purely data-driven climate dynamics. In particular,\nsparsity-promoting dynamic mode decomposition is exploited to extract the\ndominant spatial and temporal modes, which are among the most significant\ncoherent structures underlying climate variability, enabling a more efficient,\ninterpretable, and low-dimensional representation of the system dynamics. We\nhope that the combined use of Koopman modes and sparsity-promoting techniques\nwill provide insights into the significant climate modes, enabling\nreduced-order modeling of the climate system and offering a potential framework\nfor predicting and controlling weather and climate variability.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2507.05711v2", "cate": "eess.SY", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2410.11222", "title": "Quadratic Gating Mixture of Experts: Statistical Insights into Self-Attention", "authors": ["Pedram Akbarian", "Huy Nguyen", "Xing Han", "Nhat Ho"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Pedram Akbarian, Huy Nguyen, and Xing Han made equal contributions to this work", "url": "http://arxiv.org/abs/2410.11222v3", "summary": "Mixture of Experts (MoE) models are well known for effectively scaling model\ncapacity while preserving computational overheads. In this paper, we establish\na rigorous relation between MoE and the self-attention mechanism, showing that\neach row of a self-attention matrix can be written as a quadratic gating\nmixture of linear experts. Motivated by this connection, we conduct a\ncomprehensive convergence analysis of MoE models with two different quadratic\ngating functions, namely the quadratic polynomial gate and the quadratic\nmonomial gate, offering useful insights into the design of gating and experts\nfor the MoE framework. First, our analysis indicates that the use of the\nquadratic monomial gate yields an improved sample efficiency for estimating\nparameters and experts compared to the quadratic polynomial gate. Second,\nparameter and expert estimation rates become significantly faster when\nemploying non-linear experts in place of linear experts. Combining these\ntheoretical insights with the above link between MoE and self-attention, we\npropose a novel \\emph{active-attention} mechanism where we apply a non-linear\nactivation function to the value matrix in the formula of self-attention.\nFinally, we demonstrate that the proposed active-attention outperforms the\nstandard self-attention through several extensive experiments in various tasks,\nincluding image classification, language modeling, and multivariate time series\nforecasting.", "comment": "Pedram Akbarian, Huy Nguyen, and Xing Han made equal contributions to\n  this work", "pdf_url": "http://arxiv.org/pdf/2410.11222v3", "cate": "stat.ML", "date": "2024-10-15", "updated": "2025-07-08"}
{"id": "2507.00754", "title": "Language-Unlocked ViT (LUViT): Empowering Self-Supervised Vision Transformers with LLMs", "authors": ["Selim Kuzucu", "Muhammad Ferjad Naeem", "Anna Kukleva", "Federico Tombari", "Bernt Schiele"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      26 pages, 6 figures", "url": "http://arxiv.org/abs/2507.00754v2", "summary": "The integration of Large Language Model (LLMs) blocks with Vision\nTransformers (ViTs) holds immense promise for vision-only tasks by leveraging\nthe rich semantic knowledge and reasoning capabilities of LLMs. However, a\nfundamental challenge lies in the inherent modality mismatch between\ntext-centric pretraining of LLMs and vision-centric training of ViTs. Direct\nfusion often fails to fully exploit the LLM's potential and suffers from\nunstable finetuning. As a result, LLM blocks are kept frozen while only the\nvision components are learned. As a remedy to these challenges, we introduce\nLanguage-Unlocked Vision Transformers (LUViT), a novel approach that bridges\nthis modality mismatch through a synergistic pre-training strategy. LUViT\nco-adapts a ViT backbone and an LLM fusion block by (1) employing Masked\nAuto-Encoding (MAE) to pre-train the ViT for richer visual representations, and\n(2) concurrently training Low-Rank Adaptation (LoRA) layers within the LLM\nblock using the MAE objective. This joint optimization guides the ViT to\nproduce LLM-aligned features and the LLM to effectively interpret visual\ninformation. We demonstrate through extensive experiments that LUViT\nsignificantly improves performance on various downstream vision tasks,\nshowcasing a more effective and efficient pathway to harness LLM knowledge for\nvisual understanding.", "comment": "26 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.00754v2", "cate": "cs.CV", "date": "2025-07-01", "updated": "2025-07-08"}
{"id": "2409.00367", "title": "Distributionally Robust Joint Chance-Constrained Optimization for Electricity Imbalance: Integrating Renewables and Storage", "authors": ["Amir Noori", "Babak Tavassoli", "Alireza Fereidunian"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      9 pages; 11 figures, journal paper", "url": "http://arxiv.org/abs/2409.00367v2", "summary": "Integrating Distributed Energy Resources (DERs) with peer-to-peer (P2P)\nenergy trading offers promising solutions for grid modernization by\nincentivizing prosumers to participate in mitigating peak demand. However, this\nintegration also introduces operational uncertainties and computational\nchallenges. This paper aims to address these challenges with a novel scalable\nand tractable distributionally robust joint chance-constrained (DRJCC)\noptimization framework that effectively facilitates P2P energy trading by\nenhancing flexibility provision from large-scale DER operations under uncertain\nsupply and demand. Therefore, a practical framework is proposed to solve the\ncore challenges of DRJCC by integrating three key components: (1) a Wasserstein\nambiguity set that effectively quantifies uncertainty with sparse data, (2) a\nCVaR-based approximation of joint chance constraints to balance computational\nefficiency with risk control, and (3) a privacy-preserving ADMM algorithm that\nenables distributed implementation through decomposition. To discern patterns\nin the data that indicate collaboration potential and adjust ambiguity sets for\nimproved efficiency, K-means clustering is applied to historical scenarios.\nSimulation results show that the proposed framework reduces peak demand by\napproximately 28% and total community costs by around 31%, underscoring its\neffectiveness in enhancing grid robustness, operational reliability, and\neconomic optimization in renewable-based energy management.", "comment": "9 pages; 11 figures, journal paper", "pdf_url": "http://arxiv.org/pdf/2409.00367v2", "cate": "math.OC", "date": "2024-08-31", "updated": "2025-07-09"}
{"id": "2410.13849", "title": "From Gradient Clipping to Normalization for Heavy Tailed SGD", "authors": ["Florian Hübler", "Ilyas Fatkhullin", "Niao He"], "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      Fixed a typo, and removed the abuse of notation in the proof of Theorem 4", "url": "http://arxiv.org/abs/2410.13849v3", "summary": "Recent empirical evidence indicates that many machine learning applications\ninvolve heavy-tailed gradient noise, which challenges the standard assumptions\nof bounded variance in stochastic optimization. Gradient clipping has emerged\nas a popular tool to handle this heavy-tailed noise, as it achieves good\nperformance in this setting both theoretically and practically. However, our\ncurrent theoretical understanding of non-convex gradient clipping has three\nmain shortcomings. First, the theory hinges on large, increasing clipping\nthresholds, which are in stark contrast to the small constant clipping\nthresholds employed in practice. Second, clipping thresholds require knowledge\nof problem-dependent parameters to guarantee convergence. Lastly, even with\nthis knowledge, current sampling complexity upper bounds for the method are\nsub-optimal in nearly all parameters. To address these issues, we study\nconvergence of Normalized SGD (NSGD). First, we establish a parameter-free\nsample complexity for NSGD of\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{2p}{p-1}}\\right)$ to find an\n$\\varepsilon$-stationary point. Furthermore, we prove tightness of this result,\nby providing a matching algorithm-specific lower bound. In the setting where\nall problem parameters are known, we show this complexity is improved to\n$\\mathcal{O}\\left(\\varepsilon^{-\\frac{3p-2}{p-1}}\\right)$, matching the\npreviously known lower bound for all first-order methods in all problem\ndependent parameters. Finally, we establish high-probability convergence of\nNSGD with a mild logarithmic dependence on the failure probability. Our work\ncomplements the studies of gradient clipping under heavy tailed noise improving\nthe sample complexities of existing algorithms and offering an alternative\nmechanism to achieve high probability convergence.", "comment": "Fixed a typo, and removed the abuse of notation in the proof of\n  Theorem 4", "pdf_url": "http://arxiv.org/pdf/2410.13849v3", "cate": "math.OC", "date": "2024-10-17", "updated": "2025-07-09"}
{"id": "2507.01909", "title": "Modality-agnostic, patient-specific digital twins modeling temporally varying digestive motion", "authors": ["Jorge Tapias Gomez", "Nishant Nadkarni", "Lando S. Bosma", "Jue Jiang", "Ergys D. Subashi", "William P. Segars", "James M. Balter", "Mert R Sabuncu", "Neelam Tyagi", "Harini Veeraraghavan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This work is still review, it contains 7 Pages, 6 figures, and 4 tables", "url": "http://arxiv.org/abs/2507.01909v3", "summary": "Objective: Clinical implementation of deformable image registration (DIR)\nrequires voxel-based spatial accuracy metrics such as manually identified\nlandmarks, which are challenging to implement for highly mobile\ngastrointestinal (GI) organs. To address this, patient-specific digital twins\n(DT) modeling temporally varying motion were created to assess the accuracy of\nDIR methods. Approach: 21 motion phases simulating digestive GI motion as 4D\nsequences were generated from static 3D patient scans using published\nanalytical GI motion models through a semi-automated pipeline. Eleven datasets,\nincluding six T2w FSE MRI (T2w MRI), two T1w 4D golden-angle stack-of-stars,\nand three contrast-enhanced CT scans. The motion amplitudes of the DTs were\nassessed against real patient stomach motion amplitudes extracted from\nindependent 4D MRI datasets. The generated DTs were then used to assess six\ndifferent DIR methods using target registration error, Dice similarity\ncoefficient, and the 95th percentile Hausdorff distance using summary metrics\nand voxel-level granular visualizations. Finally, for a subset of T2w MRI scans\nfrom patients treated with MR-guided radiation therapy, dose distributions were\nwarped and accumulated to assess dose warping errors, including evaluations of\nDIR performance in both low- and high-dose regions for patient-specific error\nestimation. Main results: Our proposed pipeline synthesized DTs modeling\nrealistic GI motion, achieving mean and maximum motion amplitudes and a mean\nlog Jacobian determinant within 0.8 mm and 0.01, respectively, similar to\npublished real-patient gastric motion data. It also enables the extraction of\ndetailed quantitative DIR performance metrics and rigorous validation of dose\nmapping accuracy. Significance: The pipeline enables rigorously testing DIR\ntools for dynamic, anatomically complex regions enabling granular spatial and\ndosimetric accuracies.", "comment": "This work is still review, it contains 7 Pages, 6 figures, and 4\n  tables", "pdf_url": "http://arxiv.org/pdf/2507.01909v3", "cate": "cs.CV", "date": "2025-07-02", "updated": "2025-07-09"}
{"id": "2410.23244", "title": "Very fast Bayesian Additive Regression Trees on GPU", "authors": ["Giacomo Petrillo"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Check out the software at this https URL", "url": "http://arxiv.org/abs/2410.23244v2", "summary": "Bayesian Additive Regression Trees (BART) is a nonparametric Bayesian\nregression technique based on an ensemble of decision trees. It is part of the\ntoolbox of many statisticians. The overall statistical quality of the\nregression is typically higher than other generic alternatives, and it requires\nless manual tuning, making it a good default choice. However, it is a niche\nmethod compared to its natural competitor XGBoost, due to the longer running\ntime, making sample sizes above 10,000-100,000 a nuisance. I present a\nGPU-enabled implementation of BART, faster by up to 200x relative to a single\nCPU core, making BART competitive in running time with XGBoost. This\nimplementation is available in the Python package bartz.", "comment": "Check out the software at https://github.com/Gattocrucco/bartz", "pdf_url": "http://arxiv.org/pdf/2410.23244v2", "cate": "stat.ML", "date": "2024-10-30", "updated": "2025-07-09"}
{"id": "2507.01945", "title": "LongAnimation: Long Animation Generation with Dynamic Global-Local Memory", "authors": ["Nan Chen", "Mengqi Huang", "Yihao Meng", "Zhendong Mao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.01945v2", "summary": "Animation colorization is a crucial part of real animation industry\nproduction. Long animation colorization has high labor costs. Therefore,\nautomated long animation colorization based on the video generation model has\nsignificant research value. Existing studies are limited to short-term\ncolorization. These studies adopt a local paradigm, fusing overlapping features\nto achieve smooth transitions between local segments. However, the local\nparadigm neglects global information, failing to maintain long-term color\nconsistency. In this study, we argue that ideal long-term color consistency can\nbe achieved through a dynamic global-local paradigm, i.e., dynamically\nextracting global color-consistent features relevant to the current generation.\nSpecifically, we propose LongAnimation, a novel framework, which mainly\nincludes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a Color\nConsistency Reward. The SketchDiT captures hybrid reference features to support\nthe DGLM module. The DGLM module employs a long video understanding model to\ndynamically compress global historical features and adaptively fuse them with\nthe current generation features. To refine the color consistency, we introduce\na Color Consistency Reward. During inference, we propose a color consistency\nfusion to smooth the video segment transition. Extensive experiments on both\nshort-term (14 frames) and long-term (average 500 frames) animations show the\neffectiveness of LongAnimation in maintaining short-term and long-term color\nconsistency for open-domain animation colorization task. The code can be found\nat https://cn-makers.github.io/long_animation_web/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01945v2", "cate": "cs.CV", "date": "2025-07-02", "updated": "2025-07-09"}
{"id": "2502.02195", "title": "EFKAN: A KAN-Integrated Neural Operator For Efficient Magnetotelluric Forward Modeling", "authors": ["Feng Wang", "Hong Qiu", "Yingying Huang", "Xiaozhe Gu", "Renfang Wang", "Bo Yang"], "categories": ["physics.geo-ph", "cs.LG"], "primary_category": "Subjects:       Geophysics (physics.geo-ph)", "pdf_link": null, "comments": "Comments:      Submitted to Computers & Geosciences", "url": "http://arxiv.org/abs/2502.02195v2", "summary": "Magnetotelluric (MT) forward modeling is fundamental for improving the\naccuracy and efficiency of MT inversion. Neural operators (NOs) have been\neffectively used for rapid MT forward modeling, demonstrating their promising\nperformance in solving the MT forward modeling-related partial differential\nequations (PDEs). Particularly, they can obtain the electromagnetic field at\narbitrary locations and frequencies. In these NOs, the projection layers have\nbeen dominated by multi-layer perceptrons (MLPs), which may potentially reduce\nthe accuracy of solution due to they usually suffer from the disadvantages of\nMLPs, such as lack of interpretability, overfitting, and so on. Therefore, to\nimprove the accuracy of MT forward modeling with NOs and explore the potential\nalternatives to MLPs, we propose a novel neural operator by extending the\nFourier neural operator (FNO) with Kolmogorov-Arnold network (EFKAN). Within\nthe EFKAN framework, the FNO serves as the branch network to calculate the\napparent resistivity and phase from the resistivity model in the frequency\ndomain. Meanwhile, the KAN acts as the trunk network to project the resistivity\nand phase, determined by the FNO, to the desired locations and frequencies.\nExperimental results demonstrate that the proposed method not only achieves\nhigher accuracy in obtaining apparent resistivity and phase compared to the NO\nequipped with MLPs at the desired frequencies and locations but also\noutperforms traditional numerical methods in terms of computational speed.", "comment": "Submitted to Computers & Geosciences", "pdf_url": "http://arxiv.org/pdf/2502.02195v2", "cate": "physics.geo-ph", "date": "2025-02-04", "updated": "2025-07-09"}
{"id": "2507.03542", "title": "Beyond Accuracy: Metrics that Uncover What Makes a 'Good' Visual Descriptor", "authors": ["Ethan Lin", "Linxi Zhao", "Atharva Sehgal", "Jennifer J. Sun"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      VisCon @ CVPR 2025", "url": "http://arxiv.org/abs/2507.03542v2", "summary": "Text-based visual descriptors--ranging from simple class names to more\ndescriptive phrases--are widely used in visual concept discovery and image\nclassification with vision-language models (VLMs). Their effectiveness,\nhowever, depends on a complex interplay of factors, including semantic clarity,\npresence in the VLM's pre-training data, and how well the descriptors serve as\na meaningful representation space. In this work, we systematically analyze\ndescriptor quality along two key dimensions: (1) representational capacity, and\n(2) relationship with VLM pre-training data. We evaluate a spectrum of\ndescriptor generation methods, from zero-shot LLM-generated prompts to\niteratively refined descriptors. Motivated by ideas from representation\nalignment and language understanding, we introduce two alignment-based\nmetrics--Global Alignment and CLIP Similarity--that move beyond accuracy. These\nmetrics shed light on how different descriptor generation strategies interact\nwith foundation model properties, offering new ways to study descriptor\neffectiveness beyond accuracy evaluations.", "comment": "VisCon @ CVPR 2025", "pdf_url": "http://arxiv.org/pdf/2507.03542v2", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-09"}
{"id": "2502.18558", "title": "Transfer Learning for Transient Classification: From Simulations to Real Data and ZTF to LSST", "authors": ["Rithwik Gupta", "Daniel Muthukrishna", "Nabeel Rehemtulla", "Ved Shah"], "categories": ["astro-ph.IM", "astro-ph.HE", "cs.LG"], "primary_category": "Subjects:       Instrumentation and Methods for Astrophysics (astro-ph.IM)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures, 1 table. Accepted for publication in MNRAS Letters. A version of this paper was also accepted to the Machine Learning for Astrophysics Workshop 2025 at ICML", "url": "http://arxiv.org/abs/2502.18558v2", "summary": "Machine learning has become essential for automated classification of\nastronomical transients, but current approaches face significant limitations:\nclassifiers trained on simulations struggle with real data, models developed\nfor one survey cannot be easily applied to another, and new surveys require\nprohibitively large amounts of labelled training data. These challenges are\nparticularly pressing as we approach the era of the Vera C. Rubin Observatory's\nLegacy Survey of Space and Time (LSST), where existing classification models\nwill need to be retrained using LSST observations. We demonstrate that transfer\nlearning can overcome these challenges by repurposing existing models trained\non either simulations or data from other surveys. Starting with a model trained\non simulated Zwicky Transient Facility (ZTF) light curves, we show that\ntransfer learning reduces the amount of labelled real ZTF transients needed by\n95% while maintaining equivalent performance to models trained from scratch.\nSimilarly, when adapting ZTF models for LSST simulations, transfer learning\nachieves 94% of the baseline performance while requiring only 30% of the\ntraining data. These findings have significant implications for the early\noperations of LSST, suggesting that reliable automated classification will be\npossible soon after the survey begins, rather than waiting months or years to\naccumulate sufficient training data.", "comment": "7 pages, 5 figures, 1 table. Accepted for publication in MNRAS\n  Letters. A version of this paper was also accepted to the Machine Learning\n  for Astrophysics Workshop 2025 at ICML", "pdf_url": "http://arxiv.org/pdf/2502.18558v2", "cate": "astro-ph.IM", "date": "2025-02-25", "updated": "2025-07-08"}
{"id": "2507.05677", "title": "Integrated Structural Prompt Learning for Vision-Language Models", "authors": ["Jiahui Wang", "Qin Xu", "Bo Jiang", "Bin Luo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05677v2", "summary": "Prompt learning methods have significantly extended the transferability of\npre-trained Vision-Language Models (VLMs) like CLIP for various downstream\ntasks. These methods adopt handcraft templates or learnable vectors to provide\ntext or image instructions in fine-tuning VLMs. However, most existing works\nignore the structural relationships between learnable prompts and tokens within\nand between modalities. Moreover, balancing the performance of base and new\nclasses remains a significant challenge. In this paper, we propose an\nIntegrated Structural Prompt (ISP) for VLMs to enhance the interaction of\ninformation representations between the text and image branches. ISP introduces\nself-structural and cross-structural prompt modules to model the structural\nrelationships between learnable prompts and frozen tokens within and across\nmodalities. This enables efficient information transfer while preserving\nfeature stability. Additionally, we propose a sample probing module that\ndynamically adjusts loss coefficients based on sample difficulty, preventing\nthe mode from overfitting to simple samples and improving generalization\nability to new classes. Extensive experiments on three widely used settings:\nbase-to-new generalization, cross-dataset evaluation, and domain generalization\ndemonstrate that the proposed ISP achieves competitive performance against\nstate-of-the-art methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05677v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2503.09312", "title": "Terrier: A Deep Learning Repeat Classifier", "authors": ["Robert Turnbull", "Neil D. Young", "Edoardo Tescari", "Lee F. Skerratt", "Tiffany A. Kosch"], "categories": ["q-bio.GN", "cs.LG", "I.2"], "primary_category": "Subjects:       Genomics (q-bio.GN)", "pdf_link": null, "comments": "Comments:      14 pages, 9 figures", "url": "http://arxiv.org/abs/2503.09312v2", "summary": "Repetitive DNA sequences underpin genome architecture and evolutionary\nprocesses, yet they remain challenging to classify accurately. Terrier is a\ndeep learning model designed to overcome these challenges by classifying\nrepetitive DNA sequences using a publicly available, curated repeat sequence\nlibrary trained under the RepeatMasker schema. Poor representation of taxa\nwithin repeat databases often limits the classification accuracy and\nreproducibility of current repeat annotation methods, limiting our\nunderstanding of repeat evolution and function. Terrier overcomes these\nchallenges by leveraging deep learning for improved accuracy. Trained on\nRepbase, which includes over 100,000 repeat families -- four times more than\nDfam -- Terrier maps 97.1% of Repbase sequences to RepeatMasker categories,\noffering the most comprehensive classification system available. When\nbenchmarked against DeepTE, TERL, and TEclass2 in model organisms (rice, fruit\nflies, humans, and mice), Terrier achieved superior accuracy while classifying\na broader range of sequences. Further validation in non-model amphibian,\nflatworm and Northern krill genomes highlights its effectiveness in improving\nclassification in non-model species, facilitating research on repeat-driven\nevolution, genomic instability, and phenotypic variation.", "comment": "14 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2503.09312v2", "cate": "q-bio.GN", "date": "2025-03-12", "updated": "2025-07-09"}
{"id": "2507.05963", "title": "Tora2: Motion and Appearance Customized Diffusion Transformer for Multi-Entity Video Generation", "authors": ["Zhenghao Zhang", "Junchao Liao", "Xiangyu Meng", "Long Qin", "Weizhi Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ACM MM25 Conference Proceedings", "url": "http://arxiv.org/abs/2507.05963v2", "summary": "Recent advances in diffusion transformer models for motion-guided video\ngeneration, such as Tora, have shown significant progress. In this paper, we\npresent Tora2, an enhanced version of Tora, which introduces several design\nimprovements to expand its capabilities in both appearance and motion\ncustomization. Specifically, we introduce a decoupled personalization extractor\nthat generates comprehensive personalization embeddings for multiple open-set\nentities, better preserving fine-grained visual details compared to previous\nmethods. Building on this, we design a gated self-attention mechanism to\nintegrate trajectory, textual description, and visual information for each\nentity. This innovation significantly reduces misalignment in multimodal\nconditioning during training. Moreover, we introduce a contrastive loss that\njointly optimizes trajectory dynamics and entity consistency through explicit\nmapping between motion and personalization embeddings. Tora2 is, to our best\nknowledge, the first method to achieve simultaneous multi-entity customization\nof appearance and motion for video generation. Experimental results demonstrate\nthat Tora2 achieves competitive performance with state-of-the-art customization\nmethods while providing advanced motion control capabilities, which marks a\ncritical advancement in multi-condition video generation. Project page:\nhttps://ali-videoai.github.io/Tora2_page/.", "comment": "ACM MM25 Conference Proceedings", "pdf_url": "http://arxiv.org/pdf/2507.05963v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2505.00282", "title": "A Unifying Framework for Robust and Efficient Inference with Unstructured Data", "authors": ["Jacob Carlson", "Melissa Dell"], "categories": ["econ.EM", "cs.LG"], "primary_category": "Subjects:       Econometrics (econ.EM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00282v2", "summary": "This paper presents a general framework for conducting efficient inference on\nparameters derived from unstructured data, which include text, images, audio,\nand video. Economists have long used unstructured data by first extracting\nlow-dimensional structured features (e.g., the topic or sentiment of a text),\nsince the raw data are too high-dimensional and uninterpretable to include\ndirectly in empirical analyses. The rise of deep neural networks has\naccelerated this practice by greatly reducing the costs of extracting\nstructured data at scale, but neural networks do not make generically unbiased\npredictions. This potentially propagates bias to the downstream estimators that\nincorporate imputed structured data, and the availability of different\noff-the-shelf neural networks with different biases moreover raises p-hacking\nconcerns. To address these challenges, we reframe inference with unstructured\ndata as a problem of missing structured data, where structured variables are\nimputed from high-dimensional unstructured inputs. This perspective allows us\nto apply classic results from semiparametric inference, leading to estimators\nthat are valid, efficient, and robust. We formalize this approach with MAR-S, a\nframework that unifies and extends existing methods for debiased inference\nusing machine learning predictions, connecting them to familiar problems such\nas causal inference. Within this framework, we develop robust and efficient\nestimators for both descriptive and causal estimands and address challenges\nlike inference with aggregated and transformed missing structured data-a common\nscenario that is not covered by existing work. These methods-and the\naccompanying implementation package-provide economists with accessible tools\nfor constructing unbiased estimators using unstructured data in a wide range of\napplications, as we demonstrate by re-analyzing several influential studies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00282v2", "cate": "econ.EM", "date": "2025-05-01", "updated": "2025-07-08"}
{"id": "2507.06119", "title": "Omni-Video: Democratizing Unified Video Understanding and Generation", "authors": ["Zhiyu Tan", "Hao Yang", "Luozheng Qin", "Jia Gong", "Mengping Yang", "Hao Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Technical report, project page: this https URL", "url": "http://arxiv.org/abs/2507.06119v2", "summary": "Notable breakthroughs in unified understanding and generation modeling have\nled to remarkable advancements in image understanding, reasoning, production\nand editing, yet current foundational models predominantly focus on processing\nimages, creating a gap in the development of unified models for video\nunderstanding and generation. This report presents Omni-Video, an efficient and\neffective unified framework for video understanding, generation, as well as\ninstruction-based editing. Our key insight is to teach existing multimodal\nlarge language models (MLLMs) to produce continuous visual clues that are used\nas the input of diffusion decoders, which produce high-quality videos\nconditioned on these visual clues. To fully unlock the potential of our system\nfor unified video modeling, we integrate several technical improvements: 1) a\nlightweight architectural design that respectively attaches a vision head on\nthe top of MLLMs and a adapter before the input of diffusion decoders, the\nformer produce visual tokens for the latter, which adapts these visual tokens\nto the conditional space of diffusion decoders; and 2) an efficient multi-stage\ntraining scheme that facilitates a fast connection between MLLMs and diffusion\ndecoders with limited data and computational resources. We empirically\ndemonstrate that our model exhibits satisfactory generalization abilities\nacross video generation, editing and understanding tasks.", "comment": "Technical report, project page:\n  https://howellyoung-s.github.io/OmniVideo_project/", "pdf_url": "http://arxiv.org/pdf/2507.06119v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-09"}
{"id": "2506.03049", "title": "Torsion in Persistent Homology and Neural Networks", "authors": ["Maria Walch"], "categories": ["math.AT", "cs.LG"], "primary_category": "Subjects:       Algebraic Topology (math.AT)", "pdf_link": null, "comments": "Comments:      Minor corrections and clarifications", "url": "http://arxiv.org/abs/2506.03049v2", "summary": "We explore the role of torsion in hybrid deep learning models that\nincorporate topological data analysis, focusing on autoencoders. While most TDA\ntools use field coefficients, this conceals torsional features present in\ninteger homology. We show that torsion can be lost during encoding, altered in\nthe latent space, and in many cases, not reconstructed by standard decoders.\nUsing both synthetic and high-dimensional data, we evaluate torsion sensitivity\nto perturbations and assess its recoverability across several autoencoder\narchitectures. Our findings reveal key limitations of field-based approaches\nand underline the need for architectures or loss terms that preserve torsional\ninformation for robust data representation.", "comment": "Minor corrections and clarifications", "pdf_url": "http://arxiv.org/pdf/2506.03049v2", "cate": "math.AT", "date": "2025-06-03", "updated": "2025-07-09"}
{"id": "2506.12418", "title": "Noise tolerance via reinforcement: Learning a reinforced quantum dynamics", "authors": ["Abolfazl Ramezanpour"], "categories": ["quant-ph", "cond-mat.dis-nn", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      25 pages, 12 figures", "url": "http://arxiv.org/abs/2506.12418v2", "summary": "The performance of quantum simulations heavily depends on the efficiency of\nnoise mitigation techniques and error correction algorithms. Reinforcement has\nemerged as a powerful strategy to enhance the efficiency of learning and\noptimization algorithms. In this study, we demonstrate that a reinforced\nquantum dynamics can exhibit significant robustness against interactions with a\nnoisy environment. We study a quantum annealing process where, through\nreinforcement, the system is encouraged to maintain its current state or follow\na noise-free evolution. A learning algorithm is employed to derive a concise\napproximation of this reinforced dynamics, reducing the total evolution time\nand, consequently, the system's exposure to noisy interactions. This also\navoids the complexities associated with implementing quantum feedback in such\nreinforcement algorithms. The efficacy of our method is demonstrated through\nnumerical simulations of reinforced quantum annealing with one- and two-qubit\nsystems under Pauli noise.", "comment": "25 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2506.12418v2", "cate": "quant-ph", "date": "2025-06-14", "updated": "2025-07-09"}
{"id": "2506.14920", "title": "Q2SAR: A Quantum Multiple Kernel Learning Approach for Drug Discovery", "authors": ["Alejandro Giraldo", "Daniel Ruiz", "Mariano Caruso", "Javier Mancilla", "Guido Bellomo"], "categories": ["quant-ph", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.14920v3", "summary": "Quantitative Structure-Activity Relationship (QSAR) modeling is a cornerstone\nof computational drug discovery. This research demonstrates the successful\napplication of a Quantum Multiple Kernel Learning (QMKL) framework to enhance\nQSAR classification, showing a notable performance improvement over classical\nmethods. We apply this methodology to a dataset for identifying DYRK1A kinase\ninhibitors. The workflow involves converting SMILES representations into\nnumerical molecular descriptors, reducing dimensionality via Principal\nComponent Analysis (PCA), and employing a Support Vector Machine (SVM) trained\non an optimized combination of multiple quantum and classical kernels. By\nbenchmarking the QMKL-SVM against a classical Gradient Boosting model, we show\nthat the quantum-enhanced approach achieves a superior AUC score, highlighting\nits potential to provide a quantum advantage in challenging cheminformatics\nclassification tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.14920v3", "cate": "quant-ph", "date": "2025-06-17", "updated": "2025-07-09"}
{"id": "2506.20573", "title": "LARP: Learner-Agnostic Robust Data Prefiltering", "authors": ["Kristian Minchev", "Dimitar Iliev Dimitrov", "Nikola Konstantinov"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Presented at ICML 2025 Workshop on DataWorld: Unifying Data Curation Frameworks Across Domains", "url": "http://arxiv.org/abs/2506.20573v2", "summary": "The widespread availability of large public datasets is a key factor behind\nthe recent successes of statistical inference and machine learning methods.\nHowever, these datasets often contain some low-quality or contaminated data, to\nwhich many learning procedures are sensitive. Therefore, the question of\nwhether and how public datasets should be prefiltered to facilitate accurate\ndownstream learning arises. On a technical level this requires the construction\nof principled data prefiltering methods which are learner-agnostic robust, in\nthe sense of provably protecting a set of pre-specified downstream learners\nfrom corrupted data. In this work, we formalize the problem of Learner-Agnostic\nRobust data Prefiltering (LARP), which aims at finding prefiltering procedures\nthat minimize a worst-case loss over a pre-specified set of learners. We first\ninstantiate our framework in the context of scalar mean estimation with Huber\nestimators under the Huber data contamination model. We provide a hardness\nresult on a specific problem instance and analyze several natural prefiltering\nprocedures. Our theoretical results indicate that performing LARP on a\nheterogeneous set of learners leads to some loss in model performance compared\nto the alternative of prefiltering data for each learner/use-case individually.\nWe explore the resulting utility loss and its dependence on the problem\nparameters via extensive experiments on real-world image and tabular data,\nobserving statistically significant reduction in utility. Finally, we model the\ntrade-off between the utility drop and the cost of repeated (learner-specific)\nprefiltering within a game-theoretic framework and showcase benefits of LARP\nfor large datasets.", "comment": "Presented at ICML 2025 Workshop on DataWorld: Unifying Data Curation\n  Frameworks Across Domains", "pdf_url": "http://arxiv.org/pdf/2506.20573v2", "cate": "stat.ML", "date": "2025-06-25", "updated": "2025-07-09"}
{"id": "2506.21460", "title": "Wild refitting for black box prediction", "authors": ["Martin J. Wainwright"], "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Minor revisions: fixed discussion, corrected spelling", "url": "http://arxiv.org/abs/2506.21460v2", "summary": "We describe and analyze a computionally efficient refitting procedure for\ncomputing high-probability upper bounds on the instance-wise mean-squared\nprediction error of penalized nonparametric estimates based on least-squares\nminimization. Requiring only a single dataset and black box access to the\nprediction method, it consists of three steps: computing suitable residuals,\nsymmetrizing and scaling them with a pre-factor $\\rho$, and using them to\ndefine and solve a modified prediction problem recentered at the current\nestimate. We refer to it as wild refitting, since it uses Rademacher residual\nsymmetrization as in a wild bootstrap variant. Under relatively mild conditions\nallowing for noise heterogeneity, we establish a high probability guarantee on\nits performance, showing that the wild refit with a suitably chosen wild noise\nscale $\\rho$ gives an upper bound on prediction error. This theoretical\nanalysis provides guidance into the design of such procedures, including how\nthe residuals should be formed, the amount of noise rescaling in the wild\nsub-problem needed for upper bounds, and the local stability properties of the\nblock-box procedure. We illustrate the applicability of this procedure to\nvarious problems, including non-rigid structure-from-motion recovery with\nstructured matrix penalties; plug-and-play image restoration with deep neural\nnetwork priors; and randomized sketching with kernel methods.", "comment": "Minor revisions: fixed discussion, corrected spelling", "pdf_url": "http://arxiv.org/pdf/2506.21460v2", "cate": "stat.ML", "date": "2025-06-26", "updated": "2025-07-08"}
{"id": "2506.22675", "title": "Bayesian Invariance Modeling of Multi-Environment Data", "authors": ["Luhuan Wu", "Mingzhang Yin", "Yixin Wang", "John P. Cunningham", "David M. Blei"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.22675v3", "summary": "Invariant prediction [Peters et al., 2016] analyzes feature/outcome data from\nmultiple environments to identify invariant features - those with a stable\npredictive relationship to the outcome. Such features support generalization to\nnew environments and help reveal causal mechanisms. Previous methods have\nprimarily tackled this problem through hypothesis testing or regularized\noptimization. Here we develop Bayesian Invariant Prediction (BIP), a\nprobabilistic model for invariant prediction. BIP encodes the indices of\ninvariant features as a latent variable and recover them by posterior\ninference. Under the assumptions of Peters et al. [2016], the BIP posterior\ntargets the true invariant features. We prove that the posterior is consistent\nand that greater environment heterogeneity leads to faster posterior\ncontraction. To handle many features, we design an efficient variational\napproximation called VI-BIP. In simulations and real data, we find that BIP and\nVI-BIP are more accurate and scalable than existing methods for invariant\nprediction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.22675v3", "cate": "stat.ML", "date": "2025-06-27", "updated": "2025-07-09"}
{"id": "2507.04417", "title": "Neural Networks for Tamed Milstein Approximation of SDEs with Additive Symmetric Jump Noise Driven by a Poisson Random Measure", "authors": ["Jose-Hermenegildo Ramirez-Gonzalez", "Ying Sun"], "categories": ["stat.ML", "cs.LG", "60H10, 68T07", "I.2.6; G.3"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      14 pages, 9 figures, 4 tables", "url": "http://arxiv.org/abs/2507.04417v2", "summary": "This work aims to estimate the drift and diffusion functions in stochastic\ndifferential equations (SDEs) driven by a particular class of L\\'evy processes\nwith finite jump intensity, using neural networks. We propose a framework that\nintegrates the Tamed-Milstein scheme with neural networks employed as\nnon-parametric function approximators. Estimation is carried out in a\nnon-parametric fashion for the drift function $f: \\mathbb{Z} \\to \\mathbb{R}$,\nthe diffusion coefficient $g: \\mathbb{Z} \\to \\mathbb{R}$. The model of interest\nis given by \\[ dX(t) = \\xi + f(X(t))\\, dt + g(X(t))\\, dW_t + \\gamma\n\\int_{\\mathbb{Z}} z\\, N(dt,dz), \\] where $W_t$ is a standard Brownian motion,\nand $N(dt,dz)$ is a Poisson random measure on $(\\mathbb{R}_{+} \\times\n\\mathbb{Z}$, $\\mathcal{B} (\\mathbb{R}_{+}) \\otimes \\mathcal{Z}$, $\\lambda(\n\\Lambda \\otimes v))$, with $\\lambda, \\gamma > 0$, $\\Lambda$ being the Lebesgue\nmeasure on $\\mathbb{R}_{+}$, and $v$ a finite measure on the measurable space\n$(\\mathbb{Z}, \\mathcal{Z})$. Neural networks are used as non-parametric\nfunction approximators, enabling the modeling of complex nonlinear dynamics\nwithout assuming restrictive functional forms. The proposed methodology\nconstitutes a flexible alternative for inference in systems with\nstate-dependent noise and discontinuities driven by L\\'evy processes.", "comment": "14 pages, 9 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.04417v2", "cate": "stat.ML", "date": "2025-07-06", "updated": "2025-07-09"}
{"id": "2507.05610", "title": "On the Inherent Privacy of Zeroth Order Projected Gradient Descent", "authors": ["Devansh Gupta", "Meisam Razaviyayn", "Vatsal Sharan"], "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      Accepted at AISTATS'25", "url": "http://arxiv.org/abs/2507.05610v2", "summary": "Differentially private zeroth-order optimization methods have recently gained\npopularity in private fine tuning of machine learning models due to their\nreduced memory requirements. Current approaches for privatizing zeroth-order\nmethods rely on adding Gaussian noise to the estimated zeroth-order gradients.\nHowever, since the search direction in the zeroth-order methods is inherently\nrandom, researchers including Tang et al. (2024) and Zhang et al. (2024a) have\nraised an important question: is the inherent noise in zeroth-order estimators\nsufficient to ensure the overall differential privacy of the algorithm? This\nwork settles this question for a class of oracle-based optimization algorithms\nwhere the oracle returns zeroth-order gradient estimates. In particular, we\nshow that for a fixed initialization, there exist strongly convex objective\nfunctions such that running (Projected) Zeroth-Order Gradient Descent (ZO-GD)\nis not differentially private. Furthermore, we show that even with random\ninitialization and without revealing (initial and) intermediate iterates, the\nprivacy loss in ZO-GD can grow superlinearly with the number of iterations when\nminimizing convex objective functions.", "comment": "Accepted at AISTATS'25", "pdf_url": "http://arxiv.org/pdf/2507.05610v2", "cate": "math.OC", "date": "2025-07-08", "updated": "2025-07-09"}
