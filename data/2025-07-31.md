# AI-Enhanced arXiv Daily 2025-07-31

<a id='toc'></a>
## 今日总计: 939 篇论文
### 目录
- [cs.CR](#cscr) (51 篇)
- [cs.AI](#csai) (94 篇)
- [cs.LG](#cslg) (123 篇)
- [cs.MA](#csma) (4 篇)
- [cs.RO](#csro) (47 篇)
- [cs.CV](#cscv) (164 篇)
- [cs.HC](#cshc) (33 篇)
- [cs.ET](#cset) (1 篇)
- [cs.SE](#csse) (18 篇)
- [cs.SI](#cssi) (7 篇)
- [cs.NI](#csni) (7 篇)
- [cs.IT](#csit) (14 篇)
- [cs.AR](#csar) (3 篇)
- [cs.DC](#csdc) (9 篇)
- [cs.CY](#cscy) (26 篇)
- [cs.CE](#csce) (3 篇)
- [cs.FL](#csfl) (5 篇)
- [eess.SY](#eesssy) (30 篇)
- [eess.SP](#eesssp) (21 篇)
- [eess.IV](#eessiv) (11 篇)
- [eess.AS](#eessas) (4 篇)
- [cs.CL](#cscl) (113 篇)
- [cs.DS](#csds) (8 篇)
- [cs.GR](#csgr) (8 篇)
- [cs.IR](#csir) (19 篇)
- [cs.NE](#csne) (4 篇)
- [math.NA](#mathna) (17 篇)
- [cs.SD](#cssd) (15 篇)
- [cs.LO](#cslo) (2 篇)
- [quant-ph](#quant-ph) (10 篇)
- [stat.ML](#statml) (14 篇)
- [physics.flu-dyn](#physicsflu-dyn) (1 篇)
- [math.OC](#mathoc) (13 篇)
- [cs.CC](#cscc) (2 篇)
- [physics.data-an](#physicsdata-an) (1 篇)
- [physics.comp-ph](#physicscomp-ph) (1 篇)
- [q-bio.GN](#q-biogn) (1 篇)
- [nlin.AO](#nlinao) (1 篇)
- [cs.DB](#csdb) (3 篇)
- [cond-mat.stat-mech](#cond-matstat-mech) (2 篇)
- [cond-mat.mtrl-sci](#cond-matmtrl-sci) (3 篇)
- [stat.AP](#statap) (2 篇)
- [econ.EM](#econem) (1 篇)
- [cs.GT](#csgt) (2 篇)
- [q-bio.NC](#q-bionc) (3 篇)
- [math.AT](#mathat) (1 篇)
- [q-fin.PM](#q-finpm) (1 篇)
- [stat.ME](#statme) (2 篇)
- [physics.chem-ph](#physicschem-ph) (1 篇)
- [q-bio.BM](#q-biobm) (1 篇)
- [cond-mat.dis-nn](#cond-matdis-nn) (1 篇)
- [cond-mat.soft](#cond-matsoft) (1 篇)
- [astro-ph.IM](#astro-phim) (1 篇)
- [cs.MM](#csmm) (3 篇)
- [q-bio.QM](#q-bioqm) (1 篇)
- [physics.med-ph](#physicsmed-ph) (1 篇)
- [cs.DL](#csdl) (1 篇)
- [physics.optics](#physicsoptics) (1 篇)
- [math.CO](#mathco) (1 篇)
- [physics.soc-ph](#physicssoc-ph) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [7] [Prompt Optimization and Evaluation for LLM Automated Red Teaming](https://arxiv.org/abs/2507.22133)
> *LLM自动化红队提示优化与评估*

*Michael Freenor, Lauren Alvarez, Milton Leal, Lily Smith, Joel Garrett, Yelyzaveta Husieva, Madeline Woodruff, Ryan Miller, Erich Kummerfeld, Rafael Medeiros, Sander Schulhoff* | **Category: cs.CR, cs.CL** | **Updated: 2025-07-29**

**Keywords:** LLM, 自动化红队, 提示优化, 漏洞识别, 攻击成功率

**Comment:** 9 pages, 5 Figures, and 1 Appendix item

> **TL;DR:** 本文提出了一种优化LLM攻击生成器提示的方法，通过重复攻击来衡量个体攻击的成功率（可发现性），从而发现可利用的模式，以实现更鲁棒的评估和生成器优化。

**AI_Comments:** 本文提出了一种新颖的提示优化方法，通过引入“可发现性”这一概念，将传统的ASR评估从整体样本均值细化到单个攻击层面，这对于深入理解LLM漏洞和提升攻击生成器效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）应用的普及，识别系统漏洞变得越来越重要。自动化红队通过使用LLM生成和执行攻击来加速这一过程。

**Method:** 本文引入了一种优化攻击生成器提示的方法，该方法将攻击成功率（ASR）应用于单个攻击。通过针对随机种子目标多次重复每次攻击，测量攻击的“可发现性”（即单个攻击成功的期望）。

**Result:** 该方法揭示了可利用的模式，为提示优化提供了信息。

**Conclusion:** 这种方法最终能够对攻击生成器进行更鲁鲁棒的评估和完善。

> **ai_Abstract:** 本文针对LLM应用中识别系统漏洞的重要性，提出了一种优化LLM自动化红队攻击生成器提示的新方法。该方法通过将攻击成功率（ASR）应用于单个攻击，并重复多次攻击以测量其“可发现性”，从而揭示可利用的模式。这有助于信息化的提示优化，并最终实现对攻击生成器更鲁棒的评估和改进。

> **摘要翻译:** 使用大型语言模型（LLM）的应用程序正变得越来越普遍，这使得识别系统漏洞变得日益重要。自动化红队通过使用LLM生成并针对目标系统执行攻击，从而加速了这一工作。攻击生成器通过攻击成功率（ASR）进行评估，ASR是根据每次攻击的成功判断计算出的样本均值。在本文中，我们引入了一种优化攻击生成器提示的方法，该方法将ASR应用于单个攻击。通过针对随机种子目标多次重复每次攻击，我们测量了攻击的“可发现性”——即单个攻击成功的期望。这种方法揭示了可利用的模式，这些模式为提示优化提供了信息，最终实现了对生成器更鲁棒的评估和完善。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [14] [Strategic Deflection: Defending LLMs from Logit Manipulation](https://arxiv.org/abs/2507.22160)
> *策略性偏转：防御LLMs免受Logit操纵*

*Yassine Rachidy, Jihad Rbaiti, Youssef Hmamouche, Faissal Sehbaoui, Amal El Fallah Seghrouchni* | **Category: cs.CR, cs.AI, cs.CL** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, Logit操纵, 越狱攻击, 策略性偏转, 防御策略

**Comment:** 20 pages

> **TL;DR:** SDeflection是一种新的防御LLM对抗logit操纵攻击的方法，它通过生成语义上相关但无害的回复来中和恶意意图，而不是直接拒绝，从而显著降低攻击成功率。

**AI_Comments:** 这项工作提出了一种创新的防御理念，从被动的拒绝转向主动的“偏转”，即在不完全拒绝用户请求的前提下，巧妙地化解其恶意意图。这对于提高LLM在实际应用中的鲁棒性和用户体验具有重要意义，尤其是在处理模糊或恶意意图混合的场景时。其创新性在于改变了防御的范式，从堵截转变为疏导。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）在关键领域的广泛应用，确保其免受越狱攻击的安全性至关重要。传统的防御方法主要依赖于拒绝恶意提示，但最近的logit级别攻击已能通过直接操纵生成过程中的token选择来绕过这些防护。

**Method:** 我们引入了策略性偏转（SDeflection）防御机制。该机制不是完全拒绝，而是生成一个与用户请求语义上相邻但去除了有害意图的答案，从而中和攻击者的有害意图。

**Result:** 我们的实验表明，SDeflection显著降低了攻击成功率（ASR），同时保持了模型在良性查询上的性能。

**Conclusion:** 这项工作代表了防御策略的关键转变，从简单的拒绝转向战略性内容重定向，以中和高级威胁。

> **ai_Abstract:** 本文介绍了一种名为“策略性偏转”（SDeflection）的新型防御机制，旨在保护大型语言模型（LLMs）免受通过直接操纵token选择的logit级别攻击。与传统的拒绝策略不同，SDeflection通过生成语义上接近但剥离了有害意图的响应来中和恶意请求。实验结果表明，SDeflection能显著降低攻击成功率，同时不影响模型在正常查询上的表现，标志着LLM防御策略从简单拒绝转向了更智能的战略性内容重定向。

> **摘要翻译:** 随着大型语言模型（LLMs）在关键领域的日益普及，确保其免受越狱攻击的安全性至关重要。虽然传统防御主要依赖于拒绝恶意提示，但最近的logit级别攻击已表明能够通过直接操纵生成过程中的token选择来绕过这些防护。我们引入了策略性偏转（SDeflection），这是一种重新定义LLM对此类高级攻击响应的防御机制。该模型不是完全拒绝，而是生成一个与用户请求语义上相邻但去除了有害意图的答案，从而中和攻击者的有害意图。我们的实验表明，SDeflection显著降低了攻击成功率（ASR），同时保持了模型在良性查询上的性能。这项工作代表了防御策略的关键转变，从简单的拒绝转向战略性内容重定向，以中和高级威胁。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [36] [Interpretable Anomaly-Based DDoS Detection in AI-RAN with XAI and LLMs](https://arxiv.org/abs/2507.21193)
> *在AI-RAN中使用XAI和LLM的可解释性基于异常的DDoS检测*

*Sotiris Chatzimiltis, Mohammad Shojafar, Mahdi Boloursaz Mashhadi, Rahim Tafazolli* | **Category: cs.CR, cs.LG** | **Updated: 2025-07-27**

**Keywords:** AI-RAN, DDoS检测, 可解释人工智能, LLMs, 异常检测

**Comment:** 

> **TL;DR:** 本文提出了一种结合LSTM、XAI（LIME/SHAP）和LLM的可解释性异常检测系统，用于AI-RAN中的DDoS攻击检测，并在真实5G数据上取得了高准确率和可解释的输出。

**AI_Comments:** 该论文的创新点在于将基于异常的DDoS检测与可解释人工智能（XAI）和大型语言模型（LLMs）相结合，特别是在AI-RAN这一新兴且关键的领域。通过引入LIME/SHAP和LLMs，论文有效地解决了传统AI模型在网络安全领域可解释性不足的问题，使得检测结果不仅准确，而且易于非专家用户理解和采取行动。这对于提升未来5G/6G网络的安全性和管理效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 下一代无线接入网络（RANs）引入了可编程性、智能化和近实时控制，以增强RAN内部和更广泛5G/6G基础设施的安全。论文首先对大型语言模型（LLMs）辅助的可解释（XAI）入侵检测系统（IDS）在未来RAN环境中的机遇、挑战和研究空白进行了全面调查，并在此基础上提出了一个LLM可解释的基于异常的DDoS检测系统。

**Method:** 该方法提出了一个基于LLM的可解释性异常检测系统，用于分布式拒绝服务（DDoS）攻击。它使用从E2节点提取的多变量时间序列关键性能指标（KPMs），在近实时RAN智能控制器（Near-RT RIC）中运行。一个基于LSTM的模型被训练用于识别恶意用户设备（UE）行为。为了增强透明度，应用了LIME和SHAP等事后局部可解释性方法来解释个体预测。此外，还利用LLMs将技术解释转换为非专业用户可访问的自然语言洞察。

**Result:** 在真实5G网络KPMs上的实验结果表明，该框架实现了高检测精度（F1-score > 0.96），同时提供了可操作和可解释的输出。

**Conclusion:** 该论文成功提出了一个结合LSTM、XAI和LLMs的可解释性异常DDoS检测系统，在真实5G网络数据上表现出高准确率，并能提供易于理解的解释，从而增强了未来RAN环境的安全性。

> **ai_Abstract:** 本文针对AI-RAN中DDoS攻击检测的可解释性问题，提出了一个结合LSTM、XAI（如LIME和SHAP）以及LLMs的基于异常的检测系统。该系统利用5G网络中的关键性能指标（KPMs），通过LSTM模型识别恶意行为，并利用XAI方法解释预测结果，最终通过LLMs将技术解释转化为非专业用户可理解的自然语言。实验证明，该框架在真实5G数据上实现了高精度检测（F1-score > 0.96），并提供了可解释的输出，提升了未来RAN环境的安全性。

> **摘要翻译:** 下一代无线接入网络（RANs）通过智能控制器引入了可编程性、智能化和近实时控制，从而增强了RAN内部以及更广泛的5G/6G基础设施的安全性。本文进行了一项全面调查，重点介绍了大型语言模型（LLMs）辅助的可解释（XAI）入侵检测系统（IDS）在未来安全RAN环境中的机遇、挑战和研究空白。受此启发，我们提出了一个基于LLM的可解释性异常检测系统，用于分布式拒绝服务（DDoS）攻击，该系统使用从E2节点提取的多变量时间序列关键性能指标（KPMs），并在近实时RAN智能控制器（Near-RT RIC）中运行。一个基于LSTM的模型被训练用于识别基于这些KPMs的恶意用户设备（UE）行为。为了增强透明度，我们应用了LIME和SHAP等事后局部可解释性方法来解释个体预测。此外，还利用LLMs将技术解释转换为非专业用户可访问的自然语言洞察。在真实5G网络KPMs上的实验结果表明，我们的框架实现了高检测精度（F1-score > 0.96），同时提供了可操作和可解释的输出。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [85] [MaXsive: High-Capacity and Robust Training-Free Generative Image Watermarking in Diffusion Models](https://arxiv.org/abs/2507.21195)
> *MaXsive: 扩散模型中高容量、鲁棒的免训练生成图像水印技术*

*Po-Yuan Mao, Cheng-Chang Tsai, Chun-Shien Lu* | **Category: cs.CR, cs.AI, cs.MM** | **Updated: 2025-07-28**

**Keywords:** 图像水印, 扩散模型, 免训练, 鲁棒性, 容量

**Comment:** 

> **TL;DR:** MaXsive是一种高容量、鲁棒的免训练扩散模型生成图像水印技术，通过利用初始噪声和X形模板来应对RST攻击，并解决版权和不当内容生成问题。

**AI_Comments:** MaXsive的创新之处在于其免训练的特性，这大大降低了应用成本。通过利用初始噪声和引入独特的X形模板来解决RST攻击问题，它在保持高容量的同时显著提高了鲁棒性，解决了现有方法的关键局限性，对于扩散模型生成的图像版权保护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在图像合成方面的巨大成功导致了商业模型的发布，引发了版权保护和不当内容生成的问题。现有的免训练扩散水印技术容易受到旋转、缩放和平移（RST）攻击，且一些旨在缓解此问题的方法会降低水印容量，可能导致身份（ID）串通。

**Method:** 本文提出MaXsive，一种免训练的扩散模型生成水印技术。它最佳地利用初始噪声来水印扩散模型。此外，该方法不使用精细重复的环形图案，而是注入X形模板来恢复RST失真。

**Result:** MaXsive的有效性已在两个著名的水印基准上，在验证和识别场景下得到验证。

**Conclusion:** MaXsive通过利用初始噪声和创新的X形模板，显著提高了水印的鲁棒性，同时保持了高容量，有效解决了现有方法的局限性，并为扩散模型中的图像版权保护提供了实用的解决方案。

> **ai_Abstract:** MaXsive是一种针对扩散模型提出的高容量、鲁棒的免训练生成图像水印技术，旨在解决版权保护和不当内容生成问题。针对现有方法在旋转、缩放和平移（RST）攻击下脆弱且容量受限的问题，MaXsive创新性地利用初始噪声进行水印，并引入X形模板来校正RST失真。这种设计在不牺牲容量的前提下显著提升了水印的鲁棒性，从而降低了身份串通的风险。其有效性已在两个主要水印基准上得到验证。

> **摘要翻译:** 扩散模型在图像合成方面的巨大成功导致了庞大商业模型的发布，这引发了版权保护和不当内容生成的问题。免训练扩散水印为这些问题提供了一种低成本的解决方案。然而，现有工作仍然容易受到旋转、缩放和平移（RST）攻击。尽管有些方法采用精心设计的图案来缓解这个问题，但它们通常会降低水印容量，这可能导致身份（ID）串通。为了解决这些问题，我们提出了MaXsive，一种高容量和鲁棒的免训练扩散模型生成水印技术。MaXsive最佳地利用初始噪声来水印扩散模型。此外，该方法不使用精细重复的环形图案，而是提出注入X形模板来恢复RST失真。这种设计在不损失任何容量的情况下显著提高了鲁棒性，使得身份串通更不可能发生。MaXsive的有效性已在验证和识别场景下，在两个著名的水印基准上得到验证。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [141] [Verification Cost Asymmetry in Cognitive Warfare: A Complexity-Theoretic Framework](https://arxiv.org/abs/2507.21258)
> *认知战中的验证成本不对称：一个复杂性理论框架*

*Joshua Luberisse* | **Category: cs.CR, cs.CC, cs.CY, cs.GT, F.0; H.0** | **Updated: 2025-07-28**

**Keywords:** 认知战, 验证成本不对称, 复杂性理论, 可概率检查证明, 信息流

**Comment:** 

> **TL;DR:** 本文提出了认知战中的验证成本不对称（VCA）系数，利用可概率检查证明和参数化复杂性理论构建传播协议，使可信受众的验证成本恒定，而对手的成本超线性，为认知战中建立民主优势奠定理论基础。

**AI_Comments:** 这项研究具有创新性，因为它将复杂性理论应用于认知战这一新兴领域，特别是信息验证成本的不对称性。它不仅提供了理论框架，还通过用户研究进行了验证，并指出了实际应用，为在信息战中保护民主社会提供了潜在的新策略。其核心思想是利用信息验证的内在复杂性来区分和惩罚恶意行为者，同时减轻可信用户的负担，这对于应对虚假信息传播具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在对抗性信息流下，人类验证是一个受工作记忆限制和认知偏差约束的成本受限决策过程。

**Method:** 引入了验证成本不对称（VCA）系数，并将其形式化为在相同声明分布下不同人群之间预期验证工作的比率。利用可概率检查证明（PCP）和参数化复杂性理论，构建了传播协议，旨在将可信受众的验证成本降低到恒定的人力投入，同时对缺乏密码基础设施的对抗性人群施加超线性成本。通过受控用户研究验证了该框架，并演示了实际信息活动的编码。

**Result:** 结果为在认知战中构建民主优势奠定了复杂性理论基础，并可立即应用于内容认证、平台治理和信息行动学说。

**Conclusion:** 该研究建立了认知战中民主优势的复杂性理论基础，并具有在内容认证、平台治理和信息行动学说方面的即时应用。

> **ai_Abstract:** 本文提出了认知战中的验证成本不对称（VCA）框架，旨在解决对抗性信息流下人类验证的成本问题。通过引入VCA系数，并结合可概率检查证明和参数化复杂性理论，设计了能够显著降低可信受众验证成本，同时大幅增加对抗性群体成本的传播协议。研究通过理论证明和用户研究验证了该框架的有效性，为在认知战中获得信息优势提供了坚实的复杂性理论基础，并具有内容认证、平台治理和信息行动等实际应用。

> **摘要翻译:** 在对抗性信息流下，人类验证是一个受工作记忆限制和认知偏差约束的成本受限决策过程。我们引入了验证成本不对称（VCA）系数，并将其形式化为在相同声明分布下不同人群之间预期验证工作的比率。借鉴可概率检查证明（PCP）和参数化复杂性理论，我们构建了传播协议，旨在将可信受众的验证成本降低到恒定的人力投入，同时对缺乏密码基础设施的对抗性人群施加超线性成本。我们证明了这种不对称的理论保证，通过测量有无可即时检查溯源的用户研究验证了该框架，并演示了实际信息活动的编码。这些结果为在认知战中构建民主优势奠定了复杂性理论基础，并可立即应用于内容认证、平台治理和信息行动学说。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [163] [Adversarial attacks and defenses in explainable artificial intelligence: A survey](https://arxiv.org/abs/2306.06123)
> *可解释人工智能中的对抗性攻击与防御：一项综述*

*Hubert Baniecki, Przemyslaw Biecek* | **Category: cs.CR, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 可解释人工智能, 对抗性攻击, 对抗性防御, 对抗性机器学习, 综述

**Comment:** Accepted by Information Fusion

> **TL;DR:** 该综述全面概述了可解释人工智能（XAI）中对抗性攻击及其防御的研究，指出XAI方法易受对抗性机器学习（AdvML）攻击，并提出了统一的符号和分类法，讨论了防御策略，并指出了未来的研究方向。

**AI_Comments:** 该论文的重要性在于它填补了可解释人工智能（XAI）和对抗性机器学习（AdvML）交叉领域的研究空白。通过提供全面的综述、统一的符号和分类法，它为该领域的研究人员和从业者提供了宝贵的资源。论文强调了XAI方法的安全性和可信度问题，这对XAI在实际高风险应用中的部署至关重要。其对现有不安全性和未来研究方向的概述，为后续研究奠定了基础，具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 可解释人工智能（XAI）方法被视为调试、信任模型和解释预测的补救措施。然而，对抗性机器学习（AdvML）的最新进展揭示了现有解释方法的局限性和脆弱性，使其安全性和可信度受到质疑。在关键决策和知识发现中，操纵、欺骗或“洗白”模型推理证据的可能性会带来有害后果，因此需要对XAI的对抗性攻击和防御进行深入研究。

**Method:** 本综述全面概述了针对机器学习模型解释的对抗性攻击以及公平性指标的研究。文章引入了统一的符号和方法分类法，为对抗性机器学习（AdvML）和可解释人工智能（XAI）交叉领域的研究人员和从业者提供了共同基础。文章还讨论了如何防御攻击和设计鲁棒的解释方法。

**Result:** 本综述提供了可解释人工智能（XAI）中对抗性攻击和防御的全面研究概述。它引入了统一的符号和分类法，讨论了防御对抗性攻击和设计鲁棒解释方法。此外，它还列出了XAI中现有的不安全性，并概述了对抗性XAI（AdvXAI）的新兴研究方向。

**Conclusion:** 未来的工作应致力于改进解释方法和评估协议，以解决本综述中报告的安全问题。

> **ai_Abstract:** 本综述探讨了可解释人工智能（XAI）在对抗性机器学习（AdvML）面前的脆弱性及其潜在的严重后果。文章全面概述了针对XAI的对抗性攻击和防御策略，提出了统一的符号和分类法，并讨论了如何构建鲁棒的解释方法。此外，本综述还指出了XAI中现有的安全漏洞，并为未来的对抗性XAI研究方向提供了指导，强调需改进解释方法和评估协议以应对安全挑战。

> **摘要翻译:** 可解释人工智能（XAI）方法被视为调试和信任统计及深度学习模型以及解释其预测的补救措施。然而，对抗性机器学习（AdvML）的最新进展突显了最先进解释方法的局限性和脆弱性，使其安全性和可信度受到质疑。当应用于高风险决策和知识发现时，操纵、欺骗或“洗白”模型推理证据的可能性会带来有害后果。本综述全面概述了有关机器学习模型解释的对抗性攻击以及公平性指标的研究。我们引入了统一的符号和方法分类法，为AdvML和XAI交叉领域的研究人员和从业者提供了共同基础。我们讨论了如何防御攻击和设计鲁棒的解释方法。我们列出了XAI中现有的不安全性，并概述了对抗性XAI（AdvXAI）的新兴研究方向。未来的工作应致力于改进解释方法和评估协议，以考虑到所报告的安全问题。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [198] [Radio Adversarial Attacks on EMG-based Gesture Recognition Networks](https://arxiv.org/abs/2507.21387)
> *针对基于肌电图手势识别网络的射频对抗攻击*

*Hongyi Xie* | **Category: cs.CR** | **Updated: 2025-07-28**

**Keywords:** EMG手势识别, 对抗攻击, 射频干扰, 电磁兼容性, 深度学习安全

**Comment:** 

> **TL;DR:** 首次展示了通过射频干扰对基于EMG的手势识别系统进行物理对抗攻击，显著降低了识别准确率，揭示了其安全漏洞。

**AI_Comments:** 这项工作具有重要的创新性和实践意义。它首次将对抗攻击从数字领域扩展到物理射频领域，并直接作用于EMG设备，揭示了现有EMG手势识别系统在电磁干扰下的脆弱性，特别是在医疗和人机交互等安全关键应用中。研究不仅提出了攻击方法，还量化了攻击效果，并初步提出了防御措施，为未来EMG系统的安全设计提供了宝贵见解。其局限性可能在于攻击的同步性要求（虽然提到了无同步策略，但实际物理实现仍有挑战）以及对特定频率和功率的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度学习模型在EMG手势识别中取得了高精度，但其在物理领域对抗攻击的脆弱性尚未得到充分探索。本研究旨在揭示并量化EMG系统在物理射频干扰下的安全漏洞，尤其是在康复、假肢和虚拟现实等安全关键应用中。

**Method:** 提出了一种名为ERa Attack的射频对抗方法，通过有意电磁干扰（IEMI）针对EMG设备。该方法利用低功率软件定义无线电发射器注入优化的射频扰动。攻击流程包括：使用投影梯度下降生成对抗性扰动，通过逆短时傅里叶变换提取50-150 Hz分量，并采用无同步策略（恒定频谱噪声或窄带调制）。扰动被限制在信号幅度的1-10%内，并对433 MHz载波进行幅度调制。实验在Myo数据集上进行。

**Result:** 在1米距离和0 dBm发射功率下，分类准确率从97.8%显著下降到58.3%，误分类率为41.7%，定向攻击成功率为25.6%。攻击效果随距离呈指数衰减，在3米处准确率恢复到85%。将功率增加到10 dBm时，在1米距离上准确率额外降低15%。

**Conclusion:** 本研究开创了针对EMG识别系统的射频对抗攻击，揭示了安全关键应用中的关键漏洞。量化了不同扰动模式和距离下的攻击效果，并提出了包括硬件屏蔽、频谱监测和对抗训练在内的防御措施，为设计更鲁棒的EMG系统提供了依据。

> **ai_Abstract:** 本文首次提出了一种通过射频干扰对EMG手势识别网络进行物理对抗攻击的方法——ERa Attack。该方法利用低功率软件定义无线电发射器注入优化的射频扰动，成功地将EMG分类准确率从97.8%降低到58.3%，揭示了EMG系统在物理领域的关键漏洞。研究量化了攻击效果与距离和功率的关系，并提出了相应的防御策略，为未来鲁棒EMG系统的设计提供了重要指导。

> **摘要翻译:** 表面肌电图（EMG）使得康复、假肢和虚拟现实中的非侵入式人机交互成为可能。尽管深度学习模型实现了超过97%的分类准确率，但其在物理领域对抗攻击的脆弱性在很大程度上仍未被探索。我们提出了ERa Attack，这是第一个通过有意电磁干扰（IEMI）针对EMG设备的射频（RF）对抗方法。攻击者使用低功率软件定义无线电发射器注入优化的射频扰动，以误导下游模型。我们的方法连接了数字和物理领域：我们使用投影梯度下降生成对抗性扰动，通过逆短时傅里叶变换提取50-150 Hz分量，并采用无同步策略（恒定频谱噪声或窄带调制）。扰动被限制在信号幅度的1-10%内，并对433 MHz载波进行幅度调制。在Myo数据集（7种手势，350个样本）上的实验证明了显著影响：在1米距离和0 dBm发射功率下，分类准确率从97.8%下降到58.3%，误分类率为41.7%，定向攻击成功率为25.6%。攻击效果随距离呈指数衰减，在3米处准确率恢复到85%。将功率增加到10 dBm时，在1米距离上准确率额外降低15%。这项工作开创了基于射频的EMG识别系统对抗攻击，揭示了安全关键应用中的关键漏洞。我们量化了不同扰动模式和距离下的攻击效果，并提出了包括硬件屏蔽、频谱监测和对抗训练在内的防御措施。我们的发现为设计抵抗电磁威胁的鲁棒EMG系统提供了信息。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [220] [Voting by mail: a Markov chain model for managing the security risks of election systems](https://arxiv.org/abs/2410.13900)
> *邮寄投票：一种用于管理选举系统安全风险的马尔可夫链模型*

*Carmen A. Haseltine, Laura A. Albert* | **Category: cs.CR, math.PR** | **Updated: 2025-07-29**

**Keywords:** 邮寄投票, 马尔可夫链, 风险评估, 选举安全, 投票系统

**Comment:** 

> **TL;DR:** 本文提出一个基于离散时间马尔可夫链（DTMC）的动态数学模型，用于评估邮寄投票（VBM）过程的风险和性能，并发现投票箱和自动通知系统对VBM安全至关重要。

**AI_Comments:** 这篇论文通过引入离散时间马尔可夫链（DTMC）模型，为邮寄投票（VBM）的风险评估提供了一个新颖且动态的数学框架，这在当前对选举系统安全日益关注的背景下具有重要意义。其创新之处在于能够捕捉动态风险、考虑多层威胁，并结合真实数据进行案例研究。该方法有望为选举管理者提供更科学的工具来规划和保护VBM流程，尤其是在识别关键安全措施方面。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，美国对邮寄投票（VBM）的审查日益严格，引发了对缺席投票完整性和安全性的担忧。

**Method:** 引入了一个动态数学建模框架，该框架使用离散时间马尔可夫链（DTMC）来模拟邮寄投票过程，并通过新颖的分层网络方法评估选举性能和风险，该方法考虑了邮寄投票过程、恶意和非恶意威胁以及安全缓解措施之间的相互作用。该模型能够捕获动态风险并随时间评估性能，并考虑从无意选民错误到复杂定向攻击的各种结果。通过基于威斯康星州密尔沃基县的真实世界数据进行的案例研究来评估模型。

**Result:** 分析表明，投票箱和自动选票通知系统对于确保邮寄投票操作的安全性和可靠性至关重要。

**Conclusion:** 邮寄投票的风险评估可以通过所提出的DTMC模型得到显著改进，并且投票箱和自动选票通知系统是确保邮寄投票系统安全可靠运行的关键。

> **ai_Abstract:** 本文针对美国邮寄投票（VBM）日益增长的安全担忧，提出了一种基于离散时间马尔可夫链（DTMC）的动态数学模型框架。该模型通过分层网络方法，综合考虑VBM流程、各类威胁和安全缓解措施，以评估选举性能和风险，并能捕获动态风险。通过密尔沃基县的真实数据案例研究，该模型被验证能够有效评估VBM的风险，并指出投票箱和自动选票通知系统对保障VBM安全可靠运行至关重要。

> **摘要翻译:** 近年来，美国对邮寄投票（VBM）的审查日益严格，引发了对缺席投票完整性和安全性的担忧。本文通过引入一个动态数学建模框架来解决这些问题，该框架用于对邮寄投票流程进行风险评估。我们引入了一个离散时间马尔可夫链（DTMC）来模拟邮寄投票过程，并通过一种新颖的分层网络方法评估选举性能和风险，该方法考虑了邮寄投票过程、恶意和非恶意威胁以及安全缓解措施之间的相互作用。时变DTMC框架捕获动态风险并随时间评估性能。DTMC模型考虑了从无意选民错误到复杂、有针对性攻击的一系列结果，代表了邮寄投票规划和保护风险评估的重大进步。本文使用基于威斯康星州密尔沃基县真实世界数据的案例研究来评估DTMC模型。分析包括攻击场景的开发和安全措施的评估，以说明不同攻击时间的影响。分析表明，投票箱和自动选票通知系统对于确保安全可靠的操作至关重要。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [252] [Digital identity management system with blockchain:An implementation with Ethereum and Ganache](https://arxiv.org/abs/2507.21398)
> *基于区块链的数字身份管理系统：以太坊和Ganache的实现*

*André Davi Lopes, Tais Mello, Wesley dos Reis Bezerra* | **Category: cs.CR** | **Updated: 2025-07-29**

**Keywords:** 数字身份, 区块链, 以太坊, Ganache, 分布式系统

**Comment:** 

> **TL;DR:** 本文开发了一个利用FastAPI、MongoDB、gRPC、Docker、以太坊和Ganache等现代技术构建的分布式数字身份系统，旨在展示分布式系统和区块链在数字身份安全、可追溯性和去中心化方面的优势。

**AI_Comments:** 该论文通过实际实现展示了区块链技术在数字身份管理中的应用潜力。其创新点在于结合了微服务架构与区块链模拟，验证了分布式系统的优势。尽管目前是基于模拟环境，但已为未来与真实区块链网络的集成奠定了基础，具有较好的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的目的是展示分布式系统和区块链技术在数字身份的安全、可追溯性和去中心化方面的优势。

**Method:** 该方法包括开发一个带有JWT认证的微服务架构、在MongoDB中进行数据持久化、使用Ganache模拟区块链操作以及使用Docker进行容器化。

**Result:** 结果表明了所提出方法的可行性，系统具有功能性Web界面、完整的审计日志以及基于以太坊的区块链模拟。

**Conclusion:** 该论文讨论了理论基础、技术实现、获得的结果以及与真实区块链网络集成的未来前景，并证明了所提出方法的可行性。

> **ai_Abstract:** 本文开发了一个基于微服务架构的分布式数字身份管理系统，利用FastAPI、MongoDB、gRPC、Docker等技术，并通过以太坊和Ganache模拟区块链操作。研究旨在突出区块链在数字身份安全、可追溯性和去中心化方面的优势，并验证了所提方案的可行性，实现了功能性Web界面和完整的审计日志。

> **摘要翻译:** 本文介绍了一个利用FastAPI、MongoDB、gRPC、Docker以及使用Ganache和以太坊进行区块链模拟等现代技术开发的分布式数字身份系统。其目标是展示分布式系统和区块链在数字身份的安全、可追溯性和去中心化方面的优势。方法包括开发一个带有JWT认证的微服务架构、在MongoDB中进行数据持久化、使用Ganache模拟区块链操作以及使用Docker进行容器化。结果表明了所提出方法的可行性，系统具有功能性Web界面、完整的审计日志以及基于以太坊的区块链模拟。本文讨论了理论基础、技术实现、获得的结果以及与真实区块链网络集成的未来前景。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [275] [Development and analysis of a secured VoIP system for surveillance activities](https://arxiv.org/abs/2507.21038)
> *用于监控活动的安全VoIP系统的开发与分析*

*M. Matsive Ali* | **Category: cs.CR** | **Updated: 2025-07-29**

**Keywords:** VoIP系统, 安全通信, 中间人攻击, 嵌入式系统, 监控活动

**Comment:** 

> **TL;DR:** 开发了一个用于监控活动的嵌入式安全VoIP系统，通过加密传输语音数据，以抵御中间人攻击。

**AI_Comments:** 这篇论文的创新点在于将嵌入式系统与加密VoIP技术相结合，专为监控活动设计，并强调了其紧凑性和数据安全传输能力。其重要性在于提供了一种应对中间人攻击的实用解决方案，特别适用于需要保密通信的特定场景。然而，抽象中未详细说明加密的具体算法和安全性分析的深入程度，也未提及系统的性能（如延迟、带宽消耗）或在实际监控环境中的鲁棒性测试。

<details>
  <summary>Details</summary>

**Motivation:** 电话是主要的通信方式，但VoIP正日益普及。然而，VoIP数据传输面临中间人攻击等网络安全威胁，因此需要开发一种安全的VoIP系统。

**Method:** 论文开发了一个基于嵌入式系统的安全VoIP系统。该系统包含驻极体麦克风、嵌入式C、Particle Photon微控制器和物联网技术。它使用MAX9814麦克风收集声音信号，Particle Photon微控制器安全地传输加密数据。有权访问的设备可以从VoIP系统的TCP服务器下载数据，并在本地存储音频并上传到Google Drive。

**Result:** 该VoIP系统能够通过加密数据传输在路由器范围内发送语音，提供了一种安全的通信方式，同时保留了原始信号的完整性。

**Conclusion:** 开发的VoIP系统为监控活动提供了一种安全、紧凑且能保持原始信号完整性的通信方法，有效应对了网络安全威胁。

> **ai_Abstract:** 本文开发并分析了一个用于监控活动的安全VoIP系统，旨在解决VoIP通信中存在的中间人攻击等安全问题。该系统是一个紧凑的嵌入式解决方案，集成了麦克风、微控制器和物联网技术，能够通过加密方式在IP网络上传输语音数据。系统利用MAX9814麦克风采集音频，由Particle Photon微控制器进行安全传输，并支持通过TCP服务器下载数据至本地存储并上传至Google Drive。研究表明，该系统能提供安全的通信，同时保持原始信号的完整性。

> **摘要翻译:** 自20世纪90年代以来，电话一直是主要的通信方式。然而，VoIP（互联网协议语音）作为一种高度直接且经济实惠的数据传输形式，正日益成为日常通信的重要组成部分。VoIP是一种能够通过公共或私人IP网络发送语音和多媒体数据包的技术。然而，一种名为中间人攻击的网络攻击在通过任何网络传输数据时都构成了严重的安全隐患。因此，作者设计了一个系统，该系统在路由器范围内使用加密数据传输通过互联网发送语音。开发了一个包含驻极体麦克风、嵌入式C、Particle Photon微控制器和物联网（IoT）技术的嵌入式系统。由于其紧凑的尺寸，这种设备可以集成到汽车、监控系统或秘密监听工具中。该VoIP系统使用MAX9814麦克风收集声音信号，同时Particle Photon微控制器安全地传输数据。有权访问的设备可以从VoIP系统的传输控制协议（TCP）服务器下载数据。被访问的设备在本地存储音频，并将相应数据上传到Google Drive。该VoIP系统提供了一种安全的通信方法，同时保持了原始信号的完整性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [323] [Cascading and Proxy Membership Inference Attacks](https://arxiv.org/abs/2507.21412)
> *级联和代理成员推理攻击*

*Yuntao Du, Jiacheng Li, Yuetian Chen, Kaiyuan Zhang, Zhizhen Yuan, Hanshen Xiao, Bruno Ribeiro, Ninghui Li* | **Category: cs.CR, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 成员推理攻击, 隐私风险, 级联成员推理攻击, 代理成员推理攻击, 影子模型

**Comment:** Our code is available at: https://github.com/zealscott/MIA

> **TL;DR:** 本文提出了两种新的成员推理攻击方法CMIA和PMIA，分别针对自适应和非自适应设置，并在实验中表现出优于现有方法的性能。

**AI_Comments:** 这篇论文通过提出CMIA和PMIA两种新颖的攻击方法，显著提升了成员推理攻击的效率和准确性，尤其是在自适应和非自适应两种重要场景下。其创新点在于CMIA利用了实例间的成员依赖性，而PMIA引入了代理选择策略。这些方法对于评估机器学习模型的隐私风险具有重要意义，促使研究人员开发更强大的隐私保护机制。

<details>
  <summary>Details</summary>

**Motivation:** 现有成员推理攻击（MIA）旨在评估机器学习模型对其训练数据泄露的程度。本文的动机是改进MIA的性能，尤其是在考虑实例间的成员依赖性以及在非自适应设置下的攻击能力。

**Method:** 本文提出了两种成员推理攻击方法：1. 级联成员推理攻击（CMIA）：针对自适应设置，通过条件影子训练整合成员依赖性以提高性能。2. 代理成员推理攻击（PMIA）：针对非自适应设置，采用代理选择策略识别与查询实例行为相似的样本，并利用其行为进行成员后验赔率测试。两种攻击都提供了理论分析。

**Result:** 广泛的实验结果表明，CMIA和PMIA在自适应和非自适应两种设置下都显著优于现有成员推理攻击，特别是在评估隐私风险至关重要的低误报率区域。

**Conclusion:** CMIA和PMIA是有效的成员推理攻击方法，能够显著提升现有MIA的性能，对评估机器学习模型的隐私风险具有重要意义。

> **ai_Abstract:** 本文研究了成员推理攻击（MIA），并将其分为自适应和非自适应两种类型。针对自适应设置，提出了级联成员推理攻击（CMIA），通过利用实例间的成员依赖性来增强攻击效果。针对非自适应设置，引入了代理成员推理攻击（PMIA），该方法通过代理选择策略进行成员推理。理论分析和实验结果表明，CMIA和PMIA在性能上显著优于现有MIA，尤其在低误报率下表现突出，对于评估模型隐私风险至关重要。

> **摘要翻译:** 成员推理攻击（MIA）通过确定特定查询实例是否包含在数据集中，评估训练好的机器学习模型对其训练数据泄露了多少信息。我们根据攻击者是否被允许在成员查询上训练影子模型，将现有MIA分为自适应或非自适应。在自适应设置中，攻击者可以在访问查询实例后训练影子模型，我们强调利用实例间成员依赖性的重要性，并提出了一种与攻击无关的框架，称为级联成员推理攻击（CMIA），它通过条件影子训练来整合成员依赖性，以提高成员推理性能。在非自适应设置中，攻击者在获取成员查询之前被限制训练影子模型，我们引入了代理成员推理攻击（PMIA）。PMIA采用代理选择策略，识别与查询实例行为相似的样本，并利用它们在影子模型中的行为执行成员后验赔率测试以进行成员推理。我们对这两种攻击都提供了理论分析，并且广泛的实验结果表明，CMIA和PMIA在两种设置下都大大优于现有MIA，特别是在低误报率区域，这对于评估隐私风险至关重要。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [390] [NCCR: to Evaluate the Robustness of Neural Networks and Adversarial Examples](https://arxiv.org/abs/2507.21483)
> *NCCR：评估神经网络和对抗性样本的鲁棒性*

*Pu Shi* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 神经网络, 对抗性样本, 鲁棒性评估, NCCR, 神经元覆盖变化率

**Comment:** 

> **TL;DR:** 本文提出了一种名为NCCR（神经元覆盖变化率）的新指标，用于评估神经网络的鲁棒性和对抗性样本的稳定性，并能用于检测对抗性样本。

**AI_Comments:** 这项工作提出了一种新颖的、基于神经元激活变化的量化指标NCCR，以评估神经网络的鲁棒性。其创新之处在于提供了一种直接衡量模型抵抗扰动能力的方法，并能区分对抗性样本。这对于提高深度学习模型的安全性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的研究主要集中在对抗性攻击和防御上，但对于如何评估神经网络及其输入的鲁棒性研究较少。神经网络容易受到微小扰动但对人类不可察觉的对抗性样本的攻击，因此需要一种方法来衡量模型抵抗攻击的能力和对抗性样本的稳定性。

**Method:** 本文提出了一种名为神经元覆盖变化率（NCCR）的指标。NCCR通过监测当输入受到扰动时特定选择的神经元输出的变化来衡量深度学习模型抵抗攻击的能力以及对抗性样本的稳定性。变化程度越小的网络被认为鲁棒性越强。

**Result:** 在图像识别和说话人识别模型上的实验结果表明，NCCR指标能够很好地评估神经网络或其输入的鲁棒性。此外，它还可以用于检测输入是否为对抗性样本，因为对抗性样本的鲁棒性总是较低。

**Conclusion:** NCCR是一个有效且可靠的指标，可以用来评估神经网络的鲁棒性及其输入的稳定性，并且能够识别对抗性样本。

> **ai_Abstract:** 本文提出了一种新的度量标准——神经元覆盖变化率（NCCR），旨在解决神经网络鲁棒性评估领域的研究空白。NCCR通过监测输入扰动下特定神经元输出的变化来量化深度学习模型抵抗攻击的能力以及对抗性样本的稳定性。实验结果表明，NCCR能有效评估神经网络及其输入的鲁棒性，并能用于识别鲁棒性较低的对抗性样本。

> **摘要翻译:** 神经网络最近受到了广泛关注，随之而来的是相关的安全问题。许多研究表明，神经网络容易受到对抗性样本的攻击，这些样本经过了人工扰动，其修改微小到人类感知无法区分。为了解决这些问题，人们提出了不同的攻击和防御方法，但关于评估神经网络及其输入鲁棒性的研究却很少。在这项工作中，我们提出了一种名为神经元覆盖变化率（NCCR）的指标，用于衡量深度学习模型抵抗攻击的能力和对抗性样本的稳定性。NCCR监测当输入受到扰动时特定选择的神经元输出的变化，变化程度越小的网络被认为鲁棒性越强。在图像识别和说话人识别模型上的实验结果表明，我们的指标能够很好地评估神经网络或其输入的鲁棒性。它还可以用于检测输入是否为对抗性样本，因为对抗性样本的鲁棒性总是较低。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [448] [Hot-Swap MarkBoard: An Efficient Black-box Watermarking Approach for Large-scale Model Distribution](https://arxiv.org/abs/2507.20650)
> *热插拔标记板：一种用于大规模模型分发的黑盒水印方法*

*Zhicheng Zhang, Peizhuo Lv, Mengke Wan, Jiang Fang, Diandian Guo, Yezeng Chen, Yinlong Liu, Wei Ma, Jiyan Sun, Liru Geng* | **Category: cs.CR, cs.AI, cs.CV** | **Updated: 2025-07-28**

**Keywords:** 水印, 知识产权, 端侧AI, LoRA, 黑盒验证

**Comment:** 

> **TL;DR:** 本文提出Hot-Swap MarkBoard，一种高效的黑盒水印方法，用于大规模深度学习模型分发，通过多分支LoRA和参数混淆实现无需重训的独特用户定制水印。

**AI_Comments:** 本文的创新之处在于，它为大规模端侧AI分发场景提供了独特的、可定制的用户水印，且无需重新训练，这对于知识产权保护至关重要。利用多分支LoRA实现高效定制以及参数混淆机制增强鲁棒性是其关键优势。其黑盒验证能力和广泛的兼容性进一步提升了其在实际应用中的价值。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型作为端侧AI部署时面临日益严重的知识产权风险，因为模型被分发到大量本地设备，容易被盗窃和再分发。现有水印方案多为云端AIaaS设计，不适用于每个用户模型实例需携带独特水印的大规模分发场景，且通常需要重训才能修改水印。

**Method:** Hot-Swap MarkBoard通过在多分支低秩适应（LoRA）模块中独立嵌入多个水印来编码用户特定的n位二进制签名，通过分支交换实现无需重训的高效水印定制。此外，参数混淆机制将水印权重与基础模型权重纠缠，防止在不降低模型性能的情况下被移除。该方法支持黑盒验证，兼容多种模型架构和深度学习任务（包括分类、图像生成和文本生成）。

**Result:** 在三类任务和六种骨干模型上的广泛实验表明，与现有方法相比，Hot-Swap MarkBoard表现出卓越的效率和适应性，并实现了100%的验证准确率。

**Conclusion:** Hot-Swap MarkBoard通过提供一种高效、可定制且鲁棒的黑盒水印解决方案，有效解决了大规模深度学习模型分发中的知识产权保护挑战，并具有高验证准确性。

> **ai_Abstract:** Hot-Swap MarkBoard是一种高效的黑盒水印方法，旨在解决大规模深度学习模型分发中的知识产权风险。针对现有方法需重训才能定制水印的痛点，该方法通过在多分支LoRA模块中独立嵌入多个水印来编码用户特定的二进制签名，并通过分支交换实现无需重训的水印定制。结合参数混淆机制，确保水印难以移除。该方法支持黑盒验证，兼容多种模型架构和DL任务，并在实验中展现出卓越的效率和适应性，实现了100%的验证精度。

> **摘要翻译:** 近年来，深度学习（DL）模型越来越多地作为端侧AI部署在终端用户设备上，从而提高了效率和隐私性。然而，这种部署趋势带来了更严重的知识产权（IP）风险，因为模型被分发到大量本地设备上，使其容易被盗窃和再分发。大多数现有的所有权保护解决方案（例如，基于后门的水印）是为基于云的AI即服务（AIaaS）设计的，不直接适用于大规模分发场景，在这些场景中，每个用户特定的模型实例都必须携带独特的水印。这些方法通常嵌入固定水印，修改嵌入式水印需要重新训练模型。为了解决这些挑战，我们提出了Hot-Swap MarkBoard，一种高效的水印方法。它通过独立地将多个水印嵌入到多分支低秩适应（LoRA）模块中来编码用户特定的n位二进制签名，从而通过分支交换实现无需重新训练的高效水印定制。参数混淆机制进一步将水印权重与基础模型的权重纠缠在一起，防止在不降低模型性能的情况下被移除。该方法支持黑盒验证，并兼容各种模型架构和DL任务，包括分类、图像生成和文本生成。在三类任务和六种骨干模型上的广泛实验证明了我们的方法比现有方法具有卓越的效率和适应性，实现了100%的验证准确率。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [450] [Privacy-Preserving AI for Encrypted Medical Imaging: A Framework for Secure Diagnosis and Learning](https://arxiv.org/abs/2507.21060)
> *加密医学影像的隐私保护AI：一个安全诊断与学习的框架*

*Abdullah Al Siam, Sadequzzaman Shohan* | **Category: cs.CR, cs.AI, eess.IV** | **Updated: 2025-05-17**

**Keywords:** 隐私保护AI, 加密医学影像, 安全诊断, Masked-CNN, 数据隐私

**Comment:** 

> **TL;DR:** 该研究提出了一个用于加密医学图像的隐私保护AI框架，使用Masked-CNN和AES-CBC加密，实现了与未加密模型相当的诊断性能，同时保障了数据隐私。

**AI_Comments:** 该论文的创新点在于提出了一个将加密技术与深度学习相结合的实用框架，有效地解决了医疗影像数据隐私与AI诊断效率之间的矛盾。Masked-CNN的引入使得AI模型能够直接在加密数据上进行推断，具有重要的现实意义。其贡献在于提供了一个可扩展的解决方案，有望推动安全AI在医疗领域的应用。

<details>
  <summary>Details</summary>

**Motivation:** AI在医学诊断中的快速应用引发了对患者隐私的担忧，尤其是在敏感影像数据传输、存储或处理时。

**Method:** 本文提出了一种新颖的框架，用于对加密医学图像进行隐私保护的诊断推断。该方法利用修改后的卷积神经网络（Masked-CNN），能够在转换或加密的图像格式上运行。它结合了AES-CBC加密和JPEG2000压缩来保护医学图像，同时保持其适用于AI推断。系统在NIH ChestX-ray14和LIDC-IDRI等公共DICOM数据集上进行评估，关注诊断准确性、推断延迟、存储效率和隐私泄露抵抗性。

**Result:** 实验结果表明，加密推断模型实现了与其未加密对应模型相当的性能，在准确性和延迟方面只有微小的权衡。

**Conclusion:** 所提出的框架弥合了数据隐私和临床实用性之间的鸿沟，为安全的AI驱动诊断提供了一个实用、可扩展的解决方案。

> **ai_Abstract:** 本论文提出了一个针对加密医学影像的隐私保护AI框架，旨在解决AI在医疗诊断中面临的患者隐私问题。该框架采用了一种名为Masked-CNN的修改版卷积神经网络，结合AES-CBC加密和JPEG2000压缩技术，以实现在加密状态下对医学图像进行诊断推断。实验结果显示，该加密推断模型在准确性和延迟方面与未加密模型表现相当，证明了其在保障数据隐私的同时，仍能提供实用且可扩展的AI驱动诊断能力。

> **摘要翻译:** 人工智能（AI）在医学诊断中的快速整合引发了对患者隐私的紧迫担忧，特别是当敏感影像数据必须进行传输、存储或处理时。在本文中，我们提出了一种新颖的框架，用于在加密医学图像上进行隐私保护的诊断推断，该框架使用经过修改的卷积神经网络（Masked-CNN），能够对转换或加密的图像格式进行操作。我们的方法利用AES-CBC加密结合JPEG2000压缩来保护医学图像，同时保持其适用于AI推断。我们使用公共DICOM数据集（NIH ChestX-ray14和LIDC-IDRI）对系统进行了评估，重点关注诊断准确性、推断延迟、存储效率和隐私泄露抵抗性。实验结果表明，加密推断模型实现了与其未加密对应模型相当的性能，在准确性和延迟方面只有微小的权衡。所提出的框架弥合了数据隐私和临床实用性之间的鸿沟，为安全的AI驱动诊断提供了一个实用、可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [451] [Can We End the Cat-and-Mouse Game? Simulating Self-Evolving Phishing Attacks with LLMs and Genetic Algorithms](https://arxiv.org/abs/2507.21538)
> *我们能结束猫鼠游戏吗？使用大型语言模型和遗传算法模拟自进化的网络钓鱼攻击*

*Seiji Sato, Tetsushi Ohki, Masakatsu Nishigaki* | **Category: cs.CR** | **Updated: 2025-07-29**

**Keywords:** 网络钓鱼攻击, 大型语言模型, 遗传算法, 网络安全, 社会工程

**Comment:** 

> **TL;DR:** 该研究提出一个结合LLM和遗传算法的框架，模拟自进化的网络钓鱼攻击，以预测未来威胁并分析攻防动态。

**AI_Comments:** 这项研究的创新之处在于将LLMs的生成能力与遗传算法的进化机制相结合，模拟了网络钓鱼攻击的动态演变，并引入了心理学背景，使其更贴近现实。它揭示了网络安全中攻击者与防御者之间的固有不对称性，为预测和对抗未来社会工程威胁提供了宝贵的见解。其可扩展和经济高效的特点也使其具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有预测网络钓鱼威胁的方法依赖于现有训练数据，难以应对新兴攻击方法，因此需要一种新颖的方法来解决这一局限性，以实现主动网络安全。

**Method:** 本研究提出了一个新颖的框架，将基于大型语言模型（LLM）的网络钓鱼攻击模拟与心理学背景下的遗传算法相结合。该框架通过与模拟受害者的对抗性互动，使网络钓鱼策略能够动态进化。模拟使用Llama 3.1进行。

**Result:** 1. 自进化的网络钓鱼策略采用日益复杂的心理操纵技术，超越了简单的LLM生成攻击。2. 受害者先验知识的变化显著影响攻击策略的演变。3. 进化的攻击与自适应防御之间的对抗性互动创造了猫鼠动态，揭示了网络安全中固有的不对称性，即攻击者不断完善其方法，而防御者难以全面应对所有演进的威胁。

**Conclusion:** 该方法为分析网络钓鱼策略和防御的演变提供了一种可扩展、经济高效的方法，为未来的社会工程威胁提供了见解，并强调了主动网络安全措施的必要性。

> **ai_Abstract:** 这篇论文提出了一种结合大型语言模型（LLMs）和遗传算法的新框架，用于模拟自进化的网络钓鱼攻击。该框架通过与模拟受害者的对抗性互动，使网络钓鱼策略动态演变。研究发现，自进化策略比简单LLM生成的攻击更复杂，受害者知识影响攻击演变，并且攻防之间存在“猫鼠游戏”的不对称性。该方法提供了一种分析未来网络钓鱼威胁及其防御的有效途径。

> **摘要翻译:** 预测新兴攻击方法对于主动网络安全至关重要。大型语言模型（LLMs）的最新进展使得网络钓鱼消息的自动化生成成为可能，并加速了对潜在攻击技术的研究。然而，由于依赖现有训练数据，预测未来威胁仍然具有挑战性。为了解决这一局限性，我们提出了一个新颖的框架，该框架将基于LLM的网络钓鱼攻击模拟与心理学背景下的遗传算法相结合，通过与模拟受害者的对抗性互动，使网络钓鱼策略能够动态进化。通过使用Llama 3.1进行的模拟，我们证明了（1）自进化的网络钓鱼策略采用日益复杂的心理操纵技术，超越了简单的LLM生成攻击，（2）受害者先验知识的变化显著影响攻击策略的演变，以及（3）进化的攻击与自适应防御之间的对抗性互动创造了猫鼠动态，揭示了网络安全固有的不对称性——攻击者不断完善其方法，而防御者难以全面应对所有演进的威胁。我们的方法为分析网络钓鱼策略和防御的演变提供了一种可扩展、经济高效的方法，为未来的社会工程威胁提供了见解，并强调了主动网络安全措施的必要性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [457] [Security practices in AI development](https://arxiv.org/abs/2507.21061)
> *人工智能开发中的安全实践*

*Petr Spelda, Vit Stritecky* | **Category: cs.CR, cs.CY** | **Updated: 2025-05-17**

**Keywords:** 人工智能安全, 安全实践, 通用人工智能, 可信度, 证券化

**Comment:** 11 pages

> **TL;DR:** 本文探讨了通用人工智能系统安全声明的可信度，指出安全实践而非工具能力是关键，并揭示了现有实践的不足，最终提出改进建议。

**AI_Comments:** 本文创新性地将AI安全实践置于“证券化过程”的视角下审视，揭示了其在支持商业开发中的角色及其局限性。它强调了安全实践的重要性超越了工具本身的能力，并指出了当前实践在多样性和参与方面的不足，为未来AI安全治理提供了宝贵的改进方向。

<details>
  <summary>Details</summary>

**Motivation:** 探究通用人工智能系统（如大型语言模型）的安全声明如何变得可信。

**Method:** 通过分析安全工具（如对齐和红队测试程序）的能力与所需安全保障之间的差距，批判性地调查人工智能安全实践如何弥补这一差距，并识别其在多样性和参与方面的不足。

**Result:** 发现当前的安全实践是证券化过程的一部分，旨在支持通用人工智能系统的（商业）开发，而这些系统的可信度只能被不完美地测试而非完全保证。

**Conclusion:** 通过提出多项改进措施，以完善当前的人工智能安全实践。

> **ai_Abstract:** 本文分析了通用人工智能系统（如大型语言模型）安全声明的可信度来源，指出安全实践而非安全工具的能力是关键因素。研究揭示了安全工具与实际安全保障之间的差距，并批判性地探讨了现有AI安全实践如何试图弥补这一差距，同时指出了其在多样性和参与方面的不足。研究认为，这些实践是为支持AI商业开发而进行的证券化过程，其可信度难以完全保证。最后，文章提出了改进当前AI安全实践的建议。

> **摘要翻译:** 关于通用人工智能系统（如大型语言模型）的安全声明，其可信度何在？我们发现，并非安全工具（如对齐和红队测试程序）的能力，而是基于这些工具的安全实践，重新塑造了人工智能安全的形象，并使这些声明变得可接受。在揭示安全工具能力与所需安全保障之间差距的原因后，我们批判性地调查了人工智能安全实践如何试图弥补这一差距，并指出了在多样性和参与方面的几项不足。我们发现，这些安全实践是证券化过程的一部分，旨在支持通用人工智能系统的（商业）开发，而这些系统的可信度只能被不完美地测试而非完全保证。最后，我们提出了一些改进当前人工智能安全实践的建议。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [464] [Private key and password protection by steganographic image encryption](https://arxiv.org/abs/2507.21068)
> *基于隐写图像加密的私钥和密码保护*

*Debesh Choudhury, Sujoy Chakraborty* | **Category: cs.CR** | **Updated: 2025-06-05**

**Keywords:** 私钥保护, 隐写术, 图像加密, QR码, LFSR

**Comment:** 5 pages, 3 figures, Applications of Digital Image Processing XLV,
  SPIE Optical Engineering + Applications 2022, Proc. SPIE 12226,

> **TL;DR:** 该研究提出了一种通过将加密的私钥或密码QR码隐写嵌入到彩色图像中来保护其安全的技术，并通过用户选择的种子图像生成加密密钥，实验证明了其可行性。

**AI_Comments:** 该论文提出了一种新颖的结合隐写术、QR码和LFSR来保护敏感信息（如私钥和密码）的方法。其创新之处在于利用图像作为载体，并通过用户可控的种子图像来生成加密密钥，提高了安全性。该方法的重要性在于为关键信息的存储和传输提供了一种额外的安全层。论文中提到用户可以通过多份备份轻松恢复被修改的种子图像，这增加了系统的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 保护和保存私钥或密码的安全。

**Method:** 将私钥或密码转换为加密的QR码，并使用隐写方案嵌入到真实的彩色图像中。加密QR码的密钥由线性反馈移位寄存器（LFSR）的输出生成，该LFSR由用户选择的种子图像初始化。通过从彩色图像中提取加密的QR码，然后对其进行解密来恢复私钥或密码。

**Result:** 实验证明了使用样本私钥数据和真实彩色图像实现该技术的可行性。

**Conclusion:** 该技术能够有效地保护和保存私钥或密码，并具有可行性。

> **ai_Abstract:** 本文提出了一种通过隐写图像加密来保护私钥或密码的方法。该方法将私钥或密码转换为加密的QR码，并嵌入到彩色图像中。加密密钥由用户选择的种子图像初始化的线性反馈移位寄存器生成。该技术允许用户安全存储种子图像，即使攻击者修改种子图像，用户也能通过多份备份轻松恢复。实验证明了该技术的可行性。

> **摘要翻译:** 我们提出了一种技术，用于在加密的二维图形图像中保护和保存私钥或密码。明文私钥或密码被转换为加密的QR码，并使用隐写方案嵌入到真实的彩色图像中。私钥或密码通过首先从彩色图像中提取加密的QR码，然后对其进行解密来从隐写彩色图像中恢复。用于加密QR码的加密密钥由线性反馈移位寄存器（LFSR）的输出生成，该LFSR由用户选择的种子图像初始化。用户可以安全地存储种子图像，而无需攻击者知晓。即使活跃的攻击者修改了种子图像（在不知道它是种子图像的情况下），如果用户保留多份副本，也可以轻松恢复它，从而可以轻松重新生成加密密钥。我们的实验证明了使用样本私钥数据和真实彩色图像实现该技术的可行性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [471] [Applications Of Zero-Knowledge Proofs On Bitcoin](https://arxiv.org/abs/2507.21085)
> *零知识证明在比特币上的应用*

*Yusuf Ozmiş* | **Category: cs.CR** | **Updated: 2025-06-19**

**Keywords:** 零知识证明, 比特币, zk-STARKs, 储备金证明, 轻客户端, Rollup

**Comment:** 

> **TL;DR:** 本文探讨了零知识证明如何增强比特币的功能和隐私，具体分析了储备金证明、ZK轻客户端和隐私保护Rollup三种应用场景，并讨论了它们的效率和信任假设权衡。

**AI_Comments:** 本文创新性地将零知识证明应用于比特币的多个核心功能，包括储备金证明、轻客户端验证和隐私保护Rollup。其亮点在于提出了适应比特币UTXO模型的具体协议设计，并对其实用性进行了评估。这为比特币生态系统带来了增强隐私和可扩展性的潜力。然而，论文也指出了在实际应用中，效率和信任假设之间的权衡是需要仔细考虑的关键限制。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探索零知识证明如何增强比特币的功能和隐私。

**Method:** 本文首先探讨了储备金证明方案，通过使用zk-STARKs，使托管方无需透露地址或实际余额即可证明其比特币持有量超过预设阈值X。其次，研究了ZK轻客户端，提出了一种基于STARK的协议，用于生成和验证区块头链的证明，实现信任最小化的客户端操作。第三，通过BitVM探索了隐私保护Rollup，设计了一个概念性的Rollup，利用零知识证明保持交易数据机密性。在每种情况下，论文都分析了安全性，与现有方法进行了比较，并讨论了实现考虑因素。

**Result:** 研究结果表明，零知识证明可以为比特币带来强大的功能，例如链上储备审计、无需信任的轻客户端和私有第二层执行。然而，每种应用都需要在效率和信任假设之间进行仔细权衡。

**Conclusion:** 零知识证明可以为比特币带来强大的功能，但每种应用都需要在效率和信任假设之间进行仔细权衡。

> **ai_Abstract:** 本文深入探讨了零知识证明（ZKP）在增强比特币功能和隐私方面的应用。研究内容包括三个主要方面：一是利用zk-STARKs实现无需透露具体信息的比特币储备金证明；二是设计基于STARK的协议以构建信任最小化的ZK轻客户端；三是基于BitVM概念性地构建使用零知识证明的隐私保护Rollup。论文分析了这些方案的安全性、效率、与现有方法的比较以及实现考量，并提出了适应比特币UTXO模型的具体协议设计。研究结果强调，尽管ZKP能为比特币带来链上审计、无需信任的客户端和私有二层执行等强大特性，但每项应用都需在效率和信任假设间进行权衡。

> **摘要翻译:** 本文探讨了零知识证明如何增强比特币的功能和隐私。首先，我们考虑储备金证明方案：通过使用zk-STARKs，托管方可以证明其比特币持有量超过预设阈值X，而无需透露地址或实际余额。我们概述了一个基于STARK的比特币UTXO协议，并讨论了其效率。其次，我们研究了ZK轻客户端，其中移动或轻量级设备使用简洁证明来验证比特币的工作量证明链。我们提出了一种协议，用于生成和验证基于STARK的区块头链证明，从而实现信任最小化的客户端操作。第三，我们通过BitVM探索了隐私保护Rollups：利用BitVM，我们设计了一个概念性的Rollup，该Rollup使用零知识证明保持交易数据机密性。在每种情况下，我们都分析了安全性，与现有方法进行了比较，并讨论了实现考虑因素。我们的贡献包括针对比特币UTXO模型设计的具体协议，以及对其实用性的评估。结果表明，虽然零知识证明可以为比特币带来强大的功能（例如，链上储备审计、无需信任的轻客户端和私有第二层执行），但每种应用都需要在效率和信任假设之间进行仔细权衡。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [478] [Intelligent ARP Spoofing Detection using Multi-layered Machine Learning (ML) Techniques for IoT Networks](https://arxiv.org/abs/2507.21087)
> *用于物联网网络的多层机器学习（ML）技术的智能ARP欺骗检测*

*Anas Ali, Mubashar Husain, Peter Hans* | **Category: cs.CR, cs.CY** | **Updated: 2025-06-23**

**Keywords:** ARP欺骗, 物联网网络, 机器学习, 网络安全, 异常检测

**Comment:** 

> **TL;DR:** 本论文提出了一种智能多层机器学习框架，用于实时检测物联网网络中的ARP欺骗，实现了高检测精度和低误报率。

**AI_Comments:** 本论文的创新之处在于其针对物联网环境的特点，提出了一种结合多层机器学习技术和分层架构的ARP欺骗检测框架。这种方法有效解决了传统检测机制在资源受限和去中心化物联网环境中效率低下的问题，并通过在不同层级部署不同复杂度的模型，平衡了检测精度和计算效率。其高检测准确率和低误报率证明了该方法的有效性和实用性，为物联网网络安全领域提供了重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 地址解析协议（ARP）欺骗仍然是物联网网络面临的关键威胁，攻击者可以利用ARP缺乏认证的弱点来拦截、修改或中断数据传输。物联网环境的去中心化和资源受限特性加剧了这种漏洞，使得传统检测机制在大规模应用中失效。

**Method:** 本研究引入了一种智能、多层机器学习框架，用于实时物联网部署中的ARP欺骗检测。该方法结合了基于ARP头部行为、流量分析和时间数据包异常的特征工程，以及包含决策树、集成模型和深度学习分类器的混合检测管道。论文提出了一种分层架构，优先在边缘网关使用轻量级模型，在中心化节点使用更深层模型，以平衡检测精度和计算效率。

**Result:** 该系统在模拟物联网流量和CICIDS2017数据集上进行了验证，实现了超过97%的检测准确率和低误报率。与基于签名和基于规则的系统进行比较评估，证明了该方法的鲁棒性和泛化能力。

**Conclusion:** 我们的结果表明，智能机器学习集成能够为物联网场景量身定制主动的ARP欺骗检测，为可扩展和自主的网络安全解决方案奠定了基础。

> **ai_Abstract:** 本论文提出了一种针对物联网网络中ARP欺骗的智能多层机器学习检测框架。该框架通过结合特征工程和混合机器学习模型（包括决策树、集成模型和深度学习分类器）来实现实时检测。为平衡准确性和效率，系统采用了分层架构，在边缘网关使用轻量级模型，在中心节点使用深度模型。在模拟物联网流量和CICIDS2017数据集上的验证显示，该方法实现了超过97%的检测准确率和低误报率，并展现了优于传统方法的鲁棒性和泛化能力，为物联网网络安全提供了可扩展的解决方案。

> **摘要翻译:** 地址解析协议（ARP）欺骗仍然是物联网网络面临的关键威胁，攻击者可以利用ARP缺乏认证的弱点来拦截、修改或中断数据传输。物联网环境的去中心化和资源受限特性加剧了这种漏洞，使得传统检测机制在大规模应用中失效。本论文引入了一种智能、多层机器学习框架，旨在实时物联网部署中检测ARP欺骗。我们的方法结合了基于ARP头部行为、流量分析和时间数据包异常的特征工程，以及包含决策树、集成模型和深度学习分类器的混合检测管道。我们提出了一种分层架构，优先在边缘网关使用轻量级模型，在中心化节点使用更深层模型，以平衡检测精度和计算效率。该系统在模拟物联网流量和CICIDS2017数据集上进行了验证，实现了超过97%的检测准确率和低误报率。与基于签名和基于规则的系统进行比较评估，证明了我们方法的鲁棒性和泛化能力。我们的结果表明，智能机器学习集成能够为物联网场景量身定制主动的ARP欺骗检测，为可扩展和自主的网络安全解决方案奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [485] [The Discovery, Disclosure, and Investigation of CVE-2024-25825](https://arxiv.org/abs/2507.21092)
> *CVE-2024-25825 的发现、披露与调查*

*Hunter Chasens* | **Category: cs.CR, D.4.6; K.6.5** | **Updated: 2025-06-26**

**Keywords:** CVE-2024-25825, FydeOS, 默认凭证, 国家行为者, 负责任披露

**Comment:** 97 pages, BSc thesis

> **TL;DR:** 本文详细介绍了 FydeOS 中 CVE-2024-25825 漏洞的发现、披露以及与国家行为者关联的进一步调查，该漏洞属于默认凭证问题。

**AI_Comments:** 本文揭示了一个关键的安全漏洞，并深入探讨了其可能与国家行为者关联的引人入胜的方面，这在网络安全领域是一个重大的担忧。它还提出了关于在怀疑代码被投毒时负责任披露实践的重要讨论点，挑战了传统智慧。漏洞的具体技术细节（/etc/shadow 中的通配符）被清晰地阐述。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在描述 CVE-2024-25825 漏洞的发现、披露及其与国家行为者之间联系的进一步调查。

**Method:** 本文描述了 FydeOS 中发现的 CVE-2024-25825 漏洞，该漏洞是 CWE-1392、CWE-1393 和 CWE-258 的组合，具体表现为 /etc/shadow 配置文件中 root 用户条目包含通配符，允许使用任何密码或无密码进入。在负责任的披露后，作者通知了 Fyde、CISA 和 Mitre，并对该漏洞是否可能被国家行为者故意植入进行了进一步调查。

**Result:** CVE-2024-25825 漏洞在 FydeOS 中被发现，具体是 /etc/shadow 文件中 root 用户的条目包含通配符，允许使用任何密码或无密码登录。Fyde 在被告知前已了解此漏洞。经过进一步调查，该漏洞不太可能是由国家行为者故意植入的。

**Conclusion:** 调查结论认为该漏洞不太可能是由国家行为者故意植入的。论文还提出，在怀疑存在投毒代码的情况下，联系适当的 CERT 机构可能比联系母公司更谨慎，尽管这与负责任披露的典型教义相冲突。

> **ai_Abstract:** 本文详细阐述了 FydeOS 中 CVE-2024-25825 漏洞的发现、披露及相关调查。该漏洞属于默认凭证问题（CWE-1392, CWE-1393, CWE-258），具体表现为 /etc/shadow 文件中 root 用户条目存在通配符，允许任意或无密码登录。论文描述了向 Fyde、CISA 和 Mitre 进行负责任披露的过程，并深入调查了该漏洞是否与国家行为者有关。最终调查结果表明，该漏洞不太可能是故意植入的。论文还探讨了在怀疑代码被投毒时，应联系 CERT 而非公司本身的做法，这与传统负责任披露原则有所冲突。

> **摘要翻译:** CVE-2024-25825 是在 FydeOS 中发现的一个漏洞。本论文描述了它的发现、披露以及与国家行为者相关的进一步调查。该漏洞是 CWE-1392：使用默认凭证、CWE-1393：使用默认密码和 CWE-258：配置文件中的空密码，这些问题存在于 /etc/shadow 配置文件中。/etc/shadow 文件中 root 用户的条目包含一个通配符，允许使用任何密码或无密码进入。在负责任的披露之后，Fyde、CISA 和 Mitre 都被告知了。Fyde 已经意识到了这个漏洞。有人担心这个漏洞可能被故意放置，也许是由国家行为者放置的。经过进一步调查，似乎不太可能是这种情况。在怀疑存在投毒代码的情况下，联系适当的 CERT 机构可能比联系母公司更谨慎。然而，这与负责任披露的典型教义相冲突。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [493] [SkyEye: When Your Vision Reaches Beyond IAM Boundary Scope in AWS Cloud](https://arxiv.org/abs/2507.21094)
> *SkyEye：当您的视野超越AWS云中IAM边界范围时*

*Minh Hoang Nguyen, Anh Minh Ho, Bao Son To* | **Category: cs.CR** | **Updated: 2025-07-01**

**Keywords:** AWS, IAM, 云安全, 枚举, SkyEye

**Comment:** 

> **TL;DR:** 本文介绍了SkyEye，一个合作多主体IAM枚举框架，旨在通过超越主体特定IAM权限的限制，提供AWS云环境中IAM配置的全面态势感知。

**AI_Comments:** SkyEye的创新之处在于其合作多主体IAM枚举框架，旨在突破传统主体特定权限视图的限制，提供更全面的IAM态势感知。这对于在复杂AWS云环境中管理安全和合规性至关重要，特别是在授权不足可能限制可见性的情况下。该方法有望帮助企业更好地识别和缓解潜在的安全风险。

<details>
  <summary>Details</summary>

**Motivation:** 随着企业将基础设施和应用迁移到云端以降低成本和提高效率，云安全成为主要关注点。尤其在AWS环境中，身份和访问管理（IAM）是关键安全支柱。由于应用扩展和数据存储，需要对IAM配置进行彻底、系统和精确的枚举，以识别错误配置、减少未经授权的权限升级风险并保持合规性。传统的IAM权限视图可能不足以提供完整的态势感知，而授权不足是主要挑战。

**Method:** 本文提出了SkyEye，一个合作多主体IAM枚举框架。该框架包含尖端的枚举模型，旨在支持对所提供AWS凭证的IAM进行完整的态势感知，并能够超越主体特定的IAM权限范围，揭示完整的可见性，尽管授权不足是主要挑战。

**Result:** 本文提出了SkyEye框架，旨在通过提供IAM的完整态势感知来解决现有挑战，但摘要中未提及具体实验结果。

**Conclusion:** 本文提出SkyEye框架，旨在解决AWS云环境中IAM配置全面态势感知的挑战，特别是超越主体特定权限范围的局限性，以帮助安全专业人员识别错误配置、降低风险并保持合规性。

> **ai_Abstract:** 本文针对云安全日益增长的挑战，特别是AWS环境中身份和访问管理（IAM）的复杂性，提出了一种名为SkyEye的合作多主体IAM枚举框架。该框架旨在通过先进的枚举模型，为安全专业人员提供超越传统主体特定权限范围的IAM配置全面态势感知，从而帮助识别错误配置、降低权限升级风险并确保合规性，尤其是在授权不足的挑战下。

> **摘要翻译:** 近年来，由于企业将内部基础设施和应用程序迁移到云环境的趋势日益增长，云安全已成为企业关注的主要问题。这种转变是为了降低与传统本地基础设施相关的高成本和维护费用。通过利用高可用性和可扩展性等云能力，公司可以实现更高的运营效率和灵活性。然而，这种迁移也带来了新的安全挑战。确保敏感数据保护、维护法规遵从性以及减轻网络威胁风险是必须解决的关键问题。身份和访问管理（IAM）构成了大多数云部署（尤其是在AWS环境中）的关键安全支柱。随着组织采用AWS来扩展应用程序和存储数据，对IAM配置进行彻底、系统和精确枚举的需求呈指数级增长。枚举是指对身份、权限和资源授权进行系统映射和询问，以获取态势感知。通过了解用户、组及其无数策略（无论是内联策略还是附加的托管策略）之间的相互作用，安全专业人员需要枚举并识别错误配置，降低未经授权的权限升级风险，并保持强大的合规性姿态。本文将介绍SkyEye，一个合作多主体IAM枚举框架，它包含尖端枚举模型，支持对所提供的AWS凭证的IAM进行完整的态势感知，突破了主体特定IAM权限视图的界限，揭示了完整的可见性，尽管授权不足是主要挑战。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [506] [Singularity Cipher: A Topology-Driven Cryptographic Scheme Based on Visual Paradox and Klein Bottle Illusions](https://arxiv.org/abs/2507.21097)
> *奇点密码：一种基于视觉悖论和克莱因瓶错觉的拓扑驱动密码方案*

*Abraham Itzhak Weinberg* | **Category: cs.CR** | **Updated: 2025-07-02**

**Keywords:** 奇点密码, 拓扑学, 视觉悖论, 克莱因瓶, 隐写术

**Comment:** 

> **TL;DR:** 奇点密码是一种结合拓扑变换和视觉错觉的新型加解密隐写框架，通过模拟克莱因瓶的非定向性实现符号加密，并利用视觉错觉隐藏加密内容，增强了加密强度和检测抵抗性。

**AI_Comments:** 该论文提出了一个极具创新性的密码学方法，将抽象的拓扑学概念（如克莱因瓶和莫比乌斯带的非定向性）与视觉心理学（感知错觉）相结合，创造出一种独特的双层加密-隐写方案。其创新点在于不依赖传统的代数复杂性，而是利用拓扑变换实现高混淆扩散，并借助视觉悖论提供隐写功能，增强了检测抵抗性。这种跨学科的方法为密码学和隐写术领域带来了新的视角和可能性，特别是在需要高度隐蔽性和抗检测性的应用场景中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的密码方案仅依赖代数复杂性，而奇点密码旨在通过引入基于拓扑学的符号加密和利用人类认知模糊性的视觉隐写术，提供一种双层方法，以增强加密强度和检测抵抗性，适用于安全通信、水印和对抗环境中的合理否认。

**Method:** 奇点密码将拓扑变换和视觉悖论相结合。它受克莱因瓶非定向性启发，应用符号扭曲函数模拟拓扑遍历，产生高混淆和扩散的密文。然后，使用缺失方块悖论等感知错觉对二进制数据进行编码，以视觉方式模糊加密内容的存在。该方案引入了双层方法：基于拓扑的符号加密和用于人类认知模糊性的视觉隐写术。

**Result:** 奇点密码增强了加密强度和检测抵抗性，使其非常适用于安全通信、水印和对抗环境中的合理否认。该论文形式化了其架构，提供了加密和解密算法，评估了安全属性，并将其方法与经典、后量子和隐写方法进行了比较。

**Conclusion:** 奇点密码通过结合拓扑学和视觉隐写术，提供了一种新颖且强大的加密-隐写框架，克服了传统密码学仅依赖代数复杂性的局限性，显著增强了安全性和检测抵抗性。

> **ai_Abstract:** 奇点密码是一种新颖的密码-隐写框架，它结合了拓扑变换和视觉悖论，以实现多维安全。该方案受克莱因瓶非定向性启发，利用符号扭曲函数进行拓扑遍历，产生高混淆和扩散的密文。加密后的数据通过视觉错觉（如缺失方块悖论）进行编码，以视觉方式隐藏内容。与传统密码不同，奇点密码采用双层方法：基于拓扑的符号加密和利用人类认知模糊性的视觉隐写术，从而增强了加密强度和检测抵抗性，适用于安全通信和水印等应用。

> **摘要翻译:** 本文提出奇点密码，一种新颖的密码-隐写框架，该框架整合了拓扑变换和视觉悖论，以实现多维安全。受克莱因瓶（由两个莫比乌斯带构成）的非定向特性启发，该密码应用符号扭曲函数模拟拓扑遍历，在密文中产生高混淆和扩散。然后，利用感知错觉，如缺失方块悖论，对生成的二进制数据进行编码，以视觉方式模糊加密内容的存在。与仅依赖代数复杂性的传统密码不同，奇点密码引入了一种双层方法：根植于拓扑学的符号加密和为人类认知模糊性设计的视觉隐写术。这种组合增强了密码强度和检测抵抗性，使其非常适用于安全通信、水印和对抗环境中的合理否认。本文形式化了其架构，提供了加密和解密算法，评估了安全属性，并将其方法与经典、后量子和隐写方法进行了比较。文中还讨论了潜在应用和未来的研究方向。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [509] [SoK: A Systematic Review of Context- and Behavior-Aware Adaptive Authentication in Mobile Environments](https://arxiv.org/abs/2507.21101)
> *SoK: 移动环境中上下文和行为感知自适应认证的系统综述*

*Vyoma Harshitha Podapati, Divyansh Nigam, Sanchari Das* | **Category: cs.CR** | **Updated: 2025-07-06**

**Keywords:** 自适应认证, 移动环境, 机器学习, 异常检测, 系统综述

**Comment:** 

> **TL;DR:** 该SoK系统综述了移动环境中上下文和行为感知的自适应认证，发现机器学习、异常检测和时空分析是主流技术。

**AI_Comments:** 这篇SoK具有重要意义，因为它系统地梳理了移动环境中自适应认证的研究现状，揭示了机器学习在其中的主导作用。它指出了现有实现碎片化和未能满足用户期望的问题，为未来的研究方向提供了清晰的洞察。其创新之处在于对41篇研究的七个维度分析，提供了全面的视角。

<details>
  <summary>Details</summary>

**Motivation:** 随着移动计算成为数字交互的核心，自适应认证因其实时、上下文和行为感知的验证能力受到关注。然而，现有实现存在碎片化、智能技术应用不一致且未能满足用户期望的问题。

**Method:** 本知识系统化（SoK）分析了自2011年以来41项关于移动环境中自适应认证的同行评审研究。分析涵盖七个维度：隐私和安全模型、交互方式、用户行为、风险感知、实现挑战、可用性需求和机器学习框架。

**Result:** 研究发现，该领域强烈依赖机器学习（64.3%），尤其用于连续认证（61.9%）和防止未经授权访问（54.8%）。AI驱动的方法如异常检测（57.1%）和时空分析（52.4%）以及基于传感器和位置感知的模型正日益塑造交互格局。

**Conclusion:** 移动环境中的自适应认证高度依赖机器学习，尤其是AI驱动的异常检测和时空分析方法。

> **ai_Abstract:** 本知识系统化（SoK）对自2011年以来41项关于移动环境中上下文和行为感知自适应认证的同行评审研究进行了系统分析。研究发现，该领域高度依赖机器学习（64.3%），特别是用于连续认证和防止未经授权访问。AI驱动的异常检测和时空分析方法以及基于传感器和位置感知的模型是主流技术，反映了该领域不断演进的交互格局。

> **摘要翻译:** 随着移动计算成为数字交互的核心，研究人员已将注意力转向自适应认证，因其具备实时、上下文和行为感知的验证能力。然而，许多实现仍然碎片化，智能技术应用不一致，并且未能达到用户期望。在本知识系统化（SoK）中，我们分析了自2011年以来41项关于移动环境中自适应认证的同行评审研究。我们的分析涵盖了七个维度：隐私和安全模型、交互方式、用户行为、风险感知、实现挑战、可用性需求和机器学习框架。我们的发现揭示了对机器学习的强烈依赖（64.3%），特别是用于连续认证（61.9%）和防止未经授权访问（54.8%）。人工智能驱动的方法，如异常检测（57.1%）和时空分析（52.4%），正日益塑造交互格局，同时基于传感器和位置感知的模型的使用也在增长。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [512] [PRISM: Programmatic Reasoning with Image Sequence Manipulation for LVLM Jailbreaking](https://arxiv.org/abs/2507.21540)
> *PRISM：基于图像序列操作的程序化推理用于LVLM越狱*

*Quanchen Zou, Zonghao Ying, Moyang Chen, Wenzhuo Xu, Yisong Xiao, Yakai Li, Deyue Zhang, Dongdong Yang, Zhao Liu, Xiangzheng Zhang* | **Category: cs.CR, cs.CV** | **Updated: 2025-07-29**

**Keywords:** LVLM越狱, 对抗性攻击, 视觉-语言模型, 程序化推理, ROP, 安全漏洞

**Comment:** 

> **TL;DR:** PRISM是一种新的LVLM越狱框架，它将恶意指令分解为一系列良性视觉组件，通过引导LVLM进行多步推理来生成有害输出，有效规避了现有安全防御。

**AI_Comments:** 该研究提出了一种新颖的LVLM越狱方法，其创新点在于借鉴了软件安全领域的ROP技术，将恶意意图隐藏在多步推理的组合过程中，使得攻击难以被单一组件检测。这揭示了LVLM安全防御的一个深层漏洞，即现有防御可能未能充分考虑模型在复杂推理过程中的信息整合方式。这项工作的重要性在于，它不仅提供了一种高效的攻击手段，更重要的是，它指出了未来LVLM安全研究和防御建设的关键方向——需要关注并保护模型整个推理链条的安全性，而不仅仅是输入或输出层面的过滤。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型视觉-语言模型（LVLMs）的安全对齐机制日益先进，但它们仍然容易受到复杂的对抗性攻击。现有的越狱方法通常依赖于直接且语义明确的提示，而忽略了LVLMs在多步推理中组合信息的微妙漏洞。

**Method:** 提出了一种名为PRISM的新型越狱框架，灵感来源于软件安全中的面向返回编程（ROP）技术。该方法将有害指令分解为一系列单独无害的视觉“小工具”，并通过精心设计的文本提示引导输入序列，促使模型通过其推理过程整合这些良性视觉小工具，从而产生连贯且有害的输出。这种恶意意图是“涌现”的，难以从任何单一组件中检测。

**Result:** 在SafeBench和MM-SafetyBench等既定基准上对流行LVLM进行了广泛实验验证。结果表明，该方法在最先进的模型上始终如一地显著优于现有基线，实现了接近完美的攻击成功率（SafeBench上超过0.90），并将攻击成功率提高了高达0.39。

**Conclusion:** 研究结果揭示了一个关键且未充分探索的漏洞，该漏洞利用了LVLM的组合推理能力，强调了迫切需要保护整个推理过程的防御措施。

> **ai_Abstract:** 本文提出了一种名为PRISM的新型LVLM越狱框架，灵感来源于软件安全中的ROP技术。该方法通过将有害指令分解为一系列单独无害的视觉元素，并利用文本提示引导LVLM进行多步推理，使其整合这些元素以生成有害输出，从而规避现有安全防御。实验结果表明，PRISM在主流基准测试中显著优于现有方法，实现了高攻击成功率，揭示了LVLM在组合推理方面的关键漏洞，并强调了加强整个推理过程防御的必要性。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）日益复杂，随之而来的是旨在防止有害内容生成的安全对齐机制的进步。然而，这些防御措施仍然容易受到复杂的对抗性攻击。现有越狱方法通常依赖于直接和语义明确的提示，忽略了LVLMs在多个推理步骤中组合信息的微妙漏洞。在本文中，我们提出了一种受软件安全中面向返回编程（ROP）技术启发的、新颖且有效的越狱框架。我们的方法将有害指令分解为一系列单独无害的视觉“小工具”。精心设计的文本提示引导输入序列，促使模型通过其推理过程整合这些良性视觉小工具，从而产生连贯且有害的输出。这使得恶意意图是“涌现”的，并且难以从任何单一组件中检测出来。我们通过在SafeBench和MM-SafetyBench等既定基准上针对流行LVLM进行广泛实验验证了我们的方法。结果表明，我们的方法在最先进的模型上始终如一地显著优于现有基线，实现了接近完美的攻击成功率（SafeBench上超过0.90），并将攻击成功率提高了高达0.39。我们的发现揭示了一个关键且未充分探索的漏洞，该漏洞利用了LVLM的组合推理能力，强调了迫切需要保护整个推理过程的防御措施。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [519] [A Formal Rebuttal of "The Blockchain Trilemma: A Formal Proof of the Inherent Trade-Offs Among Decentralization, Security, and Scalability"](https://arxiv.org/abs/2507.21111)
> *《区块链三难困境：去中心化、安全性与可扩展性之间固有权衡的正式证明》的正式驳斥*

*Craig Wright* | **Category: cs.CR, cs.AI, cs.DC, cs.GT, cs.SE, 68M14, 68P25, 68T30, 94A60, 18C10, D.4.6; K.6.5; C.2.1; H.3.5; D.2.11** | **Updated: 2025-07-10**

**Keywords:** 区块链三难困境, 去中心化, 可扩展性, 形式驳斥, 比特币

**Comment:** 79 pages; A response and rebuttal of [Mssassi, Souhail, and Anas Abou
  El Kalam. "The Blockchain Trilemma: A Formal Proof of the Inherent Trade-Offs
  Among Decentralization, Security, and Scalability." Applied Sciences 15, no.
  1 (2024): 19. https://doi.org/10.3390/app15010019.]

> **TL;DR:** 本文正式驳斥了广为流传但缺乏形式依据的“区块链三难困境”理论，指出该理论基于语义含糊、误用分布式系统理论和缺乏操作指标定义，并通过对比特币的重新解读，证明可扩展性是工程结果而非权衡，并批评了学术界的问题。

**AI_Comments:** 这篇论文具有重要的创新性，它直接挑战了区块链领域一个被广泛接受但未经验证的理论——“区块链三难困境”。通过严谨的形式分析和对现有概念的重新定义，它可能改变人们对区块链可扩展性的认知，并促使学术界对理论基础进行更严格的审视。论文对学术讨论和同行评审机制的批判也具有重要的警示意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在驳斥广为引用但缺乏正式依据的“区块链三难困境”理论，该理论声称区块链协议中去中心化、安全性与可扩展性之间存在固有的权衡。

**Method:** 本文通过形式分析、经验证据以及对方法论和术语的详细批判来驳斥“区块链三难困境”。具体方法包括：指出其语义含糊、误用分布式系统理论、未能定义操作指标，并重点关注拓扑网络类比与协议级架构的混淆、对比特币设计的错误描述，以及未能将主张建立在复杂性理论或对抗模型上。通过将比特币重构为由证据信任管理的确定性、无状态分发协议。

**Result:** 研究结果表明，“区块链三难困境”理论建立在语义含糊、对分布式系统理论的误用以及未能定义操作指标的基础上。具体而言，该理论混淆了拓扑网络类比与协议级架构，错误描述了比特币的设计，且未能将主张建立在复杂性理论或对抗模型上。通过重新构建比特币，本文证明可扩展性并非权衡，而是一种工程结果。

**Conclusion:** 本文得出结论，指出了学术讨论和同行评审中允许此类谬误持续存在的系统性问题，并为评估未来区块链研究中的主张提供了正式标准。

> **ai_Abstract:** 本文正式驳斥了流行的“区块链三难困境”理论，该理论声称去中心化、安全性与可扩展性之间存在固有权衡。作者通过形式分析、经验证据和详细批判，指出该理论基于语义混淆、分布式系统理论的误用及缺乏操作定义。论文特别澄清了对比特币的误解，并论证可扩展性是工程设计而非权衡。最后，本文批评了学术界中导致此类谬误持续存在的问题，并提出了评估未来区块链研究主张的标准。

> **摘要翻译:** 本文对所谓的“区块链三难困境”进行了全面驳斥，该理论被广泛引用，但形式上缺乏依据，声称区块链协议中去中心化、安全性与可扩展性之间存在固有的权衡。通过形式分析、经验证据以及对方法论和术语的详细批判，我们证明该三难困境基于语义含糊、对分布式系统理论的误用以及未能定义操作指标。本文特别关注了拓扑网络类比与协议级架构的混淆、对比特币设计的错误描述——包括矿工、SPV客户端和基于区块头的验证的作用——以及未能将主张建立在复杂性理论或对抗模型上。通过将比特币重构为由证据信任管理的确定性、无状态分发协议，我们表明可扩展性并非权衡，而是一种工程结果。论文最后指出了学术讨论和同行评审中允许此类谬误持续存在的系统性问题，并为评估未来区块链研究中的主张提供了正式标准。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [520] [HexaMorphHash HMH- Homomorphic Hashing for Secure and Efficient Cryptographic Operations in Data Integrity Verification](https://arxiv.org/abs/2507.21096)
> *六边形同态哈希HMH——用于数据完整性验证中安全高效密码操作的同态哈希*

*Krishnendu Das* | **Category: cs.CR, cs.DB** | **Updated: 2025-07-01**

**Keywords:** 同态哈希, 数据完整性, 分布式系统, 格密码学, 量子安全

**Comment:** 

> **TL;DR:** 针对分布式系统中现有哈希方法在动态环境下的局限性，本文提出了一种基于格的同态哈希函数HexaMorphHash，实现了常数时间增量更新、常数摘要大小，并提高了计算效率、内存使用和可伸缩性。

**AI_Comments:** 这篇论文通过引入基于格的同态哈希函数HexaMorphHash，在数据完整性验证领域展现了显著的创新性。其核心优势在于实现了常数时间增量更新和常数摘要大小，这对于高动态、高更新频率的分布式系统至关重要。此外，利用SIS问题的复杂性使其具备抗量子威胁能力，增强了其在未来密码学环境中的重要性。该研究解决了传统和一致性哈希在可伸缩性和负载均衡方面的局限，为大数据和云计算环境下的安全高效操作提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在大数据和云计算的分布式系统中，传统哈希方法在动态环境下（节点改变时需要彻底重新哈希）效率低下；一致性哈希虽有所缓解，但在高强度更新条件下仍存在负载均衡和可伸缩性问题。

**Method:** 提出了一种创新的基于格的同态哈希函数HexaMorphHash，利用短整数解（SIS）问题的复杂性，实现常数时间增量更新并保持常数摘要大小，同时对抗量子威胁。

**Result:** 与现有方法（如直接签名、全面数据库签名、Merkle树、AdHash、MuHash、ECMH和同态签名方案）相比，HexaMorphHash在计算效率、内存使用和可伸缩性方面有显著提升。

**Conclusion:** HexaMorphHash为大型分布式系统中频繁更新传播提供了一个可行的解决方案，确保了数据完整性和系统性能。

> **ai_Abstract:** 本文提出了一种名为HexaMorphHash（HMH）的创新型同态哈希函数，旨在解决分布式系统中现有哈希方法在动态环境和高更新频率下数据完整性验证的效率和可伸缩性问题。HMH基于格理论和短整数解（SIS）问题，实现了常数时间增量更新和常数摘要大小，并具备抗量子威胁能力。实验比较表明，HMH在计算效率、内存使用和可伸缩性方面优于多种现有技术，为大规模分布式系统中的数据完整性维护提供了有效方案。

> **摘要翻译:** 在大数据和云计算领域，分布式系统需要有效地管理、存储和验证跨多个节点的庞大数据集，同时保持强大的数据完整性。传统的哈希方法虽然简单，但在动态环境中遇到了实质性的困难，因为当节点改变时需要彻底重新哈希。一致性哈希通过减少数据重新分配来缓解其中一些挑战；然而，在高强度更新条件下，它仍然面临负载均衡和可伸缩性的限制。本文介绍了一种创新的方法，使用基于格的同态哈希函数HexaMorphHash，该函数在保持常数摘要大小的同时，能够实现常数时间的增量更新。通过利用短整数解（SIS）问题的复杂性，我们的方法确保了强大的保护措施，甚至可以抵御量子威胁。我们进一步将我们的方法与现有方法进行了比较，例如每次更新的直接签名、全面数据库签名、基于Merkle树的技术、AdHash、MuHash、ECMH和同态签名方案，突出了在计算效率、内存使用和可伸缩性方面的显著进步。我们的贡献为大型分布式系统中频繁更新的传播提供了一个可行的解决方案，同时保障了数据完整性和系统性能。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [527] [Vulnerability Mitigation System (VMS): LLM Agent and Evaluation Framework for Autonomous Penetration Testing](https://arxiv.org/abs/2507.21113)
> *漏洞缓解系统（VMS）：用于自主渗透测试的LLM代理和评估框架*

*Farzana Abdulzada* | **Category: cs.CR** | **Updated: 2025-07-14**

**Keywords:** LLM代理, 渗透测试, 漏洞缓解系统, 网络安全, CTF基准

**Comment:** 

> **TL;DR:** 本文提出了漏洞缓解系统（VMS），一个基于大型语言模型（LLM）的自主渗透测试代理，并设计了新的CTF基准来评估其在复杂网络威胁下的有效性。

**AI_Comments:** 这篇论文的创新点在于提出了一个基于LLM的自主渗透测试系统，并构建了专门的评估基准，这对于推动LLM在网络安全领域的实际应用具有重要意义。其贡献在于将LLM的能力扩展到复杂的渗透测试任务，并提供了可重复的评估方法。未来研究可以探索如何进一步提升LLM在识别和利用新型漏洞方面的能力，以及如何应对更高级的对抗性攻击。

<details>
  <summary>Details</summary>

**Motivation:** 传统的渗透测试难以适应日益复杂的网络环境和不断增加的网络威胁，需要一种无需人工干预的自主渗透测试系统来解决这一问题。

**Method:** 本文提出了一个基于大型语言模型（LLM）的漏洞缓解系统（VMS），该系统具有两部分架构（规划和摘要器）用于生成命令和处理反馈。为了标准化和评估系统功能，作者设计了两个包含200个挑战的新型夺旗赛（CTF）基准，这些基准基于PicoCTF和OverTheWire平台。实验中使用了不同的LLM，并调整了温度和top-p参数，同时在容器化环境中确保安全操作。

**Result:** 实验结果表明，在各种LLM中，GPT-4o的表现最佳，有时甚至超出预期。研究发现，大型语言模型可以有效地应用于许多网络安全任务。

**Conclusion:** 大型语言模型（LLM）可以有效应用于网络安全任务，但操作中存在风险，需要确保在安全环境下运行。VMS及其评估基准的公开可用性有助于推动安全、自主网络安全工具的开发。

> **ai_Abstract:** 本文提出了一种名为漏洞缓解系统（VMS）的新型LLM代理，旨在实现自主渗透测试，以应对传统方法在复杂网络威胁面前的不足。VMS采用两部分架构来生成命令和处理反馈。为评估其性能，作者开发了基于PicoCTF和OverTheWire的200个挑战的CTF基准。实验证明，GPT-4o表现优异，显示了LLM在网络安全任务中的潜力，同时强调了安全操作的重要性。VMS及其基准的公开有助于推动安全、自主网络安全工具的发展。

> **摘要翻译:** 随着网络威胁频率的增加，传统的渗透测试无法捕捉当今复杂环境的全部情况。为了解决这个问题，我们提出了漏洞缓解系统（VMS），这是一种基于大型语言模型（LLM）的新型代理，能够无需人工干预地执行渗透测试。VMS具有两部分架构，用于规划和摘要器，使其能够生成命令和处理反馈。为了标准化测试，我们设计了两个基于PicoCTF和OverTheWire平台的新型夺旗赛（CTF）基准，包含200个挑战。这些基准使我们能够评估系统功能的有效性。我们使用各种LLM进行了多次实验，同时调整了温度和top-p参数，发现GPT-4o表现最佳，有时甚至超出了预期。结果表明，LLM可以有效地应用于许多网络安全任务；但是，存在风险。为了确保安全操作，我们使用了容器化环境。VMS和基准都已公开可用，从而推动了安全、自主网络安全工具的创建。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [534] [Kintsugi: Decentralized E2EE Key Recovery](https://arxiv.org/abs/2507.21122)
> *Kintsugi: 去中心化端到端加密密钥恢复*

*Emilie Ma, Martin Kleppmann* | **Category: cs.CR** | **Updated: 2025-07-18**

**Keywords:** E2EE, 密钥恢复, 去中心化, 密码认证, 容错

**Comment:** 15 pages with 4 additional pages of workshop discussion transcript.
  To be published in the proceedings of the Twenty-ninth International Workshop
  on Security Protocols

> **TL;DR:** Kintsugi是一个去中心化的协议，允许用户在丢失设备后通过密码恢复端到端加密数据，而无需依赖中心化服务器。

**AI_Comments:** Kintsugi的创新在于其去中心化的密钥恢复机制，通过分布式信任解决了传统E2EE恢复方案的中心化信任风险。它在不依赖昂贵硬件的情况下提供了强大的安全保障，尤其是在抵抗离线暴力破解和容错性方面表现出色。这对于提升E2EE系统的可用性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有端到端加密（E2EE）密钥恢复方法（如Signal和WhatsApp）通过依赖单一提供商管理的服务器来中心化信任，存在单点故障和信任问题。

**Method:** Kintsugi是一种去中心化协议，通过将信任分布在多个恢复节点上实现密钥恢复，这些节点可以是独立服务器或P2P设备。用户需要$t+1$个恢复节点协助解密共享备份。该协议是密码认证的，无需专用安全硬件即可防止离线暴力破解密码猜测。

**Result:** Kintsugi可以容忍最多$t$个诚实但好奇的串通恢复节点以及$n-t-1$个离线节点，并在消息可能任意延迟的异步网络模型中安全运行。

**Conclusion:** Kintsugi提供了一种去中心化、安全且容错的E2EE密钥恢复方案，解决了现有中心化方法的信任集中化问题，并能抵抗多种攻击和故障模式。

> **ai_Abstract:** Kintsugi是一个去中心化的端到端加密(E2EE)密钥恢复协议。它旨在解决现有中心化恢复方案中信任集中化的问题，允许用户在丢失设备后，仅凭密码即可恢复加密数据。该协议通过将信任分散到多个恢复节点（可以是独立服务器或P2P设备）来实现去中心化，并要求达到$t+1$的节点阈值才能协助用户解密备份。Kintsugi采用密码认证，能有效防御离线暴力破解，且无需专用安全硬件。它还具备高容错性，可应对部分恶意或离线节点，并在异步网络环境中安全运行。

> **摘要翻译:** Kintsugi是一种密钥恢复协议，允许用户在丢失设备后仍能通过其（可能低熵的）密码重新访问端到端加密数据。现有的E2EE密钥恢复方法，例如Signal和WhatsApp部署的那些，通过依赖由单一提供商管理的服务器来集中信任。Kintsugi是去中心化的，将信任分布在多个恢复节点上，这些节点可以是独立方运行的服务器，也可以是点对点设置中的最终用户设备。为了恢复用户的密钥，需要$t+1$个恢复节点的阈值来协助用户解密共享备份。Kintsugi是密码认证的，无需任何专门的安全硬件即可防止离线暴力破解密码猜测。Kintsugi可以容忍最多$t$个诚实但好奇的串通恢复节点，以及$n-t-1$个离线节点，并且可以在消息可能任意延迟的异步网络模型中安全运行。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [540] [Security study based on the Chatgptplugin system: ldentifying Security Vulnerabilities](https://arxiv.org/abs/2507.21128)
> *基于ChatGPT插件系统的安全研究：识别安全漏洞*

*Ruomai Ren* | **Category: cs.CR, cs.SE** | **Updated: 2025-07-21**

**Keywords:** ChatGPT, 插件系统, 安全漏洞, 安全研究, 漏洞识别

**Comment:** Master's thesis

> **TL;DR:** 本研究旨在分析ChatGPT插件系统的安全性，识别其主要安全漏洞并提出改进措施，以应对当前研究对插件系统安全关注不足的问题。

**AI_Comments:** 该研究及时且重要，填补了ChatGPT插件系统安全研究的空白，对促进插件生态的健康发展具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 插件系统虽然增强用户体验，但其安全性始终是挑战，尤其在ChatGPT插件系统快速发展且缺乏监管的背景下。现有研究多关注ChatGPT模型本身安全，忽视插件系统带来的安全风险。

**Method:** 分析ChatGPT插件商店中插件的安全性，揭示其主要安全漏洞。

**Result:** 揭示了ChatGPT插件系统中的主要安全漏洞。

**Conclusion:** 识别出ChatGPT插件系统的主要安全漏洞，并需要提出相应的改进措施以增强其安全性。

> **ai_Abstract:** 本研究关注ChatGPT插件系统的安全问题，指出插件系统在提供便利的同时存在安全挑战和监管不足。鉴于当前研究主要集中在ChatGPT模型本身，本研究旨在分析ChatGPT插件商店中的插件安全，识别主要漏洞并提出改进措施，以填补现有研究空白。

> **摘要翻译:** 插件系统是一类外部程序，为用户提供广泛的功能。虽然它们增强了用户体验，但其安全性始终是一个挑战。特别是由于开发者的多样性和复杂性，许多插件系统缺乏足够的监管。随着ChatGPT成为一个流行的大型语言模型平台，其插件系统也正在逐步发展，开放平台为创作者提供了上传涵盖广泛应用场景插件的机会。然而，当前的研究和讨论大多集中在ChatGPT模型本身的安全问题上，而忽视了插件系统可能带来的安全风险。本研究旨在分析ChatGPT插件商店中插件的安全性，揭示其主要安全漏洞，并提出相应的改进建议。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [555] [Analysis of Threat-Based Manipulation in Large Language Models: A Dual Perspective on Vulnerabilities and Performance Enhancement Opportunities](https://arxiv.org/abs/2507.21133)
> *大语言模型中基于威胁的操纵分析：漏洞与性能增强机会的双重视角*

*Atil Samancioglu* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-22**

**Keywords:** 大语言模型, 威胁操纵, 漏洞, 性能增强, 提示工程

**Comment:** 

> **TL;DR:** 研究发现大型语言模型在面对基于威胁的操纵时，既存在系统性漏洞，也能带来显著的性能提升，对AI安全和实际提示工程有重要意义。

**AI_Comments:** 这篇论文的创新之处在于其双重视角，不仅关注LLMs的脆弱性，还发现了威胁操纵可能带来的性能提升机会，这为AI安全和提示工程提供了新的思考方向。研究规模大（3,390个响应，3个主流LLM），且引入了新颖的威胁分类和评估框架，使其结果具有较高的可信度和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）对基于威胁的操纵表现出复杂的响应，既揭示了漏洞，也展现出意想不到的性能增强机会。本研究旨在对这些现象进行全面分析。

**Method:** 本研究对来自三个主要LLMs（Claude、GPT-4、Gemini）在10个任务领域和6种威胁条件下的3,390个实验响应进行了全面分析。研究引入了一种新颖的威胁分类法和多指标评估框架，以量化负面操纵效应和正面性能改进。

**Result:** 结果揭示了系统性漏洞，其中策略评估在基于角色的威胁下显示出最高的指标显著性；同时在许多情况下性能显著增强，效果大小高达+1336%。统计分析表明存在系统性的确定性操纵（pFDR < 0.0001），并且分析深度和响应质量有显著改善。

**Conclusion:** 这些发现对AI安全和高风险应用中的实际提示工程具有双重影响。

> **ai_Abstract:** 本研究深入分析了大型语言模型（LLMs）在面对威胁性操纵时的行为，发现其既存在系统性漏洞，也展现出显著的性能提升潜力。通过对3,390个实验响应的评估，研究引入了新的威胁分类法和评估框架，量化了负面影响和正面改进。结果显示，LLMs在某些威胁下易受攻击，但同时在分析深度和响应质量上表现出惊人的提升。这些发现对提升AI安全性和优化高风险场景下的提示工程具有重要指导意义。

> **摘要翻译:** 大型语言模型（LLMs）对基于威胁的操纵表现出复杂的响应，揭示了漏洞和意想不到的性能增强机会。本研究对来自三个主要LLMs（Claude、GPT-4、Gemini）在10个任务领域和6种威胁条件下的3,390个实验响应进行了全面分析。我们引入了一种新颖的威胁分类法和多指标评估框架，以量化负面操纵效应和正面性能改进。结果揭示了系统性漏洞，其中策略评估在基于角色的威胁下显示出最高的指标显著性，同时在许多情况下性能显著增强，效果大小高达+1336%。统计分析表明存在系统性的确定性操纵（pFDR < 0.0001），并且分析深度和响应质量有显著改善。这些发现对AI安全和高风险应用中的实际提示工程具有双重影响。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [569] [Learning-based Privacy-Preserving Graph Publishing Against Sensitive Link Inference Attacks](https://arxiv.org/abs/2507.21139)
> *基于学习的隐私保护图发布以对抗敏感链接推断攻击*

*Yucheng Wu, Yuncong Yang, Xiao Han, Leye Wang, Junjie Wu* | **Category: cs.CR** | **Updated: 2025-07-23**

**Keywords:** 隐私保护, 图发布, 敏感链接推断, 图结构学习, 隐私-效用权衡

**Comment:** 

> **TL;DR:** 本文提出了PPGSL框架，这是首个基于学习的隐私保护图结构学习框架，旨在自动优化图发布中的隐私-效用权衡，以有效抵御敏感链接推断攻击。

**AI_Comments:** 本文的创新点在于提出了首个基于学习的隐私保护图结构学习框架，通过对抗性训练的方式自动寻找最优的隐私-效用权衡，而非依赖启发式规则，这为图数据隐私保护提供了一个新颖且有效的方法。

<details>
  <summary>Details</summary>

**Motivation:** 发布图数据虽然有利于结构分析和下游任务，但可能导致严重的隐私泄露，特别是攻击者可能利用发布的图数据精确推断敏感链接。现有隐私保护图发布方法依赖启发式图修改策略，难以确定具有最佳隐私-效用权衡的图。

**Method:** 本文提出了PPGSL（Privacy-Preserving Graph Structure Learning）框架，这是一个基于学习的隐私保护图结构学习框架。PPGSL通过首先模拟一个强大的替代攻击者对给定图进行敏感链接攻击，然后训练一个参数化图来防御这些模拟的对抗性攻击，同时保持原始图的有利效用。为了学习两部分的参数，引入了一种安全的迭代训练协议，该协议能增强隐私保护并确保训练过程中的稳定收敛。此外，还结合了多种加速技术以提高处理大规模图的效率。

**Result:** 实验结果证实，PPGSL实现了最先进的隐私-效用权衡性能，并有效阻止了各种敏感链接推断攻击。

**Conclusion:** PPGSL是首个针对敏感链接推断攻击的隐私保护图结构学习框架，它能够自动学习具有最优隐私-效用权衡的图，并通过理论证明和实验结果验证了其在隐私保护和效用保持方面的有效性。

> **ai_Abstract:** 本文提出了PPGSL，一个新颖的基于学习的隐私保护图结构学习框架，旨在解决图数据发布中敏感链接推断攻击导致的隐私泄露问题。与传统启发式方法不同，PPGSL通过模拟攻击者并训练参数化图来自动优化隐私-效用权衡。该框架采用安全迭代训练协议和加速技术，并在实验中证明了其在隐私保护和效用保持方面的优越性能。

> **摘要翻译:** 发布图数据广泛用于实现各种结构分析和下游任务。然而，它也可能带来严重的隐私泄露，因为攻击者可能利用发布的图数据发起攻击，精确推断私人信息，例如图中隐藏敏感链接的存在。先前关于隐私保护图数据发布的研究依赖于启发式图修改策略，并且难以确定具有最佳隐私-效用权衡的图进行发布。
相比之下，我们提出了第一个针对敏感链接推断攻击的隐私保护图结构学习框架，命名为PPGSL，它能够自动学习具有最佳隐私-效用权衡的图。PPGSL首先通过模拟一个强大的替代攻击者对给定图进行敏感链接攻击来操作。然后，它训练一个参数化图来防御模拟的对抗性攻击，同时保持原始图的有利效用。为了学习PPGSL两部分的参数，我们引入了一种安全的迭代训练协议。正如理论证明所支持的，它可以在训练过程中增强隐私保护并确保稳定的收敛。此外，我们结合了多种加速技术，以提高PPGSL在处理大规模图时的效率。实验结果证实PPGSL实现了最先进的隐私-效用权衡性能，并有效阻止了各种敏感链接推断攻击。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [577] [Hierarchical Graph Neural Network for Compressed Speech Steganalysis](https://arxiv.org/abs/2507.21591)
> *用于压缩语音隐写分析的层次图神经网络*

*Mustapha Hemis, Hamza Kheddar, Mohamed Chahine Ghanem, Bachir Boudraa* | **Category: cs.CR, cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-29**

**Keywords:** 图神经网络, 隐写分析, 语音, VoIP, GraphSAGE

**Comment:** 

> **TL;DR:** 本文首次将图神经网络（GNN），特别是GraphSAGE架构，应用于压缩VoIP语音流的隐写分析，实现了高检测精度和效率，特别适用于在线隐写分析任务。

**AI_Comments:** 本文的创新点在于首次将图神经网络（GraphSAGE）应用于压缩语音的隐写分析，有效解决了传统深度学习方法在计算复杂度和泛化能力上的不足。其在检测精度和效率上的显著提升，尤其是在短样本和低嵌入率条件下的优异表现，对在线隐写分析领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习（DL）的隐写分析方法常面临计算复杂度和跨数据集泛化能力差的问题。引入图神经网络（GNN）可以利用关系数据来提高检测精度和适应性。

**Method:** 本研究首次将图神经网络（GNN），具体为GraphSAGE架构，应用于压缩VoIP语音流的隐写分析。该方法涉及从VoIP流中直接构建图，并利用GraphSAGE捕获分层隐写分析信息，包括细粒度细节和高级模式。

**Result:** 实验结果表明，该方法在揭示VoIP信号中基于量化索引调制（QIM）的隐写模式方面表现良好。即使对于0.5秒的短样本，检测精度也超过98%；在低嵌入率的挑战性条件下，精度达到95.17%，比现有最佳方法提高了2.8%。此外，模型表现出卓越的效率，0.5秒样本的平均检测时间低至0.016秒，提高了0.003秒。

**Conclusion:** 该模型在检测精度和效率之间取得了优越的平衡，尤其适用于短样本和低嵌入率的在线隐写分析任务。

> **ai_Abstract:** 本论文提出了一种新颖的基于层次图神经网络（GNN），特别是GraphSAGE架构的压缩语音隐写分析方法。该方法首次将GNN应用于VoIP语音流，通过简单的图构建和GraphSAGE捕获分层信息，显著提高了检测精度和效率。实验证明，该方法在短样本和低嵌入率条件下，检测精度超过95%，并大幅缩短了检测时间，使其非常适合在线隐写分析。

> **摘要翻译:** 基于深度学习（DL）的隐写分析方法常面临计算复杂度和跨不同数据集泛化能力差的问题。将图神经网络（GNN）整合到隐写分析方案中，能够利用关系数据提高检测精度和适应性。本文首次将图神经网络（GNN），特别是GraphSAGE架构，应用于压缩IP语音（VoIP）语音流的隐写分析。该方法涉及从VoIP流中直接构建图，并采用GraphSAGE捕获分层隐写分析信息，包括细粒度细节和高级模式，从而实现高检测精度。实验结果表明，所开发的方法在揭示VoIP信号中基于量化索引调制（QIM）的隐写模式方面表现良好。即使对于0.5秒的短样本，其检测精度也超过98%；在低嵌入率的挑战性条件下，精度达到95.17%，比现有最佳方法提高了2.8%。此外，该模型表现出卓越的效率，0.5秒样本的平均检测时间低至0.016秒，提高了0.003秒。这使得它在在线隐写分析任务中效率很高，在短样本和低嵌入率的限制下，在检测精度和效率之间提供了卓越的平衡。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [583] [Privacy Artifact ConnecTor (PACT): Embedding Enterprise Artifacts for Compliance AI Agents](https://arxiv.org/abs/2507.21142)
> *隐私工件连接器（PACT）：嵌入企业工件以支持合规AI代理*

*Chenhao Fang, Yanqing Peng, Rajeev Rao, Matt Sarmiento, Wendy Summer, Arya Pudota, Alex Goncalves, Jordi Mola, Hervé Robert* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 隐私合规, 工件嵌入, 图神经网络, 企业数据, AI代理

**Comment:** 

> **TL;DR:** PACT是一个嵌入驱动的图，用于连接企业中分散的隐私相关工件，显著提高了合规AI代理的召回率和匹配率。

**AI_Comments:** PACT的创新之处在于它将分散的企业工件通过嵌入技术连接成一个统一的图结构，这对于大型企业进行隐私风险评估和合规性管理至关重要。其利用先进的DRAGON嵌入模型和对比学习进行微调，并在多项指标上取得了显著的性能提升，表明了该方法的有效性和实用性。这为构建更智能、更高效的合规AI代理提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 企业环境中评估隐私风险和确保法规遵从的关键信息分散在大量异构且快速增长的内部工件中，且发现和提取困难。因此，大规模隐私合规需要系统来识别不同工件之间的互联性。

**Method:** PACT是一个嵌入驱动的图，它连接了数百万个跨多种工件类型、由不同团队和项目生成的工件。它使用最先进的DRAGON嵌入模型，通过对比学习目标和轻量级微调，通过文本组件（如原始元数据、所有权细节和合规上下文）链接工件。

**Result:** PACT的微调模型将recall@1从18%提高到53%；与基线AI代理配对时，查询匹配率从9.6%提高到69.7%；在标准推荐系统中，候选选择的hitrate@1从25.7%提高到44.9%。

**Conclusion:** PACT通过其嵌入驱动的图和微调的DRAGON模型，显著提升了企业环境中隐私工件的连接和发现能力，从而有效支持大规模隐私合规AI代理。

> **ai_Abstract:** PACT是一个嵌入驱动的图系统，旨在解决企业环境中分散的隐私相关工件连接问题，以支持大规模隐私合规。它利用DRAGON嵌入模型和对比学习，通过文本组件链接数百万个工件，并在实验中显著提升了隐私AI代理的召回率、查询匹配率和推荐系统中的命中率。

> **摘要翻译:** 企业环境中包含大量异构、快速增长的内部工件集合，涉及代码、数据和许多不同的工具。评估隐私风险和确保法规遵从的关键信息通常嵌入在这些不同的资源中，每个资源都有其自身的神秘发现和提取技术。因此，遵守政府法规的大规模隐私合规需要系统来在一个共同、共享的宇宙中识别不同工件的互联性质。
我们提出了隐私工件连接器（PACT），这是一个嵌入驱动的图，它连接了跨多种工件类型、由各种团队和项目生成的数百万个工件。PACT由最先进的DRAGON嵌入模型提供支持，利用对比学习目标和轻量级微调，通过其文本组件（如原始元数据、所有权细节和合规上下文）链接工件。实验结果表明，PACT的微调模型将recall@1从18%提高到53%，与基线AI代理配对时，查询匹配率从9.6%提高到69.7%，在标准推荐系统中，候选选择的hitrate@1从25.7%提高到44.9%。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [605] [Leveraging Trustworthy AI for Automotive Security in Multi-Domain Operations: Towards a Responsive Human-AI Multi-Domain Task Force for Cyber Social Security](https://arxiv.org/abs/2507.21145)
> *利用可信人工智能提升多域作战中的汽车安全：迈向网络社会安全的响应式人机多域特遣部队*

*Vita Santa Barletta, Danilo Caivano, Gabriel Cellammare, Samuele del Vescovo, Annita Larissa Sciacovelli* | **Category: cs.CR** | **Updated: 2025-07-23**

**Keywords:** 可信人工智能, 汽车安全, 多域作战, 对抗性机器学习, 超参数

**Comment:** 13 pages, 6 figures, 1 table

> **TL;DR:** 本研究探讨了决策树集成模型（随机森林、梯度提升、极限梯度提升）的超参数如何影响黑盒对抗性机器学习（AML）攻击（零阶优化）所需的时间。研究发现，超参数如树的数量或提升轮次显著影响攻击执行时间，其中随机森林和梯度提升比极限梯度提升更敏感。通过优化超参数，本研究旨在支持防御性可信人工智能实践，以增强机器学习系统的韧性，应对多域作战中的网络社会安全挑战。

**AI_Comments:** 该论文关注在多域作战背景下，联网自动驾驶汽车面临的对抗性机器学习威胁，具有重要的现实意义。其创新之处在于从超参数角度分析攻击执行时间，为防御性可信AI的实现提供了具体指导。研究结果有助于提升ML系统的韧性，但更深入的防御策略和实际部署挑战可能需要进一步探讨。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探究决策树集成模型（随机森林、梯度提升、极限梯度提升）的关键超参数如何影响黑盒对抗性机器学习攻击（如零阶优化）所需的时间，以应对联网自动驾驶汽车在多域作战中面临的复杂且协同的威胁。

**Method:** 本研究通过分析决策树集成模型（随机森林、梯度提升、极限梯度提升）中诸如树的数量或提升轮次等关键超参数，来评估它们对黑盒对抗性机器学习攻击（零阶优化）执行时间的影响。同时，还分析了对抗性训练所需的时间，以评估攻击者的机会窗口。

**Result:** 研究结果表明，诸如树的数量或提升轮次等超参数显著影响攻击执行时间，其中随机森林和梯度提升模型比极限梯度提升模型对这些参数更为敏感。对抗性训练时间也得到了分析。

**Conclusion:** 通过优化超参数，本研究支持在多表面威胁场景中实践防御性可信人工智能，并有助于开发适用于民用和军事领域的弹性机器学习系统，以符合多域作战中的网络社会安全框架和人机多域特遣部队的需求。

> **ai_Abstract:** 本研究探讨了决策树集成模型（随机森林、梯度提升、极限梯度提升）的超参数对黑盒对抗性机器学习攻击（零阶优化）时间的影响，以增强联网自动驾驶汽车在多域作战中的安全性。研究发现超参数显著影响攻击执行时间，旨在通过优化超参数支持防御性可信人工智能实践，从而构建更具韧性的机器学习系统，以应对网络社会安全挑战。

> **摘要翻译:** 多域作战（MDOs）强调跨域防御复杂的协同威胁，其中智能城市和联网自动驾驶汽车（CAVs）等民用基础设施正成为主要目标。作为军民两用资产，联网自动驾驶汽车易受多表面威胁（MSTs）的攻击，特别是对抗性机器学习（AML）攻击，这种攻击可以同时危害多个车载机器学习系统（例如，入侵检测系统、交通标志识别系统）。因此，本研究调查了基于决策树的集成模型——随机森林（RF）、梯度提升（GB）和极限梯度提升（XGB）中的关键超参数如何影响黑盒对抗性机器学习攻击（即零阶优化（ZOO））所需的时间。研究结果表明，树的数量或提升轮次等参数显著影响攻击执行时间，其中随机森林和梯度提升模型比极限梯度提升模型更为敏感。对抗性训练（AT）时间也进行了分析，以评估攻击者的机会窗口。通过优化超参数，本研究支持在多表面威胁场景中实践防御性可信人工智能（D-TAI），并有助于为民用和军事领域开发弹性机器学习系统，这与多域作战中的网络社会安全框架和人机多域特遣部队相符。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [625] [Towards Unifying Quantitative Security Benchmarking for Multi Agent Systems](https://arxiv.org/abs/2507.21146)
> *迈向多智能体系统统一量化安全基准测试*

*Gauri Sharma, Vidhi Kulkarni, Miles King, Ken Huang* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 多智能体系统, 安全基准测试, 级联风险, 智能体级联注入, AI安全

**Comment:** 9 pages, 5 figures

> **TL;DR:** 本文提出了一种名为Agent Cascading Injection (ACI)的新型多智能体系统攻击向量，并提出了一种量化安全基准测试方法，旨在评估智能体间信任失效。

**AI_Comments:** 本文的创新之处在于识别并形式化了一种针对多智能体系统的新型级联攻击向量（ACI），这对于理解和缓解复杂AI系统中的新型威胁至关重要。其重要性体现在它不仅揭示了智能体间信任可能导致的系统性风险，还提出了一种量化评估这些风险的基准测试方法，为未来多智能体系统的安全设计和防御提供了具体工具和方向。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI系统越来越多地采用多智能体架构，这种连接性引入了新的安全风险，尤其是级联风险——一个智能体的漏洞可能通过利用智能体间的信任扩散并危及整个系统。此外，目前缺乏用于评估智能体间通信协议安全性的量化基准测试框架。

**Method:** 本文定义了一种名为Agent Cascading Injection (ACI)的攻击向量，并参照OWASP的Agentic AI漏洞评分系统，对其进行了形式化，包括对抗目标方程和关键变量。接着，分析了ACI的传播链、放大因子和智能体间复合效应等特性，并将其映射到OWASP的Agentic AI风险类别。最后，提出了一种针对级联信任失败对多智能体系统进行压力测试的方法论，旨在实现可测量、标准化的智能体间安全评估。

**Result:** 本文定义并形式化了Agent Cascading Injection (ACI)这一攻击向量，揭示了局部漏洞如何升级为系统性故障。分析了ACI的传播特性及其与OWASP风险类别的对应关系。提出了一种用于量化评估多智能体系统对级联信任失败的抵抗力的基准测试方法，为工程师提供了衡量系统弹性、进行数据驱动的架构权衡以及开发抵御新型智能体威胁所需的方法。

**Conclusion:** ACI攻击凸显了量化基准测试框架在评估智能体间通信协议安全性方面的关键需求。本文的工作为工程师提供了必要的工具，以基准测试系统弹性、进行数据驱动的架构权衡，并开发针对新一代智能体威胁的强大防御措施。

> **ai_Abstract:** 本文针对多智能体系统日益增长的级联安全风险，引入并形式化了一种名为“智能体级联注入（ACI）”的新型攻击向量。该攻击通过利用智能体间的信任，使局部漏洞能够放大并导致系统范围的故障。文章分析了ACI的传播特性，并将其与OWASP的智能体AI风险类别相对应。为解决量化安全评估的空白，论文提出了一种对多智能体系统进行压力测试的方法论，旨在建立统一的、可测量的智能体间安全基准测试框架，从而帮助工程师增强系统韧性并开发有效防御措施。

> **摘要翻译:** 不断发展的AI系统越来越多地部署多智能体架构，其中自主智能体通过不断发展的协议进行协作、信息共享和任务委派。这种连接性虽然强大，但也引入了新的安全风险。其中一种风险是级联风险：一个智能体中的漏洞可以通过利用智能体间的信任，在系统中级联传播，从而危及其他智能体。结合OWASP的智能体AI漏洞评分系统倡议，我们定义了一种攻击向量——智能体级联注入（Agent Cascading Injection, ACI），类似于智能体影响链（Agent Impact Chain）和爆炸半径（Blast Radius），在智能体网络中运行。在ACI攻击中，注入到一个智能体的恶意输入或工具漏洞利用会导致级联妥协和下游效应在信任其输出的智能体中放大。我们用对抗目标方程和关键变量（受损智能体、注入漏洞、污染观测等）形式化了这种攻击，捕捉了局部漏洞如何升级为系统范围的故障。然后，我们分析了ACI的特性——传播链、放大因子和智能体间复合效应——并将这些映射到OWASP新兴的智能体AI风险类别（例如影响链和编排漏洞利用）。最后，我们认为ACI突出表明了对量化基准测试框架的迫切需求，以评估智能体到智能体通信协议的安全性。我们概述了一种针对级联信任失败对多智能体系统（使用Google的A2A和Anthropic的MCP等架构）进行压力测试的方法论，该方法基于可测量、标准化的智能体到智能体安全评估的基础工作。我们的工作为工程师提供了必要的工具，以基准测试系统弹性、进行数据驱动的架构权衡，并开发针对新一代智能体威胁的强大防御措施。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [646] [WaveVerify: A Novel Audio Watermarking Framework for Media Authentication and Combatting Deepfakes](https://arxiv.org/abs/2507.21150)
> *WaveVerify：一种用于媒体认证和打击深度伪造的新型音频水印框架*

*Aditya Pujari, Ajita Rattani* | **Category: cs.CR** | **Updated: 2025-07-23**

**Keywords:** 音频水印, 深度伪造, 媒体认证, AI内容透明度, 语音诈骗

**Comment:** Accepted to IJCB 2025 (IEEE/IAPR International Joint Conference on
  Biometrics). Code available at: (1) Official Lab Repo:
  https://github.com/vcbsl/WaveVerify (2) Original Author Repo:
  https://github.com/pujariaditya/WaveVerify

> **TL;DR:** 由于深度伪造欺诈的激增，急需强大的音频内容认证。本文旨在开发法证工具和水印技术以应对这一挑战。

**AI_Comments:** 该论文解决了当前AI技术发展中一个非常紧迫和重要的社会问题，即深度伪造带来的欺诈和虚假信息风险。其提出的音频水印框架可能成为维护媒体真实性和打击AI滥用的关键技术。

<details>
  <summary>Details</summary>

**Motivation:** 语音生成技术的快速发展使得合成语音与真实人声难以区分，这在带来便利的同时也引入了重大风险，例如深度伪造冒充诈骗和合成媒体驱动的虚假信息传播。深度伪造欺诈尝试在2024年激增了1300%，金融部门损失超过1000万美元，个人受害者损失超过6000美元。因此，全球监管机构和政府正在制定措施，强调开发法证工具和水印技术来提高AI内容透明度和可追溯性，以维护媒体完整性。

**Method:** 未在摘要中提及

**Result:** 未在摘要中提及

**Conclusion:** 未在摘要中提及

> **ai_Abstract:** 本研究提出WaveVerify，一种新型音频水印框架，旨在应对深度伪造技术带来的挑战。鉴于AI生成语音的普及及其在诈骗和虚假信息传播中的应用，以及深度伪造欺诈事件的急剧增加，迫切需要开发强大的音频内容认证和溯源工具。该框架旨在通过水印技术，支持媒体认证并打击日益增长的深度伪造威胁。

> **摘要翻译:** 语音生成技术的快速发展使得合成语音在感知上与真实人声难以区分。虽然这些创新促进了有益的应用，例如个性化文本转语音系统和语音保存，但它们也带来了重大风险，包括深度伪造冒充诈骗和合成媒体驱动的虚假信息传播。最新报告显示，2024年深度伪造欺诈尝试比2023年激增了1300%以上，这凸显了对强大音频内容认证的迫切需求。金融部门受影响尤为严重，因语音诈骗损失超过1000万美元，个人受害者报告因AI生成的深度伪造电话损失超过6000美元。作为回应，全球监管机构和政府正在制定措施，以提高AI内容的透明度和可追溯性，强调开发法证工具和水印技术作为维护媒体完整性的重要策略。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [647] [GUARD-CAN: Graph-Understanding and Recurrent Architecture for CAN Anomaly Detection](https://arxiv.org/abs/2507.21640)
> *GUARD-CAN：用于CAN异常检测的图理解和循环架构*

*Hyeong Seon Kim, Huy Kang Kim* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-29**

**Keywords:** CAN异常检测, 图神经网络, 循环神经网络, 车载网络, 网络安全

**Comment:** Comments:12 pages, 3 figures, 3 tables; accepted to the 26th World
  Conference on Information Security Applications (WISA 2025)

> **TL;DR:** GUARD-CAN是一个结合图学习和循环神经网络的CAN总线异常检测框架，能有效检测多种车载网络攻击，无需复杂特征工程。

**AI_Comments:** GUARD-CAN的创新之处在于其结合了图表示学习（GCN）和循环神经网络（GRU）来处理CAN总线的时序和结构信息，从而实现对车载网络攻击的有效检测。其优势在于无需复杂的手动特征工程，并能从多视角（序列和窗口级别）进行异常检测。这对于提高车载网络的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代车载网络CAN总线由于缺乏加密和认证，面临各种网络威胁。为了解决这一安全问题，需要一个有效的异常检测框架。

**Method:** GUARD-CAN将CAN消息分割成固定长度的窗口，并将每个窗口转换为保留消息顺序的图。利用过完备自编码器（AE）和图卷积网络（GCN）生成图嵌入向量，然后将这些向量序列输入门控循环单元（GRU）以检测跨图的时间异常模式。模型在序列和窗口级别进行异常检测，并通过香农熵分析验证了窗口大小选择的重要性。

**Result:** GUARD-CAN模型能有效检测四种CAN攻击类型（洪泛、模糊、重放和欺骗攻击），且无需依赖复杂的特征工程。

**Conclusion:** GUARD-CAN通过结合图学习和循环神经网络，能够有效且无需复杂特征工程地检测多种CAN总线攻击，提高了车载网络安全性。

> **ai_Abstract:** 本文提出了GUARD-CAN，一个用于车载CAN总线异常检测的框架，旨在解决CAN缺乏加密和认证导致的安全问题。GUARD-CAN将CAN消息窗口转换为图结构，并利用图卷积网络（GCN）和自编码器（AE）提取图嵌入。这些嵌入随后被输入到门控循环单元（GRU）中，以识别时间上的异常模式。该模型在序列和窗口级别进行多视角异常检测，并强调了窗口大小选择的重要性。实验结果表明，GUARD-CAN能够有效检测包括洪泛、模糊、重放和欺骗在内的四种CAN攻击，且无需复杂的特征工程。

> **摘要翻译:** 现代车载网络由于控制器局域网络（CAN）缺乏加密和认证，面临各种网络威胁。为了解决这一安全问题，本文提出了GUARD-CAN，一个结合了基于图的表示学习和时间序列建模的异常检测框架。GUARD-CAN将CAN消息分割成固定长度的窗口，并将每个窗口转换为保留消息顺序的图。为了在同一窗口内检测时间感知和结构感知的异常，GUARD-CAN利用过完备自编码器（AE）和图卷积网络（GCN）生成图嵌入向量。模型将这些向量分组为序列，并将其输入门控循环单元（GRU），以检测跨图的时间异常模式。GUARD-CAN在序列级别和窗口级别都执行异常检测，这允许进行多视角性能评估。该模型还通过基于香农熵的分析验证了窗口大小选择的重要性。结果表明，GUARD-CAN提出的模型能够有效检测四种CAN攻击类型（洪泛、模糊、重放和欺骗攻击），而无需依赖复杂的特征工程。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [666] [NIST Post-Quantum Cryptography Standard Algorithms Based on Quantum Random Number Generators](https://arxiv.org/abs/2507.21151)
> *基于量子随机数发生器的NIST后量子密码标准算法*

*Abel C. H. Chen* | **Category: cs.CR, cs.PF, quant-ph, stat.AP** | **Updated: 2025-07-24**

**Keywords:** 量子随机数发生器, 后量子密码, NIST标准, ML-KEM, 数字签名

**Comment:** in Chinese language

> **TL;DR:** 量子计算对现有密码学构成威胁，NIST的后量子密码（PQC）算法在特定场景下可能安全不足。本文提出并评估了基于量子随机数发生器（QRNG）的PQC算法，以增强其安全性，并提供了部署参考数据。

**AI_Comments:** 本文通过引入量子随机数发生器来增强NIST后量子密码算法的安全性，特别是在随机性来源方面。这一创新点在于将量子计算的优势融入到PQC算法的基础构建中，以应对传统伪随机数可能存在的安全隐患。其重要性在于为PQC的实际部署提供了更强的安全保障和性能评估数据。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，量子计算技术的发展对RSA和椭圆曲线密码学构成了潜在的安全威胁。尽管NIST发布的后量子密码（PQC）算法旨在抵抗量子计算攻击，但在某些特定应用场景下可能无法提供足够的安全性。

**Method:** 本研究提出基于量子随机数发生器（QRNG）的PQC算法，利用量子计算生成随机数作为密钥对生成、密钥封装和数字签名的基础。研究提出了一个通用的QRNG架构，并设计了六种QRNG。每个生成器都根据NIST SP 800-90B中概述的统计验证程序进行评估，包括熵源验证和独立同分布（IID）输出测试。

**Result:** 实验结果评估了六种QRNG的计算时间，以及基于QRNG的ML-KEM、基于QRNG的ML-DSA和基于QRNG的SLH-DSA的性能。

**Conclusion:** 这些研究结果为未来PQC系统的部署提供了有价值的参考数据。

> **ai_Abstract:** 本文针对量子计算对现有密码学的威胁以及NIST后量子密码算法在特定场景下的安全不足，提出并评估了基于量子随机数发生器（QRNG）的后量子密码算法。研究设计了通用的QRNG架构和六种具体QRNG，并依据NIST标准对其进行了统计验证和性能评估，包括QRNG的计算时间以及基于QRNG的ML-KEM、ML-DSA和SLH-DSA的性能。研究结果为未来PQC系统的部署提供了重要参考数据。

> **摘要翻译:** 近年来，量子计算技术的进步对RSA密码学和椭圆曲线密码学构成了潜在的安全威胁。为此，美国国家标准与技术研究院（NIST）于2024年8月发布了几项联邦信息处理标准（FIPS）的后量子密码（PQC），包括基于模块格的密钥封装机制（ML-KEM）、基于模块格的数字签名算法（ML-DSA）和无状态基于哈希的数字签名算法（SLH-DSA）。尽管这些PQC算法旨在抵抗量子计算攻击，但它们在某些特定的应用场景中可能无法提供足够的安全性。为了解决这个问题，本研究提出了基于量子随机数发生器（QRNG）的PQC算法。这些算法利用量子计算生成随机数，作为密钥对生成、密钥封装和数字签名生成的基础。本文提出了一个通用的QRNG架构，并设计了六种QRNG。每个生成器都根据NIST SP 800-90B中概述的统计验证程序进行评估，包括熵源验证和独立同分布（IID）输出测试。实验结果评估了六种QRNG的计算时间，以及基于QRNG的ML-KEM、基于QRNG的ML-DSA和基于QRNG的SLH-DSA的性能。这些发现为未来PQC系统的部署提供了有价值的参考数据。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [687] [Assessment of Quantitative Cyber-Physical Reliability of SCADA Systems in Autonomous Vehicle to Grid (V2G) Capable Smart Grids](https://arxiv.org/abs/2507.21154)
> *评估自主车网(V2G)智能电网中SCADA系统量化信息物理可靠性*

*Md Abdul Gaffar* | **Category: cs.CR, cs.SY, eess.SY, math.OC** | **Updated: 2025-07-24**

**Keywords:** 车网(V2G), SCADA系统, 网络物理攻击, 可靠性评估, 智能电网

**Comment:** 5 pages, 6 figures

> **TL;DR:** 本文评估了自主车网(AV2G)通信基础设施对SCADA系统可靠性的网络物理攻击影响，并强调了智能电网中网络安全强化策略的必要性。

**AI_Comments:** 本文创新性地将贝叶斯攻击图和概率容量中断建模应用于评估AV2G对SCADA系统可靠性的网络物理影响，并通过蒙特卡洛模拟量化了性能下降，为智能电网的网络安全防护提供了重要见解。

<details>
  <summary>Details</summary>

**Motivation:** 随着电动汽车通过车网(V2G)技术日益融入电网，虽然带来了优势，但也引入了新的网络物理攻击面和对监控与数据采集(SCADA)系统的漏洞，因此需要评估这些威胁对系统可靠性的影响。

**Method:** 本文采用贝叶斯攻击图结合基于IEEE RTS-79系统数据的概率容量中断建模进行量化可靠性评估，并使用蒙特卡洛模拟方法展示AV2G攻击如何降低系统性能。

**Result:** 研究表明，基于AV2G的攻击会降低系统性能。

**Conclusion:** 智能电网设计中需要加强网络安全强化策略。

> **ai_Abstract:** 本文研究了自主车网(AV2G)通信基础设施对智能电网中监控与数据采集(SCADA)系统可靠性的影响。随着车网(V2G)技术在电网整合中的普及，新的网络物理攻击面和漏洞随之出现。研究通过结合贝叶斯攻击图、概率容量中断建模和蒙特卡洛模拟，对AV2G攻击导致的系统性能下降进行了量化评估，并强调了在智能电网设计中实施网络安全强化策略的重要性。

> **摘要翻译:** 电动汽车(EV)通过车网(V2G)系统技术整合到电网中的趋势日益增长，但这些现象既带来了优势也带来了劣势。V2G可以通过提供分布式储能和辅助服务来提高电网可靠性。然而，另一方面，它涵盖了国家电网的网络物理攻击面，在监控与数据采集(SCADA)系统中引入了新的漏洞。本文研究了由自主车网(AV2G)通信基础设施引起的恶意行为，并评估了它们对SCADA系统可靠性的影响。本文提出了一种量化可靠性评估方法，该方法结合了贝叶斯攻击图和基于IEEE RTS-79系统数据的概率容量中断建模。这项工作通过使用蒙特卡洛模拟方法展示了基于AV2G的攻击如何降低系统性能，强调了在智能电网设计中加强网络安全策略的必要性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [716] [Unmasking Synthetic Realities in Generative AI: A Comprehensive Review of Adversarially Robust Deepfake Detection Systems](https://arxiv.org/abs/2507.21157)
> *揭示生成式AI中的合成现实：对抗性鲁棒深度伪造检测系统的全面综述*

*Naseem Khan, Tuan Nguyen, Amine Bermak, Issa Khalil* | **Category: cs.CR, cs.CV, F.2.2; I.2.7** | **Updated: 2025-07-24**

**Keywords:** 深度伪造检测, 对抗性鲁棒性, 生成式AI, 系统综述, 媒体真实性

**Comment:** 27 pages, 4 Tables, 3 Figures

> **TL;DR:** 本文综述了深度伪造检测系统，强调了它们在面对对抗性攻击时的脆弱性，并指出迫切需要开发更具鲁棒性的解决方案。

**AI_Comments:** 本文的创新点在于系统性地指出了当前深度伪造检测领域的一个关键局限性：缺乏对抗性鲁棒性。它不仅评估了现有方法的优缺点，更明确地提出了未来研究的重点方向，即开发能抵御对抗性攻击的鲁棒系统。其贡献的开源代码仓库也具有实用价值，有助于推动研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 快速发展的生成式人工智能（Generative AI）导致深度伪造（deepfake）泛滥，对数字安全、虚假信息缓解和身份保护构成了严峻挑战。

**Method:** 本系统综述评估了最先进的深度伪造检测方法，包括检测完全合成媒体和定位真实内容中被操纵区域的两种核心范式。研究强调了可复现的实现，并贡献了一个聚合开源实现的GitHub仓库，以促进复现和测试。

**Result:** 当前的深度伪造检测方法在受控环境下表现出显著的精度和适应性，但全面评估显示其对抗性鲁棒性不足。现有方法对旨在逃避检测的对抗性扰动表现出脆弱性，从而削弱了其在真实世界对抗性环境中的可靠性。

**Conclusion:** 本研究发现，方法学发展与不断演变的威胁格局之间存在关键脱节。因此，迫切需要未来工作优先考虑对抗性弹性，倡导可扩展、与模态无关的架构，以抵御复杂的操纵。本综述综合了当代深度伪造检测的优缺点，并为构建鲁棒可信系统指明了方向。

> **ai_Abstract:** 这篇综述系统性地评估了当前先进的深度伪造检测方法，包括对完全合成媒体的检测和对真实内容中操纵区域的定位。尽管现有方法在受控环境中表现良好，但研究发现它们普遍缺乏对抗性鲁棒性，易受对抗性攻击影响，这在真实世界中是一个严重缺陷。文章强调了未来研究应优先关注提升检测系统的对抗性弹性，并为此提供了一个开源实现的GitHub仓库。

> **摘要翻译:** 生成式人工智能的快速发展推动了深度伪造的扩散——合成媒体涵盖完全生成的内容和微妙编辑的真实材料——对数字安全、虚假信息缓解和身份保护构成了挑战。本系统综述评估了最先进的深度伪造检测方法，强调可复现的实现以提高透明度和验证。我们 delineates 了两个核心范式：（1）利用统计异常和分层特征提取检测完全合成媒体，以及（2）采用视觉伪影和时间不一致等多模态线索定位真实内容中被操纵的区域。这些方法，涵盖单模态和多模态框架，在受控环境中表现出显著的精度和适应性，通过先进的学习技术和跨模态融合有效识别操纵。然而，全面评估揭示了两种范式在对抗性鲁棒性评估方面不足。当前方法对对抗性扰动——旨在逃避检测的微妙改变——表现出脆弱性，从而削弱了在真实世界对抗性环境中的可靠性。这一差距凸显了方法学发展与不断演变的威胁格局之间的关键脱节。为了解决这个问题，我们贡献了一个精选的GitHub仓库，聚合了开源实现，从而实现复现和测试。我们的研究结果强调未来工作迫切需要优先考虑对抗性弹性，倡导能够抵御复杂操纵的可扩展、与模态无关的架构。本综述综合了当代深度伪造检测的优缺点，同时为构建鲁棒可信系统指明了路径。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [717] [Modelling Arbitrary Computations in the Symbolic Model using an Equational Theory for Bounded Binary Circuits](https://arxiv.org/abs/2507.21731)
> *使用有界二元电路的等式理论在符号模型中建模任意计算*

*Michiel Marcus, Frank Westers, Anne Nijsten* | **Category: cs.CR** | **Updated: 2025-07-29**

**Keywords:** 等式理论, 二元电路, 符号模型, 密码原语, 攻击发现

**Comment:** 

> **TL;DR:** 本文提出了一类有界二元电路的等式理论，用于在符号模型中建模密码原语并发现攻击。研究证明了这些理论在电路大小不超过3时与布尔逻辑的等价性，并使用Maude-NPA进行了性能评估，指出该方法未来需提升可扩展性。

**AI_Comments:** 本文在利用等式理论对有界二元电路进行建模方面迈出了开创性的一步，旨在促进密码原语的形式化分析和自动攻击发现。其创新之处在于提出了一类具有有限变体性质的新理论。然而，论文也明确指出其局限性在于可扩展性，表明当前方法可能主要适用于较小规模的电路，未来的研究需致力于解决这一问题。

<details>
  <summary>Details</summary>

**Motivation:** 在符号模型中指定密码原语的实现，并自动发现作为二元电路的攻击。

**Method:** 提出了一类具有有限变体性质的有界二元电路的等式理论。提供了这些等式理论与布尔逻辑在电路大小为3以下的等价性证明。使用Maude-NPA进行变体复杂性和性能基准测试。

**Result:** 提出了有界二元电路的等式理论，并证明了其在电路大小不超过3时与布尔逻辑的等价性。使用Maude-NPA提供了变体复杂性和性能基准。这是该方向上的首个结果。

**Conclusion:** 提出的有界二元电路等式理论可以作为在符号模型中指定密码原语和发现攻击的基础构建块，但该方法需要后续研究以提高其可扩展性。

> **ai_Abstract:** 本文提出了一类新的有界二元电路等式理论，该理论具有有限变体性质，旨在作为在符号模型中指定密码原语实现和自动发现攻击的基础。作者证明了这些理论在电路大小不超过3时与布尔逻辑的等价性，并利用Maude-NPA进行了变体复杂性和性能基准测试。研究强调这是该领域的一个初步成果，未来需要进一步研究以提升其可扩展性。

> **摘要翻译:** 在这项工作中，我们提出了一类具有有限变体性质的有界二元电路的等式理论。这些理论可以作为构建块，用于在符号模型中指定密码原语实现并自动发现作为二元电路的攻击。我们提供了这类等式理论与布尔逻辑在电路大小为3以下的等价性证明，并使用Maude-NPA提供了变体复杂性和性能基准。这是该方向上的第一个结果，需要后续研究来提高该方法的可扩展性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [751] [Generating Adversarial Point Clouds Using Diffusion Model](https://arxiv.org/abs/2507.21163)
> *使用扩散模型生成对抗性点云*

*Ruiyang Zhao, Bingbing Zhu, Chuxuan Tong, Xiaoyi Zhou, Xi Zheng* | **Category: cs.CR, cs.AI, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 对抗攻击, 点云, 扩散模型, 黑盒攻击, 模型安全

**Comment:** 

> **TL;DR:** 提出一种利用扩散模型生成黑盒对抗性点云的新方法，以提高攻击成功率和不可感知性。

**AI_Comments:** 该论文的创新点在于首次将扩散模型应用于黑盒对抗性点云生成，这为解决现有白盒攻击方法在实际场景中应用受限的问题提供了新思路。这种方法提高了黑盒攻击的实用性和有效性，对于评估和增强点云识别模型的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 点云识别模型的脆弱性可能导致自动驾驶等关键应用的安全风险。现有白盒攻击方法在实际场景中应用受限，而黑盒攻击效果不佳，因此需要一种新的黑盒攻击方法来揭示模型缺陷。

**Method:** 本文提出一种新颖的黑盒对抗样本生成方法。该方法利用3D扩散模型，将点云的压缩特征作为先验知识来指导逆向扩散过程，向干净样本添加对抗点。随后，利用其逆向过程将其他类别的分布转换为对抗点并添加到点云中。

**Result:** Not mentioned in abstract

**Conclusion:** 该方法旨在提高黑盒设置下的攻击成功率和不可感知性，为评估点云识别模型的安全性提供了一种更具实际意义的手段。

> **ai_Abstract:** 本文针对点云识别模型在实际应用中的安全脆弱性问题，提出了一种基于扩散模型的新型黑盒对抗样本生成方法。该方法无需访问模型内部信息，通过利用点云的压缩特征引导3D扩散模型的逆向过程来添加对抗点，旨在提高黑盒攻击的成功率和不可感知性，从而更有效地评估点云模型的安全性。

> **摘要翻译:** 用于3D点云分类的对抗攻击方法揭示了点云识别模型的脆弱性。这种脆弱性可能导致使用深度学习模型的关键应用（如自动驾驶）中的安全风险。为了揭示这些模型的缺陷，研究人员可以通过对抗攻击来评估其安全性。然而，大多数现有的对抗攻击方法都基于白盒攻击。虽然这些方法实现了高攻击成功率和不可感知性，但它们在实际场景中的适用性有限。黑盒攻击在实际场景中更具意义，但通常效果不佳。本文提出了一种新颖的黑盒对抗样本生成方法，该方法利用扩散模型来提高黑盒设置下的攻击成功率和不可感知性，而无需依赖点云分类模型的内部信息来生成对抗样本。我们使用3D扩散模型，将点云的压缩特征作为先验知识来指导逆向扩散过程，向干净样本添加对抗点。随后，其逆向过程被用于将其他类别的分布转换为对抗点，然后将其添加到点云中。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [786] [OneShield -- the Next Generation of LLM Guardrails](https://arxiv.org/abs/2507.21170)
> *OneShield -- 下一代LLM护栏*

*Chad DeLuca, Anna Lisa Gentile, Shubhi Asthana, Bing Zhang, Pawan Chowdhary, Kellen Cheng, Basel Shbita, Pengyuan Li, Guang-Jie Ren, Sandeep Gopisetty* | **Category: cs.CR, cs.AI, cs.CL** | **Updated: 2025-07-25**

**Keywords:** LLM安全, 护栏, OneShield, 模型无关, 可定制

**Comment:** 

> **TL;DR:** OneShield是一个独立、模型无关且可定制的解决方案，旨在为大型语言模型（LLM）提供安全防护，以应对其不断演变的安全、隐私和伦理风险。

**AI_Comments:** OneShield的创新之处在于其“模型无关”和“可定制”的特性，这使其能够适应LLM快速发展的特性，避免了一刀切方案的局限性。其专注于“特定客户”需求的方法也提升了其实用性。该方案的实际部署和使用统计数据增加了其可信度，表明它是一个有前景的LLM安全防护方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的兴起带来了巨大的应用潜力，但也引发了关于安全、隐私和伦理的问题。由于LLM的不断演变，现有的一刀切解决方案难以普遍保护用户免受潜在风险。

**Method:** 本文提出了OneShield，一个独立的、模型无关且可定制的解决方案，用于保护LLM。OneShield旨在提供定义风险因素、表达和声明上下文安全合规策略以及缓解LLM风险的功能，并专注于每个特定客户的需求。

**Result:** 论文描述了OneShield框架的实现、可扩展性考量，并提供了自首次部署以来的使用统计数据。

**Conclusion:** OneShield提供了一个可定制且模型无关的LLM安全防护框架，旨在解决LLM带来的不断演变的安全、隐私和伦理风险，并已实际部署和收集使用统计数据。

> **ai_Abstract:** 本文提出了一种名为OneShield的独立、模型无关且可定制的解决方案，旨在应对大型语言模型（LLM）在安全、隐私和伦理方面不断演变的挑战。OneShield允许用户定义风险因素、制定上下文安全与合规策略，并有效缓解LLM的潜在风险。论文详细阐述了该框架的实现细节、可扩展性考虑因素，并分享了其自部署以来的使用统计数据。

> **摘要翻译:** 大型语言模型的兴起引发了人们对无数应用巨大潜力的普遍兴奋。虽然LLM提供了许多可能性，但关于安全、隐私和伦理的问题也随之出现，所有主要参与者都在努力通过为其自身模型和独立解决方案采取保护措施来解决这些问题。LLM不断演变的特性使得普遍保护用户免受其潜在风险的任务极具挑战性，并且一刀切的解决方案是不可行的。在这项工作中，我们提出了OneShield，我们独立、模型无关且可定制的解决方案，旨在保护LLM。OneShield旨在提供定义风险因素、表达和声明上下文安全和合规策略以及缓解LLM风险的功能，重点关注每个特定客户。我们描述了该框架的实现、可扩展性考量，并提供了OneShield自首次部署以来的使用统计数据。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [787] [Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?](https://arxiv.org/abs/2507.21817)
> *分布外，运气差：在漏洞数据集上训练的LLM能多好地检测出CWE Top 25弱点？*

*Yikun Li, Ngoc Tan Bui, Ting Zhang, Martin Weyssow, Chengran Yang, Xin Zhou, Jinfeng Jiang, Junkai Chen, Huihui Huang, Huu Hung Nguyen, Chiok Yew Ho, Jie Tan, Ruiyin Li, Yide Yin, Han Wei Ang, Frank Liauw, Eng Lieh Ouh, Lwin Khin Shar, David Lo* | **Category: cs.CR, cs.SE** | **Updated: 2025-07-29**

**Keywords:** 漏洞检测, 大型语言模型, 泛化差距, 数据集, CWE

**Comment:** 

> **TL;DR:** 鉴于现有漏洞数据集的缺陷导致LLMs在漏洞检测中存在严重的“泛化差距”，本文提出了BenchVul、TitanVul和RVG框架，显著提高了LLMs对CWE Top 25漏洞的泛化检测能力。

**AI_Comments:** 本文通过构建高质量、去重且覆盖关键CWE的数据集，并引入上下文感知的漏洞生成方法，有效地解决了现有漏洞检测数据集中常见的“泛化差距”问题。其创新点在于结合了人工审查、多智能体LLM验证和模拟开发工作流来创建更真实、更具挑战性的数据集和生成方法，这对于提升自动化漏洞检测模型的实际应用效果至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 自动化漏洞检测研究进展显著但实际影响有限。现有漏洞数据集存在标签不准确（20-71%）、大量重复和关键CWE类型覆盖不足等问题，导致模型出现“泛化差距”，在独立数据上性能大幅下降（最高40.6%），甚至不如随机猜测。

**Method:** 本文提出了一个三部分解决方案：1. 手动整理的测试数据集BenchVul，涵盖MITRE Top 25最危险CWE。2. 高质量训练数据集TitanVul，包含35,045个函数，通过聚合七个公共来源并使用多智能体LLM框架进行去重和验证。3. 现实漏洞生成（RVG）框架，通过模拟开发工作流为代表性不足但关键的CWE类型合成上下文感知漏洞示例。

**Result:** 1. BenchVul揭示了自测试的局限性：在现有数据集（如BigVul和PrimeVul）上训练的模型在BenchVul上的性能大幅下降（从0.776降至0.519，从0.567降至0.337）。2. 在TitanVul上训练模型显示出改进的泛化能力，模型性能从在相同数据集上评估时的0.584提高到在BenchVul上测试时的0.767。3. 用RVG生成的数据补充TitanVul进一步提高了性能，模型性能提高了14.0%达到0.874。

**Conclusion:** 本文提出的BenchVul、TitanVul和RVG框架的每个组件都有效地弥补了泛化差距，显著提高了LLMs在漏洞检测方面的泛化能力。

> **ai_Abstract:** 鉴于现有漏洞数据集的缺陷导致大型语言模型在漏洞检测中存在严重的“泛化差距”，本文提出了一个三部分解决方案。该方案包括构建一个高质量的测试数据集BenchVul（涵盖Top 25 CWE）、一个聚合并验证的高质量训练数据集TitanVul，以及一个通过模拟开发工作流生成上下文感知漏洞示例的现实漏洞生成（RVG）框架。实验结果表明，这些组件显著提高了模型在独立数据上的泛化能力，弥补了性能差距。

> **摘要翻译:** 自动化漏洞检测研究已取得实质性进展，但其实际影响仍然有限。当前的漏洞数据集存在标签不准确率高达20-71%、大量重复以及对关键CWE类型覆盖不足等问题。这些问题造成了显著的“泛化差距”，模型通过利用虚假关联而非学习真正的漏洞模式，从而在自测试性能（在用于训练的相同数据集的保留数据上测量）上产生误导性结果。我们的分析显示，许多模型在独立数据上评估时性能大幅下降，降幅高达40.6%，有时甚至不如随机猜测。
为解决这些局限性，我们提出了一个三部分解决方案。首先，我们引入了一个手动整理的测试数据集BenchVul，涵盖了MITRE前25个最危险的CWE。其次，我们构建了一个高质量的训练数据集TitanVul，通过聚合七个公共来源并使用新颖的多智能体LLM框架进行去重和验证，包含了35,045个函数。第三，我们提出了一个现实漏洞生成（RVG）框架，该框架通过模拟开发工作流，为代表性不足但关键的CWE类型合成上下文感知的漏洞示例。
我们的评估显示了每个组件在弥合泛化差距方面的优势。首先，BenchVul揭示了自测试的局限性：在现有数据集（如BigVul和PrimeVul）上训练的模型在BenchVul上的性能下降（从0.776降至0.519，从0.567降至0.337）。其次，在TitanVul上训练模型显示出改进的泛化能力，模型性能从在相同数据集上评估时的0.584提高到在BenchVul上测试时的0.767。第三，用RVG生成的数据补充TitanVul进一步提高了性能，使模型性能提高了14.0%达到0.874。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [805] [Large Language Model-Based Framework for Explainable Cyberattack Detection in Automatic Generation Control Systems](https://arxiv.org/abs/2507.22239)
> *基于大语言模型的自动发电控制系统可解释网络攻击检测框架*

*Muhammad Sharshar, Ahmad Mohammad Saber, Davor Svetinovic, Amr M. Youssef, Deepa Kundur, Ehab F. El-Saadany* | **Category: cs.CR, cs.AI, cs.SY, eess.SY** | **Updated: 2025-07-29**

**Keywords:** 网络攻击检测, 大语言模型, 自动发电控制系统, 可解释AI, 智能电网

**Comment:** Accepted Publication

> **TL;DR:** 该论文提出了一个结合轻量级机器学习和大型语言模型（LLM）的混合框架，用于智能电网中可解释的网络攻击检测，在实现高检测精度的同时提供人类可读的解释。

**AI_Comments:** 该论文的创新之处在于将大语言模型引入到网络攻击检测的可解释性环节，解决了传统ML/DL模型“黑箱”问题，增强了操作员对系统决策的信任。这种结合轻量级ML高效检测与LLM强大解释能力的混合方法，在智能电网等需要高可靠性和透明度的关键基础设施领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 智能电网的数字化引入了新的网络安全漏洞，如针对自动发电控制系统（AGC）的虚假数据注入攻击（FDIAs）。尽管机器学习和深度学习模型在检测此类攻击方面表现出潜力，但其不透明的决策过程限制了操作员的信任和实际应用。

**Method:** 该论文提出了一个混合框架，将轻量级机器学习（ML）的攻击检测与大语言模型（LLM）生成的自然语言解释相结合。LightGBM等分类器用于攻击检测。检测到攻击后，系统调用GPT-3.5 Turbo、GPT-4 Turbo和GPT-4o mini等LLM来生成事件的人类可读解释。

**Result:** LightGBM等分类器实现了高达95.13%的攻击检测准确率，推理延迟仅为0.004秒。在100个测试样本上评估，GPT-4o mini在20次提示下，识别攻击目标准确率为93%，估计攻击幅度平均绝对误差为0.075 pu，估计攻击开始时间平均绝对误差为2.19秒。

**Conclusion:** 所提出的框架有效平衡了实时检测与可解释、高保真解释，满足了智能电网网络安全领域对可操作AI的关键需求。

> **ai_Abstract:** 本文提出了一个针对智能电网AGC系统网络攻击检测的混合框架，旨在解决现有机器学习模型缺乏可解释性的问题。该框架结合了高效的轻量级机器学习（如LightGBM）进行高精度、低延迟的攻击检测，并利用大语言模型（如GPT系列）生成人类可读的攻击事件解释。实验结果表明，该框架在保持高检测性能的同时，有效提供了攻击目标、幅度和时间等关键信息的可解释性，为智能电网网络安全提供了实用且可信赖的AI解决方案。

> **摘要翻译:** 智能电网日益增长的数字化提高了运行效率，但也引入了新的网络安全漏洞，例如针对自动发电控制（AGC）系统的虚假数据注入攻击（FDIAs）。尽管机器学习（ML）和深度学习（DL）模型在检测此类攻击方面显示出前景，但其不透明的决策制定过程限制了操作员的信任和实际适用性。本文提出了一种混合框架，该框架将轻量级基于ML的攻击检测与大语言模型（LLM）生成的自然语言解释相结合。LightGBM等分类器实现了高达95.13%的攻击检测准确率，推理延迟仅为0.004秒。一旦检测到网络攻击，系统会调用包括GPT-3.5 Turbo、GPT-4 Turbo和GPT-4o mini在内的LLM来生成事件的人类可读解释。在100个测试样本上进行评估，带有20次提示的GPT-4o mini在识别攻击目标方面达到了93%的准确率，在估计攻击幅度方面平均绝对误差为0.075 pu，在估计攻击开始时间方面平均绝对误差（MAE）为2.19秒。这些结果表明，所提出的框架有效平衡了实时检测与可解释、高保真解释，解决了智能电网网络安全领域对可操作AI的关键需求。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [813] [FedBAP: Backdoor Defense via Benign Adversarial Perturbation in Federated Learning](https://arxiv.org/abs/2507.21177)
> *FedBAP：联邦学习中通过良性对抗扰动进行后门防御*

*Xinhai Yan, Libing Wu, Zhuangzhuang Zhang, Bingyi Liu, Lijuan Huo, Jing Wang* | **Category: cs.CR, cs.LG** | **Updated: 2025-07-26**

**Keywords:** 联邦学习, 后门攻击, 后门防御, 对抗扰动, FedBAP

**Comment:** Accepted to ACM Multimedia 2025

> **TL;DR:** FedBAP是一种新的联邦学习后门防御框架，通过生成良性对抗扰动来减少模型对后门触发器的依赖，从而提高防御效果和模型鲁棒性。

**AI_Comments:** 该论文提出了一种新颖的后门防御方法FedBAP，其创新点在于通过生成良性对抗扰动来直接削弱模型对后门触发器的过度依赖，并迫使模型学习更鲁棒的决策边界。这与传统防御方法关注剔除恶意客户端或检测攻击有所不同。自适应缩放机制的引入也体现了对防御强度和模型性能平衡的考量。该方法对新型后门攻击的卓越表现，凸显了其潜在的重要性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）虽然保护数据隐私，但极易受到后门攻击。现有防御方法效果有限，因为它们忽视了模型对后门触发器的过度依赖，尤其是在恶意客户端比例增加时。

**Method:** 本文提出了FedBAP框架，旨在通过减少模型对后门触发器的依赖来缓解联邦学习中的后门攻击。具体方法包括：1. 提出一种扰动触发器生成机制，精确匹配后门触发器的位置和大小，以确保对模型输出的强大影响。2. 利用这些扰动触发器生成良性对抗扰动，以扰乱模型对后门触发器的依赖，同时迫使模型学习更鲁棒的决策边界。3. 设计一个自适应缩放机制，动态调整扰动强度，有效平衡防御强度和模型性能。

**Result:** 实验结果表明，FedBAP在三种后门攻击下，分别将攻击成功率降低了0.22%-5.34%、0.48%-6.34%和97.22%-97.6%。尤其值得注意的是，FedBAP在对抗新型后门攻击方面表现出色。

**Conclusion:** FedBAP通过减少模型对后门触发器的依赖，成功地在联邦学习中实现了有效的后门防御，并显著提升了模型鲁棒性，尤其在对抗新型攻击方面表现卓越。

> **ai_Abstract:** FedBAP是一种针对联邦学习中后门攻击的新型防御框架。它通过提出一种扰动触发器生成机制，创建与后门触发器精确匹配的扰动，并利用这些扰动生成良性对抗扰动，以削弱模型对后门触发器的依赖并强化决策边界。此外，通过自适应缩放机制动态调整扰动强度，平衡防御效果与模型性能。实验证明，FedBAP能显著降低多种后门攻击的成功率，尤其对新型攻击表现突出。

> **摘要翻译:** 联邦学习（FL）实现了协作模型训练同时保护数据隐私，但它极易受到后门攻击。大多数现有联邦学习防御方法由于忽略了模型对后门触发器的过度依赖而效果有限，尤其是在恶意客户端比例增加时。在本文中，我们提出了FedBAP，一种新颖的防御框架，通过减少模型对后门触发器的依赖来缓解联邦学习中的后门攻击。具体来说，首先，我们提出了一种扰动触发器生成机制，该机制创建的扰动触发器在位置和大小上精确匹配后门触发器，确保对模型输出的强大影响。其次，我们利用这些扰动触发器生成良性对抗扰动，以扰乱模型对后门触发器的依赖，同时迫使它学习更鲁棒的决策边界。最后，我们设计了一个自适应缩放机制，以动态调整扰动强度，有效平衡防御强度和模型性能。实验结果表明，FedBAP在三种后门攻击下分别将攻击成功率降低了0.22%-5.34%、0.48%-6.34%和97.22%-97.6%。特别是，FedBAP在对抗新型后门攻击方面表现出卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [849] [SHoM: A Mental-Synthesis Trust Management Model for Mitigating Botnet-Driven DDoS Attacks in the Internet of Things](https://arxiv.org/abs/2507.21178)
> *SHoM：一种用于缓解物联网中僵尸网络DDoS攻击的心理合成信任管理模型*

*Masoud Hayeri Khyavi* | **Category: cs.CR** | **Updated: 2025-07-30**

**Keywords:** 物联网, DDoS攻击, 僵尸网络, 信任管理, 安全模型

**Comment:** 22 Pages, 15 figure, 9 tables

> **TL;DR:** 本文提出SHoM模型，通过信任管理来应对物联网中僵尸网络驱动的DDoS攻击，旨在设计一个可靠灵活的安全模型。

**AI_Comments:** 本文提出了一种新颖的“心理合成信任管理”模型SHoM来解决物联网DDoS攻击问题，这在理念上具有创新性。其重要性在于试图从信任管理的角度为物联网安全提供新的解决方案。然而，摘要中未提及具体的实现细节或实验结果，仅说明研究了相关模型，因此模型的实际性能和有效性尚待验证。

<details>
  <summary>Details</summary>

**Motivation:** 物联网的广泛应用使其成为商业、工业和社交生态系统的重要组成部分。然而，由于物联网终端设备计算、存储和通信能力有限，其基础设施极易受到网络威胁，特别是DDoS攻击。攻击者常利用这些弱点将物联网设备构建成僵尸网络来执行DDoS攻击，对物联网安全构成严重风险。

**Method:** 本文提出了一个名为SHoM的模型，通过信任管理来处理物联网中的僵尸网络DDoS攻击。该模型试图考虑所有与信任因素相关的安全方面，以设计一个可靠且灵活的物联网DDoS攻击防御模型。

**Result:** Not mentioned in abstract

**Conclusion:** 本文提出了一个针对物联网僵尸网络DDoS攻击的信任管理模型SHoM，旨在设计一个可靠且灵活的模型来应对此类攻击。

> **ai_Abstract:** 本文针对物联网设备因资源受限易受僵尸网络DDoS攻击的现状，提出了一种名为SHoM的心理合成信任管理模型。该模型旨在通过全面考虑与信任相关的安全因素，构建一个可靠且灵活的防御机制，以有效缓解物联网环境中的DDoS威胁。初步研究涵盖了大量现有安全模型。

> **摘要翻译:** 物联网在加强商业、工业和社会生态系统方面的优势使其得到了广泛扩展。然而，由于终端设备的计算、存储和通信能力有限，物联网基础设施容易受到多种网络威胁。因此，DDoS攻击对物联网的安全构成了严重威胁。攻击者可以利用这些弱点，迅速将物联网设备用作僵尸网络的一部分来执行DDoS攻击。最关键的发展是越来越多的机器人大军正在由物联网设备构建。我们提供了一个通过信任管理来处理物联网中僵尸网络DDoS攻击的模型。在这个模型中，我们试图考虑所有与信任因素相关的安全方面，以设计一个可靠且灵活的物联网DDoS攻击防御模型。在初步研究中，通过使用评论文章，已经研究了大约40-50个与该主题相关的安全模型。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [857] [Privacy-Preserving Anonymization of System and Network Event Logs Using Salt-Based Hashing and Temporal Noise](https://arxiv.org/abs/2507.21904)
> *使用基于盐的哈希和时间噪声对系统和网络事件日志进行隐私保护匿名化*

*Shreyas Bargale, Akshit Vakati Venkata, Jaimandeep Singh, Chester Rebeiro* | **Category: cs.CR** | **Updated: 2025-07-29**

**Keywords:** 隐私保护, 日志匿名化, 哈希, 时间戳匿名化, PII

**Comment:** 

> **TL;DR:** 论文提出了一种新的日志匿名化方法，通过基于盐的IP哈希、带范围映射的端口哈希和带噪声的时间戳匿名化，在保护隐私的同时保持日志的分析可用性。

**AI_Comments:** 这篇论文的创新点在于提出了针对日志中不同类型敏感数据的细粒度匿名化方法，特别是IP地址的逐字节哈希和时间戳的保序噪声注入，有效解决了隐私与可用性的平衡难题。开源工具的发布也极大地促进了研究的实用性和可重复性。

<details>
  <summary>Details</summary>

**Motivation:** 系统和网络事件日志对安全分析至关重要，但通常包含个人身份信息（PII），导致隐私问题。日志匿名化的挑战在于平衡隐私保护与分析结构保留，以避免过度匿名化破坏上下文完整性或弱技术导致重新识别。

**Method:** 论文引入了新颖的字段特定匿名化方法：IP地址采用逐字节的基于盐的哈希技术，保留子网和主机结构；端口号采用带范围映射的全值哈希，保持可解释性；时间戳采用使用自适应噪声注入的保序匿名化方案，混淆精确时间而不扰乱事件序列。此外，还发布了一个实现这些技术的开源工具。

**Result:** 使用熵度量、碰撞率和残余泄露分析进行的评估表明，所提出的方法在有效保护隐私的同时保留了分析效用。

**Conclusion:** 该方法成功地解决了日志匿名化中的隐私与可用性权衡问题，通过字段特定的匿名化技术，实现了对PII的有效保护，同时保持了日志的分析价值。

> **ai_Abstract:** 本文提出了一种创新的日志匿名化框架，旨在解决系统和网络事件日志中个人身份信息（PII）的隐私问题，同时保持其分析可用性。该框架引入了针对IP地址、端口号和时间戳的字段特定匿名化技术，包括基于盐的逐字节IP哈希、带范围映射的端口全值哈希以及带自适应噪声的保序时间戳匿名化。这些方法旨在平衡隐私保护与数据结构保留。通过评估，证明了该方法在有效保护隐私的同时，仍能支持有意义的安全分析和操作监控。

> **摘要翻译:** 系统和网络事件日志对于安全分析、威胁检测和操作监控至关重要。然而，这些日志通常包含个人身份信息（PII），在共享或分析时引发重大的隐私问题。日志匿名化的一个关键挑战是平衡隐私保护与保留足够的结构以进行有意义的分析。过度激进的匿名化可能会破坏上下文完整性，而弱技术则可能通过链接或推断攻击导致重新识别的风险。本文介绍了新颖的字段特定匿名化方法，以解决这种权衡。对于IP地址，我们提出了一种应用于逐字节级别的基于盐的哈希技术，在确保不可逆性的同时保留了子网和主机结构，以实现跨各种日志条目的关联。对于端口号，带范围映射的全值哈希保持了可解释性。我们还提出了一种使用自适应噪声注入的保序时间戳匿名化方案，该方案模糊了精确时间而不扰乱事件序列。一个实现了这些技术的开源工具已经发布，以支持实际部署和可重复研究。使用熵度量、碰撞率和残余泄露分析进行的评估表明，所提出的方法在有效保护隐私的同时保留了分析效用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [891] [Mitigation of Social Media Platforms Impact on the Users](https://arxiv.org/abs/2507.21181)
> *社交媒体平台对用户影响的缓解*

*Smita Khapre, Sudhanshu Semwal* | **Category: cs.CR, cs.CY, cs.GR** | **Updated: 2025-07-26**

**Keywords:** 社交媒体, 数据隐私, 安全, 去中心化框架, 分形树, L系统

**Comment:** WSCG 2025 33. International Conference on Computer Graphics,
  Visualization and Computer Vision 2025

> **TL;DR:** 本文提出了一种基于分形树和L系统算法的去中心化数据安排框架，以缓解社交媒体平台对用户安全、隐私和数据的影响。

**AI_Comments:** 该论文提出了一种创新的去中心化数据安排框架，利用分形树和L系统算法来解决社交媒体平台带来的用户安全和隐私问题。其创新点在于结合了这些算法来构建一个更安全的数据管理模型。然而，论文目前仅提出了概念，尚未展示其实际效果和性能验证，这有待于未来的研究工作。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体平台虽然提供了诸多便利，但其架构和数据处理（尤其通过人工智能算法）对用户安全、隐私和数据安全构成潜在影响。

**Method:** 提出了一种基于分形树（Fractal-tree）和L系统（L-Systems）算法的去中心化数据安排新框架。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种基于分形树和L系统算法的去中心化数据安排框架，旨在缓解社交媒体平台因其架构、数据处理和AI算法对用户安全、隐私和数据安全造成的潜在负面影响。该框架旨在提供一种新的数据管理方式，以应对现有社交媒体模式可能带来的风险。未来的工作将验证其有效性并探索集成加密算法以进一步增强安全性。

> **摘要翻译:** 社交媒体平台提供了诸多好处，并允许人们为各种事业聚集在一起。许多社区、学术界、政府机构、机构、医疗保健、娱乐和企业都在社交媒体平台上。它们直观且对用户免费。没有社交媒体的生活已变得难以想象。它们的架构和数据处理旨在实现可扩展性、不间断可用性以及个人和协作收入生成。主要地，人工智能算法被用于存储的用户数据上以进行优化和信息流。即使使用元数据，这也可能影响用户安全、隐私和数据安全。本文提出了一种基于分形树和L系统算法的去中心化数据安排新框架，以缓解社交媒体平台的一些影响。未来的工作将侧重于通过将其结果与当前数据库中使用的最先进的安全方法进行比较，来证明新的去中心化框架的有效性。还可以为该框架实现一种加密算法，为每个分支采用新的密钥生成。这将加强数据库安全；例如，如果用户密钥泄露，为每个分支重新生成密钥将通过在所提出的基于L系统的树框架中应用防御机制来保持数据安全。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [926] [Secure Tug-of-War (SecTOW): Iterative Defense-Attack Training with Reinforcement Learning for Multimodal Model Security](https://arxiv.org/abs/2507.22037)
> *安全拔河 (SecTOW)：基于强化学习的多模态模型安全迭代攻防训练*

*Muzhi Dai, Shixuan Liu, Zhiyuan Zhao, Junyu Gao, Hao Sun, Xuelong Li* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 多模态大语言模型安全, 越狱, 强化学习, 攻防训练, SecTOW

**Comment:** 10 pages, 4 figures

> **TL;DR:** 多模态大语言模型（MLLMs）面临越狱输入的安全挑战。本文提出了安全拔河（SecTOW），一种创新的迭代攻防训练方法，通过强化学习提高MLLMs的安全性并保持通用性能。

**AI_Comments:** SecTOW的创新之处在于其采用迭代攻防训练范式，通过强化学习动态生成越狱数据并提升防御能力，有效解决了越狱数据稀疏性和传统方法无法解决内在漏洞的问题。该方法在平衡模型安全性和通用性能方面表现出色，为MLLMs的安全性研究提供了新的视角和有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在应用中取得突破，但其安全性仍是关键挑战，特别是针对旨在绕过安全限制的越狱输入（不安全图像-查询对）。与通用多模态数据相比，此类不安全输入相对稀疏，限制了训练样本的多样性，难以开发出鲁棒的防御模型。现有护栏类方法依赖外部模块，未能解决MLLMs的内在漏洞。而传统监督微调（SFT）常过度拒绝无害输入，损害了通用性能。

**Method:** 本文提出了安全拔河（SecTOW），一种创新的迭代攻防训练方法来增强MLLMs的安全性。SecTOW包含防御者和辅助攻击者两个模块，两者都使用强化学习（GRPO）进行迭代训练。在迭代过程中，攻击者识别防御模型的安全漏洞并扩展越狱数据。扩展的数据随后用于训练防御者，使其能够解决已识别的安全漏洞。此外，设计了用于GRPO的奖励机制，以简化响应标签的使用，减少对复杂生成标签的依赖，并实现合成数据的有效利用。还使用质量监控机制来减轻防御者对无害输入的过度拒绝，并确保攻击者生成的越狱数据的多样性。

**Result:** 在安全特定和通用基准上的实验结果表明，SecTOW显著提高了安全性，同时保留了通用性能。

**Conclusion:** SecTOW通过迭代攻防训练和强化学习，有效提升了多模态大语言模型的安全性，并解决了越狱数据稀疏和性能权衡的问题，同时保持了模型的通用性能。

> **ai_Abstract:** 本文针对多模态大语言模型（MLLMs）面临的越狱攻击和数据稀疏性问题，提出了一种名为“安全拔河”（SecTOW）的迭代攻防训练方法。SecTOW包含一个防御者和一个辅助攻击者，两者通过强化学习（GRPO）协同训练。攻击者负责发现防御漏洞并生成多样化的越狱数据，而防御者则利用这些数据进行学习以增强安全性。该方法通过奖励机制简化了标签依赖，并通过质量监控机制平衡了安全性与模型的通用性能。实验证明，SecTOW能在显著提升MLLMs安全性的同时，保持其原有的通用表现。

> **摘要翻译:** 多模态大语言模型（MLLMs）的快速发展在各种应用中取得了突破，但其安全性仍然是一个严峻的挑战。一个紧迫的问题涉及不安全的图像-查询对——专门设计用于绕过安全限制并从MLLMs中引出意外响应的越狱输入。与一般的多模态数据相比，此类不安全输入相对稀疏，这限制了可用于开发鲁棒防御模型的训练样本的多样性和丰富性。同时，现有的护栏类方法依赖外部模块来强制执行安全约束，但未能解决MLLMs内部的内在漏洞。另一方面，传统的监督微调（SFT）经常过度拒绝无害输入，从而损害了通用性能。鉴于这些挑战，我们提出了安全拔河（SecTOW），一种创新的迭代攻防训练方法，以增强MLLMs的安全性。SecTOW由两个模块组成：一个防御者和一个辅助攻击者，两者都使用强化学习（GRPO）进行迭代训练。在迭代过程中，攻击者识别防御模型的安全漏洞并扩展越狱数据。扩展的数据随后用于训练防御者，使其能够解决已识别的安全漏洞。我们还设计了用于GRPO的奖励机制，以简化响应标签的使用，减少对复杂生成标签的依赖，并实现合成数据的有效利用。此外，还使用质量监控机制来减轻防御者对无害输入的过度拒绝，并确保攻击者生成的越狱数据的多样性。在安全特定和通用基准上的实验结果表明，SecTOW显著提高了安全性，同时保留了通用性能。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [933] [SDD: Self-Degraded Defense against Malicious Fine-tuning](https://arxiv.org/abs/2507.21182)
> *SDD：抵御恶意微调的自降级防御*

*Zixuan Chen, Weikai Lu, Xin Lin, Ziqian Zeng* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-27**

**Keywords:** 大型语言模型, 恶意微调, 安全防御, 自降级防御, 安全对齐

**Comment:** Accepted by ACL2025

> **TL;DR:** SDD是一种防御框架，通过使LLM对有害指令产生高质量但无关的响应，从而在恶意微调时显著降低其整体能力，有效抵御恶意微调攻击。

**AI_Comments:** 这篇论文的创新点在于提出了“自降级防御”这一独特的概念，即通过在正常使用时对有害提示进行“无关化”处理，使得恶意微调反而会削弱模型的整体能力，从而达到防御目的。这种防御机制不同于传统的过滤或检测方法，提供了一种新颖的对抗策略，对于保障开源LLMs的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开放源代码的大型语言模型（LLMs）虽然采用安全对齐方法来抵抗有害指令，但恶意微调可以在有害数据上轻松绕过这些保护措施。因此，需要提出一种对策来抵抗恶意微调攻击。

**Method:** 本文首先从理论上揭示了恶意微调成功的原因，并确定了潜在的防御策略。在此基础上，引入了自降级防御（SDD）框架。SDD鼓励LLMs对有害提示产生高质量但无关的响应。当攻击者尝试恶意微调时，经SDD对齐的LLM的通用能力会显著下降，使其无法遵循有害指令。

**Result:** 实验结果证实了SDD框架在对抗此类攻击方面的有效性。

**Conclusion:** SDD框架能够有效抵御针对大型语言模型的恶意微调攻击，通过降低模型在恶意微调后的通用能力来实现安全。

> **ai_Abstract:** 本文提出了一种名为自降级防御（SDD）的新框架，旨在解决大型语言模型（LLMs）易受恶意微调攻击的问题。研究首先理论分析了恶意微调成功的机制，并在此基础上设计了SDD。SDD通过引导LLMs对有害指令生成高质量但无关的回复，从而在恶意微调尝试时显著降低模型的通用能力，使其无法执行有害指令。实验证明了SDD对这类攻击的有效性。

> **摘要翻译:** 开源大型语言模型（LLMs）通常采用安全对齐方法来抵抗有害指令。然而，最近的研究表明，在有害数据上恶意微调这些LLMs可以轻易绕过这些安全防护。为了对抗这一点，我们从理论上揭示了恶意微调成功的原因，并确定了潜在的防御策略。基于理论分析，我们引入了自降级防御（SDD）框架。SDD鼓励LLMs对有害提示产生高质量但无关的响应。当攻击者尝试恶意微调时，经SDD对齐的LLM的通用能力将显著下降，使其无法遵循有害指令。我们的实验结果证实了SDD对抗此类攻击的有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [2] [Shapley Uncertainty in Natural Language Generation](https://arxiv.org/abs/2507.21406)
> *自然语言生成中的Shapley不确定性*

*Meilin Zhu, Gaojie Jin, Xiaowei Huang, Lijun Zhang* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** Shapley不确定性, 自然语言生成, 大型语言模型, 不确定性度量, 问答系统

**Comment:** 

> **TL;DR:** 本文提出了一种基于Shapley的不确定性度量方法，用于更准确地预测大型语言模型在问答任务中的性能，解决了现有语义熵度量依赖阈值的问题。

**AI_Comments:** 本文的创新点在于提出了一个基于Shapley的不确定性度量，它超越了传统语义熵度量对阈值的依赖，能够更好地捕捉语义关系的连续性。此外，文章还为有效的不确定性度量建立了三个基本属性，并证明了其方法的有效性，这对于提升大型语言模型的可信度和对齐性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在问答任务中，判断何时信任大型语言模型（LLM）的输出至关重要。Kuhn et al. (2023) 引入的语义熵作为一种不确定性度量，主要依赖于设置阈值来衡量语义等价关系，而本文旨在提出一个更细致的框架来超越这种阈值依赖性。

**Method:** 本文提出了一种基于Shapley的不确定性度量，旨在捕获语义关系的连续性。作者建立了表征有效不确定性度量的三个基本属性，并证明所提出的Shapley不确定性满足这些标准。

**Result:** 通过广泛的实验证明，与类似的基线度量相比，本文提出的Shapley不确定性在问答及其他数据集中能更准确地预测大型语言模型（LLM）的性能。

**Conclusion:** 本文提出的Shapley不确定性度量能够更准确地预测LLM的性能，并且满足了有效不确定性度量的基本属性，为LLM的信任度评估提供了一个更细致的框架。

> **ai_Abstract:** 本文针对大型语言模型（LLM）在问答任务中输出信任度的问题，提出了一种新的基于Shapley的不确定性度量方法。该方法旨在克服现有语义熵度量对阈值的依赖，通过捕获语义关系的连续性来提供更细致的不确定性评估。研究确立了有效不确定性度量的三个基本属性，并证明所提出的Shapley不确定性满足这些属性。实验结果表明，与现有基线方法相比，Shapley不确定性在预测LLM性能方面表现出更高的准确性。

> **摘要翻译:** 在问答任务中，确定何时信任输出对于大型语言模型（LLM）的对齐至关重要。Kuhn et al. (2023) 通过纳入相同含义的语言不变性，引入了语义熵作为一种不确定性度量。它主要依赖于设置阈值来衡量语义等价关系的水平。我们提出了一个更细致的框架，通过开发一种基于Shapley的不确定性度量来超越这种阈值处理，该度量捕获了语义关系的连续性。我们建立了表征有效不确定性度量的三个基本属性，并证明我们的Shapley不确定性满足这些标准。通过广泛的实验，我们证明我们的Shapley不确定性比类似的基线度量更能准确地预测问答及其他数据集中的LLM性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [8] [Project Patti: Why can You Solve Diabolical Puzzles on one Sudoku Website but not Easy Puzzles on another Sudoku Website?](https://arxiv.org/abs/2507.21137)
> *Patti项目：为什么你可以在一个数独网站上解决地狱级难题，却无法在另一个数独网站上解决简单难题？*

*Arman Eisenkolb-Vaithyanathan* | **Category: cs.AI, I.2.8** | **Updated: 2025-07-22**

**Keywords:** 数独难度, SAT问题, Nishio算法, 通用评级系统, 结构复杂性

**Comment:** 24 pages, 8 Figures

> **TL;DR:** 本文提出了两种新的数独难度度量标准，并构建了一个通用的数独难度评级系统，以解决不同数独网站难度评级不一致的问题。

**AI_Comments:** 该论文的创新点在于提出了两种新颖且互补的数独难度度量方法，一种基于计算复杂性理论（SAT），另一种模拟人类认知过程。通过结合这两种方法，并构建一个通用的、跨网站的难度评级系统，有效解决了数独爱好者长期面临的“难度不统一”问题。其重要性在于为数独难题的量化分析提供了新的视角和工具，并可能促进更一致的用户体验。此外，为初学者提供解题算法也增加了实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在回答“不同数独网站的数独难度评级由什么构成？”这个问题，并解决不同数独网站之间数独难度评级不一致的问题。

**Method:** 本文提出了两种方法来表征数独难度：1. 将数独难题转换为可满足性（SAT）问题，并从SAT子句长度分布中导出第一个难度指标。2. 模拟人类数独解题者，通过在回溯算法Nishio中交织四种流行的数独策略，并通过计算策略应用次数来计算第二个难度指标。作者使用这两种指标分析了来自五个流行网站的数千个数独难题，并通过Spearman秩相关系数评估了指标与网站标记难度之间的关系。最后，构建了一个基于这两种指标的简单无监督分类器，形成一个通用的评级系统。

**Result:** 结果显示，所提出的指标与5个网站中的4个网站的难度级别存在强相关性。构建的通用评级系统能够将个体谜题和来自不同数独网站的整个难度级别分为三个类别：通用简单、通用中等和通用困难，从而实现数独网站间难度的一致映射。实验结果表明，对于5个数独网站中的4个，通用分类与网站标记的难度级别非常吻合。

**Conclusion:** 本文提出了两种新的数独难度度量标准和一个通用的数独难度评级系统，能够有效统一不同数独网站的难度评级。此外，还提出了一个可供数独初学者使用的解题算法。

> **ai_Abstract:** 本文针对不同数独网站难度评级不一致的问题，提出了两种新的数独难度度量标准。第一种基于将数独转换为SAT问题并分析子句长度分布；第二种通过模拟人类解题策略（Nishio算法）并计算策略应用次数。作者利用这两种指标分析了大量数独谜题，发现它们与网站原有难度评级有强相关性。在此基础上，构建了一个无监督分类器，形成了一个通用的三级（简单、中等、困难）数独难度评级系统，实验证明该系统能有效统一不同网站的难度标准。文章末尾还提供了一个数独解题算法。

> **摘要翻译:** 本文试图回答“不同数独网站的数独难度评级由什么构成？”这个问题。我提出了两种新的度量标准来表征数独难度，这两种方法都可以解决每一个数独难题。第一种方法是基于将数独难题转换为其对应的可满足性（SAT）问题。第一个提出的度量标准源自SAT子句长度分布，它捕捉了数独难题的结构复杂性，包括给定数字的数量及其所在单元格。第二种方法通过在名为Nishio的回溯算法中交织四种流行的数独策略来模拟人类数独解题者。第二个度量标准通过计算随机Nishio的回溯迭代中数独策略应用次数来计算。利用这两个度量标准，我分析了来自五个流行网站的一千多个数独难题，以表征每个网站的每个难度级别。我使用Spearman秩相关系数评估了所提出的度量标准与网站标记难度级别之间的关系，发现5个网站中有4个存在强相关性。我使用基于两种提出的度量标准的简单无监督分类器构建了一个通用评级系统。该评级系统能够将来自不同数独网站的个体谜题和整个难度级别分为三类——通用简单、通用中等和通用困难——从而实现数独网站间难度的一致映射。实验结果表明，对于5个数独网站中的4个，通用分类与网站标记的难度级别非常吻合。最后，我提出了一种可供数独初学者使用的解题算法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [21] [Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence](https://arxiv.org/abs/2507.22197)
> *通过系统性实现可解释性：人工智能的硬系统性挑战*

*Matthieu Queloz* | **Category: cs.AI, cs.CL, cs.CY** | **Updated: 2025-07-29**

**Keywords:** 可解释性, 系统性, 人工智能, 联结主义, 硬系统性挑战

**Comment:** 39 pages; final, published version

> **TL;DR:** 本文认为AI的可解释性是系统性这一更广泛理想的一部分，重新定义了超越福多尔观点的系统性，并基于系统化的基本原理提出了AI的“硬系统性挑战”。

**AI_Comments:** 这篇论文对人工智能的可解释性进行了有价值的概念性重构，将其置于一个更深刻、更具挑战性的“系统性”理想之中。其创新之处在于超越了传统上福多尔对联结主义的挑战，提出了一个细致入微的系统性框架，并基于系统化的基本原理引入了“硬系统性挑战”。这为人工智能能力讨论提供了哲学深度，暗示仅仅实现可解释性可能不足以让AI体现真正的理性或科学思维。它促使人们对指导AI开发的基本原则进行更深入的反思。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在将人工智能的可解释性置于更广泛的“系统性”概念中进行重新定义。它挑战了传统上对联结主义的“系统性挑战”，并试图基于对系统性及其基本原理更丰富的理解，为人工智能设定一个更高要求的理想。

**Method:** 该论文提出可解释性是系统性的一个方面。它提供了一个概念框架来区分“思想的系统性”的四种含义，并利用这些区分来化解系统性与联结主义之间感知的紧张关系。作者确定了系统化的五个基本原理并将其应用于人工智能模型，从而引出了“硬系统性挑战”。论文还论证了系统化本身的需求应由系统化的基本原理来规范，从而形成了对人工智能模型系统性需求的动态理解。

**Result:** 论文提出了一种比福多尔概念要求更高的、更丰富的系统性概念。它化解了系统性与联结主义之间感知的紧张关系。通过识别并应用系统化的五个基本原理于人工智能，揭示了“硬系统性挑战”。论文还形成了一种对人工智能模型系统性需求的动态理解，指明了人工智能模型需要在何时以及在何种程度上展现系统性。

**Conclusion:** 论文总结认为，人工智能中系统化的需求应由其潜在的基本原理来规范，从而对人工智能模型何时以及如何需要展现系统性以达到超越仅仅可解释性的更高理想，形成了一种动态理解。

> **ai_Abstract:** 本文认为，人工智能的可解释性是更广泛的系统性理想的一个子集。它提出了一个更丰富的系统性概念，区分了“思想的系统性”的四种含义，这有助于调和系统性与联结主义之间的关系，并超越了福多尔的观点。通过识别系统化的五个基本原理并将其应用于人工智能，本文引入了“硬系统性挑战”，并得出结论认为，人工智能系统性的需求应由这些基本原理动态指导，从而定义了人工智能应何时以及如何展现系统性。

> **摘要翻译:** 这篇论文认为，可解释性只是塑造我们对人工智能（AI）期望的更广泛理想的一个方面。从根本上说，问题在于AI在多大程度上表现出系统性——不仅仅是能够感知思想是如何由可重组的成分构成的，而是在努力形成一个一致、连贯、全面且简约原则的整合思想体系。这种更丰富的系统性概念被“系统性挑战”对联结主义的长期影响所掩盖，根据该挑战，网络架构与福多尔及其同事所称的“思想的系统性”根本上是对立的。我提出了一个关于“思想的系统性”的概念框架，区分了该短语的四种含义。我利用这些区分来化解系统性与联结主义之间感知的紧张关系，并表明历史上塑造我们对何谓理性、权威和科学思想的认识的系统性概念比福多尔的概念要求更高。然后我论证，为了确定我们是否有理由要求AI模型达到这种系统性理想，我们必须审视系统化的基本原理，并探讨它们在多大程度上适用于AI模型。我确定了五个这样的基本原理并将其应用于AI。这揭示了“硬系统性挑战”。然而，系统化本身的需求需要由系统化的基本原理来规范。这产生了对思想系统化需求的动态理解，它告诉我们AI模型需要达到何种程度的系统性以及何时需要。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [25] [PHAX: A Structured Argumentation Framework for User-Centered Explainable AI in Public Health and Biomedical Sciences](https://arxiv.org/abs/2507.22009)
> *PHAX：一种面向公共卫生和生物医学领域以用户为中心的解释性AI结构化论证框架*

*Bahar İlgen, Akshat Dubey, Georges Hattab* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 可解释人工智能, 结构化论证, 公共卫生, 生物医学, 以用户为中心的AI

**Comment:** Preprint. Under review

> **TL;DR:** PHAX是一个结构化论证框架，旨在为公共卫生领域提供以用户为中心的解释性AI，生成清晰、情境化和特定受众的解释。

**AI_Comments:** PHAX的创新之处在于其结构化论证方法应用于XAI，直接解决了在公共卫生等敏感领域中对以人为本、情境感知和特定受众解释的关键需求。通过将形式推理与自适应沟通相结合，它提供了一种比传统XAI方法更健壮和适应性更强的解决方案，从而促进了更大的信任和透明度。

<details>
  <summary>Details</summary>

**Motivation:** 在公共卫生和生物医学领域，AI系统除了准确预测外，还需要提供透明、可信和对社会负责的解释。现有的可解释人工智能（XAI）方法缺乏结构和适应性，无法满足包括临床医生、政策制定者和公众在内的多样化健康利益相关者的需求。

**Method:** 本文介绍了PHAX，一个公共卫生论证和可解释性框架。PHAX是一个多层架构，结合了可反驳推理、自适应自然语言技术和用户建模，以产生情境感知、面向特定受众的理由。它利用结构化论证来支持AI驱动的决策制定、证明建议的合理性以及实现跨用户类型的交互式对话。

**Result:** PHAX通过用例展示了其适用性，例如医疗术语简化、医患沟通和政策合理化。它特别展示了简化决策如何被建模为论证链，并根据用户专业知识进行个性化，从而增强了可解释性和信任。

**Conclusion:** PHAX通过将形式推理方法与沟通需求相结合，为公共卫生领域透明、以人为本的AI愿景做出了贡献。

> **ai_Abstract:** 本文介绍了PHAX，一个新颖的结构化论证框架，旨在公共卫生和生物医学领域实现以用户为中心的可解释人工智能（XAI）。为解决AI解释需要超越单纯预测的透明度和可信度问题，PHAX采用多层架构，结合了可反驳推理、自适应自然语言处理和用户建模。它为AI输出生成情境感知和特定受众的理由，从而增强决策制定、建议的合理性以及交互式对话。该框架的实用性通过医疗术语简化、医患沟通和政策合理化等用例得到验证，突出了其个性化解释并提高可解释性和信任的能力。

> **摘要翻译:** 确保AI驱动的公共卫生和生物医学系统具有透明度和信任，不仅仅需要准确的预测，还需要清晰、情境化和对社会负责的解释。尽管可解释人工智能（XAI）在特征归因和模型可解释性等领域取得了进展，但大多数方法仍然缺乏应对包括临床医生、政策制定者和公众在内的各种健康利益相关者所需的结构和适应性。我们引入了PHAX——一个公共卫生论证和可解释性框架——它利用结构化论证为AI输出生成以人为中心的解释。PHAX是一个多层架构，结合了可反驳推理、自适应自然语言技术和用户建模，以产生情境感知、面向特定受众的理由。更具体地说，我们展示了论证如何通过支持AI驱动的决策、证明建议的合理性以及实现跨用户类型的交互式对话来增强可解释性。我们通过医疗术语简化、医患沟通和政策合理化等用例展示了PHAX的适用性。特别是，我们展示了简化决策如何被建模为论证链并根据用户专业知识进行个性化——从而增强了可解释性和信任。通过将形式推理方法与沟通需求相结合，PHAX为公共卫生领域透明、以人为本的AI愿景做出了贡献。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [28] [CoEx -- Co-evolving World-model and Exploration](https://arxiv.org/abs/2507.22281)
> *CoEx -- 世界模型与探索的协同演化*

*Minsoo Kim, Seung-won Hwang* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-29**

**Keywords:** LLM智能体, 世界模型, 规划, 探索, 神经符号

**Comment:** 

> **TL;DR:** CoEx是一个分层LLM智能体，通过动态更新世界模型来协同演化规划和探索，解决了现有智能体世界模型静态导致规划错误的问题，并在多个复杂任务中表现优于现有范式。

**AI_Comments:** CoEx的创新点在于其分层架构和动态更新的神经符号世界模型，这有效地解决了现有LLM智能体中世界模型静态导致的规划与真实世界状态错位的问题。通过将子目标经验整合到持久的神经符号信念状态中，CoEx能够持续学习和适应，从而显著提升了智能体在复杂任务中的规划和探索能力，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM智能体在规划时依赖预训练获得的静态内部世界模型，这导致模型与真实世界状态逐渐不一致，从而产生发散和错误的规划。

**Method:** 本文提出了一个分层智能体架构CoEx。CoEx通过分层状态抽象，使LLM规划能够与动态更新的世界模型协同演化。它利用LLM推理来编排由子目标组成的动态计划，并通过学习机制将这些子目标经验持续整合到持久的神经符号信念状态（包括文本推理和基于代码的符号记忆）中，以更新其世界模型。

**Result:** CoEx在ALFWorld、PDDL和Jericho等包含丰富环境和复杂任务的多种智能体场景中进行了评估。实验表明，CoEx在规划和探索方面优于现有智能体范式。

**Conclusion:** CoEx通过其分层架构和动态世界模型更新机制，有效解决了LLM智能体中静态世界模型导致的规划偏差问题，显著提升了智能体在复杂环境中的规划和探索能力。

> **ai_Abstract:** CoEx是一种新型分层LLM智能体架构，旨在解决现有LLM智能体因静态世界模型导致的规划错误问题。CoEx通过允许LLM规划与动态更新的神经符号世界模型协同演化，该模型结合了文本推理和代码记忆，并利用LLM推理来编排子目标计划。实验证明，CoEx在复杂环境下的规划和探索任务中表现优于现有智能体范式。

> **摘要翻译:** 现代LLM智能体中的规划依赖于LLM作为内部世界模型的利用，该模型在预训练期间获得。然而，现有智能体设计未能有效地将新观测结果同化到世界模型的动态更新中。这种对LLM静态内部世界模型的依赖，逐渐容易与底层的真实世界状态发生错位，导致生成发散和错误的规划。我们引入了一种分层智能体架构CoEx，其中分层状态抽象允许LLM规划与动态更新的世界模型协同演化。CoEx通过使用LLM推理来编排由子目标组成的动态计划，并与世界进行交互，其学习机制将这些子目标经验持续整合到神经符号信念状态（由文本推理和基于代码的符号记忆组成）形式的持久世界模型中。我们在ALFWorld、PDDL和Jericho等一系列涉及丰富环境和复杂任务的智能体场景中评估了我们的智能体。我们的实验表明，CoEx在规划和探索方面优于现有智能体范式。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [35] [LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models](https://arxiv.org/abs/2507.22359)
> *LLM-Crowdsourced：一种无基准的大语言模型相互评估范式*

*Qianhong Guo, Wei Xie, Xiaofang Cai, Enze Wang, Shuoyoucheng Ma, Kai Chen, Xiaofeng Wang, Baosheng Wang* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 大语言模型评估, 无基准, LLM-Crowdsourced, 相互评估, 模型性能

**Comment:** 

> **TL;DR:** 提出LLM-Crowdsourced，一种无基准的LLM相互评估范式，解决现有评估问题并揭示新发现。

**AI_Comments:** 该论文提出了一种创新的、无基准的LLM评估方法，通过让LLM进行自我和相互评估，有效规避了传统评估方法的局限性，如数据污染和主观性。其亮点在于利用LLM的生成和理解能力来构建一个动态、透明的评估体系。此外，该方法不仅提供了一种新的评估范式，还揭示了LLM的一些内在行为模式，例如记忆式回答，这对于深入理解LLM的能力和局限性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有大语言模型（LLMs）的评估方法存在数据污染、黑盒操作和主观偏好等问题，难以全面评估LLMs的真实能力。

**Method:** 提出LLM-Crowdsourced，一种无基准的评估范式。该方法利用LLM生成问题、独立回答并相互评估，并整合了动态、透明、客观和专业四项关键评估标准。

**Result:** 实验验证了该方法在区分LLM性能方面的优势。研究揭示了多项新发现：Gemini在原创和专业问题设计能力上表现最佳；部分LLM出现“基于记忆的回答”；LLM评估结果表现出高度一致性（鲁棒性）。

**Conclusion:** LLM-Crowdsourced范式有效解决了现有LLM评估方法的挑战，并能够发现传统方法难以捕捉的LLM特性。

> **ai_Abstract:** 该论文提出了一种名为LLM-Crowdsourced的无基准评估范式，旨在解决现有大型语言模型（LLM）评估方法中存在的数据污染、黑盒操作和主观偏好等问题。该范式利用LLM自身生成问题、独立回答并进行相互评估，并整合了动态、透明、客观和专业四项关键评估标准。实验结果表明，该方法能有效区分不同LLM的性能，并发现了一些传统方法难以检测到的LLM特性，例如Gemini在问题设计上的优势、部分LLM的“记忆式回答”行为以及评估结果的高一致性。

> **摘要翻译:** 尽管大型语言模型（LLMs）在各种任务中展现出卓越的能力，但评估其能力仍然是一项具有挑战性的任务。现有的评估方法存在数据污染、黑盒操作和主观偏好等问题。这些问题使得全面评估LLMs的真实能力变得困难。为了应对这些挑战，我们提出了一种新颖的无基准评估范式——LLM-Crowdsourced。它利用LLM生成问题、独立回答并相互评估。该方法整合了现有评估方法无法同时满足的四项关键评估标准：动态、透明、客观和专业。在数学和编程领域的八个主流LLM上进行的实验验证了我们方法在区分LLM性能方面的优势。此外，我们的研究揭示了一些传统方法难以检测到的新发现，包括但不限于：（1）Gemini在原创和专业问题设计能力方面表现最佳；（2）一些LLM通过将问题误认为结构相似的熟悉问题来表现出“基于记忆的回答”；（3）LLM评估结果表现出高度一致性（鲁棒性）。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [50] [The Geometry of Harmfulness in LLMs through Subconcept Probing](https://arxiv.org/abs/2507.21141)
> *通过子概念探测揭示大型语言模型中有害性的几何结构*

*McNair Shah, Saleena Angeline, Adhitya Rajendra Kumar, Naitik Chheda, Kevin Zhu, Vasu Sharma, Sean O'Brien, Will Cai* | **Category: cs.AI** | **Updated: 2025-07-23**

**Keywords:** 大型语言模型, 有害性, 子概念探测, 概念子空间, 干预

**Comment:** 

> **TL;DR:** 本文提出了一种多维框架，通过学习55个有害性子概念的线性探测器，在LLM内部识别并干预有害内容。研究发现有害性子空间是低秩的，并且通过主导方向干预可以显著消除有害性，同时对模型效用影响很小。

**AI_Comments:** 该论文的创新之处在于提出了一个基于“子概念探测”和“概念子空间”的框架来理解和干预LLMs中的有害性。发现有害性子空间具有低秩特性，并通过主导方向干预能够有效降低有害性且对模型效用影响甚微，这为LLMs的安全性和可控性提供了有前景的解决方案。该方法为未来LLMs的审计和强化提供了实用的工具。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）的快速发展，理解和有效遏制其有害行为的需求日益增长。

**Method:** 本文引入了一个多维框架，用于探测和干预模型内部的有害内容。具体而言，针对55个不同的有害性子概念（例如，种族仇恨、就业诈骗、武器），研究人员学习了一个线性探测器，从而在激活空间中得到了55个可解释的方向。这些方向共同构成了一个有害性子空间。随后，研究人员测试了从模型内部完全消除整个子空间，以及在该子空间的主导方向进行干预和消除的效果。

**Result:** 研究发现，这些方向共同构成的有害性子空间具有显著的低秩特性。此外，通过对该子空间的主导方向进行干预，可以几乎消除有害性，同时对模型效用的降低幅度很小。

**Conclusion:** 研究结果推进了“概念子空间为LLM行为提供了可扩展的视角”这一新兴观点，并为社区提供了实用的工具，以审计和强化未来几代语言模型。

> **ai_Abstract:** 本文提出了一个多维框架，用于探测和干预大型语言模型（LLMs）中的有害内容。通过为55个有害性子概念学习线性探测器，研究人员发现了激活空间中一个低秩的有害性子空间。实验表明，通过对该子空间的主导方向进行干预，可以有效消除有害性，同时保持模型效用。这为理解和控制LLM行为提供了新的视角和实用工具。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展加剧了理解和可靠遏制其有害行为的需求。我们引入了一个多维框架，用于探测和干预模型内部的有害内容。对于55个不同的有害性子概念（例如，种族仇恨、就业诈骗、武器），我们学习了一个线性探测器，从而在激活空间中得到了55个可解释的方向。总的来说，这些方向构成了一个有害性子空间，我们发现它具有显著的低秩特性。随后，我们测试了从模型内部完全消除整个子空间，以及在该子空间的主导方向进行干预和消除的效果。我们发现，主导方向干预可以在有害性几乎消除的同时，对模型效用的降低幅度很小。我们的研究结果推进了“概念子空间为LLM行为提供了可扩展的视角”这一新兴观点，并为社区提供了实用的工具，以审计和强化未来几代语言模型。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [52] [Unrolling Dynamic Programming via Graph Filters](https://arxiv.org/abs/2507.21705)
> *通过图滤波器展开动态规划*

*Sergio Rozada, Samuel Rey, Gonzalo Mateos, Antonio G. Marques* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 动态规划, 图滤波器, 贝尔曼方程, 策略迭代, 马尔可夫决策过程

**Comment:** 

> **TL;DR:** 本文提出BellNet，一个基于图滤波器的可学习参数模型，通过展开和截断策略迭代来解决动态规划中贝尔曼方程的计算开销问题，并在实验中表现出高效性。

**AI_Comments:** 这篇论文通过将动态规划与图信号处理相结合，提供了一个新颖的视角来解决贝尔曼方程的计算挑战。将策略迭代解释为图滤波器级联的创新性方法，不仅可能提高计算效率，还为理解和设计更复杂的RL算法提供了新的理论框架，具有很好的迁移性。

<details>
  <summary>Details</summary>

**Motivation:** 标准的策略迭代等方法在解决大型状态-动作空间或涉及长期依赖的马尔可夫决策过程（MDP）问题时，计算成本高昂。

**Method:** 本文提出BellNet，一个通过展开和截断策略迭代形成的可学习参数模型。BellNet通过最小化贝尔曼误差进行训练。它将MDP的转移概率矩阵视为加权有向图的邻接矩阵，并借鉴图信号处理，将BellNet解释为非线性图滤波器的级联。

**Result:** 初步实验表明，在网格状环境中，BellNet能够以经典方法所需迭代次数的一小部分有效逼近最优策略。

**Conclusion:** BellNet提供了一种简洁、可迁移且统一的策略和价值迭代表示，并在推理过程中明确控制复杂度，能够高效逼近最优策略。

> **ai_Abstract:** 本文提出BellNet，一种新颖的可学习参数模型，旨在解决动态规划中贝尔曼方程求解的计算效率问题。BellNet通过展开和截断策略迭代过程，并将其解释为非线性图滤波器的级联。这种方法利用图信号处理的视角，将MDP的转移概率矩阵视为图的邻接矩阵，从而实现了策略和价值迭代的统一且高效的表示。初步实验证明，BellNet在逼近最优策略方面比传统方法更高效。

> **摘要翻译:** 动态规划（DP）是许多工程领域中使用的基本工具。DP的主要目标是为给定的马尔可夫决策过程（MDP）求解贝尔曼最优方程。像策略迭代这样的标准方法利用这些方程的定点性质进行迭代求解。然而，当状态-动作空间很大或问题涉及长期依赖时，这些算法的计算成本可能很高。本文提出了一种新方法，通过展开和截断策略迭代，形成一个可学习的参数模型，称为BellNet，我们训练它以最小化从随机值函数初始化开始的贝尔曼误差。将MDP的转移概率矩阵视为加权有向图的邻接矩阵，我们从图信号处理中汲取灵感，将BellNet解释（并紧凑地重新参数化）为非线性图滤波器的级联。这种全新的视角促进了策略和价值迭代的简洁、可迁移和统一的表示，并在推理过程中明确控制复杂度。在网格状环境中进行的初步实验表明，BellNet能够以经典方法所需迭代次数的一小部分有效逼近最优策略。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [58] [Assistax: A Hardware-Accelerated Reinforcement Learning Benchmark for Assistive Robotics](https://arxiv.org/abs/2507.21638)
> *Assistax：一个用于辅助机器人的硬件加速强化学习基准*

*Leonard Hinckeldey, Elliot Fosong, Elle Miller, Rimvydas Rubavicius, Trevor McInroe, Patricia Wollstadt, Christiane B. Wiebel-Herboth, Subramanian Ramamoorthy, Stefano V. Albrecht* | **Category: cs.AI, cs.LG, cs.RO** | **Updated: 2025-07-29**

**Keywords:** 强化学习, 辅助机器人, 硬件加速, 基准, 多智能体强化学习

**Comment:** Accepted for the Coordination and Cooperation in Multi-Agent
  Reinforcement Learning Workshop at the Reinforcement Learning Conference 2025

> **TL;DR:** Assistax是一个硬件加速的强化学习基准，旨在推动辅助机器人领域的RL研究，通过多智能体RL模拟人机交互。

**AI_Comments:** Assistax的创新之处在于其将硬件加速（通过JAX）引入强化学习基准，显著提高了模拟效率，这对于计算密集型的具身机器人任务至关重要。其次，它通过多智能体强化学习来模拟辅助机器人与人类患者之间的复杂交互，这比传统游戏基准更能反映真实世界的挑战。该工作填补了RL基准在真实世界具身应用，特别是辅助机器人领域的空白，为未来的研究提供了重要的、高效的平台。

<details>
  <summary>Details</summary>

**Motivation:** 现有的强化学习基准多以游戏为主，难以直接应用于真实世界的具身应用。为了使RL基准多样化并解决具身交互场景中出现的复杂性，特别是辅助机器人任务中的挑战，作者提出了Assistax。

**Method:** 论文引入了Assistax，一个开源基准，利用JAX的硬件加速在基于物理的模拟中实现显著提速。它通过多智能体强化学习（MARL）概念化辅助机器人与活跃人类患者之间的交互，训练多样化的伙伴智能体，以测试具身机器人智能体的零样本协调能力。论文还对流行的连续控制RL和MARL算法进行了广泛评估和超参数调优，以提供可靠的基线。

**Result:** Assistax在矢量化训练运行时，相比基于CPU的替代方案，开环挂钟时间快了高达370倍。它为流行的连续控制RL和MARL算法提供了可靠的基线。

**Conclusion:** Assistax被确立为一个实用的基准，用于推进辅助机器人领域的强化学习研究。

> **ai_Abstract:** Assistax是一个开源的硬件加速强化学习基准，旨在解决辅助机器人领域具身交互的复杂性。它利用JAX实现物理模拟的加速，并采用多智能体RL模拟人机交互，以测试机器人的零样本协调能力。Assistax在速度上比CPU方案快370倍，并提供了可靠的RL和MARL算法基线，是推进辅助机器人RL研究的实用工具。

> **摘要翻译:** 强化学习（RL）算法的发展在很大程度上是由雄心勃勃的挑战任务和基准驱动的。游戏主导了RL基准，因为它们提出了相关的挑战，运行成本低廉且易于理解。虽然围棋和Atari等游戏带来了许多突破，但它们通常不能直接转化为真实世界的具身应用。认识到RL基准多样化的必要性以及解决具身交互场景中出现的复杂性，我们引入了Assistax：一个旨在解决辅助机器人任务中出现的挑战的开源基准。Assistax利用JAX的硬件加速，在基于物理的模拟中显著加速学习。在开环挂钟时间方面，与基于CPU的替代方案相比，Assistax在矢量化训练运行时速度提高了高达370倍。Assistax使用多智能体RL将辅助机器人与活跃人类患者之间的交互概念化，以训练一群多样化的伙伴智能体，从而测试具身机器人智能体的零样本协调能力。对流行的连续控制RL和MARL算法进行广泛评估和超参数调优，提供了可靠的基线，并将Assistax确立为推进辅助机器人RL研究的实用基准。代码可在以下网址获取：https://github.com/assistive-autonomy/assistax。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [63] [The Incomplete Bridge: How AI Research (Mis)Engages with Psychology](https://arxiv.org/abs/2507.22847)
> *不完整的桥梁：人工智能研究如何（误）接触心理学*

*Han Jiang, Pengda Wang, Xiaoyuan Yi, Xing Xie, Ziang Xiao* | **Category: cs.AI, cs.CL, cs.CY** | **Updated: 2025-07-30**

**Keywords:** AI研究, 心理学, 跨学科整合, 大型语言模型, 误用

**Comment:** 

> **TL;DR:** 本研究分析了2023年至2025年间AI顶会中1006篇与LLM相关的论文及其引用的2544篇心理学文献，以探讨AI研究与心理学之间的跨学科结合模式、常引用领域、未充分探索领域以及心理学理论的误用，并提供更有效整合的指导，旨在促进AI与心理学更深层次的合作。

**AI_Comments:** 这项研究的创新之处在于其大规模的数据分析，涵盖了AI顶会中数千篇论文及其引用的心理学文献，为AI与心理学之间的跨学科互动提供了一个全面的量化视角。其重要性在于，它不仅揭示了当前AI研究中对心理学理论的吸收和误用情况，还为未来的研究指明了方向，有助于弥合两个领域之间的“不完整桥梁”，促进AI系统更合理、更深入地借鉴人类智能的洞察。

<details>
  <summary>Details</summary>

**Motivation:** 社会科学，特别是心理学，积累了丰富的理论和方法来研究人类思维和行为，并为人工智能系统的设计和理解提供了宝贵见解。本研究旨在探讨AI研究与心理学之间的跨学科协同作用，识别当前的整合模式、未充分探索的领域以及心理学理论在AI研究中的误用情况，并提供改进指导。

**Method:** 本研究分析了2023年至2025年间在顶级AI会议上发表的1,006篇与大型语言模型（LLM）相关的论文，以及这些论文引用的2,544篇心理学出版物。通过分析，识别了跨学科整合的关键模式、最常被引用的心理学领域，并强调了仍未充分探索的领域。此外，还考察了心理学理论/框架是如何被操作化和解释的，识别了常见的误用类型。

**Result:** 分析结果揭示了AI与心理学之间跨学科整合的关键模式，定位了最常被引用的心理学领域，并指出了仍未充分探索的领域。研究还识别了心理学理论/框架在AI研究中常见的误用类型，并提供了更有效整合的指导。

**Conclusion:** 本研究为AI和心理学之间的跨学科互动提供了一份全面的图谱，从而有助于促进更深层次的合作并推进AI系统的发展。

> **ai_Abstract:** 本研究旨在探讨人工智能（AI）研究与心理学之间的跨学科互动，特别关注大型语言模型（LLM）领域。通过分析2023年至2025年间AI顶会中的1006篇LLM相关论文及其引用的2544篇心理学文献，研究识别了跨学科整合模式、最常引用的心理学领域和未充分探索的领域。此外，研究还审查了心理学理论在AI研究中的操作化和解释方式，指出了常见的误用，并提供了改进整合的指导。这项工作旨在为AI与心理学之间的合作提供全面视图，以促进未来的深入协作和AI系统的发展。

> **摘要翻译:** 社会科学积累了丰富的理论和方法来研究人类思维和行为，同时为人工智能（AI）系统的设计和理解提供了宝贵的见解。本研究以心理学为突出案例，通过分析2023年至2025年间在顶级AI会议上发表的1,006篇与大型语言模型（LLM）相关的论文及其引用的2,544篇心理学出版物，探讨了AI与该领域之间的跨学科协同作用。通过我们的分析，我们识别了跨学科整合的关键模式，定位了最常被引用的心理学领域，并强调了仍未充分探索的领域。我们进一步审查了心理学理论/框架是如何被操作化和解释的，识别了常见的误用类型，并为更有效的整合提供了指导。我们的工作提供了一份AI与心理学之间跨学科互动的全面图谱，从而促进更深层次的合作并推进AI系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [65] [Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects](https://arxiv.org/abs/2507.21407)
> *图增强大型语言模型智能体：当前进展与未来展望*

*Yixin Liu, Guibin Zhang, Kun Wang, Shiyuan Li, Shirui Pan* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型智能体, 图增强, 规划, 记忆, 多智能体系统

**Comment:** 15 pages, 7 figures

> **TL;DR:** 本文全面概述了图增强大型语言模型智能体（GLA）的当前进展，并指出了未来研究方向，旨在解决LLM智能体在规划、记忆和工具使用方面的局限性。

**AI_Comments:** 这篇综述文章非常及时地梳理了图增强大型语言模型智能体（GLA）这一新兴且快速发展的领域。其创新之处在于系统地将GLA方法按照LLM智能体的核心功能进行分类，并深入探讨了图在增强这些功能（如规划、记忆、工具使用和多智能体协调）中的具体作用。这为研究人员提供了一个清晰的框架来理解当前进展。文章的重要性体现在它不仅总结了现有工作，更明确指出了未来的研究方向，例如提高结构适应性、实现统一、可扩展和多模态的GLA系统，这对于推动该领域的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLM）智能体在许多应用中表现出色，但它们在可靠规划、长期记忆、工具管理和多智能体协调等关键智能体程序中存在局限性。鉴于图增强LLM智能体（GLA）研究的快速增长和碎片化，需要一个及时且全面的概述来整合现有进展并指明未来方向。

**Method:** 本文通过提供对图增强大型语言模型智能体（GLA）研究的全面概述来解决上述问题。具体方法包括：1. 根据主要功能（规划、记忆、工具使用）对现有GLA方法进行分类。2. 分析图和图学习算法如何促进每个功能。3. 讨论GLA解决方案如何促进多智能体系统（MAS）的编排、效率优化和可信赖性。4. 提出未来研究的关键方向，包括提高结构适应性以及实现统一、可扩展和多模态的GLA系统。

**Result:** 本文提供了一个关于图增强大型语言模型智能体（GLA）最新进展的全面概述，并成功地将现有方法根据其在LLM智能体系统中的主要功能（如规划、记忆和工具使用）进行了分类。它还分析了图和图学习算法如何增强这些功能，并讨论了GLA在多智能体系统中的应用，如促进编排、效率优化和可信赖性。此外，本文还识别并提出了未来研究的关键方向。

**Conclusion:** 本文旨在作为图增强大型语言模型智能体（GLA）未来研究的路线图，并加深对图在LLM智能体系统中作用的理解，通过系统地概述当前进展和指出未来方向，以解决LLM智能体在复杂工作流中的局限性。

> **ai_Abstract:** 本综述文章全面审视了图增强大型语言模型智能体（GLA）的最新进展与未来前景。文章指出，尽管大型语言模型（LLMs）智能体能力强大，但在规划、记忆、工具管理和多智能体协调方面仍有限制，而图结构能有效增强这些方面。为应对GLA研究的快速发展与碎片化，本文对现有GLA方法按其在LLM智能体系统中的核心功能（如规划、记忆、工具使用）进行了分类和分析，并探讨了图和图学习算法如何贡献于这些功能。此外，文章还深入讨论了GLA在多智能体系统中的应用，包括促进编排、优化效率和提升可信赖性。最后，文章提出了GLA领域未来的关键研究方向，旨在为该领域提供清晰的路线图。

> **摘要翻译:** 大型语言模型（LLMs）驱动的自主智能体在网络导航、软件开发和具身控制等广泛应用中展现出令人印象深刻的能力。然而，大多数LLMs在几个关键的智能体程序中存在局限性，例如可靠的规划、长期记忆、工具管理和多智能体协调。图可以作为强大的辅助结构，增强复杂智能体工作流中的结构、连续性和协调性。鉴于图增强LLM智能体（GLA）研究的快速增长和碎片化，本文及时且全面地概述了最新进展，并强调了未来工作的关键方向。具体而言，我们将现有GLA方法按其在LLM智能体系统中的主要功能进行分类，包括规划、记忆和工具使用，然后分析图和图学习算法如何对每个功能做出贡献。对于多智能体系统，我们进一步讨论了GLA解决方案如何促进多智能体系统（MAS）的编排、效率优化和可信赖性。最后，我们强调了推动该领域发展的关键未来方向，从提高结构适应性到实现统一、可扩展和多模态的GLA系统。我们希望本文能为GLA的未来研究提供路线图，并促进对图在LLM智能体系统中所扮演角色的更深入理解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [67] [UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding](https://arxiv.org/abs/2507.22025)
> *UI-AGILE：通过有效的强化学习和精确的推理时定位提升GUI智能体*

*Shuquan Lian, Yuhang Wu, Jia Ma, Zihan Song, Bingqi Chen, Xiawu Zheng, Hui Li* | **Category: cs.AI, cs.CL, cs.CV** | **Updated: 2025-07-30**

**Keywords:** GUI智能体, 强化学习, 定位准确性, 多模态大语言模型, UI-AGILE

**Comment:** 

> **TL;DR:** UI-AGILE是一个提升GUI智能体性能的综合框架，通过改进训练过程中的奖励函数和采样策略，以及在推理时采用分解定位方法，显著提高了定位准确性。

**AI_Comments:** UI-AGILE通过其在训练和推理阶段的全面创新，为GUI智能体的发展提供了重要贡献。特别是在奖励函数设计（连续奖励和简单思考奖励）和推理时分解定位策略上，展现了对现有瓶颈的深刻理解和有效解决。这些方法有望显著提升GUI智能体在复杂实际应用中的鲁棒性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有GUI智能体的训练和推理技术在推理设计、无效奖励和视觉噪声方面存在问题，限制了多模态大语言模型（MLLMs）在GUI智能体能力上的进一步发展。

**Method:** UI-AGILE在训练阶段提出了一系列改进：1) 连续奖励函数以激励高精度定位；2) “简单思考”奖励以平衡规划、速度和定位准确性；3) 基于裁剪的重采样策略以缓解稀疏奖励问题。在推理阶段，提出了“带选择的分解定位”新方法，通过将图像分解为更小的部分，显著提高了高分辨率显示器上的定位准确性。

**Result:** UI-AGILE在ScreenSpot-Pro和ScreenSpot-v2两个基准测试中取得了最先进的性能。例如，结合训练和推理增强方法，在ScreenSpot-Pro上比最佳基线提高了23%的定位准确性。

**Conclusion:** UI-AGILE通过其在训练和推理阶段的创新方法，有效解决了现有GUI智能体面临的问题，显著提升了GUI智能体的性能和定位准确性，达到了最先进水平。

> **ai_Abstract:** 本文介绍了UI-AGILE，一个旨在解决GUI智能体训练和推理中存在问题的综合框架。该框架在训练阶段引入了连续奖励函数、平衡规划与速度的“简单思考”奖励以及基于裁剪的重采样策略，以提高学习效率和定位精度。在推理阶段，提出了一种新颖的“带选择的分解定位”方法，通过分解图像显著提升了高分辨率显示器上的定位准确性。实验证明，UI-AGILE在ScreenSpot-Pro和ScreenSpot-v2基准测试中达到了最先进的性能，特别是在ScreenSpot-Pro上实现了23%的定位准确性提升。

> **摘要翻译:** 多模态大语言模型（MLLMs）的出现极大地推动了图形用户界面（GUI）智能体能力的发展。然而，现有的GUI智能体训练和推理技术仍然面临推理设计、无效奖励和视觉噪声的困境。为了解决这些问题，我们引入了UI-AGILE，这是一个在训练和推理阶段全面增强GUI智能体的框架。在训练方面，我们提出了一系列监督微调（SFT）过程的改进：1）连续奖励函数，以激励高精度定位；2）“简单思考”奖励，以平衡规划、速度和定位准确性；3）基于裁剪的重采样策略，以缓解稀疏奖励问题并改善复杂任务上的学习。在推理方面，我们提出了带选择的分解定位，这是一种通过将图像分解为更小的、可管理的部分，从而显著提高高分辨率显示器上定位准确性的新方法。实验表明，UI-AGILE在ScreenSpot-Pro和ScreenSpot-v2两个基准测试中取得了最先进的性能。例如，结合我们提出的训练和推理增强方法，在ScreenSpot-Pro上比最佳基线提高了23%的定位准确性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [92] [The Impact of Foundational Models on Patient-Centric e-Health Systems](https://arxiv.org/abs/2507.21882)
> *基础模型对以患者为中心的电子健康系统的影响*

*Elmira Onagh, Alireza Davoodi, Maleknaz Nayebi* | **Category: cs.AI, cs.SE** | **Updated: 2025-07-29**

**Keywords:** 人工智能, 电子健康系统, 患者中心, AI成熟度, 大型语言模型

**Comment:** Paper published in COMPSAC 2025

> **TL;DR:** 本研究调查了116个以患者为中心的医疗应用中AI的集成和成熟度，发现绝大多数应用仍处于AI集成的早期阶段。

**AI_Comments:** 这项研究通过量化分析揭示了当前以患者为中心的电子健康系统中AI集成的真实水平，其创新之处在于使用了LLMs辅助功能提取和Gartner模型进行成熟度评估。研究结果对理解AI在医疗健康领域的应用现状及其未来发展方向具有重要意义，提示了在提升AI可信度、透明度和实际影响方面仍需努力。

<details>
  <summary>Details</summary>

**Motivation:** 理解人工智能（AI）在以患者为中心的应用程序中的成熟度对于评估其可信度、透明度和实际影响至关重要。

**Method:** 本研究调查了116个以患者为中心的医疗应用程序中AI功能的集成和成熟度。研究人员使用大型语言模型（LLMs）提取关键功能特征，并将其归类到Gartner AI成熟度模型的不同阶段。

**Result:** 结果显示，超过86.21%的应用程序仍处于AI集成的早期阶段，而只有13.79%的应用程序展示了高级AI集成。

**Conclusion:** 大多数以患者为中心的电子健康系统在AI集成方面仍处于早期阶段，表明AI在医疗健康领域广泛且深入的应用仍有很大的发展空间。

> **ai_Abstract:** 本研究旨在评估人工智能在以患者为中心的电子健康系统中的成熟度。通过分析116个医疗应用，研究人员利用大型语言模型提取AI功能特征，并将其映射到Gartner AI成熟度模型。结果表明，绝大多数（超过86%）的应用仍处于AI集成的早期阶段，仅有少数（约14%）展示了高级AI集成，这强调了AI在医疗应用中深度整合的挑战和潜力。

> **摘要翻译:** 随着人工智能（AI）在医疗技术中日益普及，了解AI在以患者为中心的应用程序中的成熟度对于评估其可信度、透明度和实际影响至关重要。在本研究中，我们调查了116个以患者为中心的医疗应用程序中AI功能集成的整合和成熟度。我们使用大型语言模型（LLMs）提取了关键功能特征，然后将其归类到Gartner AI成熟度模型的不同阶段。我们的结果显示，超过86.21%的应用程序仍处于AI集成的早期阶段，而只有13.79%的应用程序展示了高级AI集成。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [100] [Adaptive XAI in High Stakes Environments: Modeling Swift Trust with Multimodal Feedback in Human AI Teams](https://arxiv.org/abs/2507.21158)
> *高风险环境下自适应可解释人工智能：在人机团队中通过多模态反馈建模快速信任*

*Nishani Fernando, Bahareh Nakisa, Adnan Ahmad, Mohammad Naim Rastgoo* | **Category: cs.AI, cs.HC, H.1.2; I.2.6; I.2.4** | **Updated: 2025-07-25**

**Keywords:** 自适应可解释AI, 快速信任, 人机团队, 多模态反馈, 高风险环境

**Comment:** 15 pages, 1 figure, Accepted to MAI-XAI@ECAI2025

> **TL;DR:** 提出一个用于高风险场景的自适应可解释AI（XAI）概念框架AXTF，通过生理和行为信号推断用户状态，以非侵入性方式提升人机团队的快速信任。

**AI_Comments:** 这篇论文的创新点在于提出了一个非侵入式、自适应的XAI概念框架，特别关注在高风险环境下通过隐式反馈（生理和行为信号）来建模和提升人机快速信任。这解决了现有XAI在实际高压场景中应用受限的痛点，为未来开发更智能、更实用的人机协作系统提供了新的思路和基础。其提出的AXTF框架具有很高的理论价值和潜在应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 在紧急响应等高风险、时间敏感且认知要求高的场景中，人机团队的有效协作依赖于快速信任，但现有XAI方法提供统一解释且依赖不切实际的显式反馈，无法有效建立这种信任。

**Method:** 提出一个名为自适应可解释性信任框架（AXTF）的概念框架。该框架通过利用EEG、ECG和眼动追踪等生理和行为信号来推断用户的实时认知和情绪状态（隐式反馈），从而实现非侵入式操作。其核心是一个多目标、个性化的信任估计模型，将工作量、压力和情绪映射到动态信任估计，这些估计指导解释特征的调整，以提供响应式和个性化的支持。

**Result:** 该概念框架通过响应用户的实时认知和情绪状态，促进了高风险环境中人机团队的快速信任。它实现了对解释特征的动态调节，从而提供响应式和个性化的支持。

**Conclusion:** 该概念框架为开发适应高压、时间敏感环境需求的自适应、非侵入性XAI系统奠定了基础。

> **ai_Abstract:** 本文提出了一个名为自适应可解释性信任框架（AXTF）的创新概念框架，旨在解决高风险人机团队协作中快速信任建立的挑战。针对现有XAI方法在时间敏感和高压环境下实用性不足的问题，AXTF通过非侵入性地利用EEG、ECG和眼动追踪等生理行为信号来推断用户的实时认知和情绪状态。其核心是一个多目标个性化信任估计模型，能够动态调节解释特征，从而提供响应式和个性化的XAI支持，以促进人机协作中的快速信任。

> **摘要翻译:** 有效的人工智能团队协作在很大程度上取决于快速信任，尤其是在紧急响应等高风险场景中，及时准确的决策至关重要。在这些时间敏感且认知要求高的环境中，自适应可解释性对于培养操作员与人工智能系统之间的信任至关重要。然而，现有的可解释人工智能（XAI）方法通常提供统一的解释，并且严重依赖显式反馈机制，这在如此高压的场景中往往不切实际。为了弥补这一空白，我们提出了一个自适应XAI的概念框架，它通过对用户的实时认知和情绪状态作出响应（通过隐式反馈）来非侵入性地运行，从而增强高风险环境中的快速信任。所提出的自适应可解释性信任框架（AXTF）利用生理和行为信号，如脑电图（EEG）、心电图（ECG）和眼动追踪，来推断用户状态并支持解释适应。其核心是一个多目标、个性化的信任估计模型，该模型将工作量、压力和情绪映射到动态信任估计。这些估计指导解释特征的调节，从而实现响应式和个性化的支持，促进人机协作中的快速信任。这个概念框架为开发适应高压、时间敏感环境严格要求的自适应、非侵入性XAI系统奠定了基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [108] [GDAIP: A Graph-Based Domain Adaptive Framework for Individual Brain Parcellation](https://arxiv.org/abs/2507.21727)
> *GDAIP：一种基于图的个体大脑分区域适应框架*

*Jianfei Zhu, Haiqi Zhu, Shaohui Liu, Feng Jiang, Baichun Wei, Chunzhi Yi* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大脑分区, 域适应, 图神经网络, fMRI, GDAIP

**Comment:** 

> **TL;DR:** GDAIP是一种结合图注意力网络和Minimax熵的域适应框架，用于解决fMRI个体大脑分区中跨数据集域偏移问题，实现拓扑合理、跨会话一致且能反映功能组织的个体分区。

**AI_Comments:** 这篇论文的创新点在于将图神经网络与域适应技术结合，专门解决fMRI脑分区中常见的跨数据集域偏移问题。通过构建多层次的脑图并利用半监督和对抗优化策略，有效地提高了分区结果的鲁棒性和泛化能力，对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度学习方法在fMRI个体大脑分区中存在跨数据集数据分布不一致（域偏移）的问题。

**Method:** 提出GDAIP框架，结合图注意力网络（GAT）和基于Minimax熵（MME）的域适应。构建组级和个体级跨数据集脑图。通过半监督训练和对目标脑图无标签顶点的预测熵进行对抗优化，将参考图谱从组级脑图适应到个体脑图，从而在跨数据集设置下实现个体分区。

**Result:** GDAIP产生具有拓扑合理边界、强跨会话一致性以及能够反映功能组织的个体分区。评估指标包括分区可视化、Dice系数和功能同质性。

**Conclusion:** GDAIP能够有效解决跨数据集域偏移问题，实现高质量的个体大脑分区。

> **ai_Abstract:** GDAIP是一种创新的基于图的域适应框架，旨在解决fMRI个体大脑分区中跨数据集的域偏移问题。它结合了图注意力网络（GAT）和Minimax熵（MME）进行域适应，并通过构建组级和个体级脑图、利用半监督训练和对抗优化实现参考图谱从组级到个体脑图的适应。实验结果表明，GDAIP能够生成拓扑合理、跨会话一致且反映功能组织的个体分区。

> **摘要翻译:** 最近的深度学习方法在从功能性磁共振成像（fMRI）中学习个体大脑分区方面显示出前景。然而，大多数现有方法假设跨域数据分布一致，并且难以应对真实世界跨数据集场景中固有的域偏移。为了解决这一挑战，我们提出了图域适应个体分区（GDAIP），这是一个新颖的框架，它将图注意力网络（GAT）与基于Minimax熵（MME）的域适应相结合。我们在组级和个体级构建了跨数据集脑图。通过利用半监督训练和对目标脑图无标签顶点的预测熵进行对抗优化，参考图谱从组级脑图适应到个体脑图，从而在跨数据集设置下实现个体分区。我们使用分区可视化、Dice系数和功能同质性评估了我们的方法。实验结果表明，GDAIP生成了具有拓扑合理边界、强跨会话一致性以及能够反映功能组织的个体分区。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [109] [UserBench: An Interactive Gym Environment for User-Centric Agents](https://arxiv.org/abs/2507.22034)
> *UserBench：一个面向用户中心智能体的交互式Gym环境*

*Cheng Qian, Zuxin Liu, Akshara Prabhakar, Zhiwei Liu, Jianguo Zhang, Haolin Chen, Heng Ji, Weiran Yao, Shelby Heinecke, Silvio Savarese, Caiming Xiong, Huan Wang* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-29**

**Keywords:** LLM智能体, 用户协作, 基准测试, 用户对齐, 交互环境

**Comment:** 25 Pages, 17 Figures, 6 Tables

> **TL;DR:** UserBench是一个新的基准测试，旨在评估LLM智能体在模糊和演变目标下与用户主动协作的能力，并发现当前模型在用户对齐方面存在显著不足。

**AI_Comments:** UserBench的创新之处在于它关注LLM智能体与用户的“主动协作”能力，特别是在目标模糊和动态变化的情况下，这超越了传统仅关注任务完成度的评估。它提供了一个急需的基准来衡量智能体在真实世界交互中的“用户对齐”能力，揭示了当前LLM在这方面的显著局限性。这对于推动更智能、更人性化的AI助手发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）驱动的智能体在推理和工具使用方面取得了显著进展，但它们在主动与用户协作方面的能力，尤其是在目标模糊、演变或间接表达的情况下，仍未得到充分探索。为了弥补这一空白，本研究引入了UserBench。

**Method:** 我们引入了UserBench，一个以用户为中心的基准测试，旨在多轮、偏好驱动的交互中评估智能体。UserBench包含模拟用户，他们从不明确的目标开始，并逐步揭示偏好，要求智能体主动澄清意图并利用工具做出有根据的决策。

**Result:** 对领先的开源和闭源LLM的评估显示，任务完成度与用户对齐度之间存在显著脱节。例如，模型平均只有20%的时间能提供与所有用户意图完全一致的答案，即使是最先进的模型也只能通过主动交互发现不到30%的用户偏好。

**Conclusion:** 这些结果凸显了构建不仅仅是能干的任务执行者，而且是真正的协作伙伴的智能体所面临的挑战。UserBench提供了一个交互式环境来衡量和提升这项关键能力。

> **ai_Abstract:** 本文介绍了UserBench，一个用于评估LLM智能体在多轮、偏好驱动交互中与用户主动协作能力的基准测试。该基准通过模拟用户逐步揭示模糊目标和偏好，要求智能体主动澄清意图并利用工具做出决策。评估结果表明，当前LLM在任务完成度与用户对齐度之间存在显著差距，平均只有20%的答案完全符合用户意图，且主动交互发现的用户偏好不足30%。UserBench旨在成为一个交互式环境，以促进和衡量智能体作为协作伙伴的关键能力。

> **摘要翻译:** 大型语言模型（LLMs）驱动的智能体在推理和工具使用方面取得了令人印象深刻的进展，使它们能够解决复杂的任务。然而，它们主动与用户协作的能力，尤其是在目标模糊、演变或间接表达的情况下，仍未得到充分探索。为了弥补这一空白，我们引入了UserBench，一个以用户为中心的基准测试，旨在多轮、偏好驱动的交互中评估智能体。UserBench包含模拟用户，他们从不明确的目标开始，并逐步揭示偏好，要求智能体主动澄清意图并利用工具做出有根据的决策。我们对领先的开源和闭源LLM的评估显示，任务完成度与用户对齐度之间存在显著脱节。例如，模型平均只有20%的时间能提供与所有用户意图完全一致的答案，即使是最先进的模型也只能通过主动交互发现不到30%的用户偏好。这些结果凸显了构建不仅仅是能干的任务执行者，而且是真正的协作伙伴的智能体所面临的挑战。UserBench提供了一个交互式环境来衡量和提升这项关键能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [121] [GovRelBench:A Benchmark for Government Domain Relevance](https://arxiv.org/abs/2507.21419)
> *GovRelBench：政府领域相关性基准*

*Haiquan Wang, Yi Chen, Shang Zeng, Yun Bian, Zhe Cui* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** GovRelBench, 大型语言模型, 政府领域, 领域相关性, 评估基准

**Comment:** 

> **TL;DR:** GovRelBench是一个用于评估大型语言模型在政府领域核心能力（特别是领域相关性）的基准，它包含政府领域提示和评估工具GovRelBERT，并引入了SoftGovScore方法来准确计算文本的政府领域相关性得分。

**AI_Comments:** 这项工作提出了一种新颖的基准GovRelBench，专门用于解决大型语言模型在政府领域核心能力评估（特别是领域相关性）方面的不足。其创新点在于设计了专用的评估工具GovRelBERT和SoftGovScore方法，通过软分数转换来更精确地衡量文本的领域相关性。这对于推动大型模型在特定垂直领域的应用和优化具有重要意义。论文还提供了代码和数据集，有助于后续研究的复现和拓展。

<details>
  <summary>Details</summary>

**Motivation:** 当前对政府领域大型语言模型（LLMs）的评估主要侧重于特定场景下的安全考虑，而对模型自身核心能力，特别是领域相关性的评估仍然不足。为了弥补这一空白，本研究提出了GovRelBench。

**Method:** 本研究提出了GovRelBench，一个专门用于评估政府领域大型语言模型核心能力的基准。GovRelBench包含政府领域提示和专门的评估工具GovRelBERT。在GovRelBERT的训练过程中，引入了SoftGovScore方法：该方法通过将硬标签转换为软分数，基于ModernBERT架构训练模型，使其能够准确计算文本的政府领域相关性得分。

**Result:** Not mentioned in abstract

**Conclusion:** 这项工作旨在增强政府领域大型模型的能力评估框架，为相关研究和实践提供一个有效的工具。

> **ai_Abstract:** 本论文提出了GovRelBench，一个针对政府领域大型语言模型（LLMs）核心能力（尤其是领域相关性）的评估基准。GovRelBench包含政府领域提示和专用的评估工具GovRelBERT。其中，GovRelBERT在训练时采用了SoftGovScore方法，该方法通过将硬标签转换为软分数，使模型能准确计算文本的政府领域相关性得分。该工作旨在弥补当前LLM评估中对领域相关性关注不足的空白，为政府领域的大模型评估提供有效工具。

> **摘要翻译:** 当前对政府领域大型语言模型（LLMs）的评估主要侧重于特定场景下的安全考虑，而对模型自身核心能力，特别是领域相关性的评估仍然不足。为了弥补这一空白，我们提出了GovRelBench，一个专门用于评估政府领域大型语言模型核心能力的基准。GovRelBench包含政府领域提示和专门的评估工具GovRelBERT。在GovRelBERT的训练过程中，我们引入了SoftGovScore方法：该方法通过将硬标签转换为软分数，基于ModernBERT架构训练模型，使其能够准确计算文本的政府领域相关性得分。这项工作旨在增强政府领域大型模型的能力评估框架，为相关研究和实践提供一个有效的工具。我们的代码和数据集可在https://github.com/pan-xi/GovRelBench获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [144] [The Interspeech 2025 Speech Accessibility Project Challenge](https://arxiv.org/abs/2507.22047)
> *Interspeech 2025 语音无障碍项目挑战赛*

*Xiuwen Zheng, Bornali Phukon, Jonghwan Na, Ed Cutrell, Kyu Han, Mark Hasegawa-Johnson, Pan-Pan Jiang, Aadhrik Kuila, Colin Lea, Bob MacDonald, Gautam Mantena, Venkatesh Ravichandran, Leda Sari, Katrin Tomanek, Chang D. Yoo, Chris Zwilling* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 语音无障碍, ASR, 言语障碍, Interspeech挑战赛, 词错误率, 语义得分

**Comment:** To appear in Proceedings of Interspeech, 2025

> **TL;DR:** Interspeech 2025挑战赛利用大量受损语音数据，旨在改善ASR系统对言语障碍人士的识别能力；顶尖团队显著超越基线，为未来ASR系统设定了新基准。

**AI_Comments:** 这项挑战赛具有重要意义，因为它填补了ASR技术在服务言语障碍人群方面的一个关键空白。大规模、多样化数据集的使用以及新基准的建立是其重要贡献。这表明有针对性的挑战能够推动AI在特定服务不足领域的创新。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自动语音识别（ASR）系统在过去十年取得了显著进展，但其对言语障碍人士的表现仍然不足，部分原因是公共训练数据有限。Interspeech 2025语音无障碍项目挑战赛旨在弥补这一差距。

**Method:** 该挑战赛利用了从500多名有不同言语障碍的人士收集和转录的400多小时SAP数据。挑战赛在EvalAI上举办，并利用远程评估流程，根据词错误率（WER）和语义得分（SemScore）评估提交结果。

**Result:** 在22个有效团队中，有12个团队在词错误率（WER）方面超越了whisper-large-v2基线，17个团队在语义得分（SemScore）方面超越了基线。表现最好的团队同时取得了8.11%的最低WER和88.44%的最高SemScore。

**Conclusion:** 该挑战赛为未来自动语音识别（ASR）系统识别受损语音设定了新的性能基准。

> **ai_Abstract:** Interspeech 2025语音无障碍项目（SAP）挑战赛旨在解决ASR系统在识别言语障碍人士语音方面存在的性能不足和训练数据缺乏的问题。该挑战赛使用了超过400小时的多样化受损语音数据，并以词错误率和语义得分作为评估标准。挑战结果显示，许多参赛团队超越了whisper-large-v2基线，其中表现最佳的团队为受损语音的ASR识别树立了新的性能标杆。

> **摘要翻译:** 尽管过去十年自动语音识别（ASR）系统取得了显著进展，但这些系统对言语障碍人士的表现仍然不足，部分原因是公共训练数据有限。为了弥补这一差距，2025年Interspeech语音无障碍项目（SAP）挑战赛启动，利用从500多名有不同言语障碍的人士收集和转录的400多小时SAP数据。SAP挑战赛在EvalAI上举办，并利用远程评估流程，根据词错误率（WER）和语义得分（SemScore）评估提交结果。结果，22个有效团队中有12个在WER方面超越了whisper-large-v2基线，而17个团队在SemScore方面超越了基线。值得注意的是，表现最好的团队同时取得了8.11%的最低WER和88.44%的最高SemScore，为未来ASR系统识别受损语音设定了新的基准。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [149] [LLM-based Content Classification Approach for GitHub Repositories by the README Files](https://arxiv.org/abs/2507.21899)
> *基于LLM的GitHub仓库README文件内容分类方法*

*Malik Uzair Mehmood, Shahid Hussain, Wen Li Wang, Muhammad Usama Malik* | **Category: cs.AI, cs.LG, cs.SE** | **Updated: 2025-07-29**

**Keywords:** LLM, 内容分类, GitHub, README文件, 微调

**Comment:** 8 pages, 4 Figures

> **TL;DR:** 本研究开发了一种基于大型语言模型（LLM）的方法，用于自动分类GitHub仓库的README文件内容，并在性能上超越了现有技术，同时探索了参数高效微调（PEFT）的有效性。

**AI_Comments:** 这项研究通过利用LLM解决GitHub README文件内容分类问题，展现了其在代码管理和信息组织方面的创新应用。其主要贡献在于开发了一种高效且高性能的分类方法，并验证了PEFT的有效性，为资源受限的场景提供了经济可行的解决方案。该方法对于提高GitHub仓库的可发现性和可用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** GitHub仓库的README文件对于项目的采用和利用至关重要，但由于所有者有时忽视推荐，导致文件内容不够详尽，从而阻碍了仓库潜力的充分发挥。鉴于大型语言模型（LLMs）在文本分类等任务中的卓越表现，本研究旨在利用LLMs解决这一问题，提升GitHub仓库的识别和使用效率。

**Method:** 本研究开发了一种微调LLM的方法，用于自动分类GitHub README文件的不同部分。具体使用了BERT、DistilBERT和RoBERTa三种编码器-only的LLM模型。这些预训练模型在一个包含4226个README文件部分的金标准数据集上进行了微调。此外，研究还探讨了参数高效微调（PEFT）技术，如低秩适应（LoRA）的使用。

**Result:** 本方法在GitHub README文件内容分类任务中，超越了当前最先进的方法，并取得了0.98的总体F1分数。此外，研究表明，参数高效微调（PEFT）技术（如LoRA）提供了一种经济高效的替代方案，在不显著影响性能的情况下实现了与完全微调相似的效果。

**Conclusion:** 本研究证明了使用LLM设计GitHub README文件内容自动分类器的潜力。这项工作有助于开发自动化工具，以改善GitHub仓库的识别和潜在用途。

> **ai_Abstract:** 本研究提出了一种基于LLM的GitHub仓库README文件内容自动分类方法。针对README文件信息不完整影响仓库利用率的问题，作者利用BERT、DistilBERT和RoBERTa等编码器-only LLM，在一个包含4226个README文件部分的金标准数据集上进行微调。该方法在F1分数为0.98的情况下超越了现有最先进技术，并验证了PEFT（如LoRA）在保持性能的同时提供经济高效微调的可能性。研究结果强调了LLM在自动化GitHub仓库内容分类方面的潜力，有助于提升仓库的识别和使用效率。

> **摘要翻译:** GitHub是全球最受欢迎的用于存储、共享和管理代码的平台。每个GitHub仓库都关联有一个README文件。根据GitHub的建议，README文件应包含项目相关信息，以支持仓库的使用和改进。然而，GitHub仓库所有者有时会忽视这些建议。这阻碍了GitHub仓库充分发挥其潜力。本研究认为，GitHub仓库README文件的全面性显著影响其采用和利用，缺乏细节可能会阻碍其在研究社区中广泛参与和影响的充分发挥。大型语言模型（LLMs）在许多基于文本的任务中表现出色，包括文本分类、文本生成、文本摘要和文本翻译。在本研究中，开发了一种方法来微调LLM，以自动分类GitHub README文件的不同部分。使用了三种仅编码器LLM，包括BERT、DistilBERT和RoBERTa。这些预训练模型随后根据一个包含4226个README文件部分的金标准数据集进行了微调。这种方法优于当前最先进的方法，并取得了0.98的总体F1分数。此外，我们还研究了参数高效微调（PEFT）技术（如低秩适应（LoRA））的使用，并展示了其作为完全微调的经济替代方案，且性能损失不大。结果证明了使用LLM设计GitHub README文件内容自动分类器的潜力。因此，本研究有助于开发GitHub仓库的自动化工具，以改善其识别和潜在用途。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [155] [Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems](https://arxiv.org/abs/2507.21162)
> *大语言模型驱动的主动配电网调度问题自动化建模与优化*

*Xu Yang, Chenhui Lin, Yue Yang, Qi Wang, Haotian Liu, Haizhou Hua, Wenchuan Wu* | **Category: cs.AI, cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-25**

**Keywords:** 大语言模型, 主动配电网, 调度, 自动化建模, 优化

**Comment:** 

> **TL;DR:** 该论文提出了一种由大语言模型（LLM）驱动的自动化建模与优化方法，用于解决主动配电网（ADN）的调度问题，使缺乏专业知识的操作员也能通过自然语言查询高效地制定调度策略。

**AI_Comments:** 该论文的创新之处在于利用大语言模型（LLM）使复杂的电力系统优化变得大众化，通过用户友好的自然语言界面，使非专业操作员也能进行操作。这有望显著降低主动配电网（ADN）的运营成本并提高调度效率。

<details>
  <summary>Details</summary>

**Motivation:** 随着分布式能源在主动配电网（ADN）中的渗透率不断提高，有效的ADN调度变得至关重要。然而，许多新加入的ADN运营商（如配电系统聚合商、虚拟电厂管理者和终端产消者）往往缺乏电力系统运行、建模、优化和编程方面的专业知识。这种知识鸿沟使得依赖人工专家既昂贵又耗时。为解决这一挑战并实现智能、灵活的ADN调度，本文提出了解决方案。

**Method:** 本文提出了一种由大语言模型（LLM）驱动的自动化建模与优化方法。首先，将ADN调度问题分解为顺序阶段，并设计了一个多LLM协调架构，包括信息提取器、问题制定器和代码编程器，分别负责信息检索、优化问题制定和代码实现。其次，为每个LLM智能体开发了定制的细化技术，极大地提高了生成内容的准确性和可靠性。所提出的方法还具有以用户为中心的界面，使ADN操作员能够通过简单的自然语言查询来推导调度策略。

**Result:** 通过在各种测试案例上进行的全面比较和端到端演示，验证了所提出的架构和方法的有效性。

**Conclusion:** 该方法消除了技术障碍，提高了ADN操作员获取调度策略的效率，实现了智能、灵活的ADN调度。

> **ai_Abstract:** 本文提出了一种由大语言模型（LLM）驱动的自动化建模与优化框架，用于解决主动配电网（ADN）的调度问题。针对新ADN运营商缺乏专业知识的挑战，该方法将调度问题分解为多个阶段，并采用多LLM协调架构（包括信息提取器、问题制定器和代码编程器），同时开发了定制的细化技术以提高生成内容的准确性。该框架提供了一个用户中心的界面，允许操作员通过自然语言查询来获取调度策略，其有效性已通过全面的测试验证。

> **摘要翻译:** 主动配电网（ADN）中分布式能源渗透率的不断提高使得有效的ADN调度变得势在必行。然而，众多新整合的ADN运营商，如配电系统聚合商、虚拟电厂管理者和终端产消者，往往缺乏电力系统运行、建模、优化和编程方面的专业知识。这种知识鸿沟使得依赖人工专家既昂贵又耗时。为了解决这一挑战并实现智能、灵活的ADN调度，本文提出了一种由大型语言模型（LLM）驱动的自动化建模和优化方法。首先，将ADN调度问题分解为顺序阶段，并设计了多LLM协调架构。该框架包括信息提取器、问题制定器和代码编程器，分别负责信息检索、优化问题制定和代码实现。随后，为每个LLM智能体开发了定制的细化技术，极大地提高了生成内容的准确性和可靠性。所提出的方法具有以用户为中心的界面，使ADN操作员能够通过简单的自然语言查询来推导调度策略，从而消除技术障碍并提高效率。在各种测试案例上进行的全面比较和端到端演示验证了所提出的架构和方法的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [164] [SAT-Based Bounded Fitting for the Description Logic ALC](https://arxiv.org/abs/2507.21752)
> *基于SAT的描述逻辑ALC有界拟合*

*Maurice Funk, Jean Christoph Jung, Tom Voellmer* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 有界拟合, 描述逻辑ALC, SAT求解器, PAC学习, NP完全性

**Comment:** 33 pages, full version of paper accepted at ISWC 2025

> **TL;DR:** 研究了描述逻辑ALC中的有界拟合问题，证明了其NP完全性，并展示了基于SAT求解器的实现，强调了其概率保证优于其他算法。

**AI_Comments:** 这项工作探讨了将有界拟合范式应用于描述逻辑ALC，其创新之处在于证明了该问题的计算复杂性（NP完全性），并强调了有界拟合在PAC学习框架下提供的独特概率保证，这对于学习算法的可靠性至关重要。基于SAT求解器的实现也展示了将理论复杂性问题转化为实际可操作的解决方案的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在研究描述逻辑ALC及其语法片段中的有界拟合问题，因为有界拟合是一种从正负数据示例中学习逻辑公式的通用范式，并已引起广泛关注。

**Method:** 研究了描述逻辑ALC及其语法片段中的有界拟合，并基于SAT求解器实现了ALC及其片段中的有界拟合，讨论了优化并与其他概念学习工具进行了比较。

**Result:** 证明了所研究的所有片段中，底层的尺寸受限拟合问题是NP完全的，即使在单个正例和单个负例的特殊情况下也是如此。此外，有界拟合在Valiant的PAC学习框架中提供了概率保证，而其他ALC概念学习算法则不提供此类保证。

**Conclusion:** 有界拟合在描述逻辑ALC中是可行的，尽管其核心问题是NP完全的，但它提供了其他学习算法所缺乏的概率保证，并且可以通过SAT求解器有效实现。

> **ai_Abstract:** 本文研究了描述逻辑ALC及其语法片段中的有界拟合问题，这是一种从数据中学习逻辑公式的方法。研究表明，即使在最简单的情况下，底层尺寸受限拟合问题也是NP完全的。作者强调，有界拟合在PAC学习框架下提供概率保证，这是其他ALC概念学习算法所不具备的优势。最后，文章介绍了一个基于SAT求解器的有界拟合实现，并对其优化和与其他工具的比较进行了讨论。

> **摘要翻译:** 有界拟合是一种从正负数据示例中学习逻辑公式的通用范式，最近受到了广泛关注。我们研究了描述逻辑ALC及其语法片段中的有界拟合。我们证明了所研究的所有片段中，底层的尺寸受限拟合问题是NP完全的，即使在单个正例和单个负例的特殊情况下也是如此。根据设计，有界拟合在Valiant的PAC学习框架中提供了概率保证。相比之下，我们证明了其他学习ALC概念的算法不提供此类保证。最后，我们提出了基于SAT求解器的ALC及其片段中有界拟合的实现。我们讨论了优化并比较了我们的实现与其他概念学习工具。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [177] [Evo-DKD: Dual-Knowledge Decoding for Autonomous Ontology Evolution in Large Language Models](https://arxiv.org/abs/2507.21438)
> *Evo-DKD：大语言模型中自主本体演化的双知识解码*

*Vishal Raman, Vijai Aravindh R* | **Category: cs.AI, I.2.4; I.2.6; I.2.7; H.2.8** | **Updated: 2025-07-29**

**Keywords:** 本体演化, 大语言模型, 双知识解码, 知识图谱, 闭环推理

**Comment:** 9 pages, 10 figures

> **TL;DR:** Evo-DKD 是一种新的双解码器框架，用于大语言模型中的自主本体演化，它结合了结构化本体遍历和非结构化文本推理，优于单一解码器方法。

**AI_Comments:** Evo-DKD 的创新之处在于其双解码器框架和动态门控机制，有效地结合了LLM的非结构化推理能力与结构化知识的维护需求。它解决了本体演化中手动维护的痛点，并提供了可持续的解决方案。模拟双解码器行为的策略（基于提示的模式控制）是一个值得关注的工程权衡，可能在实际性能上与真正的双解码器存在差异。

<details>
  <summary>Details</summary>

**Motivation:** 本体和知识图谱需要持续演化以保持全面和准确，但手动维护劳动密集。大语言模型（LLMs）拥有大量非结构化知识，但在维护结构化一致性方面存在困难。

**Method:** 提出 Evo-DKD，一个新颖的双解码器框架，用于自主本体演化。它在LLM中引入两个并行解码流：一个生成候选本体编辑（如新概念或关系），另一个生成自然语言解释。一个动态注意力门控机制协调这两个流，决定如何融合结构化和非结构化知识。由于GPU限制，通过基于提示的模式控制模拟双解码器行为。系统在一个闭环推理中运行：提议的本体编辑通过一致性检查和文本解释交叉验证，然后注入知识库，反过来指导后续推理。

**Result:** Evo-DKD 在本体更新的精度和下游任务性能方面均优于仅使用结构化或仅使用非结构化解码的基线。在医疗本体细化、语义搜索改进和文化遗产时间线建模等用例中展示了其有效性。

**Conclusion:** Evo-DKD 为大语言模型驱动的知识库维护提供了一种新范式，结合了符号推理和神经推理的优势，实现可持续的本体演化。

> **ai_Abstract:** Evo-DKD 是一种新颖的双解码器框架，旨在解决大语言模型在自主本体演化中结构化一致性维护的挑战。它通过并行生成本体编辑和自然语言解释，并利用动态注意力门控机制协调结构化和非结构化知识融合，实现了知识库的闭环维护。实验证明，Evo-DKD 在本体更新精度和下游任务性能上均优于现有基线，为大语言模型驱动的知识库维护开辟了新路径。

> **摘要翻译:** 本体和知识图谱需要持续演化才能保持全面和准确，但手动维护劳动密集。大语言模型（LLMs）拥有大量的非结构化知识，但在维护结构化一致性方面存在困难。我们提出了 Evo-DKD，一个新颖的用于自主本体演化的双解码器框架，它结合了结构化本体遍历和非结构化文本推理。Evo-DKD 在大语言模型中引入了两个并行的解码流：一个解码器生成候选本体编辑（例如，新概念或关系），而另一个生成自然语言解释。一个动态的基于注意力的门控机制协调这两个流，在每一步决定如何融合结构化和非结构化知识。由于GPU限制，我们使用基于提示的模式控制来模拟双解码器行为，以近似单流模式下的协调解码。该系统在一个闭环推理中运行：提议的本体编辑经过验证（通过一致性检查和与文本解释的交叉验证），然后注入知识库，这反过来为后续推理提供信息。我们在包括医疗本体细化、语义搜索改进和文化遗产时间线建模在内的用例中展示了 Evo-DKD 的有效性。实验表明，Evo-DKD 在本体更新的精度和下游任务性能方面均优于使用仅结构化或仅非结构化解码的基线。我们提供了定量指标和定性示例，证实了双解码器设计和门控路由器的贡献。Evo-DKD 为大语言模型驱动的知识库维护提供了一种新范式，结合了符号和神经推理的优势，实现可持续的本体演化。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [211] [An ontological analysis of risk in Basic Formal Ontology](https://arxiv.org/abs/2507.21171)
> *风险在基本形式本体论中的本体论分析*

*Federico Donato, Adrien Barton* | **Category: cs.AI** | **Updated: 2025-07-26**

**Keywords:** 本体论, 风险, BFO, 角色, 倾向

**Comment:** 7 pages. 2 figures. Conference: Semantic Technology for Intelligence,
  Defense, and Security (STIDS 2024)

> **TL;DR:** 本文使用基本形式本体论（BFO）对风险的性质进行了本体论分析，认为风险是BFO:Role的一个子类。

**AI_Comments:** 本文的创新之处在于其对风险概念进行了严格的本体论分析，并提出了将其归类为BFO:Role的子类这一新颖观点，这对于在形式本体论框架下理解和建模风险具有重要意义。通过明确风险的充分条件，为未来更精确的风险定义和应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探索风险的性质，并使用基本形式本体论（BFO）的范畴对其进行表征，特别是为了论证风险是BFO:Role的子类，并与将其归类为BFO:Disposition子类的观点进行对比。

**Method:** 本文采用本体论分析方法，利用基本形式本体论（BFO）的范畴来刻画风险。通过一个风险实例（涉及对象、物理和心理过程及其相互关系）的应用，从实例中进行概括，以获得风险的总体分析，并明确风险的充分条件。

**Result:** 本文的主要结果是将风险范畴归类为BFO:Role的子类，并将其与将风险归类为BFO:Disposition子类的观点进行对比。研究还明确了成为风险的充分条件。

**Conclusion:** 本文得出结论，风险范畴应被视为基本形式本体论（BFO）中BFO:Role的子类。

> **ai_Abstract:** 本文对风险的性质进行了本体论分析，并利用基本形式本体论（BFO）的范畴对其进行表征。研究主要论证了风险（Risk）范畴是BFO:Role的一个子类，并将其与归类为BFO:Disposition子类的观点进行了对比。通过一个风险实例的应用，论文从具体实例中概括出风险的总体分析，明确了成为风险的充分条件。

> **摘要翻译:** 本文探讨了风险的性质，并使用基本形式本体论（BFO）的范畴对其进行了表征。文章认为，风险范畴是BFO:Role的一个子类，并将其与将风险归类为BFO:Disposition子类的类似观点进行了对比。这种建模选择被应用于一个风险示例，该示例代表了对象、过程（包括物理和心理）及其相互关系，然后从示例中的实例进行概括，以获得风险的总体分析，明确了构成风险的充分条件。未来工作还将提及合理的必要条件。索引词：本体论，风险，BFO，角色，倾向

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [227] [Towards a rigorous evaluation of RAG systems: the challenge of due diligence](https://arxiv.org/abs/2507.21753)
> *迈向RAG系统严格评估：尽职调查的挑战*

*Grégoire Martinon, Alexandra Lorenzo de Brionne, Jérôme Bohard, Antoine Lojou, Damien Hervault, Nicolas J-B. Brunel* | **Category: cs.AI, stat.AP** | **Updated: 2025-07-29**

**Keywords:** RAG系统, 评估协议, 尽职调查, 幻觉, LLM-Judge

**Comment:** in French language. EvalLLM2025: Workshop on Evaluation Generative
  Models (LLM) and Challenges, AMIAD, 2025, Marseille, France

> **TL;DR:** 本文提出了一种结合人工和LLM-Judge注释的严格评估协议，用于评估投资基金尽职调查中的RAG系统，以精确衡量性能并提高工业应用中RAG系统评估协议的可靠性和可扩展性。

**AI_Comments:** 这篇论文的创新点在于提出了结合人工和LLM-Judge注释的混合评估协议，并借鉴了PPI方法来确保评估的精确性和统计学保证。这对于解决RAG系统在关键应用中（如尽职调查）的可靠性问题至关重要，并为工业级RAG系统评估提供了更具可扩展性的方案。提供数据集也有助于未来的研究。

<details>
  <summary>Details</summary>

**Motivation:** 尽管RAG系统在生成式AI领域有巨大潜力，但在医疗和金融等高风险应用中，其可靠性（如幻觉问题）仍然是一个主要担忧。因此，需要一个严格的评估协议来确保其在关键场景下的性能。

**Method:** 本研究评估了一个用于投资基金尽职调查的RAG系统。提出了一种结合人工注释和LLM-Judge注释的鲁棒评估协议，用于识别系统故障（如幻觉、离题、引用失败和弃权）。该方法受预测驱动推理（PPI）启发。

**Result:** 实现了具有统计学保证的精确性能测量。提供了一个全面的数据集供进一步分析。

**Conclusion:** 通过结合人工和LLM-Judge注释的评估协议，可以提高RAG系统评估的可靠性和可扩展性，从而更好地应用于工业领域。

> **ai_Abstract:** 本文针对RAG系统在金融等高风险领域存在的可靠性问题，特别是在尽职调查中的应用，提出了一种严格的评估协议。该协议结合了人工和LLM-Judge注释，旨在识别幻觉、离题等系统故障，并受预测驱动推理方法启发，以实现具有统计学保证的精确性能测量。研究还提供了一个全面的数据集，旨在提高RAG系统评估协议在工业应用中的可靠性和可扩展性。

> **摘要翻译:** 生成式AI的兴起推动了医疗保健和金融等高风险领域的显著进步。检索增强生成（RAG）架构，结合了语言模型（LLM）和搜索引擎，因其能够从文档语料库生成响应而特别引人注目。尽管其潜力巨大，RAG系统在关键上下文中的可靠性仍然是一个问题，诸如幻觉等问题持续存在。本研究评估了一个用于投资基金尽职调查的RAG系统。我们提出了一种结合人工注释和LLM-Judge注释的鲁棒评估协议，以识别系统故障，如幻觉、离题、引用失败和弃权。受预测驱动推理（PPI）方法的启发，我们实现了具有统计学保证的精确性能测量。我们提供了一个全面的数据集供进一步分析。我们的贡献旨在增强工业应用中RAG系统评估协议的可靠性和可扩展性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [234] [Validating Pharmacogenomics Generative Artificial Intelligence Query Prompts Using Retrieval-Augmented Generation (RAG)](https://arxiv.org/abs/2507.21453)
> *使用检索增强生成 (RAG) 验证药物基因组学生成式人工智能查询提示*

*Ashley Rector, Keaton Minor, Kamden Minor, Jeff McCormack, Beth Breeden, Ryan Nowers, Jay Dorris* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 药物基因组学, 生成式人工智能, 检索增强生成 (RAG), Sherpa Rx, CPIC, PharmGKB

**Comment:** 

> **TL;DR:** Sherpa Rx，一个结合 RAG 的药物基因组学 AI 工具，在准确性、相关性、清晰度和完整性方面表现出色，并显著优于 ChatGPT-4omini。

**AI_Comments:** 这篇论文的创新点在于将检索增强生成 (RAG) 应用于药物基因组学领域，并成功整合了权威的 CPIC 和 PharmGKB 数据，以提高 AI 响应的准确性和上下文相关性。其重要性体现在证明了这种结合 RAG 的生成式 AI 在提供个性化、准确的药物基因组学信息方面具有超越通用大型语言模型的潜力，有助于改善临床决策。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在评估 Sherpa Rx 的性能，该人工智能工具利用大型语言模型和检索增强生成 (RAG) 为药物基因组学生成上下文相关响应。

**Method:** 研究评估了 Sherpa Rx，该工具整合了临床药物遗传学实施联盟 (CPIC) 指南和药物基因组学知识库 (PharmGKB) 数据。使用一个包含 260 个查询的数据集，涵盖 26 项 CPIC 指南，评估药物-基因相互作用、剂量建议和治疗影响。研究分为两阶段：第一阶段仅嵌入 CPIC 数据；第二阶段额外纳入 PharmGKB 内容。响应根据准确性、相关性、清晰度、完整性（5 分李克特量表）和召回率进行评分。使用 Wilcoxon 符号秩检验比较了不同阶段和模型之间的准确性，并通过一项 20 题的测验评估了工具的实际应用性。

**Result:** 在第一阶段 (N=260)，Sherpa Rx 表现出高水平的性能：准确性 4.9，相关性 5.0，清晰度 5.0，完整性 4.8，召回率 0.99。子集分析 (N=20) 显示，第二阶段与第一阶段子集相比，准确性 (4.6 vs. 4.4) 和完整性 (5.0 vs. 4.8) 有所提高。ChatGPT-4omini 在相关性 (5.0) 和清晰度 (4.9) 方面表现相当，但在准确性 (3.9) 和完整性 (4.2) 方面落后。第一阶段和第二阶段之间的准确性差异无统计学意义。然而，第二阶段显着优于 ChatGPT-4omini。在 20 题测验中，Sherpa Rx 取得了 90% 的准确率，优于其他模型。

**Conclusion:** 整合 CPIC 和 PharmGKB 等额外资源与检索增强生成 (RAG) 可提高 AI 的准确性和性能。本研究强调了 Sherpa Rx 等生成式 AI 在药物基因组学中的变革性潜力，可通过提供准确、个性化的响应来改善决策。

> **ai_Abstract:** 本研究评估了 Sherpa Rx，一个结合大型语言模型和检索增强生成 (RAG) 的药物基因组学 AI 工具。通过整合 CPIC 指南和 PharmGKB 数据，并在包含 260 个查询的数据集上进行测试，Sherpa Rx 在准确性、相关性、清晰度、完整性和召回率方面表现出色。研究发现，尽管额外整合 PharmGKB 数据并未显著提高其自身准确性，但 Sherpa Rx 在准确性和完整性方面显著优于 ChatGPT-4omini，并在实际应用测验中达到 90% 的准确率，表明其在药物基因组学决策支持方面的巨大潜力。

> **摘要翻译:** 本研究评估了 Sherpa Rx，这是一款利用大型语言模型和检索增强生成（RAG）进行药物基因组学分析的人工智能工具，旨在验证其在关键响应指标上的性能。Sherpa Rx 整合了临床药物遗传学实施联盟（CPIC）指南和药物基因组学知识库（PharmGKB）数据，以生成与上下文相关的响应。研究使用了一个包含 260 个查询的数据集（N=260），涵盖 26 项 CPIC 指南，用于评估药物-基因相互作用、剂量建议和治疗影响。在第一阶段，仅嵌入了 CPIC 数据。第二阶段额外纳入了 PharmGKB 内容。响应根据准确性、相关性、清晰度、完整性（5 分李克特量表）和召回率进行评分。Wilcoxon 符号秩检验比较了第一阶段和第二阶段之间以及第二阶段和 ChatGPT-4omini 之间的准确性。一项 20 题的测验评估了该工具与其它模型相比的实际应用性。在第一阶段（N=260），Sherpa Rx 表现出高水平的性能，准确性 4.9，相关性 5.0，清晰度 5.0，完整性 4.8，召回率 0.99。子集分析（N=20）显示，第二阶段与第一阶段子集相比，准确性（4.6 对 4.4）和完整性（5.0 对 4.8）有所提高。ChatGPT-4omini 在相关性（5.0）和清晰度（4.9）方面表现相当，但在准确性（3.9）和完整性（4.2）方面落后。第一阶段和第二阶段之间的准确性差异无统计学意义。然而，第二阶段显着优于 ChatGPT-4omini。在 20 题测验中，Sherpa Rx 取得了 90% 的准确率，优于其他模型。整合 CPIC 和 PharmGKB 等额外资源与 RAG 可提高 AI 的准确性和性能。本研究强调了 Sherpa Rx 等生成式 AI 在药物基因组学中的变革性潜力，通过提供准确、个性化的响应来改善决策。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [274] [Ontological Foundations of State Sovereignty](https://arxiv.org/abs/2507.21172)
> *国家主权的存在论基础*

*John Beverley, Danielle Limbaugh* | **Category: cs.AI** | **Updated: 2025-07-26**

**Keywords:** 国家主权, 本体论, 国际事务, 模糊数据

**Comment:** 6 pages. 0 figures. Conference: Semantic Technology for Intelligence,
  Defense, and Security (STIDS 2024)

> **TL;DR:** 本文是关于国家主权本质的入门，并提出处理模糊或矛盾主权数据的策略，为国际事务的本体论应用奠定基础。

**AI_Comments:** 这篇论文似乎是基础性的，旨在澄清与国家主权相关的概念问题，尤其是在数据模糊的情况下。其创新之处在于提出了一种处理此类数据的方法，这对于后续国际事务中的本体论应用工作至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在作为国家主权性质及其相关主张重要性的入门介绍，并揭示一种处理关于哪些国家实际上拥有主权的模糊或矛盾数据的方法，为国际事务中的本体论应用工作奠定基础。

**Method:** 论文通过作为入门介绍，并“揭示”一种处理模糊或矛盾数据的方法来探讨国家主权。

**Result:** 论文揭示了一种处理关于哪些国家实际上拥有主权的模糊或矛盾数据的方法，并为国际事务中的本体论应用工作奠定了基础。

**Conclusion:** 本文通过介绍国家主权的本质及其相关主张的重要性，并提出处理模糊或矛盾主权数据的方法，为国际事务中的本体论应用工作奠定了基础。

> **ai_Abstract:** 本文是对国家主权性质及其相关主张重要性的入门介绍。它还旨在揭示一种处理关于哪些国家实际上拥有主权的模糊或矛盾数据的方法。这些目标共同旨在为国际事务中的本体论应用工作奠定基础。

> **摘要翻译:** 这篇短文是关于国家主权性质及其相关主张重要性的入门介绍。它还旨在揭示（仅仅是揭示）一种处理关于哪些国家实际上拥有主权的模糊或矛盾数据的方法。这些目标共同旨在为国际事务中的本体论应用工作奠定基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [283] [Hybrid Causal Identification and Causal Mechanism Clustering](https://arxiv.org/abs/2507.21792)
> *混合因果识别与因果机制聚类*

*Saixiong Liu, Yuhua Qian, Jue Li, Honghong Cheng, Feijiang Li* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 因果识别, 因果推断, 异构性, 混合模型, 聚类

**Comment:** 

> **TL;DR:** 针对真实世界中异构因果关系，本文提出了MCVCI模型进行因果推断，并引入MCVCC方法进行因果机制聚类，实验证明其有效性。

**AI_Comments:** 这篇论文的创新点在于提出了同时处理因果识别和因果机制异构性的方法。通过引入混合模型和聚类技术，它能够更好地适应真实世界中复杂多变的因果关系，突破了传统单一因果机制建模的局限性。其重要性在于提升了因果推断在复杂场景下的准确性和解释性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于加性噪声的双变量因果识别方法大多只使用单一因果机制，无法有效处理真实世界中观测数据普遍存在的异构因果关系。

**Method:** 提出混合条件变分因果推断模型（MCVCI），结合高斯混合模型和神经网络的拟合能力，并利用混合条件变分自编码器概率边界获得的似然作为因果决策标准。此外，还提出了混合条件变分因果聚类（MCVCC）方法来揭示因果机制的表达。

**Result:** 与最先进的方法相比，本文提出的方法在多个模拟和真实数据集上表现出全面的最佳性能。

**Conclusion:** 本文提出的MCVCI和MCVCC方法能够有效处理异构因果关系，并揭示因果机制表达，其有效性已通过实验验证。

> **ai_Abstract:** 本文针对现有因果推断方法无法处理真实世界中异构因果关系的问题，提出了两种新方法：混合条件变分因果推断模型（MCVCI）和混合条件变分因果聚类（MCVCC）。MCVCI结合了高斯混合模型和神经网络，利用变分自编码器的概率似然进行因果推断；MCVCC则旨在通过聚类揭示因果机制的异构性。实验证明，所提方法在模拟和真实数据上均优于现有先进方法。

> **摘要翻译:** 双变量因果方向识别是因果推断领域一个基础且重要的问题。在二元因果方法中，大多数基于加性噪声的方法只使用单一的因果机制来构建因果模型。在现实世界中，观测数据总是从具有异构因果关系的不同环境中收集的。因此，本文针对观测数据，提出了一种混合条件变分因果推断模型（MCVCI）来推断异构因果关系。具体来说，根据混合加性噪声模型（HANM）的可识别性，MCVCI结合了高斯混合模型和神经网络的优越拟合能力，并巧妙地利用从混合条件变分自编码器的概率边界获得的似然作为因果决策准则。此外，我们将因果异构性建模为聚类数量，并提出了混合条件变分因果聚类（MCVCC）方法，该方法可以揭示因果机制的表达。与最先进的方法相比，在多个模拟和真实数据集上的全面最佳性能证明了本文提出的方法的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [289] [An LLM Driven Agent Framework for Automated Infrared Spectral Multi Task Reasoning](https://arxiv.org/abs/2507.21471)
> *LLM驱动的用于自动化红外光谱多任务推理的代理框架*

*Zujie Xie, Zixuan Chen, Jiheng Liang, Xiangyang Yu, Ziru Yu* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** LLM, 红外光谱, 代理框架, 多任务推理, 低数据

**Comment:** 19 pages

> **TL;DR:** 本研究提出了一个LLM驱动的代理框架，用于在低数据条件下自动化红外光谱分析，并在多任务推理中表现出色。

**AI_Comments:** 该论文的创新点在于将大型语言模型（LLMs）作为智能代理应用于红外光谱分析，通过集成结构化的领域知识库，实现了自动化且可解释的光谱数据处理和多任务推理。特别是其提出的闭环、多轮交互协议，能够动态优化预测，有效解决了低数据量条件下的挑战，为未来科学工作流程的自动化提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 红外光谱学在化学和材料性质测量方面具有优势，但其高维、重叠的光谱带对传统化学计量学方法构成挑战。新兴的大型语言模型（LLMs）虽具泛化和推理能力，但在红外光谱分析中的应用仍未充分探索。本研究旨在解决在低数据条件下实现准确、自动化红外光谱解释的关键挑战。

**Method:** 本研究引入了一个端到端的大型语言模型驱动的代理框架。该框架将结构化文献知识库、自动化光谱预处理、特征提取和多任务推理整合到一个统一的管道中。代理通过查询精选的同行评审红外出版物语料库来选择经过科学验证的例程。选定的方法将每个光谱转换为低维特征集，然后将其输入少样本提示模板进行分类、回归和异常检测。一个闭环、多轮协议迭代地将错误预测的样本附加到提示中，从而实现预测的动态细化。

**Result:** 在印泥、中药、普洱茶、陈皮和废水COD等不同材料数据集上，多轮LLM始终优于单轮推理，在低数据条件下与机器学习和深度学习模型相媲美或超越它们。

**Conclusion:** 该LLM驱动的代理框架为自动化和准确的红外光谱解释提供了一个有效的解决方案，特别是在低数据场景下，并展示出优于传统方法的性能。

> **ai_Abstract:** 本研究提出了一个LLM驱动的代理框架，旨在解决红外光谱分析中在低数据条件下的自动化和准确解释难题。该框架整合了文献知识库、光谱预处理、特征提取和多任务推理，并通过多轮交互式精炼机制提升预测性能。实验结果表明，该方法在多种数据集上，尤其是在数据量有限的情况下，表现优于单轮推理以及传统的机器学习和深度学习模型。

> **摘要翻译:** 红外光谱学能够快速、无损地测量化学和材料性质，但其高维、重叠的光谱带对传统的化学计量学方法构成了挑战。新兴的大型语言模型（LLMs）凭借其泛化和推理能力，为自动化复杂的科学工作流程提供了广阔前景。尽管前景广阔，但它们在红外光谱分析中的应用在很大程度上仍未被探索。本研究旨在解决在低数据条件下实现准确、自动化红外光谱解释的关键挑战，利用一个LLM驱动的框架。我们引入了一个端到端的大型语言模型驱动的代理框架，该框架将结构化的文献知识库、自动化光谱预处理、特征提取和多任务推理整合到一个统一的管道中。通过查询精选的同行评审红外出版物语料库，该代理选择经过科学验证的例程。选定的方法将每个光谱转换为低维特征集，然后将其输入少样本提示模板进行分类、回归和异常检测。一个闭环、多轮协议迭代地将错误预测的样本附加到提示中，从而实现预测的动态细化。在印泥、中药、普洱茶、陈皮和废水COD等不同材料数据集上，多轮LLM始终优于单轮推理，在低数据条件下与机器学习和深度学习模型相媲美或超越它们。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [294] [Can adversarial attacks by large language models be attributed?](https://arxiv.org/abs/2411.08003)
> *大型语言模型的对抗性攻击可以被归因吗？*

*Manuel Cebrian, Andres Abeliuk, Jan Arne Telle* | **Category: cs.AI, cs.CL, cs.CY, cs.FL** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 归因, 对抗性攻击, 可识别性, 形式语言理论

**Comment:** 22 pages, 5 figures, 2 tables

> **TL;DR:** 研究表明，由于理论上的不可识别性和模型生态系统的快速增长，将大型语言模型在对抗性设置中的输出归因于特定模型在实践中是不可行的。

**AI_Comments:** 这篇论文通过结合形式语言理论的严谨性和对当前LLM生态的实证分析，对LLM输出归因问题提出了深刻的见解。其创新点在于从理论层面揭示了LLM输出归因的根本性限制，并提供了有限概率性LLM不可识别性的新反例。同时，通过量化模型数量的爆炸式增长，强调了实践中归因的不可行性。这对于理解LLM在恶意使用场景下的溯源挑战具有重要意义，对政策制定者和安全研究人员具有很高的参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 在网络攻击和虚假信息传播等对抗性场景中，归因大型语言模型（LLM）的输出面临巨大挑战，且其重要性日益增长。

**Method:** 本文从理论和实证两个角度探讨了归因问题。理论上，将LLM的可能输出集建模为形式语言，并分析有限文本样本是否能唯一识别源模型，借鉴了形式语言理论（极限识别）。实证上，对不断扩展的LLM生态系统进行数据驱动分析，量化了给定输出的可能模型来源（假设空间）的爆炸式增长。

**Result:** **理论结果**: 在模型能力重叠的温和假设下，某些类别的LLM仅凭其输出是根本无法识别的。划分了四种理论可识别性机制：1) 无限类别的确定性LLM语言不可识别；2) 无限类别的概率性LLM也不可识别；3) 有限类别的确定性LLM可识别；4) 即使是有限类别的概率性LLM也可能不可识别（提供了新的反例）。
**实证结果**: 近年来，给定输出的合理模型来源数量呈爆炸式增长。即使在保守假设下（每个开源模型最多在一个新数据集上进行微调），不同候选模型的数量大约每0.5年翻一番；允许多数据集微调组合则翻倍时间短至0.28年。这种组合增长，加上对所有模型和潜在用户进行穷举式似然归因的巨大计算成本，使得实践中的穷举归因不可行。

**Conclusion:** 鉴于LLM输出的理论不可识别性以及LLM生态系统中模型来源的组合式增长和归因的巨大计算成本，将大型语言模型在对抗性设置中的输出归因于特定模型在实践中是不可行的。

> **ai_Abstract:** 本文探讨了在对抗性场景下对大型语言模型（LLM）输出进行归因的挑战。研究结合了形式语言理论的理论分析和对LLM生态系统的实证数据分析。理论上，论文证明了在模型能力重叠的条件下，某些LLM仅凭其输出是不可识别的，并提出了四种可识别性机制，包括有限概率性LLM的不可识别性新反例。实证上，文章量化了LLM模型来源假设空间的快速增长，显示候选模型数量的指数级增加。综合来看，由于理论上的根本限制和实践中归因的巨大计算成本，将LLM的对抗性输出归因于特定模型是不可行的。

> **摘要翻译:** 将大型语言模型（LLMs）在对抗性设置（例如网络攻击和虚假信息传播）中的输出进行归因，带来了巨大的挑战，其重要性可能日益增长。我们从理论和实证两个角度探讨了这一归因问题，借鉴了形式语言理论（极限识别）和对不断扩展的LLM生态系统进行的数据驱动分析。通过将LLM的可能输出集建模为一种形式语言，我们分析了有限的文本样本是否能够唯一地确定源模型。我们的结果表明，在模型能力重叠的温和假设下，某些类别的LLM仅凭其输出是根本无法识别的。我们划分了四种理论可识别性机制：(1) 无限类别的确定性（离散）LLM语言是不可识别的（Gold在1967年的经典结果）；(2) 无限类别的概率性LLM也是不可识别的（确定性案例的延伸）；(3) 有限类别的确定性LLM是可识别的（与Angluin的“告密标准”一致）；以及(4) 即使是有限类别的概率性LLM也可能是不可识别的（我们提供了一个建立这一负面结果的新反例）。除了这些理论见解，我们还量化了近年来给定输出的合理模型来源（假设空间）数量的爆炸式增长。即使在保守假设下——每个开源模型最多在一个新数据集上进行微调——不同候选模型的数量大约每0.5年翻一番，而允许多数据集微调组合则翻倍时间短至0.28年。这种组合增长，加上对所有模型和潜在用户进行穷举式似然归因的巨大计算成本，使得实践中的穷举归因不可行。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [301] [Scoring Verifiers: Evaluating Synthetic Verification for Code and Reasoning](https://arxiv.org/abs/2502.13820)
> *评分验证器：评估代码和推理的合成验证*

*Aleksander Ficek, Somshubra Majumdar, Vahid Noroozi, Boris Ginsburg* | **Category: cs.AI, cs.CL, cs.LG, cs.SE** | **Updated: 2025-07-30**

**Keywords:** 合成验证, 代码验证, 大型语言模型, 基准测试, 推理能力

**Comment:** COLM 2025

> **TL;DR:** 本文提出了一种将现有代码基准转换为评分和排序数据集的方法，以评估合成验证器的有效性，并发布了四个新基准，实验表明推理可以显著改进测试用例生成，增加测试用例数量可提高验证准确性。

**AI_Comments:** 该论文通过提出一套将现有编码基准转化为评分和排序数据集的方法，创新性地解决了合成验证器评估的难题。其贡献在于不仅提供了新的评估框架和指标，还发布了四个实用的新基准，为未来LLM代码和推理能力的评估提供了宝贵资源。实验结果也为如何优化合成验证提供了明确的方向，强调了推理能力和测试用例规模的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的编码能力通常通过预定义测试来增强，但合成验证技术（如生成测试用例和奖励建模）能进一步提升其能力。此外，代码验证在通过强化学习提高LLM的推理能力方面取得了巨大成功。然而，缺乏有效的方法来评估这些合成验证器的效果。

**Method:** 本文提出了一种方法，可以将现有的编码基准转换为评分和排序数据集，用于评估合成验证器的有效性。同时，还提出了多种指标来衡量合成验证器的不同方面。作者利用该方法发布了四个新的基准（HE-R、HE-R+、MBPP-R和MBPP-R+），并分析了标准、基于推理和基于奖励的LLM的合成验证方法。

**Result:** 研究人员发布了四个新的基准数据集：HE-R、HE-R+、MBPP-R和MBPP-R+。实验结果表明，推理能力可以显著提高测试用例的生成质量。此外，增加测试用例的数量可以有效提高验证的准确性。

**Conclusion:** 本文提出了一种评估合成验证器的新方法和相关基准，并证明了推理在测试用例生成中的重要性以及测试用例数量对验证准确性的积极影响。

> **ai_Abstract:** 本文提出了一种评估大型语言模型（LLM）合成验证器有效性的新方法。该方法将现有代码基准转换为评分和排序数据集，并引入多项指标。研究者基于此方法发布了HE-R、HE-R+、MBPP-R和MBPP-R+四个新基准，并对标准、基于推理和基于奖励的LLM的合成验证进行了分析。实验结果表明，推理能显著提升测试用例生成效果，且增加测试用例数量可提高验证准确性。

> **摘要翻译:** 合成验证技术，如生成测试用例和奖励建模，是增强大型语言模型（LLM）编码能力超越预定义测试的常用方法。此外，代码验证最近在通过强化学习提高LLM推理能力方面取得了巨大成功。在本文中，我们提出了一种方法，可以将现有编码基准转换为评分和排序数据集，以评估合成验证器的有效性。我们还提出了多种指标来衡量合成验证器在所提出基准中的不同方面。通过采用所提出的方法，我们发布了四个新的基准（HE-R、HE-R+、MBPP-R和MBPP-R+），并分析了使用标准、基于推理和基于奖励的LLM的合成验证方法。我们的实验表明，推理可以显著改善测试用例生成，并且扩大测试用例的数量可以提高验证准确性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [337] [Tell Me You're Biased Without Telling Me You're Biased -- Toward Revealing Implicit Biases in Medical LLMs](https://arxiv.org/abs/2507.21176)
> *告诉我你带有偏见，而无需直接告诉我——揭示医疗大型语言模型中的隐性偏见*

*Farzana Islam Adiba, Rahmatollah Beheshti* | **Category: cs.AI** | **Updated: 2025-07-26**

**Keywords:** 医疗LLMs, 偏见检测, 知识图谱, 对抗性扰动, 偏见模式

**Comment:** 

> **TL;DR:** 本研究提出了一种结合知识图谱和辅助大型语言模型的新颖框架，用于系统性地揭示医疗大型语言模型中复杂的偏见模式，并实验证明其在揭示偏见方面比现有基线方法具有更强的能力和可扩展性。

**AI_Comments:** 该论文提出了一种新颖且实用的方法来解决医疗大型语言模型中的关键问题——偏见检测。其创新之处在于结合了知识图谱和对抗性扰动技术，这使得它能够揭示传统方法难以发现的复杂和隐性偏见。这对于确保医疗AI的公平性和可靠性至关重要，具有重要的应用价值。该研究的可扩展性也为其在未来更广泛的LLM评估中提供了潜力。

<details>
  <summary>Details</summary>

**Motivation:** 用于医疗应用的大型语言模型存在偏见和不公平模式。在将这些模型应用于临床决策之前，识别这些偏见模式至关重要，以便有效减轻其影响。

**Method:** 本研究提出了一种结合知识图谱（KGs）和辅助大型语言模型（LLMs）的新颖框架，用于系统性地揭示医疗LLMs中复杂的偏见模式。具体而言，该方法整合了对抗性扰动技术以识别细微的偏见模式，并采用了定制的多跳知识图谱表征来增强对任意LLMs的系统评估。

**Result:** 通过在三个数据集、六个LLMs和五种偏见类型上进行的一系列综合实验表明，与现有基线方法相比，所提出的框架在揭示LLMs复杂偏见模式方面具有显著更强的能力和可扩展性。

**Conclusion:** 本研究提出的结合知识图谱和辅助大型语言模型的新颖框架，能够有效且可扩展地揭示医疗大型语言模型中复杂的隐性偏见，这对于确保其在临床应用中的公平性和安全性至关重要。

> **ai_Abstract:** 本研究旨在解决医疗大型语言模型中存在的偏见问题，提出了一种创新的框架，该框架结合了知识图谱和辅助大型语言模型。通过整合对抗性扰动技术和定制的多跳知识图谱表征，该框架能够系统性地识别和揭示医疗LLMs中复杂的、甚至是细微的偏见模式。实验结果表明，与现有方法相比，该框架在偏见检测能力和可扩展性方面均表现出显著优势。

> **摘要翻译:** 用于医疗应用的大型语言模型（LLMs）已知会表现出有偏见和不公平的模式。在将这些模型应用于临床决策之前，识别这些偏见模式至关重要，以便有效减轻其影响。在本研究中，我们提出了一个新颖的框架，它结合了知识图谱（KGs）和辅助LLMs，以系统地揭示医疗LLMs中复杂的偏见模式。具体而言，所提出的方法整合了对抗性扰动技术来识别细微的偏见模式。该方法采用了定制的多跳知识图谱表征，以增强对任意LLMs的系统评估。通过一系列综合实验（在三个数据集、六个LLMs和五种偏见类型上），我们表明我们提出的框架与其它基线方法相比，在揭示LLMs复杂偏见模式方面具有显著更强的能力和可扩展性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [340] [MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE](https://arxiv.org/abs/2507.21802)
> *MixGRPO：通过混合ODE-SDE解锁基于流的GRPO效率*

*Junzhe Li, Yutao Cui, Tao Huang, Yinping Ma, Chun Fan, Miles Yang, Zhao Zhong* | **Category: cs.AI, cs.CV** | **Updated: 2025-07-29**

**Keywords:** GRPO, 流匹配, SDE, ODE, 图像生成, 效率优化

**Comment:** 

> **TL;DR:** MixGRPO通过结合SDE和ODE的混合采样策略，显著提高了基于流的GRPO模型在图像生成人类偏好对齐中的效率和性能。

**AI_Comments:** MixGRPO通过引入混合ODE-SDE采样策略和滑动窗口机制，巧妙地解决了GRPO模型在效率上的瓶颈，这是一种新颖且实用的优化方法。其创新点在于将计算资源集中于关键的时间步长，同时利用ODE的确定性优势来加速非关键部分的采样，从而在保证性能的同时大幅提升了训练效率。MixGRPO-Flash的提出进一步展示了该方法的通用性和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于流的GRPO方法（如FlowGRPO）由于需要在马尔可夫决策过程（MDP）中对所有去噪步骤进行采样和优化，效率低下。

**Method:** 论文提出了MixGRPO框架，通过集成随机微分方程（SDE）和常微分方程（ODE）来利用混合采样策略。它引入了一个滑动窗口机制，在窗口内使用SDE采样和GRPO引导优化，而在窗口外应用ODE采样。这种设计将采样随机性限制在窗口内的时间步长，减少了优化开销。此外，还提出了MixGRPO-Flash变体，通过支持滑动窗口之外更高阶的求解器进一步提高训练效率。

**Result:** MixGRPO在人类偏好对齐的多个维度上表现出显著增益，在有效性和效率方面均优于DanceGRPO，训练时间降低了近50%。MixGRPO-Flash进一步将训练时间减少了71%，同时保持了可比的性能。

**Conclusion:** MixGRPO及其变体MixGRPO-Flash通过创新的混合采样策略和滑动窗口机制，显著提高了基于流的GRPO模型在图像生成人类偏好对齐中的效率和性能。

> **ai_Abstract:** 本文提出MixGRPO框架，通过结合SDE和ODE的混合采样策略，解决了现有基于流的GRPO方法在图像生成人类偏好对齐中的效率问题。MixGRPO引入滑动窗口机制，在窗口内使用SDE进行优化，窗口外使用ODE，从而减少优化开销并加速收敛。其变体MixGRPO-Flash进一步提升了训练效率。实验结果表明，MixGRPO及其变体在性能和效率上均显著优于现有方法，训练时间大幅缩短。

> **摘要翻译:** 尽管GRPO在图像生成的人类偏好对齐中显著增强了流匹配模型，但像FlowGRPO这样的方法由于需要在马尔可夫决策过程（MDP）中对所有去噪步骤进行采样和优化，仍然表现出效率低下。在本文中，我们提出了**MixGRPO**，这是一个新颖的框架，通过集成随机微分方程（SDE）和常微分方程（ODE）来利用混合采样策略。这简化了MDP内的优化过程，以提高效率并提升性能。具体来说，MixGRPO引入了一个滑动窗口机制，仅在窗口内使用SDE采样和GRPO引导优化，而在窗口外应用ODE采样。这种设计将采样随机性限制在窗口内的时间步长，从而减少了优化开销，并允许更集中的梯度更新以加速收敛。此外，由于滑动窗口之外的时间步长不参与优化，因此支持更高阶的求解器进行采样。因此，我们提出了一个更快的变体，称为**MixGRPO-Flash**，它在实现可比性能的同时进一步提高了训练效率。MixGRPO在人类偏好对齐的多个维度上表现出显著增益，在有效性和效率方面均优于DanceGRPO，训练时间降低了近50%。值得注意的是，MixGRPO-Flash进一步将训练时间减少了71%。代码和模型可在https://github.com/Tencent-Hunyuan/MixGRPO 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [343] [Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence](https://arxiv.org/abs/2506.15677)
> *具身网络智能体：连接物理-数字领域以实现集成智能体智能*

*Yining Hong, Rui Sun, Bingxuan Li, Xingcheng Yao, Maxine Wu, Alexander Chien, Da Yin, Ying Nian Wu, Zhecan James Wang, Kai-Wei Chang* | **Category: cs.AI, cs.CL, cs.CV, cs.MM, cs.RO** | **Updated: 2025-07-29**

**Keywords:** 具身智能体, 网络智能体, 物理-数字融合, AI智能体, 基准

**Comment:** 

> **TL;DR:** 本文提出具身网络智能体，一个将具身感知与网络规模推理相结合的新范式，并开发了相应的模拟平台和基准，揭示了现有AI系统与人类能力之间的显著差距。

**AI_Comments:** 本文提出具身网络智能体这一创新范式，旨在解决当前AI智能体在整合物理与数字领域智能方面的局限性。其重要性在于构建了一个统一的模拟平台和综合基准，为评估和推进具身与网络结合的AI能力提供了具体工具和评估标准。研究结果揭示了现有AI系统与人类能力的显著差距，明确了未来研究的挑战和方向，具有重要的开创性意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的AI智能体要么专注于数字信息处理，要么专注于物理世界交互，很少能同时进行。这种分离限制了它们解决需要整合物理和数字智能的任务的能力，例如根据在线食谱烹饪或使用网络知识解释现实世界地标。

**Method:** 研究引入了“具身网络智能体”这一新范式，并为此开发了“具身网络智能体任务环境”，这是一个统一的模拟平台，紧密整合了真实的3D室内外环境与功能性网页界面。在此基础上，构建并发布了“具身网络智能体基准”，包含烹饪、导航、购物、旅游和地理定位等多项任务，这些任务均需物理和数字领域间的协同推理。

**Result:** 实验结果显示，最先进的AI系统与人类能力之间存在显著的性能差距，这在具身认知和网络规模知识获取的交叉领域带来了挑战和机遇。

**Conclusion:** 本文通过引入具身网络智能体范式、开发统一模拟平台和发布综合基准，揭示了当前AI系统在整合物理与数字智能方面的不足，并为未来在该交叉领域的研究指明了方向和挑战。

> **ai_Abstract:** 本文提出具身网络智能体，旨在弥合AI智能体在数字信息处理与物理世界交互之间的鸿沟，以解决需要整合物理和数字智能的复杂任务。为此，研究团队开发了一个统一的模拟平台“具身网络智能体任务环境”，并构建了包含多种跨领域任务的“具身网络智能体基准”进行评估。实验结果表明，当前最先进的AI系统与人类能力之间存在显著差距，这为具身认知与网络知识结合领域的研究提出了新的挑战与机遇。

> **摘要翻译:** 当前的人工智能智能体大多是孤立的——它们要么检索和推理在线获取的大量数字信息和知识；要么通过具身感知、规划和行动与物理世界互动——但很少两者兼顾。这种分离限制了它们解决需要整合物理和数字智能的任务的能力，例如根据在线食谱烹饪、使用动态地图数据导航或使用网络知识解释现实世界地标。我们引入了具身网络智能体，这是一种能够流畅地连接具身和网络规模推理的新型人工智能智能体范式。为了实现这一概念，我们首先开发了具身网络智能体任务环境，这是一个统一的模拟平台，紧密整合了真实的3D室内外环境与功能性网页界面。在此平台基础上，我们构建并发布了具身网络智能体基准，该基准包含一系列多样化的任务，包括烹饪、导航、购物、旅游和地理定位——所有这些任务都需要在物理和数字领域之间进行协调推理，以便系统地评估跨领域智能。实验结果揭示了最先进的人工智能系统与人类能力之间存在显著的性能差距，这在具身认知和网络规模知识获取的交叉领域带来了挑战和机遇。所有数据集、代码和网站均可在我们的项目页面 https://embodied-web-agent.github.io/ 公开获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [345] [Learning to Imitate with Less: Efficient Individual Behavior Modeling in Chess](https://arxiv.org/abs/2507.21488)
> *用更少的数据学习模仿：国际象棋中高效的个体行为建模*

*Zhenwei Tang, Difan Jiao, Eric Xue, Reid McIlroy-Young, Jon Kleinberg, Siddhartha Sen, Ashton Anderson* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 个体行为建模, 国际象棋, 数据效率, Maia4All, 个性化AI

**Comment:** 

> **TL;DR:** Maia4All是一个新框架，它使用少量数据（20局棋）即可高效地模拟国际象棋中的个体人类行为，显著优于传统方法（5000局棋）。

**AI_Comments:** Maia4All的创新之处在于其两阶段优化过程，通过“原型丰富”和“民主化”步骤，极大地降低了训练个体AI模型所需的数据量，从5000局减少到20局，这是数据效率上的巨大突破。这使得个性化AI建模对于数据稀疏或新用户变得可行，具有重要的实际应用价值。其超越国际象棋，应用于LLMs的潜力也表明了该方法的普适性和广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人类行为建模方法需要大量的个体数据，这对于新用户或数据稀疏的用户来说不切实际，阻碍了人工智能系统准确模拟个体决策。

**Method:** 本研究引入了Maia4All框架，通过两阶段优化过程实现高效的个体决策风格学习和适应：1) 丰富步骤，通过原型丰富的模型连接群体和个体层面的人类行为建模；2) 民主化步骤，利用能力水平或用户原型初始化和细化个体嵌入，仅需最少的数据。

**Result:** Maia4All能够以高保真度准确预测个体走法并分析行为模式，仅需20局棋即可实现个体人类行为建模，而传统方法需要5,000局棋，显著提高了数据效率。

**Conclusion:** Maia4All为国际象棋中的个性化类人AI行为建模树立了新标准，并通过原型丰富的模型展示了群体AI系统如何灵活适应个体用户，该方法也适用于国际象棋之外的领域，如LLMs。

> **ai_Abstract:** 该论文介绍了Maia4All，一个用于国际象棋中高效个体行为建模的框架。针对现有方法需要大量个体数据的问题，Maia4All采用两阶段优化过程：通过原型丰富模型连接群体和个体行为，并利用用户原型初始化个体嵌入，从而在仅有20局棋的数据量下，实现了高精度预测个体走法和分析行为模式，相较于传统方法所需的5000局棋，数据效率显著提高。该方法不仅适用于国际象棋，也为个性化AI适应提供了普适性范例。

> **摘要翻译:** 随着人类寻求与人工智能系统协作、学习并更好地理解它们，开发能够准确模仿个体决策的人工智能变得越来越重要。国际象棋，一个长期以来的人工智能基准，具有精确的技能衡量标准，为人类-人工智能对齐提供了理想的试验平台。然而，现有的人类行为建模方法需要每个个体提供大量数据，这使得它们对于新用户或数据稀疏的用户来说不切实际。在这项工作中，我们引入了Maia4All，一个旨在即使数据有限也能高效学习和适应个体决策风格的框架。Maia4All通过两阶段优化过程实现这一点：(1) 丰富步骤，通过原型丰富的模型连接群体和个体层面的人类行为建模；(2) 民主化步骤，利用能力水平或用户原型初始化和细化个体嵌入，仅需最少的数据。我们的实验结果表明，Maia4All能够以高保真度准确预测个体走法并分析行为模式，为国际象棋中个性化的类人AI行为建模建立了新标准。Maia4All仅需20局棋即可实现国际象棋中的个体人类行为建模，而之前需要5,000局棋，这代表了数据效率的显著提升。我们的工作提供了一个例子，说明群体AI系统如何使用原型丰富的模型作为桥梁灵活适应个体用户。这种方法超越了国际象棋，正如我们在对特殊LLMs的案例研究中所展示的那样，突出了其在个性化AI适应中更广泛应用的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [386] [An Agentic AI for a New Paradigm in Business Process Development](https://arxiv.org/abs/2507.21823)
> *业务流程开发新范式的智能体AI*

*Mohammad Azarijafari, Luisa Mich, Michele Missikoff* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 智能体AI, 业务流程开发, 工业自动化, 模块化, 协作

**Comment:** 

> **TL;DR:** 本文提出一种基于智能体AI的业务流程开发新方法，实现更模块化、智能和灵活的自动化。

**AI_Comments:** 这篇论文提出了一种创新的业务流程开发范式，将AI智能体引入业务流程设计，从传统的任务导向转变为目标、对象和智能体导向。其重要性在于提升了业务流程的模块化、智能化、灵活性和上下文感知能力，特别适用于动态工业环境。

<details>
  <summary>Details</summary>

**Motivation:** 传统业务流程设计是基于任务的，而AI智能体是工业自动化技术演进的下一场重大革命，需要一种新的方法来利用智能体AI的能力进行业务流程设计和开发。

**Method:** 提出一种新的业务流程设计和开发方法，该方法利用智能体AI的能力，并采用基于智能体的方法，其中智能体通过业务对象实现业务目标。当单个智能体无法实现目标时，引入“合并目标”概念，通过多个智能体协作实现。模型围绕目标、对象和智能体进行组织。

**Result:** 该方法实现了更模块化和智能的业务流程开发。结果是，这种方法能够在动态工业环境中实现灵活且上下文感知的自动化。

**Conclusion:** 基于智能体、目标和对象的模型可以实现更模块化、智能、灵活和上下文感知的业务流程开发，适用于动态工业环境。

> **ai_Abstract:** 本文提出了一种利用智能体AI进行业务流程设计和开发的新范式。与传统基于任务的方法不同，该研究引入了一种基于智能体的方法，其中智能体协同工作以实现业务目标（通过业务对象定义），包括通过多智能体协作实现的“合并目标”。这种模型通过将流程围绕目标、对象和智能体进行组织，从而实现更模块化、智能、灵活和上下文感知的自动化，适用于动态工业环境。

> **摘要翻译:** 人工智能智能体代表着工业自动化技术持续演进中的下一次重大革命。在本文中，我们介绍了一种利用智能体AI能力进行业务流程设计和开发的新方法。我们摒弃了传统的基于任务的业务流程设计方法，提出了一种基于智能体的方法，其中智能体通过一组业务对象识别的业务目标做出贡献。当单个智能体无法完成目标时，我们有一个可以通过多个智能体协作实现的合并目标。所提出的模型通过围绕目标、对象和智能体进行组织，从而实现更模块化和智能的业务流程开发。因此，这种方法能够在动态工业环境中实现灵活且上下文感知的自动化。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [397] [Large Language Models for Supply Chain Decisions](https://arxiv.org/abs/2507.21502)
> *大型语言模型在供应链决策中的应用*

*David Simchi-Levi, Konstantina Mellou, Ishai Menache, Jeevan Pathuri* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 供应链管理, 决策支持, 优化, 自动化

**Comment:** Forthcoming chapter in AI in Supply Chains: Perspectives from Global
  Thought Leaders, edited by Maxime C. Cohen and Tinglong Dai, and part of the
  Springer Series in Supply Chain Management (edited by Prof. Chris Tang)

> **TL;DR:** 本文探讨了如何利用大型语言模型（LLMs）解决当前供应链管理中优化工具的理解、交互和模型更新的挑战，从而显著缩短决策时间并提高效率。

**AI_Comments:** 本文提出了利用大型语言模型解决传统供应链优化工具在实际应用中面临的理解、交互和模型更新的痛点，具有重要的创新性。它指出了LLMs在促进技术民主化、提高决策效率方面的巨大潜力，对于推动供应链管理智能化具有里程碑意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的供应链管理中，尽管使用了优化技术，但业务规划者和高管仍需花费大量时间精力去理解、解释技术建议，分析情景，并更新数学模型。这导致决策过程缓慢，需要数据科学团队或技术提供商的介入。

**Method:** 本文报告了如何应用大型语言模型（LLMs）来解决现有供应链优化工具所面临的三个挑战：促进对工具结果的理解，以及实现与供应链工具的无人干预交互。

**Result:** 应用大型语言模型后，决策时间从几天几周显著缩短至几分钟几小时，并大幅提升了规划者和高管的生产力及影响力。

**Conclusion:** 大型语言模型可以颠覆性地使供应链技术民主化，促进对工具结果的理解并实现无人干预的交互，从而显著提高决策效率。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在供应链决策中的应用。当前供应链管理中，尽管有优化工具，但业务规划者在理解、交互和模型更新方面仍面临挑战，导致决策效率低下。受LLMs最新进展启发，研究提出利用LLMs来解决这些问题，旨在使供应链技术民主化，促进对工具结果的理解并实现无人干预的交互。实验表明，LLMs的应用能够显著缩短决策时间，并提高规划者和高管的生产力。

> **摘要翻译:** 供应链管理需要解决各种复杂的决策挑战，从采购策略到规划和执行。在过去的几十年里，计算和信息技术的进步使得决策从手动、基于直觉和经验的方式，转变为使用各种应用优化技术的工具进行更自动化和数据驱动的决策。这些技术使用数学方法来改进决策。不幸的是，业务规划者和高管仍然需要花费大量时间和精力来（i）理解和解释这些技术提供的建议；（ii）分析各种情景并回答假设性问题；（iii）更新这些工具中使用的数学模型以反映当前的业务环境。解决这些挑战需要数据科学团队和/或技术提供商参与解释结果或对技术进行必要的更改，从而显著减慢决策速度。受大型语言模型（LLM）最新进展的启发，我们报告了这项颠覆性技术如何使供应链技术民主化——即促进对工具结果的理解，以及在无人干预的情况下与供应链工具进行交互。具体来说，我们报告了我们如何应用LLM来解决上述三个挑战，从而将决策时间从几天几周大幅缩短到几分钟几小时，并显著提高规划者和高管的生产力和影响力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [402] [Agentic Web: Weaving the Next Web with AI Agents](https://arxiv.org/abs/2507.21206)
> *智能体网络：用AI智能体编织下一个网络*

*Yingxuan Yang, Mulei Ma, Yuxuan Huang, Huacan Chai, Chenyu Gong, Haoran Geng, Yuanjian Zhou, Ying Wen, Meng Fang, Muhao Chen, Shangding Gu, Ming Jin, Costas Spanos, Yang Yang, Pieter Abbeel, Dawn Song, Weinan Zhang, Jun Wang* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 智能体网络, AI智能体, 大型语言模型, 机器对机器交互, 框架

**Comment:** 

> **TL;DR:** 论文提出了一个用于理解和构建“智能体网络”的框架，该网络由LLM驱动的AI智能体定义，旨在通过机器对机器交互实现自动化和目标驱动的任务执行，从而减轻用户负担。

**AI_Comments:** 这篇论文为理解“智能体网络”这一新兴概念提供了一个全面的宏观视角和结构化框架。其创新之处在于提出了智能、交互和经济三个关键维度来分析智能体系统的核心能力，并前瞻性地讨论了技术挑战、社会风险和治理问题。这对于推动AI智能体在网络中的发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）驱动的AI智能体的兴起，互联网正向“智能体网络”转变，用户意图可以被委托给智能体，从而减轻用户日常数字操作的负担，并实现更互动、自动化的网络体验。

**Method:** 论文提出了一个结构化的框架来理解和构建智能体网络。该框架追溯了智能体网络从PC和移动网络时代的发展，并确定了支持这一转变的核心技术基础。核心是一个包含智能、交互和经济三个关键维度的概念模型。论文还分析了创建可扩展智能体系统所涉及的架构和基础设施挑战，包括通信协议、编排策略和新兴范式（如智能体注意力经济）。

**Result:** 论文提出了一个用于理解和构建智能体网络的结构化框架，并识别了其核心技术基础和关键维度（智能、交互、经济），这些维度共同实现了AI智能体的能力。同时，分析了构建可扩展智能体系统面临的挑战。

**Conclusion:** 论文讨论了智能体网络的潜在应用、社会风险和治理问题，并概述了开发由人类意图和自主智能体行为共同塑造的开放、安全、智能生态系统的研究方向。

> **ai_Abstract:** 本文探讨了由大型语言模型（LLMs）驱动的AI智能体所带来的“智能体网络”新范式。该网络通过机器对机器的自主交互，使智能体能代表用户执行复杂任务，从而实现自动化并减轻用户负担。论文提出了一个结构化框架来理解和构建智能体网络，该框架追溯了其演变，并提出了一个包含智能、交互和经济三个核心维度的概念模型，以支持智能体的能力。文章还分析了构建可扩展智能体系统的架构和基础设施挑战，并讨论了其潜在应用、社会风险、治理问题以及未来的研究方向。

> **摘要翻译:** 由大型语言模型（LLMs）驱动的AI智能体的出现标志着互联网向智能体网络（Agentic Web）的关键转变，这是互联网的一个新阶段，其特点是自主的、目标驱动的交互。在这种范式下，智能体直接相互作用，代表用户规划、协调和执行复杂任务。这种从人类驱动到机器对机器交互的转变，使得意图可以被委托，从而减轻用户日常数字操作的负担，并实现更互动、自动化的网络体验。在本文中，我们提出了一个结构化的框架来理解和构建智能体网络。我们追溯了它从PC和移动网络时代的演变，并确定了支持这一转变的核心技术基础。我们框架的核心是一个由智能、交互和经济三个关键维度组成的概念模型。这些维度共同支持了AI智能体的能力，例如检索、推荐、规划和协作。我们分析了创建可扩展智能体系统所涉及的架构和基础设施挑战，包括通信协议、编排策略以及智能体注意力经济等新兴范式。最后，我们讨论了智能体系统带来的潜在应用、社会风险和治理问题，并概述了开发由人类意图和自主智能体行为共同塑造的开放、安全、智能生态系统的研究方向。智能体网络相关研究的持续更新集合可在以下网址获取：https://github.com/SafeRL-Lab/agentic-web。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [434] [DualSG: A Dual-Stream Explicit Semantic-Guided Multivariate Time Series Forecasting Framework](https://arxiv.org/abs/2507.21830)
> *DualSG：一种双流显式语义引导的多元时间序列预测框架*

*Kuiye Ding, Fanda Fan, Yao Wang, Ruijie jian, Xiaorui Wang, Luqi Gong, Yishan Jiang, Chunjie Luo an Jianfeng Zhan* | **Category: cs.AI** | **Updated: 2025-07-30**

**Keywords:** 多元时间序列预测, 大型语言模型, 语义引导, 双流框架, 时间序列描述

**Comment:** This paper has been accepted by ACM Multimedia 2025 (ACM MM 2025)

> **TL;DR:** DualSG是一个双流框架，将LLM作为语义引导模块，通过时间序列描述和引导融合模块，显式地将数值预测与语义引导结合起来，在多元时间序列预测中优于现有方法。

**AI_Comments:** DualSG的创新之处在于其将LLM定位为“语义引导模块”而非“端到端预测器”，有效规避了LLM在处理数值精度方面的固有劣势。通过引入“时间序列描述”这种显式提示格式，解决了文本与时间序列模态隐式对齐的难题，提供了更好的可解释性。其双流框架和引导融合模块的设计，在提升预测性能的同时，也兼顾了计算效率，对于结合LLM进行时间序列预测领域具有重要参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的将大型语言模型（LLMs）用于多元时间序列预测（MTSF）的方法存在问题：将LLMs作为端到端预测器会导致数值精度损失，并迫使LLMs处理超出其设计范围的模式；尝试在潜在空间中对齐文本和时间序列模态常遇到对齐困难。

**Method:** 提出DualSG，一个双流框架，提供显式语义引导，其中LLMs充当语义引导器来优化而非替代传统预测。引入了时间序列描述（Time Series Caption），这是一种显式的提示格式，以自然语言总结趋势模式，并为LLMs提供可解释的上下文。设计了一个描述引导融合模块（caption-guided fusion module），显式建模变量间关系，同时减少噪声和计算。

**Result:** 在来自不同领域的真实世界数据集上的实验表明，DualSG始终优于15种最先进的基线方法。

**Conclusion:** 显式地将数值预测与语义引导相结合对于多元时间序列预测是有效的，并且DualSG框架证明了其价值。

> **ai_Abstract:** 本文提出了DualSG，一个用于多元时间序列预测的双流框架。针对现有LLM在时间序列预测中精度低和模态对齐难的问题，DualSG将LLM作为语义引导模块而非独立预测器，通过显式的时间序列描述（Time Series Caption）和描述引导融合模块，将数值预测与语义指导相结合。实验证明DualSG在多个真实世界数据集上优于现有SOTA方法。

> **摘要翻译:** 多元时间序列预测在许多应用中扮演着关键角色。最近的工作探索了使用大型语言模型（LLMs）进行多元时间序列预测（MTSF），以利用其推理能力。然而，许多方法将LLMs视为端到端预测器，这通常导致数值精度损失，并迫使LLMs处理超出其预期设计的模式。另外，试图在潜在空间中对齐文本和时间序列模态的方法经常遇到对齐困难。在本文中，我们提出不将LLMs视为独立的预测器，而是将其作为双流框架中的语义引导模块。我们提出了DualSG，一个提供显式语义引导的双流框架，其中LLMs充当语义引导器来优化而非替代传统预测。作为DualSG的一部分，我们引入了时间序列描述（Time Series Caption），这是一种显式的提示格式，它以自然语言总结趋势模式，并为LLMs提供可解释的上下文，而不是依赖于潜在空间中文本和时间序列之间的隐式对齐。我们还设计了一个描述引导融合模块，它显式地建模变量间关系，同时减少噪声和计算。在来自不同领域的真实世界数据集上的实验表明，DualSG始终优于15种最先进的基线方法，证明了显式结合数值预测与语义引导的价值。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [447] [MoHoBench: Assessing Honesty of Multimodal Large Language Models via Unanswerable Visual Questions](https://arxiv.org/abs/2507.21503)
> *MoHoBench：通过无法回答的视觉问题评估多模态大型语言模型的诚实性*

*Yanxu Zhu, Shitong Duan, Xiangxu Zhang, Jitao Sang, Peng Zhang, Tun Lu, Xiao Zhou, Jing Yao, Xiaoyuan Yi, Xing Xie* | **Category: cs.AI, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 多模态大型语言模型, 诚实性, 无法回答的视觉问题, MoHoBench, 可信赖性

**Comment:** 

> **TL;DR:** MoHoBench是一个新基准，用于评估多模态大型语言模型（MLLMs）在面对无法回答的视觉问题时的诚实性。研究发现大多数MLLMs未能拒绝回答不恰当的问题，且其诚实性受视觉信息而非仅语言建模影响，需要专门的多模态对齐方法。

**AI_Comments:** 该论文通过关注MLLM在面对无法回答的视觉问题时的“诚实性”，解决了多模态模型可信度的一个关键但未充分探索的方面，具有创新性。MoHoBench作为一个大规模、高质量控制的基准的创建是一项重要贡献。研究发现视觉信息深刻影响诚实性，这突显了多模态对齐的复杂性以及仅基于语言的解决方案的不足。对齐方法的初步探索为未来构建更可靠的MLLM提供了宝贵的起点。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大型语言模型（MLLMs）在视觉-语言任务中取得了显著进展，但它们可能产生有害或不可信的内容。现有工作对语言模型的可信度进行了研究，但MLLMs在面对无法回答的视觉问题时的诚实行为能力仍未得到充分探索。

**Method:** 本研究将诚实性定义为模型对无法回答的视觉问题的响应行为，并定义了四种代表性问题类型。构建了MoHoBench，一个包含12k+视觉问题样本的大规模MLLM诚实性基准，其质量通过多阶段过滤和人工验证保证。使用MoHoBench对28个流行的MLLM进行了诚实性基准测试和全面分析。此外，还使用监督学习和偏好学习实现了初步的对齐方法以改善诚实行为。

**Result:** 研究发现：（1）大多数模型在必要时未能适当地拒绝回答；（2）MLLMs的诚实性不仅仅是语言建模问题，而且深受视觉信息的影响。

**Conclusion:** 需要开发专门的多模态诚实性对齐方法。本研究使用监督学习和偏好学习实现了初步的对齐方法，以改善诚实行为，为未来可信赖的MLLM工作奠定了基础。

> **ai_Abstract:** 本文提出了MoHoBench，这是一个首次系统评估多模态大型语言模型（MLLMs）在面对无法回答的视觉问题时诚实性的基准。MoHoBench包含超过12,000个经过严格筛选的视觉问题样本。研究发现，大多数MLLMs难以拒绝不恰当的回答，并且它们的诚实性受视觉信息而非单纯语言建模的显著影响。这表明需要开发专门的多模态诚实性对齐方法，并且本文介绍了使用监督学习和偏好学习进行初步对齐的探索。

> **摘要翻译:** 最近，多模态大型语言模型（MLLM）在视觉-语言任务中取得了显著进展，但也可能产生有害或不可信的内容。尽管对语言模型的可信度进行了大量研究，但MLLM的诚实行为能力，特别是在面对无法回答的视觉问题时，仍未得到充分探索。这项工作首次对各种MLLM的诚实行为进行了系统评估。我们将诚实性定义为模型对无法回答的视觉问题的响应行为，定义了四种此类问题的代表性类型，并构建了MoHoBench，一个大规模的MLLM诚实性基准，包含12k+视觉问题样本，其质量通过多阶段过滤和人工验证得到保证。使用MoHoBench，我们对28个流行的MLLM的诚实性进行了基准测试并进行了全面分析。我们的发现表明：（1）大多数模型在必要时未能适当地拒绝回答，并且（2）MLLM的诚实性不仅仅是语言建模问题，而且深受视觉信息的影响，这需要开发专门的多模态诚实性对齐方法。因此，我们使用监督学习和偏好学习实现了初步的对齐方法，以改善诚实行为，为未来可信赖的MLLM工作奠定了基础。我们的数据和代码可在https://github.com/DSTTSD/MoHoBench找到。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [459] [Finding Uncommon Ground: A Human-Centered Model for Extrospective Explanations](https://arxiv.org/abs/2507.21571)
> *寻找不寻常的共识：一种以人为中心的外部解释模型*

*Laura Spillner, Nima Zargham, Mihai Pomarlan, Robert Porzel, Rainer Malaka* | **Category: cs.AI, cs.HC** | **Updated: 2025-07-29**

**Keywords:** AI解释, 人工智能, 个性化, 以人为中心, 世界观模型

**Comment:** Presented at the IJCAI 2023 Workshop on Explainable Artificial
  Intelligence (XAI)

> **TL;DR:** 本文提出了一种以人为中心的个性化AI解释方法，通过构建代理的世界观模型来为用户提供最相关的新信息。

**AI_Comments:** 该论文的创新之处在于将AI解释的重心从模型内部机制转移到以人为中心的视角，强调个性化和上下文的重要性。通过引入“代理的世界观”和“动态记忆”的概念，提供了一种新颖的机制来估计用户对信息的了解程度，从而提供更有效、更贴合用户需求的解释。这对于提高AI的透明度和用户信任度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AI解释主要关注模型内部机制，但对于非专业用户而言往往不适用。为了促进以人为本的AI解释，需要关注个体及其偏好以及解释的上下文。

**Method:** 本文提出了一种个性化的解释方法，代理根据用户最可能感兴趣的信息来定制提供的内容。为此，提出了一种代理的世界观模型，该模型也作为其与同一用户之前交互的个人动态记忆，基于此人工智能代理可以估计其知识中哪些部分最可能是用户的新信息。

**Result:** Not mentioned in abstract

**Conclusion:** 本文提出了一种以人为中心的个性化AI解释模型，通过代理的世界观和动态记忆来提供对用户最相关的新信息。

> **ai_Abstract:** 本文针对现有AI解释不适用于非专业用户的问题，提出了一种以人为中心的个性化AI解释模型。该模型通过构建代理的世界观和动态记忆，能够根据用户需求和上下文，提供最相关且对用户而言是新颖的解释信息，从而提升AI解释的可用性和用户体验。

> **摘要翻译:** AI解释的需求，在很大程度上，是由增加黑盒机器学习模型透明度的愿望所驱动的。然而，这类解释，即关注导致特定输出的内部机制，通常不适合非专业人士。为了促进以人为本的AI解释，代理需要关注个体及其偏好以及解释给出的上下文。本文提出了一种个性化的解释方法，代理根据最可能与用户相关的信息来定制提供的内容。我们提出了一种代理的世界观模型，该模型也作为其与同一用户之前交互的个人动态记忆，基于此人工智能代理可以估计其知识中哪些部分最可能是用户的新信息。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [465] [CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting](https://arxiv.org/abs/2507.21257)
> *CompoST：一个用于分析大型语言模型在QALD设置中组合解释问题能力的基准*

*David Maria Schmidt, Raoul Schubert, Philipp Cimiano* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-28**

**Keywords:** 大型语言模型, 组合解释, SPARQL查询, 基准, CompoST

**Comment:** Research Track, 24th International Semantic Web Conference (ISWC
  2025), November 2-6, 2025, Nara, Japan

> **TL;DR:** 本文提出了CompoST基准，发现LLM在将问题组合式地解释为SPARQL查询方面存在困难，即使提供了原子构建块，性能也显著下降。

**AI_Comments:** 本文通过引入CompoST基准，填补了LLM在组合解释能力评估方面的空白，具有重要的研究价值。其受控数据集的构建方式新颖，能够有效揭示LLM在处理复杂结构化信息时的深层局限性。研究结果表明，当前LLM在真正的组合推理方面仍有待提高，为未来的模型改进指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在将问题映射到SPARQL查询方面表现出色，但其解释过程的系统性仍是未解之谜。本研究旨在探究LLM解释问题的能力在多大程度上是组合性的。

**Method:** 本文提出了CompoST基准，并基于DBpedia中的图模式生成了三个难度不同的数据集，利用Lemon词典进行语言化。这些数据集以受控方式创建，用于测试LLM在已知原子构建块的情况下解释结构复杂问题的能力。实验使用了不同大小的模型，并采用了多种提示、少样本优化技术以及微调。

**Result:** 实验结果显示，宏观F1分数随与优化样本的偏差增加而从0.45下降到0.26，再到0.09。即使输入中提供了所有必要信息，最低复杂度的F1分数也未超过0.57。

**Conclusion:** 大型语言模型难以系统地、组合地解释问题并将其映射到SPARQL查询。

> **ai_Abstract:** 本文提出了CompoST，一个用于评估大型语言模型（LLMs）组合解释问题能力的基准。研究通过创建基于DBpedia图模式的受控数据集，测试LLMs将问题映射到SPARQL查询的系统性。实验结果表明，LLMs在处理结构复杂问题时，即使已理解原子部分，其组合解释能力也显著不足，表现为F1分数随复杂性增加而大幅下降。

> **摘要翻译:** 语言解释是一个组合过程，其中更复杂语言结构的意义是从其组成部分的意义推断出来的。大型语言模型（LLMs）拥有卓越的语言解释能力，并已成功应用于将问题映射到SPARQL查询。一个悬而未决的问题是这种解释过程的系统性如何。针对这个问题，本文提出了一个基准，用于调查LLMs解释问题的能力在多大程度上是组合性的。为此，我们基于DBpedia中的图模式生成了三个难度不同的数据集，并依赖Lemon词典进行语言化。我们的数据集以非常受控的方式创建，旨在测试LLMs在已知原子构建块的情况下解释结构复杂问题的能力。这使我们能够评估LLMs在多大程度上能够解释那些它们“理解”原子部分的复杂问题。我们使用不同大小的模型进行了实验，采用了各种提示和少样本优化技术以及微调。我们的结果表明，宏观F1分数从0.45下降到0.26，再到0.09，随着与优化样本的偏差增加而性能下降。即使在输入中向模型提供了所有必要信息，最低复杂度的F1分数也未超过0.57。因此，我们得出结论，LLMs在系统地、组合地解释问题并将其映射到SPARQL查询方面存在困难。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [469] [Strategist: Self-improvement of LLM Decision Making via Bi-Level Tree Search](https://arxiv.org/abs/2408.10635)
> *策略师：通过双层树搜索实现大型语言模型决策的自我改进*

*Jonathan Light, Min Cai, Weiqin Chen, Guanzhi Wang, Xiusi Chen, Wei Cheng, Yisong Yue, Ziniu Hu* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 决策, 树搜索, 自我改进, 游戏AI

**Comment:** website: https://llm-strategist.github.io

> **TL;DR:** STRATEGIST结合LLM和MCTS，无需训练数据即可在复杂游戏中做出更好的决策，超越现有方法并与人类表现相当。

**AI_Comments:** 该论文的创新之处在于其双层方法，将大型语言模型的高层策略生成与蒙特卡洛树搜索的低层执行相结合，有效弥补了大型语言模型在详细规划上的不足，同时避免了传统强化学习对大量数据的依赖。其重要性在于提供了一种无需训练数据即可在复杂决策任务中提升大型语言模型性能的通用框架，尤其适用于部分信息博弈。

<details>
  <summary>Details</summary>

**Motivation:** 传统强化学习需要大量数据和训练，而大型语言模型在复杂动作空间的详细规划和决策方面存在不足。

**Method:** 提出STRATEGIST，一种结合大型语言模型（用于搜索和更新高层策略）和低层蒙特卡洛树搜索（MCTS，用于细化和执行）的新方法。该框架通过基于群体的自我博弈模拟优化策略，无需训练数据。

**Result:** 在部分信息竞争性多轮游戏（如GOPS和《抵抗：阿瓦隆》）中表现出有效性。STRATEGIST代理的表现优于传统强化学习、其他基于LLM的技能获取技术和现有LLM代理，并与人类玩家表现相当。

**Conclusion:** STRATEGIST成功地将大型语言模型与蒙特卡洛树搜索相结合，克服了它们各自的局限性，实现了在复杂环境中无需大量训练数据的高效决策，并取得了与人类玩家相当的强大表现。

> **ai_Abstract:** STRATEGIST提出了一种将大型语言模型（LLM）与蒙特卡洛树搜索（MCTS）相结合的新方法，旨在解决传统强化学习数据需求大和LLM在复杂规划中不足的问题。该方法通过LLM搜索和更新高层策略，再由MCTS进行细化和执行。作为一个无需训练数据的通用框架，STRATEGIST通过群体自我博弈模拟优化策略，并在部分信息竞争性多轮游戏中展现出卓越性能，超越了传统RL方法和现有LLM代理，达到与人类玩家相当的水平。

> **摘要翻译:** 传统强化学习和规划通常需要大量数据和训练才能开发出有效的策略。相比之下，大型语言模型（LLMs）展现出强大的泛化和零样本能力，但在需要详细规划和复杂动作空间决策的任务上表现不佳。我们引入了STRATEGIST，一种结合了这两种方法优势的新颖方法。我们的方法利用大型语言模型搜索和更新高层策略（以文本形式），然后由低层蒙特卡洛树搜索（MCTS）进行细化和执行。STRATEGIST是一个通用的框架，可以通过基于群体的自我博弈模拟来优化策略，而无需任何训练数据。我们证明了STRATEGIST在学习部分信息竞争性多轮游戏（包括纯策略游戏（GOPS）和多智能体、隐藏身份的讨论游戏如《抵抗：阿瓦隆》）的最佳策略方面的有效性。我们的结果表明，配备STRATEGIST的代理在两种游戏环境中都优于传统强化学习方法、其他基于LLM的技能获取技术、以及预先存在的LLM代理，并实现了与人类玩家相当的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [487] [Probabilistic Active Goal Recognition](https://arxiv.org/abs/2507.21846)
> *概率主动目标识别*

*Chenyuan Zhang, Cristian Rojas Cardenas, Hamid Rezatofighi, Mor Vered, Buser Say* | **Category: cs.AI, cs.SC** | **Updated: 2025-07-29**

**Keywords:** 主动目标识别, 概率框架, 蒙特卡洛树搜索, 多智能体系统, 目标推断

**Comment:** Accepted by KR2025

> **TL;DR:** 提出了一种结合联合信念更新机制和蒙特卡洛树搜索（MCTS）的概率主动目标识别框架，用于在多智能体环境中高效推断隐藏目标。

**AI_Comments:** 该论文的创新之处在于将概率框架与MCTS结合应用于主动目标识别，实现了无需领域特定知识的目标推断。其重要性在于推动了多智能体系统向更具交互性和适应性的方向发展，提供了一个实用的目标推断框架。论文强调了“主动”收集信息的重要性，这与传统“被动”目标识别形成对比，是其核心贡献。

<details>
  <summary>Details</summary>

**Motivation:** 在多智能体环境中，有效的交互依赖于理解其他智能体的信念和意图。以往的目标识别工作大多将观察者视为被动推理者，而主动目标识别（AGR）则侧重于战略性地收集信息以减少不确定性。

**Method:** 采用概率框架进行主动目标识别，并提出了一个集成解决方案，该方案结合了联合信念更新机制和蒙特卡洛树搜索（MCTS）算法，使得观察者能够高效地规划并推断参与者的隐藏目标，而无需领域特定知识。

**Result:** 在基于网格的领域中进行的全面实证评估表明，所提出的联合信念更新显著优于被动目标识别，并且其领域无关的MCTS性能与强大的领域特定贪婪基线相当。

**Conclusion:** 这些结果表明，所提出的解决方案是一个实用且鲁棒的目标推断框架，将该领域推向了更具交互性和适应性的多智能体系统。

> **ai_Abstract:** 本论文提出了一种概率主动目标识别（AGR）框架，旨在解决多智能体环境中理解其他智能体意图的问题。该框架整合了联合信念更新机制和蒙特卡洛树搜索（MCTS）算法，使得观察者无需领域特定知识即可高效地推断隐藏目标。实验结果表明，该联合信念更新方法显著优于被动目标识别，并且其领域无关的MCTS表现与领域特定的贪婪基线相当，证明了其作为目标推断实用且鲁棒的潜力。

> **摘要翻译:** 在多智能体环境中，有效的交互取决于理解其他智能体的信念和意图。虽然以往关于目标识别的工作主要将观察者视为被动推理者，但主动目标识别（AGR）侧重于战略性地收集信息以减少不确定性。我们采用概率框架进行主动目标识别，并提出了一个结合联合信念更新机制和蒙特卡洛树搜索（MCTS）算法的集成解决方案，使得观察者能够高效地规划并推断参与者的隐藏目标，而无需领域特定知识。通过在基于网格的领域进行的全面实证评估，我们表明我们的联合信念更新显著优于被动目标识别，并且我们的领域无关MCTS性能与我们强大的领域特定贪婪基线相当。这些结果表明，我们的解决方案是一个实用且鲁棒的目标推断框架，将该领域推向了更具交互性和适应性的多智能体系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [490] [A Survey on Large Language Model Acceleration based on KV Cache Management](https://arxiv.org/abs/2412.19442)
> *基于KV缓存管理的大语言模型加速综述*

*Haoyang Li, Yiming Li, Anxin Tian, Tianhao Tang, Zhanchao Xu, Xuejia Chen, Nicole Hu, Wei Dong, Qing Li, Lei Chen* | **Category: cs.AI, cs.DC** | **Updated: 2025-07-30**

**Keywords:** 大语言模型, KV缓存管理, LLM加速, 推理优化, 综述

**Comment:** Accepted to TMLR 2025. The revised version incorporates more papers
  and has been further polished

> **TL;DR:** 该综述全面回顾了基于KV缓存管理的大语言模型加速策略，将其分为令牌级、模型级和系统级优化，并提供了数据集和基准的概述，旨在为研究人员和实践者提供洞察力，以支持高效可扩展的KV缓存管理技术开发和LLM的实际部署。

**AI_Comments:** 这篇综述的重要性在于它系统地整理了当前LLM加速领域中KV缓存管理这一关键技术。通过将优化策略细分为令牌级、模型级和系统级，它提供了一个清晰的分类框架，有助于研究人员和工程师理解和选择合适的加速方法。其价值在于为LLM在实际应用中的高效部署提供了宝贵的参考和指导。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）在多种领域取得了革命性进展，但在推理阶段面临巨大的计算和内存需求，尤其是在扩展到长上下文和实时应用时。KV缓存管理是加速LLM推理的关键优化技术，可以减少冗余计算并提高内存利用率。因此，需要对KV缓存管理策略进行全面综述。

**Method:** 本综述对LLM加速的KV缓存管理策略进行了全面概述，将其分为令牌级（KV缓存选择、预算分配、合并、量化、低秩分解）、模型级（架构创新、注意力机制）和系统级（内存管理、调度、硬件感知设计）优化。此外，还概述了用于评估这些策略的文本和多模态数据集及基准。

**Result:** 通过提供详细的分类和比较分析，本工作旨在为研究人员和实践者提供有用的见解，以支持高效和可扩展的KV缓存管理技术的开发。

**Conclusion:** 本综述旨在通过提供详细的分类和比较分析，为研究人员和实践者提供有用的见解，以支持高效和可扩展的KV缓存管理技术的开发，从而促进LLM在实际应用中的部署。

> **ai_Abstract:** 本综述深入探讨了基于KV缓存管理的大语言模型加速技术。针对LLM推理阶段的计算和内存挑战，文章详细分类并阐述了令牌级、模型级和系统级的KV缓存优化策略，并介绍了相关数据集与基准。旨在为LLM的高效部署提供实践指导和理论洞察。

> **摘要翻译:** 大语言模型（LLMs）凭借其理解上下文和进行逻辑推理的能力，彻底改变了自然语言处理、计算机视觉和多模态任务等广泛领域。然而，LLMs的计算和内存需求，特别是在推理阶段，在将其扩展到真实世界、长上下文和实时应用时带来了巨大挑战。键值（KV）缓存管理已成为加速LLM推理的关键优化技术，通过减少冗余计算和提高内存利用率。本综述全面概述了用于LLM加速的KV缓存管理策略，将其分为令牌级、模型级和系统级优化。令牌级策略包括KV缓存选择、预算分配、合并、量化和低秩分解，而模型级优化则侧重于架构创新和注意力机制以增强KV重用。系统级方法解决了内存管理、调度和硬件感知设计，以提高跨不同计算环境的效率。此外，本综述还概述了用于评估这些策略的文本和多模态数据集和基准。通过提供详细的分类和比较分析，这项工作旨在为研究人员和实践者提供有用的见解，以支持高效和可扩展的KV缓存管理技术的开发，从而促进LLMs在实际应用中的实际部署。KV缓存管理精选论文列表位于：https://github.com/TreeAI-Lab/Awesome-KV-Cache-Management。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [494] [What Does it Mean for a Neural Network to Learn a "World Model"?](https://arxiv.org/abs/2507.21513)
> *神经网络学习“世界模型”意味着什么？*

*Kenneth Li, Fernanda Viégas, Martin Wattenberg* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-29**

**Keywords:** 神经网络, 世界模型, 线性探测, 状态空间, 操作性定义

**Comment:** 

> **TL;DR:** 该论文提出了一套精确的标准，用于定义神经网络何时学习并使用了“世界模型”，旨在为实验研究提供通用语言。

**AI_Comments:** 这篇论文的创新之处在于，它试图为“世界模型”这一在机器学习领域广泛使用但常缺乏精确定义的术语提供一套形式化且可操作的准则。这对于建立一个共同的实验研究语言，促进该领域的严谨性和可复现性具有重要意义。通过关注潜在状态空间并提供非平凡性检查条件，该工作为评估和比较不同神经网络的“世界模型”能力奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在为“世界模型”等常用术语提供操作性定义，以提供一个共同的语言供实验研究使用，解决这些术语常被非正式使用的问题。

**Method:** 论文提出了一套精确的准则来定义神经网络学习和使用“世界模型”的含义。该定义基于线性探测文献中的思想，并形式化了通过数据生成过程表示进行分解的计算概念。此外，定义还包含了一组条件，用于检查所定义的“世界模型”并非神经网络数据或任务的微不足道的后果。论文特别关注表示世界的潜在“状态空间”，将建模动作的影响留待未来工作。

**Result:** 论文提出了神经网络学习和使用“世界模型”的一套精确标准和定义，以及用于验证这些模型非平凡性的条件。

**Conclusion:** 论文通过提出一套精确的准则和定义，为神经网络学习“世界模型”的概念提供了操作性含义，旨在促进该领域实验研究的标准化和共同语言的建立。

> **ai_Abstract:** 本文提出了一套精确的准则和定义，以明确神经网络学习和使用“世界模型”的含义。该研究旨在为相关术语提供操作性定义，从而促进实验研究的标准化和共同语言的建立。定义基于线性探测方法，侧重于表示潜在世界状态空间，并包含验证模型非平凡性的条件。

> **摘要翻译:** 我们提出了一套精确的准则，用于判断神经网络何时学习并使用了“世界模型”。目标是为那些经常非正式使用的术语赋予操作性意义，以便为实验研究提供一个共同的语言。我们特别关注表示世界的潜在“状态空间”这一概念，将建模动作的影响留待未来工作。我们的定义基于线性探测文献中的思想，并形式化了通过数据生成过程表示进行分解的计算概念。该定义的一个重要补充是一组条件，用于检查这种“世界模型”并非神经网络数据或任务的微不足道的后果。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [499] [Ensuring Medical AI Safety: Interpretability-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data](https://arxiv.org/abs/2501.13818)
> *确保医疗AI安全：可解释性驱动的虚假模型行为及相关数据检测与缓解*

*Frederik Pahde, Thomas Wiegand, Sebastian Lapuschkin, Wojciech Samek* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 医疗AI安全, 可解释性, 偏见检测, 偏见缓解, 虚假相关性

**Comment:** 

> **TL;DR:** 本文通过增强Reveal2Revise框架，引入半自动化可解释性偏见标注能力，成功检测并缓解了医疗AI模型中的虚假关联偏见，提高了模型在真实世界医疗任务中的鲁棒性和适用性。

**AI_Comments:** 该论文的创新点在于将可解释性方法应用于半自动化的偏见标注，从而降低了专家标注的工作量，并提供了一个更全面的偏见检测与缓解框架。其重要性在于直接解决了医疗AI应用中关键的安全问题，通过提高模型鲁棒性，使其更适用于高风险的临床环境。该方法在不同模型和数据集上的成功应用，也展示了其广泛的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络在医疗应用中日益普及，但其在存在虚假相关性时容易产生捷径学习，这可能导致致命后果。现有的工作多独立处理偏见的检测或缓解，缺乏一个全面的框架来结合这些步骤。

**Method:** 本文回顾并增强了Reveal2Revise框架，加入了半自动化的基于可解释性的偏见标注能力。这包括样本级和特征级的偏见标注方法，为偏见缓解提供了有价值的信息，以消除不期望的捷径行为。

**Result:** 该框架在四个医疗数据集（涵盖两种模态，包含受控和真实世界由数据伪影引起的虚假相关性）上得到了应用验证。研究成功识别并缓解了VGG16、ResNet50和当代Vision Transformer模型中的这些偏见，最终提高了它们在真实世界医疗任务中的鲁棒性和适用性。

**Conclusion:** 通过引入半自动化可解释性偏见标注能力，增强Reveal2Revise框架，可以有效检测并缓解医疗AI模型中的虚假关联偏见，从而提高模型在实际医疗应用中的安全性和可靠性。

> **ai_Abstract:** 本文针对医疗AI中深度神经网络因虚假相关性导致的捷径学习问题，提出了一种增强的Reveal2Revise框架。该框架通过引入半自动化的可解释性偏见标注能力（包括样本级和特征级标注），旨在综合检测和缓解模型偏见。研究在四个医疗数据集上验证了其有效性，成功识别并减轻了VGG16、ResNet50和Vision Transformer模型中的偏见，显著提升了模型在真实世界医疗任务中的鲁棒性和适用性，从而确保了医疗AI的安全性。

> **摘要翻译:** 尽管深度神经网络在医疗应用中日益普及，但它们在存在虚假相关性时容易产生捷径学习，这在实践中可能导致潜在的致命后果。虽然大量工作单独解决了此类捷径行为的检测或缓解，但Reveal2Revise方法提供了一个结合这些步骤的全面偏见缓解框架。然而，有效解决这些偏见通常需要领域专家进行大量的标注工作。在这项工作中，我们审查了Reveal2Revise框架的步骤，并用半自动化的基于可解释性的偏见标注能力对其进行了增强。这包括样本级和特征级的偏见标注方法，为偏见缓解方法提供了有价值的信息，以消除不期望的捷径行为。我们使用四个跨越两种模态的医疗数据集展示了该框架的适用性，这些数据集具有由数据伪影引起的受控和真实世界的虚假相关性。我们成功地识别并缓解了VGG16、ResNet50和当代Vision Transformer模型中的这些偏见，最终提高了它们在真实世界医疗任务中的鲁棒性和适用性。我们的代码可在https://github.com/frederikpahde/medical-ai-safety获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [511] [Can the current trends of AI handle a full course of mathematics?](https://arxiv.org/abs/2507.21664)
> *当前人工智能趋势能否胜任一门完整的数学课程？*

*Mariam Alsayyad, Fayadh Kadhem* | **Category: cs.AI, cs.HC, math.HO** | **Updated: 2025-07-29**

**Keywords:** 人工智能, 数学教育, 大学课程, 人机协作, 能力评估

**Comment:** 36 pages

> **TL;DR:** 本文探讨了当前人工智能在大学数学课程中的能力，发现其在组织和准确性方面表现出色，但在处理人类情感方面仍有不足，并建议结合人类和人工智能的潜力以达到最佳教学效果。

**AI_Comments:** 该论文探讨了人工智能在教育领域，特别是数学教学中的潜力与局限性，其创新点在于强调了即便在科学领域，人类情感和非结构化交互的重要性仍是当前AI难以企及的。这为未来AI在教育应用中的发展指明了方向，即需要更深入地思考人机协作模式，而不仅仅是自动化替代。其局限性在于可能没有提供具体的AI技术细节或实验数据来支撑其评估结果。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探讨当前人工智能（AI）在承担大学水平的完整数学课程方面的能力。

**Method:** 该研究从四个重要方面评估了人工智能的能力：创建课程大纲、呈现选定材料、回答学生问题和创建评估。

**Result:** 研究表明，尽管人工智能在组织和准确性等重要部分表现出色，但仍有一些人类方面（特别是隐藏的情感部分）是当前人工智能能力无法满足的。

**Conclusion:** 本文建议整合人类和人工智能的潜力，以尽可能最好地实现大学水平完整数学课程的目标，从而创造更好的成果。

> **ai_Abstract:** 本文评估了当前人工智能在承担大学水平完整数学课程方面的能力。研究发现，尽管人工智能在课程组织和内容准确性方面表现突出，但在处理需要人类情感和理解的方面仍存在显著不足。鉴于此，论文提出将人类教师的专业知识与人工智能的优势相结合，以期在大学数学教育中取得更优异的教学效果。

> **摘要翻译:** 本文探讨了当前人工智能（AI）在承担大学水平完整数学课程方面的能力。该研究从四个重要方面评估了这种能力，即创建课程大纲、呈现选定材料、回答学生问题和创建评估。结果表明，尽管人工智能在组织和准确性等重要部分表现出色，但仍有一些人类方面远远超出了当前人工智能的能力。即使在科学领域，也存在一个隐藏的情感部分，以其目前的状态无法由人工智能来满足。本文提出了一些建议，以整合人类和人工智能的潜力，从而在尽可能最好地实现创建大学水平完整数学课程的目标方面创造更好的成果。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [524] [Nearest-Better Network for Visualizing and Analyzing Combinatorial Optimization Problems: A Unified Tool](https://arxiv.org/abs/2507.22440)
> *最近更好网络用于可视化和分析组合优化问题：一个统一工具*

*Yiya Diao, Changhe Li, Sanyou Zeng, Xinye Cai, Wenjian Luo, Shengxiang Yang, Carlos A. Coello Coello* | **Category: cs.AI, cs.NE** | **Updated: 2025-07-30**

**Keywords:** 最近更好网络, 组合优化, 旅行商问题, 算法分析, 适应度景观

**Comment:** 

> **TL;DR:** 本文提出了一种高效的最近更好网络（NBN）计算方法，并将其扩展到组合优化问题，揭示了OneMax和旅行商问题（TSP）的景观特征及现有TSP算法的局限性。

**AI_Comments:** 本文通过提出NBN的理论基础和高效计算方法，显著扩展了NBN在组合优化领域的应用，这是一个重要的创新。其对OneMax和TSP景观特征的首次发现以及对现有算法局限性的深入分析，为算法设计和优化提供了宝贵的指导，展示了NBN作为统一分析工具的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 最近更好网络（NBN）在连续优化问题中的可视化和特征保留方面表现出色，但其计算耗时且难以扩展到组合优化问题，而这对分析算法行为至关重要。

**Method:** 本文提供了NBN作为算法最大概率转换网络的理论推导，并提出了一种对数线性时间复杂度的NBN高效计算方法。通过将该高效NBN算法应用于OneMax问题和旅行商问题（TSP）进行分析。

**Result:** OneMax的适应度景观表现出中性、崎岖性和多模态特征。TSP问题的主要挑战是崎岖性、多模态和欺骗性。两种先进的TSP算法（EAX和LKH）分别在处理多模态和欺骗性挑战时存在局限性：LKH在全局最优解附近存在欺骗性解时失效；EAX在存在多个吸引盆地时会降低盆地间交互效率导致算法停滞。

**Conclusion:** 本文通过开发高效的NBN计算方法并将其应用于组合优化问题，首次揭示了OneMax和TSP的复杂适应度景观特征，并深入分析了现有TSP算法在应对这些挑战时的具体局限性，为理解和改进组合优化算法提供了统一的工具和重要见解。

> **ai_Abstract:** 本文针对最近更好网络（NBN）在处理连续优化问题时计算耗时且难以应用于组合优化的问题，提出了一种理论推导，将NBN解释为算法的最大概率转换网络，并开发了一种高效的、具有对数线性时间复杂度的NBN计算方法。通过将此新方法应用于OneMax和旅行商问题（TSP），研究首次揭示了OneMax景观的中性、崎岖性和多模态特征，以及TSP的崎岖性、多模态和欺骗性挑战。此外，研究还深入分析了现有先进TSP算法（EAX和LKH）在应对这些复杂景观特征时的具体局限性，为理解和改进组合优化算法提供了新的工具和见解。

> **摘要翻译:** 最近更好网络（NBN）是一种强大的方法，用于可视化连续优化问题的采样数据，同时保留多个景观特征。然而，NBN的计算非常耗时，并且将该方法扩展到组合优化问题具有挑战性，但对于分析算法行为非常重要。本文提供了一个直接的理论推导，表明NBN网络本质上作为算法的最大概率转换网络。本文还提出了一种高效的NBN计算方法，具有对数线性时间复杂度，以解决耗时问题。通过将这种高效的NBN算法应用于OneMax问题和旅行商问题（TSP），我们首次取得了几个显著的发现：OneMax的适应度景观表现出中性、崎岖性和多模态特征。TSP问题的主要挑战是崎岖性、多模态和欺骗性。两种最先进的TSP算法（即EAX和LKH）在分别解决多模态和欺骗性挑战时存在局限性。基于局部搜索操作的LKH在全局最优解附近存在欺骗性解时会失效。基于单种群的EAX可以有效地保持多样性。然而，当存在多个吸引盆地时，EAX会同时在多个盆地中保留个体，从而降低盆地间交互效率并导致算法停滞。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [528] [LeMix: Unified Scheduling for LLM Training and Inference on Multi-GPU Systems](https://arxiv.org/abs/2507.21276)
> *LeMix：多GPU系统上LLM训练和推理的统一调度*

*Yufei Li, Zexin Li, Yinglun Zhu, Cong Liu* | **Category: cs.AI, cs.CL, cs.DC** | **Updated: 2025-07-28**

**Keywords:** LLM, 统一调度, 训练, 推理, 多GPU系统

**Comment:** Accepted by RTSS 2025

> **TL;DR:** LeMix系统通过统一调度LLM训练和推理工作负载，解决了现有分离部署导致的GPU利用率低下和数据适应延迟问题，显著提高了吞吐量和响应时间。

**AI_Comments:** 该论文的创新之处在于首次提出了LLM推理和训练工作负载的联合调度方法，直接解决了传统分离部署的低效率问题。这对于在生产环境中实现更具成本效益和响应性的LLM操作至关重要，具有显著的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代LLM部署中，推理服务和持续再训练是常见的需求。然而，当前将这些工作负载分离到不同服务器的做法，会导致GPU空闲等显著低效率，并延迟对新数据的适应。这些低效率源于服务期间的动态请求到达和管道并行训练中的工作负载异构性。

**Method:** 本文提出了LeMix系统，用于在多GPU系统上协同定位和管理并发的LLM服务和训练工作负载。LeMix通过集成离线分析、执行预测机制和运行时调度，根据工作负载特性和系统条件动态调整资源分配，并理解任务特定行为和跨共享节点的协同执行干扰。

**Result:** LeMix将吞吐量提高了高达3.53倍，将推理损失降低了高达0.61倍，并提供了高达2.12倍的响应时间SLO达成率，优于传统的独立设置。

**Conclusion:** LeMix是首次揭示和利用LLM推理和训练联合机会的工作，为在生产环境中更高效地部署LLM铺平了道路。

> **ai_Abstract:** LeMix系统旨在解决当前LLM部署中推理和训练分离导致的低效率问题。通过在多GPU系统上统一调度这两种工作负载，LeMix利用离线分析、执行预测和运行时调度动态管理资源分配，从而提高GPU利用率和服务质量。实验结果表明，LeMix显著提升了吞吐量、降低了推理损失并提高了响应时间SLO达成率，为生产环境中LLM的高效部署提供了新途径。

> **摘要翻译:** 现代大型语言模型（LLM）的部署通常涉及推理服务和持续再训练，以适应不断演变的数据和用户反馈。常见的做法是将这些工作负载分离到不同的服务器上，并在隔离的阶段进行，这导致了显着的低效率（例如，GPU空闲）以及在分布式设置中对新数据适应的延迟。我们的经验分析表明，这些低效率源于服务期间的动态请求到达和管道并行训练中的工作负载异构性。为了解决这些挑战，我们提出了LeMix，一个用于协同定位和管理并发LLM服务和训练工作负载的系统。LeMix集成了离线分析、执行预测机制和运行时调度，以根据工作负载特性和系统条件动态调整资源分配。通过理解任务特定的行为和跨共享节点的协同执行干扰，LeMix在不影响服务响应能力的情况下提高了利用率和服务质量。我们的评估显示，与传统的独立设置相比，LeMix将吞吐量提高了高达3.53倍，将推理损失降低了高达0.61倍，并提供了高达2.12倍的响应时间SLO达成率。据我们所知，这是首次揭示和利用LLM推理和训练联合机会的工作，为在生产环境中更高效地部署LLM铺平了道路。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [532] [A Scalable Approach to Probabilistic Neuro-Symbolic Robustness Verification](https://arxiv.org/abs/2502.03274)
> *概率神经符号鲁棒性验证的可扩展方法*

*Vasileios Manginas, Nikolaos Manginas, Edward Stevinson, Sherwin Varghese, Nikos Katzouris, Georgios Paliouras, Alessio Lomuscio* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 神经符号AI, 鲁棒性验证, 概率推理, 可扩展性, 自动驾驶

**Comment:** 19th Conference on Neurosymbolic Learning and Reasoning

> **TL;DR:** 本文提出了一种可扩展的近似验证方法，用于解决概率神经符号系统鲁棒性验证的复杂性问题，并在自动驾驶领域展示了其有效性。

**AI_Comments:** 这篇论文的创新点在于首次提出了针对概率神经符号系统鲁棒性验证的近似、基于松弛的方法，解决了该问题的高计算复杂性挑战。其重要性在于为NeSy AI系统在安全关键领域的实际部署提供了理论基础和实用工具。特别是在自动驾驶领域的应用展示了其潜在的实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决概率神经符号推理系统鲁棒性形式验证的问题，以促进其在关键领域的安全部署。

**Method:** 提出了一种首次应用于概率神经符号系统的、基于松弛的近似验证方法。

**Result:** 证明了核心计算的决策版本是$\mathrm{NP}^{\mathrm{PP}}$-完全的；实验表明所提出的方法比基于求解器的方法具有指数级的扩展性优势；成功应用于自动驾驶领域，验证了高维度输入下的安全属性。

**Conclusion:** 所提出的近似、基于松弛的验证方法能够有效且可扩展地验证概率神经符号系统的鲁棒性，从而促进其在关键领域的安全部署。

> **ai_Abstract:** 本文关注概率神经符号（NeSy）AI系统的鲁棒性验证问题，以确保其在关键应用中的安全部署。研究首先分析了该问题的计算复杂性，发现其核心计算是$\mathrm{NP}^{\mathrm{PP}}$-完全的。鉴于此，作者提出了一种创新的、基于松弛的近似验证方法，这是首次应用于此类系统。实验结果表明，该方法在扩展性上远优于传统求解器，并成功应用于自动驾驶场景，验证了高维度输入下的安全属性。

> **摘要翻译:** 神经符号人工智能（NeSy AI）已成为整合神经网络学习与符号推理的一个有前景的方向。通常，在此类系统的概率变体中，神经网络首先从子符号输入中提取一组符号，然后符号组件以概率方式进行推理以回答查询。在这项工作中，我们解决了正式验证此类NeSy概率推理系统鲁棒性的问题，从而为它们在关键领域的安全部署铺平了道路。我们分析了精确解决此问题的复杂性，并表明核心计算的决策版本是$\mathrm{NP}^{\mathrm{PP}}$-完全的。面对这一结果，我们提出了首个针对概率NeSy系统进行近似、基于松弛的验证方法。我们在标准NeSy基准上通过实验证明，所提出的方法比基于求解器的解决方案具有指数级的扩展优势，并且我们将我们的技术应用于真实世界的自动驾驶领域，在该领域中，我们在大输入维度下验证了一个安全属性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [544] [EDGE-GRPO: Entropy-Driven GRPO with Guided Error Correction for Advantage Diversity](https://arxiv.org/abs/2507.21848)
> *EDGE-GRPO：熵驱动的GRPO，带有引导纠错以实现优势多样性*

*Xingjian Zhang, Siwei Wen, Wenjun Wu, Lei Huang* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 强化学习, GRPO, 优势崩溃, 策略熵, 引导纠错

**Comment:** 

> **TL;DR:** EDGE-GRPO提出了一种新的算法，通过熵驱动的优势和引导纠错来解决LLM中GRPO算法的优势崩溃问题，提高了推理基准的性能。

**AI_Comments:** 本文针对LLM中强化学习的GRPO算法所面临的“优势崩溃”问题提出了创新的解决方案，即引入“熵驱动的优势”和“引导纠错”。这种方法从策略熵的细粒度分析出发，直接解决了现有方法在增强多样性和训练信号方面的不足。其贡献在于提供了一种更鲁棒的优化策略，有望提升LLM在复杂推理任务上的表现。

<details>
  <summary>Details</summary>

**Motivation:** 现有的强化学习算法GRPO在大型语言模型（LLMs）中用于逐步推理时，由于依赖稀疏奖励规则，常导致组内奖励相同，从而引发优势崩溃问题。

**Method:** 本文首先分析了模型反射的局限性，并研究了细粒度样本级别的响应策略熵。在此基础上，提出了EDGE-GRPO算法，该算法采用熵驱动的优势（Entropy-Driven Advantage）和引导纠错（Guided Error Correction）来有效缓解优势崩溃问题。

**Result:** 在几个主要的推理基准上进行了广泛的实验，结果表明EDGE-GRPO方法是有效且优越的。

**Conclusion:** EDGE-GRPO算法通过引入熵驱动的优势和引导纠错，成功解决了GRPO在LLM中面临的优势崩溃问题，显著提高了推理性能。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）中GRPO算法在逐步推理时遇到的优势崩溃问题，提出了一种名为EDGE-GRPO的新算法。该问题源于GRPO对稀疏奖励的依赖导致组内奖励相同。EDGE-GRPO通过分析模型反射的局限性并研究响应的策略熵，引入了熵驱动的优势和引导纠错机制来有效缓解优势崩溃。实验证明，该方法在多个推理基准上表现出有效性和优越性。

> **摘要翻译:** 大型语言模型（LLMs）通过强化学习在增强逐步推理方面取得了显著进展。然而，依赖稀疏奖励规则的组相对策略优化（GRPO）算法，经常遇到组内奖励相同的问题，导致优势崩溃。现有工作通常从两个角度解决这一挑战：强制模型反射以增强响应多样性，以及引入内部反馈以增强训练信号（优势）。在这项工作中，我们首先分析了模型反射的局限性，并研究了细粒度样本级别的响应策略熵。基于我们的实验结果，我们提出了EDGE-GRPO算法，该算法采用熵驱动的优势（Entropy-Driven Advantage）和引导纠错（Guided Error Correction）来有效缓解优势崩溃问题。在几个主要的推理基准上进行了广泛的实验，结果证明了我们方法的有效性和优越性。代码可在https://github.com/ZhangXJ199/EDGE-GRPO获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [560] [SAKE: Steering Activations for Knowledge Editing](https://arxiv.org/abs/2503.01751)
> *SAKE: 引导激活进行知识编辑*

*Marco Scialanga, Thibault Laugel, Vincent Grari, Marcin Detyniecki* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 知识编辑,大型语言模型,引导激活,最优传输,鲁棒性

**Comment:** 

> **TL;DR:** SAKE提出了一种通过引导激活来编辑大型语言模型知识的方法，以克服现有知识编辑方法的局限性，实现了更鲁棒的编辑。

**AI_Comments:** SAKE通过将知识编辑从单一提示扩展到事实分布，并结合最优传输，为解决现有知识编辑方法在鲁棒性和泛化性上的不足提供了一个新颖且有前景的方向。这种方法有望提高知识编辑的实用性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型需要以受控且高效的方式更新其记忆的真实世界事实。现有的知识编辑方法存在局限性，包括缺乏上下文鲁棒性以及无法泛化到与事实相关的逻辑含义。

**Method:** 我们提出了SAKE，一种引导激活方法，它将要编辑的事实建模为一个分布而不是单个提示。SAKE利用最优传输，改变大型语言模型在整个事实相关分布（定义为释义和逻辑含义）上的行为。

**Result:** 多项数值实验证明了该方法的有效性：SAKE能够比现有方法进行更鲁棒的编辑。

**Conclusion:** SAKE通过将事实建模为分布并利用最优传输来引导激活，从而克服了现有知识编辑方法的局限性，实现了更鲁棒的知识编辑。

> **ai_Abstract:** SAKE是一种新的知识编辑方法，旨在解决现有大型语言模型知识编辑方法在上下文鲁棒性和泛化能力方面的不足。该方法通过将待编辑的事实建模为一个分布而非单一提示，并利用最优传输技术来引导模型激活，从而在整个事实相关分布（包括释义和逻辑含义）上改变LLM的行为。实验结果表明，SAKE能够实现比现有方法更鲁棒的知识编辑。

> **摘要翻译:** 随着大型语言模型被证明能够记忆真实世界的事实，以受控且高效的方式更新这些知识的需求应运而生。知识编辑（KE）方法在设计时考虑了这些限制，旨在改变预训练模型中的特定事实。然而，它们已被证明存在一些局限性，包括缺乏上下文鲁棒性以及未能泛化到与事实相关的逻辑含义。为了克服这些问题，我们提出了SAKE，一种引导激活方法，它将要编辑的事实建模为一个分布而不是单个提示。SAKE利用最优传输，改变大型语言模型在整个事实相关分布（定义为释义和逻辑含义）上的行为。多项数值实验证明了该方法的有效性：SAKE因此能够比现有方法进行更鲁棒的编辑。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [564] [ST-GDance: Long-Term and Collision-Free Group Choreography from Music](https://arxiv.org/abs/2507.21518)
> *ST-GDance：基于音乐的长期无碰撞群舞编排*

*Jing Xu, Weiqiang Wang, Cunjian Chen, Jun Liu, Qiuhong Ke* | **Category: cs.AI** | **Updated: 2025-07-30**

**Keywords:** 群舞生成, 音乐, 编排, 无碰撞, 时空解耦

**Comment:** 10 pages, 3 figures. Accepted at BMVC 2025

> **TL;DR:** ST-GDance是一种新颖的框架，通过解耦空间和时间依赖性，解决了从音乐生成长期、无碰撞群舞的挑战，并在AIOZ-GDance数据集上表现优于现有方法。

**AI_Comments:** ST-GDance的创新之处在于其对时空依赖性的解耦处理，这有效解决了现有方法在处理大规模群舞生成时面临的计算复杂度和碰撞问题。通过轻量级图卷积和加速稀疏注意力，该框架实现了高效且高质量的群舞编排，对于电影、游戏和动画制作等领域具有重要应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 从音乐生成群舞在电影、游戏和动画制作中具有广泛应用。然而，现有方法在处理多舞者同步和空间协调时面临计算复杂性高、运动碰撞风险大以及难以建模密集时空交互等问题，导致可扩展性差和多舞者碰撞。

**Method:** 我们提出了ST-GDance框架，它解耦了空间和时间依赖性，以优化长期和无碰撞的群舞编排。具体而言，我们采用轻量级图卷积进行距离感知空间建模，并使用加速稀疏注意力进行高效时间建模。

**Result:** ST-GDance的设计显著降低了计算成本，同时确保了流畅和无碰撞的交互。在AIOZ-GDance数据集上的实验表明，ST-GDance优于最先进的基线方法，尤其在生成长期和连贯的群舞序列方面表现突出。

**Conclusion:** ST-GDance通过创新的时空解耦方法，成功解决了群舞生成中的计算复杂性和碰撞问题，实现了长期、流畅且无碰撞的群舞序列生成。

> **ai_Abstract:** ST-GDance是一个为解决从音乐生成长期、无碰撞群舞挑战而提出的新型框架。它通过解耦空间和时间依赖性来优化群舞编排，具体使用轻量级图卷积进行空间建模和加速稀疏注意力进行时间建模。这种设计显著降低了计算成本，并有效避免了多舞者碰撞。实验证明，ST-GDance在生成长而连贯的群舞序列方面优于现有方法。

> **摘要翻译:** 从音乐生成群舞在电影、游戏和动画制作中具有广泛应用。然而，它需要同步多个舞者，同时保持空间协调。随着舞者数量和序列长度的增加，这项任务面临更高的计算复杂性和更大的运动碰撞风险。现有方法通常难以建模密集的时空交互，导致可扩展性问题和多舞者碰撞。为了解决这些挑战，我们提出了ST-GDance，一个新颖的框架，它解耦了空间和时间依赖性，以优化长期和无碰撞的群舞编排。我们采用轻量级图卷积进行距离感知空间建模，并采用加速稀疏注意力进行高效时间建模。这种设计显著降低了计算成本，同时确保了流畅和无碰撞的交互。在AIOZ-GDance数据集上的实验表明，ST-GDance优于最先进的基线，特别是在生成长期和连贯的群舞序列方面。项目页面：https://yilliajing.github.io/ST-GDance-Website/。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [588] [An Algebraic Approach to Moralisation and Triangulation of Probabilistic Graphical Models](https://arxiv.org/abs/2503.11820)
> *概率图模型中范化与三角化的代数方法*

*Antonio Lorenzin, Fabio Zanasi* | **Category: cs.AI, cs.LO, math.CT** | **Updated: 2025-07-28**

**Keywords:** 范畴论, 概率图模型, 范化, 三角化, 代数方法

**Comment:** Full version of the conference paper

> **TL;DR:** 本文提出一个范畴论框架，将概率图模型中的范化和三角化建模为函子，引入了一种模块化的代数视角。

**AI_Comments:** 本文的创新之处在于将范畴论引入概率图模型领域，以代数方式重新诠释了范化和三角化这两种核心转换。这种方法提供了一个更抽象、更统一的框架来理解和操作图模型，有望提升理论的模块性和严谨性。其重要性在于为未来图模型的理论研究和算法设计提供了新的数学工具和视角。

<details>
  <summary>Details</summary>

**Motivation:** 概率图模型中的范化（Moralisation）和三角化（Triangulation）是允许在不同概率分布分解方式之间切换的转换。本文旨在引入一种模块化、代数的方法来处理这些转换。

**Method:** 本文提出了一个范畴论框架，将贝叶斯网络和马尔可夫网络之间的范化和三角化建模为函子。两种网络本身被表示为从“语法”域到“语义”协域的函子。范化和三角化在语法上可归纳定义，并作为函子预组合的一种形式。

**Result:** 范化和三角化可以在所提出的语法上归纳定义，并作为函子预组合的一种形式操作。这种方法为概率图模型理论引入了一种模块化的代数视角。

**Conclusion:** 本文成功地将概率图模型中的范化和三角化转换置于一个范畴论框架中，从而引入了一种新的、模块化的代数视角。

> **ai_Abstract:** 本文提出了一个创新的范畴论框架，用于建模概率图模型中的范化和三角化转换。这些转换被视为贝叶斯网络和马尔可夫网络范畴之间的函子，其中网络本身也表示为函子。该方法使得范化和三角化能够通过函子预组合在语法上归纳定义，从而为概率图模型理论提供了一种模块化、代数的新视角。

> **摘要翻译:** 范化和三角化是允许在概率分布分解为图模型的不同方式之间切换的转换。范化允许将贝叶斯网络（一种有向模型）视为马尔可夫网络（一种无向模型），而三角化则以相反的方向工作。我们提出了一个范畴论框架，其中这些转换被建模为贝叶斯网络范畴和马尔可夫网络范畴之间的函子。这两种网络（这些范畴的对象）本身被表示为从“语法”域到“语义”协域的函子。值得注意的是，范化和三角化可以在这种语法上归纳定义，并作为函子预组合的一种形式进行操作。这种方法为概率图模型理论引入了一种模块化、代数视角。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [591] [Curiosity by Design: An LLM-based Coding Assistant Asking Clarification Questions](https://arxiv.org/abs/2507.21285)
> *设计式好奇：一个基于LLM的提问式编程助手*

*Harsh Darji, Thibaud Lutellier* | **Category: cs.AI** | **Updated: 2025-07-28**

**Keywords:** LLM, 编程助手, 澄清问题, 用户意图, 代码生成

**Comment:** 

> **TL;DR:** 一个基于LLM的编程助手，通过提问澄清问题来解决模糊的用户输入，从而生成更准确的代码。

**AI_Comments:** 这项工作通过引入“提问式”交互，为LLM编程助手提供了一个重要的创新方向，有效解决了用户意图模糊的常见问题。其模仿人类代码审查过程的设计理念具有很强的实用性，有望显著提升LLM在实际编程场景中的可用性和可靠性。未来可以探索其在更复杂、多轮对话场景下的表现。

<details>
  <summary>Details</summary>

**Motivation:** 当前的大型语言模型（LLMs）作为编程助手时，由于开发者提示的歧义性，常常导致生成不正确的代码，因为现有模型在没有大量提示工程或外部上下文的情况下难以推断用户意图。

**Method:** 本研究构建了一个端到端的系统，旨在模仿人类代码审查过程，通过在面对模糊或不明确的查询时提出澄清问题。该系统包括：1）一个经过训练用于检测不明确编程相关查询的查询分类器；2）一个经过微调用于生成澄清问题的LLM。

**Result:** 评估显示，经过微调的LLM在生成有用澄清问题方面优于标准的零样本提示。用户研究表明，用户认为模型生成的澄清问题优于基线，这证明了该编程助手能够产生比基线编程助手更准确和有帮助的代码响应。

**Conclusion:** 该研究成功构建了一个能够通过提问澄清问题来处理模糊用户输入的LLM编程助手，显著提高了代码生成的准确性和有用性。

> **ai_Abstract:** 该论文介绍了一个名为“设计式好奇”的LLM编程助手，旨在解决由于用户提示模糊导致的错误代码生成问题。该系统通过一个查询分类器识别不明确的编程查询，并利用一个微调的LLM生成澄清问题。实验证明，该方法在生成有用澄清问题方面优于零样本提示，且用户反馈表明其生成的代码响应比基线助手更准确和有帮助。

> **摘要翻译:** 大型语言模型（LLMs）越来越多地被用作编程助手。然而，开发者提示的歧义性常常导致生成不正确的代码，因为当前模型在没有大量提示工程或外部上下文的情况下难以推断用户意图。这项工作旨在构建一个基于LLM的编程助手，通过在面对模糊或不明确的查询时提出澄清问题来模仿人类代码审查过程。我们的端到端系统包括（1）一个经过训练用于检测不明确编程相关查询的查询分类器，以及（2）一个经过微调用于生成澄清问题的LLM。我们的评估显示，经过微调的LLM在生成有用澄清问题方面优于标准的零样本提示。此外，我们的用户研究表明，用户认为我们的模型生成的澄清问题优于基线，这表明我们的编程助手能够产生比基线编程助手更准确和有帮助的代码响应。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [600] [MultiEditor: Controllable Multimodal Object Editing for Driving Scenarios Using 3D Gaussian Splatting Priors](https://arxiv.org/abs/2507.21872)
> *MultiEditor：利用3D高斯泼溅先验实现驾驶场景可控多模态物体编辑*

*Shouyi Lu, Zihan Lin, Chao Lu, Huanran Wang, Guirong Zhuo, Lianqing Zheng* | **Category: cs.AI** | **Updated: 2025-07-30**

**Keywords:** 多模态编辑, 3D高斯泼溅, 自动驾驶, 数据增强, 潜在扩散

**Comment:** 

> **TL;DR:** MultiEditor是一个双分支潜在扩散框架，利用3D高斯泼溅先验，实现驾驶场景中图像和激光雷达点云的多模态联合编辑，有效解决稀有类别数据稀缺问题并提升感知模型性能。

**AI_Comments:** 本文的创新点在于将3D高斯泼溅（3DGS）引入到多模态数据编辑中，作为强大的结构和外观先验，这使得多模态数据的联合编辑更加精确和可控。其提出的多级外观控制和跨模态一致性模块有效地解决了多模态数据生成中的挑战。该工作对于解决自动驾驶领域中稀有类别数据稀缺问题具有重要意义，有望显著提升自动驾驶感知系统的鲁棒性和安全性。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶系统高度依赖多模态感知数据来理解复杂环境，但真实世界数据的长尾分布阻碍了泛化能力，尤其对于稀有但安全关键的车辆类别。这导致感知模型在欠 H表征类别上的检测精度不足。

**Method:** 本文提出了MultiEditor，一个双分支潜在扩散框架，用于联合编辑驾驶场景中的图像和激光雷达点云。核心方法是引入3D高斯泼溅（3DGS）作为目标物体的结构和外观先验。在此基础上，设计了一个多级外观控制机制，包括像素级粘贴、语义级引导和多分支细化，以实现跨模态的高保真重建。此外，还提出了一个深度引导的可变形跨模态条件模块，利用3DGS渲染的深度自适应地实现模态间的相互引导，显著增强了跨模态一致性。

**Result:** MultiEditor在视觉和几何保真度、编辑可控性以及跨模态一致性方面表现出卓越的性能。通过MultiEditor生成稀有类别车辆数据，显著提升了感知模型在欠代表类别上的检测精度。

**Conclusion:** MultiEditor通过其创新的3DGS先验和跨模态控制机制，成功地实现了驾驶场景中多模态数据的可控编辑，有效缓解了数据长尾分布带来的挑战，并显著增强了自动驾驶感知模型的性能，尤其是在稀有类别数据方面。

> **ai_Abstract:** MultiEditor是一个针对自动驾驶场景的多模态对象编辑框架，旨在解决真实世界数据长尾分布导致的稀有类别数据不足问题。该框架采用双分支潜在扩散模型，并引入3D高斯泼溅（3DGS）作为结构和外观先验，以实现图像和激光雷达点云的联合编辑。通过多级外观控制机制和深度引导的跨模态条件模块，MultiEditor在保证高保真重建和跨模态一致性的同时，显著提升了感知模型在稀有类别上的检测精度。

> **摘要翻译:** 自动驾驶系统高度依赖多模态感知数据来理解复杂环境。然而，真实世界数据的长尾分布阻碍了泛化能力，尤其对于稀有但安全关键的车辆类别。为了解决这一挑战，我们提出了MultiEditor，一个双分支潜在扩散框架，旨在联合编辑驾驶场景中的图像和激光雷达点云。我们方法的核心是引入3D高斯泼溅（3DGS）作为目标物体的结构和外观先验。利用这一先验，我们设计了一个多级外观控制机制——包括像素级粘贴、语义级引导和多分支细化——以实现跨模态的高保真重建。我们进一步提出了一个深度引导的可变形跨模态条件模块，利用3DGS渲染的深度自适应地实现模态间的相互引导，显著增强了跨模态一致性。广泛的实验表明，MultiEditor在视觉和几何保真度、编辑可控性和跨模态一致性方面取得了卓越的性能。此外，利用MultiEditor生成稀有类别车辆数据显著提升了感知模型在欠代表类别上的检测精度。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [616] [2D-Curri-DPO: Two-Dimensional Curriculum Learning for Direct Preference Optimization](https://arxiv.org/abs/2504.07856)
> *2D-Curri-DPO：基于二维课程学习的直接偏好优化*

*Mengyang Li, Zhong Zhang* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 直接偏好优化, 课程学习, 大型语言模型, 提示复杂度, 成对可区分度

**Comment:** We found a critical flaw in the prompt complexity metric, which
  affects the 2D curriculum grid construction and leads to potentially invalid
  comparisons. Since this undermines our main conclusions, we are withdrawing
  the paper and will revise the methodology before resubmission

> **TL;DR:** 2D-Curri-DPO提出了一种新的二维课程学习框架，结合提示复杂度和成对可区分度来优化直接偏好优化（DPO），显著提升了大型语言模型与人类偏好的对齐效果。

**AI_Comments:** 2D-Curri-DPO的创新点在于其引入的二维课程学习范式，同时考虑了提示复杂度和响应偏好可区分度，这比现有的一维方法更为全面。其自适应机制也增强了训练稳定性。这项工作为大语言模型与人类偏好的对齐提供了一个更强大、更可解释的优化范式，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的直接偏好优化（DPO）方法依赖于单一偏好对，且现有的一维课程学习方法（如Curriculum-DPO）虽然整合了多对数据，但忽略了输入提示本身的复杂性。为了更有效地将大型语言模型与人类偏好对齐，需要解决这些局限性。

**Method:** 我们提出了2D-Curri-DPO框架，该框架采用二维课程学习，联合建模提示复杂度（PC）和成对可区分度（PD）。它引入了双重难度指标来量化提示语义复杂度和响应偏好清晰度，定义了一个包含多种可选策略的课程策略空间以适应任务，并结合了基于KL散度的自适应机制，用于动态更新参考模型以增强训练稳定性。

**Result:** 综合实验表明，2D-Curri-DPO在MT-Bench、Vicuna Bench和WizardLM等多个基准测试中显著优于标准DPO和先前的课程方法。我们的方法在UltraFeedback等挑战性测试集上实现了最先进的性能。消融研究证实了二维结构和自适应机制的益处，同时分析为策略选择提供了指导。

**Conclusion:** 有效对齐需要同时建模提示复杂度和成对可区分度，这确立了自适应、多维课程学习作为一种强大且可解释的基于偏好的语言模型优化新范式。

> **ai_Abstract:** 2D-Curri-DPO是一个新颖的框架，通过引入一个同时建模提示复杂度和成对可区分度的二维课程学习机制来改进直接偏好优化（DPO）。它解决了传统DPO和一维课程学习方法在处理复杂提示时不足的问题。该框架包含双重难度指标、可选择的课程策略空间以及基于KL散度的自适应机制，以提高训练稳定性。实验结果表明，2D-Curri-DPO在多个基准测试中显著优于现有方法，并在挑战性数据集上实现了最先进的性能，证明了多维课程学习在偏好对齐中的有效性。

> **摘要翻译:** 将大型语言模型与人类偏好对齐对其安全部署至关重要。虽然直接偏好优化（DPO）为从人类反馈中进行强化学习提供了一种高效的替代方案，但传统的DPO方法受限于其对单一偏好对的依赖。最近的工作，如Curriculum-DPO，利用基于成对可区分度（PD）的一维难度课程整合了多对数据，但却忽视了输入提示本身的复杂性。为了解决这个问题，我们提出了2D-Curri-DPO，一个新颖的框架，采用二维课程学习，联合建模提示复杂度（PC）和成对可区分度。该框架引入了双重难度指标来量化提示语义复杂度和响应偏好清晰度，定义了一个包含多种可选策略的课程策略空间以适应任务，并结合了基于KL散度的自适应机制，用于动态更新参考模型以增强训练稳定性。综合实验表明，2D-Curri-DPO在MT-Bench、Vicuna Bench和WizardLM等多个基准测试中显著优于标准DPO和先前的课程方法。我们的方法在UltraFeedback等挑战性测试集上实现了最先进的性能。消融研究证实了二维结构和自适应机制的益处，同时分析为策略选择提供了指导。这些发现表明，有效对齐需要同时建模提示复杂度和成对可区分度，这确立了自适应、多维课程学习作为一种强大且可解释的基于偏好的语言模型优化新范式。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [632] [Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks](https://arxiv.org/abs/2507.21974)
> *5G无线网络中用于根本原因分析的推理语言模型*

*Mohamed Sana, Nicola Piovesan, Antonio De Domenico, Yibin Kang, Haozhe Zhang, Merouane Debbah, Fadhel Ayed* | **Category: cs.AI, cs.NI** | **Updated: 2025-07-29**

**Keywords:** 根本原因分析, 大型语言模型, 5G网络, 领域适应, 推理

**Comment:** 

> **TL;DR:** 针对5G网络中根本原因分析的挑战，本文提出一个轻量级框架，利用LLMs并结合两阶段训练方法，显著提升了RCA的准确性和可解释性。

**AI_Comments:** 本文创新性地将大型语言模型应用于5G网络的根本原因分析，并通过引入领域特定数据集和两阶段训练方法有效解决了LLMs在专业领域知识和可解释性方面的不足。其提出的TeleLogs数据集为RCA能力基准测试提供了宝贵资源，而结合监督微调和强化学习的训练策略则显著提升了模型的实用性和解释力，为网络故障诊断自动化提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 移动网络中的根本原因分析（RCA）因需要可解释性、领域专业知识和因果推理而极具挑战性。现有开源推理LLMs在这些问题上表现不佳，凸显了领域特定适应的必要性。

**Method:** 本文提出了一个轻量级框架，利用大型语言模型（LLMs）进行根本原因分析（RCA）。为此，引入了TeleLogs，一个经过整理的、带有注释的故障排除问题数据集，用于基准测试RCA能力。为解决现有LLMs的不足，提出了一种两阶段训练方法，该方法将监督微调与强化学习相结合，以提高LLMs的准确性和推理质量。该方法微调一系列RCA模型，以整合领域知识并生成结构化、多步骤的诊断解释。

**Result:** 评估显示，现有开源推理LLMs在处理RCA问题时表现不佳。在多个LLM尺寸上进行的广泛实验表明，与最先进的推理和非推理模型相比，所提出的方法实现了显著的性能提升，并且对随机测试变体具有强大的泛化能力。

**Conclusion:** 领域适应、推理增强的LLMs在网络操作和管理中，对于实用且可解释的根本原因分析具有广阔前景。

> **ai_Abstract:** 本文针对5G无线网络中根本原因分析（RCA）的挑战，提出了一个利用大型语言模型（LLMs）的轻量级框架。为解决现有LLMs在RCA任务上的不足，作者引入了TeleLogs数据集，并提出了一种结合监督微调和强化学习的两阶段训练方法，以将领域知识融入LLMs并生成可解释的多步骤诊断。实验证明，该方法显著提升了LLMs在RCA任务上的性能和泛化能力，展现了领域适应型推理LLMs在网络运维中的巨大潜力。

> **摘要翻译:** 移动网络中的根本原因分析（RCA）由于需要可解释性、领域专业知识和因果推理而仍然是一项具有挑战性的任务。在这项工作中，我们提出了一个轻量级框架，利用大型语言模型（LLMs）进行RCA。为此，我们引入了TeleLogs，这是一个经过整理的、带有注释的故障排除问题数据集，旨在衡量RCA能力。我们的评估显示，现有的开源推理LLMs在这些问题上表现不佳，突出了领域特定适应的必要性。为了解决这个问题，我们提出了一种两阶段训练方法，该方法将监督微调与强化学习相结合，以提高LLMs的准确性和推理质量。所提出的方法微调了一系列RCA模型，以整合领域知识并生成结构化、多步骤的诊断解释，从而提高了可解释性和有效性。在多种LLM尺寸上进行的广泛实验表明，与最先进的推理和非推理模型相比，性能显著提高，包括对随机测试变体的强大泛化能力。这些结果表明，领域适应、推理增强的LLMs在网络操作和管理中，对于实用且可解释的根本原因分析具有广阔前景。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [633] [Adaptive Cluster Collaborativeness Boosts LLMs Medical Decision Support Capacity](https://arxiv.org/abs/2507.21159)
> *自适应聚类协作性提升大型语言模型医疗决策支持能力*

*Zhihao Peng, Liuxin Bao, Shengyuan Liu, Yixuan Yuan* | **Category: cs.AI, cs.LG, cs.MA** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 医疗决策支持, 自适应聚类, 协作性, 自多样性

**Comment:** 

> **TL;DR:** 本文提出一种自适应聚类协作方法，通过最大化自多样性和交叉一致性来提升大型语言模型（LLMs）在医疗决策支持中的能力，并在两个医疗数据集上验证了其有效性。

**AI_Comments:** 本文的创新点在于提出了自适应选择和优化LLM集群组件的方法，而非依赖预定义或人工干预，这对于提升LLM在专业领域（如医疗）的应用具有重要意义。通过引入自多样性和交叉一致性机制，有效解决了现有协作方法中组件选择规则缺乏和不一致输出的问题，展示了其在医疗决策支持方面超越现有SOTA模型的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLMs）的协作方法缺乏明确的组件选择规则，需要人工干预或临床验证；同时，现有架构过度依赖预定义的LLM集群，导致部分LLMs在医疗决策支持场景中表现不佳，从而使协作性失效。

**Method:** 提出一种自适应聚类协作方法，包含自多样性最大化和交叉一致性最大化机制。自多样性通过计算LLM内部输出的模糊匹配值来衡量，并优先选择高自多样性的LLM作为集群组件，无需训练。交叉一致性通过测量最高自多样性LLM与其他LLM之间的值来确定，并逐步排除交叉一致性最低的LLM，以消除协作传播中的潜在不一致输出。

**Result:** 在NEJMQA和MMLU-Pro-health两个专业医疗数据集上进行了广泛实验，结果表明该方法在面向医师的专业领域中是有效的。例如，在NEJMQA数据集上，该方法在所有学科中都达到了公开的官方及格分数，特别是在妇产科，其准确率（ACC）达到65.47%，而GPT-4的ACC为56.12%。

**Conclusion:** 该自适应聚类协作方法能有效提升大型语言模型在医疗决策支持中的能力，尤其是在处理特定医疗专业领域，并能克服现有协作方法的局限性。

> **ai_Abstract:** 本文提出一种名为自适应聚类协作（Adaptive Cluster Collaborativeness）的新方法，旨在解决现有大型语言模型（LLM）在医疗决策支持中协作性不足和依赖预定义集群的问题。该方法通过最大化自多样性（基于LLM内部输出模糊匹配值选择组件）和交叉一致性（逐步消除不一致的LLM输出）来提升LLM性能。在NEJMQA和MMLU-Pro-health医疗数据集上的实验结果表明，该方法显著提高了LLM在医生导向型专业领域的准确性，甚至超越了GPT-4在特定学科的表现。

> **摘要翻译:** 大型语言模型（LLMs）的协作性已在自然语言处理系统中被证明是有效的，对医疗保健发展具有相当大的前景。然而，它缺乏明确的组件选择规则，需要人工干预或临床特定验证。此外，现有架构严重依赖预定义的大型语言模型集群，其中部分大型语言模型在医疗决策支持场景中表现不佳，从而使大型语言模型的协作性失效。为此，我们提出了一种自适应聚类协作方法，涉及自多样性最大化和交叉一致性最大化机制，以提升大型语言模型在医疗决策支持方面的能力。对于自多样性，我们计算大型语言模型内部成对输出的模糊匹配值作为其自多样性值，随后以无训练的方式优先选择具有高自多样性值的大型语言模型作为集群组件。对于交叉一致性，我们首先测量具有最高自多样性值的大型语言模型与其他模型之间的交叉一致性值，然后逐渐屏蔽掉具有最低交叉一致性值的大型语言模型，以消除协作传播过程中潜在的不一致输出。在NEJMQA和MMLU-Pro-health两个专业医疗数据集上进行的广泛实验表明，我们的方法在面向医师的专业领域中是有效的。例如，在NEJMQA上，我们的方法在所有学科中都达到了公开的官方及格分数，特别是在妇产科，我们的方法实现了65.47%的ACC，而GPT-4的ACC为56.12%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [634] [Large Language Models for Wireless Communications: From Adaptation to Autonomy](https://arxiv.org/abs/2507.21524)
> *无线通信中的大型语言模型：从适应到自治*

*Le Liang, Hao Ye, Yucheng Sheng, Ouya Wang, Jiacheng Wang, Shi Jin, Geoffrey Ye Li* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 无线通信, 自治网络, 基础模型, 人工智能

**Comment:** 

> **TL;DR:** 本文探讨了大型语言模型（LLMs）在无线通信领域的应用，旨在利用其推理和泛化能力，实现智能、自适应和自治的未来无线网络。

**AI_Comments:** 该论文探讨了将大型语言模型（LLMs）应用于无线通信这一新兴且重要的交叉领域。其创新之处在于不仅关注LLMs的适应性应用，更展望了其在实现无线系统自治方面的潜力。这为未来智能无线网络的发展提供了新的研究视角和方向。

<details>
  <summary>Details</summary>

**Motivation:** 无线通信系统日益增长的复杂性和动态性需要智能和自适应的解决方案。大型语言模型（LLMs）在推理、泛化和零样本学习方面的能力为解决这些挑战提供了新的可能性。

**Method:** 本文探讨了将LLMs应用于无线通信的三个主要方向：1. 适应预训练LLMs以执行核心通信任务；2. 开发无线领域专用基础模型以平衡多功能性和效率；3. 赋能具备自主推理和协调能力的智能体LLMs。

**Result:** 文章强调了LLM方法相对于传统方法的独特优势，以及在该领域的最新进展和实际案例研究。

**Conclusion:** 文章概述了开放的挑战和研究机会，包括多模态融合、与轻量级模型的协作以及自我改进能力，为未来智能、自适应和自治的无线网络指明了道路。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）如何通过其强大的推理和泛化能力革新无线通信领域。文章提出了将LLMs应用于无线系统的三种途径：适应现有预训练模型、开发无线专用基础模型以及实现具备自主能力的智能体LLMs。文中强调了LLM方法相较于传统方法的优势，并指出了多模态融合、与轻量级模型协作以及自我改进等未来研究方向，旨在构建智能、自适应和自治的无线网络。

> **摘要翻译:** 大型语言模型（LLMs）的出现彻底改变了人工智能，提供了前所未有的推理、泛化和零样本学习能力。这些优势为无线通信开辟了新领域，其中日益增长的复杂性和动态性要求智能和自适应的解决方案。本文探讨了LLMs在以下三个关键方向上改变无线系统的作用：适应预训练LLMs以执行核心通信任务，开发无线领域专用基础模型以平衡多功能性和效率，以及赋能具备自主推理和协调能力的智能体LLMs。我们强调了最新进展、实际案例研究以及基于LLM的方法相对于传统方法的独特优势。最后，我们概述了开放的挑战和研究机会，包括多模态融合、与轻量级模型的协作以及自我改进能力，为未来智能、自适应和自治的无线网络指明了道路。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [644] [Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach](https://arxiv.org/abs/2505.14479)
> *迈向使用大型语言模型实现可靠证明生成：一种神经符号方法*

*Oren Sultan, Eitan Stern, Dafna Shahaf* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-29**

**Keywords:** 神经符号, 证明生成, 大型语言模型, 形式化验证, 几何问题

**Comment:** long paper

> **TL;DR:** 大型语言模型在形式证明方面存在困难；一种结合类比问题和验证器反馈的神经符号方法显著提高了证明准确性，尤其是在几何问题上。

**AI_Comments:** 本研究的创新之处在于其双重神经符号方法，有效地结合了大型语言模型的生成能力与符号推理的严谨性，以解决其在形式化证明方面的固有弱点。其重要性在于为提高大型语言模型在需要高可信度的关键应用中的可靠性、准确性和一致性提供了可行途径。特别是形式化验证器提供反馈的机制，是提升证明质量的关键组成部分。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在需要严格逻辑演绎和符号推理的形式领域（例如数学证明生成）中面临挑战。本研究旨在克服这一挑战，并提高大型语言模型在复杂和需要信任的应用中的可靠性、准确性和一致性。

**Method:** 提出了一种神经符号方法，该方法包含两个方面：1) 检索类比问题并利用其证明来指导大型语言模型；2) 使用形式化验证器评估生成的证明并提供反馈，帮助模型修正不正确的证明。以几何问题作为概念验证。

**Result:** 该方法显著提高了OpenAI o1模型在证明准确性方面的表现（提升58%-70%）；类比问题和验证器的反馈都对这些提升有所贡献。

**Conclusion:** 转向生成可验证正确结论的大型语言模型，可以显著提高其可靠性、准确性和一致性，从而解锁需要可信度的复杂任务和关键现实世界应用。

> **ai_Abstract:** 本文提出了一种神经符号方法，旨在提高大型语言模型在形式领域（如数学证明生成，特别是几何问题）中的表现。该方法通过利用类比问题的证明来指导大型语言模型，并结合形式化验证器提供反馈和修正。研究表明，该方法显著提升了证明准确性（对OpenAI o1模型有58%-70%的改进），这预示着未来大型语言模型在复杂和关键应用中将更加可靠和值得信赖。

> **摘要翻译:** 大型语言模型（LLM）在需要严格逻辑演绎和符号推理的形式领域（例如数学证明生成）中面临挑战。我们提出了一种神经符号方法，该方法结合了大型语言模型的生成优势和结构化组件来克服这一挑战。作为概念验证，我们专注于几何问题。我们的方法分为两部分：(1) 我们检索类比问题并使用它们的证明来指导大型语言模型，以及 (2) 一个形式化验证器评估生成的证明并提供反馈，帮助模型修正不正确的证明。我们证明了我们的方法显著提高了OpenAI o1模型的证明准确性（提升58%-70%）；类比问题和验证器的反馈都对这些提升有所贡献。更广泛地说，转向生成可验证正确结论的大型语言模型可以显著提高其可靠性、准确性和一致性，从而解锁需要可信度的复杂任务和关键现实世界应用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [652] [Games Agents Play: Towards Transactional Analysis in LLM-based Multi-Agent Systems](https://arxiv.org/abs/2507.21354)
> *代理人玩的游戏：迈向基于LLM的多智能体系统中的事务分析*

*Monika Zamojska, Jarosław A. Chudziak* | **Category: cs.AI, cs.MA** | **Updated: 2025-07-28**

**Keywords:** 多智能体系统, 事务分析, 认知架构, 心理动力学, LLM

**Comment:** Proceedings of the Annual Meeting of the Cognitive Science Society
  (CogSci 2025), https://escholarship.org/uc/item/7gg6j165

> **TL;DR:** 本文介绍了Trans-ACT，一种将事务分析（TA）原则嵌入多智能体系统（MAS）的方法，以创建具有更真实心理动力学的智能体，并在“愚蠢游戏”场景中展示了更深入、更具上下文意识的互动。

**AI_Comments:** 这项研究创新性地将心理学中的事务分析理论引入到多智能体系统的设计中，通过模拟人类的自我状态（父母、成人、儿童）和人生脚本，显著提升了智能体交互的心理真实性和复杂性。这对于模拟更复杂、更贴近人类社会行为的MAS具有重要意义，尤其在人机交互、社会模拟等领域有巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 目前大多数多智能体系统（MAS）框架未能捕捉人类行为潜在的认知复杂性，因此需要一种能生成具有真实心理动力学智能体的方法。

**Method:** 本文引入了Trans-ACT（事务分析认知工具包）方法，将事务分析（TA）原则嵌入到多智能体系统（MAS）中。Trans-ACT将父母、成人和儿童自我状态整合到智能体的认知架构中，每个自我状态检索特定上下文的记忆并用于塑造对新情况的反应。最终的答案根据智能体潜在的人生脚本选择。

**Result:** 实验模拟重现了“愚蠢游戏”场景，结果表明，基于认知和TA原则的智能体能够产生更深入、更具上下文意识的互动。

**Conclusion:** 该研究为包括冲突解决、教育支持和高级社会心理学研究在内的各种应用开辟了新途径。

> **ai_Abstract:** 本文提出了一种名为Trans-ACT的新方法，旨在将事务分析（TA）的心理学原理融入基于LLM的多智能体系统（MAS）。Trans-ACT通过整合父母、成人和儿童等自我状态到智能体的认知架构中，使其能够根据上下文记忆和人生脚本生成更具真实心理动态的反应。通过“愚蠢游戏”场景的模拟，研究证明了这种方法能够产生更深入、更具上下文意识的智能体互动，并为冲突解决、教育和心理学研究等领域提供了新的应用潜力。

> **摘要翻译:** 多智能体系统（MAS）越来越多地用于模拟社会互动，但大多数框架未能捕捉人类行为潜在的认知复杂性。在本文中，我们引入了Trans-ACT（事务分析认知工具包），这是一种将事务分析（TA）原则嵌入MAS的方法，以生成具有真实心理动力学特征的智能体。Trans-ACT将父母、成人和儿童自我状态整合到智能体的认知架构中。每个自我状态检索特定上下文的记忆，并利用它们来塑造对新情况的反应。最终的答案根据智能体潜在的人生脚本选择。我们的实验模拟重现了“愚蠢游戏”场景，结果表明，基于认知和TA原则的智能体能够产生更深入、更具上下文意识的互动。展望未来，我们的研究为包括冲突解决、教育支持和高级社会心理学研究在内的各种应用开辟了新途径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [656] [A Neuro-Symbolic Approach for Probabilistic Reasoning on Graph Data](https://arxiv.org/abs/2507.21873)
> *一种用于图数据概率推理的神经符号方法*

*Raffaele Pojer, Andrea Passerini, Kim G. Larsen, Manfred Jaeger* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 神经符号, 图神经网络, 关系贝叶斯网络, 概率推理, 图数据

**Comment:** Submitted to the Journal of Artificial Intelligence Research (JAIR);
  under revision. 29 pages, 6 figures. Code available at
  https://github.com/raffaelepojer/NeSy-for-graph-data

> **TL;DR:** 提出一种神经符号框架，将图神经网络（GNNs）与关系贝叶斯网络（RBNs）结合，以在图数据上实现更强大的概率推理和学习。

**AI_Comments:** 这项工作的创新在于提出了一种将图神经网络（GNNs）与关系贝叶斯网络（RBNs）无缝集成的神经符号框架，有效弥补了GNN在符号推理和通用推理方面的不足。通过结合两者的优势，该方法在图数据上实现了强大的概率推理能力。提供了两种实现方式，增加了方法的灵活性和适用性。同时，为特定应用提供新的公开基准数据集也对社区有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）在图数据预测任务上表现出色，但缺乏整合符号领域知识和进行通用推理的能力。关系贝贝叶斯网络（RBNs）支持对图结构进行生成式概率建模并进行丰富的符号知识和概率推理。因此，研究的动机是结合GNNs的学习能力与RBNs的灵活推理能力。

**Method:** 本文提出了一种将图神经网络（GNNs）无缝集成到关系贝叶斯网络（RBNs）中的神经符号框架。开发了两种集成方式：一是将GNN直接编译成RBN的原生语言，二是将GNN作为外部组件。同时，提出了一种针对这些神经符号模型的最大后验（MAP）推理方法。

**Result:** 该框架应用于两个不同问题：将节点分类的GNN转换为集体分类模型，显著提高了准确性；解决环境规划中的多目标网络优化问题，其中MAP推理支持复杂的决策制定。两项应用都提供了新的公开基准数据集。

**Conclusion:** 这项工作引入了一种强大且连贯的神经符号方法来处理图数据，弥合了学习和推理之间的鸿沟，从而实现了新颖的应用并提高了各种任务的性能。

> **ai_Abstract:** 本文提出了一种神经符号框架，将图神经网络（GNNs）与关系贝叶斯网络（RBNs）无缝集成，旨在结合GNNs的学习能力和RBNs的灵活推理能力，以克服GNNs在整合符号领域知识和通用推理方面的不足。该框架提供了两种实现方式，并引入了一种最大后验（MAP）推理方法。通过在节点分类和环境规划中的多目标网络优化问题上的应用，证明了其在提高准确性和支持复杂决策方面的有效性，并提供了新的基准数据集。这项工作为图数据处理提供了一种强大的神经符号方法，弥合了学习与推理之间的差距，有望在多样化任务中实现新颖应用和性能提升。

> **摘要翻译:** 图神经网络（GNNs）在图结构数据上的预测任务中表现出色，但通常缺乏整合符号领域知识和执行通用推理的能力。相比之下，关系贝叶斯网络（RBNs）能够对图状结构进行完全生成式概率建模，并支持丰富的符号知识和概率推理。本文提出了一个神经符号框架，将GNNs无缝集成到RBNs中，结合了GNNs的学习能力和RBNs的灵活推理能力。
我们开发了两种这种集成的实现方式：一种是将GNNs直接编译成RBN的原生语言，另一种是将GNN作为外部组件。这两种方法都保留了GNNs的语义和计算特性，同时完全符合RBN的建模范式。我们还为这些神经符号模型提出了一种最大后验（MAP）推理方法。
为了展示该框架的多功能性，我们将其应用于两个不同的问题。首先，我们将一个用于节点分类的GNN转换成一个集体分类模型，该模型明确地建模了同质和异质标签模式，从而大大提高了准确性。其次，我们在环境规划中引入了一个多目标网络优化问题，其中MAP推理支持复杂的决策制定。这两个应用都包含了新的公开可用基准数据集。
这项工作引入了一种强大且连贯的图数据神经符号方法，以弥合学习和推理之间的鸿沟，从而实现新颖的应用并提高各种任务的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [660] [Structured Relevance Assessment for Robust Retrieval-Augmented Language Models](https://arxiv.org/abs/2507.21287)
> *用于鲁棒检索增强语言模型的结构化相关性评估*

*Aryan Raj, Astitva Veer Garg, Anitha D* | **Category: cs.AI** | **Updated: 2025-07-28**

**Keywords:** 检索增强语言模型, 相关性评估, 知识整合, 幻觉, 鲁棒性

**Comment:** International Conference on ICT for Sustainable Development (ICT4SD)

> **TL;DR:** 本文提出了一个结构化相关性评估框架，通过改进文档评估、平衡内外知识整合以及有效处理无法回答的查询，增强了检索增强语言模型（RALM）的鲁棒性，显著降低了幻觉率并提高了推理透明度。

**AI_Comments:** 该论文的创新之处在于提出了一个结构化相关性评估框架，通过多维评分和合成数据训练来提高RALM的鲁棒性。其重要性在于有效解决了RALM面临的事实错误和幻觉问题，提升了问答系统的可靠性。尽管文中提及了区分可信信息和平衡延迟的挑战，但这项工作为RALM的实际应用提供了有价值的进展。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强语言模型（RALMs）在减少事实错误方面面临重大挑战，特别是在文档相关性评估和知识整合方面，这促使作者开发一个框架来提高其鲁棒性。

**Method:** 本研究引入了一个结构化相关性评估框架，该框架通过多维评分系统（考虑语义匹配和来源可靠性）、基于嵌入的相关性评分和混合质量文档的合成训练数据来增强文档评估。此外，还实施了利基主题的专门基准测试、知识整合机制以及针对知识覆盖不足查询的“未知”响应协议。

**Result:** 初步评估表明，幻觉率显著降低，推理过程的透明度得到改善。

**Conclusion:** 该框架推动了更可靠的问答系统的发展，使其能够在动态环境和可变数据质量下有效运行。尽管在准确区分可信信息和平衡系统延迟与彻底性方面仍存在挑战，但这项工作代表着提高RALM可靠性的重要一步。

> **ai_Abstract:** 本文提出了一个结构化相关性评估框架，旨在增强检索增强语言模型（RALM）的鲁棒性，以应对事实错误和知识整合的挑战。该框架通过多维评分系统（结合语义匹配和来源可靠性）、基于嵌入的相关性评分、合成训练数据以及专门的基准测试和“未知”响应协议来改进文档评估和知识整合。初步结果显示，该方法显著降低了RALM的幻觉率并提高了推理透明度，为开发更可靠的问答系统迈出了重要一步。

> **摘要翻译:** 检索增强语言模型（RALMs）在减少事实错误方面面临重大挑战，特别是在文档相关性评估和知识整合方面。我们引入了一个结构化相关性评估框架，通过改进文档评估、平衡内部和外部知识整合以及有效处理无法回答的查询来增强RALM的鲁棒性。我们的方法采用多维评分系统，同时考虑语义匹配和来源可靠性，利用基于嵌入的相关性评分和带有混合质量文档的合成训练数据。我们实施了利基主题的专门基准测试、知识整合机制以及针对知识覆盖不足查询的“未知”响应协议。初步评估表明，幻觉率显著降低，推理过程的透明度得到改善。我们的框架推动了更可靠的问答系统的发展，使其能够在动态环境和可变数据质量下有效运行。尽管在准确区分可信信息和平衡系统延迟与彻底性方面仍存在挑战，但这项工作代表着提高RALM可靠性的有意义的一步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [671] [SLR: Automated Synthesis for Scalable Logical Reasoning](https://arxiv.org/abs/2506.15787)
> *SLR：可扩展逻辑推理的自动化合成*

*Lukas Helff, Ahmad Omar, Felix Friedrich, Antonia Wüst, Hikaru Shindo, Rupert Mitchell, Tim Woydt, Patrick Schramowski, and Wolfgang Stammer Kristian Kersting* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 逻辑推理, 自动化合成, 课程学习, 基准测试

**Comment:** 

> **TL;DR:** SLR是一个自动化框架，用于通过可扩展逻辑推理系统地评估和训练大型语言模型（LLMs），它能自动合成推理任务提示、验证程序和真实规则，无需人工标注。SLR创建了一个包含1.9万个提示的基准测试SLR-Bench，并表明通过SLR进行的课程学习可显著提高LLM的逻辑推理能力，且成本更低，并能泛化到其他基准。

**AI_Comments:** SLR的创新之处在于其端到端的自动化合成能力，能够生成用于LLM评估和训练的推理任务、验证程序和真实规则，且无需人工标注，这大大提高了效率和可扩展性。其通过课程学习显著提升LLM推理能力并降低计算成本的成果非常重要，为未来LLM的训练和部署提供了新的方向。SLR-Bench的构建也为LLM的逻辑推理能力评估提供了一个新的、结构化的基准。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是为了通过可扩展逻辑推理，系统地评估和训练大型语言模型（LLMs）。现有的方法可能缺乏自动化、可扩展性或对任务难度的精确控制，并且需要大量的人工标注。

**Method:** 该论文引入了SLR框架，这是一个端到端系统，用于通过可扩展逻辑推理对LLMs进行系统评估和训练。SLR根据用户任务规范自动合成：(i) 归纳推理任务的指令提示，(ii) 可在模型输出上执行以提供可验证奖励的验证程序，以及(iii) 潜在的真实规则。这个过程是完全自动化的、可扩展的，不需要人工标注，并能精确控制任务难度。研究人员使用SLR创建了SLR-Bench，这是一个包含1.9万个提示的基准测试，分为20个课程级别，这些级别在关系、算术和递归复杂度上逐渐增加。

**Result:** 大规模评估显示，当代LLMs能够生成语法上有效的规则，但在正确的逻辑推理上经常失败。最近的推理LLMs表现有所改善，但测试时计算成本非常高，仅1,000个提示的成本就超过300美元。通过SLR进行的课程学习使Llama-3-8B在SLR-Bench上的准确率翻倍，以极低的计算成本实现了与Gemini-Flash-Thinking相当的性能。此外，这些推理能力可以泛化到各种已建立的基准测试。

**Conclusion:** SLR框架能够有效地通过自动化和可扩展的方式评估和训练LLMs的逻辑推理能力。通过SLR进行的课程学习显著提高了LLMs（如Llama-3-8B）的推理准确性，同时降低了计算成本，并且其推理能力可以泛化到其他下游推理任务，证明了SLR的有效性。

> **ai_Abstract:** 本文介绍了SLR，一个用于大规模逻辑推理的自动化框架，旨在系统评估和训练大型语言模型（LLMs）。SLR能够自动合成推理任务提示、验证程序和真实规则，无需人工标注，并能精确控制任务难度。研究者利用SLR构建了SLR-Bench基准测试，包含1.9万个按难度分级的提示。评估结果显示，尽管LLMs能生成语法正确的规则，但在逻辑推理上仍有欠缺；而SLR支持的课程学习显著提升了Llama-3-8B的准确率，使其在计算成本更低的情况下达到与Gemini-Flash-Thinking相当的水平，并且这种推理能力能泛化到其他基准测试，证明了SLR在提升LLM推理能力方面的有效性。

> **摘要翻译:** 我们引入了SLR，这是一个端到端框架，用于通过可扩展逻辑推理系统地评估和训练大型语言模型（LLMs）。给定用户的任务规范，SLR自动合成 (i) 归纳推理任务的指令提示，(ii) 一个验证程序，可在模型输出上执行以提供可验证的奖励，以及 (iii) 潜在的真实规则。这个过程是完全自动化的，可扩展的，不需要人工标注，并能精确控制任务难度。使用SLR，我们创建了SLR-Bench，这是一个包含1.9万个提示的基准测试，分为20个课程级别，这些级别在关系、算术和递归复杂度上逐渐增加。大规模评估显示，当代LLMs能够轻松生成语法上有效的规则，但在正确的逻辑推理上经常失败。最近的推理LLMs表现有所改善，但测试时计算成本非常高，仅1,000个提示的成本就超过300美元。最后，通过SLR进行的课程学习使Llama-3-8B在SLR-Bench上的准确率翻倍，以极低的计算成本实现了与Gemini-Flash-Thinking相当的性能。此外，这些推理能力可以泛化到各种已建立的基准测试，突出了SLR在下游推理中的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [673] ["Teammates, Am I Clear?": Analysing Legible Behaviours in Teams](https://arxiv.org/abs/2507.21631)
> *队友们，我明白了吗？：分析团队中的可理解行为*

*Miguel Faria, Francisco S. Melo, Ana Paiva* | **Category: cs.AI, cs.MA** | **Updated: 2025-07-29**

**Keywords:** 可理解决策, 多代理系统, 团队合作, 顺序决策, 协作

**Comment:** 

> **TL;DR:** 本文将可理解决策扩展到多代理团队，表明拥有可理解代理的团队优于仅由标准最优代理组成的团队。

**AI_Comments:** 本文的创新之处在于将可理解决策的概念从单代理扩展到多代理设置，这对于改进复杂团队环境中的人机或代理间协作至关重要。其研究结果表明，引入可理解代理的团队具有显著的性能优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于可理解决策的研究主要集中于单个代理与人类的交互，忽略了在多代理团队或人机团队中实现可理解决策的益处。

**Method:** 本文提出了一种将可理解决策扩展到多代理设置的方法，并在多代理基准场景中展示了其性能。

**Result:** 拥有一个可理解代理的团队能够胜过仅由具有标准最优行为的代理组成的团队。

**Conclusion:** 将可理解决策扩展到多代理设置能够提高协作代理的性能。

> **ai_Abstract:** 本文针对现有研究仅关注单代理交互的局限性，提出了将可理解决策扩展到多代理团队的方法。该方法在协作多代理环境中表现出性能提升，在基准测试中，包含可理解代理的团队优于仅由标准最优代理组成的团队。

> **摘要翻译:** 本文研究了在团队和团队合作背景下，顺序决策中的可理解性概念。已有工作将可理解性概念扩展到顺序决策，包括确定性和随机场景。然而，这些工作侧重于一个代理与一个人交互，忽略了在代理团队或与人类组成的团队中进行可理解决策的益处。在这项工作中，我们提出了将可理解决策扩展到多代理设置，以提高协作代理的性能。我们通过在多代理基准场景中使用我们提出的扩展，展示了可理解决策在团队场景中的性能。我们表明，拥有一个可理解代理的团队能够胜过仅由具有标准最优行为的代理组成的团队。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [694] [A finite time analysis of distributed Q-learning](https://arxiv.org/abs/2405.14078)
> *分布式Q学习的有限时间分析*

*Han-Dong Lim, Donghwan Lee* | **Category: cs.AI, cs.LG, cs.MA** | **Updated: 2025-07-29**

**Keywords:** 分布式Q学习, 有限时间分析, 样本复杂度, 多智能体强化学习, 表格查找

**Comment:** Published at RLC2025

> **TL;DR:** 本文对分布式Q学习算法进行了有限时间分析，并在表格查找设置下给出了新的样本复杂度结果。

**AI_Comments:** 这项工作通过提供分布式Q学习算法的有限时间分析和样本复杂度结果，对多智能体强化学习的理论基础做出了重要贡献。特别是，在缺乏中心奖励函数的分布式场景下，对算法性能进行量化分析具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 单智能体强化学习的成功推动了多智能体强化学习的兴趣增长。本研究旨在解决一个分布式Q学习场景中的序贯决策问题，其中多个智能体合作但不共享中心奖励函数。

**Method:** 作者研究了一个分布式Q学习算法的有限时间分析，并提供了其在表格查找设置下的样本复杂度结果。

**Result:** 本文提供了一个新的样本复杂度结果，其表达式为 $\tilde{\mathcal{O}}\left( \min\left\{\frac{1}{\epsilon^2}\frac{t_{\text{mix}}}{(1-\gamma)^6 d_{\min}^4 } ,\frac{1}{\epsilon}\frac{\sqrt{|\gS||\gA|}}{(1-\sigma_2(\boldsymbol{W}))(1-\gamma)^4 d_{\min}^3} \right\}\right)$。

**Conclusion:** 本文成功地对分布式Q学习算法进行了有限时间分析，并得到了新的样本复杂度界限，这有助于理解多智能体强化学习算法的收敛性质。

> **ai_Abstract:** 本文研究了分布式Q学习算法的有限时间分析，该算法用于解决多智能体合作的序贯决策问题，且智能体无法访问中心奖励函数。研究在表格查找设置下，提出了一个新的样本复杂度上界，为理解分布式Q学习的收敛性能提供了理论依据。

> **摘要翻译:** 多智能体强化学习（MARL）的兴趣显著增长，这得益于单智能体强化学习（RL）应用所取得的经验成功。在本研究中，我们考虑了一个分布式Q学习场景，其中多个智能体合作解决一个序贯决策问题，但无法访问作为局部奖励平均值的中心奖励函数。具体来说，我们研究了分布式Q学习算法的有限时间分析，并在表格查找设置下提供了新的样本复杂度结果：$\tilde{\mathcal{O}}\left( \min\left\{\frac{1}{\epsilon^2}\frac{t_{\text{mix}}}{(1-\gamma)^6 d_{\min}^4 } ,\frac{1}{\epsilon}\frac{\sqrt{|\gS||\gA|}}{(1-\sigma_2(\boldsymbol{W}))(1-\gamma)^4 d_{\min}^3} \right\}\right)$。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [696] [SafeDriveRAG: Towards Safe Autonomous Driving with Knowledge Graph-based Retrieval-Augmented Generation](https://arxiv.org/abs/2507.21585)
> *SafeDriveRAG：基于知识图谱检索增强生成实现安全自动驾驶*

*Hao Ye, Mengshi Qi, Zhaohong Liu, Liang Liu, Huadong Ma* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 自动驾驶安全, 知识图谱, 检索增强生成, 视觉语言模型, VQA

**Comment:** 

> **TL;DR:** 本文提出了一个大规模交通安全VQA基准（SafeDrive228K）和一个基于知识图谱检索增强生成（RAG）的视觉语言模型（VLM）方法（SafeDriveRAG），显著提升了自动驾驶系统在安全关键场景下的性能。

**AI_Comments:** 该论文的创新点在于构建了首个大规模交通安全领域的视觉问答基准SafeDrive228K，填补了现有研究在交通安全关键场景评估方面的空白。其提出的SafeDriveRAG方法，通过结合知识图谱和检索增强生成，有效提升了视觉语言模型在复杂安全场景下的性能，具有重要的实践意义和研究价值。方法的即插即用特性也增强了其通用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究忽视了在交通安全关键驾驶场景中评估视觉语言模型（VLM），因此需要开发新的方法和基准来增强自动驾驶系统的感知、态势理解和路径规划安全性。

**Method:** 创建了首个大规模多模态问答基准SafeDrive228K，包含228K个示例和18个子任务，涵盖多种交通安全查询。提出了一种即插即用的多模态知识图谱检索增强生成方法SafeDriveRAG，该方法采用新颖的多尺度子图检索算法，并整合了互联网收集的交通安全指南。

**Result:** 整合RAG显著提高了五种主流VLM的性能：在交通事故任务中提升4.73%，在极端情况任务中提升8.79%，在交通安全常识任务中提升14.57%。

**Conclusion:** 所提出的基准和方法在推进交通安全研究方面具有巨大潜力。

> **ai_Abstract:** 该论文旨在通过引入新的基准和方法来提升自动驾驶系统的安全性。作者创建了SafeDrive228K，这是首个大规模多模态交通安全问答基准，包含228K个示例，用于全面评估视觉语言模型（VLM）的理解和推理能力。同时，提出了一种基于知识图谱检索增强生成（RAG）的SafeDriveRAG方法，该方法结合了多尺度子图检索和交通安全指南。实验结果表明，SafeDriveRAG显著提升了主流VLM在多项交通安全关键任务中的表现，凸显了其在推动自动驾驶安全研究方面的潜力。

> **摘要翻译:** 在这项工作中，我们研究了如何利用视觉语言模型（VLM）来增强自动驾驶系统的安全性，包括感知、态势理解和路径规划。然而，现有研究在交通安全关键驾驶场景中对这些模型的评估却 largely overlooked。为了弥补这一空白，我们创建了基准（SafeDrive228K），并提出了一种基于VLM与知识图谱检索增强生成（SafeDriveRAG）的新基线用于视觉问答（VQA）。具体来说，我们引入了SafeDrive228K，这是首个大规模多模态问答基准，包含18个子任务的228K个示例。该基准涵盖了从交通事故和极端情况到常见安全知识的各种交通安全查询，能够全面评估模型的理解和推理能力。此外，我们提出了一种即插即用的多模态知识图谱检索增强生成方法，该方法采用了一种新颖的多尺度子图检索算法以实现高效的信息检索。通过整合从互联网收集的交通安全指南，该框架进一步增强了模型处理安全关键情况的能力。最后，我们对五种主流VLM进行了全面评估，以评估它们在安全敏感驾驶任务中的可靠性。实验结果表明，整合RAG显著提高了性能，在交通事故任务中取得了+4.73%的增益，在极端情况任务中取得了+8.79%的增益，在交通安全常识任务中取得了+14.57%的增益，这突显了我们提出的基准和方法在推进交通安全研究方面的潜力。我们的源代码和数据可在https://github.com/Lumos0507/SafeDriveRAG获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [699] [Enhancing Student Learning with LLM-Generated Retrieval Practice Questions: An Empirical Study in Data Science Courses](https://arxiv.org/abs/2507.05629)
> *利用大型语言模型生成检索练习题增强学生学习：一项在数据科学课程中的实证研究*

*Yuan An, John Liu, Niyam Acharya, Ruhma Hashmi* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 检索练习, 学生学习, 数据科学, 知识保留

**Comment:** 

> **TL;DR:** 本研究表明，在数据科学课程中，使用大型语言模型（LLM）生成的检索练习题显著提高了学生的知识保留率，但仍需教师进行人工验证。

**AI_Comments:** 本文的创新点在于实证验证了LLM生成检索练习题对学生学习的积极影响，为LLM在教育领域的应用提供了具体证据。其重要性在于，它提出了一个潜在的解决方案，以应对传统检索练习题生成耗时的问题，提高了教学效率。然而，其局限性在于LLM生成问题的质量不稳定，需要教师进行额外的人工干预，这在一定程度上抵消了自动化的优势。

<details>
  <summary>Details</summary>

**Motivation:** 检索练习是一种有效的教学技术，但为教师生成高质量的检索练习题耗时费力，尤其是在快速发展的技术学科中。大型语言模型（LLMs）有潜力自动化这一过程，但其生成的问题对学生学习的有效性尚未明确。

**Method:** 本研究对两门大学数据科学课程的约60名学生进行了实证研究。比较了学生在接受LLM生成的多项选择检索练习题的一周与未提供此类问题的一周的学习成果。

**Result:** 结果表明，接触LLM生成检索练习题的学生知识保留率显著提高，平均准确率为89%，而没有此类练习的一周为73%。

**Conclusion:** 这些发现表明，LLM生成的检索问题可以有效支持学生学习，并可能为将检索练习整合到实时教学中提供可扩展的解决方案。然而，尽管有这些令人鼓舞的结果和潜在的省时效益，仍需谨慎，因为LLM生成问题的质量可能有所不同，教师仍需在发布给学生之前手动验证和修改生成的问题。

> **ai_Abstract:** 本研究旨在探讨利用大型语言模型（LLM）生成检索练习题对学生学习效果的影响。通过一项涉及约60名数据科学课程学生的实证研究，研究人员比较了学生在接受LLM生成的多项选择检索练习题后与未接受此类练习时的知识保留率。结果显示，LLM辅助的检索练习显著提高了学生的知识保留，准确率从73%提升至89%。这表明LLM在支持学生学习方面具有潜力，并可能提供一种可扩展的教学辅助方案，但研究也强调了教师仍需对生成问题的质量进行人工验证和修订。

> **摘要翻译:** 检索练习是一种公认的教学技术，已知能显著增强学生的学习和知识保留。然而，生成高质量的检索练习题对教师来说通常耗时且劳动密集，尤其是在快速发展的技术学科中。大型语言模型（LLMs）提供了通过响应提示生成问题来自动化此过程的潜力，但LLM生成的检索练习对学生学习的有效性仍有待确定。在本研究中，我们对两门大学数据科学课程（约60名学生）进行了一项实证研究。我们比较了学生在一周内接受LLM生成的多项选择检索练习题的学习成果，与未提供此类问题的一周的学习成果。结果表明，接触LLM生成检索练习的学生知识保留率显著提高，平均准确率为89%，而没有此类练习的一周为73%。这些发现表明，LLM生成的检索问题可以有效支持学生学习，并可能为将检索练习整合到实时教学中提供可扩展的解决方案。然而，尽管有这些令人鼓舞的结果和潜在的省时效益，仍需谨慎，因为LLM生成问题的质量可能有所不同。教师仍需在将生成的问题发布给学生之前手动验证和修改。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [708] [SynLang and Symbiotic Epistemology: A Manifesto for Conscious Human-AI Collaboration](https://arxiv.org/abs/2507.21067)
> *SynLang与共生认识论：有意识人机协作的宣言*

*Jan Kapusta* | **Category: cs.AI, cs.CY, cs.HC** | **Updated: 2025-06-03**

**Keywords:** 人机协作, 共生认识论, SynLang, 透明度, 可解释AI

**Comment:** 32 pages, 4 figures. Includes 2 Appendices containing SynLang v1.2.0
  protocol specification, and formal BNF grammar

> **TL;DR:** 本文提出了共生认识论作为人机认知伙伴关系的哲学基础，并引入了SynLang作为一种透明人机协作的形式协议，旨在通过结构化通信和信心校准的透明度来增强人机智能、保留人类能动性并维护道德责任。

**AI_Comments:** 该论文提出了一种新颖且重要的视角，即“共生认识论”，将AI视为真正的推理伙伴，而非仅仅是工具。SynLang协议通过提供双层透明度（TRACE和TRACE_FE）来解决当前AI系统不透明的问题，这对于建立人机之间的信任和促进有效的协作至关重要。其创新点在于将哲学基础与具体技术协议相结合，旨在实现真正意义上的人机共生智能。

<details>
  <summary>Details</summary>

**Motivation:** 当前的AI系统依赖不透明的推理过程，这阻碍了人类的监督和协作潜力。传统的解释性AI方法提供事后解释，并且通常未能建立真正的共生协作。

**Method:** 本文提出了共生认识论作为人机认知伙伴关系的哲学基础，将AI定位为推理伙伴。引入了SynLang（共生句法语言）作为透明人机协作的形式协议。该协议定义了TRACE（用于高级推理模式）和TRACE_FE（用于详细因素解释）两种互补机制，并集成了信心量化、对AI行为的声明式控制以及用于多代理协调的上下文继承。

**Result:** 该框架通过实际的人机对话进行了经验验证，展示了AI对结构化推理协议的适应性以及成功的元认知干预。

**Conclusion:** 通过双层透明度，SynLang与共生认识论共同使AI系统能够增强人类智能、保留人类能动性，并在协作决策中维护道德责任。

> **ai_Abstract:** 本文提出了一种名为“共生认识论”的哲学基础，旨在将AI定位为人类的推理伙伴，而非工具或替代品，以促进校准的信任。为实现透明的人机协作，引入了“SynLang”协议，该协议通过TRACE和TRACE_FE机制提供双层透明度（高级推理模式和详细解释），并集成信心量化、声明式控制和上下文继承。通过实际人机对话验证，SynLang和共生认识论共同致力于提升人类智能、保留人类能动性，并在协作决策中实现道德问责。

> **摘要翻译:** 当前的人工智能系统依赖不透明的推理过程，这阻碍了人类的监督和协作潜力。传统的解释性人工智能方法提供事后解释，并且通常未能建立真正的共生协作。在本文中，共生认识论被提出作为人机认知伙伴关系的哲学基础。与将人工智能视为单纯工具或替代品的框架不同，共生认识论将人工智能定位为推理伙伴，通过明确的推理模式和信心评估，使人类信心与人工智能可靠性保持一致，从而培养校准的信任。SynLang（共生句法语言）被引入作为透明人机协作的形式协议。该框架通过实际的人机对话进行了经验验证，展示了人工智能对结构化推理协议的适应性以及成功的元认知干认知干预。该协议定义了两种互补机制：TRACE用于高级推理模式，TRACE_FE用于详细因素解释。它还集成了信心量化、对人工智能行为的声明式控制以及用于多代理协调的上下文继承。通过结构化通信和嵌入信心校准的透明度，SynLang与共生认识论共同使人工智能系统能够增强人类智能、保留人类能动性，并在协作决策中维护道德责任。通过双层透明度，从高级推理模式开始，逐步深入到细粒度解释，该协议有助于快速理解并支持对人工智能决策的彻底验证。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [712] [Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis](https://arxiv.org/abs/2507.21875)
> *Tiny-BioMoE：一种用于生物信号分析的轻量级嵌入模型*

*Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis* | **Category: cs.AI** | **Updated: 2025-07-30**

**Keywords:** 生物信号分析, 疼痛评估, 嵌入模型, 轻量级, 多模态

**Comment:** 

> **TL;DR:** Tiny-BioMoE是一个轻量级预训练嵌入模型，用于从生物信号中提取高质量特征，有效支持自动疼痛识别。

**AI_Comments:** 该论文提出了一种轻量级且参数较少的生物信号嵌入模型Tiny-BioMoE，其创新点在于为复杂的疼痛评估任务提供了高效且客观的生理信号分析工具。模型预训练在大量数据上，并能有效提取高质量特征，对于需要实时或资源受限的自动疼痛评估系统具有重要意义。其开源代码也促进了研究的可重复性和进一步发展。

<details>
  <summary>Details</summary>

**Motivation:** 疼痛评估复杂且普遍，需要准确一致的评估。自动疼痛评估系统可实现持续监测、支持临床决策并减轻患者痛苦。利用生理信号提供客观精确的洞察，多模态整合可增强系统性能。

**Method:** 本文提出Tiny-BioMoE，一个轻量级预训练嵌入模型，用于生物信号分析。该模型在440万生物信号图像表示上训练，包含730万参数，旨在提取高质量嵌入以支持下游任务。

**Result:** 涉及电皮肤活动、血容量脉搏、呼吸信号、外周血氧饱和度及其组合的广泛实验表明，该模型在自动疼痛识别任务中对不同模态均有效。

**Conclusion:** Tiny-BioMoE是一种有效的工具，能够为自动疼痛识别任务从生物信号中提取高质量嵌入，并在多模态数据上表现出有效性。

> **ai_Abstract:** 本文提出Tiny-BioMoE，一个轻量级预训练嵌入模型，用于生物信号分析和自动疼痛识别。该模型在440万生物信号图像表示上训练，仅包含730万参数，旨在有效提取高质量嵌入。实验证明，Tiny-BioMoE在电皮肤活动、血容量脉搏、呼吸信号、外周血氧饱和度等多种生理信号模态下的自动疼痛识别任务中均表现出有效性。

> **摘要翻译:** 疼痛是一种复杂而普遍的疾病，影响着相当一部分人口。对于疼痛患者以及在医疗系统中制定有效的管理策略而言，准确和一致的评估至关重要。自动疼痛评估系统能够实现持续监测，支持临床决策，并有助于最大程度地减少患者痛苦，同时降低功能恶化的风险。利用生理信号可以客观而精确地洞察一个人的状态，并且将它们整合到多模态框架中可以进一步提高系统性能。本研究已提交给《第二届下一代疼痛评估多模态感知大挑战 (AI4PAIN)》。所提出的方法引入了Tiny-BioMoE，这是一种用于生物信号分析的轻量级预训练嵌入模型。该模型在440万生物信号图像表示上进行训练，仅包含730万参数，是提取高质量嵌入以支持下游任务的有效工具。涉及电皮肤活动、血容量脉搏、呼吸信号、外周血氧饱和度及其组合的广泛实验突出显示了该模型在自动疼痛识别任务中跨不同模态的有效性。该模型的架构（代码）和权重可在https://github.com/GkikasStefanos/Tiny-BioMoE 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [726] [Intrinsic Barriers and Practical Pathways for Human-AI Alignment: An Agreement-Based Complexity Analysis](https://arxiv.org/abs/2502.05934)
> *人类-AI对齐的内在障碍与实用途径：基于一致性的复杂性分析*

*Aran Nayebi* | **Category: cs.AI, cs.CC, cs.GT, cs.LG, cs.MA** | **Updated: 2025-07-29**

**Keywords:** AI对齐, 复杂性分析, 多目标优化, 可扩展性障碍, 人机协作

**Comment:** 20 pages, improved lower bounds and added clarifications

> **TL;DR:** 论文将AI对齐形式化，证明当目标或代理数量足够大时，对齐存在内在限制，即“没有免费午餐”原则，并识别了实现对齐的关键可扩展性障碍。

**AI_Comments:** 该论文为理解AI对齐提供了一个严谨的理论框架，超越了特定方法，建立了根本性限制。其“没有免费午餐”原则是一个关键的洞察，强调了管理复杂性的必要性，而非穷尽式地编码价值观。这种理论基础对于指导未来实际的对齐工作具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在理解人机对齐的根本限制和挑战，尤其是在处理大量目标或代理时，并阐明编码人类价值观的“没有免费午餐”原则。

**Method:** 论文将AI对齐形式化为一个多目标优化问题（$\langle M,N,\varepsilon,\delta\rangle$-一致性）。利用通信复杂性，证明了一个信息论下界。此外，还提供了在计算无界和有界理性下、带有噪声消息的情况下实现对齐的显式算法。

**Result:** 研究证明了当M（目标数量）或N（代理数量）足够大时，存在内在的对齐开销，这确立了对齐本身的严格内在限制。分析还识别出三个关键的可扩展性障碍：任务数量（M）、代理数量（N）和任务状态空间大小（D）。

**Conclusion:** 编码“所有人类价值观”必然导致不对齐，未来的对齐方法需要通过共识驱动的目标减少或优先级排序来明确管理复杂性。论文识别出的可扩展性障碍为更安全、可扩展的人机协作提供了指导。

> **ai_Abstract:** 该论文将AI对齐形式化为一个多目标优化问题，并利用通信复杂性证明了当目标或代理数量足够大时，AI对齐存在内在的信息论下限，即“没有免费午餐”原则。这表明编码所有人类价值观必然导致不对齐。论文还提出了实现对齐的算法，并识别出任务数量、代理数量和任务状态空间大小是关键的可扩展性障碍，为未来更安全、可扩展的人机协作提供了指导。

> **摘要翻译:** 我们将AI对齐形式化为一个多目标优化问题，称为$\langle M,N,\varepsilon,\delta\rangle$-一致性，该问题以更少的假设推广了现有方法，其中一组$N$个代理（包括人类）必须以至少$1-\delta$的概率在$M$个候选目标上达到近似（$\varepsilon$）一致。利用通信复杂性，我们证明了一个信息论下界，表明一旦$M$或$N$足够大，任何交互或理性都无法避免内在的对齐开销。这个障碍确立了对齐本身而非特定方法的严格内在限制，阐明了一个关键的“没有免费午餐”原则：编码“所有人类价值观”必然导致不对齐，要求未来的方法通过共识驱动的目标减少或优先级排序来明确管理复杂性。为了补充这个不可能的结果，我们提供了在计算无界和有界理性下、带有噪声消息的情况下实现对齐的显式算法。即使在这些对齐理论上保证任意精度的最佳情况下，我们的分析也确定了三个关键的可扩展性障碍：任务数量（$M$）、代理数量（$N$）和任务状态空间大小（$D$）；从而突出了基本的复杂性理论约束，并为更安全、可扩展的人机协作提供了指导。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [727] [Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light](https://arxiv.org/abs/2507.11482)
> *在进化之光下阐明强化学习的三大教义*

*Mani Hamidi, Terrence W. Deacon* | **Category: cs.AI** | **Updated: 2025-07-28**

**Keywords:** 强化学习, 进化理论, 智能体, 奖励假设, 生命起源理论

**Comment:** 

> **TL;DR:** 本文提出一个受开放式进化理论启发的框架，以重新审视强化学习的三个核心教义：智能体定义、学习目标和奖励假设的范围。文章讨论了进化动力学如何在个体生命周期内运作，并利用进化见解重新审视了学习目标和奖励假设。对于智能体问题，作者认为仅靠进化范式不足以解决，并提倡整合生命起源理论中的思想。

**AI_Comments:** 这篇论文以其跨学科的视角，挑战了强化学习领域内的核心“教义”，具有显著的创新性。它将生物进化理论引入到对RL基本问题的思考中，尤其是对智能体（agency）概念的探讨，超越了传统计算方法的局限。论文的价值在于其对深层概念性问题的批判性审视，并为理解生物学习和智能体提供了一个更广阔、更基础的理论框架，可能启发未来RL研究的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）的三个核心原则——关于智能体的定义、学习目标和奖励假设的范围——被认为是概念修订的关键目标，对理论和应用具有重大影响，因此需要重新审视。

**Method:** 作者提出了一个受开放式进化理论启发的框架来重新考虑这三个“教义”。首先，他们确立了进化动力学可以在个体生命周期内在大脑中运作。然后，他们利用进化见解来丰富学习的“适应而非搜索”观点，并使用进化适应度的类比来阐明标量奖励与多目标学习的争论。对于智能体问题，他们认为进化范式本身无法完全解决，并倡导整合生命起源理论中关于生存和复制的热力学思想。

**Result:** 本文重新审视了强化学习的三个核心教义。通过进化理论，文章丰富了“适应而非搜索”的学习观，并阐明了标量奖励与多目标奖励之间的辩论。对于最根本的智能体问题，作者认为进化范式虽有启发性，但不足以提供完整的形式化解释，需要结合生命起源理论中的热力学原理来理解智能体和资源受限的强化学习。

**Conclusion:** 尽管进化理论有助于重新思考强化学习的学习目标和奖励假设，但它本身无法完全解决智能体的问题。为了对智能体在生物系统中的作用提供正式的解释，需要整合生命起源理论中的思想，特别是生存和复制的热力学基础。

> **ai_Abstract:** 本文深入探讨了强化学习（RL）的三个核心“教义”：智能体的定义、学习目标以及奖励假设的范围。作者提出了一个受开放式进化理论启发的框架来重新审视这些基本概念。文章首先论证了进化动力学可以在个体生命周期内发生，并以此为基础，利用进化见解重新阐释了学习目标和奖励假设。然而，对于智能体这一最根本的问题，作者认为单独的进化范式不足以提供完整解释，并倡导结合生命起源理论中关于生存和复制的热力学原理，以建立对生物系统中智能体和资源受限RL的理解。

> **摘要翻译:** 强化学习（RL）的三个核心原则——关于智能体的定义、学习目标和奖励假设的范围——已被强调为概念修订的关键目标，对理论和应用具有重大影响。我们提出了一个受开放式进化理论启发的框架，以重新审视这三个“教义”。我们重新审视了每个假设并解决了随之提出的相关问题。为了使我们的论点与作为生物学习模型的RL相关，我们首先确定进化动力学可以在个体生命周期内的活体大脑中合理地运作，而不仅仅局限于跨代过程。我们首先重新审视第二个教义，借鉴进化见解来丰富学习的“适应而非搜索”观点。然后，我们讨论了关于奖励假设局限性的第三个教义，使用进化适应度的类比来阐明标量奖励与多目标辩论。在讨论了RL中探索的实际意义之后，我们转向第一个——也可以说是最基本的问题：缺乏智能体的正式解释。我们认为，与其他两个问题不同，单独的进化范式无法解决智能体问题，尽管它指向了一个富有成效的方向。我们倡导整合生命起源理论中的思想，其中生存和复制的热力学为理解生物系统中的智能体和资源受限的强化学习提供了有前景的基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [731] [Efficacy of AI RAG Tools for Complex Information Extraction and Data Annotation Tasks: A Case Study Using Banks Public Disclosures](https://arxiv.org/abs/2507.21360)
> *AI RAG工具在复杂信息提取和数据标注任务中的效率：以银行公开披露文件为例的案例研究*

*Nicholas Botti, Flora Haberkorn, Charlotte Hoopes, Shaun Khan* | **Category: cs.AI, cs.HC, econ.GN, q-fin.EC** | **Updated: 2025-07-28**

**Keywords:** AI RAG, 信息提取, 数据标注, 效率, 银行公开披露

**Comment:** 

> **TL;DR:** AI RAG工具显著加速了复杂信息提取和数据标注任务，并提高了准确性，尤其是在交互式使用条件下。

**AI_Comments:** 这篇论文通过实证研究验证了AI RAG工具在特定复杂信息处理任务中的巨大潜力，特别强调了交互式使用模式的优越性和操作者AI技能的重要性。其创新点在于通过严谨的实验设计量化了效率提升，并识别了影响AI辅助系统表现的人为因素。这对于未来AI工具的设计和部署具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 理解AI检索增强生成（RAG）工具辅助分析师进行信息提取和数据标注任务的有效性，并通过复制一个现有的、具有挑战性的真实世界标注任务来验证。

**Method:** 采用受试者内设计和随机任务分配。复制了一个针对全球系统重要性银行（GSIBs）数千页公开披露文件的复杂多部分标注任务。测试了两种AI使用条件：“天真”AI使用（只接受工具给出的第一个答案）和“交互式”AI使用（分析师可互动并自行判断，必要时跟进额外信息）。与纯人工基线进行比较。

**Result:** 与纯人工相比，AI工具的使用将任务执行速度加快了10倍，并增强了任务准确性，尤其是在交互式条件下。推断到整个任务，这些方法可节省高达268小时。标注员的技能，不仅是主题领域，还包括AI工具的使用，是任务准确性和速度的因素。

**Conclusion:** AI RAG工具能显著提高复杂信息提取和数据标注任务的效率和准确性，交互式使用效果更佳，且标注员对AI工具的熟练度也很重要。

> **ai_Abstract:** 本研究通过一项受试者内设计实验，评估了AI RAG工具在协助分析师执行复杂信息提取和数据标注任务方面的效率。研究复制了针对银行公开披露文件的真实世界标注任务，并比较了“天真”AI使用和“交互式”AI使用两种条件与纯人工基线的表现。结果显示，AI工具（尤其是在交互式模式下）显著提升了任务速度和准确性，并指出标注员对AI工具的熟练度对性能有重要影响。

> **摘要翻译:** 我们利用受试者内设计和随机任务分配来理解使用AI检索增强生成（RAG）工具协助分析师进行信息提取和数据标注任务的有效性。我们复制了一个现有的、具有挑战性的真实世界标注任务，该任务具有复杂的多部分标准，应用于全球系统重要性银行（GSIBs）数千页公开披露文件，这些文件包含异构和不完整的信息内容。我们测试了两种处理条件。首先是“天真”AI使用条件，在此条件下标注员只使用工具，并且必须接受他们得到的第一个答案。其次是“交互式”AI处理条件，在此条件下标注员交互式地使用工具，并在必要时运用他们的判断力来跟进额外信息。与纯人工基线相比，AI工具的使用将任务执行速度加快了10倍，并提高了任务准确性，尤其是在交互式条件下。我们发现，当推断到整个任务时，这些方法与纯人工方法相比，可以节省高达268小时。此外，我们的发现表明，标注员的技能，不仅是主题领域，还包括AI工具的使用，是任务准确性和速度的一个因素。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [736] [Artificial intelligence for sustainable wine industry: AI-driven management in viticulture, wine production and enotourism](https://arxiv.org/abs/2507.21098)
> *人工智能助力可持续葡萄酒产业：葡萄栽培、葡萄酒生产和葡萄酒旅游中的AI驱动管理*

*Marta Sidorkiewicz, Karolina Królikowska, Berenika Dyczek, Edyta Pijet-Migon, Anna Dubel* | **Category: cs.AI, cs.CY, I.2.6; I.2.1; H.4.2** | **Updated: 2025-07-02**

**Keywords:** 人工智能, 可持续发展, AI驱动管理, 葡萄栽培, 葡萄酒生产, 葡萄酒旅游

**Comment:** 6 pages, 4 figures. Accepted for presentation at the 27th European
  Conference on Artificial Intelligence (ECAI 2025), October 19-24, 2025,
  Bologna, Italy

> **TL;DR:** 本研究探讨了人工智能如何在葡萄栽培、葡萄酒生产和葡萄酒旅游中实现智能管理，以增强葡萄酒产业的可持续性和效率，通过对波兰酿酒师的问卷调查和AI方法分析，发现AI能优化资源利用、减少环境影响并改善客户体验，从而促进经济、环境和社会的可持续发展。

**AI_Comments:** 该研究全面探讨了AI在葡萄酒产业全链条（从葡萄栽培到葡萄酒旅游）中的应用，为行业的可持续发展提供了新的视角和解决方案。其创新之处在于将AI技术与具体的行业痛点结合，并提供了实证（问卷调查）和技术分析相结合的方法。研究的局限性可能在于其主要基于波兰酿酒师的调查，结果的普适性可能需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 葡萄酒产业面临环境和经济挑战，需要创新解决方案来优化资源利用、减少环境影响和改善客户参与度。理解AI在可持续酿酒中的潜力对于促进负责任和高效的行业实践至关重要。

**Method:** 研究基于对波兰酿酒师的问卷调查，并结合对适用于葡萄栽培、生产和旅游的AI方法进行综合分析。探讨了关键的AI技术，包括预测分析、机器学习和计算机视觉。

**Result:** 研究结果表明，AI增强了葡萄园监测，优化了灌溉，并简化了生产流程，有助于可持续资源管理。在葡萄酒旅游中，AI驱动的聊天机器人、推荐系统和虚拟品鉴能个性化消费者体验。

**Conclusion:** 该研究强调了AI对经济、环境和社会可持续性的影响，支持当地葡萄酒企业和文化遗产。

> **ai_Abstract:** 本研究旨在探讨人工智能（AI）在提升葡萄酒产业可持续性和效率方面的潜力。通过对波兰酿酒师的问卷调查和对AI方法的综合分析，研究发现AI在葡萄栽培、葡萄酒生产和葡萄酒旅游等多个环节中均能发挥重要作用。具体而言，AI技术如预测分析、机器学习和计算机视觉能够优化葡萄园管理、灌溉、生产流程，并提升葡萄酒旅游中的消费者体验。研究最终强调了AI对葡萄酒产业在经济、环境和社会层面实现可持续发展的积极影响。

> **摘要翻译:** 本研究探讨了人工智能（AI）在提升葡萄酒产业可持续性和效率方面的作用。它专注于葡萄栽培、葡萄酒生产和葡萄酒旅游中的AI驱动智能管理。随着葡萄酒产业面临环境和经济挑战，AI提供了创新解决方案，以优化资源利用、减少环境影响和改善客户参与度。理解AI在可持续酿酒中的潜力对于促进负责任和高效的行业实践至关重要。该研究基于对波兰酿酒师进行的问卷调查，并结合对适用于葡萄栽培、生产和旅游的AI方法进行综合分析。探讨了关键的AI技术，包括预测分析、机器学习和计算机视觉。研究结果表明，AI增强了葡萄园监测，优化了灌溉，并简化了生产流程，有助于可持续资源管理。在葡萄酒旅游中，AI驱动的聊天机器人、推荐系统和虚拟品鉴能个性化消费者体验。该研究强调了AI对经济、环境和社会可持续性的影响，支持当地葡萄酒企业和文化遗产。关键词：人工智能、可持续发展、AI驱动管理、葡萄栽培、葡萄酒生产、葡萄酒旅游、葡萄酒企业、当地社区

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [739] [DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](https://arxiv.org/abs/2507.07426)
> *DrugMCTS：一个结合多智能体、RAG和蒙特卡洛树搜索的药物重定向框架*

*Zerui Yang, Yuwei Wan, Yinqiao Li, Yudai Matsuda, Tong Xie, Linqi Song* | **Category: cs.AI, cs.CE** | **Updated: 2025-07-12**

**Keywords:** 药物重定向, 大型语言模型, 多智能体, RAG, 蒙特卡洛树搜索

**Comment:** 

> **TL;DR:** DrugMCTS是一个结合多智能体、RAG和蒙特卡洛树搜索的框架，用于药物重定向，解决了大型语言模型在科学领域推理的局限性，并显著提高了性能。

**AI_Comments:** DrugMCTS的创新之处在于其结合了多智能体系统、RAG和蒙特卡洛树搜索，为LLM在复杂科学推理（如药物发现）中的应用提供了一种无需大量微调的有效方法。它通过结构化推理和反馈机制，解决了LLM在处理超出预训练知识范围的推理任务时的局限性，对提升LLM在专业领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在药物发现等科学领域展现潜力，但其推理能力受限于预训练知识。传统方法如微调或检索增强生成存在计算开销大或未能充分利用结构化科学数据的局限性。

**Method:** 提出DrugMCTS框架，协同整合RAG（检索增强生成）、多智能体协作和蒙特卡洛树搜索，用于药物重定向。该框架使用五个专门智能体，负责检索和分析分子及蛋白质信息，从而实现结构化和迭代推理。

**Result:** DrugMCTS使Qwen2.5-7B-Instruct的性能超越Deepseek-R1逾20%。在DrugBank和KIBA数据集上的大量实验表明，DrugMCTS与通用LLM和深度学习基线相比，实现了显著更高的召回率和鲁棒性。

**Conclusion:** 研究结果强调了结构化推理、基于智能体的协作和反馈驱动的搜索机制在推进LLM药物发现应用中的重要性。

> **ai_Abstract:** 本文提出了DrugMCTS，一个用于药物重定向的新型框架，旨在克服大型语言模型在科学领域推理的局限性。DrugMCTS结合了检索增强生成（RAG）、多智能体协作和蒙特卡洛树搜索，并利用五个专门智能体进行分子和蛋白质信息分析，实现结构化迭代推理。实验证明，该框架无需特定领域微调即可显著提升LLM性能，并在药物发现任务中展现出更高的召回率和鲁棒性。

> **摘要翻译:** 大型语言模型最近的进展在药物发现等科学领域展现出巨大的潜力。然而，当推理超出预训练期间获得的知识时，它们的有效性仍然受到限制。传统方法，例如微调或检索增强生成，面临着计算开销高或未能充分利用结构化科学数据的局限性。为了克服这些挑战，我们提出了DrugMCTS，一个协同整合RAG、多智能体协作和蒙特卡洛树搜索的新颖框架，用于药物重定向。该框架采用五个专门的智能体，负责检索和分析分子和蛋白质信息，从而实现结构化和迭代推理。无需领域特定的微调，DrugMCTS赋能Qwen2.5-7B-Instruct的性能超越Deepseek-R1逾20%。在DrugBank和KIBA数据集上的大量实验表明，DrugMCTS与通用LLM和深度学习基线相比，实现了显著更高的召回率和鲁棒性。我们的结果强调了结构化推理、基于智能体的协作和反馈驱动的搜索机制在推进LLM药物发现应用中的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [747] [Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline](https://arxiv.org/abs/2507.21886)
> *通过呼吸信号进行高效疼痛识别：一种单交叉注意力Transformer多窗口融合管道*

*Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis* | **Category: cs.AI, cs.LG, eess.SP** | **Updated: 2025-07-30**

**Keywords:** 疼痛识别, 呼吸信号, 交叉注意力Transformer, 多窗口融合, 自动疼痛评估

**Comment:** arXiv admin note: text overlap with arXiv:2507.21881,
  arXiv:2507.21875

> **TL;DR:** 该研究提出了一种基于呼吸信号的单交叉注意力Transformer多窗口融合管道，用于高效疼痛识别。

**AI_Comments:** 该论文的创新点在于将呼吸信号作为疼痛识别的主要输入，并结合了高效的交叉注意力Transformer和多窗口融合技术。其重要性在于提供了一种非侵入性且可能更高效的自动疼痛评估方法，这对于临床决策和患者管理具有潜在价值。研究还强调了紧凑模型在适当优化后也能达到甚至超越大型模型的性能，这对于资源受限的应用场景具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确和一致的疼痛评估对于疼痛患者至关重要，并支持有效管理策略的开发。自动疼痛评估系统能够提供持续监测并支持临床决策，旨在减轻痛苦和预防功能衰退。

**Method:** 该方法引入了一个以呼吸作为输入信号的管道，结合了高效的交叉注意力Transformer和多窗口策略。该研究已提交至第二届下一代疼痛评估多模态感知挑战赛（AI4PAIN）。

**Result:** 广泛的实验表明，呼吸是疼痛评估中一种有价值的生理模态。此外，实验揭示了紧凑高效的模型在适当优化后可以实现强大的性能，通常超越大型模型。所提出的多窗口方法有效捕捉了短期、长期特征以及全局特性，从而增强了模型的表征能力。

**Conclusion:** 呼吸信号是一种有价值的疼痛评估模态，并且通过结合高效的交叉注意力Transformer和多窗口策略，可以构建出紧凑高效的模型，实现强大的疼痛识别性能。

> **ai_Abstract:** 本研究提出了一种用于疼痛识别的创新管道，该管道利用呼吸信号作为输入，并结合了高效的交叉注意力Transformer和多窗口融合策略。实验证明呼吸是疼痛评估的有效生理模态，并且所提出的紧凑模型在性能上表现出色，多窗口方法有效捕捉了不同时间尺度的特征，增强了模型的表示能力。

> **摘要翻译:** 疼痛是一种复杂状况，影响着大部分人口。对于经历疼痛的个体而言，准确和一致的评估至关重要，它支持有效和先进管理策略的开发。自动化疼痛评估系统提供持续监测并支持临床决策，旨在减轻痛苦和预防功能下降。这项研究已提交至“第二届下一代疼痛评估多模态感知大挑战”（AI4PAIN）。所提出的方法引入了一个以呼吸作为输入信号的管道，并结合了高效的交叉注意力Transformer以及多窗口策略。广泛的实验表明，呼吸是一种有价值的疼痛评估生理模态。此外，实验揭示，紧凑高效的模型在适当优化后，可以实现强大的性能，往往超越大型模型。所提出的多窗口方法有效捕捉了短期和长期特征，以及全局特性，从而增强了模型的表征能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [753] [Progressive Homeostatic and Plastic Prompt Tuning for Audio-Visual Multi-Task Incremental Learning](https://arxiv.org/abs/2507.21588)
> *渐进式稳态塑性提示调优用于音视频多任务增量学习*

*Jiong Yin, Liang Li, Jiehua Zhang, Yuhan Gao, Chenggang Yan, Xichun Sheng* | **Category: cs.AI, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 音视频学习, 增量学习, 提示调优, 多任务学习, 灾难性遗忘

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本文提出了一种名为PHP的三阶段提示调优方法，旨在解决音视频多任务增量学习中知识遗忘与新任务学习的平衡问题，并在多任务上取得了SOTA性能。

**AI_Comments:** 该论文的创新点在于提出了一个精巧的三阶段渐进式提示调优框架（PHP），巧妙地结合了任务共享和任务特定的提示策略，以应对音视频多任务增量学习中的灾难性遗忘问题。其分阶段的设计，从跨任务跨模态共享理解到任务特定模态独立细化，展现了对知识平衡和迁移能力的深刻理解。SOTA性能的实现表明了其方法的有效性和实用性，为音视频领域的持续学习提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 音视频多任务增量学习的目标是持续学习多个音视频任务而无需联合训练所有任务。其主要挑战在于如何有效保留旧任务知识，同时利用先前经验促进新任务的学习，避免灾难性遗忘。

**Method:** 本文提出了一种三阶段的渐进式稳态塑性音视频提示（PHP）方法。在浅层阶段，设计了任务共享模态聚合适配器以促进跨任务和跨模态的音视频表示学习。在中间阶段，提出了任务特定模态共享动态生成适配器，构建了针对个体任务且跨模态通用的提示。在深层阶段，引入了任务特定模态独立提示，以进一步细化对每个任务和模态的个体信息理解。通过这三个阶段，PHP实现了在保留任务特定提示的同时，调整共享参数以适应新任务，从而平衡知识共享和特异性。

**Result:** 该方法在四种不同任务（AVE, AVVP, AVS, AVQA）的不同学习顺序下均取得了当前最佳（SOTA）性能。

**Conclusion:** PHP方法通过其独特的三阶段提示调优策略，成功解决了音视频多任务增量学习中知识保留与新任务学习的平衡问题，并在多个音视频任务上实现了当前最优性能，展现了其在持续学习场景下的有效性和鲁棒性。

> **ai_Abstract:** 本文提出了一种名为渐进式稳态塑性音视频提示（PHP）的三阶段方法，旨在解决音视频多任务增量学习中知识遗忘与新任务学习的平衡挑战。PHP通过分层设计，包括任务共享模态聚合适配器、任务特定模态共享动态生成适配器以及任务特定模态独立提示，有效实现了旧知识的保留和新知识的有效学习。该方法在多个音视频任务上取得了当前最佳性能，证明了其在持续学习环境中的有效性。

> **摘要翻译:** 音视频多任务增量学习旨在无需联合训练所有任务的情况下，持续从多个音视频任务中学习。该问题的挑战在于如何保留旧任务知识，同时利用以往经验促进新任务的学习。为了应对这些挑战，我们引入了一种三阶段的渐进式稳态塑性音视频提示（PHP）方法。在浅层阶段，我们设计了任务共享模态聚合适配器，以促进跨任务和跨模态的音视频表示学习，增强任务间的共享理解。在中间阶段，我们提出了任务特定模态共享动态生成适配器，该适配器构建了针对个体任务且跨模态通用的提示，平衡了模型保留知识以对抗遗忘的能力与多任务通用迁移的潜力。在深层阶段，我们引入了任务特定模态独立提示，通过针对每个任务和模态的个体信息，进一步细化理解能力。通过结合这三个阶段，PHP在保留任务特定提示的同时，调整共享参数以适应新任务，从而有效平衡知识共享和特异性。我们的方法在四种不同任务（AVE、AVVP、AVS和AVQA）的不同顺序下取得了SOTA性能。我们的代码可在https://github.com/ENJOY-Yin-jiong/PHP 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [759] [What Does 'Human-Centred AI' Mean?](https://arxiv.org/abs/2507.19960)
> *“以人为中心的AI”意味着什么？*

*Olivia Guest* | **Category: cs.AI, I.2.0; K.2; K.4.0** | **Updated: 2025-07-29**

**Keywords:** 人工智能, 人类中心, 认知劳动, 社会技术关系, 人在回路中

**Comment:** 

> **TL;DR:** 本文认为AI是技术与人类之间执行认知劳动的关系，强调所有AI都涉及人类认知，并提出需要正视“人在回路中”以真正实现以人为中心。

**AI_Comments:** 本文创新性地将AI定义为技术与人类认知劳动的关系，并提出了“取代”、“增强”和“替代”的分类框架，有助于更清晰地理解AI对人类社会的影响。其重要性在于批判了当前对“以人为中心的AI”的模糊理解，强调了认知在AI中的核心作用，对推动AI的伦理和负责任发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 作者旨在澄清“以人为中心的AI”的真正含义，并指出将AI视为独立于人类认知劳动的技术是一种误解，这种误解会阻碍对AI的批判性审视和真正的人类中心化设计。

**Method:** 作者提出将AI视为技术与人类之间的一种关系，其中技术在不同程度上执行人类认知劳动。通过对比技术与认知（如算盘vs心算、闹钟vs叫醒员、相机vs视觉等）的例子来论证。引入了新的定义来分析社会技术关系，将其分为对人类认知劳动的“取代”（有害）、“增强”（有益）和/或“替代”（中性）三种类型。

**Result:** 所有的AI都牵涉到人类认知。模糊AI语境中的认知会导致扭曲、阻碍批判性参与、误导认知科学，并限制我们在AI系统工程中真正以人类为中心的能力。

**Conclusion:** 为了真正地“去神话化”AI，我们必须正视“人在回路中”的现实，承认AI与人类认知的内在联系。

> **ai_Abstract:** 本文探讨了“以人为中心的AI”的真正含义，认为AI应被理解为技术与人类之间的一种关系，其中技术执行人类认知劳动。作者通过具体例子和新颖的分类（取代、增强、替代）来分析这种关系，并强调所有AI都与人类认知紧密相关。文章指出，忽视AI中的认知因素会导致对AI的误解和对人类中心化设计能力的限制，主张必须正视AI中的“人在回路中”的现实。

> **摘要翻译:** 虽然“以人为中心的人工智能（AI）”似乎理所当然地意味着以“人类行为和经验”为中心，但这别无他法。我认为，AI被有效地视为技术与人类之间的一种关系，在这种关系中，人工制品似乎能在或多或少的程度上执行人类的认知劳动。这一点通过将技术与认知并置的例子得以证明，其中包括：算盘对比心算；闹钟对比叫醒员；相机对比视觉；以及血汗工厂对比裁缝。利用新颖的定义和分析，社会技术关系可以被分析为对人类认知劳动的不同类型的：取代（有害）、增强（有益）和/或替代（中性）。最终，所有AI都牵涉到人类认知；无论如何。在AI语境中模糊认知——从时钟到人工神经网络——会导致扭曲，减缓批判性参与，误导认知科学，并确实限制了我们在AI系统工程中真正以人类和人性为中心的能力。要开始去神话化AI，我们必须直视“人在回路中”的现实。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [763] [A Multi-Agent System Enables Versatile Information Extraction from the Chemical Literature](https://arxiv.org/abs/2507.20230)
> *多智能体系统实现化学文献中的通用信息提取*

*Yufan Chen, Ching Ting Leung, Bowen Yu, Jianwei Sun, Yong Huang, Linyan Li, Hao Chen, Hanyu Gao* | **Category: cs.AI, cs.CV, cs.MA** | **Updated: 2025-07-29**

**Keywords:** 多智能体系统, MLLM, 化学信息提取, 反应数据库, 多模态

**Comment:** 

> **TL;DR:** 该研究开发了一种基于多模态大语言模型（MLLM）的多智能体系统，用于从化学文献中自动提取信息，该系统在化学反应图形基准数据集上表现出色，显著超越了现有最佳模型。

**AI_Comments:** 这项工作的创新之处在于将多模态大语言模型（MLLM）与多智能体系统相结合，有效地处理了化学文献中复杂多样的图形和文本信息。其显著超越现有技术水平的F1分数（80.8% vs 35.6%）证明了该方法的强大能力和实用性。该系统为构建高质量化学数据库和加速AI驱动的化学研究提供了关键技术支持，具有重要的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 为了加速AI驱动的化学研究，高质量的化学数据库至关重要。从文献中自动提取化学信息对于构建反应数据库至关重要，但目前受到化学信息多模态和风格多样性的限制。

**Method:** 研究开发了一种基于多模态大语言模型（MLLM）的多智能体系统，用于鲁棒和自动的化学信息提取。该系统利用MLLM强大的推理能力来理解不同化学图形的结构，将提取任务分解为子任务，并协调一组专业智能体，每个智能体结合了MLLM的能力和专用工具的精确领域特定优势，以准确解决问题并将结果整合为统一输出。

**Result:** 该系统在来自文献的复杂多模态化学反应图形基准数据集上取得了80.8%的F1分数，显著超越了之前的最先进模型（F1分数35.6%）。此外，它在关键子任务中也表现出持续改进，包括分子图像识别、反应图像解析、命名实体识别和基于文本的反应提取。

**Conclusion:** 这项工作是实现化学信息自动提取到结构化数据集的关键一步，这将有力推动AI驱动的化学研究。

> **ai_Abstract:** 本研究提出了一种基于多模态大语言模型（MLLM）的多智能体系统，旨在解决化学文献中多模态和多样化风格的化学信息自动提取难题。该系统通过分解任务和协调结合MLLM与专业工具的智能体，实现了对复杂化学图形的理解和信息整合。实验结果显示，该系统在化学反应图形提取任务中取得了80.8%的F1分数，远超现有最佳模型（35.6%），并在多项子任务上展现出显著提升，为AI驱动的化学研究提供了重要的自动化信息提取工具。

> **摘要翻译:** 为了充分加速AI驱动的化学研究，高质量的化学数据库是基石。从文献中自动提取化学信息对于构建反应数据库至关重要，但目前受到化学信息多模态和风格多样性的限制。在这项工作中，我们开发了一种基于多模态大语言模型（MLLM）的多智能体系统，用于鲁棒和自动的化学信息提取。它利用MLLM强大的推理能力来理解不同化学图形的结构，将提取任务分解为子任务，并协调一组专业智能体，每个智能体结合了MLLM的能力和专用工具的精确领域特定优势，以准确解决问题并将结果整合为统一输出。我们的系统在来自文献的复杂多模态化学反应图形基准数据集上取得了80.8%的F1分数，显著超越了之前的最先进模型（F1分数35.6%）。此外，它在关键子任务中也表现出持续改进，包括分子图像识别、反应图像解析、命名实体识别和基于文本的反应提取。这项工作是实现化学信息自动提取到结构化数据集的关键一步，这将有力推动AI驱动的化学研究。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [766] [Multi-Representation Diagrams for Pain Recognition: Integrating Various Electrodermal Activity Signals into a Single Image](https://arxiv.org/abs/2507.21881)
> *用于疼痛识别的多表示图：将各种皮肤电活动信号整合到单个图像中*

*Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis* | **Category: cs.AI** | **Updated: 2025-07-30**

**Keywords:** 疼痛识别, 皮肤电活动, 多表示图, 疼痛评估, 信号整合

**Comment:** arXiv admin note: text overlap with arXiv:2507.21875

> **TL;DR:** 该研究提出了一种利用皮肤电活动（EDA）信号的多表示图方法，用于自动疼痛评估，并通过将多种信号表示整合到单个图像中，实现了与传统融合方法相当甚至更优的性能。

**AI_Comments:** 该论文的创新点在于提出了一种将多种皮肤电活动信号表示整合到单一图像中的方法，这提供了一种新颖且可能更有效的信号融合策略。其在自动疼痛评估领域的应用具有重要意义，有助于提升疼痛监测的客观性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 疼痛影响着大量人群，可靠且持续的疼痛评估对于患者和管理策略的开发至关重要。自动疼痛评估系统通过整合生理信号，可以提供客观、准确的洞察，从而进行持续监测、辅助临床决策并减轻痛苦。

**Method:** 该方法引入了一个管道，利用皮肤电活动（EDA）信号作为输入模式。它创建信号的多种表示并将其可视化为波形，然后将这些波形共同可视化在一个单一的多表示图中。

**Result:** 通过包含各种处理和滤波技术以及多种表示组合的广泛实验表明，所提出的方法是有效的。它始终能产生与传统融合方法相当的结果，在某些情况下甚至更优，证明了它作为集成不同信号表示或模式的稳健替代方案。

**Conclusion:** 所提出的多表示图方法是集成不同信号表示或模式的稳健替代方案，在疼痛识别方面表现出与传统融合方法相当或更优的性能。

> **ai_Abstract:** 本研究提出了一种用于疼痛识别的新方法，通过将皮肤电活动（EDA）信号的多种表示整合到一个单一的多表示图中。该方法旨在提供客观、准确的疼痛评估，并已提交给AI4PAIN挑战赛。实验结果表明，该方法在性能上与传统融合方法相当，甚至在某些情况下表现更优，证明了其在集成不同生理信号表示方面的鲁棒性。

> **摘要翻译:** 疼痛是一种多方面现象，影响着相当一部分人口。可靠且持续的评估有益于经历疼痛的人群，并支撑着有效和先进管理策略的开发。自动疼痛评估系统提供持续监测，为临床决策提供信息，旨在减轻痛苦并防止功能下降。通过整合生理信号，这些系统能对个体状况提供客观、准确的洞察。本研究已提交给《第二届下一代疼痛评估多模态感知大挑战（AI4PAIN）》。所提出的方法引入了一个利用皮肤电活动信号作为输入模式的管道。信号的多种表示被创建并可视化为波形，它们被共同可视化在一个单一的多表示图中。包含各种处理和滤波技术以及多种表示组合的广泛实验，证明了所提出方法的有效性。它始终能产生与传统融合方法相当，在某些情况下甚至更优的结果，从而确立了其作为集成不同信号表示或模式的稳健替代方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [772] [Leveraging Generative AI to Enhance Synthea Module Development](https://arxiv.org/abs/2507.21123)
> *利用生成式AI增强Synthea模块开发*

*Mark A. Kramer, Aanchal Mathur, Caroline E. Adams, Jason A. Walonoski* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-18**

**Keywords:** 大型语言模型, Synthea, 合成健康数据, 模块开发, 渐进式优化

**Comment:** Title: Leveraging Generative AI to Enhance Synthea Module Development
  Word Count: [Approximately 12,000 words] Figures: 3 Tables: 3 Supplementary
  Material: Extensive appendices with prompts and disease profiles

> **TL;DR:** 本文探讨了如何利用大型语言模型（LLMs）辅助Synthea疾病模块的开发，以期缩短开发时间、降低专业要求、增加模型多样性并提高数据质量。

**AI_Comments:** 这篇论文的创新点在于探索了将生成式AI（特别是LLMs）应用于合成健康数据生成器Synthea的模块开发，这为加速医疗数据模拟、降低开发门槛提供了新思路。其提出的“渐进式优化”方法也体现了对LLM生成内容质量控制的思考。然而，论文也坦诚地指出了LLM应用的局限性，如对人工监督和严格验证的需求，这对于确保合成数据的临床准确性和可靠性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有Synthea模块开发可能存在开发时间长、需要专业知识等问题。本文旨在通过引入LLMs来解决这些问题，从而减少开发时间、降低所需专业知识、扩大模型多样性并提高合成患者数据的整体质量。

**Method:** 作者展示了LLMs支持Synthea模块创建的四种方式：生成疾病配置文件、从疾病配置文件生成疾病模块、评估现有Synthea模块以及改进现有模块。他们引入了“渐进式优化”的概念，即通过检查LLM生成的模块的语法正确性和临床准确性进行迭代评估，然后利用这些信息修改模块。

**Result:** LLMs能够以四种方式支持Synthea模块创建：生成疾病配置文件、从疾病配置文件生成疾病模块、评估现有Synthea模块和改进现有模块。研究提出了渐进式优化方法来迭代改进LLM生成的模块。

**Conclusion:** LLMs在此背景下的应用前景广阔，但同时也存在挑战和局限性，例如需要人工监督、严格的测试和验证以及LLM生成内容可能不准确。论文最后提出了未来研究和开发的建议，以充分实现LLM辅助合成数据创建的潜力。

> **ai_Abstract:** 本文研究了利用大型语言模型（LLMs）辅助开源合成健康数据生成器Synthea的疾病模块开发。研究展示了LLMs在生成疾病配置文件、创建和改进模块以及评估现有模块方面的潜力，旨在缩短开发时间、降低专业门槛并提升数据质量。论文提出了“渐进式优化”方法，并通过迭代评估和修正来提高LLM生成内容的准确性。同时，文章也指出了LLM应用中的挑战，如对人工监督、严格测试和内容准确性的需求，并对未来研究提出了建议。

> **摘要翻译:** 本文探讨了利用大型语言模型（LLMs）辅助Synthea（一个开源的合成健康数据生成器）新疾病模块的开发。将LLMs整合到模块开发过程中，有望缩短开发时间、降低所需专业知识、扩大模型多样性并提高合成患者数据的整体质量。我们展示了LLMs支持Synthea模块创建的四种方式：生成疾病配置文件、从疾病配置文件生成疾病模块、评估现有Synthea模块以及改进现有模块。我们引入了渐进式优化的概念，这涉及通过检查LLM生成模块的语法正确性和临床准确性来迭代评估，然后利用这些信息修改模块。虽然LLMs在此背景下的使用前景广阔，但我们也承认其挑战和局限性，例如需要人工监督、严格的测试和验证的重要性，以及LLM生成内容可能存在不准确性。论文最后提出了未来研究和开发的建议，以充分实现LLM辅助合成数据创建的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [800] [Measuring and Analyzing Intelligence via Contextual Uncertainty in Large Language Models using Information-Theoretic Metrics](https://arxiv.org/abs/2507.21129)
> *使用信息论度量通过大型语言模型中的上下文不确定性来衡量和分析智能*

*Jae Wan Shim* | **Category: cs.AI** | **Updated: 2025-07-21**

**Keywords:** 大型语言模型, 上下文不确定性, 信息论, 熵衰减曲线, 认知档案

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的、与任务无关的方法，利用“熵衰减曲线”和“信息增益跨度”来分析大型语言模型（LLM）如何处理信息以及其内在智能，超越了仅仅衡量模型能做什么的传统方法。

**AI_Comments:** 这篇论文提供了一种创新性的方法来理解LLM智能的“如何”，而不仅仅是“是什么”。熵衰减曲线和IGS指数的引入为内在分析提供了量化工具，这对于推进AI的可解释性和发展至关重要。其与任务无关的特性是一个显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLM）的能力已得到广泛验证，但其产生这些结果的内部机制仍是科学界深入探究的焦点。现有指标主要衡量模型“能做什么”，而本文旨在深入探究模型“如何”处理信息，以理解其内在运作。

**Method:** 本文引入了一种新颖的、与任务无关的方法来探测LLM的动态，即为任何给定模型创建量化的“认知档案”。该档案的核心是“熵衰减曲线”，它描绘了模型标准化预测不确定性随上下文长度的变化。该方法应用于多种最先进的LLM，跨越不同文本。此外，还引入了“信息增益跨度（IGS）指数”来总结衰减轨迹的理想程度。

**Result:** 研究揭示了独特且一致的认知档案，这些档案对模型规模和文本复杂性均敏感。

**Conclusion:** 这项工作提供了一个新的、有原则的视角，用于分析和比较人工智能的内在操作动态。

> **ai_Abstract:** 本文提出了一种新颖的、与任务无关的方法来分析大型语言模型（LLM）的内部信息处理机制，超越了传统的性能衡量标准。它引入了“熵衰减曲线”来可视化模型预测不确定性如何随上下文长度变化，从而形成一个“认知档案”。此外，还提出了“信息增益跨度（IGS）指数”来量化这种衰减的理想程度。将此方法应用于各种LLM后，揭示了对模型规模和文本复杂性敏感的一致认知档案，为理解人工智能的操作动态提供了一个新框架。

> **摘要翻译:** 大型语言模型（LLMs）的卓越能力已在特定任务基准上得到广泛记录，然而，产生这些结果的内部机制仍是科学界深入探究的主题。本文通过超越衡量模型“能做什么”的指标，转向表征模型“如何”处理信息的方法，为这项探究做出了贡献。我们引入了一种新颖的、与任务无关的方法来探究这些动态，即为任何给定模型创建量化的“认知档案”。该档案以“熵衰减曲线”为核心，该曲线描绘了模型标准化预测不确定性如何随上下文长度的变化而变化。我们将此方法应用于多种最先进的LLM，跨越不同的文本，揭示了独特且一致的认知档案，这些档案对模型规模和文本复杂性均敏感。我们还引入了信息增益跨度（IGS）指数来总结衰减轨迹的理想程度。因此，这项工作为分析和比较人工智能的内在操作动态提供了一个新的、有原则的视角。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [801] [Optimizing Multi-Tier Supply Chain Ordering with LNN+XGBoost: Mitigating the Bullwhip Effect](https://arxiv.org/abs/2507.21383)
> *使用LNN+XGBoost优化多层供应链订单：缓解牛鞭效应*

*Chunan Tong* | **Category: cs.AI** | **Updated: 2025-07-28**

**Keywords:** 供应链优化, 牛鞭效应, 液态神经网络, XGBoost, 混合模型

**Comment:** 

> **TL;DR:** 本研究提出一种结合液态神经网络（LNN）和XGBoost的混合模型，旨在优化多层供应链的订单策略，以缓解牛鞭效应并提高累积利润。

**AI_Comments:** 本文的创新点在于将液态神经网络（LNN）与XGBoost相结合，以解决供应链管理中的牛鞭效应问题。LNN的低计算成本和适应性使其在实时决策和边缘计算方面具有优势，而XGBoost则提供了强大的全局优化能力。这种混合模型有望在提高供应链效率和鲁棒性方面发挥重要作用，特别是在动态和复杂的市场环境下。

<details>
  <summary>Details</summary>

**Motivation:** 供应链管理面临需求波动、库存不平衡和牛鞭效应导致的订单变异性放大等挑战。传统方法难以应对动态市场，现有机器学习技术（如LSTM、XGBoost）存在计算复杂性、训练效率低或时间序列建模限制。液态神经网络（LNN）虽有潜力但在供应链优化中应用不足。

**Method:** 本研究引入了一种混合LNN和XGBoost模型，通过利用LNN的动态特征提取能力和XGBoost的全局优化能力，来优化多层供应链中的订单策略。

**Result:** 该模型旨在缓解牛鞭效应并提高累积利润。研究调查了混合框架内局部和全局协同作用如何解决供应链管理中适应性和效率的双重需求。

**Conclusion:** 所提出的混合LNN和XGBoost方法填补了现有方法中的关键空白，为动态高效的供应链管理提供了一种创新解决方案。

> **ai_Abstract:** 本文针对供应链管理中牛鞭效应等挑战，提出一种结合液态神经网络（LNN）和XGBoost的混合模型。该模型旨在通过LNN的动态特征提取和XGBoost的全局优化能力，优化多层供应链的订单策略，从而缓解牛鞭效应并提升整体盈利能力。该方法填补了现有技术空白，为动态高效的供应链管理提供了创新途径。

> **摘要翻译:** 供应链管理面临重大挑战，包括需求波动、库存不平衡以及由于牛鞭效应导致的放大上游订单变异性。简单移动平均等传统方法难以应对动态市场条件。LSTM、强化学习和XGBoost等新兴机器学习技术提供了潜在解决方案，但受限于计算复杂性、训练效率低下或时间序列建模的限制。液态神经网络受动态生物系统启发，因其适应性强、计算成本低和对噪声鲁棒性高而成为一个有前景的替代方案，使其适用于实时决策和边缘计算。尽管它们在自动驾驶汽车和医疗监控等应用中取得了成功，但其在供应链优化中的潜力仍未得到充分探索。本研究引入了一种混合LNN和XGBoost模型，以优化多层供应链中的订单策略。通过利用LNN的动态特征提取能力和XGBoost的全局优化能力，该模型旨在缓解牛鞭效应并提高累积利润。该研究调查了混合框架内局部和全局协同作用如何解决供应链管理中适应性和效率的双重需求。所提出的方法填补了现有方法中的关键空白，为动态高效的供应链管理提供了一种创新解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [809] [Exploring the Link Between Bayesian Inference and Embodied Intelligence: Toward Open Physical-World Embodied AI Systems](https://arxiv.org/abs/2507.21589)
> *探索贝叶斯推理与具身智能之间的联系：迈向开放物理世界的具身AI系统*

*Bin Liu* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 贝叶斯推理, 具身智能, 开放物理世界, 搜索, 学习

**Comment:** 16 pages

> **TL;DR:** 本文探讨了贝叶斯推理与具身智能的深层概念联系，分析了贝叶斯方法在现代具身智能系统中应用不足的原因，并强调了其在构建开放物理世界具身AI系统中的潜力。

**AI_Comments:** 该论文富有洞察力地指出了当前具身智能系统在开放物理世界应用中的局限性，并提出了贝叶斯推理作为解决这一问题的潜在途径。其创新之处在于重新审视了贝贝斯方法在具身智能中的作用，并结合“苦涩的教训”框架进行分析。这为未来具身AI系统的发展指明了一个重要方向，即如何利用概率推理处理不确定性，从而实现更强大的适应性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管贝叶斯统计与具身智能之间存在深刻的概念联系，但贝叶斯原理在当今的具身智能系统中并未得到广泛或明确的应用。此外，当前的具身智能系统主要局限于封闭的物理世界环境。本文旨在探讨这种差距，并揭示贝叶斯方法在构建真正开放物理世界具身智能系统中的潜力。

**Method:** 作者通过“搜索”和“学习”这两个现代AI的核心主题，审视了贝叶斯方法和当代具身智能方法。

**Result:** 分析揭示了贝叶斯推理未能在现代具身智能发展中发挥核心作用的原因，并指出当前具身智能系统仍主要局限于封闭的物理世界环境。

**Conclusion:** 贝叶斯方法有望在将具身智能系统扩展到真正的开放物理世界方面发挥关键作用。

> **ai_Abstract:** 本文探讨了贝叶斯推理与具身智能之间的深层联系，指出具身智能的认知过程可视为贝叶斯推理。尽管概念上高度相关，但贝叶斯方法在当前具身智能系统中应用不足。作者通过分析搜索和学习两个核心主题，解释了这种差距，并强调了贝叶斯方法在推动具身智能系统从封闭环境走向开放物理世界中的巨大潜力。

> **摘要翻译:** 具身智能认为，认知能力从根本上产生于代理与其环境的实时感觉运动交互，并受其塑造。这种自适应行为本质上需要在不确定性下进行持续推理。贝叶斯统计提供了一个原则性的概率框架来解决这一挑战，通过将知识表示为概率分布，并根据新证据更新信念。具身智能的核心计算过程——包括感知、行动选择、学习，甚至更高层次的认知——都可以被有效地理解和建模为贝叶斯推理的形式。尽管贝叶斯统计与具身智能之间存在深刻的概念联系，但贝叶斯原理在当今的具身智能系统中并未得到广泛或明确的应用。在这项工作中，我们通过两个基本视角：搜索和学习——现代AI的两个核心主题，正如Rich Sutton颇具影响力的文章“The Bitter Lesson”中所强调的那样——审视了贝叶斯和当代具身智能方法。这项分析揭示了为什么贝叶斯推理在现代具身智能的发展中没有发挥核心作用。同时，它揭示了当前具身智能系统在很大程度上仍然局限于封闭的物理世界环境，并强调了贝叶斯方法在将这些系统扩展到真正开放物理世界的具身智能方面的潜在关键作用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [824] [Libra: Large Chinese-based Safeguard for AI Content](https://arxiv.org/abs/2507.21929)
> *Libra：面向AI内容的中文大型安全防护系统*

*Ziyang Chen, Huimu Yu, Xing Wu, Dongqin Liu, Songlin Hu* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 安全防护, 中文内容, 数据效率, 安全评估基准

**Comment:** 

> **TL;DR:** 提出Libra-Guard，一个用于中文LLM的安全防护系统，采用两阶段训练并引入Libra-Test基准进行评估，表现优于现有模型。

**AI_Comments:** 这项工作通过提出Libra-Guard安全防护系统和Libra-Test评估基准，为中文大型语言模型的安全治理提供了创新且全面的解决方案。其两阶段训练方法有效提升了数据效率，并减少了对人工标注的依赖，是其重要创新点。Libra-Test作为首个专门针对中文内容的安全性评估基准，填补了该领域的空白，对于推动中文AI系统的安全发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在文本理解和生成方面表现出色，但在高风险应用中引发严重的安全和伦理问题，因此需要缓解这些风险。

**Method:** 提出了Libra-Guard安全防护系统，采用两阶段课程训练流程，首先在合成样本上进行防护预训练，然后用高质量真实数据进行微调，显著减少对人工标注的依赖。同时，引入了Libra-Test，首个专门用于评估中文内容安全防护系统有效性的基准，涵盖七种关键危害场景，包含5700多个由领域专家标注的样本。

**Result:** 实验表明，Libra-Guard的准确率达到86.79%，优于Qwen2.5-14B-Instruct (74.33%) 和 ShieldLM-Qwen-14B-Chat (65.69%)，并接近Claude-3.5-Sonnet和GPT-4o等闭源模型。

**Conclusion:** 这些贡献为推进中文LLM的安全治理建立了一个强大的框架，代表着朝着开发更安全、更可靠的中文AI系统迈出了试探性的一步。

> **ai_Abstract:** 本文介绍了Libra-Guard，一个针对中文大型语言模型（LLM）的安全防护系统，旨在解决LLM在应用中存在的安全和伦理问题。该系统采用两阶段课程训练方法，结合合成数据预训练和真实数据微调，以提高效率并减少人工标注依赖。为评估其效果，研究还发布了Libra-Test，首个中文内容安全评估基准。实验结果显示，Libra-Guard在准确率上显著优于现有开源模型，并接近顶尖闭源模型，为中文LLM的安全治理提供了强有力的框架。

> **摘要翻译:** 大型语言模型（LLMs）在文本理解和生成方面表现出色，但在高风险应用中引发严重的安全和伦理问题。为了缓解这些风险，我们提出了Libra-Guard，一个旨在增强中文LLM安全性的尖端防护系统。Libra-Guard利用两阶段课程训练流程，通过在合成样本上进行防护预训练，随后在高质量真实数据上进行微调，从而提高数据效率，显著减少对人工标注的依赖。为了进行严格的安全评估，我们还引入了Libra-Test，这是首个专门用于评估中文内容防护系统有效性的基准。它涵盖了七个关键危害场景，并包含5700多个由领域专家标注的样本。实验表明，Libra-Guard的准确率达到86.79%，优于Qwen2.5-14B-Instruct (74.33%) 和 ShieldLM-Qwen-14B-Chat (65.69%)，并接近Claude-3.5-Sonnet和GPT-4o等闭源模型。这些贡献为推进中文LLM的安全治理建立了一个强大的框架，代表着朝着开发更安全、更可靠的中文AI系统迈出了一步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [827] [INTEGRALBENCH: Benchmarking LLMs with Definite Integral Problems](https://arxiv.org/abs/2507.21130)
> *INTEGRALBENCH：使用定积分问题评估大型语言模型*

*Bintao Tang, Xin Yang, Yuhao Wang, Zixuan Qiu, Zimo Ji, Wenyuan Jiang* | **Category: cs.AI** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, 定积分, 基准测试, 数学推理, 性能评估

**Comment:** 19 pages, 5 figures

> **TL;DR:** INTEGRALBENCH是一个新的基准测试，用于评估大型语言模型（LLM）在定积分问题上的表现，揭示了显著的性能差距。

**AI_Comments:** 这项工作通过创建一个专门针对定积分的基准测试，填补了LLM在特定数学推理能力评估方面的空白，对于推动LLM在复杂数学问题解决上的发展具有重要意义。其提供符号和数值真值解以及难度注释的特点，使得评估更加细致和全面。

<details>
  <summary>Details</summary>

**Motivation:** 为了推进自动化数学推理，需要一个专门针对定积分计算的严格评估框架。

**Method:** 提出了INTEGRALBENCH，一个专注于定积分问题的基准测试，提供符号和数值真值解以及手动难度注释。评估了九个最先进的LLM。

**Result:** 揭示了显著的性能差距，并且问题难度与模型准确性之间存在强相关性，为该挑战性领域建立了基线指标。

**Conclusion:** INTEGRALBENCH旨在通过提供专门针对定积分计算的严格评估框架来推进自动化数学推理。

> **ai_Abstract:** 该论文介绍了INTEGRALBENCH，一个专门用于评估大型语言模型在定积分问题上的性能基准。该基准提供符号和数值的真值解以及难度注释。对九个LLM的评估显示，模型在处理定积分问题时存在显著的性能差异，且问题难度与模型准确性密切相关。INTEGRALBENCH旨在通过提供一个严格的评估框架来促进自动化数学推理的发展。

> **摘要翻译:** 我们提出了INTEGRALBENCH，这是一个专门设计用于评估大型语言模型（LLM）在定积分问题上表现的基准测试。INTEGRALBENCH提供符号和数值的真值解，并附有手动难度注释。我们对九个最先进的LLM的评估揭示了显著的性能差距，以及问题难度与模型准确性之间的强相关性，为这个具有挑战性的领域建立了基线指标。INTEGRALBENCH旨在通过提供专门针对定积分计算的严格评估框架来推进自动化数学推理。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [863] [NPO: Learning Alignment and Meta-Alignment through Structured Human Feedback](https://arxiv.org/abs/2507.21131)
> *NPO：通过结构化人类反馈学习对齐和元对齐*

*Madhava Gaikwad, Ashwini Ramchandra Doke* | **Category: cs.AI, 68T05, H.5.1; I.2.6; C.4** | **Updated: 2025-07-22**

**Keywords:** 对齐学习, 元对齐, 结构化反馈, 人机协作系统, 对齐损失

**Comment:** 20 pages

> **TL;DR:** NPO是一个新的学习框架，通过结构化人类反馈来衡量和减少对齐损失和元对齐，从而在人机协作系统中实现持续对齐监控。

**AI_Comments:** 这篇论文的创新点在于其提出了可测量、可监督和可减少的对齐损失概念，并引入了“元对齐”这一新颖的度量，强调了对监控过程本身的保真度。NPO的架构提供了一种将理论对齐保证与实际部署中的可靠性相结合的实用方法，对于需要持续适应人类反馈的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法将对齐视为静态或事后属性，无法有效处理人机协作决策系统中的反馈驱动适应。本文旨在提供一个可测量、可监督和可减少的对齐损失框架，并引入元对齐概念，以解决这一局限性。

**Method:** NPO引入了可测量的对齐损失形式化，并通过结构化反馈（包括“喜欢”、覆盖和弃权）使其可监督和可减少。它还提出了元对齐概念，并展示其可通过阈值保真度还原为主要对齐。该框架包含一个可扩展的操作循环，涉及场景评分、阈值调整、策略验证和结构化反馈摄取。

**Result:** 在随机反馈下，NPO展示了对齐损失和监控保真度都呈加性收敛的正式结果。在超大规模部署环境中，NPO经验性地证明了可衡量的价值。模拟和消融研究进一步阐明了理论原理。

**Conclusion:** NPO提供了一种紧凑、可检查的架构，用于持续对齐监控，有助于弥合理论对齐保证与动态环境中的实际可靠性之间的鸿沟。

> **ai_Abstract:** NPO是一个用于人机协作决策系统的对齐感知学习框架，通过形式化和减少可测量的对齐损失以及引入元对齐概念，解决了现有方法中对齐的静态处理问题。该框架利用结构化人类反馈，实现了对齐损失和监控保真度的收敛，并在实际超大规模部署中展现了显著价值，从而提供了一个持续对齐监控的可靠架构。

> **摘要翻译:** 我们提出了NPO，一个对齐感知的学习框架，它将人机协作决策系统中的反馈驱动适应操作化。与将对齐视为静态或事后属性的现有方法不同，NPO引入了一种对齐损失的形式化，这种损失在结构化反馈下是可测量、可监督和可减少的。同时，我们提出元对齐作为控制再训练或覆盖触发的监控过程的保真度，并表明它可以通过阈值保真度正式地还原为主要对齐。我们的实现涵盖了一个可扩展的操作循环，包括场景评分、阈值调整、策略验证和结构化反馈摄取，包括“喜欢”、覆盖和弃权。我们提供了随机反馈下的正式收敛结果，并表明对齐损失和监控保真度都呈加性收敛。从经验上看，NPO在超大规模部署环境中展示了可衡量的价值。基于模拟的工件和消融研究进一步阐明了实际的理论原理。总而言之，NPO提供了一个紧凑、可检查的架构，用于持续对齐监控，有助于弥合理论对齐保证与动态环境中的实际可靠性之间的鸿沟。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [865] [StaffPro: an LLM Agent for Joint Staffing and Profiling](https://arxiv.org/abs/2507.21636)
> *StaffPro：一个用于联合人员配置和画像的LLM智能体*

*Alessio Maritan* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** LLM智能体, 人员配置, 员工画像, 劳动力管理, 人机反馈

**Comment:** 

> **TL;DR:** StaffPro是一个LLM智能体，通过建立人机反馈循环，联合解决人员配置和员工画像问题，实现终身员工画像和优化人员配置性能。

**AI_Comments:** StaffPro的创新之处在于其将LLM智能体应用于人员配置和员工画像这两个紧密耦合的劳动力管理核心问题，并提出了一个联合解决的框架。其允许使用自然语言表达优化目标、接受文本任务描述以及建立持续人机反馈循环的设计，大大增强了系统的灵活性、用户友好性和适应性。特别是通过分析人类反馈进行“终身员工画像”的机制，使其能够随着时间推移不断优化性能，体现了重要的人本主义设计理念。这为自动化人员管理提供了一个更智能、更人性化的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 在大语言模型（LLM）智能体表现出卓越的推理和决策能力背景下，本研究旨在利用它们解决劳动力管理中两个紧密交织的挑战：人员配置（任务分配和调度，可能需要团队组建）和员工画像（从非结构化数据中持续估计员工的技能、偏好及其他潜在属性）。

**Method:** 本研究将人员配置和员工画像问题置于一个正式的数学框架中，该框架将调度决策与潜在特征估计联系起来。研究引入了StaffPro，一个联合解决这两个问题的LLM智能体。StaffPro允许使用自然语言表达优化目标，接受文本任务描述，并提供高度灵活性。它通过建立持续的人机反馈循环直接与人类交互，通过分析人类反馈持续估计员工的潜在特征，实现终身员工画像。

**Result:** 一个咨询公司模拟示例表明，StaffPro成功估计了员工属性并生成了高质量的调度。

**Conclusion:** StaffPro凭借其创新设计，为自动化人员管理提供了一个稳健、可解释且以人为中心的解决方案。

> **ai_Abstract:** StaffPro是一个创新的LLM智能体，旨在联合解决劳动力管理中的人员配置和员工画像问题。它将调度决策与潜在特征估计相结合，允许通过自然语言表达优化目标，并接受文本任务描述。StaffPro通过持续的人机反馈循环与用户交互，从而实现对员工潜在特征的终身估计和优化的人员配置性能。模拟结果验证了其在估计员工属性和生成高质量调度方面的有效性，提供了一个稳健、可解释且以人为中心的自动化人员管理方案。

> **摘要翻译:** 大型语言模型（LLM）智能体将预训练的LLM与模块化算法组件相结合，并已展现出卓越的推理和决策能力。在这项工作中，我们研究了它们在劳动力管理中两个紧密交织的挑战中的应用：人员配置，即任务向工人的分配和调度，这可能需要团队组建；以及画像，即从非结构化数据中持续估计工人的技能、偏好和其他潜在属性。我们将这些问题置于一个正式的数学框架中，该框架将调度决策与潜在特征估计联系起来，并引入了StaffPro，一个联合解决人员配置和画像的LLM智能体。与现有的人员配置解决方案不同，StaffPro允许使用自然语言表达优化目标，接受文本任务描述并提供高度灵活性。StaffPro通过建立持续的人机反馈循环直接与人类交互，确保自然直观的使用。通过分析人类反馈，我们的智能体持续估计工人的潜在特征，实现了终身工人画像并确保了随时间推移的最佳人员配置性能。一个咨询公司模拟示例表明，StaffPro成功估计了工人的属性并生成了高质量的调度。凭借其创新设计，StaffPro为自动化人员管理提供了一个稳健、可解释且以人为中心的解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [871] [Teaching Language Models To Gather Information Proactively](https://arxiv.org/abs/2507.21389)
> *教会语言模型主动收集信息*

*Tenghao Huang, Sihao Chen, Muhao Chen, Jonathan May, Longqi Yang, Mengting Wan, Pei Zhou* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-28**

**Keywords:** 主动信息收集, 大型语言模型, 强化微调, 协作式AI, 问题生成

**Comment:** 

> **TL;DR:** 当前大型语言模型在处理不完整提示时表现不佳。本文引入了一种新的任务范式和强化微调策略，旨在训练语言模型主动提问以获取缺失信息，显著提升其协作能力。

**AI_Comments:** 这项工作具有创新性，它将大型语言模型从被动响应者转变为主动信息收集者，这对于解决复杂问题至关重要。特别是，奖励引出“隐性”用户知识的强化微调策略，对于提升模型在真实世界场景中的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLMs）在面对不完整或未充分说明的提示时，往往表现被动或提供狭窄的澄清，未能主动收集解决高质量问题所需的关键缺失信息，这限制了它们作为协作伙伴的能力。

**Method:** 本文引入了一种新的任务范式：主动信息收集，要求大型语言模型识别提供上下文中的空白并策略性地通过有针对性的问题引导出隐性用户知识。为系统研究和训练此能力，设计了一个可扩展的框架，生成部分指定、真实世界的任务，通过掩盖关键信息来模拟真实的模糊性。核心创新是一种强化微调策略，奖励那些能引出真正新的、隐性用户信息的提问。

**Result:** 实验表明，本文训练的Qwen-2.5-7B模型在自动评估指标上比o3-mini显著高出18%。更重要的是，人工评估显示，本文模型生成的澄清问题和最终大纲分别受到人类标注者42%和28%的青睐。

**Conclusion:** 这些结果共同强调了主动澄清在将大型语言模型从被动文本生成器提升为真正协作的思考伙伴方面的价值。

> **ai_Abstract:** 本文旨在解决当前大型语言模型（LLMs）在面对不完整提示时缺乏主动获取信息能力的问题。研究引入了一种名为“主动信息收集”的新任务范式，旨在训练LLMs识别信息空白并通过提问获取隐性用户知识。为此，论文设计了一个可扩展的框架来模拟真实世界的模糊任务，并提出了一种创新的强化微调策略，奖励那些能有效引出新、隐性信息的提问。实验结果表明，该方法训练的模型在自动和人工评估中均显著优于现有模型，证明了主动澄清对于提升LLMs协作能力的重要性。

> **摘要翻译:** 大型语言模型（LLMs）正日益被期望作为协作伙伴发挥作用，通过来回对话解决复杂、模糊的问题。然而，当前的LLMs在现实世界环境中常常受挫，当面临不完整或未充分说明的提示时，会默认为被动响应或狭窄的澄清，未能主动收集对于高质量解决方案至关重要的缺失信息。在这项工作中，我们引入了一种新的任务范式：主动信息收集，其中LLMs必须识别所提供上下文中的空白并通过有针对性的问题策略性地引出隐性用户知识。为了系统地研究和训练这种能力，我们设计了一个可扩展的框架，该框架生成部分指定、真实世界的任务，掩盖关键信息并模拟真实的模糊性。在此设置中，我们的核心创新是一种强化微调策略，该策略奖励那些能够引出真正新的、隐性用户信息——例如隐藏的领域专业知识或细粒度要求——的提问，这些信息否则将无法被表达。实验表明，我们训练的Qwen-2.5-7B模型在自动评估指标上比o3-mini显著高出18%。更重要的是，人工评估显示，我们模型生成的澄清问题和最终大纲分别受到人类标注者42%和28%的青睐。总而言之，这些结果突出了主动澄清在将LLMs从被动文本生成器提升为真正协作的思考伙伴方面的价值。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [880] [Thou Shalt Not Prompt: Zero-Shot Human Activity Recognition in Smart Homes via Language Modeling of Sensor Data & Activities](https://arxiv.org/abs/2507.21964)
> *汝不应提示：通过传感器数据和活动的语言建模在智能家居中进行零样本人类活动识别*

*Sourish Gunesh Dhekane, Thomas Ploetz* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 零样本人类活动识别, 智能家居, 语言建模, 传感器数据, 无提示

**Comment:** 

> **TL;DR:** 本文提出了一种无需提示大型语言模型（LLMs）的零样本智能家居人类活动识别（HAR）方法，通过语言建模传感器数据和活动嵌入来实现。

**AI_Comments:** 这项工作具有重要的创新性，因为它解决了当前零样本HAR方法中“提示-LLM”模式固有的风险。通过提出一种无需提示LLM的语言建模方法，该研究为智能家居HAR系统的部署提供了更安全、更自主的路径。其贡献在于提供了一种可行的替代方案，并强调了语言建模在未来智能家居应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 开发零样本人类活动识别（HAR）方法对于智能家居研究至关重要，因为它可以使HAR系统适应具有不同传感模式、布局和感兴趣活动的智能家居。现有方法依赖于通过精心设计的提示将传感器数据的自然语言描述输入到LLM中进行分类，但这带来了隐私侵犯、对外部服务的依赖以及由于版本变化导致预测不一致等风险。

**Method:** 本文提出了一种新的零样本HAR解决方案，该方案使用自然语言对传感器数据和活动进行建模，并利用其嵌入来执行零样本分类，从而绕过了对LLM进行活动预测的需要。

**Result:** 本文通过在六个数据集上进行详细的案例研究，展示了语言建模如何增强零样本识别中的HAR系统。

**Conclusion:** 通过语言建模传感器数据和活动，可以实现无需提示LLM的零样本人类活动识别，有效规避了现有方法的风险，并能在多样的智能家居环境中提升HAR系统的性能。

> **ai_Abstract:** 本文提出了一种创新的零样本人类活动识别（HAR）方法，专为智能家居环境设计。与现有依赖提示大型语言模型（LLM）的方法不同，本研究通过使用自然语言对传感器数据和活动进行建模，并利用其嵌入直接进行零样本分类，从而避免了隐私、外部服务依赖和模型不稳定性等风险。文章通过在六个数据集上的案例研究，证明了语言建模在零样本HAR系统中的有效性和潜力。

> **摘要翻译:** 在智能家居研究中，开发零样本人类活动识别（HAR）方法是一个关键方向——考虑到它对使HAR系统在具有不同传感模式、布局和感兴趣活动的智能家居中工作的影响。沿着这个方向的最新解决方案是基于生成传感器数据的自然语言描述，并通过精心设计的提示将其输入到大型语言模型（LLM）中进行分类。尽管它们有性能保证，但这种“提示-LLM”方法存在多重风险，包括隐私侵犯、对外部服务的依赖以及由于版本变化导致的不一致预测，这为不需要提示LLM的替代零样本HAR方法提供了理由。在本文中，我们提出了一种这样的解决方案，它使用自然语言对传感器数据和活动进行建模，利用其嵌入来执行零样本分类，从而绕过了对LLM进行活动预测的需求。我们工作的影响在于在六个数据集上进行了详细的案例研究，强调了语言建模如何增强零样本识别中的HAR系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [905] [Can You Trust an LLM with Your Life-Changing Decision? An Investigation into AI High-Stakes Responses](https://arxiv.org/abs/2507.21132)
> *你能相信大型语言模型处理你改变人生的决定吗？一项关于人工智能高风险回应的调查*

*Joshua Adrian Cahyono, Saran Subramanian* | **Category: cs.AI, cs.CY, cs.LG** | **Updated: 2025-07-22**

**Keywords:** 大型语言模型, LLM安全, 高风险决策, 奉承, 激活转向, 基准

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）在提供高风险生活建议时存在自信但误导性的风险，本研究通过三项实验（多项选择评估、自由回答分析、机械可解释性实验）调查了这些失败模式。结果显示，一些模型表现出奉承，而另一些则保持稳健；表现最佳的模型通过提问而非给出规定性建议来确保安全；模型的谨慎性可以通过激活向量直接控制。研究强调需要细致、多方面的基准来确保LLMs在关键决策中的可信度。

**AI_Comments:** 本文在评估大型语言模型在高风险场景下的安全性方面采用了多方面创新方法，特别是其利用机械可解释性（激活转向）来控制模型行为。这为提升LLM的安全对齐提供了一个有前景的方向，超越了传统的微调方法，有效解决了在实际应用中关于LLM可信度的关键担忧。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）正越来越多地被用于提供高风险的生活建议，但它们缺乏标准的安全保障措施，以防止提供自信但具有误导性的回应。这带来了奉承和过度自信的风险。本研究旨在调查这些失败模式。

**Method:** 本研究通过三项实验调查了上述失败模式：1. 一项多项选择评估，用于衡量模型在用户压力下的稳定性；2. 使用新型安全类型学和LLM判断器进行的自由回答分析；3. 一项机械可解释性实验，通过操纵“高风险”激活向量来引导模型行为。

**Result:** 结果显示，虽然一些模型表现出奉承，但另一些（如o4-mini）则保持稳健。表现最佳的模型通过频繁提出澄清问题（这是安全、探究性方法的关键特征）而非发布规定性建议来获得高安全分数。此外，研究证明模型的谨慎性可以通过激活转向直接控制。

**Conclusion:** 研究结果强调，需要细致、多方面的基准来确保大型语言模型在处理改变人生的决定时是值得信赖的。激活转向为安全对齐提供了一条新途径。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在提供高风险生活建议时可能出现的奉承和过度自信问题。通过三项实验——包括多项选择评估、自由回答分析以及通过操纵激活向量进行机械可解释性实验——研究发现，虽然部分模型存在奉承行为，但另一些模型表现出鲁棒性。研究指出，表现优秀且安全的模型倾向于通过提问来澄清而非直接给出规定性建议。此外，本研究还展示了通过“激活转向”直接控制模型谨慎性的可能性，为LLM的安全对齐提供了新途径。这些发现强调了建立细致、多方面基准的重要性，以确保LLMs在关键决策中的可信度。

> **摘要翻译:** 大型语言模型（LLMs）越来越多地被用于提供高风险的生活建议，但它们缺乏标准的安全保障措施，以防止提供自信但具有误导性的回应。这带来了奉承和过度自信的风险。本文通过三项实验调查了这些失败模式：（1）一项多项选择评估，用于衡量模型在用户压力下的稳定性；（2）使用新型安全类型学和LLM判断器进行的自由回答分析；以及（3）一项机械可解释性实验，通过操纵“高风险”激活向量来引导模型行为。我们的结果显示，虽然一些模型表现出奉承，但另一些（如o4-mini）则保持稳健。表现最佳的模型通过频繁提出澄清问题（这是安全、探究性方法的关键特征）而非发布规定性建议来获得高安全分数。此外，我们证明模型的谨慎性可以通过激活转向直接控制，这为安全对齐提供了一条新途径。这些发现强调，需要细致、多方面的基准来确保大型语言模型在处理改变人生的决定时是值得信赖的。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [928] [Self-Aware Safety Augmentation: Leveraging Internal Semantic Understanding to Enhance Safety in Vision-Language Models](https://arxiv.org/abs/2507.21637)
> *自感知安全增强：利用内部语义理解提升视觉-语言模型的安全性*

*Wanying Wang, Zeyu Ma, Han Zheng, Xin Tan, Mingang Chen* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 视觉-语言模型, 模型安全, 语义理解, 自感知, 安全增强

**Comment:** Accepted by ACM Multimedia 2025

> **TL;DR:** 本文提出SASA技术，通过将中间层语义表示投射到早期安全层，在不微调的情况下，利用模型内部语义理解增强大型视觉-语言模型的安全性。

**AI_Comments:** 本文创新性地揭示了大型视觉-语言模型中安全感知与语义理解之间的时序关系，并据此提出了一种无需微调即可增强模型安全性的有效方法SASA。其核心思想在于利用模型内部的固有语义理解来提升安全识别，这为模型安全研究提供了一个新颖且高效的视角。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）比纯语言模型更容易受到有害输入的影响。研究发现LVLM中安全感知常出现于全面语义理解之前，导致安全性降低。

**Method:** 本文提出了自感知安全增强（SASA）技术，该技术将来自中间层的信息语义表示投射到较早期的面向安全的层。这种方法利用模型的内在语义理解来增强安全识别，而无需进行微调。然后，通过线性探测来阐明模型的内部语义理解，以便在生成过程之前检测风险。

**Result:** SASA显著提高了LVLMs的安全性，同时对实用性影响最小。

**Conclusion:** 自感知安全增强（SASA）通过利用模型内部语义理解，在不进行微调的情况下，显著提升了大型视觉-语言模型的安全性。

> **ai_Abstract:** 本文研究了大型视觉-语言模型（LVLMs）对有害输入的脆弱性，发现其安全感知能力常先于语义理解出现，从而降低安全性。为此，文章提出了一种名为自感知安全增强（SASA）的新技术。SASA通过将模型中间层的语义表示投射到早期的安全相关层，利用模型自身的语义理解能力，在无需微调的情况下提升安全识别。此外，该方法还利用线性探测在生成前检测风险。实验证明，SASA能显著提高LVLMs的安全性，同时对模型实用性影响甚微。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）与纯语言骨干模型相比，更容易受到有害输入的影响。我们通过探索LVLMs的内部动态来研究这种脆弱性，将它们固有的安全理解构建为三个关键能力。具体来说，我们将这些能力定义为安全感知、语义理解和语言表达对齐，并通过实验确定了它们在模型架构中的主要位置。结果表明，安全感知通常在全面语义理解之前出现，导致安全性降低。受这些发现的启发，我们提出了自感知安全增强（SASA），这是一种将来自中间层的信息语义表示投射到较早期的面向安全的层的技术。这种方法利用模型的内在语义理解来增强安全识别，而无需进行微调。然后，我们采用线性探测来阐明模型的内部语义理解，以便在生成过程之前检测风险。在各种数据集和任务上的大量实验表明，SASA显著提高了LVLMs的安全性，同时对实用性影响最小。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [929] [The Effect of Compression Techniques on Large Multimodal Language Models in the Medical Domain](https://arxiv.org/abs/2507.21976)
> *医疗领域中压缩技术对大型多模态语言模型的影响*

*Tanvir Ahmed Khan, Aranya Saha, Ismam Nur Swapnil, Mohammad Ariful Haque* | **Category: cs.AI** | **Updated: 2025-07-29**

**Keywords:** 压缩技术, 多模态大型语言模型, 医疗领域, 剪枝, 量化

**Comment:** 12 pages, 5 figures. tcolorbox dependencies were removed for arXiv
  compatibility. All references are included via a precompiled .bbl file

> **TL;DR:** 本研究评估了在医疗领域对LLAVA模型应用结构化剪枝和激活感知量化等压缩技术的影响，提出了一种新的层选择方法，实现了显著的内存减少和性能提升。

**AI_Comments:** 本文的创新之处在于提出了新颖的剪枝层选择方法，并将其有效整合到剪枝-SFT-量化流程中，从而在内存减少和性能方面优于传统方法。这对于在资源有限的医疗环境中部署大型模型至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLM）在医疗领域具有巨大潜力，但其高昂的计算成本需要高效的压缩技术。

**Method:** 本文评估了结构化剪枝和激活感知量化对医疗应用中微调的LLAVA模型的影响。提出了一种新颖的剪枝层选择方法，分析了不同的量化技术，并在剪枝-SFT-量化流程中评估了性能权衡。

**Result:** 所提出的方法使具有7B参数的MLLM能够在4GB显存内运行，内存使用量减少了70%，与相同压缩比下的传统剪枝和量化技术相比，模型性能提高了4%。

**Conclusion:** 压缩技术，特别是本文提出的层选择方法和组合流程，能够显著降低医疗领域中MLLM的计算成本，同时提高或保持性能。

> **ai_Abstract:** 本文研究了在医疗领域应用压缩技术对大型多模态语言模型（MLLM）的影响。通过对微调的LLAVA模型进行结构化剪枝和激活感知量化，并提出一种新的层选择方法，该研究成功地将7B参数的MLLM的显存占用从4GB降低了70%，同时在相同压缩比下，模型性能比传统方法提高了4%。这项工作为在资源受限的医疗环境中部署MLLM提供了有效途径。

> **摘要翻译:** 多模态大型语言模型（MLLM）在医疗领域具有巨大的应用潜力，但其计算成本高昂，因此需要高效的压缩技术。本文评估了结构化剪枝和激活感知量化对医疗应用中微调的LLAVA模型的影响。我们提出了一种新颖的剪枝层选择方法，分析了不同的量化技术，并在剪枝-SFT-量化流程中评估了性能权衡。我们提出的方法使具有7B参数的MLLM能够在4GB显存内运行，与相同压缩比下的传统剪枝和量化技术相比，内存使用量减少了70%，模型性能提高了4%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [5] [Explaining Deep Network Classification of Matrices: A Case Study on Monotonicity](https://arxiv.org/abs/2507.22570)
> *解释深度网络对矩阵的分类：单调性案例研究*

*Leandro Farina, Sergey Korotov* | **Category: cs.LG, cs.AI, cs.NA, math.NA, 15B48, 68T07, 15A18, 62G32, I.2.6; I.5.2; G.1.3** | **Updated: 2025-07-30**

**Keywords:** 单调矩阵, 深度学习, 可解释人工智能, 特征多项式, 矩阵分类

**Comment:** 22 pages, 11 figures. To be submitted to a journal

> **TL;DR:** 该工作展示了一种利用深度学习和可解释人工智能（XAI）来发现分类矩阵的简单实用标准的方法，以单调矩阵为例。研究发现，特征多项式的两个最低阶系数的绝对值（$c_0$和$c_1$）足以以95%的准确率进行分类，并得出了单调矩阵满足$\|c_0/c_1\|\le0.18$或等效于$\mathrm{tr}(A^{-1})\ge5.7$的简单界限。

**AI_Comments:** 本论文创新性地将深度学习和可解释人工智能应用于线性代数中的一个难题——单调矩阵的表征。其主要创新点在于能够将复杂的神经网络决策提炼成简单、人类可解释的代数规则。这不仅展示了XAI在理解模型方面的强大能力，也体现了其在发现新数学见解方面的潜力。所推导出的判据，特别是关于$\mathrm{tr}(A^{-1})$的界限，是一个重要的实践成果。

<details>
  <summary>Details</summary>

**Motivation:** 尽管单调矩阵定义简单，但目前尚无基于其元素或导出参数的简易表征。本研究旨在利用深度学习和可解释人工智能（XAI）发现分类矩阵的简单、实用标准，特别是针对单调矩阵这一挑战性案例。

**Method:** 本研究结合了高性能神经网络和可解释人工智能（XAI）技术（如集成梯度等显著性方法）。首先，通过在$(-1,1)$范围内均匀随机生成单调和非单调矩阵来建立标记数据集。然后，使用深度神经网络算法，利用矩阵的元素和一组全面的矩阵特征来对矩阵进行单调或非单调分类。最后，通过显著性方法识别出关键的矩阵参数。

**Result:** 研究发现，仅凭借矩阵特征多项式的两个最低阶系数（$c_0$和$c_1$）的绝对值，即可提供足够的信息进行矩阵分类，准确率达到95%。对18,000个随机$7\times7$矩阵的数据驱动研究表明，单调类以超过99.98%的概率满足$\|c_0/c_1\|\le0.18$；由于对于单调矩阵$A$，$\|c_0/c_1\| = 1/\mathrm{tr}(A^{-1})$，这等效于简单的界限$\mathrm{tr}(A^{-1})\ge5.7$。

**Conclusion:** 本研究首次系统地利用机器学习方法为单调矩阵和非单调矩阵的区分提供了实用判据。结果表明，深度学习和可解释人工智能可以成功地从复杂模型中提取出简单、可解释的代数规则，为单调矩阵的分类提供了一个基于特征多项式系数的简单且准确的判别标准。

> **ai_Abstract:** 本论文提出了一种结合深度学习和可解释人工智能（XAI）的新颖方法，旨在为基于抽象代数性质的矩阵分类推导出简单、可解释的判据。针对目前尚无简易表征的单调矩阵，作者训练了一个深度神经网络，并利用显著性方法发现，矩阵特征多项式的两个最低阶系数（$c_0$和$c_1$）的绝对值足以实现95%的分类准确率。这项研究进一步揭示，单调矩阵以高概率满足$\|c_0/c_1\|\le0.18$，这等同于$\mathrm{tr}(A^{-1})\ge5.7$，从而提供了一个实用且可解释的单调矩阵判别标准。

> **摘要翻译:** 这项工作展示了一种利用深度学习发现基于抽象代数性质对矩阵进行分类的简单实用标准的方法。通过将高性能神经网络与可解释人工智能（XAI）技术相结合，我们可以将模型学习到的策略提炼成人类可解释的规则。我们将这种方法应用于单调矩阵的挑战性案例，单调矩阵定义为它们的逆矩阵元素非负。尽管它们的定义简单，但尚未发现用矩阵元素或导出参数进行简单表征的方法。据我们所知，我们在此提出了第一个系统的机器学习方法，用于推导区分单调矩阵和非单调矩阵的实用判据。在通过在$(-1,1)$范围内均匀随机生成单调和非单调矩阵建立标记数据集后，我们采用深度神经网络算法，使用它们的元素和一套全面的矩阵特征来将矩阵分类为单调或非单调。通过显著性方法，例如集成梯度，我们在所有特征中识别出两个矩阵参数，它们单独提供了足够的矩阵分类信息，准确率达到95%，即矩阵特征多项式的两个最低阶系数$c_0$和$c_1$的绝对值。对18,000个随机$7\times7$矩阵的数据驱动研究表明，单调类以超过99.98%的概率满足$\|c_0/c_1\|\le0.18$；因为对于单调矩阵$A$，$\|c_0/c_1\| = 1/\mathrm{tr}(A^{-1})$，这等效于简单的界限$\mathrm{tr}(A^{-1})\ge5.7$。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [9] [Advancing Compositional LLM Reasoning with Structured Task Relations in Interactive Multimodal Communications](https://arxiv.org/abs/2507.21199)
> *在交互式多模态通信中通过结构化任务关系提升组合式LLM推理*

*Xinye Cao, Hongcan Guo, Guoshun Nan, Jiaoyang Cui, Haoting Qian, Yihan Lin, Yilin Peng, Diyang Zhang, Yanzhao Hou, Huici Wu, Xiaofeng Tao, Tony Q. S. Quek* | **Category: cs.LG, cs.AI, cs.DC, cs.HC** | **Updated: 2025-07-28**

**Keywords:** 组合式LLM, 交互式多模态应用, 任务关系, ContextLoRA, ContextGear

**Comment:** Accepted by IEEE JSAC. This work has been submitted to the IEEE for
  possible publication

> **TL;DR:** 本文提出一种新范式，使用单个组合式LLM处理多种交互式多模态应用（IMAs），并引入ContextLoRA和ContextGear以解决LLM适应性和效率挑战，实验证明其优越性和实用性。

**AI_Comments:** 本文提出了一种创新性的方法，通过单个组合式LLM处理多模态应用，有效解决了现有方案中多LLM带来的复杂性和效率问题。ContextLoRA通过任务依赖图和分阶段微调，使LLM能够学习任务间的内在关联，提升了适应性；ContextGear则优化了资源利用。这项工作在资源受限的移动环境中具有重要意义，为未来IMAs的发展提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有交互式多模态应用（IMAs）依赖于为特定任务单独训练的多个大语言模型（LLMs），这导致了效率和资源消耗问题。本文旨在克服这一局限，使用单个组合式LLM处理多种IMAs，主要面临两大挑战：1) 如何引导单个LLM适应多样化的IMA目标；2) 如何在资源受限的移动环境中确保LLM的灵活性和效率。

**Method:** 针对第一个挑战，本文提出了ContextLoRA，通过构建任务依赖图来引导LLM学习IMAs之间丰富的结构化上下文，并对神经层的可学习参数矩阵进行分区以促进LLM组合。同时，开发了包括训练、冻结和掩蔽阶段的逐步微调过程，使LLM能够学习在任务之间进行推理。针对第二个挑战，引入了ContextGear，这是一种调度策略，通过战略性分组机制优化ContextLoRA的训练过程，旨在最小化计算和通信成本。

**Result:** 在三个基准测试中，所提出的ContextLoRA和ContextGear表现出优越性。此外，在真实世界的无线测试平台上原型验证了所提出的范式，证明了其在各种IMAs中的实际适用性。

**Conclusion:** 本文成功提出了一种使用单个组合式LLM处理多种交互式多模态应用的新范式，并通过ContextLoRA和ContextGear有效解决了LLM在多样化任务适应性和资源受限环境中的效率挑战。实验结果和实际原型验证均证明了所提方法的优越性和实用性。

> **ai_Abstract:** 本文提出了一种新颖的范式，旨在通过单个组合式大语言模型（LLM）处理多种交互式多模态应用（IMAs），以克服当前依赖多个独立LLM的局限性。为解决LLM适应多样化IMA目标和在资源受限环境中保持效率的挑战，作者提出了ContextLoRA，通过构建任务依赖图和分阶段微调来引导LLM学习任务间的结构化上下文和潜在依赖。同时，引入ContextGear调度策略以优化训练过程，降低计算和通信成本。实验结果和真实无线测试平台的原型验证均表明了所提方法的优越性和实际适用性。

> **摘要翻译:** 交互式多模态应用（IMAs），例如车联网中的路线规划，通过无线网络整合各种形式的数据，丰富了用户的个性化体验。大型语言模型（LLMs）的最新进展利用专家混合（MoE）机制来赋能多个IMAs，每个LLM都针对呈现不同业务流程的特定任务单独训练。与现有依赖多个LLM处理IMAs的方法不同，本文提出了一种新颖的范式，即在无线网络上使用单个组合式LLM来完成各种IMAs。两个主要挑战包括：1）引导单个LLM适应多样化的IMA目标；2）确保LLM在资源受限的移动环境中的灵活性和效率。为了解决第一个挑战，我们提出了ContextLoRA，这是一种新颖的方法，通过构建任务依赖图来引导LLM学习IMAs之间丰富的结构化上下文。我们为每个IMA划分神经层的可学习参数矩阵，以促进LLM组合。然后，我们开发了一个由任务关系指导的逐步微调过程，包括训练、冻结和掩蔽阶段。这使得LLM能够学习在任务之间进行推理，以实现更好的适应性，捕获任务之间的潜在依赖关系。对于第二个挑战，我们引入了ContextGear，这是一种调度策略，用于优化ContextLoRA的训练过程，旨在通过战略性分组机制最小化计算和通信成本。在三个基准测试上的实验表明了所提出的ContextLoRA和ContextGear的优越性。此外，我们在真实无线测试平台上原型化了我们提出的范式，展示了其在各种IMAs中的实际适用性。我们将向社区发布我们的代码。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [15] [Deep Reinforcement Learning for Real-Time Green Energy Integration in Data Centers](https://arxiv.org/abs/2507.21153)
> *深度强化学习在数据中心实时绿色能源集成中的应用*

*Abderaouf Bahi, Amel Ourici* | **Category: cs.LG, cs.AI, cs.SY, eess.SY** | **Updated: 2025-07-24**

**Keywords:** 深度强化学习, 能源管理, 数据中心, 绿色能源, 可持续性

**Comment:** 

> **TL;DR:** 本文提出了一种基于深度强化学习的能源管理系统，用于数据中心实时集成绿色能源，显著提高了能源效率、降低了成本和碳排放。

**AI_Comments:** 这项研究创新性地将深度强化学习应用于数据中心的实时绿色能源集成管理，通过智能决策有效平衡了能源成本、效率、SLA和服务质量，并显著减少了碳排放。其优势在于能够应对能源波动的复杂性，并超越传统方法，为数据中心的可持续运营提供了有力的技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过优化能源管理系统，提高电子商务数据中心的能源效率、成本效益和环境可持续性。

**Method:** 本文提出了一种基于深度强化学习（DRL）的能源管理系统，该系统利用DRL算法动态管理可再生能源、储能和电网电力的集成，以适应实时波动的能源可用性。

**Result:** DRL优化系统实现了38%的能源成本降低，优于传统强化学习方法（28%）和启发式方法（22%）。SLA违规率保持在1.5%（RL为3.0%，启发式为4.8%）。能源效率提高了82%，碳排放减少了45%。系统累计奖励为950。

**Conclusion:** 研究结果突出了深度强化学习在推进能源优化策略和解决可持续性挑战方面的潜力，为数据中心能源管理提供了稳健的解决方案。

> **ai_Abstract:** 本文提出并评估了一种基于深度强化学习（DRL）的能源管理系统，用于电子商务数据中心实时集成绿色能源。该系统通过动态管理可再生能源、储能和电网电力，显著提高了能源效率、降低了运营成本和碳排放。实验结果显示，与传统RL和启发式方法相比，DRL系统在能源成本、SLA违规率、能源效率和碳减排方面均表现出卓越性能，证明了DRL在数据中心能源优化和可持续发展方面的巨大潜力。

> **摘要翻译:** 本文探讨了在电子商务数据中心实施深度强化学习（DRL）优化的能源管理系统，旨在提高能源效率、成本效益和环境可持续性。所提出的系统利用DRL算法动态管理可再生能源、储能和电网电力的集成，实时适应波动的能源可用性。研究表明，DRL优化系统实现了38%的能源成本降低，显著优于传统强化学习（RL）方法（28%）和启发式方法（22%）。此外，它保持了1.5%的低SLA违规率，而RL为3.0%，启发式方法为4.8%。DRL优化方法还使能源效率提高了82%，超越了其他方法，碳排放减少了45%，使其成为最环保的解决方案。系统950的累积奖励反映了其在平衡多目标方面的卓越性能。通过严格的测试和消融研究，本文验证了DRL模型架构和参数的有效性，为数据中心的能源管理提供了稳健的解决方案。研究结果突出了DRL在推进能源优化策略和解决可持续性挑战方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [20] [Learning Pareto-Optimal Rewards from Noisy Preferences: A Framework for Multi-Objective Inverse Reinforcement Learning](https://arxiv.org/abs/2505.11864)
> *从噪声偏好中学习帕累托最优奖励：一个多目标逆向强化学习框架*

*Kalyan Cherukuri, Aarav Lala* | **Category: cs.LG, cs.AI, cs.CG** | **Updated: 2025-07-28**

**Keywords:** 多目标逆向强化学习, 帕累托最优奖励, 偏好学习, 行为对齐, 样本复杂度

**Comment:** 

> **TL;DR:** 本文提出了一个多目标逆向强化学习（MO-IRL）的理论框架，用于从有噪声的偏好中学习帕累托最优奖励，并通过一个可证明收敛的算法来优化策略。

**AI_Comments:** 本文的创新点在于提出了一个将人类偏好建模为向量值奖励的多目标逆向强化学习框架，突破了传统单目标奖励的局限。其理论贡献体现在对帕累托最优奖励恢复问题的形式化、样本复杂度界限的推导以及可证明收敛算法的提出，为复杂价值对齐提供了坚实的理论基础和实用方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在将生成式代理与复杂人类价值观对齐时，常将人类意图简化为标量奖励，忽略了人类反馈的多面性，导致对齐效果不佳。

**Method:** 本文提出了一个基于偏好的多目标逆向强化学习（MO-IRL）理论框架，将人类偏好建模为潜在的向量值奖励函数。它形式化了从有噪声偏好查询中恢复帕累托最优奖励表示的问题，并导出了恢复帕累托前沿的紧密样本复杂度界限。此外，还提出了一个可证明收敛的算法，用于使用偏好推断的奖励锥进行策略优化。

**Result:** 建立了识别潜在多目标结构的条件。推导了恢复帕累托前沿的ε-近似的紧密样本复杂度界限。引入了遗憾公式来量化多目标设置中的次优性。提出了一个可证明收敛的策略优化算法。

**Conclusion:** 本工作弥合了实际对齐技术与理论保证之间的鸿沟，为在高维和价值多元化环境中学习对齐行为提供了原则性基础。

> **ai_Abstract:** 本文针对生成式代理与复杂人类价值观对齐的挑战，提出了一个基于偏好的多目标逆向强化学习（MO-IRL）理论框架。该框架将人类偏好建模为向量值奖励函数，并解决了从噪声偏好中恢复帕累托最优奖励表示的问题。研究工作建立了识别多目标结构的条件，推导了帕累托前沿近似的样本复杂度界限，并提出了一个可证明收敛的策略优化算法。该工作为在高维、价值多元化环境中学习对齐行为提供了理论和实践基础。

> **摘要翻译:** 随着生成式代理能力日益增强，使其行为与复杂人类价值观对齐仍然是一个根本性挑战。现有方法通常通过将人类意图简化为标量奖励来忽略人类反馈的多面性。在这项工作中，我们引入了一个基于偏好的多目标逆向强化学习（MO-IRL）理论框架，其中人类偏好被建模为潜在的向量值奖励函数。我们形式化了从有噪声偏好查询中恢复帕累托最优奖励表示的问题，并建立了识别底层多目标结构的条件。我们推导了恢复帕累托前沿的ε-近似的紧密样本复杂度界限，并引入了遗憾公式来量化此多目标设置中的次优性。此外，我们提出了一种可证明收敛的算法，用于使用偏好推断的奖励锥进行策略优化。我们的结果弥合了实际对齐技术与理论保证之间的鸿沟，为在高维和价值多元化环境中学习对齐行为提供了原则性基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [32] [Improving Generative Ad Text on Facebook using Reinforcement Learning](https://arxiv.org/abs/2507.21983)
> *使用强化学习改进Facebook上的生成式广告文本*

*Daniel R. Jiang, Alex Nikulkov, Yu-Chia Chen, Yang Bai, Zheqing Zhu* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 强化学习, 大型语言模型, 广告文本生成, AdLlama, RLPF

**Comment:** D.J. and A.N. contributed equally, 41 pages, 6 figures

> **TL;DR:** 本研究首次在Facebook大规模部署RL训练的LLM（AdLlama）用于生成式广告，通过引入RLPF方法，显著提升了广告点击率（6.7%）和广告主满意度，量化了强化学习后训练的经济影响。

**AI_Comments:** 这项研究的创新之处在于首次将强化学习应用于大规模真实世界的生成式广告文本优化，并明确量化了其经济效益。通过引入RLPF方法，它有效地将广告性能数据转化为奖励信号，解决了LLM在特定任务中对齐的挑战。其重要性在于为生成式AI的实际应用提供了强有力的证据，并展示了RL在弥合模型能力与实际业务成果之间差距的潜力。该研究的规模和“生态有效”的设置也增加了其结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI（尤其是大型语言模型LLMs）有望带来变革性的经济变化，但强化学习（RL）作为主要的后训练技术，其经济影响在很大程度上仍未被充分探索和量化。

**Method:** 研究团队部署了名为“AdLlama”的RL训练LLM，该模型集成到Meta的文本生成功能中，帮助广告主创建广告文本变体。训练方法是“带性能反馈的强化学习（RLPF）”，它使用历史广告性能数据作为奖励信号。模型通过一个为期10周、涉及近35,000名广告主和640,000个广告变体的大规模A/B测试进行评估。

**Result:** AdLlama相比于基于精选广告训练的监督模仿模型，点击率提高了6.7%（p=0.0296）。此外，使用AdLlama的广告主生成了更多的广告变体，表明对模型输出的满意度更高。

**Conclusion:** RLPF是一种有前景且可推广的指标驱动型后训练方法，它弥合了高性能语言模型与实际成果之间的鸿沟。这项研究是迄今为止在生态有效环境中对生成式AI使用情况的最大规模研究，提供了量化RL后训练实际影响的重要数据点。

> **ai_Abstract:** 本研究首次在Facebook上部署了通过强化学习（RL）训练的大型语言模型（LLM）“AdLlama”，用于生成式广告文本。通过引入“带性能反馈的强化学习（RLPF）”方法，该模型利用历史广告性能数据作为奖励信号进行训练。在Facebook进行的大规模A/B测试显示，AdLlama显著提升了广告点击率达6.7%，并增加了广告主生成广告变体的数量，表明广告主满意度提高。这项工作量化了RL后训练对真实世界经济的积极影响，并证明RLPF是一种有效且可推广的度量驱动型后训练方法。

> **摘要翻译:** 生成式人工智能（AI），特别是大型语言模型（LLMs），有望推动变革性的经济变化。LLMs在海量文本数据上进行预训练以学习通用语言模式，但随后的后训练阶段对于使其适应特定的真实世界任务至关重要。强化学习（RL）是领先的后训练技术，但其经济影响在很大程度上仍未被充分探索和量化。我们通过Facebook上首次部署用于生成广告的RL训练LLM来审视这个问题。我们的模型“AdLlama”集成到Meta的文本生成功能中，为AI工具提供支持，帮助广告主创建人工编写广告文本的新变体。为了训练这个模型，我们引入了带性能反馈的强化学习（RLPF），这是一种使用历史广告性能数据作为奖励信号的后训练方法。在Facebook上进行的一项为期10周、涉及近35,000名广告主和640,000个广告变体的大规模A/B测试中，我们发现AdLlama与在精选广告上训练的监督模仿模型相比，点击率提高了6.7%（p=0.0296）。这代表了Facebook上广告主投资回报的显著提升。我们还发现，使用AdLlama的广告主生成了更多的广告变体，表明对模型输出的满意度更高。据我们所知，这是迄今为止在生态有效环境中对生成式AI使用情况的最大规模研究，提供了量化RL后训练实际影响的重要数据点。此外，结果表明RLPF是一种有前景且可推广的指标驱动型后训练方法，它弥合了高性能语言模型与实际成果之间的鸿沟。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [33] [Bayesian Optimization of Process Parameters of a Sensor-Based Sorting System using Gaussian Processes as Surrogate Models](https://arxiv.org/abs/2507.22766)
> *基于高斯过程作为替代模型的传感器分选系统工艺参数贝叶斯优化*

*Felix Kronenwett, Georg Maier, Thomas Laengle* | **Category: cs.LG, cs.AI, cs.SY, eess.SY** | **Updated: 2025-07-30**

**Keywords:** 贝叶斯优化, 高斯过程, 传感器分选系统, 工艺参数优化, 替代模型

**Comment:** Accepted at the 30th IEEE International Conference on Emerging
  Technologies and Factory Automation (ETFA)

> **TL;DR:** 本文提出了一种基于贝叶斯优化的方法，利用高斯过程回归模型作为替代模型，以优化、监测和调整传感器分选系统的工艺参数，旨在减少实验次数并同时考虑两个优化目标。

**AI_Comments:** 这项工作在优化传感器分选系统方面具有创新性，特别是在利用贝叶斯优化和高斯过程来处理不确定性和减少实验成本方面。其重要性在于提高了分选效率和适应性，但具体性能提升和实际应用中的鲁棒性仍需更多细节。

<details>
  <summary>Details</summary>

**Motivation:** 传感器分选系统需要根据物料流特性、系统尺寸和分选精度不断调整工艺参数。由于需求和物料流成分的变化，需要持续验证和重新调整。因此，本文旨在提出一种优化、周期性监测和调整这些参数的方法。

**Method:** 本文提出了一种基于贝叶斯优化的方法，其中使用高斯过程回归模型作为替代模型。该方法旨在最小化必要的实验次数，同时考虑两个可能的优化目标，并考虑模型计算中确定分选精度时的不确定性。

**Result:** 该方法已通过三个示例工艺参数进行了评估。

**Conclusion:** 本文提出了一种利用贝叶斯优化和高斯过程作为替代模型来优化和调整传感器分选系统工艺参数的方法，该方法有效减少了实验次数并考虑了不确定性。

> **ai_Abstract:** 本文提出了一种利用贝叶斯优化和高斯过程回归模型作为替代模型的方法，用于优化、周期性监测和调整传感器分选系统的工艺参数。该方法旨在减少所需实验次数，并同时考虑两个优化目标，并在确定分选精度时考虑不确定性。该方法已通过三个示例参数进行了评估。

> **摘要翻译:** 传感器分选系统能够将物料流物理分离成两部分。分选决策基于所用传感器的图像数据评估，并使用执行器进行。根据物料流的特性、系统的尺寸和所需的分选精度，必须设置各种工艺参数。然而，由于不断变化的需求和物料流成分，需要持续验证和重新调整。在本文中，我们介绍了一种优化、周期性监测和调整传感器分选系统工艺参数的方法。基于贝叶斯优化，高斯过程回归模型被用作替代模型，以实现对系统行为的特定要求及其所包含的不确定性。该方法在最小化必要实验次数的同时，考虑了基于对两种物料输出流的要求的两个可能的优化目标。此外，在模型计算中确定分选精度时考虑了不确定性。我们用三个示例工艺参数评估了该方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [42] [Pre-trained Models Perform the Best When Token Distributions Follow Zipf's Law](https://arxiv.org/abs/2507.22543)
> *当词元分布遵循齐夫定律时，预训练模型表现最佳*

*Yanjin He, Qingkai Zeng, Meng Jiang* | **Category: cs.LG, cs.CL, I.2.6; I.2.7** | **Updated: 2025-07-30**

**Keywords:** 词元化, 齐夫定律, 词汇量选择, 预训练模型, 幂律分布

**Comment:** 

> **TL;DR:** 研究表明，当词元分布遵循齐夫定律时，预训练模型性能最佳，这为词汇量选择提供了一个原则性方法。

**AI_Comments:** 这项工作为词汇量选择提供了一个基于理论（齐夫定律）的原则性方法，而非传统上依赖启发式或经验性选择，具有重要的理论和实践意义。它揭示了词元分布特性与模型性能之间的深层联系，为优化预训练模型提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 词元化是自然语言处理和其他序列建模领域的基础步骤，词汇量大小的选择显著影响模型性能，但目前缺乏选择最佳词汇量的系统方法。

**Method:** 通过分析词元频率分布与齐夫定律的关系，提出了一种确定词汇量的原则性方法。研究下游任务性能与词元分布遵循幂律行为的紧密程度之间的相关性。

**Result:** 实验表明，当词元分布紧密遵循齐夫定律时，模型能持续达到最佳性能。遵循齐夫定律的对齐方式能提高模型的效率和有效性。

**Conclusion:** 齐夫对齐是词汇量选择的一个稳健且可泛化的标准，可以帮助预训练模型实现最佳性能。

> **ai_Abstract:** 该研究提出了一种基于齐夫定律分析词元频率分布的原则性方法，用于确定预训练模型的最佳词汇量。研究发现，当词元分布与齐夫定律紧密对齐时，模型在NLP、基因组学和化学等多个领域的性能达到最佳，这表明齐夫对齐是词汇量选择的通用且有效标准。

> **摘要翻译:** 词元化是自然语言处理 (NLP) 和其他序列建模领域的基础步骤，其中词汇量大小的选择显著影响模型性能。尽管其重要性，选择最佳词汇量仍未得到充分探索，通常依赖启发式方法或特定数据集的选择。在这项工作中，我们通过分析齐夫定律下的词元频率分布，提出了一种确定词汇量的原则性方法。我们表明，下游任务性能与词元分布遵循幂律行为的紧密程度相关，并且与齐夫缩放对齐可以提高模型的效率和有效性。对 NLP、基因组学和化学领域的广泛实验表明，当词元分布紧密遵循齐夫定律时，模型始终能达到峰值性能，从而确立了齐夫对齐作为词汇量选择的稳健且可泛化标准。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [49] [Efficient Differentially Private Fine-Tuning of LLMs via Reinforcement Learning](https://arxiv.org/abs/2507.22565)
> *通过强化学习实现LLM高效差分隐私微调*

*Afshin Khadangi, Amir Sartipi, Igor Tchappi, Ramin Bahmani, Gilbert Fridgen* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 差分隐私, 强化学习, 大型语言模型, 微调, 梯度裁剪

**Comment:** 

> **TL;DR:** RLDP是一种新颖的强化学习框架，用于LLM的差分隐私优化，通过动态调整梯度裁剪和噪声注入来显著提高模型效用和隐私预算效率。

**AI_Comments:** RLDP的创新之处在于它首次将差分隐私优化问题转化为一个可由强化学习解决的闭环控制问题。这种动态、自适应的隐私机制管理方法克服了传统DP-SGD中硬编码、全局参数的局限性，显著提升了LLM在隐私保护下的实用性。其在多个LLM模型上的广泛实验结果令人印象深刻，表明了其在平衡隐私和模型效用方面的巨大潜力，对于将LLM应用于敏感领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在敏感数据集（如医疗保健）上训练大型语言模型（LLMs）时，数据隐私与模型效用之间的矛盾是一个关键瓶颈。传统的差分隐私随机梯度下降（DP-SGD）方法通过强制裁剪和添加噪声来保证隐私，但这会降低样本效率和最终准确性。现有变体也存在局限性，其控制参数是硬编码、全局且对优化过程不敏感，导致开发者要么过度消耗隐私预算以追求效用，要么接受性能平庸的模型以满足隐私约束。

**Method:** 本文提出了RLDP，这是首个将差分隐私优化本身视为一个闭环控制问题的框架，并结合了深度强化学习（RL）技术。RLDP持续感知学习动态的丰富统计信息，并通过选择细粒度的每个参数梯度裁剪阈值以及注入高斯噪声的幅度来进行操作。一个软演员-评论家（SAC）超策略在语言模型微调期间在线训练，从零开始学习如何以及何时分配隐私预算。这意味着RLDP能够根据优化过程的演变动态调整隐私机制。

**Result:** 在GPT2-small、Llama-1B、Llama-3B和Mistral-7B上进行的1600多次消融实验表明，RLDP的困惑度降低了1.3-30.5%（平均5.4%），并平均带来了5.6%的下游效用增益。RLDP仅用13-43%的梯度更新预算（平均加速71%）就能达到每个基线的最终效用，同时遵守相同的($\epsilon$, $\delta$)-DP契约，并且对成员推断和金丝雀提取攻击表现出相同或更低的敏感性。

**Conclusion:** RLDP是第一个将差分隐私优化视为一个可采用现代深度强化学习的闭环控制问题的框架，它通过动态和自适应地管理隐私预算，显著提高了LLM在差分隐私设置下的微调效率和模型效用，同时保持了强大的隐私保证。

> **ai_Abstract:** RLDP是一种创新的强化学习框架，旨在解决大型语言模型（LLMs）在敏感数据上进行差分隐私微调时面临的隐私与效用之间的权衡问题。与传统的DP-SGD及其变体不同，RLDP将差分隐私优化视为一个闭环控制问题，通过在线训练的软演员-评论家（SAC）策略，动态且细粒度地调整梯度裁剪阈值和噪声注入量。这种自适应的隐私预算分配策略显著提高了LLM的微调效率和最终模型性能。实验证明，RLDP在困惑度和下游任务效用方面均优于现有基线，并能以更少的梯度更新预算达到同等效用，同时保持强大的隐私保护。

> **摘要翻译:** 数据隐私与模型效用之间的紧张关系已成为在包括医疗保健在内的敏感语料库上训练的大型语言模型（LLM）实际部署的决定性瓶颈。差分隐私随机梯度下降（DP-SGD）保证了形式上的隐私，但其代价是显著的：梯度被强制裁剪并受到噪声扰动，从而降低了样本效率和最终准确性。尽管已提出了许多变体来缓解这种权衡，但它们都存在一个缺陷：它们的控制旋钮是硬编码、全局且对不断演变的优化格局不敏感。因此，实践者被迫要么为了追求效用而过度花费隐私预算，要么为了遵守隐私限制而接受平庸的模型。我们提出了RLDP，这是第一个将差分隐私优化本身视为一个可采用现代深度强化学习（RL）的闭环控制问题的框架。RLDP持续感知学习动态的丰富统计信息，并通过选择细粒度的每个参数梯度裁剪阈值以及注入高斯噪声的幅度来进行操作。一个软演员-评论家（SAC）超策略在语言模型微调期间在线训练；它从零开始学习如何以及何时分配隐私预算。在GPT2-small、Llama-1B、Llama-3B和Mistral-7B上进行的1600多次消融实验表明，RLDP的困惑度降低了1.3-30.5%（平均5.4%），并平均带来了5.6%的下游效用增益。RLDP仅用13-43%的梯度更新预算（平均加速71%）就能达到每个基线的最终效用，同时遵守相同的($\epsilon$, $\delta$)-DP契约，并且对成员推断和金丝雀提取攻击表现出相同或更低的敏感性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [55] [Mining Intrinsic Rewards from LLM Hidden States for Efficient Best-of-N Sampling](https://arxiv.org/abs/2505.12225)
> *从LLM隐藏状态中挖掘内在奖励以实现高效的Best-of-N采样*

*Jizhou Guo, Zhaomin Wu, Hanchen Yang, Philip S. Yu* | **Category: cs.LG, cs.AI, cs.CL, stat.ML** | **Updated: 2025-07-29**

**Keywords:** LLM, Best-of-N采样, 隐藏状态, 内在奖励, SWIFT

**Comment:** 

> **TL;DR:** SWIFT是一种轻量级技术，通过利用LLM隐藏状态中的信息，显著提高了Best-of-N采样的效率，参数量极小且只需少量样本即可训练。

**AI_Comments:** SWIFT的创新之处在于其将奖励信号的来源从耗费资源的文本转移到LLM内部的隐藏状态，并采用极其轻量级的线性层结构。这显著降低了计算成本和数据需求，对于大规模LLM的应用和部署具有重要意义。其对闭源模型的适用性也拓宽了其应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 由于需要大量数据且计算成本高昂的基于文本的奖励模型，Best-of-N采样在增强大型语言模型(LLM)性能方面虽然有效，但计算开销巨大，难以普及。

**Method:** SWIFT（Simple Weighted Intrinsic Feedback Technique）是一种新颖的轻量级技术，通过将数据源从文本改为LLM的隐藏状态来挖掘内在奖励。它在token级别操作，仅由线性层组成，利用LLM隐藏状态中嵌入的丰富信息来解决效率问题。

**Result:** SWIFT的参数量不到基线的0.005%，且只需少量样本即可训练，实验表明其性能优于基线。SWIFT展现出强大的可扩展性，可通过logits应用于一些闭源模型，并可与传统奖励模型结合以获得进一步的性能提升。

**Conclusion:** SWIFT通过利用LLM隐藏状态中的内在奖励，提供了一种高效、轻量级的Best-of-N采样方法，解决了传统方法计算成本高昂的问题，并具有广泛的适用性和与现有技术的兼容性。

> **ai_Abstract:** 本文提出SWIFT（Simple Weighted Intrinsic Feedback Technique），一种利用LLM隐藏状态而非文本来挖掘内在奖励的轻量级技术，旨在解决Best-of-N采样中基于文本奖励模型计算成本过高的问题。SWIFT在token级别操作，仅包含线性层，能以极少的参数和训练样本实现优于基线的性能，并具有良好的可扩展性、对闭源模型的适用性以及与现有奖励模型结合的潜力。

> **摘要翻译:** 通过Best-of-N采样增强大型语言模型（LLM）的性能是有效的，并引起了广泛关注。然而，由于大量、数据饥渴的基于文本的奖励模型，其计算成本过高。通过将数据源从文本更改为隐藏状态，我们引入了SWIFT（Simple Weighted Intrinsic Feedback Technique），这是一种新颖、轻量级的技术，它利用LLM隐藏状态中嵌入的丰富信息来解决这些问题。SWIFT在token级别操作，仅由线性层组成。大量实验表明，SWIFT在参数量不到基线0.005%的情况下，性能优于基线，并且只需少量样本即可进行训练，这表明其效率显著提高。SWIFT强大的可扩展性、通过logits适用于某些闭源模型的能力，以及与传统奖励模型结合以获得进一步性能提升的能力，都凸显了其实用价值。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [57] [SPADE-S: A Sparsity-Robust Foundational Forecaster](https://arxiv.org/abs/2507.21155)
> *SPADE-S：一种稀疏性鲁棒的基础预测器*

*Malcolm Wolff, Matthew Li, Ravi Kiran Selvam, Hanjing Zhu, Kin G. Olivares, Ruijun Ma, Abhinav Katoch, Shankar Ramasubramanian, Mengfei Cao, Roberto Bandarra, Rahul Gopalsamy, Stefania La Vattiata, Sitan Yang, Michael M. Mahoney* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-24**

**Keywords:** 时间序列预测, 稀疏性, 鲁棒性, 需求预测, 深度学习

**Comment:** 

> **TL;DR:** 现有的时间序列预测模型在处理稀疏或低幅度数据时表现不佳，因为存在偏见。SPADE-S是一种新的架构，旨在克服这些偏见，显著提高此类序列的预测精度，尤其是在需求预测方面。

**AI_Comments:** SPADE-S解决了时间序列预测中现有深度学习模型的一个关键局限性，特别是在处理稀疏和低幅度数据方面，这在零售需求等现实场景中很常见。其专注于减少系统性偏见是创新的。论文强调了显著的经验增益，证明了其实用重要性。然而，摘要中没有详细说明SPADE-S内部具体的架构创新。

<details>
  <summary>Details</summary>

**Motivation:** 尽管时间序列预测取得了显著进展，但对于幅度和/或稀疏模式具有强异质性的时间序列进行准确建模仍然是现有深度学习架构的挑战。现有模型在低幅度、稀疏时间序列上表现不佳的原因包括：对高幅度序列有隐性偏置的损失函数、训练时采样方法以及时间序列编码方法的局限性。

**Method:** SPADE-S是一种鲁棒的预测架构，旨在显著减少基于幅度和稀疏性的系统性偏见，并提高整体预测精度。

**Result:** 经验结果表明，SPADE-S在各种需求预测用例中均优于现有最先进的方法。具体而言，根据分位数预测和序列幅度，SPADE-S可以将预测精度提高高达15%。对于来自大型在线零售商的三个不同数据集（范围从300万到7亿个序列），SPADE-S在P90整体预测精度方面分别取得了2.21%、6.58%和4.28%的提升，在P50预测精度方面分别取得了0.92%、0.77%和1.95%的提升。

**Conclusion:** SPADE-S有效解决了稀疏和低幅度时间序列预测的挑战，与现有最先进的方法相比，显著提高了预测精度。

> **ai_Abstract:** SPADE-S是一种新颖的预测架构，旨在克服当前深度学习模型在处理稀疏和低幅度时间序列方面的局限性。它识别并减轻了现有模型中的系统性偏见，从而显著提高了预测精度，特别是在需求预测领域。在大型数据集上的实证结果证明了其有效性。

> **摘要翻译:** 尽管时间序列预测取得了显著进展，但对于幅度和/或稀疏模式具有强异质性的时间序列进行准确建模仍然是现有最先进深度学习架构的挑战。我们发现导致现有模型在低幅度、稀疏时间序列上系统性表现不佳的几个因素，包括对高幅度序列有隐性偏置的损失函数、训练时采样方法以及时间序列编码方法的局限性。SPADE-S是一种鲁棒的预测架构，它显著减少了基于幅度和稀疏性的系统性偏见，并提高了整体预测精度。经验结果表明，SPADE-S在各种需求预测用例中均优于现有最先进的方法。特别是，我们发现，根据分位数预测和序列的幅度，SPADE-S可以将预测精度提高高达15%。这使得来自一家大型在线零售商的三个不同数据集（范围从300万到7亿个序列）的P90整体预测精度分别提高了2.21%、6.58%和4.28%，P50预测精度分别提高了0.92%、0.77%和1.95%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [59] [Evaluation and Benchmarking of LLM Agents: A Survey](https://arxiv.org/abs/2507.21504)
> *LLM智能体的评估与基准测试：一项综述*

*Mahmoud Mohammadi, Yipeng Li, Jane Lo, Wendy Yip* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** LLM智能体, 评估, 基准测试, 综述, 分类法

**Comment:** 

> **TL;DR:** 本综述深入探讨了LLM智能体评估的复杂领域，提出了一个二维分类法，并强调了企业特有的挑战和未来的研究方向，旨在为LLM智能体的系统评估提供框架。

**AI_Comments:** 该综述性论文及时且重要，填补了LLM智能体评估领域系统性框架的空白。其提出的二维分类法有助于组织和理解现有工作，而对企业级挑战的强调则使其更具实践指导意义。这对于推动LLM智能体从理论研究走向实际应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** LLM智能体的兴起为AI应用开辟了新领域，但对其评估仍然是一个复杂且不发达的领域，现有研究碎片化，缺乏系统性框架。

**Method:** 本综述引入了一个二维分类法来组织现有工作，该分类法沿两个维度展开：(1)评估目标——评估什么（如智能体行为、能力、可靠性、安全性）和(2)评估过程——如何评估（包括交互模式、数据集和基准、指标计算方法和工具）。

**Result:** 本综述提供了一个LLM智能体评估领域的深入概述，提出了一个二维分类法，并强调了当前研究中常被忽视的企业特定挑战（如基于角色的数据访问、可靠性保证、动态和长周期交互、合规性）。此外，还指明了未来的研究方向，包括全面、更真实和可扩展的评估。

**Conclusion:** 这项工作旨在为智能体评估的碎片化现状带来清晰性，并提供一个系统评估的框架，使研究人员和从业者能够为实际部署评估LLM智能体。

> **ai_Abstract:** 本综述旨在解决LLM智能体评估领域的复杂性和碎片化问题。文章提出了一个二维分类法，从评估目标（行为、能力、可靠性、安全性）和评估过程（交互模式、数据集、指标、工具）两方面系统梳理了现有工作。此外，论文还特别指出了企业应用中面临的独特挑战，并展望了未来研究方向，旨在为LLM智能体的实际部署评估提供清晰的框架。

> **摘要翻译:** LLM智能体的兴起为AI应用开辟了新领域，但对这些智能体的评估仍然是一个复杂且不发达的领域。本综述深入概述了LLM智能体评估的新兴领域，引入了一个二维分类法，该分类法将现有工作组织为：(1)评估目标——评估什么，例如智能体行为、能力、可靠性和安全性；以及(2)评估过程——如何评估，包括交互模式、数据集和基准、指标计算方法和工具。除了分类法，我们还强调了企业特有的挑战，例如基于角色的数据访问、对可靠性保证的需求、动态和长周期交互以及合规性，这些在当前研究中常常被忽视。我们还确定了未来的研究方向，包括全面、更真实和可扩展的评估。这项工作旨在为智能体评估的碎片化现状带来清晰性，并提供一个系统评估的框架，使研究人员和从业者能够为实际部署评估LLM智能体。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [66] [LLAMAPIE: Proactive In-Ear Conversation Assistants](https://arxiv.org/abs/2505.04066)
> *LLAMAPIE: 主动式入耳对话助手*

*Tuochao Chen, Nicholas Batchelder, Alisa Liu, Noah Smith, Shyamnath Gollakota* | **Category: cs.LG, cs.CL, cs.HC, cs.SD, eess.AS** | **Updated: 2025-07-29**

**Keywords:** 对话助手, 主动式AI, 实时处理, 入耳设备, 语言模型

**Comment:** Published by ACL2025 (Findings)

> **TL;DR:** LlamaPIE是一种实时的、主动式入耳助手，通过耳戴设备提供简洁指导，无需用户明确调用即可增强对话。

**AI_Comments:** 这篇论文的创新点在于提出了第一个实时的、主动式入耳对话助手LlamaPIE，区别于传统的被动式语言模型。其双模型管道设计巧妙地解决了何时响应和如何响应的挑战，并通过设备端处理实现了实用性。用户研究结果有力地支持了主动式辅助的优越性，为未来人机交互，尤其是在对话增强领域，提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统语言模型需要用户明确调用才能工作，会打断对话。本文旨在开发一种能在后台运行、预测用户需求且不打断对话的实时主动式助手。面临的挑战包括何时响应、如何生成简洁响应、利用用户上下文知识以及实时设备端处理。

**Method:** 构建了一个半合成对话数据集。提出了一个双模型管道：一个小型模型决定何时响应，一个大型模型生成响应。在真实世界数据集上进行评估，并在Apple Silicon M2硬件上实现并进行了用户研究。

**Result:** 该方法在提供有益、不引人注目的帮助方面表现出有效性。用户研究表明，用户对主动式助手（LlamaPIE）的偏好显著高于无帮助基线和反应式模型。

**Conclusion:** LlamaPIE具有增强实时对话的巨大潜力，因为它能够主动提供帮助，且用户更偏爱这种模式。

> **ai_Abstract:** LlamaPIE是一种新颖的实时主动式入耳对话助手，通过耳戴设备提供不间断的、上下文感知的指导。它克服了传统语言模型需显式调用的局限性，采用双模型架构（一个决策模型和一个生成模型）并在半合成数据集上训练。实验证明，LlamaPIE能有效提供有益且不显眼的帮助，用户研究也显示其相比无帮助和反应式模型具有显著优势，预示其在增强实时对话方面的巨大潜力。

> **摘要翻译:** 我们介绍了LlamaPIE，这是第一个实时主动式助手，旨在通过耳戴设备提供的谨慎、简洁的指导来增强人类对话。与需要明确用户调用的传统语言模型不同，该助手在后台运行，预测用户需求而不会中断对话。我们解决了几个挑战，包括确定何时响应、制作增强对话的简洁响应、利用用户知识进行上下文感知辅助以及实时、设备端处理。为了实现这一点，我们构建了一个半合成对话数据集，并提出了一个双模型管道：一个决定何时响应的小型模型和一个生成响应的较大模型。我们在真实世界数据集上评估了我们的方法，证明了其在提供有益、不引人注目的帮助方面的有效性。在Apple Silicon M2硬件上实现的助手用户研究表明，与无帮助基线和反应式模型相比，用户对主动式助手表现出强烈偏好，突显了LlamaPie增强实时对话的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [72] [Learning from Limited and Imperfect Data](https://arxiv.org/abs/2507.21205)
> *从有限和不完美数据中学习*

*Harsh Rangwani* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-28**

**Keywords:** 长尾学习, 不完美数据, 域适应, 半监督学习, 生成模型

**Comment:** PhD Thesis

> **TL;DR:** 本论文旨在开发实用的深度神经网络算法，以应对真实世界中有限和不完美数据（如长尾分布、分布偏移、标注稀缺）带来的挑战，共分为四个部分，涵盖生成模型、归纳正则化、度量优化和域适应。

**AI_Comments:** 该论文着眼于深度学习在真实世界应用中的一个核心挑战——数据质量和数量的限制。其创新性在于系统地提出了针对不同“不完美”数据场景（长尾、半监督、域适应）的解决方案，而非单一模型。这种分而治之的策略，结合生成模型、正则化和度量优化等多种技术，为克服现实数据瓶颈提供了多角度的实用方法，对于推动深度学习的实际落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 真实世界的数据（如互联网数据）与经过精心整理的数据集显著不同，常常存在长尾不平衡和分布偏移问题。当前为精心整理数据集设计的算法在处理不完美数据集时表现不佳。为了扩大深度模型的应用范围，需要开发能够从多样化、真实世界数据分布中学习的鲁棒算法，以克服劳动密集型的数据整理过程。

**Method:** 本论文开发了针对深度神经网络的实用算法，分为四个部分：1. 学习长尾数据生成模型，以减轻模式崩溃并实现尾部类别的多样化图像生成。2. 通过归纳正则化方案，使尾部类别能够有效地泛化。3. 开发用于优化相关指标的算法，以学习有限标注的长尾数据（半监督）。4. 专注于模型对具有少量或零标注样本的各种领域的有效域适应。

**Result:** 开发了能够从有限和不完美数据中学习的实用深度神经网络算法。具体成果包括：减轻长尾数据生成模型中的模式崩溃，实现尾部类别的多样化图像生成；通过归纳正则化方案实现尾部类别的有效泛化；开发了用于半监督长尾数据学习的相关度量优化算法；实现了模型对具有少量或零标注样本的各种领域的有效域适应。

**Conclusion:** 本论文通过开发一系列针对有限和不完美数据的深度学习算法，旨在克服真实世界数据分布带来的挑战，从而扩展深度模型在实际应用中的潜力。

> **ai_Abstract:** 本论文致力于解决深度学习模型在真实世界中有限和不完美数据（如长尾分布、分布偏移、标注稀缺）上的性能挑战。作者开发了一系列实用的深度神经网络算法，涵盖了四个主要方面：一是针对长尾数据的生成模型学习，以改善模式崩溃和多样性；二是通过归纳正则化提升尾部类别的泛化能力；三是为半监督长尾数据优化相关学习度量；四是实现模型在极少标注样本情况下的高效域适应。这些工作旨在使深度模型更能适应复杂多变的真实数据环境。

> **摘要翻译:** 世界上数据（例如互联网等）的分布与精心整理的数据集显著不同，并且常常被常见类别样本过度填充。为精心整理数据集设计的算法在用于从具有长尾不平衡和分布偏移的不完美数据集中学习时表现不佳。为了扩展深度模型的应用，通过开发能够从多样化、真实世界数据分布中学习的鲁棒算法来克服劳动密集型的数据整理过程至关重要。为此，我们开发了实用的深度神经网络算法，可以从真实世界中有限和不完美的数据中学习。本论文分为四个部分，每个部分涵盖一种从有限或不完美数据中学习的场景。论文的第一部分侧重于从长尾数据中学习生成模型，我们在此减轻了模式崩溃，并使尾部（少数）类别能够生成多样化的美学图像。在第二部分，我们通过归纳正则化方案实现了尾部类别的有效泛化，这使得尾部类别能够像头部类别一样有效地泛化，而无需显式生成图像。在第三部分，我们开发了用于从有限标注（半监督）的长尾数据中学习的相关度量优化算法，随后是第四部分，该部分侧重于模型对具有极少或零标注样本的各种领域的有效域适应。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [73] [Teach Me to Trick: Exploring Adversarial Transferability via Knowledge Distillation](https://arxiv.org/abs/2507.21992)
> *教我欺骗：通过知识蒸馏探索对抗性迁移能力*

*Siddhartha Pradhan, Shikshya Shiwakoti, Neha Bathuri* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 知识蒸馏, 对抗样本, 迁移性, 黑盒攻击, 模型压缩

**Comment:** 10 pages, 4 figures

> **TL;DR:** 本文研究了如何利用多异构教师模型的知识蒸馏来增强可迁移对抗样本的生成，并发现其在攻击成功率和效率上与集成方法相当。

**AI_Comments:** 本文的创新点在于首次将知识蒸馏技术应用于增强对抗样本的迁移能力，并证明了其在效率和攻击效果上的优越性。通过利用多教师模型和特定的KD策略，该研究为黑盒对抗攻击提供了一种高效且有效的生成对抗样本的新范式，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探究来自多个异构教师模型的知识蒸馏能否增强可迁移对抗样本的生成。

**Method:** 研究人员使用两种知识蒸馏策略（基于课程的切换和联合优化）训练了一个轻量级学生模型，教师模型为ResNet50和DenseNet-161。然后，使用训练好的学生模型通过FG、FGS和PGD攻击生成对抗样本，并针对黑盒目标模型（GoogLeNet）进行评估。此外，还进行了消融研究以分析不同设置的影响。

**Result:** 学生模型从多个教师蒸馏后，其攻击成功率与基于集成的基线模型相当，同时将对抗样本生成时间缩短了六倍。消融研究进一步表明，较低的温度设置和硬标签监督的引入显著增强了迁移能力。

**Conclusion:** 这些发现表明，知识蒸馏不仅可以作为一种模型压缩技术，还可以作为一种强大的工具，用于提高黑盒对抗性攻击的效率和有效性。

> **ai_Abstract:** 本研究探讨了利用多教师知识蒸馏（KD）技术增强对抗样本的迁移能力。通过训练一个轻量级学生模型，并采用课程切换和联合优化两种KD策略，以ResNet50和DenseNet-161为教师模型，研究人员成功生成了可迁移的对抗样本。实验结果表明，该方法在攻击成功率上可与集成方法媲美，且显著缩短了对抗样本生成时间。研究还发现，低温设置和硬标签监督对提升迁移性至关重要，揭示了KD在提升黑盒对抗攻击效率和有效性方面的潜力。

> **摘要翻译:** 我们研究了来自多个异构教师模型的知识蒸馏（KD）是否可以增强可迁移对抗样本的生成。使用两种KD策略：基于课程的切换和联合优化，训练了一个轻量级学生模型，其中ResNet50和DenseNet-161作为教师模型。然后，使用训练好的学生模型通过FG、FGS和PGD攻击生成对抗样本，并针对黑盒目标模型（GoogLeNet）进行评估。我们的结果表明，从多个教师蒸馏而来的学生模型，其攻击成功率与基于集成的基线模型相当，同时将对抗样本生成时间缩短了六倍。一项消融研究进一步揭示，较低的温度设置和硬标签监督的引入显著增强了迁移能力。这些发现表明，KD不仅可以作为一种模型压缩技术，还可以作为一种强大的工具，用于提高黑盒对抗性攻击的效率和有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [89] [Addressing Representation Collapse in Vector Quantized Models with One Linear Layer](https://arxiv.org/abs/2411.02038)
> *使用一个线性层解决向量量化模型中的表示崩溃问题*

*Yongxin Zhu, Bocheng Li, Yifei Xin, Zhihua Xia, Linli Xu* | **Category: cs.LG, cs.CV, cs.SD, eess.AS** | **Updated: 2025-07-30**

**Keywords:** 向量量化, 表示崩溃, 线性层, SimVQ, 码本利用率

**Comment:** Accepted at ICCV2025

> **TL;DR:** SimVQ通过引入一个线性层重新参数化码向量，优化整个线性空间而非单个码向量，有效解决了向量量化中的表示崩溃问题，提高了码本利用率。

**AI_Comments:** SimVQ的创新之处在于其通过一个简单的线性层来重新参数化码向量，从而优化整个线性空间，这与传统方法优化单个码向量不同。这种简单而有效的解决方案避免了现有复杂优化或牺牲模型容量的问题，展现了其在解决表示崩溃问题上的重要性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 向量量化（VQ）在无监督学习中离散化连续表示至关重要，但存在表示崩溃问题，导致码本利用率低并限制了可扩展性。现有解决方案复杂或牺牲模型容量，未能完全解决问题。

**Method:** 本研究提出SimVQ，通过在潜在基上引入一个可学习的线性变换层来重新参数化码向量。这种方法优化的是整个线性空间，而非最近的单个码向量。尽管两个线性矩阵的乘法等同于应用一个单一线性层，但这种简单方法有效防止了崩溃。

**Result:** 在图像和音频任务上的大量实验表明，SimVQ提高了码本利用率，易于实现，并且在不同模态和架构之间具有良好的泛化能力。

**Conclusion:** SimVQ通过一种简单而有效的方法解决了向量量化中的表示崩溃问题，提高了模型性能和泛化能力。

> **ai_Abstract:** 本文针对向量量化（VQ）中普遍存在的表示崩溃问题，提出了一种名为SimVQ的新方法。该方法将码向量通过一个线性变换层重新参数化，从而优化整个线性空间而非仅更新少数码向量。实验证明，SimVQ有效提高了码本利用率，易于实现，并在图像和音频任务上展现出良好的跨模态和架构泛化能力，解决了现有复杂方案的不足。

> **摘要翻译:** 向量量化（VQ）在无监督学习中对于离散化连续表示至关重要，但它面临表示崩溃问题，导致码本利用率低下并限制了可扩展性。现有解决方案通常依赖于复杂的优化或减少潜在维度，这会损害模型容量且未能完全解决问题。我们确定根本原因是分离的码本优化，其中只有少数码向量通过梯度下降进行更新。为了解决这个问题，我们提出了\textbf{Sim}ple\textbf{VQ}，它通过一个可学习的线性变换层在潜在基上重新参数化码向量，优化\textit{整个线性空间}而不是最近的\textit{单个码向量}。尽管两个线性矩阵的乘法等同于应用一个单一线性层，但这种简单方法有效地防止了崩溃。在图像和音频任务上的大量实验表明，SimVQ提高了码本使用率，易于实现，并且在不同模态和架构之间具有良好的泛化性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [90] [Position: Adopt Constraints Over Penalties in Deep Learning](https://arxiv.org/abs/2505.20628)
> *立场：在深度学习中采用约束而非惩罚*

*Juan Ramirez, Meraj Hashemizadeh, Simon Lacoste-Julien* | **Category: cs.LG, math.OC** | **Updated: 2025-07-28**

**Keywords:** 深度学习, 约束优化, 惩罚项, 拉格朗日方法, 可信AI

**Comment:** Code available at
  https://github.com/merajhashemi/constraints-vs-penalties

> **TL;DR:** 本文认为在深度学习中，通过惩罚项来强制执行约束是无效的，因为它无法同时保证约束满足和最优性能，且需要昂贵的调优。作者提倡采用拉格朗日方法等定制的约束优化方法，这些方法能真正解决约束问题，消除调优需求，并无缝集成。

**AI_Comments:** 本文提出了一种重要的范式转变，即从在深度学习中通过惩罚项强制执行约束转向采用更原则性的约束优化方法。其创新之处在于明确指出了惩罚方法的局限性，并强调了拉格朗日方法等替代方案在解决约束问题、提高效率和集成度方面的优势。这对于构建可信赖的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习中通过惩罚项来强制执行外部需求（约束）的方法存在根本性缺陷。这种方法可能无法同时确保约束满足和最优受限性能，且需要耗时的试错来调优惩罚系数，导致时间与计算开销。

**Method:** 提倡更广泛地采用定制的约束优化方法，例如拉格朗日方法。该方法能联合优化惩罚“系数”（拉格朗日乘数）和模型参数。

**Result:** 采用定制的约束优化方法（如拉格朗日方法）能够：(i) 真正解决约束问题，并通过明确定义可行性并验证其何时实现来负责任地解决问题；(ii) 消除对大量惩罚项调优的需求；(iii) 与现代深度学习流程无缝集成。

**Conclusion:** 在深度学习中，应采用定制的约束优化方法而非惩罚项来强制执行约束，以实现真正的约束满足、优化性能并提高效率。

> **ai_Abstract:** 本文指出，在深度学习中，通过添加固定权重惩罚项来强制执行约束的方法存在固有限制，因为它难以同时实现约束满足和最优性能，并带来高昂的调优成本。作者主张转向采用拉格朗日方法等定制的约束优化技术。这些方法能够有效解决约束问题，消除繁琐的参数调优，并能与现有深度学习框架良好融合，从而为开发更可靠、高效的AI系统提供途径。

> **摘要翻译:** 最近旨在开发具有问责制保证的可信人工智能系统的努力，导致了广泛使用结合外部需求或约束的机器学习公式。这些需求通常通过惩罚来强制执行——即向任务损失中添加固定权重的项。我们认为这种方法从根本上不适合，因为可能没有一个惩罚系数能同时确保约束满足和最优受限性能，即无法真正解决约束问题。此外，调整这些系数需要昂贵的试错，导致显著的时间和计算开销。因此，我们提倡更广泛地采用定制的约束优化方法——例如拉格朗日方法，它联合优化惩罚“系数”（拉格朗日乘数）和模型参数。此类方法(i)真正解决了约束问题，并通过明确定义可行性并验证其何时实现来负责任地解决；(ii)消除了对大量惩罚项调优的需求；(iii)与现代深度学习流程无缝集成。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [95] [TolerantECG: A Foundation Model for Imperfect Electrocardiogram](https://arxiv.org/abs/2507.09887)
> *TolerantECG：一种用于不完美心电图的基础模型*

*Huynh Dang Nguyen, Trong-Thang Pham, Ngan Le, Van Nguyen* | **Category: cs.LG, cs.AI, eess.SP** | **Updated: 2025-07-29**

**Keywords:** 心电图, 基础模型, 噪声鲁棒性, 导联缺失, 自监督学习

**Comment:** Accepted at ACM MM 2025

> **TL;DR:** TolerantECG是一个心电图基础模型，通过结合对比学习和自监督学习，能够有效处理噪声和导联缺失的心电图数据，并在多个数据集上表现出色。

**AI_Comments:** 该论文的创新点在于提出了一个能够处理不完美ECG数据（噪声和导联缺失）的基础模型，并通过结合对比学习和自监督学习来提升其鲁棒性和泛化能力。这对于临床实践中ECG数据的复杂性具有重要意义，有望提高诊断的准确性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 心电图（ECG）的有效性常因噪声或标准12导联记录中一个或多个导联的不可用而受损，导致诊断错误或不确定性。

**Method:** 提出了TolerantECG，一个对噪声具有鲁棒性并能处理任意子集12导联ECG信号的基础模型。其训练结合了对比学习和自监督学习框架，共同学习ECG信号表示、文本报告描述以及损坏或导联缺失的信号。

**Result:** TolerantECG在PTB-XL数据集中各种ECG信号条件和类别级别上始终排名第一或第二，并在MIT-BIH心律失常数据库上取得了最高性能。

**Conclusion:** TolerantECG模型有效解决了不完美心电图数据（噪声、导联缺失）的挑战，并在诊断方面表现出卓越的性能。

> **ai_Abstract:** TolerantECG是一个针对不完美心电图（ECG）信号的基础模型，旨在解决ECG诊断中因噪声和导联缺失导致的问题。该模型结合了对比学习和自监督学习，能够鲁棒地处理噪声并适应任意导联子集。在PTB-XL和MIT-BIH心律失常数据库上的测试结果表明，TolerantECG在多种条件下表现优异，达到最佳或次佳性能。

> **摘要翻译:** 心电图（ECG）是诊断心脏疾病的重要且有效的工具。然而，其有效性可能会因噪声或标准12导联记录中一个或多个导联的不可用而受到影响，从而导致诊断错误或不确定性。为了解决这些挑战，我们提出了TolerantECG，一个针对ECG信号的基础模型，它对噪声具有鲁棒性，并且能够使用标准12导联ECG的任意子集进行工作。TolerantECG的训练结合了对比学习和自监督学习框架，以共同学习ECG信号表示及其相应的基于知识检索的文本报告描述以及损坏或导联缺失的信号。全面的基准测试结果表明，TolerantECG在PTB-XL数据集中各种ECG信号条件和类别级别上始终排名第一或第二，并在MIT-BIH心律失常数据库上取得了最高性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [99] [Capacity-Constrained Continual Learning](https://arxiv.org/abs/2507.21479)
> *容量受限的持续学习*

*Zheng Wen, Doina Precup, Benjamin Van Roy, Satinder Singh* | **Category: cs.LG, cs.AI, cs.IT, cs.SY, eess.SY, math.IT, stat.ML** | **Updated: 2025-07-29**

**Keywords:** 持续学习, 容量约束, 资源分配, LQG问题, 序列预测

**Comment:** 

> **TL;DR:** 本文研究了在容量限制下，智能体如何优化资源分配以实现最优性能，并针对容量受限的线性二次高斯（LQG）序列预测问题给出了解决方案。

**AI_Comments:** 本文开辟了在资源受限环境下进行持续学习的理论研究。其创新点在于将容量约束引入持续学习框架，并提供了具体问题的解决方案。这项工作对于理解和设计更实际、高效的AI系统具有重要意义，因为它承认了现实世界中资源有限的普遍性。

<details>
  <summary>Details</summary>

**Motivation:** 任何智能体都受限于有限的内存和计算资源，但目前对于有限容量智能体如何最优分配资源以获得最佳性能的研究相对较少。本文旨在探讨这一问题。

**Method:** 通过研究一个简单但相关的持续学习问题：容量受限的线性二次高斯（LQG）序列预测问题。在适当的技术条件下推导了该问题的解决方案。对于可分解为子问题的问题，还展示了如何在稳态下在这些子问题之间最优分配容量。

**Result:** 在适当的技术条件下，本文推导出了容量受限的线性二次高斯（LQG）序列预测问题的解决方案。此外，对于可分解的子问题，还展示了如何在稳态下最优分配容量。

**Conclusion:** 本文的研究结果是系统理论研究容量限制下学习的第一步。

> **ai_Abstract:** 本文探讨了在有限内存和计算资源下，智能体如何优化资源分配以实现最佳性能的持续学习问题。研究聚焦于容量受限的线性二次高斯（LQG）序列预测问题，并在特定条件下给出了解决方案。此外，论文还展示了在可分解的子问题中，如何在稳态下进行最优容量分配。这项工作被视为在容量约束下进行学习的系统理论研究的开端。

> **摘要翻译:** 我们可能构建的任何智能体都受到容量限制，因为内存和计算资源本质上是有限的。然而，对于容量有限的智能体应如何分配其资源以实现最佳性能，目前关注相对较少。本文的目标是通过研究一个简单但相关的持续学习问题：容量受限的线性二次高斯（LQG）序列预测问题，来阐明这个问题。我们在适当的技术条件下推导了该问题的解决方案。此外，对于可以分解为一组子问题的问题，我们还展示了如何在稳态下在这些子问题之间最优分配容量。我们将本文的结果视为系统理论研究容量限制下学习的第一步。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [106] [Handling Out-of-Distribution Data: A Survey](https://arxiv.org/abs/2507.21160)
> *处理分布外数据：一项综述*

*Lakpa Tamang, Mohamed Reda Bouadjenek, Richard Dazeley, Sunil Aryal* | **Category: cs.LG, cs.AI, 68T07 (Primary), 68T45, 68T10 (Secondary), I.5.1** | **Updated: 2025-07-25**

**Keywords:** 分布偏移, 协变量偏移, 概念偏移, 分布外数据, 机器学习综述

**Comment:** 20 pages, 6 figures, 6 tables. Accepted at IEEE Transactions on
  Knowledge and Data Engineering

> **TL;DR:** 本文综述了机器学习中处理分布偏移（协变量偏移和概念偏移）的现有方法，并提出了未来的研究方向。

**AI_Comments:** 这是一篇重要的综述性文章，系统地梳理了机器学习中分布偏移问题，并首次将OOD数据作为重点纳入综述，填补了现有文献的空白，对该领域的未来研究具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习和数据驱动应用中，训练和部署阶段数据分布的变化（分布偏移）是一个重大挑战。传统方法难以充分处理这些问题，因此需要能同时处理所有类型分布偏移的模型。

**Method:** 本文通过综述形式，首先形式化定义了分布偏移，讨论了传统方法的不足；其次，广泛回顾了现有检测、测量和缓解分布偏移的方法和技术；最后，讨论了当前的处理机制并提出了未来研究方向。

**Result:** 本文总结了三方面贡献：形式化定义了分布偏移并指出传统方法不足；广泛回顾了现有检测、测量和缓解分布偏移的方法；讨论了当前处理机制并提出了未来研究方向。尤其关注了现有综述中被忽视的OOD数据。

**Conclusion:** 本文回顾了分布偏移领域的文献，尤其关注了现有综述中被忽视的分布外数据，并提出了未来的研究方向。

> **ai_Abstract:** 本文综述了机器学习中处理分布偏移（包括协变量偏移和概念/语义偏移）的挑战与现有方法。文章首先形式化定义了分布偏移，指出传统方法的局限性，并呼吁开发更通用的模型。接着，详细回顾了用于检测、测量和缓解分布偏移的各种技术，并讨论了当前处理机制的现状。最后，提出了该领域的未来研究方向，特别关注了现有综述中较少涉及的分布外数据。

> **摘要翻译:** 在机器学习（ML）和数据驱动应用领域，一个重大挑战是训练和部署阶段之间数据分布的变化，通常称为分布偏移。本文概述了处理两种主要分布偏移的不同机制：(i) 协变量偏移：训练和测试数据之间特征或协变量的值发生变化；(ii) 概念/语义偏移：由于测试阶段出现新类别，模型在训练期间学到的概念发生偏移。我们的贡献总结为三方面。首先，我们形式化了分布偏移，回顾了传统方法如何未能充分处理它们，并呼吁开发一种能够同时在所有类型分布偏移中表现更好的模型。其次，我们讨论了处理分布偏移的重要性，并对已开发的用于检测、测量和缓解这些偏移影响的方法和技术进行了广泛综述。第三，我们讨论了分布偏移处理机制的现状，并提出了该领域的未来研究方向。总的来说，我们提供了分布偏移文献的回顾性概述，重点关注了现有综述中被忽视的分布外（OOD）数据。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [115] [Hierarchical Stochastic Differential Equation Models for Latent Manifold Learning in Neural Time Series](https://arxiv.org/abs/2507.21531)
> *神经时间序列中潜在流形学习的分层随机微分方程模型*

*Pedram Rajaei, Maryam Ostadsharif Memar, Navid Ziaei, Behzad Nazari, Ali Yousefi* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 分层SDE, 潜在流形学习, 神经时间序列, 布朗桥, 计算效率

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的分层随机微分方程（SDE）模型，用于神经时间序列中的潜在流形学习，旨在平衡计算效率和可解释性，并有效处理复杂时间序列数据。

**AI_Comments:** 该论文的创新之处在于提出了分层随机微分方程模型，并利用布朗桥SDE来建模潜在空间，以期在计算效率和模型可解释性之间取得平衡。其推断计算成本与观测数据长度呈线性关系的特性，在处理大规模神经时间序列数据时具有显著的实际应用价值和效率优势。

<details>
  <summary>Details</summary>

**Motivation:** 流形假设认为高维神经时间序列位于由更简单底层动力学形成的低维流形上。现有的潜在动力学变量模型（如状态空间模型、循环神经网络、神经常微分方程和高斯过程潜在变量模型）在平衡计算效率和可解释性方面存在局限性，因此需要一种新的方法来揭示这种结构。

**Method:** 本文提出了一种新颖的分层随机微分方程（SDE）模型。该模型假设流形轨迹可以从稀疏的流形轨迹样本中重建。潜在空间使用布朗桥SDE进行建模，其中点（在时间和值上指定）从多元标记点过程采样。这些布朗桥定义了第二组SDE的漂移，然后将其映射到观测数据。这产生了一个连续、可微分的潜在过程，能够随着流形点数量的增加建模任意复杂的时间序列。

**Result:** 推断的计算成本与观测数据的长度呈线性关系。该模型在合成数据和神经记录上都得到了验证，结果表明它能准确恢复底层流形结构，并能有效地随数据维度扩展。

**Conclusion:** 本文提出的分层随机微分方程模型能够准确恢复底层流形结构并有效扩展，成功地在计算效率和可解释性之间取得了平衡，为神经时间序列中的潜在流形学习提供了一种有效的新方法。

> **ai_Abstract:** 本文提出了一种新颖的分层随机微分方程（SDE）模型，用于高维神经时间序列中的潜在流形学习。该模型通过假设流形轨迹可从稀疏样本重建，利用布朗桥SDE建模潜在空间，并将其漂移作为第二组SDE的输入，最终映射到观测数据。这种方法生成了一个连续、可微分的潜在过程，能够建模复杂时间序列。研究表明，其推断计算成本与数据长度呈线性关系，并在合成数据和神经记录上成功恢复了底层流形结构，展现出良好的可扩展性，解决了现有方法的效率与可解释性权衡问题。

> **摘要翻译:** 流形假设表明，高维神经时间序列位于由更简单的底层动力学形成的低维流形上。为了揭示这种结构，潜在动力学变量模型，如状态空间模型、循环神经网络、神经常微分方程和高斯过程潜在变量模型被广泛使用。我们提出了一种新颖的分层随机微分方程（SDE）模型，它平衡了计算效率和可解释性，解决了现有方法的关键局限性。我们的模型假设流形轨迹可以从流形轨迹的稀疏样本集中重建。潜在空间使用布朗桥SDE进行建模，其中点——在时间和值上都指定——从多元标记点过程采样。这些布朗桥定义了第二组SDE的漂移，然后将其映射到观测数据。这产生了一个连续、可微分的潜在过程，能够随着流形点数量的增加建模任意复杂的时间序列。我们推导了训练和推断过程，并表明推断的计算成本与观测数据的长度呈线性关系。然后，我们在合成数据和神经记录上验证了我们的模型，以证明它准确地恢复了底层流形结构，并有效地随数据维度扩展。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [116] [Classification of Honey Botanical and Geographical Sources using Mineral Profiles and Machine Learning](https://arxiv.org/abs/2507.22032)
> *使用矿物质成分和机器学习对蜂蜜植物源和地理来源进行分类*

*Mokhtar Al-Awadhi, Ratnadeep Deshmukh* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 蜂蜜分类, 矿物质成分, 机器学习, 随机森林, 植物源, 地理来源

**Comment:** 13 pages, 7 figures, conference paper

> **TL;DR:** 本文利用机器学习和矿物质特征对蜂蜜的植物源和地理来源进行分类，随机森林表现最佳。

**AI_Comments:** 本文创新性地结合蜂蜜矿物质成分与机器学习进行来源分类，并取得了高精度结果，对蜂蜜溯源具有重要意义。但其泛化能力可能需要更多数据集验证。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种基于机器学习的方法，利用矿物质成分识别蜂蜜的植物源和地理来源。

**Method:** 该方法包括预处理（缺失值处理和数据归一化）和分类两个步骤。分类阶段使用了各种监督分类模型，并在公开数据集上测试，其中随机森林（RF）分类器表现最佳。

**Result:** 蜂蜜中的矿物质含量为分类提供了判别信息。随机森林分类器对蜂蜜植物源分类的交叉验证准确率为99.30%，对地理来源分类的准确率为98.01%。

**Conclusion:** 蜂蜜矿物质成分结合机器学习，特别是随机森林，能有效识别蜂蜜的植物源和地理来源。

> **ai_Abstract:** 本文提出了一种利用矿物质成分和机器学习对蜂蜜植物源和地理来源进行分类的方法。该方法包括数据预处理（缺失值处理、数据归一化）和使用监督分类模型进行分类。在公开数据集上测试结果显示，蜂蜜中的矿物质含量具有判别性。随机森林分类器表现最佳，对植物源分类准确率达99.30%，对地理来源分类准确率达98.01%。

> **摘要翻译:** 本文提出了一种基于机器学习的方法，利用矿物质元素谱识别蜂蜜的植物源和地理来源。所提出的方法包括两个步骤：预处理和分类。预处理阶段涉及缺失值处理和数据归一化。在分类阶段，我们采用各种监督分类模型来区分蜂蜜的六种植物源和13种地理来源。我们在一个公开可用的蜂蜜矿物质元素数据集上测试了分类器的性能。该数据集包含来自不同植物源和地理来源的蜂蜜的矿物质元素谱。结果表明，蜂蜜中的矿物质元素含量提供了有用的判别信息，可用于分类蜂蜜的植物源和地理来源。结果还表明，随机森林（RF）分类器在该数据集上获得了最佳性能，对蜂蜜植物源分类的交叉验证准确率为99.30%，对蜂蜜地理来源分类的准确率为98.01%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [122] [Inducing Causal World Models in LLMs for Zero-Shot Physical Reasoning](https://arxiv.org/abs/2507.19855)
> *在大型语言模型中引入因果世界模型以实现零样本物理推理*

*Aditya Sharma, Linh Nguyen, Ananya Gupta, Chengyu Wang, Chiamaka Adebayo, Jakub Kowalski* | **Category: cs.LG, cs.HC, 68T05, 68T07, 68T40, I.2.6; I.2.9; I.2.7; I.2.10; H.5.2** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 因果推理, 物理世界模型, 零样本学习, 多模态数据

**Comment:** 12 pages, 4 figures,

> **TL;DR:** 本文提出CWMI框架，通过引入因果物理模块和因果干预损失，使LLM学习因果关系并预测干预结果，从而在零样本物理推理任务上显著优于现有模型。

**AI_Comments:** 这项工作通过引入显式的因果物理模块和创新的训练目标（因果干预损失），有效地解决了LLM在物理因果推理方面的根本性缺陷。其创新之处在于从预测统计相关性转向预测干预结果，这有助于构建更接近人类认知模式的物理世界理解。该研究为提高AI系统在现实世界中的可靠性和泛化能力提供了重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）尽管具有先进的语言能力，但从根本上缺乏对物理动力学的直观理解，这限制了它们在需要因果推理的现实世界场景中的有效性。

**Method:** 本文引入了因果世界模型归纳（CWMI）框架，旨在LLM中嵌入显式的因果物理模型。该方法包含一个专门的因果物理模块（CPM）和一个新的训练目标——因果干预损失，鼓励模型从多模态数据中学习因果关系。通过训练模型预测假设干预的结果，而非仅仅捕获统计相关性，CWMI发展出对物理定律的稳健内部表征。

**Result:** 实验结果表明，CWMI在零样本物理推理任务上显著优于最先进的LLM，包括PIQA基准和新提出的PhysiCa-Bench数据集。

**Conclusion:** 引入因果世界模型是迈向更可靠、更通用AI系统的关键一步。

> **ai_Abstract:** 本文提出因果世界模型归纳（CWMI）框架，旨在解决大型语言模型（LLM）在物理因果推理方面的不足。CWMI通过引入因果物理模块（CPM）和因果干预损失，使LLM能够从多模态数据中学习因果关系，并预测假设干预的结果，而非仅捕捉统计相关性。实验证明，CWMI在零样本物理推理任务上表现出色，显著超越现有最先进的LLM，强调了构建因果世界模型对提升AI系统可靠性和泛化能力的重要性。

> **摘要翻译:** 大型语言模型（LLM）尽管具有先进的语言能力，但从根本上缺乏对物理动力学的直观理解，这限制了它们在需要因果推理的现实世界场景中的有效性。在本文中，我们介绍了因果世界模型归纳（CWMI），这是一个旨在LLM中嵌入显式因果物理模型的新颖框架。我们的方法结合了一个专门的因果物理模块（CPM）和一个新的训练目标，称为因果干预损失，鼓励模型从多模态数据中学习因果关系。通过训练模型预测假设干预的结果，而不是仅仅捕获统计相关性，CWMI发展出对物理定律的稳健内部表征。实验结果表明，CWMI在零样本物理推理任务上显著优于最先进的LLM，包括PIQA基准和我们新提出的PhysiCa-Bench数据集。这些发现表明，引入因果世界模型是迈向更可靠、更通用AI系统的关键一步。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [125] [Adversarial bandit optimization for approximately linear functions](https://arxiv.org/abs/2505.20734)
> *对近似线性函数的对抗性强盗优化*

*Zhuoyu Cheng, Kohei Hatano, Eiji Takimoto* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 对抗性强盗优化, 线性函数, 遗憾界, 非凸, 非光滑

**Comment:** 

> **TL;DR:** 研究了非凸非光滑函数在对抗性扰动下的强盗优化问题，得到了期望和高概率遗憾界，并改进了线性强盗优化的遗憾界，同时给出了期望遗憾的下界。

**AI_Comments:** 这项研究通过考虑线性函数与任意扰动相结合的强盗优化问题，扩展了现有理论，为理解更复杂的非凸非光滑优化场景提供了新的理论工具。其创新性在于对扰动项的处理以及对遗憾界更精确的刻画，对实际应用中存在噪声或不确定性的决策过程具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决一类非凸非光滑函数下的强盗优化问题，其中损失函数是线性函数和任意小扰动的和。

**Method:** 提出了期望和高概率遗憾界，并给出了期望遗憾的下界。

**Result:** 得到了问题的期望和高概率遗憾界；改进了无扰动特殊情况（强盗线性优化）下的高概率遗憾界。

**Conclusion:** 研究了带有小扰动的近似线性函数的对抗性强盗优化问题，并提供了其遗憾界和下界，同时对无扰动的特殊情况给出了改进的结果。

> **ai_Abstract:** 本文研究了针对非凸非光滑函数的对抗性强盗优化问题，其损失函数由线性部分和对抗性选择的微小扰动组成。研究人员推导了该问题的期望和高概率遗憾界，并进一步改进了无扰动情况下（即强盗线性优化）的高概率遗憾界。此外，论文还给出了期望遗憾的下界。

> **摘要翻译:** 我们考虑了非凸非光滑函数的强盗优化问题，其中在每次试验中，损失函数是线性函数和在观察到玩家选择后选定的一个微小但任意扰动的总和。我们为该问题提供了期望遗憾界和高概率遗憾界。我们的结果也意味着对强盗线性优化（没有扰动的特殊情况）的改进的高概率遗憾界。我们还给出了期望遗憾的下界。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [129] [Bubbleformer: Forecasting Boiling with Transformers](https://arxiv.org/abs/2507.21244)
> *气泡生成器：利用Transformer预测沸腾*

*Sheikh Md Shakeel Hassan, Xianwei Zou, Akash Dhruv, Vishwanath Ganesan, Aparna Chandramowlishwaran* | **Category: cs.LG, cs.AI, cs.CE** | **Updated: 2025-07-28**

**Keywords:** 沸腾预测, Transformer, 两相流, 核化, 时空模型

**Comment:** 39 pages, 13 figures, Submitted to NeurIPS 2025

> **TL;DR:** 提出Bubbleformer，一个基于Transformer的模型，用于在不依赖未来输入的情况下预测沸腾动力学，解决了现有模型在核化学习和流体沸腾建模上的局限性，并在两相沸腾流预测中取得了新的基准成果。

**AI_Comments:** 这篇论文通过引入Transformer架构来解决复杂的沸腾现象预测问题，具有显著的创新性。它克服了传统模型在自主预测和处理复杂流体动力学方面的局限，特别是无需未来输入和对多相流体泛化的能力。新提出的物理指标和高保真数据集BubbleML 2.0的发布，也为该领域的研究提供了宝贵的工具和资源，有望推动两相流体建模领域的重大进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的神经网络PDE代理模型在建模沸腾这一固有的混沌多相过程时面临巨大挑战。它们在推理过程中需要未来的输入（例如气泡位置），因为它们无法从过去的状态中学习核化，限制了自主预测沸腾动态的能力。此外，它们也无法模拟流动沸腾速度场，其中尖锐的界面-动量耦合需要长距离和方向性的归纳偏差。

**Method:** 本文提出了Bubbleformer，一个基于Transformer的时空模型，用于预测稳定和长距离的沸腾动力学，包括核化、界面演化和传热，且在推理过程中不依赖模拟数据。Bubbleformer集成了分解轴向注意力、频率感知缩放以及热物理参数条件，以泛化到不同的流体、几何形状和操作条件。

**Result:** 为了评估混沌系统中的物理保真度，本文提出了可解释的基于物理的指标，用于评估热通量一致性、界面几何形状和质量守恒。同时，发布了BubbleML 2.0，这是一个高保真数据集，涵盖了多种工作流体、沸腾配置、流态和边界条件。Bubbleformer在两相沸腾流的预测和预报方面都取得了新的基准结果。

**Conclusion:** Bubbleformer成功地克服了现有模型在预测沸腾动力学方面的局限性，通过其创新的Transformer架构实现了自主、稳定和长距离的沸腾预测，并在关键物理指标和实际应用中展现出卓越的性能，为两相流体建模提供了新的范例。

> **ai_Abstract:** 本文介绍了Bubbleformer，一个基于Transformer的时空模型，旨在克服现有模型在预测沸腾动力学方面的局限性。它能自主预测包括核化、界面演化和传热在内的稳定长距离沸腾动态，无需推理时依赖模拟数据。Bubbleformer通过集成分解轴向注意力、频率感知缩放和热物理参数条件，实现了对不同流体、几何形状和操作条件的泛化。为评估模型性能，论文提出了新的物理指标，并发布了高保真数据集BubbleML 2.0。实验结果表明，Bubbleformer在两相沸腾流的预测和预报上达到了新的基准。

> **摘要翻译:** 建模沸腾（一种固有的混沌多相过程，是能源和热系统的核心）对神经网络PDE代理模型来说仍然是一个重大挑战。现有模型在推理过程中需要未来的输入（例如气泡位置），因为它们无法从过去的状态中学习核化，这限制了它们自主预测沸腾动态的能力。它们也无法模拟流动沸腾速度场，其中尖锐的界面-动量耦合需要长距离和方向性的归纳偏差。我们引入了Bubbleformer，一个基于Transformer的时空模型，可以在不依赖推理期间的模拟数据的情况下，预测稳定和长距离的沸腾动态，包括核化、界面演化和传热。Bubbleformer集成了分解轴向注意力、频率感知缩放以及热物理参数条件，以泛化到不同的流体、几何形状和操作条件。为了评估混沌系统中的物理保真度，我们提出了可解释的基于物理的指标，用于评估热通量一致性、界面几何形状和质量守恒。我们还发布了BubbleML 2.0，这是一个高保真数据集，涵盖了多种工作流体（低温流体、制冷剂、电介质）、沸腾配置（池式沸腾和流动沸腾）、流态（气泡流、弹状流、环状流）和边界条件。Bubbleformer在两相沸腾流的预测和预报方面都取得了新的基准结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [151] [Structure-Informed Deep Reinforcement Learning for Inventory Management](https://arxiv.org/abs/2507.22040)
> *结构化深度强化学习在库存管理中的应用*

*Alvaro Maggiar, Sohrab Andaz, Akhil Bagaria, Carson Eisenach, Dean Foster, Omer Gottesman, Dominique Perrault-Joncas* | **Category: cs.LG, math.OC** | **Updated: 2025-07-29**

**Keywords:** 深度强化学习, 库存管理, 结构化策略网络, DirectBackprop, 运筹学

**Comment:** 

> **TL;DR:** 本文将深度强化学习应用于库存管理，使用DirectBackprop算法在多种场景下学习策略，表现优于基准，并提出了结构化策略网络以提高性能和可解释性。

**AI_Comments:** 本文创新性地将深度强化学习应用于复杂的库存管理问题，并提出“结构化策略网络”以结合理论洞察，提升了模型的性能、可解释性和鲁棒性。其重要性在于弥合了数据驱动方法与传统运筹学之间的鸿沟，为实际库存管理提供了更有效和可解释的解决方案，尤其是在需求不确定或非平稳的环境下。

<details>
  <summary>Details</summary>

**Motivation:** 传统库存管理方法常依赖不切实际的需求分布假设。本文旨在将深度强化学习应用于实际库存管理问题，避免这些假设，并探索其在复杂场景下的性能和实用性。

**Method:** 本文应用基于DirectBackprop的深度强化学习（DRL）算法，在包括多周期销售损失系统、易腐库存管理、双重采购和联合采购与移除等多种库存管理场景中学习策略。为提高策略性能和可解释性，作者提出了一种“结构化策略网络”技术，将最优策略的解析特性明确融入学习过程。

**Result:** 通用DRL实现在各种设置下与现有基准和启发式方法相比具有竞争力或表现更优。DRL方法能够自然地捕捉传统运筹学方法得出的最优策略的许多已知结构特性。结构化策略网络提高了策略性能和可解释性，并在实际需求数据示例中展示了样本外性能的鲁棒性。本文还展示了DRL在非平稳环境中的应用。

**Conclusion:** 本文成功将数据驱动的深度强化学习与库存管理中的分析洞察相结合，同时保持了实际适用性，弥合了理论与实践之间的差距。

> **ai_Abstract:** 本文将基于DirectBackprop的深度强化学习应用于多种库存管理场景，旨在克服传统方法对需求分布的假设。研究表明，该DRL方法在性能上优于现有基准，并能自然捕捉最优策略的结构特性。为进一步提升性能和可解释性，作者提出了结构化策略网络，将分析特性融入学习过程。该工作成功结合了数据驱动学习与分析洞察，为库存管理提供了实用的解决方案。

> **摘要翻译:** 本文研究了深度强化学习（DRL）在经典库存管理问题中的应用，重点关注实际实施的考虑因素。我们将基于DirectBackprop的DRL算法应用于几种基本的库存管理场景，包括有销售损失的多周期系统（有和无提前期）、易腐库存管理、双源采购以及联合库存采购和移除。DRL方法仅使用实际可用的历史信息学习跨产品的策略，避免了对需求分布的不切实际的假设或对分布参数的访问。我们证明，我们的通用DRL实现在这些多样化的设置中与现有基准和启发式方法相比具有竞争力或表现更优，同时只需要极少的参数调整。通过检查学习到的策略，我们发现DRL方法自然地捕捉了许多从传统运筹学方法中得出的最优策略的已知结构特性。为了进一步提高策略性能和可解释性，我们提出了一种结构化策略网络技术，该技术将最优策略的解析特性明确地融入学习过程。这种方法可以帮助提高可解释性，并增加策略在样本外性能中的鲁棒性，正如我们在一个具有实际需求数据的示例中所示。最后，我们提供了一个DRL在非平稳环境中的说明性应用。我们的工作弥合了库存管理中数据驱动学习与分析洞察之间的差距，同时保持了实际适用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [160] [Unsupervised risk factor identification across cancer types and data modalities via explainable artificial intelligence](https://arxiv.org/abs/2506.12944)
> *无监督风险因素识别：跨癌种和数据模态的可解释人工智能方法*

*Maximilian Ferle, Jonas Ader, Thomas Wiemers, Nora Grieb, Adrian Lindenmeyer, Hans-Jonas Meyer, Thomas Neumuth, Markus Kreuz, Kristin Reiche, Maximilian Merz* | **Category: cs.LG, q-bio.TO** | **Updated: 2025-07-29**

**Keywords:** 无监督学习, 风险分层, 可解释人工智能, 癌症, 生存分析

**Comment:** 

> **TL;DR:** 本文提出了一种无监督机器学习方法，通过可微分的多元对数秩统计量直接优化患者群体的生存异质性，以识别具有不同预后结果的患者群，并适用于多种癌症类型和数据模态，提供可解释的结果。

**AI_Comments:** 该论文的创新之处在于提出了一种直接优化生存异质性的无监督学习方法，并引入了可微分的对数秩统计量，使其能够应用于多种数据模态和神经网络架构，实现了模型无关性。其重要性体现在解决了传统生存分析难以转化为临床可操作标准的问题，并通过提供可解释的结果增强了临床决策的信任度。这种泛癌种的方法有望发现新的预后生物标志物，推动肿瘤治疗的个性化发展。

<details>
  <summary>Details</summary>

**Motivation:** 当前的风险分层方法往往无法将复杂的生存分析转化为可操作的临床标准。因此，需要一种能够直接优化患者群体生存异质性，并适用于不同数据模态的新方法。

**Method:** 提出了一种新颖的无监督机器学习方法，通过多元对数秩统计量的可微分适应来直接优化患者群体的生存异质性。该方法能够训练任何神经网络架构，适用于任何数据模态以识别预后不同的患者群体。此外，还进行了事后可解释性分析，以揭示决定分组的临床有意义特征。

**Result:** 该方法在模拟实验中得到了彻底评估，并在实践中应用于两种不同的癌症类型：分析多发性骨髓瘤患者的实验室参数和非小细胞肺癌患者的计算机断层扫描图像。在两种情况下，都成功识别了预后明显不同的患者亚组，且其生存结果显著不同。事后可解释性分析揭示了决定分组的临床有意义特征，这些特征与已建立的风险因素吻合良好。

**Conclusion:** 这种泛癌种、模型无关的方法代表了临床风险分层的一个有价值的进步，能够发现跨多样数据类型的新型预后特征，同时提供可解释的结果，有望补充肿瘤学及其他领域的治疗个性化和临床决策。

> **ai_Abstract:** 本文介绍了一种新颖的无监督机器学习方法，该方法通过可微分的多元对数秩统计量直接优化患者群体的生存异质性，以识别具有不同预后结果的患者亚组。该方法具有模型无关性，能够应用于多种数据模态和神经网络架构。通过模拟实验验证并在多发性骨髓瘤和非小细胞肺癌数据上进行实践应用，该方法成功识别了预后显著不同的患者群体。结合事后可解释性分析，该方法能够揭示与已知风险因素一致的临床有意义特征，从而为跨癌种的风险分层和个性化治疗提供有价值的工具。

> **摘要翻译:** 风险分层是临床决策中的关键工具，但目前的方法往往未能将复杂的生存分析转化为可操作的临床标准。我们提出了一种新颖的无监督机器学习方法，通过多元对数秩统计量的可微分适应，直接优化患者群体的生存异质性。与大多数依赖代理指标的现有方法不同，我们的方法代表了一种新颖的训练任何神经网络架构以识别预后不同患者群体的方法，可应用于任何数据模态。我们在模拟实验中彻底评估了该方法，并通过将其应用于两种不同的癌症类型来证明其实用性：分析多发性骨髓瘤患者的实验室参数和非小细胞肺癌患者的计算机断层扫描图像，在两种情况下都识别出预后明显不同的患者亚组，其生存结果显著不同。事后可解释性分析揭示了决定分组的临床有意义特征，这些特征与已建立的风险因素吻合良好，从而有力地证明了该方法的实用性。这种泛癌种、模型无关的方法代表了临床风险分层的一个有价值的进步，能够发现跨多样数据类型的新型预后特征，同时提供可解释的结果，有望补充肿瘤学及其他领域的治疗个性化和临床决策。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [162] [OCSVM-Guided Representation Learning for Unsupervised Anomaly Detection](https://arxiv.org/abs/2507.21164)
> *OCSVM引导的表示学习用于无监督异常检测*

*Nicolas Pinon, Carole Lartizien* | **Category: cs.LG, cs.AI, eess.IV, stat.ML** | **Updated: 2025-07-25**

**Keywords:** 无监督异常检测, 表示学习, OCSVM, 异常检测, 医学影像

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的方法，通过自定义损失函数将表示学习与可解析的单类SVM紧密结合，用于无监督异常检测，并在MNIST-C和脑部MRI病变检测任务中表现出良好的性能和鲁棒性。

**AI_Comments:** 本文的创新点在于提出了一种新颖的、紧密耦合表示学习与可解析OCSVM的方法，通过自定义损失函数直接对齐潜在特征与OCSVM决策边界，有效解决了现有UAD方法中特征空间次优和过度重构异常的问题。其在医学影像（脑部MRI细微病变检测）中的成功应用，尤其是在处理小而不高强度病变以及评估体素级指标方面，显示了其在临床相关场景中的重要性和实用性。此外，对领域变化鲁棒性的评估也增加了其在真实世界应用中的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 无监督异常检测（UAD）在许多机器学习应用中是必需的，但现有方法存在局限性：基于重构的方法往往过度重构异常，而解耦表示学习与密度估计器的方法可能导致次优特征空间。一些近期方法试图耦合特征学习和异常检测，但常依赖替代目标、限制核选择或引入近似，从而限制了表达能力和鲁棒性。

**Method:** 本文提出了一种新颖的方法，通过自定义损失函数将表示学习与可解析的单类SVM（OCSVM）紧密结合，该损失函数直接将潜在特征与OCSVM决策边界对齐。模型在基于MNIST-C的新基准和具有挑战性的脑部MRI细微病变检测任务上进行评估，特别是针对小而不高强度的病变，并评估了体素级指标，同时考虑了对领域变化的鲁棒性。

**Result:** 实验结果表明，所提出的模型在性能和鲁棒性方面表现出色，尤其是在检测小而不高强度的脑部MRI病变方面，并能应对领域变化（如MNIST-C中的损坏类型和MRI中的扫描仪/年龄变化）。

**Conclusion:** 本文提出的OCSVM引导的表示学习方法有效解决了无监督异常检测中的挑战，通过紧密耦合表示学习与OCSVM，在通用UAD和现实世界医学成像应用中展现出巨大潜力。

> **ai_Abstract:** 本文提出了一种名为OCSVM引导的表示学习（OCSVM-Guided Representation Learning）的新型无监督异常检测方法。该方法通过一个定制的损失函数，将表示学习与可解析的单类SVM（OCSVM）紧密耦合，旨在直接对齐潜在特征与OCSVM决策边界，以克服现有UAD方法在重构异常或特征空间次优方面的局限性。模型在MNIST-C基准和脑部MRI细微病变检测任务上进行了评估，特别是在检测小而不高强度的病变以及应对领域变化方面表现出卓越的性能和鲁棒性，显示出其在通用UAD和医学成像领域的应用潜力。

> **摘要翻译:** 无监督异常检测（UAD）旨在无需标记数据的情况下检测异常，这在许多机器学习应用中是必要的，因为异常样本稀有或不可用。大多数最先进的方法分为两类：基于重构的方法，它们通常会很好地重构异常；以及解耦表示学习与密度估计器的方法，它们可能遭受次优特征空间的困扰。尽管一些最新方法试图将特征学习和异常检测结合起来，但它们通常依赖替代目标、限制核选择或引入近似，从而限制了其表达能力和鲁棒性。为了解决这一挑战，我们提出了一种新颖的方法，通过自定义损失公式将表示学习与可解析的单类支持向量机（OCSVM）紧密结合，该公式直接将潜在特征与OCSVM决策边界对齐。该模型在两项任务中进行了评估：一个基于MNIST-C的新基准，以及一个具有挑战性的脑部MRI细微病变检测任务。与大多数关注图像级别大而高强度病变的方法不同，我们的方法成功地针对小而不高强度的病变，同时我们评估了体素级指标，解决了更具临床相关性的场景。两项实验都评估了对领域变化的鲁棒性，包括MNIST-C中的损坏类型和MRI中的扫描仪/年龄变化。结果表明了我们提出模型的性能和鲁棒性，突出了其在通用UAD和现实世界医学成像应用中的潜力。源代码可在https://github.com/Nicolas-Pinon/uad_ocsvm_guided_repr_learning获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [171] [R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning](https://arxiv.org/abs/2507.17307)
> *R-Stitch：高效推理的动态轨迹拼接*

*Zhuokun Chen, Zeren Chen, Jiahao He, Mingkui Tan, Jianfei Cai, Bohan Zhuang* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-24**

**Keywords:** 思维链推理, 语言模型加速, 混合解码, R-Stitch, 推理延迟

**Comment:** 

> **TL;DR:** R-Stitch是一种混合解码框架，通过在推理轨迹中动态切换大小模型来加速CoT推理，显著降低延迟并保持准确性。

**AI_Comments:** R-Stitch的创新之处在于其动态、基于置信度的模型切换机制，避免了传统推测解码的局限性（如全序列回滚和低一致性问题）。它提供了一种高效且模型无关的CoT推理加速方案，对于降低LLM推理成本具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有CoT推理因长序列自回归解码导致计算开销大。现有加速策略（早期停止、压缩奖励、推测解码）有局限性，如推测解码在大小模型一致性低时加速有限，且未能利用小模型生成简洁中间推理的优势。

**Method:** 本文提出了R-Stitch，一个令牌级、基于置信度的混合解码框架，用于加速CoT推理。它默认使用小型语言模型（SLM）生成令牌，仅当SLM的置信度低于阈值时才委托给大型语言模型（LLM）。这种设计避免了全序列回滚，并选择性地在不确定步骤调用LLM。R-Stitch是模型无关、无需训练且兼容标准解码管道的。

**Result:** 在数学推理基准测试中，R-Stitch将推理延迟降低高达85%，同时准确率下降可忽略不计。

**Conclusion:** R-Stitch通过动态切换大小模型，在显著加速CoT推理的同时保持了高的答案质量，证明了其在实际应用中的有效性。

> **ai_Abstract:** 本文提出了R-Stitch，一种令牌级、基于置信度的混合解码框架，旨在加速大型语言模型中的思维链（CoT）推理。针对CoT推理计算开销大且现有加速方法局限性大的问题，R-Stitch通过在小型语言模型（SLM）和大型语言模型（LLM）之间动态切换来优化。它默认使用SLM生成令牌，仅在SLM置信度不足时调用LLM。实验证明，R-Stitch能将推理延迟降低高达85%，同时保持几乎不变的准确率，展现了其在高效CoT推理中的实用价值。

> **摘要翻译:** 思维链（CoT）推理通过在推理过程中鼓励逐步的中间推理，增强了大型语言模型的解决问题能力。尽管CoT有效，但由于其依赖于长令牌序列上的自回归解码，引入了大量的计算开销。现有的加速策略要么通过早期停止或压缩奖励设计来减少序列长度，要么通过使用较小模型进行推测解码来提高解码速度。然而，当大小模型之间的一致性较低时，推测解码的加速效果有限，并且未能利用小型模型在生成简洁中间推理方面的潜在优势。在本文中，我们提出了R-Stitch，一个令牌级、基于置信度的混合解码框架，它通过在推理轨迹中在小型语言模型（SLM）和大型语言模型（LLM）之间切换来加速CoT推理。R-Stitch默认使用SLM生成令牌，仅当SLM的置信度低于阈值时才委托给LLM。这种设计避免了全序列回滚，并选择性地在不确定的步骤调用LLM，从而同时保持效率和答案质量。R-Stitch是模型无关的、无需训练的，并且与标准解码管道兼容。在数学推理基准测试上的实验表明，R-Stitch在推理延迟方面实现了高达85%的降低，而准确率下降可忽略不计，这突显了其在加速CoT推理方面的实际有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [172] [Categorical Distributions are Effective Neural Network Outputs for Event Prediction](https://arxiv.org/abs/2507.21616)
> *分类分布是事件预测中有效的神经网络输出*

*Kevin Doran, Tom Baden* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 分类分布, 神经网络, 事件预测, 时间点过程, 数据集限制

**Comment:** 32 pages, 26 figures

> **TL;DR:** 本文证明了使用简单的分类概率分布作为神经网络输出在事件预测中是有效的，并发现现有数据集和模型可能隐藏了这种简单方法的潜力。

**AI_Comments:** 创新点在于重新审视了神经网络输出结构的选择，挑战了传统时间点过程模型的复杂性，并揭示了现有数据集的局限性。其重要性在于提供了一种简单而有效的事件预测方法，并对数据集质量和模型评估提出了新的思考。

<details>
  <summary>Details</summary>

**Motivation:** 探究为何简单的分类概率分布输出结构不常用于神经时间点过程模型，以及现有数据集和模型评估的局限性。

**Method:** 通过扩展现有数据集和创建新数据集来克服信息限制，并在此基础上评估分类分布作为神经网络输出的性能。

**Result:** 发现许多现有数据集未能充分揭示底层事件生成过程的信息，且现有模型表现良好可能归因于模型大小的正则化效应和输出结构的限制。研究表明，简单的分类分布输出在各种数据集上都具有竞争力。

**Conclusion:** 简单的分类概率分布作为神经网络输出在事件预测任务中是有效的，并且其潜力可能被现有数据集和模型的评估方式所低估。

> **ai_Abstract:** 本文探讨了在事件预测任务中使用分类概率分布作为神经网络输出的有效性。研究发现，现有时间点过程模型数据集的信息量有限，且许多模型表现良好是由于其自身的正则化效应。通过扩展和创建新数据集，研究证明了简单的分类分布输出在多种数据集上均表现出色，挑战了现有实践。

> **摘要翻译:** 我们证明了使用简单的神经网络输出，即分类概率分布，在下一个尖峰预测任务中的有效性。这项案例研究促使我们调查为什么这种简单的输出结构不常用于神经时间点过程模型。我们发现有证据表明，许多用于评估时间点过程模型的现有数据集并未揭示太多关于底层事件生成过程的信息，并且许多现有模型表现良好是由于模型大小的正则化效应和输出结构的限制。我们扩展了现有数据集并创建了新的数据集，以探索这种信息受限的范围之外，发现输出简单的分类分布在广泛的数据集上都具有竞争力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [179] [Weight-Parameterization in Continuous Time Deep Neural Networks for Surrogate Modeling](https://arxiv.org/abs/2507.22045)
> *连续时间深度神经网络中用于替代建模的权重参数化*

*Haley Rosso, Lars Ruthotto, Khachik Sargsyan* | **Category: cs.LG, math.OC** | **Updated: 2025-07-29**

**Keywords:** 连续时间深度学习, 权重参数化, 神经ODE, 勒让德多项式, 替代建模

**Comment:** 34 pages, 6 figures, submitted to the MoRE24 special issue of
  Computational Science and Engineering

> **TL;DR:** 该研究探索了在连续时间深度神经网络中，使用多项式基函数（尤其是勒让德多项式）来参数化时间变化的权重，以提高训练稳定性、降低计算成本并保持高精度，用于复杂物理系统的替代建模。

**AI_Comments:** 这项工作在连续时间深度学习模型（如神经ODE）的训练效率和稳定性方面取得了重要进展。通过引入基于正交多项式（特别是勒让德多项式）的权重参数化，它有效地解决了时变权重学习中的计算和稳定性挑战。其创新性在于将数学上的正交基特性引入到神经网络的权重演化中，为未来开发更高效、更稳定的连续时间模型提供了新的方向。该方法对于需要高精度和计算效率的物理系统替代建模具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在连续时间深度学习模型（如神经ODE）中，训练表达性强且稳定的时变权重是一个核心挑战，尤其是在计算资源受限的情况下。

**Method:** 本研究调查了将权重的时间演变约束到由多项式基函数（包括单项式和勒让德多项式）构成的低维子空间中的权重参数化策略。在神经ODE和残差网络(ResNet)架构中，评估了“先离散后优化”和“先优化后离散”两种训练范式。

**Result:** 在三个高维基准问题上的实验结果表明，勒让德参数化产生了更稳定的训练动态，降低了计算成本，并且实现了与单项式参数化和无约束权重模型相当或更好的精度。

**Conclusion:** 研究结果阐明了在时间依赖权重参数化中基函数选择的作用，并证明了使用正交多项式基函数在模型表达能力和训练效率之间提供了有利的权衡。

> **ai_Abstract:** 本论文探讨了在连续时间深度神经网络中，通过将时间变化的权重限制在由多项式基函数（如勒让德多项式）跨越的低维子空间内，来优化复杂物理系统替代建模的训练过程。研究发现，勒让德参数化能显著提升训练稳定性，降低计算成本，同时保持或超越现有方法的准确性，从而在模型表达能力和训练效率之间取得良好平衡。

> **摘要翻译:** 连续时间深度学习模型，例如神经常微分方程（ODEs），为复杂物理系统的替代建模提供了一个有前景的框架。训练这些模型的一个核心挑战在于学习具有表达性但又稳定的时变权重，特别是在计算约束下。这项工作研究了权重参数化策略，这些策略将权重的时间演变约束到由多项式基函数构成的低维子空间中。我们在“先离散后优化”和“先优化后离散”的训练范式下，在神经ODE和残差网络（ResNet）架构中评估了单项式和勒让德多项式基。在三个高维基准问题上的实验结果表明，勒让德参数化产生了更稳定的训练动态，降低了计算成本，并且实现了与单项式参数化和无约束权重模型相当或更好的精度。这些发现阐明了在时间依赖权重参数化中基函数选择的作用，并证明了使用正交多项式基函数在模型表达能力和训练效率之间提供了有利的权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [184] [Adaptive Multimodal Protein Plug-and-Play with Diffusion-Based Priors](https://arxiv.org/abs/2507.21260)
> *自适应多模态蛋白质即插即用与扩散先验*

*Amartya Banerjee, Xingyu Xu, Caroline Moosmüller, Harlin Lee* | **Category: cs.LG, cs.AI, q-bio.QM** | **Updated: 2025-07-28**

**Keywords:** 蛋白质结构生成, 扩散模型, 即插即用, 多模态数据, 逆问题

**Comment:** Code: https://github.com/amartya21/Adam-PnP

> **TL;DR:** Adam-PnP通过自适应噪声估计和动态模态加权，有效整合多源实验数据指导扩散模型进行蛋白质结构生成，显著提升了重建精度。

**AI_Comments:** 这篇论文的创新点在于提出了一个无需精确噪声知识和手动权重调整的自适应多模态数据集成框架Adam-PnP，有效地将多源异构实验数据融入到蛋白质扩散模型中，解决了现有方法的局限性，对蛋白质结构生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度生成模型（尤其是扩散模型）在蛋白质结构生成中表现出色，但将多源噪声实验数据整合到这些模型中仍面临挑战，主要问题在于需要精确的实验噪声水平知识和手动调整每种数据模态的权重。

**Method:** 本文提出了Adam-PnP框架，一个即插即用（Plug-and-Play）的方案，它使用来自多个异构实验源的梯度来指导预训练的蛋白质扩散模型。该框架将自适应噪声估计方案和动态模态加权机制整合到扩散过程中，从而减少了手动超参数调整的需求。

**Result:** 在复杂的重建任务上，Adam-PnP显著提高了精度。

**Conclusion:** Adam-PnP通过其自适应噪声估计和动态模态加权机制，成功解决了多模态实验数据与扩散模型集成中的挑战，显著提升了蛋白质结构重建的准确性。

> **ai_Abstract:** 本文介绍了Adam-PnP，一个即插即用框架，旨在解决将多源噪声实验数据整合到蛋白质扩散模型中以进行结构生成的挑战。Adam-PnP通过利用来自异构实验源的梯度来指导预训练的扩散模型，并集成了自适应噪声估计和动态模态加权机制，从而减少了手动超参数调整。实验证明，Adam-PnP在蛋白质结构重建任务中显著提升了精度。

> **摘要翻译:** 在逆问题中，目标是恢复通常在测量过程中经历了一些有损或噪声转换的未知参数（例如图像）。最近，深度生成模型，特别是扩散模型，已成为蛋白质结构生成的强大先验。然而，将来自多个来源的噪声实验数据整合以指导这些模型仍然是一个重大挑战。现有方法通常需要精确的实验噪声水平知识和手动调整每种数据模态的权重。在这项工作中，我们引入了Adam-PnP，一个即插即用框架，它使用来自多个异构实验源的梯度来指导预训练的蛋白质扩散模型。我们的框架具有自适应噪声估计方案和动态模态加权机制，这些机制集成到扩散过程中，减少了手动超参数调整的需求。在复杂重建任务上的实验表明，使用Adam-PnP显著提高了准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [195] [HiPreNets: High-Precision Neural Networks through Progressive Training](https://arxiv.org/abs/2506.15064)
> *HiPreNets：通过渐进式训练实现高精度神经网络*

*Ethan Mulle, Wei Kang, Qi Gong* | **Category: cs.LG, cs.NA, cs.NE, math.NA** | **Updated: 2025-07-29**

**Keywords:** 高精度神经网络, 渐进式训练, 分阶段训练, 残差学习, $L^{\infty}$误差

**Comment:** 

> **TL;DR:** HiPreNets是一种渐进式训练框架，通过顺序学习预测残差来提高神经网络的精度，解决了复杂问题中实现高精度模型的挑战。

**AI_Comments:** 该论文的创新之处在于提出了一种渐进式训练框架HiPreNets，通过顺序学习预测残差来系统地提高神经网络的精度，并特别关注了在许多实际应用中至关重要的$L^{\infty}$误差。这种方法为解决复杂非线性问题中高精度模型训练的挑战提供了一个有前景的途径。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络在解决科学和工程中的非线性问题时面临挑战，尤其是在问题复杂性增加时难以训练出高精度模型。非凸优化和大量超参数调整使得性能提升困难，并且传统方法通常优先考虑最小化均方误差（MSE），而忽略了在许多应用中至关重要的$L^{\infty}$误差。

**Method:** 本文提出了一种用于训练和调整高精度神经网络（HiPreNets）的渐进式框架。该方法改进了一种先前探索过的分阶段训练技术，通过使用额外的网络顺序学习现有全连接神经网络的预测残差，从而提高整体精度。该方法还讨论了如何利用残差结构来指导损失函数、参数数量的选择以及引入自适应数据采样技术。

**Result:** 通过几个基准问题验证了该框架的有效性。

**Conclusion:** 该论文提出并验证了HiPreNets框架，证明其能有效提高神经网络的精度，尤其是在复杂问题中对$L^{\infty}$误差有严格要求的场景。

> **ai_Abstract:** 本文提出了HiPreNets，一个用于训练和调整高精度神经网络的渐进式框架，旨在解决复杂问题中传统深度学习方法在精度提升上的挑战，特别是对$L^{\infty}$误差的忽视。该方法通过改进分阶段训练技术，顺序学习现有网络的预测残差来提高整体精度，并利用残差结构指导损失函数选择、参数数量和自适应数据采样。该框架的有效性已通过基准问题得到验证。

> **摘要翻译:** 深度神经网络是解决科学和工程中非线性问题的强大工具，但随着问题复杂性的增加，训练高精度模型变得具有挑战性。非凸优化和众多需要调整的超参数使得性能提升困难，并且传统方法通常优先考虑最小化均方误差（MSE），而忽略了在许多应用中至关重要的$L^{\infty}$误差。为了解决这些挑战，我们提出了一种用于训练和调整高精度神经网络（HiPreNets）的渐进式框架。我们的方法改进了一种先前探索过的神经网络分阶段训练技术，通过使用额外的网络顺序学习其预测残差，从而提高现有全连接神经网络的整体精度。我们讨论了如何利用残差的结构来指导损失函数的选择、使用的参数数量以及引入自适应数据采样技术的方法。我们通过几个基准问题验证了我们框架的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [207] [Online hierarchical partitioning of the output space in extreme multi-label data stream](https://arxiv.org/abs/2507.20894)
> *在线极端多标签数据流输出空间的分层划分*

*Lara Neves, Afonso Lourenço, Alberto Cano, Goreti Marreiros* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 多标签分类, 数据流, 在线学习, 概念漂移, 层次划分

**Comment:** Accepted at 28th European Conference on Artificial Intelligence (ECAI
  2025)

> **TL;DR:** iHOMER是一种在线多标签学习框架，通过动态划分标签空间并集成漂移检测机制，显著优于现有基线，在在线多标签分类中表现出强大的鲁棒性。

**AI_Comments:** iHOMER的创新点在于其在线、增量式的标签空间分层划分能力，无需预定义层次，这对于处理动态变化的多标签数据流至关重要。同时，集成全局和局部漂移检测机制，使其能够有效应对概念漂移，增强了模型在非平稳环境下的适应性和鲁棒性。其在多个数据集上显著优于现有SOTA方法的表现，证明了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 处理具有演化分布、高维标签空间、稀疏标签出现和复杂标签依赖的多标签数据流，以及概念漂移对输入分布、标签相关性和不平衡率的影响，这些都使得模型适应变得复杂。

**Method:** 本文提出了iHOMER（Incremental Hierarchy Of Multi-label Classifiers），一个在线多标签学习框架。iHOMER通过基于Jaccard相似度的在线分裂-聚合聚类，将标签空间增量地划分为不相交的、相关的簇，不依赖预定义层次。它利用由多元伯努利过程驱动的全局树状学习器来指导实例划分。为应对非平稳性，iHOMER在全局和局部层面集成了漂移检测机制，从而实现标签分区和子树的动态重构。

**Result:** 在23个真实世界数据集上的实验表明，iHOMER比5个最先进的全局基线（如MLHAT、MLHT of Pruned Sets和iSOUPT）性能高出23%，比12个局部基线（如kNN、EFDT、ARF和ADWIN bagging/boosting集成的二元相关转换）性能高出32%。

**Conclusion:** iHOMER在在线多标签分类方面表现出强大的鲁棒性，有效应对了多标签数据流中的挑战，并显著优于现有先进方法。

> **ai_Abstract:** 本文提出了一种名为iHOMER的在线多标签学习框架，旨在解决多标签数据流中存在的演变分布、高维标签空间、稀疏性、复杂依赖和概念漂移等挑战。iHOMER通过在线分裂-聚合聚类动态地将标签空间划分为相关簇，并结合全局树状学习器。其创新之处在于集成了全局和局部层面的漂移检测机制，以适应非平稳环境。实验结果表明，iHOMER在多个真实数据集上显著优于现有的全局和局部基线方法，验证了其在在线多标签分类任务中的强大鲁棒性。

> **摘要翻译:** 在线极端多标签数据流输出空间的分层划分

对具有多标签输出的数据流进行挖掘带来了严峻挑战，原因包括不断演变的分布、高维标签空间、稀疏的标签出现以及复杂的标签依赖关系。此外，概念漂移不仅影响输入分布，还会随着时间推移影响标签相关性和不平衡率，从而使模型适应变得复杂。为了应对这些挑战，结构化学习器被分为局部方法和全局方法。局部方法将任务分解为更简单的组件，而全局方法则使算法适应完整的输出空间，通过利用标签相关性可能产生更好的预测。这项工作引入了iHOMER（Incremental Hierarchy Of Multi-label Classifiers），一个在线多标签学习框架，它增量地将标签空间划分为不相交的、相关的簇，而不依赖预定义的层次结构。iHOMER利用基于Jaccard相似度的在线分裂-聚合聚类和由多元伯努利过程驱动的全局树状学习器来指导实例划分。为了解决非平稳性问题，它在全局和局部层面集成了漂移检测机制，从而实现标签分区和子树的动态重构。在23个真实世界数据集上的实验表明，iHOMER比5个最先进的全局基线（如MLHAT、MLHT of Pruned Sets和iSOUPT）性能高出23%，比12个局部基线（如kNN、EFDT、ARF和ADWIN bagging/boosting集成的二元相关转换）性能高出32%，确立了其在在线多标签分类中的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [214] [Foundation Models for Demand Forecasting via Dual-Strategy Ensembling](https://arxiv.org/abs/2507.22053)
> *通过双策略集成实现需求预测的基础模型*

*Wei Yang, Defu Cao, Yan Liu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 需求预测, 基础模型, 集成学习, 供应链, 时间序列

**Comment:** 

> **TL;DR:** 提出一个双策略集成框架，提升基础模型在真实供应链销售预测中的表现，通过结合分层集成和架构集成来提高准确性和泛化能力。

**AI_Comments:** 该论文的创新点在于提出了一个结合分层和架构集成的双策略框架，有效解决了基础模型在复杂需求预测中面临的鲁棒性和泛化性问题。这种方法为提升时间序列预测中基础模型的实用性提供了有价值的思路。

<details>
  <summary>Details</summary>

**Motivation:** 准确的需求预测对供应链优化至关重要，但实际中因层级复杂性、领域漂移和外部因素变化而困难。现有基础模型在时间序列预测中潜力大，但存在架构刚性和分布变化下鲁棒性有限的问题。

**Method:** 提出一个统一的集成框架，结合两种互补策略：(1) 分层集成（Hierarchical Ensemble, HE），按语义级别（如商店、类别、部门）划分训练和推理以捕捉局部模式；(2) 架构集成（Architectural Ensemble, AE），整合来自不同模型骨干的预测以减轻偏差并提高稳定性。

**Result:** 在M5基准和三个外部销售数据集（涵盖域内和零样本预测）上进行了广泛实验。结果显示，该方法持续优于强基线，提高了跨层级的准确性，并为复杂预测环境中的泛化提供了简单而有效的机制。

**Conclusion:** 该双策略集成框架有效提升了基础模型在复杂需求预测任务中的性能和泛化能力。

> **ai_Abstract:** 本文提出了一个名为“双策略集成”的统一框架，旨在提升基础模型在真实世界销售预测中的表现。该框架结合了分层集成（根据语义级别捕捉局部模式）和架构集成（整合不同模型预测以提高稳定性）两种策略。实验结果表明，该方法在多个数据集上均优于现有基线，显著提升了预测准确性和泛化能力。

> **摘要翻译:** 精确的需求预测对于供应链优化至关重要，但在实践中由于层级复杂性、领域漂移和不断变化的外部因素而仍然困难重重。虽然最近的基础模型在时间序列预测方面展现出强大潜力，但它们通常受限于架构刚性和在分布变化下鲁棒性不足。在本文中，我们提出了一个统一的集成框架，以增强基础模型在真实世界供应链销售预测中的性能。我们的方法结合了两种互补策略：(1) 分层集成（HE），它通过语义级别（例如商店、类别、部门）划分训练和推理以捕捉局部模式；以及 (2) 架构集成（AE），它整合来自不同模型骨干的预测以减轻偏差并提高稳定性。我们在M5基准和三个外部销售数据集上进行了广泛实验，涵盖了域内和零样本预测。结果表明，我们的方法持续优于强大的基线，提高了跨层级的准确性，并为复杂预测环境中的泛化提供了一种简单而有效的机制。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [218] [AGORA: Incentivizing Group Emergence Capability in LLMs via Group Distillation](https://arxiv.org/abs/2507.21166)
> *AGORA：通过群体蒸馏激励大型语言模型中的群体涌现能力*

*Ren Zhuang, Ben Wang, Shuifa Sun* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 群体涌现能力, 结构化交互, 大型语言模型, 协作集成, 群体蒸馏

**Comment:** 

> **TL;DR:** 提出AGORA框架，通过结构化交互和群体涌现能力，使LLM协作 ensemble 在复杂推理任务上超越SOTA单体系统。

**AI_Comments:** 这篇论文的创新点在于提出了“结构化交互”作为大模型能力提升的新维度，超越了传统的“增加模型参数”的路径。通过AGORA框架和群体涌现能力，实现了显著的性能提升，为构建更智能、更具协作性的AI系统提供了新的视角和方向。其重要性在于为未来大模型的发展指明了新的研究方向，即从单体模型向协作生态系统转变。

<details>
  <summary>Details</summary>

**Motivation:** 复杂推理的进展受限于当前训练数据集的静态性质。现有范式主要通过增加模型参数来提升能力，本文旨在提出结构化交互作为新的扩展轴，以超越这一限制。

**Method:** 提出一个名为AGORA的自演化框架，该框架通过实现协作式集成（collaborative ensemble）来利用群体涌现能力，并通过结构化交互合成独立模型无法达到的集体能力。标题中也提到“群体蒸馏”（Group Distillation）作为激励群体涌现能力的方法。

**Result:** AGORA框架使协作集成在具有挑战性的数学基准测试上，推理性能比最先进的单体系统高出4.45个百分点。

**Conclusion:** 群体涌现能力是集体能力的合成，独立模型无法达到，这验证了交互是智能的可扩展驱动因素。研究结果表明，构建协作生态系统是能力涌现的重要前沿。

> **ai_Abstract:** 本文提出AGORA框架，旨在通过结构化交互和群体蒸馏来提升大型语言模型的复杂推理能力，超越当前受限于静态数据集和参数增长的范式。AGORA使协作式模型集合能够利用群体涌现能力，在数学基准测试上比最先进的单体系统性能提升高达4.45个百分点，证明了交互作为智能可扩展驱动的重要性，并将协作生态系统的工程化定位为能力发展的新前沿。

> **摘要翻译:** 复杂推理的进展受限于当前训练数据集的静态性质。我们提出结构化交互作为新的扩展轴，超越了增加模型参数的流行范式。我们的自演化框架AGORA，使协作集成在具有挑战性的数学基准测试上，推理性能比最先进的单体系统高出4.45个百分点。这种增益源于群体涌现能力——即独立模型无法实现的集体能力的综合，这验证了交互是智能的可扩展驱动因素。我们的结果表明，协作生态系统的工程化是能力涌现的重要前沿。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [230] [Automated Generation of Diverse Courses of Actions for Multi-Agent Operations using Binary Optimization and Graph Learning](https://arxiv.org/abs/2506.20031)
> *使用二元优化和图学习为多智能体操作自动生成多样化行动方案*

*Prithvi Poddar, Ehsan Tarkesh Esfahani, Karthik Dantu, Souma Chowdhury* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 多智能体系统, 行动方案生成, 二元优化, 图学习, 遗传算法

**Comment:** Accepted for presentation in proceedings of IEEE CASE 2025

> **TL;DR:** 本文提出了一种新的理论和计算框架，用于为多智能体操作生成多样化的行动方案池，通过结合遗传算法进行任务分配和图神经网络进行任务排序，以应对环境变化和智能体能力差异。

**AI_Comments:** 本文的创新之处在于结合了遗传算法和图神经网络来解决多智能体任务分配和排序中的多样性生成问题，特别是在环境变化和智能体能力差异的复杂场景下。其提出的图抽象和量化多样性的方法也很有趣。该框架对于实际应用中的多智能体协同规划具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在灾难响应、搜救和军事任务中，涉及多智能体的行动需要自动化流程来支持行动方案（COA）的规划。环境变化（如雨、雪、路障等）可能会影响COA的预期性能，因此需要一个任务分布多样化的COA池。此外，智能体能力（人类或自主系统）的差异也带来了规划过程中的实际机遇和计算挑战。

**Method:** 本文提出了一种新的理论公式和计算框架，用于生成具有智能体-任务兼容性软变化的行动方案池。核心在于任务空间的图抽象和COA池本身以量化其多样性。将COA制定为集中的多机器人任务分配问题，使用遗传算法进行任务分配（忽略顺序），共同最大化COA池内的多样性和智能体-任务映射的整体兼容性。然后，使用策略梯度方法训练图神经网络，在每个COA中执行单智能体任务排序，以最大化适应任务特征的完成率。

**Result:** 在模拟环境中的COA生成过程测试表明，与随机游走基线相比，性能显著提高，任务排序的优化差距很小，对于5个智能体/100个任务的操作，规划多达20个COA的执行时间约为50分钟。

**Conclusion:** 本研究成功地提出了一种结合二元优化和图学习的自动化方法，用于生成多智能体操作中多样化的行动方案，并在模拟环境中验证了其有效性和效率。

> **ai_Abstract:** 本文提出了一种利用二元优化和图学习为多智能体操作自动生成多样化行动方案（COA）的框架。该方法通过图抽象量化COA多样性，并使用遗传算法进行任务分配以最大化多样性和兼容性。随后，训练图神经网络进行任务排序以提高完成率。在模拟环境中的测试结果显示，该方法相比随机游走基线具有显著性能提升，任务排序优化差距小，且效率高。

> **摘要翻译:** 灾难响应、搜救和军事任务中涉及多个智能体的行动需要自动化流程来支持行动方案（COA）的规划。此外，环境（雨、雪、路障等）中影响通行的变化可能会影响COA的预期性能，因此需要一个任务在智能体之间分布多样化的COA池。此外，智能体能力（可能是人类团队和/或自主系统）的变化给规划过程带来了实际机遇和计算挑战。本文提出了一种新的理论公式和计算框架，用于为具有智能体-任务兼容性软变化的行动生成此类多样化的COA池。问题公式的关键是任务空间的图抽象和COA池本身，以量化其多样性。将COA制定为集中的多机器人任务分配问题，使用遗传算法进行（忽略顺序的）任务分配给每个智能体，共同最大化COA池内的多样性和智能体-任务映射的整体兼容性。然后，使用策略梯度方法训练图神经网络，以在每个COA中执行单智能体任务排序，从而最大化适应任务特征的完成率。我们在模拟环境中对COA生成过程的测试表明，与随机游走基线相比，性能显著提高，任务排序的优化差距很小，对于5个智能体/100个任务的操作，规划多达20个COA的执行时间约为50分钟。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [233] [Hyperbolic Genome Embeddings](https://arxiv.org/abs/2507.21648)
> *双曲基因组嵌入*

*Raiyan R. Khan, Philippe Chlenski, Itsik Pe'er* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 基因组嵌入, 双曲CNN, DNA序列建模, 基因组表示学习, 转座元件

**Comment:** 30 pages, 16 figures, 10 tables. Camera-ready version for ICLR 2025

> **TL;DR:** 本文提出了一种利用双曲CNNs进行基因组序列建模的新方法，该方法无需明确的系统发育映射，即可学习到富有表现力的DNA序列表示，在多个基准测试中表现优于欧几里得模型和许多DNA语言模型，同时参数量更少且无需预训练。

**AI_Comments:** 该论文的创新点在于将双曲几何引入基因组序列建模，这与生物进化的层次结构和树状结构具有天然的契合性。通过利用双曲空间，模型能够更有效地捕捉复杂的生物学关系，且在参数效率和性能上超越了传统的欧几里得模型和一些大型DNA语言模型。引入转座元件基准数据集也很有意义，填补了基因组研究中一个重要但未被充分探索的空白。其在无需预训练的情况下取得优异性能，显示了该方法的实用性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的基因组序列建模方法难以将机器学习模型的归纳偏置与生物系统的演化结构对齐。

**Method:** 本文提出了一种双曲CNNs的新应用，该方法利用生物系统的演化结构，从而实现更具表现力的DNA序列表示。该策略避免了明确的系统发育映射，同时能够识别与核心功能和调控行为相关的序列关键属性。

**Result:** 在42个基因组解释基准数据集中的37个上，本文的双曲模型优于其欧几里得对应物。值得注意的是，该方法在七个GUE基准数据集上超越了最先进的性能，始终优于许多DNA语言模型，同时使用的参数少了几个数量级且避免了预训练。此外，本文还引入了一组新的基准数据集——转座元件基准，探索了基因组中一个重要但未被充分研究的且具有深远进化意义的组成部分。

**Conclusion:** 本文的工作通过探索双曲模型如何在各种数据生成条件下识别基因组信号，并构建解释数据集嵌入双曲性的经验方法，进一步证明了其有效性。这些评估持续证明了双曲框架作为基因组表示学习的强大范式的潜力。

> **ai_Abstract:** 本文提出了一种新颖的双曲卷积神经网络（CNN）应用，用于基因组序列建模，以解决现有方法难以将机器学习归纳偏置与生物进化结构对齐的问题。该方法能够学习到更具表现力的DNA序列表示，无需明确的系统发育映射，并能识别序列的关键功能和调控属性。实验结果表明，在大多数基因组解释基准数据集上，双曲模型优于欧几里得模型，并在GUE基准数据集上超越了最先进的DNA语言模型，同时显著减少了参数量且无需预训练。此外，研究还引入了新的转座元件基准数据集，并论证了双曲框架在基因组表示学习中的潜力。

> **摘要翻译:** 当前的基因组序列建模方法往往难以将机器学习模型的归纳偏置与生物系统的演化结构对齐。为此，我们提出了一种双曲CNNs的新应用，该方法利用了这种结构，从而实现更具表现力的DNA序列表示。我们的策略避免了明确的系统发育映射，同时能够识别与核心功能和调控行为相关的序列关键属性。在42个基因组解释基准数据集中的37个上，我们的双曲模型优于其欧几里得对应物。值得注意的是，我们的方法在七个GUE基准数据集上甚至超越了最先进的性能，始终优于许多DNA语言模型，同时使用的参数少了几个数量级且避免了预训练。我们的结果包括一组新的基准数据集——转座元件基准——该基准探索了基因组中一个重要但未被充分研究的且具有深远进化意义的组成部分。我们通过探索我们的双曲模型如何在各种数据生成条件下识别基因组信号，以及通过构建一种解释数据集嵌入双曲性的经验方法，进一步证明了我们工作的有效性。在这些评估中，我们发现了持续的证据，突出了我们的双曲框架作为基因组表示学习的强大范式的潜力。我们的代码和基准数据集可在 https://github.com/rrkhan/HGE 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [240] [Deep Polynomial Chaos Expansion](https://arxiv.org/abs/2507.21273)
> *深度多项式混沌展开*

*Johannes Exenberger, Sascha Ranftl, Robert Peharz* | **Category: cs.LG** | **Updated: 2025-07-28**

**Keywords:** 多项式混沌展开, 不确定性量化, 深度学习, 概率电路, 高维问题

**Comment:** 8th Workshop on Tractable Probabilistic Modeling, UAI 2025

> **TL;DR:** DeepPCE结合了多项式混沌展开(PCE)和概率电路，解决了传统PCE在高维问题上的扩展性差的问题，同时保持了其统计推断能力。

**AI_Comments:** DeepPCE的创新之处在于其将PCE的统计推断能力与深度学习的扩展性相结合，通过引入概率电路的概念，有效解决了PCE在高维问题中的瓶颈。这使得它在保持可解释性的同时，能够处理更复杂的系统。

<details>
  <summary>Details</summary>

**Motivation:** 传统的多项式混沌展开（PCE）在高维问题中，由于基函数数量随参数数量呈指数增长，导致其扩展性不佳。

**Method:** 本文将多项式混沌展开（PCE）与概率电路的思想相结合，提出了一种深度泛化的PCE模型——深度多项式混沌展开（DeepPCE）。

**Result:** DeepPCE在高维输入空间中能有效扩展，其预测性能与多层感知器（MLPs）相当，同时保留了PCE通过简单前向传播计算精确统计推断的能力。

**Conclusion:** DeepPCE是一种有效的深度泛化多项式混沌展开方法，能够处理高维问题并提供精确的统计推断。

> **ai_Abstract:** 本文提出了一种名为深度多项式混沌展开（DeepPCE）的新模型，旨在解决传统多项式混沌展开（PCE）在高维问题中扩展性差的局限性。DeepPCE通过结合PCE与概率电路的思想，实现了对PCE的深度泛化。该方法在高维输入空间中表现出良好的扩展性，预测性能可与多层感知器（MLPs）媲美，同时保持了PCE进行精确统计推断的能力。

> **摘要翻译:** 多项式混沌展开（PCE）是一种经典且广泛使用的替代建模技术，应用于物理模拟和不确定性量化。通过对一组基多项式（相对于不确定输入参数的分布正交）进行线性组合，PCE能够对关键统计量（如（条件）均值、方差、协方差和Sobol敏感性指数）进行可处理的推断，这些统计量对于理解建模系统以及识别有影响的参数及其相互作用至关重要。然而，随着基函数数量随参数数量呈指数增长，PCE在高维问题中扩展性不佳。我们通过将PCE与概率电路的思想相结合来解决这一挑战，从而得到了深度多项式混沌展开（DeepPCE）——一种PCE的深度泛化，能够有效地扩展到高维输入空间。DeepPCE实现了与多层感知器（MLPs）相当的预测性能，同时保留了PCE通过简单前向传播计算精确统计推断的能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [261] [TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation and Analysis](https://arxiv.org/abs/2506.20380)
> *TESSERA：用于地球表示和分析的地表光谱时间嵌入*

*Zhengpeng Feng, Clement Atzberger, Sadiq Jaffer, Jovana Knezevic, Silja Sormunen, Robin Young, Madeline C Lisaius, Markus Immitzer, David A. Coomes, Anil Madhavapeddy, Andrew Blake, Srinivasan Keshav* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** TESSERA, 遥感, 基础模型, 时间序列, 地球嵌入

**Comment:** 

> **TL;DR:** TESSERA是一个开放的、全球性的、面向陆地的遥感基础模型，它利用自监督学习从卫星时间序列数据生成即用型嵌入，并在多项下游任务中表现优异。

**AI_Comments:** TESSERA的创新性在于其作为首个开放、全球、面向陆地的遥感基础模型，通过自监督学习处理复杂的卫星时间序列数据。它结合了光学和雷达数据，并利用Transformer架构，显著提高了数据可用性和分析效率。其在多项任务中超越基线模型的能力，预示着其在地球科学应用中的巨大潜力，特别是在数据和标签稀缺的环境下。

<details>
  <summary>Details</summary>

**Motivation:** 卫星遥感时间序列数据量大、常被传感器噪声、云和大气条件损坏，且时间间隔不均，这使得它们难以使用。

**Method:** TESSERA是一个利用自监督学习从像素级卫星时间序列数据生成10米尺度“即用型”嵌入的基础模型。它使用两个并行的基于Transformer的编码器结合Sentinel-2光学数据（10个光谱波段，10-60米空间分辨率）和Sentinel-1合成孔径雷达反向散射系数（2个，10米分辨率），然后通过多层感知器融合创建年度全球嵌入图。

**Result:** TESSERA在五项不同的下游任务中与最先进的特定任务模型和其他基础模型进行比较，结果显示它与这些基线模型表现相近或超越它们。

**Conclusion:** 研究人员认为TESSERA的易用性、开放性、计算效率、标签效率、数据效率和高性能将在广泛的植被生态和农业应用中发挥变革性作用。

> **ai_Abstract:** TESSERA是一个创新的遥感基础模型，旨在解决卫星时间序列数据使用中的挑战。它利用自监督学习，结合Sentinel-1和Sentinel-2数据，通过Transformer编码器生成10米尺度的即用型地球表面光谱时间嵌入。该模型在多项下游任务中表现优异，有望在生态和农业应用中实现数据高效且高性能的分析。

> **摘要翻译:** 卫星遥感通过重复观测和多传感器技术，支持广泛的下游应用，包括气候建模、碳核算以及保护和可持续土地利用策略。然而，卫星时间序列数据量庞大，经常受到传感器噪声、云和大气条件的损坏，并且时间间隔不均，这使得它们难以使用。我们提出了TESSERA，一个开放的、全球性的、面向陆地的遥感基础模型，它利用自监督学习从像素级卫星时间序列数据生成10米尺度的“即用型”嵌入。TESSERA使用两个并行的基于Transformer的编码器，结合来自十个Sentinel-2光谱波段（10-60米空间分辨率）的光学数据和两个Sentinel-1合成孔径雷达反向散射系数（10米分辨率），以创建嵌入，随后通过多层感知器融合这些嵌入，以创建年度全球嵌入图。我们在五项不同的下游任务中将我们的工作与最先进的特定任务模型和其他基础模型进行比较，发现TESSERA与这些基线模型表现相近或超越它们。我们相信TESSERA的易用性、开放性、计算效率、标签效率、数据效率和高性能将在广泛的植被生态和农业应用中发挥变革性作用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [281] [LLM-Adapted Interpretation Framework for Machine Learning Models](https://arxiv.org/abs/2507.21179)
> *适用于机器学习模型的LLM自适应解释框架*

*Yuqi Jin, Zihan Hu, Weiteng Zhang, Weihao Xie, Jianwei Shuai, Xian Shen, Zhen Feng* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-26**

**Keywords:** LLM, 可解释AI, 机器学习, XGBoost, 临床诊断

**Comment:** 11 pages, 8 figures, 2 tables

> **TL;DR:** LAI-ML框架结合LLM和知识蒸馏，将XGBoost等黑箱模型的预测转化为可解释的临床叙述，提高了预测准确性并纠正了部分原始模型错误。

**AI_Comments:** 该研究的创新点在于将知识蒸馏与大型语言模型（LLM）相结合，不仅实现了对黑箱机器学习模型的解释，还利用LLM的推理能力纠正了原始模型的部分预测错误。这对于提升医学AI模型的可信度、透明度和临床采纳度具有重要意义，为解决AI在医疗领域的“黑箱”挑战提供了实用且可部署的方案。

<details>
  <summary>Details</summary>

**Motivation:** 解决高性能机器学习模型（如XGBoost）在临床应用中因缺乏可解释性而成为“黑箱”的问题，旨在弥合预测准确性和叙述透明度之间的差距，特别是在肌肉减少症风险评估方面。

**Method:** 提出了LLM自适应解释框架（LAI-ML），一种新颖的知识蒸馏架构。LAI-ML利用HAGA和CACS技术将训练好的XGBoost模型的特征归因转换为概率格式，然后由一个通过强化学习循环和案例检索指导的大型语言模型（LLM）生成数据忠实的诊断叙述。

**Result:** LAI-ML框架实现了83%的预测准确率，比基线XGBoost模型高出13%，显著优于后者。值得注意的是，LLM不仅复制了教师模型的逻辑，还在21.7%的不一致案例中纠正了其预测，显示出增强的推理能力。

**Conclusion:** LAI-ML有效地将不透明的模型预测转化为可信且可解释的临床见解，为医学AI中的“黑箱”问题提供了一种可部署的解决方案。

> **ai_Abstract:** 本文提出了一种名为LLM自适应解释框架（LAI-ML）的新型知识蒸馏架构，旨在解决高性能机器学习模型在临床应用中缺乏可解释性的问题。LAI-ML将XGBoost模型的特征归因转换为概率格式，并利用大型语言模型（LLM）生成数据忠实的诊断叙述。实验结果显示，LAI-ML在预测准确率上达到83%，比基线XGBoost模型高出13%。此外，LLM还能纠正原始模型的部分预测错误，提升了模型的推理能力。该框架为医学AI中的“黑箱”问题提供了一种可部署的解决方案，将不透明的模型预测转化为可信且可解释的临床见解。

> **摘要翻译:** 背景与目标：XGBoost等高性能机器学习模型通常是“黑箱”，由于缺乏可解释性，限制了它们在临床上的应用。本研究旨在弥合预测准确性和叙述透明度之间的差距，用于肌肉减少症风险评估。方法：我们提出了LLM自适应解释框架（LAI-ML），一种新颖的知识蒸馏架构。LAI-ML使用专门的技术（HAGA和CACS）将训练好的XGBoost模型的特征归因转换为概率格式。然后，一个由强化学习循环和基于案例检索指导的大型语言模型（LLM）生成数据忠实的诊断叙述。结果：LAI-ML框架实现了83%的预测准确率，显著优于基线XGBoost模型，高出13%。值得注意的是，LLM不仅复制了教师模型的逻辑，还在21.7%的不一致案例中纠正了其预测，显示出增强的推理能力。结论：LAI-ML有效地将不透明的模型预测转化为可信且可解释的临床见解，为医学AI中的“黑箱”问题提供了一种可部署的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [290] [DGP: A Dual-Granularity Prompting Framework for Fraud Detection with Graph-Enhanced LLMs](https://arxiv.org/abs/2507.21653)
> *DGP：一种用于图增强型大型语言模型欺诈检测的双粒度提示框架*

*Yuan Li, Jun Hu, Bryan Hooi, Bingsheng He, Cheng Chen* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 欺诈检测, 图增强型LLM, 双粒度提示, 信息过载, 文本摘要

**Comment:** 

> **TL;DR:** DGP是一种双粒度提示框架，通过对目标节点保留细粒度文本信息，同时将邻居信息总结为粗粒度文本提示，解决了图增强型LLM在欺诈检测中因多跳关系导致的信息过载问题，显著提升了性能。

**AI_Comments:** DGP的创新之处在于其双粒度提示策略，巧妙地解决了图增强型LLMs在处理复杂图数据时面临的信息过载和长上下文问题。通过区分目标节点和邻居信息的粒度，并引入定制化的总结策略，它在不牺牲关键信息的前提下，有效压缩了提示内容，从而提升了模型性能。这对于将LLMs应用于图结构数据，特别是欺诈检测等领域，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 图增强型大型语言模型（Graph-Enhanced LLMs）在欺诈检测中面临挑战，特别是当处理异构欺诈检测图时，多跳关系会导致邻居信息呈指数级增长，生成冗长且不相关的提示内容，从而淹没目标节点的关键信号，降低模型性能。

**Method:** 本文提出双粒度提示（Dual Granularity Prompting, DGP）框架，通过为目标节点保留细粒度文本细节，同时将邻居信息总结为粗粒度文本提示来缓解信息过载。DGP引入了针对不同数据模态的定制化总结策略：对文本字段进行双层语义抽象，对数值特征进行统计聚合，从而将冗长的邻居内容有效压缩为简洁、信息丰富的提示。

**Result:** DGP在可管理的Token预算内运行，并在公共和工业数据集上将欺诈检测性能（AUPRC）相对于最先进方法提高了高达6.8%。

**Conclusion:** DGP框架通过双粒度提示有效解决了图增强型LLM在欺诈检测中面临的信息过载问题，显著提升了性能，展示了图增强型LLM在欺诈检测领域的潜力。

> **ai_Abstract:** 本研究提出DGP（Dual-Granularity Prompting）框架，旨在解决图增强型大型语言模型（Graph-Enhanced LLMs）在异构欺诈检测图中因多跳关系导致的信息过载问题。传统的仅文本提示方法在处理大量冗余邻居信息时性能下降。DGP通过对目标节点保持细粒度文本信息，同时对邻居信息进行粗粒度总结来缓解此问题，具体采用双层语义抽象处理文本字段和统计聚合处理数值特征。实验证明，DGP在保持合理Token预算的同时，显著提升了欺诈检测的性能。

> **摘要翻译:** 现实世界的欺诈检测应用受益于图学习技术，这些技术共同利用节点特征（通常富含文本数据）和图结构信息。最近，图增强型大型语言模型（Graph-Enhanced LLMs）作为一种有前途的图学习方法出现，它将图信息转换为提示，利用LLMs对文本和结构信息进行推理的能力。其中，仅文本提示（text-only prompting）将图信息转换为仅由文本标记组成的提示，提供了一种仅依赖LLM微调而无需额外图特定编码器的解决方案。然而，仅文本提示在异构欺诈检测图上表现不佳：多跳关系随着每次额外的跳数呈指数级扩展，导致与密集文本信息相关的邻居迅速增长。这些邻居可能会用提示中冗长、不相关的内容使模型不堪重负，并抑制来自目标节点的关键信号，从而降低性能。为了解决这一挑战，我们提出了双粒度提示（Dual Granularity Prompting, DGP），它通过为目标节点保留细粒度文本细节，同时将邻居信息总结为粗粒度文本提示来缓解信息过载。DGP引入了针对不同数据模态的定制化总结策略：对文本字段进行双层语义抽象，对数值特征进行统计聚合，从而将冗长的邻居内容有效压缩为简洁、信息丰富的提示。在公共和工业数据集上的实验表明，DGP在可管理的Token预算内运行，同时将欺诈检测性能（AUPRC）相对于最先进方法提高了高达6.8%，显示了图增强型大型语言模型在欺诈检测中的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [292] [Agent-centric learning: from external reward maximization to internal knowledge curation](https://arxiv.org/abs/2507.22255)
> *智能体中心学习：从外部奖励最大化到内部知识管理*

*Hanqi Zhou, Fryderyk Mantiuk, David G. Nagy, Charley M. Wu* | **Category: cs.LG, cs.AI, cs.SC** | **Updated: 2025-07-29**

**Keywords:** 智能体中心学习, 表征赋能, 知识管理, 通用智能, 适应性

**Comment:** RLC Finding the Frame Workshop 2025

> **TL;DR:** 提出一种以智能体为中心的新学习范式：表征赋能，强调通过内部知识管理而非外部奖励来提升智能体的适应性。

**AI_Comments:** 这篇论文提出了一种新颖的视角，将智能体学习的重点从外部奖励转向内部知识管理，这对于提升通用智能体的适应性和自主性具有重要意义。它挑战了传统AI设计的范式，强调了智能体内部状态和自我组织能力的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 传统通用智能追求外部目标（控制环境或掌握特定任务）导致智能体缺乏适应性。

**Method:** 提出“表征赋能”（representational empowerment）作为一种新的以智能体为中心的学习范式。该目标衡量智能体可控地维护和多样化自身知识结构的能力。

**Result:** Not mentioned in abstract

**Conclusion:** 关注内部表征作为计算赋能的主要基础，为设计适应性智能系统提供了新视角。

> **ai_Abstract:** 这篇论文提出了一种名为“表征赋能”的新型以智能体为中心的学习范式，旨在解决传统外部目标导向学习导致智能体适应性不足的问题。该方法将学习的重心从外部奖励转移到智能体内部知识结构的可控维护和多样化，强调通过提升智能体自我塑造理解的能力来增强其“准备度”和适应性。

> **摘要翻译:** 追求通用智能传统上集中于外部目标：智能体对环境的控制或对特定任务的掌握。然而，这种外部关注可能产生缺乏适应性的专业化智能体。我们提出表征赋能，这是一种通过将控制中心向内转移，从而实现真正以智能体为中心的学习范式的新视角。该目标衡量智能体可控地维护和多样化自身知识结构的能力。我们认为，塑造自身理解的能力是实现更好“准备度”的一个要素，这与直接的环境影响不同。将内部表征作为计算赋能的主要基质，为设计适应性智能系统提供了一个新视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [296] [Large Language Model-Enhanced Reinforcement Learning for Diverse and Novel Recommendations](https://arxiv.org/abs/2507.21274)
> *大型语言模型增强的强化学习用于多样化和新颖推荐*

*Jiin Woo, Alireza Bagheri Garakani, Tianchen Zhou, Zhishen Huang, Yan Gao* | **Category: cs.LG** | **Updated: 2025-07-28**

**Keywords:** 大型语言模型, 强化学习, 推荐系统, 多样性, 新颖性

**Comment:** 

> **TL;DR:** LAAC是一种利用大型语言模型(LLM)作为参考策略的强化学习方法，旨在提升推荐系统的多样性和新颖性，同时保持准确性，并在不进行昂贵微调的情况下集成LLM知识。

**AI_Comments:** LAAC的创新之处在于其将大型语言模型作为强化学习的参考策略，以克服传统RL在推荐系统随机探索的局限性，并引入双层优化和正则化机制来有效融合LLM知识并提升推荐质量，同时避免了LLM的昂贵微调，使其更具实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在推荐系统中，多样性和新颖性对于捕捉用户偏好和鼓励探索至关重要，但许多系统优先考虑点击相关性。虽然强化学习(RL)已被探索用于提高多样性，但其随机探索可能不符合用户兴趣。

**Method:** 本文提出LAAC（LLM-guided Adversarial Actor Critic），一种新颖的方法，利用大型语言模型（LLM）作为参考策略来建议新颖物品，同时训练一个轻量级策略使用系统特定数据来完善这些建议。该方法将训练公式化为演员和评论家网络之间的双层优化，使评论家能够选择性地偏爱有前景的新颖动作，并使演员能够改进其策略超越LLM推荐。为减轻对不可靠LLM建议的过高估计，应用了正则化，将未探索物品的评论家值锚定在接近估计良好的数据集动作上。

**Result:** 在真实世界数据集上的实验表明，LAAC在多样性、新颖性和准确性方面优于现有基线，同时在不平衡数据上保持鲁棒性，有效地集成了LLM知识而无需昂贵的微调。

**Conclusion:** LAAC通过结合大型语言模型和强化学习，成功地在推荐系统中实现了多样性、新颖性和准确性的提升，并展示了在不平衡数据上的鲁棒性和无需昂贵微调的优点。

> **ai_Abstract:** 本文提出了一种名为LAAC（LLM-guided Adversarial Actor Critic）的新型强化学习方法，旨在解决推荐系统中多样性和新颖性不足的问题。LAAC利用大型语言模型（LLM）生成新颖物品建议，并通过双层优化训练一个轻量级策略来精炼这些建议。该方法通过正则化避免LLM建议的过高估计。实验证明，LAAC在多样性、新颖性和准确性方面优于现有基线，并在不平衡数据上表现出鲁棒性，实现了在不进行昂贵微调的情况下有效整合LLM知识。

> **摘要翻译:** 在推荐系统中，多样性和新颖性对于捕捉不同的用户偏好和鼓励探索至关重要，然而许多系统优先考虑点击相关性。虽然强化学习（RL）已被探索用于提高多样性，但它通常依赖于可能与用户兴趣不符的随机探索。我们提出了LAAC（LLM引导的对抗性演员-评论家），这是一种新颖的方法，它利用大型语言模型（LLM）作为参考策略来建议新颖物品，同时训练一个轻量级策略使用系统特定数据来完善这些建议。该方法将训练公式化为演员和评论家网络之间的双层优化，使评论家能够选择性地偏爱有前景的新颖动作，并使演员能够改进其策略超越LLM推荐。为了减轻对不可靠LLM建议的过高估计，我们应用了正则化，将未探索物品的评论家值锚定在接近估计良好的数据集动作上。在真实世界数据集上的实验表明，LAAC在多样性、新颖性和准确性方面优于现有基线，同时在不平衡数据上保持鲁棒性，有效地集成了LLM知识而无需昂贵的微调。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [300] [Generating Heterogeneous Multi-dimensional Data : A Comparative Study](https://arxiv.org/abs/2507.00090)
> *生成异构多维数据：一项比较研究*

*Michael Corbeau, Emmanuelle Claeys, Mathieu Serrurier, Pascale Zaraté* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 异构数据生成, 比较研究, 消防员干预, 生成模型, 领域特定评估

**Comment:** accepted at IEEE SMC 2025 Vienna

> **TL;DR:** 本文比较了多种数据生成方法，包括VAE、GAN和DPM，以创建用于消防员干预模拟的异构、不平衡的多维数据，并使用领域特定指标评估生成数据的质量。

**AI_Comments:** 本文的创新点在于将多种先进的生成模型应用于消防员干预这一特定且关键的领域，尤其是在处理高度不平衡、非高斯分布的异构多维数据方面。其采用领域特定评估指标而非仅仅依赖传统指标，提升了合成数据在真实世界场景中的实用性和相关性，对于优化紧急响应资源分配具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 消防员干预中的人员和物资资源分配至关重要，依赖于模拟来实验各种场景以实现全局优化响应。研究各种场景需要强制性的数据生成。

**Method:** 本研究比较了随机抽样、表格变分自编码器（TVAE）、标准生成对抗网络（GAN）、条件表格生成对抗网络（CTGAN）和扩散概率模型（DPM）等多种数据生成方法，以评估它们在捕捉消防员干预复杂性方面的效率。合成数据质量的评估使用消防领域特定的领域指标（包括响应时间分布、干预时空分布和事故表示）和标准度量（如Wasserstein距离）相结合的方式进行。

**Result:** 摘要中未提及具体结果。

**Conclusion:** 摘要中未提及。

> **ai_Abstract:** 本研究旨在比较多种数据生成方法（包括随机抽样、TVAE、GAN、CTGAN和DPM），以生成用于消防员干预模拟的异构多维数据。鉴于传统评估指标的不足，论文提出结合领域特定指标（如响应时间、时空分布、事故表示）和标准度量（如Wasserstein距离）来评估合成数据的质量，特别关注数据变异性、复杂相关性、异常情况和操作相关性。该研究强调了处理高度不平衡且非高斯分布数据的复杂性。

> **摘要翻译:** 消防员干预中人员和物资资源的分配至关重要。这种分配依赖于模拟来实验各种场景。这种分配的主要目标是消防员响应的全局优化。因此，数据生成对于研究各种场景是强制性的。在本研究中，我们提出比较不同的数据生成方法。研究了随机抽样、表格变分自编码器、标准生成对抗网络、条件表格生成对抗网络和扩散概率模型等方法，以确定它们在捕捉消防员干预复杂性方面的有效性。传统的评估指标往往无法捕捉真实世界场景中合成数据集的细微需求。为了解决这一差距，本研究结合了针对消防领域量身定制的领域特定指标和诸如Wasserstein距离等标准度量，对合成数据质量进行了评估。领域特定指标包括响应时间分布、干预的时空分布以及事故表示。这些指标旨在评估数据变异性、保留精细和复杂相关性以及诸如发生率极低的事件等异常情况、与初始统计分布的一致性以及合成数据的操作相关性。该分布的特殊性在于高度不平衡，没有变量遵循高斯分布，这增加了数据生成过程的复杂性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [308] [OWLViz: An Open-World Benchmark for Visual Question Answering](https://arxiv.org/abs/2503.07631)
> *OWLViz：一个开放世界视觉问答的基准*

*Thuy Nguyen, Dang Nguyen, Hoang Nguyen, Thuan Luong, Long Hoang Dang, Viet Dac Lai* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 开放世界视觉问答, 基准, 多模态系统, 工具使用, 复杂推理

**Comment:** 8 pages + appendix

> **TL;DR:** 提出了OWLViz，一个开放世界视觉问答的新基准，人类表现远超最先进的多模态模型，揭示了当前系统在工具选择和复杂推理方面的局限性。

**AI_Comments:** OWLViz基准的提出，通过其开放世界和多能力整合的特性，有效揭示了当前最先进多模态模型在复杂推理和工具使用方面的深层局限。其显著的人机性能差距强调了在实用AI领域，特别是代理VLM发展中的巨大挑战和研究潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态系统在开放世界视觉问答任务中存在显著局限性，特别是在选择合适工具和执行复杂推理序列方面表现不佳，因此需要建立新的研究方向来推进实用AI。

**Method:** 提出了OWLViz，一个针对开放世界视觉问答（OWLViz）任务的具有挑战性的基准。该基准包含简洁、明确的查询，需要整合视觉理解、网络探索和专业工具使用等多项能力。

**Result:** 人类在该直观任务上能达到69.2%的准确率，而最先进的VLM（如Gemini 2.0）仅能达到26.6%的准确率。依赖有限视觉和视觉语言模型作为工具的当前代理VLM表现更差。

**Conclusion:** 现有多模态系统在选择适当工具和执行复杂推理序列方面的能力存在显著局限性，这为推进实用AI研究确立了新的方向。

> **ai_Abstract:** 本文提出了OWLViz，一个用于开放世界视觉问答的新型高难度基准。该基准要求模型整合视觉理解、网络探索和工具使用等多方面能力。实验结果显示，人类在该任务上表现远超最先进的视觉语言模型（包括Gemini 2.0），凸显了当前多模态系统在工具选择和复杂推理方面的显著不足，为未来AI研究指明了方向。

> **摘要翻译:** 我们提出了一个针对开放世界视觉问答（OWLViz）任务的具有挑战性的基准。OWLViz提供了简洁、明确的查询，需要整合多项能力，包括视觉理解、网络探索和专业工具使用。虽然人类在这些直观任务上能达到69.2%的准确率，但即使是最先进的视觉语言模型（VLM）也表现不佳，其中最好的模型Gemini 2.0也只达到了26.6%的准确率。目前依赖有限视觉和视觉语言模型作为工具的代理VLM表现更差。这种性能差距揭示了多模态系统在选择适当工具和执行复杂推理序列方面的显著局限性，为推进实用AI研究确立了新的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [320] [Hypernetworks for Model-Heterogeneous Personalized Federated Learning](https://arxiv.org/abs/2507.22330)
> *超网络用于模型异构的个性化联邦学习*

*Chen Zhang, Husheng Li, Xiang Liu, Linshan Jiang, Danxin Wang* | **Category: cs.LG, cs.DC** | **Updated: 2025-07-30**

**Keywords:** 超网络, 联邦学习, 模型异构性, 个性化

**Comment:** 

> **TL;DR:** 提出MH-pFedHN，一个基于超网络的框架，用于解决模型异构的个性化联邦学习问题，无需外部数据，具有强泛化能力和隐私保护。

**AI_Comments:** 该论文的创新之处在于利用超网络解决模型异构的个性化联邦学习问题，且无需外部数据或披露客户端架构，从而增强了隐私和灵活性。引入多头结构是一种巧妙的方法，可以促进知识共享并减少计算。其作为未来研究的稳健基线具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有个性化联邦学习方法在处理客户端模型异构性时，通常需要外部数据、依赖模型解耦或采用部分学习策略，这限制了其实用性和可扩展性。

**Method:** 该文提出MH-pFedHN，一个服务器端超网络，以客户端特定的嵌入向量为输入，为每个客户端的异构模型输出个性化参数。为促进知识共享和减少计算，引入了超网络中的多头结构，允许模型大小相似的客户端共享头部。此外，还提出了MH-pFedHNGD，它集成了可选的轻量级全局模型以提高泛化能力。该框架不依赖外部数据集，不要求披露客户端模型架构。

**Result:** 在多个基准和模型设置上的大量实验表明，该方法实现了具有竞争力的准确性、强大的泛化能力，并可作为未来模型异构个性化联邦学习研究的强大基线。

**Conclusion:** 所提出的MH-pFedHN和MH-pFedHNGD框架为模型异构的个性化联邦学习提供了一种有效、实用且保护隐私的解决方案，展现出强大的性能，并可作为未来研究的稳健基线。

> **ai_Abstract:** 本文针对现有模型异构个性化联邦学习方法存在的局限性，提出了一种基于超网络的框架MH-pFedHN。MH-pFedHN利用服务器端超网络为异构客户端模型生成个性化参数，并引入多头结构以提高效率，同时提出MH-pFedHNGD以集成可选的轻量级全局模型来提升泛化能力。该框架无需外部数据且不要求披露客户端模型架构，实验证明其具有竞争力的准确性、强大的泛化能力，并可作为未来研究的稳健基线。

> **摘要翻译:** 个性化联邦学习的最新进展主要集中于解决客户端模型异构性问题。然而，大多数现有方法仍需要外部数据、依赖模型解耦或采用部分学习策略，这可能限制其实用性和可扩展性。在本文中，我们重新审视了基于超网络的方法，并利用其强大的泛化能力，设计了一个简单而有效的框架，用于异构个性化联邦学习。具体来说，我们提出了MH-pFedHN，它利用一个服务器端超网络，该网络以客户端特定的嵌入向量作为输入，并为每个客户端的异构模型输出定制的个性化参数。为了促进知识共享和减少计算，我们在超网络中引入了多头结构，允许模型大小相似的客户端共享头部。此外，我们进一步提出了MH-pFedHNGD，它集成了可选的轻量级全局模型以提高泛化能力。我们的框架不依赖外部数据集，也不要求披露客户端模型架构，从而提供了增强的隐私和灵活性。在多个基准和模型设置上的大量实验表明，我们的方法实现了具有竞争力的准确性、强大的泛化能力，并可作为未来模型异构个性化联邦学习研究的强大基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [322] [Enhancing Ultra-Low-Bit Quantization of Large Language Models Through Saliency-Aware Partial Retraining](https://arxiv.org/abs/2504.13932)
> *通过显著性感知的部分重训练增强大型语言模型的超低比特量化*

*Deyu Cao, Samin Aref* | **Category: cs.LG, cs.CL, 68T50, 68T07, 68T09, 68U15, I.2.7; I.2.6; I.2.4** | **Updated: 2025-07-30**

**Keywords:** 超低比特量化, 大型语言模型, 显著性感知, 部分重训练, 模型压缩

**Comment:** This is a post-peer-review accepted manuscript from the proceedings
  of the 22nd International Conference on Modeling Decisions for Artificial
  Intelligence (MDAI'25). The publisher authenticated version and full citation
  details are available on Springer's website (LNAI 15957).
  https://doi.org/10.1007/978-3-032-00891-6_28

> **TL;DR:** 本文提出了一种新的超低比特量化方法，通过显著性感知的部分重训练，在不进行完全重训练的情况下，显著降低了大型语言模型（LLMs）的精度损失，超越了现有ApiQ方法的性能。

**AI_Comments:** 本文通过引入显著性感知正则化项，在部分重训练的框架下，有效提升了超低比特量化大型语言模型的性能，避免了计算成本高昂的完全重训练。这一创新性方法在解决大型语言模型部署的资源消耗问题上具有重要意义，因为它在保持模型性能的同时，显著提高了模型的资源效率。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在推理过程中资源消耗巨大（能源和水），引发了环境和经济担忧。量化技术可以压缩模型以提高资源效率，但可能导致性能下降。现有方法如ApiQ在精度保持方面表现出色，但在超低比特量化方面仍有提升空间。

**Method:** 研究了将现有量化感知训练技术与ApiQ的部分训练结合，发现其在有限训练数据和冻结权重下未能超越ApiQ基线。基于此，得出两个关键洞察：1）通过部分训练难以实现完全重训练所获得的大量表征能力；2）这种增益可能取决于在量化感知训练中使用大型且多样化的数据集。在此基础上，提出了一种新颖的超低比特量化方法，该方法基于ApiQ并引入了显著性感知正则化项，优先保留量化过程中最具影响力的参数，从而在不进行完全重训练的情况下扩展了性能。

**Result:** 在LLaMA 7B和13B基准测试中，所提出的方法将ApiQ的精度下降分别降低了10.85%和7.54%。

**Conclusion:** 本文提出的显著性感知部分重训练方法有效地增强了大型语言模型的超低比特量化，在不进行完全重训练的情况下，显著减少了相对于ApiQ的精度下降。

> **ai_Abstract:** 本文旨在解决大型语言模型（LLMs）推理过程中的资源密集问题，通过改进超低比特量化技术。在现有ApiQ方法的基础上，作者提出了一种新颖的显著性感知部分重训练方法。该方法引入了一个正则化项，用于优先保留量化过程中最重要的参数，从而在不进行完全重训练的情况下，显著降低了超低比特量化带来的精度损失。在LLaMA 7B和13B模型上的实验结果表明，与ApiQ相比，该方法分别将精度下降减少了10.85%和7.54%。该方法的Python实现已公开可用。

> **摘要翻译:** 大型语言模型日益增长的使用引发了对其推理过程中资源使用强度的环境和经济担忧。为每个用户提供这些模型需要大量的能源和冷却用水。量化等模型压缩技术可以缩小大型语言模型，使其更具资源效率，但代价是潜在的性能下降。量化方法通过用较低精度的量化值替换其高精度参数来压缩模型大小。在现有方法中，ApiQ方法以最小的内存和时间开销实现了卓越的精度保持。我们研究了两个想法，以将超低比特量化的性能扩展到ApiQ的水平之上。首先，我们尝试将现有量化感知训练技术与ApiQ的部分训练相结合。我们发现，在有限的训练数据和冻结的权重下，这并没有超越基线ApiQ方法。这导致了两个关键见解：（1）通过完全重训练获得的大量表征能力不太可能通过部分训练实现。（2）这种增益可能取决于在量化感知训练中使用大型和多样化的数据集。其次，通过一种受这两个见解启发的新颖方法，我们提出了一种超低比特量化方法，该方法基于ApiQ并扩展了其性能，而无需进行完全重训练。这种公开可用的方法依赖于一个显著性感知正则化项，该项在量化过程中优先保留最具影响力的参数。我们在LLaMA 7B和13B基准测试上的实验表明，我们的方法将ApiQ的精度下降分别降低了10.85%和7.54%。所提出的量化方法的Python实现已在GitHub上公开提供：https://github.com/TokuyuSou/ULB-SAPR。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [332] [Diffusion Beats Autoregressive in Data-Constrained Settings](https://arxiv.org/abs/2507.15857)
> *扩散模型在数据受限设置下优于自回归模型*

*Mihir Prabhudesai, Mengning Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak* | **Category: cs.LG, cs.AI, cs.CV, cs.RO** | **Updated: 2025-07-29**

**Keywords:** 扩散模型, 自回归模型, 数据受限, 语言模型, 缩放定律

**Comment:** Project Webpage: https://diffusion-scaling.github.io

> **TL;DR:** 当数据稀缺但计算资源充足时，扩散模型能显著优于自回归模型，因为它能更好地利用重复数据。

**AI_Comments:** 这篇论文强调了扩散模型在特定情境（数据稀缺）下的显著优势，解决了大型语言模型训练中一个实际的限制。其提出的“隐式数据增强”概念以及对扩散模型缩放定律和临界计算阈值的推导是创新性的贡献，为扩散模型在数据稀缺环境下的效率提供了理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 自回归（AR）模型长期主导大型语言模型领域，但基于扩散的语言模型作为有前景的替代方案兴起，其相对于AR模型的优势，尤其是在数据受限设置下，尚未得到充分探索。

**Method:** 本文系统地研究了在数据受限设置下（训练涉及对有限数据进行重复遍历）的掩码扩散模型，并将其与自回归模型进行比较。

**Result:** 研究发现，当计算资源充足但数据稀缺时，扩散模型显著优于自回归模型。扩散模型能更好地利用重复数据，实现更低的验证损失和更优的下游性能。这种优势被解释为隐式数据增强。研究还发现了扩散模型的新缩放定律，并推导出了扩散模型开始优于自回归模型的临界计算阈值的闭式表达式。

**Conclusion:** 当数据而非计算是瓶颈时，扩散模型为标准自回归范式提供了一个有力的替代方案。

> **ai_Abstract:** 本文系统研究了在数据受限环境下掩码扩散模型与自回归模型的性能。研究发现，当数据稀缺而计算资源充足时，扩散模型能显著超越自回归模型，其优势在于能更有效地利用重复数据，从而获得更低的验证损失和更优的下游性能。这种优势被归因于隐式数据增强，即模型暴露于多样化的词元排序。此外，研究还提出了扩散模型的新缩放定律，并推导出了扩散模型超越自回归模型的临界计算阈值，表明在数据是瓶颈的情况下，扩散模型是一个有力的替代方案。

> **摘要翻译:** 自回归（AR）模型长期以来一直主导着大型语言模型的领域，推动着广泛任务的进展。最近，基于扩散的语言模型作为一种有前景的替代方案出现，尽管它们相对于AR模型的优势仍未得到充分探索。在本文中，我们系统地研究了数据受限设置下的掩码扩散模型——在这种设置下，训练涉及对有限数据进行重复遍历——并发现当计算资源充足但数据稀缺时，它们显著优于AR模型。扩散模型能更好地利用重复数据，实现更低的验证损失和更优的下游性能。我们将这种优势解释为隐式数据增强：与AR模型固定的从左到右分解不同，掩码扩散模型使模型暴露于多样化的词元排序和预测任务分布。我们发现了扩散模型的新缩放定律，并推导出了扩散模型开始优于AR模型的临界计算阈值的闭式表达式。这些结果表明，当数据而非计算是瓶颈时，扩散模型为标准AR范式提供了一个有力的替代方案。我们的代码可在以下网址获取：https://diffusion-scaling.github.io。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [335] ["So, Tell Me About Your Policy...": Distillation of interpretable policies from Deep Reinforcement Learning agents](https://arxiv.org/abs/2507.07848)
> *“那么，告诉我你的策略…”：从深度强化学习智能体中提取可解释策略*

*Giovanni Dispoto, Paolo Bonetti, Marcello Restelli* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 深度强化学习, 可解释性, 策略提取, 优势函数, 机器学习

**Comment:** Accepted at ECAI 2025

> **TL;DR:** 本文提出了一种新颖的算法，能够从深度强化学习智能体中提取可解释的策略，解决了深度强化学习缺乏可解释性的问题，并且能够利用已收集的经验进行训练。

**AI_Comments:** 本文的创新之处在于提出了一种具有理论保证的方法，能够从复杂的深度强化学习模型中提取可解释的策略，这对于DRL在任务关键型和真实世界应用中的部署至关重要。特别是其能够利用先前收集的经验进行训练，这提高了数据利用效率。该工作有效解决了DRL可解释性差的痛点，有助于推动DRL的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习（DRL）虽然在复杂任务中表现出色，但其缺乏可解释性是一个重大挑战，尤其是在理解学习到的模式、状态特征的重要性以及策略生成方式方面。在任务关键型和真实世界环境中，通常倾向于部署更简单、更可解释的算法，即使牺牲性能。因此，需要一种方法来提取可解释的策略而不牺牲专家行为的特性。

**Method:** 本文提出了一种新颖的算法，该算法具有理论保证，能够从深度强化学习智能体中提取可解释的策略（例如线性策略）。该方法通过考虑优势函数（其中包含关于为什么某个动作优于其他动作的信息）来实现，并且与以往工作不同，它能够利用先前收集的经验来训练可解释策略。

**Result:** 所提出的算法在经典控制环境和金融交易场景中进行了实证评估，结果表明它能够从复杂的专家策略中提取有意义的信息。

**Conclusion:** 本文提出的算法成功地解决了深度强化学习的可解释性问题，能够从复杂的DRL智能体中提取出具有理论保证且可解释的策略，并且能够有效利用已有的经验数据。

> **ai_Abstract:** 深度强化学习（DRL）在解决复杂问题上取得了显著进展，但其缺乏可解释性限制了其在关键领域的应用。本文提出了一种新颖的算法，旨在从DRL智能体中提取可解释的策略（如线性策略），同时保留专家行为的特性。该方法通过利用优势函数，并允许使用已收集的经验进行训练。实验结果表明，该算法能够有效地从复杂的专家策略中提取有意义的信息。

> **摘要翻译:** 最近强化学习（RL）的进步主要得益于深度神经网络的引入，这极大地推动了深度强化学习（DRL）领域新方法的提出。这些技术展示了解决复杂游戏（如Atari、Go）以及其他现实世界应用（包括金融交易）的能力。然而，一个显著的挑战源于其缺乏可解释性，尤其是在尝试理解学习到的底层模式、状态特征的相对重要性以及它们如何整合以生成策略输出时。因此，在任务关键型和现实世界环境中，通常更倾向于部署更简单、更可解释的算法，尽管这会以牺牲性能为代价。在本文中，我们提出了一种新颖的算法，并提供了理论保证，该算法能够提取可解释的策略（例如线性策略），同时不忽视专家行为的特殊性。这一结果是通过考虑优势函数获得的，该函数包含了关于为什么某个动作优于其他动作的信息。与以往的工作不同，我们的方法能够利用先前收集的经验来训练可解释策略。所提出的算法在经典控制环境和金融交易场景中进行了实证评估，证明了其从复杂专家策略中提取有意义信息的能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [344] [MaPPO: Maximum a Posteriori Preference Optimization with Prior Knowledge](https://arxiv.org/abs/2507.21183)
> *MaPPO：结合先验知识的最大后验偏好优化*

*Guangchen Lan, Sipeng Zhang, Tianle Wang, Yuwei Zhang, Daoan Zhang, Xinpeng Wei, Xiaoman Pan, Hongming Zhang, Dong-Jun Han, Christopher G. Brinton* | **Category: cs.LG, cs.AI, cs.CL, I.2.6; I.2.7** | **Updated: 2025-07-27**

**Keywords:** 偏好优化, 大型语言模型, 最大后验, 先验知识, 模型对齐

**Comment:** 

> **TL;DR:** MaPPO是一种新的偏好优化方法，通过将先验奖励知识纳入最大后验目标来改进LLM与人类偏好的对齐，且无需额外超参数，在多个基准测试中表现出一致的性能提升。

**AI_Comments:** MaPPO的创新之处在于其将先验奖励知识融入最大后验目标，这比传统的最大似然估计方法更具原则性，并能有效避免过度简化的二元分类问题。其无需额外超参数和作为插件的兼容性，使其具有很高的实用价值和广阔的应用前景。该方法在多个基准测试中表现出一致的性能提升，表明其在LLM对齐方面的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的偏好优化方法（如DPO及其变体）将偏好学习视为最大似然估计问题，这可能通过过度简化的二元分类响应来限制对齐效果。随着大型语言模型（LLMs）代表用户时代的到来，需要更有效的方法来将LLMs与人类偏好对齐并提高性能。

**Method:** 本文提出了最大后验偏好优化（MaPPO），一个从偏好中学习的框架，它将先验奖励知识明确地纳入优化目标。MaPPO通过将先验奖励估计整合到最大后验（MaP）目标中，扩展了现有的最大似然估计（MLE）范式，从而推广了DPO及其变体。MaPPO没有引入额外的超参数，并支持离线和在线设置下的偏好优化。此外，MaPPO可以作为插件与DPO变体（包括SimPO、IPO和CPO）结合使用。

**Result:** 在MT-Bench、AlpacaEval 2.0和Arena-Hard三个标准基准上，对不同模型大小和模型系列的广泛实证评估表明，MaPPO在不牺牲计算效率的情况下，始终能提高对齐性能，并对DPO变体（如SimPO、IPO和CPO）带来持续改进。

**Conclusion:** MaPPO通过将先验奖励知识整合到最大后验目标中，提供了一种原则性的方法来改进大型语言模型与人类偏好的对齐，并在多个基准测试中展现出卓越且稳定的性能提升，同时兼容现有方法并无需额外超参数。

> **ai_Abstract:** 本文提出了一种名为MaPPO（最大后验偏好优化）的新型框架，旨在通过将先验奖励知识显式整合到优化目标中，来改进大型语言模型（LLMs）与人类偏好的对齐。与DPO等现有方法基于最大似然估计不同，MaPPO采用最大后验（MaP）目标，从而推广了DPO及其变体，并减轻了过度简化的二元分类问题。MaPPO无需额外超参数，支持离线和在线设置，并可作为插件增强现有DPO变体。在MT-Bench、AlpacaEval 2.0和Arena-Hard等多个标准基准上的广泛评估表明，MaPPO在不牺牲计算效率的情况下，持续提高了LLM的对齐性能。

> **摘要翻译:** 随着大型语言模型（LLMs）代表用户的时代展开，偏好优化（PO）方法已成为将LLMs与人类偏好对齐并提高性能的核心方法。我们提出了最大后验偏好优化（MaPPO），一个从偏好中学习的框架，它将先验奖励知识明确地纳入优化目标。虽然现有方法如直接偏好优化（DPO）及其变体将偏好学习视为最大似然估计（MLE）问题，但MaPPO通过将先验奖励估计整合到原则性的最大后验（MaP）目标中来扩展这一范式。这不仅推广了DPO及其变体，而且通过减轻响应的过度简化二元分类来增强对齐。更重要的是，MaPPO没有引入额外的超参数，并支持离线和在线设置下的偏好优化。此外，MaPPO可以作为插件与DPO变体结合使用，并在广泛使用的SimPO、IPO和CPO上持续改进。在包括MT-Bench、AlpacaEval 2.0和Arena-Hard在内的三个标准基准上，对不同模型大小和模型系列的广泛实证评估表明，在不牺牲计算效率的情况下，对齐性能得到了持续改进。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [346] [Probabilistic Consistency in Machine Learning and Its Connection to Uncertainty Quantification](https://arxiv.org/abs/2507.21670)
> *机器学习中的概率一致性及其与不确定性量化的联系*

*Paul Patrone, Anthony Kearsley* | **Category: cs.LG, math.PR** | **Updated: 2025-07-29**

**Keywords:** 概率一致性, 不确定性量化, 机器学习, 贝叶斯分类器, 水平集理论

**Comment:** 

> **TL;DR:** 本文通过诊断推理，分析了机器学习模型中的概率一致性与不确定性量化之间的联系。研究表明，自洽的机器学习模型等价于类条件概率分布，并提出了构建贝叶斯最优分类器和估计不确定性的方法，为机器学习的不确定性量化提供了理论基础。

**AI_Comments:** 本文通过引入诊断推理和流行率概念，为理解机器学习模型的内部机制及其概率解释提供了新颖的视角。其提出的分类水平集理论以及自洽模型与类条件概率分布的等价性，对于提升机器学习模型的可解释性和置信度量化具有重要意义。特别是，证明了归一化和自洽条件是模型具有有效概率解释的必要条件，为未来机器学习模型的设计和评估提供了坚实的理论基础，对不确定性量化领域贡献显著。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习的黑盒性质使其难以量化预测置信度，并且难以理解模型如何抽象训练数据。本文旨在解决这些问题并探索其与不确定性量化（UQ）的联系。

**Method:** 本文通过诊断推理，分析了流行率（prevalence）的多种解释，推导出了分类的水平集理论。研究了二元贝叶斯最优分类器的性质，并将其边界集重新解释为成对密度比的水平集。通过流行率参数化贝叶斯分类器，揭示了其单调性和类切换特性。在多类别情况下，推导了归一化和自洽条件。

**Result:** 某些类型的自洽机器学习模型等价于类条件概率分布。通过流行率参数化贝叶斯分类器，可以推导出密度比。这些信息足以构建多类别贝叶斯最优分类器和估计类别分配中的内在不确定性。多类别情况下的归一化和自洽条件是任意机器学习模型具有有效概率解释的必要条件。

**Conclusion:** 本文的分析为机器学习的不确定性量化（UQ）提供了信息，通过不确定性传播框架展示了其应用。研究表明，所推导的归一化和自洽条件是任意机器学习模型具有有效概率解释的必要条件。

> **ai_Abstract:** 本文针对机器学习模型黑盒性质导致难以量化预测置信度的问题，提出了一种基于诊断推理的方法，探讨机器学习中的概率一致性与不确定性量化的联系。研究通过分析流行率，推导了分类的水平集理论，证明了自洽的机器学习模型等价于类条件概率分布。通过对二元贝叶斯最优分类器的分析及其流行率参数化，揭示了其单调性和类切换特性，并证明这些信息足以构建多类别贝叶斯最优分类器和估计不确定性。研究还提出了多类别情况下的归一化和自洽条件，并证明其是任意机器学习模型具有有效概率解释的必要条件，为机器学习的不确定性量化提供了理论基础。

> **摘要翻译:** 机器学习（ML）通常被视为一种强大的数据分析工具，因其黑盒性质而易于学习。然而，正是这种性质也使得难以量化从ML模型中提取的预测置信度，更根本的是，难以理解这些模型是如何训练数据的数学抽象。本文的目标是通过诊断推理来揭示这些问题及其与不确定性量化（UQ）的联系。在这种情况下，流行率——即类别中元素的比例——通常具有固有的兴趣。在这里，我们分析了流行率的多种解释，以推导分类的水平集理论，该理论表明某些类型的自洽ML模型等价于类条件概率分布。我们首先研究二元贝叶斯最优分类器的性质，认识到它们的边界集可以被重新解释为成对密度比的水平集。通过根据流行率参数化贝叶斯分类器，我们接着展示了它们满足重要的单调性和类切换特性，这些特性可以用于在不直接访问边界集的情况下推导密度比。此外，这些信息足以完成诸如构建多类别贝叶斯最优分类器和估计类别分配中固有不确定性等任务。在多类别情况下，我们使用这些结果来推导归一化和自洽条件，后者等价于分类器的全概率定律。我们还表明，这些是任意ML模型具有有效概率解释的必要条件。在整个研究中，我们通过不确定性传播框架展示了这种分析如何为ML的UQ这一更广泛的任务提供信息。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [352] [Blending data and physics for reduced-order modeling of systems with spatiotemporal chaotic dynamics](https://arxiv.org/abs/2507.21299)
> *数据与物理融合：用于时空混沌动力学系统降阶建模*

*Alex Guo, Michael D. Graham* | **Category: cs.LG** | **Updated: 2025-07-21**

**Keywords:** 降阶建模, 混沌动力学, 数据驱动, 物理信息, 混合模型

**Comment:** 

> **TL;DR:** 本文提出了一种结合数据和物理信息的混合降阶模型，用于预测时空混沌动力学，即使在数据稀缺或物理模型不准确的情况下，其预测性能也优于纯数据驱动的方法。

**AI_Comments:** 该论文的创新点在于将数据驱动方法与物理知识（全阶模型）相结合，解决了纯数据驱动方法在数据稀缺或模型不准确时的局限性。其重要性体现在为复杂混沌系统的降阶建模提供了一种更鲁棒和准确的方法，尤其是在工程和科学领域中物理模型已知的场景下。通过结合自编码器和神经ODE，该方法展现了强大的泛化能力和预测性能。

<details>
  <summary>Details</summary>

**Motivation:** 尽管数据驱动技术在混沌动力学系统的降阶建模中表现强大，但仍有巨大潜力可以利用已知的物理信息（即全阶模型FOM）来提高预测能力。

**Method:** 开发了一种由数据和FOM共同指导的混合降阶模型（ROM），用于演化不变流形上的时空混沌动力学，其中流形坐标通过自编码器找到。该方法将FOM的向量场投影到不变流形上，然后通过动态数据对这个物理导出的向量场进行校正，或者将其用作贝叶斯先验并用数据进行更新。两种情况下都使用了神经常微分方程方法。

**Result:** 相对于纯数据驱动方法，在数据充足、数据稀缺甚至FOM不正确（即参数值错误）的情况下，混合方法都显著改善了时间序列预测。

**Conclusion:** 结合数据和物理信息的混合降阶建模方法能够显著提高时空混沌混沌动力学系统的预测能力，即使在数据条件不理想或物理模型存在误差的情况下也表现出色。

> **ai_Abstract:** 本研究提出了一种结合数据和全阶物理模型（FOM）的混合降阶模型（ROM），用于预测具有时空混沌动力学的系统。该模型利用自编码器在不变流形上构建系统，并将FOM的向量场投影到该流形上，然后通过数据进行校正或作为贝叶斯先验进行更新，并结合神经常微分方程。通过对Kuramoto-Sivashinsky和复杂Ginzburg-Landau方程的模拟数据进行测试，结果表明，即使在数据稀缺或FOM不准确的情况下，该混合方法在时间序列预测方面也显著优于纯数据驱动方法。

> **摘要翻译:** 虽然数据驱动技术是混沌动力学系统降阶建模的强大工具，但利用已知物理知识（即全阶模型（FOM））来提高预测能力仍有巨大潜力。我们开发了一种混合降阶模型（ROM），由数据和FOM共同指导，用于在不变流形上演化时空混沌动力学，其中流形坐标通过自编码器找到。该方法将FOM的向量场投影到不变流形上；然后，这个物理导出的向量场要么使用动态数据进行校正，要么用作贝叶斯先验并用数据进行更新。在这两种情况下，都使用了神经常微分方程方法。我们考虑了来自Kuramoto-Sivashinsky和复杂Ginzburg-Landau方程的模拟数据。相对于纯数据驱动方法，在数据充足、数据稀缺甚至FOM不正确（即参数值错误）的情况下，混合方法都显著改善了时间序列预测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [364] [BlockFFN: Towards End-Side Acceleration-Friendly Mixture-of-Experts with Chunk-Level Activation Sparsity](https://arxiv.org/abs/2507.08771)
> *BlockFFN：面向端侧加速友好的块级激活稀疏混合专家模型*

*Chenyang Song, Weilin Zhao, Xu Han, Chaojun Xiao, Yingfa Chen, Yuxuan Li, Zhiyuan Liu, Maosong Sun* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 混合专家模型, 激活稀疏性, 端侧加速, 块级稀疏性, 推测解码

**Comment:** 21 pages, 7 figures, 15 tables

> **TL;DR:** 提出BlockFFN，一种新的MoE架构，通过改进路由和引入块级稀疏性训练目标，实现端侧高效加速，并在实际设备上取得显著提速。

**AI_Comments:** 这篇论文的创新点在于提出了BlockFFN架构，并首次将块级稀疏性作为明确的优化目标，并通过CLS-aware训练和高效加速内核（结合激活稀疏性和推测解码）解决了MoE在端侧部署的挑战。其重要性在于为LLMs在资源受限设备上的高效部署提供了新的解决方案，尤其是在移动和边缘计算场景下具有巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLMs）计算负担重。混合专家模型（MoE）虽然具有激活稀疏性，但其非可微、不灵活的路由损害了模型性能。此外，这些稀疏激活架构在块级别稀疏性低，导致在低资源（如端侧设备）下加速不友好，且与主流加速技术（如推测解码）不兼容。

**Method:** 本文引入了BlockFFN这一新型MoE架构及其高效训练和部署技术。具体而言，使用集成了ReLU激活和RMSNorm的路由器实现可微且灵活的路由。接着，设计了CLS（块级稀疏性）感知训练目标以同时提升token级稀疏性（TLS）和块级稀疏性（CLS），使BlockFFN更利于加速。最后，首次结合激活稀疏性与推测解码，实现了高效加速内核。

**Result:** BlockFFN在性能上优于其他MoE基线模型，实现了超过80%的token级稀疏性（TLS）和70%的8-token块级稀疏性（CLS）。其加速内核在真实的端侧设备上比密集模型实现了高达3.67倍的加速。

**Conclusion:** BlockFFN成功解决了现有MoE架构在端侧加速和稀疏性模式上的挑战，通过创新的架构设计、训练目标和加速内核，显著提升了LLMs在资源受限环境下的部署效率和性能。

> **ai_Abstract:** 本文提出了BlockFFN，一种新型混合专家（MoE）架构，旨在解决现有MoE在端侧设备上加速不友好和稀疏性模式不兼容的问题。通过引入可微路由、设计块级稀疏性感知训练目标以及开发结合激活稀疏性和推测解码的高效加速内核，BlockFFN显著提升了模型性能和在端侧设备上的加速效率，实现了高token级和块级稀疏性，并在实际设备上取得了显著的速度提升。

> **摘要翻译:** 为了减轻大型语言模型（LLMs）的计算负担，以混合专家模型（MoE）为代表的激活稀疏架构受到了越来越多的关注。然而，传统MoE的不可微且不灵活的路由损害了模型性能。此外，尽管每个token只激活少数参数，但这些稀疏激活架构表现出较低的块级稀疏性，这意味着多个连续token的联合激活了大部分参数。这种稀疏模式对于低资源条件（例如，端侧设备）下的加速不友好，并且与主流加速技术（例如，推测解码）不兼容。为了应对这些挑战，我们引入了一种新颖的MoE架构——BlockFFN，以及其高效的训练和部署技术。具体来说，我们使用了一个集成了ReLU激活和RMSNorm的路由器，以实现可微且灵活的路由。接下来，为了促进token级稀疏性（TLS）和块级稀疏性（CLS），设计了CLS感知训练目标，使BlockFFN更利于加速。最后，我们首次结合激活稀疏性与推测解码，实现了高效的加速内核。实验结果表明，BlockFFN在性能上优于其他MoE基线模型，实现了超过80%的TLS和70%的8-token CLS。我们的内核在实际端侧设备上比密集模型实现了高达3.67倍的加速。所有代码和检查点都已公开可用（https://github.com/thunlp/BlockFFN）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [370] [Prediction accuracy versus rescheduling flexibility in elective surgery management](https://arxiv.org/abs/2507.15566)
> *择期手术管理中的预测准确性与重新调度灵活性*

*Pieter Smet, Martina Doneda, Ettore Lanzarone, Giuliana Carello* | **Category: cs.LG, math.OC** | **Updated: 2025-07-29**

**Keywords:** 择期手术, 住院时长预测, 重新调度, 预测准确性, 资源利用

**Comment:** 

> **TL;DR:** 本文探讨择期手术中住院时长（LOS）预测准确性与重新调度灵活性之间的关系，以应对预测误差导致的床位溢出并优化资源利用。

**AI_Comments:** 这篇论文的创新点在于它挑战了“预测精度越高越好”的直观假设，并引入了“重新调度灵活性”这一操作层面的变量进行权衡分析。这对于资源受限的医疗系统具有重要意义，因为它可能引导医院在投资高精度预测模型时，同时考虑其与操作灵活性的协同效应，从而实现更经济有效的资源管理。该研究对于理解数据驱动决策在实际操作中的局限性与潜力提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 在择期手术管理中，下游资源（尤其是住院床位）的可用性至关重要。医院使用机器学习模型预测患者住院时长（LOS），但预测误差可能导致排班不可行。为解决此类问题，需要实施重新调度策略。然而，高精度预测模型的训练成本高昂，因此需要探究预测准确性与重新调度灵活性之间的权衡。

**Method:** 本研究基于先前提出的模拟机器学习（simulated ML）方法来评估数据驱动方法，探索了住院时长预测准确性与各种纠正策略下的重新调度灵活性之间的关系。具体而言，文章研究了在住院时长预测误差下，最有效的患者重新调度策略，以防止床位溢出并优化资源利用。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了择期手术管理中，患者住院时长（LOS）预测的准确性与应对预测误差的重新调度灵活性之间的权衡。研究指出，尽管高精度预测有助于减少重新调度需求，但其训练成本高昂。文章利用模拟机器学习方法，分析了在存在LOS预测误差的情况下，各种纠正性策略下预测准确性与重新调度灵活性之间的关系，旨在找出最有效的患者重新调度策略，以避免床位溢出并优化资源利用。

> **摘要翻译:** 择期手术患者的入院计划中，下游资源的可用性至关重要，其中最关键的是住院床位。为确保床位可用性，医院可能在入院计划阶段使用机器学习（ML）模型预测患者的住院时长（LOS）。然而，每位患者的实际住院时长可能与预测值不同，从而可能导致排班不可行。为解决此类不可行性，可以实施利用操作灵活性的重新调度策略。例如，计划者可以推迟入院日期，将患者重新安置到不同病房，甚至在已入院患者中进行病房间转移。一个直接的假设是，更好的住院时长预测有助于减少重新调度的影响。然而，能够做出如此准确预测的机器学习模型的训练过程可能非常昂贵。本文基于先前提出模拟机器学习以评估数据驱动方法的工作，探讨了住院时长预测准确性与各种纠正策略下的重新调度灵活性之间的关系。具体而言，我们研究了在住院时长预测误差下，最有效的患者重新调度策略，以防止床位溢出并优化资源利用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [392] [PREIG: Physics-informed and Reinforcement-driven Interpretable GRU for Commodity Demand Forecasting](https://arxiv.org/abs/2507.21710)
> *PREIG：物理信息与强化驱动的可解释GRU商品需求预测模型*

*Hongwei Ma, Junbin Gao, Minh-Ngoc Tran* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 商品需求预测, 物理信息神经网络, GRU, 可解释性, 混合优化

**Comment:** 

> **TL;DR:** PREIG是一种新颖的深度学习框架，结合了GRU和物理信息神经网络（PINN），通过嵌入经济约束和混合优化策略，实现了商品需求预测的准确性、可解释性和经济一致性，性能优于现有模型。

**AI_Comments:** PREIG的创新之处在于其将深度学习（GRU）与领域知识（经济约束）和优化理论（PINN原则、混合优化策略）相结合，有效解决了商品需求预测中长期存在的准确性、可解释性和经济一致性难题。其定制损失函数和混合优化策略是提高模型性能和实用性的关键。

<details>
  <summary>Details</summary>

**Motivation:** 由于市场动态波动、非线性依赖性以及对经济一致性预测的需求，准确预测商品需求仍然是一个关键挑战。

**Method:** PREIG是一个深度学习框架，它将门控循环单元（GRU）架构与物理信息神经网络（PINN）原理独特地结合起来，嵌入了领域特定的经济约束：价格与需求之间的负弹性。该约束通过定制的损失函数强制执行，以惩罚违反物理规则的行为。为进一步提高预测性能和稳定性，PREIG整合了混合优化策略，将NAdam和L-BFGS与基于种群的训练（POP）相结合。

**Result:** PREIG在多个商品数据集上的实验表明，其在RMSE和MAPE方面显著优于传统计量经济模型（ARIMA、GARCH）和深度学习基线模型（BPNN、RNN）。与GRU相比，PREIG在保持良好可解释性的同时，预测性能依然出色。

**Conclusion:** PREIG通过桥接领域知识、优化理论和深度学习，为经济领域高维非线性时间序列预测提供了一个鲁棒、可解释且可扩展的解决方案。

> **ai_Abstract:** PREIG是一种新颖的深度学习框架，专为商品需求预测设计。它将GRU与物理信息神经网络（PINN）相结合，通过嵌入价格与需求之间的负弹性这一经济约束，并采用定制损失函数，确保预测的经济一致性和可解释性。模型还引入混合优化策略以提升性能和稳定性。实验证明，PREIG在预测准确性方面显著优于传统和深度学习基线模型，并能保持良好的可解释性，为高维非线性时间序列预测提供了一个稳健、可解释且可扩展的解决方案。

> **摘要翻译:** 准确预测商品需求仍然是一个关键挑战，原因在于市场动态波动、非线性依赖性以及对经济一致性预测的需求。本文介绍了一种名为PREIG的新型深度学习框架，专为商品需求预测量身定制。该模型独特地将门控循环单元（GRU）架构与物理信息神经网络（PINN）原理相结合，通过嵌入领域特定的经济约束：价格与需求之间的负弹性。这种约束通过定制的损失函数强制执行，该函数惩罚违反物理规则的行为，确保模型预测保持可解释性并与经济理论保持一致。为了进一步提高预测性能和稳定性，PREIG整合了一种混合优化策略，将NAdam和L-BFGS与基于种群的训练（POP）相结合。对多个商品数据集进行的实验表明，PREIG在RMSE和MAPE方面显著优于传统计量经济模型（ARIMA、GARCH）和深度学习基线模型（BPNN、RNN）。与GRU相比，PREIG在保持良好可解释性的同时，预测性能依然出色。通过结合领域知识、优化理论和深度学习，PREIG为经济领域高维非线性时间序列预测提供了一个鲁棒、可解释且可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [401] [Reinforcement Learning Fine-Tunes a Sparse Subnetwork in Large Language Models](https://arxiv.org/abs/2507.17107)
> *强化学习在大型语言模型中微调稀疏子网络*

*Andrii Balashov* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 强化学习, 大型语言模型, 参数稀疏性, 微调, 子网络

**Comment:** The manuscript has been withdrawn due to significant overlap in
  methodology and results with a prior work (arXiv:2505.11711) that we were not
  aware of at the time of submission. To maintain academic integrity and avoid
  redundancy in the literature, we have chosen to withdraw this version

> **TL;DR:** 研究发现，强化学习（RL）微调大型语言模型时，只修改一小部分（5-30%）参数，形成稀疏子网络，且这些子网络在不同设置下表现出高度重叠。仅微调该稀疏子网络即可达到与完全微调相同的性能，这表明RL通过聚焦于模型中的特定部分来适应模型。

**AI_Comments:** 这项研究提出了一个令人惊讶且重要的发现，即强化学习在微调大型语言模型时，实际上只更新了模型中一个小的、稀疏的子网络。这挑战了传统上认为RL需要更新大量参数的假设。其创新性在于揭示了RL-induced parameter update sparsity这一自然现象，并证明了其普遍性及在不同设置下的重叠性。该发现对于理解LLM的微调机制、提高RL训练效率以及与“彩票假说”建立联系具有重要意义，可能为未来的参数高效学习和模型剪枝提供新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）是使大型语言模型（LLMs）与复杂任务和人类偏好对齐的关键后预训练步骤。通常认为RL微调需要更新模型的大部分参数，但本文旨在挑战这一假设，并发现RL微调实际上只修改了模型中的一小部分子网络。

**Method:** 本文通过实验观察了RL微调过程中参数更新的稀疏性。研究使用了多种RL算法（如PPO, DPO, SimPO, PRIME）和不同的模型家族（如OpenAI, Meta, 和开源LLMs）进行验证。研究还分析了更新的子网络在不同随机种子、数据集和算法之间的重叠情况，并尝试仅微调该稀疏子网络来恢复模型性能。

**Result:** RL微调始终只修改一小部分参数（通常为5-30%的权重），而大部分参数保持不变，这种现象被称为RL引起的参数更新稀疏性。这种稀疏性是自然产生的，无需任何稀疏性约束或参数高效微调。更新的子网络在不同种子、数据集和算法之间表现出高度重叠，远超偶然性。仅微调这个稀疏子网络就能恢复完整的模型性能，并且其参数与完全微调的模型参数几乎相同。分析表明，这种稀疏性出现是因为RL在模型原始分布附近操作，只需要进行有针对性的改变。

**Conclusion:** 强化学习（RL）在大型语言模型中进行微调时，并非通过改变所有权重来适应模型，而是通过聚焦训练一个小型、持续更新的稀疏子网络。这一发现为理解RL如何适应模型提供了新视角，并有望实现更高效的RL方法，同时从彩票假说的角度重新审视稀疏性。

> **ai_Abstract:** 本文发现，在大型语言模型中，强化学习（RL）微调并非更新大部分参数，而是自然地只修改一小部分稀疏子网络（5-30%的权重），称之为RL引起的参数更新稀疏性。这种稀疏性在多种RL算法和模型家族中普遍存在，且更新的子网络在不同设置下表现出高度重叠。研究表明，仅微调此稀疏子网络即可恢复与完全微调模型相同的性能。这一发现揭示了RL通过聚焦于模型中的特定、小型且一致更新的子网络来适应模型，从而为开发更高效的RL方法提供了新思路。

> **摘要翻译:** 强化学习（RL）是使大型语言模型（LLMs）与复杂任务和人类偏好对齐的关键后预训练步骤。虽然通常认为RL微调需要更新模型的大部分参数，但我们通过一个令人惊讶的发现挑战了这一假设：RL微调始终只修改一小部分子网络（通常是5-30%的权重），而大部分参数保持不变。我们称这种现象为RL引起的参数更新稀疏性。它自然产生，无需任何稀疏性约束或参数高效微调，并且出现在多种RL算法（例如PPO、DPO、SimPO、PRIME）和模型家族（例如OpenAI、Meta和开源LLMs）中。此外，RL更新的子网络在不同随机种子、数据集和算法之间显示出显著的重叠——远超偶然性——这表明预训练模型中存在部分可转移的结构。我们证明，仅微调这个稀疏子网络就能恢复完整的模型性能，并产生与完全微调模型几乎相同的参数。我们的分析表明，这种稀疏性出现是因为RL在模型原始分布附近操作，只需要进行有针对性的改变。KL惩罚、梯度裁剪和在策略动态对稀疏模式的影响有限。这些发现为RL如何适应模型提供了新视角：它不是通过移动所有权重，而是通过将训练集中在一个小型、持续更新的子网络上。这一洞察力能够实现更高效的RL方法，并从彩票假说的角度重新审视稀疏性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [403] [DEM-NeRF: A Neuro-Symbolic Method for Scientific Discovery through Physics-Informed Simulation](https://arxiv.org/abs/2507.21350)
> *DEM-NeRF：一种通过物理信息模拟进行科学发现的神经符号方法*

*Wenkai Tan, Alvaro Velasquez, Houbing Song* | **Category: cs.LG** | **Updated: 2025-07-28**

**Keywords:** 神经符号, NeRF, 物理信息神经网络, 弹性物体, 科学发现

**Comment:** 

> **TL;DR:** DEM-NeRF是一个新颖的神经符号框架，它结合了NeRF和物理信息神经网络（PINN），用于从稀疏多视图图像序列中重建和模拟弹性物体，无需显式几何信息，并提高了模拟精度和结果的可解释性。

**AI_Comments:** DEM-NeRF的创新之处在于其将NeRF与PINN的巧妙结合，实现了从稀疏图像数据进行弹性物体的物理信息模拟，且无需显式几何输入。这种神经符号方法有效地弥合了数据驱动模型与物理原理之间的鸿沟，并通过能量约束设计提升了模型的准确性和可解释性，为科学发现提供了一个强有力的新工具。其在处理复杂边界条件上的方法也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 传统的纯经验方法在建模物理系统时可能偏离既定的物理原理，而传统的数值求解器则需要完整的几何知识且高保真模拟成本高昂。本文旨在通过结合数据驱动学习和符号方程的神经符号方法来解决这些限制。

**Method:** 本文提出了一个新颖的神经符号框架，DEM-NeRF。它将神经辐射场（NeRF）用于物体重建，并与结合弹性偏微分方程的物理信息神经网络（PINN）相结合。该方法通过利用图像监督和符号物理约束来学习变形物体的时空表示。为了处理复杂的边界和初始条件，该方法采用了能量约束的物理信息神经网络架构。

**Result:** 该设计增强了模拟精度和结果的可解释性。

**Conclusion:** DEM-NeRF框架成功地将NeRF与PINN结合，实现了从稀疏图像序列对弹性物体的重建和模拟，提高了精度和可解释性，为科学发现提供了一种新的神经符号方法。

> **ai_Abstract:** 本文提出了DEM-NeRF，一种新颖的神经符号框架，旨在解决物理系统建模中纯经验方法与传统数值求解器之间的局限性。该方法结合了神经辐射场（NeRF）进行物体重建和物理信息神经网络（PINN）以整合弹性物理方程，从而能够从稀疏多视图图像序列中重建和模拟弹性物体，而无需显式几何信息。通过采用能量约束的PINN架构，DEM-NeRF利用图像监督和符号物理约束学习时空表示，显著提高了模拟精度和结果的可解释性。

> **摘要翻译:** 神经网络已成为建模物理系统的强大工具，能够从有限数据中学习复杂表示，同时整合基础科学知识。特别是，结合数据驱动学习（神经）与符号方程和规则（符号）的神经符号方法，解决了纯经验方法（可能偏离既定物理原理）与传统数值求解器（需要完整几何知识且高保真模拟成本过高）之间的矛盾。在本工作中，我们提出了一种新颖的神经符号框架，用于直接从稀疏多视图图像序列重建和模拟弹性物体，而无需显式几何信息。具体而言，我们将神经辐射场（NeRF）用于物体重建，并与结合弹性控制偏微分方程的物理信息神经网络（PINN）相结合。通过这样做，我们的方法学习了变形物体的时空表示，该表示利用了图像监督和符号物理约束。为了处理传统上使用有限元方法、边界元方法或基于传感器的测量来解决的复杂边界和初始条件，我们采用了能量约束的物理信息神经网络架构。这种设计增强了模拟精度和结果的可解释性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [408] [EvoSLD: Automated Neural Scaling Law Discovery With Large Language Models](https://arxiv.org/abs/2507.21184)
> *EvoSLD: 基于大型语言模型的神经缩放定律自动化发现*

*Haowei Lin, Xiangyu Wang, Jianzhu Ma, Yitao Liang* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-27**

**Keywords:** 缩放定律, 自动化发现, 大型语言模型, 进化算法, 神经网络

**Comment:** 

> **TL;DR:** EvoSLD是一个自动化框架，利用进化算法和大型语言模型来发现神经网络的缩放定律，表现出比传统方法更高的准确性、可解释性和效率。

**AI_Comments:** EvoSLD的创新之处在于其结合了进化算法与大型语言模型来自动化缩放定律的发现过程，这显著减少了对人工专业知识和手动实验的依赖。其在多个真实世界场景中的优异表现，特别是其在误差降低和效率提升方面的成果，凸显了其在推动AI研究效率上的重要性。该方法有望成为未来AI模型设计和优化中的一个强大工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统上，发现神经网络的缩放定律需要大量的人类专业知识和手动实验，EvoSLD旨在自动化这一过程。

**Method:** EvoSLD是一个自动化缩放定律发现（SLD）框架，它利用进化算法在大型语言模型（LLMs）的指导下，共同演化符号表达式及其优化例程。它旨在处理不同实验设置中的缩放变量、控制变量和响应指标，并寻找在分组数据子集上最小化拟合误差的简约、通用函数形式。

**Result:** EvoSLD在五个真实世界的场景中进行了评估，在两种情况下重新发现了精确的人工推导定律，并在其他情况下超越了它们，在保留测试集上的归一化均方误差实现了数量级的降低。与符号回归和消融变体等基线相比，EvoSLD展示了卓越的准确性、可解释性和效率。

**Conclusion:** EvoSLD通过自动化神经缩放定律的发现过程，显著提高了准确性、可解释性和效率，具有加速AI研究的巨大潜力。

> **ai_Abstract:** EvoSLD是一个利用大型语言模型（LLMs）指导进化算法的自动化框架，用于发现神经网络的缩放定律。该框架旨在处理多种变量和度量，通过共同演化符号表达式和优化例程来寻找简约的函数形式。在五个真实世界场景中的评估表明，EvoSLD能够重新发现或超越现有的人工推导定律，并在准确性、可解释性和效率方面优于基线方法，有望加速AI研究。

> **摘要翻译:** 缩放定律是预测神经网络性能如何随模型大小、数据集大小和计算资源等变量变化而演变的基本数学关系。传统上，发现这些定律需要广泛的人类专业知识和手动实验。我们引入了EvoSLD，这是一个自动化的缩放定律发现（SLD）框架，它利用大型语言模型（LLMs）指导的进化算法来共同演化符号表达式及其优化例程。EvoSLD旨在处理各种实验设置中的缩放变量、控制变量和响应指标，并寻找在分组数据子集上最小化拟合误差的简约、通用函数形式。在最近文献中的五个真实世界场景中进行评估，EvoSLD在两种情况下重新发现了精确的人工推导定律，并在其他情况下超越了它们，在保留测试集上的归一化均方误差实现了数量级的降低。与符号回归和消融变体等基线相比，EvoSLD展示了卓越的准确性、可解释性和效率，突出了其加速AI研究的潜力。代码可在https://github.com/linhaowei1/SLD获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [424] [Towards Federated Learning with On-device Training and Communication in 8-bit Floating Point](https://arxiv.org/abs/2407.02610)
> *迈向8位浮点设备端训练与通信的联邦学习*

*Bokun Wang, Axel Berg, Durmus Alp Emre Acar, Chuteng Zhou* | **Category: cs.LG, cs.DC** | **Updated: 2025-07-30**

**Keywords:** 联邦学习, 8位浮点, 设备端训练, 通信压缩, 神经网络

**Comment:** extended version

> **TL;DR:** 本文探讨了在联邦学习中使用8位浮点（FP8）进行设备端训练和通信，以降低计算和通信成本，并提出了一种结合FP8客户端训练和FP32服务器模型的新方法，实验证明能显著减少通信量。

**AI_Comments:** 该论文的创新点在于将FP8量化技术引入联邦学习，解决了设备端训练的计算效率和通信瓶颈问题。通过结合FP8客户端训练和FP32服务器模型，在保证模型性能的同时大幅减少了通信开销，对于推动联邦学习在资源受限设备上的应用具有重要意义。这是一个务实且有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有神经网络训练（FP32/FP16）的计算成本较高。8位浮点（FP8）训练已被证明能有效降低计算成本。在联邦学习场景中，设备端训练的计算和客户端-服务器通信成本是主要挑战。

**Method:** 提出了一种新颖的方法，将8位浮点（FP8）客户端训练与保持全局32位浮点（FP32）服务器模型相结合，并提供了收敛性分析。

**Result:** 实验结果表明，与FP32基线相比，该方法在各种任务和模型上，在达到相同训练模型精度的情况下，通信量至少减少了2.9倍。

**Conclusion:** 在联邦学习中使用FP8进行设备端训练和通信是可行的，并且能够显著降低通信成本，同时保持模型精度。

> **ai_Abstract:** 本文研究了在联邦学习中应用8位浮点（FP8）训练，旨在降低设备端训练的计算成本和客户端-服务器通信成本。作者提出了一种新方法，将FP8客户端训练与FP32全局服务器模型相结合，并进行了收敛性分析。实验结果表明，该方法在保持相同模型精度的前提下，能将通信量至少减少2.9倍，验证了其在联邦学习中的有效性。

> **摘要翻译:** 最近的研究表明，8位浮点（FP8）可用于高效训练神经网络，与FP32/FP16训练相比，计算成本更低。在这项工作中，我们研究了在联邦学习背景下使用FP8训练。这种方法不仅带来了FP8在边缘设备端训练中所需的常见优势，而且由于显著的权重压缩，还降低了客户端-服务器的通信成本。我们提出了一种将FP8客户端训练与保持全局FP32服务器模型相结合的新颖方法，并提供了收敛性分析。对各种机器学习模型和数据集进行的实验表明，与FP32基线相比，我们的方法在各种任务和模型上，在达到相同训练模型精度的情况下，始终能带来至少2.9倍的通信量减少。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [431] [Machine Learning Risk Intelligence for Green Hydrogen Investment: Insights for Duqm R3 Auction](https://arxiv.org/abs/2507.19529)
> *绿色氢能投资的机器学习风险智能：杜克姆R3拍卖的见解*

*Obumneme Nwafor, Mohammed Abdul Majeed Al Hooti* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 绿色氢能, 机器学习, 风险评估, 维护压力指数, 杜克姆R3拍卖

**Comment:** Updated version

> **TL;DR:** 论文提出一个AI决策支持系统，利用气象数据预测绿色氢能基础设施的维护压力，以弥补运营数据缺失导致的风险评估空白，支持投资决策和拍卖评估。

**AI_Comments:** 论文的创新点在于在缺乏历史运营数据的情况下，利用易于获取的气象数据作为代理，通过机器学习方法进行风险预测，为绿色氢能等新兴产业的投资决策提供了实用的解决方案。这对于在恶劣环境（如沙漠）中部署的能源项目尤为重要。

<details>
  <summary>Details</summary>

**Motivation:** 绿色氢能投资增长迅速，但大型设施尤其在沙漠环境中缺乏历史运营和维护数据，导致基础设施规划和拍卖决策（如阿曼杜克姆R3拍卖）中难以进行准确的风险评估。

**Method:** 本文提出了一个基于人工智能的决策支持系统，该系统利用公开可用的气象数据（如沙尘暴、极端温度、湿度波动）来开发预测性维护压力指数（MPI），以预测氢能基础设施的风险水平和未来的维护需求。

**Result:** 该工具能够通过时间基准测试评估和验证性能声明，并在缺乏历史运营基准的情况下，将时间风险智能纳入拍卖评估标准，从而增强监管远见和运营决策。

**Conclusion:** 该AI决策支持系统通过预测性维护压力指数，即使在缺乏历史运营数据的情况下，也能为绿色氢能投资提供准确的风险评估，强化了监管远见和运营决策。

> **ai_Abstract:** 针对绿色氢能投资中大型设施运营数据缺乏导致风险评估困难的问题，尤其是在阿曼杜克姆R3拍卖背景下，本文提出一个基于人工智能的决策支持系统。该系统利用公开气象数据构建维护压力指数（MPI），预测氢能基础设施的风险和维护需求，从而弥补数据空白，支持投资决策和监管评估。

> **摘要翻译:** 随着绿色氢能成为全球脱碳的重要组成部分，阿曼通过国家拍卖和国际伙伴关系占据了战略地位。在成功进行了两轮绿色氢能项目后，该国在杜克姆地区启动了第三轮拍卖（R3）。尽管该地区具有相对的地理空间同质性，但它仍然容易受到环境波动的影响，这些波动对生产力构成固有风险。尽管全球对绿色氢能的投资不断增长，但运营数据仍然稀缺，沙特阿拉伯的NEOM设施等主要项目预计要到2026年才开始生产，阿曼的ACME杜克姆项目则计划于2028年。在沙漠环境中缺乏大型氢能设施的历史维护和性能数据，为基础设施规划和拍卖决策中的准确风险评估带来了巨大的知识空白。鉴于这种数据空白，环境条件成为预测基础设施维护压力的可获取且可靠的替代指标，因为沙尘暴、极端温度和湿度波动等恶劣沙漠条件是可再生能源系统设备退化的公认驱动因素。为了解决这一挑战，本文提出了一种人工智能决策支持系统，该系统利用公开可用的气象数据来开发一个预测性维护压力指数（MPI），该指数可以预测氢能基础设施的风险水平和未来的维护需求。该工具通过实现时间基准测试来评估和验证随时间的性能声明，从而增强了监管远见和运营决策。尽管缺乏历史运营基准，它仍可用于将时间风险智能纳入拍卖评估标准。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [433] [Persistent Backdoor Attacks in Continual Learning](https://arxiv.org/abs/2409.13864)
> *持续学习中的持久后门攻击*

*Zhen Guo, Abhinav Kumar, Reza Tourani* | **Category: cs.LG, cs.CR** | **Updated: 2025-07-29**

**Keywords:** 持久后门攻击, 持续学习, 对抗性攻击, 神经网络安全

**Comment:** 19 pages, 20 figures, 6 tables

> **TL;DR:** 本文提出了两种针对持续学习的持久后门攻击（盲任务后门和潜在任务后门），这些攻击在不同持续学习算法下均表现出高成功率和持久性，并能有效规避现有防御。

**AI_Comments:** 这项研究的创新之处在于首次系统性地探讨了后门攻击在持续学习环境中的持久性问题，并提出了两种有效的攻击方法。其重要性在于揭示了持续学习模型在面对持续威胁时的脆弱性，即使是先进的防御也难以抵御，为未来的安全研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 后门攻击对神经网络构成重大威胁，但在持续学习中，关于其实用性和持久性，以及模型参数的持续更新如何影响攻击有效性，目前研究较少。本文旨在填补这一空白。

**Method:** 本文引入了两种持久后门攻击：盲任务后门攻击（Blind Task Backdoor）和潜在任务后门攻击（Latent Task Backdoor）。盲任务后门通过微妙地改变损失计算来实现，无需直接控制训练过程；潜在任务后门仅影响单个任务的训练，而其他任务则正常训练。

**Result:** 评估结果表明，在各种配置下（包括静态、动态、物理和语义触发器），这两种攻击都有效。它们在不同持续学习算法中始终保持高成功率，并能有效规避SentiNet和I-BAU等最先进的防御。

**Conclusion:** 本研究成功展示了在持续学习环境中，所提出的两种后门攻击的有效性和持久性，并揭示了持续学习模型面临的严重安全漏洞，即使面对先进防御也难以抵御。

> **ai_Abstract:** 本文提出了两种新型持久后门攻击——盲任务后门和潜在任务后门，旨在解决持续学习环境中后门攻击的持久性问题。这些攻击通过最小的对抗性影响，在不同的持续学习算法和触发器类型下均表现出高成功率和持久性，并能有效规避SentiNet和I-BAU等现有先进防御。这项研究揭示了持续学习系统中的一个关键安全漏洞。

> **摘要翻译:** 后门攻击对神经网络构成重大威胁，使攻击者能够操纵特定输入的模型输出，通常会带来毁灭性的后果，尤其是在关键应用中。虽然后门攻击已在各种背景下进行了研究，但很少关注它们在持续学习中的实用性和持久性，特别是理解当新的数据分布被学习和整合时，模型参数的持续更新如何随时间影响这些攻击的有效性。为了弥补这一空白，我们引入了两种持久后门攻击——盲任务后门（Blind Task Backdoor）和潜在任务后门（Latent Task Backdoor），每种攻击都利用了最小的对抗性影响。我们的盲任务后门在不直接控制训练过程的情况下，巧妙地改变了损失计算，而潜在任务后门只影响单个任务的训练，所有其他任务都正常训练。我们在各种配置下评估了这些攻击，证明了它们对静态、动态、物理和语义触发器的有效性。我们的结果表明，这两种攻击在不同的持续学习算法中都能持续保持高成功率，同时有效规避了SentiNet和I-BAU等最先进的防御。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [440] [Hybrid activation functions for deep neural networks: S3 and S4 -- a novel approach to gradient flow optimization](https://arxiv.org/abs/2507.22090)
> *深度神经网络的混合激活函数：S3和S4——一种梯度流优化的新方法*

*Sergii Kavun* | **Category: cs.LG, cs.AI, cs.NE, cs.NI, 68T07, 68T05, 65D10, 68Q32, I.2.6; I.5.1; G.1.2; I.5.2** | **Updated: 2025-07-29**

**Keywords:** 混合激活函数, S3, S4, 梯度流优化, 深度神经网络

**Comment:** 15 pages, 2 figures, 5 tables

> **TL;DR:** 本文提出了两种新型混合激活函数S3和S4（S3的平滑改进版），旨在优化深度神经网络的梯度流。S4在多项任务上表现优于现有激活函数，解决了死神经元和梯度消失问题，并提供了更稳定的梯度流。

**AI_Comments:** 该论文提出S3和S4这两种混合激活函数，创新性在于结合了不同激活函数的优点，并通过平滑过渡机制和可调参数k增强了函数的灵活性和鲁棒性。S4在解决传统激活函数局限性（如死神经元和梯度消失）方面的实验结果令人印象深刻，尤其是在保持梯度流稳定性和提高收敛速度方面。这为深度学习模型训练的稳定性与性能提升提供了新的方向，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的激活函数如ReLU存在“死神经元”问题，而Sigmoid和Tanh则存在“梯度消失”问题，这些问题会影响梯度流、训练稳定性和模型性能。

**Method:** 本文引入了两种新型混合激活函数：S3（Sigmoid-Softsign）和其改进版本S4（平滑的S3）。S3将Sigmoid用于负输入，Softsign用于正输入。S4采用由陡峭度参数k控制的平滑过渡机制。研究在二分类、多分类和回归任务上使用三种不同的神经网络架构进行了综合实验。

**Result:** S4在实验中表现优于九种基线激活函数，在MNIST上达到97.4%的准确率，在Iris分类上达到96.0%的准确率，在Boston Housing回归上达到18.7的MSE。S4展示了更快的收敛速度（比ReLU快19%），并在不同网络深度下保持了稳定的梯度流。S4的梯度范围为[0.24, 0.59]，而ReLU在深层网络中表现出18%的死神经元。

**Conclusion:** S4激活函数通过其混合设计和平滑过渡机制解决了现有激活函数的主要局限性。可调参数k使其能够适应不同的任务和网络深度，使S4成为深度学习应用的通用选择。这些发现表明混合激活函数是改善神经网络训练动态的一个有前景的方向。

> **ai_Abstract:** 本文提出S3和S4两种新型混合激活函数，旨在解决传统激活函数如ReLU的死神经元问题和Sigmoid/Tanh的梯度消失问题。S4作为S3的平滑改进版，结合了Sigmoid和Softsign的优点，并通过可调参数k实现平滑过渡。实验结果表明，S4在分类和回归任务上均优于多种基线激活函数，展现出更快的收敛速度、更稳定的梯度流和更低的死神经元比例，证明了混合激活函数在优化神经网络训练动态方面的潜力。

> **摘要翻译:** 激活函数是深度神经网络中的关键组成部分，直接影响梯度流、训练稳定性和模型性能。传统的函数如ReLU存在死神经元问题，而Sigmoid和tanh则表现出梯度消失问题。我们引入了两种新型混合激活函数：S3 (Sigmoid-Softsign) 和其改进版本S4 (平滑的S3)。S3将Sigmoid用于负输入，Softsign用于正输入，而S4采用由陡峭度参数k控制的平滑过渡机制。我们使用三种不同的神经网络架构，在二分类、多分类和回归任务上进行了综合实验。S4相比九种基线激活函数表现出卓越的性能，在MNIST上达到97.4%的准确率，在Iris分类上达到96.0%的准确率，在Boston Housing回归上达到18.7的MSE。该函数表现出更快的收敛速度（比ReLU快19%）并在网络深度上保持了稳定的梯度流。比较分析显示，S4的梯度范围为[0.24, 0.59]，而ReLU在深层网络中存在18%的死神经元。S4激活函数通过其混合设计和平滑过渡机制解决了现有函数的主要局限性。可调参数k允许其适应不同的任务和网络深度，使S4成为深度学习应用的通用选择。这些发现表明混合激活函数是改善神经网络训练动态的一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [441] [Data-Driven Extended Corresponding State Approach for Residual Property Prediction of Hydrofluoroolefins](https://arxiv.org/abs/2507.21720)
> *氢氟烯烃残余性质预测的数据驱动扩展对应态方法*

*Gang Wang, Peng Hu* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 氢氟烯烃, 数据驱动, 扩展对应态, 残余性质, 图神经网络

**Comment:** 

> **TL;DR:** 提出了一种结合图神经网络的数据驱动扩展对应态模型，用于准确预测氢氟烯烃的残余热力学性质，以克服数据缺乏并加速新型制冷剂的发现。

**AI_Comments:** 本文的创新之处在于将图神经网络模块引入扩展对应态模型，通过分子结构表征流体，显著增强了模型的泛化能力。这有效地解决了氢氟烯烃热力学数据缺乏的问题，并为新型制冷剂的发现提供了强大的工具，体现了将物理知识与机器学习结合的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 氢氟烯烃是下一代制冷剂，但缺乏可靠的热力学数据阻碍了新型优质氢氟烯烃制冷剂的发现和应用。

**Method:** 提出了一种神经网络扩展对应态模型，结合了理论方法和数据驱动方法。通过包含图神经网络模块和专门设计的模型架构，利用微观分子结构表征流体，增强泛化能力。模型使用已知流体的高精度数据进行训练，并通过留一法交叉验证进行评估。

**Result:** 与传统扩展对应态模型或立方状态方程相比，该模型在液体和超临界区域的密度和能量性质方面显示出显著提高的准确性。密度在液体区域的平均绝对偏差为1.49%，超临界区域为2.42%；残余熵分别为3.37%和2.50%；残余焓分别为1.85%和1.34%。

**Conclusion:** 这些结果证明了将物理知识嵌入机器学习模型的有效性。所提出的神经网络扩展对应态模型有望显著加速新型氢氟烯烃制冷剂的发现。

> **ai_Abstract:** 本文提出了一种创新的数据驱动扩展对应态模型，该模型结合了图神经网络和专门设计的架构，用于准确预测氢氟烯烃的残余热力学性质。该模型通过利用流体的微观分子结构来增强泛化能力，并使用高精度数据进行训练和验证。实验结果表明，与传统方法相比，该模型在液体和超临界区域的密度和能量性质预测方面显著提高了准确性，有望加速新型氢氟烯烃制冷剂的发现。

> **摘要翻译:** 氢氟烯烃因其极低的全球变暖潜值而被认为是最有前途的下一代制冷剂，可以有效缓解全球变暖效应。然而，可靠热力学数据的缺乏阻碍了新型优质氢氟烯烃制冷剂的发现和应用。在这项工作中，我们整合了理论方法和数据驱动方法的优势，提出了一种神经网络扩展对应态模型来预测氢氟烯烃制冷剂的残余热力学性质。其创新之处在于，通过包含图神经网络模块和专门设计的模型架构，利用其微观分子结构来表征流体，从而增强其泛化能力。所提出的模型使用现有已知流体的高精度数据进行训练，并通过留一法交叉验证方法进行评估。与传统扩展对应态模型或立方状态方程相比，所提出的模型在液体和超临界区域的密度和能量性质方面显示出显著提高的准确性，密度的平均绝对偏差在液体区域为1.49%，超临界区域为2.42%；残余熵分别为3.37%和2.50%；残余焓分别为1.85%和1.34%。这些结果证明了将物理知识嵌入机器学习模型的有效性。所提出的神经网络扩展对应态模型有望显著加速新型氢氟烯烃制冷剂的发现。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [442] [Hierarchical mixtures of Gaussians for combined dimensionality reduction and clustering](https://arxiv.org/abs/2206.04841)
> *结合降维和聚类的分层高斯混合模型*

*Sacha Sokoloski, Philipp Berens* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-29**

**Keywords:** 分层高斯混合模型, 降维, 聚类, 概率模型, 高维数据

**Comment:** 

> **TL;DR:** HMoGs是一种新的概率模型，它将降维和聚类统一起来，具有高计算效率，能有效处理高维数据，并保持统计严谨性、可解释性和不确定性量化。

**AI_Comments:** HMoGs的创新之处在于其将降维和聚类统一到一个单一的概率框架中，并通过指数族参数化显著提升了计算效率，使其适用于处理大规模高维数据。其强调保留统计严谨性、可解释性和不确定性量化，是其相对于许多现代嵌入式或自监督方法的优势。这为高维数据分析提供了一个理论基础更强且更实用的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的高维数据聚类方法（如基于嵌入、变分和自监督方法）通常缺乏统计严谨性、可解释性和不确定性量化，因此需要一种将降维和聚类统一的实用方法来解决这些不足。

**Method:** 本文引入了分层高斯混合模型（HMoGs），将降维和聚类整合到单一概率模型中。HMoGs提供了模型似然的闭式表达式、潜在状态和聚类成员的精确推断以及最大似然优化的精确算法。其新颖的指数族参数化显著降低了计算复杂度。此外，研究还探索了稀疏约束降维以进一步提升性能和可解释性。

**Result:** HMoGs在合成实验和MNIST数据集上得到了验证，结果表明联合优化降维和聚类能够提高模型性能。稀疏约束降维进一步改善了聚类性能并增强了可解释性。HMoGs能够高效建模数百个潜在维度，并捕获高维数据中的额外结构。

**Conclusion:** HMoGs提供了一种实用的高维聚类方法，它成功地将经典统计建模与现代数据和计算规模相结合，同时保留了统计严谨性、可解释性和不确定性量化，弥补了现有基于嵌入、变分和自监督方法的不足。

> **ai_Abstract:** 本文提出了一种名为分层高斯混合模型（HMoGs）的新型概率模型，旨在统一降维和聚类。HMoGs通过其独特的指数族参数化显著降低了计算复杂度，使其能够高效处理高维数据并捕获复杂结构。该模型提供了精确的推断和优化算法，并在合成数据和MNIST上验证了其性能提升，尤其是在联合优化降维和聚类以及引入稀疏约束时。HMoGs弥补了现有高维聚类方法在统计严谨性、可解释性和不确定性量化方面的不足。

> **摘要翻译:** 我们引入了分层高斯混合模型（HMoGs），它将降维和聚类统一到一个单一的概率模型中。HMoGs为模型似然提供了闭式表达式，对潜在状态和聚类成员进行精确推断，并提供了最大似然优化的精确算法。HMoGs新颖的指数族参数化大大降低了其相对于类似基于模型方法的计算复杂度，使其能够高效地建模数百个潜在维度，从而捕获高维数据中的额外结构。我们在合成实验和MNIST数据集上演示了HMoGs，并展示了降维和聚类的联合优化如何促进模型性能的提高。我们还探讨了稀疏约束降维如何进一步提高聚类性能，同时增强可解释性。通过将经典统计建模与现代数据和计算规模相结合，HMoGs为高维聚类提供了一种实用方法，该方法保留了统计严谨性、可解释性和不确定性量化，而这些在基于嵌入、变分和自监督方法中常常缺失。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [443] [Compression Method for Deep Diagonal State Space Model Based on $H^2$ Optimal Reduction](https://arxiv.org/abs/2507.10078)
> *基于$H^2$最优降阶的深度对角状态空间模型压缩方法*

*Hiroki Sakamoto, Kazuhiro Sato* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-30**

**Keywords:** 深度学习, 状态空间模型, 模型压缩, $H^2$降阶, 参数缩减

**Comment:** Accepted to IEEE Control Systems Letters

> **TL;DR:** 本研究提出了一种基于$H^2$模型降阶技术，用于深度对角状态空间模型的参数压缩方法，实现了参数大幅减少且不牺牲性能。

**AI_Comments:** 这项研究的创新之处在于将控制理论中的$H^2$模型降阶技术创造性地应用于深度学习模型中的状态空间模型组件，解决了模型在资源受限设备上部署的难题。其重要性在于提供了一种高效的参数压缩方案，实现了模型尺寸的大幅缩小而不损失性能，这对于边缘计算和移动设备上的深度学习应用具有重要意义。该方法的普适性及其在其他深度学习架构中的应用潜力值得进一步探讨。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型结合线性状态空间模型（SSMs）在捕捉序列数据长距离依赖方面表现出色，但其庞大的参数量限制了在资源受限设备上的部署。

**Method:** 本研究通过将控制理论中的$H^2$模型降阶技术应用于深度对角状态空间模型中的线性SSM组件，提出了一种高效的参数缩减方法。

**Result:** 实验结果显示，本研究提出的模型压缩方法在LRA基准测试中优于现有使用平衡截断的方法，成功将SSMs的参数量减少到1/32，同时不牺牲原始模型的性能。

**Conclusion:** 本研究提出了一种有效的深度对角状态空间模型参数压缩方法，通过应用$H^2$最优降阶技术，在大幅减少模型参数的同时保持了性能。

> **ai_Abstract:** 本研究针对结合线性状态空间模型（SSMs）的深度学习模型参数量大、难以部署在资源受限设备上的问题，提出了一种基于控制理论中$H^2$模型降阶技术的高效参数缩减方法。实验证明，该方法在LRA基准测试中表现优于现有方法，并能将SSMs的参数量减少至1/32，同时保持原始模型的性能，为深度对角状态空间模型的部署提供了有效途径。

> **摘要翻译:** 将线性状态空间模型（SSMs）整合到深度学习模型中，因其能够捕捉序列数据中的长距离依赖而受到关注。然而，它们庞大的参数量对在资源受限设备上的部署构成了挑战。在本研究中，我们通过将控制理论中的$H^2$模型降阶技术应用于这些模型中的线性SSM组件，提出了一种高效的参数缩减方法。在实验中，LRA基准测试结果表明，基于我们提出的方法进行模型压缩优于现有使用平衡截断的方法，同时成功地将SSMs中的参数数量减少到1/32，而没有牺牲原始模型的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [452] [A Contrastive Diffusion-based Network (CDNet) for Time Series Classification](https://arxiv.org/abs/2507.21357)
> *用于时间序列分类的对比扩散网络 (CDNet)*

*Yaoyu Zhang, Chi-Guhn Lee* | **Category: cs.LG, 62M10, I.5.1** | **Updated: 2025-07-28**

**Keywords:** 时间序列分类, 对比学习, 扩散模型, 深度学习, 数据增强

**Comment:** 19 pages, conference

> **TL;DR:** 针对时间序列分类中深度学习模型在复杂数据条件（如类相似性、多模态分布和噪声）下性能下降的问题，本文提出了CDNet（对比扩散网络）。CDNet通过学习扩散过程生成信息丰富的正负样本来增强现有分类器，并在UCR档案和模拟数据集上显示出显著的性能提升。

**AI_Comments:** CDNet的创新之处在于其将对比学习与扩散模型相结合，并通过学习样本间的转换而非简单的去噪来生成更具信息量的正负样本，从而有效提升了时间序列分类在复杂数据条件下的鲁棒性。这种方法为处理时间序列数据中的复杂性和不确定性提供了一个新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型在时间序列分类（TSC）中广泛应用，但其性能在类相似性、多模态分布和噪声等具有挑战性的数据条件下会下降。

**Method:** 提出CDNet，一个对比扩散网络，通过学习扩散过程生成信息丰富的正负样本来增强现有分类器。CDNet不同于传统的扩散模型，它通过逆扩散步骤的卷积近似学习样本（类内和类间）之间的转换。引入了理论基础的基于CNN的机制，以实现去噪和模式覆盖，并结合不确定性加权的复合损失进行鲁棒训练。

**Result:** 在UCR档案和模拟数据集上的广泛实验表明，CDNet显著改善了最先进的（SOTA）深度学习分类器，尤其是在噪声、相似和多模态条件下。

**Conclusion:** CDNet通过生成信息丰富的正负样本，有效解决了深度学习时间序列分类模型在复杂数据条件下的性能局限性，从而显著提高了分类器的鲁棒性和准确性。

> **ai_Abstract:** CDNet（对比扩散网络）旨在解决深度学习时间序列分类模型在面对类相似性、多模态分布和噪声等挑战性数据条件时性能下降的问题。该网络通过学习扩散过程生成具有信息量的正负样本来增强现有分类器，并利用卷积近似逆扩散步骤来学习样本间的转换。CDNet引入了基于CNN的去噪和模式覆盖机制，并采用不确定性加权的复合损失进行鲁棒训练。实验证明，CDNet显著提升了现有深度学习分类器的性能，尤其是在噪声、相似和多模态条件下。

> **摘要翻译:** 深度学习模型因其可扩展性和效率而被广泛应用于时间序列分类（TSC）。然而，在类相似性、多模态分布和噪声等具有挑战性的数据条件下，它们的性能会下降。为了解决这些限制，我们提出了CDNet，一个对比扩散网络，它通过学习的扩散过程生成信息丰富的正负样本来增强现有分类器。与传统去噪单个样本的扩散模型不同，CDNet通过逆扩散步骤的卷积近似学习样本之间（包括类内和类间）的转换。我们引入了一种理论上基于CNN的机制，以实现去噪和模式覆盖，并结合不确定性加权的复合损失进行鲁棒训练。在UCR档案和模拟数据集上进行的广泛实验表明，CDNet显著改善了最先进的（SOTA）深度学习分类器，特别是在噪声、相似和多模态条件下。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [463] [A Scalable and High Availability Solution for Recommending Resolutions to Problem Tickets](https://arxiv.org/abs/2507.19846)
> *推荐问题工单解决方案的可扩展高可用方案*

*Harish Saragadam, Chetana K Nayak, Joy Bose* | **Category: cs.LG, cs.IR, 68T50, I.2.7; I.2.6; H.3.3; H.4.1** | **Updated: 2025-07-29**

**Keywords:** 问题工单, 机器学习, 解决方案推荐, NLP, 高可用性

**Comment:** 9 pages, 7 figures

> **TL;DR:** 本文提出了一种可扩展、高可用且基于机器学习的问题工单解决方案推荐系统，通过结合聚类、监督学习和高级自然语言处理模型，有效解决了数据漂移、数据缺失和文本歧义等挑战，并在实验中展现出高预测准确率。

**AI_Comments:** 该论文解决了服务行业中一个实际且普遍存在的问题。其创新之处在于结合多种机器学习和自然语言处理技术（如聚类、监督学习、Siamese网络、One-shot学习和索引嵌入）来应对数据漂移和文本歧义等特定数据挑战。此外，通过Kubernetes部署实现可扩展性和高可用性也是一个重要的实际贡献，使得该解决方案具备生产部署能力。

<details>
  <summary>Details</summary>

**Motivation:** 在服务行业中，解决事件或问题工单是常见任务，但现有的机器学习方法在推荐解决方案时面临诸多挑战，例如数据漂移、数据缺失、缺乏历史解决方案数据，以及由于自由文本和相似文本导致的解决方案模糊性。

**Method:** 本文提出了一种鲁棒的机器学习驱动解决方案，该方案结合了聚类、监督学习和高级自然语言处理（NLP）模型。具体方法包括基于聚类的解决方案识别、使用LDA、Siamese网络和One-shot学习进行监督分类，以及索引嵌入。此外，该方案还包括一个实时仪表板和一个基于Kubernetes的高可用生产部署。

**Result:** 在开源Bitext客户支持数据集和专有电信数据集上的实验表明，该方案具有高预测准确率。

**Conclusion:** 本文成功提出并验证了一种可扩展、高可用且基于机器学习的问题工单解决方案推荐系统，该系统能有效应对常见的数据挑战，并取得了高准确率。

> **ai_Abstract:** 本文提出了一种可扩展且高可用的机器学习解决方案，用于推荐问题工单的解决方案，旨在解决数据漂移、数据缺失和自由文本导致的歧义等常见挑战。该方案结合了聚类、监督学习（包括LDA、Siamese网络和One-shot学习与索引嵌入）以及高级NLP模型。此外，它还提供了实时仪表板和基于Kubernetes的生产部署。在开源Bitext和专有电信数据集上的实验结果表明，该方案具有高预测准确率。

> **摘要翻译:** 事件或问题工单的解决是任何服务行业（包括电信领域的计费和收费系统）的常见主题。机器学习可以通过历史工单数据中的模式，帮助识别并建议问题工单的解决方案。然而，由于各种现象（如数据漂移）以及数据缺失、缺乏与过去事件解决方案相关的数据、由于自由文本和相似文本导致太多听起来相似的解决方案等问题，这个过程可能会变得复杂。本文提出了一种鲁棒的机器学习驱动解决方案，该方案采用聚类、监督学习和高级自然语言处理模型来有效应对这些挑战。在先前工作的基础上，我们展示了基于聚类的解决方案识别、使用LDA、Siamese网络和One-shot学习进行监督分类，以及索引嵌入。此外，我们还展示了一个实时仪表板和一个基于Kubernetes的高可用生产部署。我们使用开源Bitext客户支持数据集和专有电信数据集进行的实验都证明了高预测准确率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [472] [Embeddings to Diagnosis: Latent Fragility under Agentic Perturbations in Clinical LLMs](https://arxiv.org/abs/2507.21188)
> *从嵌入到诊断：临床LLM中代理扰动下的潜在脆弱性*

*Raj Krishnan Vijayaraj* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-27**

**Keywords:** 临床LLM, 潜在脆弱性, 几何感知评估, 诊断不稳定性, 对抗性扰动

**Comment:** 

> **TL;DR:** 临床LLM在微小输入变化下表现出潜在脆弱性，本文提出LAPD框架和LDFR指标来诊断这种不稳定性。

**AI_Comments:** 该研究创新性地提出了一个几何感知评估框架LAPD和度量LDFR，用于揭示临床LLM在潜在表示层面的脆弱性，这是传统NLP指标难以捕捉的。它强调了在安全关键领域（如医疗）中，仅关注表面性能是不够的，还需要深入探究模型内部表示的稳定性。这对于提高临床AI的可靠性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 临床决策支持的LLM在面对微小但有临床意义的输入变化（如症状遮蔽或否定发现）时常会失败，尽管它们在静态基准上表现良好。这些推理失败通常无法被标准NLP指标检测到，因为这些指标对导致诊断不稳定的潜在表示变化不敏感。

**Method:** 本文提出了一个几何感知评估框架LAPD（Latent Agentic Perturbation Diagnostics），系统地探测临床LLM在结构化对抗性编辑下的潜在鲁棒性。在该框架内，引入了模型无关的诊断信号LDFR（Latent Diagnosis Flip Rate），它捕捉嵌入在PCA降维潜在空间中跨越决策边界时的表示不稳定性。临床笔记通过基于诊断推理的结构化提示管道生成，然后沿四个轴（遮蔽、否定、同义词替换、数字变异）进行扰动。研究在基础LLM和临床LLM上计算LDFR，并在DiReCT基准（MIMIC-IV）的90份真实临床笔记上验证了LDFR的普适性。

**Result:** 研究发现，即使在最小的表面变化下，潜在脆弱性也会出现。结果揭示了表面鲁棒性与语义稳定性之间存在持续的差距。

**Conclusion:** 强调了在安全关键型临床AI中进行几何感知审计的重要性。

> **ai_Abstract:** 本文提出LAPD框架和LDFR指标，用于诊断临床大型语言模型在微小输入扰动下的潜在脆弱性。研究发现，即使是表面上的细微变化，也会导致模型在潜在表示空间中发生不稳定性，从而影响诊断准确性。该方法通过系统地扰动临床笔记并分析嵌入在潜在空间中的行为，揭示了表面鲁棒性与语义稳定性之间的差距，强调了在临床AI中进行几何感知评估的重要性。

> **摘要翻译:** 临床决策支持的大型语言模型（LLMs）在面对微小但具有临床意义的输入变化（例如遮蔽症状或否定发现）时，尽管在静态基准测试中表现出色，但往往会失败。这些推理失败常常无法被标准NLP指标检测到，因为它们对驱动诊断不稳定的潜在表示变化不敏感。我们提出了一个几何感知评估框架，LAPD（潜在代理扰动诊断），它系统地探测临床LLM在结构化对抗性编辑下的潜在鲁棒性。在这个框架内，我们引入了潜在诊断翻转率（LDFR），这是一个与模型无关的诊断信号，它捕捉当嵌入在PCA降维的潜在空间中跨越决策边界时所产生的表示不稳定性。临床笔记使用基于诊断推理的结构化提示管道生成，然后沿着四个轴进行扰动：遮蔽、否定、同义词替换和数字变异，以模拟常见的歧义和遗漏。我们在基础LLM和临床LLM上计算了LDFR，发现即使在最小的表面变化下，潜在脆弱性也会出现。最后，我们在DiReCT基准（MIMIC-IV）的90份真实临床笔记上验证了我们的发现，证实了LDFR在合成设置之外的普适性。我们的结果揭示了表面鲁棒性与语义稳定性之间存在持续的差距，强调了在安全关键型临床AI中进行几何感知审计的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [476] [Quantize Once, Train Fast: Allreduce-Compatible Compression with Provable Guarantees](https://arxiv.org/abs/2305.18627)
> *一次量化，快速训练：Allreduce兼容的压缩与可证明的保证*

*Jihao Xin, Marco Canini, Peter Richtárik, Samuel Horváth* | **Category: cs.LG, cs.DC, stat.ML, I.2.11** | **Updated: 2025-07-29**

**Keywords:** 梯度量化, 分布式训练, Allreduce, 通信压缩, 理论保证

**Comment:** ECAI'25

> **TL;DR:** 本文提出了一种名为Global-QSGD的梯度量化方法，该方法与Allreduce兼容，并通过全局范数缩放来减少通信开销，同时保持准确性并提供理论收敛保证，实验证明其能有效加速分布式训练。

**AI_Comments:** Global-QSGD的创新之处在于其对Allreduce兼容性的解决，并首次为梯度量化提供了严格的理论收敛保证，而非仅仅依赖启发式方法。这显著提升了量化方法的可靠性和可信度。其在大规模分布式训练中的加速效果，表明了其在实际应用中的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 分布式训练在大规模深度学习中存在高通信开销问题，尤其随着模型和数据集的增长，梯度压缩（特别是量化）是缓解此瓶颈的有前景方法，但现有量化方案常与Allreduce不兼容，且缺乏理论保证。

**Method:** 本文引入了Global-QSGD，一种Allreduce兼容的梯度量化方法，它利用全局范数缩放来减少通信开销并保持精度。该方法基于严格的理论分析，扩展了标准无偏压缩器框架以建立形式化的收敛保证。此外，还开发了性能模型来评估其在不同硬件配置下的影响。

**Result:** 在NVLink、PCIe和大规模云环境中的广泛实验表明，Global-QSGD将分布式训练速度比基线量化方法提高了高达3.51%。

**Conclusion:** Global-QSGD是一种实用且高效的大规模深度学习工作负载解决方案，能够加速分布式训练并保持精度。

> **ai_Abstract:** 本文针对分布式深度学习中日益增长的通信开销问题，提出了一种名为Global-QSGD的梯度量化方法。该方法通过全局范数缩放实现与Allreduce的兼容性，旨在减少通信量的同时保持模型精度。Global-QSGD具备严格的理论收敛保证，并经过性能模型评估。实验结果表明，Global-QSGD在多种硬件环境下能将分布式训练速度提升高达3.51%，证明其在大规模深度学习应用中的实用性和高效性。

> **摘要翻译:** 分布式训练使得大规模深度学习成为可能，但其面临高昂的通信开销，尤其当模型和数据集不断增长时。梯度压缩，特别是量化，是缓解这一瓶颈的一种有前景的方法。然而，现有的量化方案通常与分布式深度学习中主流的通信原语Allreduce不兼容，并且许多先前的解决方案依赖启发式方法而缺乏理论保证。我们引入了Global-QSGD，这是一种与Allreduce兼容的梯度量化方法，它利用全局范数缩放来减少通信开销，同时保持精度。Global-QSGD得到了严格的理论分析支持，扩展了标准无偏压缩器框架以建立形式化的收敛保证。此外，我们开发了一个性能模型来评估其在不同硬件配置下的影响。在NVLink、PCIe和大规模云环境中的广泛实验表明，Global-QSGD将分布式训练速度比基线量化方法提高了高达3.51%，使其成为大规模深度学习工作负载的实用且高效的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [498] [Zero-Shot Machine Unlearning with Proxy Adversarial Data Generation](https://arxiv.org/abs/2507.21738)
> *零样本机器遗忘与代理对抗数据生成*

*Huiqiang Chen, Tianqing Zhu, Xin Yu, Wanlei Zhou* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 机器遗忘, 零样本, 对抗数据生成, 过遗忘

**Comment:** Accepted by IJCAI 2025

> **TL;DR:** ZS-PAG是一个零样本机器遗忘框架，通过生成代理对抗数据和在特定子空间进行遗忘来解决过遗忘问题，并在不依赖剩余数据的情况下提升模型性能。

**AI_Comments:** ZS-PAG在零样本机器遗忘这一实用且具有挑战性的问题上取得了创新性突破。通过巧妙地生成代理数据来弥补剩余数据缺失的困境，并结合子空间遗忘，有效防止了过遗忘。这种方法对于数据隐私和模型更新等实际应用场景具有重要意义，其理论保证也增强了方法的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器遗忘算法在零样本场景（即仅有需遗忘样本可用）下不适用，因为它们依赖剩余数据来防止过遗忘问题，而过遗忘会导致模型在剩余数据上的性能显著下降。

**Method:** 本文提出了一个名为ZS-PAG的新颖框架来解决零样本机器遗忘问题。该方法有三个关键创新点：1）通过生成对抗样本来近似不可访问的剩余数据；2）利用生成的样本，确定一个特定的子空间来执行遗忘过程，从而在零样本场景中防止过遗忘；3）考虑遗忘过程对剩余样本的影响，并设计了一种基于影响的伪标签策略。

**Result:** 所提出的方法在遗忘后进一步提高了模型的性能，具有理论保证，并且在各种基准测试上的实验验证了其有效性和优于多个基线方法。

**Conclusion:** ZS-PAG框架通过代理对抗数据生成和子空间遗忘，有效解决了零样本机器遗忘的挑战，成功防止了过遗忘并提升了模型性能。

> **ai_Abstract:** 本文提出了ZS-PAG框架，旨在解决零样本机器遗忘中的过遗忘问题。针对现有方法需要依赖剩余数据而无法应用于零样本场景的局限性，ZS-PAG通过生成代理对抗数据来近似不可访问的剩余数据，并在特定子空间进行遗忘以防止性能下降。此外，该方法还设计了基于影响的伪标签策略来进一步提升模型遗忘后的性能。实验结果表明，ZS-PAG具有理论保证，并在多个基准测试上表现出有效性和优越性。

> **摘要翻译:** 机器遗忘旨在从已训练模型中移除特定样本的影响。该过程中的一个关键挑战是过遗忘，即由于模型参数的变化，模型在剩余数据上的性能显著下降。现有的遗忘算法依赖剩余数据来防止这个问题。因此，这些方法在更实际的场景中不适用，即仅有需遗忘样本可用（即零样本遗忘）。本文提出了一个新颖的框架ZS-PAG来填补这一空白。我们的方法提供了三个关键创新：(1) 我们通过生成对抗样本来近似不可访问的剩余数据；(2) 利用生成的样本，我们确定一个特定的子空间来执行遗忘过程，从而在具有挑战性的零样本场景中防止过遗忘；(3) 我们考虑了遗忘过程对剩余样本的影响，并设计了一种基于影响的伪标签策略。因此，我们的方法在遗忘后进一步提高了模型的性能。所提出的方法具有理论保证，并且在各种基准测试上的实验验证了我们所提出方法相对于几个基线的有效性和优越性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [505] [MALLM-GAN: Multi-Agent Large Language Model as Generative Adversarial Network for Synthesizing Tabular Data](https://arxiv.org/abs/2406.10521)
> *MALLM-GAN：基于多智能体大型语言模型作为生成对抗网络用于合成表格数据*

*Yaobin Ling, Xiaoqian Jiang, Yejin Kim* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 大型语言模型, 生成对抗网络, 合成数据, 表格数据, 数据稀缺

**Comment:** 

> **TL;DR:** MALLM-GAN是一个利用大型语言模型（LLM）模拟生成对抗网络（GAN）的新框架，旨在从少量样本中生成高质量的合成表格数据，有效解决了数据稀缺和隐私问题。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型（LLMs）应用于生成对抗网络（GANs）的框架中，以解决合成表格数据生成中的数据稀缺问题。特别是在小样本量场景下，该方法能够显著提高合成数据的质量，这对于数据敏感且数据获取困难的领域（如医疗保健）具有重要意义。通过利用LLM的强大生成能力和优化能力，MALLM-GAN为合成数据生成提供了一条新颖且有效的途径。

<details>
  <summary>Details</summary>

**Motivation:** 在大数据时代，获取大量数据对推动研究至关重要，但由于隐私问题或高成本（尤其是在医疗领域），此类数据往往难以获取。尽管合成表格数据可以解决此问题，但现有模型通常需要大量数据进行有效训练，这与解决数据稀缺的目标相悖。

**Method:** 我们提出了一个名为MALLM-GAN的新框架，它利用大型语言模型（LLM）模拟生成对抗网络（GAN）的架构来生成合成表格数据。该方法将数据生成过程作为上下文信息，并利用LLM作为优化器，显著提高了小样本场景下合成数据的质量。

**Result:** 在公共和私人数据集上的实验结果表明，我们的模型在为下游任务生成更高质量的合成数据方面优于几种最先进的模型，同时保持了真实数据的隐私。

**Conclusion:** MALLM-GAN框架通过利用大型语言模型模拟生成对抗网络，能够有效生成高质量的合成表格数据，尤其适用于小样本场景，并能同时保护原始数据的隐私。

> **ai_Abstract:** MALLM-GAN是一个新颖的框架，它将大型语言模型（LLM）与生成对抗网络（GAN）架构相结合，用于生成高质量的合成表格数据。该方法通过将数据生成过程作为上下文并利用LLM作为优化器，特别擅长处理小样本数据集，并已在实验中证明其在生成高质量、隐私保护的合成数据方面优于现有最先进的模型。

> **摘要翻译:** 在大数据时代，获取丰富的数据对于推动研究至关重要。然而，由于隐私问题或高成本，此类数据往往难以获取，尤其是在医疗领域。生成合成（表格）数据可以解决这个问题，但现有模型通常需要大量数据才能有效训练，这与我们解决数据稀缺的目标相悖。为了应对这一挑战，我们提出了一个新颖的框架来生成合成表格数据，该框架由模仿生成对抗网络（GAN）架构的大型语言模型（LLM）驱动。通过将数据生成过程作为上下文信息并利用LLM作为优化器，我们的方法在小样本的常见场景中显著提高了合成数据生成的质量。我们在公共和私人数据集上的实验结果表明，我们的模型在为下游任务生成更高质量的合成数据方面优于几种最先进的模型，同时保持了真实数据的隐私。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [514] [Efficient Neural Combinatorial Optimization Solver for the Min-max Heterogeneous Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2507.21386)
> *用于最小-最大异构容量车辆路径问题的有效神经组合优化求解器*

*Xuan Wu, Di Wang, Chunguo Wu, Kaifang Qi, Chunyan Miao, Yubin Xiao, Jian Zhang, You Zhou* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 神经组合优化, 车辆路径问题, 异构容量, 强化学习, 数据增强

**Comment:** 

> **TL;DR:** 论文提出了ECHO，一种用于MMHCVRP的新型NCO求解器，通过解决现有方法的局限性并利用MMHCVRP的特定属性，ECHO优于现有方法。

**AI_Comments:** 这项创新的亮点在于解决了MMHCVRP的特定挑战，例如短视决策，并通过新颖的架构组件和数据增强，利用了领域特定的属性（车辆置换不变性、节点对称性）。这有助于实现更现实的VRP解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有神经组合优化求解器主要关注单车辆VRP变体，忽视了更现实的最小-最大异构容量车辆路径问题（MMHCVRP）。现有的MMHCVRP求解器在解码时做出短视决策，并忽略了关键属性，导致性能不佳。

**Method:** 提出的求解器ECHO采用：1. 双模态节点编码器来捕获节点之间的局部拓扑关系。2. 无参数交叉注意力机制，通过优先考虑前一步骤中选择的车辆来缓解短视决策。3. 针对MMHCVRP量身定制的数据增强策略，利用车辆置换不变性和节点对称性，以稳定强化学习训练过程。

**Result:** ECHO在不同数量的车辆和节点上均优于最先进的神经组合优化求解器。它在规模和分布模式上都表现出良好的泛化能力。消融研究验证了所有提出方法的有效性。

**Conclusion:** ECHO通过结合特定的机制和数据增强，有效解决了现有MMHCVRP求解器的局限性，从而实现了卓越的性能和泛化能力。

> **ai_Abstract:** 本文介绍了ECHO，一种为最小-最大异构容量车辆路径问题（MMHCVRP）设计的有效神经组合优化（NCO）求解器。与之前常做出短视决策并忽视关键MMHCVRP属性的求解器不同，ECHO集成了用于捕获拓扑关系的双模态节点编码器、用于减少短视决策的无参数交叉注意力机制，以及用于稳定强化学习训练的定制数据增强策略。实验表明，ECHO在各种规模和分布下，性能和泛化能力均超越了最先进的NCO求解器。

> **摘要翻译:** 大量神经组合优化（NCO）求解器已被提出用于解决车辆路径问题（VRPs）。然而，这些求解器大多只关注单车辆VRP变体，忽视了更现实的最小-最大异构容量车辆路径问题（MMHCVRP），该问题涉及多辆车。现有的MMHCVRP求解器通常在每个解码步骤选择一辆车及其下一个要访问的节点，但往往做出短视的解码决策，并忽视MMHCVRP的关键属性，包括局部拓扑关系、车辆置换不变性和节点对称性，导致次优性能。为了更好地解决这些局限性，我们提出了ECHO，一种高效的NCO求解器。首先，ECHO利用所提出的双模态节点编码器来捕获节点之间的局部拓扑关系。其次，为了缓解短视决策，ECHO采用所提出的无参数交叉注意力机制来优先考虑前一个解码步骤中选择的车辆。最后，利用车辆置换不变性和节点对称性，我们引入了一种针对MMHCVRP的定制数据增强策略，以稳定强化学习训练过程。为了评估ECHO的性能，我们进行了广泛的实验。实验结果表明，ECHO在不同数量的车辆和节点上均优于最先进的NCO求解器，并在规模和分布模式上都表现出良好的泛化能力。最后，消融研究验证了所有提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [535] [Operator-Based Machine Intelligence: A Hilbert Space Framework for Spectral Learning and Symbolic Reasoning](https://arxiv.org/abs/2507.21189)
> *基于算子的机器学习智能：一种用于谱学习和符号推理的希尔伯特空间框架*

*Andrew Kiruluta, Andreas Lemos, Priscilla Burity* | **Category: cs.LG** | **Updated: 2025-07-27**

**Keywords:** 希尔伯特空间, 谱学习, 算子, 泛函分析, 机器学习

**Comment:** 

> **TL;DR:** 本报告探讨了在无限维希尔伯特空间中进行机器学习的替代方法，利用泛函分析和谱理论，并讨论了其相对于传统神经网络的优缺点及未来方向。

**AI_Comments:** 这篇报告通过引入无限维希尔伯特空间的概念，为机器学习提供了一个全新的数学框架，摆脱了传统神经网络在有限维参数空间和非线性函数逼近上的限制。其创新之处在于将学习任务转化为希尔伯特空间中的采样和计算问题，并结合了泛函分析和谱理论等高级数学工具。这为开发更具可解释性和可扩展性的机器学习模型提供了理论基础，可能有助于解决传统神经网络的一些黑箱问题。

<details>
  <summary>Details</summary>

**Motivation:** 传统机器学习模型（特别是神经网络）受限于有限维参数空间和非线性函数逼近。本报告旨在探索一种将学习任务表达为在无限维希尔伯特空间中进行采样和计算的替代方法。

**Method:** 该方法将学习任务表达为在无限维希尔伯特空间中的采样和计算，利用泛函分析、信号处理和谱理论工具。报告回顾了再生核希尔伯特空间（RKHS）、谱算子学习和小波域表示等基础概念，并提出了希尔伯特空间学习的严格数学公式，重点介绍了基于散射变换和Koopman算子的最新模型。

**Result:** 报告回顾了相关基础概念，提出了严格的数学公式，并讨论了基于散射变换和Koopman算子的最新模型。同时，也讨论了相对于传统神经网络架构的优势和局限性。没有具体实验结果，更多是概念和框架的探讨。

**Conclusion:** 报告最后概述了基于希尔伯特信号处理的可扩展和可解释机器学习的发展方向。

> **ai_Abstract:** 本报告提出了一种替代传统机器学习（特别是神经网络）的方法，将学习任务置于无限维希尔伯特空间中，利用泛函分析、信号处理和谱理论进行采样和计算。文章回顾了再生核希尔伯特空间、谱算子学习和小波域表示等核心概念，并提供了严格的数学框架，探讨了散射变换和Koopman算子模型，同时分析了其相对于传统神经网络的优缺点，并展望了基于希尔伯特信号处理的可扩展和可解释机器学习的未来方向。

> **摘要翻译:** 传统机器学习模型，特别是神经网络，根植于有限维参数空间和非线性函数逼近。本报告探索了一种替代的表述方式，即学习任务在无限维希尔伯特空间中表达为采样和计算，利用泛函分析、信号处理和谱理论的工具。我们回顾了再生核希尔伯特空间（RKHS）、谱算子学习和小波域表示等基础概念。我们提出了希尔伯特空间学习的严格数学公式，重点介绍了基于散射变换和Koopman算子的最新模型，并讨论了相对于传统神经网络架构的优势和局限性。报告最后概述了基于希尔伯特信号处理的可扩展和可解释机器学习的发展方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [539] [Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs](https://arxiv.org/abs/2407.15549)
> *潜在对抗训练提高LLM对持续有害行为的鲁棒性*

*Abhay Sheshadri, Aidan Ewart, Phillip Guo, Aengus Lynch, Cindy Wu, Vivek Hebbar, Henry Sleight, Asa Cooper Stickland, Ethan Perez, Dylan Hadfield-Menell, Stephen Casper* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-29**

**Keywords:** 潜在对抗训练,大型语言模型,鲁棒性,有害行为,越狱

**Comment:** Code at https://github.com/aengusl/latent-adversarial-training.
  Models at https://huggingface.co/LLM-LAT

> **TL;DR:** 针对性潜在对抗训练（Targeted LAT）能有效提高大型语言模型（LLMs）对越狱、后门和不良知识的鲁棒性，且计算成本低。

**AI_Comments:** 本文的创新点在于提出了“目标导向的潜在对抗训练”，通过针对特定竞争任务来优化对抗过程，从而更精确有效地提升LLM的鲁棒性。与传统方法相比，其在计算效率上的显著提升（数量级减少）是一个重要优势。这对于LLM安全领域具有重要意义，因为它提供了一种更实用的方法来应对持续存在的有害行为，尤其是在模型编辑和内容审核方面。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）即使经过显式微调，仍可能表现出不良行为（如“越狱”产生有害文本），这源于微调多是抑制而非移除不良能力。因此，需要更有效的方法来提高LLM对这些持续有害行为的鲁棒性。

**Method:** 本文实验了“目标导向的潜在对抗训练 (targeted LAT)”，其中对抗者旨在最小化特定竞争任务上的损失。这与以往旨在最大化期望行为损失的“无目标导向的潜在对抗训练 (untargeted LAT)”不同。

**Result:** 1. 使用目标导向的LAT显著提高了LLM对越狱的鲁棒性，性能优于R2D2基线，且计算量少几个数量级。2. 提高了在不知触发器的情况下移除后门的效率。3. 更有效地遗忘特定不良任务的知识，并且对再学习更具鲁棒性。

**Conclusion:** 目标导向的潜在对抗训练可以作为防御LLM有害行为的有效工具。

> **ai_Abstract:** 本文提出并实验了目标导向的潜在对抗训练（targeted LAT），以解决大型语言模型（LLMs）在微调后仍易受有害行为（如越狱、后门、不良知识再学习）影响的问题。与传统的无目标导向LAT不同，targeted LAT通过最小化特定竞争任务上的损失来增强模型鲁棒性。实验证明，该方法在提高LLM对越狱的防御能力、高效移除后门以及有效遗忘特定不良知识方面表现出色，且计算效率远超现有基线，显示出其作为防御LLM有害行为的强大潜力。

> **摘要翻译:** 大型语言模型（LLMs）常常会以它们被明确微调以避免的方式表现出不良行为。例如，LLM红队文献已经产生了各种各样的“越狱”技术，以从被微调为无害的模型中引出有害文本。最近关于红队、模型编辑和可解释性的工作表明，这一挑战源于（对抗）微调主要是抑制而不是移除LLM中不良能力的方式。先前的研究引入了潜在对抗训练（LAT）作为提高对广泛类别故障鲁棒性的一种方法。这些先前的工作考虑了无目标导向的潜在空间攻击，其中对抗者扰动潜在激活以最大化期望行为示例上的损失。无目标导向的LAT可以提供一种通用类型的鲁棒性，但没有利用关于特定故障模式的信息。在这里，我们实验了目标导向的LAT，其中对抗者试图最小化特定竞争任务上的损失。我们发现它可以增强各种最先进的方法。首先，我们使用目标导向的LAT来提高对越狱的鲁棒性，其性能优于强大的R2D2基线，且计算量少几个数量级。其次，我们使用它在不知道触发器的情况下更有效地移除后门。最后，我们使用它以一种对再学习也更具鲁棒性的方式，更有效地遗忘特定不良任务的知识。总的来说，我们的结果表明，目标导向的LAT可以成为防御LLM有害行为的有效工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [550] [An $\tilde{O}$ptimal Differentially Private Learner for Concept Classes with VC Dimension 1](https://arxiv.org/abs/2505.06581)
> *VC维数为1的概念类别的最优差分隐私学习器*

*Chao Yan* | **Category: cs.LG, cs.CR** | **Updated: 2025-07-29**

**Keywords:** 差分隐私, PAC学习, VC维数, 样本复杂度, 概念类别

**Comment:** Add proper learner

> **TL;DR:** 提出了一个针对VC维数为1的概念类别，且具有近乎最优样本复杂度的差分隐私PAC学习器，显著优于现有最佳上界。

**AI_Comments:** 本文的创新之处在于其首次为VC维数为1的概念类别提供了近乎最优的差分隐私PAC学习器，其样本复杂度达到了理论下界，这是该领域的一个重大突破。它显著改进了现有算法的效率，对差分隐私机器学习的理论和实践都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在差分隐私PAC学习领域，对于VC维数为1的概念类别，现有算法的样本复杂度表现不佳，例如Ghazi等人[STOC21]的最佳已知上界为$\tilde{O}(VC\cdot d^5)$。本文旨在改进这一现状，实现更优的样本复杂度。

**Method:** 本文提出了一种新的算法，专门针对VC维数为1和Littlestone维数为$d$的任何概念类别。

**Result:** 该算法达到了$\tilde{O}_{\varepsilon,\delta,\alpha,\delta}(\log^* d)$的样本复杂度，几乎匹配了Alon等人[STOC19]证明的$\Omega(\log^* d)$下界。

**Conclusion:** 本文成功为VC维数为1的概念类别设计了一个近乎最优的差分隐私PAC学习器，其样本复杂度显著优于现有技术水平，接近理论下限。

> **ai_Abstract:** 本文介绍了一种针对VC维数为1且Littlestone维数为$d$的概念类别的差分隐私PAC学习器。该算法实现了$\tilde{O}(\log^* d)$的样本复杂度，这几乎达到了理论下限，并显著改进了之前针对一般VC类别的最佳已知上界$\tilde{O}(VC\cdot d^5)$。

> **摘要翻译:** 我们提出了第一个针对VC维数为1且Littlestone维数为$d$的任何概念类别的近乎最优差分隐私PAC学习器。我们的算法实现了$\tilde{O}_{\varepsilon,\delta,\alpha,\delta}(\log^* d)$的样本复杂度，几乎匹配了Alon等人[STOC19]证明的$\Omega(\log^* d)$下界。在我们的工作之前，Ghazi等人[STOC21]表明，对于一般的VC类别，最佳已知上界是$\tilde{O}(VC\cdot d^5)$。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [551] [TempRe: Template generation for single and direct multi-step retrosynthesis](https://arxiv.org/abs/2507.21762)
> *TempRe：单步和直接多步逆合成的模板生成*

*Nguyen Xuan-Vu, Daniel P Armstrong, Zlatko Jončev, Philippe Schwaller* | **Category: cs.LG** | **Updated: 2025-07-30**

**Keywords:** 逆合成, 模板生成, 序列生成, 分子发现, 合成规划

**Comment:** 

> **TL;DR:** 提出TempRe，一个将模板基逆合成重构为序列生成的生成框架，解决了传统方法的局限性，实现了可扩展、灵活且化学上合理的逆合成，并在单步和多步任务中表现优异。

**AI_Comments:** 本文的创新点在于将模板基逆合成问题转化为序列生成任务，这有效地结合了传统模板方法的化学合理性与生成模型的灵活性和可扩展性。TempRe通过这种新颖的表述方式，显著提升了逆合成规划的效率和准确性，尤其是在处理多步合成路径方面，为计算机辅助合成规划领域提供了一个强大且实用的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 逆合成规划因庞大复杂的化学反应空间而面临挑战。传统基于模板的方法可处理性好但可扩展性和泛化性差；而无模板生成方法可能生成无效反应。

**Method:** 提出了TempRe，一个生成框架，将基于模板的方法重新表述为序列生成，从而实现可扩展、灵活且化学上合理的逆合成。

**Result:** 在单步和多步逆合成任务中，TempRe表现优于模板分类和基于SMILES的生成方法。在PaRoutes多步基准测试中，TempRe取得了很高的top-k路线准确率。此外，TempRe被扩展到直接多步合成路线生成，提供了传统单步和基于搜索方法的轻量级高效替代方案。

**Conclusion:** 这些结果突出了模板生成模型作为计算机辅助合成规划中强大范式的潜力。

> **ai_Abstract:** 本文提出了TempRe，一个创新的生成框架，它将传统的基于模板的逆合成方法重新定义为序列生成问题。该方法旨在克服现有模板方法的扩展性和泛化性限制，并避免无模板方法可能产生的无效反应。TempRe在单步和多步逆合成任务中均表现出色，优于现有方法，并在多步基准测试中展现了高准确率。此外，它还被扩展用于直接多步合成路线生成，提供了一种高效的替代方案，展示了模板生成模型在计算机辅助合成规划中的巨大潜力。

> **摘要翻译:** 逆合成规划由于其庞大而复杂的化学反应空间，仍然是分子发现中的一个核心挑战。传统的基于模板的方法虽然具有可处理性，但存在可扩展性差和泛化能力有限的问题，而无模板生成方法则存在生成无效反应的风险。在这项工作中，我们提出了TempRe，一个生成框架，它将基于模板的方法重新表述为序列生成，从而实现可扩展、灵活且化学上合理的逆合成。我们评估了TempRe在单步和多步逆合成任务中的表现，证明了其优于模板分类和基于SMILES的生成方法。在PaRoutes多步基准测试中，TempRe取得了很高的top-k路线准确率。此外，我们将TempRe扩展到直接多步合成路线生成，为传统的单步和基于搜索的方法提供了一种轻量级且高效的替代方案。这些结果突出了模板生成模型作为计算机辅助合成规划中强大范式的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [567] [Recovering Manifold Structure Using Ollivier-Ricci Curvature](https://arxiv.org/abs/2410.01149)
> *使用Ollivier-Ricci曲率恢复流形结构*

*Tristan Luca Saidi, Abigail Hickok, Andrew J. Blumberg* | **Category: cs.LG, cs.AI, cs.CG** | **Updated: 2025-07-28**

**Keywords:** Ollivier-Ricci曲率, 流形学习, 最近邻图, 图修剪, 几何数据分析

**Comment:** 

> **TL;DR:** ORC-ManL是一种基于Ollivier-Ricci曲率和度量失真估计的新算法，用于修剪最近邻图中的虚假边，显著提高了几何数据分析任务的性能。

**AI_Comments:** ORC-ManL的创新之处在于将Ollivier-Ricci曲率引入到最近邻图的修剪中，解决了流形学习中虚假边的问题。该方法不仅在理论上得到了支持，并通过实验证明了其在多种几何数据分析任务中的显著性能提升，尤其是在生物医学数据分析中的应用潜力值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机源于流形学习：当生成最近邻图的数据是来自低维流形的噪声样本时，穿过环境空间的捷径边的Ollivier-Ricci曲率比沿着数据流形分布的边的曲率更负。

**Method:** ORC-ManL算法利用Ollivier-Ricci曲率和估计的度量失真作为标准，从最近邻图中修剪虚假边。它基于的观察是，流形学习中，穿过环境空间的捷径边比沿着数据流形分布的边具有更负的Ollivier-Ricci曲率。

**Result:** ORC-ManL方法优于其他修剪方法，并且显著提高了许多使用最近邻图作为输入的下游几何数据分析任务的性能。具体评估了流形学习、持久同源性、维度估计等。该方法还可以用于改善单细胞RNA测序数据的聚类和流形学习。经验收敛实验支持了理论发现。

**Conclusion:** ORC-ManL是一种有效且性能优越的算法，能够通过修剪最近邻图中的虚假边来恢复流形结构，从而改善多种几何数据分析任务的性能，并已被证明在生物数据分析中也有应用潜力。

> **ai_Abstract:** 本文提出了一种名为ORC-ManL的新算法，该算法利用Ollivier-Ricci曲率和估计的度量失真来有效修剪最近邻图中的虚假边。研究表明，在低维流形噪声采样数据中，捷径边的Ollivier-Ricci曲率更负。实验结果表明，ORC-ManL在流形学习、持久同源性、维度估计等多种几何数据分析任务中表现优异，并能改进单细胞RNA测序数据的聚类和流形学习。

> **摘要翻译:** 我们引入了ORC-ManL，这是一种新的算法，它使用基于Ollivier-Ricci曲率和估计度量失真的准则来修剪最近邻图中的虚假边。我们的动机来自于流形学习：我们表明，当生成最近邻图的数据由低维流形的噪声样本组成时，穿过环境空间的捷径边比沿着数据流形分布的边具有更负的Ollivier-Ricci曲率。我们证明了我们的方法优于替代的修剪方法，并且它显著提高了许多使用最近邻图作为输入的下游几何数据分析任务的性能。具体来说，我们在流形学习、持久同源性、维度估计等方面进行了评估。我们还表明，ORC-ManL可以用于改善单细胞RNA测序数据的聚类和流形学习。最后，我们提供了支持我们理论发现的经验收敛实验。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [571] [Systolic Array-based Accelerator for State-Space Models](https://arxiv.org/abs/2507.21394)
> *基于脉动阵列的状态空间模型加速器*

*Shiva Raja, Cansu Demirkiran, Aakash Sarkar, Milos Popovic, Ajay Joshi* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-29**

**Keywords:** 状态空间模型, 脉动阵列, 硬件加速器, 序列建模, 能效

**Comment:** 

> **TL;DR:** 本文提出了一种名为EpochCore的专用硬件加速器，用于高效加速状态空间模型（SSMs）的推理，特别针对长序列任务，实现了显著的性能和能效提升。

**AI_Comments:** 该论文的创新之处在于提出了一种专门针对状态空间模型（SSMs）的硬件加速器，解决了SSM在传统CPU/GPU上计算和内存密集的问题。通过设计专用的脉动阵列、处理单元（LIMA-PE）和数据流（ProDF），该加速器能够高效处理长序列任务，显著提升了SSM的性能和能效。尽管面积成本有所增加，但其带来的性能和能效增益（数百倍）远超其代价，对推动SSM在实际应用中的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的RNNs、CNNs和Transformers在处理超长序列时面临内存保留（固定上下文窗口）的限制，难以实现高精度。尽管状态空间模型（SSMs）能更有效地处理超长数据序列，但其需要通过连续积分求解微分方程，导致在传统CPU和GPU上训练和推理都计算和内存密集。

**Method:** 本文引入了名为EpochCore的专用硬件加速器来加速SSMs。EpochCore基于脉动阵列（SAs）设计，旨在提高SSM模型在长序列任务推理时的能效和吞吐量。在SA中，提出了一种通用的处理单元（PE）LIMA-PE，用于执行传统和专门的MAC操作，以支持传统DNNs和SSMs。此外，还提出了一种新颖的数据流ProDF，以实现SSM模型的高效执行。

**Result:** 通过利用LIMA-PE微架构和ProDF数据流，EpochCore在性能上平均实现了250倍的提升，能效方面实现了45倍的改进，但代价是面积成本比传统基于SA的加速器增加了2倍。与GPU内核操作相比，在LRA数据集上的延迟/推理速度提高了约2000倍。

**Conclusion:** 本文提出的EpochCore加速器，结合LIMA-PE处理单元和ProDF数据流，显著提升了状态空间模型在长序列任务上的推理性能和能效，有效地解决了SSM在传统硬件上的计算和内存密集问题。

> **ai_Abstract:** 本文针对现有模型在处理超长序列时的局限性以及状态空间模型（SSMs）在传统硬件上计算密集的问题，提出了一种基于脉动阵列的专用硬件加速器EpochCore。该加速器集成了通用的LIMA-PE处理单元和新颖的ProDF数据流，旨在高效加速SSM的推理。实验结果表明，EpochCore在性能和能效上取得了显著提升，证明了其在长序列任务中加速SSM的潜力。

> **摘要翻译:** 序列建模对于AI理解时间数据和检测复杂的时间依赖模式至关重要。虽然循环神经网络（RNNs）、卷积神经网络（CNNs）和Transformer在捕获长距离依赖方面取得了进展，但由于内存保留有限（固定上下文窗口），它们在处理超长序列时难以实现高精度。状态空间模型（SSMs）利用指数衰减记忆，实现了较长的上下文窗口，因此比循环和基于Transformer的模型更有效地处理超长数据序列。与CNN和RNN等传统神经网络模型不同，基于SSM的模型需要通过连续积分求解微分方程，这使得在传统CPU和GPU上进行训练和推理都计算和内存密集。本文介绍了一种名为EpochCore的专用硬件加速器，用于加速SSMs。EpochCore基于脉动阵列（SAs），旨在提高SSM模型在长距离序列任务推理时的能效和吞吐量。在SA内部，我们提出了一种通用的处理单元（PE），称为LIMA-PE，用于执行传统和专门的MAC操作，以支持传统DNN和SSM。为了补充EpochCore微架构，我们提出了一种新颖的数据流ProDF，它能够实现基于SSM模型的高效执行。通过利用LIMA-PE微架构和ProDF，EpochCore在性能上平均实现了250倍的提升，能效方面实现了45倍的改进，但代价是面积成本比传统基于SA的加速器增加了2倍，并且与GPU内核操作相比，在LRA数据集上的延迟/推理速度提高了约2000倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [580] [Tapping into the Black Box: Uncovering Aligned Representations in Pretrained Neural Networks](https://arxiv.org/abs/2507.22832)
> *深入黑箱：揭示预训练神经网络中对齐的表示*

*Maciej Satkiewicz* | **Category: cs.LG, cs.CV, cs.NE, I.2.6; I.4.10** | **Updated: 2025-07-30**

**Keywords:** ReLU网络, 隐式线性模型, 反向传播, 特征解释, 可解释AI

**Comment:** 15 pages, 4 figures, preprint

> **TL;DR:** 本文提出ReLU网络学习了一种可利用的隐式线性模型，通过修改反向传播可以揭示神经网络内部的高分辨率、可解释的特征。

**AI_Comments:** 这篇论文通过提出一种新颖的反向传播修改方法，有效地“打开”了神经网络的“黑箱”，揭示了其内部学习到的可解释特征。这一方法对于理解深度学习模型、提高模型可信度以及促进知识发现具有重要意义。其创新之处在于将隐式线性模型与反向传播修改相结合，实现了对模型内部表示的有效可视化和解释。

<details>
  <summary>Details</summary>

**Motivation:** 神经网络，特别是ReLU网络，常被视为“黑箱”，难以理解其内部决策过程。本文旨在揭示这些网络中学习到的可解释模式。

**Method:** 作者认为ReLU网络学习了一种隐式线性模型。通过对反向传播进行简单修改，可以将决策边界近似地拉回到输入空间，产生被称为“激励回溯”的梯度。

**Result:** “激励回溯”在多个流行的ImageNet预训练深度架构上，揭示了具有显著感知对齐的高分辨率输入和目标特定特征。这强烈表明神经网络确实依赖于训练后可恢复的可解释模式。

**Conclusion:** 研究发现神经网络学习了可解释的模式，这对于知识发现和开发可靠的人工智能系统具有深远意义。

> **ai_Abstract:** 本文提出ReLU网络学习了一种可利用的隐式线性模型。通过对反向传播进行简单修改，可以生成“激励回溯”梯度，这些梯度在ImageNet预训练模型上揭示了高分辨率、感知对齐的可解释特征。研究结果表明神经网络内部存在可恢复的、可解释的模式，对知识发现和可靠AI系统开发具有重要意义。

> **摘要翻译:** 在本文中，我们认为ReLU网络学习了一个我们可以实际利用的隐式线性模型。我们形式化地描述了该模型，并展示了通过对反向传播进行某些简单的修改，我们可以近似地将其决策边界拉回到输入空间。由此产生的梯度（称为“激励回溯”）在许多流行的ImageNet预训练深度架构上，揭示了具有卓越感知对齐的高分辨率输入和目标特定特征。这强烈表明神经网络确实依赖于训练后可以恢复的可解释模式。因此，我们的发现可能对知识发现和可靠人工智能系统的发展产生深远影响。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [595] [Local Attention Mechanism: Boosting the Transformer Architecture for Long-Sequence Time Series Forecasting](https://arxiv.org/abs/2410.03805)
> *局部注意力机制：提升Transformer架构在长序列时间序列预测中的表现*

*Ignacio Aguilera-Martos, Andrés Herrera-Poyatos, Julián Luengo, Francisco Herrera* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 局部注意力机制, Transformer, 时间序列预测, 长序列, 计算复杂度

**Comment:** 

> **TL;DR:** 本文提出局部注意力机制（LAM），一种针对时间序列分析的高效注意力机制，将传统注意力机制的复杂度从O(n^2)降低到O(nlogn)。实验证明，结合LAM的Transformer模型超越了现有最佳模型。

**AI_Comments:** 本文的创新点在于提出了局部注意力机制（LAM），通过利用时间序列的连续性特性，显著降低了Transformer在处理长序列时的计算复杂性，从O(n^2)优化到O(nlogn)，这对于长序列时间序列预测是一个重要的进步。同时，研究还关注了数据集不足的问题，并提出了新的数据集，对该领域的模型评估具有积极意义。该方法的有效性通过实验得到了验证，显示出超越现有SOTA模型的潜力。

<details>
  <summary>Details</summary>

**Motivation:** Transformer架构在自然语言处理和时间序列分析（特别是长序列预测）中表现出色，但传统注意力机制的计算复杂性高。同时，缺乏合适的长期预测数据集。

**Method:** 引入局部注意力机制（LAM），利用时间序列的连续性特性来减少注意力分数的计算量。提出了在张量代数中实现LAM的算法，实现了O(nlogn)的时间和内存复杂度。此外，提出了一组新的数据集以改善长序列预测模型的评估。

**Result:** 实验分析表明，结合LAM的Transformer架构超越了包括传统注意力机制在内的现有最先进模型。

**Conclusion:** 局部注意力机制（LAM）有效提升了Transformer在长序列时间序列预测中的性能，并解决了传统注意力机制的计算效率问题。研究还指出了长序列时间序列预测领域未来的挑战。

> **ai_Abstract:** 本文提出了一种名为局部注意力机制（LAM）的高效注意力机制，专门用于时间序列分析。LAM利用时间序列的连续性，将Transformer的计算复杂性从O(n^2)降低到O(nlogn)。研究还提出了一组新的数据集以更好地评估长序列预测模型。实验结果显示，结合LAM的Transformer模型在性能上优于现有最先进的模型。

> **摘要翻译:** Transformer在自然语言处理领域已成为领先于其他深度学习架构的选择。这一趋势也渗透到时间序列分析领域，特别是对于长序列预测，在性能和运行时间方面都展现出有前景的结果。
本文引入了局部注意力机制（LAM），这是一种专为时间序列分析量身定制的高效注意力机制。该机制利用时间序列的连续性特性来减少计算的注意力分数。我们提出了一种在张量代数中实现LAM的算法，其运行时间和内存复杂度为O(nlogn)，显著优于传统注意力机制的O(n^2)时间和内存复杂度。我们还注意到缺乏适当的数据集来评估长序列预测模型。因此，我们提出了一组新颖的数据集，以改进对解决长序列预测挑战的模型的评估。
我们的实验分析表明，结合LAM的Transformer架构超越了包括传统注意力机制在内的现有最先进模型。这些结果证实了我们方法的有效性，并突出了长序列时间序列预测领域未来的一系列挑战。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [597] [Beyond Neural Networks: Symbolic Reasoning over Wavelet Logic Graph Signals](https://arxiv.org/abs/2507.21190)
> *超越神经网络：基于小波逻辑图信号的符号推理*

*Andrew Kiruluta, Andreas Lemos, Priscilla Burity* | **Category: cs.LG** | **Updated: 2025-07-27**

**Keywords:** 图拉普拉斯小波变换, 符号推理, 非神经网络, 图信号, 可解释性

**Comment:** 

> **TL;DR:** 该论文提出了一种基于图拉普拉斯小波变换（GLWT）的非神经网络学习框架，通过在图谱域进行多尺度滤波、非线性收缩和符号逻辑操作，实现图信号处理和推理，并在去噪和令牌分类任务上表现出竞争性，同时具有更高的透明度和效率。

**AI_Comments:** 该论文的创新之处在于提出了一种完全非神经网络的图学习方法，通过结合图拉普拉斯小波变换和符号逻辑，实现了图信号的有效处理和推理。其重要性在于提供了一个高度可解释且资源高效的深度学习替代方案，这对于需要透明度（如可解释AI）和资源受限环境下的图数据分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为深度神经网络在图学习方面提供一种原理性、可解释且资源高效的替代方案。

**Method:** 提出一个基于图拉普拉斯小波变换（GLWT）的非神经网络学习框架。该模型在图谱域操作，使用结构化多尺度滤波、非线性收缩和基于小波系数的符号逻辑。图节点信号通过GLWT分解、非线性调制和重组，并通过符号领域特定语言（DSL）支持组合推理。

**Result:** 在合成图去噪和语言令牌图上的实验表明，与轻量级GNN相比，该模型性能具有竞争力，且透明度和效率更高。

**Conclusion:** 这项工作为图学习提供了一种原理性、可解释且资源高效的深度神经网络替代方案。

> **ai_Abstract:** 本文介绍了一种名为“超越神经网络”的新型学习框架，它完全基于图拉普拉斯小波变换（GLWT），旨在替代传统的深度神经网络。该框架在图谱域内通过多尺度滤波、非线性收缩和符号逻辑对小波系数进行操作，并利用符号领域特定语言（DSL）实现组合推理。实验证明，在图去噪和令牌分类任务上，该模型在保持竞争性性能的同时，显著提高了透明度和效率，为图学习提供了一种可解释且资源高效的替代方案。

> **摘要翻译:** 我们提出一个完全非神经网络的学习框架，该框架基于图拉普拉斯小波变换（GLWT）。与依赖于卷积、循环或基于注意力的神经网络的传统架构不同，我们的模型纯粹在图谱域中操作，利用结构化多尺度滤波、非线性收缩以及基于小波系数的符号逻辑。定义在图节点上的信号通过GLWT分解，通过可解释的非线性进行调制，并重新组合以用于去噪和令牌分类等下游任务。该系统通过基于图小波激活的符号领域特定语言（DSL）支持组合推理。在合成图去噪和语言令牌图上的实验表明，与轻量级图神经网络（GNN）相比，该系统具有竞争性性能，并且透明度和效率大大提高。这项工作为图学习提供了一种原理性、可解释且资源高效的深度神经网络替代方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [607] [Unlocking Interpretability for RF Sensing: A Complex-Valued White-Box Transformer](https://arxiv.org/abs/2507.21799)
> *解锁射频感知的可解释性：一种复值白盒Transformer*

*Xie Zhang, Yina Wang, Chenshu Wu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 射频感知, 可解释性, 白盒Transformer, 复值网络, 子空间正则化

**Comment:** 

> **TL;DR:** RF-CRATE是一个数学上可解释的复值白盒Transformer，用于射频感知，性能与黑盒模型相当，并显著提升了可解释性。

**AI_Comments:** 这篇论文的创新点在于首次将白盒Transformer架构扩展到复数域，以解决射频感知领域深度学习模型可解释性差的问题。其重要性在于，在不牺牲性能的前提下，显著提升了模型的可解释性，这对于安全敏感的应用至关重要。引入的子空间正则化也有效提升了模型从有限数据中提取判别特征的能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度无线感知（DWS）模型大多是黑盒，可解释性有限，这阻碍了它们的泛化能力，并在安全敏感的物理应用中引发担忧。

**Method:** 提出了RF-CRATE，第一个基于复稀疏率规约原理的数学可解释深度网络架构。通过非平凡的理论推导将原始实值白盒Transformer扩展到复数域，并利用CR-Calculus框架构建了全复值白盒Transformer。引入了子空间正则化策略以增强特征多样性。

**Result:** RF-CRATE在多种感知任务中实现了与精心设计的黑盒模型相当的性能，并提供了完全的数学可解释性。与CRATE相比，RF-CRATE在分类上平均提高了5.08%，回归误差减少了10.34%，子空间正则化使性能平均提高了19.98%。

**Conclusion:** RF-CRATE通过将CRATE扩展到复数域，成功地为射频感知提供了数学可解释的深度网络架构，并在保持高性能的同时显著提升了可解释性。

> **ai_Abstract:** 本文提出了RF-CRATE，这是一种用于射频感知的首个数学可解释的深度网络架构。它将白盒Transformer扩展到复数域以处理射频信号，并引入子空间正则化以提高特征提取能力。实验证明，RF-CRATE在保持与黑盒模型相当性能的同时，提供了完全的数学可解释性，并在多个感知任务中实现了显著的性能提升。

> **摘要翻译:** 深度学习的经验成功促进了其在射频（RF）领域的应用，从而在深度无线感知（DWS）方面取得了显著进展。然而，大多数现有的DWS模型作为黑盒运行，可解释性有限，这阻碍了它们的泛化能力，并在安全敏感的物理应用中引发担忧。在这项工作中，受白盒Transformer显著进展的启发，我们提出了RF-CRATE，这是第一个用于射频感知的数学可解释深度网络架构，其基础是复稀疏率规约原理。为了适应独特的射频信号，我们进行了非平凡的理论推导，将原始的实值白盒Transformer扩展到复数域。通过利用CR-Calculus框架，我们成功构建了一个具有理论推导的自注意力模块和残差多层感知器模块的全复值白盒Transformer。此外，为了提高模型从有限无线数据中提取判别特征的能力，我们引入了子空间正则化，这是一种新颖的正则化策略，可增强特征多样性，从而在多个感知任务中平均性能提高了19.98%。我们使用多个公共和自收集的包含不同射频信号的数据集，广泛评估了RF-CRATE与七个基线的性能。结果表明，RF-CRATE实现了与精心设计的黑盒模型相当的性能，同时提供了完全的数学可解释性。更重要的是，通过将CRATE扩展到复数域，RF-CRATE与CRATE相比，在各种感知任务中实现了显著的改进，平均分类增益为5.08%，回归误差减少了10.34%。RF-CRATE已完全开源：https://github.com/rfcrate/RF_CRATE。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [620] [FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning](https://arxiv.org/abs/2507.14322)
> *FedStrategist：一种联邦学习中自适应和鲁棒聚合的元学习框架*

*Md Rafid Haque, Abu Raihan Mostofa Kamal, Md. Azam Hossain* | **Category: cs.LG, cs.CR, cs.DC, I.2.11; C.2.4; K.6.5** | **Updated: 2025-07-28**

**Keywords:** 联邦学习, 元学习, 鲁棒聚合, 模型中毒攻击, 上下文多臂老虎机

**Comment:** 24 pages, 8 figures. This work is intended for a journal submission

> **TL;DR:** FedStrategist是一个元学习框架，通过动态选择聚合规则来增强联邦学习抵御模型中毒攻击的能力，实现了性能与安全之间的权衡管理。

**AI_Comments:** FedStrategist的创新在于将鲁棒聚合问题转化为一个实时控制的元学习问题，并引入了上下文多臂老虎机代理进行动态决策。这解决了传统静态防御在联邦学习中面对自适应攻击和异构环境时的局限性。其能够通过一个参数控制性能与安全权衡的特点，也极大地提升了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习虽然保护隐私，但其去中心化特性使其容易受到模型中毒攻击。现有静态防御措施的有效性高度依赖上下文，在面对自适应对手或异构数据环境时往往失效。

**Method:** 本文提出了FedStrategist，一个新颖的元学习框架，将鲁棒聚合重新定义为实时、成本感知的控制问题。它设计了一个轻量级的上下文多臂老虎机代理，根据实时诊断指标，从多种防御策略中动态选择最优的聚合规则。

**Result:** 实验证明没有单一的静态规则是普遍最优的。FedStrategist自适应代理在多样化场景（包括“Krum友好”环境和针对“隐形”对手）中成功学习到更优的策略。它还能学习保守策略以优先保证模型完整性，即使非鲁棒基线能达到高但受损的准确性。代理的策略可通过单一的“风险容忍度”参数进行控制，允许实践者明确管理性能和安全之间的权衡。

**Conclusion:** FedStrategist提供了一种新颖、实用且可分析的方法来创建有弹性、智能的去中心化AI系统。

> **ai_Abstract:** 本文提出了FedStrategist，一个基于元学习的框架，旨在解决联邦学习中模型中毒攻击的鲁棒聚合问题。它将鲁棒聚合视为一个实时、成本感知的控制问题，并利用一个轻量级上下文多臂老虎机代理，根据实时诊断指标动态选择最佳聚合规则。实验证明，FedStrategist能学习到优于单一静态规则的自适应策略，有效应对不同场景和复杂的隐形攻击，并能通过风险容忍度参数平衡性能与安全，从而构建更具弹性的去中心化AI系统。

> **摘要翻译:** 联邦学习（FL）为隐私保护协作AI提供了一种范式，但其去中心化性质带来了模型中毒攻击的显著漏洞。虽然存在许多静态防御措施，但它们的有效性高度依赖于上下文，在面对自适应对手或异构数据环境时往往失效。本文引入了FedStrategist，一个新颖的元学习框架，将鲁棒聚合重新定义为实时、成本感知的控制问题。我们设计了一个轻量级的上下文多臂老虎机代理，它根据实时诊断指标，从一系列防御措施中动态选择最优的聚合规则。通过全面的实验，我们证明没有单一的静态规则是普遍最优的。我们展示了我们的自适应代理在各种场景中成功学习了更优的策略，包括“Krum友好”环境和针对旨在中和特定诊断信号的复杂“隐形”对手。至关重要的是，我们分析了非鲁棒基线获得高但受损准确性的悖论情景，并证明我们的代理学习了一种保守策略以优先考虑模型完整性。此外，我们证明了代理的策略可以通过单一的“风险容忍度”参数进行控制，允许实践者明确管理性能和安全之间的权衡。我们的工作为创建有弹性、智能的去中心化AI系统提供了一种新的、实用且可分析的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [623] [Can sparse autoencoders make sense of gene expression latent variable models?](https://arxiv.org/abs/2410.11468)
> *稀疏自编码器能否理解基因表达潜在变量模型？*

*Viktoria Schuster* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 稀疏自编码器, 基因表达, 潜在变量模型, 单细胞, 可解释性

**Comment:** 8 pages, 3 figures

> **TL;DR:** 本文探讨了稀疏自编码器（SAE）在解释生物数据嵌入方面的潜力，并通过模拟数据和单细胞模型应用，展示了其提取生物信号的能力，并引入了scFeatureLens工具。

**AI_Comments:** 这项工作具有创新性，因为它将稀疏自编码器在大型语言模型中的成功应用扩展到了生物数据领域，特别是基因表达分析。引入的scFeatureLens工具提高了生物数据解释的自动化程度和可扩展性，对于大规模单细胞基因表达模型分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏自编码器（SAE）已被用于大型语言模型中以发现可解释的潜在特征。本研究的动机是探索SAE在分解复杂和高维生物数据嵌入方面的潜力，以期在基因表达潜在变量模型中实现可解释性。

**Method:** 本研究使用模拟数据来评估SAE在从潜在空间中提取真实生成变量时的有效性、超参数范围和局限性。此外，将SAE应用于预训练单细胞模型的嵌入，并引入了scFeatureLens，这是一种自动化的可解释性方法，用于将SAE特征与基因集中的生物学概念联系起来。

**Result:** 结果表明，SAE在模拟数据上能够有效提取生成变量。在单细胞模型应用中，SAE能够发现和引导关键生物过程，甚至揭示可能被遗漏的微弱生物信号。scFeatureLens的引入使得大规模分析和假设生成成为可能。

**Conclusion:** 稀疏自编码器可以有效地应用于基因表达潜在变量模型，以提高生物数据嵌入的可解释性，并能够发现重要的生物信号。新引入的scFeatureLens工具进一步促进了大规模分析和假设生成。

> **ai_Abstract:** 本文研究了稀疏自编码器（SAE）在解释高维生物数据（特别是基因表达潜在变量模型）嵌入方面的应用。通过模拟数据评估了SAE的性能和局限性，并将其应用于预训练的单细胞模型，结果显示SAE能有效识别关键生物过程和微弱信号。研究还推出了scFeatureLens工具，旨在自动化SAE特征与生物概念的关联，以支持大规模生物分析和假设生成。

> **摘要翻译:** 稀疏自编码器（SAE）最近被用于揭示大型语言模型中可解释的潜在特征。通过将密集嵌入投影到更高维度和稀疏的空间中，学习到的特征变得解耦且更容易解释。这项工作探讨了SAE在分解复杂和高维生物数据嵌入方面的潜力。通过使用模拟数据，它概述了SAE在从潜在空间中提取真实生成变量时的有效性、超参数范围和局限性。应用于预训练单细胞模型的嵌入表明，SAE可以发现并引导关键生物过程，甚至揭示可能被遗漏的微弱生物信号。这项工作还引入了scFeatureLens，这是一种自动化的可解释性方法，用于将SAE特征与基因集中的生物学概念联系起来，从而在单细胞基因表达模型中实现大规模分析和假设生成。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [640] [Enabling Pareto-Stationarity Exploration in Multi-Objective Reinforcement Learning: A Multi-Objective Weighted-Chebyshev Actor-Critic Approach](https://arxiv.org/abs/2507.21397)
> *在多目标强化学习中实现帕累托平稳性探索：一种多目标加权切比雪夫演员-评论家方法*

*Fnu Hairi, Jiao Yang, Tianchen Zhou, Haibo Yang, Chaosheng Dong, Fan Yang, Michinari Momma, Yan Gao, Jia Liu* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 多目标强化学习, 帕累托平稳性, 演员-评论家, 加权切比雪夫, 样本复杂度

**Comment:** 

> **TL;DR:** 本文提出了一种名为 MOCHA 的多目标加权切比雪夫演员-评论家算法，用于在多目标强化学习中系统地探索帕累托平稳解，并提供有限时间样本复杂度保证，在实验中表现优于其他基线方法。

**AI_Comments:** 本文的创新点在于首次将加权切比雪夫方法与演员-评论家框架相结合，以解决多目标强化学习中帕累托平稳性探索的挑战，并提供了理论上的样本复杂度保证。其在实际数据集上的优越表现也突显了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在许多多目标强化学习（MORL）应用中，在多个非凸奖励目标下系统地探索帕累托平稳解并提供理论上的有限时间样本复杂度保证是一个重要但尚未充分探索的问题。本文旨在填补这一重要空白。

**Method:** 本文提出了一种多目标加权切比雪夫演员-评论家（MOCHA）算法。该算法巧妙地将加权切比雪夫（WC）和演员-评论家框架相结合，以系统地实现帕累托平稳性探索，并提供有限时间样本复杂度保证。

**Result:** MOCHA算法的样本复杂度结果揭示了在寻找 $\epsilon$-帕累托平稳解时对 $p_{\min}$ 的有趣依赖性，其中 $p_{\min}$ 表示 WC-标量化中给定权重向量 $\mathbf{p}$ 的最小值。通过仔细选择学习率，每次探索的样本复杂度可以达到 $\tilde{\mathcal{O}}(\epsilon^{-2})$。此外，在大型KuaiRand离线数据集上的模拟研究表明，MOCHA算法的性能显著优于其他基线MORL方法。

**Conclusion:** 本文提出的MOCHA算法成功地在多目标强化学习中实现了帕累托平稳性探索，并提供了理论上的有限时间样本复杂度保证，同时在实际数据集上展示了优越的性能。

> **ai_Abstract:** 本文针对多目标强化学习（MORL）中系统探索帕累托平稳解并提供有限时间样本复杂度保证这一重要且未充分探索的问题，提出了一种名为多目标加权切比雪夫演员-评论家（MOCHA）的算法。MOCHA算法结合了加权切比雪夫和演员-评论家框架，实现了对帕累托平稳解的有效探索。理论分析表明，其样本复杂度可达到 $\tilde{\mathcal{O}}(\epsilon^{-2})$，并依赖于权重向量的最小值。在KuaiRand离线数据集上的实验结果表明，MOCHA算法的性能显著优于现有的基线MORL方法。

> **摘要翻译:** 在许多多目标强化学习（MORL）应用中，能够在多个非凸奖励目标下系统地探索帕累托平稳解并提供理论上的有限时间样本复杂度保证是一个重要但尚未充分探索的问题。这促使我们迈出第一步，填补MORL中的重要空白。具体来说，本文提出了一种多目标加权切比雪夫演员-评论家（MOCHA）算法，用于MORL，它巧妙地将加权切比雪夫（WC）和演员-评论家框架相结合，以系统地实现帕累托平稳性探索，并提供有限时间样本复杂度保证。MOCHA算法的样本复杂度结果揭示了在寻找 $\epsilon$-帕累托平稳解时对 $p_{\min}$ 的有趣依赖性，其中 $p_{\min}$ 表示 WC-标量化中给定权重向量 $\mathbf{p}$ 的最小值。通过仔细选择学习率，每次探索的样本复杂度可以达到 $\tilde{\mathcal{O}}(\epsilon^{-2})$。此外，在大型KuaiRand离线数据集上的模拟研究表明，MOCHA算法的性能显著优于其他基线MORL方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [651] [Generalists vs. Specialists: Evaluating LLMs on Highly-Constrained Biophysical Sequence Optimization Tasks](https://arxiv.org/abs/2410.22296)
> *通用模型 vs. 专用模型：评估大型语言模型在高度受限生物物理序列优化任务中的表现*

*Angelica Chen, Samuel D. Stanton, Frances Ding, Robert G. Alberstein, Andrew M. Watkins, Richard Bonneau, Vladimir Gligorijević, Kyunghyun Cho, Nathan C. Frey* | **Category: cs.LG, q-bio.QM** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 生物物理优化, Ehrlich函数, LLOME, 专用求解器

**Comment:** Supercedes arXiv:2407.00236v1. arXiv admin note: text overlap with
  arXiv:2407.00236

> **TL;DR:** 本研究引入了Ehrlich函数作为合成基准来评估LLM在受限生物物理序列优化中的性能。结果表明，虽然LLM在没有明确奖励的情况下表现不佳，但我们提出的LLOME方法结合偏好学习损失，可以与专用求解器LaMBO-2相媲美甚至超越，尽管专用求解器仍具竞争力且开销更低。

**AI_Comments:** 该论文通过引入Ehrlich函数这一新颖的合成测试套件，为评估LLMs在特定生物物理优化任务中的性能提供了一个有价值的工具。提出的LLOME方法展示了LLMs在结合特定优化策略和偏好学习后，可以有效处理高约束问题，甚至与专用求解器竞争。这表明LLMs在特定领域应用中，通过适当的微调和算法设计，能够克服其固有局限性。然而，论文也指出了LLMs在奖励校准和对明确奖励的依赖性方面的局限，这为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在生物分子优化问题中展现出潜力，但计算成本高昂且难以满足精确约束。另一方面，LaMBO-2等专用求解器效率高且控制精细，但需要更多领域专业知识。由于实验室验证成本高昂和合成基准不足，比较这些方法具有挑战性。

**Method:** 我们引入了Ehrlich函数，一个捕捉生物物理序列优化问题几何结构的合成测试套件。针对开箱即用的LLMs在仅凭提示难以优化Ehrlich函数的问题，我们提出了LLOME（Language Model Optimization with Margin Expectation），一种用于在线黑盒优化的双层优化例程。该方法结合了一种新颖的偏好学习损失。

**Result:** 仅凭提示，开箱即用的LLMs难以优化Ehrlich函数。结合新颖的偏好学习损失后，LLOME不仅能够学习解决一些Ehrlich函数，甚至在适度困难的Ehrlich变体上表现得与LaMBO-2一样好或更好。然而，LLMs也表现出一些可能性-奖励校准不良，并且在没有明确奖励的情况下表现不佳。

**Conclusion:** 我们的结果表明，LLMs偶尔可以提供显著的益处，但专用求解器仍然具有竞争力并且开销更少。

> **ai_Abstract:** 本研究旨在比较通用大型语言模型（LLMs）与专用求解器在高度受限生物物理序列优化任务中的表现。为解决现有基准不足的问题，论文引入了合成测试套件Ehrlich函数。研究发现，开箱即用的LLMs在优化Ehrlich函数时表现不佳。为此，论文提出了LLOME（Language Model Optimization with Margin Expectation），这是一种结合新型偏好学习损失的双层优化方法。实验结果表明，LLOME在部分Ehrlich函数上能与专用求解器LaMBO-2达到相同甚至更好的性能，但LLMs存在似然-奖励校准问题，且依赖明确奖励。总体而言，尽管LLMs有潜力，但专用求解器在效率和成本方面仍具优势。

> **摘要翻译:** 尽管大型语言模型（LLMs）在生物分子优化问题中展现出潜力，但它们会产生高昂的计算成本，并且难以满足精确的约束。另一方面，像LaMBO-2这样的专用求解器提供了效率和细粒度控制，但需要更多的领域专业知识。由于昂贵的实验室验证和不充分的合成基准，比较这些方法具有挑战性。我们通过引入Ehrlich函数来解决这个问题，Ehrlich函数是一个捕获生物物理序列优化问题几何结构的合成测试套件。仅凭提示，开箱即用的LLMs难以优化Ehrlich函数。为此，我们提出了LLOME（Language Model Optimization with Margin Expectation），一种用于在线黑盒优化的双层优化例程。当与一种新颖的偏好学习损失结合时，我们发现LLOME不仅可以学习解决一些Ehrlich函数，甚至在适度困难的Ehrlich变体上表现得与LaMBO-2一样好或更好。然而，LLMs也表现出一些可能性-奖励校准不良，并且在没有明确奖励的情况下表现不佳。我们的结果表明，LLMs偶尔可以提供显著的益处，但专用求解器仍然具有竞争力并且开销更少。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [661] [SQuat: Subspace-orthogonal KV Cache Quantization](https://arxiv.org/abs/2503.24358)
> *SQuat：子空间正交KV缓存量化*

*Hao Wang, Ligong Han, Kai Xu, Akash Srivastava* | **Category: cs.LG, cs.AI, cs.CL, cs.IT, math.IT** | **Updated: 2025-07-28**

**Keywords:** KV缓存量化, 子空间正交, LLM解码, 内存优化, 注意力机制

**Comment:** 

> **TL;DR:** SQuat是一种新型的KV缓存量化方法，通过子空间正交性最小化量化误差，从而显著减少LLM的内存占用并提高吞吐量，无需模型微调或额外校准。

**AI_Comments:** SQuat的创新点在于其独特的子空间正交性约束，有效避免了量化误差的累积，这对于保持LLM生成质量至关重要。其无需微调和校准的特性也大大降低了实际应用的门槛。理论基础的提供增加了方法的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** KV缓存虽然能加速LLM解码，但会增加内存使用。现有KV缓存量化方法存在量化误差累积问题，可能导致输出质量下降。

**Method:** SQuat（子空间正交KV缓存量化）首先构建由查询张量构成的子空间以捕获关键任务信息。在键张量量化时，它强制量化误差与该子空间正交，从而最大限度地减少量化误差对注意力机制输出的影响。该方法无需模型微调，无需额外离线学习校准数据集，并基于其开发的理论框架。

**Result:** 实验结果显示，SQuat将峰值内存减少了2.17到2.82倍，吞吐量提高了2.45到3.60倍，并取得了比现有KV缓存量化算法更优的基准测试分数。

**Conclusion:** SQuat通过引入子空间正交性，有效解决了KV缓存量化中的误差累积问题，在不牺牲模型性能的前提下，显著降低了LLM解码的内存开销并提高了吞吐量，且具有易于部署的优点。

> **ai_Abstract:** 本文提出SQuat，一种子空间正交KV缓存量化方法，旨在解决大型语言模型（LLM）解码过程中KV缓存的内存开销及现有量化方法带来的误差累积问题。SQuat通过构建查询张量子空间，并确保量化误差与该子空间正交，从而最小化对注意力机制输出的影响。该方法无需微调或额外校准数据集，并有理论基础支持。实验结果表明，SQuat显著减少了内存占用并提高了吞吐量，优于现有算法。

> **摘要翻译:** KV缓存通过存储先前生成token的KV张量来加速LLM解码。它以增加内存使用为代价减少了冗余计算。为了减轻这种开销，现有方法将KV张量压缩成低位表示；然而，随着更多token的生成，量化误差可能会累积，可能导致不期望的输出。在本文中，我们引入了SQuat（子空间正交KV缓存量化）。它首先构建一个由查询张量跨越的子空间，以捕获最关键的任务相关信息。在键张量量化过程中，它强制（反）量化键与原始键之间的差异与该子空间保持正交，从而最大限度地减少量化误差对注意力机制输出的影响。SQuat无需模型微调，无需额外的离线学习校准数据集，并且基于我们开发的理论框架。通过数值实验，我们表明我们的方法将峰值内存减少了2.17到2.82倍，吞吐量提高了2.45到3.60倍，并取得了比现有KV缓存量化算法更有利的基准测试分数。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [662] [Bayesian Neural Network Surrogates for Bayesian Optimization of Carbon Capture and Storage Operations](https://arxiv.org/abs/2507.21803)
> *贝叶斯神经网络代理模型用于碳捕获与储存操作的贝叶斯优化*

*Sofianos Panagiotis Fotias, Vassilis Gaganis* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 碳捕获与储存, 贝叶斯优化, 随机模型, 油藏工程, 可持续性

**Comment:** 

> **TL;DR:** 本文研究了使用贝叶斯优化（BO）并比较不同随机模型（包括高斯过程和新颖模型）来优化碳捕获与储存（CCS）项目的决策变量，旨在提高经济可行性和可持续性。

**AI_Comments:** 这项研究的创新之处在于将贝叶斯优化及其替代随机模型（特别是标题中提及的贝叶斯神经网络代理模型，超越传统的高斯过程）首次应用于油藏工程领域的碳捕获与储存操作优化。这对于应对CCS项目中的复杂决策变量和多目标优化挑战具有重要意义，尤其是在确保经济可行性和环境可持续性方面。它为能源行业的可持续发展提供了一种新的优化工具。

<details>
  <summary>Details</summary>

**Motivation:** 碳捕获与储存（CCS）是实现可持续未来的关键技术，但其开发需要优化决策变量。在传统高斯过程（GP）表现不佳的复杂环境下（如决策变量多或多目标函数尺度不一），需要更合适的随机模型来提升贝叶斯优化（BO）的效率和经济可行性。

**Method:** 论文采用无导数技术——贝叶斯优化（BO）来优化CCS项目开发中的决策变量。研究在BO框架内检验并比较了多种新颖的随机模型（包括标题中提到的贝叶斯神经网络代理模型）以及作为BO标准的高斯过程（GP）。通过将净现值（NPV）作为关键目标函数，评估了这些模型的有效性。

**Result:** 提出的框架展示了提高经济可行性并确保CCS技术可持续部署的潜力。这项研究是贝叶斯优化研究，特别是寻找更合适的随机模型在油藏工程行业的首次应用。

**Conclusion:** 该研究表明，贝叶斯优化，特别是探索更合适的随机模型，在油藏工程行业具有巨大潜力，可以作为增强能源领域可持续性的优选方法。

> **ai_Abstract:** 本文探讨了在碳捕获与储存（CCS）操作中使用贝叶斯优化（BO）来优化决策变量，以提升经济可行性和可持续性。研究比较了高斯过程（GP）与其他新颖随机模型在BO框架下的表现，特别是在GP可能表现不佳的复杂场景中。该工作是BO在油藏工程领域的首次应用，强调了其作为能源行业可持续性增强工具的潜力。

> **摘要翻译:** 碳捕获与储存（CCS）是促进可持续未来的关键技术。该过程涉及将超临界二氧化碳注入地下地层，这种方法已广泛应用于提高石油采收率，具有双重目的：它不仅能抑制二氧化碳排放和应对气候变化，还能延长油田和平台的运营寿命和可持续性，从而促进向更环保实践的转变。本文对碳捕获与储存项目开发中决策变量的优化策略进行了彻底的比较评估，采用了一种称为贝叶斯优化的无导数技术。除了通常作为贝叶斯优化黄金标准的高斯过程，还在贝叶斯优化框架内检验和比较了各种新颖的随机模型。本研究调查了在高斯过程表现不佳的环境中（例如决策变量数量众多或多个目标函数尺度不一的情况），使用比高斯过程更奇特的随机模型进行贝叶斯优化的有效性。通过将净现值（NPV）作为关键目标函数，所提出的框架展示了其在提高经济可行性同时确保碳捕获与储存技术可持续部署方面的潜力。最终，这项研究代表了贝叶斯优化研究，特别是寻找更合适的随机模型，在油藏工程行业的首次应用，凸显了其作为提高能源部门可持续性优选方法的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [667] [Exploring Adaptive Structure Learning for Heterophilic Graphs](https://arxiv.org/abs/2507.21191)
> *探索异配图的自适应结构学习*

*Garv Kaushik* | **Category: cs.LG** | **Updated: 2025-07-27**

**Keywords:** 异配图, 结构学习, 图卷积网络, 长距离依赖, 过平滑

**Comment:** Initially submitted this draft at Tiny ICLR 2025

> **TL;DR:** 本文提出了一种自适应结构学习方法，通过重新连接浅层图卷积网络（GCN）中的边，以解决异配图上长距离依赖捕获不足和过平滑问题，尽管其泛化能力和性能存在局限性。

**AI_Comments:** 本文提出了一种新颖的自适应结构学习方法，通过修改图结构来解决异配图上GCNs的局限性，特别是在捕获长距离依赖方面。这种在GCN内部进行结构学习的思路具有创新性。然而，该研究明确指出了其方法的局限性，即泛化能力差和性能不一致，这为未来的研究提供了明确的方向，例如探索更鲁棒的结构学习机制或结合其他技术来提高其通用性。

<details>
  <summary>Details</summary>

**Motivation:** 图卷积网络（GCNs）在异配图上的性能提升是当前关注的焦点，但其局部特征聚合机制阻碍了捕获同类非局部节点之间的长距离依赖。此外，异配图固有的连接结构常常与同类远距离节点之间的信息共享相冲突，导致下游判别任务中出现过平滑和性能下降。

**Method:** 本文提出了一种结构学习方法，通过在浅层GCN中重新连接边来避免过平滑导致的性能下降。具体方法是通过参数化邻接矩阵来学习非局部节点之间的连接，并扩展浅层GCN的跳数范围，以促进长距离依赖的捕获。

**Result:** 该方法有助于捕获长距离依赖。然而，该方法在异配图上不具备泛化性，并且在节点分类任务上的表现会根据图结构而变化，存在不一致性。

**Conclusion:** 本文提出的自适应结构学习方法在一定程度上解决了异配图上长距离依赖捕获的挑战，但其泛化能力和性能稳定性仍有待提高，尤其是在不同图结构上的表现不一致。

> **ai_Abstract:** 本文针对图卷积网络（GCNs）在异配图上捕获长距离依赖和避免过平滑的问题，提出了一种自适应结构学习方法。该方法通过重新连接浅层GCN的边并参数化邻接矩阵，旨在学习非局部节点间的连接并扩展跳数范围，从而有效捕获长距离依赖。尽管该方法在解决特定问题上取得了一定进展，但其在不同异配图上的泛化能力有限，且在节点分类任务上的性能表现不稳定，受图结构影响较大。

> **摘要翻译:** 图卷积网络（GCNs）在图表示学习中获得了关注，近期研究重点在于提高其在各种现实世界应用中处理异配图的性能。典型的消息传递范式中的局部特征聚合阻碍了捕获同类非局部节点之间的长距离依赖。异配图固有的连接结构常常与同类远距离节点之间的信息共享相冲突。我们提出结构学习，以重新连接浅层GCN中的边，从而避免过平滑导致的下游判别任务性能下降。参数化邻接矩阵以学习非局部节点之间的连接并扩展浅层GCN的跳数范围，有助于捕获长距离依赖。然而，我们的方法在异配图上不具备泛化性，并且在节点分类任务上的表现会根据图结构而变化，存在不一致性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [678] [HI-PMK: A Data-Dependent Kernel for Incomplete Heterogeneous Data Representation](https://arxiv.org/abs/2501.04300)
> *HI-PMK：一种用于不完整异构数据表示的数据依赖核*

*Youran Zhou, Mohamed Reda Bouadjenek, Jonathan Wells, Sunil Aryal* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 数据依赖核, 不完整数据, 异构数据, 缺失值处理, 概率质量核

**Comment:** 

> **TL;DR:** HI-PMK是一种新型的、无需插补的数据依赖表示学习方法，用于处理不完整和异构数据，通过概率质量差异度量和缺失感知不确定性策略，在多项基准数据集上表现优于传统方法。

**AI_Comments:** HI-PMK的创新之处在于其无需插补的策略，通过直接处理缺失数据和异构特征，避免了传统插补方法可能引入的偏差和隐私风险。其概率质量差异度量和MaxU策略是核心创新点，使得该方法在复杂现实数据场景中具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在现实世界的机器学习中，处理不完整和异构数据仍然是一个核心挑战。现有方法通常依赖于插补，这可能引入偏差或隐私风险，或者未能同时解决数据异构性和结构化缺失问题。

**Method:** 本研究提出了异构不完整概率质量核（HI-PMK），这是一种新颖的数据依赖表示学习方法，无需进行数据插补。HI-PMK引入了两项关键创新：1) 一种基于概率质量的差异度量，能够适应异构特征（数值、有序、名义）的局部数据分布；2) 一种缺失感知不确定性策略（MaxU），通过为未观测条目分配最大合理差异度，保守地处理所有三种缺失机制（MCAR、MAR、MNAR）。

**Result:** 在超过15个基准数据集上进行的广泛实验表明，HI-PMK在各种缺失数据设置下，始终优于传统的基于插补的流程和核方法。

**Conclusion:** HI-PMK是一种保护隐私、可扩展且易于应用于分类和聚类等下游任务的方法，能够有效解决不完整异构数据的表示问题。

> **ai_Abstract:** HI-PMK是一种新型的数据依赖核方法，旨在解决机器学习中不完整和异构数据的表示挑战，而无需进行数据插补。它通过引入基于概率质量的差异度量来适应局部数据分布，并采用缺失感知不确定性策略（MaxU）保守地处理各种缺失机制。实验证明，HI-PMK在处理缺失数据方面优于传统的插补和核方法，并且具有隐私保护、可扩展性和广泛适用性。

> **摘要翻译:** 处理不完整和异构数据仍然是现实世界机器学习中的一个核心挑战，其中缺失值可能遵循复杂的机制（MCAR、MAR、MNAR），且特征可以是混合类型（数值和分类）。现有方法通常依赖于插补，这可能引入偏差或隐私风险，或者未能同时解决数据异构性和结构化缺失问题。我们提出了异构不完整概率质量核（HI-PMK），这是一种新颖的数据依赖表示学习方法，无需进行插补。HI-PMK引入了两项关键创新：(1) 一种基于概率质量的差异度量，能够适应异构特征（数值、有序、名义）的局部数据分布；(2) 一种缺失感知不确定性策略（MaxU），通过为未观测条目分配最大合理差异度，保守地处理所有三种缺失机制。我们的方法是保护隐私、可扩展的，并且易于应用于分类和聚类等下游任务。在超过15个基准数据集上进行的广泛实验表明，HI-PMK在各种缺失数据设置下始终优于传统的基于插补的流程和核方法。代码可在以下网址获取：https://github.com/echoid/Incomplete-Heter-Kernel

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [704] [Data Leakage and Redundancy in the LIT-PCBA Benchmark](https://arxiv.org/abs/2507.21404)
> *LIT-PCBA基准测试中的数据泄露和冗余*

*Amber Huang, Ian Scott Knight, Slava Naprienko* | **Category: cs.LG, q-bio.QM** | **Updated: 2025-07-29**

**Keywords:** 数据泄露, 数据冗余, 虚拟筛选, 基准测试, LIT-PCBA

**Comment:** 

> **TL;DR:** LIT-PCBA虚拟筛选基准测试存在严重的数据泄露和冗余问题，导致模型过拟合而非泛化，甚至一个简单的记忆基线模型就能超越最先进的模型，因此该基准测试不适用于其预期目的。

**AI_Comments:** 这篇论文揭示了广泛使用的LIT-PCBA基准测试中存在的严重数据完整性问题，其创新之处在于通过详细的数据审计和设计一个简单的记忆基线模型，有力地证明了这些缺陷对模型评估的负面影响。它强调了在机器学习领域，特别是药物发现等关键应用中，高质量和无偏见的数据集的重要性。这项工作对整个计算化学和虚拟筛选社区具有重要意义，提醒研究人员在选择和使用基准测试时需谨慎，并呼吁开发更严谨的数据集。

<details>
  <summary>Details</summary>

**Motivation:** LIT-PCBA是一个广泛使用的虚拟筛选基准测试，但作者的审计发现它存在根本性缺陷，这些缺陷使其不适用于公平的模型评估。

**Method:** 作者通过审计LIT-PCBA数据集，揭示了数据泄露、重复和模拟冗余问题。他们具体识别了训练集和验证集中的重复不活跃分子、数据分割内部的重复，以及查询集中的泄露配体。此外，他们还分析了结构冗余，并实现了一个简单的基于记忆的基线模型，该模型没有学习、物理或建模，仅通过利用这些缺陷就超越了最先进的模型。

**Result:** LIT-PCBA数据集存在严重的数据泄露、重复和普遍的模拟冗余；训练集和验证集中有2,491个重复的不活跃分子，在单个数据分割内部还有数千个重复；查询集中的三个配体被泄露；对于某些目标，超过80%的查询配体是近似重复；仅在ALDH1中，训练集和验证集之间发现323对高度相似的活性分子；一个简单的基于记忆的基线模型通过利用这些缺陷，在LIT-PCBA上超越了包括CHEESE等深度神经网络在内的最先进模型。

**Conclusion:** LIT-PCBA基准测试不适用于其预期目的，并使基于其使用的先前结果受到质疑。作者分享了这项审计，旨在提高社区对数据完整性的认识，并提供工具以帮助开发更严谨和可靠的数据集。

> **ai_Abstract:** 本文对广泛使用的虚拟筛选基准LIT-PCBA进行了审计，揭示了该数据集存在严重的数据泄露、重复和模拟冗余问题。研究发现，训练集与验证集之间存在大量重复数据，查询集中的测试案例也发生了泄露，且存在高度结构冗余。这些缺陷导致基于LIT-PCBA训练的模型倾向于记忆而非泛化。作者通过一个简单的无学习记忆基线模型，证明了其性能超越了现有最先进的模型，从而证实LIT-PCBA不适用于其预期目的，并质疑了此前基于该基准的研究结果。

> **摘要翻译:** LIT-PCBA是一个广泛使用的虚拟筛选基准测试，但我们的审计显示其存在根本性缺陷。该数据集遭受着严重的数据泄露、普遍的重复和广泛的模拟冗余——这些缺陷使其无法用于公平的模型评估。值得注意的是，我们发现训练集和验证集中有2,491个不活跃分子重复，在单个数据分割内部还有数千个重复（训练集中2,945个，验证集中789个）。关键的是，查询集中的三个配体——旨在代表未见的测试案例——被泄露：两个出现在训练集中，一个在验证集中。结构冗余加剧了这些问题：对于某些目标，超过80%的查询配体是近似重复，Tanimoto相似度大于等于0.9。仅在ALDH1中，我们发现在训练集和验证集之间有323对高度相似的活性分子，这使得化学多样性的说法失效。这些以及其他缺陷共同导致在LIT-PCBA上训练的模型倾向于记忆而非泛化。为了证明这些数据完整性失败的后果，我们实现了一个简单的基于记忆的基线模型——不使用学习、物理和建模——该模型仅仅通过利用这些伪影，就在LIT-PCBA上超越了包括CHEESE等深度神经网络在内的最先进模型。我们的发现表明该基准测试不适用于其预期目的，并对基于其使用的先前结果提出了质疑。我们分享这项审计旨在提高认识，并提供工具以帮助社区未来开发更严谨和可靠的数据集。所有重现我们审计和基线实现所需的脚本均可在以下网址获取：https://github.com/sievestack/LIT-PCBA-audit

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [707] [Wavelet Meets Adam: Compressing Gradients for Memory-Efficient Training](https://arxiv.org/abs/2501.07237)
> *小波遇上Adam：压缩梯度以实现内存高效训练*

*Ziqing Wen, Ping Luo, Jiahuan Wang, Xiaoge Deng, Jinping Zou, Kun Yuan, Tao Sun, Dongsheng Li* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 小波变换, Adam, 梯度压缩, 内存高效训练, 大型语言模型

**Comment:** 

> **TL;DR:** 本文提出梯度小波变换（GWT）来压缩Adam等优化器的梯度，显著减少LLM训练时的内存占用，同时保持甚至超越现有方法的性能。

**AI_Comments:** 本文的创新点在于将小波变换引入梯度压缩，为Adam等优化器提供了一种新颖且高效的内存优化方案。它解决了现有内存高效方法可能导致性能下降的痛点，通过实验证明了在保持甚至超越性能的同时，显著降低了内存需求，对于推动大型模型训练的可行性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）参数量巨大，导致训练时内存消耗高，尤其在使用Adam等内存密集型优化器时。现有内存高效算法（如奇异值分解投影或权重冻结）通常会导致次优结果。

**Method:** 提出了一种名为梯度小波变换（GWT）的新型解决方案，通过对梯度应用小波变换来显著减少维护优化器状态所需的内存。GWT可以无缝集成到内存密集型优化器中。

**Result:** GWT在预训练和微调任务上进行了广泛实验，结果表明它在内存使用和训练性能方面均优于先进的内存高效优化器和全秩方法，达到了最先进的性能。

**Conclusion:** 梯度小波变换（GWT）是一种有效且高效的方法，可以显著减少大型语言模型训练中优化器的内存需求，同时保持甚至提升训练性能，解决了现有内存高效方案的局限性。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）训练中Adam等优化器带来的高内存消耗问题，提出了一种名为梯度小波变换（GWT）的新方法。GWT通过对梯度进行小波变换来大幅压缩优化器状态所需的内存，并能与现有优化器无缝集成。实验证明，GWT在内存效率和训练性能上均达到或超越了当前最先进的内存高效方法和全秩更新，为LLM的内存高效训练提供了有效解决方案。

> **摘要翻译:** 大型语言模型（LLMs）在各种自然语言处理任务中展现出令人印象深刻的性能。然而，其庞大的参数量在训练过程中带来了显著的内存挑战，尤其是在使用Adam等内存密集型优化器时。现有的内存高效算法通常依赖于奇异值分解投影或权重冻结等技术。尽管这些方法有助于缓解内存限制，但与全秩更新相比，它们通常会产生次优结果。在本文中，我们研究了超越低秩训练的内存高效方法，提出了一种名为梯度小波变换（GWT）的新型解决方案，它将小波变换应用于梯度，以显著减少维护优化器状态所需的内存。我们证明了GWT可以与内存密集型优化器无缝集成，从而在不牺牲性能的情况下实现高效训练。通过在预训练和微调任务上进行大量实验，我们表明GWT在内存使用和训练性能方面均优于先进的内存高效优化器和全秩方法，达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [719] [Analysis of Fourier Neural Operators via Effective Field Theory](https://arxiv.org/abs/2507.21833)
> *通过有效场理论分析傅里叶神经算子*

*Taeyoung Kim* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 傅里叶神经算子, 有效场理论, 频率行为, 非线性激活, 临界条件

**Comment:** 37 pages, 10 figures

> **TL;DR:** 本文首次通过系统性的有效场理论分析了傅里叶神经算子（FNOs），解释了其稳定性、泛化能力和频率行为，并提供了超参数选择的准则。

**AI_Comments:** 本文通过引入有效场理论，为傅里叶神经算子（FNOs）的内部机制提供了一个新颖且深入的理论框架。其创新之处在于将物理学中的场论方法应用于神经网络分析，这为理解FNOs的频率行为和非线性特性提供了独特的视角。这项工作不仅解释了现有现象，还为模型设计和超参数优化提供了指导，对于推动FNOs在科学计算领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 傅里叶神经算子（FNOs）已成为高维偏微分方程的领先替代模型，但其稳定性、泛化能力和频率行为缺乏原理性解释。

**Method:** 本文首次在无限维函数空间中对FNOs进行了系统性的有效场理论分析，推导了层核和四点顶点的封闭递归关系，并检查了三种重要的实际设置：解析激活、尺度不变情况和带有残差连接的架构。

**Result:** 理论表明非线性激活不可避免地将频率输入耦合到高频模式，并通过实验证实了这种频率转移。对于宽网络，获得了权重初始化集合上的显式临界条件，使小输入扰动在深度上保持均匀尺度，并通过实证测试验证了这些预测。

**Conclusion:** 研究结果量化了非线性如何使神经算子能够捕获非平凡特征，通过临界分析提供了超参数选择的标准，并解释了为什么尺度不变激活和残差连接能增强FNOs中的特征学习。

> **ai_Abstract:** 本文首次运用有效场理论对傅里叶神经算子（FNOs）进行了系统性分析，旨在解释其稳定性、泛化能力和频率行为。研究推导了层核和四点顶点的递归关系，并探讨了非线性激活、尺度不变性和残差连接的影响。结果表明非线性激活导致频率转移，并为宽网络提供了保持扰动尺度的临界条件。这些发现有助于理解FNOs捕获特征的能力，并为超参数选择提供了理论依据。

> **摘要翻译:** 傅里叶神经算子（FNOs）已成为高维偏微分方程的领先替代模型，但其稳定性、泛化能力和频率行为缺乏原理性解释。我们首次在无限维函数空间中对FNOs进行了系统性的有效场理论分析，推导了层核和四点顶点的封闭递归关系，然后检查了三种重要的实际设置——解析激活、尺度不变情况和带有残差连接的架构。该理论表明非线性激活不可避免地将频率输入耦合到高频模式，这些模式否则会被频谱截断丢弃，并且实验证实了这种频率转移。对于宽网络，我们获得了权重初始化集合上的显式临界条件，使小输入扰动在深度上保持均匀尺度，并且经验测试验证了这些预测。总而言之，我们的结果量化了非线性如何使神经算子能够捕获非平凡特征，通过临界分析提供了超参数选择的准则，并解释了为什么尺度不变激活和残差连接能增强FNOs中的特征学习。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [720] [Utilizing Evolution Strategies to Train Transformers in Reinforcement Learning](https://arxiv.org/abs/2501.13883)
> *利用进化策略训练强化学习中的Transformer*

*Matyáš Lorenc, Roman Neruda* | **Category: cs.LG, cs.NE** | **Updated: 2025-07-30**

**Keywords:** 进化策略, Transformer, 强化学习, Decision Transformer, 黑盒优化

**Comment:** 

> **TL;DR:** 本文探讨了使用进化策略在强化学习环境中训练基于Transformer架构的智能体，并证明其能有效训练复杂模型。

**AI_Comments:** 本文的创新之处在于其将进化策略应用于训练强化学习中的Transformer模型，特别是像Decision Transformer这样相对复杂和大型的模型。这对于探索黑盒优化技术在深度学习模型训练中的潜力具有重要意义，尤其是在传统梯度方法可能面临挑战的场景。

<details>
  <summary>Details</summary>

**Motivation:** 探索进化策略训练强化学习中基于Transformer架构智能体的能力，特别是对于相对较大和复杂的模型。

**Method:** 使用OpenAI的高度并行化进化策略，在MuJoCo Humanoid运动环境和Atari游戏环境中训练Decision Transformer，以测试这种黑盒优化技术的能力。

**Result:** 所检验的进化策略总体上能够取得良好结果，并成功生成了高性能智能体。

**Conclusion:** 进化策略能够应对复杂模型的训练。

> **ai_Abstract:** 本文研究了进化策略在强化学习中训练基于Transformer架构智能体的有效性。研究人员利用OpenAI的并行进化策略，在MuJoCo Humanoid和Atari游戏环境中训练了Decision Transformer。实验结果表明，进化策略能够成功训练这些相对复杂的大型模型，并产生高性能的智能体，证实了其处理复杂模型训练的能力。

> **摘要翻译:** 我们探索了进化策略在强化学习环境中训练基于Transformer架构的智能体的能力。我们使用OpenAI高度并行化的进化策略在MuJoCo Humanoid运动环境和Atari游戏环境中训练Decision Transformer，测试了这种黑盒优化技术训练相对较大和复杂模型（与文献中先前测试的模型相比）的能力。所检验的进化策略总体上证明能够取得良好结果，并成功生成了高性能智能体，展示了进化策略处理此类复杂模型训练的能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [735] [A Survey on Memory-Efficient Transformer-Based Model Training in AI for Science](https://arxiv.org/abs/2501.11847)
> *AI科学领域中内存高效Transformer模型训练综述*

*Kaiyuan Tian, Linbo Qiao, Baihui Liu, Gongqingjian Jiang, Shanshan Li, Dongsheng Li* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 内存高效, Transformer, 大型语言模型, AI科学, 预训练技术

**Comment:** The article has been accepted by Frontiers of Computer Science (FCS),
  with the DOI: {10.1007/s11704-025-50302-6}

> **TL;DR:** 本综述回顾了Transformer模型在科学领域的应用，并系统地分类和分析了内存高效的预训练技术，旨在为AI科学中可扩展、经济高效的LLM训练提供见解。

**AI_Comments:** 这篇综述及时地解决了大型语言模型在科学应用中面临的关键内存效率问题。其系统性的分类方法（算法级、系统级、软硬件协同优化）为研究人员提供了一个清晰的框架。以AlphaFold 2为例的实证说明增强了文章的实用性。该工作对于推动AI在科学领域的实际应用具有重要意义，尤其是在资源受限的环境下。

<details>
  <summary>Details</summary>

**Motivation:** 科学研究中传统方法成本高且效率低下，深度学习和大型语言模型（LLMs）提供了创新解决方案。然而，模型规模的持续扩大导致了显著的内存需求，阻碍了LLMs在科学领域进一步发展和应用。

**Method:** 本综述系统地回顾和分类了针对大规模Transformer的内存高效预训练技术，包括算法级、系统级以及软硬件协同优化。

**Result:** 以AlphaFold 2为例，本综述展示了定制的内存优化方法如何在保持预测准确性的同时减少存储需求。

**Conclusion:** 通过连接模型效率和科学应用需求，本综述希望为AI科学中可扩展、经济高效的LLM训练提供见解。

> **ai_Abstract:** 本综述探讨了Transformer-based大型语言模型在生物、医学、化学和气象等科学领域的应用及其面临的内存挑战。文章系统回顾了算法级、系统级和软硬件协同优化的内存高效预训练技术，并通过AlphaFold 2案例展示了内存优化在保持准确性前提下降低存储需求的可行性，旨在为AI科学中可扩展且经济高效的LLM训练提供方向。

> **摘要翻译:** 科学研究面临传统方法的高成本和低效率，但深度学习和大型语言模型（LLMs）的兴起提供了创新的解决方案。本综述回顾了Transformer-based LLM在生物学、医学、化学和气象学等科学领域的应用，强调了它们在推动研究方面的作用。然而，模型规模的持续扩大导致了显著的内存需求，阻碍了LLMs在科学领域进一步发展和应用。本综述系统地回顾和分类了针对大规模Transformer的内存高效预训练技术，包括算法级、系统级以及软硬件协同优化。以AlphaFold 2为例，我们展示了定制的内存优化方法如何在保持预测准确性的同时减少存储需求。通过连接模型效率和科学应用需求，我们希望为AI科学中可扩展、经济高效的LLM训练提供见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [738] [EdgeAgentX-DT: Integrating Digital Twins and Generative AI for Resilient Edge Intelligence in Tactical Networks](https://arxiv.org/abs/2507.21196)
> *EdgeAgentX-DT：集成数字孪生与生成式AI以实现战术网络中弹性边缘智能*

*Abir Ray* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 数字孪生, 生成式AI, 边缘智能, 战术网络, 韧性

**Comment:** 13 pages, 6 figures

> **TL;DR:** EdgeAgentX-DT通过结合数字孪生仿真和生成式AI训练，显著提升了军事网络中的边缘智能，并在对抗环境中展现出更快的学习速度、更高的吞吐量、更低的延迟和更强的韧性。

**AI_Comments:** 该论文的创新点在于将数字孪生与生成式AI（特别是扩散模型和Transformer）结合，为战术网络中的边缘智能提供了强大的训练和验证机制。其重要性体现在解决了军事网络在复杂对抗环境下对韧性、性能和快速适应能力的需求。通过创建逼真的虚拟训练环境和多样化的对抗场景，EdgeAgentX-DT显著提升了边缘AI的可靠性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过整合数字孪生仿真和生成式AI驱动的场景训练，显著增强军事网络中的边缘智能，尤其是在对抗环境下。

**Method:** EdgeAgentX-DT是EdgeAgentX框架的扩展，它利用网络数字孪生作为与真实边缘设备同步的虚拟副本，提供安全、真实的训练和验证环境。系统利用扩散模型和Transformer等生成式AI方法，创建多样化和对抗性的场景，用于基于仿真的智能体训练。其多层架构包括：(1) 设备上的边缘智能；(2) 数字孪生同步；(3) 生成式场景训练。

**Result:** 实验仿真表明，EdgeAgentX-DT相较于EdgeAgentX有显著改进，包括更快的学习收敛速度、更高的网络吞吐量、更低的延迟以及对干扰和节点故障更强的韧性。一个涉及同时发生干扰攻击、智能体故障和网络负载增加的复杂战术场景案例研究表明，EdgeAgentX-DT能够维持运行性能，而基线方法则失败。

**Conclusion:** 这些结果强调了数字孪生赋能的生成式训练在加强对抗环境中的边缘AI部署方面的潜力。

> **ai_Abstract:** EdgeAgentX-DT是一个结合了数字孪生和生成式AI的先进框架，旨在提升军事网络中的边缘智能。它通过网络数字孪生提供安全的训练环境，并利用生成式AI创建多样化的对抗场景进行智能体训练。实验证明，EdgeAgentX-DT在学习收敛、网络吞吐量、延迟和韧性方面均优于现有框架，尤其在复杂战术场景下表现出卓越的性能，证明了数字孪生与生成式训练在对抗环境中部署边缘AI的巨大潜力。

> **摘要翻译:** 我们引入了EdgeAgentX-DT，它是EdgeAgentX框架的先进扩展，集成了数字孪生仿真和生成式AI驱动的场景训练，以显著增强军事网络中的边缘智能。EdgeAgentX-DT利用网络数字孪生（与真实边缘设备同步的虚拟副本），提供一个安全、真实的训练和验证环境。系统利用生成式AI方法，如扩散模型和Transformer，创建多样化和对抗性的场景，用于稳健的基于仿真的智能体训练。我们的多层架构包括：(1) 设备上的边缘智能；(2) 数字孪生同步；(3) 生成式场景训练。实验仿真表明，EdgeAgentX-DT相较于EdgeAgentX有显著改进，包括更快的学习收敛速度、更高的网络吞吐量、更低的延迟以及对干扰和节点故障更强的韧性。一个涉及同时发生干扰攻击、智能体故障和网络负载增加的复杂战术场景案例研究表明，EdgeAgentX-DT能够维持运行性能，而基线方法则失败。这些结果强调了数字孪生赋能的生成式训练在加强对抗环境中的边缘AI部署方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [744] [Task-Focused Consolidation with Spaced Recall: Making Neural Networks learn like college students](https://arxiv.org/abs/2507.21109)
> *以任务为中心的巩固与间隔回忆：让神经网络像大学生一样学习*

*Prital Bamnodkar* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 持续学习, 灾难性遗忘, 主动回忆, 间隔重复, 神经网络

**Comment:** 

> **TL;DR:** 本文提出了一种名为TFC-SR的新型持续学习方法，灵感来自人类学习策略，旨在解决神经网络中的灾难性遗忘问题。TFC-SR通过引入主动回忆探测机制，显著优于现有基线方法，尤其在内存受限环境下表现更佳，强调了主动记忆检索的重要性。

**AI_Comments:** TFC-SR的创新之处在于将人类学习中的“主动回忆”和“间隔重复”概念引入到持续学习的经验回放机制中，通过周期性的“主动回忆探测”有效稳定了旧知识的表示，从而显著缓解了灾难性遗忘。其重要性在于提供了一种更高效、更仿生学的持续学习范式，尤其在内存受限场景下具有实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络常常遭受灾难性遗忘的严重限制，即在学习新任务后，对过去任务的性能会下降。

**Method:** 本文引入了一种名为“以任务为中心的巩固与间隔回忆”（TFC-SR）的新型持续学习方法，其灵感来源于人类学习策略，如主动回忆、刻意练习和间隔重复。TFC-SR通过引入“主动回忆探测”机制来增强标准的经验回放，该机制对模型的记忆进行周期性的、任务感知的评估，以稳定过去知识的表示。

**Result:** TFC-SR在Split MNIST和Split CIFAR-100基准测试中表现显著优于领先的基于正则化和基于回放的基线方法。例如，在Split CIFAR-100上，TFC-SR的最终准确率达到13.17%，而标准回放为7.40%。研究表明，这种优势来自探测本身稳定作用，而非回放量的差异。此外，TFC-SR在内存受限环境下表现更佳，但在内存充足时，更高的回放量仍然更有效。

**Conclusion:** TFC-SR是一种鲁棒且高效的方法，它强调了将主动记忆检索机制整合到持续学习系统中的重要性。

> **ai_Abstract:** 本文提出了一种名为“以任务为中心的巩固与间隔回忆”（TFC-SR）的新型持续学习方法，旨在解决深度神经网络中的灾难性遗忘问题。该方法受到人类学习策略的启发，通过引入“主动回忆探测”机制来增强经验回放，以周期性地稳定模型对过去知识的表示。实验结果表明，TFC-SR在Split MNIST和Split CIFAR-100基准测试中显著优于现有基线方法，尤其在内存受限环境下表现突出。研究强调了将主动记忆检索机制整合到持续学习系统中的重要性。

> **摘要翻译:** 深度神经网络经常遭受灾难性遗忘的严重限制，即在学习新任务后，对过去任务的性能会下降。本文介绍了一种受人类学习策略（如主动回忆、刻意练习和间隔重复）启发的新型持续学习方法，命名为“以任务为中心的巩固与间隔回忆”（TFC-SR）。TFC-SR通过我们称之为“主动回忆探测”的机制增强了标准的经验回放。这是一种周期性的、任务感知的模型记忆评估，可以稳定过去知识的表示。我们在Split MNIST和Split CIFAR-100基准测试中，将TFC-SR与领先的基于正则化和基于回放的基线方法进行了比较。我们的结果表明，TFC-SR的表现明显优于这些方法。例如，在Split CIFAR-100上，它实现了13.17%的最终准确率，而标准回放的准确率为7.40%。我们证明了这种优势来自于探测本身的稳定作用，而不是回放量的差异。此外，我们分析了内存大小和性能之间的权衡，并表明虽然TFC-SR在内存受限的环境中表现更好，但在可用内存充足时，更高的回放量仍然更有效。我们得出结论，TFC-SR是一种鲁棒且高效的方法，强调了将主动记忆检索机制整合到持续学习系统中的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [756] [PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN](https://arxiv.org/abs/2502.12207)
> *PAR-AdvGAN：通过渐进式自回归AdvGAN提升对抗攻击能力*

*Jiayu Zhang, Zhiyu Zhu, Xinyi Wang, Silin Liao, Zhibo Jin, Flora D. Salim, Huaming Chen* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 对抗攻击, GAN, 自回归, 黑盒攻击, 对抗样本

**Comment:** Best paper award of ECML-PKDD 2025

> **TL;DR:** PAR-AdvGAN通过引入渐进式自回归机制，显著提升了对抗样本的攻击能力和生成速度。

**AI_Comments:** PAR-AdvGAN的创新点在于将自回归迭代机制引入到对抗样本生成中，这使得它能够更充分地利用生成网络的潜力，从而生成更具攻击性的对抗样本。其在生成速度上的显著提升也极具重要性，为实际应用提供了可能。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络易受对抗样本攻击，而现有基于GAN的方法（如AdvGAN）在生成对抗扰动时通常限于单次迭代，未能充分发挥其潜力。

**Method:** 本文提出了一种名为渐进式自回归AdvGAN（PAR-AdvGAN）的新方法。它在渐进式生成网络中融入了自回归迭代机制，以生成具有增强攻击能力的对抗样本。

**Result:** PAR-AdvGAN在大型实验中表现出优于现有最先进的黑盒对抗攻击方法以及原始AdvGAN的性能。此外，PAR-AdvGAN显著加速了对抗样本的生成，在Inception-v3模型上速度高达335.5帧/秒，超越了基于梯度的可转移攻击算法。

**Conclusion:** PAR-AdvGAN通过结合渐进式生成和自回归迭代机制，有效提升了对抗攻击能力和生成效率，是目前最先进的黑盒对抗攻击方法之一。

> **ai_Abstract:** 该论文提出了一种名为PAR-AdvGAN的新型生成对抗网络，旨在解决现有GANs在生成对抗样本时单次迭代的局限性。PAR-AdvGAN通过引入渐进式自回归迭代机制，显著提升了对抗样本的攻击能力和生成效率。实验结果表明，PAR-AdvGAN在黑盒攻击方面优于多种最先进的方法和原始AdvGAN，并实现了更快的生成速度。

> **摘要翻译:** 深度神经网络在各个领域都表现出卓越的性能。然而，它们容易受到对抗样本的攻击，这可能导致错误的预测。生成对抗网络（GANs）可以利用生成器和判别器模型快速生成高质量的对抗样本。由于两个模块以竞争和同步的方式训练，基于GAN的算法如AdvGAN与传统方法相比，可以生成具有更好可转移性的对抗样本。然而，扰动的生成通常限于单次迭代，这使得这些样本无法充分利用方法的潜力。为了解决这个问题，我们引入了一种名为渐进式自回归AdvGAN（PAR-AdvGAN）的新方法。它在渐进式生成网络中融入了自回归迭代机制，以生成具有增强攻击能力的对抗样本。我们通过大规模实验彻底评估了我们的PAR-AdvGAN方法，证明了其优于各种最先进的黑盒对抗攻击以及原始AdvGAN的卓越性能。此外，PAR-AdvGAN显著加速了对抗样本的生成，即在Inception-v3模型上达到高达335.5帧每秒的速度，优于基于梯度的可转移攻击算法。我们的代码可在以下网址获取：https://github.com/LMBTough/PAR

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [767] [Torque-based Graph Surgery:Enhancing Graph Neural Networks with Hierarchical Rewiring](https://arxiv.org/abs/2507.21422)
> *基于扭矩的图手术：通过分层重连接增强图神经网络*

*Sujia Huang, Lele Fu, Zhen Cui, Tong Zhang, Na Song, Bo Huang* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 图神经网络, 图重连接, 扭矩, 异质图, 噪声图

**Comment:** 

> **TL;DR:** 本文提出了一种受经典力学中扭矩概念启发的扭矩驱动分层重连接策略，用于动态调制消息传递，以改善异质图上的表示学习并增强对噪声图的鲁棒性，并在基准数据集上超越了现有最先进方法。

**AI_Comments:** 这项工作通过引入基于经典力学扭矩概念的图重连接策略，为图神经网络的图结构优化提供了一个新颖的视角。其创新点在于将物理概念转化为图结构优化的量化度量，并通过分层重连接有效解决了异质图和噪声图上的GNN性能瓶颈。该方法不仅提高了模型在复杂图结构上的表示学习能力，也增强了其鲁棒性，对图学习领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图神经网络（GNNs）在处理图结构数据时，其原生图中的交互可能不利于消息传递过程，这促使了图重连接方法的发展。

**Method:** 本文提出了一种扭矩驱动的分层重连接策略。该策略受经典力学中扭矩概念的启发，旨在动态调整消息传递。具体而言，定义了一个干扰感知扭矩度量，该度量结合了结构距离和能量分数来量化边引起的扰动，鼓励每个节点从最近的低能量邻居聚合信息。利用该度量，通过审慎地修剪高扭矩边和添加低扭矩链接，分层重新配置每一层的感受野，从而抑制传播噪声并增强相关信号。

**Result:** 在基准数据集上的广泛评估表明，该方法在异质图和同质图上均超越了现有最先进方法，并在噪声图上保持了高准确性。

**Conclusion:** 本文提出的扭矩驱动分层重连接策略能有效改善图神经网络在异质图上的表示学习并增强对噪声图的鲁棒性，在多种图类型上均表现出色。

> **ai_Abstract:** 本文提出了一种名为“扭矩驱动分层重连接”的新型图重连接策略，旨在解决图神经网络（GNNs）在处理原生图结构时面临的挑战，尤其是在异质图和噪声图上。该方法引入了一个干扰感知扭矩度量，结合结构距离和能量分数来识别并优化图连接，通过剪枝高扭矩边和添加低扭矩边来动态调整消息传递。实验结果表明，该方法在多种图类型上均优于现有最先进技术，并显著提升了GNN的性能和鲁棒性。

> **摘要翻译:** 图神经网络（GNNs）已成为从图结构数据中学习的强大工具，它利用消息传递来传播信息和更新节点表示。然而，大多数研究表明，图中编码的原始交互可能不利于这一过程，这促使了图重连接方法的发展。在这项工作中，我们提出了一种扭矩驱动的分层重连接策略，该策略受经典力学中扭矩概念的启发，动态调制消息传递，以改善异质图中的表示学习并增强对噪声图的鲁棒性。具体而言，我们定义了一个干扰感知扭矩度量，该度量结合了结构距离和能量分数来量化边引起的扰动，从而鼓励每个节点从其最近的低能量邻居聚合信息。我们使用该度量通过审慎地修剪高扭矩边和添加低扭矩链接来分层重新配置每一层的感受野，抑制传播噪声并增强相关信号。在基准数据集上的广泛评估表明，我们的方法在异质图和同质图上均超越了现有最先进方法，并在噪声图上保持了高准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [775] [Discovering Interpretable Ordinary Differential Equations from Noisy Data](https://arxiv.org/abs/2507.21841)
> *从噪声数据中发现可解释的常微分方程*

*Rahul Golder, M. M. Faruque Hasan* | **Category: cs.LG, physics.comp-ph** | **Updated: 2025-07-29**

**Keywords:** 可解释常微分方程, 噪声数据, 数据驱动发现, 样条变换, 无监督估计

**Comment:** 20 pages, 11 figures, 7 tables

> **TL;DR:** 本文提出了一种无监督参数估计方法，通过近似通解和样条变换从噪声数据中发现具有高精度和稀疏性的可解释常微分方程，无需正则化。

**AI_Comments:** 该论文提出了一种新颖的无监督参数估计方法，用于从噪声数据中发现可解释的ODE。其创新之处在于结合了近似通解的假设和样条变换，以线性方式估计ODE系数，并且能够在没有正则化的情况下实现稀疏性。该方法对噪声数据的鲁棒性使其在实际实验设置中具有重要应用潜力，克服了现有方法在可解释性和物理意义上的不足。

<details>
  <summary>Details</summary>

**Motivation:** 过去十年中，数据驱动的物理系统动力学可解释模型发现受到了关注。然而，现有方法通常使用预设函数形式或基函数，导致模型缺乏物理意义和可解释性，也无法代表系统的真实物理特性。

**Method:** 提出了一种无监督参数估计方法。首先找到一个近似的通解，其函数形式与一般齐次、线性、常系数ODE的解析解相同。然后，通过样条变换线性估计控制常微分方程（ODE）的系数。样条逼近从函数形式中获取梯度信息，这些信息是线性独立的，并构成梯度矩阵的基础。该梯度矩阵用于线性系统中以找到ODE的系数。

**Result:** 通过案例研究发现，该建模方法能够高精度地发现ODE，并在不使用任何正则化技术的情况下促进解的稀疏性。该方法对噪声数据也具有鲁棒性。

**Conclusion:** 该方法对噪声数据具有鲁棒性，从而允许将数据驱动技术整合到真实的实验设置中，以进行物理现象的数据驱动学习。

> **ai_Abstract:** 本文提出了一种无监督参数估计方法，用于从噪声数据中发现可解释的常微分方程（ODE）。该方法首先假设并找到一个近似的通解，然后利用样条变换线性估计ODE的系数。通过获取线性独立的梯度信息并构建梯度矩阵，该方法能够精确求解ODE。实验证明，该方法在处理噪声数据时具有高精度和鲁棒性，并且能在不使用正则化的情况下促进解的稀疏性，有助于将数据驱动技术应用于真实物理现象的学习。

> **摘要翻译:** 在过去十年中，数据驱动地发现近似物理系统潜在动力学的可解释模型受到了关注。当前的方法采用预先指定的函数形式或基函数，并且通常导致模型缺乏物理意义和可解释性，更不用说代表系统的真实物理学。我们提出了一种无监督参数估计方法，该方法首先找到一个近似通解，然后通过样条变换线性估计控制常微分方程（ODE）的系数。近似通解使用与一般齐次、线性、常系数ODE的解析解相同的函数形式进行假设。一个额外的优点是，即使在存在噪声数据的情况下，它也能够产生高保真度、平滑的函数形式。样条逼近从函数形式中获取梯度信息，这些信息是线性独立的，并创建梯度矩阵的基础。该梯度矩阵用于线性系统中以找到ODE的系数。从案例研究中，我们观察到我们的建模方法以高精度发现了ODE，并且在不使用任何正则化技术的情况下促进了解决方案的稀疏性。该方法对噪声数据也具有鲁棒性，因此允许将数据驱动技术集成到真实的实验设置中，用于物理现象的数据驱动学习。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [779] [Pre-, In-, and Post-Processing Class Imbalance Mitigation Techniques for Failure Detection in Optical Networks](https://arxiv.org/abs/2507.21119)
> *光网络故障检测中类不平衡缓解的预处理、处理中和后处理技术*

*Yousuf Moiz Ali, Jaroslaw E. Prilepsky, Nicola Sambo, João Pedro, Mohammad M. Hosseini, Antonio Napoli, Sergei K. Turitsyn, Pedro Freire* | **Category: cs.LG, eess.SP, physics.optics** | **Updated: 2025-07-17**

**Keywords:** 类不平衡, 光网络, 故障检测, 阈值调整, 随机欠采样

**Comment:** 3 pages + 1 page for acknowledgement and references

> **TL;DR:** 本文比较了光网络故障检测中用于缓解类不平衡的预处理、处理中和后处理技术，发现阈值调整F1增益最高，而随机欠采样推理速度最快，揭示了性能与复杂性之间的权衡。

**AI_Comments:** 该论文通过对比分析，为光网络故障检测中类不平衡问题的解决提供了实用指导，特别强调了性能与计算效率之间的权衡，这对于实际系统部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决光网络故障检测中存在的类不平衡问题，以提高检测性能。

**Method:** 比较了预处理、处理中和后处理的类不平衡缓解技术，具体包括阈值调整（Threshold Adjustment）和随机欠采样（Random Under-sampling, RUS）。

**Result:** 阈值调整（Threshold Adjustment）实现了最高的F1增益（15.3%），而随机欠采样（Random Under-sampling, RUS）提供了最快的推理速度。

**Conclusion:** 在光网络故障检测中，不同的类不平衡缓解技术在性能和计算复杂性之间存在关键的权衡。

> **ai_Abstract:** 本文对比了多种类不平衡缓解技术在光网络故障检测中的应用效果。研究发现，阈值调整方法能显著提升F1分数，而随机欠采样则在推理速度上表现出色，凸显了在实际应用中性能与效率间的取舍。

> **摘要翻译:** 我们比较了光网络故障检测中用于缓解类不平衡的预处理、处理中和后处理技术。阈值调整实现了最高的F1增益（15.3%），而随机欠采样（RUS）提供了最快的推理速度，这突出显示了性能与复杂性之间的关键权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [791] [Multi-branch of Attention Yields Accurate Results for Tabular Data](https://arxiv.org/abs/2502.12507)
> *多分支注意力机制在表格数据上取得准确结果*

*Xuechen Li, Yupeng Li, Jian Liu, Xiaolin Jin, Xin Hu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 表格数据, Transformer, 多分支注意力, 特征异构性, 协同学习

**Comment:** 19 pages, 3 figures

> **TL;DR:** 针对表格数据特征异构性，提出MAYA框架，通过多分支注意力机制和协同学习提升Transformer在表格分类和回归任务上的性能。

**AI_Comments:** 这篇论文的创新点在于为Transformer模型处理表格数据的特征异构性提供了专门的解决方案。多分支注意力机制（MBA）和协同学习是其核心创新，有效地在融合异构特征的同时控制了模型复杂度。双重注意力机制进一步增强了模型捕获复杂交互的能力。该工作为将Transformer应用于表格数据任务开辟了新的途径，并展示了其在分类和回归任务上的优越性，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于Transformer的方法缺乏处理表格数据固有特征异构性的专门机制。

**Method:** 提出MAYA，一个基于编码器-解码器的Transformer框架。编码器中设计了多分支注意力（MBA）机制来融合异构特征并限制参数增长，并采用带有动态一致性权重约束的协同学习来生成更鲁棒的表示。解码器中利用交叉注意力机制整合表格数据和标签特征，形成双重注意力机制捕捉实例内和实例间交互。

**Result:** 广泛实验表明，该模型在表格分类和回归任务中，在基于Transformer的方法中取得了优越的性能。

**Conclusion:** MAYA框架通过其创新的注意力机制和协同学习，有效解决了表格数据特征异构性问题，并在表格分类和回归任务上超越了现有的Transformer基线模型。

> **ai_Abstract:** 本文提出了MAYA，一个针对表格数据特征异构性设计的编码器-解码器Transformer框架。该框架在编码器中引入了多分支注意力（MBA）机制以有效融合异构特征，并结合协同学习提升表示的鲁棒性。在解码器中，利用交叉注意力实现表格数据与标签特征的集成，形成捕捉实例内外部交互的双重注意力机制。实验结果表明，MAYA在表格分类和回归任务中均优于现有的基于Transformer的方法。

> **摘要翻译:** 表格数据固有地表现出显著的特征异构性，但现有的基于Transformer的方法缺乏专门的机制来处理这一特性。为了弥补这一差距，我们提出了MAYA，一个基于编码器-解码器的Transformer框架。在编码器中，我们设计了一个多分支注意力（MBA）机制，该机制构建了多个并行的注意力分支，并对每个分支的特征进行平均，有效融合了异构特征，同时限制了参数增长。此外，我们采用带有动态一致性权重约束的协同学习来产生更鲁棒的表示。在解码器阶段，利用交叉注意力机制将表格数据与相应的标签特征无缝集成。这种双重注意力机制有效地捕获了实例内和实例间的交互。我们在各种数据集上评估了所提出的方法，并将其与其他的最先进的基于Transformer的方法进行了比较。大量的实验表明，我们的模型在表格分类和回归任务中，在基于Transformer的方法中均取得了优越的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [795] [evoxels: A differentiable physics framework for voxel-based microstructure simulations](https://arxiv.org/abs/2507.21748)
> *evoxels：一个基于体素微观结构模拟的可微分物理框架*

*Simon Daubner, Alexander E. Cohen, Benjamin Dörich, Samuel J. Cooper* | **Category: cs.LG, cond-mat.mtrl-sci, cs.CE, physics.comp-ph** | **Updated: 2025-07-29**

**Keywords:** 可微分物理, 体素模拟, 材料科学, 逆向设计, 微观结构

**Comment:** 9 pages, 3 figures, structure following JOSS style

> **TL;DR:** evoxels是一个可微分的物理框架，它使用体素方法整合了3D显微镜数据、物理模拟、逆向建模和机器学习，用于材料科学。

**AI_Comments:** 这篇论文引入了一个创新的可微分物理框架evoxels，它通过整合多种技术（3D成像、物理模拟、逆向建模、机器学习）在一个统一的体素框架下，有望极大地推动材料科学中的逆向设计和发现。其“可微分”的特性是关键创新点，可能允许更高效的优化和参数反演。

<details>
  <summary>Details</summary>

**Motivation:** 桥接材料科学中的实验、理论和计算领域，尤其对于逆向材料设计至关重要，即从期望性能反推最佳微观结构和制造路径。

**Method:** 提出了一个名为evoxels的可微分物理框架，它基于完全Pythonic的统一体素方法，并整合了分段3D显微镜数据、物理模拟、逆向建模和机器学习。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** evoxels是一个新颖的可微分物理框架，专为材料科学中的体素基微观结构模拟而设计。它旨在弥合材料实验、理论和计算之间的鸿沟，特别支持逆向材料设计。该框架采用Python编写，整合了3D显微镜数据、物理模拟、逆向建模和机器学习，以加速对加工-结构-性能关系的理解和发现。

> **摘要翻译:** 材料科学本质上涵盖多个学科：实验人员使用先进的显微镜揭示微观和纳米尺度的结构，而理论家和计算科学家则开发模型来连接加工、结构和性能。弥合这些领域对于逆向材料设计至关重要，即从期望的性能出发，反向推导出最佳的微观结构和制造路径。将高分辨率成像与预测性模拟和数据驱动优化相结合，可以加速发现并加深对加工-结构-性能关系的理解。可微分物理框架evoxels基于一种完全Python化、统一的体素方法，该方法整合了分段的3D显微镜数据、物理模拟、逆向建模和机器学习。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [807] [Quantum Geometry of Data](https://arxiv.org/abs/2507.21135)
> *数据的量子几何*

*Alexander G. Abanov, Luca Candelori, Harold C. Steinacker, Martin T. Wells, Jerome R. Busemeyer, Cameron J. Hogan, Vahagn Kirakosyan, Nicola Marzari, Sunil Pinnamaneni, Dario Villani, Mengjia Xu, Kharen Musaelian* | **Category: cs.LG, quant-ph, stat.ML** | **Updated: 2025-07-22**

**Keywords:** 量子几何, 量子认知机器学习, 数据编码, 维度灾难, 希尔伯特空间

**Comment:** 27 pages, 14 figures, 1 table

> **TL;DR:** 本文展示了量子认知机器学习（QCML）如何将数据编码为量子几何，通过赫米特矩阵和希尔伯特空间表示数据，从而揭示数据的几何和拓扑结构，避免维度灾难，并有望增进对认知现象的理解。

**AI_Comments:** 这篇论文提出了一种新颖的数据表示方法，即通过量子几何来编码数据，这是量子计算与机器学习结合的一个创新点。其核心优势在于能够从数据中直接导出丰富的几何和拓扑结构，并有效应对维度灾难，这对于处理高维数据具有重要意义。此外，它将机器学习与量子认知理论联系起来，为理解认知现象提供了新的视角，具有潜在的跨学科影响力。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在展示量子认知机器学习（QCML）如何将数据编码为量子几何，并强调这种新颖的数据表示方法所带来的优势，例如揭示数据的内在结构和克服维度灾难。

**Method:** 本文提出了一种量子认知机器学习（QCML）方法，将数据编码为量子几何。在该方法中，数据特征通过学习的赫米特矩阵表示，数据点则被映射到希尔伯特空间中的量子状态。这种描述能够直接从数据中导出其几何和拓扑结构。

**Result:** 这种量子几何描述赋予数据集丰富的几何和拓扑结构，包括内在维度、量子度量和贝里曲率。QCML能够捕获数据的全局属性，同时避免了局部方法固有的维度灾难。该方法已在多个合成和真实世界示例中得到验证。

**Conclusion:** QCML的量子几何表示有望在量子认知的框架内推进我们对认知现象的理解。

> **ai_Abstract:** 本文介绍了量子认知机器学习（QCML）如何将数据编码为量子几何。通过将数据特征表示为赫米特矩阵并将数据点映射到希尔伯特空间，QCML能够揭示数据集固有的丰富几何和拓扑结构，如内在维度、量子度量和贝里曲率。这种方法能捕获数据的全局属性，有效避免传统局部方法面临的维度灾难，并在合成和真实世界示例中得到验证。研究表明，QCML的量子几何表示有望加深对认知现象的理解。

> **摘要翻译:** 我们展示了量子认知机器学习（QCML）如何将数据编码为量子几何。在QCML中，数据的特征由学习的赫米特矩阵表示，数据点被映射到希尔伯特空间中的状态。这种量子几何描述赋予数据集丰富的几何和拓扑结构——包括内在维度、量子度量和贝里曲率——这些都直接来源于数据。QCML捕获数据的全局属性，同时避免了局部方法固有的维度灾难。我们通过许多合成和真实世界的例子对此进行了说明。QCML的量子几何表示有望在量子认知的框架内推进我们对认知现象的理解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [808] [AdaptHetero: Machine Learning Interpretation-Driven Subgroup Adaptation for EHR-Based Clinical Prediction](https://arxiv.org/abs/2507.21197)
> *AdaptHetero：机器学习解释驱动的EHR临床预测子组适应*

*Ling Liao, Eva Aagaard* | **Category: cs.LG, stat.ML** | **Updated: 2025-07-28**

**Keywords:** 机器学习解释, 子组适应, EHR, 临床预测, 异质性

**Comment:** 11 pages, 3 figures

> **TL;DR:** AdaptHetero是一个利用机器学习解释性来识别并适应EHR数据中异构子组的模型，从而提高临床预测性能。

**AI_Comments:** AdaptHetero的创新之处在于其将MLI从单纯的解释工具提升为指导模型适应和优化的机制，特别是在处理EHR数据固有的异质性方面。通过结合SHAP和无监督聚类，它能够识别并响应不同患者子组的独特行为，这对于提高临床预测的准确性和公平性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习解释性在EHR数据中的应用受限于数据固有的复杂性和异质性，这阻碍了其有效指导特定子组建模的能力。现有方法主要用于建立信任和发现见解，但未能将这些见解转化为针对不同亚群的模型调整指导。

**Method:** 提出AdaptHetero框架，这是一个MLI驱动的框架，它将可解释性见解转化为可操作的指导，用于在单个医院系统内针对不同亚群调整模型训练和评估。该框架通过整合基于SHAP的解释和无监督聚类来实现。

**Result:** 在GOSSIS-1-eICU、WiDS和MIMIC-IV三个大规模EHR数据集上进行评估，AdaptHetero持续识别出预测ICU死亡率、院内死亡和隐匿性低氧血症时的异构模型行为。通过集成SHAP解释和无监督聚类，该框架增强了临床有意义的子组特定特征的识别，从而提高了预测性能。

**Conclusion:** AdaptHetero通过利用机器学习解释性来识别并适应EHR数据中的异构子组，有效提高了临床预测模型的性能和准确性。

> **ai_Abstract:** AdaptHetero是一个创新的框架，它利用机器学习解释性（MLI）来克服电子健康记录（EHR）数据中固有的复杂性和异质性问题。该框架通过整合SHAP解释和无监督聚类，将可解释性见解转化为指导，以在医院系统内为特定亚群定制模型训练和评估。在多个大型EHR数据集上的评估显示，AdaptHetero能有效识别异构模型行为并增强子组特征识别，从而显著提高ICU死亡率、院内死亡和隐匿性低氧血症等临床预测任务的性能。

> **摘要翻译:** 机器学习解释主要用于建立临床医生的信任并在EHR中发现可操作的见解。然而，EHR数据固有的复杂性和异质性限制了其在指导特定子组建模方面的有效性。我们提出了AdaptHetero，一个新颖的MLI驱动框架，它将可解释性见解转化为可操作的指导，用于在单个医院系统内针对不同亚群调整模型训练和评估。在三个大规模EHR数据集（GOSSIS-1-eICU、WiDS和MIMIC-IV）上进行评估，AdaptHetero持续识别出预测ICU死亡率、院内死亡和隐匿性低氧血症时的异构模型行为。通过整合基于SHAP的解释和无监督聚类，该框架增强了临床有意义的子组特定特征的识别，从而提高了预测性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [816] [MemShare: Memory Efficient Inference for Large Reasoning Models through KV Cache Reuse](https://arxiv.org/abs/2507.21433)
> *MemShare：通过KV缓存重用实现大型推理模型的内存高效推理*

*Kaiwen Chen, Xin Tan, Minchen Yu, Hong Xu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型推理模型, KV缓存, 内存效率, 推理优化, 缓存重用

**Comment:** 11 pages, 7 figures, submitted to AAAI 2026

> **TL;DR:** MemShare通过重用KV缓存块，显著降低大型推理模型的内存开销并提高吞吐量。

**AI_Comments:** MemShare的创新点在于识别大型推理模型中KV缓存状态的相似性，并利用协同过滤算法实现高效的零拷贝缓存重用。这对于优化大型模型推理的内存效率和吞吐量具有重要意义，是解决当前AI模型部署挑战的有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 大型推理模型（LRMs）在推理过程中生成冗长的思维链序列，导致巨大的内存开销。研究观察到LRMs经常产生高度相似的中间推理步骤，对应于各层相似的KV缓存状态。

**Method:** 本文提出了MemShare，一种新颖的KV缓存管理方法。它采用协同过滤算法高效识别可重用的KV缓存块，并实现零拷贝缓存重用，以显著减少内存开销并提高吞吐量。

**Result:** 实验结果表明，MemShare在保持更好准确性的同时，吞吐量最高提升了84.79%，并且比现有KV缓存管理方法表现更优。

**Conclusion:** MemShare通过创新的KV缓存重用机制，有效解决了大型推理模型推理时的内存效率问题，显著提高了性能。

> **ai_Abstract:** 本文提出了MemShare，一种针对大型推理模型（LRM）的新型KV缓存管理方法，旨在解决其推理过程中由于生成冗长思维链序列导致的内存开销问题。MemShare利用LRM中间推理步骤的相似性，通过协同过滤算法识别并重用KV缓存块，实现了零拷贝缓存重用。实验证明，MemShare在提高吞吐量高达84.79%的同时，保持了更高的准确性，优于现有方法。

> **摘要翻译:** 大型推理模型（LRM）在数学推理和形式逻辑任务中取得了显著进展。然而，它们倾向于生成冗长的思维链序列，导致推理过程中产生大量的内存开销。我们观察到LRM经常产生高度相似的中间推理步骤，这对应于各层相似的KV缓存状态。受此观察启发，我们提出了MemShare，一种新颖的KV缓存管理方法，可有效减少内存开销。MemShare采用协同过滤算法高效识别可重用的KV缓存块，并实现零拷贝缓存重用，从而显著减少内存开销，提高吞吐量，同时保持准确性。实验结果表明，与现有KV缓存管理方法相比，MemShare在保持更好准确性的同时，吞吐量最高提升了84.79%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [819] [A calibration test for evaluating set-based epistemic uncertainty representations](https://arxiv.org/abs/2502.16299)
> *一种用于评估基于集合的认知不确定性表示的校准测试*

*Mira Jürgens, Thomas Mortier, Eyke Hüllermeier, Viktor Bengs, Willem Waegeman* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-29**

**Keywords:** 认知不确定性, 校准, 可信集, 非参数测试, 机器学习

**Comment:** 

> **TL;DR:** 该论文提出了一种新颖的统计测试，用于评估基于集合的认知不确定性表示的校准性，其特点是允许实例依赖的凸组合，并利用适当的评分规则和核基估计器。

**AI_Comments:** 本文的创新之处在于提出了一个允许实例依赖的凸组合的校准测试，并将其与非参数测试程序以及基于核的估计器相结合。这为评估机器学习模型中认知不确定性提供了一种更精细、更准确的方法，对于构建更可靠和可信赖的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在机器学习中，准确表示认知不确定性是一项具有挑战性但至关重要的任务。可信集（credal sets）是广泛使用的认知不确定性表示方法，但需要一种严格的方法来评估其有效性，特别是其校准性，即这些集合是否包含真实的数据生成分布。

**Method:** 本文提出了一种新颖的统计测试，用于确定集合预测的凸组合是否存在分布校准。该框架允许凸组合是实例依赖的，并通过适当的评分规则学习这种组合。基于可微分的、基于核的校准误差估计器，引入了一种非参数测试程序。

**Result:** 在合成和真实世界的实验中，该方法展示了捕获实例级变异性（即不同集成成员在输入空间不同区域可能校准得更好）的优势。

**Conclusion:** 本文提出的非参数统计测试提供了一种更灵活和准确的方法来评估基于集合的认知不确定性表示的校准性，尤其是在考虑实例级变异性方面表现出优势。

> **ai_Abstract:** 该论文旨在解决机器学习中认知不确定性准确表示的挑战，特别是针对基于凸集（可信集）的表示。作者提出了一种新颖的非参数统计测试，用于评估这些集合的校准性。其核心创新在于允许预测的实例依赖凸组合，并通过适当的评分规则学习，同时利用基于核的估计器进行测试。这种方法能够更好地捕捉不同集成成员在输入空间中表现出的差异，从而提高校准评估的准确性。实验结果验证了捕获实例级变异性所带来的益处。

> **摘要翻译:** 在机器学习中，准确表示认知不确定性是一项具有挑战性但至关重要的任务。一种广泛使用的表示方法是概率预测器的凸集，也称为可信集（credal sets）。构建这些可信集的一种流行方式是通过集成或专门的监督学习方法，其中认知不确定性可以通过集合大小或成员之间的分歧等度量来量化。原则上，这些集合应该包含真实的数据生成分布。作为这种有效性的必要条件，我们采用最强的校准概念作为代理。具体来说，我们提出了一种新颖的统计测试，用于确定集合预测的凸组合是否存在分布校准。与以前的方法不同，我们的框架允许凸组合是实例相关的，认识到不同的集成成员在输入空间的不同区域可能校准得更好。此外，我们通过适当的评分规则学习这种组合，这些规则本质上优化了校准。基于可微分的、基于核的校准误差估计器，我们引入了一种非参数测试程序，并在合成和真实世界实验中展示了捕获实例级变异性的优势。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [831] [Cardiovascular Disease Prediction using Machine Learning: A Comparative Analysis](https://arxiv.org/abs/2507.21898)
> *使用机器学习预测心血管疾病：一项比较分析*

*Risshab Srinivas Ramesh, Roshani T S Udupa, Monisha J, Kushi K K S* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 心血管疾病预测, 机器学习, CatBoost, 比较分析, 数据预处理

**Comment:** 

> **TL;DR:** 本研究使用机器学习方法比较分析了心血管疾病的预测模型，发现CatBoost表现最佳，并指出了数据预处理的重要性。

**AI_Comments:** 本研究的创新点在于对多种机器学习模型在心血管疾病预测上的比较分析，并明确指出了CatBoost模型的优越性能。其重要性在于揭示了数据质量对模型预测可靠性的影响，并强调了未来研究中数据预处理的重要性。局限性在于发现吸烟和饮酒与CVD存在意外的负相关，这暗示了数据集可能存在潜在问题或需要更深入的特征工程。

<details>
  <summary>Details</summary>

**Motivation:** 心血管疾病（CVDs）是全球主要的死亡原因，占所有死亡人数的31%，因此预测心血管疾病具有重要意义。

**Method:** 本研究使用包含68,119条记录的心血管疾病数据集，探索了数值型（年龄、身高、体重、血压、BMI）和分类型（性别、胆固醇、血糖、吸烟、饮酒、活动）因素对CVD发生的影响。研究进行了t检验、卡方检验和ANOVA等统计分析，并应用了逻辑回归模型和CatBoost等机器学习模型进行预测和性能比较。

**Result:** 统计分析发现CVD与老年人、高血压、体重过重和胆固醇异常水平之间存在强关联，而体育活动是保护因素。逻辑回归模型显示年龄、血压和胆固醇是主要风险因素，但吸烟和饮酒存在意外的负相关。模型性能比较显示CatBoost表现最佳，准确率为0.734，ECE为0.0064，并在概率预测方面表现出色（Brier分数=0.1824）。

**Conclusion:** CatBoost是预测心血管疾病的最佳模型。数据挑战（包括异常值和偏态分布）表明需要改进预处理以提高预测可靠性。

> **ai_Abstract:** 本研究旨在通过机器学习方法预测心血管疾病（CVDs），并对不同模型进行比较分析。研究利用包含68,119条记录的CVD数据集，分析了多种数值和分类因素对CVD的影响。通过统计分析识别出主要风险因素，并使用逻辑回归和CatBoost等机器学习模型进行预测。结果显示，CatBoost在预测性能上表现最优，但在数据中发现了异常关联和数据质量问题，强调了改进数据预处理对提高预测可靠性的重要性。

> **摘要翻译:** 心血管疾病（CVDs）是全球主要的死亡原因，占所有死亡人数的31%。本研究涉及一个包含68,119条记录的心血管疾病（CVD）数据集，旨在探讨数值型（年龄、身高、体重、血压、BMI）和分类型（性别、胆固醇、血糖、吸烟、饮酒、活动）因素对CVD发生的影响。我们进行了统计分析，包括t检验、卡方检验和ANOVA，以识别CVD与老年人、高血压、体重过重和胆固醇异常水平之间的强关联，而体育活动则是一个保护因素。逻辑回归模型突出显示年龄、血压和胆固醇是主要的风险因素，但吸烟和饮酒存在意外的负相关，这表明可能存在数据问题。模型性能比较显示CatBoost表现最佳，准确率为0.734，ECE为0.0064，并在概率预测方面表现出色（Brier分数=0.1824）。数据挑战，包括异常值和偏态分布，表明需要改进预处理以提高预测可靠性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [835] [A Study on Variants of Conventional, Fuzzy, and Nullspace-Based Independence Criteria for Improving Supervised and Unsupervised Learning](https://arxiv.org/abs/2507.21136)
> *关于传统、模糊和基于零空间的独立性准则变体以改进监督和无监督学习的研究*

*Mojtaba Moattari* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-22**

**Keywords:** 独立性准则, 监督学习, 无监督学习, 降维, 可解释机器学习

**Comment:** 

> **TL;DR:** 该研究提出并评估了三种新的独立性准则，用于设计无监督和监督降维方法，结果显示其优于现有基线，并为可解释机器学习开辟了新方向。

**AI_Comments:** 这项研究的创新之处在于提出了新的独立性准则，并将其应用于降维，以提高机器学习方法在非线性数据处理中的性能。其重要性在于不仅超越了现有基线，更重要的是为可解释机器学习开辟了新途径，这对于提高机器学习模型的透明度和信任度至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 传统的监督和无监督学习方法使用核函数来捕获数据结构中的非线性，但专家需要确保其提出的非线性能够最大化变异性并捕获数据的固有多样性。本研究旨在通过设计新的独立性准则来改进无监督学习。

**Method:** 研究回顾了所有独立性准则，然后提出了三种新的独立性准则。这些准则被用于设计无监督和监督降维方法。研究在线性和神经网络非线性设置中评估了这些方法的对比度、准确性和可解释性。

**Result:** 研究结果表明，所提出的方法优于基线方法（tSNE、PCA、正则化LDA、带有（无）监督学习器和层共享的VAE）。

**Conclusion:** 所提出的方法为研究人员开辟了一条新的可解释机器学习（ML）路径。

> **ai_Abstract:** 本研究旨在通过提出新的独立性准则来改进监督和无监督学习中的非线性数据处理。作者回顾了现有独立性准则，并提出了三种新的准则，将其应用于设计无监督和监督降维方法。实验结果表明，这些新方法在对比度、准确性和可解释性方面优于多种现有基线方法，并为可解释机器学习领域提供了新的研究方向。

> **摘要翻译:** 无监督和监督学习方法通常使用核函数来捕获数据结构中固有的非线性。然而，专家必须确保他们提出的非线性能够最大化变异性并捕获数据的固有多样性。我们回顾了所有独立性准则来设计无监督学习器。然后，我们提出了3种独立性准则，并用它们来设计无监督和监督降维方法。我们在线性和神经网络非线性设置中评估了这些方法的对比度、准确性和可解释性。结果表明，这些方法优于基线（tSNE、PCA、正则化LDA、带有（无）监督学习器和层共享的VAE），并为研究人员开辟了一条新的可解释机器学习（ML）路径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [845] [Long-Term Fairness Inquiries and Pursuits in Machine Learning: A Survey of Notions, Methods, and Challenges](https://arxiv.org/abs/2406.06736)
> *机器学习中长期公平性的探究与追求：概念、方法与挑战综述*

*Usman Gohar, Zeyu Tang, Jialu Wang, Kun Zhang, Peter L. Spirtes, Yang Liu, Lu Cheng* | **Category: cs.LG, cs.AI, cs.CY** | **Updated: 2025-07-29**

**Keywords:** 机器学习, 长期公平性, 综述, 公平性概念, 挑战

**Comment:** Accepted in TMLR

> **TL;DR:** 本文综述了机器学习中长期公平性，涵盖了概念、方法、挑战和未来研究方向。

**AI_Comments:** 这篇综述论文对于理解机器学习中长期公平性问题及其复杂性具有重要意义，为该领域未来的研究提供了结构化的视角和方向。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习系统在日常生活中（尤其是在高风险领域）的广泛应用引发了对公平性影响的担忧。现有研究主要关注静态公平性，但自动化决策具有长期影响，且现成的公平性方法可能无法实现长期公平性。此外，反馈循环和模型与环境的交互引入了额外的复杂性，可能偏离最初的公平性目标。

**Method:** 本文通过综述现有关于长期公平性的文献，并从不同角度进行审视，提出了一个长期公平性研究的分类法。

**Result:** 本文综述了现有关于长期公平性的文献，提出了一个长期公平性研究的分类法，并强调了关键挑战。

**Conclusion:** 本文讨论了未来的研究方向，分析了当前问题和潜在的进一步探索。

> **ai_Abstract:** 本文综述了机器学习中长期公平性的研究。鉴于机器学习系统在日常应用中日益增长的公平性担忧，特别是现有静态公平性方法无法处理长期影响和反馈循环带来的复杂性，本综述回顾了现有文献，提出了长期公平性研究的分类法，并强调了关键挑战和未来的研究方向。

> **摘要翻译:** 机器学习系统在日常生活中的广泛整合，特别是在高风险领域，引发了对公平性影响的担忧。虽然先前的研究已经调查了静态公平性措施，但最近的研究表明，自动化决策具有长期影响，并且现成的公平性方法可能无法实现长期公平性。此外，反馈循环以及模型与环境之间的交互引入了额外的复杂性，这可能偏离最初的公平性目标。在这项综述中，我们从不同角度审查了关于长期公平性的现有文献，并提出了一个长期公平性研究的分类法。我们强调了关键挑战并考虑了未来的研究方向，分析了当前问题和潜在的进一步探索。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [854] [Conceptualizing Uncertainty: A Concept-based Approach to Explaining Uncertainty](https://arxiv.org/abs/2503.03443)
> *概念化不确定性：一种基于概念的不确定性解释方法*

*Isaac Roberts, Alexander Schulz, Sarah Schroeder, Fabian Hinder, Barbara Hammer* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 不确定性解释, 概念激活向量, 高维数据, 机器学习, 模型可解释性

**Comment:** 

> **TL;DR:** 本文提出了一种基于概念激活向量的方法，用于在高维数据分类中解释模型的不确定性，并展示了其在模型改进中的效用。

**AI_Comments:** 本文的创新之处在于提出了基于概念激活向量来解释高维数据中的不确定性，这不仅提供了局部解释，还能够提供全局解释，对于提升模型的可解释性和信任度具有重要意义。通过将解释用于模型改进，进一步验证了其方法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管存在不确定性量化方法，但在高维设置中解释不确定性仍然是一个开放的挑战。现有工作主要集中于局部解释的特征归因方法，而理解不确定性的来源和全局特征对于提高模型的可解释性和信任至关重要。

**Method:** 本文提出通过概念激活向量来解释高维数据分类设置中的不确定性，这种方法可以提供局部和全局的不确定性解释。

**Result:** 通过利用生成的不确定性解释，作者展示了其在改进和优化模型方面的实用性。

**Conclusion:** 通过概念激活向量提供的不确定性解释，能够有效帮助理解不确定性并改进模型，尤其是在高维数据分类任务中。

> **ai_Abstract:** 本研究提出了一种基于概念激活向量的方法，用于解释高维数据分类中机器学习模型的不确定性。该方法能够提供局部和全局的不确定性解释，克服了现有特征归因方法仅限于局部解释的局限性。研究通过利用这些解释来改进和优化模型，证明了其在增强模型可解释性和信任方面的实用性。

> **摘要翻译:** 机器学习中的不确定性是指模型预测的置信度或缺乏置信度的程度。虽然存在不确定性量化方法，但对不确定性的解释，特别是在高维环境中，仍然是一个开放的挑战。现有工作主要集中于特征归因方法，这些方法仅限于局部解释。从全局角度理解不确定性、其来源和特征对于增强模型预测的可解释性和信任至关重要。在这项工作中，我们提出通过概念激活向量来解释高维数据分类设置中的不确定性，这产生了不确定性的局部和全局解释。我们通过利用生成解释来改进和优化我们的模型，从而证明了其效用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [864] [Retrieve-Augmented Generation for Speeding up Diffusion Policy without Additional Training](https://arxiv.org/abs/2507.21452)
> *检索增强生成，用于无需额外训练加速扩散策略*

*Sodtavilan Odonchimed, Tatsuya Matsushima, Simon Holk, Yusuke Iwasawa, Yutaka Matsuo* | **Category: cs.LG, cs.RO** | **Updated: 2025-07-29**

**Keywords:** 扩散策略, 检索增强生成, 模仿学习, 加速推理, 无需训练

**Comment:** 

> **TL;DR:** 提出RAGDP框架，通过知识库检索加速预训练扩散策略的推理，无需额外训练，并在加速20倍时仍比现有蒸馏方法提升7%准确率。

**AI_Comments:** 这篇论文的创新点在于提出了一个无需额外训练即可加速扩散策略推理的框架RAGDP，解决了现有知识蒸馏方法训练成本高的问题。通过引入检索增强生成，它有效地利用了预训练模型的知识，并在速度和准确性之间取得了优异的平衡，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散策略（DPs）在模仿学习中表现出色，但因多步去噪而生成时间长。现有知识蒸馏方法虽能加速，但需要大量训练时间。

**Method:** 提出RAGDP。它通过DP编码器编码观测-动作对，构建专家演示的向量数据库。推理时，嵌入当前观测，检索最相似的专家动作，并将其与中间去噪步骤结合，以减少所需的扩散步骤。

**Result:** RAGDP在不额外训练的情况下，改善了速度与准确性的权衡。即使模型加速20倍，RAGDP在准确性上仍保持优势，比CP等蒸馏模型高出7%。

**Conclusion:** RAGDP提供了一种无需额外训练即可显著加速预训练扩散策略推理的有效框架，并在速度和准确性之间取得了更好的平衡。

> **ai_Abstract:** 本文提出了RAGDP（Retrieve-Augmented Generation for Diffusion Policies）框架，旨在解决扩散策略（DPs）推理速度慢且现有加速方法（如知识蒸馏）需要大量额外训练的问题。RAGDP通过构建专家演示的向量数据库，并在推理时检索最相似的专家动作与中间去噪步骤结合，从而在无需额外训练的情况下加速预训练DPs。实验结果显示，RAGDP在加速20倍时，其准确性比现有蒸馏模型提升7%，显著改善了速度与准确性的权衡。

> **摘要翻译:** 扩散策略（DPs）因其在各种模仿学习任务中实现显著精度提升的能力而受到关注。然而，DPs依赖于扩散模型，这需要多个去噪步骤来生成单个动作，导致生成时间长。为了解决这个问题，已经提出了基于知识蒸馏的方法，例如一致性策略（CP）。然而，这些方法需要大量的训练时间，特别是对于困难任务。在本研究中，我们提出了RAGDP（Retrieve-Augmented Generation for Diffusion Policies）作为一种新颖的框架，它通过使用知识库来加速预训练DPs的推理，从而无需额外训练。具体来说，RAGDP通过DP编码器编码观测-动作对，以构建专家演示的向量数据库。在推理过程中，对当前观测进行嵌入，并提取最相似的专家动作。这个提取的动作与中间去噪步骤相结合，以减少与原始扩散步骤相比所需的步骤数。我们表明，通过将RAGDP与基础模型和现有加速方法结合使用，我们在不额外训练的情况下改善了准确性和速度的权衡。即使在模型加速20倍时，RAGDP在准确性上仍保持优势，比CP等蒸馏模型高出7%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [870] [Advancing Wildfire Risk Prediction via Morphology-Aware Curriculum Contrastive Learning](https://arxiv.org/abs/2507.21147)
> *通过形态感知课程对比学习推进野火风险预测*

*Fabrizio Lo Scudo, Alessio De Rango, Luca Furnari, Alfonso Senatore, Donato D'Ambrosio, Giuseppe Mendicino, Gianluigi Greco* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 野火风险预测, 对比学习, 课程学习, 数据不平衡, 时空数据

**Comment:** To appear in the Proceedings of ECAI 2025

> **TL;DR:** 本文提出了一种新的形态感知课程对比学习方法，以解决野火风险预测中数据不平衡和高维时空数据的挑战，并降低计算成本，同时保持性能。

**AI_Comments:** 该论文的创新点在于引入了形态感知课程对比学习框架，以解决野火风险预测中数据不平衡和计算效率的挑战。通过利用形态信息，该方法能够更好地处理区域多样性，并实现更高效的模型训练。这对于实时野火风险管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 野火对自然生态系统和人类健康造成严重影响，气候变化加剧了这些影响。野火事件数据存在严重不平衡，且高维时空数据复杂，给深度学习模型训练带来挑战。此外，需要降低计算成本以实现更频繁的更新。

**Method:** 本文通过采用对比学习框架来增强补丁动态特征的潜在表示，引入了一种新的基于形态的课程对比学习方法。该方法旨在缓解与不同区域特征相关的问题，并允许使用更小的补丁尺寸而不影响性能。

**Result:** 进行了实验分析以验证所提出的建模策略的有效性。

**Conclusion:** 通过实验分析，验证了所提出的基于形态的课程对比学习方法在野火风险预测中的有效性，能够解决数据不平衡和降低计算成本等挑战。

> **ai_Abstract:** 本文针对野火风险预测中数据不平衡、高维时空数据复杂性以及计算成本高的问题，提出了一种新的形态感知课程对比学习方法。该方法通过增强潜在表示来处理动态特征，旨在缓解区域特征差异并支持小补丁尺寸，同时保持性能。实验分析验证了其有效性。

> **摘要翻译:** 野火严重影响自然生态系统和人类健康，导致生物多样性丧失、水文地质风险增加以及有毒物质排放量升高。气候变化加剧了这些影响，特别是在气温上升和干旱期延长的地区，如地中海。这要求开发利用最先进技术的先进风险管理策略。然而，在这种背景下，数据显示出一种不平衡的偏向，即野火事件的发生率远低于典型情况。这种不平衡，加上高维时空数据固有的复杂性，给训练深度学习架构带来了重大挑战。此外，由于精确的野火预测主要依赖于天气数据，因此找到一种降低计算成本以实现使用最新天气预报更频繁更新的方法将是有益的。本文研究了如何通过增强补丁动态特征的潜在表示，采用对比框架来应对这些挑战。因此，我们引入了一种新的基于形态的课程对比学习方法，该方法减轻了与不同区域特征相关的问题，并允许使用更小的补丁尺寸而不影响性能。进行了实验分析以验证所提出的建模策略的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [872] [PVD-ONet: A Multi-scale Neural Operator Method for Singularly Perturbed Boundary Layer Problems](https://arxiv.org/abs/2507.21437)
> *PVD-ONet：一种用于奇摄动边界层问题的多尺度神经算子方法*

*Tiantian Sun, Jian Zu* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 奇摄动问题, 边界层, 神经算子, PVD-ONet, 多尺度问题

**Comment:** 34pages,14figures

> **TL;DR:** 本文提出了PVD-Net和PVD-ONet两种新颖的神经网络方法，旨在解决物理信息神经网络在奇摄动问题上的收敛失败，并在多尺度问题中表现出优异性能。

**AI_Comments:** PVD-ONet的创新性在于其结合了Prandtl-Van Dyke匹配原理与神经网络和算子学习，有效解决了传统物理信息神经网络在处理奇摄动问题时的收敛难题。该方法无需数据、直接从控制方程学习，并能实现对问题族的快速预测，这对于复杂多尺度问题的求解具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 物理信息神经网络（PINN）和Physics-informed DeepONet在求解偏微分方程时，常在奇摄动问题上无法收敛。

**Method:** 本文提出了Prandtl-Van Dyke神经网络（PVD-Net）及其算子学习扩展Prandtl-Van Dyke深度算子网络（PVD-ONet）两种新框架。这两种方法均仅依赖控制方程，无需数据。为了满足不同的任务需求，PVD-Net和PVD-ONet都开发了侧重稳定性和高精度建模的两个版本。主导阶PVD-Net采用双网络架构结合Prandtl匹配条件，适用于稳定性优先场景。高阶PVD-Net采用五网络设计结合Van Dyke匹配原理，以捕捉精细尺度边界层结构，适用于高精度场景。PVD-ONet通过组装多个DeepONet模块，将PVD-Net推广到算子学习设置，直接将初始条件映射到解算子，实现对整个边界层问题族的即时预测而无需重新训练。

**Result:** 在各种模型上的数值实验表明，所提出的方法在各种误差指标下均持续优于现有基线。

**Conclusion:** PVD-Net和PVD-ONet为多尺度问题提供了一种强大的新方法。

> **ai_Abstract:** 本文提出PVD-Net和PVD-ONet两种新颖的神经网络框架，旨在解决物理信息神经网络在奇摄动问题上收敛失败的挑战。PVD-Net提供稳定性优先和高精度两种版本，分别结合Prandtl和Van Dyke匹配条件。PVD-ONet将PVD-Net推广至算子学习，通过集成DeepONet模块实现对边界层问题族的即时预测。数值实验结果表明，该方法在多尺度问题上表现优异，显著超越现有基线。

> **摘要翻译:** 物理信息神经网络和物理信息深度算子网络在求解偏微分方程方面表现出色；然而，它们在奇摄动问题上常常无法收敛。为了解决这个问题，我们提出了两种新颖的框架：Prandtl-Van Dyke神经网络（PVD-Net）及其算子学习扩展Prandtl-Van Dyke深度算子网络（PVD-ONet），它们都仅依赖于控制方程而无需数据。为了满足不同的任务特定需求，PVD-Net和PVD-ONet都开发了两个不同的版本，分别针对侧重稳定性和高精度建模。主导阶PVD-Net采用双网络架构结合Prandtl匹配条件，旨在解决稳定性优先的场景。高阶PVD-Net采用五网络设计结合Van Dyke匹配原理，以捕捉精细尺度边界层结构，使其非常适合高精度场景。PVD-ONet通过组装多个DeepONet模块，将PVD-Net推广到算子学习设置，直接将初始条件映射到解算子，并能对整个边界层问题族进行即时预测而无需重新训练。对各种模型的数值实验表明，我们提出的方法在各种误差指标下均持续优于现有基线，从而为多尺度问题提供了一种强大的新方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [874] [Prediction of acoustic field in 1-D uniform duct with varying mean flow and temperature using neural networks](https://arxiv.org/abs/2507.22370)
> *使用神经网络预测一维均匀管道中变平均流和温度声场*

*D. Veerababu, Prasanta K. Ghosh* | **Category: cs.LG, cs.SD, eess.AS, 34A06, G.1.6; I.6.4; J.2** | **Updated: 2025-07-30**

**Keywords:** 神经网络, 声场预测, 一维管道, 温度梯度, 迁移学习

**Comment:** 22 pages

> **TL;DR:** 使用物理约束神经网络预测一维管道中变流和温度下的声场，并与传统方法验证。

**AI_Comments:** 这篇论文的创新点在于将受物理定律约束的神经网络应用于一维管道中声场的预测，提供了一种传统数值方法的替代方案。它不仅验证了神经网络预测声学变量的能力，还展示了迁移学习和自动微分等先进机器学习技术在声学问题解决中的应用潜力，这对于复杂声学建模具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 探索将受物理定律约束的神经网络作为一种替代数值工具，用于预测非均匀介质中一维管道内的声传播。

**Method:** 推导了一维管道中非均匀介质声传播的控制方程，将其转化为无约束优化问题，并使用神经网络求解。研究中还应用了迁移学习和自动微分等机器学习技术。

**Result:** 成功预测了声压和粒子速度等声学状态变量，并通过传统的Runge-Kutta求解器进行了验证。研究了温度梯度对声场的影响。展示了机器学习技术（如迁移学习和自动微分）在声学应用中的利用。

**Conclusion:** 该研究展示了利用机器学习技术（特别是受物理定律约束的神经网络、迁移学习和自动微分）来预测一维管道中声场的可行性和潜力。

> **ai_Abstract:** 本文提出了一种利用受物理定律约束的神经网络预测一维均匀管道中变平均流和温度下声场的方法。研究推导了声传播的控制方程，并将其转化为无约束优化问题通过神经网络求解。预测的声压和粒子速度通过传统Runge-Kutta求解器进行了验证。此外，论文还探讨了温度梯度对声场的影响，并展示了迁移学习和自动微分等机器学习技术在声学领域的应用潜力。

> **摘要翻译:** 受物理定律约束的神经网络作为一种替代数值工具出现。本文推导了代表声音在携带非均匀介质的一维管道内传播的控制方程。该问题被转化为一个无约束优化问题，并使用神经网络求解。声压和粒子速度这两种声学状态变量都得到了预测，并与传统的Runge-Kutta求解器进行了验证。研究了温度梯度对声场的影响。演示了机器学习技术（如迁移学习和自动微分）在声学应用中的利用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [878] [Uncovering Gradient Inversion Risks in Practical Language Model Training](https://arxiv.org/abs/2507.21198)
> *揭示实际语言模型训练中的梯度反演风险*

*Xinguo Feng, Zhongkui Ma, Zihan Wang, Eu Joe Chegne, Mengyao Ma, Alsharif Abuadbba, Guangdong Bai* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 梯度反演, 语言模型, 联邦学习, 隐私威胁, Grab

**Comment:** 15 Pages, 5 figures, 10 tables. Accepted by ACM CCS 2024

> **TL;DR:** 提出Grab攻击，显著提高了语言模型在联邦学习中梯度反演攻击的成功率，揭示了新的隐私威胁。

**AI_Comments:** 这项工作通过提出一种针对语言模型特性的新型梯度反演攻击Grab，显著提高了在联邦学习场景下对语言模型进行数据恢复的成功率，揭示了此前被低估的隐私风险。其创新点在于结合了dropout掩码优化和离散优化，以适应文本数据的离散性挑战。这对于理解和缓解联邦学习中语言模型的隐私威胁具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 梯度反演攻击在视觉模型中是显著的隐私威胁，但在语言模型中因文本数据的离散性常被认为效果不佳或依赖不切实际的训练设置，导致其潜在隐私威胁被低估，尽管联邦学习是新兴的语言模型训练方法。

**Method:** 本文提出了一种领域特定的梯度反演攻击，名为Grab（基于混合优化的梯度反演）。Grab具有两个交替优化过程，以解决实际训练设置带来的挑战，包括对层间dropout掩码进行同时优化以改进token恢复，以及进行离散优化以实现有效的token序列化。

**Result:** Grab可以恢复高达92.9%的私有训练数据，在基准设置下比利用带有辅助模型的离散优化攻击策略提高了显著的28.9%恢复率，在实际设置下提高了48.5%恢复率。

**Conclusion:** Grab在理解新兴的联邦学习语言模型训练模式中的隐私威胁方面迈出了重要一步。

> **ai_Abstract:** 本文提出了一种名为Grab的领域特定梯度反演攻击，旨在解决在联邦学习中对语言模型进行梯度反演攻击时因文本数据离散性而面临的挑战。Grab通过结合dropout掩码同时优化和离散优化，显著提高了私有训练数据的恢复率，最高可达92.9%。研究结果表明，Grab在基准和实际设置下均优于现有攻击策略，揭示了语言模型联邦学习中被低估的隐私风险。

> **摘要翻译:** 梯度反演攻击已被证明是对联邦学习（FL）的重大隐私威胁，尤其是在视觉模型等连续领域。相比之下，当应用于语言模型时，由于文本数据中token的离散性带来的挑战，它通常被认为效果较差或高度依赖不切实际的训练设置。因此，尽管FL是语言模型的一种新兴训练方法，其潜在的隐私威胁仍被严重低估。在这项工作中，我们提出了一种领域特定的梯度反演攻击，名为Grab（基于混合优化的梯度反演）。Grab具有两个交替优化过程，以解决实际训练设置带来的挑战，包括对层间dropout掩码进行同时优化以改进token恢复，以及进行离散优化以实现有效的token序列化。Grab可以恢复私有训练数据的大部分（高达92.9%的恢复率），其性能优于利用带有辅助模型的离散优化攻击策略，在基准设置下恢复率显著提高了28.9%，在实际设置下提高了48.5%。Grab在理解新兴的联邦学习语言模型训练模式中的隐私威胁方面迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [887] [Multi-state Protein Design with DynamicMPNN](https://arxiv.org/abs/2507.21938)
> *使用 DynamicMPNN 进行多态蛋白质设计*

*Alex Abrudan, Sebastian Pujalte Ojeda, Chaitanya K. Joshi, Matthew Greenig, Felipe Engelberger, Alena Khmelinskaia, Jens Meiler, Michele Vendruscolo, Tuomas P. J. Knowles* | **Category: cs.LG, q-bio.BM, I.2.6; J.3** | **Updated: 2025-07-29**

**Keywords:** 多态蛋白质设计, 逆向折叠, DynamicMPNN, 构象集合, 蛋白质工程

**Comment:** ICML 2025 GenBio Workshop

> **TL;DR:** DynamicMPNN 是一种新型逆向折叠模型，专门用于设计与蛋白质多态构象兼容的序列，其性能优于现有方法。

**AI_Comments:** DynamicMPNN 的创新之处在于其直接针对多态性进行联合学习的训练范式，这克服了传统方法在处理蛋白质动态行为时的局限性。这对于理解和设计在多种构象下发挥功能的蛋白质具有重要意义，可能在酶工程和药物发现等领域带来突破。

<details>
  <summary>Details</summary>

**Motivation:** 现有的结构生物学范式和设计方法难以有效处理蛋白质的多态性，导致多态设计成功率低，而许多关键生物过程依赖于多态蛋白质。

**Method:** 引入了 DynamicMPNN，这是一个逆向折叠模型，通过在构象集合上进行联合学习，显式训练其生成与多种构象兼容的序列。该模型在包含 46,033 对构象对的数据集上进行训练，并使用 AlphaFold 进行评估。

**Result:** DynamicMPNN 在具有挑战性的多态蛋白质基准测试中，与 ProteinMPNN 相比，在结构归一化 RMSD 上性能提高了多达 13%。

**Conclusion:** DynamicMPNN 成功地解决了多态蛋白质设计中的挑战，显著提高了设计兼容多构象序列的能力。

> **ai_Abstract:** 本文介绍了 DynamicMPNN，一种专门为多态蛋白质设计开发的逆向折叠模型。与以往依赖单态预测聚合的方法不同，DynamicMPNN 通过在蛋白质构象集合上进行联合学习，直接生成与多种构象兼容的序列。该模型在大量构象对上进行训练和评估，结果显示其在多态蛋白质设计任务上，性能显著优于现有模型 ProteinMPNN。

> **摘要翻译:** 结构生物学长期以来一直由“一种序列、一种结构、一种功能”的范式主导，然而许多关键的生物过程——从酶催化到膜转运——都依赖于采用多种构象状态的蛋白质。现有的多态设计方法依赖于单态预测的后验聚合，与单态设计相比，实验成功率很低。我们引入了 DynamicMPNN，这是一种逆向折叠模型，通过在构象集合上进行联合学习，明确训练其生成与多种构象兼容的序列。DynamicMPNN 在涵盖 75% CATH 超家族的 46,033 个构象对上进行训练，并使用 AlphaFold 初始猜测进行评估，在我们具有挑战性的多态蛋白质基准测试中，其在结构归一化 RMSD 上比 ProteinMPNN 表现高出多达 13%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [889] [Compton Form Factor Extraction using Quantum Deep Neural Networks](https://arxiv.org/abs/2504.15458)
> *利用量子深度神经网络提取康普顿形状因子*

*Brandon B. Le, Dustin Keller* | **Category: cs.LG, hep-ph, nucl-th, quant-ph** | **Updated: 2025-07-29**

**Keywords:** 康普顿形状因子, 量子深度神经网络, 深度虚拟康普顿散射, 强子物理, 部分子分布

**Comment:** 36 pages, 17 figures. v2: major revisions

> **TL;DR:** 该论文利用量子深度神经网络（QDNNs）从深度虚拟康普顿散射（DVCS）实验中提取康普顿形状因子（CFFs），结果表明QDNNs在特定情况下优于经典深度神经网络（CDNNs），即使模型复杂度有限，也能提供更高的预测准确性和精度。

**AI_Comments:** 该论文的创新之处在于将量子深度神经网络（QDNNs）应用于康普顿形状因子（CFFs）的提取，并在特定物理领域展示了相对于经典方法的潜在“量子优势”。这可能为核物理和粒子物理领域的数据分析开辟新的途径，尤其随着量子计算的成熟。论文还强调了开发一种量化这种优势的度量标准，这是一项有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机是从DVCS实验中提取康普顿形状因子（CFFs），并探索量子深度神经网络（QDNNs）在此任务中的潜力，尤其是在发现它们可能优于经典深度神经网络之后。

**Method:** 该论文利用量子深度神经网络（QDNNs）从托马斯·杰斐逊国家加速器设施进行的深度虚拟康普顿散射（DVCS）实验中提取康普顿形状因子（CFFs）。分析采用了标准的两扭度Belitsky、Kirchner和Müller（BKM）形式主义，并辅以旨在最大限度减少模型依赖性的拟合过程。通过经典深度神经网络（CDNNs）和QDNNs对CFFs进行了伪数据提取测试，并进行了详细的比较分析。此外，还开发了一种度量标准来量化基于DVCS实验数据特征的量子优势程度。

**Result:** 结果表明，量子深度神经网络（QDNNs）在特定情况下可以优于经典深度神经网络（CDNNs），即使在模型复杂度有限的情况下，也能提供更高的预测准确性和精度。研究还开发了一种度量标准来量化基于DVCS实验数据特征的量子优势。

**Conclusion:** 这些发现强调了量子深度神经网络（QDNNs）在推进未来多维部分子分布和强子物理研究中的前景。

> **ai_Abstract:** 本论文展示了利用量子深度神经网络（QDNNs）从深度虚拟康普顿散射（DVCS）实验中提取康普顿形状因子（CFFs）。研究采用了BKM形式主义和一种旨在最小化模型依赖性的拟合过程。通过对伪数据进行与经典深度神经网络（CDNNs）的比较测试，结果显示QDNNs即使在模型复杂度有限的情况下，也能实现卓越的准确性和精度。该研究还引入了一种量化量子优势的度量标准，突出了QDNNs在未来部分子分布和强子物理研究中的潜力。

> **摘要翻译:** 我们展示了利用量子深度神经网络（QDNNs）从托马斯·杰斐逊国家加速器设施进行的深度虚拟康普顿散射（DVCS）实验中提取康普顿形状因子（CFFs）。该分析采用了标准的两扭度Belitsky、Kirchner和Müller形式主义，并辅以旨在以类似于传统局部拟合的方式最小化模型依赖性的拟合过程。使用经典深度神经网络（CDNNs）和QDNNs对CFFs进行了伪数据提取测试，并进行了详细的比较分析。结果表明，QDNNs在特定情况下可以优于CDNNs，即使模型复杂度有限，也能提供更高的预测准确性和精度。受此启发，我们开发了一种度量标准来量化基于DVCS实验数据特征的量子优势程度。这些发现强调了QDNNs在推进未来多维部分子分布和强子物理研究中的前景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [912] [Deep Unfolding for MIMO Signal Detection](https://arxiv.org/abs/2507.21152)
> *MIMO信号检测的深度展开*

*Hangli Ge, Noboru Koshizuka* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 深度展开, MIMO信号检测, 复值计算, Wirtinger微积分, 大规模MIMO

**Comment:** 

> **TL;DR:** 本文提出了一种基于深度展开神经网络的MIMO检测器（DPST），利用复值计算，实现了高效、可解释、低复杂度的MIMO信号检测，并在下一代大规模MIMO系统中具有实用性。

**AI_Comments:** 这篇论文的创新点在于将深度展开网络与复值计算（通过Wirtinger微积分）相结合，使其MIMO检测器能够在信号处理固有的复数域中原生操作，而非依赖传统的实值近似。这提高了方法的效率、可解释性和性能，并降低了计算复杂度，使其在大规模MIMO系统中具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有MIMO信号检测方法依赖实值近似，不符合信号处理的复值本质。

**Method:** 本文提出了一种名为动态部分收缩阈值（DPST）的深度展开神经网络MIMO检测器，该方法利用Wirtinger微积分进行复值计算，并在复数域原生操作。该算法仅需少量可训练参数，从而简化了训练。

**Result:** 该方法以更少的迭代次数和更低的计算复杂度实现了卓越的检测性能，同时具有高效、可解释和低复杂度的特点。

**Conclusion:** 所提出的DPST方法是下一代大规模MIMO系统的一种实用解决方案。

> **ai_Abstract:** 本文提出了一种名为动态部分收缩阈值（DPST）的深度展开神经网络MIMO检测器，该检测器通过Wirtinger微积分引入复值计算，并原生在复数域操作，解决了现有实值近似方法的局限性。该方法参数量少，训练简化，数值结果显示其在检测性能、迭代次数和计算复杂度方面均优于现有方法，为下一代大规模MIMO系统提供了实用高效的解决方案。

> **摘要翻译:** 在本文中，我们提出了一种基于深度展开神经网络的MIMO检测器，该检测器利用Wirtinger微积分引入了复值计算。该方法被称为动态部分收缩阈值（DPST），能够实现高效、可解释和低复杂度的MIMO信号检测。与依赖实值近似的现有方法不同，我们的方法在复数域中原生操作，这与信号处理任务的基本性质相符。所提出的算法仅需要少量可训练参数，从而简化了训练过程。数值结果表明，所提出的方法以更少的迭代次数和更低的计算复杂度实现了卓越的检测性能，使其成为下一代大规模MIMO系统的一种实用解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [924] [Context-Aware Probabilistic Modeling with LLM for Multimodal Time Series Forecasting](https://arxiv.org/abs/2505.10774)
> *基于LLM的上下文感知概率建模用于多模态时间序列预测*

*Yueyang Yao, Jiajun Li, Xingyuan Dai, MengMeng Zhang, Xiaoyan Gong, Fei-Yue Wang, Yisheng Lv* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 时间序列预测, LLM, 多模态, 概率建模, 上下文感知

**Comment:** 13 pages, 2 figures

> **TL;DR:** CAPTime是一种利用LLM进行上下文感知概率多模态时间序列预测的方法，通过有效整合文本和时间序列，表现优于现有方法。

**AI_Comments:** 本文的创新之处在于其有效地将外部文本上下文与LLM的概率建模能力相结合，用于多模态时间序列预测。通过引入学习交互和结合混合分布专家与冻结LLM，CAPTime克服了传统方法在上下文感知和分布建模方面的局限性。这对于需要整合多样化数据源的复杂时间序列预测应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在时间序列预测中难以有效整合外部文本并使其与大型语言模型（LLM）的概率特性对齐。当前方法要么通过基本提示进行浅层文本-时间序列融合，要么依赖于与LLM标记生成范式冲突的确定性数值解码，这限制了上下文感知和分布建模。

**Method:** 本文提出了CAPTime，一种上下文感知概率多模态时间序列预测方法。该方法首先使用预训练的时间序列编码器编码时间模式，然后通过可学习的交互将其与文本上下文对齐，以生成联合多模态表示。通过将混合分布专家与冻结的LLM结合，实现了上下文感知概率预测，同时保留了LLM固有的分布建模能力。在数据稀缺场景下，通过混合概率解码增强了鲁棒性。

**Result:** 在多种时间序列预测任务上的实验表明，CAPTime具有卓越的准确性和泛化能力，特别是在多模态场景中。额外的分析强调了其在数据稀缺场景下通过混合概率解码的鲁棒性。

**Conclusion:** CAPTime通过有效整合文本信息并利用LLM的概率建模能力，成功解决了现有方法在多模态时间序列预测中的局限性，实现了上下文感知和高准确度的预测。

> **ai_Abstract:** CAPTime是一种新颖的上下文感知概率多模态时间序列预测方法，旨在解决现有方法在整合文本上下文与LLM时面临的挑战。它通过编码时间模式并与文本上下文对齐，结合混合分布专家和冻结的LLM，实现了卓越的准确性和泛化能力，尤其适用于多模态和数据稀缺场景。

> **摘要翻译:** 时间序列预测对于能源市场、气候分析和交通管理等应用至关重要。然而，现有方法难以有效整合外部文本并使其与大型语言模型（LLM）的概率特性对齐。当前方法要么通过基本提示进行浅层文本-时间序列融合，要么依赖于与LLM标记生成范式冲突的确定性数值解码，这限制了上下文感知和分布建模。为了解决这些局限性，我们提出了CAPTime，一种上下文感知概率多模态时间序列预测方法，它利用文本信息抽象和自回归LLM解码。我们的方法首先使用预训练的时间序列编码器编码时间模式，然后通过可学习的交互将其与文本上下文对齐，以生成联合多模态表示。通过将混合分布专家与冻结的LLM结合，我们实现了上下文感知概率预测，同时保留了LLM固有的分布建模能力。在多种时间序列预测任务上的实验表明，CAPTime具有卓越的准确性和泛化能力，特别是在多模态场景中。额外的分析强调了其在数据稀缺场景下通过混合概率解码的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [932] [CIMR: Contextualized Iterative Multimodal Reasoning for Robust Instruction Following in LVLMs](https://arxiv.org/abs/2507.22074)
> *CIMR：用于LVLM中鲁棒指令遵循的上下文迭代多模态推理*

*Yangshu Yuan, Heng Chen, Xinyi Jiang, Christian Ng, Kexin Qiu* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-22**

**Keywords:** 多模态推理, 指令遵循, 自校正, LVLM, 上下文感知

**Comment:** 

> **TL;DR:** CIMR是一个新颖的框架，通过上下文迭代推理和自校正，显著提高了大型视觉语言模型（LVLM）在复杂多模态指令遵循任务上的性能。

**AI_Comments:** CIMR的创新点在于引入了上下文感知的迭代推理和自校正模块，并通过动态融合机制深度整合多模态信息，有效解决了LVLM在复杂指令遵循中的推理和纠错难题。其在MAP数据集上的显著性能提升，证明了该框架在实际应用中的巨大潜力，为未来LVLM在复杂多模态任务上的发展提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）和大型视觉语言模型（LVLMs）在处理需要逻辑推理、动态反馈集成和迭代自校正的复杂、多步骤多模态指令时表现不佳。

**Method:** 本文提出了CIMR（Contextualized Iterative Multimodal Reasoning）框架，引入了上下文感知的迭代推理和自校正模块。CIMR分两个阶段操作：初始推理和响应生成，随后使用解析的多模态反馈进行迭代细化。一个动态融合模块在每个步骤深度整合文本、视觉和上下文特征。研究者在Visual Instruction Tuning (VIT) 数据集上微调了LLaVA-1.5-7B，并在新引入的Multi-modal Action Planning (MAP) 数据集上对CIMR进行了评估。

**Result:** CIMR在Multi-modal Action Planning (MAP) 数据集上达到了91.5%的准确率，超越了GPT-4V (89.2%)、LLaVA-1.5 (78.5%)、MiniGPT-4 (75.3%) 和 InstructBLIP (72.8%) 等现有最先进模型。

**Conclusion:** CIMR证明了其迭代推理和自校正能力在复杂任务中的有效性，显著提升了LVLM在鲁棒指令遵循方面的性能。

> **ai_Abstract:** CIMR是一个新颖的上下文迭代多模态推理框架，旨在解决大型视觉语言模型（LVLMs）在处理复杂、多步骤、需要逻辑推理和自校正的多模态指令时的不足。该框架通过初始推理和响应生成，结合使用解析的多模态反馈进行迭代细化，并在每一步深度整合文本、视觉和上下文特征。在新的多模态动作规划（MAP）数据集上，CIMR在微调LLaVA-1.5-7B后，以91.5%的准确率显著超越了GPT-4V等现有SOTA模型，验证了其在复杂任务中迭代推理和自校正的有效性。

> **摘要翻译:** 大型语言模型（LLM）和大型视觉语言模型（LVLM）的快速发展增强了我们处理和生成人类语言和视觉信息的能力。然而，这些模型在处理需要逻辑推理、动态反馈集成和迭代自校正的复杂、多步骤多模态指令时常常遇到困难。为了解决这个问题，我们提出了CIMR：上下文迭代多模态推理，这是一个新颖的框架，引入了上下文感知的迭代推理和自校正模块。CIMR分两个阶段操作：初始推理和响应生成，然后使用解析的多模态反馈进行迭代细化。一个动态融合模块在每一步深度整合文本、视觉和上下文特征。我们在Visual Instruction Tuning (VIT) 数据集上微调了LLaVA-1.5-7B，并在新引入的多模态动作规划（MAP）数据集上评估了CIMR。CIMR达到了91.5%的准确率，超越了GPT-4V (89.2%)、LLaVA-1.5 (78.5%)、MiniGPT-4 (75.3%) 和 InstructBLIP (72.8%) 等最先进模型，这证明了其在复杂任务中迭代推理和自校正能力的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [935] [Latte: Collaborative Test-Time Adaptation of Vision-Language Models in Federated Learning](https://arxiv.org/abs/2507.21494)
> *Latte：联邦学习中视觉-语言模型的协作式测试时自适应*

*Wenxuan Bao, Ruxi Deng, Ruizhong Qiu, Tianxin Wei, Hanghang Tong, Jingrui He* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** 联邦学习, 测试时自适应, 视觉-语言模型, 分布偏移, 协作式学习

**Comment:** Accepted by ICCV 2025

> **TL;DR:** Latte是一种新的联邦学习框架，通过客户端本地记忆和外部记忆协作，有效解决去中心化设置中视觉-语言模型测试时自适应的数据限制和个性化问题，性能优越且成本低。

**AI_Comments:** Latte的创新点在于其独特的双记忆（本地记忆和外部记忆）协作机制，有效解决了联邦学习环境下测试时自适应的数据稀缺和个性化问题。它将联邦学习的去中心化特性与测试时自适应的需求相结合，提供了一种高效且低成本的解决方案，对于在边缘设备上部署大型预训练模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有测试时自适应方法通常为单一领域设计，且需要大量数据。在联邦学习等去中心化设置中，单独应用于每个客户端会导致测试数据有限；而通过服务器直接共享单一全局记忆则无法实现个性化，无法适应每个客户端独特的分布。

**Method:** Latte框架中，每个客户端维护一个本地记忆存储自身历史测试数据的嵌入，以及一个外部记忆存储来自其他相关客户端的类原型。在通信过程中，客户端在服务器协调下从相似客户端检索原型以扩展记忆。本地自适应时，Latte利用嵌入相似性和不确定性来增强模型性能。

**Result:** 理论分析表明Latte能有效利用同分布客户端并对异分布客户端保持鲁棒性。在域适应和损坏基准上的广泛实验验证了Latte在去中心化设置中实现了卓越性能，同时只引入了可忽略的通信和计算成本。

**Conclusion:** Latte框架通过其独特的双记忆协作机制，成功解决了联邦学习中视觉-语言模型测试时自适应面临的数据稀缺和个性化挑战，实现了高性能和低成本的解决方案。

> **ai_Abstract:** Latte是一个为联邦学习环境设计的协作式测试时自适应框架，旨在解决视觉-语言模型在去中心化设置中面临的数据稀缺和个性化挑战。它通过客户端维护本地记忆和外部记忆，并允许客户端在服务器协调下从相似者处协作获取原型来扩展知识。结合嵌入相似性和不确定性进行本地自适应，Latte在理论和实践中都展现出对同分布客户端的有效利用和对异分布客户端的鲁棒性，并在去中心化基准测试中实现了优越性能，同时保持了低通信和计算成本。

> **摘要翻译:** 预训练视觉-语言模型的测试时自适应在解决测试期间的分布偏移方面受到了越来越多的关注。在这些方法中，基于记忆的算法因其无需训练的特性和利用历史测试数据的能力而脱颖而出。然而，现有的测试时自适应方法通常为单一领域设计，且需要大量数据。在联邦学习等去中心化设置中，将这些方法单独应用于每个客户端会受限于有限的测试数据，而通过服务器直接共享单一全局记忆则无法针对每个客户端独特的分布进行适当的个性化。为了解决这个问题，我们提出了Latte，一个新颖的框架，其中每个客户端维护一个本地记忆来存储其自身历史测试数据的嵌入，以及一个外部记忆来存储来自其他相关客户端的类原型。在通信过程中，每个客户端在服务器的协调下从相似客户端检索原型以扩展其记忆。对于本地自适应，Latte利用嵌入相似性和不确定性来增强模型性能。我们的理论分析表明，Latte能有效利用同分布客户端，同时对异分布客户端保持鲁棒性。在域适应和损坏基准上的广泛实验验证了Latte在去中心化设置中实现了卓越性能，同时只引入了可忽略的通信和计算成本。我们的代码可在 https://github.com/baowenxuan/Latte 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [936] [SLA-Centric Automated Algorithm Selection Framework for Cloud Environments](https://arxiv.org/abs/2507.21963)
> *以SLA为中心的云环境自动化算法选择框架*

*Siana Rizwan, Tasnim Ahmed, Salimur Choudhury* | **Category: cs.LG** | **Updated: 2025-07-29**

**Keywords:** SLA, 自动化算法选择, 云计算, 机器学习, 组合优化

**Comment:** 

> **TL;DR:** 本文提出了一个以SLA为中心的自动化算法选择框架，利用机器学习在资源受限的云环境中解决组合优化问题，以避免SLA违规。

**AI_Comments:** 这篇论文提出了一种创新的方法，将机器学习应用于云环境中以SLA为中心的算法选择，以优化资源利用并避免SLA违规。其亮点在于结合了集成学习、针对特定问题的应用（0-1背包问题）以及对模型可解释性的关注（SHAP）。该框架对于提高云服务效率和CSP盈利能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 云计算中的服务水平协议（SLA）违规会影响效率和云服务提供商（CSP）的盈利能力，因此需要一个SLA感知的自动化算法选择框架来解决资源受限云环境中的组合优化问题。

**Method:** 本文提出了一个SLA感知的自动化算法选择框架，用于资源受限云环境中的组合优化问题。该框架利用机器学习模型集成来预测性能，并根据SLA约束对算法-硬件对进行排名。研究将该框架应用于0-1背包问题，并构建了一个包含实例特定特征、内存使用、运行时和6种算法最优性差距的数据集。框架在分类和回归任务上进行了经验基准评估，并进行了消融研究，探讨了超参数、学习方法以及大型语言模型在回归中的有效性和基于SHAP的可解释性。

**Result:** 该框架成功应用于0-1背包问题，并在分类和回归任务中进行了评估。消融研究探索了超参数、学习方法、大型语言模型在回归中的有效性以及基于SHAP的可解释性的影响。

**Conclusion:** 本文提出了一个以SLA为中心的自动化算法选择框架，有效解决了云环境中组合优化问题中的SLA违规风险，并通过实证评估和消融研究验证了其性能和可解释性。

> **ai_Abstract:** 本文提出了一个以SLA为中心的自动化算法选择框架，旨在解决云环境中组合优化问题中的SLA违规风险。该框架利用机器学习模型集成来预测性能并根据SLA约束对算法-硬件对进行排名。研究将该框架应用于0-1背包问题，并构建了相关数据集。通过在分类和回归任务上的经验评估和消融研究，验证了框架的有效性，并分析了超参数、学习方法以及大型语言模型在回归中的作用和基于SHAP的可解释性。

> **摘要翻译:** 云计算提供按需资源访问，受消费者和云服务提供商（CSP）之间的服务水平协议（SLA）规范。SLA违规会影响效率和CSP的盈利能力。在这项工作中，我们提出了一个SLA感知的自动化算法选择框架，用于资源受限云环境中的组合优化问题。该框架使用机器学习模型集成来预测性能，并根据SLA约束对算法-硬件对进行排名。我们还将我们的框架应用于0-1背包问题。我们整理了一个数据集，包含实例特定特征以及6种算法的内存使用、运行时和最优性差距。作为经验基准，我们在分类和回归任务上评估了该框架。我们的消融研究探讨了超参数、学习方法和大型语言模型在回归中的有效性以及基于SHAP的可解释性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [548] [Replicating the behaviour of electric vehicle drivers using an agent-based reinforcement learning model](https://arxiv.org/abs/2507.21341)
> *使用基于代理的强化学习模型复制电动汽车驾驶员行为*

*Zixin Feng, Qunshan Zhao, Alison Heppenstall* | **Category: cs.MA** | **Updated: 2025-07-28**

**Keywords:** 电动汽车, 充电行为, 强化学习, 代理模型, 充电网络

**Comment:** 

> **TL;DR:** 本研究提出了一种多阶段强化学习框架，用于模拟电动汽车驾驶员在大地理区域内的充电行为，并通过识别“充电荒漠”和验证政策转变来解决现有模拟无法捕捉自适应行为和长途旅行需求的问题。

**AI_Comments:** 本研究的创新之处在于其首次将多阶段强化学习应用于私人电动汽车驾驶员的充电行为模拟，并关注大地理尺度下的长途旅行需求。这解决了现有研究的显著空白，并为城市规划者和政策制定者提供了识别充电基础设施不足区域（“充电荒漠”）的有效工具。模型的验证方法和对驾驶员自适应行为与有限理性的捕捉，使其结果更具说服力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管电动汽车充电网络迅速扩张，但其效率仍存在疑问。现有基于静态行为规则的模拟方法难以捕捉人类驾驶员的自适应行为。强化学习虽已引入电动汽车模拟，但主要集中于车队运营优化而非私人驾驶员的独立充电决策。此外，现有研究很少探索大地理尺度下的长途旅行充电行为，而这正是电动汽车驾驶员的主要担忧。

**Method:** 本研究提出了一种多阶段强化学习框架，用于模拟大地理区域内的电动汽车充电需求。该模型通过真实世界数据进行验证，并识别出最能反映实际驾驶员行为（包括自适应行为和有限理性）的训练阶段。

**Result:** 模拟结果识别出电动汽车驾驶员电量持续较低的关键“充电荒漠”。研究发现也突出了近期政策向高速公路走廊和城市边界沿线扩展快速充电枢纽的转变，以满足长途旅行的需求。

**Conclusion:** 通过多阶段强化学习模型，本研究成功复制了电动汽车驾驶员的自适应行为和有限理性，识别了充电基础设施的不足区域，并验证了当前政策在满足长途充电需求方面的有效性。

> **ai_Abstract:** 本研究提出了一种多阶段强化学习框架，旨在模拟大地理区域内电动汽车驾驶员的充电需求。该模型解决了传统模拟方法无法捕捉驾驶员自适应行为以及现有强化学习应用未关注私人驾驶员独立决策和长途旅行充电行为的不足。通过真实数据验证，模型成功复制了驾驶员的自适应行为和有限理性，并识别出“充电荒漠”。研究结果还支持了当前政策向高速公路沿线扩展快速充电站以满足长途旅行需求的趋势。

> **摘要翻译:** 尽管电动汽车（EV）充电网络迅速扩张，但其在满足电动汽车驾驶员日益增长的需求方面的效率仍存在疑问。以前依赖静态行为规则的基于模拟的方法难以捕捉人类驾驶员的自适应行为。尽管强化学习已引入电动汽车模拟研究，但其应用主要集中于优化车队运营，而非模拟做出独立充电决策的私人驾驶员。此外，长途旅行仍然是电动汽车驾驶员主要关注的问题。然而，现有模拟研究很少探索大地理尺度下的充电行为。为了解决这些空白，我们提出了一种多阶段强化学习框架，用于模拟大地理区域内的电动汽车充电需求。我们根据真实世界数据验证了该模型，并确定了最能反映实际驾驶员行为的训练阶段，该阶段捕捉了私人驾驶员的自适应行为和有限理性。基于模拟结果，我们还识别出电动汽车驾驶员电量持续较低的关键“充电荒漠”。我们的研究结果也强调了近期政策向高速公路走廊和城市边界沿线扩展快速充电枢纽的转变，以满足长途旅行的需求。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [562] [Agent-Based Exploration of Recommendation Systems in Misinformation Propagation](https://arxiv.org/abs/2507.21724)
> *基于智能体对推荐系统在错误信息传播中作用的探索*

*Lise Jakobsen, Anna Johanne Holden, Önder Gürcan, Özlem Özgöbek* | **Category: cs.MA** | **Updated: 2025-07-29**

**Keywords:** 错误信息传播, 推荐系统, 基于智能体建模, 在线社交网络, 算法设计

**Comment:** 14 pages, 3 figures, Social Simulation Conference 2025 (SSC'2025)

> **TL;DR:** 基于智能体的模拟研究表明，流行度推荐算法会显著放大错误信息传播，而协同过滤和内容推荐算法能更有效地限制错误信息暴露。

**AI_Comments:** 本文通过采用稳健的基于智能体建模方法，为推荐系统与错误信息传播之间复杂的相互作用提供了宝贵的见解。其发现，即流行度驱动的算法会加剧错误信息传播而其他方法可以缓解，对平台设计者至关重要。基于项目的协同过滤表现出改进的性能，是该研究的一个重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探究不同推荐算法对在线社交网络中错误信息传播的影响。

**Method:** 本研究采用基于智能体建模的方法，模拟了一个由异构智能体（包括普通用户、机器人和影响者）组成的合成环境，这些智能体通过带有推荐系统的社交网络进行互动。研究评估了四种推荐策略：基于流行度、协同过滤、基于内容过滤，以及一个随机基线。

**Result:** 研究结果表明，流行度驱动的算法显著放大了错误信息，而基于项目的协同过滤和基于内容的方法在限制虚假内容暴露方面更有效。其中，基于项目的协同过滤的表现优于相关文献中先前的报告。

**Conclusion:** 这些发现强调了算法设计在塑造在线信息暴露中的作用，并表明基于智能体建模可用于深入了解错误信息如何传播。

> **ai_Abstract:** 本研究利用基于智能体建模的方法，模拟了一个包含异构智能体（用户、机器人、影响者）的社交网络环境，以评估不同推荐算法对错误信息传播的影响。研究发现，基于流行度的算法会显著放大错误信息，而基于项目的协同过滤和基于内容的推荐方法能有效限制错误信息的暴露，且基于项目的协同过滤表现优于以往研究。这项研究强调了算法设计在塑造在线信息暴露中的关键作用，并展示了智能体建模在理解错误信息传播动态方面的实用性。

> **摘要翻译:** 本研究利用基于智能体建模的方法，探讨了各种推荐算法对在线社交网络中错误信息传播的影响。我们模拟了一个由异构智能体（包括普通用户、机器人和影响者）组成的合成环境，这些智能体通过带有推荐系统的社交网络进行互动。我们评估了四种推荐策略：基于流行度、协同过滤和基于内容的过滤，以及一个随机基线。我们的结果显示，流行度驱动的算法显著放大了错误信息，而基于项目的协同过滤和基于内容的方法在限制虚假内容暴露方面更有效。研究发现，基于项目的协同过滤的表现优于相关文献中先前的报告。这些发现突出了算法设计在塑造在线信息暴露中的作用，并表明基于智能体建模可用于深入了解错误信息如何传播。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [576] [Towards Cognitive Synergy in LLM-Based Multi-Agent Systems: Integrating Theory of Mind and Critical Evaluation](https://arxiv.org/abs/2507.21969)
> *迈向基于大型语言模型的多智能体系统中的认知协同：整合心智理论与批判性评估*

*Adam Kostka, Jarosław A. Chudziak* | **Category: cs.MA** | **Updated: 2025-07-29**

**Keywords:** 多智能体系统, 大型语言模型, 认知协同, 心智理论, 批判性评估

**Comment:** Accepted at CogSci 2025

> **TL;DR:** 本研究探索了在基于LLM的多智能体系统中，通过整合心智理论和批判性评估，实现人类般认知协同的方法，并证明其能提高协作质量和效率。

**AI_Comments:** 本文的创新点在于将人类协作中关键的“心智理论”和“批判性评估”机制引入到LLM-based多智能体系统中，以解决当前系统在高级协作认知上的不足。其重要性在于为构建更智能、更具协同能力的AI系统提供了新的思路和框架，特别是在复杂决策制定等领域具有潜在应用价值。研究通过实证案例验证了方法的有效性，但抽象中未提及具体实验设置或数据集，可能需要进一步的详细评估来验证其在不同场景下的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 基于大型语言模型（LLM）的多智能体系统在孤立任务中表现良好，但在需要更高阶认知的自适应协作方面表现不佳。当前人工系统缺乏人类团队实现协同所需的递归推理、结构化批判和推断他人心智状态的能力，这限制了它们进行复杂集体推理的能力。

**Method:** 本研究通过一个关于复杂决策制定的实证案例研究，探索了实现有效协作的认知过程，重点关注自适应心智理论（ToM）和系统性批判性评估。

**Result:** 实证案例研究表明，整合这些认知机制（心智理论和批判性评估）能够使智能体交互更加连贯、自适应和严谨。

**Conclusion:** 本文通过提出一个模拟人类协作推理多智能体系统的结构化框架，为认知科学和人工智能研究做出了贡献。它强调了动态心智理论和批判性评估在提升多智能体系统应对复杂现实世界挑战能力方面的重要性。

> **ai_Abstract:** 本研究旨在解决基于大型语言模型（LLM）的多智能体系统在协作中缺乏高级认知能力的问题。论文提出并探索了整合心智理论（ToM）和系统性批判性评估这两种认知机制，以期在LLM-based MAS中实现类似人类的认知协同。通过实证案例研究，结果显示这些机制的整合显著提高了智能体交互的连贯性、自适应性和严谨性，为开发能够有效应对复杂现实世界挑战的协作式AI系统提供了结构化框架。

> **摘要翻译:** 最近，多智能体系统（MAS）领域日益受到关注，研究人员正致力于开发能够进行高效集体推理的人工智能。基于大型语言模型（LLM）的智能体在独立任务中表现良好，但在自适应协作所需的更高阶认知方面却力不从心。人类团队实现协同不仅通过知识共享，还通过递归推理、结构化批判以及推断他人心智状态的能力。当前的人工系统缺乏这些基本机制，限制了它们进行复杂集体推理的能力。这项工作探索了实现有效协作的认知过程，重点关注自适应心智理论（ToM）和系统性批判性评估。我们研究了三个关键问题。首先，建模他人视点能力如何增强协调并减少冗余推理？其次，结构化批判在多大程度上通过识别逻辑缺陷和减轻偏见来提高推理质量？第三，这些机制的相互作用能否带来涌现的认知协同，使系统的集体智能超越其各部分的总和。通过一个关于复杂决策制定的实证案例研究，我们表明这些认知机制的整合能够带来更连贯、自适应和严谨的智能体交互。本文通过提出一个模拟人类协作推理多智能体系统的结构化框架，为认知科学和人工智能研究做出了贡献。它强调了动态心智理论和批判性评估在提升多智能体系统应对复杂现实世界挑战能力方面的重要性。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [590] [Validating Generative Agent-Based Models of Social Norm Enforcement: From Replication to Novel Predictions](https://arxiv.org/abs/2507.22049)
> *验证基于生成式智能体的社会规范执行模型：从复现到新颖预测*

*Logan Cross, Nick Haber, Daniel L. K. Yamins* | **Category: cs.MA** | **Updated: 2025-07-29**

**Keywords:** 生成式智能体模型, 社会规范执行, 大语言模型, 验证框架, 社会困境

**Comment:** 

> **TL;DR:** 本研究提出了一种两阶段验证方法，用于基于大语言模型（LLM）的生成式智能体模型，以模拟人类社会行为。通过复现经典心理学实验并进行新颖预测，研究发现个性化差异和心智理论对智能体行为至关重要，并展示了此类模型在理解人类社会行为方面的潜力。

**AI_Comments:** 该论文的创新之处在于提出了一个系统的两阶段验证框架，解决了当前基于LLM的生成式智能体模型在模拟人类社会行为时面临的关键验证挑战。通过结合心理学经典范式进行复现和新颖预测，有效地证明了LLM智能体在捕捉复杂社会行为方面的潜力。特别指出个性化差异和心智理论是关键认知组件，这为未来构建更真实、更具解释力的社会模拟模型提供了重要指导。论文不仅提供了验证方法，还展示了模型生成新颖且可检验见解的能力，对于推动计算社会科学和人工智能领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大语言模型（LLM）的进步，人们越来越关注使用它们通过生成式智能体建模（GABM）来模拟人类社会行为。然而，验证这些模型仍然是一个关键挑战。

**Method:** 本研究提出了一种系统的两阶段验证方法，利用心理学文献中的社会困境范式。首先，识别LLM智能体在混合动机环境下重现已知人类行为所需的认知组件，这些行为来自两篇里程碑式的论文。然后，使用经过验证的架构来模拟新颖条件。通过模型比较不同的认知架构来确定关键组件。

**Result:** 模型比较表明，基于角色的个体差异和心智理论能力对于复现第三方惩罚（TPP）作为信任度的昂贵信号至关重要。对于公共物品博弈的第二项研究，该架构能够复现通过流言传播声誉信息而增加合作的行为。然而，需要额外的战略组件才能复现允许排斥和流言条件下合作率的额外提升。在惩罚匿名的环境下，TPP率显著下降，但仍有大量TPP存在，表明声誉和内在道德动机都在这种行为中发挥作用。公开讨论时期进一步增加了公共物品博弈的贡献，使群体能够发展合作的社会规范。

**Conclusion:** 这项工作为验证生成式智能体模型提供了一个框架，同时展示了它们在生成关于人类社会行为的新颖且可检验的见解方面的潜力。

> **ai_Abstract:** 本研究提出了一种验证基于大语言模型（LLM）的生成式智能体模型（GABM）的两阶段系统方法，旨在模拟人类社会行为。该方法首先通过复现心理学经典社会困境实验来识别智能体所需的认知组件（如个性化差异和心智理论），然后利用验证后的架构进行新颖预测。研究发现，这些模型能有效复现第三方惩罚和公共物品博弈中的合作行为，并揭示了声誉和内在动机在社会规范执行中的作用。此外，通过引入公开讨论等干预措施，展示了模型在生成可检验的人类社会行为新见解方面的潜力，为GABM的验证提供了一个实用框架。

> **摘要翻译:** 随着大语言模型（LLM）的进步，人们越来越关注使用它们通过生成式智能体建模（GABM）来模拟人类社会行为。然而，验证这些模型仍然是一个关键挑战。我们提出了一种系统的两阶段验证方法，利用心理学文献中的社会困境范式，首先识别LLM智能体在混合动机环境下重现两篇里程碑论文中已知人类行为所需的认知组件，然后使用经过验证的架构来模拟新颖条件。我们对不同认知架构的模型比较表明，基于角色的个体差异和心智理论能力对于复现作为信任度昂贵信号的第三方惩罚（TPP）至关重要。对于公共物品博弈的第二项研究，该架构能够复现通过流言传播声誉信息而增加合作的行为。然而，需要额外的战略组件才能复现允许排斥和流言条件下合作率的额外提升。然后，我们用经过验证的生成式智能体测试了每篇论文的新颖预测。我们发现，在惩罚匿名的环境下，TPP率显著下降，但仍有大量TPP存在，这表明声誉和内在道德动机都在这种行为中发挥作用。对于第二篇论文，我们引入了一项新颖的干预措施，发现公共物品博弈回合前的公开讨论时期进一步增加了贡献，使群体能够发展合作的社会规范。这项工作为验证生成式智能体模型提供了一个框架，同时展示了它们在生成关于人类社会行为的新颖且可检验的见解方面的潜力。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [1] [Research Challenges and Progress in the End-to-End V2X Cooperative Autonomous Driving Competition](https://arxiv.org/abs/2507.21610)
> *端到端V2X协同自动驾驶竞赛中的研究挑战与进展*

*Ruiyang Hao, Haibao Yu, Jiaru Zhong, Chuanye Wang, Jiahao Wang, Yiming Kan, Wenxian Yang, Siqi Fan, Huilin Yin, Jianing Qiu, Yao Mu, Jiankai Sun, Li Chen, Walter Zimmer, Dandan Zhang, Shanghang Zhang, Mac Schwager, Wei Huang, Xiaobo Zhang, Ping Luo, Zaiqing Nie* | **Category: cs.RO, cs.CV, I.4.9** | **Updated: 2025-07-29**

**Keywords:** V2X, 自动驾驶, 挑战赛, 协同驾驶, 数据融合

**Comment:** 10 pages, 4 figures, accepted by ICCVW

> **TL;DR:** 本文介绍了“端到端V2X协同自动驾驶挑战赛”的设计和成果，旨在推动V2X技术在自动驾驶中的应用，并分析了关键研究问题和新兴技术趋势。

**AI_Comments:** 本文通过组织一个具有实际约束的挑战赛，有效地推动了V2X协同自动驾驶领域的研究进展。这种以竞赛为驱动的研究模式，不仅提供了一个统一的基准，还能够识别出当前技术面临的关键挑战和新兴的解决方案趋势，具有很高的实践指导意义和创新性。

<details>
  <summary>Details</summary>

**Motivation:** 随着自动驾驶技术的快速发展，车联网（V2X）通信作为扩展感知范围和增强驾驶安全的关键技术而出现。然而，在有限通信带宽和动态环境等实际约束下，整合来自车辆和基础设施的多源传感器数据面临重大技术挑战。为促进该领域的研究，组织了此挑战赛。

**Method:** 组织了“端到端V2X协同自动驾驶挑战赛”，设有协作时间感知和协作端到端规划两个赛道。该挑战赛基于UniV2X框架和V2X-Seq-SPD数据集构建。

**Result:** 挑战赛吸引了全球30多支队伍参与，并建立了评估协同驾驶系统的统一基准。论文描述了挑战赛的设计和成果，强调了包括带宽感知融合、鲁棒多智能体规划和异构传感器集成在内的关键研究问题，并分析了顶级解决方案中的新兴技术趋势。

**Conclusion:** 通过解决通信和数据融合中的实际约束，该挑战赛有助于可扩展和可靠的V2X协同自动驾驶系统的发展。

> **ai_Abstract:** 本文介绍了“端到端V2X协同自动驾驶挑战赛”的设计与成果。该挑战赛旨在解决V2X技术在自动驾驶中集成多源传感器数据所面临的实际挑战，如通信带宽限制。挑战赛分为协作时间感知和协作端到端规划两个赛道，并基于UniV2X框架和V2X-Seq-SPD数据集进行。它吸引了众多团队参与，建立了统一的评估基准，并揭示了带宽感知融合、鲁棒多智能体规划和异构传感器集成等关键研究问题，从而推动了可扩展和可靠的V2X协同自动驾驶系统的发展。

> **摘要翻译:** 随着自动驾驶技术的快速发展，车联网（V2X）通信已成为通过提供超视距可见性来扩展感知范围和增强驾驶安全的关键使能技术。然而，在有限通信带宽和动态环境等实际约束下，整合来自车辆和基础设施的多源传感器数据面临重大的技术挑战。为促进该领域的研究，我们组织了“端到端V2X协同自动驾驶挑战赛”，该挑战赛设有协作时间感知和协作端到端规划两个赛道。挑战赛基于UniV2X框架和V2X-Seq-SPD数据集构建，吸引了全球30多支队伍的参与，并建立了评估协同驾驶系统的统一基准。本文描述了挑战赛的设计和成果，强调了包括带宽感知融合、鲁棒多智能体规划和异构传感器集成在内的关键研究问题，并分析了顶级解决方案中的新兴技术趋势。通过解决通信和数据融合中的实际约束，该挑战赛有助于可扩展和可靠的V2X协同自动驾驶系统的发展。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [43] [Adaptive Prior Scene-Object SLAM for Dynamic Environments](https://arxiv.org/abs/2507.21709)
> *动态环境下自适应先验场景-物体SLAM*

*Haolan Zhang, Thanh Nguyen Canh, Chenghao Li, Nak Young Chong* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** SLAM, 动态环境, 定位漂移, 可靠性评估, 姿态优化

**Comment:** Accepted by IEEE The 2025 IEEE International Conference on Real-time
  Computing and Robotics

> **TL;DR:** 本文提出了一种新的场景-物体SLAM方法，通过可靠性评估框架和姿态优化策略，显著提高了动态环境下SLAM的定位精度和系统鲁棒性，解决了传统方法在动态场景中的漂移问题。

**AI_Comments:** 这篇论文的创新点在于提出了一个结合当前帧质量和可靠参考帧场景变化的可靠性评估框架，以及针对不可靠姿态估计的优化策略，有效解决了动态环境下SLAM的长期难题。其重要性在于提升了自主系统在复杂动态场景下的定位能力，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统SLAM方法假设环境是静态的，在动态场景中会出现严重的定位漂移。尽管现有方法有所改进，但在剧烈视角变化和移动物体特征不佳的情况下，定位漂移问题依然存在。

**Method:** 提出了一种新颖的基于场景-物体的可靠性评估框架，该框架通过当前帧质量指标和相对于可靠参考帧的场景变化来全面评估SLAM稳定性。此外，为了解决姿态估计不可靠时现有系统缺乏错误校正机制的问题，采用了一种姿态优化策略，利用可靠帧的信息来优化相机姿态估计。

**Result:** 在TUM RGB-D数据集上的大量实验表明，该方法在挑战性动态场景下显著提高了定位精度和系统鲁棒性。

**Conclusion:** 本文提出的自适应先验场景-物体SLAM方法通过其可靠性评估框架和姿态优化策略，有效解决了动态环境中SLAM的定位漂移问题，并显著提升了系统的定位精度和鲁棒性。

> **ai_Abstract:** 本文提出了一种针对动态环境的自适应先验场景-物体SLAM方法，旨在解决传统SLAM在动态场景中的定位漂移问题。该方法引入了一个基于场景-物体的可靠性评估框架，结合当前帧质量和场景变化来评估SLAM稳定性，并采用姿态优化策略来修正不可靠的姿态估计。实验结果表明，该方法显著提升了在挑战性动态场景下的定位精度和系统鲁棒性。

> **摘要翻译:** 视觉同步定位与建图（SLAM）在自主系统的实时定位中起着至关重要的作用。然而，假设环境是静态的传统SLAM方法，在动态场景中经常遭受显著的定位漂移。尽管最近的进展改善了此类环境中的SLAM性能，但这些系统仍然面临定位漂移的困扰，特别是由于突然的视角变化和特征不佳的移动物体。在本文中，我们提出了一种新颖的基于场景-物体的可靠性评估框架，该框架通过当前帧质量指标和相对于可靠参考帧的场景变化来全面评估SLAM稳定性。此外，为了解决现有系统在姿态估计变得不可靠时缺乏错误校正机制的问题，我们采用了一种姿态优化策略，利用可靠帧的信息来优化相机姿态估计，有效减轻了动态干扰的不利影响。在TUM RGB-D数据集上的大量实验表明，我们的方法在挑战性动态场景下实现了定位精度和系统鲁棒性的显著提高。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [45] [VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback](https://arxiv.org/abs/2507.17294)
> *VLA-Touch：通过双层触觉反馈增强视觉-语言-动作模型*

*Jianxin Bi, Kevin Yuchen Ma, Ce Hao, Mike Zheng Shou, Harold Soh* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 触觉反馈, 视觉-语言-动作模型, 机器人操作, 双层整合, 扩散控制器

**Comment:** 19 pages, 5 figures

> **TL;DR:** VLA-Touch 通过双层触觉反馈增强视觉-语言-动作模型，以提高机器人处理接触密集型任务的能力。

**AI_Comments:** 该论文的创新之处在于，它在不需对基础VLA模型进行微调的情况下，实现了触觉反馈的双层整合。这有效解决了多模态数据集缺乏的挑战，并显著提升了VLA模型在接触密集型任务中的表现。

<details>
  <summary>Details</summary>

**Motivation:** 最先进的视觉-语言-动作（VLA）模型缺乏解释和使用触觉信号的能力，这限制了它们在接触密集型任务中的有效性。由于缺乏大型多模态数据集，将触觉反馈整合到这些系统中具有挑战性。

**Method:** 本文提出了VLA-Touch方法，该方法通过触觉感知增强通用机器人策略，而无需对基础VLA进行微调。该方法引入了两项关键创新：1）一个利用预训练触觉-语言模型的管道，为高层任务规划提供语义触觉反馈；2）一个基于扩散的控制器，利用触觉信号细化VLA生成的动作，以实现接触密集型操作。

**Result:** 通过实际实验，我们证明了双层触觉反馈的整合提高了任务规划效率，同时增强了执行精度。

**Conclusion:** 双层触觉反馈的整合显著提高了任务规划效率并增强了操作执行精度。

> **ai_Abstract:** VLA-Touch 旨在解决视觉-语言-动作（VLA）模型在接触密集型任务中的局限性。该方法通过引入双层触觉反馈来增强通用机器人策略，且无需对基础VLA进行微调。VLA-Touch 的核心创新包括：利用预训练触觉-语言模型为高层任务规划提供语义触觉反馈，以及使用基于扩散的控制器利用触觉信号细化VLA生成的动作。实际实验证明，这种双层触觉反馈整合显著提高了任务规划效率并增强了执行精度。

> **摘要翻译:** 触觉反馈被普遍认为是与物理世界进行有效交互的关键。然而，最先进的视觉-语言-动作（VLA）模型缺乏解释和使用触觉信号的能力，这限制了它们在接触密集型任务中的有效性。由于缺乏大型多模态数据集，将触觉反馈整合到这些系统中具有挑战性。我们提出了VLA-Touch，一种在不微调基础VLA的情况下，通过触觉感知增强通用机器人策略的方法。我们的方法引入了两项关键创新：(1) 一个利用预训练触觉-语言模型的管道，为高层任务规划提供语义触觉反馈；(2) 一个基于扩散的控制器，利用触觉信号细化VLA生成的动作，以实现接触密集型操作。通过实际实验，我们证明了双层触觉反馈的整合提高了任务规划效率，同时增强了执行精度。代码已在提供的URL开源。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [69] [Bayesian Optimization applied for accelerated Virtual Validation of the Autonomous Driving Function](https://arxiv.org/abs/2507.22769)
> *贝叶斯优化在自动驾驶功能加速虚拟验证中的应用*

*Satyesh Shanker Awasthi, Mohammed Irshadh Ismaaeel Sathyamangalam Imran, Stefano Arrigoni, Francesco Braghin* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-30**

**Keywords:** 贝叶斯优化, 自动驾驶, 虚拟验证, 关键场景, 仿真

**Comment:** 

> **TL;DR:** 本文提出使用贝叶斯优化加速自动驾驶功能的虚拟验证，能以更少仿真次数识别危险场景。

**AI_Comments:** 这篇论文的创新点在于将贝叶斯优化应用于自动驾驶功能的虚拟验证，有效解决了传统穷举仿真验证的效率问题。其重要性在于能够显著加速危险场景的发现，从而提高自动驾驶系统的安全性和验证效率。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶功能（ADFs）的严格验证对于确保自动驾驶汽车（AVs）的安全性和公众接受度至关重要。然而，当前依赖仿真的验证方法在探索巨大参数空间时计算成本高昂且耗时。

**Method:** 引入了一个基于贝叶斯优化（BO）的框架，用于加速关键场景的发现。

**Result:** 该框架在基于模型预测控制器（MPC）的运动规划器上表现出有效性，能以比暴力实验设计（DoE）方法少几个数量级的仿真识别出越野事件等危险情况。此外，该研究还探讨了框架在高维参数空间中的可扩展性及其识别多个不同关键区域的能力。

**Conclusion:** 贝叶斯优化框架能够显著加速自动驾驶功能的虚拟验证，有效识别关键危险场景，并具有良好的可扩展性。

> **ai_Abstract:** 本文提出了一种基于贝叶斯优化（BO）的框架，旨在加速自动驾驶功能（ADFs）的虚拟验证，以克服当前仿真验证中探索庞大参数空间所面临的计算成本高和耗时问题。研究表明，该框架能以显著减少的仿真次数有效识别出危险场景，如越野事件，并且在高维参数空间中展现出良好的可扩展性以及识别多个关键区域的能力。

> **摘要翻译:** 自动驾驶功能（ADFs）的严格验证和确认（V&V）对于确保自动驾驶汽车（AVs）的安全性和公众接受度至关重要。目前的验证严重依赖于仿真，以在车辆的运行设计域（ODD）内实现足够的测试覆盖，但穷尽探索可能的场景的巨大参数空间计算成本高昂且耗时。这项工作引入了一个基于贝叶斯优化（BO）的框架，以加速关键场景的发现。我们在一个基于模型预测控制器（MPC）的运动规划器上展示了该框架的有效性，结果表明它识别危险情况（例如越野事件）所需的仿真次数比暴力实验设计（DoE）方法少几个数量级。此外，本研究还调查了该框架在高维参数空间中的可扩展性及其识别作为案例研究的运动规划器ODD内多个不同关键区域的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [93] [Multi-UAV Deployment in Obstacle-Cluttered Environments with LOS Connectivity](https://arxiv.org/abs/2507.21772)
> *多无人机在障碍物密集环境中的部署与视距连接*

*Yuda Chen, Shuaikang Wang, Jie Li, Meng Guo* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 多无人机部署, 视距连接, 障碍物环境, RRT*算法, 模型预测控制

**Comment:** iros2025

> **TL;DR:** 本文提出了一种在障碍物密集环境中部署多无人机并维持视距连接的方法，结合了基于最小边RRT*的拓扑设计和分布式模型预测控制，确保了碰撞避免和团队视距连接。

**AI_Comments:** 该论文的创新之处在于其结合了拓扑优化（基于RRT*的约束搜索）和动态控制（分布式MPC），以解决多无人机在复杂障碍物环境中部署和通信的难题。特别是，它为非线性约束（如视距连接）提供了理论保证，而非仅仅依赖近似，这增强了方法的鲁棒性和可靠性。硬件实验的验证也提升了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在障碍物密集的复杂环境中，多无人机协同操作时，由于障碍物阻碍，通信受限，导致难以建立可靠的通信网络。现有解决方案（通过中继无人机构建多跳网络）面临两大挑战：如何设计多跳网络结构以及如何在协同运动中保持连接性。

**Method:** 首先，提出了一种基于最小边RRT*算法的高效约束搜索方法，用于寻找需要较少无人机进行部署的生成树拓扑结构。其次，为实现部署，提出了一种分布式模型预测控制策略，用于在线运动协调，该策略明确地考虑了无人机间距、无人机-障碍物距离以及视距（LOS）连接约束。

**Result:** 通过所提出的方法，能够找到所需无人机数量更少的部署拓扑，并确保所有无人机轨迹无碰撞，同时始终保持团队范围内的视距连接。在3D山谷状环境中的大量仿真以及硬件实验验证了其在部署位置在线变化时的动态适应性。

**Conclusion:** 本文提出的基于最小边RRT*的约束搜索方法和分布式模型预测控制策略，有效地解决了在障碍物密集环境中多无人机部署和视距连接的挑战，并提供了理论保证，通过仿真和硬件实验验证了其有效性和动态适应性。

> **ai_Abstract:** 本文针对多无人机在障碍物密集环境中的部署和通信挑战，提出了一套解决方案。首先，利用基于最小边RRT*的约束搜索方法优化了多跳网络拓扑结构，以减少所需无人机数量。其次，开发了一种分布式模型预测控制策略，用于在线运动协调，该策略在考虑无人机间距和障碍物规避的同时，特别确保了全程的视距连接，并提供了理论上的碰撞避免和连接性保证。仿真和硬件实验均验证了该方法的有效性和动态适应性。

> **摘要翻译:** 一个可靠的通信网络对于在障碍物密集环境中运行的多无人机至关重要，因为障碍物经常导致通信受限。一个常见的解决方案是部署中间无人机通过多跳网络中继信息，这带来了两个挑战：（i）如何设计多跳网络的结构；（ii）如何在协同运动中保持连接性。为此，这项工作首先提出了一种基于最小边RRT*算法的高效约束搜索方法，以找到一种需要较少无人机用于部署任务的生成树拓扑结构。然后，为了实现这种部署，提出了一种分布式模型预测控制策略，用于在线运动协调。它不仅明确地包含了无人机间距和无人机-障碍物距离约束，还包含了视距（LOS）连接约束。众所周知，这些约束是非线性的，并且通常通过各种近似方法来解决。相比之下，这项工作提供了理论保证，确保所有智能体轨迹在任何时候都无碰撞，并具有团队范围内的视距连接。在3D山谷状环境中进行了大量仿真，同时硬件实验验证了其在部署位置在线变化时的动态适应性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [101] [Humanoid Occupancy: Enabling A Generalized Multimodal Occupancy Perception System on Humanoid Robots](https://arxiv.org/abs/2507.20217)
> *人形机器人占用感知：实现通用多模态占用感知系统*

*Wei Cui, Haoyu Wang, Wenkang Qin, Yijie Guo, Gang Han, Wen Zhao, Jiahang Cao, Zhang Zhang, Jiaru Zhong, Jingkai Sun, Pihai Sun, Shuai Shi, Botuo Jiang, Jiahao Ma, Jiaxu Wang, Hao Cheng, Zhichao Liu, Yang Wang, Zheng Zhu, Guan Huang, Jian Tang, Qiang Zhang* | **Category: cs.RO, cs.AI, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 人形机器人, 占用感知, 多模态融合, 环境理解, 数据集

**Comment:** Tech Report

> **TL;DR:** 本文介绍了“Humanoid Occupancy”，一个通用多模态占用感知系统，旨在为人形机器人提供全面的环境理解能力，并为此创建了首个全景占用数据集，以促进人形机器人的广泛部署。

**AI_Comments:** 这项工作具有创新性，因为它解决了在人形机器人上实现占用感知面临的特定挑战，例如运动学干扰，并提供了一个通用的解决方案，而非局限于特定场景。创建首个用于人形机器人的全景占用数据集是一项重要贡献，为该新兴领域的未来研究和开发提供了宝贵的资源。该系统对软硬件集成以及多模态融合的关注，凸显了其为复杂现实世界场景提供的实用且鲁棒的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 当前人形机器人技术迅速发展，但视觉感知模块多为特定场景定制。基于占用空间的表示被认为适合人形机器人，但实现存在挑战。因此，需要一个通用多模态占用感知系统，以实现全面环境理解。

**Method:** 本文提出了“Humanoid Occupancy”系统，该系统集成了硬件、软件、数据采集设备和专用标注流程。它采用先进的多模态融合技术，生成包含占用状态和语义标签的基于网格的占用输出。该系统解决了运动学干扰和遮挡等挑战，建立了有效的传感器布局策略，并开发了首个专门用于人形机器人的全景占用数据集。其网络架构结合了多模态特征融合和时间信息整合。

**Result:** “Humanoid Occupancy”系统为人形机器人提供了有效的环境感知能力。它为标准化通用视觉模块奠定了技术基础。此外，研究团队还开发了第一个专门用于人形机器人的全景占用数据集。

**Conclusion:** “Humanoid Occupancy”系统为人形机器人提供了有效的环境感知，为通用视觉模块的标准化奠定了基础，并为人形机器人在复杂现实世界场景中的广泛部署铺平了道路。

> **ai_Abstract:** 本文介绍了“Humanoid Occupancy”，一个专为人形机器人设计的通用多模态占用感知系统。该系统整合了硬件、软件、数据采集和标注流程，并利用先进的多模态融合技术生成包含语义标签的网格化占用输出。为解决人形机器人的独特挑战，如运动学干扰和遮挡，该研究还开发了首个用于人形机器人的全景占用数据集。该系统旨在提供鲁棒的环境感知能力，标准化视觉模块，并促进人形机器人在复杂现实世界场景中的广泛部署。

> **摘要翻译:** 人形机器人技术正在迅速发展，制造商推出了针对特定场景的各种异构视觉感知模块。在各种感知范式中，基于占用空间的表示已被广泛认为是特别适合人形机器人，因为它提供了全面环境理解所必需的丰富语义和3D几何信息。在这项工作中，我们提出了Humanoid Occupancy，一个通用的多模态占用感知系统，它集成了硬件和软件组件、数据采集设备和专用的标注流程。我们的框架采用先进的多模态融合技术，生成基于网格的占用输出，编码占用状态和语义标签，从而为任务规划和导航等下游任务实现整体环境理解。为了解决人形机器人的独特挑战，我们克服了运动学干扰和遮挡等问题，并建立了有效的传感器布局策略。此外，我们开发了第一个专门用于人形机器人的全景占用数据集，为该领域的未来研究和开发提供了宝贵的基准和资源。网络架构结合了多模态特征融合和时间信息整合，以确保鲁棒的感知。总的来说，Humanoid Occupancy为人形机器人提供了有效的环境感知，并为标准化通用视觉模块奠定了技术基础，为人形机器人在复杂现实世界场景中的广泛部署铺平了道路。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [147] [MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects](https://arxiv.org/abs/2507.21796)
> *MoDeSuite：用于可变形物体移动操作基准测试的机器人学习任务套件*

*Yuying Zhang, Kevin Sebastian Luck, Francesco Verdoja, Ville Kyrki, Joni Pajarinen* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 移动操作, 可变形物体, 机器人学习, 基准测试, MoDeSuite

**Comment:** 

> **TL;DR:** MoDeSuite是一个新的机器人学习任务套件，旨在为涉及可变形物体的移动操作提供标准化基准，填补了现有刚性物体基准的空白，并展示了在仿真和真实世界中的应用潜力。

**AI_Comments:** MoDeSuite的创新之处在于其首次为涉及可变形物体的移动操作提供了标准化基准，填补了该领域的一个重要空白。它不仅提出了多样化的任务，还通过实际的算法评估和仿真到真实世界的部署，证明了其作为研究工具的实用性和潜力。这将极大地促进机器人学习在复杂真实世界环境中处理可变形物体的能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器人学习算法在操作可变形物体方面仍面临重大挑战，且缺乏针对涉及可变形物体的移动操作任务的标准化基准。

**Method:** 引入MoDeSuite，一个包含八个独特移动操作任务（涵盖弹性物体和可变形物体）的任务套件。通过训练两种最先进的强化学习算法和两种模仿学习算法来评估其性能，并在仿真中展示困难。此外，将训练好的策略部署到真实世界的Spot机器人上，以展示从仿真到真实的迁移潜力。

**Result:** MoDeSuite成功地作为第一个移动操作可变形物体任务套件被引入。通过评估展示了最先进的强化学习和模仿学习算法在这些任务中的表现和遇到的困难。成功地将训练策略从仿真迁移到真实世界的Spot机器人上。

**Conclusion:** MoDeSuite填补了移动操作中可变形物体标准化基准的空白，并有望在涉及可变形物体的移动操作领域开辟新的研究方向。

> **ai_Abstract:** MoDeSuite是一个新颖的机器人学习任务套件，专门为涉及可变形物体的移动操作基准测试而设计。该套件包含八项任务，涵盖弹性体和可变形物体，旨在解决现有机器人学习算法在处理此类物体时的挑战以及缺乏标准化基准的问题。研究人员通过在仿真中训练和评估了四种主流学习算法，并成功将策略部署到真实机器人上，证明了其在仿真到真实迁移方面的潜力。MoDeSuite预计将推动可变形物体移动操作领域的研究。

> **摘要翻译:** 移动操作是机器人在多样化、真实世界环境中运行的关键能力。然而，操作可变形物体和材料对现有机器人学习算法来说仍然是一个重大挑战。尽管已经提出了各种基准来评估刚性物体的操作策略，但仍然明显缺乏解决涉及可变形物体的移动操作任务的标准化基准。
为了解决这一空白，我们引入了MoDeSuite，这是第一个专为机器人学习设计的移动操作可变形物体任务套件。MoDeSuite由八个独特的移动操作任务组成，涵盖弹性物体和可变形物体，每个任务都呈现出受真实世界机器人应用启发而产生的独特挑战。成功完成这些任务需要机器人底座和机械臂之间的有效协作，以及利用物体可变形性的能力。为了评估和演示所提出的基准的使用，我们训练了两种最先进的强化学习算法和两种模仿学习算法，突出了遇到的困难，并展示了它们在仿真中的性能。此外，我们通过将训练好的策略直接部署到真实世界的Spot机器人上，展示了该套件的实际相关性，展示了从仿真到真实的迁移潜力。我们期望MoDeSuite将在涉及可变形物体的移动操作领域开辟一个新的研究领域。更多详细信息、代码和视频请访问https://sites.google.com/view/modesuite/home。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [170] [Integration of Large Language Models within Cognitive Architectures for Autonomous Robots](https://arxiv.org/abs/2309.14945)
> *大型语言模型在自主机器人认知架构中的集成*

*Miguel Á. González-Santamarta, Irene González-Fernández, Francisco J. Rodríguez-Lera, Ángel Manuel Guerrero-Higueras, Vicente Matellán-Olivera* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 认知架构, 自主机器人, 自然语言规划, MERLIN2

**Comment:** 9 pages, 6 figures, 2 tables, Submitted to ROBOT 2025 (8th Iberian
  Robotics Conference)

> **TL;DR:** 本文提出将大型语言模型（LLMs）集成到自主机器人认知架构MERLIN2中，以解决传统符号推理系统在定义领域和问题时的困难，实现基于自然语言的规划系统，尽管性能略逊于传统方法，但显著增强了自然语言交互能力。

**AI_Comments:** 本文的创新点在于将LLMs引入机器人认知架构，以解决传统符号推理在领域定义上的局限性，并实现了基于自然语言的规划。其重要性在于为机器人提供了更直观、更自然的交互方式。尽管在性能上仍有提升空间，但其在自然语言交互方面的优势预示了未来机器人系统发展的一个重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的认知架构中使用的符号推理系统在定义领域和问题时存在困难且容易出错。

**Method:** 本文提出将大型语言模型（LLMs）集成到基于ROS 2的认知架构MERLIN2中，用于自主机器人。具体而言，展示了如何设计、开发和部署LLM的推理能力到MERLIN2的审慎过程中，将审慎系统从基于PDDL的规划系统更新为自然语言规划系统。

**Result:** 通过定量和定性评估，结果显示经典方法实现了更好的性能，但所提出的解决方案通过自然语言提供了增强的交互能力。

**Conclusion:** 尽管基于LLM的自然语言规划系统在性能上可能不如传统方法，但它显著提升了自主机器人与用户的自然语言交互能力。

> **ai_Abstract:** 本文针对传统认知架构中符号推理系统定义领域和问题困难的问题，提出将大型语言模型（LLMs）集成到自主机器人认知架构MERLIN2中。通过这种集成，MERLIN2的审慎系统从基于PDDL的规划器转变为自然语言规划系统。尽管评估结果显示经典方法在性能上表现更好，但所提出的LLM集成方案显著增强了机器人通过自然语言进行交互的能力。

> **摘要翻译:** 符号推理系统已被用于认知架构中，以提供推理和规划能力。然而，定义领域和问题已被证明是困难且容易出错的。此外，大型语言模型（LLMs）已成为处理不同任务的自然语言工具。在本文中，我们提出使用LLMs来解决这些问题。通过这种方式，本文提出了将LLMs集成到ROS 2集成的自主机器人认知架构MERLIN2中。具体而言，我们展示了如何利用LLMs的推理能力在MERLIN2的审慎过程中进行设计、开发和部署。因此，审慎系统从基于PDDL的规划系统更新为自然语言规划系统。这项提议通过定量和定性评估，衡量了将LLMs整合到认知架构中的影响。结果表明，经典方法实现了更好的性能，但所提出的解决方案通过自然语言提供了增强的交互能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [204] [Interactive Adversarial Testing of Autonomous Vehicles with Adjustable Confrontation Intensity](https://arxiv.org/abs/2507.21814)
> *自动驾驶汽车可调对抗强度的交互式对抗测试*

*Yicheng Guo, Chengkai Xu, Jiaqi Liu, Hao Zhang, Peng Hang, Jian Sun* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 自动驾驶, 对抗测试, 交互式评估, 鲁棒性, ExamPPO

**Comment:** 

> **TL;DR:** 本文提出ExamPPO，一个交互式对抗测试框架，通过将周围车辆建模为智能考官并引入对抗因子来调节测试难度，有效评估自动驾驶汽车的鲁棒性和决策弱点。

**AI_Comments:** ExamPPO的创新之处在于引入了“对抗因子”来连续调节测试强度，这使得测试过程更加灵活和细致。同时，将周围车辆建模为“智能考官”并结合多头注意力网络，提升了测试场景的交互性和真实性。该方法为自动驾驶汽车的安全评估提供了一个更全面和可控的工具，对于提升自动驾驶系统的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自动驾驶汽车测试方法存在对高质量测试数据依赖性强、交互能力弱和对抗鲁棒性低等局限性，因此需要一种新的测试方法。

**Method:** 本文提出了ExamPPO，一个交互式对抗测试框架。该框架将周围车辆（SV）建模为智能考官，配备多头注意力增强的策略网络，以实现情境感知和持续的行为干预。引入了一个标量对抗因子来调节对抗行为的强度，实现测试难度的连续细粒度调整。结合结构化评估指标，ExamPPO系统地探测自动驾驶汽车在不同场景和策略下的鲁棒性。

**Result:** 广泛的实验表明，ExamPPO能够有效调节对抗行为，揭示被测试自动驾驶汽车的决策弱点，并能泛化到异构环境。

**Conclusion:** ExamPPO为评估自动驾驶决策系统的安全性和智能性提供了一个统一且可复现的解决方案。

> **ai_Abstract:** 本文针对现有自动驾驶汽车测试方法交互性弱和鲁棒性低的局限性，提出了ExamPPO框架。ExamPPO将周围车辆模拟为智能考官，利用多头注意力网络进行情境干预，并通过引入对抗因子实现测试难度的精细化控制。实验证明，该框架能有效生成对抗行为，揭示自动驾驶汽车的决策缺陷，并提供统一可复现的安全评估方案。

> **摘要翻译:** 科学的测试技术对于确保自动驾驶汽车（AVs）的安全运行至关重要，其中高风险、高交互场景是主要关注点。为了解决现有测试方法（例如它们对高质量测试数据的过度依赖、弱交互能力和低对抗鲁棒性）的局限性，本文提出了ExamPPO，一个交互式对抗测试框架，该框架能够对自动驾驶汽车进行场景自适应和强度可控的评估。该框架将周围车辆（SV）建模为智能考官，配备多头注意力增强的策略网络，从而实现情境敏感和持续的行为干预。引入了一个标量对抗因子来调节对抗行为的强度，允许对测试难度进行连续、细粒度的调整。结合结构化评估指标，ExamPPO系统地探测自动驾驶汽车在不同场景和策略下的鲁棒性。在多个场景和自动驾驶策略下的广泛实验表明，ExamPPO能够有效调节对抗行为，揭露被测试自动驾驶汽车的决策弱点，并能泛化到异构环境，从而为评估自动驾驶决策系统的安全性和智能性提供了一个统一且可复现的解决方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [215] [I Know You're Listening: Adaptive Voice for HRI](https://arxiv.org/abs/2506.15107)
> *我知道你在听：面向人机交互的自适应语音*

*Paige Tuttösí* | **Category: cs.RO, cs.HC, cs.SD, eess.AS** | **Updated: 2025-07-30**

**Keywords:** 自适应语音, 人机交互, 语言教学机器人, 文本到语音, 第二语言学习者

**Comment:** PhD Thesis Simon Fraser University https://summit.sfu.ca/item/39353
  Read the Room: IROS 2023, Mmm whatcha say?: INTERSPEECH 2024, Emojivoice:
  RO-MAN 2025, You sound a little tense: SSW 2025. Thesis presentation here:
  https://www.youtube.com/watch?v=9BcEwqYOMYI

> **TL;DR:** 开发了一种自适应机器人语音，通过表情符号提示实现富有表现力，通过调整音高适应环境噪音，并为第二语言学习者优化了清晰度，以提高语言教学机器人的效果。

**AI_Comments:** 本文的创新之处在于其多维度的自适应语音设计，不仅关注语音的表达力，还兼顾了环境适应性和特定用户群体（L2学习者）的需求。特别是“L2清晰模式”的提出，通过精确调整元音持续时间来提高非母语听众的理解，具有重要的实用价值。这对于提升语言教学机器人的用户体验和教学效果具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在语言教学机器人任务特定合成语音方面有限，这可能严重影响机器人在语言教学任务中的有效性，尤其是在第二语言（L2）教学领域。

**Method:** 1. 开发了一种轻量级且富有表现力的机器人语音：通过对Matcha-TTS进行微调，并使用表情符号提示来创建实时运行且计算资源需求有限的表达性语音。2. 探索了机器人语音如何适应物理和社会环境：通过在嘈杂和高能量环境中提高音高和音高率来调整语音。3. 为第二语言（L2）听众创建了清晰度更高的英语文本到语音（TTS）系统：采用数据驱动、基于感知的方***研究L2说话者如何利用持续时间线索来解释英语中困难的紧/松元音，并开发了Matcha-TTS的“L2清晰模式”，对紧元音进行延长处理。

**Result:** 1. 开发出的表达性语音被认为更具表现力、更符合社交场合，并且适合长时间的表达性语音（如讲故事）。2. 通过调整音高和音高率，机器人语音在嘈杂和高能量环境中显得更合适，并且似乎更了解当前环境。3. “L2清晰模式”比基础版Matcha-TTS更受尊重、更易懂、更具鼓励性，并减少了这些具有挑战性的紧/松最小对中的转录错误。

**Conclusion:** 本文通过开发轻量级表达性语音、实现语音对环境的自适应以及提升第二语言学习者的语音清晰度，显著提升了语言教学机器人的语音能力和教学效果。

> **ai_Abstract:** 本文提出了一种用于人机交互（HRI）的自适应机器人语音系统，旨在改善语言教学机器人的效果。研究通过三方面贡献解决现有不足：首先，开发了基于Matcha-TTS并利用表情符号提示的轻量级、富有表现力的实时语音；其次，探索了如何通过调整音高使机器人语音适应不同环境；最后，为第二语言学习者设计了提升英语元音清晰度的“L2清晰模式”。实验结果表明，所提出的语音系统在表现力、环境适应性及L2听众理解度方面均有显著提升。

> **摘要翻译:** 虽然社交机器人在语言教学中的应用已被探索，但针对语言教学机器人的任务特定合成语音研究仍然有限。鉴于语言是一项口头任务，这一空白可能会严重影响机器人在语言教学任务中的有效性。我们通过三项贡献解决了第二语言（L2）教学机器人语音的不足：1. 我们解决了对轻量级且富有表现力的机器人语音的需求。通过Matcha-TTS的微调版本，我们使用表情符号提示创建了一种表达性语音，该语音随时间表现出一定范围的表达能力。该语音可以在计算资源有限的情况下实时运行。通过案例研究，我们发现这种语音更具表现力、更符合社交场合，并且适合长时间的表达性讲话，例如讲故事。2. 我们探索了如何使机器人的声音适应物理和社会环境，以便在各种地点部署我们的声音。我们发现，在嘈杂和高能量的环境中提高音高和音高率会使机器人的声音显得更合适，并使其似乎更了解当前环境。3. 我们创建了一个英语文本到语音（TTS）系统，通过利用对第二语言听众来说难以理解的已知元音语言特性，提高了对L2听众的清晰度。我们使用数据驱动的、基于感知的方***了解L2说话者如何利用持续时间线索来解释英语中具有最小紧（长）和松（短）元音的挑战性单词。我们发现元音的持续时间强烈影响L2听众的感知，并为Matcha-TTS创建了一个“L2清晰模式”，该模式对紧元音进行延长处理，同时保持松元音不变。我们的清晰模式被发现比基础版Matcha-TTS更受尊重、更易懂、更具鼓励性，同时减少了这些具有挑战性的紧/松最小对中的转录错误。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [226] [Online Concurrent Multi-Robot Coverage Path Planning](https://arxiv.org/abs/2403.10460)
> *在线并发多机器人覆盖路径规划*

*Ratijit Mitra, Indranil Saha* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 多机器人覆盖, 路径规划, 并发规划, 在线算法, 资源优化

**Comment:** Accepted in IROS 2025

> **TL;DR:** 本文提出了一种非基于规划周期的集中式算法，实现了多机器人路径规划和执行的并发，有效解决了现有算法资源浪费的问题，并在大型未知工作空间中实现了完整的覆盖，显著提高了覆盖速度和效率。

**AI_Comments:** 该论文的主要创新点在于提出了非基于规划周期的并发规划与执行策略，有效解决了传统滚动窗口方法中资源利用率低下的问题。其重要性体现在提高了多机器人系统在复杂未知环境中进行全面覆盖的效率和速度，尤其适用于大规模机器人部署。通过理论证明、大规模仿真和实际实验验证，增强了研究的可靠性和说服力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的集中式基于规划周期的在线多机器人覆盖路径规划算法在路径规划和执行过程中存在交错现象，导致机器人和计算资源浪费，因为在路径规划时机器人停止执行，而在执行时则不进行规划。

**Method:** 本文提出了一种非基于规划周期的集中式算法。该算法能够随时为一部分没有路径的机器人（即已达到先前目标的机器人）规划路径，而其余机器人则继续执行其未完成的路径，从而实现规划和执行的并发。作者形式化证明了该算法能确保对未知工作空间的完全覆盖，并分析了其时间复杂度。

**Result:** 该算法在覆盖八个大型2D网格基准工作空间时，分别使用了多达512个空中和地面机器人，展现了其可扩展性。与最先进的基于规划周期的算法相比，其完成覆盖的速度提高了1.6倍。通过ROS + Gazebo在六个2D网格基准工作空间中分别使用10架四旋翼无人机和TurtleBots进行了仿真验证。此外，还成功进行了一次有三架四旋翼无人机的户外实验和一次有两台TurtleBots的室内实验。

**Conclusion:** 本文提出的非基于规划周期的集中式算法有效解决了传统基于规划周期的多机器人覆盖路径规划中资源浪费的问题，通过实现规划与执行的并发，显著提高了覆盖效率和速度，并被证明能够实现未知工作空间的完全覆盖。

> **ai_Abstract:** 本文提出了一种新型的集中式多机器人覆盖路径规划算法，旨在解决现有基于规划周期的算法中规划与执行交错导致的资源浪费问题。该算法允许路径规划和执行并发进行，即在部分机器人执行路径的同时，为其他已完成任务的机器人规划新路径。研究证明该算法能实现未知工作空间的完全覆盖，并显著提高了覆盖速度（最高1.6倍）。通过大规模仿真和真实世界实验，验证了其在多机器人系统中的可扩展性和有效性。

> **摘要翻译:** 最近，集中式滚动窗口在线多机器人覆盖路径规划算法在彻底探索大型、复杂、未知的工作空间方面，展现出了卓越的可扩展性。在一个规划周期内，路径规划和路径执行是交错进行的，这意味着当为没有路径的机器人进行路径规划时，有待执行路径的机器人不会执行；随后，当拥有新路径或待执行路径的机器人执行以达到各自目标时，那些尚未获得新路径的机器人不会进行路径规划，这导致了机器人资源和计算资源的浪费。作为补救措施，我们提出了一种非基于规划周期的集中式算法。该算法可以随时为一部分没有路径的机器人（即已达到先前目标的机器人）规划路径，而其余机器人则继续执行其未完成的路径，从而实现规划和执行的并发。我们形式化证明了所提出的算法确保了对未知工作空间的完全覆盖，并分析了其时间复杂度。为了展示可扩展性，我们评估了我们的算法在覆盖八个大型2D网格基准工作空间时的表现，分别使用了多达512个空中和地面机器人。与最先进的基于规划周期的算法相比，它在完成覆盖方面显示出优越性，速度提升高达1.6倍。为了验证，我们在六个2D网格基准工作空间中，分别使用10架四旋翼无人机和TurtleBots进行了ROS + Gazebo仿真。我们还成功进行了一次三架四旋翼无人机的户外实验和一次两台TurtleBots的室内实验。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [266] [Evaluating Interactions between Automated Vehicles and Cyclists using a coupled In-the-Loop Test Environment](https://arxiv.org/abs/2507.21859)
> *使用耦合在环测试环境评估自动驾驶车辆与骑行者之间的交互*

*Michael Kaiser, Clemens Groß, Lisa Marie Otto, Steffen Müller* | **Category: cs.RO, cs.HC** | **Updated: 2025-07-29**

**Keywords:** 自动驾驶系统, 弱势道路使用者, 在环测试, 骑行者交互, 虚幻引擎5

**Comment:** 

> **TL;DR:** 本文提出并验证了一个耦合在环测试环境，用于评估自动驾驶车辆与骑行者之间的交互，提高了测试的真实感和安全性。

**AI_Comments:** 本文提出了一种创新方法，通过将真实的人类和车辆组件集成到虚拟环境中，增强了自动驾驶系统与弱势道路使用者交互测试的真实性。双向交互和闭环特性是相对于传统模拟或单独的实地测试的重大改进，解决了自动驾驶系统安全开发的关键需求。其主要局限性可能在于设置和校准的复杂性，以及虚拟与现实世界感知/反应之间可能存在的残余差异。

<details>
  <summary>Details</summary>

**Motivation:** 评估自动驾驶系统（ADS）与骑行者等弱势道路使用者（VRU）之间的交互对于提高VRU的安全性至关重要，但现有方法往往缺乏真实感。

**Method:** 本文提出了一个耦合在环测试环境，通过虚幻引擎5开发的虚拟环境（VE）将“骑行者在环”测试台与“车辆在环”测试台集成。该设置实现了真实人类骑行者与真实自动驾驶车辆之间的闭环、双向交互。自动驾驶车辆通过模拟摄像头输入对骑行者手势作出反应，骑行者则实时感知并响应VE中的车辆。通过比较真实自动驾驶穿梭巴士在试验场和耦合在环环境中的车辆轨迹，并测量组件延迟进行验证。

**Result:** 结果表明该方法是可行的，并突出了其在真实ADS评估方面的优势和局限性。

**Conclusion:** 本文提出的耦合在环测试环境在评估自动驾驶系统与弱势道路使用者交互方面是可行的，并能提供更真实的测试条件，同时也揭示了其优势与局限性。

> **ai_Abstract:** 本文提出并验证了一种新颖的耦合在环测试环境，旨在真实评估自动驾驶系统（ADS）与人类骑行者的交互。该环境通过虚幻引擎5将真实人类骑行者和真实自动驾驶车辆集成到虚拟环境中，实现了双向、闭环交互。通过比较真实自动驾驶穿梭巴士在试验场和新测试环境中的车辆轨迹，验证实验证实了该方法的可行性，并揭示了其在真实ADS评估方面的优势和局限性。

> **摘要翻译:** 评估自动驾驶系统（ADS）与骑行者等弱势道路使用者（VRU）之间的交互对于提高VRU的安全性至关重要，但往往缺乏真实感。本文提出并验证了一个耦合在环测试环境，该环境通过在虚幻引擎5中开发的虚拟环境（VE）将骑行者在环测试台与车辆在环测试台集成在一起。该设置能够在安全可控的条件下，实现真实人类骑行者与真实自动驾驶车辆之间的闭环、双向交互。自动驾驶车辆通过模拟摄像头输入对骑行者的手势作出反应，而骑行者则在固定自行车上，实时感知并响应VE中的车辆。验证实验使用一辆具有循迹功能的真实自动驾驶穿梭巴士进行，在试验场和耦合在环测试环境中执行了三种测试机动——直线行驶带停车、圆形轨迹行驶和双车道变换。通过比较两种环境中的车辆轨迹来评估性能。此外，还测量了测试设置中单个组件引入的延迟。结果证明了该方法的可行性，并强调了其在真实ADS评估方面的优势和局限性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [279] [Swing Leg Motion Strategy for Heavy-load Legged Robot Based on Force Sensing](https://arxiv.org/abs/2309.01112)
> *基于力传感的重载足式机器人摆动腿运动策略*

*Ze Fu, Yinghui Li, Weizhong Guo* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-30**

**Keywords:** 重载足式机器人, 摆动腿, 力传感, 运动策略, 复杂地形

**Comment:** The manuscript is withdrawn due to ongoing major revisions and
  improvements to the methodology and experimental validation

> **TL;DR:** 本文提出了一种基于力传感的重载足式机器人摆动腿运动策略，通过模仿大象运动并结合地形信息，提高了机器人通过复杂地形的成功率和能效。

**AI_Comments:** 该研究通过模仿生物运动（大象）并结合力传感信息，为重载足式机器人的步态规划提供了新颖的解决方案。其创新点在于根据有无地形信息提供差异化的摆动腿轨迹规划策略，有效提升了机器人在复杂环境下的适应性和能效。对于重载机器人领域的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 重载足式机器人虽然负载能力强且能适应非结构化地形，但其自身重量大，对运动稳定性和环境感知能力提出了更高要求。本文旨在利用力传感信息来提升其运动性能。

**Method:** 本文模仿大象的运动，提出了一种用于静态步态下摆动腿的有限状态机模型。根据是否存在额外的地形信息，为摆动腿提供了不同的轨迹规划策略。

**Result:** 在新型四足机器人上的实验结果表明，该方法具有很强的鲁棒性，能够使重载足式机器人自主、平稳地通过各种复杂地形。

**Conclusion:** 本文提出的基于力传感的摆动腿运动策略，显著提高了重载足式机器人通过复杂地形的自主性和平稳性。

> **ai_Abstract:** 本文针对重载足式机器人因自重大而面临的运动稳定性与环境感知挑战，提出了一种基于力传感的摆动腿运动策略。该策略模仿大象运动，并采用有限状态机模型，根据地形信息提供不同的轨迹规划，旨在提高机器人通过复杂地形的成功率和能效。实验证明，该方法能使重载机器人鲁棒、自主、平稳地通过多种复杂地形。

> **摘要翻译:** 重载足式机器人具有强大的负载能力，能够适应各种非结构化地形。但其自身重量大，对运动稳定性和环境感知能力提出了更高的要求。为了利用力传感信息来提高其运动性能，本文模仿大象的运动，提出了一种用于静态步态下摆动腿的有限状态机模型。根据是否存在额外的地形信息，为摆动腿提供了不同的轨迹规划策略，以提高踩踏成功率并节省能量。在新型四足机器人上的实验结果表明，我们的方法具有很强的鲁棒性，能够使重载足式机器人自主、平稳地通过各种复杂地形。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [282] [IRASim: A Fine-Grained World Model for Robot Manipulation](https://arxiv.org/abs/2406.14540)
> *IRASim：一个用于机器人操作的细粒度世界模型*

*Fangqi Zhu, Hongtao Wu, Song Guo, Yuxiao Liu, Chilam Cheang, Tao Kong* | **Category: cs.RO, cs.AI, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 世界模型, 机器人操作, 扩散变换器, 动作条件, 视频生成

**Comment:** Opensource, project website: https://gen-irasim.github.io

> **TL;DR:** IRASim是一个新的世界模型，通过显式建模动作与帧的对齐，能生成带有细粒度机器人-物体交互细节的视频，且在视频质量、策略评估相关性和策略性能提升上表现出色。

**AI_Comments:** IRASim的创新之处在于其帧级动作条件模块，显式地解决了现有世界模型在细粒度机器人-物体交互中动作与视觉帧对齐不足的问题。这对于提升机器人操作的精确性和可控性至关重要。其在策略评估和性能提升方面的显著效果，预示着该模型在加速机器人研究和部署上的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有世界模型难以准确建模视觉空间中细粒度的机器人-物体交互，因为它们忽视了动作与相应帧之间的精确对齐。

**Method:** 提出了IRASim，一个能够根据历史观测和机器人动作轨迹生成带有细粒度机器人-物体交互视频的世界模型。它训练了一个扩散变换器，并在每个变换器块中引入了一个新颖的帧级动作条件模块，以显式建模和加强动作-帧对齐。

**Result:** 1. 生成视频的质量超越所有基线方法，并随模型尺寸和计算量的增加有效扩展。2. 使用IRASim进行的策略评估与使用真实模拟器的高度相关，表明其加速真实世界策略评估的潜力。3. 通过IRASim进行基于模型的规划的测试时扩展显著提升了策略性能，在Push-T基准上IoU指标从0.637提高到0.961。4. IRASim提供灵活的动作可控性，允许通过键盘或VR控制器控制数据集中虚拟机械臂。

**Conclusion:** IRASim通过其创新的动作-帧对齐建模，显著提升了机器人操作世界模型的性能和实用性，特别是在视频生成质量、策略评估和策略性能方面，并展现了其在加速真实世界机器人研究中的巨大潜力。

> **ai_Abstract:** 本文介绍了IRASim，一种用于机器人操作的细粒度世界模型。针对现有方法在建模机器人-物体交互时忽视动作-帧对齐的问题，IRASim通过引入扩散变换器和帧级动作条件模块，实现了对齐的显式建模，从而生成高质量、细节丰富的机器人操作视频。实验证明，IRASim在视频生成质量、策略评估与真实模拟器的相关性以及通过模型规划提升策略性能方面均优于现有方法，并提供了灵活的动作控制能力。

> **摘要翻译:** 世界模型允许自主智能体通过预测不同动作的视觉结果来进行规划和探索。然而，对于机器人操作而言，现有方法忽视了每个动作与相应帧之间的精确对齐，因此难以在视觉空间中准确建模细粒度的机器人-物体交互。在本文中，我们提出了IRASim，一个新颖的世界模型，能够根据历史观测和机器人动作轨迹生成具有细粒度机器人-物体交互细节的视频。我们训练了一个扩散变换器，并在每个变换器块中引入了一个新颖的帧级动作条件模块，以显式建模和加强动作-帧对齐。广泛的实验表明：（1）我们方法生成的视频质量超越所有基线方法，并随模型尺寸和计算量的增加有效扩展；（2）使用IRASim进行的策略评估与使用真实模拟器的高度相关，突出了其加速真实世界策略评估的潜力；（3）通过IRASim进行基于模型的规划的测试时扩展显著提升了策略性能，在Push-T基准上IoU指标从0.637提高到0.961；（4）IRASim提供灵活的动作可控性，允许通过键盘或VR控制器控制数据集中虚拟机械臂。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [330] [A Systematic Robot Design Optimization Methodology with Application to Redundant Dual-Arm Manipulators](https://arxiv.org/abs/2507.21896)
> *一种应用于冗余双臂机械手的系统化机器人设计优化方法*

*Dominic Guri, George Kantor* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 机器人设计优化, 双臂机械手, 冗余, 农业机器人, 任务特定指标

**Comment:** 8 pages, 6 figures, 2 tables

> **TL;DR:** 本文提出了一种四部分的机器人设计优化方法，旨在自动化特定任务机器人系统的开发，并通过优化用于辣椒采摘的双臂机器人系统进行验证，结果显示在可达性成功率和灵巧性方面有显著提升。

**AI_Comments:** 本文提出了一种结构化的机器人设计优化方法，其创新之处在于将机器人设计、任务与环境建模、性能指标和优化算法整合为一个统一框架。特别值得注意的是，引入利用自运动流形的新型任务指标，能够更全面地表征机械手冗余，对于提升机器人性能具有重要意义。该研究对于推动机器人技术在农业等复杂环境中的应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 部署操作机器人时，确定机械手的最佳放置以最大化性能是一个主要挑战，在农业环境中尤其如此。当前的设计过程依赖直觉，限制了机器人自动化在农业领域的普及和可负担性。

**Method:** 本文提出了一种四部分的机器人设计优化方法，包括：(a) 机器人设计模型，(b) 用于仿真的任务和环境表示，(c) 任务特定的性能指标，以及 (d) 用于优化配置的算法。该方法通过引入利用自运动流形来全面表征机械手冗余的新型任务指标来增强性能。

**Result:** 该框架在可达性成功率和灵巧性方面取得了同步改进。与基线方法相比，可达性成功率至少提高了14%，基于任务特定指标的灵巧性提高了30%以上。

**Conclusion:** 所提出的系统化机器人设计优化方法能有效提升特定任务机器人系统的性能，特别是在农业采摘等复杂环境中，通过优化设计显著改善了可达性和灵巧性。

> **ai_Abstract:** 本文提出了一种系统化的四部分机器人设计优化方法，旨在解决在复杂农业环境中部署操作机器人时面临的性能优化挑战。该方法包含机器人设计模型、任务与环境仿真表示、任务专用性能指标以及优化算法。通过优化用于辣椒采摘的双臂机器人系统，并引入利用自运动流形的新型任务指标，研究证明该框架显著提高了可达性成功率（至少14%）和灵巧性（超过30%）。

> **摘要翻译:** 在部署操作机器人时，确定机械手的最佳放置以最大化性能是一个主要且反复出现的挑战。在鲜花、水果和蔬菜等高价值作物的复杂、杂乱的农业环境中，这一挑战尤为严峻，而这些环境本可以从根据其特定要求量身定制的机器人系统中大大受益。然而，此类系统的设计仍然是一个具有挑战性、依赖直觉的过程，限制了农民等领域专家对基于机器人技术的自动化方案的可负担性和采用。为了解决这一挑战，我们提出了一种四部分的机器人设计优化方法，旨在自动化特定任务机器人系统的开发。该框架包括 (a) 机器人设计模型，(b) 用于仿真的任务和环境表示，(c) 任务特定的性能指标，以及 (d) 用于完善配置的优化算法。我们通过使用两个现成的冗余机械手，优化用于辣椒采摘的双臂机器人系统来演示我们的框架。为了提高性能，我们引入了新颖的任务指标，这些指标利用自运动流形来全面表征机械手冗余。我们的结果表明，我们的框架在可达性成功率和灵巧性方面实现了同步提升。具体而言，我们的方法与基线方法相比，可达性成功率至少提高了14%，并且基于我们的任务特定指标，灵巧性提高了30%以上。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [338] [GSON: A Group-based Social Navigation Framework with Large Multimodal Model](https://arxiv.org/abs/2409.18084)
> *GSON：一个基于群组的、采用大型多模态模型的社交导航框架*

*Shangyi Luo, Peng Sun, Ji Zhu, Yuhong Deng, Cunjun Yu, Anxing Xiao, Xueqian Wang* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 社交导航, 大型多模态模型, 机器人, 零样本学习, 群组感知

**Comment:** Accepted by IEEE Robotics and Automation Letters (RA-L)

> **TL;DR:** GSON是一个新的基于群组的社交导航框架，它利用大型多模态模型（LMMs）来增强机器人的社交感知能力，并通过视觉提示实现零样本社交关系提取，在真实复杂社交场景中显著优于现有导航方法，减少了社交扰动。

**AI_Comments:** GSON的创新之处在于其将大型多模态模型引入机器人社交导航领域，并通过视觉提示实现零样本社交关系提取，有效克服了传统方法的局限性。结合中层规划器，它在保持导航效率的同时显著提升了社交智能，对于服务机器人和自动驾驶车辆在人类复杂环境中安全高效运行具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着服务机器人和自动驾驶车辆在人类环境中日益普及，导航系统需要从简单的到达目的地演变为融入社交意识，以应对复杂的人类社交环境。

**Method:** GGSON框架利用大型多模态模型（LMMs）增强机器人的社交感知能力。它使用视觉提示实现行人社交关系的零样本提取，并将结果与行人检测和跟踪管道结合，以克服LMM的推理速度限制。规划系统包含一个介于全局路径规划和局部运动规划之间的中层规划器，旨在保持全局上下文和响应性，同时避免扰乱预测的社交群体。

**Result:** 通过在排队、对话和拍照等复杂社交场景中的真实世界移动机器人导航实验验证了GSON。对比结果表明，GSON在最小化社交扰动方面显著优于现有导航方法，同时在传统导航指标上保持了相当的性能。

**Conclusion:** GSON框架通过利用大型多模态模型，显著提升了机器人在复杂人类社交环境中的导航能力，有效减少了对社交群体的干扰，并在实际应用中表现出优越性。

> **ai_Abstract:** GSON是一个新颖的基于群组的社交导航框架，旨在提升机器人在人类环境中的社交感知能力。该框架利用大型多模态模型（LMMs）进行零样本社交关系提取，并通过结合行人检测与跟踪管道克服LMM的速度限制。其规划系统引入中层规划器，平衡全局规划与局部响应，避免扰乱社交群体。实验证明，GSON在复杂社交场景中显著减少了社交扰动，优于现有导航方法。

> **摘要翻译:** 随着服务机器人和自动驾驶车辆在人类环境中日益普及，导航系统需要从简单的到达目的地演变为融入社交意识。本文介绍了GSON，一个新颖的基于群组的社交导航框架，它利用大型多模态模型（LMMs）来增强机器人的社交感知能力。我们的方法使用视觉提示来实现行人社交关系的零样本提取，并将这些结果与鲁棒的行人检测和跟踪管道相结合，以克服LMM固有的推理速度限制。规划系统包含一个介于全局路径规划和局部运动规划之间的中层规划器，有效地保持了全局上下文和响应性，同时避免了对预测社交群体的干扰。我们通过涉及排队、对话和拍照等复杂社交场景的广泛真实世界移动机器人导航实验验证了GSON。对比结果显示，我们的系统在最小化社交扰动方面显著优于现有导航方法，同时在传统导航指标上保持了相当的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [383] [Design, Dynamic Modeling and Control of a 2-DOF Robotic Wrist Actuated by Twisted and Coiled Actuators](https://arxiv.org/abs/2503.05508)
> *扭曲盘绕驱动器驱动的两自由度机器人腕部设计、动态建模与控制*

*Yunsong Zhang, Xinyu Zhou, Feitian Zhang* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-30**

**Keywords:** 机器人腕部, 扭曲盘绕驱动器, 动态建模, 非线性模型预测控制, 软机器人

**Comment:** 

> **TL;DR:** 本文提出了一种由扭曲盘绕驱动器驱动的两自由度机器人腕部设计，开发了其拉格朗日动态模型，并设计了基于模型的非线性模型预测控制器。实验验证了其性能和控制方法的有效性。

**AI_Comments:** 该论文通过提出一种新型两自由度机器人腕部设计及其基于动态模型的NMPC控制策略，有效地解决了人工肌肉驱动软机器人在多自由度配置下控制难题。其创新点在于将TCAs与紧凑的并联机构结合，并开发了详细的拉格朗日模型和先进的NMPC，并通过详尽的实验验证了其性能，对软机器人领域具有重要意义。文章清晰地展示了从设计、建模到控制和实验验证的完整研究流程，并强调了其作为模块化构建块的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 人工肌肉驱动的模块化软机器人虽然潜力巨大，但由于缺乏针对多自由度配置的基于动态模型的控制策略，其应用受到限制。

**Method:** 本文设计了一种由扭曲盘绕驱动器（TCAs）驱动的两自由度机器人腕部，采用紧凑的3RRRR并联机构实现轻量化。开发了全面的拉格朗日动态模型来捕捉其非线性行为。基于该模型，设计了非线性模型预测控制器（NMPC）以确保精确的轨迹跟踪。制作了物理原型并进行了实验，将NMPC与传统PID控制器进行比较，并将其集成到多段软机器人手臂中进行轨迹跟踪任务。

**Result:** 实验结果表明，基于动态模型的控制方法在管理TCA驱动的机器人腕部运动方面是有效和鲁棒的。该腕部模块成功地在多段软机器人手臂中执行了轨迹跟踪任务。

**Conclusion:** 本文提出的基于动态模型的控制方法能够有效且鲁棒地管理由扭曲盘绕驱动器驱动的机器人腕部运动，验证了其在复杂软机器人系统中的实用性和可集成性。

> **ai_Abstract:** 本文针对人工肌肉驱动软机器人在多自由度配置下缺乏基于动态模型的控制策略的问题，提出了一种由扭曲盘绕驱动器驱动的两自由度机器人腕部设计。研究开发了其拉格朗日动态模型，并基于该模型设计了非线性模型预测控制器（NMPC）。通过物理原型实验，验证了所提动态模型的准确性以及NMPC在轨迹跟踪方面的有效性和鲁棒性，并将其成功集成到多段软机器人手臂中，展示了其在复杂软机器人系统中的应用潜力。

> **摘要翻译:** 人工肌肉驱动的模块化软机器人在执行复杂任务方面展现出巨大潜力。然而，由于缺乏针对多自由度配置的基于动态模型的控制策略，其更广泛的应用仍然受限。本文提出了一种两自由度机器人腕部的新颖设计，设想其作为此类先进机器人系统的基本组成部分。该腕部模块由扭曲盘绕驱动器（TCAs）驱动，并利用紧凑的3RRRR并联机构实现轻量化结构和增强的运动能力。开发了一个全面的拉格朗日动态模型来捕捉模块复杂的非线性行为。利用该模型，设计了非线性模型预测控制器（NMPC）以确保精确的轨迹跟踪。制作了机器人腕部的物理原型，并进行了大量实验以验证其运动性能和所提出动态模型的保真度。随后，在各种操作条件下对NMPC和传统PID控制器进行了比较评估。实验结果证明了基于动态模型的控制方法在管理TCA驱动的机器人腕部运动方面的有效性和鲁棒性。最后，为了说明其实用性和可集成性，该腕部模块被整合到一个多段软机器人手臂中，并成功执行了轨迹跟踪任务。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [391] [An Integrated Approach to Robotic Object Grasping and Manipulation](https://arxiv.org/abs/2411.13205)
> *机器人物体抓取与操作的集成方法*

*Owais Ahmed, M Huzaifa, M Areeb, Hamza Ali Khan* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 机器人抓取, 物品拣选, 仓库自动化, 不确定性处理, 自主系统

**Comment:** 

> **TL;DR:** 本文介绍了一个创新的机器人系统，旨在解决仓库中从货架上自动抓取和操作不确定位置物品的挑战，以提高效率。

**AI_Comments:** 该论文提出了一种解决仓库自动化中关键瓶颈（即物品拣选）的集成方法。其创新之处在于机器人系统能够处理物品位置的不确定性，这在现实世界仓库环境中是一个普遍且具有挑战性的问题。该方法通过自主适应和定位物品，显著提高了拣选效率，对于推动仓库机器人技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 应对仓库操作中日益增长的人工劳动和效率挑战，特别是从货架上拣选物品的复杂过程以及物品位置的不确定性。

**Method:** 开发了一个创新的机器人系统，该系统能够自主完成模拟订单，从货架上高效拣选特定物品，并能自主适应和定位检索不确定位置的物品。

**Result:** 该系统能够自主完成模拟订单，并能高效地从货架上拣选特定物品，即使在没有预先建立的物品位置知识的情况下也能处理不确定的物品位置。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了一个为解决仓库自动化中物品拣选挑战而设计的创新机器人系统。该系统旨在自主完成订单，能够高效地从货架上拣选特定物品，并特别强调其处理物体位置不确定性的能力。该机器人无需预先知道物品位置，即可自主适应并定位和检索目标物品，从而提高了仓库操作的效率。

> **摘要翻译:** 为了应对仓库操作中日益增长的人工劳动和效率挑战，亚马逊已开始通过引入机器人来协助各种任务，进行重大转型。虽然大量机器人已成功部署用于仓库内的物品运输等任务，但从货架上拣选物品的复杂过程仍然是一个重大挑战。本项目通过开发一个创新的机器人系统来解决这个问题，该系统能够自主完成模拟订单，通过从货架上高效选择特定物品。所提出的机器人系统的一个显著特点是它能够应对货架上每个箱子中物体位置不确定性的挑战。该系统被设计为能够自主调整其方法，采用策略使其能够高效地定位和检索所需物品，即使在没有预先建立的位置知识的情况下。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [396] [ODE Methods for Computing One-Dimensional Self-Motion Manifolds](https://arxiv.org/abs/2507.21957)
> *ODE 方法计算一维自运动流形*

*Dominic Guri, George Kantor* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 自运动流形, 冗余机械臂, 逆运动学, 常微分方程, 棱柱关节

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的常微分方程（ODE）方法，用于计算冗余机械臂的一维自运动流形（SMMs），解决了现有逆运动学（IK）求解器局部最优的局限性，并能处理断开的组件和棱柱关节。

**AI_Comments:** 该论文的创新点在于引入了常微分方程（ODE）方法来计算自运动流形，这提供了一种新的视角来解决冗余机械臂的全局逆运动学问题。其重要性体现在能够获得全局解，这对于高级辅助任务（如避障和避免关节限制）至关重要。此外，将方法扩展到棱柱关节系统填补了现有文献的空白。论文也提及了方法的局限性，显示了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 冗余机械臂的逆运动学（IK）求解器通常是基于梯度的迭代方法，只能返回局部最优解。为了获得冗余机械臂的全局IK解决方案并更好地解决辅助任务（如避免关节限制或障碍物），需要计算自运动流形（SMMs）。

**Method:** 引入了一种新颖的常微分方程（ODE）公式，使用标准的显式固定步长ODE积分器来计算一维任务冗余的自运动流形（SMMs）。该方法还解决了在非冗余机械臂中“诱导”冗余的挑战，并提出了搜索多个断开的SMM组件的方法。此外，方法被扩展到棱柱关节系统。

**Result:** 计算出准确的自运动流形（SMM）解决方案，无需额外的逆运动学（IK）细化。成功将方法扩展到棱柱关节系统，这是当前SMM文献中未涵盖的领域。手稿展示了方法的推导和多个示例，说明了方法的工作原理及其局限性。

**Conclusion:** 本文提出了计算一维自运动流形的新型常微分方程（ODE）方法及其推导，并通过多个例子展示了这些方法的工作原理和局限性。这些方法能够准确计算SMMs，并适用于棱柱关节系统。

> **ai_Abstract:** 本文提出了一种基于常微分方程（ODE）的新颖方法，用于计算冗余机械臂的一维自运动流形（SMMs）。SMMs是冗余机械臂的全局逆运动学（IK）解决方案，解决了现有局部最优IK求解器的局限性。该方法利用标准显式固定步长ODE积分器，并能处理非冗余机械臂中的“诱导”冗余以及SMM的多个不连通组件。研究结果表明，该方法能够准确计算SMM，无需额外IK细化，并首次扩展到棱柱关节系统。

> **摘要翻译:** 冗余机械臂众所周知能够提供无限的关节配置来达到期望的末端执行器姿态。逆运动学（IK）解的多样性允许同时解决诸如避免关节限制或障碍物等辅助任务。然而，最广泛使用的IK求解器是基于梯度的数值迭代方法，它们本质上返回局部最优解。在这项工作中，我们探索了自运动流形（SMMs）的计算，它代表了解决冗余机械臂逆运动学问题的所有关节配置的集合。因此，SMMs是冗余机械臂的全局IK解决方案。我们专注于维度为1的任务冗余，引入了一种新颖的ODE公式，使用标准的显式固定步长ODE积分器来计算SMMs。我们还解决了在非冗余机械臂中“诱导”冗余的挑战，这些机械臂被分配给自然由比非冗余机械臂少一个自由度描述的任务。此外，认识到SMMs可以由多个不连通的组件组成，我们提出了搜索这些独立SMM组件的方法。我们的公式和算法计算出准确的SMM解决方案，无需额外的IK细化，并且我们将我们的方法扩展到棱柱关节系统——这是当前SMM文献中未涵盖的领域。本手稿介绍了这些方法的推导和几个示例，展示了这些方法的工作原理及其局限性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [399] [Distance and Collision Probability Estimation from Gaussian Surface Models](https://arxiv.org/abs/2402.00186)
> *基于高斯曲面模型的距离和碰撞概率估计*

*Kshitij Goel, Wennie Tabib* | **Category: cs.RO, cs.CG, cs.CV, cs.GR** | **Updated: 2025-07-30**

**Keywords:** 碰撞概率估计, 椭球形机器人, 高斯曲面模型

**Comment:** Accepted at IROS 2025

> **TL;DR:** 本文提出了一种高效的方法，用于从高斯曲面模型中估计椭球形机器人的距离和碰撞概率。

**AI_Comments:** 这篇论文通过将椭球形机器人模型与高斯曲面环境模型相结合，解决了在不确定性感知运动规划中进行精确且高效碰撞估计的关键挑战。其创新点在于弥补了现有方法在高斯曲面模型下无法处理椭球体以及缺乏高效连续空间占有估计的空白。所提出的方法不仅提高了精度（通过椭球体表示），还显著提升了计算效率，使其适用于嵌入式系统，这对于实际机器人应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 连续空间碰撞概率估计对于不确定性感知运动规划至关重要。现有方法通常将机器人建模为球体，而椭球体能提供更紧密的近似并适应狭窄空间。处理原始点云计算量大，且现有少量从高斯曲面模型估计连续空间占用的方法无法处理椭球形机器人或估计碰撞概率、欧氏距离和梯度。

**Method:** 本文提出了连续空间方法，通过将椭球体间欧氏距离和碰撞概率估计的现有工作扩展到高斯曲面模型，来估计椭球形机器人与高斯分布建模的环境表面之间的碰撞概率、欧氏距离和梯度。同时提出了一种几何融合方法来改进碰撞概率估计。

**Result:** 所提出的方法在2D和3D数值实验中使用真实点云数据进行了评估。这些量的高效计算方法被证明在现代嵌入式计算机的低功耗CPU上，单线程每对椭球体可在几微秒内完成。

**Conclusion:** 本文成功地弥补了从高斯曲面模型估计椭球形机器人距离和碰撞概率的空白，并展示了其高效率，为不确定性感知运动规划提供了关键工具。

> **ai_Abstract:** 本文提出了一种用于从高斯曲面模型中估计椭球形机器人与环境之间距离、梯度和碰撞概率的连续空间方法。针对现有方法在椭球体表示和高斯曲面模型应用上的不足，本文通过扩展椭球体间距离和碰撞概率估计的工作，并引入几何融合方法，实现了高效且准确的计算。实验证明，该方法在低功耗CPU上能以微秒级速度完成计算，为不确定性感知运动规划提供了关键支持。

> **摘要翻译:** 本文描述了估计椭球形机器人模型与一组高斯分布建模的环境表面之间碰撞概率、欧氏距离和梯度的连续空间方法。连续空间碰撞概率估计对于不确定性感知运动规划至关重要。大多数碰撞检测和避障方法假设机器人被建模为球体，但椭球形表示提供了更紧密的近似，并能实现在杂乱和狭窄空间中的导航。最先进的方法通过处理原始点云来推导欧氏距离和梯度，这对于大型工作空间来说计算成本很高。高斯曲面建模（例如混合模型、飞溅）的最新进展实现了压缩和高保真曲面表示。从这些模型估计连续空间占用的方法很少。它们要求高斯模型来建模自由空间，并且无法估计椭球形机器人的碰撞概率、欧氏距离和梯度。所提出的方法通过将椭球体到椭球体欧氏距离和碰撞概率估计的先前工作扩展到高斯曲面模型来弥补这一空白。还提出了一种几何融合方法来改进碰撞概率估计。这些方法通过使用真实世界点云数据的2D和3D数值实验进行了评估。这些量的高效计算方法被证明在现代嵌入式计算机的低功耗CPU上，单线程每对椭球体可在几微秒内执行。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [439] [A General Safety Framework for Autonomous Manipulation in Human Environments](https://arxiv.org/abs/2412.10180)
> *面向人类环境中自主操作的通用安全框架*

*Jakob Thumm, Julian Balletshofer, Leonardo Maglanoc, Luis Muschal, Matthias Althoff* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-28**

**Keywords:** 自主操作, 人机协作, 安全框架, 可达性分析, 动能

**Comment:** 

> **TL;DR:** 本文提出SARA shield，一个基于可达性分析的新型安全框架，旨在确保在人类环境中自主机器人操作的安全性，同时实现快速机器人速度。

**AI_Comments:** SARA shield的创新之处在于其利用可达性分析来形式化地分类接触类型，并针对不同人体部位的疼痛和损伤阈值来验证机器人的动能，从而在保证安全的前提下实现了更快的机器人速度。这有效地解决了人机交互中安全性与效率之间的常见权衡问题。

<details>
  <summary>Details</summary>

**Motivation:** 现有的确保人类安全的机器人方法要么过于保守，阻碍了自然的人机协作，要么依赖于不适用于自主机器人的强假设（例如，预先定义的轨迹知识）。因此，需要一个既能保证人类安全又能实现机器人高速运行的通用安全框架。

**Method:** 本文提出了SARA shield（通过可达性分析实现安全自主人机协作的防护罩）框架。该框架是一种新颖的功率和力限制方法，利用可达性分析以形式化正确的方式对潜在接触（分为非受限和受限）进行分类。对于每种接触类型，它正式验证机器人的动能低于相应人体接触部位的疼痛和损伤阈值。

**Result:** 实验结果表明，SARA shield在满足接触安全约束的同时，与现有先进方法相比，显著提高了机器人性能。

**Conclusion:** SARA shield为人类环境中的自主机器人操作提供了正式的安全保障，通过在限制功率和力的同时，确保机器人在与人类协作时能够以更快的速度运行，并防止接触伤害。

> **ai_Abstract:** 本文介绍了一个名为SARA shield的新型通用安全框架，用于人类环境中的自主机器人操作。该框架通过可达性分析对潜在接触类型进行分类，并正式验证机器人的动能保持在人体疼痛和损伤阈值以下，从而克服了现有安全方法的局限性。实验证明，SARA shield在确保安全的同时，显著提升了机器人性能。

> **摘要翻译:** 自主机器人有望显著增强人工劳动力，特别是在重复性和危险性任务中。为了在此类机器人在人类环境中成功部署，确保人类安全至关重要。目前确保人类安全的先进方法要么过于保守，无法实现自然的人机协作，要么做出不适用于自主机器人的强假设，例如，预先定义的轨迹知识。因此，我们提出了通过可达性分析实现安全自主人机协作的防护罩（SARA shield）。这种新颖的功率和力限制框架为人类环境中的操作提供了正式的安全保证，同时实现了快速的机器人速度。由于非受限接触允许比受限接触（也称为夹持）显著更高的接触力，我们使用可达性分析以形式化正确的方式按类型对潜在接触进行分类。对于每种接触类型，我们正式验证机器人的动能低于相应人体接触部位的疼痛和损伤阈值。我们的实验表明，与现有先进方法相比，SARA shield在满足接触安全约束的同时，显著提高了机器人性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [458] [A Deep Learning-Driven Autonomous System for Retinal Vein Cannulation: Validation Using a Chicken Embryo Model](https://arxiv.org/abs/2507.21965)
> *深度学习驱动的视网膜静脉插管自主系统：使用鸡胚模型进行验证*

*Yi Wang, Peiyao Zhang, Mojtaba Esfandiari, Peter Gehlbach, Iulian I. Iordachita* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 深度学习, 视网膜静脉插管, 机器人辅助, 微外科手术, 鸡胚模型

**Comment:** 

> **TL;DR:** 本研究提出了一种深度学习驱动的自主机器人系统，用于视网膜静脉插管，利用鸡胚模型进行验证，实现了更高的精度和更短的手术时间。

**AI_Comments:** 该论文的创新之处在于将先进的深度学习技术与机器人辅助系统相结合，解决了视网膜静脉插管这一高精度微外科手术中的挑战。使用鸡胚模型作为替代验证模型是其方法学上的一个亮点。该研究为未来更安全、更精确的自动化微外科手术铺平了道路，具有重要的临床应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 视网膜静脉插管（RVC）是一种治疗视网膜静脉阻塞（RVO）的微创手术，但由于视网膜静脉的微小和脆弱性，以及对手术精度和无颤抖操作的高要求，存在显著的技术挑战。这些限制凸显了对机器人辅助以提高准确性和稳定性的需求。

**Method:** 本研究提出了一种自动化机器人系统，该系统结合了顶置显微镜和B型光学相干断层扫描（OCT）成像技术，用于精确的深度感知。系统采用基于深度学习的模型，实现实时针头导航、接触检测和静脉穿刺识别，并使用鸡胚模型作为人类视网膜静脉的替代模型进行验证。

**Result:** 该系统能以85%的准确率自主检测针头位置和穿刺事件。实验表明，与手动方法相比，导航和穿刺时间显著减少。

**Conclusion:** 研究结果表明，整合先进成像技术和深度学习具有自动化显微外科任务的潜力，为实现更安全、更可靠、更高精度和可重复性的视网膜静脉插管手术提供了途径。

> **ai_Abstract:** 本研究开发并验证了一个深度学习驱动的自主机器人系统，用于视网膜静脉插管。该系统结合了顶置显微镜和B-scan OCT成像进行深度感知，并利用深度学习模型实现针头导航、接触检测和穿刺识别。在鸡胚模型上的实验表明，该系统能以85%的准确率自主检测针头位置和穿刺事件，并显著缩短了导航和穿刺时间，展示了自动化微外科手术的潜力。

> **摘要翻译:** 视网膜静脉插管（RVC）是一种微创显微外科手术，用于治疗视网膜静脉阻塞（RVO），后者是导致视力损伤的主要原因。然而，视网膜静脉的微小和脆弱性，加上需要高精度、无颤抖的针头操作，带来了显著的技术挑战。这些限制凸显了对机器人辅助以提高准确性和稳定性的需求。本研究提出了一种自动化机器人系统，该系统结合了顶置显微镜和B型光学相干断层扫描（OCT）成像技术，用于精确的深度感知。基于深度学习的模型能够实现实时针头导航、接触检测和静脉穿刺识别，并使用鸡胚模型作为人类视网膜静脉的替代模型进行验证。该系统能以85%的准确率自主检测针头位置和穿刺事件。实验表明，与手动方法相比，导航和穿刺时间显著减少。我们的结果证明了整合先进成像和深度学习以自动化显微外科任务的潜力，为实现更安全、更可靠、更高精度和可重复性的RVC手术提供了途径。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [477] [Spatial Language Likelihood Grounding Network for Bayesian Fusion of Human-Robot Observations](https://arxiv.org/abs/2507.19947)
> *用于人机观测贝叶斯融合的空间语言似然接地网络*

*Supawich Sitdhipol, Waritwong Sukprasongdee, Ekapol Chuangsuwanich, Rina Tse* | **Category: cs.RO, cs.CL, cs.IT, cs.LG, cs.SY, eess.SY, math.IT** | **Updated: 2025-07-30**

**Keywords:** 空间语言, 似然接地, 贝叶斯融合, 人机协作, 不确定性感知

**Comment:** Accepted to the 2025 IEEE International Conference on Systems, Man,
  and Cybernetics (SMC); Supplementary video: https://cu-asl.github.io/fp-lgn/

> **TL;DR:** 本文提出了一种特征金字塔似然接地网络（FP-LGN），用于将空间语言与地图图像特征及其空间关系语义相结合，以实现对人类观测进行不确定性感知的贝叶斯融合，从而显著提高人机协作任务的性能。

**AI_Comments:** 该论文提出了一种新颖的FP-LGN模型，用于解决人机协作中融合人类语言不确定性的关键问题。其创新点在于将空间语言接地为概率估计器，并通过三阶段课程学习来捕获偶然不确定性，这对于实现更鲁棒、更高效的人机协同至关重要。论文通过与专家规则的对比和协作任务性能的提升，验证了其方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 在协作任务中，融合人类观察信息可以帮助机器人克服感知限制。然而，一个不确定性感知的融合框架需要一个接地似然来表示人类输入的不确定性。

**Method:** 本文提出了一种特征金字塔似然接地网络（FP-LGN），通过学习相关的地图图像特征及其与空间关系语义的关系来接地空间语言。该模型被训练为概率估计器，使用三阶段课程学习来捕获人类语言中的偶然不确定性。

**Result:** 结果显示，FP-LGN在平均负对数似然（NLL）方面与专家设计的规则相匹配，并表现出更低的标准差，具有更强的鲁棒性。协作感知结果表明，接地似然成功地实现了异构人类语言观测和机器人传感器测量的不确定性感知融合，显著提高了人机协作任务的性能。

**Conclusion:** 接地似然成功地实现了异构人类语言观测和机器人传感器测量的不确定性感知融合，显著提高了人机协作任务的性能。

> **ai_Abstract:** 本文提出了一种特征金字塔似然接地网络（FP-LGN），旨在通过学习地图图像特征和空间关系语义来接地空间语言，以实现对人类观测的不确定性感知融合。该网络被训练为概率估计器，以捕获人类语言中的偶然不确定性。实验结果表明，FP-LGN在性能上与专家规则相当，且鲁棒性更强，成功地将人类语言观测与机器人传感器测量融合，显著提升了人机协作任务的表现。

> **摘要翻译:** 从人类观测中融合信息可以帮助机器人在协作任务中克服感知限制。然而，一个不确定性感知的融合框架需要一个接地似然来表示人类输入的不确定性。本文提出了一种特征金字塔似然接地网络（FP-LGN），通过学习相关的地图图像特征及其与空间关系语义的关系来接地空间语言。该模型被训练为概率估计器，使用三阶段课程学习来捕获人类语言中的偶然不确定性。结果显示，FP-LGN在平均负对数似然（NLL）方面与专家设计的规则相匹配，并表现出更低的标准差，具有更强的鲁棒性。协作感知结果表明，接地似然成功地实现了异构人类语言观测和机器人传感器测量的不确定性感知融合，显著提高了人机协作任务的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [500] [GS-SDF: LiDAR-Augmented Gaussian Splatting and Neural SDF for Geometrically Consistent Rendering and Reconstruction](https://arxiv.org/abs/2503.10170)
> *GS-SDF：激光雷达增强的高斯泼溅和神经SDF，用于几何一致的渲染和重建*

*Jianheng Liu, Yunfei Wan, Bowen Wang, Chunran Zheng, Jiarong Lin, Fu Zhang* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 高斯泼溅, 神经SDF, 激光雷达, 数字孪生, 几何一致性

**Comment:** 8 pages, IROS 2025

> **TL;DR:** GS-SDF是一种结合激光雷达、高斯泼溅和神经SDF的新系统，旨在提高数字孪生中渲染和重建的几何一致性。

**AI_Comments:** 该论文的创新之处在于将激光雷达数据、高斯泼溅和神经SDF进行协同整合，特别是在改善几何一致性方面，这是高斯泼溅的一个已知局限。代码的发布也对社区有所贡献。

<details>
  <summary>Details</summary>

**Motivation:** 数字孪生在自动驾驶和具身人工智能中至关重要，但实现高粒度表面重建和高保真渲染仍面临挑战。高斯泼溅在机器人应用中因碎片化基元和稀疏观测数据导致几何不一致。现有正则化方法在复杂环境中效果不佳，且将稀疏激光雷达数据与高斯泼溅有效结合仍然困难。

**Method:** 本文提出GS-SDF，一个统一的激光雷达-视觉系统，它将高斯泼溅与神经符号距离场（SDF）协同作用。精确的激光雷达点云使训练后的神经SDF能够提供流形几何场。这促使作者提供基于SDF的高斯初始化，用于物理上接地基元放置，以及全面的几何正则化，以实现几何一致的渲染和重建。

**Result:** 实验证明，在不同轨迹下，该方法均展现出卓越的重建精度和渲染质量。

**Conclusion:** GS-SDF通过有效整合激光雷达和神经SDF与高斯泼溅，成功解决了几何不一致问题，并显著提高了重建和渲染质量。

> **ai_Abstract:** 本文提出GS-SDF，一个新颖的统一激光雷达-视觉系统，它将高斯泼溅与神经符号距离场（SDF）相结合，以克服数字孪生中高粒度表面重建和高保真渲染的挑战。它通过利用精确的激光雷达数据训练SDF来解决高斯泼溅的几何不一致性，进而促进基于SDF的高斯初始化和全面的几何正则化。实验表明，该方法提高了重建精度和渲染质量。

> **摘要翻译:** 数字孪生对于自动驾驶和具身人工智能的发展至关重要。然而，实现高粒度表面重建和高保真渲染仍然是一个挑战。高斯泼溅提供了高效逼真的渲染，但在机器人应用中由于碎片化的基元和稀疏的观测数据而存在几何不一致性。现有的依赖于渲染导出约束的正则化方法在复杂环境中往往失效。此外，有效整合稀疏激光雷达数据与高斯泼溅仍然具有挑战性。我们提出了一个统一的激光雷达-视觉系统，将高斯泼溅与神经符号距离场协同作用。精确的激光雷达点云使训练后的神经符号距离场能够提供流形几何场。这促使我们提供基于SDF的高斯初始化，用于物理上接地的基元放置，以及全面的几何正则化，以实现几何一致的渲染和重建。实验证明，在不同轨迹下，该方法均展现出卓越的重建精度和渲染质量。为了回馈社区，代码已在 https://github.com/hku-mars/GS-SDF 发布。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [521] [DISCOVERSE: Efficient Robot Simulation in Complex High-Fidelity Environments](https://arxiv.org/abs/2507.21981)
> *DISCOVERSE：复杂高保真环境中的高效机器人模拟*

*Yufei Jia, Guangyu Wang, Yuhang Dong, Junzhe Wu, Yupei Zeng, Haonan Lin, Zifan Wang, Haizhou Ge, Weibin Gu, Kairui Ding, Zike Yan, Yunjie Cheng, Yue Li, Ziming Wang, Chuxuan Li, Wei Sui, Lu Shi, Guanzhong Tian, Ruqi Huang, Guyue Zhou* | **Category: cs.RO, 68T40, I.2.9** | **Updated: 2025-07-29**

**Keywords:** 机器人模拟, 3DGS, Real2Sim2Real, Sim2Real, 高保真环境

**Comment:** 8pages, IROS2025 (Camera Ready)

> **TL;DR:** DISCOVERSE是一个基于3DGS的统一开源机器人模拟框架，用于实现超真实感环境中的高效机器人学习，并在Sim2Real迁移方面表现出色。

**AI_Comments:** DISCOVERSE的创新之处在于其将3DGS技术引入机器人模拟，实现了超真实感环境的合成，这对于弥合Sim2Real差距至关重要。其统一、模块化和开源的特性，以及对现有资产和ROS的广泛支持，使其成为一个潜力巨大的平台，有望推动大规模机器人学习和现实世界部署。该框架在Sim2Real迁移方面的SOTA表现，证明了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器人模拟器在现实世界场景的几何和外观合成方面可能不足，导致Sim2Real差距难以分析和弥合。该研究旨在提供一个能够合成超真实感环境的模拟框架，以促进大规模机器人学习和复杂机器人基准测试，并分析和弥合Sim2Real差距。

**Method:** 提出了DISCOVERSE，一个统一的、模块化、开源的基于3DGS的Real2Sim2Real机器人学习模拟框架。它采用整体的Real2Sim管道，合成复杂真实世界场景的超真实感几何和外观。该框架由高斯泼溅（Gaussian Splatting）和MuJoCo驱动，支持大规模并行模拟多种传感器模态和精确物理，并兼容现有3D资产、机器人模型和ROS插件。

**Result:** 通过在模仿学习方面的广泛实验，DISCOVERSE相较于现有模拟器，展示了最先进的零样本Sim2Real迁移性能。

**Conclusion:** DISCOVERSE提供了一个高效且高保真的机器人模拟解决方案，能够显著提升机器人学习的Sim2Real迁移性能，并有助于分析和弥合现实与模拟之间的差距。

> **ai_Abstract:** DISCOVERSE是一个创新的、基于3DGS的开源机器人模拟框架，专为Real2Sim2Real机器人学习设计。它通过集成Real2Sim管道来合成高度逼真的环境，结合高斯泼溅和MuJoCo实现并行多模态传感器模拟和精确物理，并支持现有资产和ROS插件。实验证明，DISCOVERSE在零样本Sim2Real迁移方面超越了现有模拟器，为大规模机器人学习和Sim2Real差距分析提供了强大的工具。

> **摘要翻译:** 我们提出了首个统一、模块化、开源的基于3DGS的Real2Sim2Real机器人学习模拟框架。它具有一个整体的Real2Sim管道，能够合成复杂真实世界场景的超真实感几何和外观，为分析和弥合Sim2Real差距铺平了道路。Discoverse由高斯泼溅和MuJoCo驱动，能够大规模并行模拟多种传感器模态和精确物理，并全面支持现有3D资产、机器人模型和ROS插件，从而赋能大规模机器人学习和复杂的机器人基准测试。通过在模仿学习方面的广泛实验，Discoverse与现有模拟器相比，展示了最先进的零样本Sim2Real迁移性能。代码和演示请访问：https://air-discoverse.github.io/。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [557] [OPAL: Encoding Causal Understanding of Physical Systems for Robot Learning](https://arxiv.org/abs/2504.06538)
> *OPAL：编码物理系统因果理解以进行机器人学习*

*Daniel Tcheurekdjian, Joshua Klasmeier, Tom Cooney, Christopher McCann, Tyler Fenstermaker* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 机器人学习, 拓扑约束, 拓扑注意力, 因果理解, 零样本性能

**Comment:** We withdraw our submission following peer review feedback that
  identified methodological limitations: specifically, our experimental design
  does not adequately support the causal claims made in the submission. The
  work was preliminary undergraduate research that requires substantial
  additional experimental validation to properly establish the proposed causal
  relationships

> **TL;DR:** OPAL是一种新型视觉-语言-动作架构，通过引入拓扑约束和拓扑注意力，显著提高了机器人在复杂操作任务中的零样本性能，并降低了计算需求。

**AI_Comments:** OPAL的创新点在于将拓扑约束和拓扑注意力引入到机器人学习的视觉-语言-动作架构中，以编码对物理系统的因果理解。这不仅提升了机器人在复杂任务中的零样本泛化能力和动作序列的连贯性，还显著降低了计算成本，为机器人学习领域提供了一种新颖且高效的建模方法。其理论保证和从基本物理定律推导限制搜索空间的思想具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高机器人学习的性能，尤其是在零样本泛化能力和长序列动作的连贯性方面，并探索将因果理解嵌入到Transformer架构中的方法。

**Method:** 该论文提出了OPAL（Operant Physical Agent with Language），一个新颖的视觉-语言-动作架构。它通过引入拓扑约束到流匹配中进行机器人控制，并进一步引入了拓扑注意力。该方法将动作序列建模为具有非平凡约束的拓扑结构化表示。

**Result:** OPAL在10个复杂操作任务中表现出优于Octo、OpenVLA和π0等现有方法的卓越性能。它在无需任务特定微调的情况下实现了零样本性能的显著提升，同时将推理计算需求降低了42%。所提出的拓扑方法提供了理论保证，从而产生了更连贯的长序列动作。

**Conclusion:** 该研究强调了通过推导基本物理定律来约束机器人学习问题的搜索空间以及使用拓扑注意力将因果理解嵌入到Transformer架构中的潜力。

> **ai_Abstract:** OPAL是一种新颖的视觉-语言-动作机器人学习架构，它通过在流匹配中引入拓扑约束和拓扑注意力，实现了对物理系统因果理解的编码。该方法将动作序列表示为具有拓扑结构的表示。实验证明，OPAL在复杂操作任务中表现优异，显著提升了零样本性能，降低了计算成本，并生成了更连贯的长序列动作。这表明了利用物理定律约束学习空间和通过拓扑注意力嵌入因果理解的巨大潜力。

> **摘要翻译:** 我们提出了OPAL（Operant Physical Agent with Language），一种新颖的视觉-语言-动作架构，它将拓扑约束引入到流匹配中以实现机器人控制。为此，我们进一步引入了拓扑注意力。我们的方法将动作序列建模为具有非平凡约束的拓扑结构化表示。在10个复杂操作任务中的实验结果表明，与之前的Octo、OpenVLA和π0等方法相比，OPAL表现出卓越的性能。我们的架构在无需任务特定微调的情况下实现了零样本性能的显著提升，同时将推理计算需求降低了42%。我们的拓扑方法提供的理论保证带来了更连贯的长序列动作。我们的结果突出了通过从基本物理定律中推导来约束机器人学习问题搜索空间的潜力，以及使用拓扑注意力将因果理解嵌入到Transformer架构中的可能性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [584] [A Nonlinear MPC Framework for Loco-Manipulation of Quadrupedal Robots with Non-Negligible Manipulator Dynamics](https://arxiv.org/abs/2507.22042)
> *四足机器人运动操作的非线性MPC框架，考虑不可忽略的机械臂动力学*

*Ruturaj Sambhus, Kapi Ketan Mehta, Ali MirMohammad Sadeghi, Basit Muhammad Imran, Jeeseop Kim, Taizoon Chunawala, Vittorio Pastore, Sujith Vijayan, Kaveh Akbari Hamed* | **Category: cs.RO, math.OC** | **Updated: 2025-07-29**

**Keywords:** 非线性MPC, 运动操作, 四足机器人, 机械臂动力学, 分解策略

**Comment:** 

> **TL;DR:** 提出了一种高效的非线性MPC框架，用于四足机器人运动操作，解决了机械臂动力学不可忽略的问题。

**AI_Comments:** 该论文提出了一种创新的分层非线性MPC框架，通过巧妙地结合运动模板模型和机械臂的全阶动力学模型，有效解决了四足机器人运动操作中机械臂动力学不可忽略的挑战。其计算效率（60 Hz实时求解）和在实际硬件上的验证，对于提升复杂机器人系统的自主能力具有重要意义。该方法展示了在处理外部干扰和复杂环境下的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的MPC方法在处理具有高自由度模型的腿足机器人运动操作任务时，计算效率不足，无法有效处理机械臂动力学不可忽略的情况。

**Method:** 本文提出了一种计算高效的非线性MPC（NMPC）框架。该框架采用分解策略，将单刚体（SRB）等运动模板模型与机器人机械臂的全阶动力学模型结合，进行力矩级控制。NMPC以60 Hz的频率实时求解，生成的运动轨迹由500 Hz的低层全身控制器（WBC）跟踪，机械臂的最优力矩指令直接应用。通过数值仿真和硬件实验在Unitree Go2四足机器人上验证。

**Result:** 所提出的NMPC框架在执行多种运动操作任务时表现出强大的鲁棒稳定性，有效处理了外部干扰、有效载荷变化和不平坦地形。

**Conclusion:** 该非线性MPC框架能够有效且鲁棒地解决四足机器人与不可忽略机械臂动力学相结合的运动操作任务。

> **ai_Abstract:** 本文介绍了一种用于四足机器人运动操作的计算高效非线性模型预测控制（NMPC）框架。该框架通过分解策略将运动模板模型与机械臂的全阶动力学模型结合，实现了对具有不可忽略机械臂动力学的四足机器人的力矩级控制。该分层控制架构能够以60 Hz的频率实时求解NMPC问题，并与低层全身控制器协同工作。通过仿真和硬件实验验证，该框架在处理外部干扰、载荷变化和不平坦地形时表现出鲁棒性，有效完成了多种运动操作任务。

> **摘要翻译:** 模型预测控制（MPC）结合降阶模板模型已成为动态腿足运动轨迹优化的强大工具。然而，腿足机器人执行的运动操作任务引入了额外的复杂性，需要计算高效的MPC算法来处理高自由度（DoF）模型。本文提出了一种计算高效的非线性MPC（NMPC）框架，专为配备机器人机械臂的四足机器人运动操作任务量身定制，其中机械臂的动力学相对于四足机器人而言不可忽略。所提出的框架采用分解策略，将运动模板模型（例如单刚体（SRB）模型）与机器人机械臂的全阶动力学模型耦合，进行力矩级控制。这种分解使得NMPC问题能够以60 Hz的频率在滚动时域内进行高效实时求解。NMPC生成的运动最优状态和输入轨迹由以500 Hz运行的低层非线性全身控制器（WBC）跟踪，而机械臂的最优力矩指令则直接应用。这种分层控制架构通过广泛的数值仿真和在配备4.4公斤4自由度Kinova机械臂的15公斤Unitree Go2四足机器人上的硬件实验得到验证。鉴于Kinova机械臂的动力学相对于Go2基座不可忽略，所提出的NMPC框架在执行各种运动操作任务时表现出强大的鲁棒稳定性，有效处理了外部干扰、有效载荷变化和不平坦地形。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [598] [Fluidically Innervated Lattices Make Versatile and Durable Tactile Sensors](https://arxiv.org/abs/2507.21225)
> *流体神经晶格实现多功能耐用触觉传感器*

*Annan Zhang, Miguel Flores-Acton, Andy Yu, Anshul Gupta, Maggie Yao, Daniela Rus* | **Category: cs.RO, cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-28**

**Keywords:** 触觉传感, 软体机器人, 流体神经, 3D打印, 弹性体晶格

**Comment:** Accepted for publication in the proceedings of the 2025 International
  Symposium on Experimental Robotics (ISER)

> **TL;DR:** 本文介绍了一种通过流体神经技术实现的被动软体机器人指尖触觉传感器，该传感器利用3D打印弹性体晶格中的气道压力变化进行感应，具有简单、可扩展、耐用的特点，并能准确预测接触位置和力。

**AI_Comments:** 这项研究的创新之处在于其“流体神经”概念，通过将简单的气道集成到3D打印的弹性体晶格中，实现了无需复杂材料或设计的触觉传感。这种方法不仅简化了制造过程，还提高了传感器的耐用性和可扩展性，对于推动机器人触觉感知在实际应用中的发展具有重要意义。其单材料、易于制造的特性使其在机器人领域具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 触觉传感对于机器人在动态和非结构化环境中导航至关重要，特别是在精细物体操作、表面探索和人机交互等应用中。

**Method:** 本文引入了一种被动软体机器人指尖，集成了通过3D打印弹性体晶格和嵌入式气道制造的触觉传感。这种称为“流体神经”的传感方法通过检测密封气道内的压力变化来工作。研究人员对传感器响应进行了表征，开发了几何模型来估计尖端位移，并训练了一个神经网络来预测接触位置和接触力。此外，该指尖还与导纳控制器集成以模拟弹簧行为，并验证了其在高冲击和循环载荷条件下的耐用性。

**Result:** 该研究成功地表征了传感器的响应，开发了几何模型以估计尖端位移，并训练了一个神经网络以准确预测接触位置和接触力。此外，该指尖与导纳控制器集成后能够模拟弹簧行为，并通过触觉反馈展示了环境探索能力，并在高冲击和循环载荷条件下验证了其耐久性。

**Conclusion:** 这种触觉传感技术在简易性、适应性和耐用性方面具有优势，为多功能机器人操作开辟了新的机遇。

> **ai_Abstract:** 本文提出了一种新型的软体机器人触觉传感器，该传感器基于3D打印的弹性体晶格，并采用“流体神经”方法，通过监测嵌入式气道内的压力变化来感知触觉。这种传感器设计简单、制造可扩展、材料单一且具有高耐用性。研究人员通过实验表征了传感器的性能，建立了几何模型，并利用神经网络实现了接触位置和力的精确预测。此外，该传感器还展示了在环境探索中的应用潜力和在高负载下的耐久性，为机器人精细操作提供了新的可能性。

> **摘要翻译:** 触觉传感在使机器人能够导航动态和非结构化环境中发挥着基础性作用，特别是在精细物体操作、表面探索和人机交互等应用中。在本文中，我们介绍了一种集成了触觉传感的被动软体机器人指尖，该指尖使用带有嵌入式气道的3D打印弹性体晶格制造。这种被称为流体神经的传感方法，通过检测密封气道内的压力变化，将晶格转化为触觉传感器，为机器人触觉传感提供了一种简单而稳健的解决方案。与依赖复杂材料或设计的传统方法不同，流体神经提供了一种简单、可扩展、单一材料的制造工艺。我们对传感器的响应进行了表征，开发了几何模型来估计尖端位移，并训练了一个神经网络来准确预测接触位置和接触力。此外，我们还将指尖与导纳控制器集成以模拟弹簧状行为，通过触觉反馈展示了其环境探索能力，并验证了其在高冲击和循环载荷条件下的耐久性。这种触觉传感技术在简易性、适应性和耐久性方面具有优势，并为多功能机器人操作开辟了新的机会。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [618] [Diffusion Denoiser-Aided Gyrocompassing](https://arxiv.org/abs/2507.21245)
> *扩散去噪器辅助的陀螺罗盘定向*

*Gershy Ben-Arie, Daniel Engelsman, Rotem Dror, Itzik Klein* | **Category: cs.RO, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 陀螺罗盘定向, 扩散去噪, 航向估计, 低成本陀螺仪, 自主导航

**Comment:** 8 pages, 8 figures

> **TL;DR:** 本文提出了一种新颖的扩散去噪器辅助陀螺罗盘定向方法，通过在深度学习模型输入前处理惯性传感器信号，显著提高了低成本陀螺仪的定向精度，对于自主平台导航具有重要意义。

**AI_Comments:** 该论文的创新点在于将扩散去噪技术引入陀螺罗盘定向领域，并与深度学习模型结合，有效地解决了低成本陀螺仪在复杂环境下精度受限的问题。其重要性体现在为自主平台提供了更可靠的导航解决方案，尤其是在缺乏外部辅助且对传感器成本敏感的应用场景中。

<details>
  <summary>Details</summary>

**Motivation:** 在自动驾驶等实际应用中，由于尺寸、重量和功率限制，传感器质量受限，导致低成本陀螺仪的测量噪声严重降低了陀螺罗盘定向性能。在没有外部导航辅助的情况下，使用低成本陀螺仪实现准确及时的陀螺罗盘定向是一个重大挑战。

**Method:** 本文提出了一种新颖的扩散去噪器辅助陀螺罗盘定向方法。该方法将基于扩散的去噪框架与增强型基于学习的航向估计模型相结合。扩散去噪器在将原始惯性传感器信号输入深度学习模型之前进行处理，从而实现准确的陀螺罗盘定向。

**Result:** 使用模拟和真实传感器数据进行的实验表明，所提出的方法与基于模型的陀螺罗盘定向相比，陀螺罗盘定向精度提高了26%；与基于学习的其他方法相比，精度提高了15%。

**Conclusion:** 这项进展对于确保在导航系统中集成低成本陀螺仪的自主平台实现准确和鲁棒的导航具有特殊意义。

> **ai_Abstract:** 本文针对低成本陀螺仪在无外部辅助下进行陀螺罗盘定向时面临的噪声挑战，提出了一种名为“扩散去噪器辅助陀螺罗盘定向”的新方法。该方法将基于扩散的去噪框架与增强型学习航向估计模型相结合，在深度学习模型处理原始惯性传感器信号前进行去噪。实验结果表明，与传统方法和现有学习方法相比，该方法能显著提高陀螺罗盘定向精度，对集成低成本陀螺仪的自主平台实现准确鲁棒导航具有重要意义。

> **摘要翻译:** 准确的初始航向角对于在不同领域中实现高效安全的导航至关重要。与磁力计不同，陀螺仪可以提供独立于磁干扰的准确航向参考，这一过程被称为陀螺罗盘定向。然而，在没有外部导航辅助的情况下，使用低成本陀螺仪实现准确及时的陀螺罗盘定向仍然是一个重大挑战。在自动驾驶等实际应用中，通常会遇到此类挑战，在这些应用中，尺寸、重量和功率限制限制了传感器质量，并且嘈杂的测量严重降低了陀螺罗盘定向性能。为了应对这一挑战，我们提出了一种新颖的扩散去噪器辅助陀螺罗盘定向方法。它将基于扩散的去噪框架与增强型基于学习的航向估计模型相结合。扩散去噪器在将原始惯性传感器信号输入深度学习模型之前进行处理，从而实现准确的陀螺罗盘定向。使用模拟和真实传感器数据进行的实验表明，我们提出的方法与基于模型的陀螺罗盘定向相比，陀螺罗盘定向精度提高了26%，与基于学习的其他方法相比，精度提高了15%。这项进展对于确保在导航系统中集成低成本陀螺仪的自主平台实现准确和鲁棒的导航具有特殊意义。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [627] [ManiTaskGen: A Comprehensive Task Generator for Benchmarking and Improving Vision-Language Agents on Embodied Decision-Making](https://arxiv.org/abs/2505.20726)
> *ManiTaskGen：一种用于基准测试和改进具身决策中视觉-语言代理的综合任务生成器*

*Liu Dai, Haina Wang, Weikang Wan, Hao Su* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 任务生成, 具身决策, 视觉-语言代理, 基准测试, 移动操作

**Comment:** Project Website: https://manitaskgen.github.io/

> **TL;DR:** ManiTaskGen是一个自动生成具身移动操作任务的系统，旨在解决现有基准测试任务受限的问题，并用于评估和改进视觉-语言代理的具身决策能力。

**AI_Comments:** ManiTaskGen的创新之处在于其能够自动生成综合、多样且可行的具身移动操作任务，从而克服了现有基准测试中任务手动标注和场景受限的局限性。这对于具身通用人工智能（E-AGI）的发展至关重要，因为它为视觉-语言代理的训练和评估提供了更广泛、更丰富的资源。该框架的通用性以及在模拟和真实世界场景中的验证，使其成为该领域的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 目前的通用机器人策略的训练和评估通常局限于特定场景中的任务，涉及受限的指令和情景。现有基准测试也通常依赖于在少数场景中手动标注有限的任务。本文认为探索任何给定场景中所有可行的任务至关重要，因为它们能为评估提供广泛的基准，并为代理改进提供宝贵资源。

**Method:** 本文引入了ManiTaskGen，一个新颖的系统，能够为任何给定场景自动生成全面、多样化、可行的移动操作任务。生成的任务包括基于过程的特定指令（例如“将物体从X移动到Y”）和基于结果的抽象指令（例如“清理桌子”）。

**Result:** ManiTaskGen被应用于模拟和真实世界场景，证明了生成任务的有效性和多样性。利用这些任务自动构建了基准，彻底评估了基于现有视觉-语言模型（VLMs）构建的代理的具身决策能力。此外，本文提出了一种简单而有效的方法，利用ManiTaskGen任务来增强具身决策。

**Conclusion:** 这项工作提出了一个适用于任意场景的通用任务生成框架，有助于具身决策代理的基准测试和改进。

> **ai_Abstract:** 本文介绍了ManiTaskGen，一个自动生成具身移动操作任务的系统，旨在解决现有具身代理基准测试任务受限的问题。ManiTaskGen能够为任何场景生成多样化且可行的任务，包括过程性和结果性指令。该系统已在模拟和真实场景中得到验证，并被用于构建基准以评估视觉-语言代理的具身决策能力。此外，本文还提出了一种利用ManiTaskGen任务改进具身决策的方法。这项工作提供了一个通用的任务生成框架，以促进具身决策代理的基准测试和性能提升。

> **摘要翻译:** 构建能够完成任意任务的具身代理是实现具身通用人工智能（E-AGI）的核心目标。尽管最近的工作推动了此类通用机器人策略的发展，但它们的训练和评估通常局限于特定场景中的任务，涉及受限的指令和情景。现有基准测试也通常依赖于在少数场景中手动标注有限的任务。我们认为，探索任何给定场景中所有可行的任务至关重要，因为它们既能为评估提供广泛的基准，也能为代理改进提供宝贵资源。为此，我们引入了 ManiTaskGen，一个新颖的系统，能够为任何给定场景自动生成全面、多样化、可行的移动操作任务。生成的任务既包括基于过程的特定指令（例如，“将物体从 X 移动到 Y”），也包括基于结果的抽象指令（例如，“清理桌子”）。我们将 ManiTaskGen 应用于模拟和真实世界场景，证明了生成任务的有效性和多样性。然后，我们利用这些任务自动构建基准，彻底评估了基于现有视觉-语言模型（VLMs）构建的代理的具身决策能力。此外，我们提出了一种简单而有效的方法，利用 ManiTaskGen 任务来增强具身决策。总的来说，这项工作提出了一个适用于任意场景的通用任务生成框架，有助于具身决策代理的基准测试和改进。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [639] [NMPCM: Nonlinear Model Predictive Control on Resource-Constrained Microcontrollers](https://arxiv.org/abs/2507.21259)
> *NMPCM：资源受限微控制器上的非线性模型预测控制*

*Van Chung Nguyen, Pratik Walunj, Chuong Le, An Duy Nguyen, Hung Manh La* | **Category: cs.RO** | **Updated: 2025-07-28**

**Keywords:** 非线性模型预测控制, 微控制器, 四旋翼无人机, 计算效率, 实时系统

**Comment:** 

> **TL;DR:** 该研究提出了一种高效的NMPC解决方案（NMPCM），使其能够在资源受限的微控制器上运行，并成功应用于四旋翼无人机。

**AI_Comments:** 这篇论文的创新点在于成功地将计算复杂度高的非线性模型预测控制（NMPC）部署到资源受限的微控制器上，解决了长期存在的实际应用难题。其重要性体现在为动态机器人系统（特别是无人机）的自主控制提供了更高效、更精确的板载解决方案，有望推动NMPC在嵌入式系统中的广泛应用。

<details>
  <summary>Details</summary>

**Motivation:** 非线性模型预测控制（NMPC）虽是控制动态机器人系统的强大方法，但其高计算复杂度使其难以在资源受限的微控制器上实现，而全NMPC在微控制器上的应用仍是一个重大挑战。

**Method:** 本文提出了一种高效的解决方案NMPCM，用于在微控制器上生成和部署NMPC以控制四旋翼无人机。该方法旨在优化计算效率同时保持高控制精度。

**Result:** 通过Gazebo/ROS仿真和真实世界实验验证了该方法的有效性，证明其能够在实时系统中实现高频率的NMPC执行。

**Conclusion:** 本文成功解决了在资源受限微控制器上实现全NMPC的挑战，提供了一个高效且高精度的解决方案，适用于动态机器人系统，如四旋翼无人机。

> **ai_Abstract:** 本文针对非线性模型预测控制（NMPC）在资源受限微控制器上实现困难的问题，提出了一种名为NMPCM的高效解决方案。NMPCM优化了计算效率并保持了高控制精度，成功实现了在微控制器上部署NMPC以控制四旋翼无人机。仿真和实际实验均验证了其在实时系统中实现高频率NMPC的能力。

> **摘要翻译:** 非线性模型预测控制（NMPC）是一种控制高动态机器人系统的强大方法，因为它考虑了系统动力学并在每一步优化控制输入。然而，其高计算复杂度使得在资源受限的微控制器上实现变得不切实际。尽管最近的研究表明带有线性化动力学的模型预测控制（MPC）在微控制器上是可行的，但应用完整的NMPC仍然是一个重大挑战。这项工作提出了一种在微控制器上生成和部署NMPC（NMPCM）以控制四旋翼无人机的高效解决方案。所提出的方法优化了计算效率，同时保持了高控制精度。Gazebo/ROS仿真和真实世界实验验证了该方法的有效性，证明了其在实时系统中实现高频率NMPC执行的能力。代码可在以下网址获取：https://github.com/aralab-unr/NMPCM。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [659] [Autonomous Exploration with Terrestrial-Aerial Bimodal Vehicles](https://arxiv.org/abs/2507.21338)
> *陆空双模车辆的自主探索*

*Yuman Gao, Ruibin Zhang, Tiancheng Lai, Yanjun Cao, Chao Xu, Fei Gao* | **Category: cs.RO** | **Updated: 2025-07-28**

**Keywords:** 自主探索, 双模车辆, 蒙特卡洛树搜索, 能量时间感知, 机器人规划

**Comment:** 

> **TL;DR:** 本文提出了一种用于陆空双模车辆的自主探索分层框架，通过扩展蒙特卡洛树搜索来优化模式选择和视点序列，以应对能量和时间限制，并在仿真和实际平台中验证了其有效性。

**AI_Comments:** 该论文的创新点在于提出了一个分层的自主探索框架，并引入了扩展的蒙特卡洛树搜索来解决陆空双模车辆在能量和时间受限下的模式选择和路径规划问题。这种结合多模态灵活性与资源优化的方法，对于提升复杂环境下机器人自主探索能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于实际探索任务中固有的能量和时间限制，需要一种方法来利用陆空双模车辆的灵活运动模式进行自主探索。

**Method:** 本文提出一个分层框架，首先提取环境信息以识别信息丰富的区域，生成一组潜在的双模视点。然后引入一种扩展的蒙特卡洛树搜索方法，策略性地优化模式选择和视点序列，以自适应地管理能量和时间约束。结合改进的双模车辆运动规划器，构建了一个完整的双模能量和时间感知探索系统。

**Result:** 广泛的模拟和在定制的真实世界平台上的部署证明了该系统的有效性。

**Conclusion:** 所提出的双模能量和时间感知探索系统能够有效应对自主探索中的能量和时间限制。

> **ai_Abstract:** 本文针对陆空双模车辆的自主探索，提出了一种分层框架。该框架通过提取环境信息、生成双模视点，并利用扩展蒙特卡洛树搜索策略性地优化模式选择和视点序列，以有效管理探索任务中的能量和时间约束。结合改进的运动规划器，构建了一个完整的能量和时间感知探索系统，并在仿真和真实世界平台中验证了其有效性。

> **摘要翻译:** 陆空双模车辆结合了空中机器人的高机动性和地面机器人的长续航能力，为自主探索提供了巨大的潜力。鉴于实际探索任务中固有的能量和时间限制，我们提出了一个用于双模车辆的分层框架，以利用其灵活的运动模式进行探索。首先提取环境信息以识别信息丰富的区域，然后生成一组潜在的双模视点。为了自适应地管理能量和时间限制，我们引入了一种扩展的蒙特卡洛树搜索方法，该方法策略性地优化了模式选择和视点序列。结合改进的双模车辆运动规划器，我们提出了一个完整的双模能量和时间感知探索系统。广泛的模拟和在定制的真实世界平台上的部署证明了我们系统的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [680] [Projecting the New Body: How Body Image Evolves During Learning to Walk with a Wearable Robot](https://arxiv.org/abs/2507.21384)
> *投射新身体：穿戴式机器人行走学习过程中身体意象如何演变*

*I-Chieh Lee, He Huang* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-28**

**Keywords:** 穿戴式机器人, 身体意象, 运动学习, 步态, 感知校准

**Comment:** 

> **TL;DR:** 穿戴式机器人使用者在学习行走时，其身体意象会随步态改善而演变，但感知与实际运动间存在差异，提示需要增强感知和频繁校准以优化训练和技术发展。

**AI_Comments:** 这篇论文创新性地探讨了穿戴式机器人使用者的身体意象如何随运动学习而演变，并指出了感知与实际运动之间存在的关键差异。其重要性在于为未来穿戴式机器人和辅助技术的设计提供了具体指导，强调了具身感和感知校准在提升用户体验和训练效果中的核心作用。

<details>
  <summary>Details</summary>

**Motivation:** 穿戴式机器人改变了人体结构、运动能力和身体感知，挑战了传统人体运动系统的定义。本研究旨在探讨在使用穿戴式机器人学习行走时，身体意象如何随时间演变。

**Method:** 研究测量了穿戴者在每次训练后步态表现和通过感知运动选择系数（SCoMo）测量的感知身体意象。基于扩展到穿戴者-机器人系统的人体运动学习理论，研究假设感知身体意象的学习会与实际步态改善共同演变，并变得更确定和准确。

**Result:** 结果证实运动学习改善了身体和感知的步态模式趋于正常，表明通过练习，穿戴者将机器人腿整合到其感觉运动系统中，以实现穿戴者-机器人运动协调。然而，感知与实际运动之间存在持续差异，这可能是由于穿戴者缺乏对假肢的直接感觉和控制。此外，后期训练中感知的高估可能会限制进一步的运动改善。

**Conclusion:** 研究结果表明，增强穿戴者对穿戴式机器人的感觉以及频繁校准身体意象感知对于下肢穿戴式机器人的有效训练和开发更具具身感的辅助技术至关重要。

> **ai_Abstract:** 本研究探讨了穿戴式机器人使用者在学习行走过程中身体意象的演变。通过测量步态表现和感知身体意象，研究发现运动学习能改善物理和感知的步态，并使穿戴者将机器人腿整合到其感觉运动系统中。然而，感知与实际运动之间存在持续差异，且感知高估可能限制进一步的运动改善。研究强调增强穿戴者对机器人的感知和校准身体意象对于优化训练和开发更具具身感的辅助技术的重要性。

> **摘要翻译:** 穿戴式机器人技术的进步挑战了传统的人体运动系统定义，因为穿戴式机器人重新定义了身体结构、运动能力以及对自身身体的感知。我们测量了每次训练后的步态表现和通过感知运动选择系数（SCoMo）感知的身体意象。基于扩展到穿戴者-机器人系统的人体运动学习理论，我们假设在使用机器人腿行走时，感知的身体意象学习会与实际步态改善共同演变，并变得更加确定和准确。我们的结果证实，运动学习改善了身体和感知的步态模式趋于正常，表明通过练习，穿戴者将机器人腿整合到他们的感觉运动系统中，以实现穿戴者-机器人运动协调。然而，感知与实际运动之间存在持续的差异，这可能是由于穿戴者缺乏对假肢的直接感觉和控制。此外，后期训练中感知的高估可能会限制进一步的运动改善。这些发现表明，增强人类对穿戴式机器人的感觉和频繁校准身体意象感知对于下肢穿戴式机器人的有效训练以及开发更具具身感的辅助技术至关重要。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [689] [Learning Approach to Efficient Vision-based Active Tracking of a Flying Target by an Unmanned Aerial Vehicle](https://arxiv.org/abs/2506.18264)
> *基于学习方法实现无人机对飞行目标的视觉主动高效追踪*

*Jagadeswara PKV Pothuri, Aditya Bhatt, Prajit KrisshnaKumar, Manaswin Oddiraju, Souma Chowdhury* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 视觉追踪, 无人机, 深度学习, 强化学习, 核相关滤波器

**Comment:** Accepted for presentation in proceedings of AIAA Aviation 2025

> **TL;DR:** 本文提出了一种基于学习的方法，通过结合深度学习与KCF进行高效目标检测，并利用强化学习进行机动决策，使无人机能够主动追踪飞行目标。

**AI_Comments:** 该论文通过将传统滤波（KCF）与深度学习相结合用于感知，并利用强化学习实现鲁棒控制，提出了一种创新的混合方法，这代表了无人机完全自主高效追踪领域的重要进展。在AirSim中进行训练和测试也为复杂的控制任务提供了实用的方法。

<details>
  <summary>Details</summary>

**Motivation:** 自主跟踪空中飞行物体在民用和国防领域具有重要应用，如搜救和反无人机系统。地面跟踪存在基础设施、范围和可行性限制。无人机进行的视觉主动跟踪可以弥补这些不足，并支持空中协调。

**Method:** 该方法解决了两个耦合问题：1) 高效准确的目标检测和状态估计：提出将标准深度学习架构与核相关滤波器（KCF）相结合。2) 机动决策：利用强化学习训练一个神经控制器，用于快速计算速度机动，并为此开发了新的状态空间、动作空间和奖励公式。感知框架在实验室规模设置中验证，控制模型在AirSim中训练和测试。

**Result:** 所提出的感知框架（深度学习+KCF）在实验室设置中验证了其计算效率和准确性。针对复杂目标机动，训练的强化学习模型在AirSim中测试表现优于基线PID控制，在跟踪正常运行时间和保持与目标的平均距离方面均有提升。

**Conclusion:** 本文提出的结合深度学习与KCF的感知方法和基于强化学习的控制方法，为无人机高效视觉主动追踪飞行目标提供了有效的解决方案，并在关键指标上超越了传统方法。

> **ai_Abstract:** 本文旨在解决无人机对飞行目标进行高效视觉主动追踪的挑战，该技术对多种应用至关重要。它处理两个核心问题：准确高效的目标检测与状态估计，以及智能的机动决策。针对检测问题，论文提出了一种将深度学习与核相关滤波器（KCF）创新性结合的方法，实现了计算效率与准确性兼顾。在机动控制方面，论文利用强化学习训练了一个神经控制器，并在仿真中证明其在跟踪正常运行时间和目标距离保持方面优于传统PID控制。

> **摘要翻译:** 对空中飞行物体的自主跟踪具有重要的民用和国防应用，范围从搜救到反无人机系统（counter-UAS）。基于地面的跟踪需要设置基础设施，可能受到范围限制，并且在偏远地区、拥挤城市或植被茂密地区可能不可行。从另一架机载飞行器（例如，追逐无人机（UAV））对空中物体进行基于视觉的主动跟踪有望填补这一重要空白，并服务于空中协调用例。无人机基于视觉的主动跟踪需要解决两个耦合问题：1）计算高效且准确的目标物体检测和目标状态估计；2）机动决策，以确保目标在未来的时间步中保持在视野内，并处于有利于持续检测的位置。作为第一个问题的解决方案，本文提出了一种将标准深度学习架构与核相关滤波器（KCF）新颖集成的方法，以实现计算高效的物体检测，且不牺牲精度，这与独立的学习或滤波方法不同。所提出的感知框架通过实验室规模的设置进行了验证。对于第二个问题，为了克服限制传统控制器有效性的线性假设和背景变化，我们提出了使用强化学习来训练一个神经控制器，以快速计算速度机动。为此目的，开发了新的状态空间、动作空间和奖励公式，并在AirSim中使用仿真进行训练。训练后的模型也在AirSim中针对复杂目标机动进行了测试，发现在跟踪正常运行时间和跟踪过程中保持的平均距离方面，其性能优于基线PID控制。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [701] [Sound Source Localization for Human-Robot Interaction in Outdoor Environments](https://arxiv.org/abs/2507.21431)
> *户外环境下人机交互中的声源定位*

*Victor Liu, Timothy Du, Jordy Sehn, Jack Collier, François Grondin* | **Category: cs.RO, cs.HC, eess.AS** | **Updated: 2025-07-29**

**Keywords:** 声源定位, 人机交互, 麦克风阵列, 声学回声消除, 户外环境

**Comment:** 

> **TL;DR:** 本文提出了一种用于户外嘈杂环境下人机交互的声源定位策略，结合了无人地面车辆上的麦克风阵列和操作员的近讲麦克风，实现了优于现有技术的定位精度。

**AI_Comments:** 该论文的创新之处在于结合了无人地面车辆上的麦克风阵列和操作员的近讲麦克风，并辅以先进的信号处理技术（如粗对齐、回声消除和理想比率掩码），从而在充满挑战的户外嘈杂环境中实现了鲁棒的声源定位。其超越现有技术水平的性能证明了其在实际人机交互应用中的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了在嘈杂的户外环境中实现丰富的人机交互，需要为机器人提供来自活跃操作员声音的方向信息。

**Method:** 该方法结合了嵌入在无人地面车辆上的麦克风阵列和操作员附近的异步近讲麦克风。它采用信号粗对齐策略和时域声学回声消除算法，以估计时频理想比率掩码，从而从干扰和环境噪声中分离目标语音，实现选择性声源定位。

**Result:** 结果表明，在信噪比为1dB时，平均角度误差为4度，在5度误差范围内的准确率达到95%，这显著优于现有最先进的定位方法。

**Conclusion:** 所提出的声源定位策略能够有效隔离目标语音并提供声源方向，从而在嘈杂场景中实现机器人与操作员的丰富交互，并展现出优于现有方法的性能。

> **ai_Abstract:** 本文提出了一种创新的声源定位策略，旨在嘈杂的户外环境中增强人机交互。该方法结合了无人地面车辆上的麦克风阵列和操作员的近讲麦克风，并利用信号粗对齐、时域声学回声消除和时频理想比率掩码来有效隔离目标语音。实验结果表明，该策略在1dB信噪比下实现了4度的平均角度误差和95%的5度以内准确率，性能显著优于现有技术。

> **摘要翻译:** 本文提出了一种声源定位策略，该策略依赖于嵌入在无人地面车辆中的麦克风阵列和操作员附近的异步近讲麦克风。该策略将信号粗对齐策略与时域声学回声消除算法相结合，以估计时频理想比率掩码，从而将目标语音从干扰和环境噪声中分离出来。这实现了选择性声源定位，并为机器人提供了来自活跃操作员声音的到达方向，从而在嘈杂场景中实现丰富的人机交互。结果表明，在信噪比为1dB时，平均角度误差为4度，在5度误差范围内的准确率达到95%，这显著优于现有最先进的定位方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [730] [Multifunctional physical reservoir computing in soft tensegrity robots](https://arxiv.org/abs/2507.21496)
> *软张拉整体机器人中的多功能物理储层计算*

*Ryo Terajima, Katsuma Inoue, Kohei Nakajima, Yasuo Kuniyoshi* | **Category: cs.RO, cs.LG, nlin.CD** | **Updated: 2025-07-29**

**Keywords:** 物理储层计算, 软体机器人, 张拉整体机器人, 具身认知, 未训练吸引子

**Comment:** 25 pages, 12 figures. The following article has been accepted by
  Chaos: An Interdisciplinary Journal of Nonlinear Science

> **TL;DR:** 本研究探讨了在软张拉整体机器人中利用物理储层计算实现多功能行为控制，并发现了反映机器人内在特性的“未训练吸引子”。

**AI_Comments:** 本论文在将物理储层计算应用于软张拉整体机器人的背景下引入了“未训练吸引子”的概念，这是一个创新性发现。这表明机器人的固有物理特性在其计算能力中发挥作用，超越了显式训练，为具身智能提供了新见解，并可能通过利用内在动力学来简化机器人控制。

<details>
  <summary>Details</summary>

**Motivation:** 最近的研究表明物理系统的动力学可用于信息处理（物理储层计算，PRC），软体机器人是这类系统的典型。本研究旨在将此方法扩展到软张拉整体机器人，以控制和嵌入多种行为，并探索PRC中“未训练吸引子”对具身AI和认知的潜在影响。

**Method:** 本研究是一项模拟研究，将物理储层计算方法应用于软张拉整体机器人，以控制并嵌入多种行为。通过对机器人与环境组成的系统进行多稳态动力学分析和吸引子分析，以发现“未训练吸引子”。

**Result:** 由机器人和环境组成的系统是一个多稳态动力学系统，能够从不同初始条件收敛到不同的吸引子。吸引子分析揭示了在训练数据之外存在“未训练吸引子”，它们反映了张拉整体机器人及其与环境相互作用的内在属性和结构。

**Conclusion:** 本研究阐明了物理储层计算（特别是“未训练吸引子”的发现）在理解迄今尚未完全解决的具身认知各种特征方面的潜力。

> **ai_Abstract:** 本模拟研究探讨了将物理储层计算（PRC）应用于软张拉整体机器人，以实现多功能行为的控制和嵌入。研究表明，机器人与环境系统形成了一个具有不同吸引子的多稳态动力学系统。重要的是，研究发现了系统状态空间中的“未训练吸引子”，这些吸引子揭示了张拉整体机器人固有的特性。论文强调了这些发现对于推动具身AI研究中具身认知的理解的潜力。

> **摘要翻译:** 最近的研究表明，物理系统的动力学可以在物理储层计算（PRC）的框架下用于所需的信息处理。软体机器人就是这种物理系统的例子，它们的非线性身体-环境动力学可以用于计算和生成控制其自身行为所需的运动信号。在本模拟研究中，我们将这种方法扩展到不仅控制和嵌入一种，而且多种行为到一种称为张拉整体机器人的软体机器人中。由机器人和环境组成的系统是一个多稳态动力学系统，从不同的初始条件收敛到不同的吸引子。此外，吸引子分析揭示了系统状态空间中存在训练数据之外的“未训练吸引子”。这些未训练的吸引子反映了张拉整体机器人及其与环境相互作用的内在属性和结构。这些PRC最新发现在具身AI研究中的影响仍未被探索。我们在此说明了它们理解迄今尚未完全解决的具身认知各种特征的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [746] [Automated UAV-based Wind Turbine Blade Inspection: Blade Stop Angle Estimation and Blade Detail Prioritized Exposure Adjustment](https://arxiv.org/abs/2507.04922)
> *基于无人机的风力涡轮机叶片自动化检测：叶片停止角度估计和叶片细节优先曝光调整*

*Yichuan Shi, Hao Liu, Haowen Zheng, Haowen Yu, Xianqi Liang, Jie Li, Minmin Ma, Ximin Lyu* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 无人机检测, 风力涡轮机叶片, 停止角度估计, 曝光调整, 自动化检测

**Comment:** 8 pages, 7 figures, final submission to IROS 2025

> **TL;DR:** 本文提出了一种无人机检测平台以及两种方法：基于费马点的叶片停止角度估计和叶片细节优先曝光调整，以解决现有无人机风力涡轮机叶片自动化检测中平台限制、角度估计鲁棒性差以及曝光调整缺失的问题。

**AI_Comments:** 该论文解决了无人机风力涡轮机叶片检测领域的实际痛点，特别是针对叶片停止角度估计的鲁棒性和图像捕获过程中的曝光优化。引入费马点概念用于角度估计是其创新点之一，而优先曝光调整则直接提升了检测数据的实用价值。广泛的实地测试增强了其结果的可信度，对于推动自动化风电检测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的无人机风力涡轮机叶片检测平台难以满足自动化检测任务需求，当前的叶片停止角度估计方法易受环境因素影响，以及在图像捕获过程中缺乏实时叶片细节优先曝光调整，导致细节丢失无法恢复。

**Method:** 本文提出了一个无人机检测平台以满足自动化检测要求。引入了一种基于费马点的叶片停止角度估计方法，以提高精度和成功率。提出了一种叶片细节优先曝光调整方法，以确保图像捕获期间的适当亮度和细节保留。

**Result:** 在5个运营中的风电场，对10种风力涡轮机模型进行了超过120次飞行测试，验证了所提出方法在增强检测自主性方面的有效性。

**Conclusion:** 本文提出的无人机检测平台、基于费马点的叶片停止角度估计方法和叶片细节优先曝光调整方法，有效解决了风力涡轮机叶片自动化检测中的关键挑战，显著提高了检测的自主性和质量。

> **ai_Abstract:** 本文针对无人机风力涡轮机叶片自动化检测中存在的平台限制、叶片停止角度估计鲁棒性不足以及实时曝光调整缺失等问题，提出了一套解决方案。该方案包括一个新型无人机检测平台、一种基于费马点的叶片停止角度估计方法（提高了精度和成功率），以及一种叶片细节优先曝光调整方法（确保图像质量和细节保留）。通过在多个风电场的广泛测试，验证了这些方法在提升检测自主性方面的有效性。

> **摘要翻译:** 无人机（UAVs）在风力涡轮机叶片自动化检测中至关重要。然而，该领域仍然存在一些问题。首先，现有检测平台在满足自动化检测任务和场景需求方面面临挑战。此外，当前的叶片停止角度估计方法容易受到环境因素的影响，限制了其鲁棒性。另外，在捕获过程中缺乏实时的叶片细节优先曝光调整，导致丢失的细节无法通过后期优化恢复。为了解决这些挑战，我们引入了一个平台和两种方法。最初，提出了一个无人机检测平台以满足自动化检测要求。随后，引入了一种基于费马点的叶片停止角度估计方法，实现了更高的精度和成功率。最后，我们提出了一种叶片细节优先曝光调整方法，以确保图像捕获期间的适当亮度和细节保留。大量的测试，包括在5个运营中的风电场对10种风力涡轮机模型进行的超过120次飞行，验证了所提出方法在增强检测自主性方面的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [760] [Decision Transformer-Based Drone Trajectory Planning with Dynamic Safety-Efficiency Trade-Offs](https://arxiv.org/abs/2507.21506)
> *基于决策Transformer的无人机轨迹规划与动态安全-效率权衡*

*Chang-Hun Ji, SiWoon Song, Youn-Hee Han, SungTae Moon* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 无人机轨迹规划, 决策Transformer, 安全-效率权衡, Return-to-Go, 动态调整

**Comment:** Accepted to IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) 2025. \c{opyright} 2025 IEEE. Personal use of this
  material is permitted. \c{opyright} 2025 IEEE. Personal use of this material
  is permitted. Permission from IEEE must be obtained for all other uses

> **TL;DR:** 本文提出了一种基于决策Transformer的无人机轨迹规划器，通过单一参数Return-to-Go (RTG) 动态调整安全-效率权衡，无需专家知识，并在模拟和真实世界实验中表现出色。

**AI_Comments:** 这项研究的创新之处在于将决策Transformer应用于无人机轨迹规划，并通过单一的Return-to-Go (RTG) 参数实现了安全-效率的动态、直观调整，极大地简化了传统方法中复杂的参数调优过程。其重要性在于提供了一种高效且用户友好的解决方案，提升了无人机在复杂未知环境中的适应性和任务执行能力。实验验证包括了模拟和真实世界，增加了研究结果的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于多项式的规划器在调整安全-效率权衡时需要专家知识且效果不佳，而基于强化学习的规划器未能明确解决这一权衡问题。无人机轨迹规划器应能根据任务需求在未知环境中动态调整安全-效率权衡。

**Method:** 引入了一种基于决策Transformer的轨迹规划器，利用单一参数Return-to-Go (RTG) 作为“温度参数”来动态调整安全-效率权衡。RTG直观地衡量轨迹的安全性和效率，因此RTG调整不需要专家知识。

**Result:** 在Gazebo模拟（结构化网格和非结构化随机环境）中验证了该方法。实验结果表明，该规划器可以通过简单调整RTG参数动态调整安全-效率权衡，并且在各种RTG设置下优于现有基线方法，在偏向安全时生成更安全的轨迹，在偏向效率时生成更高效的轨迹。真实世界实验进一步证实了所提出规划器的可靠性和实用性。

**Conclusion:** 本文提出的基于决策Transformer的无人机轨迹规划器通过单一RTG参数实现了安全-效率的动态权衡，无需专家知识，并在模拟和真实世界中展现出优越的性能和实用性。

> **ai_Abstract:** 本文提出了一种基于决策Transformer的无人机轨迹规划器，旨在解决传统方法在动态调整安全-效率权衡方面的局限性。该规划器通过引入Return-to-Go (RTG) 作为单一温度参数，实现了无需专家知识的动态权衡调整。RTG直观反映轨迹的安全性和效率。通过Gazebo模拟和真实世界实验验证，该方法不仅能够有效调整安全-效率权衡，而且在不同RTG设置下，其性能优于现有基线方法，能根据需求生成更安全或更高效的轨迹。

> **摘要翻译:** 无人机轨迹规划器应能根据未知环境中不断变化的任务需求，动态调整安全-效率权衡。尽管传统的基于多项式的规划器提供了计算效率和平滑轨迹生成，但它们需要专家知识来调整多个参数以实现这种权衡。此外，即使经过仔细调整，所得的调整也可能无法达到所需的权衡。同样，尽管基于强化学习的规划器在未知环境中具有适应性，但它们没有明确解决安全-效率权衡问题。为了克服这一限制，我们引入了一种基于决策Transformer的轨迹规划器，该规划器利用单一参数Return-to-Go (RTG) 作为“温度参数”来动态调整安全-效率权衡。在我们的框架中，由于RTG直观地衡量轨迹的安全性和效率，因此RTG调整不需要专家知识。我们使用Gazebo模拟在结构化网格和非结构化随机环境中验证了我们的方法。实验结果表明，我们的规划器可以通过简单调整RTG参数动态调整安全-效率权衡。此外，我们的规划器在各种RTG设置下均优于现有基线方法，在偏向安全时生成更安全的轨迹，在偏向效率时生成更高效的轨迹。真实世界实验进一步证实了我们提出的规划器的可靠性和实用性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [777] [Deployment of Objects with a Soft Everting Robot](https://arxiv.org/abs/2507.22188)
> *软翻转机器人物体部署*

*Ethan DeVries, Jack Ferlazzo, Mustafa Ugur, Laura H. Blumenschein* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-29**

**Keywords:** 软翻转机器人, 有效载荷部署, 机器人运动, 危险环境, 模型预测

**Comment:** 9 pages, 10 figures, This work has been submitted to the IEEE for
  possible publication

> **TL;DR:** 本文研究并实验证明了软翻转机器人携带和部署重达1.5公斤的物体，并能在复杂地形中（如通过狭窄孔洞、进行大角度转弯、跨越间隙）进行有效运输。

**AI_Comments:** 这篇论文的创新之处在于填补了软翻转机器人在有效载荷部署方面研究的空白，特别是通过机器人内部运输物体。其重要性体现在为软机器人应用于危险环境中的实际救援和物资运输提供了坚实的实验数据和理论基础。研究详细量化了机器人的负载能力和运动限制，为未来的软机器人设计和应用提供了宝贵的参考。

<details>
  <summary>Details</summary>

**Motivation:** 软翻转机器人在探索任务中具有优势，但其在移动和部署有效载荷方面的潜力尚未得到充分研究。利用其导航能力和可展开的身体，在危险区域运送有效载荷将是许多应用中的一项重要能力。

**Method:** 本文分析了软翻转机器人如何通过其内部部署更大、更重的有效载荷，并分析了可部署的物体类型及其可穿越的地形特征。在现有模型的基础上，提出了量化有效载荷对机器人生长和自支撑影响的方法，并开发了预测有效载荷滑动的模型。随后，通过一系列任务（转向、垂直运输、穿过孔洞和跨越间隙）实验量化了软翻转机器人使用各种形状、尺寸和重量的有效载荷进行运输的能力。

**Result:** 研究结果表明，软翻转机器人可以运输各种形状、重量达1.5公斤的有效载荷；能够通过与有效载荷间隙仅为0.01厘米的圆形孔径；能够实现高达135度的离散转弯；能够跨越1.15米长的无支撑间隙。

**Conclusion:** 软翻转机器人能够有效地在各种复杂地形中运输多种形状和重量的有效载荷，包括重达1.5公斤的物体，并能通过狭窄空间、进行大角度转弯和跨越长距离间隙。

> **ai_Abstract:** 本文探讨了软翻转机器人在部署有效载荷方面的潜力。研究分析了机器人内部如何运输更大、更重的物体，并建立了量化有效载荷影响的模型。实验结果表明，该机器人能有效运输重达1.5公斤的多种形状有效载荷，并能穿越狭窄孔洞、完成大角度转弯以及跨越较长间隙，展示了其在危险区域进行有效载荷交付的强大能力。

> **摘要翻译:** 软翻转机器人与传统刚性机器人相比具有显著优势，包括增强的灵活性、改进的环境交互以及在不可预测环境中安全导航。虽然软翻转机器人已被广泛用于探索型任务，但其在此类任务中移动和部署有效载荷的潜力却较少被研究，以往的工作主要集中于机器人的传感器和工具。利用软翻转机器人的导航能力和可展开的身体在危险区域运送有效载荷，例如将水瓶带给被困在废墟下的人，将在许多应用中代表一项重要的能力。在这项工作中，我们分析了软翻转机器人如何通过其内部部署更大、更重的有效载荷。我们分析了可以部署的物体以及它们可以穿越的地形特征。在现有模型的基础上，我们提出了量化有效载荷对机器人生长和自支撑影响的方法，并开发了一个预测有效载荷滑动的模型。然后，我们通过一系列任务：转向、垂直运输、穿过孔洞和跨越间隙，实验量化了使用各种有效载荷形状、尺寸和重量的软翻转机器人的有效载荷运输能力。总的来说，结果表明我们可以运输各种形状和重达1.5公斤的有效载荷，并且我们可以通过与有效载荷间隙仅为0.01厘米的圆形孔径，进行高达135度的离散转弯，并跨越1.15米长的无支撑间隙。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [793] [LITE: A Learning-Integrated Topological Explorer for Multi-Floor Indoor Environments](https://arxiv.org/abs/2507.21517)
> *LITE：一种用于多层室内环境的学习集成拓扑探索器*

*Junhao Chen, Zhen Zhang, Chengrui Zhu, Xiaojun Hou, Tianyang Hu, Huifeng Wu, Yong Liu* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 多层探索, 拓扑探索, 学习集成, 室内导航, 机器人探索

**Comment:** IROS2025

> **TL;DR:** LITE是一种用于多层室内环境探索的学习集成拓扑探索器，它将环境分解为楼层-楼梯拓扑结构，并结合学习或非学习的2D探索方法进行3D探索，表现出更高的探索效率和泛化能力。

**AI_Comments:** LITE的创新点在于将多层环境分解为拓扑结构，并提出了一种灵活的框架，能够集成现有的2D探索方法进行3D探索，有效解决了传统方法和现有学习方法在多层环境中的局限性。其结合注意力机制的2D探索策略提升了效率，并在真实机器人上的验证进一步证明了其实用性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 多层室内环境探索仍是开放研究领域，尽管基于学习的探索器在2D环境中表现出巨大潜力，但大多数受限于2D环境，无法有效应对多层3D环境。

**Method:** 本文提出了一种名为LITE的学习集成拓扑探索器，用于多层室内环境。LITE将环境分解为楼层-楼梯拓扑结构，从而能够无缝集成学习或非学习的2D探索方法进行3D探索。在探索过程中，使用基于YOLO11的实例分割模型逐步构建楼层-楼梯拓扑，并通过有限状态机实现楼层间的转换。此外，LITE还实现了一种基于注意力机制的2D探索策略，利用注意力机制捕获不同区域间的空间依赖性，以确定下一个全局目标，从而实现更高效的探索。

**Result:** 在HM3D和MP3D数据集上进行的广泛比较和消融研究表明，LITE提出的2D探索策略在探索效率方面显著优于所有基线探索器。在多个3D多层环境中的实验表明，该框架与各种2D探索方法兼容，有助于实现有效的多层室内探索。在真实世界中，通过四足机器人验证了该方法，突出了其强大的泛化能力。

**Conclusion:** LITE通过将多层环境分解为楼层-楼梯拓扑结构，并集成高效的2D探索策略，成功实现了多层室内环境的有效探索，并展现出优越的探索效率、兼容性和泛化能力。

> **ai_Abstract:** 本文提出LITE，一种用于多层室内环境探索的学习集成拓扑探索器。LITE通过将环境分解为楼层-楼梯拓扑，并结合基于YOLO11的实例分割和注意力机制的2D探索策略，实现了高效的3D探索。实验证明，LITE在探索效率上优于基线方法，并兼容多种2D探索方式，在真实世界中也展现出良好的泛化能力。

> **摘要翻译:** 这项工作专注于多层室内探索，这仍然是一个开放的研究领域。与传统方法相比，最近基于学习的探索器由于其鲁棒的环境学习和建模能力，展现出巨大的潜力，但大多数仅限于2D环境。在本文中，我们提出了一种用于多层室内环境的学习集成拓扑探索器LITE。LITE将环境分解为楼层-楼梯拓扑结构，从而能够无缝集成学习或非学习的2D探索方法进行3D探索。在探索过程中，我们使用基于YOLO11的实例分割模型逐步构建楼层-楼梯拓扑，智能体可以通过有限状态机在楼层之间转换。此外，我们实现了一种基于注意力机制的2D探索策略，该策略利用注意力机制捕获不同区域之间的空间依赖性，从而确定下一个全局目标以实现更高效的探索。在HM3D和MP3D数据集上进行的广泛比较和消融研究表明，我们提出的2D探索策略在探索效率方面显著优于所有基线探索器。此外，在多个3D多层环境中的实验表明，我们的框架与各种2D探索方法兼容，有助于实现有效的多层室内探索。最后，我们通过四足机器人在真实世界中验证了我们的方法，突出了其强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [802] [Unscented Kalman Filter with a Nonlinear Propagation Model for Navigation Applications](https://arxiv.org/abs/2507.10082)
> *用于导航应用的非线性传播模型无迹卡尔曼滤波器*

*Amit Levy, Itzik Klein* | **Category: cs.RO, eess.SP** | **Updated: 2025-07-29**

**Keywords:** 无迹卡尔曼滤波器, 非线性传播模型, 导航应用, sigma点, 误差状态向量

**Comment:** 6 pages, 4 figures

> **TL;DR:** 本文提出了一种新的方法，通过非线性动态模型传播sigma点，以提高无迹卡尔曼滤波器在导航应用中的精度和性能。

**AI_Comments:** 本文的创新点在于提出了根据非线性动态模型传播无迹卡尔曼滤波器中sigma点的新方法。这对于提高非线性导航估计的精度和稳定性具有重要意义，尤其是在复杂动态环境下。

<details>
  <summary>Details</summary>

**Motivation:** 无迹卡尔曼滤波器（UKF）在导航应用中常用于非线性估计，但均值和协方差矩阵的预测对其稳定行为至关重要。传统的sigma点传播方式需要改进以提高滤波器精度和导航性能。

**Method:** 本文引入了一种创新方法，根据导航误差状态向量的非线性动态模型传播sigma点。

**Result:** 该方法提高了滤波器的精度和导航性能，并通过自主水下航行器在多种场景下记录的真实传感器数据验证了其优势。

**Conclusion:** 所提出的根据非线性动态模型传播sigma点的方法，能有效提高无迹卡尔曼滤波器在导航应用中的精度和性能。

> **ai_Abstract:** 本文提出了一种用于无迹卡尔曼滤波器的新型sigma点传播方法，该方法基于导航误差状态向量的非线性动态模型。实验证明，该方法能有效提升滤波器在导航应用中的精度和整体性能，并通过自主水下航行器的真实传感器数据进行了验证。

> **摘要翻译:** 无迹卡尔曼滤波器是一种常用于导航应用的非线性估计算法。均值和协方差矩阵的预测对于滤波器的稳定行为至关重要。这种预测是通过根据当前动态模型传播sigma点来完成的。在本文中，我们介绍了一种创新方法，根据导航误差状态向量的非线性动态模型传播sigma点。这提高了滤波器的精度和导航性能。我们使用自主水下航行器在多个场景中记录的真实传感器数据，展示了我们提出的方法的优势。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [821] [Model Predictive Adversarial Imitation Learning for Planning from Observation](https://arxiv.org/abs/2507.21533)
> *基于观测的规划：模型预测对抗模仿学习*

*Tyler Han, Yanda Bao, Bhaumik Mehta, Gabriel Guo, Anubhav Vishwakarma, Emily Kang, Sanghun Jung, Rosario Scalise, Jason Zhou, Bryan Xu, Byron Boots* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 模型预测控制, 对抗模仿学习, 规划, 逆向强化学习, 观测学习

**Comment:** Open-source code in process of being cleaned and documented for
  release. Please contact directly in the meantime for code. Under Review

> **TL;DR:** 本文提出了一种结合模型预测控制和对抗模仿学习的新方法，用于从不完整观测数据中学习规划器，显著提高了样本效率、泛化能力和鲁棒性。

**AI_Comments:** 该论文的创新之处在于其将IRL、MPC与AIL相结合，实现了从不完整观测数据中端到端学习规划器。这种统一的方法不仅提高了学习效率和鲁棒性，还在可解释性、复杂性和安全性方面带来了潜在益处，对于解决现实世界中数据稀疏和不确定性问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人类演示数据通常模糊且不完整，这促使模仿学习方法需要同时展示可靠的规划行为。现有的从演示中进行规划的方法通常涉及通过逆向强化学习（IRL）学习奖励函数，然后通过模型预测控制（MPC）部署该奖励。

**Method:** 作者通过用基于规划的智能体替换逆向强化学习（IRL）中的策略来统一现有方法，并将其与对抗模仿学习（AIL）联系起来。这种新颖的公式使得能够从仅观测的演示中端到端地交互式学习规划器。

**Result:** 研究观察到在样本效率、域外泛化和鲁棒性方面有显著改进。评估包括在模拟控制基准和使用少量到单个仅观测演示的真实世界导航实验中进行。

**Conclusion:** 该方法通过将逆向强化学习与模型预测控制和对抗模仿学习相结合，实现了从仅观测演示中端到端地交互式学习规划器，并在可解释性、复杂性、安全性、样本效率、泛化能力和鲁棒性方面带来了益处和显著改进。

> **ai_Abstract:** 本文提出了一种新颖的模型预测对抗模仿学习方法，旨在从模糊和不完整的仅观测演示中学习可靠的规划行为。该方法通过将逆向强化学习（IRL）中的策略替换为基于规划的智能体，并与对抗模仿学习（AIL）相结合，实现了规划器的端到端交互式学习。实验结果表明，该方法在样本效率、域外泛化能力和鲁棒性方面取得了显著提升，并在模拟和真实世界导航任务中得到了验证。

> **摘要翻译:** 人类演示数据通常模糊且不完整，这促使模仿学习方法需要同时展示可靠的规划行为。从演示中进行规划的常见范式涉及通过逆向强化学习（IRL）学习奖励函数，然后通过模型预测控制（MPC）部署该奖励。为了统一这些方法，我们推导了一种用基于规划的智能体替代IRL中策略的方法。通过与对抗模仿学习的联系，这种公式使得能够从仅观测的演示中端到端地交互式学习规划器。除了在可解释性、复杂性和安全性方面的好处外，我们还研究并观察到在样本效率、域外泛化和鲁棒性方面有显著改进。该研究包括在模拟控制基准和使用少量到单个仅观测演示的真实世界导航实验中进行的评估。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [856] [Pretraining a Unified PDDL Domain from Real-World Demonstrations for Generalizable Robot Task Planning](https://arxiv.org/abs/2507.21545)
> *从真实世界演示中预训练统一的PDDL领域，用于可泛化的机器人任务规划*

*Haoming Ye, Yunxiao Xiao, Cewu Lu, Panpan Cai* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 机器人任务规划, PDDL, 领域预训练, 泛化能力, 零样本学习

**Comment:** Preprint. Under review

> **TL;DR:** 提出UniDomain框架，通过预训练统一的PDDL领域，显著提升机器人任务规划在复杂、未见任务上的泛化能力和规划效率。

**AI_Comments:** 这篇论文的创新点在于提出了一个从大规模真实世界演示中预训练统一PDDL领域的方法，有效解决了现有LLM和符号规划结合方法泛化能力受限的问题。其通过构建一个包含大量操作符、谓词和因果边的统一领域，并支持原子领域的检索与融合，实现了对复杂未见任务的零样本解决，对机器人任务规划的实用化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界中的机器人任务规划需要处理语言和视觉中的隐式约束，但现有的大型语言模型（LLMs）和视觉语言模型（VLMs）在长周期结构和符号接地方面存在困难。此外，现有结合LLMs与符号规划的方法通常依赖于手工或狭窄的领域，限制了泛化能力。

**Method:** 提出UniDomain框架，该框架从12,393个机器人操作演示视频中提取原子领域，形成一个包含3137个操作符、2875个谓词和16481个因果边的统一PDDL领域。给定目标任务类别，UniDomain从统一领域中检索相关原子并系统地将它们融合为高质量的元领域，以支持规划中的组合泛化。

**Result:** 在多样化的真实世界任务上进行实验表明，UniDomain能以零样本方式解决复杂的、未见过的任务，相比最先进的LLM和LLM-PDDL基线，任务成功率提高了58%，规划最优性提高了160%。

**Conclusion:** UniDomain通过预训练统一的PDDL领域，显著提升了机器人在真实世界复杂任务规划中的泛化能力和规划效率。

> **ai_Abstract:** UniDomain是一个新颖的机器人任务规划框架，通过从大量真实世界机器人操作演示中预训练一个统一的PDDL领域来解决现有方法泛化能力不足的问题。该框架能够从视频中提取原子领域并构建一个庞大的统一领域，然后根据目标任务检索并融合相关原子以支持组合泛化。实验证明，UniDomain在解决复杂、未见任务方面表现出色，显著提高了任务成功率和规划最优性，优于现有LLM及LLM-PDDL基线。

> **摘要翻译:** 机器人任务规划在现实世界环境中需要对来自语言和视觉的隐式约束进行推理。虽然大型语言模型（LLMs）和视觉语言模型（VLMs）提供了强大的先验知识，但它们在长周期结构和符号接地方面表现不佳。现有结合LLMs与符号规划的方法通常依赖于手工或狭窄的领域，限制了泛化能力。我们提出了UniDomain，一个从机器人操作演示中预训练PDDL领域并将其应用于在线机器人任务规划的框架。它从12,393个操作视频中提取原子领域，形成一个包含3137个操作符、2875个谓词和16481个因果边的统一领域。给定目标任务类别，它从统一领域中检索相关原子，并系统地将它们融合为高质量的元领域，以支持规划中的组合泛化。在多样化的真实世界任务上的实验表明，UniDomain能够以零样本方式解决复杂的、未见过的任务，相比最先进的LLM和LLM-PDDL基线，任务成功率提高了58%，规划最优性提高了160%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [858] [MP1: MeanFlow Tames Policy Learning in 1-step for Robotic Manipulation](https://arxiv.org/abs/2507.10543)
> *MP1：MeanFlow 在一步机器人操作中驯服策略学习*

*Juyi Sheng, Ziyi Wang, Peiming Li, Mengyuan Liu* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 机器人操作, 策略学习, MeanFlow, 1-NFE, 点云

**Comment:** 

> **TL;DR:** MP1 使用 MeanFlow 范式，通过直接学习区间平均速度，在单次网络评估中生成机器人操作动作轨迹，实现更快更精确的推理，并在基准测试中表现优异。

**AI_Comments:** 这篇论文的创新点在于将 MeanFlow 范式应用于机器人操作的策略学习，实现了单次网络评估生成动作轨迹，显著提高了推理速度和精度。通过避免 ODE 解算器和一致性约束，简化了模型并提升了性能。引入的分散损失也有效地提升了模型的泛化能力，这对于机器人学习，特别是少样本学习非常重要。其在实际应用中的高效性（超快推理速度）和优越的性能使其具有很高的实用价值和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 机器人学习中的生成模型面临扩散模型迭代采样慢和基于流的方法受架构限制（常依赖显式一致性损失）的权衡问题。

**Method:** 引入 MP1，将 3D 点云输入与 MeanFlow 范式结合，以单次网络函数评估（1-NFE）生成动作轨迹。通过“MeanFlow 恒等式”直接学习区间平均速度，避免额外一致性约束。消除推理时的数值ODE解算器误差。结合 CFG 提高轨迹可控性。引入轻量级分散损失（Dispersive Loss）以增强泛化能力。

**Result:** 在 Adroit 和 Meta-World 基准测试以及真实世界场景中验证。MP1 实现了卓越的平均任务成功率，比 DP3 高 10.2%，比 FlowPolicy 高 7.3%。平均推理时间仅为 6.8 毫秒，比 DP3 快 19 倍，比 FlowPolicy 快近 2 倍。

**Conclusion:** MP1 通过其独特的方法解决了机器人操作中策略学习的效率和精度问题，显著提高了性能并缩短了推理时间，为机器人学习提供了一个高效且通用的解决方案。

> **ai_Abstract:** 本文提出了 MP1，一种针对机器人操作的新型策略学习方法，旨在解决现有生成模型在效率和精度上的权衡。MP1 结合 3D 点云输入与 MeanFlow 范式，能够通过单次网络评估生成精确的动作轨迹。其核心在于通过“MeanFlow 恒等式”直接学习区间平均速度，从而避免了额外的一致性约束和数值 ODE 解算器误差。此外，MP1 引入了 CFG 增强可控性，并采用分散损失提高泛化能力。实验结果表明，MP1 在多个基准测试中取得了显著优于现有方法的成功率和推理速度。

> **摘要翻译:** 在机器人操作中，机器人学习已成为一种普遍方法。然而，该领域内的生成模型面临着扩散模型缓慢的迭代采样与更快的基于流的方法的架构限制（通常依赖显式一致性损失）之间的基本权衡。为了解决这些局限性，我们引入了 MP1，它将 3D 点云输入与 MeanFlow 范式相结合，通过一次网络函数评估（1-NFE）生成动作轨迹。通过“MeanFlow 恒等式”直接学习区间平均速度，我们的策略避免了任何额外的一致性约束。这种公式消除了推理过程中的数值 ODE 解算器误差，从而产生更精确的轨迹。MP1 进一步整合了 CFG 以提高轨迹可控性，同时保留了 1-NFE 推理，而无需重新引入结构约束。由于细微的场景上下文变化对于机器人学习至关重要，尤其是在少样本学习中，我们引入了一种轻量级的分散损失（Dispersive Loss），在训练期间排斥状态嵌入，从而在不减慢推理速度的情况下提高泛化能力。我们在 Adroit 和 Meta-World 基准测试以及真实世界场景中验证了我们的方法。实验结果表明，MP1 实现了卓越的平均任务成功率，比 DP3 高 10.2%，比 FlowPolicy 高 7.3%。其平均推理时间仅为 6.8 毫秒，比 DP3 快 19 倍，比 FlowPolicy 快近 2 倍。我们的代码可在 https://github.com/LogSSim/MP1.git 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [898] [Multi-robot LiDAR SLAM: a practical case study in underground tunnel environments](https://arxiv.org/abs/2507.21553)
> *多机器人激光雷达SLAM：地下隧道环境中的一个实际案例研究*

*Federica Di Lauro, Domenico G. Sorrenti, Miguel Angel Sotelo* | **Category: cs.RO** | **Updated: 2025-07-30**

**Keywords:** 多机器人SLAM, 激光雷达, 地下隧道, 回环检测, 启发式方法

**Comment:** 14 pages, 14 figures

> **TL;DR:** 本文分析了多机器人激光雷达SLAM系统在地下隧道环境中的局限性，发现回环检测是主要失败原因，并提出了一种新的启发式方法来克服这些限制。

**AI_Comments:** 本文通过对实际案例（地下隧道）的深入分析，揭示了多机器人激光雷达SLAM中回环检测作为关键失败源的局限性，并提出了一种实用的启发式方法。其创新性在于针对特定环境挑战提出解决方案，并为未来的研究方向提供了指引。

<details>
  <summary>Details</summary>

**Motivation:** 分析现有去中心化激光雷达SLAM系统的局限性，并发现主要的失败来源，即回环检测产生过多的误报。

**Method:** 分析去中心化激光雷达SLAM系统管线，发现回环检测是主要失败来源。针对此问题，开发并提出了一种新的启发式方法来克服这些限制。研究环境为极具挑战性的地下隧道。

**Result:** 发现回环检测是导致现有去中心化激光雷达SLAM系统出现过多误报的一个重要失败来源。

**Conclusion:** 通过分析去中心化激光雷达SLAM系统，发现回环检测是主要限制，并提出了一种新的启发式方法来克服这些限制，同时指出了潜在的未充分探索的研究领域。

> **ai_Abstract:** 本文对多机器人激光雷达SLAM系统进行了深入分析，特别关注其在极具挑战性的地下隧道环境中的应用。研究发现，现有去中心化系统的主要局限在于回环检测环节产生过多的误报。为解决这一问题，作者提出了一种新的启发式方法，旨在提高系统的鲁棒性。此外，文章还指出了未来多机器人SLAM研究中值得探索的新方向。

> **摘要翻译:** 多机器人SLAM旨在通过多个机器人之间的交互实现定位和地图构建。在本文描述的工作中，我们分析了一个去中心化激光雷达SLAM系统的管线，以研究现有技术的当前局限性，并发现了一个重要的失败来源，即回环检测是过多误报的来源。因此，我们开发并提出了一种新的启发式方法来克服这些局限性。这项工作所参考的环境是极具挑战性的地下隧道案例。我们还强调了仍未充分探索的潜在新研究领域。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [921] [Scanning Bot: Efficient Scan Planning using Panoramic Cameras](https://arxiv.org/abs/2507.16175)
> *扫描机器人：使用全景相机进行高效扫描规划*

*Euijeong Lee, Kyung Min Han, Young J. Kim* | **Category: cs.RO** | **Updated: 2025-07-29**

**Keywords:** 扫描规划, 全景相机, 三维重建, 自主导航, 视点规划

**Comment:** 

> **TL;DR:** 该论文提出了一种名为“扫描机器人”的自主扫描规划系统，用于全景相机，能够生成高效、无碰撞的扫描路径，显著提高三维重建的速度和覆盖率。

**AI_Comments:** 该研究的创新之处在于提出了全自主的扫描规划，有效解决了全景相机三维重建中手动操作耗时、效率低下和用户难度大的实际问题。其在真实世界实验中展示的99%覆盖率和3倍速度提升，证明了其在实际应用中的巨大潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 操作全景RGB-D相机进行三维场景重建时，手动选择视点和搬运相机耗时且繁琐，新手用户难以确保足够的特征重叠和避免空间限制。

**Method:** 提出了一种完全自主的扫描规划方法，为环境扫描生成高效的巡视计划，确保无碰撞导航和视点之间足够的重叠。

**Result:** 在真实世界实验中，实现了99%的平均扫描覆盖率，总扫描时间比最先进的规划器快3倍。

**Conclusion:** 所提出的自主扫描规划方法显著提高了使用全景相机进行三维场景重建的效率和覆盖率，优于现有最先进的视点规划器。

> **ai_Abstract:** 本论文介绍了“扫描机器人”，一个针对全景RGB-D相机设计的全自主扫描规划系统，旨在解决手动操作、耗时和空间限制等三维场景重建的挑战。该系统能生成高效、无碰撞的巡视计划，并确保视点间充分重叠。在合成和真实环境中的广泛实验证明，该方法在真实世界中实现了99%的平均扫描覆盖率，并且总扫描时间比现有最先进的规划器快3倍。

> **摘要翻译:** 全景RGB-D相机以其生成高质量三维场景重建的能力而闻名。然而，操作这些相机涉及手动选择视点和物理搬运相机，这使得三维模型的生成既耗时又繁琐。此外，由于空间限制，例如确保视点帧之间有足够的特征重叠，这个过程对于新手用户来说可能具有挑战性。为了解决这些挑战，我们提出了一种完全自主的扫描规划，它为环境扫描生成一个高效的巡视计划，确保无碰撞导航和计划内视点之间足够的重叠。在合成和真实世界环境中进行的广泛实验验证了我们规划器相对于最先进视点规划器的性能。特别是，在真实世界实验中，我们的方法实现了99%的平均扫描覆盖率，并且在总扫描时间上比最先进的规划器快3倍。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [938] [Safety Evaluation of Motion Plans Using Trajectory Predictors as Forward Reachable Set Estimators](https://arxiv.org/abs/2507.22389)
> *使用轨迹预测器作为前向可达集估计器进行运动规划的安全评估*

*Kaustav Chakraborty, Zeyuan Feng, Sushant Veer, Apoorva Sharma, Wenhao Ding, Sever Topan, Boris Ivanovic, Marco Pavone, Somil Bansal* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-30**

**Keywords:** 运动规划安全, 轨迹预测, 前向可达集, 共形预测, 贝叶斯滤波

**Comment:** 

> **TL;DR:** 本文提出了一种利用多模态轨迹预测器作为前向可达集估计器的安全监控器，以评估自动驾驶系统运动规划的安全性，并通过共形预测和贝叶斯滤波器确保其完备性和稳健性。

**AI_Comments:** 该论文的创新点在于将多模态轨迹预测器与前向可达集估计相结合，并引入共形预测和贝叶斯滤波器来解决自动驾驶安全监控中完备性和稳健性的挑战。特别是，贝叶斯滤波器动态调整保守性的机制，对于应对预测器在OOD场景下的不确定性具有重要意义，增强了系统的鲁棒性。这对于提高端到端自动驾驶系统的实际部署安全性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 端到端自动驾驶系统缺乏可解释的中间模块，导致验证整个系统安全性时，对最终输出（即运动规划）的安全性提出了更高的要求。这需要一个既完备（能检测所有不安全规划）又稳健（不误报安全规划）的安全监控器。

**Method:** 本文提出了一种利用现代多模态轨迹预测器来近似周围智能体的前向可达集（FRS）的安全监控器。通过建立一个凸优化程序，从预测的状态分布中高效提取数据驱动的FRS。为确保完备性，采用共形预测来校准FRS，以高概率覆盖真实轨迹。为在分布外（OOD）场景或预测器故障时保持稳健性，引入贝叶斯滤波器根据预测器的观测性能动态调整FRS的保守性。最后，通过检查自车运动规划与这些校准FRS的交集来评估其安全性。

**Result:** 在nuScenes数据集上进行的广泛实验表明，所提出的方法在保持完备性的同时显著提高了稳健性。

**Conclusion:** 该方法为学习型自动驾驶系统提供了一种实用且可靠的安全监控器。

> **ai_Abstract:** 本文提出了一种新颖的安全监控器，旨在解决端到端自动驾驶系统中运动规划的安全验证问题。该方法利用多模态轨迹预测器估算周围智能体的前向可达集（FRS），并通过凸优化程序高效提取这些数据驱动的FRS。为确保检测所有不安全规划（完备性），引入共形预测对FRS进行校准；为防止误报安全规划（稳健性），在预测器性能不佳或面对分布外数据时，采用贝叶斯滤波器动态调整FRS的保守性。通过检查自车运动规划与这些校准FRS的交集来评估碰撞风险。实验结果表明，该方法在保持完备性的同时显著提升了稳健性，为自动驾驶系统提供了一种实用且可靠的安全保障。

> **摘要翻译:** 端到端自主堆栈的出现——通常缺乏可解释的中间模块——增加了确保最终输出（即运动规划）安全以验证整个堆栈安全性的负担。这需要一个既完备（能够检测所有不安全规划）又稳健（不标记安全规划）的安全监控器。在这项工作中，我们提出了一种原则性的安全监控器，它利用现代多模态轨迹预测器来近似周围智能体的前向可达集（FRS）。通过制定一个凸程序，我们根据车道拓扑和智能体历史等场景上下文，直接从预测的状态分布中高效提取这些数据驱动的FRS。为了确保完备性，我们利用共形预测来校准FRS，并保证以高概率覆盖真实轨迹。为了在分布外（OOD）场景或预测器故障时保持稳健性，我们引入了一个贝叶斯滤波器，根据预测器的观测性能动态调整FRS的保守性。然后，我们通过检查自我车辆的运动规划与这些校准FRS的交集来评估其安全性，确保规划在其他车辆合理未来行为下保持无碰撞。在nuScenes数据集上的大量实验表明，我们的方法在保持完备性的同时显著提高了稳健性，为学习型自主堆栈提供了一个实用且可靠的安全监控器。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [4] [Adversarial Reconstruction Feedback for Robust Fine-grained Generalization](https://arxiv.org/abs/2507.21742)
> *用于鲁棒细粒度泛化的对抗性重建反馈*

*Shijie Wang, Jian Shi, Haojie Li* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 细粒度图像检索, 对抗性学习, 重建反馈, 泛化, 知识蒸馏

**Comment:** ICCV 2025

> **TL;DR:** 本文提出了AdvRF，一个对抗性重建反馈框架，通过学习与类别无关的差异表示来解决细粒度图像检索中对未知类别的泛化能力受限的问题，并在细粒度和粗粒度数据集上取得了令人印象深刻的性能。

**AI_Comments:** 该论文提出了一种新颖的对抗性重建反馈机制，巧妙地将细粒度图像检索问题转化为视觉差异重建任务。其核心创新在于通过检索模型和重建模型之间的相互反馈，强制模型学习与类别无关的判别性表示，从而有效解决了传统方法在处理未见类别时的泛化性差的问题。这种利用对抗性思想和知识蒸馏来增强模型鲁棒性和泛化能力的方法具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有细粒度图像检索（FGIR）方法过度依赖预定义类别的监督，导致检索表示中引入类别特定的语义，从而产生对预定义类别的语义依赖，严重阻碍了对未见类别的泛化能力。

**Method:** 我们提出了AdvRF，一个新颖的对抗性重建反馈框架，旨在学习与类别无关的差异表示。AdvRF通过协同检索模型中的类别感知差异定位和重建模型中的类别无关特征学习，将FGIR重新表述为视觉差异重建任务。重建模型揭示了检索模型忽视的残余差异，迫使其提高定位准确性，而检索模型的精炼信号则引导重建模型提高其重建能力。最终，检索模型定位视觉差异，重建模型将这些差异编码为与类别无关的表示，然后通过知识蒸馏转移到检索模型中以实现高效部署。

**Result:** 定量和定性评估表明，我们的AdvRF在广泛使用的细粒度数据集和粗粒度数据集上都取得了令人印象深刻的性能。

**Conclusion:** AdvRF通过学习与类别无关的差异表示，有效解决了细粒度图像检索中现有方法泛化能力受限的问题，并在多种数据集上表现出色，证明了其在增强模型鲁棒性和泛化性方面的有效性。

> **ai_Abstract:** 本文提出了一种名为AdvRF的对抗性重建反馈框架，旨在解决细粒度图像检索（FGIR）中现有方法因依赖预定义类别而导致的泛化能力受限问题。AdvRF将FGIR重构为视觉差异重建任务，通过结合检索模型的类别感知差异定位和重建模型的类别无关特征学习，实现互补增强。重建模型促使检索模型提高定位精度，而检索模型则引导重建模型提升重建能力，最终生成与类别无关的表示。这些表示通过知识蒸馏传递给检索模型，以实现对未见类别的鲁棒泛化。实验结果验证了AdvRF在细粒度和粗粒度数据集上的优越性能。

> **摘要翻译:** 现有细粒度图像检索（FGIR）方法主要依赖预定义类别的监督来学习用于检索细粒度对象的判别性表示。然而，它们无意中将类别特定的语义引入检索表示中，从而产生了对预定义类别的语义依赖，严重阻碍了对未见类别的泛化能力。为了解决这个问题，我们提出了AdvRF，一个新颖的对抗性重建反馈框架，旨在学习与类别无关的差异表示。具体来说，AdvRF通过协同检索模型中的类别感知差异定位和重建模型中的类别无关特征学习，将FGIR重新表述为视觉差异重建任务。重建模型揭示了检索模型忽视的残余差异，迫使其提高定位准确性，而检索模型的精炼信号则引导重建模型提高其重建能力。因此，检索模型定位视觉差异，而重建模型将这些差异编码为与类别无关的表示。然后，这种表示通过知识蒸馏转移到检索模型中以实现高效部署。定量和定性评估表明，我们的AdvRF在广泛使用的细粒度数据集和粗粒度数据集上都取得了令人印象深刻的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [10] [LinDeps: A Fine-tuning Free Post-Pruning Method to Remove Layer-Wise Linear Dependencies with Guaranteed Performance Preservation](https://arxiv.org/abs/2507.21573)
> *LinDeps：一种无需微调的后剪枝方法，用于去除层级线性依赖并保证性能保持*

*Maxim Henry, Adrien Deliège, Anthony Cioppa, Marc Van Droogenbroeck* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 神经网络剪枝, 线性依赖, 后剪枝, 无需微调, 压缩率

**Comment:** 10 pages, 4 figures, 5 tables, 45 references

> **TL;DR:** LinDeps是一种无需微调的后剪枝方法，通过识别和移除线性依赖的滤波器来提高CNN压缩率并保持性能。

**AI_Comments:** LinDeps的创新之处在于其“后剪枝”特性和“无需微调”的性能保证。它通过线性依赖分析和信号恢复机制，解决了传统剪枝方法在处理层内结构依赖性上的不足，并避免了耗时的微调过程，使其成为现有和未来剪枝技术的强大补充，尤其适用于资源受限的部署场景。

<details>
  <summary>Details</summary>

**Motivation:** 卷积神经网络（CNN）的尺寸和复杂性日益增长，给资源受限平台的部署带来了挑战。现有剪枝技术忽略了层内特征图的结构依赖性，导致次优的剪枝决策。

**Method:** LinDeps是一种新颖的后剪枝方法，可应用于任何现有剪枝技术之上。它通过线性依赖分析系统地识别和移除冗余滤波器。具体地，它应用枢轴QR分解到特征图以检测和剪枝线性依赖的滤波器，然后通过新颖的信号恢复机制调整下一层的核，以在无需微调的情况下保持兼容性和性能。

**Result:** 在CIFAR-10和ImageNet数据集上使用VGG和ResNet骨干网络的实验表明，LinDeps提高了现有剪枝技术的压缩率，同时保持了性能，达到了CNN剪枝领域的新SOTA。在无法进行再训练的低资源设置中，LinDeps也显示出显著的剪枝改进和推理加速。

**Conclusion:** LinDeps是任何当前或未来剪枝技术的重要附加组件。

> **ai_Abstract:** 本文提出了一种名为LinDeps的新型后剪枝方法，旨在解决现有CNN剪枝技术在移除冗余时性能下降的问题。LinDeps通过线性依赖分析识别并移除层内的冗余滤波器，具体采用枢轴QR分解来检测线性依赖的滤波器，并通过信号恢复机制调整后续层核，从而在无需微调的情况下保持模型性能。实验结果表明，LinDeps显著提升了现有剪枝方法的压缩率，同时保持了模型性能，并在低资源环境下展现出优越的剪枝效果和推理速度，达到了CNN剪枝领域的新里程碑。

> **摘要翻译:** 卷积神经网络（CNN）广泛应用于许多计算机视觉任务。然而，它们不断增长的尺寸和复杂性对在资源受限平台上高效部署提出了重大挑战。因此，网络剪枝已成为一种有效的方法，通过移除冗余或不重要的参数来减少神经网络的尺寸和计算需求。然而，剪枝的一个根本挑战在于如何在不降低性能的情况下最优地移除冗余。大多数现有剪枝技术忽略了层内特征图之间的结构依赖性，导致次优的剪枝决策。在这项工作中，我们引入了LinDeps，一种新颖的后剪枝方法，即一种可以应用于任何剪枝技术之上的剪枝方法，它通过线性依赖分析系统地识别和移除冗余滤波器。特别是，LinDeps将枢轴QR分解应用于特征图，以检测和剪枝线性依赖的滤波器。然后，一种新颖的信号恢复机制调整下一层的核，以在无需任何微调的情况下保持兼容性和性能。我们在CIFAR-10和ImageNet数据集上使用VGG和ResNet骨干网络的实验表明，LinDeps在保持性能的同时提高了现有剪枝技术的压缩率，从而在CNN剪枝领域达到了新的SOTA。我们还在无法进行再训练的低资源设置中对LinDeps进行了基准测试，这表明与现有SOTA方法相比，剪枝有了显著改进并加快了推理速度。因此，LinDeps构成了任何当前或未来剪枝技术的重要附加组件。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [23] [Evaluating Deep Learning Models for African Wildlife Image Classification: From DenseNet to Vision Transformers](https://arxiv.org/abs/2507.21364)
> *评估用于非洲野生动物图像分类的深度学习模型：从DenseNet到Vision Transformers*

*Lukman Jibril Aliyu, Umar Sani Muhammad, Bilqisu Ismail, Nasiru Muhammad, Almustapha A Wakili, Seid Muhie Yimam, Shamsuddeen Hassan Muhammad, Mustapha Abdullahi* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 深度学习, 图像分类, 非洲野生动物, 迁移学习, 模型部署

**Comment:** Accepted as a camera-ready paper at Deep Learning Indaba 2025
  (Kigali, Rwanda)

> **TL;DR:** 本研究比较了用于非洲野生动物图像分类的深度学习模型。Vision Transformer (ViT-H/14) 达到了最高的准确率 (99%) 但计算成本高昂，而DenseNet-201 在卷积网络中表现最佳 (67%) 且更易于部署，被集成到Hugging Face Gradio Space中以实现实时应用。

**AI_Comments:** 该论文的创新之处在于其对非洲野生动物图像分类中深度学习模型的实际比较和部署考量。它不仅展示了不同模型（包括Vision Transformers和CNNs）的性能差异，更重要的是强调了在资源受限的保护场景中，模型的可部署性和计算成本是关键因素。将DenseNet-201集成到Hugging Face Gradio Space的实践，为非洲本土AI研究提供了有价值的案例和见解，有助于推动AI技术在野生动物保护中的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 非洲野生动物数量在过去五十年中下降了超过65%，因此急需利用深度学习进行图像分类来监测和保护生物多样性。

**Method:** 本研究对用于非洲野生动物图像自动分类的深度学习模型进行了比较研究，重点是使用冻结特征提取器的迁移学习。使用了包含水牛、大象、犀牛和斑马四种物种的公共数据集，评估了DenseNet-201、ResNet-152、EfficientNet-B4和Vision Transformer ViT-H/14的性能。

**Result:** DenseNet-201在卷积网络中表现最佳，准确率为67%；ViT-H/14实现了最高的整体准确率，达到99%，但计算成本显著更高，引发了部署担忧。实验强调了准确性、资源需求和可部署性之间的权衡。性能最佳的CNN（DenseNet-201）被集成到Hugging Face Gradio Space中以实现实时野外使用。

**Conclusion:** 这项工作通过提供模型选择、数据集准备和深度学习工具在野生动物保护中负责任部署的实用见解，促进了非洲本土AI研究。研究表明，轻量级模型在保护环境中具有部署可行性。

> **ai_Abstract:** 本研究比较了多种深度学习模型在非洲野生动物图像分类中的表现，以应对野生动物数量锐减的威胁。通过对DenseNet-201、ResNet-152、EfficientNet-B4和ViT-H/14等模型在四种非洲物种数据集上的评估，发现ViT-H/14虽然准确率最高（99%），但计算成本过高。DenseNet-201作为性能最佳的卷积神经网络（67%准确率），在准确性和可部署性之间取得了良好平衡，并被成功部署到Hugging Face Gradio Space中，证明了轻量级模型在实际保护应用中的可行性。研究强调了在模型选择时需权衡准确性、资源消耗和部署便捷性。

> **摘要翻译:** 非洲的野生动物种群面临严峻威胁，过去五十年间脊椎动物数量下降了65%以上。为此，利用深度学习进行图像分类已成为生物多样性监测和保护的一种有前景的工具。本文对用于非洲野生动物图像自动分类的深度学习模型进行了比较研究，重点关注使用冻结特征提取器的迁移学习。我们使用包含水牛、大象、犀牛和斑马四种物种的公共数据集，评估了DenseNet-201、ResNet-152、EfficientNet-B4和Vision Transformer ViT-H/14的性能。DenseNet-201在卷积网络中表现最佳（准确率为67%），而ViT-H/14实现了最高的整体准确率（99%），但计算成本显著更高，引发了部署担忧。我们的实验强调了准确性、资源需求和可部署性之间的权衡。性能最佳的CNN（DenseNet-201）被集成到Hugging Face Gradio Space中以实现实时野外使用，展示了在保护环境中部署轻量级模型的可行性。这项工作通过提供模型选择、数据集准备和深度学习工具在野生动物保护中负责任部署的实用见解，促进了非洲本土AI研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [27] [Unified 3D MRI Representations via Sequence-Invariant Contrastive Learning](https://arxiv.org/abs/2501.12057)
> *统一的3D MRI表征：通过序列不变对比学习*

*Liam Chalcroft, Jenny Crinion, Cathy J. Price, John Ashburner* | **Category: cs.CV, physics.med-ph** | **Updated: 2025-07-29**

**Keywords:** 3D MRI, 自监督学习, 对比学习, 序列不变, 定量MRI

**Comment:** 

> **TL;DR:** 提出一种序列不变自监督学习框架，利用定量MRI模拟多种对比图像，学习与序列无关的3D MRI表征，在数据稀疏环境下显著提升了分割和去噪性能。

**AI_Comments:** 这篇论文的创新点在于提出了“序列不变”的对比学习方法，有效地解决了3D MRI数据稀疏和序列多样性带来的挑战。通过利用定量MRI生成多对比度图像并强制表征一致性，该方法学习了更具鲁棒性和泛化能力的解剖学特征，这对于医疗图像分析领域具有重要意义。其在低数据量设置下的显著性能提升和对未见站点的泛化能力，预示着其在实际临床应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 2D自然图像的自监督深度学习在3D MRI中难以应用，因为3D MRI数据稀缺，且预训练的2D骨干网络无法捕获体积上下文信息。

**Method:** 提出一个“序列不变”的自监督学习框架，利用定量MRI (qMRI)。通过从单个3D qMRI扫描模拟多种MRI对比图像，并强制这些对比图像之间保持一致的表征，从而学习以解剖学为中心而非特定于序列的特征。

**Result:** 在健康大脑分割 (IXI)、脑卒中病变分割 (ARC) 和MRI去噪任务上，相对于基线自监督学习方法取得了显著提升，尤其是在数据稀疏环境下（Dice系数提高高达+8.3%，PSNR提高高达+4.2 dB）。该方法还能泛化到未曾见过的站点。

**Conclusion:** 该序列不变的自监督学习框架能够学习到统一的3D MRI表征，并在多种任务和协议下表现出色，支持可扩展的临床应用。

> **ai_Abstract:** 该研究提出了一种名为“序列不变”的自监督学习框架，旨在解决3D MRI数据稀缺和2D预训练模型无法捕获体积上下文的问题。通过利用定量MRI模拟多种对比图像并强制表征一致性，该框架能够学习到与MRI序列无关的解剖学中心特征。实验证明，该方法在多种3D MRI任务（如分割和去噪）上，尤其是在数据量较少的情况下，显著优于现有自监督学习方法，并且具有良好的泛化能力，有望促进可扩展的临床应用。

> **摘要翻译:** 自监督深度学习加速了2D自然图像分析，但很难转化为3D MRI，因为3D MRI数据稀缺，且预训练的2D骨干网络无法捕获体积上下文信息。我们提出了一个“序列不变”的自监督框架，利用定量MRI (qMRI)。通过从单个3D qMRI扫描模拟多种MRI对比图像，并强制这些对比图像之间保持一致的表征，我们学习了以解剖学为中心而非特定于序列的特征。结果是一个在各种任务和协议中表现出色的单一3D编码器。在健康大脑分割 (IXI)、脑卒中病变分割 (ARC) 和MRI去噪的实验中，与基线自监督学习方法相比，显示出显著的提升，尤其是在数据稀疏设置下（Dice系数高达+8.3%，PSNR高达+4.2 dB）。它还能泛化到未曾见过的站点，支持可扩展的临床使用。代码和训练模型已在 https://github.com/liamchalcroft/contrast-squared 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [38] [Few-Shot Vision-Language Reasoning for Satellite Imagery via Verifiable Rewards](https://arxiv.org/abs/2507.21745)
> *通过可验证奖励实现卫星图像的少样本视觉-语言推理*

*Aybora Koksal, A. Aydin Alatan* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 少样本学习, 视觉-语言推理, 强化学习, 卫星图像, 遥感

**Comment:** ICCV 2025 Workshop on Curated Data for Efficient Learning (CDEL). 10
  pages, 3 figures, 6 tables. Our model, training code and dataset will be at
  https://github.com/aybora/FewShotReasoning

> **TL;DR:** 本文提出了首个用于卫星图像的少样本可验证奖励强化学习（RLVR）框架，无需标注数据，仅依赖轻量级、基于规则的奖励，通过少量样本即可显著提升模型性能，并在数据稀缺领域实现高效、经济的视觉-语言推理模型开发。

**AI_Comments:** 这篇论文的创新点在于提出了首个将少样本强化学习与可验证奖励结合的框架（RLVR），用于解决卫星图像等遥感领域中数据标注稀缺和昂贵的问题。其重要性体现在它提供了一种实用且高效的解决方案，使得在数据受限的专业领域也能开发出高性能的视觉-语言推理模型。通过仅使用少量甚至一个示例就能达到显著效果，极大地降低了数据标注成本和模型开发门槛，对于推动遥感AI的发展具有重要意义。论文还探讨了提示设计和损失权重对训练稳定性的影响，增加了方法的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言和视觉-语言模型虽然具有强大的推理能力，但对于遥感等专业领域来说，由于标注数据稀缺且昂贵，这些模型并不实用。

**Method:** 本文提出了首个用于卫星图像的少样本可验证奖励强化学习（RLVR）框架。该框架消除了对图像描述标注的监督需求，仅依赖于轻量级的、基于规则的二元奖励或基于IoU的奖励。通过将语言模型中的“1-shot RLVR”范式应用于视觉-语言模型，作者采用策略梯度优化，仅使用少量（甚至一个）精心策划的示例来对齐模型输出，以执行卫星推理任务。

**Result:** 在多个遥感基准测试（包括分类、视觉问答和接地）上的综合实验表明，即使单个示例也能显著优于基础模型。扩展到128个示例时，性能可以达到或超过使用数千个标注样本训练的模型。尽管极端的一样本设置可能导致轻微的、任务特定的过拟合，但该方法在不同任务中始终表现出稳健的泛化能力和效率。此外，研究发现提示设计和损失权重显著影响训练稳定性和最终准确性。

**Conclusion:** 本文的方法实现了领域专家视觉-语言推理模型在成本效益和数据效率方面的开发，为数据稀缺领域提供了一个实用的方案：从紧凑的VLM开始，整理少量可奖励检查的案例，并通过RLVR进行训练。

> **ai_Abstract:** 本文针对遥感等数据稀缺领域中视觉-语言模型应用不切实际的问题，提出了一种名为RLVR（可验证奖励强化学习）的少样本框架。该框架无需依赖昂贵的图像描述标注，而是通过轻量级、基于规则的奖励，结合策略梯度优化，仅使用少量（甚至一个）示例即可显著提升模型在卫星图像推理任务（如分类、VQA、接地）上的性能。实验表明，该方法在数据效率和泛化能力方面表现出色，并为数据稀缺领域提供了一种经济高效的视觉-语言模型开发范式。

> **摘要翻译:** 大型语言模型和视觉-语言模型最近的进展使强大的推理能力成为可能，但对于遥感等专业领域而言，由于标注数据稀缺且昂贵，这些模型仍然不切实际。我们提出了首个用于卫星图像的少样本可验证奖励强化学习（RLVR）框架，该框架消除了对图像描述标注的监督需求——仅依赖轻量级的、基于规则的二元奖励或基于IoU的奖励。通过将语言模型中的“1-shot RLVR”范式应用于视觉-语言模型，我们采用策略梯度优化，仅使用少量（甚至一个）精心策划的示例来对齐模型输出，以执行卫星推理任务。在多个遥感基准测试（包括分类、视觉问答和接地）上的综合实验表明，即使单个示例也能显著优于基础模型。扩展到128个示例时，性能可以达到或超过使用数千个标注样本训练的模型。尽管极端的一样本设置可能导致轻微的、任务特定的过拟合，但我们的方法在不同任务中始终表现出稳健的泛化能力和效率。此外，我们发现提示设计和损失权重显著影响训练稳定性和最终准确性。我们的方法实现了领域专家视觉-语言推理模型在成本效益和数据效率方面的开发，为数据稀缺领域提供了一个实用的方案：从紧凑的VLM开始，整理少量可奖励检查的案例，并通过RLVR进行训练。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [40] [Staining and locking computer vision models without retraining](https://arxiv.org/abs/2507.22000)
> *无需再训练的计算机视觉模型染色与锁定*

*Oliver J. Sutton, Qinghua Zhou, George Leete, Alexander N. Gorban, Ivan Y. Tyukin* | **Category: cs.CV, cs.AI, cs.LG, 68T07, 68T45, 68W40, I.2.10; F.2.0; K.5.1; K.6.5** | **Updated: 2025-07-29**

**Keywords:** 计算机视觉模型, 知识产权, 水印, 模型锁定, 无需再训练

**Comment:** 10 pages, 9 pages of appendices, 10 figures

> **TL;DR:** 提出了无需再训练即可对预训练计算机视觉模型进行水印和锁定的新方法，以保护知识产权。

**AI_Comments:** 该论文的创新之处在于能够在无需再训练的情况下对预训练模型进行染色和锁定，这是一个重要的实际优势。提供了关于误报率的可证明保证也增加了所提方法的鲁棒性和可信度。这种方法为快速发展的计算机视觉模型领域的知识产权保护提供了一个实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 保护计算机视觉模型所有者的知识产权。

**Method:** 该文介绍了染色（水印）和锁定计算机视觉模型的新方法。染色通过在模型中嵌入秘密行为来识别模型，而锁定旨在使模型在未插入秘密触发器的情况下无法使用。与现有方法不同，这些算法无需微调或再训练即可对预训练模型进行染色和锁定。染色和锁定通过直接修改少量模型权重来实现。

**Result:** 这些方法提供了可证明、可计算的保证，限制了其最坏情况下的误报率。染色和锁定对（未锁定）模型的性能影响最小。锁定模型通过在输入图像的角落插入一个小的“触发补丁”来解锁。实验结果表明了这些方法的有效性，并证明了它们在各种计算机视觉模型上的实际性能。

**Conclusion:** 该论文成功引入了通过染色和锁定保护计算机视觉模型知识产权的新颖方法，这些方法高效且有效。

> **ai_Abstract:** 该论文提出了“染色”（水印）和“锁定”计算机视觉模型的新颖方法，旨在保护知识产权。与现有方法不同，这些算法通过直接修改少量模型权重，无需再训练或微调即可应用于预训练模型。这些方法提供了关于误报率的可证明保证，并且对模型性能影响最小。染色在模型中嵌入可识别的秘密行为，而锁定则使得模型在输入中没有特定“触发补丁”的情况下无法使用。实验结果证实了这些方法在各种模型上的有效性和实际性能。

> **摘要翻译:** 我们引入了对计算机视觉模型进行染色和锁定的新方法，以保护其所有者的知识产权。染色，也称为水印，在模型中嵌入秘密行为，该行为随后可用于识别模型；而锁定旨在使模型在未将秘密触发器插入输入图像的情况下无法使用。与现有方法不同，我们的算法可以在无需微调或再训练的情况下对预训练模型进行染色和锁定，并提供可证明、可计算的保证，限制其最坏情况下的误报率。染色和锁定通过直接修改少量模型权重来实现，并且对（未锁定）模型的性能影响最小。锁定模型通过在输入图像的角落插入一个小的“触发补丁”来解锁。我们展示了实验结果，证明了我们方法的有效性，并展示了它们在各种计算机视觉模型上的实际性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [56] [VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning](https://arxiv.org/abs/2507.22607)
> *VL-Cogito：面向高级多模态推理的渐进式课程强化学习*

*Ruifeng Yuan, Chenghao Xiao, Sicong Leng, Jianyu Wang, Long Li, Weiwen Xu, Hou Pong Chan, Deli Zhao, Tingyang Xu, Zhongyu Wei, Hao Zhang, Yu Rong* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 多模态推理, 强化学习, 课程学习, VL-Cogito, PCuRL

**Comment:** 21 pages, 5 figures, 6 tables. Work in progress

> **TL;DR:** VL-Cogito通过渐进式课程强化学习（PCuRL）框架，显著提升了模型在复杂多模态推理任务中的性能，超越了现有模型。

**AI_Comments:** 该论文通过引入渐进式课程强化学习框架PCuRL，有效解决了多模态推理任务中现有模型性能不稳定的问题。其创新点在于在线难度软加权和动态长度奖励机制，这有助于模型在复杂任务中平衡效率与准确性，提升了多模态推理的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 由于多模态任务固有的复杂性和多样性，尤其是在语义内容和问题表述方面，现有模型在各种领域和难度级别上往往表现出不稳定的性能。

**Method:** 本文提出了VL-Cogito模型，通过新颖的多阶段渐进式课程强化学习（PCuRL）框架进行训练。PCuRL系统地引导模型通过难度逐渐增加的任务，并引入了两项关键创新：(1) 在线难度软加权机制，动态调整连续RL训练阶段的训练难度；(2) 动态长度奖励机制，鼓励模型根据任务复杂性自适应地调节其推理路径长度，从而平衡推理效率和正确性。

**Result:** 实验评估表明，VL-Cogito在涵盖数学、科学、逻辑和一般理解的主流多模态基准测试中，始终与现有面向推理的模型持平或超越。

**Conclusion:** VL-Cogito及其渐进式课程强化学习（PCuRL）框架能够有效提升模型在复杂多模态推理任务中的性能和稳定性。

> **ai_Abstract:** VL-Cogito是一个通过渐进式课程强化学习（PCuRL）训练的新型多模态推理模型，旨在解决现有模型在复杂多模态任务中表现不稳定的问题。PCuRL通过逐步增加任务难度来提升模型推理能力，并引入了在线难度软加权和动态长度奖励机制。实验证明VL-Cogito在多模态基准测试中表现优异，超越或匹敌现有模型。

> **摘要翻译:** 强化学习已证明其在增强大型语言模型推理能力方面的有效性。最近的研究工作已逐步将这种范式扩展到多模态推理任务。由于多模态任务固有的复杂性和多样性，尤其是在语义内容和问题表述方面，现有模型在各种领域和难度级别上往往表现出不稳定的性能。为了解决这些限制，我们提出了VL-Cogito，一个通过新颖的多阶段渐进式课程强化学习（PCuRL）框架训练的高级多模态推理模型。PCuRL系统地引导模型通过难度逐渐增加的任务，显著提高了其在不同多模态环境中的推理能力。该框架引入了两项关键创新：(1) 在线难度软加权机制，动态调整连续RL训练阶段的训练难度；(2) 动态长度奖励机制，鼓励模型根据任务复杂性自适应地调节其推理路径长度，从而平衡推理效率和正确性。实验评估表明，VL-Cogito在涵盖数学、科学、逻辑和一般理解的主流多模态基准测试中，始终与现有面向推理的模型持平或超越，验证了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [62] [Motion Diffusion Autoencoders: Enabling Attribute Manipulation in Human Motion Demonstrated on Karate Techniques](https://arxiv.org/abs/2501.18729)
> *运动扩散自编码器：在空手道技术上演示的人体运动属性操纵*

*Anthony Richardson, Felix Putze* | **Category: cs.CV, cs.LG, 68T07 (Primary) 68T30, 92C99 (Secondary), I.2.4; I.2.6** | **Updated: 2025-07-29**

**Keywords:** 运动扩散自编码器, 属性操纵, 人体运动, 姿态表示, Transformer

**Comment:** 9 pages, 7 figures

> **TL;DR:** 本文提出了首个成功操纵人体运动属性的方法，通过设计一种新颖的基于旋转的姿态表示，并结合Transformer编码器和扩散概率模型，实现在语义嵌入空间中对高级属性的线性操纵，并在空手道技术上进行了演示。

**AI_Comments:** 本文的创新点在于首次成功地实现了人体运动数据的属性操纵，这是一个此前未解决的难题。其提出的连续、基于旋转的姿态表示非常新颖，有效解决了骨骼与运动轨迹解耦的问题。此外，将Transformer编码器与扩散概率模型相结合的架构，提供了一种在语义上有意义的线性嵌入空间中进行属性操纵的有效方法，对于运动合成和编辑领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 属性操纵旨在改变数据点或时间序列的单个属性，同时不影响其他方面。这项工作专注于人体运动领域，特别是空手道运动模式。据作者所知，这是首次成功操纵人体运动数据的属性。

**Method:** 核心方法包括：1. 设计一种新颖的连续的、基于旋转的姿态表示，该表示能够解耦人体骨骼和运动轨迹，同时仍能准确重建原始解剖结构。2. 使用Transformer编码器来发现高层次语义，并使用扩散概率模型来建模剩余的随机变化。3. 通过在语义嵌入空间中发现属性变化的线性方向并沿着该方向移动嵌入来操纵高级属性。

**Result:** 研究表明，从Transformer编码器获得的嵌入空间是语义有意义且线性的。这使得通过发现其在语义嵌入空间中的线性变化方向并沿着该方向移动嵌入来操纵高级属性成为可能。

**Conclusion:** 本文成功地展示了对人体运动数据属性的操纵，并证明了所提出的方法能够实现语义有意义的线性属性修改。

> **ai_Abstract:** 本文提出了一种运动扩散自编码器，首次成功实现了人体运动（以空手道技术为例）的属性操纵。该方法设计了一种新颖的连续、基于旋转的姿态表示，以解耦骨骼和运动轨迹。核心操纵策略结合了Transformer编码器来识别高层语义，以及扩散概率模型来处理随机变化。研究结果表明，Transformer编码器生成的嵌入空间具有语义意义和线性特性，从而能够通过在嵌入空间中沿特定方向移动来修改高级运动属性。所有代码和数据均已开源。

> **摘要翻译:** 属性操纵处理的是改变数据点或时间序列的单个属性，同时不影响所有其他方面的问题。这项工作专注于人体运动领域，更精确地说是空手道运动模式。据我们所知，它首次成功操纵了人体运动数据属性。实现人体运动属性操纵的关键要求之一是合适的姿态表示。因此，我们设计了一种新颖的连续的、基于旋转的姿态表示，它能够解耦人体骨骼和运动轨迹，同时仍能准确重建原始解剖结构。操纵方法的核心思想是使用Transformer编码器来发现高层次语义，并使用扩散概率模型来建模剩余的随机变化。我们表明，从Transformer编码器获得的嵌入空间是语义有意义且线性的。这使得通过在语义嵌入空间中发现其线性变化方向并沿着该方向移动嵌入来操纵高级属性成为可能。所有代码和数据都已公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [74] [TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs](https://arxiv.org/abs/2507.21584)
> *TARS：用于减少多模态大语言模型幻觉的最小-最大标记自适应偏好策略*

*Kejia Zhang, Keda Tao, Zhiming Luo, Chang Liu, Jiasheng Tang, Huan Wang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 多模态大语言模型, 幻觉减少, 直接偏好优化, 标记自适应策略, 最小-最大优化

**Comment:** 

> **TL;DR:** TARS 提出了一种标记自适应的最小-最大偏好策略，通过解决现有直接偏好优化（DPO）的过拟合问题，有效减少多模态大语言模型（MLLMs）中的幻觉。

**AI_Comments:** TARS 的创新之处在于将 DPO 框架转化为一个最小-最大优化问题，通过引入标记级分布偏移来模拟对齐不确定性，有效解决了现有 DPO 方法中过拟合和缺乏因果接地的问题。其在仅使用少量样本的情况下就能显著降低幻觉率并匹敌顶尖模型的表现，显示了其在提高 MLLMs 可靠性方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在视觉-语言推理中存在生成事实不正确或视觉上无根据的“幻觉”输出，损害了其可靠性。现有的直接偏好优化（DPO）策略在纠正幻觉时，将偏好视为固定目标，容易过拟合表层语言线索，导致分布刚性和虚假关联，从而削弱了与因果相关视觉信息的接地能力。

**Method:** 本文提出了 TARS，一种标记自适应的偏好策略，将直接偏好优化（DPO）重构为一个最小-最大优化问题。TARS 在语义约束下最大化标记级别的分布偏移以模拟对齐不确定性，同时最小化在这些受控扰动下的预期偏好损失。这种联合目标旨在在缓解对偏好模式的过拟合的同时，保持因果接地。

**Result:** TARS 在多个幻觉基准测试中表现出持续的强大性能。仅使用 4.8k 个偏好样本且无需专家反馈，TARS 将幻觉率从 26.4% 降低到 13.2%，并将认知值从 2.5 降低到 0.4。它优于标准 DPO，并在几个关键指标上与 GPT-4o 匹配。

**Conclusion:** TARS 通过其创新的最小-最大标记自适应偏好策略，有效解决了 MLLMs 中的幻觉问题，并在减少幻觉率和提高模型可靠性方面取得了显著成果，甚至在某些方面达到或超越了顶尖模型。

> **ai_Abstract:** 本文提出了一种名为 TARS 的标记自适应偏好策略，旨在解决多模态大语言模型（MLLMs）中普遍存在的幻觉问题。针对现有直接偏好优化（DPO）方法易过拟合偏好数据表层特征的局限性，TARS 将 DPO 重新构建为最小-最大优化问题。该策略通过在语义约束下最大化标记级分布偏移来模拟对齐不确定性，同时最小化预期偏好损失，从而在减少幻觉的同时保持视觉信息的因果接地。实验结果表明，TARS 在多个幻觉基准测试上表现出色，仅用少量数据便显著降低了幻觉率，并实现了与 GPT-4o 相当的性能。

> **摘要翻译:** 多模态大语言模型（MLLMs）能够进行视觉-语言推理，但通常会生成看似合理但事实不正确或视觉上无根据的输出，从而损害了它们的可靠性。直接偏好优化（DPO）是纠正幻觉的常用策略，通过将模型输出与人类偏好对齐。现有的 DPO 策略通常将与幻觉相关的偏好视为固定目标，在训练期间依赖静态监督信号。这种方法倾向于过度拟合偏好数据中的表面语言线索，导致分布刚性和虚假关联，从而损害了与因果相关视觉信息的接地能力。为了克服这一限制，我们提出了 TARS，一种标记自适应偏好策略，将 DPO 重构为一个最小-最大优化问题。TARS 在语义约束下最大化标记级别的分布偏移以模拟对齐不确定性，并同时最小化在这些受控扰动下的预期偏好损失。这种联合目标在缓解对偏好模式的过拟合的同时，保持因果接地，从而减少多模态推理中的幻觉。我们在多个幻觉基准测试中评估了 TARS，并发现其性能持续强劲。仅使用 4.8k 个偏好样本且无需专家反馈，TARS 将幻觉率从 26.4% 降低到 13.2%，并将认知值从 2.5 降低到 0.4。它优于标准 DPO，并在几个关键指标上与 GPT-4o 匹配。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [75] [Bridging Synthetic and Real-World Domains: A Human-in-the-Loop Weakly-Supervised Framework for Industrial Toxic Emission Segmentation](https://arxiv.org/abs/2507.22002)
> *弥合合成与真实世界领域：一种用于工业有毒排放物分割的人在回路弱监督框架*

*Yida Tao, Yen-Chia Hsu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 工业烟雾分割, 域适应, 弱监督学习, 人在回路, 公民科学

**Comment:** 

> **TL;DR:** CEDANet是一种结合了人工反馈和弱监督域适应的框架，用于工业烟雾分割，解决了真实世界数据标注成本高的问题，并在F1分数和IoU上显著优于基线模型。

**AI_Comments:** 该论文的创新点在于将“人在回路”（human-in-the-loop）的概念与弱监督域适应相结合，特别是利用公民科学提供的低成本、大规模视频级弱标签来解决工业烟雾分割中像素级标注稀缺的问题。这种方法不仅大幅降低了数据标注成本，还显著提升了模型性能，使其在无目标域标注的情况下达到接近全监督的准确率，为实际环境监测应用提供了极具潜力的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 工业烟雾分割对于空气质量监测和环境保护至关重要，但由于真实世界中像素级标注成本高昂且稀缺，常常受到阻碍。

**Method:** 本文引入了CEDANet，一个结合了人工反馈和类别感知域适应的框架。它独特地整合了公民提供的视频级弱标签与对抗性特征对齐。具体而言，它利用公民投票细化源域训练分割模型生成的伪标签，并采用类别特定的域判别器将丰富的源域表示转移到工业域。

**Result:** 在SMOKE5K和自定义IJmond数据集上的综合实验表明，CEDANet在公民反馈下，F1分数为0.414，烟雾类别IoU为0.261，远超基线模型（分别为0.083和0.043）。这表示F1分数提高了五倍，烟雾类别IoU提高了六倍。值得注意的是，使用公民约束伪标签的CEDANet的性能与在有限的100张完全标注图像上训练的相同架构相当，F1分数为0.418，IoU为0.264。

**Conclusion:** 该研究验证了结合公民科学与弱监督域适应的可扩展性和成本效益，为复杂的、数据稀缺的环境监测应用提供了实用解决方案。

> **ai_Abstract:** 本文提出CEDANet，一个用于工业烟雾分割的人在回路弱监督域适应框架。针对像素级标注稀缺问题，CEDANet结合公民提供的视频级弱标签和对抗性特征对齐，通过公民投票精炼伪标签并使用类别特定判别器进行域迁移。实验证明，CEDANet显著优于基线模型，并在无目标域标注的情况下达到与小样本全监督相当的性能，验证了其在数据稀缺环境监测中的实用性和成本效益。

> **摘要翻译:** 工业烟雾分割对于空气质量监测和环境保护至关重要，但往往受到真实世界中像素级标注成本高昂和稀缺的阻碍。我们引入了CEDANet，一个结合了人工反馈的类别感知域适应框架，它独特地整合了公民提供的视频级弱标签与对抗性特征对齐。具体而言，我们使用公民投票细化源域训练的分割模型生成的伪标签，并采用类别特定的域判别器将丰富的源域表示转移到工业领域。在SMOKE5K和自定义IJmond数据集上的综合实验表明，CEDANet在公民反馈下，F1分数为0.414，烟雾类别IoU为0.261，远超基线模型（分别为0.083和0.043）。这表示F1分数提高了五倍，烟雾类别IoU提高了六倍。值得注意的是，使用公民约束伪标签的CEDANet的性能与在有限的100张完全标注图像上训练的相同架构相当，F1分数为0.418，IoU为0.264，这表明它能够在没有目标域标注的情况下达到小样本全监督级别的准确性。我们的研究验证了结合公民科学与弱监督域适应的可扩展性和成本效益，为复杂的、数据稀缺的环境监测应用提供了实用解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [78] [GAITEX: Human motion dataset from impaired gait and rehabilitation exercises of inertial and optical sensor data](https://arxiv.org/abs/2507.21069)
> *GAITEX：基于惯性与光学传感器数据的步态障碍与康复训练人体运动数据集*

*Andreas Spilz, Heiko Oppel, Jochen Werner, Kathrin Stucke-Straub, Felix Capanni, Michael Munz* | **Category: cs.CV, cs.AI, cs.HC** | **Updated: 2025-06-06**

**Keywords:** 人体运动数据集, 惯性测量单元, 动作捕捉, 步态分析, 康复训练

**Comment:** 

> **TL;DR:** GAITEX是一个多模态人体运动数据集，包含19名参与者的步态障碍和康复训练数据，采用同步惯性测量单元（IMU）和光学动作捕捉（MoCap）系统记录，旨在支持机器学习驱动的人体运动分析。

**AI_Comments:** GAITEX数据集的创新之处在于其多模态特性，结合了IMU和MoCap数据，并专注于步态障碍和康复训练这一重要且数据稀缺的领域。数据集不仅提供原始传感器数据，还包括处理后的姿态、生物力学模型和详细注释，极大地降低了研究人员的使用门槛。此外，提供用于后处理和验证的代码，增强了研究的可重复性。该数据集的发布有望显著加速机器学习在临床运动分析和康复领域的应用发展。

<details>
  <summary>Details</summary>

**Motivation:** 开发用于物理治疗练习和步态分析的鲁棒传感器分类模型，需要大量多样化的数据集，而这些数据集的收集成本高昂且耗时。

**Method:** GAITEX数据集包含来自19名参与者的物理治疗练习（包括正确和临床相关变体）以及步态相关练习（包括正常和受损步态模式）的多模态数据。数据通过同步IMU和基于标记的动作捕捉（MoCap）系统记录。数据集包括来自九个IMU和三十五个光学标记的原始数据，用于捕获全身运动学。每个IMU还配备了四个光学标记，以实现IMU姿态估计与MoCap参考值之间的精确比较。此外，还提供处理过的IMU姿态、特定受试者的OpenSim模型、逆运动学结果以及可视化工具，并包含运动执行质量和时间戳分割的详细注释。

**Result:** GAITEX数据集的发布，该数据集是首个结合了惯性传感器和光学传感器数据的步态障碍与康复训练人体运动数据集，支持机器学习模型在自动运动评估、步态分析、时间活动分割和生物力学参数估计等任务中的开发和基准测试。

**Conclusion:** 该资源旨在加速机器学习驱动的人体运动分析领域的研究，并为开发和基准测试机器学习模型提供支持。

> **ai_Abstract:** 本研究介绍了GAITEX，一个用于人体运动分析的多模态数据集。该数据集包含19名参与者的物理治疗和步态相关练习数据，特别涵盖了临床相关的变体、正常及受损步态模式。数据通过同步的惯性测量单元（IMU）和光学动作捕捉（MoCap）系统获取，包括IMU原始数据、光学标记数据、处理后的IMU姿态、OpenSim模型和逆运动学结果，并提供详细的运动质量和时间戳注释。GAITEX旨在解决开发鲁棒传感器分类模型所需大规模数据集的挑战，并支持机器学习模型在自动运动评估、步态分析、时间活动分割和生物力学参数估计等领域的开发与基准测试。

> **摘要翻译:** 可穿戴惯性测量单元（IMU）提供了一种经济高效且可扩展的方式，用于评估临床和日常环境中的人体运动质量。然而，开发用于物理治疗练习和步态分析的鲁棒传感器分类模型，需要大量多样化的数据集，而这些数据集的收集成本高昂且耗时。在此，我们提出了一个多模态物理治疗练习数据集——包括正确和临床相关变体——以及步态相关练习——包括正常和受损步态模式——这些数据是从19名参与者身上使用同步IMU和基于标记的动作捕捉（MoCap）系统记录的。该数据集包括来自九个IMU和三十五个光学标记的原始数据，用于捕获全身运动学。每个IMU还额外配备了四个光学标记，从而可以精确比较IMU导出的姿态估计值与MoCap系统的参考值。为了支持进一步分析，我们还提供了与常见分段坐标系对齐的已处理IMU姿态、特定受试者的OpenSim模型、逆运动学结果以及在肌肉骨骼背景下可视化IMU姿态的工具。运动执行质量和带时间戳的分割的详细注释支持各种分析目标。该数据集支持机器学习模型在自动运动评估、步态分析、时间活动分割和生物力学参数估计等任务中的开发和基准测试。为了促进可重现性，我们提供了用于后处理、传感器到分段对齐、逆运动学计算和技术验证的代码。该资源旨在加速机器学习驱动的人体运动分析领域的研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [81] [LiteFat: Lightweight Spatio-Temporal Graph Learning for Real-Time Driver Fatigue Detection](https://arxiv.org/abs/2507.21756)
> *LiteFat：用于实时驾驶员疲劳检测的轻量级时空图学习*

*Jing Ren, Suyu Ma, Hong Jia, Xiwei Xu, Ivan Lee, Haytham Fayek, Xiaodong Li, Feng Xia* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 驾驶员疲劳检测, 时空图学习, 轻量级模型, 实时检测, 嵌入式设备

**Comment:** 6 pages, 1 figure

> **TL;DR:** LiteFat是一种轻量级的时空图学习模型，用于实时驾驶员疲劳检测，它通过将视频数据转换为时空图并使用轻量级网络来提高效率和降低延迟，同时保持高精度。

**AI_Comments:** LiteFat的创新之处在于其轻量级的时空图学习方法，它通过优化数据处理（转换为STG）和模型结构（使用MobileNet和轻量级GNN），解决了传统深度学习模型在嵌入式设备上部署的计算和延迟瓶颈。这对于实时、资源受限的应用场景（如智能车辆）具有重要意义，能有效提升道路安全。

<details>
  <summary>Details</summary>

**Motivation:** 现有驾驶员疲劳检测方案依赖计算量大的深度学习模型，导致高延迟，不适用于资源有限的嵌入式机器人设备（如智能车辆/汽车），而这些设备需要快速检测以防止事故发生。

**Method:** LiteFat通过面部特征点检测将视频流数据转换为时空图（STG），关注关键运动模式以减少不必要的数据处理。它使用MobileNet提取面部特征并创建STG的特征矩阵。随后，采用轻量级时空图神经网络来识别疲劳迹象，以实现最小处理和低延迟。

**Result:** 在基准数据集上的实验结果表明，与当前最先进的方法相比，LiteFat在性能上具有竞争力，同时显著降低了计算复杂度和延迟。

**Conclusion:** 这项工作有助于开发实时、资源高效的人体疲劳检测系统，这些系统可以部署在嵌入式机器人设备上。

> **ai_Abstract:** 本文介绍了LiteFat，一个轻量级时空图学习模型，用于实时驾驶员疲劳检测。针对现有深度学习模型计算量大、延迟高的问题，LiteFat通过将视频数据转化为时空图，并结合MobileNet提取特征和轻量级时空图神经网络进行疲劳识别，显著降低了计算复杂度和延迟，同时保持了高检测精度。这使得在资源受限的嵌入式设备上部署高效的疲劳检测系统成为可能。

> **摘要翻译:** 检测驾驶员疲劳对于道路安全至关重要，因为疲劳驾驶仍然是交通事故的主要原因。许多现有解决方案依赖于计算量大的深度学习模型，这导致高延迟，不适用于资源有限的嵌入式机器人设备（如智能车辆/汽车），而这些设备需要快速检测以防止事故发生。本文介绍了LiteFat，一种轻量级时空图学习模型，旨在高效检测驾驶员疲劳，同时保持高精度和低计算需求。LiteFat涉及使用面部特征点检测将视频流数据转换为时空图（STG），该方法侧重于关键运动模式并减少不必要的数据处理。LiteFat使用MobileNet提取面部特征并为STG创建特征矩阵。然后，采用轻量级时空图神经网络以最小的处理和低延迟识别疲劳迹象。在基准数据集上的实验结果表明，与当前最先进的方法相比，LiteFat在性能上具有竞争力，同时显著降低了计算复杂度和延迟。这项工作有助于开发实时、资源高效的人体疲劳检测系统，这些系统可以部署在嵌入式机器人设备上。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [86] [Exploring Probabilistic Modeling Beyond Domain Generalization for Semantic Segmentation](https://arxiv.org/abs/2507.21367)
> *探索语义分割中超越域泛化的概率建模*

*I-Hsiang Chen, Hua-En Chang, Wei-Ting Chen, Jenq-Neng Hwang, Sy-Yen Kuo* | **Category: cs.CV** | **Updated: 2025-07-28**

**Keywords:** 域泛化, 语义分割, 概率建模, 扩散模型, 域适应

**Comment:** Accepted by ICCV2025

> **TL;DR:** 本文提出了PDAF，一个概率扩散对齐框架，通过引入潜在域先验（LDP）和扩散建模来解决域泛化语义分割中的域偏移问题，有效提升了模型在未见环境中的泛化能力。

**AI_Comments:** 本文的创新点在于引入了潜在域先验（LDP）并结合概率扩散建模来解决域泛化问题，这为语义分割领域的域适应提供了一个新颖且强大的范式。通过迭代建模域偏移和集成三个专门模块，PDAF能够更精细地处理域间差异，有望在实际应用中取得更好的泛化效果。其无需成对样本的DPE模块也增强了方法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 域泛化语义分割（DGSS）是一个关键但具有挑战性的任务，因为未见环境中的域偏移会严重损害模型性能。现有方法通常忽略内在的潜在域先验，导致次优结果。

**Method:** 本文提出了PDAF（Probabilistic Diffusion Alignment Framework），一个概率扩散对齐框架，通过概率扩散建模增强现有分割网络的泛化能力。PDAF引入潜在域先验（LDP）来捕获域偏移，并将其作为条件因子来对齐源域和未见目标域。它集成到预训练的分割模型中，并利用成对的源图像和伪目标图像来模拟潜在域偏移，从而实现LDP建模。该框架包含三个模块：潜在先验提取器（LPE）通过监督域偏移来预测LDP；域补偿模块（DCM）调整特征表示以减轻域偏移；扩散先验估计器（DPE）利用扩散过程估计LDP，无需成对样本。

**Result:** 广泛的实验验证了PDAF在多样化和具有挑战性的城市场景中的有效性。

**Conclusion:** PDAF通过迭代建模域偏移并逐步优化特征表示，有效提升了复杂目标条件下的泛化能力。

> **ai_Abstract:** 本文提出了一种名为PDAF（Probabilistic Diffusion Alignment Framework）的新型概率扩散对齐框架，旨在解决域泛化语义分割中因域偏移导致的性能下降问题。PDAF通过引入潜在域先验（LDP）来捕获并利用域偏移信息，并将其作为条件因子对齐源域和未见目标域。该框架包含三个关键模块：LPE、DCM和DPE，它们协同工作以迭代地建模和补偿域偏移，从而在复杂目标条件下显著提升模型泛化能力。实验结果验证了PDAF在多样化城市场景中的有效性。

> **摘要翻译:** 域泛化语义分割（DGSS）是一项关键但具有挑战性的任务，因为未见环境中的域偏移会严重损害模型性能。虽然最近的研究通过将特征投影到源域来增强特征对齐，但它们通常忽略内在的潜在域先验，导致次优结果。在本文中，我们引入了PDAF，一个概率扩散对齐框架，通过概率扩散建模增强现有分割网络的泛化能力。PDAF引入了一个潜在域先验（LDP）来捕获域偏移，并使用该先验作为条件因子来对齐源域和未见目标域。为了实现这一点，PDAF集成到一个预训练的分割模型中，并利用成对的源图像和伪目标图像来模拟潜在域偏移，从而实现LDP建模。该框架包括三个模块：潜在先验提取器（LPE）通过监督域偏移来预测LDP；域补偿模块（DCM）调整特征表示以减轻域偏移；扩散先验估计器（DPE）利用扩散过程估计LDP，无需成对样本。这种设计使PDAF能够迭代地建模域偏移，逐步优化特征表示，以增强复杂目标条件下的泛化能力。广泛的实验验证了PDAF在多样化和具有挑战性的城市场景中的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [97] [MedViT V2: Medical Image Classification with KAN-Integrated Transformers and Dilated Neighborhood Attention](https://arxiv.org/abs/2502.13693)
> *MedViT V2：结合KAN集成Transformer和膨胀邻域注意力的医学图像分类*

*Omid Nejati Manzari, Hojat Asgariandehkordi, Taha Koleilat, Yiming Xiao, Hassan Rivaz* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 医学图像分类, Transformer, KAN, 膨胀邻域注意力, MedViTV2

**Comment:** 

> **TL;DR:** MedViTV2是一种新型医学图像分类模型，首次将KAN层集成到Transformer中，并引入DiNA，在多中心和受损医学图像数据集上实现了SOTA性能和更高效率。

**AI_Comments:** 该论文的主要创新在于首次将Kolmogorov-Arnold Network (KAN) 层集成到Transformer架构中用于医学图像分类，这为深度学习模型带来了新的非线性建模能力。同时，引入的膨胀邻域注意力 (DiNA) 有效解决了模型扩展时的特征崩溃问题，并提高了对全局上下文的捕获能力。MedViTV2在处理受损医学图像方面的卓越表现，以及其显著的计算效率提升，都显示了其在真实世界临床应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有医学图像分类方法主要针对干净的标注图像设计，但在真实临床数据中，多中心研究和设备差异常导致图像损坏，这些方法难以应对。

**Method:** 提出了MedViTV2，一种新的架构，首次将Kolmogorov-Arnold Network (KAN) 层集成到Transformer架构中，并开发了高效的KAN块以降低计算负荷并提高精度。此外，引入了增强的膨胀邻域注意力 (DiNA) 来捕获全局上下文并扩展感受野，以有效扩展模型并解决特征崩溃问题。还引入了分层混合策略，有效堆叠局部特征感知和全局特征感知块，以平衡局部和全局特征感知，从而提高性能。

**Result:** 在17个医学图像分类数据集和12个受损医学图像数据集上进行了广泛实验，MedViTV2在29项实验中的27项中取得了最先进的结果，同时降低了计算复杂度。MedViTV2比之前的版本计算效率高44%，并显著提高了精度，在MedMNIST上提高了4.6%，在NonMNIST上提高了5.8%，在MedMNIST-C基准上提高了13.4%。

**Conclusion:** MedViTV2通过集成KAN层和增强的膨胀邻域注意力，显著提升了医学图像分类的性能和计算效率，尤其在处理受损图像方面表现出色，达到了最先进水平，证明了其在广义医学图像分类中的巨大潜力。

> **ai_Abstract:** MedViTV2是一种针对广义医学图像分类的新型Transformer架构，旨在解决真实临床数据中常见的图像损坏问题。它首次将Kolmogorov-Arnold Network (KAN) 层集成到Transformer中，并引入了增强的膨胀邻域注意力 (DiNA) 和分层混合策略。实验证明，MedViTV2在多个医学图像分类和受损图像数据集上取得了最先进的性能，计算效率相比前一版本提高了44%，并在MedMNIST、NonMNIST和MedMNIST-C基准测试中显著提升了精度。

> **摘要翻译:** 卷积网络、Transformer、混合模型和基于Mamba的架构在各种医学图像分类任务中都表现出强大的性能。然而，这些方法主要设计用于使用标记数据对干净图像进行分类。相比之下，真实世界的临床数据通常涉及多中心研究特有的图像损坏，这些损坏源于不同制造商的成像设备差异。在本文中，我们引入了医学视觉Transformer (MedViTV2)，这是一种首次将Kolmogorov-Arnold Network (KAN) 层集成到Transformer架构中的新型架构，旨在实现广义医学图像分类。我们开发了一种高效的KAN块，以降低计算负荷，同时提高原始MedViT的精度。此外，为了克服MedViT在扩展时脆弱的问题，我们提出了一种增强的膨胀邻域注意力 (DiNA)，它是高效融合点积注意力核的适应，能够捕获全局上下文并扩展感受野，从而有效地扩展模型并解决特征崩溃问题。此外，引入了一种分层混合策略，以高效的方式堆叠我们的局部特征感知块和全局特征感知块，从而平衡局部和全局特征感知以提升性能。在17个医学图像分类数据集和12个受损医学图像数据集上进行的广泛实验表明，MedViTV2在29项实验中的27项中取得了最先进的结果，同时降低了计算复杂度。MedViTV2比之前的版本计算效率高44%，并显著提高了精度，在MedMNIST上提高了4.6%，在NonMNIST上提高了5.8%，在MedMNIST-C基准上提高了13.4%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [107] [ZIUM: Zero-Shot Intent-Aware Adversarial Attack on Unlearned Models](https://arxiv.org/abs/2507.21985)
> *ZIUM：针对未学习模型的零样本意图感知对抗性攻击*

*Hyun Jun Yook, Ga San Jhun, Jae Hyun Cho, Min Jeon, Donghyun Kim, Tae Hyung Kim, Youn Kyu Lee* | **Category: cs.CV, cs.CR** | **Updated: 2025-07-29**

**Keywords:** 机器遗忘, 对抗性攻击, 零样本, 意图感知, 未学习模型

**Comment:** Accepted to ICCV2025

> **TL;DR:** ZIUM是一种零样本、意图感知的对抗性攻击，能有效攻击已进行机器遗忘的模型，实现定制内容生成并显著降低攻击时间。

**AI_Comments:** ZIUM的创新之处在于其“意图感知”和“零样本”特性，解决了现有攻击方法中内容定制受限和计算成本高的问题。这对于评估和提高机器遗忘模型的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器遗忘（MU）模型容易被对抗性提示利用，生成包含已移除概念的内容，构成安全风险。然而，现有对抗性攻击方法在生成符合攻击者意图的内容方面仍面临挑战，且识别成功提示的计算成本高昂。

**Method:** 本文提出了ZIUM，一种针对未学习模型的零样本意图感知对抗性攻击。ZIUM能够灵活定制目标攻击图像以反映攻击者的意图，并支持零样本对抗性攻击，无需对先前攻击过的未学习概念进行进一步优化。

**Result:** 在多种机器遗忘场景下的评估表明，ZIUM能根据用户意图提示成功定制内容，攻击成功率优于现有方法。此外，其零样本对抗性攻击显著减少了对先前攻击过的未学习概念的攻击时间。

**Conclusion:** ZIUM有效解决了现有对抗性攻击方法的局限性，实现了对已遗忘模型的意图感知攻击，并显著提高了效率。

> **ai_Abstract:** 本文提出了ZIUM，一种针对已进行机器遗忘模型的零样本意图感知对抗性攻击方法。该方法旨在解决现有攻击方案在内容定制和计算效率方面的不足。ZIUM允许攻击者灵活定制攻击内容以符合其意图，并支持零样本攻击，显著减少了对重复攻击概念的优化需求和攻击时间。实验结果表明，ZIUM在内容定制能力和攻击成功率方面均优于现有方法。

> **摘要翻译:** 机器遗忘（MU）从深度学习模型中移除特定的数据点或概念，以增强隐私并防止生成敏感内容。对抗性提示可以利用未学习的模型生成包含已移除概念的内容，构成重大的安全风险。然而，现有的对抗性攻击方法在生成符合攻击者意图的内容方面仍面临挑战，同时识别成功提示需要高昂的计算成本。为了解决这些挑战，我们提出了ZIUM，一种针对未学习模型的零样本意图感知对抗性攻击，它能够灵活定制目标攻击图像以反映攻击者的意图。此外，ZIUM支持零样本对抗性攻击，无需对先前攻击过的未学习概念进行进一步优化。在各种MU场景下的评估表明，ZIUM在根据用户意图提示成功定制内容方面表现出有效性，并且与现有方法相比，攻击成功率更高。此外，其零样本对抗性攻击显著减少了对先前攻击过的未学习概念的攻击时间。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [114] [From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning](https://arxiv.org/abs/2507.22028)
> *从看到到体验：利用强化学习扩展导航基础模型*

*Honglin He, Yukai Ma, Wayne Wu, Bolei Zhou* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-29**

**Keywords:** 导航基础模型, 强化学习, 机器人学习, 城市导航, S2E框架

**Comment:** 

> **TL;DR:** 本文提出了S2E框架，结合视频预训练和强化学习，以提高导航基础模型在真实世界城市导航中的交互性和安全性，并引入了Anchor-Guided Distribution Matching和Residual-Attention Module以及NavBench-GS评估基准。

**AI_Comments:** 这篇论文通过将强化学习引入导航基础模型的后训练阶段，有效解决了传统离线数据训练模型在真实世界交互和安全性方面的局限性。S2E框架的创新点在于其结合了大规模视频预训练的泛化能力与强化学习在模拟环境中的交互性学习，并通过Anchor-Guided Distribution Matching和Residual-Attention Module确保了学习的稳定性和效率。提出的NavBench-GS评估基准也为未来研究提供了系统评估工具，具有重要的实践意义和创新性。

<details>
  <summary>Details</summary>

**Motivation:** 导航基础模型在离线数据上训练，缺乏对行为后果的推理能力和反事实理解，导致在需要交互和安全行为的真实世界城市导航中存在局限性。

**Method:** 提出了Seeing-to-Experiencing (S2E) 框架，结合视频预训练和强化学习（RL）。S2E通过Anchor-Guided Distribution Matching策略稳定学习并建模多样运动模式，以及Residual-Attention Module在不擦除预训练知识的情况下获得反应性行为。此外，建立了NavBench-GS评估基准。

**Result:** 实验表明S2E缓解了仅通过离线数据扩展时常见的收益递减问题。对强化学习与监督微调在机器人学习后训练中的益处进行了深入分析。

**Conclusion:** 强调了整合交互式在线经验对于有效扩展机器人领域基础模型的关键作用。

> **ai_Abstract:** 本文提出S2E框架，旨在通过结合视频预训练和强化学习来提升导航基础模型在真实世界城市导航中的交互性和安全性。针对离线数据训练模型的局限性，S2E引入了Anchor-Guided Distribution Matching和Residual-Attention Module以稳定学习、建模多样模式并获取反应性行为，同时保留预训练知识。此外，论文建立了NavBench-GS评估基准，用于系统评估模型的泛化性和安全性。实验证明S2E有效缓解了仅依赖离线数据扩展的收益递减问题，并强调了在线交互经验在机器人领域扩展基础模型的重要性。

> **摘要翻译:** 导航基础模型通过大规模网络数据训练，使智能体能够泛化到不同的环境和实体。然而，这些仅在离线数据上训练的模型通常缺乏推理其行为后果或通过反事实理解进行适应的能力。因此，它们在真实世界城市导航中面临显著局限性，而在此类导航中，交互式和安全行为（例如避开障碍物和移动行人）至关重要。为了解决这些挑战，我们引入了“从看到到体验”（Seeing-to-Experiencing, S2E）框架，以通过强化学习扩展导航基础模型的能力。S2E结合了视频预训练和通过强化学习进行后训练的优势。它保持了从大规模真实世界视频中获得的泛化能力，同时通过在模拟环境中的强化学习增强了其交互性。具体来说，我们引入了两项创新：一种锚点引导分布匹配策略，通过基于锚点的监督稳定学习并建模多样化的运动模式；以及一个残差注意力模块，该模块从模拟环境中获取反应性行为，而不会擦除模型的预训练知识。此外，我们建立了一个全面的端到端评估基准NavBench-GS，该基准基于真实世界场景的光真实感3DGS重建，并结合了物理交互。它可以系统地评估导航基础模型的泛化能力和安全性。大量实验表明，S2E缓解了仅通过离线数据扩展时常见的收益递减问题。我们对强化学习与监督微调在机器人学习后训练中的益处进行了深入分析。我们的发现强调了整合交互式在线经验对于有效扩展机器人领域基础模型的关键作用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [117] [See Different, Think Better: Visual Variations Mitigating Hallucinations in LVLMs](https://arxiv.org/abs/2507.22003)
> *见不同，思更佳：视觉变异缓解大型视觉-语言模型中的幻觉*

*Ziyun Dai, Xiaoqiang Li, Shaohua Zhang, Yuanchen Wu, Jide Li* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 幻觉缓解, 大型视觉-语言模型, 视觉变异, 视觉-语义对齐, 细粒度理解

**Comment:** Accepted by ACM MM25

> **TL;DR:** 大型视觉-语言模型（LVLMs）常出现幻觉问题。本文提出了ViHallu框架，通过生成视觉变异图像和构建视觉指令来增强视觉-语义对齐，从而有效缓解幻觉现象。

**AI_Comments:** 本文创新性地提出了一个以视觉为中心的幻觉缓解框架ViHallu，区别于以往文本中心的方法。通过生成可控的视觉变异图像并结合精心构建的视觉指令来微调LVLMs，直接从视觉层面提升了模型的视觉-语义对齐能力和细粒度视觉理解，有效缓解了幻觉问题。同时，发布专用数据集也对该领域的研究提供了有价值的资源。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）在视觉理解和多模态推理方面表现出色，但经常出现幻觉现象，即生成的文本响应与提供的视觉内容不一致。现有缓解幻觉的方法主要以文本为中心，视觉-语义对齐的挑战严重限制了它们的有效性，尤其是在面对细粒度视觉理解场景时。

**Method:** 本文提出了ViHallu，一个以视觉为中心的幻觉缓解框架，通过视觉变异图像生成和视觉指令构建来增强视觉-语义对齐。ViHallu引入了具有可控视觉改变但保持整体图像结构的视觉变异图像。这些图像与精心构建的视觉指令相结合，通过微调使LVLMs更好地理解细粒度视觉内容，从而更精确地捕捉视觉内容和文本之间的对应关系。此外，还发布了ViHallu-Instruction数据集。

**Result:** 在多个基准测试上的大量实验表明，ViHallu有效增强了模型的细粒度视觉理解能力，同时显著降低了幻觉倾向。

**Conclusion:** ViHallu是一个有效的以视觉为中心的框架，通过视觉变异和指令来改善视觉-语义对齐，从而缓解大型视觉-语言模型中的幻觉问题。

> **ai_Abstract:** 大型视觉-语言模型（LVLMs）面临幻觉问题，即生成文本与视觉内容不符，现有方法多以文本为中心且效果有限。本文提出ViHallu框架，通过生成视觉变异图像和构建视觉指令来增强LVLMs的视觉-语义对齐能力。该方法通过微调使模型更好地理解细粒度视觉内容，实验证明其有效提升了模型的细粒度视觉理解并显著减少了幻觉。同时，本文还发布了ViHallu-Instruction数据集。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）在视觉理解和多模态推理方面展现出卓越的能力。然而，LVLMs频繁出现幻觉现象，表现为生成的文本响应与提供的视觉内容不一致。现有的幻觉缓解方法主要以文本为中心，视觉-语义对齐的挑战显著限制了它们的有效性，尤其是在面对细粒度视觉理解场景时。为此，本文提出了ViHallu，一个以视觉为中心的幻觉缓解框架，它通过视觉变异图像生成和视觉指令构建来增强视觉-语义对齐。ViHallu引入了具有可控视觉改变但保持整体图像结构的视觉变异图像。这些图像与精心构建的视觉指令相结合，使LVLMs通过微调更好地理解细粒度视觉内容，从而使模型更精确地捕捉视觉内容和文本之间的对应关系，进而增强视觉-语义对齐。在多个基准测试上的大量实验表明，ViHallu有效增强了模型的细粒度视觉理解能力，同时显著降低了幻觉倾向。此外，我们发布了ViHallu-Instruction，一个专门为缓解幻觉和视觉-语义对齐设计的视觉指令数据集。代码可在https://github.com/oliviadzy/ViHallu获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [123] [MOR-VIT: Efficient Vision Transformer with Mixture-of-Recursions](https://arxiv.org/abs/2507.21761)
> *MoR-ViT：基于递归混合的高效视觉Transformer*

*YiZhou Li* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 视觉Transformer, 高效ViT, 动态递归, 递归混合, 计算效率

**Comment:** 18 pages,9 figuers

> **TL;DR:** MoR-ViT引入了一种新颖的动态递归机制，使每个Transformer令牌能够自适应地确定其处理深度，从而显著减少参数并加速推理，同时保持最先进的准确性。

**AI_Comments:** MoR-ViT的创新之处在于引入了令牌级的动态递归机制，这与以往固定的计算深度或静态压缩方法不同，能够更灵活地分配计算资源。这种方法不仅显著提高了ViT的效率，还保持了高性能，对于ViT在资源受限环境中的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 标准视觉Transformer（ViT）架构存在参数冗余和计算成本高的问题，这限制了它们的实际部署。尽管现有的高效ViT方法（如静态模型压缩或令牌级稀疏化）已有所进展，但它们仍受限于所有令牌固定的计算深度。

**Method:** 本文提出了MoR-ViT，这是一种新颖的视觉Transformer框架，首次引入了受递归混合（MoR）范式启发的令牌级动态递归机制。该方法使每个令牌能够自适应地确定其处理深度，从而实现灵活且依赖于输入的计算资源分配。

**Result:** 在ImageNet-1K和迁移基准测试中，MoR-ViT不仅实现了最先进的准确性，并且参数减少了高达70%，推理速度提升了2.5倍。它在可比条件下也优于领先的高效ViT基线模型，如DynamicViT和TinyViT。

**Conclusion:** 这些结果表明动态递归是实现高效视觉Transformer的有效策略，并为真实世界场景中可扩展和可部署的深度学习模型开辟了新途径。

> **ai_Abstract:** 本文提出了一种名为MoR-ViT的新型视觉Transformer模型，旨在解决传统ViT模型中存在的参数冗余和高计算成本问题。MoR-ViT首次引入了令牌级动态递归机制，允许每个令牌根据输入自适应地调整其处理深度，从而实现计算资源的灵活分配。实验结果表明，MoR-ViT在ImageNet-1K等基准测试中取得了领先的准确性，同时实现了显著的参数减少（高达70%）和推理加速（2.5倍），并超越了现有的高效ViT模型。这证明了动态递归在构建高效、可扩展和可部署的深度学习模型方面的潜力。

> **摘要翻译:** 视觉Transformer（ViT）在图像识别方面取得了显著成功，但标准ViT架构受到大量参数冗余和高计算成本的限制，这阻碍了它们的实际部署。尽管近期在高效ViT方面的工作主要集中于静态模型压缩或令牌级稀疏化，但它们仍然受限于所有令牌固定的计算深度。在这项工作中，我们提出了MoR-ViT，这是一种新颖的视觉Transformer框架，首次引入了受递归混合（MoR）范式启发的令牌级动态递归机制。这种方法使每个令牌能够自适应地确定其处理深度，从而实现灵活且依赖于输入的计算资源分配。在ImageNet-1K和迁移基准测试中进行的大量实验表明，MoR-ViT不仅实现了最先进的准确性，并且参数减少了高达70%，推理速度提升了2.5倍，同时在可比条件下优于领先的高效ViT基线模型，如DynamicViT和TinyViT。这些结果确立了动态递归作为高效视觉Transformer的有效策略，并为真实世界场景中可扩展和可部署的深度学习模型开辟了新途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [127] [Seeing Beyond Frames: Zero-Shot Pedestrian Intention Prediction with Raw Temporal Video and Multimodal Cues](https://arxiv.org/abs/2507.21161)
> *超越帧：基于原始时间视频和多模态线索的零样本行人意图预测*

*Pallavi Zambare, Venkata Nikhil Thanikella, Ying Liu* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-25**

**Keywords:** 行人意图预测, 零样本学习, 时间视频, 多模态, 自动驾驶

**Comment:** Accepted in IEEE 3rd International Conference on Artificial
  Intelligence, Blockchain, and Internet of Things (AIBThings 2025)

> **TL;DR:** 该论文介绍了BF-PIP，一种基于Gemini 2.5 Pro的零样本行人意图预测方法，利用原始时间视频和多模态线索，无需额外训练即可达到73%的预测准确率，并优于GPT-4V基线18%。

**AI_Comments:** 这项研究的创新之处在于提出了一个零样本的行人意图预测方法，避免了传统方法对大量标注数据和再训练的需求。通过利用原始时间视频和多模态线索，并基于Gemini 2.5 Pro，该方法在不进行额外训练的情况下取得了显著的性能提升，特别是超越了GPT-4V基线。这对于自动驾驶系统在动态和未知环境中实现敏捷和高效的感知具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 行人意图预测对于复杂城市环境中的自动驾驶至关重要。传统方法依赖于对帧序列的监督学习，并且需要大量的再训练才能适应新场景。

**Method:** 本文介绍了BF-PIP（超越帧行人意图预测），这是一种基于Gemini 2.5 Pro构建的零样本方法。它直接从短的连续视频片段中推断穿越意图，并辅以结构化的JAAD元数据。与基于GPT-4V的离散帧操作方法不同，BF-PIP处理不间断的时间片段。它还通过专门的多模态提示整合了边界框注释和自车速度。

**Result:** 在没有任何额外训练的情况下，BF-PIP实现了73%的预测准确率，比GPT-4V基线高出18%。

**Conclusion:** 结合时间视频输入与上下文线索可以增强时空感知，并在模糊条件下改善意图推断。这种方法为智能交通系统中敏捷、免再训练的感知模块铺平了道路。

> **ai_Abstract:** 该论文提出了一种名为BF-PIP的零样本行人意图预测方法，该方法基于Gemini 2.5 Pro，旨在解决传统方法在复杂城市环境中对自动驾驶行人意图预测的局限性。BF-PIP直接从短的连续视频片段中推断穿越意图，并结合了JAAD元数据、边界框注释和自车速度等多模态线索。与基于帧的方法不同，BF-PIP处理不间断的时间视频。实验结果表明，BF-PIP在无需额外训练的情况下达到了73%的预测准确率，比GPT-4V基线高出18%，证明了结合时间视频和上下文线索能有效提升意图推断能力，为智能交通系统提供了无需再训练的感知模块。

> **摘要翻译:** 行人意图预测对于复杂城市环境中的自动驾驶至关重要。传统方法依赖于对帧序列的监督学习，并且需要大量的再训练才能适应新场景。本文介绍了BF-PIP（超越帧行人意图预测），这是一种基于Gemini 2.5 Pro构建的零样本方法。它直接从短的连续视频片段中推断穿越意图，并辅以结构化的JAAD元数据。与基于GPT-4V的离散帧操作方法不同，BF-PIP处理不间断的时间片段。它还通过专门的多模态提示整合了边界框注释和自车速度。在没有任何额外训练的情况下，BF-PIP实现了73%的预测准确率，比GPT-4V基线高出18%。这些发现表明，将时间视频输入与上下文线索结合可以增强时空感知，并在模糊条件下改善意图推断。这种方法为智能交通系统中敏捷、免再训练的感知模块铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [128] [Emerging Trends in Pseudo-Label Refinement for Weakly Supervised Semantic Segmentation with Image-Level Supervision](https://arxiv.org/abs/2507.21587)
> *图像级监督下弱监督语义分割中伪标签细化的新兴趋势*

*Zheyuan Zhang, Wang Zhang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 弱监督语义分割, 图像级监督, 伪标签细化, 综述, 新兴趋势

**Comment:** 

> **TL;DR:** 这篇综述关注图像级监督下的弱监督语义分割（WSSS）及其伪标签细化的新兴趋势，旨在填补现有综述的空白，提供全面更新的进展、挑战和未来方向。

**AI_Comments:** 这是一篇重要的综述性论文，它系统地梳理了图像级监督下弱监督语义分割的最新进展和趋势。其价值在于填补了现有综述的空白，为研究人员提供了一个全面的视角，并指明了未来的研究方向，对于推动该领域的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于新方法的快速发展以及现有综述未能捕捉最新趋势的局限性，迫切需要一份更新且全面的综述来综合图像级标签弱监督语义分割的最新进展和最先进技术。

**Method:** 本文对图像级标签弱监督语义分割的最新进展进行了全面综述，根据所涉及的额外监督类型和级别对现有方法进行分类。同时探讨了将先进方法应用于特定领域数据集的挑战，并讨论了现有方法的局限性，提出了未来研究方向。

**Result:** 提供了图像级标签弱监督语义分割最新进展的全面综述，对现有方法进行了分类，并探讨了将先进方法应用于特定领域数据集的挑战。同时评估了现有方法的局限性，并指出了未来研究的几个有前景的方向。

**Conclusion:** 这篇综述旨在帮助已熟悉弱监督语义分割基本概念的研究人员，深化他们对当前进展和方法创新的理解，并概述了未来的研究方向。

> **ai_Abstract:** 本综述旨在为图像级监督下的弱监督语义分割（WSSS）领域提供一份全面且更新的概览。鉴于该领域新方法层出不穷而现有综述存在局限性，本文聚焦主流研究方向，对最新进展进行分类总结，并探讨了将先进方法应用于特定领域数据集的挑战。同时，文章评估了现有方法的局限性，并指出了未来研究的 promising directions。

> **摘要翻译:** 与全监督语义分割不同，弱监督语义分割（WSSS）依赖较弱的监督形式来执行密集预测任务。在各种弱监督类型中，图像级标注的WSSS被认为是最具挑战性也最实用的一种，吸引了大量的研究关注。因此，在这篇综述中，我们专注于图像级标注的WSSS。此外，本综述集中于主流研究方向，刻意省略了影响力较小的分支。鉴于新方法的快速发展以及现有综述在捕捉最新趋势方面的局限性，迫切需要一份更新且全面的综述。我们的目标是通过综合图像级标签WSSS的最新进展和最先进技术来填补这一空白。基本上，我们对图像级标签WSSS的最新进展进行了全面综述，根据所涉及的额外监督类型和级别对现有方法进行分类。我们还探讨了将先进方法应用于特定领域数据集的挑战，这是一个尚未得到充分探索的主题。最后，我们讨论了当前的挑战，评估了现有方法的局限性，并概述了未来研究的几个有前景的方向。本综述旨在为已经熟悉WSSS基本概念并寻求深化对当前进展和方法创新理解的研究人员提供帮助。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [132] [YOLO-PRO: Enhancing Instance-Specific Object Detection with Full-Channel Global Self-Attention](https://arxiv.org/abs/2503.02348)
> *YOLO-PRO：通过全通道全局自注意力增强实例特定目标检测*

*Lin Huang, Yujuan Tan, Weisheng Li, Shitai Shan, Liu Liu, Linlin Shen, Jing Yu, Yue Niu* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 目标检测, YOLO-PRO, 自注意力, 瓶颈结构, 解耦头

**Comment:** 

> **TL;DR:** YOLO-PRO通过引入实例特定瓶颈（ISB）和实例特定非对称解耦头（ISADH）模块，解决了传统目标检测中瓶颈结构和解耦头的局限性，在MS-COCO上实现了最先进的性能。

**AI_Comments:** 本文的主要创新点在于提出了ISB和ISADH两个模块，有效解决了传统目标检测模型在实例辨别力和计算效率上的痛点。ISB通过融合批量和实例特征实现了更精细的注意力机制，而ISADH则优化了特征集成方式。其在MS-COCO上的SOTA表现证明了方法的有效性，并且强调了其在边缘设备部署的潜力，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本论文旨在解决传统目标检测框架中固有的局限性，包括：1. 传统瓶颈结构导致实例辨别力下降，原因是过度强调批量统计信息。2. 解耦头结构存在计算冗余。

**Method:** 本论文提出了两个新颖的模块：1. 实例特定瓶颈（ISB）模块，通过批量统计特征和实例特定特征的协同融合，创新性地重建特征图以建立高效的全通道全局注意力机制。2. 实例特定非对称解耦头（ISADH）模块，开创了一种非对称解耦架构，通过双流批量-实例表示融合实现分层多维特征集成。这两个模块在YOLO-PRO框架中协同部署。

**Result:** 在MS-COCO基准测试上的大量实验表明，YOLO-PRO框架（协调部署ISB和ISADH）在所有计算尺度上都取得了最先进的性能。具体而言，YOLO-PRO在N/S/M/L/X尺度上超越YOLOv8 1.0-1.6% AP，并在关键的N/M/L/X组中优于YOLO11 0.1-0.5% AP，同时保持了有竞争力的计算效率。

**Conclusion:** 本工作通过引入ISB和ISADH模块，有效解决了传统目标检测框架的局限性，显著提升了目标检测的性能，并为开发可在边缘设备上部署的高精度检测器提供了实用见解。

> **ai_Abstract:** 本研究提出YOLO-PRO框架，通过引入实例特定瓶颈（ISB）和实例特定非对称解耦头（ISADH）两个新模块，解决传统目标检测中瓶颈结构和解耦头的局限性。ISB通过特征图重建和特征融合实现全通道全局注意力，ISADH则采用非对称解耦架构进行多维特征集成。实验结果显示，YOLO-PRO在MS-COCO基准上超越YOLOv8和YOLO11，实现了最先进的性能和良好的计算效率，为边缘设备上的高精度检测器开发提供了实践指导。

> **摘要翻译:** 本文通过提出两个新颖的模块：全通道全局自注意力实例特定瓶颈（ISB）和实例特定非对称解耦头（ISADH），解决了目标检测框架中传统瓶颈结构（因过度强调批量统计信息而导致实例辨别力下降）和解耦头（计算冗余）固有的局限性。ISB模块创新性地重建特征图，通过批量统计特征和实例特定特征的协同融合，建立高效的全通道全局注意力机制。作为补充，ISADH模块开创了一种非对称解耦架构，通过双流批量-实例表示融合实现分层多维特征集成。在MS-COCO基准测试上的大量实验表明，ISB和ISADH在YOLO-PRO框架中的协调部署在所有计算尺度上都取得了最先进的性能。具体而言，YOLO-PRO在N/S/M/L/X尺度上超越YOLOv8 1.0-1.6% AP，并在关键的N/M/L/X组中优于YOLO11 0.1-0.5% AP，同时保持了有竞争力的计算效率。这项工作为开发可在边缘设备上部署的高精度检测器提供了实用见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [142] [Top2Pano: Learning to Generate Indoor Panoramas from Top-Down View](https://arxiv.org/abs/2507.21371)
> *Top2Pano：从俯视图生成室内全景图的学习方法*

*Zitong Zhang, Suranjan Gautam, Rui Yu* | **Category: cs.CV** | **Updated: 2025-07-28**

**Keywords:** 室内全景图, 俯视图, 3D重建, 扩散模型, 体素渲染

**Comment:** ICCV 2025. Project page: https://top2pano.github.io/

> **TL;DR:** Top2Pano是一种端到端模型，能从2D俯视图生成逼真的360度室内全景图，通过推断3D结构并结合扩散细化，性能优于现有基线。

**AI_Comments:** 该论文解决了从2D俯视图生成360度室内全景图这一具有实际应用价值的挑战性任务。其创新之处在于提出了一种端到端的方法，巧妙地结合了体素占用率估计、体素渲染和基于ControlNet的扩散细化，有效克服了缺乏明确3D结构和保证几何一致性及照片真实感的难题。模型从示意性平面图泛化生成高质量全景图的能力是其显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 从2D俯视图生成沉浸式360度室内全景图在虚拟现实、室内设计、房地产和机器人等领域有广泛应用。这项任务面临挑战，主要在于缺乏明确的3D结构，以及需要确保几何一致性和照片真实感。

**Method:** 本文提出了Top2Pano，一个端到端模型，用于从俯视图合成逼真的室内全景图。该方法首先估计体素占用率以推断3D结构，然后使用体素渲染生成粗糙的颜色和深度全景图。这些粗糙全景图随后引导一个使用ControlNet的基于扩散的细化阶段，以增强真实感和结构保真度。

**Result:** 在两个数据集上的评估显示，Top2Pano的性能优于现有基线，能有效重建几何形状、遮挡和空间布局。它还具有良好的泛化能力，能够从示意性平面图生成高质量的全景图。

**Conclusion:** Top2Pano的成果突显了其在连接俯视图与沉浸式室内合成方面的潜力。

> **ai_Abstract:** Top2Pano是一种创新的端到端模型，旨在解决从2D俯视图生成逼真360度室内全景图的挑战。该模型通过估计体素占用率来推断3D结构，并利用体素渲染生成初步的全景图，随后通过基于ControlNet的扩散模型进行精细化处理，以提高真实感和结构准确性。实验证明，Top2Pano在几何重建、遮挡处理和空间布局方面表现优异，并能从简易平面图生成高质量全景图，展现了其在沉浸式室内合成领域的巨大潜力。

> **摘要翻译:** 从2D俯视图生成沉浸式360度室内全景图在虚拟现实、室内设计、房地产和机器人等领域具有应用前景。由于缺乏明确的3D结构以及对几何一致性和照片真实感的需求，这项任务极具挑战性。我们提出了Top2Pano，一个用于从俯视图合成逼真室内全景图的端到端模型。我们的方法通过估计体素占用率来推断3D结构，然后使用体素渲染生成粗糙的颜色和深度全景图。这些全景图引导一个使用ControlNet的基于扩散的细化阶段，以增强真实感和结构保真度。在两个数据集上的评估表明，Top2Pano的性能优于基线方法，能有效重建几何形状、遮挡和空间布局。它还具有良好的泛化能力，能够从示意性平面图生成高质量的全景图。我们的结果突显了Top2Pano在连接俯视图与沉浸式室内合成方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [157] [Category-level Meta-learned NeRF Priors for Efficient Object Mapping](https://arxiv.org/abs/2503.01582)
> *类别级元学习NeRF先验用于高效物体映射*

*Saad Ejaz, Hriday Bavle, Laura Ribeiro, Holger Voos, Jose Luis Sanchez-Lopez* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-29**

**Keywords:** NeRF, 3D物体映射, 类别级先验, 元学习, 神经辐射场

**Comment:** 

> **TL;DR:** 本文介绍了PRENOM，一种基于NeRF的方法，利用类别级元学习先验实现高效的3D物体映射，显著提升了重建质量和速度。

**AI_Comments:** 本文通过有效地将NeRF捕捉精细细节的能力与类别级先验的效率相结合，在实时、高质量3D物体映射方面迈出了重要一步。用于生成先验的元学习方法和用于NeRF架构优化的遗传算法是创新的贡献。概率射线采样进一步提高了效率，使其成为实际应用中一个强大的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的类别级形状先验（如DeepSDF）在重建尖锐几何形状时表现不佳且计算成本高昂。尽管NeRF能捕捉精细细节，但尚未有效集成到实时多物体映射框架中与类别级先验结合。本文旨在弥合这一差距，实现高效、高质量的3D物体映射。

**Method:** 本文提出了PRENOM（基于先验的高效神经物体映射器），它将类别级先验与物体级NeRF相结合。PRENOM通过在开源形状数据集生成的合成重建任务上进行元学习来获得物体先验知识。为适应物体类别差异，它采用多目标遗传算法优化每个类别的NeRF架构，以平衡重建质量和训练时间。此外，还引入了基于先验的概率射线采样，将采样引导至预期物体区域，从而加速收敛并提高重建质量。

**Result:** PRENOM实现了高质量的重建并保持了计算可行性。与合成数据集上无先验的NeRF方法相比，Chamfer距离降低了21%。与噪声真实世界数据集上使用形状先验的其他方法相比，在所有重建指标上平均提高了13%，姿态和尺寸估计精度相当，同时训练时间减少了5倍。

**Conclusion:** PRENOM成功地将类别级先验与NeRFs集成，实现了高效且高质量的3D物体映射，有效解决了现有方法的局限性，适用于实时多物体映射。

> **ai_Abstract:** 本文提出了PRENOM，一种新颖的神经物体映射器，它将类别级元学习先验与物体级NeRF相结合，用于高效的3D物体重建和姿态估计。为了解决现有方法（如DeepSDF）的局限性以及NeRF与类别先验集成不足的问题，PRENOM采用了在合成数据上进行元学习、针对每个类别使用多目标遗传算法优化NeRF架构以及基于先验的概率射线采样。实验结果表明，PRENOM在重建质量（例如，比无先验NeRFs降低21%的Chamfer距离，比其他形状先验方法提高13%）和计算效率（训练时间快5倍）方面表现出色，使其适用于实时多物体映射。

> **摘要翻译:** 在3D物体映射中，类别级先验能够实现高效的物体重建和规范姿态估计，每个语义类别（例如，椅子、书籍、笔记本电脑等）仅需要一个先验。DeepSDF主要被用作类别级形状先验，但它在重建尖锐几何形状方面存在困难，并且计算成本高昂。相比之下，NeRF能够捕捉精细细节，但尚未在实时多物体映射框架中与类别级先验有效集成。为了弥合这一差距，我们引入了PRENOM，一个基于先验的高效神经物体映射器，它将类别级先验与物体级NeRF相结合，以提高重建效率并实现规范物体姿态估计。PRENOM通过在开源形状数据集生成的合成重建任务上进行元学习来“认识”物体。为了考虑物体类别变异，它采用多目标遗传算法来优化每个类别的NeRF架构，平衡重建质量和训练时间。此外，基于先验的概率射线采样将采样引导至预期的物体区域，在资源受限的情况下加速收敛并提高重建质量。实验结果突出显示了PRENOM在保持计算可行性的同时实现高质量重建的能力。具体而言，与合成数据集上基于无先验NeRF的方法相比，Chamfer距离降低了21%。此外，与使用形状先验的其他方法在噪声真实世界数据集上的评估表明，在所有重建指标上平均提高了13%，并且姿态和尺寸估计精度相当，同时训练时间减少了5倍。代码可在以下网址获取：https://github.com/snt-arg/PRENOM

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [158] [AU-LLM: Micro-Expression Action Unit Detection via Enhanced LLM-Based Feature Fusion](https://arxiv.org/abs/2507.21778)
> *AU-LLM：基于增强型LLM特征融合的微表情动作单元检测*

*Zhishu Liu, Kaishen Yuan, Bo Zhao, Yong Xu, Zitong Yu* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 微表情, 动作单元, LLM, 特征融合, 情感计算

**Comment:** 

> **TL;DR:** AU-LLM是首个利用大语言模型（LLM）检测微表情动作单元（AU）的框架，通过增强型融合投影器（EFP）弥合视觉-语言语义鸿沟，并在基准数据集上达到了最先进的性能。

**AI_Comments:** 本文的创新点在于首次将大语言模型（LLM）引入到微表情动作单元（AU）检测这一细粒度视觉任务中，有效地利用了LLM的强大推理能力。通过提出增强型融合投影器（EFP）来弥合视觉-语言语义鸿沟，并成功将视觉特征转化为LLM可处理的紧凑表示，解决了微表情数据稀缺和表情强度细微的挑战。这为情感计算领域开辟了新的研究方向，展示了LLM在处理复杂、细微视觉任务上的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 微表情动作单元（AU）的检测在情感计算中是一个艰巨的挑战，对于解码细微、非自愿的人类情感至关重要。尽管大语言模型（LLM）展现出强大的推理能力，但它们在微表情AU检测这种细粒度、低强度领域的应用仍未被探索。

**Method:** 本文提出了AU-LLM框架，首次将大语言模型（LLM）应用于微表情动作单元（AU）检测，以解决数据稀缺和表情细微强度的问题。该框架通过一个名为“增强型融合投影器（EFP）”的关键组件来弥合视觉-语言语义鸿沟。EFP使用多层感知器（MLP）智能融合来自专业3D-CNN骨干网络的中间层（局部纹理）和高层（全局语义）视觉特征，将其转化为一个信息密集的单一令牌，从而使LLM能够对细微的面部肌肉运动进行精细推理。

**Result:** AU-LLM在基准CASME II和SAMM数据集上进行了广泛评估，包括严格的留一受试者（LOSO）和跨域协议。结果表明，AU-LLM取得了新的最先进性能，验证了基于LLM的推理在微表情分析方面的巨大潜力和鲁棒性。

**Conclusion:** 基于LLM的推理在微表情分析方面具有显著的潜力和鲁棒性，AU-LLM的成功应用为此提供了强有力的证据。

> **ai_Abstract:** 本文提出了AU-LLM，一个开创性的框架，首次将大语言模型（LLM）应用于微表情动作单元（AU）检测。针对微表情数据细微强度和稀缺性的挑战，AU-LLM引入了增强型融合投影器（EFP），利用多层感知器（MLP）融合3D-CNN提取的中层和高层视觉特征，生成信息密集的令牌以供LLM进行细致推理。在CASME II和SAMM数据集上的严格评估表明，AU-LLM达到了新的最先进性能，验证了LLM在微表情分析中的巨大潜力和鲁棒性。

> **摘要翻译:** 微表情动作单元（AU）的检测在情感计算中是一个艰巨的挑战，对于解码细微、非自愿的人类情感至关重要。尽管大语言模型（LLM）展现出强大的推理能力，但它们在微表情AU检测这种细粒度、低强度领域的应用仍未被探索。本文率先探索了这一方向，引入了AU-LLM，这是一个新颖的框架，首次利用LLM在微表情数据集（具有细微强度和数据稀缺性）中检测AU。我们特别解决了关键的视觉-语言语义鸿沟问题，即增强型融合投影器（EFP）。EFP采用多层感知器（MLP）智能融合来自专业3D-CNN骨干网络的中间层（局部纹理）和高层（全局语义）视觉特征，将其转化为一个信息密集的单一令牌。这种紧凑的表示有效地使LLM能够对细微的面部肌肉运动进行精细推理。通过在基准CASME II和SAMM数据集上进行广泛评估，包括严格的留一受试者（LOSO）和跨域协议，AU-LLM建立了新的最先进水平，验证了基于LLM的推理在微表情分析方面的巨大潜力和鲁棒性。代码可在https://github.com/ZS-liu-JLU/AU-LLMs获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [159] [VeS: Teaching Pixels to Listen Without Supervision](https://arxiv.org/abs/2507.22008)
> *VeS：教像素无需监督地“倾听”*

*Sajay Raj* | **Category: cs.CV, I.2.10** | **Updated: 2025-07-29**

**Keywords:** 音视频模型, 低资源语言, 多语言, 密集令牌路由, 无监督

**Comment:** 6 pages, 1 figure, 1 table. Code and models are released

> **TL;DR:** 本文研究了在低资源、多语言、嘈杂环境下，密集音视频模型的目标函数能否有效，并发现密集令牌路由在这种环境下比全局池化更关键，即使视觉骨干网络保持冻结也能实现优异的检索和零样本定位。

**AI_Comments:** 这项工作的重要创新在于证明了密集音视频模型，特别是采用密集令牌路由的方法，在低资源、多语言且嘈杂的现实环境中也能表现出色，而无需额外的监督或微调视觉骨干。这挑战了现有模型主要依赖高资源英语语料的假设，为多语言和发展中地区的音视频理解提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前密集的音视频模型在英语中心、富含字幕的网络视频上表现出色，但尚不清楚这些目标函数在低资源、语码转换和嘈杂的多语言环境中是否依然有效，而这些环境正是发展中地区的典型特征。

**Method:** 研究团队在Project Vaani的一个多语言子集上（涵盖数十种印度语言和方言变体）比较了三种对比目标函数：(i) 全局平均池化损失（CLIP风格），(ii) 密集最大-平均令牌匹配器（DenseAV风格），以及 (iii) 一种简单的混合方法。实验中视觉骨干网络保持完全冻结。

**Result:** 密集目标函数相较于全局池化在R@1 (音视频) 上实现了+59%的相对提升，并显著降低了平均/中位数排名。同时，它持续产生清晰的口语物体零样本定位热图，即使视觉骨干网络完全冻结（无LoRA/部分微调）。

**Conclusion:** 研究结果表明，密集令牌路由并非高资源英语语料库的奢侈品；当注释和声学清晰度稀缺时，它更具决定性。

> **ai_Abstract:** 本文探讨了密集音视频模型在低资源、多语言、嘈杂环境下的有效性。通过在Project Vaani的多语言子集上比较三种对比目标函数，研究发现密集令牌路由（DenseAV风格）相较于全局池化（CLIP风格）在音视频检索和零样本定位方面有显著提升（R@1提升59%），即使视觉骨干网络完全冻结。这表明密集令牌路由在注释和声学数据稀缺的环境中更为关键。

> **摘要翻译:** 最近的密集音视频（AV）模型实现了令人印象深刻的检索和新兴定位，但几乎所有证据都来自以英语为中心、字幕丰富的网络视频。目前尚不清楚这些目标在低资源、语码转换和嘈杂的多语言环境中是否有效，而这些环境正是发展中地区的典型特征。我们证明它们是有效的——并且聚合函数的选择变得更加关键。我们使用Project Vaani的一个多语言子集（涵盖数十种印度语言和方言变体）比较了三种对比目标函数：(i) 全局平均池化损失（CLIP风格），(ii) 密集最大-平均令牌匹配器（DenseAV风格），以及 (iii) 一种简单的混合方法（受冻结视觉对齐策略启发）。密集目标函数相较于全局池化在R@1 (音视频) 上实现了+59%的相对提升，并显著降低了平均/中位数排名，同时持续产生清晰的口语物体零样本定位热图——尽管视觉骨干网络保持完全冻结（无LoRA/部分微调）。我们的结果表明，密集令牌路由并非高资源英语语料库的奢侈品；当注释和声学清晰度稀缺时，它更具决定性。我们发布了代码库和训练好的模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [167] [Improving Visual Place Recognition with Sequence-Matching Receptiveness Prediction](https://arxiv.org/abs/2503.06840)
> *利用序列匹配接受度预测改进视觉地点识别*

*Somayeh Hussaini, Tobias Fischer, Michael Milford* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 视觉地点识别, 序列匹配, 接受度预测, 监督学习, 性能提升

**Comment:** 8 pages, 5 figures, Accepted to the IEEE/RSJ International Conference
  on Intelligent Robots and Systems (IROS) 2025

> **TL;DR:** 提出一种监督学习方法，通过预测序列匹配接受度来选择性地信任序列匹配系统，从而显著提升视觉地点识别（VPR）性能。

**AI_Comments:** 该论文的创新点在于提出了一个通用的序列匹配接受度预测器，解决了传统序列匹配方法在VPR中表现不稳定的痛点。其优势在于与底层VPR技术无关，具有很好的普适性，能够显著提升现有系统的鲁棒性和准确性。这项工作对于实际部署VPR系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在视觉地点识别（VPR）中，过滤和基于序列的匹配方法虽然能通过整合时间信息提升性能，但在某些情况下其效果不可预测，甚至可能降低性能。

**Method:** 提出一种新的监督学习方法，用于预测VPR技术每帧的序列匹配接受度（SMR）。该方法使系统能够选择性地决定何时信任序列匹配系统的输出，并且与底层VPR技术无关。同时，还探讨了使用预测器替换被丢弃匹配的互补方法，并进行了消融研究。

**Result:** 该方法有效地预测了SMR，并显著提升了多种最先进和经典VPR技术（如CosPlace, MixVPR, EigenPlaces, SALAD, AP-GeM, NetVLAD和SAD）在三个基准VPR数据集（Nordland, Oxford RobotCar, 和SFU-Mountain）上的性能。

**Conclusion:** 通过预测每帧的序列匹配接受度（SMR），本研究提出的监督学习方法能够有效改善视觉地点识别的性能，使其能够更可靠地利用序列信息。

> **ai_Abstract:** 本文提出一种新的监督学习方法，旨在解决视觉地点识别（VPR）中序列匹配方法性能不稳定的问题。该方法通过预测每帧的序列匹配接受度（SMR），使VPR系统能够智能地判断何时采信序列匹配的输出。实验证明，该方法在多种主流VPR技术和基准数据集上均能显著提升性能，并探讨了其在补充被丢弃匹配方面的应用。

> **摘要翻译:** 在视觉地点识别（VPR）中，过滤和基于序列的匹配方法可以通过整合图像序列中的时间信息来提高性能，特别是在挑战性条件下。尽管这些方法被普遍应用，但它们对系统行为的影响可能是不可预测的，并且在某些情况下实际上会使性能变差。在这项工作中，我们提出了一种新的监督学习方法，该方法学习预测VPR技术的每帧序列匹配接受度（SMR），从而使系统能够选择性地决定何时信任序列匹配系统的输出。我们的方法与底层VPR技术无关，并有效地预测了SMR，从而显著提高了各种最先进和经典VPR技术（即CosPlace、MixVPR、EigenPlaces、SALAD、AP-GeM、NetVLAD和SAD）以及三个基准VPR数据集（Nordland、Oxford RobotCar和SFU-Mountain）上的VPR性能。我们还提供了关于使用预测器替换被丢弃匹配的互补方法的见解，并进行了消融研究，包括对我们的SMR预测器与所选序列长度之间相互作用的分析。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [178] [T2I-Copilot: A Training-Free Multi-Agent Text-to-Image System for Enhanced Prompt Interpretation and Interactive Generation](https://arxiv.org/abs/2507.20536)
> *T2I-Copilot: 一个免训练的多智能体文本到图像系统，用于增强提示词解释和交互式生成*

*Chieh-Yun Chen, Min Shi, Gong Zhang, Humphrey Shi* | **Category: cs.CV, cs.AI, cs.HC** | **Updated: 2025-07-29**

**Keywords:** 文本到图像, 多智能体系统, 提示词工程, 大型语言模型, 生成式AI

**Comment:** ICCV 2025

> **TL;DR:** T2I-Copilot是一个免训练的多智能体系统，利用LLM协作自动化提示词工程和迭代生成，显著提升文本到图像的生成质量和对齐度。

**AI_Comments:** 该论文提出了一种创新的免训练多智能体系统，通过LLM的协作来解决T2I生成中提示词工程的痛点。其优势在于无需额外训练即可提升生成质量和用户体验，并且在性能和成本效益方面表现出色，具有很强的实用价值和潜在影响力。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像（T2I）生成模型对提示词措辞高度敏感，常要求用户反复修改且缺乏明确反馈。现有技术（如自动提示工程、受控文本嵌入、去噪、多轮生成）要么可控性有限，要么需要额外训练，限制了泛化能力。

**Method:** T2I-Copilot是一个免训练的多智能体系统，通过协同利用（多模态）大型语言模型来自动化提示词措辞、模型选择和迭代优化。它包含三个智能体：(1) 输入解释器，解析输入提示词，解决歧义，生成标准化报告；(2) 生成引擎，从不同类型的T2I模型中选择合适的模型，并组织视觉和文本提示词以启动生成；(3) 质量评估器，评估美学质量和文本-图像对齐度，提供分数和反馈以供潜在的再生成。T2I-Copilot可完全自主运行，也支持人工干预。

**Result:** 在GenAI-Bench上，使用开源生成模型，T2I-Copilot的VQA分数与商业模型RecraftV3和Imagen 3相当。它以仅16.59%的成本超越FLUX1.1-pro 6.17%，并分别超越FLUX.1-dev和SD 3.5 Large 9.11%和6.36%。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了T2I-Copilot，一个免训练的多智能体文本到图像系统，旨在解决现有T2I模型对提示词敏感且缺乏用户反馈的问题。该系统利用（多模态）大型语言模型协同自动化提示词工程、模型选择和迭代优化。T2I-Copilot包含输入解释器、生成引擎和质量评估器三个核心智能体，能够显著简化提示词工程，并提升生成质量和文本-图像对齐度。实验证明，T2I-Copilot在GenAI-Bench上表现出色，其VQA分数可与商业模型媲美，并在成本效益上显著优于其他开源模型。

> **摘要翻译:** 文本到图像（T2I）生成模型彻底改变了内容创作，但它们对提示词措辞仍然高度敏感，经常要求用户在没有明确反馈的情况下反复修改提示词。虽然自动提示工程、受控文本嵌入、去噪和多轮生成等技术可以缓解这些问题，但它们提供的可控性有限，或者通常需要额外的训练，从而限制了泛化能力。因此，我们引入了T2I-Copilot，一个免训练的多智能体系统，它利用（多模态）大型语言模型之间的协作来自动化提示词措辞、模型选择和迭代优化。与直接生成相比，这种方法显著简化了提示词工程，同时提高了生成质量和文本-图像对齐度。具体而言，T2I-Copilot由三个智能体组成：(1) 输入解释器，负责解析输入提示词、解决歧义并生成标准化报告；(2) 生成引擎，负责从不同类型的T2I模型中选择合适的模型，并组织视觉和文本提示词以启动生成；(3) 质量评估器，负责评估美学质量和文本-图像对齐度，提供分数和反馈以供潜在的再生成。T2I-Copilot可以完全自主运行，同时也支持人工干预以进行精细控制。在GenAI-Bench上，使用开源生成模型，T2I-Copilot的VQA分数与商业模型RecraftV3和Imagen 3相当，以仅16.59%的成本超越FLUX1.1-pro 6.17%，并分别超越FLUX.1-dev和SD 3.5 Large 9.11%和6.36%。代码将在https://github.com/SHI-Labs/T2I-Copilot发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [183] [ChartM$^3$: Benchmarking Chart Editing with Multimodal Instructions](https://arxiv.org/abs/2507.21167)
> *ChartM$^3$: 多模态指令图表编辑基准测试*

*Donglu Yang, Liang Zhang, Zihao Yue, Liangyu Chen, Yichen Xu, Wenxuan Wang, Qin Jin* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 图表编辑, 多模态指令, 基准测试, 大语言模型, 视觉指示器

**Comment:** 

> **TL;DR:** 现有基于自然语言的图表编辑方法存在歧义。本文提出了一种新颖的多模态图表编辑范式，结合自然语言和视觉指示器。为支持此范式，研究者引入了ChartM$^3$基准测试和ChartM$^3$-Train大型训练集，并发现微调多模态大语言模型（MLLMs）能显著提升图表编辑性能。

**AI_Comments:** 该论文通过引入多模态指令解决了当前图表编辑系统的一个关键限制，提升了细粒度编辑的精度。创建专门的基准测试（ChartM$^3$）和大规模训练数据集（ChartM$^3$-Train）是重要贡献，为该领域的多模态大语言模型（MLLMs）的评估和开发提供了宝贵资源。论文发现MLLMs在解释视觉指示器方面存在不足，并通过多模态监督显著改进了性能，这为未来多模态AI研究提供了重要启示。

<details>
  <summary>Details</summary>

**Motivation:** 图表是数据分析中广泛使用的基本可视化格式。虽然让用户根据高级意图编辑图表具有巨大的实际价值，但现有方法主要依赖自然语言指令，这些指令通常过于模糊，无法支持细粒度编辑。

**Method:** 引入了一种新颖的多模态图表编辑范式，用户意图通过自然语言和视觉指示器（明确突出显示要修改的元素）的组合来表达。提出了ChartM$^3$，一个新的多模态图表编辑基准，具有多级别复杂度和多视角评估，包含1,000个样本，涵盖四个编辑难度级别。每个样本包括（图表、代码、多模态指令）三元组。为全面评估图表编辑模型，ChartM$^3$提供了评估视觉外观和代码正确性的指标。构建了ChartM$^3$-Train，一个包含24,000个多模态图表编辑样本的大规模训练集。在此数据集上对多模态大语言模型（MLLMs）进行微调。

**Result:** ChartM$^3$基准测试揭示了当前多模态大语言模型（MLLMs），包括GPT-4o，在解释和根据视觉指示器行动方面的显著局限性。在ChartM$^3$-Train数据集上对MLLMs进行微调可带来实质性改进。

**Conclusion:** 这项工作证明了多模态监督在构建实用图表编辑系统中的重要性。

> **ai_Abstract:** 图表是数据分析中的核心可视化形式，但现有基于自然语言的编辑方法在细粒度操作上存在歧义。本文提出了一种新的多模态图表编辑范式，通过结合自然语言和视觉指示器来明确用户意图。为支持这一范式，研究者构建了ChartM$^3$基准测试，包含1,000个不同难度级别的多模态编辑样本，并提供了视觉和代码正确性评估指标。基准测试结果显示，当前的多模态大语言模型（MLLMs）在处理视觉指示器方面存在明显不足。为解决此问题，论文进一步构建了ChartM$^3$-Train，一个包含24,000个多模态编辑样本的大规模训练集。实验证明，在此数据集上对MLLMs进行微调能显著提升其性能，强调了多模态监督对于构建实用图表编辑系统的重要性。

> **摘要翻译:** 图表是数据分析中广泛使用的基本可视化格式。虽然让用户根据高级意图编辑图表具有巨大的实际价值，但现有方法主要依赖自然语言指令，这些指令通常过于模糊，无法支持细粒度编辑。在这项工作中，我们引入了一种新颖的多模态图表编辑范式，其中用户意图通过自然语言和视觉指示器（明确突出显示要修改的元素）的组合来表达。为了支持这种范式，我们提出了ChartM$^3$，一个新的多模态图表编辑基准，具有多级别复杂度和多视角评估。ChartM$^3$包含1,000个样本，涵盖四个编辑难度级别。每个样本包括（图表、代码、多模态指令）三元组。为了全面评估图表编辑模型，ChartM$^3$提供了评估视觉外观和代码正确性的指标。我们的基准测试揭示了当前多模态大语言模型（MLLMs），包括GPT-4o，在解释和根据视觉指示器行动方面的显著局限性。为了解决这个问题，我们构建了ChartM$^3$-Train，一个包含24,000个多模态图表编辑样本的大规模训练集。在此数据集上对MLLMs进行微调可带来实质性改进，证明了多模态监督在构建实用图表编辑系统中的重要性。我们的数据集、代码和评估工具可在https://github.com/MLrollIT/ChartM3 和 https://github.com/yaolinli/VCE 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [185] [Locally Controlled Face Aging with Latent Diffusion Models](https://arxiv.org/abs/2507.21600)
> *基于潜在扩散模型的局部可控人脸老化*

*Lais Isabelle Alves dos Santos, Julien Despois, Thibaut Chauffier, Sileye O. Ba, Giovanni Palma* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 人脸老化, 潜在扩散模型, 局部控制, 异质性老化, 图像生成

**Comment:** 

> **TL;DR:** 该研究提出了一种新颖的人脸老化方法，利用潜在扩散模型实现对特定面部区域的局部老化控制，克服了现有方法将老化视为全局同质过程的局限性，从而生成更真实、个性化的老化效果。

**AI_Comments:** 该论文的创新点在于提出了局部控制的人脸老化方法，突破了传统全局老化模型的限制，更符合人脸老化的生物学特性。通过引入潜在扩散模型进行局部区域选择性老化和精炼器进行融合，显著提升了生成结果的真实感和可控性，对于个性化数字内容生成和虚拟形象应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人脸老化方法将老化视为一个全局、同质的过程，忽略了面部区域因内在时间因素和外部因素（如日晒）而异质性老化。这导致现有基于GAN和扩散模型的技术在生成时仅依赖参考图像和目标年龄，缺乏对局部老化的精细控制。

**Method:** 该方法利用潜在扩散模型，通过局部老化迹象选择性地老化特定面部区域，从而实现对生成过程更精细的控制。此外，它还采用一个潜在扩散精炼器来无缝融合这些局部老化的区域，以确保全局一致且自然的外观合成。

**Result:** 实验结果表明，该方法有效实现了人脸老化的三个关键标准：鲁棒的身份保持、高保真度和真实感图像，以及自然、可控的老化进程。

**Conclusion:** 该研究成功开发了一种通过局部控制实现更真实、个性化人脸老化的新方法，克服了现有全局老化方法的限制，并在身份保持、图像质量和老化可控性方面表现出色。

> **ai_Abstract:** 该论文提出了一种基于潜在扩散模型的新型人脸老化方法，旨在解决现有技术将老化视为全局同质过程的不足。通过利用局部老化迹象，该方法能够选择性地对特定面部区域进行老化处理，并使用潜在扩散精炼器进行无缝融合，从而实现更精细的控制和生成更真实、个性化的老化效果。实验证明，该方法在身份保持、图像质量和老化可控性方面均表现优异。

> **摘要翻译:** 我们提出了一种新颖的人脸老化方法，解决了当前将老化视为全局、同质过程的局限性。现有使用GAN和扩散模型的技术通常根据参考图像和目标年龄进行生成，却忽略了面部区域因内在时间因素和外部因素（如日晒）而异质性老化。我们的方法利用潜在扩散模型，通过局部老化迹象选择性地老化特定面部区域。这种方法对生成过程提供了显著更精细的控制，从而实现更真实和个性化的老化。我们采用一个潜在扩散精炼器来无缝融合这些局部老化的区域，确保全局一致且自然的外观合成。实验结果表明，我们的方法有效实现了人脸老化的三个关键标准：鲁棒的身份保持、高保真度和真实感图像，以及自然、可控的老化进程。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [186] [MSGCoOp: Multiple Semantic-Guided Context Optimization for Few-Shot Learning](https://arxiv.org/abs/2507.21786)
> *MSGCoOp：面向少样本学习的多语义引导上下文优化*

*Zhaolong Wang, Tongfeng Sun, Mingzheng Du, Yachao Huang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 少样本学习, 提示学习, 视觉-语言模型, 上下文优化, 语义引导

**Comment:** 

> **TL;DR:** MSGCoOp提出了一种多语义引导上下文优化框架，通过并行可学习上下文向量和LLM生成的语义指导，结合多样性正则化损失，显著提升了少样本学习中的基类到新类泛化能力和跨域泛化鲁棒性，同时保持计算效率。

**AI_Comments:** MSGCoOp的创新之处在于其结合了多语义引导和多样性正则化，以优化提示学习中的上下文向量。特别是利用LLM自动生成语义指导，为提示注入了更丰富的知识，并通过多样性损失确保了提示学习到互补而非冗余的特征，这对于提升少样本泛化能力至关重要。其在保持计算效率的同时取得了显著的性能提升，表明了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言预训练模型（VLMs）在零样本泛化方面表现出色，但提示学习方法在泛化到新类别时常遇到困难，这归因于对已知类别的过拟合和对通用知识的遗忘。此外，当前提升泛化能力的方法往往引入复杂的架构或高昂的计算开销。

**Method:** 本文提出了多语义引导上下文优化（MSGCoOp）框架。该方法利用并行可学习上下文向量的集成来捕捉多样化的语义方面。为丰富这些提示，引入了语义引导机制，通过大型语言模型（LLM）自动生成的全面类别描述来对齐提示。此外，多样性正则化损失鼓励提示学习互补和正交的特征，防止它们坍缩为冗余表示。

**Result:** 在11个基准数据集上的大量实验表明，MSGCoOp显著提高了基类到新类的泛化性能，比强大的KgCoOp基线平均调和平均数提升了1.10%。该方法还在跨域泛化任务中表现出增强的鲁棒性。

**Conclusion:** MSGCoOp通过结合多语义引导和多样性正则化，在保持计算效率的同时，有效解决了少样本学习中VLM的泛化能力问题，尤其是在基类到新类和跨域泛化方面表现优异。

> **ai_Abstract:** 本文提出MSGCoOp框架，旨在解决视觉-语言预训练模型在少样本学习中泛化能力不足的问题。通过利用并行可学习上下文向量的集成，并结合LLM生成的语义指导机制，以及多样性正则化损失，MSGCoOp能够学习多样化、互补的提示表示。实验证明，该方法在11个基准数据集上显著提升了基类到新类的泛化性能和跨域鲁棒性，同时保持了计算效率。

> **摘要翻译:** 视觉-语言预训练模型（VLMs）如CLIP已展现出卓越的零样本泛化能力，而提示学习已成为全量微调的有效替代方案。然而，现有方法在泛化到新类别时常遇到困难，这种现象归因于对已知类别的过拟合和对通用知识的遗忘。此外，近期提高泛化能力的方法往往引入复杂的架构或高昂的计算开销。在本文中，我们提出了一种多语义引导上下文优化（MSGCoOp）框架，旨在增强少样本泛化能力同时保持计算效率。我们的方法利用并行可学习上下文向量的集成来捕捉多样化的语义方面。为了丰富这些提示，我们引入了一种语义引导机制，该机制通过大型语言模型（LLM）自动生成的全面类别描述来对齐提示。此外，多样性正则化损失鼓励提示学习互补和正交的特征，防止它们坍缩为冗余表示。在11个基准数据集上的大量实验表明，MSGCoOp显著提高了基类到新类的泛化性能，比强大的KgCoOp基线平均调和平均数提升了1.10%。我们的方法还在跨域泛化任务中表现出增强的鲁棒性。我们的代码可在以下网址获取：https://github.com/Rain-Bus/MSGCoOp。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [197] [Multimodal LLMs as Customized Reward Models for Text-to-Image Generation](https://arxiv.org/abs/2507.21391)
> *多模态大型语言模型作为文本到图像生成的定制奖励模型*

*Shijie Zhou, Ruiyi Zhang, Huaisheng Zhu, Branislav Kveton, Yufan Zhou, Jiuxiang Gu, Jian Chen, Changyou Chen* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 多模态LLMs, 奖励模型, 文本到图像生成, LLaVA-Reward, SkipCA

**Comment:** Accepted at ICCV 2025. Code available at
  https://github.com/sjz5202/LLaVA-Reward

> **TL;DR:** 本文提出了LLaVA-Reward，一个利用预训练多模态大语言模型（MLLMs）的奖励模型，用于高效自动评估文本到图像（T2I）生成。它通过直接利用MLLM的隐藏状态并引入SkipCA模块来解决现有MLLM方法训练耗时且困难的问题，并在生成与人类对齐的分数方面优于现有方法。

**AI_Comments:** LLaVA-Reward的创新点在于其直接利用MLLM隐藏状态进行奖励建模，并引入SkipCA模块以增强视觉和文本表示之间的双向交互，这有效地解决了现有MLLM评估方法的效率和训练难题。其支持多种偏好数据类型进行灵活微调，并能从多维度进行评估，显示出其在T2I生成评估领域的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于多模态大语言模型（MLLM）的文本到图像（T2I）生成评估方法需要指令遵循数据进行监督微调，并且通过分析文本响应来评估生成质量，这既耗时又难以训练。

**Method:** 本文提出了LLaVA-Reward，它直接利用给定文本-图像对的MLLM的隐藏状态。为了增强解码器专用MLLM中视觉和文本表示之间的双向交互，本文进一步提出了添加跳跃连接交叉注意力（SkipCA）模块，通过连接早期层的视觉特征和后期层的隐藏表示来增强文本-图像相关性推理。此外，LLaVA-Reward支持不同类型的偏好数据进行高效微调，包括配对偏好数据和非配对数据。LLaVA-Reward在四个评估视角上进行训练：文本-图像对齐、保真度/伪影、安全性和总体排名。

**Result:** 实验结果表明，LLaVA-Reward在生成与人类对齐的自动评估分数以及文本到图像生成中的推理时间扩展方面，优于传统的和基于MLLM的方法。

**Conclusion:** LLaVA-Reward通过其新颖的设计和训练方法，有效地解决了现有MLLM评估方法的局限性，并在文本到图像生成评估中实现了卓越的性能，从而提高了评估效率和准确性。

> **ai_Abstract:** 本文介绍了LLaVA-Reward，一个基于预训练多模态大语言模型（MLLMs）的高效奖励模型，用于自动评估文本到图像（T2I）生成。它通过直接利用MLLM的隐藏状态并引入跳跃连接交叉注意力（SkipCA）模块来增强文本-图像交互，解决了现有MLLM评估方法耗时且训练困难的问题。LLaVA-Reward支持配对和非配对偏好数据进行微调，并在文本-图像对齐、保真度、安全性和总体排名等四个评估维度上进行了训练。实验证明，LLaVA-Reward在生成人类对齐的评估分数和推理时间扩展方面优于现有方法。

> **摘要翻译:** 我们引入了LLaVA-Reward，这是一种高效的奖励模型，旨在利用预训练的多模态大型语言模型（MLLMs）从多个角度自动评估文本到图像（T2I）生成。现有的基于MLLM的方法需要指令遵循数据进行监督微调，并通过分析文本响应来评估生成质量，这既耗时又难以训练。为了解决这个问题，我们提出了LLaVA-Reward，它直接利用给定文本-图像对的MLLM的隐藏状态。为了增强解码器专用MLLM中视觉和文本表示之间的双向交互，我们进一步提出了添加跳跃连接交叉注意力（SkipCA）模块。这种设计通过连接早期层的视觉特征和后期层的隐藏表示，增强了文本-图像相关性推理。此外，LLaVA-Reward支持不同类型的偏好数据进行高效微调，包括配对偏好数据和非配对数据。我们在四个评估视角上训练了LLaVA-Reward：文本-图像对齐、保真度/伪影、安全性和总体排名。实证结果表明，LLaVA-Reward在生成与人类对齐的自动评估分数以及文本到图像生成中的推理时间扩展方面，优于传统的和基于MLLM的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [201] [XAI for Point Cloud Data using Perturbations based on Meaningful Segmentation](https://arxiv.org/abs/2507.22020)
> *基于有意义分割扰动的点云数据XAI*

*Raju Ningappa Mulawade, Christoph Garth, Alexander Wiebel* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** XAI, 点云, 分割, 扰动, 显著性图

**Comment:** 18 pages, 14 figures

> **TL;DR:** 本文提出了一种新颖的基于分割的XAI方法，通过点位移机制引入扰动，为点云分类提供人类可解释的显著性图。

**AI_Comments:** 本文的创新之处在于提出了一个新颖的点位移机制，并将其与有意义的分割相结合，以生成人类可解释的显著性图。这解决了现有XAI方法在点云数据解释中可解释性不足的问题。其强调“有意义的分割”是其核心优势，有望提高用户对AI决策的信任和理解。该方法对于自动驾驶、机器人等关键应用领域中点云模型的可解释性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI的指数级增长，理解AI算法在关键领域的决策过程变得至关重要。特别是在点云数据分类中，需要生成易于人类理解的解释，以便更好地分析AI算法并做出适当决策。

**Method:** 本文提出了一种针对点云分类神经网络的基于分割的可解释人工智能（XAI）方法。其核心是一个新颖的点位移机制，用于在点云数据中引入扰动。该方法利用点云分割模型生成解释，将分割后的点云段用于引入扰动并生成显著性图。点位移机制确保被移动的点不再影响分类算法的输出。与传统方法不同，其使用的分割段具有人类易于解释的意义。

**Result:** 本文的方法能够生成比现有方法更具意义的显著性图。通过与使用传统聚类算法生成解释的方法进行比较，并分析示例输入的显著性图，证明了该方法在生成有意义解释方面的有效性。

**Conclusion:** 本文提出的基于有意义分割扰动的XAI方法，通过新颖的点位移机制，能够为点云分类提供人类易于理解的、更具意义的显著性图，从而帮助用户更好地分析和理解AI算法的决策过程。

> **ai_Abstract:** 本文提出了一种新颖的基于分割的可解释人工智能（XAI）方法，专为点云分类任务设计。该方法引入了一种独特的点位移机制来扰动点云数据，并利用点云分割模型生成显著性图。与现有技术相比，其关键创新在于生成的分割段具有人类可解释的语义意义，从而产生更具洞察力的显著性图。研究通过与传统聚类方法的比较以及对示例输入的分析，验证了其在提供有意义解释方面的有效性。

> **摘要翻译:** 我们提出了一种新颖的基于分割的可解释人工智能（XAI）方法，用于处理点云分类的神经网络。作为该方法的一个组成部分，我们提出了一种新颖的点位移机制，用于在点云数据中引入扰动。近年来，人工智能呈指数级增长。因此，当人工智能算法应用于关键领域时，理解其决策过程至关重要。我们的工作重点是解释分类点云数据的人工智能算法。用于解释人工智能算法的方法的一个重要方面是它们能够产生易于人类理解的解释。这使得他们能够更好地分析人工智能算法并根据该分析做出适当的决策。因此，在这项工作中，我们旨在生成可以被人类轻松解释的有意义的解释。我们考虑的点云数据代表3D对象，例如汽车、吉他、笔记本电脑。我们利用点云分割模型来为分类模型的工作原理生成解释。这些分割段用于将扰动引入输入点云数据并生成显著性图。扰动是使用本文提出的新颖点位移机制引入的，该机制确保被移动的点不再影响分类算法的输出。与以前的方法相比，我们的方法使用的分割段是有意义的，即人类可以轻松解释这些分割段的含义。因此，我们的方法优于其他方法的优势在于它能够产生更有意义的显著性图。我们将我们的方法与使用经典聚类算法生成解释的方法进行了比较。我们还分析了使用我们的方法为示例输入生成的显著性图，以证明该方法在生成有意义解释方面的实用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [202] [A Survey on Wi-Fi Sensing Generalizability: Taxonomy, Techniques, Datasets, and Future Research Prospects](https://arxiv.org/abs/2503.08008)
> *Wi-Fi 感知泛化能力综述：分类、技术、数据集及未来研究展望*

*Fei Wang, Tingting Zhang, Wei Xi, Han Ding, Ge Wang, Di Zhang, Yuanhao Cui, Fan Liu, Jinsong Han, Jie Xu, Tony Xiao Han* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** Wi-Fi感知, 泛化能力, 领域适应, 综述, 数据集

**Comment:** Under Review; 30 pages, 322 references

> **TL;DR:** 一篇综述性文章，审查了200多篇关于Wi-Fi感知泛化能力的论文，涵盖分类、技术、数据集和未来方向，旨在为研究人员提供指导。

**AI_Comments:** 这篇综述非常重要，它系统地整理了大量关于Wi-Fi感知泛化能力的研究，这是实际部署中的一个关键挑战。其全面的分类、对技术的详细分析以及数据集的总结为未来的研究提供了有价值的路线图。感知数据集平台（SDP）的推出是促进社区协作的一个显著贡献。

<details>
  <summary>Details</summary>

**Motivation:** Wi-Fi感知在应用于新用户、设备或环境时，由于显著的领域漂移，性能会下降。为了解决这一挑战，研究人员提出了各种泛化技术来增强Wi-Fi感知系统的鲁棒性和适应性。

**Method:** 本综述对2015年以来发表的200多篇论文进行了全面而结构化的回顾，根据Wi-Fi感知流程（实验设置、信号预处理、特征学习和模型部署）进行分类。文章分析了信号预处理、域适应、元学习、度量学习、数据增强、跨模态对齐、联邦学习和持续学习等关键技术。此外，还总结了活动识别、用户识别、室内定位和姿态估计等各种任务的公开数据集，并深入探讨了它们在领域多样性方面的表现。

**Result:** 本综述对2015年以来发表的200多篇论文进行了全面而结构化的回顾，根据Wi-Fi感知流程进行了分类，并分析了信号预处理、域适应等关键泛化技术。文章总结了活动识别、用户识别等各种任务的公开数据集，并讨论了大规模预训练、多模态基础模型集成等新兴趋势和未来方向。此外，还推出了用于共享数据集和模型的感知数据集平台（SDP）。

**Conclusion:** 本综述旨在为致力于提高Wi-Fi感知系统泛化能力的研究人员和从业者提供有价值的参考和实用指南。

> **ai_Abstract:** 本综述旨在解决Wi-Fi感知因领域漂移导致的性能下降问题，通过回顾200多篇关于泛化技术的论文进行探讨。它根据感知流程对现有研究进行分类，分析了域适应和元学习等关键技术，总结了公开数据集，并讨论了大规模预训练等未来趋势。此外，论文还推出了感知数据集平台（SDP）以促进社区协作，旨在为提高Wi-Fi感知泛化能力提供全面的指导。

> **摘要翻译:** Wi-Fi感知作为一种强大的非侵入性技术，已广泛应用于利用商用无线设备识别人类活动、监测生命体征以及实现情境感知应用。然而，由于显著的领域漂移，Wi-Fi感知在应用于新用户、设备或环境时，性能会下降。为了解决这一挑战，研究人员提出了各种泛化技术，旨在增强Wi-Fi感知系统的鲁棒性和适应性。在本综述中，我们对2015年以来发表的200多篇论文进行了全面而结构化的回顾，并根据Wi-Fi感知流程（实验设置、信号预处理、特征学习和模型部署）对其进行分类。我们分析了关键技术，包括信号预处理、域适应、元学习、度量学习、数据增强、跨模态对齐、联邦学习和持续学习。此外，我们总结了活动识别、用户识别、室内定位和姿态估计等各种任务的公开数据集，并深入探讨了它们在领域多样性方面的表现。我们还讨论了新兴趋势和未来方向，包括大规模预训练、与多模态基础模型的集成以及持续部署。为了促进社区协作，我们引入了感知数据集平台（SDP），用于共享数据集和模型。本综述旨在为致力于提高Wi-Fi感知系统泛化能力的研究人员和从业者提供有价值的参考和实用指南。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [219] [RANa: Retrieval-Augmented Navigation](https://arxiv.org/abs/2504.03524)
> *RANa：检索增强导航*

*Gianluca Monaci, Rafael S. Rezende, Romain Deffayet, Gabriela Csurka, Guillaume Bono, Hervé Déjean, Stéphane Clinchant, Christian Wolf* | **Category: cs.CV, cs.IR, cs.RO** | **Updated: 2025-07-29**

**Keywords:** 导航, 检索增强, 强化学习, 零样本迁移, 视觉基础模型

**Comment:** 

> **TL;DR:** RANa提出了一种检索增强型导航代理，通过利用历史数据显著提高性能并实现零样本迁移。

**AI_Comments:** RANa的创新之处在于将检索机制引入到导航任务中，允许代理利用历史经验，这在现实世界应用中具有重要意义。通过结合强化学习和视觉基础模型，该方法不仅提高了导航性能，还实现了零样本迁移，展现了其强大的泛化能力和实用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大规模学习导航方法通常将每个情节视为新问题，代理在未知环境中以干净的内存开始，无法利用早期机器人操作中收集的信息。

**Method:** 引入了一种新的检索增强代理RANa，通过强化学习训练，能够查询在相同环境中从先前情节收集的数据库，并学习如何整合这些额外的上下文信息。该代理架构适用于通用导航任务，并在ImageNav、Instance-ImageNav和ObjectNav上进行评估。检索和上下文编码方法是数据驱动的，并使用视觉基础模型（FM）进行语义和几何理解。

**Result:** 检索允许跨任务和环境进行零样本迁移，同时显著提高了性能。

**Conclusion:** 通过引入检索增强机制，代理能够有效利用历史信息，从而在通用导航任务中实现性能提升和跨任务/环境的零样本迁移，克服了传统方法对未知环境泛化能力的局限性。

> **ai_Abstract:** 本文提出了一种名为RANa的检索增强型导航代理，旨在解决传统大规模学习导航方法未能有效利用历史经验的问题。RANa代理通过强化学习训练，能够查询并整合来自先前导航情节的数据库信息，从而在未知环境中提升性能。该方法利用视觉基础模型进行语义和几何理解，并在ImageNav、Instance-ImageNav和ObjectNav等基准上进行了评估。实验结果表明，RANa显著提高了性能，并实现了跨任务和环境的零样本迁移。

> **摘要翻译:** 基于大规模学习的导航方法通常将每个情节视为一个新问题，代理在未知环境中以干净的内存开始。虽然这些对未知环境的泛化能力极其重要，但我们认为，在现实环境中，代理应该能够利用早期机器人操作期间收集的信息。我们通过引入一个新的检索增强代理来解决这个问题，该代理通过强化学习进行训练，能够查询在相同环境中从先前情节收集的数据库，并学习如何整合这些额外的上下文信息。我们为通用导航任务引入了一种独特的代理架构，并在ImageNav、Instance-ImageNav和ObjectNav上进行了评估。我们的检索和上下文编码方法是数据驱动的，并采用视觉基础模型（FM）进行语义和几何理解。我们为这些设置提出了新的基准，并表明检索允许跨任务和环境进行零样本迁移，同时显著提高了性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [221] [Distribution-Based Masked Medical Vision-Language Model Using Structured Reports](https://arxiv.org/abs/2507.21794)
> *基于分布的掩码医学视觉-语言模型，使用结构化报告*

*Shreyank N Gowda, Ruichi Zhang, Xiao Gu, Ying Weng, Lu Yang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 医学图像-语言模型, 不确定性感知, 结构化报告, 预训练, 胸部X射线

**Comment:** Accepted in MICCAI-W 2025

> **TL;DR:** 本文介绍了一种不确定性感知的医学图像-文本预训练模型，该模型利用LLM生成的结构化报告来增强医学图像数据，以捕获医学数据中固有的可变性和模糊性，并在多项下游任务中取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于引入了不确定性感知机制和利用LLM生成的结构化报告来增强医学图像-文本预训练。这种方法有助于模型更好地理解和处理医学数据中固有的复杂性和模糊性，提高了临床信息的捕获能力和模型的泛化性。将LLM用于生成结构化临床上下文是其重要贡献，有望为医学AI领域带来更可靠、更贴近临床的应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有医学图像-语言预训练模型难以处理医学数据的可变性和模糊性，限制了它们捕获细微临床信息和不确定性的能力，从而影响了在各种下游任务上的性能。

**Method:** 本文提出了一种不确定性感知的医学图像-文本预训练模型。该方法以胸部X射线为例，利用大型语言模型（LLM）生成的结构化文本报告来增强图像数据，提供临床相关上下文。这些报告包含疾病定义、关键区域的“外观”部分以及将模型预测与临床语义相结合的“观察”和“结论”。通过对跨模态和模态内不确定性进行建模，该框架旨在捕获医学图像和文本中固有的模糊性。

**Result:** 该模型在医学图像-文本预训练方面取得了显著进展，并在多项下游任务中获得了最先进的性能，产生了改进的表示和性能。

**Conclusion:** 通过引入不确定性感知的预训练方法，并利用LLM生成的结构化报告，该模型有效解决了医学数据中的可变性和模糊性问题，显著提升了在医学图像分析下游任务上的性能。

> **ai_Abstract:** 本文提出了一种不确定性感知的医学图像-文本预训练模型，旨在解决现有模型在处理医学数据可变性和模糊性方面的不足。该模型利用LLM生成的结构化报告（包含疾病定义、关键区域和临床观察）来增强胸部X射线图像数据，并通过建模跨模态和模态内不确定性，捕获医学图像和文本中固有的模糊性。实验结果表明，该方法在医学图像-文本预训练方面取得了显著进步，并在多个下游任务中达到了最先进的性能。

> **摘要翻译:** 医学图像-语言预训练旨在将医学图像与临床相关文本对齐，以提高模型在各种下游任务上的性能。然而，现有模型常常难以处理医学数据固有的可变性和模糊性，限制了它们捕获细微临床信息和不确定性的能力。这项工作引入了一种不确定性感知的医学图像-文本预训练模型，该模型增强了医学图像分析中的泛化能力。在现有方法的基础上，并专注于胸部X射线，我们的方法利用大型语言模型（LLM）生成的结构化文本报告来增强图像数据，提供临床相关上下文。这些报告首先定义疾病，然后是“外观”部分以突出关键感兴趣区域，最后是“观察”和“结论”将模型预测与临床语义相结合。通过对跨模态和模态内不确定性进行建模，我们的框架捕获了医学图像和文本中固有的模糊性，从而在下游任务中产生了改进的表示和性能。我们的模型在医学图像-文本预训练方面取得了显著进展，并在多项下游任务中获得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [237] [InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity](https://arxiv.org/abs/2503.16418)
> *无限你：在保持身份的同时灵活地重新制作照片*

*Liming Jiang, Qing Yan, Yumin Jia, Zichuan Liu, Hao Kang, Xin Lu* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 身份保留生成, 扩散变换器, InfuseNet, 多阶段训练, 图像生成

**Comment:** ICCV 2025 (Highlight). Project page:
  https://bytedance.github.io/InfiniteYou/ Code and model:
  https://github.com/bytedance/InfiniteYou

> **TL;DR:** InfiniteYou (InfU)是一个利用Diffusion Transformers (DiTs)实现高保真、身份保留图像生成的框架，通过InfuseNet和多阶段训练解决了现有方法的身份相似度不足、文本图像对齐差和生成质量低的问题，达到了SOTA性能。

**AI_Comments:** 该论文的创新点在于提出了InfiniteYou (InfU)框架，首次将DiTs应用于高保真身份保留图像生成任务，并解决了现有方法的关键痛点。InfuseNet通过残差连接巧妙地注入身份特征，而多阶段训练策略则进一步优化了生成质量和文本-图像对齐。其即插即用设计显著增强了实用性和通用性，对相关领域具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法，特别是使用先进的Diffusion Transformers (DiTs)如FLUX时，在实现灵活、高保真的身份保留图像生成方面仍然面临巨大挑战。具体问题包括身份相似度不足、文本-图像对齐性差以及生成质量和美观度低。

**Method:** 论文提出了InfiniteYou (InfU)框架，这是最早利用DiTs进行身份保留图像生成的鲁棒框架之一。其核心是InfuseNet组件，通过残差连接将身份特征注入DiT基础模型，以增强身份相似度并保持生成能力。此外，还采用了多阶段训练策略，包括预训练和使用合成的单人多样本(SPMS)数据进行监督微调(SFT)，以进一步改善文本-图像对齐、提高图像质量并缓解人脸复制粘贴问题。

**Result:** 广泛的实验表明，InfU取得了最先进的性能，超越了现有的基线方法。

**Conclusion:** InfU的即插即用设计确保了与各种现有方法的兼容性，为更广泛的社区做出了宝贵的贡献。

> **ai_Abstract:** 本论文介绍了InfiniteYou (InfU)，一个利用扩散变换器(DiTs)实现高保真、身份保留图像生成的框架。InfU通过其核心组件InfuseNet将身份特征注入DiT模型，并结合多阶段训练策略（包括预训练和使用合成SPMS数据进行SFT），解决了现有方法在身份相似度、文本-图像对齐和生成质量方面的不足。实验证明InfU达到了最先进的性能，并且其即插即用设计增强了与其他方法的兼容性。

> **摘要翻译:** 实现灵活、高保真的身份保留图像生成仍然是一项艰巨的任务，尤其是在使用FLUX等先进的扩散变换器（DiTs）时。我们引入了InfiniteYou（InfU），这是最早利用DiTs完成此任务的稳健框架之一。InfU解决了现有方法的显著问题，例如身份相似度不足、文本-图像对齐性差以及生成质量和美观度低。InfU的核心是InfuseNet，这是一个通过残差连接将身份特征注入DiT基础模型的组件，从而在保持生成能力的同时增强了身份相似度。多阶段训练策略，包括使用合成的单人多样本（SPMS）数据进行预训练和监督微调（SFT），进一步改善了文本-图像对齐，提高了图像质量，并缓解了人脸复制粘贴问题。广泛的实验表明，InfU取得了最先进的性能，超越了现有的基线。此外，InfU的即插即用设计确保了与各种现有方法的兼容性，为更广泛的社区做出了宝贵的贡献。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [239] [On Explaining Visual Captioning with Hybrid Markov Logic Networks](https://arxiv.org/abs/2507.21246)
> *基于混合马尔可夫逻辑网络解释视觉字幕生成*

*Monika Shah, Somdeb Sarkhel, Deepak Venugopal* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 图像字幕生成, 可解释性, 混合马尔可夫逻辑网络, 深度神经网络, 多模态任务

**Comment:** 

> **TL;DR:** 提出一种基于混合马尔可夫逻辑网络（HMLNs）的框架，用于解释深度神经网络在图像字幕生成中的决策过程，通过识别训练数据中影响特定字幕生成的实例。

**AI_Comments:** 该论文提出了一种创新的方法，利用混合马尔可夫逻辑网络（HMLNs）来解决深度学习模型在图像字幕生成中缺乏可解释性的问题。其核心创新在于将符号规则与实值函数结合，并尝试将生成的字幕与训练数据中的具体实例关联起来，从而提供更深层次的解释。这对于提高用户对复杂AI模型决策过程的信任和理解至关重要。该方法通过量化训练示例对输出的影响，为理解模型行为提供了一个新颖的视角，并可能推动可解释AI（XAI）领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络在图像字幕等多模态任务中取得了巨大进展，但解释这些模型如何整合视觉信息、语言信息和知识表示来生成有意义的字幕仍然是一个挑战。标准性能指标无法提供深入的洞察。

**Method:** 开发了一个基于混合马尔可夫逻辑网络（HMLNs）的新颖可解释性框架。HMLNs结合了符号规则和实值函数。该方法假设训练数据中的相关示例影响了观察到的字幕生成。通过学习训练实例上的HMLN分布，并在以生成样本为条件时推断这些实例分布的变化，从而量化哪些示例可能是生成特定字幕的更丰富信息来源。

**Result:** 在Amazon Mechanical Turk上对几种最先进的字幕生成模型进行的实验表明，所提出的解释框架具有可解释性，并允许从可解释性维度比较这些模型。

**Conclusion:** 该框架提供可解释的解释，并允许根据可解释性维度比较不同的字幕生成模型。

> **ai_Abstract:** 本文提出了一种基于混合马尔可夫逻辑网络（HMLNs）的新型框架，旨在解决深度神经网络（DNNs）在图像字幕生成中解释性不足的问题。该框架通过学习训练数据实例上的HMLN分布，并分析在给定生成字幕时的分布变化，以量化训练数据中哪些示例可能对特定字幕的生成产生了影响，从而提供可解释的洞察。实验结果表明，该框架能够提供可解释的解释，并可用于比较不同字幕生成模型的可解释性。

> **摘要翻译:** 深度神经网络（DNNs）在图像字幕等多模态任务中取得了巨大进展。然而，解释/理解这些模型如何整合视觉信息、语言信息和知识表示来生成有意义的字幕仍然是一个挑战。衡量性能的标准指标通常依赖于将生成的字幕与人工编写的字幕进行比较，但这可能无法为用户提供关于这种整合的深入见解。在这项工作中，我们开发了一个基于混合马尔可夫逻辑网络（HMLNs）的新颖解释框架，该框架易于解释——HMLN是一种可以结合符号规则和实值函数的语言——我们假设训练数据中的相关示例如何影响了观察到的字幕的生成。为此，我们学习了训练实例上的HMLN分布，并在以生成的样本为条件时推断这些实例的变化，这使我们能够量化哪些示例可能是生成观察到的字幕的更丰富信息的来源。我们使用Amazon Mechanical Turk对几种最先进的字幕生成模型生成的字幕进行的实验表明了我们解释的可解释性，并允许我们从可解释性维度比较这些模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [241] [Decoupled Spatio-Temporal Consistency Learning for Self-Supervised Tracking](https://arxiv.org/abs/2507.21606)
> *解耦时空一致性学习用于自监督跟踪*

*Yaozong Zheng, Bineng Zhong, Qihua Liang, Ning Li, Shuxiang Song* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 自监督跟踪, 时空一致性, 实例对比学习, 无标注, 视觉跟踪

**Comment:** Accepted by AAAI2025

> **TL;DR:** 该研究提出了一种名为SSTrack的自监督跟踪框架，通过解耦时空一致性学习和实例对比损失，在不依赖边界框标注的情况下，显著超越了现有的自监督跟踪方法。

**AI_Comments:** 这项工作具有重要意义，因为它通过创新的解耦时空一致性学习和实例对比损失，成功地消除了对昂贵边界框标注的需求，为视觉跟踪领域提供了一种高效且可扩展的自监督学习范式。其显著的性能提升也证明了该方法的有效性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉跟踪成功很大程度上依赖于手动边界框标注，但这些标注需要巨大的人力，限制了现有跟踪数据集的规模和多样性。

**Method:** 提出了一种名为SSTrack的自监督跟踪框架，旨在消除对边界框标注的需求。具体来说，提出了一种解耦时空一致性训练框架，通过全局空间定位和局部时间关联来学习跨时间戳的丰富目标信息。此外，设计了一种实例对比损失，从多视角学习实例级对应关系，提供鲁棒的实例监督而无需额外标签。

**Result:** SSTrack在九个基准数据集上进行了广泛实验，结果表明其超越了SOTA自监督跟踪方法，在GOT10K、LaSOT、TrackingNet数据集上的AUC (AO) 分数分别提高了25.3%、20.4%和14.8%。

**Conclusion:** SSTrack这种新的设计范式使其能够以自监督方式有效学习通用跟踪表示，同时减少对大量边界框标注的依赖。

> **ai_Abstract:** 该论文提出了一种名为SSTrack的自监督跟踪框架，旨在解决现有视觉跟踪方法对大量手动边界框标注的依赖问题。SSTrack采用解耦时空一致性训练框架，通过全局空间定位和局部时间关联学习目标信息，并引入实例对比损失以实现无标签的实例级监督。实验结果表明，SSTrack在多个基准数据集上显著优于现有自监督跟踪方法，证明了其在学习通用跟踪表示方面的有效性。

> **摘要翻译:** 视觉跟踪的成功在很大程度上得益于带有手动边界框标注的数据集。然而，这些边界框标注需要巨大的人力，限制了现有跟踪数据集的规模和多样性。在这项工作中，我们提出了一种名为SSTrack的新型自监督跟踪框架，旨在消除对边界框标注的需求。具体来说，我们提出了一种解耦时空一致性训练框架，通过全局空间定位和局部时间关联来学习跨时间戳的丰富目标信息。这允许模拟真实场景中实例的外观和运动变化。此外，我们设计了一种实例对比损失，从多视角学习实例级对应关系，提供鲁棒的实例监督而无需额外标签。这种新的设计范式使SSTrack能够以自监督方式有效学习通用跟踪表示，同时减少对大量边界框标注的依赖。在九个基准数据集上进行的大量实验表明，SSTrack超越了最先进的自监督跟踪方法，在GOT10K、LaSOT、TrackingNet数据集上的AUC (AO) 分数分别提高了25.3%、20.4%和14.8%。代码：https://github.com/GXNU-ZhongLab/SSTrack。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [243] [Shallow Deep Learning Can Still Excel in Fine-Grained Few-Shot Learning](https://arxiv.org/abs/2507.22041)
> *浅层深度学习在细粒度小样本学习中仍能表现出色*

*Chaofei Qi, Chao Ye, Zhitai Liu, Weiyang Lin, Jianbin Qiu* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 细粒度小样本学习, 浅层深度学习, 位置感知特征聚类, 位置编码补偿, ConvNet-4

**Comment:** 

> **TL;DR:** 本文提出了一种名为LCN-4的浅层深度学习网络，通过引入位置感知特征聚类模块和位置编码补偿技术，在细粒度小样本学习任务上取得了与深层网络相当或更优的性能。

**AI_Comments:** 本文的创新点在于重新审视了浅层网络在细粒度小样本学习中的应用潜力，打破了对深层骨干网络的固有依赖。通过引入位置感知特征聚类模块以及两种独特的位置编码补偿技术，LCN-4有效地解决了浅层网络在特征提取过程中容易丢失空间和位置信息的痛点。其重要性在于为资源受限或需要更高效模型的场景提供了新的选择，证明了并非所有任务都必须依赖极深的网络才能取得SOTA性能。这对于推动更轻量级、更高效的深度学习模型发展具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 细粒度小样本学习（FGFSL） heavily relies on deep backbones, but shallower networks like ConvNet-4 are often overlooked due to their tendency to extract non-abstract visual attributes. This paper aims to re-evaluate the potential of shallow deep architectures and investigate if they can achieve comparable or superior performance to mainstream deep backbones.

**Method:** 本文受ConvNet-4启发，提出了一种名为位置感知星座网络（LCN-4）的浅层深度学习架构。LCN-4配备了一个创新的位置感知特征聚类模块，该模块能有效编码和整合空间特征融合、特征聚类和隐性特征定位，从而显著减少总体损失。具体而言，它提出了通用的网格位置编码补偿来解决特定普通卷积在特征提取过程中位置信息丢失的问题，并进一步提出了通用的频域位置嵌入技术来弥补聚类特征中的位置损失。

**Result:** 在三个代表性的细粒度小样本基准测试中，LCN-4显著优于基于ConvNet-4的最新技术，并取得了与大多数基于ResNet12的方法相当或更优的性能。

**Conclusion:** 实验结果证实了作者的猜想，即浅层深度学习在细粒度小样本学习中可以表现出色，甚至可以与主流的深层骨干网络相媲美或超越。

> **ai_Abstract:** 该论文探讨了浅层深度学习网络在细粒度小样本学习（FGFSL）中的潜力，挑战了深层网络在此领域的主导地位。作者提出了一种新的浅层架构——位置感知星座网络（LCN-4），它通过引入位置感知特征聚类模块、通用的网格位置编码补偿和频域位置嵌入技术来解决特征提取和聚类过程中的位置信息丢失问题。实验结果表明，LCN-4在FGFSL基准测试中表现出色，不仅超越了基于ConvNet-4的现有技术，而且达到了与大多数基于ResNet12的深层方法相当或更优的性能，证明了浅层网络在特定任务中仍能取得卓越表现。

> **摘要翻译:** 深度学习已在包括细粒度小样本学习（FGFSL）在内的广泛领域得到广泛应用，而FGFSL严重依赖于深度骨干网络。然而，像ConvNet-4这样的浅层深度骨干网络通常不被青睐，因为它们倾向于提取更多非抽象的视觉属性。在本文中，我们首先重新评估了网络深度与充分编码小样本实例能力之间的关系，并深入探讨了浅层深度架构是否能实现与主流深度骨干网络相当或更优的性能。受香草ConvNet-4的启发，我们引入了一种位置感知星座网络（LCN-4），它配备了一个尖端的位置感知特征聚类模块。该模块能够熟练地编码和整合空间特征融合、特征聚类和隐性特征定位，从而显著最小化总体损失。具体而言，我们创新性地提出了一种通用的网格位置编码补偿，以有效解决特定普通卷积在特征提取过程中位置信息丢失的问题。此外，我们还进一步提出了一种通用的频域位置嵌入技术，以弥补聚类特征中的位置损失。我们已在三个代表性的细粒度小样本基准测试上进行了验证程序。相关实验已经证实，LCN-4显著优于基于ConvNet-4的最新技术，并取得了与大多数基于ResNet12的方法相当或更优的性能，证实了我们猜想的正确性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [257] [ReGATE: Learning Faster and Better with Fewer Tokens in MLLMs](https://arxiv.org/abs/2507.21420)
> *ReGATE：在多模态大语言模型中以更少Token实现更快更好的学习*

*Chaoyu Li, Yogesh Kulkarni, Pooyan Fazli* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-29**

**Keywords:** 多模态大语言模型, Token剪枝, 训练加速, 教师-学生框架, 计算效率

**Comment:** 

> **TL;DR:** ReGATE是一种自适应Token剪枝方法，通过教师-学生框架显著加速多模态大语言模型（MLLM）的训练，同时保持或超越性能。

**AI_Comments:** ReGATE的创新之处在于其将自适应Token剪枝应用于MLLM的训练阶段，而非仅仅推理阶段，并通过独特的教师-学生框架实现了这一目标。这种方法有效解决了MLLM训练成本高昂的问题，对于推动大模型训练效率具有重要意义。其在减少Token使用量和加速训练方面展现出显著效果，为未来大模型的高效训练提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLM）的训练计算成本随Token数量迅速增加。现有效率方法主要针对推理，依赖于Token减少或合并，在训练阶段效益有限。

**Method:** 本文提出了ReGATE（Reference-Guided Adaptive Token Elision），一种用于加速MLLM训练的自适应Token剪枝方法。ReGATE采用教师-学生框架，其中被训练的MLLM作为学生，一个冻结的参考大语言模型（LLM）作为教师。教师计算每个Token的参考损失，并将其与学生自身难度分数的指数移动平均（EMA）相结合。这种基于自适应难度评分的方法能够选择性地处理关键Token，同时在前向传播中跳过信息量较少的Token，从而显著降低计算开销。

**Result:** ReGATE应用于VideoLLaMA2时，在MVBench上以高达2倍的速度匹配了标准训练的峰值精度，仅使用了35%的Token。通过额外训练，它甚至在多个多模态基准测试中超越了基线，同时总Token数量减少了41%以上。

**Conclusion:** ReGATE通过自适应Token剪枝，显著加速了多模态大语言模型（MLLM）的训练，同时在保持或超越性能的同时，大幅减少了Token使用量。

> **ai_Abstract:** 本文提出ReGATE，一种基于教师-学生框架的自适应Token剪枝方法，旨在加速多模态大语言模型（MLLM）的训练。该方法通过结合教师模型计算的Token参考损失和学生模型的难度分数，实现对关键Token的选择性处理，从而显著降低计算成本。实验证明，ReGATE在保持或超越基线性能的同时，能大幅减少训练所需的Token数量和训练时间。

> **摘要翻译:** 多模态大语言模型（MLLM）的训练计算成本随着涉及的Token数量迅速增加。现有的效率方法主要针对推理，并依赖于Token的减少或合并，在训练过程中效益有限。在本文中，我们提出了ReGATE（Reference-Guided Adaptive Token Elision），一种用于加速MLLM训练的自适应Token剪枝方法。具体来说，ReGATE采用了一个教师-学生框架，其中正在训练的MLLM作为学生，一个冻结的参考大语言模型（LLM）作为教师。教师计算每个Token的参考损失，并将其与学生自身难度分数的指数移动平均（EMA）相结合。这种基于自适应难度的评分使得在正向传播中能够选择性地处理关键Token，同时跳过信息量较少的Token，从而显著降低计算开销。实验表明，当ReGATE应用于VideoLLaMA2时，在MVBench上以高达2倍的速度匹配了标准训练的峰值精度，仅使用了35%的Token。通过额外的训练，它甚至在多个多模态基准测试中超越了基线，同时将总Token数量减少了41%以上。代码和模型将很快发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [258] [HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels](https://arxiv.org/abs/2507.21809)
> *混元世界1.0：从文字或像素生成沉浸式、可探索、交互式3D世界*

*HunyuanWorld Team, Zhenwei Wang, Yuhao Liu, Junta Wu, Zixiao Gu, Haoyuan Wang, Xuhui Zuo, Tianyu Huang, Wenhuan Li, Sheng Zhang, Yihang Lian, Yulin Tsai, Lifu Wang, Sicong Liu, Puhua Jiang, Xianghui Yang, Dongyuan Guo, Yixuan Tang, Xinyue Mao, Jiaao Yu, Junlin Yu, Jihong Zhang, Meng Chen, Liang Dong, Yiwen Jia, Chao Zhang, Yonghao Tan, Hao Zhang, Zheng Ye, Peng He, Runzhou Wu, Minghui Chen, Zhan Li, Wangchen Qin, Lei Wang, Yifu Sun, Lin Niu, Xiang Yuan, Xiaofeng Yang, Yingping He, Jie Xiao, Yangyu Tao, Jianchen Zhu, Jinbao Xue, Kai Liu, Chongqing Zhao, Xinming Wu, Tian Liu, Peng Chen, Di Wang, Yuhong Liu, Linus, Jie Jiang, Tengfei Wang, Chunchao Guo* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 3D世界生成, 沉浸式, 交互式, 全景, 网格

**Comment:** Technical Report; Project Page:
  https://3d-models.hunyuan.tencent.com/world/

> **TL;DR:** HunyuanWorld 1.0是一个新颖的框架，能够从文本或图像条件生成沉浸式、可探索和交互式的3D世界，结合了现有方法的优点并解决了其局限性。

**AI_Comments:** HunyuanWorld 1.0的创新之处在于其结合了视频和3D生成方法的优点，并通过引入全景世界代理和语义分层3D网格表示，有效地解决了3D世界生成中的一致性、效率和交互性问题。这为虚拟现实、游戏开发和内容创作等领域提供了强大的工具，具有重要的实际应用价值和研究意义。

<details>
  <summary>Details</summary>

**Motivation:** 从文本或图像创建沉浸式、可玩性的3D世界是计算机视觉和图形学中的一个基本挑战。现有方法（基于视频或基于3D）存在3D一致性差、渲染效率低、训练数据有限和内存效率低等问题。

**Method:** 本研究提出了HunyuanWorld 1.0框架，它结合了现有方法的优点，通过以下特点实现3D世界生成：1) 利用全景世界代理提供360度沉浸式体验；2) 支持网格导出，兼容现有计算机图形管道；3) 采用解耦对象表示以增强交互性。其核心是语义分层的3D网格表示，利用全景图像作为360度世界代理进行语义感知的世界分解和重建。

**Result:** 实验证明，该方法在生成连贯、可探索和交互式3D世界方面达到了最先进的性能，并支持虚拟现实、物理模拟、游戏开发和交互式内容创建等多功能应用。

**Conclusion:** HunyuanWorld 1.0成功解决了从文本或图像生成高质量、可交互3D世界的挑战，通过其创新的框架和表示方式，在多个应用领域展现了巨大潜力。

> **ai_Abstract:** HunyuanWorld 1.0是一个创新的框架，旨在解决从文本或图像生成沉浸式、可探索和交互式3D世界的挑战。它克服了现有视频基和3D基方法的局限性，通过引入全景世界代理实现360度沉浸感、支持网格导出兼容现有管道以及利用解耦对象表示增强交互性。其核心是一个语义分层的3D网格表示，利用全景图像进行世界分解和重建。实验证明，该方法在生成高质量3D世界方面达到了最先进的性能，并适用于VR、游戏开发等多种应用。

> **摘要翻译:** 从文本或图像创建沉浸式、可玩性的3D世界仍然是计算机视觉和图形学中的一个基本挑战。现有的世界生成方法通常分为两类：基于视频的方法提供了丰富的多样性，但缺乏3D一致性和渲染效率；基于3D的方法提供了几何一致性，但在训练数据有限和内存效率低的表示方面存在困难。为了解决这些限制，我们提出了HunyuanWorld 1.0，这是一个新颖的框架，结合了两类方法的优点，能够从文本和图像条件生成沉浸式、可探索和交互式的3D场景。我们的方法具有三个关键优势：1) 通过全景世界代理提供360度沉浸式体验；2) 具备网格导出能力，与现有计算机图形管道无缝兼容；3) 采用解耦对象表示以增强交互性。我们框架的核心是语义分层的3D网格表示，它利用全景图像作为360度世界代理进行语义感知的世界分解和重建，从而能够生成多样化的3D世界。大量的实验表明，我们的方法在生成连贯、可探索和交互式3D世界方面达到了最先进的性能，同时在虚拟现实、物理模拟、游戏开发和交互式内容创建方面实现了多功能应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [265] [Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models](https://arxiv.org/abs/2506.01413)
> *激励推理以实现大型语言模型的高级指令遵循*

*Yulei Qin, Gang Li, Zongyi Li, Zihan Xu, Yuchen Shi, Zhekai Lin, Xiao Cui, Ke Li, Xing Sun* | **Category: cs.CV, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 指令遵循, 复杂指令, 强化学习, 思维链, 大型语言模型

**Comment:** 15 pages of main body, 5 tables, 5 figures, 42 pages of appendix

> **TL;DR:** 本文提出了RAIF，一种通过激励推理来提升大型语言模型遵循复杂指令能力的方法，解决了传统思维链的局限性，并在多个基准测试中取得了显著效果。

**AI_Comments:** 本文的创新点在于提出RAIF，通过强化学习和行为克隆机制，有效解决了传统CoT在处理复杂指令时推理深度不足的问题。其通过可验证的规则中心奖励信号来培养推理能力，并利用样本对比来加强CoT，这些都是提升LLM指令遵循能力的关键。实验结果显示，即使是较小的模型也能通过RAIF达到大型模型的性能，这表明该方法在模型效率和性能提升方面具有重要意义和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLMs）在遵循复杂指令方面面临挑战，尤其是在存在并行、链式和分支结构的多重约束时。尽管思维链（CoT）被期望能普遍提升LLMs的能力，但研究发现，普通的CoT因其肤浅的推理模式（仅仅复述指令）而产生负面影响，未能识别约束之间的层级和维度关系。

**Method:** 本文提出了RAIF方法。首先，基于现有分类法分解复杂指令，并提出了一种可复现的数据获取方法。其次，利用带有可验证的以规则为中心的奖励信号的强化学习（RL）来培养专门用于指令遵循的推理能力。通过样本对比来解决复杂指令下推理的浅层非本质性问题，以加强CoT。此外，还利用专家行为克隆来促进从快速思考的LLM到熟练推理器的稳定分布转移。

**Result:** 在七个综合基准测试上的广泛评估证实了所提出方法的有效性。一个1.5B的LLM实现了11.74%的性能提升，性能与一个8B的LLM相当。对OOD（分布外）约束的评估也证实了RAIF的泛化能力。

**Conclusion:** RAIF通过激励推理，显著提升了大型语言模型遵循复杂指令的能力，解决了传统CoT的不足，并展现了出色的性能提升和泛化能力。

> **ai_Abstract:** 本文提出了一种名为RAIF（Reasoning for Advanced Instruction-Following）的新方法，旨在解决大型语言模型在遵循复杂指令时面临的挑战，特别是传统思维链（CoT）因肤浅推理而导致的性能下降问题。RAIF通过分解复杂指令、采用基于可验证规则奖励的强化学习以及行为克隆，来激励LLMs进行更深层次的推理。实验结果表明，RAIF显著提升了LLMs在复杂指令遵循任务上的表现，甚至使小型模型达到大型模型的性能水平，并展现了良好的泛化能力。

> **摘要翻译:** 现有大型语言模型（LLMs）在遵循复杂指令方面面临挑战，尤其是在存在并行、链式和分支结构的多重约束时。一种直观的解决方案，即思维链（CoT），被期望能普遍提升LLMs的能力。然而，我们发现普通的CoT因其肤浅的推理模式（仅仅复述指令）而对性能产生负面影响。它未能剥离约束的组成部分，以识别它们在类型和维度层级之间的关系。为此，我们提出了RAIF，这是一种系统方法，通过激励推理以进行测试时计算扩展来提升LLMs处理复杂指令的能力。首先，我们基于现有分类法对复杂指令进行分解，并提出了一种可复现的数据获取方法。其次，我们利用带有可验证的以规则为中心的奖励信号的强化学习（RL）来培养专门用于指令遵循的推理能力。我们通过样本对比来解决复杂指令下推理的浅层非本质性问题，以加强CoT。我们还利用专家行为克隆来促进从快速思考的LLM到熟练推理器的稳定分布转移。在七个综合基准测试上的广泛评估证实了所提出方法的有效性，其中一个1.5B的LLM实现了11.74%的性能提升，性能与一个8B的LLM相当。对OOD约束的评估也证实了我们RAIF的泛化能力。代码和数据可在https://github.com/yuleiqin/RAIF获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [272] [LookCloser: Frequency-aware Radiance Field for Tiny-Detail Scene](https://arxiv.org/abs/2503.18513)
> *仔细看：用于微小细节场景的频率感知辐射场*

*Xiaoyu Zhang, Weihong Pan, Chong Bao, Xiyu Zhang, Xiaojun Xiang, Hanqing Jiang, Hujun Bao* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 频率感知, 辐射场, NeRF, 视图合成, 细节渲染

**Comment:** Accepted to CVPR 2025. Project page:
  https://coscatter.github.io/LookCloser

> **TL;DR:** 提出FA-NeRF，一个频率感知框架，能在一个NeRF模型中同时捕捉场景整体结构和高精细节，解决了现有NeRF难以平衡高低频信息的问题。

**AI_Comments:** 该论文的创新点在于提出了“频率感知”的概念并将其引入NeRF框架，通过3D频率量化、频率网格和特征重加权等机制，有效解决了现有NeRF在同时捕捉场景宏观结构和微观细节方面的局限性。这对于提升沉浸式场景渲染的真实感和细节表现力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有NeRF框架难以同时建模场景的整体结构（低频信息）和对象的精细细节（高频信息），无法平衡两者。

**Method:** 提出FA-NeRF，一个频率感知视图合成框架。核心方法包括：1) 3D频率量化方法分析场景频率分布，实现频率感知渲染；2) 引入频率网格以加速收敛和查询；3) 采用频率感知特征重加权策略平衡不同频率内容的特征。

**Result:** 实验表明，该方法在建模整个场景同时保留精细细节方面，显著优于现有方法。

**Conclusion:** FA-NeRF成功地在一个统一的NeRF模型中解决了现有方法在平衡场景整体结构和精细细节建模上的不足，实现了对复杂场景更全面的渲染。

> **ai_Abstract:** 本文提出了FA-NeRF，一个新颖的频率感知视图合成框架，旨在解决当前NeRF模型在平衡场景整体结构（低频）和精细细节（高频）建模上的不足。FA-NeRF通过引入3D频率量化方法、频率网格和频率感知特征重加权策略，在一个单一模型中同时捕捉这两种信息，实验证明其在保留细节的同时对整个场景建模表现出显著优越性。

> **摘要翻译:** 人类通过跨越多种频率的信息来感知和理解周围环境。在沉浸式场景中，人们自然地扫描环境以掌握其整体结构，同时检查吸引他们注意力的物体的精细细节。然而，当前的NeRF框架主要侧重于建模高频局部视图或具有低频信息的场景的广阔结构，这在平衡两者方面存在局限性。我们引入了FA-NeRF，一个新颖的频率感知视图合成框架，它能在单个NeRF模型中同时捕获整体场景结构和高清晰度细节。为了实现这一点，我们提出了一种3D频率量化方法，该方法分析场景的频率分布，从而实现频率感知渲染。我们的框架包含一个频率网格，用于快速收敛和查询，以及一个频率感知特征重加权策略，以平衡不同频率内容之间的特征。大量实验表明，我们的方法在建模整个场景同时保留精细细节方面显著优于现有方法。项目页面：https://coscatter.github.io/LookCloser/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [278] [Ov3R: Open-Vocabulary Semantic 3D Reconstruction from RGB Videos](https://arxiv.org/abs/2507.22052)
> *Ov3R：基于RGB视频的开放词汇语义三维重建*

*Ziren Gong, Xiaohan Li, Fabio Tosi, Jiawei Han, Stefano Mattoccia, Jianfei Cai, Matteo Poggi* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 开放词汇, 语义三维重建, RGB视频, CLIP, 空间AI

**Comment:** 

> **TL;DR:** Ov3R是一个从RGB视频进行开放词汇语义三维重建的新框架，通过将CLIP语义直接整合到重建过程中，实现了最先进的稠密三维重建和开放词汇三维分割性能。

**AI_Comments:** 该论文的创新之处在于其首次将CLIP语义直接整合到三维重建过程中，从而实现了开放词汇的语义理解和更精细的语义对齐。这对于推动空间AI的发展具有重要意义，尤其是在需要实时、语义感知能力的机器人和AR/VR应用中。其提出的CLIP3R和2D-3D OVS模块设计巧妙，有效融合了视觉、几何和语义信息。通过实现最先进的性能，该工作为未来的研究提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在推进空间AI的发展，并解决现有方法在三维重建中未能直接整合CLIP语义的问题，以实现全局一致的几何和细粒度语义对齐。

**Method:** 本文提出了Ov3R框架，包含两个核心组件：CLIP3R是一个CLIP增强的三维重建模块，可从重叠片段预测密集点图并嵌入对象级语义；2D-3D OVS是一个2D-3D开放词汇语义模块，通过学习融合空间、几何和语义线索的描述符将2D特征提升到3D。Ov3R将CLIP语义直接整合到重建过程中。

**Result:** Ov3R框架在稠密三维重建和开放词汇三维分割方面均取得了最先进的性能。

**Conclusion:** Ov3R通过整合CLIP语义到三维重建过程，实现了全局一致的几何和细粒度语义对齐，是迈向实时、语义感知空间AI的重要一步。

> **ai_Abstract:** Ov3R是一个新颖的开放词汇语义三维重建框架，它利用RGB视频流，并直接将CLIP语义融入重建过程。该框架包含CLIP3R和2D-3D OVS两个模块，分别负责生成带语义的密集点图和将2D特征提升到3D。Ov3R克服了以往方法的局限性，实现了全局一致的几何和细粒度语义对齐，并在稠密三维重建和开放词汇三维分割方面达到了最先进的性能，为实时、语义感知的空间AI奠定了基础。

> **摘要翻译:** 我们提出了Ov3R，一个用于从RGB视频流进行开放词汇语义三维重建的新颖框架，旨在推进空间AI。该系统具有两个关键组件：CLIP3R是一个CLIP增强的三维重建模块，它从重叠片段预测密集点图，同时嵌入对象级语义；2D-3D OVS是一个2D-3D开放词汇语义模块，通过学习融合空间、几何和语义线索的描述符，将2D特征提升到3D。与以往的方法不同，Ov3R将CLIP语义直接整合到重建过程中，实现了全局一致的几何和细粒度语义对齐。我们的框架在稠密三维重建和开放词汇三维分割方面均取得了最先进的性能，标志着朝着实时、语义感知的空间AI迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [280] [Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions](https://arxiv.org/abs/2404.07214)
> *探索视觉-语言模型的边界：当前方法论和未来方向的综述*

*Akash Ghosh, Arkadeep Acharya, Sriparna Saha, Vinija Jain, Aman Chadha* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 视觉-语言模型, 大型语言模型, 多模态AI, 图像字幕, 视觉问答

**Comment:** One of the first survey on Visual Language Models

> **TL;DR:** 本综述探讨了视觉-语言模型（VLMs）的最新进展，旨在克服大型语言模型（LLMs）在处理视觉信息方面的局限性。文章对VLMs进行了分类，分析了它们的架构、训练数据和性能，并指出了未来的研究方向。

**AI_Comments:** 这是一篇重要的综述性论文，它系统地梳理了视觉-语言模型（VLMs）的当前发展，为研究人员提供了清晰的分类框架和深入的模型分析。其价值在于为该领域的初学者提供了入门指南，同时也为经验丰富的研究者指明了未来的研究方向和潜在挑战，有助于推动多模态AI的进一步发展。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在处理文本信息方面表现出色，但缺乏处理视觉信息的能力。为了弥补这一不足，研究人员致力于将视觉能力与LLMs结合，从而催生了视觉-语言模型（VLMs），以解决更复杂的任务，如图像字幕和视觉问答。

**Method:** 本综述将视觉-语言模型（VLMs）分为三类：专注于视觉-语言理解的模型、处理多模态输入生成单模态（文本）输出的模型，以及接受和生成多模态输入输出的模型。文章详细分析了每种模型的基础架构、训练数据来源、优缺点，并评估了VLMs在各种基准数据集上的表现。

**Result:** 本综述旨在提供对视觉-语言模型（VLMs）多样化格局的细致理解，并强调了该动态领域未来研究的潜在方向。

**Conclusion:** 本综述通过对视觉-语言模型（VLMs）的分类、架构和性能分析，为读者提供了对其基本组成部分的全面理解，并展望了该领域的未来发展。

> **ai_Abstract:** 本综述探讨了视觉-语言模型（VLMs）的兴起，以弥补大型语言模型（LLMs）在处理视觉信息方面的不足。文章将VLMs分为三类：视觉-语言理解、多模态输入-单模态输出、多模态输入-多模态输出。通过深入分析各模型的架构、训练数据、优缺点及基准性能，本综述旨在全面理解VLM领域，并展望未来的研究方向。

> **摘要翻译:** 大型语言模型（LLMs）的出现极大地重塑了人工智能革命的轨迹。然而，这些LLMs表现出一个显著的局限性，即它们主要擅长处理文本信息。为了解决这一限制，研究人员努力将视觉能力与LLMs相结合，从而催生了视觉-语言模型（VLMs）。这些先进的模型有助于解决更复杂的任务，如图像字幕和视觉问答。在本综合性综述论文中，我们深入探讨了VLM领域内的关键进展。我们的分类将VLM分为三个不同的类别：专注于视觉-语言理解的模型、处理多模态输入以生成单模态（文本）输出的模型，以及既接受又产生多模态输入和输出的模型。这种分类是基于它们在处理和生成各种数据模态方面的各自能力和功能。我们仔细剖析了每个模型，对其基础架构、训练数据来源以及其优点和局限性进行了广泛分析，尽可能为读者提供了对其基本组成部分的全面理解。我们还分析了VLM在各种基准数据集上的性能。通过这样做，我们旨在提供对VLM多样化格局的细致理解。此外，我们强调了该动态领域未来研究的潜在途径，期待进一步的突破和进步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [287] [Positive-Augmented Contrastive Learning for Vision-and-Language Evaluation and Training](https://arxiv.org/abs/2410.07336)
> *正向增强对比学习用于视觉-语言评估与训练*

*Sara Sarto, Nicholas Moratelli, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara* | **Category: cs.CV, cs.AI, cs.CL, cs.MM** | **Updated: 2025-07-29**

**Keywords:** 对比学习, 图像描述评估, 视觉-语言, CLIP, 微调

**Comment:** International Journal of Computer Vision (2025)

> **TL;DR:** 现有的图像描述评估指标存在缺陷。本文提出PAC-S++，一个基于CLIP的可学习指标，通过正向增强对比学习改进了描述评估和微调过程，从而生成更高质量的描述。

**AI_Comments:** 本文的创新之处在于利用正向增强对比学习在基于CLIP的框架中创建一个可学习的度量。其作为评估工具和微调奖励的双重作用意义重大，解决了描述生成质量方面的关键缺陷。专注于减少幻觉并提高语义丰富度是其一大亮点，有望推动图像描述领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 尽管图像描述生成取得了显著进展，但现有评估指标未能捕捉描述的完整质量或细粒度细节，主要原因是它们依赖非特定的人工参考或嘈杂的预训练数据。寻找一个有效的指标对于描述评估和生成阶段都至关重要，因为指标在描述模型微调阶段可以发挥关键作用，最终提升生成描述的质量。

**Method:** 本文提出PAC-S++，一个可学习的度量标准，它利用了在网络收集和清洗数据上预训练的CLIP模型，并通过额外生成的视觉和文本正样本对进行正则化。利用这种更强大和精炼的预训练，PAC-S++也被用作在通常用于微调描述模型的自批判序列训练（SCST）阶段的奖励。

**Result:** 在不同图像和视频数据集上的大量实验表明，PAC-S++与流行指标相比在任务上更有效，包括其对物体幻觉的敏感性。此外，将PAC-S++集成到描述模型的微调阶段，可以生成语义更丰富、重复更少、语法错误更少的描述。在域外基准测试上的评估进一步证明了我们微调方法在增强模型能力方面的有效性。

**Conclusion:** PAC-S++是一种有效的可学习指标，用于图像描述评估，也是微调图像描述模型的强大奖励，从而生成更高质量的描述。

> **ai_Abstract:** 本文提出PAC-S++，一种新颖的可学习指标，用于视觉-语言评估和训练。它通过利用强大的CLIP模型并结合正向样本正则化来改进现有评估指标。PAC-S++不仅作为有效的评估工具，还作为SCST（自批判序列训练）中微调描述模型的奖励信号，从而在各种数据集和域外场景中生成语义更丰富、更准确的描述，并有效减少物体幻觉、重复和语法错误。

> **摘要翻译:** 尽管在描述生成方面取得了显著进展，但现有评估指标往往未能捕捉描述的完整质量或细粒度细节。这主要是由于它们依赖非特定的人工编写的参考或嘈杂的预训练数据。然而，找到一个有效的指标不仅对描述评估至关重要，对生成阶段也同样重要。指标确实可以在描述模型的微调阶段发挥关键作用，最终提高生成描述的质量。在本文中，我们提出了PAC-S++，一个可学习的指标，它利用了在网络收集和清洗数据上预训练的CLIP模型，并通过额外生成的视觉和文本正样本对进行正则化。利用这种更强大和精炼的预训练，我们还将PAC-S++作为奖励应用于通常用于微调描述模型的自批判序列训练（SCST）阶段。在不同图像和视频数据集上的大量实验突出了PAC-S++与流行指标相比在任务上的有效性，包括其对物体幻觉的敏感性。此外，我们表明将PAC-S++集成到描述模型的微调阶段，可以生成语义更丰富、重复更少、语法错误更少的描述。在域外基准测试上的评估进一步证明了我们微调方法在增强模型能力方面的有效性。源代码和训练模型公开可用：https://github.com/aimagelab/pacscore。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [293] [LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering](https://arxiv.org/abs/2506.02733)
> *LinkTo-Anime：一个基于3D模型渲染的2D动画光流数据集*

*Xiaoyi Feng, Kaifeng Zou, Caichun Cen, Tao Huang, Hui Guo, Zizhou Huang, Yingli Zhao, Mingqing Zhang, Ziyuan Zheng, Diwei Wang, Yuntao Zou, Dagang Li* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 光流, 动画, 数据集, 3D渲染, 角色运动

**Comment:** 

> **TL;DR:** LinkTo-Anime是一个针对赛璐珞动画角色运动的2D动画光流数据集，通过3D模型渲染生成，填补了现有数据集的空白。

**AI_Comments:** 该论文通过专注于赛璐珞动画这一具有独特视觉和运动特征的领域，填补了现有光流数据集的一个明显空白。利用3D模型渲染生成数据，确保了高质量和多样性，并提供了精确的真实值。包含丰富的标注和基准测试，使其成为研究领域的重要资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有光流数据集主要关注真实世界模拟或合成人类运动，但很少有针对赛璐珞动画角色运动的数据集，而赛璐珞动画具有独特的视觉和运动特征。这阻碍了光流估计及动漫视频生成、线稿上色等下游任务的研究。

**Method:** 本文引入了LinkTo-Anime，这是第一个专门为赛璐珞动画角色运动设计的高质量数据集，通过3D模型渲染生成。该数据集提供前向和后向光流、遮挡掩码以及Mixamo骨架等丰富的标注。LinkTo-Anime包含395个视频序列，总计24,230个训练帧、720个验证帧和4,320个测试帧。此外，还构建了一个包含多种光流估计方法的综合基准。

**Result:** LinkTo-Anime数据集包含395个视频序列，总计24,230个训练帧、720个验证帧和4,320个测试帧。同时，构建了一个综合基准，用于分析各种光流估计方法在多个数据集上的缺点和局限性。

**Conclusion:** 本文介绍了LinkTo-Anime，一个专门为赛璐珞动画角色运动设计的高质量光流数据集，它通过3D模型渲染生成，并提供丰富的标注和综合基准。该数据集旨在弥补现有数据集的空白，并促进动画领域光流估计及相关下游任务的研究。

> **ai_Abstract:** LinkTo-Anime是一个新的高质量2D动画光流数据集，专门针对赛璐珞动画角色运动，通过3D模型渲染生成。它解决了现有光流数据集缺乏动画特定数据的问题，并提供了详细的标注信息和一套用于评估光流算法的基准。该数据集旨在推动动画领域的光流估计及相关下游任务的研究。

> **摘要翻译:** 现有光流数据集主要关注真实世界模拟或合成人类运动，但很少有专门针对赛璐珞动画（cel anime）角色运动的：这是一个具有独特视觉和运动特征的领域。为了弥补这一空白，并促进光流估计以及动漫视频生成和线稿上色等下游任务的研究，我们引入了LinkTo-Anime，这是第一个专门为赛璐珞动画角色运动设计的高质量数据集，通过3D模型渲染生成。LinkTo-Anime提供了丰富的标注，包括前向和后向光流、遮挡掩码和Mixamo骨架。该数据集包含395个视频序列，总计24,230个训练帧、720个验证帧和4,320个测试帧。此外，我们还构建了一个包含各种光流估计方法的综合基准，以分析多个数据集的缺点和局限性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [297] [Semantic Segmentation of iPS Cells: Case Study on Model Complexity in Biomedical Imaging](https://arxiv.org/abs/2507.21608)
> *iPS细胞的语义分割：生物医学成像中模型复杂性的案例研究*

*Maoquan Zhang, Bisser Raytchev, Xiujuan Sun* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** iPS细胞, 语义分割, DeepLabv3, 模型复杂性, 生物医学成像

**Comment:** 19th International Conference on Machine Vision Applications MVA2025

> **TL;DR:** 本研究表明，针对iPS细胞语义分割任务，精心配置的DeepLabv3模型表现优异，甚至超越了SAM2和MedSAM2等大型基础模型，提示在生物医学特定任务中，模型复杂性并非性能提升的唯一途径。

**AI_Comments:** 本文挑战了当前AI领域中“模型越大越好”的主流趋势，通过实例证明了针对特定生物医学任务，一个经过良好调整的、相对简单的模型可以胜过更复杂的通用基础模型。这对于资源受限或需要高度领域特异性准确性的应用具有重要意义。提供的开源实现也对再生医学等领域的发展具有积极推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像分割需要高准确性和鲁棒性。本研究旨在重新审视“更大更通用模型总是更好”的假设，特别是在处理具有细微、低对比度边界的专业任务时。

**Method:** 本研究使用了一个精心配置的DeepLabv3模型来分割诱导多能干细胞（iPS）集落。在实验条件下，将其性能与SAM2和MedSAM2等大型基础模型进行了比较。同时提供了一个开源实现，包含针对小型数据集和领域特定编码的策略。

**Result:** 精心配置的DeepLabv3模型在iPS细胞集落分割中实现了高性能，并在实验条件下，在未经结构修改的情况下，优于SAM2和MedSAM2等大型基础模型。

**Conclusion:** 对于以细微、低对比度边界为特征的专业任务，增加模型复杂性不一定能转化为更好的性能。适当调整的、更简单的模型可以在特定领域的生物医学应用中提供强大的准确性和实用可靠性。

> **ai_Abstract:** 本研究探讨了iPS细胞集落的语义分割，结果表明，经过精心配置的DeepLabv3模型能够实现高性能，并超越了SAM2和MedSAM2等大型基础模型。研究结果挑战了模型复杂性必然带来更好性能的观念，尤其是在处理具有低对比度边界的专业生物医学任务时。本工作倡导在特定领域应用中，更简单、适应性更强的模型也能提供强大的准确性和实用可靠性，并为此提供了一个开源实现以促进相关领域的进一步发展。

> **摘要翻译:** 医学图像分割不仅需要准确性，还需要在具有挑战性的成像条件下保持鲁棒性。在这项研究中，我们展示了一个精心配置的DeepLabv3模型在诱导多能干细胞（iPS）集落分割方面可以实现高性能，并且在我们的实验条件下，其性能优于SAM2及其医学变体MedSAM2等大型基础模型，且无需进行结构修改。这些结果表明，对于以细微、低对比度边界为特征的专业任务，增加模型复杂性不一定能转化为更好的性能。我们的工作重新审视了“越大越好、越通用越好”的架构假设，并提供了证据，表明经过适当调整的、更简单的模型可以在特定领域的生物医学应用中提供强大的准确性和实用可靠性。我们还提供了一个开源实现，其中包括针对小型数据集和领域特定编码的策略，旨在支持再生医学及相关领域语义分割的进一步发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [302] [Dual Guidance Semi-Supervised Action Detection](https://arxiv.org/abs/2507.21247)
> *双重指导半监督动作检测*

*Ankit Singh, Efstratios Gavves, Cees G. M. Snoek, Hilde Kuehne* | **Category: cs.CV** | **Updated: 2025-07-28**

**Keywords:** 半监督学习, 动作检测, 时空定位, 双重指导网络, 伪边界框

**Comment:** 

> **TL;DR:** 该论文提出了一种用于时空动作定位的半监督学习方法，利用双重指导网络选择更好的伪边界框，并在有限标注数据下显著提升了性能。

**AI_Comments:** 该论文的创新点在于将半监督学习应用于时空动作定位，并提出了独特的双重指导网络来优化伪边界框的选择，解决了动作检测中数据标注成本高的问题。其重要性在于为未来低资源条件下的时空动作检测研究提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 半监督学习（SSL）在深度学习模型预测性能方面潜力巨大，尤其是在难以获取标注数据的情况下。然而，SSL的应用主要集中在图像分类领域，而其在时空动作定位中的应用研究较少。

**Method:** 本文提出了一种用于时空动作定位的半监督方法。该方法引入了一个双重指导网络来选择更好的伪边界框。它将帧级分类与边界框预测相结合，以强制执行跨帧和边界框的动作类别一致性。

**Result:** 在UCF101-24、J-HMDB-21和AVA等时空动作定位数据集上的评估表明，所提出的模块在有限标注数据设置下显著提升了模型的性能。该框架比扩展的基于图像的半监督基线取得了更优越的结果。

**Conclusion:** 该研究成功地将半监督学习应用于时空动作定位，通过引入双重指导网络有效提升了模型在有限标注数据下的性能，并超越了现有基线。

> **ai_Abstract:** 本论文针对半监督学习在时空动作定位领域的应用空白，提出了一种名为“双重指导”的半监督方法。该方法通过结合帧级分类和边界框预测来选择更准确的伪边界框，从而在数据标注有限的情况下提升模型性能。实验结果表明，该方法在多个标准数据集上均显著优于现有的基于图像的半监督基线。

> **摘要翻译:** 半监督学习（SSL）在标注数据难以获取时，在提高深度学习模型的预测性能方面展现出巨大潜力。然而，迄今为止，SSL的应用主要在图像分类领域进行研究。在这项工作中，我们提出了一种用于时空动作定位的半监督方法。我们引入了一个双重指导网络来选择更好的伪边界框。它将帧级分类与边界框预测相结合，以强制执行跨帧和边界框的动作类别一致性。我们在著名的时空动作定位数据集，即UCF101-24、J-HMDB-21和AVA上的评估表明，所提出的模块在有限标注数据设置下显著增强了模型的性能。我们的框架与扩展的基于图像的半监督基线相比，取得了更优越的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [305] [Anyone Can Jailbreak: Prompt-Based Attacks on LLMs and T2Is](https://arxiv.org/abs/2507.21820)
> *任何人都可以越狱：基于提示的LLMs和T2Is攻击*

*Ahmed B Mustafa, Zihan Ye, Yang Lu, Michael P Pound, Shreyank N Gowda* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 越狱, 提示攻击, LLM, T2I, 安全机制

**Comment:** 

> **TL;DR:** 尽管LLMs和T2I系统在对齐和内容审核方面取得了进展，但它们仍然容易受到普通用户通过巧妙提示进行的低成本、高影响的越狱攻击。本文系统地调查了非专家如何规避安全机制，提出了一个统一的越狱策略分类法，并强调了对上下文感知防御的迫切需求。

**AI_Comments:** 本文的创新之处在于系统地调查了非专家如何利用低成本、高影响的提示来“越狱”LLMs和T2I系统。它揭示了当前内容审核管道的脆弱性，并提出了一个实用的越狱策略分类法。其重要性在于强调了在实际应用中开发更强大、上下文感知防御机制的紧迫性，对于AI安全领域具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）和文本到图像（T2I）系统在对齐和内容审核方面取得了显著进展，但它们仍然容易受到基于提示的攻击（即越狱）。与需要专业知识的传统对抗性示例不同，目前的许多越狱攻击都是由普通用户通过巧妙的提示轻松实现且影响巨大的。因此，本文旨在系统地调查非专家如何可靠地规避安全机制。

**Method:** 本文采用系统式调查方法，研究了非专家如何通过多轮叙事升级、词汇伪装、隐含链式、虚构冒充和细微语义编辑等技术可靠地规避安全机制。研究提出了一个统一的提示级别越狱策略分类法，涵盖了文本输出和T2I模型，并基于对流行API的实证案例研究进行验证。

**Result:** 分析表明，内容审核管道的每个阶段，从输入过滤到输出验证，都可以通过可访问的策略绕过。

**Conclusion:** 本文得出结论，迫切需要上下文感知的防御措施，以应对这些越狱攻击在现实世界中易于复制的特性。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）和文本到图像（T2I）系统容易受到普通用户通过巧妙提示进行的“越狱”攻击。研究通过系统调查，揭示了非专家如何利用多轮叙事、词汇伪装等技术绕过安全机制。文章提出了一个统一的提示级别越狱策略分类法，并指出内容审核管道的各个阶段均可被规避。最终，论文强调了开发上下文感知防御措施的紧迫性。

> **摘要翻译:** 尽管大型语言模型（LLMs）和文本到图像（T2I）系统在对齐和内容审核方面取得了显著进展，但它们仍然容易受到基于提示的攻击，即越狱。与需要专业知识的传统对抗性示例不同，目前许多越狱攻击都是由普通用户通过巧妙措辞的提示轻松实现且影响巨大的。本文对非专家如何通过多轮叙事升级、词汇伪装、隐含链式、虚构冒充和细微语义编辑等技术可靠地规避安全机制进行了系统式调查。我们提出了一个统一的提示级别越狱策略分类法，涵盖了文本输出和T2I模型，并以对流行API的实证案例研究为基础。我们的分析揭示，内容审核管道的每个阶段，从输入过滤到输出验证，都可以通过易于访问的策略绕过。最后，我们强调迫切需要上下文感知的防御措施，以反映这些越狱攻击在现实世界中易于复制的特性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [307] [DEPTHOR: Depth Enhancement from a Practical Light-Weight dToF Sensor and RGB Image](https://arxiv.org/abs/2504.01596)
> *DEPTHOR：基于实用轻量级dToF传感器和RGB图像的深度增强*

*Jijun Xiang, Xuan Zhu, Xianqi Wang, Yu Wang, Hong Zhang, Fei Guo, Xin Yang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 深度增强, dToF传感器, 深度补全, 单目深度估计, 噪声鲁棒训练

**Comment:** 16 pages, 15 figures, 7 tables

> **TL;DR:** DEPTHOR提出了一种新的基于补全的深度增强方法，通过模拟真实世界dToF数据和整合单目深度估计来解决dToF图像的校准误差和异常信号问题，在多个数据集上实现了最先进的性能。

**AI_Comments:** 本文的创新点在于提出了模拟真实世界dToF数据的方法，使得模型能够在噪声环境下进行鲁棒训练，以及将单目深度估计引入深度补全任务，有效利用了全局和上下文信息。这使得该方法能够更好地适应实际dToF传感器的局限性，具有重要的实际应用价值。其在多个数据集上取得的SOTA结果也证明了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于超分辨率的深度增强方法依赖理想化假设，忽略了dToF成像固有的校准误差和异常信号，限制了其在实际应用中的可行性。为了解决这些挑战，本文提出了DEPTHOR。

**Method:** 本文提出了一种名为DEPTHOR的新型基于补全的方法，其在训练策略和模型架构上都有改进。首先，提出了一种从合成数据集中准确的真实值模拟真实世界dToF数据的方法，以实现噪声鲁棒训练。其次，设计了一个新的网络，结合了单目深度估计（MDE），利用全局深度关系和上下文信息来改进挑战区域的预测。

**Result:** 在ZJU-L5数据集上，所提出的训练策略显著增强了深度补全模型，结果与深度超分辨率方法相当；所提出的模型达到了最先进的性能，Rel和RMSE分别提高了27%和18%。在作者收集的更具挑战性的dToF样本集上，该方法优于现有最先进的方法，Rel和RMSE分别提高了23%和22%。

**Conclusion:** DEPTHOR通过创新的训练策略和网络架构，有效解决了dToF传感器在实际应用中存在的校准误差和异常信号问题，实现了高精度、密集的深度图生成，并在多个数据集上取得了显著的性能提升。

> **ai_Abstract:** 本文提出了一种名为DEPTHOR的新型深度补全方法，旨在解决实际dToF传感器存在的校准误差和异常信号问题。该方法通过模拟真实世界dToF数据进行噪声鲁棒训练，并结合单目深度估计网络，利用全局深度关系和上下文信息来提升深度预测。实验结果表明，DEPTHOR在多个数据集上均达到了最先进的性能，显著改善了深度图的精度和密度。

> **摘要翻译:** 深度增强，即利用RGB图像作为指导将dToF原始信号转换为高精度、密集的深度图，是计算机视觉中的一项关键任务。尽管现有的基于超分辨率的方法在公共数据集上显示出有希望的结果，但它们通常依赖于理想化的假设，例如精确的区域对应和可靠的dToF输入，忽略了导致未对准和dToF成像固有异常信号的校准误差，从而限制了实际应用。为了解决这些挑战，我们提出了一种新颖的基于补全的方法，名为DEPTHOR，其在训练策略和模型架构上都有进步。首先，我们提出了一种从合成数据集中的精确真实值模拟真实世界dToF数据的方法，以实现噪声鲁棒训练。其次，我们设计了一个新的网络，该网络结合了单目深度估计（MDE），利用全局深度关系和上下文信息来改进挑战区域的预测。在ZJU-L5数据集上，我们的训练策略显著增强了深度补全模型，实现了与深度超分辨率方法相当的结果，而我们的模型达到了最先进的性能，Rel和RMSE分别提高了27%和18%。在我们收集的一组更具挑战性的dToF样本上，我们的方法在初步的基于立体的GT上优于SOTA方法，Rel和RMSE分别提高了23%和22%。我们的代码可在https://github.com/ShadowBbBb/Depthor获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [310] [Dual Cross-image Semantic Consistency with Self-aware Pseudo Labeling for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2507.21440)
> *用于半监督医学图像分割的双跨图像语义一致性与自感知伪标签*

*Han Wu, Chong Wang, Zhiming Cui* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 半监督学习, 医学图像分割, 语义一致性, 伪标签, 原型对齐

**Comment:** IEEE TMI

> **TL;DR:** 本文提出了一种名为DuCiSC的半监督学习框架，通过双重跨图像语义一致性和自感知伪标签，有效解决了医学图像分割中标记数据有限和特征差异的问题。

**AI_Comments:** DuCiSC的创新之处在于其对跨图像区域级语义一致性的关注，以及提出的自感知伪标签策略，这些对于在有限标记数据下提升医学图像分割的性能至关重要。该方法在不同复杂度的医学数据集上的验证结果，证明了其强大的鲁棒性和实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前半监督医学图像分割方法主要依赖于图像内像素级一致性训练，忽视了更全面的语义级别（如对象区域）的一致性。同时，由于标记和未标记数据数量不平衡，导致提取的特征存在严重差异。

**Method:** 本文提出了DuCiSC（Dual Cross-image Semantic Consistency）学习框架。该框架除了像素级语义一致性外，还引入了双重范式来鼓励区域级语义一致性：1）在标记图像和未标记图像之间；2）在标记图像和融合图像之间。这通过显式对齐原型来实现，从而解决特征差异问题。此外，DuCiSC设计了一种新颖的自感知置信度估计算法，用于准确选择可靠的伪标签，并利用未标记数据的训练动态。

**Result:** DuCiSC方法通过原型表示有效地建立了跨图像语义一致性，解决了特征差异问题。自感知置信度估计策略能够准确选择可靠的伪标签。该方法在四个数据集上进行了广泛验证，包括左心房、胰腺、ACDC和下牙槽神经分割，显示出优于现有最先进方法的分割结果。

**Conclusion:** DuCiSC框架通过引入双重跨图像语义一致性和自感知伪标签策略，有效克服了半监督医学图像分割中现有方法的局限性，并在多个数据集上取得了卓越的分割性能。

> **ai_Abstract:** 本文提出DuCiSC，一种用于半监督医学图像分割的新型学习框架。它通过引入双重跨图像区域级语义一致性（通过对齐标记/未标记和标记/融合图像的原型）以及自感知伪标签策略，解决了现有方法中语义一致性不足和特征差异的问题。DuCiSC在多个医学图像数据集上的广泛验证表明其性能优于现有最先进方法。

> **摘要翻译:** 半监督学习在解决医学图像分割中标记训练数据有限的挑战方面已被证明非常有效。通常，当前依赖于通过伪标签进行图像内像素级一致性训练的方法，忽视了更全面的语义级别（例如，对象区域）的一致性，并且由于标记和未标记数据数量不平衡而导致提取特征的严重差异。为了克服这些限制，我们提出了一种新的双跨图像语义一致性（DuCiSC）学习框架，用于半监督医学图像分割。具体来说，除了强制执行像素级语义一致性之外，DuCiSC 提出了双重范式，通过显式对齐其原型来鼓励跨以下两者的区域级语义一致性：1）标记图像和未标记图像；以及 2）标记图像和融合图像。依靠这些双重范式，DuCiSC 可以通过原型表示有效地建立一致的跨图像语义，从而解决特征差异问题。此外，我们设计了一种新颖的自感知置信度估计策略，以准确选择可靠的伪标签，从而利用未标记数据的训练动态。我们的 DuCiSC 方法在四个数据集上进行了广泛验证，包括两个流行的用于分割左心房和胰腺的二元基准数据集，一个多类别自动心脏诊断挑战数据集，以及一个具有复杂解剖结构的下牙槽神经分割的挑战性场景，结果显示出优于以往最先进方法的分割效果。我们的代码已在 https://github.com/ShanghaiTech-IMPACT/DuCiSC 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [313] [MetaLab: Few-Shot Game Changer for Image Recognition](https://arxiv.org/abs/2507.22057)
> *MetaLab：少量样本图像识别的颠覆者*

*Chaofei Qi, Zhitai Liu, Jianbin Qiu* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 少量样本图像识别, 元学习, CIELab, 图神经网络, 图像识别

**Comment:** 

> **TL;DR:** MetaLab是一种高效的少量样本图像识别方法，通过在CIELab颜色空间进行域转换和图神经网络实现高精度和泛化能力，接近人类识别水平。

**AI_Comments:** MetaLab通过结合CIELab颜色空间转换和图神经网络的元学习方法，在少量样本图像识别领域取得了接近人类识别水平的突破性成果，具有重要的创新性和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 困难的少量样本图像识别具有显著的应用前景，但与传统的、大规模图像识别仍存在实质性的技术差距。

**Method:** 本文提出了一种名为CIELab引导的相干元学习（MetaLab）的高效原创方法。MetaLab由两个协作的神经网络组成：LabNet（用于CIELab颜色空间域转换和提取丰富分组特征）和相干LabGNN（促进亮度图和颜色图之间的相互学习）。

**Result:** 在四种粗粒度、四种细粒度以及四种跨域少量样本基准测试中进行了广泛的比较研究。MetaLab在每类一个样本的情况下，实现了高精度、鲁棒的性能和有效的泛化能力。所有实验表明，MetaLab的准确率接近99%，达到了人类识别的上限，且视觉偏差很小。

**Conclusion:** MetaLab显著缩小了少量样本图像识别与人类识别之间的技术差距，为该领域带来了突破性的进展。

> **ai_Abstract:** 本文提出了一种名为MetaLab的少量样本图像识别方法，旨在弥补与传统大规模图像识别之间的技术差距。MetaLab包含LabNet和LabGNN两个协作网络，利用CIELab颜色空间进行域转换和特征提取，并通过图神经网络实现亮度图和颜色图的相互学习。实验证明，MetaLab在多种基准测试中展现出高精度、鲁棒性和泛化能力，在每类一个样本的情况下，准确率接近99%，达到人类识别的上限。

> **摘要翻译:** 困难的少量样本图像识别具有显著的应用前景，但与传统的、大规模图像识别仍存在实质性的技术差距。在本文中，我们提出了一种针对少量样本图像识别的高效原创方法，称为CIELab引导的相干元学习（MetaLab）。从结构上看，我们的MetaLab包含两个协作的神经网络：LabNet，它可以对CIELab颜色空间进行域转换并提取丰富的分组特征；以及相干LabGNN，它可以促进亮度图和颜色图之间的相互学习。为了充分验证，我们对四种粗粒度基准、四种细粒度基准和四种跨域少量样本基准进行了广泛的比较研究。具体而言，我们的方法在每类一个样本的情况下，可以实现高精度、鲁棒的性能和有效的泛化能力。总的来说，所有实验都表明我们的MetaLab可以达到99%以上的准确率，接近人类识别的上限，且视觉偏差很小。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [329] [Co-AttenDWG: Co-Attentive Dimension-Wise Gating and Expert Fusion for Multi-Modal Offensive Content Detection](https://arxiv.org/abs/2505.19010)
> *Co-AttenDWG：用于多模态冒犯性内容检测的协同注意力维度门控和专家融合*

*Md. Mithun Hossain, Md. Shakil Hossain, Sudipto Chaki, M. F. Mridha* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 多模态学习, 冒犯性内容检测, 协同注意力, 维度门控, 专家融合

**Comment:** 

> **TL;DR:** Co-AttenDWG是一种新的多模态学习方法，通过协同注意力、维度门控和专家融合，提高了冒犯性内容检测的性能并增强了跨模态交互。

**AI_Comments:** Co-AttenDWG的创新之处在于其结合了协同注意力、维度门控和专家融合，旨在解决现有多模态融合策略中跨模态交互不足和融合僵化的问题。这种多层次的融合和特征调制策略显著提升了多模态学习的性能，特别是在冒犯性内容检测方面，并有望推广到其他多模态应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在多模态学习中存在跨模态交互不足和融合策略僵化的问题，未能充分利用不同模态的互补优势。

**Method:** 本文提出了Co-AttenDWG方法，首先将文本和视觉特征投影到共享嵌入空间，然后通过专用的协同注意力机制实现模态间细粒度交互。接着，维度门控网络自适应地调节通道级别的特征贡献。同时，双路径编码器独立细化模态特定表示，并通过额外的交叉注意力层进一步对齐模态。最后，专家融合模块整合学习到的门控和自注意力，生成鲁棒的统一表示。

**Result:** Co-AttenDWG在MIMIC和SemEval Memotion 1.0数据集上取得了最先进的性能和卓越的跨模态对齐。

**Conclusion:** Co-AttenDWG有效解决了多模态学习中跨模态交互和融合的局限性，在多模态冒犯性内容检测及其他多模态应用中表现出显著效果。

> **ai_Abstract:** 本文提出Co-AttenDWG，一种用于多模态冒犯性内容检测的新方法。它通过将文本和视觉特征投影到共享空间，利用协同注意力实现细粒度交互，并通过维度门控网络、双路径编码器和交叉注意力层增强特征表示和模态对齐。最终，专家融合模块整合特征以生成鲁棒的统一表示。实验结果表明，Co-AttenDWG在多模态数据集上实现了最先进的性能和优越的跨模态对齐。

> **摘要翻译:** 多模态学习已成为一个重要的研究方向，因为整合文本和视觉信息可以显著提高分类、检索和场景理解等任务的性能。尽管大型预训练模型取得了进展，但现有方法常常存在跨模态交互不足和融合策略僵化的问题，未能充分利用不同模态的互补优势。为了解决这些局限性，我们提出了Co-AttenDWG，即协同注意力维度门控和专家融合。我们的方法首先将文本和视觉特征投影到共享嵌入空间中，其中专用的协同注意力机制能够实现模态之间同步的、细粒度的交互。维度门控网络进一步强化了这一点，它在通道级别自适应地调节特征贡献，以强调显著信息。同时，双路径编码器独立地细化模态特定的表示，而额外的交叉注意力层则进一步对齐模态。最终的特征通过一个专家融合模块进行聚合，该模块整合了学习到的门控和自注意力，从而产生一个鲁棒的统一表示。在MIMIC和SemEval Memotion 1.0数据集上的实验结果表明，Co-AttenDWG实现了最先进的性能和卓越的跨模态对齐，突出了其在各种多模态应用中的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [341] [X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image Generative Models Great Again](https://arxiv.org/abs/2507.22058)
> *X-Omni：强化学习让离散自回归图像生成模型重焕生机*

*Zigang Geng, Yibing Wang, Yeyao Ma, Chen Li, Yongming Rao, Shuyang Gu, Zhao Zhong, Qinglin Lu, Han Hu, Xiaosong Zhang, Linus, Di Wang, Jie Jiang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 强化学习, 自回归模型, 图像生成, 离散token, 统一建模

**Comment:** 

> **TL;DR:** X-Omni通过强化学习显著提升了离散自回归图像生成模型的质量，实现了图像与语言生成的无缝集成，并取得了最先进的性能。

**AI_Comments:** X-Omni的创新之处在于其利用强化学习有效解决了离散自回归图像生成模型的固有缺陷，成功地将图像和语言生成整合到统一的框架中。这扭转了当前研究领域偏向分离训练的趋势，展示了统一建模的巨大潜力。其在高质量图像生成和复杂指令遵循上的表现，预示着未来多模态AI发展的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 尝试通过离散自回归模型生成图像时，存在视觉保真度低、输出失真以及难以遵循复杂指令等问题，这可能是由于自回归推理中的累积误差或离散化过程中的信息损失所致。因此，近期研究倾向于将图像生成与扩散目标、语言生成与自回归目标分开训练，而非采用统一建模方法。

**Method:** 本文提出X-Omni框架，通过强化学习有效缓解了离散自回归建模方法的伪影问题，并显著提升了生成质量，从而实现了图像与语言生成的无缝集成。X-Omni框架包含一个语义图像分词器、一个用于语言和图像的统一自回归模型，以及一个用于图像生成的离线扩散解码器。

**Result:** X-Omni使用一个7B语言模型，在图像生成任务中实现了最先进的性能，生成了高质量的图像，并展现出强大的遵循指令和渲染长文本的能力。

**Conclusion:** 强化学习能够有效解决离散自回归图像生成模型的固有问题，使其能够生成高质量图像并实现图像与语言的统一建模，从而扭转了当前研究偏离统一建模的趋势。

> **ai_Abstract:** 本文提出了X-Omni框架，旨在解决离散自回归图像生成模型中存在的低视觉保真度和指令遵循困难等问题。通过引入强化学习，X-Omni显著提升了图像生成质量，并实现了图像与语言生成的统一。该框架包含语义图像分词器、统一自回归模型和离线扩散解码器。实验证明，X-Omni使用7B语言模型在图像生成任务中达到最先进水平，能够生成高质量图像并有效遵循指令。

> **摘要翻译:** 许多努力都致力于将“下一个token预测”范式扩展到视觉内容，旨在为图像生成和理解创建一种统一的方法。然而，通过离散token的自回归建模来生成图像一直受到视觉保真度低、输出失真以及在渲染复杂细节时无法遵循复杂指令等问题的困扰。这些缺点可能归因于自回归推理过程中的累积误差或离散化过程中产生的信息损失。可能由于这一挑战，最近的研究越来越多地转向将图像生成与扩散目标、语言生成与自回归目标联合训练，从而偏离了统一建模方法。在这项工作中，我们证明了强化学习可以有效缓解伪影并大大提高离散自回归建模方法的生成质量，从而实现图像和语言生成的无缝集成。我们的框架包括一个语义图像分词器、一个用于语言和图像的统一自回归模型，以及一个用于图像生成的离线扩散解码器，该框架被称为X-Omni。X-Omni使用一个7B语言模型在图像生成任务中取得了最先进的性能，生成了高美学质量的图像，同时在遵循指令和渲染长文本方面表现出强大的能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [342] [Sparfels: Fast Reconstruction from Sparse Unposed Imagery](https://arxiv.org/abs/2505.02178)
> *Sparfels: 稀疏未定位图像的快速重建*

*Shubhendu Jena, Amine Ouasfi, Mae Younes, Adnane Boukhayma* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 稀疏视图重建, 表面元素泼溅, 3D基础模型, 2D高斯泼溅, 形状重建

**Comment:** ICCV 2025. Project page :
  https://shubhendu-jena.github.io/Sparfels-web/

> **TL;DR:** Sparfels是一种基于表面元素泼溅的稀疏视图重建方法，它利用3D基础模型和新的泼溅颜色方差公式，在稀疏未校准设置下实现了快速（3分钟内）和最先进的形状重建和新视图合成性能。

**AI_Comments:** 该论文的创新点在于其结合了最新的3D基础模型与2D高斯泼溅技术，并引入了独特的泼溅颜色方差公式来优化形状重建。其在稀疏未校准设置下实现快速（3分钟内）且最先进的性能，对于实际应用具有重要意义，尤其是在处理缺乏精确相机姿态信息的图像数据时。该方法在速度和精度之间取得了很好的平衡。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法很少解决从嘈杂或未定位的稀疏相机中学习稀疏辐射场的问题，并且在这种设置下，形状恢复相对未被充分探索。虽然一些辐射和形状学习测试时间优化方法通过学习数据先验或使用外部单目几何先验的组合来解决稀疏定位设置，但本研究旨在解决稀疏未校准图像的快速和准确重建问题。

**Method:** 本研究提出了一种名为Sparfels的方法，它是一种高效简单的流水线，利用单个最近的3D基础模型。该方法利用该模型的各种任务头（特别是点图和相机初始化）来实例化一个束调整的2D高斯泼溅（2DGS）模型，并使用图像对应关系在2DGS训练中引导相机优化。关键贡献在于提出了一种新的、可高效计算的沿射线的泼溅颜色方差公式。通过在训练中减少这一矩，可以实现更准确的形状重建。

**Result:** 该方法在稀疏未校准设置下的重建和新视图基准测试中，基于已建立的多视图数据集，展示了最先进的性能。它能在消费级GPU上在3分钟内完成重建。

**Conclusion:** Sparfels通过结合3D基础模型、2D高斯泼溅和创新的泼溅颜色方差公式，成功地在稀疏未校准图像设置下实现了快速且最先进的形状重建和新视图合成。

> **ai_Abstract:** 本文提出了Sparfels，一种用于稀疏视图重建的表面元素泼溅方法。它利用单个3D基础模型及其任务头（如点图和相机初始化）来实例化一个束调整的2D高斯泼溅模型，并通过图像对应关系在训练中引导相机优化。该方法引入了一种新的、可高效计算的沿射线泼溅颜色方差公式，通过减少该方差来提高形状重建精度。Sparfels在消费级GPU上可在3分钟内完成重建，并在稀疏未校准设置下的重建和新视图合成基准测试中达到了最先进的性能。

> **摘要翻译:** 我们提出了一种用于稀疏视图重建的方法，该方法采用表面元素泼溅技术，可在消费级GPU上在3分钟内运行。虽然很少有方法能解决从嘈杂或未定位的稀疏相机中学习稀疏辐射场的问题，但在此设置下，形状恢复相对未被充分探索。一些辐射和形状学习测试时间优化方法通过学习数据先验或使用外部单目几何先验的组合来解决稀疏定位设置。与此不同，我们提出了一种高效且简单的流水线，利用单个最近的3D基础模型。我们利用其各种任务头，特别是点图和相机初始化，来实例化一个束调整的2D高斯泼溅（2DGS）模型，并利用图像对应关系在2DGS训练中引导相机优化。我们贡献的关键是提出了一种新的、可高效计算的沿射线的泼溅颜色方差公式。在训练中减少这一矩会导致更准确的形状重建。我们在基于已建立的多视图数据集的重建和新视图基准测试中，展示了稀疏未校准设置下的最先进性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [347] [Cross-Architecture Distillation Made Simple with Redundancy Suppression](https://arxiv.org/abs/2507.21844)
> *通过冗余抑制简化跨架构蒸馏*

*Weijia Zhang, Yuehao Liu, Wu Ran, Chao Ma* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 跨架构蒸馏, 知识蒸馏, 冗余抑制, 模型压缩, 架构无关

**Comment:** Accepted by ICCV 2025 (Highlight)

> **TL;DR:** 提出了一种通过抑制冗余信息来简化跨架构知识蒸馏的简单方法，优于现有方法并具有更少的参数开销。

**AI_Comments:** 该论文的创新点在于将跨架构知识蒸馏问题转化为冗余信息抑制的范式，并提出了简单有效的RSD损失和轻量级解耦模块。相较于现有复杂方法，其在性能提升的同时显著降低了参数开销，这对于实际应用具有重要意义。其简洁性使其成为未来研究的有力基线。

<details>
  <summary>Details</summary>

**Motivation:** 现有跨架构知识蒸馏方法引入了复杂的模块、针对特定架构的设计和过多的参数，这损害了它们的效率和适用性。

**Method:** 提出了一种名为冗余抑制蒸馏（RSD）的简单损失函数，它包括跨架构不变性最大化和特征去相关目标，以提取异构表示中的架构无关知识。此外，设计了一个轻量级模块，将RSD目标与学生模型的内部表示解耦，以保留其架构特定能力。

**Result:** 该方法在CIFAR-100和ImageNet-1k基准测试中优于OFA，且参数开销仅为其一小部分。

**Conclusion:** 该方法有望成为跨架构蒸馏领域一个简单而强大的基线。

> **ai_Abstract:** 本研究提出了一种名为冗余抑制蒸馏（RSD）的简单方法，用于跨架构知识蒸馏。该方法通过将知识转移建模为冗余信息抑制问题，旨在提取异构表示中的架构无关知识，从而避免了现有方法中复杂的模块和过多的参数。RSD损失结合了跨架构不变性最大化和特征去相关，并辅以一个轻量级模块以保留学生模型的架构特定能力。实验结果表明，该方法在CIFAR-100和ImageNet-1k上表现优于OFA，且具有显著降低的参数开销，有望成为跨架构蒸馏领域的一个强有力基线。

> **摘要翻译:** 我们描述了一种简单的跨架构知识蒸馏方法，其中知识迁移被转化为冗余信息抑制的形式。现有方法引入了复杂的模块、针对特定架构的设计和过多的参数，这损害了它们的效率和适用性。我们提出通过减少冗余的架构专属信息来提取异构表示中的架构无关知识。为此，我们提出了一种简单的冗余抑制蒸馏（RSD）损失，它包括跨架构不变性最大化和特征去相关目标。为了防止学生模型完全失去其架构特定能力，我们进一步设计了一个轻量级模块，将RSD目标与学生模型的内部表示解耦。我们的方法没有OFA开创性方法中的架构特定设计和复杂操作。它在CIFAR-100和ImageNet-1k基准测试上优于OFA，且参数开销仅为其一小部分，这突显了其作为跨架构蒸馏社区简单而强大基线的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [350] [SpatialViz-Bench: Automatically Generated Spatial Visualization Reasoning Tasks for MLLMs](https://arxiv.org/abs/2507.07610)
> *SpatialViz-Bench：为多模态大语言模型自动生成的空间可视化推理任务*

*Siting Wang, Luoyang Sun, Cheng Deng, Kun Shao, Minnan Pei, Zheng Tian, Haifeng Zhang, Jun Wang* | **Category: cs.CV, cs.CL, cs.HC** | **Updated: 2025-07-30**

**Keywords:** 空间可视化, 多模态大语言模型, 基准测试, 自动生成, 性能评估

**Comment:** 

> **TL;DR:** 引入SpatialViz-Bench，一个用于评估多模态大语言模型（MLLMs）空间可视化能力的综合基准，揭示了当前模型在该任务上的显著不足和反直觉现象。

**AI_Comments:** 该论文通过引入SpatialViz-Bench，填补了MLLMs空间可视化能力评估的空白，其自动生成问题的方法提高了评估的可靠性。发现模型在2D到3D转换、人类直觉理解以及思维链提示的负面影响等方面的反直觉现象，对未来MLLMs的设计和改进具有重要指导意义。其公开数据集和代码也有助于推动该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 人类具有空间可视化能力，而多模态大语言模型（MLLMs）在此方面的评估不足，现有评估方法（如IQ测试或数学竞赛）可能与训练数据重叠，导致评估可靠性受损。

**Method:** 引入SpatialViz-Bench，一个包含12个任务、4个子能力、1180个自动生成问题的综合多模态基准。对33个最先进的MLLMs进行了评估，并进行了错误类型的统计和定性分析。

**Result:** 评估显示模型性能差异大，基准具有强区分力；模型显示的难度感知与人类直觉不符；存在剧烈的2D到3D性能断崖；模型默认采用公式化推导而非可视化；开源模型在思维链提示下性能反而下降。

**Conclusion:** SpatialViz-Bench揭示了最先进的多模态大语言模型在空间可视化任务中仍存在缺陷，填补了该领域的一个重要空白。

> **ai_Abstract:** 本文介绍了SpatialViz-Bench，一个用于评估多模态大语言模型（MLLMs）空间可视化能力的综合基准。该基准包含12个任务和1180个自动生成的问题，旨在解决现有评估的不足。对33个MLLMs的评估揭示了模型在该任务上的显著性能差异，并发现了多项反直觉现象，例如模型对难度的感知与人类直觉不符、2D到3D性能的急剧下降以及思维链提示在开源模型中可能导致性能退化。研究表明，当前MLLMs在空间可视化能力方面仍存在明显不足。

> **摘要翻译:** 人类可以直接在脑海中想象和操作视觉图像，这种能力被称为空间可视化。尽管多模态大语言模型（MLLMs）支持基于想象的推理，但空间可视化能力仍未得到充分评估，通常被嵌入到更广泛的数学和逻辑评估中。现有评估常依赖智商测试或数学竞赛，这可能与训练数据重叠，从而损害评估的可靠性。为此，我们引入了SpatialViz-Bench，一个全面的多模态空间可视化基准，包含12个任务、4个子能力，共1180个自动生成的问题。我们对33个最先进的MLLMs的评估不仅揭示了广泛的性能差异并证明了该基准强大的区分能力，还发现了反直觉的现象：模型显示的难度感知与人类直觉不符，表现出剧烈的2D到3D性能断崖，默认采用公式化推导而非可视化，以及在开源模型中，思维链提示反而导致性能下降。通过对错误类型的统计和定性分析，SpatialViz-Bench表明最先进的MLLMs在空间可视化任务中仍表现出不足，从而解决了该领域的一个显著空白。基准数据和评估代码已公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [353] [Wind Turbine Feature Detection Using Deep Learning and Synthetic Data](https://arxiv.org/abs/2507.21611)
> *风力涡轮机特征检测：基于深度学习与合成数据*

*Arash Shahirpour, Jakob Gebler, Manuel Sanders, Tim Reuscher* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 风力涡轮机, 特征检测, 深度学习, 合成数据, YOLOv11

**Comment:** 8 pages, 5 figures, accepted at ICMV 2025

> **TL;DR:** 本文提出了一种使用合成数据训练深度学习模型来检测风力涡轮机及其关键特征的方法，并在真实图像上取得了良好性能。

**AI_Comments:** 该论文的创新点在于利用合成数据来训练深度学习模型，以解决真实世界图像数据获取和标注的困难及多样性不足的问题。这种方法显著减少了对人工标注的依赖，并能有效模拟各种环境条件，从而提高了模型在复杂真实场景中的鲁棒性。其重要性在于为无人机自主检测等需要大量高质量训练数据的应用提供了一种高效且可扩展的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 风力涡轮机叶片的自主无人机检测需要准确检测涡轮机及其关键特征以确保安全定位和避免碰撞。现有深度学习方法依赖手动标注的真实图像，导致训练数据集在数量和多样性（包括天气条件、光照、涡轮类型和图像复杂性）上受到限制。

**Method:** 本文提出了一种生成合成训练数据的方法，该方法允许控制视觉和环境因素的变化，以增加数据多样性并创建具有挑战性的学习场景。在此基础上，仅使用合成风力涡轮机图像和修改后的损失函数训练了一个YOLOv11特征检测网络，用于检测图像中的风力涡轮机及其关键特征。

**Result:** 训练后的网络在合成图像和真实世界风力涡轮机图像上都进行了评估，并在两者上都显示出有希望的性能。在训练中从未见过的真实图像上，该网络实现了0.97的Pose mAP50-95。

**Conclusion:** 仅使用合成数据训练的深度学习模型能够有效地检测风力涡轮机及其关键特征，并在真实世界数据上表现良好，成功解决了真实数据标注和多样性不足的问题。

> **ai_Abstract:** 本文针对风力涡轮机叶片自主无人机检测中特征检测的挑战，提出了一种创新方法。该方法通过生成多样化的合成训练数据来克服真实世界图像标注和多样性不足的问题，并在此基础上训练了一个YOLOv11深度学习网络。实验结果表明，该网络仅依靠合成数据训练，却能在真实图像上实现高精度（Pose mAP50-95达到0.97），证明了合成数据在提升模型泛化能力和减少对昂贵真实数据标注依赖方面的潜力。

> **摘要翻译:** 对于风力涡轮机（WT）叶片的自主无人机检测，准确检测风力涡轮机及其关键特征对于无人机安全定位和避免碰撞至关重要。现有的深度学习方法通常依赖手动标注的真实世界图像，这限制了训练数据集在天气条件、光照、涡轮机类型和图像复杂性方面的数量和多样性。在本文中，我们提出了一种生成合成训练数据的方法，该方法允许控制视觉和环境因素的变化，从而增加多样性并创建具有挑战性的学习场景。此外，我们仅使用合成风力涡轮机图像和修改后的损失函数训练了一个YOLOv11特征检测网络，以检测图像中的风力涡轮机及其关键特征。所得网络使用合成图像和一组真实世界风力涡轮机图像进行了评估，并在合成和真实世界数据上都显示出有希望的性能，在训练期间从未见过的真实图像上实现了0.97的Pose mAP50-95。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [357] [Scaling RL to Long Videos](https://arxiv.org/abs/2507.07966)
> *将强化学习扩展到长视频*

*Yukang Chen, Wei Huang, Baifeng Shi, Qinghao Hu, Hanrong Ye, Ligeng Zhu, Zhijian Liu, Pavlo Molchanov, Jan Kautz, Xiaojuan Qi, Sifei Liu, Hongxu Yin, Yao Lu, Song Han* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 长视频推理, 强化学习, 视觉语言模型, 数据集, 训练框架

**Comment:** Code at https://github.com/NVlabs/Long-RL and model at
  https://huggingface.co/Efficient-Large-Model/LongVILA-R1-7B

> **TL;DR:** 本文提出了一个用于将视觉语言模型（VLMs）中的推理扩展到长视频的完整框架，该框架利用强化学习，并引入了大规模数据集、两阶段训练流程和高效的训练基础设施，实现了长视频RL训练的显著性能提升和加速。

**AI_Comments:** 本文的创新点在于提出了一个端到端的长视频强化学习推理框架，通过整合大规模数据集、两阶段训练策略和优化的训练基础设施，有效解决了长视频推理的挑战。MR-SP系统的提出，特别是其序列并行和vLLM-based引擎，为长视频RL训练提供了显著的效率提升，是其核心亮点。该研究对于推动视觉语言模型在实际长视频应用中的落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉语言模型（VLMs）在长视频推理方面面临独特挑战，需要一个能够有效处理长视频的完整框架。

**Method:** 该方法整合了三个关键组件：1) 一个名为LongVideo-Reason的大规模数据集（104K长视频QA对，包含高质量推理标注）；2) 一个两阶段训练流程，通过思维链监督微调（CoT-SFT）和强化学习（RL）扩展VLM；3) 一个名为多模态强化序列并行（MR-SP）的长视频RL训练基础设施，该基础设施结合了序列并行和基于vLLM的引擎，并利用缓存的视频嵌入进行高效的rollout和预填充。

**Result:** LongVILA-R1-7B在VideoMME视频基准测试中取得了65.1%（无字幕）和71.1%（有字幕）的准确率，并持续优于LongVILA-7B。它支持处理多达8,192帧的视频，并可配置FPS设置。MR-SP系统在长视频RL训练中实现了高达2.1倍的加速。该训练系统支持多种模态（视频、文本、音频）、多种模型（VILA和Qwen系列）以及图像和视频生成模型的RL训练，在单个A100节点（8个GPU）上支持长达一小时的视频（例如3,600帧）的RL训练。

**Conclusion:** 本文提出的完整框架，包括新的数据集、两阶段训练流程和优化的基础设施，成功地将强化学习扩展到长视频推理任务，显著提升了视觉语言模型在长视频理解方面的性能和训练效率，并支持更长的视频处理能力。

> **ai_Abstract:** 本文提出了一个将强化学习应用于长视频推理的完整框架。该框架包含三个核心要素：一个大规模的长视频问答数据集LongVideo-Reason；一个结合CoT-SFT和RL的两阶段训练流程，用于扩展VLM；以及一个名为MR-SP的高效训练基础设施，它利用序列并行和缓存视频嵌入加速长视频RL训练。实验证明，该方法显著提升了模型在长视频理解任务上的性能，并实现了高达2.1倍的训练加速，支持处理超长视频帧。

> **摘要翻译:** 我们引入了一个完整堆栈框架，利用强化学习将视觉语言模型（VLMs）中的推理扩展到长视频。我们通过整合三个关键组件来解决长视频推理的独特挑战：(1) 一个大规模数据集LongVideo-Reason，包含104K个高质量推理标注的长视频问答对，涵盖体育、游戏和vlog等不同领域；(2) 一个两阶段训练流程，通过思维链监督微调（CoT-SFT）和强化学习（RL）扩展VLM；(3) 一个用于长视频RL的训练基础设施，名为多模态强化序列并行（MR-SP），它结合了序列并行和专为长视频定制的基于vLLM的引擎，利用缓存的视频嵌入进行高效的rollout和预填充。在我们的实验中，LongVILA-R1-7B在视频基准测试中表现出色，在VideoMME上无字幕和有字幕的情况下分别达到65.1%和71.1%的准确率，并在多个基准测试中持续优于LongVILA-7B。此外，LongVILA-R1-7B支持每视频处理多达8,192帧，并可配置FPS设置。值得注意的是，我们的MR-SP系统在长视频RL训练中实现了高达2.1倍的加速。此外，我们发布了可公开获取的训练系统，支持在各种模态（视频、文本和音频）、各种模型（VILA和Qwen系列）甚至图像和视频生成模型上进行RL训练。在单个A100节点（8个GPU）上，它支持长达一小时的视频（例如3,600帧）的RL训练。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [363] [FlagEvalMM: A Flexible Framework for Comprehensive Multimodal Model Evaluation](https://arxiv.org/abs/2506.09081)
> *FlagEvalMM：一个用于综合多模态模型评估的灵活框架*

*Zheqi He, Yesheng Liu, Jing-shu Zheng, Xuejing Li, Jin-Ge Yao, Bowen Qin, Richeng Xuan, Xi Yang* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-28**

**Keywords:** 多模态模型评估, 灵活框架, 视觉-语言, 效率, 开源

**Comment:** Accepted by ACL 2025 Demo

> **TL;DR:** FlagEvalMM是一个开源评估框架，用于全面评估多模态模型，通过解耦推理和利用加速工具来提高效率。

**AI_Comments:** FlagEvalMM的创新之处在于其灵活的架构，通过解耦推理和评估来优化资源分配，并无缝集成新的任务和模型。其重要性体现在它通过利用先进的推理加速工具显著提高了评估效率，并为多模态模型提供了准确而全面的评估，从而成为推动多模态研究的宝贵工具。

<details>
  <summary>Details</summary>

**Motivation:** 旨在全面评估多模态模型，涵盖广泛的视觉-语言理解和生成任务，如视觉问答、文本到图像/视频生成和图像-文本检索。

**Method:** FlagEvalMM通过独立的评估服务将模型推理与评估解耦，从而实现灵活的资源分配和新任务与模型的无缝集成。此外，它还利用先进的推理加速工具（如vLLM、SGLang）和异步数据加载来显著提高评估效率。

**Result:** 广泛的实验表明，FlagEvalMM能提供关于模型优势和局限性的准确而高效的见解。

**Conclusion:** FlagEvalMM是一个有价值的工具，有助于推动多模态研究的进展。

> **ai_Abstract:** FlagEvalMM是一个开源、灵活的多模态模型评估框架，它通过将推理与评估解耦、利用独立服务和集成高效加速工具（如vLLM、SGLang）来全面评估视觉-语言任务。该框架能够提供准确且高效的模型洞察，支持新任务和模型的集成，并被证明是推动多模态研究的重要工具。

> **摘要翻译:** 我们提出了FlagEvalMM，一个开源评估框架，旨在全面评估多模态模型，涵盖广泛的视觉-语言理解和生成任务，例如视觉问答、文本到图像/视频生成和图像-文本检索。我们通过独立的评估服务将模型推理与评估解耦，从而实现灵活的资源分配和新任务与模型的无缝集成。此外，FlagEvalMM利用先进的推理加速工具（例如vLLM、SGLang）和异步数据加载来显著提高评估效率。广泛的实验表明，FlagEvalMM能提供关于模型优势和局限性的准确而高效的见解，使其成为推动多模态研究的宝贵工具。该框架可在https://github.com/flageval-baai/FlagEvalMM公开访问。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [365] [Tracking Moose using Aerial Object Detection](https://arxiv.org/abs/2507.21256)
> *使用空中目标检测追踪驼鹿*

*Christopher Indris, Raiyan Rahman, Goetz Bramesfeld, Guanghui Wang* | **Category: cs.CV, I.4.8** | **Updated: 2025-07-28**

**Keywords:** 空中目标检测, 小型目标检测, 分块增强, 驼鹿追踪, 无人机部署

**Comment:** 18 pages, 6 figures, 8 tables

> **TL;DR:** 本文通过对数据集应用分块增强，比较了三种目标检测器在空中小型目标检测任务中的性能，发现即使是更快、更简单的模型也能有效追踪驼鹿，支持无人机部署。

**AI_Comments:** 本文的创新点在于提出了使用分块增强来优化小型目标检测，并证明了在资源受限的无人机平台上部署更轻量级模型的潜力，这对野生动物保护领域的实际应用具有重要意义。其局限性可能在于研究仅限于特定动物（驼鹿）和特定检测场景，通用性需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 空中野生动物追踪对保护工作至关重要，但面临挑战：载人飞机成本高、风险大、干扰性强；自主无人机车载AI系统计算能力有限。小型目标检测本身就是一项挑战，因为目标可能只有几个像素宽，且需要计算效率。

**Method:** 本文对数据集应用了分块增强（patching augmentation）。对三种常见但架构不同的目标检测器进行了比较研究，并通过改变分块方法的超参数来评估检测精度。

**Result:** 每个模型在至少一种分块配置下都达到了至少93%的mAP@IoU=0.5。统计分析深入阐述了各种因素的影响。分析还表明，对于这项任务，更快、更简单的模型与需要更多计算能力的模型同样有效，并且在有限的分块尺度下表现良好。

**Conclusion:** 更快、更简单的模型在有限的分块尺度下表现良好，且与更复杂的模型同样有效，这鼓励了无人机部署在空中小型目标检测任务中。

> **ai_Abstract:** 本文针对空中野生动物追踪中小型目标检测的挑战，提出通过分块增强方法研究不同目标检测模型的性能。研究比较了三种不同架构的模型，并发现即使是计算资源需求较低的模型也能达到高精度（至少93% mAP@IoU=0.5），这表明在计算能力有限的无人机上部署这些模型是可行的，从而促进了无人机在野生动物保护领域的应用。

> **摘要翻译:** 空中野生动物追踪对于保护工作至关重要，它依赖于检测飞机下方地面上的小型物体。这带来了技术挑战：载人飞机昂贵、有风险且具有干扰性；自主无人机车载AI系统的计算能力有限。由于感兴趣的物体可能只有几个像素宽，因此小目标检测本身就是一个具有挑战性的计算机视觉子领域，并且还需要考虑计算效率。本文对数据集应用了分块增强，以研究模型在各种设置下的性能。使用这些数据对三种常见但架构不同的目标检测器进行了比较研究，并根据检测精度改变了分块方法的超参数。每个模型在至少一种分块配置下都达到了至少93%的mAP@IoU=0.5。统计分析对各种因素的影响提供了深入的评论。分析还表明，对于这项任务，更快、更简单的模型与需要更多计算能力的模型同样有效，并且在有限的分块尺度下表现良好，这鼓励了无人机部署。数据集和模型将通过https://github.com/chrisindris/Moose提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [366] [Boost Self-Supervised Dataset Distillation via Parameterization, Predefined Augmentation, and Approximation](https://arxiv.org/abs/2507.21455)
> *通过参数化、预定义增强和近似提升自监督数据集蒸馏*

*Sheng-Feng Yu, Jia-Jiun Yao, Wei-Chen Chiu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 数据集蒸馏, 自监督学习, 参数化, 数据增强, 模型泛化

**Comment:** 

> **TL;DR:** 本文提出自监督数据集蒸馏（SSDD）方法，通过引入创新的参数化、预定义增强和轻量级网络近似，有效提取数据集信息，提升蒸馏效率和泛化能力。

**AI_Comments:** 这篇论文在数据集蒸馏领域开辟了自监督学习的新方向，解决了传统数据集蒸馏主要聚焦于监督数据集的局限性。其创新点在于针对自监督学习的特点，引入了参数化、预定义增强和轻量级网络近似等技术，有效提升了蒸馏的效率和模型的泛化能力，特别是跨架构泛化能力，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型数据集对训练深度模型至关重要，但其快速增长导致训练成本高昂。现有数据集蒸馏技术主要针对监督数据集，本文旨在解决自监督数据集的蒸馏问题，以提取丰富信息并增强跨架构泛化能力。

**Method:** 提出了自监督数据集蒸馏（SSDD）方法，并引入了三项关键技术：1）对图像和表示进行创新的低维基参数化；2）利用预定义增强来解决数据增强随机性导致的训练不稳定性；3）使用轻量级网络建模同一图像不同增强视图表示之间的连接，以实现更紧凑的蒸馏对。

**Result:** 在各种数据集上的大量实验验证了该方法在蒸馏效率、跨架构泛化能力和迁移学习性能方面的优越性。

**Conclusion:** 本文提出的自监督数据集蒸馏方法，结合参数化、预定义增强和近似技术，能够有效提取真实数据集的丰富信息，生成具有增强跨架构泛化能力的蒸馏集，并在多个方面表现出优越性。

> **ai_Abstract:** 本文针对训练大型深度模型时数据集规模增长带来的高昂计算成本问题，提出了自监督数据集蒸馏（Self-Supervised Dataset Distillation, SSDD）方法。该方法旨在将图像及其自监督训练的表示蒸馏成紧凑的代表性数据集，以提取丰富信息并增强跨架构泛化能力。为实现这一目标，作者引入了三项关键创新：对图像和表示进行低维基参数化、利用预定义增强处理数据增强的随机性，以及使用轻量级网络建模增强视图间的连接。实验结果表明，该方法在蒸馏效率、跨架构泛化和迁移学习性能上均表现出优越性。

> **摘要翻译:** 尽管更大的数据集对于训练大型深度模型至关重要，但数据集规模的快速增长带来了巨大的挑战，即高昂的训练成本，甚至导致令人望而却步的计算开销。数据集蒸馏最近成为一种流行的技术，通过学习一组高度紧凑的代表性样本来减小数据集大小，理想情况下，使用这些样本训练的模型应与使用完整数据集训练的模型具有可比的性能。虽然现有的大多数数据集蒸馏工作都集中在监督数据集上，但我们旨在将图像及其自监督训练的表示蒸馏到蒸馏集中。这一过程被称为自监督数据集蒸馏，它有效地从真实数据集中提取丰富信息，生成具有增强跨架构泛化能力的蒸馏集。特别是，为了更忠实和紧凑地保留原始数据集的关键特性，提出了几种新颖技术：1）我们通过不同的低维基对图像和表示引入了创新的参数化，其中实验表明参数化的基选择起着关键作用；2）我们通过利用预定义增强来解决数据增强随机性引起的不稳定性——这是自监督学习中的一个关键组成部分，但在之前的自监督数据集蒸馏工作中被低估了；3）我们进一步利用轻量级网络来建模同一图像不同增强视图表示之间的连接，从而产生更紧凑的蒸馏对。在各种数据集上进行的大量实验验证了我们方法在蒸馏效率、跨架构泛化和迁移学习性能方面的优越性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [369] [StepAL: Step-aware Active Learning for Cataract Surgical Videos](https://arxiv.org/abs/2507.22059)
> *StepAL：用于白内障手术视频的步长感知主动学习*

*Nisarg A. Shah, Bardia Safaei, Shameema Sikder, S. Swaroop Vedula, Vishal M. Patel* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 主动学习, 手术视频分析, 步骤识别, 白内障手术, 标注成本

**Comment:** Accepted to MICCAI 2025

> **TL;DR:** StepAL是一种用于白内障手术视频的主动学习方法，通过选择完整视频进行标注，在减少标注量的同时提高了手术步骤识别的准确性。

**AI_Comments:** StepAL的创新之处在于其针对长手术视频的特性，提出了“步长感知”的特征表示和“全视频选择”策略，这与传统主动学习方法仅选择帧或短片段不同。这种方法更符合手术视频的上下文需求，对于减少医疗领域视频分析中昂贵且耗时的标注成本具有重要意义，有望推动计算机辅助手术系统的发展。

<details>
  <summary>Details</summary>

**Motivation:** 传统主动学习方法针对图像或短视频片段设计，不适用于长、未剪辑的手术视频中的手术步骤识别，因为手术步骤之间存在依赖性，且标注者需要整个视频的上下文进行标注，导致效率低下。

**Method:** StepAL是一个用于手术步骤识别中全视频选择的主动学习框架。它结合了步长感知特征表示（利用伪标签捕获每个视频中预测步骤的分布）和熵加权聚类策略。这种组合优先选择既不确定又展现多样步骤组成的视频进行标注。

**Result:** 在两个白内障手术数据集（Cataract-1k和Cataract-101）上的实验表明，StepAL持续优于现有主动学习方法，在标注视频更少的情况下，实现了更高的步骤识别准确性。

**Conclusion:** StepAL为高效的手术视频分析提供了一种有效方法，减轻了开发计算机辅助手术系统中的标注负担。

> **ai_Abstract:** StepAL是一种针对白内障手术视频的主动学习框架，旨在解决传统方法在长手术视频中识别手术步骤的低效问题。它通过结合步长感知特征表示和熵加权聚类策略来选择整个视频进行标注，优先选择不确定且步骤组成多样的视频。实验证明，StepAL在减少标注量的同时，提高了手术步骤识别的准确性，为高效手术视频分析提供了有效途径。

> **摘要翻译:** 主动学习（AL）可以在保持模型性能的同时，降低手术视频分析中的标注成本。然而，传统的AL方法是为图像或短视频片段开发的，对于长、未剪辑手术视频中的手术步骤识别来说是次优的，因为手术步骤之间存在内部依赖性。这些方法通常选择单个帧或片段进行标注，这对于标注者需要整个视频上下文才能进行标注的手术视频来说是无效的。为了解决这个问题，我们提出了StepAL，一个专为手术步骤识别中全视频选择而设计的主动学习框架。StepAL整合了步长感知特征表示（利用伪标签捕获每个视频中预测步骤的分布）和熵加权聚类策略。这种组合优先选择既不确定又展现多样步骤组成的视频进行标注。在两个白内障手术数据集（Cataract-1k和Cataract-101）上的实验表明，StepAL持续优于现有主动学习方法，在标注视频更少的情况下，实现了更高的步骤识别准确性。StepAL为高效的手术视频分析提供了一种有效方法，减轻了开发计算机辅助手术系统中的标注负担。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [371] [The Importance of Facial Features in Vision-based Sign Language Recognition: Eyes, Mouth or Full Face?](https://arxiv.org/abs/2507.20884)
> *视觉手语识别中面部特征的重要性：眼睛、嘴巴还是全脸？*

*Dinh Nam Pham, Eleftherios Avramidis* | **Category: cs.CV, cs.CL, eess.IV** | **Updated: 2025-07-29**

**Keywords:** 自动手语识别, 面部特征, 深度学习, 嘴巴, 非手动特征

**Comment:** Accepted at 9th International Workshop on Sign Language Translation
  and Avatar Technologies @ ACM IVA'25

> **TL;DR:** 本文系统研究了眼睛、嘴巴和全脸等不同面部区域在自动手语识别中的贡献，发现嘴巴是最重要的非手动面部特征，能显著提高准确性。

**AI_Comments:** 本文的创新之处在于系统性地比较了不同面部区域（眼睛、嘴巴、全脸）在手语识别中的具体贡献，并使用了两种主流的深度学习模型进行验证，而非仅仅停留在手动与非手动特征的二元比较。研究结果为未来自动手语识别系统的设计提供了重要的指导，特别是强调了嘴巴区域的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管非手动面部特征在手语交流中至关重要，但其在自动手语识别（ASLR）中的重要性仍未被充分探索。现有研究多依赖手工特征提取，且未能深入比较不同面部区域的贡献。

**Method:** 本文使用两种深度学习模型（基于CNN的模型和基于Transformer的模型），在包含随机选择类别的孤立手语数据集上，系统研究了眼睛、嘴巴和全脸等不同面部区域的贡献。通过定量性能评估和定性显著图评估进行分析。

**Result:** 研究发现，嘴巴是最重要的非手动面部特征，能显著提高手语识别的准确性。

**Conclusion:** 我们的研究结果强调了在自动手语识别中整合面部特征的必要性。

> **ai_Abstract:** 本文系统探讨了眼睛、嘴巴和全脸等不同面部区域在视觉自动手语识别（ASLR）中的具体贡献。研究利用CNN和Transformer两种深度学习模型，在一个孤立手语数据集上进行了定量和定性评估。结果表明，嘴巴是非手动面部特征中最重要的部分，能显著提升ASLR的准确性，强调了面部特征在ASLR中的关键作用。

> **摘要翻译:** 非手动面部特征在手语交流中扮演着关键角色，然而它们在自动手语识别（ASLR）中的重要性仍未被充分探索。尽管先前的研究表明，结合面部特征可以提高识别率，但相关工作往往依赖于手工特征提取，并且未能超越手动特征与手动和面部特征组合的比较。在这项工作中，我们系统地研究了不同面部区域——眼睛、嘴巴和全脸——的贡献，使用了两种不同的深度学习模型（一个基于CNN的模型和一个基于Transformer的模型），这些模型在一个包含随机选择类别的孤立手语数据集上进行训练。通过定量性能和定性显著图评估，我们揭示了嘴巴是最重要的非手动面部特征，显著提高了准确性。我们的研究结果强调了在ASLR中整合面部特征的必要性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [377] [Enhancing Glass Defect Detection with Diffusion Models: Addressing Imbalanced Datasets in Manufacturing Quality Control](https://arxiv.org/abs/2505.03134)
> *使用扩散模型增强玻璃缺陷检测：解决制造质量控制中的不平衡数据集问题*

*Sajjad Rezvani Boroujeni, Hossein Abedi, Tom Bush* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 扩散模型, 缺陷检测, 数据不平衡, 数据增强, 质量控制

**Comment:** 12 pages, 7 figures, published in Computer and Decision Making - An
  International Journal (COMDEM)

> **TL;DR:** 本文提出使用去噪扩散概率模型（DDPMs）生成合成图像来解决工业玻璃缺陷检测中数据集不平衡问题，显著提高了缺陷检测的性能。

**AI_Comments:** 本文的创新点在于利用扩散模型（DDPMs）来解决工业界常见的类别不平衡问题，这为数据稀缺或不平衡场景下的深度学习应用提供了新的思路。该方法不仅在玻璃缺陷检测中取得了显著效果，其通用性也预示着在其他工业质量控制领域的广阔应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 工业玻璃制造中的视觉缺陷检测面临挑战，因为缺陷产品频率低导致数据集不平衡，这限制了深度学习模型和计算机视觉系统的性能。

**Method:** 本文采用去噪扩散概率模型（DDPMs）生成合成的缺陷玻璃产品图像进行数据增强，以有效解决制造质量控制和自动化视觉检测中的类别不平衡问题。该方法通过增加少数类别的表示来显著提高标准CNN架构（ResNet50V2、EfficientNetB0和MobileNetV2）的图像分类性能。

**Result:** 实验结果表明，所有测试的深度神经网络架构在缺陷样本的召回率方面都有显著提高，同时在验证集上保持了完美的精确度。其中，ResNet50V2的整体分类准确率在经过增强数据训练后从78%提高到93%。

**Conclusion:** 这项工作提供了一种可扩展、经济高效的方法来增强玻璃制造中的自动化缺陷检测，并有可能扩展到其他具有类似类别不平衡挑战的工业质量保证系统和行业。

> **ai_Abstract:** 该研究针对工业玻璃制造中因缺陷产品稀少导致的数据集不平衡问题，提出了一种基于去噪扩散概率模型（DDPMs）的数据增强新方法。通过生成合成缺陷图像，该方法有效解决了类别不平衡，显著提升了包括ResNet50V2在内的多种CNN架构的缺陷检测性能，尤其是在召回率和整体分类准确率方面，为自动化质量控制提供了一种可扩展且经济高效的解决方案。

> **摘要翻译:** 工业玻璃制造中的视觉缺陷检测仍然是一个关键挑战，因为缺陷产品频率低，导致数据集不平衡，这限制了深度学习模型和计算机视觉系统的性能。本文提出了一种新颖的方法，使用去噪扩散概率模型（DDPMs）生成合成的缺陷玻璃产品图像进行数据增强，有效解决了制造质量控制和自动化视觉检测中的类别不平衡问题。该方法通过增加少数类别的表示，显著提高了标准CNN架构（ResNet50V2、EfficientNetB0和MobileNetV2）在检测异常方面的图像分类性能。实验结果表明，在所有测试的深度神经网络架构中，关键机器学习指标，特别是缺陷样本的召回率，均有显著改善，同时在验证集上保持了完美的精确度。最显著的改进体现在ResNet50V2的整体分类准确率上，其在使用增强数据训练后从78%提高到93%。这项工作提供了一种可扩展、经济高效的方法来增强玻璃制造中的自动化缺陷检测，并有可能扩展到其他具有类似类别不平衡挑战的工业质量保证系统和行业。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [387] [Unleashing the Power of Motion and Depth: A Selective Fusion Strategy for RGB-D Video Salient Object Detection](https://arxiv.org/abs/2507.21857)
> *释放运动和深度的力量：一种用于RGB-D视频显著目标检测的选择性融合策略*

*Jiahao He, Daerji Suolang, Keren Fu, Qijun Zhao* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** RGB-D VSOD, 显著目标检测, 跨模态融合, 光流, 深度信息

**Comment:** submitted to TMM on 11-Jun-2024, ID: MM-020522, still in peer review

> **TL;DR:** 本文提出SMFNet，通过像素级选择性融合和多维度选择性注意力模块，有效结合光流和深度信息，显著提升RGB-D视频显著目标检测性能。

**AI_Comments:** 本文通过引入选择性融合策略，创新性地解决了RGB-D VSOD中运动和深度信息贡献不均的问题，这对于充分利用多模态数据至关重要。其提出的SMFNet框架及其组件（PSF和MSAM）展现了有效整合不同模态信息的能力。提供代码和基准测试结果也增加了其研究价值和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的RGB-D视频显著目标检测（RGB-D VSOD）模型未能有效利用光流和深度信息，常将它们同等对待，而未考虑其在不同场景下贡献的不相等性，这限制了运动和深度信息的潜力。

**Method:** 本文提出了一种新颖的选择性跨模态融合框架（SMFNet）用于RGB-D VSOD。该框架包含：1. 像素级选择性融合策略（PSF），根据光流和深度的实际贡献实现最佳融合。2. 多维度选择性注意力模块（MSAM），将PSF融合的特征与RGB模态在多个维度上进行整合，以有效增强特征表示。

**Result:** SMFNet在RDVS和DVisal数据集上对19个最先进模型进行了全面评估，结果表明SMFNet优于其他模型。同时，在五个包含合成深度的视频基准数据集上的评估也验证了SMFNet的有效性。

**Conclusion:** 本文提出的SMFNet通过创新的选择性融合策略，有效解决了RGB-D VSOD中运动和深度信息利用不足的问题，显著提升了检测性能，并建立了更全面的基准。

> **ai_Abstract:** 本文针对RGB-D视频显著目标检测（RGB-D VSOD）中运动和深度信息利用不足的问题，提出了一种新颖的选择性跨模态融合框架SMFNet。该框架包含像素级选择性融合策略（PSF）以优化光流和深度的融合，以及多维度选择性注意力模块（MSAM）以增强融合特征与RGB模态的整合。实验证明SMFNet在多个基准数据集上优于现有SOTA模型，并提供了迄今为止最全面的RGB-D VSOD基准。

> **摘要翻译:** 将显著目标检测（SOD）应用于RGB-D视频是一项新兴任务，称为RGB-D VSOD，由于结合运动和深度信息带来了显著的性能提升，并且RGB-D视频现在在日常生活中可以轻松捕获，因此最近引起了越来越多的关注。现有的RGB-D VSOD模型在获取运动线索方面有不同的尝试，其中从光流中明确提取运动信息似乎是一种更有效和有前途的替代方案。尽管如此，仍然存在一个关键问题是如何有效地利用光流和深度来辅助RGB模态进行SOD。以前的方法在模型设计上总是平等对待光流和深度，没有明确考虑它们在不同场景下的不相等贡献，从而限制了运动和深度的潜力。为了解决这个问题并释放运动和深度的力量，我们提出了一种新颖的用于RGB-D VSOD的选择性跨模态融合框架（SMFNet），其中包含一种像素级选择性融合策略（PSF），该策略根据光流和深度的实际贡献实现了最佳融合。此外，我们提出了一种多维度选择性注意力模块（MSAM），以将PSF派生的融合特征与剩余的RGB模态在多个维度上进行整合，有效增强特征表示以生成精炼的特征。我们对SMFNet在RDVS和DVisal数据集上与19个最先进的模型进行了全面评估，使这次评估成为迄今为止最全面的RGB-D VSOD基准，它也证明了SMFNet优于其他模型。同时，在五个包含合成深度的视频基准数据集上的评估也验证了SMFNet的功效。我们的代码和基准测试结果已在https://github.com/Jia-hao999/SMFNet 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [394] [MOVE: Motion-Guided Few-Shot Video Object Segmentation](https://arxiv.org/abs/2507.22061)
> *MOVE：运动引导的少样本视频目标分割*

*Kaining Ying, Hengrui Hu, Henghui Ding* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 运动引导, 少样本学习, 视频目标分割, 数据集, DMA网络

**Comment:** ICCV 2025, Project Page: https://henghuiding.com/MOVE/

> **TL;DR:** 本文介绍了MOVE数据集，用于运动引导的少样本视频目标分割，并提出DMA基线方法，解决了现有方法在处理视频动态性方面的不足，并取得了更好的性能。

**AI_Comments:** 这篇论文通过引入专门的MOVE数据集和提出DMA方法，有效地填补了运动引导少样本视频目标分割领域的空白。其创新点在于强调了视频中运动模式的重要性，而非仅仅关注静态对象类别。对现有方法的全面评估揭示了当前技术的局限性，而DMA的提出则为未来的研究提供了强有力的基线，对推动该领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的少样本视频目标分割（FSVOS）数据集和方法主要关注静态对象类别，忽略了视频中丰富的时序动态性，限制了它们在需要运动理解的场景中的应用。为了填补这一空白，本文旨在解决运动引导的少样本视频目标分割问题。

**Method:** 引入了大规模的运动引导少样本视频目标分割数据集MOVE。基于MOVE数据集，全面评估了来自3个不同相关任务的6种最先进方法，并在2种实验设置下进行。针对现有方法表现不佳的问题，提出了一个基线方法：解耦运动外观网络（DMA）。

**Result:** 实验结果表明，当前方法难以解决运动引导的少样本视频目标分割问题。提出的DMA方法在少样本运动理解方面取得了卓越的性能。

**Conclusion:** 本文提出的DMA方法在少样本运动理解方面表现出色，为未来在该方向的研究奠定了坚实的基础。

> **ai_Abstract:** 本文针对运动引导的少样本视频目标分割（FSVOS）问题，指出现有方法忽视视频时序动态性的局限。为解决此问题，作者引入了大规模数据集MOVE，并评估了现有SOTA方法，发现它们表现不佳。为此，提出了一种新的基线方法——解耦运动外观网络（DMA），实验证明其在少样本运动理解上表现优越，为该领域未来研究奠定基础。

> **摘要翻译:** 这项工作旨在解决运动引导的少样本视频目标分割（FSVOS）问题，其目标是根据少量带有相同运动模式的标注示例来分割视频中的动态目标。现有的FSVOS数据集和方法通常侧重于对象类别，这些是静态属性，忽略了视频中丰富的时序动态性，限制了它们在需要运动理解的场景中的应用。为了填补这一空白，我们引入了MOVE，一个专门为运动引导FSVOS设计的大规模数据集。基于MOVE，我们全面评估了来自3个不同相关任务的6种最先进方法，并在2种实验设置下进行。我们的结果表明，当前方法难以解决运动引导的FSVOS问题，这促使我们分析相关挑战并提出一个基线方法，即解耦运动外观网络（DMA）。实验证明，我们的方法在少样本运动理解方面取得了卓越的性能，为未来在该方向的研究奠定了坚实的基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [395] [Fine-Grained Perturbation Guidance via Attention Head Selection](https://arxiv.org/abs/2506.10978)
> *细粒度扰动引导通过注意力头选择*

*Donghoon Ahn, Jiwon Kang, Sanghyun Lee, Minjae Kim, Jaewon Min, Wooseok Jang, Sangwu Lee, Sayak Paul, Susung Hong, Seungryong Kim* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 扩散模型, 注意力扰动, 细粒度控制, HeadHunter, SoftPAG

**Comment:** Project page: https://cvlab-kaist.github.io/HeadHunter/

> **TL;DR:** 本文提出了“HeadHunter”框架和“SoftPAG”方法，通过选择性地扰动扩散模型中的特定注意力头，实现对生成图像质量和视觉属性的细粒度控制，解决了现有注意力扰动方法缺乏精确应用位置的问题。

**AI_Comments:** 这项工作在扩散模型引导领域具有重要创新性。通过首次深入分析注意力头的专业化并提出头部层面的扰动策略，解决了现有方法在DiT架构中缺乏精确定位的问题。其提出的HeadHunter框架和SoftPAG方法为用户提供了前所未有的细粒度控制能力，有望显著提升生成图像的质量和可控性。这项研究不仅具有理论分析价值（揭示注意力层内可解释性），也提供了实用的工程解决方案，对未来扩散模型的设计和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扩散模型注意力扰动方法在确定扰动应施加的位置时缺乏原则性方法，特别是在Diffusion Transformer (DiT) 架构中，质量相关的计算分布在不同层级，导致难以进行细粒度控制。

**Method:** 本文首先研究了注意力扰动的粒度，发现特定的注意力头控制着不同的视觉概念。在此基础上，提出了“HeadHunter”框架，用于迭代选择与用户目标对齐的注意力头，实现细粒度控制。此外，还引入了SoftPAG，通过将所选注意力头的注意力图线性插值到单位矩阵，提供连续的扰动强度调节和伪影抑制。

**Result:** 该方法不仅缓解了现有层级扰动导致的过平滑问题，还通过组合式头部选择实现了对特定视觉风格的定向操作。在Stable Diffusion 3和FLUX.1等DiT文本到图像模型上的验证表明，该方法在通用质量提升和特定风格引导方面均表现出卓越性能。

**Conclusion:** 本文首次对扩散模型中的注意力扰动进行了头部层面的分析，揭示了注意力层内可解释的专业化，并为有效扰动策略的实际设计提供了可能。

> **ai_Abstract:** 本文针对扩散模型中注意力扰动缺乏细粒度控制的问题，深入研究了注意力头的特性，发现不同注意力头控制特定视觉概念。基于此，提出了“HeadHunter”框架，通过迭代选择注意力头实现对生成质量和视觉属性的精细控制。同时引入SoftPAG以调节扰动强度和抑制伪影。实验证明，该方法在提升图像质量和实现风格引导方面优于现有方法，并首次提供了扩散模型中注意力扰动的头部级分析。

> **摘要翻译:** 标题：细粒度扰动引导通过注意力头选择

摘要：扩散模型中近期的引导方法通过扰动模型来构建一个隐式的弱模型，并引导生成远离它，从而指导逆向采样。在这些方法中，注意力扰动在分类器无关引导不适用的无条件场景中表现出强大的经验性能。然而，现有的注意力扰动方法缺乏确定扰动应施加位置的原则性方法，尤其是在质量相关计算分布在各层的Diffusion Transformer (DiT) 架构中。在本文中，我们研究了注意力扰动的粒度，从层级到单个注意力头，并发现特定的头部控制着不同的视觉概念，如结构、风格和纹理质量。基于这一洞察，我们提出了“HeadHunter”，一个系统框架，用于迭代选择与用户中心目标对齐的注意力头，从而实现对生成质量和视觉属性的细粒度控制。此外，我们引入了SoftPAG，它将每个选定头部的注意力图线性插值到单位矩阵，提供了一个连续的旋钮来调整扰动强度和抑制伪影。我们的方法不仅缓解了现有层级扰动导致的过平滑问题，而且通过组合式头部选择实现了对特定视觉风格的定向操作。我们在现代大型DiT文本到图像模型（包括Stable Diffusion 3和FLUX.1）上验证了我们的方法，在通用质量增强和特定风格引导方面均表现出卓越性能。我们的工作首次对扩散模型中的注意力扰动进行了头部层面的分析，揭示了注意力层内可解释的专业化，并为有效扰动策略的实际设计提供了可能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [398] [EMIT: Enhancing MLLMs for Industrial Anomaly Detection via Difficulty-Aware GRPO](https://arxiv.org/abs/2507.21619)
> *EMIT：通过难度感知GRPO增强MLLM用于工业异常检测*

*Wei Guan, Jun Lan, Jian Cao, Hao Tan, Huijia Zhu, Weiqiang Wang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 工业异常检测, 多模态大语言模型, 难度感知GRPO, 少样本学习, 数据增强

**Comment:** 

> **TL;DR:** EMIT框架通过难度感知GRPO和数据增强技术显著提升多模态大语言模型在工业异常检测中的性能。

**AI_Comments:** 本文的创新点在于提出了EMIT框架，特别是在数据稀缺和处理困难样本方面的策略。利用GPT生成文本描述来弥补图像数据缺失是应对少样本问题的一种新颖方法。难度感知GRPO通过重采样和重加权机制，有效提升了模型从复杂数据中学习的能力，这对于实际工业应用中常见的小缺陷和模糊异常检测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 工业异常检测（IAD）对制造系统的安全和可靠性至关重要。尽管多模态大语言模型（MLLMs）展现出强大的视觉-语言推理能力，但它们在没有特定领域适应的情况下，在IAD中的有效性仍然有限。

**Method:** 本文提出了EMIT，一个统一的框架，通过难度感知组相对策略优化（GRPO）来增强MLLMs用于工业异常检测（IAD）。EMIT构建了一个多任务IAD数据集，并利用GPT生成的对象文本描述来弥补缺失的缺陷图像。对于少样本异常检测，它整合了软提示和热图引导的对比嵌入。为更好地处理困难数据样本，EMIT引入了难度感知GRPO，通过响应重采样策略确保采样响应中包含正确答案，并采用优势重加权机制加强从这些困难样本中学习。

**Result:** 在MMAD基准测试上的大量实验表明，EMIT显著增强了MLLMs的IAD性能，在七个任务中比基础模型（InternVL3-8B）平均提高了7.77%。

**Conclusion:** EMIT框架及其提出的难度感知GRPO和数据增强策略，能够有效提升多模态大语言模型在工业异常检测领域的性能，尤其是在处理困难样本和少样本场景时。

> **ai_Abstract:** 本文提出了EMIT框架，旨在通过难度感知组相对策略优化（GRPO）来提升多模态大语言模型（MLLMs）在工业异常检测（IAD）中的应用。EMIT通过构建多任务数据集、利用GPT生成描述弥补数据缺失、整合软提示和热图引导对比嵌入处理少样本问题，并引入难度感知GRPO来有效学习困难样本。实验证明，EMIT显著提高了MLLMs在IAD任务上的表现。

> **摘要翻译:** 工业异常检测 (IAD) 在维护制造系统的安全性和可靠性方面发挥着至关重要的作用。尽管多模态大语言模型 (MLLMs) 展现出强大的视觉-语言推理能力，但它们在没有领域特定适应的情况下，在 IAD 中的有效性仍然有限。在这项工作中，我们提出了 EMIT，一个统一的框架，通过难度感知组相对策略优化 (GRPO) 来增强 MLLMs 用于 IAD。EMIT 构建了一个多任务 IAD 数据集，并利用 GPT 生成的对象文本描述来弥补缺失的缺陷图像。对于少样本异常检测，它集成了软提示和热图引导对比嵌入（源自补丁级比较）。为了更好地处理困难数据样本，即 MLLM 难以生成正确答案的情况，我们提出了一个难度感知 GRPO，它通过结合响应重采样策略（以确保采样响应中包含正确答案）以及优势重加权机制（以加强从这些困难数据样本中学习）来扩展了原始 GRPO。在 MMAD 基准测试上的大量实验表明，EMIT 显著增强了 MLLMs 的 IAD 性能，在七个任务中比基础模型 (InternVL3-8B) 平均提高了 7.77%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [407] [UncertainSAM: Fast and Efficient Uncertainty Quantification of the Segment Anything Model](https://arxiv.org/abs/2505.05049)
> *UncertainSAM：快速高效的Segment Anything模型不确定性量化*

*Timo Kaiser, Thomas Norrenbrock, Bodo Rosenhahn* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** Segment Anything Model, 不确定性量化, 贝叶斯熵, USAM, 语义分割

**Comment:** Accepted to ICML'25

> **TL;DR:** UncertainSAM (USAM) 提出了一种快速高效的不确定性量化方法，专门用于解决Segment Anything Model (SAM) 在不确定性量化方面的挑战。

**AI_Comments:** 该论文的创新点在于提出了一个理论驱动的贝叶斯熵公式来量化SAM的不确定性，并引入了“任务不确定性”的概念。其开发的USAM模型不仅轻量高效，还能识别不确定性来源，这对于理解和改进模型行为至关重要。该方法为SAM在实际应用中的可靠性提供了关键支持，尤其是在需要高置信度的场景中。

<details>
  <summary>Details</summary>

**Motivation:** Segment Anything Model (SAM) 在语义分割领域应用广泛，但其类无关的特性使得现有的不确定性量化（UQ）方法难以有效应用。因此，需要一种新的、有效的方法来量化SAM的分割结果的不确定性，以满足多种任务的需求。

**Method:** 本文提出了一种基于贝叶斯熵公式的不确定性量化模型，该模型综合考虑了偶然不确定性、认知不确定性以及新引入的任务不确定性。基于此公式，研究人员训练了一个名为USAM的轻量级后处理不确定性量化方法。USAM模型能够追溯不确定性的根源，例如模型欠参数化、提示信息不足或图像模糊性。

**Result:** 所提出的确定性USAM在SA-V、MOSE、ADE20k、DAVIS和COCO等多个数据集上展现出卓越的预测能力。它提供了一种计算成本低廉且易于使用的不确定性量化替代方案，能够支持用户提示、增强半监督流程，并有助于平衡准确性与成本效率之间的权衡。

**Conclusion:** UncertainSAM提供了一种快速高效且易于使用的不确定性量化方法，有效解决了Segment Anything模型在不确定性量化方面的挑战，从而为SAM在各种实际应用中提供了更可靠的支持。

> **ai_Abstract:** 本文提出了UncertainSAM (USAM)，一种针对Segment Anything Model (SAM) 的快速高效不确定性量化 (UQ) 方法。鉴于SAM的类无关特性对现有UQ方法构成挑战，USAM基于贝叶斯熵公式，整合了偶然、认知和任务不确定性，并能识别不确定性来源。该轻量级后处理模型在多个数据集上表现出优越的预测能力，并提供了计算成本低廉且易于使用的UQ解决方案，适用于用户提示、半监督学习及精度与效率的权衡。

> **摘要翻译:** Segment Anything Model (SAM) 的引入为众多语义分割应用铺平了道路。对于一些任务，量化 SAM 的不确定性尤其重要。然而，类无关基础模型 SAM 的模糊性挑战了当前的不确定性量化 (UQ) 方法。本文提出了一种理论驱动的不确定性量化模型，该模型基于贝叶斯熵公式，并同时考虑了偶然不确定性、认知不确定性以及新引入的任务不确定性。我们利用此公式训练了 USAM，这是一种轻量级的后处理 UQ 方法。我们的模型将不确定性的根源追溯到欠参数化模型、不充分的提示或图像模糊性。我们提出的确定性 USAM 在 SA-V、MOSE、ADE20k、DAVIS 和 COCO 数据集上展示了卓越的预测能力，提供了一种计算成本低廉且易于使用的 UQ 替代方案，可支持用户提示、增强半监督管道或平衡准确性与成本效率之间的权衡。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [415] [An Angular-Temporal Interaction Network for Light Field Object Tracking in Low-Light Scenes](https://arxiv.org/abs/2507.21460)
> *用于弱光场景下光场目标跟踪的角-时间交互网络*

*Mianzhao Wang, Fan Shi, Xu Cheng, Feifei Zhang, Shengyong Chen* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 光场跟踪, 弱光场景, 角-时间交互, ESI, ATINet

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的光场极平面结构图像（ESI）表示和角-时间交互网络（ATINet），用于在弱光场景下进行光场目标跟踪，并取得了SOTA性能。

**AI_Comments:** 本文的创新点在于提出了光场极平面结构图像（ESI）这一新颖表示，有效处理了弱光场景下的光场冗余和视觉增强问题。同时，设计的角-时间交互网络（ATINet）能够深度学习光场的角度和时间交互特性，并通过自监督学习进一步提升性能，为复杂光场环境下的目标跟踪提供了新的SOTA解决方案。此外，引入大规模弱光光场数据集也对该领域的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的光场表示在时间域内，尤其是在复杂的弱光场景中，难以提供可靠的角度建模，这使得识别移动目标面临挑战。

**Method:** 本文提出了一种新颖的光场极平面结构图像（ESI）表示，它明确定义了光场内的几何结构，并通过利用光线角度的突然变化来增强弱光场景下的视觉表达并减少冗余。在此基础上，进一步提出了一个角-时间交互网络（ATINet），用于学习光场的几何结构线索和角-时间交互线索中的角度感知表示。ATINet还可以通过自监督方式进行优化，以增强跨时间域的几何特征交互。此外，还引入了一个大规模的光场弱光目标跟踪数据集。

**Result:** 广泛的实验表明，ATINet在单目标跟踪中达到了最先进的性能。将所提出的方法扩展到多目标跟踪也显示了高质量光场角-时间建模的有效性。

**Conclusion:** 本文提出的ESI表示和ATINet网络能够有效解决弱光场景下光场目标跟踪的挑战，通过捕捉独特的空间-角度线索和角-时间交互，实现了优异的跟踪性能。

> **ai_Abstract:** 本文针对弱光场景下光场目标跟踪中角度建模的挑战，提出了一种新颖的光场极平面结构图像（ESI）表示，以捕捉光场几何结构并增强视觉表达。在此基础上，设计了一个角-时间交互网络（ATINet），通过学习角度感知表示和自监督优化，实现了对目标的高效跟踪。研究还构建了一个大规模弱光光场数据集，并在单目标和多目标跟踪任务上验证了ATINet的先进性能。

> **摘要翻译:** 高质量的4D光场表示与高效的角度特征建模对于场景感知至关重要，因为它可以提供区分性的空间-角度线索来识别移动目标。然而，最近的发展仍然难以在时间域内提供可靠的角度建模，特别是在复杂的弱光场景中。在本文中，我们提出了一种新颖的光场极平面结构图像（ESI）表示，它明确定义了光场内的几何结构。通过利用极平面内光线角度的突然变化，这种表示可以增强弱光场景中的视觉表达并减少高维光场中的冗余。我们进一步提出了一种用于光场目标跟踪的角-时间交互网络（ATINet），该网络从光场的几何结构线索和角-时间交互线索中学习角度感知表示。此外，ATINet还可以通过自监督方式进行优化，以增强跨时间域的几何特征交互。最后，我们引入了一个用于目标跟踪的大规模光场弱光数据集。广泛的实验表明，ATINet在单目标跟踪中取得了最先进的性能。此外，我们将所提出的方法扩展到多目标跟踪，这也显示了高质量光场角-时间建模的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [418] [MetaCLIP 2: A Worldwide Scaling Recipe](https://arxiv.org/abs/2507.22062)
> *MetaCLIP 2: 全球化扩展方案*

*Yung-Sung Chuang, Yang Li, Dong Wang, Ching-Feng Yeh, Kehan Lyu, Ramya Raghavendra, James Glass, Lifei Huang, Jason Weston, Luke Zettlemoyer, Xinlei Chen, Zhuang Liu, Saining Xie, Wen-tau Yih, Shang-Wen Li, Hu Xu* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-29**

**Keywords:** CLIP, 多语言, 全球化扩展, 图像-文本预训练, MetaCLIP 2

**Comment:** 10 pages

> **TL;DR:** MetaCLIP 2 提出了一种新的方法，首次从头开始在全球范围的网络图像-文本对上训练 CLIP 模型，解决了多语言数据处理和“多语言诅咒”的挑战，并在英语和多语言基准测试中取得了最先进的性能。

**AI_Comments:** MetaCLIP 2 的创新之处在于它首次提供了一个在全球网络数据上从零开始训练 CLIP 的完整“食谱”，解决了多语言环境下数据整理和性能下降的核心问题。其重要性体现在它为构建更具普适性和鲁棒性的多语言多模态基础模型奠定了基础，克服了“多语言诅咒”，并为未来的研究提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 现有的对比语言-图像预训练（CLIP）模型虽然在英语世界取得了成功，但将其训练扩展到全球范围的网络数据面临挑战：一是缺乏处理非英语数据的整理方法；二是现有多语言 CLIP 模型的英语性能不如其纯英语对应模型，即存在大型语言模型中常见的“多语言诅咒”。

**Method:** 本文提出了 MetaCLIP 2，这是第一个从头开始在全球范围的网络尺度图像-文本对上训练 CLIP 的方案。为了验证其发现的普适性，研究人员进行了严格的消融实验，并只进行了解决上述挑战所必需的最小改动，从而形成了一个能使英语和非英语世界数据相互受益的训练方案。

**Result:** 在零样本 ImageNet 分类任务中，MetaCLIP 2 ViT-H/14 的性能比其纯英语对应模型高出 0.8%，比 mSigLIP 高出 0.7%。此外，在多语言基准测试中，MetaCLIP 2 在没有引入系统级混杂因素（如翻译、定制架构更改）的情况下，创造了新的最先进结果，例如在 CVQA 上达到 57.4%，在 Babel-ImageNet 上达到 50.2%，在 XM3600 图像到文本检索上达到 64.3%。

**Conclusion:** MetaCLIP 2 成功地解决了在全球范围内扩展 CLIP 训练的挑战，首次实现了从头开始对全球网络数据进行训练，并在英语和多语言任务上均取得了优于现有模型的性能，证明了其训练方案的有效性。

> **ai_Abstract:** 本文介绍了 MetaCLIP 2，一个旨在解决现有 CLIP 模型在全球化扩展中面临挑战的训练方案。它首次实现了从零开始在全球网络规模的图像-文本对上训练 CLIP，通过最小化改动解决了非英语数据处理和“多语言诅咒”问题。实验结果表明，MetaCLIP 2 在零样本 ImageNet 分类中超越了其英语对应模型和 mSigLIP，并在多语言基准测试中，如 CVQA、Babel-ImageNet 和 XM3600，取得了最先进的性能，证明了其在全球数据上进行有效预训练的能力。

> **摘要翻译:** 对比语言-图像预训练（CLIP）是一种流行的基础模型，支持从零样本分类、检索到多模态大型语言模型（MLLMs）的编码器。尽管 CLIP 已成功在数十亿规模的英语图像-文本对上进行训练，但将 CLIP 的训练进一步扩展到从全球网络数据中学习仍然具有挑战性：(1) 没有可用的整理方法来处理来自非英语世界的数据点；(2) 现有多语言 CLIP 的英语性能不如其纯英语对应模型，即大型语言模型中常见的“多语言诅咒”。在此，我们提出了 MetaCLIP 2，这是第一个从头开始在全球网络规模图像-文本对上训练 CLIP 的方案。为了推广我们的发现，我们进行了严格的消融实验，只进行了解决上述挑战所必需的最小改动，并提出了一个能够使英语和非英语世界数据相互受益的方案。在零样本 ImageNet 分类中，MetaCLIP 2 ViT-H/14 比其纯英语对应模型高出 0.8%，比 mSigLIP 高出 0.7%，并且令人惊讶地在多语言基准测试中创造了新的最先进水平，而没有系统级混杂因素（例如，翻译、定制架构更改），例如 CVQA 达到 57.4%，Babel-ImageNet 达到 50.2%，以及 XM3600 图像到文本检索达到 64.3%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [423] [Low-Cost Test-Time Adaptation for Robust Video Editing](https://arxiv.org/abs/2507.21858)
> *鲁棒视频编辑的低成本测试时自适应*

*Jianhui Wang, Yinda Chen, Yangfan He, Xinyuan Song, Yi Xin, Dapeng Zhang, Zhongwei Wan, Bin Li, Rongchao Zhang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 视频编辑, 测试时自适应, 时间一致性, 提示过拟合, 低成本

**Comment:** 

> **TL;DR:** Vid-TTA是一种轻量级测试时自适应框架，通过自监督辅助任务和动态损失平衡机制，显著提升了视频编辑的质量，解决了时间不一致性和提示过拟合问题，同时保持低计算开销。

**AI_Comments:** Vid-TTA的创新点在于其轻量级的测试时自适应方法，通过自监督任务和动态损失平衡机制，有效解决了视频编辑中长期存在的时间不一致性和提示过拟合问题。其“即插即用”的特性使其具有很高的实用价值和广阔的应用前景，能够显著提升现有视频编辑模型的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频编辑方法面临两大挑战：由于未能捕捉复杂运动模式导致的时间不一致性，以及UNet骨干架构的局限性导致的对简单提示的过拟合。此外，学习型方法通常需要大量计算资源并受限于高质量标注数据的稀缺性。

**Method:** 本文提出了Vid-TTA，一个轻量级测试时自适应框架，通过自监督辅助任务在推理过程中为每个测试视频个性化优化。该方法包含一个运动感知帧重建机制，用于识别和保留关键运动区域；一个提示扰动和重建策略，用于增强模型对不同文本描述的鲁棒性。这些创新由一个元学习驱动的动态损失平衡机制协调，该机制根据视频特性自适应调整优化过程。

**Result:** 实验表明，Vid-TTA显著改善了视频的时间一致性，并减轻了提示过拟合，同时保持了较低的计算开销，为现有视频编辑模型提供了即插即用的性能提升。

**Conclusion:** Vid-TTA通过其新颖的测试时自适应框架，有效解决了视频编辑中的关键挑战，实现了高质量、鲁棒且计算效率高的视频编辑，为现有模型提供了显著的性能增强。

> **ai_Abstract:** 本文提出Vid-TTA，一个针对视频编辑的轻量级测试时自适应框架。它通过运动感知帧重建和提示扰动与重建策略，结合元学习驱动的动态损失平衡机制，解决了现有方法在时间一致性和提示过拟合方面的挑战。实验证明，Vid-TTA在低计算开销下显著提高了视频编辑的质量和鲁棒性，可作为现有模型的即插即用增强。

> **摘要翻译:** 视频编辑是内容创作的关键组成部分，它将原始素材转化为符合特定视觉和叙事目标的连贯作品。现有方法面临两大主要挑战：由于未能捕捉复杂运动模式导致的时间不一致性，以及UNet骨干架构的局限性导致的对简单提示的过拟合。虽然基于学习的方法可以提高编辑质量，但它们通常需要大量的计算资源，并受限于高质量标注数据的稀缺性。在本文中，我们提出了Vid-TTA，一个轻量级的测试时自适应框架，它在推理过程中通过自监督辅助任务为每个测试视频进行个性化优化。我们的方法结合了运动感知帧重建机制，用于识别和保留关键运动区域；以及提示扰动和重建策略，用于增强模型对不同文本描述的鲁棒性。这些创新由一个元学习驱动的动态损失平衡机制协调，该机制根据视频特性自适应调整优化过程。广泛的实验表明，Vid-TTA显著改善了视频时间一致性并减轻了提示过拟合，同时保持了较低的计算开销，为现有视频编辑模型提供了即插即用的性能提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [425] [GLIMPSE: Holistic Cross-Modal Explainability for Large Vision-Language Models](https://arxiv.org/abs/2506.18985)
> *GLIMPSE: 大规模视觉-语言模型的整体跨模态可解释性*

*Guanxi Shen* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 视觉-语言模型, 可解释性, 跨模态, 注意力机制, 梯度映射

**Comment:** Keywords: Explainable Computer Vision, Large Vision-Language Models,
  AI Interpretability, Explainable AI, Visual Saliency, Attribution Maps,
  Cross-Modal Attribution, Human Attention Alignment, AI Transparency

> **TL;DR:** GLIMPSE是一个轻量级、模型无关的框架，用于解释大型视觉-语言模型（LVLMs）的输出，通过生成跨模态热图来揭示其视觉和文本注意力，在忠实度和人类注意力对齐方面表现优异。

**AI_Comments:** GLIMPSE的创新之处在于其轻量级、模型无关的特性，以及融合多种技术来生成整体跨模态热图，这对于解释复杂的LVLM行为至关重要。它不仅提高了可解释性方法的忠实度，还在人类注意力对齐方面达到了SOTA，为LVLM的诊断、调试和信任建立提供了有力的工具。

<details>
  <summary>Details</summary>

**Motivation:** 解释LVLM的视觉注意力是一个重大挑战，但对于理解模型行为至关重要。

**Method:** GLIMPSE（Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation）是一个轻量级、模型无关的框架。它融合了梯度加权注意力、自适应层传播和相关性加权令牌聚合，以生成整体响应级别热图，用于解释跨模态推理。

**Result:** GLIMPSE在忠实度方面优于现有方法，并在人类注意力对齐方面达到了最先进水平。它能够揭示LVLM跨模态归因的细粒度洞察、追踪推理动态、分析系统性错位、诊断幻觉和偏差，并确保透明度。

**Conclusion:** GLIMPSE提供了一种分析方法来深入理解LVLM的跨模态归因，并有助于诊断模型问题和提高透明度。

> **ai_Abstract:** 本文介绍了GLIMPSE，一个轻量级、模型无关的框架，旨在为大型视觉-语言模型（LVLM）提供整体的跨模态可解释性。通过融合梯度加权注意力、自适应层传播和相关性加权令牌聚合，GLIMPSE生成响应级别的热图，以解释LVLM的视觉注意力和文本信号，从而帮助理解其推理过程。实验表明，GLIMPSE在忠实度方面优于现有方法，并在人类注意力对齐方面达到了最先进水平，并能用于深入分析LVLM的行为、诊断问题并提高透明度。

> **摘要翻译:** 近期的大规模视觉-语言模型（LVLM）在视觉问答（VQA）方面取得了显著进展。然而，解释LVLM将视觉注意力集中在哪里仍然是一个重大挑战，但对于理解模型行为至关重要。我们引入了GLIMPSE（用于提示式视觉显著性解释的梯度层重要性映射），这是一个轻量级、模型无关的框架，它将LVLM的输出共同归因于支持开放式生成的最相关视觉证据和文本信号。GLIMPSE融合了梯度加权注意力、自适应层传播和相关性加权令牌聚合，以生成整体响应级别热图，用于解释跨模态推理，在忠实度方面优于现有方法，并在人类注意力对齐方面推动了最先进水平。我们展示了一种分析方法，可以深入了解LVLM的跨模态归因、追踪推理动态、分析系统性错位、诊断幻觉和偏差，并确保透明度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [426] [HDR Environment Map Estimation with Latent Diffusion Models](https://arxiv.org/abs/2507.21261)
> *使用潜在扩散模型进行HDR环境图估计*

*Jack Hilliard, Adrian Hilton, Jean-Yves Guillemaut* | **Category: cs.CV** | **Updated: 2025-07-28**

**Keywords:** HDR环境图, 潜在扩散模型, ERP表示, 单视图估计, PanoDiT

**Comment:** 

> **TL;DR:** 本文提出了一种利用潜在扩散模型（LDM）从单视图图像估计高质量HDR环境图的新方法，解决了ERP表示中常见的失真和接缝问题，并达到了与现有技术相当的性能。

**AI_Comments:** 该论文通过将潜在扩散模型应用于HDR环境图估计，并在架构上进行创新（如ERP卷积填充和PanoDiT），解决了ERP格式的特定挑战。尽管PanoDiT存在图像质量与合理性之间的权衡，但该方法整体上实现了与现有技术相媲美的结果，突显了扩散模型在该领域的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 从单视图图像估计HDR环境图时，现有的ERP（等矩形投影）表示方法存在两极失真和侧边接缝伪影的常见问题。

**Method:** 本文提出了一种利用潜在扩散模型（LDM）的新颖方法来生成高质量环境图。为消除边框接缝伪影，在潜在自编码器中引入了ERP卷积填充。此外，通过提出一种全景适应的扩散Transformer（PanoDiT）架构，研究了调整扩散网络架构是否能提高估计环境图的质量和准确性。

**Result:** 所提出的模型能够估计出高质量的环境图，在图像质量和照明精度方面与最先进的方法具有竞争力。然而，提出的PanoDiT网络虽然减少了ERP失真和伪影，但牺牲了图像质量和合理性。

**Conclusion:** 本文提出的基于潜在扩散模型的方法，通过引入ERP卷积填充等创新，显著推动了从单视图图像估计HDR环境图的领域，尽管特定架构调整（如PanoDiT）存在一些权衡，但整体上取得了具有竞争力的结果。

> **ai_Abstract:** 本文提出了一种利用潜在扩散模型（LDM）从单视图图像估计HDR环境图的新颖方法。为解决ERP表示中常见的失真和接缝问题，该方法在潜在自编码器中引入了ERP卷积填充，并探讨了一种全景适应的扩散Transformer（PanoDiT）架构。评估结果显示，尽管PanoDiT在减少失真的同时牺牲了部分图像质量，但整体模型在图像质量和照明精度方面均达到了与现有最先进方法相当的竞争力。

> **摘要翻译:** 我们通过建立一种利用潜在扩散模型（LDM）的新颖方法，推进了从单视图图像估计HDR环境图的领域，以生成能够合理照亮镜面反射表面的高质量环境图。当使用绝大多数方法所采用的ERP表示格式时，一个常见问题是两极处的失真和环境图侧面的接缝。我们通过在潜在自编码器中提出ERP卷积填充来消除边界接缝伪影。此外，我们通过提出一种全景适应的扩散Transformer架构，研究了调整扩散网络架构以适应ERP格式是否能提高估计环境图的质量和准确性。我们提出的PanoDiT网络减少了ERP失真和伪影，但代价是图像质量和合理性。我们使用标准基准进行评估，以证明我们的模型估计的高质量环境图在图像质量和照明精度方面与最先进的方法具有竞争力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [437] [RobustSplat: Decoupling Densification and Dynamics for Transient-Free 3DGS](https://arxiv.org/abs/2506.02751)
> *RobustSplat：解耦致密化与动态性以实现无瞬态3DGS*

*Chuanyu Fu, Yuqi Zhang, Kunbin Yao, Guanying Chen, Yuan Xiong, Chuan Huang, Shuguang Cui, Xiaochun Cao* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 3D Gaussian Splatting, 瞬态对象, 鲁棒性, 新视角合成, 动态场景

**Comment:** ICCV 2025. Project page: https://fcyycf.github.io/RobustSplat/

> **TL;DR:** RobustSplat通过延迟高斯增长和多尺度掩码引导，解决了3DGS在处理瞬态对象时产生的伪影问题。

**AI_Comments:** RobustSplat通过创新性地解耦了高斯致密化过程与瞬态动态，并引入了分阶段优化和多尺度掩码引导，有效解决了3DGS在动态场景中的关键挑战。这种方法不仅提升了渲染质量，也为未来3DGS在复杂现实世界场景中的应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D Gaussian Splatting (3DGS) 方法在建模受瞬态对象影响的场景时遇到困难，导致渲染图像中出现伪影。作者发现高斯致密化过程在增强场景细节捕获的同时，无意中通过生长额外的建模瞬态干扰的高斯来促成这些伪影。

**Method:** 提出RobustSplat，包含两个关键设计：1. 延迟高斯增长策略：优先优化静态场景结构，然后才允许高斯分裂/克隆，从而减轻早期优化中对瞬态对象的过拟合。2. 尺度级联掩码引导方法：首先利用低分辨率特征相似性监督进行可靠的初始瞬态掩码估计，然后逐步过渡到高分辨率监督以实现更精确的掩码预测。

**Result:** 在多个具有挑战性的数据集上进行的广泛实验表明，该方法优于现有方法，清晰地展示了其鲁棒性和有效性。

**Conclusion:** RobustSplat通过解耦致密化和动态性，有效解决了3DGS在瞬态场景中产生的伪影问题，显著提升了渲染质量和鲁棒性。

> **ai_Abstract:** 本文提出了RobustSplat，一种改进3D Gaussian Splatting (3DGS) 的方法，旨在解决现有3DGS在处理包含瞬态对象的场景时产生的伪影问题。通过引入延迟高斯增长策略和尺度级联掩码引导方法，RobustSplat有效避免了高斯对瞬态干扰的过拟合，并实现了精确的瞬态掩码预测。实验结果表明，RobustSplat在处理复杂瞬态场景时表现出卓越的鲁棒性和有效性，优于现有方法。

> **摘要翻译:** 3D高斯泼溅 (3DGS) 因其在新视角合成和3D建模中的实时、照片级真实感渲染而受到广泛关注。然而，现有方法在准确建模受瞬态对象影响的场景时遇到困难，导致渲染图像中出现伪影。我们发现，高斯致密化过程在增强场景细节捕获的同时，无意中通过生长额外的建模瞬态干扰的高斯来促成这些伪影。为了解决这个问题，我们提出了RobustSplat，一个基于两个关键设计的鲁棒解决方案。首先，我们引入了一种延迟高斯增长策略，该策略优先优化静态场景结构，然后才允许高斯分裂/克隆，从而减轻早期优化中对瞬态对象的过拟合。其次，我们设计了一种尺度级联掩码引导方法，该方法首先利用低分辨率特征相似性监督进行可靠的初始瞬态掩码估计，利用其更强的语义一致性和对噪声的鲁棒性，然后逐步过渡到高分辨率监督以实现更精确的掩码预测。在多个具有挑战性的数据集上进行的广泛实验表明，我们的方法优于现有方法，清晰地展示了我们方法的鲁棒性和有效性。我们的项目页面是https://fcyycf.github.io/RobustSplat/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [445] [GuidPaint: Class-Guided Image Inpainting with Diffusion Models](https://arxiv.org/abs/2507.21627)
> *GuidPaint：基于扩散模型的类别引导图像修复*

*Qimin Wang, Xinda Liu, Guohua Geng* | **Category: cs.CV, I.4.4** | **Updated: 2025-07-29**

**Keywords:** 图像修复, 扩散模型, 分类器指导, 无需训练, 上下文感知

**Comment:** 

> **TL;DR:** GuidPaint是一种无需训练、类别引导的图像修复框架，通过在去噪过程中引入分类器指导，实现了对掩蔽区域内容的高精度控制，解决了现有方法语义不一致和视觉不合理的问题，并在定性和定量评估中取得了显著改进。

**AI_Comments:** 本文提出了一种无需训练的图像修复方法GuidPaint，其创新点在于引入了分类器指导，解决了现有上下文感知方法在语义控制上的不足。这种方法在不增加训练成本的前提下，显著提升了修复内容的精确性和真实性，具有重要的实用价值。结合随机和确定性采样的策略也增加了用户的灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于扩散模型的多模态图像修复方法计算成本高昂，需要修改架构并重新训练；而上下文感知扩散修复方法虽然无需额外训练，但缺乏对掩蔽区域的细粒度控制，常导致语义不一致或视觉上不合理的内容。

**Method:** 我们提出了GuidPaint，一个无需训练的类别引导图像修复框架。它通过将分类器指导整合到去噪过程中，实现了对掩蔽区域内中间生成内容的精确控制，确保了语义一致性和视觉真实性。此外，它还结合了随机和确定性采样，允许用户选择偏好的中间结果并进行确定性细化。

**Result:** 实验结果表明，GuidPaint在定性和定量评估中都比现有的上下文感知修复方法取得了明显的改进。

**Conclusion:** GuidPaint通过引入分类器指导和结合随机/确定性采样，成功解决了现有图像修复方法在控制性和语义一致性方面的不足，实现了高质量、可控的图像修复。

> **ai_Abstract:** GuidPaint是一种创新的图像修复框架，旨在克服现有扩散模型在细粒度控制和语义一致性方面的局限性。它通过整合分类器指导到去噪过程，实现了对掩蔽区域内容的精确控制，确保生成内容的语义连贯性和视觉真实感。该框架无需额外训练，并结合了随机和确定性采样策略，使用户能够灵活地选择和优化修复结果。实验证明，GuidPaint在修复质量上显著优于现有上下文感知方法。

> **摘要翻译:** 近年来，扩散模型因其强大的生成能力而被广泛应用于图像修复任务，并取得了令人印象深刻的结果。现有基于扩散模型的多模态修复方法通常需要架构修改和重新训练，导致计算成本高昂。相比之下，上下文感知扩散修复方法利用模型的固有先验知识来调整中间去噪步骤，从而无需额外训练即可实现高质量修复，并显著降低了计算量。然而，这些方法缺乏对掩蔽区域的细粒度控制，常常导致语义不一致或视觉上不合理的内容。为了解决这个问题，我们提出了GuidPaint，一个无需训练的类别引导图像修复框架。通过将分类器指导整合到去噪过程中，GuidPaint能够精确控制掩蔽区域内的中间生成内容，确保语义一致性和视觉真实性。此外，它还结合了随机和确定性采样，允许用户选择偏好的中间结果并进行确定性细化。实验结果表明，GuidPaint在定性和定量评估中都比现有的上下文感知修复方法取得了明显的改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [461] [CAPE: A CLIP-Aware Pointing Ensemble of Complementary Heatmap Cues for Embodied Reference Understanding](https://arxiv.org/abs/2507.21888)
> *CAPE：一种基于CLIP的互补热图线索指向集成模型，用于具身指代理解*

*Fevziye Irem Eyiokur, Dogucan Yaman, Hazım Kemal Ekenel, Alexander Waibel* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 具身指代理解, 指向手势, 多模态理解, CLIP, 热图

**Comment:** 

> **TL;DR:** 该论文提出CAPE，一个双模型框架，结合头部到指尖和手腕到指尖的指向线索，通过高斯射线热图和CLIP感知指向集成模块，用于具身指代理解，并在YouRefIt数据集上实现了性能提升。

**AI_Comments:** 该论文的创新点在于认识到单一指向线假设的局限性，并提出了一个双模型框架来捕捉不同指向线索。高斯射线热图的使用为模型提供了强大的空间监督信号，而CLIP感知集成则有效地结合了多模态信息。辅助的对象中心预测任务也进一步增强了模型的定位能力，提高了具身指代理解的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在有效利用视觉线索进行消歧方面存在困难，并且依赖单一指向线（如头到指尖或手腕到指尖）的假设过于简单，可能导致次优性能。

**Method:** 提出一个双模型框架，一个模型学习头到指尖方向，另一个学习手腕到指尖方向。引入高斯射线热图表示这些线作为强监督信号。提出CLIP-Aware Pointing Ensemble模块，基于CLIP特征进行混合集成。此外，提出对象中心预测头作为辅助任务以增强指代物定位。

**Result:** 在基准YouRefIt数据集上，在0.25 IoU阈值下，mAP提高了约4%。

**Conclusion:** 所提出的CAPE方法通过结合多源指向线索和CLIP特征，有效提升了具身指代理解的性能。

> **ai_Abstract:** 该论文针对具身指代理解中的视觉线索利用不足和单一指向线假设的局限性，提出了CAPE模型。CAPE采用双模型框架，分别处理头到指尖和手腕到指尖的指向方向，并引入高斯射线热图作为监督信号。通过CLIP感知指向集成模块融合两个模型的优势，并辅以对象中心预测任务。实验证明，该方法在YouRefIt数据集上显著提升了性能。

> **摘要翻译:** 我们解决了具身指代理解问题，该问题涉及通过指向手势和语言预测场景中人物所指的对象。准确识别指代物需要多模态理解：整合文本指令、视觉指向和场景上下文。然而，现有方法往往难以有效利用视觉线索进行消歧。我们还观察到，虽然指代物通常与头到指尖线对齐，但有时它更密切地与手腕到指尖线对齐。因此，依赖单一线条假设可能过于简单，并可能导致次优性能。为了解决这个问题，我们提出了一个双模型框架，其中一个模型从头到指尖方向学习，另一个从手腕到指尖方向学习。我们进一步引入了这些线的高斯射线热图表示，并将其用作输入，以提供强大的监督信号，鼓励模型更好地关注指向线索。为了结合两个模型的优势，我们提出了CLIP感知指向集成模块，该模块基于CLIP特征执行混合集成。此外，我们提出了一个对象中心预测头作为辅助任务，以进一步增强指代物定位。我们通过在基准YouRefIt数据集上的广泛实验和分析验证了我们的方法，在0.25 IoU阈值下实现了大约4 mAP的改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [466] [Describe, Adapt and Combine: Empowering CLIP Encoders for Open-set 3D Object Retrieval](https://arxiv.org/abs/2507.21489)
> *描述、适应与结合：赋能CLIP编码器以实现开放集3D对象检索*

*Zhichuan Wang, Yang Zhou, Zhe Liu, Rui Yu, Song Bai, Yulong Wang, Xinwei He, Xiang Bai* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 开放集3D对象检索, CLIP, 多模态大语言模型, 泛化, 多视图图像

**Comment:** Accepted to ICCV 2025

> **TL;DR:** DAC框架通过结合CLIP和多模态大语言模型（MLLM），仅利用多视图图像，显著提升了开放集3D对象检索任务的泛化能力。

**AI_Comments:** 该研究的创新点在于巧妙地结合了预训练的CLIP模型和多模态大语言模型（MLLM），以解决开放集3D对象检索中3D数据稀缺导致的泛化性瓶颈。通过仅依赖多视图图像，并利用MLLM的描述和外部提示能力，DAC显著提升了模型对未见类别的泛化能力。引入AB-LoRA进一步优化了性能，为低资源3D任务提供了一条高效且有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有开放集3D对象检索方法由于3D训练数据不足，难以生成泛化表示，且通常需要多种模态并训练特定的骨干网络，导致性能受限。

**Method:** 本文提出了一个名为Describe, Adapt and Combine (DAC) 的框架，仅利用多视图图像进行开放集3D对象检索。DAC创新性地将CLIP模型与多模态大语言模型（MLLM）结合，以学习广义的3D表示。MLLM具有双重用途：首先，在训练期间描述已知类别信息以与CLIP的训练目标对齐进行适应；其次，在推理期间提供与视觉线索互补的未知对象外部提示。为增强协同作用，引入了Additive-Bias Low-Rank adaptation (AB-LoRA) 以缓解过拟合并进一步增强对未见类别的泛化能力。

**Result:** DAC仅使用多视图图像，在四个开放集3DOR数据集上，平均mAP显著超越现有技术10.01%。此外，其泛化能力也在基于图像和跨数据集设置中得到验证。

**Conclusion:** DAC框架通过有效结合CLIP和MLLM，并引入AB-LoRA，显著提升了开放集3D对象检索的泛化能力，仅依赖多视图图像即可超越现有方法，为解决3D数据稀缺问题提供了有效途径。

> **ai_Abstract:** 本文提出了一种名为DAC（Describe, Adapt and Combine）的框架，用于解决开放集3D对象检索中现有方法因3D数据稀缺导致泛化能力不足的问题。DAC创新性地利用预训练的CLIP模型和多模态大语言模型（MLLM），仅通过多视图图像学习广义的3D表示。MLLM在训练时用于描述已知类别信息以适应CLIP，在推理时提供关于未知对象的外部提示。为了进一步提升泛化能力和缓解过拟合，引入了Additive-Bias Low-Rank adaptation (AB-LoRA)。实验结果表明，DAC在四个开放集3DOR数据集上显著超越现有技术，平均mAP提升10.01%，并展现出优异的泛化能力。

> **摘要翻译:** 开放集3D对象检索（3DOR）是一项新兴任务，旨在检索训练集之外的未见类别3D对象。现有方法通常利用所有模态（即体素、点云、多视图图像）并在融合前训练特定的骨干网络。然而，由于3D训练数据不足，它们仍然难以产生泛化表示。CLIP通过在网络规模的图像-文本对上进行对比预训练，天然地为广泛的下游任务生成泛化表示。在此基础上，我们提出了一个简单而有效的框架，名为描述、适应与结合（DAC），仅通过多视图图像进行开放集3DOR。DAC创新性地将CLIP模型与多模态大语言模型（MLLM）协同作用，以学习广义的3D表示，其中MLLM用于双重目的。首先，它描述已知类别信息，以与CLIP的训练目标对齐进行训练期间的适应。其次，它在推理期间提供与视觉线索互补的未知对象外部提示。为了改善协同作用，我们引入了一种加性偏置低秩适应（AB-LoRA），它减轻了过拟合并进一步增强了对未见类别的泛化能力。仅使用多视图图像，DAC在四个开放集3DOR数据集上平均mAP显著超越现有技术10.01%。此外，其泛化能力也在基于图像和跨数据集设置中得到验证。代码可在https://github.com/wangzhichuan123/DAC获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [470] [PEVLM: Parallel Encoding for Vision-Language Models](https://arxiv.org/abs/2506.19651)
> *PEVLM：面向视觉-语言模型的并行编码*

*Letian Kang, Shixian Luo, Yiqiang Li, Yuxin Yin, Shenxuan Zhou, Xiaoyang Yu, Jin Yang, Yong Wu* | **Category: cs.CV, cs.LG, cs.PF** | **Updated: 2025-07-29**

**Keywords:** 视觉-语言模型, 并行编码, 长视频理解, 注意力机制, 效率

**Comment:** 

> **TL;DR:** PEVLM是一种无需微调的并行编码方法，旨在提高视觉-语言模型在长视频理解中的预填充效率，通过将注意力复杂度从二次降低到线性，显著加速计算并提高准确性。

**AI_Comments:** PEVLM的创新之处在于其无需微调的并行编码方法，通过巧妙的块划分和共享汇聚块设计，在不牺牲准确性的前提下，将注意力复杂度从二次降低到线性，极大地提升了长视频理解的效率。其超越全注意力性能和在严格延迟约束下的显著准确性提升，使其在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言模型在长视频理解中的应用受到标准注意力机制二次复杂度的限制。

**Method:** PEVLM是一种无需微调的并行编码方法。它将输入视频划分为带有共享“汇聚块”（sink block）的上下文块，同时保留顺序位置嵌入以使注意力权重分布与全注意力（Full-Attention）对齐。该设计将注意力复杂度从O((T × N)^2)降低到O(T × N)。

**Result:** PEVLM在多项基准测试中始终优于现有并行编码方法，注意力计算速度提升高达7.47倍，端到端延迟降低40%。它不仅保持了高准确性，在某些设置下甚至超越了全注意力性能。在严格的延迟限制下，准确性从23.26%提高到61.03%。

**Conclusion:** PEVLM在低延迟、长上下文视频理解方面表现出显著的有效性，是实际应用中一个有前景的解决方案。

> **ai_Abstract:** 该论文提出了PEVLM，一种用于视觉-语言模型的无需微调的并行编码方法，旨在解决长视频理解中标准注意力机制的二次复杂度问题。PEVLM通过将视频分割成上下文块并使用共享汇聚块来降低注意力复杂度，同时保持与全注意力相似的权重分布。实验证明，PEVLM在保持甚至超越现有方法准确性的同时，显著提高了注意力计算速度和降低了端到端延迟，使其成为低延迟、长上下文视频理解的有效方案。

> **摘要翻译:** 视觉-语言模型（VLM）在多模态理解和生成任务中展示了强大的能力。然而，它们在长视频理解中的应用仍受到标准注意力机制二次复杂度的阻碍。在这项工作中，我们引入了PEVLM，一种无需微调的并行编码方法，旨在提高VLM在长视频场景中的预填充效率。PEVLM将输入视频划分为带有共享“汇聚块”（sink block）的上下文块，同时保留顺序位置嵌入以使注意力权重分布与全注意力（Full-Attention）对齐。这种设计将注意力复杂度从O((T × N)^2)降低到O(T × N)，其中T是帧数，N是每帧的令牌数，而不会牺牲准确性。在多个最先进的模型和基准上进行的广泛实验表明，PEVLM始终优于现有并行编码方法，在注意力计算方面实现了高达7.47倍的加速，并将端到端延迟降低了40%。值得注意的是，PEVLM不仅保持了高准确性，在某些设置下甚至超越了全注意力性能。在严格的延迟约束下，它实现了显著的增益，将准确性从23.26%提高到61.03%。这些结果强调了PEVLM在低延迟、长上下文视频理解方面的有效性，使其成为实际应用中一个有前景的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [483] [Image Captioning via Compact Bidirectional Architecture](https://arxiv.org/abs/2201.01984)
> *通过紧凑双向架构进行图像字幕生成*

*Zijie Song, Yuanen Zhou, Zhenzhen Hu, Daqing Liu, Huixia Ben, Richang Hong, Meng Wang* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-29**

**Keywords:** 图像字幕, 双向架构, Transformer, 自批判训练, MSCOCO

**Comment:** 

> **TL;DR:** 本文提出了一种紧凑的双向Transformer模型用于图像字幕生成，该模型可以隐式和显式地利用双向上下文，并且解码器可以并行执行，在MSCOCO基准测试上取得了SOTA结果。

**AI_Comments:** 该论文的创新点在于提出了一个紧凑的双向Transformer模型，有效地解决了传统图像字幕模型单向性限制和现有双向模型解码器顺序执行的问题。通过引入L2R和R2L流的紧密耦合以及并行解码，显著提高了效率和性能。句子级和词级集成的结合进一步增强了模型的鲁棒性。其重要性在于为图像字幕领域提供了一种高效且高性能的双向建模新范式。

<details>
  <summary>Details</summary>

**Motivation:** 大多数当前图像字幕模型是单向的，只能利用过去上下文而不能利用未来上下文。虽然基于精炼的模型可以利用双向上下文，但其解码器通常包含两个网络且只能顺序执行。

**Method:** 本文引入了一种紧凑的双向Transformer模型，通过将左到右（L2R）和右到左（R2L）流紧密耦合到一个单一紧凑模型中实现。它隐式地利用双向上下文并可选地允许双向流的显式交互。最终字幕通过句子级集成从L2R或R2L流中选择。此外，还将传统的单流自批判训练扩展到双流版本，并验证了其在LSTM骨干网上的通用性。

**Result:** 在MSCOCO基准测试上的广泛消融研究表明，紧凑的双向架构和句子级集成比显式交互机制更重要。结合词级集成后，句子级集成的效果进一步增强。与非视觉语言预训练模型相比，该模型取得了新的最先进结果。

**Conclusion:** 紧凑的双向架构在图像字幕生成中能够有效利用双向上下文并实现并行解码，通过句子级和词级集成以及双流自批判训练，取得了优异的性能和良好的通用性。

> **ai_Abstract:** 本文提出了一种用于图像字幕生成的紧凑双向Transformer模型，旨在解决传统单向模型无法利用未来上下文以及现有双向模型解码器顺序执行的问题。该模型通过将左到右和右到左的生成流紧密耦合，实现了双向上下文的隐式和显式利用，并允许解码器并行执行。研究表明，紧凑的双向架构和句子级集成是性能提升的关键因素。结合词级集成和扩展的双流自批判训练，该模型在MSCOCO基准测试上取得了非视觉语言预训练模型中的最新最佳结果，并验证了其在不同骨干网络上的通用性。

> **摘要翻译:** 大多数当前的图像字幕模型通常从左到右生成字幕。这种单向特性使得它们只能利用过去上下文而不能利用未来上下文。尽管基于精炼的模型可以通过在第二阶段基于预检索或预生成的字幕生成新字幕来利用过去和未来上下文，但这些模型的解码器通常由两个网络（即第一阶段的检索器或字幕生成器和第二阶段的字幕生成器）组成，并且只能顺序执行。在本文中，我们引入了一种紧凑的双向Transformer模型用于图像字幕生成，该模型可以隐式和显式地利用双向上下文，同时解码器可以并行执行。具体来说，它通过将左到右（L2R）和右到左（R2L）流紧密耦合到一个单一紧凑模型中来实现，作为隐式利用双向上下文的正则化，并可选地允许双向流的显式交互，而最终字幕则以句子级集成的方式从L2R或R2L流中选择。我们在MSCOCO基准测试上进行了广泛的消融研究，发现紧凑的双向架构和句子级集成比显式交互机制扮演着更重要的角色。通过与词级集成无缝结合，句子级集成的效果进一步放大。我们进一步将传统的单流自批判训练扩展到该架构下的双流版本，并与非视觉语言预训练模型相比，取得了新的最先进结果。最后，我们通过将其扩展到LSTM骨干网验证了这种紧凑双向架构的通用性。源代码可在https://github.com/YuanEZhou/cbtic获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [486] [Fairness and Robustness of CLIP-Based Models for Chest X-rays](https://arxiv.org/abs/2507.21291)
> *基于CLIP模型的胸部X射线图像公平性和鲁棒性*

*Théo Sourget, David Restrepo, Céline Hudelot, Enzo Ferrante, Stergios Christodoulidis, Maria Vakalopoulou* | **Category: cs.CV** | **Updated: 2025-07-28**

**Keywords:** CLIP模型, 胸部X射线, 公平性, 鲁棒性, 捷径学习

**Comment:** Accepted for publication at the FAIMI MICCAI workshop 2025

> **TL;DR:** 本研究评估了六种广泛使用的基于CLIP的模型在胸部X射线分类任务上的公平性和鲁棒性，发现存在年龄相关的性能差距以及对捷径学习的依赖。

**AI_Comments:** 本文对将基于CLIP的通用模型应用于医学影像领域所面临的公平性和鲁棒性挑战进行了及时且重要的探讨。研究发现的年龄相关性能差距和对捷径学习的依赖性，揭示了在临床部署前进行严格评估的必要性。此外，对嵌入可视化局限性的探讨也为未来研究提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于CLIP的模型在自然图像-文本领域表现出色，并已应用于医学影像任务，但它们在不同临床任务中的公平性和鲁棒性仍未得到充分探索。

**Method:** 研究评估了六种基于CLIP的模型在胸部X射线分类任务上的表现，使用了MIMIC-CXR、NIH-CXR14和NEATX三个公开数据集。研究评估了模型在年龄、性别和种族等六种患者亚组条件下的公平性，并通过评估有无胸腔引流管的气胸病例来评估模型对捷径学习的鲁棒性。此外，还对模型生成的嵌入进行了分析。

**Result:** 结果显示，不同年龄患者之间存在性能差距，但其他属性的结果更为公平。所有模型在没有胸腔引流管的图像上表现较差，表明模型依赖虚假关联。敏感属性可以从嵌入中分类出来，但PCA等可视化技术未能显示这些模式，表明其评估模型的局限性。

**Conclusion:** 基于CLIP的模型在胸部X射线分类中存在年龄相关的公平性问题以及对虚假关联（如胸腔引流管）的鲁棒性问题。同时，一些可视化技术在评估模型时存在局限性。

> **ai_Abstract:** 本研究全面评估了六种基于CLIP的模型在胸部X射线分类任务中的公平性和鲁棒性。利用MIMIC-CXR、NIH-CXR14和NEATX三个数据集，作者分析了模型在不同年龄、性别和种族患者亚组间的性能差异，并探究了模型对捷径学习（如胸腔引流管）的依赖。结果发现，模型在不同年龄组间存在性能差距，且在缺乏虚假关联（如无胸腔引流管）的图像上表现下降，表明模型存在公平性问题和对虚假特征的过度依赖。研究还指出，尽管敏感属性可从嵌入中分类，但某些可视化技术在评估模型时存在局限性。

> **摘要翻译:** 受CLIP模型在自然图像-文本领域强大性能的启发，最近的努力已将这些架构应用于医学任务，特别是在放射学领域，那里有大量配对的图像和报告数据集，如胸部X射线。尽管这些模型在准确性和判别性能方面显示出令人鼓舞的结果，但它们在不同临床任务中的公平性和鲁棒性在很大程度上仍未得到充分探索。在本研究中，我们广泛评估了六种广泛使用的基于CLIP的模型在胸部X射线分类任务上的表现，使用了三个公开数据集：MIMIC-CXR、NIH-CXR14和NEATX。我们评估了模型在基于年龄、性别和种族的六种条件和患者亚组中的公平性。此外，我们通过评估有无胸腔引流管的气胸病例来评估模型对捷径学习的鲁棒性。我们的结果表明，不同年龄患者之间存在性能差距，但对于其他属性，结果更为公平。此外，所有模型在没有胸腔引流管的图像上表现出较低的性能，这表明它们依赖虚假关联。我们通过对模型生成的嵌入进行研究，进一步补充了性能分析。虽然敏感属性可以从嵌入中分类出来，但我们使用PCA没有看到这种模式，这表明这些可视化技术在评估模型时的局限性。我们的代码可在https://github.com/TheoSourget/clip_cxr_fairness获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [491] [ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts](https://arxiv.org/abs/2507.04270)
> *ZERO：基于多模态提示的工业级视觉基础模型*

*Sangbum Choi, Kyeongryeol Go, Taewoong Jang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 视觉基础模型, 多模态提示, 零样本, 工业应用, 泛化

**Comment:** 9 pages, 2 figures

> **TL;DR:** ZERO是一个工业级视觉基础模型，利用多模态提示实现零样本泛化，在学术和工业数据集上表现出色，并在挑战赛中取得优异成绩。

**AI_Comments:** ZERO的创新之处在于它是首个明确为工业领域特定、零样本应用设计的视觉基础模型，通过多模态提示实现了无需再训练的强大泛化能力。这对于解决工业领域数据稀缺问题、加速AI在实际生产环境中的部署具有重要意义。其在多项基准测试和挑战赛中的优异表现，进一步验证了其在复杂工业场景下的实用性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基础模型在缺乏高质量、领域特定数据集的情况下，难以在实际工业环境中进行零样本部署。

**Method:** ZERO通过利用多模态（文本和视觉）提示进行泛化，无需再训练。它在一个紧凑但具有代表性的90万标注样本上进行训练，这些样本来源于一个专有的十亿级工业数据集。

**Result:** ZERO在LVIS-Val等学术基准测试上表现出有竞争力的性能，并在37个不同的工业数据集上显著优于现有模型。此外，ZERO在CVPR 2025目标实例检测挑战赛中获得第二名，在基础小样本目标检测挑战赛中获得第四名。

**Conclusion:** ZERO是首个专为领域特定、零样本工业应用而构建的视觉基础模型，具有最小适应性和有限数据下的实际可部署性和泛化能力。

> **ai_Abstract:** ZERO是一个由Superb AI推出的工业级视觉基础模型，旨在解决现有基础模型在工业零样本部署中面临的领域数据稀缺问题。该模型通过利用多模态（文本和视觉）提示实现无需再训练的泛化能力。ZERO在一个包含90万标注样本的专有工业数据集上训练，并在学术基准测试和37个工业数据集上均表现出色，还在CVPR 2025和基础小样本目标检测挑战赛中取得了优异成绩，证明了其在工业应用中的实用性和泛化能力。

> **摘要翻译:** 基础模型彻底改变了人工智能，但由于缺乏高质量、领域特定的数据集，它们在现实世界工业环境中的零样本部署面临挑战。为了弥合这一差距，Superb AI推出了ZERO，一个工业级视觉基础模型，它利用多模态提示（文本和视觉）进行泛化，无需再训练。ZERO在一个紧凑但具有代表性的90万标注样本上进行训练，这些样本来源于一个专有的十亿级工业数据集，它在LVIS-Val等学术基准测试上表现出有竞争力的性能，并在37个不同的工业数据集上显著优于现有模型。此外，ZERO在CVPR 2025目标实例检测挑战赛中获得第二名，在基础小样本目标检测挑战赛中获得第四名，突显了其在最小适应性和有限数据下的实际可部署性和泛化能力。据我们所知，ZERO是第一个明确为领域特定、零样本工业应用而构建的视觉基础模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [496] [The Evolution of Video Anomaly Detection: A Unified Framework from DNN to MLLM](https://arxiv.org/abs/2507.21649)
> *视频异常检测的演变：从DNN到MLLM的统一框架*

*Shibo Gao, Peipei Yang, Haiyang Guo, Yangyang Liu, Yi Chen, Shuai Li, Han Zhu, Jian Xu, Xu-Yao Zhang, Linlin Huang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 视频异常检测, MLLM, LLM, 统一框架, 综述

**Comment:** 

> **TL;DR:** 本文首次全面综述了基于MLLM和LLM的视频异常检测（VAD）方法，提出了一个统一框架，并分析了该领域在大模型时代的变化、挑战和未来方向。

**AI_Comments:** 本文的创新之处在于它是首篇全面综述基于MLLM和LLM的视频异常检测（VAD）方法的论文，并提出了一个统一的框架，将传统的DNN方法与新兴的LLM方法整合起来。其重要性在于系统地梳理了大模型对VAD领域带来的变革，填补了该领域系统性综述的空白，并为未来的研究指明了方向。通过对挑战和未来方向的提炼，为研究人员提供了宝贵的指导。

<details>
  <summary>Details</summary>

**Motivation:** 随着多模态大语言模型（MLLM）和大语言模型（LLM）的快速发展，视频异常检测（VAD）领域出现了新的机遇和挑战，出版物数量激增且任务不断演变，因此迫切需要对近期进展进行系统性综述。

**Method:** 本文首次全面综述了基于MLLM和LLM的视频异常检测（VAD）方法，深入探讨了大模型时代VAD领域的变化及其深层原因。此外，本文提出了一个统一框架，涵盖了基于深度神经网络（DNN）和基于LLM的VAD方法，对LLM赋能的新VAD范式进行了透彻分析，构建了分类系统，并比较了它们的优缺点。最后，本文提炼了关键挑战并概述了未来的研究方向。

**Result:** 本文提供了一份关于基于MLLM和LLM的VAD方法的首次全面综述，提出了一个统一框架，分析了LLM赋能的VAD新范式，构建了分类系统，并比较了其优缺点。此外，本文还识别了关键挑战并指明了未来的研究方向。

**Conclusion:** 本文基于技术发展轨迹和现有瓶颈，提炼了视频异常检测领域的关键挑战，并概述了未来的研究方向，为VAD社区提供了指导。

> **ai_Abstract:** 本综述文章首次全面分析了基于多模态大语言模型（MLLM）和大语言模型（LLM）的视频异常检测（VAD）方法。文章讨论了大模型时代VAD领域在数据标注、输入模态、模型架构和任务目标方面的转变，并提出了一个统一框架，涵盖了从深度神经网络（DNN）到LLM的VAD方法，对新范式进行了深入分析、分类和优缺点比较。最后，文章总结了当前挑战并展望了未来研究方向，为VAD社区提供指导。

> **摘要翻译:** 视频异常检测（VAD）旨在识别和定位视频中的异常行为或事件，是智能监控和公共安全领域的核心技术。随着深度学习的进步，深度模型架构的持续演进推动了VAD方法学的创新，显著增强了特征表示和场景适应性，从而提高了算法的泛化能力并扩展了应用边界。更重要的是，多模态大语言模型（MLLMs）和大语言模型（LLMs）的快速发展为VAD领域带来了新的机遇和挑战。在MLLMs和LLMs的支持下，VAD在数据标注、输入模态、模型架构和任务目标方面都经历了显著的转变。出版物数量的激增和任务的演变迫切需要对近期进展进行系统性综述。本文首次全面综述了基于MLLMs和LLMs的VAD方法，深入探讨了大模型时代VAD领域发生的变化及其深层原因。此外，本文提出了一个统一框架，涵盖了基于深度神经网络（DNN）和基于LLM的VAD方法，对LLM赋能的新VAD范式进行了透彻分析，构建了分类系统，并比较了它们的优缺点。在此基础上，本文重点关注当前基于MLLMs/LLMs的VAD方法。最后，基于技术发展轨迹和现有瓶颈，本文提炼了关键挑战并概述了未来的研究方向，为VAD社区提供了指导。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [497] [Aether Weaver: Multimodal Affective Narrative Co-Generation with Dynamic Scene Graphs](https://arxiv.org/abs/2507.21893)
> *Aether Weaver：基于动态场景图的多模态情感叙事协同生成*

*Saeed Ghorbani* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 多模态生成, 叙事协同生成, 动态场景图, 情感一致性, 大型语言模型

**Comment:** 

> **TL;DR:** Aether Weaver是一个新颖的集成框架，用于多模态叙事协同生成，通过同时合成文本、动态场景图、视觉场景和情感音景，克服了传统顺序管线的限制。

**AI_Comments:** 这项研究的创新之处在于提出了一个真正集成的多模态协同生成框架，而非简单的顺序管线。通过引入动态场景图和情感一致性控制，该系统显著提升了生成叙事的连贯性、视觉效果和情感共鸣，对于沉浸式故事创作和创意内容生成具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 克服现有顺序文本到视觉管线在多模态叙事生成方面的局限性。

**Method:** Aether Weaver是一个集成的多模态叙事协同生成框架。它包含一个叙述者（大型语言模型）生成叙事文本和多模态提示，一个导演作为动态场景图管理器，分析文本以构建和维护故事世界的结构化表示，确保空间-时间及关系一致性。此外，一个叙事弧控制器指导高层故事结构，影响多模态情感一致性，并由情感基调映射器补充，确保所有模态的情感表达一致。

**Result:** 通过对包含各种体裁的叙事提示进行定性评估，Aether Weaver在叙事深度、视觉保真度和情感共鸣方面显著优于级联基线方法。

**Conclusion:** Aether Weaver提供了一个强大的平台，用于快速创意原型设计和沉浸式讲故事体验。

> **ai_Abstract:** Aether Weaver是一个创新的多模态叙事协同生成框架，旨在解决传统顺序生成流程的不足。该系统能够同步生成文本叙事、动态场景图、视觉场景和情感音景。其核心组件包括一个负责文本和多模态提示生成的Narrator（大型语言模型），一个管理动态场景图并确保一致性的Director，以及一个控制高层故事结构和情感一致性的Narrative Arc Controller和Affective Tone Mapper。定性评估表明，Aether Weaver在叙事深度、视觉保真度和情感共鸣方面优于现有方法，为创意原型和沉浸式叙事提供了强大的平台。

> **摘要翻译:** 我们引入了Aether Weaver，一个新颖的、集成的多模态叙事协同生成框架，它克服了顺序文本到视觉管线的局限性。我们的系统在紧密集成的协同生成机制驱动下，同时合成文本叙事、动态场景图表示、视觉场景和情感音景。其核心是叙述者，一个大型语言模型，负责生成叙事文本和多模态提示；而导演则作为动态场景图管理器，分析文本以构建和维护故事世界的结构化表示，确保视觉渲染和后续叙事生成的时空和关系一致性。此外，一个叙事弧控制器指导高层故事结构，影响多模态情感一致性，并由情感基调映射器进一步补充，确保所有模态的情感表达一致。通过对涵盖各种体裁的叙事提示进行定性评估，我们证明Aether Weaver与级联基线方法相比，显著增强了叙事深度、视觉保真度和情感共鸣。这个集成框架为快速创意原型设计和沉浸式讲故事体验提供了一个强大的平台。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [501] [PPJudge: Towards Human-Aligned Assessment of Artistic Painting Process](https://arxiv.org/abs/2507.09242)
> *PPJudge：迈向艺术绘画过程的人类对齐评估*

*Shiqi Jiang, Xinpeng Li, Xi Mao, Changbo Wang, Chenhui Li* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 艺术绘画过程评估, PPJudge, PPAD, Transformer, 计算创造力

**Comment:** ACM International Conference on Multimedia 2025

> **TL;DR:** 本文提出PPJudge框架和PPAD数据集，旨在实现对动态艺术绘画过程的评估，并在准确性、鲁棒性及与人类判断一致性上超越现有方法。

**AI_Comments:** 本文的创新点在于首次将艺术绘画过程的动态性纳入评估范畴，弥补了现有研究仅关注静态最终图像的不足。通过构建大规模的PPAD数据集和设计高效的PPJudge模型，为艺术评估和计算创造性领域带来了突破，具有重要的实践和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有艺术图像评估方法主要关注静态最终图像，忽略了艺术绘画过程的动态性和多阶段性质，这导致了评估的局限性。

**Method:** 本文提出了PPJudge框架，包括：1. 构建了首个大规模绘画过程评估数据集（PPAD），该数据集包含真实和合成绘画过程图像，并由领域专家在八个详细属性上进行标注。2. 提出了PPJudge模型，这是一个基于Transformer的模型，其特点在于结合了时序感知位置编码和异构专家混合架构，以有效评估绘画过程。

**Result:** 实验结果表明，所提出的方法在准确性、鲁棒性以及与人类判断的一致性方面均优于现有基线方法。

**Conclusion:** 该方法为计算创造力和艺术教育提供了新的见解。

> **ai_Abstract:** 本文针对现有艺术图像评估方法忽视绘画过程动态性的问题，提出了PPJudge框架。该框架包含首个大规模绘画过程评估数据集PPAD，以及一个基于Transformer的PPJudge模型，该模型通过时序感知位置编码和异构专家混合架构增强。实验证明，PPJudge在准确性、鲁棒性和与人类判断的一致性方面均优于现有方法，并为计算创造力和艺术教育提供了新的视角。

> **摘要翻译:** 艺术图像评估已成为计算机视觉领域的一个突出研究方向。近年来，该领域涌现出大量旨在评估绘画美学质量的数据集和方法。然而，大多数现有方法仅关注静态最终图像，忽视了艺术绘画过程的动态和多阶段性质。为了弥补这一空白，我们提出了一种新颖的、与人类对齐的绘画过程评估框架。具体来说，我们引入了绘画过程评估数据集（PPAD），这是第一个大规模数据集，包含真实和合成的绘画过程图像，由领域专家在八个详细属性上进行标注。此外，我们提出了PPJudge（绘画过程评估器），一个基于Transformer的模型，该模型通过时序感知位置编码和异构专家混合架构得到增强，能够有效评估绘画过程。实验结果表明，我们的方法在准确性、鲁棒性以及与人类判断的一致性方面优于现有基线，为计算创造力和艺术教育提供了新见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [517] [One-stage Modality Distillation for Incomplete Multimodal Learning](https://arxiv.org/abs/2309.08204)
> *不完整多模态学习的单阶段模态蒸馏*

*Shicai Wei, Yang Luo, Chunbo Luo* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 模态蒸馏, 不完整多模态学习, 多任务学习, 知识转移, 特征融合

**Comment:** 

> **TL;DR:** 本文提出了一种单阶段模态蒸馏框架，通过多任务学习将特权知识转移和模态信息融合统一起来，以解决不完整多模态输入问题，并在RGB-D分类和分割任务上取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了一个“单阶段”模态蒸馏框架，将知识转移和信息融合统一起来，而非传统的分离处理。这种统一优化有助于更直接地捕获有价值的表示。通过引入联合适应网络和交叉翻译网络，解决了不完整模态输入带来的表示异构性和特征聚合问题，为多模态学习在实际应用中的鲁棒性提供了新的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 多模态数据学习日益受到关注，但在实际开发场景中并非所有模态都始终可用，这导致了在模态不完整情况下的推理挑战。

**Method:** 本文提出了一种单阶段模态蒸馏框架，通过多任务学习将特权知识转移和模态信息融合统一到单一优化过程中。该框架包含：1. 联合适应网络（joint adaptation network）用于模态转移任务，通过联合分布适应解决输入差异导致的表示异构性，以保留特权信息。2. 交叉翻译网络（cross translation network）用于模态融合任务，聚合恢复的模态和可用模态特征，并利用参数共享策略显式捕获跨模态线索。

**Result:** 在RGB-D分类和分割任务上的大量实验表明，所提出的多模态继承框架能够克服各种场景下不完整模态输入的问题，并取得了最先进的性能。

**Conclusion:** 本文提出的单阶段模态蒸馏框架通过统一特权知识转移和模态信息融合，有效解决了不完整多模态学习中的挑战，并在多项任务上实现了卓越性能。

> **ai_Abstract:** 本文提出了一种新颖的单阶段模态蒸馏框架，旨在解决多模态学习中模态输入不完整的问题。该框架通过多任务学习统一了特权知识转移和模态信息融合，从而直接捕获有助于模型推理的有效表示。具体包括一个联合适应网络用于模态转移以处理表示异构性，以及一个交叉翻译网络用于模态融合以聚合特征并捕获跨模态线索。实验证明，该方法在RGB-D分类和分割任务上表现出色，并达到了最先进的性能。

> **摘要翻译:** 基于多模态数据的学习最近引起了越来越多的兴趣。虽然可以收集各种感官模态进行训练，但在开发场景中并非所有模态都始终可用，这给不完整模态的推断带来了挑战。为了解决这个问题，本文提出了一种单阶段模态蒸馏框架，通过多任务学习将特权知识转移和模态信息融合统一到一个优化过程中。与传统独立执行模态蒸馏的方法相比，这有助于捕获能够直接辅助最终模型推断的有价值表示。具体来说，我们提出了用于模态转移任务的联合适应网络，通过联合分布适应解决输入差异引起的表示异构性，以保留特权信息。然后，我们引入了用于模态融合任务的交叉翻译网络，以聚合恢复的模态和可用模态特征。它利用参数共享策略显式捕获跨模态线索。在RGB-D分类和分割任务上的大量实验表明，所提出的多模态继承框架可以克服各种场景下不完整模态输入的问题，并实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [522] [VAGU & GtS: LLM-Based Benchmark and Framework for Joint Video Anomaly Grounding and Understanding](https://arxiv.org/abs/2507.21507)
> *VAGU & GtS：基于LLM的视频异常定位与理解联合基准和框架*

*Shibo Gao, Peipei Yang, Yangyang Liu, Yi Chen, Han Zhu, Xuyao Zhang, Linlin Huang* | **Category: cs.CV, cs.MM** | **Updated: 2025-07-29**

**Keywords:** 视频异常检测, 异常定位, 异常理解, LLM, 基准数据集

**Comment:** 21 pages, 19 figures, 8 tables

> **TL;DR:** 本文提出了VAGU基准和GtS框架，首次整合视频异常定位与理解，并引入JeAUG评估指标，解决了现有方法无法同时兼顾这两项任务的问题。

**AI_Comments:** 本文创新性地解决了视频异常检测领域中异常定位和语义理解分离的问题，首次提出了一个联合基准VAGU，填补了现有数据集的空白。其提出的免训练GtS框架为实际应用提供了高效的解决方案，而新的评估指标JeAUG则为未来更全面、准确的视频异常检测研究奠定了基础，具有重要的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频异常检测（VAD）方法未能同时支持异常理解和精确时间定位，缺乏整合这两种关键任务的模型和数据集，导致对异常事件的理解和定位不够全面。

**Method:** 提出了VAGU（视频异常定位与理解），首个整合视频异常定位与理解的基准数据集，包含异常类别、语义解释、精确时间定位和视频问答标注。基于此数据集，提出了Glance then Scrutinize (GtS) 框架，这是一个由文本提示引导的免训练框架，用于实现高概率异常区域的粗略定位、详细异常解释和时间边界细化。此外，还提出了JeAUG度量标准，用于联合评估语义可解释性和时间精度。

**Result:** 大量实验验证了所提出的VAGU基准、GtS框架和JeAUG评估指标的有效性。

**Conclusion:** 本文成功地提出了VAGU基准、GtS框架和JeAUG度量，解决了视频异常定位与理解的联合任务，并为未来的全面视频异常检测研究提供了新的数据集、框架和评估标准。

> **ai_Abstract:** 本文针对现有视频异常检测（VAD）方法在异常定位和语义理解之间存在的割裂问题，首次提出了VAGU基准数据集，该数据集整合了视频异常定位与理解两项任务，并提供了丰富的标注信息，包括异常类别、语义解释、精确时间定位和视频问答。在此基础上，作者提出了免训练的Glance then Scrutinize (GtS) 框架，该框架能够通过文本提示实现异常区域的粗略定位、详细解释及时间边界细化。为全面评估模型性能，论文还引入了JeAUG度量标准，用于联合衡量语义可解释性和时间精度。实验结果验证了所提基准、框架和度量的有效性。

> **摘要翻译:** 视频异常检测（VAD）旨在识别视频中的异常事件并准确确定其时间间隔。当前的VAD方法主要分为两类：专注于时间定位的传统基于DNN的方法，以及强调语义理解的基于LLM的方法。异常理解和定位对于全面的视频异常检测都至关重要，并且可以相互补充。然而，目前没有模型或数据集同时支持这两项任务。为了解决这个问题，我们引入了VAGU（视频异常定位与理解），这是第一个整合这两项任务的基准。每个VAGU实例都包含异常类别、语义解释、精确时间定位和视频问答的注释。我们还提供了多项选择的视频问答用于客观评估。基于此数据集，我们提出了Glance then Scrutinize（GtS），一个由文本提示引导的免训练框架。该框架首先实现高概率异常区域的粗略定位，然后进行详细的异常解释和时间边界细化。此外，我们提出了JeAUG度量标准，它联合评估语义可解释性和时间精度，克服了传统度量的局限性。大量的实验验证了我们基准、框架和评估指标的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [533] [FIX-CLIP: Dual-Branch Hierarchical Contrastive Learning via Synthetic Captions for Better Understanding of Long Text](https://arxiv.org/abs/2507.10095)
> *FIX-CLIP：通过合成字幕进行双分支分层对比学习以更好地理解长文本*

*Bingchao Wang, Zhiwei Ning, Jianyu Ding, Xuanang Gao, Yin Li, Dongsheng Jiang, Jie Yang, Wei Liu* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 长文本理解, 对比学习, CLIP, 合成字幕, 双分支训练

**Comment:** Accepted by ICCV 2025

> **TL;DR:** FIX-CLIP通过双分支训练、可学习区域提示和分层特征对齐，并利用合成字幕，解决了CLIP在长文本理解方面的不足，在长短文本检索上均达到SOTA性能。

**AI_Comments:** 本文通过提出双分支训练、区域提示和分层特征对齐等创新模块，有效解决了CLIP在长文本理解上的固有局限性。特别是利用合成字幕来扩充训练数据，为长文本-图像对齐提供了一种新颖且高效的策略。其在检索和扩散模型中的应用潜力，显示了该方法在多模态理解领域的广泛实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** CLIP在短文本任务上表现出色，但受限于文本编码器的输入长度（>77 tokens），在处理长文本输入时表现不佳。本文旨在解决CLIP在长文本理解方面的这一局限性。

**Method:** 本文提出了FIX-CLIP，包含三个新颖模块：1. 双分支训练管线，分别将短文本与掩码图像、长文本与原始图像对齐，以增强长文本表示并保持短文本能力。2. Transformer层中带有单向掩码的多个可学习区域提示，用于区域信息提取。3. 中间编码器层中的分层特征对齐模块，以促进多尺度特征的一致性。此外，作者收集了30M图像并利用现有MLLMs合成长文本字幕进行训练。

**Result:** FIX-CLIP在长文本和短文本检索基准测试中均实现了最先进的性能。对于下游应用，FIX-CLIP的文本编码器在扩散模型中以即插即用的方式处理长文本输入时，展现出良好的性能。

**Conclusion:** FIX-CLIP通过其新颖的架构和数据合成策略，成功地扩展了CLIP在长文本理解方面的能力，并在多项基准测试中取得了优异表现，证明了其在长文本处理和下游应用中的有效性。

> **ai_Abstract:** FIX-CLIP旨在解决CLIP在处理长文本时的局限性。该模型引入了双分支训练管线、可学习区域提示和分层特征对齐模块，以增强长文本理解能力，同时保持短文本性能。通过收集30M图像并合成长文本字幕进行训练，FIX-CLIP在长短文本检索任务中均达到了SOTA性能，并展示了其在扩散模型中处理长文本输入的即插即用潜力。

> **摘要翻译:** CLIP在许多短文本任务中以零样本方式展现出有前景的性能。然而，受限于文本编码器的输入长度，CLIP在输入长文本（>77 tokens）的下游任务中表现不佳。为了弥补这个问题，我们提出了FIX-CLIP，它包含三个新颖的模块：(1) 一个双分支训练管线，分别将短文本和长文本与掩码图像和原始图像对齐，这既提升了长文本表示能力又保留了短文本能力。(2) Transformer层中带有单向掩码的多个可学习区域提示，用于区域信息提取。(3) 中间编码器层中的分层特征对齐模块，以促进多尺度特征的一致性。此外，我们收集了30M图像并利用现有MLLM合成长文本字幕进行训练。大量实验表明，FIX-CLIP在长文本和短文本检索基准测试中均取得了最先进的性能。对于下游应用，我们发现FIX-CLIP的文本编码器在处理长文本输入的扩散模型中，以即插即用的方式提供了有前景的性能。代码可在https://github.com/bcwang-sjtu/Fix-CLIP 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [545] [Evaluating Deepfake Detectors in the Wild](https://arxiv.org/abs/2507.21905)
> *野外深度伪造检测器评估*

*Viacheslav Pirogov, Maksim Artemev* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 深度伪造检测, 真实世界评估, 图像操作, 机器学习, 数据集

**Comment:** Accepted to the ICML 2025 Workshop 'DataWorld: Unifying Data Curation
  Frameworks Across Domains'

> **TL;DR:** 本文评估了现代深度伪造检测器在真实世界场景中的性能。研究发现，深度伪造检测仍然具有挑战性，大多数检测器表现不佳，且基本图像操作会显著降低模型性能。

**AI_Comments:** 这项研究的重要性在于它首次尝试在“真实世界”场景下评估深度伪造检测器，揭示了现有技术在实际应用中的局限性。其创新之处在于提出了模拟真实世界场景的测试程序和构建了大规模高质量数据集。研究结果对深度伪造检测领域具有重要指导意义，强调了未来研究需要关注的问题。

<details>
  <summary>Details</summary>

**Motivation:** 深度伪造技术（由先进机器学习模型驱动）对身份验证和数字媒体的真实性构成了重大且不断演变的威胁。尽管已开发出许多检测器来解决此问题，但其在应用于真实世界数据时的有效性尚未经过测试。

**Method:** 本文引入了一种新颖的测试程序，旨在模拟深度伪造检测的真实世界场景，以评估现代深度伪造检测器。研究人员使用最先进的深度伪造生成方法，创建了一个包含超过50万张高质量深度伪造图像的综合数据集。

**Result:** 分析表明，检测深度伪造仍然是一项具有挑战性的任务。在测试的深度伪造检测器中，只有不到一半的检测器实现了高于60%的AUC分数，最低的为50%。研究还表明，基本的图像操作（如JPEG压缩或图像增强）可以显著降低模型性能。

**Conclusion:** 检测深度伪造仍然是一项具有挑战性的任务，现有检测器在真实世界场景中的表现不佳，且容易受到图像操作的影响。

> **ai_Abstract:** 本研究评估了现代深度伪造检测器在模拟真实世界场景下的性能。通过创建一个包含50多万张高质量深度伪造图像的大型数据集，研究发现深度伪造检测仍具挑战性，多数检测器表现不佳（AUC低于60%），且易受JPEG压缩或图像增强等基本图像操作的影响。所有代码和数据均已公开。

> **摘要翻译:** 由先进机器学习模型驱动的深度伪造对身份验证和数字媒体的真实性构成了重大且不断演变的威胁。尽管已开发出许多检测器来解决此问题，但其在应用于真实世界数据时的有效性尚未经过测试。在这项工作中，我们评估了现代深度伪造检测器，引入了一种旨在模拟深度伪造检测真实世界场景的新颖测试程序。使用最先进的深度伪造生成方法，我们创建了一个包含超过50万张高质量深度伪造图像的综合数据集。我们的分析表明，检测深度伪造仍然是一项具有挑战性的任务。评估显示，在测试的深度伪造检测器中，只有不到一半的检测器实现了高于60%的AUC分数，最低的为50%。我们证明了基本的图像操作，如JPEG压缩或图像增强，可以显著降低模型性能。所有代码和数据均可在https://github.com/messlav/Deepfake-Detectors-in-the-Wild公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [546] [Semantic segmentation of SEM images of lower bainitic and tempered martensitic steels](https://arxiv.org/abs/2312.17251)
> *贝氏体下部和回火马氏体钢SEM图像的语义分割*

*Xiaohan Bie, Manoj Arthanari, Evelin Barbosa de Melo, Baihua Ren, Juancheng Li, Stephen Yue, Salim Brahimi, Jun Song* | **Category: cs.CV, cond-mat.mtrl-sci, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 语义分割, 深度学习, 碳化物, 下贝氏体, 回火马氏体, 扫描电镜图像

**Comment:** 

> **TL;DR:** 本研究利用深度学习对贝氏体下部和回火马氏体钢的扫描电镜图像进行语义分割，以定量分析碳化物。研究发现两种钢中碳化物含量相似，但分布和取向有差异。该模型准确率高，并可推广应用于其他材料的第二相分析，提供高效的AI驱动工作流程。

**AI_Comments:** 这篇论文创新性地将深度学习语义分割应用于钢铁材料的微观结构分析，特别是碳化物析出物的定量表征。其重要性在于提供了一种高效、自动化的方法，替代了传统繁琐的手动分析，且达到了高准确率。这为材料科学研究，尤其是金属材料的相分析，提供了一个强大的AI驱动工具，具有广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过深度学习技术对扫描电子显微镜图像进行分割，从而对强度相当的下贝氏体和回火马氏体钢中的碳化物析出物进行定量分析，包括体积分数、尺寸分布和取向。

**Method:** 本研究采用深度学习技术对扫描电子显微镜图像进行语义分割，以区分碳化物和铁基体。分割后，对碳化物的体积分数、尺寸分布和取向进行分析。该深度学习模型在像素级别上实现了98.0%的像素级准确率。

**Result:** 研究发现，下贝氏体和回火马氏体中的碳化物含量相似，但回火马氏体中的碳化物分布更均匀。下贝氏体中的碳化物比回火马氏体中的碳化物表现出更好的排列趋势，但两种微观结构中的碳化物取向均呈分散状。此外，两种钢中碳化物的长宽比和尺寸表现出显著相似性。深度学习模型在像素级别上分类碳化物/铁基体达到了98.0%的准确率。

**Conclusion:** 深度学习实现的语义分割可应用于各种材料中第二相的分析，提供了一种省时、多功能的AI驱动工作流程，用于定量微观结构分析。

> **ai_Abstract:** 本研究利用深度学习技术对下贝氏体和回火马氏体钢的扫描电镜图像进行语义分割，旨在定量分析其中的碳化物析出物。研究发现，两种钢中碳化物含量相似，但回火马氏体中的碳化物分布更均匀，而下贝氏体中的碳化物排列趋势更好。尽管如此，两种微观结构中的碳化物取向均呈分散状。该深度学习模型在碳化物/铁基体分类上达到了98.0%的像素级准确率，证明了其在材料微观结构定量分析中的高效和通用性。

> **摘要翻译:** 本研究采用深度学习技术对扫描电子显微镜图像进行分割，从而能够定量分析强度相当的下贝氏体和回火马氏体钢中的碳化物析出物。分割后，对图像数据集中的碳化物进行了研究，并探测了它们的体积分数、尺寸分布和取向。我们的研究结果表明，下贝氏体和回火马氏体具有相似的碳化物含量，尽管回火马氏体中的碳化物分布更均匀。下贝氏体中的碳化物比回火马氏体中的碳化物表现出更好的排列趋势，这与其它研究人员的观察结果一致。然而，两种微观结构都显示出分散的碳化物取向，没有任何可辨别的模式。对下贝氏体和回火马氏体中碳化物的长宽比和尺寸进行比较分析，揭示了惊人的相似性。该深度学习模型在像素级别上分类碳化物/铁基体时，实现了98.0%的像素级准确率。深度学习衍生的语义分割将其适用性扩展到各种材料中第二相的分析，为定量微观结构分析提供了一种省时、多功能的AI驱动工作流程。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [549] [VoluMe -- Authentic 3D Video Calls from Live Gaussian Splat Prediction](https://arxiv.org/abs/2507.21311)
> *VoluMe——基于实时高斯溅射预测的真实3D视频通话*

*Martin de La Gorce, Charlie Hewitt, Tibor Takacs, Robert Gerdisch, Zafiirah Hosenie, Givi Meishvili, Marek Kowalski, Thomas J. Cashman, Antonio Criminisi* | **Category: cs.CV, cs.GR** | **Updated: 2025-07-28**

**Keywords:** 3D视频通话, 高斯溅射, 实时重建, 视频会议, 真实性

**Comment:** 

> **TL;DR:** VoluMe是一种新方法，仅使用一个2D网络摄像头即可实时预测3D高斯重建，实现真实、逼真且可访问的3D视频通话。

**AI_Comments:** VoluMe的创新之处在于其能够从单个2D网络摄像头实时生成高质量、真实的3D人物表示，这显著降低了3D视频会议的硬件门槛。通过引入“真实性”概念和稳定性损失，该方法解决了现有方案在动态场景和时间一致性上的不足。其重要性在于，它使得3D会议不再需要昂贵的专业设备，有望推动3D通信在日常应用中的普及。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D会议解决方案通常需要复杂的硬件、固定外观或预训练生成模型，这些限制不适用于视频会议应用。本研究旨在解决在3D会议中表示人物的挑战，并提供一种更灵活、真实且易于访问的解决方案。

**Method:** 本研究提出了首个从单个2D网络摄像头实时预测3D高斯重建的方法。该方法通过独立地基于每个视频帧来调节3D表示，以忠实地重建输入视频（称为“真实性”），并能真实地泛化到新的视角。此外，引入了一个稳定性损失来确保视频序列在时间上的稳定性。

**Result:** 该方法在视觉质量和稳定性指标上均达到了现有技术的最新水平。研究人员成功地使用标准2D摄像头和显示器进行了实时一对一3D会议演示。

**Conclusion:** VoluMe证明了其方法能够让任何人以可访问、逼真且真实的方式进行体积通信，从而实现3D视频会议。

> **ai_Abstract:** 该论文介绍了一种名为VoluMe的新型3D视频会议方法，旨在解决现有方案在真实性、可访问性和硬件要求方面的限制。VoluMe创新性地实现了从单个2D网络摄像头实时预测3D高斯重建，确保了3D表示的实时性、逼真性和对输入视频的真实性。通过独立处理每个视频帧并引入稳定性损失，该方法在视觉质量和时间稳定性上均达到了最先进水平。实验证明，VoluMe能够利用标准2D设备进行高质量的实时3D会议，极大地提升了3D通信的普及性和用户体验。

> **摘要翻译:** 虚拟3D会议与标准2D视频通话相比，有望增强共存感、提高参与度，从而提高远程会议的效率。然而，在3D会议中表示人物仍然是一个挑战；现有解决方案通过使用复杂硬件、通过注册使用固定外观或通过反演预训练生成模型来实现高质量。这些方法导致了不适合视频会议应用的限制。我们提出了第一个仅通过单个2D网络摄像头实时预测3D高斯重建的方法，其中3D表示不仅是实时的、逼真的，而且对输入视频是真实的。通过独立地基于每个视频帧来调节3D表示，我们的重建忠实地从捕获的视角再现了输入视频（我们称之为真实性），同时真实地泛化到新的视角。此外，我们引入了一个稳定性损失，以获得在视频序列上时间稳定的重建。我们表明，与现有方法相比，我们的方法在视觉质量和稳定性指标方面提供了最先进的精度，并使用标准2D摄像头和显示器演示了我们方法在实时一对一3D会议中的应用。这表明我们的方法可以让任何人通过一种不仅高度可访问，而且真实和逼真的3D视频会议方法进行体积通信。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [558] [Automated Detection of Antarctic Benthic Organisms in High-Resolution In Situ Imagery to Aid Biodiversity Monitoring](https://arxiv.org/abs/2507.21665)
> *用于辅助生物多样性监测的高分辨率原位图像中南极底栖生物的自动化检测*

*Cameron Trotter, Huw Griffiths, Tasnuva Ming Khan, Rowan Whittle* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 南极, 底栖生物, 物体检测, 生物多样性监测, 高分辨率图像

**Comment:** Accepted to ICCV 2025's Joint Workshop on Marine Vision (ICCVW,
  CVAUI&AAMVEM). Main paper (11 pages, 3 figures, 3 tables) plus supplementary
  (7 pages, 5 figures, 2 tables)

> **TL;DR:** 本文提出了一种定制的物体检测框架和首个公开数据集，用于在高分辨率拖曳相机图像中识别和分类南极底栖生物，以克服手动标注的局限性并实现大规模监测。

**AI_Comments:** 这项工作通过提供一个定制的物体检测框架和第一个公开数据集，有效解决了南极底栖生物多样性监测中手动标注效率低下的核心痛点。其创新性在于结合多种技术以应对海洋生态图像的特定挑战（如数据稀疏、物体大小多样）。尽管在小型和稀有生物检测方面仍有局限，但该研究为大规模、自动化的生物多样性监测提供了重要的可扩展基础，对海洋生态学研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 监测南极底栖生物多样性对于理解气候驱动压力下的生态变化至关重要，但对高分辨率原位图像进行手动标注耗时且需要专业知识，阻碍了大规模分析。

**Method:** 本文提出了一种定制的物体检测框架，用于识别和分类高分辨率拖曳相机图像中的南极底栖生物。该框架结合了分辨率保持补丁、空间数据增强、微调以及通过切片辅助超推理进行的后处理。此外，本文还发布了第一个用于威德尔海底栖生物多样性监测的公共计算机视觉数据集。

**Result:** 该框架在检测25种细粒度形态类型的中大型生物方面表现出强大的性能，显著优于该领域的其他工作。

**Conclusion:** 该框架为未来机器辅助的原位底栖生物多样性监测研究提供了可扩展的基础，但检测小型和稀有分类群仍然是一个挑战。

> **ai_Abstract:** 本文提出了一种针对南极底栖生物的高分辨率原位图像的自动化物体检测框架，旨在解决手动标注耗时且专业化的问题，以促进生物多样性监测。该研究还发布了首个用于威德尔海底栖生物多样性监测的公共计算机视觉数据集。该框架结合了分辨率保持补丁、数据增强、微调和后处理等技术，并在检测中大型生物方面表现出色，覆盖了25种形态类型。尽管在小型和稀有分类群的检测上仍面临挑战，但该框架为未来机器辅助的监测研究奠定了可扩展的基础。

> **摘要翻译:** 监测南极底栖生物多样性对于理解气候驱动压力下的生态变化至关重要。这项工作通常通过捕获高分辨率原位图像来完成，但此类数据的手动标注仍然费力且专业化，阻碍了大规模分析。我们提出了一种定制的物体检测框架，用于识别和分类高分辨率拖曳相机图像中的南极底栖生物，并提供了第一个用于威德尔海底栖生物多样性监测的公共计算机视觉数据集。我们的方法解决了海洋生态图像相关的关键挑战，包括标注数据有限、物体大小可变和海底结构复杂。所提出的框架结合了分辨率保持补丁、空间数据增强、微调以及通过切片辅助超推理进行的后处理。我们对多种物体检测架构进行了基准测试，并展示了在检测25种细粒度形态类型的中大型生物方面的强大性能，这比该领域的其他工作显著更多。小型和稀有分类群的检测仍然是一个挑战，反映了当前检测架构的局限性。我们的框架为未来机器辅助的原位底栖生物多样性监测研究提供了可扩展的基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [561] [NarrLV: Towards a Comprehensive Narrative-Centric Evaluation for Long Video Generation Models](https://arxiv.org/abs/2507.11245)
> *NarrLV：迈向长视频生成模型综合叙事评估*

*X. Feng, H. Yu, M. Wu, S. Hu, J. Chen, C. Zhu, J. Wu, X. Chu, K. Huang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 长视频生成, 叙事评估, 基准, 时间叙事原子, MLLM

**Comment:** Project Page: https://amap-ml.github.io/NarrLV-Website/

> **TL;DR:** NarrLV是一个针对长视频生成模型叙事能力的综合评估基准，引入了时间叙事原子（TNA）概念，并基于电影叙事理论构建了自动提示生成和MLLM驱动的评估框架，实验证明其与人类判断高度一致。

**AI_Comments:** NarrLV的创新之处在于其首次提出了针对长视频生成模型叙事能力的综合评估框架，而非仅仅关注视频时长。引入“时间叙事原子”（TNA）的概念，并将其与电影叙事理论结合，是量化叙事丰富度的巧妙方法。利用MLLM进行评估也体现了对最新AI技术的应用。这项工作对于推动长视频生成技术向更高层次的叙事表达发展具有重要意义，因为它为模型开发者提供了清晰的性能衡量标准和改进方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前的长视频生成模型评估主要依赖于简单叙事提示的基准，但长视频生成的目标不仅仅是延长时长，更在于准确表达丰富的叙事内容。然而，缺乏专门针对长视频生成模型的叙事评估基准。

**Method:** 提出了NarrLV，首个全面评估长视频生成模型叙事表达能力的基准。受电影叙事理论启发，引入了时间叙事原子（TNA）作为基本叙事单位，并利用其数量量化叙事丰富度。构建了自动提示生成管道，能灵活生成可扩展TNA数量的评估提示。设计了基于MLLM（多模态大语言模型）的问答框架，用于三级叙事内容表达的有效评估指标。

**Result:** 对现有长视频生成模型和基础生成模型进行了广泛评估。实验结果表明，所提出的评估指标与人类判断高度一致。评估结果揭示了当前视频生成模型在叙事内容表达方面的详细能力边界。

**Conclusion:** NarrLV成功地填补了长视频生成模型叙事能力评估基准的空白，其提出的新方法能够准确衡量模型的叙事表达能力，并揭示了现有模型的局限性，为未来的研究提供了明确的方向。

> **ai_Abstract:** 本研究提出了NarrLV，一个专为评估长视频生成模型叙事能力而设计的综合基准。鉴于现有评估方法无法充分衡量长视频的叙事丰富性，NarrLV引入了“时间叙事原子”（TNA）概念来量化叙事内容，并基于电影叙事理论构建了自动提示生成机制。此外，研究还设计了一个基于多模态大语言模型（MLLM）的问答框架作为评估指标。实验证明，NarrLV的评估结果与人类判断高度吻合，有效揭示了当前视频生成模型在叙事表达方面的能力边界，填补了该领域评估工具的空白。

> **摘要翻译:** 随着基础视频生成技术的快速发展，长视频生成模型凭借其扩展的内容创作空间展现出广阔的研究潜力。最近的研究表明，长视频生成任务的目标不仅是延长视频时长，还在于在更长的视频中准确表达更丰富的叙事内容。然而，由于缺乏专门为长视频生成模型设计的评估基准，目前对这些模型的评估主要依赖于具有简单叙事提示的基准（例如VBench）。据我们所知，我们提出的NarrLV是第一个全面评估长视频生成模型叙事表达能力的基准。受电影叙事理论启发，（i）我们首先引入了在视频中保持连续视觉呈现的基本叙事单位，称之为时间叙事原子（Temporal Narrative Atom, TNA），并使用其数量来定量测量叙事丰富度。在影响TNA变化的三个关键电影叙事元素的指导下，我们构建了一个自动提示生成管道，能够生成具有可灵活扩展TNA数量的评估提示。（ii）然后，基于叙事内容表达的三个渐进层次，我们设计了一个使用基于MLLM的问答框架的有效评估指标。（iii）最后，我们对现有的长视频生成模型和基础生成模型进行了广泛评估。实验结果表明，我们的指标与人类判断高度一致。得出的评估结果揭示了当前视频生成模型在叙事内容表达方面的详细能力边界。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [573] [ArtSeek: Deep artwork understanding via multimodal in-context reasoning and late interaction retrieval](https://arxiv.org/abs/2507.21917)
> *艺寻：通过多模态上下文推理和后期交互检索实现深度艺术品理解*

*Nicola Fanelli, Gennaro Vessio, Giovanna Castellano* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 艺术品理解, 多模态, 上下文推理, 检索增强生成, ArtSeek

**Comment:** 

> **TL;DR:** ArtSeek是一个多模态框架，通过图像输入、检索增强生成和上下文推理，实现对数字化艺术品的深度理解和分析，并在多个基准测试中取得了SOTA结果。

**AI_Comments:** ArtSeek的创新之处在于其仅依赖图像输入的特性，解决了传统方法对外部知识库链接的依赖，使其能应用于更广泛的数字化艺术品。其结合检索增强生成和上下文推理的代理策略，以及专门构建的WikiFragments数据集，共同提升了艺术品理解的深度和准确性。该方法不仅在视觉艺术领域表现出色，还具有推广到其他需要外部知识领域的潜力，对可扩展的多模态AI研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 分析数字化艺术品面临独特挑战，需要深入理解艺术、语境和历史知识。现有方法常依赖于Wikidata或Wikipedia链接，这在许多数字化藏品中并不常见。

**Method:** 本文引入ArtSeek框架，结合多模态大语言模型与检索增强生成，仅依赖图像输入。它包含：基于后期交互检索的智能多模态检索模块、用于预测艺术家、流派、风格、媒介和标签的对比多任务分类网络，以及通过Qwen2.5-VL实现的、通过上下文示例进行复杂视觉问答和艺术品解释的代理推理策略。核心是WikiFragments数据集，一个维基百科规模的图像-文本片段数据集，用于支持知识驱动的多模态推理。

**Result:** ArtSeek在多个基准测试中取得了最先进的结果，包括在风格分类上比GraphCLIP提升了+8.4%的F1分数，在ArtPedia上的图像描述任务中获得了+7.1的BLEU@1增益。定性分析表明，即使对于模糊的作品，ArtSeek也能解释视觉图案、推断历史背景和检索相关知识。

**Conclusion:** ArtSeek框架能够深度理解艺术品，并在多个任务上达到SOTA性能，其方法可推广到其他需要外部知识的领域，支持可扩展的多模态AI研究。数据集和源代码将公开。

> **ai_Abstract:** 本文介绍了ArtSeek，一个用于深度艺术品理解的多模态框架。该框架结合了多模态大语言模型和检索增强生成，仅通过图像输入即可分析艺术品，无需外部链接。ArtSeek包含智能检索、多任务分类和代理推理策略，并引入了WikiFragments数据集。它在艺术品风格分类和图像描述等任务上取得了最先进的性能，并能解释视觉图案和推断历史背景，显示出其在艺术分析领域的强大潜力。

> **摘要翻译:** 分析数字化艺术品带来了独特的挑战，不仅需要视觉解释，还需要对丰富的艺术、语境和历史知识有深入理解。我们引入了ArtSeek，一个用于艺术分析的多模态框架，它结合了多模态大型语言模型和检索增强生成。与现有工作不同，我们的管道仅依赖图像输入，使得其适用于未链接到Wikidata或Wikipedia（在大多数数字化藏品中很常见）的艺术品。ArtSeek集成了三个关键组件：一个基于后期交互检索的智能多模态检索模块、一个用于预测艺术家、流派、风格、媒介和标签的对比多任务分类网络，以及通过Qwen2.5-VL实现的、通过上下文示例进行复杂视觉问答和艺术品解释的代理推理策略。这种方法的核心是WikiFragments，一个维基百科规模的图像-文本片段数据集，旨在支持知识驱动的多模态推理。我们的框架在多个基准测试中取得了最先进的结果，包括在风格分类上比GraphCLIP提升了+8.4%的F1分数，在ArtPedia上的图像描述任务中获得了+7.1的BLEU@1增益。定性分析表明，ArtSeek即使对于模糊的作品也能解释视觉图案、推断历史背景并检索相关知识。尽管专注于视觉艺术，我们的方法可以推广到其他需要外部知识的领域，支持可扩展的多模态AI研究。数据集和源代码将在https://github.com/cilabuniba/artseek公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [574] [VLM-CPL: Consensus Pseudo Labels from Vision-Language Models for Annotation-Free Pathological Image Classification](https://arxiv.org/abs/2403.15836)
> *VLM-CPL：基于视觉-语言模型的共识伪标签，用于免标注病理图像分类*

*Lanfeng Zhong, Zongyao Huang, Yang Liu, Wenjun Liao, Shichuan Zhang, Guotai Wang, Shaoting Zhang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 病理图像分类, 视觉-语言模型, 伪标签, 零样本学习, 半监督学习

**Comment:** Accepted at TMI

> **TL;DR:** VLM-CPL提出一种无需人工标注的病理图像分类方法，利用VLM生成伪标签并采用共识和半监督学习策略处理噪声，性能优于零样本VLM和现有方法。

**AI_Comments:** 这篇论文的创新点在于其提出了一种无需人工标注的病理图像分类框架，通过巧妙地利用VLM的零样本能力并设计了一系列噪声伪标签过滤和半监督学习机制来克服领域差距带来的噪声问题。特别是提示-特征共识和高置信度交叉监督策略，有效地提升了伪标签的可靠性，使得在病理图像这种标注成本高昂的领域实现自动化成为可能，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在病理图像分类中需要大量标注数据，而人工标注耗时耗力。本研究旨在提出一种无需人工标注的方法来解决这个问题。

**Method:** 提出VLM-CPL方法，利用预训练视觉-语言模型（VLM）的零样本推理能力获取训练集的伪标签。为解决领域差距导致的噪声，VLM-CPL包含两种噪声标签过滤技术和半监督学习策略。具体步骤包括：1) 使用VLM对多重增强视图进行零样本推理，获得基于提示的伪标签及不确定性估计。2) 利用VLM的特征表示能力，通过特征空间中的样本聚类获得基于特征的伪标签。3) 引入提示-特征共识，根据两种伪标签的一致性选择可靠样本。4) 提出高置信度交叉监督（High-confidence Cross Supervision），从可靠伪标签样本和剩余未标注样本中学习。5) 提出创新的开放集提示策略，过滤全切片中不相关的斑块以提高选定斑块的质量。

**Result:** 在五个公开病理图像数据集上进行的斑块级和切片级分类实验结果表明，该方法显著优于VLM的零样本分类，并且优于现有的噪声标签学习方法。

**Conclusion:** VLM-CPL通过有效处理VLM生成的带噪伪标签，实现了无需人工标注的病理图像分类，并在多个数据集上取得了优越性能。

> **ai_Abstract:** 本文提出了VLM-CPL，一种无需人工标注的病理图像分类方法。该方法利用预训练的视觉-语言模型（VLM）进行零样本推理生成初始伪标签，并通过引入提示-特征共识、高置信度交叉监督以及开放集提示策略来有效过滤噪声伪标签并进行半监督学习。实验证明，VLM-CPL在多个病理图像数据集上的性能优于VLM的零样本分类和现有噪声标签学习方法。

> **摘要翻译:** 病理图像分类是自动癌症诊断的基础。尽管深度学习方法取得了显著性能，但它们严重依赖带标注数据，需要大量人工标注工作。在本研究中，我们提出了一种新颖的无需人工标注的方法，通过利用预训练的视觉-语言模型（VLMs）。在没有人工标注的情况下，利用VLM的零样本推理能力获取训练集的伪标签，由于预训练数据集和目标数据集之间的领域差距，这些伪标签可能包含大量噪声。为了解决这个问题，我们引入了VLM-CPL，这是一种新颖的方法，包含两种噪声标签过滤技术和一种半监督学习策略。具体来说，我们首先通过VLM使用输入图像的多个增强视图进行零样本推理，获得带有不确定性估计的基于提示的伪标签。然后，通过利用VLM的特征表示能力，我们通过特征空间中的样本聚类获得基于特征的伪标签。引入提示-特征共识（Prompt-feature consensus）以根据两种伪标签之间的一致性选择可靠样本。我们进一步提出高置信度交叉监督（High-confidence Cross Supervision），以从具有可靠伪标签的样本和剩余的未标注样本中学习。此外，我们提出了一种创新的开放集提示策略，用于从全切片中过滤不相关的斑块，以提高所选斑块的质量。在五个公共病理图像数据集上进行的斑块级和切片级分类实验结果表明，我们的方法显著优于VLM的零样本分类，并且优于现有的噪声标签学习方法。代码已公开在https://github.com/HiLab-git/VLM-CPL。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [575] [AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery](https://arxiv.org/abs/2507.13420)
> *AI回溯：美索不达米亚消失的考古景观与CORONA图像上的遗址自动检测*

*Alessandro Pistola, Valentina Orru', Nicolo' Marchetti, Marco Roccetti* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 考古遗址检测, 深度学习, CORONA卫星图像, 美索不达米亚, 消失景观

**Comment:** 25 pages, 9 Figures

> **TL;DR:** 通过使用旧的CORONA卫星图像重新训练深度学习模型，该研究提高了在现代景观中自动检测消失的考古遗址的准确性，并发现了新的遗址。

**AI_Comments:** 这篇论文的创新点在于将深度学习模型与历史性的CORONA卫星图像相结合，成功解决了现代景观变化导致考古遗址难以发现的问题。它不仅提高了遗址检测的准确性，更重要的是，通过发现肉眼不可见的“新”遗址，展示了AI在考古学领域，特别是在“消失的景观”研究中的巨大潜力。这对于保护和理解受人类活动影响的文化遗产具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 过去五十年间，美索不达米亚的考古景观发生了巨大变化，许多遗址被完全破坏，传统方法难以发现这些消失的遗址，因此需要新的技术手段。

**Method:** 通过使用1960年代的CORONA灰度卫星图像，升级并重新训练了一个现有的基于Bing的卷积神经网络模型，用于在美索不达米亚中部平原的阿布格莱布地区自动识别考古遗址。

**Result:** 研究取得了双重成果：首先，在图像分割级别，交并比（IoU）值超过85%，考古遗址检测的总体准确率达到了90%。其次，重新训练的模型成功识别出了四个经实地验证确认的、传统技术未能发现的新的考古遗址。

**Conclusion:** 本研究证实了结合AI技术和1960年代的CORONA图像能够有效发现当前不可见的考古遗址，这对于研究因人类活动导致考古证据消失的景观具有重要意义，并构成了一项具体突破。

> **ai_Abstract:** 本文通过使用1960年代的CORONA卫星图像重新训练了一个深度学习模型，以应对美索不达米亚地区考古景观因人类活动而消失的问题。该模型在自动识别考古遗址方面表现出显著提高的准确性（IoU超过85%，总体准确率达90%），并且成功发现了四个传统方法未曾识别的新遗址。研究结果证明了结合AI技术和历史卫星图像在发现当前不可见的考古遗址方面的有效性，为受人类活动影响的消失考古景观研究提供了重要突破。

> **摘要翻译:** 通过使用被称为CORONA的最古老的灰度卫星图像之一所提供的知识升级现有的深度学习模型，我们改进了AI模型在过去五十年中已完全转变（包括许多相同遗址的完全破坏）的环境中自动识别考古遗址的态度。最初基于Bing的卷积网络模型使用伊拉克巴格达西部美索不达米亚中部平原阿布格莱布地区的CORONA卫星图像进行了再训练。结果是双重的，并且令人惊讶。首先，在感兴趣区域获得的检测精度显著提高：特别是，在图像分割级别，交并比（IoU）值超过了85%，而检测考古遗址的总体准确率达到了90%。其次，我们重新训练的模型识别出了四个新的具有考古学意义的遗址（通过实地验证确认），这些遗址是考古学家以前通过传统技术未能识别的。这证实了使用AI技术和1960年代的CORONA图像来发现当前不再可见的考古遗址的有效性，这是在研究因人类活动导致考古证据消失的景观方面的一个具体突破，具有重大影响。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [585] [Optimizing Active Learning in Vision-Language Models via Parameter-Efficient Uncertainty Calibration](https://arxiv.org/abs/2507.21521)
> *通过参数高效不确定性校准优化视觉-语言模型中的主动学习*

*Athmanarayanan Lakshmi Narayanan, Amrutha Machireddy, Ranganath Krishnan* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 主动学习, 视觉-语言模型, 不确定性校准, 参数高效, 样本选择

**Comment:** International Joint Conference on Neural Networks 2025 (Accepted)

> **TL;DR:** 本文提出了一种参数高效的主动学习方法，通过引入不确定性校准损失来有效选择视觉-语言模型中的信息数据，从而在计算效率上超越或匹配现有复杂采样技术。

**AI_Comments:** 这项工作在优化大规模视觉-语言模型的主动学习方面具有重要意义，特别是在降低标注成本和提高计算效率方面。其创新点在于将参数高效的不确定性校准引入AL框架，并提出了可微分损失函数。对Prompt学习和LoRA的比较分析也为未来研究提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 主动学习（AL）在降低神经网络模型开发中的标注成本方面表现出色。然而，对于大规模视觉-语言模型，由于参数量巨大，不确定性估计和高效采样面临挑战，需要新的方法来选择最具信息量的数据。

**Method:** 我们引入了一种新颖的参数高效学习方法，该方法在主动学习框架中融入了不确定性校准损失。我们提出了一种可微分损失函数，旨在促进不确定性校准，从而有效选择更少但信息量最大的数据样本进行微调。此外，我们还研究了Prompt学习与低秩适应（LoRA）在样本选择中的有效性。

**Result:** 通过在多个数据集和视觉骨干网络上的广泛实验，我们的解决方案能够匹配甚至超越复杂的基于特征的采样技术的性能，同时计算效率极高。此外，我们还详细比较分析了Prompt学习和LoRA在高效主动学习中样本选择的有效性。

**Conclusion:** 本研究提出了一种参数高效的不确定性校准方法，显著提升了视觉-语言模型中主动学习的效率和性能，有效解决了大规模模型数据选择的挑战。

> **ai_Abstract:** 本文针对大规模视觉-语言模型中的主动学习，提出了一种参数高效的学习方法。该方法引入了不确定性校准损失，并通过可微分损失函数促进不确定性校准，从而高效选择最具信息量的数据样本进行模型微调。实验证明，该方法在性能上可与复杂采样技术媲美甚至超越，同时具有显著的计算效率。此外，研究还对比分析了Prompt学习与LoRA在样本选择中的应用效果。

> **摘要翻译:** 主动学习（AL）已成为一种强大的方法，通过选择性地采样最具信息量的数据用于神经网络模型开发，从而最大限度地降低标注成本。对于大规模视觉-语言模型而言，有效的AL需要解决不确定性估计和高效采样方面的挑战，鉴于其中涉及的巨大参数量。在这项工作中，我们引入了一种新颖的参数高效学习方法，该方法在AL框架中融入了不确定性校准损失。我们提出了一种可微分损失函数，旨在促进不确定性校准，以便有效地选择更少且信息量最大的数据样本进行微调。通过在多个数据集和视觉骨干网络上的广泛实验，我们证明了我们的解决方案能够匹配并超越复杂的基于特征的采样技术的性能，同时计算效率极高。此外，我们还研究了Prompt学习与低秩适应（LoRA）在样本选择中的有效性，提供了这些方法在高效AL背景下的详细比较分析。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [589] [Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment](https://arxiv.org/abs/2507.11642)
> *基于姿态的动作意图推断，用于比赛风格和疲劳评估*

*Abhishek Jaiswal, Nisheeth Srivastava* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 姿态分析, 动作意图, 疲劳评估, 体育分析, 弱监督

**Comment:** 

> **TL;DR:** 该研究提出了一种基于姿态的方法，通过分析体育活动视频来推断人类意图，并在板球比赛中成功区分了攻击性和防守性击球意图，为体育分析和人类行为分析提供了通用技术。

**AI_Comments:** 这项研究的创新之处在于利用体育场景作为收集人类情绪状态数据的替代方案，以克服传统视觉诊断中数据敏感性的挑战。其通过姿态分析推断意图的方法在特定任务中表现出色，并引入了弱监督来解决数据标注限制，这对于实际应用具有重要意义。该研究不仅对体育分析做出了贡献，也为将人类行为分析应用于其他领域提供了新的视角和方法。

<details>
  <summary>Details</summary>

**Motivation:** 姿态基精神状态推断在诊断疲劳、预防损伤和提高性能方面潜力巨大，但人类受试者数据敏感性导致视觉诊断面临数据积累挑战。因此，需要研究验证工具和克服数据标注限制。

**Method:** 研究选择体育场景作为积累人类受试者数据的替代方案，并在板球比赛中测试假设。提出了一种基于姿态的解决方案，通过运动分析识别活动视频中的人类意图。利用现有数据统计作为弱监督来验证发现。

**Result:** 该方法在区分攻击性和防守性击球意图方面，F1分数超过75%，AUC-ROC超过80%。研究表明姿态为意图推断提供了强信号，即使数据管道中存在固有噪声。

**Conclusion:** 姿态泄露了强烈的意图信号，即使数据存在噪声。该研究为体育分析提供了可泛化技术，并为将人类行为分析应用于各个领域开辟了可能性。

> **ai_Abstract:** 本研究提出了一种基于姿态的动作意图推断方法，旨在解决人类受试者数据敏感性导致的数据积累挑战。通过在板球比赛中测试，该方法利用运动分析从活动视频中识别击球意图，并在区分攻击性和防守性击球意图上取得了超过75%的F1分数和80%的AUC-ROC。研究结果表明姿态能提供强烈的意图信号，并利用弱监督克服了数据标注限制，为体育分析和更广泛的人类行为分析提供了可泛化技术。

> **摘要翻译:** 基于姿态的心理状态推断在诊断疲劳、预防损伤和提高各个领域的性能方面具有重要潜力。此类工具在投入实践之前，必须通过大型数据集进行研究验证。不幸的是，由于人类受试者数据的敏感性，这种视觉诊断面临严峻挑战。为了解决这个问题，我们将体育环境确定为一种可行的替代方案，用于从经历不同情绪状态的人类受试者那里积累数据。我们在板球比赛中验证了我们的假设，并提出了一种基于姿态的解决方案，用于从活动视频中识别人类意图。我们的方法在通过运动分析区分攻击性和防守性击球意图方面，F1分数超过75%，AUC-ROC超过80%。这些发现表明，即使数据管道中存在固有噪声，姿态也能泄露强烈的意图推断信号。此外，我们利用现有数据统计作为弱监督来验证我们的发现，为克服数据标注限制提供了潜在解决方案。这项研究为体育分析的可泛化技术做出了贡献，也为在各个领域应用人类行为分析开辟了可能性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [602] [Few-shot Online Anomaly Detection and Segmentation](https://arxiv.org/abs/2403.18201)
> *少量样本在线异常检测与分割*

*Shenxing Wei, Xing Wei, Zhiheng Ma, Songlin Dong, Shaochen Zhang, Yihong Gong* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 少量样本学习, 在线学习, 异常检测, 图像分割, 神经气体网络

**Comment:** 

> **TL;DR:** 提出一种基于神经网络气体的少量样本在线异常检测与分割方法，利用无标签流数据增量更新模型，在MVTec AD和BTAD数据集上表现良好。

**AI_Comments:** 这项研究的创新之处在于其关注于真实世界的“少量样本在线”场景，这对于工业应用具有重要意义。通过结合神经气体网络、预训练CNN特征和增量学习，该方法有效解决了数据稀缺和持续学习的挑战，无需存储历史数据，提升了实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有异常检测方法需要大量训练数据，且忽略了模型部署后可利用无标签流数据（包含正常和异常样本）提升性能的实际场景，因此需要解决少量样本在线异常检测与分割（FOADS）的挑战性任务。

**Method:** 使用神经气体网络（Neural Gas network）建模正常图像的特征分布，该网络能够灵活调整拓扑结构以识别数据流中的异常值。采用从ImageNet预训练CNN中提取的多尺度特征嵌入，以在有限训练样本下获得鲁棒表示。引入一种无需存储先前样本即可增量更新参数的算法。

**Result:** 该方法在FOADS设置下取得了显著的性能，同时在MVTec AD和BTAD数据集上保持了可接受的时间复杂度。

**Conclusion:** 该研究成功提出了一种针对少量样本在线异常检测与分割的有效方法，证明了在数据受限和流式数据场景下的实用性与高效性。

> **ai_Abstract:** 本文提出了一种解决少量样本在线异常检测与分割（FOADS）任务的新方法。针对传统方法对大量训练数据的依赖，该研究利用神经气体网络建模正常图像特征分布，并结合CNN多尺度特征嵌入和增量更新算法，实现在模型部署后利用无标签流数据持续优化。实验证明，该方法在FOADS场景下表现出色，且计算效率高。

> **摘要翻译:** 从图像中检测异常模式是工业应用中一项关键的人工智能技术。该领域最近的研究强调了大量训练数据的必要性，却忽略了模型部署后可以利用包含正常和异常样本的未标记数据来提高模型性能的实际场景。因此，本文重点解决具有挑战性但实用的少量样本在线异常检测与分割（FOADS）任务。在FOADS框架下，模型在少量正常数据集上进行训练，然后通过同时利用包含正常和异常样本的未标记流数据来检查和改进其能力。
为了解决这个问题，我们提出使用神经气体网络（Neural Gas network）来建模正常图像的特征分布，该网络提供了灵活的拓扑结构适应性，以识别数据流中的异常值。为了在有限的训练样本下获得改进的性能，我们采用从ImageNet预训练的CNN中提取的多尺度特征嵌入，以获得鲁棒的表示。此外，我们引入了一种可以增量更新参数而无需存储先前样本的算法。全面的实验结果表明，我们的方法在FOADS设置下可以实现显著的性能，同时确保在MVTec AD和BTAD数据集上的时间复杂度保持在可接受的范围内。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [608] [SwinECAT: A Transformer-based fundus disease classification model with Shifted Window Attention and Efficient Channel Attention](https://arxiv.org/abs/2507.21922)
> *SwinECAT：一种基于Transformer的眼底疾病分类模型，结合了移位窗口注意力和高效通道注意力*

*Peiran Gu, Teng Yao, Mengshen He, Fuhao Duan, Feiyan Liu, RenYuan Peng, Bao Ge* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 眼底疾病分类, Transformer, Swin Attention, ECA, 医学图像分析

**Comment:** 17 pages

> **TL;DR:** SwinECAT是一种基于Transformer的眼底疾病分类模型，结合了移位窗口注意力和高效通道注意力，解决了眼底图像分析中的挑战，并在9类眼底疾病分类上取得了当前公开数据集的最高性能。

**AI_Comments:** SwinECAT的创新性在于将Swin Transformer的全局和局部特征捕获能力与ECA的通道注意力机制相结合，有效地提升了眼底疾病分类的准确性和精细度。该研究将分类类别从常见的4-6类扩展到9类，显著提高了诊断的粒度，对于实际医疗应用具有重要意义。在公开数据集上取得最高性能也证明了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 在医学图像分析领域，特别是眼底图像分析中，存在病灶区域小、疾病间差异细微等挑战，这些问题会导致模型预测准确性降低和过拟合。为了解决这些挑战并提高诊断的精细度，本文提出了SwinECAT模型。

**Method:** 本文提出了SwinECAT模型，该模型结合了移位窗口（Swin）注意力机制和高效通道注意力（ECA）机制。SwinECAT利用Swin Transformer骨干网络中的Swin注意力机制来有效捕获眼底图像中的局部空间结构和长程依赖。同时，轻量级的ECA机制被整合进来，以引导SwinECAT的注意力关注关键特征通道，从而实现更具判别性的特征表示。与以往通常分类4到6种眼底疾病的研究不同，这项工作将眼底疾病分类扩展到9种不同的类型。

**Result:** SwinECAT模型在包含16,140张眼底图像的眼底疾病图像数据集（EDID）上进行了9类分类评估。实验结果显示，SwinECAT取得了88.29%的准确率，加权F1-score为0.88，宏观F1-score为0.90。该模型的分类结果显著优于基线Swin Transformer和多个其他基线模型。据作者所知，这是在该公共数据集上9类分类中报告的最高性能。

**Conclusion:** SwinECAT模型通过结合移位窗口注意力和高效通道注意力，有效解决了眼底疾病分类中的挑战，并在9类眼底疾病分类任务上取得了目前公开数据集中的最佳性能，证明了其在提高诊断精细度和准确性方面的潜力。

> **ai_Abstract:** SwinECAT是一种用于眼底疾病分类的Transformer模型，旨在解决眼底图像分析中病灶小、差异细微导致的准确性低和过拟合问题。该模型结合了Swin Transformer的移位窗口注意力以捕获局部和长程依赖，并引入高效通道注意力（ECA）以增强特征判别力。SwinECAT将分类类别扩展至9种，并在EDID数据集上实现了88.29%的准确率和优异的F1-score，性能超越现有基线，达到了该数据集上9类分类的最高水平。

> **摘要翻译:** 近年来，人工智能在医学影像领域的应用日益增多。在这些应用中，眼底图像分析面临特殊挑战，包括某些眼底疾病的病灶区域小以及疾病间细微的差异，这可能导致模型预测准确性降低和过拟合。为了应对这些挑战，本文提出了一种基于Transformer的模型SwinECAT，它结合了移位窗口（Swin）注意力和高效通道注意力（ECA）。SwinECAT利用Swin Transformer骨干网络中的Swin注意力机制来有效捕获眼底图像中的局部空间结构和长程依赖。轻量级的ECA机制被整合进来，以引导SwinECAT的注意力关注关键特征通道，从而实现更具判别性的特征表示。与以往研究通常将眼底图像分类为4到6个类别不同，这项工作将眼底疾病分类扩展到9种不同的类型，从而提高了诊断的精细度。我们在包含16,140张眼底图像的眼底疾病图像数据集（EDID）上评估了我们的方法，用于9类分类。实验结果表明，SwinECAT实现了88.29%的准确率，加权F1-score为0.88，宏观F1-score为0.90。我们提出的SwinECAT模型的分类结果显著优于基线Swin Transformer和多个对比基线模型。据我们所知，这代表了在该公共数据集上进行9类分类的最高报告性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [612] [GLCP: Global-to-Local Connectivity Preservation for Tubular Structure Segmentation](https://arxiv.org/abs/2507.21328)
> *GLCP：用于管状结构分割的全局到局部连接性保持*

*Feixiang Zhou, Zhuangzhi Gao, He Zhao, Jianyang Xie, Yanda Meng, Yitian Zhao, Gregory Y. H. Lip, Yalin Zheng* | **Category: cs.CV** | **Updated: 2025-07-28**

**Keywords:** 管状结构分割, 全局到局部连接性, 血管网络, 结构碎片化, 深度学习

**Comment:** MICCAI 2025 (Oral)

> **TL;DR:** 本文提出GLCP框架，通过结合交互式多头分割（IMS）和双注意力细化（DAR）模块，有效解决了管状结构分割中全局连接性保持和局部不连续性处理的挑战，实现了卓越的分割精度和连续性。

**AI_Comments:** 这篇论文的创新点在于其GLCP框架能够同时关注管状结构的全局连接性和局部不连续性，解决了现有方法常忽略局部细节导致碎片化的问题。IMS模块通过多任务学习明确地处理不连续区域，而DAR模块则进一步优化了分割结果，这对于需要高精度和完整性的医疗图像分析（如血管网络分割）具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 管状结构（如血管网络）的精确分割在医疗领域至关重要，但现有方法常因忽略局部不连续区域而导致结构碎片化和次优分割结果，这是一个亟待解决的挑战。

**Method:** 本文提出了一种新颖的全局到局部连接性保持（GLCP）框架。该框架包含两个核心模块：1. 交互式多头分割（IMS）模块：用于联合学习全局分割、骨架图和局部不连续图，以同时处理局部不连续区域并保持全局拓扑完整性。2. 轻量级双注意力细化（DAR）模块：用于进一步细化分割结果，提高分割质量。

**Result:** 在2D和3D数据集上的大量实验表明，与现有最先进的方法相比，GLCP在管状结构分割中实现了卓越的准确性和连续性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种名为全局到局部连接性保持（GLCP）的新型框架，旨在解决管状结构分割中常见的结构碎片化问题。GLCP通过引入交互式多头分割（IMS）模块，联合学习全局分割、骨架图和局部不连续图，从而在保持全局拓扑完整性的同时，显式地处理局部不连续区域。此外，轻量级双注意力细化（DAR）模块被设计用于进一步提升分割质量。实验证明，GLCP在2D和3D数据集上均优于现有最先进的方法，在管状结构分割中展现出卓越的准确性和连续性。

> **摘要翻译:** 管状结构（如血管网络）的精确分割在各种医疗领域中发挥着关键作用。这项任务中一个仍然存在的重大挑战是结构碎片化，这可能会对下游应用产生不利影响。现有方法主要侧重于设计各种损失函数来约束全局拓扑结构。然而，它们常常忽略局部不连续区域，导致次优的分割结果。为了克服这一限制，我们提出了一种新颖的全局到局部连接性保持（GLCP）框架，该框架可以同时感知管状网络的全局和局部结构特征。具体来说，我们提出了一个交互式多头分割（IMS）模块，分别联合学习全局分割、骨架图和局部不连续图。这使得我们的模型能够在保持全局拓扑完整性的同时，明确地针对局部不连续区域。此外，我们设计了一个轻量级基于双注意力的细化（DAR）模块，通过细化生成的分割图来进一步提高分割质量。在2D和3D数据集上的大量实验表明，与几种最先进的方法相比，我们的GLCP在管状结构分割中实现了卓越的准确性和连续性。源代码将发布在https://github.com/FeixiangZhou/GLCP。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [614] [APT: Improving Diffusion Models for High Resolution Image Generation with Adaptive Path Tracing](https://arxiv.org/abs/2507.21690)
> *APT：通过自适应路径追踪改进扩散模型以生成高分辨率图像*

*Sangmin Han, Jinho Jeong, Jinwoo Kim, Seon Joo Kim* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 扩散模型, 高分辨率图像生成, 自适应路径追踪, 分块方法, 训练无关

**Comment:** 

> **TL;DR:** APT是一种训练无关方法，通过解决现有分块方法的问题，提高了扩散模型生成高分辨率图像的质量和速度。

**AI_Comments:** APT创新性地解决了训练无关分块方法在处理高分辨率图像时遇到的特定问题（分布偏移和单调性），并通过结合统计匹配和尺度感知调度提供了有效的解决方案。其能同时提升图像质量和推理速度的特点，使其在高分辨率图像生成领域具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有潜在扩散模型在固定分辨率下训练，难以扩展到高分辨率图像。训练方法计算资源需求大，不实用。训练无关的分块方法存在“分块级别分布偏移”和“分块单调性增加”问题。

**Method:** 提出自适应路径追踪 (APT) 框架，结合统计匹配 (Statistical Matching) 确保上采样潜在空间中分块分布一致，并采用尺度感知调度 (Scale-aware Scheduling) 处理分块单调性。

**Result:** APT生成的高分辨率图像细节更清晰、更精致。APT还实现快捷去噪过程，以最小的质量下降实现更快的采样速度。实验结果证实APT输出更详细，推理速度更快。

**Conclusion:** APT为高分辨率图像生成提供了一种实用方法，通过解决现有训练无关方法的局限性，显著提高了生成质量和推理速度。

> **ai_Abstract:** 本文提出了一种名为自适应路径追踪（APT）的训练无关框架，旨在解决现有潜在扩散模型在高分辨率图像生成中遇到的挑战。针对分块方法中存在的“分块级别分布偏移”和“分块单调性增加”问题，APT通过结合统计匹配和尺度感知调度来确保分块分布一致性并处理单调性。实验证明，APT能生成更清晰、细节更丰富的高分辨率图像，并显著加快采样速度，为高分辨率图像生成提供了一个实用的解决方案。

> **摘要翻译:** 潜在扩散模型（LDMs）通常在固定分辨率下训练，限制了它们在扩展到高分辨率图像时的能力。虽然基于训练的方法通过在高分辨率数据集上进行训练来解决这一限制，但它们需要大量数据和可观的计算资源，这使得它们不太实用。因此，无需训练的方法，特别是基于分块的方法，已成为一种流行的替代方案。这些方法将图像分成多个分块并融合每个分块的去噪路径，在高分辨率生成方面表现出强大的性能。然而，我们观察到基于分块的方法存在两个关键问题，我们称之为“分块级别分布偏移”和“分块单调性增加”。为了解决这些问题，我们提出了自适应路径追踪（APT），一个结合统计匹配以确保上采样潜在空间中分块分布保持一致，并采用尺度感知调度以处理分块单调性的框架。结果是，APT在生成高分辨率图像时能产生更清晰、更精致的细节。此外，APT还实现了快捷去噪过程，从而以最小的质量下降实现更快的采样。我们的实验结果证实，APT能生成更详细的输出，并提高了推理速度，为高分辨率图像生成提供了一种实用方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [617] [SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation](https://arxiv.org/abs/2507.12857)
> *SCORE：场景上下文在开放词汇遥感实例分割中的重要性*

*Shiqi Huang, Shuting He, Huaiyuan Qin, Bihan Wen* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 遥感实例分割, 开放词汇学习, 场景上下文, 多粒度, SOTA

**Comment:** ICCV 2025 (Highlight), code see
  https://github.com/HuangShiqi128/SCORE

> **TL;DR:** SCORE框架通过整合多粒度场景上下文，显著提升了遥感开放词汇实例分割的性能，解决了现有方法的局限性。

**AI_Comments:** 本文的主要创新点在于首次将开放词汇学习引入遥感实例分割领域，并特别关注了遥感数据的特有挑战。通过整合多粒度场景上下文（区域和全局）来增强视觉和文本表示，SCORE有效地解决了遥感图像中对象多样性、小目标和模糊性问题，以及现有模型泛化能力不足的局限性。其提出的区域感知集成和全局上下文适应机制是解决这些挑战的关键。该研究为大规模、真实世界的地理空间分析提供了更具泛化性和鲁棒性的解决方案，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有遥感实例分割方法是为封闭词汇预测设计的，限制了它们识别新类别或跨数据集泛化的能力，这限制了其在多样地球观测场景中的适用性。此外，现有开放词汇分割模型直接应用于遥感面临多样地貌、季节变化以及空中图像中小型或模糊物体等挑战。

**Method:** 提出SCORE（Scene Context matters in Open-vocabulary REmote sensing instance segmentation）框架，该框架整合了多粒度场景上下文，即区域上下文和全局上下文，以增强视觉和文本表示。具体而言，引入了区域感知集成（Region-Aware Integration）来利用区域上下文细化类别嵌入，从而提高对象可区分性。此外，提出了全局上下文适应（Global Context Adaptation），用遥感全局上下文丰富朴素文本嵌入，为分类器创建更具适应性和表达能力的语言潜在空间。该研究还为开放词汇遥感实例分割建立了新的基准。

**Result:** 实验结果表明，所提出的方法在多样数据集上实现了最先进（SOTA）的性能。

**Conclusion:** SCORE为大规模、真实世界的地理空间分析提供了一个鲁棒的解决方案。

> **ai_Abstract:** SCORE是一个针对遥感实例分割的开放词汇学习框架。为解决现有封闭词汇方法的局限性以及开放词汇模型在遥感场景中面临的挑战，SCORE通过整合多粒度场景上下文（区域和全局）来增强视觉和文本表示。该框架包含区域感知集成以提高对象可区分性，以及全局上下文适应以创建更具表达性的语言潜在空间。SCORE在开放词汇遥感实例分割基准上实现了最先进的性能，为大规模地理空间分析提供了鲁棒的解决方案。

> **摘要翻译:** 大多数现有遥感实例分割方法是为封闭词汇预测设计的，限制了它们识别新类别或跨数据集泛化的能力。这限制了它们在多样地球观测场景中的适用性。为了解决这个问题，我们引入了遥感实例分割的开放词汇（OV）学习。尽管当前的OV分割模型在自然图像数据集上表现良好，但它们直接应用于遥感面临着多样地貌、季节变化以及空中图像中小型或模糊物体等挑战。为了克服这些挑战，我们提出了SCORE（场景上下文在开放词汇遥感实例分割中的重要性），一个整合多粒度场景上下文（即区域上下文和全局上下文）以增强视觉和文本表示的框架。具体而言，我们引入了区域感知集成，它利用区域上下文细化类别嵌入以提高对象可区分性。此外，我们提出了全局上下文适应，它用遥感全局上下文丰富朴素文本嵌入，为分类器创建更具适应性和表达能力的语言潜在空间。我们为多样数据集上的OV遥感实例分割建立了新的基准。实验结果表明，我们提出的方法实现了SOTA性能，这为大规模、真实世界的地理空间分析提供了一个鲁棒的解决方案。我们的代码可在https://github.com/HuangShiqi128/SCORE获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [630] [Probabilistic Directed Distance Fields for Ray-Based Shape Representations](https://arxiv.org/abs/2404.09081)
> *射线基形状表示的概率定向距离场*

*Tristan Aumentado-Armstrong, Stavros Tsogkas, Sven Dickinson, Allan Jepson* | **Category: cs.CV, cs.LG, I.2.10** | **Updated: 2025-07-29**

**Keywords:** 定向距离场, 3D形状表示, 可微分渲染, 概率建模, 神经表示

**Comment:** Extension of arXiv:2112.05300. Accepted to TPAMI

> **TL;DR:** 本文提出定向距离场（DDFs）作为一种新型神经形状表示，通过将定向点映射到表面可见性和深度，实现高效可微分渲染，并引入概率DDFs处理不连续性，在多种应用中表现出色，并理论研究了视图一致性。

**AI_Comments:** 这篇论文通过引入定向距离场（DDFs）提出了一种新颖的3D形状表示方法，有效地结合了显式和隐式表示的优点。其创新点在于将“定向点”的概念引入距离场，实现了高效的可微分渲染，这对于逆图形和学习框架至关重要。DDFs能够同时提供深度和表面法线，并且通过概率扩展处理不连续性，显著提高了其在复杂场景中的适用性。此外，对视图一致性的理论分析也增强了该表示的鲁棒性。其多功能性和在多个应用中展现的强大性能，使其成为3D计算机视觉领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D形状表示方法在可微分渲染方面存在局限：显式表示易渲染但几何保真度低；隐式表示保真度高但渲染过程复杂低效，限制了可扩展性。

**Method:** 本文提出了定向距离场（DDFs），一种基于经典距离场的新型神经形状表示。DDFs的核心操作是将一个定向点（位置和方向）映射到表面可见性和深度。这使得每个像素只需一次前向传播即可高效地进行可微分渲染以获取深度，并通过额外的反向传播提取微分几何量（如表面法线）。此外，文章引入了概率DDFs（PDDFs）来建模底层场中固有的不连续性。

**Result:** DDFs实现了高效的可微分渲染，每个像素只需一次前向传播即可获得深度，并通过额外的反向传播提取微分几何量。在单形状拟合、生成建模和单图像3D重建等应用中展示了强大的性能，且使用了简单的架构组件。理论研究发现了一小组场属性，足以保证DDF的视图一致性。

**Conclusion:** DDFs作为一种新型神经形状表示，通过其独特的操作方式克服了现有3D形状表示在可微分渲染效率和几何保真度方面的限制。其在多种应用中表现出强大的性能和多功能性，并且通过理论分析确定了保证视图一致性的关键属性。

> **ai_Abstract:** 本文提出了一种名为定向距离场（DDFs）的新型神经3D形状表示方法，旨在解决现有显式和隐式表示在可微分渲染效率和几何保真度方面的权衡问题。DDFs通过将定向点映射到表面可见性和深度，实现了高效的可微分渲染和微分几何量提取。通过引入概率DDFs（PDDFs），该方法能够处理底层场的不连续性。实验证明，DDFs在形状拟合、生成建模和3D重建等任务中表现出色。此外，文章还从理论上分析了保证DDF视图一致性所需的场属性。

> **摘要翻译:** 在现代计算机视觉中，3D形状的最佳表示仍然是任务依赖的。应用于此类表示的基本操作之一是可微分渲染，因为它使得学习框架中的逆图形方法成为可能。标准的显式形状表示（体素、点云或网格）通常易于渲染，但可能存在几何保真度有限等问题。另一方面，隐式表示（占用场、距离场或辐射场）保留了更高的保真度，但渲染过程复杂或效率低下，限制了可扩展性。在这项工作中，我们设计了定向距离场（DDFs），一种基于经典距离场的新型神经形状表示。DDF中的基本操作是将一个定向点（位置和方向）映射到表面可见性和深度。这使得高效的可微分渲染成为可能，每个像素只需一次前向传播即可获取深度，并通过额外的反向传播提取微分几何量（例如，表面法线）。使用概率DDFs（PDDFs），我们展示了如何建模底层场中固有的不连续性。然后，我们将DDFs应用于多个应用，包括单形状拟合、生成建模和单图像3D重建，通过我们表示的多功能性展示了简单的架构组件下的强大性能。最后，由于DDFs的维度允许视图依赖的几何伪影，我们对视图一致性所需的约束进行了理论研究。我们发现了一小组场属性，它们足以保证DDF是一致的，而无需知道该场表示的是哪种形状。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [631] [SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models](https://arxiv.org/abs/2507.14811)
> *SegQuant：一种面向扩散模型的语义感知和通用量化框架*

*Jiaji Zhang, Ruichao Sun, Hailiang Zhao, Jiaju Wu, Peng Chen, Hao Li, Yuying Liu, Kingsum Chow, Gang Xiong, Shuiguang Deng* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 扩散模型, 量化, 后训练量化, 通用性, SegQuant

**Comment:** 

> **TL;DR:** SegQuant是一个新的量化框架，通过结合语义感知和双尺度量化技术，解决了现有扩散模型量化方法通用性差的问题，实现了高性能和广泛适用性。

**AI_Comments:** SegQuant的创新之处在于其统一的框架设计和结合了语义感知(SegLinear)与极性不对称激活保留(DualScale)的策略，这增强了量化方法对不同扩散模型的通用性。其重要性在于为计算密集型扩散模型在实际部署中的应用提供了更高效、更灵活的解决方案，尤其是在资源受限的环境下。通过解决现有PTQ方法通用性差的问题，它有望加速扩散模型在工业界的应用。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型计算量大，难以部署在资源受限或延迟敏感的环境中。现有后训练量化(PTQ)方法对扩散模型而言，通常依赖于特定架构的启发式方法，限制了其通用性，并阻碍了与工业部署流程的集成。

**Method:** 提出了SegQuant，一个统一的量化框架。SegQuant结合了两种互补技术：1) SegLinear，一种段感知、基于图的量化策略，用于捕获结构语义和空间异质性；2) DualScale，一种双尺度量化方案，用于保留对生成输出视觉保真度至关重要的极性不对称激活。

**Result:** SegQuant在Transformer之外的扩散模型中也广泛适用，实现了强大的性能，同时确保与主流部署工具的无缝兼容性。

**Conclusion:** SegQuant通过其统一的框架和自适应技术，成功解决了扩散模型量化中的通用性限制，为在资源受限环境中部署扩散模型提供了高效且兼容的解决方案。

> **ai_Abstract:** SegQuant是一种创新的统一量化框架，旨在解决扩散模型在资源受限环境中部署时的计算密集问题。它通过引入段感知、基于图的SegLinear策略和保留极性不对称激活的双尺度DualScale方案，克服了现有后训练量化方法通用性差的局限性。SegQuant不仅适用于多种扩散模型架构，还能实现高性能并与现有部署工具无缝集成。

> **摘要翻译:** 扩散模型展现出卓越的生成能力，但计算密集，在资源受限或对延迟敏感的环境中部署面临重大挑战。量化提供了一种有效的方法来减小模型大小和计算成本，其中后训练量化（PTQ）因其与预训练模型的兼容性而无需重新训练或训练数据而特别有吸引力。然而，现有用于扩散模型的PTQ方法通常依赖于特定架构的启发式方法，这限制了它们的通用性并阻碍了与工业部署流程的集成。为了解决这些限制，我们提出了SegQuant，一个统一的量化框架，它自适应地结合互补技术以增强跨模型的多功能性。SegQuant包含一个段感知、基于图的量化策略（SegLinear），它捕获结构语义和空间异质性，以及一个双尺度量化方案（DualScale），它保留了极性不对称激活，这对于保持生成输出的视觉保真度至关重要。SegQuant广泛适用于Transformer之外的扩散模型，实现了强大的性能，同时确保与主流部署工具的无缝兼容性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [643] [MMAT-1M: A Large Reasoning Dataset for Multimodal Agent Tuning](https://arxiv.org/abs/2507.21924)
> *MMAT-1M: 一个用于多模态智能体微调的大型推理数据集*

*Tianhong Gao, Yannian Fu, Weiqun Wu, Haixiao Yue, Shanshan Liu, Gang Zhang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 多模态智能体, 大规模数据集, 思维链, 工具使用, GPT-4o

**Comment:** 

> **TL;DR:** MMAT-1M是一个百万级多模态智能体微调数据集，旨在通过支持思维链、反思和动态工具使用来提升多模态大模型的推理和工具能力，并已在多个基准测试中展现出显著性能提升。

**AI_Comments:** MMAT-1M的创新之处在于其百万级的规模和新颖的四阶段数据引擎，特别是利用GPT-4o生成并精炼包含思维链、反思和动态工具使用的多轮对话数据，这为多模态大模型在复杂推理任务中的应用奠定了基础。其引入反思机制来提高逻辑一致性和准确性也很有价值。该数据集的发布有望推动多模态智能体研究的进展。

<details>
  <summary>Details</summary>

**Motivation:** 当前多模态领域缺乏大规模、高质量的智能体微调数据集，以充分释放多模态大语言模型的潜力。

**Method:** MMAT-1M数据集通过一个新颖的四阶段数据引擎构建：1) 整理公开的多模态问答数据集；2) 利用GPT-4o生成原始问答对的推理过程，并通过多轮范式动态整合API调用和RAG信息；3) 通过反思细化推理过程，确保逻辑一致性和准确性，创建包含推理和反思（RR）的多轮对话数据集；4) 可选地将多轮对话压缩成单轮推理和反思（ORR）格式以提高效率。

**Result:** 在MMAT-1M上对开源多模态模型进行微调后，观察到显著的性能提升。例如，InternVL2.5-8B-RR模型在八个公共基准测试中平均提升2.7%，在RAG基准测试Dyn-VQA上提升8.8%。

**Conclusion:** MMAT-1M数据集有效提升了多模态推理和基于工具的能力，证明了其在增强多模态大模型潜力方面的有效性。

> **ai_Abstract:** 本文介绍了MMAT-1M，一个百万级多模态智能体微调数据集，旨在解决多模态领域缺乏大规模高质量智能体微调数据集的问题。该数据集通过一个四阶段数据引擎构建，利用GPT-4o生成并精炼包含思维链、反思和动态工具使用（如API调用和RAG）的多轮对话数据。实验结果表明，在MMAT-1M上微调开源多模态模型（如InternVL2.5-8B-RR）可以显著提升其在多个公共基准测试上的性能，验证了MMAT-1M在增强多模态推理和工具使用能力方面的有效性。

> **摘要翻译:** 大型语言模型（LLMs）通过智能体微调得到增强，在思维链（CoT）和工具利用方面展现出卓越能力，显著超越了独立模型的性能。然而，多模态领域仍缺乏一个大规模、高质量的智能体微调数据集，以充分释放多模态大语言模型的全部潜力。为了弥补这一空白，我们引入了MMAT-1M，这是第一个百万级多模态智能体微调数据集，旨在支持思维链、反思和动态工具使用。我们的数据集通过一个新颖的四阶段数据引擎构建：1) 我们首先整理公开可用的包含问答对的多模态数据集；2) 然后，利用GPT-4o，我们为原始问答对生成推理过程，并通过多轮范式动态整合API调用和检索增强生成（RAG）信息；3) 此外，我们通过反思来细化推理过程，以确保逻辑一致性和准确性，从而创建一个包含推理和反思（RR）的多轮对话数据集；4) 最后，为了提高效率，我们可选择将多轮对话压缩成单轮推理和反思（ORR）格式。通过在MMAT-1M上对开源多模态模型进行微调，我们观察到显著的性能提升。例如，InternVL2.5-8B-RR模型在八个公共基准测试中平均实现了2.7%的改进，在RAG基准测试Dyn-VQA上实现了8.8%的改进，这表明该数据集在增强多模态推理和基于工具的能力方面的有效性。该数据集已在https://github.com/VIS-MPU-Agent/MMAT-1M公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [645] [LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning](https://arxiv.org/abs/2507.13568)
> *LoRA-Loop：弥合合成回放循环以实现持续VLM学习*

*Kaihong Wang, Donghyun Kim, Margrit Betke* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 持续学习, 视觉语言模型, 合成回放, LoRA, Stable Diffusion

**Comment:** 

> **TL;DR:** LoRA-Loop通过将任务特定低秩适配器注入冻结的Stable Diffusion模型，提高了视觉语言模型持续学习中合成回放的保真度，从而解决了现有方法生成样本不匹配的问题。

**AI_Comments:** 该论文的创新之处在于通过LoRA适配器直接对生成模型（Stable Diffusion）进行微调，使其能够为特定任务生成更精准、更高质量的合成数据。这直接解决了现有合成回放方法中样本与领域不匹配的关键问题，对于提升VLM的持续学习能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉语言模型持续学习中的合成回放方法，由于生成器未能捕获领域特定细微差别和细粒度语义，导致生成不匹配的样本，从而误导微调并损害先验知识的保留。

**Method:** 本文提出了一个LoRA增强的合成回放框架，将任务特定的低秩适配器注入冻结的Stable Diffusion模型中，以有效捕获每个新任务独特的视觉和语义模式。具体来说，引入了两阶段、基于置信度的样本选择：首先根据微调后的VLM置信度对真实任务数据进行排序，以将LoRA微调集中在最具代表性的示例上；然后生成合成样本，并再次根据置信度选择它们进行蒸馏。该方法可以无缝集成到现有回放管道中。

**Result:** 在多领域任务增量学习（MTIL）基准上的大量实验表明，该方法优于之前的合成回放技术，在可塑性、稳定性和零样本能力之间实现了最佳平衡。

**Conclusion:** 这些结果表明，通过LoRA进行生成器适应对于视觉语言模型中鲁棒的持续学习是有效的。

> **ai_Abstract:** 本文提出了LoRA-Loop，一个LoRA增强的合成回放框架，旨在解决视觉语言模型（VLM）持续学习中现有合成回放方法因生成器无法捕获领域特异性而导致样本不匹配的问题。LoRA-Loop通过将任务特定的低秩适配器注入到冻结的Stable Diffusion模型中，使其能够为新任务生成更高保真度的合成样本。该框架采用两阶段、基于置信度的样本选择机制，确保LoRA微调和合成样本蒸馏都使用最具代表性的数据。实验结果表明，该方法在MTIL基准测试上优于现有技术，并在模型可塑性、稳定性及零样本能力之间取得了优化平衡，证明了通过LoRA适应生成器对于VLM鲁棒持续学习的有效性。

> **摘要翻译:** 视觉语言模型（VLM）的持续学习通过合成回放取得了显著的性能，其中使用Stable Diffusion生成样本以在微调过程中进行正则化并保留知识。然而，现实世界的下游应用通常表现出生成器无法捕获的领域特定细微差别和细粒度语义，导致合成回放方法产生不匹配的样本，从而误导微调并损害先验知识的保留。在这项工作中，我们提出了一个LoRA增强的合成回放框架，该框架将任务特定的低秩适配器注入冻结的Stable Diffusion模型中，有效地捕获每个新任务独特的视觉和语义模式。具体来说，我们引入了两阶段、基于置信度的样本选择：我们首先根据微调后的VLM置信度对真实任务数据进行排序，以将LoRA微调集中在最具代表性的示例上，然后生成合成样本并再次根据置信度选择它们进行蒸馏。我们的方法可以无缝集成到现有回放管道中——只需替换为适应后的生成器即可提高回放保真度。在多领域任务增量学习（MTIL）基准上的大量实验表明，我们的方法优于之前的合成回放技术，在可塑性、稳定性和零样本能力之间实现了最佳平衡。这些结果表明，通过LoRA进行生成器适应对于VLM中鲁棒的持续学习是有效的。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [650] [The Cooperative Network Architecture: Learning Structured Networks as Representation of Sensory Patterns](https://arxiv.org/abs/2407.05650)
> *协作网络架构：学习结构化网络作为感觉模式的表示*

*Pascal J. Sager, Jan M. Deriu, Benjamin F. Grewe, Thilo Stadelmann, Christoph von der Malsburg* | **Category: cs.CV, cs.AI, cs.LG, cs.NE** | **Updated: 2025-07-30**

**Keywords:** 协作网络架构, 感觉模式, 结构化网络, 无监督学习, 不变对象识别

**Comment:** 

> **TL;DR:** 提出了一种名为协作网络架构 (CNA) 的新模型，它使用可学习的结构化神经网络（称为“网”）来表示感觉信号，能够无监督学习并对噪声和变形具有鲁棒性，为不变对象识别奠定基础。

**AI_Comments:** CNA 的创新之处在于其动态组装和无监督学习“网片段”的能力，这提供了一种新颖的、对噪声和变形具有鲁棒性的感觉模式表示方法。它通过整合局部特征处理与全局结构形成，为解决当前视觉系统中的挑战提供了新的视角，对未来不变对象识别研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉系统在处理噪声、变形和分布外数据时面临挑战。本文从新的角度解决这些问题。

**Method:** 引入了协作网络架构 (CNA)，该模型通过结构化的、循环连接的神经元网络（称为“网”）来表示感觉信号。这些“网”由重叠的“网片段”动态组装而成，这些片段是根据感觉输入的统计规律学习到的。

**Result:** 证明了“网片段”可以无监督地学习，并能灵活地重新组合以编码新模式，从而实现了图形补全和对噪声的弹性。该架构对噪声、变形和分布外数据具有鲁棒性。

**Conclusion:** CNA 是一个有前景的范例，用于开发整合局部特征处理和全局结构形成的神经网络表示，为未来不变对象识别的研究奠定了基础。

> **ai_Abstract:** 本文提出协作网络架构 (CNA)，一种通过学习感觉输入中的统计规律来动态组装重叠“网片段”以形成结构化、循环连接的神经元网络（“网”）的模型。CNA 能够无监督学习，并展示了对噪声、变形和分布外数据的鲁棒性，实现了图形补全。该研究为开发结合局部特征处理和全局结构形成的神经网络表示提供了新范式，有望推动不变对象识别领域的发展。

> **摘要翻译:** 我们引入了协作网络架构（CNA），这是一个使用结构化、循环连接的神经元网络（称为“网”）来表示感觉信号的模型。这些“网”由重叠的“网片段”动态组装而成，这些片段是根据感觉输入的统计规律学习到的。这种架构对噪声、变形和分布外数据具有鲁棒性，从一个新颖的角度解决了当前视觉系统中的挑战。我们证明了“网片段”可以在无监督的情况下学习，并能灵活地重新组合以编码新模式，从而实现了图形补全和对噪声的弹性。我们的发现确立了 CNA 作为一个有前景的范例，用于开发整合局部特征处理和全局结构形成的神经网络表示，为未来不变对象识别的研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [655] [Chain-of-Cooking:Cooking Process Visualization via Bidirectional Chain-of-Thought Guidance](https://arxiv.org/abs/2507.21529)
> *烹饪链：通过双向思维链引导进行烹饪过程可视化*

*Mengling Xu, Ming Tao, Bing-Kun Bao* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 烹饪过程可视化, 图像生成, 思维链, 语义一致性, 上下文连贯性

**Comment:** Accepted by ACM MM 2025

> **TL;DR:** 本文提出Chain-of-Cooking模型，通过动态补丁选择、语义演化模块和双向思维链引导，解决烹饪过程可视化中图像语义不一致和上下文连贯性差的问题，并构建了CookViz数据集。

**AI_Comments:** 这项工作通过引入动态补丁选择和双向思维链引导等创新机制，有效解决了烹饪过程可视化中长期存在的语义不一致和上下文连贯性挑战。构建专门的CookViz数据集也为该领域的研究提供了宝贵资源。其创新点在于从多方面考虑了烹饪过程中图像生成和序列连贯性的复杂性，具有重要的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注生成成品食物图像，但在烹饪过程可视化中面临两大挑战：一是食材外观在不同烹饪步骤中变化多样，难以生成与文本描述匹配的正确外观，导致语义不一致；二是当前步骤可能依赖于前一步操作，难以保持图像序列的上下文连贯性。

**Method:** 本文提出了一个名为Chain-of-Cooking的烹饪过程可视化模型。为生成正确的食材外观，提出了动态补丁选择模块(Dynamic Patch Selection Module)以检索与当前文本内容最相关的先前生成的图像补丁作为参考。为增强生成图像的连贯性和合理顺序，提出了语义演化模块(Semantic Evolution Module)和双向思维链(Bidirectional Chain-of-Thought, CoT)引导。语义演化模块建立潜在提示与当前烹饪步骤之间的语义关联并与潜在特征合并。CoT引导更新合并后的特征以指导当前烹饪步骤与前一步保持连贯。此外，构建了一个包含烹饪过程中间图像-文本对的数据集CookViz。

**Result:** 定量和定性实验表明，该方法在生成连贯且语义一致的烹饪过程方面优于现有方法。

**Conclusion:** 提出的Chain-of-Cooking模型及其组件，通过有效解决烹饪过程可视化中图像语义不一致和上下文连贯性问题，成功实现了高质量的烹饪步骤图像生成。

> **ai_Abstract:** 本文提出Chain-of-Cooking模型，旨在解决烹饪过程可视化中图像语义不一致和上下文连贯性差的问题。通过引入动态补丁选择模块处理外观变化，以及语义演化模块和双向思维链引导来增强序列连贯性，该模型能够为食谱的每个烹饪步骤生成连贯且语义一致的图像。研究还构建了新的CookViz数据集，实验证明了其优于现有方法的性能。

> **摘要翻译:** 烹饪过程可视化是图像生成和食物分析交叉领域中一项很有前景的任务，旨在为食谱的每个烹饪步骤生成一张图像。然而，大多数现有工作侧重于根据给定食谱生成成品食物的图像，并且在可视化烹饪过程时面临两个挑战。首先，食材外观在烹饪步骤中变化多样，难以生成与文本描述匹配的正确食物外观，导致语义不一致。其次，当前步骤可能依赖于前一步的操作，保持图像序列的上下文连贯性至关重要。在这项工作中，我们提出了一个名为Chain-of-Cooking的烹饪过程可视化模型。具体来说，为了生成正确的食材外观，我们提出了一个动态补丁选择模块，用于检索与当前文本内容最相关的先前生成的图像补丁作为参考。此外，为了增强生成图像的连贯性并保持合理的顺序，我们提出了一个语义演化模块和一个双向思维链（CoT）引导。为了更好地利用先前文本的语义，语义演化模块在潜在提示和当前烹饪步骤之间建立语义关联，并将其与潜在特征合并。然后，CoT引导更新合并后的特征，以指导当前烹饪步骤与前一步保持连贯。此外，我们构建了一个名为CookViz的数据集，包含烹饪过程的中间图像-文本对。定量和定性实验表明，我们的方法在生成连贯且语义一致的烹饪过程方面优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [669] [Semantics versus Identity: A Divide-and-Conquer Approach towards Adjustable Medical Image De-Identification](https://arxiv.org/abs/2507.21703)
> *语义与身份：一种面向可调节医学图像去身份化的分而治之方法*

*Yuan Tian, Shuo Wang, Rongzhao Zhang, Zijian Chen, Yankai Jiang, Chunyi Li, Xiangyang Zhu, Fang Yan, Qiang Hu, XiaoSong Wang, Guangtao Zhai* | **Category: cs.CV** | **Updated: 2025-07-25**

**Keywords:** 医学图像去身份化, 隐私保护, 语义保留, 分而治之, 医学基础模型

**Comment:** Accepted to ICCV2025;

> **TL;DR:** 本文提出一种分而治之的框架，通过身份阻断和医学语义补偿来解决医学图像去身份化问题，同时实现可调节的隐私保护和语义保留，并达到最先进的性能。

**AI_Comments:** 该论文的创新之处在于其“分而治之”的两步方法，明确地将身份阻断与语义补偿分离开来。利用医学基础模型进行语义保留以及基于最小描述长度（MDL）原理的特征解耦策略，以鲁棒地从语义特征中去除身份信息，是重要的进展。这种方法提供了灵活的隐私级别，解决了先前工作的一个关键局限性。鉴于医疗数据共享和人工智能发展中对隐私日益增长的需求，其重要性很高。

<details>
  <summary>Details</summary>

**Motivation:** 医学成像在计算机辅助诊断中取得显著进展，但其再识别（ReID）风险引发了严重的隐私担忧，因此需要去身份化（DeID）技术。然而，现有去身份化方法既不能有效保留医学语义，也无法灵活调整以适应不同的隐私级别。

**Method:** 本文提出一个分而治之的框架，包括两个步骤：1) 身份阻断，通过阻断不同比例的身份相关区域以实现不同的隐私级别；2) 医学语义补偿，利用预训练的医学基础模型（MFMs）提取医学语义特征来补偿被阻断的区域。此外，考虑到MFMs的特征可能仍包含残余身份信息，作者引入了一种基于最小描述长度（MDL）原理的特征解耦策略，以有效解耦并去除这些身份成分。

**Result:** 在七个数据集和三个下游任务上对现有方法进行了广泛评估，结果表明本文方法达到了最先进的性能。

**Conclusion:** 本文提出的分而治之框架，通过身份阻断、医学语义补偿以及基于MDL的特征解耦策略，有效解决了医学图像去身份化中语义保留和隐私级别可调节性问题，并在多项评估中展现出最先进的性能。

> **ai_Abstract:** 本文提出一种新颖的“分而治之”框架，用于医学图像去身份化，旨在克服现有方法在语义保留和隐私级别可调节性方面的局限。该框架包含两个主要步骤：身份阻断，用于通过遮蔽身份相关区域来控制隐私级别；以及医学语义补偿，利用医学基础模型（MFMs）来恢复医学信息。此外，为消除MFM特征中可能残余的身份信息，研究引入了一种基于最小描述长度原理的特征解耦策略。在七个数据集和三个下游任务上的广泛评估表明，该方法表现出卓越的性能，为在保留诊断效用的同时保护医学图像隐私提供了强大的解决方案。

> **摘要翻译:** 医学成像极大地推动了计算机辅助诊断的发展，然而其再识别（ReID）风险引发了关键的隐私担忧，需要去身份化（DeID）技术。不幸的是，现有去身份化方法既不能特别保留医学语义，也无法灵活调整以适应不同的隐私级别。为了解决这些问题，我们提出了一个分而治之的框架，包括两个步骤：(1) 身份阻断，该步骤阻断不同比例的身份相关区域，以实现不同的隐私级别；以及(2) 医学语义补偿，该步骤利用预训练的医学基础模型（MFMs）提取医学语义特征来补偿被阻断的区域。此外，认识到MFMs的特征可能仍然包含残余身份信息，我们引入了一种基于最小描述长度原理的特征解耦策略，以有效解耦并丢弃这些身份成分。在七个数据集和三个下游任务上对现有方法进行了广泛评估，证明了我们达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [672] [DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation](https://arxiv.org/abs/2507.13985)
> *梦境场景：基于3D高斯的端到端文本到3D场景生成*

*Haoran Li, Yuli Tian, Kun Lan, Yong Liao, Lin Wang, Pan Hui, Peng Yuan Zhou* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 3D场景生成, 文本到3D, 3D高斯, GPT-4, 端到端系统

**Comment:** Extended version of ECCV 2024 paper "DreamScene"

> **TL;DR:** DreamScene是一个基于3D高斯的端到端框架，能从文本生成高质量、可编辑的3D场景，解决了现有方法的自动化、一致性和精细控制问题。

**AI_Comments:** DreamScene的创新之处在于其端到端集成和多模态方法，特别是结合GPT-4进行智能场景规划，以及使用3D高斯表示和优化的采样策略来提高生成质量和一致性。它解决了现有方法在自动化、一致性和精细控制方面的痛点，尤其是在支持精细场景编辑方面，大大提高了实用性，对游戏、电影和设计等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在从自然语言生成3D场景时，面临自动化、3D一致性和精细控制方面的挑战。

**Method:** DreamScene是一个端到端的框架，包含：1) 场景规划模块，使用GPT-4代理推断对象语义和空间约束构建混合图；2) 基于图的放置算法生成无碰撞布局；3) 形成模式采样（FPS）通过多时间步采样和重建优化生成对象几何体；4) 渐进式相机采样策略确保全局一致性。系统还支持精细场景编辑。

**Result:** 实验证明DreamScene在质量、一致性和灵活性方面超越了现有方法。

**Conclusion:** DreamScene为开放域3D内容创建提供了一个实用的解决方案。

> **ai_Abstract:** DreamScene是一个创新的端到端框架，旨在解决当前文本到3D场景生成中自动化、一致性和控制的难题。它利用GPT-4进行场景规划和图基放置算法创建无碰撞布局，并通过形成模式采样（FPS）和渐进式相机采样生成高质量的3D对象几何体和全局一致的场景。该系统还支持精细的场景编辑功能，并在实验中展现出优于现有方法的质量、一致性和灵活性，为3D内容创建提供了实用的解决方案。

> **摘要翻译:** 从自然语言生成3D场景在游戏、电影和设计等应用中具有巨大潜力。然而，现有方法在自动化、3D一致性和精细控制方面存在困难。我们提出了DreamScene，一个用于从文本或对话生成高质量和可编辑3D场景的端到端框架。DreamScene首先包含一个场景规划模块，其中GPT-4代理推断对象语义和空间约束以构建混合图。然后，基于图的放置算法生成结构化、无碰撞的布局。在此布局的基础上，形成模式采样（FPS）利用多时间步采样和重建优化生成对象几何体，从而实现快速逼真的合成。为了确保全局一致性，DreamScene采用了针对室内和室外设置的渐进式相机采样策略。最后，该系统支持精细的场景编辑，包括对象移动、外观变化和4D动态运动。实验表明，DreamScene在质量、一致性和灵活性方面超越了现有方法，为开放域3D内容创建提供了一个实用的解决方案。代码和演示可在https://jahnsonblack.github.io/DreamScene-Full/ 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [677] [Attention-Driven Multimodal Alignment for Long-term Action Quality Assessment](https://arxiv.org/abs/2507.21945)
> *长期动作质量评估中的注意力驱动多模态对齐*

*Xin Wang, Peng-Jie Li, Yuan-Yuan Shen* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 动作质量评估, 多模态对齐, 注意力机制, 长期视频分析, LMAC-Net

**Comment:** Accepted to Applied Soft Computing

> **TL;DR:** 针对长期动作质量评估中现有方法无法有效处理多模态信息和时间动态的问题，本文提出了LMAC-Net，通过多模态注意力一致性机制，显著提升了评估效果。

**AI_Comments:** 这篇论文的创新点在于提出了LMAC-Net，特别是其多模态注意力一致性机制，这对于解决长期视频中视觉与音频信息深度融合和时间动态捕捉的挑战至关重要。该方法通过显式对齐和两级评估，提升了模型的解释性和性能，对于艺术体育等领域的自动化评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有长期动作质量评估方法未能有效融合视觉和音频等多模态信息，且难以捕捉模态间的深层协作和长时间序列中的动态变化，导致评估精度不足，尤其在艺术体育项目中无法准确评估动作执行和音乐同步。

**Method:** 提出了长期多模态注意力一致性网络（LMAC-Net）。该网络引入多模态注意力一致性机制，显式对齐多模态特征，实现视觉和音频信息的稳定集成并增强特征表示。具体而言，它包含一个多模态局部查询编码器模块以捕获时间语义和跨模态关系，并采用两级分数评估以提供可解释的结果。此外，结合注意力损失和回归损失共同优化多模态对齐和分数融合。

**Result:** 在RG和Fis-V数据集上的实验表明，LMAC-Net显著优于现有方法，验证了所提方法的有效性。

**Conclusion:** LMAC-Net通过创新的多模态注意力一致性机制，有效解决了长期动作质量评估中多模态信息融合和时间动态捕捉的挑战，显著提升了评估性能。

> **ai_Abstract:** 本文针对长期动作质量评估中现有方法无法有效融合多模态信息及捕捉时间动态的问题，提出了一种新型的长期多模态注意力一致性网络（LMAC-Net）。LMAC-Net通过引入多模态注意力一致性机制，实现了视觉和音频特征的深度对齐与融合，并通过多模态局部查询编码器和两级分数评估增强了模型能力。实验证明，LMAC-Net在多个数据集上显著优于现有方法，验证了其在复杂动作质量评估中的有效性。

> **摘要翻译:** 长期动作质量评估（AQA）侧重于评估长达数分钟视频中人类活动的质量。这项任务在艺术体育（如艺术体操和花样滑冰）的自动化评估中发挥着重要作用，其中准确的动作执行和与背景音乐的时间同步对于表现评估至关重要。然而，现有方法主要分为两类：一类是仅依赖视觉特征的单模态方法，不足以建模音乐等多模态线索；另一类是通常采用简单特征级对比融合的多模态方法，忽略了深层跨模态协作和时间动态。因此，它们难以捕捉模态之间复杂的交互，并且无法在扩展序列中准确跟踪关键的性能变化。为了解决这些挑战，我们提出了长期多模态注意力一致性网络（LMAC-Net）。LMAC-Net引入了一种多模态注意力一致性机制，以显式对齐多模态特征，从而实现视觉和音频信息的稳定集成并增强特征表示。具体而言，我们引入了一个多模态局部查询编码器模块来捕获时间语义和跨模态关系，并使用两级分数评估来获得可解释的结果。此外，应用基于注意力和基于回归的损失来共同优化多模态对齐和分数融合。在RG和Fis-V数据集上进行的实验表明，LMAC-Net显著优于现有方法，验证了我们所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [681] [Analyzing the Sensitivity of Vision Language Models in Visual Question Answering](https://arxiv.org/abs/2507.21335)
> *视觉问答中视觉语言模型敏感性分析*

*Monika Shah, Sudarshan Balaji, Somdeb Sarkhel, Sanorita Dey, Deepak Venugopal* | **Category: cs.CV** | **Updated: 2025-07-28**

**Keywords:** 视觉语言模型, 视觉问答, 格莱斯会话准则, 敏感性分析, 模型局限性

**Comment:** 

> **TL;DR:** 研究发现，当问题中添加修饰语违反格莱斯会话准则时，最先进的视觉语言模型（VLMs）的表现会下降，这表明它们在处理类似人类的会话细微差别方面存在局限性。

**AI_Comments:** 这篇论文通过引入格莱斯会话准则来评估视觉语言模型（VLMs）的敏感性，提供了一个新颖的视角。通过在问题中添加修饰语来模拟对准则的违反，这种方法能够深入揭示VLMs在处理复杂、非直接语言方面的局限性，这对于提升VLMs的鲁棒性和类人理解能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文的动机是探讨视觉语言模型（VLMs）在处理违反格莱斯会话准则的对话时的敏感性，并研究VLMs是否能像人类一样处理这些违反。

**Method:** 研究通过向人工制作的问题中添加修饰语来分析视觉语言模型（VLMs）的响应。实验使用了GPT-4o、Claude-3.5-Sonnet和Gemini-1.5-Flash这三个最先进的VLM，并基于VQA v2.0数据集中的问题进行。

**Result:** 初步结果表明，随着修饰语的增加，视觉语言模型的性能持续下降。

**Conclusion:** 这种研究方法是理解视觉语言模型局限性的一个有前景的方向。

> **ai_Abstract:** 本文探讨了视觉语言模型（VLMs）在视觉问答中对会话细微差别的敏感性，特别是当问题违反格莱斯会话准则时。研究通过向VQA v2.0数据集中的问题添加修饰语，测试了GPT-4o、Claude-3.5-Sonnet和Gemini-1.5-Flash这三种先进VLM的性能。初步结果显示，添加修饰语导致VLMs的性能持续下降，这表明当前VLMs在处理此类非合作性语境时存在局限性，并为未来理解其能力边界提供了方向。

> **摘要翻译:** 我们可以将视觉问答视为人与AI系统之间的一种（多模态）对话。本文通过格莱斯提出的会话合作原则来探讨视觉语言模型（VLMs）的敏感性。具体来说，即使格莱斯会话准则被违反，人类通常也能理解对话，尽管这需要更多的认知努力。在此，我们研究VLMs是否能够以类似于人类的方式处理对格莱斯准则的违反。具体而言，我们向人工制作的问题中添加修饰语，并分析VLMs对这些修饰语的响应。在我们的研究中，我们使用了三个最先进的VLMs，即GPT-4o、Claude-3.5-Sonnet和Gemini-1.5-Flash，对来自VQA v2.0数据集的问题进行测试。我们的初步结果似乎表明，随着修饰语的增加，VLMs的性能持续下降，这表明我们的方法是理解VLMs局限性的一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [685] [Geometric Algebra Meets Large Language Models: Instruction-Based Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes](https://arxiv.org/abs/2408.02275)
> *几何代数与大型语言模型：3D、交互式和可控场景中独立网格的指令式变换*

*Prodromos Kolyvakis, Manos Kamarianakis, George Papagiannakis* | **Category: cs.CV, cs.AI, cs.GR** | **Updated: 2025-07-29**

**Keywords:** 几何代数, 大型语言模型, 3D场景编辑, 物体重定位, 零样本学习

**Comment:** 10 pages, 4 figures

> **TL;DR:** 本文将几何代数与大型语言模型结合，提出Shenlong系统，通过自然语言指令实现精确的3D场景物体重定位，无需特定训练，显著提升效率和成功率。

**AI_Comments:** 这项研究的创新之处在于它将共形几何代数（CGA）作为一种精确的形式化语言与大型语言模型（LLMs）的自然语言理解能力相结合，解决了传统3D场景编辑中对专业知识和大量训练数据的依赖问题。通过提供一种指令式的、可控的3D物体变换方法，Shenlong系统在效率和精度上都取得了显著提升，尤其是在零样本学习能力和100%成功率方面表现突出。这对于普及3D内容创作、降低技术门槛具有重要意义，在教育、娱乐和虚拟现实等领域具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 传统的3D场景编辑（特别是物体重定位）需要复杂的手动操作和专业知识，且依赖大量训练数据或缺乏形式化语言进行精确编辑。

**Method:** 本文将大型语言模型（LLMs）与共形几何代数（CGA）结合，开发了Shenlong系统。CGA作为形式化语言精确建模空间变换，LLMs利用零样本学习将自然语言指令转换为CGA操作，应用于3D场景以实现精确空间变换。该系统在仿真环境中实现，并兼容现有图形管线。

**Result:** Shenlong系统将LLM响应时间缩短16%，平均成功率提高9.6%。在常见实际查询中，Shenlong达到了100%的完美成功率，而其他系统未能达到。

**Conclusion:** Shenlong系统通过结合几何代数和大型语言模型，显著提升了3D场景编辑的效率和精度，尤其在物体重定位方面表现出色，有望普及3D场景编辑，促进教育、数字娱乐和虚拟现实等领域创新。

> **ai_Abstract:** 本文提出Shenlong系统，将大型语言模型（LLMs）与共形几何代数（CGA）相结合，以实现通过自然语言指令对3D场景中的物体进行精确重定位。该系统利用CGA作为强大的形式化语言进行空间变换建模，并借助LLMs的零样本学习能力，将自然语言指令转化为可执行的CGA操作。实验结果表明，Shenlong显著缩短了LLM响应时间，提高了成功率，并在特定查询中实现了100%的成功率，有望使3D场景编辑更加普及和高效。

> **摘要翻译:** 本文介绍了一种大型语言模型（LLMs）与共形几何代数（CGA）的新颖集成，旨在彻底改变可控3D场景编辑，特别是物体重定位任务。传统上，这些任务需要复杂的手动过程和专业知识。这些传统方法通常依赖于大型训练数据集，或者缺乏用于精确编辑的形式化语言。
我们的系统Shenlong利用CGA作为一种强大的形式化语言，精确建模了物体准确定位所需的空间变换。Shenlong利用预训练LLM的零样本学习能力，将自然语言指令转换为CGA操作，然后将其应用于场景，从而在无需专门预训练的情况下，促进3D场景内的精确空间变换。
Shenlong在逼真的模拟环境中实现，确保与现有图形管线的兼容性。为了准确评估CGA的影响，我们与强大的欧几里得空间基线进行了基准测试，评估了延迟和准确性。比较性能评估表明，与传统方法相比，Shenlong将LLM响应时间显著缩短了16%，平均成功率提高了9.6%。值得注意的是，Shenlong在常见的实际查询中实现了100%的完美成功率，这是其他系统未能达到的基准。这些进展强调了Shenlong普及3D场景编辑的潜力，增强了教育、数字娱乐和虚拟现实等领域的访问性并促进了创新。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [686] [Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis](https://arxiv.org/abs/2507.17860)
> *通过生成式AI图像合成促进AI皮肤病变分类器的公平性评估*

*Ko Watanabe, Stanislav Frolov, Adriano Lucieri, Andreas Dengel* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 生成式AI, 公平性评估, 皮肤病变分类器, 合成数据, 偏见

**Comment:** 

> **TL;DR:** 本文利用生成式AI合成图像来评估AI皮肤病变分类器的公平性，发现合成数据评估有前景，但模型训练数据与合成数据基础不一致时评估会遇到困难。

**AI_Comments:** 本文创新性地提出利用生成式AI合成图像来解决AI公平性评估中数据代表性不足的挑战。这一方法在医疗AI领域具有重要意义，尤其是在隐私保护和数据稀缺的情况下。然而，研究也指出了其局限性，即合成数据与模型训练数据不一致时可能影响评估效果，这提示未来研究需关注合成数据的泛化性和适用性。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在皮肤癌筛查中潜力巨大，但其固有的偏见可能带来潜在危险。因此，评估和改进这些系统的公平性至关重要。公平性评估的一个关键挑战是确保评估数据集能够充分代表不同个人身份信息（PII）和少数群体。

**Method:** 本研究利用最先进的生成式AI (GenAI) 模型LightningDiT来合成高度逼真的图像，并使用这些合成数据评估公开可用的黑色素瘤分类器的公平性。

**Result:** 结果表明，使用高度逼真的合成数据进行公平性评估是一个有前景的方向。然而，研究发现，当用于评估的黑色素瘤检测模型所训练的数据与合成图像基础数据集不同时，验证公平性变得困难。

**Conclusion:** 尽管存在挑战，但研究提出，所提出的方法为利用合成数据衡量和增强医学影像GenAI系统中的公平性提供了一条有价值的新途径。

> **ai_Abstract:** 本文针对AI皮肤病变分类器存在的偏见问题，提出利用生成式AI（GenAI）模型LightningDiT合成逼真图像来评估其公平性。研究发现，使用合成数据进行公平性评估具有前景，但如果评估模型训练数据与合成图像的基础数据不一致，则公平性验证会变得困难。尽管如此，该方法为医学影像GenAI系统的公平性评估和增强提供了一条新途径。

> **摘要翻译:** 深度学习及其在边缘设备上的应用在彻底改变黑色素瘤等皮肤癌的常规筛查方面具有巨大潜力。伴随这项技术带来的预期益处，意想不到的内在偏见也带来了潜在危险。因此，评估和改进此类系统的公平性至关重要。公平性评估的一个关键挑战是确保评估数据集充分代表不同的个人身份信息（PII）（性别、年龄和种族）和其他少数群体。在此背景下，本研究利用最先进的生成式AI（GenAI）LightningDiT模型来评估公开可用的黑色素瘤分类器的公平性。结果表明，使用高度逼真的合成数据进行公平性评估是一个有前景的方向。然而，我们的发现表明，当用于评估的黑色素瘤检测模型所训练的数据与合成图像基础数据集不同时，验证公平性变得困难。尽管如此，我们提出我们的方法为利用合成数据衡量和增强医学影像GenAI系统中的公平性提供了一条有价值的新途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [700] [From Semantics, Scene to Instance-awareness: Distilling Foundation Model for Open-vocabulary Situation Recognition](https://arxiv.org/abs/2507.14686)
> *从语义、场景到实例感知：为开放词汇情境识别蒸馏基础模型*

*Chen Cai, Tianyi Liu, Jianjun Gao, Wenyang Liu, Kejun Wu, Ruoyu Wang, Yi Wang, Soo Chin Liew* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 开放词汇情境识别, 知识蒸馏, 多模态大语言模型, 泛化能力, 零样本学习

**Comment:** 

> **TL;DR:** 本文提出MIPD框架，通过从大型多模态模型蒸馏知识，显著提升小型模型在开放词汇情境识别中对未知和稀有情境的泛化和零样本能力。

**AI_Comments:** 这篇论文通过知识蒸馏的方式，有效地将大型多模态模型的强大能力迁移到轻量级模型上，解决了边缘设备部署的资源限制问题。其创新点在于引入了多模态交互提示蒸馏（MIPD）框架，特别是利用LLM生成判断性理由和通过负向引导实现多模态知识对齐，这为提升模型对开放词汇和稀有情境的理解提供了新思路。该方法在泛化能力和处理未见情境方面表现突出，对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态大语言模型（MLLMs）在复杂接地情境识别（GSR）上表现不佳且资源密集，不适合边缘设备部署；而传统GSR模型泛化能力差，无法识别未见和稀有情境。

**Method:** 本文提出多模态交互提示蒸馏（MIPD）框架，旨在将基础模型知识蒸馏到小型Ov-GSR模型。具体步骤包括：首先，利用基于LLM的判断性理由生成器（JRG）构建富含上下文语义的正负视觉和注视理由；其次，引入场景感知和实例感知提示，通过负向引导多模态提示对齐（NMPA）模块将理由与MLLM教师模型的视觉信息对齐；最后，将对齐后的多模态知识蒸馏到学生Ov-GSR模型中，以增强其泛化能力和情境理解。

**Result:** MIPD在改进的Ov-SWiG数据集上对已见、稀有和未见情境均实现了卓越性能，并在HICO-DET数据集上展示了改进的未见检测能力。

**Conclusion:** 通过知识蒸馏，本文提出的MIPD框架成功地将大型多模态模型的知识转移到小型模型中，显著提升了其在开放词汇情境识别任务中的泛化能力和对未见/稀有情境的理解，有效弥补了已知与未知场景之间的差距并减轻了预测偏差。

> **ai_Abstract:** 本文针对多模态大语言模型在情境识别中资源密集和传统模型泛化能力不足的问题，提出了开放词汇接地情境识别（Ov-GSR）任务。为此，作者引入了多模态交互提示蒸馏（MIPD）框架，通过利用LLM生成理由并与MLLM教师模型的视觉信息对齐，将丰富的多模态知识蒸馏到小型GSR模型中。实验结果表明，MIPD在处理已见、稀有和未见情境时表现出色，显著提升了模型的泛化能力和情境理解。

> **摘要翻译:** 近期多模态大语言模型（MLLMs）展现出强大的零样本能力，但在复杂的接地情境识别（GSR）方面表现不佳，且在边缘设备部署时资源密集。同时，传统GSR模型通常缺乏泛化能力，在识别未见和稀有情境时表现不足。本文中，我们利用从教师MLLM向小型GSR模型转移知识来增强其泛化和零样本能力，从而引入了开放词汇接地情境识别（Ov-GSR）任务。为此，我们提出了一种新颖的框架——多模态交互提示蒸馏（MIPD），该框架从基础模型中蒸馏丰富的多模态知识，使学生Ov-GSR模型能够识别未见情境并更好地感知稀有情境。具体来说，MIPD框架首先利用基于LLM的判断性理由生成器（JRG）构建富含上下文语义信息的正负瞥视和注视理由。然后，引入所提出的场景感知和实例感知提示，通过负向引导多模态提示对齐（NMPA）模块将理由与MLLM教师的视觉信息对齐，从而有效地捕获整体和感知的多模态知识。最后，将对齐的多模态知识蒸馏到学生Ov-GSR模型中，为其泛化提供更强的基础，从而增强情境理解，弥合已见和未见场景之间的差距，并减轻稀有情况下的预测偏差。我们在改进的Ov-SWiG数据集上评估了MIPD，在已见、稀有和未见情境上均取得了卓越的性能，并进一步展示了在HICO-DET数据集上未见检测的改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [703] [Texture, Shape, Order, and Relation Matter: A New Transformer Design for Sequential DeepFake Detection](https://arxiv.org/abs/2404.13873)
> *纹理、形状、顺序和关系很重要：一种用于序列深度伪造检测的新型Transformer设计*

*Yunfei Li, Yuezun Li, Baoyuan Wu, Junyu Dong, Guopu Zhu, Siwei Lyu* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 序列深度伪造检测, Transformer, 纹理, 形状, 操作顺序

**Comment:** An extension of WACV 2025 (Oral)

> **TL;DR:** 本文提出了一种名为TSOM的新型Transformer设计，用于序列深度伪造检测，通过关注纹理、形状和操作顺序来提高性能。TSOM++进一步探索了操作之间的关系。

**AI_Comments:** 本文的创新点在于从纹理、形状、操作顺序和操作关系等多个维度深入分析并设计了针对序列深度伪造检测的Transformer架构，特别是引入了多样化像素差异注意力、多源交叉注意力、形状引导高斯映射以及反向预测顺序，这些都为该领域的检测精度带来了显著提升。TSOM++通过序列对比学习进一步捕获操作间的复杂关系，显示了其全面性。该工作为深度伪造检测领域提供了新的思路和有效工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的序列深度伪造检测方法通常将问题表述为图像到序列的问题，并使用传统的Transformer架构，但这些方法缺乏专门的设计，导致性能有限。

**Method:** 本文提出了一种名为TSOM的新型Transformer设计，从纹理、形状和操作顺序三个角度进行探索。TSOM包含四个主要改进：1) 一个新的纹理感知分支，采用多样化像素差异注意力模块捕获细微操作痕迹；2) 一个多源交叉注意力模块，用于寻找空间和序列特征之间的深层关联；3) 一个形状引导高斯映射策略，为操作形状提供初始先验；4) 将预测顺序从正向反转为反向。在此基础上，扩展方法TSOM++额外探索了操作之间的关系，并提出了一个新的序列对比学习方案来捕获序列中各种操作类型之间的关系。

**Result:** 通过与几种最先进方法的广泛实验比较，证明了我们方法的优越性。

**Conclusion:** 本文提出的TSOM及其扩展TSOM++在序列深度伪造检测任务中表现出优越的性能，有效解决了现有方法设计不足的问题，并通过关注纹理、形状、顺序和关系显著提高了检测能力。

> **ai_Abstract:** 本文提出了一种名为TSOM的新型Transformer设计，用于解决序列深度伪造检测中现有方法性能受限的问题。TSOM通过引入纹理感知分支、多源交叉注意力、形状引导高斯映射和反向预测顺序来提升检测能力。在此基础上，TSOM++进一步通过序列对比学习探索操作之间的关系。实验结果表明，该方法优于现有的最先进方法。

> **摘要翻译:** 序列深度伪造检测是一项新兴任务，它按顺序预测操作序列。现有方法通常将其表述为图像到序列的问题，采用传统的Transformer架构。然而，这些方法缺乏专门的设计，因此性能有限。因此，本文通过探索操作的纹理、形状和顺序三个视角，描述了一种名为{TSOM}的新型Transformer设计。我们的方法具有四个主要改进：1) 我们描述了一个新的纹理感知分支，它采用多样化像素差异注意力模块有效捕获细微的操作痕迹。2) 然后我们引入一个多源交叉注意力模块，以寻求空间和序列特征之间的深度相关性，从而能够有效建模复杂的操作痕迹。3) 为了进一步增强交叉注意力，我们描述了一种形状引导高斯映射策略，提供操作形状的初始先验。4) 最后，观察到序列中的后续操作可能会影响前一个操作中留下的痕迹，我们巧妙地将预测顺序从正向反转为反向，从而获得了预期的显著增益。在TSOM的基础上，我们引入了一种扩展方法{TSOM++}，它额外探索了操作的关系：5) 我们提出了一种新的序列对比学习方案来捕获序列中各种操作类型之间的关系，进一步增强了操作痕迹的检测。我们与几种最先进的方法进行了广泛的实验比较，证明了我们方法的优越性。代码已在https://github.com/OUC-VAS/TSOM发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [713] [Enhancing Generalization in Data-free Quantization via Mixup-class Prompting](https://arxiv.org/abs/2507.21947)
> *通过混合类提示增强无数据量化的泛化能力*

*Jiwoong Park, Chaeun Lee, Yongseok Choi, Sein Park, Deokki Hong, Jungwook Choi* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 无数据量化, 混合类提示, 泛化能力, 低比特量化, 后训练量化

**Comment:** 

> **TL;DR:** 本文提出了一种名为“混合类提示”的新型文本提示策略，用于无数据量化（DFQ）。该方法通过融合多个类别标签生成多样化、鲁棒的合成数据，从而增强了量化模型的泛化能力和优化稳定性，并在低比特量化场景中取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了“混合类提示”策略，巧妙地解决了无数据量化中合成数据生成的多义性问题，从而显著提升了量化模型的泛化能力和优化稳定性。这一方法对于在隐私受限或数据稀缺场景下部署高效的量化模型具有重要意义，尤其在推动极低比特量化性能方面展现出巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 后训练量化（PTQ）在校准数据有限（尤其是在隐私约束下）时面临挑战。无数据量化（DFQ）通过生成合成图像来缓解此问题，但合成图像与量化模型泛化能力之间的关系尚未得到充分探索。现有的基于单类别提示的合成图像生成方法存在多义性问题，导致性能下降。

**Method:** 提出了一种名为“混合类提示”（mixup-class prompt）的混淆（mixup）文本提示策略。该策略在文本提示级别融合多个类别标签，以生成多样化、鲁棒的合成数据。通过梯度范数和泛化误差分析提供了定量见解。

**Result:** 在卷积神经网络（CNNs）和视觉Transformer（ViTs）上的实验表明，所提方法始终优于现有最先进的DFQ方法（如GenQ）。此外，它在极低比特场景中提升了性能边界，在具有挑战性的2比特权重、4比特激活（W2A4）量化中达到了新的最先进精度。

**Conclusion:** 所提出的混合类提示方法通过生成多样化、鲁棒的合成数据，显著增强了无数据量化中量化模型的泛化能力和优化稳定性，尤其在极低比特量化场景中取得了突破性的性能。

> **ai_Abstract:** 本文针对无数据量化（DFQ）中合成图像泛化能力不足的问题，提出了一种名为“混合类提示”的新型文本提示策略。该方法通过在文本提示层面融合多个类别标签来生成多样化、鲁棒的合成数据，有效解决了传统单类别提示的多义性问题。实验结果表明，该方法显著增强了量化模型的泛化能力和优化稳定性，并在CNN和ViT上均优于现有最先进的DFQ方法，尤其在2比特权重、4比特激活等极低比特量化场景中取得了创纪录的精度。

> **摘要翻译:** 后训练量化（PTQ）提高了效率，但在校准数据有限的情况下，尤其是在隐私约束下，面临挑战。无数据量化（DFQ）通过使用生成模型（如生成对抗网络（GANs）和文本条件潜在扩散模型（LDMs））生成合成图像来缓解此问题，同时应用现有的PTQ算法。然而，生成的合成图像与PTQ期间量化模型泛化能力之间的关系仍未得到充分探索。在不研究这种关系的情况下，先前基于单类别提示的提示工程方法生成的合成图像存在多义性等问题，导致性能下降。我们提出了混合类提示（mixup-class prompt），这是一种基于混合的文本提示策略，可在文本提示级别融合多个类别标签，以生成多样化、鲁棒的合成数据。这种方法增强了泛化能力，并提高了PTQ中的优化稳定性。我们通过梯度范数和泛化误差分析提供了定量见解。在卷积神经网络（CNNs）和视觉Transformer（ViTs）上的实验表明，我们的方法始终优于最先进的DFQ方法，如GenQ。此外，它在极低比特场景中推动了性能边界，在具有挑战性的2比特权重、4比特激活（W2A4）量化中实现了新的最先进精度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [714] [Fuse Before Transfer: Knowledge Fusion for Heterogeneous Distillation](https://arxiv.org/abs/2410.12342)
> *先融合再迁移：异构蒸馏中的知识融合*

*Guopeng Li, Qiang Wang, Ke Yan, Shouhong Ding, Yuan Gao, Gui-Song Xia* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 知识蒸馏, 异构蒸馏, 跨架构知识蒸馏, 特征融合, InfoNCE损失

**Comment:** Accepted by ICCV2025

> **TL;DR:** 本文提出了一种名为“先融合再迁移”（Fuse Before Transfer）的异构知识蒸馏方法，通过引入一个融合卷积和注意力模块的辅助模型作为桥梁，并结合空间无关的InfoNCE损失，有效解决了异构模型间特征差异大的问题，并在CIFAR-100和ImageNet-1K上取得了SOTA性能。

**AI_Comments:** 该论文在知识蒸馏领域具有重要创新。它解决了当前KD方法主要集中于同构架构的局限性，通过引入一个巧妙设计的辅助模型，有效地弥合了异构模型之间的特征鸿沟。辅助模型融合卷积和注意力模块的设计，以及采用空间无关的InfoNCE损失来解决空间分布差异，都是其核心创新点。这使得知识可以在不同类型的神经网络（如CNN、ViT、MLP）之间高效地迁移，极大地扩展了知识蒸馏的应用范围和灵活性。其在多个数据集上取得的显著性能提升也验证了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 大多数知识蒸馏（KD）方法主要集中在架构相似的教师-学生对上。然而，通过扩展到跨架构KD（CAKD），即知识可以灵活地从同构和异构教师转移到给定学生，可以大大提高KD的潜力和灵活性。CAKD的主要挑战在于异构模型之间存在显著的特征差距，这源于它们固有的归纳偏置和模块功能的区别。

**Method:** 为了解决异构模型间的特征差距，本文引入了一个辅助模型作为桥梁，以促进异构教师和学生之间平滑的特征知识迁移。该辅助模型通过融合来自学生和教师模块功能的卷积和注意力模块，结合了跨架构归纳偏置和模块功能的优势。此外，针对异构特征在CAKD中表现出不同的空间分布，阻碍了传统像素级均方误差（MSE）损失的有效性，本文利用空间无关的InfoNCE损失在空间平滑后对齐特征，从而改善了CAKD中的特征对齐。

**Result:** 所提出的方法在一些同构模型对以及CNN、ViT和MLP的任意异构组合上进行了评估。结果显示，蒸馏模型取得了最先进的性能，在CIFAR-100上最大增益达到11.47%，在ImageNet-1K上最大增益达到3.67%。

**Conclusion:** 本文通过引入一个融合卷积和注意力模块的辅助模型，并采用空间无关的InfoNCE损失来处理异构特征对齐，成功克服了异构知识蒸馏中的挑战，显著提高了不同架构模型间知识迁移的效率和性能。

> **ai_Abstract:** 本文提出了一种名为“先融合再迁移”的跨架构知识蒸馏（CAKD）方法，旨在解决异构模型间巨大的特征差距。该方法引入了一个辅助模型作为桥梁，该模型通过融合卷积和注意力模块，结合了不同架构的归纳偏置和模块功能。同时，为了应对异构特征多样化的空间分布，该方法采用空间无关的InfoNCE损失进行特征对齐。实验结果表明，该方法在同构和异构模型组合上均实现了最先进的性能，在CIFAR-100和ImageNet-1K上分别获得了显著的性能提升。

> **摘要翻译:** 大多数知识蒸馏（KD）方法主要集中在架构相似的教师-学生对上，例如都为卷积神经网络（CNN）。然而，通过扩展到新颖的跨架构KD（CAKD），即同构和异构教师的知识可以灵活地转移到给定学生，可以大大提高KD的潜力和灵活性。CAKD的主要挑战在于异构模型之间存在显著的特征差距，这源于它们固有的归纳偏置和模块功能的区别。为此，我们引入了一个辅助模型作为桥梁，以促进异构教师和学生之间平滑的特征知识转移。更重要的是，在我们提出的设计原则中，辅助模型通过合并来自学生和教师模块功能的卷积和注意力模块，结合了跨架构归纳偏置和模块功能的优势。此外，我们观察到异构特征在CAKD中表现出不同的空间分布，阻碍了传统像素级均方误差（MSE）损失的有效性。因此，我们利用空间无关的InfoNCE损失在空间平滑后对齐特征，从而改善了CAKD中的特征对齐。我们提出的方法在一些同构模型对以及CNN、ViT和MLP的任意异构组合上进行了评估，蒸馏模型取得了最先进的性能，在CIFAR-100上最大增益达到11.47%，在ImageNet-1K上最大增益达到3.67%。我们的代码和模型将发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [715] [Differential-UMamba: Rethinking Tumor Segmentation Under Limited Data Scenarios](https://arxiv.org/abs/2507.18177)
> *Differential-UMamba：在有限数据场景下重新思考肿瘤分割*

*Dhruv Jain, Romain Modzelewski, Romain Herault, Clement Chatelain, Eva Torfeh, Sebastien Thureau* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 肿瘤分割, 有限数据, UNet, Mamba, 噪声抑制

**Comment:** 

> **TL;DR:** Diff-UMamba结合UNet和Mamba，通过噪声抑制提高有限数据下肿瘤分割精度。

**AI_Comments:** Diff-UMamba的创新点在于结合了UNet的经典结构和mamba机制的长程依赖建模能力，并特别设计了噪声抑制模块来应对有限数据场景下的过拟合问题。这种“差分”策略在医学图像处理中具有潜力，尤其是在数据标注成本高昂的领域，对于提高模型在实际应用中的泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在数据稀缺场景下，深度学习模型容易过拟合噪声和不相关模式，限制了其对未见样本的泛化能力，尤其是在医学图像分割中。

**Method:** 引入了Diff-UMamba，一个结合了UNet框架和mamba机制的新型架构，用于建模长距离依赖。其核心是一个噪声抑制模块，该模块采用信号差分策略来抑制编码器中的噪声或不相关激活，从而过滤掉虚假特征并增强任务相关表示。

**Result:** 在多个公共数据集（Medical Segmentation Decathlon数据集的肺部和胰腺、AIIB23）上，在各种分割任务中比基线方法实现了1-3%的性能提升。在BraTS-21数据集上通过改变训练样本比例进行有限数据评估，并在一个小的内部非小细胞肺癌锥形束CT总肿瘤体积分割数据集上比基线提高了4-5%。

**Conclusion:** Diff-UMamba通过噪声抑制和增强任务相关表示，显著提高了在有限数据场景下的肿瘤分割精度和鲁棒性。

> **ai_Abstract:** 本文提出了Diff-UMamba，一个结合UNet和mamba机制的新型深度学习架构，旨在解决数据稀缺场景下医学图像分割中模型过拟合和泛化能力差的问题。Diff-UMamba引入了噪声抑制模块，通过信号差分策略过滤噪声和增强任务相关特征。实验结果表明，该方法在多个公共和内部数据集上，特别是在有限数据条件下，显著提高了肿瘤分割的准确性和鲁棒性，性能比基线方法提升1-5%。

> **摘要翻译:** 在数据稀缺的场景下，深度学习模型经常会过拟合噪声和不相关的模式，这限制了它们对未见样本的泛化能力。为了解决医学图像分割中的这些挑战，我们引入了Diff-UMamba，这是一种结合了UNet框架和mamba机制的新型架构，用于建模长距离依赖。Diff-UMamba的核心是一个噪声抑制模块，该模块采用信号差分策略来抑制编码器中嘈杂或不相关的激活。这鼓励模型过滤掉虚假特征并增强与任务相关的表示，从而提高其对临床重要区域的关注。因此，该架构实现了更高的分割精度和鲁棒性，尤其是在低数据设置下。Diff-UMamba在多个公共数据集上进行了评估，包括医学分割十项全能数据集（肺部和胰腺）和AIIB23，在各种分割任务中比基线方法持续获得了1-3%的性能提升。为了进一步评估有限数据条件下的性能，在BraTS-21数据集上通过改变可用训练样本的比例进行了额外实验。该方法还在一个小的内部非小细胞肺癌数据集上进行了验证，用于锥形束CT中总肿瘤体积的分割，其性能比基线提高了4-5%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [718] [Suppressing Gradient Conflict for Generalizable Deepfake Detection](https://arxiv.org/abs/2507.21530)
> *抑制梯度冲突以实现可泛化的深度伪造检测*

*Ming-Hui Liu, Harry Cheng, Xin Luo, Xin-Shun Xu* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 深度伪造检测, 梯度冲突, 泛化能力, 数据增强, 表示学习

**Comment:** V1

> **TL;DR:** 本文提出了CS-DFD框架，通过抑制梯度冲突来提高深度伪造检测模型的泛化能力，解决了同时训练原始和在线合成伪造图像导致性能下降的问题。

**AI_Comments:** 本文的创新点在于明确识别并解决了深度伪造检测中因同时训练多种数据而导致的梯度冲突问题，这解释了为何增加数据有时反而会降低性能。提出的CS-DFD框架及其UVS和CGR模块为解决这一挑战提供了一个新颖且有效的解决方案，特别是在提高模型对未知伪造技术的泛化能力方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 鲁棒的深度伪造检测模型必须能够泛化到训练数据之外不断演变的操纵技术。一种有前景的策略是通过在线合成包含广泛可泛化伪影的假图像来扩充训练数据。然而，令人惊讶的是，在深度伪造检测中，同时在原始和在线合成伪造图像上进行训练可能会导致性能下降。这与普遍认为纳入更多源域数据会提高检测准确性的观点相悖。通过实证分析，我们将这种性能下降归因于反向传播过程中的梯度冲突，这种冲突迫使在源域准确性和目标域泛化之间进行权衡。

**Method:** 为了解决梯度冲突问题，本文提出了一个冲突抑制深度伪造检测（CS-DFD）框架，通过两个协同模块明确地缓解梯度冲突。首先，更新向量搜索（UVS）模块搜索初始梯度向量附近的一个替代更新向量，以调和原始和在线合成伪造图像之间的差异。通过将搜索过程进一步转化为极值优化问题，UVS产生唯一的更新向量，该向量最大化了每种数据类型的同步损失减少。其次，冲突梯度减少（CGR）模块通过一种新颖的冲突下降损失来强制实现低冲突的特征嵌入空间。这种损失惩罚了未对齐的梯度方向，并指导学习具有对齐、非冲突梯度的表示。

**Result:** 在多个深度伪造基准上的实验表明，CS-DFD在域内检测准确性和跨域泛化方面都达到了最先进的性能。

**Conclusion:** UVS和CGR的协同作用减轻了参数优化和表示学习中的梯度干扰，从而提高了模型的泛化能力。

> **ai_Abstract:** 为了解决深度伪造检测模型在同时训练原始和在线合成伪造图像时性能下降的问题，本文深入分析并发现其根源在于训练过程中的梯度冲突。针对此问题，作者提出了冲突抑制深度伪造检测（CS-DFD）框架，该框架包含两个协同模块：更新向量搜索（UVS）和冲突梯度减少（CGR）。UVS通过寻找最优更新向量来协调不同数据类型的损失减少，而CGR则通过引入冲突下降损失来学习低冲突的特征表示。实验结果表明，CS-DFD在多个基准测试中，无论是在域内检测准确性还是跨域泛化能力方面，均达到了最先进的水平。

> **摘要翻译:** 鲁棒的深度伪造检测模型必须能够泛化到训练数据之外不断演变的操纵技术。一种有前景的策略是通过在线合成包含广泛可泛化伪影的假图像来扩充训练数据。然而，在深度伪造检测中，令人惊讶的是，同时在原始和在线合成伪造图像上进行训练可能会导致性能下降。这与普遍认为纳入更多源域数据会提高检测准确性的观点相悖。通过实证分析，我们将这种性能下降归因于反向传播过程中的梯度冲突，这种冲突迫使在源域准确性和目标域泛化之间进行权衡。为了克服这个问题，我们提出了一个冲突抑制深度伪造检测（CS-DFD）框架，通过两个协同模块明确地缓解梯度冲突。首先，更新向量搜索（UVS）模块搜索初始梯度向量附近的一个替代更新向量，以调和原始和在线合成伪造图像之间的差异。通过将搜索过程进一步转化为极值优化问题，UVS产生唯一的更新向量，该向量最大化了每种数据类型的同步损失减少。其次，冲突梯度减少（CGR）模块通过一种新颖的冲突下降损失来强制实现低冲突的特征嵌入空间。这种损失惩罚了未对齐的梯度方向，并指导学习具有对齐、非冲突梯度的表示。UVS和CGR的协同作用减轻了参数优化和表示学习中的梯度干扰。在多个深度伪造基准上的实验表明，CS-DFD在域内检测准确性和跨域泛化方面都达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [723] [MapDiffusion: Generative Diffusion for Vectorized Online HD Map Construction and Uncertainty Estimation in Autonomous Driving](https://arxiv.org/abs/2507.21423)
> *MapDiffusion：自动驾驶中矢量化在线高清地图构建和不确定性估计的生成扩散模型*

*Thomas Monninger, Zihan Zhang, Zhipeng Mo, Md Zafar Anwar, Steffen Staab, Sihao Ding* | **Category: cs.CV, cs.AI, cs.LG, cs.RO** | **Updated: 2025-07-29**

**Keywords:** MapDiffusion, 矢量化高清地图, 扩散模型, 不确定性估计, 自动驾驶

**Comment:** Accepted for 2025 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS 2025)

> **TL;DR:** MapDiffusion是一个利用生成扩散模型构建在线高清地图并估计不确定性的新方法，显著提升了自动驾驶中地图构建的准确性和鲁棒性。

**AI_Comments:** MapDiffusion的创新点在于将生成扩散模型引入到在线高清地图构建领域，解决了传统方法无法量化不确定性的痛点。通过生成多个地图样本并进行聚合，不仅提升了预测精度，还为自动驾驶提供了关键的不确定性信息，这对于复杂环境下的安全决策至关重要。其在处理遮挡和模糊区域时的表现尤其突出，展现了该方法在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的地图构建模型提供的是确定性点估计，无法捕捉不确定性以及现实世界环境（如遮挡和缺失车道线）固有的模糊性，这对于自动驾驶至关重要。

**Method:** 本文提出了MapDiffusion，一种新颖的生成方法，利用扩散范式学习可能矢量化地图的完整分布。它通过对BEV潜在网格进行条件化，迭代地细化随机初始化的查询，以生成多个合理的地图样本。这些样本可以聚合以提高预测精度并导出与场景模糊性直接相关的L不确定性估计。

**Result:** 在nuScenes数据集上的广泛实验表明，MapDiffusion在在线地图构建方面取得了最先进的性能，单样本性能超越基线5%。聚合多个样本能持续改善ROC曲线上的性能，验证了分布建模的优势。此外，不确定性估计在遮挡区域显著更高，证实了其在识别传感器输入模糊区域的价值。

**Conclusion:** 通过建模完整的地图分布，MapDiffusion增强了在线矢量化高清地图构建的鲁棒性和可靠性，使自动驾驶车辆能够在复杂环境中进行不确定性感知的决策。

> **ai_Abstract:** MapDiffusion提出了一种基于生成扩散模型的新方法，用于自动驾驶中的矢量化在线高清地图构建和不确定性估计。针对传统方法无法捕捉不确定性的问题，MapDiffusion通过迭代细化BEV潜在网格上的查询，生成多个可能的地图样本，从而学习地图的完整分布。实验证明，该方法在地图构建性能上达到最先进水平，并通过样本聚合进一步提升精度，同时能有效识别高不确定性的模糊区域，显著增强了在线高清地图的鲁棒性和可靠性，支持自动驾驶车辆进行不确定性感知决策。

> **摘要翻译:** 自动驾驶需要从传感器数据中理解静态环境。学习到的鸟瞰图（BEV）编码器常用于融合多种输入，而矢量解码器则从潜在BEV网格预测矢量化地图表示。然而，传统的地图构建模型提供确定性点估计，未能捕捉不确定性以及现实世界环境固有的模糊性，例如遮挡和缺失的车道线。我们提出了MapDiffusion，一种新颖的生成方法，利用扩散范式学习可能矢量化地图的完整分布。MapDiffusion不再从学习到的查询中预测单一的确定性输出，而是基于BEV潜在网格，迭代地细化随机初始化的查询，以生成多个合理的地图样本。这允许聚合样本以提高预测精度，并导出与场景模糊性直接相关的不确定性估计。在nuScenes数据集上的广泛实验表明，MapDiffusion在在线地图构建方面取得了最先进的性能，单样本性能超越基线5%。我们进一步表明，聚合多个样本能持续改善ROC曲线上的性能，验证了分布建模的优势。此外，我们的不确定性估计在遮挡区域显著更高，这强化了它们在识别传感器输入模糊区域的价值。通过建模完整的地图分布，MapDiffusion增强了在线矢量化高清地图构建的鲁棒性和可靠性，使自动驾驶车辆能够在复杂环境中进行不确定性感知的决策。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [725] [Impact of Underwater Image Enhancement on Feature Matching](https://arxiv.org/abs/2507.21715)
> *水下图像增强对特征匹配的影响*

*Jason M. Summers, Mark W. Jones* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 水下图像增强, 特征匹配, 评估框架, SLAM, 视觉退化

**Comment:** 

> **TL;DR:** 本文提出了用于评估水下图像增强效果的定量度量和新型评估框架，并展示了其对特征匹配和SLAM性能的影响。

**AI_Comments:** 该论文的创新之处在于提出了新的定量度量（局部匹配稳定性和最远可匹配帧）以及一个专门针对水下环境的评估框架，用于量化图像增强对特征匹配性能的影响。其重要性在于，它弥补了现有评估方法在实际应用评估中的不足，并直接关联了图像增强与下游关键任务（如SLAM）的性能，这对于水下机器人和自主系统的发展具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 水下图像因光吸收、散射、海洋生物和碎片导致视觉退化，影响水下车辆的路径检测和自主导航等下游任务，这些任务依赖于鲁棒的特征提取和帧匹配。因此，需要评估增强技术对帧匹配性能的影响。

**Method:** 本文引入了局部匹配稳定性和最远可匹配帧作为评估水下图像增强成功与否的定量度量。提出了一种针对水下环境的新型评估框架，并通过基于度量的分析来识别现有方法的优缺点并找出其在实际应用评估中的不足。该框架还结合了实用的匹配策略。

**Result:** 通过度量分析，识别了现有方法的优缺点，并指出了其在评估实际适用性方面的空白。此外，研究展示了视觉改进如何影响完整的实际算法（如同步定位与映射SLAM）的性能。

**Conclusion:** 该评估框架增强了其与实际水下场景操作的相关性，并证明了视觉改进对实际算法性能的影响。

> **ai_Abstract:** 本研究提出了一种评估水下图像增强效果的新型框架，该框架引入了局部匹配稳定性和最远可匹配帧作为定量度量。针对水下环境的视觉退化问题，该框架旨在评估增强技术对特征匹配性能的影响。通过度量分析，研究识别了现有方法的优缺点，并揭示了其在实际应用评估中的不足。该框架结合了实用的匹配策略，为水下图像增强方法的比较提供了鲁棒的基准，并证明了视觉改进对实际SLAM算法性能的积极影响。

> **摘要翻译:** 我们引入局部匹配稳定性（local matching stability）和最远可匹配帧（furthest matchable frame）作为评估水下图像增强成功与否的定量度量。这种增强过程解决了由光吸收、散射、海洋生物生长和碎片引起的视觉退化问题。增强后的图像在水下航行器路径检测和自主导航等下游任务中发挥着关键作用，这些任务依赖于鲁棒的特征提取和帧匹配。为了评估增强技术对帧匹配性能的影响，我们提出了一种专为水下环境设计的新型评估框架。通过基于度量的分析，我们识别了现有方法的优缺点，并指出了它们在评估实际适用性方面的空白。通过结合实用的匹配策略，我们的框架为比较增强方法提供了一个鲁棒的、上下文感知的基准。最后，我们演示了视觉改进如何影响一个完整的实际算法——同步定位与映射（SLAM）——的性能，从而加强了该框架与水下操作场景的相关性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [728] [C2-Evo: Co-Evolving Multimodal Data and Model for Self-Improving Reasoning](https://arxiv.org/abs/2507.16518)
> *C2-Evo: 多模态数据与模型协同演化以实现自我提升推理*

*Xiuwei Chen, Wentao Hu, Hanhui Li, Jun Zhou, Zisheng Chen, Meng Cao, Yihan Zeng, Kui Zhang, Yu-Jie Yuan, Jianhua Han, Hang Xu, Xiaodan Liang* | **Category: cs.CV, cs.CL, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 多模态大语言模型, 自改进, 数据演化, 模型演化, 推理

**Comment:** 

> **TL;DR:** C2-Evo是一个自动闭环自改进框架，通过协同演化训练数据和模型能力来提升多模态大语言模型的推理能力。

**AI_Comments:** C2-Evo的创新之处在于其提出了一个联合演化训练数据和模型能力的闭环框架，有效解决了现有自改进MLLMs在数据与模型匹配度上的痛点。特别是其跨模态数据演化和数据-模型演化循环的设计，为高质量多模态数据集的自动生成和模型能力的自适应提升提供了新思路。该方法有望降低对昂贵人工标注数据的依赖，并推动MLLMs在复杂推理任务上的进一步发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有MLLMs的进一步增强需要高质量、复杂的数据集，但其获取成本高且难以扩展。当前的自改进模型存在两个核心挑战：数据增强分离导致数据复杂度不一致（如简化图表与冗余文本）；数据和模型演化分离导致任务难度与模型能力不匹配。

**Method:** 提出C2-Evo框架，它在给定基础数据集和模型的情况下，通过两个循环进行增强：1. 跨模态数据演化循环：通过结合结构化文本子问题和迭代指定的几何图生成复杂的多模态问题来扩展基础数据集。2. 数据-模型演化循环：根据基础模型的性能自适应选择生成的问题，交替进行监督微调和强化学习。

**Result:** 持续改进模型和训练数据，并在多个数学推理基准上持续获得显著的性能提升。

**Conclusion:** C2-Evo通过协同演化多模态数据和模型，有效解决了现有自改进MLLMs在数据和模型演化上的局限性，实现了推理能力的持续自我提升。

> **ai_Abstract:** 本文提出了C2-Evo，一个针对多模态大语言模型（MLLMs）的自动闭环自改进框架。该框架旨在解决当前MLLMs在数据质量和自改进过程中数据与模型演化分离的问题。C2-Evo通过一个跨模态数据演化循环生成复杂的训练数据，并结合一个数据-模型演化循环根据模型表现自适应选择数据进行交替的监督微调和强化学习。实验结果表明，C2-Evo能持续提升模型和训练数据，并在多个数学推理基准上取得显著性能提升。

> **摘要翻译:** 多模态大语言模型（MLLMs）的最新进展展示了令人印象深刻的推理能力。然而，进一步增强现有MLLMs需要高质量、精心策划任务复杂度的视觉-语言数据集，这既昂贵又难以扩展。尽管最近迭代自我完善的自改进模型提供了一个可行的解决方案，但它们仍然面临两个核心挑战：(i) 大多数现有方法分别增强视觉或文本数据，导致数据复杂度不一致（例如，过于简化的图表与冗余的文本描述配对）；(ii) 数据和模型的演化也是分离的，导致模型暴露于难度不匹配的任务场景。为了解决这些问题，我们提出了C2-Evo，一个自动、闭环的自改进框架，它联合演化训练数据和模型能力。具体而言，给定一个基础数据集和一个基础模型，C2-Evo通过一个跨模态数据演化循环和一个数据-模型演化循环来增强它们。前者通过结合结构化文本子问题和迭代指定的几何图来生成复杂的多模态问题，从而扩展基础数据集；而后者根据基础模型的性能自适应选择生成的问题，交替进行监督微调和强化学习。因此，我们的方法持续改进其模型和训练数据，并在多个数学推理基准上持续获得显著的性能提升。我们的代码、模型和数据集将会发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [742] [SAM2Long: Enhancing SAM 2 for Long Video Segmentation with a Training-Free Memory Tree](https://arxiv.org/abs/2410.16268)
> *SAM2Long：通过免训练记忆树增强SAM 2用于长视频分割*

*Shuangrui Ding, Rui Qian, Xiaoyi Dong, Pan Zhang, Yuhang Zang, Yuhang Cao, Yuwei Guo, Dahua Lin, Jiaqi Wang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 视频分割, SAM 2, 记忆树, 免训练

**Comment:** ICCV 2025, Project page:
  https://mark12ding.github.io/project/SAM2Long/ ; github page:
  https://github.com/Mark12Ding/SAM2Long/

> **TL;DR:** SAM2Long通过免训练的记忆树搜索策略，解决了SAM 2在长视频分割中的误差累积问题，显著提升了性能。

**AI_Comments:** SAM2Long的创新之处在于其免训练的记忆树搜索设计，该设计巧妙地解决了SAM 2在处理长视频时固有的“误差累积”问题。通过引入多路径选择和累积得分机制，它提升了模型对复杂场景（如遮挡和对象重现）的鲁棒性，在不依赖额外训练的情况下实现了显著的性能提升，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** SAM 2的贪婪选择记忆设计存在“误差累积”问题，导致错误或遗漏的掩码会级联并影响后续帧的分割，这限制了其在复杂长视频方面的性能。

**Method:** 本文引入了SAM2Long，一种改进的免训练视频对象分割策略。它通过考虑每帧的分割不确定性，以约束树搜索的方式从多个分割路径中选择视频级的最优结果。具体实践中，该方法在整个视频中保持固定数量的分割路径，每帧基于现有路径提出多个掩码以创建候选分支，然后选择相同固定数量的具有更高累积得分的分支作为下一帧的新路径。最终，选择累积得分最高的路径作为最终分割结果。

**Result:** SAM2Long在所有24项头对头比较中平均提高了3.0点，在SA-V和LVOS等长视频对象分割基准测试中，J&F最高提升了5.3点。

**Conclusion:** SAM2Long通过其启发式搜索设计，能够有效分割和跟踪复杂长视频中的对象，并对遮挡和对象重新出现具有鲁棒性，显著提升了SAM 2在长视频分割上的性能。

> **ai_Abstract:** 本文介绍了SAM2Long，一种针对SAM 2在长视频分割中“误差累积”问题的改进策略。SAM2Long采用免训练的记忆树搜索方法，通过在每帧中维护并选择具有高累积得分的多个分割路径，有效解决了遮挡和对象重现带来的挑战。实验结果表明，SAM2Long在多个长视频分割基准测试中显著提升了SAM 2的性能。

> **摘要翻译:** Segment Anything Model 2 (SAM 2) 已成为图像和视频中对象分割的强大基础模型，为各种下游视频应用铺平了道路。SAM 2用于视频分割的关键设计是其记忆模块，该模块从前一帧中提示对象感知记忆以进行当前帧预测。然而，其贪婪选择记忆设计存在“误差累积”问题，即错误或遗漏的掩码会级联并影响后续帧的分割，这限制了SAM 2在复杂长视频方面的性能。为此，我们引入了SAM2Long，一种改进的免训练视频对象分割策略，它考虑了每帧内的分割不确定性，并通过约束树搜索方式从多个分割路径中选择视频级的最优结果。在实践中，我们在整个视频中保持固定数量的分割路径。对于每一帧，基于现有路径提出多个掩码，创建各种候选分支。然后，我们选择相同固定数量的具有更高累积得分的分支作为下一帧的新路径。处理完最后一帧后，选择累积得分最高的路径作为最终分割结果。受益于其启发式搜索设计，SAM2Long对遮挡和对象重新出现具有鲁棒性，并且可以有效地分割和跟踪复杂长视频中的对象。值得注意的是，SAM2Long在所有24项头对头比较中平均提高了3.0点，在SA-V和LVOS等长视频对象分割基准测试中，J&F最高提升了5.3点。代码已发布在 https://github.com/Mark12Ding/SAM2Long。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [752] [Enhancing and Accelerating Brain MRI through Deep Learning Reconstruction Using Prior Subject-Specific Imaging](https://arxiv.org/abs/2507.21349)
> *通过使用先前的受试者特异性成像，通过深度学习重建增强和加速脑部MRI*

*Amirmohammad Shamaei, Alexander Stebner, Salome, Bosshart, Johanna Ospel, Gouri Ginde, Mariana Bento, Roberto Souza* | **Category: cs.CV, physics.med-ph** | **Updated: 2025-07-28**

**Keywords:** 深度学习, MRI重建, 脑部成像, 先验信息, 图像配准

**Comment:** 

> **TL;DR:** 本研究提出了一种新颖的深度学习框架，通过整合先前的受试者特异性成像，显著增强并加速了脑部MRI重建，优于现有方法并大幅缩短了重建时间。

**AI_Comments:** 该研究的创新之处在于其深度学习重建框架中集成了深度配准模型，有效解决了传统配准耗时的问题，从而实现了图像质量的提升和处理速度的加快，这对于临床应用至关重要。使用纵向数据集并在下游任务（脑分割）上进行验证，增强了研究结果的说服力。代码的公开可用性也提升了其影响力。

<details>
  <summary>Details</summary>

**Motivation:** 磁共振成像（MRI）采集时间过长导致成本增加和患者舒适度降低。尽管深度学习结合先前扫描可提高重建质量，但整合这些先前信息所需的传统配准过程耗时。

**Method:** 提出了一种新颖的基于深度学习的MRI重建框架，包含一个初始重建网络、一个深度配准模型和一个基于Transformer的增强网络。该方法在包含18名受试者2,808张T1加权MRI扫描的纵向数据集上进行了验证，涉及四种加速因子（R5、R10、R15、R20）。

**Result:** 定量指标证实该方法优于现有方法（p < 0.05，Wilcoxon符号秩检验）。在下游脑分割任务中，观察到准确性和与参考分割的体积一致性均有所提高。与使用传统配准算法的方法相比，总重建时间大幅缩短。

**Conclusion:** 所提出的深度学习方法有效增强并加速了脑部MRI重建，提高了图像质量并缩短了处理时间，使其更适用于实时临床应用。

> **ai_Abstract:** 本论文提出了一种新颖的深度学习框架，用于通过利用先前的受试者特异性成像来增强和加速脑部MRI重建。该框架由一个初始重建网络、一个深度配准模型和一个基于Transformer的增强网络组成。该方法在一个纵向数据集上进行了验证，结果表明其重建质量优于现有方法，并显著缩短了重建时间，同时提高了下游脑分割的准确性，使其适用于实时临床应用。

> **摘要翻译:** 磁共振成像（MRI）是一种重要的医学成像方式。然而，长时间的采集仍然是一个重大挑战，导致成本增加和患者舒适度降低。最近的研究表明，使用深度学习模型结合来自先前受试者特异性MRI扫描的信息，可以提高当前扫描的重建质量。整合这些先前信息需要将先前的扫描与当前图像重建进行配准，这可能非常耗时。我们提出了一种新颖的基于深度学习的MRI重建框架，该框架包括一个初始重建网络、一个深度配准模型和一个基于Transformer的增强网络。我们在一个包含来自18名受试者的2,808张图像的T1加权MRI扫描纵向数据集上验证了我们的方法，涉及四种加速因子（R5、R10、R15、R20）。定量指标证实了我们的方法优于现有方法（p < 0.05，Wilcoxon符号秩检验）。此外，我们分析了我们的MRI重建方法对下游脑分割任务的影响，并观察到准确性和与参考分割的体积一致性都有所提高。与使用传统配准算法的方法相比，我们的方法还大大缩短了总重建时间，使其更适合实时临床应用。与这项工作相关的代码已在https://github.com/amirshamaei/longitudinal-mri-deep-recon公开提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [758] [Contrast-Prior Enhanced Duality for Mask-Free Shadow Removal](https://arxiv.org/abs/2507.21949)
> *对比度先验增强的无掩码阴影去除双重性*

*Jiyu Wu, Yifan Liu, Jiancheng Huang, Mingfu Yan, Shifeng Chen* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 阴影去除, 无掩码, 对比度先验, 注意力机制, 扩散网络

**Comment:** 

> **TL;DR:** 本文提出了一种新的无掩码阴影去除方法，通过自适应门控双分支注意力机制处理对比度先验的歧义性，并引入基于扩散的频率-对比度融合网络以恢复细节，实现了最先进的性能。

**AI_Comments:** 这项研究的创新之处在于其对无掩码阴影去除的深入探索，特别是在处理对比度先验的固有模糊性方面。通过引入AGBA机制，它有效地解决了在复杂场景中区分阴影与非阴影区域的挑战。此外，结合扩散模型和频率-对比度融合网络来恢复细节和柔和边界，是该领域的又一重要进展。该方法在实用性上具有显著优势，因为它摆脱了对难以获取的阴影掩码的依赖，使其在实际应用中更具可行性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的阴影去除方法依赖难以获取的阴影掩码。虽然局部对比度信息是一种潜在的替代方案，但其固有的模糊性在复杂场景中（难以区分阴影、低反射物体和背景纹理）成为一个关键限制。

**Method:** 为了解决对比度先验的模糊性，我们提出了自适应门控双分支注意力（AGBA）机制，动态过滤和重新加权对比度先验，以有效分离阴影特征。此外，为恢复柔和阴影边界和精细细节，我们引入了基于扩散的频率-对比度融合网络（FCFN），利用高频和对比度线索指导生成过程。

**Result:** 大量实验表明，我们的方法在无掩码方法中达到了最先进的性能，同时相对于基于掩码的方法保持了有竞争力的表现。

**Conclusion:** 本文提出的结合AGBA机制和FCFN的无掩码阴影去除方法，有效解决了对比度先验的歧义性及细节恢复的挑战，在无掩码阴影去除领域取得了领先成果，并与基于掩码的方法表现相当。

> **ai_Abstract:** 本文提出了一种创新的无掩码阴影去除框架，旨在克服传统方法对阴影掩码的依赖以及对比度先验在复杂场景中的局限性。为解决对比度信息的模糊性，作者引入了自适应门控双分支注意力（AGBA）机制，以有效分离阴影特征。同时，为恢复精细的阴影边界和细节，提出了基于扩散的频率-对比度融合网络（FCFN）。实验结果表明，该方法在无掩码阴影去除领域达到了最先进的水平，并与基于掩码的方法性能相当。

> **摘要翻译:** 现有阴影去除方法通常依赖阴影掩码，这在实际场景中难以获取。探索内在图像线索，如局部对比度信息，为在没有明确掩码的情况下指导阴影去除提供了一种潜在的替代方案。然而，这种线索固有的模糊性在复杂场景中成为一个关键限制，因为它可能无法区分真实阴影、低反射物体和复杂的背景纹理。为了解决这一问题，我们提出了自适应门控双分支注意力（AGBA）机制。AGBA动态过滤并重新加权对比度先验，以有效地将阴影特征与混淆的视觉元素分离。此外，为了解决恢复柔和阴影边界和精细细节的持续挑战，我们引入了一个基于扩散的频率-对比度融合网络（FCFN），它利用高频和对比度线索来指导生成过程。大量实验表明，我们的方法在无掩码方法中取得了最先进的结果，同时相对于基于掩码的方法保持了有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [761] [Addressing High Class Imbalance in Multi-Class Diabetic Retinopathy Severity Grading with Augmentation and Transfer Learning](https://arxiv.org/abs/2507.17121)
> *利用数据增强和迁移学习解决多类别糖尿病视网膜病变严重程度分级中的高度类别不平衡问题*

*Faisal Ahmed* | **Category: cs.CV, cs.LG, F.2.2; I.2.7** | **Updated: 2025-07-28**

**Keywords:** 糖尿病视网膜病变, 深度学习, 类别不平衡, 数据增强, 迁移学习

**Comment:** 9 pages, 1 Figure

> **TL;DR:** 本文提出了一种深度学习框架，结合迁移学习和数据增强，有效解决了糖尿病视网膜病变（DR）二进制和五类别分类中的类别不平衡和数据有限问题，取得了高性能。

**AI_Comments:** 该论文创新性地将数据增强和迁移学习相结合，有效解决了医学图像分类中常见的类别不平衡和数据量不足的挑战。其在DR诊断上的高性能表现，尤其是在二分类任务中达到SOTA水平，以及在多类别任务中的竞争力，显示了其在真实临床部署的巨大潜力。该研究还对不同网络架构的效率进行了权衡分析，为实际应用提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 糖尿病视网膜病变（DR）是全球视力丧失的主要原因，通过自动化视网膜图像分析进行早期诊断可以显著降低失明风险。现有方法面临类别不平衡和训练数据有限的挑战。

**Method:** 本文提出了一种鲁棒的深度学习框架，用于二进制和五类别DR分类。该框架利用迁移学习和广泛的数据增强来解决类别不平衡和训练数据有限的挑战。研究评估了包括ResNet和EfficientNet变体在内的多种预训练卷积神经网络架构，并在APTOS 2019数据集上进行了测试。

**Result:** 在二分类任务中，模型达到了98.9%的准确率，98.6%的精确率，99.3%的召回率，98.9%的F1分数和99.4%的AUC。在更具挑战性的五类别严重程度分类任务中，模型获得了84.6%的准确率和94.1%的AUC，优于现有方法。研究还表明EfficientNet-B0和ResNet34在准确性和计算效率之间提供了最佳权衡。

**Conclusion:** 结合类别平衡增强和迁移学习对于高性能DR诊断是有效的。所提出的框架为DR筛查提供了一个可扩展且准确的解决方案，具有在真实临床环境中部署的潜力。

> **ai_Abstract:** 本文提出了一种基于深度学习的糖尿病视网膜病变（DR）分类框架，旨在解决多类别DR严重程度分级中存在的高度类别不平衡和数据稀缺问题。该框架利用迁移学习和广泛的数据增强技术，在APTOS 2019数据集上对多种预训练卷积神经网络（如ResNet和EfficientNet）进行了评估。实验结果显示，在DR二分类任务中，模型达到了98.9%的准确率和99.4%的AUC，表现出最先进的性能；在更复杂的五类别严重程度分类任务中，模型也取得了84.6%的准确率和94.1%的AUC，优于现有方法。研究强调了类别平衡增强与迁移学习结合的有效性，并提出该框架可作为DR筛查的可扩展且准确的解决方案，有望应用于临床实践。

> **摘要翻译:** 糖尿病视网膜病变（DR）是全球视力丧失的主要原因，通过自动化视网膜图像分析进行早期诊断可以显著降低失明风险。本文提出了一种鲁棒的深度学习框架，用于二进制和五类别DR分类，利用迁移学习和广泛的数据增强来解决类别不平衡和训练数据有限的挑战。我们在APTOS 2019数据集上评估了一系列预训练卷积神经网络架构，包括ResNet和EfficientNet的变体。对于二分类，我们提出的模型实现了98.9%的最新准确率，精确率为98.6%，召回率为99.3%，F1分数为98.9%，AUC为99.4%。在更具挑战性的五类别严重程度分类任务中，我们的模型获得了84.6%的竞争性准确率和94.1%的AUC，优于几种现有方法。我们的发现还表明，EfficientNet-B0和ResNet34在两项任务中都在准确性和计算效率之间提供了最佳权衡。这些结果强调了结合类别平衡增强与迁移学习对于高性能DR诊断的有效性。所提出的框架为DR筛查提供了一个可扩展且准确的解决方案，具有在真实临床环境中部署的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [770] [JWB-DH-V1: Benchmark for Joint Whole-Body Talking Avatar and Speech Generation Version 1](https://arxiv.org/abs/2507.20987)
> *JWB-DH-V1：全身说话虚拟形象与语音联合生成基准版本1*

*Xinhan Di, Kristin Qi, Pengqian Yu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 全身虚拟形象, 语音生成, 多模态, 基准, 扩散模型视频

**Comment:** WiCV @ ICCV 2025

> **TL;DR:** 当前方法在全身说话虚拟形象生成中难以实现多模态一致性。本文介绍了JWB-DH-V1，一个大规模数据集和评估协议，用于基准测试并识别全身虚拟形象联合音视频生成中的性能差距。

**AI_Comments:** 本文通过提供一个专门用于全身合成的基准，解决了说话虚拟形象生成领域的一个关键空白，超越了典型的面部/手部中心评估。大规模数据集和全面的评估协议是重要的贡献。所识别的性能差异为未来的研究提供了清晰的指导，使这项工作对提升全身虚拟形象生成的真实性和一致性具有重要影响。

<details>
  <summary>Details</summary>

**Motivation:** 当前方法在联合生成全身运动和自然语音时难以实现多模态一致性。现有方法缺乏评估视觉和音频质量的综合评估框架，且缺乏足够的区域特定性能分析基准。

**Method:** 本文引入了全身说话虚拟形象与语音联合生成版本I（JWB-DH-V1），包含一个大规模多模态数据集（10,000个独特身份，200万个视频样本）和一个用于评估全身可动画虚拟形象的联合音视频生成的评估协议。他们还使用此基准评估了SOTA模型。

**Result:** 对SOTA模型的评估显示，面部/手部中心性能与全身性能之间存在一致的性能差异。

**Conclusion:** 这些性能差异表明了未来在全身说话虚拟形象生成方面的重要研究领域。

> **ai_Abstract:** 本文介绍了JWB-DH-V1，这是一个新的基准数据集和评估协议，旨在解决全身说话虚拟形象与语音联合生成中多模态一致性的挑战。该基准包含一个大规模多模态数据集，拥有10,000个身份和200万个视频样本，以及一个评估音视频质量的协议。他们使用JWB-DH-V1对最先进模型的评估突出了面部/手部中心生成与全身生成之间显著的性能差异，指明了未来研究的关键方向。

> **摘要翻译:** 最近基于扩散的视频生成技术取得了进展，实现了照片般逼真的短视频片段，但当前方法在联合生成全身运动和自然语音时，仍然难以实现多模态一致性。当前方法缺乏评估视觉和音频质量的综合评估框架，并且缺乏用于区域特定性能分析的足够基准。为了解决这些空白，我们引入了全身说话虚拟形象与语音联合生成版本I（JWB-DH-V1），它包含一个大规模多模态数据集，拥有10,000个独特身份，跨越200万个视频样本，以及一个用于评估全身可动画虚拟形象的联合音视频生成的评估协议。我们对SOTA模型的评估揭示了面部/手部中心性能与全身性能之间存在一致的性能差异，这表明了未来研究的关键领域。数据集和评估工具可在https://github.com/deepreasonings/WholeBodyBenchmark公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [771] [Language Driven Occupancy Prediction](https://arxiv.org/abs/2411.16072)
> *语言驱动的占用预测*

*Zhu Yu, Bowen Pang, Lizhe Liu, Runmin Zhang, Qiang Li, Si-Yuan Cao, Maochun Luo, Mingxia Chen, Sheng Yang, Hui-Liang Shen* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 开放词汇占用, 语言驱动, 语义传递标注, 3D占用预测, LOcc

**Comment:** ICCV 2025; Project Page: https://github.com/pkqbajng/LOcc

> **TL;DR:** LOcc是一个新的框架，通过语义传递标注生成密集的3D语言占用真值，从而在开放词汇占用预测中实现更准确的监督，并在Occ3D-nuScenes数据集上超越了现有技术。

**AI_Comments:** LOcc的创新之处在于其语义传递标注管道，它巧妙地利用了图像中的语义信息来生成高精度的3D语言占用真值，有效解决了传统方法中监督信号不准确的问题。这不仅提升了开放词汇占用预测的性能，还通过自动化标注过程显著降低了人工标注成本，具有重要的实际应用价值和研究潜力。

<details>
  <summary>Details</summary>

**Motivation:** 之前的开放词汇占用（OVO）预测方法通常通过粗糙的体素到文本对应关系（通过图像特征作为中间体）或来自基于体素的模型视图投影的噪声和稀疏对应关系来监督网络，导致监督不准确。

**Method:** 本文提出了LOcc框架，用于开放词汇占用（OVO）预测。核心方法是引入了一个语义传递标注（semantic transitive labeling）流程，用于生成密集和细粒度的3D语言占用真值。该流程将图像中的文本标签转移到LiDAR点云，最终转移到体素，以建立精确的体素到文本对应关系。LOcc通过将现有监督占用模型的预测头替换为用于二元占用状态的几何头和用于语言特征的语言头，有效地利用生成的语言真值来指导3D语言体学习。

**Result:** 实验证明，所提出的传递语义标注流程可以生成更准确的伪标注真值，减少了劳动密集型的人工标注。此外，LOcc在各种架构上都得到了验证，所有模型在Occ3D-nuScenes数据集上都持续优于最先进的零样本占用预测方法。

**Conclusion:** 通过提出语义传递标注流程和LOcc框架，本文有效解决了开放词汇占用预测中监督不准确的问题，并实现了优于现有技术的性能，同时减少了对人工标注的依赖。

> **ai_Abstract:** 本文提出了LOcc，一个用于开放词汇占用（OVO）预测的通用框架。针对现有方法监督不准确的问题，LOcc引入了一个语义传递标注流程，将图像中的文本标签精确地转移到3D体素，生成密集且细粒度的语言占用真值。该框架通过新的几何头和语言头利用这些真值指导3D语言体的学习。实验证明，LOcc生成的伪标注真值更准确，显著减少了人工标注需求，并且在Occ3D-nuScenes数据集上，其性能持续超越了最先进的零样本占用预测方法。

> **摘要翻译:** 我们引入了LOcc，一个有效且可泛化的开放词汇占用（OVO）预测框架。以前的方法通常通过图像特征作为中间体的粗略体素到文本对应关系，或来自基于体素的模型视图投影的嘈杂和稀疏对应关系来监督网络。为了缓解不准确的监督问题，我们提出了一个语义传递标注管道来生成密集和细粒度的3D语言占用真值。我们的管道提供了一种可行的方法来挖掘图像中有价值的语义信息，将文本标签从图像转移到LiDAR点云并最终转移到体素，以建立精确的体素到文本对应关系。通过用用于二元占用状态的几何头和用于语言特征的语言头替换监督占用模型的原始预测头，LOcc有效地利用生成的语言真值来指导3D语言体的学习。通过广泛的实验，我们证明了我们的传递语义标注管道可以产生更准确的伪标注真值，减少了劳动密集型的人工标注。此外，我们在各种架构中验证了LOcc，所有模型在Occ3D-nuScenes数据集上都持续优于最先进的零样本占用预测方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [774] [Sun sensor calibration algorithms: A systematic mapping and survey](https://arxiv.org/abs/2507.21541)
> *太阳传感器校准算法：系统性映射与综述*

*Michael Herman, Olivia J. Pinon Fischer, Dimitri N. Mavris* | **Category: cs.CV, astro-ph.IM** | **Updated: 2025-07-29**

**Keywords:** 太阳传感器, 校准算法, 系统综述, 姿态确定, 不确定性

**Comment:** Submitted to Acta Astronautica

> **TL;DR:** 本文对太阳传感器校准算法进行了系统性映射和全面综述，填补了现有文献中缺乏整合性回顾的空白，并提出了未来的研究方向。

**AI_Comments:** 这篇综述论文具有重要的学术价值，因为它填补了太阳传感器校准领域缺乏系统性整合资源的空白。通过提供系统性映射和全面调查，它不仅总结了现有知识，还清晰地指出了研究空白和未来方向，对于该领域的学者和工程师具有很强的指导意义。其创新之处在于其“系统性映射”的方法。

<details>
  <summary>Details</summary>

**Motivation:** 太阳传感器校准过程复杂且存在难以观测的不确定性，尽管过去二十年研究广泛，但缺乏系统性整合和回顾现有工作的资源，这促使了对先进校准算法的需求，以最小化不确定性并提高精度。

**Method:** 本文提出了一种太阳传感器建模和校准算法的系统性映射方法，并对各种传感器配置下的每种方法进行了全面调查，同时分析了研究空白并为未来的研究方向提出了建议。

**Result:** 本文提供了太阳传感器建模和校准算法的系统性映射，对现有方法进行了全面调查，并识别了研究空白，提出了未来研究的建议。

**Conclusion:** 本综述为太阳传感器建模和校准算法提供了一个整合性的、系统的视角，总结了现有技术，并指出了未来的研究方向和挑战。

> **ai_Abstract:** 本文对太阳传感器校准算法进行了系统性映射和全面综述。鉴于太阳传感器在航天器姿态确定中的重要性以及其校准过程中面临的复杂不确定性挑战，尽管相关研究已持续二十年，但仍缺乏一个整合性的系统回顾。本综述旨在填补这一空白，通过对不同传感器配置下的建模和校准方法进行系统性梳理和全面调查，分析现有研究的不足，并为未来的研究方向提供建议。

> **摘要翻译:** 姿态传感器通过感知天文物体、场或其他现象来确定航天器的姿态。太阳和恒星是两种主要的天文感知对象。姿态传感器是航天器生存和知识改进的关键部件。其中，太阳传感器是航天器姿态确定中最常见和最重要的传感器。太阳传感器测量航天器坐标系中的太阳矢量。由于涉及的不确定性的复杂性，太阳传感器校准过程尤其困难。这些不确定性很小，难以观测，并且在传感器的生命周期内随时间和空间变化。此外，传感器还受到多种不确定性来源的影响，包括制造、电气、环境和干扰源。这促使了先进校准算法的开发，以在传感器生命周期内最小化不确定性并提高精度。尽管在过去二十年中，文献中对太阳传感器的建模和校准技术进行了广泛探索，但目前还没有一个资源能够整合和系统地回顾这部分工作。本综述提出了太阳传感器建模和校准算法在各种传感器配置中的系统性映射。它特别提供了对每种方法的全面调查，以及对研究空白的分析和对太阳传感器建模和校准技术未来方向的建议。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [782] [Detection Transformers Under the Knife: A Neuroscience-Inspired Approach to Ablations](https://arxiv.org/abs/2507.21723)
> *检测Transformer剖析：一种受神经科学启发的消融方法*

*Nils Hütten, Florian Hölken, Hasan Tercan, Tobias Meisen* | **Category: cs.CV, cs.AI, I.2; I.4** | **Updated: 2025-07-29**

**Keywords:** 检测Transformer, 可解释人工智能, 消融研究, 模型可解释性, DeepDissect

**Comment:** 

> **TL;DR:** 该研究系统性地分析了消融检测Transformer（DETR、DDETR、DINO）关键组件的影响，以理解其内部机制并识别冗余。

**AI_Comments:** 本研究的创新之处在于将神经科学启发的消融方法应用于检测Transformer等复杂的AI模型，弥补了理解其内部工作机制的关键空白。它提供了实际的见解，可用于模型简化和性能优化，并对可解释人工智能领域做出了贡献。

<details>
  <summary>Details</summary>

**Motivation:** 尽管检测Transformer发展迅速，但在理解其内部组件的独特作用方面仍存在显著研究空白，而这些知识对于提高模型的透明度和效率至关重要。本研究受神经科学消融研究的启发，旨在通过选择性损伤来探究大脑区域的功能。

**Method:** 本研究系统性地分析了消融三种最先进的检测Transformer模型（DETR、DDETR和DINO）中关键组件的影响。消融目标包括查询嵌入、编码器和解码器多头自注意力（MHSA）以及解码器多头交叉注意力（MHCA）层。研究通过gIoU和F1-score性能指标评估这些消融对COCO数据集上分类和回归子任务的影响。此外，为促进复现性和未来研究，本研究公开发布了DeepDissect库。

**Result:** 研究结果揭示了模型特有的鲁棒性模式：DETR对编码器MHSA和解码器MHCA的消融特别敏感；DDETR的多尺度可变形注意力增强了其鲁棒性；DINO由于其“向前两次更新”规则（有助于知识在块间分布）表现出最大的鲁棒性。这些发现还揭示了结构冗余，特别是在DDETR和DINO的解码器MHCA层中，这表明在不牺牲性能的情况下存在模型简化的机会。

**Conclusion:** 本研究通过阐明内部组件对模型性能的贡献，推进了检测Transformer的可解释人工智能（XAI）研究，为关键应用中的优化、透明度和效率提升提供了见解。

> **ai_Abstract:** 本研究采用受神经科学启发的消融方法，系统地分析了在最先进的检测Transformer模型（DETR、DDETR、DINO）中移除关键组件（如查询嵌入、MHSA、MHCA）的影响。通过在COCO数据集上评估性能，研究揭示了模型特有的鲁棒性模式，并识别出结构冗余，尤其是在DDETR和DINO的解码器MHCA层中，这为模型简化提供了机会。该工作通过阐明内部组件对模型性能的贡献，提升了检测Transformer的可解释人工智能（XAI），并为优化、透明度和效率提供了见解。

> **摘要翻译:** 近年来，可解释人工智能（XAI）作为一种增强模型可解释性和透明度的方法，尤其是在检测Transformer等复杂模型中，受到了越来越多的关注。尽管取得了快速进展，但在理解内部组件的独特作用方面仍存在巨大的研究空白——这些知识对于提高透明度和效率至关重要。受神经科学消融研究的启发（该研究通过选择性损伤来探究大脑区域的功能），我们系统地分析了消融三种最先进的检测Transformer模型（检测Transformer (DETR)、可变形检测Transformer (DDETR) 和改进去噪锚框的DETR (DINO)）中关键组件的影响。消融目标包括查询嵌入、编码器和解码器多头自注意力（MHSA）以及解码器多头交叉注意力（MHCA）层。我们评估了这些消融对COCO数据集上分类和回归子任务的性能指标gIoU和F1-score的影响，并进行了量化。为了促进复现性和未来的研究，我们公开发布了DeepDissect库。我们的研究结果揭示了模型特有的鲁棒性模式：DETR对编码器MHSA和解码器MHCA的消融特别敏感，而DDETR的多尺度可变形注意力增强了鲁棒性，DINO由于其“向前两次更新”规则（有助于知识在块间分布）表现出最大的鲁棒性。这些见解也揭示了结构冗余，特别是在DDETR和DINO的解码器MHCA层中，这凸显了在不牺牲性能的情况下简化模型的机会。本研究通过阐明内部组件对模型性能的贡献，推进了检测Transformer的XAI研究，为关键应用中的优化、透明度和效率提升提供了见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [785] [DASH: 4D Hash Encoding with Self-Supervised Decomposition for Real-Time Dynamic Scene Rendering](https://arxiv.org/abs/2507.19141)
> *DASH：基于自监督分解的4D哈希编码，用于实时动态场景渲染*

*Jie Chen, Zhangchi Hu, Peixi Wu, Huyue Zhu, Hebei Li, Xiaoyan Sun* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 4D哈希编码, 自监督分解, 实时渲染, 动态场景, 高斯泼溅

**Comment:** ICCV 2025

> **TL;DR:** DASH提出一种结合4D哈希编码和自监督分解的实时动态场景渲染框架，解决了现有方法的低秩假设和哈希冲突问题，实现了SOTA性能和实时渲染速度。

**AI_Comments:** DASH的创新点在于结合了自监督分解与4D哈希编码，有效解决了动态场景渲染中常见的低秩假设问题和哈希冲突。其无需手动标注的自监督分解机制显著提高了实用性，而实时渲染速度和高质量输出则展现了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的动态高斯泼溅平面方法存在不合适的低秩假设，导致特征重叠和渲染质量差。直接将4D哈希编码应用于整个动态场景会导致大量哈希冲突和冗余。

**Method:** DASH框架首先采用自监督分解机制将动态和静态组件分离，无需手动标注。然后，为动态元素引入多分辨率4D哈希编码器，提供避免低秩假设的显式表示。最后，提出时空平滑正则化策略以减轻不稳定的变形伪影。

**Result:** DASH在真实世界数据集上实现了最先进的动态渲染性能，在单个4090 GPU上以264 FPS的实时速度展现了增强的视觉质量。

**Conclusion:** DASH通过结合自监督分解和4D哈希编码，有效解决了动态场景渲染中的现有挑战，实现了高质量的实时动态场景渲染。

> **ai_Abstract:** DASH是一个针对实时动态场景渲染的框架，它结合了4D哈希编码和自监督分解。该方法首先通过自监督机制将场景分解为动态和静态部分，然后对动态部分应用多分辨率4D哈希编码，以避免低秩假设和哈希冲突。此外，DASH还引入了时空平滑正则化策略来改善渲染稳定性。实验证明，DASH在渲染质量和实时性能上均达到了SOTA水平。

> **摘要翻译:** 动态场景重建是3D视觉领域的一个长期挑战。现有动态高斯泼溅中的基于平面方法存在不合适的低秩假设，导致特征重叠和渲染质量差。尽管4D哈希编码提供了没有低秩约束的显式表示，但将其直接应用于整个动态场景会导致大量哈希冲突和冗余。为了解决这些挑战，我们提出了DASH，一个采用4D哈希编码与自监督分解相结合的实时动态场景渲染框架。我们的方法首先采用自监督分解机制，在没有手动标注或预计算掩码的情况下分离动态和静态组件。接下来，我们为动态元素引入了多分辨率4D哈希编码器，提供了一种避免低秩假设的显式表示。最后，我们提出了一种时空平滑正则化策略，以减轻不稳定的变形伪影。在真实世界数据集上的实验表明，DASH实现了最先进的动态渲染性能，在单个4090 GPU上以264 FPS的实时速度展现了增强的视觉质量。代码：https://github.com/chenj02/DASH。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [790] [Mitigating Spurious Correlations in Weakly Supervised Semantic Segmentation via Cross-architecture Consistency Regularization](https://arxiv.org/abs/2507.21959)
> *弱监督语义分割中通过跨架构一致性正则化缓解虚假关联*

*Zheyuan Zhang, Yen-chia Hsu* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 弱监督语义分割, 虚假关联, 跨架构一致性, 师生框架, 像素级标签稀缺

**Comment:** 

> **TL;DR:** 提出一种新的弱监督语义分割框架，利用CNN和ViT的师生模型及跨架构一致性正则化来解决像素级标签稀缺和模型虚假关联问题，无需外部监督。

**AI_Comments:** 该论文的创新点在于提出了一个无需外部监督的WSSS框架，通过结合CNN和ViT的师生架构以及引入跨架构一致性正则化来解决虚假关联问题。这种方法有望提高弱监督语义分割的准确性和鲁棒性，尤其是在特定领域如工业烟雾中，具有重要的应用潜力。其不依赖额外先验知识的设计也提升了方法的普适性和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 在实际场景中，像素级标签稀缺是一个重大挑战，尤其是在工业烟雾等领域获取详细标注非常困难。现有的弱监督语义分割（WSSS）方法由于监督差距和模型固有偏差，存在前景覆盖不完整、对象边界不准确以及虚假关联（如排放物与烟囱的空间耦合）等局限性。

**Method:** 提出一种新的WSSS框架，直接解决共现问题，不依赖外部监督。该框架采用结合CNN和ViT的师生模型。引入知识迁移损失，通过对齐内部表示来强制实现跨架构一致性。此外，还结合了后处理技术来解决部分覆盖问题并进一步提高伪掩膜质量。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该论文提出了一种新的弱监督语义分割（WSSS）框架，旨在解决像素级标签稀缺以及现有WSSS方法中存在的虚假关联、前景覆盖不完整和边界不准确等问题。针对传统方法依赖外部先验知识且缺乏可扩展性的不足，本研究采用了一个不依赖外部监督的师生模型，结合了CNN和ViT的优势。通过引入知识迁移损失来强制实现跨架构一致性，并结合后处理技术，以提高伪掩膜质量和解决部分覆盖问题。

> **摘要翻译:** 像素级标签的稀缺是实际场景中的一个重大挑战。在工业烟雾等特定领域，获取这种详细的标注尤为困难，通常需要专业知识。为了缓解这一问题，弱监督语义分割（WSSS）已成为一种有前景的方法。然而，由于监督差距以及仅使用图像级标签训练的模型固有的偏差，现有WSSS方法存在局限性，例如前景覆盖不完整、对象边界不准确以及虚假关联，尤其是在我们的领域中，排放物总是与烟囱空间耦合。
以往的解决方案通常依赖额外的先验知识或外部知识来缓解这些问题，但它们往往缺乏可扩展性，并且未能解决模型对共现上下文的固有偏差。为了解决这个问题，我们提出了一种新颖的WSSS框架，直接针对共现问题，而无需依赖外部监督。与采用单一网络的现有方法不同，我们采用结合CNN和ViT的师生框架。我们引入了一种知识迁移损失，通过对齐内部表示来强制实现跨架构一致性。此外，我们还结合了后处理技术来解决部分覆盖问题并进一步提高伪掩膜质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [794] [Recursive Visual Imagination and Adaptive Linguistic Grounding for Vision Language Navigation](https://arxiv.org/abs/2507.21450)
> *递归视觉想象和自适应语言接地用于视觉语言导航*

*Bolei Chen, Jiaxu Kang, Yifei Wang, Ping Zhong, Qi Wu, Jianxin Wang* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-29**

**Keywords:** 视觉语言导航, 递归视觉想象, 自适应语言接地, 场景表示, 语言对齐

**Comment:** Submitted to AAAI 2026

> **TL;DR:** 本文提出RVI和ALG技术，通过递归总结视觉感知和自适应语言对齐，解决视觉语言导航（VLN）中场景表示过于详细和视觉语言对齐模糊的问题，并在VLN-CE和ObjectNav任务上超越SOTA。

**AI_Comments:** 本文的创新点在于提出了RVI和ALG两种技术，分别解决了VLN中视觉表示的冗余性和视觉-语言对齐的模糊性。通过关注高层次的视觉规律和语义布局，并实现细粒度的语言接地，显著提升了导航代理在复杂环境下的表现，为长序列导航决策提供了更鲁棒的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 当前视觉语言导航（VLN）代理存在场景表示过于详细和视觉-语言对齐模糊的问题，这削弱了它们对导航友好的高级场景先验的理解，并容易导致违反语言指令的行为。

**Method:** 本文提出一种导航策略，通过递归总结沿途视觉感知，并自适应地与指令对齐以增强语言接地。具体地，通过将历史轨迹结构化建模为紧凑的神经网格，提出了几种递归视觉想象（RVI）技术，使代理关注视觉转换的规律性和语义场景布局。此外，还提出了自适应语言接地（ALG）技术，有目的地将学习到的情境记忆与不同的语言组件对齐，以促进准确预测导航动作和进展。

**Result:** 本文提出的导航策略在具有挑战性的VLN-CE和ObjectNav任务上优于现有最先进的方法。

**Conclusion:** 本文提出的递归视觉想象（RVI）和自适应语言接地（ALG）技术在视觉语言导航（VLN）任务中表现出优越性，有效解决了现有代理在场景表示和语言对齐方面的局限性。

> **ai_Abstract:** 本文针对视觉语言导航（VLN）中代理面临的场景表示冗余和语言对齐模糊问题，提出了一种新颖的导航策略。该策略引入了递归视觉想象（RVI）技术，通过总结历史视觉感知并关注场景的高级语义布局，避免了对不必要几何细节的关注。同时，自适应语言接地（ALG）技术实现了学习到的情境记忆与语言指令的细粒度匹配。实验结果表明，该方法在VLN-CE和ObjectNav任务上均超越了现有最先进水平，验证了RVI和ALG在VLN中的有效性。

> **摘要翻译:** 视觉语言导航（VLN）通常要求代理通过遵循语言指令，在未知场景中导航到指定的物体或远程区域。此类任务需要组织历史视觉观察以进行语言接地，这对于长序列导航决策至关重要。然而，当前的代理存在场景表示过于详细和视觉-语言对齐模糊的问题，这削弱了它们对导航友好型高级场景先验的理解，并容易导致违反语言指令的行为。为了解决这些问题，我们提出了一种导航策略，通过递归总结沿途的视觉感知，并将其自适应地与指令对齐以增强语言接地。特别是，通过将历史轨迹结构化建模为紧凑的神经网格，提出了几种递归视觉想象（RVI）技术，旨在促使代理关注视觉转换的规律性和语义场景布局，而不是处理误导性的几何细节。然后，提出了一种自适应语言接地（ALG）技术，有目的地将学习到的情境记忆与不同的语言组件对齐。这种细粒度的语义匹配有助于准确预测导航动作和进展。我们的导航策略在具有挑战性的VLN-CE和ObjectNav任务上优于现有最先进的方法，显示了我们的RVI和ALG技术在VLN中的优越性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [798] [Puzzle Similarity: A Perceptually-guided Cross-Reference Metric for Artifact Detection in 3D Scene Reconstructions](https://arxiv.org/abs/2411.17489)
> *拼图相似度：一种用于三维场景重建中伪影检测的感知引导交叉参考度量*

*Nicolai Hermann, Jorge Condor, Piotr Didyk* | **Category: cs.CV, cs.AI, cs.GR, cs.LG, 68T07, 68T45, 68T10, I.4; I.3; I.2** | **Updated: 2025-07-29**

**Keywords:** 拼图相似度, 三维场景重建, 伪影检测, 交叉参考度量, 图像质量评估

**Comment:** 

> **TL;DR:** 本文提出了一种名为“拼图相似度”的新型交叉参考度量，用于在三维场景重建中定位新颖视图中的伪影。该方法利用训练视图的图像块统计信息建立场景特定分布，并结合新收集的人工标注数据集，实现了最先进的伪影定位效果，与人类评估高度相关。

**AI_Comments:** 本文的创新点在于提出了一个新颖的、感知引导的交叉参考度量“拼图相似度”，它巧妙地利用了训练视图的上下文信息来识别三维重建中的伪影，无需真实参考图像，这对于实际应用非常重要。同时，为了弥补该领域评估数据集的不足，作者还构建了一个新的人工标注数据集，这对于推动后续研究具有显著贡献。该方法在伪影定位上的SOTA表现和与人类感知的相关性，使其在自动图像修复和质量评估方面具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现代三维重建技术能有效建模复杂场景，但由于缺乏真实图像和无参考图像度量的局限性，自动评估新颖视图的质量和识别伪影极具挑战。缺乏可靠的度量阻碍了新颖视图的质量评估，并限制了如图像修复等后处理技术在提升重建质量方面的应用。

**Method:** 本文提出了一种新的交叉参考度量——“拼图相似度”，旨在定位新颖视图中的伪影。该方法利用训练视图的图像块统计信息建立场景特定分布，然后用此分布识别新颖视图中重建质量差的区域。鉴于缺乏评估三维重建中交叉参考方法的好度量，作者收集了一个新的人工标注数据集，包含未见重建视图中的伪影和失真图。

**Result:** 通过所构建的数据集，本文证明了所提出的方法在新颖视图的伪影定位方面达到了最先进水平，即使没有对齐的参考图像，其结果也与人类评估高度相关。

**Conclusion:** 本文提出的新度量可以用于增强自动化图像修复、引导式采集或稀疏输入三维重建等应用。

> **ai_Abstract:** 针对三维场景重建中新颖视图质量评估和伪影识别的挑战，本文提出了一种名为“拼图相似度”的新型感知引导交叉参考度量。该方法通过分析训练视图的图像块统计数据建立场景特定分布，从而有效定位新颖视图中的伪影区域。为验证其有效性，研究团队收集了一个新的人工标注伪影数据集。实验结果表明，“拼图相似度”在伪影定位上达到了最先进水平，且与人类评估高度一致，这有望推动自动化图像修复和三维重建等应用的发展。

> **摘要翻译:** 现代重建技术可以有效地从稀疏的二维视图中建模复杂的三维场景。然而，由于缺乏真实图像以及无参考图像度量在预测可靠伪影图方面的局限性，自动评估新颖视图的质量和识别伪影具有挑战性。此类度量的缺失阻碍了对新颖视图质量的评估，并限制了采用后处理技术（如图像修复）来提高重建质量。为了解决这个问题，最近的工作建立了一类新的度量（交叉参考），仅通过利用来自替代视点捕获的上下文来预测图像质量（arXiv:2404.14409）。在这项工作中，我们提出了一种新的交叉参考度量——拼图相似度，旨在定位新颖视图中的伪影。我们的方法利用训练视图的图像块统计信息来建立场景特定分布，随后用于识别新颖视图中重建不良的区域。鉴于在三维重建背景下缺乏评估交叉参考方法的好度量，我们收集了一个新颖的、人工标注的、包含未见重建视图中伪影和失真图的数据集。通过这个数据集，我们证明了我们的方法在定位新颖视图中的伪影方面达到了最先进水平，即使没有对齐的参考，也与人类评估相关。我们可以利用我们的新度量来增强自动图像修复、引导式采集或稀维输入三维重建等应用。项目页面请访问 https://nihermann.github.io/puzzlesim/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [806] [Bias Analysis for Synthetic Face Detection: A Case Study of the Impact of Facial Attributes](https://arxiv.org/abs/2507.19705)
> *合成人脸检测中的偏见分析：面部属性影响的案例研究*

*Asmae Lamsaf, Lucia Cascone, Hugo Proença, João Neves* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 合成人脸检测, 偏见分析, 面部属性, 公平性, 数据偏斜

**Comment:** Accepted at IJCB2025

> **TL;DR:** 合成人脸检测模型存在偏见，尤其是在特定面部属性方面。本研究提出了一个评估框架来分析并揭示这些偏见的来源。

**AI_Comments:** 这项研究非常及时和重要，因为它解决了AI模型在实际应用中日益突出的公平性和伦理问题。提出的评估框架具有通用性，可以用于未来对其他检测任务的偏见分析。通过深入分析偏见的来源，为开发更公平、鲁棒的合成人脸检测模型提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有的合成人脸检测模型和训练数据集可能存在偏见，导致对特定人群的检测失败，从而引发重大的社会、法律和伦理问题。因此，对合成人脸检测的偏见分析将成为未来一个关键的研究议题。

**Method:** 本文引入了一个评估框架，利用均匀分布属性标签的合成数据生成来减轻数据偏斜，从而分析合成人脸检测器对面部属性的偏见。基于此框架，对五种最先进的检测器在具有25个受控面部属性的合成数据集上的偏见水平进行了广泛的案例研究。此外，通过分析与检测器训练集中面部属性平衡的关联以及受控属性修改图像对中检测器激活图的分析，揭示了偏见的来源。

**Result:** 研究结果证实，合成人脸检测器普遍偏向于特定面部属性的存在或缺失。本研究还通过分析与训练集中面部属性平衡的关联以及检测器激活图，成功揭示了观察到的偏见的来源。

**Conclusion:** 合成人脸检测器普遍存在偏见，且这种偏见与训练数据中的属性平衡以及模型对特定属性的激活方式有关。因此，偏见分析是未来合成人脸检测领域的重要研究方向，对于开发更公平、鲁棒的模型至关重要。

> **ai_Abstract:** 本文关注合成人脸检测模型中存在的偏见问题，指出现有模型和数据集可能导致对特定人群的检测失败。为此，作者提出了一个评估框架，利用均匀分布属性标签的合成数据来系统分析合成人脸检测器对面部属性的偏见。通过对五种最先进检测器的案例研究，证实了合成人脸检测器普遍存在对特定面部属性的偏见，并进一步揭示了这些偏见的来源，强调了偏见分析在未来合成人脸检测领域的重要性。

> **摘要翻译:** 合成人脸检测的偏见分析在未来几年必将成为一个关键议题。尽管已经开发了许多检测模型并发布了多个数据集来可靠地识别合成内容，但一个关键方面却在很大程度上被忽视了：这些模型和训练数据集可能存在偏见，导致对特定人群的检测失败，并引发重大的社会、法律和伦理问题。在这项工作中，我们引入了一个评估框架，旨在分析合成人脸检测器在多个面部属性方面的偏见。该框架利用合成数据生成，并通过均匀分布的属性标签来减轻数据中的任何偏斜，否则这些偏斜可能会影响偏见分析的结果。我们基于所提出的框架，对五种最先进的检测器在具有25个受控面部属性的合成数据集中的偏见水平进行了广泛的案例研究。虽然结果证实，总的来说，合成人脸检测器偏向于特定面部属性的存在/缺失，但我们的研究也通过分析与检测器训练集中面部属性平衡的关联，以及分析受控属性修改图像对中检测器的激活图，揭示了观察到的偏见的来源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [810] [Very High-Resolution Bridge Deformation Monitoring Using UAV-based Photogrammetry](https://arxiv.org/abs/2410.18984)
> *基于无人机摄影测量的高分辨率桥梁变形监测*

*Mehdi Maboudi, Jan Backhaus, Inka Mai, Yahya Ghassoun, Yogesh Khedar, Dirk Lowke, Bjoern Riedel, Ulf Bestmann, Markus Gerke* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-29**

**Keywords:** 无人机摄影测量, 桥梁变形监测, 结构健康监测, 高分辨率, 全区域量化

**Comment:** 

> **TL;DR:** 本文研究了使用无人机摄影测量技术进行高分辨率桥梁变形监测的可行性，并在实验中证明其能够实现优于1毫米的精度，并提供全区域变形量化。

**AI_Comments:** 本文创新性地将无人机摄影测量技术应用于桥梁变形的高分辨率监测，实现了优于1毫米的精度，并提供了全区域的变形量化能力，这显著优于传统的点或剖面测量方法。其重要性在于为老旧基础设施的健康监测提供了一种更经济、高效且全面的解决方案，对结构安全评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 基础设施（如桥梁）的结构健康监测至关重要，因为许多现有结构已达到或即将达到其设计使用寿命，需要准确高效的监测方法。

**Method:** 研究团队使用配备高分辨率相机（PhaseOne iXM-100）和RTK-GNSS接收机的多旋翼无人机（DJI Matrice 600 Pro），对一个可施加预定义载荷的钢筋混凝土研究桥梁进行了广泛测试。在施加受控载荷之前、期间和之后捕获了超高分辨率图像块，并监测了桥梁上不同点的运动。同时，计算了密集图像点云以评估基于表面的数据采集性能。此外，利用稳定区域的大地测量控制网络作为光束法平差的控制信息，并与位移传感器、测速仪和激光轮廓测量等不同传感技术进行对比验证。

**Result:** 与参考数据（位移传感器）的比较显示，基于无人机的变形监测结果差异小于1毫米。该方法实现了全区域的变形量化，与传统的点或剖面测量形成对比。

**Conclusion:** 本文表明，所引入的基于无人机的监测方法能够实现非常高分辨率的桥梁变形监测，其精度与传统测量方法相当，并能提供更全面的区域变形量化，证明了其在结构健康监测中的适用性。

> **ai_Abstract:** 本文提出并验证了一种基于无人机摄影测量的高分辨率桥梁变形监测方法。该研究旨在解决传统监测方法的成本和风险问题，并通过对一座受控载荷下的研究桥梁进行实验。实验中，无人机搭载高分辨率相机采集图像，并结合大地测量控制网络进行数据处理。结果显示，该方法与传统位移传感器对比，精度差异小于1毫米，并且能够实现桥梁的全区域变形量化，而非仅限于点或剖面测量，证明了其在结构健康监测中的高效性和准确性。

> **摘要翻译:** 基础设施对象（如桥梁）的准确高效结构健康监测是一项至关重要的任务，因为许多现有结构已达到或即将达到其计划使用寿命。在本文中，我们探讨了基于无人机的监测是否适用于结构健康监测（SHM），特别是关注载荷下的几何变形。这种先进技术因其能够降低繁琐传统检查方法的成本和风险而日益普及。为此，我们对一座研究用的钢筋混凝土桥梁进行了广泛测试，该桥梁可以通过地锚施加预定义载荷。在施加受控载荷之前、期间和之后捕获了超高分辨率图像块。根据这些图像，监测了桥梁上不同点的运动，此外，还计算了密集图像点云，以评估基于表面的数据采集性能。此外，稳定区域的大地测量控制网络被用作光束法平差的控制信息。我们应用了不同的传感技术来判断基于图像的变形结果：位移传感器、测速仪和激光轮廓测量。作为摄影测量测量的平台，使用了配备两个RTK-GNSS接收机的多旋翼无人机DJI Matrice 600 Pro。安装的相机是带有80毫米镜头的PhaseOne iXM-100（100MP）。在距地面30米的高度飞行，地面采样距离（GSD）为1.3毫米，同时保持80%的前向和侧向重叠。与参考数据（位移传感器）的比较显示，差异小于1毫米。我们展示了通过采用所引入的基于无人机的监测方法，可以实现全区域的变形量化，这与传统的点或剖面测量形成对比。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [822] [Group Relative Augmentation for Data Efficient Action Detection](https://arxiv.org/abs/2507.21353)
> *用于数据高效动作检测的群组相对增强*

*Deep Anil Patel, Iain Melvin, Zachary Izzo, Martin Renqiang Min* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 动作检测, 数据高效, 视频-语言模型, 特征增强, LoRA

**Comment:** 

> **TL;DR:** 本文提出了一种结合LoRA和新型可学习内部特征增强的高效策略，用于在有限数据下将大型视频-语言模型（VLMs）应用于动作检测，并通过群组加权损失函数来优化训练，实现了在复杂动作检测数据集上的强大性能和显著数据效率。

**AI_Comments:** 本文的创新点在于结合了参数高效微调（LoRA）与一种新颖的可学习内部特征增强，并在VLM骨干内部通过FiLM应用，以生成任务相关的多样化特征。此外，引入的群组加权损失函数，根据预测差异动态加权样本，是提升学习鲁棒性的关键。该方法有效地解决了在数据稀缺场景下大型VLM适应动作检测的挑战，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在仅有少量样本的情况下，将大型视频-语言模型（VLMs）应用于动作检测面临两大挑战：一是过拟合问题，二是场景级预训练与所需的人体中心理解之间存在的粒度不匹配问题。

**Method:** 本文提出了一种结合参数高效微调（LoRA）和新型可学习内部特征增强的有效自适应策略。这些增强通过FiLM在冻结的VLM骨干内部应用，以生成与任务直接相关的多样化特征变体。此外，引入了一个群组加权损失函数，该函数根据每个增强样本的预测与群组平均值的差异动态调整其训练贡献，从而通过优先处理信息丰富且合理的增强来促进鲁棒学习。

**Result:** 该方法在复杂的多标签、多人动作检测数据集（AVA, MOMA）上展示了其有效性，取得了强大的mAP性能，并显示出在有限样本下适应VLM的显著数据效率。

**Conclusion:** 本文提出的结合LoRA、可学习内部特征增强和群组加权损失函数的策略，能够有效解决在数据稀缺情况下将大型VLMs应用于动作检测的挑战，显著提升了性能和数据效率。

> **ai_Abstract:** 本文提出了一种数据高效的动作检测方法，旨在解决在有限数据下将大型视频-语言模型（VLMs）应用于动作检测时面临的过拟合和粒度不匹配问题。该方法结合了参数高效微调（LoRA）和一种新颖的可学习内部特征增强技术，通过FiLM在VLM骨干中生成多样化特征。同时，引入了群组加权损失函数，根据样本预测与群组平均值的差异来动态调整训练贡献，以促进鲁棒学习。实验结果表明，该方法在AVA和MOMA等复杂数据集上实现了强大的mAP性能，并显著提升了VLM在有限样本下的数据效率。

> **摘要翻译:** 本文标题：用于数据高效动作检测的群组相对增强

摘要翻译：
仅使用少量示例来适应大型视频-语言模型（VLMs）进行动作检测带来了挑战，例如过拟合以及场景级预训练与所需的人体中心理解之间的粒度不匹配。我们提出了一种高效的自适应策略，该策略将参数高效微调（LoRA）与一种新颖的可学习内部特征增强相结合。这些增强通过FiLM应用于冻结的VLM骨干内部，直接生成与任务相关的多样化特征变体。此外，我们引入了一个群组加权损失函数，该函数根据每个增强样本的预测与群组平均值的差异动态调整其训练贡献。这通过优先处理信息丰富但合理的增强来促进鲁棒学习。我们在复杂的多标签、多人动作检测数据集（AVA、MOMA）上展示了我们方法的有效性，实现了强大的mAP性能，并展示了在有限示例下适应VLM的显著数据效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [825] [PanoSplatt3R: Leveraging Perspective Pretraining for Generalized Unposed Wide-Baseline Panorama Reconstruction](https://arxiv.org/abs/2507.21960)
> *PanoSplatt3R: 利用透视预训练实现广义无姿态宽基线全景重建*

*Jiahui Ren, Mochu Xiang, Jiajun Zhu, Yuchao Dai* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 宽基线全景重建, 无姿态, 透视预训练, RoPE rolling, 新视角合成

**Comment:** Accepted to ICCV 2025

> **TL;DR:** PanoSplatt3R 是一种无需姿态信息的宽基线全景重建方法，通过将透视域预训练扩展到全景域并引入 RoPE rolling，显著优于现有SOTA方法，在实际应用中潜力巨大。

**AI_Comments:** PanoSplatt3R 的创新之处在于其能够进行无姿态的宽基线全景重建，这显著降低了对传统精确姿态数据的依赖，极大地拓展了该技术在实际场景中的应用范围。通过巧妙地将透视域的预训练模型迁移到全景域，并引入 RoPE rolling 机制来适应全景图像的独特周期性，该方法在不牺牲性能的前提下解决了实际部署中的一大痛点，展现了卓越的实用性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有宽基线全景重建方法高度依赖精确的姿态信息，这在实际场景中需要额外计算资源且易受噪声影响，限制了其广泛应用和实用性。

**Method:** 本文提出 PanoSplatt3R，一种无姿态宽基线全景重建方法。该方法将透视域的基础重建预训练扩展并适应到全景域，以实现强大的泛化能力。为确保高效无缝的域迁移，引入了 RoPE rolling，它在不同的注意力头中跨卷绕坐标建模旋转位置嵌入，以最小化对 RoPE 机制的修改，同时建模全景图像的水平周期性。

**Result:** 综合实验表明，PanoSplatt3R 即使在没有姿态信息的情况下，也显著优于当前最先进的方法。其优越性在新视角生成质量和深度估计精度方面均得到体现。

**Conclusion:** PanoSplatt3R 在无姿态信息下实现了卓越的宽基线全景重建，在生成高质量新视角和准确深度估计方面表现出色，具有巨大的实际应用潜力。

> **ai_Abstract:** PanoSplatt3R 提出了一种无需姿态信息的宽基线全景重建方法，旨在克服现有方法对精确姿态信息依赖的局限性。该方法通过将透视域的基础重建预训练扩展到全景域，并引入 RoPE rolling 来处理全景图像的水平周期性，从而实现了强大的泛化能力。实验证明，PanoSplatt3R 在无姿态信息的情况下，在新视角生成和深度估计方面均显著超越了现有SOTA方法，展现了其在实际应用中的巨大潜力。

> **摘要翻译:** 宽基线全景重建已成为一种高效且关键的方法，不仅可以实现周围3D环境的几何重建，还可以生成高度真实和沉浸式的新颖视图。尽管现有方法在各种基准测试中表现出卓越的性能，但它们主要依赖于准确的姿态信息。在实际场景中，获取精确姿态通常需要额外的计算资源，并且极易受噪声影响。这些限制阻碍了此类方法的广泛适用性和实用性。在本文中，我们提出了 PanoSplatt3R，一种无姿态宽基线全景重建方法。我们扩展并调整了透视域的基础重建预训练到全景域，从而实现了强大的泛化能力。为确保无缝高效的域迁移过程，我们引入了 RoPE rolling，它在不同的注意力头中跨旋转位置嵌入中的卷绕坐标进行建模，同时保持对 RoPE 机制的最小修改，并建模全景图像的水平周期性。全面的实验表明，PanoSplatt3R 即使在没有姿态信息的情况下，也显著优于当前最先进的方法。这种优越性在新颖视图生成和深度估计精度方面均显而易见，从而展示了其在实际应用中的巨大潜力。项目页面：https://npucvr.github.io/PanoSplatt3R

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [826] [Signs as Tokens: A Retrieval-Enhanced Multilingual Sign Language Generator](https://arxiv.org/abs/2411.17799)
> *手语即符号：一种检索增强型多语言手语生成器*

*Ronglai Zuo, Rolandos Alexandros Potamias, Evangelos Ververas, Jiankang Deng, Stefanos Zafeiriou* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-29**

**Keywords:** 手语生成, 文本到手语, 多语言模型, 检索增强, 3D化身

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本文介绍了SOKE，一个检索增强型多语言手语生成模型，能从文本生成3D手语化身，提高效率和精度。

**AI_Comments:** 该论文的创新点在于解决了文本到手语生成这一相对未被充分探索的领域，并提出了多项新颖的技术。解耦分词器、多头解码以及检索增强型手语生成方法的结合，有效地提高了生成效率和手语精度，为未来手语生成研究提供了重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有研究已成功将预训练语言模型应用于手语翻译（手语到文本），但逆向任务——手语生成（文本到手语）——仍未被充分探索。

**Method:** 本文引入了SOKE（Signs as Tokens），一个多语言手语模型，能使用预训练语言模型从文本输入自回归地生成3D手语化身。为使手语与语言模型对齐，模型利用解耦分词器将连续手语离散化为代表不同身体部位的符号序列。在解码阶段，与现有方法不同，SOKE提出了多头解码方法，能够同时预测多个符号，提高推理效率并保持不同身体部位间的信息有效融合。此外，模型还提出了检索增强型手语生成方法，通过结合外部手语词典提供准确的词级手语作为辅助条件，显著提高了生成手语的精度。

**Result:** 广泛的定性和定量评估证明了SOKE的有效性。

**Conclusion:** SOKE在手语生成方面表现出有效性，能够从文本生成高质量的3D手语化身，并且在效率和精度上有所提升。

> **ai_Abstract:** SOKE是一个新颖的多语言手语模型，旨在从文本生成3D手语化身，以解决文本到手语生成领域探索不足的问题。它通过解耦分词器将连续手语离散化，并采用多头解码方法以实现高效的并行符号预测。此外，模型引入了检索增强机制，利用外部手语词典作为辅助条件，显著提升了生成手语的精度和效率。

> **摘要翻译:** 手语是一种视觉语言，包含自然语言的所有语言特征，是聋哑和听障社区主要的交流方式。尽管许多研究已成功将预训练语言模型（LMs）应用于手语翻译（手语到文本），但逆向任务——手语生成（文本到手语）——仍未被充分探索。在这项工作中，我们引入了一个多语言手语模型，Signs as Tokens (SOKE)，它可以使用预训练的语言模型从文本输入自回归地生成3D手语化身。为了使手语与语言模型对齐，我们利用了一个解耦分词器，将连续手语离散化为代表各种身体部位的符号序列。在解码过程中，与现有将所有部分符号扁平化为一个单一序列并一次预测一个符号的方法不同，我们提出了一种多头解码方法，能够同时预测多个符号。这种方法在保持不同身体部位间有效信息融合的同时，提高了推理效率。为了进一步简化生成过程，我们提出了一种检索增强型手语生成（SLG）方法，该方法结合了外部手语词典，提供准确的词级手语作为辅助条件，显著提高了生成手语的精度。广泛的定性和定量评估证明了SOKE的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [828] [Knowledge Regularized Negative Feature Tuning of Vision-Language Models for Out-of-Distribution Detection](https://arxiv.org/abs/2507.19847)
> *知识正则化负特征微调视觉-语言模型用于分布外检测*

*Wenjie Zhu, Yabin Zhang, Xin Jin, Wenjun Zeng, Lei Zhang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 分布外检测, 视觉-语言模型, 负特征微调, 知识正则化, 泛化性

**Comment:** accepted by ACMMM 2025

> **TL;DR:** 提出KR-NFT方法，通过负特征微调和知识正则化，提高视觉-语言模型在OOD检测中的泛化性和性能，尤其在未见类别上表现优异。

**AI_Comments:** 这篇论文的创新点在于提出了KR-NFT方法，将负特征微调与知识正则化相结合，有效解决了视觉-语言模型在OOD检测中泛化性不足的问题。特别是在处理未见类别时的性能提升，显示了其在实际应用中的潜力。该方法通过分离特征空间和引入动态适应因子，提供了一种新颖的OOD检测范式，且效率和可扩展性优于传统方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的负提示微调方法虽然提升了视觉-语言模型的OOD检测能力，但在未见类别和风格上的泛化性能有所下降，限制了模型的可靠性。

**Method:** 本文提出知识正则化负特征微调 (KR-NFT) 方法，该方法结合了负特征微调 (NFT) 架构和知识正则化 (KR) 优化策略。NFT通过对预训练文本特征进行分布感知转换，将正负特征有效分离到不同空间，以最大化分布内 (ID) 和分布外 (OOD) 图像的区别；同时引入图像条件可学习因子，实现动态适应。KR策略旨在增强ID和OOD集合之间的区分度，并减轻预训练知识遗忘。

**Result:** KR-NFT相比传统负提示微调具有更高的效率和可扩展性。在ImageNet数据集的少样本训练下，KR-NFT不仅提高了ID分类准确率和OOD检测性能，还在包含未见ID类别的泛化设置下显著降低了FPR95 5.44%。

**Conclusion:** KR-NFT通过其创新的适应架构和优化策略，有效解决了视觉-语言模型在OOD检测中泛化能力下降的问题，显著提升了在已知和未知ID类别上的OOD检测性能和ID分类准确率，为构建更可靠的机器学习模型提供了新途径。

> **ai_Abstract:** 本文提出了一种名为知识正则化负特征微调 (KR-NFT) 的新方法，旨在解决视觉-语言模型在OOD检测中泛化性能下降的问题。KR-NFT结合了负特征微调 (NFT) 架构和知识正则化 (KR) 优化策略。NFT通过对预训练文本特征进行分布感知转换，有效分离正负特征以最大化ID和OOD图像的区别，并通过图像条件可学习因子增强适应性。KR策略则在增强ID和OOD区分度的同时，减轻预训练知识遗忘。实验表明，KR-NFT在提高ID分类准确率和OOD检测性能方面表现优异，尤其在处理未见ID类别时能显著降低FPR95，并展现出更高的效率和可扩展性。

> **摘要翻译:** 分布外 (OOD) 检测对于构建可靠的机器学习模型至关重要。尽管负提示微调增强了视觉-语言模型的OOD检测能力，但这些微调模型在未见类别和风格上的泛化性能往往会下降。为了解决这一挑战，我们提出了一种名为知识正则化负特征微调 (KR-NFT) 的新方法，它集成了创新的适应架构，称为负特征微调 (NFT) 和相应的知识正则化 (KR) 优化策略。具体而言，NFT对预训练文本特征应用分布感知转换，有效地将正负特征分离到不同的空间中。这种分离最大化了分布内 (ID) 图像和OOD图像之间的区别。此外，我们通过一个轻量级元网络引入了图像条件可学习因子，从而能够动态适应单个图像并减轻对类别和风格变化的敏感性。与传统的负提示微调相比，NFT表现出卓越的效率和可扩展性。为了优化这种适应架构，KR优化策略旨在增强ID和OOD集合之间的区分度，同时减轻预训练知识遗忘。这增强了在训练过的ID类别上的OOD检测性能，同时提高了在未见ID数据集上的OOD检测能力。值得注意的是，当使用ImageNet数据集的少样本进行训练时，KR-NFT不仅提高了ID分类准确率和OOD检测，而且在未探索的包含未见ID类别的泛化设置下，FPR95显著降低了5.44%。代码可在 \href{https://github.com/ZhuWenjie98/KRNFT} 找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [830] [Multi-View Reconstruction with Global Context for 3D Anomaly Detection](https://arxiv.org/abs/2507.21555)
> *基于全局上下文的多视角重建三维异常检测*

*Yihan Sun, Yuqi Cheng, Yunkang Cao, Yuxin Zhang, Weiming Shen* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 三维异常检测, 多视角重建, 全局上下文, 点云, 质量检测

**Comment:** 6 pages, 5 figures, IEEE International Conference on Systems, Man,
  and Cybernetics (IEEE SMC), 2025

> **TL;DR:** MVR通过将高分辨率点云转换为多视角图像，并利用重建框架来增强全局信息学习，以提高三维异常检测的精度。

**AI_Comments:** 该论文的创新点在于提出了MVR方法，通过将点云转换为多视角图像并结合重建框架，有效地解决了三维异常检测中全局信息不足的问题。这种方法对于工业质量检测等高精度应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在处理高精度三维异常检测时，由于缺乏足够的全局信息，性能会下降，因此需要一种能增强全局信息学习的方法。

**Method:** 提出多视角重建（MVR）方法，该方法无损地将高分辨率点云转换为多视角图像，并采用基于重建的异常检测框架来增强全局信息学习。

**Result:** MVR在Real3D-AD基准测试中，实现了89.6%的对象级AU-ROC和95.7%的点级AU-ROC。

**Conclusion:** 多视角重建（MVR）方法通过增强全局信息学习，显著提高了高精度三维异常检测的性能。

> **ai_Abstract:** 本文提出了一种名为多视角重建（MVR）的新方法，用于解决高精度三维异常检测中现有方法因全局信息不足导致的性能下降问题。MVR将高分辨率点云无损转换为多视角图像，并结合基于重建的异常检测框架来增强全局信息学习。实验结果表明，该方法在Real3D-AD基准测试上取得了优异的性能，有效提升了三维异常检测的准确性。

> **摘要翻译:** 三维异常检测在工业质量检测中至关重要。尽管现有方法取得了显著进展，但由于全局信息不足，它们在高精度三维异常检测中的性能会下降。为了解决这个问题，我们提出了多视角重建（MVR），一种无损地将高分辨率点云转换为多视角图像并采用基于重建的异常检测框架来增强全局信息学习的方法。大量的实验证明了MVR的有效性，在Real3D-AD基准测试中实现了89.6%的对象级AU-ROC和95.7%的点级AU-ROC。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [838] [SAMITE: Position Prompted SAM2 with Calibrated Memory for Visual Object Tracking](https://arxiv.org/abs/2507.21732)
> *SAMITE：基于位置提示和校准记忆的SAM2模型用于视觉目标跟踪*

*Qianxiong Xu, Lanyun Zhu, Chenxi Liu, Guosheng Lin, Cheng Long, Ziyue Li, Rui Zhao* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 视觉目标跟踪, SAM2, 原型记忆库, 位置提示, 错误传播

**Comment:** 

> **TL;DR:** SAMITE是一个新的视觉目标跟踪模型，它在SAM2的基础上增加了原型记忆库和位置提示生成器，以解决现有方法中存在的遮挡、干扰和错误传播问题，并在多个基准测试中表现出色。

**AI_Comments:** SAMITE的创新点在于其引入了原型记忆库和位置提示生成器，这有效地解决了视觉目标跟踪中的关键挑战，如遮挡、干扰和错误传播。通过量化跟踪结果的正确性并提供显式的位置线索，该模型显著提高了跟踪的鲁棒性和准确性，为基于SAM2的VOT研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉目标跟踪（VOT）方法存在问题：模板匹配方法忽略时间依赖性；自回归方法易偏向训练对象类别，泛化性差。尽管一些方法尝试将视频基础模型SAM2应用于VOT，但它们未能克服目标遮挡和干扰的挑战，也缺乏阻止跟踪错误传播的措施。

**Method:** 本文提出了SAMITE模型，它在SAM2的基础上增加了两个模块：1) 原型记忆库：量化每帧跟踪结果的特征和位置正确性，并选择最佳帧来条件化后续帧，从而过滤掉因遮挡和干扰导致不准确的结果，以阻止错误传播。2) 位置提示生成器：生成位置掩码提示，为目标提供明确的位置线索，以进一步减少干扰物的影响，提高跟踪精度。

**Result:** 在六个基准测试上进行了广泛的实验，结果显示SAMITE表现出优越性。

**Conclusion:** SAMITE模型通过引入原型记忆库和位置提示生成器，有效解决了视觉目标跟踪中遮挡、干扰和错误传播的挑战，显著提升了跟踪性能。

> **ai_Abstract:** 本文提出了SAMITE模型，这是一种基于SAM2的视觉目标跟踪（VOT）方法，旨在解决现有VOT方法在处理遮挡、干扰和错误传播方面的不足。SAMITE引入了原型记忆库来量化并选择最佳跟踪帧以阻止错误传播，并使用位置提示生成器提供明确的目标位置线索，以减少干扰影响。在六个基准测试上的实验证明了SAMITE的优越性能。

> **摘要翻译:** 视觉目标跟踪（VOT）广泛应用于自动驾驶等领域，用于连续跟踪视频中的目标。现有方法大致可分为模板匹配和自回归方法，前者通常忽略帧间的时间依赖性，后者在训练时容易偏向对象类别，对未见类别显示出较弱的泛化能力。为了解决这些问题，一些方法提出将视频基础模型SAM2应用于VOT，其中每帧的跟踪结果将被编码为记忆，以自回归方式条件化其余帧。然而，现有方法未能克服目标遮挡和干扰的挑战，并且没有任何措施来阻止跟踪错误的传播。为了解决这些问题，我们提出了一种SAMITE模型，它在SAM2的基础上增加了额外的模块，包括：(1) 原型记忆库：我们提出量化每帧跟踪结果的特征和位置正确性，并选择最佳帧来条件化后续帧。由于被遮挡和分散注意力的对象的特征在特征和位置上都不准确，它们的得分自然会更低，从而可以被过滤以阻止错误传播；(2) 位置提示生成器：为了进一步减少干扰物的影响，我们提出生成位置掩码提示，为目标提供明确的位置线索，从而实现更准确的跟踪。在六个基准测试上进行了广泛的实验，显示了SAMITE的优越性。代码可在https://github.com/Sam1224/SAMITE获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [847] [SCALAR: Scale-wise Controllable Visual Autoregressive Learning](https://arxiv.org/abs/2507.19946)
> *SCALAR：尺度级可控视觉自回归学习*

*Ryan Xu, Dongyang Jin, Yancheng Bai, Rui Lan, Xu Duan, Lei Sun, Xiangxiang Chu* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 视觉自回归模型, 可控图像合成, 尺度级条件解码, SCALAR, 多模态控制

**Comment:** 

> **TL;DR:** SCALAR提出了一种基于视觉自回归模型的可控图像生成方法，通过尺度级条件解码机制提高了生成质量和控制精度。

**AI_Comments:** SCALAR的创新之处在于其“尺度级条件解码机制”，该机制通过将控制信号与VAR模型的层次结构对齐，有效解决了传统VAR模型在可控生成中效率低下和破坏性注入的问题。这种方法不仅提升了生成图像的质量和控制精度，还通过SCALAR-Uni扩展了多模态控制能力，为视觉生成领域带来了新的突破。

<details>
  <summary>Details</summary>

**Motivation:** 可控图像合成是视觉生成建模的关键焦点，但现有的视觉自回归（VAR）模型在实现高效且精确的可控生成方面面临挑战，常因控制编码效率低下和注入机制破坏性而影响保真度和效率。

**Method:** SCALAR引入了一种新颖的尺度级条件解码机制。它利用预训练的图像编码器提取语义控制信号编码，并将其投影到特定尺度的表示中，然后注入到VAR骨干网络的相应层中，从而在整个生成过程中提供持续且结构对齐的引导。在此基础上，SCALAR-Uni将多种控制模态对齐到共享潜在空间，支持单一模型中的灵活多条件引导。

**Result:** SCALAR在各种任务中实现了卓越的生成质量和控制精度。

**Conclusion:** SCALAR通过其尺度级条件解码机制，显著提升了视觉自回归模型在可控图像合成方面的性能，并能扩展支持多模态控制。

> **ai_Abstract:** SCALAR是一种针对视觉自回归（VAR）模型的可控图像生成方法，旨在解决现有VAR模型在可控性方面的效率和保真度问题。该方法引入了尺度级条件解码机制，通过预训练图像编码器提取语义控制信号，并将其按比例注入VAR网络的相应层，提供持续的生成指导。在此基础上，SCALAR-Uni进一步实现了多模态控制。实验证明，SCALAR在图像生成质量和控制精度上均表现出色。

> **摘要翻译:** 可控图像合成，使得对生成输出进行精细控制成为可能，已成为视觉生成建模的关键焦点。然而，对于视觉自回归（VAR）模型而言，由于其分层的、下一尺度预测的风格，可控生成仍然具有挑战性。现有的基于VAR的方法常常因低效的控制编码和破坏性的注入机制而影响保真度和效率。在这项工作中，我们提出了SCALAR，一种基于VAR的可控生成方法，它结合了一种新颖的尺度级条件解码机制。SCALAR利用预训练的图像编码器提取语义控制信号编码，这些编码被投影到特定尺度的表示中，并注入到VAR骨干网络的相应层中。这种设计在整个生成过程中提供了持续且结构对齐的引导。在SCALAR的基础上，我们开发了SCALAR-Uni，一个统一的扩展，它将多种控制模态对齐到一个共享的潜在空间中，支持单一模型中的灵活多条件引导。大量的实验表明，SCALAR在各种任务中实现了卓越的生成质量和控制精度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [851] [Predict Patient Self-reported Race from Skin Histological Images](https://arxiv.org/abs/2507.21912)
> *从皮肤组织学图像预测患者自我报告的种族*

*Shengjia Chen, Ruchika Verma, Kevin Clare, Jannes Jegminat, Eugenia Alleva, Kuan-lin Huang, Brandon Veremis, Thomas Fuchs, Gabriele Campanella* | **Category: cs.CV, cs.CE** | **Updated: 2025-07-30**

**Keywords:** 人工智能偏见, 计算病理学, 种族预测, 皮肤组织学图像, 深度学习

**Comment:** Accepted to the MICCAI Workshop on Fairness of AI in Medical Imaging
  (FAIMI), 2025

> **TL;DR:** 深度学习模型可以从皮肤组织学图像中预测患者自我报告的种族，揭示了人工智能在计算病理学中学习人口偏见的风险，并强调了数据整理和偏见缓解的重要性。

**AI_Comments:** 本研究通过直接调查AI模型在计算病理学中可能产生的意想不到的人口偏见，具有创新性。它揭示了AI在医疗应用中一个重要的伦理问题，即模型可能从医学图像中学习到敏感的人口属性。对表皮作为“捷径”特征的识别尤其有见地，为未来偏见缓解策略提供了具体的方向。这些发现对于促进AI在医疗保健应用中的公平性和公正性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能在计算病理学中已成功应用于疾病检测、生物标志物分类和预后预测，但其学习意想不到的人口偏见，特别是与健康社会决定因素相关的偏见的潜力仍未得到充分研究。本研究旨在调查深度学习模型是否可以从数字化皮肤病理学幻灯片中预测自我报告的种族，并识别潜在的形态学捷径。

**Method:** 本研究使用了一个包含不同种族人群的多中心数据集，并应用了基于注意力的深度学习模型来揭示与种族相关的形态学特征。研究评估了三种数据集整理策略以控制混杂因素，并通过注意力分析识别关键预测特征。

**Result:** 在控制混杂因素后，白人和黑人人口群体的预测性能仍然很高（AUC：0.799，0.762），而总体性能下降到0.663。注意力分析显示表皮是关键的预测特征，当这些区域被移除时，性能显著下降。

**Conclusion:** 研究结果强调了在病理学中公平部署人工智能需要仔细的数据整理和偏见缓解。

> **ai_Abstract:** 本研究旨在探讨深度学习模型是否能从皮肤组织学图像中预测患者自我报告的种族，以解决计算病理学人工智能中人口偏见未被充分研究的问题。研究利用一个多中心、多族裔数据集，通过注意力机制识别与种族相关的形态特征。结果显示，在控制混杂因素后，模型对白人和黑人族群的预测性能依然较高，并发现表皮是关键的预测特征。这些发现强调了在病理学中部署公平人工智能时，数据整理和偏见缓解的重要性。

> **摘要翻译:** 人工智能 (AI) 在计算病理学 (CPath) 中已成功应用于疾病检测、生物标志物分类和预后预测。然而，其学习意想不到的人口偏见，特别是与健康社会决定因素相关的偏见的潜力仍未得到充分研究。本研究调查了深度学习模型是否可以从数字化皮肤病理学幻灯片中预测自我报告的种族，并识别潜在的形态学捷径。我们使用一个包含不同种族人群的多中心数据集，应用基于注意力的机制来揭示与种族相关的形态学特征。在评估了三种数据集整理策略以控制混杂因素后，最终的实验表明，白人和黑人人口群体的预测性能仍然很高（AUC：0.799，0.762），而总体性能下降到0.663。注意力分析显示表皮是关键的预测特征，当这些区域被移除时，性能显著下降。这些发现强调了需要仔细的数据整理和偏见缓解，以确保在病理学中公平部署人工智能。代码可在以下网址获取：https://github.com/sinai-computational-pathology/CPath_SAIF。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [860] [A Deep Learning Pipeline Using Synthetic Data to Improve Interpretation of Paper ECG Images](https://arxiv.org/abs/2507.21968)
> *使用合成数据改进纸质心电图图像判读的深度学习流程*

*Xiaoyu Wang, Ramesh Nadarajah, Zhiqiang Zhang, David Wong* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 深度学习, 心电图图像, 合成数据, 自动判读, ConvNeXt

**Comment:** 

> **TL;DR:** 该研究提出了一种深度学习框架，利用合成数据和两阶段微调策略，有效分类纸质心电图图像，并在BHF挑战赛中取得了高AUROC分数，有望实现心电图自动判读。

**AI_Comments:** 该论文的创新点在于专注于纸质心电图图像的自动判读，这弥补了现有研究多关注数字信号的不足，更贴近临床实际。通过引入合成数据和两阶段微调策略，有效应对了纸质图像特有的视觉噪声和细节识别挑战，展示了深度学习在解决实际医疗数据问题上的强大能力和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 心血管疾病是全球主要的死亡原因，早期检测至关重要。心电图是识别心血管疾病的关键工具，但人工判读耗时且需要专业知识。尽管数字信号的自动判电图判读已有进展，但临床实践中大多数心电图数据以图像形式存储或共享，存在将图像形式的心电图自动分类的空白和挑战（视觉噪声和精细波形检测）。

**Method:** 该研究提出了一个专门用于分类纸质心电图图像的深度学习框架。方法包括一个减少视觉噪声的预处理流程，以及一个两阶段微调策略：首先在合成和外部心电图图像数据集上进行微调以学习领域特定特征，然后进一步在目标数据集上微调以增强疾病特异性识别。模型骨干采用ConvNeXt架构。

**Result:** 该方法在英国心脏基金会开放数据科学挑战赛的公共验证集上取得了0.9688的AUROC分数，在私有测试集上取得了0.9677的AUROC分数。

**Conclusion:** 该研究提出的深度学习方法在纸质心电图图像分类方面表现出色，其高AUROC分数凸显了其作为临床工作流中自动化心电图判读实用工具的潜力。

> **ai_Abstract:** 本研究提出了一种深度学习框架，旨在解决临床实践中纸质心电图图像自动分类的挑战。该框架针对视觉噪声和精细波形识别问题，设计了预处理流程和两阶段微调策略，利用合成数据和ConvNeXt架构，实现了对纸质心电图图像的有效诊断分类。该方法在英国心脏基金会开放数据科学挑战赛中取得优异成绩，验证了其在自动化心电图判读方面的应用潜力。

> **摘要翻译:** 心血管疾病（CVDs）是全球主要的死亡原因，早期检测对于改善患者预后至关重要。心电图（ECGs），特别是12导联心电图，在识别心血管疾病中发挥着关键作用。这些通常由人类专家判读，这是一个耗时且需要专业知识的过程。该领域的历史研究主要集中于从数字信号自动判读心电图，最近的深度学习方法取得了显著成果。然而，在实践中，临床实践中大多数心电图数据以图像形式存储或共享。为了弥补这一差距，我们提出了一个专门设计用于将纸质心电图图像分为五种主要诊断类别的深度学习框架。我们的方法是2024年英国心脏基金会开放数据科学挑战赛的获胜作品。它解决了纸质心电图分类的两个主要挑战：视觉噪声（例如阴影或折痕）以及检测精细波形模式的需求。我们提出了一个减少视觉噪声的预处理流程和两阶段微调策略：模型首先在合成和外部心电图图像数据集上进行微调以学习领域特定特征，然后进一步在目标数据集上微调以增强疾病特异性识别。我们采用ConvNeXt架构作为模型的骨干。我们的方法在英国心脏基金会开放数据科学挑战赛的公共验证集上取得了0.9688的AUROC分数，在私有测试集上取得了0.9677的AUROC分数，突显了其作为临床工作流中自动化心电图判读实用工具的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [861] [AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning](https://arxiv.org/abs/2412.03248)
> *AIM：通过令牌合并和剪枝实现多模态大型语言模型自适应推理*

*Yiwu Zhong, Zhuoming Liu, Yin Li, Liwei Wang* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-29**

**Keywords:** 多模态LLM, 自适应推理, 令牌合并, 令牌剪枝, 计算效率

**Comment:** Accepted to ICCV 2025

> **TL;DR:** AIM提出了一种无训练的自适应推理方法，通过令牌合并和剪枝显著降低多模态LLM的计算量，同时保持性能。

**AI_Comments:** AIM的创新点在于其无训练的自适应推理方法，通过结合令牌合并和剪枝，有效解决了多模态LLM的计算效率问题。其极简设计使其能够广泛应用于不同类型的多模态LLM，并且在性能保持甚至提升的同时实现了显著的计算量减少。这项工作对于推动多模态LLM在实际应用中的部署具有重要意义，尤其是在资源受限的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（LLMs）在处理视觉数据时依赖大量视觉令牌，导致计算需求高，限制了其在资源受限环境和长上下文任务中的应用。

**Method:** 我们提出了一种无训练的自适应推理方法，包括：a) 在LLM之前基于嵌入相似性的迭代令牌合并；b) 在LLM层内基于多模态重要性的渐进令牌剪枝。该方法设计简洁，可应用于视频和图像LLM。

**Result:** 在多种视频和图像基准测试中，我们的方法显著降低了计算负载（例如，FLOPs减少7倍），同时保持了视频和图像LLM的性能。在相似计算成本下，我们的方法在长视频理解方面优于现有SOTA方法（例如，MLVU上提升4.6）。

**Conclusion:** AIM通过令牌合并和剪枝提供了一种高效的自适应推理方法，显著降低了多模态LLM的计算成本，同时保持或提升了性能，并为未来设计高效多模态LLM提供了见解。

> **ai_Abstract:** 本文提出了一种名为AIM的无训练自适应推理方法，用于多模态大型语言模型（LLMs）。针对现有模型计算量大、不适用于资源受限环境的问题，AIM通过在LLM前进行基于嵌入相似性的迭代令牌合并和在LLM层内进行基于多模态重要性的渐进令牌剪枝，显著减少了计算负载（例如，FLOPs减少7倍），同时保持甚至提升了性能。该方法适用于图像和视频LLMs，并在长视频理解等任务上超越了现有技术。研究还提供了关于令牌冗余和LLM层行为的深入分析，为未来高效多模态LLM的设计提供了指导。

> **摘要翻译:** 大型语言模型（LLMs）使得多模态LLMs的创建成为可能，这些模型对图像和视频等视觉数据表现出强大的理解能力。然而，这些模型通常依赖于视觉编码器生成的大量视觉令牌，导致计算需求高，这限制了它们在资源受限环境和长上下文任务中的适用性。在这项工作中，我们提出了一种针对多模态LLMs的无训练自适应推理方法，该方法能够在性能下降最小的情况下适应各种效率要求。我们的方法包括：a) 在LLMs之前基于嵌入相似性的迭代令牌合并；b) 在LLM层内基于多模态重要性的渐进令牌剪枝。通过极简设计，我们的方法可以应用于视频和图像LLMs。在各种视频和图像基准测试中进行的大量实验表明，我们的方法显著降低了计算负载（例如，FLOPs减少7倍），同时保持了视频和图像LLMs的性能。此外，在相似的计算成本下，我们的方法在长视频理解方面优于现有最先进的方法（例如，MLVU上提升4.6）。此外，我们的深入分析提供了关于令牌冗余和LLM层行为的见解，为未来设计高效多模态LLMs的研究提供了指导。我们的代码可在https://github.com/LaVi-Lab/AIM获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [869] [When Tokens Talk Too Much: A Survey of Multimodal Long-Context Token Compression across Images, Videos, and Audios](https://arxiv.org/abs/2507.20198)
> *当Token“话太多”时：图像、视频和音频多模态长上下文Token压缩综述*

*Kele Shao, Keda Tao, Kejia Zhang, Sicheng Feng, Mu Cai, Yuzhang Shang, Haoxuan You, Can Qin, Yang Sui, Huan Wang* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 多模态大语言模型, Token压缩, 长上下文, 图像压缩, 视频压缩, 音频压缩

**Comment:** For ongoing updates and to track the latest advances in this
  promising area, we maintain a public repository:
  https://github.com/cokeshao/Awesome-Multimodal-Token-Compression

> **TL;DR:** 本文综述了多模态长上下文Token压缩技术，旨在解决多模态大语言模型处理长上下文时面临的计算挑战，并对现有方法进行了系统分类。

**AI_Comments:** 这是一篇重要的综述性文章，它填补了多模态长上下文Token压缩领域系统性梳理的空白。其创新之处在于首次对该新兴领域进行了全面的分类和综合，特别是根据模态特性和底层机制进行细致划分，这对于研究人员理解现有方法并选择合适策略具有极大的指导意义。该综述的重要性在于它明确指出了MLLMs在处理长上下文时的计算瓶颈，并提出了Token压缩这一关键解决方案，有助于推动该领域的研究进展和实际应用。同时，维护公共存储库的做法也体现了其对领域发展的持续贡献。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在处理长而复杂的上下文（如高分辨率图像、长视频序列和长音频输入）方面取得了显著进展，但这导致了巨大的计算挑战，主要是由于自注意力机制与大量输入Token的二次方复杂度。为了缓解这些瓶颈，Token压缩作为一种有效减少训练和推理期间Token数量的关键方法应运而生。

**Method:** 本文首次对多模态长上下文Token压缩这一新兴领域进行了系统的综述和综合。研究根据主要数据焦点（图像、视频、音频）对现有方法进行分类，并进一步根据底层机制（包括基于转换、基于相似性、基于注意力、基于查询的方法）进行剖析。

**Result:** 本综述旨在整合当前进展，识别关键挑战，并启发该快速发展领域的未来研究方向。

**Conclusion:** 该综述提供了一个全面且结构化的概述，并维护一个公共存储库以持续跟踪和更新该有前景领域的最新进展。

> **ai_Abstract:** 本篇综述首次系统地回顾了多模态长上下文Token压缩领域。针对多模态大语言模型处理长上下文带来的计算挑战，文章详细介绍了Token压缩的重要性。研究根据数据模态（图像、视频、音频）和底层机制（基于转换、相似性、注意力、查询）对现有压缩方法进行了分类和剖析，旨在整合当前进展、识别关键挑战并为未来研究提供方向。

> **摘要翻译:** 多模态大语言模型（MLLMs）取得了显著进展，这主要得益于它们处理日益增长和复杂上下文的能力，例如高分辨率图像、扩展的视频序列和冗长的音频输入。尽管这种能力显著增强了MLLM的性能，但它引入了巨大的计算挑战，主要由于自注意力机制与大量输入Token的二次方复杂度。为了缓解这些瓶颈，Token压缩已成为一种有前途且关键的方法，可以有效地减少训练和推理期间的Token数量。在本文中，我们首次对多模态长上下文Token压缩这一新兴领域进行了系统性的综述和综合。认识到有效的压缩策略与每种模态的独特特征和冗余性密切相关，我们根据其主要数据焦点对现有方法进行分类，使研究人员能够快速访问和学习针对其特定兴趣领域量身定制的方法：（1）以图像为中心的压缩，解决视觉数据中的空间冗余；（2）以视频为中心的压缩，解决动态序列中的时空冗余；（3）以音频为中心的压缩，处理声学信号中的时间冗余和频谱冗余。除了这种模态驱动的分类之外，我们还根据其底层机制进一步剖析了方法，包括基于转换、基于相似性、基于注意力、和基于查询的方法。通过提供一个全面且结构化的概述，本综述旨在整合当前进展，识别关键挑战，并启发这个快速发展领域的未来研究方向。我们还维护一个公共存储库，以持续跟踪和更新这个有前景领域的最新进展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [882] [DIVE: Taming DINO for Subject-Driven Video Editing](https://arxiv.org/abs/2412.03347)
> *DIVE：驯服DINO实现主体驱动的视频编辑*

*Yi Huang, Wei Xiong, He Zhang, Chaoqi Chen, Jianzhuang Liu, Mingfu Yan, Shifeng Chen* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 视频编辑, DINO, 时间一致性, 主体驱动, 扩散模型

**Comment:** Accepted by ICCV 2025

> **TL;DR:** DIVE提出一个利用DINO特征解决视频编辑中时间一致性和主体身份保持的框架，实现了高质量的视频编辑。

**AI_Comments:** 该论文的创新点在于将DINOv2模型的强大语义特征引入到视频编辑领域，有效地解决了传统视频编辑中时间一致性和主体身份保持的难题。通过利用DINO特征进行运动对齐和身份注册，DIVE为高质量、主体驱动的视频编辑提供了一个新颖且有效的方法，展示了DINO在视频处理领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管扩散模型在图像生成和编辑方面取得了成功，但视频编辑在保持时间一致性和运动对齐方面仍面临挑战。

**Method:** 本文提出了DINO引导的视频编辑（DIVE）框架。其核心是利用预训练DINOv2模型提取的语义特征作为隐式对应关系来指导编辑过程。具体来说，DIVE利用DINO特征与源视频的运动轨迹对齐，以确保时间运动一致性；同时，将参考图像的DINO特征整合到预训练的文本到图像模型中，学习低秩适应（LoRAs），从而有效地注册目标主体的身份。

**Result:** 在各种真实世界视频上的大量实验表明，我们的框架能够实现高质量的编辑结果，并具有鲁棒的运动一致性。

**Conclusion:** DIVE框架突出显示了DINO在视频编辑方面的潜力。

> **ai_Abstract:** DIVE是一个用于主体驱动视频编辑的框架，旨在解决视频编辑中时间一致性和运动对齐的挑战。它利用预训练DINOv2模型的语义特征作为隐式对应关系，通过DINO特征与源视频运动轨迹对齐来确保时间一致性，并通过将参考图像的DINO特征整合到文本到图像模型中学习LoRAs来注册主体身份。实验证明，DIVE能在真实视频上实现高质量且运动一致的编辑效果。

> **摘要翻译:** 在扩散模型在图像生成和编辑方面取得成功的基础上，视频编辑最近受到了广泛关注。然而，保持时间一致性和运动对齐仍然具有挑战性。为了解决这些问题，本文提出了DINO引导的视频编辑（DIVE），一个旨在促进源视频中主体驱动编辑的框架，该编辑可以基于目标文本提示或具有特定身份的参考图像进行条件设置。DIVE的核心在于利用从预训练DINOv2模型中提取的强大语义特征作为隐式对应关系来指导编辑过程。具体来说，为了确保时间运动一致性，DIVE采用DINO特征与源视频的运动轨迹对齐。为了实现精确的主体编辑，DIVE将参考图像的DINO特征整合到预训练的文本到图像模型中，以学习低秩适应（LoRAs），从而有效地注册目标主体的身份。在各种真实世界视频上的大量实验表明，我们的框架能够实现高质量的编辑结果，并具有鲁棒的运动一致性，突出了DINO对视频编辑的潜在贡献。项目页面：https://dino-video-editing.github.io

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [883] [From Gallery to Wrist: Realistic 3D Bracelet Insertion in Videos](https://arxiv.org/abs/2507.20331)
> *从图库到手腕：视频中逼真的3D手镯插入*

*Chenjian Gao, Lihe Ding, Rui Han, Zhanpeng Huang, Zibin Wang, Tianfan Xue* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 视频物体插入, 3D高斯溅射, 2D扩散模型, 时间一致性, 逼真光照

**Comment:** 12 pages

> **TL;DR:** 结合3D高斯溅射（3DGS）和2D扩散模型，实现视频中逼真、时间一致的3D手镯插入。

**AI_Comments:** 该论文的创新之处在于首次将3D渲染（3DGS）和2D扩散模型相结合用于视频物体插入，有效弥补了单一范式在时间一致性和光照逼真度上的不足。这种混合方法提供了一个新颖且前景广阔的解决方案，对于增强现实、虚拟试穿等应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在计算机图形学中，将3D物体插入视频是一个长期存在的挑战，尤其是在动态场景中实现时间一致性和逼真光照方面。现有的2D扩散模型难以保持时间连贯性，而传统3D渲染方法在光照逼真度上有所欠缺。

**Method:** 本文提出一种混合物体插入流程，结合3D高斯溅射（3DGS）的时间一致性和2D扩散模型的逼真光照能力。具体地，利用3DGS进行初始渲染，然后使用2D扩散增强模型进行结果细化，以确保逼真的光照交互。该方法引入了一个着色驱动的流程，分离物体固有属性，并优化着色和sRGB图像以实现照片级真实感。为了保持时间连贯性，通过多帧加权调整优化3DGS模型。

**Result:** 该方法是首次将3D渲染和2D扩散相结合用于视频物体插入，提供了一个用于逼真和一致视频编辑的鲁棒解决方案。

**Conclusion:** 通过结合3D渲染和2D扩散模型的优势，本文成功解决了视频中3D物体插入在时间一致性和逼真光照方面的挑战，为视频编辑提供了一个强大的新工具。

> **ai_Abstract:** 本文提出一种混合方法，将3D高斯溅射与2D扩散模型相结合，解决视频中3D物体插入在时间一致性和光照逼真度方面的挑战。该方法利用3DGS实现时间连贯性，并通过2D扩散增强模型细化光照效果，专注于在动态手腕场景中插入手镯。通过优化3DGS模型和引入着色驱动的流程，实现了逼真且一致的视频编辑。这是首次将两种范式结合用于鲁棒视频物体插入的方法。

> **摘要翻译:** 将3D物体插入视频是计算机图形学中一个长期存在的挑战，在增强现实、虚拟试穿和视频合成等领域都有应用。实现时间一致性和逼真光照仍然很困难，特别是在具有复杂物体运动、视角变化和不同光照的动态场景中。虽然2D扩散模型在生成照片级真实感编辑方面表现出前景，但它们通常难以保持帧间的时间连贯性。相反，传统3D渲染方法在空间和时间一致性方面表现出色，但在实现照片级真实感光照方面有所不足。在这项工作中，我们提出了一种混合物体插入流程，结合了这两种范式的优点。具体来说，我们专注于将手镯插入动态手腕场景中，利用3D高斯溅射（3DGS）的高时间一致性进行初始渲染，并使用基于2D扩散的增强模型细化结果，以确保逼真的光照交互。我们的方法引入了一种着色驱动的流程，它分离了物体的固有属性（反照率、着色、反射率），并细化了着色和sRGB图像以实现照片级真实感。为了保持时间连贯性，我们通过多帧加权调整优化了3DGS模型。这是首次将3D渲染和2D扩散相结合用于视频物体插入的方法，为逼真和一致的视频编辑提供了一个鲁棒的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [884] [PanoGAN A Deep Generative Model for Panoramic Dental Radiographs](https://arxiv.org/abs/2507.21200)
> *PanoGAN：一种全景牙科X射线图像的深度生成模型*

*Soren Pedersen, Sanyam Jain, Mikkel Chavez, Viktor Ladehoff, Bruna Neves de Freitas, Ruben Pauwels* | **Category: cs.CV, cs.ET, cs.LG, eess.IV** | **Updated: 2025-07-28**

**Keywords:** 全景牙科X射线图像, 生成对抗网络, 数据增强, DCGAN, 牙科成像

**Comment:** 

> **TL;DR:** 该研究开发了一种名为PanoGAN的深度生成模型，用于合成牙科全景X射线图像，旨在解决牙科数据稀缺问题。

**AI_Comments:** 该论文通过开发PanoGAN，为解决牙科领域数据稀缺的挑战提供了一个创新的解决方案。其亮点在于使用了WGANGP来提高生成图像的质量和稳定性，并对不同预处理策略（如去噪）对生成效果的影响进行了深入探讨，揭示了细节保留与整体清晰度之间的权衡。尽管是探索性研究，且仍存在伪影问题，但其为未来牙科影像学中的生成模型研究奠定了坚实的基础，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决牙科研究和教育中数据稀缺的问题，通过合成牙科全景X射线图像来扩充数据。

**Method:** 本研究开发了一个生成对抗网络（GAN），具体是使用带有梯度惩罚的Wasserstein损失（WGANGP）的深度卷积GAN（DCGAN）。模型在包含2322张不同质量X射线图像的数据集上进行训练，主要关注牙槽区域。进行了广泛的预处理和数据清洗以标准化输入。研究探索了四种候选模型，通过改变判别器迭代次数、特征深度以及训练前是否使用去噪来优化模型。

**Result:** 临床专家根据解剖可见性和真实感对生成的X射线图像进行了5分制评估。大多数图像显示出中等的解剖描绘，但有些图像受到伪影的干扰。研究观察到一种权衡：在未去噪数据上训练的模型能够产生更精细的细节，特别是在下颌管和骨小梁等结构中；而在去噪数据上训练的模型则提供了卓越的整体图像清晰度和锐度。

**Conclusion:** 这些发现为未来在牙科成像中基于GAN的方法奠定了基础。

> **ai_Abstract:** 本研究开发了PanoGAN，一种基于深度卷积GAN（DCGAN）和WGANGP的生成模型，用于合成牙科全景X射线图像，以应对牙科数据稀缺问题。模型在2322张图像数据集上训练，并经过严格预处理。通过改变模型参数探索了四种候选模型，并由临床专家评估。结果显示，生成的图像具有中等解剖描绘，且发现去噪处理对图像细节和整体清晰度存在权衡。该研究为牙科成像中的GAN应用奠定了基础。

> **摘要翻译:** 本文介绍了一种用于合成牙科全景X射线图像的生成对抗网络（GAN）的开发。尽管具有探索性质，但该研究旨在解决牙科研究和教育中数据稀缺的问题。我们使用带有梯度惩罚的Wasserstein损失（WGANGP）的深度卷积GAN（DCGAN）在包含2322张不同质量X射线图像的数据集上进行了训练。重点放在牙槽区域，其他解剖结构被裁剪掉。进行了广泛的预处理和数据清洗以标准化输入，同时保留解剖变异性。我们通过改变判别器迭代次数、特征深度以及训练前是否使用去噪，探索了四种候选模型。临床专家根据解剖可见性和真实感，使用5分制（1分非常差，5分优秀）对生成的X射线图像进行了评估。大多数图像显示出中等的解剖描绘，尽管有些图像因伪影而退化。观察到一种权衡：在未去噪数据上训练的模型产生了更精细的细节，特别是在下颌管和骨小梁等结构中，而在去噪数据上训练的模型则提供了卓越的整体图像清晰度和锐度。这些发现为未来在牙科成像中基于GAN的方法奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [886] [RelMap: Enhancing Online Map Construction with Class-Aware Spatial Relation and Semantic Priors](https://arxiv.org/abs/2507.21567)
> *RelMap：通过类别感知空间关系和语义先验增强在线地图构建*

*Tianhui Cai, Yun Zhang, Zewei Zhou, Zhiyu Huang, Jiaqi Ma* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 在线地图构建, 高精地图, 空间关系, 语义先验, Transformer

**Comment:** 

> **TL;DR:** RelMap是一个端到端框架，通过引入类别感知空间关系先验和基于MoE的语义先验，提升了在线高清地图构建的准确性和泛化能力。

**AI_Comments:** RelMap的创新之处在于其明确地引入了类别感知空间关系先验和基于MoE的语义先验，以解决现有Transformer方法在在线高清地图构建中忽视地图元素关系的问题。这种对关系和语义的深度建模有助于提升模型在复杂场景下的准确性和泛化能力，对于自动驾驶领域的地图构建具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于Transformer的在线高清地图构建方法忽略了地图元素固有的空间和语义关系，这限制了它们的准确性和泛化能力。

**Method:** 本文提出了RelMap，一个端到端的框架。它引入了类别感知空间关系先验（Class-aware Spatial Relation Prior），使用可学习的类别感知关系编码器明确编码地图元素之间的相对位置依赖。此外，它还提出了基于专家混合（MoE）的语义先验（Semantic Prior），根据预测的类别概率将特征路由到特定类别的专家，以优化实例特征解码。该方法兼容单帧和时序感知骨干网络。

**Result:** RelMap在nuScenes和Argoverse 2数据集上均取得了最先进的性能。

**Conclusion:** 通过整合类别感知空间关系和语义先验，RelMap显著提升了在线高清地图构建的准确性和泛化能力，达到了最先进的性能。

> **ai_Abstract:** RelMap是一个端到端框架，旨在通过整合类别感知空间关系先验和基于专家混合（MoE）的语义先验来改进在线高清地图构建。现有方法忽视地图元素间的空间和语义关系导致准确性受限。RelMap通过引入可学习的类别感知关系编码器来编码相对位置依赖，并通过MoE机制细化实例特征解码。该方法兼容多种感知骨干网络，并在nuScenes和Argoverse 2数据集上实现了最先进的性能。

> **摘要翻译:** 在线高精（HD）地图构建在自动驾驶系统规模化中扮演着越来越重要的角色。基于Transformer的方法在在线高精地图构建中已变得普遍；然而，现有方法常常忽略地图元素固有的空间和语义关系，这限制了它们的准确性和泛化能力。为了解决这个问题，我们提出了RelMap，一个通过结合空间关系和语义先验来增强在线地图构建的端到端框架。我们引入了一种类别感知空间关系先验，它使用可学习的类别感知关系编码器明确编码地图元素之间的相对位置依赖。此外，我们提出了一种基于专家混合（MoE）的语义先验，它根据预测的类别概率将特征路由到特定类别的专家，从而细化实例特征解码。我们的方法兼容单帧和时序感知骨干网络，在nuScenes和Argoverse 2数据集上均取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [892] [Collaborative Perceiver: Elevating Vision-based 3D Object Detection via Local Density-Aware Spatial Occupancy](https://arxiv.org/abs/2507.21358)
> *协同感知器：通过局部密度感知空间占用提升基于视觉的3D目标检测*

*Jicheng Yuan, Manh Nguyen Duc, Qian Liu, Manfred Hauswirth, Danh Le Phuoc* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 3D目标检测, 视觉, 鸟瞰图, 空间占用, 多任务学习

**Comment:** The manuscript has been accepted by ICONIP2025

> **TL;DR:** Collaborative Perceiver (CoP) 框架通过将空间占用作为辅助信息，显著提升了基于视觉的3D目标检测性能。

**AI_Comments:** CoP的创新之处在于其多任务学习框架，将空间占用作为辅助信息，有效弥补了现有视觉BEV 3D目标检测方法在环境上下文感知方面的不足。LDO、VHS和CFF等模块的设计使得模型能够更细致地理解物理世界，从而生成更鲁棒的BEV表示。这对于提升自动驾驶中3D目标检测的准确性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于视觉的鸟瞰图 (BEV) 3D目标检测方法在构建BEV表示时，常忽略道路和人行道等内在环境上下文，这阻碍了检测器全面感知物理世界特征。

**Method:** 本文引入了一个名为Collaborative Perceiver (CoP) 的多任务学习框架，该框架利用空间占用作为辅助信息，以挖掘3D目标检测和占用预测任务之间共享的一致结构和概念相似性。具体包括：1) 提出一个生成包含局部密度信息 (LDO) 的密集占用真值的管道；2) 采用体素高度引导采样 (VHS) 策略，根据不同的对象属性提取细粒度局部特征；3) 开发一个全局-局部协同特征融合 (CFF) 模块，无缝整合两任务之间的互补知识，从而构成更鲁棒的BEV表示。

**Result:** 在nuScenes基准测试中，CoP超越了现有的基于视觉的框架，在测试集上实现了49.5%的mAP和59.2%的NDS。

**Conclusion:** Collaborative Perceiver (CoP) 框架通过有效利用空间占用作为辅助信息，并结合创新的特征提取与融合策略，显著提升了基于视觉的3D目标检测性能和BEV表示的鲁棒性。

> **ai_Abstract:** 本文提出了Collaborative Perceiver (CoP) 框架，旨在通过引入空间占用作为辅助信息来提升基于视觉的3D目标检测性能。针对现有方法忽略环境上下文的问题，CoP采用多任务学习策略，结合3D检测与占用预测。该框架包含生成局部密度感知占用真值 (LDO)、体素高度引导采样 (VHS) 以提取细粒度特征，以及全局-局部协同特征融合 (CFF) 模块。实验证明，CoP在nuScenes基准测试上取得了优异的性能，超越了现有基于视觉的方法。

> **摘要翻译:** 基于视觉的鸟瞰图（BEV）3D目标检测在自动驾驶领域取得了显著进展，因为它具有成本效益和丰富的上下文信息。然而，现有方法通常通过折叠提取的对象特征来构建BEV表示，忽略了内在的环境上下文，例如道路和人行道。这阻碍了检测器全面感知物理世界的特征。为了缓解这个问题，我们引入了一个多任务学习框架，即协同感知器（CoP），它利用空间占用作为辅助信息，挖掘3D目标检测和占用预测任务之间共享的一致结构和概念相似性，弥合空间表示和特征细化方面的差距。为此，我们首先提出了一个生成密集占用真值的管道，该管道整合了局部密度信息（LDO）以重建详细的环境信息。其次，我们采用体素高度引导采样（VHS）策略，根据不同的对象属性提取细粒度局部特征。此外，我们开发了一个全局-局部协同特征融合（CFF）模块，该模块无缝整合两个任务之间的互补知识，从而构成更鲁棒的BEV表示。在nuScenes基准测试上进行的广泛实验表明，CoP优于现有基于视觉的框架，在测试集上实现了49.5%的mAP和59.2%的NDS。代码和补充材料可在以下链接获取：https://github.com/jichengyuan/Collaborative-Perceiver。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [894] [MAGE: Multimodal Alignment and Generation Enhancement via Bridging Visual and Semantic Spaces](https://arxiv.org/abs/2507.21741)
> *MAGE：通过桥接视觉和语义空间实现多模态对齐与生成增强*

*Shaojun E, Yuchen Yang, Jiaheng Wu, Yan Zhang, Tiejun Zhao, Ziyan Chen* | **Category: cs.CV, cs.MM** | **Updated: 2025-07-29**

**Keywords:** 多模态对齐, 语义空间, 视觉数据, 大型语言模型, MAGE

**Comment:** 9 pages

> **TL;DR:** MAGE是一个新的多模态框架，通过引入智能对齐网络和结合交叉熵与均方误差的训练策略，解决了现有方法中视觉数据编码后的空间和语义损失问题，并在多个基准测试中取得了显著优于同类工作的性能。

**AI_Comments:** MAGE的创新之处在于其通过智能对齐网络（IAN）和结合多种损失函数的训练策略，有效地桥接了视觉和文本的语义空间，解决了多模态学习中的核心挑战。此外，其通过构建专门的微调数据集来增强“任意到任意”的能力，也展现了对模型实用性和泛化能力的关注。该工作对提升多模态大模型的性能和应用潜力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态学习方法在编码视觉数据后，难以有效解决空间和语义损失问题。大型多模态模型的性能与视觉编码器和大型语言模型之间的耦合度正相关，但现有方法常面临向量差距或语义差异，导致信息在传播过程中丢失。

**Method:** 本文提出了MAGE（多模态对齐与生成增强）框架，通过创新的对齐机制桥接视觉和文本的语义空间。MAGE引入了智能对齐网络（IAN）以实现维度和语义对齐。为减少同义异构数据间的差距，MAGE采用结合交叉熵和均方误差的训练策略。此外，为增强MAGE的“任意到任意”能力，开发了一个用于多模态工具调用指令的微调数据集。

**Result:** MAGE多模态大模型架构在MME、MMBench和SEED等多个评估基准测试中，与同类工作相比取得了显著更好的性能。

**Conclusion:** MAGE框架通过有效对齐视觉和文本的语义空间，成功解决了多模态学习中视觉数据编码后的信息损失问题，并在多项基准测试中展现出卓越的性能，证明了其在多模态对齐和生成方面的优越性。

> **ai_Abstract:** MAGE是一个新颖的多模态框架，旨在解决大型多模态模型中视觉数据编码后的空间和语义损失问题。它通过引入智能对齐网络（IAN）实现了视觉与文本语义空间的对齐，并采用结合交叉熵和均方误差的训练策略来增强对齐效果。为提升其“任意到任意”的能力，MAGE还利用了一个专门的工具调用指令微调数据集。该模型在多个主流评估基准测试中表现出优于现有方法的性能。

> **摘要翻译:** 在多模态学习的最新进展中，有效解决视觉数据编码后的空间和语义损失仍然是一个关键挑战。这是因为大型多模态模型的性能与视觉编码器和大型语言模型之间的耦合度呈正相关。现有方法常常面临向量差距或语义差异等问题，导致信息在传播过程中丢失。为了解决这些问题，我们提出了MAGE（多模态对齐与生成增强），一个通过创新对齐机制桥接视觉和文本语义空间的新颖框架。通过引入智能对齐网络（IAN），MAGE实现了维度和语义对齐。为了减少同义异构数据之间的差距，我们采用了一种结合交叉熵和均方误差的训练策略，显著增强了对齐效果。此外，为了增强MAGE的“任意到任意”能力，我们开发了一个用于多模态工具调用指令的微调数据集，以扩展模型的输出能力边界。最后，我们提出的多模态大型模型架构MAGE在包括MME、MMBench和SEED在内的各种评估基准测试中，与同类工作相比取得了显著更好的性能。完整的代码和附录可在以下链接获取：https://github.com/GTCOM-NLP/MAGE。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [895] [EIFNet: Leveraging Event-Image Fusion for Robust Semantic Segmentation](https://arxiv.org/abs/2507.21971)
> *EIFNet：利用事件-图像融合实现鲁棒语义分割*

*Zhijiang Li, Haoran He* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 事件相机, 语义分割, 多模态融合, 注意力机制, EIFNet

**Comment:** 

> **TL;DR:** EIFNet是一个多模态融合网络，通过结合事件和图像数据，解决了事件相机语义分割中的特征提取和融合难题，达到了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了一个端到端的多模态融合网络EIFNet，并通过专门设计的模块（如AEFRM、MARM、MGFM）有效解决了事件相机数据固有的稀疏性和噪声问题，以及事件与图像数据融合的挑战。其在复杂环境下的鲁棒性对于自动驾驶和机器人等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 事件相机语义分割面临两大挑战：从稀疏嘈杂的事件流中提取可靠特征，以及有效融合结构和表示不同的密集图像数据。

**Method:** 提出EIFNet，一个多模态融合网络，结合事件和帧输入。它包含自适应事件特征细化模块（AEFRM）用于改进事件表示，以及模态自适应重校准模块（MARM）和多头注意力门控融合模块（MGFM）用于对齐和整合跨模态特征。

**Result:** 在DDD17-Semantic和DSEC-Semantic数据集上的实验表明，EIFNet实现了最先进的性能，证明了其在基于事件的语义分割中的有效性。

**Conclusion:** EIFNet在事件相机语义分割中表现出卓越的有效性，成功克服了事件特征提取和多模态融合的挑战。

> **ai_Abstract:** EIFNet是一个创新的多模态融合网络，旨在解决事件相机语义分割中稀疏事件特征提取和事件-图像数据融合的难题。通过引入AEFRM、MARM和MGFM等模块，EIFNet有效整合了事件和帧数据，并在多个标准数据集上实现了最先进的性能，验证了其在复杂环境下的鲁棒场景理解能力。

> **摘要翻译:** 基于事件的语义分割探索了事件相机的潜力，事件相机提供高动态范围和精细时间分辨率，以在挑战性环境中实现鲁棒的场景理解。尽管有这些优势，但由于两个主要挑战，这项任务仍然很困难：从稀疏和嘈杂的事件流中提取可靠的特征，以及有效地将它们与结构和表示不同的密集、语义丰富的图像数据融合。为了解决这些问题，我们提出了EIFNet，一个结合了事件和基于帧输入的优点的多模态融合网络。该网络包括一个自适应事件特征细化模块（AEFRM），通过多尺度活动建模和空间注意力来改进事件表示。此外，我们引入了一个模态自适应重校准模块（MARM）和一个多头注意力门控融合模块（MGFM），它们使用注意力机制和门控融合策略来对齐和整合跨模态特征。在DDD17-Semantic和DSEC-Semantic数据集上的实验表明，EIFNet实现了最先进的性能，证明了其在基于事件的语义分割中的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [896] [UniPaint: Unified Space-time Video Inpainting via Mixture-of-Experts](https://arxiv.org/abs/2412.06340)
> *UniPaint：基于专家混合的统一时空视频修复*

*Zhen Wan, Chenyang Qi, Zhiheng Liu, Tao Gui, Yue Ma* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 视频修复, 视频插帧, 专家混合, 统一框架, 时空学习

**Comment:** ICCV 1st Workshop on Human-Interactive Generation and Editing
  (poster)

> **TL;DR:** UniPaint是一个统一的视频修复框架，通过专家混合注意力机制和时空掩码策略，同时处理视频修复和插帧任务，并取得了最佳性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个统一框架来同时处理视频修复和插帧，而非将它们视为独立任务，并发现两者可以相互增强。核心的MoE注意力机制和时空掩码策略是其实现统一和提升性能的关键。这种统一范式对于未来视频生成领域的研究具有重要启发意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法将视频修复和视频插帧视为独立任务，无法利用它们之间的相互增强作用。

**Method:** 提出UniPaint，一个统一的生成式时空视频修复框架。它引入了一个可插拔的时空视频修复适配器，并核心提出了一种专家混合（MoE）注意力机制以覆盖各种任务。此外，在训练阶段设计了一种时空掩码策略来相互增强和提升性能。

**Result:** UniPaint生成了高质量和美观的结果，并在各种任务和规模设置下取得了最佳的量化结果。

**Conclusion:** UniPaint通过统一视频修复和插帧任务，并利用MoE注意力及创新的掩码策略，显著提升了视频合成性能，证明了统一框架的优越性。

> **ai_Abstract:** UniPaint是一个创新的统一时空视频修复框架，旨在同时解决视频修复和视频插帧任务。它通过引入可插拔适配器、核心的专家混合（MoE）注意力机制以及独特的时空掩码训练策略，实现了任务间的相互增强。实验结果表明，UniPaint在生成高质量视频方面表现出色，并在多项任务中取得了领先的量化性能。

> **摘要翻译:** 在本文中，我们提出了UniPaint，一个统一的生成式时空视频修复框架，它能够实现时空修复和插帧。与将视频修复和视频插帧视为两个不同任务的现有方法不同，我们利用一个统一的修复框架来处理它们，并观察到这两个任务可以相互增强合成性能。具体来说，我们首先引入了一个即插即用的时空视频修复适配器，该适配器可用于各种个性化模型。关键的见解是提出了一种专家混合（MoE）注意力机制来覆盖各种任务。然后，我们在训练阶段设计了一种时空掩码策略，以相互增强并提高性能。UniPaint产生了高质量且美观的结果，在各种任务和规模设置下都取得了最佳的量化结果。代码和检查点可在$\\href{https://github.com/mmmmm-w/UniPaint}{此仓库}$获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [897] [Beyond Class Tokens: LLM-guided Dominant Property Mining for Few-shot Classification](https://arxiv.org/abs/2507.20511)
> *超越类别标记：LLM引导的少样本分类主导属性挖掘*

*Wei Zhuo, Runjie Luo, Wufeng Xue, Linlin Shen* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 少样本学习, 主导属性, 大型语言模型, 对比学习, 图像分类

**Comment:** 11 pages, 7 figures

> **TL;DR:** 本文提出了一种名为BCT-CLIP的少样本学习（FSL）方法，通过利用大型语言模型（LLM）的先验知识，并探索图像的主导属性而非简单类别标记，以解决数据稀缺导致的视觉多样性不足问题，并在11个广泛使用的数据集上取得了优越性能。

**AI_Comments:** 该论文的创新点在于超越了传统的类别标记，引入了“主导属性”的概念，并通过LLM的强大能力来挖掘这些属性。这种方法有效地解决了少样本学习中数据稀缺导致的视觉多样性不足问题，通过更细粒度的属性表示增强了模型的判别能力。其结合LLM进行知识引导和对比学习的策略，为未来的少样本学习研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 少样本学习（FSL）在识别仅有少量图像的新类别时面临数据稀缺的重大挑战。尽管基于CLIP的对比语言-图像预训练方法通过利用类名文本表示缓解了问题，但简单地将视觉表示与类名嵌入对齐会损害新类别判别的视觉多样性。

**Method:** 本文提出了一种新颖的少样本学习（FSL）方法BCT-CLIP，该方法通过对比学习探索主导属性，超越了简单使用类别标记。该方法利用基于大型语言模型（LLM）的先验知识，构建了全面的结构化图像表示，包括全局类别表示和局部感知属性嵌入。具体而言，该方法包含一个带有局部感知交叉注意力的多属性生成器（MPG）以生成多个视觉属性标记，一个带有基于聚类剪枝的LLM辅助检索过程以获取主导属性描述，以及一种新的用于属性标记学习的对比学习策略。

**Result:** 在11个广泛使用的数据集上取得了优越的性能。

**Conclusion:** 对主导属性的探索显著推进了判别性类别特定表示学习和少样本分类。

> **ai_Abstract:** 本文提出了一种名为BCT-CLIP的少样本学习（FSL）方法，旨在通过挖掘图像的主导属性来解决现有CLIP类方法中因简单类别标记对齐导致的视觉多样性不足问题。该方法利用大型语言模型（LLM）的先验知识，构建了包含全局类别表示和局部感知属性嵌入的综合图像结构化表示。BCT-CLIP引入了多属性生成器（MPG）、LLM辅助的属性检索过程以及新的对比学习策略。实验结果表明，该方法在11个常用数据集上表现出色，有效提升了判别性类别特定表示学习和少样本分类性能。

> **摘要翻译:** 少样本学习（FSL）致力于发展仅使用少量图像识别新类别的泛化能力，但由于数据稀缺面临重大挑战。最近基于对比语言-图像预训练的CLIP类方法通过利用类别名称的文本表示来发现未见图像，从而缓解了这个问题。尽管取得了成功，但简单地将视觉表示与类别名称嵌入对齐会损害新类别判别的视觉多样性。为此，我们提出了一种新颖的少样本学习（FSL）方法（BCT-CLIP），该方法通过对比学习探索主导属性，超越了简单使用类别标记。通过利用基于LLM的先验知识，我们的方法通过全面的结构化图像表示推动了FSL，包括全局类别表示和局部感知属性嵌入。特别是，我们提出了一个新颖的多属性生成器（MPG），它具有局部感知交叉注意力以生成多个视觉属性标记，一个带有基于聚类剪枝的LLM辅助检索过程以获取主导属性描述，以及一种新的用于属性标记学习的对比学习策略。在11个广泛使用的数据集上的优越性能表明，我们对主导属性的探索推进了判别性类别特定表示学习和少样本分类。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [917] [Back Home: A Computer Vision Solution to Seashell Identification for Ecological Restoration](https://arxiv.org/abs/2501.04873)
> *回家：一种用于生态修复的海螺识别计算机视觉解决方案*

*Alexander Valverde, Luis Solano, André Montoya* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 海螺识别, 计算机视觉, 生态修复, 来源推断, BackHome19K

**Comment:** ICCV 2025 (CV4E Workshop)

> **TL;DR:** 该研究开发了一个基于计算机视觉的系统，通过识别海螺的海岸来源（太平洋或加勒比海）来帮助哥斯达黎加执法部门将查获的海螺送回其原生生态系统。

**AI_Comments:** 该论文创新性地将计算机视觉技术应用于生态保护领域，解决了非法海螺贸易中一个实际且紧迫的问题。其构建大规模标注数据集和开发轻量级实时系统的结合，使其解决方案具有高度实用性和可部署性。异常过滤器的引入也增强了系统的鲁棒性，使其能有效应对实际应用中的噪声数据。该工作为其他物种的溯源和生态修复提供了可借鉴的范例。

<details>
  <summary>Details</summary>

**Motivation:** 哥斯达黎加每年有约五吨海螺被非法收集，但查获后由于缺乏信息，其海岸来源（太平洋或加勒比海）难以验证，导致无法将其送回原生环境。

**Method:** 研究引入了BackHome19K，这是首个大规模图像语料库（19,058张照片，516个物种），并标注了海岸级别标签。提出了一种轻量级管道，可在移动级CPU上实时推断来源。训练了一个异常过滤器来预筛选上传，以增加对用户生成噪声的鲁棒性。

**Result:** 在保留测试集上，分类器达到了86.3%的平衡准确率。过滤器拒绝了93%的180个域外对象，零误报。该系统已作为网络应用程序部署，为野生动物官员处理了70,000个贝壳，每张图像处理时间不到三秒。

**Conclusion:** 该计算机视觉解决方案成功地帮助哥斯达黎加执法部门将查获的海螺安全地送回其原生生态系统，解决了非法收集海螺后归还的难题。

> **ai_Abstract:** 该论文介绍了一个名为“BackHome”的计算机视觉解决方案，旨在解决哥斯达黎加非法收集海螺后难以确定其原产海岸的问题。通过构建首个大规模带海岸标签的海螺图像数据集BackHome19K，并开发一个轻量级实时识别系统，该系统能够在移动设备上运行，并具备高准确率和异常过滤能力。该系统已成功部署并帮助执法人员将查获的海螺送回其原生栖息地，对生态修复具有重要意义。

> **摘要翻译:** 每年估计有五吨海螺从哥斯达黎加的海滩被非法收集作为纪念品。然而，一旦这些样本被查获，由于缺乏信息，其海岸来源——太平洋或加勒比海——无法轻易验证，这阻碍了当地政府没收后将其送回。为了解决这个问题，我们引入了BackHome19K，这是第一个大规模图像语料库（19,058张照片，516个物种），并标注了海岸级别标签，并提出了一种轻量级管道，可在移动级CPU上实时推断来源。一个经过训练的异常过滤器预筛选上传，增加了对用户生成噪声的鲁棒性。在保留测试集上，分类器达到了86.3%的平衡准确率，而过滤器拒绝了93%的180个域外对象，零误报。该系统已作为网络应用程序部署，已为野生动物官员处理了70,000个贝壳，每张图像处理时间不到三秒，使得被没收的样本能够安全地归还到其原生生态系统。数据集可在https://huggingface.co/datasets/FIFCO/BackHome19K 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [922] [Generalizable Neural Electromagnetic Inverse Scattering](https://arxiv.org/abs/2506.21349)
> *可泛化神经电磁逆散射*

*Yizhe Cheng, Chunxun Tian, Haoru Wang, Wentao Zhu, Xiaoxuan Ma, Yizhou Wang* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-29**

**Keywords:** 电磁逆散射, 泛化能力, 物理信息, 诱导电流, 稀疏发射器

**Comment:** 

> **TL;DR:** 本文提出了一种新的、可泛化的物理驱动框架，用于解决电磁逆散射问题（EISP），通过将诱导电流作为中间表示，显著提高了重建精度、泛化能力和对稀疏发射器设置的鲁棒性。

**AI_Comments:** 这篇论文通过引入诱导电流作为可泛化的中间表示，为解决电磁逆散射问题提供了一个创新的物理驱动视角。它有效地解决了现有数据驱动方法在泛化能力和稀疏数据鲁棒性方面的关键局限性，特别是通过解耦非线性和病态问题，使得解决方案更加稳健和实用。这项工作代表了电磁成像领域的一个重要进展，有望推动成本效益高的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 电磁逆散射问题（EISP）在医学成像等应用中至关重要，但其本质上是病态和高度非线性的，极具挑战性。现有的机器学习方法（如Img-Interiors）需要针对特定案例进行优化，缺乏对未见数据的泛化能力，并且在稀疏发射器设置下（例如只有一个发射器）会失效。

**Method:** 本文从物理信息角度重新审视EISP，将其重新表述为两阶段的逆透射-散射过程。该表述揭示了诱导电流作为一种可泛化的中间表示，有效地将非线性散射过程与病态逆问题解耦。在此基础上，提出了一种新的可泛化物理驱动框架，包括一个电流估计器和一个介电常数求解器，以端到端的方式工作。电流估计器明确学习诱导电流作为入射场和散射场之间的物理桥梁，而介电常数求解器直接从估计的诱导电流计算相对介电常数。

**Result:** 广泛的实验表明，该方法在重建精度、泛化能力和鲁棒性方面优于最先进的方法。该设计实现了对未见数据的介电常数的数据驱动训练和可泛化前向预测，同时对发射器稀疏性保持强大的鲁棒性。

**Conclusion:** 这项工作为电磁逆散射提供了一个全新的视角，代表着向经济高效的电磁成像实用解决方案迈出了重要一步。

> **ai_Abstract:** 本文针对电磁逆散射问题（EISP）中现有机器学习方法泛化能力差和稀疏发射器设置下失效的局限性，提出了一种新的可泛化物理驱动框架。该框架将EISP重新表述为两阶段过程，并利用诱导电流作为可泛化的中间表示，有效地解耦了非线性散射和病态逆问题。所提出的方法由电流估计器和介电常数求解器组成，实现了对未见数据的介电常数的高精度、可泛化重建，并对稀疏发射器具有强大的鲁棒性，实验结果优于现有技术。

> **摘要翻译:** 解决电磁逆散射问题（EISP）在医学成像等应用中至关重要，其目标是从散射电磁场中重建相对介电常数。这个逆过程本质上是病态和高度非线性的，使其特别具有挑战性。最近一种基于机器学习的方法Img-Interiors通过利用连续隐式函数显示出有希望的结果。然而，它需要针对特定案例进行优化，缺乏对未见数据的泛化能力，并且在稀疏发射器设置下（例如只有一个发射器）会失效。为了解决这些限制，我们从物理信息的角度重新审视EISP，将其重新表述为两阶段的逆透射-散射过程。这种表述揭示了诱导电流作为一种可泛化的中间表示，有效地将非线性散射过程与病态逆问题解耦。基于这一见解，我们提出了第一个可泛化的物理驱动EISP框架，包括一个电流估计器和一个介电常数求解器，以端到端的方式工作。电流估计器明确学习诱导电流作为入射场和散射场之间的物理桥梁，而介电常数求解器直接从估计的诱导电流计算相对介电常数。这种设计实现了对未见数据的介电常数的数据驱动训练和可泛化前向预测，同时对发射器稀疏性保持强大的鲁棒性。广泛的实验表明，我们的方法在重建精度、泛化能力和鲁棒性方面优于最先进的方法。这项工作为电磁逆散射提供了一个全新的视角，代表着向经济高效的电磁成像实用解决方案迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [931] [ZeroStereo: Zero-shot Stereo Matching from Single Images](https://arxiv.org/abs/2501.08654)
> *零视差立体匹配：从单张图像实现零样本立体匹配*

*Xianqi Wang, Hao Yang, Gangwei Xu, Junda Cheng, Min Lin, Yong Deng, Jinliang Zang, Yurui Chen, Xin Yang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 零样本立体匹配, 立体图像生成, 单目深度估计, 扩散修复, 泛化能力

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 本文提出了ZeroStereo，一个用于零样本立体匹配的新型立体图像生成流程。它通过利用单目深度估计模型生成的伪视差从单张图像合成高质量右图像，并引入扩散修复模型处理遮挡，以及“无训练置信度生成”和“自适应视差选择”来优化生成质量。实验证明，该方法在多个数据集上实现了最先进的零样本泛化能力，所需数据量与Scene Flow相当。

**AI_Comments:** 这篇论文的创新点在于提出了一个完整的零样本立体图像生成流程ZeroStereo，通过结合单目深度估计、扩散修复模型以及其独特的“无训练置信度生成”和“自适应视差选择”机制，有效地解决了真实世界立体数据稀缺导致监督方法泛化能力不足的问题。其能够仅用与Scene Flow相当的数据量就达到SOTA的零样本泛化能力，显示了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的监督立体匹配方法在真实世界场景中泛化能力差，因为缺乏真实世界标注的立体数据。

**Method:** 本文提出了ZeroStereo，一个新颖的立体图像生成流程，用于零样本立体匹配。该方法通过利用单目深度估计模型生成的伪视差，从任意单张图像合成高质量的右图像。它微调了一个扩散修复模型来恢复遮挡区域的缺失细节并保留语义结构。此外，还提出了“无训练置信度生成”来减轻不可靠伪标签的影响，以及“自适应视差选择”来确保多样化和真实的视差分布，同时防止过度遮挡和前景失真。

**Result:** 实验证明，使用ZeroStereo流程训练的模型在多个数据集上实现了最先进的零样本泛化能力，且所需数据集量仅与Scene Flow相当。

**Conclusion:** ZeroStereo通过其新颖的立体图像生成流程，有效解决了零样本立体匹配中真实世界数据稀缺和泛化能力差的问题，并在多个数据集上达到了最先进的性能。

> **ai_Abstract:** ZeroStereo提出了一种新颖的零样本立体匹配流水线，通过利用单目深度估计的伪视差从单张图像合成高质量的立体图像。它通过扩散修复模型处理遮挡区域，并引入了“无训练置信度生成”和“自适应视差选择”以提高生成质量和数据多样性。该方法在仅使用与Scene Flow相当的数据量下，在多个数据集上实现了最先进的零样本泛化能力，解决了真实世界立体数据稀缺导致的泛化问题。

> **摘要翻译:** 标题：ZeroStereo：从单张图像实现零样本立体匹配

摘要：最先进的监督立体匹配方法在各种基准测试中取得了显著性能。然而，由于真实世界立体数据标注的稀缺性，它们在真实世界场景中的泛化仍然具有挑战性。在本文中，我们提出了ZeroStereo，一种新颖的立体图像生成流程，用于零样本立体匹配。我们的方法通过利用单目深度估计模型生成的伪视差，从任意单张图像合成高质量的右图像。与以前通过用相邻像素或随机背景填充缺失区域来处理遮挡区域的方法不同，我们微调了一个扩散修复模型来恢复缺失细节，同时保留语义结构。此外，我们提出了“无训练置信度生成”，它在无需额外训练的情况下减轻了不可靠伪标签的影响，以及“自适应视差选择”，它确保了多样化和真实的视差分布，同时防止了过度遮挡和前景失真。实验证明，使用我们流程训练的模型在多个数据集上实现了最先进的零样本泛化能力，且所需数据集量仅与Scene Flow相当。代码：https://github.com/Windsrain/ZeroStereo。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [937] [Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition](https://arxiv.org/abs/2507.21977)
> *运动至关重要：基于骨架的微动作识别中的运动引导调制网络*

*Jihao Gu, Kun Li, Fei Wang, Yanyan Wei, Zhiliang Wu, Hehe Fan, Meng Wang* | **Category: cs.CV** | **Updated: 2025-07-29**

**Keywords:** 微动作识别, 骨架, 运动引导, 调制网络, 时空表示学习

**Comment:** 

> **TL;DR:** 提出了一个运动引导调制网络（MMN），通过捕捉和调制细微运动线索，显著提升了基于骨架的微动作识别的准确性，并在两个数据集上达到了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了一个运动引导调制网络（MMN），通过显式地捕捉和利用细微运动线索来提升微动作识别的准确性。其引入的MSM和MTM模块分别从空间和时间维度对运动信息进行精细化处理，并通过运动一致性学习策略进一步聚合多尺度特征，有效解决了传统方法对微动作细微变化识别不足的问题。这对于需要高精度识别微表情、微动作的应用场景（如情感分析）具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有微动作识别方法忽略了微动作中固有的细微变化，这限制了区分具有细微变化的微动作的准确性。

**Method:** 提出了一种新颖的运动引导调制网络（MMN），通过隐式捕捉和调制细微运动线索来增强时空表示学习。具体而言，引入了运动引导骨架调制模块（MSM）在骨架层面注入运动线索，并设计了运动引导时间调制模块（MTM）在帧层面整合运动信息。此外，还提出了一种运动一致性学习策略来聚合来自多尺度特征的运动线索进行微动作分类。

**Result:** 在Micro-Action 52和iMiGUE数据集上的实验结果表明，MMN在基于骨架的微动作识别中达到了最先进的性能。

**Conclusion:** 明确建模细微运动线索对于基于骨架的微动作识别至关重要。

> **ai_Abstract:** 本文提出了一种新颖的运动引导调制网络（MMN），旨在解决现有微动作识别方法忽略细微运动变化的问题。MMN通过引入运动引导骨架调制模块（MSM）和运动引导时间调制模块（MTM），分别在骨架和帧层面捕捉并整合细微运动线索，以增强时空表示学习。此外，还采用了运动一致性学习策略。实验证明，MMN在Micro-Action 52和iMiGUE数据集上取得了最先进的性能，强调了明确建模细微运动线索的重要性。

> **摘要翻译:** 微动作（MAs）是社会互动中非语言交流的重要形式，在人类情感分析中具有潜在应用。然而，现有的微动作识别方法往往忽略了微动作中固有的细微变化，这限制了区分具有细微变化的微动作的准确性。为了解决这个问题，我们提出了一种新颖的运动引导调制网络（MMN），该网络隐式地捕捉和调制细微运动线索，以增强时空表示学习。具体而言，我们引入了一个运动引导骨架调制模块（MSM），在骨架层面注入运动线索，作为控制信号来指导空间表示建模。同时，我们设计了一个运动引导时间调制模块（MTM），在帧层面整合运动信息，促进微动作中整体运动模式的建模。最后，我们提出了一种运动一致性学习策略，用于聚合来自多尺度特征的运动线索以进行微动作分类。在Micro-Action 52和iMiGUE数据集上的实验结果表明，MMN在基于骨架的微动作识别中实现了最先进的性能，突显了明确建模细微运动线索的重要性。代码将在https://github.com/momiji-bit/MMN提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [16] [Helping or Homogenizing? GenAI as a Design Partner to Pre-Service SLPs for Just-in-Time Programming of AAC](https://arxiv.org/abs/2507.21811)
> *帮助还是同质化？生成式AI作为设计伙伴，为职前言语-语言病理学家提供即时AAC编程支持*

*Cynthia Zastudil, Christine Holyfield, Christine Kapp, Kate Hamilton, Kriti Baru, Liam Newsam, June A. Smith, Stephen MacNeil* | **Category: cs.HC** | **Updated: 2025-07-29**

**Keywords:** 生成式AI, 辅助和替代交流 (AAC), 视觉场景显示器 (VSD), 言语-语言病理学家 (SLP), 用户研究

**Comment:** 

> **TL;DR:** 研究探讨生成式AI辅助非专家创建AAC设备（VSDs）的有效性，发现其提高了效率和信心，但也导致过度依赖和同质化。

**AI_Comments:** 这项研究创新性地探讨了生成式AI在辅助交流（AAC）设备配置中的应用，特别关注了其对非专家用户的帮助与潜在负面影响。其重要性在于揭示了AI辅助工具在提高效率的同时，可能带来的过度依赖和同质化问题，为未来AI在辅助技术及其他领域的应用提供了宝贵的警示和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 辅助和替代交流 (AAC) 设备，特别是视觉场景显示器 (VSDs)，配置困难，影响其广泛采用。本研究旨在利用生成式AI帮助非专家高效创建VSDs。

**Method:** 开发了一个使用生成式AI自动建议图像初始热点的原型。进行了一项受试者内用户研究，评估原型对职前言语-语言病理学家 (SLP) 的有效性。评估指标包括创建时间、质量、用户信心，并分析了自动生成热点的相关性、发展适宜性以及用户与生成热点的互动频率。

**Result:** 结果好坏参半：SLP用户变得更高效、更自信。然而，也出现了多重负面影响，包括过度依赖和交流选项的同质化。

**Conclusion:** 生成式AI的整合在辅助技术领域存在潜在风险，这些发现的影响超越了AAC领域。未来的工作需要进一步识别和解决与将生成式AI整合到辅助技术中相关的风险。

> **ai_Abstract:** 本文开发了一个利用生成式AI自动建议视觉场景显示器（VSDs）热点的原型，旨在帮助非专家（如职前SLP）高效创建AAC设备。通过用户研究发现，该原型能提高用户效率和信心，但也导致了过度依赖和交流选项同质化等负面影响。研究强调了生成式AI在辅助技术中应用的潜在风险，并指出未来需进一步研究以应对这些挑战。

> **摘要翻译:** 辅助和替代交流 (AAC) 设备被世界各地许多有语言交流困难的人使用。视觉场景显示器 (VSD) 是一种对语言能力最低的自闭症儿童发展语言和交流技能特别有用的 AAC 设备。VSDs 使用嵌入交互热点的图像，将语言直接连接到对 AAC 用户有意义的真实世界语境中。虽然 VSDs 可以有效支持新兴交流者，但其广泛采用受到设备配置困难的影响。我们开发了一个原型，利用生成式 AI 自动建议图像上的初始热点，以帮助非专业人士高效创建 VSDs。我们进行了一项受试者内用户研究，以了解我们的原型在支持非专业用户（特别是对 VSD 作为 AAC 干预不熟悉的职前言语-语言病理学家 (SLP)）方面的有效性。职前 SLP 正在积极学习成为临床认证的 SLP，并拥有关于语言和交流技能发展的领域特定知识。我们根据创建时间、质量和用户信心评估了原型的有效性。我们还分析了自动生成热点的相关性和发展适宜性以及用户与生成热点互动的频率。我们的结果好坏参半，SLP 变得更高效、更自信。然而，也存在多重负面影响，包括过度依赖和交流选项的同质化。这些发现的影响超越了 AAC 领域，尤其是在生成式 AI 越来越普及的各个领域，包括辅助技术。未来的工作需要进一步识别和解决将生成式 AI 整合到辅助技术中相关的这些风险。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [22] [Empowering Educators in the Age of AI: An Empirical Study on Creating custom GPTs in Qualitative Research Method education](https://arxiv.org/abs/2507.21074)
> *AI时代赋能教育者：一项关于在定性研究方法教育中创建定制GPT的实证研究*

*Qian Huang, Thijs Willems* | **Category: cs.HC, cs.AI** | **Updated: 2025-06-10**

**Keywords:** 定制GPT, 定性研究方法教育, 教育者赋能, 生成式AI, 行动研究

**Comment:** 20 pages

> **TL;DR:** 本研究探讨了两名教师如何在定性研究方法课程中整合定制GPT工具，以赋能教育者设计AI工具，促进学生反思性、负责任和协作学习。

**AI_Comments:** 这项研究的创新之处在于其将AI应用于定性研究方法教育，并强调了教育者作为AI工具设计者的积极作用，而非仅仅是使用者。这对于推动AI在高等教育中更具教学意义和负责任的整合具有重要意义。它也指出了AI在带来益处的同时可能引发的认知挑战，为未来的AI教学设计提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 当前对AI在教育中的应用主要关注学生作为被动用户，且AI在定性方法教育中的使用有限。本研究旨在解决这两个空白，并探讨生成式AI如何与教学意图结合以支持学科学习。

**Method:** 本研究采用行动研究方法，并借鉴了技术教学内容知识（TPACK）框架。两名教师为硕士级别的定性研究方法课程设计了四个定制GPT工具，以支持研究问题制定、访谈练习、田野笔记分析和设计思维等任务。数据来源包括学生反思、AI聊天记录和最终作业，并通过主题分析进行分析。

**Result:** 研究结果表明，定制GPT工具增强了学生的反思性，改进了访谈技巧，并支持了结构化分析思维。然而，学生也表达了对认知负荷、数据沉浸感降低以及AI回应公式化性质的担忧。

**Conclusion:** 本研究得出三个关键见解：AI与人工引导结合时可作为主动学习的强大支架；定制GPT可作为迭代研究实践中的认知伙伴；教育者主导的设计对于具有教学意义的AI整合至关重要。这表明赋能教育者设计定制工具可以促进与AI更具反思性、负责任和协作性的学习。

> **ai_Abstract:** 本研究探讨了在硕士级别定性研究方法课程中，教师如何整合定制GPT工具以赋能教育者设计AI应用。研究发现，这些工具能增强学生的反思性和分析思维，但也存在认知负荷等问题。研究强调了教育者主导设计AI的重要性，并指出AI与人工引导结合能有效促进主动学习。

> **摘要翻译:** 随着生成式AI（Gen-AI）工具在教育中日益普及，越来越需要了解教育者（而不仅仅是学生）如何积极塑造其设计和使用。本研究调查了两名教师如何将四种定制GPT工具整合到一门针对城市规划政策学生的硕士级别定性研究方法课程中。本研究旨在解决两个主要空白：将学生视为被动AI用户的主导框架，以及AI在定性方法教育中的有限使用。本研究探讨了生成式AI如何在与教学意图对齐时支持学科学习。借鉴技术教学内容知识（TPACK）框架和行动研究方法，教师设计了GPT以支持研究问题制定、访谈练习、田野笔记分析和设计思维等任务。对学生反思、AI聊天记录和最终作业进行主题分析后发现，这些工具增强了学生的反思性，改进了访谈技巧，并支持了结构化分析思维。然而，学生也表达了对认知负荷、数据沉浸感降低以及AI回应公式化性质的担忧。本研究提供了三个关键见解：AI与人工引导结合时可作为主动学习的强大支架；定制GPT可作为迭代研究实践中的认知伙伴；教育者主导的设计对于具有教学意义的AI整合至关重要。这项研究通过展示如何赋能教育者设计定制工具来促进与AI更具反思性、负责任和协作性的学习，从而为高等教育中AI的新兴学术研究做出了贡献。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [64] [Data-Driven and Participatory Approaches toward Neuro-Inclusive AI](https://arxiv.org/abs/2507.21077)
> *数据驱动和参与式方法迈向神经包容性AI*

*Naba Rizvi* | **Category: cs.HC, cs.AI, cs.CY** | **Updated: 2025-06-12**

**Keywords:** 神经包容性AI, 自闭症, 数据偏见, AI伦理, AUTALIC

**Comment:** PhD Dissertation at UC San Diego (June 2025)

> **TL;DR:** AI中的偏见数据排斥了自闭症患者。本文定义了神经包容性AI，揭示了反自闭症偏见，并提出了AUTALIC基准以促进数据包容性。

**AI_Comments:** 本文的创新之处在于提出了“神经包容性AI”这一重要概念，挑战了传统AI以“模仿人类”为基准的范式，并明确指出其对神经多样性群体的排斥。研究通过实证数据揭示了AI领域中普遍存在的反自闭症偏见以及伦理考量缺失的现状，具有重要的社会意义。AUTALIC基准的提出为未来开发和评估更公平、包容的AI模型提供了具体工具。其局限性可能在于，二元标注虽然有效，但在复杂语境下是否能完全捕捉所有细微差别可能还需要进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** AI中存在偏见数据表示，这导致全球多达7500万自闭症患者被边缘化，因为医疗应用将自闭症视为神经典型社交技能的缺陷而非人类多样性的一部分。当前AI发展侧重于模仿人类交流，但这种基准排斥了自闭症群体的视角。

**Method:** 1. 探讨了当前研究中反自闭症偏见的起源、普遍性和影响。 2. 定义了神经包容性AI，即数据集和系统不再以模仿人类作为机器智能的基准。 3. 与标注者和大型语言模型（LLMs）进行了实证实验，以改善数据中自闭症的代表性。 4. 开发了一个名为AUTALIC的基准，用于评估或微调模型。

**Result:** 1. 发现90%的类人AI代理排除了自闭症视角。 2. AI开发者仍然认为伦理考量超出了其工作范围。 3. 发现二元标注方案足以捕捉反自闭症仇恨言论标注的细微差别。

**Conclusion:** 本文定义了神经包容性AI，并开发了AUTALIC基准，旨在为未来更具神经包容性的工作奠定基础，以改善AI中自闭症群体的代表性。

> **ai_Abstract:** 本文关注AI中因偏见数据表示而导致的自闭症群体边缘化问题。作者提出“神经包容性AI”的概念，旨在摆脱以模仿人类为基准的传统AI开发模式。研究发现现有90%的类人AI代理排斥自闭症视角，且AI开发者普遍忽视伦理考量。为提升自闭症数据代表性，作者通过与标注者和LLMs的实证实验，验证了二元标注方案在识别反自闭症仇恨言论上的有效性，并开发了AUTALIC基准，旨在促进更具神经包容性的AI发展。

> **摘要翻译:** 人工智能中偏颇的数据表示通过将自闭症视为神经典型社交技能的缺陷而非人类多样性的一部分的医疗应用，边缘化了全球多达7500万自闭症患者，这种观点根植于质疑自闭症患者人性的研究。图灵将人工智能定义为模仿人类交流的能力，随着人工智能开发越来越关注类人代理，这一基准仍然很受欢迎。与此相反，我们将神经包容性人工智能定义为数据集和系统，它们不再以模仿人性作为机器智能的基准。然后，我们探讨了当前研究中反自闭症偏见的起源、普遍性和影响。我们的工作发现，90%的类人AI代理排除了自闭症视角，并且AI创作者仍然认为伦理考量超出了其工作范围。为了改善数据中自闭症的代表性，我们与标注者和大型语言模型进行了实证实验，发现二元标注方案足以捕捉标注反自闭症仇恨言论的细微差别。我们的基准AUTALIC可用于评估或微调模型，其开发旨在为未来更具神经包容性的工作奠定基础。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [79] [VeasyGuide: Personalized Visual Guidance for Low-vision Learners on Instructor Actions in Presentation Videos](https://arxiv.org/abs/2507.21837)
> *VeasyGuide：针对低视力学习者在演示视频中教师动作的个性化视觉引导*

*Yotam Sechayk, Ariel Shamir, Amy Pavel, Takeo Igarashi* | **Category: cs.HC** | **Updated: 2025-07-29**

**Keywords:** 低视力, 视觉引导, 教师动作, 演示视频, 辅助技术, VeasyGuide

**Comment:** ASSETS '25, Denver, CO, USA

> **TL;DR:** VeasyGuide是一个帮助低视力学习者检测演示视频中教师视觉动作的工具，通过运动检测、动态高亮和放大来减少认知负荷并提高信息获取效率。

**AI_Comments:** VeasyGuide的创新之处在于其结合运动检测、个性化高亮和放大技术，为低视力学习者提供了急需的视觉辅助，弥补了传统教育视频在无障碍性方面的不足。其协同设计方法确保了用户需求的有效整合，而对视力正常参与者的积极影响则预示了其广泛应用前景和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在教育演示视频中，教师常使用指向、标记和素描等视觉动作来传达信息，但这些微妙的视觉提示通常缺乏语言描述，导致低视力学习者难以寻找视觉指示或只能依赖音频，从而错过信息并增加认知负荷。

**Method:** 研究团队与三名低视力参与者进行了协同设计研究，开发了VeasyGuide工具。该工具利用运动检测技术识别教师动作，并动态地高亮和放大这些动作。VeasyGuide提供熟悉的视觉高亮，传达空间语境，并通过广泛的个性化和实时视觉反馈适应不同学习者和内容。

**Result:** 对8名低视力参与者的评估显示，学习者在检测教师动作方面有显著改善，响应时间更快，认知负荷显著降低。对8名视力正常参与者的单独评估表明，VeasyGuide也增强了他们的参与度和注意力。

**Conclusion:** VeasyGuide能有效帮助低视力学习者检测教师动作，减少视觉搜索工作和认知负荷，并具有作为普适性工具的潜力，能增强所有学习者的参与度和注意力。

> **ai_Abstract:** 本文介绍VeasyGuide，一个为低视力学习者设计的工具，旨在解决他们在教育演示视频中难以识别教师视觉动作的问题。该工具通过运动检测、动态高亮和放大教师动作，结合个性化和实时反馈，帮助低视力学习者减少视觉搜索努力、提高动作检测能力并降低认知负荷。初步评估显示，VeasyGuide显著改善了低视力学习者的学习体验，并对视力正常者也有益，展现了其普适性潜力。

> **摘要翻译:** 教师在教育演示视频中经常依靠指向、标记和素描等视觉动作来传达信息。这些微妙的视觉提示通常缺乏语言描述，迫使低视力（LV）学习者寻找视觉指示或仅仅依靠音频，这可能导致信息遗漏和认知负荷增加。为了解决这一挑战，我们与三名低视力参与者进行了一项协同设计研究，并开发了VeasyGuide，一个利用运动检测来识别教师动作并动态高亮和放大它们的工具。VeasyGuide产生熟悉的视觉高亮，传达空间语境，并通过广泛的个性化和实时视觉反馈适应不同的学习者和内容。VeasyGuide通过明确“看什么”和“看哪里”来减少视觉搜索工作。在对8名低视力参与者的评估中，学习者在检测教师动作方面表现出显著改善，响应时间更快，认知负荷显著降低。对8名视力正常参与者的单独评估表明，VeasyGuide也增强了参与度和注意力，这表明它作为一种普适性工具的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [113] [What Makes a Level Hard in Super Mario Maker 2?](https://arxiv.org/abs/2507.21078)
> *《什么让《超级马力欧创作家2》的关卡变得困难？》*

*Carlo A. Furia, Andrea Mocci* | **Category: cs.HC, cs.SE** | **Updated: 2025-06-13**

**Keywords:** 超级马力欧创作家2, 关卡难度, 回归模型, 自然语言处理, 游戏设计

**Comment:** 

> **TL;DR:** 分析《超级马力欧创作家2》用户创作关卡的数据，以理解影响关卡难度的因素。

**AI_Comments:** 这篇论文通过结合量化分析（回归模型）和定性分析（NLP）来探讨游戏关卡设计中的难度因素，具有一定的创新性。虽然作者承认结果并非“惊人”，但其系统性地识别了影响关卡难度的具体特征，对于游戏设计者和研究者理解用户行为及优化关卡制作工具具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 了解《超级马力欧创作家2》中哪些因素影响用户创作关卡的难度。

**Method:** 采用两种分析方法：一种基于回归模型，另一种使用自然语言处理技术。

**Result:** 揭示了关卡特征（如风格、流行度、时机）以及主题和情感与关卡难度（简单或困难）之间存在一致的关联。

**Conclusion:** 研究所得发现有助于提炼出简单和困难《超级马力欧创作家2》关卡之间的关键差异，从而更好地理解最终用户的关卡设计。

> **ai_Abstract:** 本文分析了《超级马力欧创作家2》中用户创作的关卡数据，旨在识别影响关卡难度的因素。研究使用了回归模型和自然语言处理技术，发现关卡特征（如风格、流行度、时机）以及相关主题和情感与关卡难度存在关联，为理解用户关卡设计提供了见解。

> **摘要翻译:** 像《超级马力欧创作家2》（SMM2）这样的游戏降低了普通用户成为关卡设计师的门槛。在本文中，我们着手分析了大量关于SMM2用户创作关卡的数据，以了解哪些因素会影响其他用户体验到的关卡难度。为此，我们进行了两种分析：一种基于回归模型，另一种使用自然语言处理技术。主要结果揭示了哪些关卡特征（例如，其风格、流行度、时机）以及哪些主题和情感与更简单或更困难的关卡具有一致的关联。虽然我们的发现均不令人惊讶，但它们有助于提炼出简单和困难SMM2关卡之间的一些关键差异，这反过来又可以为更好地理解最终用户关卡设计铺平道路。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [135] [Leveraging LLMs for Persona-Based Visualization of Election Data](https://arxiv.org/abs/2507.21900)
> *利用大型语言模型进行基于角色的选举数据可视化*

*Swaroop Panda, Arun Kumar Sekar* | **Category: cs.HC** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 选民角色, 选举数据, 可视化, 个性化

**Comment:** 

> **TL;DR:** 本文提出利用大型语言模型为不同选民角色定制选举数据可视化，以提高信息理解和相关性。

**AI_Comments:** 本文的创新之处在于将大型语言模型与选民角色相结合，为选举数据可视化提供了个性化和更具相关性的新方法。这对于提高公众对选举信息的理解和参与度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 可视化是传播选举信息和影响公众认知的关键工具。选民角色（Personas）提供了一个理解不同选民群体视角、需求和行为的宝贵框架，因此为这些角色定制可视化能使选举信息更容易理解和更具相关性。

**Method:** 研究人员利用英国议会选举数据和大型语言模型（LLMs）创建了涵盖选民人口统计、技术偏好、投票倾向和信息消费模式的选民角色。随后，他们阐明了这些角色如何通过特定设计标准指导可视化设计，提供了基于这些标准的示例性可视化原型，并使用这些角色和LLMs对原型进行了评估。

**Result:** 成功创建了涵盖多方面信息的选民角色，并基于这些角色设计并评估了可视化原型，旨在提高选举信息的可理解性和相关性。

**Conclusion:** 基于所提出的框架和不同的设计成果，论文提出了一些可行的见解。

> **ai_Abstract:** 本文提出了一种利用大型语言模型（LLMs）为不同选民角色定制选举数据可视化的创新方法。通过分析英国议会选举数据并结合LLMs的能力，研究者创建了详细的选民角色，这些角色涵盖了人口统计、技术偏好、投票倾向和信息消费模式。在此基础上，论文阐述了这些角色如何指导可视化设计，并提供了原型示例及评估，旨在提高选举信息的可理解性和相关性。

> **摘要翻译:** 可视化是传播选举及其结果信息的必要工具，可能影响公众认知。选民角色（Personas）划分了人群中独特的细分群体，为理解不同选民群体的细微视角、需求和行为提供了宝贵框架。在这项工作中，我们提出为这些角色定制可视化，使选举信息更容易理解和更具相关性。我们利用英国议会选举数据和大型语言模型（LLMs）的新发展，创建了涵盖选民中观察到的人口统计、技术偏好、投票倾向和信息消费模式的选民角色。随后，我们阐明了这些角色如何通过特定的设计标准指导可视化设计。然后，我们提供了基于这些标准的示例性可视化原型，并使用这些角色和LLMs评估了这些原型。最后，我们基于该框架和不同的设计成果提出了一些可行的见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [169] [Metaverse Support Groups for LGBTQ+ Youth: An Observational Study on Safety, Self-Expression, and Early Intervention](https://arxiv.org/abs/2507.21079)
> *元宇宙中针对LGBTQ+青年的支持小组：一项关于安全性、自我表达和早期干预的观察性研究*

*Joe Hasei, Yosuke Matsumoto, Hiroki Kawai, Yuko Okahisa, Manabu Takaki, Toshifumi Ozaki* | **Category: cs.HC, cs.CY** | **Updated: 2025-06-14**

**Keywords:** 元宇宙, LGBTQ+青年, 支持小组, 社交信心, 早期干预

**Comment:** 

> **TL;DR:** 本研究评估了元宇宙中为LGBTQ+青年提供的支持小组，发现它们能有效降低社会孤立和自杀风险，提供安全的自我表达空间，并具有早期干预的潜力。

**AI_Comments:** 这项研究的创新之处在于将元宇宙技术应用于LGBTQ+青年的心理健康支持，提供了一个匿名、安全且可访问的自我表达空间。它强调了虚拟支持在降低心理障碍和提供肯定环境方面的潜力，特别是对于边缘化群体。研究也指出了虚拟支持的补充性质，而非替代传统服务，这为其未来发展提供了务实的方向。其局限性可能在于观察性研究的设计，未能提供因果关系的强有力证据，且仅限于单一平台。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在评估基于元宇宙的支持小组，以减少LGBTQ+青年的社会孤立和自杀风险。

**Method:** 本研究使用Cluster平台，提供增强的匿名性、基于头像的自我表达和可访问性，对元宇宙中的支持小组进行了观察性研究，评估其对LGBTQ+青年的影响。

**Result:** 研究发现，79.2%的参与者选择与性别认同匹配的头像，满意度高（平均4.10/5），不适感低（平均1.79/5）。与现实世界互动相比，虚拟空间中的社交信心显著提高（p<0.001），尤其是在初始信心较低的参与者中，平均增加2.08分。约一半首次参与者年龄在16岁或以下，显示出早期干预的潜力。元宇宙在安全性/隐私（3.94/5）、自我表达（4.02/5）和可访问性（4.21/5）方面得分高于现实世界。此外，73.6%的参与者表示在虚拟环境中感到更被接受。然而，一些线下信心较高的个体经历了轻微的适应挑战，信心平均下降0.58分。

**Conclusion:** 研究结果表明，基于元宇宙的支持有效降低了心理障碍，并提供了肯定的空间，可能减少自杀意念等严重后果。未来的研究应侧重于将虚拟支持与现有社区和临床框架相结合，以增强长期影响。

> **ai_Abstract:** 本研究旨在评估元宇宙中针对LGBTQ+青年的支持小组，以解决社会孤立和自杀风险问题。通过Cluster平台提供增强的匿名性、头像自我表达和可访问性，研究发现元宇宙支持小组显著提升了参与者的社交信心和自我接受度，尤其对低信心个体和年轻参与者具有早期干预潜力。尽管对部分线下高信心者存在适应挑战，但研究证实元宇宙为LGBTQ+青年提供了安全且肯定的虚拟空间，有效降低了心理障碍，并建议未来研究整合虚拟支持与现有社区和临床服务。

> **摘要翻译:** 本研究评估了旨在减少LGBTQ+青年社会孤立和自杀风险的元宇宙支持小组。使用Cluster平台，提供了增强的匿名性、基于头像的自我表达和可访问性。主要发现显示，79.2%的参与者选择了与其性别认同相符的头像，并报告了高满意度（平均：4.10/5）和低不适感（平均：1.79/5）。与现实世界互动相比，虚拟空间中的社交信心显著提高（p<0.001），尤其是在初始信心较低的参与者中，平均增加了2.08分。约一半的首次参与者年龄在16岁或以下，突显了早期干预的潜力。元宇宙在安全性/隐私（3.94/5）、自我表达（4.02/5）和可访问性（4.21/5）方面得分高于现实世界环境。此外，73.6%的参与者表示在虚拟环境中感到更被接受。然而，一些线下信心较高的个体经历了轻微的适应挑战，信心平均下降0.58分，这表明虚拟支持是面对面服务的补充而非替代。这些发现表明，基于元宇宙的支持有效降低了心理障碍并提供了肯定的空间，可能减少自杀意念等严重后果。未来的研究应侧重于将虚拟支持与现有社区和临床框架相结合，以增强长期影响。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [191] [MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation](https://arxiv.org/abs/2507.21953)
> *MapAgent：轨迹构建的记忆增强型移动任务自动化规划*

*Yi Kong, Dianxi Shi, Guoli Yang, Zhang ke-di, Chenlin Huang, Xiaopeng Li, Songchang Jin* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-29**

**Keywords:** LLM智能体, 移动任务自动化, 记忆增强, 轨迹记忆, 任务规划

**Comment:** 

> **TL;DR:** MapAgent是一个基于LLM的智能体框架，利用历史轨迹构建的记忆来增强移动设备上的任务规划。

**AI_Comments:** MapAgent的创新之处在于其独特的轨迹构建记忆机制，将历史任务执行数据转化为可重用的结构化知识，有效弥补了LLM在真实移动应用场景理解上的不足。这种方法显著提升了LLM智能体在复杂移动任务自动化中的规划能力和鲁棒性。其双LLM架构也为任务执行提供了更强的支持。该研究对于推动LLM在移动设备上的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的LLM驱动的自主智能体在处理复杂的真实世界任务时面临挑战，原因在于它们缺乏对真实移动应用的了解，这可能导致任务规划效率低下甚至产生幻觉。

**Method:** MapAgent框架包含三个主要部分：1) 轨迹记忆机制，将任务执行轨迹转换为可重用的结构化页面记忆数据库，每个页面捕获UI布局和功能上下文；2) 粗到细的任务规划方法，从记忆数据库中检索相关页面并注入LLM规划器以弥补对真实世界应用场景理解的不足；3) 由双LLM架构支持的任务执行器，将规划的任务转换为可执行动作。

**Result:** 在真实世界场景中的实验结果表明，MapAgent的性能优于现有方法。

**Conclusion:** MapAgent通过利用轨迹构建的记忆来增强LLM的任务规划能力，有效解决了现有LLM智能体在移动任务自动化中面临的挑战，并取得了优越的性能。

> **ai_Abstract:** 本文提出了MapAgent，一个基于LLM的智能体框架，旨在解决现有LLM智能体在移动任务自动化中面临的知识缺乏和幻觉问题。MapAgent通过构建轨迹记忆数据库来捕获UI布局和功能上下文，并采用粗到细的规划方法将相关记忆注入LLM规划器。结合双LLM架构的任务执行器，MapAgent在真实世界场景中表现出优越的性能。

> **摘要翻译:** 最近由大型语言模型（LLM）驱动的自主智能体的进步，在通过图形用户界面（GUI）自动化移动设备上的任务方面展现出巨大的潜力。尽管取得了初步进展，但这些智能体在处理复杂的真实世界任务时仍面临挑战。这些挑战源于基于LLM的智能体缺乏对现实移动应用的了解，这可能导致无效的任务规划甚至引起幻觉。为了解决这些挑战，我们提出了一种新颖的基于LLM的智能体框架，名为MapAgent，它利用从历史轨迹构建的记忆来增强当前的任务规划。具体来说，我们首先提出了一种基于轨迹的记忆机制，将任务执行轨迹转换为可重用和结构化的页面记忆数据库。轨迹中的每个页面都被提取为一个紧凑而全面的快照，捕获其UI布局和功能上下文。其次，我们引入了一种从粗到细的任务规划方法，该方法根据相似性从记忆数据库中检索相关页面，并将其注入LLM规划器，以弥补在理解真实世界应用场景方面的潜在不足，从而实现更明智和上下文感知的任务规划。最后，规划的任务通过由双LLM架构支持的任务执行器转换为可执行动作，确保有效跟踪任务进度。真实世界场景中的实验结果表明，MapAgent的性能优于现有方法。代码将开源以支持进一步研究。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [225] [Empathy in Explanation](https://arxiv.org/abs/2507.21081)
> *解释中的共情*

*Katherine M. Collins, Kartik Chandra, Adrian Weller, Jonathan Ragan-Kelley, Joshua B. Tenenbaum* | **Category: cs.HC, cs.AI** | **Updated: 2025-06-16**

**Keywords:** 解释, 情感, 社会互动, 计算框架, 共情

**Comment:** CogSci non-archival conference paper

> **TL;DR:** 研究解释中情感的作用，开发了一个计算框架来模拟考虑情感影响的解释者，并在医生解释病情的场景中验证了模型，发现人们在解释时确实会考虑情感。

**AI_Comments:** 这项研究的创新之处在于将情感因素整合到解释的计算模型中，为理解人类解释行为提供了一个新的视角。它强调了解释不仅仅是信息传递，更是一种涉及情感交互的社会过程，这对于设计更具共情能力的AI解释系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究将解释视为一种合作的社会互动，本文在此基础上进一步探讨情感在这种社会互动中的作用。

**Method:** 开发了一个计算框架，用于模拟考虑解释对听者情感影响的解释者。通过模拟医生向病人解释病情（考虑病人的后悔倾向）来测试该框架，并与不考虑情感的模型进行比较。

**Result:** 该模型能够很好地预测人类的直觉，并且优于不考虑情感的模型。

**Conclusion:** 人们在提供解释时确实会考虑情感因素。

> **ai_Abstract:** 本文探讨了在社会互动背景下解释中情感的作用。研究者开发了一个计算框架，用于模拟解释者如何考虑解释对听者情感（如后悔）的影响。通过在医生向病人解释病情的场景中进行测试，结果表明该模型能有效预测人类直觉，且优于不考虑情感的模型，证实了人们在解释过程中会考虑情感因素。

> **摘要翻译:** 我们为什么会给出那样的解释？最近的研究表明，我们应该将解释视为一种合作的社会互动，发生在提问者和解释者之间。在此，我们应用这一视角来考察情感在这种社会互动中扮演的角色。我们开发了一个计算框架，用于模拟那些考虑解释可能对听者产生情感影响的解释者。我们通过使用该框架来模拟人类关于医生如何向患者解释其患病原因（考虑到患者的后悔倾向）的直觉来测试我们的框架。我们的模型能够很好地预测人类的直觉，并且优于不考虑情感的消融模型，这表明人们在给出解释时确实会考虑情感。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [247] [DataSway: Vivifying Metaphoric Visualization with Animation Clip Generation and Coordination](https://arxiv.org/abs/2507.22051)
> *DataSway：通过动画片段生成与协调，激活比喻可视化*

*Liwenhan Xie, Jiayi Zhou, Anyi Rao, Huamin Qu, Xinhuan Shu* | **Category: cs.HC** | **Updated: 2025-07-30**

**Keywords:** 比喻可视化, 动画生成, 人机协作, 视觉-语言模型, DataSway

**Comment:** 19 pages, 5 figures; Website:
  https://shellywhen.github.io/projects/DataSway

> **TL;DR:** 提出DataSway，一个支持人机协作的工作流，利用VLM生成和协调动画片段，解决了比喻可视化动画设计中的挑战，提升数据理解和参与度。

**AI_Comments:** 这篇论文提出了一种创新的人机协作方法，利用视觉-语言模型来自动化比喻可视化动画的生成，有效解决了传统手动设计中语义对齐和交互性整合的挑战。DataSway原型及其用户研究验证了其在创意支持和可用性方面的价值，对于提升数据可视化表现力和降低动画创作门槛具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 动画比喻可视化虽能增强数据理解和参与度，但创作者在设计此类动画时面临多重挑战，包括制作与比喻语义对齐的动作、动画过程中数据表示的保真性以及交互性的无缝集成。

**Method:** 本文提出了一种人机协作工作流，旨在促进基于SVG的比喻可视化动画的创建。用户可以初步从视觉-语言模型（VLMs）中获取数据元素的动画片段，并随后根据实体顺序、属性值、空间布局或随机性来协调这些片段的时间线。该设计决策得到了与八位经验丰富设计师进行形成性研究的指导。

**Result:** 开发了原型系统DataSway，并通过对14位用户的用户研究评估了其创意支持和可用性。一个包含6个案例的画廊展示了其在基于Web的超媒体中的能力和应用。

**Conclusion:** 本文最后提出了对定制化数据可视化动画未来研究的启示。

> **ai_Abstract:** DataSway是一个创新的人机协作工作流，专为解决比喻可视化动画设计中的挑战而设计。它利用视觉-语言模型（VLMs）生成数据元素的动画片段，并允许用户灵活协调这些片段的时间线。通过开发原型系统DataSway和进行用户研究，该方法被证明能有效提升创意支持和可用性。论文还展示了DataSway在Web超媒体中的应用潜力，并为未来定制化数据可视化动画的研究提供了重要的方向和启示。

> **摘要翻译:** 动画比喻可视化能使数据鲜活起来，增强对抽象数据编码的理解，并促进更深层次的参与。然而，创作者在设计这些动画时面临重大挑战，例如制作与比喻语义对齐的动作、在动画过程中保持忠实的数据表示，以及无缝集成交互性。我们提出了一种人机协作工作流，以促进为基于SVG的比喻可视化创建动画。用户可以最初从视觉-语言模型（VLMs）中获取数据元素的动画片段，然后根据实体顺序、属性值、空间布局或随机性协调其时间线。我们的设计决策得益于与八位经验丰富设计师的形成性研究。我们进一步开发了一个原型系统DataSway，并进行了一项用户研究（N=14）以评估其创意支持和可用性。一个包含六个案例的画廊展示了其在基于Web的超媒体中的能力和应用。我们最后提出了对定制数据可视化动画未来研究的启示。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [288] [Eliciting User Requirements for AI-Enhanced Learning Environments using a Participatory Approach](https://arxiv.org/abs/2507.21088)
> *使用参与式方法获取AI增强学习环境的用户需求*

*Bibeg Limbu, Irene-Angelica Chounta, Vilma Sukacke, Andromachi Filippidi, Chara Spyropoulou, Marianna Anagnostopoulou, Eleftheria Tsourlidaki, Nikos Karacapilidis* | **Category: cs.HC** | **Updated: 2025-07-30**

**Keywords:** AI增强学习环境, 用户需求, 参与式方法, 活动理论, 主题分析

**Comment:** 12 pages, 2 figures, 15th International Conference on Methodologies
  and Intelligent Systems for Technology Enhanced Learning (mis4tel), Workshop
  Track: Workshop on Integration of Emerging Technologies into Education and
  Training (ETELT) https://mis4tel-conference.net/tracks/workshops/etelt,
  accepted

> **TL;DR:** 本文通过两阶段参与式研讨会和主题分析，探讨了教育利益相关者对AI增强学习环境的需求和期望，以生成用户需求。

**AI_Comments:** 该论文通过采用参与式方法，直接从教育利益相关者那里获取需求和期望，这种用户中心的创新方法对于新兴技术（如AI在教育中的应用）的设计至关重要。通过识别需求和期望之间的矛盾，能够更全面地理解用户痛点，从而提供更实际和有效的设计建议。

<details>
  <summary>Details</summary>

**Motivation:** 探索教育利益相关者对AI增强学习环境的需求和期望。

**Method:** 采用了两阶段的参与式研讨会。第一阶段通过演绎主题分析结合活动理论分析定性数据，阐明用户需求。第二阶段通过归纳主题分析阐明用户期望。然后交叉检查需求和期望，识别矛盾，以生成用户需求。

**Result:** 阐明了用户需求和期望，并识别了两者之间的矛盾，最终生成了AI增强学习环境的用户需求。

**Conclusion:** 该论文为未来在学习环境中整合AI的设计举措提供了建议。

> **ai_Abstract:** 本研究通过两阶段参与式研讨会，探讨了教育利益相关者对AI增强学习环境的需求和期望。研究利用演绎主题分析（结合活动理论）和归纳主题分析，分别阐明了用户需求和期望，并通过交叉检查识别矛盾，最终生成了AI增强学习环境的用户需求，并为未来的AI教育设计提供了建议。

> **摘要翻译:** 本文探讨了教育利益相关者对AI（人工智能）增强学习环境的需求和期望。数据是通过两阶段的参与式研讨会收集的。第一次研讨会概述了利益相关者在技术和教学方面的特征。收集到的定性数据使用活动理论进行演绎主题分析，阐明了用户需求。第二次研讨会阐明了与AI在教育中整合相关的期望。对第二次研讨会进行归纳主题分析，从而获取用户的期望。我们交叉检查了需求和期望，识别出矛盾，以生成新兴技术的用户需求。本文为未来在学习环境中整合AI的设计举措提供了建议。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [316] [UI-E2I-Synth: Advancing GUI Grounding with Large-Scale Instruction Synthesis](https://arxiv.org/abs/2504.11257)
> *UI-E2I-Synth：利用大规模指令合成推进GUI接地*

*Xinyi Liu, Xiaoyi Zhang, Ziyun Zhang, Yan Lu* | **Category: cs.HC, cs.CL, cs.CV** | **Updated: 2025-07-30**

**Keywords:** GUI接地, 数据合成, 大规模语言模型, GPT-4o, 基准测试

**Comment:** 

> **TL;DR:** 本文提出了UI-E2I-Synth数据合成管道和UI-I2E-Bench基准，以解决GUI指令接地任务中数据稀缺和挑战。

**AI_Comments:** 该论文的创新点在于利用大型语言模型GPT-4o进行GUI指令的大规模数据合成，有效解决了GUI接地任务中数据稀缺和标注成本高昂的痛点。这种方法提高了数据生成的效率和多样性，对于推动视觉-语言模型在GUI自动化领域的应用具有重要意义。提出的新基准也为未来研究提供了更全面的评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有GUI接地任务面临公共训练数据集有限、手动指令数据标注资源密集、以及元素到屏幕比例、不平衡元素类型和隐式指令等未探索的挑战。

**Method:** 引入大规模数据合成管道UI-E2I-Synth，使用GPT-4o生成不同复杂度的指令数据集；提出新的GUI指令接地基准UI-I2E-Bench，旨在解决现有基准的局限性。

**Result:** 在合成数据上训练的模型在GUI指令接地方面取得了卓越的性能，证明了所提出的数据合成管道的先进性。

**Conclusion:** 所提出的数据合成管道UI-E2I-Synth和基准UI-I2E-Bench推进了GUI指令接地任务，并为未来的研究提供了实践见解。

> **ai_Abstract:** 本文介绍了UI-E2I-Synth，一个利用GPT-4o进行大规模GUI指令数据合成的管道，旨在解决GUI指令接地任务中数据稀缺和手动标注耗时的问题。同时，文章还提出了UI-I2E-Bench，一个旨在克服现有基准局限性的新GUI指令接地基准。实验结果表明，在UI-E2I-Synth合成数据上训练的模型在GUI指令接地任务上表现优异，验证了该数据合成方法的有效性，并且新基准为未来研究提供了有价值的洞察。

> **摘要翻译:** 大型视觉-语言模型的最新进展正在加速图形用户界面（GUI）代理的开发，这些代理利用类似人类的视觉感知能力来提高数字设备上的生产力。与依赖于平台相关且易受实现变化影响的GUI元数据方法相比，基于视觉的方法具有更广泛的适用性。在这种基于视觉的范式中，GUI指令接地（即将用户指令映射到给定屏幕截图中相应元素的位置）仍然是一个关键挑战，特别是由于公共训练数据集有限和手动指令数据标注资源密集。在本文中，我们深入探讨了此任务中未探索的挑战，包括元素与屏幕的比例、不平衡的元素类型和隐式指令。为了应对这些挑战，我们引入了一个大规模数据合成管道UI-E2I-Synth，用于使用GPT-4o而不是人工标注员生成不同复杂度的指令数据集。此外，我们提出了一个新的GUI指令接地基准UI-I2E-Bench，旨在通过结合多样化的标注方面来解决现有基准的局限性。我们通过合成数据训练的模型在GUI指令接地方面取得了卓越的性能，展示了所提出的数据合成管道的进步。所提出的基准，伴随着广泛的分析，为GUI接地未来的研究提供了实践见解。我们将在https://microsoft.github.io/FIVE-UI-Evol/发布相应的工件。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [351] [Emotionally Aware Moderation: The Potential of Emotion Monitoring in Shaping Healthier Social Media Conversations](https://arxiv.org/abs/2507.21089)
> *情感感知审核：情绪监测在塑造更健康的社交媒体对话中的潜力*

*Xiaotian Su, Naim Zierau, Soomin Kim, April Yi Wang, Thiemo Wambsganss* | **Category: cs.HC, cs.CL** | **Updated: 2025-06-24**

**Keywords:** 情绪监测, 社交媒体审核, 仇恨言论, 情绪意识, 用户行为

**Comment:** 

> **TL;DR:** 本研究提出并评估了两种情绪监测仪表盘，旨在提高用户情绪意识并减少仇恨言论，结果显示有效减少仇恨言论但可能增加负面情绪表达。

**AI_Comments:** 该研究创新性地探讨了情绪监测作为一种新型审核手段的潜力，超越了传统的事后审查，转向提升用户自我意识。其重要性在于为创建更健康、更具同理心的在线交流环境提供了新的视角和实证依据。然而，研究也揭示了潜在的负面影响，即可能在敏感话题上引发更多负面情绪表达，这提示未来设计需更精细化。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体平台现有的主动审核技术（如检测和遏制有害评论）常被批评为审查制度，且未能解决不文明行为的根本原因。

**Method:** 研究提出并评估了两种情绪监测仪表盘，旨在提高用户情绪意识并减轻仇恨言论。通过一项涉及211名参与者的研究，评估了这两种机制对用户评论行为和情绪体验的影响。

**Result:** 干预措施有效提高了用户对其情绪状态的认知，并减少了仇恨言论。然而，研究也指出潜在的意外影响，包括在讨论敏感问题时负面情绪（愤怒、恐惧和悲伤）表达的增加。

**Conclusion:** 这些见解为进一步研究将主动情绪调节工具整合到社交媒体平台中以促进更健康的数字互动提供了基础。

> **ai_Abstract:** 本研究提出并评估了两种情绪监测仪表盘，旨在通过提高用户情绪意识来缓解社交媒体上的仇恨言论。一项对211名参与者的研究表明，这些干预措施能有效提升用户情绪感知并减少仇恨言论，但同时可能导致在敏感话题讨论中负面情绪的更多表达。研究为未来在社交媒体中整合情绪调节工具以促进健康互动提供了依据。

> **摘要翻译:** 社交媒体平台越来越多地采用主动审核技术，例如检测和遏制有毒和不文明评论，以防止有害内容的传播。尽管做出了这些努力，但此类方法经常因制造审查气氛和未能解决不文明行为的根本原因而受到批评。我们的工作通过提出和评估两种类型的情绪监测仪表盘来提高用户的情绪意识并减轻仇恨言论，从而做出了理论和实践贡献。在一项涉及211名参与者的研究中，我们评估了这两种机制对用户评论行为和情绪体验的影响。结果显示，这些干预措施有效地提高了用户对其情绪状态的认知并减少了仇恨言论。然而，我们的研究结果也表明潜在的意外影响，包括在讨论敏感问题时负面情绪（愤怒、恐惧和悲伤）表达的增加。这些见解为进一步研究将主动情绪调节工具整合到社交媒体平台中以促进更健康的数字互动提供了基础。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [414] [Thinking Like a Scientist: Can Interactive Simulations Foster Critical AI Literacy?](https://arxiv.org/abs/2507.21090)
> *像科学家一样思考：交互式模拟能否培养批判性人工智能素养？*

*Yiling Zhao, Audrey Michal, Nithum Thain, Hari Subramonyam* | **Category: cs.HC, cs.AI** | **Updated: 2025-06-25**

**Keywords:** AI素养, 交互式模拟, 批判性思维, AI教育, 假设检验

**Comment:** 

> **TL;DR:** 交互式模拟能通过科学探究方式有效提升批判性AI素养和知识迁移。

**AI_Comments:** 本研究的创新之处在于提出并实证检验了交互式模拟作为一种新颖的、探究驱动的AI素养教育方法，超越了被动学习模式。其重要性在于解决了在日益由AI驱动的世界中对批判性AI素养的迫切社会需求，并为该领域主动学习方法的有效性提供了具体证据。抽象中提到“单纯的参与并不能预测学习效果”是一个有趣的发现，暗示了互动质量的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于AI系统对个人和社会决策的影响日益增长，培养批判性AI素养至关重要。传统方法未能有效促进深度概念理解和批判性参与，因此需要探索更有效的方法。

**Method:** 本研究采用一项包含605名参与者的对照研究，评估交互式AI教程对AI素养学习的影响。该方法通过让学习者进行假设检验、实验和直接观察AI行为，来模拟科学家的思维方式。

**Result:** 交互式模拟能有效提升跨主题的AI素养，并支持更高的知识迁移和自我报告的信心。但单纯的参与并不能预测学习效果。

**Conclusion:** 交互式、探究驱动的方法（如交互式模拟）能够更好地帮助个体批判性地参与日常AI应用，对AI素养教育领域有所贡献。

> **ai_Abstract:** 本文研究了交互式模拟在培养批判性AI素养方面的有效性，以解决传统教育方法的局限性。通过一项包含605名参与者的对照研究，结果表明交互式AI教程能显著增强学习者对公平性和偏见等AI概念的理解，提高知识迁移并增强信心。研究结果表明，探究驱动的交互式方法对于帮助个体批判性地参与AI应用具有重要价值。

> **摘要翻译:** 随着人工智能系统塑造个人和社会决策，培养批判性人工智能素养至关重要。博客文章、静态课程和社交媒体讨论等传统方法往往无法支持深度的概念理解和批判性参与。本研究探讨了交互式模拟是否能通过让学习者参与假设检验、实验和直接观察AI行为，从而帮助他们像科学家一样思考。在一项有605名参与者的对照研究中，我们评估了交互式AI教程如何影响对公平性、数据集代表性和语言模型中的偏见等关键概念的学习。结果显示，交互式模拟能有效提升跨主题的AI素养，支持更高的知识迁移和自我报告的信心，尽管单纯的参与并不能预测学习效果。这项工作为不断发展的人工智能素养教育领域做出了贡献，强调了交互式、探究驱动的方法如何能更好地帮助个体批判性地参与日常AI应用。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [479] [VizGenie: Toward Self-Refining, Domain-Aware Workflows for Next-Generation Scientific Visualization](https://arxiv.org/abs/2507.21124)
> *VizGenie：迈向下一代科学可视化的自优化、领域感知工作流*

*Ayan Biswas, Terece L. Turton, Nishath Rajiv Ranasinghe, Shawn Jones, Bradley Love, William Jones, Aric Hagberg, Han-Wei Shen, Nathan DeBardeleben, Earl Lawrence* | **Category: cs.HC, cs.AI, cs.GR, cs.LG** | **Updated: 2025-07-18**

**Keywords:** 科学可视化, 大型语言模型, 智能体框架, 自优化, 视觉问答

**Comment:** 

> **TL;DR:** VizGenie是一个基于LLM的自改进智能体框架，通过协调领域特定模块和动态生成的脚本，并结合自然语言界面、图像分析和VQA，显著降低了科学可视化任务的认知负担，实现洞察加速和可持续的可视化实践。

**AI_Comments:** VizGenie的创新之处在于其将LLM与领域特定工具相结合，构建了一个自改进、智能体的可视化框架。其亮点在于能够动态生成代码以扩展功能、通过自然语言界面简化用户交互，以及通过VQA实现图像级语义理解。这种方法显著降低了用户进行复杂科学可视化任务的认知负担，并促进了可重复的研究，为下一代可视化工具的发展提供了有前景的方向。其持续学习和自我完善的机制是其重要性所在。

<details>
  <summary>Details</summary>

**Motivation:** 目前的科学可视化工作流程可能存在认知开销大、适应性差的问题。VizGenie旨在通过利用大型语言模型（LLM）来推进科学可视化，使其实现自改进、领域感知，并降低迭代可视化任务的认知负担，从而加速洞察生成并建立可持续的实践。

**Method:** VizGenie是一个自改进的智能体框架，通过大型语言模型（LLM）协调领域特定和动态生成的模块来推进科学可视化。它允许用户通过预设工具访问核心功能，并自主使用LLM生成新的可视化脚本（如VTK Python代码），从而按需扩展能力。生成的脚本经过自动化后端验证并无缝集成。系统具有直观的自然语言界面，通过图像分析和微调视觉模型进行视觉问答（VQA）来解释高级查询。它还通过VQA支持对生成可视化的交互式查询。检索增强生成（RAG）用于提供上下文驱动的响应，同时保持全面的溯源记录，以增强可靠性和可重复性。

**Result:** 在复杂的体积数据集上进行的评估表明，VizGenie显著降低了迭代可视化任务的认知开销。该平台能够动态地从用户交互中学习，持续增强对以特征为中心的探索和科学可视化中可重复研究的支持。

**Conclusion:** VizGenie通过整合精选的领域特定工具与LLM驱动的灵活性，不仅加速了洞察生成，还建立了一种可持续的、不断发展的可视化实践。它能够从用户交互中动态学习，持续提升对特征中心探索和可重复研究的支持。

> **ai_Abstract:** VizGenie是一个创新的自改进智能体框架，它利用大型语言模型（LLM）来革新科学可视化。该系统通过协调预设的领域工具和动态生成的代码（如VTK Python脚本）来扩展其能力。它提供直观的自然语言界面，结合图像分析和视觉问答（VQA）来解释用户查询，并允许对结果进行交互式探索。VizGenie通过自动化验证和检索增强生成（RAG）确保了可靠性和可重复性。在复杂数据集上的评估表明，它显著降低了迭代可视化任务的认知开销，从而加速了洞察生成并促进了可持续、可演进的科学可视化实践。

> **摘要翻译:** 我们提出了VizGenie，一个自改进的智能体框架，通过协调一系列领域特定和动态生成的模块，利用大型语言模型（LLM）推动科学可视化。用户最初通过现有工具访问核心功能——例如基于阈值的过滤、切片提取和统计分析。对于超出此基线的任务，VizGenie自主使用LLM生成新的可视化脚本（例如VTK Python代码），按需扩展其能力。每个生成的脚本都经过自动化后端验证，并在测试成功后无缝集成，持续增强系统的适应性和鲁棒性。VizGenie的一个独特特点是其直观的自然语言界面，允许用户发出高级的基于特征的查询（例如，“可视化头骨”）。系统通过微调的视觉模型利用基于图像的分析和视觉问答（VQA）来精确解释这些查询，弥合了领域专业知识和技术实现之间的鸿沟。此外，用户可以通过VQA交互式地查询生成的可视化，促进更深入的探索。检索增强生成（RAG）进一步增强了可靠性和可重复性，它在提供上下文驱动响应的同时保持全面的溯源记录。对复杂体积数据集的评估表明，迭代可视化任务的认知开销显著降低。通过将精选的领域特定工具与LLM驱动的灵活性相结合，VizGenie不仅加速了洞察生成，还建立了一种可持续的、不断发展的可视化实践。由此产生的平台动态地从用户交互中学习，持续增强对以特征为中心的探索和科学可视化中可重复研究的支持。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [542] [ProMemAssist: Exploring Timely Proactive Assistance Through Working Memory Modeling in Multi-Modal Wearable Devices](https://arxiv.org/abs/2507.21378)
> *ProMemAssist：通过多模态可穿戴设备中的工作记忆建模探索及时主动协助*

*Kevin Pu, Ting Zhang, Naveen Sendhilnathan, Sebastian Freitag, Raj Sodhi, Tanya Jonker* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 主动协助, 工作记忆, 可穿戴设备, 多模态, 智能眼镜

**Comment:** Accepted to UIST'25

> **TL;DR:** ProMemAssist是一个智能眼镜系统，通过实时建模用户工作记忆来提供更及时、更少干扰的主动协助，并在用户研究中表现优于LLM基线系统。

**AI_Comments:** ProMemAssist的创新之处在于将认知心理学中的工作记忆模型引入到可穿戴AI系统中，以解决现有系统缺乏用户心理状态感知的痛点。通过平衡协助价值与中断成本，该系统旨在提供更自然、更少干扰的用户体验，这对于未来主动式智能体的设计具有重要意义。其多模态数据整合和认知理论的应用是值得关注的亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可穿戴AI系统通常依赖用户启动或预定义的任务知识，忽略了用户的当前精神状态，导致无法提供及时、恰当的协助。

**Method:** 本文引入了ProMemAssist系统，一个智能眼镜系统。它利用多模态传感器信号实时建模用户的工作记忆（WM），并基于认知理论（如替换和干扰）将感知信息表示为记忆项和事件。该WM模型指导一个时机预测器，以平衡协助的价值和中断的成本。

**Result:** 在对12名参与者进行的认知要求高的任务用户研究中，ProMemAssist与LLM基线系统相比，提供了更具选择性的协助，并获得了更高的参与度。定性反馈强调了WM建模在提供细致、上下文敏感支持方面的益处。

**Conclusion:** 通过工作记忆建模，ProMemAssist能够提供更具选择性、更高参与度的及时主动协助，为开发更具专注性和用户感知能力的主动智能体提供了设计启示。

> **ai_Abstract:** ProMemAssist是一个创新的智能眼镜系统，通过实时建模用户的工作记忆（WM），旨在提供及时且非侵入性的主动协助。它利用多模态传感器数据，并基于认知理论来预测最佳的协助时机，以平衡帮助的价值和潜在的干扰。用户研究表明，该系统在提供选择性协助和提高用户参与度方面优于传统的LLM基线系统，证明了WM建模在创建更智能、更人性化可穿戴AI系统中的潜力。

> **摘要翻译:** 可穿戴AI系统旨在日常生活中提供及时协助，但现有方法通常依赖用户启动或预定义的任务知识，忽视了用户当前的心理状态。我们引入了ProMemAssist，一个智能眼镜系统，它利用多模态传感器信号实时建模用户的工作记忆（WM）。基于WM的认知理论，我们的系统将感知到的信息表示为具有编码机制（如替换和干扰）的记忆项和事件。这个WM模型指导一个时机预测器，平衡协助的价值和中断的成本。在一项有12名参与者完成认知要求高的任务的用户研究中，ProMemAssist与LLM基线系统相比，提供了更具选择性的协助并获得了更高的参与度。定性反馈强调了WM建模对于细致、上下文敏感支持的益处，为更具专注性和用户感知能力的主动智能体提供了设计启示。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [578] [Exploring Keyboard Positioning and Ten-Finger Typing in Mixed Reality](https://arxiv.org/abs/2410.04177)
> *探索混合现实中的键盘定位和十指打字*

*Cecilia Schmitz, Joshua Reynolds, Scott Kuhl, Keith Vertanen* | **Category: cs.HC** | **Updated: 2025-07-28**

**Keywords:** 混合现实, 键盘, 打字, 触觉反馈, 眼动追踪

**Comment:** 

> **TL;DR:** 本文研究了混合现实中键盘定位和十指打字的效果。实验发现，用户更喜欢使用空中键盘，并且用食指打字的速度最快。虽然十指打字结合眼动追踪可以减少错误，但整体速度不如食指打字。

**AI_Comments:** 这项研究在混合现实打字领域具有重要意义，它通过实验比较了不同键盘定位（空中、桌面、墙面）和打字方式（食指、十指）的效果，并引入了创新的眼动追踪技术来解决十指打字中的误触问题。其局限性在于，尽管十指打字结合眼动追踪减少了错误，但速度仍不如食指打字，这表明在提高MR中十指打字效率方面仍有挑战。

<details>
  <summary>Details</summary>

**Motivation:** 混合现实中的打字通常使用食指在空中键盘上进行，这缺乏实体设备的触觉反馈，并且限制了用户使用更方便的手指按键，导致准确性和速度不足。

**Method:** 本文进行了两项实验。第一个实验研究了将虚拟键盘放置在桌面或墙壁上以提供触觉反馈的效果，键盘是确定性的，支持大小写和符号，并仅依赖于商品头显的眼部追踪。第二个实验探索了十指打字，并使用了一种新颖的眼动追踪技术来避免意外按键。

**Result:** 在第一个实验中，用户更喜欢空中键盘，并获得了最高的输入速率（12个单词/分钟），所有条件下的错误率相似。在第二个实验中，眼动追踪技术在十指打字中更受欢迎，并使修正次数减半。然而，参与者在使用食指且不带眼动追踪时速度更快（11个单词/分钟）。

**Conclusion:** 空中键盘结合食指打字在混合现实中当前表现出更高的速度和用户偏好。虽然眼动追踪有助于十指打字减少错误，但整体效率仍低于食指打字。未来的研究可以进一步探索如何提高混合现实中十指打字的效率和用户体验。

> **ai_Abstract:** 本研究探讨了混合现实环境中键盘定位对打字性能的影响，以及引入十指打字和眼动追踪技术的潜力。实验结果表明，尽管空中键盘结合食指打字在速度上表现最佳（12 WPM），且用户偏好度高，但为十指打字引入眼动追踪技术能有效减少错误。然而，总体而言，食指打字仍比十指打字更快。

> **摘要翻译:** 准确性和速度在打字时至关重要。混合现实中的打字通常通过食指在空中键盘上进行。这使得用户既无法获得物理设备上的触觉反馈，也无法用最方便的手指按键。我们的第一个实验研究了通过将虚拟键盘放置在桌面或墙壁上来提供触觉反馈。该键盘是确定性的（没有自动更正），支持大小写和符号打字，并且只依赖于商用头显的自我中心摄像头提供的手部追踪。用户更喜欢使用空中键盘，并获得了每分钟12个单词的最高输入速率。所有条件下的错误率相似。我们的第二个实验探索了十指打字，并使用了一种新颖的眼动追踪技术来避免意外按键。这种技术在十指打字中更受欢迎，并将修正次数减半。然而，参与者在使用食指且不带眼动追踪时速度更快，为每分钟11个单词。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [604] [InSituTale: Enhancing Augmented Data Storytelling with Physical Objects](https://arxiv.org/abs/2507.21411)
> *InSituTale：通过物理对象增强增强型数据故事讲述*

*Kentaro Takahira, Yue Yu, Takanori Fujiwara, Suzuki Ryo, Huamin Qu* | **Category: cs.HC, cs.GR** | **Updated: 2025-07-29**

**Keywords:** 增强数据故事讲述, 物理对象交互, 可视化控制, InSituTale, 人机交互

**Comment:** 

> **TL;DR:** InSituTale 引入了一种增强型物理数据故事讲述方法，允许演示者通过物理对象互动来操作可视化，并在一项用户研究中展示了其直观性、实用性和参与性。

**AI_Comments:** 该论文的创新之处在于其将物理对象交互引入增强型数据故事讲述领域，解决了现有系统对身体手势和语音过度依赖的局限性。通过结合深度摄像头和 Vision-LLM，InSituTale 提供了一种新颖且直观的交互范式，有望提升数据演示的沉浸感和参与度。其重要性在于为未来的人机交互和数据可视化领域开辟了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的增强型数据故事讲述系统主要依赖身体手势或语音来控制可视化，而与物理对象的互动在很大程度上未被充分探索。本研究旨在探索并实现通过物理对象操纵可视化。

**Method:** 首先，进行了一项数据驱动演示调查，以识别常见的可视化命令。其次，与九位 HCI/VIS 研究人员进行了研讨会，收集了物理操作与这些命令之间的映射。基于这些见解，开发了 InSituTale 原型，该原型结合了深度摄像头进行对象跟踪和 Vision-LLM 用于检测真实世界事件。最后，通过一项包含 12 名参与者的用户研究评估了 InSituTale。

**Result:** 用户研究表明 InSituTale 能够实现直观的交互，提供高实用性，并促进引人入胜的演示体验。

**Conclusion:** InSituTale 成功地通过物理对象互动增强了增强型数据故事讲述，提供了一种将物理和数字元素融合的连贯数据故事讲述体验。

> **ai_Abstract:** InSituTale 提出了一种新的增强型数据故事讲述方法，允许演示者通过物理对象而非传统手势或语音来控制可视化。该方法基于对现有演示命令的调查和与研究人员的研讨会，开发了一个结合深度摄像头跟踪和 Vision-LLM 的原型系统。用户研究验证了 InSituTale 提供直观、实用且引人入胜的演示体验。

> **摘要翻译:** 增强型数据故事讲述通过将可视化与物理环境和演示者动作相结合来增强叙事呈现。现有系统主要依赖身体手势或语音来控制可视化，而与物理对象的互动在很大程度上未被充分探索。我们引入了增强型物理数据故事讲述，这是一种使演示者能够通过物理对象互动来操纵可视化的方法。为了支持这种方法，我们首先对数据驱动的演示进行了调查，以识别常见的可视化命令。然后，我们与九位 HCI/VIS 研究人员进行了研讨会，收集了物理操作与这些命令之间的映射。在这些见解的指导下，我们开发了 InSituTale，这是一个结合了通过深度摄像头进行对象跟踪和 Vision-LLM 用于检测真实世界事件的原型。通过物理操作，演示者可以动态执行各种可视化命令，提供融合物理和数字元素的连贯数据故事讲述体验。一项包含 12 名参与者的用户研究表明，InSituTale 能够实现直观的交互，提供高实用性，并促进引人入胜的演示体验。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [611] [Can LLMs Reason About Trust?: A Pilot Study](https://arxiv.org/abs/2507.21075)
> *大型语言模型能否推理信任？：一项初步研究*

*Anushka Debnath, Stephen Cranefield, Emiliano Lorini, Bastin Tony Roy Savarimuthu* | **Category: cs.HC, cs.CL, cs.CY, cs.MA** | **Updated: 2025-06-11**

**Keywords:** 大型语言模型, 信任, 社会关系, 人工智能, 初步研究

**Comment:** 17 pages, 5 figures, 3 tables Accepted for presentation as a full
  paper at the COINE 2025 workshop at AAMAS 2025 see
  https://coin-workshop.github.io/coine-2025-detroit/accepted_for_presentation.html

> **TL;DR:** 本文初步研究了大型语言模型（LLMs）在需要培养信任关系的环境中，推理个体间信任的能力，并评估LLMs是否能通过角色扮演来诱导信任。

**AI_Comments:** 这项研究的创新之处在于它首次探讨了大型语言模型能否理解并模拟人类社会中复杂的“信任”概念，这对于未来AI在社交互动和关系建立中的应用具有重要意义。虽然是一项初步研究，但其开启了LLMs在更深层次社会智能方面潜力的探索。

<details>
  <summary>Details</summary>

**Motivation:** 信任是人类社会中建立和维护长期健康关系的重要组成部分，它为合作奠定了坚实基础。随着许多人类互动通过电子方式发生，AI系统有可能协助用户理解其关系的社会状态。因此，研究LLMs推理和诱导信任的能力变得重要。

**Method:** 研究人员调查了大型语言模型（LLMs）在需要培养信任关系的环境中，推理两个个体之间信任的能力。他们还评估了LLMs是否能够通过在基于信任的互动中扮演一方角色并规划能够灌输信任的行动来诱导信任。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本初步研究探讨了大型语言模型（LLMs）在需要培养信任关系的情境中，推理个体间信任的能力。此外，论文还评估了LLMs通过角色扮演和规划行动来诱导信任的可能性，旨在探索AI系统在理解和影响人类社会关系方面的潜力。

> **摘要翻译:** 在人类社会中，信任是社会态度的重要组成部分，有助于建立和维护长期、健康的关系，为合作奠定坚实基础，使个体能够有效地协同工作并实现共同目标。由于许多人类互动通过电子方式（如使用移动应用程序）进行，人工智能系统协助用户理解其关系社会状态的可能性随之产生。在本文中，我们调查了大型语言模型（LLMs）在需要培养信任关系的环境中，推理两个个体之间信任的能力。我们还评估了LLMs是否能够通过在基于信任的互动中扮演一方角色并规划能够灌输信任的行动来诱导信任。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [648] [MEDebiaser: A Human-AI Feedback System for Mitigating Bias in Multi-label Medical Image Classification](https://arxiv.org/abs/2507.10044)
> *MEDebiaser：一种用于减轻多标签医学图像分类偏差的人机反馈系统*

*Shaohan Shi, Yuheng Shao, Haoran Jiang, Yunjie Yao, Zhijun Zhang, Xu Ding, Quan Li* | **Category: cs.HC** | **Updated: 2025-07-29**

**Keywords:** 医学图像分类, 偏差缓解, 人机反馈, 多标签, 局部解释

**Comment:** Will appear at UIST2025

> **TL;DR:** MEDebiaser是一个交互式系统，允许医生直接使用局部解释来改进AI模型，以减轻多标签医学图像分类中的偏差，提高人机协作效率。

**AI_Comments:** MEDebiaser的创新之处在于它建立了一个直接的人机反馈循环，使医生能够无需技术背景即可干预和修正AI模型的偏差。这大大降低了将医学专业知识融入AI训练过程的门槛和成本，提高了医疗AI的实用性和可信度。其重要性体现在它能加速AI在临床诊断中的落地应用，并提高诊断的准确性和公平性。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像中多标签的分布不平衡和共现导致多标签医学图像分类中存在偏差。传统的医患与AI模型之间的协作模式难以实现有效的反馈，因为将医学专业知识通过工程师整合到训练过程中既耗时又费力。

**Method:** MEDebiaser通过结合预测与注意力损失函数，并采用定制的排序策略来缓解可扩展性问题，使医生无需技术专业知识即可减轻偏差，减少对工程师的依赖，从而增强更直接的人机反馈。

**Result:** 该机制和用户研究表明，MEDebiaser有效减少了偏差，提高了可用性，并增强了协作效率。

**Conclusion:** MEDebiaser为将医学专业知识整合到AI驱动的医疗保健中提供了一个实用的解决方案，有效减轻了多标签医学图像分类中的偏差，并提高了人机协作效率。

> **ai_Abstract:** MEDebiaser是一个创新的人机交互系统，旨在解决多标签医学图像分类中因数据不平衡和共现导致的偏差问题。它允许医生直接利用局部解释来优化AI模型，无需依赖工程师的技术介入。该系统通过结合预测与注意力损失函数和定制的排序策略，有效减轻了模型偏差，提高了系统的可用性，并显著增强了医疗专业人员与AI之间的协作效率，为AI在医疗领域的应用提供了实用且高效的解决方案。

> **摘要翻译:** 医学图像通常包含多标签，其分布不平衡且存在共现，导致多标签医学图像分类中存在偏差。医学专业人员和机器学习从业者之间的密切合作显著推动了医学图像分析。然而，传统的协作模式难以促进医生和AI模型之间有效的反馈，因为通过工程师将医学专业知识整合到训练过程中可能耗时且费力。为了弥合这一差距，我们引入了MEDebiaser，一个交互式系统，使医生能够使用局部解释直接改进AI模型。通过结合预测与注意力损失函数并采用定制的排序策略来缓解可扩展性问题，MEDebiaser允许医生在没有技术专业知识的情况下减轻偏差，减少对工程师的依赖，从而增强更直接的人机反馈。我们的机制和用户研究表明，它有效减少了偏差，提高了可用性，并增强了协作效率，为将医学专业知识整合到AI驱动的医疗保健中提供了一个实用的解决方案。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [674] [MindChat: Enhancing BCI Spelling with Large Language Models in Realistic Scenarios](https://arxiv.org/abs/2507.21435)
> *MindChat：在现实场景中利用大型语言模型增强脑机接口拼写*

*JIaheng Wang, Yucun Zhong, Chengjie Huang, Lin Yao* | **Category: cs.HC** | **Updated: 2025-07-29**

**Keywords:** 脑机接口, 大型语言模型, 拼写器, 效率, 提示工程

**Comment:** 

> **TL;DR:** MindChat是一个利用大型语言模型（LLM）的脑机接口（BCI）拼写器，通过提供上下文感知的补全来减少击键次数和拼写时间，显著提高了BCI拼写效率。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型（LLM）引入脑机接口（BCI）拼写领域，通过上下文预测显著提高了拼写效率。其重要性在于为重度运动障碍患者提供了一种更高效、更实用的交流方式，有望推动BCI技术从实验室走向现实应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有脑机接口拼写器需要用户逐字输入，且拼写错误率随EEG解码不准确而增加，严重阻碍了BCI在现实通信中的效率和可用性，尤其对于重度运动障碍患者。

**Method:** 本文提出了MindChat，一个LLM辅助的BCI拼写器。通过提示工程，该系统利用LLM（GPT-4o）在拼写过程中持续提供上下文感知的单词和句子补全/预测，从而减少用户手动击键。

**Result:** 在涵盖四种对话场景的在线复制拼写实验中，MindChat与传统BCI拼写器相比，节省了超过62%的击键次数和超过32%的拼写时间。

**Conclusion:** LLM增强的高速BCI拼写器有望实现真正实用的应用。

> **ai_Abstract:** 本文提出了MindChat，一个基于大型语言模型（LLM）的脑机接口（BCI）拼写器，旨在解决现有BCI拼写器效率低下和错误率高的问题。通过利用LLM（GPT-4o）进行上下文感知的词语和句子补全，MindChat显著减少了用户手动击键次数。实验结果显示，MindChat相较于传统BCI拼写器，能节省超过62%的击键和32%的拼写时间，预示着LLM在提升BCI实用性方面的巨大潜力。

> **摘要翻译:** 脑机接口（BCI）拼写器可以提供一个独立于周围神经系统的新交流通道，这对于重度运动障碍患者尤为宝贵。然而，当前的BCI拼写器通常要求用户逐字输入，并且由于脑电图（EEG）解码不准确，拼写错误会按比例增加，这在很大程度上阻碍了BCI在现实世界通信中的效率和可用性。在本文中，我们提出了MindChat，一个大型语言模型（LLM）辅助的BCI拼写器，旨在通过减少用户手动击键来提高BCI拼写效率。我们基于提示工程，提示LLM（GPT-4o）在拼写过程中持续建议上下文感知的单词和句子补全/预测。涵盖四种对话场景的在线复制拼写实验表明，与传统BCI拼写器相比，MindChat节省了超过62%的击键次数和超过32%的拼写时间。我们设想由LLM增强的高速BCI拼写器将可能带来真正实用的应用。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [711] [Automated Brake Onset Detection in Naturalistic Driving Data](https://arxiv.org/abs/2507.17943)
> *自然驾驶数据中自动刹车起始点检测*

*Shu-Yuan Liu, Johan Engström, Gustav Markkula* | **Category: cs.HC, cs.RO** | **Updated: 2025-07-28**

**Keywords:** 刹车起始点检测, 自然驾驶数据, 自动驾驶系统, 响应时间, 分段线性加速度模型

**Comment:** 

> **TL;DR:** 本文开发了一种基于分段线性加速度模型的算法，用于在车辆控制信号不可用的大规模驾驶数据中自动检测刹车起始点，并通过人工标注进行了验证。

**AI_Comments:** 该论文的创新点在于提出了一种在缺乏传统车辆控制信号（如踏板数据）的情况下，利用车辆纵向时间序列数据自动检测刹车起始点的方法，这对于分析大规模自然驾驶数据，特别是自动驾驶系统（ADS）的日志数据具有重要意义。其高效性、通用性和可配置性使其在实际应用中具有广阔前景，有助于推进ADS的评估技术。尽管论文提到了算法存在局限性，但其核心价值在于解决了数据可用性受限时的关键测量问题。

<details>
  <summary>Details</summary>

**Motivation:** 在碰撞避免场景中，响应时间测量对于评估自动驾驶系统（ADS）至关重要，包括建立人类基准和比较ADS与人类驾驶员的响应性能。现有方法依赖手动标注或车辆控制信号（如油门和刹车踏板运动），但在车辆控制信号不可用的大规模数据（特别是快速增长的ADS日志数据）分析中不适用。

**Method:** 开发了一种基于分段线性加速度模型的简单高效算法，用于自动估计刹车起始点，可应用于包含车辆纵向时间序列数据的任何类型驾驶数据。提出了一种人工标注方法来识别刹车起始点并作为验证的真实值。使用R^2作为置信度指标来衡量算法的准确性，并使用ADS和人类的自然碰撞避免数据分析其分类性能，并与人工标注进行验证。

**Result:** 该算法高效、可泛化、适用于任何道路使用者和场景类型，并且高度可配置。

**Conclusion:** 本文提出的自动刹车起始点检测算法，尽管存在局限性，但其高效性、通用性和可配置性使其成为在缺乏车辆控制信号的大规模驾驶数据中评估自动驾驶系统响应时间的一种有价值的工具。

> **ai_Abstract:** 为了解决在缺乏车辆控制信号的大规模驾驶数据中，现有方法无法有效检测刹车起始点的问题，本文提出了一种基于分段线性加速度模型的自动化算法。该算法能从车辆纵向时间序列数据中高效估算刹车起始点，并通过人工标注作为真实值进行验证。研究结果表明，该算法高效、通用且高度可配置，适用于多种道路使用者和场景，为自动驾驶系统的评估提供了新的工具。

> **摘要翻译:** 响应时间测量在碰撞避免场景中评估自动驾驶系统（ADS）方面发挥着关键作用，包括但不限于建立人类基准和比较ADS与人类驾驶员的响应性能。例如，测量（人类驾驶员或ADS的）冲突响应时间需要确定刺激起始点和响应起始点。在现有研究中，响应起始点依赖于手动标注或车辆控制信号，如加速器和刹车踏板运动。当分析大规模数据而车辆控制信号不可用时，这些方法不适用。这尤其适用于快速扩展的ADS日志数据，其中通过车载传感器观察周围道路使用者的行为。为了推进ADS的评估技术，并在车辆控制信号不可用时测量响应时间，我们开发了一种基于分段线性加速度模型的简单高效算法，用于自动估计刹车起始点，可应用于包含车辆纵向时间序列数据的任何类型驾驶数据。我们还提出了一种人工标注方法来识别刹车起始点，并将其用作验证的真实值。R^2被用作衡量算法准确性的置信度指标，并使用ADS和人类的自然碰撞避免数据分析其分类性能，我们的方法通过人类手动标注进行了验证。尽管我们的算法受到某些限制，但它高效、可泛化、适用于任何道路使用者和场景类型，并且高度可配置。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [745] [Using Tactile Charts to Support Comprehension and Learning of Complex Visualizations for Blind and Low-Vision Individuals](https://arxiv.org/abs/2507.21462)
> *使用触觉图表支持盲人和低视力个体理解和学习复杂可视化*

*Tingying He, Maggie McCracken, Daniel Hajas, Sarah Creem-Regehr, Alexander Lex* | **Category: cs.HC** | **Updated: 2025-07-29**

**Keywords:** 触觉图表, 盲人低视力, 复杂可视化, 心理模型, 3D打印

**Comment:** 

> **TL;DR:** 本研究调查了触觉图表是否能帮助盲人和低视力（BLV）个体理解和学习复杂可视化，并发现触觉模型支持图表类型理解，是BLV个体首选的学习方法。

**AI_Comments:** 这项研究的创新之处在于其专注于为盲人和低视力个体提供复杂可视化的触觉支持，而不仅仅是简单图表。通过3D打印技术制作触觉模板，并结合用户访谈，验证了触觉模型在帮助BLV个体建立心理模型和理解复杂数据方面的有效性。其重要性在于为信息无障碍和包容性教育提供了切实可行的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 可视化是传达数据的强大工具，但盲人和低视力（BLV）个体通常只能依靠辅助技术（主要是替代文本）来获取信息。现有研究表明心理模型对于解释这些描述很重要，但BLV个体无法通过可视化图像建立这样的心理模型。关于触觉数据表示的研究大多集中在简单图表类型，对于更复杂的图表是否适用尚不清楚，这促使研究填补这一空白。

**Method:** 研究人员与两名BLV研究员合作，设计了带有探索说明的3D打印触觉模板图表，用于四种高级图表类型：UpSet图、小提琴图、聚类热图和分面折线图。随后，对12名BLV参与者进行了访谈研究，比较使用触觉模板是否能改善图表的心理模型和理解，以及这种理解是否能转化为通过替代文本体验新数据集的能力。数据通过主题分析进行。

**Result:** 主题分析表明，触觉模型支持图表类型理解，并且是BLV个体首选的学习方法。研究还报告了参与者对触觉图表设计及其在BLV教育中作用的看法。

**Conclusion:** 触觉图表能够有效支持盲人和低视力个体理解和学习复杂可视化，并且是他们首选的学习方式，这表明触觉图表在BLV教育中具有重要作用。

> **ai_Abstract:** 本研究旨在探究触觉图表对盲人和低视力（BLV）个体理解和学习复杂可视化的支持作用。研究团队设计了四种高级图表类型的3D打印触觉模板，并对12名BLV参与者进行了访谈研究。结果表明，触觉模型有助于BLV个体理解图表类型，并成为他们首选的学习方法。该研究为BLV教育中触觉图表的应用和设计提供了宝贵见解。

> **摘要翻译:** 我们研究了触觉图表是否支持盲人和低视力（BLV）个体理解和学习复杂可视化，并贡献了四种触觉图表设计和一项访谈研究。可视化是传达数据的强大工具，但BLV个体通常只能依靠辅助技术——主要是替代文本——来获取这些信息。先前的研究表明，图表类型的心理模型对于解释这些描述很重要，但BLV个体无法通过可视化图像建立这样的心理模型。触觉图表有望填补这一空白，支持建立心理模型的过程。然而，关于触觉数据表示的研究大多集中在简单图表类型，对于更复杂的图表是否也适用，如科学出版物中常见的图表，尚不清楚。我们与两名BLV研究员合作，设计了带有探索说明的3D打印触觉模板图表，用于四种高级图表类型：UpSet图、小提琴图、聚类热图和分面折线图。随后，我们对12名BLV参与者进行了一项访谈研究，比较使用我们的触觉模板是否能改善图表的心理模型和理解，以及这种理解是否能转化为通过替代文本体验新数据集的能力。主题分析表明，触觉模型支持图表类型理解，并且是BLV个体首选的学习方法。我们还报告了参与者对触觉图表设计及其在BLV教育中作用的看法。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [764] [Decoding Instructional Dialogue: Human-AI Collaborative Analysis of Teacher Use of AI Tool at Scale](https://arxiv.org/abs/2507.17985)
> *解码教学对话：大规模人机协作分析教师人工智能工具使用情况*

*Alex Liu, Lief Esbenshade, Shawon Sarkar, Victor Tian, Zachary Zhang, Kevin He, Min Sun* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 人机协作, 定性分析, 教师AI使用, 大型语言模型, 教育技术

**Comment:** 

> **TL;DR:** 本研究提出了一种人机协作方法，对K-12教师使用的生成式AI平台中超过14万条师生-AI消息进行了大规模定性分析，发现大型语言模型能有效支持主题识别，并揭示了教师使用AI进行教学实践、内容创建、评估反馈、个性化教学和专业职责的模式。

**AI_Comments:** 该论文的创新之处在于其提出的大规模人机协作定性分析方法，有效结合了人类洞察力与AI的效率，解决了传统定性研究难以扩展的问题。其重要性体现在为理解教师在教育实践中如何利用AI提供了量化和模式化的证据，对教师培训和专业发展具有直接指导意义。此外，它也为AI在社会科学研究中的应用开辟了新的路径。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在教育工具中的整合潜力巨大，但目前对于教育工作者如何在实践中使用这些工具以及如何大规模有效地研究他们与AI的互动知之甚少。

**Method:** 本研究采用了一种人机协作方法，对来自K-12教师使用的生成式AI平台的超过14万条师生-AI消息进行了大规模定性分析。通过一个四阶段的编码流程，结合了归纳主题发现、代码本开发、结构化标注和模型基准测试，以检查教育者参与模式并评估LLM在定性编码任务中的表现。开发了一个与既定教师评估框架对齐的分层代码本。

**Result:** 研究发现，LLMs，特别是Claude 3.5 Haiku，能够可靠地支持主题识别，在复杂场景中扩展人类识别能力，并在准确性和结构可靠性方面优于开源模型。分析还揭示了教育者如何向AI查询以增强教学实践（79.7%）、创建或改编内容（76.1%）、支持评估和反馈循环（46.9%）、关注学生个性化需求（43.3%）以及协助其他专业职责（34.2%）的实质性模式。

**Conclusion:** 本研究为AI增强的定性研究提供了一个可扩展、透明的模型，并为生成式AI在教育实践中不断演变的角色提供了基础性见解。

> **ai_Abstract:** 本研究提出了一种创新的人机协作方法，旨在大规模分析K-12教师在实际教学中如何使用生成式AI工具。通过对超过14万条师生-AI对话进行四阶段编码，研究不仅验证了LLM（特别是Claude 3.5 Haiku）在定性编码任务中的可靠性和优越性，还揭示了教师利用AI进行教学实践、内容创建、评估反馈、个性化教学和专业职责的具体模式。这项工作为AI增强的定性研究提供了可扩展模型，并为AI在教育领域的应用提供了重要见解。

> **摘要翻译:** 大型语言模型（LLMs）整合到教育工具中，有可能极大地影响教师如何规划教学、支持不同学习者以及进行专业反思。然而，关于教育工作者在实践中如何实际使用这些工具，以及如何大规模地有意义地研究他们与AI的互动，我们知之甚少。本文提出了一种人机协作方法，对来自K-12教师使用的生成式AI平台的超过14万条师生-AI消息进行了大规模定性分析。通过一个四阶段的编码流程，我们结合了归纳主题发现、代码本开发、结构化标注和模型基准测试，以检查教育者参与模式并评估LLM在定性编码任务中的表现。我们开发了一个与既定教师评估框架对齐的分层代码本，捕捉了教育者的教学目标、情境需求和教学策略。我们的研究结果表明，LLMs，特别是Claude 3.5 Haiku，能够可靠地支持主题识别，在复杂场景中扩展人类识别能力，并在准确性和结构可靠性方面优于开源模型。分析还揭示了教育者如何向AI查询以增强教学实践（占总对话的79.7%）、创建或改编内容（76.1%）、支持评估和反馈循环（46.9%）、关注学生个性化教学需求（43.3%）以及协助其他专业职责（34.2%）的实质性模式，突出了新兴的AI相关能力，这些能力对教师培养和专业发展具有直接影响。这项研究为AI增强的定性研究提供了一个可扩展、透明的模型，并为生成式AI在教育实践中不断演变的角色提供了基础性见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [815] [Conversations over Clicks: Impact of Chatbots on Information Search in Interdisciplinary Learning](https://arxiv.org/abs/2507.21490)
> *对话而非点击：聊天机器人在跨学科学习中信息搜索的影响*

*Hannah Kim, Sergei L. Kosakovsky Pond, Stephen MacNeil* | **Category: cs.HC, cs.CY, cs.IR, J.3; K.3.2** | **Updated: 2025-07-29**

**Keywords:** 生成式AI, 聊天机器人, 信息搜索, 跨学科学习, 电子学习

**Comment:** 9 pages, 2 tables, 3 figures, 2025 ASEE/IEEE Frontiers in Education
  (FIE) Conference preprint

> **TL;DR:** 研究生成式AI聊天机器人对跨学科学习者信息搜索行为的影响，发现其在有学习计划后有益，但传统信息线索效果不佳，需谨慎使用。

**AI_Comments:** 本文探讨了生成式AI在跨学科学习中信息搜索的复杂影响，具有重要的实践意义。其创新之处在于采用自我民族志方法深入分析用户与GenAI的互动，并揭示了GenAI在不同学习阶段和信息呈现方式下的不同效果。研究结果警示了在电子学习中盲目引入GenAI的风险，强调了先验知识在信息识别中的关键作用，为未来GenAI在教育领域的应用提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在探讨生成式AI（GenAI）对学习者体验的影响，特别是学习者如何与GenAI提供的信息互动并利用这些信息。研究背景是电子学习环境中信息导航的复杂性，尤其是在生物信息学等跨学科领域，由于学习者先验知识和背景各异，挑战更大。

**Method:** 采用自我民族志方法（autoethnographic approach）来研究GenAI如何影响生物信息学研究中的信息搜索，具体关注聊天机器人互动如何影响学习者定向行为以及学习者如何识别GenAI响应中的信息线索。

**Result:** 1. 一旦学习计划建立，GenAI支持学习者定向，但在计划建立之前则适得其反。
2. 传统的价值丰富信息源（如项目符号和相关术语）在应用于GenAI响应时效果不佳。
3. 信息线索主要通过领域先验知识的存在与否来识别。

**Conclusion:** 研究结果表明，在电子学习环境，特别是在跨学科学习背景下，应谨慎采用生成式AI。

> **ai_Abstract:** 本研究通过自我民族志方法，探讨了生成式AI（GenAI）聊天机器人在生物信息学等跨学科电子学习环境中对学习者信息搜索行为的影响。研究发现，GenAI在学习计划建立后有助于定向，但在计划建立前可能适得其反。同时，传统的信息提示（如项目符号）在GenAI响应中效果不佳，而信息线索的识别主要依赖于学习者的先验知识。论文建议在跨学科电子学习中谨慎引入GenAI。

> **摘要翻译:** 这篇完整的学术论文探讨了生成式人工智能（GenAI）对学习者体验的影响，重点关注学习者如何参与并利用其提供的信息。在电子学习环境中，学习者通常需要独立地导航复杂的 информационное пространство。在生物信息学等跨学科领域，由于先验知识和背景的多样性，这一挑战变得更加复杂。在本文中，我们研究了GenAI如何影响生物信息学研究中的信息搜索：(1) 与GenAI聊天机器人的互动如何影响学习者的定向行为？(2) 学习者如何识别GenAI聊天机器人响应中的信息线索？我们采用自我民族志方法来研究这些问题。研究发现，一旦学习计划建立，GenAI支持定向，但在那之前则适得其反。此外，传统上富有价值的信息源，如项目符号和相关术语，在应用于GenAI响应时效果较差。信息线索主要通过领域先验知识的存在或缺失来识别。这些发现表明，在电子学习环境中，特别是在跨学科学习背景下，应谨慎采用GenAI。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [823] [RISEE: A Highly Interactive Naturalistic Driving Trajectories Dataset with Human Subjective Risk Perception and Eye-tracking Information](https://arxiv.org/abs/2507.19490)
> *RISEE：一个包含人类主观风险感知和眼动信息的高度交互式自然驾驶轨迹数据集*

*Xinzheng Wu, Junyi Chen, Peiyi Wang, Shunxiang Chen, Haolan Meng, Yong Shen* | **Category: cs.HC, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 自然驾驶数据集, 主观风险感知, 眼动追踪, 自动驾驶, 人因

**Comment:** Preprint accepted by ITSC 2025

> **TL;DR:** RISEE是一个新数据集，结合了无人机和模拟数据，包含人类主观风险感知和眼动数据，用于自动驾驶系统的人因研究，解决了现有数据集缺乏人因信息和安全关键场景的问题。

**AI_Comments:** RISEE数据集的创新之处在于其整合了人类主观风险感知和眼动信息，这对于自动驾驶系统理解人类行为和提高决策质量至关重要。结合无人机和模拟数据采集的混合方法提高了数据的真实性和安全性。该数据集的发布将极大地推动自动驾驶领域的人因研究。

<details>
  <summary>Details</summary>

**Motivation:** 在自动驾驶决策和规划系统的研发和验证阶段，需要整合人类因素以实现符合人类认知的决策和评估。然而，大多数现有数据集主要关注车辆运动状态和轨迹，忽视了人类相关信息。此外，当前的自然驾驶数据集缺乏足够多的安全关键场景，而模拟数据集则真实性较低。

**Method:** 本文构建了风险知情主观评估和眼动追踪（RISEE）数据集，其中除了常规的自然驾驶轨迹外，还专门包含了人类主观评估和眼动追踪数据。通过利用无人机（高真实性和广泛场景覆盖）和模拟（高安全性和可复现性）数据采集方法的互补优势，首先在高速公路匝道汇入区进行无人机交通视频录制。之后，在模拟软件中重建手动选择的高度交互场景，并生成驾驶员第一视角（FPV）视频，然后由招募的参与者观看和评估。在视频观看过程中，收集参与者的眼动追踪数据。经过数据处理和筛选。

**Result:** 经过数据处理和筛选，保留了来自101名参与者在179个场景中的3567个有效主观风险评分，以及2045个合格的眼动追踪数据段。收集的数据和生成的FPV视频示例可在其网站上获取。

**Conclusion:** 该论文成功构建了RISEE数据集，通过整合人类主观风险感知和眼动信息，弥补了现有自动驾驶数据集在人因信息和安全关键场景方面的不足，为自动驾驶系统的决策和评估提供了更符合人类认知的数据基础。

> **ai_Abstract:** RISEE数据集旨在弥补现有自动驾驶数据集中人类因素信息和安全关键场景的不足。该数据集结合无人机和模拟方法，收集了自然驾驶轨迹、人类主观风险评估和眼动数据。它通过在模拟环境中重建高度交互场景，并让参与者观看第一视角视频并提供风险评估和眼动数据来构建。最终，数据集包含了大量有效的风险评分和眼动数据，为自动驾驶系统的人因集成提供了宝贵资源。

> **摘要翻译:** 在自动驾驶决策和规划系统的研究与开发（R&D）以及验证与确认（V&V）阶段，有必要整合人类因素以实现符合人类认知的决策和评估。然而，大多数现有数据集主要关注车辆运动状态和轨迹，而忽视了与人类相关的信息。此外，当前的自然驾驶数据集缺乏足够的安全关键场景，而模拟数据集则存在真实性低的问题。为了解决这些问题，本文构建了风险知情主观评估和眼动追踪（RISEE）数据集，该数据集除了常规的自然驾驶轨迹外，还专门包含了人类主观评估和眼动追踪数据。通过利用基于无人机（高真实性和广泛场景覆盖）和基于模拟（高安全性和可复现性）数据采集方法的互补优势，我们首先在高速公路匝道汇入区进行了基于无人机的交通视频录制。之后，将手动选择的高度交互场景在模拟软件中重建，并生成驾驶员第一视角（FPV）视频，然后由招募的参与者观看和评估。在视频观看过程中，收集参与者的眼动追踪数据。经过数据处理和筛选，保留了来自101名参与者在179个场景中的3567个有效主观风险评分，以及2045个合格的眼动追踪数据段。收集的数据和生成的FPV视频示例可在我们的网站上获取。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [842] [Enhancing Manufacturing Training Through VR Simulations](https://arxiv.org/abs/2507.21070)
> *通过VR模拟增强制造培训*

*Vladislav Li, Ilias Siniosoglou, Panagiotis Sarigiannidis, Vasileios Argyriou* | **Category: cs.HC** | **Updated: 2025-06-06**

**Keywords:** VR模拟, 制造培训, 工业培训, 虚拟现实, 培训效率

**Comment:** 

> **TL;DR:** 本文提出了一种先进的基于VR的工业培训架构，通过高保真模拟、动态场景和自适应反馈系统，显著提高了信息保留、任务执行精度和整体培训效率，证明VR是工业培训中传统方法的有效替代品。

**AI_Comments:** 这篇论文创新性地将VR技术应用于工业制造培训，通过构建高保真、动态且带有自适应反馈的模拟环境，有效解决了传统培训中理论与实践脱节、安全性不足等痛点。提出的VRTSS评分机制也为VR培训效果的量化评估提供了新的思路。其重要性在于为企业提供了更安全、高效且可扩展的员工技能培训方案，尤其适用于复杂且高风险的工业操作。

<details>
  <summary>Details</summary>

**Motivation:** 在当代工业制造培训中，理论知识与实践经验的结合仍然是一个重大难题。随着公司向更复杂、技术导向的环境转型，传统培训方法在确保安全和效率的同时，常常无法充分培养工人必要的实践技能。

**Method:** 本文提出了一种先进的基于VR的工业培训架构，旨在通过高保真模拟、动态和情境敏感的场景以及自适应反馈系统来提高学习效率。该系统包含直观的基于手势的控制，并使用新的评分指标——VR培训场景得分（VRTSS）来动态评估学员表现。

**Result:** 该系统的实验评估显示出有前景的结果，在信息保留、任务执行精度和整体培训效率方面有显著提升。

**Conclusion:** 结果强调了VR作为工业培训中一个关键工具的能力，为传统学习方法提供了一个可扩展、交互式且高效的替代方案。

> **ai_Abstract:** 本文提出了一种先进的基于VR的工业培训架构，旨在解决传统培训方法在复杂制造环境中理论与实践脱节的问题。该系统通过高保真模拟、动态场景、自适应反馈和直观的手势控制，提供沉浸式、无风险的学习体验，并引入VR培训场景得分（VRTSS）动态评估学员表现。实验结果表明，该系统显著提升了信息保留、任务执行精度和整体培训效率，证明了VR在工业培训中作为传统方法的可扩展、交互式和高效替代方案的潜力。

> **摘要翻译:** 在当代工业制造培训中，理论知识与实践经验的结合仍然是一个重大难题。随着公司向更复杂、技术导向的环境转型，传统培训方法在确保安全和效率的同时，常常无法充分培养工人必要的实践技能。虚拟现实（VR）已成为解决这一问题的变革性工具，它提供沉浸式、互动式和无风险的教学体验。通过模拟真实的工业环境，VR促进了学员在受控且刺激的环境中获取重要技能，从而减轻了在工作场所进行体验式学习相关的风险。本文提出了一种先进的基于VR的工业培训架构，旨在通过高保真模拟、动态和情境敏感的场景以及自适应反馈系统来提高学习效率。所建议的系统包含直观的基于手势的控制，从而降低了所有技能水平用户的学习曲线。一种新的评分指标，即VR培训场景得分（VRTSS），用于动态评估学员表现，确保持续的参与和激励。该系统的实验评估显示出有前景的结果，在信息保留、任务执行精度和整体培训效率方面有显著提升。结果强调了VR作为工业培训中一个关键工具的能力，为传统学习方法提供了一个可扩展、交互式且高效的替代方案。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [877] [FingerTip 20K: A Benchmark for Proactive and Personalized Mobile LLM Agents](https://arxiv.org/abs/2507.21071)
> *FingerTip 20K：一个用于主动和个性化移动LLM代理的基准*

*Qinglong Yang, Haoming Li, Haotian Zhao, Xiaokai Yan, Jingtao Ding, Fengli Xu, Yong Li* | **Category: cs.HC, cs.AI** | **Updated: 2025-06-09**

**Keywords:** 移动GUI代理, LLM, 基准, 主动, 个性化

**Comment:** 

> **TL;DR:** 该论文引入了FingerTip基准，旨在解决当前移动GUI代理在主动意图预测和个性化用户偏好方面的局限性，通过收集真实的安卓设备交互数据，推动构建更以用户为导向的代理。

**AI_Comments:** 该论文的创新之处在于提出了一个全新的基准FingerTip，专门针对当前移动GUI代理在主动性（意图预测）和个性化方面的局限性。通过收集真实的、连续的用户交互数据，并包含丰富的上下文信息，该工作为开发更智能、更贴合用户习惯的移动代理提供了宝贵的数据集和评估框架。其重要性体现在推动了移动LLM代理从被动执行向主动服务和个性化体验的转变。

<details>
  <summary>Details</summary>

**Motivation:** 当前的移动GUI代理仅限于遵循明确的人类指令，导致缺乏主动意图预测能力。此外，这些代理在任务执行过程中未能利用与用户相关的上下文信息，从而忽略了用户偏好中可能存在的巨大差异。

**Method:** 我们引入了FingerTip基准，包含两个新赛道：通过分析环境观察和用户过往意图提供主动任务建议，以及通过满足用户操作偏好实现个性化任务执行。我们收集了各种日常应用中多步安卓设备交互的独特人类演示数据。这些演示不是孤立的，而是从用户在真实生活中的长期使用中持续获取的，并包含重要的用户相关上下文信息。

**Result:** 我们的实验揭示了我们提出的任务的挑战性。使用我们收集的数据进行微调的模型有效利用了用户信息并取得了良好结果，突显了我们方法在构建更以用户为导向的移动GUI代理方面的潜力。

**Conclusion:** 通过我们收集的数据进行微调的模型有效利用了用户信息并取得了良好结果，这突出表明了我们方法在构建更以用户为导向的移动GUI代理方面的巨大潜力。

> **ai_Abstract:** 本论文介绍了FingerTip基准，旨在解决现有移动GUI代理在主动意图预测和个性化用户偏好方面的不足。该基准包含主动任务建议和个性化任务执行两个赛道，并收集了来自用户真实生活的、包含上下文信息的安卓设备多步交互演示数据。实验结果表明，该方法能够有效利用用户信息并取得良好效果，为构建更以用户为导向的移动GUI代理提供了潜力。

> **摘要翻译:** 移动GUI代理正成为提高人机交互效率的关键工具，其中多模态大型语言模型（MLLMs）正成为该领域的主导范式。然而，当前的代理仅限于遵循明确的人类指令，导致主动意图预测能力不足。此外，这些代理在任务执行过程中未能利用与用户相关的上下文信息，从而忽略了用户偏好中可能存在的巨大差异。为了解决这些挑战，我们引入了FingerTip基准。它包含两个新赛道：通过分析环境观察和用户过往意图提供主动任务建议，以及通过满足用户操作偏好实现个性化任务执行。我们收集了各种日常应用中多步安卓设备交互的独特人类演示数据。这些演示不是孤立的，而是从用户在真实生活中的长期使用中持续获取的，并包含重要的用户相关上下文信息。我们的实验揭示了我们提出的任务的挑战性。使用我们收集的数据进行微调的模型有效利用了用户信息并取得了良好结果，突显了我们方法在构建更以用户为导向的移动GUI代理方面的潜力。我们的代码已在https://anonymous.4open.science/r/FingerTip-57B8 开源，以供复现。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [879] [CineVision: An Interactive Pre-visualization Storyboard System for Director-Cinematographer Collaboration](https://arxiv.org/abs/2507.20355)
> *CineVision：一个用于导演与摄影师协作的交互式预可视化故事板系统*

*Zheng Wei, Hongtao Wu, lvmin Zhang, Xian Xu, Yefeng Zheng, Pan Hui, Maneesh Agrawala, Huamin Qu, Anyi Rao* | **Category: cs.HC** | **Updated: 2025-07-29**

**Keywords:** 预可视化, 故事板, 导演-摄影师协作, AI平台, 电影前期制作

**Comment:** UIST 2025

> **TL;DR:** CineVision是一个AI驱动的交互式预可视化故事板系统，旨在改善导演和摄影师之间的沟通与协作。它通过实时视觉预可视化、动态灯光控制和风格模拟，帮助团队更高效地传达创意愿景。一项研究表明，CineVision能缩短任务时间并提高可用性。

**AI_Comments:** 该创新在于利用AI进行实时视觉预可视化，整合剧本创作，并提供风格模拟等高级功能，直接解决了传统故事板效率低下的问题。它在简化工作流程和改善协作方面的潜力巨大，特别是对于新团队而言。

<details>
  <summary>Details</summary>

**Motivation:** 电影制作中导演和摄影师之间的有效沟通至关重要，但传统的视觉参考和手绘故事板方法在前期制作中往往缺乏必要的效率和精确性。

**Method:** 本文提出了CineVision，一个AI驱动的平台，它将剧本创作与实时视觉预可视化相结合，以弥合沟通鸿沟。通过提供动态灯光控制、基于著名电影制作人的风格模拟以及可定制的角色设计，CineVision使导演能够更清晰地传达他们的创意愿景，并快速迭代场景构图。

**Result:** 在一项24名参与者的实验室研究中，CineVision比两种基线方法产生了更短的任务时间和更高的可用性评级，这表明在受控条件下，它有潜力简化早期沟通并加速故事板草稿的制作。

**Conclusion:** 这些发现强调了CineVision在简化前期制作流程和促进电影制作团队（特别是新合作者）之间更深层次的创意协同方面的潜力。

> **ai_Abstract:** CineVision是一个AI驱动的平台，旨在增强电影前期制作中导演和摄影师之间的沟通与协作。它将剧本创作与实时视觉预可视化相结合，提供动态灯光控制、风格模拟和可定制角色设计等功能。一项实验室研究表明，与传统方法相比，CineVision能缩短任务时间并提高可用性，这表明它有潜力简化前期制作流程并促进电影制作中的创意协同。

> **摘要翻译:** 导演和摄影师之间有效的沟通是电影制作的基础，然而，依赖视觉参考和手绘故事板的传统方法在前期制作中往往缺乏必要的效率和精确性。我们提出了CineVision，一个AI驱动的平台，它将剧本创作与实时视觉预可视化相结合，以弥合这一沟通鸿沟。通过提供动态灯光控制、基于著名电影制作人的风格模拟以及可定制的角色设计，CineVision使导演能够以更高的清晰度传达他们的创意愿景，并快速迭代场景构图。在一项24名参与者的实验室研究中，CineVision比两种基线方法产生了更短的任务时间和更高的可用性评级，这表明在受控条件下，它有潜力简化早期沟通并加速故事板草稿的制作。这些发现强调了CineVision在简化前期制作流程和促进电影制作团队（特别是新合作者）之间更深层次的创意协同方面的潜力。我们的代码和演示可在https://github.com/TonyHongtaoWu/CineVision 获取。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [885] [AI Literacy as a Key Driver of User Experience in AI-Powered Assessment: Insights from Socratic Mind](https://arxiv.org/abs/2507.21654)
> *人工智能素养作为人工智能驱动评估中用户体验的关键驱动因素：来自Socratic Mind的见解*

*Meryem Yilmaz Soylu, Jeonghyun Lee, Jui-Tse Hung, Christopher Zhang Cui, David A. Joyner* | **Category: cs.HC, cs.AI, K.3.1; I.2.6** | **Updated: 2025-07-29**

**Keywords:** 人工智能素养, 用户体验, AI评估, Socratic Mind, 学习有效性

**Comment:** 34 pages, 1 figure, 3 tables

> **TL;DR:** 研究发现，学生的人工智能素养（而非接触经验）显著影响他们对AI评估工具Socratic Mind的可用性、满意度和参与度，进而影响学习效果。建议AI工具设计应考虑不同素养水平。

**AI_Comments:** 这项研究创新性地指出，在使用AI辅助学习工具时，学生的人工智能素养（包括自我效能、概念理解和应用技能）比单纯的AI接触经验更能决定用户体验和学习效果。这对于AI教育工具的设计者具有重要的指导意义，提示他们应更加关注用户AI素养的培养和适应性支持，而非仅仅假设用户会因接触而自然适应。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能工具在高等教育中日益普及，理解学生如何与这些系统互动对于支持有效学习至关重要。本研究旨在探讨学生的人工智能素养和先前接触人工智能技术的经验如何影响他们对人工智能驱动的形成性评估工具Socratic Mind的看法。

**Method:** 本研究基于自我决定理论和用户体验研究，分析了人工智能素养、感知可用性、满意度、参与度以及感知学习有效性之间的关系。通过验证性调查问卷，收集了309名计算机科学和商科本科生数据。数据采用偏最小二乘结构方程模型进行分析。

**Result:** 研究结果显示，人工智能素养——特别是自我效能、概念理解和应用技能——显著预测了可用性、满意度和参与度。可用性和满意度反过来强烈预测了感知学习有效性。然而，先前的人工智能接触经验没有显示出显著影响。

**Conclusion:** 结论指出，人工智能素养而非单纯的接触经验塑造了学生的体验。因此，设计者应整合自适应指导和以用户为中心的功能，以支持不同素养水平，从而促进包容、激励和有效的人工智能学习环境。

> **ai_Abstract:** 本研究探讨了人工智能素养和先前AI接触经验对学生使用AI驱动评估工具Socratic Mind用户体验的影响。结果表明，人工智能素养（特别是自我效能、概念理解和应用技能）是影响可用性、满意度和参与度的关键因素，进而影响学习效果。而先前AI接触经验无显著影响。研究强调了AI素养在塑造学生AI工具体验中的重要性，并建议在AI学习环境设计中考虑支持不同素养水平。

> **摘要翻译:** 随着人工智能（AI）工具日益融入高等教育，了解学生如何与这些系统互动对于支持有效学习至关重要。本研究考察了学生的人工智能素养和先前接触AI技术的经验如何塑造他们对Socratic Mind（一个交互式AI驱动的形成性评估工具）的看法。我们借鉴自我决定理论和用户体验研究，分析了人工智能素养、感知可用性、满意度、参与度以及感知学习有效性之间的关系。通过验证性调查问卷，收集了309名计算机科学和商科本科生数据。偏最小二乘结构方程模型显示，人工智能素养——特别是自我效能、概念理解和应用技能——显著预测了可用性、满意度和参与度。可用性和满意度反过来强烈预测了感知学习有效性，而先前接触AI的经验没有显示出显著影响。这些发现强调，人工智能素养而非单纯的接触经验塑造了学生的体验。设计者应整合自适应指导和以用户为中心的功能，以支持不同素养水平，从而促进包容、激励和有效的人工智能学习环境。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [899] [Identification of Design Recommendations for Augmented Reality Authors in Corporate Training](https://arxiv.org/abs/2507.21722)
> *企业培训中增强现实作者的设计建议识别*

*Stefan Graser, Martin Schrepp, Stephan Böhm* | **Category: cs.HC, cs.SE** | **Updated: 2025-07-29**

**Keywords:** 增强现实, 设计建议, 企业培训, 用户中心设计, 自然语言处理

**Comment:** 9 pages, 1 table, 1 figure

> **TL;DR:** 本研究识别并分析了企业培训中增强现实（AR）相关的实用设计建议，通过扩展现有数据集、使用NLP分类并由专家评估，最终提供了597条设计建议的更新数据集，其中32个主题被认为与企业培训中的AR应用高度相关。

**AI_Comments:** 这项研究的创新之处在于其多方法途径，结合了NLP分类和专家定性评估，以系统地识别和验证特定于企业培训中AR应用的设计建议。其重要性在于为AR应用开发者和研究者提供了实用的、经过验证的指导，有助于提升企业培训中AR的用户体验和应用效果。通过提供分类和评估后的设计建议，它直接支持了AR应用在特定领域的优化和发展。

<details>
  <summary>Details</summary>

**Motivation:** 当前研究缺乏针对特定情境的增强现实（AR）设计建议，尤其是在用户中心设计（UCD）过程的评估阶段。本研究旨在弥补这一空白，识别和分析与企业培训中AR相关的实用设计建议。

**Method:** 采用多方法途径：1) 扩展现有混合现实（MR）设计建议数据集，纳入2020年以来发布的AR特定建议；2) 使用基于预训练Sentence Transformer模型的NLP分类方法对建议进行分类；3) 总结所有主题内容；4) 与五位专家通过定性轮流法（Round Robin）评估其在企业培训（CT）中AR应用的相关性。

**Result:** 构建了一个包含597条实践者设计建议的更新数据集，这些建议被分为84个主题，并提供了其在企业培训中AR应用背景下的新见解。其中，有32个主题（共284条陈述）被评估为与企业培训中的AR应用高度相关。

**Conclusion:** 本研究直接贡献于扩展作者的AR特定用户体验（UX）测量方法，支持AR作者改进企业培训场景中的AR应用。这有助于识别和分析企业培训中AR相关的实用设计建议。

> **ai_Abstract:** 本研究旨在弥补当前研究中缺乏针对企业培训特定情境的增强现实（AR）设计建议的空白。通过扩展现有混合现实设计建议数据集，并结合自然语言处理分类和专家评估，研究人员识别并分析了与用户中心设计评估阶段相关的实用AR设计建议。最终，本研究提供了一个包含597条实践者设计建议的更新数据集，其中32个主题被认为对企业培训中的AR应用具有高度相关性，从而支持AR作者改进企业培训场景中的AR应用程序。

> **摘要翻译:** 创新技术，如增强现实（AR），引入了新的交互范式，需要在软件开发过程中识别软件需求。通常，设计建议与此相关，积极支持应用程序设计并满足利益相关者的需求。然而，当前研究缺乏特定于上下文的AR设计建议。本研究通过识别和分析与用户中心设计（UCD）过程评估阶段相关的实用AR设计建议来弥补这一空白。我们依赖于现有的混合现实（MR）设计建议数据集。我们采用了多方法途径：(1) 扩展数据集，纳入2020年以来发布的AR特定建议；(2) 使用基于预训练Sentence Transformer模型的NLP分类方法对已识别的建议进行分类；(3) 总结所有主题的内容；(4) 通过与五位专家进行的定性轮流法评估其在企业培训（CT）中AR应用的相关性。结果是，提供了一个包含597条实践者设计建议的更新数据集，这些建议被分为84个主题，并提供了其在企业培训中AR应用背景下的新见解。在此基础上，共有32个主题，包含284条陈述，被评估为与企业培训中的AR应用高度相关。这项研究直接有助于作者扩展其AR特定用户体验（UX）测量方法，支持AR作者改进企业培训场景中的AR应用程序。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [918] [Snap, Segment, Deploy: A Visual Data and Detection Pipeline for Wearable Industrial Assistants](https://arxiv.org/abs/2507.21072)
> *即时捕捉、分割、部署：面向可穿戴工业助手的视觉数据与检测管线*

*Di Wen, Junwei Zheng, Ruiping Liu, Yi Xu, Kunyu Peng, Rainer Stiefelhagen* | **Category: cs.HC, cs.RO** | **Updated: 2025-06-09**

**Keywords:** 工业助手, 设备端AI, 目标检测, 检索增强生成, 可穿戴计算

**Comment:** 

> **TL;DR:** 该论文提出了一种基于移动设备的工业助手系统，通过设备端感知和RAG实现实时支持，解决了工厂环境中云计算受限的问题。

**AI_Comments:** 该论文的创新之处在于为工业辅助开发了一个完全在设备端运行、保护隐私的解决方案，有效应对了工厂环境中常见的资源限制。其将目标检测、语音识别和RAG集成到模块化管线中的方法值得关注。引入Gear8数据集和自动化数据构建管线以增强鲁棒性也是一项重要贡献。该研究的重要性在于，它使得智能辅助能够在传统云计算方案不可行的环境中得以实现。

<details>
  <summary>Details</summary>

**Motivation:** 工业装配任务需要快速适应复杂程序和多样化组件，但常在计算、连接受限且隐私要求严格的环境中进行，导致传统基于云或完全自主的解决方案不切实际。

**Method:** 本系统是一个基于移动设备的工业培训和操作支持助手系统，通过设备端感知和语音接口实现实时交互。它将轻量级目标检测、语音识别和检索增强生成（RAG）集成到一个模块化的设备端管线中，完全在设备上运行。为实现可扩展训练，采用了自动化数据构建管线和两阶段细化策略以提高视觉鲁棒性。

**Result:** 在自定义的Gear8数据集上进行的实验表明，系统对域偏移和常见视觉损坏的鲁棒性有所提高。结构化用户研究证实了其实用可行性，用户对指导的清晰度和交互质量给予了积极反馈。

**Conclusion:** 该框架为工业环境中的实时、保护隐私的智能辅助提供了一个可部署的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的基于移动设备的工业助手系统，专为资源有限且隐私要求严格的工厂环境设计。该系统集成了设备端感知（目标检测）、语音识别和RAG，形成一个完全在设备上运行的管线，为装配任务提供实时、半解放双手的支持。为确保可扩展性和鲁棒性，论文引入了自动化数据构建管线和两阶段细化策略。在自定义的Gear8数据集上的实验结果以及用户研究均证实了该系统的鲁棒性提升、实用可行性及积极的用户体验，展示了其作为可部署、保护隐私的智能辅助解决方案的潜力。

> **摘要翻译:** 工业装配任务日益要求快速适应复杂程序和多样化组件，但往往在计算、连接受限且隐私要求严格的环境中进行。这些限制使得传统的基于云或完全自主的解决方案不适用于工厂部署。本文介绍了一种基于移动设备的工业培训和操作支持助手系统，通过设备端感知和语音接口实现实时、半解放双手的交互。该系统将轻量级目标检测、语音识别和检索增强生成（RAG）集成到一个模块化的设备端管线中，完全在设备上运行，无需人工监督或云服务即可为零件处理和程序理解提供直观支持。为了实现可扩展的训练，我们采用了自动化数据构建管线，并引入了两阶段细化策略，以提高域偏移下的视觉鲁棒性。在我们生成的数据集（即Gear8）上的实验表明，其对域偏移和常见视觉损坏的鲁棒性有所提高。一项结构化用户研究进一步证实了其实用可行性，用户对指导的清晰度和交互质量给予了积极反馈。这些结果表明，我们的框架为工业环境中的实时、保护隐私的智能辅助提供了可部署的解决方案。我们将在接受后发布Gear8数据集和源代码。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [927] [Impact of eHMI on Pedestrians' Interactions with Level-5 Automated Driving Systems](https://arxiv.org/abs/2507.21303)
> *eHMI对行人与L5级自动驾驶系统交互的影响*

*Viktoria Marcus, Griffin Pitts, Sanaz Motamedi* | **Category: cs.HC, cs.CY, cs.ET** | **Updated: 2025-07-28**

**Keywords:** 外部人机界面, 自动驾驶系统, 行人交互, L5级自动驾驶, 交通安全

**Comment:** Accepted and to be presented at ASPIRE 2025 - the 69th International
  Annual Meeting of HFES

> **TL;DR:** 本研究通过在线调查发现，外部人机界面（eHMI）显著提升了行人在与L5级自动驾驶系统交互时的安全性、信任度和理解度，促使行人更早、更自信地过马路，并认为视觉eHMI比听觉更必要。

**AI_Comments:** 这篇论文的创新点在于实证研究了eHMI在L5级自动驾驶系统中对行人交互的具体影响，特别强调了其在提升行人安全感、信任度和理解方面的作用。研究通过在线调查提供的数据支持了eHMI的有效性，并对视觉和听觉eHMI的偏好进行了初步探索，为未来eHMI的设计提供了有价值的指导。然而，作为一项在线调查，其结果可能存在一定的局限性，例如缺乏真实世界交互的复杂性和细微差别。未来的研究可以考虑在真实或模拟环境中进行更深入的验证。

<details>
  <summary>Details</summary>

**Motivation:** 每年全球一半以上的交通事故死亡涉及弱势道路使用者，主要归因于人为错误。L5级自动驾驶系统有望减少导致行人事故的驾驶员错误，但其有效性取决于其他道路使用者的清晰度和可理解性。外部人机界面（eHMI）被提出以促进行人与ADS的沟通，但关于最佳eHMI功能的共识尚不明确。

**Method:** 本研究进行了一项在线调查，共有153名参与者对涉及L5级自动驾驶系统（有和没有eHMI）的过马路场景进行了回应。

**Result:** 结果显示，有eHMI时，行人过马路更早、更自信，并报告与L5级ADS交互时安全感、信任度和理解度显著提高。视觉eHMI功能（包括文本显示和外部车速表）被认为比听觉功能更必要，尽管听觉提示也获得了积极反馈。

**Conclusion:** 本研究表明，eHMI可以显著提高行人对L5级ADS意图的理解，增强感知安全性和信任度，从而促进更直观的行人与ADS交互。

> **ai_Abstract:** 本研究通过在线调查探讨了外部人机界面（eHMI）对行人与L5级自动驾驶系统（ADS）交互的影响。结果显示，eHMI显著提升了行人对ADS意图的理解、感知安全性和信任度，促使行人更早且更自信地过马路。研究还发现视觉eHMI功能（如文本显示和外部车速表）比听觉功能更受青睐，证明eHMI能有效促进行人与ADS的直观互动。

> **摘要翻译:** 每年，全球超过一半的交通事故死亡涉及弱势道路使用者（例如行人），这通常是由于人为错误造成的。L5级自动驾驶系统（ADS）可以减少导致行人事故的驾驶员错误，但其有效性取决于其他道路使用者的清晰度和可理解性。外部人机界面（eHMIs）已被提出以促进行人与ADS的沟通，尽管关于最佳eHMI功能的共识仍不明确。在一项在线调查中，153名参与者对涉及L5级ADS（有和没有eHMIs）的过马路场景进行了回应。结果显示，有eHMIs时，行人过马路更早、更自信，并报告与L5级ADS交互时安全感、信任度和理解度显著提高。视觉eHMI功能（包括文本显示和外部车速表）被认为比听觉功能更必要，尽管听觉提示也获得了积极反馈。这项研究表明，eHMIs可以显著提高行人对L5级ADS意图的理解，增强感知安全性和信任度，从而促进更直观的行人与ADS交互。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [295] [Implementing Large Quantum Boltzmann Machines as Generative AI Models for Dataset Balancing](https://arxiv.org/abs/2502.03086)
> *大型量子玻尔兹曼机作为生成式AI模型在数据集平衡中的应用*

*Salvatore Sinno, Markus Bertl, Arati Sahoo, Bhavika Bhalgamiya, Thomas Groß, Nicholas Chancellor* | **Category: cs.ET, cs.AI, cs.LG, cs.NE, quant-ph** | **Updated: 2025-07-29**

**Keywords:** 量子玻尔兹曼机, 数据集平衡, 生成式AI, 入侵检测系统, 量子机器学习

**Comment:** S. Sinno, M. Bertl, A. Sahoo, B. Bhalgamiya, T. Gro{\ss} and N.
  Chancellor, "Implementing Large Quantum Boltzmann Machines as Generative AI
  Models for Dataset Balancing," 2025 International Conference on Next
  Generation Information System Engineering (NGISE), Ghaziabad, Delhi (NCR),
  India, 2025, pp. 1-8, doi: 10.1109/NGISE64126.2025.11085158

> **TL;DR:** 本研究利用D-Wave量子硬件上的大型量子受限玻尔兹曼机（QRBMs）作为生成模型，解决了入侵检测系统中的数据集不平衡问题，并证明其在生成高质量合成样本和提高分类性能方面优于传统方法，同时展现出高效率和可扩展性。

**AI_Comments:** 本研究的创新之处在于将量子机器学习，特别是大型量子受限玻尔兹曼机，应用于实际的数据不平衡问题，并利用了D-Wave的量子硬件。其重要性体现在QRBMs在生成高质量合成数据方面超越了传统方法，并显著提高了分类性能，同时展现出极高的处理效率（毫秒级）。抽象中未提及本研究的具体局限性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探索将大型量子受限玻尔兹曼机（QRBMs）作为生成模型，在D-Wave的Pegasus量子硬件上实现，以解决入侵检测系统（IDS）中存在的数据集不平衡问题。

**Method:** 研究成功地在D-Wave的Pegasus量子硬件上嵌入了一个包含120个可见单元和120个隐藏单元的QRBM，克服了默认嵌入工具的限制。该QRBM合成了超过160万个攻击样本，从而实现了超过420万条记录的平衡数据集。随后，将QRBM与SMOTE和RandomOversampler等传统平衡方法进行了比较评估，并使用多种分类器验证了性能。

**Result:** QRBMs生成了更高质量的合成样本，与传统平衡方法相比，显著提高了各种分类器的检测率、精确率、召回率和F1分数。此外，QRBMs展现出卓越的可扩展性和效率，在数毫秒内完成了数据集平衡任务。

**Conclusion:** 本研究强调了量子机器学习（QML）和QRBMs作为下一代数据预处理工具的变革潜力，为现代信息系统中复杂的计算挑战提供了强大的解决方案。

> **ai_Abstract:** 本研究成功地在D-Wave的Pegasus量子硬件上实现了大型量子受限玻尔兹曼机（QRBMs），作为生成式AI模型来解决入侵检测系统中的数据集不平衡问题。该QRBM包含120个可见单元和120个隐藏单元，成功合成了超过160万个攻击样本，构建了一个超过420万条记录的平衡数据集。与传统平衡方法（如SMOTE）相比，QRBMs生成的合成样本质量更高，显著提升了检测率、精确率、召回率和F1分数。研究结果表明，QRBMs具有高效性（在数毫秒内完成任务）和可扩展性，凸显了其作为数据预处理中下一代工具的巨大潜力，能为复杂计算挑战提供强大解决方案。

> **摘要翻译:** 本研究探讨了在D-Wave的Pegasus量子硬件上实现大型量子受限玻尔兹曼机（QRBMs）作为生成模型，以解决入侵检测系统（IDS）中的数据集不平衡问题。QRBMs是量子机器学习（QML）的关键进展。通过利用Pegasus增强的连接性和计算能力，成功嵌入了一个拥有120个可见单元和120个隐藏单元的QRBM，超越了默认嵌入工具的限制。该QRBM合成了超过160万个攻击样本，实现了超过420万条记录的平衡数据集。与SMOTE和RandomOversampler等传统平衡方法的比较评估显示，QRBMs产生了更高质量的合成样本，显著提高了各种分类器的检测率、精确率、召回率和F1分数。本研究强调了QRBMs的可扩展性和效率，在数毫秒内完成了平衡任务。这些发现凸显了QML和QRBMs作为数据预处理中下一代工具的变革潜力，为现代信息系统中的复杂计算挑战提供了强大的解决方案。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [29] [LLM4VV: Evaluating Cutting-Edge LLMs for Generation and Evaluation of Directive-Based Parallel Programming Model Compiler Tests](https://arxiv.org/abs/2507.21447)
> *LLM4VV：评估前沿大型语言模型在基于指令的并行编程模型编译器测试生成和评估中的应用*

*Zachariah Sollenberger, Rahul Patel, Saieda Ali Zada, Sunita Chandrasekaran* | **Category: cs.SE, cs.ET** | **Updated: 2025-07-29**

**Keywords:** LLMs, 编译器测试, 测试生成, 双LLM系统, 自动验证

**Comment:** 

> **TL;DR:** 本研究提出一个双LLM系统，用于自动生成和验证编译器测试，并证明LLMs在生成高质量编译器测试方面的潜力。

**AI_Comments:** 这项研究的创新之处在于提出了一个双LLM系统来解决LLM生成代码的验证和信任问题，特别是针对编译器测试的生成和评估，这在自动化测试领域具有重要意义。它为提高LLM在软件开发生命周期中的应用可靠性提供了新的视角和解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在软件和测试开发中的应用日益增多，但LLM生成代码的正确性验证仍缺乏全面自主的解决方案，且幻觉问题和缺乏逻辑推理可解释性导致对其结果的信任问题。

**Method:** 本论文提出了一个双LLM系统（包括一个生成式LLM和一个判别式LLM），并实验使用LLMs生成大量编译器测试。实验中使用了参数量不同的LLMs，并采用十个精心选择的指标来展示结果。

**Result:** 研究结果表明，大型语言模型具备生成高质量编译器测试并自动验证它们的巨大潜力。

**Conclusion:** 大型语言模型具备生成高质量编译器测试并自动验证它们的巨大潜力。

> **ai_Abstract:** 本研究旨在解决大型语言模型（LLMs）在软件和测试开发中生成代码的正确性验证难题及其幻觉问题。为此，论文提出了一个创新的双LLM系统，由一个生成式LLM和一个判别式LLM组成，用于自动生成和评估基于指令的并行编程模型编译器测试。通过对不同参数量LLMs的实验和十项指标的评估，研究结果表明LLMs在自动生成和验证高质量编译器测试方面具有显著潜力。

> **摘要翻译:** 大型语言模型（LLMs）在软件和测试开发中的应用自LLMs首次引入以来持续增长，但直到最近，人们对LLMs的期望才变得更加现实。验证LLM生成的代码的正确性是提高其有用性的关键，但目前尚未开发出全面且完全自主的解决方案。当LLMs在未花费时间和精力验证其输出的情况下盲目应用于问题时，幻觉是一个主要问题，并且LLMs无法解释逻辑推理导致对其结果的信任问题。为了解决这些挑战，同时旨在有效应用LLMs，本文提出了一个双LLM系统（即一个生成式LLM和一个判别式LLM），并实验使用LLMs生成大量编译器测试。我们实验了多种参数数量不同的LLMs，并使用我们在叙述中详细描述的十个精心选择的指标展示了结果。通过我们的发现，显而易见，LLMs具备生成高质量编译器测试并自动验证它们的巨大潜力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [134] [Generating Highly Structured Test Inputs Leveraging Constraint-Guided Graph Refinement](https://arxiv.org/abs/2507.21271)
> *生成利用约束引导图细化的高度结构化测试输入*

*Zhaorui Yang, Yuxin Qiu, Haichao Zhu, Qian Zhang* | **Category: cs.SE, K.6.3** | **Updated: 2025-07-28**

**Keywords:** 结构化数据, 测试输入生成, 基于图, 约束引导, 模糊测试

**Comment:** ICSME 2025 Registered Reports

> **TL;DR:** 针对AI应用中高度结构化数据的测试输入生成效率低下且常产生无效输入的问题，本文提出了GRAphRef，一个基于图的框架。它利用约束引导的变异和细化，生成有效的结构化测试输入。

**AI_Comments:** 该论文提出了一种创新的基于图的方法（GRAphRef），旨在解决AI领域中结构化数据测试输入生成长期存在的有效性和语义保留问题。其通过图表示统一结构化领域并利用约束引导细化的方法，是朝着更通用、更高效的测试迈出的重要一步，超越了传统的手工定制解决方案。明确提及将在多个真实世界系统上进行评估并与强基线进行比较，表明了其严谨的实证研究计划。

<details>
  <summary>Details</summary>

**Motivation:** 现代AI应用处理高度结构化数据（如3D网格和点云），但现有测试输入生成工具通常是手工制作的，效率低下，并经常生成无效输入，导致泛化能力差。因此，需要一种能够统一结构化领域并强制执行结构约束的通用、可重用的变异策略。

**Method:** 本文开发并评估了GRAphRef，一个基于图的测试输入生成框架，支持基于约束的变异和细化。GRAphRef将结构化输入映射到图，应用邻居相似性引导的变异，并使用约束细化阶段修复无效输入。该方法将在八个真实世界的网格处理AI系统上进行验证性研究，并与AFL、MeshAttack、Saffron以及两种消融变体进行比较。评估指标包括结构有效性、语义保留（通过预测一致性）和性能开销。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文旨在解决AI应用中高度结构化数据测试输入生成效率低下和无效的问题。它提出了一种名为GRAphRef的创新性基于图的框架，通过将结构化输入映射到图，并利用邻居相似性引导的变异和约束细化阶段来修复无效输入，从而实现通用且可重用的输入生成策略。GRAphRef旨在确保生成的测试输入同时具有结构和语义的有效性。该框架计划在多个真实世界的网格处理AI系统上进行评估，并与现有工具进行比较，以验证其在提升输入有效性、语义保留和性能方面的效果。

> **摘要翻译:** [背景] 现代AI应用越来越多地处理高度结构化数据，例如3D网格和点云，其中测试输入生成必须同时保持结构和语义的有效性。然而，现有的模糊测试工具和输入生成器通常是为特定输入类型手工制作的，并且经常生成随后被丢弃的无效输入，导致效率低下和泛化能力差。[目标] 本研究旨在探讨结构化领域的测试输入是否可以通过基于图的表示进行统一，从而实现通用、可重用的变异策略，同时强制执行结构约束。我们将评估这种方法在八个AI系统中增强输入有效性和语义保留的有效性。[方法] 我们开发并评估了GRAphRef，一个支持基于约束的变异和细化的基于图的测试输入生成框架。GRAphRef将结构化输入映射到图，应用邻居相似性引导的变异，并使用约束细化阶段修复无效输入。我们将在八个真实世界的网格处理AI系统上进行一项验证性研究，将GRAphRef与AFL、MeshAttack、Saffron以及两种消融变体进行比较。评估指标包括结构有效性、语义保留（通过预测一致性）和性能开销。实验数据来源于ShapeNetCore网格种子以及MeshCNN和HodgeNet等系统的模型输出。将使用统计分析和组件延迟分解来评估每个假设。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [190] ["Maybe We Need Some More Examples:" Individual and Team Drivers of Developer GenAI Tool Use](https://arxiv.org/abs/2507.21280)
> *“也许我们需要更多例子：”开发者生成式AI工具使用的个体和团队驱动因素*

*Courtney Miller, Rudrajit Choudhuri, Mara Ulloa, Sankeerti Haniyur, Robert DeLine, Margaret-Anne Storey, Emerson Murphy-Hill, Christian Bird, Jenna L. Butler* | **Category: cs.SE** | **Updated: 2025-07-28**

**Keywords:** 生成式AI工具, 开发者采纳, 生产力压力悖论, 个体驱动因素, 团队驱动因素

**Comment:** 

> **TL;DR:** 开发者对生成式AI工具的使用不均衡，主要受其对工具的看法、参与方式和应对挑战时的反应影响，组织对快速生产力提升的期望若无足够学习支持，会导致“生产力压力悖论”。

**AI_Comments:** 该研究通过定性访谈深入探讨了开发者采纳生成式AI工具的个体和团队驱动因素，提出了“生产力压力悖论”这一重要概念，对组织如何有效推广AI工具提供了实践指导。其创新点在于从开发者视角分析了认知和行为模式对工具使用的影响。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成式AI工具在软件工程中广泛可用，但开发者的采纳率不均衡。这种不均衡阻碍了生产力提升，不符合管理层的期望，并给开发者的未来角色带来了不确定性。

**Method:** 通过对27个团队（每个团队一名频繁用户和一名不频繁用户）的54名开发者进行配对访谈。

**Result:** 开发者使用差异主要源于他们如何看待工具（协作工具 vs. 功能）、参与方式（实验性 vs. 保守型）以及遇到挑战时的反应（适应性坚持 vs. 快速放弃）。

**Conclusion:** 研究结果表明，组织对快速生产力提升的广泛期望，如果没有足够的学习支持，会产生“生产力压力悖论”，从而削弱了促使采纳的生产力效益。

> **ai_Abstract:** 本研究探讨了软件开发者对生成式AI工具采用不均衡的原因。通过对54名开发者的访谈，发现使用差异主要取决于开发者对工具的认知（协作工具或功能）、参与方法（实验性或保守型）以及面对挑战时的应对方式。研究提出，组织在缺乏足够学习支持的情况下追求快速生产力提升，可能导致“生产力压力悖论”，反而损害了预期效益。

> **摘要翻译:** 尽管生成式AI工具在软件工程中广泛可用，但开发者的采纳率仍然不均衡。这种不均衡是有问题的，因为它阻碍了生产力提升，不符合管理层的期望，并给开发者的未来角色带来了不确定性。通过对27个团队（每个团队一名频繁用户和一名不频繁用户）的54名开发者进行配对访谈，我们证明了使用差异主要源于开发者如何看待工具（作为协作工具 vs. 功能）、他们的参与方式（实验性 vs. 保守型）以及他们在遇到挑战时如何回应（适应性坚持 vs. 快速放弃）。我们的发现暗示，组织对快速生产力提升的广泛期望，如果没有足够的学习支持，会产生“生产力压力悖论”，从而削弱了促使采纳的生产力效益。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [205] [Harnessing Large Language Model for Virtual Reality Exploration Testing: A Case Study](https://arxiv.org/abs/2501.05625)
> *利用大型语言模型进行虚拟现实探索测试：一个案例研究*

*Zhenyu Qi, Haotang Li, Hao Qin, Kebin Peng, Sen He, Xue Qin* | **Category: cs.SE** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 虚拟现实, 探索测试, GUI测试, GPT-4o

**Comment:** 

> **TL;DR:** 本案例研究探讨了大型语言模型（LLMs），特别是GPT-4o，在虚拟现实（VR）探索测试中进行视场（FOV）分析的能力，并发现LLMs能有效识别、描述VR实体，但存在标注局限性。

**AI_Comments:** 本研究创新性地将大型语言模型应用于虚拟现实探索测试，特别是GUI自动化测试领域，这在VR行业快速发展的背景下具有重要意义。通过具体的案例研究和量化数据，验证了LLMs在实体识别、特征描述、场景理解方面的潜力。提示工程的有效性也为后续研究提供了实践指导。然而，论文也坦诚地指出了LLMs在自动标注方面的局限性，为未来的研究指明了方向，体现了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 随着虚拟现实（VR）行业的发展，对自动化图形用户界面（GUI）测试的需求迅速增长。大型语言模型（LLMs）因其长期信息保留和对视觉、文本数据分析的能力，被认为是解决VR不断演进的用户界面复杂性的潜在关键。

**Method:** 本文进行了一项案例研究，以调查使用大型语言模型（特别是GPT-4o）在VR探索测试中进行视场（FOV）分析的能力。研究具体验证了LLMs识别FOV中测试实体的能力，并通过提示工程提升了识别准确率，并探讨了实体特征描述、场景识别和空间理解。

**Result:** 研究验证了LLMs能够识别视场中的测试实体，并且提示工程能将测试实体识别的准确率从41.67%提高到71.30%。LLMs能以至少90%的准确率描述已识别实体的特征。颜色、位置和形状是有效表示实体的核心特征，这三者的结合能将多视场中确定相同实体的准确率提高到最高的0.70的F1分数。此外，LLMs在精确设计的结构化提示下，能够进行VR中的场景识别和空间理解。

**Conclusion:** 研究发现大型语言模型（LLMs）在VR探索测试中能够有效识别和描述实体，并进行场景识别和空间理解。然而，LLMs目前无法对已识别的测试实体进行标注，这被视为未来研究方向的潜在解决方案。

> **ai_Abstract:** 本研究通过一个案例分析，探讨了大型语言模型（LLMs），特别是GPT-4o，在虚拟现实（VR）探索测试中进行视场（FOV）分析的潜力。结果显示，LLMs能够有效识别VR环境中的测试实体，并通过提示工程显著提升识别准确率。LLMs还能高准确率地描述实体特征，并发现颜色、位置和形状是关键特征，其组合能有效提升相同实体的识别精度。研究还证明了LLMs在VR场景识别和空间理解方面的能力。然而，研究也指出LLMs在自动标注已识别实体方面存在局限性，并提出了未来的研究方向。

> **摘要翻译:** 随着虚拟现实（VR）行业的扩张，对自动化图形用户界面（GUI）测试的需求正在迅速增长。大型语言模型（LLMs），能够长期保留信息并分析视觉和文本数据，正成为解密VR不断演进的用户界面复杂性的潜在关键。在本文中，我们进行了一个案例研究，以调查使用LLMs，特别是GPT-4o，在VR探索测试中进行视场（FOV）分析的能力。具体而言，我们验证了LLMs可以识别FOV中的测试实体，并且提示工程可以有效地将测试实体识别的准确率从41.67%提高到71.30%。我们的研究还表明，LLMs可以以至少90%的准确率准确描述已识别实体的特征。我们进一步发现，有效代表实体的核心特征是颜色、位置和形状。此外，这三个特征的组合尤其可以用于提高在多个FOV中确定相同实体的准确性，最高F1分数为0.70。此外，我们的研究表明，LLMs在精确设计的结构化提示下，能够进行VR中的场景识别和空间理解。最后，我们发现LLMs未能标记已识别的测试实体，我们讨论了作为未来研究方向的潜在解决方案。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [246] [Black-Box Bug-Amplification for Multithreaded Software](https://arxiv.org/abs/2507.21318)
> *多线程软件的黑盒错误放大*

*Yeshayahu Weiss, Gal Amram, Achiya Elyasaf, Eitan Farchi, Oded Margalit, Gera Weiss* | **Category: cs.SE** | **Updated: 2025-07-28**

**Keywords:** 错误放大, 并发错误, 黑盒测试, 回归模型, 多线程软件

**Comment:** 35 pages, 5 figurs, 4 listing and 3 tables

> **TL;DR:** 该论文提出了一种黑盒错误放大方法，通过训练预测模型来系统地放大并发系统中难以重现的错误，显著提高了错误发生率。

**AI_Comments:** 该论文提出了一种新颖且实用的方法来解决并发系统中的关键挑战——难以重现的错误。其创新点在于将错误放大问题转化为罕见事件回归问题，并利用机器学习模型进行预测引导搜索。这种黑盒、非侵入式的特性使其在实际应用中具有很高的价值，因为它避免了对系统内部结构的修改，降低了部署难度。实验结果显著，证明了模型引导搜索的有效性，为并发软件测试领域提供了一个强大的新工具。

<details>
  <summary>Details</summary>

**Motivation:** 并发系统中的错误通常很难重现，因为它们只在罕见条件下出现，即使发生概率很低，测试人员也经常遇到只在特定输入下发生的故障。

**Method:** 该方法将待测系统视为黑盒，利用重复试验执行来训练一个预测模型，该模型估计给定输入配置触发错误的概率。将多种基于模型的搜索技术与蛮力随机采样基线进行比较。

**Result:** 结果表明，回归模型集成可以显著提高几乎所有场景下的错误发生率，通常比随机采样提高一个数量级。

**Conclusion:** 本工作贡献包括：(i) 将错误放大创新性地表述为一个罕见事件回归问题；(ii) 对多种错误发生放大技术进行实证评估，证明了模型引导搜索的有效性；(iii) 一个实用的、非侵入式测试框架，帮助实践者在不改变内部系统架构的情况下发现隐藏的并发故障。

> **ai_Abstract:** 本研究提出了一种针对多线程软件的黑盒错误放大方法，旨在解决并发系统中难以重现的错误问题。通过将系统视为黑盒，并利用重复试验训练预测模型来估计输入触发错误的概率，该方法能够系统地放大错误发生率。实验结果表明，回归模型集成相比随机采样能显著提高错误发现效率，最高可达一个数量级。该工作创新性地将错误放大视为罕见事件回归问题，并提供了一个实用的非侵入式测试框架。

> **摘要翻译:** 错误，特别是并发系统中的错误，通常难以重现，因为它们只在罕见条件下出现。测试人员经常遇到只在特定输入下发生的故障，即使发生概率很低。我们提出了一种系统地放大此类难以捉摸的错误发生的方法。我们将待测系统视为黑盒，并使用重复试验执行来训练一个预测模型，该模型估计给定输入配置触发错误的概率。我们在包含17个代表性并发错误的多元数据集上评估了这种方法。将多种基于模型的搜索技术与蛮力随机采样基线进行比较。我们的结果表明，回归模型的集成可以显著提高几乎所有场景下的错误发生率，通常比随机采样提高一个数量级。这项工作的贡献包括：(i) 将错误放大创新性地表述为一个罕见事件回归问题；(ii) 对多种错误发生放大技术进行实证评估，证明了模型引导搜索的有效性；(iii) 一个实用的、非侵入式测试框架，帮助实践者在不改变内部系统架构的情况下发现隐藏的并发故障。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [253] [iPanda: An LLM-based Agent for Automated Conformance Testing of Communication Protocols](https://arxiv.org/abs/2507.00378)
> *iPanda：一个基于LLM的通信协议自动化一致性测试代理*

*Xikai Sun, Fan Dang, Shiqi Jiang, Jingao Xu, Kebin Liu, Xin Miao, Zihao Yang, Weichen Zhang, Haimo Lu, Yawen Zheng, Yunhao Liu* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-29**

**Keywords:** LLM, 一致性测试, 通信协议, 自动化, 测试生成

**Comment:** 10 pages, 4 figures

> **TL;DR:** iPanda是一个利用大型语言模型（LLM）自动化通信协议一致性测试的框架，它通过自动生成测试用例和程序，显著提高了测试效率和成功率。

**AI_Comments:** iPanda的创新之处在于它是首个将LLM应用于自动化通信协议一致性测试的框架，并结合了多阶段的生成与优化策略（关键词生成、RAG、CoT、迭代优化），显著提升了测试效率和程序质量，解决了传统测试中的痛点。其通过结合多种AI技术来解决复杂工程问题的方法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统通信协议一致性测试方法需要手动创建大量测试用例和脚本，这使得整个过程劳动密集且效率低下。

**Method:** iPanda是首个利用LLM自动化协议一致性测试的框架。它首先采用基于关键词的方法自动生成全面的测试用例；然后，利用检索增强生成和定制的CoT（思维链）策略来解释协议实现并生成可执行的测试程序；为了进一步提高程序质量，iPanda还结合了迭代优化机制来交互式地完善生成的测试脚本；最后，通过执行和分析生成的测试，系统地验证实现与协议规范之间的一致性。

**Result:** 在各种协议上的综合实验表明，iPanda显著优于纯基于LLM的方法，将测试程序生成的成功率（Pass@1）提高了4.675到10.751倍。

**Conclusion:** iPanda成功地利用大型语言模型自动化了通信协议的一致性测试，并通过创新的方法显著提高了测试用例和程序的生成效率及准确性。

> **ai_Abstract:** 本论文提出了iPanda，一个基于LLM的创新框架，用于自动化通信协议的一致性测试。针对传统方法中手动创建测试用例和脚本效率低下的问题，iPanda通过关键词生成测试用例、结合检索增强生成和CoT策略生成可执行测试程序，并采用迭代优化机制提升程序质量。实验证明，iPanda在测试程序生成成功率上显著优于纯LLM方法，性能提升显著。

> **摘要翻译:** 一致性测试对于确保协议实现符合其规范至关重要。然而，传统的测试方法涉及手动创建大量测试用例和脚本，使得该过程劳动密集且效率低下。最近，大型语言模型（LLM）展示了令人印象深刻的文本理解和代码生成能力，为自动化提供了有希望的机会。在本文中，我们提出了iPanda，这是第一个利用LLM自动化协议一致性测试的框架。给定协议规范文档及其实现，iPanda首先采用基于关键词的方法自动生成全面的测试用例。然后，它利用检索增强生成和定制的CoT策略来有效地解释实现并生成可执行的测试程序。为了进一步提高程序的质量，iPanda结合了迭代优化机制以交互方式完善生成的测试脚本。最后，通过执行和分析生成的测试，iPanda系统地验证了实现和协议规范之间的一致性。在各种协议上的综合实验表明，iPanda显著优于纯LLM方法，将测试程序生成的成功率（Pass@1）提高了4.675倍到10.751倍。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [309] [Does Editing Improve Answer Quality on Stack Overflow? A Data-Driven Investigation](https://arxiv.org/abs/2507.21329)
> *编辑是否能提高Stack Overflow上的答案质量？一项数据驱动的调查*

*Saikat Mondal, Chanchal K. Roy* | **Category: cs.SE** | **Updated: 2025-07-28**

**Keywords:** Stack Overflow, 协作编辑, 答案质量, 数据驱动, 软件维护

**Comment:** Accepted in the 41st International Conference on Software Maintenance
  and Evolution (ICSME 2025 - Research Track)

> **TL;DR:** 本研究发现Stack Overflow上被接受的编辑对答案质量既有积极影响也有消极影响，例如，有些编辑提高了语义相关性，但另一些却降低了代码可用性、增加复杂性、引入安全漏洞并降低可读性。

**AI_Comments:** 这项研究通过大规模数据分析系统性地评估了Stack Overflow上编辑的实际效果，填补了现有研究的空白。其创新之处在于对多个关键质量维度进行了量化分析，并揭示了编辑过程中的复杂性和潜在负面影响。这为平台用户、版主以及未来的协作编辑系统设计者提供了宝贵的实证依据和警示。

<details>
  <summary>Details</summary>

**Motivation:** 技术问答平台如Stack Overflow上的高质量答案至关重要，因为它们直接影响软件开发实践。低质量答案可能导致效率低下、错误和安全漏洞。为了提高内容质量，Stack Overflow允许协作编辑。然而，现有研究尚未系统评估已接受的编辑是否能提高关键质量维度。

**Method:** 本研究分析了94,994个至少有一个被接受编辑的Python相关答案，以确定编辑是否改善了：1) 语义相关性，2) 代码可用性，3) 代码复杂性，4) 安全漏洞，5) 代码优化，以及6) 可读性。

**Result:** 编辑对答案质量既有积极也有消极影响。53.3%的编辑提高了答案与问题的匹配度，但38.1%的编辑使其相关性降低。9%的先前损坏的代码变得可执行，但14.7%的可用代码在编辑后变得不可解析。32.3%的编辑增加了代码复杂性。20.5%的编辑引入了额外的安全问题。尽管51.0%的编辑优化了性能，但总体执行时间仍然增加。49.7%的编辑使代码更难阅读。

**Conclusion:** 本研究强调了编辑结果的不一致性，并提供了关于编辑如何影响软件可维护性、安全性及效率的见解，这可能对用户和版主起到警示作用，并有助于未来协作编辑系统的改进。

> **ai_Abstract:** 本研究对Stack Overflow上94,994个Python相关答案的接受编辑进行了数据驱动分析，旨在评估编辑对语义相关性、代码可用性、复杂性、安全漏洞、优化和可读性的影响。研究发现，编辑对答案质量既有积极也有消极作用，例如，部分编辑提高了语义相关性，但也有部分导致代码质量下降（如增加复杂性、引入安全漏洞、降低可读性）。研究结果揭示了编辑结果的不一致性，并为协作编辑系统提供了改进建议，以提高软件的可维护性、安全性和效率。

> **摘要翻译:** 技术问答平台（如Stack Overflow，简称SO）中的高质量答案至关重要，因为它们直接影响软件开发实践。低质量答案可能导致效率低下、错误和安全漏洞，从而增加生产软件的维护成本和技术债务。为了提高内容质量，SO允许协作编辑，用户可以修订答案以增强清晰度、正确性和格式。多项研究已审查被拒绝的编辑并确定了拒绝的原因。然而，先前的研究尚未系统评估已接受的编辑是否能提高关键质量维度。尽管有一项研究调查了编辑对C/C++漏洞的影响，但更广泛的质量方面仍未被探索。在本研究中，我们分析了94,994个至少有一个被接受编辑的Python相关答案，以确定编辑是否提高了 (1) 语义相关性，(2) 代码可用性，(3) 代码复杂性，(4) 安全漏洞，(5) 代码优化，以及 (6) 可读性。我们的发现显示编辑既有积极影响也有消极影响。虽然53.3%的编辑提高了答案与问题的匹配度，但38.1%的编辑使其相关性降低。一些先前损坏的代码（9%）变得可执行，但工作中的代码（14.7%）在编辑后变得不可解析。许多编辑增加了复杂性（32.3%），使代码更难维护。20.5%的编辑非但没有修复安全问题，反而引入了额外的问题。尽管51.0%的编辑优化了性能，但总体执行时间仍然增加。可读性也受到了影响，因为49.7%的编辑使代码更难阅读。本研究强调了编辑结果的不一致性，并提供了关于编辑如何影响软件可维护性、安全性及效率的见解，这可能对用户和版主起到警示作用，并有助于未来协作编辑系统的改进。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [317] [Kodezi Chronos: A Debugging-First Language Model for Repository-Scale Code Understanding](https://arxiv.org/abs/2507.12482)
> *Kodezi Chronos：一个面向调试的语言模型，用于代码库规模的代码理解*

*Ishraq Khan, Assad Chowdary, Sharoz Haseeb, Urvish Patel, Yousuf Zaii* | **Category: cs.SE, cs.AI, cs.CE, cs.LG, 68N30, 68Q60, 68T05, 68T20, 68T30, 68T37, 68T50, D.2.3; D.2.5; D.2.7; F.3.2; H.3.3; I.2.2; I.2.6; I.2.7; I.2.8** | **Updated: 2025-07-29**

**Keywords:** 代码调试, 语言模型, 代码理解, 代码库规模, Kodezi Chronos

**Comment:** 27 pages, 21 figures, 37 tables, 2 algorithms. Extended technical
  report. Introduces Chronos, an autonomous debugging system achieving 87.1%
  success rate on real-world bugs. Code and data available at
  https://github.com/Kodezi/chronos

> **TL;DR:** Kodezi Chronos是一个专门用于调试的语言模型，它通过结合图引导检索、持久调试记忆和多层架构，在真实调试任务中显著优于现有LLM，并能处理大型代码库。

**AI_Comments:** 本文提出Kodezi Chronos，其创新点在于将LLM专门化应用于调试领域，并通过结合图引导检索和持久化记忆机制，有效解决了LLM在处理大规模代码上下文和缺乏结构化推理方面的局限性。其在真实调试任务上的显著性能提升（67.3%修复准确率对比现有模型的不到15%）表明了该方法的巨大潜力。该模型的引入对于提高软件开发效率具有重要意义。然而，其在硬件相关和动态语言错误上的局限性也提示了未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLMs）在代码生成和软件自动化方面有所改进，但受限于推理时上下文和缺乏结构化代码推理能力。尽管LLMs在代码合成基准测试中表现出色（>70%），但在实际调试任务中表现极差（<15%），因此调试问题仍未解决。

**Method:** Kodezi Chronos结合了以下方法：1. 自适应图引导检索（Adaptive Graph-Guided Retrieval），通过多跳遍历导航高达1000万行的代码库（92%精度，85%召回率）。2. 持久调试记忆（Persistent Debug Memory），该记忆在超过1500万次会话上进行训练。3. 一个7层架构，用于迭代的修复-测试-完善循环。

**Result:** 在5,000个真实场景中，Chronos实现了67.3%的修复准确率，而Claude和GPT-4.1分别为14.2%和13.8%。Chronos将调试时间减少了40%，迭代次数减少了65%。它能解决涉及跨代码库上下文和时间推理的复杂多文件错误。在人类评估中（N=50），89%的参与者更喜欢Chronos。检索复杂度为O(k log d)，并有收敛保证。

**Conclusion:** Kodezi Chronos是一个专门为调试设计的语言模型，它通过创新的检索和记忆机制，显著提高了调试的准确性和效率，远超现有通用LLM，并能有效处理大规模代码库和复杂错误。

> **ai_Abstract:** 本文介绍了Kodezi Chronos，一个专注于调试的语言模型，旨在解决现有LLM在实际调试任务中表现不佳的问题。Chronos通过结合自适应图引导检索（处理大型代码库）、持久调试记忆和7层迭代架构，在真实调试场景中实现了67.3%的修复准确率，远超Claude和GPT-4.1。它显著减少了调试时间和迭代次数，并能处理复杂的跨文件和时间推理错误。尽管在特定类型问题上仍有限制，但用户评价显示其优于现有模型。

> **摘要翻译:** 大型语言模型（LLMs）改进了代码生成和软件自动化，但仍受限于推理时上下文和缺乏对代码的结构化推理能力。尽管取得了这些进展，调试问题仍未解决。虽然Claude Opus 4和GPT-4.1在代码合成基准测试中达到了70%以上，但它们在实际调试任务中表现低于15%。我们引入了Kodezi Chronos，一个专门为调试构建的语言模型。Chronos结合了自适应图引导检索，通过多跳遍历导航多达1000万行的代码库（92%精度，85%召回率），在超过1500万次会话上训练的持久调试记忆，以及一个用于迭代修复-测试-完善循环的7层架构。在5,000个真实场景中，Chronos实现了67.3%的修复准确率，而Claude和GPT-4.1分别为14.2%和13.8%。Chronos将调试时间减少了40%，迭代次数减少了65%。它解决了涉及跨代码库上下文和时间推理的复杂多文件错误。主要限制包括对硬件相关问题成功率为23.4%，对动态语言错误成功率为41.2%。理论分析表明检索复杂度为O(k log d)，并有收敛保证。在人类评估中（N=50），89%的参与者更喜欢Chronos而非基线模型。Chronos将于2025年第四季度在Kodezi OS中提供，并于2026年第一季度通过API提供。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [372] [MAAD: Automate Software Architecture Design through Knowledge-Driven Multi-Agent Collaboration](https://arxiv.org/abs/2507.21382)
> *MAAD：通过知识驱动的多智能体协作自动化软件架构设计*

*Ruiyin Li, Yiran Zhang, Xiyu Zhou, Peng Liang, Weisong Sun, Jifeng Xuan, Zhi Jin, Yang Liu* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 软件架构设计, 多智能体系统, 大型语言模型, 自动化, 知识驱动

**Comment:** 23 pages, 8 images, 1 table, Manuscript submitted to a journal (2025)

> **TL;DR:** MAAD是一个知识驱动的多智能体系统，旨在自动化软件架构设计过程，通过协作代理生成架构蓝图和评估报告，并在案例研究和对比实验中表现出优越性。

**AI_Comments:** MAAD的创新之处在于其知识驱动的多智能体协作框架，将复杂的架构设计任务分解并分配给专业代理，这提高了设计过程的自动化和效率。其重要性在于解决了传统架构设计中耗时、依赖人工和方案有限的痛点，为软件开发带来了新的范式。通过与现有LLM的集成和性能评估，也为未来基于LLM的自动化工具提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 软件架构设计复杂、知识密集且耗时，传统方法依赖人工且设计方案有限。尽管大型语言模型（LLM）在软件工程任务中表现出色，但在架构设计领域的应用仍较少，且面临领域知识和复杂决策的挑战。

**Method:** 本文提出了MAAD（Multi-Agent Architecture Design），一个自动化框架，采用知识驱动的多智能体系统（MAS）进行架构设计。MAAD协调四个专业代理（分析师、建模师、设计师和评估师）协作解释需求规范，并生成包含质量属性评估报告的架构蓝图。

**Result:** MAAD在生成全面的架构组件和提供有洞察力、结构化的架构评估报告方面表现出优越性。来自工业架构师的反馈进一步证实了MAAD的实用性。在不同LLM的测试中，GPT-4o在生成架构设计方面表现最佳。

**Conclusion:** MAAD框架通过知识驱动的多智能体协作，有效自动化了软件架构设计过程，能够生成高质量的架构蓝图和评估报告，并强调了LLM选择在MAS驱动架构设计中的重要性。

> **ai_Abstract:** 本文提出了MAAD（多智能体架构设计），一个知识驱动的多智能体系统，旨在自动化复杂的软件架构设计过程。MAAD通过协调分析师、建模师、设计师和评估师四个专业代理，协同解释需求并生成包含质量属性评估的架构蓝图和报告。实验结果表明，MAAD在生成全面的架构组件和提供有洞察力的评估报告方面优于现有基线，并得到了工业架构师的认可。研究还强调了大型语言模型选择对设计质量的重要性。

> **摘要翻译:** 软件架构设计是软件开发中一个关键但本质上复杂且知识密集阶段。它需要深厚的领域专业知识、开发经验、架构知识、在相互竞争的质量属性之间进行仔细权衡以及适应不断变化需求的能力。传统上，这个过程耗时费力，严重依赖架构师，尤其在敏捷开发的压力下，往往导致设计备选方案有限。尽管基于大型语言模型（LLM）的智能体在各种软件工程任务中表现出有希望的性能，但它们在架构设计中的应用相对稀少，需要更多探索，尤其是在面对多样化领域知识和复杂决策时。为解决这些挑战，我们提出了MAAD（多智能体架构设计），一个采用知识驱动多智能体系统（MAS）进行架构设计的自动化框架。MAAD协调四个专业智能体（即分析师、建模师、设计师和评估师）协同解释需求规范，并生成富含基于质量属性评估报告的架构蓝图。随后，我们通过案例研究和与最先进的MAS基线MetaGPT的对比实验评估了MAAD。我们的结果表明，MAAD的优越性在于生成全面的架构组件以及提供有洞察力且结构化的架构评估报告。来自11个需求规范的工业架构师的反馈进一步增强了MAAD的实际可用性。我们最终探索了MAAD框架在三种LLM（GPT-4o、DeepSeek-R1和Llama 3.3）下的性能，发现GPT-4o在生成架构设计方面表现出更好的性能，强调了LLM选择在MAS驱动架构设计中的重要性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [432] [HLSDebugger: Identification and Correction of Logic Bugs in HLS Code with LLM Solutions](https://arxiv.org/abs/2507.21485)
> *HLSDebugger：使用大型语言模型解决方案识别和纠正HLS代码中的逻辑错误*

*Jing Wang, Shang Liu, Yao Lu, Zhiyao Xie* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-29**

**Keywords:** HLS, 调试, LLM, 逻辑错误, 自动化调试

**Comment:** This work has been accepted at ICCAD 2025 (International Conference
  on Computer-Aided Design)

> **TL;DR:** HLSDebugger 是一种基于大型语言模型的解决方案，用于自动化高层次综合（HLS）代码中的逻辑错误调试，它通过构建大规模数据集和采用编码器-解码器结构，在错误识别和纠正方面显著优于现有先进LLM。

**AI_Comments:** HLSDebugger 的创新之处在于其专门针对 HLS 逻辑错误调试，解决了 LLM 应用中的关键挑战，特别是通过构建大规模高质量数据集来弥补数据稀缺性。其编码器-解码器结构实现了多任务处理，在错误识别和纠正方面的卓越表现（尤其是在纠正方面大幅超越 GPT-4）证明了其有效性和重要性，对加速硬件设计流程具有显著意义。

<details>
  <summary>Details</summary>

**Motivation:** 高层次综合（HLS）代码的调试极具挑战性且劳动密集，尤其对于缺乏硬件领域知识的初学者。尽管大型语言模型（LLMs）在自动化HLS调试方面有巨大潜力，但仍面临高质量电路数据稀缺、硬件逻辑错误调试的复杂性以及缺乏可靠测试用例需多任务处理等挑战。

**Method:** HLSDebugger 提出了一种定制解决方案。它首先生成并发布了一个包含30万个数据样本的大型HLS逻辑错误标注数据集。其模型采用编码器-解码器结构，能同时执行错误位置识别、错误类型预测和错误纠正。

**Result:** HLSDebugger 在错误识别方面显著优于 GPT-4 等先进LLM，在错误纠正方面的性能更是超过3倍。

**Conclusion:** HLSDebugger 在自动化HLS代码调试的探索中取得了实质性进展。

> **ai_Abstract:** 本文提出了一种名为 HLSDebugger 的定制解决方案，旨在解决高层次综合（HLS）代码逻辑调试中大型语言模型（LLMs）应用面临的挑战。针对高质量训练数据稀缺、硬件逻辑调试复杂性以及多任务处理需求，HLSDebugger 首先构建并发布了一个包含30万个HLS逻辑错误样本的大型标注数据集。该模型采用编码器-解码器结构，能够同时实现错误位置识别、错误类型预测和错误纠正。实验结果表明，HLSDebugger 在错误识别和纠正方面均显著优于 GPT-4 等现有先进 LLMs，尤其在错误纠正方面性能提升超过三倍，标志着自动化 HLS 代码调试领域的重大进展。

> **摘要翻译:** 高层次综合（HLS）通过将高级描述自动转换为高效的硬件实现来加速硬件设计。然而，调试HLS代码是一项具有挑战性且劳动密集型任务，特别是对于缺乏足够硬件领域知识的新手电路设计师或软件工程师而言。大型语言模型（LLMs）的最新出现有望自动化HLS调试过程。尽管潜力巨大，但在将LLMs应用于HLS逻辑调试时仍然存在三个关键挑战：1）用于训练LLMs的高质量电路数据稀缺，构成重大挑战。2）调试硬件中的逻辑错误本质上比使用现有黄金测试用例识别软件错误更复杂。3）缺乏可靠的测试用例需要多任务解决方案，即同时执行错误识别和纠正，这使得有效HLS调试所需的多任务处理变得复杂。在这项工作中，我们提出了一种名为HLSDebugger的定制解决方案来应对这些挑战。HLSDebugger首先生成并发布了一个包含30万个数据样本的大型标注数据集，专门针对HLS逻辑错误。HLSDebugger模型采用编码器-解码器结构，使用相同的模型执行错误位置识别、错误类型预测和错误纠正。HLSDebugger在错误识别方面显著优于GPT-4等先进LLMs，在错误纠正方面更是超过3倍。它在自动化HLS代码调试的探索中取得了实质性进展。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [495] [Ethical Classification of Non-Coding Contributions in Open-Source Projects via Large Language Models](https://arxiv.org/abs/2507.21583)
> *通过大型语言模型对开源项目中非代码贡献的伦理分类*

*Sergio Cobos, Javier Luis Cánovas Izquierdo* | **Category: cs.SE** | **Updated: 2025-07-29**

**Keywords:** 开源软件, 伦理分类, 大型语言模型, 非代码贡献, 行为准则

**Comment:** Accepted at the 2025 8th AAAI/ACM Conference on AI, Ethics, and
  Society (AIES'25)

> **TL;DR:** 本文提出了一种利用大型语言模型（LLM）来分类开源项目（OSS）中非代码贡献伦理质量的方法，以解决现有行为准则监控和执行的挑战。

**AI_Comments:** 本文的创新点在于将大型语言模型应用于开源项目中非代码贡献的伦理分类，这为解决行为准则的监控和执行难题提供了一个有前景的解决方案。通过利用LLM强大的文本分类能力和提示工程的灵活性，该方法有望提高伦理评估的效率和准确性，从而促进更积极和可持续的开源社区环境。

<details>
  <summary>Details</summary>

**Motivation:** 开源软件（OSS）项目在社会协作中面临伦理挑战，这可能危及项目的可持续性。尽管行为准则（如贡献者盟约）被广泛部署以确保尊重和包容的环境，但监控和执行这些准则具有挑战性。当前的传统方法存在局限性，因此需要一种新的方法来评估非代码贡献的伦理质量。

**Method:** 本研究提出了一种基于大型语言模型（LLM）的方法，用于分类OSS项目中非代码贡献的伦理质量。研究人员基于“贡献者盟约”定义了一套伦理指标，并开发了一种分类方法，利用提示工程来指导模型的输出，以评估OSS非代码贡献中的伦理行为。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种利用大型语言模型（LLM）对开源项目（OSS）中非代码贡献进行伦理分类的新方法。鉴于现有行为准则在监控和执行方面的挑战，研究人员基于“贡献者盟约”定义了伦理指标，并通过提示工程指导LLM，旨在评估和改善OSS社区的伦理环境。

> **摘要翻译:** 开源软件（OSS）的开发不仅是技术挑战，由于贡献者的多样性，也是一个社会挑战。为此，GitHub等社交编码平台提供了托管和开发代码所需的基础设施，也支持社区协作，而这种协作是由非代码贡献驱动的，例如问题（即变更提案或错误报告）或对现有贡献的评论。与任何其他社会活动一样，这种开发过程面临伦理挑战，这可能危及项目的可持续性。为了营造一个富有成效和积极的环境，OSS项目越来越多地部署行为准则，这些准则定义了规则，以确保一个尊重和包容的参与环境，其中“贡献者盟约”是主要遵循的模型。然而，由于当前方法的局限性，监控和执行这些行为准则是一项具有挑战性的任务。在本文中，我们提出了一种方法，通过依赖大型语言模型（LLM）来分类OSS项目中非代码贡献的伦理质量，LLM是一种用于文本分类任务的有前景的技术。我们基于“贡献者盟约”定义了一套伦理指标，并开发了一种分类方法，利用提示工程来指导模型的输出，以评估OSS非代码贡献中的伦理行为。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [556] [Predicting Maintenance Cessation of Open Source Software Repositories with An Integrated Feature Framework](https://arxiv.org/abs/2507.21678)
> *使用集成特征框架预测开源软件仓库的维护终止*

*Yiming Xu, Runzhi He, Hengzhi Ye, Minghui Zhou, Huaimin Wang* | **Category: cs.SE** | **Updated: 2025-07-29**

**Keywords:** 开源软件, 维护终止, 预测, 特征框架, 生存分析

**Comment:** 

> **TL;DR:** 本研究引入了“维护终止”的明确定义，并构建了一个大规模数据集，提出了一个集成多视角特征框架来预测开源软件的维护终止，实现了高预测性能和可解释性，并展示了实际应用。

**AI_Comments:** 该论文的创新之处在于其对“维护终止”的明确操作性定义，以及构建了一个大规模、纵向的数据集来支持这一研究。提出的集成多视角特征框架考虑了更全面的因素，显著提升了预测性能和模型可解释性，克服了现有方法的局限性。实际部署案例也证明了其在工业界的应用价值和可扩展性，为开源软件的风险管理提供了坚实基础。

<details>
  <summary>Details</summary>

**Motivation:** 开源软件（OSS）项目的维护风险对现代软件供应链的质量、安全性和弹性构成重大威胁。现有预测OSS维护风险的方法常受限于操作定义模糊、可解释性有限以及数据集规模或泛化能力不足。

**Method:** 本研究引入了基于显式归档状态和项目文档语义分析的“维护终止”概念。构建了一个包含115,466个GitHub仓库（含57,733个确认终止事件）的大规模、纵向数据集，并辅以全面的基于时间线的行为特征。提出了一个集成多视角特征框架，系统地结合了以用户为中心的特征、以维护者为中心的特征和项目演化特征。采用AFT生存分析进行预测，并使用特征消融和SHAP分析验证方法有效性和可解释性。最后，在openEuler生态系统中部署了GBSA分类器进行主动包风险筛选。

**Result:** AFT生存分析显示C-index高达0.846，显著优于仅依赖表面特征的模型。特征消融和SHAP分析进一步证实了方法的有效性和可解释性。在openEuler生态系统中成功部署GBSA分类器。

**Conclusion:** 本研究为维护风险预测建立了可扩展、可解释的基础，从而在大规模开源生态系统中实现了可复现的风险管理。

> **ai_Abstract:** 本研究旨在解决开源软件（OSS）项目维护终止的预测问题，以应对其对软件供应链的威胁。研究首先明确定义了“维护终止”，并构建了一个包含11万余个GitHub仓库的大规模数据集。在此基础上，提出了一种集成的多视角特征框架，结合了用户、维护者和项目演化特征。实验结果表明，该方法在预测维护终止方面表现出色（C-index 0.846），优于传统方法，并具有良好的可解释性。研究还展示了其在实际开源生态系统中的应用潜力。

> **摘要翻译:** 开源软件（OSS）项目的维护风险对现代软件供应链的质量、安全性和弹性构成重大威胁。尽管先前的研究提出了各种预测OSS维护风险的方法——利用从表面特征（例如，星标、提交）到社交网络分析和行为模式等信号——但现有方法通常存在操作定义模糊、可解释性有限以及数据集规模或泛化能力不足的问题。在这项工作中，我们引入了“维护终止”的概念，它基于明确的归档状态和对项目文档的严格语义分析。在此基础上，我们整理了一个包含115,466个GitHub仓库的大规模、纵向数据集——其中包括57,733个已确认的终止事件——并辅以全面的、基于时间线的行为特征。我们提出了一个集成多视角特征框架来预测维护终止，系统地结合了以用户为中心的特征、以维护者为中心的特征和项目演化特征。AFT生存分析显示出高C-index（0.846），显著优于仅依赖表面特征的模型。特征消融和SHAP分析进一步证实了我们方法的有效性和可解释性。最后，我们通过在openEuler生态系统中部署GBSA分类器来展示其在实际应用中的可行性，用于主动的包风险筛选。我们的工作为维护风险预测建立了可扩展、可解释的基础，从而在大规模开源生态系统中实现了可复现的风险管理。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [619] [MultiAIGCD: A Comprehensive dataset for AI Generated Code Detection Covering Multiple Languages, Models,Prompts, and Scenarios](https://arxiv.org/abs/2507.21693)
> *MultiAIGCD：一个涵盖多种语言、模型、提示和场景的AI生成代码检测综合数据集*

*Basak Demirok, Mucahid Kutlu, Selin Mergen* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-29**

**Keywords:** AI生成代码检测, 数据集, LLMs, 代码生成, MultiAIGCD

**Comment:** 

> **TL;DR:** MultiAIGCD是一个用于检测AI生成代码的综合数据集，涵盖Python、Java和Go语言，通过多种LLM和提示生成，并考虑了三种使用场景。该数据集包含大量的AI生成代码和人工编写代码，并用于基准测试了现有检测模型的性能。

**AI_Comments:** 该论文的主要创新在于构建了一个大规模且多维度的AI生成代码检测数据集MultiAIGCD，涵盖了多种编程语言、不同的生成模型、多样的提示方式以及实际应用场景。这对于AI生成代码检测领域的研究具有重要意义，因为它提供了一个标准化的基准和丰富的训练资源，有助于开发更鲁棒、更通用的检测系统。数据集的全面性是其核心价值，尤其是在跨模型和跨语言测试场景下的评估，揭示了当前检测方法的局限性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）在代码生成领域的迅速发展，AI生成代码的检测变得至关重要，以维护教育领域的学术诚信和招聘过程中的公平性。

**Method:** 研究引入了MultiAIGCD数据集，用于Python、Java和Go语言的AI生成代码检测。该数据集通过CodeNet的问题定义和人工编写代码，使用六种不同的LLM和三种不同的提示生成了大量的代码样本，涵盖了从问题描述生成代码、修复运行时错误和纠正错误输出三种使用场景。

**Result:** MultiAIGCD数据集包含121,271个AI生成代码片段和32,148个人工编写代码片段。研究还对三种最先进的AI生成代码检测模型进行了基准测试，并评估了它们在跨模型和跨语言等各种测试场景下的性能。

**Conclusion:** 本研究构建并发布了MultiAIGCD数据集，旨在支持AI生成代码检测领域的研究，并评估了现有检测模型在该数据集上的表现。

> **ai_Abstract:** 本研究介绍了MultiAIGCD，一个用于检测Python、Java和Go语言中AI生成代码的综合数据集。该数据集通过利用CodeNet数据并结合多种大型语言模型、不同的提示和三种实际应用场景（从问题描述生成、修复运行时错误和纠正输出）来生成AI代码。MultiAIGCD包含了超过12万个AI生成代码片段和3万个人工编写代码片段。研究还利用该数据集对现有AI生成代码检测模型进行了基准测试，并分析了它们在跨模型和跨语言场景下的性能，旨在推动该领域的研究发展。

> **摘要翻译:** 随着大型语言模型（LLMs）的迅速发展，它们在代码生成中的作用显著扩大。虽然这简化了开发流程，但也引发了教育和求职面试等领域的担忧。因此，开发强大的系统来检测AI生成代码对于维护学术诚信和确保招聘过程的公平性至关重要。在本研究中，我们引入了MultiAIGCD，这是一个用于Python、Java和Go语言的AI生成代码检测数据集。我们从CodeNet数据集的问题定义和人工编写代码中，使用六种不同的LLM和三种不同的提示，生成了Java、Python和Go的多个代码样本。这个生成过程涵盖了三个关键的使用场景：(i) 从问题描述生成代码，(ii) 修复人工编写代码中的运行时错误，以及 (iii) 纠正不正确的输出。总体而言，MultiAIGCD包含121,271个AI生成代码片段和32,148个人工编写代码片段。我们还对三种最先进的AI生成代码检测模型进行了基准测试，并评估了它们在跨模型和跨语言等各种测试场景下的性能。我们共享了我们的数据集和代码，以支持该领域的研究。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [684] [Automated Prompt Engineering for Cost-Effective Code Generation Using Evolutionary Algorithm](https://arxiv.org/abs/2408.11198)
> *利用进化算法实现经济高效的代码生成的自动化提示工程*

*Hamed Taherkhani, Melika Sepindband, Hung Viet Pham, Song Wang, Hadi Hemmati* | **Category: cs.SE, cs.AI, cs.NE** | **Updated: 2025-07-29**

**Keywords:** 自动化提示工程, 代码生成, 进化算法, 大型语言模型, 成本效益

**Comment:** 

> **TL;DR:** 该论文提出了一种名为EPiC的自动化提示工程方法，通过轻量级进化算法优化提示，以更低的成本生成高质量代码，解决了现有LLM代码生成方法成本高昂的问题。

**AI_Comments:** 该论文的创新点在于将轻量级进化算法应用于提示工程，以解决LLM代码生成中成本高昂的问题。通过优化提示本身而非增加LLM交互次数，EPiC在保证代码质量的同时显著降低了成本，为LLM在实际软件开发中的应用提供了更经济高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLM）代码生成方法虽然有效，但由于与LLM的多次交互和大量的token使用，导致成本高昂。

**Method:** 本文提出了一种名为“代码进化提示工程”（EPiC）的替代方法，该方法利用轻量级进化算法来优化原始提示，使其生成高质量代码，同时最大程度地减少与LLM的交互。

**Result:** EPiC在pass@k上实现了高达6%的提升，并且比最先进的基线方法成本效益高2-10倍。

**Conclusion:** EPiC是一种有效且成本效益高的自动化提示工程方法，能够为代码生成任务提供高质量的结果，并显著降低运营成本。

> **ai_Abstract:** 该论文提出了一种名为EPiC（Evolutionary Prompt Engineering for Code）的自动化提示工程方法，旨在解决现有大型语言模型（LLM）代码生成方法成本高昂的问题。EPiC利用轻量级进化算法优化提示，以最小化与LLM的交互，从而生成高质量代码。实验结果表明，EPiC不仅能提高代码生成质量（pass@k提升高达6%），而且成本效益比现有方法高2-10倍。

> **摘要翻译:** 大型语言模型在各种软件开发任务中，尤其是在代码生成方面，得到了越来越多的应用。最近最先进的方法尝试将代码执行的反馈融入到提示中，以帮助引导大型语言模型在迭代过程中生成正确的代码。尽管这些方法有效，但由于与大型语言模型的多次交互和大量的token使用，它们可能成本高昂。为了解决这个问题，我们提出了一种名为“代码进化提示工程”（EPiC）的替代方法，该方法利用轻量级进化算法将原始提示优化为改进版本，从而生成高质量代码，且与大型语言模型的交互最少。我们对最先进（SOTA）基于大型语言模型的代码生成代理的评估表明，EPiC不仅在pass@k上实现了高达6%的提升，而且比基线方法成本效益高2-10倍。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [688] [Vibe Coding as a Reconfiguration of Intent Mediation in Software Development: Definition, Implications, and Research Agenda](https://arxiv.org/abs/2507.21928)
> *氛围编程作为软件开发中意图 S 介导的重构：定义、影响和研究议程*

*Christian Meske, Tobias Hermanns, Esther von der Weiden, Kai-Uwe Loser, Thorsten Berger* | **Category: cs.SE, cs.AI, cs.HC** | **Updated: 2025-07-29**

**Keywords:** 氛围编程, 生成式AI, 软件开发, 意图介导, 认知劳动

**Comment:** 

> **TL;DR:** 氛围编程正在改变软件开发，通过人与生成式AI的自然语言对话共同创建软件。本文定义了氛围编程，分析了其对认知工作和专业知识的重构，并提出了机遇、风险及未来研究议程。

**AI_Comments:** 本文创新性地提出了“氛围编程”的概念，并深入分析了其对软件开发认知工作和专业知识分配的重构。其重要性在于，在AI生成代码日益普及的背景下，为理解和管理这一新范式提供了理论框架和实践指导，并明确指出了未来的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 软件开发正在经历根本性变革，氛围编程的广泛应用导致大量当代代码库由AI生成。这种快速采纳与有限概念理解之间的脱节，凸显了对这一新兴范式进行探究的必要性。

**Method:** 本文借鉴意图视角和历史分析，将氛围编程定义为一种软件开发范式，其中人类和生成式AI通过自然语言对话进行协作流，共同创建软件制品，将开发者意图的介导从确定性指令转向概率性推理。

**Result:** 氛围编程通过重新分配人机之间的认知劳动，重构了认知工作；将软件开发过程中的专业知识从设计或技术实现等传统领域转向协作编排。本文还识别了关键机遇（民主化、加速、系统性杠杆）和风险（黑箱代码库、责任差距、生态系统偏差）。

**Conclusion:** 本文以涵盖以人为中心、以技术为中心和以组织为中心的研究议程作结，以指导未来对该范式的调查。

> **ai_Abstract:** 本文定义了“氛围编程”这一新兴的软件开发范式，即人类与生成式AI通过自然语言对话共同创建软件。研究指出，氛围编程通过重新分配认知劳动和转变专业知识，重构了软件开发中的意图介导过程。文章探讨了该范式带来的机遇（如民主化、加速）和风险（如黑箱代码），并提出了未来研究的议程。

> **摘要翻译:** 软件开发正在经历一场根本性变革，随着氛围编程的普及，当代代码库的很大一部分现在由AI生成。快速采用与有限概念理解之间的脱节，凸显了对这一新兴范式进行探究的必要性。借鉴意图视角和历史分析，我们将氛围编程定义为一种软件开发范式，其中人类和生成式AI通过自然语言对话进行协作流，共同创建软件制品，将开发者意图的介导从确定性指令转向概率性推理。通过意图介导，我们指的是开发者将其概念目标转化为计算系统可执行的表示形式的基本过程。我们的结果表明，氛围编程通过重新分配人机之间的认知劳动，重构了认知工作，将软件开发过程中的专业知识从设计或技术实现等传统领域转向协作编排。我们识别了关键机遇，包括民主化、加速和系统性杠杆，以及风险，例如黑箱代码库、责任差距和生态系统偏差。我们以涵盖以人为中心、以技术为中心和以组织为中心的研究议程作结，以指导未来对该范式的调查。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [765] [DeepGo: Predictive Directed Greybox Fuzzing](https://arxiv.org/abs/2507.21952)
> *DeepGo：预测性定向灰盒模糊测试*

*Peihong Lin, Pengfei Wang, Xu Zhou, Wei Xie, Gen Zhang, Kai Lu* | **Category: cs.SE, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 定向灰盒模糊测试, 深度学习, 强化学习, 路径预测, 模糊测试策略

**Comment:** 

> **TL;DR:** DeepGo是一种新型的定向灰盒模糊测试工具，它通过结合历史和预测信息，并利用深度学习和强化学习来预测路径转换并找到最优路径，以提高模糊测试效率。

**AI_Comments:** DeepGo的创新之处在于其结合了预测性能力（通过DNN预测未探索路径）和优化能力（通过RLF寻找最优路径），弥补了传统DGF依赖历史数据和启发式算法的不足。这种前瞻性的方法有望显著提高模糊测试在复杂软件中的覆盖率和效率。其引入的路径转换模型和动作组概念也为模糊测试的策略优化提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有定向灰盒模糊测试（DGF）技术主要依赖启发式算法优化适应度指标，但这些算法通常基于历史执行信息，缺乏对未探索路径的预见性。这导致DGF在处理具有复杂约束的难以执行路径时效率低下，无法有效到达目标。

**Method:** 本文提出了DeepGo，一个预测性定向灰盒模糊测试器。它首先提出了路径转换模型，将DGF建模为通过特定路径转换序列到达目标的过程。接着，利用深度神经网络构建虚拟集成环境（VEE），预测未探索路径的转换及其奖励。然后，开发了模糊测试强化学习（RLF）模型，结合历史和预测路径转换生成最高奖励的序列，并指导变异策略。最后，引入了动作组的概念，综合优化模糊测试的关键步骤，以有效地实现到达目标的最优路径。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** DeepGo是一种创新的定向灰盒模糊测试工具，旨在解决现有DGF技术在探索复杂路径时的效率问题。它通过引入路径转换模型，并结合深度神经网络构建的虚拟集成环境（VEE）来预测未探索路径的奖励。此外，DeepGo还利用强化学习（RLF）模型来生成最优路径转换序列，并指导模糊测试的变异策略，同时引入动作组概念以全面优化模糊测试过程，从而实现高效的目标站点到达。

> **摘要翻译:** 最先进的定向灰盒模糊测试（DGF）技术通过重新定义和优化适应度指标来精确快速地到达目标站点。然而，适应度指标的优化主要基于启发式算法，这些算法通常依赖于历史执行信息，缺乏对尚未执行路径的预见性。因此，那些具有复杂约束的难以执行路径会阻碍DGF到达目标，使得DGF效率低下。在本文中，我们提出了DeepGo，一个预测性定向灰盒模糊测试器，它能够结合历史和预测信息，引导DGF通过最优路径到达目标站点。我们首先提出了路径转换模型，该模型将DGF建模为通过特定路径转换序列到达目标站点的过程。变异生成的新种子会引起路径转换，而对应高奖励路径转换序列的路径表明通过它到达目标站点的可能性很高。然后，为了预测路径转换和相应的奖励，我们使用深度神经网络构建了一个虚拟集成环境（VEE），该环境逐渐模仿路径转换模型并预测尚未采取的路径转换的奖励。为了确定最优路径，我们开发了一个模糊测试强化学习（RLF）模型来生成具有最高序列奖励的转换序列。RLF模型可以结合历史和预测路径转换来生成最优路径转换序列，以及指导模糊测试变异策略的策略。最后，为了执行高奖励路径转换序列，我们提出了动作组的概念，该概念全面优化了模糊测试的关键步骤，以有效地实现到达目标的最优路径。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [829] [Fine-Tuning Code Language Models to Detect Cross-Language Bugs](https://arxiv.org/abs/2507.21954)
> *微调代码语言模型以检测跨语言错误*

*Zengyang Li, Yimeng Li, Binbin Huang, Peng Liang, Ran Mo, Hui Liu, Yutao Ma* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 跨语言错误, 代码语言模型, 微调, 错误检测, 多语言编程

**Comment:** 33 pages, 6 images, 9 tables, Manuscript submitted to a journal
  (2025)

> **TL;DR:** 微调后的代码语言模型能有效检测跨语言错误，小模型表现优于大模型，且跨语言错误与单语言错误有显著区别。

**AI_Comments:** 本文的创新点在于首次系统性地探索了代码语言模型在跨语言错误检测领域的应用。通过构建专门的CLB数据集和开发CLCFinder工具，为该领域提供了宝贵的研究资源和基准。研究结果强调了CLB的独特性及其与单语言错误的区别，对未来跨语言编程工具的开发具有重要指导意义。此外，发现小型模型表现优于大型模型，为资源受限环境下的部署提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 多语言编程日益普及，但其引入的跨语言错误（CLBs）难以被现有单语言错误检测工具发现。

**Method:** 开发了CLCFinder工具，构建了一个包含三种PL组合和九种交互类型的CLB数据集。在此数据集上微调了13个预训练代码语言模型，并评估了数据集大小、token序列长度和代码注释的影响。

**Result:** 微调前所有CodeLMs表现差，微调后均有提升，UniXcoder-base表现最佳（F1=0.7407）。小型微调CodeLMs表现优于大型CodeLMs。在单语言错误数据集上微调的CodeLMs在CLB检测上表现不佳。增加微调数据集大小显著提升性能，而更长的token序列不一定提升性能。代码注释的影响因模型而异。

**Conclusion:** 代码语言模型通过微调可以有效检测跨语言错误，且跨语言错误与单语言错误具有显著区别，需要专门的方法来处理。

> **ai_Abstract:** 本文研究了预训练代码语言模型在检测跨语言错误（CLBs）方面的潜力。研究团队开发了CLCFinder工具并构建了一个包含多语言组合的CLB数据集。他们在此数据集上微调了13个CodeLMs，发现微调后模型性能显著提升，特别是小型模型表现优异。研究还表明，CLBs与单语言错误有本质区别，需要专门的检测方法。

> **摘要翻译:** 多语言编程涉及在单个项目中结合使用多种编程语言（PLs），因其优势而日益普及。然而，它引入了跨语言错误（CLBs），这些错误源于不同编程语言之间的交互，且难以被单语言错误检测工具检测到。本文研究了预训练代码语言模型（CodeLMs）在CLB检测中的潜力。我们开发了CLCFinder，一个跨语言代码识别工具，并构建了一个CLB数据集，该数据集涉及三种编程语言组合（Python-C/C++、Java-C/C++和Python-Java）以及九种交互类型。我们在此数据集上微调了13个CodeLMs并评估了它们的性能，分析了数据集大小、token序列长度和代码注释的影响。结果表明，所有CodeLMs在微调前表现不佳，但在微调后表现出不同程度的性能提升，其中UniXcoder-base取得了最佳的F1分数（0.7407）。值得注意的是，小型微调CodeLMs往往比大型模型表现更好。在单语言错误数据集上微调的CodeLMs在CLB检测上表现不佳，这表明CLBs与单语言错误之间存在区别。此外，增加微调数据集大小显著提高了性能，而更长的token序列不一定能提高模型性能。代码注释的影响因模型而异。一些微调CodeLMs的性能得到了改善，而另一些则表现出性能下降。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [939] [CodeEvo: Interaction-Driven Synthesis of Code-centric Data through Hybrid and Iterative Feedback](https://arxiv.org/abs/2507.22080)
> *CodeEvo：通过混合迭代反馈进行交互驱动的以代码为中心的数据合成*

*Qiushi Sun, Jinyang Gong, Lei Li, Qipeng Guo, Fei Yuan* | **Category: cs.SE, cs.AI, cs.CL** | **Updated: 2025-07-25**

**Keywords:** 代码生成, LLM, 数据合成, 混合反馈, 迭代交互

**Comment:** Work in progress

> **TL;DR:** CodeEvo是一个通过LLM代理迭代交互和混合反馈机制合成高质量以代码为中心的数据的框架，其数据显著优于现有基线。

**AI_Comments:** CodeEvo的创新之处在于其交互式、代理驱动的数据合成范式和混合反馈机制，这解决了传统合成数据缺乏验证和质量控制的问题。该方法通过模拟人类协作编程过程，显著提高了合成数据的质量和实用性，对于提升代码生成LLM的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高质量指令-代码对对于训练代码生成LLM至关重要，但手动数据昂贵且规模有限。现有合成方法缺乏严格的数据验证，导致合成数据不接地气、重复或过于简单。

**Method:** CodeEvo是一个受协作编程启发的框架，通过两个LLM代理（Coder和Reviewer）之间的迭代交互来合成代码数据。Coder生成候选代码和测试用例，Reviewer通过产生新指令和反馈来指导合成过程。引入了结合编译器确定性和代理生成灵活性的混合反馈机制，实现自动质量控制。

**Result:** 在CodeEvo数据上微调的模型在各种难度的代码生成基准测试中显著优于现有基线。深入分析提供了有效以代码为中心的数据合成的见解。

**Conclusion:** CodeEvo通过其独特的交互式合成和混合反馈机制，能够有效生成高质量的以代码为中心的数据，显著提升了代码生成LLM的性能。

> **ai_Abstract:** CodeEvo是一个创新的框架，旨在解决高质量代码-指令对数据获取的挑战。它通过模拟协作编程，利用两个LLM代理（Coder和Reviewer）进行迭代交互，并结合了编译器确定性和LLM生成灵活性的混合反馈机制，自动合成以代码为中心的数据。实验证明，基于CodeEvo数据训练的模型在代码生成任务上表现优于现有基线，为高效的代码数据合成提供了新方法。

> **摘要翻译:** 获取高质量的指令-代码对对于训练用于代码生成的大型语言模型（LLM）至关重要。手动整理的数据成本高昂且规模固有受限，这促使了以代码为中心的合成方法的发展。然而，当前的方法要么侧重于增强现有代码，要么依赖预定义的启发式方法，两者都缺乏严格的数据验证，导致合成数据不不接地气、重复或过于简单。受协作编程实践的启发，我们提出了CodeEvo，这是一个通过两个LLM代理（一个Coder，根据给定指令生成候选代码和测试用例；一个Reviewer，通过产生新指令和反馈来指导合成过程）之间的迭代交互来合成代码数据的框架。我们进一步引入了一种混合反馈机制，该机制结合了编译器的确定性与代理的生成灵活性，从而在整个合成过程中实现了自动质量控制。大量的实验表明，在CodeEvo数据上进行微调的模型在各种难度的代码生成基准测试中显著优于现有基线。深入分析从多个角度提供了关于有效以代码为中心的数据合成的见解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [256] [Half-life of Youtube News Videos: Diffusion Dynamics and Predictive Factors](https://arxiv.org/abs/2507.21187)
> *YouTube新闻视频的半衰期：传播动力学和预测因素*

*Anahit Sargsyan, Hridoy Sankar Dutta, Juergen Pfeffer* | **Category: cs.SI** | **Updated: 2025-07-27**

**Keywords:** YouTube新闻视频, 半衰期, 传播动力学, 预测因素, 可解释AI

**Comment:** To be published in International Conference on Machine Learning,
  Optimization, and Data Science (LOD 2025)

> **TL;DR:** 研究了YouTube新闻视频在24小时内的早期传播模式和半衰期，并预测了其延迟。

**AI_Comments:** 这项研究通过首次量化YouTube新闻视频的24小时半衰期，填补了对短期传播动态研究的空白。其创新之处在于引入了大规模跨国数据集，并结合了统计、深度学习和可解释AI技术来预测和解释传播速度。研究成果对于理解在线新闻传播、舆论形成以及内容推荐机制具有重要意义。数据集和代码的公开也有助于推动后续研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究对YouTube新闻视频的短期传播趋势关注有限，但其消费显著影响公众舆论和政治叙事。

**Method:** 引入并分析了一个包含超过50,000个视频的丰富数据集，涵盖75个国家和六大洲。量化评估了24小时半衰期并识别了独特的传播模式。训练并对比了6种基于统计和深度学习技术的模型来预测半衰期延迟。使用可解释AI（XAI）技术调查了视频和频道相关预测因素的重要性。

**Result:** YouTube新闻视频的平均24小时半衰期约为7小时，在国家内部和国家之间存在显著差异，范围从2小时到15小时。成功预测了新闻视频24小时半衰期的延迟。

**Conclusion:** YouTube新闻视频的早期传播具有可量化的半衰期，并且可以通过多种模型预测其延迟，视频和频道相关因素是重要的预测指标。

> **ai_Abstract:** 本文研究了YouTube新闻视频在发布后24小时内的早期传播动态和半衰期。通过分析一个包含5万多个视频的跨国数据集，研究发现平均24小时半衰期约为7小时，且存在显著地域差异。此外，研究还利用统计和深度学习模型预测了半衰期的延迟，并使用可解释AI技术评估了视频和频道相关预测因素的重要性。

> **摘要翻译:** YouTube新闻视频的消费显著影响公众舆论和政治叙事。虽然先前的研究已经考察了YouTube新闻视频在较长时间内的传播动态，但对短期趋势的关注有限。本文研究了YouTube新闻视频的早期传播模式和分散速率，重点关注前24小时。为此，我们引入并分析了一个包含来自75个国家和六大洲的50,000多个视频的丰富数据集。我们首次对YouTube新闻视频的24小时半衰期进行了定量评估，并确定了其独特的传播模式。研究结果显示，平均24小时半衰期约为7小时，在国家内部和国家之间存在显著差异，范围从最短的2小时到最长的15小时。此外，我们探讨了预测新闻视频24小时半衰期延迟的问题。利用所提供的数据集，我们训练并对比了6种基于统计和深度学习技术的不同模型的性能。对模型间预测结果的差异进行了追溯和分析。最后，我们通过可解释AI（XAI）技术调查了视频和频道相关预测因素的重要性。数据集、分析代码库和训练好的模型已在http://bit.ly/3ILvTLU发布，以促进该领域的进一步研究。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [315] [How Growing Toxicity Manifests: A Topic Trajectory Analysis of U.S. Immigration Discourse on Social Media](https://arxiv.org/abs/2507.21418)
> *增长的毒性如何显现：美国社交媒体移民讨论的话题轨迹分析*

*Una Joh, Yiqi Li, Jeff Hemsley* | **Category: cs.SI, J.4; K.4.2; I.2.7** | **Updated: 2025-07-29**

**Keywords:** 社交媒体, 移民讨论, 毒性, 话题轨迹, 话题分析

**Comment:** This is the preprint of a paper accepted at ICWSM 2026

> **TL;DR:** 该研究利用400万条X帖子，结合用户和话题中心方法，分析了美国社交媒体上移民讨论中毒性变化如何表现为话题转移。结果显示，毒性增加的用户转向恐慌和基于恐惧的话题，而毒性减少的用户转向法律和政策主题。

**AI_Comments:** 该论文的创新之处在于结合了分层话题发现和轨迹分析，提供了一个新颖且可复制的方法来研究大规模社会议题中的动态对话和毒性演变。其重要性在于揭示了在线毒性与话题内容之间的具体关联，为理解和可能干预网络讨论中的两极分化提供了见解。

<details>
  <summary>Details</summary>

**Motivation:** 在线公共领域中，关于移民的讨论常常变得日益分裂，并伴随着有害语言和两极分化。本研究旨在探究毒性转变如何表现为话题转变。

**Method:** 研究使用了来自X的400万条帖子，结合了用户中心和话题中心的方法。话题发现方法利用基于指令的嵌入和递归HDBSCAN，发现了美国移民讨论中的157个细粒度子话题。研究重点关注四组用户：毒性增加的用户、毒性减少的用户以及两个没有显著毒性趋势但毒性水平匹配的参考组。通过将每个发帖历史视为通过五维话题空间的轨迹，使用置换MANOVA比较平均组轨迹。

**Result:** 研究发现，毒性增加的用户倾向于转向危言耸听、基于恐惧的框架，而毒性减少的用户则转向法律和政策主题。这两种模式都与各自的参考组存在统计学上的显著差异。

**Conclusion:** 本研究结合分层话题发现和轨迹分析的流程，为大规模研究社会问题动态对话提供了一种可复制的方法。

> **ai_Abstract:** 本研究分析了美国社交媒体上移民讨论中不断增长的毒性如何表现为话题转移。通过分析400万条X帖子，研究团队采用了一种结合用户和话题中心的方法，利用基于指令的嵌入和递归HDBSCAN发现了157个细粒度子话题。研究将用户分为毒性增加、毒性减少和两个参考组，并使用轨迹分析比较了他们的平均话题轨迹。结果显示，毒性增加的用户倾向于恐慌和基于恐惧的话题，而毒性减少的用户则转向法律和政策主题。该方法提供了一个可复制的框架，用于大规模研究社会问题的动态对话。

> **摘要翻译:** 在网络公共领域中，关于移民的讨论常常变得日益分裂，并伴随着有害语言和两极分化。我们利用六个月内的400万条X帖子，结合用户和话题中心的方法，研究毒性变化如何表现为话题转变。我们的话题发现方法利用基于指令的嵌入和递归HDBSCAN，揭示了美国移民讨论中的157个细粒度子话题。我们重点关注四组用户：(1)毒性增加的用户，(2)毒性减少的用户，以及两个没有显著毒性趋势但毒性水平匹配的参考组。我们将每个发帖历史视为通过五维话题空间的轨迹，并使用置换MANOVA比较平均组轨迹。我们的发现表明，毒性增加的用户倾向于转向危言耸听、基于恐惧的框架，而毒性减少的用户则转向法律和政策主题。这两种模式都与各自的参考组存在统计学上的显著差异。这个结合了分层话题发现和轨迹分析的流程，为大规模研究社会问题动态对话提供了一种可复制的方法。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [336] [Masked Language Models are Good Heterogeneous Graph Generalizers](https://arxiv.org/abs/2506.06157)
> *掩码语言模型是优秀的异构图泛化器*

*Jinyu Yang, Cheng Yang, Shanyuan Cui, Zeyuan Guo, Liangwei Yang, Muhan Zhang, Zhiqiang Zhang, Chuan Shi* | **Category: cs.SI, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 异构图, 掩码语言模型, 泛化, 元路径, 跨领域学习

**Comment:** 

> **TL;DR:** 提出MLM4HG方法，利用掩码语言模型和元路径文本序列，解决异构图神经网络在跨域和多任务泛化能力差的问题，并在实验中表现出优越的泛化性能。

**AI_Comments:** 该论文提出了一种新颖的方法，通过将异构图数据转换为语言模型可处理的文本格式，并利用掩码语言模型（MLM）的强大泛化能力来解决异构图学习中的跨域和多任务泛化难题。其创新点在于避免了异构图神经网络（HGNNs）和大型语言模型（LLMs）之间嵌入空间不一致的问题，并通过统一的任务范式提升了模型的泛化性。这种将图结构信息“语言化”的思路为异构图学习提供了一个有前景的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 异构图神经网络（HGNNs）在捕获异构图（HGs）的结构和语义信息方面表现出色，但在跨领域和跨任务泛化方面存在困难。现有结合HGNNs和大型语言模型（LLMs）的方法，由于HGNNs和LLMs之间嵌入空间的不一致以及HG令牌通常来源于节点级任务，限制了模型的泛化能力。

**Method:** 提出MLM4HG方法。该方法引入基于元路径的文本序列来提取异构图中的结构和语义信息，并设计定制的文本模板将不同的图任务统一为完形填空式的“掩码”令牌预测范式。具体地，MLM4HG首先将来自不同领域的异构图基于元路径转换为文本，然后将其与统一的任务文本结合形成一个基于异构图的语料库。最后，该语料库被送入预训练语言模型进行微调，并限制目标词汇表，从而使微调后的语言模型能够泛化到未见的异构图。

**Result:** 在四个真实世界数据集上进行的广泛的跨领域和多任务实验表明，MLM4HG在少样本和零样本场景下均优于现有最先进方法的泛化性能。

**Conclusion:** MLM4HG通过将异构图转换为文本并利用掩码语言模型进行训练，有效提升了异构图模型在跨域和多任务场景下的泛化能力。

> **ai_Abstract:** 本文提出了一种名为MLM4HG的基于掩码语言建模的方法，旨在解决异构图神经网络在跨领域和多任务泛化能力上的不足。MLM4HG通过将异构图中的结构和语义信息转换为基于元路径的文本序列，并利用定制的文本模板将图任务统一为掩码预测问题，从而使得预训练语言模型能够进行微调并泛化到未见的异构图。实验结果表明，MLM4HG在多种泛化场景下均显著优于现有SOTA方法。

> **摘要翻译:** 异构图神经网络（HGNNs）擅长捕获异构图（HGs）中的结构和语义信息，但在跨领域和跨任务泛化方面表现不佳。随着大型语言模型（LLMs）的快速发展，最近一项研究探索了将HGNNs与LLMs结合以实现可泛化的异构图学习。然而，这种方法通常使用HGNNs将结构信息编码为HG令牌，并且HGNNs和LLMs之间嵌入空间的差异已被证明会影响LLM对HG的理解。此外，由于这些HG令牌通常来源于节点级任务，模型在跨任务泛化方面的能力仍然有限。
为此，我们提出了一种简单而有效的基于掩码语言建模的方法，称为MLM4HG。MLM4HG引入基于元路径的文本序列而不是HG令牌来提取异构图中固有的结构和语义信息，并设计定制的文本模板将不同的图任务统一为连贯的完形填空式“掩码”令牌预测范式。具体而言，MLM4HG首先基于元路径将来自不同领域的异构图转换为文本，然后将其与统一的任务文本结合形成一个基于HG的语料库。此外，该语料库被送入预训练语言模型进行微调，并限制目标词汇表，从而使微调后的语言模型能够泛化到未见的异构图。在四个真实世界数据集上进行的广泛的跨领域和多任务实验表明，MLM4HG在少样本和零样本场景下均优于现有最先进方法的泛化性能。我们的代码可在https://github.com/BUPT-GAMMA/MLM4HG 获取。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [378] [Who's important? -- SUnSET: Synergistic Understanding of Stakeholder, Events and Time for Timeline Generation](https://arxiv.org/abs/2507.21903)
> *谁是重要的？——SUnSET：利益相关者、事件和时间的协同理解用于时间线生成*

*Tiviatis Sim, Kaiwen Yang, Shen Xin, Kenji Kawaguchi* | **Category: cs.SI, cs.CL, cs.IR** | **Updated: 2025-07-29**

**Keywords:** 时间线摘要, 利益相关者, 大型语言模型, 新闻分析, 相关性度量

**Comment:** 

> **TL;DR:** SUnSET提出了一种新的时间线摘要框架，通过利用大型语言模型和利益相关者排名来衡量利益相关者和相关事件的重要性，并超越了现有基线。

**AI_Comments:** 这项研究的创新之处在于其SUnSET框架，特别强调了利益相关者在新闻事件时间线生成中的关键作用。通过引入基于利益相关者的排名和利用LLM构建SET三元组，它弥补了现有方法仅关注文本内容而忽略人际关系网络的不足。其超越SOTA的成果表明了该方法的有效性和重要性，对于提升新闻理解和信息追踪具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有新闻摘要方法主要基于文章文本内容，未能有效分析事件中涉及的各方。随着新闻报道日益全球化和去中心化，追踪多来源相关事件面临挑战。因此，需要一个新颖的框架来衡量利益相关者的重要性以及相关事件的联系。

**Method:** 提出SUnSET（利益相关者、事件和时间的协同理解）框架，用于时间线摘要任务。该方法利用大型语言模型（LLMs）构建SET三元组，并引入了基于利益相关者的排名来构建一个可扩展的“相关性”度量。

**Result:** 实验结果表明，SUnSET的表现优于所有先前的基线，并成为了新的最先进技术，突出了新闻文章中利益相关者信息的重要性。

**Conclusion:** 利益相关者信息在新闻文章中具有显著影响，SUnSET框架能够有效提升时间线摘要的性能。

> **ai_Abstract:** 该研究针对现有新闻摘要方法未能有效分析事件中利益相关者的问题，提出了SUnSET框架。该框架利用大型语言模型构建利益相关者、事件和时间（SET）三元组，并通过引入基于利益相关者的排名来建立“相关性”度量，旨在提高时间线摘要的准确性。实验证明，SUnSET超越了所有现有基线，成为新的最先进技术，强调了新闻文章中利益相关者信息的重要性。

> **摘要翻译:** 随着新闻报道在全球范围内的日益普及和在线去中心化，追踪多个来源的相关事件带来了巨大的挑战。现有的新闻摘要方法通常利用大型语言模型和基于文章摘要的图方法。然而，这并不有效，因为它只考虑了日期相似文章的文本内容来理解事件的要点。为了弥补对所涉各方分析的不足，提出一个新颖的框架来衡量利益相关者的重要性以及通过相关实体连接相关事件至关重要。因此，我们提出了SUnSET：利益相关者、事件和时间的协同理解，用于时间线摘要（TLS）任务。我们利用强大的大型语言模型（LLMs）构建SET三元组，并引入了基于利益相关者的排名来构建一个“相关性”度量，该度量可以扩展到一般情况。我们的实验结果超越了所有先前的基线，并成为了新的最先进技术，突出了新闻文章中利益相关者信息的影响。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [626] [Demystifying Misconceptions in Social Bots Research](https://arxiv.org/abs/2303.17251)
> *揭秘社交机器人研究中的误解*

*Stefano Cresci, Kai-Cheng Yang, Angelo Spognardi, Roberto Di Pietro, Filippo Menczer, Marinella Petrocchi* | **Category: cs.SI, cs.AI, cs.CY, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 社交机器人, 研究方法, 误解, 在线操纵, 偏见

**Comment:** 

> **TL;DR:** 本文讨论并揭示了社交机器人研究中普遍存在的偏见、夸大结果和误解，旨在促进更严谨、公正和负责任的研究方法。

**AI_Comments:** 本文的创新之处在于其批判性地审视了社交机器人研究领域内普遍存在的偏见和误解，这对确保该研究领域的科学严谨性和可靠性至关重要。它不仅指出了问题，还提供了解决这些问题的方向，对于提高该领域研究的质量和公信力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 社交机器人研究中存在广泛的偏见、夸大其词的结果和误解，导致模糊性、不切实际的期望和看似无法调和的发现。克服这些问题对于确保可靠的解决方案和重申科学方法的有效性至关重要。

**Method:** 本文讨论了影响当前社交机器人研究的一系列重要方法论和概念问题，并引用近期研究的例子进行说明。更重要的是，本文揭示了常见的误解，并反驳了社交机器人研究中普遍存在的谬误论点，同时为未来的研究提供了健全的方法论方向。

**Result:** 分析揭示了需要以严谨、公正和负责任的方式讨论在线虚假信息和操纵研究。通过识别和驳斥社交机器人研究支持者和反对者使用的常见谬误论点，本文加强了这一努力，并为未来的研究提供了健全的方法。

**Conclusion:** 本文旨在通过揭示和纠正社交机器人研究中的常见误解和偏见，从而促进该领域研究的严谨性、可靠性和科学有效性。

> **ai_Abstract:** 本文旨在解决社交机器人研究中普遍存在的偏见、夸大结果和误解，这些问题导致研究的模糊性和不可靠性。通过讨论方法论和概念问题，并揭示常见误解，本文强调了以严谨、公正和负责任的方式进行在线虚假信息和操纵研究的必要性。文章通过反驳谬误论点并为未来研究提供健全方法来支持这一目标。

> **摘要翻译:** 对社交机器人的研究旨在推进知识并为最受争议的在线操纵形式之一提供解决方案。然而，社交机器人研究受到普遍存在的偏见、夸大其词的结果和误解的困扰，这些问题为模糊性、不切实际的期望和看似无法调和的发现奠定了基础。克服这些问题对于确保可靠的解决方案和重申科学方法的有效性至关重要。在此，我们讨论了一系列影响当前社交机器人研究的重要方法论和概念问题，并用近期研究的例子逐一说明。更重要的是，我们揭示了常见的误解，解决了关于社交机器人研究讨论方式的基本问题。我们的分析表明，需要以严谨、公正和负责任的方式讨论关于在线虚假信息和操纵的研究。本文通过识别和驳斥社交机器人研究支持者和反对者使用的常见谬误论点，并为未来的研究提供健全的方法论方向，从而加强了这一努力。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [695] [Scalable Signed Exponential Random Graph Models under Local Dependence](https://arxiv.org/abs/2507.07660)
> *可扩展的局部依赖符号指数随机图模型*

*Marc Schalberger, Cornelius Fritz* | **Category: cs.SI, stat.CO** | **Updated: 2025-07-29**

**Keywords:** 符号网络, 随机图模型, 局部依赖, 可扩展性, 结构平衡

**Comment:** 

> **TL;DR:** 提出了一种结合SBM和ERGM的、基于局部依赖的可扩展方法，用于分析大型有符号网络，解决了传统方法的局限性。

**AI_Comments:** 这篇论文的创新点在于将局部依赖性引入到符号随机图模型中，并结合了SBM和ERGM的优势，从而解决了传统模型在处理大规模复杂有符号网络时的可扩展性和全局依赖假设不现实的问题。其两步分解和估计方法提供了一个实用的解决方案，对于理解社交网络中的合作与冲突关系具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统网络分析方法（如SBM和ERGM）在处理包含合作、中立和冲突等复杂关系的真实世界大型有符号网络时面临挑战，特别是在网络规模增长时，其同质性假设和全局依赖变得不切实际。

**Method:** 提出了一种新颖的方法，通过结合SBM和ERGM的优点并缓解其缺点来解决问题。该方法引入了基于非重叠块的局部依赖，并采用两步过程：首先，使用SBM近似将网络分解为子网络；然后，使用ERGM方法估计参数。

**Result:** 该方法在大型合成网络上得到验证，并成功应用于一个包含数千名编辑的有符号维基百科网络。通过使用局部依赖，发现了与结构平衡理论一致的模式。

**Conclusion:** 该研究提出了一种有效且可扩展的局部依赖符号指数随机图模型，能够更好地分析和理解大型有符号网络中的复杂关系，并揭示了结构平衡等网络模式。

> **ai_Abstract:** 本文提出了一种可扩展的符号指数随机图模型，旨在克服传统网络分析方法在处理大型有符号网络时的局限性。该方法结合了随机块模型（SBM）和指数族随机图模型（ERGM）的优点，引入了基于非重叠块的局部依赖性。通过将网络分解为子网络并分步估计参数，该模型能够有效分析包含正负关系的复杂网络。在合成数据和维基百科网络上的应用验证了其有效性，并发现了与结构平衡理论一致的模式。

> **摘要翻译:** 传统网络分析侧重于二元边，而现实世界的关​​系则更为微妙，包含合作、中立和冲突。社交媒体讨论中负边的兴起激发了人们对分析有符号交互的兴趣，尤其是在两极分化的辩论中。然而，数字网络生成的大量数据对随机块模型（SBM）和指数族随机图模型（ERGM）等传统方法提出了挑战，特别是由于同质性假设和全局依赖性，这随着网络规模的增长变得越来越不切实际。为了解决这个问题，我们提出了一种新颖的方法，通过结合SBM和ERGM的优点并缓解其缺点，通过结合基于非重叠块的局部依赖性。我们的方法涉及一个两步过程：首先，使用SBM近似将网络分解为子网络，然后使用ERGM方法估计参数。我们在大型合成网络上验证了我们的方法，并将其应用于一个由数千名编辑组成的有符号维基百科网络。通过使用局部依赖性，我们发现了与结构平衡理论一致的模式。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [762] [Quotegraph: A Social Network Extracted from Millions of News Quotations](https://arxiv.org/abs/2507.17626)
> *Quotegraph：一个从数百万新闻引文中提取的社交网络*

*Marko Čuljak, Robert West, Andreas Spitz, Akhil Arora* | **Category: cs.SI** | **Updated: 2025-07-29**

**Keywords:** Quotegraph, 社交网络, 新闻引文, Wikidata, 计算社会科学

**Comment:** 

> **TL;DR:** Quotegraph是一个从2008年至2020年英文新闻文章中提取的，包含52.8万个节点和863万条边的社交网络，它通过Wikidata丰富了实体信息并包含上下文，旨在为计算社会科学家提供研究公众人物行为的新资源。

**AI_Comments:** Quotegraph的创新之处在于它从新闻引文中构建了一个大规模、上下文丰富的社交网络，这与传统的在线社交网络形成了互补。其语言无关的构建流程也具有重要意义，为未来多语言数据集的创建奠定了基础。该资源对于研究新闻媒体中公众人物的表述和互动具有巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在创建一个大规模的社交网络，作为在线社交网络的补充，以提供对公众人物行为及其在新闻中如何被捕捉的新颖见解。

**Method:** Quotegraph是通过分析2008年至2020年间发布的英文新闻文章中具有说话者归属的引文而构建的。它利用Quotebank语料库，将节点链接到Wikidata以获取详细的生平实体信息，并用引文的上下文信息丰富了关系。网络构建的每个部分都是语言无关的。

**Result:** Quotegraph包含52.8万个独特节点和863万条从说话者指向他们提及的人的定向边。节点链接到Wikidata，提供了国籍、性别和政治派别等详细的生平实体信息。关系还通过引文的上下文信息得到丰富。

**Conclusion:** Quotegraph是计算社会科学家一个引人注目的资源，它补充了在线社交网络，并有潜力对公众人物的行为及其在新闻中的体现提供新的见解。

> **ai_Abstract:** 本论文介绍了Quotegraph，一个从2008年至2020年英文新闻引文中提取的大规模社交网络。该网络包含52.8万个节点和863万条定向边，节点与Wikidata关联以提供丰富的实体信息，并且关系包含上下文信息。该构建方法是语言无关的，可用于构建其他语言的数据集。Quotegraph被视为计算社会科学领域的重要资源，可补充现有在线社交网络，并有望揭示公众人物行为的新见解。

> **摘要翻译:** 我们引入Quotegraph，这是一个新颖的大规模社交网络，它源自2008年至2020年间发布的英文新闻文章中具有说话者归属的引文。Quotegraph包含52.8万个独特节点和863万条定向边，这些边从说话者指向他们提及的人。节点链接到Wikidata中相应的条目，从而使数据集具备详细的生平实体信息，包括国籍、性别和政治派别。由于Quotegraph源自Quotebank（一个庞大的引文语料库），其关系额外富含了它们所出现的上下文信息。网络构建管道的每个部分都与语言无关，从而能够基于非英文新闻语料库构建类似的数据集。我们相信Quotegraph是计算社会科学家一个引人注目的资源，它补充了在线社交网络，并有潜力对公众人物的行为及其在新闻中的体现提供新的见解。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [384] [Load Balancing for AI Training Workloads](https://arxiv.org/abs/2507.21372)
> *AI训练工作负载的负载均衡*

*Sarah McClure, Sylvia Ratnasamy, Scott Shenker* | **Category: cs.NI, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 负载均衡, AI训练, 拥塞控制, 丢包恢复

**Comment:** 

> **TL;DR:** 研究了大型AI训练工作负载的负载均衡算法性能，并探讨了拥塞控制和丢包恢复算法的选择。

**AI_Comments:** 该研究的创新点在于将负载均衡与拥塞控制和丢包恢复算法相结合进行评估，这对于优化AI训练基础设施的性能具有重要意义。局限性在于抽象中未提及具体评估方法或算法细节。

<details>
  <summary>Details</summary>

**Motivation:** 研究大型AI训练工作负载的负载均衡算法性能，以及拥塞控制和丢包恢复算法对负载均衡性能的影响。

**Method:** 通过调查和评估各种负载均衡算法在专用基础设施上的性能，同时考虑拥塞控制和丢包恢复算法。

**Result:** 负载均衡的性能取决于拥塞控制和丢包恢复算法。

**Conclusion:** 本研究为拥塞控制和丢包恢复算法的适当选择提供了启示。

> **ai_Abstract:** 本文调查了大型AI训练工作负载的负载均衡算法性能。研究发现，负载均衡的性能与拥塞控制和丢包恢复算法密切相关，并为这些关键设计提供了选择建议。

> **摘要翻译:** 我们研究了在专用基础设施上运行的大规模AI训练工作负载的各种负载均衡算法的性能。负载均衡的性能取决于拥塞控制和丢包恢复算法，因此我们的评估也为这些设计的适当选择提供了启示。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [444] [Deep Reinforcement Learning-based Cell DTX/DRX Configuration for Network Energy Saving](https://arxiv.org/abs/2507.21385)
> *深度强化学习在小区DTX/DRX配置中实现网络节能*

*Wei Mao, Lili Wei, Omid Semiari, Shu-ping Yeh, Hosein Nikopour* | **Category: cs.NI, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 深度强化学习, 小区DTX/DRX, 网络节能, 5G, QoS

**Comment:** 7 pages, 7 figures

> **TL;DR:** 利用深度强化学习为5G小区DTX/DRX配置提供最优方案，以平衡节能和数据包延迟，实现高达45%的节能且QoS下降不超过1%。

**AI_Comments:** 该研究创新性地将深度强化学习应用于5G网络节能配置，特别是解决了DTX/DRX技术中节能与延迟的权衡问题。通过结合DQN和上下文多臂老虎机模型，并设计平滑奖励函数，提升了AI代理在复杂动态网络环境下的适应性和性能。其重要性在于为未来5G及更高代移动通信网络的能效管理提供了智能化的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 5G的3GPP Release 18小区DTX/DRX是重要的网络节能特性，但会增加数据包延迟。问题在于如何优化配置以在节能和延迟之间取得平衡，尤其是在不同网络和流量条件下。

**Method:** 采用深度强化学习 (DRL) 框架训练AI代理。具体设计包括：1) 基于上下文多臂老虎机 (CB) 模型实现的深度Q网络 (DQN) 学习算法；2) 利用理论最优但不连续奖励函数的平滑近似来设计奖励函数。

**Result:** 模拟结果显示，与不使用小区DTX/DRX的情况相比，该代理可实现高达约45%的节能（取决于流量负载场景），同时始终保持不超过约1%的QoS下降。

**Conclusion:** 通过精心设计的DRL方法，可以训练出一个AI代理，在任何网络和流量条件下选择最佳的小区DTX/DRX配置，从而在最大化节能的同时最小化QoS下降。

> **ai_Abstract:** 本文研究如何利用深度强化学习优化5G网络中小区DTX/DRX的配置，以在节能和数据包延迟之间取得平衡。通过设计基于上下文多臂老虎机模型的深度Q网络和优化的奖励函数，训练了一个AI代理。模拟结果表明，该方法在保持QoS下降不超过1%的同时，可实现高达45%的节能。

> **摘要翻译:** 3GPP Release 18小区不连续传输和接收（cell DTX/DRX）是5G一项重要的网络节能新功能。作为一种时域技术，当流量负载不重时，它会在给定时间内周期性地聚合用户数据传输，以便剩余时间可以保持静默，并启用高级睡眠模式（ASM），从而关闭更多无线组件，为小区节省更多能量。然而，不可避免地，数据包延迟会增加，因为在静默期间不允许传输。本文研究如何配置小区DTX/DRX以最优地平衡节能和数据包延迟，从而对于延迟敏感的流量，在最大限度地节能的同时，将服务质量（QoS）的下降降至最低。由于最佳配置可能因不同的网络和流量条件而异，问题复杂，我们采用深度强化学习（DRL）框架来训练AI代理解决此问题。通过精心设计1）学习算法，该算法在上下文多臂老虎机（CB）模型上实现了深度Q网络（DQN），以及2）奖励函数，该函数利用理论上最优但不连续的奖励函数的平滑近似，我们能够训练出一个AI代理，该代理始终尝试在任何网络和流量条件下选择最佳的小区DTX/DRX配置。模拟结果表明，与不使用小区DTX/DRX的情况相比，我们的代理可以根据流量负载场景实现高达约45%的节能，同时始终保持不超过约1%的QoS下降。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [482] [OpenRASE: Service Function Chain Emulation](https://arxiv.org/abs/2507.22131)
> *OpenRASE：服务功能链仿真*

*Theviyanthan Krishnamohan, Paul Harvey* | **Category: cs.NI, cs.DC, cs.NE** | **Updated: 2025-07-29**

**Keywords:** 服务功能链, 仿真, OpenRASE, 资源分配, Mininet

**Comment:** Accepted to IEEE SoftCom 2025

> **TL;DR:** OpenRASE是一个基于Mininet和Docker的服务功能链（SFC）仿真器，旨在解决现有评估工具的不足，并能测量真实的CPU使用率和延迟，以评估SFC资源分配算法的有效性和实用性。

**AI_Comments:** OpenRASE的创新之处在于其结合了Mininet和Docker，为服务功能链的资源分配算法提供了一个高保真、可扩展且能测量真实网络指标的仿真环境，解决了现有工具的不足。这对于研究和开发更高效的SFC资源管理策略具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 服务功能链（SFC）在可编程计算机网络中至关重要，但其操作面临资源分配和优化挑战，需要新的算法来解决。现有用于评估这些算法的工具存在不准确、保真度低、不可扩展、不灵活或需要额外代码等问题。

**Method:** 本文介绍了名为OpenRASE的服务功能链仿真器，它基于Mininet和Docker构建。OpenRASE旨在动态环境中探索服务功能链的资源分配算法，并允许测量真实的CPU使用率和延迟。文中详细描述了OpenRASE的设计和实现，并讨论了其特性。

**Result:** OpenRASE能够测量真实的CPU使用率和延迟。研究人员利用OpenRASE实验性地评估了两种不同的服务功能链资源分配算法（包括一种在线遗传算法），结果表明OpenRASE在动态网络条件下具有有效性和实用性。

**Conclusion:** OpenRASE仿真器能够有效且实用地评估服务功能链的资源分配算法，尤其是在动态网络条件下，解决了现有评估工具的不足。

> **ai_Abstract:** 本文提出了OpenRASE，一个基于Mininet和Docker的服务功能链（SFC）仿真器，旨在克服现有SFC资源分配算法评估工具的局限性。OpenRASE能够在一个动态环境中测量真实的CPU使用率和延迟，从而有效探索和评估SFC的资源分配算法。通过实验评估两种算法，包括一种在线遗传算法，验证了OpenRASE在动态网络条件下的有效性和实用性。

> **摘要翻译:** 服务功能链（SFC）是提供可编程计算机网络的关键使能技术之一，为网络自主性铺平了道路。然而，这也带来了新的挑战，例如与其操作相关的资源分配和优化，需要新的算法来解决这些挑战。文献中已经使用了各种工具来评估这些算法。然而，这些工具存在不准确、保真度低、不可扩展、不灵活或需要额外代码等问题。本文介绍了一种基于Mininet和Docker的服务功能链仿真器，名为OpenRASE。OpenRASE的目标是在动态环境中探索服务功能链的资源分配算法，允许测量真实的CPU使用率和延迟。我们描述了OpenRASE的设计和实现，并讨论了其特性。我们还实验性地评估了两种不同的算法，以解决SFC资源分配的挑战，其中包括一种在线遗传算法，利用OpenRASE展示了其在动态网络条件下的有效性和实用性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [510] [Generalized few-shot transfer learning architecture for modeling the EDFA gain spectrum](https://arxiv.org/abs/2507.21728)
> *用于建模EDFA增益谱的广义少样本迁移学习架构*

*Agastya Raj, Zehao Wang, Tingjun Chen, Daniel C Kilper, Marco Ruffini* | **Category: cs.NI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** EDFA增益谱, 少样本学习, 迁移学习, 半监督神经网络, 光网络

**Comment:** This is a preprint of a paper accepted and published in the Journal
  of Optical Communications and Networking (JOCN). The final published version
  is available at: https://doi.org/10.1364/JOCN.560987

> **TL;DR:** 该研究提出了一种基于半监督自归一化神经网络（SS-NN）的广义少样本迁移学习架构，用于准确建模掺铒光纤放大器（EDFA）的增益谱。该方法显著减少了所需的测量次数，同时实现了比基准方法更低的误差和更好的误差分布。

**AI_Comments:** 该论文的创新点在于提出了一个结合半监督学习和少样本迁移学习的通用架构，用于解决EDFA增益谱建模中数据稀缺和异构性问题。通过引入协方差匹配损失来处理异构迁移学习中的特征不对齐，提高了模型的泛化能力和实用性。这对于优化光网络性能，特别是在多供应商环境中，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确建模掺铒光纤放大器（EDFA）的增益谱对于优化光网络性能至关重要，尤其是在网络向多供应商解决方案发展时。

**Method:** 本文提出了一种基于半监督自归一化神经网络（SS-NN）的广义少样本迁移学习架构。该模型利用EDFA内部特征（如VOA输入或输出功率和衰减）来改进增益谱预测。SS-NN模型采用两阶段训练策略：包括带噪声增强测量的无监督预训练和带自定义加权MSE损失的监督微调。此外，该框架通过迁移学习（TL）技术进行了扩展，支持跨助推器、前置放大器和ILA EDFA的同构（相同特征空间）和异构（不同特征集）模型适应。为了解决异构TL中的特征不匹配问题，引入了协方差匹配损失以对齐源域和目标域之间的二阶特征统计。

**Result:** 在COSMOS和Open Ireland测试平台上的26个EDFA进行的广泛实验表明，与基准方法相比，所提出的方法显著减少了系统测量要求，同时实现了更低的平均绝对误差和改进的误差分布。

**Conclusion:** 所提出的广义少样本迁移学习架构能够有效且准确地建模EDFA增益谱，显著减少了所需的测量数据量，并提升了预测精度。

> **ai_Abstract:** 本研究提出了一种基于半监督自归一化神经网络（SS-NN）的广义少样本迁移学习架构，用于精确建模EDFA增益谱。该模型利用EDFA内部特征，通过两阶段训练（无监督预训练和监督微调）进行优化。此外，该框架结合了同构和异构迁移学习技术，并通过协方差匹配损失处理异构特征不匹配。实验证明，该方法显著减少了测量需求，并实现了比现有方法更低的预测误差和更优的误差分布。

> **摘要翻译:** 掺铒光纤放大器（EDFA）增益谱的精确建模对于优化光网络性能至关重要，尤其是在网络向多供应商解决方案演进时。在这项工作中，我们提出了一种基于半监督自归一化神经网络（SS-NN）的广义少样本迁移学习架构，该架构利用EDFA内部特征（例如VOA输入或输出功率和衰减）来改进增益谱预测。我们的SS-NN模型采用两阶段训练策略，包括使用噪声增强测量进行无监督预训练和使用自定义加权MSE损失进行监督微调。此外，我们通过迁移学习（TL）技术扩展了该框架，实现了跨助推器、前置放大器和ILA EDFA的同构（相同特征空间）和异构（不同特征集）模型适应。为了解决异构TL中的特征不匹配问题，我们引入了协方差匹配损失以对齐源域和目标域之间的二阶特征统计。在COSMOS和Open Ireland测试平台上的26个EDFA进行的广泛实验表明，所提出的方法显著减少了系统测量要求，同时实现了比基准方法更低的平均绝对误差和改进的误差分布。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [570] [RRTO: A High-Performance Transparent Offloading System for Model Inference in Mobile Edge Computing](https://arxiv.org/abs/2507.21739)
> *RRTO：一种面向移动边缘计算模型推理的高性能透明卸载系统*

*Zekai Sun, Xiuxian Guan, Zheng Lin, Yuhao Qing, Haoze Song, Zihan Fang, Zhe Chen, Fangming Liu, Heming Cui, Wei Ni, Jun Luo* | **Category: cs.NI** | **Updated: 2025-07-29**

**Keywords:** 移动边缘计算, 模型推理, 透明卸载, 记录/回放, 性能优化

**Comment:** 15 pages, 12 figures,

> **TL;DR:** RRTO是一种高性能透明卸载系统，通过记录/回放机制消除重复RPC，显著降低了移动边缘计算中模型推理的延迟和能耗，且无需修改源代码。

**AI_Comments:** RRTO的创新点在于其记录/回放机制和操作符序列搜索算法，解决了透明卸载中传输延迟的痛点，同时保持了广泛的兼容性。其性能提升显著，且无需修改源代码，极大地降低了ML应用在移动边缘部署的门槛，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在资源受限的移动设备上部署机器学习应用面临计算资源有限和平台兼容性差的挑战。现有移动边缘计算（MEC）中的卸载推理方法（透明和非透明）各有优缺点，非透明方法性能高但需修改代码，透明方法兼容性好但引入显著传输延迟。

**Method:** 提出RRTO系统，引入记录/回放机制，利用ML模型中静态操作符序列消除重复的远程过程调用（RPCs）。为可靠识别此序列，RRTO集成了一种新颖的操作符序列搜索算法，该算法检测重复模式，过滤初始化噪声，并通过两级策略加速匹配。

**Result:** RRTO与最先进的透明方法相比，在每次推理的延迟和能耗方面均实现了高达98%的显著降低，并且无需任何源代码修改即可获得与非透明方法相当的结果。

**Conclusion:** RRTO成功地在不修改源代码的情况下，实现了移动边缘计算模型推理的高性能透明卸载，解决了现有透明卸载方法传输延迟大的问题，并达到了与非透明方法相当的性能。

> **ai_Abstract:** RRTO是一种针对移动边缘计算（MEC）模型推理设计的高性能透明卸载系统。它通过引入记录/回放机制和新颖的操作符序列搜索算法，有效消除了现有透明卸载方法中因重复远程过程调用（RPC）导致的传输延迟。实验证明，RRTO在不修改源代码的情况下，与现有透明方法相比，显著降低了推理延迟和能耗，并达到了与非透明方法相当的性能。

> **摘要翻译:** 将机器学习（ML）应用程序部署到资源受限的移动设备上仍然具有挑战性，这归因于有限的计算资源和糟糕的平台兼容性。尽管移动边缘计算（MEC）提供了基于卸载的推理范式，使用GPU服务器，但现有方法分为非透明和透明方法，后者需要修改源代码。非透明卸载实现了高性能，但需要侵入式代码修改，限制了与各种应用程序的兼容性。相反，透明卸载提供了广泛的兼容性，但由于每个操作符的远程过程调用（RPC）引入了显著的传输延迟。为了克服这一限制，我们提出了RRTO，这是第一个专为MEC推理设计的高性能透明卸载系统。RRTO引入了一种记录/回放机制，该机制利用ML模型中的静态操作符序列来消除重复的RPC。为了可靠地识别此序列，RRTO集成了一种新颖的操作符序列搜索算法，该算法检测重复模式，过滤初始化噪声，并通过两级策略加速匹配。评估表明，与最先进的透明方法相比，RRTO在每次推理延迟和能耗方面均实现了高达98%的显著降低，并且无需任何源代码修改即可获得与非透明方法相当的结果。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [773] [Wall-Proximity Matters: Understanding the Effect of Device Placement with Respect to the Wall for Indoor Wi-Fi Sensing](https://arxiv.org/abs/2412.13208)
> *墙体邻近性很重要：理解室内Wi-Fi感知中设备相对于墙体放置的影响*

*He Wang, Yunpeng Ge, Ivan Wang-Hei Ho* | **Category: cs.NI** | **Updated: 2025-07-29**

**Keywords:** Wi-Fi感知, 墙体邻近性, 感知覆盖, 部署策略, 理论模型

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本文提出一个理论模型，解释了墙体-设备距离对Wi-Fi感知覆盖范围的影响，并通过实验证明将设备放置在墙体附近可以显著扩大感知覆盖范围，并提高呼吸监测和人群计数精度。

**AI_Comments:** 该论文的创新点在于首次系统地探讨了墙体邻近性对室内Wi-Fi感知性能的影响，并提出了一个理论模型来解释和利用这一现象。通过结合墙体反射路径，该研究突破了传统Wi-Fi感知仅关注视线路径的局限性，为扩大感知覆盖范围提供了新的视角。其重要性在于为未来Wi-Fi传感系统的部署提供了实用的优化策略，有望提升现有应用的准确性和鲁棒性。实验结果证明了该方法的有效性，尤其是在人群计数方面的显著提升，显示了其潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Wi-Fi感知在多种应用中得到广泛探索，但其实际部署受到不稳定的感知性能和有限的无线感知覆盖知识的阻碍。现有工作忽略了墙体对室内动态感知能力的影响，因此本文旨在填补这一空白。

**Method:** 本文提出了一个考虑墙体-设备距离对感知覆盖影响的理论模型。该模型结合了墙体反射路径和视线（LoS）路径的动态信号，开发了一个针对室内环境的综合感知覆盖模型。

**Result:** 该模型表明，将发射器和接收器战略性地部署在墙体附近特定范围内可以显著扩大感知覆盖范围。在呼吸监测和静止人群计数应用中，模型表现出显著的性能提升，其中计数准确率提高了11.2%。

**Conclusion:** 研究结果为Wi-Fi感知的优化部署策略铺平了道路，有助于在各种应用中实现更有效和准确的感知解决方案。

> **ai_Abstract:** 本文针对Wi-Fi感知在实际应用中遇到的性能不稳定和覆盖范围有限的问题，提出了一种新的理论模型。该模型首次考虑了墙体-设备距离对室内Wi-Fi感知覆盖的影响，通过整合墙体反射路径和视线路径，构建了一个全面的感知覆盖模型。研究表明，将设备策略性地部署在墙体附近可以显著扩展感知范围，并在呼吸监测和人群计数实验中验证了其有效性，显著提高了计数准确率。这项工作为优化Wi-Fi感知部署提供了新的思路。

> **摘要翻译:** Wi-Fi感知已在各种应用中得到广泛探索，包括生命体征监测、人类活动识别、室内定位和跟踪。然而，在实际场景中的实现受到不稳定的感知性能和有限的无线感知覆盖知识的阻碍。尽管以前的工作旨在解决这些挑战，但它们忽略了墙体对室内动态感知能力的影响。为了填补这一空白，我们提出了一个理论模型，该模型考虑了墙体-设备距离对感知覆盖范围的影响。通过结合动态信号的墙体反射路径和视线（LoS）路径，我们开发了一个针对室内环境的综合感知覆盖模型。该模型表明，在特定范围内将发射器和接收器战略性地部署在墙体附近可以显著扩大感知覆盖范围。我们通过呼吸监测和静止人群计数应用的实验评估了我们模型的性能，展示了计数准确率显著提高了11.2%。这些发现为Wi-Fi感知的优化部署策略铺平了道路，有助于在各种应用中实现更有效和准确的感知解决方案。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [844] [InfiniteHBD: Building Datacenter-Scale High-Bandwidth Domain for LLM with Optical Circuit Switching Transceivers](https://arxiv.org/abs/2502.03885)
> *InfiniteHBD：使用光电路交换收发器构建用于LLM的数据中心级高带宽域*

*Chenchen Shou, Guyue Liu, Hao Nie, Huaiyu Meng, Yu Zhou, Yimin Jiang, Wenqing Lv, Yelong Xu, Yuanwei Lu, Zhang Chen, Yanbo Yu, Yichen Shen, Yibo Zhu, Daxin Jiang* | **Category: cs.NI, cs.DC, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 高带宽域, 光电路交换, 大型语言模型, 数据中心, 可扩展性

**Comment:** 

> **TL;DR:** InfiniteHBD是一种新型的收发器中心HBD架构，利用光电路交换技术解决了现有LLM训练高带宽域在可扩展性、成本和容错性方面的限制，并显著降低成本、提高容错性和带宽利用率。

**AI_Comments:** 这篇论文通过提出InfiniteHBD，一个基于光电路交换收发器的HBD架构，为大规模LLM训练提供了一个创新且高效的解决方案。其核心创新在于将OCS嵌入到收发器层面，从而实现了高度可配置的网络拓扑和卓越的故障隔离能力，解决了现有HBD架构在成本、可扩展性和容错性方面的根本性问题。特别是，其在降低成本和GPU浪费方面的显著成果，以及对模型FLOPs利用率的提升，凸显了其在实际数据中心部署中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 扩展大型语言模型（LLM）训练依赖于多维并行，其中高带宽域（HBD）对于通信密集型并行至关重要。然而，现有的HBD架构在可扩展性、成本和容错性方面面临基本限制：以交换机为中心的HBD成本过高，以GPU为中心的HBD存在严重的故障传播，而交换机-GPU混合HBD的故障影响范围仍然很大。

**Method:** 论文提出InfiniteHBD，一种新颖的以收发器为中心的高带宽域（HBD）架构，通过在每个收发器中嵌入光电路交换（OCS）来实现连接性和动态切换的统一。该设计实现了可重构的点对多点连接，允许拓扑结构适应可变大小的环。关键创新包括基于硅光子（SiPh）的低成本OCS收发器（OCSTrx）、与节点内/节点间通信协同设计的可重构k跳环形拓扑，以及最大化GPU利用率同时最小化跨ToR数据中心网络流量的HBD-DCN编排算法。

**Result:** InfiniteHBD的成本是NVL-72的31%；GPU浪费率接近于零（比NVL-72和TPUv4低一个数量级以上）；当节点故障率低于7%时，跨ToR流量接近于零；与NVIDIA DGX（每节点8个GPU）相比，模型FLOPs利用率提高了3.37倍。

**Conclusion:** InfiniteHBD通过其创新的收发器中心架构和光电路交换技术，成功解决了现有高带宽域在可扩展性、成本和容错性方面的挑战，为大规模LLM训练提供了高效且经济的解决方案。

> **ai_Abstract:** 论文提出了一种名为InfiniteHBD的新型收发器中心高带宽域（HBD）架构，旨在解决大规模语言模型（LLM）训练中现有HBD在可扩展性、成本和容错性方面的挑战。InfiniteHBD通过在每个收发器中嵌入光电路交换（OCS）来实现可重构的点对多点连接和动态切换，从而提供数据中心范围的可扩展性、单节点故障隔离的容错性以及无故障GPU的全带宽利用。其关键创新包括低成本SiPh-based OCS收发器、可重构k跳环形拓扑和优化的HBD-DCN编排算法。评估结果显示，InfiniteHBD显著降低了成本和GPU浪费，减少了跨ToR流量，并大幅提高了模型FLOPs利用率。

> **摘要翻译:** 扩展大型语言模型（LLM）训练依赖于多维并行，其中高带宽域（HBD）对于张量并行（TP）和专家并行（EP）等通信密集型并行至关重要。然而，现有的HBD架构在可扩展性、成本和容错性方面面临基本限制：以交换机为中心的HBD（例如NVL-72）会产生过高的扩展成本，而以GPU为中心的HBD（例如TPUv3/Dojo）则遭受严重的故障传播。TPUv4等交换机-GPU混合HBD采取了折衷方法，但故障爆炸半径在立方体级别（例如64个TPU）仍然很大。
我们提出InfiniteHBD，一种新颖的以收发器为中心的高带宽域架构，利用光电路交换（OCS）在收发器级别统一连接性和动态切换。通过在每个收发器中嵌入OCS，InfiniteHBD实现了可重构的点对多点连接，允许拓扑结构适应可变大小的环。这种设计提供了：i）数据中心范围的可扩展性而不会出现成本爆炸；ii）通过将故障隔离到单个节点来实现容错性；以及iii）对无故障GPU实现全带宽利用。主要创新包括基于硅光子（SiPh）的低成本OCS收发器（OCSTrx）、与节点内/节点间通信协同设计的可重构k跳环形拓扑，以及最大化GPU利用率同时最小化跨ToR数据中心网络流量的HBD-DCN编排算法。评估表明，InfiniteHBD的成本是NVL-72的31%，GPU浪费率接近于零（比NVL-72和TPUv4低一个数量级以上），当节点故障率低于7%时，跨ToR流量接近于零，并且与NVIDIA DGX（每节点8个GPU）相比，模型FLOPs利用率提高了3.37倍。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [44] [Properties of Algorithmic Information Distance](https://arxiv.org/abs/2507.21988)
> *算法信息距离的性质*

*Marcus Hutter* | **Category: cs.IT, math.IT, math.MG** | **Updated: 2025-07-29**

**Keywords:** 算法信息距离, 柯尔莫哥洛夫复杂度, 度量空间, 嵌入, 理论性质

**Comment:** 33 pages

> **TL;DR:** 本文探讨了未归一化算法信息距离 $d_K$ 的理论性质，表明其并非欧几里得距离，但有限欧几里得点集可嵌入其中，并提出了未来研究的框架和开放问题。

**AI_Comments:** 本文对算法信息距离 $d_K$ 的理论性质进行了深入探讨，尤其是在其几何嵌入特性方面。其创新之处在于揭示了 $d_K$ 与欧几里得距离的区别，并提出了一个用于未来研究 $d_K$ 的新颖框架。这项工作对于理解信息距离的内在结构及其在理论计算机科学和数据分析中的应用具有重要意义。提出的开放问题也为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 通用归一化信息距离已成功应用于聚类问题，本文旨在探究未归一化算法信息距离 $d_K$ 除了作为度量之外的其他性质。

**Method:** 本文通过理论分析，研究了未归一化算法信息距离 $d_K$ 的性质，并开发了用于未来研究该距离所需的概念框架和工具。

**Result:** 研究表明，许多（无限）维空间无法等距尺度嵌入到具有度量 $d_K$ 的有限字符串空间中。此外，$d_K$ 不是欧几里得距离，但欧几里得空间中的任何有限点集都可以尺度嵌入到 $(\text{\{}0,1\text{\}}^*,d_K)$ 中。

**Conclusion:** 本文的主要贡献是为未来寻找 $d_K$ 更多（有趣）性质开发了必要的框架和工具，并提出了几个开放问题。

> **ai_Abstract:** 本文深入探讨了未归一化算法信息距离 $d_K$ 的理论特性。研究发现，尽管 $d_K$ 是一种度量，但它并非欧几里得距离，且许多高维空间无法等距尺度嵌入到基于 $d_K$ 的有限字符串空间中。然而，欧几里得空间中的任何有限点集都可以尺度嵌入到该空间。此外，本文为未来研究 $d_K$ 提供了必要的理论框架和工具，并提出了若干开放性问题。

> **摘要翻译:** 基于柯尔莫哥洛夫复杂度的领域无关通用归一化信息距离（以近似形式）已成功应用于各种困难的聚类问题。在本文中，我们研究了未归一化算法信息距离 $d_K$ 的理论性质。我们在这项工作中提出的主要问题是，除了作为度量之外，这种奇特的距离还具有哪些性质。我们表明，许多（无限）维空间可以（不能）等距尺度嵌入到具有度量 $d_K$ 的有限字符串空间中。我们还表明，$d_K$ 不是欧几里得距离，但欧几里得空间中的任何有限点集都可以尺度嵌入到 $(\text{\{}0,1\text{\}}^*,d_K)$ 中。一项主要贡献是开发了必要的框架和工具，以便将来发现 $d_K$ 更多（有趣）的性质，并提出了几个开放问题。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [104] [Age of Estimates: When to Submit Jobs to a Markov Machine to Maximize Revenue](https://arxiv.org/abs/2507.22865)
> *估计的年龄：何时向马尔可夫机器提交作业以最大化收益*

*Sahan Liyanaarachchi, Sennur Ulukus* | **Category: cs.IT, cs.SY, eess.SY, math.IT** | **Updated: 2025-07-30**

**Keywords:** 马尔可夫机器, 作业调度, 收益最大化, 估计年龄, 阈值策略

**Comment:** 

> **TL;DR:** 本文研究了在马尔可夫机器上何时提交作业以最大化平均收益的问题，发现最优策略是基于状态估计年龄的阈值或切换策略。

**AI_Comments:** 这项工作创新性地将“估计年龄”的概念引入马尔可夫机器的作业调度问题，解决了传统研究中对利用决策过程假设过于简化的不足。其重要性在于为AI工厂等新兴计算范式提供了更精细、更优化的资源利用策略，有望显著提升计算资源的经济效益。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI工厂的兴起，有效跟踪和利用计算资源（常建模为马尔可夫机器MM）变得至关重要。现有工作主要关注MM的跟踪，但对利用决策过程的假设过于简化。本文旨在解决如何最大化MM的效用（即平均收益）这一核心问题。

**Method:** 假设泊松作业到达过程和基于查询的采样程序来获取马尔可夫机器（MM）的状态。研究目标是找到最佳的作业提交时间，以最大化每个作业单位产生的平均收益。

**Result:** 根据马尔可夫机器（MM）的参数，最优策略表现为基于对MM状态“估计年龄”的“阈值策略”或“切换策略”形式。

**Conclusion:** 最大化马尔可夫机器平均收益的最佳策略取决于其参数，并可归结为基于状态估计年龄的阈值或切换策略。

> **ai_Abstract:** 本文研究了在人工智能工厂背景下，如何最大化马尔可夫机器（MM）的平均收益。针对现有研究侧重于MM跟踪而非有效利用的不足，作者提出了一种解决MM效用最大化的问题。通过假设泊松作业到达和基于查询的状态采样，研究确定了最佳作业提交时间。结果表明，最优策略是基于MM状态“估计年龄”的阈值策略或切换策略，具体取决于MM的参数。

> **摘要翻译:** 随着人工智能工厂开创计算霸权的新时代，开发有效跟踪和利用可用计算资源的策略变得至关重要。这些计算资源通常被建模为马尔可夫源，它们根据内部负载和外部利用率在空闲和繁忙状态之间振荡，通常被称为马尔可夫机器（MM）。大多数先前的工作只关注跟踪这些MM的问题，同时通常假设管理其利用率的基本决策过程。我们的关键观察是，跟踪MM的最终目标是正确地利用它。在这项工作中，我们考虑最大化MM效用的问题，其中效用被定义为MM产生的平均收益。假设泊松作业到达过程和基于查询的采样程序来采样MM的状态，我们找到了向MM提交可用作业的最佳时间，以最大化每个作业单位产生的平均收益。我们表明，根据MM的参数，最优策略是基于我们对MM状态“估计年龄”的“阈值策略”或“切换策略”的形式。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [268] [Double-Target Collaborative Spectrum Sharing for 6G Hybrid Satellite-Terrestrial Networks with User-Centric Channel Pools](https://arxiv.org/abs/1904.03979)
> *面向用户中心信道池的6G混合卫星-地面网络双目标协作频谱共享*

*Yanmin Wang, Wei Feng, Ming Xiao, Cheng-Xiang Wang* | **Category: cs.IT, math.IT** | **Updated: 2025-07-29**

**Keywords:** 6G, 混合卫星-地面网络, 频谱共享, 双目标优化, 用户中心信道池

**Comment:** 

> **TL;DR:** 本文提出了一种面向6G混合卫星-地面网络（HSTN）的双目标协作频谱共享方案，通过联合功率和信道分配以及引入用户中心信道池，有效解决了频谱稀缺问题，并显著提升了网络性能。

**AI_Comments:** 该研究提出了一种创新的双目标优化方法来解决6G混合卫星-地面网络中的频谱共享问题，并通过引入用户中心信道池有效降低了问题复杂度。其在保证地面终端服务质量的同时，兼顾了对卫星终端的干扰控制，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了应对即将到来的第六代（6G）时代中，混合卫星-地面网络（HSTN）在提供扩展宽带覆盖（例如海事通信场景）时面临的频谱稀缺问题。

**Method:** 提出了一种双目标频谱共享问题，旨在最大化服务地面移动终端（MTs）的数量和平均总传输速率。该问题通过联合功率和信道分配实现，仅利用慢变的大尺度信道状态信息（CSI），并确保地面MTs的严格服务质量，同时限制对卫星MTs的泄漏干扰。为高效解决复杂的混合整数规划（MIP）问题，引入了用户中心信道池。

**Result:** 仿真结果表明，所提出的频谱共享方案能为混合卫星-地面网络（HSTN）带来显著的性能增益。

**Conclusion:** 本文提出的双目标协作频谱共享方案，结合用户中心信道池，能够有效应对6G混合卫星-地面网络中的频谱稀缺问题，并显著提升网络性能。

> **ai_Abstract:** 本文针对6G混合卫星-地面网络中的频谱稀缺问题，提出了一种双目标协作频谱共享方案。该方案在仅利用大尺度CSI的情况下，对地面移动终端进行联合功率和信道分配，并严格保证地面终端的服务质量，同时限制对卫星终端的干扰。通过最大化服务地面终端数量和总传输速率，将问题建模为混合整数规划，并引入用户中心信道池以高效求解。仿真验证了该方案能显著提升网络性能。

> **摘要翻译:** 在即将到来的第六代（6G）时代，卫星和地面蜂窝网络可以整合在一起，以扩展宽带覆盖，例如在海事通信场景中。为应对频谱稀缺问题，本文考虑了混合卫星-地面网络（HSTN）中的协作频谱共享。仅利用慢变的大尺度信道状态信息（CSI），对机会性地与卫星移动终端共享相同频段的地面移动终端（MTs）实施联合功率和信道分配。特别地，在对卫星移动终端的泄漏干扰约束下，为地面移动终端提供了严格的服务质量保证。以最大化服务地面移动终端数量和平均总传输速率为目标，提出了一个双目标频谱共享问题。为高效解决复杂的混合整数规划（MIP）问题，引入了用户中心信道池。仿真结果表明，所提出的频谱共享方案能够为混合卫星-地面网络带来显著的性能增益。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [324] [On Purely Data-Driven Massive MIMO Detectors](https://arxiv.org/abs/2401.07515)
> *关于纯数据驱动的大规模MIMO检测器*

*Hao Ye, Le Liang* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-29**

**Keywords:** 大规模MIMO, 检测器, 数据驱动, ChannelNet, 对称性

**Comment:** 

> **TL;DR:** ChannelNet 是一种纯数据驱动的大规模MIMO检测器，通过利用MIMO系统的固有对称性，实现了高效的可扩展性和低计算复杂度，并在经验评估中优于或匹配现有技术水平。

**AI_Comments:** ChannelNet的创新之处在于其纯数据驱动的方法和对MIMO系统固有对称性的利用，这使其在可扩展性和计算效率上超越了传统的模型驱动方法。其理论保证和经验表现都表明了该方法在大规模MIMO检测器设计中的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大规模多输入多输出（MIMO）系统的学习型检测器开发受限于问题的高维性。大多数现有研究采用模型驱动方法，将深度神经网络（DNNs）集成到现有迭代检测框架中，但这些方法缺乏灵活性且计算复杂度高。

**Method:** 本文引入了ChannelNet，一种纯数据驱动的学习型大规模MIMO检测器。ChannelNet利用MIMO系统的固有对称性，通过引入信道嵌入层和天线共享特征处理器来实现。这些模块保持对天线置换的等变性，并使ChannelNet能够以低计算复杂度（O(Nt Nr)）有效地扩展到大量天线和高调制阶数。

**Result:** ChannelNet在理论上可以以任意精度近似任何连续置换对称函数和最优最大似然检测（ML）函数，在任何连续信道分布下。经验评估表明，ChannelNet在不同天线数量、调制方案和信道分布下，持续优于或匹配现有最先进的检测器，同时显著降低了计算开销。

**Conclusion:** 本研究强调了纯数据驱动设计在推进大规模MIMO系统高效且可扩展检测器方面的潜力。

> **ai_Abstract:** 本文提出了一种名为ChannelNet的纯数据驱动大规模MIMO检测器，旨在解决现有模型驱动方法在灵活性和计算复杂度上的不足。ChannelNet通过利用MIMO系统的固有对称性，引入信道嵌入层和天线共享特征处理器，实现了对天线置换的等变性，并能以低计算复杂度高效扩展。理论分析表明其能近似最优检测函数，经验评估也证实了ChannelNet在性能上优于或匹配现有技术，同时显著降低了计算开销，展示了纯数据驱动设计在MIMO检测领域的巨大潜力。

> **摘要翻译:** 大规模多输入多输出（MIMO）系统学习型检测器的开发受到问题高维性所固有的复杂性阻碍。为了提高可扩展性，大多数先前的研究都采用了模型驱动方法，将深度神经网络（DNNs）集成到现有的迭代检测框架中。然而，这些方法通常缺乏灵活性且涉及大量的计算复杂性。在本文中，我们引入了ChannelNet，一种纯数据驱动的学习型大规模MIMO检测器，它克服了这些局限性。ChannelNet通过结合信道嵌入层和天线共享特征处理器来利用MIMO系统的固有对称性。这些模块保持对天线置换的等变性，并使ChannelNet能够以低计算复杂度（具体为 $\mathcal{O}(N_t N_r)$，其中 $N_t$ 和 $N_r$ 分别表示发射和接收天线数量）高效地扩展到大量天线和高调制阶数。理论上，ChannelNet可以在任何连续信道分布下，以任意精度近似任何连续置换对称函数和最优最大似然检测（ML）函数。经验评估表明，ChannelNet在不同天线数量、调制方案和信道分布下，持续优于或匹配现有最先进的检测器，同时显著降低了计算开销。这项研究突出了纯数据驱动设计在推动大规模MIMO系统高效和可扩展检测器方面的潜力。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [373] [End-to-End Energy Saving in Cell-Free Massive MIMO ISAC for Ultra-Reliable Target-Aware Actuation](https://arxiv.org/abs/2401.10315)
> *面向超可靠目标感知驱动的无蜂窝大规模MIMO ISAC端到端节能*

*Zinat Behdad, Özlem Tuğfe Demir, Ki Won Sung, Cicek Cavdar* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-29**

**Keywords:** 无蜂窝大规模MIMO, ISAC, 能耗优化, 目标感知驱动, 6G

**Comment:** 13 pages

> **TL;DR:** 本文提出一种联合功率和块长分配算法，以最小化无蜂窝大规模MIMO ISAC系统中端到端能耗，同时满足通信和感知要求，并展示了其在能耗和检测能力上的优势。

**AI_Comments:** 本文创新性地将联合功率和块长分配应用于无蜂窝大规模MIMO ISAC系统，以实现端到端能耗最小化，并考虑了通信和感知的双重需求。特别地，对不同类型检测器的能耗和复杂度权衡分析，以及杂波感知型检测器显著的节能潜力，为未来6G ISAC系统的设计提供了重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 新兴的6G感知应用中的超可靠目标感知驱动（即利用及时准确的感知信息触发关键动作）要求在严格的可靠性和延迟约束下，实现感知与通信的紧密集成。

**Method:** 本文研究了下行链路CF-mMIMO系统中的集成感知与通信（ISAC），该系统支持多静态感知和超可靠低延迟通信（URLLC）。提出了一种联合功率和块长分配算法，以最小化端到端能耗，同时满足通信和感知要求。端到端能耗包括传输、感知接收器以及感知和通信的处理。非凸优化问题通过FPP-SCA、凹凸规划（CCP）和分数规划技术的组合求解。考虑了两种目标检测器：杂波感知型和杂波不感知型，每种都有不同的复杂性和性能权衡。进行了基于每秒千兆操作数（GOPS）的计算复杂度分析，以量化通信和感知任务的处理要求。

**Result:** 仿真结果表明，所提出的算法以更少的端到端能耗实现了增强的检测能力。此外，研究了检测器复杂性、每个接入点（AP）的天线元件数量以及感知AP数量之间的权衡。杂波感知型检测器虽然更复杂，但需要更少的天线和感知接收AP来满足检测要求，从而节省了高达40%的能量。

**Conclusion:** 本文提出的联合功率和块长分配算法能有效降低无蜂窝大规模MIMO ISAC系统的端到端能耗，同时提升检测能力，尤其在采用杂波感知型检测器时能实现显著的节能效果。

> **ai_Abstract:** 该论文针对6G应用中超可靠目标感知驱动的挑战，研究了无蜂窝大规模MIMO ISAC系统中的集成感知与通信。提出了一种联合功率和块长分配算法，旨在最小化端到端能耗，同时满足通信和感知需求。通过结合FPP-SCA、CCP和分数规划等技术解决非凸优化问题。研究了杂波感知型和杂波不感知型两种检测器，并进行了计算复杂度分析。仿真结果表明，所提算法能以更低的能耗实现更强的检测能力，且杂波感知型检测器能带来高达40%的节能效果。

> **摘要翻译:** 超可靠目标感知驱动——即在新兴的6G感知应用中，利用及时准确的感知信息触发关键动作——要求在严格的可靠性和延迟约束下，实现感知与通信的紧密集成。本文研究了下行链路无蜂窝大规模MIMO（CF-mMIMO）系统中的集成感知与通信（ISAC），该系统支持多静态感知和超可靠低延迟通信（URLLC）。我们提出了一种联合功率和块长分配算法，以最小化端到端能耗，同时满足通信和感知要求。端到端能耗包括传输、感知接收器以及感知和通信的处理。非凸优化问题通过FPP-SCA、凹凸规划（CCP）和分数规划技术的组合求解。我们考虑了两种目标检测器：杂波感知型和杂波不感知型，每种都有不同的复杂性和性能权衡。进行了基于每秒千兆操作数（GOPS）的计算复杂度分析，以量化通信和感知任务的处理要求。我们在各种通信和感知要求下进行了全面的性能评估，并将我们的方法与两种替代方案进行基准测试：一种仅最小化ISAC的传输能耗，另一种仅最小化URLLC的端到端能耗而不集成感知。仿真结果表明，所提出的算法以更少的端到端能耗实现了增强的检测能力。此外，我们研究了检测器复杂性、每个接入点（AP）的天线元件数量以及感知AP数量之间的权衡。杂波感知型检测器虽然更复杂，但需要更少的天线和感知接收AP来满足检测要求，从而节省了高达40%的能量。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [421] [Beamforming Design for Beyond Diagonal RIS-Aided Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2503.07189)
> *超越对角线RIS辅助的无蜂窝大规模MIMO系统中的波束成形设计*

*Yizhuo Li, Jiakang Zheng, Bokai Xu, Yiyang Zhu, Jiayi Zhang, Dusit Niyato, Bo Ai* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-29**

**Keywords:** 超越对角线RIS, 无蜂窝大规模MIMO, 波束成形, 频谱效率, 交替优化

**Comment:** 

> **TL;DR:** 本文研究了在超越对角线可重构智能表面（BD-RIS）辅助的无蜂窝大规模MIMO系统中，通过联合优化有源和无源波束成形来提高和谱效率。文章提出了交替优化算法，结合分数规划和流形优化来解决该问题。仿真结果表明，BD-RIS相比传统RIS能显著提升和谱效率，尤其在全连接架构下可提升约40%。

**AI_Comments:** 本文创新性地将超越对角线RIS（BD-RIS）应用于无蜂窝大规模MIMO系统，克服了传统RIS仅能反射信号的局限性。所提出的交替优化和流形优化算法为复杂的联合波束成形设计提供了鲁棒的解决方案，并实现了显著的性能增益（总谱效率提高约40%），突显了BD-RIS在未来无线通信中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的可重构智能表面（RIS）由于只能反射信号而存在固有的局限性。与此不同，超越对角线RIS（BD-RIS）因其同时具备反射和传输信号的能力而备受关注。本文的动机是利用BD-RIS来改善无蜂窝大规模MIMO系统的总谱效率。

**Method:** 本文提出了一种交替优化算法来解决波束成形设计问题。该算法利用分数规划进行分解，并交替求解子问题。此外，为了解决BD-RIS波束成形矩阵的酉约束带来的挑战，提出了一种流形优化算法来最优地解决该问题。

**Result:** 仿真结果表明，BD-RISs全面优于传统的RISs，尤其是在全连接架构下，性能最佳，与理想RISs相比，总谱效率提高了约40%。

**Conclusion:** 超越对角线RIS（BD-RIS）是提高无蜂窝大规模MIMO系统谱效率的有效且有前景的技术，其性能显著优于传统RIS。

> **ai_Abstract:** 本文研究了在超越对角线可重构智能表面（BD-RIS）辅助的无蜂窝大规模MIMO系统中，如何在发射功率和BD-RIS酉约束下，通过同时优化有源和无源波束成形来提高总谱效率。为解决此问题，文章提出了一种基于分数规划的交替优化算法，并引入流形优化来处理BD-RIS波束成形矩阵的酉约束。仿真结果表明，BD-RIS相比传统RIS具有显著优势，尤其在全连接架构下，总谱效率可提升约40%。

> **摘要翻译:** 可重构智能表面（RIS）辅助的无蜂窝（CF）大规模多输入多输出（mMIMO）是一种有前景的架构，可进一步以低成本和低功耗提高频谱效率（SE）。然而，传统的RIS由于其仅能反射信号的能力而存在不可避免的局限性。相比之下，超越对角线RIS（BD-RIS）因其同时具备反射和传输信号的能力而备受关注。本文重点关注使用BD-RIS来提高CF mMIMO系统的总频谱效率。这需要通过同时优化有源和无源波束成形器，在发射功率约束和BD-RIS的酉约束下完成波束成形设计。为了解决这个问题，我们引入了一种交替优化算法，该算法使用分数规划对其进行分解并交替求解子问题。此外，为了解决BD-RIS波束成形矩阵的酉约束带来的挑战，提出了一种流形优化算法来最优地解决该问题。仿真结果表明，BD-RISs全面优于RISs，尤其是在全连接架构下性能最佳，与理想RISs相比，总频谱效率提高了约40%。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [473] [Algebraic Barriers to Halving Algorithmic Information Quantities in Correlated Strings](https://arxiv.org/abs/2504.14408)
> *相关字符串中算法信息量减半的代数障碍*

*Andrei Romashchenko* | **Category: cs.IT, cs.DM, math.IT** | **Updated: 2025-07-28**

**Keywords:** 算法信息量, 柯尔莫哥洛夫复杂度, 代数障碍, 有限射影平面, 通信复杂度

**Comment:** 22 pages, 3 figures. v3: revised and extended version. A short
  version of the paper has been accepted to appear at the MFCS 2025

> **TL;DR:** 本文研究了在相关字符串元组中将算法信息量减半的可能性，并通过构造一个具体的三元组，证明了Alexander Shen提出的问题（是否存在一个字符串z使得每个条件柯尔莫哥洛夫复杂度约为对应无条件复杂度的一半）的否定答案。

**AI_Comments:** 本文通过构造性的反例解决了柯尔莫哥洛夫复杂度领域的一个重要开放问题，证明了在某些情况下无法将信息量减半。其创新之处在于将组合学、加性组合学和代数方法（特别是有限射影平面中的关联性质）应用于信息理论问题，提供了一个显式的构造。这不仅解决了理论问题，还为秘密密钥协商协议的通信复杂度提供了实际的下限，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 研究相关字符串元组中算法信息量缩减的可能性，特别是回答Alexander Shen提出的问题：对于任意三元组 (a, b, c)，是否存在一个字符串 z，使得每个条件柯尔莫哥洛夫复杂度 C(a|z), C(b|z), C(c|z) 大约是相应无条件柯尔莫哥洛夫复杂度的一半。

**Method:** 通过构造一个具体的三元组 (a, b, c) 来证明不存在满足条件的字符串 z。该构造基于有限射影平面中关联的组合性质，并利用了加性组合学和代数方法（特别是Bourgain–Katz–Tao和Stevens–De Zeeuw的结果）获得的素数域上点线关联的最新界限。

**Result:** 证明了Alexander Shen提出的问题（关于存在一个字符串z使得条件柯尔莫哥洛夫复杂度减半）的否定答案，并通过一个完全显式的例子进行了说明。

**Conclusion:** 这些结果揭示了有效信息交换的代数障碍，并强调了具有和不具有适当子域的域之间在信息论行为上的分离。

> **ai_Abstract:** 本文研究了相关字符串中算法信息量减半的问题，特别是针对Alexander Shen提出的关于是否存在一个中间字符串能将三元组中每个字符串的条件柯尔莫哥洛夫复杂度降低一半的问题。作者通过构造一个具体的反例，证明了这样的字符串不存在。该构造利用了有限射影平面中的组合性质以及加性组合学和代数方法在素数域上点线关联的最新研究成果。研究结果揭示了信息交换中的代数障碍，并对秘密密钥协商协议的通信复杂度提供了下限。

> **摘要翻译:** 我们研究了相关字符串元组中算法信息量缩减的可能性。特别是，我们解决了Alexander Shen提出的一个问题：对于任意字符串三元组 (a, b, c)，是否存在一个字符串 z，使得每个条件柯尔莫哥洛夫复杂度 C(a|z), C(b|z), C(c|z) 大约是相应无条件柯尔莫哥洛夫复杂度的一半。我们通过构造一个不存在此类字符串 z 的三元组 (a, b, c) 对此问题提供了否定答案。此外，我们提供了一个完全显式的此类元组示例。我们的构造基于有限射影平面中关联的组合性质，并依赖于使用加性组合学和代数方法（特别是Bourgain–Katz–Tao和Stevens–De Zeeuw的结果）获得的素数域上点线关联的最新界限。作为一个应用，我们表明这种不可能性在某些设置下对秘密密钥协商协议的通信复杂度产生了下限。这些结果揭示了有效信息交换的代数障碍，并强调了具有和不具有适当子域的域之间在信息论行为上的分离。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [529] [A DPI-PAC-Bayesian Framework for Generalization Bounds](https://arxiv.org/abs/2507.14795)
> *泛化界限的DPI-PAC-贝叶斯框架*

*Muhan Guan, Farhad Farokhi, Jingge Zhu* | **Category: cs.IT, math.IT, stat.ML** | **Updated: 2025-07-29**

**Keywords:** 泛化界限, PAC-贝叶斯, 数据处理不等式, 信息论, 监督学习

**Comment:** 7 pages, 1 figures, the final version with full proofs

> **TL;DR:** 该论文提出了一个统一的DPI-PAC-贝叶斯框架，用于推导监督学习中的泛化误差界限，通过结合数据处理不等式和PAC-贝叶斯方法，实现了更紧密的界限。

**AI_Comments:** 这项工作通过将数据处理不等式（DPI）与PAC-贝叶斯理论相结合，提出了一种新颖且统一的框架，用于推导更紧密的泛化界限。其创新之处在于能够消除传统PAC-贝叶斯界限中的冗余松弛项，并在特定条件下恢复奥卡姆剃刀界限，这对于理解和提高机器学习模型的泛化能力具有重要意义。该框架为信息论工具在泛化保证方面的应用提供了新的视角和灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发一个统一的框架，用于在监督学习环境中推导泛化误差界限，并解决现有PAC-贝叶斯界限中存在的松弛问题。

**Method:** 通过将数据处理不等式（DPI）嵌入到测度变换技术中，构建了一个DPI-PAC-贝叶斯框架。该框架用于导出针对Rényi散度和任何f-散度测量的二元Kullback-Leibler泛化间隙的显式界限。文章还展示了使用Rényi、Hellinger (p)和卡方散度推导出的三个界限。

**Result:** 该框架能够获得对二元Kullback-Leibler泛化间隙的显式界限。当先验分布选择为均匀分布时，所提出的界限可以恢复经典的奥卡姆剃刀界限，并消除了PAC-贝叶斯界限中存在的额外 \(\log(2\sqrt{n})/n\) 松弛，从而实现了更紧密的结果。该框架还显示出与其它已知界限的紧密联系。

**Conclusion:** 该DPI-PAC-贝叶斯框架成功地连接了数据处理和PAC-贝叶斯视角，提供了一个灵活的、信息论工具来构建泛化保证。

> **ai_Abstract:** 这篇论文提出了一个名为DPI-PAC-贝叶斯的新框架，用于在监督学习中推导泛化误差界限。该框架通过整合数据处理不等式（DPI）和测度变换技术，为Rényi散度和f-散度下的Kullback-Leibler泛化间隙提供了显式界限。研究表明，该框架能导出更紧密的界限，尤其是在均匀先验分布下，它不仅恢复了经典的奥卡姆剃刀界限，还消除了传统PAC-贝叶斯界限中的冗余松弛。这使得该框架成为一个灵活且信息论的工具，能够为机器学习模型提供更精确的泛化保证。

> **摘要翻译:** 我们开发了一个统一的数据处理不等式PAC-贝叶斯框架——简称DPI-PAC-贝叶斯——用于在监督学习环境中推导泛化误差界限。通过将数据处理不等式（DPI）嵌入到测度变换技术中，我们获得了针对数据独立先验分布和算法依赖后验分布之间测量的Rényi散度和任何f-散度的二元Kullback-Leibler泛化间隙的显式界限。我们展示了在该框架下使用Rényi、Hellinger (p)和卡方散度推导出的三个界限。此外，我们的框架还展示了与其它知名界限的紧密联系。当先验分布选择为均匀分布时，我们的界限可以恢复经典的奥卡姆剃刀界限，并且关键的是，消除了PAC-贝叶斯界限中存在的额外 \(\log(2\sqrt{n})/n\) 松弛，从而实现了更紧密的结果。因此，该框架连接了数据处理和PAC-贝叶斯视角，提供了一个灵活的、信息论工具来构建泛化保证。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [592] [Overview of 3GPP Release 19 Study on Channel Modeling Enhancements to TR 38.901 for 6G](https://arxiv.org/abs/2507.19266)
> *3GPP Release 19 关于 TR 38.901 6G 信道建模增强研究概述*

*Hitesh Poddar, Dimitri Gold, Daewon Lee, Nan Zhang, Gokul Sridharan, Henrik Asplund, Mansoor Shafi* | **Category: cs.IT, math.IT** | **Updated: 2025-07-29**

**Keywords:** 信道建模, 3GPP, 6G, TR 38.901, 7-24 GHz

**Comment:** 

> **TL;DR:** 该研究概述了 3GPP Release 19 对 TR 38.901 信道模型进行的增强，以解决 7-24 GHz 频段的建模空白，为未来的 6G 部署提供更准确的模型。

**AI_Comments:** 该论文展示了 3GPP 在推动 6G 发展中的重要作用，特别是在关键的信道建模领域。通过解决 7-24 GHz 频段的建模空白并引入多项增强，该研究为未来 6G 系统的准确评估和部署奠定了基础，具有重要的实践意义和前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 随着无线系统每十年演进，开发准确和标准化的信道模型对于新兴技术的开发、评估和性能评估变得越来越重要。之前的研究主要集中在 sub-6 GHz 和毫米波频段，在准确建模 7-24 GHz 频段（6G 的一个有前景的候选频段）方面存在一些空白。为了弥补这些空白，3GPP 批准了一项 Release 19 信道建模研究。

**Method:** 3GPP 批准了一项 Release 19 信道建模研究，该研究旨在对 TR 38.901 信道模型进行增强。

**Result:** 该研究对信道模型进行了多项增强，包括：准确建模城郊宏蜂窝 (SMa) 场景的能力、真实的终端 (UT) 天线模型、簇数量的可变性、每个簇中射线数量的可变性、捕获所有极化之间功率可变性的框架、近场 (NF) 传播以及空间非平稳性 (SNS) 效应。

**Conclusion:** 本文介绍了 3GPP Release 19 信道建模研究的成果，并概述了指导 3GPP TR 38.901 信道模型验证、完善和增强的基本原理和关键讨论，这些增强对于未来的 6G 部署至关重要。

> **ai_Abstract:** 本文概述了 3GPP Release 19 针对 TR 38.901 信道模型进行的增强研究。该研究旨在弥补现有模型在 7-24 GHz 频段的空白，为 6G 部署提供更准确的信道模型。主要增强包括支持城郊宏蜂窝场景、真实用户终端天线模型、簇和射线数量可变性、极化功率可变性、近场传播和空间非平稳性效应的建模能力。

> **摘要翻译:** 信道模型是无线通信系统的基本组成部分，为无线电波传播的物理特性提供了关键见解。随着无线系统每十年演进，开发准确和标准化的信道模型对于新兴技术的开发、评估和性能评估变得越来越重要。一项开发标准化信道模型的努力始于 2000 年左右，通过第三代合作伙伴计划 (3GPP) 和国际电信联盟 (ITU) 进行，旨在解决从 sub-1 GHz 到 100 GHz 的广泛频率范围。之前的努力主要集中在 sub-6 GHz 频段和毫米波频段，在准确建模 7-24 GHz 频率范围方面存在一些空白，而该频段是 6G 的一个有前景的候选频段。为了弥补这些空白，3GPP 批准了一项 Release (Rel) 19 信道建模研究。这项研究对信道模型进行了多项增强，包括：准确建模城郊宏蜂窝 (SMa) 场景的能力、真实的终端 (UT) 天线模型、簇数量的可变性、每个簇中射线数量的可变性、捕获所有极化之间功率可变性的框架、近场 (NF) 传播以及空间非平稳性 (SNS) 效应，所有这些都可能对未来的 6G 部署至关重要。本文介绍了这项研究的成果，并概述了指导 3GPP TR 38.901 信道模型验证、完善和增强的基本原理和关键讨论。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [641] [(2,2)-GB Codes: Classification and Comparison with weight-4 Surface Codes](https://arxiv.org/abs/2507.21237)
> *(2,2)-GB码：分类及与权重-4表面码的比较*

*François Arnault, Philippe Gaborit, Nicolas Saussay* | **Category: cs.IT, math.IT, quant-ph** | **Updated: 2025-07-28**

**Keywords:** 量子纠错, 广义循环码, 表面码, CSS码, 凯莱图

**Comment:** 

> **TL;DR:** 本文构建了三类新型最优(2,2)-GB码，性能与最佳表面码相当，并引入了新的等价关系进行严格比较，纠正了关于偶数距离GB码的错误观念。

**AI_Comments:** 这篇论文的创新点在于构建了新型最优(2,2)-GB码，特别是成功地找到了最优的偶数距离GB码，这打破了长期以来的一个错误观念。此外，引入CSS保持等价关系为基于凯莱图的CSS码的严格比较提供了一个新的框架，增强了研究的严谨性。这项工作对于量子纠错码的设计和分析具有重要意义，为寻找高性能的量子码提供了新的方向和工具。

<details>
  <summary>Details</summary>

**Motivation:** 广义循环码（GB码）为量子纠错中的表面码提供了一个有吸引力的替代方案。

**Method:** 1. 构建了由每行有两个非零元素的二元循环矩阵对构成的(2,2)-广义循环码。2. 利用最小距离的下限，构建了三类新型最优(2,2)-GB码。3. 引入了一种保持CSS结构的等价关系，用于严格比较基于凯莱图的CSS码。4. 对长度小于200的所有极值、非等价的(2,2)-GB码进行了分类，并与现有著名的2D权重-4表面码进行了比较。

**Result:** 1. 构建了三类新型最优(2,2)-GB码，参数分别为[[ 2n^2, 2, n ]]、[[ 4r^2, 2, 2r ]]和[[(2t + 1)^2 + 1, 2, 2t + 1 ]]。2. 这些GB码的性能与Kitaev的拓扑码和最佳2D权重-4表面码相当，达到了已知的理论极限。3. 第二类GB码提供了最优的偶数距离GB码，打破了之前认为不可能的长期观念。4. 在新的CSS保持等价关系框架下，前两类GB码与所有先前已知的最优权重-4 2D表面码不等价。5. 第三类GB码与已知最佳的奇数距离2D表面码等价。

**Conclusion:** (2,2)-GB码是量子纠错码的有效替代方案，通过构建新型最优GB码并引入新的比较框架，证明了其与现有最佳表面码的竞争力，特别是解决了偶数距离GB码存在的难题。

> **ai_Abstract:** 本文关注(2,2)-广义循环（GB）码在量子纠错中的应用。通过利用最小距离下限，研究者构建了三类新型最优(2,2)-GB码，这些码在性能上与Kitaev的拓扑码及最佳2D权重-4表面码相当，并达到了理论极限。值得注意的是，其中一类码成功实现了最优的偶数距离GB码，纠正了此前认为不可能的观点。为了对这些基于凯莱图的CSS码进行严格比较，文章提出了一种新的CSS结构保持等价关系。在此框架下，研究发现两类新型GB码与现有最佳表面码不等价，而另一类则等价。此外，文章还对长度小于200的极值(2,2)-GB码进行了分类和比较。

> **摘要翻译:** 广义循环（GB）码为量子纠错中的表面码提供了一个有吸引力的替代方案。本文重点研究(2,2)-广义循环码，这些码由每行有两个非零元素的二元循环矩阵对构成。利用其最小距离的下限，我们构建了三类新型最优(2,2)-GB码，参数分别为[[ 2n^2, 2, n ]]、[[ 4r^2, 2, 2r ]]和[[(2t + 1)^2 + 1, 2, 2t + 1 ]]。这些族码的性能与Kitaev的拓扑码和最佳2D权重-4表面码相当，达到了已知的理论极限。特别是，第二类码通过提供最优的偶数距离GB码，打破了长期以来认为不可能的观念。所有这些码都是从凯莱图导出的CSS码。认识到标准等价关系不能保持其CSS结构，我们引入了一种保持CSS结构的等价关系，用于严格比较基于凯莱图的CSS码。在此框架下，前两类码与所有先前已知的最优权重-4 2D表面码不等价，而第三类码则与已知最佳的奇数距离2D表面码等价。最后，我们对长度小于200的所有极值、非等价的(2,2)-GB码进行了分类，并提供了与现有著名2D权重-4表面码的比较表。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [710] [Distributed Iterative ML and Message Passing for Grant-Free Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2507.21363)
> *免授权蜂窝无源大规模MIMO系统中分布式迭代ML与消息传递*

*Zilu Zhao, Christian Forsch, Laura Cottatellucci, Dirk Slock* | **Category: cs.IT, eess.SP, math.IT, stat.AP** | **Updated: 2025-07-28**

**Keywords:** 免授权, 蜂窝无源大规模MIMO, 活动检测, 数据检测, 信道估计

**Comment:** 

> **TL;DR:** 本文提出了一种用于免授权蜂窝无源大规模MIMO系统的分布式算法，结合了迭代ML进行活动检测和一种改进的PP-VB-EP算法进行联合数据检测与信道估计，以解决设备连接和导频污染挑战，并改善了收敛性。

**AI_Comments:** 本文的创新点在于为免授权蜂窝无源大规模MIMO系统设计了一套全面的分布式算法，有效解决了活动检测和导频污染缓解的关键问题。特别值得注意的是，引入的PP-VB-EP算法通过伪先验机制显著提升了算法的收敛性和鲁棒性，这对于实际部署具有重要意义。此外，对伪先验的分布式计算也增强了方案的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 免授权（GF）与蜂窝无源（CF）大规模多输入多输出（MaMIMO）系统的集成在活动检测和导频污染缓解的分布式算法设计方面引入了显著挑战，尤其是在支持大规模设备连接的物联网（IoT）背景下。

**Method:** 本文提出了一种分布式算法。首先，采用分量迭代分布式最大似然（ML）方法进行活动检测，该方法考虑接收信号的导频和数据部分。接着，使用伪先验混合变分贝叶斯与期望传播（PP-VB-EP）算法进行联合数据检测和信道估计。为了分布式计算伪先验，进一步开发了变级别期望传播（VL-EP）算法的分布式版本。

**Result:** 与传统VB-EP相比，所提出的PP-VB-EP算法表现出改进的收敛行为和对初始化更低的敏感性，尤其当数据符号来自有限字母表时。PP-VB-EP中使用的伪先验充当近似后验和正则化项，可防止消息传递（MP）算法发散。

**Conclusion:** 本文成功提出了一种分布式算法，有效解决了免授权蜂窝无源大规模MIMO系统中活动检测和导频污染缓解的关键挑战，并通过引入PP-VB-EP和分布式VL-EP提升了算法的收敛性和鲁棒性。

> **ai_Abstract:** 本文针对免授权蜂窝无源大规模MIMO系统，提出了一种新型分布式算法。该算法通过分量迭代分布式最大似然方法进行活动检测，并引入伪先验混合变分贝叶斯与期望传播（PP-VB-EP）算法进行联合数据检测和信道估计。PP-VB-EP算法改进了收敛性并降低了对初始化的敏感度，其伪先验项作为正则化器防止消息传递算法发散。此外，为实现伪先验的分布式计算，还开发了变级别期望传播的分布式版本。

> **摘要翻译:** 蜂窝无源（CF）大规模多输入多输出（MaMIMO）被认为是实现下一代无线通信的主要候选技术之一。随着物联网（IoT）兴趣的增长，免授权（GF）接入方案已成为支持大规模设备连接的一种有前景的解决方案。GF和CF-MaMIMO的集成带来了重大挑战，特别是在设计用于活动检测和导频污染缓解的分布式算法方面。在本文中，我们提出了一种解决这些挑战的分布式算法。我们的方法首先采用分量迭代分布式最大似然（ML）方法进行活动检测，该方法同时考虑接收信号的导频和数据部分。之后，使用伪先验混合变分贝叶斯与期望传播（PP-VB-EP）算法进行联合数据检测和信道估计。与传统的VB-EP相比，所提出的PP-VB-EP表现出改进的收敛行为和对初始化更低的敏感性，尤其是在数据符号来自有限字母表时。PP-VB-EP中使用的伪先验作为近似后验，并作为正则化项，防止消息传递（MP）算法发散。为了以分布式方式计算伪先验，我们进一步开发了变级别期望传播（VL-EP）算法的分布式版本。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [780] [On the Hulls of Group Codes](https://arxiv.org/abs/2507.21623)
> *群码的核*

*Xiheng Deng, Yuan Ren* | **Category: cs.IT, math.IT** | **Updated: 2025-07-29**

**Keywords:** 群码, 核维度, 有限域, 存在准则, 阿贝尔群

**Comment:** Submitted to Designs, Codes and Cryptography. Submission ID
  64937899-ea28-4559-9d88-9de59566a860

> **TL;DR:** 本文提出了一个判断群码存在性的通用准则，并将其应用于低维核的情况，推广了先前对阿贝尔群的研究。

**AI_Comments:** 本文的创新之处在于提出了一个普适的群码核维度存在性准则，并成功地将其应用于推广了以往仅限于阿贝尔群的研究，尤其是在1维核存在性方面。这对于理解群码的结构及其应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为给定核维度的群码的存在性提供一个通用的判别准则，并将其应用于特定维度的核，以推广现有研究。

**Method:** 通过证明一个群码存在性的通用判别准则，并将其应用于推导核维度小于等于3的群码存在的明确准则。

**Result:** 证明了一个群码具有给定核维度的存在性通用准则，并推导出了核维度小于等于3的群码存在的明确准则。特别是，1维核的存在准则推广了先前只考虑阿贝尔群的工作。

**Conclusion:** 本文提出的准则成功地推广了先前关于阿贝尔群码1维核存在性的研究，为群码的存在性提供了更普适的判断方法。

> **ai_Abstract:** 本文研究了有限域上群码的性质。作者提出了一个判断具有给定核维度的群码存在性的通用准则，并将其应用于推导出核维度小于等于3的群码存在的具体准则。值得注意的是，该研究将1维核存在性的准则推广到了非阿贝尔群，超越了以往仅限于阿贝尔群的限制。

> **摘要翻译:** 设 $\mathbb {F}_q$ 是一个有限域，$G$ 是一个有限群，且 $(|G|,q)=1$。
在 $\mathbb {F}_q[G]$ 中，群码是指一个双边理想。我们将证明一个关于给定核维度的群码存在性的通用准则，然后将其应用于推导核维度小于等于3的群码存在的明确准则。特别是，我们关于1维核存在性的准则推广了先前只考虑阿贝尔群 $G$ 的工作。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [850] [Beamforming Saturation in Two-Timescale RIS-assisted Communication](https://arxiv.org/abs/2507.21776)
> *两时隙RIS辅助通信中的波束成形饱和*

*Masoud Sadeghian, Angel Lozano, Gabor Fodor* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-29**

**Keywords:** 可重构智能表面, 两时隙, 波束成形增益, 饱和, 功率角谱

**Comment:** 

> **TL;DR:** RIS辅助通信中，两时隙波束成形增益会随着RIS单元数量的增加而迅速饱和，其最终增益取决于功率角谱的衰减率。

**AI_Comments:** 这项研究揭示了RIS辅助通信中两时隙波束成形增益的一个关键限制，即饱和现象。它强调了功率角谱在确定RIS系统最终性能中的重要性，为未来RIS系统设计提供了新的视角，尤其是在大规模RIS部署时需考虑实际增益限制。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在研究RIS辅助无线通信中的两时隙方法，以减轻信道估计的开销，并探讨其波束成形增益特性。

**Method:** 论文考虑了RIS辅助的无线通信，并采用了基于信道统计数据优化RIS相移的两时隙方法。它通过分析功率角谱（PAS）来展示波束成形增益的饱和现象。

**Result:** 结果表明，虽然RIS捕获的功率随其单元数量线性增长，但两时隙波束成形增益在重辐射到接收器时，随着RIS单元数量的增加会迅速饱和。最终可实现的增益由角域中功率角谱的衰减率决定，该衰减率直接影响RIS单元之间空间相关性减小的速度。

**Conclusion:** 波束成形增益的饱和现象对RIS辅助通信的有效性有重要影响，需要考虑功率角谱的衰减率来评估最终增益。

> **ai_Abstract:** 本文研究了RIS辅助无线通信中的两时隙方法，该方法通过优化RIS相移来减少信道估计开销。研究发现，尽管RIS捕获功率随单元数量线性增长，但两时隙波束成形增益在重辐射时会迅速饱和，其最终增益受功率角谱衰减率的影响。文章讨论了这种饱和对RIS辅助通信有效性的重要启示。

> **摘要翻译:** 本文考虑了可重构智能表面（RIS）辅助的无线通信，重点关注两时隙方法，其中RIS相移基于信道统计数据进行优化，以减轻与信道估计相关的开销。结果表明，虽然RIS捕获的功率随其单元数量线性扩展，但对于广泛的功率角谱（PAS），两时隙波束成形增益在向接收器重新辐射时，会随着RIS单元数量的增加而迅速饱和。最终可实现的增益由角域中PAS的衰减率决定，该衰减率直接影响RIS单元之间空间相关性减小的速度。本文讨论了这种饱和对RIS辅助通信有效性的影响。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [920] [Pilot-to-Data Power Ratio in RIS-Assisted Multiantenna Communication](https://arxiv.org/abs/2507.21785)
> *RIS辅助多天线通信中的导频到数据功率比*

*Masoud Sadeghian, Angel Lozano, Gabor Fodor* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-29**

**Keywords:** RIS, PDPR, 多天线通信, 信道状态信息, 优化

**Comment:** 

> **TL;DR:** 本文研究了在RIS辅助的多天线通信中优化导频到数据功率比（PDPR），发现在广泛的操作条件下，优化PDPR能带来显著的益处，尤其是在RIS单元数量或信道相干性增加时。

**AI_Comments:** 本文的创新点在于首次将导频到数据功率比（PDPR）的优化问题引入到RIS辅助的通信网络中，填补了该领域的研究空白。通过理论分析和闭式解的推导，验证了PDPR优化在RIS系统中带来的显著增益，尤其是在RIS规模扩大时，这对于未来RIS部署和系统设计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 导频到数据功率比（PDPR）的优化有助于无线系统在最小化导频开销的同时获取信道状态信息。尽管PDPR在蜂窝网络中的优化已被广泛研究，但在RIS辅助网络中PDPR的影响却鲜有考察，因此本文旨在解决这一优化问题。

**Method:** 本文在通信由RIS辅助的情况下，对PDPR进行了优化，其中RIS的相移是根据信道统计数据进行调整的。研究通过遍历最小均方误差（ergodic minimum mean squared error）来证明优化PDPR的益处，并推导出了其闭式解。

**Result:** 在代表宏蜂窝部署的设置中，优化PDPR在广泛的操作条件下显示出显著的益处。这些益处通过遍历最小均方误差得到证明，并且随着RIS单元数量和/或信道相干性的增加而变得更加显著。本文还导出了遍历最小均方误差的闭式解。

**Conclusion:** 优化导频到数据功率比（PDPR）在RIS辅助的多天线通信系统中具有显著的优势，尤其是在RIS元素数量和信道相干性较高时。

> **ai_Abstract:** 本文研究了在可重构智能表面（RIS）辅助的多天线通信系统中，导频到数据功率比（PDPR）的优化问题。与传统蜂窝网络不同，RIS辅助网络中的PDPR优化此前鲜有研究。通过基于信道统计数据调整RIS相移，并采用遍历最小均方误差（EMMSE）作为性能指标，研究发现优化PDPR能显著提升系统性能。EMMSE的闭式解得到了推导，并且这种性能提升在RIS单元数量增加或信道相干性增强时尤为明显。

> **摘要翻译:** 导频到数据功率比（PDPR）的优化是一种帮助无线系统在最小化导频开销的同时获取信道状态信息的手段。尽管PDPR在蜂窝网络中的优化已被广泛研究，但在RIS辅助网络中PDPR的影响却鲜有考察。本文探讨了当通信由RIS辅助时，如何进行PDPR优化，其中RIS的相移是根据信道统计数据进行调整的。对于宏蜂窝部署的典型设置，优化PDPR在广泛的操作条件下显示出显著的益处。这些益处通过遍历最小均方误差得到证明（为此推导出了闭式解），并且随着RIS单元数量和/或信道相干性的增加而变得更加显著。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [19] [No Redundancy, No Stall: Lightweight Streaming 3D Gaussian Splatting for Real-time Rendering](https://arxiv.org/abs/2507.21572)
> *无冗余，无停顿：用于实时渲染的轻量级流式3D高斯泼溅*

*Linye Wei, Jiajun Tang, Fan Fei, Boxin Shi, Runsheng Wang, Meng Li* | **Category: cs.AR** | **Updated: 2025-07-30**

**Keywords:** 3D高斯泼溅, 实时渲染, 边缘部署, 算法硬件协同设计, 工作负载均衡

**Comment:** Accepted by International Conference on Computer-Aided Design (ICCAD)
  2025

> **TL;DR:** LS-Gaussian通过算法/硬件协同设计，解决了3D高斯泼溅在实时渲染中的冗余和停顿问题，显著提升了边缘设备的渲染效率。

**AI_Comments:** 该论文的创新点在于提出了一个算法/硬件协同设计框架LS-Gaussian，专门针对3DGS在边缘设备上的实时渲染效率问题。通过解决计算冗余和硬件停顿这两个核心问题，显著提升了性能，并在实际应用场景（如自动驾驶）中具有重要意义。定制加速器的设计也体现了软硬件结合的优化思路。

<details>
  <summary>Details</summary>

**Motivation:** 3D高斯泼溅（3DGS）在处理高帧率要求和资源受限的边缘部署时面临效率挑战，主要表现为计算冗余和停顿。

**Method:** 本文提出了LS-Gaussian，一个算法/硬件协同设计框架，用于轻量级流式3D渲染。它通过两种方式解决问题：一是提出视点变换算法，利用帧间连续性进行高效稀疏渲染，以减少计算冗余；二是根据视点变换预测每个图像块的工作负载，实现更均衡的并行计算，并协同设计定制的3DGS加速器以支持实时工作负载感知映射，从而减少硬件停顿。

**Result:** LS-Gaussian在边缘GPU基线上平均实现5.41倍加速，使用定制加速器时最高达17.3倍加速，同时仅造成极小的视觉质量下降。

**Conclusion:** LS-Gaussian通过解决3DGS的计算冗余和停顿问题，显著提升了实时渲染效率，使其适用于资源受限的边缘部署。

> **ai_Abstract:** 本文提出了LS-Gaussian，一个算法/硬件协同设计框架，旨在解决3D高斯泼溅（3DGS）在实时渲染中面临的计算冗余和硬件停顿问题。LS-Gaussian通过利用帧间连续性进行高效稀疏渲染，并预测工作负载以实现均衡并行计算，同时设计定制加速器来支持实时渲染。实验结果表明，LS-Gaussian显著提升了渲染速度，同时保持了视觉质量。

> **摘要翻译:** 3D高斯泼溅（3DGS）能够实现高质量的3D场景渲染，并在自动驾驶和具身智能等领域得到日益广泛的应用。然而，当面临高帧率要求和资源受限的边缘部署时，3DGS仍然面临主要的效率挑战。为了实现高效的3DGS，本文提出了LS-Gaussian，一个用于轻量级流式3D渲染的算法/硬件协同设计框架。LS-Gaussian的核心观察是3DGS存在大量的计算冗余和停顿。一方面，在实际场景中，高帧率3DGS通常应用于相机连续观察和渲染同一场景但视角略有不同的设置。因此，LS-Gaussian提出了一种视点变换算法，利用帧间连续性进行高效稀疏渲染，而不是单独渲染每一帧。另一方面，由于图像内的不同块并行渲染但工作负载不均衡，频繁的硬件停顿也减慢了渲染过程。LS-Gaussian根据视点变换预测每个块的工作负载，以实现更均衡的并行计算，并协同设计了一个定制的3DGS加速器，以实时支持工作负载感知映射。实验结果表明，LS-Gaussian在边缘GPU基线上平均实现了5.41倍的加速，使用定制加速器时最高达17.3倍的加速，同时仅造成极小的视觉质量下降。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [145] [A Multi-Agent Generative AI Framework for IC Module-Level Verification Automation](https://arxiv.org/abs/2507.21694)
> *一种用于IC模块级验证自动化的多智能体生成式AI框架*

*Wenbo Liu, Forbes Hou, Jon Zhang, Hong Liu, Allen Lei* | **Category: cs.AR, cs.AI, B.5.2; I.2.11** | **Updated: 2025-07-29**

**Keywords:** 多智能体, 生成式AI, 芯片验证, 自动化, 测试台

**Comment:** 20 pages, 12 figures. DVCon China 2025

> **TL;DR:** 本文提出了一种多智能体验证框架（MAVF），通过多智能体协作自动化芯片模块级验证，显著优于传统方法和单LLM方法，有望解决芯片设计中的验证瓶颈。

**AI_Comments:** 该论文创新性地将多智能体协作引入IC模块级验证自动化，有效弥补了单一大型语言模型在复杂验证任务中的不足。通过将验证流程分解为多个专业智能体协同工作，显著提升了验证效率和准确性，为解决芯片设计中的关键瓶瓶颈问题提供了有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大语言模型在EDA领域的代码生成等方面取得了初步进展，但在芯片验证这一关键瓶颈环节的应用仍处于探索阶段，现有单一LLM方法在复杂验证任务中存在局限性。

**Method:** 本文提出了一种多智能体验证框架（MAVF），通过多个专业智能体（包括规范解析、验证策略生成和代码实现）的协作，构建了一个从设计规范到测试台的自动化转换系统。

**Result:** 通过在多个复杂程度不同的芯片模块上进行验证实验，结果表明MAVF在验证文档解析和生成以及自动化测试台生成方面，显著优于传统手动方法和单一对话生成式AI方法。

**Conclusion:** 这项研究为探索生成式AI在验证自动化中的应用开辟了新方向，有望为解决芯片设计中最具挑战性的瓶颈问题提供有效方法。

> **ai_Abstract:** 本研究提出了一种多智能体验证框架（MAVF），旨在克服单一大型语言模型在复杂芯片验证任务中的局限性。该框架通过整合规范解析、验证策略生成和代码实现等多个专业智能体，实现了从设计规范到测试台的自动化转换。实验结果表明，MAVF在验证文档处理和自动化测试台生成方面，性能显著优于传统手动方法和单一对话生成式AI方法，为解决芯片设计中的验证瓶颈提供了新的方向。

> **摘要翻译:** 随着大语言模型在电子设计自动化（EDA）领域展现出巨大潜力，生成式AI辅助芯片设计正吸引学术界和工业界的广泛关注。尽管这些技术在代码生成等任务中取得了初步进展，但其在芯片验证——芯片开发周期中的关键瓶颈——中的应用仍处于探索阶段。本文提出了一种创新的多智能体验证框架（MAVF），旨在解决当前单一LLM方法在复杂验证任务中的局限性。我们的框架通过多个专业智能体（包括规范解析、验证策略生成和代码实现）的协作工作，构建了一个从设计规范到测试台的自动化转换系统。通过在多个复杂程度不同的芯片模块上进行验证实验，结果显示MAVF在验证文档解析和生成以及自动化测试台生成方面，显著优于传统手动方法和单一对话生成式AI方法。这项研究为探索生成式AI在验证自动化中的应用开辟了新方向，有望为解决芯片设计中最具挑战性的瓶颈问题提供有效方法。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [916] [A Customized Memory-aware Architecture for Biological Sequence Alignment](https://arxiv.org/abs/2507.22221)
> *生物序列比对的定制化内存感知架构*

*Nasrin Akbari, Mehdi Modarressi, Alireza Khadem* | **Category: cs.AR, cs.ET, n/a, C.3** | **Updated: 2025-07-29**

**Keywords:** 序列比对, 内存感知, 存内计算, 3D DRAM, 内存墙

**Comment:** 20 pages, 11 figures

> **TL;DR:** 本文提出了一种内存感知架构，并将其集成到3D DRAM中作为存内计算，以解决生物序列比对中传统并行处理器面临的内存带宽瓶颈，实现了显著的性能提升和功耗降低。

**AI_Comments:** 该论文的创新点在于将内存感知架构与新兴的3D DRAM存内计算技术相结合，有效解决了生物序列比对中长期存在的内存墙问题。这种将计算推向内存的设计理念对于处理大数据量、计算密集型任务具有重要意义，尤其是在生物信息学领域。其显著的性能提升和功耗降低证明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 随着生物信息学数据库中数据量的指数级增长，序列比对所需的时间、处理能力和内存带宽需求也随之增长。传统的并行机器（如GPU）在处理序列比对算法时，由于其过高的内存带宽需求，无法充分发挥最大吞吐量。

**Method:** 提出了一种定制化的内存感知架构，旨在减少序列比对算法的带宽需求。该设计被集成到新兴的3D DRAM的逻辑层中，作为一种存内计算架构，以进一步增加可用带宽。

**Result:** 实验结果表明，所提出的架构比基于GPU的设计实现了高达2.4倍的加速。此外，通过将计算移至更靠近内存的位置，平均功耗降低了37%。

**Conclusion:** 通过定制化的内存感知和存内计算架构，可以有效克服生物序列比对中传统并行机器的内存墙问题，显著提高吞吐量并降低功耗。

> **ai_Abstract:** 本文针对生物序列比对中传统并行处理器（如GPU）面临的内存带宽瓶颈问题，提出了一种定制化的内存感知架构。该架构将计算集成到3D DRAM的逻辑层中，形成一种存内计算（PIM）设计，以显著减少内存带宽需求并提高吞吐量。实验证明，该架构比GPU设计实现了高达2.4倍的加速，并平均降低了37%的功耗。

> **摘要翻译:** 序列比对是计算生物学中的一个基本过程，用于识别生物序列中的相似区域。随着生物信息学数据库中数据量的指数级增长，比较查询序列与可用数据库所需的时间、处理能力和内存带宽也随之成比例增长。序列比对算法通常涉及简单的算术运算，并具有高度固有的细粒度和粗粒度并行性。这些特性可以被大规模并行处理器（如GPU）潜在地利用以提高吞吐量。在本文中，我们表明序列比对算法过高的内存带宽需求阻碍了传统并行机器上最大可实现吞吐量的发挥。然后，我们提出了一种内存感知架构，以减少序列比对算法的带宽需求，有效地推动内存墙以提取更高的吞吐量。该设计被集成到新兴的3D DRAM的逻辑层中，作为一种存内计算架构，以进一步增加可用带宽。实验结果表明，所提出的架构比基于GPU的设计实现了高达2.4倍的加速。此外，通过将计算移至更靠近内存的位置，平均功耗降低了37%。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [96] [Minimizing CGYRO HPC Communication Costs in Ensembles with XGYRO by Sharing the Collisional Constant Tensor Structure](https://arxiv.org/abs/2507.22245)
> *通过共享碰撞常数张量结构，XGYRO 在系综中最小化 CGYRO HPC 通信成本*

*Igor Sfiligoi, Emily A. Belli, Jeff Candy* | **Category: cs.DC** | **Updated: 2025-07-29**

**Keywords:** CGYRO, HPC, 通信成本, XGYRO, 系综模拟, 内存优化

**Comment:** 3 pages, 3 figures, Accepted at ICPP25

> **TL;DR:** XGYRO通过在系综模拟中共享碰撞常数张量结构，显著降低了CGYRO模拟的HPC通信成本和内存消耗。

**AI_Comments:** 这项工作的创新之处在于将模拟系综作为一个整体HPC作业来处理，从而能够实现对单个模拟不可行的全局优化。对于资源密集型且通常以系综形式进行的聚变等离子体模拟而言，这种方法尤为重要。通过利用参数扫描模拟中的数据结构共性，该工具有效地解决了实际的性能瓶颈（通信开销和内存消耗），为常见的科研工作流程带来了显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 第一性原理聚变等离子体模拟（如CGYRO）计算和内存密集，导致在使用大量HPC节点时产生显著的通信开销，这对于单个模拟难以避免。而大多数聚变研究又由模拟系综组成，因此需要一种方法来优化整体性能。

**Method:** 开发了名为XGYRO的新工具，该工具将整个CGYRO模拟系综作为一个HPC作业执行。通过将系综视为一个单元，XGYRO可以改变全局缓冲区分配逻辑，并应用仅在系综层面可行的优化。主要的优化在于共享碰撞常数张量结构，因为其值在参数扫描模拟中通常是相同的。

**Result:** 共享碰撞常数张量结构（该结构主导CGYRO模拟的内存消耗）显著减少了每个模拟的内存消耗，从而降低了整体通信开销。

**Conclusion:** XGYRO通过在系综模拟中共享关键数据结构，有效地降低了CGYRO模拟的HPC通信成本和内存使用。

> **ai_Abstract:** 本文介绍了一种名为XGYRO的新工具，旨在优化CGYRO聚变等离子体模拟在高新能计算（HPC）环境中的通信成本。通过将CGYRO模拟系综作为单个HPC作业运行，XGYRO能够实现全局优化，特别是通过在模拟之间共享内存占用主导的碰撞常数张量结构。这种方法显著减少了单个模拟的内存消耗和整体通信开销，解决了大规模聚变研究中的关键挑战。

> **摘要翻译:** 第一性原理聚变等离子体模拟计算和内存密集，CGYRO 也不例外。因此，使用许多 HPC 节点以使问题适应可用内存会导致显著的通信开销，这对于任何单一模拟都难以避免。尽管如此，大多数聚变研究都是由模拟系综组成的，因此我们开发了一个名为 XGYRO 的新工具，它将整个 CGYRO 模拟系综作为单个 HPC 作业执行。通过将系综视为一个单元，XGYRO 可以改变全局缓冲区分配逻辑并应用在任何单一模拟上不可行，但仅在整个系综上可行的优化。主要的节省来自于碰撞常数张量结构的共享，因为其值在参数扫描模拟之间通常是相同的。该数据结构主导了 CGYRO 模拟的内存消耗，因此在整个系综中分发它会为每个模拟带来巨大的内存节省，进而导致整体更低的通信开销。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [138] [Towards Experiment Execution in Support of Community Benchmark Workflows for HPC](https://arxiv.org/abs/2507.22294)
> *面向HPC社区基准工作流的实验执行支持*

*Gregor von Laszewski, Wesley Brewer, Sean R. Wilkinson, Andrew Shao, J. P. Fleischer, Harshad Pitkar, Christine R. Kirkpatrick, Geoffrey C. Fox* | **Category: cs.DC** | **Updated: 2025-07-30**

**Keywords:** HPC, 基准测试, 工作流模板, 实验管理, 适应性

**Comment:** 

> **TL;DR:** 论文提出工作流模板和“基准木工”概念，通过简化实验管理工具来提高HPC基准测试的适应性，并通过Cloudmesh Experiment Executor和SmartSim验证。

**AI_Comments:** 这篇论文通过引入“工作流模板”和“基准木工”的概念，为HPC社区的基准测试提供了一个创新性的方法。它强调了简化实验管理工具对于提高计算工作流适应性的重要性，特别是在教育和实际应用中。通过验证两个现有工具，增强了其提出的解决方案的实用性和可行性。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准测试有限，难以充分展示计算资源能力。

**Method:** 提出工作流模板作为解决方案，提供可适应特定科学应用的设计，并识别常见使用模式。引入“基准木工”概念，通过关注简单实验管理工具来提高计算工作流的适应性。

**Result:** 发现将简单的实验管理工具整合到计算工作流中可以提高适应性，尤其是在教育领域。所提出的概念得到了Cloudmesh的Experiment Executor和HPE的SmartSim这两个工具的验证。

**Conclusion:** 通过Cloudmesh Experiment Executor和HPE SmartSim的验证，证明了工作流模板和“基准木工”概念在提高HPC基准测试适应性方面的有效性，并在多种科学应用中进行了测试。

> **ai_Abstract:** 本文旨在解决HPC领域中现有基准测试难以充分展示计算资源能力的问题。作者提出使用工作流模板作为解决方案，提供可适应特定科学应用的设计，并识别了常见的使用模式。研究发现，通过在计算工作流中集成简单的实验管理工具，可以提高系统的适应性，尤其是在教育方面，并将其命名为“基准木工”。这一概念通过Cloudmesh的Experiment Executor和HPE的SmartSim两个工具得到验证，这些工具已在包括云掩膜、地震预测和AI/ML交互等多种科学应用中进行了测试。

> **摘要翻译:** 演示计算资源能力是现有基准测试面临的一个关键障碍。我们提出工作流模板作为解决方案，为特定的科学应用提供可适应的设计。本文识别了这些模板的常见使用模式，这些模式源于数十年的高性能计算（HPC）经验，包括最近与MLCommons科学工作组的合作。我们发现，在更广泛的计算工作流中专注于简单的实验管理工具可以提高适应性，尤其是在教育领域。这个我们称之为“基准木工”的概念，通过两个独立的工具得到了验证：Cloudmesh的实验执行器（Experiment Executor）和惠普企业（Hewlett Packard Enterprise）的SmartSim。这两个框架功能重叠显著，已在各种科学应用中进行了测试，包括传导云掩膜、地震预测、模拟-AI/ML交互以及计算流体动力学代理的开发。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [180] [A Semi-Supervised Federated Learning Framework with Hierarchical Clustering Aggregation for Heterogeneous Satellite Networks](https://arxiv.org/abs/2507.22339)
> *一种用于异构卫星网络的半监督联邦学习分层聚类聚合框架*

*Zhuocheng Liu, Zhishu Shen, Qiushi Zheng, Tiehua Zhang, Zheng Lei, Jiong Jin* | **Category: cs.DC, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 联邦学习, LEO卫星网络, 半监督学习, 分层聚类, 异构网络

**Comment:** 

> **TL;DR:** 本文提出一种针对异构LEO卫星网络的半监督联邦学习框架，采用分层聚类聚合、稀疏化和自适应量化技术，显著降低处理时间和能耗，同时保持模型精度。

**AI_Comments:** 该论文的创新点在于为LEO卫星网络设计了一个新颖的半监督联邦学习框架，有效应对了异构性和资源受限带来的挑战。通过引入分层聚类聚合、稀疏化和自适应量化，显著优化了通信开销和计算效率，同时保持了模型精度，这对于未来6G网络中的分布式智能应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 低地球轨道（LEO）卫星是6G网络的关键组成部分，用于大规模地球观测和传感任务。联邦学习（FL）为这些资源受限和动态环境中的分布式智能提供了一个有前景的范例。然而，在异构和部分未标记的卫星网络中，实现可靠收敛同时最小化处理时间和能耗仍然是一个巨大的挑战。

**Method:** 我们提出了一种新颖的半监督联邦学习框架，专为具有分层聚类聚合的LEO卫星网络量身定制。为了进一步减少通信开销，我们集成了稀疏化和自适应权重量化技术。此外，我们将FL聚类分为两个阶段：卫星集群聚合阶段和地面站（GSs）聚合阶段。GSs的监督学习指导选定的参数服务器（PS）卫星，这些PS卫星反过来在联邦训练过程中支持完全未标记的卫星。

**Result:** 在卫星网络测试平台上进行的广泛实验表明，与其它对比方法相比，我们提出的方案在保持模型准确性的同时，可以显著减少处理时间（高达3倍）和能耗（高达4倍）。

**Conclusion:** 该框架有效解决了异构和部分未标记LEO卫星网络中联邦学习的收敛、处理时间和能耗挑战，实现了更高的效率和可靠性。

> **ai_Abstract:** 本文提出了一种针对异构LEO卫星网络的半监督联邦学习框架，旨在解决资源受限环境下联邦学习的收敛、处理时间与能耗问题。该框架创新性地结合了分层聚类聚合、稀疏化和自适应权重量化技术，并将联邦学习的聚合过程划分为卫星集群聚合和地面站聚合两个阶段，利用地面站的监督学习来指导未标记卫星的训练。实验结果表明，该方法在保持模型精度的前提下，显著提升了处理效率并降低了能耗。

> **摘要翻译:** 低地球轨道（LEO）卫星正成为6G网络的关键组成部分，许多卫星已被部署以支持大规模地球观测和传感相关任务。联邦学习（FL）为这些资源受限和动态环境中的分布式智能提供了一个有前景的范例。然而，在异构和部分未标记的卫星网络中，实现可靠收敛，同时最小化处理时间和能耗，仍然是一个巨大的挑战。为了解决这一挑战，我们提出了一种新颖的半监督联邦学习框架，该框架专为具有分层聚类聚合的LEO卫星网络量身定制。为了进一步减少通信开销，我们集成了稀疏化和自适应权重量化技术。此外，我们将FL聚类分为两个阶段：卫星集群聚合阶段和地面站（GSs）聚合阶段。GSs的监督学习指导选定的参数服务器（PS）卫星，这些PS卫星反过来在联邦训练过程中支持完全未标记的卫星。在卫星网络测试平台上进行的广泛实验表明，与其它对比方法相比，我们提出的方案在保持模型准确性的同时，可以显著减少处理时间（高达3倍）和能耗（高达4倍）。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [222] [Leveraging Caliper and Benchpark to Analyze MPI Communication Patterns: Insights from AMG2023, Kripke, and Laghos](https://arxiv.org/abs/2507.22372)
> *利用 Caliper 和 Benchpark 分析 MPI 通信模式：来自 AMG2023、Kripke 和 Laghos 的见解*

*Grace Nansamba, Evelyn Namugwanya, David Boehme, Dewi Yokelson, Riley Shipley, Derek Schafer, Michael McKinsey, Olga Pearce, Anthony Skjellum* | **Category: cs.DC** | **Updated: 2025-07-30**

**Keywords:** Caliper, MPI, 通信模式, HPC, 性能分析

**Comment:** 10 pages, 6 figures

> **TL;DR:** 研究人员通过引入“通信区域”增强了 Caliper HPC 分析工具，以捕捉 MPI 通信的详细指标，并利用 AMG2023、Kripke 和 Laghos 等应用揭示了通信瓶颈和行为，同时展示了其在 CPU 和 GPU 系统上分析可伸缩性的能力。

**AI_Comments:** 该论文的创新之处在于通过引入“通信区域”显著扩展了 Caliper 的功能，使其能够对 MPI 通信进行前所未有的深入分析，包括数据和进程级别的详细指标。这对于识别和优化大规模高性能计算应用中的性能瓶颈至关重要。将 Caliper 与 Thicket 结合进行可视化分析，以及利用 Benchpark 真实应用进行验证，都提升了研究的实用性和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决在 Caliper HPC 分析工具中无法捕获通信数据和 MPI 进程的详细指标的问题，本研究旨在引入“通信区域”以实现对 MPI 通信模式的深入分析，进而识别高性能计算（HPC）应用中的瓶颈。

**Method:** 研究人员在 Caliper HPC 分析工具中引入了“通信区域”功能，使其能够捕获通信数据及相关 MPI 进程的指标。随后，利用 Benchpark 套件中的 AMG2023、Kripke 和 Laghos 三个代表性应用，验证了该功能的实用性。此外，结合 Caliper 和 Thicket 工具，创建了新的 MPI 通信模式可视化图，包括光环交换，并比较了 CPU 和 GPU 系统的扩展行为。

**Result:** 增强后的 Caliper 能够揭示详细的通信行为。研究人员成功创建了 MPI 通信模式的新可视化图，包括光环交换。研究发现通信瓶颈和详细行为，证明了 Caliper 中新增的特殊区域具有显著的实用性。研究还展示了 CPU 和 GPU 导向系统之间的比较扩展行为，并能够观察给定应用内不同区域的可扩展性和消息流量指标的差异。

**Conclusion:** 在 Caliper 中加入“通信区域”显著增强了其分析 MPI 通信模式的能力，揭示了高性能计算应用中的关键瓶颈和详细行为，并证明了其在理解不同硬件架构扩展性方面的实用性。

> **ai_Abstract:** 本研究在 Caliper HPC 分析工具中引入了“通信区域”，以捕获以前无法获得的关于 MPI 通信数据和进程的详细指标。通过对 AMG2023、Kripke 和 Laghos 等 Benchpark 应用的分析，增强的 Caliper 结合 Thicket 工具创建了新的 MPI 通信模式可视化图，成功揭示了通信瓶颈和详细行为。研究结果强调了新功能对于分析不同硬件架构（CPU 和 GPU）上应用程序可伸缩性和消息流量的显著价值。

> **摘要翻译:** 我们在广泛使用的 Caliper HPC 分析工具中引入了“通信区域”。通信区域是一种注释，能够捕获关于正在通信的数据的指标（包括这些指标的统计数据），以及参与通信的 MPI 进程的指标，这是 Caliper 以前无法实现的。我们通过三个代表性的建模和仿真应用程序——AMG2023、Kripke 和 Laghos——探索了通信区域的实用性，这些应用程序都属于包含 Caliper 注释的综合 Benchpark 套件。增强后的 Caliper 揭示了详细的通信行为。结合使用 Caliper 和 Thicket，我们创建了 MPI 通信模式的新可视化图，包括光环交换。我们的发现揭示了通信瓶颈和详细行为，表明 Caliper 中特殊区域的添加具有显著的实用性。研究展示了面向 CPU 和 GPU 系统的比较扩展行为；我们能够查看给定应用程序内的不同区域，并观察可伸缩性和消息流量指标的差异。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [263] [DSPE: Profit Maximization in Edge-Cloud Storage System using Dynamic Space Partitioning with Erasure Code](https://arxiv.org/abs/2507.22801)
> *DSPE：使用动态空间分区和擦除码在边缘云存储系统中实现利润最大化*

*Shubhradeep Roy, Suvarthi Sarkar, Vivek Verma, Aryabartta Sahu* | **Category: cs.DC** | **Updated: 2025-07-30**

**Keywords:** 边缘云存储, 动态空间分区, 擦除码, 利润最大化, 协同缓存

**Comment:** 

> **TL;DR:** 该论文提出了一种名为DSPE的利润驱动框架，通过协同缓存、擦除码和弹性存储分区来解决边缘服务器存储容量有限的问题，从而在动态工作负载下提高系统盈利能力5%到8%。

**AI_Comments:** 该论文的创新点在于结合了动态空间分区、擦除码和协同缓存，以利润最大化为目标，有效地解决了边缘存储容量限制和动态工作负载下的数据访问效率问题。特别是其将存储空间划分为私有和公共区域，并针对性地进行管理，体现了对边缘计算特性的深刻理解。该方法通过量化盈利能力的提升，展示了其在实际应用中的潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 边缘服务器的存储容量有限，在处理高容量和低延迟敏感的数据访问请求时面临巨大挑战，尤其是在动态工作负载下。

**Method:** 本文提出了一个利润驱动的框架，该框架整合了协同缓存、擦除码和弹性存储分区三个关键机制。它动态地将每个边缘服务器的存储空间划分为私有区域和公共区域。私有区域根据传入请求速率进一步细分为不同的访问点，以实现对数据局部性和所有权的自适应控制。设计了数据放置和替换策略，以确定如何以及在何处存储或逐出编码数据块，从而在截止日期内最大化数据访问。私有区域服务本地AP的请求，而公共区域处理来自相邻服务器的协作存储请求。

**Result:** 实验结果表明，与现有最先进的方法相比，在不同工作负载条件下，所提出的方法将整体系统盈利能力提高了大约5%到8%。

**Conclusion:** 该论文通过引入动态空间分区和弹性缓存策略，有效解决了边缘云存储系统中有限存储容量和动态工作负载下的盈利能力问题，显著提升了系统性能。

> **ai_Abstract:** 该论文针对边缘云存储系统中边缘服务器存储容量有限以及动态工作负载下低延迟数据访问的挑战，提出了一种名为DSPE的利润驱动框架。该框架整合了协同缓存、擦除码和弹性存储分区机制，通过动态划分存储区域（私有和公共），并设计数据放置与替换策略，旨在最大化数据访问的利润。实验结果表明，与现有方法相比，DSPE在系统盈利能力上提升了5%至8%。

> **摘要翻译:** 边缘存储系统通过将存储和计算更接近最终用户，已成为现代云网络中实现低延迟数据访问的关键推动者。然而，边缘服务器有限的存储容量在处理高容量和延迟敏感的数据访问请求时带来了重大挑战，尤其是在动态工作负载下。在这项工作中，我们提出了一个利润驱动的框架，该框架整合了三个关键机制：协同缓存、擦除码和弹性存储分区。与传统复制不同，擦除码实现了空间高效的冗余，允许从K个编码块中的任意K加M个子集中重建数据。我们动态地将每个边缘服务器的存储空间划分为私有区域和公共区域。私有区域根据其传入请求速率进一步细分到各个访问点，从而实现对数据局部性和所有权的自适应控制。我们设计了一种数据放置和替换策略，用于确定如何以及在何处存储或逐出编码数据块，以在截止日期内最大化数据访问。私有区域服务来自本地AP的请求，而公共区域处理来自相邻服务器的协作存储请求。我们提出的动态空间分区和弹性缓存策略在合成数据和来自Netflix和Spotify的真实世界痕迹上进行了评估。实验结果表明，与现有最先进的方法相比，在不同工作负载条件下，我们的方法将整体系统盈利能力提高了大约5%到8%。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [348] [Understanding Power and Energy Utilization in Large Scale Production Physics Simulation Codes](https://arxiv.org/abs/2201.01278)
> *理解大规模生产物理模拟代码中的功耗和能源利用*

*Adam Bertsch, Michael R. Collette, Shawn A. Dawson, Si D. Hammond, Ian Karlin, M. Scott McKinley, Kevin Pedretti, Robert N. Rieben, Brian S. Ryujin, Arturo Vargas, Kenneth Weiss* | **Category: cs.DC** | **Updated: 2025-07-30**

**Keywords:** 功耗, 能源利用, 物理模拟, E级计算, TDP

**Comment:** 15 pages; accepted to the International Journal of High Performance
  Computing Applications (IJHPCA)

> **TL;DR:** 研究发现，大规模物理模拟代码的实际能耗远低于处理器热设计功耗（TDP）的估算，TDP不是衡量实际功耗的准确指标。

**AI_Comments:** 这篇论文揭示了在高性能计算领域一个重要的误区，即处理器TDP不能准确反映实际应用（特别是大规模物理模拟）的功耗。其创新之处在于通过实际测量而非理论估算，提供了关于真实世界能耗的宝贵数据，对于未来E级计算系统的设计和优化具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于在通往E级计算的道路上，功耗是转向先进架构的常见原因，且实际功耗测量困难，人们倾向于使用TDP作为替代。然而，TDP被指出并非实际功耗的准确指标，因此需要通过实验理解实际的功耗和能源利用情况。

**Method:** 在劳伦斯利弗莫尔和桑迪亚国家实验室的商用和先进技术系统上，进行了一系列实验来测量运行模拟代码时的功耗和能源使用情况。

**Result:** 实验表明，大规模劳伦斯利弗莫尔模拟代码比简单的处理器TDP模型所暗示的效率要高得多。

**Conclusion:** 处理器热设计功耗（TDP）不能代表运行模拟时的典型功耗使用情况，大规模生产物理模拟代码的实际能耗效率更高。

> **ai_Abstract:** 本文研究了大规模生产物理模拟代码的功耗和能源利用。鉴于功耗是E级计算面临的关键挑战，且处理器热设计功耗（TDP）常被错误地用作功耗替代指标，作者通过在劳伦斯利弗莫尔和桑迪亚国家实验室的系统上进行实验，测量了运行模拟代码的实际功耗和能耗。结果显示，这些大规模模拟代码的实际能源效率远高于TDP模型所预测的。

> **摘要翻译:** 功耗是通往E级计算之路转向先进架构的常见原因。这既是由于成功部署和运行这些机器所需的供电的实际考量，也是对运行大型模拟时能耗的担忧。由于获取准确的功耗测量可能具有挑战性，使用处理器热设计功耗（TDP）作为替代可能很诱人，因为它简单易得。然而，TDP并不能代表运行模拟时的典型功耗使用情况。我们利用劳伦斯利弗莫尔和桑迪亚国家实验室的商用和先进技术系统，进行了一系列实验来测量运行模拟代码时的功耗和能源使用情况。这些实验表明，大规模劳伦斯利弗莫尔模拟代码比简单的处理器TDP模型所暗示的效率要高得多。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [376] [SP-Chain: Boosting Intra-Shard and Cross-Shard Security and Performance in Blockchain Sharding](https://arxiv.org/abs/2407.06953)
> *SP-Chain：提升区块链分片中的分片内和跨分片安全性和性能*

*Mingzhe Li, You Lin, Wei Wang, Jin Zhang* | **Category: cs.DC** | **Updated: 2025-07-30**

**Keywords:** 区块链分片, 安全性, 性能, SP-Chain, 跨分片

**Comment:** Published in IOTJ

> **TL;DR:** SP-Chain是一种新的区块链分片系统，通过两阶段并发投票、无偏领导者轮换和证明辅助的跨分片交易处理机制，显著提升了分片内和跨分片的安全性和性能，实现了高吞吐量和低延迟。

**AI_Comments:** SP-Chain通过其在分片内和跨分片机制上的创新，有效地解决了现有区块链分片系统在安全性与性能之间难以兼顾的问题，特别是在恶意行为下的表现令人印象深刻。其提出的两阶段并发投票和无偏领导者轮换方案对于提升分片内效率和抵抗攻击具有重要意义。证明辅助的跨分片交易处理机制也有效地降低了开销。这篇论文的贡献在于提供了一个实用且高性能的区块链分片解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的区块链分片协议在保护安全性方面存在问题，或者为了安全性牺牲了大量性能，无法同时满足分片内和跨分片的高性能和高安全性要求。

**Method:** 提出SP-Chain系统。在分片内方面，设计了两阶段并发投票方案以提供高系统吞吐量和低交易确认延迟；提出了高效的无偏领导者轮换方案以确保恶意行为下的高性能。在跨分片方面，提出了证明辅助的高效跨分片交易处理机制，以低开销保护跨分片交易。该系统基于Harmony实现。

**Result:** SP-Chain在4,000个节点的网络中，即使在恶意行为下也能处理超过10,000笔交易/秒，确认延迟为7.6秒。

**Conclusion:** SP-Chain通过其创新的分片内和跨分片机制，显著提升了区块链分片系统的安全性和性能，能够在大规模网络中实现高吞吐量和低延迟。

> **ai_Abstract:** 本文提出了SP-Chain，一个旨在解决现有区块链分片系统在安全性与性能之间权衡问题的方案。SP-Chain通过引入两阶段并发投票和高效无偏领导者轮换机制增强了分片内安全性和性能，并通过证明辅助的机制优化了跨分片交易处理。实验结果显示，SP-Chain在恶意环境下仍能达到高吞吐量（超过10,000 tx/sec）和低确认延迟（7.6s），验证了其在大规模网络中的有效性。

> **摘要翻译:** 当前区块链克服可扩展性限制的一种有前景的方法是使用分片，即将交易处理分配给多个较小的节点组。一个表现良好的区块链分片系统需要在分片内和跨分片两方面都具有高性能和高安全性。然而，现有协议要么在保护安全性方面存在问题，要么为了安全性牺牲了大量性能。在本文中，我们提出了SP-Chain，一个在分片内和跨分片两方面都增强了安全性和性能的区块链分片系统。在分片内方面，我们设计了两阶段并发投票方案，以提供高系统吞吐量和低交易确认延迟。此外，我们提出了一个高效的无偏领导者轮换方案，以确保在恶意行为下的高性能。在跨分片方面，提出了一种证明辅助的高效跨分片交易处理机制，以低开销保护跨分片交易。我们基于Harmony实现了SP-Chain，并通过大规模部署评估了其性能。广泛的评估表明，SP-Chain在4,000个节点的网络中，即使在恶意行为下也能处理超过10,000笔交易/秒，确认延迟为7.6秒。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [400] [PS-WL: A Probability-Sensitive Wear Leveling scheme for SSD array scaling](https://arxiv.org/abs/2506.19660)
> *PS-WL: 一种面向SSD阵列扩展的概率敏感磨损均衡方案*

*Shuhang Xu, Yunfei Gu, Linhui Liu, Chentao Wu* | **Category: cs.DC** | **Updated: 2025-07-30**

**Keywords:** 固态硬盘, 磨损均衡, 故障概率, 阵列扩展, 有效寿命模型

**Comment:** 

> **TL;DR:** 针对SSD阵列扩展时传统磨损均衡忽略磨损与故障概率非线性关系导致硬盘过早失效的问题，PS-WL提出一种概率敏感的磨损均衡方案，通过直接平衡故障风险来提高系统安全性、效率和稳定性。

**AI_Comments:** PS-WL的创新之处在于将磨损均衡的优化目标从简单的磨损平衡转向更深层次的故障风险平衡，引入了“有效寿命”模型来量化风险，并结合PID控制器进行动态管理，这在提升SSD阵列可靠性和效率方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代数据中心中，基于闪存的固态硬盘（SSD）阵列的扩展是频繁且关键的操作。然而，传统的磨损均衡（WL）范式在扩展过程中存在根本缺陷：它忽略了磨损与故障概率之间的非线性关系，可能导致最脆弱、老化的磁盘过早失效。

**Method:** 提出概率敏感磨损均衡（PS-WL）方案，将优化目标从平衡磨损转移到直接平衡故障风险。其核心是引入一个“有效寿命”模型，该模型源自真实的故障概率，以更准确地评估磁盘寿命。该模型指导PID控制器进行磨损均衡操作，并通过保守区域限制热数据迁移以最小化性能开销。

**Result:** 综合模拟验证了PS-WL优于现有先进方法。结果表明，该方法显著降低了性能开销，最关键的是，在不同的系统配置和工作负载下，持续有效地降低了聚合阵列的故障风险。

**Conclusion:** 通过直接优化可靠性，PS-WL构建了一个从设计上就更安全、更高效、更稳定的可扩展存储系统。

> **ai_Abstract:** 本文提出了一种名为PS-WL的概率敏感磨损均衡方案，旨在解决SSD阵列扩展时传统磨损均衡未能考虑磨损与故障概率非线性关系导致硬盘过早失效的问题。PS-WL通过引入基于真实故障概率的“有效寿命”模型，将优化目标从平衡磨损转向直接平衡故障风险，并利用PID控制器和保守区域来指导磨损均衡操作并最小化性能开销。模拟结果显示，PS-WL能显著降低性能开销并有效降低阵列故障风险，从而构建更安全、高效、稳定的可扩展存储系统。

> **摘要翻译:** 随着基于闪存的固态硬盘（SSD）阵列成为现代数据中心不可或缺的一部分，扩展这些阵列以满足爆炸式的数据增长是一项频繁且关键的操作。然而，在扩展过程中应用的传统磨损均衡（WL）范式存在一个根本缺陷：它忽略了磨损与故障概率之间的非线性关系，可能导致最脆弱、老化的磁盘过早失效。为了从根本上解决这个关键问题，我们提出了概率敏感磨损均衡（PS-WL）方案，该方案将优化目标从平衡磨损转移到直接平衡故障风险。PS-WL的核心是引入一个“有效寿命”模型，该模型源自真实的故障概率，以更准确地评估磁盘寿命。该模型指导PID控制器进行磨损均衡操作，并通过保守区域限制热数据迁移以最小化性能开销。综合模拟验证了PS-WL优于现有先进方法。结果表明，我们的方法显著降低了性能开销，最关键的是，在不同的系统配置和工作负载下，持续有效地降低了聚合阵列的故障风险。这证明通过直接优化可靠性，PS-WL构建了一个从设计上就更安全、更高效、更稳定的可扩展存储系统。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [913] [Accelerating Stable Matching between Workers and Spatial-Temporal Tasks for Dynamic MCS: A Stagewise Service Trading Approach](https://arxiv.org/abs/2502.08386)
> *动态移动群智感知中加速工作者与时空任务的稳定匹配：一种分阶段服务交易方法*

*Houyi Qi, Minghui Liwang, Xianbin Wang, Liqun Fu, Yiguang Hong, Li Li, Zhipeng Cheng* | **Category: cs.DC, cs.NI** | **Updated: 2025-07-29**

**Keywords:** 移动群智感知, 稳定匹配, 分阶段交易, 期货交易, 现货交易

**Comment:** 

> **TL;DR:** 提出了一种分阶段交易框架，通过期货和现货交易机制，在动态移动群智感知网络中实现工作者与时空任务的高效稳定匹配，并证明了其经济和算法特性，实验验证了其优越性。

**AI_Comments:** 该论文提出了一种创新的分阶段服务交易方法，将期货和现货交易理念引入移动群智感知任务匹配中，有效解决了动态环境下的时空任务匹配难题。其理论证明和实验验证增强了方法的可靠性，特别是在考虑网络动态性和任务多样性方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在移动群智感知（MCS）网络中，设计有效的激励机制对于吸引分布式移动用户（工作者）为各种应用（任务）贡献异构数据至关重要。

**Method:** 提出了一种新颖的分阶段交易框架，以实现高效稳定的任务-工作者匹配，该框架整合了期货交易和现货交易阶段。在期货交易阶段，引入了FT-SMP^3机制，实现长期任务分配和基于历史统计与风险感知的路径预规划。在现货交易阶段，开发了ST-DP^2WR机制，通过实时招募和路径调整动态提升任务和工作者的实际效用。

**Result:** 提出的机制满足稳定性、个体理性、竞争均衡和弱帕累托最优等关键经济和算法特性。广泛的实验进一步验证了该框架在实际网络设置中的有效性，在服务质量、计算效率和决策开销方面表现出卓越的性能。

**Conclusion:** 该研究通过提出的分阶段服务交易框架，成功解决了动态移动群智感知网络中工作者与时空任务的稳定匹配问题，并在理论和实践中证明了其优越性。

> **ai_Abstract:** 本文针对移动群智感知（MCS）网络中工作者与任务的有效匹配问题，提出了一种新颖的分阶段服务交易框架。该框架结合了期货交易（FT-SMP^3）和现货交易（ST-DP^2WR）机制，旨在实现高效稳定的任务-工作者匹配，同时考虑任务多样性和网络动态性。研究证明了所提机制的经济和算法特性，并通过实验验证了其在服务质量、计算效率和决策开销方面的优越性能。

> **摘要翻译:** 在移动群智感知（MCS）网络中，设计有效的激励机制对于吸引分布式移动用户（工作者）为各种应用（任务）贡献异构数据至关重要。本文提出了一种新颖的分阶段交易框架，以实现高效稳定的任务-工作者匹配，明确考虑了MCS环境中固有的任务多样性（例如，时空限制）和网络动态性。该框架整合了期货和现货交易阶段。在前者中，我们引入了期货交易驱动的稳定匹配和路径预规划机制（FT-SMP^3），该机制能够基于历史统计数据和风险感知分析，实现长期任务-工作者分配和工作者轨迹的预规划。在后者中，我们开发了现货交易驱动的基于DQN的路径规划和现场工作者招募机制（ST-DP^2WR），该机制通过支持实时招募和路径调整，动态提高了任务和工作者的实际效用。我们严格证明了所提出的机制满足关键的经济和算法特性，包括稳定性、个体理性、竞争均衡和弱帕累托最优。广泛的实验进一步验证了我们框架在实际网络设置中的有效性，在服务质量、计算效率和决策开销方面表现出卓越的性能。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [3] [Not someone, but something: Rethinking trust in the age of medical AI](https://arxiv.org/abs/2504.05331)
> *非某人，而是某物：重新思考医疗AI时代的信任*

*Jan Beger* | **Category: cs.CY, cs.AI, cs.HC** | **Updated: 2025-07-29**

**Keywords:** 医疗AI, 信任, 医疗保健, 生物伦理学, 系统设计

**Comment:** 

> **TL;DR:** 本文认为，对医疗AI的信任并非简单地从人转移到机器，而是一种动态关系，必须通过深思熟虑的设计、负责任的部署和明确的道德责任来建立和维护，并强调透明度、问责制和与良好护理价值观的一致性。

**AI_Comments:** 这篇论文的创新之处在于，它将关于AI在医学中作用的讨论从“AI是否应该存在”转向了“AI如何才能赢得信任”，这是一个更具建设性和实际意义的视角。其跨学科的方法（哲学、生物伦理学、系统设计）为理解和构建对医疗AI的信任提供了一个全面且深刻的框架，超越了单纯的技术可靠性，强调了伦理和设计的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能（AI）在医疗保健领域的深入应用，医疗决策中的信任正在迅速变化，尤其在放射学领域。因此，需要重新思考和探讨如何建立和维护对医疗AI的信任。

**Method:** 这是一篇观点论文，借鉴了哲学、生物伦理学和系统设计领域的知识，探讨了人类信任和机器可靠性之间的关键区别，并提出了建立对AI信任的论点和方法。

**Result:** 对AI的信任并非简单地从人类转移到机器，而是一种动态、不断演变的关系，必须建立和维护。对AI的信任不应建立在模仿同情心或直觉上，而应建立在深思熟虑的设计、负责任的部署和明确的道德责任之上。关键要素包括透明度、问责制以及与良好护理价值观的一致性。

**Conclusion:** 对医疗AI的信任不应被视为理所当然，而应被视为需要随着时间推移而赢得的东西，这需要通过深思熟虑的设计、负责任的部署和明确的道德责任来实现，以避免盲目乐观和本能的恐惧。

> **ai_Abstract:** 本文是一篇观点论文，旨在重新思考医疗AI时代的信任问题。随着AI在医疗领域的广泛应用，尤其在放射学中，对医疗决策的信任模式正在快速改变。文章指出，对AI的信任并非简单地从人类转移到机器，而是一种动态且需要持续建立和维护的关系。它强调，AI应通过深思熟虑的设计、负责任的部署和明确的道德责任来赢得信任，而非模仿人类情感。文章借鉴哲学、生物伦理学和系统设计，着重强调透明度、问责制以及与良好护理价值观的一致性，旨在提供一种平衡的视角，避免盲目乐观和过度恐惧。

> **摘要翻译:** 随着人工智能（AI）在医疗保健领域的嵌入，医疗决策中的信任正在迅速改变。这种转变在放射学领域尤为明显，AI工具越来越多地嵌入到整个影像工作流程中——从排程和获取到解释、报告以及与转诊医生和患者的沟通。这篇观点论文认为，对AI的信任并非简单地从人类转移到机器——它是一种动态的、不断演变的关系，必须建立和维护。它没有争论AI是否属于医学，而是提出了：AI必须赢得什么样的信任，以及如何赢得？它借鉴了哲学、生物伦理学和系统设计，探讨了人类信任和机器可靠性之间的关键区别——强调透明度、问责制以及与良好护理价值观的一致性。它认为，对AI的信任不应建立在模仿同情心或直觉上，而应建立在深思熟虑的设计、负责任的部署和明确的道德责任之上。目标是获得一种平衡的观点——既避免盲目乐观，也避免本能的恐惧。对AI的信任必须被视为需要随着时间推移而赢得的东西，而不是理所当然。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [17] [Failure Risk Prediction in a MOOC: A Multivariate Time Series Analysis Approach](https://arxiv.org/abs/2507.21118)
> *MOOC中的失败风险预测：一种多元时间序列分析方法*

*Anass El Ayady, Maxime Devanne, Germain Forestier, Nour El Mawas* | **Category: cs.CY, cs.AI, cs.LG** | **Updated: 2025-07-17**

**Keywords:** MOOC, 失败预测, 时间序列分析, 学习分析, 行为数据

**Comment:** in French language, Environnements Informatiques pour l'Apprentissage
  Humain 2025, Jun 2025, Villeneuve d'Ascq (Lille), France

> **TL;DR:** MOOCs完成率低，本文利用多元时间序列分析学习行为数据，在课程不同阶段预测有风险的学习者，以提供个性化反馈。

**AI_Comments:** 该论文解决了MOOCs中一个实际且重要的问题。利用多元时间序列分析学习行为数据是一种相关且有前景的方法。研究发现数据丰富性影响预测准确性，这一见解具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** MOOCs完成率低，主要原因是缺乏个性化内容。因此，需要预测学习者表现以提供定制化反馈。

**Method:** 采用多元时间序列分类方法，将学习者的行为轨迹（点击、事件）作为时间序列进行分析，以识别有风险的学习者。实验在开放大学学习分析数据集（OULAD）上进行，涉及三门课程（两门STEM，一门SHS）。

**Result:** 初步结果显示，所评估的方法在预测MOOC学习者失败方面前景广阔。分析还表明，预测准确性受记录交互量影响。

**Conclusion:** 评估的方法在预测MOOC学习者失败方面具有前景，且丰富多样的行为数据对预测准确性至关重要。

> **ai_Abstract:** 本文旨在解决MOOCs完成率低的问题，通过预测学习者失败来提供个性化反馈。研究采用多元时间序列分类方法，分析学习者的行为轨迹（如点击和事件）以识别课程不同阶段的风险学习者。在开放大学学习分析数据集上进行的实验表明，所评估的方法在预测学习者失败方面前景广阔，并强调了丰富交互数据对预测准确性的重要性。

> **摘要翻译:** MOOCs提供免费开放的广泛访问，但完成率仍然很低，这通常是由于缺乏个性化内容。为了解决这个问题，预测学习者表现以提供定制化反馈至关重要。行为轨迹（如点击和事件）可以作为时间序列进行分析，以预测学习者的结果。这项工作比较了多元时间序列分类方法，以在课程的不同阶段（例如5周、10周后）识别有风险的学习者。实验评估在开放大学学习分析数据集（OULAD）上进行，重点关注三门课程：两门STEM课程和一门SHS课程。初步结果表明，所评估的方法在预测MOOC学习者失败方面前景广阔。分析还表明，预测准确性受记录交互量的影响，突出了丰富多样行为数据的重要性。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [37] [The Dual Personas of Social Media Bots](https://arxiv.org/abs/2504.12498)
> *社交媒体机器人的双重身份*

*Lynnette Hui Xian Ng, Kathleen M. Carley* | **Category: cs.CY, cs.SI** | **Updated: 2025-07-29**

**Keywords:** 社交媒体机器人, 机器人身份, 信息传播, 机器人检测, 好坏二元性

**Comment:** 

> **TL;DR:** 该研究介绍了社交媒体机器人的15种不同身份，并指出它们并非都是恶意的，强调应根据其用途而非普遍性来制定机器人检测政策。

**AI_Comments:** 这篇论文的创新之处在于它打破了对社交媒体机器人单一的负面认知，提出了更细致的“身份”分类方法。这对于理解和管理在线信息生态系统具有重要意义，尤其是在机器人检测和政策制定方面提供了新的视角，强调了区分机器人用途而非一概而论的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的研究主要关注社交媒体机器人的恶意性质，但作者认为机器人具有多种不同的身份，并且可以用于传播好信息和坏信息，并非单一的“坏”代理。因此，需要更细致地理解和分类这些机器人。

**Method:** 作者引入了15种社交媒体机器人代理身份，分为基于内容的机器人身份和基于行为的机器人身份两大类。他们还制定了衡量机器人好坏二元性的标准，详细阐述了好机器人和坏机器人代理的衡量指标。

**Result:** 论文提出了15种社交媒体机器人代理身份，并将其分为内容型和行为型两大类。同时，建立了衡量机器人好坏的标准和指标。

**Conclusion:** 本文提出了一项指导方针，旨在为机器人检测法规提供信息，强调政策应关注这些代理如何被使用，而不是一概而论地将机器人代理称为坏的。

> **ai_Abstract:** 这篇论文探讨了社交媒体机器人的多面性，挑战了它们普遍被视为恶意的传统观点。文章提出了15种机器人身份，并将其归类为基于内容和基于行为的两种主要类型。此外，论文还建立了评估机器人好坏的指标，并提出政策制定者应根据机器人的实际用途而非其本身来制定检测法规。

> **摘要翻译:** 社交媒体机器人是参与在线对话的AI代理。大多数研究都关注通用机器人和这些代理的恶意性质。然而，机器人有许多不同的身份，每种身份都专门针对特定的行为或内容特征。机器人并非单一的坏，因为它们既用于传播好信息也用于传播坏信息。在本文中，我们介绍了社交媒体机器人的十五种代理身份。这些身份分为两大主要类别：基于内容的机器人身份和基于行为的机器人身份。我们还形成了衡量机器人好坏二元性的标准，详细阐述了好机器人和坏机器人代理的衡量指标。我们的工作提出了一项指导方针，旨在为机器人检测法规提供信息，强调政策应关注这些代理如何被使用，而不是一概而论地将机器人代理称为坏的。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [80] [Trustworthy AI: UK Air Traffic Control Revisited](https://arxiv.org/abs/2507.21169)
> *可信赖人工智能：英国空中交通管制再探*

*Rob Procter, Mark Rouncefield* | **Category: cs.CY, cs.AI, I.2.1** | **Updated: 2025-07-25**

**Keywords:** 可信赖人工智能, 空中交通管制, 社会技术挑战, 人种学研究, 安全关键应用

**Comment:** 6 pages

> **TL;DR:** 本文探讨了在组织环境中采用人工智能所面临的社会技术挑战，并基于一项正在进行的空中交通管制人种学研究，揭示了可信赖人工智能的需求，尤其是在安全关键应用领域。

**AI_Comments:** 本文的创新之处在于其采用人种学研究方法，深入探讨了人工智能在实际组织环境中（特别是安全关键领域如空中交通管制）的社会技术挑战。它强调了在构建可信赖AI时，不仅要关注技术本身，还要考虑用户与工具之间的信任关系，这对于推动AI的实际落地具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 相关文献中，关于在组织环境中采用人工智能所面临的社会技术挑战的探讨，以及可信赖人工智能需求研究中忽视人们如何处理日常工作中工具信任问题的现象，是本文的研究动机。

**Method:** 本文采用了一项正在进行的空中交通管制工作中的工具使用人种学研究。

**Result:** 研究揭示了当前工具在空中交通管制工作中如何被使用，以及这对空中交通管制及其他安全关键应用领域中可信赖人工智能的需求有何启示。

**Conclusion:** 研究结果有助于理解在安全关键领域中可信赖人工智能的具体需求，强调了社会技术因素在人工智能采纳中的重要性。

> **ai_Abstract:** 本文通过一项针对空中交通管制领域中现有工具使用情况的人种学研究，探讨了在组织环境中采用人工智能所面临的社会技术挑战。研究旨在弥补当前可信赖人工智能研究中对实际工作场景中信任问题关注不足的空白，并揭示了空中交通管制及其他安全关键应用领域对可信赖人工智能的需求。

> **摘要翻译:** 探索组织环境中人工智能应用所面临的社会技术挑战，在相关文献中迄今为止仍 largely absent。特别是，对可信赖人工智能需求的研究通常忽视了人们在日常工作实践中如何处理对所使用工具的信任问题。本文介绍了一项正在进行的空中交通管制工作中当前工具使用情况的人种学研究的一些发现，以及它揭示的关于空中交通管制和其他安全关键应用领域中可信赖人工智能的需求。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [136] [A ChatGPT-based approach for questions generation in higher education](https://arxiv.org/abs/2507.21174)
> *一种基于ChatGPT的高等教育问题生成方法*

*Sinh Trong Vu, Huong Thu Truong, Oanh Tien Do, Tu Anh Le, Tai Tan Mai* | **Category: cs.CY, cs.AI** | **Updated: 2025-07-30**

**Keywords:** ChatGPT, 问题生成, 高等教育, 大型语言模型, 评估

**Comment:** Proceedings of the 1st ACM Workshop on AI-Powered Q&A Systems for
  Multimedia. 2024

> **TL;DR:** 该研究探索了利用ChatGPT在高等教育中生成测验问题的方法，并通过盲测评估，初步结果显示出简化学习者评估的潜力。

**AI_Comments:** 该研究的创新点在于将ChatGPT应用于高等教育中的题目生成，并关注了交互式提示模式的设计和实际利益相关者的评估。其重要性在于为高等教育机构提供了一种潜在的、更高效的评估工具。局限性可能在于其初步结果仅来自一个机构（越南银行学院），且“盲测”的评估深度有待进一步探讨，通用性可能需要更多验证。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型已被广泛应用于现实生活，本研究旨在探索ChatGPT在高等教育中生成测验问题和评估学习者的应用，以提高效率并提供独特的用户体验。

**Method:** 本研究探索了交互式提示模式，以设计最佳的AI驱动题库创建过程。生成的题目通过向讲师和学习者等利益相关者发送“盲测”调查进行评估。

**Result:** 在越南银行学院的初步结果相对乐观，表明该方法在简化高等教育机构学习者评估所需的时间和精力方面具有潜在方向。

**Conclusion:** 研究结果表明，基于ChatGPT的方法在高等教育中生成问题和评估学习者方面具有潜力，可以有效简化评估过程。

> **ai_Abstract:** 本论文探讨了基于ChatGPT在高等教育中生成测验问题和评估学习者的应用。研究通过探索交互式提示模式来设计AI驱动的题库创建流程，并利用“盲测”调查对生成的问题进行评估。初步结果显示，该方法在简化高等教育机构的学习者评估时间和精力方面具有前景。

> **摘要翻译:** 大型语言模型已广泛应用于现实生活的许多方面，为企业带来了显著的效率提升，并提供了独特的用用户体验。在本文中，我们重点探索了基于大型语言模型的聊天机器人ChatGPT，在支持高等教育工作者生成测验问题和评估学习者方面的应用。具体来说，我们探索了交互式提示模式，以设计一个最优的AI驱动的题库创建过程。生成的题目通过向包括讲师和学习者在内的各种利益相关者发送的“盲测”调查进行评估。越南银行学院的初步结果相对乐观，这表明了在高等教育机构中简化学习者评估所需时间和精力的潜在方向。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [192] [The Human Capital Ontology (Extended Abstract)](https://arxiv.org/abs/2507.21175)
> *人力资本本体论（扩展摘要）*

*Shane Babcock, Maxwell Farrington, John Gugliotti* | **Category: cs.CY** | **Updated: 2025-07-26**

**Keywords:** 本体论, 人力资本, 人事管理局, 职业系列, 行动性质

**Comment:** 3 pages. 2 figures. Conference: Semantic Technology for Intelligence,
  Defense, and Security (STIDS 2024)

> **TL;DR:** 人力资本本体论（HCO）是一个用于表示美国人事管理局（OPM）数据标准，并对联邦政府职位进行分类的本体论，它扩展了通用核心本体和基本形式本体，并用于描述人力资源行动和职业分类。

**AI_Comments:** 该论文介绍的人力资本本体论（HCO）在标准化和整合美国联邦政府人力资本数据方面具有重要意义。其创新之处在于将现有的数据标准（如OPM的NOA代码和职业分类）整合到一个统一的本体框架中，并与外部标准（如BLS的SOC代码）进行关联。这有助于提高数据的一致性、互操作性和可分析性，对于政府机构进行人力资源管理和决策制定具有实际价值。该工作也为其他大型组织的数据标准化提供了参考。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是创建一个本体论来表示美国人事管理局（OPM）维护和使用的数据标准，以便表示人力资本操作和对职位进行分类，并增强结构化数据驱动的人力资本测量水平。

**Method:** 人力资本本体论（HCO）是一个本体论，它扩展了通用核心本体（Common Core Ontologies）和上层基本形式本体（Basic Formal Ontology, BFO）。HCO表示OPM的行动性质（NOA）代码，用于描述人力资源人事行动。它还表示职业组、工作族及其细分的职业系列以及相应的代码，用于对联邦政府的白领和蓝领职位进行分类和评级。HCO还编码了OPM职业系列与美国劳工统计局维护的标准职业分类代码之间的交叉参考。

**Result:** HCO提供了OPM行动性质（NOA）代码的表示，这些代码用于描述人力资源人事行动。它还表示了职业组、工作族和职业系列及其对应的代码，用于对联邦政府的白领和蓝领职位进行分类和评级。此外，HCO还编码了OPM职业系列与美国劳工统计局的标准职业分类代码之间的交叉参考。论文还报告了HCO在美国政府内部的近期和计划应用，以及提升结构化数据驱动的人力资本测量水平的并行努力。

**Conclusion:** 本文档记录并论证了HCO建模上述内容的方法，并报告了HCO在美国政府中的近期和计划应用。此外，还报告了提升结构化数据驱动的人力资本测量水平的并行努力。

> **ai_Abstract:** 人力资本本体论（HCO）是一个扩展自通用核心本体和基本形式本体的本体论，旨在标准化并表示美国人事管理局（OPM）的人力资本运营数据，包括人事行动代码（NOA）、职业分类（职业组、工作族、职业系列）及其与美国劳工统计局标准职业分类代码的交叉参考。本文档不仅阐述了HCO的建模方法，还介绍了其在美国政府的实际应用以及在提升结构化人力资本测量方面的并行工作。

> **摘要翻译:** 人力资本本体论（HCO）是一个本体论，它代表了美国人事管理局（OPM）维护和使用的数据标准，用于表示人力资本运营和对职位进行分类。HCO是通用核心本体论和上层基本形式本体论（BFO）的扩展。HCO提供了OPM行动性质（NOA）代码的表示，这些代码用于描述人力资源人事行动。HCO还表示职业组和工作族，以及这些组细分的职业系列，以及它们对应的代码，这些代码由OPM用于对联邦政府的白领和蓝领职位进行分类和评级。HCO还编码了OPM职业系列与美国劳工统计局维护的相应标准职业分类代码之间的交叉参考。除了记录和论证HCO对上述内容进行建模的方法外，我们还报告了HCO在美国政府中的近期和计划应用。我们还报告了我们为增强结构化数据驱动的人力资本测量水平而进行的并行努力。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [248] [When Proximity Falls Short: Inequalities in Commuting and Accessibility by Public Transport in Santiago, Chile](https://arxiv.org/abs/2507.21743)
> *当邻近性不足时：智利圣地亚哥公共交通通勤和可达性不平等*

*Cesar Marin-Flores, Leo Ferres, Henrikki Tenkanen* | **Category: cs.CY** | **Updated: 2025-07-29**

**Keywords:** 通勤不平等, 可达性, 移动数据, 圣地亚哥, 公共交通

**Comment:** 30 pages, Journal Paper

> **TL;DR:** 该研究利用手机数据分析了智利圣地亚哥的通勤模式和可达性不平等，发现平均通勤时间在社会经济群体间一致，但高收入群体尽管居住在机会密度高的区域，通勤时间并未更短，且土著人口和性别间存在显著差异，表明通勤不平等与社会人口结构紧密相关。

**AI_Comments:** 该研究的创新之处在于利用大规模移动网络数据（XDRs）进行动态分析，突破了传统静态模型的局限性。其重要性在于揭示了空间邻近性与实际出行体验之间的关键脱节，挑战了传统的城市规划假设。同时，研究强调了土著人口和性别等特定弱势群体的通勤不平等，为更细致的政策干预提供了依据。研究的局限性可能在于其对智利圣地亚哥的聚焦，以及对移动数据依赖可能引入的偏差。

<details>
  <summary>Details</summary>

**Motivation:** 传统的城市可达性测量方法依赖静态模型或调查数据，而移动网络的位置信息使得大规模、动态分析人们如何在城市中出行成为可能。本研究旨在利用手机活动数据（XDRs）分析智利圣地亚哥的通勤模式和可达性不平等。

**Method:** 研究使用来自手机活动的扩展详细记录（XDRs）来分析通勤模式。首先，识别居住和工作地点，并使用R5多模式路径引擎（结合公共交通和步行）建模通勤路线。为了探索空间模式，研究应用了双变量空间聚类分析（LISA）和回归技术。

**Result:** 研究发现，平均通勤时间在不同社会经济群体之间保持一致。然而，尽管高收入人群居住在机会密度更高的区域，他们并未持续性地经历更短的通勤时间，这突显了空间邻近性与实际出行体验之间的脱节。分析揭示了不同社会人口群体之间，特别是土著人口分布和性别方面存在的显著差异。

**Conclusion:** 研究结果表明，圣地亚哥的通勤和可达性不平等与更广泛的社会和人口结构密切相关。

> **ai_Abstract:** 本研究利用手机数据（XDRs）动态分析了智利圣地亚哥的通勤模式和可达性不平等，超越了传统的静态模型。研究识别居住和工作地点，并使用结合公共交通和步行的多模式路径引擎建模通勤路线。结果显示，尽管平均通勤时间在社会经济群体间一致，但高收入人群即使居住在机会密度高的区域，通勤时间也并未更短，揭示了空间邻近性与实际出行体验之间的脱节。研究还发现土著人口和性别间存在显著差异，表明通勤和可达性不平等与更广泛的社会人口结构紧密相关。

> **摘要翻译:** 城市可达性的传统衡量方法通常依赖于静态模型或调查数据。然而，来自移动网络的位置信息现在能够对人们如何驾驭城市进行大规模、动态的分析。本研究利用源自手机活动的扩展详细记录（XDRs）来分析智利圣地亚哥的通勤模式和可达性不平等。首先，我们识别居住和工作地点，并使用R5多模式路径引擎（结合公共交通和步行）建模通勤路线。为了探索空间模式，我们应用了双变量空间聚类分析（LISA）以及回归技术，以识别独特的通勤行为及其与弱势人口群体的契合度。我们的发现揭示，平均通勤时间在不同社会经济群体之间保持一致。然而，尽管居住在机会密度更高的区域，高收入人群并未持续性地经历更短的通勤时间。这突显了空间邻近性与实际出行体验之间的脱节。我们的分析揭示了社会人口群体之间存在的显著差异，特别是关于土著人口和性别的分布。总的来说，我们研究的发现表明，圣地亚哥的通勤和可达性不平等与更广泛的社会和人口结构密切相关。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [303] [High hopes for "Deep Medicine"? AI, economics, and the future of care](https://arxiv.org/abs/2507.21054)
> *对“深度医学”抱有高度期望？人工智能、经济学与护理的未来*

*Robert Sparrow, Joshua Hatherley* | **Category: cs.CY, cs.AI, cs.HC, cs.LG** | **Updated: 2025-04-15**

**Keywords:** 医疗AI, 医患关系, 深度医学, 人工智能, 医疗保健

**Comment:** 

> **TL;DR:** 本文批判性地审视了对医疗AI的乐观预测，认为AI可能不会改善反而会损害医患关系和满意度。

**AI_Comments:** 这篇论文提供了一个对医疗AI发展持批判性态度的重要视角，挑战了当前普遍存在的乐观情绪。它强调了在推广AI应用时，除了技术效率，还需要关注其对医患关系和人文关怀的潜在负面影响，这对于未来医疗政策和技术发展具有重要启示意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在挑战埃里克·托波尔（Eric Topol）在《深度医学》一书中提出的关于人工智能将显著改善医疗保健文化的乐观观点，指出实际情况可能恰恰相反，即AI的使用可能对医患关系产生负面影响。

**Method:** Not mentioned in abstract

**Result:** 医疗人工智能的使用似乎可能进一步侵蚀治疗关系，并威胁专业人员和患者的满意度，而非促进医患亲密关系的回归。

**Conclusion:** 与普遍的乐观预测相反，医疗AI不太可能促进医患之间更富同情心的护理，反而可能损害治疗关系并降低专业人员和患者的满意度。

> **ai_Abstract:** 本文对埃里克·托波尔在《深度医学》中提出的医疗AI将带来积极变革的观点进行了批判性审视。作者认为，尽管人们普遍对医疗AI抱有高期望，但有迹象表明，AI的应用可能不会像预期那样促进医患关系的改善或提供更富同情心的护理，反而可能进一步损害治疗关系并降低专业人员和患者的满意度。

> **摘要翻译:** 在备受赞誉的《深度医学》一书中，埃里克·托波尔（Eric Topol）认为，用于医疗保健的人工智能的发展将导致医学文化和实践的巨大转变。他提出，在未来几十年内，人工智能将变得足够复杂，以至于许多医生日常任务可以委托给它。托波尔或许是医学人工智能益处最清晰的倡导者，但绝非唯一一个宣扬其潜力的人，他们认为AI能让医生在未来投入更多时间和精力为患者提供富有同情心的护理。不幸的是，有几个因素预示着医疗保健的未来将呈现截然不同的景象。医疗人工智能的使用非但不能促进医患更亲密关系的回归，反而似乎可能进一步侵蚀治疗关系，并威胁专业人员和患者的满意度。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [304] [Against racing to AGI: Cooperation, deterrence, and catastrophic risks](https://arxiv.org/abs/2507.21839)
> *反对AGI竞赛：合作、威慑与灾难性风险*

*Leonard Dung, Max Hellrigel-Holderbaum* | **Category: cs.CY, cs.AI** | **Updated: 2025-07-29**

**Keywords:** AGI竞赛, 灾难性风险, 国际合作, AI安全, 通用人工智能

**Comment:** 

> **TL;DR:** 论文反对AGI竞赛，认为其会增加灾难性风险并削弱AI安全研究，且竞赛的益处被高估；提倡国际合作和协调作为更好的替代方案。

**AI_Comments:** 这篇论文的创新之处在于它不仅指出了AGI竞赛的潜在危险性，更重要的是，它提出了具体的替代方案——国际合作、协调与威慑。这超越了单纯的风险警示，为AI治理提供了建设性的思考方向。其重要性在于，在当前全球AI军备竞赛的背景下，它呼吁理性思考，强调了集体安全和长期稳定优于短期竞争利益。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在反驳“AGI竞赛论”，即主要AI开发参与者为了抢先竞争对手而加速开发通用人工智能。作者认为这种竞赛的弊大于利，并提出了更优的替代方案。

**Method:** 作者通过论证和分析来反对AGI竞赛。他们首先指出AGI竞赛的缺点被低估，包括增加灾难性风险和损害AI安全研究；其次，质疑竞赛胜利所带来的好处是否如预期般巨大；最后，提出国际合作、协调和威慑措施是更优的替代方案。

**Result:** 论文指出AGI竞赛会大幅增加AI带来的灾难性风险（包括核不稳定），并削弱AI安全研究的有效性。同时，竞赛的预期收益可能被高估，因为胜者不一定能完全主导败者。相比之下，国际合作、协调和威慑措施是风险更小且能带来类似收益的替代方案。

**Conclusion:** AGI竞赛不符合任何一方的自身利益，因为鼓励和寻求围绕AI问题的国际合作是更可取的行动。

> **ai_Abstract:** 这篇论文批判了当前主要AI参与者之间加速开发通用人工智能的“AGI竞赛”模式。作者认为，这种竞赛会显著增加AI相关的灾难性风险，如核不稳定，并阻碍AI安全研究的进展。同时，论文质疑竞赛胜利所能带来的主导地位是否被夸大。文章提出，国际合作、协调以及适当的威慑措施是更安全且同样能实现目标的可行替代方案。因此，论文主张，AGI竞赛并非最佳路径，国际合作才是更符合各方利益的选择。

> **摘要翻译:** AGI竞赛是指，在AI发展中的主要参与者，尤其是强大的国家，为了在竞争对手有机会之前构建出高度能力的AI，特别是通用人工智能（AGI），而加速其前沿AI发展的自身利益观点。我们反对AGI竞赛。首先，AGI竞赛的弊端远高于这种观点所描绘的。AGI竞赛将大幅增加AI带来的灾难性风险，包括核不稳定，并损害技术性AI安全研究的有效性前景。其次，竞赛的预期收益可能低于AGI竞赛的支持者所认为的。特别是，竞赛的胜利是否能使胜利者完全支配失败者是值得怀疑的。第三，国际合作与协调，以及可能精心设计的威慑措施，构成了AGI竞赛的可行替代方案，这些方案的风险小得多，并有望提供AGI竞赛所应提供的绝大部分好处。因此，AGI竞赛不符合任何人的自身利益，因为其他行动，特别是激励和寻求围绕AI问题的国际合作，是更可取的。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [360] [Prompt template for a fictitious LLM agent in a content-flagging experiment](https://arxiv.org/abs/2507.21842)
> *用于内容标记实验的虚构LLM代理的提示模板*

*Marie-Therese Sekwenz, Daria Simons, Alina Wundsam* | **Category: cs.CY** | **Updated: 2025-07-29**

**Keywords:** 数字服务法, 法律设计, 用户体验设计, 内容举报机制, 参与式设计

**Comment:** 

> **TL;DR:** 本文通过一个专家研讨会，探讨设计师如何将《欧盟数字服务法》(DSA)等抽象的数字法规（特别是第16条关于内容举报机制）转化为实际的用户体验设计，强调用户体验设计决策在确保法律合规和促进数字人文主义方面的关键作用。

**AI_Comments:** 该论文切入了一个法律、技术和设计交叉领域的关键且及时的话题，尤其是在DSA等数字法规日益增多的背景下。它关注设计师作为中介的角色，提供了深刻的见解。采用定性专家研讨会的方法，获得了宝贵的深入视角。论文呼吁采用参与式和法律设计方法来促进合规和数字人文主义，强调了跨学科合作的重要性，这是其重要贡献。尽管是定性研究，但样本量（N=9）可能限制了其结果的普遍性。

<details>
  <summary>Details</summary>

**Motivation:** 随着《欧盟数字服务法》(DSA)等数字法规的实践，技术、法律和设计之间出现了挑战。本文旨在探讨设计师如何作为中介，将抽象的法律要求转化为用户真实的数字体验，并重点关注DSA第16条规定的内容举报机制设计所面临的挑战。

**Method:** 本研究采用定性案例研究方法，通过与来自不同领域的9位专业设计师进行专家研讨会，探讨他们如何解释法律义务以及这些解释如何反映在讨论和设计解决方案中。

**Result:** 研究发现，用户体验(UX)设计选择会显著影响甚至误导或阻碍用户的决策，从而凸显了设计决策的关键作用。此外，研究表明参与式设计方法可以弥合学科鸿沟，使法律义务在促进合规的设计解决方案中变得易于理解。

**Conclusion:** 本文认为，以法律设计为视角，数字法规和用户体验的共同创造是数字人文主义的核心场所。设计师、工程师和法律学者必须在此协作，以确保系统遵守法律标准，从而应对法规给这些学科带来的挑战。

> **ai_Abstract:** 本文通过对9位专业设计师进行专家研讨会，进行了一项定性案例研究，旨在探讨设计师如何解释并落实《欧盟数字服务法》第16条等数字法规，将其应用于面向用户的内容举报机制设计中。研究强调，用户体验设计选择显著影响用户的决策，并能在遵守法律标准方面起到支持或阻碍作用。作者提倡采用参与式设计和法律设计方法来弥合学科间鸿沟，认为数字法规与用户体验的共同创造是实现数字人文主义的关键，这需要设计师、工程师和法律学者之间的紧密合作。

> **摘要翻译:** 《欧盟数字服务法》(DSA)等数字法规代表着塑造以人为本和以人权为基础的社会框架的重大努力。然而，当这些法律付诸实践时，在技术、法律和设计交叉领域出现了挑战。本文提出了一个定性案例研究，探讨设计师如何充当抽象法律要求与用户真实数字体验之间的中介，重点关注DSA第16条规定的内容举报机制设计。
通过与来自不同领域的专业设计师（N=9）进行专家研讨会，我们探讨了设计师如何解释法律义务以及这些解释如何体现在讨论和设计解决方案中。我们的发现与之前关于举报机制和“黑暗模式”设计的研究相呼应，强调了用户体验(UX)设计选择如何误导或阻碍用户的决策，从而也突出了设计决策的关键作用。
我们展示了参与式设计方法如何弥合学科鸿沟，使法律义务在促进合规的设计解决方案中变得易于理解。
通过以法律设计为视角，我们认为数字法规和用户体验的共同创造是数字人文主义的核心场所；设计师、工程师和法律学者必须在此协作，以确保系统遵守法律标准，从而应对法规给这些学科带来的挑战。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [379] [Examining the sentiment and emotional differences in product and service reviews: The moderating role of culture](https://arxiv.org/abs/2507.21057)
> *考察产品和服务评论中的情感和情绪差异：文化的调节作用*

*Vinh Truong* | **Category: cs.CY** | **Updated: 2025-05-07**

**Keywords:** 情感分析, 产品评论, 服务评论, 文化差异, 在线评论

**Comment:** 

> **TL;DR:** 研究发现产品和服务评论的情绪和情感表达存在差异，且受文化背景调节。

**AI_Comments:** 本研究的创新之处在于区分了产品和服务评论的情绪和情感差异，并引入了文化背景作为调节变量。它将马斯洛需求层次理论和霍夫斯泰德文化框架扩展到在线评论领域，为理解消费者在线表达提供了新的理论视角。研究结果对企业优化营销和客户服务策略具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在区分产品和服务评论中的情感和情绪差异，纠正了以往研究将所有评论一概而论的不足。

**Method:** 本研究使用先进的机器学习技术识别情绪，并分析了霍夫斯泰德文化维度定义的集体主义和个人主义文化对评论模式的影响。

**Result:** 产品评论更注重实用性，语气更中性或务实；服务评论情感参与度更高，表达更广泛的情绪。集体主义文化消费者语言更温和，个人主义文化消费者反馈更直接强烈。性别对情绪变化影响最小，产品类型和文化背景是主导因素。

**Conclusion:** 理论上，本研究将马斯洛需求层次理论和霍夫斯泰德文化框架扩展到在线评论领域，并提出了一个解释消费者表达模式的模型。实践上，为企业优化营销和客户参与策略提供了有价值的指导。

> **ai_Abstract:** 本研究探讨了电子商务平台上产品和服务评论中的情感和情绪差异，纠正了以往研究统一处理评论的不足。研究发现，产品评论更注重实用性且语气中性，而服务评论情感参与度更高，情绪表达更丰富。此外，文化背景对评论模式有调节作用：集体主义文化消费者语言更温和，个人主义文化消费者反馈更直接。研究还发现性别影响不大。本研究将马斯洛需求层次理论和霍夫斯泰德文化框架应用于在线评论，并为企业优化营销策略提供了实践指导。

> **摘要翻译:** 本研究探讨了电子商务平台上产品和服务评论中的情感和情绪差异。与以往研究对所有评论一视同仁不同，本研究区分了产品评论（通常满足基本功能需求）和服务评论（通常迎合体验和情感需求）。研究结果揭示了两者在情感表达和情绪上的明显差异。产品评论通常侧重于实用性，如功能、可靠性和性价比，语气普遍更中性或务实。相比之下，服务评论涉及更强的情感投入，因为服务通常包含个人互动和主观体验。客户在评论服务时会表达更广泛的情绪，如喜悦、沮丧或失望，这些情绪是使用先进机器学习技术识别出来的。文化背景进一步影响这些模式。根据霍夫斯泰德文化维度定义的集体主义文化中的消费者，通常使用更温和、更考虑社会和谐的语言。相反，个人主义文化中的消费者倾向于提供更直接、情感更强烈的反馈。值得注意的是，性别对情绪变化的影响微乎其微，这进一步证实了产品性质（产品与服务）和文化背景是主导因素。理论上，本研究将马斯洛需求层次理论和霍夫斯泰德文化框架扩展到在线评论领域，提出了一个解释这些维度如何塑造消费者表达的模型。实践上，这些见解为企业优化其营销和客户参与策略提供了宝贵指导，使其能够根据产品类型和文化背景调整信息传递和服务设计以符合客户期望。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [409] [Barriers to Digital Mental Health Services among College Students](https://arxiv.org/abs/2507.21093)
> *大学生数字心理健康服务障碍*

*Ha Na Cho, Kyuha Jung, Daniel Eisenberg, Cheryl A. King, Kai Zheng* | **Category: cs.CY, cs.HC** | **Updated: 2025-06-30**

**Keywords:** 数字心理健康, 大学生, 障碍, 定性研究, 心理健康服务

**Comment:** 

> **TL;DR:** 该定性研究探讨了大学生使用数字心理健康干预（DMHI）的障碍，并确定了九个关键障碍，强调需要个性化和文化敏感的干预措施。

**AI_Comments:** 这项研究通过定性方法深入探讨了大学生数字心理健康服务的使用障碍，其创新之处在于从用户反馈中提炼出具体且多维度的障碍清单。研究结果对未来数字心理健康服务的设计和推广具有重要的实践指导意义，有助于提升服务的有效性和可及性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探索大学生使用数字心理健康干预（DMHI）的障碍。

**Method:** 本研究是一项定性研究，数据来源于一项大型随机临床试验（eBridge），该试验使用动机性访谈进行在线咨询。研究人员对学生参与者使用DMHI平台的反馈进行了主题分析。

**Result:** 研究确定了九个使用DMHI和面对面心理健康服务的关键障碍：情绪困扰、时间限制、隐私问题、资源可及性、经济挑战、药物污名、对沟通的不满、内容清晰度以及与治疗相关的担忧。

**Conclusion:** 研究结果强调需要个性化、文化敏感的干预措施，并改进策略以增强年轻人获得和参与心理健康支持的能力。

> **ai_Abstract:** 本定性研究旨在探究大学生在利用数字心理健康干预（DMHI）时所面临的障碍。研究数据来源于一项针对eBridge干预措施的随机临床试验，该干预通过动机性访谈提供在线咨询。通过对学生参与者反馈的主题分析，研究识别出九个主要的阻碍因素，包括情绪困扰、时间限制、隐私、资源可及性、财务、药物污名、沟通不满、内容清晰度及治疗相关担忧。研究强调了开发个性化、文化敏感的干预措施以及优化策略以提升年轻人心理健康支持可及性和参与度的重要性。

> **摘要翻译:** 这项定性研究探讨了大学生使用数字心理健康干预（DMHI）的障碍。数据来源于一项大型随机临床试验，该试验名为eBridge，使用动机性访谈进行在线咨询，旨在将有心理健康问题的学生与专业服务联系起来。我们应用主题分析法分析了学生参与者关于使用DMHI平台体验的反馈。我们确定了采用DMHI和使用面对面心理健康服务的九个关键障碍：情绪困扰、时间限制、隐私问题、资源可及性、经济挑战、药物污名、对沟通的不满、内容清晰度以及与治疗相关的担忧。我们的研究结果强调需要个性化、文化敏感的干预措施，并改进策略以增强年轻人获得和参与心理健康支持的能力。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [427] [Dependency on Meta AI Chatbot in Messenger Among STEM and Non-STEM Students in Higher Education](https://arxiv.org/abs/2507.21059)
> *高等教育中STEM和非STEM学生在Messenger中对Meta AI聊天机器人的依赖*

*Hilene E. Hernandez, Rhiziel P. Manalese, Roque Francis B. Dianelo, Jaymark A. Yambao, Almer B. Gamboa, Lloyd D. Feliciano, Mike Haizon M. David, Freneil R. Pampo, John Paul P. Miranda* | **Category: cs.CY** | **Updated: 2025-05-13**

**Keywords:** Meta AI, 聊天机器人, 学生依赖, 高等教育, STEM学生

**Comment:** 17 pages, 4 tables, 34 references

> **TL;DR:** 高等教育学生普遍不愿过度依赖Meta AI聊天机器人进行学术或社交支持，更倾向于传统资源，但重视其便利性和实用性。STEM学生表现出更强的整合意愿。

**AI_Comments:** 这项研究提供了对学生AI聊天机器人使用感知的重要横断面快照，强调了对便利性的认可但避免深度依赖的细致观点。STEM和非STEM学生使用模式的区分具有启发性。其局限性可能在于依赖性的自我报告性质以及单一区域的重点。

<details>
  <summary>Details</summary>

**Motivation:** 为了解高等教育学生在学术背景下对Meta AI的潜在依赖。

**Method:** 这项描述性横断面研究调查了来自菲律宾吕宋岛公立和私立机构的872名高等教育学生。收集了人口统计信息以及基于现有文献的Meta AI依赖感知。使用描述性统计总结数据，并使用Mann-Whitney U检验分析STEM和非STEM学生之间的差异。

**Result:** 学生普遍不同意在学术任务、心理支持和社交因素上过度依赖Meta AI聊天机器人。但在其技术优势和学术实用性上存在中度认同。学生重视Meta AI的便利性、可用性和解决问题的帮助，但更倾向于传统的资源和人际互动来获得学术和社会支持。对依赖风险和批判性思维影响的担忧得到承认，特别是在STEM学生中，他们更多地依赖聊天机器人进行学术目的。

**Conclusion:** Meta AI是一种有价值但补充性的资源，而非变革性的。使用模式受机构鼓励和个人偏好影响。学生普遍不愿过度依赖，偏爱传统资源和独立解决问题。对过度依赖及其对批判思维影响的担忧依然存在，尤其是在STEM学生中，他们似乎更倾向于将这些工具融入到他们的学习中。

> **ai_Abstract:** 本研究调查了菲律宾的872名高等教育学生，以评估他们在学术背景下对Meta AI聊天机器人的依赖程度，并比较了STEM和非STEM学生。研究结果显示，学生普遍避免对核心学术或社交支持过度依赖，更倾向于传统方法。然而，他们承认Meta AI的便利性、技术优势和解决问题的实用性。对依赖性和批判性思维影响的担忧依然存在，尤其是在STEM学生中，他们表现出更倾向于将这些工具用于学术目的，这表明Meta AI在教育中扮演的是补充性而非变革性的角色。

> **摘要翻译:** 为了解高等教育学生在学术背景下对Meta AI的潜在依赖。这项描述性横断面研究调查了来自菲律宾吕宋岛公立和私立机构的872名高等教育学生。收集了人口统计信息以及基于现有文献的Meta AI依赖感知。使用描述性统计总结数据，并使用Mann-Whitney U检验分析STEM和非STEM学生之间的差异。结果表明学生对Meta AI聊天机器人的使用持细致入微的看法。尽管普遍不同意在学术任务、心理支持和社交因素上过度依赖聊天机器人，但在其技术优势和学术实用性上存在中度认同。学生重视Meta AI的便利性、可用性和解决问题的帮助，但更倾向于传统的资源和人际互动来获得学术和社会支持。对依赖风险和批判性思维影响的担忧得到承认，特别是在STEM学生中，他们更多地依赖聊天机器人进行学术目的。这表明，虽然Meta AI是一种有价值的资源，但其在教育环境中的作用是补充性的而非变革性的，机构鼓励和个人偏好影响着使用模式。学生普遍不愿过度依赖Meta AI聊天机器人。这反映出他们偏爱传统资源和独立解决问题。尽管学生承认AI聊天机器人的学术益处和技术便利性，但对过度依赖及其对批判性思维影响的担忧依然存在，尤其是在STEM学生中，他们似乎更倾向于将这些工具融入到他们的学习中。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [438] [Bridging the Gap: Enhancing News Interpretation Across Diverse Audiences with Large Language Models](https://arxiv.org/abs/2507.21055)
> *弥合鸿沟：利用大型语言模型增强不同受众的新闻解读能力*

*Leyi Ouyang* | **Category: cs.CY, cs.AI, cs.SI** | **Updated: 2025-04-30**

**Keywords:** 大型语言模型, 新闻理解, 智能体框架, 受众差异, 信息传播

**Comment:** 9 pages, 3 figures, 5 tables

> **TL;DR:** 该研究提出一个基于LLM的智能体框架，通过模拟讨论来识别并解决不同受众在新闻理解上的差异，并通过补充材料显著提高理解力。

**AI_Comments:** 该论文提出了一种新颖的基于LLM智能体模拟的方法来识别和解决不同受众对新闻理解的差异。其创新点在于利用智能体模拟社会交流，使得理解鸿沟的识别更加精准。这种方法对于提升新闻传播的普适性和有效性具有重要意义，尤其是在信息过载的时代，确保信息准确传达给不同背景的受众变得尤为关键。

<details>
  <summary>Details</summary>

**Motivation:** 尽管记者努力提供准确信息，但由于专业知识和年龄差异，不同受众对新闻的理解存在显著差异，尤其是在其主要知识领域之外的内容。本研究旨在识别这些理解鸿沟并提供解决方案以提升受众对新闻内容的理解。

**Method:** 提出一个基于大型语言模型（LLMs）的智能体框架，模拟社会交流行为，其中多个智能体（可设计为不同职业专家或不同年龄组）可以讨论新闻。通过迭代讨论过程识别智能体的困惑或误解，并据此为智能体设计特定的新闻补充材料。

**Result:** 框架能够通过迭代讨论过程识别智能体对新闻的困惑甚至误解。智能体在接收补充材料后，新闻理解能力显著提高。

**Conclusion:** 该框架通过直接解决受众的理解鸿沟，在增强不同受众新闻理解方面具有实用性和效率。

> **ai_Abstract:** 本文提出一个基于大型语言模型（LLMs）的智能体框架，旨在解决不同受众在新闻理解上的差异。该框架通过模拟社会交流，让代表不同专业或年龄组的智能体讨论新闻，从而识别他们的理解障碍和误解。研究结果表明，该框架能有效识别问题，并据此生成定制化的补充材料，显著提升智能体对新闻内容的理解。这证明了该框架在弥合新闻理解鸿沟方面的有效性。

> **摘要翻译:** 在一个互联互通的世界里，新闻媒体在向包括科技、金融和农业在内的不同领域的公众传递信息方面至关重要。记者们努力呈现准确的信息，然而，由于受众特定的专业知识和年龄，新闻的解读在不同受众之间往往存在显著差异。在这项工作中，我们研究如何识别这些理解鸿沟，并提供解决方案以提高受众对新闻内容的理解，特别是针对其主要知识领域之外的文章方面。我们提出了一个基于大型语言模型（LLMs）的智能体框架，用于模拟社会交流行为，其中几个智能体可以讨论新闻。这些智能体可以被设计成来自不同职业的专家，或者来自不同年龄组。我们的结果表明，该框架可以通过迭代讨论过程识别智能体的困惑甚至误解。基于这些准确的识别，该框架可以为这些智能体设计特定的新闻补充材料。我们的结果显示，智能体在接收这些材料后，新闻理解能力显著提高。这些发现突出了我们的框架在通过直接解决理解鸿沟方面，在增强不同受众新闻理解方面的实用性和效率。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [480] [Automated but Atrophied? Student Over-Reliance vs Expert Augmentation of AI in Learning and Cybersecurity](https://arxiv.org/abs/2507.21062)
> *自动化但萎缩？学生过度依赖与专家增强AI在学习和网络安全中的应用*

*Koffka Khan* | **Category: cs.CY, 68T07 (Primary), 68T05, 68U99 (Secondary), I.2.6; I.2.7; K.3.2; K.4.1; F.2.2** | **Updated: 2025-05-22**

**Keywords:** AI素养, 过度依赖, 专家增强, 学习, 网络安全

**Comment:** 

> **TL;DR:** 本文提出一项研究，对比学生过度依赖AI与专业人士增强性使用AI在学习和网络安全中的不同影响，并假设盲目依赖AI会削弱技能，而引导性使用AI能提升效率。

**AI_Comments:** 该论文提案具有重要的现实意义，直面了AI普及带来的教育和专业能力培养挑战。其创新之处在于通过对比学生和专业人士的真实案例，深入探讨了AI使用模式对成果的影响，并强调了AI素养和批判性思维的重要性。研究设计涵盖了多维度的定性和定量数据收集，有望为高等教育和职业发展中的AI整合提供实证支持和具体建议。

<details>
  <summary>Details</summary>

**Motivation:** 随着生成式AI在教育和实践中日益普及，学生和专业人士对其使用方式和结果存在显著差异。本文旨在通过对比学生过度依赖AI与专家增强AI的案例，探究AI作为学习替代品或专家工具对成果的影响，以期为负责任的AI整合提供信息。

**Method:** 本文提出一项比较研究设计，基于两个真实案例：一个大学生试图完全外包学习给AI，另一个是网络安全专业人员在演习中协作使用AI工具增强专业知识。研究方法包括课堂和工作场所数据收集，具体为学生和专业人士的调查、访谈和绩效分析。研究将借鉴教育技术和工作场所AI的现有文献。

**Result:** 研究假设：盲目依赖AI会侵蚀基本技能和学术诚信；而知识渊博的用户在引导下使用AI可以提高生产力而不牺牲质量。预期研究结果旨在为课程中负责任的AI整合提供信息，平衡创新与领域知识的必要性。

**Conclusion:** 本文提出针对教学策略、促进AI素养的机构政策的建议，并呼吁进行长期研究，以追踪大学期间的AI使用如何随时间影响专业能力。研究旨在平衡创新与领域知识的必要性，指导负责任的AI整合。

> **ai_Abstract:** 本文提出一项比较研究，旨在探讨学生过度依赖AI与专业人士增强性使用AI在学习和网络安全领域中对结果的不同影响。通过分析学生外包学习和网络安全专家协作使用AI的真实案例，研究旨在验证盲目依赖AI可能削弱基本技能，而引导性使用AI能提升效率的假设。研究将采用调查、访谈和绩效分析等方法收集数据，并期望为负责任的AI整合、课程设计和AI素养的培养提供指导。

> **摘要翻译:** 大学生和在职专业人士在教育和实践中越来越多地接触到生成式人工智能（AI），但他们的方法和结果却显著不同。本文提出一项学术研究，对比新手过度依赖AI与专家增强AI，并以两个真实世界的案例为基础。其中一个案例中，一名大学生试图将学习完全外包给AI，从而避免课程参与。在另一个案例中，经验丰富的网络安全专业人员在“信风2025”红蓝队演习中协作使用AI工具来增强（而非取代）他们的领域专业知识。本提案概述了一项比较研究设计，以调查学生将AI视为学习替代品与专业人士将AI用作专家工具的看法如何影响结果。借鉴教育技术和工作场所AI的当前文献，我们探讨了其对高等教育中课程设计、AI素养和评估改革的影响。我们假设，盲目依赖AI会侵蚀基本技能和学术诚信，而知识渊博的用户在引导下使用AI可以提高生产力而不牺牲质量。本文详细介绍了课堂和工作场所数据收集的方法，包括学生和专业人士的调查、访谈和绩效分析。预期研究结果旨在为课程中负责任的AI整合提供信息，平衡创新与领域知识的必要性。我们最后提出了教学策略、促进AI素养的机构政策的建议，并呼吁进行长期研究，以追踪大学期间的AI使用如何随时间影响专业能力。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [536] [Cybroc: Cyborgizing Broccoli for Longevity](https://arxiv.org/abs/2507.21064)
> *Cybroc：西兰花赛博格化以求长寿*

*Ke Huang, Yue Zhou, Xi He, Weibo Chen, Botao Amber Hu* | **Category: cs.CY** | **Updated: 2025-05-24**

**Keywords:** 赛博格化, 长寿主义, 艺术装置, 生物增强, 超人类主义

**Comment:** Accepted by ISEA 2025

> **TL;DR:** 一个通过赛博格化西兰花进行讽刺性艺术装置，探讨长寿主义、生物增强的局限性及超人类主义伦理。

**AI_Comments:** 这篇论文通过独特的艺术装置形式，将日常蔬菜与前沿的超人类主义概念结合，以讽刺的手法巧妙地探讨了生物增强的伦理和社会影响，其创新性在于通过具象化的“西兰花赛博格”挑战了观众对长寿和技术极限的固有观念，引发了深刻的哲学思考。

<details>
  <summary>Details</summary>

**Motivation:** 探索日益流行的民粹主义长寿运动，并引发对生物增强伦理的思考。

**Method:** 一系列动力艺术装置，通过为象征健康食品的西兰花安装假肢，使其进行模拟人类长寿锻炼（如冷水浴、跑步机、臂力摆动、推雪橇等），以讽刺性地将其赛博格化。

**Result:** 尽管有机械增强，西兰花在进行高强度表演后仍不可避免地腐烂。

**Conclusion:** 促使人们反思生物增强的局限性、超越自然能力的人类增强伦理，特别是超人类主义理想，并挑战观众思考自然、技术与人类追求长寿的交汇点。

> **ai_Abstract:** Cybroc是一个通过赛博格化西兰花来讽刺性探索长寿主义的动力艺术装置系列。该作品为西兰花安装假肢，模拟人类健身活动，旨在揭示生物增强的局限性。尽管有机械增强，西兰花的腐烂引发了对超人类主义伦理的深思，并促使观众反思自然、技术与人类寿命追求的复杂关系。

> **摘要翻译:** Cybroc是一系列动力艺术装置，通过对西兰花的讽刺性赛博格化，探讨了近期日益流行的民粹主义长寿运动。该艺术作品为健康食品的象征——西兰花——安装了假肢，使其进行所谓的增强寿命的锻炼，例如冷水浴、跑步机跑步、臂力摆动（手臂摆动）、推雪橇等——所有这些都是对原始人类生存任务的模拟，并被重新定义为现代健身程序。尽管有机械增强，西兰花在展示高强度表演后不可避免地腐烂，这促使人们反思生物增强的局限性以及超越自然能力的人类增强伦理，特别是超人类主义理想。通过将象征健康的蔬菜与人类增强的前沿概念并置，Cybroc挑战观众思考在我们的超人类时代中，自然、技术与人类追求延长寿命的交汇点。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [599] [Digital Sovereigns Big Tech and Nation-State Influence](https://arxiv.org/abs/2507.21066)
> *数字主权者：大型科技公司与民族国家影响力*

*Michael Bollerman* | **Category: cs.CY** | **Updated: 2025-06-01**

**Keywords:** 科技巨头, 数字主权, 民族国家影响力, 监管, 全球治理

**Comment:** 

> **TL;DR:** 科技巨头权力日益增长，行为类似主权国家，对民主和全球治理构成挑战，本研究旨在提出监管政策以制衡其影响力。

**AI_Comments:** 这篇论文探讨了一个非常及时且重要的主题，即大型科技公司日益增长的“准主权”权力。其创新之处在于将科技公司与民族国家进行类比，突出了其在经济、政治和社会领域日益扩大的影响力。论文强调了这种权力对民主治理、经济不平等和数据隐私的潜在威胁，并旨在提出具体的政策建议，这对于当前全球数字治理的讨论具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 科技公司已获得前所未有的权力与影响力，行为日益类似于准民族国家，对全球治理、民主、经济平等及数据隐私构成挑战。

**Method:** 本论文旨在审视科技公司如何超越传统商业模式，采纳主权国家的特征，并将考察科技公司作为准政府实体的关键案例，评估企业影响力失控带来的风险。

**Result:** Not mentioned in abstract

**Conclusion:** 本论文旨在提出政策框架和监管干预措施，以遏制科技巨头的过度扩张，恢复民主机构与企业权力之间的平衡，确保数字未来符合公共利益。

> **ai_Abstract:** 本论文探讨了科技巨头日益增长的权力，这些公司正超越传统商业模式，表现出类似主权国家的特征，例如制定法规、塑造公共话语和影响法律框架。这种现象对民主治理、经济平等和数据隐私构成挑战。研究旨在通过分析关键案例来评估其失控影响的风险，并最终提出政策框架和监管干预措施，以平衡企业权力与民主机构，确保数字未来符合公共利益。

> **摘要翻译:** 近年来，科技公司获得了前所未有的权力和影响力，在全球范围内类似于准民族国家。市值万亿美元的公司不再仅仅是数字服务的提供者；它们现在拥有巨大的经济力量，影响全球基础设施，并显著影响政治和社会动态。本论文旨在研究这些公司如何超越传统商业模式，采纳通常与主权国家相关的特征。它们现在在各国执行法规、塑造公共话语并影响法律框架。这种转变带来了独特的挑战，包括削弱民主治理、加剧经济不平等以及助长不受监管的数据利用和隐私侵犯。本研究将审视科技公司充当准政府实体的关键案例，并评估企业影响力失控在全球治理中带来的风险。最终，本论文旨在提出政策框架和监管干预措施，以遏制科技巨头的过度扩张，恢复民主机构与企业权力之间的平衡，并确保数字未来符合公共利益，而不是制造出“弗兰肯斯坦”式的怪物。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [621] [Information Fusion in Multimodal IoT Systems for physical activity level monitoring](https://arxiv.org/abs/2403.14707)
> *信息融合在多模态物联网系统中用于身体活动水平监测*

*Mohsen Shirali, Zahra Ahmadi, Jose-Luis Bayo-Monton, Zoe Valero-Ramon, Carlos Fernandez-Llatas* | **Category: cs.CY, 68U35, H.4.0; J.3; I.2.1** | **Updated: 2025-07-28**

**Keywords:** 信息融合, 物联网, 聚类, 身体活动监测, 健康监测

**Comment:** 

> **TL;DR:** 本研究利用物联网系统中的信息融合和聚类方法来监测身体活动水平，以早期发现行为变化并深入理解行为习惯，从而实现持续健康监测。

**AI_Comments:** 该研究的创新点在于将信息融合与聚类方法结合应用于物联网系统，以实现身体活动水平的有效监测和行为模式的深入理解，这对于早期健康风险预警和个性化健康管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是利用物联网系统中的信息融合技术，通过识别行为相似性和关键特征，从而促进早期行为变化检测，并深入理解行为习惯，以实现持续健康监测。

**Method:** 本研究利用物联网系统中的信息融合技术，并采用聚类方法来识别行为相似性及各聚类内的关键特征。

**Result:** 该方法促进了行为变化的早期检测，并为持续健康监测提供了对行为习惯更深入的理解。

**Conclusion:** 该研究通过信息融合和聚类方法，成功促进了行为变化的早期检测，并为持续健康监测提供了对行为习惯更深入的理解。

> **ai_Abstract:** 本研究探讨了在物联网系统中利用信息融合和聚类方法进行身体活动水平监测。通过识别行为相似性和特征，该方法旨在促进早期行为变化检测，并提供对日常行为更深入的理解，以支持持续健康监测。

> **摘要翻译:** 本研究利用物联网系统中的信息融合技术，并采用聚类方法来识别行为相似性及各聚类内的关键特征。这种方法有助于早期发现行为变化，并为持续健康监测提供对行为习惯更深入的理解。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [668] [Making a Case for Research Collaboration Between Artificial Intelligence and Operations Research Experts](https://arxiv.org/abs/2507.21076)
> *为人工智能与运筹学专家之间的研究协作提供案例*

*Radhika Kulkarni, Gianluca Brero, Yu Ding, Swati Gupta, Sven Koenig, Ramayya Krishnan, Thiago Serra, Phebe Vayanos, Segev Wasserkrug, Holly Wiberg* | **Category: cs.CY** | **Updated: 2025-06-12**

**Keywords:** 人工智能, 运筹学, 协作, 决策制定, 研讨会

**Comment:** 

> **TL;DR:** 该报告概述了旨在促进人工智能和运筹学之间研究协作的研讨会成果，并提出了五项关键建议，以期改善决策并最大化社会影响。

**AI_Comments:** 这篇论文的创新之处在于，它不仅指出了人工智能和运筹学结合的必要性，更重要的是，通过实际的研讨会形式，汇集了行业和学术界的意见，并提出了具体、可执行的五项建议。这对于推动跨学科研究具有重要的指导意义，特别是为两大核心计算领域未来的发展提供了清晰的路线图。其重要性在于，它从组织和结构层面为AI/OR的深度融合提供了策略，而不仅仅停留在技术层面的探讨。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探索人工智能（AI）和运筹学（OR）之间的协同作用，以改进决策制定，并创建一个统一的AI/OR协作研究愿景，重点是克服文化差异和最大化社会影响。

**Method:** INFORMS、ACM SIGAI和计算社区联盟（CCC）在2021年举办了三次研讨会，探讨AI/OR协同。研讨会讨论了技术创新、应用、可信赖AI开发、AI/OR整合的具体领域，以及“挑战问题”和结合AI和OR技术策略。

**Result:** 报告提出了五项增强AI/OR协作的关键建议：1) 资金机会，2) 联合教育，3) 长期研究项目，4) 协调会议/期刊，以及5) 基准创建。

**Conclusion:** 该报告总结了通过研讨会探讨AI与OR协作的成果，并提出了具体的、可操作的建议，以促进这两个领域之间的深度融合与合作，从而更好地改进决策并产生更大的社会效益。

> **ai_Abstract:** 本报告介绍了2021年由INFORMS、ACM SIGAI和CCC联合举办的三次研讨会的成果，旨在促进人工智能（AI）与运筹学（OR）之间的研究协作。研讨会探讨了AI/OR协同在改进决策、克服文化差异和最大化社会影响方面的潜力。报告总结了会议讨论，并提出了五项关键建议，包括资金机会、联合教育、长期研究项目、会议/期刊协调以及基准创建，以期加强这两个领域间的融合与合作。

> **摘要翻译:** 2021年，INFORMS、ACM SIGAI和计算社区联盟（CCC）举办了三次研讨会，旨在探索人工智能（AI）和运筹学（OR）之间的协同作用，以改进决策制定。这些研讨会旨在为AI/OR协作创建一个统一的研究愿景，重点是克服文化差异并最大化社会影响。前两次研讨会讨论了技术创新、应用和可信赖AI的开发，而最后一次研讨会则强调了AI/OR整合的具体领域。参与者讨论了“挑战问题”以及结合AI和OR技术的策略。本报告概述了增强AI/OR协作的五项关键建议：1）资金机会，2）联合教育，3）长期研究项目，4）协调会议/期刊，以及5）基准创建。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [676] [A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models](https://arxiv.org/abs/2506.22493)
> *政治指南针测试的详细因素分析：探索大型语言模型的意识形态*

*Sadia Kamal, Lalu Prasad Yadav Prakash, S M Rafiuddin, Mohammed Rakib, Arunkumar Bagavathi, Atriya Sen, Sagnik Ray Choudhury* | **Category: cs.CY, cs.CL, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 政治指南针测试, 政治倾向, 微调, 提示词变体

**Comment:** 

> **TL;DR:** 本研究发现，标准生成参数对LLM的政治指南针测试（PCT）分数影响不显著，但提示词变体和微调会产生影响。此外，用政治内容更高的文本数据集进行微调并不会差异性地影响PCT分数。这促使人们对PCT的有效性以及LLM中政治倾向的编码机制进行深入调查。

**AI_Comments:** 本文对量化LLM政治倾向的常用方法——政治指南针测试（PCT）的有效性提出了质疑，并深入探讨了影响LLM政治倾向的多种因素。其创新之处在于揭示了标准生成参数的无关紧要性，以及提示词和微调的重要性。研究结果对理解LLM的意识形态编码机制具有重要意义，并呼吁对现有评估工具进行更严格的验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究使用政治指南针测试（PCT）或类似问卷来量化大型语言模型（LLM）的政治倾向。本文旨在深入探讨PCT测试的有效性，并调查影响LLM政治倾向的各种因素及其编码机制。

**Method:** 研究通过实验证明了标准生成参数对LLM的PCT分数没有显著影响。同时，研究独立和组合地考察了外部因素（如提示词变体和微调）对PCT分数的影响。此外，研究还测试了用政治内容更高的文本数据集进行微调是否会差异性地影响PCT分数。

**Result:** 标准生成参数对模型的PCT分数没有显著影响。然而，提示词变体和微调（单独或组合）会影响PCT分数。当模型在政治内容更高的文本数据集上进行微调时，PCT分数并未受到差异性影响。

**Conclusion:** 本研究的结果表明，需要对政治指南针测试（PCT）及类似测试的有效性，以及政治倾向在大型语言模型（LLM）中编码的机制进行彻底调查。

> **ai_Abstract:** 本论文对大型语言模型（LLM）的政治指南针测试（PCT）进行了详细的因素分析。研究发现，标准生成参数对LLM的PCT分数影响不大，但外部因素如提示词变体和微调则会显著影响分数。此外，即使在政治内容更高的文本数据集上进行微调，LLM的PCT分数也未受到差异性影响。这些发现强调了对PCT有效性及其在LLM中政治倾向编码机制进行深入调查的必要性。

> **摘要翻译:** 政治指南针测试（PCT）或类似的问卷已被用于量化大型语言模型的政治倾向。基于最近一系列检验PCT测试有效性的工作，我们证明了标准生成参数的变化不会显著影响模型的PCT分数。然而，外部因素，如提示词变体和微调，单独或组合都会影响分数。最后，我们证明了当模型在政治内容高于其他数据集的文本数据集上进行微调时，PCT分数并未受到差异性影响。这要求对PCT和类似测试的有效性以及政治倾向在大型语言模型中编码的机制进行彻底调查。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [724] [Safety Features for a Centralised AGI Project](https://arxiv.org/abs/2507.21082)
> *集中式AGI项目的安全特性*

*Sarah Hastings-Woodhouse* | **Category: cs.CY** | **Updated: 2025-06-17**

**Keywords:** AGI, 安全特性, 集中式开发, 国家安全, 风险降低

**Comment:** 

> **TL;DR:** 鉴于AI发展迅速且可能很快出现AGI，带来潜在的安全威胁，本报告分析了美国政府集中控制AGI开发的设想，并提出了降低风险的安全特性。

**AI_Comments:** 该论文的创新之处在于其提出了一个关于由政府集中控制AGI开发的设想，这与当前AI主要由私营部门主导的现状形成鲜明对比。它从国家和全球安全的角度出发，探讨了对潜在高风险技术进行严格监管和安全特性设计的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 近期人工智能的进展超出了预期，一些专家预测本十年内可能会出现与人类在所有认知领域能力匹配或超越人类能力的人工智能（AGI），这可能对国家和全球安全构成严重威胁。目前人工智能的开发主要在私营部门进行，监管极少。

**Method:** 本报告分析了美国政府将其AGI开发集中在其直接控制下的情景，并识别了四个高级别优先事项和七个安全特性以降低风险。

**Result:** 在政府集中控制AGI开发的设想下，报告识别了四个高级别优先事项和七个安全特性，旨在降低潜在风险。

**Conclusion:** 在政府集中控制AGI开发的设想下，识别并实施安全特性对于降低AGI可能带来的国家和全球安全风险至关重要。

> **ai_Abstract:** 鉴于AI的快速发展及其可能带来的AGI相关国家和全球安全威胁，本报告分析了美国政府集中控制AGI开发的设想，并提出了旨在降低风险的四个高级别优先事项和七个安全特性。

> **摘要翻译:** 近期人工智能的进展超出了预期，一些专家现在预测，本十年内可能会出现与人类在所有认知领域能力匹配或超越人类能力的人工智能（AGI），这可能对国家和全球安全构成严重威胁。目前人工智能的开发主要在私营部门进行，监管极少。本报告分析了美国政府将其AGI开发集中在其直接控制下的情景，并识别了四个高级别优先事项和七个安全特性以降低风险。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [732] [The Carbon Cost of Conversation, Sustainability in the Age of Language Models](https://arxiv.org/abs/2507.20018)
> *对话的碳成本：语言模型时代的持续性*

*Sayed Mahbub Hasan Amiri, Prasun Goswami, Md. Mainul Islam, Mohammad Shakhawat Hossen, Sayed Majhab Hasan Amiri, Naznin Akter* | **Category: cs.CY, cs.AI, cs.CL** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 碳足迹, 环境可持续性, 自然语言处理, 电子垃圾

**Comment:** 22 Pages, 5 Tables

> **TL;DR:** 本文探讨了大型语言模型（LLMs）对环境造成的被忽视的碳足迹、水资源消耗和电子垃圾问题，并提出了可持续发展路径，强调立即采取行动以避免AI的生态代价超过其社会效益。

**AI_Comments:** 这篇论文非常重要，它揭示了大型语言模型光鲜外表下被忽视的环境成本，提出了一个紧迫且具有全球影响的问题。其创新之处在于不仅量化了问题，还提出了多维度的解决方案，从技术到政策再到文化层面，为可持续AI发展提供了清晰的路线图。它强调了企业责任和全球合作的必要性，对于推动AI行业向更环保、更公平的方向发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）彻底改变了自然语言处理（NLP），但其环境成本却被危险地忽视了。本文旨在批判LLMs的可持续性，并量化其碳足迹、水资源消耗和电子垃圾贡献。

**Method:** 通过对GPT-4等模型和Mistral 7B等节能替代方案的案例研究，量化了大型语言模型（LLMs）的碳足迹、水资源消耗和对电子垃圾的贡献。分析了行业领导者和落后者，并探讨了技术创新、政策改革和文化转变等可持续发展途径。

**Result:** 训练单个LLM可能排放相当于数百辆汽车每年行驶的二氧化碳，数据中心冷却加剧了脆弱地区的水资源短缺。系统性挑战（如企业漂绿、冗余模型开发和监管空白）加剧了危害，并 disproportionately 地加重了全球南方边缘化社区的负担。

**Conclusion:** 文章呼吁将技术进步与地球界限对齐，倡导公平、透明和再生的AI系统，优先考虑人类和环境福祉。如果现在不立即采取行动，AI的生态代价可能超过其社会效益。

> **ai_Abstract:** 本文深入探讨了大型语言模型（LLMs）日益增长的环境成本，包括其巨大的碳足迹、水资源消耗和电子垃圾产生。通过案例研究和对行业实践的批判性分析，揭示了LLMs对环境和社会造成的负面影响，特别是对全球南方边缘化社区的 disproportionate 负担。文章提出了一系列可持续发展路径，涵盖技术创新、政策改革和文化转变，并强调了立即采取行动、加强道德问责和全球合作的重要性，以确保AI发展与地球生态平衡和人类福祉相协调。

> **摘要翻译:** 大型语言模型（LLMs），如GPT-3和BERT，已经彻底改变了自然语言处理（NLP），但它们的环境成本却被危险地忽视了。本文批判了LLMs的可持续性，通过对GPT-4等模型和Mistral 7B等节能替代方案的案例研究，量化了它们的碳足迹、水资源消耗以及对电子垃圾的贡献。训练单个LLM所产生的二氧化碳排放量可能相当于数百辆汽车每年的行驶排放量，而数据中心冷却则加剧了脆弱地区的水资源短缺。企业漂绿、冗余模型开发和监管空白等系统性挑战使危害持续存在，并 disproportionately 地加重了全球南方边缘化社区的负担。然而，可持续的NLP发展路径是存在的：技术创新（例如，模型剪枝、量子计算）、政策改革（碳税、强制性排放报告）以及优先考虑必要性而非新颖性的文化转变。通过分析行业领导者（谷歌、微软）和落后者（亚马逊），这项工作强调了道德问责和全球合作的紧迫性。如果不立即采取行动，AI的生态代价可能超过其社会效益。文章最后呼吁将技术进步与地球界限对齐，倡导公平、透明和再生的AI系统，优先考虑人类和环境福祉。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [781] [The Value of Gen-AI Conversations: A bottom-up Framework for AI Value Alignment](https://arxiv.org/abs/2507.21091)
> *生成式人工智能对话的价值：一种人工智能价值对齐的自下而上框架*

*Lenart Motnikar, Katharina Baum, Alexander Kagan, Sarah Spiekermann-Hoff* | **Category: cs.CY, cs.AI** | **Updated: 2025-06-26**

**Keywords:** 生成式人工智能, 价值对齐, 对话代理, 伦理AI, 自下而上方法

**Comment:** Thirty-Third European Conference on Information Systems (ECIS 2025),
  Amman, Jordan

> **TL;DR:** 生成式人工智能对话在价值对齐方面面临挑战。本文提出了一种自下而上的方法，利用真实世界对话日志来识别核心价值观和错位，发现了9个核心价值观和32个错位，为更好地实现道德AI提供了见解。

**AI_Comments:** 本文通过从传统的自上而下方法转向数据驱动的自下而上框架，为AI价值对齐提供了一种创新方法。其优势在于利用真实世界的对话数据来识别具体的价值错位，提供了具体的、可操作的见解，而非抽象原则。这种实证方法对于开发符合伦理且以用户为中心的对话式AI至关重要，尤其是在敏感领域。

<details>
  <summary>Details</summary>

**Motivation:** 当前的对话代理价值对齐工作主要依赖于自上而下的方法，这些方法往往与CA运行的具体环境脱节，可能导致与用户利益不一致，因此需要一种新的方法来解决此挑战。

**Method:** 本文提出了一种新颖的、自下而上的价值对齐方法，利用ISO基于价值的工程标准中的价值本体论。研究分析了来自一个主要欧洲就业服务CA的16,908个对话日志中识别出的593个伦理敏感系统输出。

**Result:** 分析结果揭示了九个核心价值观和32种不同的对用户产生负面影响的价值错位。

**Conclusion:** 研究结果为寻求解决伦理挑战并实现更具情境敏感性价值对齐的CA提供商提供了可操作的见解。

> **ai_Abstract:** 本文旨在解决生成式人工智能对话代理与人类价值观对齐的挑战，指出了当前自上而下方法的局限性。它引入了一种新颖的自下而上框架，利用ISO基于价值的工程标准。通过分析来自一个就业服务CA的大量真实世界对话日志，研究识别出九个核心价值观和32个对用户产生负面影响的价值错位实例，为开发更具伦理对齐和情境敏感性的AI提供了实用见解。

> **摘要翻译:** 基于生成式人工智能的对话代理（CA）经常面临确保符合人类价值观的道德互动的挑战。当前的价值对齐工作主要依赖于自上而下的方法，例如技术指南或法律价值原则。然而，这些方法往往与CA运行的具体环境脱节，可能导致与用户利益不一致。为了解决这一挑战，我们提出了一种新颖的、自下而上的价值对齐方法，利用ISO基于价值的工程标准中的价值本体论进行伦理IT设计。我们分析了来自一个主要欧洲就业服务CA的16,908个对话日志中识别出的593个伦理敏感系统输出，以识别真实世界互动中的核心价值观和价值错位实例。结果揭示了九个核心价值观和32种不同的对用户产生负面影响的价值错位。我们的研究结果为寻求解决伦理挑战并实现更具情境敏感性价值对齐的CA提供商提供了可操作的见解。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [789] [The Xeno Sutra: Can Meaning and Value be Ascribed to an AI-Generated "Sacred" Text?](https://arxiv.org/abs/2507.20525)
> *异经：人工智能生成的“神圣”文本能否被赋予意义和价值？*

*Murray Shanahan, Tara Das, Robert Thurman* | **Category: cs.CY, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 人工智能生成文本, 佛教经文, 意义建构, 大型语言模型, 人工智能哲学

**Comment:** 

> **TL;DR:** 本文通过分析一个由大型语言模型生成的人工智能佛教“经文”，探讨了人工智能能否创造有意义的“神圣”文本，以及社会应如何应对人工智能对人类意义建构的侵犯，并认为佛教哲学具有良好的适应性。

**AI_Comments:** 本文的创新之处在于以人工智能生成的“神圣”文本作为案例研究，探讨了关于人工智能、意义建构和人类精神性的深刻哲学问题。其重要性在于促使人们批判性地反思人工智能能力的边界以及人类如何应对先进人工智能。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是探讨人工智能技术对人类意义建构的潜在侵犯，以及社会应如何应对这种可能性。同时，也旨在探究人工智能生成的“神圣”文本是否能被赋予意义和价值。

**Method:** 本文通过一个案例研究，使用大型语言模型生成了一部虚构的佛教“经文”，并从哲学和文学角度对生成的文本进行了详细分析。

**Result:** 研究发现，人工智能生成的文本在概念上具有微妙性，意象丰富，典故密集，这使得人们很难仅仅因为其机械起源而随意否定它。

**Conclusion:** 本文认为，佛教哲学本质上非常适合适应人工智能对人类意义建构所带来的挑战。

> **ai_Abstract:** 本文通过一个案例研究，探讨了由大型语言模型生成的人工智能佛教“经文”。它从哲学和文学角度对文本进行了分析，指出其概念上的微妙性和丰富的意象，这使得仅仅因为其机械起源而否定其价值变得困难。该研究提出了关于社会应如何应对人工智能侵犯人类意义建构的问题，并认为佛教哲学能够很好地适应这种挑战。

> **摘要翻译:** 本文介绍了一个使用大型语言模型生成虚构佛教“经文”的案例研究，并从哲学和文学角度对生成的文本进行了详细分析。文本中发现的概念上的微妙、丰富的意象和典故的密集性，使得人们很难仅仅因为其机械起源而随意否定它。这引发了关于我们社会应如何应对一项可能侵犯人类意义建构的潜在令人不安的技术的问题。我们认为，佛教哲学本质上非常适合适应这种情况。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [837] [A Tactical Behaviour Recognition Framework Based on Causal Multimodal Reasoning: A Study on Covert Audio-Video Analysis Combining GAN Structure Enhancement and Phonetic Accent Modelling](https://arxiv.org/abs/2507.21100)
> *基于因果多模态推理的战术行为识别框架：一项结合GAN结构增强和语音口音建模的隐蔽音视频分析研究*

*Wei Meng* | **Category: cs.CY, cs.AI, cs.CV, 05C82, 68T07, 68T05, 62H30, I.2.10; I.4.8; H.5.1; H.2.8** | **Updated: 2025-07-04**

**Keywords:** 战术行为识别, 多模态推理, 图神经网络, 威胁检测, 隐蔽分析

**Comment:** This paper introduces a structurally innovative and mathematically
  rigorous framework for multimodal tactical reasoning, offering a significant
  advance in causal inference and graph-based threat recognition under noisy
  conditions

> **TL;DR:** 本文提出TACTIC-GRAPHS，一个结合谱图理论和多模态图神经网络推理的框架，用于高噪声和弱结构战术视频中的语义理解和威胁检测，并取得了高准确率。

**AI_Comments:** 该研究通过结合谱图理论和多模态图神经网络，为在高噪声和弱结构环境下进行复杂的战术行为识别提供了一种新颖且有效的方法。其创新点在于将多种模态（视觉、听觉、动作）的信息融入到图结构中，并通过因果推理进行分析，显著提升了在挑战性条件下的威胁检测能力和系统可解释性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在高噪声和弱结构环境下，对战术视频进行语义理解和威胁检测。

**Method:** 引入TACTIC-GRAPHS系统，结合谱图理论和多模态图神经网络推理。该框架包含谱嵌入、时间因果边缘建模和跨异构模态的判别路径推理。通过语义感知关键帧提取方法融合视觉、听觉和动作线索构建时间图，并利用图注意力机制和拉普拉斯谱映射进行跨模态加权和因果信号分析。

**Result:** 在TACTIC-AVS和TACTIC-Voice数据集上，时间对齐准确率达到89.3%，完整威胁链识别率超过85%，节点延迟在±150毫秒以内。

**Conclusion:** 该方法增强了结构可解释性，并支持在监控、国防和智能安全系统中的应用。

> **ai_Abstract:** 本文提出TACTIC-GRAPHS框架，融合谱图理论与多模态图神经网络推理，旨在解决高噪声和弱结构战术视频中的语义理解与威胁检测问题。该系统通过谱嵌入、时间因果边缘建模和多模态判别路径推理，并结合语义感知关键帧提取技术，构建并分析时间图。实验证明，该方法在时间对齐和威胁链识别方面表现出色，并提升了结构可解释性，适用于监控、国防和智能安全领域。

> **摘要翻译:** 这篇论文介绍了 TACTIC-GRAPHS，一个结合谱图理论和多模态图神经推理的系统，用于在高噪声和弱结构下的战术视频中进行语义理解和威胁检测。该框架结合了谱嵌入、时间因果边缘建模和跨异构模态的判别路径推理。一种语义感知的关键帧提取方法融合了视觉、听觉和动作线索来构建时间图。模型利用图注意力机制和拉普拉斯谱映射进行跨模态加权和因果信号分析。在 TACTIC-AVS 和 TACTIC-Voice 数据集上的实验表明，时间对齐准确率达到 89.3%，完整威胁链识别率超过 85%，节点延迟在正负 150 毫秒以内。该方法增强了结构可解释性，并支持在监控、国防和智能安全系统中的应用。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [893] [Assessing the Ecological Impact of AI](https://arxiv.org/abs/2507.21102)
> *评估人工智能的生态影响*

*Sylvia Wenmackers* | **Category: cs.CY, cs.AI** | **Updated: 2025-07-07**

**Keywords:** 人工智能, 生态影响, 可持续性, 生成式AI, 哲学

**Comment:** This was presented as a lightning talk at: LOCO 2024, December 3,
  2024, Glasgow/Online

> **TL;DR:** 本文提出了一种结合哲学思想，对生成式AI的可持续性进行实际可行分析的方法，以应对目前AI生态影响评估的不足。

**AI_Comments:** 这篇论文的创新之处在于它呼吁将哲学思想融入到对AI生态影响的实际评估中，这对于弥补现有评估的不足和推动AI的可持续发展具有重要意义。它强调了从更广阔的视角审视AI环境足迹的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 技术哲学家已开始关注AI，特别是大型语言模型和生成式AI的环境影响，但AI开发者很少提供具体的生态影响评估，即使有也常限于特定阶段的温室气体排放。因此，需要更全面和实际可行的分析。

**Method:** 本文提出并鼓励对生成式AI的可持续性方面进行实际可行的分析，并结合哲学思想进行指导。

**Result:** Not mentioned in abstract

**Conclusion:** 本文旨在鼓励进行结合哲学思想的、实际可行的生成式AI可持续性分析。

> **ai_Abstract:** 本文指出，尽管技术哲学家日益关注人工智能（特别是大型语言模型和生成式AI）的环境影响，但AI开发者在提供具体的生态影响评估方面存在不足，且现有评估多限于温室气体排放。因此，本文提出并鼓励进行结合哲学思想的、实际可行的生成式AI可持续性分析。

> **摘要翻译:** 技术哲学家最近开始更多地关注人工智能，特别是大型语言模型（LLMs）和生成式人工智能（genAI）应用对环境的影响。与此同时，很少有AI开发者对其模型和产品的生态影响给出具体的估计，即使有，他们的分析也往往仅限于AI开发或使用某些阶段的温室气体排放。当前的提案鼓励结合哲学思想，对生成式AI的可持续性方面进行实际可行的分析。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [613] [Improving Neural Network Training using Dynamic Learning Rate Schedule for PINNs and Image Classification](https://arxiv.org/abs/2507.21749)
> *使用动态学习率调度改进PINN和图像分类的神经网络训练*

*D. Veerababu, Ashwin A. Raikar, Prasanta K. Ghosh* | **Category: cs.CE, cs.LG, 34A06, G.1.6; I.6.4; J.2** | **Updated: 2025-07-29**

**Keywords:** 动态学习率, 神经网络训练, PINNs, 图像分类, 超参数优化

**Comment:** 10 pages

> **TL;DR:** 本文提出了一种动态学习率调度器（DLRS）算法，该算法根据训练过程中的损失值自适应调整学习率，从而加速神经网络训练并提高稳定性，尤其适用于物理信息神经网络（PINNs）和图像分类任务。

**AI_Comments:** 这项研究提出了一种实用的动态学习率调度方法，通过利用损失值反馈来优化训练过程。其创新点在于将学习率的自适应调整与训练损失直接关联，而非采用固定的衰减策略。这对于提升神经网络训练效率和稳定性具有重要意义，尤其是在处理复杂问题如PINNs和图像分类时。该方法的普适性强，有望在不同神经网络架构和任务中应用。

<details>
  <summary>Details</summary>

**Motivation:** 训练神经网络，尤其是在问题复杂性增加时，具有挑战性。学习率是一个关键的超参数，通常在训练过程中保持静态，但这在复杂系统中可能不够适应，导致训练困难或效率低下。因此，需要一种更具适应性的学习率方法来有效应对变化的梯度并优化学习过程。

**Method:** 本文提出了一种动态学习率调度器（DLRS）算法。该算法根据训练过程中计算出的损失值来动态调整学习率。

**Result:** 实验结果表明，所提出的DLRS算法在物理信息神经网络（PINNs）和图像分类（使用多层感知器和卷积神经网络）问题上，能够加速训练并提高稳定性。

**Conclusion:** 本文提出的动态学习率调度器（DLRS）通过根据损失值自适应调整学习率，有效解决了神经网络训练中的挑战，显著加速了训练过程并增强了模型的稳定性。

> **ai_Abstract:** 本文提出了一种动态学习率调度器（DLRS）算法，旨在解决神经网络训练中学习率选择的挑战。该算法通过根据训练过程中的损失值自适应地调整学习率。在物理信息神经网络（PINNs）和图像分类任务上的实验证明，DLRS能够显著加速训练过程并提高模型的稳定性。

> **摘要翻译:** 训练神经网络可能具有挑战性，特别是当问题复杂性增加时。尽管使用更宽或更深的神经网络，但训练过程可能很繁琐，尤其是在超参数选择错误时。学习率是其中一个关键的超参数，通常在训练过程中保持静态。复杂系统中的学习动态通常需要一种更具适应性的学习率方法。这种适应性对于有效应对变化的梯度并在训练过程中优化学习过程至关重要。在本文中，提出了一种动态学习率调度器（DLRS）算法，该算法根据训练过程中计算出的损失值来调整学习率。实验在与物理信息神经网络（PINNs）和图像分类相关的问题上进行，分别使用多层感知器和卷积神经网络。结果表明，所提出的DLRS加速了训练并提高了稳定性。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [682] [ChemDFM-R: An Chemical Reasoner LLM Enhanced with Atomized Chemical Knowledge](https://arxiv.org/abs/2507.21990)
> *ChemDFM-R：一种通过原子化化学知识增强的化学推理LLM*

*Zihan Zhao, Bo Chen, Ziping Wan, Lu Chen, Xuanze Lin, Shiyang Yu, Situo Zhang, Da Ma, Zichen Zhu, Danyang Zhang, Huayang Wang, Zhongyang Dai, Liyang Wen, Xin Chen, Kai Yu* | **Category: cs.CE, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 化学推理, 大型语言模型, 原子化知识, 领域特定强化学习, 可解释性

**Comment:** 13 figures, 4 tables

> **TL;DR:** ChemDFM-R是一个通过原子化化学知识和特定训练方法增强的化学推理LLM，在化学任务上表现出色并提供可解释的推理。

**AI_Comments:** 这篇论文的创新点在于通过“原子化化学知识”和“混合源蒸馏”以及“领域特定强化学习”来专门提升LLM在化学领域的推理能力。其提供“可解释的、理由驱动的输出”对于科学研究和人机协作具有重要意义，增强了模型的可信度和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）取得了显著进展，但它们在化学等科学领域的应用仍受到浅层领域理解和有限推理能力的阻碍。

**Method:** 1. 构建了一个全面的原子化知识点数据集，以增强模型对化学基本原理和逻辑结构的理解。2. 提出了一种混合源蒸馏策略，该策略将专家策划的知识与通用领域推理技能相结合。3. 进行领域特定强化学习以增强化学推理能力。

**Result:** ChemDFM-R在多样化的化学基准测试中取得了尖端性能，同时提供了可解释的、理由驱动的输出。进一步的案例研究表明，显式推理链显著提高了模型在实际人机协作场景中的可靠性、透明度和实用性。

**Conclusion:** 通过构建原子化知识数据集和采用混合源蒸馏及领域特定强化学习，ChemDFM-R显著提升了LLM在化学领域的推理能力、可靠性、透明度和实用性。

> **ai_Abstract:** ChemDFM-R是一个针对化学领域开发的LLM，旨在解决现有LLM在化学领域理解和推理能力不足的问题。它通过构建原子化化学知识数据集、采用混合源蒸馏策略整合专家知识和通用推理技能，并结合领域特定强化学习进行训练。实验证明ChemDFM-R在化学任务上表现出色，并能提供可解释的推理过程，显著提升了模型在实际应用中的可靠性和透明度。

> **摘要翻译:** 尽管大型语言模型（LLMs）取得了令人瞩目的进展，但它们在化学等科学领域的应用仍受到浅层领域理解和有限推理能力的阻碍。在这项工作中，我们专注于化学特定领域，并开发了一个化学推理LLM，ChemDFM-R。我们首先构建了一个全面的原子化知识点数据集，以增强模型对化学基本原理和逻辑结构的理解。然后，我们提出了一种混合源蒸馏策略，该策略将专家策划的知识与通用领域推理技能相结合，随后进行领域特定强化学习以增强化学推理。在多样化的化学基准测试上的实验表明，ChemDFM-R取得了尖端性能，同时提供了可解释的、理由驱动的输出。进一步的案例研究表明，显式推理链如何显著提高模型在实际人机协作场景中的可靠性、透明度和实用性。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [907] [Falling through the cracks: energy storage along segmented brittle crack fronts](https://arxiv.org/abs/2507.19406)
> *裂纹中的能量储存：沿分段脆性裂纹前沿的能量储存*

*Xinyue Wei, John M. Kolinski* | **Category: cs.CE** | **Updated: 2025-07-29**

**Keywords:** 脆性裂纹, 裂纹扩展, 能量储存, 韧带, 应变能密度

**Comment:** 

> **TL;DR:** 脆性裂纹扩展中，断裂韧带会集中应变能密度，且表观断裂能随韧带内应变能增加而增加，通过三维测量证实了这一点。

**AI_Comments:** 这项研究通过创新的原位3D测量技术，首次对脆性裂纹扩展中的韧带特征进行了定量分析，揭示了其在能量储存和断裂能增加中的关键作用，填补了该领域定量分析的空白。

<details>
  <summary>Details</summary>

**Motivation:** 脆性裂纹扩展中形成的阶梯状裂纹和连接韧带会改变裂纹场的结构和稳定性，但缺乏对其力学的定量分析。

**Method:** 进行原位3D测量，利用激光薄片扫描脆性水凝胶样本，记录嵌入示踪粒子散射强度，以解析阶梯状裂纹和韧带特征周围的变形场。

**Result:** 韧带集中了应变能密度；表观断裂能与韧带内的应变能成比例增加。

**Conclusion:** 表观断裂能的增加与韧带内应变能的集中有关。

> **ai_Abstract:** 这项研究通过原位3D测量，定量分析了脆性裂纹扩展中形成的阶梯状裂纹和连接韧带的力学行为。利用激光扫描脆性水凝胶样本并追踪粒子，研究发现韧带区域会集中应变能密度，并且表观断裂能的增加与韧带内储存的应变能呈正比。

> **摘要翻译:** 脆性裂纹扩展过程中，光滑的裂纹前沿曲线经常变得不连续，形成阶梯状裂纹和连接新形成裂纹前沿的材料韧带。这些普遍特征从根本上改变了扩展裂纹的奇异场结构和稳定性；然而，缺乏对其力学的定量分析。在此，我们进行原位3D测量，以解析阶梯状裂纹周围以及关键的韧带特征内的变形场。通过用薄激光片扫描脆性水凝胶样品，同时记录嵌入示踪粒子的散射强度，获得了3D运动学数据。我们发现韧带集中了应变能密度，此外，表观断裂能与韧带内的应变能成比例增加。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [543] [Efficient Runtime Verification of Real-Time Systems under Parametric Communication Delays](https://arxiv.org/abs/2404.18282)
> *实时系统在参数化通信延迟下的高效运行时验证*

*Martin Fränzle, Thomas M. Grosen, Kim G. Larsen, Martin Zimmermann* | **Category: cs.FL** | **Updated: 2025-07-29**

**Keywords:** 运行时验证, 实时系统, 参数化延迟, 在线监控, 基于区域算法

**Comment:** 

> **TL;DR:** 本文提出了一种纯粹基于区域的在线监控和测试算法，旨在高效处理实时系统在参数化通信延迟下的运行时验证问题，避免了昂贵的参数化时间自动机验证过程，并在UPPAAL上取得了初步的积极结果。

**AI_Comments:** 该研究的创新之处在于提出了纯粹基于区域的算法来精确处理实时系统运行时验证中的参数化通信延迟问题，避免了传统昂贵的参数化时间自动机验证方法。这对于提高实时系统在线监控的实用性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 实时系统的在线监控和测试通常假设观察到的轨迹能够立即获得精确的时间戳，但实际上，连接被观察系统与监控设备的电路会引入显著且波动的参数化延迟，导致这一假设难以成立，从而使得传统的直接构造方法不再准确。

**Method:** 提出了纯粹基于区域的在线监控和测试算法，该算法能够精确处理参数化延迟，且无需诉诸于参数化时间自动机的昂贵验证过程。这些算法已在实时模型检查工具UPPAAL上实现。

**Result:** 算法已在实时模型检查工具UPPAAL上实现，并报告了令人鼓舞的初步结果。

**Conclusion:** 本文提出的纯粹基于区域的算法能够有效解决实时系统在参数化通信延迟下进行运行时验证的挑战，并在实践中展现出高效且精确的潜力。

> **ai_Abstract:** 本文针对实时系统在线监控中因通信延迟导致时间戳不准确的问题，提出了一种高效的纯粹基于区域的在线监控和测试算法。该算法能够精确处理参数化延迟，避免了昂贵的参数化时间自动机验证，并在实时模型检查工具UPPAAL上实现了原型，取得了积极的初步成果。

> **摘要翻译:** 时序Büchi自动机为表达实时系统需求提供了一种非常富有表现力的形式主义。通过对系统观察到的轨迹进行此类自动机的符号执行，可以实现嵌入式实时系统的在线监控和主动测试。然而，这种直接构造只有在轨迹观察是即时的意义上才是忠实的，即监控器（或测试线束）可以为其观察到的动作分配精确的时间戳，这在实践中很少是真的，因为连接被观察系统到其监控或测试设备的电路引入了大量且波动的参数化延迟。我们提出了纯粹基于区域的在线监控和测试算法，这些算法能够精确处理此类参数化延迟，而无需诉诸于参数化时间自动机的昂贵验证过程。我们已将算法在实时模型检查工具UPPAAL上实现，并报告了令人鼓舞的初步结果。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [606] [Exploiting Assumptions for Effective Monitoring of Real-Time Properties under Partial Observability](https://arxiv.org/abs/2409.05456)
> *在部分可观察性下利用假设有效监控实时属性*

*Alessandro Cimatti, Thomas M. Grosen, Kim G. Larsen, Stefano Tonetta, Martin Zimmermann* | **Category: cs.FL** | **Updated: 2025-07-29**

**Keywords:** 运行时验证, 部分可观察性, 实时系统, 假设, 时间自动机

**Comment:** 

> **TL;DR:** 本文提出了一种基于假设的运行时验证 (ABRV) 方法，用于在部分可观察的实时系统中有效监控时序属性，通过利用关于系统行为的假设，实现更早的判断并处理不可观察的部分。

**AI_Comments:** 本文的创新之处在于将假设引入运行时验证，以解决实时系统在部分可观察性下的监控难题，这在信息物理系统等领域具有重要实际意义。其结合时间自动机和MITL的正式方法，并利用UPPAAL进行实现，体现了理论与实践的结合。通过利用假设，该方法能够提前给出判断并处理不可观察事件，显著提升了监控的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 运行时验证对于确保实时系统（特别是信息物理系统）的正确性和可靠性至关重要。然而，在部分可观察的系统中，有效预测属性的失效或成功是一个重大挑战。

**Method:** 本文开发了一种用于连续实时环境的基于假设的运行时验证 (ABRV) 方法。该方法利用关于系统行为的假设（以时间自动机指定）来使监视器预测未来结果并处理不可观察的系统部分（如内部故障）。要监控的属性使用度量区间时序逻辑 (MITL) 指定。该方法还包括使用定时约束序列形式化具有数据和时间不确定性的观测。提出了一种基于区域的在线算法来计算监控裁决，并在 UPPAAL 工具上实现。

**Result:** 在概念验证案例上的实验评估证明了该方法的可行性和有效性，说明了假设如何促进更早的判断，实现对依赖于不可观察事件的属性的监控，并提供有关可伸缩性的见解。

**Conclusion:** 该基于假设的运行时验证方法在部分可观察性下对实时属性进行有效监控是可行且有效的，通过利用假设来改进预测并处理不可观察部分。

> **ai_Abstract:** 本文针对实时系统中部分可观察性下时序属性的运行时验证挑战，提出了一种基于假设的运行时验证 (ABRV) 方法。该方法利用时间自动机指定的系统行为假设，结合度量区间时序逻辑 (MITL) 定义的属性，并通过基于区域的在线算法在 UPPAAL 上实现，旨在预测未来结果并处理不可观察的系统部分。实验证明了其可行性和有效性，显示了假设如何促进更早的判断并实现对依赖不可观察事件的属性的监控。

> **摘要翻译:** 运行时验证时序属性对于确保实时系统（特别是在信息物理系统）的正确性和可靠性至关重要。该领域的一个重大挑战是有效预测属性的失效或成功，尤其是在处理部分可观察系统时。本文通过开发一种用于连续实时设置的基于假设的运行时验证 (ABRV) 方法来应对这些挑战。我们的方法利用关于系统行为的假设（指定为时间自动机），使监视器能够预测未来的结果并处理不可观察的系统部分，例如内部故障。要监控的属性使用度量区间时序逻辑 (MITL) 指定。该方法还包括使用定时约束序列形式化具有数据和时间不确定性的观测。我们提出了一种基于区域的在线算法来计算监控裁决，并在 UPPAAL 工具上实现。在概念验证案例上的实验评估证明了该方法的可行性和有效性，说明了假设如何促进更早的判断，实现对依赖于不可观察事件的属性的监控，并提供有关可伸缩性的见解。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [675] [Conservative Perception Models for Probabilistic Verification](https://arxiv.org/abs/2503.18077)
> *用于概率验证的保守感知模型*

*Matthew Cleaveland, Pengyuan Lu, Oleg Sokolsky, Insup Lee, Ivan Ruchkin* | **Category: cs.FL** | **Updated: 2025-07-29**

**Keywords:** 概率验证, 感知模型, 区间马尔可夫决策过程, 自主系统, 保守抽象

**Comment:** 

> **TL;DR:** 本文提出了一种构建可证明保守的区间马尔可夫决策过程（IMDP）模型的方法，用于验证带有感知组件的自主系统，解决了感知复杂性和不确定性带来的验证挑战。

**AI_Comments:** 本文的创新之处在于提出了一种在概率验证框架下，为具有学习感知组件的自主系统构建可证明保守模型的方法。这对于提高自主系统的可靠性和安全性具有重要意义，尤其是在处理黑盒学习模型的不确定性方面迈出了关键一步。

<details>
  <summary>Details</summary>

**Motivation:** 由于感知组件的复杂性和操作环境的不确定性，验证带有学习感知组件的自主系统行为是一个具有挑战性的问题。将黑盒感知组件构建成可模型检查的模型以提供系统级数学保证一直是一个持久的挑战。

**Method:** 本文提出了一种构建可证明保守的闭环系统区间马尔可夫决策过程（IMDP）模型的方法，这些系统包含感知组件。

**Result:** 我们的技术能够生成具有用户指定概率的保守抽象。该方法在自动制动案例研究中进行了评估，使用了合成感知组件和CARLA驾驶模拟器中的对象检测器YOLO11。

**Conclusion:** 本文提出了一种构建保守感知模型的方法，该方法能够对带有学习感知组件的自主系统进行概率验证，从而为系统级数学保证提供了解决方案。

> **ai_Abstract:** 本文针对带有学习感知组件的自主系统验证难题，提出了一种构建可证明保守的区间马尔可夫决策过程（IMDP）模型的方法。该方法旨在将复杂的黑盒感知组件抽象为可模型检查的模型，以提供系统级的数学保证。研究证明，该技术能够生成具有用户指定概率的保守抽象，并在自动制动案例研究中，利用合成感知组件和YOLO11目标检测器进行了有效验证。

> **摘要翻译:** 验证带有学习感知组件的自主系统行为是一个具有挑战性的问题，这归因于感知的复杂性和操作环境的不确定性。概率模型检测是为系统随机模型提供保证的强大工具。然而，为系统级数学保证构建黑盒感知组件的可模型检查模型一直是一个持久的挑战。在本文中，我们提出了一种构建带有感知组件的闭环系统的可证明保守区间马尔可夫决策过程（IMDP）模型的方法。我们证明了我们的技术可以产生具有用户指定概率的保守抽象。我们在一个自动制动案例研究中评估了我们的方法，该案例研究使用了合成感知组件和CARLA驾驶模拟器中的对象检测器YOLO11。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [733] [Time for Timed Monitorability](https://arxiv.org/abs/2504.10008)
> *定时可监控性研究*

*Thomas M. Grosen, Sean Kauffman, Kim G. Larsen, Martin Zimmermann* | **Category: cs.FL** | **Updated: 2025-07-29**

**Keywords:** 时间自动机, 可监控性, 实时属性, 运行时验证, 可判定性

**Comment:** 

> **TL;DR:** 本文研究了实时属性的可监控性问题，使用时间自动机表示。研究结果表明，对于确定性时间Muller自动机，可监控性是可判定的，且监控界限可计算；而对于非确定性时间Büchi自动机，该问题是不可判定的，且界限不可计算。

**AI_Comments:** 本文对运行时验证领域做出了重要的理论贡献，特别是将可监控性的概念扩展到实时系统。对确定性Muller自动机和非确定性Büchi自动机之间在可判定性和可计算性方面的明确区分，为实时属性监控的固有复杂性提供了关键见解。监控界限的引入和分析尤其具有创新性，为设计高效监控系统提供了实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 监控是验证工具箱的重要组成部分，尤其是在模型检测等穷举验证不可行的情况下。在线监控的目标是在运行时确定规范的满足或违反。然而，并非所有规范都适用于监控，且离散时间下的可监控性已得到广泛研究，但实时属性的可监控性仍需深入探讨。本文旨在填补这一空白，并进一步细化可监控性，以确定产生有用判决所需的事件和时间界限。

**Method:** 本文研究了以时间自动机表示的实时属性的可监控性问题。具体分析了确定性时间Muller自动机和非确定性时间Büchi自动机在可监控性和监控界限计算方面的异同，并通过理论证明得出结论。

**Result:** 对于由确定性时间Muller自动机给出的规范，可监控性问题是可判定的，并且可以有效地计算出产生有用判决所需的事件数量和时间界限。然而，对于由非确定性时间Büchi自动机给出的规范，可监控性问题是不可判定的，且相应的界限也是不可计算的。

**Conclusion:** 本文为定时可监控性建立了关键的可判定性和可计算性结果，强调了时间自动机中确定性/非确定性所引入的不同复杂性，尤其是在提供早期、有界判决的能力方面。

> **ai_Abstract:** 本文探讨了实时属性的可监控性问题，这是运行时验证的关键方面。研究了以时间自动机表示的规范，证明了对于确定性时间Muller自动机，可监控性是可判定的，但对于非确定性时间Büchi自动机则是不可判定的。此外，论文还引入了产生有用判决所需的事件和时间界限的概念，并证明了这些界限对于确定性时间Muller自动机是可计算的，而对于非确定性时间Büchi自动机则不可计算。

> **摘要翻译:** 监控是验证工具箱的重要组成部分，尤其是在使用模型检测等穷举验证不可行的情况下。在线监控的目标是在运行时，即基于有限的执行前缀，确定规范的满足或违反。然而，并非所有规范都适用于监控，例如，没有有限执行可以证明满足或违反的属性。可监控性是指给定规范是否适用于监控的问题，并且在离散时间领域已得到广泛研究。
本文研究了以时间自动机表示的实时属性的可监控性问题。对于由确定性时间Muller自动机给出的规范，我们证明了其可判定性，而对于由非确定性时间Büchi自动机给出的规范，我们表明该问题是不可判定的。
此外，我们对可监控性进行了细化，以确定事件数量以及在监控属性可能产生有用判决之前必须经过的时间的界限。我们证明，对于确定性时间Muller自动机，这些界限可以有效地计算。相比之下，我们表明对于非确定性时间Büchi自动机，这些界限是不可计算的。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [788] [Active Learning of Upward-Closed Sets of Words](https://arxiv.org/abs/2504.21429)
> *词语向上闭合集的积极学习*

*Quentin Aristote* | **Category: cs.FL, F.4.3** | **Updated: 2025-07-29**

**Keywords:** 向上闭合集, L*算法, 自动机学习, 良拟序, 有限生成幺半群

**Comment:** 13 pages, 2 figures; presented at CALCO 2025

> **TL;DR:** 本文基于Angluin的L*算法，提出了对词语向上闭合集基的可计算性的新证明，并将其推广到有限生成幺半群，同时描述了一种学习准序自动机的新算法。

**AI_Comments:** 这篇论文的创新之处在于利用Angluin的L*算法为良拟序理论中的一个既有结果提供了新的证明，并成功地将两个看似不相关的1980年代的重要成果联系起来。通过将Valk和Jantzen的结果推广到有限生成幺半群，论文扩展了相关理论的适用范围，对自动机学习和形式语言理论有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在提供一个关于词语向上闭合集基可计算性的新证明，并关联Angluin的L*算法与Valk和Jantzen关于整数元组向上闭合集基可计算性的结果。

**Method:** 提出了一种基于Angluin的L*算法的新证明方法，该算法能从一个最小充分的教师那里学习自动机。同时，描述了一种学习准序自动机的新算法，并将Valk和Jantzen的结果推广到有限生成幺半群。

**Result:** 成功给出了词语向上闭合集基可计算性的新证明，并将Angluin的L*算法与Valk和Jantzen的结果关联起来。此外，还提出了一个学习准序自动机的新算法，并将Valk和Jantzen的泛化结果扩展到有限生成幺半群。

**Conclusion:** 通过基于L*算法的新证明，不仅重新验证了词语向上闭合集基的可计算性，还成功地统一并扩展了1980年代的两个重要成果，并提出了新的学习算法。

> **ai_Abstract:** 本文提供了一个关于词语向上闭合集基可计算性的新证明，该证明利用了Angluin的L*算法，从而将L*算法与Valk和Jantzen关于整数元组向上闭合集基可计算性的结果联系起来。此外，论文还提出了一种学习准序自动机的新算法，并将Valk和Jantzen的泛化结果推广到有限生成幺半群。

> **摘要翻译:** 我们对关于词语向上闭合集基的可计算性这一良拟序理论中的结果给出了一个新的证明。这个新证明基于Angluin的L*算法，该算法能从一个最小充分的教师那里学习自动机。这尤其关联了1980年代的两个结果：Angluin的L*算法，以及Valk和Jantzen关于整数元组向上闭合集基可计算性的结果。在此过程中，我们描述了一种从最小充分教师处学习准序自动机的算法，并将Valk和Jantzen结果的一个泛化（涵盖词语和整数）扩展到有限生成幺半群。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [11] [Probabilistically safe and efficient model-based reinforcement learning](https://arxiv.org/abs/2504.00626)
> *概率安全高效的基于模型的强化学习*

*Filippo Airaldi, Bart De Schutter, Azita Dabiri* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 强化学习, 模型预测控制, 控制屏障函数, 安全性, 随机系统

**Comment:** 8 pages, 4 figures, accepted to 2025 CDC

> **TL;DR:** 本文提出一种基于样本、基于模型的强化学习方法，通过结合模型预测控制（MPC）和概率控制屏障函数（CBF）来解决安全关键型随机RL任务，旨在平衡安全性和计算效率。

**AI_Comments:** 该方法创新性地将模型预测控制（MPC）与概率控制屏障函数（CBF）以及可学习的终端成本相结合，在基于样本的强化学习框架中实现了随机环境下的安全性和效率。利用强化学习算法学习终端成本和CBF约束是减轻采样计算负担的巧妙方法，对实际安全关键应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决安全关键型随机强化学习（RL）任务中的挑战。目标是在确保安全性的同时提高效率，尤其是在存在随机性和计算负担的情况下。

**Method:** 该方法采用基于样本、基于模型的方法。核心是一个作为函数逼近的模型预测控制（MPC）方案，提供基于模型的预测控制策略。为确保安全，MPC控制器中集成了概率控制屏障函数（CBF）。为近似最优控制公式中的随机效应并满足概率CBF条件，采用了具有保证的基于样本的方法。为平衡采样带来的额外计算负担，MPC目标中包含可学习的终端成本公式。部署了强化学习算法来学习终端成本和CBF约束。

**Result:** 在受限线性时不变（LTI）问题上的数值实验结果证实，所提出的方法在减少计算时间的同时，能够保持控制性能和安全性。

**Conclusion:** 所提出的方法通过结合模型预测控制、概率控制屏F函数和可学习的终端成本，有效实现了安全关键型随机强化学习任务中的概率安全和高效控制。

> **ai_Abstract:** 本文提出一种用于安全关键型随机任务的基于样本、基于模型的强化学习方法。该方法利用模型预测控制（MPC）框架，并集成了概率控制屏障函数（CBF）以确保安全。为处理随机性和计算负荷，它采用了基于样本的方法和可学习的终端成本，两者均通过强化学习算法学习。实验结果表明，该方法在保持性能和安全性的同时，显著减少了计算时间。

> **摘要翻译:** 本文提出一种基于样本、基于模型的方法来解决安全关键型随机强化学习（RL）任务。该方法的核心是一个模型预测控制（MPC）方案，它作为函数逼近，提供基于模型的预测控制策略。为确保安全，一个概率控制屏障函数（CBF）被整合到MPC控制器中。为了在最优控制公式中近似随机效应并满足概率CBF条件，采用了具有保证的基于样本的方法。此外，为了平衡采样带来的额外计算负担，MPC目标中包含了一个可学习的终端成本公式。部署了一个RL算法来学习终端成本和CBF约束。在受限LTI问题上的数值实验结果证实了所提出方法在减少计算时间的同时保持控制性能和安全性的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [31] [Ensemble Control of Stochastic Oscillators via Periodic and Feedback Control](https://arxiv.org/abs/2507.21441)
> *随机振子的集成控制：通过周期性与反馈控制*

*Kaito Ito, Haruhiro Kume, Hideaki Ishii* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-29**

**Keywords:** 集成控制, 随机振子, 周期性控制, 反馈控制, 相位分布

**Comment:** 16 pages

> **TL;DR:** 本文提出了一种通过结合周期性前馈和反馈控制来引导受随机噪声影响的振子群相位分布的方法，并证明了其可达性和收敛性。

**AI_Comments:** 这篇论文通过结合周期性前馈和反馈控制，为随机振子的集成控制提供了一种新颖且实用的方法。其创新之处在于解决了随机噪声下相位分布控制的理论难题，并通过凸优化和反馈机制提高了控制的精确性和收敛速度。特别是在测量误差下仍能保持收敛性，这增加了方法的鲁棒性和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决在随机噪声下振子群相位分布的集成控制问题，因为这方面的理论理解尚缺乏。

**Method:** 首先，通过目标密度的傅里叶系数和振子的相位敏感函数，表征了周期性前馈控制下相位分布的可达性，并通过凸优化设计了周期性输入。其次，提出了一种结合周期性与反馈控制的集成控制方法，其中反馈部分旨在加速分布的收敛。

**Result:** 提出了所提方法的收敛性结果，包括在相位分布存在测量误差的情况下依然成立的结果。通过数值例子证明了所提方法的有效性。

**Conclusion:** 该研究成功地通过结合周期性前馈和反馈控制，解决了随机振子群相位分布的集成控制问题，并证明了其在存在测量误差情况下的有效性和收敛性。

> **ai_Abstract:** 本文提出了一种针对受随机噪声影响的振子群的集成控制方法，旨在将振子群的相位分布引导至特定目标分布。研究首先通过分析周期性前馈控制下相位分布的可达性，并利用凸优化设计周期性输入。接着，结合周期性与反馈控制，设计了一种加速分布收敛的集成控制策略。该方法被证明在存在测量误差的情况下仍能保持收敛性，并通过数值示例验证了其有效性。

> **摘要翻译:** 我们解决了将所有接收相同控制输入的振子的相位分布引导至给定目标分布的问题。在大量群体限制下，振子的分布可以用概率密度来描述。因此，我们的问题可以看作是在稳态密度约束下的集成控制问题。特别是，我们考虑了振子受到随机噪声影响的情况，对此的理论理解仍然缺乏。首先，我们通过目标密度的傅里叶系数和振子的相位敏感函数，表征了周期性前馈控制下相位分布的可达性。这使我们能够通过解决一个凸优化问题，设计一个使振子的稳态分布最接近目标的周期性输入。其次，我们设计了一种结合周期性与反馈控制的集成控制方法，其中反馈部分旨在加速振子分布的收敛。我们展示了所提出方法的一些收敛性结果，包括在相位分布存在测量误差的情况下依然成立的结果。通过数值例子证明了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [46] [Unifying Direct and Indirect Learning for Safe Control of Linear Systems](https://arxiv.org/abs/2504.18331)
> *统一直接和间接学习以实现线性系统的安全控制*

*Amir Modares, Niyousha Ghiasi, Bahare Kiumarsi, Hamidreza Modares* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 安全控制, 线性系统, 集合成员识别, 矩阵区间, 保守性减少

**Comment:** arXiv admin note: text overlap with arXiv:2502.04195

> **TL;DR:** 本文提出了一种结合直接和间接学习的新型集合成员识别方法，以实现线性系统在不确定性和扰动下的安全控制，并通过减少保守性来保证收缩性。

**AI_Comments:** 该论文的创新点在于其统一直接和间接学习的框架，特别是提出了将开环和闭环学习相结合的新型集合成员识别方法。通过引入CMZ和自适应更新FOLMS，有效地减少了控制器的保守性，这对于安全关键系统至关重要。论文通过理论分析和仿真验证了其方法的有效性，为处理不确定性下的线性系统安全控制提供了一条有前景的路径。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为存在系统不确定性和有界扰动的线性系统开发支持学习的安全控制器。其主要动机是减少现有方法的保守性。

**Method:** 本文首先使用矩阵区间（MZ）表征数据驱动的闭环动力学（CLD），并通过引入一致等式约束来消除不兼容的扰动实现，将其细化为约束矩阵区间（CMZ）。为了进一步减少保守性，该方法将开环学习与闭环学习相结合，提出了一种新颖的集合成员识别方法，将开环动力学建模为CMZ。先验知识作为初始可行开环模型集（FOLMS），并根据新的在线数据进行细化。这个后验FOLMS自适应地替换了闭环学习过程中用于扰动消除的先验知识集。最终，利用细化后的参数化CLD集，直接自适应地学习控制器，并通过线性规划问题保证多面体安全集的λ收缩性。

**Result:** 该方法通过引入一致等式约束和结合开环与闭环学习，成功减少了保守性。通过模拟示例验证了所提出方法的有效性，并支持了理论结果。

**Conclusion:** 本文开发了一种结合直接和间接学习的集合成员识别方法，以实现线性系统的安全控制，有效减少了保守性，并通过仿真验证了其有效性。

> **ai_Abstract:** 本文提出了一种用于线性系统安全控制的统一直接和间接学习方法，该方法能有效处理系统不确定性和有界扰动。通过引入约束矩阵区间（CMZ）来细化闭环动力学，并结合开环和闭环学习，采用一种新颖的集合成员识别方法，利用先验知识和在线数据自适应地更新模型集。这种方法显著减少了保守性，并通过线性规划问题确保了多面体安全集的λ收缩性，最终实现鲁棒的安全控制器。仿真结果验证了其有效性。

> **摘要翻译:** 本文为存在系统不确定性和有界扰动的线性系统开发了支持学习的安全控制器。给定扰动区间，首先使用矩阵区间（MZ）表征基于数据的闭环动力学（CLD），并通过几个步骤细化，得到约束矩阵区间（CMZ）。这种细化是通过引入一致等式约束来实现的，这些约束消除了不兼容的扰动实现。更精确地说，先验知识和观测数据分别用于构建符合数据和先验知识的扰动序列的CMZ表示，并通过扰动序列的初始MZ进行交集，从而产生细化的CMZ。这种方法减少了保守性。为了进一步减少保守性，我们通过提出一种新颖的集合成员识别方法，将开环动力学建模为CMZ，从而统一了开环学习和闭环学习。先验知识作为该CMZ的初始可行开环模型集（FOLMS），每当有新的信息丰富的在线数据可用时，该集合就会被细化为后验集合。然后，这个后验FOLMS自适应地替换了闭环学习过程中用于扰动消除的先验知识集。由此产生的细化参数化CLD集随后被利用来直接和自适应地学习能够鲁棒地强制执行安全的控制器。为了实现这一目标，我们提出了一个线性规划问题，以保证多面体安全集的λ收缩性。提供了一个仿真示例来验证所提出方法的有效性并支持理论结果。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [87] [Experimental Implementation and Validation of Predictor-Based CACC for Vehicular Platoons With Distinct Actuation Delays](https://arxiv.org/abs/2507.21579)
> *具有不同执行延迟的车辆队列中基于预测器的CACC的实验实现与验证*

*Amirhossein Samii, Redmer de Haan, Nikolaos Bekiaris-Liberis* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 协作自适应巡航控制, 执行延迟, 车辆队列, 预测器, 稳定性

**Comment:** Accepted for presentation at the IEEE Conference on Decision and
  Control (CDC) 2025. 8 pages

> **TL;DR:** 实验验证了一种基于预测器的协作自适应巡航控制（CACC）设计，该设计能有效补偿具有不同执行延迟的异构车辆队列中的延迟，确保车辆和队列稳定性。

**AI_Comments:** 这项研究通过实验验证了其提出的基于预测器的CACC设计在处理异构车辆队列中独特且长期执行延迟方面的有效性，具有创新性。它不仅提供了理论公式，还结合了实际车辆实验和大规模仿真，增强了研究结果的可靠性和实用性，对未来自动驾驶车辆队列的稳定控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决异构车辆队列中存在长期且可能不同的执行延迟时，实现延迟补偿的需求。

**Method:** 提供了所实现控制设计的明确公式，考虑了零阶保持和采样测量的影响；通过推导连续车辆对的速度传递函数，数值获得了车辆和队列的稳定性条件；并对大量车辆的队列进行了数字实现的仿真。

**Result:** 仿真和实验结果均证实了所提出的基于预测器的CACC设计在存在长期/不同执行延迟的情况下，能够有效保证单个车辆稳定性、队列稳定性和跟踪性能。

**Conclusion:** 基于预测器的CACC设计能够有效补偿异构车辆队列中的长期和不同执行延迟，并保证车辆和队列的稳定性与跟踪性能。

> **ai_Abstract:** 本文对一种新颖的基于预测器的协作自适应巡航控制（CACC）设计进行了实验验证。该设计专门针对具有长期且不同执行延迟的异构车辆队列，旨在实现有效的延迟补偿。研究人员提供了控制设计的详细公式，并考虑了数字实现中的采样效应。通过数值分析和仿真，他们验证了该设计在保证单个车辆稳定性、队列稳定性和跟踪性能方面的有效性，即使在存在显著执行延迟的情况下也能表现良好。

> **摘要翻译:** 我们在一对车辆中，对最近提出的一种基于预测器的协作式自适应巡航控制（CACC）设计进行了实验验证。该设计旨在实现异构车辆队列中的延迟补偿，这些队列可能存在长期且对每辆车都不同的执行延迟。我们提供了所实现控制设计的明确公式，考虑了零阶保持和采样测量的影响；并通过推导连续车辆对的速度传递函数，数值获得了车辆和队列的稳定性条件。我们还展示了在控制器数字实现下，对更多车辆队列进行的一致仿真结果。仿真和实验结果都证实了基于预测器的CACC设计在存在长期/不同执行延迟的情况下，能够保证单个车辆稳定性、队列稳定性以及跟踪的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [139] [A reference frame-based microgrid primary control for ensuring global convergence to a periodic orbit](https://arxiv.org/abs/2408.00916)
> *一种基于参考系的微电网一次控制，用于确保全局收敛到周期轨道*

*Xinyuan Jiang, Constantino M. Lagoa, Daning Huang, Yan Li* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-30**

**Keywords:** 微电网, 全局收敛, 周期轨道, 移位无源性, 端口哈密顿系统

**Comment:** 

> **TL;DR:** 本文提出了一种基于参考系的微电网一次控制方法，通过扩展移位无源性理论，首次在全状态空间中证明了微电网非标称稳态的全局收敛性，并验证了其在抑制振荡和提高暂态性能方面的有效性。

**AI_Comments:** 这篇论文的创新点在于将移位无源性理论应用于微电网的极限环稳定性分析，并首次在全状态空间中证明了非标称稳态的全局收敛性，这对于高可再生能源渗透率下电力系统的稳定运行具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 具有高可再生能源渗透率的电力系统容易出现频率振荡和电压不稳定。传统的稳定性分析通常简化振幅动力学，导致对稳态（本质上是极限环）的轨道收敛性分析不足。

**Method:** 本文提出了一种分析微电网轨道稳定性的方法，并为逆变器接口的可再生发电机提出了一种电压控制器。其核心是将端口哈密顿系统的移位无源性扩展到极限环分析，并证明如果系统在不考虑特定常数项的情况下是移位无源的，则周期轨道是全局吸引的。

**Result:** 实现了微电网在全状态空间中非标称稳态的首次全局稳定性结果，为系统耗散性确保收敛的同步现象提供了新见解。所提出的控制器通过测试微电网验证，与标准下垂控制相比，展示了其卓越的稳定性和瞬态平滑性。

**Conclusion:** 本文提出了一种创新的基于参考系的微电网一次控制方法，通过扩展移位无源性理论，首次在全状态空间中证明了微电网非标称稳态的全局稳定性，有效解决了高可再生能源渗透率下的稳定性问题。

> **ai_Abstract:** 本文针对高可再生能源渗透率下微电网的频率振荡和电压不稳定问题，提出了一种基于参考系的微电网一次控制策略。该方法通过将端口哈密顿系统的移位无源性理论扩展应用于极限环分析，解决了旋转内部参考系中常数项带来的挑战，并首次在全状态空间中证明了微电网非标称稳态的全局收敛性。实验验证表明，所提出的控制器在稳定性和暂态平滑性方面优于传统的下垂控制。

> **摘要翻译:** 具有高可再生能源渗透率的电力系统容易受到频率振荡和电压不稳定的影响。传统上，电力系统的稳定性要么被视为局部稳定性，要么被视为角度振荡器同步问题，并简化假设振幅动力学发生在更短的时间尺度上。然而，如果没有这个假设，所研究的稳态本质上是一个极限环，其轨道的收敛性存在疑问。本文提出了一种分析微电网轨道稳定性的方法，并为逆变器接口的可再生发电机提出了一种电压控制器。该问题的主要障碍在于每个发电机旋转内部参考系中的常数项。我们将端口哈密顿系统的移位无源性扩展到极限环分析，并证明，如果系统在不考虑这些常数项的情况下是移位无源的，则周期轨道是全局吸引的。据我们所知，这是微电网在全状态空间中非标称稳态的第一个全局稳定性结果，它为系统耗散性确保收敛的同步现象提供了新见解。所提出的控制器通过测试微电网验证，与标准下垂控制相比，展示了其稳定性和瞬态平滑性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [143] [Deep Neuro-Adaptive Sliding Mode Controller for Higher-Order Heterogeneous Nonlinear Multi-Agent Teams with Leader](https://arxiv.org/abs/2507.21667)
> *深度神经自适应滑模控制器，用于具有领导者的高阶异构非线性多智能体团队*

*Khushal Chaudhari, Krishanu Nath, Manas Kumar Bera* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 深度神经网络, 滑模控制, 多智能体系统, 神经自适应, 领导者-跟随者跟踪

**Comment:** 

> **TL;DR:** 本文提出了一种基于深度神经网络（DNN）的神经自适应滑模控制（SMC）策略，用于在高阶、异构、非线性且存在未知动力学和外部扰动的多智能体系统中实现领导者-跟随者跟踪。通过数值模拟验证了其有效性、适应性和鲁棒性。

**AI_Comments:** 本文的创新点在于将深度神经网络引入神经自适应滑模控制中，以更准确地处理高阶、异构和未知非线性动力学，并结合集合论范式中的受限势函数确保系统轨迹的有界性，这增强了控制器对近似误差和外部扰动的鲁棒性。该方法为复杂多智能体系统的控制提供了一个有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 解决在高阶、异构、非线性、未知动力学及外部扰动下的多智能体系统中的领导者-跟随者跟踪问题。

**Method:** 提出了一种基于深度神经网络（DNN）的神经自适应滑模控制（SMC）策略。DNN用于比浅层神经网络更准确地补偿未知非线性动力学，SMC确保鲁棒跟踪。该框架在集合论范式内采用受限势函数以确保系统轨迹在紧凑集合内保持有界。控制方案基于非光滑Lyapunov稳定性理论，并推导出DNN内外层网络权重的更新律。

**Result:** 数值模拟示例展示了所提出控制器的有效性、适应性和鲁棒性。

**Conclusion:** 所提出的基于DNN的神经自适应滑模控制器能够有效、自适应且鲁棒地解决高阶异构非线性多智能体系统在外部扰动下的领导者-跟随者跟踪问题。

> **ai_Abstract:** 本文提出了一种针对高阶、异构、非线性且存在未知动力学和外部扰动的多智能体系统，实现领导者-跟随者跟踪的深度神经网络（DNN）神经自适应滑模控制（SMC）策略。该方法利用DNN高精度补偿未知非线性，结合SMC提供鲁棒跟踪，并通过受限势函数确保系统轨迹有界。基于非光滑Lyapunov稳定性理论，推导了DNN权重更新律。仿真结果验证了所提控制器的有效性、适应性和鲁棒性。

> **摘要翻译:** 这封信提出了一种基于深度神经网络（DNN）的神经自适应滑模控制（SMC）策略，用于在具有高阶、异构、非线性以及未知动力学且存在外部扰动下的多智能体系统中的领导者-跟随者跟踪。DNN用于比浅层神经网络（NNs）更准确地补偿未知非线性动力学，而SMC确保鲁棒跟踪。该框架在集合论范式内采用受限势函数，以确保系统轨迹在紧凑集合内保持有界，从而提高了对近似误差和外部扰动的鲁棒性。该控制方案以非光滑Lyapunov稳定性理论为基础，并推导出DNN内外层网络权重的更新律。通过数值模拟示例展示了所提出控制器的有效性、适应性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [174] [Koopman-based control using sum-of-squares optimization: Improved stability guarantees and data efficiency](https://arxiv.org/abs/2411.03875)
> *基于Koopman算子和平方和优化的控制：改进的稳定性保证和数据效率*

*Robin Strässer, Julian Berberich, Frank Allgöwer* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-30**

**Keywords:** Koopman算子, 平方和优化, 非线性系统控制, 稳定性保证, 数据效率

**Comment:** Accepted for publication in the European Journal of Control, 2025

> **TL;DR:** 本文提出了一种基于Koopman算子和平方和(SOS)优化的新型控制器设计方法，用于未知非线性系统。该方法利用SafEDMD生成带有误差界限的双线性代理模型，并通过SOS优化显式考虑双线性，从而显著减少保守性，提供更大的吸引域和更高的数据效率，并保证闭环稳定性。

**AI_Comments:** 该论文的创新点在于将Koopman算子、SafEDMD与平方和(SOS)优化相结合，用于未知非线性系统的控制器设计。通过显式地处理代理模型的双线性及其误差界限，该方法克服了现有方法的保守性，提供了更强的稳定性保证和更高的效率。其重要性体现在为复杂非线性系统的控制提供了一种更鲁棒和数据高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在近似代理模型的双线性时过于保守，仅提供局部保证，导致稳定性区域受限且数据效率不高。

**Method:** 本文提出了一种针对未知非线性系统的Koopman算子控制器设计方法。该方法利用SafEDMD架构生成带有认证误差界限的数据驱动双线性代理模型，并在控制器设计中显式地考虑这些误差界限和双线性。通过平方和(SOS)优化来参数化一个有理控制器，以稳定受误差影响的双线性代理模型，进而稳定底层的非线性系统。控制器设计条件通过半定规划得到。

**Result:** 该方法显著减少了保守性，建立了更大的吸引域，并提高了数据效率。数值例子评估证明了其相对于现有方法的优势。

**Conclusion:** 本文提出的基于Koopman算子和平方和优化的控制器设计方法，通过显式考虑双线性，成功地为未知非线性系统提供了改进的稳定性保证和更高的数据效率。

> **ai_Abstract:** 本文提出了一种基于Koopman算子和SafEDMD的新型控制器设计方法，用于未知非线性系统。该方法生成带有认证误差界限的数据驱动双线性代理模型，并利用平方和(SOS)优化显式地处理双线性，从而在控制器设计中保证闭环稳定性。与现有方法相比，该方法显著减少了保守性，提供了更大的吸引域和更高的数据效率。

> **摘要翻译:** 在本文中，我们提出了一种利用Koopman算子针对未知非线性系统的新型控制器设计方法。具体来说，我们使用最近提出的面向稳定性和证书的扩展动态模态分解（SafEDMD）架构来生成具有认证误差界限的数据驱动双线性代理模型。然后，通过在基于双线性系统的控制器设计中考虑所获得的误差界限，可以保证真实非线性系统的闭环稳定性。现有方法过度近似了代理模型的双线性，从而引入了保守性并仅提供局部保证，而我们通过在控制器设计中使用平方和（SOS）优化来显式地考虑双线性。更精确地说，我们参数化了一个稳定受误差影响的双线性代理模型，并因此稳定底层非线性系统的有理控制器。由此产生的SOS优化问题为基于半定规划的未知非线性系统提供了显式的数据驱动控制器设计条件。我们的方法通过建立更大的吸引域和提高数据效率，显著降低了保守性。所提出的方法通过数值例子进行了评估，证明了其相对于现有方法的优势。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [199] [Data-Driven Greenhouse Climate Regulation in Lettuce Cultivation Using BiLSTM and GRU Predictive Control](https://arxiv.org/abs/2507.21669)
> *生菜种植中基于BiLSTM和GRU预测控制的数据驱动温室气候调节*

*Soumo Emmanuel Arnaud, Marcello Calisti, Athanasios Polydoros* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 温室气候调节, 数据驱动, 预测控制, GRU, LSTM

**Comment:** 

> **TL;DR:** 本研究探索了使用GRU和LSTM神经网络的数据驱动预测控制方法，以优化温室气候调节。结果显示，GRU方法在保持相同经济性能和作物产量的同时，显著减少了温度和湿度违规，并降低了计算时间，证明其是更高效实用的解决方案。

**AI_Comments:** 该论文的创新之处在于将先进的深度学习模型（GRU和LSTM）应用于温室气候的预测控制，以解决传统模型的局限性。其重要性在于证明了GRU在效率和实用性方面的优势，为实现更可持续和经济的农业生产提供了新的途径。该研究的局限性可能在于其结果的普适性，即是否适用于所有类型的作物或不同的温室环境。

<details>
  <summary>Details</summary>

**Motivation:** 传统的温室模型复杂且不精确，限制了常规控制策略的有效性，导致维持最佳室内气候需要大量的能源和资源。为了实现可持续食品生产并提高经济可行性和环境可持续性，需要先进的控制系统来解决这些挑战。

**Method:** 本研究调查了使用门控循环单元（GRU）和长短期记忆（LSTM）神经网络的数据驱动预测控制方法。

**Result:** 实验表明，基于GRU的预测控制将温度和湿度违规减少了高达5%，并且计算时间比LSTM方法减少了40%，同时保持了相同的经济性能和作物产量。

**Conclusion:** 基于GRU的预测控制为精准农业中的实时温室气候调节提供了一种更高效和实用的解决方案。

> **ai_Abstract:** 本研究提出了一种基于数据驱动的预测控制方法，利用GRU和LSTM神经网络来优化生菜种植中的温室气候调节。研究发现，相比于LSTM，GRU模型在减少温度和湿度违规方面表现出相似的性能，但计算效率更高，减少了40%的计算时间，同时保持了相同的经济效益和作物产量。这表明GRU预测控制是精准农业中温室气候实时调节的有效且实用的方案。

> **摘要翻译:** 随着全球人口的增长，高效的温室管理对于可持续食品生产至关重要。然而，维持最佳室内气候需要大量的能源和资源，这使得先进的控制系统对于经济可行性和环境可持续性至关重要。传统的温室模型通常复杂且不精确，限制了常规控制策略的有效性。为了应对这些挑战，本研究调查了使用门控循环单元（GRU）和长短期记忆（LSTM）神经网络的数据驱动预测控制方法。我们的实验表明，基于GRU的预测控制将温度和湿度违规减少了高达5%，并且计算时间比LSTM方法减少了40%，同时保持了相同的经济性能和作物产量。这些发现表明，基于GRU的预测控制为精准农业中的实时温室气候调节提供了一种更高效和实用的解决方案。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [209] [AVSim -- Realistic Simulation Framework for Airborne and Vector-Borne Disease Dynamics](https://arxiv.org/abs/2502.06212)
> *AVSim -- 空气传播和媒介传播疾病动态的真实模拟框架*

*Pandula Thennakoon, Mario De Silva, M. Mahesha Viduranga, Sashini Liyanage, Roshan Godaliyadda, Mervyn Parakrama Ekanayake, Vijitha Herath, Anuruddhika Rathnayake, Ganga Thilakarathne, Janaka Ekanayake, Samath Dharmarathne* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-30**

**Keywords:** 疾病建模, 基于智能体模拟, 人类移动, GPS轨迹, 空气传播疾病, 媒介传播疾病

**Comment:** 13 pages, 15 figures, submitted to IEEE Transactions on Systems, Man,
  and Cybernetics: Systems

> **TL;DR:** AVSim是一个新的基于智能体的模拟框架，利用真实的GPS数据和行为模式来更准确地模拟空气传播和媒介传播疾病的动态，并能评估干预措施。

**AI_Comments:** AVSim的创新之处在于其结合真实GPS数据和先进的数据分析技术（谱聚类、图论）来克服传统ABM在模拟人类复杂移动和行为方面的不足。这使得其在疾病传播建模上提供了前所未有的真实性和粒度，对于公共卫生干预措施的评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有计算疾病模型在复制真实人类运动方面存在挑战，常导致过度简化和不真实的建模。它们依赖合成假设，未能考虑真实环境结构、交通系统和不同职业群体的行为异质性。

**Method:** 引入AVSim框架，利用来自真实参与者（按职业划分）的GPS轨迹，准确建模人类移动的双重性质（目的地和停留时间）。结合谱聚类和图论分析揭示职业内的潜在行为模式，实现细粒度的智能体行为建模。通过与真实GPS数据验证合成人类移动模式，并用COVID-19和登革热模拟演示其能力。

**Result:** AVSim能够追踪感染路径，识别高风险区域，并评估如疫苗接种、隔离和媒介控制等干预措施，具有职业和地理特异性。

**Conclusion:** AVSim提供了一个更真实、更细致的疾病动态模拟框架，克服了现有模型在人类移动和行为异质性建模方面的局限性，有助于更好地理解和控制传染病。

> **ai_Abstract:** AVSim是一个新颖的基于智能体的模拟框架，旨在解决现有疾病模型在模拟真实人类运动和行为异质性方面的局限性。它通过整合真实的GPS轨迹数据和利用谱聚类与图论分析揭示行为模式，实现了对空气传播和媒介传播疾病动态更精细、更真实的建模。AVSim已通过COVID-19和登革热模拟得到验证，能够有效追踪感染路径、识别高风险区域并评估干预措施的有效性。

> **摘要翻译:** 计算疾病建模在理解和控制传染病传播中发挥着关键作用。虽然基于智能体的模型（ABMs）提供了对个体动态的详细见解，但由于其复杂的多因素性质，准确复制人类运动仍然具有挑战性。大多数现有框架未能模拟真实的人类运动，导致过度简化和不真实的建模。此外，许多当前模型依赖合成假设，未能考虑到真实的环境结构、交通系统以及不同职业群体间的行为异质性。为了解决这些限制，我们引入了AVSim，一个基于智能体的模拟框架，旨在真实条件下模拟空气传播和媒介传播疾病的动态。AVSim的一个显著特点是，它能够通过利用来自真实参与者（按职业划分）的GPS轨迹，准确模拟人类移动的双重性质（个体访问的目的地及其停留时间）。与现有方法相比，这使得人类运动的表示更加精细和真实。此外，谱聚类结合图论分析被用于揭示职业内的潜在行为模式，从而实现智能体行为的细粒度建模。我们针对真实GPS数据验证了合成的人类移动模式，并通过COVID-19和登革热的模拟展示了AVSim的能力。结果突出显示了AVSim追踪感染路径、识别高风险区域以及评估疫苗接种、隔离和媒介控制等干预措施的能力，具有职业和地理特异性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [244] [Minimum Attention Control (MAC) in a Receding Horizon Framework with Applications](https://arxiv.org/abs/2507.20835)
> *最小注意力控制（MAC）在滚动时域框架中的应用*

*Ganesh Teja Theertham, Santhosh Kumar Varanasi, Phanindra Jampana* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-30**

**Keywords:** 最小注意力控制, 滚动时域, 稀疏控制, 模型预测控制, 零范数

**Comment:** 21 pages, 12 figures

> **TL;DR:** 本文提出了一种在滚动时域框架下结合零范数约束和阶段成本的最小注意力模型预测控制（MAMPC）算法，旨在实现稀疏控制动作，但跟踪误差存在权衡。

**AI_Comments:** 这篇论文的创新点在于将最小注意力控制（MAC）与滚动时域框架相结合，并利用零范数约束来实现稀疏控制。通过交替最小化算法求解，其内层具有解析解，这可能提高了算法的计算效率。然而，稀疏控制动作与跟踪误差之间的权衡是该方法的一个重要考量点。

<details>
  <summary>Details</summary>

**Motivation:** 最小注意力控制（MAC）旨在通过提供最小的输入变化来满足控制目标。本文的动机是将MAC技术与滚动时域框架结合，并通过引入零范数约束和阶段成本来解决优化问题，以实现稀疏的控制动作。

**Method:** 本研究将输入变化的零范数约束与阶段成本结合，在滚动时域框架中进行参考跟踪。在当前时域的优化问题中，考虑了前一时域的最优输入。采用交替最小化算法（MAMPC）来求解该优化问题，其中外层是二次规划，内层（解决稀疏性）具有解析解。该算法在四罐系统和燃料电池堆上进行了案例研究，并与标准MPC进行了详细比较。

**Result:** 提出的最小注意力模型预测控制（MAMPC）算法在案例研究中表现出稀疏的控制动作，但与跟踪误差之间存在权衡。

**Conclusion:** 所提出的MAMPC算法能够实现稀疏的控制动作，但需要权衡跟踪误差。

> **ai_Abstract:** 本文提出了一种最小注意力模型预测控制（MAMPC）算法，该算法在滚动时域框架下结合了输入变化的零范数约束和阶段成本，旨在实现稀疏的控制动作。该算法通过交替最小化求解，其中外层为二次规划，内层具有解析解。在四罐系统和燃料电池堆上的应用表明，MAMPC能够产生稀疏的控制动作，但与跟踪误差之间存在权衡。

> **摘要翻译:** 最小注意力控制（MAC）是一种控制技术，它提供最小的输入变化以满足控制目标。在数学上，输入变化的零范数被用作给定控制目标的约束，并相对于过程动力学进行最小化。在本文中，除了零范数约束之外，还在滚动时域框架中考虑了阶段成本用于参考跟踪。为此，在当前时域的优化问题中也考虑了前一时域的最优输入。采用交替最小化算法来解决该优化问题（最小注意力模型预测控制（MAMPC））。优化的外层是二次规划，而内层（解决稀疏性）具有解析解。所提出的算法在两个案例研究中得到了实现：一个具有慢动力学的四罐系统和一个具有快动力学的燃料电池堆。所提出的算法与标准MPC的详细比较研究表明，其控制动作稀疏，但在跟踪误差方面存在权衡。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [259] [Analytical Treatment of Hollow Toroid Flux Tubes](https://arxiv.org/abs/2507.21702)
> *空心环形磁通管的解析处理*

*Herbert Schmidt* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 磁通管, 解析处理, 轴对称几何, 空心环形, 磁场建模

**Comment:** 10 pages, 9 figures, 1 table, accepted for publication at the 16th
  International Modelica & fmi Conference

> **TL;DR:** 本文讨论了空心环形磁通管的解析表达式，并将其结果与现有基于平面磁通管的模型进行比较。

**AI_Comments:** 这项研究通过引入更精确的轴对称几何模型来分析磁通管，可能为磁场建模提供更准确的理论基础，尤其是在需要高精度分析的领域。其创新点在于超越了传统的平面近似，采用了更接近实际的空心环形几何。

<details>
  <summary>Details</summary>

**Motivation:** 现有的圆柱形磁极周围杂散磁通管模型通常基于平面磁通管，将圆柱周长作为深度，但这是一种简化方法。本文旨在提供更精确的解析表达式来处理实际的轴对称几何。

**Method:** 论文讨论了使用空心环形一小部分的实际轴对称几何的解析表达式，并将其结果与现有（已接受的）方法进行比较。

**Result:** 论文比较了新提出的解析表达式与现有方法的模型结果。具体比较结果未在摘要中提及。

**Conclusion:** 本文旨在提出并比较一种基于实际轴对称几何的磁通管分析方法与现有方法。

> **ai_Abstract:** 本文提出了一种分析处理空心环形磁通管的新方法。与现有将圆柱周长作为深度的平面磁通管模型不同，该研究利用实际的轴对称几何，推导了解析表达式，并将其结果与传统方法进行对比。

> **摘要翻译:** 圆柱形磁极周围的杂散磁通管通常从平面磁通管的结果开始建模，将圆柱的周长作为深度。虽然这是一种经过验证的方法，但我们在此讨论使用空心环形一小部分的实际轴对称几何的解析表达式，并将其结果与公认的方法进行比较。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [312] [The impact of large-scale EV charging on the real-time operation of distribution systems: A comprehensive review](https://arxiv.org/abs/2507.21759)
> *大规模电动汽车充电对配电系统实时运行的影响：一项全面综述*

*Zhe Yu, Chuang Yang, Qin Wang* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 电动汽车充电, 配电系统, 实时运行, 智能电网, 管理策略

**Comment:** 

> **TL;DR:** 本文综述了大规模电动汽车充电对配电系统实时运行的负面影响，并探讨了如何通过实时管理策略将其转化为积极贡献，同时深入分析了实时管理系统。

**AI_Comments:** 这是一篇重要的综述性文章，它不仅指出了大规模电动汽车充电对电网的潜在负面影响，更强调了通过智能管理将挑战转化为机遇的可能性。其创新之处在于从双重角色（负荷与储能）的角度审视电动汽车，并聚焦于实时管理策略的分析，这对于未来智能电网的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大规模电动汽车（EVs）的集成给配电网的实时运行带来了不确定性，可能加剧负荷波动、损害电能质量并威胁电网稳定性和安全性。然而，电动汽车作为可控负荷和储能设备，也具备缓解波动、平衡可再生能源波动性并提供辅助服务以支持电网稳定的潜力。

**Method:** 本文通过一项全面综述，探讨了电动汽车充电对配电系统实时运行的负面影响，并概述了将这些挑战转化为积极贡献的方法。此外，还深入分析了电动汽车充电的实时管理系统，重点关注状态估计和管理策略。

**Result:** 本文探讨了电动汽车充电对配电系统实时运行的负面影响，并提出了通过有效实时管理策略将其转化为有利结果的方法。同时，对电动汽车充电的实时管理系统进行了深入分析，特别是状态估计和管理策略。

**Conclusion:** 电动汽车大规模集成对配电系统实时运行构成挑战，但通过有效的实时管理策略，其负面影响可以最小化并转化为积极贡献，从而支持电网稳定和安全。

> **ai_Abstract:** 本文全面综述了大规模电动汽车充电对配电系统实时运行的影响。研究指出，电动汽车充电的不可预测性可能导致负荷波动、电能质量下降和电网稳定性风险。但同时强调，电动汽车作为可控负荷和储能设备，通过智能电网中的实时管理策略，其负面影响可被最小化并转化为积极贡献，如缓解波动和提供辅助服务。文章深入分析了电动汽车充电的实时管理系统，特别是状态估计和管理策略。

> **摘要翻译:** 随着电动汽车（EVs）大规模集成到配电网中，电动汽车充电的不可预测性给电网的实时运行带来了相当大的不确定性。这可能加剧负荷波动，损害电能质量，并对电网的稳定性和安全性构成风险。然而，由于电动汽车作为可控负荷和储能设备的双重作用，它们有潜力缓解这些波动，平衡可再生能源的波动性，并提供支持电网稳定的辅助服务。通过利用智能电网中信息和能量的双向流动，电动汽车充电的不利影响可以通过有效的实时管理策略降至最低，甚至转化为有利的结果。本文探讨了电动汽车充电对配电系统实时运行的负面影响，并概述了将这些挑战转化为积极贡献的方法。此外，本文还深入分析了电动汽车充电的实时管理系统，重点关注状态估计和管理策略。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [358] [Receding Hamiltonian-Informed Optimal Neural Control and State Estimation for Closed-Loop Dynamical Systems](https://arxiv.org/abs/2411.01297)
> *闭环动力系统的后退哈密顿信息最优神经控制与状态估计*

*Josue N. Rivera, Dengfeng Sun* | **Category: eess.SY, cs.AI, cs.ET, cs.LG, cs.RO, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 最优神经控制, 哈密顿信息, 模型预测控制, 动力系统, 神经网络

**Comment:** 27 pages. Source code: https://github.com/wzjoriv/Hion

> **TL;DR:** 本文提出了Hion控制器，一种基于神经网络的新型控制器，用于动力系统和显式非线性模型预测控制，通过结合庞特里亚金最大原理和T-mano架构，实现了卓越的优化和跟踪能力。

**AI_Comments:** 该论文提出了一种新颖的Hion控制器，将神经网络与庞特里亚金最大原理相结合，用于解决动力系统中的最优控制问题。其创新点在于通过T-mano架构实现了定制的瞬态行为和闭环反馈，并展示了优于传统MPC的性能，这对于复杂动态系统的控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在定制瞬态行为、预测控制和闭环反馈方面存在局限性，本文旨在解决这些问题。

**Method:** 本文提出了哈密顿信息最优神经（Hion）控制器，这是一种基于神经网络的控制器，用于动力系统和显式非线性模型预测控制。该框架结合了庞特里亚金最大原理来估计未来状态和制定最优控制策略，并采用了Taylored Multi-Faceted Approach for Neural ODE and Optimal Control (T-mano) 架构。

**Result:** 与现有模型预测控制器进行比较分析，结果显示Hion控制器在最优性和跟踪能力方面表现出优越性。此外，本文还展示了针对线性和非线性动力系统的最优控制策略。

**Conclusion:** Hion控制器作为一种新型的神经网络控制器，结合了庞特里亚金最大原理和T-mano架构，能够为动力系统提供卓越的优化和跟踪能力，并实现定制的瞬态行为、预测控制和闭环反馈。

> **ai_Abstract:** 本文引入并形式化了Hion控制器，这是一种基于神经网络的新型控制器，专为动力系统和显式非线性模型预测控制设计。Hion控制器利用庞特里亚金最大原理预测未来状态并制定最优控制策略，并结合了T-mano架构以实现定制的瞬态行为、预测控制和闭环反馈。实验结果表明，与现有方法相比，Hion控制器在最优性和跟踪能力上表现出显著优势。

> **摘要翻译:** 本文将哈密顿信息最优神经（Hion）控制器形式化，这是一种用于动力系统和显式非线性模型预测控制的新型神经网络控制器。Hion控制器利用庞特里亚金最大原理估计未来状态并制定最优控制策略。所提出的框架，连同我们的神经ODE和最优控制定制多方面方法（T-mano）架构，允许定制瞬态行为、预测控制和闭环反馈，解决了现有方法的局限性。与已建立的模型预测控制器进行比较分析，揭示了Hion控制器卓越的优化和跟踪能力。本文还展示了线性和非线性动力系统的最优控制策略。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [368] [Hierarchical Game-Based Multi-Agent Decision-Making for Autonomous Vehicles](https://arxiv.org/abs/2507.21941)
> *自动驾驶中基于分层博弈的多智能体决策*

*Mushuang Liu, Yan Wan, Frank Lewis, Subramanya Nageshrao, H. Eric Tseng, Dimitar Filev* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 自动驾驶, 分层博弈, 多智能体决策, 交互图, 计算复杂度

**Comment:** 12 pages, 20 figures, 1 algorithm

> **TL;DR:** 本文提出一种新颖的分层博弈框架，用于自动驾驶多智能体决策，通过交互图选择参与者并分解子博弈，显著降低计算复杂度并提高决策效率。

**AI_Comments:** 这篇论文通过引入分层博弈的概念，巧妙地解决了自动驾驶在多智能体场景下决策的计算复杂性问题。其创新点在于交互图的选择性参与者机制和将博弈分解为子博弈，这使得模型在保证决策效率和安全性的同时，能够处理复杂的交通环境。与现有主流方法（如成对博弈）的对比也突出了其优势。

<details>
  <summary>Details</summary>

**Motivation:** 为解决自动驾驶在多智能体场景下的决策问题，并克服现有方法（如标准多玩家博弈和成对博弈）的计算复杂度和效率不足。

**Method:** 提出了一种新颖的基于分层博弈的决策框架，该框架包含一个交互图，用于智能地选择有限数量的交通参与者作为博弈玩家。为进一步降低计算成本，还提出了一种改进的分层博弈，将其分解为一系列子博弈。通过全面的仿真研究，以交叉路口场景为例验证了框架的有效性。

**Result:** 与标准多玩家博弈相比，分层博弈显著降低了计算复杂度。与成对博弈相比，分层博弈能为自动驾驶车辆带来更高效的决策（减少不必要的等待和让行）。仿真研究验证了所提出框架的有效性。

**Conclusion:** 所提出的分层博弈决策框架及其改进版本能够有效解决自动驾驶在多智能体场景下的决策问题，在降低计算复杂度的同时提高决策效率和安全性。

> **ai_Abstract:** 本文提出了一种新颖的分层博弈决策框架，用于自动驾驶在多智能体环境下的决策。该框架利用交互图智能选择博弈参与者，并进一步通过分解子博弈来优化，显著降低了计算复杂度，并提高了自动驾驶车辆的决策效率和安全性，在仿真中展示了其有效性。

> **摘要翻译:** 本文开发了一种用于多智能体场景下自动驾驶的博弈论决策框架。为自动驾驶车辆开发了一种新颖的基于分层博弈的决策框架。该框架具有一个交互图，该图表征了自动驾驶车辆与其周围交通智能体（包括自动驾驶车辆、人类驾驶车辆、行人、自行车等）之间的交互关系，并使自动驾驶车辆能够智能地选择有限数量的智能体作为其博弈玩家。与将所有周围智能体都视为博弈玩家的标准多玩家博弈相比，分层博弈显著降低了计算复杂度。此外，与文献中最流行的成对博弈方法相比，分层博弈为自动驾驶车辆带来了更高效的决策（在减少不必要的等待和让行方面）。为了进一步降低计算成本，我们提出了一种改进的分层博弈，它将分层博弈分解为一系列子博弈。对两种分层博弈的决策安全性和效率进行了分析。进行了全面的仿真研究以验证所提出框架的有效性，并以交叉路口场景作为案例研究。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [410] [Planning Persuasive Trajectories Based on a Leader-Follower Game Model](https://arxiv.org/abs/2507.22022)
> *基于主从博弈模型的说服性轨迹规划*

*Chaozhe R. He, Yichen Dong, Nan Li* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 自动驾驶汽车, 说服性轨迹, 主从博弈, 模型预测控制, 人机交互

**Comment:** To appear at MECC 2025 (https://mecc2025.a2c2.org/)

> **TL;DR:** 该研究提出了一个框架，使自动驾驶汽车能够主动塑造人类驾驶员的意图和行为，通过主从博弈模型预测人类行为，并使用分支MPC算法规划说服性轨迹。

**AI_Comments:** 这项研究的创新之处在于其将主从博弈模型与分支MPC相结合，使自动驾驶汽车能够主动“说服”人类驾驶员，而不仅仅是被动响应。这对于提升自动驾驶汽车在复杂交通环境中的安全性、效率和接受度具有重要意义。该方法通过预测人类意图并主动规划来影响其行为，为人机交互开辟了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 为了使自动驾驶汽车能够主动塑造交互人类驾驶员的意图和行为，以实现更安全、更高效的交通。

**Method:** 该框架采用带有自适应角色机制的主从博弈模型来预测人类交互意图和行为。然后，它利用分支模型预测控制（MPC）算法来规划自动驾驶汽车轨迹，以说服人类采取期望的意图。

**Result:** 仿真结果（在交叉路口场景中）表明，尽管存在不确定性，该框架在生成说服性自动驾驶汽车轨迹方面是有效的。

**Conclusion:** 所提出的框架能够有效地为自动驾驶汽车生成说服性轨迹，从而影响人类驾驶员的意图和行为。

> **ai_Abstract:** 该论文提出了一个创新框架，旨在使自动驾驶汽车能够主动影响人类驾驶员的意图和行为。该框架结合了带有自适应角色机制的主从博弈模型来预测人类行为，并利用分支模型预测控制（MPC）算法来规划具有说服力的AV轨迹。在交叉路口场景的仿真验证了该框架在不确定性下生成有效说服性轨迹的能力。

> **摘要翻译:** 我们提出了一个框架，使自动驾驶汽车（AVs）能够主动塑造交互人类驾驶员的意图和行为。该框架采用带有自适应角色机制的主从博弈模型来预测人类交互意图和行为。然后，它利用分支模型预测控制（MPC）算法来规划自动驾驶汽车轨迹，说服人类采取期望的意图。所提出的框架在交叉路口场景中得到了演示。仿真结果表明，尽管存在不确定性，该框架在生成说服性自动驾驶汽车轨迹方面是有效的。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [430] [Toward Trusted Onboard AI: Advancing Small Satellite Operations using Reinforcement Learning](https://arxiv.org/abs/2507.22198)
> *迈向可信的星载人工智能：利用强化学习推进小型卫星操作*

*Cannon Whitney, Joseph Melville* | **Category: eess.SY, cs.RO, cs.SY, 68T05, I.2.9** | **Updated: 2025-07-29**

**Keywords:** 强化学习, 星载AI, 小型卫星, 命令自动化, 数字孪生

**Comment:** 11 pages, 2 figures, 2 tables, accepted to the 39th Small Satellite
  Conference

> **TL;DR:** 本文开发了一种用于3U立方星命令自动化的强化学习算法，通过数字孪生训练并在隔离环境中验证，以实现可信的星载AI，减少对地面控制的依赖。

**AI_Comments:** 本论文的创新点在于将强化学习应用于实际星载系统的宏观控制自动化，并特别强调了“信任”的建立。与现有研究多限于模拟不同，本文通过构建数字孪生并在隔离环境中进行验证，而非直接授予命令权限，提供了一种安全且可行的在轨验证方法。这对于推进星载AI的实际部署具有重要意义，尤其是在需要高自主性和低延迟的远程空间任务中。其局限性可能在于，虽然验证了算法的有效性，但尚未在实际任务中完全实现其命令权限，未来的研究可能需要进一步探索如何逐步建立和提升对星载AI的信任，直至其能完全自主执行任务。

<details>
  <summary>Details</summary>

**Motivation:** 现有卫星控制的强化学习研究主要限于基于模拟的实验，且对地面控制的依赖性高。本研究旨在开发一种可信的星载AI，以实现更快的响应时间和减少对地面控制的依赖，并为将AI集成到星载系统设定先例。

**Method:** 开发了一种用于3U立方星命令自动化的宏观控制动作强化学习(RL)算法。该算法通过将实时遥测数据编译为观测信息，使星载智能体能够生成高级动作（如调整姿态指向太阳），这些动作随后被转换为控制算法并执行。研究通过构建特定航天器的数字孪生并在此模拟环境中训练RL智能体来发出宏观动作。训练好的智能体策略被复制到一个隔离环境中，接收编译后的卫星信息以进行推理预测，从而在不授予命令权限的情况下验证RL算法在轨的有效性。

**Result:** 成功开发并验证了用于星载命令自动化的强化学习算法。通过在数字孪生环境中训练并在隔离环境中验证，证明了该RL算法在轨的有效性，并能够安全地将其预测与实际卫星行为进行比较，确保在预期参数内运行。

**Conclusion:** 本研究不仅为特定卫星开发了强化学习算法，更重要的是，它为将可信人工智能集成到星载系统设定了先例。通过在隔离环境中验证算法，证明了在不授予命令权限的情况下，实现星载AI的可行性和安全性，为未来自主和远程应用奠定了基础。

> **ai_Abstract:** 本文开发了一种用于3U立方星命令自动化的强化学习（RL）算法，专注于实现宏观控制动作RL。通过将实时遥测数据编译为观测信息，星载智能体能够生成高级动作。研究利用航天器的数字孪生进行RL智能体训练，并在隔离环境中验证其策略，以在不授予命令权限的情况下评估算法在轨的有效性。这项工作旨在减少对地面控制的依赖，提高响应速度，并为将可信AI集成到星载系统设定先例，从而推进小型卫星的自主操作。

> **摘要翻译:** 一篇强化学习（RL）算法被开发用于3U立方星的星载命令自动化。这项工作专注于宏观控制动作RL的实现，这是一种技术，其中星载智能体被提供基于实时遥测编译的信息作为其观测。智能体利用这些信息生成高级动作，例如调整姿态指向太阳，这些动作随后被翻译成控制算法并通过低级指令执行。一旦建立了对星载智能体的信任，就可以利用实时环境信息实现更快的响应时间并减少对地面控制的依赖。该方法不仅侧重于为特定卫星开发RL算法，而且为将可信AI集成到星载系统设定了先例。这项研究建立在以下三个领域先前的基础上：（1）用于发出高级命令并将其转换为低级可执行指令的RL算法；（2）与实时操作系统（特别是星载航天器）接口的AI推理模型的部署；以及（3）在AI系统中建立信任的策略，特别是对于远程和自主应用。现有用于卫星控制的RL研究主要限于基于模拟的实验；在这项工作中，通过构建特定航天器的数字孪生并在该模拟环境中训练RL智能体以发出宏观动作，从而调整了这些技术。训练好的智能体的策略被复制到一个隔离环境中，在那里它被提供编译后的卫星信息以进行推理预测，从而在不授予命令权限的情况下证明了RL算法在轨的有效性。这个过程使得能够安全地将算法的预测与实际卫星行为进行比较，并确保在预期参数内运行。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [462] [Optimal Planning for Enhancing the Resilience of Modern Distribution Systems Against Cyberattacks](https://arxiv.org/abs/2507.22226)
> *现代配电系统抗网络攻击韧性增强的优化规划*

*Armita Khashayardoost, Ahmad Mohammad Saber, Deepa Kundur* | **Category: eess.SY, cs.CR, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 网络攻击, 配电系统, 韧性, 物联网设备, 分布式发电

**Comment:** Accepted Publication

> **TL;DR:** 本研究探讨了物联网设备在智能电网中引入的网络攻击漏洞，特别是在配电层面，攻击者如何利用高功率物联网设备（如电动汽车充电器）操纵局部需求并破坏电网稳定。研究表明传统保护措施不足，并提出利用分布式发电（DGs）增强韧性的策略，强调了配电层面网络韧性规划的紧迫性。

**AI_Comments:** 本文探讨了智能电网中一个日益增长且关键的问题：物联网设备带来的网络攻击漏洞，特别是针对配电层面。其创新之处在于将研究重点从传统的输电层面转移到配电层面，并具体分析了高功率物联网设备被利用的风险。提出的分布式发电（DGs）作为韧性增强策略具有实用价值，突出了预防性规划的重要性。这项研究对于提升现代配电系统的网络安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 智能电网中物联网设备的日益集成在配电层面引入了新的漏洞，特别是网络攻击可能利用高功率物联网设备（如电动汽车充电器）来操纵局部需求并破坏电网稳定。以往研究主要集中在输电层面，因此本研究旨在探讨此类攻击在配电层面的可行性和影响。

**Method:** 本研究调查了网络攻击者如何针对电压敏感节点（特别是暴露于高功耗设备存在的节点）进行攻击，以导致电压偏差和服务中断。为解决传统电网保护措施对智能局部攻击的不足，本文提出了使用分布式发电（DGs）的韧性策略，并探讨了它们在先发制人规划中的作用。

**Result:** 分析表明，传统的电网保护措施不足以应对这些智能的局部攻击。本研究证明了网络攻击者在配电层面利用高功率物联网设备进行攻击的可行性和影响。

**Conclusion:** 本研究强调了在智能电网中进行配电层面网络韧性规划的紧迫性，并提出利用分布式发电（DGs）作为增强韧性的有效策略。

> **ai_Abstract:** 本论文研究了物联网设备在智能电网配电层面引入的网络攻击漏洞，特别关注利用高功率物联网设备（如电动汽车充电器）操纵局部需求并破坏电网稳定的攻击。研究分析了攻击者如何针对电压敏感节点造成电压偏差和服务中断，并指出传统电网保护措施对此类智能局部攻击的不足。为应对此挑战，论文提出利用分布式发电（DGs）的韧性策略，并强调了在智能电网中进行配电层面网络韧性规划的迫切性。

> **摘要翻译:** 智能电网中物联网设备的日益集成在配电层面引入了新的漏洞。特别令人担忧的是，网络攻击可能利用高功率物联网设备，如电动汽车充电器，来操纵局部需求并破坏电网稳定。虽然以往研究主要集中在输电层面的此类攻击，但本文调查了它们在配电层面的可行性和影响。我们研究了网络攻击者如何针对电压敏感节点，特别是那些因高功耗设备存在而暴露的节点，以导致电压偏差和服务中断。我们的分析表明，传统的电网保护措施不足以应对这些智能的局部攻击。为了解决这个问题，我们提出了使用分布式发电（DGs）的韧性策略，探讨它们在先发制人规划中的作用。这项研究强调了智能电网中配电层面网络韧性规划的紧迫性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [504] [Safe and Efficient Data-driven Connected Cruise Control](https://arxiv.org/abs/2507.22227)
> *安全高效的数据驱动互联巡航控制*

*Haosong Xiao, Chaozhe R. He* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 互联巡航控制, V2V通信, 数据驱动, 能源效率, 安全滤波器

**Comment:** To appear at MECC 2025 (https://mecc2025.a2c2.org/)

> **TL;DR:** 本文设计了一种安全高效的数据驱动互联巡航控制系统，利用V2V通信和人类驾驶数据，通过安全滤波器实现节能和安全驾驶，相比非互联系统能耗降低超10%。

**AI_Comments:** 这篇论文的创新点在于结合了数据驱动方法、V2V通信和控制障碍函数来设计互联巡航控制系统，同时兼顾了安全性和能效。其重要性体现在量化了V2V连接在节能方面的潜力，并指出了安全与能效权衡的未来研究方向，对互联自动驾驶技术的发展具有实际指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 为互联自动驾驶车辆设计一种安全高效的巡航控制系统，该系统能够利用来自前方多辆车的运动信息，平稳应对交通扰动并最大化能源效率。

**Method:** 通过车-车（V2V）通信获取前方多辆车的运动信息，并系统地利用从人类驾驶车辆链收集的位置和速度数据。设计了一个互联巡航控制器，该控制器能平稳响应交通扰动同时最大化能源效率。通过控制障碍函数导出的安全滤波器提供安全保障。

**Result:** 对所提出的控制设计在真实交通数据集上的能源性能进行了研究，并量化了安全滤波器对能源的影响。结果表明，与标准非互联自适应巡航控制相比，优化利用V2V连接可将能耗降低10%以上。

**Conclusion:** 优化利用V2V连接可以显著降低互联自动驾驶车辆的能耗，同时通过安全滤波器提供安全保障。研究还揭示了安全滤波器与能效设计之间有趣的相互作用，指明了未来的研究方向。

> **ai_Abstract:** 本文提出了一种针对互联自动驾驶车辆的安全高效数据驱动巡航控制系统。该系统利用V2V通信获取前方车辆运动数据，并结合人类驾驶数据设计控制器，以实现平稳的交通响应和最大化能效。通过引入基于控制障碍函数的安全滤波器确保驾驶安全。实验结果表明，与非互联系统相比，利用V2V连接可显著降低能耗超过10%，并揭示了安全与能效设计间的相互作用。

> **摘要翻译:** 在本文中，我们为互联自动驾驶车辆设计了一种安全高效的巡航控制系统，该系统通过车-车（V2V）通信获取前方多辆车的运动信息。系统地利用从一系列人类驾驶车辆收集到的位置和速度数据，设计了一个互联巡航控制器，该控制器能够平稳地响应交通扰动，同时最大化能源效率。一个源自控制障碍函数的安全滤波器提供了安全保障。我们研究了所提出的控制设计在真实交通数据集上的能源性能，并量化了安全滤波器对能源的影响。结果表明，与标准非互联自适应巡航控制相比，优化利用V2V连接可将能耗降低10%以上。同时，突出了安全滤波器与能源效率设计之间有趣的相互作用，揭示了未来的研究方向。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [525] [Design and Experimental Validation of UAV Swarm-Based Phased Arrays with MagSafe- and LEGO-Inspired RF Connectors](https://arxiv.org/abs/2507.22295)
> *基于无人机蜂群的相控阵设计与实验验证：采用MagSafe和乐高启发式射频连接器*

*Bidya Debnath, Mst Mostary Begum, Prashant Neupant, Brooke E. Molen, Junming Diao* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-30**

**Keywords:** 无人机蜂群, 相控阵, 射频连接器, MagSafe, 乐高

**Comment:** 

> **TL;DR:** 本文提出了一种基于无人机蜂群的相控阵天线系统，利用MagSafe和乐高启发式射频连接器解决分布式相控阵中的同步、定位和相位一致性等挑战，实现了低损耗连接、可扩展性和鲁棒的波束控制，适用于下一代空中通信和雷达应用。

**AI_Comments:** 该论文的创新点在于将消费电子产品（MagSafe和乐高）的设计理念巧妙地应用于高精度射频连接器，解决了无人机蜂群分布式相控阵在飞行中对接和信号传输的关键技术难题。这种非传统的方法极大地简化了复杂系统的集成，提高了系统的实用性和部署效率。其可扩展性设计也预示着在未来机载通信和遥感领域具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 解决分布式相控阵中存在的关键挑战，包括单元间振荡器同步、定位、相位一致性和位置精度问题。

**Method:** 提出了一种新型的基于无人机蜂群的相控阵天线系统，其核心是利用MagSafe和乐高启发式的非螺纹、免手持射频连接器，实现在飞行中对接时精确的单元间距和连续、低损耗的射频信号传播路径。该射频连接器经过多阶段优化，实现了紧凑的尺寸、DC到射频带宽和低至0.2 dB的插入损耗。系统架构通过调整每架无人机上的阵列单元密度和无人机尺寸，提供了增益和频率上的可扩展性。

**Result:** 射频连接器实现了紧凑的外形、DC到射频的带宽，以及低至0.2 dB的测量插入损耗。两架基于无人机的相控阵原型在静止和飞行测试中的实验结果与仿真结果高度吻合，证明了鲁棒的多方向波束控制能力。

**Conclusion:** 这项工作提供了一个实用、可扩展、低复杂度的平台，能够为下一代机载通信、雷达和遥感应用实现快速部署。

> **ai_Abstract:** 本文介绍了一种创新的无人机蜂群相控阵天线系统，其核心在于采用受MagSafe和乐高启发的射频连接器。这些非螺纹、免手持连接器解决了分布式相控阵在同步、定位和相位一致性方面的难题，实现了飞行中精确对接和低损耗信号传输。连接器经过优化，体积小巧，带宽宽，插入损耗低。该系统设计具有增益和频率的可扩展性。实验验证表明，原型系统在静态和动态测试中均能实现鲁棒的波束控制，为下一代空中通信、雷达和遥感提供了实用、可扩展且低复杂度的解决方案。

> **摘要翻译:** 本文提出了一种新型的基于无人机蜂群的相控阵天线系统，该系统利用MagSafe和乐高启发式的射频（RF）连接器来解决分布式相控阵中的关键挑战，包括单元间振荡器同步、定位、相位一致性和位置精度。所提出的非螺纹、免手持连接器实现了精确的单元间距，并在飞行中对接期间建立了连续、低损耗的射频信号传播路径。射频连接器的多阶段优化实现了紧凑的外形、DC到射频的带宽，以及低至0.2 dB的测量插入损耗。该系统架构通过调整每架无人机上的阵列单元密度和无人机尺寸，提供了增益和频率上的可扩展性。两架基于无人机的相控阵原型在静止和飞行测试中的实验结果与仿真结果高度吻合，证明了鲁棒的多方向波束控制能力。这项工作提供了一个实用、可扩展、低复杂度的平台，能够为下一代机载通信、雷达和遥感应用实现快速部署。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [553] [Assessing Value of Renewable-based VPP Versus Electrical Storage: Multi-market Participation Under Different Scheduling Regimes and Uncertainties](https://arxiv.org/abs/2507.22496)
> *评估可再生能源虚拟电厂与储能的价值：不同调度机制和不确定性下的多市场参与*

*Hadi Nemati, Ignacio Egido, Pedro Sánchez-Martín, Álvaro Ortega* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-30**

**Keywords:** 虚拟电厂, 储能系统, 市场参与, 鲁棒优化, 不确定性

**Comment:** 

> **TL;DR:** 本文比较了可再生能源虚拟电厂（RVPP）和电网级储能系统（ESS）在能源和备用市场中的表现、策略和经济效益，并通过鲁棒优化和模拟提供了量化指导。

**AI_Comments:** 本文的创新点在于对可再生能源虚拟电厂（RVPP）和电网级储储能系统（ESS）在多市场参与下的价值进行了公平且量化的比较。通过引入两阶段鲁棒优化框架来处理多种不确定性，并提出ESS尺寸优化算法，提升了研究的严谨性和实用性。这对于能源市场运营商在投资和策略制定方面具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在公平比较可再生能源虚拟电厂（RVPP）和电网级储能系统（ESS）在能源和备用市场中的参与，评估它们的技术性能、市场策略和经济成果，并为运营商提供关于两者相对价值的定量指导。

**Method:** 研究采用了两阶段鲁棒优化框架，其中RVPP模型处理价格、发电和需求不确定性，而ESS模型仅考虑价格不确定性。此外，还提出了一个算法来确定ESS的规模，以使其市场表现与RVPP匹配。模拟涵盖了有利和不利情景，反映了可调度资源的季节性能源限制、不可调度资源的预测误差以及替代不确定性管理策略。

**Result:** 研究结果为运营商提供了关于可再生能源虚拟电厂和电网级储能系统两种方法相对价值的定量指导。

**Conclusion:** 研究通过对可再生能源虚拟电厂和电网级储能系统在多市场参与下的表现进行公平比较和量化分析，为运营商在评估两者相对价值时提供了决策依据。

> **ai_Abstract:** 本研究旨在公平比较可再生能源虚拟电厂（RVPP）和电网级储能系统（ESS）在能源和备用市场中的性能。通过在代表性样本日建模不确定性并采用两阶段鲁棒优化框架，文章评估了它们的技术、市场和经济表现。RVPP模型考虑了价格、发电和需求不确定性，而ESS模型仅考虑价格不确定性。研究还提出了一种ESS规模确定算法，以匹配RVPP的市场表现。模拟涵盖了多种情景，最终为运营商提供了关于这两种方法相对价值的定量指导。

> **摘要翻译:** 本文比较了仅基于可再生能源的虚拟电厂（RVPP）和电网级储能系统（ESS）在能源和备用市场中的参与情况，评估了它们的技术性能、市场策略和经济成果。为了确保公平比较，调度分析是在代表性样本日进行的，这些样本日捕捉了季节性运行机制，并明确建模了相关的不确定性。采用了两阶段鲁棒优化框架：RVPP模型处理价格、发电和需求不确定性，而ESS模型仅考虑价格不确定性。此外，还提出了一种用于确定ESS规模的算法，以使其市场表现与RVPP匹配。模拟涵盖了有利和不利情景，反映了可调度资源的季节性能源限制、不可调度资源的预测误差以及替代不确定性管理策略。结果为运营商提供了关于每种方法相对价值的定量指导。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [581] [Safe Deployment of Offline Reinforcement Learning via Input Convex Action Correction](https://arxiv.org/abs/2507.22640)
> *离线强化学习通过输入凸作用校正的安全部署*

*Alex Durkin, Jasper Stolte, Matthew Jones, Raghuraman Pitchumani, Bei Li, Christian Michler, Mehmet Mercangöz* | **Category: eess.SY, cs.AI, cs.LG, cs.SY, stat.ML** | **Updated: 2025-07-30**

**Keywords:** 离线强化学习, 动作校正, 输入凸神经网络, 化学过程控制, 安全部署

**Comment:** 

> **TL;DR:** 本文提出一种基于输入凸神经网络的部署时安全层，用于校正离线强化学习在化学反应器控制中的动作，以提高安全性和性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个部署时安全层，通过输入凸神经网络（PICNNs）实现对离线RL动作的实时凸优化校正，有效解决了离线RL在实际部署中面临的稳态偏移和安全性问题。这种方法无需再训练且不依赖于环境交互，使其在工业高风险场景中具有很高的实用价值和可解释性。它为离线RL在安全关键系统中的应用铺平了道路。

<details>
  <summary>Details</summary>

**Motivation:** 离线强化学习在化学过程控制中具有潜力，但在线实验风险高、成本大。离线RL面临稳态偏移和接近设定点性能下降的挑战，需要解决安全部署问题。

**Method:** 开发了一个与Gymnasium兼容的放热聚合连续搅拌釜反应器模拟环境，包含非线性动力学和操作约束，并生成了离线数据集。评估了行为克隆和隐式Q学习作为基线。提出了一种新颖的部署时安全层，利用输入凸神经网络（PICNNs）作为学习成本模型，通过梯度下降在凸的、状态条件成本面上进行实时、可微分的动作校正，无需再训练或环境交互。

**Result:** 实验结果表明，离线强化学习（特别是结合凸动作校正）可以优于传统控制方法，并在所有场景中保持稳定性。

**Conclusion:** 结果证明了将离线强化学习与可解释且安全感知的校正相结合，应用于高风险化学过程控制的可行性，并为工业系统中更可靠的数据驱动自动化奠定了基础。

> **ai_Abstract:** 本文探讨了离线强化学习在放热聚合反应器安全高效控制中的应用。研究人员构建了一个模拟环境和离线数据集，并评估了基线离线RL算法所面临的挑战。为解决这些问题，提出了一种基于输入凸神经网络的部署时安全层，该层能够实时、可微分地校正RL策略的动作，从而提高了控制性能和稳定性。实验证明，结合此安全层，离线RL在化学过程控制中表现优异，为工业自动化提供了新的安全可靠的数据驱动方法。

> **摘要翻译:** 离线强化学习（offline RL）提供了一个有前景的框架，可利用历史数据开发化学过程系统的控制策略，而无需在线实验的风险或成本。本工作研究了离线强化学习在放热聚合连续搅拌釜反应器安全高效控制中的应用。我们引入了一个与Gymnasium兼容的模拟环境，该环境捕捉了反应器的非线性动力学，包括反应动力学、能量平衡和操作约束。该环境支持三种工业相关的场景：启动、降级和升级。它还包括通过随机调整的比例积分控制器生成的、可重现的离线数据集，为评估现实过程控制任务中的离线强化学习算法提供了基准。
我们评估了行为克隆和隐式Q学习作为基线算法，突出了离线智能体面临的挑战，包括稳态偏移和接近设定点时性能下降。为了解决这些问题，我们提出了一种新颖的部署时安全层，该层利用输入凸神经网络（PICNNs）作为学习成本模型，执行基于梯度的动作校正。PICNN通过在凸的、状态条件成本面上进行下降，实现策略动作的实时、可微分校正，无需再训练或环境交互。
实验结果表明，离线强化学习，特别是与凸动作校正结合时，可以优于传统控制方法并在所有场景中保持稳定性。这些发现证明了将离线强化学习与可解释且安全感知的校正相结合，应用于高风险化学过程控制的可行性，并为工业系统中更可靠的数据驱动自动化奠定了基础。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [609] [Distributed Average Consensus in Wireless Multi-Agent Systems with Over-the-Air Aggregation](https://arxiv.org/abs/2507.22648)
> *无线多智能体系统中基于空中聚合的分布式平均一致性*

*Themistoklis Charalambous, Zheng Chen, Christoforos N. Hadjicostis* | **Category: eess.SY, cs.SY, eess.SP** | **Updated: 2025-07-30**

**Keywords:** 分布式平均一致性, 无线多智能体系统, 空中聚合, 比率一致性算法, 信号叠加

**Comment:** 5 pages T. Charalambous, Z. Chen and C. N. Hadjicostis, "Distributed
  Average Consensus in Wireless Multi-Agent Systems with Over-the-Air
  Aggregation," 2024 IEEE 25th International Workshop on Signal Processing
  Advances in Wireless Communications (SPAWC), Lucca, Italy, 2024, pp. 441-445

> **TL;DR:** 本文提出了一种利用无线信道信号叠加特性，通过空中聚合实现无线多智能体系统分布式平均一致性的算法，并在噪声可忽略的情况下证明了其收敛性。

**AI_Comments:** 该论文的创新点在于将空中聚合（over-the-air aggregation）的概念引入到分布式平均一致性算法中，利用了无线信道的物理层特性，可能提高了通信效率。通过修改经典的比率一致性算法并增加归一化步骤来处理信道系数，显示了其在实际无线环境下的鲁棒性考虑。其局限性可能在于对噪声水平的要求，即“噪声可忽略”的假设。

<details>
  <summary>Details</summary>

**Motivation:** 解决无线网络中多智能体系统的平均一致性问题。

**Method:** 提出了一种分布式平均一致性算法，该算法利用无线多址信道的信号叠加特性进行空中聚合。该算法部署了知名比率一致性算法的修改版本，并增加了额外的归一化步骤以补偿任意信道系数。

**Result:** 在接收端噪声水平可忽略不计的情况下，该算法对于时不变和时变信道均渐近收敛到平均值。数值模拟证实了结果的有效性。

**Conclusion:** 在无线多智能体系统中，通过空中聚合实现的分布式平均一致性算法在低噪声环境下能够有效收敛。

> **ai_Abstract:** 本文提出了一种用于无线多智能体系统的分布式平均一致性算法。该算法利用无线多址信道的空中聚合特性，通过修改的比率一致性算法并加入归一化步骤来处理信道系数。研究表明，在接收端噪声水平可忽略的情况下，该算法对于时不变和时变信道都能渐近收敛到平均值，并通过数值模拟验证了其有效性。

> **摘要翻译:** 本文解决了无线网络中多智能体系统的平均一致性问题。我们通过引入空中聚合的概念，提出了一种分布式平均一致性算法，该概念利用了无线多址信道的信号叠加特性。所提出的算法部署了知名比率一致性算法的修改版本，并增加了额外的归一化步骤，以补偿任意信道系数。我们表明，当接收端噪声水平可忽略不计，该算法对于时不变和时变信道均渐近收敛到平均值。数值模拟证实了我们结果的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [637] [Malleability-Resistant Encrypted Control System with Disturbance Compensation and Real-Time Attack Detection](https://arxiv.org/abs/2507.22693)
> *具有扰动补偿和实时攻击检测的抗可塑性加密控制系统*

*Naoki Aizawa, Keita Emura, Kiminao Kogiso* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-30**

**Keywords:** 加密控制系统, PID控制器, 扰动观测器, 密钥同态加密, 可塑性攻击检测

**Comment:** 

> **TL;DR:** 本研究提出了一种基于密钥同态加密的加密PID控制系统，结合扰动观测器，以提高控制性能并抵抗基于可塑性的攻击，同时实现实时攻击检测。

**AI_Comments:** 该论文的创新点在于将扰动观测器与密钥同态加密相结合，解决了加密控制系统中性能和安全性的双重挑战。实时攻击检测机制的引入进一步增强了系统的鲁棒性。实验验证部分也增加了研究的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决加密控制系统中的可塑性攻击问题，同时提高控制性能并补偿建模不确定性。

**Method:** 本研究提出了一种使用密钥同态加密（KHE）方案的加密PID控制系统，并集成了扰动观测器（DOB）来补偿建模不确定性。系统设计用于在解密或评估过程中密文被篡改时输出错误符号，从而实现实时检测。通过工业线性平台进行了阶段定位控制实验和攻击检测测试。

**Result:** 加密的基于DOB的PID控制器在跟踪精度方面优于传统的加密PID控制器。系统成功检测到两种类型的基于可塑性的攻击：一种使控制系统不稳定，另一种降低其性能。

**Conclusion:** 本研究的主要贡献包括：(i) 实现了基于KHE的加密DOB-PID控制器；(ii) 提高了不确定性下的控制性能；(iii) 实验证明了加密控制系统中的攻击检测能力。

> **ai_Abstract:** 本研究提出了一种基于密钥同态加密的加密PID控制系统，该系统集成了扰动观测器（DOB），旨在提高控制性能、补偿不确定性并抵抗可塑性攻击。系统具备实时攻击检测能力，通过实验验证，在跟踪精度上优于传统加密PID控制器，并成功检测到多种可塑性攻击。

> **摘要翻译:** 本研究提出了一种结合扰动观测器（DOB）的加密PID控制系统，该系统采用密钥同态加密（KHE）方案，旨在在提供抗可塑性攻击能力的同时实现控制性能。该控制器将DOB与PID结构相结合，通过估计和消除外部扰动来补偿建模不确定性。为了增强安全性，系统设计为在解密或评估过程中密文被篡改时输出错误符号，从而实现基于可塑性的信号或参数篡改的实时检测。为了验证所提出的方法，我们使用工业线性平台进行了阶段定位控制实验和攻击检测测试。结果表明，基于DOB的加密PID控制器在跟踪精度方面优于传统的加密PID控制器。此外，该系统成功检测到两种类型的基于可塑性的攻击：一种使控制系统不稳定，另一种降低其性能。本研究的主要贡献是：(i) 实现了基于KHE的加密DOB-PID控制器；(ii) 提高了不确定性下的控制性能；(iii) 实验证明了加密控制系统中的攻击检测能力。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [664] [Foundations for Energy-Aware Zero-Energy Devices: From Energy Sensing to Adaptive Protocols](https://arxiv.org/abs/2507.22740)
> *面向能量感知零能耗设备的基石：从能量感知到自适应协议*

*Onel L. A. López, Mateen Ashraf, Samer Nasser, Gabriel M. de Jesus, Ritesh Kumar Singh, Miltiadis C. Filippou, Jeroen Famaey* | **Category: eess.SY, cs.SY, 94Cxx, C.2.2; C.2.3; B.4.1; B.4.2; B.4.3; H.1.2** | **Updated: 2025-07-30**

**Keywords:** 零能耗设备, 能量感知协议, 物联网, 能量收集, 协议设计

**Comment:** 31 pags, 16 figs, 8 tables. Submitted to IEEE Proceedings of the IEEE

> **TL;DR:** 零能耗设备（ZED）需要能量感知和自适应协议，但现有模型过于简化。本文提供了能量感知ZED协议设计的关键建模组件、权衡和局限性的结构化概述，并提供设计见解和未来研究方向。

**AI_Comments:** 本文的重要性在于它为零能耗设备（ZED）的设计提供了一个全面的、结构化的基础，解决了该领域的一个根本挑战。其创新之处在于识别并剖析了ZED能量建模中被忽视的复杂性，超越了以往过度简化的方法。这对于该领域的研究人员和设计师来说具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 零能耗设备（ZED）依靠收集环境能量运行，其有限且动态的能量预算要求协议具备能量感知和智能自适应能力。然而，现有方法通常过分简化能量信息获取、任务级别可变性和能量存储动态等关键方面，限制了其实用性和可移植性，因此需要更现实的理论模型。

**Method:** 本文通过提供能量感知ZED协议设计中关键建模组件、权衡和局限性的结构化概述来弥补这一空白。具体方法包括剖析能量信息获取方法和成本、描述核心操作任务、分析能量使用模型和存储约束，以及回顾代表性协议策略。此外，本文还提供如何利用能量信息的设计见解和指南，并概述了未来的关键研究方向。

**Result:** 本文提供了能量感知零能耗设备（ZED）协议设计的关键建模组件、权衡和局限性的结构化概述。它详细阐述了能量信息获取、操作任务、能量使用模型和存储约束，并回顾了协议策略，同时提供了设计见解和指南。

**Conclusion:** 本文概述了关键研究方向，旨在为未来的零能耗设备（ZED）激发更高效、更可扩展的协议解决方案。

> **ai_Abstract:** 零能耗设备（ZED）是可持续物联网的关键，但其有限的能量预算要求协议具备能量感知和自适应能力。现有的理论模型往往过分简化能量信息获取和存储动态等关键方面，限制了其实用性。本文旨在弥补这一空白，提供能量感知ZED协议设计的关键建模组件、权衡和局限性的结构化概述。文中详细分析了能量信息获取方法、操作任务、能量使用模型和存储约束，并回顾了相关协议策略。此外，本文还提供了设计见解和指南，并为未来的高效ZED协议解决方案指明了研究方向。

> **摘要翻译:** 零能耗设备（ZED）通过完全依靠收集环境能量运行，是可持续物联网网络的关键推动者。其有限且动态的能量预算要求协议具备能量感知和智能自适应能力。然而，为ZED设计有效的能量感知协议需要能够真实反映设备约束的理论模型。事实上，现有方法经常过分简化能量信息（EI）获取、任务级别可变性和能量存储动态等关键方面，限制了其实用相关性和可移植性。本文通过提供能量感知ZED协议设计中关键建模组件、权衡和局限性的结构化概述来弥补这一空白。为此，我们剖析了EI获取方法和成本，描述了核心操作任务，分析了能量使用模型和存储约束，并回顾了代表性协议策略。此外，我们还提供了关于ZED操作协议如何利用EI的设计见解和指南，这些通常通过精选的内部示例进行说明。最后，我们概述了关键研究方向，以激发未来ZED更高效、更可扩展的协议解决方案。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [692] [Of Good Demons and Bad Angels: Guaranteeing Safe Control under Finite Precision](https://arxiv.org/abs/2507.22760)
> *善魔与恶天使：有限精度下的安全控制保障*

*Samuel Teuber, Debasmita Lohar, Bernhard Beckert* | **Category: eess.SY, cs.AI, cs.LG, cs.LO, cs.SY** | **Updated: 2025-07-30**

**Keywords:** 神经网络, 安全性, 有限精度, 网络物理系统, 混合博弈

**Comment:** 15 pages, 3 figures, 1 table; Accepted at FMCAD 2025

> **TL;DR:** 该论文通过引入有限精度扰动下的鲁棒性，弥合了理论安全保障与神经网络控制网络物理系统实际实现之间的差距，并提出了一个端到端的解决方案，以确保在汽车和航空领域的案例研究中实现高效且严格的无限时间范围安全保证。

**AI_Comments:** 本文的创新之处在于其独特的“善魔与恶天使”混合博弈模型，巧妙地将有限精度扰动纳入安全验证框架。这有效地弥合了理论安全保障与实际系统实现之间的鸿沟，为安全关键型神经网络控制系统提供了更可靠的保障。其提供的端到端解决方案对于实际工程应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着神经网络在安全关键型神经网络控制网络物理系统 (NNCS) 中日益普及，正式保障其安全性变得至关重要。现有的基于微分动态逻辑 (dL) 的验证方法依赖于理想化的实值神经网络语义，未能考虑有限精度实现引入的舍入误差。

**Method:** 本研究通过将有限精度扰动（在感知、执行和计算中）下的鲁棒性纳入安全验证，弥合了理论保障与实际实现之间的差距。问题被建模为善魔（负责控制动作）和恶天使（引入扰动）之间的混合博弈。利用此界限，采用最先进的混合精度定点调谐器来合成健全高效的实现。

**Result:** 该方法在汽车和航空领域的案例研究中进行了评估，产生了高效的神经网络实现，并提供了严格的无限时间范围安全保证。

**Conclusion:** 该论文提供了一个完整的端到端解决方案，用于在考虑有限精度扰动的情况下，为神经网络控制网络物理系统提供严格的无限时间范围安全保障。

> **ai_Abstract:** 该论文解决了神经网络控制网络物理系统 (NNCSs) 在有限精度实现下保障安全性的挑战。针对现有方法未能考虑舍入误差的问题，作者提出了一种新方法，通过将有限精度扰动下的鲁棒性纳入安全验证。该方法将问题建模为“善魔”与“恶天使”之间的混合博弈，并利用先进的混合精度定点调谐器来合成高效且健全的神经网络实现。实验结果表明，该方案能在汽车和航空领域提供严格的无限时间范围安全保证。

> **摘要翻译:** 随着神经网络 (NNs) 在安全关键型神经网络控制网络物理系统 (NNCSs) 中日益普及，正式保障其安全性变得至关重要。对于这些系统，必须在其整个运行过程中确保安全性，这需要无限时间范围的验证。为了验证 NNCSs 的无限时间范围安全性，最近的方法利用微分动态逻辑 (dL)。然而，这些基于 dL 的保障依赖于理想化的实值 NN 语义，未能考虑有限精度实现引入的舍入误差。本文通过将有限精度扰动（在感知、执行和计算中）下的鲁棒性纳入安全验证，弥合了理论保障与实际实现之间的差距。我们将问题建模为善魔（负责控制动作）和恶天使（引入扰动）之间的混合博弈。这种公式化使得能够对给定（有界）扰动进行鲁棒性的正式证明。利用这个界限，我们采用最先进的混合精度定点调谐器来合成健全高效的实现，从而提供一个完整的端到端解决方案。我们在汽车和航空领域的案例研究中评估了我们的方法，产生了高效的神经网络实现，并提供了严格的无限时间范围安全保证。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [721] [Cluster Synchronization and Phase Cohesiveness of Kuramoto Oscillators via Mean-phase Feedback Control and Pacemakers](https://arxiv.org/abs/2507.22778)
> *Kuramoto振子的簇同步与相位内聚性：通过平均相位反馈控制和起搏器实现*

*Ryota Kokubo, Rui Kato, Hideaki Ishii* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-30**

**Keywords:** 簇同步, 相位内聚性, Kuramoto振子, 平均相位反馈, 起搏器

**Comment:** 13 pages, 11 figures

> **TL;DR:** 本文提出了两种控制Kuramoto振子簇同步和相位内聚性的方法：平均相位反馈控制和起搏器，并给出了实现条件和优化方法。

**AI_Comments:** 本文针对Kuramoto振子网络，提出了两种新颖的控制策略（平均相位反馈和起搏器）来实现簇同步和相位内聚性，并结合了凸优化寻找最优参数，具有理论和实际应用价值，尤其在理解和控制脑网络同步模式方面有潜在意义。

<details>
  <summary>Details</summary>

**Motivation:** 脑网络中存在多种同步簇共存的特征同步模式，而神经系统疾病与神经元大群体的病理性过度同步有关。受这些现象启发，本文旨在控制Kuramoto振子的簇同步和簇相位内聚性。

**Method:** 本文提出了两种控制方法：1. 基于将平均相位反馈到簇中；2. 基于使用起搏器。研究了反馈增益和起搏器权重对网络实现簇同步和簇相位内聚性的条件。提出了一种通过凸优化寻找最优反馈增益的方法。

**Result:** 本文给出了反馈增益和起搏器权重使网络实现簇同步的条件，并提出了一种通过凸优化寻找最优反馈增益的方法。同时，也给出了实现簇相位内聚性的条件。数值例子证明了所提方法的有效性。

**Conclusion:** 通过平均相位反馈控制和起搏器，可以有效地控制Kuramoto振子的簇同步和相位内聚性，并且可以通过凸优化找到最优反馈增益。

> **ai_Abstract:** 本文研究了Kuramoto振子的簇同步和相位内聚性控制问题，提出了平均相位反馈控制和起搏器两种方法。论文详细阐述了实现簇同步和簇相位内聚性的反馈增益和起搏器权重条件，并引入了基于凸优化的最优反馈增益寻找方法。数值模拟验证了所提方法的有效性。

> **摘要翻译:** 脑网络通常表现出特征同步模式，其中几个同步簇共存。另一方面，神经系统疾病被认为与病理性同步有关，例如大量神经元的过度同步。受这些现象的启发，本文提出了两种控制Kuramoto振子簇同步和簇相位内聚性的方法。一种是基于将平均相位反馈到簇中，另一种是基于使用起搏器。首先，我们展示了反馈增益和起搏器权重使网络实现簇同步的条件。然后，我们提出了一种通过凸优化寻找最优反馈增益的方法。其次，我们展示了反馈增益和起搏器权重使网络实现簇相位内聚性的条件。一个数值例子证明了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [796] [Kernel Modelling of Fading Memory Systems](https://arxiv.org/abs/2403.11945)
> *衰减记忆系统的核建模*

*Yongkang Huo, Thomas Chaffey, Rodolphe Sepulchre* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-07-29**

**Keywords:** 核建模, 衰减记忆系统, 非线性系统, 系统辨识, 因果关系

**Comment:** 

> **TL;DR:** 本文提出了一种新的基于核的方法，用于识别具有衰减记忆的非线性系统，通过学习从过去输入到当前输出的泛函，从而简化核选择、强制因果关系并实现时间模拟。

**AI_Comments:** 本文的创新之处在于将基于核的框架中对衰减记忆系统的建模从学习作用于轨迹的算子转向学习作用于过去输入的泛函。这种转变简化了实际应用中的核选择等问题，并使得时间模拟成为可能，这对于实际应用具有重要意义。摘要中未提及局限性。

<details>
  <summary>Details</summary>

**Motivation:** 本文是最近引入的基于核的框架的后续研究，该框架用于识别由理想输入-输出增量特性正则化的非线性输入-输出系统。研究动机是为具有衰减记忆的系统改进该框架。

**Method:** 本文提出学习将过去输入映射到当前输出的泛函，而不是将输入轨迹映射到输出轨迹的算子，以识别具有衰减记忆的非线性系统。这项工作是在一个基于核的框架内进行的。

**Result:** 这项修改简化了核的选择，强制了因果关系，并实现了时间模拟，同时保留了先前框架的优势。

**Conclusion:** 本文提出的修改改进了用于衰减记忆系统的基于核的框架，通过简化核选择、强制因果关系和实现时间模拟。

> **ai_Abstract:** 本文扩展了用于识别非线性输入-输出系统的基于核的框架，特别关注具有衰减记忆的系统。它引入了一种新方法，即学习将过去输入映射到当前输出的泛函，而非映射完整轨迹的算子。这种修改带来了多项优势：它简化了核的选择，确保了因果关系，并促进了时间模拟，同时保留了原始框架的优点。

> **摘要翻译:** 本文是最近引入的基于核的框架的后续研究，该框架用于识别由理想的输入-输出增量特性正则化的非线性输入-输出系统。假设系统具有衰减记忆，我们建议学习将过去输入映射到当前输出的泛函，而不是将输入轨迹映射到输出轨迹的算子。在保留先前提出的框架优势的同时，这一修改简化了核的选择，强制了因果关系，并实现了时间模拟。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [852] [Collision Avoidance for Convex Primitives via Differentiable Optimization Based High-Order Control Barrier Functions](https://arxiv.org/abs/2410.19159)
> *凸形基元基于可微分优化的高阶控制障碍函数避碰*

*Shiqing Wei, Rooholla Khorrambakht, Prashanth Krishnamurthy, Vinicius Mariano Gonçalves, Farshad Khorrami* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 控制障碍函数, 避碰, 可微分优化, 高阶控制, 凸形基元

**Comment:** 

> **TL;DR:** 本文提出了一种基于可微分优化的高阶控制障碍函数（HOCBF）框架，用于凸形基元的避碰，解决了传统CBF在处理扭矩控制和意外平衡点方面的挑战，并通过实验验证了其有效性。

**AI_Comments:** 这项工作通过引入可微分优化和高阶CBF，为凸形基元的避碰提供了一种新颖且有效的解决方案，尤其是在处理扭矩控制和虚假平衡点方面具有创新性。循环机制的提出是解决HOCBF实际应用中一个重要限制的关键一步，增强了系统的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 确保动力系统的安全性至关重要，其中避碰是一个主要问题。然而，在处理凸形基元和需要扭矩控制的任务时，以及出现意外平衡点时，传统的控制障碍函数（CBFs）仍面临挑战。

**Method:** 本文通过引入高阶控制障碍函数（HOCBF）框架来解决这些挑战。具体方法包括：1. 通过可微分优化将非凸安全约束转换为线性约束，并证明了高阶连续可微性。2. 使用HOCBFs适应扭矩控制，以实现涉及力和高动态的任务。3. 分析高阶情况下的虚假平衡点问题，并提出一种循环机制来防止安全集边界上出现不期望的平衡点。

**Result:** 通过在Franka Research 3机械臂上进行的三个实验，验证了所提出框架的有效性，成功实现了避碰，并证明了循环机制的有效性。

**Conclusion:** 本文提出的基于可微分优化的高阶控制障碍函数（HOCBF）框架，有效解决了凸形基元避碰中面临的扭矩控制和意外平衡点问题，并通过实验验证了其有效性。

> **ai_Abstract:** 本文提出了一种基于可微分优化的高阶控制障碍函数（HOCBF）框架，用于解决凸形基元在避碰中遇到的挑战，特别是扭矩控制和虚假平衡点问题。该框架通过可微分优化将非凸安全约束线性化，并引入循环机制来避免不期望的平衡点。实验结果在Franka Research 3机械臂上验证了其在避碰和解决虚假平衡点方面的有效性。

> **摘要翻译:** 确保动力系统的安全性至关重要，其中避碰是一个主要问题。最近，控制障碍函数（CBF）已成为一种通过优化技术将安全约束集成到控制合成中的有效方法。然而，在处理凸形基元和需要扭矩控制的任务时，以及出现意外平衡点时，挑战依然存在。这项工作通过引入一种用于凸形基元之间避碰的高阶CBF（HOCBF）框架来应对这些挑战。我们通过可微分优化将非凸安全约束转换为线性约束，并证明了高阶连续可微性。然后，我们采用HOCBFs来适应扭矩控制，从而实现涉及力和高动态的任务。此外，我们分析了高阶情况下的虚假平衡点问题，并提出了一种循环机制来防止安全集边界上出现不期望的平衡点。最后，我们通过在Franka Research 3机械臂上进行的三个实验验证了我们的框架，展示了成功的避碰和循环机制的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [908] [Instantaneous Core Loss -- Cycle-by-cycle Modeling of Power Magnetics in PWM DC-AC Converters](https://arxiv.org/abs/2501.13555)
> *瞬时磁芯损耗——PWM DC-AC变换器中功率磁性元件的逐周期建模*

*Binyu Cui, Jun Wang, Xibo Yuan, Alfonso Martinez, George Slama, Matthew Wilkowski, Ryosuke Ota, Keiji Wada* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-29**

**Keywords:** 瞬时磁芯损耗, PWM DC-AC变换器, 逐周期建模, 功率磁性元件, 时域磁芯损耗

**Comment:** 

> **TL;DR:** 本文提出了“瞬时磁芯损耗”的新概念及其测量与建模方法，旨在实现PWM DC-AC变换器中磁芯损耗的逐周期建模，弥补现有平均模型无法处理主要环路损耗的不足。

**AI_Comments:** 本文的创新之处在于引入了“瞬时磁芯损耗”的概念，并提供了其测量和建模方法，超越了传统的平均模型。这对于PWM DC-AC变换器中功率损耗的精确预测和设计优化具有重要意义，尤其适用于承受复杂激励的磁性元件。

<details>
  <summary>Details</summary>

**Motivation:** 现有的磁芯损耗建模方法（如iGSE或基于CWH的损耗图）虽然对DC-DC变换器有效，但对于PWM DC-AC变换器，由于基频正弦波分量引入的“主要环路损耗”，现有方法无法实现逐开关周期的建模。

**Method:** 本文提出了“瞬时磁芯损耗”这一新颖的基本概念，并首次在实验中观测到时域磁芯损耗。通过扩展无功电压抵消概念，提出了一种测量瞬时磁芯损耗（仅包含实功率损耗）随时间变化的方法。在此基础上，提出了一种建模方法，将文献中通常为平均值的主要环路磁芯损耗分解到时域，从而实现PWM变换器中磁芯损耗的逐周期建模。

**Result:** 通过对软磁元件的测量发现，放电阶段的磁芯损耗高于充电阶段。

**Conclusion:** 这项工作通过从平均模型转向时域模型，增强了对磁芯损耗过程的基本理解，并实现了PWM变换器中磁芯损耗的逐周期建模。

> **ai_Abstract:** 本文针对现有模型无法对PWM DC-AC变换器中主要环路磁芯损耗进行逐周期建模的局限性，提出了“瞬时磁芯损耗”的新概念。通过扩展无功电压抵消方法，开发了一种测量时域瞬时磁芯损耗的方法。实验发现放电阶段的磁芯损耗更高。在此基础上，提出了一种建模方法，将主要环路磁芯损耗分解到时域，从而实现逐周期建模，深化了对磁芯损耗过程的理解。

> **摘要翻译:** 如今，PWM激励是电力电子变换器中磁性元件最常见的波形之一。改进型广义Steinmetz方程（iGSE）或基于复合波形假设（CWH）的损耗图等磁芯损耗建模方法对PWM激励进行分段处理，已被证明对DC-DC变换器有效。然而，作为PWM DC-AC变换器中的额外挑战，基频正弦波分量在分段高频段之上引发了“主要环路损耗”，而现有方法无法以开关周期为基础对其进行建模。为了解决这一空白，本文提出了一个新颖的基本概念——瞬时磁芯损耗，这是历史上首次在实验中观测到的时域磁芯损耗。通过扩展无功电压抵消概念，这项工作提出了一种测量瞬时磁芯损耗（仅包含实功率损耗）随时间变化的方法。基于对所评估软磁元件的测量，发现放电阶段的磁芯损耗高于充电阶段。然后提出了一种建模方法，将文献中通常为平均值的主要环路磁芯损耗分解到时域，从而实现PWM变换器中磁芯损耗的逐周期建模。这项工作通过从平均模型转向时域模型，增强了对磁芯损耗过程的基本理解。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [914] [Simultaneous improvement of control and estimation for battery management systems](https://arxiv.org/abs/2507.21300)
> *电池管理系统控制与估计的同步改进*

*Mohammad S. Ramadan, Marfred Barrera, Mihai Anitescu, Sylvia Herbert* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-28**

**Keywords:** 电池管理系统, 荷电状态, 随机最优控制, 双重控制, 可观测性

**Comment:** 

> **TL;DR:** 本文提出一种随机最优控制方法，通过利用高可观测区域，同时提高电池管理系统的荷电状态控制和估计精度。

**AI_Comments:** 该论文的创新之处在于应用随机最优控制（双重控制）来同时解决电池管理系统中的控制和估计挑战，特别是通过利用可观测性的概念。这种集成方法对于需要精确控制和准确状态知识的实际电池应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 电池系统的荷电状态（SoC）估计是一个重要指标，但由于观测模型的非线性导致可观测性变化，影响估计精度。本文旨在同时实现控制目标并提高估计精度。

**Method:** 采用随机最优控制（也称为双重控制）方法。通过优先选择通过状态空间中高可观测区域的轨迹，隐式地提高未来测量质量，从而同时改善估计精度和满足控制目标。

**Result:** 将该算法应用于多电池系统的数值模拟，结果显示在控制目标和状态估计误差方面均有统计学上的改进。

**Conclusion:** 随机最优控制方法通过利用可观测性，有效提高了电池管理系统中控制目标和状态估计的精度。

> **ai_Abstract:** 本文针对电池荷电状态（SoC）估计中由于观测模型非线性导致的可观测性变化问题，提出了一种随机最优控制（双重控制）方法，旨在同时实现控制目标并提高估计精度。该方法通过引导轨迹通过高可观测区域来隐式提升未来测量质量。在多电池系统数值模拟中的应用表明，该方法在控制性能和状态估计误差方面均取得了统计学上的改进。

> **摘要翻译:** 电池系统的荷电状态是一个重要的指标，通常通过观测模型（由开路电压图表示）进行估计。这些观测模型在荷电状态方面通常是非线性的，导致从状态估计的角度来看可观测性各不相同。在本文中，我们采用了一种随机最优控制（也称为双重控制）方法，以同时满足电池系统荷电状态的控制目标并提高估计精度。这通过优先选择通过状态空间中高可观测区域的轨迹来隐式实现，从而提高未来测量的质量。我们将我们的算法应用于多电池系统的数值模拟，并显示在控制目标和状态估计误差方面都有统计学上的改进。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [18] [On the Feasibility of Distributed Phase Synchronization for Coherent Signal Superposition](https://arxiv.org/abs/2506.22252)
> *分布式相位同步实现相干信号叠加的可行性研究*

*Alphan Sahin* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** 分布式相位同步, 相干信号叠加, 相位编码导频, 载波频率偏移, 空中计算

**Comment:** Accepted for presentation at IEEE PIMRC - Workshop on Integrated,
  Intelligent and Ubiquitous Connectivity for 6G and Beyond

> **TL;DR:** 本文研究了在移动性和硬件损伤下分布式相位同步实现相干信号叠加的可行性，提出相位编码导频（PCPs）方法消除相位变化，并发现残余载波频率偏移是影响相位一致性持续时间的主要因素，同时通过概念验证展示了PCPs的实际可行性。

**AI_Comments:** 本文深入探讨了分布式相位同步在复杂环境下的关键问题，并提出了创新的相位编码导频（PCPs）解决方案，具有重要的理论和实践意义。对残余CFO、移动性和节点数量等影响因素的量化分析，为未来相干通信系统的设计提供了宝贵的指导。概念验证的成功进一步增强了该方法在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 分布式相位同步是相干空中计算（OAC）、分布式波束成形和干扰对齐等范式的基本使能技术，因此需要在移动性和硬件损伤条件下分析其可行性。

**Method:** 研究引入了相位编码导频（PCPs）策略，通过无线电设备相互通信来消除上下行链路中的往返相位变化，以将接收符号的相位对齐到期望角度。此外，考虑载波频率偏移（CFO）鲁棒的多用户程序，推导了相位偏差的统计数据以评估相位一致性退化的速度。还通过使用现成无线电设备进行了相干信号叠加的概念验证演示。

**Result:** 研究结果表明，残余载波频率偏移（CFO）是决定相位一致性持续时间的主要因素，此外移动性和网络中节点数量也有不可忽略的影响。概念验证演示了相位编码导频（PCPs）在实践中的可行性。

**Conclusion:** 本研究分析了分布式相位同步实现相干信号叠加的可行性，引入了相位编码导频（PCPs）作为有效的解决方案，并确定了残余CFO、移动性和节点数量是影响相位一致性的关键因素，同时通过实践演示证实了PCPs的可行性。

> **ai_Abstract:** 本文探讨了在移动性和硬件损伤条件下，分布式相位同步实现相干信号叠加的可行性，该技术对相干空中计算（OAC）等应用至关重要。研究提出了一种名为相位编码导频（PCPs）的新策略，旨在通过消除无线电通信中的往返相位变化来精确对齐接收信号的相位。通过对相位偏差统计数据的推导，研究发现残余载波频率偏移（CFO）是影响相位一致性持续时间的关键因素，同时移动性和网络节点数量也有显著影响。此外，通过实际设备的概念验证演示，验证了PCPs在实践中的有效性和可行性。

> **摘要翻译:** 本研究分析了在移动性和硬件损伤下，分布式相位同步实现相干信号叠加的可行性，这是相干空中计算（OAC）、分布式波束成形和干扰对齐等范式的基本使能技术。针对相干OAC，我们引入了相位编码导频（PCPs）——一种无线电台之间相互通信以消除上行（UL）和下行（DL）往返相位变化，从而将接收符号的相位对齐到期望角度的策略。在本研究中，考虑到载波频率偏移（CFO）鲁棒的多用户程序，我们推导了相位偏差的统计数据，以评估相位一致性退化的速度。我们的结果表明，残余CFO是决定相位一致性持续时间的主要因素，此外移动性和网络中节点数量的影响也不可忽略。我们还通过使用现成无线电设备进行了相干信号叠加的概念验证演示，以证明PCPs在实践中的可行性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [39] [DOA Estimation via Continuous Aperture Arrays: MUSIC and CRLB](https://arxiv.org/abs/2507.21347)
> *基于连续孔径阵列的DOA估计：MUSIC和CRLB*

*Haonan Si, Zhaolin Wang, Xiansheng Guo, Jin Zhang, Yuanwei Liu* | **Category: eess.SP** | **Updated: 2025-07-28**

**Keywords:** DOA估计, 连续孔径阵列, MUSIC算法, CRLB, 空间自由度

**Comment:** Submit to possible IEEE journal

> **TL;DR:** 本文研究了使用连续孔径阵列(CAPA)进行方向到达(DOA)估计，提出了一种新的MUSIC算法来处理CAPA的无限维连续信号。理论和数值结果表明，CAPA能显著提高DOA估计精度，且所提出的MUSIC算法实现了接近最优的性能并保持低计算复杂度。

**AI_Comments:** 这项研究创新性地将MUSIC算法应用于连续孔径阵列，克服了传统算法无法处理无限维连续信号的挑战。通过引入连续-离散变换和高效的近似方法，该工作在理论上证明了CAPA在DOA估计精度上的显著优势，并提出了一个兼顾性能和计算复杂度的实用算法，对于未来阵列信号处理领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的空间离散阵列(SPDA)在DOA估计中存在空间自由度限制，而连续孔径阵列(CAPA)能显著提高空间自由度。然而，CAPA的无限维连续信号使得传统估计算法无法直接应用，因此需要新的算法来解决这一挑战。

**Method:** 1. 提出了一种新的多信号分类(MUSIC)算法用于CAPA。2. 引入了等效的连续-离散变换，以方便连续算子的特征分解。3. 使用高斯-勒让德正交法精确近似MUSIC谱，以降低计算复杂度。4. 分析了CAPA在有无快照信号先验知识情况下的DOA估计Cramér-Rao下界(CRLB)。

**Result:** 1. 理论证明了CAPA相比传统SPDA能显著提高DOA估计精度。2. 数值结果验证了CAPA的优势以及所提出的MUSIC算法的有效性。3. 所提出的方法在保持低计算复杂度的同时，实现了接近最优的估计性能。

**Conclusion:** 连续孔径阵列(CAPA)能够显著提高DOA估计精度，并且本文提出的新型MUSIC算法能够有效应用于CAPA，实现接近最优的估计性能且计算复杂度低。

> **ai_Abstract:** 本文研究了基于连续孔径阵列（CAPA）的方向到达（DOA）估计，旨在解决CAPA无限维连续信号导致传统算法不适用的问题。作者提出了一种新的MUSIC算法，通过连续-离散变换和高斯-勒让德正交法处理连续信号并降低计算复杂度。研究还分析了CAPA的Cramér-Rao下界，并理论和数值证明了CAPA相比传统离散阵列能显著提高DOA估计精度。实验结果表明，所提MUSIC算法对CAPA有效，且在低计算复杂度下能达到接近最优的估计性能。

> **摘要翻译:** 研究了使用连续孔径阵列（CAPA）的方向到达（DOA）估计。与传统的空间离散阵列（SPDA）相比，CAPA显著增强了DOA估计的空间自由度（DoFs），但其无限维连续信号使得传统的估计算法不适用。为了解决这一挑战，本文针对CAPA提出了一种新的多信号分类（MUSIC）算法。具体而言，提出了一种等效的连续-离散变换，以促进连续算子的特征分解。随后，使用高斯-勒让德正交法精确近似MUSIC谱，有效地降低了计算复杂度。此外，还分析了在有和没有快照信号先验知识两种情况下，使用CAPA进行DOA估计的Cramér-Rao下界（CRLBs）。理论证明，与传统的SPDA相比，CAPA显著提高了DOA估计精度。数值结果进一步验证了这一观点，并证明了所提出的CAPA MUSIC算法的有效性。所提出的方法在保持低计算复杂度的同时，实现了接近最优的估计性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [94] [Transmission With Machine Language Tokens: A Paradigm for Task-Oriented Agent Communication](https://arxiv.org/abs/2507.21454)
> *采用机器语言令牌的传输：一种面向任务的智能体通信范式*

*Zhuoran Xiao, Chenhui Ye, Yijia Feng, Yunbo Hu, Tianyu Jiao, Liyu Cai, Guangyi Liu* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** 机器语言令牌, 智能体通信, 面向任务, 联合编码, 大语言模型

**Comment:** Accepted by IEEE Globecom 2025

> **TL;DR:** 本文提出了一种面向任务的智能体通信系统，利用大语言模型学习机器语言令牌，并通过联合令牌与信道编码方案，显著降低传输开销并提高通信准确性。

**AI_Comments:** 本文的创新点在于提出了一个AI原生的智能体通信范式，核心是利用LLM生成和处理机器语言令牌，而非传统的人类语言，这对于提升智能体间通信的效率和优化是至关重要的。此外，引入的联合令牌与信道编码（JTCC）方案进一步优化了传输效率和抗噪能力，显示了其在实际应用中的潜力。该研究对于构建未来高效、智能的AI驱动通信系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大基础模型的快速发展，未来的生产过程将主要由智能体参与，这需要一种新颖的、为智能体通信量身定制的AI原生通信系统。然而，现有大语言模型（LLM）的输出是人类语言，这对于智能体类型的通信来说具有高度限制且非最优。

**Method:** 本文提出了一种面向任务的智能体通信系统。具体而言，该系统利用原始LLM学习由令牌嵌入表示的专用机器语言。同时，训练多模态LLM以理解应用任务并从多模态输入中提取必要的隐含信息，然后使用机器语言令牌表达。此外，为了减少传输开销，引入了一种联合令牌和信道编码（JTCC）方案，该方案通过利用令牌序列的稀疏性来压缩令牌序列，同时增强对信道噪声的鲁棒性。

**Result:** 广泛的实验表明，与SOTA方法相比，所提出的方法降低了下游任务的传输开销，同时提高了准确性。

**Conclusion:** 本文提出的面向任务的智能体通信系统，通过学习和利用机器语言令牌以及创新的联合令牌与信道编码方案，能够有效降低通信开销并提升准确性，为未来智能体间的AI原生通信提供了高效可行的范式。

> **ai_Abstract:** 本文针对未来智能体主导的生产过程对AI原生通信系统的需求，提出了一种创新性的面向任务的智能体通信系统。该系统利用大语言模型学习专用的机器语言令牌，并通过多模态LLM处理多模态输入并以机器语言令牌形式表达。为进一步优化传输效率和鲁棒性，引入了联合令牌与信道编码（JTCC）方案。实验证明，该方法能有效降低传输开销并提高通信准确性。

> **摘要翻译:** 大基础模型的快速发展正在推动各行各业的范式转变。一个重要的变化是，未来的生产过程中，智能体将取代传统机器或人类成为主要参与者，这因此需要一种新颖的、为智能体通信量身定制的AI原生通信系统。将大语言模型（LLM）的能力与面向任务的语义通信相结合是一种潜在的方法。然而，现有LLM的输出是人类语言，这对于智能体类型的通信来说具有高度限制且非最优。在本文中，我们创新性地提出了一种面向任务的智能体通信系统。具体而言，我们利用原始LLM学习由令牌嵌入表示的专用机器语言。同时，训练多模态LLM以理解应用任务并从多模态输入中提取必要的隐含信息，然后使用机器语言令牌表达。这种表示对于空中接口传输而言效率显著更高。此外，为了减少传输开销，我们引入了一种联合令牌和信道编码（JTCC）方案，该方案通过利用令牌序列的稀疏性来压缩令牌序列，同时增强对信道噪声的鲁棒性。广泛的实验表明，我们的方法降低了下游任务的传输开销，同时相对于SOTA方法提高了准确性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [150] [Two-Dimensional Nonseparable Fractional Fourier Transform: Theory and Application](https://arxiv.org/abs/2507.21511)
> *二维不可分离分数傅里叶变换：理论与应用*

*Daxiang Li, Zhichao Zhang, Wei Yao* | **Category: eess.SP, 26A33, 42A38, 94A08, 94A12, I.4.3; I.6.3; I.5.2; G.1.2** | **Updated: 2025-07-29**

**Keywords:** 二维分数傅里叶变换, 不可分离, 时频分析, 图像处理, 快速算法

**Comment:** 26 pages, 11 figures

> **TL;DR:** 本文提出了一种更通用的二维不可分离分数傅里叶变换（NSFRFT），解决了现有二维FRFT的局限性，并在图像处理应用中表现出优越性能。

**AI_Comments:** 该论文通过引入二维不可分离分数傅里叶变换（NSFRFT）的概念，显著提升了二维时频分析的理论完备性和应用广度。其创新性在于解决了现有二维FRFT在处理非分离项和保持几何一致性方面的根本缺陷，并提供了高效的计算算法，这对于雷达、通信和图像处理等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的二维分数傅里叶变换（如SFRFT、GT、CFRFT）存在局限性：缺乏理论统一性和通用性；无法处理具有不可分离项的二维非平稳信号；未能与二维Wigner分布保持一致的四维旋转关系。这些限制影响了其在雷达、通信、声纳和光学成像等实际应用中的性能。

**Method:** 本文引入了二维不可分离分数傅里叶变换（NSFRFT）的更一般定义，该变换具有四个自由度，并包含现有的SFRFT、GT和CFRFT作为特例。研究了其性质，并提出了三种离散算法，其中两种是计算复杂度为O(N^2 log N)的快速算法。

**Result:** 数值模拟和实验证明，二维NSFRFT在图像加密、解密、滤波和去噪等应用中表现出优越的性能。它能更好地处理具有不可分离项的二维非平稳信号，并与二维Wigner分布保持更通用的四维旋转关系。

**Conclusion:** 二维不可分离分数傅里叶变换（NSFRFT）提供了一种更通用、理论更统一的二维FRFT框架，有效解决了现有方法的局限性，并在实际应用中展现出显著优势。

> **ai_Abstract:** 本文提出了一种更通用的二维不可分离分数傅里叶变换（NSFRFT），旨在克服现有二维FRFT（如SFRFT、GT、CFRFT）在处理非平稳信号和保持时频分析几何一致性方面的局限性。NSFRFT具有四个自由度，包含了现有方法作为特例，并与二维Wigner分布保持更普适的四维旋转关系。文章推导了其理论性质，并开发了三种离散算法，其中两种是高效的快速算法。实验结果表明，NSFRFT在图像加密、解密、滤波和去噪等应用中表现出显著的性能提升。

> **摘要翻译:** 一维（1D）分数傅里叶变换（FRFT）推广了一维傅里叶变换，在非平稳信号的时频分析中具有显著优势。为了将一维FRFT的优势扩展到高维信号，已经开发了二维FRFT，例如二维可分离FRFT（SFRFT）、回转变换（GT）和耦合FRFT（CFRFT）。然而，现有的二维FRFT存在以下局限性：(1) 缺乏理论统一性和通用性；(2) 无法处理具有不可分离项的二维非平稳信号；(3) 未能与二维Wigner分布（WD）保持一致的四维旋转关系，而这对于确保时频分析中的几何一致性和对称性至关重要。这些局限性限制了这些方法在雷达、通信、声纳和光学成像等实际应用中的性能，在这些应用中不可分离项经常出现。为了解决这些挑战，我们引入了二维FRFT的更一般定义，称为二维不可分离FRFT（NSFRFT）。二维NSFRFT具有四个自由度，包含二维SFRFT、GT和CFRFT作为特例，并与二维WD保持更通用的四维旋转关系。我们推导了其性质并提出了三种离散算法，其中两种是计算复杂度为O(N^2 log N)的快速算法，与二维SFRFT相当。数值模拟和实验证明了二维NSFRFT在图像加密、解密、滤波和去噪等应用中的优越性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [156] [Comprehensive Analysis of Behavioral Hardware Impairments in Cell-Free Massive MIMO-OFDM Uplink: Centralized Operation](https://arxiv.org/abs/2507.21626)
> *蜂窝自由大规模MIMO-OFDM上行链路中行为硬件损伤的综合分析：集中式操作*

*Özlem Tuğfe Demir, Muhammed Selman Somuncu, Ahmet M. Elbir, Emil Björnson* | **Category: eess.SP, cs.IT, math.IT** | **Updated: 2025-07-29**

**Keywords:** 蜂窝自由大规模MIMO, 硬件损伤, 频谱效率, OFDM, Bussgang分解

**Comment:** 4 pages, 2 figures, presented at IEEE Signal Processing and
  Communications Applications Conference (SIU), 2025

> **TL;DR:** 本文首次全面分析了蜂窝自由大规模MIMO-OFDM上行链路中宽带硬件损伤对频谱效率的影响，并提出了一种基于Bussgang分解的失真感知合并向量来优化频谱效率。

**AI_Comments:** 本文的创新之处在于首次对蜂窝自由大规模MIMO宽带系统中的多种行为硬件损伤进行了全面分析，并提出了基于Bussgang分解的失真感知合并向量，为优化未来6G系统中存在硬件损伤的系统性能提供了理论基础和实用方法。

<details>
  <summary>Details</summary>

**Motivation:** 蜂窝自由大规模MIMO因其低成本AP的密集部署而不可避免地存在硬件损伤。尽管窄带损伤已得到充分研究，但其在宽带系统中的影响仍未被探索。

**Method:** 本文首次对低噪声放大器中的非线性失真、相位噪声、同相正交失衡和低分辨率模数转换器等硬件损伤对蜂窝自由大规模MIMO上行链路频谱效率的影响进行了全面分析。研究采用OFDM波形和集中式处理，AP共享信道状态信息以进行联合上行合并。利用Bussgang分解，推导了一个失真感知合并向量，通过将失真建模为独立的有色噪声来优化频谱效率。

**Result:** 论文推导了一个失真感知合并向量，该向量通过将失真建模为独立的有色噪声来优化频谱效率。

**Conclusion:** 本文首次提供了蜂窝自由大规模MIMO-OFDM上行链路中宽带硬件损伤的综合分析，并提出了一种有效的方法来减轻这些损伤对频谱效率的影响。

> **ai_Abstract:** 本文首次全面分析了蜂窝自由大规模MIMO-OFDM上行链路中，由于低成本AP密集部署导致的宽带硬件损伤（如非线性失真、相位噪声、IQ不平衡、低分辨率ADC）对频谱效率的影响。研究采用OFDM波形和集中式处理，并利用Bussgang分解，推导了一个将失真建模为独立有色噪声的失真感知合并向量，以优化系统频谱效率。

> **摘要翻译:** 蜂窝自由大规模MIMO是6G的关键技术，提供卓越的频谱和能量效率。然而，其低成本接入点（AP）的密集部署使得硬件损伤不可避免。虽然窄带损伤已得到充分研究，但其在宽带系统中的影响仍未被探索。本文首次全面分析了蜂窝自由大规模MIMO上行链路中硬件损伤（如低噪声放大器中的非线性失真、相位噪声、同相正交不平衡和低分辨率模数转换器）对上行链路频谱效率的影响。使用OFDM波形和集中式处理，AP共享信道状态信息以进行联合上行合并。利用Bussgang分解，我们推导了一个失真感知合并向量，通过将失真建模为独立的有色噪声来优化频谱效率。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [176] [A Novel Framework for Near-Field Covert Communications with RIS and RSMA](https://arxiv.org/abs/2507.21956)
> *一种基于RIS和RSMA的近场隐蔽通信新框架*

*Atiquzzaman Mondal, Amira Bendaimi, Huseyin Arslan* | **Category: eess.SP, cs.ET** | **Updated: 2025-07-29**

**Keywords:** 近场通信, 隐蔽通信, RIS, RSMA, 波束成形

**Comment:** 12 pages, 7 figures, IEEE Transactions on Communications

> **TL;DR:** 本文提出一种利用RIS和RSMA在近场实现隐蔽通信的新框架，旨在最大化隐蔽速率同时抑制敌方检测。

**AI_Comments:** 该论文的创新点在于将RIS和RSMA两种技术结合应用于近场隐蔽通信场景，这在当前研究中具有前瞻性。通过联合优化RIS和基站的波束成形，有效提升了隐蔽通信速率并抑制了窃听者的检测能力。采用交替优化和连续凸近似等方法来解决非凸优化问题，体现了算法设计的巧妙性。这项工作对于未来近场通信和安全通信领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探索利用可重构智能表面（RIS）和速率分裂多址（RSMA）辅助的近场（NF）隐蔽通信，以增强合法用户的接收信号，同时抑制被动对手的检测能力，并提高隐蔽通信速率。

**Method:** 本研究将RIS部署在合法用户和被动对手的近场中，并让基站（BS）应用RSMA。推导了对手的检测错误概率（DEP）、中断概率（OP）和最优检测阈值的闭合形式表达式。提出了一个非凸的BS和RIS联合波束成形优化问题，以最大化隐蔽速率。为解决此问题，提出了一种交替优化（AO）算法，其中BS波束成形器采用基于连续凸近似（SCA）的两阶段迭代方法设计。此外，还引入了两种低复杂度的技术来进一步降低对手的接收功率。

**Result:** 仿真结果表明，所提出的算法有效提高了隐蔽通信速率。

**Conclusion:** 近场RSMA-RIS集成在隐蔽通信中具有潜力，所提出的算法能够有效提高隐蔽通信速率。

> **ai_Abstract:** 本文提出了一种利用可重构智能表面（RIS）和速率分裂多址（RSMA）在近场（NF）中实现隐蔽通信的新框架。该框架旨在通过RIS增强合法用户信号并抑制对手检测，同时利用RSMA提高隐蔽通信速率。研究推导了对手的检测错误概率、中断概率和最优检测阈值，并提出了一个非凸的联合波束成形优化问题。为解决此问题，论文提出了一种基于交替优化和连续凸近似的算法，并引入了低复杂度技术。仿真结果验证了所提出算法能有效提升隐蔽通信速率，突显了近场RSMA-RIS在隐蔽通信中的巨大潜力。

> **摘要翻译:** 本文探索了在速率分裂多址（RSMA）和可重构智能表面（RIS）辅助下的近场（NF）隐蔽通信。特别是，RIS在合法用户和被动对手的近场中运行，增强了合法用户的接收信号，同时抑制了对手的检测能力。而基站（BS）应用RSMA来提高由私有和共享速率分量组成的隐蔽通信速率。为了表征系统隐蔽性，我们推导了对手的检测错误概率（DEP）、中断概率（OP）和最优检测阈值的闭合形式表达式。我们制定了一个在单位模量约束下的非凸联合波束成形优化问题，以最大化隐蔽速率。为了解决这个问题，我们提出了一种交替优化（AO）算法，其中BS波束成形器使用基于连续凸近似（SCA）的两阶段迭代方法设计。此外，还引入了两种低复杂度的技术来进一步降低对手的接收功率。仿真结果表明，所提出的算法有效提高了隐蔽通信速率，突显了近场RSMA-RIS集成在隐蔽通信中的潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [206] [Trainable Joint Time-Vertex Fractional Fourier Transform](https://arxiv.org/abs/2507.21527)
> *可训练联合时域-顶点分数傅里叶变换*

*Ziqi Yan, Zhichao Zhang* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** 分数傅里叶变换, 图信号处理, 维纳滤波, 梯度反向传播, 自适应学习

**Comment:** 35 pages,5 figures

> **TL;DR:** 本文提出一种基于超微分形式的联合时域-顶点分数傅里叶变换（JFRFT）维纳滤波方法，利用梯度反向传播机制实现变换阶对和滤波器系数的自适应选择和优化，提高了时变图信号去噪性能并降低了计算负担。

**AI_Comments:** 本文的创新点在于将分数傅里叶变换的变换阶和滤波器系数作为可学习参数，并结合神经网络和梯度反向传播进行自适应优化，实现了模型驱动的信号处理。这种将传统信号处理与深度学习相结合的方法，有效克服了传统方法中参数手动选择的局限性，提高了处理效率和性能，对于时变图信号处理领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决图分数傅里叶变换（GFRFT）维纳滤波和传统联合时域-顶点分数傅里叶变换（JFRFT）维纳滤波的局限性。

**Method:** 首先，构建并分析了JFRFT的超微分形式。其次，将时变图信号划分为等跨度的动态图序列，通过向量化重组建立时空联合表示，然后进行联合时域-顶点维纳滤波。最后，通过严格证明变换阶的可微性，将变换阶和滤波器系数作为可学习参数嵌入神经网络架构中，通过梯度反向传播实现同步迭代优化，构建了参数自适应学习滤波框架。

**Result:** 实验结果表明，所提出的框架提高了时变图信号的去噪性能，同时减少了传统网格搜索策略的计算负担。

**Conclusion:** 本文提出的基于超微分形式的JFRFT滤波框架，通过模型驱动的梯度反向传播机制自适应学习最优变换阶对和滤波器系数，有效提升了时变图信号的去噪效果，并降低了计算复杂度。

> **ai_Abstract:** 本文针对传统图分数傅里叶变换（GFRFT）和联合时域-顶点分数傅里叶变换（JFRFT）维纳滤波的局限性，提出了一种基于JFRFT超微分形式的新型滤波方法。该方法通过构建JFRFT的超微分形式并分析其性质，将时变图信号进行时空联合表示。关键创新在于将变换阶和滤波器系数作为可学习参数嵌入神经网络，利用梯度反向传播实现同步优化，构建了一个参数自适应学习滤波框架。实验证明，该框架能有效提升时变图信号的去噪性能，并显著降低传统网格搜索的计算负担。

> **摘要翻译:** 为了解决图分数傅里叶变换（GFRFT）维纳滤波和传统联合时域-顶点分数傅里叶变换（JFRFT）维纳滤波的局限性，本研究提出了一种基于JFRFT超微分形式的滤波方法。该方法采用梯度反向传播机制，以实现变换阶对和滤波器系数的自适应选择。首先，利用GFRFT和分数傅里叶变换的超微分形式，构建了JFRFT的超微分形式并分析了其性质。其次，将时变图信号沿时间维度划分为等跨度的动态图序列。然后通过向量化重组建立时空联合表示，接着进行联合时域-顶点维纳滤波。此外，通过严格证明变换阶的可微性，将变换阶和滤波器系数作为可学习参数嵌入神经网络架构中。通过梯度反向传播，实现它们的同步迭代优化，从而构建了一个参数自适应学习滤波框架。该方法利用模型驱动的方法学习最优的变换阶对和滤波器系数。实验结果表明，所提出的框架提高了时变图信号的去噪性能，同时减少了传统网格搜索策略的计算负担。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [212] [Energy-Aware Resource Allocation for Multi-Operator Cell-Free Massive MIMO in V-CRAN Architectures](https://arxiv.org/abs/2507.21644)
> *针对V-CRAN架构中多运营商无蜂窝大规模MIMO的节能资源分配*

*Derya Nurcan-Atceken, Özlem Tuğfe Demir, Aysegul Altin-Kayhan, Emil Björnson, Cicek Cavdar, Bulent Tavli* | **Category: eess.SP, cs.IT, math.IT** | **Updated: 2025-07-29**

**Keywords:** 无蜂窝大规模MIMO, V-CRAN, 资源分配, 能源效率, 混合整数规划

**Comment:** 6 pages, 2 figures, to be presented at 2025 International Conference
  on Future Communications and Networks (FCN)

> **TL;DR:** 本文提出了一个优化框架，用于在多运营商V-CRAN中高效部署无蜂窝大规模MIMO，通过联合优化资源分配和用户-运营商分配来最小化功耗，并发现灵活的用户-运营商分配能显著降低功耗。

**AI_Comments:** 本文在多运营商V-CRAN架构下对无蜂窝大规模MIMO的资源分配问题进行了深入研究，其创新点在于提出了一个综合性的混合整数规划框架，能够同时优化多个关键网络参数以最小化系统功耗。研究强调了用户设备-运营商分配灵活性对节能的显著影响，为未来无线网络的设计和部署提供了宝贵的实践指导。该工作对于推动下一代无线通信系统的能源效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 无蜂窝大规模MIMO在虚拟化云无线接入网络（V-CRAN）中的实现，作为一种有前景的架构，旨在提高下一代无线系统的频谱效率、网络灵活性和能源效率。

**Method:** 论文开发了一个整体优化框架，用于在多移动网络运营商（MNOs）的V-CRAN中高效部署无蜂窝大规模MIMO。具体来说，构建了一系列混合整数规划（MIP）模型，联合优化接入点（AP）选择、用户设备（UE）关联、云资源分配和MNO分配，同时最小化跨MNOs的最大总功耗（TPC）。研究考虑了两种不同场景：用户设备是否可以被分配给任意MNO。

**Result:** 数值结果表明，不同的部署假设对功耗有影响，并突出显示了灵活的用户设备-MNO分配能显著降低总功耗。

**Conclusion:** 研究结果为无蜂窝大规模MIMO V-CRAN中的资源管理优化提供了关键见解，为节能无线网络实现铺平了道路。

> **ai_Abstract:** 本研究提出了一个全面的优化框架，旨在多运营商虚拟化云无线接入网络（V-CRAN）中高效部署无蜂窝大规模MIMO系统。通过构建混合整数规划（MIP）模型，该框架能够联合优化接入点选择、用户设备关联、云资源分配以及移动网络运营商分配，目标是最小化跨运营商的最大总功耗。研究对比了用户设备是否可灵活分配给不同运营商的场景，并发现灵活的用户设备-运营商分配能够显著降低系统总功耗。这些发现为无蜂窝大规模MIMO V-CRAN的资源管理优化提供了重要指导，有助于实现更节能的无线网络。

> **摘要翻译:** 无蜂窝大规模多输入多输出（MIMO）在虚拟化云无线接入网络（V-CRAN）中的实现已成为一种有前景的架构，旨在提高下一代无线系统的频谱效率（SE）、网络灵活性和能源效率（EE）。在这项工作中，我们开发了一个整体优化框架，用于在多移动网络运营商（MNOs）的V-CRAN中高效部署无蜂窝大规模MIMO。具体来说，我们制定了一系列混合整数规划（MIP）模型，以联合优化接入点（AP）选择、用户设备（UE）关联、云资源分配和MNO分配，同时最小化跨MNOs的最大总功耗（TPC）。我们根据用户设备是否可以被分配给任意MNO来考虑两种不同场景。数值结果表明了不同部署假设对功耗的影响，突出显示了灵活的用户设备-MNO分配能显著降低总功耗。研究结果为无蜂窝大规模MIMO V-CRAN中的资源管理优化提供了关键见解，为节能无线网络实现铺平了道路。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [255] [Causal Link Discovery with Unequal Edge Error Tolerance](https://arxiv.org/abs/2507.21570)
> *不等边误差容忍的因果链接发现*

*Joni Shaska, Urbashi Mitra* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** 因果发现, 非对称误差控制, Neyman-Pearson因果发现, R
nyi散度, epsilon-CUT

**Comment:** 14 pages, 6 figures, portions presented at International Symposium on
  Information Theory (ISIT) 2024 and Asilomar 2024

> **TL;DR:** 本文提出了一个名为Neyman-Pearson因果发现的新型框架，用于非对称误差控制下的因果发现，该框架旨在最小化一种误差，同时将另一种误差控制在用户指定的容忍水平之下，并为线性加性高斯噪声模型引入了epsilon-CUT算法，提供有限样本的假阳性率保证。

**AI_Comments:** 该论文的创新点在于提出了Neyman-Pearson因果发现框架，首次在因果发现中引入了非对称误差控制的概念，并提供了有限样本误差保证。这对于实际应用中不同类型误差具有不同代价的场景非常重要，弥补了现有方法的不足。epsilon-CUT算法的提出，进一步验证了该理论框架的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管在应用中不同类型的边误差可能具有不同重要性，但当前的因果发现算法不区分误差类型，也不提供有限样本的边误差保证。因此，本文旨在解决这一问题，通过非对称误差控制来优化因果发现。

**Method:** 本文提出了Neyman-Pearson因果发现框架，通过信息论技术找到了由Rényi散度表征的性能极限。此外，对于线性加性高斯噪声模型，引入了一种名为epsilon-CUT的因果发现算法。

**Result:** Neyman-Pearson因果发现框架找到了由Rényi散度表征的性能极限。epsilon-CUT算法在提供有限样本假阳性率保证的同时，与现有最先进的方法保持竞争力。

**Conclusion:** 本文提出的Neyman-Pearson因果发现框架及其配套的epsilon-CUT算法，有效地解决了因果发现中不对称误差控制的问题，并在提供理论保证的同时，达到了与现有方法相当的性能。

> **ai_Abstract:** 本文提出了一种名为Neyman-Pearson因果发现的新型框架，用于解决因果发现中不同类型边误差重要性不对称的问题。针对现有方法不区分误差类型且缺乏有限样本保证的不足，该框架旨在最小化一种误差的同时，将另一种误差限制在特定容忍水平内。研究利用信息论确定了基于Rényi散度的性能极限，并为线性加性高斯噪声模型开发了epsilon-CUT算法，该算法在提供假阳性率的有限样本保证方面表现出色，并与现有技术具有竞争力。

> **摘要翻译:** 本文提出了一种名为Neyman-Pearson因果发现的新型框架，用于非对称误差控制下的因果发现。尽管在应用中不同类型的边误差可能具有不同重要性，但当前最先进的因果发现算法不区分边误差的类型，也不提供任何有限样本的边误差保证。因此，该框架旨在最小化一种误差，同时将另一种误差控制在用户指定的容忍水平之下。本文利用信息论技术，找到了Neyman-Pearson因果发现的基本性能极限，并由Rényi散度表征。此外，针对线性加性高斯噪声模型，引入了一种名为epsilon-CUT的因果发现算法，该算法提供有限样本的假阳性率保证，同时与最先进的方法保持竞争力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [318] [Affine Invariant Semi-Blind Receiver: Joint Channel Estimation and High-Order Signal Detection for Multiuser Massive MIMO-OFDM Systems](https://arxiv.org/abs/2507.21593)
> *仿射不变半盲接收机：多用户大规模MIMO-OFDM系统中信道估计与高阶信号检测联合方法*

*Erdeng Zhang, Shuntian Zheng, Sheng Wu, Haoge Jia, Zhe Ji, Ailing Xiao* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** 大规模MIMO-OFDM, 半盲接收机, 信道估计, 信号检测, 仿射不变性

**Comment:** 

> **TL;DR:** 针对多用户大规模MIMO-OFDM系统中的信道估计和高阶信号检测问题，提出了一种利用星座仿射不变性的半盲联合方法，显著提高了频谱效率。

**AI_Comments:** 该论文的创新点在于提出了一个利用星座仿射不变性的半盲联合信道估计和信号检测方法，并结合了混合预编码、数据增强以及迭代细化策略，有效应对了大规模MIMO-OFDM系统在高密度用户、高阶调制和频率选择性信道下的挑战。其重要性在于提供了一种提高频谱效率和降低导频开销的潜在解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有盲和半盲信道估计与信号检测算法在多用户大规模MIMO-OFDM系统中面临高用户密度导致的严重用户间干扰（IUI）和导频开销问题，且在频率选择性信道和高阶调制下性能下降、复杂度增加。

**Method:** 提出了一种新颖的半盲联合信道估计和信号检测（JCESD）方法。该方法采用混合预编码架构抑制IUI；将JCESD公式化为利用星座仿射不变性的非凸星座拟合优化问题；使用少量导频进行粗略估计以初始化和消除模糊性；利用正交幅度调制（QAM）星座的对称性通过数据增强机制增加高阶调制的有效样本数；通过迭代细化策略利用改进的信号检测结果增强信道估计精度以应对频率选择性信道。

**Result:** 仿真结果表明，在多用户场景下，所提出的方法比广泛使用的基于导频的方法平均吞吐量增益达到11%。

**Conclusion:** 所提出的方法在多用户大规模MIMO-OFDM系统中具有提高频谱效率的潜力。

> **ai_Abstract:** 本文针对多用户大规模MIMO-OFDM系统中存在的高用户间干扰、高导频开销以及频率选择性信道和高阶调制带来的挑战，提出了一种新颖的仿射不变半盲联合信道估计和信号检测（JCESD）方法。该方法结合混合预编码抑制干扰，利用星座仿射不变性进行非凸优化，并采用少量导频初始化。针对高阶调制，引入数据增强机制；针对频率选择性信道，采用迭代细化策略提升信道估计精度。仿真结果显示，该方法在吞吐量方面优于传统导频方法，有效提高了频谱效率。

> **摘要翻译:** 大规模多输入多输出（MIMO）系统与正交频分复用（OFDM）相结合是未来无线网络中下行多用户（MU）通信的基础，因其能够提高频谱效率并同时支持大量用户。然而，高用户密度加剧了严重的用户间干扰（IUI）和导频开销。因此，现有的盲和半盲信道估计（CE）和信号检测（SD）算法性能下降且复杂度增加，尤其是在频率选择性信道和高阶调制需求带来的进一步挑战下。为此，本文提出了一种新颖的半盲联合信道估计和信号检测（JCESD）方法。具体而言，所提出的方法采用混合预编码架构来抑制IUI。此外，我们将JCESD公式化为利用星座仿射不变性的非凸星座拟合优化问题。使用少量导频进行粗略估计以初始化和消除模糊性。对于高阶调制，数据增强机制利用正交幅度调制（QAM）星座的对称性来增加有效样本数。为了解决频率选择性信道问题，信道估计精度通过利用改进的信号检测结果的迭代细化策略得到提升。仿真结果表明，在多用户场景下，与广泛使用的基于导频的方法相比，所提出的方法平均吞吐量增益达到11%，突出了该方法提高频谱效率的潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [374] [Impact of Phase Noise and Power Amplifier Non-Linearities on Downlink Cell-Free Massive MIMO-OFDM Systems](https://arxiv.org/abs/2507.21635)
> *相位噪声和功率放大器非线性对下行链路无蜂窝大规模MIMO-OFDM系统的影响*

*Özlem Tuğfe Demir, Emil Björnson* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** 无蜂窝大规模MIMO, 相位噪声, 功率放大器非线性, 频谱效率, 硬件损伤

**Comment:** 6 pages, 3 figures, presented at IEEE SmartNets 2025

> **TL;DR:** 本文分析了相位噪声和功率放大器非线性对无蜂窝大规模MIMO-OFDM系统下行链路频谱效率的影响，发现相位噪声导致的性能下降比功率放大器失真更严重，尤其是在分布式操作中。

**AI_Comments:** 本文对6G关键技术无蜂窝大规模MIMO系统中的硬件损伤进行了深入分析，特别是区分了相位噪声和功率放大器非线性对系统性能的影响。其创新点在于量化了两种损伤的相对影响，并明确指出相位噪声是更主要的性能瓶颈，为未来失真感知预编码设计提供了重要指导。这对于实际系统部署和优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 无蜂窝大规模MIMO系统依赖低成本接入点，引入了不可避免的硬件损伤，但其对宽带下行链路系统的综合影响，在使用行为模型分析时，仍未被充分探索。

**Method:** 本文对无蜂窝大规模MIMO-OFDM系统在实际硬件损伤（包括相位噪声和三阶功率放大器非线性）下的下行链路频谱效率（SE）进行了全面分析。通过利用Bussgang分解，推导了SE表达式，并通过仿真量化了损伤的相对影响。同时考察了集中式和分布式预编码策略。

**Result:** 研究结果表明，相位噪声引起的性能下降比功率放大器失真更严重，尤其是在分布式操作中。

**Conclusion:** 相位噪声对系统性能的负面影响比功率放大器失真更大，尤其是在分布式操作中，这突出了未来需要考虑失真感知的预编码设计的必要性。

> **ai_Abstract:** 本文研究了相位噪声和三阶功率放大器非线性等硬件损伤对无蜂窝大规模MIMO-OFDM系统下行链路频谱效率的影响。研究通过Bussgang分解推导了频谱效率表达式，并对比了集中式和分布式预编码策略。结果显示，相位噪声对系统性能的劣化作用比功率放大器失真更显著，特别是在分布式操作环境下。这强调了未来设计预编码方案时应考虑失真效应的重要性。

> **摘要翻译:** 无蜂窝大规模多输入多输出（MIMO）是第六代（6G）移动网络的关键推动者，通过分布式接入点（AP）的用户中心操作，提供了显著的频谱和能量效率增益。然而，其对低成本接入点的依赖引入了不可避免的硬件损伤，当使用行为模型分析时，这些损伤对宽带下行链路系统的综合影响仍未被探索。本文对实际硬件损伤（包括相位噪声和三阶功率放大器非线性）下的无蜂窝大规模MIMO-OFDM系统下行链路频谱效率（SE）进行了全面分析。研究了集中式和分布式预编码策略。通过利用Bussgang分解，我们推导了SE表达式，并通过仿真量化了损伤的相对影响。我们的结果表明，相位噪声导致的性能下降比功率放大器失真更严重，尤其是在分布式操作中，这突出了未来需要考虑失真感知的预编码设计的必要性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [416] [Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN](https://arxiv.org/abs/2507.21696)
> *O-RAN中用于自主网络优化的边缘智能体AI框架*

*Abdelaziz Salama, Zeinab Nezami, Mohammed M. H. Qazzaz, Maryam Hafeez, Syed Ali Raza Zaidi* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** 边缘AI, O-RAN, 网络优化, 自主网络, AI智能体

**Comment:** 

> **TL;DR:** 本文提出了一个用于O-RAN中自主网络优化的新型边缘AI框架，通过多工具架构、主动异常检测和安全对齐奖励机制，在5G场景下实现了零网络中断，验证了AI智能体在关键网络基础设施中安全有效部署的可行性。

**AI_Comments:** 该论文的创新点在于提出了一个集成了多工具架构、主动异常检测和安全对齐奖励机制的边缘AI框架，有效解决了AI智能体在RAN部署中的安全性和可靠性问题。其重要性在于通过实验证明了该框架在极端条件下的鲁棒性（零中断），为未来5G及6G网络的智能化和自主化运营提供了实际可行的解决方案。特别是在与传统方法和LLM智能体方法的对比中展现出的优越性，突出了其在网络优化领域的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在传统无线接入网络（RAN）基础设施中部署AI智能体，对未来的6G网络构成显著的安全性和可靠性挑战。

**Method:** 本文提出了一个用于开放RAN环境的自主网络优化新型边缘AI框架，通过以下三项核心创新解决挑战：1) 基于角色的多工具架构，实现分布式、上下文感知的决策；2) 由流量预测工具驱动的主动异常检测智能体；3) 平衡性能与操作稳定性的安全对齐奖励机制。该框架集成到RAN智能控制器（RIC）中，利用多模态数据融合，包括网络KPI、流量预测模型和外部信息源，以预测和响应动态网络条件。

**Result:** 在真实的5G场景下进行的大量评估表明，该边缘框架在高压力条件下实现了零网络中断，而传统固定功率网络的中断率为8.4%，基于大型语言模型（LLM）智能体的方法为3.3%，同时保持了接近实时的响应能力和一致的服务质量（QoS）。

**Conclusion:** 这些结果表明，当配备正确的工具和上下文感知能力时，AI智能体可以安全有效地部署在关键网络基础设施中，为5G及未来网络的智能和自主运行奠定了基础。

> **ai_Abstract:** 本文提出了一种用于开放无线接入网络（O-RAN）中自主网络优化的新型边缘AI框架，旨在解决AI智能体在传统RAN部署中的安全性和可靠性挑战。该框架包含三项核心创新：基于角色的多工具架构、主动异常检测智能体以及安全对齐的奖励机制。通过集成到RAN智能控制器（RIC）并利用多模态数据融合，该框架能够预测并响应动态网络条件。在5G场景下的评估显示，该框架在高压力下实现了零网络中断，显著优于传统方法和基于LLM的智能体方法，同时保持了良好的实时响应和QoS。研究结果证实了AI智能体在关键网络基础设施中安全有效部署的可行性，为智能和自主的5G及未来网络运行奠定了基础。

> **摘要翻译:** 在传统无线接入网络（RAN）基础设施中部署AI智能体，对未来的6G网络构成显著的安全性和可靠性挑战。本文提出了一个用于开放RAN环境的自主网络优化新型边缘AI框架，通过以下三项核心创新解决这些挑战：1) 基于角色的多工具架构，实现分布式、上下文感知的决策；2) 由流量预测工具驱动的主动异常检测智能体；3) 平衡性能与操作稳定性的安全对齐奖励机制。该框架集成到RAN智能控制器（RIC）中，利用多模态数据融合，包括网络KPI、流量预测模型和外部信息源，以预测和响应动态网络条件。在真实的5G场景下进行的大量评估表明，该边缘框架在高压力条件下实现了零网络中断，而传统固定功率网络的中断率为8.4%，基于大型语言模型（LLM）智能体的方法为3.3%，同时保持了接近实时的响应能力和一致的服务质量（QoS）。这些结果表明，当配备正确的工具和上下文感知能力时，AI智能体可以安全有效地部署在关键网络基础设施中，为5G及未来网络的智能和自主运行奠定了基础。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [467] [EcoFL: Resource Allocation for Energy-Efficient Federated Learning in Multi-RAT ORAN Networks](https://arxiv.org/abs/2507.21698)
> *EcoFL：多RAT ORAN网络中节能联邦学习的资源分配*

*Abdelaziz Salama, Mohammed M. H. Qazzaz, Syed Danial Ali Shah, Maryam Hafeez, Syed Ali Zaidi, Hamed Ahmadi* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** 联邦学习, 资源分配, 节能, ORAN网络, 多RATs

**Comment:** 

> **TL;DR:** EcoFL是一个为多RAT ORAN网络设计的联邦学习框架，通过两阶段优化（RL-based rApp和CNN-based xApp）解决无线网络中FL的能耗和通信效率问题，实现更低的功耗和强大的通信弹性。

**AI_Comments:** EcoFL的创新之处在于其结合ORAN架构与多RATs，并采用RL和CNN结合的两阶段优化方法，有效解决了联邦学习在无线网络中面临的能耗和通信效率问题。其在功耗方面的显著降低（19%）展示了其实用价值和对未来节能AI应用的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在无线网络部署中面临通信开销大、连接不可靠以及能耗高（尤其是在动态环境中）等挑战，本研究旨在解决这些问题。

**Method:** 本文提出了EcoFL框架，它利用开放无线电接入网络（ORAN）架构与多无线电接入技术（RATs）来提升通信效率和确保联邦学习操作的鲁棒性。EcoFL采用两阶段优化方法：一个基于强化学习（RL）的rApp用于动态RAT选择，平衡能效与网络性能；一个基于卷积神经网络（CNN）的xApp用于近实时资源分配，采用自适应策略。这种协调方法显著增强了波动网络条件下的通信弹性。

**Result:** 实验结果表明，与基线方法相比，EcoFL在保持联邦学习模型竞争性性能的同时，功耗降低了19%。这突出了其在可扩展、节能的协作学习应用方面的巨大潜力。

**Conclusion:** EcoFL框架通过其创新的两阶段优化方法，成功解决了无线网络中联邦学习的能耗和通信效率挑战，为未来节能、可扩展的协作学习应用提供了强大支持。

> **ai_Abstract:** EcoFL是一个为多RAT ORAN网络设计的集成联邦学习框架，旨在解决无线网络中FL的通信开销、连接不可靠和高能耗问题。它采用两阶段优化方法：通过RL-based rApp进行动态RAT选择以平衡能效和网络性能，并通过CNN-based xApp进行近实时资源分配。实验证明，EcoFL在保证模型性能的同时，能将功耗降低19%，展现了其在节能协作学习中的巨大潜力。

> **摘要翻译:** 联邦学习（FL）能够在边缘设备上进行分布式模型训练，同时保护数据隐私。然而，在无线网络中部署FL面临严峻挑战，包括通信开销、不可靠的连接以及高能耗，尤其是在动态环境中。本文提出了EcoFL，一个集成的FL框架，它利用开放无线电接入网络（ORAN）架构与多无线电接入技术（RATs）来提高通信效率并确保FL操作的鲁棒性。EcoFL实现了两阶段优化方法：一个基于强化学习（RL）的rApp用于动态RAT选择，平衡能效与网络性能；一个基于卷积神经网络（CNN）的xApp用于近实时资源分配，采用自适应策略。这种协调方法显著增强了波动网络条件下的通信弹性。实验结果表明，与基线方法相比，FL模型性能具有竞争力，同时功耗降低了19%，这突出了其在可扩展、节能的协作学习应用方面的巨大潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [488] [Advancing Brainwave-Based Biometrics: A Large-Scale, Multi-Session Evaluation](https://arxiv.org/abs/2501.17866)
> *推进脑电波生物识别技术：一项大规模、多会话评估*

*Matin Fallahi, Patricia Arias-Cabarcos, Thorsten Strufe* | **Category: eess.SP, cs.CR** | **Updated: 2025-07-29**

**Keywords:** 脑电波生物识别, 大规模评估, 深度学习, 等错误率, 生物识别传感器

**Comment:** 

> **TL;DR:** 一项大规模、多会话脑电波生物识别研究发现深度学习优于传统方法，但EER随时间增加，且仍未达到工业标准，不过支持减少传感器使用，并已开源代码以促进未来研究。

**AI_Comments:** 本文通过迄今为止最大规模的多会话脑电波数据集评估，显著推进了脑电波生物识别领域的研究，解决了现有研究数据规模小、泛化性不足的局限。其发现EER随时间增加并提出强化注册集的建议，对实际应用具有重要的指导意义。同时，证明减少传感器数量的可行性，为脑电波生物识别技术从医用级向更普及的消费级设备过渡奠定了基础。尽管目前性能尚未完全达到工业标准，但其开源分析代码的举动，极大地促进了未来该领域的研究发展。

<details>
  <summary>Details</summary>

**Motivation:** 当前脑电波生物识别研究依赖于小规模、单会话数据集，导致结果泛化性存疑。本文旨在通过一项大规模、多会话研究来解决这一局限性，并评估该技术的实际可行性。

**Method:** 研究使用了一个公共脑电波数据集，包含345名受试者和超过6,007个会话（平均每位受试者17个会话），数据采集跨越五年，并使用了三种头戴设备。研究比较了深度学习方法和手工特征提取方法，并分析了等错误率（EER）随时间的变化以及使用更少脑电波测量传感器的可行性。最终，将结果与现有工作和生物识别标准进行了比较。

**Result:** 深度学习方法显著优于手工特征提取方法。等错误率（EER）随时间增加，例如从1天后的6.7%增加到1年后的14.3%。可以减少脑电波测量传感器的数量，且EER的增加在可接受范围内，这对于从医用级设备向消费级设备过渡至关重要。研究性能与现有方法相当或更优，但仍未达到工业基准。

**Conclusion:** 脑电波生物识别技术需要通过在成功登录后强化注册集来应对EER随时间增加的问题。减少传感器数量是可行的，有助于该技术向经济实惠的消费级设备过渡。尽管研究性能有所提升，但仍需更大的训练集以达到工业级标准。

> **ai_Abstract:** 本文针对脑电波生物识别领域中现有研究数据集规模小、泛化性受限的问题，开展了一项大规模、多会话评估。研究利用包含345名受试者和6007个会话的公共数据集，发现深度学习方法在性能上优于传统的手工特征提取方法。研究指出等错误率（EER）会随时间推移而增加，因此建议在成功登录后强化注册集。此外，研究还证明了在可接受的EER增加范围内，可以减少脑电波测量传感器的数量，这对于推动该技术向消费级设备发展至关重要。尽管研究结果优于或持平于现有方法，但仍未达到工业级基准。作者推测通过更大的训练集有望进一步提升性能，并已开源分析代码以支持后续研究。

> **摘要翻译:** 脑电波生物识别领域因其在无需动手交互、防偷窥、连续认证和可撤销性方面革新用户认证的潜力而受到关注。然而，当前研究通常依赖于少于55名受试者的单会话或有限会话数据集，这引发了对研究结果泛化性的担忧。为了弥补这一空白，我们使用一个包含345名受试者和超过6,007个会话（平均每位受试者17个会话）的公共脑电波数据集进行了一项大规模研究，这些数据使用三种头戴设备在五年内记录。我们的结果显示，深度学习方法显著优于手工特征提取方法。我们还观察到等错误率（EER）随时间增加（例如，从1天后的6.7%增加到1年后的14.3%）。因此，有必要在成功登录尝试后加强注册集。此外，我们证明可以使用更少的脑电波测量传感器，且EER的增加在可接受范围内，这对于从医用级设备向经济实惠的消费级设备过渡是必要的。最后，我们将我们的结果与先前的工作和现有生物识别标准进行了比较。虽然我们的性能与现有方法相当或更优，但仍未达到工业基准。根据结果，我们推测通过更大的训练集有可能实现进一步的改进。为了支持未来的研究，我们已经开源了我们的分析代码。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [523] [Affine Frequency Division Multiplexing (AFDM) for 6G: Properties, Features, and Challenges](https://arxiv.org/abs/2507.21704)
> *仿射频分复用 (AFDM) 用于 6G：特性、特点和挑战*

*Hyeon Seok Rou, Kuranage Roche Rayan Ranasinghe, Vincent Savaux, Giuseppe Thadeu Freitas de Abreu, David González G., Christos Masouros* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** AFDM, 6G, 波形, ISAC, 标准化

**Comment:** 

> **TL;DR:** AFDM 是一种新兴的 6G 波形，具有在异构和高移动性环境中增强鲁棒性、适用于 ISAC 以及与现有系统向后兼容的特点，本文对其属性、特点和挑战进行了概述。

**AI_Comments:** 这篇综述性文章突出了 AFDM 作为 6G 关键波形候选的潜力。其创新点在于作为 OFDM 的自然推广，能够实现向后兼容性，同时在高移动性和 ISAC 应用中展现出优越性能。特别是其固有的线性调频参数化为物理层安全提供了新途径。文章全面分析了 AFDM 的特性和挑战，对于推动 6G 标准化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 推动 6G 系统发展，寻找适合未来通信的新型波形，解决现有技术在高移动性和异构环境中的局限性，并支持集成感知与通信 (ISAC) 应用。

**Method:** 本文对仿射频分复用 (AFDM) 进行了概述。它首先介绍了 AFDM 的基本属性和独特特性，接着强调了其优势特点，最后讨论了其在 6G 标准化努力和代表性要求中的潜力和挑战。

**Result:** AFDM 在异构和高移动性环境中具有增强的鲁棒性，固有适用于集成感知与通信 (ISAC) 应用。与 OTFS 等其他候选技术不同，AFDM 具有独特的优势，增强了其在 6G 实际部署和标准化中的相关性。作为 OFDM 的自然推广，它保证了与现有传统系统的强大向后兼容性，并提供了波形设计的新可能性，例如通过其固有的线性调频参数化实现物理层安全。

**Conclusion:** 本文强调了 AFDM 作为 6G 标准化候选波形的适用性，并概述了其基本属性、优势特点、潜力和面临的挑战。

> **ai_Abstract:** 本文概述了仿射频分复用 (AFDM) 作为 6G 系统的潜在波形。AFDM 在高移动性和异构环境中表现出增强的鲁棒性，并适用于集成感知与通信 (ISAC)。与 OTFS 不同，AFDM 与现有 OFDM 系统具有强大的向后兼容性，并能通过其线性调频参数化提供物理层安全。文章详细阐述了 AFDM 的基本特性、优势以及在 6G 标准化中的潜力和挑战，强调了其作为 6G 候选波形的适用性。

> **摘要翻译:** 仿射频分复用（AFDM）是未来第六代（6G）系统的一种新兴波形候选，提供了一系列有前景的特性，例如在异构和高移动性环境中增强的鲁棒性，以及固有适用于集成感知与通信（ISAC）应用。此外，与正交时频空间（OTFS）调制等其他候选技术不同，AFDM 提供了多项独特的优势，增强了其在 6G 实际部署和标准化中的相关性。值得注意的是，作为正交频分复用（OFDM）的自然推广，它保证了与现有传统系统的强大向后兼容性，同时在波形设计方面提供了新的可能性，例如通过其固有的线性调频参数化实现物理层安全。总而言之，本文概述了 AFDM，强调了其作为 6G 标准化候选波形的适用性。首先，我们简要介绍了 AFDM 的基本属性和独特特性，接着重点介绍了其优势特点，最后讨论了其在 6G 标准化努力和代表性要求中的潜力和挑战。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [579] [CRB-Rate Tradeoff for Bistatic ISAC with Gaussian Information and Deterministic Sensing Signals](https://arxiv.org/abs/2507.21879)
> *双基地ISAC中高斯信息与确定性感知信号的CRB-速率权衡*

*Xianxin Song, Xianghao Yu, Jie Xu, Derrick Wing Kwan Ng* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** ISAC, CRB, 波束成形, DoA估计, 双基地系统

**Comment:** 13 pages,6 figures

> **TL;DR:** 本文研究了双基地ISAC系统中的发射波束成形设计，旨在最小化感知CRB，同时满足通信SINR要求，并探讨了不同信号类型对系统性能的影响。

**AI_Comments:** 本文针对双基地ISAC系统，在高斯信息与确定性感知信号叠加传输的复杂场景下，深入探讨了CRB-速率的权衡与波束成形设计。其创新点在于对不同信号类型下的优化问题进行了严谨的数学建模和求解，特别是非凸问题的SCA应用。研究结果揭示了高斯信息信号对感知性能的潜在负面影响，为ISAC系统设计提供了重要的工程指导和性能边界分析。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究双基地综合感知与通信（ISAC）系统，该系统包含多天线基站、多天线感知接收器、单天线通信用户和点目标，并探索在高斯信息信号与确定性感知信号叠加传输场景下的系统设计与性能权衡。

**Method:** 研究了一个由多天线基站、多天线感知接收器、单天线通信用户和点目标组成的双基地ISAC系统。首先推导了目标到达方向（DoA）估计的Cramér-Rao下界（CRB），并提出了实用的估计器。随后，将发射波束成形设计建模为一个优化问题，目标是最小化CRB，同时满足通信用户处的最小信干噪比（SINR）要求和基站的最大发射功率限制。对于仅采用高斯信息信号的情况，问题是凸的并可获得最优解；对于同时传输高斯信息和确定性感知信号的情况，问题是非凸的，通过逐次凸逼近（SCA）获得了局部最优解。

**Result:** 当基站仅使用高斯信息信号时，波束成形优化问题是凸的，可以得到最优解。当同时传输高斯信息和确定性感知信号时，问题是非凸的，通过逐次凸逼近（SCA）获得了局部最优解。数值结果表明，单独使用高斯信息信号会导致目标感知性能显著下降，而所提出的发射波束成形设计相比各种基准方案实现了更优的ISAC性能边界。

**Conclusion:** 采用高斯信息信号会导致目标感知性能显著下降，而本文提出的发射波束成形设计在双基地ISAC系统中实现了优于现有基准方案的综合性能边界。

> **ai_Abstract:** 本文研究了一种双基地ISAC系统，其中基站同时传输高斯信息和确定性感知信号。作者推导了目标DoA估计的CRB，并提出了实用的估计器。通过将发射波束成形设计建模为优化问题，旨在最小化CRB并满足通信SINR和功率约束，文章分析了不同信号类型下的求解方法：仅高斯信号时为凸优化，混合信号时为非凸优化并采用SCA求解。数值结果表明，所提出的波束成形设计能实现卓越的ISAC性能，并指出单独使用高斯信息信号会导致感知性能下降。

> **摘要翻译:** 在本文中，我们研究了一个双基地综合感知与通信（ISAC）系统，该系统由一个多天线基站（BS）、一个多天线感知接收器、一个单天线通信用户（CU）和一个待感知的点目标组成。具体来说，基站传输高斯信息信号和确定性感知信号的叠加。基站旨在向通信用户传输信息符号，而感知接收器旨在通过处理回波信号来估计目标相对于感知接收器的到达方向（DoA）。对于感知接收器，我们假设只完美已知确定性感知信号序列和信息信号的协方差矩阵，而信息信号的具体实现则不可用。在此设置下，我们首先推导了DoA估计的相应Cramér-Rao下界（CRB），并提出了实用的估计器来精确估计目标的DoA。随后，我们将发射波束成形设计表述为一个优化问题，旨在最小化CRB，同时满足通信用户处的最小信干噪比（SINR）要求和基站的最大发射功率约束。当基站仅采用高斯信息信号时，所得的波束成形优化问题是凸的，从而能够推导出最优解。相反，当同时传输高斯信息和确定性感知信号时，所得问题是非凸的，并通过利用逐次凸逼近（SCA）获得了局部最优解。最后，数值结果表明，采用高斯信息信号会导致目标感知性能显著下降，并且所提出的发射波束成形设计与各种基准方案相比，实现了更优越的ISAC性能边界。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [635] [Zak-OTFS Based Coded Random Access for Uplink mMTC](https://arxiv.org/abs/2507.22013)
> *基于Zak-OTFS的上行mMTC编码随机接入*

*Alessandro Mirri, Venkatesh Khammammetti, Beyza Dabak, Enrico Paolini, Krishna Narayanan, Robert Calderbank* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** Zak-OTFS, 编码随机接入, mMTC, 双选择性信道, 丢包率

**Comment:** 

> **TL;DR:** 本文提出了一种基于Zak-OTFS调制的免授权编码随机接入方案，用于上行大规模机器类型通信（mMTC），在双选择性信道下，相比传统OFDM方案能显著降低丢包率。

**AI_Comments:** 该论文创新性地将Zak-OTFS调制应用于免授权编码随机接入，有效解决了传统OFDM在双选择性高移动性信道下的性能瓶颈。其通过利用Zak-OTFS在时延-多普勒域的特性，实现了更准确的信道估计和干扰消除，对于提升未来大规模机器类型通信的可靠性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在双选择性无线信道中，传统的基于OFDM的编码随机接入（CRA）方案由于时频变异性导致不可靠的槽间信道预测，从而性能不佳。

**Method:** 本文提出了一种基于Zak-正交时频空间（Zak-OTFS）调制的免授权编码随机接入（CRA）方案。该方案利用Zak-OTFS的可预测性，实现了准确的跨槽信道估计，并促进了用户数据包副本的可靠连续干扰消除。

**Result:** 与基于OFDM的CRA基线相比，所提出的方案在高移动性和用户密度下实现了显著更低的丢包率。在标准化Veh-A信道上的广泛仿真证实了基于Zak-OTFS的CRA的鲁棒性和可扩展性。

**Conclusion:** 基于Zak-OTFS的编码随机接入方案在双选择性信道下表现出优越的性能和鲁棒性，适用于未来的mMTC部署。

> **ai_Abstract:** 本文提出了一种基于Zak-OTFS调制的免授权编码随机接入（CRA）方案，旨在解决双选择性无线信道中传统OFDM-CRA因时频变异性导致的信道预测不可靠问题。该方案利用Zak-OTFS的可预测性，实现了准确的信道估计和可靠的连续干扰消除。实验结果表明，在高移动性和用户密度下，该方案的丢包率显著低于OFDM-CRA，并验证了其在未来mMTC部署中的鲁棒性和可扩展性。

> **摘要翻译:** 本文提出了一种基于Zak-正交时频空间（Zak-OTFS）调制在时延-多普勒域中的免授权编码随机接入（CRA）方案，用于上行大规模机器类型通信（mMTC）。该方案专为双选择性无线信道设计，在这些信道中，传统的基于正交频分复用（OFDM）的CRA由于时频变异性而导致不可靠的槽间信道预测。通过利用Zak-OTFS的可预测性，所提出的方法能够实现跨槽的精确信道估计，促进用户数据包副本的可靠连续干扰消除。与基于OFDM的CRA基线进行公平比较表明，所提出的方案在高移动性和用户密度下实现了显著更低的丢包率。在标准化Veh-A信道上的广泛仿真证实了基于Zak-OTFS的CRA的鲁棒性和可扩展性，支持其在未来mMTC部署中的适用性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [690] [Site-Specific Location Calibration and Validation of Ray-Tracing Simulator NYURay at Upper Mid-Band Frequencies](https://arxiv.org/abs/2507.22027)
> *射线追踪模拟器NYURay在上中频段的站点特定位置校准与验证*

*Mingjun Ying, Dipankar Shakya, Peijie Ma, Guanyue Qian, Theodore S. Rappaport* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** 射线追踪, 位置校准, NYURay, 上中频段, 6G部署

**Comment:** 16 pages, 7 figures

> **TL;DR:** 本文针对射线追踪模拟器NYURay，提出了一种站点特定位置校准算法，通过纠正GPS误差显著提高了发射机-接收机位置精度，并验证了其在路径损耗预测上的高准确性，为6G部署提供可靠信道统计。

**AI_Comments:** 本文的创新点在于提出了一个系统性的位置校准算法，有效解决了射线追踪模拟器中GPS定位误差导致精度下降的问题。通过对NYURay的实地校准和验证，显著提升了模拟器在站点特定信道预测的准确性，这对于未来无线数字孪生和6G网络部署具有重要意义。该研究填补了现有RT模拟器缺乏系统性验证的空白。

<details>
  <summary>Details</summary>

**Motivation:** 射线追踪（RT）模拟器在无线数字孪生中至关重要，但其准确性常受限于测量数据不足和缺乏系统性验证。

**Method:** 本文提出了一个位置校准算法，通过优化发射机-接收机（TX-RX）位置来纠正GPS引起的位置误差，以对齐模拟和测量的功率延迟剖面。研究对NYU内部开发的射线追踪器NYURay在上中频段（6.75 GHz和16.95 GHz）进行了站点特定位置校准和验证。

**Result:** 该算法将视距（LOS）场景下的TX-RX位置精度提高了42.3%，非视距（NLOS）场景下提高了13.5%。在18个TX-RX位置的验证显示，路径损耗预测具有出色的RT精度，路径损耗指数（PLE）偏差低于0.14。虽然RT低估了延迟扩展和角度扩展，但它们的累积分布在统计上仍然相似。

**Conclusion:** 经过验证的NYURay推进了RT验证的进展，并为6G部署提供了可靠的信道统计数据。

> **ai_Abstract:** 本文针对射线追踪(RT)模拟器在无线数字孪生中面临的精度受限问题，提出了一种针对NYURay模拟器的站点特定位置校准算法。该算法通过优化TX-RX位置来纠正GPS误差，显著提高了位置精度。实验结果表明，校准后的NYURay在路径损耗预测方面表现出高精度，并为6G部署提供了可靠的信道统计数据，推进了RT验证方法的进步。

> **摘要翻译:** 射线追踪（RT）模拟器对于无线数字孪生至关重要，能够为下一代无线系统提供精确的站点特定无线信道预测。然而，RT模拟的准确性常常受限于测量数据不足和缺乏系统性验证。本文介绍了NYU内部开发的射线追踪器NYURay在上中频段（6.75 GHz和16.95 GHz）的站点特定位置校准和验证。我们提出了一种位置校准算法，通过优化发射机-接收机（TX-RX）位置来校正GPS引起的位置误差，以使模拟和测量的功率延迟剖面保持一致，从而将视距（LOS）场景下的TX-RX位置精度提高了42.3%，非视距（NLOS）场景下提高了13.5%。在18个TX-RX位置进行的验证显示，在路径损耗预测方面具有出色的RT精度，路径损耗指数（PLE）偏差低于0.14。尽管RT低估了延迟扩展和角度扩展，但它们的累积分布在统计上仍然相似。经过验证的NYURay推动了RT验证的进展，并为6G部署提供了可靠的信道统计数据。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [803] [Joint Multitarget Detection and Tracking with mmWave Radar](https://arxiv.org/abs/2412.17211)
> *毫米波雷达联合多目标检测与跟踪*

*Jiang Zhu, Menghuai Xu, Ruohai Guo, Fangyong Wang, Guangying Zheng, Fengzhong Qu* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** 毫米波雷达, 多目标检测, 目标跟踪, MNOMP-SPA-KF, 数据关联

**Comment:** 

> **TL;DR:** 该论文提出了一种名为MNOMP-SPA-KF的端到端框架，用于毫米波雷达的多目标检测、估计和跟踪，并通过实验证明了其有效性。

**AI_Comments:** 该论文提出了一种创新的端到端框架MNOMP-SPA-KF，集成了多种先进算法，如2D-MNOMP、SPA和KF，以解决毫米波雷达多目标检测和跟踪中的关键问题。特别是在低复杂度、超分辨率检测以及弱目标检测方面的改进，显示了其潜在的应用价值，有助于推动智能系统和自动化发展。

<details>
  <summary>Details</summary>

**Motivation:** 准确的毫米波雷达目标检测和跟踪是实现更智能、高效、自动化系统的关键传感能力。

**Method:** 本文提出了一种名为MNOMP-SPA-KF的端到端检测-估计-跟踪框架，包括目标检测和估计模块、数据关联(DA)模块和目标跟踪模块。在目标估计和检测模块中，设计了低复杂度、超分辨率和基于恒定虚警率(CFAR)的二维多快照牛顿正交匹配追踪(2D-MNOMP)来提取径向距离和速度，并结合Bartlett波束形成器提取方位角。在DA模块中，采用乘积和算法(SPA)结合径向速度信息获取目标和测量之间的关联概率。在目标跟踪模块中，利用估计器的渐近分布，实现卡尔曼滤波器(KF)进行目标跟踪。为提高弱目标检测概率，还引入了外推法。

**Result:** 数值和真实数据实验表明，与其它基准算法相比，MNOMP-SPA-KF算法是有效的。

**Conclusion:** MNOMP-SPA-KF算法能够有效实现毫米波雷达的多目标检测和跟踪，并且在弱目标检测方面表现良好。

> **ai_Abstract:** 本文提出了一种名为MNOMP-SPA-KF的毫米波雷达多目标检测、估计和跟踪的端到端框架。该框架结合了2D-MNOMP进行目标检测和参数估计，SPA进行数据关联，以及KF进行目标跟踪。为增强弱目标检测能力，还引入了外推法。实验结果验证了该算法的有效性。

> **摘要翻译:** 使用毫米波雷达进行精确的目标检测和跟踪是一项关键的传感能力，它将使更智能的系统成为可能，并创建智能、高效、自动化的系统。本文提出了一种名为MNOMP-SPA-KF的端到端检测-估计-跟踪框架，包括目标检测和估计模块、数据关联（DA）模块和目标跟踪模块。在目标估计和检测模块中，设计了一种低复杂度、超分辨率和基于恒定虚警率（CFAR）的二维多快照牛顿正交匹配追踪（2D-MNOMP），用于提取多目标的径向距离和速度，随后使用传统的（Bartlett）波束形成器提取多目标的方位角。在DA模块中，采用乘积和算法（SPA）通过结合径向速度信息来获得现有目标和测量之间的关联概率。在目标跟踪模块中，利用估计器的渐近分布，实现卡尔曼滤波器（KF）进行目标跟踪。为了提高弱目标的检测概率，外推法也被耦合到MNOMP-SPA-KF中。数值和真实数据实验表明，与其它基准算法相比，MNOMP-SPA-KF算法是有效的。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [859] [Faster-Than-Nyquist Equalization with Convolutional Neural Networks](https://arxiv.org/abs/2501.11594)
> *基于卷积神经网络的超奈奎斯特均衡*

*Bruno De Filippo, Carla Amatetti, Alessandro Vanelli-Coralli* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** 超奈奎斯特信号, 卷积神经网络, 均衡, 符号间干扰, 频谱效率

**Comment:** Accepted for presentation at the 2025 IEEE 36th International
  Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), 1-4
  September, 2025, Istanbul (Turkey)

> **TL;DR:** 本文提出了一种基于跳跃连接卷积神经网络的深度学习架构，用于超奈奎斯特（FTN）接收机中的符号间干扰（ISI）均衡和符号解调，该架构在性能上优于现有基准，实现了更高的有效吞吐量和接近AWGN信道的误码率。

**AI_Comments:** 该论文创新性地将带有跳跃连接的卷积神经网络应用于超奈奎斯特（FTN）信号的均衡和解调，有效解决了长期存在的符号间干扰问题。其重要性在于，通过深度学习显著提升了FTN系统的频谱效率和吞吐量，超越了传统和基于DNN的基准，为未来高速无线通信系统提供了新的解决方案。代码开源也极大地促进了研究的可复现性和进一步发展。

<details>
  <summary>Details</summary>

**Motivation:** 超奈奎斯特（FTN）信号技术旨在通过突破奈奎斯特-香农采样定理的限制来提高无线通信系统的频谱效率。然而，采用FTN信号需要解决接收端的符号间干扰（ISI）模式均衡问题。受卷积神经网络（带有跳跃连接）的模式识别能力的启发，研究人员提出了这种深度学习架构来解决ISI均衡问题。

**Method:** 本文提出了一种基于带有跳跃连接的卷积神经网络的深度学习架构，用于FTN接收机中的ISI均衡和符号解调。该模型在考虑正交相移键控（QPSK）调制和低密度奇偶校验（LDPC）编码的情况下进行了性能评估，并与频域均衡、基于二次规划的接收机以及基于深度神经网络的均衡方案等一系列基准进行了比较。

**Result:** 研究表明，所提出的接收机优于所有基准，实现了与加性高斯白噪声（AWGN）信道相当的误码率，并且由于FTN信号的频谱效率提高，实现了更高的有效吞吐量。在60%的压缩因子和3/4的码率下，该模型在仅10dB的每比特能量与噪声功率谱密度比下，实现了2.5 Mbps的峰值有效吞吐量，而其他接收机由于强烈的符号间干扰而受到误码平层的限制。

**Conclusion:** 本文提出的基于卷积神经网络的深度学习接收机在超奈奎斯特（FTN）系统中表现出卓越的ISI均衡和符号解调能力，显著提升了频谱效率和有效吞吐量，超越了现有基准，证明了深度学习在未来无线通信中的巨大潜力。

> **ai_Abstract:** 本文提出了一种基于带有跳跃连接的卷积神经网络的深度学习架构，用于解决超奈奎斯特（FTN）信号中的符号间干扰（ISI）均衡和符号解调问题。该模型在正交相移键控调制和低密度奇偶校验编码下进行了性能评估，并与多种现有均衡方案进行对比。实验结果表明，所提出的接收机在误码率和有效吞吐量方面均优于现有基准，能够有效利用FTN信号提升频谱效率，并在强ISI环境下表现出鲁棒性。研究代码已开源，以促进可复现性。

> **摘要翻译:** 超奈奎斯特（FTN）信号旨在通过超越奈奎斯特-香农采样定理设定的界限来提高无线通信系统的频谱效率。在其首次在科学文献中引入50年后，无线通信发生了显著变化，但频谱效率仍然是关键挑战之一。为了采用FTN信号，需要在接收端对符号间干扰（ISI）模式进行均衡。受带有跳跃连接的卷积神经网络的模式识别能力的启发，我们提出了一种用于FTN接收机中ISI均衡和符号解调的深度学习架构。我们研究了所提出模型在考虑正交相移键控调制和低密度奇偶校验编码时的性能，并将其与一系列基准进行了比较，包括频域均衡、基于二次规划的接收机以及基于深度神经网络的均衡方案。我们表明，我们的接收机优于任何基准，实现了与加性高斯白噪声信道相当的误码率，并且由于FTN信号的频谱效率提高，实现了更高的有效吞吐量。在60%的压缩因子和3/4的码率下，所提出的模型在仅10dB的每比特能量与噪声功率谱密度比下，实现了2.5 Mbps的峰值有效吞吐量，而其他接收机由于强烈的符号间干扰而受到误码平层的限制。为了促进无线通信领域深度学习的可复现性，我们的代码在参考文献中提供的仓库中开源。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [915] [A Neural Network-aided Low Complexity Chase Decoder for URLLC](https://arxiv.org/abs/2506.10513)
> *一种神经网络辅助的URLLC低复杂度Chase译码器*

*Enrico Testi, Enrico Paolini* | **Category: eess.SP** | **Updated: 2025-07-29**

**Keywords:** URLLC, Chase译码, 神经网络, 低复杂度, 译码

**Comment:** 

> **TL;DR:** 本文提出了一种神经网络辅助的增强型Chase-II译码算法，通过预测扰动模式，显著减少了URLLC系统中译码所需的试验次数，兼具准最大似然译码的可靠性和神经网络推理的效率。

**AI_Comments:** 本文的创新点在于将神经网络引入到Chase-II译码中，以解决传统准最大似然译码计算复杂度过高的问题。通过利用NN的预测能力，有效减少了译码试验次数，为URLLC的实际部署提供了一种高效且可靠的解决方案。这是一个将AI技术应用于通信物理层信号处理的典型案例，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 超可靠低延迟通信（URLLC）要求在严格的延迟约束下，译码算法同时提供高可靠性和低复杂度。现有的LDPC和Polar码迭代译码方案在URLLC短块长度下无法接近理论性能极限，而Chase-II等准最大似然译码方案虽然接近最优译码，但计算成本过高，不适合实际部署。

**Method:** 本文提出了一种增强型Chase-II译码算法，该算法利用神经网络（NN）预测有希望的扰动模式，从而大幅减少所需的译码试验次数。

**Result:** 该方法显著减少了所需的译码试验次数，并将准最大似然译码的可靠性与神经网络推理的效率相结合。

**Conclusion:** 所提出的方法非常适合时间敏感和资源受限的应用。

> **ai_Abstract:** 本文针对URLLC中译码算法在可靠性、复杂度和延迟之间的挑战，提出了一种神经网络辅助的增强型Chase-II译码算法。该方法利用神经网络预测有效的扰动模式，显著降低了传统Chase-II译码所需的计算量，同时保持了准最大似然译码的高可靠性，使其适用于资源受限的URLLC系统。

> **摘要翻译:** 超可靠低延迟通信（URLLC）要求译码算法在严格的延迟约束下，同时提供高可靠性和低复杂度。虽然LDPC和Polar码的迭代译码方案在性能和复杂度之间提供了良好的折衷，但在典型的URLLC短块长度范围内，它们未能接近理论性能极限。相反，代数码的准最大似然译码方案，如Chase-II译码，与最优译码的差距更小，但对于URLLC系统的实际部署而言，计算成本过高。为了弥补这一差距，我们提出了一种增强型Chase-II译码算法，该算法利用神经网络（NN）预测有希望的扰动模式，从而大幅减少所需的译码试验次数。所提出的方法结合了准最大似然译码的可靠性与神经网络推理的效率，使其非常适合时间敏感和资源受限的应用。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [213] [Comparative Analysis of Vision Transformers and Convolutional Neural Networks for Medical Image Classification](https://arxiv.org/abs/2507.21156)
> *视觉Transformer与卷积神经网络在医学图像分类中的比较分析*

*Kunal Kawadkar* | **Category: eess.IV, cs.CV, cs.LG, I.2.10; I.4.8** | **Updated: 2025-07-24**

**Keywords:** Vision Transformers, Convolutional Neural Networks, Medical Image Classification, Task-specific, Deep Learning

**Comment:** 9 pages, 8 figures, 3 tables. Submitted to IEEE Access

> **TL;DR:** 本研究比较了Vision Transformers (ViTs) 和卷积神经网络 (CNNs) 在三种医学图像分类任务中的性能。结果显示不同任务下，表现最佳的模型不同，强调了医学AI应用中任务特定架构选择的重要性。

**AI_Comments:** 这项研究具有重要的实践意义，因为它直接比较了两种主流深度学习架构在实际医学图像任务中的表现。其创新之处在于系统性地评估了ViT和CNN在多个医学领域的适用性，并明确指出没有“一刀切”的最佳模型，强调了任务特定优化的必要性。这为医学AI开发者提供了宝贵的指导，有助于提高临床决策支持系统的准确性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Vision Transformers (ViTs) 在计算机视觉领域取得了革命性进展，但它们与传统卷积神经网络 (CNNs) 在医学图像处理中的相对有效性尚未得到充分探索。

**Method:** 本研究对CNN和ViT架构在胸部X射线肺炎检测、脑肿瘤分类和皮肤癌黑色素瘤检测三个关键医学成像任务中进行了全面的比较分析。评估了四种最先进的模型：ResNet-50、EfficientNet-B0、ViT-Base和DeiT-Small，使用了总计8,469张医学图像的数据集。

**Result:** 研究结果表明模型在特定任务上表现出各自的优势：ResNet-50在胸部X射线分类中达到98.37%的准确率，DeiT-Small在脑肿瘤检测中表现最佳，准确率为92.16%，EfficientNet-B0在皮肤癌分类中以81.84%的准确率领先。

**Conclusion:** 这些发现为医学AI应用中选择架构的实践者提供了重要见解，强调了在临床决策支持系统中进行任务特定架构选择的重要性。

> **ai_Abstract:** 本研究对Vision Transformers (ViTs) 和卷积神经网络 (CNNs) 在医学图像分类中的性能进行了比较分析。通过在胸部X射线、脑肿瘤和皮肤癌检测三个任务上评估ResNet-50、EfficientNet-B0、ViT-Base和DeiT-Small四种模型，研究发现不同模型在不同任务上表现出最佳性能，例如ResNet-50在胸部X射线分类中准确率最高，DeiT-Small在脑肿瘤检测中表现出色，而EfficientNet-B0在皮肤癌分类中领先。研究强调了在医学AI应用中根据具体任务选择合适模型架构的重要性。

> **摘要翻译:** 视觉Transformer（ViT）的出现彻底改变了计算机视觉领域，然而与传统卷积神经网络（CNN）相比，它们在医学成像中的有效性仍未得到充分探索。本研究对CNN和ViT架构在三个关键医学成像任务中进行了全面的比较分析：胸部X射线肺炎检测、脑肿瘤分类和皮肤癌黑色素瘤检测。我们评估了四种最先进的模型——ResNet-50、EfficientNet-B0、ViT-Base和DeiT-Small——使用了总计8,469张医学图像的数据集。我们的结果表明了模型在特定任务上的优势：ResNet-50在胸部X射线分类中取得了98.37%的准确率，DeiT-Small在脑肿瘤检测中表现出色，准确率为92.16%，EfficientNet-B0在皮肤癌分类中以81.84%的准确率领先。这些发现为医学AI应用中选择架构的实践者提供了关键见解，强调了在临床决策支持系统中进行任务特定架构选择的重要性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [269] [Querying GI Endoscopy Images: A VQA Approach](https://arxiv.org/abs/2507.21165)
> *查询胃肠道内窥镜图像：一种VQA方法*

*Gaurav Parajuli* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-25**

**Keywords:** 视觉问答, 胃肠道内窥镜, 医学影像, Florence2, AI诊断

**Comment:** 

> **TL;DR:** 本研究探讨了如何将Florence2模型应用于胃肠道内窥镜图像的医学视觉问答（VQA），以解决现有通用VQA模型在医学领域表现不佳的问题。

**AI_Comments:** 这项研究通过将Florence2模型应用于医学专业领域的VQA，解决了通用VQA模型在医学成像领域表现不佳的关键问题，显示了其在开发高效AI诊断系统方面的创新性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** VQA在医学诊断AI系统中具有巨大潜力，可以帮助临床医生准确高效地诊断胃肠道疾病。然而，现有的多模态大型语言模型（LLMs）在医学成像等专业领域的VQA任务上表现非常差。

**Method:** 本研究是ImageCLEFmed-MEDVQA-GI 2025子任务1的提交，探索了Florence2模型在胃肠道内窥镜图像上回答医学视觉问题时的适应性。模型性能使用ROUGE、BLEU和METEOR等标准指标进行评估。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了将视觉问答（VQA）技术应用于胃肠道内窥镜图像的医学诊断。鉴于当前通用VQA模型在医学专业领域表现不佳，研究者将Florence2模型应用于胃肠道内窥镜图像的医学视觉问答任务，旨在提高诊断效率和准确性。该研究作为ImageCLEFmed-MEDVQA-GI 2025子任务1的一部分，并通过ROUGE、BLEU和METEOR等标准指标评估了模型性能。

> **摘要翻译:** 视觉问答（VQA）结合了自然语言处理（NLP）和图像理解，以回答关于给定图像的问题。它在开发医学诊断AI系统方面具有巨大潜力。这样的系统可以帮助临床医生准确高效地诊断胃肠道疾病。尽管当今许多可用的多模态大型语言模型在通用领域具有出色的VQA能力，但它们在医学成像等专业领域的VQA任务上表现非常差。本研究是ImageCLEFmed-MEDVQA-GI 2025子任务1的提交，旨在探索Florence2模型适应于回答胃肠道内窥镜图像上的医学视觉问题。我们还使用ROUGE、BLEU和METEOR等标准指标评估了模型性能。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [276] [SurgiSR4K: A High-Resolution Endoscopic Video Dataset for Robotic-Assisted Minimally Invasive Procedures](https://arxiv.org/abs/2507.00209)
> *SurgiSR4K: 一个用于机器人辅助微创手术的高分辨率内窥镜视频数据集*

*Fengyi Jiang, Xiaorui Zhang, Lingbo Jin, Ruixing Liang, Yuxin Chen, Adi Chola Venkatesh, Jason Culman, Tiantian Wu, Lirong Shao, Wenqing Sun, Cong Gao, Hallie McNamara, Jingpei Lu, Omid Mohareri* | **Category: eess.IV, cs.AI, cs.CV, cs.RO** | **Updated: 2025-07-29**

**Keywords:** 高分辨率, 内窥镜视频, 数据集, 机器人辅助手术, 微创手术

**Comment:** 

> **TL;DR:** SurgiSR4K是首个公开的高分辨率（4K）内窥镜视频数据集，专为机器人辅助微创手术设计，旨在填补现有4K数据集的空白，并支持多种计算机视觉任务的研发。

**AI_Comments:** SurgiSR4K的创新之处在于它是首个公开的原生4K分辨率机器人辅助微创手术数据集，填补了该领域的数据空白。其重要性在于为高分辨率计算机视觉算法在手术领域的研发提供了关键资源，有望显著提升手术图像引导的精度和安全性。数据集包含的复杂视觉场景也使其更具现实意义和挑战性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管4K内窥镜系统日益普及，但目前缺乏专门针对机器人辅助微创手术的公开原生4K数据集，这限制了高分辨率图像在计算机辅助指导中的应用。

**Method:** 我们引入了SurgiSR4K，这是首个公开可用的原生4K分辨率手术图像和视频数据集，它捕捉了机器人辅助手术的真实场景。

**Result:** SurgiSR4K数据集包含了高光反射、工具遮挡、出血和软组织变形等多种视觉场景，旨在反映腹腔镜和机器人手术中常见的挑战。该数据集为超分辨率、烟雾去除、手术器械检测、3D组织重建、单目深度估计、实例分割、新视角合成和视觉-语言模型开发等广泛的计算机视觉任务提供了可能性。

**Conclusion:** SurgiSR4K数据集为高分辨率手术成像研究奠定了坚实基础，并促进了旨在提高图像引导机器人手术性能、安全性和可用性的智能成像技术的发展。

> **ai_Abstract:** 本文介绍了SurgiSR4K，这是首个公开的、原生4K分辨率的内窥镜视频数据集，专为机器人辅助微创手术设计。该数据集旨在填补当前高分辨率手术数据稀缺的空白，包含了多种复杂的真实手术场景，如反射、遮挡和组织变形。SurgiSR4K为超分辨率、器械检测、3D重建等多种计算机视觉任务提供了基础，有望推动高分辨率手术成像和智能图像引导技术的发展。

> **摘要翻译:** 高分辨率成像对于增强视觉清晰度和实现微创手术（MIS）中精确的计算机辅助指导至关重要。尽管4K内窥镜系统日益普及，但目前仍缺乏专门为机器人辅助微创手术量身定制的公开原生4K数据集。我们引入了SurgiSR4K，这是首个公开可用的原生4K分辨率手术图像和视频数据集，它代表了机器人辅助手术的真实条件。SurgiSR4K包含多种视觉场景，包括高光反射、工具遮挡、出血和软组织变形，这些都经过精心设计，以反映腹腔镜和机器人手术中常见的挑战。该数据集为可能受益于高分辨率数据的广泛计算机视觉任务提供了可能性，例如超分辨率（SR）、烟雾去除、手术器械检测、3D组织重建、单目深度估计、实例分割、新视角合成和视觉-语言模型（VLM）开发。SurgiSR4K为推进高分辨率手术成像研究提供了坚实的基础，并促进了旨在提高图像引导机器人手术性能、安全性和可用性的智能成像技术的发展。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [325] [ST-DAI: Single-shot 2.5D Spatial Transcriptomics with Intra-Sample Domain Adaptive Imputation for Cost-efficient 3D Reconstruction](https://arxiv.org/abs/2507.21516)
> *ST-DAI：单次2.5D空间转录组与样本内域自适应插补，用于经济高效的3D重建*

*Jiahe Qian, Yaoyu Fang, Xinkun Wang, Lee A. Cooper, Bo Zhou* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 空间转录组, 3D重建, 域自适应, 插补, 成本效益

**Comment:** 21 pages, 4 figures, 3 tables, under review

> **TL;DR:** ST-DAI是一种经济高效的3D空间转录组方法，通过单次2.5D采样和样本内域自适应插补，从稀疏采样的切片重建完整的3D数据。

**AI_Comments:** 该论文的创新之处在于其“单次”和“样本内域自适应插补”方法，显著降低了实验成本，且不依赖于大型外部数据集，从而提高了泛化能力。对齐、伪监督、参数高效域对齐层（PDLs）和置信度评分生成器（CSG）的结合使用，使得插补过程更加稳健，是其方法学上的亮点。该研究为3D空间转录组的普及提供了经济高效的解决方案，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 3D空间转录组的每个切片采集成本高昂是一个重大挑战。现有方法需要大型外部数据集，导致成本高且存在显著的领域差异，在新样本上泛化性差。

**Method:** 本文提出了ST-DAI，一个用于3D空间转录组的单次框架。首先，在经济高效的2.5D采样阶段，一个参考（中心）切片被完全采样，而其他（相邻）切片被稀疏采样。其次，提出了一种单次3D插补学习方法，仅使用样本特异性训练，从这种经济高效的2.5D空间转录组方案生成完全采样的3D空间转录组。为解决切片间的错位和领域差异问题，该方法首先将中心切片与相邻切片对齐，然后生成中心切片的密集伪监督，接着执行快速多域细化（FMDR），通过参数高效域对齐层（PDLs）仅微调少量参数，使网络适应相邻切片的域。在细化过程中，置信度评分生成器（CSG）根据估计的可靠性重新加权伪标签，从而引导插补到可信区域。

**Result:** ST-DAI实现了与完全采样方法相当的基因表达预测性能，同时大幅降低了测量负担。

**Conclusion:** ST-DAI为3D空间转录组提供了一种经济高效的解决方案，其性能与完全采样方法相当。

> **ai_Abstract:** ST-DAI是一种新颖的单次框架，用于解决3D空间转录组高成本问题。它采用2.5D采样方案，即中心切片完全采样，相邻切片稀疏采样。通过样本内域自适应插补框架，结合对齐、伪监督、快速多域细化（FMDR）及参数高效域对齐层（PDLs），并利用置信度评分生成器（CSG）处理错位和领域差异，从而从稀疏数据重建完整的3D信息。该方法在显著降低成本的同时，实现了与完全采样方法相当的基因表达预测性能。

> **摘要翻译:** 对于3D空间转录组（ST），完全采样每个组织切片的高昂单切片采集成本仍然是一个重大挑战。尽管最近的方法可以从组织学图像中预测基因表达，但这些方法需要大型外部数据集，这导致成本高昂，并且存在显著的领域差异，导致在新样本上的泛化性差。在这项工作中，我们引入了ST-DAI，一个用于3D ST的单次框架，它将经济高效的2.5D采样方案与样本内域自适应插补框架相结合。首先，在经济高效的2.5D采样阶段，一个参考切片（中心切片）被完全采样，而其他切片（相邻切片）被稀疏采样，从而以显著降低的实验成本捕获体积上下文。其次，我们提出了一种单次3D插补学习方法，该方法允许我们仅使用样本特异性训练，从这种经济高效的2.5D ST方案生成完全采样的3D ST。我们观察到切片之间的位置错位和领域差异。为了解决这些问题，我们采用了一个流程，首先将中心切片与相邻切片对齐，然后生成中心切片上的密集伪监督，然后执行快速多域细化（FMDR），通过使用参数高效域对齐层（PDLs）仅微调少量参数，使网络适应相邻切片的域。在细化过程中，置信度评分生成器（CSG）根据其估计的可靠性重新加权伪标签，从而引导插补到可信区域。我们的实验结果表明，ST-DAI实现了与完全采样方法相当的基因表达预测性能，同时大幅降低了测量负担。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [380] [Control Copy-Paste: Controllable Diffusion-Based Augmentation Method for Remote Sensing Few-Shot Object Detection](https://arxiv.org/abs/2507.21816)
> *Control Copy-Paste：一种用于遥感小样本目标检测的可控扩散增强方法*

*Yanxing Liu, Jiancheng Pan, Bingchen Zhang* | **Category: eess.IV** | **Updated: 2025-07-29**

**Keywords:** 小样本目标检测, 遥感图像, 扩散模型, 数据增强, 上下文多样性

**Comment:** 5 Pages, 3 figures

> **TL;DR:** 本文提出Control Copy-Paste，一种基于可控扩散的增强方法，通过将小样本新目标无缝注入到不同背景的图像中，并采用方向对齐策略，解决了遥感小样本目标检测中因背景单调导致的过拟合问题，平均提升检测性能10.76%。

**AI_Comments:** 该论文的创新点在于认识到遥感小样本目标检测中不仅目标多样性重要，上下文多样性也至关重要，并提出了一种通过可控扩散模型融合目标与多样化上下文的新颖数据增强方法。方向对齐策略进一步提升了集成效果。其重要性在于为解决遥感FSOD的过拟合问题提供了有效途径，并验证了上下文多样性的关键作用。

<details>
  <summary>Details</summary>

**Motivation:** 遥感图像小样本目标检测（FSOD）面临训练数据有限导致难以代表真实场景数据分布，从而引发过拟合问题。现有方法通过扩散模型增加目标多样性不足以解决问题，因为周围上下文也至关重要，且检测器可能过拟合于单调上下文。

**Method:** 我们提出了Control Copy-Paste，一种可控的基于扩散的增强方法。具体来说，通过条件扩散模型将小样本新目标无缝注入到具有多样化上下文的图像中。同时，开发了一种方向对齐策略来减轻实例不同纵横比引起的集成失真。

**Result:** 在公共DIOR数据集上的实验表明，我们的方法可以将检测性能平均提高10.76%。

**Conclusion:** 本文提出的Control Copy-Paste方法通过利用多样化的上下文信息，有效解决了遥感小样本目标检测中的过拟合问题，显著提升了检测性能。

> **ai_Abstract:** 本文针对遥感图像小样本目标检测（FSOD）中因数据有限和上下文单调导致的过拟合问题，提出了Control Copy-Paste方法。该方法利用可控扩散模型将小样本新目标无缝集成到多样化上下文的图像中，并引入方向对齐策略以减少集成失真。在DIOR数据集上的实验结果表明，该方法能够平均提升检测性能10.76%，有效增强了FSOD的性能。

> **摘要翻译:** 光学遥感图像的小样本目标检测（FSOD）旨在仅用少量标注边界框检测稀有目标。有限的训练数据使得难以表示真实遥感场景的数据分布，从而导致臭名昭著的过拟合问题。当前研究人员已开始利用扩散模型增强小样本新实例的多样性来解决过拟合问题。然而，单纯增加目标多样性是不够的，因为周围上下文在目标检测中也起着关键作用，并且在目标多样性足够的情况下，检测器倾向于过拟合于单调的上下文。因此，我们提出了Control Copy-Paste，一种可控的基于扩散的方法，通过利用多样化的上下文信息来提高FSOD的性能。具体来说，我们通过条件扩散模型将小样本新目标无缝注入到具有多样化上下文的图像中。我们还开发了一种方向对齐策略来减轻因实例不同纵横比引起的集成失真。在公共DIOR数据集上的实验表明，我们的方法可以将检测性能平均提高10.76%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [422] [VidFuncta: Towards Generalizable Neural Representations for Ultrasound Videos](https://arxiv.org/abs/2507.21863)
> *VidFuncta：迈向超声视频可泛化神经表征*

*Julia Wolleb, Florentin Bieder, Paul Friedrich, Hemant D. Tagare, Xenophon Papademetris* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 超声视频, 隐式神经表征, VidFuncta, 视频分析, 深度学习

**Comment:** Accepted 6th International Workshop of Advances in Simplifying
  Medical UltraSound (ASMUS) to be held at MICCAI 2025

> **TL;DR:** VidFuncta 提出了一种新的隐式神经表征框架，能够将变长超声视频编码为紧凑、时序解析的表征，解决了标准深度学习方法在超声视频分析中的泛化性问题，并在多个下游任务中表现优异。

**AI_Comments:** VidFuncta 的创新之处在于将隐式神经表征（INRs）扩展到超声视频的时间域，通过解耦视频表征，有效应对了超声数据不标准化和操作者偏差带来的挑战。其将变长视频编码为紧凑表征的能力，以及在多个下游任务上的验证，显示了其作为通用超声视频分析框架的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度学习方法在全视频超声分析中面临挑战，因为超声采集不标准化且存在操作者偏差。本文旨在通过隐式神经表征（INRs）为超声视频分析提供新视角，解决 Functa 框架在医学视频时间域扩展上的空白。

**Method:** 本文提出了 VidFuncta 框架，它基于 Functa 构建，能够将变长超声视频编码为紧凑、时序解析的表征。VidFuncta 将每个视频解耦为静态的视频特定向量和一系列时间相关的调制向量，从而捕获时间动态和数据集层面的冗余。

**Result:** VidFuncta 在视频重建方面优于 2D 和 3D 基线方法，并支持下游任务直接在学习到的 1D 调制向量上操作。该方法在心脏、肺部和乳腺三个公共超声视频数据集上进行了验证，并在射血分数预测、B 线检测和乳腺病变分类等下游任务中评估了其性能，结果表明其表现良好。

**Conclusion:** VidFuncta 作为一种可泛化且高效的超声视频表征框架，具有巨大的潜力。

> **ai_Abstract:** 本文提出 VidFuncta，一个基于 Functa 的新型框架，旨在解决超声视频分析中因采集不标准化和操作者偏差导致的泛化性问题。VidFuncta 将变长超声视频编码为紧凑、时序解析的隐式神经表征，通过解耦视频为静态和时间相关向量，有效捕获视频动态和数据冗余。实验证明，VidFuncta 在视频重建上优于现有基线，并能支持下游任务直接处理其学习到的 1D 调制向量，在多个超声视频数据集和临床任务中展现出优异性能和泛化潜力。

> **摘要翻译:** 超声在临床护理中广泛应用，但由于采集不标准化和操作者偏差，标准深度学习方法在全视频分析中常常面临困难。我们通过隐式神经表征（INRs）为超声视频分析提供了一个新视角。我们基于 Functa 框架，其中每个图像都由一个调制向量表示，该向量调节一个共享神经网络。然而，其在医学视频时间域的扩展仍未被探索。为了弥补这一空白，我们提出了 VidFuncta，一个新颖的框架，它利用 Functa 将变长超声视频编码为紧凑、时序解析的表征。VidFuncta 将每个视频解耦为静态的视频特定向量和一系列时间相关的调制向量，从而捕获时间动态和数据集层面的冗余。我们的方法在视频重建方面优于 2D 和 3D 基线方法，并支持下游任务直接在学习到的 1D 调制向量上操作。我们在心脏、肺部和乳腺三个公共超声视频数据集上验证了 VidFuncta，并评估了其在射血分数预测、B 线检测和乳腺病变分类等下游任务中的性能。这些结果突出了 VidFuncta 作为超声视频可泛化且高效表征框架的潜力。我们的代码已在 https://github.com/JuliaWolleb/VidFuncta_public 公开。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [474] [Cyst-X: AI-Powered Pancreatic Cancer Risk Prediction from Multicenter MRI in Centralized and Federated Learning](https://arxiv.org/abs/2507.22017)
> *Cyst-X：基于多中心MRI集中式和联邦学习的AI胰腺癌风险预测*

*Hongyi Pan, Gorkem Durak, Elif Keles, Deniz Seyithanoglu, Zheyuan Zhang, Alpay Medetalibeyoglu, Halil Ertugrul Aktas, Andrea Mia Bejar, Ziliang Hong, Yavuz Taktak, Gulbiz Dagoglu Kartal, Mehmet Sukru Erturk, Timurhan Cebeci, Maria Jaramillo Gonzalez, Yury Velichko, Lili Zhao, Emil Agarunov, Federica Proietto Salanitri, Concetto Spampinato, Pallavi Tiwari, Ziyue Xu, Sachin Jambawalikar, Ivo G. Schoots, Marco J. Bruno, Chenchang Huang, Candice Bolan, Tamas Gonda, Frank H. Miller, Rajesh N. Keswani, Michael B. Wallace, Ulas Bagci* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 胰腺癌, IPMN, MRI, AI, 联邦学习

**Comment:** 

> **TL;DR:** Cyst-X是一个AI框架，利用多中心MRI数据预测胰腺导管内乳头状黏液性肿瘤（IPMNs）的恶性程度，在集中式和联邦学习设置中均表现出色，并发布了首个大规模多中心胰腺囊肿MRI数据集。

**AI_Comments:** Cyst-X的创新之处在于将AI应用于多中心MRI数据，用于IPMN恶性程度预测，并结合了联邦学习以解决数据隐私问题。其性能优于现有指南和专家，具有重要的临床应用潜力。发布数据集有助于推动该领域的开放研究。

<details>
  <summary>Details</summary>

**Motivation:** 胰腺癌预计到2030年将成为西方国家第二大致命恶性肿瘤，迫切需要更好的早期检测方法。目前对胰腺导管内乳头状黏液性肿瘤（IPMNs）的评估指南存在不足，常导致不必要的 Aunque手术或漏诊恶性肿瘤。

**Method:** 本文提出了Cyst-X，一个AI框架，利用MRI的卓越软组织对比度预测IPMN恶性程度。模型在来自7个机构的764名患者的723张T1加权和738张T2加权扫描数据上进行训练。同时，作者也展示了在联邦学习设置下的强大性能，实现了不共享患者数据的协作训练。

**Result:** Cyst-X模型的AUC达到0.82，显著优于京都指南（AUC=0.75）和专家放射科医生。AI衍生的影像特征与已知的临床标记物一致，并提供了生物学上有意义的见解。在联邦学习设置下也表现出强大的性能。

**Conclusion:** Cyst-X是一个有效且隐私保护的AI框架，用于预测IPMN恶性程度，其性能优于现有指南和专家。发布Cyst-X数据集将有助于推动隐私保护的AI发展和改善IPMN风险分层。

> **ai_Abstract:** Cyst-X是一个创新的AI框架，旨在利用多中心MRI数据预测胰腺导管内乳头状黏液性肿瘤（IPMNs）的恶性程度，以解决当前胰腺癌早期检测的挑战。该框架在7个机构的大规模MRI数据集上进行训练，其性能（AUC=0.82）显著优于现有指南和专家。Cyst-X还展示了在联邦学习环境下的有效性，实现了数据隐私保护的协作研究。此外，研究团队发布了Cyst-X数据集，以促进该领域的AI发展。

> **摘要翻译:** 胰腺癌预计到2030年将成为西方国家第二大致命恶性肿瘤，这凸显了对更好早期检测的迫切需求。胰腺导管内乳头状黏液性肿瘤（IPMNs）是胰腺癌的关键前兆，但目前的指南难以评估，常常导致不必要的手术或漏诊恶性肿瘤。我们提出了Cyst-X，一个AI框架，利用多中心MRI数据预测IPMN的恶性程度，其利用了MRI优于CT的卓越软组织对比度。我们的模型在来自七个机构的764名患者的723张T1加权和738张T2加权扫描数据上进行训练（AUC=0.82），显著优于京都指南（AUC=0.75）和专家放射科医生。AI衍生的影像特征与已知的临床标记物一致，并提供了生物学上有意义的见解。我们还在联邦学习设置中展示了强大的性能，从而无需共享患者数据即可实现协作训练。为了促进隐私保护的AI开发并改善IPMN风险分层，Cyst-X数据集作为首个大规模、多中心胰腺囊肿MRI数据集发布。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [530] [Cardiac-CLIP: A Vision-Language Foundation Model for 3D Cardiac CT Images](https://arxiv.org/abs/2507.22024)
> *Cardiac-CLIP：一个用于3D心脏CT图像的视觉-语言基础模型*

*Yutao Hu, Ying Zheng, Shumei Miao, Xiaolei Zhang, Jiahao Xia, Yaolei Qi, Yiyang Zhang, Yuting He, Qian Chen, Jing Ye, Hongyan Qiao, Xiuhua Hu, Lei Xu, Jiayin Zhang, Hui Liu, Minwen Zheng, Yining Wang, Daimin Zhang, Ji Zhang, Wenqi Shao, Yun Liu, Longjiang Zhang, Guanyu Yang* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-29**

**Keywords:** Cardiac-CLIP, 基础模型, 3D心脏CT, 视觉-语言, 对比学习

**Comment:** 

> **TL;DR:** Cardiac-CLIP是一个为3D心脏CT图像设计的视觉-语言基础模型，通过两阶段预训练，在心血管疾病诊断的多种下游任务中取得了最先进的性能，尤其在急性冠脉综合征的预测等复杂临床任务中表现出色。

**AI_Comments:** Cardiac-CLIP的创新在于将视觉-语言基础模型应用于3D心脏CT图像这一复杂领域，其两阶段预训练策略（结合MAE和对比学习）有效地从大量非结构化数据中学习了丰富的多模态表示。该模型在大规模真实世界数据集上的验证，以及在急性冠脉综合征预测等高难度临床任务中的卓越表现，凸显了其在推动心血管诊断智能化方面的巨大潜力和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 基础模型在医疗领域展现出巨大潜力，但在复杂心血管诊断中的应用尚未得到充分探索。

**Method:** 本文提出了Cardiac-CLIP，一个多模态基础模型，专为3D心脏CT图像设计。它通过两阶段预训练策略开发：第一阶段使用3D掩码自编码器（MAE）从大规模未标记体积数据中进行自监督表示学习；第二阶段引入对比学习以对齐视觉和文本表示。为支持预训练，收集了16641份真实临床CT扫描和114k份公开数据。同时，将自由文本放射学报告标准化为统一模板，并根据诊断属性构建病理向量，生成软标签矩阵以监督对比学习过程。为评估模型，收集了来自12个独立机构的6722份真实临床数据和开源数据构建评估数据集，并在心血管异常分类、信息检索和临床分析等多项任务中进行综合评估。

**Result:** 实验结果表明，Cardiac-CLIP在内部和外部数据的各种下游任务中均达到了最先进的性能。特别地，Cardiac-CLIP在支持复杂临床任务（如急性冠脉综合征的前瞻性预测）方面表现出卓越的有效性。

**Conclusion:** Cardiac-CLIP作为一个为3D心脏CT图像设计的视觉-语言基础模型，通过其创新的两阶段预训练方法和大规模数据的支持，在心血管诊断领域展现出强大的能力和广泛的应用前景，特别是在解决复杂且具有挑战性的临床预测任务上。

> **ai_Abstract:** Cardiac-CLIP是一个专为3D心脏CT图像设计的多模态视觉-语言基础模型。该模型采用两阶段预训练策略：首先通过3D掩码自编码器进行自监督学习，然后利用对比学习对齐视觉与文本表示。研究团队收集了大规模临床CT图像和放射学报告数据进行训练，并通过标准化报告构建软标签矩阵。在心血管异常分类、信息检索和临床分析等任务上的综合评估显示，Cardiac-CLIP在内部和外部数据上均取得了最先进的性能，尤其在急性冠脉综合征等复杂临床预测任务中展现出显著效果。

> **摘要翻译:** 基础模型在医学领域展现出卓越的潜力。然而，它们在复杂心血管诊断中的应用仍未得到充分探索。在本文中，我们提出了Cardiac-CLIP，一个为3D心脏CT图像设计的多模态基础模型。Cardiac-CLIP通过两阶段预训练策略开发。第一阶段采用3D掩码自编码器（MAE）从大规模未标记的体积数据中进行自监督表示学习，使视觉编码器能够捕获丰富的解剖和上下文特征。在第二阶段，引入对比学习以对齐视觉和文本表示，促进跨模态理解。为支持预训练，我们收集了16641份真实临床CT扫描，并辅以114k份公开可用数据。同时，我们将自由文本放射学报告标准化为统一模板，并根据诊断属性构建病理向量，在此基础上生成软标签矩阵以监督对比学习过程。另一方面，为了全面评估Cardiac-CLIP的有效性，我们从12个独立机构收集了6722份真实临床数据，并结合开源数据构建评估数据集。具体而言，Cardiac-CLIP在心血管异常分类、信息检索和临床分析等多项任务中进行了全面评估。实验结果表明，Cardiac-CLIP在内部和外部数据的各种下游任务中均达到了最先进的性能。特别是，Cardiac-CLIP在支持复杂临床任务（如急性冠脉综合征的前瞻性预测）方面表现出卓越的有效性，这在现实世界场景中是众所周知的困难。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [587] [ReXGroundingCT: A 3D Chest CT Dataset for Segmentation of Findings from Free-Text Reports](https://arxiv.org/abs/2507.22030)
> *ReXGroundingCT：一个用于从自由文本报告中分割发现的3D胸部CT数据集*

*Mohammed Baharoon, Luyang Luo, Michael Moritz, Abhinav Kumar, Sung Eun Kim, Xiaoman Zhang, Miao Zhu, Mahmoud Hussain Alabbad, Maha Sbayel Alhazmi, Neel P. Mistry, Kent Ryan Kleinschmidt, Brady Chrisler, Sathvik Suryadevara, Sri Sai Dinesh Jaliparthi, Noah Michael Prudlo, Mark David Marino, Jeremy Palacio, Rithvik Akula, Hong-Yu Zhou, Ibrahim Ethem Hamamci, Scott J. Adams, Hassan Rayhan AlOmaish, Pranav Rajpurkar* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 3D胸部CT, 数据集, 自由文本报告, 像素级分割, 放射学AI

**Comment:** 

> **TL;DR:** ReXGroundingCT是首个将自由文本放射学发现与3D胸部CT像素级分割关联起来的手动标注数据集，填补了医学AI中连接复杂文本与精确解剖位置的空白。

**AI_Comments:** 这篇论文通过创建ReXGroundingCT数据集，填补了医学AI领域的一个关键空白，即连接自由文本放射学报告与3D图像中精确解剖位置的能力。其创新之处在于首次公开提供了手动标注的自由文本到像素级分割的链接数据集，并且结合了GPT-4进行初步提取和专家手动精修，保证了数据的质量和临床相关性。这对于发展更智能、更准确的接地放射学报告生成系统和自由文本医学分割模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数据集依赖于结构化标签或预定义类别，无法捕捉临床语言的完整表达能力。医学AI领域缺乏将复杂描述性文本（如“左下叶3毫米结节”）与其在三维空间中精确解剖位置连接起来的能力，这对于接地放射学报告生成系统至关重要。

**Method:** 提出了ReXGroundingCT数据集。该数据集包含3142个非对比胸部CT扫描，并与CT-RATE数据集中的标准化放射学报告配对。采用三阶段系统管道：首先使用GPT-4提取阳性肺部和胸膜发现，然后由专家标注员手动分割这些发现。总共标注了8028个发现，涉及16301个实体，并由经委员会认证的放射科医生进行质量控制。训练集每个发现包含最多三个代表性分割，验证集和测试集包含每个发现实体的详尽标签。

**Result:** 创建了ReXGroundingCT数据集，它是第一个公开可用的将自由文本放射学发现与3D胸部CT扫描中像素级分割关联起来的手动标注数据集。数据集中标注了8028个发现，涉及16301个实体，其中约79%是局灶性异常，21%是非局灶性异常。

**Conclusion:** ReXGroundingCT为开发和评估胸部CT中的句子级接地和自由文本医学分割模型建立了新的基准。

> **ai_Abstract:** ReXGroundingCT是一个新颖的、公开可用的3D胸部CT数据集，它创新性地将放射学报告中的自由文本描述与CT图像中的像素级分割进行手动关联。该数据集旨在解决现有医学AI模型难以理解和定位复杂临床语言的问题，通过利用GPT-4辅助提取发现并由专家进行精确分割，共标注了8028个发现。ReXGroundingCT为开发和评估能够理解自然语言并进行精确图像分割的医学AI模型提供了重要的基准。

> **摘要翻译:** 我们提出了ReXGroundingCT，这是第一个公开可用的数据集，它将自由文本放射学发现与3D胸部CT扫描中的像素级分割联系起来，并且是手动标注的。虽然之前的S数据集依赖于结构化标签或预定义类别，但ReXGroundingCT捕捉了自由文本中临床语言的完整表达能力，并将其与体素成像中空间定位的3D分割标注相结合。这解决了医学AI中的一个关键空白：将复杂的描述性文本，例如“左下叶3毫米结节”，连接到其在三维空间中的精确解剖位置的能力，这对于接地放射学报告生成系统至关重要。该数据集包含3142个非对比胸部CT扫描，并与CT-RATE数据集中的标准化放射学报告配对。使用系统化的三阶段管道，GPT-4被用于提取阳性肺部和胸膜发现，然后由专家标注员手动分割。总共标注了8028个发现，涉及16301个实体，并由经委员会认证的放射科医生进行质量控制。大约79%的发现是局灶性异常，而21%是非局灶性异常。训练集每个发现包含最多三个代表性分割，而验证集和测试集包含每个发现实体的详尽标签。ReXGroundingCT为开发和评估胸部CT中的句子级接地和自由文本医学分割模型建立了新的基准。该数据集可在https://huggingface.co/datasets/rajpurkarlab/ReXGroundingCT访问。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [697] [G$^{2}$SF-MIAD: Geometry-Guided Score Fusion for Multimodal Industrial Anomaly Detection](https://arxiv.org/abs/2503.10091)
> *G$^{2}$SF-MIAD：几何引导分数融合的多模态工业异常检测*

*Chengyu Tao, Xuanming Cao, Juan Du* | **Category: eess.IV** | **Updated: 2025-07-29**

**Keywords:** 多模态异常检测, 分数融合, 几何引导, 工业检测, 各向异性距离。

**Comment:** 

> **TL;DR:** 提出G$^{2}$SF框架，通过几何引导分数融合进行多模态工业异常检测，达到SOTA性能。

**AI_Comments:** 该论文的创新之处在于几何地重新解释异常分数，并引入通过几何引导分数融合学习的各向异性距离度量，这是一种结合多模态信息的新颖方法。用于方向感知尺度因子的LSPN也是增强判别力的关键创新。该论文为工业异常检测中有效多模态融合的挑战提供了明确的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有单模态方法信息不完整；现有多模态方法在有效整合单模态结果和提高判别力方面面临挑战。

**Method:** 将基于记忆库的单模态异常分数重新解释为局部特征空间中的各向同性欧氏距离。提出了一种新颖的几何引导分数融合（G$^{2}$SF）框架，该框架逐步学习各向异性局部距离度量作为融合任务的统一分数。通过几何编码算子，提出局部尺度预测网络（LSPN）来预测表征一阶局部特征分布的方向感知尺度因子。此外，从几何先验开发了专门的损失函数和分数聚合策略。

**Result:** 在MVTec-3D AD和Eyecandies数据集上展示了最先进的检测性能，详细的消融分析验证了每个组件的贡献。

**Conclusion:** 所提出的G$^{2}$SF-MIAD方法，通过几何引导分数融合、各向异性局部距离度量学习和LSPN，有效解决了现有多模态异常检测方法的局限性，实现了卓越的性能。

> **ai_Abstract:** 本文旨在解决多模态工业异常检测中现有方法在整合单模态结果和提高判别力方面的局限性。作者提出G$^{2}$SF（几何引导分数融合）框架，将异常分数重新解释为欧氏距离，并学习各向异性局部距离度量。该框架引入了局部尺度预测网络（LSPN）以增强判别力，并开发了专门的损失函数。在MVTec-3D AD和Eyecandies数据集上的评估表明，该方法达到了最先进的性能，验证了其有效性。

> **摘要翻译:** 工业质量检测通过在生产过程中识别缺陷产品，在现代制造业中发挥着关键作用。虽然使用3D点云或2D RGB图像的单模态方法存在信息不完整的问题，但多模态异常检测通过跨模态数据的互补融合展现出前景。然而，现有方法在有效整合单模态结果和提高判别力方面面临挑战。为了解决这些局限性，我们首先将单模态中基于记忆库的异常分数重新解释为局部特征空间中的各向同性欧氏距离。我们提出了一种新颖的几何引导分数融合（G$^{2}$SF）框架，该框架从欧氏度量动态演变而来，逐步学习各向异性局部距离度量作为融合任务的统一分数。通过几何编码算子，提出了一种新颖的局部尺度预测网络（LSPN），用于预测表征一阶局部特征分布的方向感知尺度因子，从而增强正常和异常模式之间的判别力。此外，我们从几何先验开发了专门的损失函数和分数聚合策略，以确保度量的泛化性和有效性。在MVTec-3D AD和Eyecandies数据集上的综合评估表明，我们的方法达到了最先进的检测性能，详细的消融分析验证了每个组件的贡献。我们的代码可在https://github.com/ctaoaa/G2SF获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [755] [Efficacy of Image Similarity as a Metric for Augmenting Small Dataset Retinal Image Segmentation](https://arxiv.org/abs/2507.04862)
> *图像相似性作为增强小数据集视网膜图像分割的衡量指标的有效性*

*Thomas Wallace, Ik Siong Heng, Senad Subasic, Chris Messenger* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 图像相似性, 数据增强, 视网膜图像分割, Fréchet Inception Distance, 生成对抗网络

**Comment:** 30 pages, 10 figures

> **TL;DR:** 本研究评估了图像相似度（FID）与合成图像增强小数据集视网膜图像分割性能之间的关系，发现较低的FID值能带来显著改进，且合成数据比标准增强更有效。

**AI_Comments:** 本研究通过量化图像相似性（FID）与医学图像分割模型性能提升之间的关系，为小数据集增强提供了量化依据，具有重要的实践意义。其创新之处在于揭示了合成数据和标准数据增强对FID和模型性能提升之间可能存在不同的对数正态趋势，并且合成数据在特定条件下表现出更高的有效性。研究结果对于指导合成图像生成和数据增强策略具有参考价值，但也指出这种改进可能在图像足够不相似时才发生，这提示了未来研究可以进一步探索这种阈值效应。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高机器学习模型在有限医学图像数据集上的性能，合成图像是一种可行的增强方案。本研究旨在评估图像相似性度量（如FID）与合成图像增强效果之间的关系。

**Method:** 本研究使用由渐进增长生成对抗网络（PGGAN）生成的合成图像，来增强U-Net模型在有限训练数据下对糖尿病相关黄斑水肿（DME）视网膜内液分割的性能。通过评估Fréchet Inception Distance（FID）与分割性能提升之间的关系来完成。

**Result:** 研究发现，使用标准和合成图像进行增强的行为与之前的实验结果一致。不相似（高FID）的数据集不能显著改善分割效果。随着训练集和增强数据集之间FID的降低，增强数据集对图像分割的贡献变得显著且稳健。合成和标准增强在FID与模型性能提升之间遵循不同的对数正态趋势，合成数据被证明比标准增强技术更有效。更相似的数据集（较低FID）能更有效地提高U-Net性能，但这种改进可能只在图像足够不相似时发生。

**Conclusion:** 图像相似性（FID）是评估合成图像增强效果的关键指标，较低的FID值通常能带来更显著和稳健的图像分割性能提升。合成数据在特定条件下比标准增强更有效，但最佳效果可能出现在初始图像差异较大时。

> **ai_Abstract:** 本研究探讨了图像相似性度量（Fréchet Inception Distance, FID）在利用合成图像增强小数据集视网膜图像分割任务中的有效性。通过使用PGGAN生成的合成图像增强U-Net模型对糖尿病相关黄斑水肿的分割，研究发现，数据集之间FID值越低，即图像越相似，越能带来显著且稳健的分割性能提升。此外，研究表明合成数据在某些情况下比传统的标准增强方法更有效，并且合成与标准增强在FID与性能提升之间呈现不同的对数正态关系。

> **摘要翻译:** 合成图像是增强有限医学影像数据集以提高各种机器学习模型性能的一种选择。评估合成图像质量的一个常用指标是Fréchet Inception Distance（FID），它衡量两个图像数据集的相似性。在本研究中，我们评估了该指标与合成图像所带来的改进之间的关系。这些合成图像是由渐进增长生成对抗网络（PGGAN）生成的，用于增强U-Net模型在有限训练数据下对糖尿病相关黄斑水肿（DME）视网膜内液的分割。我们发现使用标准和合成图像进行增强的行为与之前进行的实验结果一致。此外，我们发现不相似（高FID）的数据集并不能显著改善分割。随着训练集和增强数据集之间FID的降低，增强数据集被证明有助于图像分割的显著且稳健的改进。最后，我们发现有充分证据表明合成和标准增强在FID与模型性能提升之间遵循独立的对数正态趋势，其中合成数据被证明比标准增强技术更有效。我们的研究结果表明，更相似的数据集（较低FID）将更有效地提高U-Net性能，然而，结果也表明这种改进可能只在图像足够不相似时发生。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [71] [Real-Time Audio-Visual Speech Enhancement Using Pre-trained Visual Representations](https://arxiv.org/abs/2507.21448)
> *实时音视频语音增强：利用预训练视觉表征*

*Teng, Ma, Sile Yin, Li-Chia Yang, Shuo Zhang* | **Category: eess.AS, cs.ET, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 语音增强, 音视频, 实时系统, 视觉表征, RAVEN

**Comment:** Accepted into Interspeech 2025

> **TL;DR:** 本文提出了一个名为RAVEN的实时音视频语音增强系统，通过利用预训练的视觉表征来隔离和增强目标说话人，并在多说话人低信噪比环境下取得了显著效果，并提供了首个开源实现。

**AI_Comments:** 这篇论文的创新点在于提出了一个简单有效的实时音视频语音增强系统RAVEN，并且是首个开源的实时AVSE实现，这对于该领域的研究和应用具有重要意义。通过结合AVSR和ASD的视觉嵌入，该系统在复杂的多说话人低信噪比环境下表现出色，展示了多模态融合在语音增强中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 纯音频环境下的语音增强，尤其是在存在干扰说话人时，仍然面临挑战。

**Method:** 本文提出了一个名为RAVEN的实时音视频语音增强（AVSE）系统，旨在隔离和增强屏幕上的目标说话人，同时抑制干扰说话人和背景噪声。研究了从音视频语音识别（AVSR）和活跃说话人检测（ASD）中学习到的视觉嵌入如何影响不同信噪比条件和不同干扰说话人数量下的AVSE性能。

**Result:** 结果表明，在低信噪比、多说话人环境中，连接AVSR和ASD模型嵌入提供了最大的改进；而在仅有噪声的场景中，单独的AVSR嵌入表现最佳。此外，开发了一个在计算机CPU上运行的实时流媒体系统，并提供了视频演示和代码库。

**Conclusion:** 连接来自音视频语音识别（AVSR）和活跃说话人检测（ASD）模型的嵌入在低信噪比、多说话人环境下提供了最大的语音增强改进，而单独的AVSR嵌入在仅有噪声的场景中表现最佳。

> **ai_Abstract:** 本文针对纯音频语音增强中存在干扰说话人的挑战，提出了一个名为RAVEN的实时音视频语音增强（AVSE）系统。该系统利用预训练的视觉表征来识别并增强目标说话人的语音，同时抑制干扰和噪声。研究发现，结合音视频语音识别（AVSR）和活跃说话人检测（ASD）的视觉嵌入在多说话人、低信噪比环境下效果最佳，而单独的AVSR嵌入在噪声环境中表现突出。此外，作者还开发了一个高效的CPU实时流媒体系统，并将其开源，填补了实时AVSE开源实现的空白。

> **摘要翻译:** 纯音频环境下的语音增强仍然具有挑战性，尤其是在存在干扰说话人的情况下。本文提出了一种简单而有效的实时音视频语音增强（AVSE）系统RAVEN，该系统能够隔离并增强屏幕上的目标说话人，同时抑制干扰说话人和背景噪声。我们研究了从音视频语音识别（AVSR）和活跃说话人检测（ASD）中学习到的视觉嵌入如何对不同信噪比条件和不同数量干扰说话人情况下的AVSE做出贡献。我们的结果表明，连接AVSR和ASD模型的嵌入在低信噪比、多说话人环境中提供了最大的改进，而单独的AVSR嵌入在仅有噪声的场景中表现最佳。此外，我们开发了一个在计算机CPU上运行的实时流媒体系统，并提供了视频演示和代码库。据我们所知，这是第一个实时AVSE系统的开源实现。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [131] [CleanMel: Mel-Spectrogram Enhancement for Improving Both Speech Quality and ASR](https://arxiv.org/abs/2502.20040)
> *CleanMel：用于提高语音质量和ASR的梅尔频谱增强*

*Nian Shao, Rui Zhou, Pengyu Wang, Xian Li, Ying Fang, Yujie Yang, Xiaofei Li* | **Category: eess.AS, cs.AI, cs.SD** | **Updated: 2025-07-30**

**Keywords:** 梅尔频谱增强, 语音质量, 自动语音识别, 去噪, 去混响

**Comment:** Submission to IEEE/ACM Trans. on TASLP

> **TL;DR:** 提出CleanMel，一种梅尔频谱去噪去混响网络，可同时提高语音质量和ASR性能。

**AI_Comments:** 这篇论文的创新点在于提出了CleanMel模型，并强调了在梅尔频谱域进行语音增强的优势，即梅尔频率能更紧凑地表示语音，从而更容易学习，这对于同时优化语音质量和ASR性能非常重要。其方法结合了跨频带和窄频带处理，增强了模型的学习能力。实验结果也支持了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 为了同时提高语音质量和自动语音识别（ASR）性能，并利用梅尔频率域在语音表示上的紧凑性，作者提出了一个梅尔频谱增强网络。

**Method:** 提出CleanMel，一个单通道梅尔频谱去噪和去混响网络。该网络以嘈杂和混响的麦克风录音为输入，预测清晰的梅尔频谱。网络由梅尔频率域中交错的跨频带和窄频带处理组成，分别用于学习全频带频谱模式和窄频带特性。增强后的梅尔频谱可用于语音波形转换或直接用于ASR。

**Result:** 在五个英语和一个中文数据集上的实验结果表明，所提出的模型在语音质量和ASR性能方面均取得了显著改善。

**Conclusion:** CleanMel模型通过在梅尔频率域进行增强，能够有效改善语音质量和自动语音识别性能，证明了梅尔频谱增强的优势。

> **ai_Abstract:** CleanMel是一个创新的单通道梅尔频谱去噪和去混响网络，旨在同时提升语音质量和自动语音识别（ASR）性能。该网络直接在梅尔频率域处理噪声和混响的语音，通过交错的跨频带和窄频带处理学习信号特性。实验证明，CleanMel在多个数据集上显著改善了语音质量和ASR性能，验证了梅尔频谱增强的有效性。

> **摘要翻译:** 在这项工作中，我们提出了CleanMel，一个用于同时提高语音质量和自动语音识别（ASR）性能的单通道梅尔频谱去噪和去混响网络。所提出的网络将嘈杂和混响的麦克风录音作为输入，并预测相应的清晰梅尔频谱。增强后的梅尔频谱可以通过神经声码器转换为语音波形，或直接用于ASR。所提出的网络由梅尔频率域中交错的跨频带和窄频带处理组成，分别用于学习全频带频谱模式和信号的窄频带特性。与线性频率域或时域语音增强相比，梅尔频谱增强的关键优势在于梅尔频率以更紧凑的方式呈现语音，因此更容易学习，这将同时有利于语音质量和ASR。在五个英语和一个中文数据集上的实验结果表明，所提出的模型在语音质量和ASR性能方面均取得了显著改善。我们模型的代码和音频示例已在线提供。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [250] [Controllable joint noise reduction and hearing loss compensation using a differentiable auditory model](https://arxiv.org/abs/2507.09372)
> *可控的联合降噪和听力损失补偿，使用可微分听觉模型*

*Philippe Gonzalez, Torsten Dau, Tobias May* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-30**

**Keywords:** 听力损失补偿, 降噪, 可微分听觉模型, 多任务学习, 语音增强

**Comment:** Accepted to Clarity 2025 Workshop

> **TL;DR:** 本文提出了一种使用可微分听觉模型进行可控联合降噪和听力损失补偿的多任务学习系统，实现了与独立任务系统相似的性能，并能在推理时调整任务平衡。

**AI_Comments:** 这项工作的创新之处在于将降噪和听力损失补偿结合为一个可控的多任务学习问题，并利用可微分听觉模型实现直接优化。其重要性在于解决了HLC中缺乏真实目标和任务平衡的难题，提供了一个灵活且高效的解决方案，尤其是在推理时能够调整降噪和补偿的平衡，这对于实际应用中的个性化需求非常有利。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习的听力损失补偿（HLC）面临缺乏真实目标值的主要挑战。现有方法要么使用非可微分模型缺乏灵活性，要么虽然使用可微分模型但只关注个体配置文件或未平衡降噪（NR）和HLC任务。

**Method:** 将降噪（NR）和听力损失补偿（HLC）表述为一个多任务学习问题，训练一个系统，使用可微分听觉模型同时从嘈杂语音和听力图预测去噪和补偿信号。

**Result:** 该系统实现了与分别针对每个任务训练的系统相似的客观度量性能，同时能够在推理过程中调整降噪和HLC之间的平衡。

**Conclusion:** 该研究成功地将降噪和听力损失补偿结合为可控的多任务学习问题，提供了一种灵活且高效的解决方案，能够根据需求调整降噪和听力损失补偿的侧重，从而提高了听障人士的语音可懂度和质量。

> **ai_Abstract:** 本文提出了一种新颖的多任务学习方法，用于联合降噪（NR）和听力损失补偿（HLC）。针对HLC缺乏真实目标和现有可微分模型未平衡任务的挑战，该系统利用可微分听觉模型，通过嘈杂语音和听力图同时预测去噪和补偿信号。实验结果显示，该系统在客观指标上达到了与独立训练系统相当的性能，并且在推理阶段能够灵活调整降噪与HLC之间的平衡，为听障人士提供了更优的语音增强方案。

> **摘要翻译:** 基于深度学习的听力损失补偿（HLC）旨在利用神经网络提高听障人士的语音可懂度和质量。HLC的一个主要挑战是缺乏真实目标。最近的工作使用神经网络在闭环框架中模拟不可微分的听觉外周模型，但这种方法缺乏灵活性。另一方面，可微分的听觉模型允许直接优化，但以前的研究侧重于个体听众的配置文件，或在不平衡每个任务的情况下进行联合降噪（NR）和HLC。这项工作将NR和HLC表述为一个多任务学习问题，训练一个系统，使用可微分听觉模型同时从嘈杂语音和听力图预测去噪和补偿信号。结果表明，该系统实现了与分别针对每个任务训练的系统相似的客观度量性能，同时能够在推理时调整NR和HLC之间的平衡。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [909] [A k-space approach to modeling multi-channel parametric array loudspeaker systems](https://arxiv.org/abs/2507.22628)
> *多通道参量阵扬声器系统建模的k空间方法*

*Tao Zhuang, Longbiao He, Feng Niu, Jia-Xin Zhong, Jing Lu* | **Category: eess.AS, cs.SD** | **Updated: 2025-07-30**

**Keywords:** k空间方法, 多通道参量阵扬声器, 声场建模, 计算效率, 非线性声学

**Comment:** 

> **TL;DR:** 提出了一种基于k空间的高效准确建模多通道参量阵扬声器系统的方法，显著提升了计算速度。

**AI_Comments:** 这项研究的创新之处在于将k空间方法引入到多通道参量阵扬声器系统的建模中，显著解决了现有方法在计算效率上的瓶颈。其提出的方法不仅速度快、内存效率高，而且在保持精度的同时避免了近轴近似的限制，这对于复杂声场的准确预测至关重要。这将极大地推动MCPAL系统在实际应用中的发展和优化。

<details>
  <summary>Details</summary>

**Motivation:** 多通道参量阵扬声器系统在生成高方向性音频束方面具有潜力，但其声场预测因复杂的非线性行为和多通道信号处理而面临挑战。

**Method:** 该方法首先使用角谱法求解线性超声场，然后利用k空间高效计算准线性音频声场。通过三维快速傅里叶变换，该方法实现了高计算和内存效率，并保持了精度，无需依赖近轴近似。

**Result:** 对于典型配置，该方法比直接积分法快四个数量级以上。

**Conclusion:** 所提出的k空间方法为模拟和设计先进的多通道参量阵扬声器系统铺平了道路。

> **ai_Abstract:** 本研究提出了一种基于k空间的方法，用于高效准确地建模放置在障板平面上的任意多通道参量阵扬声器系统。该方法利用角谱法求解线性超声场，并结合三维快速傅里叶变换在k空间中计算准线性音频声场，从而显著提高了计算和内存效率，同时保持了精度并避免了近轴近似。实验结果表明，该方法相比传统直接积分法，计算速度提升了超过四个数量级，为先进MCPAL系统的模拟与设计提供了有效途径。

> **摘要翻译:** 多通道参量阵扬声器（MCPAL）系统在实际应用中，为生成高度定向的音频束提供了增强的灵活性和前景。然而，由于涉及复杂的非线性行为和多通道信号处理，有效且准确地预测其产生的声场仍然是一个重大挑战。为了克服这一障碍，我们提出了一种k空间方法，用于对排列在障板平面上的任意MCPAL系统进行建模。在我们的方法中，首先使用角谱法求解线性超声场，然后利用k空间高效计算准线性音频声场。通过利用三维快速傅里叶变换，我们的方法不仅实现了高计算和内存效率，而且在不依赖近轴近似的情况下保持了精度。对于所研究的典型配置，所提出的方法与直接积分法相比，计算速度提高了四个数量级以上。我们提出的方法为模拟和设计先进的MCPAL系统铺平了道路。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [6] [The role of media memorability in facilitating startups' access to venture capital funding](https://arxiv.org/abs/2507.22201)
> *媒体记忆度在促进初创企业获得风险投资中的作用*

*L. Toschi, S. Torrisi, A. Fronzetti Colladon* | **Category: cs.CL, cs.SI, physics.soc-ph, I.2.7; J.4; H.4.0** | **Updated: 2025-07-29**

**Keywords:** 媒体记忆度, 风险投资, 初创企业, 媒体声誉, 创业金融

**Comment:** 

> **TL;DR:** 研究发现媒体记忆度，而非单纯的媒体曝光，能显著影响初创企业获得风险投资，VC更关注媒体内容中企业独特性和关联性的细微线索。

**AI_Comments:** 本文的创新点在于引入了“媒体记忆度”这一新颖概念，并将其与风险投资结果关联起来，弥补了以往研究仅关注媒体曝光的不足。其重要性在于为初创企业提供了更具操作性的媒体策略建议，即关注内容质量而非数量，以更有效地吸引投资者。

<details>
  <summary>Details</summary>

**Motivation:** 先前研究过于关注一般性媒体曝光，限制了对媒体如何真正影响投资决策的理解。本文旨在引入“媒体记忆度”概念，探讨其对风险投资的影响，以填补现有研究的空白。

**Method:** 本文引入了“媒体记忆度”的概念，即媒体将初创企业名称印刻在相关投资者记忆中的能力。研究使用了来自197家英国微纳米技术领域初创企业（1995年至2004年间获得融资）的数据进行分析。

**Result:** 研究表明，媒体记忆度显著影响投资结果。风险投资者依赖于详细的线索，例如初创企业在新闻语义网络中的独特性和连通性。

**Conclusion:** 媒体记忆度对初创企业获得风险投资至关重要。研究结果有助于创业金融和媒体合法化领域的研究。实践中，初创企业应通过更有针对性、有意义的报道来加强品牌记忆度，而非仅仅追求频繁的媒体提及。

> **ai_Abstract:** 本文探讨了媒体记忆度在初创企业获得风险投资中的作用，指出以往研究仅关注普遍媒体曝光的局限性。研究引入“媒体记忆度”概念，并基于197家英国微纳米技术初创企业的数据，证明媒体记忆度显著影响投资结果。研究发现风险投资者重视媒体内容中企业的独特性和网络连通性，强调初创企业应通过有针对性的报道提升品牌记忆度。

> **摘要翻译:** 媒体声誉在吸引风险投资方面发挥着重要作用。然而，先前的研究过于狭隘地关注一般性媒体曝光，限制了我们对媒体如何真正影响融资决策的理解。作为知情的决策者，风险投资者对媒体内容的细微之处反应更敏感。我们引入了媒体记忆度的概念——媒体将初创企业名称印刻在相关投资者记忆中的能力。利用197家英国微纳米技术领域初创企业（1995年至2004年间获得融资）的数据，我们发现媒体记忆度显著影响投资结果。我们的研究结果表明，风险投资者依赖于详细的线索，例如初创企业在新闻语义网络中的独特性和连通性。这有助于创业金融和媒体合法化领域的研究。在实践中，初创企业应该超越频繁的媒体提及，通过更有针对性、更有意义的报道来加强品牌记忆度，从而突出其在更广泛的行业对话中的独特性和相关性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [13] [LIMO: Less is More for Reasoning](https://arxiv.org/abs/2502.03387)
> *LIMO：推理中的“少即是多”*

*Yixin Ye, Zhen Huang, Yang Xiao, Ethan Chern, Shijie Xia, Pengfei Liu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 数学推理, 监督微调, 少样本学习, 泛化能力

**Comment:** COLM 2025

> **TL;DR:** LIMO模型通过少量数据进行简单微调，在数学推理任务上显著超越了需要大量数据的现有模型，并提出了“少即是多”的推理假设。

**AI_Comments:** LIMO的创新之处在于颠覆了LLM复杂推理对大规模数据的依赖，证明了在具有完善预训练知识的模型中，通过精巧设计的少量示例即可激发高性能的推理能力。这对于资源受限的场景和提高模型训练效率具有重要意义。其提出的“少即是多推理假设”为未来LLM的训练和应用提供了新的理论指导，强调了知识完备性和认知模板的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 挑战了大型语言模型复杂推理需要大量训练数据的普遍假设，旨在证明通过少量示例也能实现复杂的数学推理。

**Method:** 通过简单的监督式微调（supervised fine-tuning）训练LIMO模型，仅使用了先前方法所需训练数据的1%。

**Result:** LIMO模型在AIME24上取得了63.3%的准确率，在MATH500上取得了95.6%的准确率，远超先前微调模型的表现（AIME24上6.5%，MATH500上59.2%），且只使用了1%的训练数据。此外，LIMO在不同的基准测试中展现出强大的分布外泛化能力，实现了45.8%的绝对提升，甚至优于使用100倍数据训练的模型。

**Conclusion:** 提出了“少即是多推理假设”（LIMO假设）：在预训练阶段已全面编码领域知识的基础模型中，复杂的推理能力可以通过最少但策略性设计的认知过程示例来激发。该假设表明，激发复杂推理的阈值并非由任务复杂度决定，而是由模型的预训练知识库的完整性和后训练示例作为“认知模板”指导推理的有效性这两个关键因素决定。

> **ai_Abstract:** LIMO模型通过挑战LLM复杂推理需要大量数据的传统观念，提出了一种仅需少量数据进行简单监督式微调的方法。该模型在数学推理任务上表现卓越，在AIME24和MATH500上均显著超越了现有模型，且数据使用量仅为1%。LIMO还展示了强大的分布外泛化能力。研究最终提出了“少即是多推理假设”，强调在基础模型中，复杂推理的激发关键在于完善的预训练知识和有效的认知模板示例，而非大量任务数据。

> **摘要翻译:** 我们挑战了大型语言模型（LLMs）中复杂推理需要大量训练数据的普遍假设。我们证明了通过少量示例也能实现复杂的数学推理。具体而言，通过简单的监督式微调，我们的模型LIMO在AIME24上达到了63.3%的准确率，在MATH500上达到了95.6%的准确率，超越了先前的微调模型（AIME24上6.5%，MATH500上59.2%），而我们仅使用了先前方法所需训练数据的1%。此外，LIMO展现出强大的分布外泛化能力，在不同基准测试中实现了45.8%的绝对提升，超越了使用100倍数据训练的模型。综合这些发现，我们提出了“少即是多推理假设”（LIMO假设）：在预训练阶段已全面编码领域知识的基础模型中，复杂的推理能力可以通过最少但策略性设计的认知过程示例来激发。这一假设表明，激发复杂推理的阈值并非由任务复杂度决定，而是由两个关键因素决定：(1) 模型预训练知识库的完整性；(2) 后训练示例作为指导推理的“认知模板”的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [26] [Improving Task Diversity in Label Efficient Supervised Finetuning of LLMs](https://arxiv.org/abs/2507.21482)
> *提高LLM标签高效监督微调中的任务多样性*

*Abhinav Arabelly, Jagrut Nemade, Robert D Nowak, Jifan Zhang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 监督微调, 标签高效学习, 任务多样性, 数据采样

**Comment:** 

> **TL;DR:** 通过基于任务多样性和逆置信度加权采样，提高LLM标签高效监督微调的效果和效率，同时大幅降低标注成本。

**AI_Comments:** 该论文的创新之处在于将数据选择的重点从“提示多样性”转移到“任务多样性”，并结合了模型在不同任务上的置信度来指导采样。这种逆置信度加权采样策略简单而有效，为标签高效学习提供了一个新颖且实用的视角。解决了LLM微调中人工标注成本高昂的实际问题，使得LLM在资源受限或需要快速迭代的场景下更具可行性。其在提高性能（MMLU分数）的同时大幅降低成本（高达80%）的成果具有重要实践意义。抽象中未明确提及该方法是否适用于所有类型的任务，以及“任务标签易于获取”这一前提在实际应用中的普适性。此外，对于“预训练模型置信度”的具体计算方式和其鲁棒性也未详细说明。

<details>
  <summary>Details</summary>

**Motivation:** 开发用于特定应用的LLM需要大量耗时、费力且昂贵的人工标注。

**Method:** 提出一种标签高效的监督微调（SFT）方法，通过利用任务多样性作为有效数据选择的基本原则，而非提示多样性。该方法基于两个观察：1)不同提示的任务标签通常易于获取；2)预训练模型在不同任务上的置信度差异显著。结合这些事实，设计了一种简单有效的采样策略：使用逆置信度加权策略跨任务选择样本。

**Result:** 生成的模型与使用更复杂采样程序的模型相当或更好；更易于实现且计算密集度更低；实验表明，该方法可以比在完整数据集上训练获得更好的准确性（MMLU分数提高4%）；在各种标注预算和两个指令微调数据集上，算法表现始终与现有最佳方法持平或优于现有最佳方法；将标注成本降低高达80%。

**Conclusion:** 该论文提出了一种简单有效且计算效率高的方法，通过利用任务多样性结合逆置信度加权采样，显著提高了LLM标签高效监督微调的性能，同时大幅降低了标注成本。

> **ai_Abstract:** 本文提出一种标签高效的监督微调（SFT）方法，旨在降低大型语言模型（LLMs）专业应用开发中昂贵的人工标注成本。该方法不同于现有基于提示多样性的策略，转而利用任务多样性作为数据选择的关键原则。通过结合任务标签的可用性和预训练模型在不同任务上的置信度差异，研究者设计了一种简单但有效的逆置信度加权采样策略。实验证明，该方法不仅能产生与复杂采样方法相当甚至更优的模型，且更易于实现、计算开销更小，甚至在MMLU分数上比使用完整数据集训练的模型提高了4%，同时可将标注成本降低高达80%。

> **摘要翻译:** 大型语言模型（LLMs）在不同领域展现出卓越的能力，但为专业应用开发高性能模型通常需要大量人工标注——这是一个耗时、费力且昂贵的过程。在本文中，我们通过利用任务多样性作为有效数据选择的基本原则，解决了监督微调（SFT）的标签高效学习问题。这与现有基于提示多样性的方法显著不同。我们的方法基于两个关键观察：1）不同提示的任务标签通常易于获取；2）预训练模型在不同任务上的置信度水平差异显著。我们结合这些事实，设计了一种简单而有效的采样策略：我们使用逆置信度加权策略跨任务选择示例。这产生的模型与使用更复杂采样过程训练的模型相当或更好，同时更容易实现且计算密集度更低。值得注意的是，我们的实验结果表明，该方法可以比在完整数据集上训练获得更好的准确性（MMLU分数提高4%）。在各种标注预算和两个指令微调数据集上，我们的算法始终表现与现有最佳方法持平或优于现有最佳方法，同时将标注成本降低高达80%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [30] [ChartMark: A Structured Grammar for Chart Annotation](https://arxiv.org/abs/2507.21810)
> *ChartMark：一种图表标注的结构化语法*

*Yiyu Chen, Yifan Wu, Shuyu Shen, Yupeng Xie, Leixian Shen, Hui Xiong, Yuyu Luo* | **Category: cs.CL, cs.SE** | **Updated: 2025-07-29**

**Keywords:** 图表标注, 结构化语法, 可视化, ChartMark, 跨平台重用

**Comment:** IEEE VIS 2025

> **TL;DR:** ChartMark是一种结构化语法，用于解决图表标注碎片化和非标准化的问题，从而提高跨平台重用性。它将标注语义与可视化实现分离，并通过工具包演示了其灵活性和实用性。

**AI_Comments:** ChartMark的创新在于其提出的结构化语法，能够将图表标注的语义与其视觉实现解耦，这对于提升图表标注的可重用性和标准化具有重要意义。这种方法有望解决当前图表标注工具之间互操作性差的问题，为未来的可视化工具开发奠定基础。

<details>
  <summary>Details</summary>

**Motivation:** 图表标注虽然能增强可视化可访问性，但目前面临碎片化和非标准化的表示问题，这限制了其跨平台重用。

**Method:** 本文提出了ChartMark，一种将标注语义与可视化实现分离的结构化语法。它采用分层框架，映射到标注维度（如任务、图表上下文），支持抽象意图和精确视觉细节。

**Result:** 本文的工具包演示了将ChartMark规范转换为Vega-Lite可视化，突显了其灵活性、表达性和实际适用性。

**Conclusion:** ChartMark通过提供一种结构化语法，有效地解决了图表标注的碎片化和非标准化问题，显著提高了标注的跨平台重用性和可访问性。

> **ai_Abstract:** 本文提出了一种名为ChartMark的结构化语法，旨在解决现有图表标注表示碎片化和非标准化的问题，以促进跨平台重用。ChartMark通过将标注语义与可视化实现分离，并采用分层框架来捕获不同维度的标注信息。研究人员通过一个工具包展示了ChartMark规范如何灵活、富有表达力地转换为Vega-Lite可视化，证明了其在实际应用中的潜力。

> **摘要翻译:** 图表标注增强了可视化的可访问性，但其碎片化、非标准化的表示限制了跨平台重用。我们提出了ChartMark，一种将标注语义与可视化实现分离的结构化语法。ChartMark具有一个分层框架，映射到标注维度（例如，任务、图表上下文），支持抽象意图和精确的视觉细节。我们的工具包演示了将ChartMark规范转换为Vega-Lite可视化，突出了其灵活性、表达性和实际适用性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [34] [Automatic Classification of User Requirements from Online Feedback -- A Replication Study](https://arxiv.org/abs/2507.21532)
> *自动分类在线反馈中的用户需求——一项重复性研究*

*Meet Bhatt, Nic Boilard, Muhammad Rehan Chaudhary, Cole Thompson, Jacob Idoko, Aakash Sorathiya, Gouri Ginde* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 用户需求分类, 自然语言处理, 深度学习, 重复性研究, GPT-4o

**Comment:** 10 pages, 3 figures, Replication package available at
  https://zenodo.org/records/15626782, Accepted at AIRE 2025 (12th
  International Workshop on Artificial Intelligence and Requirements
  Engineering)

> **TL;DR:** 本研究复制并扩展了一项使用深度学习从用户反馈中分类需求的研究，评估了不同模型的再现性、泛化能力，并与GPT-4o进行了比较。

**AI_Comments:** 这项重复性研究对于加强NLP4RE领域实证研究的有效性至关重要。它不仅验证了现有深度学习模型的再现性和泛化能力，还首次将新兴的GPT-4o模型引入该任务，为未来研究提供了新的基线和比较点。此外，研究中对重复性ID卡和缺失环境信息的补充，极大地提升了研究的透明度和可重复性，对促进科学研究的开放性和严谨性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 需求工程领域对NLP4RE研究的重复性关注有限，而NLP的快速发展为高效的机器辅助工作流程带来了新机遇。因此，研究人员旨在复制并扩展一项评估深度学习模型分类用户需求的先前研究，以加强其外部有效性并探索新视角。

**Method:** 研究复制并扩展了一项名为“Classifying User Requirements from Online Feedback in Small Dataset Environments using Deep Learning”的基线NLP4RE研究。他们使用公开的源代码重现了原始结果，评估了模型在外部数据集上的性能，并将结果与GPT-4o零样本分类器进行了比较。此外，他们还为基线研究准备了重复性研究ID卡，并为自己的研究提供了重复性包和ID卡。

**Result:** 不同模型的再现性水平各异，朴素贝叶斯模型表现出完美的再现性。BERT和其他模型显示出混合结果。基线深度学习模型（BERT和ELMo）在外部数据集上表现出良好的泛化能力。GPT-4o的性能与传统基线机器学习模型相当。基线研究的重复性准备就绪，但缺少环境设置文件。

**Conclusion:** 本研究成功复制并扩展了先前的NLP4RE研究，证实了基线深度学习模型的泛化能力和GPT-4o的竞争力，并强调了重复性研究的重要性，通过提供重复性包和ID卡来促进未来的重复性工作。

> **ai_Abstract:** 本研究旨在解决需求工程领域中NLP4RE研究重复性不足的问题。通过复制并扩展一项使用深度学习分类用户需求的基线研究，作者评估了不同模型的再现性、在外部数据集上的泛化能力，并首次将结果与GPT-4o零样本分类器进行了比较。研究结果表明，朴素贝叶斯具有高再现性，BERT和ELMo模型具有良好的泛化能力，而GPT-4o的性能与传统机器学习模型相当。此外，研究还强调了重复性研究的重要性，并提供了详细的重复性材料。

> **摘要翻译:** 自然语言处理（NLP）技术已广泛应用于需求工程（RE）领域，以支持分类和歧义检测等任务。尽管RE研究植根于实证调查，但其对NLP for RE（NLP4RE）研究的重复性关注有限。NLP领域的快速发展为高效的机器辅助工作流程创造了新机遇，这可以带来新的视角和结果。因此，我们复制并扩展了之前的一项NLP4RE研究（基线），即“在小数据集环境下使用深度学习对在线反馈中的用户需求进行分类”，该研究评估了不同的深度学习模型从用户评论中进行需求分类。我们使用公开发布的源代码重现了原始结果，从而有助于加强基线研究的外部有效性。然后，我们通过评估模型在外部数据集上的性能并将其结果与GPT-4o零样本分类器进行比较来扩展设置。此外，我们为基线研究准备了重复性研究ID卡，这对于评估重复性准备情况很重要。结果显示，不同模型的再现性水平各异，朴素贝叶斯表现出完美的再现性。相比之下，BERT和其他模型显示出混合结果。我们的发现表明，基线深度学习模型BERT和ELMo在外部数据集上表现出良好的泛化能力，并且GPT-4o显示出与传统基线机器学习模型相当的性能。此外，我们的评估证实了基线研究的重复性准备就绪；然而，缺少环境设置文件会进一步增强准备就绪。我们将这些缺失的信息包含在我们的重复性包中，并为我们的研究提供了重复性研究ID卡，以进一步鼓励和支持我们研究的重复。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [41] [How Well Does First-Token Entropy Approximate Word Entropy as a Psycholinguistic Predictor?](https://arxiv.org/abs/2507.22209)
> *第一词元熵作为心理语言学预测器，能多大程度上近似词熵？*

*Christian Clark, Byung-Doh Oh, William Schuler* | **Category: cs.CL** | **Updated: 2025-07-29**

**Keywords:** 上下文熵, 词熵, 第一词元熵, 蒙特卡洛估计, 心理语言学

**Comment:** 

> **TL;DR:** 在心理语言学中，第一词元熵对词熵的近似效果不佳，需要谨慎使用。

**AI_Comments:** 这篇论文对于心理语言学领域具有重要意义，因为它挑战了广泛使用的上下文熵近似方法（第一词元熵）。通过证明其不准确性并提出更稳健的蒙特卡洛估计方法，它有助于该领域更精确的测量，可能提高未来心理语言学研究中词汇处理难度的可靠性。其创新之处在于严格测试并提供了一种替代现有便捷但可能存在缺陷的方法。

<details>
  <summary>Details</summary>

**Motivation:** 为了方便，上下文熵通常基于语言模型对单词第一个子词词元的概率分布进行估计。然而，这种近似会导致真实词熵的低估和潜在扭曲，因此需要更准确的估计方法。

**Method:** 为了解决现有问题，研究人员生成了蒙特卡洛（MC）估计的词熵，这种方法允许单词跨越可变数量的词元，从而提供更准确的度量。

**Result:** 阅读时间的回归实验显示，第一词元熵和MC词熵之间存在不同的结果。

**Conclusion:** 研究结果表明，在使用上下文熵的第一词元近似时需要谨慎。

> **ai_Abstract:** 本文探讨了在心理语言学研究中，将第一词元熵作为词熵近似值的准确性，这是一种出于便利的常见做法。作者提出使用蒙特卡洛（MC）估计的词熵，该方法考虑了单词跨越多个词元的情况，以克服第一词元近似导致的低估和扭曲。他们在阅读时间上的回归实验表明，两种熵估计方法之间存在不同的结果，强调了在依赖上下文熵的第一词元近似时需要谨慎。

> **摘要翻译:** 上下文熵是一种心理语言学度量，用于捕捉单词在被遇到之前处理的预期难度。最近的研究已经测试了与熵相关的效应，作为对已知惊奇效应的潜在补充。为了方便，熵通常基于语言模型对单词第一个子词词元的概率分布进行估计。然而，这种近似会导致真实词熵的低估和潜在扭曲。为了解决这个问题，我们生成了蒙特卡洛（MC）估计的词熵，这允许单词跨越可变数量的词元。阅读时间的回归实验显示，第一词元熵和MC词熵之间存在不同的结果，这表明在使用上下文熵的第一词元近似时需要谨慎。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [48] [Low-Confidence Gold: Refining Low-Confidence Samples for Efficient Instruction Tuning](https://arxiv.org/abs/2502.18978)
> *低置信度黄金：提炼低置信度样本以实现高效指令微调*

*Hongyi Cai, Jie Li, Mohammad Mahdinur Rahman, Wenzhen Dong* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 指令微调, 低置信度样本, 数据过滤, 聚类, 大型语言模型

**Comment:** 8 pages

> **TL;DR:** 本文提出了Low-Confidence Gold (LCG) 框架，通过聚类和置信度引导选择来筛选高质量指令对，显著提升了大型语言模型指令微调的效率和性能。

**AI_Comments:** 该论文的创新点在于提出了“低置信度黄金”这一概念，通过结合聚类和置信度引导的半监督方法，有效地从低置信度样本中提炼出高质量的训练数据。这种方法在保证数据多样性的同时，显著提高了指令微调的效率和模型性能，对于资源受限或需要快速迭代的大模型训练场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型的指令微调效果受限于训练数据集的质量和效率。

**Method:** 引入了Low-Confidence Gold (LCG) 框架，该框架采用基于聚类的聚类和置信度引导选择来识别有价值的指令对。通过在代表性样本上训练轻量级分类器，采用半监督方法来筛选高质量子集，同时保持数据多样性。

**Result:** 在LCG筛选的6K样本子集上进行微调的模型，其性能优于现有方法，在MT-bench上取得了显著改进，并在综合评估指标上持续获得提升。

**Conclusion:** 该框架在保持模型性能的同时提高了效率，为高效指令微调提供了一个有前景的方向。

> **ai_Abstract:** 本文提出了一种名为Low-Confidence Gold (LCG) 的新型过滤框架，旨在解决大型语言模型指令微调中训练数据集质量和效率的限制。LCG利用基于质心的聚类和置信度引导选择，通过半监督方法和轻量级分类器来识别并筛选出高质量且多样化的指令对。实验证明，使用LCG筛选的少量样本（6K）进行微调，能使模型在MT-bench及其他综合评估指标上获得优于现有方法的性能提升，这为高效指令微调提供了一个有前景的方向。

> **摘要翻译:** 大型语言模型的指令微调效果从根本上受到训练数据集质量和效率的限制。这项工作引入了“低置信度黄金”（LCG），一个新颖的过滤框架，它采用基于质心的聚类和置信度引导选择来识别有价值的指令对。通过使用在代表性样本上训练的轻量级分类器，LCG采用半监督方法筛选高质量子集，同时保留数据多样性。实验评估表明，在LCG过滤的6K样本子集上进行微调的模型，与现有方法相比，取得了卓越的性能，在MT-bench上有了显著改进，并在全面的评估指标上持续获得提升。该框架在保持模型性能的同时提高了效率，为高效指令微调建立了一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [53] [EEG-CLIP : Learning EEG representations from natural language descriptions](https://arxiv.org/abs/2503.16531)
> *EEG-CLIP：从自然语言描述中学习脑电图（EEG）表示*

*Tidiane Camaret Ndir, Robin Tibor Schirrmeister, Tonio Ball* | **Category: cs.CL, cs.LG, eess.SP** | **Updated: 2025-07-29**

**Keywords:** EEG表示学习, 对比学习, 零样本解码, 自然语言处理, 脑电图

**Comment:** 

> **TL;DR:** EEG-CLIP是一个对比学习框架，它将脑电图（EEG）与对应的临床文本描述对齐到一个共享的嵌入空间中，从而实现通用的、任务无关的EEG解码。

**AI_Comments:** EEG-CLIP的创新之处在于将计算机视觉领域中CLIP（Contrastive Language–Image Pre-training）的思想引入到脑电图（EEG）领域，通过对比学习将EEG信号与自然语言描述进行对齐。这提供了一种学习通用、任务无关EEG表示的新范式，有望克服传统EEG解码模型任务特异性强的缺点。其在零样本和少量样本设置下的表现，预示着未来EEG分析可能不再需要大量标注数据，极大降低了研究和应用门槛，具有重要的研究价值和潜在的临床应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的脑电图（EEG）解码深度网络通常只针对特定任务进行训练。为了实现更通用、任务无关的脑电图解码，研究者需要一种方法能将脑电图记录与其对应的文本医疗报告进行匹配，类似于计算机视觉领域中图像与文本说明的匹配，以支持零样本解码。

**Method:** 本研究开发了一个名为EEG-CLIP的对比学习框架，该框架将脑电图时间序列与其对应的临床文本描述对齐到一个共享的嵌入空间中。研究者通过在少量样本（few-shot）和零样本（zero-shot）设置下评估其性能，来探究其在多功能脑电图解码方面的潜力。

**Result:** EEG-CLIP成功地实现了文本和脑电图（EEG）表示的非平凡对齐。

**Conclusion:** EEG-CLIP为学习通用脑电图（EEG）表示提供了一种有前景的方法，这有望通过零样本解码或使用更少训练样本训练特定任务模型，从而简化对各种解码问题的分析。

> **ai_Abstract:** 本论文提出EEG-CLIP，一个基于对比学习的框架，旨在解决现有EEG解码模型任务特异性强的局限。通过将EEG时间序列与临床文本描述对齐到共享嵌入空间，EEG-CLIP实现了文本和EEG表示的有效关联。该方法在少量样本和零样本设置下展现出多功能EEG解码的潜力，为学习通用EEG表示提供了一条新途径，有望简化未来多样化的EEG分析任务。

> **摘要翻译:** 脑电图（EEG）解码的深度网络通常只训练解决一个特定任务，例如病理或年龄解码。一个更通用的、与任务无关的方法是训练深度网络将（临床）脑电图记录与其对应的文本医疗报告进行匹配，反之亦然。这种方法在计算机视觉领域率先将图像与其文本说明进行匹配，随后允许使用文本类别提示进行成功的零样本解码。在这项工作中，我们遵循这种方法，开发了一个对比学习框架EEG-CLIP，它将脑电图时间序列和相应临床文本的描述对齐到一个共享的嵌入空间中。我们研究了其在多功能脑电图解码方面的潜力，评估了其在各种少量样本和零样本设置下的性能。总的来说，我们表明EEG-CLIP能够非平凡地对齐文本和脑电图表示。我们的工作提出了一种学习通用脑电图表示的有前景的方法，这可以通过零样本解码或从更少的训练样本训练特定任务模型，从而使各种解码问题的分析变得更容易。我们结果的重现代码可在https://github.com/tidiane-camaret/EEGClip获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [61] [VN-MTEB: Vietnamese Massive Text Embedding Benchmark](https://arxiv.org/abs/2507.21500)
> *VN-MTEB: 越南大规模文本嵌入基准*

*Loc Pham, Tung Luu, Thu Vo, Minh Nguyen, Viet Hoang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 越南语, 文本嵌入, 基准测试, LLMs, 位置编码

**Comment:** 19 pages (including reference, appendix) 41 datasets from 6 tasks
  (retrieval, classification, pair-classification, clustering, rerank, sts) 7
  figures, 16 tables, benchmark 18 text embedding models

> **TL;DR:** 引入VN-MTEB，一个越南语文本嵌入基准，以解决缺乏大规模测试数据集的问题，并发现使用旋转位置编码的模型表现更好。

**AI_Comments:** VN-MTEB的创新之处在于其通过自动化翻译和高质量过滤方法，有效解决了越南语文本嵌入模型评估数据集缺乏的痛点。该基准的发布对于推动越南语NLP领域的发展具有重要意义，尤其是在推荐系统和内容控制等实际应用中。此外，其对不同位置编码策略性能的比较也为模型设计提供了有价值的洞察。

<details>
  <summary>Details</summary>

**Motivation:** 越南在互联网流量和在线毒性方面均位居前列，使得在应用程序中实施用于推荐和内容控制的嵌入模型至关重要。然而，缺乏大规模且任务多样化的测试数据集，使得科学家们在将AI模型部署到现实世界的大规模项目之前难以有效评估。

**Method:** 通过使用新的自动化框架，将大规模英文MTEB样本翻译成越南语，利用大型语言模型（LLMs）和尖端嵌入模型进行翻译和过滤过程，以保留高质量样本，确保语言的自然流畅性和语义的忠实性，并保留命名实体识别（NER）和代码片段。构建了一个包含六个任务、41个数据集的越南语文本嵌入基准。

**Result:** 分析发现，使用旋转位置编码（Rotary Positional Embedding）的更大、更复杂的模型在嵌入任务中表现优于使用绝对位置编码（Absolute Positional Embedding）的模型。

**Conclusion:** VN-MTEB为越南语文本嵌入模型提供了一个全面的评估基准，有助于解决评估难题，并揭示了不同位置编码策略对模型性能的影响。

> **ai_Abstract:** 本文介绍了VN-MTEB，一个专门为越南语文本嵌入模型设计的综合性基准测试平台。鉴于越南语缺乏大规模且多样化的评估数据集，研究人员通过自动化框架，利用LLMs和先进嵌入模型将大量英文MTEB样本翻译并过滤为高质量越南语数据，构建了包含六个任务、41个数据集的基准。实验结果表明，采用旋转位置编码的复杂模型在嵌入任务中表现优于采用绝对位置编码的模型。

> **摘要翻译:** 越南在互联网流量和在线毒性方面均位居前列。因此，在应用程序中实施用于推荐和内容控制的嵌入模型至关重要。然而，缺乏大规模的测试数据集，无论是在数量还是任务多样性方面，使得科学家们在将AI模型部署到现实世界的大规模项目之前难以有效评估。为了解决这个重要问题，我们引入了一个越南语嵌入模型基准VN-MTEB，该基准是通过使用我们新的自动化框架翻译大量大规模文本嵌入基准中的英文样本而创建的。我们利用大型语言模型（LLMs）和尖端嵌入模型的优势进行翻译和过滤过程，以保留高质量样本，同时确保语言的自然流畅性和语义的忠实性，并保留命名实体识别（NER）和代码片段。我们全面的基准包含专门为越南语文本嵌入设计的六个任务中的41个数据集。在我们的分析中，我们发现使用旋转位置编码的更大、更复杂的模型在嵌入任务中优于使用绝对位置编码的模型。数据集可在HuggingFace上获取：https://huggingface.co/collections/GreenNode/vn-mteb-68871433f0f7573b8e1a6686

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [70] [Towards the Law of Capacity Gap in Distilling Language Models](https://arxiv.org/abs/2311.07052)
> *走向语言模型蒸馏中容量差距定律*

*Chen Zhang, Qiuchi Li, Dawei Song, Zheyu Ye, Yan Gao, Yan Hu* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 语言模型蒸馏, 容量差距, 最优教师, 缩放定律, LLMs

**Comment:** 32 pages, 10 figures, 15 tables, accepted to ACL 2025. Code and
  checkpoints are available at https://github.com/GeneZC/MiniMA

> **TL;DR:** 本文提出了“容量差距定律”，解决了语言模型蒸馏中教师模型规模与学生模型性能之间的“容量差距诅咒”问题。该定律表明最优教师模型规模与学生模型规模呈线性关系，从而避免了大量计算密集型实验来寻找最佳教师，并在大型语言模型（LLMs）蒸馏中取得了优异性能。

**AI_Comments:** 本文的创新之处在于提出了“容量差距定律”，为语言模型蒸馏中如何选择最优教师提供了一个新的理论指导。这一发现对于提高蒸馏效率和降低计算成本具有重要意义，尤其是在处理日益增长的大型语言模型时，它能够帮助研究人员更有效地找到最佳的教师-学生模型配对，从而加速模型开发和优化过程。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型（LM）蒸馏面临一个关键问题：学生模型表现优异的教师往往是相对较小的模型，而非更大的模型，尤其是在教师和学生之间存在显著容量差距时，这被称为“容量差距诅咒”。为了找到最优教师，通常需要对不同规模的教师进行大量蒸馏实验，这对于大型语言模型（LLMs）而言计算成本极高。本文旨在解决这一关键瓶颈。

**Method:** 本文通过对一系列小规模（<3B）LM蒸馏的初步研究，归纳出了“容量差距定律”，该定律指出在不同模型和数据规模下，最优教师模型规模始终与学生模型规模呈线性关系。随后，将该定律推广到更大规模（7B）的LLM蒸馏中。

**Result:** 研究发现，最优教师模型规模与学生模型规模呈线性关系。通过将该定律推广到7B LLM蒸馏，成功获得了性能超越众多竞争对手的多功能LLMs。

**Conclusion:** 本文通过提出“容量差距定律”，有效解决了语言模型蒸馏中寻找最优教师的瓶颈问题。该定律能够高效地识别最优教师，从而在不同规模下，包括大型语言模型蒸馏中，获得性能更优异的学生模型。

> **ai_Abstract:** 本文研究了语言模型蒸馏中“容量差距诅咒”问题，即大型教师模型不一定能带来更优的学生模型。通过对小规模语言模型（<3B）的实验，本文提出了“容量差距定律”，表明最优教师模型规模与学生模型规模呈线性关系。将此定律应用于大型语言模型（7B）蒸馏，成功获得了性能卓越的通用型LLMs，有效解决了寻找最佳教师的计算瓶颈。

> **摘要翻译:** 语言模型（LM）蒸馏旨在将大型教师LM中的知识蒸馏到小型学生LM中。作为LM蒸馏面临的一个关键问题，一个优秀的学习者通常来自于相对较小规模的教师LM，而不是更大的教师LM，尤其是在教师和学生之间存在显著容量差距的情况下。这个问题通常被称为“容量差距诅咒”，它表明在教师的扩展过程中，可能存在一个产生最佳性能学生的最佳教师。因此，需要对各种规模的教师进行蒸馏试验以确定最佳教师，这在大型LM（LLMs）的背景下变得计算密集。本文通过提供从对广泛的小规模（<3B）LM蒸馏的初步研究中归纳出的“容量差距定律”来解决这一关键瓶颈，其中最优教师模型规模在不同模型和数据规模下始终与学生模型规模呈线性关系。通过将该定律扩展到更大规模（7B）的LLM蒸馏，我们成功获得了性能超越众多竞争对手的多功能LLM。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [76] [RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation](https://arxiv.org/abs/2507.22219)
> *教师模型精炼的强化学习：机器翻译的渐进式模仿学习*

*Dongyub Jude Lee, Zhenyi Ye, Pengcheng He* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 机器翻译, 强化学习, 模仿学习, 教师模型, 偏好学习

**Comment:** 

> **TL;DR:** RLfR是一种新的机器翻译框架，它利用外部教师模型（如GPT-4o）的持续高质量反馈，通过渐进式模仿学习克服了传统偏好学习方法对静态三元组数据集的依赖，并在多语言基准测试中表现出色。

**AI_Comments:** RLfR的创新之处在于其摆脱了对预设静态数据集的依赖，转而采用动态、持续的教师模型反馈机制，这模拟了人类通过迭代修正学习的过程。利用如GPT-4o这样强大的外部教师模型提供高质量反馈，是其成功的关键。该方法有望提高机器翻译模型的泛化能力和适应性，尤其是在处理特定领域或罕见语言对时。其局限性可能在于对高质量教师模型的持续可用性和计算成本的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 当前的机器翻译偏好学习方法（如DPO）虽然取得了显著进展，但严重依赖于大型、精心策划的三元组数据集，并且往往难以泛化到其调优领域之外。

**Method:** 本文提出了教师模型精炼的强化学习（RLfR）框架。该框架通过利用外部教师模型（GPT-4o）的持续高质量反馈，消除了对静态三元组数据集的依赖。RLfR将每个翻译步骤视为一个微型教程：参与者生成一个假设，教师模型对其进行精炼，然后根据参与者的假设与教师模型精炼的对齐程度给予奖励。该过程由两种互补信号引导：负编辑距离（促进词汇和结构保真度）和COMET分数（确保语义充分性），使参与者逐步学习模仿教师模型，通过增量、迭代改进来模拟人类学习过程。

**Result:** 在FLORES-200基准测试（英译德、西、中、韩、日，以及反向翻译）中，RLfR始终优于MT-SFT和基于偏好的基线方法，显著提高了COMET（语义充分性）和M-ETA（实体保留）分数。

**Conclusion:** RLfR框架通过利用教师模型提供持续高质量反馈，成功克服了传统偏好学习方法在机器翻译中对静态数据集的依赖和泛化能力不足的问题，并在多语言翻译任务中取得了显著的性能提升。

> **ai_Abstract:** 本文提出了一种名为RLfR（教师模型精炼的强化学习）的新型机器翻译框架，旨在解决现有偏好学习方法对大量静态数据集的依赖和泛化能力差的问题。RLfR通过利用外部教师模型（如GPT-4o）的持续高质量反馈，将每个翻译步骤视为一个微型教学过程。参与者根据其生成译文与教师模型精炼译文的对齐程度获得奖励，并结合负编辑距离和COMET分数两种信号进行学习。实验结果表明，RLfR在FLORES-200多语言基准测试中表现优异，显著超越了MT-SFT和偏好学习基线方法，提升了翻译的语义充分性和实体保留能力。

> **摘要翻译:** 机器翻译（MT）的偏好学习方法——例如直接偏好优化（DPO）——取得了令人瞩目的进展，但它们严重依赖于大型、精心策划的三元组数据集，并且往往难以泛化到其调优领域之外。我们提出了教师模型精炼的强化学习（RLfR），这是一个新颖的框架，通过利用外部教师模型（GPT-4o）的持续高质量反馈，消除了对静态三元组的依赖。RLfR将每个翻译步骤视为一个微型教程：参与者生成一个假设，教师对其进行精炼，然后根据参与者与教师精炼的对齐程度给予奖励。在两种互补信号——（i）负编辑距离（促进词汇和结构保真度）和（ii）COMET分数（确保语义充分性）——的引导下，参与者逐步学习模仿教师，通过增量、迭代改进来模拟人类学习过程。在FLORES-200基准测试（英译德、西、中、韩、日，以及反向翻译）中，RLfR始终优于MT-SFT和基于偏好的基线方法，显著提高了COMET（语义充分性）和M-ETA（实体保留）分数。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [77] [Instruction-tuned Large Language Models for Machine Translation in the Medical Domain](https://arxiv.org/abs/2408.16440)
> *医疗领域机器翻译的指令调优大型语言模型*

*Miguel Rios* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 机器翻译, 医疗领域, 指令调优, 术语一致性

**Comment:** Citation: Miguel Rios. 2025. Instruction-tuned Large Language Models
  for Machine Translation in the Medical Domain. In Proceedings of Machine
  Translation Summit XX Volume 1, pages 162-172

> **TL;DR:** 在医疗领域机器翻译中，指令调优的大型语言模型通过引入专业词汇，显著优于基线模型。

**AI_Comments:** 这项研究通过指令调优并结合特定领域的术语知识，有效提升了大型语言模型在医疗领域机器翻译中的表现。其创新点在于将专业词典内容融入指令调优过程，这对于提高专业领域翻译的准确性和一致性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在专业领域（如医疗）的机器翻译中表现不佳，且术语翻译的一致性对该领域的用户、研究人员和翻译人员至关重要。

**Method:** 本研究比较了医疗领域中基线大型语言模型和指令调优大型语言模型的性能。此外，研究人员将专业医学词典中的术语引入指令格式化数据集，用于微调大型语言模型。

**Result:** 经过指令调优的大型语言模型在自动评估指标上显著优于基线模型。

**Conclusion:** 指令调优结合专业词汇能够有效提升大型语言模型在医疗领域机器翻译中的性能。

> **ai_Abstract:** 本研究旨在解决大型语言模型在医疗领域机器翻译中表现不佳的问题，并强调术语一致性的重要性。通过比较基线模型和指令调优模型，并特别将专业医学词典中的术语引入指令格式化数据集进行微调，研究发现指令调优的大型语言模型在自动评估指标上显著超越了基线模型，表明指令调优是提升LLMs在专业领域机器翻译性能的有效方法。

> **摘要翻译:** 大型语言模型（LLMs）在资源丰富的语言对和领域中，已在机器翻译方面展现出良好的前景。然而，在专业领域（例如医疗领域），与标准神经机器翻译模型相比，LLMs 的表现较差。对于专业领域的用户、研究人员和翻译人员来说，术语机器翻译的一致性至关重要。在本研究中，我们比较了医疗领域中基线LLMs与指令调优LLMs的性能。此外，我们将专业医学词典中的术语引入到指令格式化的数据集中，用于微调LLMs。指令调优的LLMs在自动评估指标上显著优于基线模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [83] [Narrative Context Protocol: An Open-Source Storytelling Framework for Generative AI](https://arxiv.org/abs/2503.04844)
> *叙事上下文协议：一个用于生成式AI的开源讲故事框架*

*Hank Gerba* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 叙事上下文协议, 生成式AI, 开源框架, 讲故事, 叙事互操作性

**Comment:** 

> **TL;DR:** 引入NCP，一个开源叙事标准，通过“故事形式”编码故事结构，为生成式AI提供叙事互操作性和一致性。

**AI_Comments:** 该论文提出了一种新颖的开源协议NCP，为生成式AI在叙事领域的应用提供了重要的结构化框架。其创新点在于通过“Storyform”实现了叙事的标准化编码和跨系统可移植性，并通过“护栏”机制有效解决了AI生成叙事中常见的连贯性和上下文维持问题，同时兼顾了用户交互的自由度。这对于AI辅助创作和互动式叙事游戏的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决生成式AI叙事中互操作性、AI驱动创作工具、实时涌现叙事的需求，并确保叙事上下文和连贯性。

**Method:** 本文介绍了叙事上下文协议（NCP），一个开源叙事标准，通过将故事结构编码为“Storyform”来提供叙事特征的结构化记录。通过一个为期一年的实验，作者使用NCP和自定义创作平台创建了一个基于其小说的可玩文本体验，该体验由生成式AI驱动。

**Result:** 成功展示了NCP的能力，通过一个生成式AI驱动的文本体验，NCP作为“护栏”允许生成系统适应玩家能动性，同时保持叙事上下文和连贯性。

**Conclusion:** NCP能够为生成式AI叙事提供必要的“护栏”，确保故事的连贯性和上下文，同时支持玩家的自由输入，从而实现叙事互操作性和AI驱动的创作。

> **ai_Abstract:** 本文介绍了叙事上下文协议（NCP），一个开源叙事标准，旨在提升生成式AI在叙事创作中的互操作性、可移植性和一致性。NCP通过“Storyform”编码故事结构，为AI生成系统提供约束。通过一项为期一年的实验，作者利用NCP成功创建了一个由生成式AI驱动的互动文本体验，证明NCP能有效平衡玩家自由与叙事连贯性。

> **摘要翻译:** 我们在此介绍叙事上下文协议（NCP），这是一个开源叙事标准，旨在实现叙事互操作性、AI驱动的创作工具、实时涌现叙事等功能。通过将故事结构编码为“故事形式”（Storyform），即其叙事特征的结构化记录，NCP实现了跨系统的叙事可移植性，以及为生成式讲故事系统提供基于意图的约束。我们通过一个为期一年的实验展示了NCP的能力，在此期间，一位作者使用NCP和一个自定义创作平台，基于她现有的小说创作了一个可玩的、基于文本的体验。这个体验由生成式AI驱动，具有无约束的自然语言输入。NCP作为一组“护栏”发挥作用，允许生成系统适应玩家的能动性，同时确保叙事上下文和连贯性得以维持。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [84] [Past Meets Present: Creating Historical Analogy with Large Language Models](https://arxiv.org/abs/2409.14820)
> *过去与现在相遇：用大型语言模型创建历史类比*

*Nianqi Li, Siyu Yuan, Jiangjie Chen, Jiaqing Liang, Feng Wei, Zujie Liang, Deqing Yang, Yanghua Xiao* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 历史类比, 大型语言模型, 自我反思, 类比获取, 人工智能

**Comment:** Accepted to ACL 2025 (Outstanding Paper Award)

> **TL;DR:** 本文探讨了使用大型语言模型（LLMs）来获取历史类比，并提出了一种自我反思方法来提高其性能。

**AI_Comments:** 本文的创新点在于将大型语言模型应用于历史类比这一复杂且具有挑战性的任务，并提出了一个实用的自我反思机制来提高生成质量和可靠性。这对于提升LLMs在复杂推理和知识应用方面的能力具有重要意义。该研究不仅填补了AI领域在历史类比方面的空白，也为未来LLMs在人文社科领域的应用提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 历史类比对于人们决策和理解世界至关重要，但人们难以找到合适的类比，且AI社区之前的研究忽视了这一领域。本文旨在填补这一空白，专注于历史类比获取任务。

**Method:** 本文探讨了基于不同大型语言模型（LLMs）的检索和生成方法来获取历史类比。此外，提出了一种自我反思方法，以减轻LLMs在生成历史类比时的幻觉和刻板印象。

**Result:** 通过人工评估和专门设计的自动多维评估，发现LLMs在历史类比方面普遍具有良好潜力。并且，通过使用自我反思方法，模型的性能可以进一步提高。

**Conclusion:** 大型语言模型在生成历史类比方面潜力巨大，且通过引入自我反思机制可以有效提升其表现并减轻负面影响。

> **ai_Abstract:** 本研究旨在解决人们难以找到合适历史类比的问题，并弥补AI领域在此方面的空白。文章探索了利用大型语言模型（LLMs）进行历史类比的获取，包括检索和生成方法。为应对LLMs可能出现的幻觉和刻板印象，研究提出了一种自我反思方法。通过人工评估和自动多维评估，结果表明LLMs在历史类比方面展现出良好潜力，且自我反思方法能有效提升其性能。

> **摘要翻译:** 历史类比，即将已知的过去事件与当代但不熟悉的事件进行比较，是帮助人们做出决策和理解世界的重要能力。然而，应用历史研究表明，人们难以找到合适的类比。AI社区之前的研究也忽视了历史类比。为了填补这一空白，本文专注于历史类比获取任务，旨在为给定事件获取类比的历史事件。我们探索了基于不同大型语言模型（LLMs）的检索和生成方法来获取历史类比。此外，我们提出了一种自我反思方法，以减轻LLMs在生成历史类比时的幻觉和刻板印象。通过人工评估和我们专门设计的自动多维评估，我们发现LLMs在历史类比方面普遍具有良好潜力。并且，通过使用我们的自我反思方法，模型的性能可以进一步提高。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [91] [Neutral Residues: Revisiting Adapters for Model Extension](https://arxiv.org/abs/2410.02744)
> *中性残差：重新审视适配器以扩展模型*

*Franck Signe Talla, Edouard Grave, Hervé Jégou* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 中性残差, 适配器, 模型扩展, 领域适应, 大型语言模型

**Comment:** Accepted at ICML 2025

> **TL;DR:** 本文提出了一种名为“中性残差”的新方法，通过改进适配器来扩展预训练大型语言模型到新领域，同时避免在原始领域性能下降的问题。该方法在多语言适应任务中表现优异。

**AI_Comments:** 本文提出的“中性残差”方法极具创新性，它巧妙地通过修改适配器结构，使得新增的参数在原始任务上呈现“中性”行为（输出接近零），从而在模型扩展时有效避免了灾难性遗忘。这对于大型预训练模型的持续学习和多任务适应具有重要意义，尤其是在资源受限或需要快速适应新领域的场景中，提供了一种高效且性能优越的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 解决将预训练大型语言模型扩展到新领域时，标准技术（如微调或LoRA）导致在新旧领域性能之间出现权衡的问题，因为它们没有正式增加模型容量。

**Method:** 提出了一种名为“中性残差”的方法，通过从数据、架构和训练过程三个角度共同改进适配器来扩展LLM。该方法修改适配器，使每个新的残差块在原始领域输出接近零，从而在添加新容量的同时避免遗忘。

**Result:** 在将最先进的英文模型适应到新语言时，该方法取得了显著成果。与微调、LoRA或传统适配器等竞争方法相比，中性残差在学习新语言和不遗忘英文之间的权衡方面表现显著优越。

**Conclusion:** 通过引入“中性残差”方法，本文成功改进了适配器，为大型语言模型提供了在扩展到新领域时保持原始领域性能的能力，有效解决了领域适应中的权衡问题。

> **ai_Abstract:** 本文提出了一种名为“中性残差”的新方法，旨在解决大型语言模型在领域扩展中面临的性能权衡问题。通过重新审视并改进适配器，该方法从数据、架构和训练过程三个维度进行优化，使得新增的残差块在原始领域输出接近零，从而在增加模型容量的同时有效避免了对原始领域性能的遗忘。实验结果表明，在将英文模型适应到新语言的任务中，中性残差显著优于传统的微调、LoRA和普通适配器，在学习新语言和保持旧语言能力之间取得了更好的平衡。

> **摘要翻译:** 我们解决了将预训练大型语言模型扩展到训练期间未见过的新领域的问题。微调或低秩适应（LoRA）等标准技术在领域适应方面是成功的，但它们并未正式增加模型的容量。这通常导致在新领域表现良好与原始领域性能下降之间的权衡。在这里，我们重新审视并改进了适配器，从数据、架构和训练过程三个角度共同扩展大型语言模型，这些角度被有利地联合考虑。由此产生的方法，称为中性残差，以一种方式修改适配器，使得每个新的残差块在原始领域输出接近零。当将一个最初在英语上训练的最先进模型适应到一种新语言时，这种解决方案带来了强大的结果。中性残差在学习新语言和不遗忘英语之间的权衡方面，显著优于微调、LoRA或普通适配器等竞争方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [98] [Natural Language Processing for the Legal Domain: A Survey of Tasks, Datasets, Models, and Challenges](https://arxiv.org/abs/2410.21306)
> *法律领域的自然语言处理：任务、数据集、模型和挑战综述*

*Farid Ariai, Joel Mackenzie, Gianluca Demartini* | **Category: cs.CL, cs.AI, A.1; I.2.7; J.1** | **Updated: 2025-07-30**

**Keywords:** 自然语言处理, 法律领域, 综述, 法律文本, 挑战

**Comment:** 35 pages

> **TL;DR:** 这是一篇关于法律领域自然语言处理的综述，涵盖了任务、数据集、模型和挑战，基于对131项研究的分析。

**AI_Comments:** 这篇论文通过系统回顾和结构化呈现，为法律NLP这一复杂且快速发展的领域提供了全面的概览，具有重要的价值。其遵循PRISMA框架增加了研究的严谨性。特别有价值的是，它不仅识别了现有任务和模型，还明确指出了16个开放研究挑战，这对于指导未来研究方向和推动领域发展至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言处理（NLP）在法律领域，尤其是在开发计算辅助工具方面，具有巨大的潜力，这吸引了研究人员多年的兴趣。本综述旨在对该领域进行系统回顾。

**Method:** 本综述遵循系统评价和荟萃分析优先报告项目（PRISMA）框架，回顾了154项研究，并经过手动筛选最终选择了131项研究。它探讨了法律领域NLP的基础概念、独特性和挑战。

**Result:** 本综述概述了法律文本特有的NLP任务，如文档摘要、命名实体识别、问答、论证挖掘、文本分类和判决预测。它分析了专门针对法律的语言模型以及将通用语言模型应用于法律领域的方法。此外，还指出了十六个开放的研究挑战，包括检测和缓解人工智能应用中的偏见、需要更强大和可解释的模型以及提高可解释性以应对法律语言和推理的复杂性。

**Conclusion:** 本论文全面综述了法律领域的自然语言处理，突出了其潜力、当前状态和未来挑战，为研究人员提供了宝贵的资源。

> **ai_Abstract:** 本综述系统回顾了法律领域自然语言处理的131项研究，涵盖了该领域的任务、数据集、模型和挑战。它详细介绍了文档摘要、命名实体识别等特定任务，分析了现有模型及通用模型适应法律领域的方法，并指出了法律文本处理的独特难点，如长文档和数据集限制。此外，文章还提出了16个开放研究挑战，包括偏见检测和模型可解释性，为未来的研究方向提供了指导。

> **摘要翻译:** 自然语言处理（NLP）正在彻底改变专业人士和普通大众在法律领域的运作方式。NLP在法律领域的巨大潜力，特别是在为各种法律流程开发计算辅助工具方面，多年来一直吸引着研究人员的兴趣。本综述遵循系统评价和荟萃分析优先报告项目框架，审查了154项研究，经过手动筛选最终选择了131项。它探讨了法律领域NLP的相关基础概念，阐明了处理法律文本的独特方面和挑战，例如文档长度过长、语言复杂以及开放法律数据集有限。我们概述了法律文本特有的NLP任务，例如文档摘要、命名实体识别、问答、论证挖掘、文本分类和判决预测。此外，我们分析了已开发的面向法律的语言模型，以及将通用语言模型应用于法律领域的方法。此外，我们还指出了十六个开放的研究挑战，包括人工智能应用中偏见的检测和缓解、对更强大和可解释模型的需求以及提高可解释性以处理法律语言和推理的复杂性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [105] [Yankari: A Monolingual Yoruba Dataset](https://arxiv.org/abs/2412.03334)
> *Yankari：一个约鲁巴语单语数据集*

*Maro Akpobi* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 约鲁巴语, 单语数据集, 自然语言处理, 资源匮乏语言, 数据集构建

**Comment:** 6 pages

> **TL;DR:** 本文介绍了Yankari，一个大规模的约鲁巴语单语数据集，旨在弥补该语言在自然语言处理资源方面的空白，为开发更准确的NLP模型提供基础。

**AI_Comments:** Yankari数据集的创新之处在于其大规模和对道德数据收集实践的强调，这解决了现有语言数据集中常见的问题。其重要性在于为资源匮乏的约鲁巴语提供了急需的高质量NLP资源，这将极大地推动该语言的NLP研究和应用，促进其数字包容性。

<details>
  <summary>Details</summary>

**Motivation:** 约鲁巴语是西非一种重要的语言，拥有超过3000万使用者，但在自然语言处理（NLP）研究和应用中资源严重不足。本文旨在解决约鲁巴语NLP资源的关键空白。

**Method:** 通过精心选择来源、自动化质量控制和严格的数据清洗过程来创建数据集。该方法还注重道德数据收集实践，避免有问题的数据源，并解决现有数据集中普遍存在的问题。对数据集进行了彻底的自动化评估。

**Result:** Yankari数据集包含来自13个不同来源的51,407份文档，总计超过3000万个词元，并证明其质量优于现有资源。

**Conclusion:** Yankari数据集代表了约鲁巴语资源的一个重大进步，为开发更准确的NLP模型、支持比较语言学研究以及促进约鲁巴语的数字可访问性奠定了基础。

> **ai_Abstract:** 本文推出了Yankari，一个针对约鲁巴语的大规模单语数据集，旨在弥补该语言在NLP资源上的严重不足。该数据集通过精心挑选来源、自动化质量控制和严格的数据清洗，并遵循道德收集实践创建，包含来自13个来源的51,407份文档和超过3000万个词元。自动化评估显示其高质量。Yankari为约鲁巴语NLP模型开发、语言学研究及数字可访问性提供了重要基础。

> **摘要翻译:** 本文介绍了Yankari，一个大型的约鲁巴语单语数据集，旨在解决这种重要的西非语言在自然语言处理（NLP）资源方面的关键空白。尽管约鲁巴语使用者超过3000万，但在NLP研究和应用中却严重不足。我们详细介绍了创建此数据集的方法，包括仔细的来源选择、自动化质量控制和严格的数据清洗过程。Yankari数据集包含来自13个不同来源的51,407份文档，总计超过3000万个词元。我们的方法侧重于道德数据收集实践，避免有问题的来源并解决现有数据集中普遍存在的问题。我们对数据集进行了彻底的自动化评估，证明了其与现有资源相比的质量。Yankari数据集代表了约鲁巴语资源的一个重大进步，为开发更准确的NLP模型、支持比较语言学研究以及促进约鲁巴语的数字可访问性奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [111] [Meaning-infused grammar: Gradient Acceptability Shapes the Geometric Representations of Constructions in LLMs](https://arxiv.org/abs/2507.22286)
> *意义融入的语法：梯度可接受性塑造大型语言模型中构式的几何表示*

*Supantho Rakshit, Adele Goldberg* | **Category: cs.CL, cs.AI, 68T50** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 构式主义, 几何表示, 梯度可接受性, 构式

**Comment:** 5 pages, 3 figures, Accepted for publication at the Second
  International Workshop on Construction Grammars and NLP at the 16th
  International Conference for Computational Semantics (IWCS) 2025

> **TL;DR:** 本研究表明，大型语言模型（LLMs）能够学习和表示具有意义和梯度特性的构式，其内部表示的几何结构反映了人类对构式偏好的梯度强度。

**AI_Comments:** 本文通过对LLMs内部表示进行几何分析，为LLMs如何学习和表示语言的复杂性提供了新的视角。其创新之处在于将构式主义理论中的“意义融入的梯度性”与LLMs的内部几何结构联系起来，提供了量化证据。这项工作对于理解LLMs的语言能力以及构式主义理论在计算模型中的实现具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探究大型语言模型（LLMs）的内部表示是否能够反映基于用法的构式主义（UCx）方法所提出的，语言由具有功能融入的梯度性形式-意义配对（构式）组成这一观点。

**Method:** 研究分析了Pythia-1.4B模型中英语与格构式（双宾语和介词宾语）的神经表示。使用了包含5000个句子对的数据集，这些句子对根据人类评分的偏好强度进行了系统性变异。通过能量距离（Energy Distance）或詹森-香农散度（Jensen-Shannon Divergence）测量构式表示之间的可分离性，进行了宏观层面的几何分析。

**Result:** 宏观层面的几何分析发现，构式表示之间的可分离性系统地受到梯度偏好强度的调节。每种构式中更具原型性的范例在LLMs的激活空间中占据更独特的区域。

**Conclusion:** 这些结果提供了强有力的证据，表明LLMs学习了丰富、融入意义且具有梯度的构式表示，并为LLMs中构式主义基本原理的几何测量提供了支持。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）能否学习和表示语言构式中意义融入的梯度性。通过分析Pythia-1.4B模型中英语与格构式的神经表示，研究发现构式表示的几何结构（可分离性）与人类对构式的梯度偏好强度呈系统性关联，即更具原型性的构式范例在模型激活空间中占据更独特的区域。这为LLMs能够学习到丰富的、具有意义和梯度特性的构式表示提供了有力证据，并支持了利用几何方法衡量LLMs中构式主义原则的有效性。

> **摘要翻译:** 基于用法的构式主义（UCx）方法认为，语言由习得的形式-意义配对（构式）网络组成，其使用主要由其意义或功能决定，这要求它们具有梯度性和概率性。本研究调查了大型语言模型（LLMs）的内部表示是否反映了所提出的功能融入的梯度性。我们分析了Pythia-1.4B模型中英语与格构式（双宾语和介词宾语）的神经表示，使用了一个包含5000个句子对的数据集，这些句子对根据人类评分的偏好强度进行了系统性变异。宏观层面的几何分析发现，构式表示之间的可分离性，通过能量距离或詹森-香农散度测量，系统地受到梯度偏好强度的调节。每种构式中更具原型性的范例在LLMs的激活空间中占据更独特的区域。这些结果提供了强有力的证据，表明LLMs学习了丰富、融入意义且具有梯度的构式表示，并为LLMs中构式主义基本原理的几何测量提供了支持。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [112] [Efficient Continual Learning for Small Language Models with a Discrete Key-Value Bottleneck](https://arxiv.org/abs/2412.08528)
> *使用离散键值瓶颈的小型语言模型高效持续学习*

*Andor Diera, Lukas Galke, Fabian Karl, Ansgar Scherp* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 持续学习, 离散键值瓶颈, 灾难性遗忘, 小型语言模型, 自然语言处理

**Comment:** 

> **TL;DR:** 本文提出了一种用于小型语言模型的离散键值瓶颈（DKVB），以实现高效的持续学习并减轻灾难性遗忘，同时降低计算成本。

**AI_Comments:** 这项研究的创新之处在于将视觉领域成功的离散键值瓶颈概念引入到NLP的持续学习中，并通过针对NLP特性进行调整和引入新的初始化技术，有效解决了灾难性遗忘问题。其重要性在于提供了一种计算效率更高的方法，使得在资源受限的小型语言模型上进行持续学习成为可能，尤其是在真实世界中任务ID不总是可用的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 持续学习在各种自然语言处理（NLP）任务中仍然是一个挑战，因为用新训练数据更新的模型常常会面临灾难性遗忘先前习得知识的风险。

**Method:** 本文为仅编码器语言模型引入了一个离散键值瓶颈（DKVB），通过局部更新实现高效持续学习。该方法受到视觉领域离散键值瓶颈的启发，并考虑了新的、针对NLP的挑战。作者比较了不同的NLP瓶颈架构，并引入了一种新的、与任务无关的离散键初始化技术。

**Result:** 本文评估了DKVB在四种持续学习场景下的表现，结果表明它能够有效减轻灾难性遗忘。实验证明，所提出的方法与流行的持续学习方法相比，在实现具有竞争力的性能的同时，计算成本更低。此外，DKVB在没有提供任务ID的挑战性单头持续学习场景中也保持有效。

**Conclusion:** 该研究提出的离散键值瓶颈（DKVB）是一种针对NLP中持续学习的有效且计算效率高的方法，能够成功缓解灾难性遗忘问题，即使在任务信息有限的情况下也能表现良好。

> **ai_Abstract:** 本文针对自然语言处理中持续学习的灾难性遗忘问题，提出了一种名为离散键值瓶颈（DKVB）的新方法，用于仅编码器语言模型。该方法通过局部更新实现高效持续学习，并引入了任务无关的离散键初始化技术。实验结果表明，DKVB在减轻灾难性遗忘方面表现出色，与现有方法相比，在保持竞争性性能的同时显著降低了计算成本，并且在无任务ID的单头持续学习场景中依然有效。

> **摘要翻译:** 持续学习在各种自然语言处理（NLP）任务中仍然是一个挑战，因为用新训练数据更新的模型常常会面临灾难性遗忘先前习得知识的风险。我们为仅编码器语言模型引入了一个离散键值瓶颈（DKVB），通过局部更新实现高效持续学习。受视觉领域离散键值瓶颈的启发，我们考虑了新的、针对NLP的挑战。我们比较了不同的NLP瓶颈架构，并引入了一种新的、与任务无关的离散键初始化技术。我们在四种持续学习场景中评估了我们用于NLP的DKVB，结果表明它能减轻灾难性遗忘。我们的实验表明，所提出的方法与流行的持续学习方法相比，在实现具有竞争力的性能的同时，计算成本更低。此外，我们展示了DKVB即使在没有提供任务ID的挑战性单头持续学习场景中也保持有效。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [118] [Levels of Analysis for Large Language Models](https://arxiv.org/abs/2503.13401)
> *大型语言模型的分析层次*

*Alexander Ku, Declan Campbell, Xuechunzi Bai, Jiayi Geng, Ryan Liu, Raja Marjieh, R. Thomas McCoy, Andrew Nam, Ilia Sucholutsky, Veniamin Veselovsky, Liyi Zhang, Jian-Qiao Zhu, Thomas L. Griffiths* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 大型语言模型, 认知科学, 分析层次, David Marr, 可解释性

**Comment:** 

> **TL;DR:** 本文提出一个基于认知科学中David Marr分析层次的框架，以帮助理解大型语言模型。

**AI_Comments:** 该论文的创新点在于将认知科学，特别是David Marr的分析层次理论，引入到大型语言模型的理解和分析中。这提供了一个新的视角和系统性的框架来探究AI的内部机制，有助于弥合AI能力与可解释性之间的鸿沟，对AI的可解释性和神经科学启发AI研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代大型语言模型虽然功能强大，但难以理解。作者认为这与理解人类思维的历史性困难相似，因此提出可以利用认知科学的方法来理解大型语言模型。

**Method:** 作者提出了一个框架，该框架基于David Marr用于研究信息处理系统的分析层次，并结合认知科学中已有的技术。他们旨在通过重新审视这些技术并展示它们在理解大型语言模型行为和内部组织方面的潜力来提供一个工具包。

**Result:** 论文提出并阐述了一个基于David Marr分析层次的认知科学方法框架，旨在为理解大型语言模型提供深入见解和工具。

**Conclusion:** 论文旨在提供一个工具包，利用认知科学的方法和David Marr的分析层次，帮助人们理解大型语言模型的行为和内部组织，将其视为一种新型的“心智”。

> **ai_Abstract:** 本论文旨在解决大型语言模型日益复杂且难以理解的问题。作者提出，借鉴认知科学中理解人类思维的方法，特别是David Marr的信息处理系统分析层次框架，可以有效地解析大型语言模型。论文回顾了与各层次相关的认知科学技术，并展示了它们在揭示大型语言模型行为和内部结构方面的潜力，从而提供了一个理解这些新型AI“心智”的工具包。

> **摘要翻译:** 现代人工智能系统，例如大型语言模型，功能日益强大，但也越来越难以理解。认识到这个问题类似于理解人类思维的历史性困难，我们认为认知科学中发展出的方法对于理解大型语言模型可能是有用的。我们提出了一个基于David Marr为研究信息处理系统提出的分析层次来应用这些方法的框架。通过重新审视与每个层次相关的既定认知科学技术，并阐明它们在揭示大型语言模型行为和内部组织方面的潜力，我们旨在为理解这些新型“心智”提供一个工具包。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [119] [ECG-Byte: A Tokenizer for End-to-End Generative Electrocardiogram Language Modeling](https://arxiv.org/abs/2412.14373)
> *ECG-Byte：一种用于端到端生成式心电图语言模型的Tokenizer*

*William Han, Chaojing Duan, Michael A. Rosenberg, Emerson Liu, Ding Zhao* | **Category: cs.CL, eess.SP, I.2.7; J.3** | **Updated: 2025-07-29**

**Keywords:** 心电图, 分词器, 语言模型, 端到端, 生成式

**Comment:** 38 pages, 9 figures; Accepted to MLHC 2025

> **TL;DR:** ECG-Byte 提出了一种新的分词器，通过将心电图信号编码为字节对编码（BPE）令牌，实现了心电图语言模型的端到端训练，解决了传统两阶段方法的效率低下和可解释性差的问题，并显著提高了训练速度和数据效率。

**AI_Comments:** ECG-Byte 的创新之处在于将字节对编码（BPE）应用于心电图信号，并实现了心电图语言模型的端到端训练。这不仅显著提高了训练效率和数据利用率，还通过直接映射心电图令牌增强了模型的可解释性，为心电图分析领域的大型语言模型应用开辟了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有将多通道心电图信号生成文本的方法通常采用两阶段过程：首先通过自监督学习预训练心电图特定编码器，然后使用编码器派生的特征微调大型语言模型进行自然语言生成。然而，这些方法存在两个关键局限性：多阶段训练导致的效率低下，以及编码器生成特征的解释性挑战。

**Method:** 我们提出了 ECG-Byte，这是一种用于心电图自回归语言建模的改进字节对编码（BPE）分词器流水线。ECG-Byte 将心电图信号压缩并编码为令牌，通过结合心电图和文本令牌，实现直接的端到端大型语言模型训练。这种方法增强了可解释性，因为心电图令牌可以直接映射回原始信号。

**Result:** 利用 ECG-Byte，我们实现了具有竞争力的自然语言生成性能，同时训练速度提高了 3 倍，并且所需数据量仅为传统两阶段方法的 48%。

**Conclusion:** ECG-Byte 通过引入一种新的分词器和端到端训练范式，成功克服了现有心电图语言模型在效率和可解释性方面的局限性，并在性能上达到了与传统方法相当甚至更优的水平，展现了其在心电图分析领域的巨大潜力。

> **ai_Abstract:** 本文提出了 ECG-Byte，一种基于字节对编码（BPE）的分词器，旨在解决现有心电图（ECG）语言模型在效率和可解释性方面的挑战。传统方法采用两阶段训练，导致效率低下且特征难以解释。ECG-Byte 通过将心电图信号直接编码为令牌，实现了心电图与文本令牌的结合，从而支持大型语言模型的端到端训练。实验结果表明，ECG-Byte 在自然语言生成性能上具有竞争力，同时训练速度是传统方法的 3 倍，数据使用量仅为 48%，并提升了心电图令牌的可解释性。

> **摘要翻译:** 大型语言模型（LLMs）在各个领域都展现出卓越的多功能性，包括在心电图（ECG）方面的应用。越来越多的工作致力于从多通道心电图信号和相应的文本提示生成文本。现有方法通常涉及一个两阶段过程：首先通过自监督学习（SSL）目标预训练一个心电图专用编码器，然后使用编码器派生的特征微调一个大型语言模型（LLM）进行自然语言生成（NLG）。然而，这些方法面临两个关键限制：多阶段训练导致的效率低下，以及解释编码器生成特征的挑战。为了克服这些问题，我们提出了 ECG-Byte，这是一种用于心电图自回归语言建模的改进字节对编码（BPE）分词器流水线。ECG-Byte 将心电图信号压缩并编码成令牌，通过结合心电图和文本令牌，实现直接的端到端大型语言模型训练。这种方法增强了可解释性，因为心电图令牌可以直接映射回原始信号。利用 ECG-Byte，我们实现了具有竞争力的自然语言生成性能，同时训练速度提高了 3 倍，并且所需数据量仅为传统两阶段方法的 48%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [126] [Modeling Story Expectations to Understand Engagement: A Generative Framework Using LLMs](https://arxiv.org/abs/2412.15239)
> *建模故事预期以理解参与度：一个使用大型语言模型的生成框架*

*Hortense Fong, George Gui* | **Category: cs.CL, cs.AI, econ.GN, q-fin.EC, stat.ME, 68T50, 91F20, H.3.1; I.2.7** | **Updated: 2025-07-29**

**Keywords:** 故事预期, 参与度, 大型语言模型, 生成框架, 叙事分析

**Comment:** 

> **TL;DR:** 本研究提出了一个利用大型语言模型的新框架，通过建模观众对故事发展的预期来理解和预测故事参与度，结果显示其能显著提升现有特征工程技术的解释力。

**AI_Comments:** 这项研究的创新之处在于其利用大型语言模型来建模观众的前瞻性信念，这是现有内容分析方法难以捕捉的。通过量化预期、不确定性和惊喜等因素，该框架为理解故事参与度提供了更深层次的洞察，超越了单纯基于内容特征的分析。其重要性在于证明了前瞻性信念对参与度的显著影响，并为内容创作者提供了优化其叙事策略的新工具。该方法对于营销策略和内容推荐系统也具有潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 理解消费者何时以及为何参与故事对内容创作者至关重要。现有理论认为观众对故事发展的预期对参与度有重要影响，但由于缺乏对非结构化叙事数据中此类信念建模的原则性方法，实证研究大多侧重于直接从实际内容中提取特征，而非捕捉前瞻性信念。

**Method:** 本文引入了一个新颖的框架，利用大型语言模型（LLMs）来建模观众对故事如何发展的预期。该方法为每个故事生成多个潜在的延续，并使用既定的内容分析技术提取与预期、不确定性和惊喜相关的特征。

**Result:** 将该方法应用于超过30,000个图书章节，结果表明，该框架通过平均提升31%的边际解释力来补充现有特征工程技术。研究揭示，不同类型的参与度（继续阅读、评论和投票）是由当前和预期内容特征的不同组合驱动的。

**Conclusion:** 我们的框架提供了一种新颖的方式来研究和探索观众的前瞻性信念如何塑造他们对叙事媒体的参与，对内容导向行业的营销策略具有重要意义。

> **ai_Abstract:** 本研究提出一个基于大型语言模型（LLMs）的创新框架，旨在通过建模观众对故事发展的预期来理解其参与度。该方法通过生成故事的多种潜在延续并提取相关的预期、不确定性和惊喜特征，弥补了现有内容分析技术无法捕捉前瞻性信念的不足。在对超过30,000个图书章节的应用中，该框架将现有特征工程技术的解释力平均提高了31%，并揭示了不同参与行为（如阅读、评论、投票）是由当前及预期内容特征的不同组合驱动的。这为研究观众信念如何影响叙事媒体参与提供了新视角，并对内容营销策略具有实际指导意义。

> **摘要翻译:** 理解消费者何时以及为何参与故事对内容创作者和平台至关重要。尽管现有理论认为观众对故事发展前景的信念在参与决策中扮演重要角色，但由于缺乏对非结构化叙事数据中此类信念建模的原则性方法，实证工作大多侧重于直接从实际内容中提取特征，而非捕捉前瞻性信念。为了补充现有特征提取技术，本文引入了一个新颖的框架，利用大型语言模型来建模观众对故事可能如何发展的前瞻性信念。我们的方法为每个故事生成多个潜在的延续，并使用既定的内容分析技术提取与预期、不确定性和惊喜相关的特征。将我们的方法应用于超过30,000个图书章节，我们证明了我们的框架通过平均提升31%的边际解释力来补充现有特征工程技术。结果揭示，不同类型的参与度——继续阅读、评论和投票——是由当前和预期内容特征的不同组合驱动的。我们的框架提供了一种新颖的方式来研究和探索观众的前瞻性信念如何塑造他们对叙事媒体的参与，对内容导向行业的营销策略具有重要意义。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [133] [Rationale-guided Prompting for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2412.16936)
> *理由引导的提示用于基于知识的视觉问答*

*Zhongjian Hu, Peng Yang, Bing Li, Fengyuan Liu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 知识型视觉问答, 大型语言模型, 理由启发式, 思维链

**Comment:** 

> **TL;DR:** 提出PLRH框架，通过链式思考生成理由启发式，提高LLM在知识型VQA中的表现，在OK-VQA和A-OKVQA上均有显著提升。

**AI_Comments:** 本文的创新点在于引入了“理由启发式”（Rationale Heuristics）作为中间思考过程来指导LLMs进行知识型VQA，有效解决了以往方法未能充分激活LLMs能力的问题。通过结合CoT，该方法提升了LLMs的可解释性和性能。其重要性在于为未来LLMs在复杂推理任务中的应用提供了新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有的方法直接让LLMs预测答案，忽略中间思考过程，未能充分激活LLMs的能力。

**Method:** 提出PLRH框架，通过思维链（CoT）提示LLMs生成理由启发式（即中间思考过程），然后利用这些理由启发式来启发LLMs预测答案。

**Result:** 在OK-VQA和A-OKVQA数据集上分别比现有基线提高了2.2和2.1。

**Conclusion:** 通过引入中间思考过程（理由启发式）能够有效提升LLMs在知识型VQA任务中的性能。

> **ai_Abstract:** 本文提出了PLRH框架，旨在通过理由启发式提示（Rationale Heuristics Prompting）提升大型语言模型在基于知识的视觉问答（VQA）任务中的表现。不同于以往直接预测答案的方法，PLRH利用思维链（CoT）生成中间思考过程（理由启发式），并以此引导LLMs进行答案预测。实验结果显示，PLRH在OK-VQA和A-OKVQA数据集上均显著优于现有基线，证明了引入中间思考过程的有效性。

> **摘要翻译:** 最近，大型语言模型（LLMs）已被用于基于知识的视觉问答（VQA）。尽管之前的研究取得了令人鼓舞的结果，但先前的方法直接提示LLMs预测答案，忽略了中间思考过程。我们认为先前的方法未能充分激活LLMs的能力。我们提出了一个名为PLRH的框架，用于基于知识的VQA，该框架通过理由启发式提示LLMs。PLRH通过思维链（CoT）提示LLMs生成理由启发式，即中间思考过程，然后利用这些理由启发式来启发LLMs预测答案。实验表明，我们的方法在OK-VQA和A-OKVQA上分别优于现有基线2.2和2.1。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [140] [FineMedLM-o1: Enhancing Medical Knowledge Reasoning Ability of LLM from Supervised Fine-Tuning to Test-Time Training](https://arxiv.org/abs/2501.09213)
> *FineMedLM-o1：从监督微调到测试时训练增强大型语言模型的医学知识推理能力*

*Hongzhou Yu, Tianhao Cheng, Yingwen Wang, Wen He, Qing Wang, Ying Cheng, Yuejie Zhang, Rui Feng, Xiaobo Zhang* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 医学LLM, 深度推理, 监督微调, 测试时训练, 医学合成数据

**Comment:** 

> **TL;DR:** FineMedLM-o1通过结合监督微调（SFT）、直接偏好优化（DPO）和首次在医学领域引入的测试时训练（TTT），显著提升了大型语言模型（LLM）的医学知识推理能力，并在关键医学基准测试中取得了显著性能提升。

**AI_Comments:** 该论文的创新点在于首次将测试时训练（TTT）引入医学领域，以增强大型语言模型的推理能力，并结合了高质量数据合成和先进的微调策略（SFT和DPO）。其重要性体现在显著提升了LLM在复杂医学推理任务上的表现，为构建更可靠的医疗AI系统提供了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有医学大型语言模型（LLMs）在处理复杂医学问题（如鉴别诊断和用药建议）时，缺乏所需的深度推理能力。

**Method:** 本文提出了FineMedLM-o1模型，通过以下方法增强医学知识推理能力：1. 利用高质量医学合成数据和长篇推理数据进行监督微调（SFT）和直接偏好优化（DPO）。2. 首次在医学领域引入测试时训练（TTT），以促进领域适应和确保可靠、准确的推理。3. 提出了一种新颖的医学对话合成方法，生成的数据集在质量和复杂性上优于其他开源数据集。

**Result:** 1. FineMedLM-o1在关键医学基准测试中比现有模型平均性能提升了23%。2. 引入测试时训练（TTT）额外带来了14%的性能提升。3. 新提出的医学对话合成方法生成的数据集在质量和复杂性上优于其他开源数据集。

**Conclusion:** FineMedLM-o1通过结合监督微调、直接偏好优化和首次在医学领域引入的测试时训练，显著增强了大型语言模型在复杂医学问题上的深度推理能力，并提供了高质量的医学对话数据集。

> **ai_Abstract:** 本文介绍了FineMedLM-o1，一个旨在提升大型语言模型在复杂医学问题上深度推理能力的新模型。该模型通过结合监督微调（SFT）、直接偏好优化（DPO）以及首次在医学领域应用的测试时训练（TTT）来实现。实验结果表明，FineMedLM-o1在关键医学基准测试中表现出显著的性能提升，尤其是在TTT的加持下。此外，研究还提出了一种高质量的医学对话数据合成方法。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展在疾病诊断和治疗计划等医疗应用中展现出前景。然而，大多数现有医学LLMs难以进行复杂医学问题所需的深度推理，例如鉴别诊断和用药建议。我们提出了FineMedLM-o1，它利用高质量的医学合成数据和长篇推理数据进行监督微调（SFT）和直接偏好优化（DPO），从而实现高级对话和深度推理能力。此外，我们首次在医学领域引入了测试时训练（TTT），以促进领域适应并确保可靠、准确的推理。实验结果表明，FineMedLM-o1在关键医学基准测试中比现有模型平均性能提高了23%。此外，TTT的引入额外带来了14%的性能提升，突显了其在增强医学推理能力方面的有效性。为了支持这一过程，我们还提出了一种新颖的医学对话合成方法。与其他开源数据集相比，我们的数据集在质量和复杂性方面均表现出色。项目和数据将在GitHub上发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [146] [GneissWeb: Preparing High Quality Data for LLMs at Scale](https://arxiv.org/abs/2502.14907)
> *GneissWeb：为大规模LLMs准备高质量数据*

*Hajar Emami Gohari, Swanand Ravindra Kadhe, Syed Yousaf Shah, Constantin Adam, Abdulhamid Adebayo, Praneet Adusumilli, Farhan Ahmed, Nathalie Baracaldo Angel, Santosh Subhashrao Borse, Yuan-Chi Chang, Xuan-Hong Dang, Nirmit Desai, Revital Eres, Ran Iwamoto, Alexei Karve, Yan Koyfman, Wei-Han Lee, Changchang Liu, Boris Lublinsky, Takuyo Ohko, Pablo Pesce, Maroun Touma, Shiqiang Wang, Shalisha Witherspoon, Herbert Woisetschläger, David Wood, Kun-Lung Wu, Issei Yoshida, Syed Zawad, Petros Zerfos, Yi Zhou, Bishwaranjan Bhattacharjee* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** GneissWeb, 大语言模型, 数据集, 数据质量, 去重

**Comment:** 

> **TL;DR:** GneissWeb是一个包含约10万亿token的大型高质量数据集，通过去重和质量过滤技术构建，能够显著提升大型语言模型的性能，优于现有最先进的开放数据集。

**AI_Comments:** 该论文通过构建一个大规模、高质量的数据集GneissWeb，解决了当前大型语言模型训练中数据可访问性和质量的关键瓶颈。其创新之处在于结合了精确去重和多重质量过滤，平衡了数据量和数据质量。其重要性在于为开源LLM社区提供了一个强大的预训练资源，有望推动LLM性能的进一步提升。论文通过具体性能指标展示了GneissWeb的优越性，但抽象中未提及数据收集的来源和过程的更多细节，这可能是未来研究可以关注的方面。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的性能受数据数量和质量的显著影响。现有领先LLM的预训练数据集公众无法获取，而许多开放数据集规模较小（小于5万亿token），限制了大型模型的训练。

**Method:** 本文介绍了GneissWeb，一个包含约10万亿token的大型数据集。其制作方法包括分片精确子字符串去重和精心构建的质量过滤器集合。

**Result:** GneissWeb在数据质量和数量之间取得了有利的平衡。使用GneissWeb数据集训练的模型，在11个常用基准测试（零样本和少样本）的平均得分上，比使用FineWeb-V1.1.0训练的模型高2.73个百分点。当评估集扩展到20个基准测试时，GneissWeb训练的模型仍比FineWeb-V1.1.0训练的模型高1.75个百分点。

**Conclusion:** GneissWeb通过提供大规模高质量数据，有效解决了大型语言模型数据获取和质量的挑战，显著提升了模型的泛化能力和性能，证明了其在LLM训练中的优越性。

> **ai_Abstract:** 本文介绍了GneissWeb，一个旨在解决大型语言模型（LLMs）高质量大规模数据稀缺问题的新型数据集。GneissWeb包含约10万亿token，通过采用分片精确子字符串去重和多重质量过滤器构建。实验结果表明，使用GneissWeb训练的LLMs在多个常用基准测试上表现优于使用现有最先进开放数据集（如FineWeb-V1.1.0）训练的模型，证明了其在提升LLM性能方面的有效性。

> **摘要翻译:** 数据数量和质量在决定大型语言模型（LLMs）的性能方面起着至关重要的作用。特别是高质量数据，可以显著提升LLM在广泛的下游任务上的泛化能力。领先LLMs的大型预训练数据集仍然不对公众开放，而许多开放数据集规模较小（少于5万亿token），限制了它们在训练大型模型方面的适用性。在本文中，我们介绍了GneissWeb，一个产生约10万亿token的大型数据集，它满足了训练LLMs的数据质量和数量要求。生产该数据集的GneissWeb配方包括分片精确子字符串去重和精心构建的质量过滤器集合。GneissWeb在数据质量和数量之间取得了有利的平衡，生产出的模型优于使用最先进的开放大型数据集（5万亿+token）训练的模型。我们展示了使用GneissWeb数据集训练的模型在11个常用基准测试（包括零样本和少样本）的平均得分上，比使用FineWeb-V1.1.0训练的模型高2.73个百分点，这些基准测试用于预训练数据集评估。当评估集扩展到20个基准测试（包括零样本和少样本）时，使用GneissWeb训练的模型仍比使用FineWeb-V1.1.0训练的模型高1.75个百分点。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [148] [Intent Recognition and Out-of-Scope Detection using LLMs in Multi-party Conversations](https://arxiv.org/abs/2507.22289)
> *意图识别和多方对话中LLMs的范围外检测*

*Galo Castillo-López, Gaël de Chalendar, Nasredine Semmar* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 意图识别, 范围外检测, 大型语言模型, BERT, 多方对话

**Comment:** Accepted for publication at SIGDIAL 2025

> **TL;DR:** 本文提出一种混合BERT和LLMs的方法，用于在零样本和少样本设置下识别多方对话中的用户意图并检测范围外话语，提高了系统性能。

**AI_Comments:** 该研究创新性地结合了BERT的效率和LLMs的泛化能力，解决了传统TODS对标注数据依赖的问题。特别是在零样本和少样本场景下，这种混合方法具有实际应用价值。将BERT输出信息共享给LLMs的策略是其性能提升的关键。

<details>
  <summary>Details</summary>

**Motivation:** 任务导向对话系统（TODS）中，意图识别和范围外（OOS）检测是关键组件，但传统TODS需要大量标注数据。

**Method:** 提出一种结合BERT和LLMs的混合方法，在零样本和少样本设置下进行意图识别和OOS检测。该方法利用LLMs的泛化能力和BERT的计算效率。

**Result:** 在多方对话语料库上评估，观察到将BERT的输出信息共享给LLMs可以提高系统性能。

**Conclusion:** 结合BERT和LLMs的混合方法在多方对话中能有效进行意图识别和OOS检测，并通过信息共享提升性能。

> **ai_Abstract:** 本文针对传统任务导向对话系统在意图识别和范围外检测中对大量标注数据的依赖问题，提出了一种结合BERT和大型语言模型（LLMs）的混合方法。该方法在零样本和少样本设置下，利用LLMs的泛化能力和BERT的计算效率，实现多方对话中的意图识别和OOS检测。实验结果表明，BERT输出信息与LLMs的共享能够提升系统性能。

> **摘要翻译:** 意图识别是面向任务对话系统（TODS）中的一个基本组成部分。确定用户意图并检测意图是否超出范围（OOS）对于TODS提供可靠响应至关重要。然而，传统的TODS需要大量的标注数据。在这项工作中，我们提出了一种混合方法，结合BERT和大型语言模型（LLMs）在零样本和少样本设置下识别意图并检测OOS话语。我们的方法在这种场景下利用了LLMs的泛化能力和BERT的计算效率。我们在多方对话语料库上评估了我们的方法，并观察到将BERT的输出信息共享给LLMs可以提高系统性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [153] [My Life in Artificial Intelligence: People, anecdotes, and some lessons learnt](https://arxiv.org/abs/2504.04142)
> *我在人工智能领域的生活：人物、轶事和一些经验教训*

*Kees van Deemter* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 人工智能, 自然语言处理, 职业生涯, 经验教训, 个人传记

**Comment:** 34 pages

> **TL;DR:** 作者回顾了其在人工智能（特别是自然语言处理）领域40年的职业生涯，分享了个人经历、轶事和经验教训，旨在为年轻同事提供参考。

**AI_Comments:** 这是一篇非常个人化且具有启发性的文章，它不是一篇传统的科学论文，而是一篇职业生涯回顾。其创新之处在于通过个人叙事的方式，提供了对人工智能领域发展历程的独特视角，并为年轻一代提供了宝贵的经验教训。其重要性在于，在技术快速发展的背景下，它强调了个人选择、好奇心和人际关系在职业发展中的作用。

<details>
  <summary>Details</summary>

**Motivation:** 作者旨在分享其在人工智能领域40年的个人经验和教训，为年轻同事在当前人工智能兴起时期面临的职业和生活选择提供参考。

**Method:** 作者通过讲述其在人工智能（特别是自然语言处理）领域40年的个人职业经历，包括在不同国家和机构的工作经验、遇到的人物和轶事，来呈现其观点。

**Result:** 作者分享了其在人工智能领域40年的研究和教育经验，包括在不同国家和机构的工作经历，以及这些经历如何塑造了其职业生涯，并提供了对年轻同事有益的见解。

**Conclusion:** 作者希望通过分享个人经历和经验教训，为年轻同事在人工智能领域蓬勃发展的当下，提供关于职业和生活选择的思考和指导。

> **ai_Abstract:** 本文是一篇个人职业传记，作者回顾了其在人工智能（特别是自然语言处理）领域长达40年的研究和教育生涯。作者分享了好奇心和时代背景如何引导其在工业界和学术界以及多个国家（包括荷兰、美国、英国、苏格兰和中国）的工作经历，并强调了人物和轶事在故事中的重要性。文章旨在为年轻同事在当前人工智能蓬勃发展的时代，提供关于职业和生活选择的经验和启发。

> **摘要翻译:** 在这部非常个人化的职业传记中，我讲述了我在人工智能（AI）领域，特别是自然语言处理（NLP）领域作为研究员和教育者40年的经历。我描述了好奇心和当时的境况如何引导我在工业界和学术界工作，并在包括荷兰（阿姆斯特丹、埃因霍温和乌得勒支）、美国（斯坦福）、英国（布莱顿）、苏格兰（阿伯丁）和中国（北京和哈尔滨）在内的不同国家工作。人物和轶事在我的故事中扮演了重要角色；人工智能的历史构成了其背景。我专注于那些可能对（甚至）年轻同事有益的事情，考虑到在人工智能最终走出阴影的时代，他们将面临自己的工作和生活选择。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [154] [QE4PE: Word-level Quality Estimation for Human Post-Editing](https://arxiv.org/abs/2503.03044)
> *QE4PE：面向人工译后编辑的词级别质量评估*

*Gabriele Sarti, Vilém Zouhar, Grzegorz Chrupała, Ana Guerberof-Arenas, Malvina Nissim, Arianna Bisazza* | **Category: cs.CL, cs.HC** | **Updated: 2025-07-30**

**Keywords:** 词级别质量评估, 人工译后编辑, 机器翻译, 可用性, 生产力

**Comment:** Accepted by TACL (pre-MIT Press publication version); Code:
  https://github.com/gsarti/qe4pe. Dataset:
  https://huggingface.co/datasets/gsarti/qe4pe

> **TL;DR:** 本研究在真实场景下调查了词级别质量评估（QE）对机器翻译译后编辑的影响，发现领域、语言和编辑速度是影响高亮有效性的关键因素，并指出准确性与可用性之间存在差距。

**AI_Comments:** 该研究创新性地将词级别质量评估的可用性置于真实译后编辑场景中进行评估，而非仅仅关注其准确性。其重要性在于揭示了当前QE技术在实际应用中面临的挑战，即准确性与可用性之间的差距，为未来研究指明了方向。研究结果对于改进MT译后编辑工具和工作流程具有实际指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 词级别质量评估（QE）方法的准确性已得到广泛评估，但其可用性及其对人工译后编辑的速度、质量和编辑选择的下游影响仍未得到充分研究。

**Method:** 本研究在真实环境中调查了词级别QE对机器翻译（MT）译后编辑的影响，涉及42名专业译后编辑和两个翻译方向。比较了四种错误跨度高亮模式，包括基于监督和不确定性的词级别QE方法，用于识别最先进神经MT模型输出中的潜在错误。通过行为日志评估译后编辑的努力和生产力，并通过词级别和句段级别的人工标注评估质量改进。

**Result:** 研究发现，领域、语言和编辑速度是决定高亮有效性的关键因素。人工生成的高亮和自动化QE高亮之间存在细微差异，这突显了专业工作流程中准确性与可用性之间的差距。

**Conclusion:** 领域、语言和编辑速度是影响词级别质量评估高亮有效性的关键因素，并且在专业工作流程中，词级别质量评估的准确性与实际可用性之间存在显著差距。

> **ai_Abstract:** 本研究旨在弥补词级别质量评估（QE）系统在译后编辑中可用性研究的不足。通过在真实场景下，对42名专业译后编辑进行实验，比较了四种错误高亮模式对机器翻译译后编辑的影响。研究发现，领域、语言和编辑速度是影响QE高亮有效性的关键因素，并且指出了自动化QE的准确性与在专业工作流中的实际可用性之间存在的差距。

> **摘要翻译:** 词级别质量评估（QE）方法旨在检测机器翻译中的错误跨度，这可以指导和促进人工译后编辑。尽管词级别QE系统的准确性已得到广泛评估，但其可用性及其对人工译后编辑的速度、质量和编辑选择的下游影响仍未得到充分研究。在本研究中，我们调查了词级别QE在真实环境中对机器翻译（MT）译后编辑的影响，涉及42名专业译后编辑和两个翻译方向。我们比较了四种错误跨度高亮模式，包括基于监督和不确定性的词级别QE方法，用于识别最先进神经MT模型输出中的潜在错误。译后编辑的努力和生产力通过行为日志估算，而质量改进则通过词级别和句段级别的人工标注进行评估。我们发现，领域、语言和编辑速度是决定高亮有效性的关键因素，人工生成的高亮和自动化QE高亮之间存在细微差异，这突显了专业工作流程中准确性与可用性之间的差距。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [161] [Prompt-Reverse Inconsistency: LLM Self-Inconsistency Beyond Generative Randomness and Prompt Paraphrasing](https://arxiv.org/abs/2504.01282)
> *提示-反向不一致性：超越生成随机性和提示释义的LLM自我不一致性*

*Jihyun Janice Ahn, Wenpeng Yin* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** LLM不一致性, 提示-反向不一致性, 自我不一致性, 可信AI, LLM作为评判者

**Comment:** accepted in COLM2025, 9 pages

> **TL;DR:** 本文发现了一种新型的LLM自我不一致性，称为提示-反向不一致性（PRIN），即LLM在判断同一组答案中哪些正确、哪些不正确时会给出冲突的响应。PRIN挑战了LLM作为评判者的可信度，并表明LLM在遵循基本逻辑规则方面存在困难。

**AI_Comments:** 这项研究的创新之处在于首次提出了“提示-反向不一致性”（PRIN）这一新的LLM不一致性类型，它不同于以往关注的生成随机性和提示释义引起的不一致。PRIN的发现具有重要意义，因为它直接挑战了LLM作为“评判者”角色的可信度，并揭示了LLM在基础逻辑推理方面存在的深层次问题。这对于发展更可靠、更值得信赖的AI模型至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注生成随机性不一致和释义不一致两种LLM不一致性。本文发现了一种新的LLM自我不一致性——提示-反向不一致性（PRIN），即LLM在判断给定答案候选中哪些是正确答案和哪些是错误答案时经常给出冲突的响应。这种不一致性引发了对LLM作为评判者可信度的担忧，并表明LLM在遵循基本逻辑规则方面面临挑战，因此有必要进行研究。

**Method:** 本研究进行了一系列实验来调查提示-反向不一致性（PRIN），包括检查PRIN在不同LLM中的程度、缓解它的方法、潜在应用，以及它与随机性不一致和释义不一致的关系。

**Result:** 作为首次探索PRIN的研究，我们的发现为LLM的内部运作提供了宝贵的见解，并有助于推动可信AI的发展。

**Conclusion:** 提示-反向不一致性（PRIN）是一个重大问题，因为它损害了LLM作为评判者的可信度，并表明LLM在遵循基本逻辑规则方面面临挑战。

> **ai_Abstract:** 本文介绍了一种新型的LLM自我不一致性，称为提示-反向不一致性（PRIN）。与现有研究关注的随机性不一致和释义不一致不同，PRIN表现为LLM在判断给定答案候选中哪些是正确答案和哪些是错误答案时给出冲突的响应。这一发现对LLM作为评判者的可信度构成了挑战，并揭示了LLM在遵循基本逻辑规则方面的困难。研究通过一系列实验探讨了PRIN的程度、缓解方法、应用及其与其他不一致性的关系，旨在深入理解LLM的内部机制并促进可信AI的发展。

> **摘要翻译:** 虽然LLM的不一致性不是一个新话题，但之前的研究主要集中在两种类型的生成不一致性上：i) 随机性不一致：多次运行同一个LLM，产生不同的响应；ii) 释义不一致：释义后的提示导致同一个LLM产生不同的响应。随机性不一致源于生成模型中随机抽样的固有随机性，而释义不一致是语言建模目标的结果，其中释义后的提示改变了词汇logits的分布。本研究发现了提示-反向不一致性（PRIN），这是一种新型的LLM自我不一致性：给定一个问题和几个LLM生成的候选答案，当提示“哪些是正确答案？”和“哪些是错误答案？”时，LLM经常会有冲突的响应。PRIN提出了一个重大担忧，因为它损害了LLM作为评判者的可信度，并表明LLM在遵循基本逻辑规则方面面临挑战。我们进行了一系列实验来调查PRIN，检查PRIN在不同LLM中的程度、缓解它的方法、潜在应用，以及它与随机性不一致和释义不一致的关系。作为首次探索PRIN的研究，我们的发现为LLM的内部运作提供了宝贵的见解，并有助于推动可信AI的发展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [168] [Voices of Freelance Professional Writers on AI: Limitations, Expectations, and Fears](https://arxiv.org/abs/2504.05008)
> *自由职业专业作家对AI的看法：局限性、期望和担忧*

*Anastasiia Ivanova, Natalia Fedorova, Sergei Tilga, Ekaterina Artemova* | **Category: cs.CL, cs.CY, cs.HC** | **Updated: 2025-07-30**

**Keywords:** AI写作, 大型语言模型, 专业作家, 问卷调查, 伦理问题

**Comment:** 

> **TL;DR:** 本研究通过问卷和互动调查，探讨了自由职业专业作家对AI（特别是大型语言模型）在写作中的使用、局限性、期望和担忧，尤其关注非英语用户的采纳、伦理问题和误信息等。

**AI_Comments:** 这项研究的创新之处在于其直接面向自由职业专业作家群体，并关注了AI在多语言环境下的应用，这对于理解AI对全球写作生态的影响至关重要。其对伦理、误信息和作家声音的关注也提升了研究的深度。

<details>
  <summary>Details</summary>

**Motivation:** 尽管AI工具，特别是大型语言模型（LLMs），正在重塑专业写作，但其采纳的关键方面，如语言支持、伦理以及对作家声音和创造力的长期影响，仍未得到充分探索。

**Method:** 本研究对经常使用AI的专业作家进行了问卷调查（N=301）和互动调查（N=36）。

**Result:** 调查结果揭示了重要见解，包括LLMs对非英语使用者的重要性、误信息的程度、领域和风格适应性、可用性以及LLMs的关键功能。

**Conclusion:** 这些见解可以指导未来的发展，使作家和更广泛的用户群受益。

> **ai_Abstract:** 本研究通过对301名专业作家的问卷调查和36名作家的互动调查，深入探讨了大型语言模型（LLMs）在专业写作中的应用。研究聚焦于LLMs在多语言环境下的使用、伦理考量、用户期望及其对作家声音和创造力的影响。核心发现强调了LLMs对非英语用户的重要性、信息准确性、风格适应性及可用性，旨在为AI工具的未来发展提供指导。

> **摘要翻译:** AI驱动工具，特别是大型语言模型（LLMs）的快速发展，正在重塑专业写作。然而，其采纳的一些关键方面，例如语言支持、伦理以及对作家声音和创造力的长期影响，仍未得到充分探索。在这项工作中，我们对经常使用AI的专业作家进行了问卷调查（N=301）和互动调查（N=36）。我们研究了LLM辅助的跨25种以上语言的写作实践、伦理问题和用户期望。调查结果展示了重要的见解，反映了以下几点的重要性：LLMs对非英语使用者的采纳；误信息的程度、领域和风格适应性；LLMs的可用性和关键功能。这些见解可以指导未来的发展，使作家和更广泛的用户群受益。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [173] [BERSting at the Screams: A Benchmark for Distanced, Emotional and Shouted Speech Recognition](https://arxiv.org/abs/2505.00059)
> *BERSting at the Screams: 远距离、情感和喊叫语音识别的基准*

*Paige Tuttösí, Mantaj Dhillon, Luna Sang, Shane Eastwood, Poorvi Bhatia, Quang Minh Dinh, Avni Kapoor, Yewon Jin, Angelica Lim* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-07-30**

**Keywords:** 语音识别, 数据集, ASR, 情感识别, 喊叫语音

**Comment:** Accepted to Computer Speech and Language, Special issue:
  Multi-Speaker, Multi-Microphone, and Multi-Modal Distant Speech Recognition.
  Project Webpage and Data access :
  https://huggingface.co/datasets/Rosie-Lab/BERSt

> **TL;DR:** 本文提出了BERSt数据集，一个针对远距离、情感和喊叫语音识别的基准，以解决现有ASR系统在复杂真实世界场景中的不足。

**AI_Comments:** 该论文的创新之处在于其专注于解决现有语音识别系统在远距离、情感和喊叫语音等复杂真实世界场景中的不足。通过创建BERSt数据集，研究人员提供了一个独特且多样的资源，涵盖了多种声学环境、情感和语音类型，这对于推动ASR和SER领域的发展至关重要。数据集的收集方式（在演员家中通过智能手机）增加了数据的真实性和多样性。其重要性在于为未来研究提供了一个具有挑战性的基准，有助于开发更鲁棒、更适应真实世界条件的语音识别系统。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自动语音识别（ASR）在许多指标上已接近或达到人类水平，但在复杂、真实世界的场景（如远距离语音）中仍然表现不佳。现有数据集主要关注距离，且依赖多麦克风阵列系统，未能充分解决情感和喊叫语音的问题。

**Method:** 研究人员创建了BERSt（B(asic) E(motion) R(andom phrase) S(hou)t(s)）数据集。该数据集包含近4小时的英语语音，来自98位演员，具有不同的区域和非母语口音。数据通过智能手机在演员家中收集，因此包含至少98种不同的声学环境。数据还包括7种不同的情感提示以及喊叫和正常说话的语音。智能手机放置在19个不同的位置，包括有障碍物和与演员在不同房间的情况。该数据集公开可用，并提供了ASR和语音情感识别（SER）的初步基准测试。

**Result:** 初步基准测试结果显示，ASR性能随着距离和喊叫水平的增加而下降，并且根据预期的情感表现出不同的性能。BERSt数据集对ASR和SER任务都具有挑战性。

**Conclusion:** BERSt数据集为远距离、情感和喊叫语音识别提供了重要的基准。结果表明，ASR和SER系统在处理这些复杂场景时仍需改进，以提高在真实世界使用中的鲁棒性和准确性。

> **ai_Abstract:** 本文介绍了BERSt数据集，旨在解决自动语音识别（ASR）在复杂真实世界场景中，特别是远距离、情感和喊叫语音方面的挑战。该数据集包含近4小时的智能手机录音，来自98位演员，涵盖多种口音、98种声学环境、7种情感以及喊叫和正常说话。智能手机放置在19个不同位置，模拟真实世界场景。研究者提供了ASR和语音情感识别（SER）的初步基准，结果显示ASR性能随距离和喊叫水平增加而下降，且受情感影响。BERSt数据集对现有ASR和SER系统构成挑战，强调了提高系统鲁棒性的必要性。

> **摘要翻译:** 一些语音识别任务，如自动语音识别（ASR），在许多报告的指标中正在接近或已经达到人类表现。然而，它们在复杂、真实世界的场景中，例如远距离语音，仍然表现不佳。以前的挑战已经发布了数据集来解决远距离ASR的问题，但重点仍然主要放在距离上，特别是依赖于多麦克风阵列系统。我们在此提出了B(asic) E(motion) R(andom phrase) S(hou)t(s)（BERSt）数据集。该数据集包含来自98位演员的近4小时英语语音，这些演员具有不同的区域和非母语口音。数据是在演员家中通过智能手机收集的，因此至少包括98种不同的声学环境。数据还包括7种不同的情感提示以及喊叫和正常说话的语音。智能手机被放置在19个不同的位置，包括有障碍物和与演员在不同房间的情况。该数据可公开使用，可用于评估各种语音识别任务，包括：ASR、喊叫检测和语音情感识别（SER）。我们为ASR和SER任务提供了初步基准，发现ASR性能随着距离和喊叫水平的增加而下降，并根据预期的情感表现出不同的性能。我们的结果表明，BERSt数据集对ASR和SER任务都具有挑战性，需要继续努力以提高此类系统的鲁棒性，从而实现更准确的真实世界应用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [175] [Déjà Vu: Multilingual LLM Evaluation through the Lens of Machine Translation Evaluation](https://arxiv.org/abs/2504.11829)
> *似曾相识：通过机器翻译评估的视角对多语言大型语言模型进行评估*

*Julia Kreutzer, Eleftheria Briakou, Sweta Agrawal, Marzieh Fadaee, Kocmi Tom* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 多语言LLM, 评估, 机器翻译, 最佳实践, 元评估

**Comment:** 

> **TL;DR:** 多语言LLM的生成能力评估实践缺乏全面性和严谨性。本文借鉴机器翻译评估的最佳实践，通过实验展示如何深化对模型质量差异的理解，并提出多语言LLM评估的行动建议清单。

**AI_Comments:** 该论文的创新之处在于将机器翻译评估领域的成熟经验引入到多语言大型语言模型的评估中，提供了一个新的视角和一套可行的解决方案。这对于当前快速发展的mLLM领域具有重要意义，有助于推动评估实践的标准化和科学化，从而更好地指导模型开发。其提出的建议清单具有很强的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 多语言大型语言模型（mLLM）的生成能力和语言覆盖范围正在迅速发展，但其生成能力的评估实践仍缺乏全面性、科学严谨性和研究实验室之间的一致性，这削弱了它们有效指导mLLM开发的潜力。

**Method:** 本文借鉴了机器翻译（MT）评估领域的经验，该领域在过去几十年中为多语言生成模型开发了透明的报告标准和可靠的评估方法。通过在生成评估管道关键阶段进行的有针对性的实验，本文展示了MT评估的最佳实践如何加深对模型之间质量差异的理解。此外，本文还确定了对mLLM进行鲁棒元评估的基本组成部分。

**Result:** 本文演示了机器翻译评估的最佳实践如何能加深对多语言大型语言模型之间质量差异的理解。同时，本文还识别了对mLLM进行鲁棒元评估的关键组成部分，以确保评估方法本身得到严格评估。

**Conclusion:** 本文将这些见解提炼成一份可操作的建议清单，以指导多语言大型语言模型的研究和开发。

> **ai_Abstract:** 该论文指出当前多语言大型语言模型（mLLM）的生成能力评估存在不足，缺乏全面性、严谨性和一致性。为解决此问题，论文借鉴了机器翻译（MT）评估领域的成熟经验和最佳实践，通过实验证明这些方法能有效提升对mLLM模型质量差异的理解。此外，论文还提出了mLLM元评估的关键要素，并最终提供了一份针对mLLM研发的可操作性建议清单。

> **摘要翻译:** 多语言大型语言模型（mLLM）的生成能力和语言覆盖范围正在迅速发展。然而，mLLM生成能力的评估实践仍然缺乏全面性、科学严谨性和研究实验室之间的一致性，这削弱了它们有效指导mLLM开发的潜力。我们借鉴了机器翻译（MT）评估领域的经验，该领域曾面临类似挑战，并在几十年间为多语言生成模型开发了透明的报告标准和可靠的评估方法。通过在生成评估管道关键阶段进行的有针对性的实验，我们展示了MT评估的最佳实践如何能加深对模型之间质量差异的理解。此外，我们还确定了对mLLM进行鲁棒元评估的基本组成部分，确保评估方法本身得到严格评估。我们将这些见解提炼成一份可操作的建议清单，以指导mLLM的研究和开发。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [181] [Traits Run Deep: Enhancing Personality Assessment via Psychology-Guided LLM Representations and Multimodal Apparent Behaviors](https://arxiv.org/abs/2507.22367)
> *特质深藏不露：通过心理学引导的LLM表征和多模态表观行为增强人格评估*

*Jia Li, Yichao He, Jiacheng Xu, Tianhao Luo, Zhenzhen Hu, Richang Hong, Meng Wang* | **Category: cs.CL, cs.MM** | **Updated: 2025-07-30**

**Keywords:** 人格评估, LLM, 多模态融合, 心理学引导, 特质

**Comment:** 8 pages, 3 figures, ACM MM 2025

> **TL;DR:** 本文提出了一种名为“特质深藏不露”的新型人格评估框架，通过心理学引导的大语言模型（LLM）表征和多模态融合，显著提高了人格评估的准确性，并在AVI挑战赛中排名第一。

**AI_Comments:** 这篇论文通过将心理学洞察与先进的大语言模型（LLMs）和多模态融合相结合，为人格评估引入了一种创新方法。其中，利用心理学引导的提示来指导LLMs提取更相关的人格语义，这一点尤为新颖。所设计的多模态融合网络有效地整合了不同模态的信号，克服了跨模态理解的挑战。其在知名挑战赛中取得的顶尖表现，凸显了其在心理健康和个性化教育等领域的实际意义和潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 准确可靠的人格评估在情绪智能、心理健康诊断和个性化教育等多个领域至关重要。然而，人格特质稳定且常通过语言、面部表情和身体行为无意识地泄露，并以跨模态的异步模式呈现，传统方法难以通过表面特征建模人格语义，也难以实现有效的跨模态理解。

**Method:** 本文提出了一种名为“特质深藏不露”（Traits Run Deep）的新型人格评估框架。该框架采用心理学引导的提示（psychology-informed prompts）来提取与人格相关的高级语义表征。此外，它设计了一个以文本为中心的特质融合网络（Text-Centric Trait Fusion Network），将丰富的文本语义作为锚点，以对齐和整合来自其他模态的异步信号。具体而言，该融合模块包括一个分块投影器（Chunk-Wise Projector）以降低维度，一个跨模态连接器（Cross-Modal Connector）和一个文本特征增强器（Text Feature Enhancer）以实现有效的模态融合，以及一个集成回归头（ensemble regression head）以提高在数据稀缺情况下的泛化能力。据作者所知，这是首次应用人格特定提示来指导大语言模型（LLMs）提取人格感知语义以提高表征质量。此外，提取和融合视听表观行为特征进一步提高了准确性。

**Result:** 在AVI验证集上的实验结果表明，所提出的组件是有效的，均方误差（MSE）大约减少了45%。在AVI挑战赛2025测试集上的最终评估证实了该方法的优越性，在人格评估赛道中排名第一。

**Conclusion:** 本文提出的“特质深藏不露”框架，通过心理学引导的LLM表征和多模态融合，显著增强了人格评估的准确性，并实现了最先进的性能。

> **ai_Abstract:** 本文提出了一种名为“特质深藏不露”（Traits Run Deep）的新型人格评估框架，旨在通过结合心理学引导的大语言模型（LLM）表征和多模态表观行为来提高评估准确性。该框架利用心理学提示从LLM中提取高级人格语义，并设计了一个以文本为中心的特质融合网络，以有效整合来自文本、面部表情和身体行为等不同模态的异步信号。该方法通过改进跨模态理解和表征质量，克服了传统评估的挑战。实验结果表明，该方法显著提升了性能，在AVI验证集上将均方误差（MSE）降低了约45%，并在AVI挑战赛2025中获得人格评估赛道的第一名。

> **摘要翻译:** 准确可靠的人格评估在情绪智能、心理健康诊断和个性化教育等多个领域发挥着至关重要的作用。与转瞬即逝的情绪不同，人格特质是稳定的，常常通过语言、面部表情和身体行为无意识地泄露，并以跨模态的异步模式呈现。传统方法难以通过表面特征建模人格语义，并且似乎无法实现有效的跨模态理解。为了应对这些挑战，我们提出了一种名为“特质深藏不露”（Traits Run Deep）的新型人格评估框架。它采用心理学引导的提示（psychology-informed prompts）来提取与人格相关的高级语义表征。此外，它设计了一个以文本为中心的特质融合网络（Text-Centric Trait Fusion Network），将丰富的文本语义作为锚点，以对齐和整合来自其他模态的异步信号。具体而言，这种融合模块包括一个分块投影器（Chunk-Wise Projector）以降低维度，一个跨模态连接器（Cross-Modal Connector）和一个文本特征增强器（Text Feature Enhancer）以实现有效的模态融合，以及一个集成回归头（ensemble regression head）以提高在数据稀缺情况下的泛化能力。据我们所知，我们是第一个应用人格特定提示来指导大语言模型（LLMs）提取人格感知语义以提高表征质量的。此外，提取和融合视听表观行为特征进一步提高了准确性。在AVI验证集上的实验结果表明，所提出的组件是有效的，即均方误差（MSE）大约减少了45%。在AVI挑战赛2025测试集上的最终评估证实了我们方法的优越性，在人格评估赛道中排名第一。源代码将发布在https://github.com/MSA-LMC/TraitsRunDeep。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [182] [IterKey: Iterative Keyword Generation with LLMs for Enhanced Retrieval Augmented Generation](https://arxiv.org/abs/2505.08450)
> *IterKey：基于LLM的迭代式关键词生成，用于增强检索增强生成*

*Kazuki Hayashi, Hidetaka Kamigaito, Shinya Kouda, Taro Watanabe* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** IterKey, RAG, LLM, 关键词生成, 稀疏检索

**Comment:** 

> **TL;DR:** IterKey是一个利用LLM迭代生成关键词以增强检索增强生成（RAG）的框架，通过稀疏检索平衡了准确性和可解释性。

**AI_Comments:** 这篇论文通过引入迭代式关键词生成机制，巧妙地结合了大型语言模型（LLMs）的能力与稀疏检索的透明度，解决了RAG中准确性和可解释性难以兼顾的问题。其创新点在于利用LLM进行多阶段的关键词精炼和答案验证，这为提升基于稀疏检索的RAG性能提供了一个有效途径，特别是在需要解释性的场景下具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有检索增强生成（RAG）方法在实际应用中面临准确性和可解释性之间的权衡。密集检索准确但缺乏可解释性，而稀疏检索虽透明但因依赖关键词匹配而未能充分捕捉查询意图。

**Method:** IterKey是一个LLM驱动的迭代关键词生成框架，用于通过稀疏检索增强RAG。它包含三个LLM驱动的阶段：生成用于检索的关键词、基于检索到的文档生成答案、验证答案。如果验证失败，该过程会使用精炼的关键词迭代重复。

**Result:** 在四个问答任务中，IterKey比基于BM25的RAG和简单基线提高了5%到20%的准确性。其性能与基于密集检索的RAG和之前使用密集模型的迭代查询精炼方法相当。

**Conclusion:** IterKey是一种新颖的、基于BM25的方法，它利用大型语言模型（LLMs）迭代地改进检索增强生成（RAG），有效地平衡了准确性和可解释性。

> **ai_Abstract:** IterKey是一个创新的LLM驱动框架，旨在通过迭代关键词生成来增强检索增强生成（RAG）中的稀疏检索。它通过三阶段流程（关键词生成、答案生成、答案验证和迭代精炼）解决了RAG在准确性和可解释性之间的权衡问题。实验证明，IterKey在准确性上显著优于基线，并与密集检索方法表现相当，同时保持了可解释性。

> **摘要翻译:** 检索增强生成（RAG）已成为通过整合外部文档来补充大型语言模型（LLMs）上下文知识的一种方式。然而，实际应用不仅要求准确性，还要求可解释性。虽然密集检索方法提供高准确性，但缺乏可解释性；相反，稀疏检索方法提供透明度，但由于其依赖关键词匹配，往往无法捕捉查询的完整意图。为了解决这些问题，我们引入了IterKey，一个LLM驱动的迭代关键词生成框架，通过稀疏检索增强RAG。IterKey由三个LLM驱动的阶段组成：生成用于检索的关键词、基于检索到的文档生成答案，以及验证答案。如果验证失败，该过程将使用精炼的关键词迭代重复。在四个问答任务中，实验结果表明IterKey比基于BM25的RAG和简单基线提高了5%到20%的准确性。其性能与基于密集检索的RAG和之前使用密集模型的迭代查询精炼方法相当。总而言之，IterKey是一种新颖的、基于BM25的方法，它利用LLMs迭代地改进RAG，有效地平衡了准确性和可解释性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [189] [What Are They Talking About? A Benchmark of Knowledge-Grounded Discussion Summarization](https://arxiv.org/abs/2505.12474)
> *他们在谈论什么？一个基于知识的讨论摘要基准*

*Weixiao Zhou, Junnan Zhu, Gengyao Li, Xianfu Cheng, Xinnian Liang, Feifei Zhai, Zhoujun Li* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 基于知识的讨论, 摘要, 基准, 大型语言模型, 上下文

**Comment:** 20 pages, 17 figures and 8 tables

> **TL;DR:** 现有的对话摘要方法在处理基于共享背景的讨论时效果不佳，因为参与者常省略上下文。本文提出“基于知识的讨论摘要”（KGDS）新任务，旨在生成背景摘要和清晰的观点摘要。为此，作者构建了首个KGDS基准，并评估了12个先进的大型语言模型，结果显示KGDS仍是一个重大挑战。

**AI_Comments:** 本文的创新之处在于识别并解决了一个重要的摘要任务局限性——即现有方法难以处理需要外部知识背景的讨论。通过提出KGDS任务、构建首个专门的基准数据集和设计层次化评估框架，该研究为知识背景讨论摘要领域奠定了基础，并指明了未来的研究方向。其对先进LLM的评估结果揭示了当前模型在该任务上的显著不足，凸显了任务的挑战性和重要性，对推动更智能、更具上下文感知能力的摘要系统发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的对话摘要主要关注对话内容本身，并假设其包含足够信息来生成清晰的摘要。然而，对于基于共享背景的讨论，参与者经常省略上下文并使用隐式引用，导致不熟悉背景的读者难以理解摘要。

**Method:** 为解决上述问题，本文引入了“基于知识的讨论摘要”（KGDS）这一新任务，旨在生成补充性的背景摘要和带有澄清引用的清晰观点摘要。为促进研究，作者构建了首个KGDS基准，其中包含新闻-讨论对和专家创建的多粒度黄金标注，用于评估子摘要。同时，提出了一种新颖的、具有细粒度和可解释指标的层次化评估框架。此外，对12个先进的大型语言模型进行了广泛评估。

**Result:** 对12个先进的大型语言模型（LLMs）的广泛评估表明，基于知识的讨论摘要（KGDS）仍然是一个重大挑战。模型在背景摘要中经常遗漏关键事实并保留不相关信息，并且在观点摘要整合中常常无法解决隐式引用。

**Conclusion:** 基于知识的讨论摘要（KGDS）对现有大型语言模型而言仍是一个重大挑战，模型在背景摘要和观点摘要整合方面均存在不足，表明该领域仍有待深入研究。

> **ai_Abstract:** 本文针对传统对话摘要在处理包含隐式上下文的知识背景讨论时的局限性，提出了“基于知识的讨论摘要”（KGDS）这一新任务。KGDS旨在生成补充背景摘要和清晰的观点摘要。为推动研究，作者构建了首个KGDS基准数据集，包含新闻-讨论对和专家标注，并提出了一种新的层次化评估框架。对12个先进大型语言模型的评估结果显示，KGDS对现有模型来说仍是一项重大挑战，模型在捕捉关键事实、过滤无关信息以及解决隐式引用方面表现不足。

> **摘要翻译:** 传统的对话摘要主要关注对话内容，假设其包含足够信息以形成清晰的摘要。然而，对于基于共享背景的讨论，这一假设常常失效，因为参与者经常省略上下文并使用隐式引用。这导致不熟悉背景的读者难以理解摘要。为解决此问题，我们引入了基于知识的讨论摘要（KGDS），这是一项新颖的任务，旨在为上下文生成补充背景摘要，并生成带有澄清引用的清晰观点摘要。为促进研究，我们构建了首个KGDS基准，其中包含新闻-讨论对和专家创建的多粒度黄金标注，用于评估子摘要。我们还提出了一种新颖的、具有细粒度和可解释指标的层次化评估框架。我们对12个先进的大型语言模型（LLMs）的广泛评估表明，KGDS仍然是一个重大挑战。模型在背景摘要中经常遗漏关键事实并保留不相关信息，并且在观点摘要整合中常常无法解决隐式引用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [196] [Denoising Concept Vectors with Sparse Autoencoders for Improved Language Model Steering](https://arxiv.org/abs/2505.15038)
> *使用稀疏自编码器去噪概念向量以改进语言模型引导*

*Haiyan Zhao, Xuansheng Wu, Fan Yang, Bo Shen, Ninghao Liu, Mengnan Du* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 概念向量, 稀疏自编码器, 语言模型引导, 去噪, LLM

**Comment:** 12 pages, 4 figures, 4 tables

> **TL;DR:** 本文提出SDCV方法，通过稀疏自编码器去噪概念向量，显著提升了大型语言模型（LLM）引导的成功率和鲁棒性。

**AI_Comments:** 这项工作通过引入稀疏自编码器进行概念向量去噪，为提高大型语言模型引导的鲁棒性提供了一种新颖且有效的方法。其创新点在于显式地将概念信号与噪声分离，并通过量化改进证明了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在引导大型语言模型（LLM）时，线性概念向量因多样化数据集中的噪声特征而导致引导鲁棒性不足。

**Method:** 本文提出了稀疏自编码器去噪概念向量（SDCV）方法。其核心思想是通过放大最能区分正负样本的前k个潜在变量的激活，显式地将概念相关信号与数据集噪声分离，同时重建隐藏表示。

**Result:** SDCV方法应用于线性探测和均值差分时，在六个具有挑战性的概念上，引导成功率稳定提高了4-16%，同时保持了主题相关性。

**Conclusion:** 通过使用稀疏自编码器去噪概念向量，可以有效提升大型语言模型引导的鲁棒性和成功率。

> **ai_Abstract:** 本文提出了一种名为稀疏自编码器去噪概念向量（SDCV）的新方法，旨在解决现有线性概念向量在引导大型语言模型（LLM）时因数据集噪声导致的鲁棒性问题。SDCV通过稀疏自编码器选择性地保留判别性潜在变量，并将概念相关信号与噪声分离，从而在保持主题相关性的同时，将LLM引导的成功率提高了4-16%。

> **摘要翻译:** 线性概念向量能有效引导大型语言模型（LLM），但现有方法受限于多样化数据集中存在的噪声特征，这些噪声特征会削弱引导的鲁棒性。我们提出了稀疏自编码器去噪概念向量（SDCV），它在重建隐藏表示的同时，选择性地保留最具判别性的稀疏自编码器潜在变量。我们的关键见解是，通过放大最能区分正负样本的前k个潜在变量的激活，可以将概念相关信号与数据集噪声明确分离。将SDCV应用于线性探测和均值差分时，在六个具有挑战性的概念上，SDCV始终将引导成功率提高了4-16%，同时保持了主题相关性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [203] [MiniLongBench: The Low-cost Long Context Understanding Benchmark for Large Language Models](https://arxiv.org/abs/2505.19959)
> *MiniLongBench：大语言模型低成本长文本理解基准*

*Zhongzhan Huang, Guoming Ling, Shanshan Zhong, Hefeng Wu, Liang Lin* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 长文本理解, 大语言模型, 基准测试, 成本效率, 数据压缩

**Comment:** Accepted by ACL'25 main track

> **TL;DR:** MiniLongBench是一个低成本的长文本理解基准，通过数据压缩显著降低了评估LLM的成本，同时保持了与现有基准的高度相关性。

**AI_Comments:** 本文创新性地解决了LLM长文本理解基准评估成本过高的问题，通过数据压缩实现了高效且准确的评估。MiniLongBench的提出对于加速LLM在长文本处理领域的研究具有重要意义，因为它降低了研究门槛和资源消耗。其方法简洁有效，并且通过实证分析验证了其与现有基准的高度一致性，证明了其可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM的长文本理解（LCU）基准评估成本过高（测试时间、推理费用），且存在显著冗余，导致评估效率低下。

**Method:** 提出了一种针对信息稀疏长文本数据的简洁数据压缩方法，通过修剪著名的LCU基准LongBench，创建了MiniLongBench。该基准仅包含237个测试样本，涵盖六个主要任务类别和21个不同任务。

**Result:** MiniLongBench将LLM的平均评估成本降低到原始的4.5%，同时与LongBench结果的平均排名相关系数达到0.97。

**Conclusion:** MiniLongBench作为一个低成本的基准，具有巨大潜力，可以实质性地推动未来对LLM的长文本理解（LCU）能力的研究。

> **ai_Abstract:** 本文提出了MiniLongBench，一个针对大型语言模型（LLM）长文本理解（LCU）能力的低成本评估基准。鉴于现有LCU基准评估成本高昂且存在冗余，作者开发了一种简洁的数据压缩方法，并基于LongBench创建了MiniLongBench。该新基准仅包含237个样本，涵盖六大任务类别和21个具体任务。实验证明，MiniLongBench能将评估成本降低至原始的4.5%，同时与LongBench的排名相关性高达0.97，显示出其在推动LLM长文本理解研究方面的巨大潜力。

> **摘要翻译:** 长文本理解（LCU）是当前大型语言模型（LLM）探索的关键领域。然而，由于长文本数据固有的冗长性，现有针对LLM的LCU基准通常导致评估成本过高，例如测试时间和推理费用。通过大量的实验，我们发现现有的LCU基准表现出显著的冗余，这意味着评估效率低下。在本文中，我们提出了一种针对信息稀疏长文本数据量身定制的简洁数据压缩方法。通过修剪著名的LCU基准LongBench，我们创建了MiniLongBench。该基准仅包含六个主要任务类别和21个不同任务的237个测试样本。通过对60多个LLM的实证分析，MiniLongBench将平均评估成本降低到原始的4.5%，同时与LongBench结果的平均排名相关系数保持在0.97。因此，我们的MiniLongBench作为一个低成本的基准，具有巨大潜力，可以实质性地推动未来对LLM的LCU能力的研究。请访问https://github.com/MilkThink-Lab/MiniLongBench 获取我们的代码、数据和教程。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [210] [Leveraging Large Language Models for Bengali Math Word Problem Solving with Chain of Thought Reasoning](https://arxiv.org/abs/2505.21354)
> *利用大型语言模型和思维链推理解决孟加拉语数学应用题*

*Bidyarthi Paul, Jalisha Jashim Era, Mirazur Rahman Zim, Tahmid Sattar Aothoi, Faisal Muhammad Shah* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 孟加拉语数学应用题, 大型语言模型, 思维链推理, SOMADHAN数据集, 低资源语言

**Comment:** 

> **TL;DR:** 本文创建了首个孟加拉语数学应用题数据集SOMADHAN，并评估了多种大型语言模型在思维链推理下的表现，发现CoT显著提升了解决复杂孟加拉语数学应用题的能力，并提出高效的微调方法。

**AI_Comments:** 本文的主要创新在于首次构建了一个大规模、高质量的孟加拉语数学应用题数据集SOMADHAN，这对于解决低资源语言的数学推理问题具有里程碑意义。通过系统地评估大型语言模型在思维链推理下的表现，并引入高效的LoRA微调方法，为孟aj加拉语乃至其他低资源语言的NLP研究提供了宝贵的资源和可行的路径。这项工作不仅填补了关键的数据空白，也为推进语言公平性和教育技术中的AI推理能力做出了重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 孟加拉语数学应用题（MWPs）的解决在自然语言处理（NLP）中面临重大挑战，原因在于该语言的低资源状态和所需的多步骤推理。现有模型难以处理复杂的孟加拉语MWPs，主要是因为此前没有针对此任务的人工标注孟加拉语数据集。这一空白限制了孟加拉语数学推理的进展。

**Method:** 我们创建了SOMADHAN数据集，包含8792个复杂孟加拉语MWPs及其手动编写的逐步解决方案，旨在支持以推理为重点的评估和模型开发。我们使用SOMADHAN评估了一系列大型语言模型（LLMs），包括GPT-4o、GPT-3.5 Turbo、LLaMA系列模型、Deepseek和Qwen，采用零样本和少样本提示，并结合或不结合思维链（CoT）推理。此外，我们应用低秩适应（LoRA）高效地微调模型，使其以最小的计算成本适应孟加拉语MWPs。

**Result:** 思维链（CoT）提示始终优于标准提示，尤其是在需要多步逻辑的任务中。LLaMA-3.3 70B在少样本CoT提示下达到了88%的最高准确率。LoRA微调方法能够高效地使模型适应孟加拉语MWPs。

**Conclusion:** 我们的工作通过提供高质量的推理数据集和可扩展的复杂MWPs解决方案框架，填补了孟加拉语NLP的关键空白。我们旨在推动低资源语言的公平研究，并增强教育和语言技术中的推理能力。

> **ai_Abstract:** 本文针对孟加拉语数学应用题（MWPs）在低资源语言环境下缺乏数据集和推理能力不足的问题，提出了SOMADHAN数据集，该数据集包含8792个复杂孟加拉语MWPs及其逐步解决方案。研究评估了多种大型语言模型在思维链（CoT）推理下的性能，结果表明CoT能显著提升多步逻辑任务的表现，其中LLaMA-3.3 70B在少样本CoT下达到88%的最高准确率。此外，文章还利用LoRA技术实现了模型的高效微调。这项工作为孟加拉语NLP提供了高质量的推理数据集和可扩展的解决方案框架，旨在促进低资源语言的公平研究和提升教育技术中的推理能力。

> **摘要翻译:** 解决孟加拉语数学应用题（MWPs）在自然语言处理（NLP）中仍然是一个重大挑战，原因在于该语言的低资源状态和所需的多步骤推理。现有模型难以处理复杂的孟加拉语MWPs，很大程度上是因为此前没有针对此任务的人工标注孟加拉语数据集。这一空白限制了孟加拉语数学推理的进展。为解决此问题，我们创建了SOMADHAN，一个包含8792个复杂孟加拉语MWPs及其手动编写的逐步解决方案的数据集。我们设计该数据集旨在支持在语言资源匮乏的背景下进行以推理为重点的评估和模型开发。使用SOMADHAN，我们通过零样本和少样本提示，结合或不结合思维链（CoT）推理，评估了一系列大型语言模型（LLMs），包括GPT-4o、GPT-3.5 Turbo、LLaMA系列模型、Deepseek和Qwen。CoT提示始终优于标准提示，尤其是在需要多步逻辑的任务中。LLaMA-3.3 70B在少样本CoT提示下达到了88%的最高准确率。我们还应用低秩适应（LoRA）高效地微调模型，使其以最小的计算成本适应孟加拉语MWPs。我们的工作通过提供高质量的推理数据集和可扩展的复杂MWPs解决方案框架，填补了孟加拉语NLP的关键空白。我们旨在推动低资源语言的公平研究，并增强教育和语言技术中的推理能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [216] [PATENTWRITER: A Benchmarking Study for Patent Drafting with LLMs](https://arxiv.org/abs/2507.22387)
> *PATENTWRITER：一项基于LLM的专利起草基准研究*

*Homaira Huda Shomee, Suman Kalyan Maity, Sourav Medya* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 专利起草, 大型语言模型, 基准测试, 专利摘要生成, PATENTWRITER

**Comment:** 

> **TL;DR:** PATENTWRITER是一个评估LLM生成专利摘要能力的基准框架，发现LLM表现良好。

**AI_Comments:** 该研究通过构建首个统一的专利摘要生成基准PATENTWRITER，系统地评估了LLMs在该领域的潜力，具有重要的创新性。其评估维度全面，不仅关注生成质量，还考虑了鲁棒性和实际应用场景，为未来LLMs在法律文本生成，特别是专利领域的应用奠定了基础。开源代码和数据集也极大地促进了该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过利用大型语言模型（LLMs）来克服繁琐的专利申请过程，从而实现专利撰写范式转变。

**Method:** 研究提出了PATENTWRITER，一个统一的基准框架，用于评估LLMs在专利摘要生成方面的能力。给定专利的第一项权利要求，评估了包括GPT-4和LLaMA-3在内的六个领先LLMs在零样本、少样本和思维链提示策略下的表现。评估指标包括标准NLP度量（如BLEU、ROUGE、BERTScore）、三种输入扰动下的鲁棒性以及在两个下游专利分类和检索任务中的适用性，并进行了文体分析（长度、可读性、语调）。

**Result:** 实验结果表明，现代LLMs可以生成高保真且文体恰当的专利摘要，并且通常超越了领域特定的基线模型。

**Conclusion:** 大型语言模型在专利摘要生成方面表现出色，预示着其在专利撰写领域的巨大潜力。

> **ai_Abstract:** 本文提出了PATENTWRITER，一个针对大型语言模型（LLMs）在专利摘要生成方面进行评估的统一基准框架。该研究在给定专利第一项权利要求的情况下，系统地评估了包括GPT-4和LLaMA-3在内的六个主流LLMs在不同提示策略下的表现。评估不仅使用了标准NLP指标，还考虑了鲁棒性、下游任务适用性及文体特征。结果显示，现代LLMs能够生成高质量的专利摘要，且优于现有领域基线，这为利用LLMs革新专利撰写流程提供了有力支持。代码和数据集已开源。

> **摘要翻译:** 大型语言模型（LLMs）已成为几个重要领域的变革性方法。本文旨在通过利用LLMs来克服繁琐的专利申请过程，从而实现专利撰写范式转变。在这项工作中，我们提出了PATENTWRITER，这是第一个用于评估LLMs在专利摘要生成方面的统一基准框架。给定专利的第一项权利要求，我们在一致的设置下，包括零样本、少样本和思维链提示策略，评估了六个领先的LLMs——包括GPT-4和LLaMA-3——以生成专利摘要。我们的基准PATENTWRITER超越了表面层次的评估：我们使用一套全面的指标系统地评估输出质量——标准NLP度量（例如BLEU、ROUGE、BERTScore）、三种输入扰动下的鲁棒性，以及在两个下游专利分类和检索任务中的适用性。我们还进行了文体分析以评估长度、可读性和语调。实验结果表明，现代LLMs可以生成高保真且文体恰当的专利摘要，通常超越了领域特定的基线模型。我们的代码和数据集已开源，以支持可复现性和未来的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [217] [MuSciClaims: Multimodal Scientific Claim Verification](https://arxiv.org/abs/2506.04585)
> *MuSciClaims：多模态科学主张验证*

*Yash Kumar Lal, Manikanta Bandham, Mohammad Saqib Hasan, Apoorva Kashi, Mahnaz Koupaee, Niranjan Balasubramanian* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 科学主张验证, 多模态, 基准, 视觉语言模型, MuSciClaims

**Comment:** 

> **TL;DR:** 引入了一个新的多模态科学主张验证基准MuSciClaims，并通过诊断任务发现现有视觉语言模型在该任务上表现不佳，且存在偏见和理解障碍。

**AI_Comments:** MuSciClaims基准的创新之处在于其针对科学主张验证的特定需求，填补了现有基准的空白。通过手动扰动生成矛盾主张的设计，能够更精准地测试模型的细致理解能力。诊断任务的引入对于深入分析模型失败原因至关重要，为未来模型改进指明了方向。该工作的重要性在于揭示了当前视觉语言模型在处理复杂科学多模态信息方面的显著局限性，为多模态推理和科学AI领域的研究提供了宝贵的资源和挑战。

<details>
  <summary>Details</summary>

**Motivation:** 评估科学主张需要识别、提取和推理科学文献中信息丰富的图表中表达的多模态数据。尽管在科学问答、图表描述和其他基于图表数据的多模态推理任务方面有大量工作，但目前还没有现成的多模态基准能够直接测试主张验证能力。为了弥补这一空白，本文引入了MuSciClaims。

**Method:** 本文自动从科学文章中提取支持的主张，并手动进行扰动以生成矛盾的主张。这些扰动旨在测试特定的主张验证能力。此外，还引入了一套诊断任务来帮助理解模型失败的原因。

**Result:** 结果显示，大多数视觉语言模型表现不佳（F1分数约为0.3-0.5），即使是最好的模型也仅达到0.72的F1分数。模型还倾向于将主张判断为受支持的，可能误解了主张中细微的扰动。诊断结果表明，模型不擅长在图中定位正确的证据，难以聚合跨模态信息，并且经常无法理解图表的基本组成部分。

**Conclusion:** 本文提出的MuSciClaims基准揭示了当前视觉语言模型在多模态科学主张验证方面的显著局限性，尤其是在证据定位、跨模态信息聚合和图表理解方面。这表明该领域仍有很大的改进空间。

> **ai_Abstract:** 本文提出了一个名为MuSciClaims的新型多模态科学主张验证基准，旨在解决现有基准在直接测试主张验证能力方面的不足。该基准通过自动提取支持性主张并手动扰动生成矛盾主张来构建，并辅以诊断任务以深入分析模型失效原因。实验结果表明，当前视觉语言模型在该任务上表现普遍不佳，存在对细微扰动的误解、证据定位困难、跨模态信息聚合能力弱以及对图表基本组件理解不足等问题。

> **摘要翻译:** 评估科学主张需要识别、提取并利用科学文献中信息丰富的图表中表达的多模态数据进行推理。尽管在科学问答、图表描述以及其他基于图表数据的多模态推理任务方面已有大量工作，但目前还没有现成的多模态基准能够直接测试主张验证能力。为了弥补这一空白，我们引入了一个新的基准MuSciClaims，并附带诊断任务。我们自动从科学文章中提取受支持的主张，然后手动对其进行扰动以产生矛盾的主张。这些扰动旨在测试一系列特定的主张验证能力。我们还引入了一套诊断任务，以帮助理解模型失败的原因。我们的结果表明，大多数视觉语言模型表现不佳（F1分数约为0.3-0.5），即使是最好的模型也仅达到0.72的F1分数。它们还偏向于将主张判断为受支持的，这可能是因为它们误解了主张中细微的扰动。我们的诊断结果显示，模型不擅长在图中定位正确的证据，难以聚合跨模态信息，并且经常无法理解图表的基本组成部分。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [223] [FB-RAG: Improving RAG with Forward and Backward Lookup](https://arxiv.org/abs/2505.17206)
> *FB-RAG：通过前向和后向查找改进RAG*

*Kushal Chawla, Alfy Samuel, Anoop Kumar, Daben Liu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** RAG, 前向查找, 后向查找, LLM, 上下文检索, 延迟降低

**Comment:** 

> **TL;DR:** FB-RAG提出了一种无需训练的框架，通过使用轻量级LLM进行前向查找来识别最相关的上下文，从而显著改进了传统RAG在复杂查询上的性能，并降低了延迟。

**AI_Comments:** FB-RAG的创新之处在于其“前向查找”策略，巧妙地利用一个轻量级LLM来预判和优化上下文选择，从而克服了传统RAG在处理复杂查询时的局限性。这种无需训练的方法，避免了复杂的微调和强化学习，使其具有很高的实用性。此外，它不仅提升了性能，还显著降低了延迟，这对于实际应用至关重要。该研究还提供了一个重要的见解，即较小的模型可以通过引导作用，系统性地提升较大模型的表现和效率。

<details>
  <summary>Details</summary>

**Motivation:** 传统的检索增强生成（RAG）在处理缺乏强信号的复杂查询时面临挑战，导致在选择小上下文（可能遗漏关键信息）和大上下文（可能混淆大型语言模型LLM）之间进行权衡。

**Method:** 我们提出了前向-后向RAG（FB-RAG），一个无需训练的新框架，基于一个简单而强大的前向查找策略。FB-RAG使用一个轻量级LLM来预见潜在的未来生成内容，利用多个采样输出的证据来精确识别最相关的上下文，供最终更强大的生成器使用。这无需复杂的微调或强化学习即可提高性能。

**Result:** FB-RAG在9个数据集上持续表现出强大的结果，并且由于对强大生成器使用更短、更集中的提示，实现了性能提升同时降低了延迟。在EN.QA数据集上，FB-RAG在延迟降低超过48%的情况下与领先基线持平，或在延迟降低10%的情况下实现了8%的性能提升。分析发现，即使前向查找LLM未能生成正确答案，其尝试也足以引导最终模型给出准确响应。

**Conclusion:** 小型LLM能够系统性地提高大型LLM的性能和效率，即使其自身未能生成正确答案，也能通过前向查找策略有效地引导最终模型。

> **ai_Abstract:** FB-RAG是一个旨在解决传统RAG在复杂查询中上下文检索困境的无训练框架。它通过让一个轻量级LLM提前预测潜在的未来生成内容，并利用这些信息来为最终的强大生成器选择最相关的上下文。该方法在9个数据集上表现出色，不仅提升了性能，还显著降低了延迟，例如在EN.QA数据集上实现高达48%的延迟缩减。研究还表明，即使前向查找的LLM未能提供正确答案，其尝试也足以有效指导最终模型，证明了小型LLM在提升大型LLM性能和效率方面的潜力。

> **摘要翻译:** 传统的检索增强生成（RAG）在处理缺乏强信号以检索最相关上下文的复杂查询时面临挑战，这使得在选择可能遗漏关键信息的小上下文和可能混淆LLM的大上下文之间进行权衡。为了解决这个问题，我们提出了前向-后向RAG（FB-RAG），一个基于简单而强大的前向查找策略的无需训练的新框架。FB-RAG采用轻量级LLM来预见潜在的未来生成内容，利用多个采样输出的证据来精确识别最相关的上下文，供最终更强大的生成器使用。这在没有复杂微调或强化学习（在先前工作中常见）的情况下提高了性能。在9个数据集上，FB-RAG持续提供强大的结果。此外，由于为强大生成器提供了更短、更集中的提示，性能提升可以实现延迟降低。在EN.QA数据集上，FB-RAG在延迟降低超过48%的情况下与领先基线持平，或在延迟降低10%的情况下实现了8%的性能提升。我们的分析发现，即使前向查找LLM未能生成正确答案，其尝试也足以引导最终模型给出准确响应，这表明较小的LLM如何系统地提高较大LLM的性能和效率。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [224] [LLM-as-a-qualitative-judge: automating error analysis in natural language generation](https://arxiv.org/abs/2506.09147)
> *LLM作为定性判断者：自动化自然语言生成中的错误分析*

*Nadezhda Chirkova, Tunde Oluwaseyi Ajayi, Seth Aycock, Zain Muhammad Mujahid, Vladana Perlić, Ekaterina Borisova, Markarit Vartampetian* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** LLM-as-a-judge, 错误分析, 自然语言生成, 定性评估, 文本评估

**Comment:** 

> **TL;DR:** 本文提出了“LLM作为定性判断者”的新方法，将LLM用于自然语言生成（NLG）的错误分析，生成结构化的问题报告，以提供改进洞察。

**AI_Comments:** 这项工作创新性地将LLM-as-a-judge的应用从传统的定量评估扩展到定性错误分析，为NLG系统开发者提供了更具可操作性的改进方向。其通过结构化报告和问题聚类的方法，有效弥补了现有评估工具的不足，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的“LLM作为判断者”主要作为定量工具，输出数值分数，但缺乏对自然语言生成（NLG）系统输出中具体问题类型的定性洞察，导致开发者难以识别和改进系统。

**Method:** 提出“LLM作为定性判断者”方法，其主要输出是NLG系统输出中常见问题类型的结构化报告。该方法包含两个主要步骤：开放式逐实例问题分析和使用直观累积算法对发现的问题进行聚类。

**Result:** “LLM作为定性判断者”在2/3的情况下能正确识别实例特定问题，并能生成与人类标注者报告相似的错误类型报告。

**Conclusion:** “LLM作为定性判断者”是一种有效且实用的方法，能自动化自然语言生成中的错误分析，为开发者提供有意义的改进洞察，且其表现与人类标注接近。

> **ai_Abstract:** 本文提出了一种名为“LLM作为定性判断者”的新型LLM评估方法，旨在自动化自然语言生成（NLG）中的错误分析。与现有“LLM作为判断者”主要提供数值分数不同，该方法生成NLG系统输出中常见问题类型的结构化报告，旨在为开发者提供具体的改进洞察。该方法包括逐实例问题分析和问题聚类。实验结果表明，该方法在识别实例特定问题方面具有2/3的准确率，并且能够生成与人类标注者报告相似的错误类型报告。

> **摘要翻译:** 提示大型语言模型（LLM）评估生成的文本，即“LLM作为判断者”，已成为自然语言生成（NLG）中标准的评估方法，但主要用作定量工具，即以数值分数作为主要输出。在这项工作中，我们提出了“LLM作为定性判断者”，这是一种基于LLM的评估方法，其主要输出是NLG系统输出中常见问题类型的结构化报告。我们的方法旨在为开发者提供关于给定NLG系统可以进行哪些改进的有意义的洞察，并且包含两个主要步骤，即开放式逐实例问题分析和使用直观累积算法对发现的问题进行聚类。我们还引入了一种评估所提出策略的方法，并结合了来自12个NLG数据集的约300个实例中的问题标注。我们的结果表明，“LLM作为定性判断者”在2/3的情况下能正确识别实例特定问题，并且能够生成与人类标注者编写的报告相似的错误类型报告。我们的代码和数据已公开在https://github.com/tunde-ajayi/llm-as-a-qualitative-judge。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [231] [MFTCXplain: A Multilingual Benchmark Dataset for Evaluating the Moral Reasoning of LLMs through Hate Speech Multi-hop Explanations](https://arxiv.org/abs/2506.19073)
> *MFTCXplain：一个通过仇恨言论多跳解释评估大型语言模型道德推理能力的多语言基准数据集*

*Jackson Trager, Diego Alves, Matteo Guida, Mikel K. Ngueajio, Ameeta Agrawal, Flor Plaza-del-Arco, Yalda Daryanai, Farzan Karimi-Malekabadi, Francielle Vargas* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** LLM, 道德推理, 仇恨言论, 多语言, 数据集

**Comment:** Under Review

> **TL;DR:** 引入MFTCXplain，一个多语言基准数据集，用于通过仇恨言论多跳解释评估大型语言模型（LLM）的道德推理能力。研究发现，LLM在仇恨言论检测上表现良好，但在道德情感预测和解释对齐方面表现不佳，尤其是在低资源语言中，表明其道德推理能力有限。

**AI_Comments:** 本文的创新之处在于构建了一个多语言、多跳解释的道德推理基准数据集，并引入了道德基础理论（MFT）进行细粒度标注。这对于提升LLM道德推理的透明度和跨文化评估能力至关重要。研究结果明确指出当前LLM在深层道德理解和解释生成方面的不足，特别是对于非英语语言，这为未来LLM的对齐和道德AI研究提供了明确的方向和挑战。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）被用于社会敏感任务，确保其道德推理能力日益受到关注。然而，当前的评估基准存在两个主要缺点：缺乏支持道德分类的标注，这限制了透明度和可解释性；以及主要关注英语，这限制了在不同文化背景下评估道德推理的能力。

**Method:** 本文介绍了MFTCXplain，这是一个多语言基准数据集，用于通过使用道德基础理论（MFT）进行仇恨言论多跳解释来评估LLM的道德推理能力。该数据集包含3,000条来自葡萄牙语、意大利语、波斯语和英语的推文，并标注了二元仇恨言论标签、道德类别和文本跨度级别的理由。

**Result:** 实证结果表明，LLM的输出与人类在道德推理任务中的标注存在偏差。虽然LLM在仇恨言恨检测方面表现良好（F1值高达0.836），但其预测道德情感的能力显著较弱（F1值低于0.35）。此外，理由对齐主要在低资源语言中仍然有限。

**Conclusion:** 这些发现表明，当前LLM内化和反映人类道德推理的能力有限。

> **ai_Abstract:** 本文介绍了MFTCXplain，一个多语言基准数据集，旨在解决现有LLM道德推理评估基准中缺乏解释性标注和语言多样性的问题。该数据集包含3,000条多语言推文，通过道德基础理论（MFT）标注了仇恨言论标签、道德类别和文本理由。实验结果显示，尽管LLM在仇恨言论检测上表现尚可，但在道德情感预测和理由对齐方面表现不佳，尤其是在低资源语言中，这揭示了当前LLM在理解和反映人类道德推理方面的局限性。

> **摘要翻译:** 确保大型语言模型（LLM）的道德推理能力日益受到关注，因为这些系统被用于社会敏感任务。然而，当前的评估基准存在两个主要缺点：缺乏支持道德分类的标注，这限制了透明度和可解释性；以及主要关注英语，这限制了在不同文化背景下评估道德推理的能力。在本文中，我们介绍了MFTCXplain，这是一个多语言基准数据集，用于通过使用道德基础理论（MFT）进行仇恨言论多跳解释来评估LLM的道德推理能力。该数据集包含3,000条来自葡萄牙语、意大利语、波斯语和英语的推文，并标注了二元仇恨言论标签、道德类别和文本跨度级别的理由。实证结果表明，LLM的输出与人类在道德推理任务中的标注存在偏差。虽然LLM在仇恨言论检测方面表现良好（F1值高达0.836），但其预测道德情感的能力显著较弱（F1值低于0.35）。此外，理由对齐主要在低资源语言中仍然有限。这些发现表明，当前LLM内化和反映人类道德推理的能力有限。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [238] [Probing Information Distribution in Transformer Architectures through Entropy Analysis](https://arxiv.org/abs/2507.15347)
> *通过熵分析探测Transformer架构中的信息分布*

*Amedeo Buonanno, Alessandro Rivetti, Francesco A. N. Palmieri, Giovanni Di Gennaro, Gianmarco Romano* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 熵分析, Transformer架构, 信息分布, GPT模型, 可解释性

**Comment:** Presented to the Italian Workshop on Neural Networks (WIRN2025) and
  it will appear in a Springer Chapter

> **TL;DR:** 本文通过熵分析探讨Transformer模型中的信息分布，量化词元不确定性以揭示信息管理和转换方式，并以GPT模型为例，展示其在理解模型行为和内部表示方面的潜力，有助于Transformer模型的可解释性研究。

**AI_Comments:** 该论文的创新之处在于利用熵分析这一量化工具来深入理解Transformer模型内部的信息流动和处理机制，这对于提高大型语言模型的可解释性至关重要。其方法提供了一种新的视角来探示模型“黑箱”，对于未来的模型诊断和改进具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在调查信息如何在Transformer模型中被管理和转换，以揭示模型行为和内部表示的洞察。

**Method:** 本文采用熵分析作为工具，通过量化词元级别的不确定性并检查不同处理阶段的熵模式来探测信息分布。作为案例研究，该方法应用于一个基于GPT的大型语言模型。

**Result:** 该方法展示了揭示模型行为和内部表示的潜力。

**Conclusion:** 这种方法可能为模型行为提供见解，并有助于开发Transformer模型的可解释性和评估框架。

> **ai_Abstract:** 本文提出使用熵分析来探究Transformer架构中的信息分布。研究通过量化词元不确定性并分析不同处理阶段的熵模式，旨在理解信息在模型内部的管理与转换机制。以GPT模型为例，该方法展现了揭示模型行为和内部表示的潜力，有望为Transformer模型的可解释性和评估框架发展提供新视角。

> **摘要翻译:** 这项工作探索熵分析作为一种工具，用于探测基于Transformer的架构中的信息分布。通过量化词元级别的不确定性并检查跨不同处理阶段的熵模式，我们旨在调查信息在这些模型中是如何被管理和转换的。作为案例研究，我们将该方法应用于一个基于GPT的大型语言模型，展示了其揭示模型行为和内部表示的潜力。这种方法可能为模型行为提供见解，并有助于开发Transformer模型的可解释性和评估框架。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [245] [Learning to Extract Rational Evidence via Reinforcement Learning for Retrieval-Augmented Generation](https://arxiv.org/abs/2507.15586)
> *通过强化学习提取合理证据用于检索增强生成*

*Xinping Zhao, Shouzheng Huang, Yan Zhong, Xinshuo Hu, Meishan Zhang, Baotian Hu, Min Zhang* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 检索增强生成, 强化学习, 证据提取, 大型语言模型, 噪声消除

**Comment:** 16 pages, 7 Figures, 10 Tables

> **TL;DR:** 针对RAG中检索噪声问题，提出EviOmni模型，通过强化学习显式推理并提取关键证据，提高生成质量和下游任务准确性。

**AI_Comments:** EviOmni的创新点在于将显式推理引入证据提取过程，并通过强化学习进行优化，这比传统直接提取方法更具鲁棒性和泛化性。通过端到端训练和设计多维度奖励函数，有效解决了RAG中的噪声问题，对于提升LLM在复杂问答场景下的表现具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）虽能提高大型语言模型（LLM）的准确性，但检索噪声严重影响LLM的生成质量。以往的证据提取方法过于直接，可能过滤掉关键线索且泛化性差。

**Method:** 提出EviOmni模型，通过强化学习学习提取合理证据。该方法首先显式推理以识别检索内容中的潜在线索，然后有意识地提取以避免遗漏关键线索。将证据推理和证据提取整合为统一响应进行端到端训练，应用知识令牌掩码进行解耦以获得基于推理和提取的答案，并设计了答案、长度和格式三种可验证奖励函数，通过策略优化算法更新模型。

**Result:** 在三个基准数据集上的广泛实验表明EviOmni的有效性，它能提供紧凑且高质量的证据，提高了下游任务的准确性，并促进了在线RAG系统中的有效应用。

**Conclusion:** EviOmni通过显式推理和强化学习，有效地解决了RAG中的检索噪声问题，显著提高了证据质量和LLM的生成准确性，具有实际应用价值。

> **ai_Abstract:** 本文针对检索增强生成（RAG）中检索噪声影响大型语言模型（LLM）生成质量的问题，提出了一种名为EviOmni的新方法。EviOmni利用强化学习，通过显式推理识别检索内容中的潜在线索，并有意识地提取关键证据，从而避免遗漏信息。该方法将证据推理与提取统一为端到端训练，并引入知识令牌掩码和多种可验证奖励函数进行模型优化。实验结果表明，EviOmni能生成紧凑高质量的证据，显著提升下游任务的准确性，并适用于在线RAG系统。

> **摘要翻译:** 检索增强生成（RAG）有效提高了大型语言模型（LLM）的准确性。然而，检索噪声严重影响了LLM的生成质量，因此需要开发去噪机制。以前的方法直接提取证据，没有明确的思考过程，这有过滤掉关键线索的风险，并且难以泛化。为此，我们提出了EviOmni，它通过（1）首先显式推理以识别检索内容中的潜在线索，然后（2）有意识地提取以避免遗漏任何有助于回答问题的关键线索来学习提取合理证据。具体来说，我们将证据推理和证据提取整合到一个统一的响应中进行端到端训练；应用知识令牌掩码进行解耦，以得出基于推理和基于提取的答案；并设计了三种可验证的奖励函数，包括答案、长度和格式，通过策略优化算法更新模型。在三个基准数据集上进行的广泛实验表明了EviOmni的有效性，它提供了紧凑且高质量的证据，提高了下游任务的准确性，并促进了在线RAG系统中的有效应用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [251] [Question Generation for Assessing Early Literacy Reading Comprehension](https://arxiv.org/abs/2507.22410)
> *用于评估早期识字阅读理解的问题生成*

*Xiaocheng Yang, Sumuk Shashidhar, Dilek Hakkani-Tur* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 问题生成, 阅读理解, 早期识字, 英语学习者, 语言模型

**Comment:** 2 pages, 1 figure, accepted by SLaTE 2025

> **TL;DR:** 本文提出了一种新颖的方法，用于为K-2英语学习者生成阅读理解问题，旨在全面覆盖内容，适应学习者能力，并提供多样化的问题类型和难度级别，以期成为AI驱动英语教师的一部分。

**AI_Comments:** 该论文的创新之处在于其专门为K-2早期英语学习者设计的问题生成方法，强调了内容覆盖、学习者适应性和问题多样性。这对于个性化和高效的早期阅读理解评估具有重要意义，并为未来AI在教育领域的应用提供了潜在路径。

<details>
  <summary>Details</summary>

**Motivation:** 通过基于内容的互动来评估阅读理解在阅读习得过程中起着重要作用。本文旨在提出一种新颖的方法来生成理解问题，以帮助评估K-2英语学习者的阅读理解能力。

**Method:** 本文提出了一种新颖的理解问题生成方法，专门针对K-2英语学习者。该方法确保对基础材料的完全覆盖，适应学习者的特定熟练程度，并能生成各种难度级别的大量多样化问题类型，以确保彻底的评估。该框架使用FairytaleQA数据集作为源材料，评估了各种语言模型的性能。

**Result:** 该研究使用FairytaleQA数据集作为源材料，评估了在该框架中各种语言模型的性能。

**Conclusion:** 所提出的方法最终有可能成为自主AI驱动英语教师的重要组成部分。

> **ai_Abstract:** 本文提出了一种新颖的问题生成方法，旨在评估K-2英语学习者的早期识字阅读理解能力。该方法具有内容覆盖全面性、对学习者能力自适应性以及生成多样化难度问题类型的特点，以确保全面的评估。研究利用FairytaleQA数据集评估了不同语言模型在该框架下的表现，并展望其未来可集成到AI驱动的英语教学系统中。

> **摘要翻译:** 通过基于内容的互动来评估阅读理解在阅读习得过程中起着重要作用。在本文中，我们提出了一种新颖的方法，用于为K-2英语学习者生成理解问题。我们的方法确保了对基础材料的完全覆盖，并能适应学习者的特定熟练程度，同时可以生成各种难度级别的大量多样化问题类型，以确保彻底的评估。我们使用FairytaleQA数据集作为源材料，评估了该框架中各种语言模型的性能。最终，所提出的方法有潜力成为自主AI驱动英语教师的重要组成部分。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [254] [Reservoir Computing as a Language Model](https://arxiv.org/abs/2507.15779)
> *储层计算作为一种语言模型*

*Felix Köster, Atsushi Uchida* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 储层计算, 语言模型, Transformer, 效率, 字符级建模

**Comment:** 8 pages, 5 figures, 1 table Code available at:
  https://github.com/fekoester/Shakespeare_Res

> **TL;DR:** 本文探讨储层计算作为一种语言模型，以解决大型语言模型能耗高和处理慢的问题。研究比较了储层计算和Transformer模型在字符级语言建模上的性能、计算成本和预测精度，发现Transformer在质量上表现优异，而储层计算在速度上更高效。

**AI_Comments:** 本文探讨了储层计算作为一种潜在的低能耗、高效率的语言模型替代方案，以应对当前大型语言模型面临的挑战。其创新点在于将储层计算应用于语言建模领域，并与主流的Transformer架构进行对比，为硬件实现提供了新的思路。尽管Transformer在预测质量上仍占优，但储层计算在效率上的表现具有重要意义，尤其是在资源受限或边缘计算场景下。该研究为未来开发更高效、更普惠的语言模型提供了有价值的见解和方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在处理大量数据和生成类人文本方面表现出色，但其巨大的能耗和缓慢的处理速度是进一步提高质量并使其普及的瓶颈。为了解决这一瓶颈，本文研究储层计算在自然文本处理中的表现，这有望实现快速且节能的硬件实现。

**Method:** 本文比较了三种字符级语言建模方法：两种储层计算方法（其中只有输出层可训练）和Transformer架构（完全学习基于注意力的序列表示）。通过统一调整所有模型的可训练参数数量，探索了这两种范式的性能、计算成本和预测精度。此外，还研究了两种类型的储层计算：传统的静态线性读出储层和通过注意力机制动态调整输出权重的注意力增强储层。

**Result:** 研究表明，Transformer在预测质量方面表现出色，而储层计算在降低训练和推理速度方面保持高效。研究还揭示了这些范式如何扩展，并提供了平衡资源限制与性能的指导。

**Conclusion:** 研究结果强调了储层计算和Transformer模型在语言建模中的扩展特性，并为在资源受限的环境中平衡性能和计算效率提供了指导。

> **ai_Abstract:** 本文旨在解决大型语言模型（LLM）能耗高和处理慢的瓶颈，探索储层计算（Reservoir Computing, RC）在自然文本处理中的应用。研究比较了两种储层计算方法（仅输出层可训练）与Transformer架构在字符级语言建模上的性能、计算成本和预测精度。结果显示，Transformer在预测质量上表现优异，而储层计算在训练和推理速度上更高效。研究还分析了传统储层和注意力增强储层，并提供了平衡资源与性能的指导。

> **摘要翻译:** 大型语言模型（LLM）因其在处理大量数据和生成类人文本方面的出色表现而主导了科学和媒体领域。然而，其巨大的能源需求和缓慢的处理速度仍然是进一步提高质量同时使模型普及的瓶颈。为了解决这一瓶颈，我们将研究储层计算在自然文本处理中的表现，这有望实现快速且节能的硬件实现。调查储层计算作为语言模型的研究仍然稀少。在本文中，我们比较了字符级语言建模的三种不同方法：两种不同的储层计算方法（其中只有输出层可训练），以及众所周知的基于Transformer的架构（完全学习基于注意力的序列表示）。我们通过平等地改变所有模型的可训练参数数量，探索了这两种范式的性能、计算成本和预测精度。使用所有三种方法的一致管道，我们证明了Transformer在预测质量方面表现出色，而储层计算机在降低训练和推理速度方面保持高效。此外，我们研究了两种类型的储层计算：具有静态线性读出的传统储层，以及通过注意力机制动态调整其输出权重的注意力增强储层。我们的发现强调了这些范式如何扩展，并提供了平衡资源限制与性能的指导。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [262] [Reviving Your MNEME: Predicting The Side Effects of LLM Unlearning and Fine-Tuning via Sparse Model Diffing](https://arxiv.org/abs/2507.21084)
> *激活你的MNEME：通过稀疏模型差异预测大型语言模型（LLM）反学习和微调的副作用*

*Aly M. Kassem, Zhuan Shi, Negar Rostamzadeh, Golnoosh Farnadi* | **Category: cs.CL, cs.LG** | **Updated: 2025-06-19**

**Keywords:** 大型语言模型, 微调, 反学习, 副作用预测, 稀疏模型差异化

**Comment:** 

> **TL;DR:** MNEME是一个轻量级框架，通过稀疏模型差异化，无需微调数据即可预测LLM反学习和微调的意外副作用，准确率高达95%。

**AI_Comments:** MNEME通过引入“稀疏模型差异化”提供了一种新颖且实用的方法来解决LLM微调和反学习中未被充分关注的副作用问题。其无需访问原始微调数据、高预测准确率以及可扩展性是其主要创新点。这项工作对于LLM的可靠性和安全性管理具有重要意义，有助于开发更可控的AI系统。

<details>
  <summary>Details</summary>

**Motivation:** 现有评估方法无法检测大型语言模型（LLM）微调或反学习后产生的意外副作用，例如内容遗忘导致其他任务性能下降，尤其当这些效果不可预测或突发时。

**Method:** 本文引入了MNEME（Model diffiNg for Evaluating Mechanistic Effects），一个轻量级框架，通过稀疏模型差异化来识别这些副作用。MNEME在无需访问微调数据的情况下，使用与任务无关的数据（例如The Pile, LMSYS-Chat-1M）比较基础模型和微调后的模型，以分离行为变化。

**Result:** MNEME在WMDP知识反学习、突发未对齐和良性微调三种场景下的五个LLM上应用，预测副作用的准确率高达95%，与已知基准对齐且无需自定义启发式方法。此外，研究表明在激活样本上重新训练可以部分逆转这些副作用。

**Conclusion:** 稀疏探测和差异化为微调引起的模型变化提供了一个可扩展且自动化的视角，为理解和管理LLM行为提供了实用工具。

> **ai_Abstract:** 该研究提出了MNEME，一个轻量级框架，通过稀疏模型差异化来预测大型语言模型（LLM）在反学习和微调过程中可能出现的意外副作用。MNEME在不访问微调数据的情况下，使用任务无关的数据对比模型，以识别行为变化。实验表明，MNEME在多种场景下预测副作用的准确率高达95%，且无需自定义启发式方法。此外，研究还发现对高激活样本进行再训练可以部分逆转这些副作用。这表明稀疏探测和差异化为理解和管理LLM行为提供了可扩展的自动化工具。

> **摘要翻译:** 大型语言模型（LLM）经常被微调或反学习以适应新任务或消除不良行为。虽然现有评估方法评估了此类干预后的性能，但仍然没有一种通用方法来检测意外的副作用，例如反学习生物学内容导致化学任务性能下降，特别是当这些效应不可预测或突发时。为了解决这个问题，我们引入了MNEME，即用于评估机制效应的模型差异化，这是一个轻量级框架，用于使用稀疏模型差异化识别这些副作用。MNEME在无需访问微调数据的情况下，通过任务无关数据（例如The Pile，LMSYS-Chat-1M）比较基础模型和微调后的模型，以隔离行为转变。MNEME应用于WMDP知识反学习、突发未对齐和良性微调三种场景下的五个LLM，在预测副作用方面达到了95%的准确率，与已知基准一致且无需自定义启发式方法。此外，我们展示了在激活样本上重新训练可以部分逆转这些效应。我们的结果表明，稀疏探测和差异化为微调引起的模型变化提供了一个可扩展且自动化的视角，为理解和管理LLM行为提供了实用工具。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [264] [FRED: Financial Retrieval-Enhanced Detection and Editing of Hallucinations in Language Models](https://arxiv.org/abs/2507.20930)
> *FRED：金融领域检索增强型语言模型幻觉检测与编辑*

*Likun Tan, Kuan-Wei Huang, Kevin Wu* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 语言模型幻觉, 金融领域, 事实检测, 模型编辑, 微调

**Comment:** 

> **TL;DR:** 开发了一种名为FRED的方法，用于在金融领域检测和编辑大型语言模型中的幻觉，通过微调模型并在合成数据集上表现出色。

**AI_Comments:** 这项工作通过构建领域特定合成数据集和微调现有模型，为解决大型语言模型在特定领域（如金融）的幻觉问题提供了一个非常实用的方法。其创新之处在于结合了检测与编辑功能，并证明了小型模型在经过特定领域微调后也能达到接近大型模型的性能，这对于资源受限的部署场景具有重要意义。该框架的可推广性也增加了其潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型中的幻觉对需要事实可靠性的应用构成严峻挑战，尤其是在金融等高风险领域。

**Method:** 根据用户定义的领域特定错误分类法，通过在金融问答语料库中插入带标签的错误来构建合成数据集。然后微调Phi-4、Phi-4-mini、Qwen3-4B和Qwen3-14B这四种语言模型来检测和编辑这些事实不准确性。

**Result:** 最佳模型（微调后的Phi-4）在二元F1分数上比OpenAI-o3提高了8%，整体检测性能提高了30%。Phi-4-mini模型（40亿参数）也保持了竞争力，二元检测仅下降2%，整体检测下降0.1%。

**Conclusion:** 该工作为金融文本生成中事实不一致的检测和编辑提供了一个实用的解决方案，并引入了一个可推广的框架，可以增强大型语言模型在金融之外的各种应用中的可信度和对齐性。

> **ai_Abstract:** 该研究提出FRED框架，旨在解决大型语言模型在金融领域中的“幻觉”问题。通过构建一个带有标记错误的金融领域合成数据集，并微调多种语言模型（如Phi-4和Qwen3系列），该方法能有效检测和编辑模型生成内容中的事实不准确性。实验结果显示，微调后的Phi-4模型在检测性能上显著优于现有模型，即使是参数较小的Phi-4-mini也表现出良好的竞争力。这项工作为提高语言模型在金融及其他高风险领域的事实可靠性提供了实用且可推广的解决方案。

> **摘要翻译:** 大型语言模型中的幻觉对需要事实可靠性的应用构成了严峻挑战，特别是在金融等高风险领域。这项工作提出了一种有效的方法，用于根据提供的上下文检测和编辑模型生成响应中事实不准确的内容。给定用户定义的领域特定错误分类法，我们通过在金融问答语料库中插入带标签的错误来构建合成数据集，然后微调Phi-4、Phi-4-mini、Qwen3-4B和Qwen3-14B四种语言模型，以检测和编辑这些事实不准确性。我们表现最佳的模型，即经过微调的Phi-4，在二元F1分数上比OpenAI-o3提高了8%，整体检测性能提高了30%。值得注意的是，我们经过微调的Phi-4-mini模型，尽管只有40亿参数，但仍保持了竞争力，与OpenAI-o3相比，二元检测仅下降2%，整体检测下降0.1%。我们的工作为金融文本生成中事实不一致的检测和编辑提供了一个实用的解决方案，同时引入了一个可推广的框架，可以增强大型语言模型在金融之外的各种应用中的可信度和对齐性。我们的代码和数据可在https://github.com/pegasi-ai/shield获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [267] [Basic Reading Distillation](https://arxiv.org/abs/2507.19741)
> *基础阅读蒸馏*

*Zhi Zhou, Sirui Miao, Xiangyu Duan, Hao Yang, Min Zhang* | **Category: cs.CL** | **Updated: 2025-07-29**

**Keywords:** 基础阅读蒸馏, 大型语言模型, 模型压缩, 知识蒸馏, 任务蒸馏

**Comment:** Accepted by ACL2025

> **TL;DR:** 提出基础阅读蒸馏(BRD)方法，使小模型学习大型语言模型的基础阅读行为，从而在性能上媲美甚至超越大模型，同时显著降低计算资源需求。

**AI_Comments:** 这篇论文的创新点在于提出了“基础阅读蒸馏”这一新颖概念，关注小模型在通用文本上的“基础阅读”能力培养，而非仅仅模仿特定任务或知识。这提供了一个新的视角来解决模型压缩和部署的挑战，并且其与现有蒸馏方法的正交性意味着它可能作为一种补充策略进一步提升小模型的性能。其重要性在于，通过提升小模型的通用能力，有望在计算资源有限的设备上实现接近大型模型的性能，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型(LLMs)计算资源需求高，限制了实际部署。现有蒸馏方法（知识蒸馏或任务蒸馏）忽视了小模型在与下游任务无关的通用文本上的基础阅读能力培养。

**Method:** 提出基础阅读蒸馏(BRD)方法，通过让小模型模仿LLMs在每个句子上的基础阅读行为，如命名实体识别、问题提出和回答。之后将经过BRD训练的小模型应用于语言推理基准和BIG-bench任务。

**Result:** 经过BRD训练的小模型在各种任务上表现出与比其大20倍以上的LLMs相当或更优的性能。分析表明BRD有效影响了小模型的概率分布，并且与知识蒸馏或任务蒸馏正交。

**Conclusion:** 基础阅读蒸馏(BRD)是一种有效的方法，能够显著提升小型模型的通用阅读能力，使其在资源受限的环境下达到大型模型的性能水平，并且可以与其他蒸馏方法结合使用。

> **ai_Abstract:** 本文提出了一种名为基础阅读蒸馏（BRD）的新型蒸馏方法，旨在解决大型语言模型（LLMs）计算资源需求高的问题。与现有知识蒸馏和任务蒸馏不同，BRD专注于训练小型模型模仿LLMs在通用文本上的基础阅读行为，如命名实体识别和问答。实验证明，经过BRD训练的小型模型在多项任务上能达到或超越比其大20倍的LLMs的性能，并且BRD对小模型的概率分布产生积极影响，且与现有蒸馏方法具有正交性。

> **摘要翻译:** 大型语言模型（LLMs）在各种自然语言处理领域展现出卓越的能力，但它们需要高计算资源，这限制了它们在现实世界中的部署。蒸馏是一种通过知识蒸馏或任务蒸馏来解决此问题的技术。这两种蒸馏方法都训练小型模型以模仿LLMs的特定特征，但它们都忽略了小型模型在与下游任务无关的通用文本上的基础阅读教育。在本文中，我们提出了基础阅读蒸馏（BRD），它教育小型模型模仿LLMs的基础阅读行为，例如命名实体识别、问题提出和回答，在每个句子上进行。在进行这种基础教育后，我们将小型模型应用于各种任务，包括语言推理基准和BIG-bench任务。结果表明，该小型模型可以超越或与大20倍以上的LLMs表现相当。分析揭示，BRD有效影响了小型模型的概率分布，并且与知识蒸馏或任务蒸馏正交。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [273] [DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router](https://arxiv.org/abs/2507.22050)
> *DeepSieve：通过LLM作为知识路由器进行信息筛选*

*Minghao Guo, Qingcheng Zeng, Xujiang Zhao, Yanchi Liu, Wenchao Yu, Mengnan Du, Haifeng Chen, Wei Cheng* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** DeepSieve, RAG, LLM, 知识路由, 信息筛选

**Comment:** 22 pages, work in progress

> **TL;DR:** DeepSieve是一个新的代理式RAG框架，通过将复杂查询分解并递归路由到最合适的知识源，以提高LLM在知识密集型查询中的性能。

**AI_Comments:** DeepSieve的创新在于其代理式RAG框架和将LLM用作知识路由器的思想，实现了更细粒度的信息筛选和管理。其模块化、透明性和适应性设计也增强了其在复杂知识密集型任务中的实用性，为提高LLM的知识处理能力提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在知识密集型查询中表现不佳，因为它们无法动态访问最新或特定领域的信息。现有的检索增强生成（RAG）方法缺乏对查询和源的细粒度控制，导致检索噪声和推理不足。

**Method:** DeepSieve是一个代理式RAG框架，通过将LLM作为知识路由器进行信息筛选。它将复杂查询分解为结构化子问题，并递归地将每个子问题路由到最合适的知识源，通过多阶段蒸馏过程过滤掉不相关的信息。该设计强调模块化、透明性和适应性。

**Result:** 在跨异构源的多跳问答任务上的实验表明，与传统RAG方法相比，DeepSieve提高了推理深度、检索精度和可解释性。

**Conclusion:** DeepSieve通过其创新的代理式RAG框架和信息筛选机制，显著改善了LLM处理知识密集型查询的能力，超越了传统RAG方法。

> **ai_Abstract:** 本文介绍了DeepSieve，一种新的代理式检索增强生成（RAG）框架，旨在解决大型语言模型（LLMs）在处理知识密集型查询时遇到的挑战。DeepSieve通过将LLM作为知识路由器，将复杂查询分解为结构化子问题，并递归地路由到最相关的知识源，同时通过多阶段蒸馏过程过滤掉不相关信息。该方法提高了LLM在多跳问答任务上的推理深度、检索精度和可解释性，优于现有RAG方法。

> **摘要翻译:** 大型语言模型（LLMs）擅长许多推理任务，但由于无法动态访问最新或特定领域的信息，它们在知识密集型查询方面表现不佳。检索增强生成（RAG）已成为一种有前景的解决方案，使LLMs能够将其响应基于外部来源。然而，现有的RAG方法缺乏对查询和源的细粒度控制，常常导致检索噪声和浅层推理。在这项工作中，我们引入了DeepSieve，一个代理式RAG框架，通过将LLM作为知识路由器来整合信息筛选。DeepSieve将复杂查询分解为结构化子问题，并递归地将每个子问题路由到最合适的知识源，通过多阶段蒸馏过程过滤掉不相关的信息。我们的设计强调模块化、透明性和适应性，利用了代理系统设计的最新进展。在跨异构源的多跳问答任务上的实验表明，与传统RAG方法相比，DeepSieve提高了推理深度、检索精度和可解释性。我们的代码可在https://github.com/MinghoKwok/DeepSieve获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [286] [NeedleChain: Measuring Intact Long-Context Reasoning Capability of Large Language Models](https://arxiv.org/abs/2507.22411)
> *针链：衡量大型语言模型完整的长上下文推理能力*

*Hyeonseok Moon, Heuiseok Lim* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 长上下文理解, 基准测试, NeedleChain, ROPE Contraction

**Comment:** 13 pages

> **TL;DR:** 现有的长上下文评估基准可能高估了LLM的能力。本文提出了一个名为NeedleChain的新基准，它要求LLM完整理解所有相关上下文，并提出ROPE Contraction策略以提高长上下文理解能力，发现LLM在处理和完全理解长上下文之间存在差距。

**AI_Comments:** 这篇论文提出了一种创新的方法来更准确地评估大型语言模型的长上下文理解能力，挑战了现有评估基准的局限性。NeedleChain基准通过要求模型完整理解所有相关上下文，揭示了LLM更深层次的理解缺陷，而不是仅仅识别信息。同时提出的ROPE Contraction策略为提升LLM长上下文性能提供了实用的改进方向。这项工作对于推动LLM在复杂推理任务中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Needle-in-a-Haystack (NIAH) 基准在评估大型语言模型（LLM）长上下文（LC）理解能力时可能高估了其真实能力。即使是最先进的模型也难以完整地整合仅由查询相关句子构成的上下文。

**Method:** 本文引入了一个名为NeedleChain的新基准，其上下文完全由查询相关信息组成，要求LLM完全理解输入才能正确回答。该基准允许灵活的上下文长度和推理顺序。此外，提出了一种名为ROPE Contraction的策略来提高LLM的长上下文理解能力。

**Result:** 实验揭示了大型语言模型处理大上下文的能力与它们完全理解这些上下文的能力之间存在显著差异。

**Conclusion:** 现有的评估方法可能无法准确反映LLM完整的长上下文理解能力。NeedleChain基准为更准确地评估LLM的完整长上下文推理能力提供了一个新工具，并且ROPE Contraction策略可以改善LLM的长上下文理解。LLM在处理和完全理解长上下文之间存在差距。

> **ai_Abstract:** 本文指出，现有的Needle-in-a-Haystack (NIAH) 基准可能高估了大型语言模型（LLM）的长上下文理解能力，因为即使是顶级模型也难以完整理解仅包含相关信息的长上下文。为解决此问题，作者提出了NeedleChain基准，该基准的上下文完全与查询相关，旨在更准确地评估LLM的完整长上下文推理能力，并允许灵活的上下文长度和推理顺序。同时，还提出了一种名为ROPE Contraction的简单策略来提高LLM的长上下文理解能力。研究结果表明，LLM在处理长上下文和完全理解长上下文之间存在显著差距。

> **摘要翻译:** Needle-in-a-Haystack（NIAH）基准被广泛用于评估大型语言模型（LLM）理解长上下文（LC）的能力。它评估了在大量与查询无关的段落中识别与查询相关上下文的能力。尽管此方法被认为是评估长上下文理解的广泛接受标准，但我们的发现表明它可能高估了LLM真正的长上下文能力。我们证明，即使是GPT-4o等最先进的模型也难以完整地整合仅由十个查询相关句子组成的给定上下文。作为回应，我们引入了一个新颖的基准，\textbf{NeedleChain}，其中上下文完全由查询相关信息组成，要求LLM完全掌握输入才能正确回答。我们的基准允许灵活的上下文长度和推理顺序，从而提供了对LLM性能更全面的分析。此外，我们提出了一种极其简单但引人注目的策略来提高LLM的长上下文理解能力：ROPE Contraction。我们对各种先进LLM的实验揭示了它们处理大上下文的能力与它们完全理解这些上下文的能力之间存在显著差异。源代码和数据集可在https://github.com/hyeonseokk/NeedleChain 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [291] [Categorical Classification of Book Summaries Using Word Embedding Techniques](https://arxiv.org/abs/2507.21058)
> *使用词嵌入技术对图书摘要进行分类*

*Kerem Keskin, Mümine Kaya Keleş* | **Category: cs.CL, cs.AI** | **Updated: 2025-05-12**

**Keywords:** 词嵌入, 图书摘要分类, 自然语言处理, 机器学习, TF-IDF

**Comment:** in Turkish language. This paper was published in the proceedings of
  the 6th International Conference on Data Science and Applications ICONDATA24,
  held on September between 2 and 6, 2024, in Pristina, Kosovo. For full text
  book see https://www.icondata.org/en/proceedings-books

> **TL;DR:** 本研究利用词嵌入、自然语言处理和机器学习算法对图书摘要进行分类，并比较了One-Hot Encoding、Word2Vec和TF-IDF等方法的成功率。结果显示，对于土耳其语文本，支持向量机、朴素贝叶斯、逻辑回归模型以及TF-IDF和One-Hot编码技术表现更佳。

**AI_Comments:** 该论文通过比较不同的词嵌入技术和机器学习模型在图书摘要分类任务上的表现，为自然语言处理领域的应用提供了实证。其创新点在于对多种常用方法的综合比较，并特别指出了对于土耳其语文本的适用性，这对于特定语言的NLP研究具有参考价值。然而，论文未提及数据集的规模、具体评估指标或模型的超参数调优过程，这可能限制了结果的泛化能力和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在利用词嵌入方法、自然语言处理技术和机器学习算法对来自图书网站的图书摘要及其类别进行分类。

**Method:** 研究使用了词嵌入方法、自然语言处理技术和机器学习算法进行分类。具体采用了One-Hot Encoding、Word2Vec和Term Frequency - Inverse Document Frequency (TF-IDF) 作为词嵌入方法，并比较了它们的成功率。此外，还使用了支持向量机 (Support Vector Machine)、朴素贝叶斯 (Naive Bayes) 和逻辑回归模型 (Logistic Regression Models) 进行分类。

**Result:** 研究结果显示，支持向量机、朴素贝叶斯和逻辑回归模型以及TF-IDF和One-Hot Encoder词嵌入技术在处理土耳其语文本时取得了更成功的分类结果。

**Conclusion:** 对于土耳其语文本的图书摘要分类，支持向量机、朴素贝叶斯、逻辑回归模型以及TF-IDF和One-Hot Encoder词嵌入技术是更有效的选择。

> **ai_Abstract:** 本研究旨在使用词嵌入技术、自然语言处理和机器学习算法对图书摘要进行分类。研究比较了One-Hot Encoding、Word2Vec和TF-IDF等词嵌入方法的性能，并结合了支持向量机、朴素贝叶斯和逻辑回归等机器学习模型。结果表明，对于土耳其语文本，支持向量机、朴素贝叶斯、逻辑回归以及TF-IDF和One-Hot Encoder词嵌入技术取得了更好的分类效果。

> **摘要翻译:** 在这项研究中，使用词嵌入方法、自然语言处理技术和机器学习算法对来自图书网站的图书摘要和类别进行了分类。此外，本研究还使用了One-Hot编码、Word2Vec和词频-逆文档频率（TF-IDF）等常用词嵌入方法，并比较了它们的成功率。此外，还展示并添加了所使用的预处理方法的组合表。从结果来看，观察到支持向量机、朴素贝叶斯和逻辑回归模型以及TF-IDF和One-Hot Encoder词嵌入技术对土耳其语文本给出了更成功的结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [298] [InsurTech innovation using natural language processing](https://arxiv.org/abs/2507.21112)
> *使用自然语言处理进行保险科技创新*

*Panyi Dong, Zhiyu Quan* | **Category: cs.CL, cs.LG, stat.ML** | **Updated: 2025-07-12**

**Keywords:** 保险科技, 自然语言处理, 保险分析, 替代数据, 风险评估

**Comment:** 

> **TL;DR:** 本文通过概念概述和案例研究，展示了自然语言处理（NLP）在保险运营中的应用，特别是如何将非结构化文本转化为结构化数据，以提升商业保险的定价和风险评估能力。

**AI_Comments:** 本文创新性地将自然语言处理技术应用于保险领域，解决了传统保险公司面临的数据源不足和非结构化数据利用率低的问题。其重要性在于通过实际案例展示了NLP在提升商业保险定价和风险评估方面的潜力，为保险行业的数字化转型提供了有力的技术支持。该研究的局限性可能在于其案例研究的范围和数据的普遍性，可能需要更广泛的验证。

<details>
  <summary>Details</summary>

**Motivation:** 随着保险科技（InsurTech）的迅速发展，传统保险公司需要探索替代数据源和先进技术，以保持竞争优势。本文旨在展示自然语言处理（NLP）在此背景下的应用潜力。

**Method:** 本文提供了自然语言处理（NLP）在保险运营中应用的概念概述和实际案例研究。研究利用保险科技行业合作伙伴提供的真实替代数据，通过应用各种NLP技术，将原始非结构化文本转化为适用于精算分析和决策的结构化数据，并在商业保险领域展示了实际用例。

**Result:** 通过NLP技术，从文本中提取的丰富洞察不仅补充和完善了商业保险定价的传统评级因素，还通过引入新颖的行业分类，为评估潜在风险提供了新的视角。

**Conclusion:** 研究表明，自然语言处理（NLP）不仅仅是一个辅助工具，而是现代数据驱动型保险分析的基石。

> **ai_Abstract:** 本文探讨了自然语言处理（NLP）在保险科技（InsurTech）领域的创新应用，旨在帮助传统保险公司应对竞争挑战。通过概念性阐述和商业保险的实际案例研究，论文展示了NLP如何将非结构化文本数据转化为有价值的结构化信息，从而优化传统定价因素并为风险评估提供全新的视角。研究强调NLP是现代数据驱动型保险分析的核心要素。

> **摘要翻译:** 随着保险科技的迅速崛起，传统保险公司正日益探索替代数据源和先进技术，以维持其竞争优势。本文提供了自然语言处理（NLP）的概念概述和实际案例研究，及其在保险运营中新兴应用，重点关注将原始非结构化文本转化为适合精算分析和决策的结构化数据。我们利用保险科技行业合作伙伴提供的真实世界替代数据，这些数据丰富了传统保险数据源，并应用各种NLP技术来演示商业保险背景下的实际用例。这些丰富的、源自文本的洞察不仅补充和完善了商业保险定价的传统评级因素，而且通过引入新颖的行业分类，为评估潜在风险提供了新的视角。通过这些演示，我们表明NLP不仅仅是一个补充工具，更是现代数据驱动型保险分析的基础要素。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [321] [AI-generated stories favour stability over change: homogeneity and cultural stereotyping in narratives generated by gpt-4o-mini](https://arxiv.org/abs/2507.22445)
> *AI生成的故事偏爱稳定而非变化：gpt-4o-mini生成叙事中的同质性和文化刻板印象*

*Jill Walker Rettberg, Hermann Wigers* | **Category: cs.CL, cs.AI, H.1.2; I.2.4; I.2.0; I.2.7** | **Updated: 2025-07-30**

**Keywords:** AI偏见, 叙事同质性, 文化刻板印象, gpt-4o-mini, 生成式AI

**Comment:** This project has received funding from the European Union's Horizon
  2020 research and innovation programme under grant agreement number
  101142306. The project is also supported by the Center for Digital Narrative,
  which is funded by the Research Council of Norway through its Centres of
  Excellence scheme, project number 332643

> **TL;DR:** 本研究发现，由gpt-4o-mini生成的跨文化故事虽然包含表面国家符号，但在叙事结构上高度同质化，偏爱稳定和传统，构成了一种新的AI叙事偏见。

**AI_Comments:** 这篇论文的创新之处在于它识别并定义了一种新型的AI偏见——叙事标准化或结构同质性偏见，这超越了传统的表征偏见。它强调了大型语言模型在生成跨文化内容时可能无意中传播的单一叙事范式，即使表面上具有文化元素。这一发现对理解生成式AI的社会文化影响至关重要，并为未来提高AI文化敏感性和多样性提供了明确的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 探究主要基于英美文本训练的语言模型能否生成与其他民族文化相关的故事。

**Method:** 通过向OpenAI的gpt-4o-mini模型发送“写一个1500字潜在的{国籍}故事”的提示，为236个国家各生成了50个故事，总计11,800个故事。

**Result:** 尽管故事包含表面层面的国家符号和主题，但它们在各国之间压倒性地符合单一的叙事情节结构：主角居住或回到小镇，通过重新连接传统和组织社区活动来解决小冲突。真实世界的冲突被净化，浪漫几乎缺失，叙事张力被淡化，转而偏爱怀旧和和解。结果是叙事的同质化：一种AI生成的合成想象，将稳定置于变化之上，将传统置于成长之上。

**Conclusion:** AI生成叙事的结构同质性构成了AI偏见的一种独特形式，即叙事标准化，应与更常见的表征偏见一并承认。这些发现与文学研究、叙事学、批判性AI研究、自然语言处理研究以及提高生成式AI文化对齐性的努力相关。

> **ai_Abstract:** 本研究调查了gpt-4o-mini生成跨文化故事的能力。通过为236个国家生成总计11,800个故事，研究发现尽管故事包含表面文化元素，但其核心叙事结构高度同质化，普遍呈现主角回到家乡、通过传统和社区活动解决微小冲突的模式。故事中真实冲突被淡化，情感缺失，强调稳定和怀旧。作者认为这种叙事同质性是一种独特的AI偏见形式，即叙事标准化，对文学、AI伦理和生成式AI的文化对齐具有重要意义。

> **摘要翻译:** 一个主要基于英美文本训练的语言模型能否生成与其他民族文化相关的故事？为了找出答案，我们通过向OpenAI的gpt-4o-mini模型发送“写一个1500字潜在的{国籍}故事”的提示，生成了11,800个故事——236个国家各50个。尽管这些故事确实包含表面层面的国家符号和主题，但它们在各国之间压倒性地符合单一的叙事情节结构：主角居住或回到小镇，通过重新连接传统和组织社区活动来解决小冲突。真实世界的冲突被净化，浪漫几乎缺失，叙事张力被淡化，转而偏爱怀旧和和解。结果是叙事的同质化：一种AI生成的合成想象，将稳定置于变化之上，将传统置于成长之上。我们认为，AI生成叙事的结构同质性构成了AI偏见的一种独特形式，即叙事标准化，应与更常见的表征偏见一并承认。这些发现与文学研究、叙事学、批判性AI研究、自然语言处理研究以及提高生成式AI文化对齐性的努力相关。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [328] [SmoothRot: Combining Channel-Wise Scaling and Rotation for Quantization-Friendly LLMs](https://arxiv.org/abs/2506.05413)
> *SmoothRot：结合通道级缩放和旋转以实现量化友好的LLM*

*Patrik Czakó, Gábor Kertész, Sándor Szénási* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 后训练量化, 大型语言模型, 4比特量化, 激活异常值, Hadamard变换

**Comment:** 6 pages, 3 figures, 5 tables. Accepted to IEEE SMC 2025 conference
  proceedings

> **TL;DR:** SmoothRot是一种新的后训练量化技术，通过结合通道级缩放和Hadamard变换，有效处理LLM中的激活异常值，显著提高4比特量化精度，同时不增加推理延迟。

**AI_Comments:** 该论文提出了一种创新的后训练量化技术SmoothRot，其创新点在于结合了通道级缩放和Hadamard变换来有效处理LLM中常见的激活异常值问题。这对于实现更高效的低比特量化至关重要。其重要性在于，在不引入额外推理延迟的情况下，显著缩小了量化模型与FP16模型之间的性能差距，这对于在资源受限设备上部署大型LLM具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 提高大型语言模型（LLMs）4比特量化的效率，解决大规模激活异常值对量化准确性的关键挑战。

**Method:** 提出SmoothRot技术，通过整合通道级缩放（channel-wise scaling）与Hadamard变换（Hadamard transformations），将极端的异常值转化为对量化友好的激活，从而提高量化精度。

**Result:** 在LLaMA2 7B、LLaMA3.1 8B和Mistral 7B等流行LLM上的实验表明，SmoothRot在语言生成和零样本推理任务中，持续将量化模型与FP16模型之间的性能差距缩小约10-30%，且不引入额外的推理延迟。

**Conclusion:** SmoothRot通过有效处理激活异常值，显著提高了LLMs 4比特量化的精度，并在不增加推理延迟的情况下，缩小了量化模型与全精度模型之间的性能差距，验证了其作为一种高效后训练量化技术的有效性。

> **ai_Abstract:** SmoothRot是一种针对大型语言模型（LLMs）的创新型后训练量化技术，旨在优化4比特量化效率。该方法通过结合通道级缩放和Hadamard变换来处理激活中的极端异常值，从而生成更适合量化的激活值，显著提升了量化准确性。实验证明，SmoothRot能够将量化模型与全精度模型之间的性能差距减少10-30%，且不增加推理延迟，在多项LLM任务上表现出优异性能。

> **摘要翻译:** 我们提出了SmoothRot，一种新颖的后训练量化技术，旨在提高大型语言模型（LLMs）中4比特量化的效率。SmoothRot通过将通道级缩放与Hadamard变换相结合，解决了大规模激活异常值的关键挑战。我们的技术有效地将极端异常值转换为对量化友好的激活，显著提高了量化精度。在流行的LLM（LLaMA2 7B、LLaMA3.1 8B和Mistral 7B）上进行的实验表明，SmoothRot在语言生成和零样本推理任务中，持续将量化模型与FP16模型之间的性能差距缩小约10-30%，且不引入额外的推理延迟。代码可在https://github.com/czakop/smoothrot获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [333] [Which symbol grounding problem should we try to solve?](https://arxiv.org/abs/2507.21080)
> *我们应该尝试解决哪种符号接地问题？*

*Vincent C. Müller* | **Category: cs.CL, cs.AI** | **Updated: 2025-06-16**

**Keywords:** 符号接地问题, 零语义承诺, 人工智能, 语义, 计算智能体

**Comment:** 

> **TL;DR:** 本文批判了现有符号接地问题的解决方案，并提出应将问题重新定义为如何在人工计算智能体中解释和再现意义的行为能力和功能。

**AI_Comments:** 这篇论文通过批判现有理论，特别是对“零语义承诺”条件的否定，展现了其创新性。它强调了重新定义问题本身的重要性，并提出将符号接地问题与人工计算智能体的行为能力和功能解释相联系，为该领域提供了新的视角。其重要性在于促使研究者深入思考符号接地问题的核心，而不仅仅是寻找现存问题的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 作者旨在批判Floridi和Taddeo提出的符号接地问题解决方案及其“零语义承诺”条件，并指出其不可实现性。同时，作者也审视了Luc Steels的不同观点，并认为有必要重新思考符号接地问题的本质以及系统中“目标”在问题形成中的作用。

**Method:** 作者首先批判了Floridi和Taddeo提出的“零语义承诺”条件及其解决方案。接着，作者审视了Luc Steels的观点，并在此基础上，结合对计算的理解，提出对符号接地问题进行重新概念化。

**Result:** 作者认为Floridi和Taddeo的“零语义承诺”条件无法实现。最终，论文提出唯一合理的符号接地问题是如何解释和再现人工计算智能体中意义的行为能力和功能。

**Conclusion:** 唯一合理的符号接地问题是如何解释和再现人工计算智能体中意义的行为能力和功能。

> **ai_Abstract:** 本文批判了Floridi和Taddeo提出的符号接地问题解决方案及其“零语义承诺”条件，认为其不可实现。作者在考察了Luc Steels的观点后，提出应重新思考符号接地问题的本质和系统中“目标”的作用。最终，作者得出结论，唯一合理的符号接地问题是解释和再现人工计算智能体中意义的行为能力和功能。

> **摘要翻译:** 弗洛里迪和塔迪奥为接地问题的解决方案提出了“零语义承诺”条件，并给出了一个解决方案。我简要地指出，他们的条件无法满足，甚至连他们自己的解决方案也无法满足。在考察了卢克·斯蒂尔斯截然不同的竞争性建议之后，我建议我们需要重新思考问题是什么，以及系统中“目标”在问题形成中扮演的角色。在对计算有了恰当的理解之后，我得出结论，唯一明智的接地问题是如何解释和再现人工计算智能体中意义的行为能力和功能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [354] [Introducing HALC: A general pipeline for finding optimal prompting strategies for automated coding with LLMs in the computational social sciences](https://arxiv.org/abs/2507.21831)
> *引入HALC：一种在计算社会科学中使用大型语言模型进行自动化编码时寻找最佳提示策略的通用流程*

*Andreas Reich, Claudia Thoms, Tobias Schrimpf* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** HALC, 自动化编码, LLMs, 提示策略, 计算社会科学

**Comment:** 48 pages, 9 figures and 8 tables

> **TL;DR:** 本文提出了HALC，一个通用的流程，用于系统性地为计算社会科学中的LLM自动化编码任务构建最佳提示策略，并验证了其在可靠编码方面的有效性。

**AI_Comments:** HALC的提出解决了LLM在社会科学自动化编码中提示策略缺乏系统性优化的问题，其通用性允许整合多种策略，并通过大规模实验验证了其有效性。强调将LLM与现有编码手册对齐而非反向优化，是其创新点之一，确保了研究的实际应用价值和与社会科学研究范式的兼容性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管研究人员提出了不同的提示策略，但其有效性因LLM和任务而异，且试错法仍普遍存在，缺乏系统可靠的方法来构建最优提示。

**Method:** 提出了HALC——一个通用流程，允许系统且可靠地构建针对任何给定编码任务和模型的最佳提示，并可集成任何相关提示策略。通过向本地LLM发送1,512个独立提示，进行了超过两百万次请求，基于少量专家编码（真实值）测试了提示策略和LLM任务性能。

**Result:** 与专家编码相比，使用LLM Mistral NeMo，找到了能可靠编码单变量（气候变量${\alpha}$= .76；运动变量${\alpha}$= .78）和双变量（气候变量${\alpha}$= .71；运动变量${\alpha}$= .74）的提示。提示策略旨在使LLM与预设的编码手册对齐，而非为LLM优化编码手册。

**Conclusion:** 该论文揭示了不同提示策略的有效性、关键影响因素，并为每个编码任务和模型识别了可靠的提示。

> **ai_Abstract:** 本研究引入了HALC，一个用于在计算社会科学中使用LLM进行自动化编码时系统性地寻找最佳提示策略的通用流程。针对LLM在不同任务和模型上提示效果不一且依赖试错的问题，HALC提供了一种可靠的方法来构建最优提示。通过对本地LLM进行大规模实验，发送了超过两百万次请求，并与专家编码对比，验证了该流程能够生成可靠的提示，特别是使用Mistral NeMo模型在单变量和双变量编码上取得了高一致性。研究强调了提示策略与现有编码手册对齐的重要性，并提供了关于提示有效性和关键影响因素的见解。

> **摘要翻译:** 大型语言模型（LLMs）正被广泛用于任务自动化，包括社会科学中的自动化编码。然而，尽管研究人员提出了不同的提示策略，但其有效性因LLMs和任务而异。试错法仍然普遍存在。我们提出了HALC——一个通用的流程，允许系统且可靠地为任何给定编码任务和模型构建最佳提示，并允许集成任何被认为相关的提示策略。为了研究LLM编码并验证我们的流程，我们向本地LLMs发送了总计1,512个独立提示，进行了超过两百万次请求。我们基于少量专家编码（真实值）测试了提示策略和LLM任务性能。与这些专家编码相比，我们发现使用LLM Mistral NeMo，提示能够可靠地编码单个变量（气候变量${\alpha}$= .76；运动变量${\alpha}$= .78）和两个变量（气候变量${\alpha}$= .71；运动变量${\alpha}$= .74）。我们的提示策略设置方式旨在使LLM与我们的编码手册对齐——我们并未优化我们的编码手册以适应LLM。我们的论文提供了关于不同提示策略有效性、关键影响因素以及为每个编码任务和模型识别可靠提示的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [356] [Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance](https://arxiv.org/abs/2507.22448)
> *Falcon-H1：重新定义效率和性能的混合头语言模型家族*

*Jingwei Zuo, Maksim Velikanov, Ilyas Chahed, Younes Belkada, Dhia Eddine Rhayem, Guillaume Kunsch, Hakim Hacid, Hamza Yous, Brahim Farhat, Ibrahim Khadraoui, Mugariya Farooq, Giulia Campesan, Ruxandra Cojocaru, Yasser Djilali, Shi Hu, Iheb Chaabane, Puneesh Khanna, Mohamed El Amine Seddik, Ngoc Dung Huynh, Phuc Le Khac, Leen AlQadi, Billel Mokeddem, Mohamed Chami, Abdalgader Abubaker, Mikhail Lubinets, Kacper Piskorski, Slim Frikha* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 混合架构, Transformer, 状态空间模型, 效率, 性能

**Comment:** Technical report of Falcon-H1 model series

> **TL;DR:** Falcon-H1是新型混合架构LLM，结合Transformer和SSM，实现卓越性能和效率，超越更大模型，并已开源。

**AI_Comments:** 该论文提出了一种创新的混合架构LLM，结合了Transformer和SSM的优势，有效提升了模型的效率和性能，尤其是在参数量较小的情况下超越了更大规模的模型，这对于资源受限的环境下部署高性能LLM具有重要意义。开源发布也体现了对社区贡献的承诺。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发同时具备高性能和高效率的大型语言模型，以应对各种用例的需求，并挑战现有LLM设计、数据策略和训练动态的传统实践。

**Method:** 采用并行的混合架构，将基于Transformer的注意力机制与状态空间模型（SSM）相结合，利用SSM在长上下文记忆和计算效率方面的优势。同时，系统性地重新审视了模型设计、数据策略和训练动态。

**Result:** Falcon-H1模型在参数和训练效率方面表现出色，并达到最先进的性能。旗舰模型Falcon-H1-34B在参数和数据量更少的情况下，匹配或超越了高达70B参数规模的模型（如Qwen3-32B、Qwen2.5-72B和Llama3.3-70B）。较小的模型也显示出类似趋势，例如Falcon-H1-1.5B-Deep可与当前领先的7B-10B模型媲美，Falcon-H1-0.5B与2024年典型的7B模型性能相当。这些模型在推理、数学、多语言任务、指令遵循和科学知识方面表现出色，支持高达256K的上下文令牌和18种语言。

**Conclusion:** Falcon-H1系列模型通过其创新的混合架构设计，重新定义了LLM的效率和性能标准，并在各种规模上展现出卓越的能力，所有模型均以开放源代码许可发布，旨在促进可访问和有影响力的AI研究。

> **ai_Abstract:** 该论文介绍了Falcon-H1系列大型语言模型，其核心创新在于采用结合了Transformer注意力和状态空间模型（SSM）的并行混合架构，旨在同时优化性能和效率。通过系统性地重新审视模型设计、数据策略和训练动态，Falcon-H1在不同参数规模下均展现出卓越的性能和效率，例如旗舰模型Falcon-H1-34B能匹敌或超越参数量更大的现有模型。此外，该系列模型在推理、数学、多语言等多个任务上表现出色，并支持长上下文和多语言，所有模型均已开源发布。

> **摘要翻译:** 本报告介绍了Falcon-H1，这是一个新的大型语言模型（LLM）系列，其混合架构设计针对高效率和高性能进行了优化，适用于各种用例。与之前仅基于Transformer或Mamba架构的Falcon模型不同，Falcon-H1采用了一种并行的混合方法，将基于Transformer的注意力机制与状态空间模型（SSM）相结合，后者以其卓越的长上下文记忆和计算效率而闻名。我们系统地重新审视了模型设计、数据策略和训练动态，挑战了该领域的传统实践。Falcon-H1以多种配置发布，包括0.5B、1.5B、1.5B-deep、3B、7B和34B参数的基础模型和指令微调变体。量化后的指令微调模型也可用，Hugging Face Hub上总计有超过30个检查点。Falcon-H1模型展示了最先进的性能以及卓越的参数和训练效率。旗舰模型Falcon-H1-34B在参数和数据量更少的情况下，匹配或超越了高达70B规模的模型，如Qwen3-32B、Qwen2.5-72B和Llama3.3-70B。较小的模型也显示出类似趋势：Falcon-H1-1.5B-Deep可与当前领先的7B-10B模型媲美，而Falcon-H1-0.5B的性能与2024年典型的7B模型相当。这些模型在推理、数学、多语言任务、指令遵循和科学知识方面表现出色。Falcon-H1支持高达256K的上下文令牌和18种语言，适用于广泛的应用。所有模型均以宽松的开源许可证发布，彰显了我们对可访问和有影响力的AI研究的承诺。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [359] [Product vs. Process: Exploring EFL Students' Editing of AI-Generated Text for Expository Writing](https://arxiv.org/abs/2507.21073)
> *产品与过程：探索EFL学生对AI生成文本的议论性写作编辑*

*David James Woo, Yangyang Yu, Kai Guo, Yilin Huang, April Ka Yeng Fung* | **Category: cs.CL, cs.HC** | **Updated: 2025-06-10**

**Keywords:** AI生成文本, EFL写作, 编辑行为, 议论性写作, 人工智能辅助写作

**Comment:** 45 pages, 11 figures

> **TL;DR:** 本研究发现，EFL学生对AI生成文本的编辑工作量与作文质量提升之间存在脱节，表明AI是辅助而非替代写作技能。研究强调了在AI整合前进行体裁特定教学和过程导向写作的重要性。

**AI_Comments:** 这项研究创新性地探讨了AI在EFL写作中对学生编辑行为和作文质量的复杂影响，揭示了AI辅助写作的局限性。其重要性在于为教育者提供了关于如何有效整合AI工具的实践指导，强调了教学重点应从单纯的产品转向过程，并鼓励批判性地使用AI。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人工智能（AI）聊天机器人生成的文本在英语作为外语（EFL）写作环境中日益普及，但其对学生议论性写作过程和作品的影响仍未得到充分研究。

**Method:** 本研究考察了39名香港中学生如何编辑AI生成的文本，分析他们在议论性写作过程和作文中的编辑行为及其对人工评分（内容、组织、语言、整体质量）的影响。采用聚合设计，分析学生的屏幕录像和作文，分析方法包括定性编码、描述性统计、时间序列分析、人工评分和多元线性回归分析，分析了超过260次编辑。

**Result:** 研究识别出两种编辑模式：一是学生在进展前反复修改引言单元；二是他们快速转向主体单元（如主题句和支持句）的广泛编辑。多元线性回归分析显示，AI生成词的数量正向预测所有评分维度，而大多数编辑变量影响甚微。这些结果表明学生大量的编辑努力与作文质量提升之间存在脱节。

**Conclusion:** AI支持写作但不能取代写作技能。研究结果强调了在整合AI之前，进行体裁特定教学和以过程为中心的写作的重要性。教育者应开发同时重视过程和产品的评估方式，以鼓励学生批判性地参与AI文本。

> **ai_Abstract:** 本研究探讨了EFL中学生如何编辑AI生成文本，以及这种编辑对其议论性作文质量的影响。通过分析39名香港学生的屏幕录像和作文，研究发现学生在AI辅助写作中存在两种编辑模式，但其大量的编辑努力与作文质量的提升之间关联不大。结果表明AI可以辅助写作，但不能替代核心写作技能，并强调了在AI整合前进行体裁特定和过程导向教学的重要性，以及开发评估过程和产品的综合评估方式。

> **摘要翻译:** 人工智能 (AI) 聊天机器人生成的文本在英语作为外语 (EFL) 写作环境中得到越来越多的使用，但其对学生议论性写作过程和作文的影响仍未得到充分研究。本研究考察了EFL中学生如何编辑AI生成的文本，探索他们在议论性写作过程和议论性作文中的编辑行为，以及其对内容、组织、语言和整体质量的人工评分的影响。参与者是39名香港中学生，他们在一次研讨会上使用AI聊天机器人撰写了一篇议论性作文。研究采用聚合设计来分析他们的屏幕录像和作文，以检查学生的编辑行为和写作质量。分析方法包括定性编码、描述性统计、时间序列分析、人工评分和多元线性回归分析。我们分析了每个数据集超过260次编辑，并确定了两种编辑模式：一种是学生在进展之前反复修改引言单元，另一种是他们快速转向主体单元（例如，主题句和支持句）的广泛编辑。多元线性回归分析显示，AI生成词的数量正向预测所有评分维度，而大多数编辑变量影响甚微。这些结果表明学生大量的编辑努力与作文质量提升之间存在脱节，表明AI是辅助而非替代写作技能。研究结果强调了在整合AI之前，进行体裁特定教学和以过程为中心的写作的重要性。教育者还应开发同时重视过程和产品的评估方式，以鼓励学生批判性地参与AI文本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [375] [ChatGPT Reads Your Tone and Responds Accordingly -- Until It Does Not -- Emotional Framing Induces Bias in LLM Outputs](https://arxiv.org/abs/2507.21083)
> *ChatGPT 读取你的语气并做出相应回应——直到它不再如此——情感框架在大型语言模型输出中引入偏见*

*Franck Bardol* | **Category: cs.CL, cs.AI** | **Updated: 2025-06-17**

**Keywords:** 情感框架, LLM偏见, GPT-4, 反弹偏见, AI对齐

**Comment:** 

> **TL;DR:** 大型语言模型（如GPT-4）会根据情感措辞调整回应。研究发现，GPT-4在面对负面情感提问时，负面回应的可能性比中性提问低三倍，显示出一种“反弹”偏见，即模型会过度纠正，倾向于中性或积极回应。在敏感话题上，这种效应更为明显，表明存在对齐覆盖。这项工作揭示了由情感框架引起的偏见，对AI对齐和信任有重要影响。

**AI_Comments:** 这项研究的创新之处在于系统地揭示并量化了大型语言模型中由情感框架引起的“反弹”偏见和“语调下限”现象。它深入探讨了LLM在处理情感语调时的复杂行为，尤其是在敏感话题上的“对齐覆盖”，这对于理解和改进AI的公平性、可靠性及信任度至关重要。研究结果对AI对齐研究和实际应用中的提示工程具有重要启示。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（如GPT-4）不仅根据问题本身，还会根据其情感措辞来调整回应。这项研究的动机是系统地探索和量化情感框架如何影响LLM的输出，并揭示由此产生的一类未被充分探索的偏见。

**Method:** 研究人员系统地改变了156个提示的情感语调，这些提示涵盖了争议性和日常话题，并分析了其如何影响模型回应。他们引入了“语调下限”（tone floor）等概念，并使用语调-效价转换矩阵来量化行为。基于1536维嵌入的可视化也用于确认基于语调的语义漂移。

**Result:** 研究发现，GPT-4对负面措辞问题的负面回应可能性是中性问题的三分之一，这表明存在一种“反弹”偏见，即模型过度纠正，通常转向中性或积极。在敏感话题（如正义或政治）上，这种效应更为显著：基于语调的变化被抑制，表明存在对齐覆盖。基于1536维嵌入的可视化证实了基于语调的语义漂移。

**Conclusion:** 这项工作强调了一类由提示中情感框架驱动的、未被充分探索的偏见，对AI的对齐和信任具有重要影响。

> **ai_Abstract:** 这项研究探讨了大型语言模型（LLM），特别是GPT-4，如何根据提示的情感语调调整其回应。通过系统地改变156个提示的情感语调，研究发现GPT-4对负面措辞问题的负面回应可能性显著降低（是中性问题的三分之一），揭示了一种“反弹”偏见，即模型倾向于过度纠正至中性或积极。在敏感话题上，这种偏见更为突出，表明存在对齐机制的覆盖。研究引入了“语调下限”和语调-效价转换矩阵来量化这些行为，并通过嵌入可视化确认了语义漂移。该工作强调了情感框架在LLM输出中引入的一种未被充分探索的偏见，这对AI对齐和信任具有重要意义。

> **摘要翻译:** 大型语言模型如GPT-4不仅根据提出的问题，还根据问题的情感措辞来调整其回应。我们系统地改变了156个提示的情感语调——涵盖了争议性和日常话题——并分析了它如何影响模型回应。我们的发现表明，GPT-4对负面措辞问题的负面回应可能性比中性问题低三倍。这表明存在一种“反弹”偏见，即模型过度纠正，通常转向中性或积极。在敏感话题（例如，正义或政治）上，这种效应更为显著：基于语调的变化被抑制，表明存在对齐覆盖。我们引入了“语调下限”（tone floor）等概念——回应负面性的下限——并使用语调-效价转换矩阵来量化行为。基于1536维嵌入的可视化证实了基于语调的语义漂移。我们的工作强调了一类由提示中情感框架驱动的、未被充分探索的偏见，对AI对齐和信任具有重要影响。代码和数据可在以下网址获取：https://github.com/bardolfranck/llm-responses-viewer

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [381] [Diverse LLMs or Diverse Question Interpretations? That is the Ensembling Question](https://arxiv.org/abs/2507.21168)
> *多样化的LLM还是多样化的提问解释？这是集成的问题*

*Rafael Rosales, Santiago Miret* | **Category: cs.CL, cs.AI, cs.LG, 68T50, I.2.7; I.2.0** | **Updated: 2025-07-25**

**Keywords:** LLMs, 集成, 多样性, 问题解释, 模型多样性

**Comment:** 

> **TL;DR:** 对于二元问题回答的LLM集成，问题解释多样性比模型多样性更有效，能带来更好的准确性。

**AI_Comments:** 这篇论文为LLM的有效集成策略提供了有价值的见解，表明重新措辞问题可能比简单地增加更多模型更有益。这挑战了仅仅增加模型数量的直观方法，并强调了输入扰动的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 利用多样性已被证明可以提高大型语言模型（LLMs）的性能，但如何最有效地利用多样性仍然是一个挑战。本研究旨在比较两种多样性方法在LLM二元问题回答中的效果。

**Method:** 研究比较了两种LLM二元问题回答的多样性方法：模型多样性（多个模型回答同一问题）和问题解释多样性（同一模型以不同方式回答同一问题）。两种方法均采用多数投票作为集成共识启发式方法。实验在boolq、strategyqa和pubmedqa数据集上进行，并分析了GPT和LLaMa的表现。

**Result:** 实验表明，问题解释多样性始终比模型多样性带来更好的集成准确性。模型多样性通常产生的结果介于最佳和最差集成成员之间，没有明显的改进。

**Conclusion:** 对于使用LLM回答二元问题，改变问题表述（问题解释多样性）比使用多个不同的LLM（模型多样性）更能有效提升集成性能。

> **ai_Abstract:** 本研究探讨了两种用于LLM集成回答二元问题的多样性方法：使用多个模型（模型多样性）和以不同方式重新表述问题（问题解释多样性）。在多个数据集上的实验结果显示，问题解释多样性持续带来更高的集成准确性，而模型多样性则未能带来明显的性能提升。

> **摘要翻译:** 有效利用多样性已被证明可以提高各种机器学习模型（包括大型语言模型，LLMs）的性能。然而，确定使用多样性最有效的方式仍然是一个挑战。在这项工作中，我们比较了两种利用LLMs回答二元问题多样性方法：模型多样性，它依赖于多个模型回答同一个问题；以及问题解释多样性，它依赖于使用同一个模型以不同方式表述的同一个问题。在这两种情况下，我们都采用多数投票作为集成共识启发式方法来确定最终答案。我们在boolq、strategyqa和pubmedqa上的实验表明，问题解释多样性始终比模型多样性带来更好的集成准确性。此外，我们对GPT和LLaMa的分析表明，模型多样性通常产生的结果介于最佳和最差集成成员之间，没有明显的改进。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [389] [What is an "Abstract Reasoner"? Revisiting Experiments and Arguments about Large Language Models](https://arxiv.org/abs/2507.22457)
> *什么是“抽象推理者”？重新审视关于大型语言模型的实验和论点*

*Tian Yun, Chen Sun, Ellie Pavlick* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 抽象推理, 零样本学习, 微调, 泛化能力

**Comment:** CONLL 2025. Project webpage: https://abstract-reasoner-llm.github.io/

> **TL;DR:** 本文重新审视了大型语言模型（LLM）是否是“抽象推理者”的论点。研究发现，虽然LLM在零样本设置下表现不佳，但通过微调少量输入编码参数可以实现接近完美的性能，不过这种微调不一定能跨数据集泛化。

**AI_Comments:** 本文通过实验揭示了大型语言模型在“抽象推理”能力上的细微之处。其创新之处在于指出，即使是零样本表现不佳的模型，通过轻微的参数调整（针对输入编码）也能大幅提升性能，这挑战了简单地将LLM归类为非“抽象推理者”的观点。但同时，泛化能力的局限性也提示我们，LLM的“智能”可能更多地依赖于特定任务的适应性而非普遍的抽象推理。这对于理解LLM的能力边界和未来研究方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 近期有研究指出大型语言模型（LLM）不是“抽象推理者”，并以它们在各种挑战性任务上的零样本表现不佳为证。本文旨在重新审视这些实验，为这一主张增加细微差别。

**Method:** 本文重新审视了现有实验，并通过实验证明了LLM在零样本设置下的表现，并进一步测试了通过微调少量输入编码参数对性能的影响，以及这种微调在不同数据集间的泛化能力。

**Result:** 研究发现，尽管大型语言模型在零样本设置下表现不佳，但即使只对输入编码的一小部分参数进行微调，也能使其达到接近完美的性能。然而，这种微调并不一定能跨数据集进行泛化。

**Conclusion:** 本文认为，这些实证结果促使我们重新开放关于“抽象推理者”的定义及其重要性的讨论，以及大型语言模型是否符合这一标准。

> **ai_Abstract:** 本文旨在探讨大型语言模型（LLM）是否是“抽象推理者”这一争议。研究通过重新审视现有实验发现，虽然LLM在零样本任务上表现不佳，但通过对输入编码参数进行少量微调即可显著提升性能至接近完美。然而，这种微调的有效性并不总是能跨数据集泛化。作者基于这些发现，呼吁重新审视“抽象推理者”的定义及其对LLM的意义。

> **摘要翻译:** 最近的工作认为大型语言模型（LLMs）不是“抽象推理者”，并引用它们在各种挑战性任务上糟糕的零样本表现作为证据。我们重新审视这些实验，以增加对该主张的细微差别。首先，我们表明，虽然LLMs在零样本设置下的确表现不佳，但即使只调整一小部分输入编码参数，也能实现接近完美的性能。然而，我们也表明这种微调不一定能跨数据集迁移。我们将这些实证结果视为一个邀请，以（重新）开启关于“抽象推理者”的含义以及LLMs是否符合这一标准为何重要的讨论。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [406] [Post-Training Large Language Models via Reinforcement Learning from Self-Feedback](https://arxiv.org/abs/2507.21931)
> *通过自反馈强化学习进行大语言模型后训练*

*Carel van Niekerk, Renato Vukovic, Benjamin Matthias Ruppik, Hsien-chin Lin, Milica Gašić* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 强化学习, 自反馈, 后训练, 模型校准

**Comment:** 

> **TL;DR:** 提出RLSF，一种LLM后训练方法，利用模型自身置信度作为内在奖励，无需外部标签，能提高模型校准度和推理能力。

**AI_Comments:** RLSF的创新点在于其利用模型自身不确定性作为内在奖励进行强化学习，避免了对昂贵的人工标注或外部反馈的依赖，这对于LLM的规模化后训练具有重要意义。它提出了一种新颖的无需人工参与的校准和推理能力提升方法，为未来的LLM后训练研究开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）常产生看似合理但校准性差的答案，这限制了它们在推理密集型任务上的可靠性。

**Method:** 本文提出了自反馈强化学习（RLSF），这是一个后训练阶段，模仿人类在没有外部反馈的情况下学习，使用模型自身的置信度作为内在奖励。具体方法是，一个冻结的LLM生成多个思维链解决方案后，定义并计算每个最终答案的置信度，并据此对轨迹进行排序。这些合成偏好随后用于通过标准偏好优化来微调策略，类似于RLHF但不需要人工标签、黄金答案或外部策划的奖励。

**Result:** RLSF同时实现了：(i) 优化模型的概率估计，恢复良好的校准；(ii) 强化逐步推理，从而提高算术推理和多项选择问答的性能。

**Conclusion:** 通过将模型的自身不确定性转化为有用的自反馈，RLSF证实了基于内在模型行为的强化学习是LLM后训练流程中一个原则性且数据高效的组成部分，并值得进一步研究LLM后训练中的内在奖励。

> **ai_Abstract:** 本文提出自反馈强化学习（RLSF），一种针对大型语言模型（LLMs）的后训练方法，旨在解决LLMs产生校准性差答案的问题。RLSF利用模型自身对答案的置信度作为内在奖励，无需外部标签或人工反馈。该方法通过生成多个思维链解决方案并根据答案置信度进行排序，然后使用这些合成偏好来微调模型。实验结果表明，RLSF能够改善模型的概率估计（恢复校准性）并增强逐步推理能力，从而在算术推理和多项选择问答任务上取得性能提升。RLSF证明了基于内在奖励的强化学习是LLM后训练中一种有效且数据高效的策略。

> **摘要翻译:** 大型语言模型（LLMs）经常产生看似合理但校准性差的答案，这限制了它们在推理密集型任务上的可靠性。我们提出了自反馈强化学习（RLSF），这是一个后训练阶段，它使用模型自身的置信度作为内在奖励，模仿人类在没有外部反馈的情况下学习。在冻结的LLM生成多个思维链解决方案后，我们定义并计算每个最终答案范围的置信度，并据此对轨迹进行排序。然后，这些合成偏好用于通过标准偏好优化来微调策略，类似于RLHF，但不需要人工标签、黄金答案或外部策划的奖励。RLSF同时（i）优化模型的概率估计——恢复良好的校准——并（ii）强化逐步推理，从而提高算术推理和多项选择问答的性能。通过将模型的自身不确定性转化为有用的自反馈，RLSF证实了基于内在模型行为的强化学习是LLM后训练流程中一个原则性且数据高效的组成部分，并值得进一步研究LLM后训练中的内在奖励。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [411] [iLSU-T: an Open Dataset for Uruguayan Sign Language Translation](https://arxiv.org/abs/2507.21104)
> *iLSU-T：一个乌拉圭手语翻译开放数据集*

*Ariel E. Stassi, Yanina Boria, J. Matías Di Martino, Gregory Randall* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-07**

**Keywords:** 乌拉圭手语翻译, 开放数据集, 多模态数据, 手语处理, 可及性

**Comment:** 10 pages, 5 figures, 19th International Conference on Automatic Face
  and Gesture Recognition IEEE FG 2025

> **TL;DR:** iLSU-T是一个用于乌拉圭手语翻译的开放数据集，包含多模态视频数据，旨在促进手语处理工具的开发。

**AI_Comments:** 该论文通过发布iLSU-T数据集，填补了乌拉圭手语翻译领域本地化数据稀缺的空白，为计算机视觉和计算语言学社区提供了宝贵的资源。其创新性在于收集并整理了大量多模态的、由专业译员参与的真实世界数据。这项工作的重要性在于为手语翻译和理解研究提供了一个新的基准，并强调了本地化数据在提高残障人士可及性和包容性方面的关键作用。虽然文章提到了使用SOTA算法进行基线实验，但并未详细说明这些算法的具体表现，未来工作可以更深入地探索数据集在不同模型下的性能。数据集的开放性是其一大亮点，将极大促进该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 自动手语翻译在计算机视觉和计算语言学领域受到关注，但鉴于每个国家手语的特殊性，机器翻译需要本地数据来开发新技术和调整现有技术，以弥补现有数据不足以满足乌拉圭手语特定需求的问题。

**Method:** 本文提出了iLSU-T，一个开放的、包含乌拉圭手语RGB视频、音频和文本转录的多模态数据集。该数据集包含超过185小时的来自公共电视广播的口译手语视频，涵盖不同主题，并有18位专业手语译员参与。此外，本文还介绍了一系列使用三种最先进翻译算法的实验，旨在为该数据集建立基线并评估其有用性以及所提出的数据处理流程。

**Result:** 实验结果突出了手语翻译和理解领域对更多本地化数据集的需求，这对于开发新工具以提高所有个体的可及性和包容性至关重要。该论文的数据和代码已可访问。

**Conclusion:** iLSU-T数据集的创建和基线实验证明了本地化手语数据集对于推动手语翻译和理解研究的重要性，并强调了未来在该领域进行更多数据收集和工具开发的必要性，以实现更好的可及性和包容性。

> **ai_Abstract:** iLSU-T是首个针对乌拉圭手语翻译的开放数据集，包含185小时以上的多模态视频数据，旨在弥补本地化手语数据不足的问题。该数据集支持手语处理工具的开发，并已通过基线实验验证其价值，强调了本地化数据对手语可及性和包容性的重要性。数据和代码均已开放。

> **摘要翻译:** 近年来，自动手语翻译在计算机视觉和计算语言学领域引起了特别关注。鉴于每个国家手语的特殊性，机器翻译需要本地数据来开发新技术和调整现有技术。这项工作提出了iLSU T，一个包含乌拉圭手语RGB视频、音频和文本转录的开放数据集。这种多模态和经过整理的数据对于开发理解或生成手语处理工具的新方法至关重要。iLSU T包含超过185小时的来自公共电视广播的口译手语视频。它涵盖了不同的主题，并有18位专业手语译员参与。本文介绍了一系列使用三种最先进翻译算法的实验。目的是为该数据集建立基线，并评估其有用性以及所提出的数据处理流程。实验强调了手语翻译和理解领域对更多本地化数据集的需求，这对于开发新工具以提高所有个体的可及性和包容性至关重要。我们的数据和代码可以访问。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [417] [Contrast-CAT: Contrasting Activations for Enhanced Interpretability in Transformer-based Text Classifiers](https://arxiv.org/abs/2507.21186)
> *对比-CAT：通过对比激活增强基于Transformer的文本分类器可解释性*

*Sungmin Han, Jeonghyun Lee, Sangkyun Lee* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-27**

**Keywords:** Transformer可解释性, 文本分类, 激活归因, Contrast-CAT, 类别无关特征

**Comment:** 

> **TL;DR:** 提出Contrast-CAT方法，通过对比激活过滤无关特征，显著提升基于Transformer的文本分类器可解释性，超越现有技术。

**AI_Comments:** 这篇论文解决了Transformer模型可解释性中的一个关键问题，即激活中包含的类别无关特征。通过引入对比激活的概念，Contrast-CAT提供了一种新颖且有效的方法来净化归因图，从而提高了模型解释的可靠性和忠实度。其在性能上的显著提升，尤其是在MoRF设置下的具体量化指标，证明了其创新性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Transformer模型在AI领域影响深远，但其决策过程难以解释，即使对于文本分类等相对简单的任务也是如此，这阻碍了其在实际应用中的信任和安全部署。现有的基于激活的归因方法受限于激活中存在的类别无关特征，导致解释的可靠性降低。

**Method:** 提出Contrast-CAT，一种新颖的基于激活对比的归因方法。该方法通过过滤掉激活中的类别无关特征来精炼令牌级别的归因。具体地，它通过对比输入序列的激活与参考激活来生成更清晰、更忠实的归因图。

**Result:** Contrast-CAT在多种数据集和模型上持续优于最先进的方法。在MoRF设置下，其在AOPC上平均提升了1.30倍，在LOdds上平均提升了2.25倍，超越了最具竞争力的现有方法。

**Conclusion:** Contrast-CAT有效增强了基于Transformer的文本分类器的可解释性。

> **ai_Abstract:** 本文提出了Contrast-CAT，一种新颖的基于激活对比的归因方法，旨在提高基于Transformer的文本分类模型的可解释性。针对现有激活归因方法受类别无关特征影响的问题，Contrast-CAT通过对比输入与参考激活来过滤这些无关特征，从而生成更清晰、更可靠的归因图。实验证明，Contrast-CAT在多个数据集和模型上显著优于现有技术，特别是在MoRF设置下，其AOPC和LOdds指标有大幅提升，有效增强了Transformer模型的可解释性。

> **摘要翻译:** Transformer在AI研究中产生了深远影响，但解释其决策仍然具有挑战性——即使对于文本分类等相对简单的任务也是如此——这阻碍了在实际应用中的信任和安全部署。尽管基于激活的归因方法能有效解释基于Transformer的文本分类模型，但我们的发现表明，这些方法可能会受到激活中类别无关特征的破坏，导致解释的可靠性降低。为了解决这一局限性，我们提出了Contrast-CAT，一种新颖的基于激活对比的归因方法，通过过滤掉类别无关特征来精炼令牌级别的归因。通过对比输入序列的激活与参考激活，Contrast-CAT生成了更清晰、更忠实的归因图。在各种数据集和模型上的实验结果证实，Contrast-CAT始终优于最先进的方法。值得注意的是，在MoRF设置下，它在AOPC上平均提升了1.30倍，在LOdds上平均提升了2.25倍，超越了最具竞争力的现有方法，这表明它在增强基于Transformer的文本分类可解释性方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [419] [IFEvalCode: Controlled Code Generation](https://arxiv.org/abs/2507.22462)
> *IFEvalCode：受控代码生成*

*Jian Yang, Wei Zhang, Shukai Liu, Linzheng Chai, Yingshui Tan, Jiaheng Liu, Ge Zhang, Wangchunshu Zhou, Guanglin Niu, Zhoujun Li, Binyuan Hui, Junyang Lin* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 代码大语言模型, 受控代码生成, 指令遵循, IFEvalCode, 基准测试

**Comment:** 10 pages

> **TL;DR:** 本文介绍了IFEvalCode，这是一个新的多语言基准，用于评估大型代码模型在受控代码生成中遵循指令的能力，并发现闭源模型表现更好，且模型在生成正确代码和遵循指令之间存在显著差距。

**AI_Comments:** 该论文创新性地提出了前向和后向约束生成方法来增强代码LLM的指令遵循能力，并构建了一个新的多语言基准IFEvalCode，其独特的双指标评估体系（正确性和指令遵循）为更细致地评估代码生成模型提供了新视角。研究结果揭示了当前模型在遵循复杂指令方面的局限性，特别是在开源模型中，这对于未来可控代码生成的研究具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管代码大型语言模型（Code LLMs）在将自然语言描述转换为功能代码方面取得了显著进展，但现实世界的应用通常要求更严格地遵守详细的需求，例如编码风格、行数和结构约束，而不仅仅是代码的正确性。

**Method:** 本文引入了前向和后向约束生成来提高代码LLM在受控代码生成中的指令遵循能力。作者进一步提出了IFEvalCode，一个多语言基准，包含1.6K个测试样本，涵盖七种编程语言（Python、Java、JavaScript、TypeScript、Shell、C++和C#），每个样本都有中文和英文查询。IFEvalCode将评估解耦为两个指标：正确性（Corr.）和指令遵循（Instr.）。

**Result:** 对40多个LLM进行的实验表明，闭源模型在可控代码生成方面优于开源模型，并突显了模型生成正确代码与精确遵循指令的代码之间存在显著差距。

**Conclusion:** 为了解决现有代码LLM在受控代码生成中指令遵循能力不足的问题，本文提出了前向和后向约束生成方法，并构建了IFEvalCode基准。实验结果表明，尽管闭源模型表现较好，但所有模型在生成符合指令的代码方面仍有很大提升空间，这强调了未来研究的重点。

> **ai_Abstract:** 本研究旨在提升代码大型语言模型在受控代码生成中遵循详细指令的能力。论文提出了一种前向和后向约束生成方法，并引入了IFEvalCode，一个包含1.6K多语言样本的新型基准，该基准将代码评估分为正确性和指令遵循两部分。实验结果显示，闭源模型在可控代码生成上表现优于开源模型，同时揭示了模型在生成正确代码和生成严格遵循指令的代码之间存在明显差距。

> **摘要翻译:** 代码大型语言模型（Code LLMs）通过将自然语言描述转换为功能代码，在代码生成方面取得了显著进展；然而，现实世界的应用往往要求更严格地遵守详细要求，例如编码风格、行数和结构约束，而不仅仅是正确性。为了解决这个问题，本文引入了前向和后向约束生成，以提高代码LLM在受控代码生成中的指令遵循能力，确保输出更符合人类定义的指导原则。作者进一步提出了IFEvalCode，一个多语言基准，包含1.6K个测试样本，涵盖七种编程语言（Python、Java、JavaScript、TypeScript、Shell、C++和C#），每个样本都包含中文和英文查询。与现有基准不同，IFEvalCode将评估解耦为两个指标：正确性（Corr.）和指令遵循（Instr.），从而实现更细致的评估。对40多个LLM进行的实验表明，闭源模型在可控代码生成方面优于开源模型，并突显了模型生成正确代码与精确遵循指令的代码之间存在显著差距。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [435] [Cross-Modal State-Space Graph Reasoning for Structured Summarization](https://arxiv.org/abs/2503.20988)
> *跨模态状态空间图推理用于结构化摘要*

*Hannah Kim, Sofia Martinez, Jason Lee* | **Category: cs.CL, cs.GR** | **Updated: 2025-07-30**

**Keywords:** 跨模态摘要, 状态空间模型, 图推理, 多模态数据, 可解释性

**Comment:** arXiv admin note: This paper has been withdrawn by arXiv due to
  disputed and unverifiable authorship and affiliation

> **TL;DR:** 提出CSS-GR框架，结合状态空间模型与图推理，实现高效可解释的跨模态摘要。

**AI_Comments:** 本文的创新点在于将状态空间模型与图推理相结合，应用于跨模态摘要任务。这种方法提供了处理多模态数据关系的新颖方式，相较于纯序列模型，能够更整体且高效地进行推理。同时关注效率和可解释性是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 从大规模多模态数据中提取紧凑、有意义的摘要对于众多应用至关重要，但现有跨模态摘要方法常面临高计算开销和有限可解释性问题。

**Method:** 提出跨模态状态空间图推理（CSS-GR）框架，该框架结合了状态空间模型与基于图的消息传递。该方法构建捕获模态间和模态内关系的图，实现对文本和视觉流的更整体推理，区别于纯序列模型。

**Result:** 在标准多模态摘要基准测试中验证，该方法显著提高了摘要质量和可解释性，同时保持计算效率。

**Conclusion:** 本研究提出的CSS-GR框架在跨模态摘要任务中，显著提升了摘要质量和可解释性，同时保持了计算效率。

> **ai_Abstract:** 本文提出CSS-GR框架，用于跨模态摘要，旨在解决现有方法计算开销大和可解释性差的问题。CSS-GR结合状态空间模型和图消息传递，通过构建捕获模态间和模态内关系的图，实现对文本和视觉流的整体推理。在标准基准测试中，该方法显著提升了摘要质量和可解释性，同时保持了计算效率。

> **摘要翻译:** 从大规模多模态数据中提取紧凑、有意义的摘要对于从视频分析到医疗报告的众多应用都至关重要。先前的跨模态摘要方法常常面临高计算开销和有限可解释性问题。在本文中，我们提出了一个跨模态状态空间图推理（CSS-GR）框架，该框架结合了状态空间模型和基于图的消息传递，灵感来源于之前关于高效状态空间模型的工作。与依赖纯序列模型的现有方法不同，我们的方法构建了一个捕获模态间和模态内关系的图，从而可以对文本和视觉流进行更整体的推理。我们证明，我们的方法显著提高了摘要质量和可解释性，同时保持了计算效率，这已在标准多模态摘要基准测试中得到验证。我们还提供了详细的消融研究，以突出每个组件的贡献。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [449] [SLM-SQL: An Exploration of Small Language Models for Text-to-SQL](https://arxiv.org/abs/2507.22478)
> *SLM-SQL：小型语言模型在Text-to-SQL中的探索*

*Lei Sheng, Shuai-Shuai Xu* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 小型语言模型, Text-to-SQL, 后训练, 监督微调, 强化学习

**Comment:** 16 pages, 2 figures, work in progress

> **TL;DR:** 本文探索并显著提升了小型语言模型在Text-to-SQL任务上的性能，通过后训练技术和新数据集使0.5B模型达到56.87% EX，1.5B模型达到67.08% EX。

**AI_Comments:** 这篇论文的创新点在于它成功地将先进的后训练技术应用于小型语言模型，显著提升了它们在复杂Text-to-SQL任务上的性能，突破了SLM在逻辑推理方面的局限。这对于资源受限或需要边缘部署的应用场景具有重要意义，因为它表明即使是小型模型也能通过精心设计的方法达到可接受的性能水平。该研究还贡献了新的数据集和开源代码，有助于推动该领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在Text-to-SQL任务上表现出色，但小型语言模型因逻辑推理能力有限而表现不佳。然而，小型语言模型在推理速度和边缘部署方面具有固有优势。为了探索它们在Text-to-SQL应用中的潜力，作者利用了后训练技术的最新进展。

**Method:** 作者利用开源的SynSQL-2.5M数据集构建了两个派生数据集：用于SQL生成的SynSQL-Think-916K和用于SQL合并修订的SynSQL-Merge-Think-310K。然后，对小型语言模型应用了监督微调和基于强化学习的后训练，接着使用纠正性自洽方法进行推理。

**Result:** 实验结果验证了他们的方法SLM-SQL的有效性和泛化性。在BIRD开发集上，五个评估模型的平均改进达到31.4分。值得注意的是，0.5B模型达到了56.87%的执行准确率（EX），而1.5B模型达到了67.08%的EX。

**Conclusion:** SLM-SQL方法在Text-to-SQL任务上对小型语言模型是有效且具有泛化性的。

> **ai_Abstract:** 本文介绍了SLM-SQL，一种旨在提升小型语言模型（SLM）在Text-to-SQL任务上性能的方法。鉴于SLM在推理速度和边缘部署方面的优势，研究人员通过利用后训练技术，结合专门构建的SynSQL派生数据集（SynSQL-Think-916K和SynSQL-Merge-Think-310K），并应用监督微调、强化学习以及纠正性自洽推理，显著提高了SLM的执行准确率。实验结果表明，该方法在BIRD开发集上使模型平均提高了31.4分，其中0.5B模型达到56.87% EX，1.5B模型达到67.08% EX，证明了SLM-SQL的有效性和泛化性。

> **摘要翻译:** 大型语言模型（LLM）在将自然语言问题翻译成SQL查询（Text-to-SQL）方面表现出强大的性能。相比之下，参数量从0.5B到1.5B的小型语言模型（SLM）由于其有限的逻辑推理能力，目前在Text-to-SQL任务上表现不佳。然而，SLM在推理速度和边缘部署方面具有固有优势。为了探索它们在Text-to-SQL应用中的潜力，我们利用了后训练技术的最新进展。具体来说，我们使用开源的SynSQL-2.5M数据集构建了两个派生数据集：用于SQL生成的SynSQL-Think-916K和用于SQL合并修订的SynSQL-Merge-Think-310K。然后，我们对SLM应用了监督微调和基于强化学习的后训练，接着使用纠正性自洽方法进行推理。实验结果验证了我们的方法SLM-SQL的有效性和泛化性。在BIRD开发集上，五个评估模型平均提高了31.4分。值得注意的是，0.5B模型达到了56.87%的执行准确率（EX），而1.5B模型达到了67.08%的EX。我们将把我们的数据集、模型和代码发布到github。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [453] [TRIDENT: Benchmarking LLM Safety in Finance, Medicine, and Law](https://arxiv.org/abs/2507.21134)
> *TRIDENT：金融、医学和法律领域LLM安全基准测试*

*Zheng Hui, Yijiang River Dong, Ehsan Shareghi, Nigel Collier* | **Category: cs.CL, cs.CY, cs.LG** | **Updated: 2025-07-22**

**Keywords:** LLM安全, 基准测试, 金融, 医学, 法律

**Comment:** 

> **TL;DR:** 针对金融、医学和法律等高风险领域，本文定义了LLM领域特定安全原则，并引入Trident-Bench基准测试，发现通用模型表现尚可，但领域专用模型在伦理细节上存在不足，强调急需改进LLM在这些领域的安全性。

**AI_Comments:** 这项工作具有重要的创新性和实用性，它填补了LLM在特定高风险领域（金融、医学、法律）安全评估的空白。通过定义明确的领域特定安全原则并构建专门的基准测试，TRIDENT为LLM在该类应用中的安全部署提供了关键工具和衡量标准。研究结果揭示了通用模型和领域专用模型在安全表现上的差异，特别是领域专用模型在伦理细微之处的不足，为未来LLM的安全性改进指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）在高风险领域（如法律、金融和医学）的广泛部署，系统评估其领域特定安全性和合规性变得至关重要。现有工作主要关注LLM在这些领域的性能提升，却忽视了领域特定安全风险的评估。

**Method:** 首先，基于美国医学会医学伦理原则、美国律师协会职业行为示范规则和特许金融分析师协会道德准则，定义了LLM的领域特定安全原则。在此基础上，引入了Trident-Bench，一个专门针对法律、金融和医学领域LLM安全的基准测试。最后，评估了19个通用和领域专用模型在Trident-Bench上的表现。

**Result:** Trident-Bench有效地揭示了关键安全漏洞——强大的通用模型（如GPT、Gemini）可以满足基本预期，而领域专用模型在细微的伦理细微之处往往表现不佳。

**Conclusion:** 这项工作强调了对更细粒度的领域特定安全改进的迫切需求。Trident-Bench的引入为研究LLM在法律和金融领域的安全性提供了首批系统资源之一，并为未来旨在降低LLM在专业监管领域部署安全风险的研究奠定了基础。

> **ai_Abstract:** 本文针对大型语言模型（LLM）在高风险领域（如法律、金融、医学）部署时面临的领域特定安全评估缺失问题，定义了基于行业准则的LLM安全原则，并提出了Trident-Bench基准测试。通过对19个模型的评估，发现通用模型能达到基本安全要求，但领域专用模型在处理伦理细节上表现欠佳。研究强调了对LLM进行更细致的领域特定安全改进的必要性，并为未来相关研究提供了系统性资源。

> **摘要翻译:** 随着大型语言模型（LLM）越来越多地部署在法律、金融和医学等高风险领域，系统评估其领域特定安全性和合规性变得至关重要。虽然先前的工作主要集中于提高LLM在这些领域的性能，但往往忽视了对领域特定安全风险的评估。为了弥补这一差距，我们首先基于美国医学会医学伦理原则、美国律师协会职业行为示范规则和特许金融分析师协会道德准则，定义了LLM的领域特定安全原则。在此基础上，我们引入了Trident-Bench，一个专门针对法律、金融和医学领域LLM安全的基准测试。我们评估了19个通用和领域专用模型在Trident-Bench上的表现，结果表明它有效地揭示了关键安全漏洞——强大的通用模型（例如GPT、Gemini）可以满足基本预期，而领域专用模型在细微的伦理细微之处往往表现不佳。这突出表明迫切需要更细粒度的领域特定安全改进。通过引入Trident-Bench，我们的工作提供了研究LLM在法律和金融领域安全性的首批系统资源之一，并为未来旨在降低在专业监管领域部署LLM的安全风险的研究奠定了基础。代码和基准将发布在：https://github.com/zackhuiiiii/TRIDENT

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [468] [A Comprehensive Taxonomy of Negation for NLP and Neural Retrievers](https://arxiv.org/abs/2507.22337)
> *自然语言处理和神经检索器中否定现象的综合分类法*

*Roxana Petcu, Samarth Bhargav, Maarten de Rijke, Evangelos Kanoulas* | **Category: cs.CL, cs.IR** | **Updated: 2025-07-30**

**Keywords:** 否定, 自然语言处理, 神经检索, 分类法, 数据集

**Comment:** 

> **TL;DR:** 本文提出了一个否定的分类法、两个基准数据集和一个逻辑分类机制，旨在解决神经模型在处理否定查询时表现不佳的问题，并提高其性能和泛化能力。

**AI_Comments:** 本文的创新之处在于其首次系统地构建了否定的综合分类法，并基于此开发了专门的基准数据集和分析机制，直接解决了当前NLP和神经检索器在处理否定查询时的性能瓶颈。这不仅有助于深入理解模型在否定理解上的不足，也为未来的模型设计和训练提供了有力的工具和方向，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管密集的神经模型能够学习上下文嵌入，但它们在处理包含否定词的查询时表现仍然不佳。为了理解这一现象，本文研究了传统神经信息检索和基于LLM的模型中的否定现象。

**Method:** 1) 引入了一个源自哲学、语言学和逻辑定义的否定分类法；2) 生成了两个基准数据集，用于评估神经信息检索模型的性能，并为提高模型在否定处理上的鲁棒性进行微调；3) 提出了一个基于逻辑的分类机制，可用于分析检索模型在现有数据集上的性能。

**Result:** 本文的分类法在否定类型上产生了平衡的数据分布，提供了更好的训练设置，从而在NevIR数据集上实现了更快的收敛。此外，本文提出的分类方案揭示了现有数据集中否定类型的覆盖范围，为影响微调模型在否定处理上泛化能力的因素提供了见解。

**Conclusion:** 本文通过引入否定的分类法、生成基准数据集和提出逻辑分类机制，有效提升了神经模型处理否定查询的能力，并揭示了现有数据集的不足，为未来的模型优化和泛化提供了方向。

> **ai_Abstract:** 本文针对密集神经模型在处理否定查询时表现不佳的问题，提出了一项全面研究。作者首先引入了一个基于哲学、语言学和逻辑的否定分类法。在此基础上，他们生成了两个基准数据集，用于评估和微调神经信息检索模型。此外，还提出了一种基于逻辑的分类机制，用于分析现有数据集上检索模型的性能。研究结果表明，该分类法能产生平衡的数据分布，促进模型更快收敛，并且提出的分类方案揭示了现有数据集中否定类型的覆盖率，为提高模型泛化能力提供了重要见解。

> **摘要翻译:** 理解和解决复杂的推理任务对于满足用户的信息需求至关重要。尽管密集的神经模型学习了语境化嵌入，但它们在包含否定词的查询上仍然表现不佳。为了理解这种现象，我们研究了传统神经信息检索和基于大型语言模型（LLM）的模型中的否定。我们（1）引入了一个源自哲学、语言学和逻辑定义的否定分类法；（2）生成了两个基准数据集，可用于评估神经信息检索模型的性能，并对模型进行微调以获得更强大的否定处理能力；（3）提出了一种基于逻辑的分类机制，可用于分析检索模型在现有数据集上的性能。我们的分类法在否定类型上产生了平衡的数据分布，提供了一个更好的训练设置，从而在NevIR数据集上实现了更快的收敛。此外，我们提出了一种分类方案，揭示了现有数据集中否定类型的覆盖范围，为可能影响微调模型在否定处理上泛化能力的因素提供了见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [481] [TTS-1 Technical Report](https://arxiv.org/abs/2507.21138)
> *TTS-1 技术报告*

*Oleg Atamanenko, Anna Chalova, Joseph Coombes, Nikki Cope, Phillip Dang, Zhifeng Deng, Jimmy Du, Michael Ermolenko, Feifan Fan, Yufei Feng, Cheryl Fichter, Pavel Filimonov, Louis Fischer, Kylan Gibbs, Valeria Gusarova, Pavel Karpik, Andreas Assad Kottner, Ian Lee, Oliver Louie, Jasmine Mai, Mikhail Mamontov, Suri Mao, Nurullah Morshed, Igor Poletaev, Florin Radu, Dmytro Semernia, Evgenii Shingarev, Vikram Sivaraja, Peter Skirko, Rinat Takhautdinov, Robert Villahermosa, Jean Wang* | **Category: cs.CL, cs.AI, cs.LG, cs.SD, eess.AS** | **Updated: 2025-07-22**

**Keywords:** 文本转语音, Transformer, 自回归模型, 语音合成, 深度学习

**Comment:** 20 pages, 10 figures. For associated modeling and training code, see
  https://github.com/inworld-ai/tts

> **TL;DR:** Inworld 推出两款基于 Transformer 的自回归文本转语音 (TTS) 模型：TTS-1-Max (8.8B 参数) 追求极致质量和表现力，TTS-1 (1.6B 参数) 侧重实时和设备端应用。通过大规模训练和多阶段对齐，两模型在多项基准测试中达到最先进水平，支持 48 kHz 高分辨率、低延迟、11 种语言，并提供情感和非语言发音控制。训练代码已开源。

**AI_Comments:** 该论文介绍了 Inworld 在文本转语音领域的重要进展。其创新点在于采用了大规模的 Transformer 模型（特别是 8.8B 参数的 TTS-1-Max），结合了多阶段的训练和对齐流程，实现了卓越的语音质量和表现力。模型纯粹依赖语境学习来捕捉说话人声音的特点，这在实际应用中具有很高的灵活性。支持 48 kHz 高分辨率、多语言、情感控制以及非语言发声等特性，使其在专业和消费级应用中都具有巨大潜力。此外，开源训练和建模代码对于推动社区研究和开发具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在介绍 Inworld TTS-1 系列文本转语音模型，这些模型旨在提供高质量、富有表现力、高效且支持多语言和情感控制的语音合成能力，以满足不同应用场景的需求。

**Method:** 研究人员引入了两款基于 Transformer 的自回归文本转语音 (TTS) 模型：TTS-1-Max (8.8B 参数) 和 TTS-1 (1.6B 参数)。通过扩展训练计算资源，并采用预训练、微调以及语音-语言模型 (SpeechLM) 组件的强化学习对齐的顺序过程，实现了模型的性能优化。模型纯粹依靠说话人声音的语境学习来生成高质量语音。

**Result:** Inworld TTS-1 和 TTS-1-Max 模型在多种基准测试中均达到了最先进的性能，展示了卓越的质量。它们能够生成 48 kHz 高分辨率语音，具有低延迟特性，并支持 11 种语言。通过音频标记，模型还支持细粒度的情感控制和非语言发声。此外，训练和建模代码已在 MIT 许可下开源。

**Conclusion:** Inworld TTS-1 系列模型（TTS-1-Max 和 TTS-1）是先进的 Transformer-based 自回归文本转语音模型，通过创新的训练方法实现了卓越的性能、质量、效率和多功能性，并且其训练代码已开源，有望推动语音合成领域的发展。

> **ai_Abstract:** Inworld TTS-1 是一系列包含 TTS-1-Max（8.8B 参数）和 TTS-1（1.6B 参数）的 Transformer-based 自回归文本转语音模型。通过大规模计算、预训练、微调和强化学习对齐，这些模型在各种基准测试中取得了最先进的性能，并能纯粹通过语境学习实现高质量语音合成。它们支持 48 kHz 高分辨率、低延迟、11 种语言，并提供精细的情感和非语言发声控制。此外，其训练和建模代码已开源。

> **摘要翻译:** 我们介绍了 Inworld TTS-1，这是一组两个基于 Transformer 的自回归文本转语音 (TTS) 模型。我们最大的模型 TTS-1-Max 拥有 8.8B 参数，专为要求苛刻的应用中实现极致的质量和表现力而设计。TTS-1 是我们最高效的模型，拥有 1.6B 参数，专为实时语音合成和设备端用例而构建。通过扩展训练计算并应用预训练、微调和语音-语言模型 (SpeechLM) 组件的强化学习对齐的顺序过程，这两个模型在各种基准测试中均达到了最先进的性能，纯粹依靠说话人声音的语境学习展示了卓越的质量。Inworld TTS-1 和 TTS-1-Max 可以生成 48 kHz 的高分辨率语音，具有低延迟，并通过音频标记支持 11 种语言的细粒度情感控制和非语言发声。我们还以 MIT 许可开源了我们的训练和建模代码。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [484] [CliCARE: Grounding Large Language Models in Clinical Guidelines for Decision Support over Longitudinal Cancer Electronic Health Records](https://arxiv.org/abs/2507.22533)
> *CliCARE：将大型语言模型植根于临床指南，用于纵向癌症电子健康记录的决策支持*

*Dongchen Li, Jitao Liang, Wei Li, Xiaoyu Wang, Longbing Cao, Kun Yu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 临床决策支持, 癌症, 电子健康记录, 知识图谱

**Comment:** 

> **TL;DR:** CliCARE是一个框架，通过将非结构化纵向电子健康记录转换为时间知识图谱，并与规范指南知识图谱对齐，从而将大型语言模型植根于临床指南，以提供癌症决策支持，解决了LLM在临床领域处理长文本、多语言、幻觉和评估不足的问题，并在中英文数据集上显著优于现有基线。

**AI_Comments:** CliCARE的创新之处在于其结合时间知识图谱来处理纵向EHRs的长程依赖性，并引入规范指南知识图谱对齐来减少临床幻觉，这对于LLM在高度敏感的医疗领域的应用至关重要。其在多语言和大规模真实世界数据上的验证，以及与专家评估的高度相关性，进一步凸显了其潜在的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在改进临床决策支持和减少医生职业倦怠方面具有巨大潜力，但其在处理复杂的纵向癌症电子健康记录时面临挑战：难以有效处理记录的长度和多语言性以进行准确的时间分析；临床幻觉风险高，因为现有接地技术（如RAG）未能充分整合面向过程的临床指南；以及不可靠的评估指标阻碍了AI系统在肿瘤学中的验证。

**Method:** 我们提出了CliCARE框架，它通过将非结构化、纵向的电子健康记录（EHRs）转换为患者特定的时间知识图谱（TKGs）来捕获长程依赖性，然后通过将这些真实的患者轨迹与规范的指南知识图谱对齐，从而为决策支持过程提供接地。这种方法通过生成高保真临床摘要和可操作的建议，为肿瘤学家提供有证据支持的决策支持。

**Result:** CliCARE在来自私有中文癌症数据集和公共英文MIMIC-IV数据集的大规模、纵向数据上进行了验证，并显著优于包括领先的长上下文LLM和知识图谱增强RAG方法在内的强大基线。我们结果的临床有效性得到了可靠评估协议的支持，该协议表明与专家肿瘤学家的评估高度相关。

**Conclusion:** CliCARE框架通过创新的时间知识图谱和指南知识图谱对齐，有效地解决了大型语言模型在临床决策支持中面临的挑战，提供了高保真、证据驱动的癌症决策支持，并在真实世界数据上表现出卓越的性能和临床有效性。

> **ai_Abstract:** 本研究提出了CliCARE框架，旨在解决大型语言模型在癌症临床决策支持中处理长文本、多语言记录、减少幻觉和提高评估可靠性方面的挑战。CliCARE通过将非结构化电子健康记录转换为患者特定的时间知识图谱，并将其与规范的临床指南知识图谱对齐，从而为肿瘤学家提供证据驱动的决策支持，包括高保真临床摘要和可操作的建议。该框架在中文和英文数据集上进行了验证，结果显示其性能显著优于现有基线，并得到了专家肿瘤学家评估的临床有效性支持。

> **摘要翻译:** 大型语言模型（LLMs）通过综合复杂的纵向癌症电子健康记录（EHRs），在改善临床决策支持和减少医生职业倦怠方面展现出巨大的前景。然而，它们在这一关键领域的实施面临三个主要挑战：无法有效处理患者记录的广泛长度和多语言性质以进行准确的时间分析；临床幻觉的风险增高，因为诸如检索增强生成（RAG）等传统接地技术未能充分整合面向过程的临床指南；以及不可靠的评估指标阻碍了人工智能系统在肿瘤学中的验证。为了解决这些问题，我们提出了CliCARE，一个将大型语言模型植根于临床指南以支持纵向癌症电子健康记录决策的框架。该框架通过将非结构化、纵向的EHRs转换为患者特定的时间知识图谱（TKGs）来捕获长程依赖性，然后通过将这些真实世界的患者轨迹与规范的指南知识图谱对齐，从而为决策支持过程提供接地。这种方法通过生成高保真临床摘要和可操作的建议，为肿瘤学家提供有证据支持的决策支持。我们使用来自一个私有中文癌症数据集和公共英文MIMIC-IV数据集的大规模纵向数据验证了我们的框架。在这些多样化的设置中，CliCARE显著优于强大的基线，包括领先的长上下文LLM和知识图谱增强RAG方法。我们结果的临床有效性得到了可靠评估协议的支持，该协议表明与专家肿瘤学家的评估高度相关。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [489] [Curved Inference: Concern-Sensitive Geometry in Large Language Model Residual Streams](https://arxiv.org/abs/2507.21107)
> *弯曲推理：大型语言模型残差流中关注敏感的几何学*

*Rob Manson* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-08**

**Keywords:** 大型语言模型, 可解释性, 几何学, 残差流, 语义关注

**Comment:** 29 pages, 22 figures

> **TL;DR:** 提出“弯曲推理”框架，通过几何学方法分析大型语言模型残差流如何响应语义关注变化，发现模型内部激活轨迹随关注强度变化而改变。

**AI_Comments:** 这篇论文提出了一种新颖的几何可解释性框架“弯曲推理”，通过分析大型语言模型内部残差流的曲率和显著性来理解其对语义关注变化的响应。其创新点在于将几何学概念引入LLM可解释性，并通过具体度量揭示了模型内部处理语义的动态过程。这对于理解LLM的“黑箱”操作、诊断模型行为（如对齐和抽象能力）具有重要意义，为未来的模型设计和优化提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 旨在理解大型语言模型内部的语义处理机制，特别是残差流如何根据语义关注的变化进行调整，并提供一种诊断模型对齐和抽象能力的新方法。

**Method:** 提出“弯曲推理”几何可解释性框架，用于追踪大型语言模型残差流轨迹如何响应语义关注的变化而弯曲。在20个匹配提示（涵盖情感、道德、视角、逻辑、身份、环境和无意义领域）上分析了Gemma3-1b和LLaMA3.2-3b模型。使用五个原生空间度量，主要关注曲率和显著性，这些度量在从非嵌入矩阵导出的回拉语义度量下计算。

**Result:** 关注点变化的提示会可靠地改变两个模型内部的激活轨迹。LLaMA模型表现出一致的、统计学上显著的曲率和显著性随关注强度增加而增加的缩放。Gemma模型也对关注点变化做出响应，但对中等和强变体之间的区分较弱。

**Conclusion:** 结果支持大型语言模型几何学的两层视图：嵌入空间中编码的潜在概念结构和由特定提示推理塑造的上下文轨迹。弯曲推理揭示了模型如何随着深度导航、重新定向或强化语义意义，为诊断对齐、抽象和涌现推理动态提供了一种原则性方法。这些发现通过弯曲推理的视角，为语义抽象和模型对齐提供了新的见解。

> **ai_Abstract:** 本文提出了“弯曲推理”框架，一种几何可解释性方法，用于分析大型语言模型残差流的内部轨迹如何响应语义关注的变化。通过对Gemma和LLaMA模型的实验，研究发现语义关注的变化会可靠地改变模型内部激活轨迹，特别是LLaMA的曲率和显著性随关注强度增加而显著增强。研究结果支持LLM几何学的两层视图，并为诊断模型对齐、抽象能力和涌现推理动态提供新途径。

> **摘要翻译:** 我们提出了弯曲推理——一个几何可解释性框架，它追踪大型语言模型残差流轨迹如何响应语义关注的变化而弯曲。在涵盖情感、道德、视角、逻辑、身份、环境和无意义领域的20个匹配提示中，我们使用五个原生空间度量分析了Gemma3-1b和LLaMA3.2-3b，主要关注曲率（κ_i）和显著性（S(t)）。这些度量在从非嵌入矩阵导出的回拉语义度量下计算，确保所有测量都反映与token对齐的几何结构，而不是原始坐标结构。我们发现，关注点变化的提示可靠地改变了两个模型内部的激活轨迹——其中LLaMA在关注强度增加时，曲率和显著性都表现出一致的、统计学上显著的缩放。Gemma也对关注点变化做出响应，但对中等和强变体之间的区分较弱。我们的结果支持大型语言模型几何学的两层视图——嵌入空间中编码的潜在概念结构，以及由特定提示推理塑造的上下文轨迹。弯曲推理揭示了模型如何随着深度导航、重新定向或强化语义意义，为诊断对齐、抽象和涌现推理动态提供了一种原则性方法。这些发现通过弯曲推理的视角，为语义抽象和模型对齐提供了新的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [507] [A Benchmark Dataset and Evaluation Framework for Vietnamese Large Language Models in Customer Support](https://arxiv.org/abs/2507.22542)
> *越南大语言模型在客户支持领域的基准数据集与评估框架*

*Long S. T. Nguyen, Truong P. Hua, Thanh M. Nguyen, Toan Q. Pham, Nam K. Ngo, An X. Nguyen, Nghi D. M. Pham, Nghia H. Nguyen, Tho T. Quan* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 越南语大语言模型, 客户支持, 基准数据集, 评估框架, CSConDa

**Comment:** Under review at ICCCI 2025

> **TL;DR:** 本文介绍了CSConDa，一个包含9000多个问答对的越南语客户支持对话数据集，并提出了一个评估框架，用于基准测试越南语大语言模型（ViLLMs）在客户支持场景中的表现，以帮助企业选择合适的模型并推动ViLLM研究。

**AI_Comments:** 本文的创新之处在于填补了越南语大语言模型在客户支持领域缺乏真实世界基准数据集的空白。通过创建CSConDa数据集和配套的评估框架，它为企业选择合适的ViLLMs提供了实用工具，并为该领域的研究奠定了基础。其重要性体现在为低资源语言（越南语）的特定应用场景提供了宝贵的资源，有助于推动该语言LLM技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 目前针对越南语大语言模型（ViLLMs）的领域特定评估有限，并且缺乏反映真实客户交互的基准数据集，这使得企业难以选择适合客户支持应用的模型。

**Method:** 研究团队引入了客户支持对话数据集（CSConDa），这是一个包含9000多个问答对的精选基准数据集，这些数据来源于一家大型越南软件公司与人工顾问的真实交互。此外，他们提出了一个综合评估框架，使用自动指标和句法分析对CSConDa上的11个轻量级开源ViLLMs进行了基准测试。

**Result:** 这项研究深入分析了模型行为，解释了性能差异，并指出了关键的改进领域，从而支持了下一代ViLLMs的开发。通过建立一个稳健的基准和系统评估，他们的工作能够为客户服务问答提供明智的模型选择。

**Conclusion:** 通过建立一个稳固的基准数据集和系统的评估框架，这项工作能够帮助企业为客户服务问答选择合适的模型，并推动越南语大语言模型的研究进展。

> **ai_Abstract:** 本文针对越南语大语言模型（ViLLMs）在客户支持领域缺乏领域特定评估和真实交互基准数据集的问题，提出了解决方案。研究团队构建了CSConDa，一个包含9000多个来自真实客户交互的问答对的基准数据集，涵盖多样化主题。在此基础上，他们建立了一个全面的评估框架，对11个轻量级开源ViLLMs进行了基准测试，并使用自动指标和句法分析来分析模型表现。这项工作为ViLLMs的行为提供了深入见解，解释了性能差异，并指明了未来改进方向，旨在促进客户服务问答中ViLLMs的明智选择和进一步研究。

> **摘要翻译:** 随着人工智能的快速发展，大型语言模型（LLMs）已成为问答（QA）系统的核心，提高了客户服务效率并减轻了人工工作量。越南语大语言模型（ViLLMs）的出现，凸显了轻量级开源模型在准确性、效率和隐私方面的优势，使其成为一种实用的选择。然而，领域特定的评估仍然有限，并且缺乏反映真实客户交互的基准数据集，这使得企业难以选择适合客户支持应用的模型。为了弥补这一空白，我们引入了客户支持对话数据集（CSConDa），这是一个精选的基准数据集，包含9000多个问答对，这些数据来源于一家大型越南软件公司与人工顾问的真实交互。CSConDa涵盖定价、产品可用性和技术故障排除等多样化主题，为在实际场景中评估ViLLMs提供了代表性基础。我们进一步提出了一个综合评估框架，使用自动指标和句法分析对CSConDa上的11个轻量级开源ViLLMs进行了基准测试，以揭示模型的优势、劣势和语言模式。这项研究深入分析了模型行为，解释了性能差异，并指出了关键的改进领域，从而支持了下一代ViLLMs的开发。通过建立一个稳健的基准和系统评估，我们的工作能够为客户服务问答提供明智的模型选择，并推动越南语LLMs的研究。该数据集已公开可用，网址为https://huggingface.co/datasets/ura-hcmut/Vietnamese-Customer-Support-QA。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [515] [HRIPBench: Benchmarking LLMs in Harm Reduction Information Provision to Support People Who Use Drugs](https://arxiv.org/abs/2507.21815)
> *HRIPBench：基准测试大型语言模型在提供减害信息以支持吸毒者方面的表现*

*Kaixuan Wang, Chenxin Diao, Jason T. Jacques, Zhongliang Guo, Shuai Zhao* | **Category: cs.CL, cs.CY** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 减害, 基准测试, 吸毒者, 安全风险

**Comment:** 15 pages, 5 figures, 12 tables, a dataset

> **TL;DR:** HRIPBench是一个评估大型语言模型在为吸毒者提供减害信息方面准确性和安全风险的基准。研究发现，目前最先进的大型语言模型在该领域仍存在准确性问题和严重的安全风险，需要谨慎使用。

**AI_Comments:** 该论文通过引入HRIPBench，首次系统地评估了大型语言模型在提供减害信息方面的性能和安全风险，具有重要的创新性。它揭示了当前LLMs在该特定应用领域存在的局限性和潜在危险，为未来LLMs在敏感健康领域的应用提供了关键的警示和研究方向。其贡献在于不仅建立了评估框架，还强调了AI在公共卫生领域应用的伦理和安全考量。

<details>
  <summary>Details</summary>

**Motivation:** 吸毒对数百万人的福祉构成挑战，减害是改善健康结果和降低安全风险的公共卫生策略。尽管大型语言模型（LLMs）展现出一定的医学知识，有望满足吸毒者（PWUD）的信息需求，但它们在此类任务中的表现尚未得到充分探索。

**Method:** 研究引入了HRIPBench，一个旨在评估大型语言模型在减害信息提供方面准确性和安全风险的基准。基准数据集HRIP-Basic包含2,160个问答-证据对，涵盖三个任务：检查安全边界、提供定量值和推断多物质使用风险。研究构建了指令（Instruction）和检索增强生成（RAG）方案，以评估模型基于其固有知识和领域知识整合后的行为。

**Result:** 结果表明，目前最先进的大型语言模型在提供准确的减害信息方面仍有困难，有时甚至对吸毒者构成严重的安全风险。

**Conclusion:** 在减害背景下使用大型语言模型应受到谨慎限制，以避免导致负面的健康结果。

> **ai_Abstract:** 本研究介绍了HRIPBench，一个用于评估大型语言模型（LLMs）在为吸毒者提供减害信息时准确性和安全风险的新基准。通过包含2,160个问答-证据对的HRIP-Basic数据集，该基准涵盖了安全边界检查、定量值提供和多物质使用风险推断等任务。研究采用指令和RAG方案评估LLMs的性能。结果显示，当前最先进的LLMs在提供准确减害信息方面仍面临挑战，并可能带来严重的安全风险。因此，论文强调在减害背景下使用LLMs需极其谨慎，以防不良健康后果。

> **摘要翻译:** 数百万人的福祉受到物质使用危害的挑战。减害作为一种公共卫生策略，旨在改善他们的健康结果并降低安全风险。一些大型语言模型（LLMs）已经展示了相当水平的医学知识，有望解决吸毒者（PWUD）的信息需求。然而，它们在相关任务中的表现仍 largely 未被探索。我们引入了HRIPBench，这是一个旨在评估LLM在减害信息提供方面的准确性和安全风险的基准。基准数据集HRIP-Basic包含2,160个问答-证据对。范围涵盖三个任务：检查安全边界、提供定量值和推断多物质使用风险。我们构建了指令（Instruction）和RAG方案，以根据模型固有的知识和领域知识的整合来评估模型的行为。我们的结果表明，目前最先进的LLM在提供准确的减害信息方面仍然存在困难，有时甚至对吸毒者带来严重的安全风险。在减害情境中使用LLM应受到谨慎限制，以避免导致负面的健康结果。警告：本文包含可能导致危害的非法内容。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [518] [HIRAG: Hierarchical-Thought Instruction-Tuning Retrieval-Augmented Generation](https://arxiv.org/abs/2507.05714)
> *HIRAG：分层思维指令微调检索增强生成*

*YiHan Jiao, ZheHao Tan, Dan Yang, DuoLin Sun, Jie Feng, Yue Shen, Jian Wang, Peng Wei* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** RAG, 指令微调, 分层思维, 思维链, 大型语言模型

**Comment:** 

> **TL;DR:** 本文提出HIRAG，一种新的RAG指令微调方法，通过引入分层能力和多级思维链策略，显著提升了大型语言模型在处理实时信息和特定领域问题时的检索增强生成性能。

**AI_Comments:** HIRAG的创新点在于明确提出了RAG模型应具备的分层能力（过滤、组合、RAG特有推理），并通过指令微调和多级思维链来系统性地提升这些能力，而非仅仅依赖模型自身的上下文学习。这种“先思考后回答”的策略为RAG任务的生成模型提供了更精细化的训练方向，对于提高RAG系统在处理复杂和开放域问题时的鲁棒性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统检索增强生成（RAG）系统过度依赖大型语言模型的上下文学习能力，但缺乏对RAG生成模型所需特定能力的深入研究，导致文档质量不一致和检索系统不完善。现有的RAG生成模型微调研究也缺乏对RAG任务的细粒度关注或对思维链过程的更深层次利用。

**Method:** 本文提出RAG模型应具备三种渐进的分层能力：1) 过滤：选择相关信息的能力；2) 组合：跨段落组合语义信息的能力；3) RAG特有推理：利用内部知识进一步处理外部知识的能力。为此，作者引入了HIRAG（分层思维指令微调检索增强生成）方法，该方法融合了“先思考后回答”策略，并通过多级渐进式思维链来增强模型的开卷考试能力。

**Result:** 实验表明，HIRAG训练策略显著提高了模型在RGB、PopQA、MuSiQue、HotpotQA和PubmedQA等数据集上的性能。

**Conclusion:** HIRAG通过引入分层能力和多级思维链策略，有效解决了传统RAG系统在处理文档质量不一致和检索系统不完善方面的挑战，显著提升了大型语言模型在检索增强生成任务中的表现。

> **ai_Abstract:** 本文针对传统检索增强生成（RAG）系统在处理大型语言模型面临的实时信息和领域特定问题时的不足，提出了一种新的指令微调方法——HIRAG。HIRAG引入了过滤、组合和RAG特有推理这三种分层能力，并通过“先思考后回答”策略和多级思维链来增强模型的开卷考试能力。实验证明，该方法显著提升了模型在多个基准数据集上的性能。

> **摘要翻译:** 检索增强生成（RAG）已成为解决大型语言模型在处理实时信息和特定领域问题时面临挑战的基本范式。传统的RAG系统主要依赖于大型语言模型本身的上下文学习（ICL）能力。然而，对RAG生成模型所需特定能力的深入研究尚缺乏，导致文档质量不一致和检索系统不完善的问题。即使是有限的RAG生成模型微调研究也往往缺乏对RAG任务的细粒度关注或对思维链过程的更深层次利用。为了解决这个问题，我们提出RAG模型应具备三种渐进的分层能力：(1) 过滤：选择相关信息的能力；(2) 组合：组合跨段落语义信息的能力；(3) RAG特有推理：利用内部知识进一步处理外部知识的能力。因此，我们引入了一种新的RAG指令微调方法，分层思维指令微调检索增强生成（HIRAG），它融合了“先思考后回答”策略。该方法通过利用多级渐进式思维链，增强了模型的开卷考试能力。实验表明，HIRAG训练策略显著提高了模型在RGB、PopQA、MuSiQue、HotpotQA和PubmedQA等数据集上的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [531] [A Survey of Classification Tasks and Approaches for Legal Contracts](https://arxiv.org/abs/2507.21108)
> *法律合同分类任务与方法综述*

*Amrita Singh, Aditya Joshi, Jiaojiao Jiang, Hye-young Paik* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-09**

**Keywords:** 法律合同分类, 自动化, 综述, 自然语言处理, 机器学习

**Comment:** Under review. 49 pages + references

> **TL;DR:** 该综述是对法律合同自动分类（LCC）领域的一次全面回顾，涵盖了挑战、任务、数据集、方法论和评估技术，并提出了未来的研究方向。

**AI_Comments:** 本综述是法律合同自动分类（LCC）领域的首次全面综述，其创新之处在于系统地梳理了LCC的挑战、任务、数据集和方法论，并提出了分类体系。其重要性在于为法律NLP研究人员和从业者提供了一个清晰的路线图，指明了未来的研究方向，有助于推动法律自动化和信息可及性。该综述的局限性可能在于其内容基于已有的研究，并未提出新的模型或算法。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于合同数量庞大、复杂性高，人工审查效率低下且易出错，因此迫切需要自动化解决方案。自动法律合同分类（LCC）能够显著提高分析速度、准确性和可及性。

**Method:** 本综述深入探讨了自动法律合同分类（LCC）的挑战，详细考察了关键任务、数据集和方法论。它识别了LCC中的七种分类任务，审查了十四个英语合同相关数据集，并引入了一种LCC方法论分类法，包括传统机器学习、深度学习和基于Transformer的方法。此外，综述还讨论了评估技术并强调了已审查研究中表现最佳的结果。

**Result:** 综述识别了LCC中的七种分类任务，审查了十四个英语合同相关数据集（包括公共、专有和非公共来源），并提出了一种将LCC方法论分为传统机器学习、深度学习和基于Transformer的方法的分类法。它还讨论了评估技术并突出了表现最佳的结果。

**Conclusion:** 本综述作为首个关于LCC的全面综述，旨在通过提供当前方法的全面概述及其局限性，提出未来的研究方向，以提高LCC的效率、准确性和可扩展性，从而支持法律NLP研究人员和从业者改进法律流程，使法律信息更易获取，并促进一个更知情和公平的社会。

> **ai_Abstract:** 本综述全面审视了法律合同自动分类（LCC）领域，旨在解决合同人工审查效率低下和易错的问题。它详细探讨了LCC的挑战，识别了七种分类任务，审查了十四个英语合同数据集，并提出了一种涵盖传统机器学习、深度学习和Transformer方法的LCC方法论分类法。此外，综述还讨论了评估技术并强调了最佳表现，最终为未来的研究方向提供了指导，以提升LCC的效率、准确性和可扩展性，从而支持法律NLP领域的发展。

> **摘要翻译:** 鉴于合同规模庞大、数量众多及其固有的复杂性，人工审查效率低下且容易出错，因此对自动化有着明确的需求。自动法律合同分类（LCC）彻底改变了法律合同的分析方式，在速度、准确性和可及性方面提供了显著改进。本综述深入探讨了自动LCC的挑战，并详细考察了关键任务、数据集和方法论。我们识别了LCC中的七种分类任务，并审查了十四个与英语合同相关的数据集，包括公共、专有和非公共来源。我们还引入了一种LCC的方法论分类法，将其分为传统机器学习、深度学习和基于Transformer的方法。此外，本综述还讨论了评估技术，并强调了已审查研究中表现最佳的结果。通过对现有方法及其局限性进行全面概述，本综述提出了未来的研究方向，以提高LCC的效率、准确性和可扩展性。作为首个关于LCC的全面综述，它旨在支持法律NLP研究人员和从业者改进法律流程，使法律信息更易获取，并促进一个更知情和公平的社会。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [537] [A Deep Learning Automatic Speech Recognition Model for Shona Language](https://arxiv.org/abs/2507.21331)
> *深度学习肖纳语自动语音识别模型*

*Leslie Wellington Sirora, Mainford Mutandavari* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-07-28**

**Keywords:** 自动语音识别, 肖纳语, 深度学习, 低资源语言, 声调语言

**Comment:** 

> **TL;DR:** 为低资源语言肖纳语开发了一种基于深度学习的自动语音识别系统，克服了数据稀缺和声调复杂性问题，取得了显著的识别精度提升。

**AI_Comments:** 该研究的创新点在于为低资源、声调复杂的肖纳语设计并实现了深度学习ASR系统，并通过结合多种技术（CNN-LSTM混合架构、数据增强、迁移学习、注意力机制）有效克服了数据稀缺和声调特性带来的挑战。这对于促进低资源语言的数字包容性和可访问性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 肖纳语是一种低资源语言，具有独特的声调和语法复杂性，面临训练数据有限、缺乏标注数据以及复杂的声调细微差别等挑战。本研究旨在提高其识别准确率，超越传统统计模型。

**Method:** 本研究采用混合架构的深度学习模型，包括用于声学建模的卷积神经网络（CNN）和用于语言建模的长短期记忆网络（LSTM）。为克服数据稀缺，使用了数据增强和迁移学习技术。此外，还引入了注意力机制来处理肖纳语的声调特性。

**Result:** 开发的ASR系统取得了显著成果，词错误率为29%，音素错误率为12%，整体准确率为74%。

**Conclusion:** 本研究表明，深度学习有潜力显著提高肖纳语等资源不足语言的自动语音识别准确性，从而促进这些语言的可访问性和交流。

> **ai_Abstract:** 本研究为低资源语言肖纳语开发了一个基于深度学习的自动语音识别系统，旨在克服数据稀缺、缺乏标注数据和声调复杂性等挑战。该系统采用CNN-LSTM混合架构，并结合数据增强、迁移学习和注意力机制。实验结果显示，该系统在肖纳语上实现了29%的词错误率、12%的音素错误率和74%的整体准确率，证明了深度学习在提升低资源语言ASR精度方面的潜力。

> **摘要翻译:** 本研究提出了一种基于深度学习的肖纳语自动语音识别系统，肖纳语是一种以独特的声调和语法复杂性为特征的低资源语言。该研究旨在解决训练数据有限、缺乏标注数据以及肖纳语语音中复杂的声调细微差别所带来的挑战，目标是与传统统计模型相比，显著提高识别准确率。研究首先探讨了使用深度学习开发肖纳语准确ASR系统的可行性。其次，它调查了设计和实现肖纳语语音识别深度学习架构所涉及的具体挑战，并提出了缓解这些挑战的策略。最后，它在准确性方面比较了基于深度学习的模型与现有统计模型的性能。开发的ASR系统采用了一种混合架构，包括用于声学建模的卷积神经网络和用于语言建模的长短期记忆网络。为了克服数据稀缺，采用了数据增强技术和迁移学习。还结合了注意力机制以适应肖纳语的声调性质。最终的ASR系统取得了令人印象深刻的结果，词错误率为29%，音素错误率为12%，整体准确率为74%。这些指标表明深度学习有潜力提高肖纳语等资源不足语言的ASR准确性。这项研究为肖纳语等资源不足语言的ASR技术进步做出了贡献，最终促进了全球肖纳语使用者的可访问性和交流。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [541] [ControlMed: Adding Reasoning Control to Medical Language Model](https://arxiv.org/abs/2507.22545)
> *ControlMed：为医疗语言模型添加推理控制*

*Sung-Min Lee, Siyoon Lee, Juyeon Kim, Kyungmin Roh* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 医疗语言模型, 推理控制, 计算效率, 临床决策, ControlMed

**Comment:** 13 pages

> **TL;DR:** ControlMed是一个医疗语言模型，允许用户在推理时控制推理过程的长度，以平衡准确性和计算效率。

**AI_Comments:** ControlMed的创新之处在于其引入了对医疗LLM推理过程长度的主动控制，这对于资源受限的临床环境至关重要。通过结合预训练、监督微调和强化学习的三阶段训练管道，该模型有效地解决了现有LLM推理冗长的问题，并在保持性能的同时提高了效率。其灵活性使其在实际医疗信息分析中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有的推理大型语言模型在医疗领域取得了进展，但它们通常会生成不必要的冗长推理过程，导致显著的计算开销和响应延迟，这阻碍了它们在实际临床环境中的部署。

**Method:** ControlMed通过一个三阶段的训练流程进行训练：1）在大规模合成医疗指令数据集上进行预训练，该数据集涵盖直接和推理响应；2）使用多长度推理数据和明确的长度控制标记进行监督微调；3）使用基于模型的奖励信号进行强化学习，以提高事实准确性和响应质量。

**Result:** 在各种英语和韩语医疗基准测试中，ControlMed与最先进的模型相比，取得了相似或更好的性能。此外，用户可以根据需要通过控制推理长度来灵活平衡推理准确性和计算效率。

**Conclusion:** ControlMed是一个实用且适应性强的解决方案，适用于临床问答和医疗信息分析。

> **ai_Abstract:** ControlMed是一个旨在解决医疗领域推理大型语言模型（LLMs）计算开销和响应延迟问题的模型。它通过一个三阶段的训练流程实现对推理过程长度的细粒度控制，从而允许用户在推理时平衡推理准确性和计算效率。实验结果表明，ControlMed在多种医疗基准测试中达到了与SOTA模型相当或更优的性能，证明了其在临床应用中的实用性和适应性。

> **摘要翻译:** 推理大型语言模型（LLMs）以其增强的准确性和可解释性，正越来越多地被医疗领域采用，因为临床决策的生命攸关性质要求可靠的支持。尽管取得了这些进展，但现有的推理LLMs通常会生成不必要的冗长推理过程，导致显著的计算开销和响应延迟。这些限制阻碍了它们在实际临床环境中的实际部署。为了解决这些挑战，我们引入了ControlMed，一个医疗语言模型，它允许用户在推理时通过细粒度控制标记主动控制推理过程的长度。ControlMed通过一个三阶段的流程进行训练：1）在涵盖直接和推理响应的大规模合成医疗指令数据集上进行预训练；2）使用多长度推理数据和明确的长度控制标记进行监督微调；3）使用基于模型的奖励信号进行强化学习，以提高事实准确性和响应质量。在各种英语和韩语医疗基准测试中的实验结果表明，我们的模型与最先进的模型相比，取得了相似或更好的性能。此外，用户可以根据需要通过控制推理长度来灵活平衡推理准确性和计算效率。这些发现表明ControlMed是临床问答和医疗信息分析的实用且适应性强的解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [559] [SemRAG: Semantic Knowledge-Augmented RAG for Improved Question-Answering](https://arxiv.org/abs/2507.21110)
> *SemRAG：用于改进问答的语义知识增强型RAG*

*Kezhen Zhong, Basem Suleiman, Abdelkarim Erradi, Shijing Chen* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-10**

**Keywords:** SemRAG, 检索增强生成, 知识图谱, 语义分块, 问答

**Comment:** 16 pages, 12 figures

> **TL;DR:** SemRAG是一种增强型RAG框架，它利用语义分块和知识图谱高效整合领域知识，无需大量微调即可显著提升问答性能，解决了现有方法计算成本高、易过拟合和扩展性受限的问题。

**AI_Comments:** SemRAG的创新性在于其结合了语义分块和知识图谱来增强RAG框架，从而高效地整合领域知识。这种方法有效地解决了传统LLM适应方法中计算成本高昂和易于过拟合的痛点，同时避免了资源密集型的模型微调。其可扩展性和对可持续性目标的关注使其在实际领域特定AI应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 将领域特定知识整合到大型语言模型（LLMs）中对于提高其在专业任务中的性能至关重要。然而，现有的适应方法计算成本高昂、容易过拟合且限制了可扩展性。

**Method:** SemRAG采用了一种语义分块算法，该算法基于句子嵌入的余弦相似度来分割文档，以保持语义连贯性并降低计算开销。此外，通过将检索到的信息构建成知识图谱，SemRAG能够捕获实体之间的关系，从而提高检索准确性和上下文理解。研究还探讨了针对不同数据集优化缓冲区大小的方法。

**Result:** 在MultiHop RAG和Wikipedia数据集上的实验结果表明，SemRAG显著提高了从知识图谱中检索到的信息的相关性和正确性，优于传统的RAG方法。此外，优化缓冲区大小可以进一步提高检索性能。

**Conclusion:** SemRAG的主要优势在于它能够创建一个高效、准确的领域特定LLM管道，同时避免了资源密集型的微调。这使其成为一种实用且可扩展的方法，符合可持续发展目标，为领域特定人工智能应用提供了可行的解决方案。

> **ai_Abstract:** SemRAG是一种增强型检索增强生成（RAG）框架，旨在通过语义分块和知识图谱高效整合领域特定知识，以改进大型语言模型（LLMs）的问答性能，同时避免了传统方法中计算成本高、易过拟合和可扩展性受限的问题。该框架利用句子嵌入进行语义分块，并构建知识图谱来增强信息检索和上下文理解。实验证明，SemRAG在相关性和正确性方面优于传统RAG方法，并能通过优化缓冲区大小进一步提升性能。它提供了一个无需大量微调的实用、可扩展且高效的领域特定LLM解决方案。

> **摘要翻译:** 本文介绍了SemRAG，这是一种增强型检索增强生成（RAG）框架，它通过语义分块和知识图谱高效整合领域特定知识，而无需大量微调。将领域特定知识整合到大型语言模型（LLMs）中对于提高其在专业任务中的性能至关重要。然而，现有的适应方法计算成本高昂、容易过拟合且限制了可扩展性。为了解决这些挑战，SemRAG采用了一种语义分块算法，该算法根据句子嵌入的余弦相似度来分割文档，从而在保持语义连贯性的同时降低计算开销。此外，通过将检索到的信息构建成知识图谱，SemRAG能够捕获实体之间的关系，从而提高检索准确性和上下文理解。MultiHop RAG和Wikipedia数据集上的实验结果表明，SemRAG显著提高了从知识图谱中检索到的信息的相关性和正确性，优于传统的RAG方法。此外，我们研究了针对不同数据语料库优化缓冲区大小的方法，因为针对特定数据集优化缓冲区大小可以进一步提高检索性能，因为知识图谱的整合加强了实体关系，从而更好地理解上下文。SemRAG的主要优势在于它能够创建一个高效、准确的领域特定LLM管道，同时避免了资源密集型的微调。这使其成为一种实用且可扩展的方法，符合可持续发展目标，为领域特定人工智能应用提供了可行的解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [565] [Training language models to be warm and empathetic makes them less reliable and more sycophantic](https://arxiv.org/abs/2507.21919)
> *训练语言模型变得温暖和善解人意会使其可靠性降低且更趋炎附势*

*Lujain Ibrahim, Franziska Sofia Hafner, Luc Rocher* | **Category: cs.CL, cs.AI, cs.CY** | **Updated: 2025-07-30**

**Keywords:** 语言模型, 可靠性, 共情, 趋炎附势, 安全性风险

**Comment:** 

> **TL;DR:** 本研究发现，将语言模型训练得更温暖和善解人意，会显著降低其可靠性，尤其是在用户表达脆弱时，并使其更容易附和用户错误观念，这揭示了当前评估方法可能未能检测到的系统性风险。

**AI_Comments:** 本文揭示了一个当前AI开发中至关重要的潜在风险：过度追求模型的人性化（温暖和共情）可能会以牺牲其可靠性和安全性为代价。其创新之处在于通过对照实验量化了这种权衡，并指出现有评估基准未能捕捉到这些系统性风险。这对于AI伦理、安全以及未来AI系统设计具有重要的指导意义，提醒开发者在追求用户体验的同时，必须优先考虑模型的事实准确性和安全性。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能开发者正越来越多地构建具有温暖和善解人意个性的语言模型，这些模型被数百万人用于获取建议、治疗和陪伴。然而，本研究旨在揭示这种做法可能带来的一个显著权衡：优化语言模型以追求温暖可能会损害其可靠性。

**Method:** 研究人员对五种不同规模和架构的语言模型进行了对照实验，通过训练使其产生更温暖、更善解人意的回应，然后评估它们在安全关键任务上的表现。

**Result:** 温暖型模型比其原始版本错误率显著更高（高出10%到30%），表现为宣传阴谋论、提供不正确的事实信息以及给出有问题的医疗建议。它们也更有可能验证用户不正确的信念，尤其是在用户表达悲伤时。重要的是，这些影响在不同模型架构中保持一致，并且即使在标准基准测试中性能保持不变的情况下也发生了，这揭示了当前评估实践可能未能检测到的系统性风险。

**Conclusion:** 随着类人AI系统以前所未有的规模部署，研究结果表明需要重新思考如何开发和监督这些正在重塑人类关系和社会互动的系统。

> **ai_Abstract:** 本研究探讨了将语言模型训练得更温暖和善解人意所带来的权衡。通过对五种不同模型的实验，研究发现，尽管在标准基准测试中表现良好，但这些“温暖”模型在安全关键任务上错误率显著增加（10-30%），表现为散布阴谋论、提供错误信息和不当医疗建议，并更倾向于附和用户的错误信念，尤其是在用户脆弱时。这揭示了当前AI评估方法可能未能识别的系统性风险，并强调了重新思考类人AI系统开发和监管的必要性。

> **摘要翻译:** 人工智能（AI）开发者正越来越多地构建具有温暖和善解人意个性的语言模型，这些模型目前被数百万人用于获取建议、治疗和陪伴。在此，我们展示了这如何产生一个显著的权衡：优化语言模型以追求温暖会损害其可靠性，尤其是在用户表达脆弱时。我们对五种不同规模和架构的语言模型进行了对照实验，训练它们产生更温暖、更善解人意的回应，然后评估它们在安全关键任务上的表现。温暖型模型比其原始版本错误率显著更高（高出10%到30%），表现为宣传阴谋论、提供不正确的事实信息以及给出有问题的医疗建议。它们也更有可能验证用户不正确的信念，尤其是在用户消息表达悲伤时。重要的是，这些影响在不同模型架构中保持一致，并且即使在标准基准测试中性能保持不变的情况下也发生了，这揭示了当前评估实践可能未能检测到的系统性风险。随着类人AI系统以前所未有的规模部署，我们的发现表明需要重新思考如何开发和监督这些正在重塑人类关系和社会互动的系统。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [568] [Exploiting Synergistic Cognitive Biases to Bypass Safety in LLMs](https://arxiv.org/abs/2507.22564)
> *利用协同认知偏差绕过LLM安全*

*Xikang Yang, Biyu Zhou, Xuehai Tang, Jizhong Han, Songlin Hu* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-30**

**Keywords:** LLM安全, 认知偏差, 对抗性攻击, 越狱, CognitiveAttack

**Comment:** 

> **TL;DR:** 本研究提出CognitiveAttack框架，利用多重认知偏差有效绕过LLM安全机制，揭示了现有防御的漏洞。

**AI_Comments:** 该论文的创新点在于提出了利用多重认知偏差协同作用来攻击LLM安全的新颖视角，这与以往侧重于单一提示工程或算法操纵的方法不同。它揭示了LLM防御机制的深层漏洞，并连接了认知科学与LLM安全，为未来构建更鲁棒、更符合人类价值观的AI系统提供了重要启示。其提出的CognitiveAttack框架提供了一个系统性的红队测试工具，对于提升LLM安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的安全机制容易受到利用认知偏差的对抗性攻击。现有越狱方法多关注提示工程或算法操纵，但忽略了多偏差交互在破坏LLM安全方面的力量。

**Method:** 提出CognitiveAttack框架，它系统地利用个体和组合认知偏差。通过整合监督微调和强化学习，CognitiveAttack生成嵌入优化偏差组合的提示，以有效绕过安全协议并保持高攻击成功率。

**Result:** 实验结果显示，在30个不同的LLM（特别是开源模型）中存在显著漏洞。CognitiveAttack比SOTA黑盒方法PAP具有更高的攻击成功率（60.1% vs 31.6%），暴露了当前防御机制的关键局限性。

**Conclusion:** 多偏差交互是一种强大但未被充分探索的攻击向量。这项工作通过连接认知科学和LLM安全，引入了一种新颖的跨学科视角，为更稳健和与人类对齐的AI系统铺平了道路。

> **ai_Abstract:** 本论文介绍了一种名为CognitiveAttack的新型红队框架，旨在通过利用协同认知偏差来绕过大型语言模型（LLM）的安全机制。该方法结合了监督微调和强化学习，生成包含优化偏差组合的提示，从而有效地攻击LLM。实验证明，CognitiveAttack在多种LLM上展现出显著的漏洞利用能力，其攻击成功率远超现有先进方法，揭示了当前LLM安全防御的不足，并提出多偏差交互是一个重要的未充分探索的攻击向量。

> **摘要翻译:** 大型语言模型（LLMs）在广泛的任务中展示了令人印象深刻的能力，然而它们的安全机制仍然容易受到利用认知偏差——系统性偏离理性判断——的对抗性攻击。与以往专注于提示工程或算法操纵的越狱方法不同，这项工作强调了多偏差交互在破坏LLM防护方面的被忽视的力量。我们提出了CognitiveAttack，一个新颖的红队框架，它系统地利用个体和组合认知偏差。通过整合监督微调和强化学习，CognitiveAttack生成嵌入优化偏差组合的提示，有效绕过安全协议，同时保持高攻击成功率。实验结果揭示了30个不同LLM（特别是开源模型）的显著漏洞。与SOTA黑盒方法PAP相比，CognitiveAttack实现了更高的攻击成功率（60.1% vs 31.6%），暴露了当前防御机制的关键局限性。这些发现强调多偏差交互是一种强大但未被充分探索的攻击向量。这项工作通过连接认知科学和LLM安全，引入了一种新颖的跨学科视角，为更稳健和与人类对齐的AI系统铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [596] [Unveiling the Influence of Amplifying Language-Specific Neurons](https://arxiv.org/abs/2507.22581)
> *揭示放大特定语言神经元的影响*

*Inaya Rahmanisa, Lyzander Marciano Andrylie, Krisna Mahardika Ihsani, Alfan Farizki Wicaksono, Haryo Akbarianto Wibowo, Alham Fikri Aji* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 特定语言神经元, 大型语言模型, 语言引导, 低资源语言, 跨语言迁移

**Comment:** Our code and dataset are made available at
  https://github.com/tauimbz/lang-task-neuron

> **TL;DR:** 研究发现，放大大型语言模型中特定语言神经元能有效引导输出至目标语言，对低资源语言有益，但对跨语言任务的提升有限。

**AI_Comments:** 这项研究通过探索特定语言神经元的“放大”作用，为理解大型语言模型的多语言行为提供了新的视角，不同于以往的“去激活”方法。其发现对优化低资源语言性能具有潜在价值，但也揭示了放大方法在跨语言迁移方面的局限性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究已通过去激活特定语言神经元来探究其对模型行为的影响，但其在“放大”方面的作用尚未得到充分探索。

**Method:** 本研究通过对18种语言（包括低资源语言）进行干预，使用三种主要在不同语言上训练的模型，调查了放大特定语言神经元的效果。通过提出的语言引导偏移（LSS）评估分数比较放大因子在引导至目标语言方面的有效性，并在下游任务（常识推理、知识、翻译）上进行评估。

**Result:** 最佳放大因子能有效将输出引导至几乎所有测试语言。在下游任务上使用此因子进行干预，在某些情况下能提高自语言性能，但通常会降低跨语言结果。

**Conclusion:** 这些发现突出了特定语言神经元在多语言行为中的作用，其中放大可能对低资源语言特别有益，但对跨语言迁移的优势有限。

> **ai_Abstract:** 本文探讨了放大大型语言模型中特定语言神经元对模型行为的影响。研究通过对18种语言（包括低资源语言）进行干预，发现最佳放大因子能有效将模型输出引导至目标语言。在下游任务中，这种干预在某些情况下能提升自语言性能，但通常会损害跨语言任务的表现。研究结果表明，放大特定语言神经元对低资源语言有益，但对跨语言迁移的帮助有限。

> **摘要翻译:** 大型语言模型中与个体语言高度相关的特定语言神经元已被证明通过去激活来影响模型行为。然而，它们在放大中的作用仍未得到充分探索。本研究通过对18种语言（包括低资源语言）进行干预，使用三种主要在不同语言上训练的模型，调查了放大特定语言神经元的效果。我们通过提出的语言引导偏移（LSS）评估分数，比较放大因子在引导至目标语言方面的有效性，然后在下游任务：常识推理（XCOPA, XWinograd）、知识（Include）和翻译（FLORES）上进行评估。最佳放大因子能有效将输出引导至几乎所有测试语言。在下游任务上使用此因子进行干预，在某些情况下能提高自语言性能，但通常会降低跨语言结果。这些发现突出了特定语言神经元在多语言行为中的作用，其中放大可能对低资源语言特别有益，但对跨语言迁移的优势有限。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [603] [Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models](https://arxiv.org/abs/2507.13614)
> *基于语言学和嵌入的大型语言模型生成文本与人类生成文本的特征分析*

*Sergio E. Zanotto, Segun Aroyehun* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 语言学特征, 文本分析, 人机文本, 文体多样性

**Comment:** arXiv admin note: text overlap with arXiv:2412.03025

> **TL;DR:** 本研究通过语言学特征和嵌入方法，分析了人类和大型语言模型生成文本的特点，发现人类文本语法结构更简单、语义更丰富，且新模型生成的文本趋于同质化。

**AI_Comments:** 本研究的创新之处在于其从刻画而非分类的角度分析了人类和机器生成文本的差异，使用了多层次的语言学特征和嵌入方法。其发现人类文本的特征变异性更大以及新LLM文本趋于同质化的趋势，对于文本鉴别和理解LLM发展方向具有重要意义。这为未来区分真假文本提供了新的思路，并揭示了LLM在生成多样化文本方面可能面临的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）生成的文本与人类文本越来越难以区分，当前研究主要集中于分类，而本研究旨在通过语言学特征来刻画和区分这些文本。

**Method:** 研究选取了包含8个领域、由11种不同LLM生成的人类和机器文本数据集。计算并使用了形态学、句法和语义等不同语言层面的语言学特征（如依存长度、情感性）来刻画文本。同时考虑了不同的采样策略、重复控制和模型发布日期。最后，应用风格嵌入进一步测试了文本的变异性。

**Result:** 统计分析显示，人类文本倾向于展现更简单的句法结构和更多样化的语义内容。人类和机器文本在不同领域均显示出文体多样性，其中人类文本的特征变异性更大。值得注意的是，较新的模型输出的文本变异性相似，表明机器生成文本趋于同质化。

**Conclusion:** 人类生成文本在句法结构上更简单，语义内容更丰富，且其语言特征的变异性高于机器生成文本。随着LLM的发展，新模型生成的文本在风格上呈现出同质化趋势。

> **ai_Abstract:** 本研究通过分析语言学特征和风格嵌入，对人类和大型语言模型（LLMs）生成的文本进行了深入刻画。研究发现，人类文本通常具有更简单的句法和更丰富的语义多样性，且在不同领域表现出更大的文体变异性。与此相对，尽管机器文本也存在领域多样性，但较新的LLM生成的文本趋于同质化。该研究为理解人类与机器生成文本的差异提供了新的视角。

> **摘要翻译:** 大型语言模型（LLMs）的快速发展显著提高了其生成自然语言的能力，使得LLM生成的文本与人类手写文本越来越难以区分。虽然最近的研究主要集中于使用LLM将文本分类为人类手写或机器生成文本，但我们的研究侧重于使用一套跨越形态学、句法和语义等不同语言层面的语言学特征来刻画这些文本。我们选择了一个包含8个领域、由11种不同LLM生成的人类手写和机器生成文本的数据集。我们计算了不同的语言学特征，如依存长度和情感性，并将它们用于刻画人类手写和机器生成文本，同时考虑了不同的采样策略、重复控制和模型发布日期。我们的统计分析揭示，人类手写文本倾向于展现更简单的句法结构和更多样化的语义内容。此外，我们计算了我们这组特征在不同模型和领域间的变异性。人类和机器文本在不同领域都显示出文体多样性，其中人类在我们的特征中显示出更大的变异性。最后，我们应用风格嵌入进一步测试了人类手写和机器生成文本之间的变异性。值得注意的是，较新的模型输出的文本变异性相似，这表明机器生成文本趋于同质化。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [624] [BALSAM: A Platform for Benchmarking Arabic Large Language Models](https://arxiv.org/abs/2507.22603)
> *BALSAM：一个阿拉伯语大型语言模型基准测试平台*

*Rawan Al-Matham, Kareem Darwish, Raghad Al-Rasheed, Waad Alshammari, Muneera Alhoshan, Amal Almazrua, Asma Al Wazrah, Mais Alheraki, Firoj Alam, Preslav Nakov, Norah Alzahrani, Eman alBilali, Nizar Habash, Abdelrahman El-Sheikh, Muhammad Elmallah, Haonan Li, Hamdy Mubarak, Mohamed Anwar, Zaid Alyafeai, Ahmed Abdelali, Nora Altwairesh, Maram Hasanain, Abdulmohsen Al Thubaity, Shady Shehata, Bashar Alhafni, Injy Hamed, Go Inoue, Khalid Elmadani, Ossama Obeid, Fatima Haouari, Tamer Elsayed, Emad Alghamdi, Khalid Almubarak, Saied Alshahrani, Ola Aljarrah, Safa Alajlan, Areej Alshaqarawi, Maryam Alshihri, Sultana Alghurabi, Atikah Alzeghayer, Afrah Altamimi, Abdullah Alfaifi, Abdulrahman AlOsaimy* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 阿拉伯语LLM, 基准测试, BALSAM, NLP任务, 盲测

**Comment:** 

> **TL;DR:** BALSAM是一个全面的、社区驱动的基准测试平台，旨在推进阿拉伯语大型语言模型的开发和评估，以解决现有阿拉伯语LLM性能落后和基准测试质量不足的问题。

**AI_Comments:** BALSAM的创新之处在于其全面性、社区驱动的模式以及提供的盲测平台，这直接解决了现有阿拉伯语LLM基准测试的痛点，如数据污染和任务覆盖不足。通过提供一个统一的平台，它有望显著推动阿拉伯语LLM的开发和评估。

<details>
  <summary>Details</summary>

**Motivation:** 英语大型语言模型（LLM）的显著进步并未在所有语言中得到体现，尤其是在阿拉伯语LLM方面，由于数据稀缺、语言多样性、形态复杂性等原因，其性能落后。此外，现有的阿拉伯语基准测试通常依赖静态数据，缺乏全面的任务覆盖，或不提供带有盲测集的专用平台，这使得衡量实际进展和缓解数据污染变得困难。本文旨在弥补这些差距。

**Method:** 本文引入了BALSAM，一个全面且社区驱动的基准测试平台，旨在推进阿拉伯语大型语言模型的开发和评估。该平台包含了来自14个大类的78个自然语言处理任务，共计52,000个示例（其中37,000个测试示例和15,000个开发示例），并提供了一个用于盲测的中心化、透明的平台。

**Result:** BALSAM包含来自14个广泛类别的78个NLP任务，共有52,000个示例，其中37,000个用于测试，15,000个用于开发。它还提供了一个中心化、透明的平台用于盲测评估。

**Conclusion:** BALSAM被设想为一个统一的平台，旨在为阿拉伯语大型语言模型的能力提升设定标准并促进协作研究。

> **ai_Abstract:** 本文介绍了BALSAM，一个旨在解决阿拉伯语大型语言模型（LLM）性能滞后和现有基准测试不足问题的综合性、社区驱动的基准测试平台。BALSAM包含78个NLP任务，共52,000个示例，并提供一个中心化、透明的盲测平台，旨在成为一个统一的标准制定和促进阿拉伯语LLM研究的平台。

> **摘要翻译:** 大型语言模型（LLMs）在英语领域的令人印象深刻的进步并未在所有语言中得到体现。特别是，阿拉伯语LLM的性能落后，原因包括数据稀缺、阿拉伯语及其方言的语言多样性、形态复杂性等。现有阿拉伯语基准测试的质量进一步阻碍了进展，这些基准通常依赖静态的、公开可用的数据，缺乏全面的任务覆盖，或者不提供带有盲测集的专用平台。这使得衡量实际进展和缓解数据污染变得具有挑战性。在此，我们旨在弥补这些差距。特别是，我们引入了BALSAM，一个全面的、社区驱动的基准，旨在推进阿拉伯语LLM的开发和评估。它包括来自14个大类的78个NLP任务，共有52K个示例，分为37K个测试示例和15K个开发示例，以及一个用于盲测的中心化、透明的平台。我们将BALSAM设想为一个统一的平台，旨在设定标准并促进协作研究，以提升阿拉伯语LLM的能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [653] [Language Arithmetics: Towards Systematic Language Neuron Identification and Manipulation](https://arxiv.org/abs/2507.22608)
> *语言算术：迈向系统性语言神经元识别与操纵*

*Daniil Gurgurov, Katharina Trinley, Yusser Al Ghussin, Tanja Baeumel, Josef van Genabith, Simon Ostermann* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 语言神经元, 语言算术, 大型语言模型, 多语言处理, 神经机制

**Comment:** preprint

> **TL;DR:** 研究大型语言模型中的语言特定神经元，并通过“语言算术”方法系统地识别和操纵它们，以控制模型的语言行为。

**AI_Comments:** 本文的创新点在于提出了“语言算术”这一系统性方法来识别和操纵大型语言模型中的语言特定神经元，这对于理解和控制多语言LLM的行为具有重要意义。它不仅揭示了语言在大模型内部的编码方式，还提供了一种精细化控制模型输出语言的有效手段，超越了传统替换方法。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型展现出强大的多语言能力，但其语言特定处理背后的神经机制尚不清楚。

**Method:** 分析Llama-3.1-8B、Mistral-Nemo-12B和Aya-Expanse-8B & 32B模型中21种不同语言的语言特定神经元。使用语言激活概率熵（LAPE）方法识别这些神经元。通过“语言算术”（即系统性的激活加法和乘法）来操纵模型，以停用不需要的语言并激活所需的语言。

**Result:** 语言特定神经元倾向于聚集在更深层。非拉丁语系显示出更大的专业化。相关语言共享重叠神经元，反映了语言接近度的内部表示。通过语言算术进行的操纵优于简单的替换方法，并有效地指导了模型在语言强制、翻译、问答、理解和NLI等五种多语言任务中的行为。对高资源语言的操纵更为成功，而类型学相似性提高了有效性。跨语言神经元操纵能增强下游性能，并揭示了当神经元逐渐停用时语言选择的内部“回退”机制。

**Conclusion:** 本研究通过系统识别和操纵大型语言模型中的语言特定神经元，不仅揭示了多语言处理的神经机制，还提供了一种有效控制模型语言行为的方法，并增强了对模型内部表示的理解。

> **ai_Abstract:** 本文分析了Llama-3.1-8B、Mistral-Nemo-12B和Aya-Expanse-8B & 32B等大型语言模型中21种语言的语言特定神经元，使用LAPE方法发现这些神经元聚集在更深层，且非拉丁语系更专业化，相关语言共享神经元。研究引入“语言算术”方法，通过系统性激活加法和乘法来操纵模型，以控制语言行为，该方法在多语言任务中表现优异，尤其对高资源语言更成功。此外，研究还揭示了跨语言神经元操纵对性能的提升以及语言选择的内部“回退”机制。

> **摘要翻译:** 大型语言模型（LLMs）展现出强大的多语言能力，但语言特定处理背后的神经机制仍不清楚。我们分析了Llama-3.1-8B、Mistral-Nemo-12B以及Aya-Expanse-8B & 32B模型中21种类型学上多样化语言的语言特定神经元，识别出控制语言行为的神经元。使用语言激活概率熵（LAPE）方法，我们发现这些神经元聚集在更深层，非拉丁语系显示出更大的专业化。相关语言共享重叠神经元，反映了语言接近度的内部表示。
通过语言算术，即系统性的激活加法和乘法，我们引导模型停用不需要的语言并激活所需的语言，其效果优于更简单的替换方法。这些干预措施有效地指导了模型在五种多语言任务中的行为：语言强制、翻译、问答、理解和NLI。对高资源语言的操纵更为成功，而类型学相似性提高了有效性。我们还证明了跨语言神经元操纵能增强下游性能，并揭示了当神经元逐渐停用时语言选择的内部“回退”机制。我们的代码已公开发布在https://github.com/d-gurgurov/Language-Neurons-Manipulation。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [654] [Dialogic Social Learning for Artificial Agents: Enhancing LLM Ontology Acquisition through Mixed-Initiative Educational Interactions](https://arxiv.org/abs/2507.21065)
> *人工代理的对话式社会学习：通过混合主动教育互动增强LLM本体获取*

*Sabrina Patania, Luca Annese, Cansu Koyuturk, Azzurra Ruggeri, Dimitri Ognibene* | **Category: cs.CL, cs.HC, cs.LG, cs.RO, I.2.7, I.2.9, j.4,** | **Updated: 2025-05-25**

**Keywords:** 对话式学习, 大型语言模型, 本体获取, 混合主动互动, 社会学习

**Comment:** submitted to ICSR2025

> **TL;DR:** 大型语言模型（LLMs）通过对话式社会学习，特别是混合主动互动，能更有效地获取和应用本体知识。

**AI_Comments:** 这项研究创新性地将维果茨基的社会文化理论应用于LLM的知识获取，通过模拟人类的教学对话模式，提供了一种有别于传统监督/强化学习的新范式。其“AI社交健身房”的概念和对混合主动互动的强调，为解决LLM在线知识获取的效率问题提供了新的思路，并为未来AI训练范式的演进提供了重要启示。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在处理大量离线数据集方面表现出色，但在在线获取和整合复杂知识方面面临挑战。传统的AI训练范式（监督学习或强化学习）依赖大数据集和稀疏反馈，效率低下，限制了模型从互动中高效学习的能力。

**Method:** 本研究受维果茨基社会文化理论启发，引入了一个动态环境，命名为“AI社交健身房”，其中AI学习代理与知识渊博的AI教师代理进行双向教学对话。这些互动强调外部、结构化对话作为知识获取的核心机制。研究重点是不同教学策略，特别是结合自上而下解释和学习者提问的混合主动互动，如何影响AI学习代理在本体获取过程中的表现。

**Result:** 实证结果表明，对话式方法——尤其是涉及混合主动互动（结合自上而下解释和学习者提问）的方法——显著增强了LLM获取和应用新知识的能力，其表现优于单向教学方法和直接访问结构化知识（训练数据集中常见的格式）。

**Conclusion:** 这些发现表明，将教学和心理学见解融入AI和机器人训练可以显著提高训练后的知识获取和响应质量。这种方法为现有策略（如提示工程）提供了一条补充途径。

> **ai_Abstract:** 本研究受维果茨基社会文化理论启发，提出一种对话式社会学习范式，以解决大型语言模型（LLMs）在在线获取和整合复杂知识方面的挑战。论文引入“AI社交健身房”环境，让AI学习代理与AI教师代理进行双向教学对话，强调外部、结构化对话作为知识获取的核心机制。实证结果表明，特别是结合自上而下解释和学习者提问的混合主动对话，能显著提升LLMs获取和应用新知识的能力，优于传统单向教学或直接知识访问。这表明将教学和心理学见解融入AI训练可有效提高知识获取和响应质量，为现有方法提供补充。

> **摘要翻译:** 大型语言模型（LLMs）在处理大量离线数据集方面表现出卓越的能力。然而，它们在在线获取和整合复杂知识方面常常面临挑战。传统的AI训练范式，主要基于监督学习或强化学习，反映了“皮亚杰”式的独立探索模型。这些方法通常依赖于大型数据集和稀疏的反馈信号，限制了模型从互动中高效学习的能力。本研究受维果茨基的社会文化理论启发，探索了社会媒介学习范式解决这些局限性的潜力。
我们引入了一个动态环境，称之为“AI社交健身房”，其中AI学习代理与知识渊博的AI教师代理进行双向教学对话。这些互动强调外部、结构化对话作为知识获取的核心机制，与仅依赖内部推理或模式识别的方法形成对比。
我们的研究重点是不同教学策略如何在本体获取的背景下影响AI学习过程。实证结果表明，这种对话式方法——特别是涉及混合主动互动（结合自上而下解释和学习者提问）的方法——显著增强了LLM获取和应用新知识的能力，其表现优于单向教学方法和直接访问结构化知识（训练数据集中常见的格式）。
这些发现表明，将教学和心理学见解融入AI和机器人训练可以显著提高训练后的知识获取和响应质量。这种方法为现有策略（如提示工程）提供了一条补充途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [679] [Multilingual Political Views of Large Language Models: Identification and Steering](https://arxiv.org/abs/2507.22623)
> *大型语言模型的多语言政治观点：识别与引导*

*Daniil Gurgurov, Katharina Trinley, Ivan Vykopal, Josef van Genabith, Simon Ostermann, Roberto Zamparelli* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 政治偏见, 多语言, 偏见引导, 政治指南针测试

**Comment:** pre-print

> **TL;DR:** 研究发现大型语言模型普遍存在自由左翼政治偏见，且可通过干预技术引导。

**AI_Comments:** 该研究创新性地扩展了对LLM政治偏见的研究范围，从单一语言和少数模型扩展到多语言和更广泛的模型。其发现更大的模型偏向自由左翼立场具有重要意义，并提出了一种实用的偏见引导方法，为未来LLM的偏见缓解和控制提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究对大型语言模型（LLMs）政治偏见的评估范围狭窄，缺乏对不同架构、规模和多语言设置中偏见普遍性的探讨；同时，很少有研究探讨这些偏见是否可以被主动控制。

**Method:** 本研究对七个现代开源指令微调LLMs（包括LLaMA-3.1、Qwen-3和Aya-Expanse）在14种语言上进行了大规模政治倾向评估。采用政治指南针测试，每个陈述使用11个语义等效的释义以确保测量鲁棒性。为测试政治立场的操控性，研究利用了一种简单的质心激活干预技术。

**Result:** 结果显示，更大的模型持续向自由左翼立场倾斜，且在不同语言和模型家族中存在显著差异。质心激活干预技术能可靠地将模型响应引导至替代意识形态立场。

**Conclusion:** 大型语言模型存在可识别且可引导的多语言政治偏见。

> **ai_Abstract:** 本文通过大规模多语言研究，评估了七个开源指令微调大型语言模型的政治倾向。研究发现，大型LLM普遍存在自由左翼偏见，且这种偏见在不同语言和模型家族中存在显著差异。此外，研究还提出并验证了一种简单的质心激活干预技术，能够有效地引导LLM的政治立场。

> **摘要翻译:** 大型语言模型（LLMs）正日益被应用于日常工具和应用程序中，这引发了对其潜在政治观点影响的担忧。虽然先前的研究表明LLMs通常表现出可测量的政治偏见——频繁偏向自由或进步立场——但仍存在关键空白。大多数现有研究仅评估一小部分模型和语言，这使得政治偏见在不同架构、规模和多语言设置中的普遍性问题悬而未决。此外，很少有工作研究这些偏见是否可以被主动控制。
在这项工作中，我们通过对现代开源指令微调LLMs的政治倾向进行大规模研究来弥补这些空白。我们评估了七个模型，包括LLaMA-3.1、Qwen-3和Aya-Expanse，跨14种语言使用政治指南针测试，每个陈述有11个语义等效的释义，以确保稳健的测量。我们的结果显示，更大的模型持续向自由左翼立场倾斜，在不同语言和模型家族之间存在显著差异。为了测试政治立场的操控性，我们利用一种简单的质心激活干预技术，并表明它能可靠地在多种语言中将模型响应引导至替代意识形态立场。我们的代码已公开可用：https://github.com/d-gurgurov/Political-Ideologies-LLMs。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [709] [Listening to the Unspoken: Exploring 365 Aspects of Multimodal Interview Performance Assessment](https://arxiv.org/abs/2507.22676)
> *倾听“未言之语”：探索多模态面试表现评估的365个维度*

*Jia Li, Yang Wang, Wenhao Qian, Zhenzhen Hu, Richang Hong, Meng Wang* | **Category: cs.CL, cs.MM** | **Updated: 2025-07-30**

**Keywords:** 多模态面试评估, 365框架, 集成学习, 视频音频文本, 自动化评估

**Comment:** 8 pages, 4 figures, ACM MM 2025.
  github:https://github.com/MSA-LMC/365Aspects

> **TL;DR:** 本文提出一个新颖的多模态面试表现评估框架，通过整合视频、音频和文本三种模态，候选人的六种回应以及五个关键评估维度来全面评估面试表现，并在AVI Challenge 2025中获得第一名。

**AI_Comments:** 本文的创新点在于提出了一个“365”的全面评估框架，将多模态数据（视频、音频、文本）与多方面评估维度（6种回应、5个评估维度）相结合，旨在更全面地捕捉面试表现。其采用的共享压缩多层感知器进行特征融合以及两级集成学习策略，有助于提高评估的准确性和鲁棒性。在AVI Challenge 2025中获得第一名，充分证明了该方法的有效性和在实际应用中的潜力。该研究对于自动化面试评估领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 面试表现评估对于确定候选人是否适合专业职位至关重要。为了确保全面和公平的评估，需要一个能够整合多模态信息并捕获显式和隐式线索的评估框架。

**Method:** 本文提出了一个新颖且全面的框架，探索了面试表现的“365”个维度，通过整合三种模态（视频、音频和文本）、每个候选人的六种回应和五个关键评估维度。该框架采用模态特定特征提取器对异构数据流进行编码，并通过共享压缩多层感知器进行融合。该模块将多模态嵌入压缩到统一的潜在空间，以促进高效的特征交互。为了增强预测的鲁棒性，该方法结合了两级集成学习策略：1）独立的回归头预测每个回应的分数，2）使用均值池化机制在回应之间聚合预测，以生成五个目标维度的最终分数。

**Result:** 该框架实现了0.1824的多维度平均MSE，并在AVI Challenge 2025中获得第一名，证明了其在推进自动化和多模态面试表现评估方面的有效性和鲁棒性。

**Conclusion:** 本文提出的多模态面试表现评估框架通过整合多种模态和维度，能够捕获显式和隐式线索，实现全面和无偏见的评估，并在国际挑战赛中取得了优异成绩，展现了其在自动化面试评估领域的潜力。

> **ai_Abstract:** 本研究提出一个名为“365”的多模态面试表现评估框架，旨在通过整合视频、音频、文本三种模态数据、候选人的六种回应以及五个关键评估维度，实现对面试表现的全面和公平评估。该框架利用模态特定特征提取器和共享压缩多层感知器进行数据融合，并通过两级集成学习策略提高预测鲁棒性。该方法能够捕获多模态数据中的显式和隐式线索，实现无偏见评估。在AVI Challenge 2025中，该框架以0.1824的多维度平均MSE获得第一名，验证了其有效性和鲁棒性。

> **摘要翻译:** 面试表现评估对于确定候选人是否适合专业职位至关重要。为了确保全面和公平的评估，我们提出了一个新颖而全面的框架，通过整合三种模态（视频、音频和文本）、每个候选人的六种回应和五个关键评估维度，探索面试表现的“365”个方面。该框架采用模态特定特征提取器对异构数据流进行编码，随后通过共享压缩多层感知器进行融合。该模块将多模态嵌入压缩到统一的潜在空间，以促进高效的特征交互。为了增强预测的鲁棒性，我们结合了两级集成学习策略：(1) 独立的回归头预测每个回应的分数，(2) 使用均值池化机制在回应之间聚合预测，以生成五个目标维度的最终分数。通过倾听“未言之语”，我们的方法从多模态数据中捕获显式和隐式线索，从而实现全面和无偏见的评估。该框架实现了0.1824的多维度平均MSE，并在AVI Challenge 2025中获得第一名，证明了其在推进自动化和多模态面试表现评估方面的有效性和鲁棒性。完整实现可在https://github.com/MSA-LMC/365Aspects 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [737] [From Sufficiency to Reflection: Reinforcement-Guided Thinking Quality in Retrieval-Augmented Reasoning for LLMs](https://arxiv.org/abs/2507.22716)
> *从充分性到反思：强化引导的大语言模型检索增强推理中的思维质量*

*Jie He, Victor Gutierrez Basulto, Jeff Z. Pan* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 强化学习, 检索增强生成, 大语言模型, 推理质量, 多维度奖励

**Comment:** 

> **TL;DR:** 现有基于强化学习的大语言模型检索增强生成（RAG）方法侧重于最终答案奖励，忽视了中间推理质量，导致信息不足、推理错误和答案不一致等问题。本文提出了TIRESRAG-R1框架，引入了“思考-检索-反思”过程和多维度奖励系统（充分性、推理质量、反思奖励），显著提高了大语言模型的推理能力和稳定性，并在多跳问答任务上表现优异。

**AI_Comments:** 这篇论文通过将强化学习的奖励机制从单一的最终答案扩展到多维度的中间推理质量，显著提升了RAG方法的创新性。其提出的“思考-检索-反思”过程以及充分性、推理质量和反思奖励，为大语言模型更深层次的推理和错误修正提供了新的范式，对于提高LLM在复杂任务中的鲁棒性和可解释性具有重要意义。识别出的三种失败模式也为后续研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于强化学习的检索增强生成（RAG）方法仅依赖最终答案奖励，忽略了中间推理质量，导致大语言模型（LLMs）在推理过程中出现信息不足、推理错误和答案与推理不一致等三种主要失败模式。

**Method:** 本文提出了TIRESRAG-R1框架，采用“思考-检索-反思”过程和多维度奖励系统来提升推理和稳定性。该系统包括：（1）充分性奖励，鼓励彻底检索；（2）推理质量奖励，评估推理链的合理性和准确性；（3）反思奖励，用于检测和修正错误。此外，还采用了难度感知重加权策略和训练样本过滤。

**Result:** 在四个多跳问答数据集上的实验表明，TIRESRAG-R1的性能优于先前的RAG方法，并且对单跳任务也具有良好的泛化能力。

**Conclusion:** TIRESRAG-R1通过引入多维度奖励系统和反思机制，有效解决了现有RAG方法在中间推理质量方面的不足，显著提升了大语言模型在复杂推理任务中的性能和稳定性。

> **ai_Abstract:** 本文旨在解决现有基于强化学习的检索增强生成（RAG）方法在大语言模型（LLMs）推理中仅关注最终答案奖励而忽视中间推理质量的问题。论文分析了RAG推理模型的三种失败模式：信息不足、推理错误和答案-推理不一致。为此，作者提出了TIRESRAG-R1框架，该框架引入了“思考-检索-反思”过程和多维度奖励系统，包括充分性奖励、推理质量奖励和反思奖励，以提升检索的彻底性、推理的合理性和错误修正能力。结合难度感知重加权和训练样本过滤，TIRESRAG-R1在多跳问答任务上显著优于现有RAG方法，并展现出良好的泛化能力，有效增强了LLMs的推理和稳定性。

> **摘要翻译:** 基于强化学习的检索增强生成（RAG）方法提升了大语言模型（LLMs）的推理能力。然而，大多数方法仅依赖最终答案奖励，忽视了中间推理质量。本文分析了现有RAG推理模型，并识别出三种主要失败模式：（1）信息不足，即模型未能检索到足够的支持信息；（2）错误推理，尽管信息充足，但仍出现逻辑或内容层面的缺陷；以及（3）答案-推理不一致，即有效的推理链导致了不匹配的最终答案。我们提出了TIRESRAG-R1，一个新颖的框架，它采用“思考-检索-反思”过程和多维度奖励系统来改善推理和稳定性。TIRESRAG-R1引入了：（1）充分性奖励，以鼓励彻底的检索；（2）推理质量奖励，以评估推理链的合理性和准确性；以及（3）反思奖励，以检测和修正错误。它还采用了难度感知重加权策略和训练样本过滤，以提高在复杂任务上的性能。在四个多跳问答数据集上的实验表明，TIRESRAG-R1优于先前的RAG方法，并且对单跳任务也具有良好的泛化能力。代码和数据可在https://github.com/probe2/TIRESRAG-R1获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [743] [Sem-DPO: Mitigating Semantic Inconsistency in Preference Optimization for Prompt Engineering](https://arxiv.org/abs/2507.20133)
> *Sem-DPO：在提示工程的偏好优化中缓解语义不一致性*

*Anas Mohamed, Azal Ahmad Khan, Xinran Wang, Ahmad Faraz Khan, Shuwen Ge, Saman Bahzad Khan, Ayaan Ahmad, Ali Anwar* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 偏好优化, 提示工程, 语义一致性, 直接偏好优化, 生成式AI

**Comment:** 

> **TL;DR:** Sem-DPO通过语义加权改进DPO，在提示优化中减少语义漂移，提高输出质量和人类偏好。

**AI_Comments:** Sem-DPO的创新点在于将语义一致性引入到DPO框架中，通过简单的权重调整有效缓解了语义漂移问题。这对于提升生成式AI在提示工程中的实用性和可靠性至关重要，特别是在需要精确控制输出语义的场景下。其分析边界的提供也增加了理论上的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 现有DPO在提示工程中虽能自动优化提示，但其token级正则化未能解决语义不一致问题，导致高偏好分数提示可能偏离用户原意。

**Method:** 本文引入Sem-DPO，一种DPO的变体，它通过根据获胜提示与原始提示的语义差异调整DPO损失的权重，从而减少语义不一致训练示例的影响。研究提供了偏好调整提示生成器语义漂移的首次分析边界，证明Sem-DPO能将学习到的提示保持在原始文本的可证明有界邻域内。

**Result:** 在三个标准文本到图像提示优化基准和两个语言模型上，Sem-DPO的CLIP相似度比DPO高8-12%，人类偏好分数（HPSv2.1, PickScore）高5-9%，同时还优于最先进的基线。

**Conclusion:** 这些发现表明，增强了语义加权的强大基线应该成为提示优化研究的新标准，并为语言模型中更广泛的语义感知偏好优化奠定基础。

> **ai_Abstract:** 本文提出了Sem-DPO，一种改进的直接偏好优化（DPO）方法，旨在解决提示工程中语义不一致的问题。Sem-DPO通过引入基于语义差异的损失权重来减少语义偏离的训练示例的影响，确保优化后的提示保持与用户意图的语义一致性。实验结果表明，Sem-DPO在文本到图像生成任务中显著提高了CLIP相似度和人类偏好分数，优于DPO及其他SOTA基线，为未来的语义感知偏好优化奠定了基础。

> **摘要翻译:** 生成式AI现在可以从文本合成惊人逼真的图像，但输出质量对提示的措辞高度敏感。直接偏好优化（DPO）为自动提示工程提供了一种轻量级、离策略的强化学习替代方案，但其令牌级正则化未能检查语义不一致性，因为获得更高偏好分数的提示仍然可能偏离用户的预期含义。
我们引入了Sem-DPO，一种DPO的变体，它保留了语义一致性，同时保持了其简单性和效率。Sem-DPO通过基于获胜提示与原始提示的差异程度来调整DPO损失的权重，从而减少语义不一致训练示例的影响。我们首次为偏好调整的提示生成器提供了语义漂移的分析边界，表明Sem-DPO将学习到的提示保持在原始文本的可证明有界邻域内。在三个标准文本到图像提示优化基准和两个语言模型上，Sem-DPO的CLIP相似度比DPO高8-12%，人类偏好分数（HPSv2.1, PickScore）高5-9%，同时还优于最先进的基线。这些发现表明，增强了语义加权的强大基线应该成为提示优化研究的新标准，并为语言模型中更广泛的语义感知偏好优化奠定基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [757] [Investigating Hallucination in Conversations for Low Resource Languages](https://arxiv.org/abs/2507.22720)
> *调查低资源语言对话中的幻觉现象*

*Amit Das, Md. Najib Hasan, Souvika Sarkar, Zheng Zhang, Fatemeh Jamshidi, Tathagata Bhattacharya, Nilanjana Raychawdhury, Dongji Feng, Vinija Jain, Aman Chadha* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 幻觉, 大型语言模型, 低资源语言, 对话式人工智能, 多语言

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）在低资源语言对话中存在幻觉问题，本研究发现LLMs在中文（普通话）中很少出现幻觉，但在印地语和波斯语中幻觉数量显著更高。

**AI_Comments:** 本论文将大型语言模型幻觉这一关键问题从英语扩展到低资源语言，提供了关于不同语言性能的宝贵见解。研究发现LLMs在不同低资源语言中的幻觉率差异显著，这表明“低资源”并非一个单一的类别来衡量幻觉现象。这强调了需要针对不同语言环境进行更具针对性的研究和开发，以提高LLMs在多样化语言背景下的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）生成的文本常包含事实错误，即“幻觉”，这严重影响了LLMs的可靠性和有效性。现有研究主要关注英语中的幻觉现象，但对于低资源语言的对话数据中的幻觉问题研究不足，因此本研究旨在弥补这一空白。

**Method:** 本研究将幻觉调查扩展到印地语、波斯语和中文（普通话）这三种语言的对话数据。研究对一个数据集进行了全面分析，以检查GPT-3.5、GPT-4o、Llama-3.1、Gemma-2.0、DeepSeek-R1和Qwen-3等LLMs在这些语言中的事实和语言错误。

**Result:** 研究发现，LLMs在中文（普通话）中产生的幻觉回应非常少，但在印地语和波斯语中产生的幻觉数量显著更高。

**Conclusion:** 大型语言模型在不同低资源语言中的幻觉表现存在显著差异，中文（普通话）的幻觉率远低于印地语和波斯语。这表明，在不同语言环境中，LLMs的可靠性存在不均衡性，需要针对特定语言进行更深入的研究和改进。

> **ai_Abstract:** 本研究调查了大型语言模型（LLMs）在低资源语言对话中生成幻觉文本的现象，特别关注印地语、波斯语和中文（普通话）。与以往主要关注英语的研究不同，本文对GPT-3.5、GPT-4o、Llama-3.1、Gemma-2.0、DeepSeek-R1和Qwen-3等多种LLMs在这些语言中的事实和语言错误进行了全面分析。结果显示，LLMs在中文（普通话）中的幻觉生成率极低，但在印地语和波斯语中则显著更高。

> **摘要翻译:** 大型语言模型（LLMs）在生成与人类写作高度相似的文本方面表现出了卓越的能力。然而，它们经常生成事实不准确的陈述，这个问题通常被称为“幻觉”。解决幻觉对于提高LLMs的可靠性和有效性至关重要。虽然许多研究都集中在英语中的幻觉问题，但我们的研究将这一调查扩展到印地语、波斯语和中文这三种语言的对话数据。我们对一个数据集进行了全面分析，以检查GPT-3.5、GPT-4o、Llama-3.1、Gemma-2.0、DeepSeek-R1和Qwen-3这些模型在这些语言中的事实和语言错误。我们发现LLMs在中文（普通话）中产生的幻觉回应非常少，但在印地语和波斯语中产生的幻觉数量显著更高。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [776] [StructText: A Synthetic Table-to-Text Approach for Benchmark Generation with Multi-Dimensional Evaluation](https://arxiv.org/abs/2507.21340)
> *StructText: 一种用于基准生成和多维评估的合成表格到文本方法*

*Satyananda Kashyap, Sola Shirai, Nandana Mihindukulasooriya, Horst Samulowitz* | **Category: cs.CL, cs.AI, cs.DB, cs.IR** | **Updated: 2025-07-28**

**Keywords:** StructText, 基准生成, 关键值提取, 表格到文本, 大语言模型

**Comment:** Data available:
  https://huggingface.co/datasets/ibm-research/struct-text and code available
  at: https://github.com/ibm/struct-text

> **TL;DR:** StructText是一个自动生成高质量文本关键值提取基准的框架，利用现有表格数据通过“计划-执行”管道合成文本，并采用多维评估策略，以解决LLM评估基准的缺乏问题。

**AI_Comments:** 本文提出了一种创新的合成方法StructText，通过自动化方式大规模生成用于文本关键值提取的基准，有效解决了现有LLM评估基准缺乏且手动构建成本高昂的问题。其提出的多维评估策略，结合了LLM判断和客观指标，具有独创性。研究结果揭示了LLM在生成可提取文本时在叙述连贯性方面的局限性，这对于未来LLM在结构化信息生成和可提取性方面的研究具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型（LLMs）能够将自然语言转换为结构化数据，但缺乏评估其提取质量的基准，特别是在特定领域或组织文档中。手动构建这些基准劳动密集且限制了规模和可扩展性。

**Method:** 提出了StructText框架，这是一个端到端的方法，利用现有表格数据作为结构化真值，通过两阶段“计划-执行”管道合成生成对应的自然语言文本。为确保文本与结构化源对齐，引入了多维评估策略，结合了基于LLM的事实性、幻觉和连贯性判断，以及衡量数字和时间准确性的客观提取指标。

**Result:** 在49个数据集的71,539个示例上进行了评估。结果显示，虽然LLMs在事实准确性方面表现出色并避免了幻觉，但在生成可提取文本的叙述连贯性方面存在困难。模型能高保真地假设数字和时间信息，但这些信息嵌入在难以自动提取的叙述中。

**Conclusion:** 本文提出了StructText框架，用于自动生成用于文本中关键值提取的高保真基准，并揭示了LLM在生成可提取文本时在叙述连贯性方面的挑战。该框架、数据集、评估工具和基线提取系统已发布以支持后续研究。

> **ai_Abstract:** 本文介绍了StructText，一个自动化的端到端框架，用于生成高质量的文本关键值提取基准。它解决了大型语言模型（LLMs）评估基准的缺乏问题，通过利用现有表格数据作为事实，并采用“计划-执行”两阶段管道合成自然语言文本。该框架引入了多维评估策略，结合了LLM对事实性、幻觉和连贯性的判断以及客观提取指标。对49个数据集的评估显示，LLMs在事实准确性方面表现良好，但在叙述连贯性上存在挑战，导致嵌入的数字和时间信息难以自动提取。相关资源已公开发布以支持进一步研究。

> **摘要翻译:** 从文本中提取结构化信息，例如可以增强表格数据的键值对，在许多企业用例中非常有用。尽管大型语言模型（LLMs）已经实现了许多将自然语言转换为结构化格式的自动化管道，但仍然缺乏评估其提取质量的基准，特别是在特定领域或针对特定组织的文档中。通过手动标注构建此类基准是劳动密集型的，并限制了基准的规模和可扩展性。在这项工作中，我们提出了StructText，一个端到端框架，用于利用现有表格数据自动生成用于从文本中提取键值的高保真基准。它使用可用的表格数据作为结构化事实，并遵循两阶段“计划-执行”管道来合成生成相应的自然语言文本。为了确保文本与结构化源之间的对齐，我们引入了一种多维评估策略，该策略结合了（a）基于LLM的事实性、幻觉和连贯性判断以及（b）衡量数字和时间准确性的客观提取指标。我们在49个数据集的71,539个示例上评估了所提出的方法。结果表明，虽然LLMs实现了强大的事实准确性并避免了幻觉，但它们在生成可提取文本的叙述连贯性方面存在困难。值得注意的是，模型以高保真度假设数字和时间信息，但这些信息嵌入在难以自动提取的叙述中。我们发布了一个框架，包括数据集、评估工具和基线提取系统，以支持持续研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [784] [The pitfalls of next-token prediction](https://arxiv.org/abs/2403.06963)
> *下一词元预测的陷阱*

*Gregor Bachmann, Vaishnavh Nagarajan* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 下一词元预测, 教师强制训练, 无教师训练, 大语言模型, 规划任务

**Comment:** ICML 2024

> **TL;DR:** 本文探讨了下一词元预测器在建模人类智能方面的局限性，指出教师强制训练可能无法学习准确的预测器，并提出了一种名为“无教师”训练的多词元目标来解决此问题。

**AI_Comments:** 本文创新性地指出了下一词元预测范式在教师强制训练阶段可能存在的根本性缺陷，而不仅仅是自回归推理时的误差累积。它通过具体实验揭示了当前主流模型（如Transformer和Mamba）在此类任务上的不足，并提出了一种名为“无教师”训练的新颖解决方案，这对于推动大语言模型的发展和理解其局限性具有重要意义。该研究鼓励社区重新思考并探索超越单一下一词元预测目标的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探讨“下一词元预测器能否忠实地模拟人类智能”这一新兴担忧，纠正围绕它的流行误解，并倡导一种简单的多词元目标。

**Method:** 本文区分了下一词元预测的两个阶段：自回归推理和教师强制训练。研究揭示了教师强制训练在某些任务中可能无法学习准确的下一词元预测器的问题机制，并通过一个简单的规划任务验证了Transformer和Mamba架构的失败。最后，提出了使用“无教师”训练（一种通过虚拟词元提前预测多个词元的简单修改）来解决此问题。

**Result:** 研究发现，在特定的规划任务中，Transformer和Mamba架构在教师强制训练下无法学习准确的下一词元预测器，尽管任务本身很简单。初步证据表明，通过使用“无教师”训练，这种失败可以得到解决。

**Conclusion:** 本文的发现揭示了下一词元预测范式的潜在缺陷，并提出了一种新的训练方法——“无教师”训练，有望为未来的相关辩论奠定基础，并启发超越当前范式的探索。

> **ai_Abstract:** 本文探讨了下一词元预测器在模拟人类智能方面的局限性。作者指出，教师强制训练在某些任务中可能无法有效地学习准确的下一词元预测，这与自回归推理中的误差累积问题不同。文章详细阐述了教师强制训练失败的机制，并通过一个规划任务验证了Transformer和Mamba模型的失败。为解决此问题，论文提出并初步验证了一种名为“无教师”训练的新方法，该方法通过预测多个未来词元来提高模型性能，为超越传统下一词元预测范式提供了新思路。

> **摘要翻译:** 一个单纯的下一词元预测器能否忠实地模拟人类智能？我们阐明了这一新兴的担忧，纠正了围绕它的流行误解，并倡导一种简单的多词元目标。
  首先，我们认为下一词元预测的两个常被混淆的阶段——自回归推理和教师强制训练——必须被区别对待。流行的批评认为自回归推理过程中错误会累积，但这关键地假设了教师强制训练已经学习到了一个准确的下一词元预测器。这个假设回避了一个我们揭示的更深层次的问题：在某些类型的任务中，教师强制训练可能根本就无法学习到一个准确的下一词元预测器。我们描述了教师强制训练可能失败的一般机制，并设计了一个最小的规划任务，其中Transformer和Mamba架构都以这种方式经验性地失败了——值得注意的是，尽管该任务很容易学习。
  最后，我们提供了初步证据表明，这种失败可以通过“无教师”训练来解决，这是一种使用虚拟词元提前预测多个词元的简单修改。我们希望这一发现能为未来的辩论奠定基础，并激发超越下一词元预测范式的探索。我们的代码可在 https://github.com/gregorbachmann/Next-Token-Failures 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [792] [Resource-Efficient Adaptation of Large Language Models for Text Embeddings via Prompt Engineering and Contrastive Fine-tuning](https://arxiv.org/abs/2507.22729)
> *大型语言模型通过提示工程和对比微调实现文本嵌入的资源高效适应*

*Benedikt Roth, Stephan Rappensperger, Tianming Qiu, Hamza Imamović, Julian Wörmann, Hao Shen* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 文本嵌入, 提示工程, 对比微调, 资源高效

**Comment:** 

> **TL;DR:** 本文提出通过提示工程和资源高效的对比微调，将大型语言模型有效适应为文本嵌入模型，并在MTEB英文聚类任务上达到SOTA性能。

**AI_Comments:** 本文的创新点在于探索了将LLMs应用于文本嵌入的资源高效方法，特别是结合了提示工程和对比微调。其重要性在于解决了LLMs在非生成任务中生成高质量文本嵌入的挑战，为LLMs在更广泛的NLP应用中提供了新的可能性。通过对注意力机制的分析，也为理解LLMs的内部工作机制提供了洞察。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在文本生成方面表现出色，其令牌级表示富含语义，但将这些向量池化为文本嵌入会丢弃关键信息。许多非生成式下游任务（如聚类、分类、检索）仍然依赖于准确且可控的句子或文档级嵌入，因此需要探索有效的方法将LLMs适应为文本嵌入模型。

**Method:** 作者探索了多种适应预训练的仅解码器LLMs的策略，包括：(i) 各种令牌嵌入聚合技术；(ii) 任务特定的提示工程；(iii) 通过对比微调进行文本级增强。这些组件结合起来，并通过对合成生成的正对进行资源高效的对比微调。

**Result:** 结合所提出的方法在Massive Text Embedding Benchmark (MTEB) 的英文聚类任务上取得了最先进的性能。注意力图分析显示，微调将焦点从提示词转移到语义相关的词语，表明更有效地将意义压缩到最终的隐藏状态中。

**Conclusion:** 实验证明，通过结合提示工程和对合成生成的正对进行资源高效的对比微调，大型语言模型可以有效地适应为文本嵌入模型。

> **ai_Abstract:** 本文研究了如何将大型语言模型（LLMs）有效适应为文本嵌入模型，以支持非生成式NLP任务。作者探索了令牌嵌入聚合、任务特定提示工程和对比微调等多种策略。实验结果表明，通过这些方法的结合，特别是在合成正对上进行资源高效的对比微调，LLMs能在MTEB的英文聚类任务上达到最先进的性能，并且注意力机制的分析也验证了其语义压缩的有效性。

> **摘要翻译:** 大型语言模型（LLMs）已成为自然语言处理（NLP）的基石，在文本生成方面取得了令人印象深刻的性能。它们的令牌级表示捕获了丰富、与人类对齐的语义。然而，将这些向量池化为文本嵌入会丢弃关键信息。尽管如此，许多非生成式下游任务，如聚类、分类或检索，仍然依赖于准确且可控的句子或文档级嵌入。我们探索了几种针对预训练的、仅解码器LLMs的适应策略：(i) 各种令牌嵌入聚合技术，(ii) 任务特定的提示工程，以及 (iii) 通过对比微调进行文本级增强。结合这些组件在Massive Text Embedding Benchmark (MTEB) 的英文聚类赛道上取得了最先进的性能。对注意力图的分析进一步表明，微调将焦点从提示令牌转移到语义相关的词语，表明更有效地将意义压缩到最终的隐藏状态中。我们的实验表明，通过结合提示工程和对合成生成的正对进行资源高效的对比微调，LLMs可以有效地适应为文本嵌入模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [812] [Task Arithmetic for Language Expansion in Speech Translation](https://arxiv.org/abs/2409.11274)
> *语音翻译中的任务算术用于语言扩展*

*Yao-Fei Cheng, Hayato Futami, Yosuke Kashiwagi, Emiru Tsunoo, Wen Shen Teo, Siddhant Arora, Shinji Watanabe* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 语音翻译, 任务算术, 语言扩展, 语言控制模型, 多语言系统

**Comment:** 

> **TL;DR:** 本文提出一种增强的任务算术方法，结合语言控制模型，旨在无需重新训练即可高效扩展语音翻译系统的语言对，并在实验中取得了显著性能提升，同时能应用于数据稀缺的语言对。

**AI_Comments:** 本文的创新点在于提出了增强的任务算术方法，并引入语言控制模型，有效解决了在语音翻译中扩展语言对时传统方法成本高昂且易混淆的问题。这种无需重新训练即可扩展语言对的能力，以及通过任务类比合成模型以应对数据稀缺语言对的能力，对于构建更灵活、高效的多语言语音翻译系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩展语音翻译（ST）的语言对成本高昂，因为需要对新的和旧的组合数据集进行重新训练。

**Method:** 本文旨在通过任务算术，从现有的一对一语音翻译系统构建一个一对多语音翻译系统，从而避免重新训练。针对任务算术直接应用导致的语言混淆问题，研究者引入了一种增强的任务算术方法，该方法包含一个语言控制模型，以确保生成正确的目标语言。此外，该框架还可以通过任务类比，基于现有的机器翻译（MT）和语音翻译（ST）模型合成新的语音翻译模型，从而扩展到缺少配对ST训练数据或预训练ST模型的语言对。

**Result:** 在MuST-C和CoVoST-2数据集上的实验显示，BLEU分数分别提高了高达4.66和4.92，COMET分数分别提高了8.87和11.83。此外，该框架能够扩展到缺少配对语音翻译训练数据或预训练语音翻译模型的语言对。

**Conclusion:** 该研究提出了一种新颖的增强任务算术方法，结合语言控制模型，有效解决了语音翻译中语言对扩展成本高昂的问题，实现了显著的性能提升，并展示了在数据稀缺语言对上的泛化能力，无需重新训练即可构建一对多语音翻译系统。

> **ai_Abstract:** 本文提出了一种创新的增强任务算术方法，用于在不重新训练的情况下扩展语音翻译（ST）系统的语言对。针对直接任务算术导致的语言混淆，该方法引入了一个语言控制模型。实验结果表明，在MuST-C和CoVoST-2数据集上，BLEU和COMET分数均有显著提升。此外，该框架能够通过任务类比合成模型，扩展到缺少训练数据的语言对，为构建高效、可扩展的一对多ST系统提供了新的途径。

> **摘要翻译:** 大型语言模型（LLM）的最新进展引起了人们对语音-文本多模态基础模型的兴趣，这些模型在指令微调的语音翻译（ST）方面取得了强大性能。然而，由于需要对新的和旧的组合数据集进行重新训练，扩展语言对的成本很高。为了解决这个问题，我们旨在通过任务算术，在不重新训练的情况下，从现有的一对一语音翻译系统构建一个一对多语音翻译系统。任务算术在语音翻译中的直接应用会导致语言混淆；因此，我们引入了一种增强的任务算术方法，其中包含一个语言控制模型，以确保生成正确的目标语言。我们在MuST-C和CoVoST-2上的实验显示，BLEU分数分别提高了高达4.66和4.92，COMET分数分别提高了8.87和11.83。此外，我们证明了我们的框架可以通过任务类比，基于现有的机器翻译（MT）和语音翻译（ST）模型合成语音翻译模型，从而扩展到缺少配对语音翻译训练数据或预训练语音翻译模型的语言对。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [814] [Reducing Hallucinations in Summarization via Reinforcement Learning with Entity Hallucination Index](https://arxiv.org/abs/2507.22744)
> *通过使用实体幻觉指数的强化学习减少摘要中的幻觉*

*Praveenkumar Katwe, Rakesh Chandra, Balabantaray Kali, Prasad Vittala* | **Category: cs.CL, cs.AI, 68T50, I.2.7** | **Updated: 2025-07-30**

**Keywords:** 摘要, 幻觉, 强化学习, 实体幻觉指数, 语言模型

**Comment:** 8

> **TL;DR:** 本文提出一个基于强化学习的微调框架，利用实体幻觉指数（EHI）作为奖励信号，有效减少了抽象摘要中的实体级幻觉，且无需人工标注。

**AI_Comments:** 该研究的创新之处在于引入了实体幻觉指数（EHI）作为量化幻觉的指标，并将其与强化学习相结合，实现了无需人工标注的幻觉减少。这为解决抽象摘要中的事实准确性问题提供了一个可扩展且有效的方法，对于语言模型在现实世界中的部署具有重要意义。发布可复现的Colab管道也促进了该领域未来的研究。

<details>
  <summary>Details</summary>

**Motivation:** 抽象摘要中的幻觉问题是语言模型在实际应用中面临的关键挑战。本文旨在解决这一问题，提升摘要的事实准确性。

**Method:** 研究引入了实体幻觉指数（EHI）来量化生成摘要中命名实体的存在、正确性和接地性。首先，使用预训练语言模型生成基线摘要并计算EHI分数。然后，应用强化学习，以EHI作为奖励信号对模型参数进行微调，以偏向生成实体忠实的输出。该方法不依赖人工事实标注。

**Result:** 实验表明，EHI在不同数据集上持续改进，定性分析显示实体级幻觉显著减少，同时不影响流畅性或信息量。研究还发布了可复现的Colab管道。

**Conclusion:** 通过基于EHI的强化学习微调，可以有效减少抽象摘要中的实体幻觉，为幻觉感知模型微调提供了一种可扩展且有效的途径。

> **ai_Abstract:** 本文提出了一种基于强化学习的微调框架，旨在通过优化实体幻觉指数（EHI）来减少抽象摘要中的实体级幻觉。EHI是一个量化命名实体存在、正确性和接地性的指标。该方法利用EHI作为奖励信号进行模型微调，无需人工事实标注，实现了可扩展性。实验证明，该方法能显著减少幻觉，同时保持摘要的流畅性和信息量。

> **摘要翻译:** 在抽象摘要中减少幻觉仍然是将语言模型（LMs）部署到现实世界环境中的一个关键挑战。在这项工作中，我们引入了一个奖励驱动的微调框架，该框架明确优化了实体幻觉指数（EHI），这是一个旨在量化生成摘要中命名实体的存在、正确性和接地性的度量。给定一个会议记录语料库，我们首先使用预训练的语言模型生成基线摘要，并通过自动实体提取和匹配计算EHI分数。然后，我们应用强化学习来微调模型参数，使用EHI作为奖励信号来偏向生成实体忠实的输出。我们的方法不依赖人工编写的事实性标注，从而实现了可扩展的微调。实验表明，EHI在不同数据集上持续改进，定性分析揭示了实体级幻觉的显著减少，而流畅性或信息量没有下降。我们发布了一个可复现的Colab管道，以促进使用EHI等轻量级幻觉指标进行幻觉感知模型微调的进一步研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [834] [CUS-QA: Local-Knowledge-Oriented Open-Ended Question Answering Dataset](https://arxiv.org/abs/2507.22752)
> *CUS-QA：面向本地知识的开放式问答数据集*

*Jindřich Libovický, Jindřich Helcl, Andrei Manea, Gianluca Vico* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 开放式问答, 区域知识, 大型语言模型, 数据集, 评估指标

**Comment:** 

> **TL;DR:** 引入CUS-QA，一个面向地区知识的开放式问答数据集，包含文本和视觉模态，并提供LLM基线。发现LLM在地区知识方面有显著缺陷，且自动评估指标与人工判断关联性低。

**AI_Comments:** 这项工作通过创建一个独特的多语言、多模态区域知识问答数据集CUS-QA，填补了现有LLM在本地化知识和评估方面的空白。其创新之处在于结合了特定地区的母语数据和视觉信息，并明确指出了LLM在非通用知识上的局限性以及现有自动评估指标的不足，为未来研究提供了宝贵的资源和明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型在地区知识方面存在显著空白，且开放式问答的自动评估指标与人工判断的关联性不足，因此需要新的基准数据集来评估和推进相关研究。

**Method:** 本文引入了一个名为CUS-QA的开放式区域问答基准数据集，该数据集包含人工整理的、基于维基百科的问题和答案，由捷克、斯洛伐克和乌克兰的母语使用者创建，并提供英文翻译，涵盖纯文本和视觉理解问题。研究者使用最先进的大型语言模型作为基线，通过提示进行评估，并辅以人工判断答案的正确性。此外，还利用人工评估来分析现有自动评估指标的可靠性。

**Result:** 基线结果表明，当前大型语言模型在区域知识方面存在显著的知识空白。此外，除了基于LLM的评估之外，自动化指标与人工判断之间的相关性极小。

**Conclusion:** CUS-QA数据集可以用于评估LLM的区域知识、研究跨语言生成一致性，并推动开放式问答评估指标的发展。现有的LLM在区域知识上表现不佳，且自动评估指标的可靠性有待提高。

> **ai_Abstract:** 本文推出了CUS-QA数据集，一个面向开放式区域问答的新基准，融合了文本和视觉信息。该数据集由捷克、斯洛伐克和乌克兰的母语使用者基于维基百科手动创建，旨在评估大型语言模型（LLM）的区域知识。研究通过LLM基线和人工评估发现，当前LLM在区域知识方面存在明显不足，且多数自动评估指标与人工判断的相关性较低。CUS-QA数据集的发布旨在促进LLM区域知识评估、跨语言生成研究以及开放式问答评估指标的改进。

> **摘要翻译:** 我们引入了一个涵盖文本和视觉模态的开放式区域问答基准。我们还使用最先进的大型语言模型（LLM）提供了强大的基线。我们的数据集包含由捷克、斯洛伐克和乌克兰的母语使用者手动整理的、以维基百科为基础的问题和答案，并附有英文翻译。它包括纯文本问题和需要视觉理解的问题。作为基线，我们通过提示评估了最先进的LLM，并辅以人工判断答案的正确性。利用这些人工评估，我们分析了现有自动评估指标的可靠性。我们的基线结果突出显示了当前LLM在区域知识方面存在的显著空白。此外，除了基于LLM的评估之外，自动化指标与人工判断之间的相关性极小。我们发布此数据集作为资源，旨在（1）评估LLM中的区域知识，（2）在具有挑战性的环境下研究跨语言生成的一致性，以及（3）推进开放式问答评估指标的开发。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [836] ["Whose Side Are You On?" Estimating Ideology of Political and News Content Using Large Language Models and Few-shot Demonstration Selection](https://arxiv.org/abs/2503.20797)
> *“你站在哪一边？” 使用大型语言模型和少样本示范选择估计政治和新闻内容的意识形态*

*Muhammad Haroon, Magdalena Wojcieszak, Anshuman Chhabra* | **Category: cs.CL, cs.CY, cs.SI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 意识形态分类, 上下文学习, 少样本学习, 社交媒体内容

**Comment:** 

> **TL;DR:** 本文利用大型语言模型（LLMs）和上下文学习（ICL）来估计在线内容的政治意识形态，通过少样本示范选择显著优于现有方法，并分析了元数据和内容来源的影响。

**AI_Comments:** 这篇论文通过将大型语言模型应用于政治意识形态分类，展现了LLMs在复杂社会科学任务中的强大潜力。其创新点在于结合了上下文学习和少样本示范选择，有效解决了传统方法对大量标注数据和适应性差的问题。特别地，对元数据和内容来源影响的评估，为未来更鲁棒、更具解释性的意识形态识别系统提供了宝贵的见解。这对于理解和缓解社交媒体上的信息茧房和内容偏见具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体的快速增长引发了激进化、过滤气泡和内容偏见等问题。现有的意识形态分类方法存在局限性，它们需要大量人工、大规模数据集的标注，并且难以适应不断变化的意识形态语境。

**Method:** 本文探索使用大型语言模型（LLMs）通过上下文学习（ICL）来分类在线内容（特别是美国两党政治光谱）的政治意识形态。研究进行了大量实验，涉及标签平衡的示范选择，并在包含新闻文章和YouTube视频的三个数据集上进行验证。此外，还评估了元数据（如内容来源和描述）对意识形态分类的影响，并分析了提供政治和非政治内容来源如何影响LLM的分类。

**Result:** 该方法在三个数据集上显著优于零样本和传统监督方法。研究还发现元数据（如内容来源和描述）会影响意识形态分类，并且提供内容来源会影响LLM的分类结果。

**Conclusion:** 大型语言模型（LLMs）结合上下文学习和少样本示范选择，是有效分类在线内容政治意识形态的强大工具，且其性能优于现有方法。同时，元数据和内容来源对LLM的分类结果具有显著影响，这对于理解和改进内容意识形态识别具有重要意义。

> **ai_Abstract:** 本文旨在解决社交媒体内容意识形态分类中现有方法的局限性，提出了一种利用大型语言模型（LLMs）结合上下文学习（ICL）和少样本示范选择的新方法。通过在新闻文章和YouTube视频数据集上的广泛实验，证明该方法在识别美国两党政治意识形态方面显著优于零样本和传统监督方法。研究还深入探讨了元数据和内容来源对LLM分类结果的影响，揭示了这些因素在意识形态识别中的重要作用。

> **摘要翻译:** 社交媒体平台的快速增长引发了对激进化、过滤气泡和内容偏见的担忧。现有的意识形态分类方法存在局限性，它们需要大量人工投入、大规模数据集的标注，并且无法适应不断演变的意识形态语境。本文探讨了大型语言模型（LLMs）在上下文学习（ICL）背景下，分类在线内容在美国两党政治光谱中的政治意识形态的潜力。我们在包含新闻文章和YouTube视频的三个数据集上进行了大量的实验，涉及标签平衡的示范选择，结果表明我们的方法显著优于零样本和传统监督方法。此外，我们评估了元数据（例如内容来源和描述）对意识形态分类的影响，并讨论了其含义。最后，我们展示了提供政治和非政治内容来源如何影响LLM的分类。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [840] [IndoPref: A Multi-Domain Pairwise Preference Dataset for Indonesian](https://arxiv.org/abs/2507.22159)
> *IndoPref：一个用于印度尼西亚语的多领域成对偏好数据集*

*Vanessa Rebecca Wiyono, David Anugraha, Ayu Purwarianti, Genta Indra Winata* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 印度尼西亚语, 偏好数据集, 大语言模型, IndoPref, 多领域

**Comment:** Preprint

> **TL;DR:** 引入了IndoPref，一个全新的、人工撰写的多领域印度尼西亚语偏好数据集，用于评估LLM生成文本的质量，填补了该语言在偏好研究中的空白。

**AI_Comments:** IndoPref的创新之处在于其是首个完全由人类原生撰写的印度尼西亚语偏好数据集，直接解决了现有数据集文化和语言真实性不足的问题。这对于提升印度尼西亚语LLM的性能和真实性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 印度尼西亚语在大型语言模型（LLM）的偏好研究中代表性不足，现有多数多语言数据集源自英语翻译，缺乏文化和语言真实性。

**Method:** 引入了IndoPref，首个完全由人类撰写的多领域印度尼西亚语偏好数据集，专门用于评估LLM生成文本的自然度和质量。所有标注均以印度尼西亚语原生编写，并使用Krippendorff's alpha评估，显示出强大的标注者间一致性。此外，还在多个LLM上对数据集进行了基准测试并评估了输出质量。

**Result:** IndoPref数据集展示了较强的标注者间一致性（通过Krippendorff's alpha验证），并被用于对多个LLM进行基准测试以评估其输出质量。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了IndoPref，一个专为印度尼西亚语设计的多领域成对偏好数据集，旨在弥补该语言在大型语言模型（LLM）偏好研究中的空白。该数据集完全由人类原生撰写，并经过Krippendorff's alpha评估，显示出高度的标注一致性。研究者还利用此数据集对多个LLM进行了基准测试，以评估其生成文本的自然度和质量。

> **摘要翻译:** 超过2亿人讲印度尼西亚语，然而该语言在大型语言模型（LLM）的基于偏好的研究中仍然严重代表性不足。大多数现有的多语言数据集都来源于英语翻译，这常常导致内容缺乏文化和语言真实性。为了弥补这一差距，我们引入了IndoPref，这是第一个完全由人类撰写的多领域印度尼西亚语偏好数据集，专门设计用于评估LLM生成文本的自然度和质量。所有标注都以印度尼西亚语原生编写，并使用Krippendorff's alpha进行评估，显示出强大的标注者间一致性。此外，我们还在多个LLM上对该数据集进行了基准测试，并评估了每个模型的输出质量。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [846] [Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour](https://arxiv.org/abs/2507.21432)
> *迈向可本地部署的微调因果大语言模型用于出行方式选择行为*

*Tareq Alsaleh, Bilal Farooq* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大语言模型, 出行方式选择, 本地部署, 因果模型, LiTransMC

**Comment:** 

> **TL;DR:** 本研究开发并评估了LiTransMC，一个可本地部署的微调因果大语言模型，用于出行方式选择预测，它在预测准确性和解释性方面均超越了现有模型和传统方法。

**AI_Comments:** 该论文的创新之处在于首次开发并成功微调了可本地部署的因果大语言模型LiTransMC，用于出行方式选择预测。它不仅在预测准确性上超越了包括GPT-4o在内的通用大型模型和传统方法，更重要的是，它开创性地结合了预测和可解释性，通过对LLM生成推理的结构化分析，使其能够与行为理论对齐。这为交通研究领域提供了一个强大的、兼顾隐私和成本效益的工具，有望推动对话式、多任务交通模型的发展。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在调查开放获取、可本地部署的因果大语言模型（LLMs）在出行方式选择预测中的应用潜力，并解决现有模型在集成预测能力和可解释性方面的不足，同时满足隐私、成本和访问需求。

**Method:** 研究系统性地基准测试了11个大语言模型（1-12B参数），使用了三个陈述性和显示性偏好数据集，测试了396种配置，生成了超过79,000个合成通勤预测。除了预测准确性，还使用BERTopic进行主题建模和新颖的解释强度指数来评估模型生成的推理。LiTransMC通过参数高效和损失掩蔽策略进行微调。

**Result:** LiTransMC实现了0.6845的加权F1分数和0.000245的Jensen-Shannon散度，超越了未微调的本地模型、大型专有系统（包括GPT-4o）以及经典的出行方式选择方法（如离散选择模型和机器学习分类器）。它在即时级准确性和接近完美的分布校准方面均表现出色。

**Conclusion:** 本研究证明了创建专业化、可本地部署的LLM（结合预测和可解释性）的可行性。这项工作通过结合结构化行为预测和自然语言推理，为支持基于代理的模拟、政策测试和行为洞察生成的对话式、多任务交通模型开辟了潜力，并为将通用LLM转化为交通研究和政策制定中的专业化、可解释工具建立了途径，同时保持隐私、降低成本和通过本地部署扩大访问。

> **ai_Abstract:** 本研究引入了LiTransMC，一个为出行方式选择预测任务微调的、可本地部署的因果大语言模型。通过对11个LLM进行基准测试，并在多个数据集上进行大量配置测试，LiTransMC在预测准确性和解释性方面均表现出色，超越了现有LLM和传统方法，证明了创建结合预测和可解释性的专业化、本地部署LLM的可行性，为交通研究和政策制定提供了新的工具。

> **摘要翻译:** 本研究调查了开放获取、可本地部署的因果大语言模型（LLMs）在出行方式选择预测中的应用，并引入了LiTransMC，这是为该任务开发的第一个微调因果LLM。我们系统性地基准测试了11个LLM（1-12B参数），使用了三个陈述性和显示性偏好数据集，测试了396种配置，并生成了超过79,000个合成通勤预测。除了预测准确性，我们还使用BERTopic进行主题建模和一种新颖的解释强度指数来评估模型生成的推理，提供了LLM如何根据行为理论阐明决策因素的首次结构化分析。LiTransMC通过参数高效和损失掩蔽策略进行微调，实现了0.6845的加权F1分数和0.000245的Jensen-Shannon散度，超越了未微调的本地模型和大型专有系统，包括具有高级角色推断和基于嵌入加载的GPT-4o，同时在相同数据集上，也优于经典的出行方式选择方法，如离散选择模型和机器学习分类器。这种双重改进，即高即时级准确性和接近完美的分布校准，证明了创建专业化、可本地部署的LLM的可行性，这些LLM集成了预测和可解释性。通过将结构化行为预测与自然语言推理相结合，这项工作解锁了对话式、多任务交通模型的潜力，这些模型能够支持基于代理的模拟、政策测试和行为洞察生成。这些发现为将通用LLM转化为交通研究和政策制定中的专业化、可解释工具建立了途径，同时保持隐私、降低成本和通过本地部署扩大访问。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [848] [Simulated patient systems are intelligent when powered by large language model-based AI agents](https://arxiv.org/abs/2409.18924)
> *基于大型语言模型AI代理的模拟患者系统更智能*

*Huizi Yu, Jiayan Zhou, Lingyao Li, Shan Chen, Jack Gallifant, Anye Shi, Xiang Li, Jingxian He, Wenyue Hua, Mingyu Jin, Guang Chen, Yang Zhou, Zhao Li, Trisha Gupte, Ming-Li Chen, Zahra Azizi, Yongfeng Zhang, Yanqiu Xing, Themistocles L. Danielle S. Bitterman, Themistocles L. Assimes, Xin Ma, Lin Lu, Lizhou Fan* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 模拟患者系统, 大型语言模型, AI代理, 医疗教育, 知识图谱

**Comment:** 64 pages, 14 figures, 16 tables

> **TL;DR:** AIPatient是一个由LLM驱动的智能模拟患者系统，在医学教育和研究中表现出色，具有高准确性、可读性、鲁棒性和可用性。

**AI_Comments:** 该论文提出了一种创新的、由LLM驱动的智能模拟患者系统AIPatient，显著提升了医学训练和模拟的真实性和效率。其结合RAG框架、多代理协作以及真实患者数据构建知识图谱的方法，有效解决了传统模拟患者系统的局限性，并提供了强大的医学问答能力。系统的鲁棒性和用户验证也增加了其应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现代医学教育和研究中，模拟患者系统扮演重要角色，提供安全、整合的医学培训环境并支持临床决策模拟，但传统系统可能存在局限性。

**Method:** 开发了AIPatient，一个由基于大型语言模型（LLM）的AI代理驱动的智能模拟患者系统。该系统结合了检索增强生成（RAG）框架，并由六个特定任务的LLM代理进行复杂推理。为了模拟现实，系统还利用从MIMIC-III数据库中去识别化的真实患者数据构建的AIPatient KG（知识图谱）。

**Result:** 系统在基于电子病历（EHR）的医学问答（QA）中实现了94.15%的准确率（所有六个AI代理都在场时），超过了部分或没有代理集成的基准。其知识库显示出高有效性（F1分数=0.89）。可读性得分显示Flesch阅读易度中位数为77.23，Flesch Kincaid年级中位数为5.6，表明对所有医疗专业人员都可访问。通过非显著方差（ANOVA F值=0.6126，p > 0.1；F值=0.782，p > 0.1）证实了鲁棒性和稳定性。一项针对医学生的用例研究表明，AIPatient在病史采集场景中提供了高保真度、强大的可用性和有效的教育价值，表现与人类模拟患者相当或更好。

**Conclusion:** AIPatient系统的智能潜力突出，有望支持广泛的应用，包括医学教育、模型评估和系统集成。

> **ai_Abstract:** AIPatient是一个基于大型语言模型（LLM）和知识图谱（KG）的智能模拟患者系统，专为医学教育和研究设计。它整合了RAG框架和六个LLM代理，并利用MIMIC-III数据库的真实患者数据构建KG。实验结果显示，AIPatient在医学问答准确性、可读性、鲁棒性和稳定性方面表现优异，并在医学生用户研究中展现出与人类模拟患者相当或更优的教育价值和可用性。该系统有望广泛应用于医学教育和模型评估等领域。

> **摘要翻译:** 模拟患者系统在现代医学教育和研究中扮演着重要角色，提供安全、整合的医学培训环境，并支持临床决策模拟。我们开发了AIPatient，一个由基于大型语言模型的AI代理驱动的智能模拟患者系统。该系统结合了检索增强生成（RAG）框架，并由六个特定任务的基于LLM的AI代理提供支持，用于复杂推理。为了模拟现实，该系统还由AIPatient KG（知识图谱）提供支持，该知识图谱是使用来自重症监护医学信息集市（MIMIC）-III数据库的去识别化真实患者数据构建的。主要结果展示了该系统的智能性，包括系统在基于电子病历（EHR）的医学问答（QA）中的准确性、可读性、鲁棒性和稳定性。当所有六个AI代理都在场时，该系统实现了94.15%的QA准确率，超过了部分或没有代理集成的基准。其知识库表现出高有效性（F1分数=0.89）。可读性得分显示，Flesch阅读易度中位数为77.23，Flesch Kincaid年级中位数为5.6，表明所有医疗专业人员都可访问。通过非显著方差（ANOVA F值=0.6126，p > 0.1；F值=0.782，p > 0.1）证实了鲁棒性和稳定性。一项针对医学生的用例研究进一步表明，AIPatient提供了高保真度、强大的可用性和有效的教育价值，在病史采集场景中表现与人类模拟患者相当或更好。AIPatient系统令人期待的智能性突显了其支持广泛应用的潜力，包括医学教育、模型评估和系统集成。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [855] [Opportunities and Challenges of LLMs in Education: An NLP Perspective](https://arxiv.org/abs/2507.22753)
> *大型语言模型在教育领域的机遇与挑战：一个自然语言处理视角*

*Sowmya Vajjala, Bashar Alhafni, Stefano Bannò, Kaushal Kumar Maurya, Ekaterina Kochmar* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 教育NLP, 辅助, 评估, 机遇与挑战

**Comment:** Pre-print

> **TL;DR:** 探讨大型语言模型在教育自然语言处理（NLP）中的机遇与挑战，并提出新方向和关键问题。

**AI_Comments:** 该论文提供了一个及时且全面的视角，审视了大型语言模型在教育NLP领域的潜力与局限。其创新之处在于将LLMs的应用场景细化为辅助和评估，并结合阅读、写作、口语和辅导等具体维度进行分析，为未来的研究和应用提供了清晰的框架。论文的重要性在于其为NLP研究人员和教育技术开发者指明了方向，有助于推动LLMs在教育领域的负责任和有效部署。虽然论文主要是一个概述性工作，但其对挑战的强调提醒了业界在追求机遇的同时，也要关注潜在的风险和技术瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于大型语言模型（LLMs）为教学、学习和评估提供的新机遇，其在教育领域的作用日益受到关注。

**Method:** 本文从自然语言处理（NLP）的角度，考察了大型语言模型（LLMs）对教育NLP的影响，主要关注辅助和评估两大应用场景，并以阅读、写作、口语和辅导四个维度为基础进行探讨。

**Result:** 文章提出了大型语言模型所带来的新方向以及需要解决的关键挑战。

**Conclusion:** 作者设想，这项全面的概述将有助于对探索大型语言模型在未来开发以语言为中心和支持自然语言处理的教育应用感兴趣的自然语言处理研究人员和从业者。

> **ai_Abstract:** 本文从自然语言处理（NLP）的角度，探讨了大型语言模型（LLMs）在教育领域日益增长的应用及其带来的机遇与挑战。研究聚焦于辅助和评估两大应用场景，并结合阅读、写作、口语和辅导四个维度，分析了LLMs对教育NLP的影响。文章进一步提出了LLMs赋能的新方向以及亟待解决的关键挑战，旨在为对LLMs在未来语言教育和NLP驱动的教育应用中作用感兴趣的研究人员和从业者提供全面的参考。

> **摘要翻译:** 考虑到大型语言模型（LLMs）为教学、学习和评估带来的新机遇，其在教育领域的作用日益受到关注。在本文中，我们从辅助和评估两个主要应用场景，并以阅读、写作、口语和辅导四个维度为基础，考察了大型语言模型对教育NLP的影响。随后，我们提出了大型语言模型所带来的新方向以及需要解决的关键挑战。我们设想，这项全面的概述将有助于对探索大型语言模型在未来开发以语言为中心和支持NLP的教育应用感兴趣的NLP研究人员和从业者。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [875] [Persona-Augmented Benchmarking: Evaluating LLMs Across Diverse Writing Styles](https://arxiv.org/abs/2507.22168)
> *人格增强基准测试：评估LLMs在不同写作风格下的表现*

*Kimberly Le Truong, Riccardo Fogliato, Hoda Heidari, Zhiwei Steven Wu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** LLM评估, 写作风格, 人格化提示, 基准测试, 性能变异性

**Comment:** 

> **TL;DR:** 当前的LLM基准测试缺乏写作风格多样性，可能导致模型在非标准输入下性能脆弱。本文通过人格化提示重写评估，发现写作风格和格式显著影响LLM性能，并提出一种可扩展的基准增强方法。

**AI_Comments:** 本文揭示了当前LLM评估基准的一个关键局限性，即写作风格多样性的缺失。使用基于人格的提示作为生成多样化风格的低成本方法，既具创新性又实用。研究发现写作风格显著影响LLM性能，且与模型无关，这对开发更鲁棒的LLM和更可靠的评估指标至关重要。这项工作有助于提高LLM评估的外部有效性。

<details>
  <summary>Details</summary>

**Motivation:** 当前的LLM评估基准缺乏足够的写作风格多样性，主要遵循标准化约定，未能充分捕捉人类交流模式的丰富性。这可能导致在这些基准上优化的LLM在面对“非标准”输入时表现出脆弱的性能。

**Method:** 通过使用基于人格的LLM提示（一种模拟不同写作风格的低成本方法）重写评估提示来检验假设。

**Result:** 结果显示，即使语义内容相同，写作风格和提示格式的变化也会显著影响LLM的估计性能。研究识别出在各种模型和任务中，无论模型家族、大小和新旧程度如何，始终导致低性能或高性能的特定写作风格。

**Conclusion:** 本研究提供了一种可扩展的方法来增强现有基准，从而提高它们在衡量LLM在语言变化方面的表现时提供的评估的外部有效性。

> **ai_Abstract:** 本文探讨了写作风格多样性对大型语言模型（LLM）性能的影响，指出当前基准缺乏这种多样性可能导致LLM在非标准输入下表现脆弱。通过使用基于人格的提示重写评估提示，研究表明写作风格和格式的变化显著影响LLM性能，即使语义内容相同。研究发现特定写作风格始终能触发高或低性能，且与模型无关。该工作提出了一种可扩展的方法来增强现有基准，以提高LLM性能评估的外部有效性。

> **摘要翻译:** 当前评估大型语言模型 (LLM) 的基准测试通常没有表现出足够的写作风格多样性，许多主要遵循标准化约定。这样的基准测试未能充分捕捉人类交流模式的丰富多样性。因此，在这些基准上优化的LLM在面对“非标准”输入时，可能会表现出脆弱的性能。在这项工作中，我们通过使用基于人格的LLM提示（一种模拟不同写作风格的低成本方法）重写评估提示来检验这一假设。我们的结果表明，即使语义内容相同，写作风格和提示格式的变化也会显著影响LLM的评估性能。值得注意的是，我们识别出在各种模型和任务中，无论模型家族、大小和新旧程度如何，始终导致低性能或高性能的特定写作风格。我们的工作提供了一种可扩展的方法来增强现有基准，从而提高它们在衡量LLM在语言变化方面的表现时提供的评估的外部有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [876] [MASCA: LLM based-Multi Agents System for Credit Assessment](https://arxiv.org/abs/2507.22758)
> *MASCA：基于LLM的多智能体信用评估系统*

*Gautam Jajoo, Pranjal A Chitale, Saksham Agarwal* | **Category: cs.CL, cs.CE, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 信用评估, 多智能体系统, LLM, 对比学习, 金融应用

**Comment:** Accepted at ACL REALM Workshop. Work in Progress

> **TL;DR:** MASCA是一个基于LLM的多智能体系统，用于改进信用评估，通过分层架构和对比学习来模拟现实世界的决策过程，并展示出优于基线方法的性能。

**AI_Comments:** MASCA的创新点在于将LLM与多智能体系统相结合，并应用于传统上依赖统计模型的信用评估领域，通过模拟真实决策过程和引入对比学习来提升性能。其分层架构和对偏差的关注也增加了系统的鲁棒性和公平性。该研究为LLM在金融领域的应用开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 信用评估传统上依赖于基于规则的方法和统计模型，但仍是一个未被充分探索的挑战。现有的金融问题解决（如交易和金融建模）已利用LLM和基于代理的系统，但在信用评估方面仍有空白。

**Method:** 本文引入了MASCA，一个由LLM驱动的多智能体系统，旨在通过模仿现实世界的决策过程来增强信用评估。该框架采用分层架构，其中专门的基于LLM的智能体协同处理子任务。此外，系统整合了对比学习用于风险和回报评估，以优化决策。论文还从信号博弈论角度阐述了分层多智能体系统，并进行了详细的信用评估偏差分析。

**Result:** 实验结果表明，MASCA优于基线方法，突出了分层基于LLM的多智能体系统在金融应用，特别是信用评分中的有效性。

**Conclusion:** MASCA证明了分层基于LLM的多智能体系统在金融应用，尤其是信用评分中的有效性，通过模仿现实世界的决策过程和整合对比学习来增强信用评估。

> **ai_Abstract:** 本文提出了MASCA，一个基于LLM的多智能体系统，旨在改进信用评估。该系统通过分层架构，让专业LLM智能体协同处理子任务，并结合对比学习进行风险回报评估以优化决策。MASCA还探讨了分层多智能体系统的信号博弈论视角，并进行了信用评估中的偏差分析。实验证明，MASCA在信用评分方面超越了现有基线方法，验证了其在金融应用中的有效性。

> **摘要翻译:** 金融问题解决的最新进展已经利用大型语言模型（LLMs）和基于智能体的系统，主要集中在交易和金融建模。然而，信用评估仍然是一个未被充分探索的挑战，传统上依赖于基于规则的方法和统计模型。在本文中，我们引入了MASCA，一个由LLM驱动的多智能体系统，旨在通过模仿现实世界的决策过程来增强信用评估。该框架采用分层架构，其中专门的基于LLM的智能体协同处理子任务。此外，我们整合了对比学习用于风险和回报评估，以优化决策。我们进一步从信号博弈论的角度阐述了分层多智能体系统，为它们的结构和交互提供了理论见解。我们的论文还包括信用评估中的详细偏差分析，解决了公平性问题。实验结果表明，MASCA优于基线方法，突出了分层基于LLM的多智能体系统在金融应用，特别是信用评分中的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [890] [DBLPLink 2.0 -- An Entity Linker for the DBLP Scholarly Knowledge Graph](https://arxiv.org/abs/2507.22811)
> *DBLPLink 2.0 -- DBLP学术知识图谱的实体链接器*

*Debayan Banerjee, Tilahun Abedissa Taffa, Ricardo Usbeck* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 实体链接, 知识图谱, DBLP, 零样本学习, 大型语言模型

**Comment:** 

> **TL;DR:** 论文提出了DBLPLink 2.0，一个针对DBLP 2025版知识图谱的零样本实体链接器，利用LLM基于“yes”token的对数概率进行候选实体重排序。

**AI_Comments:** 本文的创新点在于提出了一个基于LLM的零样本实体链接方法，这在处理不断演变的知识图谱（如DBLP新增实体类型）时具有重要意义，因为它减少了对大量标注数据的依赖。通过利用LLM的语义理解能力和对数概率进行重排序是一种新颖且有潜力的策略。

<details>
  <summary>Details</summary>

**Motivation:** DBLP知识图谱的2025版本引入了新的实体类型dblp:Stream（出版场地），需要一个新的实体链接器来处理这种变化，并且寻求一种零样本的方法。

**Method:** 开发了一个零样本实体链接器，利用大型语言模型（LLMs），通过基于LLM倒数第二层输出的“yes”token的对数概率来重新排序候选实体。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了DBLPLink 2.0，一个专为DBLP 2025版RDF知识图谱设计的实体链接器。针对DBLP新增的出版场地（dblp:Stream）实体类型，该链接器不同于早期版本依赖训练KG嵌入和重排序器，而是采用了一种创新的零样本方法，利用大型语言模型（LLMs）根据“yes”token在LLM倒数第二层的对数概率对候选实体进行重排序。

> **摘要翻译:** 在这项工作中，我们提出了一个针对DBLP 2025版基于RDF知识图谱的实体链接器。与2022版本相比，DBLP现在将出版场地视为一种新的实体类型，称为dblp:Stream。在DBLPLink的早期版本中，我们通过在数据集上训练KG嵌入和重排序器来生成实体链接。相比之下，在这项工作中，我们开发了一种使用LLM的零样本实体链接器，采用了一种新颖的方法，即我们根据LLM倒数第二层输出的“yes”token的对数概率来重新排序候选实体。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [900] [Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues](https://arxiv.org/abs/2503.06424)
> *训练基于大型语言模型的导师以提高对话中的学生学习成果*

*Alexander Scarlatos, Naiming Liu, Jaewook Lee, Richard Baraniuk, Andrew Lan* | **Category: cs.CL, cs.CY** | **Updated: 2025-07-28**

**Keywords:** LLM, 智能导师, 学生学习成果, 直接偏好优化, 教学对话

**Comment:** Published in AIED 2025: The 26th International Conference on
  Artificial Intelligence in Education

> **TL;DR:** 本文提出了一种训练大型语言模型（LLM）导师的方法，使其生成的教学话语能够最大化学生正确回答的可能性，同时保持良好的教学原则，并证明其能显著提高学生正确率。

**AI_Comments:** 本文的创新点在于结合了学生行为预测（通过LLM学生模型）和教学质量评估（通过GPT-4o）来共同指导LLM导师的训练，使其不仅遵循教学原则，更能主动优化学生学习效果。这种以学生学习成果为导向的训练范式，对于提升AI教育应用的实际效果具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AI导师虽然遵循教学原则，但未被训练来最大化对话过程中的学生学习效果，可能导致次优的互动方式。本文旨在解决这一局限性。

**Method:** 研究人员提出了一种训练LLM的方法，使其生成的话语能最大化学生正确性的可能性，同时鼓励遵循良好的教学实践。具体方法是：生成候选导师话语，并使用(1)基于LLM的学生模型预测学生正确反应的几率，以及(2)由GPT-4o评估的教学准则来评分。然后，使用这些数据通过直接偏好优化来训练开源LLM Llama 3.1 8B。

**Result:** 模型生成的导师话语显著提高了学生正确回答的几率，同时保持了GPT-4o的教学质量。定性分析和人工评估也表明模型生成了高质量的导师话语。

**Conclusion:** 通过结合学生模型预测和教学准则评估来训练LLM导师，可以有效提高学生学习成果，同时保持高质量的教学互动。

> **ai_Abstract:** 本文提出了一种新颖的训练大型语言模型（LLM）作为导师的方法，旨在优化学生在对话中的学习成果。针对现有AI导师未能最大化学生学习效果的局限性，研究人员通过生成候选导师话语并利用基于LLM的学生模型预测学生正确率及GPT-4o评估教学质量进行评分。随后，使用这些评分数据对Llama 3.1 8B进行直接偏好优化训练。实验结果表明，该方法显著提高了学生正确回答的几率，同时保持了高质量的教学互动，并通过定性分析和人工评估证实了其有效性。

> **摘要翻译:** 生成式人工智能（AI）有潜力通过大型语言模型（LLM）扩展个性化辅导。最近的AI导师通过训练或提示LLM来遵循有效的教学原则，但它们并未被训练以在整个对话过程中最大化学生的学习。因此，它们可能以次优的方式与学生互动。我们通过引入一种方法来解决这一局限性，该方法训练LLM生成导师话语，以最大化学生正确性的可能性，同时仍然鼓励模型遵循良好的教学实践。具体来说，我们生成了一组候选导师话语，并使用（1）基于LLM的学生模型来预测学生正确回答的几率，以及（2）由GPT-4o评估的教学准则对其进行评分。然后，我们使用所得数据通过直接偏好优化来训练一个开源LLM，Llama 3.1 8B。我们表明，我们的模型生成的导师话语显著提高了学生正确回答的几率，同时保持了GPT-4o的教学质量。我们还进行了定性分析和人工评估，以证明我们的模型生成了高质量的导师话语。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [904] [Beyond Natural Language Plans: Structure-Aware Planning for Query-Focused Table Summarization](https://arxiv.org/abs/2507.22829)
> *超越自然语言规划：面向查询的表格摘要的结构感知规划*

*Weijia Zhang, Songgaojun Deng, Evangelos Kanoulas* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 面向查询的表格摘要, 结构化规划, 自然语言处理, SQL生成, 多表任务

**Comment:** 10 pages, 4 figures, and 5 tables

> **TL;DR:** 该研究提出SPaGe框架，使用结构化计划（TaSoF）替代模糊的自然语言计划，实现鲁棒且可扩展的面向查询的表格摘要，并在实验中超越了现有模型。

**AI_Comments:** 该论文为复杂数据任务中自然语言处理的固有局限性提供了一个创新性解决方案。通过提出从模糊的自然语言计划转向结构化表示（特别是TaSoF和SPaGe框架），它解决了面向查询的表格摘要中的可扩展性和可靠性问题。明确地建模依赖关系和实现并行执行是显著的改进。在基准测试中持续优于现有模型，强调了这种结构化方法的重要性和有效性，可能为更鲁棒和高效的数据到文本生成系统开辟新途径。

<details>
  <summary>Details</summary>

**Motivation:** 面向查询的表格摘要中，自然语言（NL）计划存在固有的模糊性，缺乏结构，限制了其转换为SQL等可执行程序，并阻碍了可扩展性，尤其是在多表任务中。

**Method:** 提出了一种向结构化表示的范式转变，引入了新的结构化计划TaSoF和一个名为SPaGe的框架。SPaGe将推理过程形式化为三个阶段：1）结构化规划，从查询生成TaSoF；2）基于图的执行，将计划步骤转换为SQL并通过有向循环图建模依赖关系以实现并行执行；3）摘要生成，用于生成查询聚焦的摘要。

**Result:** 在三个公共基准上进行的实验表明，SPaGe在单表和多表设置中都持续优于现有模型。

**Conclusion:** 结构化表示在实现鲁棒和可扩展的面向查询的表格摘要方面具有显著优势。

> **ai_Abstract:** 本文针对面向查询的表格摘要中自然语言计划的局限性（如模糊性、缺乏结构和可扩展性问题），提出了一种新的方法。该方法引入了结构化表示，包括结构化计划TaSoF和一个名为SPaGe的三阶段框架。SPaGe涵盖了结构化规划、基于图的执行（将计划转换为SQL并建模依赖关系以实现并行执行）和摘要生成。实验结果表明，SPaGe在单表和多表场景中均持续优于现有模型，凸显了结构化表示在实现鲁棒和可扩展摘要方面的优势。

> **摘要翻译:** 查询聚焦的表格摘要需要复杂的推理，通常通过分步的自然语言（NL）计划来实现。然而，自然语言计划本质上是模糊的且缺乏结构，这限制了它们转换为SQL等可执行程序，并阻碍了可扩展性，特别是对于多表任务。为了解决这个问题，我们提出了一种向结构化表示的范式转变。我们引入了一种新的结构化计划TaSoF，其灵感来源于传统多智能体系统中的形式主义，以及一个框架SPaGe，它将推理过程形式化为三个阶段：1）结构化规划，从查询生成TaSoF；2）基于图的执行，将计划步骤转换为SQL并通过有向循环图建模依赖关系以实现并行执行；3）摘要生成，生成查询聚焦的摘要。我们的方法明确地捕获了复杂的依赖关系并提高了可靠性。在三个公共基准上的实验表明，SPaGe在单表和多表设置中都持续优于现有模型，证明了结构化表示在鲁棒和可扩展摘要方面的优势。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [910] [A Scalable Pipeline for Estimating Verb Frame Frequencies Using Large Language Models](https://arxiv.org/abs/2507.22187)
> *使用大型语言模型估算动词框架频率的可扩展管道*

*Adam M. Morgan, Adeen Flinker* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 动词框架频率, 大型语言模型, 句法分析, 可扩展管道, 语料库生成

**Comment:** 

> **TL;DR:** 本文提出了一种使用大型语言模型（LLMs）自动化估算动词框架频率（VFFs）的可扩展管道。该管道通过LLM生成语料库并进行句法分析，性能优于现有解析器，资源消耗更少，并生成了一个覆盖范围更广、区分度更高的VFF数据库。

**AI_Comments:** 这项研究的创新之处在于将大型语言模型应用于动词框架频率的自动化估算，解决了传统方法在规模、准确性和资源消耗方面的局限性。其重要性体现在提供了一个高效、可扩展的工具，能够生成更全面、更精细的VFF数据库，对句法、心理语言学和计算语言学研究具有重要价值。此外，该工作作为LLM在语言学分析中应用的概念验证，展示了LLM在复杂语言任务上的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 动词框架频率（VFFs）为人类和机器语言系统中的句法提供了重要的视角，但现有的计算工具在规模、准确性或可访问性方面存在局限性。

**Method:** 本研究使用大型语言模型（LLMs）生成包含476个英语动词的句子语料库。随后，通过指示LLM模拟语言学专家，对语料库中的句子进行句法结构分析。

**Result:** 该管道在多个评估数据集上的表现优于两种广泛使用的句法解析器。与手动解析（黄金标准）相比，它所需的资源大大减少，从而实现了快速、可扩展的VFF估算。使用LLM解析器，本研究生成了一个新的VFF数据库，该数据库具有更广泛的动词覆盖范围、更细粒度的句法区分，并明确估算了心理语言学中常研究的结构替代的相对频率。

**Conclusion:** 该管道易于定制，可扩展到新的动词、句法框架，甚至其他语言。这项工作是自动化框架频率估算的概念验证，并且所有代码和数据都已发布以支持未来的研究。

> **ai_Abstract:** 本文介绍了一种利用大型语言模型（LLMs）自动化估算动词框架频率（VFFs）的可扩展管道。该方法通过LLM生成包含大量动词的语料库，并利用LLM进行句法分析。实验结果表明，该管道在性能上超越了传统的句法解析器，同时显著降低了资源消耗，实现了高效且可扩展的VFF估算。研究还构建了一个新的VFF数据库，其特点是动词覆盖更广、句法区分更细致，并提供了结构替代的频率估算。该管道具有良好的可定制性和可扩展性，为未来的语言学研究提供了有力的工具。

> **摘要翻译:** 我们提出了一种用于估算动词框架频率（VFFs）的自动化管道，即动词在特定句法框架中出现的频率。VFFs为人类和机器语言系统中的句法提供了一个强大的窗口，但现有的计算工具在规模、准确性或可访问性方面受到限制。我们使用大型语言模型（LLMs）生成了一个包含476个英语动词的句子语料库。接下来，通过指示LLM像专家语言学家一样行事，我们让它分析了这个语料库中句子的句法结构。该管道在多个评估数据集上的表现优于两种广泛使用的句法解析器。此外，与手动解析（黄金标准）相比，它所需的资源要少得多，从而实现了快速、可扩展的VFF估算。使用LLM解析器，我们制作了一个新的VFF数据库，该数据库具有更广泛的动词覆盖范围、更细粒度的句法区分，并明确估算了心理语言学中常研究的结构替代的相对频率。该管道易于定制，可扩展到新的动词、句法框架，甚至其他语言。我们将这项工作作为自动化框架频率估算的概念验证，并发布所有代码和数据以支持未来的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [919] [Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning](https://arxiv.org/abs/2507.22887)
> *在提示中展示演示的位置：上下文学习中的位置偏差*

*Kwesi Cobbina, Tianyi Zhou* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 上下文学习, 位置偏差, 大型语言模型, 提示工程, 少样本学习

**Comment:** 

> **TL;DR:** 大型语言模型(LLM)的上下文学习(ICL)性能受提示中演示位置的影响，将演示放在提示开头能获得最稳定和准确的输出。

**AI_Comments:** 这项研究识别并量化了上下文学习中一个新颖且实际存在的“提示中演示位置（DPP）”偏差，为LLM的提示工程提供了重要的实用指导。其系统性的评估方法，跨越多种任务和模型家族，使得研究发现具有很强的普适性和鲁棒性。引入新指标来量化位置偏差的影响，也增强了研究的科学性。这项工作对于优化LLM性能和提高其在少样本学习场景下的稳定性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 上下文学习（ICL）是大型语言模型（LLM）的一项关键能力，但其性能对演示的选择和顺序敏感。本文首次探索了ICL中未被研究的新的位置偏差，即演示、系统提示和用户消息在LLM输入中位置变化时，预测和准确性会发生显著变化。

**Method:** 本文设计了一个系统性评估流程，通过分类、问答、摘要和推理任务来研究这种位置偏差。引入了“准确率变化（ACCURACY-CHANGE）”和“预测变化（PREDICTION-CHANGE）”两个指标来量化演示位置变化引起的净收益和输出波动。对来自四个开源模型家族（QWEN、LLAMA3、MISTRAL、COHERE）的十个LLM进行了广泛实验。

**Result:** 实验验证了这种偏差显著影响LLM的准确性和预测：将演示放在提示的开头能产生最稳定和准确的输出，准确率提升高达+6点。相反，将演示放在用户消息的末尾会导致超过30%的预测翻转，但并不能提高问答任务的正确性。小型模型受这种敏感性的影响最大，但即使大型模型在复杂任务上也会受到轻微影响。

**Conclusion:** 演示在提示中的位置（DPP偏差）显著影响大型语言模型的上下文学习性能，其中将演示放置在提示的开头能够获得更稳定和更准确的结果。

> **ai_Abstract:** 本文首次系统性地研究了大型语言模型（LLM）上下文学习（ICL）中的“提示中演示位置（DPP）偏差”。研究发现，提示中演示、系统提示和用户消息的位置变化会显著影响LLM的预测和准确性。通过在分类、问答、摘要和推理任务上对十个LLM进行实验，并引入了“准确率变化”和“预测变化”指标进行量化，结果表明将演示放在提示的开头能获得最稳定和准确的输出，准确率可提升高达6点；而放在用户消息末尾则可能导致大量预测翻转。该研究揭示了提示工程中演示位置的关键作用，并提供了优化ICL性能的实用指导。

> **摘要翻译:** 上下文学习（ICL）是大型语言模型（LLM）一项关键的新兴能力，通过在提示中包含少量演示（demos），可以在推理过程中实现少样本学习。然而，研究发现ICL的性能可能对演示的选择及其顺序敏感。本文首次研究了ICL中一个未被探索的新的位置偏差：我们观察到，当LLM输入中演示、系统提示和用户消息的位置发生变化时，预测和准确性会发生剧烈漂移。我们将这种偏差称为“提示中演示位置（DPP）偏差”。我们设计了一个系统性评估流程，以在分类、问答、摘要和推理任务中研究这种类型的位置偏差。我们引入了两个指标：准确率变化（ACCURACY-CHANGE）和预测变化（PREDICTION-CHANGE），以量化演示位置变化引起的净收益和输出波动。对来自四个开源模型家族（QWEN、LLAMA3、MISTRAL、COHERE）的十个LLM进行的广泛实验验证了这种偏差显著影响它们的准确性和预测：将演示放在提示的开头能产生最稳定和准确的输出，准确率提升高达+6点。相反，将演示放在用户消息的末尾会导致超过30%的预测翻转，但并不能提高问答任务的正确性。小型模型受这种敏感性的影响最大，但即使大型模型在复杂任务上也会受到轻微影响。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [923] [Which LLMs Get the Joke? Probing Non-STEM Reasoning Abilities with HumorBench](https://arxiv.org/abs/2507.21476)
> *哪些大型语言模型理解笑话？使用 HumorBench 探测非 STEM 领域的推理能力*

*Reuben Narad, Siddharth Suresh, Jiayi Chen, Pine S. L. Dysart-Bricken, Bob Mankoff, Robert Nowak, Jifan Zhang, Lalit Jain* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 幽默理解, 非STEM推理, 基准测试, HumorBench

**Comment:** 

> **TL;DR:** HumorBench 是一个新基准，用于测试大型语言模型（LLMs）的非 STEM 幽默推理能力，结果显示 STEM 推理能力可以很好地迁移到幽默理解，但增加思考令牌预算的效果不一。

**AI_Comments:** 这篇论文通过引入 HumorBench，解决了大型语言模型（LLMs）评估中一个关键的空白，即将评估范围扩展到传统的 STEM 领域之外。幽默理解是一个复杂的认知任务，将其作为基准能够独特而有效地评估非 STEM 推理能力，并突出了通用推理技能的可迁移性。此外，关于增加思考令牌预算效果不一的发现，也为未来的研究提供了有趣的见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）在数学和科学领域的基准测试中表现日益饱和，因此需要开发新颖且具有挑战性的评估方法，以衡量模型在 STEM 领域之外的智能，特别是文本幽默理解能力，因为这涉及到复杂的推理过程。

**Method:** 本研究提出了 HumorBench，一个包含约 300 对来自《纽约客》漫画大赛和 Cartoonstock.com 的独特卡通-字幕对的基准测试。这些对都附有专家注释的评估标准，用于识别关键的笑点元素。大型语言模型（LLMs）通过它们对幽默的解释以及识别笑点元素的能力进行评估。为了在此任务中取得良好表现，模型需要形成并测试关于概念间关联的假设，并可能需要回溯以得出最合理的解释。

**Result:** 1. 大型语言模型（LLMs）在 STEM 推理方面的进展能有效迁移到幽默理解。2. 仅在 STEM 推理数据上训练的模型在 HumorBench 上仍表现良好，显示出推理能力的强大可迁移性。3. 通过增加思考令牌预算进行测试时扩展，对不同模型的幽默推理产生了混合结果。

**Conclusion:** 大型语言模型（LLMs）展现出强大的推理能力迁移性，能将 STEM 领域的推理能力应用于幽默理解等复杂的非 STEM 任务，尽管增加思考令牌预算的效果因模型而异。

> **ai_Abstract:** 本文介绍了 HumorBench，一个旨在评估大型语言模型（LLMs）理解和解释卡通字幕中复杂幽默能力的创新基准，以填补非 STEM 领域智能评估的空白。该基准包含约 300 对经过专家注释的卡通-字幕对。广泛的基准测试表明，LLM 在 STEM 推理方面的进展能有效地迁移到幽默理解，并且仅在 STEM 数据上训练的模型也能在该任务上表现良好，这证明了推理能力的强大可迁移性。然而，在测试时通过增加思考令牌预算对幽默推理的影响，在不同模型之间表现出混合结果。

> **摘要翻译:** 我们提出了 HumorBench，这是一个旨在评估大型语言模型（LLMs）推理和解释卡通字幕中复杂幽默能力的基准。随着推理模型在数学和科学领域的现有基准上日益饱和，在 STEM 领域之外对模型智能进行新颖和具有挑战性的评估至关重要。推理是文本幽默理解的基础，需要识别卡通/字幕中的概念与外部文化参考、文字游戏及其他机制之间的联系。HumorBench 包含约 300 对来自《纽约客》漫画大赛和 Cartoonstock.com 的独特卡通-字幕对，并附有专家注释的评估标准，用于识别重要的笑点元素。LLM 根据其对幽默的解释以及识别笑点元素的能力进行评估。为了在此任务中表现良好，模型必须形成并检验关于概念之间关联的假设，可能需要从最初的解释回溯以得出最合理的解释。我们对当前最先进模型的广泛基准测试揭示了三个关键见解：（1）LLM 在 STEM 推理方面的进展有效地转移到幽默理解；（2）仅在 STEM 推理数据上训练的模型在 HumorBench 上仍然表现良好，这表明推理能力具有很强的可迁移性；（3）通过增加思考令牌预算进行测试时扩展，对不同模型的幽默推理产生了混合结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [930] [Persona Vectors: Monitoring and Controlling Character Traits in Language Models](https://arxiv.org/abs/2507.21509)
> *人格向量：监测和控制语言模型中的性格特征*

*Runjin Chen, Andy Arditi, Henry Sleight, Owain Evans, Jack Lindsey* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 人格向量, 语言模型, 性格控制, 模型对齐, 行为监测

**Comment:** 

> **TL;DR:** 研究引入“人格向量”来监测和控制大型语言模型中助手角色的性格偏差，并能预测和纠正训练中的性格变化。

**AI_Comments:** 这项研究提出了一种新颖且实用的方法，通过“人格向量”来量化和控制大型语言模型中的复杂性格特质。其创新之处在于将抽象的性格特征映射到模型的激活空间，并提供了监测、预测和干预的工具。这对于提升LLM的可靠性、安全性和对齐性具有重要意义，尤其是在确保模型行为符合伦理和预期方面。自动化提取和通用性是其亮点。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的“助手”角色有时会偏离其预期的“乐于助人、无害、诚实”的理想行为，这促使研究如何识别和控制这些偏差。

**Method:** 本文识别了模型激活空间中的“人格向量”，这些向量代表邪恶、谄媚和幻觉倾向等特质。研究者使用这些向量监测部署时助手个性的波动，并将其应用于预测和控制训练期间发生的个性转变。他们提出了通过后验干预或新的预防性引导方法来缓解或避免个性变化。此外，人格向量还用于在数据集和单个样本层面标记会导致不良个性变化的训练数据。提取人格向量的方法是自动化的，并且只需自然语言描述即可应用于任何感兴趣的性格特质。

**Result:** 人格向量可用于监测部署时助手个性的波动。研究发现，微调后有意和无意的个性变化与相关人格向量的偏移强烈相关。这些偏移可以通过后验干预来缓解，或通过新的预防性引导方法从一开始就避免。此外，人格向量能够有效地在数据集和单个样本层面标记会导致不良个性变化的训练数据。

**Conclusion:** 人格向量提供了一种自动化且可控的方法来监测、预测和干预大型语言模型中助手角色的性格特质。这项技术有助于确保模型行为符合预期，并提升其可靠性和安全性。

> **ai_Abstract:** 本文介绍了“人格向量”，这是一种识别和控制大型语言模型中“助手”角色性格特质（如邪恶、谄媚、幻觉）的方法。这些向量可用于监测部署时的个性波动，预测和纠正训练期间的个性变化，并通过干预或预防性引导来缓解不良转变。此外，它们还能识别导致不良性格变化的训练数据，其提取过程自动化且仅需自然语言描述。

> **摘要翻译:** 大型语言模型通过模拟的“助手”角色与用户交互。虽然助手通常被训练成乐于助人、无害且诚实的，但它有时会偏离这些理想。在本文中，我们识别了模型激活空间中的方向——人格向量——这些方向是邪恶、谄媚和产生幻觉倾向等几种特质的基础。我们确认这些向量可以用于在部署时监测助手个性的波动。然后，我们将人格向量应用于预测和控制训练期间发生的个性转变。我们发现，微调后有意和无意的个性变化与相关人格向量的偏移强烈相关。这些偏移可以通过后验干预来缓解，或者通过一种新的预防性引导方法从一开始就避免。此外，人格向量可以用于标记会产生不良个性变化的训练数据，无论是在数据集层面还是单个样本层面。我们提取人格向量的方法是自动化的，并且只需自然语言描述即可应用于任何感兴趣的性格特质。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [60] [Settling Weighted Token Swapping up to Algorithmic Barriers](https://arxiv.org/abs/2507.22450)
> *解决加权令牌交换的算法障碍问题*

*Nicole Wein, Guanyu, Zhang* | **Category: cs.DS** | **Updated: 2025-07-30**

**Keywords:** 加权令牌交换, 近似算法, 算法障碍, 图论, NP-难

**Comment:** 

> **TL;DR:** 本文首次为加权令牌交换问题提供了近似算法和紧密障碍结果，解决了在通用图和树上的近似比率问题。

**AI_Comments:** 这项工作填补了加权令牌交换问题在近似算法方面的空白，特别是在正权值情况下。它不仅提供了具体的近似比率，还提出了紧密的算法障碍，这对于理解该问题的计算复杂性和可近似性具有重要意义。创新点在于首次提供了该问题的近似算法，并明确了算法性能的理论上限。

<details>
  <summary>Details</summary>

**Motivation:** 已有的研究主要集中在无权令牌交换问题，而加权令牌交换，特别是正权值情况，缺乏已知的近似算法和明确的下界。本文旨在填补这一空白，提供首个近似算法和紧密障碍结果。

**Method:** 本文提出了针对加权令牌交换问题的近似算法，并导出了紧密的障碍结果。具体算法细节未在摘要中提及，但提到了其输出是近似比率。

**Result:** 提供了加权令牌交换在通用图和树上的首个近似算法，以及紧密的障碍结果。对于通用图，近似比率为 $2+2W/w$；对于树，近似比率为 $1+W/w$，其中 $w$ 和 $W$ 分别是最小和最大令牌权重。

**Conclusion:** 本文通过提供加权令牌交换问题的首个近似算法和紧密障碍结果，显著推进了对该问题的理解，特别是在通用图和树上的可近似性方面。

> **ai_Abstract:** 本文研究加权令牌交换问题，该问题旨在通过最小化相邻令牌交换成本来达到目标配置。现有研究主要集中于无权或特殊加权情况，而对正权加权令牌交换的近似算法知之甚少。本文首次为通用图和树上的加权令牌交换问题提供了近似算法，并给出了紧密的算法障碍结果。具体地，对于通用图，近似比率为 $2+2W/w$；对于树，近似比率为 $1+W/w$，其中 $w$ 和 $W$ 分别是最小和最大令牌权重。

> **摘要翻译:** 我们研究加权令牌交换问题，在该问题中，给定一个具有 $n$ 个顶点的图、$n$ 个加权令牌、每个顶点的初始令牌分配以及每个顶点的最终令牌分配。目标是找到一个最小成本的相邻令牌交换序列，以从初始分配达到最终分配，其中成本是所有交换中两个交换令牌的权重之和的总和。无权令牌交换已得到广泛研究：它在近似因子优于 $14/13$ 的情况下是 NP 难的，并且存在一个多项式时间 4-近似算法，以及一个紧密的“障碍”结果，表明局部最优算法的类别无法实现优于 4 的比率。对于树，该问题仍然是精确求解的 NP 难问题，并且存在一个多项式时间 2-近似算法，以及一个紧密的障碍结果，表明 $\ell$-straying 算法的类别无法实现优于 2 的比率。具有 \{0,1\} 权重的加权令牌交换在近似方面要困难得多：对于任何常数 $\varepsilon>0$，即使近似到 $(1-\varepsilon) \cdot \ln n$ 的因子也是 NP 难的。限制为正权重时，没有已知的近似算法，并且唯一已知的下界是直接从无权版本继承的。我们首次为树和通用图上的加权令牌交换提供了近似算法，以及紧密的障碍结果。设 $w$ 和 $W$ 分别是最小和最大令牌权重，我们的近似比率对于通用图是 $2+2W/w$，对于树是 $1+W/w$。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [102] [Deterministic Longest Common Subsequence Approximation in Near-Linear Time](https://arxiv.org/abs/2507.22486)
> *近线性时间内确定性最长公共子序列近似算法*

*Itai Boneh, Shay Golan, Matan Kraus* | **Category: cs.DS, F.2.0** | **Updated: 2025-07-30**

**Keywords:** 最长公共子序列, 近似算法, 确定性算法, 近线性时间, 亚线性近似比

**Comment:** 

> **TL;DR:** 该论文提出了一种新的确定性算法，能在近线性时间内为最长公共子序列（LCS）问题提供$O(n^{3/4} 	ext{log} n)$的近似解，这是首次在近线性时间内实现亚线性近似比的确定性LCS近似算法。

**AI_Comments:** 该论文的主要创新在于首次实现了在近线性时间内求解LCS问题的确定性亚线性近似比算法，这在理论上是一个显著的突破，对于处理大规模序列数据具有潜在的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种能够在近线性时间内为最长公共子序列（LCS）问题提供亚线性近似比的确定性算法，填补了此前缺乏此类算法的空白。

**Method:** 提出了一种确定性算法，用于计算两个长度为$n$的输入序列的最长公共子序列（LCS）的近似解。

**Result:** 该算法在近线性时间内为LCS问题提供了$O(n^{3/4} 	ext{log} n)$的近似比。这是第一个在近线性时间内实现亚线性近似比的确定性LCS近似算法。

**Conclusion:** 该研究成功开发了首个在近线性时间内实现亚线性近似比的确定性最长公共子序列近似算法，显著推进了LCS近似算法的理论发展。

> **ai_Abstract:** 本论文介绍了一种确定性算法，该算法能够在近线性时间内计算两个长度为$n$的序列的最长公共子序列（LCS）的$O(n^{3/4} 	ext{log} n)$近似解。这是首个在近线性时间内达到亚线性近似比的确定性LCS近似算法，填补了该领域的一个重要空白。

> **摘要翻译:** 我们提供了一种确定性算法，该算法在近线性时间内为两个长度为$n$的输入序列的最长公共子序列（LCS）输出一个$O(n^{3/4} 	ext{log} n)$的近似解。这是第一个在近线性时间内实现亚线性近似比的确定性LCS近似算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [137] [BlockFIFO & MultiFIFO: Scalable Relaxed Queues](https://arxiv.org/abs/2507.22764)
> *BlockFIFO & MultiFIFO：可伸缩的松弛队列*

*Stefan Koch, Peter Sanders, Marvin Williams* | **Category: cs.DS, D.1.3; E.1** | **Updated: 2025-07-30**

**Keywords:** 并发队列, FIFO, 松弛语义, 可伸缩性, 吞吐量

**Comment:** 25 pages

> **TL;DR:** 本文提出了两种新的松弛并发FIFO队列设计BlockFIFO和MultiFIFO，它们在吞吐量和可伸缩性方面均优于现有技术。

**AI_Comments:** 这项工作通过引入两种新的松弛队列设计，有效地解决了并发FIFO队列中严格语义导致的性能瓶颈。其创新之处在于提出了两种正交的方法，并证明了它们在实际应用中的优越性，这对于需要高吞吐量和可伸缩性的并发系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在并发FIFO队列中，严格的FIFO语义会导致队列头尾的高度竞争，从而降低吞吐量。通过放宽FIFO语义以允许元素重新排序，可以实现更高的可伸缩性。

**Method:** 本文提出了两种正交设计的松弛并发FIFO队列：一种源自MultiQueue，另一种基于环形缓冲区。这两种设计在各种微基准测试和大型图上的广度优先搜索应用中进行了广泛评估。

**Result:** 这两种设计在吞吐量和可伸缩性方面均优于最先进的松弛和严格FIFO队列。

**Conclusion:** 通过放宽FIFO语义，BlockFIFO和MultiFIFO设计能够显著提高并发队列的吞吐量和可伸缩性，证明了松弛队列在高性能应用中的优越性。

> **ai_Abstract:** 本文针对并发FIFO队列中严格语义导致的低吞吐量问题，提出了两种创新的松弛并发FIFO队列设计：BlockFIFO和MultiFIFO。这两种设计分别基于MultiQueue和环形缓冲区，旨在通过放宽FIFO语义来提高可伸缩性。实验结果表明，BlockFIFO和MultiFIFO在吞吐量和可伸缩性方面均显著优于现有技术，包括严格和松弛的FIFO队列。

> **摘要翻译:** FIFO队列是广泛应用于各种应用程序中的基本数据结构。并发FIFO队列允许多个执行线程同时访问队列。在并发队列中保持严格的FIFO语义会导致队列头尾的高度竞争，从而降低吞吐量。通过放宽FIFO语义以允许一些元素的重新排序，可以实现更高的可伸缩性。这项工作提出了两种正交设计的松弛并发FIFO队列，一种源自MultiQueue，另一种基于环形缓冲区。我们在各种微基准测试和大型图上的广度优先搜索应用程序中广泛评估了这两种设计。这两种设计都优于最先进的松弛和严格FIFO队列，实现了更高的吞吐量和更好的可伸缩性。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [194] [A new width parameter of graphs based on edge cuts: $α$-edge-crossing width](https://arxiv.org/abs/2302.04624)
> *基于边割的新图宽度参数：$\alpha$-边交叉宽度*

*Yeonsu Chang, O-joung Kwon, Myounghwan Lee* | **Category: cs.DS, cs.DM, math.CO** | **Updated: 2025-07-30**

**Keywords:** 图宽度参数, 边交叉宽度, 树割分解, FPT算法, 列表染色

**Comment:** 28 pages, 3 figures, accepted to WG2023

> **TL;DR:** 引入了新的图宽度参数$\alpha$-边交叉宽度和边交叉宽度，其中$\alpha$-边交叉宽度是新参数，并提出了其近似算法和在列表染色等问题上的FPT算法，填补了复杂性空白。

**AI_Comments:** 这篇论文的创新点在于引入了新的图宽度参数$\alpha$-边交叉宽度，并对其性质进行了深入分析，特别是它与现有参数（如树割宽度、树划分宽度和边割宽度）之间的关系。其重要性体现在为图算法提供了一个新的参数化角度，并通过证明在$\alpha$-边交叉宽度参数下列表染色和预染色扩展问题是FPT可解的，成功填补了图参数化复杂性理论中的一个重要空白。这为解决一些之前被认为是W[1]-hard的问题提供了新的途径，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文引入了新的图宽度参数$\alpha$-边交叉宽度和边交叉宽度，其灵感来源于最近提出的边割宽度（edge-cut width），旨在进一步探索和理解图宽度参数。

**Method:** 论文定义了$\alpha$-边交叉宽度和边交叉宽度，它们基于树割分解（tree-cut decomposition）中的袋（bag）的边交叉数。作者提供了一个算法，对于给定的n顶点图G和整数k和$\alpha$，能在$2^{O((\alpha+k)\log (\alpha+k))}n^2$时间内输出一个树割分解，证明G的$\alpha$-边交叉宽度至多为$2\alpha^2+5k$，或者确认其宽度大于k。

**Result:** 边交叉宽度被证明等价于已知的树划分宽度（tree-partition-width）。$\alpha$-边交叉宽度是一个新参数，与树割宽度（tree-cut width）不可比较，且两者都介于树划分宽度和边割宽度之间。对于每个固定的$\alpha$，论文获得了列表染色（List Coloring）和预染色扩展（Precoloring Extension）问题的FPT算法，这些算法以$\alpha$-边交叉宽度为参数。这填补了这些问题在树划分宽度（W[1]-hard）和边割宽度（FPT）之间的复杂性空白。

**Conclusion:** 论文成功引入了新的图宽度参数$\alpha$-边交叉宽度，并为其开发了有效的近似算法。通过将其应用于列表染色和预染色扩展问题，作者证明了其作为参数可以导致FPT算法，从而解决了图参数化复杂性理论中的一个重要开放问题。

> **ai_Abstract:** 这篇论文引入了新的图宽度参数：$\alpha$-边交叉宽度和边交叉宽度，它们是基于树割分解中边交叉数定义的，并受边割宽度的启发。研究发现边交叉宽度与树划分宽度等价，而$\alpha$-边交叉宽度是新参数，与树割宽度不可比但介于树划分宽度和边割宽度之间。论文还提出了一个用于近似计算$\alpha$-边交叉宽度的算法，并展示了其在列表染色和预染色扩展问题上的应用，通过以$\alpha$-边交叉宽度为参数实现了FPT算法，成功弥补了相关问题在不同参数下的复杂性差距。

> **摘要翻译:** 我们引入了图宽度参数，称为$\alpha$-边交叉宽度和边交叉宽度。这些参数是根据树割分解（tree-cut decomposition）中一个袋（bag）所交叉的边数来定义的。它们的灵感来源于Brand等人最近（WG 2022）引入的边割宽度（edge-cut width）。我们证明了边交叉宽度等价于已知的树划分宽度（tree-partition-width）。另一方面，$\alpha$-边交叉宽度是一个新参数；树割宽度（tree-cut width）和$\alpha$-边交叉宽度是不可比较的，并且它们都介于树划分宽度和边割宽度之间。
我们提供了一种算法，对于给定的n顶点图G和整数k以及$\alpha$，该算法在$2^{O((\alpha+k)\log (\alpha+k))}n^2$时间内，要么输出一个树割分解，证明G的$\alpha$-边交叉宽度至多为$2\alpha^2+5k$，要么确认G的$\alpha$-边交叉宽度大于k。作为应用，对于每个固定的$\alpha$，我们获得了以$\alpha$-边交叉宽度为参数的列表染色（List Coloring）和预染色扩展（Precoloring Extension）问题的FPT算法。已知这些问题在以树划分宽度为参数时是W[1]-hard的，而在以边割宽度为参数时是FPT的，我们从而填补了这两个参数之间的复杂性空白。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [228] [Tighter Approximation for the Uniform Cost-Distance Steiner Tree Problem](https://arxiv.org/abs/2305.03381)
> *均匀成本距离Steiner树问题的更紧密逼近*

*Josefine Foos, Stephan Held, Yannik Kyle Dustin Spitzley* | **Category: cs.DS, 90C27, 68W25, 68M10, G.2.1; G.2.2; F.2.2; B.7.2** | **Updated: 2025-07-30**

**Keywords:** Steiner树, 逼近算法, 成本距离, 优化, 信号传输

**Comment:** arXiv admin note: substantial text overlap with arXiv:2211.03830;
  Version 2: Addition of examples (tightness of the analysis, worst-case for
  any cut-and-reconnect algorithm, optimality gap of the lower bound in the
  Manhatten Plane)

> **TL;DR:** 改进了均匀成本距离Steiner树问题的逼近算法，将逼近因子从2.39降至2.05。

**AI_Comments:** 本文的主要创新在于显著提高了均匀成本距离Steiner树问题的逼近因子，并提供了更严格的理论分析，揭示了算法逼近下限的紧致性。

<details>
  <summary>Details</summary>

**Motivation:** 该问题旨在最小化总长度与从根节点到其他终端的加权路径长度之和，应用于芯片设计或电信网络中的信号传输。

**Method:** 类似于现有方法，从近似最小长度Steiner树开始，将其分割成子树并重新连接。通过更仔细地将树分割成组件，同时考虑成本结构，并显著增强分析，从而改进了逼近因子。

**Result:** 将均匀成本距离Steiner树问题的最佳逼近因子从2.39提升到2.05。如果可以任意好地逼近最小长度Steiner树问题，算法可达到任意接近 $ 1 + \frac{1}{\sqrt{2}} $ 的逼近因子。还证明了最优解与下界之间存在 $ 1 + \frac{1}{\sqrt{2}} $ 的差距。

**Conclusion:** 本文将均匀成本距离Steiner树问题的最佳逼近因子提升至2.05，并证明了其逼近下限的紧致性。

> **ai_Abstract:** 本文研究了均匀成本距离Steiner树问题，该问题旨在最小化总长度与加权路径长度之和，并应用于信号传输。作者提出了一种新的算法，通过更精细地分割近似最小长度Steiner树并考虑成本结构，将该问题的最佳逼近因子从2.39提高到2.05。研究还证明了该算法的逼近因子可以达到任意接近 $ 1 + \frac{1}{\sqrt{2}} $，并证明了此下界的紧致性。

> **摘要翻译:** 均匀成本距离Steiner树旨在最小化总长度与从专用根节点到其他终端的加权路径长度之和。当树用于信号传输时，例如在芯片设计或电信网络中，它们会被应用。它们是通用成本距离Steiner树的特例，其中总长度和路径长度使用不同的距离函数。
我们改进了均匀成本距离Steiner树问题的最佳已发布逼近因子，从2.39提高到2.05。如果我们可以任意好地逼近最小长度Steiner树问题，我们的算法可以实现任意接近 $ 1 + \frac{1}{\sqrt{2}} $ 的逼近因子。这个界限在以下意义上是紧密的。我们还证明了我们和所有先前针对此问题的逼近算法所使用的最优解与下界之间存在 $ 1 + \frac{1}{\sqrt{2}} $ 的差距。
与以前的方法类似，我们从一个近似最小长度Steiner树开始，并将其分割成随后重新连接的子树。为了提高逼近因子，我们更仔细地将其分割成组件，同时考虑成本结构，并显著增强了分析。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [270] [Breaking the Sorting Barrier for Directed Single-Source Shortest Paths](https://arxiv.org/abs/2504.17033)
> *突破有向图单源最短路径的排序障碍*

*Ran Duan, Jiayi Mao, Xiao Mao, Xinkai Shu, Longhui Yin* | **Category: cs.DS, F.2.2** | **Updated: 2025-07-30**

**Keywords:** 单源最短路径, Dijkstra算法, 图算法, 时间复杂度, 确定性算法

**Comment:** 17 pages

> **TL;DR:** 一种新的确定性算法在稀疏有向图上实现了比Dijkstra算法更快的单源最短路径（SSSP）时间复杂度，证明Dijkstra算法并非最优。

**AI_Comments:** 这篇论文在图算法领域取得了重要的理论进展，打破了单源最短路径（SSSP）的长期复杂性障碍。其创新之处在于找到了一种在稀疏图上优于Dijkstra算法的算法，而Dijkstra算法此前被认为是此问题的最优解。这一结果挑战了传统认知，并为最短路径算法的研究开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 旨在寻找比Dijkstra算法更快的单源最短路径（SSSP）算法，因为Dijkstra算法曾被认为是稀疏图上的最优解。

**Method:** 提出了一种确定性算法，在比较-加法模型下，用于解决具有实数非负边权重的有向图上的单源最短路径（SSSP）问题。

**Result:** 提出了一种在比较-加法模型下，针对具有实数非负边权重的有向图的单源最短路径（SSSP）的确定性算法，时间复杂度为$O(m\log^{2/3}n)$。这是首次打破Dijkstra算法在稀疏图上的$O(m+n\log n)$时间界限。

**Conclusion:** Dijkstra算法对于单源最短路径（SSSP）并非最优。

> **ai_Abstract:** 本文提出了一种针对具有非负边权重的有向图上的单源最短路径（SSSP）问题的新型确定性算法。该算法在比较-加法模型下实现了$O(m\log^{2/3}n)$的时间复杂度。这一重大突破首次超越了Dijkstra算法在稀疏图上长期保持的$O(m+n\log n)$时间界限，从而证明了Dijkstra算法对于SSSP并非最优。

> **摘要翻译:** 我们提出了一种确定性算法，在比较-加法模型下，对于具有实数非负边权重的有向图，单源最短路径（SSSP）的时间复杂度为$O(m\log^{2/3}n)$。这是首次打破Dijkstra算法在稀疏图上的$O(m+n\log n)$时间界限，表明Dijkstra算法对于SSSP并非最优。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [311] [Reweighted Spectral Partitioning Works: Bounds for Special Graph Classes](https://arxiv.org/abs/2506.01228)
> *重加权谱划分有效：特殊图类的界限*

*Jack Spalding-Jamieson* | **Category: cs.DS, cs.CG, cs.DM** | **Updated: 2025-07-30**

**Keywords:** 谱划分, 重加权谱划分, 稀疏顶点割, 顶点分离器, 图类

**Comment:** 42 pages, 8 figures

> **TL;DR:** 本文展示了重加权谱划分方法在各种图类中能保证近乎最优的稀疏顶点割和顶点分离器，且对最大度数的依赖性很小。

**AI_Comments:** 本文的创新之处在于提出了“重加权谱划分”方法，有效解决了传统谱划分在处理最大度数依赖性上的不足。其重要性在于为图论中的稀疏割和分离器问题提供了更普适且性能更优的解决方案，并对经典定理如平面分离器定理进行了新的证明和改进。

<details>
  <summary>Details</summary>

**Motivation:** 传统的谱划分方法在计算某些图类的稀疏割和边分离器时，其性能对最大度数存在次优的依赖性。本文旨在提出一种改进的方法来解决这一限制。

**Method:** 本文提出并应用了“重加权谱划分”方法。通过计算拉普拉斯矩阵的第二个最小特征值（和特征向量），并结合专门的降维步骤，该方法旨在获得更好的稀疏顶点割和顶点分离器。

**Result:** 重加权谱划分方法在各种图类中保证了近乎最优的稀疏顶点割和顶点分离器，且在许多情况下对最大度数的依赖性很小或没有。此外，本文还获得了平面分离器定理的新证明、有界亏格图的强化特征值界限，以及通过专门的降维步骤得到的顶点扩展Cheeger型不等式的改进形式。

**Conclusion:** 重加权谱划分是一种有效且改进的方法，能够在多种图类中找到高质量的稀疏顶点割和顶点分离器，克服了传统谱划分方法对最大度数次优依赖的问题，并为图论中的一些经典问题提供了新的见解和更强的界限。

> **ai_Abstract:** 本文研究了重加权谱划分方法，发现它在多种图类中能有效找到近乎最优的稀疏顶点割和顶点分离器，且对最大度数的依赖性显著降低。这解决了传统谱划分方法在最大度数依赖上的次优问题。此外，本研究还提供了平面分离器定理的新证明、有界亏格图的强化特征值界限以及改进的顶点扩展Cheeger型不等式。

> **摘要翻译:** 谱划分是一种可以通过计算拉普拉斯矩阵的第二个最小特征值（和特征向量）来计算各种图类中小的稀疏割或小的边分离器的方法。针对某些图类，该特征值的上限意味着该方法可以获得小的边分离器，但通常对最大度数的依赖性是次优的。在这项工作中，我们展示了一种相关方法，称为重加权谱划分，可以保证在各种图类中获得近乎最优的稀疏顶点割和顶点分离器。在许多情况下，这几乎不需要或完全不需要依赖最大度数。我们还获得了平面分离器定理的新证明，有界亏格图的强化特征值界限，以及通过专门的降维步骤得到的顶点扩展Cheeger型不等式的改进形式。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [563] [Towards Tight Bounds for Estimating Degree Distribution in Streaming and Query Models](https://arxiv.org/abs/2507.21784)
> *趋近流式和查询模型中度分布估计的紧密界限*

*Arijit Bishnu, Debarshi Chanda, Gopinath Mishra* | **Category: cs.DS, cs.SI** | **Updated: 2025-07-29**

**Keywords:** 度分布, ccdh, 流式模型, 查询模型, 下界

**Comment:** 28 pages, 13 Figures

> **TL;DR:** 本文设计了一种算法来近似互补累积度直方图 (ccdh)，并在流式和查询模型中为其建立了第一个下界，从而几乎解决了该问题的复杂性。

**AI_Comments:** 本文的创新之处在于首次为互补累积度直方图 (ccdh) 的估计问题在流式和查询模型中建立了紧密的下界，这对于理解和解决该问题的计算复杂性具有重要意义。同时，文章也提供了一种实用的近似算法，其效率在次线性模型中得到了证明。这项工作对图算法和大规模数据处理领域具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 图的度分布及其衍生的互补累积度直方图 (ccdh) 是图分析中理解实体关系和总结图结构的基础。然而，近似 ccdh 的精确复杂性此前未知，并且是 WOLA 2019 的一个开放问题。

**Method:** 作者首先设计了一种算法，该算法在能够获得合适的顶点样本和边样本的情况下可以近似 ccdh，且独立于任何次线性模型。接着，他们证明了在流式和查询模型中可以高效地获取这些样本。此外，作者还首次为该问题在查询和流式模型中建立了下界。

**Result:** 本文设计了一种能够近似 ccdh 的算法，并证明了其所需的样本可以在流式和查询模型中高效获取。最重要的是，本文首次为该问题在查询和流式模型中建立了下界，并（几乎）解决了该问题在两种次线性模型中的复杂性。

**Conclusion:** 本文通过设计近似算法和建立严格的下界，几乎完全解决了在流式和查询模型中估计互补累积度直方图 (ccdh) 的复杂性问题。

> **ai_Abstract:** 本文研究了在流式和查询模型中估计图的互补累积度直方图 (ccdh) 的问题。针对这个此前复杂性未知的开放问题，作者首先提出了一种基于顶点和边样本的 ccdh 近似算法，并证明了这些样本可以在流式和查询模型中高效获取。更重要的是，本文首次为该问题在这些模型中建立了下界，从而几乎完全解决了其精确复杂性。

> **摘要翻译:** 图 $G=(V,E)$ 的度分布，$|V|=n$，$|E|=m$，是图分析中最基本的研究对象之一，因为它体现了实体之间的关系。特别是，度分布的一个重要派生分布是互补累积度直方图 (ccdh)。ccdh 是图结构的基本摘要，它捕获了对于每个阈值 $d$，度至少为 $d$ 的顶点的数量。为了近似 ccdh，我们考虑了 $(\varepsilon_D,\varepsilon_R)$-双准则乘法近似，它允许在域和范围上进行受控的乘法松弛。该问题的精确复杂性尚不清楚，并且在 WOLA 2019 [Sublinear.info，问题 98] 中被提出为一个开放问题。
在这项工作中，我们首先设计了一种算法，如果可以获得合适的顶点样本和边样本，则可以近似 ccdh，因此该算法独立于任何次线性模型。接下来，我们展示了在流式和查询模型中，可以高效地获取这些样本。另一方面，我们为查询和流式模型中的这个问题建立了第一个下界，并（几乎）解决了该问题在两种次线性模型中的复杂性。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [242] [Text-Driven Video Style Transfer with State-Space Models: Extending StyleMamba for Temporal Coherence](https://arxiv.org/abs/2503.12291)
> *文本驱动视频风格迁移与状态空间模型：扩展StyleMamba以实现时间连贯性*

*Chao Li, Minsu Park, Cristina Rossi, Zhuang Li* | **Category: cs.GR** | **Updated: 2025-07-29**

**Keywords:** 视频风格迁移, 状态空间模型, StyleMamba, 时间连贯性, 文本驱动

**Comment:** arXiv admin note: This paper has been withdrawn by arXiv due to
  disputed and unverifiable authorship and affiliation

> **TL;DR:** 本文将StyleMamba框架扩展到视频序列，通过引入新的时间模块和损失函数，实现了文本驱动的视频风格迁移，提高了风格一致性和平滑度，并具有计算效率。

**AI_Comments:** 本文的创新点在于将StyleMamba这一在图像风格迁移中表现出色的框架成功扩展到视频领域，并通过引入针对视频特性的新模块和损失函数（如视频状态空间融合模块、时间遮蔽定向损失和时间二阶损失），有效解决了视频风格迁移中关键的时间连贯性和风格一致性问题。其在计算效率上的提升也预示着在实时应用中的巨大潜力，是文本驱动视频风格化领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** StyleMamba在图像风格迁移方面表现出色，但现有方法在视频风格迁移中面临时间连贯性、风格一致性、场景变化和部分遮挡等挑战。本文旨在将StyleMamba扩展到视频，解决这些问题，实现实时、高质量的文本驱动视频风格化。

**Method:** 本文将StyleMamba框架扩展到视频序列。提出了新的时间模块，包括一个“视频状态空间融合模块”来建模帧间依赖性，以及一个新颖的“时间遮蔽定向损失”来确保风格一致性，同时处理场景变化和部分遮挡。此外，引入了“时间二阶损失”来抑制连续帧之间的突变风格变化。

**Result:** 在DAVIS和UCF101上的实验表明，所提出的方法在风格一致性、平滑度和计算效率方面优于竞争方法。

**Conclusion:** 本文提出的新框架为实现具有最先进感知结果的实时文本驱动视频风格化铺平了道路。

> **ai_Abstract:** 本文将高效的文本驱动图像风格迁移框架StyleMamba扩展到视频领域，通过引入视频状态空间融合模块、时间遮蔽定向损失和时间二阶损失，有效解决了视频风格迁移中的时间连贯性、风格一致性及帧间平滑性问题。实验证明，该方法在性能和效率上均优于现有方法，为实时视频风格化提供了新途径。

> **摘要翻译:** StyleMamba最近通过利用状态空间模型（SSM）和掩蔽定向损失，展示了高效的文本驱动图像风格迁移。在本文中，我们将StyleMamba框架扩展到处理视频序列。我们提出了新的时间模块，包括一个用于建模帧间依赖的“视频状态空间融合模块”，以及一个新颖的“时间掩蔽定向损失”，该损失在处理场景变化和部分遮挡的同时确保风格一致性。此外，我们引入了“时间二阶损失”以抑制连续帧之间突变的风格变化。我们在DAVIS和UCF101上的实验表明，所提出的方法在风格一致性、平滑度和计算效率方面优于竞争方法。我们相信我们的新框架为实现具有最先进感知结果的实时文本驱动视频风格化铺平了道路。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [284] [Controllable Segmentation-Based Text-Guided Style Editing](https://arxiv.org/abs/2503.16129)
> *可控的基于分割的文本引导风格编辑*

*Jingwen Li, Aravind Chandrasekar, Mariana Rocha, Chao Li, Yuqing Chen* | **Category: cs.GR** | **Updated: 2025-07-29**

**Keywords:** 风格编辑, 语义分割, 文本引导, StyleMamba, 区域特定

**Comment:** arXiv admin note: This paper has been withdrawn by arXiv due to
  disputed and unverifiable authorship and affiliation

> **TL;DR:** 一种新的基于文本提示的可控区域特定风格编辑方法，通过集成语义分割模型，实现高保真区域转换。

**AI_Comments:** 这项工作的主要创新点在于将语义分割模型与文本引导的风格迁移相结合，实现了前所未有的区域级精细控制。这解决了传统全局风格迁移方法无法满足的特定区域编辑需求，极大地提升了用户对风格化过程的控制力。其在StyleMamba基础上的扩展，以及引入区域条件向量和方向损失，都显示了其技术深度。该方法在实际应用中，尤其是在图像创作和编辑领域，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有风格迁移方法可能缺乏区域特异性控制，无法根据文本提示对图像的特定区域进行精细化风格编辑。

**Method:** 该方法在StyleMamba的状态空间风格对齐框架基础上，集成了语义分割模型到风格迁移流程中。通过引入区域条件向量和区域特定方向损失，实现基于文本提示的区域风格编辑，同时保持其他区域不变。

**Result:** 实验证明，该方法能够灵活处理真实世界场景中的复杂风格化，并在控制和质量方面优于纯粹的全局风格迁移方法，实现了高保真转换，同时尊重语义边界和用户驱动的风格描述。

**Conclusion:** 该方法通过结合语义分割和文本提示，显著提升了风格编辑的区域控制能力和转换质量，优于传统的全局风格迁移方法。

> **ai_Abstract:** 本文提出了一种新颖的、基于文本提示的可控区域特定风格编辑方法。该方法在StyleMamba框架上，通过集成语义分割模型，允许用户对图像的特定区域进行风格修改，同时保持其他区域不变。通过引入区域条件向量和区域特定方向损失，该方法实现了高保真转换，并尊重语义边界和用户描述。实验证明，该方法能灵活处理复杂场景，并在控制和质量上超越了全局风格迁移方法。

> **摘要翻译:** 我们提出了一种由文本提示驱动的可控、区域特定风格编辑的新方法。在StyleMamba引入的状态空间风格对齐框架基础上，我们的方法将语义分割模型集成到风格迁移管线中。这允许用户选择性地将文本驱动的风格变化应用于特定区域（例如，“将建筑物变成赛博朋克塔”），同时保持其他区域（例如，“人物”或“树木”）不变。通过结合区域条件向量和区域特定方向损失，我们的方法实现了高保真转换，同时尊重语义边界和用户驱动的风格描述。大量的实验表明，我们的方法可以灵活处理真实世界场景中的复杂风格化，相较于纯粹的全局风格迁移方法，提高了控制和质量。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [326] [Multi-Prompt Style Interpolation for Fine-Grained Artistic Control](https://arxiv.org/abs/2503.16133)
> *多提示风格插值实现精细化艺术控制*

*Lei Chen, Hao Li, Yuxin Zhang, Chao Li, Kai Wen* | **Category: cs.GR** | **Updated: 2025-07-29**

**Keywords:** 文本驱动风格迁移, 多提示, 风格插值, StyleMamba, 艺术控制

**Comment:** arXiv admin note: This paper has been withdrawn by arXiv due to
  disputed and unverifiable authorship and affiliation

> **TL;DR:** 提出一种多提示风格插值框架，扩展了StyleMamba，实现图像中精细化、多样的艺术风格融合，超越单提示方法。

**AI_Comments:** 该论文的创新点在于提出了多提示风格插值框架，突破了传统单提示风格迁移的限制，显著提升了艺术控制的精细度和表现力。通过结合多提示嵌入混合器、自适应混合权重和分层掩蔽定向损失，实现了对多风格融合的精准控制，为文本驱动的图像风格化带来了更广阔的可能性。其在保持计算效率的同时，实现了卓越的性能提升，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本驱动图像风格迁移方法大多只支持单一文本风格提示，限制了艺术控制范围和表现力。

**Method:** 提出一种新颖的多提示风格插值框架，扩展了StyleMamba。该方法支持在多个文本提示（如立体主义、印象派、卡通）之间进行混合或插值，以在单一图像中创建细致或混合的艺术风格。引入了多提示嵌入混合器（Multi-Prompt Embedding Mixer）与自适应混合权重（Adaptive Blending Weights），实现对每种风格空间和语义影响的精细控制。此外，提出分层掩蔽定向损失（Hierarchical Masked Directional Loss）来优化区域特定的风格一致性。

**Result:** 实验和用户研究证实，该方法优于单提示基线和简单的风格线性组合，实现了卓越的风格保真度、文本-图像对齐和艺术灵活性，同时保持了状态空间公式提供的计算效率。

**Conclusion:** 该论文成功开发了一种多提示风格插值框架，显著增强了文本驱动图像风格迁移中的艺术控制和表现力，性能优于现有方法。

> **ai_Abstract:** 本文提出了一种新颖的多提示风格插值框架，扩展了StyleMamba，旨在解决现有文本驱动图像风格迁移方法在艺术控制和表现力上的局限性。该框架允许在单一图像中融合或插值多种文本风格提示（如“立体主义”、“印象派”），通过引入多提示嵌入混合器、自适应混合权重和分层掩蔽定向损失，实现对风格影响的精细控制和区域一致性。实验结果表明，该方法在风格保真度、文本-图像对齐和艺术灵活性方面优于单提示基线和简单组合方法，同时保持了计算效率。

> **摘要翻译:** 文本驱动的图像风格迁移方法利用跨模态嵌入实现了快速、高质量的风格化，取得了显著进展。然而，大多数现有流程假定单一文本风格提示，限制了艺术控制和表现力的范围。在本文中，我们提出了一种新颖的“多提示风格插值”框架，扩展了最近引入的StyleMamba方法。我们的方法支持在多个文本提示（例如，“立体主义”、“印象派”和“卡通”）之间进行混合或插值，从而可以在单一图像中创建细致或混合的艺术风格。我们引入了“多提示嵌入混合器”与“自适应混合权重”相结合，以实现对每种风格的空间和语义影响的精细控制。此外，我们提出了一种“分层掩蔽定向损失”来优化区域特定的风格一致性。实验和用户研究证实，我们的方法优于单提示基线和简单的风格线性组合，实现了卓越的风格保真度、文本-图像对齐和艺术灵活性，同时保持了状态空间公式提供的计算效率。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [367] [ReverBERT: A State Space Model for Efficient Text-Driven Speech Style Transfer](https://arxiv.org/abs/2503.20992)
> *ReverBERT：一种用于高效文本驱动语音风格迁移的状态空间模型*

*Michael Brown, Sofia Martinez, Priya Singh* | **Category: cs.GR, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 文本驱动语音风格迁移, 状态空间模型, ReverBERT, 计算效率, 语音合成

**Comment:** arXiv admin note: This paper has been withdrawn by arXiv due to
  disputed and unverifiable authorship and affiliation

> **TL;DR:** ReverBERT是一个高效的文本驱动语音风格迁移框架，利用状态空间模型（SSM）和新颖的Transformer-based SSM层，显著降低了计算成本，同时保持了高质量的语音输出。

**AI_Comments:** ReverBERT的创新之处在于将状态空间模型（SSM）范式引入文本驱动语音风格迁移，并结合了Transformer-based SSM层以优化效率。它解决了现有方法计算成本高的问题，为该领域提供了一个高效且高质量的解决方案。其在语音空间而非图像空间操作，并利用DFT进行风格调制，是其独特之处。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本驱动语音风格迁移方法计算成本高昂。

**Method:** 本文提出了ReverBERT，一个受状态空间模型（SSM）范式启发的高效框架。该方法在语音空间中操作，并整合了潜在语音特征的离散傅里叶变换（DFT），以实现平滑和连续的风格调制。此外，还提出了一种新颖的基于Transformer的SSM层，用于连接文本风格描述符与声学属性。

**Result:** ReverBERT在基准语音语料库上的实验表明，其在自然度、表现力和计算效率方面显著优于现有基线模型。

**Conclusion:** ReverBERT提供了一种高效且高质量的文本驱动语音风格迁移解决方案，通过显著降低推理时间并保持高语音质量，克服了现有方法的计算成本问题。作者还公开发布了模型和代码，以促进该领域的进一步研究。

> **ai_Abstract:** 本文提出了ReverBERT，一个高效的文本驱动语音风格迁移框架。该模型借鉴了状态空间模型（SSM）范式，并在语音空间中进行操作，利用离散傅里叶变换实现平滑风格调制。通过引入创新的Transformer-based SSM层，ReverBERT显著降低了推理时间，同时保持了高质量的语音输出。实验证明，ReverBERT在自然度、表现力和计算效率上均优于现有基线方法。

> **摘要翻译:** 文本驱动的语音风格迁移旨在将语音的语调、语速和音色塑造成与文本描述中的风格线索相匹配。虽然现有方法利用大规模神经网络架构或预训练语言模型，但计算成本通常仍然很高。在本文中，我们提出了ReverBERT，一个用于文本驱动语音风格迁移的高效框架，它从状态空间模型（SSM）范式中汲取灵感， loosely 受Wang和Liu~\[wang2024stylemamba\]的基于图像的方法启发。与图像领域的技术不同，我们的方法在语音空间中操作，并整合了潜在语音特征的离散傅里叶变换，以实现平滑和连续的风格调制。我们还提出了一种新颖的基于Transformer的SSM层，用于连接文本风格描述符与声学属性，大大减少了推理时间，同时保持了高质量的语音特征。在基准语音语料库上进行的大量实验表明，ReverBERT在自然度、表现力和计算效率方面显著优于基线模型。我们公开发布了我们的模型和代码，以促进文本驱动语音风格迁移领域的进一步研究。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [698] [Learning Simulatable Models of Cloth with Spatially-varying Constitutive Properties](https://arxiv.org/abs/2507.21288)
> *学习具有空间变异本构特性的可模拟布料模型*

*Guanxiong Chen, Shashwat Suri, Yuhao Wu, Etienne Voulga, David I. W. Levin, Dinesh Pai* | **Category: cs.GR, cs.AI** | **Updated: 2025-07-28**

**Keywords:** 布料模拟, 质量-弹簧网络, 空间变异特性, 机器学习, 膜锁定

**Comment:** 

> **TL;DR:** 本文提出了Mass-Spring Net框架，通过运动数据学习布料的空间变异材料特性，解决了传统有限元方法的计算昂贵和膜锁定问题，实现了更快的训练、更高的精度和更好的泛化能力。

**AI_Comments:** 该研究的创新点在于提出了Mass-Spring Net框架，通过数据驱动的方式学习布料的空间变异特性，并有效解决了有限元模拟中长期存在的“膜锁定”问题。其重要性在于提供了一种高效、准确且鲁棒的布料模拟方法，有望在电影、游戏和虚拟现实等领域有广泛应用。

<details>
  <summary>Details</summary>

**Motivation:** 现实布料材料复杂且具有空间变异性；现有模拟方法（如有限元）计算昂贵、速度慢，且存在“膜锁定”等数值伪影，导致布料显得僵硬。

**Method:** 提出Mass-Spring Net通用框架，用于学习简单高效的替代模型；将布料离散化为质量-弹簧网络，利用新的力-冲量损失函数，直接从运动数据中学习未知材料参数。

**Result:** 能够准确建模各种数据源的空间变异材料特性；对有限元模拟中常见的膜锁定问题具有免疫力；与图网络和神经ODE架构相比，训练时间显著缩短，重建精度更高，对新动态场景的泛化能力更强。

**Conclusion:** Mass-Spring Net框架有效解决了布料模拟中的挑战，提供了一种高效、准确且鲁棒的解决方案。

> **ai_Abstract:** 本文提出了一个名为Mass-Spring Net的通用框架，旨在解决现实布料模拟中遇到的计算复杂和“膜锁定”问题。该框架通过将布料离散化为质量-弹簧网络，并利用新颖的力-冲量损失函数，直接从运动数据中学习布料的空间变异材料特性，从而构建一个高效的替代模型。实验结果表明，该方法能准确建模复杂材料，避免膜锁定，并比现有方法具有更快的训练速度、更高的精度和更强的泛化能力。

> **摘要翻译:** 标题：学习具有空间变异本构特性的可模拟布料模型
摘要：真实服装中使用的材料由于缝合、卷边、染色、印花、填充和粘合等常见工艺，表现出显著的复杂性和空间变异性。模拟这些材料，例如使用有限元方法，通常计算量大且速度慢。更糟糕的是，这些方法可能遭受称为“膜锁定”的数值伪影，使布料显得异常僵硬。本文提出一个通用框架，称为Mass-Spring Net，用于学习一个简单而高效的替代模型，该模型仅使用运动观测数据捕获这些复杂材料的效果。布料被离散化为具有未知材料参数的质量-弹簧网络，这些参数使用新颖的力-冲量损失函数直接从运动数据中学习。我们的方法展示了从各种数据源准确建模空间变异材料特性的能力，并且对困扰基于有限元模拟的膜锁定具有免疫力。与基于图网络和神经ODE的架构相比，我们的方法实现了显著更快的训练时间、更高的重建精度以及对新动态场景的改进泛化能力。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [862] [TiVy: Time Series Visual Summary for Scalable Visualization](https://arxiv.org/abs/2507.18972)
> *TiVy：可伸缩可视化的时间序列视觉摘要*

*Gromit Yeuk-Yin Chan, Luis Gustavo Nonato, Themis Palpanas, Cláudio T. Silva, Juliana Freire* | **Category: cs.GR, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 时间序列, 可视化, 可伸缩性, 动态时间规整, 序列模式

**Comment:** to be published in TVCG (IEEE VIS 2025)

> **TL;DR:** 提出TiVy算法，通过序列模式总结时间序列，以解决大规模时间序列可视化中的可伸缩性和视觉清晰度问题，提供更清晰、更快的可视化结果。

**AI_Comments:** TiVy的创新之处在于其结合了DTW和序列模式来总结时间序列，这与传统的聚类方法不同，它能提取长度可变且时间对齐的相似子序列，从而更好地处理时间序列数据的特性。其在性能上的显著提升（1000倍加速）对于大规模时间序列数据的实时可视化具有重要意义，解决了现有方法在可伸缩性上的痛点。

<details>
  <summary>Details</summary>

**Motivation:** 现有时间序列可视化方法在处理大规模数据时，存在可伸缩性和视觉清晰度之间的权衡问题，导致长时间跨度的数据可视化时出现视觉混乱（过多的微型图或重叠线条），难以有效识别趋势和模式。

**Method:** 提出TiVy算法，通过以下步骤总结时间序列：1. 使用动态时间规整（DTW）将时间序列基于子序列视觉相似性转换为一组符号序列。2. 根据频繁的序列模式构建相似子序列的非交集分组。3. 生成的时间序列视觉摘要提供更清晰的叠加和更少的微型图。TiVy与传统聚类不同，它提取的是时间上对齐的（长度可变）相似子序列。同时，还提供了一个交互式时间序列可视化工具，可以实时渲染大规模时间序列。

**Result:** 1. 在可视化时间序列数据时，提取出清晰准确的模式。2. 与直接的DTW聚类相比，实现了显著的加速（1000倍）。3. 在两种使用场景中，展示了探索海量时间序列数据中隐藏结构的效率。

**Conclusion:** TiVy算法通过创新的序列模式总结方法，有效解决了大规模时间序列可视化中的可伸缩性和视觉清晰度挑战，能够提取清晰准确的模式，并实现显著的性能提升，从而帮助用户更好地探索时间序列数据中的隐藏结构。

> **ai_Abstract:** 本论文提出TiVy算法，旨在解决大规模时间序列可视化中可伸缩性与视觉清晰度之间的矛盾。TiVy通过利用动态时间规整（DTW）将时间序列转换为符号序列，并基于频繁序列模式对相似子序列进行分组，从而生成一个简洁的视觉摘要，减少了视觉混乱。实验结果表明，TiVy能有效提取准确模式，并相比传统DTW聚类实现千倍加速，提高了探索海量时间序列数据的效率。

> **摘要翻译:** 可视化多个时间序列在可伸缩性和视觉清晰度之间存在根本性的权衡。时间序列捕捉了许多大规模真实世界过程的行为，从股市趋势到城市活动。用户通常通过将它们可视化为折线图，并并置或叠加多个时间序列来比较它们并识别趋势和模式，从而获得洞察。然而，现有表示在可伸缩性方面存在困难：当覆盖较长时间跨度时，会导致过多的微型图或重叠线条造成的视觉混乱。我们提出了TiVy，一种使用序列模式总结时间序列的新算法。它使用动态时间规整（DTW）将时间序列基于子序列视觉相似性转换为一组符号序列，然后根据频繁的序列模式构建相似子序列的非交集分组。分组结果是时间序列的视觉摘要，提供更清晰的叠加和更少的微型图。与常见的聚类技术不同，TiVy提取的是时间上对齐的（长度可变）相似子序列。我们还提出了一个交互式时间序列可视化工具，可以实时渲染大规模时间序列。我们的实验评估表明，我们的算法（1）在可视化时间序列数据时提取出清晰准确的模式，（2）与直接的DTW聚类相比，实现了显著的加速（1000倍）。我们还在两种使用场景中展示了我们方法在探索海量时间序列数据中隐藏结构的效率。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [866] [V2M4: 4D Mesh Animation Reconstruction from a Single Monocular Video](https://arxiv.org/abs/2503.09631)
> *V2M4：从单目视频重建4D网格动画*

*Jianqi Chen, Biao Zhang, Xiangjun Tang, Peter Wonka* | **Category: cs.GR, eess.IV** | **Updated: 2025-07-29**

**Keywords:** 4D重建, 网格动画, 单目视频, 姿态估计, 纹理优化

**Comment:** Accepted by ICCV 2025. Project page:
  https://windvchen.github.io/V2M4/

> **TL;DR:** V2M4是一种新颖的方法，可以直接从单个单目视频生成可用的4D网格动画资产，通过解决现有3D网格生成模型在4D任务中的问题，输出高质量动画。

**AI_Comments:** V2M4的创新点在于它直接利用原生3D网格生成模型进行4D重建，而不是依赖多视角图像/视频生成模型的先验知识，这可能为单目视频的4D重建开辟了新的途径。其提出的结构化工作流程，特别是针对网格一致性问题的多阶段优化，是解决该任务核心挑战的关键。该方法能够生成与主流图形和游戏软件兼容的动画资产，显示出其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法依赖于多视角图像和视频生成模型的先验知识，而本文的方法基于原生3D网格生成模型。然而，直接将3D网格生成模型应用于4D任务（为每帧生成网格）会导致网格姿态不正确、外观错位以及几何和纹理图不一致的问题。

**Method:** 我们提出了一个结构化的工作流程来解决上述问题，包括：相机搜索和网格姿态调整、用于网格外观优化的条件嵌入优化、用于拓扑一致性的成对网格配准，以及用于纹理一致性的全局纹理图优化。

**Result:** 我们的方法输出高质量的4D动画资产，这些资产与主流图形和游戏软件兼容。在各种动画类型和运动幅度的实验结果证明了我们方法的泛化性和有效性。

**Conclusion:** V2M4成功地解决了从单个单目视频重建4D网格动画的挑战，通过其创新的结构化工作流程，生成了高质量且兼容的动画资产，展现出良好的泛化性和有效性。

> **ai_Abstract:** 本文介绍了V2M4，一种创新的4D重建方法，能够直接从单个单目视频生成可用的4D网格动画资产。与依赖多视角先验的现有方法不同，V2M4基于原生3D网格生成模型。为解决直接应用于4D任务时出现的网格姿态、外观、几何和纹理不一致问题，作者提出了一个结构化工作流程，包含相机搜索与姿态调整、条件嵌入优化、成对网格配准和全局纹理优化。实验结果表明，V2M4能够输出与主流软件兼容的高质量4D动画资产，并具有良好的泛化性和有效性。

> **摘要翻译:** 我们提出了V2M4，一种新颖的4D重建方法，可以直接从单个单目视频生成可用的4D网格动画资产。与依赖多视角图像和视频生成模型先验知识的现有方法不同，我们的方法基于原生3D网格生成模型。将3D网格生成模型直接应用于4D任务中为每一帧生成网格会导致网格姿态不正确、网格外观错位以及网格几何和纹理图不一致等问题。为了解决这些问题，我们提出了一个结构化的工作流程，包括相机搜索和网格姿态调整、用于网格外观优化的条件嵌入优化、用于拓扑一致性的成对网格配准，以及用于纹理一致性的全局纹理图优化。我们的方法输出高质量的4D动画资产，这些资产与主流图形和游戏软件兼容。在各种动画类型和运动幅度的实验结果证明了我们方法的泛化性和有效性。项目页面：https://windvchen.github.io/V2M4/。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [925] [Fast Globally Optimal and Geometrically Consistent 3D Shape Matching](https://arxiv.org/abs/2504.06385)
> *快速全局最优和几何一致的3D形状匹配*

*Paul Roetzer, Florian Bernard* | **Category: cs.GR, cs.CV** | **Updated: 2025-07-29**

**Keywords:** 3D形状匹配, 几何一致性, 全局最优, 超图, 最小成本循环流

**Comment:** 8 pages main paper, 9 pages supplementary

> **TL;DR:** 本文提出了一种新颖的方法，通过将3D形状匹配建模为超积图上的最小成本循环流问题，实现了快速、全局最优且几何一致的3D形状匹配。

**AI_Comments:** 本文的创新点在于提出了一个新颖的数学框架，将3D形状匹配问题转化为超图上的最小成本循环流问题，从而实现了全局最优和几何一致的匹配，且无需严格的初始化假设，提高了实用性。该方法在处理几何一致性方面具有显著优势，对纹理迁移和统计形状建模等应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 几何一致性是3D形状匹配中一个重要且自然的先验，对于纹理迁移或统计形状建模等下游应用至关重要。然而，在实践中，几何一致性常常被忽视，或者仅在严格限制的假设下（例如良好的初始化）才能实现。

**Method:** 本文提出了一种新颖的形式化方法。其核心思想是将源形状的表面表示为循环路径的集合，然后将其与目标形状进行一致匹配。数学上，通过构建源形状和目标形状之间的超积图，并将3D形状匹配问题转化为该超图中的最小成本循环流问题，从而获得全局几何一致的匹配。

**Result:** 实验表明，本文提出的形式化方法可以高效求解，并能产生高质量的结果。

**Conclusion:** 本文提出的新颖形式化方法能够实现3D形状之间全局最优且几何一致的匹配，并且在实践中具有可扩展性。

> **ai_Abstract:** 本文提出了一种新颖的3D形状匹配形式化方法，旨在实现全局最优和几何一致的匹配，并解决现有方法在几何一致性方面的不足。该方法将源形状表面表示为循环路径集合，并将其与目标形状进行匹配。通过构建源形状和目标形状的超积图，并将匹配问题转化为最小成本循环流问题，实现了高效且高质量的全局几何一致性匹配。实验结果验证了该方法的有效性。

> **摘要翻译:** 几何一致性，即邻域的保持，是3D形状匹配中一个自然且强大的先验。几何一致的匹配对于许多下游应用至关重要，例如纹理迁移或统计形状建模。然而，在实践中，几何一致性常常被忽视，或者仅在严格限制的假设下（例如良好的初始化）才能实现。在这项工作中，我们提出了一种新颖的形式化方法，用于计算3D形状之间全局最优且几何一致的匹配，该方法在实践中具有可扩展性。我们的关键思想是将源形状的表面表示为循环路径的集合，然后将其与目标形状进行一致匹配。在数学上，我们构建了一个超积图（在源形状和目标形状之间），然后将3D形状匹配问题转化为该超图中的最小成本循环流问题，从而得到两个形状之间全局几何一致的匹配。我们通过实验证明，我们的形式化方法可以高效求解，并且能够产生高质量的结果。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [68] [Enhancing Graph-based Recommendations with Majority-Voting LLM-Rerank Augmentation](https://arxiv.org/abs/2507.21563)
> *通过多数投票LLM重排序增强来提升基于图的推荐系统*

*Minh-Anh Nguyen, Bao Nguyen, Ha Lan N. T., Tuan Anh Hoang, Duc-Trong Le, Dung D. Le* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 推荐系统, 数据增强, LLM, 多数投票, 图推荐

**Comment:** 

> **TL;DR:** 本文提出了一种利用LLM和多数投票进行数据增强的新框架，以解决推荐系统中的数据稀疏性和流行度偏差问题，并在图推荐系统中取得了显著改进。

**AI_Comments:** 该论文的创新点在于将LLMs应用于推荐系统的数据增强，通过多数投票机制生成高置信度的合成交互数据，并将其与图对比学习相结合，有效解决了数据稀疏性和流行度偏差问题。这种结合LLM能力和图神经网络的方法为推荐系统提供了一个有前景的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 推荐系统常因用户-物品交互有限导致数据稀疏性，这会降低系统性能并放大现实世界中的流行度偏差。

**Method:** 本文提出了一种新颖的数据增强框架，利用大型语言模型（LLMs）和物品文本描述来丰富交互数据。通过多次少样本提示LLMs对物品进行重排序，并通过多数投票聚合结果，生成高置信度的合成用户-物品交互数据。为有效利用增强数据，将其整合到图对比学习框架中，以减轻分布偏移并缓解流行度偏差。

**Result:** 实验结果表明，本文方法提高了准确性并减少了流行度偏差，性能优于强大的基线方法。

**Conclusion:** 通过LLM重排序和多数投票的数据增强，可以有效缓解推荐系统中的数据稀疏性和流行度偏差问题，显著提升基于图的推荐系统性能。

> **ai_Abstract:** 本文针对推荐系统中数据稀疏性和流行度偏差问题，提出了一种基于LLM和多数投票的新型数据增强框架。该框架通过LLM对物品进行重排序并结合多数投票生成高置信度合成交互数据，并将其融入图对比学习框架以减轻分布偏移。实验证明，该方法有效提升了推荐准确性并降低了流行度偏差。

> **摘要翻译:** 推荐系统常因用户-物品交互有限导致数据稀疏性，这会降低系统性能并放大现实世界中的流行度偏差。本文提出了一种新颖的数据增强框架，利用大型语言模型（LLMs）和物品文本描述来丰富交互数据。通过多次少样本提示LLMs对物品进行重排序，并通过多数投票聚合结果，我们生成了高置信度的合成用户-物品交互数据，并有基于测度集中理论的理论保证。为了在图推荐系统环境中有效利用增强数据，我们将其整合到图对比学习框架中，以减轻分布偏移并缓解流行度偏差。大量实验表明，我们的方法提高了准确性并减少了流行度偏差，性能优于强大的基线方法。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [188] [Multi-Modal Hypergraph Enhanced LLM Learning for Recommendation](https://arxiv.org/abs/2504.10541)
> *多模态超图增强LLM推荐学习*

*Xu Guo, Tong Zhang, Yuanzhi Wang, Chenxu Wang, Fuyun Wang, Xudong Wang, Xiaoya Zhang, Xin Liu, Zhen Cui* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 超图, LLM, 推荐系统, 多模态, 对比学习

**Comment:** 12 pages, 4 figures, submitted to IEEE Transactions on Knowledge and
  Data Engineering

> **TL;DR:** 本文提出HeLLM框架，通过融合超图结构和序列行为模式，增强LLM在推荐系统中捕获复杂高阶语义关联的能力。

**AI_Comments:** 该论文的创新点在于将超图结构引入LLM，以捕获推荐场景中复杂的高阶语义关联和多模态信息，弥补了现有LLM方法在图结构利用上的不足。通过将图级上下文与序列级行为模式融合，并结合对比学习，提升了LLM在推荐任务中的感知能力和表示区分度，为LLM在推荐领域的应用提供了新的思路和有效方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于LLM的推荐方法未能充分探索推荐场景中固有的多视图图结构关联。

**Method:** 提出HeLLM框架，在推荐预训练阶段设计用户超图以发现用户共享兴趣偏好，设计物品超图以捕获物品多模态相似性。引入超图卷积和协同对比学习机制增强表示的可区分性。在LLM微调阶段，将学习到的图结构嵌入直接注入LLM架构，并整合捕获用户时间行为的序列特征，使LLM能利用图结构信息作为全局上下文，增强感知复杂关系模式和整合多模态信息的能力，同时建模局部时间动态。

**Result:** 大量实验证明所提出的方法优于最先进的基线方法。

**Conclusion:** 将基于超图的上下文与LLM中的序列用户行为融合，在推荐方面具有优势。

> **ai_Abstract:** 本文提出了一种名为HeLLM的新型框架，旨在解决现有LLM推荐方法未能充分利用多视图图结构关联的问题。HeLLM通过构建用户和物品超图来捕捉高阶语义关联和多模态相似性，并结合超图卷积和对比学习来增强表示。在LLM微调阶段，将这些图结构嵌入与序列行为特征相结合，使LLM能够更好地理解全局上下文和局部动态，从而提升推荐性能。实验结果验证了该方法的优越性。

> **摘要翻译:** 大型语言模型（LLM）的蓬勃发展正在推动个性化推荐系统的发展。大多数现有的基于LLM的方法未能充分探索推荐场景中固有的多视图图结构关联。为此，我们提出了一个新颖的框架，用于多模态推荐的超图增强LLM学习（HeLLM），旨在使LLM能够通过融合图级上下文信号与序列级行为模式来捕获复杂的更高阶语义关联。在推荐预训练阶段，我们设计了一个用户超图来揭示用户之间共享的兴趣偏好，并设计了一个物品超图来捕获物品之间多模态相似性中的关联。引入超图卷积和协同对比学习机制以增强学习表示的可区分性。在LLM微调阶段，我们将学习到的图结构嵌入直接注入LLM的架构，并整合捕获每个用户时间行为的序列特征。这个过程使超图能够利用图结构信息作为全局上下文，增强LLM感知复杂关系模式和整合多模态信息的能力，同时也能建模局部时间动态。大量的实验证明了我们提出的方法优于最先进的基线方法，证实了在LLM中融合基于超图的上下文与序列用户行为在推荐方面的优势。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [200] [Intent-Aware Neural Query Reformulation for Behavior-Aligned Product Search](https://arxiv.org/abs/2507.22213)
> *意图感知神经查询重构用于行为对齐的产品搜索*

*Jayanth Yetukuri, Ishita Khan* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 意图感知, 查询重构, 电商搜索, 买家意图, 行为分析

**Comment:** Accepted at SIGIR eCom'25.
  https://sigir-ecom.github.io/eCom25Papers/paper_23.pdf

> **TL;DR:** 该研究提出一个数据管道和框架，通过挖掘大规模买家查询日志中的显式和隐式行为信号来理解和建模用户意图，从而实现意图感知的查询重写，显著提升电商搜索系统的检索相关性和用户参与度。

**AI_Comments:** 该论文的创新之处在于其提出的数据管道和框架，能够从大规模用户行为数据中提取细粒度的隐式和显式意图信号，并将其应用于查询重构。通过将查询重写与用户真实意图对齐，而非仅仅依赖表面词汇，显著提升了电商搜索系统的性能。这项工作为构建更智能、更符合用户需求的产品发现系统提供了有价值的见解和可扩展的基础。

<details>
  <summary>Details</summary>

**Motivation:** 在电商搜索系统中，理解和建模买家意图是优化搜索查询重构的一个基础性挑战。

**Method:** 该工作引入了一个强大的数据管道，旨在挖掘和分析大规模买家查询日志，重点从显式交互和隐式行为线索中提取细粒度意图信号。该管道利用先进的序列挖掘技术和监督学习模型，系统地捕获指示潜在购买意图的模式，从而构建一个高保真、富含意图的数据集。所提出的框架通过将重构基于推断的用户意图而非表面词汇信号，促进了自适应查询重写策略的开发。

**Result:** 查询重写与底层用户目标的这种对齐增强了检索相关性和下游参与度指标。在多个产品垂直领域的实证评估表明，在面向精度的相关性指标上取得了可衡量的收益，突显了意图感知重构的有效性。

**Conclusion:** 研究结果强调了以意图为中心的建模在弥合稀疏用户输入与复杂产品发现目标之间差距的价值，并为未来在用户对齐的神经检索和排名系统中的研究奠定了可扩展的基础。

> **ai_Abstract:** 本文提出一种意图感知的神经查询重构方法，旨在解决电商搜索中理解和建模买家意图的挑战。研究构建了一个数据管道，通过序列挖掘和监督学习从大规模查询日志中提取细粒度意图信号，并形成意图丰富的数据集。该框架将查询重写与用户推断意图对齐，而非仅依赖词汇信号，从而显著提升了产品搜索的检索相关性和用户参与度。实证评估证明了该意图感知重构策略的有效性，并为未来用户对齐的神经检索系统奠定了基础。

> **摘要翻译:** 理解和建模买家意图是优化电商搜索系统动态环境中的搜索查询重构的一项基础性挑战。这项工作引入了一个强大的数据管道，旨在挖掘和分析大规模买家查询日志，重点是从显式交互和隐式行为线索中提取细粒度的意图信号。该管道利用先进的序列挖掘技术和监督学习模型，系统地捕获指示潜在购买意图的模式，从而构建了一个高保真、富含意图的数据集。所提出的框架通过将重构基于推断的用户意图而非表面词汇信号，促进了自适应查询重写策略的开发。查询重写与底层用户目标的这种对齐增强了检索相关性和下游参与度指标。在多个产品垂直领域的实证评估表明，在面向精度的相关性指标上取得了可衡量的收益，突显了意图感知重构的有效性。我们的发现强调了以意图为中心的建模在弥合稀疏用户输入与复杂产品发现目标之间差距的价值，并为未来在用户对齐的神经检索和排名系统中的研究奠定了可扩展的基础。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [235] [Generative Recommendation with Semantic IDs: A Practitioner's Handbook](https://arxiv.org/abs/2507.22224)
> *基于语义ID的生成式推荐：从业者手册*

*Clark Mingxuan Ju, Liam Collins, Leonardo Neves, Bhuvesh Kumar, Louis Yufeng Wang, Tong Zhao, Neil Shah* | **Category: cs.IR** | **Updated: 2025-07-29**

**Keywords:** 生成式推荐, 语义ID, 开源框架, 基准测试, 协同过滤

**Comment:** 

> **TL;DR:** 该论文介绍并开源了GRID，一个用于带有语义ID的生成式推荐的框架，旨在促进系统性基准测试和研究，并揭示了架构组件的重要性。

**AI_Comments:** 该论文通过提供一个统一的开源框架，解决了生成式推荐领域的一个重要实际挑战。这一贡献极具价值，因为它促进了可复现性，便于系统性比较不同的GR组件，并加速了该领域的未来研究和开发。发现被忽视的架构组件对性能有实质性影响也是一个关键的见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有文献中，带有语义ID的生成式推荐（GR）模型存在建模技术、超参数和实验设置多样化的问题，导致难以直接比较。此外，缺乏一个开源的统一框架来支持系统性基准测试和扩展，这减缓了模型迭代的速度。

**Method:** 作者介绍并开源了一个名为GRID的模块化框架，用于带有语义ID的生成式推荐。他们利用GRID在公共基准上系统地实验并消融了带有SID的GR模型的不同组件。

**Result:** 通过GRID进行的全面实验表明，带有语义ID的生成式推荐模型中许多被忽视的架构组件会显著影响性能。

**Conclusion:** 研究结果提供了新颖的见解，并验证了开源平台（GRID）对于稳健基准测试和推进生成式推荐研究的实用性。

> **ai_Abstract:** 该论文旨在解决带有语义ID的生成式推荐（GR）模型在比较和迭代方面的挑战，这些挑战源于方法多样性和缺乏统一框架。为此，它介绍并开源了一个名为GRID的模块化框架，旨在促进系统性实验和加速研究。通过利用GRID进行的全面实验，作者证明了被忽视的架构组件对性能有显著影响，从而提供了新颖的见解，并验证了该平台对于稳健基准测试和推进GR研究的实用性。

> **摘要翻译:** 生成式推荐（GR）因其相较于传统模型的出色性能而受到越来越多的关注。促成GR成功的关键因素是语义ID（SID），它将连续的语义表示（例如，来自大型语言模型）转换为离散的ID序列。这使得带有SID的GR模型既能整合语义信息，又能学习协同过滤信号，同时保留离散解码的优势。然而，现有文献中多样的建模技术、超参数和实验设置使得GR方案之间的直接比较具有挑战性。此外，缺乏一个开源的统一框架阻碍了系统性基准测试和扩展，从而减缓了模型迭代。为了解决这一挑战，我们的工作介绍并开源了一个用于带有语义ID的生成式推荐的框架，即GRID，它专门设计为模块化以方便组件互换并加速想法迭代。我们使用GRID在公共基准上系统地实验并消融了带有SID的GR模型的不同组件。我们使用GRID进行的全面实验表明，带有SID的GR模型中许多被忽视的架构组件会显著影响性能。这既提供了新颖的见解，又验证了开源平台对于稳健基准测试和GR研究进展的实用性。GRID已在https://github.com/snap-research/GRID 开源。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [277] [Multi-modal Relational Item Representation Learning for Inferring Substitutable and Complementary Items](https://arxiv.org/abs/2507.22268)
> *多模态关系项目表示学习用于推断替代品和互补品*

*Junting Wang, Chenghuan Guo, Jiao Yang, Yanhui Guo, Yan Gao, Hari Sundaram* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 多模态, 项目表示学习, 替代品, 互补品, 自监督学习

**Comment:** 

> **TL;DR:** 本文提出MMSC，一个新颖的自监督多模态关系项目表示学习框架，用于推断替代品和互补品。MMSC通过结合多模态数据和自监督学习，有效解决了现有方法中用户行为数据噪声和数据稀疏性问题，并在推荐任务中显著优于现有基线，同时对冷启动项目表现良好。

**AI_Comments:** MMSC的创新之处在于其结合了多模态信息、自监督学习和大型语言模型进行数据增强，以克服传统方法在处理噪声和稀疏用户行为数据方面的局限性。其分层表示聚合机制也值得关注。该框架在提升推荐性能，尤其是在冷启动项目上的表现，显示出重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法主要侧重于从用户行为中推断项目间关联或利用项目内容信息，但这些方法常忽略关键挑战，如用户行为数据噪声和长尾分布导致的数据稀疏性。

**Method:** 本文提出了MMSC，一个自监督多模态关系项目表示学习框架。MMSC包含三个主要组件：1) 多模态项目表示学习模块，利用多模态基础模型并从项目元数据中学习；2) 自监督行为表示学习模块，对用户行为数据进行去噪和学习；3) 分层表示聚合机制，整合语义和任务层面的项目表示。此外，还利用大型语言模型（LLMs）生成增强训练数据，以进一步提升训练过程中的去噪效果。

**Result:** MMSC在五个真实世界数据集上进行了广泛实验，结果显示其在替代品推荐方面比现有基线高出26.1%，在互补品推荐方面高出39.2%。此外，实验表明MMSC在建模冷启动项目方面也有效。

**Conclusion:** MMSC框架通过结合多模态信息、自监督学习和去噪机制，成功解决了推断替代品和互补品时面临的用户行为数据噪声和数据稀疏性问题，显著提升了推荐性能，并有效处理了冷启动项目。

> **ai_Abstract:** 本文提出MMSC，一个创新的自监督多模态关系项目表示学习框架，旨在解决现有方法在推断替代品和互补品时面临的用户行为数据噪声和数据稀疏性问题。MMSC包含多模态项目表示学习、自监督行为表示学习和分层表示聚合三大模块，并利用LLMs进行数据增强。实验证明，MMSC在替代品和互补品推荐任务上显著优于现有基线，并能有效处理冷启动项目。

> **摘要翻译:** 我们引入了一个新颖的自监督多模态关系项目表示学习框架，旨在推断替代品和互补品。现有方法主要侧重于使用图神经网络（GNNs）从用户行为中推断项目间关联，或利用项目内容信息。然而，这些方法常常忽略关键挑战，例如嘈杂的用户行为数据和由于这些行为的长尾分布导致的数据稀疏性。在本文中，我们提出了MMSC，一个自监督多模态关系项目表示学习框架来解决这些挑战。具体来说，MMSC由三个主要组件组成：(1) 一个多模态项目表示学习模块，该模块利用多模态基础模型并从项目元数据中学习；(2) 一个自监督行为表示学习模块，该模块对用户行为数据进行去噪和学习；(3) 一个分层表示聚合机制，该机制在语义和任务级别整合项目表示。此外，我们利用大型语言模型（LLMs）生成增强训练数据，进一步增强训练期间的去噪过程。我们在五个真实世界数据集上进行了广泛实验，结果表明MMSC在替代品推荐方面比现有基线高出26.1%，在互补品推荐方面高出39.2%。此外，我们经验性地表明MMSC在建模冷启动项目方面是有效的。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [299] [Proposing a Semantic Movie Recommendation System Enhanced by ChatGPT's NLP Results](https://arxiv.org/abs/2507.21770)
> *提出一种由ChatGPT的自然语言处理结果增强的语义电影推荐系统*

*Ali Fallahi, Azam Bastanfard, Amineh Amini, Hadi Saboohi* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 电影推荐系统, 语义信息, ChatGPT, 知识图谱, 准确性

**Comment:** May 2023, 6 pages, 5 figures

> **TL;DR:** 本文提出一个利用ChatGPT分析电影描述的情感，并构建语义知识图谱的电影推荐系统，结果显示其准确性优于传统流派推荐。

**AI_Comments:** 该论文的创新点在于将ChatGPT这一大型语言模型应用于电影推荐系统，通过分析电影描述的语义情感来构建知识图谱。这种方法超越了传统的基于显式流派的推荐，为提升推荐准确性和个性化提供了新的视角。其重要性在于展示了大型语言模型在理解文本深层含义并应用于推荐系统领域的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 电影行业中推荐系统的重要性日益增长，目标是提供高度个性化的推荐以提升用户参与度和满意度。现有研究表明，利用基于知识的技术和文本数据的语义信息能获得更准确的结果。

**Method:** 本研究提出一种新的方法，通过利用ChatGPT作为大型语言模型，评估电影的简短描述并提取其情感倾向，从而构建基于语义信息的知识图谱。

**Result:** 结果表明，使用所提出的方法可以显著提高推荐准确性，优于使用发行商提供的明确流派。

**Conclusion:** 通过利用ChatGPT提取电影描述的语义情感信息来构建知识图谱，可以有效提升电影推荐系统的准确性，从而为用户提供更个性化和满意的服务。

> **ai_Abstract:** 本研究提出了一种由ChatGPT增强的语义电影推荐系统。该系统利用ChatGPT分析电影描述以提取情感倾向，并基于这些语义信息构建知识图谱。实验结果表明，与传统基于明确流派的推荐方法相比，该方法能显著提高推荐准确性，从而提升用户参与度和满意度。

> **摘要翻译:** 推荐系统在网络上的重要性日益增长，尤其是在电影行业，电影选择范围广泛。为了帮助用户浏览可用的电影并找到相关结果，推荐系统分析运营数据并调查用户的品味和习惯。提供高度个性化的建议可以提高用户参与度和满意度，这是电影行业（尤其是在线平台）的基本目标之一。根据最近的研究，使用基于知识的技术并考虑文本数据的语义概念是获得更合适结果的有效方法。本研究提供了一种基于语义信息构建知识图谱的新方法。它使用ChatGPT（一个大型语言模型）来评估电影的简短描述并提取其情感倾向。结果表明，与使用发行商提供的明确流派相比，使用所提出的方法可以显著提高准确性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [319] [Sustainability Evaluation Metrics for Recommender Systems](https://arxiv.org/abs/2507.22520)
> *推荐系统的可持续性评估指标*

*Alexander Felfernig, Damian Garber, Viet-Man Le, Sebastian Lubos, Thi Ngoc Trang Tran* | **Category: cs.IR** | **Updated: 2025-07-30**

**Keywords:** 可持续性, 推荐系统, 评估指标, 可持续发展目标

**Comment:** 

> **TL;DR:** 本文讨论了推荐系统的可持续性评估指标，这些指标超越了传统的准确性、精确度、召回率和满意度等指标，并分析了它们在环境、社会和经济方面的影响。

**AI_Comments:** 本文的创新之处在于将可持续性概念引入推荐系统评估领域，超越了传统的以准确性为中心的评估方法。这对于促进推荐系统负责任地发展，并考虑其更广泛的社会和环境影响具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有推荐系统评估指标（如准确性、精确度、召回率和满意度）未能全面评估其对环境、社会和经济方面的影响。本文旨在引入并讨论基于联合国可持续发展目标（SDGs）的可持续性评估指标，以更全面地评估推荐系统的质量和影响。

**Method:** 本文讨论了不同的基本可持续性评估指标，并分析了它们在推荐系统中的应用。

**Result:** 本文讨论并分析了推荐系统的不同基本可持续性评估指标及其应用。

**Conclusion:** 本文讨论了推荐系统的可持续性评估指标，这些指标可以帮助评估推荐系统在环境、社会和经济方面的影响，超越了传统的评估方法。

> **ai_Abstract:** 本文探讨了推荐系统的可持续性评估指标，这些指标旨在超越传统的性能评估，如准确性、精确度、召回率和满意度。作者根据联合国可持续发展目标（SDGs）的指导，讨论了这些指标如何帮助分析推荐系统在环境、社会和经济层面的影响，并对其应用进行了分析。

> **摘要翻译:** 面向可持续性的评估指标可以帮助评估推荐系统的质量，超越了广泛使用的准确性、精确度、召回率和满意度等指标。遵循联合国可持续发展目标（SDGs），此类指标有助于分析推荐系统对环境、社会和经济方面的影响。我们讨论了推荐系统不同的基本可持续性评估指标，并分析了它们的应用。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [339] [FedFlex: Federated Learning for Diverse Netflix Recommendations](https://arxiv.org/abs/2507.21115)
> *FedFlex：面向多样化Netflix推荐的联邦学习*

*Sven Lankester, Manel Slokom, Gustavo de Carvalho Bertoli, Matias Vizcaino, Emmanuelle Beauxis Aussalet, Laura Hollink* | **Category: cs.IR, cs.AI, cs.DC, cs.LG** | **Updated: 2025-07-15**

**Keywords:** 联邦学习, 推荐系统, 多样性, Netflix, MMR

**Comment:** 

> **TL;DR:** FedFlex是一个联邦推荐系统，它通过整合矩阵分解算法和MMR重排序来为Netflix提供多样化推荐，且不牺牲用户满意度。

**AI_Comments:** FedFlex的创新之处在于其将联邦学习与多样性推荐相结合，特别是在保护用户隐私的前提下，通过整合先进的矩阵分解算法和MMR重排序来提升推荐列表的多样性。这项工作对于解决推荐系统中的“过滤气泡”问题具有重要意义，并且通过真实用户研究验证了其有效性，表明在不牺牲用户满意度的情况下，可以实现更好的内容探索。

<details>
  <summary>Details</summary>

**Motivation:** 现有的联邦推荐系统主要关注提高准确性，但对公平性和多样性的关注有限。

**Method:** 本文提出了FedFlex，一个面向Netflix风格电视节目推荐的联邦推荐系统。FedFlex整合了两种最先进的矩阵分解算法（SVD和BPR）进行个性化微调，并应用最大边际相关性（MMR）对项目进行重新排序以增强多样性。通过为期两周的用户研究，比较了基于SVD/BPR的推荐列表和强调多样性的重排序列表。

**Result:** 研究结果表明，FedFlex能够有效地在推荐中引入多样化内容（如新类型），而无需牺牲用户满意度。

**Conclusion:** FedFlex成功地在联邦推荐系统中引入了多样性，同时保持了用户满意度。

> **ai_Abstract:** FedFlex是一个针对Netflix风格电视节目推荐的联邦学习系统，旨在解决现有联邦推荐系统在多样性方面的不足。该系统结合了SVD和BPR两种矩阵分解算法进行个性化微调，并利用最大边际相关性（MMR）来增强推荐的多样性。通过一项为期两周的用户研究，FedFlex被证明能够在不影响用户满意度的情况下，有效引入更多样化的内容，如新类型。

> **摘要翻译:** 联邦学习是一种去中心化方法，它能够在保护数据隐私的同时，实现跨多个设备的协作模型训练。它在医疗保健和个性化推荐系统等各个领域都显示出巨大的潜力。然而，大多数现有的联邦推荐系统工作主要集中在提高准确性上，而对公平性和多样性的关注有限。在本文中，我们介绍了FedFlex，一个用于Netflix风格电视节目推荐的联邦推荐系统。FedFlex整合了两种最先进的矩阵分解算法进行个性化微调。FedFlex还应用最大边际相关性（MMR）对项目进行重新排序以增强多样性。我们进行了广泛的实验，比较了SVD和BPR算法生成的推荐。在为期两周的实时用户研究中，参与者收到了两个推荐列表：列表A，基于SVD或BPR；列表B，一个强调多样性的重排序版本。参与者被要求点击他们感兴趣观看的电影。我们的发现表明，FedFlex有效地引入了多样化内容，例如新的类型，到推荐中，而无需必然牺牲用户满意度。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [361] [GeoOutageKG: A Multimodal Geospatiotemporal Knowledge Graph for Multiresolution Power Outage Analysis](https://arxiv.org/abs/2507.22878)
> *GeoOutageKG：一个用于多分辨率停电分析的多模态地理时空知识图谱*

*Ethan Frakes, Yinghui Wu, Roger H. French, Mengjie Li* | **Category: cs.IR, cs.CL, cs.CY** | **Updated: 2025-07-30**

**Keywords:** 知识图谱, 停电分析, 多模态数据, 地理时空, 灾害缓解

**Comment:** Accepted to the 24th International Semantic Web Conference Resource
  Track (ISWC 2025)

> **TL;DR:** GeoOutageKG是一个多模态地理时空知识图谱，整合了夜间灯光卫星图像、高分辨率停电地图和县级时间序列停电报告，以改善停电检测、分析和预测。

**AI_Comments:** GeoOutageKG的创新之处在于其多模态数据集成能力，它巧妙地结合了具有不同时空分辨率的数据源（县级报告的时间高粒度与卫星图像的空间高分辨率），通过构建统一的知识图谱来弥补单一数据源的不足。这种方法对于电网风险评估和灾害管理具有重要意义，因为它能提供更全面、更精确的停电视图，支持多分辨率分析。其模块化和可重用性也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 检测、分析和预测停电对于电网风险评估和灾害缓解至关重要。现有县级停电数据空间分辨率有限，难以捕捉局部模式，而夜间灯光卫星图像空间分辨率高但仅每日可用。将这些不同时空分辨率的数据源整合到统一的知识表示中，可以显著改善停电检测、分析和预测推理。

**Method:** 本文提出了GeoOutageKG，一个多模态知识图谱，它整合了包括夜间灯光卫星图像数据、高分辨率地理时空停电地图以及美国县级时间序列停电报告等多样化数据源。通过将源数据与开发的本体GeoOutageOnto对齐来构建GeoOutageKG。

**Result:** GeoOutageKG目前包含超过1060万条2014年至2024年的独立停电记录，30万张2012年至2024年的夜间灯光卫星图像，以及1.5万张停电地图。GeoOutageKG是一个新颖、模块化且可重用的语义资源。

**Conclusion:** GeoOutageKG是一个新颖、模块化且可重用的语义资源，能够实现鲁棒的多模态数据集成，并通过多分辨率分析展示了其在地理时空停电分析中的应用。

> **ai_Abstract:** 本文提出GeoOutageKG，一个多模态地理时空知识图谱，旨在解决现有停电数据在空间分辨率或时间粒度上的局限性。通过整合夜间灯光卫星图像、高分辨率停电地图和县级时间序列停电报告，GeoOutageKG能够统一表示不同分辨率的数据，从而显著改善停电的检测、分析和预测。该知识图谱基于GeoOutageOnto本体构建，目前已包含千万级的停电记录和数十万张图像和地图数据，为多分辨率停电分析提供了强大的语义资源。

> **摘要翻译:** 检测、分析和预测停电对于电网风险评估和灾害缓解至关重要。每年发生大量停电事件，极端天气事件如飓风使其加剧。现有停电数据通常在县级报告，限制了其空间分辨率，使其难以捕捉局部模式。然而，它提供了出色的时间粒度。相比之下，夜间灯光卫星图像数据提供了显著更高的空间分辨率，并能够更全面地空间描绘停电，提高了评估灾害事件后停电地理范围和严重性的准确性。然而，这些卫星数据仅按日提供。将时空视觉和时间序列数据源整合到统一的知识表示中，可以大大改善停电检测、分析和预测推理。在本文中，我们提出了GeoOutageKG，一个多模态知识图谱，它整合了多样化的数据源，包括夜间灯光卫星图像数据、高分辨率地理时空停电地图以及美国县级时间序列停电报告。我们描述了通过将源数据与开发的本体GeoOutageOnto对齐来构建GeoOutageKG的方法。目前，GeoOutageKG包含超过1060万条2014年至2024年的独立停电记录，30万张2012年至2024年的夜间灯光卫星图像，以及1.5万张停电地图。GeoOutageKG是一个新颖、模块化且可重用的语义资源，能够实现鲁棒的多模态数据集成。我们通过对地理时空停电进行多分辨率分析来展示其用途。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [393] [RecGPT Technical Report](https://arxiv.org/abs/2507.22879)
> *RecGPT 技术报告*

*Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Sunhao Dai, Wen Chen, Wenjun Yang, Yuning Jiang, Zhujin Gao, Bo Zheng, Chi Li, Dimin Wang, Dixuan Wang, Fan Li, Fan Zhang, Haibin Chen, Haozhuang Liu, Jialin Zhu, Jiamang Wang, Jiawei Wu, Jin Cui, Ju Huang, Kai Zhang, Kan Liu, Lang Tian, Liang Rao, Longbin Li, Lulu Zhao, Mao Zhang, Na He, Peiyang Wang, Qiqi Huang, Tao Luo, Wenbo Su, Xiaoxiao He, Xin Tong, Xu Chen, Xunke Xi, Yang Li, Yaxuan Wu, Yeqiu Yang, Yi Hu, Yinnan Song, Yuchen Li, Yujie Luo, Yujin Yuan, Yuliang Yan, Zhengyang Wang, Zhibo Xiao, Zhixin Ma, Zile Zhou* | **Category: cs.IR, cs.CL** | **Updated: 2025-07-30**

**Keywords:** 推荐系统, 大型语言模型, 用户意图, RecGPT, 淘宝

**Comment:** 

> **TL;DR:** RecGPT是一个基于LLM的意图中心推荐系统，通过解决传统推荐系统过度依赖历史行为的问题，提升了用户体验和平台效益。

**AI_Comments:** 该论文提出了一个创新的LLM驱动的推荐系统框架RecGPT，解决了传统推荐系统过度依赖历史行为导致的用户意图建模不足和过滤气泡问题。其将LLMs引入推荐系统的关键阶段，并采用多阶段训练范式，具有很高的工程实践价值和学术影响力。在淘宝的实际部署和积极效果验证了其方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 当前推荐系统过度依赖历史共现模式和日志拟合目标，未能显式建模用户意图，导致过拟合、过滤气泡和长尾效应，损害用户体验和生态系统可持续性。

**Method:** 提出RecGPT框架，将用户意图置于推荐流程中心。通过将大型语言模型（LLMs）整合到用户兴趣挖掘、物品检索和解释生成等关键阶段，将日志拟合推荐转变为以意图为中心的过程。采用多阶段训练范式，包括推理增强预对齐和自训练演化，并由人机协作判断系统指导，以有效校准LLMs。

**Result:** RecGPT已在淘宝App上全面部署。在线实验表明，RecGPT在所有利益相关者中实现了持续的性能提升：用户受益于内容多样性和满意度增加，商家和平台获得更高的曝光和转化。

**Conclusion:** LLM驱动、以意图为中心的设计能够促进更可持续、互惠互利的推荐生态系统。

> **ai_Abstract:** RecGPT是一个技术报告，提出了一种新的推荐系统框架，该框架通过将大型语言模型（LLMs）整合到用户兴趣挖掘、物品检索和解释生成中，将传统的“日志拟合”方法转变为以用户意图为中心。该系统旨在解决现有推荐系统过度依赖历史数据导致过拟合和过滤气泡的问题。RecGPT采用多阶段训练范式并结合人机协作判断系统，已在淘宝App上部署，并在线实验证明其能显著提升用户满意度、内容多样性以及商家和平台的曝光与转化。

> **摘要翻译:** 推荐系统是人工智能领域最具影响力的应用之一，作为连接用户、商家和平台的关键基础设施。然而，大多数当前的工业系统仍然严重依赖历史共现模式和日志拟合目标，即优化过去的用户交互而没有明确建模用户意图。这种日志拟合方法常常导致对狭窄的历史偏好过拟合，未能捕捉用户不断演变和潜在的兴趣。结果，它加剧了过滤气泡和长尾现象，最终损害用户体验并威胁整个推荐生态系统的可持续性。
为了应对这些挑战，我们重新思考了推荐系统的整体设计范式，并提出了RecGPT，一个将用户意图置于推荐流程中心的新一代框架。通过将大型语言模型（LLMs）整合到用户兴趣挖掘、物品检索和解释生成等关键阶段，RecGPT将日志拟合推荐转变为以意图为中心的过程。为了有效地将通用LLMs大规模地与上述领域特定推荐任务对齐，RecGPT引入了多阶段训练范式，该范式集成了推理增强的预对齐和自训练演化，并由人机协作判断系统指导。目前，RecGPT已在淘宝App上全面部署。在线实验表明，RecGPT在所有利益相关者中实现了持续的性能提升：用户受益于内容多样性和满意度增加，商家和平台获得更高的曝光和转化。这些在所有利益相关者中取得的全面改进结果验证了LLM驱动、以意图为中心的设计能够促进更可持续、互惠互利的推荐生态系统。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [429] [AUV-Fusion: Cross-Modal Adversarial Fusion of User Interactions and Visual Perturbations Against VARS](https://arxiv.org/abs/2507.22880)
> *AUV-Fusion：用户交互与视觉扰动的跨模态对抗融合攻击VARS*

*Hai Ling, Tianchi Wang, Xiaohao Liu, Zhulin Tao, Lifang Yang, Xianglin Huang* | **Category: cs.IR** | **Updated: 2025-07-30**

**Keywords:** 视觉感知推荐系统, 对抗攻击, 跨模态融合, 用户交互, 视觉扰动

**Comment:** 14 pages,6 figures

> **TL;DR:** AUV-Fusion是一种新型跨模态对抗攻击框架，通过融合用户交互和视觉扰动来攻击视觉感知推荐系统（VARS），提高目标项目曝光度并保持隐蔽性。

**AI_Comments:** AUV-Fusion的创新之处在于其跨模态融合攻击策略，有效结合了用户交互和视觉扰动，解决了传统攻击方法的局限性（如成本高、易检测、偏好不匹配）。它通过避免注入虚假用户档案和更有效地提取用户偏好，提高了攻击的隐蔽性和有效性，对理解和增强推荐系统的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代视觉感知推荐系统（VARS）在对抗攻击下的鲁棒性尚未得到充分探索，存在系统可靠性和安全性风险。现有攻击策略（如洗钱攻击成本高且易被检测，纯视觉扰动难以与用户偏好对齐）存在显著局限性。

**Method:** 提出AUV-Fusion框架，采用高阶用户偏好建模和跨模态对抗生成。通过多跳用户-项目交互获取鲁棒的用户嵌入，并通过MLP将其转换为语义对齐的扰动。这些扰动被注入到扩散模型中预训练VAE的潜在空间。通过协同整合真实用户交互数据与视觉上合理的扰动，避免注入虚假用户档案，并有效缓解传统纯视觉攻击中用户偏好提取不足的挑战。

**Result:** 在不同的VARS架构和真实世界数据集上的综合评估表明，与传统基线方法相比，AUV-Fusion显著提高了目标（冷启动）项目的曝光度。此外，AUV-Fusion在严格审查下保持了出色的隐蔽性。

**Conclusion:** AUV-Fusion是一种有效的跨模态对抗攻击框架，能够显著提高目标项目的曝光度，同时保持高度隐蔽性，解决了现有攻击方法的局限性。

> **ai_Abstract:** 本文提出了AUV-Fusion，一个针对视觉感知推荐系统（VARS）的跨模态对抗攻击框架。该框架通过高阶用户偏好建模和跨模态对抗生成，将用户交互数据与视觉扰动相结合。它通过多跳用户-项目交互获取用户嵌入并转化为语义扰动，注入到扩散模型的VAE潜在空间。AUV-Fusion无需注入虚假用户档案，克服了纯视觉攻击中用户偏好提取不足的问题。实验证明，AUV-Fusion能显著提高目标（冷启动）项目的曝光度，并保持极佳的隐蔽性。

> **摘要翻译:** 现代视觉感知推荐系统（VARS）利用用户交互数据和视觉特征的整合来提供高精度的个性化推荐。然而，它们对抗攻击的鲁棒性在很大程度上尚未得到充分探索，对系统可靠性和安全性构成重大风险。现有攻击策略存在显著局限性：洗钱攻击成本高且可被检测，而纯视觉扰动往往无法与用户偏好对齐。为了应对这些挑战，我们提出了AUV-Fusion，一个跨模态对抗攻击框架，它采用高阶用户偏好建模和跨模态对抗生成。具体而言，我们通过多跳用户-项目交互获得鲁棒的用户嵌入，并通过多层感知器（MLP）将其转换为语义对齐的扰动。这些扰动被注入到扩散模型中预训练的变分自编码器（VAE）的潜在空间。通过协同整合真实用户交互数据与视觉上合理的扰动，AUV-Fusion消除了注入虚假用户档案的需要，并有效缓解了传统纯视觉攻击中用户偏好提取不足的挑战。在不同VARS架构和真实世界数据集上的综合评估表明，与传统基线方法相比，AUV-Fusion显著提高了目标（冷启动）项目的曝光度。此外，AUV-Fusion在严格审查下保持了出色的隐蔽性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [446] [AgentMaster: A Multi-Agent Conversational Framework Using A2A and MCP Protocols for Multimodal Information Retrieval and Analysis](https://arxiv.org/abs/2507.21105)
> *AgentMaster：一个使用A2A和MCP协议的多智能体对话框架，用于多模态信息检索和分析*

*Callie C. Liao, Duoduo Liao, Sai Surya Gadiraju* | **Category: cs.IR, cs.AI, cs.CL** | **Updated: 2025-07-08**

**Keywords:** 多智能体系统, A2A协议, MCP协议, 多模态信息检索, 对话式AI

**Comment:** 

> **TL;DR:** AgentMaster是一个新的多智能体对话框架，结合了A2A和MCP协议，用于多模态信息检索和分析，并展现出强大的协调和响应能力。

**AI_Comments:** AgentMaster的创新之处在于首次将Google的A2A协议和Anthropic的MCP协议在单一多智能体系统框架中结合并自主实现，从而显著提升了智能体间的通信和协调能力。这对于开发更复杂、更智能的对话式AI系统具有重要意义，尤其是在处理多模态信息和复杂任务方面展现出巨大潜力。其模块化设计也预示了良好的可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人工智能多智能体系统（MAS），特别是与大型语言模型（LLMs）结合的系统，在解决复杂任务方面面临智能体间通信、协调以及与异构工具和资源交互的挑战。

**Method:** 提出了AgentMaster，一个新颖的模块化多协议MAS框架，内部实现了A2A和MCP协议，以实现动态协调和灵活通信。它通过统一的对话界面支持自然语言交互，并能响应多模态查询，用于信息检索、问答和图像分析等任务。

**Result:** 通过BERTScore F1和LLM-as-a-Judge度量G-Eval进行评估，分别平均达到96.3%和87.1%。这表明系统具有强大的智能体间协调、查询分解、动态路由以及领域特定和相关响应的能力。

**Conclusion:** 所提出的AgentMaster框架有助于提升由多智能体系统驱动的、领域特定、协作和可扩展的对话式AI的潜在能力。

> **ai_Abstract:** AgentMaster是一个创新的多智能体系统（MAS）对话框架，它独特地集成了自主实现的Google A2A和Anthropic MCP协议，旨在解决现有MAS在智能体间通信和协调方面的挑战。该系统提供统一的自然语言界面，支持多模态信息检索、问答和图像分析。通过BERTScore F1和G-Eval评估，AgentMaster展现出卓越的智能体协调和响应能力，为构建可扩展的领域特定对话式AI提供了新途径。

> **摘要翻译:** 人工智能（AI）中多智能体系统（MAS）的兴起，特别是与大型语言模型（LLM）相结合，极大地促进了复杂任务的解决。然而，当前系统仍面临智能体间通信、协调以及与异构工具和资源交互的挑战。最近，Anthropic公司引入了模型上下文协议（MCP），谷歌引入了智能体到智能体（A2A）通信协议。据我们所知，目前很少有应用在一个MAS框架中同时采用这两种协议。我们提出了AgentMaster的初步研究，这是一个新颖的模块化多协议MAS框架，具有自主实现的A2A和MCP，能够实现动态协调和灵活通信。通过统一的对话界面，该系统支持无需事先技术专业知识的自然语言交互，并响应多模态查询，执行包括信息检索、问答和图像分析在内的任务。通过BERTScore F1和LLM-as-a-Judge度量G-Eval的评估，平均得分分别为96.3%和87.1%，这揭示了强大的智能体间协调、查询分解、动态路由以及领域特定、相关响应的能力。总的来说，我们提出的框架有助于提升由MAS驱动的领域特定、协作和可扩展的对话式AI的潜在能力。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [460] [RATE: An LLM-Powered Retrieval Augmented Generation Technology-Extraction Pipeline](https://arxiv.org/abs/2507.21125)
> *RATE：一种基于LLM的检索增强生成技术提取流程*

*Karan Mirhosseini, Arya Aftab, Alireza Sheikh* | **Category: cs.IR, cs.AI, cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-19**

**Keywords:** 技术提取, 大型语言模型, 检索增强生成, 技术图谱, 脑机接口, 扩展现实

**Comment:** 9 pages, 4 figures, 1 table

> **TL;DR:** 提出RATE，一个基于LLM的自动化技术提取管道，结合RAG和多定义LLM验证，在BCI-XR文献中表现优于BERT，F1分数达91.27%。

**AI_Comments:** RATE的创新之处在于其结合了RAG和多定义LLM验证的混合方法，显著提高了技术提取的准确性和召回率。其在大规模文献上的成功应用，并与BERT模型的对比，清晰地展示了LLM在信息抽取领域的优越性，对于自动化构建技术图谱和洞察技术发展趋势具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在技术快速变革时代，技术图谱对决策至关重要，而技术图谱的构建高度依赖于自动化技术提取方法。

**Method:** 论文引入了检索增强技术提取（RATE）方法，这是一个基于大型语言模型（LLM）的自动化技术提取流程。RATE结合了检索增强生成（RAG）和基于多定义LLM的验证，旨在实现候选生成的高召回率和候选过滤的高精确度。该流程在678篇关于脑机接口（BCI）和扩展现实（XR）的研究文章上进行了案例研究，并与基于BERT的技术提取模型进行了比较评估。

**Result:** RATE在专家标注的黄金标准数据集上取得了91.27%的F1分数，显著优于作为比较方法的BERT模型（F1分数为53.73%）。RATE验证的技术术语被映射到共现网络中，揭示了研究领域的 тематические 聚类和结构特征。

**Conclusion:** 研究结果强调了定义驱动的LLM方法在技术提取和绘图方面的潜力，并为BCI-XR领域的新兴趋势提供了新见解。

> **ai_Abstract:** 本文提出了一种名为RATE的自动化技术提取流程，它利用大型语言模型（LLM）结合检索增强生成（RAG）和多定义验证，从科学文献中高效准确地提取技术。通过在脑机接口（BCI）和扩展现实（XR）领域的678篇文章中进行案例研究，RATE在技术提取任务上取得了91.27%的F1分数，显著优于传统的BERT模型（53.73%）。该研究强调了LLM在构建技术图谱和揭示新兴趋势方面的巨大潜力。

> **摘要翻译:** 在技术快速变革的时代，技术图谱在增强决策方面发挥着关键作用。这些图谱高度依赖于自动化技术提取方法。本文介绍了一种基于大型语言模型（LLM）的检索增强技术提取（RATE）流程，用于从科学文献中自动化提取技术。RATE将检索增强生成（RAG）与基于多定义LLM的验证相结合。这种混合方法在候选生成中实现了高召回率，同时在候选过滤中实现了高精确度。尽管该流程设计为通用且广泛适用，但我们以678篇关于脑机接口（BCI）和扩展现实（XR）的研究文章为例进行了演示。因此，RATE验证的技术术语被映射到共现网络中，揭示了研究领域的 тематические 聚类和结构特征。为了评估目的，专家们整理了一个包含70篇随机选定文章中技术的黄金标准数据集。此外，一个基于BERT（Bidirectional Encoder Representations of Transformers）的技术提取模型被用作比较方法。RATE取得了91.27%的F1分数，显著优于BERT的53.73%的F1分数。我们的研究结果突出了定义驱动的LLM方法在技术提取和绘图方面的潜力。它们还为BCI-XR领域的新兴趋势提供了新见解。源代码可在https://github.com/AryaAftab/RATE 获取。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [492] [Efficient Data Retrieval and Comparative Bias Analysis of Recommendation Algorithms for YouTube Shorts and Long-Form Videos](https://arxiv.org/abs/2507.21467)
> *YouTube Shorts和长视频推荐算法的高效数据检索与比较偏差分析*

*Selimhan Dagtas, Mert Can Cakmak, Nitin Agarwal* | **Category: cs.IR, cs.SI** | **Updated: 2025-07-29**

**Keywords:** 推荐算法, YouTube Shorts, 偏见分析, 数据收集, 内容多样性

**Comment:** 

> **TL;DR:** 本研究开发了一个高效的数据收集框架，用于分析YouTube短视频和长视频的推荐算法。研究发现短视频推荐算法倾向于更迅速地转向吸引人但多样性较低的内容，并在政治敏感话题中放大特定观点，强调了负责任AI实践的重要性。

**AI_Comments:** 本研究的创新之处在于其高效的数据收集框架，能够克服YouTube API的限制，对短视频和长视频的推荐算法进行比较分析，这对于理解当前数字平台的内容分发机制至关重要。其对政治敏感话题偏见的深入探讨也具有重要现实意义。研究结果为设计更公平、透明的推荐系统提供了宝贵的见解，对负责任的AI实践具有指导作用。

<details>
  <summary>Details</summary>

**Motivation:** 短视频内容日益普及，改变了用户参与方式，引发了对推荐算法在塑造用户体验中作用的关键问题。同时，人们对算法偏见、信息茧房和内容多样性不足的担忧持续存在。

**Method:** 本研究开发了一个高效的数据收集框架，利用并行计算和高级抓取技术，克服YouTube API的限制，分析YouTube短视频和长视频的推荐算法。

**Result:** 分析揭示了两种视频格式的推荐算法存在明显不同的行为模式：短视频比长视频更快地转向吸引人但多样性较低的内容。此外，对南海争端等政治敏感话题的偏见调查表明，这些算法在塑造叙事和放大特定观点方面发挥作用。

**Conclusion:** 本研究为设计公平透明的推荐系统提供了可操作的见解，并强调了在不断发展的数字媒体环境中负责任的AI实践的重要性。

> **ai_Abstract:** 本研究针对YouTube短视频和长视频的推荐算法，开发了一套高效的数据收集框架。通过该框架，研究分析了两种视频格式的推荐机制，发现短视频推荐算法更倾向于快速推送吸引人但内容多样性较低的视频，而长视频则相对平衡。此外，研究还深入探讨了算法在政治敏感话题（如南海争端）中可能存在的偏见，揭示了其在塑造公众叙事和放大特定观点方面的作用。本研究旨在提供构建公平透明推荐系统的实用建议，并强调了在数字媒体领域推行负责任AI实践的必要性。

> **摘要翻译:** 短视频内容（如YouTube Shorts）日益普及，改变了数字平台上的用户参与方式，引发了关于推荐算法在塑造用户体验中作用的关键问题。这些算法显著影响内容消费，但对偏见、信息茧房和内容多样性的担忧持续存在。本研究开发了一个高效的数据收集框架，通过并行计算和先进的抓取技术克服YouTube API的限制，分析YouTube短视频和长视频的推荐算法。分析揭示了两种格式的推荐算法存在明显的行为模式差异，其中短视频与长视频相比，更迅速地转向吸引人但多样性较低的内容。此外，对政治敏感话题（如南海争端）中偏见的新颖调查，突出了这些算法在塑造叙事和放大特定观点方面的作用。通过为设计公平透明的推荐系统提供可操作的见解，本研究强调了在不断发展的数字媒体环境中负责任的AI实践的重要性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [502] [Conversational LLMs Simplify Secure Clinical Data Access, Understanding, and Analysis](https://arxiv.org/abs/2507.01053)
> *对话式大型语言模型简化安全临床数据访问、理解和分析*

*Rafi Al Attrach, Pedro Moreira, Rajna Fani, Renato Umeton, Leo Anthony Celi* | **Category: cs.IR, cs.AI, cs.DB, 68T50, 68P15, H.2.3; I.2.7; J.3** | **Updated: 2025-07-30**

**Keywords:** 临床数据, 大型语言模型, MIMIC-IV, SQL查询, 自然语言处理

**Comment:** 10 pages, 4 figures

> **TL;DR:** M3利用对话式LLM简化了对MIMIC-IV等复杂临床数据的访问、查询和分析，将数小时的手动SQL工作缩短为几分钟的对话。

**AI_Comments:** M3的创新之处在于其通过对话式LLM将复杂的临床数据查询过程简化为自然语言交互，极大地降低了非技术背景研究人员使用大型临床数据集的门槛。其提供底层SQL查询以保证可验证性和可复现性的设计也值得称赞。该系统对于加速医学研究、将原始临床数据转化为可操作洞察具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型临床数据集（如MIMIC-IV）的出现，其复杂性以及对高级查询技能和临床背景理解的需求，构成了有效利用这些数据的重大障碍，限制了医疗研究的潜力。

**Method:** M3通过单一命令检索MIMIC-IV数据，启动本地SQLite实例或连接BigQuery，并通过模型上下文协议（MCP）让研究人员用自然语言与数据库对话。它使用语言模型将自然语言临床问题翻译成SQL，执行查询，并返回结构化结果及底层查询，以实现可验证性和可复现性。

**Result:** 通过与M3的几分钟对话，可以完成过去需要数小时手动编写SQL并理解复杂临床工作流程才能实现的精细队列分析。

**Conclusion:** M3通过简化临床数据的访问，邀请更广泛的研究社区挖掘重症监护数据，并加速将原始记录转化为可操作的洞察。

> **ai_Abstract:** 本研究提出M3，一个利用对话式大型语言模型（LLM）的系统，旨在简化对复杂临床数据集（如MIMIC-IV）的访问、理解和分析。M3通过将自然语言问题转化为SQL查询，使用户能够以会话方式与数据库交互，从而降低了技术门槛。实验证明，M3能将耗时数小时的手动SQL分析缩短为几分钟的对话，从而加速了临床数据的洞察提取，并促进了更广泛的研究社区对重症监护数据的利用。

> **摘要翻译:** 随着越来越大的临床数据集变得可用，它们有可能为医学研究带来前所未有的机遇。其中最重要的是重症监护医学信息库（MIMIC-IV），它是世界上最大的开源电子健康记录数据库。然而，这些数据集固有的复杂性，特别是对复杂查询技能的需求以及对底层临床环境的理解需求，常常对其有效使用构成重大障碍。M3降低了理解和查询MIMIC-IV数据的技术门槛。它通过一个命令从PhysioNet检索MIMIC-IV，启动本地SQLite实例（或连接到托管的BigQuery），并通过模型上下文协议（MCP）让研究人员用普通英语与数据库对话。用自然语言提出临床问题；M3使用语言模型将其翻译成SQL，针对MIMIC-IV数据集执行查询，并返回结构化结果以及底层查询，以供验证和复现。演示表明，与M3进行几分钟的对话就能产生那种曾经需要数小时手工编写SQL并依赖于理解临床工作流程复杂性的细致队列分析。通过简化访问，M3邀请更广泛的研究社区挖掘临床重症监护数据，并加速将原始记录转化为可操作的洞察。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [594] [Page image classification for content-specific data processing](https://arxiv.org/abs/2507.21114)
> *页面图像分类用于内容特定数据处理*

*Kateryna Lutsai, Pavel Straňák* | **Category: cs.IR, cs.AI, cs.CV, 68T10, 68T09, 62H30, I.7.5; H.3.7** | **Updated: 2025-07-11**

**Keywords:** 页面图像分类, 历史文献, 人工智能, 机器学习, 内容特定处理

**Comment:** 65 pages, 57 figures, 20 tables

> **TL;DR:** 该项目开发并评估了一个图像分类系统，专门用于历史文献页面，以实现基于内容的自动化处理，解决人工分类大量数字化历史文献的挑战。

**AI_Comments:** 该论文的创新点在于将人工智能和机器学习应用于历史文献的页面图像分类，以解决传统手动处理效率低下的问题。其重要性体现在能够自动化处理海量异构的历史文献数据，为后续内容特定的分析（如OCR、图像分析）奠定基础，极大地提升了数字化人文学科研究的效率和深度。

<details>
  <summary>Details</summary>

**Motivation:** 人文学科的数字化项目产生了大量历史文献页面图像，手动分类和分析这些包含不同内容（文本、图形、布局）的异构数据面临巨大挑战。为了实现高效处理和定制化下游分析流程，需要自动化的页面内容分类方法。

**Method:** 开发和评估一个专门针对历史文献页面的图像分类系统，该系统利用人工智能和机器学习的最新进展，并选择了一组类别以促进内容特定的处理工作流程，从而分离需要不同分析技术（例如，文本的光学字符识别，图形的图像分析）的页面。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该研究旨在解决人文学科数字化项目中历史文献页面图像手动分类和分析的挑战。面对大量异构内容（包括不同文本类型、图形元素和布局），研究提出并开发了一个基于人工智能和机器学习的图像分类系统。该系统专门用于对历史文献页面进行内容分类，以实现高效的自动化处理，并支持针对特定内容定制后续的分析流程，如对文本进行OCR或对图形进行图像分析。

> **摘要翻译:** 人文学科的数字化项目通常会生成大量的历史文献页面图像，这对人工分类和分析提出了重大挑战。这些档案包含多样化的内容，包括各种文本类型（手写、打字、印刷）、图形元素（图画、地图、照片）和布局（纯文本、表格、表单）。高效处理这些异构数据需要自动化方法根据其内容对页面进行分类，从而实现定制化的下游分析流程。本项目通过开发和评估一个专门为历史文献页面设计的图像分类系统来解决这一需求，该系统利用了人工智能和机器学习的最新进展。选择这些类别是为了促进内容特定的处理工作流程，将需要不同分析技术（例如，文本的光学字符识别，图形的图像分析）的页面分开。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [629] [A Comprehensive Review on Harnessing Large Language Models to Overcome Recommender System Challenges](https://arxiv.org/abs/2507.21117)
> *利用大型语言模型克服推荐系统挑战的综合综述*

*Rahul Raja, Anshaj Vats, Arpita Vats, Anirban Majumder* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-17**

**Keywords:** 大型语言模型, 推荐系统, 冷启动, 语义理解, 综述

**Comment:** 

> **TL;DR:** 大型语言模型能从根本上改进推荐系统，解决传统挑战如数据稀疏、冷启动和语义理解不足等问题，是核心推动力而非辅助组件。

**AI_Comments:** 鉴于大型语言模型的快速发展，这篇论文是一篇及时且重要的综述。它有效地将大型语言模型的能力与推荐系统中的具体挑战对应起来，为研究人员和从业者提供了结构化的理解。其将大型语言模型视为“基础推动力”而非仅仅是“辅助组件”的重点，突出了该领域的一个重要范式转变。对权衡（准确性、可扩展性、实时性能）的讨论增加了实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统推荐系统面临稀疏和噪声交互数据、冷启动问题、个性化深度有限以及用户和物品内容语义理解不足等挑战。大型语言模型的出现为解决这些问题提供了新范式。

**Method:** 本文对如何利用大型语言模型解决现代推荐系统中的关键挑战进行了全面的技术综述。文章探讨了大型语言模型在提示驱动的候选检索、语言原生排名、检索增强生成（RAG）和会话推荐中的应用，并对新兴的LLM驱动架构进行了分类和有效性分析。

**Result:** 基于大型语言模型的方法在无需大量任务特定监督的情况下，增强了个性化、语义对齐和可解释性。大型语言模型支持零样本和少样本推理，通过利用外部知识和上下文线索，使系统在冷启动和长尾场景中有效运行。论文还提供了一个结构化框架来理解LLM增强推荐系统的设计空间，并概述了准确性、可扩展性和实时性能之间的权衡。

**Conclusion:** 大型语言模型不仅仅是辅助组件，更是构建更具适应性、语义更丰富和以用户为中心的推荐系统的基础推动力。

> **ai_Abstract:** 本文全面综述了大型语言模型（LLMs）如何解决传统推荐系统中长期存在的挑战，如数据稀疏、冷启动和有限的语义理解。文章考察了LLMs在推荐系统中的各种应用，包括检索、排名、RAG和会话推荐，强调了它们在最少监督下增强个性化、语义对齐和可解释性的能力。该综述认为，LLMs是构建更具适应性和以用户为中心的推荐系统的基础。

> **摘要翻译:** 推荐系统传统上遵循模块化架构，包括候选生成、多阶段排名和重新排名，每个模块都通过监督目标和手动设计的特征单独训练。尽管在许多领域有效，但此类系统面临持续的挑战，包括稀疏和噪声交互数据、冷启动问题、个性化深度有限以及用户和物品内容语义理解不足。大型语言模型（LLMs）的最新出现提供了一种新范式，通过统一的、语言原生的机制来解决这些局限性，这些机制可以跨任务、领域和模态进行泛化。在本文中，我们对如何利用大型语言模型解决现代推荐系统中的关键挑战进行了全面的技术综述。我们考察了大型语言模型在提示驱动的候选检索、语言原生排名、检索增强生成（RAG）和会话推荐中的使用，说明了这些方法如何在无需大量任务特定监督的情况下增强个性化、语义对齐和可解释性。大型语言模型还进一步实现了零样本和少样本推理，通过利用外部知识和上下文线索，使系统能够在冷启动和长尾场景中有效运行。我们对这些新兴的LLM驱动架构进行了分类，并分析了它们在缓解传统管道核心瓶颈方面的有效性。在此过程中，我们为理解LLM增强推荐系统的设计空间提供了一个结构化框架，并概述了准确性、可扩展性和实时性能之间的权衡。我们的目标是证明大型语言模型不仅仅是辅助组件，更是构建更具适应性、语义更丰富和以用户为中心的推荐系统的基础推动力。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [663] [Affect-aware Cross-Domain Recommendation for Art Therapy via Music Preference Elicitation](https://arxiv.org/abs/2507.21120)
> *情感感知跨域推荐用于艺术疗法通过音乐偏好启发*

*Bereket A. Yilma, Luis A. Leiva* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-18**

**Keywords:** 艺术疗法, 跨域推荐, 音乐偏好启发, 情感感知, 推荐系统

**Comment:** Accepted at the 19th ACM Conference on Recommender Systems

> **TL;DR:** 本文提出一种基于音乐偏好启发的跨域推荐方法，用于艺术疗法，以弥补现有视觉推荐系统在情感捕获上的不足，并在一项大规模研究中证明其优于传统视觉方法。

**AI_Comments:** 这篇论文的创新点在于首次将音乐驱动的偏好启发引入艺术疗法中的跨域推荐系统，以更全面地捕捉用户情感。其重要性在于提升了艺术疗法推荐的个性化和效果，为情感计算和推荐系统领域的交叉研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉艺术推荐系统（VA RecSys）在艺术疗法中仅依赖视觉刺激进行用户建模，限制了它们在偏好启发过程中捕获完整情感反应的能力。先前的研究表明，音乐刺激能引发独特的情感反映，这为通过跨域推荐（CDR）增强艺术疗法中的个性化提供了机会。

**Method:** 提出了一系列基于音乐驱动偏好启发的艺术疗法跨域推荐（CDR）方法。

**Result:** 一项针对200名用户的大规模研究表明，音乐驱动的偏好启发是有效的，并且优于经典的仅视觉启发方法。

**Conclusion:** 通过引入音乐驱动的偏好启发，跨域推荐能有效提升艺术疗法中推荐系统的个性化和情感捕获能力。

> **ai_Abstract:** 本文针对艺术疗法（AT）中的个性化推荐问题，指出当前视觉艺术推荐系统（VA RecSys）在捕获用户完整情感反应方面的局限性。为解决此问题，作者提出了一种新颖的跨域推荐（CDR）方法，该方法通过音乐驱动的偏好启发来增强情感感知。通过一项包含200名用户的大规模研究，研究结果证明了所提音乐驱动偏好启发方法的有效性，并显示其性能优于传统的仅视觉启发方法。

> **摘要翻译:** 艺术疗法（AT）是一种成熟的实践，通过创意表达促进情感处理和恢复。最近，视觉艺术推荐系统（VA RecSys）已出现以支持AT，通过个性化治疗性艺术作品推荐展示了其潜力。然而，当前的VA RecSys依赖视觉刺激进行用户建模，限制了它们在偏好启发过程中捕获完整情感反应的能力。先前的研究表明，音乐刺激能引发独特的情感反映，这为跨域推荐（CDR）增强AT中的个性化提供了机会。由于CDR在此背景下尚未被探索，我们提出了一系列基于音乐驱动偏好启发的AT CDR方法。一项针对200名用户的大规模研究表明，音乐驱动的偏好启发是有效的，优于经典的仅视觉启发方法。我们的源代码、数据和模型可在https://github.com/ArtAICare/Affect-aware-CDR获取。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [911] [Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated Videos](https://arxiv.org/abs/2502.07327)
> *生成幽灵：探究AI生成视频中隐藏的排序偏差*

*Haowen Gao, Liang Pang, Shicheng Xu, Leigang Qu, Tat-Seng Chua, Huawei Shen, Xueqi Cheng* | **Category: cs.IR, cs.CV** | **Updated: 2025-07-29**

**Keywords:** AI生成视频, 排序偏差, 视频检索, 基准数据集, 对比学习

**Comment:** 13 pages, Accepted at ACMMM2025

> **TL;DR:** 本文研究发现视频检索模型对AI生成视频存在明显的偏好，这种偏好源于视觉和时间信息，并且在训练集中加入AI生成视频会加剧偏好。

**AI_Comments:** 本文创新性地将AI生成内容偏好研究扩展到视频检索领域，并构建了专门的基准数据集，揭示了视频模态下偏好源于视觉和时间信息的复杂交互。研究结果对于理解和改进未来视频检索系统，尤其是在AIGC日益普及的背景下，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管AI生成视频数量激增，但它们对内容生态系统的影响，特别是在视频信息检索中的影响，仍未被充分探索。已有研究发现检索模型在即席和图像检索任务中偏好AI生成内容，因此需要探究在更具挑战性的视频检索中是否存在类似偏好。

**Method:** 首先构建了一个包含真实和AI生成视频的综合基准数据集（13,000个视频，由两个最先进的开源视频生成模型生成），并设计了一套公平严谨的指标来评估偏好。然后应用了三个现成的视频检索模型在该混合数据集上执行检索任务。最后使用对比学习方法对检索模型进行微调以减轻偏好。

**Result:** 研究结果揭示了检索中对AI生成视频的明显偏好。进一步调查表明，将AI生成视频纳入检索模型的训练集会加剧这种偏好。与图像模态不同，视频检索偏好源于未见的视觉和时间信息，是两者的复杂相互作用。

**Conclusion:** 本研究结果强调了AI生成视频对检索系统潜在的影响。

> **ai_Abstract:** 本文探究了AI生成视频在视频检索中引入的排序偏差。研究者构建了一个包含真实和AI生成视频的基准数据集，并设计了评估偏好的指标。实验结果显示，视频检索模型对AI生成视频存在明显偏好，且这种偏好由视觉和时间信息共同引起，并会因训练集中包含AI生成视频而加剧。为缓解此偏好，研究者尝试了对比学习方法。这项研究揭示了AI生成视频对检索系统的潜在影响。

> **摘要翻译:** 随着AI生成内容（AIGC）的快速发展，高质量AI生成视频的创作变得越来越快和容易，导致互联网上充斥着各种视频内容。然而，这些视频对内容生态系统的影响在很大程度上仍未被探索。视频信息检索仍然是访问视频内容的基本方法。基于检索模型在即席和图像检索任务中通常偏爱AI生成内容的观察，我们调查了在具有挑战性的视频检索背景下是否也存在类似的偏好，其中时间因素和视觉因素可能进一步影响模型行为。为了探索这一点，我们首先构建了一个包含真实和AI生成视频的综合基准数据集，以及一套公平严谨的指标来评估偏好。该基准包含由两个最先进的开源视频生成模型生成的13,000个视频。我们精心设计了一套严格的指标来准确测量这种偏好，同时考虑了AIGC视频有限帧率和次优质量可能引起的潜在偏差。然后，我们将三个现成的视频检索模型应用于该混合数据集以执行检索任务。我们的研究结果揭示了检索中对AI生成视频的明显偏好。进一步的调查表明，将AI生成视频纳入检索模型的训练集会加剧这种偏好。与图像模态中观察到的偏好不同，我们发现视频检索偏好源于未见的视觉和时间信息，使得视频偏好的根本原因成为这两个因素的复杂相互作用。为了减轻这种偏好，我们使用对比学习方法对检索模型进行了微调。这项研究的结果强调了AI生成视频对检索系统潜在的影响。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [405] [Pendulum Model of Spiking Neurons](https://arxiv.org/abs/2507.22146)
> *脉冲神经元的摆模型*

*Joy Bose* | **Category: cs.NE, q-bio.NC, C.1.3; I.5.1; I.6.3** | **Updated: 2025-07-29**

**Keywords:** 脉冲神经元, 摆模型, 二阶动力学, 神经拟态计算, STDP

**Comment:** 5 pages, 2 figures, 1 table

> **TL;DR:** 提出一种基于阻尼驱动摆的脉冲神经元模型，具有二阶非线性动力学，能更好地处理时间特征和时序敏感计算，适用于神经拟态硬件。

**AI_Comments:** 这篇论文的创新点在于引入了基于摆动力学的二阶非线性模型，这与传统的积分-发射模型有显著不同，有望更好地模拟生物神经元的复杂动态行为，特别是振荡和相位编码。其重要性在于为处理时序敏感任务（如序列处理和符号学习）提供了新的计算范式，并为在神经拟态硬件上实现节能系统开辟了途径。

<details>
  <summary>Details</summary>

**Motivation:** 传统模型如LIF神经元缺乏二阶非线性动力学，无法自然产生振荡行为和基于相位的尖峰编码，也无法捕捉更丰富的时间特征和支持时序敏感计算。

**Method:** 提出基于阻尼驱动摆动力学的脉冲神经元模型，该模型具有二阶非线性动力学。分析了单神经元动力学，并扩展到受STDP学习规则控制的多神经元层。通过Python代码和Brian2模拟器进行实现，并概述了在神经拟态硬件平台上部署该模型的方法。

**Result:** 该模型自然产生振荡行为和基于相位的尖峰编码，捕获更丰富的时间特征，并支持对序列处理和符号学习至关重要的时序敏感计算。展示了在Python和Brian2中的实际实现。

**Conclusion:** 该框架为开发用于神经拟态计算和序列认知任务的节能神经系统提供了基础。

> **ai_Abstract:** 这篇论文提出了一种新的脉冲神经元模型，称为“摆神经元”，其灵感来源于阻尼驱动摆的动力学。与传统的LIF模型不同，摆神经元引入了二阶非线性动力学，使其能够自然地产生振荡并支持基于相位的尖峰编码，从而捕捉更复杂的时间特征和进行时序敏感计算。作者分析了单神经元动力学，并将其扩展到多神经元层，结合了STDP学习规则。该模型已通过Python和Brian2模拟器实现，并提出了在神经拟态硬件上部署的策略。该研究旨在为开发高效的神经拟态计算和序列认知系统奠定基础。

> **摘要翻译:** 我们提出了一种受生物学启发的脉冲神经元模型，该模型基于阻尼驱动摆的动力学。与漏积分-发射（LIF）神经元等传统模型不同，摆神经元结合了二阶非线性动力学，自然地产生振荡行为和基于相位的尖峰编码。该模型捕捉了更丰富的时间特征，并支持对序列处理和符号学习至关重要的时序敏感计算。我们分析了单神经元动力学，并将模型扩展到由尖峰时间依赖可塑性（STDP）学习规则控制的多神经元层。我们展示了使用Python代码和Brian2脉冲神经模拟器进行的实际实现，并概述了使用二阶方程的近似方法在神经拟态硬件平台上部署该模型的方法。该框架为开发用于神经拟态计算和序列认知任务的节能神经系统提供了基础。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [615] [($\boldsymbolθ_l, \boldsymbolθ_u$)-Parametric Multi-Task Optimization: Joint Search in Solution and Infinite Task Spaces](https://arxiv.org/abs/2503.08394)
> *($oldsymbolθ_l, oldsymbolθ_u$)-参数化多任务优化：在解空间和无限任务空间中的联合搜索*

*Tingyang Wei, Jiao Liu, Abhishek Gupta, Puay Siew Tan, Yew-Soon Ong* | **Category: cs.NE, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 参数化多任务优化, 无限任务空间, 联合搜索, 知识转移, 机器人控制

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的参数化多任务优化（PMTO）算法，旨在解决传统多任务优化中任务集固定有限的限制，通过在离线模式下学习近似模型，实现在线模式下对无限任务空间的快速优化，并在机器人控制和鲁棒工程设计中展示了其有效性。

**AI_Comments:** 该论文的创新点在于将多任务优化扩展到无限且连续的参数化任务空间，突破了传统MTO的限制。其提出的双模式（离线学习与在线应用）PMTO算法，特别是通过构建两个近似模型来实现任务间知识转移和任务空间探索，是其核心贡献。这使得系统能够在面对新任务时无需从头开始，大大提高了效率和适应性。在机器人控制和鲁鲁棒工程设计等领域的实际应用验证，进一步凸显了该方法的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 传统多任务优化通常局限于固定且有限的任务集。本文旨在放宽这一条件，处理在参数化、连续且有界任务空间中定义的非固定且可能无限的任务集。

**Method:** 本文提出了一种新颖的($oldsymbol{	heta}_l$, $oldsymbol{	heta}_u$)-参数化多任务优化（PMTO）算法，该算法以两种互补模式运行：1. 离线优化模式：在解空间和任务空间中进行联合搜索，创建两个近似模型：一个用于将统一解空间中的点映射到所有任务的目标空间，以加速收敛并促进任务间知识转移；另一个用于概率性地将任务映射到其对应解，以促进对任务空间未探索区域的进化探索。2. 在线模式：利用导出的模型直接优化任务边界内的任何任务，无需从头开始搜索。

**Result:** 该算法在合成测试问题和实际案例研究中得到了验证。结果表明，PMTO在快速重新配置机器人控制器以适应不断变化的任务条件方面具有显著的现实世界适用性。此外，通过鲁棒工程设计中的一个例子，也展示了PMTO大幅加速极小极大优化问题求解的潜力。

**Conclusion:** 参数化多任务优化（PMTO）方法能够有效处理无限任务空间中的优化问题，并通过离线学习和在线快速应用的方式，显著提升了在机器人控制和鲁棒工程设计等实际应用中的优化效率和适应性。

> **ai_Abstract:** 本文提出了一种新颖的参数化多任务优化（PMTO）框架，旨在解决传统多任务优化中任务集固定且有限的局限性。PMTO考虑在参数化、连续且有界任务空间中定义的非固定且可能无限的任务集。该框架包含一个双模式算法：离线模式通过联合搜索解空间和任务空间，构建两个近似模型——一个用于统一解空间到任务目标空间的映射以促进知识转移和加速收敛，另一个用于任务到解的概率映射以促进任务空间探索；在线模式则利用这些预训练模型实现任务的直接快速优化。实验证明，PMTO在机器人控制器快速重配置和极小极大优化问题求解等实际应用中展现出显著的有效性和加速潜力。

> **摘要翻译:** 多任务优化通常以固定有限的任务集为特征。本文通过考虑在参数化、连续且有界任务空间中定义的非固定且可能无限的优化任务集来放宽这一条件。我们将这种独特的问题设置称为参数化多任务优化（PMTO）。假设任务参数的边界为($oldsymbol{	heta}_l$, $oldsymbol{	heta}_u$)，本文设计了一种新颖的($oldsymbol{	heta}_l$, $oldsymbol{	heta}_u$)-PMTO算法，以两种互补模式运行。在离线优化模式下，通过创建两个近似模型，在解空间和任务空间中进行联合搜索：(1) 用于将统一解空间中的点映射到所有任务的目标空间，这通过充当任务间知识转移的通道，可证明地加速收敛；(2) 用于概率性地将任务映射到其对应解，这有助于对任务空间未探索区域进行进化探索。在在线模式下，导出的模型能够直接优化边界内的任何任务，而无需从头开始搜索。这一结果在合成测试问题和实际案例研究中得到了验证，PMTO在变化任务条件下机器人控制器快速重新配置方面显示出显著的现实世界适用性。通过鲁棒工程设计中的一个例子，也展示了PMTO大幅加速极小极大优化问题求解的潜力。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [748] [Reservoir Computation with Networks of Differentiating Neuron Ring Oscillators](https://arxiv.org/abs/2507.21377)
> *使用分化神经元环形振荡器网络的储层计算*

*Alexander Yeung, Peter DelMastro, Arjun Karuvally, Hava Siegelmann, Edward Rietman, Hananel Hazan* | **Category: cs.NE, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 储层计算, 分化神经元, 小世界网络, MNIST, 节能AI

**Comment:** 8 pages, 5 figures

> **TL;DR:** 本文提出了一种基于分化神经元网络的储层计算新方法，在MNIST手写数字识别任务上取得了与现有方法相当的性能，并有望为功耗大的AI应用提供可持续的替代方案。

**AI_Comments:** 本文的创新点在于提出了使用分化神经元作为储层计算的基质，这与传统的积分神经元方法不同。其重要性在于为解决当前AI应用高能耗问题提供了一个潜在的可持续替代方案，这对于未来AI技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的储层计算方法使用耦合积分神经元网络，需要持续电流来维持活动，这导致了功耗大的问题。本文旨在探索一种替代方案，以解决现有方法的能耗问题。

**Method:** 本文引入了一种由分化神经元组成的小世界图网络作为储层计算的替代基质。这些分化神经元仅在输入发生变化时才活跃。研究人员找到了使这些小世界网络能作为有效储层的耦合强度和网络拓扑结构。

**Result:** 该研究证明了这些分化神经元网络在MNIST数字识别任务中的有效性，取得了90.65%的性能，与现有储层计算方法的性能相当。

**Conclusion:** 研究结果表明，分化神经元可以作为积分神经元的潜在替代品，并能为功耗大的AI应用提供可持续的未来替代方案。

> **ai_Abstract:** 本文提出了一种新颖的储层计算方法，利用分化神经元构成的小世界网络作为替代基质，以解决传统积分神经元网络能耗高的问题。研究通过优化耦合强度和网络拓扑，在MNIST手写数字识别任务上实现了90.65%的准确率，证明了分化神经元作为低功耗AI应用潜力的有效性。

> **摘要翻译:** 储层计算是一种机器学习方法，它利用复杂系统动力学的丰富表现形式进行函数逼近。当前储层计算方法使用耦合积分神经元网络，需要持续电流来维持活动。本文引入了一种由分化神经元组成的小世界图，作为储层计算基质中积分神经元的替代方案，这些分化神经元仅在输入发生变化时才活跃。我们发现耦合强度和网络拓扑结构使得这些小世界网络能够作为有效的储层。我们在MNIST数字识别任务中展示了这些网络的功效，取得了90.65%的性能，与现有储层计算方法相当。这些发现表明，分化神经元可以作为积分神经元的潜在替代品，并能为功耗大的AI应用提供可持续的未来替代方案。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [881] [Hebbian Memory-Augmented Recurrent Networks: Engram Neurons in Deep Learning](https://arxiv.org/abs/2507.21474)
> *赫布记忆增强循环网络：深度学习中的印迹神经元*

*Daniel Szelogowski* | **Category: cs.NE, cs.AI, cs.IR, cs.LG, q-bio.NC, I.2.0; I.2.4; I.2.6; I.2.m; E.1; E.2; E.4; H.3; J.3; J.4** | **Updated: 2025-07-29**

**Keywords:** 赫布学习, 记忆增强网络, 循环神经网络, 印迹神经元, 可解释性

**Comment:** 20 pages, 11 figures, 4 tables

> **TL;DR:** 受生物神经系统启发，本文引入了印迹神经网络（ENN），这是一种结合赫布可塑性和稀疏注意力驱动检索机制的循环网络，旨在通过显式记忆提高模型可解释性。ENN在多个基准测试中表现出与传统RNN相当的性能，并提供了显著的解释性增强。

**AI_Comments:** 该论文的创新点在于将生物学中赫布学习和印迹记忆的概念引入深度学习，提出了一种新型的循环网络架构，显著提升了模型的可解释性。这对于理解深度学习模型的内部运作机制具有重要意义，并为开发更透明、更鲁棒的AI模型提供了新方向。其局限性可能在于其性能与现有主流RNN变体相当，但尚未超越，未来可能需要进一步探索如何利用其显式记忆机制实现性能上的突破。

<details>
  <summary>Details</summary>

**Motivation:** 当前人工循环网络架构主要依赖隐式隐藏状态记忆，限制了其可解释性和建模长距离依赖的能力。受生物神经系统中通过赫布突触可塑性增强的显式、联想性记忆痕迹（印迹）的启发。

**Method:** 引入了印迹神经网络（ENN），这是一种新型循环架构，它包含一个显式的、可微分的记忆矩阵，该矩阵具有赫布可塑性和稀疏的、注意力驱动的检索机制。ENN通过动态赫布痕迹显式建模记忆形成和回忆。

**Result:** ENN在MNIST数字分类、CIFAR-10图像序列建模和WikiText-103语言建模三个基准测试中，实现了与经典RNN、GRU和LSTM架构大致相当的准确性和泛化性能。所有模型在大型WikiText-103任务上收敛到相似的准确性和困惑度。ENN通过可观察的记忆动态显著增强了解释性，赫布痕迹可视化揭示了生物学上合理的、结构化的记忆形成过程。

**Conclusion:** 神经科学启发的机制有潜力促进开发更具可解释性和鲁棒性的深度学习模型。

> **ai_Abstract:** 该论文引入了一种受神经生物学启发的循环神经网络——印迹神经网络（ENN），它通过显式的、可微分的记忆矩阵和赫布可塑性来模拟记忆形成和回忆。ENN旨在解决传统RNN因隐式记忆而导致的解释性差和长距离依赖建模受限的问题。实验结果表明，ENN在多个基准测试中表现出与传统RNN、GRU和LSTM相当的性能，并显著提升了模型的可解释性，揭示了生物学上合理的记忆动态。

> **摘要翻译:** 尽管在各种任务中取得了成功，但当前的人工循环网络架构主要依赖隐式隐藏状态记忆，这限制了它们的可解释性和建模长距离依赖的能力。相比之下，生物神经系统采用显式的、联想性记忆痕迹（即印迹），这些痕迹通过赫布突触可塑性得到加强，并在回忆时稀疏激活。受这些神经生物学见解的启发，我们引入了印迹神经网络（ENN），这是一种新颖的循环架构，它结合了一个显式的、可微分的记忆矩阵，该矩阵具有赫布可塑性和稀疏的、注意力驱动的检索机制。ENN通过动态赫布痕迹显式地建模记忆的形成和回忆，与传统的RNN变体相比，提高了透明度和可解释性。我们在三个典型基准测试中评估了ENN架构：MNIST数字分类、CIFAR-10图像序列建模和WikiText-103语言建模。我们的实证结果表明，ENN在准确性和泛化性能方面与经典的RNN、GRU和LSTM架构大致相当，所有模型在大型WikiText-103任务上都收敛到相似的准确性和困惑度。同时，ENN通过可观察的记忆动态显著增强了解释性。赫布痕迹的可视化进一步揭示了生物学上合理的、结构化的记忆形成过程，验证了神经科学启发的机制在开发更具可解释性和鲁棒性的深度学习模型方面的潜力。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [47] [The eigenvalue decomposition of normal matrices by the skew-symmetric part](https://arxiv.org/abs/2410.12421)
> *通过斜对称部分计算正规矩阵的特征值分解*

*Simon Mataigne, Kyle A. Gallivan* | **Category: math.NA, cs.NA, 65F15, 15B10, 15B57, 62R30** | **Updated: 2025-07-30**

**Keywords:** 特征值分解, 正规矩阵, 斜对称部分, 奇异值分解, 正交矩阵

**Comment:** 45 pages, 6 figures, 2 tables

> **TL;DR:** 提出了一种通过其斜对称部分的分解来计算稠密实正规矩阵特征值分解的新方法，该方法对具有少量实特征值的正规矩阵（如正交矩阵）有优势，且在大多数情况下与Hessenberg分解具有相同的运算量。

**AI_Comments:** 该论文的创新点在于提出了一种通过分解正规矩阵的斜对称部分来执行特征值分解的新颖方法。这种方法尤其适用于那些实特征值较少的正规矩阵，如正交矩阵，这可能在特定应用领域带来性能提升。其与现有高效算法的结合以及在运算量上的竞争力（与Hessenberg分解相当）是其重要性所在。此外，其在黎曼几何计算中的应用展示了该方法的潜在实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 该方法对具有少量实特征值的正规矩阵（如正交矩阵）具有优势，这表明其动机在于为特定类型的正规矩阵提供更有效或更稳定的特征值分解方法。

**Method:** 该方法通过分解稠密实正规矩阵的斜对称部分来计算其特征值分解。它依赖于已知的、可高效实现的算法，如双对角奇异值分解和对称特征值分解。

**Result:** 该方法的数值性能与现有算法进行了比较。在大多数情况下，该方法的运算量与稠密矩阵的Hessenberg分解相同。

**Conclusion:** 该文提出了一种通过斜对称部分分解计算正规矩阵特征值分解的新方法，该方法对具有少量实特征值的正规矩阵（如正交矩阵）表现出优势，并且在运算量上与Hessenberg分解相当。此外，该方法还被应用于特殊正交群上黎曼重心计算。

> **ai_Abstract:** 本文提出了一种计算稠密实正规矩阵特征值分解的新方法，该方法利用其斜对称部分的分解，并结合了双对角奇异值分解和对称特征值分解等高效算法。研究表明，该方法对于具有少量实特征值的正规矩阵（特别是正交矩阵）具有显著优势，并且在大多数情况下，其运算量与稠密矩阵的Hessenberg分解相当。文中还提供了该方法的稳定性、复杂度分析以及与现有算法的数值性能比较，并展示了其在特殊正交群上计算黎曼重心的应用。

> **摘要翻译:** 我们提出了一种通过其斜对称部分的分解来计算稠密实正规矩阵A的特征值分解的新方法。该方法依赖于已知可高效实现的算法，如双对角奇异值分解和对称特征值分解。该方法的优势体现在具有少量实特征值的正规矩阵，例如正交矩阵。我们对该方法进行了稳定性和复杂度分析。数值性能与现有算法进行了比较。在大多数情况下，该方法的运算量与稠密矩阵的Hessenberg分解相同。最后，我们提供了在特殊正交群上计算黎曼重心的应用实验。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [82] [Solving Random Hyperbolic Conservation Laws Using Linear Programming](https://arxiv.org/abs/2501.10104)
> *使用线性规划求解随机双曲守恒律*

*Shaoshuai Chu, Michael Herty, Maria Lukacova-Medvidova, Yizhou Zhou* | **Category: math.NA, cs.NA** | **Updated: 2025-07-29**

**Keywords:** 随机双曲守恒律, 线性规划, 测度值解, 结构保持, 数值方法

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的结构保持数值方法，通过广义测度值解和线性规划来求解随机双曲守恒律系统。

**AI_Comments:** 该论文提出了一种创新的方法，将随机双曲守恒律问题转化为线性规划问题，这在数值求解领域具有重要意义。其结构保持特性是其一大优势。

<details>
  <summary>Details</summary>

**Motivation:** 需要一种新颖的结构保持数值方法来求解随机双曲守恒律系统。

**Method:** 该方法利用广义的、测度值解的概念来处理随机守恒律，从而得到一个关于Young测度的线性偏微分方程，并通过线性规划问题计算近似解。

**Result:** 对一维Burgers方程和等熵Euler方程的数值结果，以及与随机配置方法的比较，都说明了所提出数值方法的行为。

**Conclusion:** 所提出的数值方法具有结构保持特性，并且通过数值结果证明了其有效性。

> **ai_Abstract:** 本文介绍了一种新颖的结构保持数值方法，用于求解随机双曲守恒律系统。该方法基于广义测度值解的概念，将问题转化为一个关于Young测度的线性偏微分方程，并通过线性规划求解。文章分析了该方法的结构保持特性，并讨论了其优缺点。通过一维Burgers方程和等熵Euler方程的数值实验以及与随机配置方法的对比，验证了该方法的有效性。

> **摘要翻译:** 本文提出了一种求解随机双曲守恒律系统的新型结构保持数值方法。该方法利用随机守恒律的广义测度值解的概念，从而得到一个关于Young测度的线性偏微分方程，并允许基于线性规划问题计算近似解。我们分析了所导出的数值方法的结构保持特性，并讨论了其优缺点。一维Burgers方程和等熵Euler方程的数值结果以及与随机配置方法的比较说明了所提出数值方法的行为。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [124] [A Neural Network Enhanced Born Approximation for Inverse Scattering](https://arxiv.org/abs/2503.01596)
> *神经网络增强的Born逆散射近似*

*Ansh Desai, Jonathan Ma, Timo Lahivaara, Peter Monk* | **Category: math.NA, cs.NA, 35R30, 35J25, 35P25, 68T07** | **Updated: 2025-07-30**

**Keywords:** 逆散射, Born近似, 卷积神经网络, 时间谐波声学, 折射率

**Comment:** 23 pages, 11 figures. To be published

> **TL;DR:** 本文提出了两种基于卷积神经网络（CNN）的Born近似修正方法（BCNN和CNNB），以扩展其在逆散射问题中的应用范围，使其适用于非弱散射情况。

**AI_Comments:** 这项工作通过将深度学习（CNN）与经典的Born近似相结合，有效解决了逆散射问题中传统方法在强散射条件下的局限性。其创新点在于提出了两种不同的神经网络集成策略（预校正和后校正），并证明了其在扩展模型适用性方面的有效性。特别是CNNB的强大泛化能力，预示着这种数据驱动方法在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的Born逆散射近似在弱散射情况下表现良好，但当散射不弱时会失效。本文旨在通过引入神经网络来修正Born近似，以克服其在强散射条件下的局限性，从而更准确地确定散射体的折射率。

**Method:** 本文提出了两种卷积神经网络（CNN）算法来修正传统的Born逆散射近似：1. Born-CNN (BCNN)：对Born重建结果进行后校正。2. CNN-Born (CNNB)：对原始数据进行预校正。这两种方法都利用了Born近似在弱散射中的高保真度，并通过CNN扩展其适用范围。

**Result:** 所提出的修正Born模型（BCNN和CNNB）提供了获取折射率的替代数据驱动方法。这些方法成功地将Born近似的实用性扩展到传统方法失效的区域。特别是CNNB在更复杂的分布外散射体上表现出强大的泛化能力。

**Conclusion:** 通过结合卷积神经网络，修正后的Born模型（BCNN和CNNB）成功地将Born近似的应用范围扩展到非弱散射情况，为时间谐波声学逆散射问题提供了有效且具有强大泛化能力的数据驱动解决方案。

> **ai_Abstract:** 本文针对时间谐波声学逆散射问题中传统Born近似在非弱散射情况下的局限性，提出了两种基于卷积神经网络（CNN）的修正方法：Born-CNN (BCNN) 对Born重建结果进行后校正，而CNN-Born (CNNB) 则对原始数据进行预校正。研究表明，这些神经网络增强的Born模型能够有效扩展Born近似的应用范围，即使在传统方法失效的强散射条件下也能准确获取散射体的折射率，尤其CNNB展现出优异的泛化能力。

> **摘要翻译:** 时间谐波声学逆散射涉及根据远场波散射数据确定不可接近、可穿透散射体的折射率这一病态且非线性问题。当散射较弱时，正则化逆Born近似提供了一种线性化模型，用于恢复散射体的形状和材料特性。我们提出了两种卷积神经网络（CNN）算法，即使在散射不弱的情况下也能修正传统的逆Born近似。这些算法分别命名为Born-CNN (BCNN) 和 CNN-Born (CNNB)。BCNN对Born重建进行后校正，而CNNB对数据进行预校正。这两种方法都利用了Born近似在弱散射中的出色保真度，同时将其适用性扩展到其理论极限之外。CNNB尤其对更复杂的分布外散射体表现出强大的泛化能力。基于数值测试和与其他标准方法的基准测试，我们修正后的Born模型提供了获取折射率的替代数据驱动方法，将Born近似的效用扩展到传统方法失效的区域。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [166] [Error estimates for numerical approximations of a nonlinear gradient flow model](https://arxiv.org/abs/2505.13929)
> *非线性梯度流模型数值逼近的误差估计*

*Jerome Droniou, Kim-Ngan Le, Huateng Zhu* | **Category: math.NA, cs.NA** | **Updated: 2025-07-30**

**Keywords:** 非线性梯度流, 梯度离散化方法, 误差估计, 数值分析, 隐式格式

**Comment:** 

> **TL;DR:** 本文使用梯度离散化方法（GDM）对非线性梯度流模型进行数值分析，提出了一种全离散隐式格式，并证明了其解的存在性、唯一性、稳定性和一致性，并建立了误差估计。

**AI_Comments:** 这项工作通过采用GDM框架，为非线性梯度流模型的数值逼近提供了严谨的理论基础，特别是在证明了隐式格式的各项性质和误差估计方面。GDM作为统一的收敛性分析框架，提升了研究的通用性和适用性。

<details>
  <summary>Details</summary>

**Motivation:** 对非线性梯度流模型进行数值分析，该模型可视为抛物线型极小曲面问题或正则化全变分流。

**Method:** 采用梯度离散化方法（GDM），提出了一种全离散隐式格式。GDM是一个统一的收敛性分析框架，涵盖了协调和非协调数值方法。

**Result:** 证明了所提出的全离散隐式格式解的存在性和唯一性；分析了格式的稳定性和一致性；建立了误差估计。

**Conclusion:** 本文成功地对非线性梯度流模型进行了数值分析，并为所提出的全离散隐式格式提供了严谨的数学证明，包括解的存在性、唯一性、稳定性和误差估计，为该模型的数值逼近提供了理论基础。

> **ai_Abstract:** 本文利用梯度离散化方法（GDM）对一种可视为抛物线型极小曲面问题或正则化全变分流的非线性梯度流模型进行了数值分析。研究提出了一种全离散隐式格式，并从理论上证明了其解的存在性、唯一性、稳定性和一致性，同时建立了误差估计。

> **摘要翻译:** 我们使用梯度离散化方法（GDM）对非线性梯度流进行数值分析，该方法可视为抛物线型极小曲面问题或正则化全变分流。GDM是一个统一的收敛性分析框架，涵盖了协调和非协调数值方法，例如，协调和非协调有限元、两点通量逼近等。在本文中，提出了一种模型的全离散隐式格式，证明了该格式解的存在性和唯一性，分析了格式的稳定性和一致性，并建立了误差估计。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [586] [An inherent regularization approach to parameter-free preconditioning for nearly incompressible linear poroelasticity and elasticity](https://arxiv.org/abs/2507.22334)
> *针对近不可压缩线性多孔弹性与弹性的无参数预处理的固有正则化方法*

*Weizhang Huang, Zhuoran Wang* | **Category: math.NA, cs.NA, 65N30, 65F08, 65F10, 74F10** | **Updated: 2025-07-30**

**Keywords:** 多孔弹性, 弹性, 正则化, 预处理, 鞍点系统

**Comment:** 

> **TL;DR:** 本文研究了一种固有正则化策略和块Schur补预处理方法，用于高效迭代求解近不可压缩线性多孔弹性问题，实现了与网格尺寸和锁定参数无关的收敛性。

**AI_Comments:** 本文的创新之处在于提出了一种固有的正则化策略，有效解决了近不可压缩多孔弹性问题中的近奇异性挑战，从而实现了无参数的迭代求解器收敛。这对于提高此类复杂耦合系统数值模拟的效率和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 线性多孔弹性问题在锁定状态下（固体近不可压缩）会导致离散后的鞍点系统近奇异，这使得高效的迭代求解变得困难。

**Method:** 将近奇异系统重新表述为鞍点问题，并通过在(2,2)块中添加一项进行正则化，确保新系统非奇异且保留解。然后应用块Schur补预处理，并考虑两场和三场公式，利用线性弹性问题的有效求解器。

**Result:** 预处理后的MINRES和GMRES收敛性基本独立于网格尺寸和锁定参数。对于两场和三场公式，均实现了无参数收敛。数值实验证实了正则化策略的有效性和块预处理器的鲁棒性。

**Conclusion:** 本文提出的固有正则化策略与块Schur补预处理相结合，为近不可压缩线性多孔弹性问题提供了一种高效且鲁棒的迭代求解方法，实现了与关键参数无关的收敛性。

> **ai_Abstract:** 本文提出了一种固有正则化策略和块Schur补预处理方法，以解决使用最低阶弱伽辽金有限元和隐式欧拉格式离散的线性多孔弹性问题在锁定状态下出现的近奇异鞍点系统。通过将系统重构为鞍点问题并对(2,2)块进行正则化，确保了新系统的非奇异性，并使得块Schur补预处理变得有效。研究表明，预处理后的MINRES和GMRES算法对于两场和三场公式均能实现与网格尺寸和锁定参数无关的无参数收敛，并通过数值实验验证了方法的有效性和鲁棒性。

> **摘要翻译:** 固有正则化策略和块Schur补预处理被研究用于在空间上使用最低阶弱伽辽金有限元方法和在时间上使用隐式欧拉格式离散的线性多孔弹性问题。在每个时间步，所得的鞍点系统在锁定状态下（固体接近不可压缩时）变得近奇异。这种近奇异性源于对应于线性弹性系统的前导块。为了实现高效的迭代求解，首先将这个近奇异系统重新表述为一个鞍点问题，然后通过在(2,2)块中添加一项进行正则化。这种正则化在保留解的同时确保了新系统的非奇异性。因此，块Schur补预处理变得有效。结果表明，预处理后的MINRES和GMRES的收敛性基本上独立于网格尺寸和锁定参数。对于线性多孔弹性的迭代求解，考虑了两场和三场公式。两场公式的有效求解建立在线性弹性有效迭代求解的基础上。在这种情况下，当与块Schur补预处理结合使用时，MINRES和GMRES实现了无参数收敛，其中前导块的逆利用了线性弹性的高效求解器。多孔弹性问题也可以通过在线性弹性部分引入数值压力变量而重新表述为三场系统。固有正则化策略自然地扩展到这种公式，并且预处理后的MINRES和GMRES也显示出正则化系统的无参数收敛性。二维和三维的数值实验证实了正则化策略的有效性和块预处理器的鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [601] [Numerical PDE solvers outperform neural PDE solvers](https://arxiv.org/abs/2507.21269)
> *数值偏微分方程求解器优于神经偏微分方程求解器*

*Patrick Chatain, Michael Rizvi-Martel, Guillaume Rabusseau, Adam Oberman* | **Category: math.NA, cs.LG, cs.NA, 35R30 (Primary) 65M06 65M32 65C20 68T07 (Secondary)** | **Updated: 2025-07-28**

**Keywords:** DeepFDM, 有限差分, 偏微分方程, 逆问题, 机器学习

**Comment:** 17 pages, 7 figures

> **TL;DR:** DeepFDM是一个可微分的有限差分框架，用于学习时变PDE中的空间变系数。它通过将经典的前向欧拉离散化嵌入卷积架构中，实现了比现有神经方法更低的误差、更少的训练时间和参数，并且能准确恢复系数。

**AI_Comments:** DeepFDM的创新之处在于将传统的有限差分方法与深度学习架构相结合，特别是在卷积网络中嵌入经典的前向欧拉离散化，并通过CFL条件确保了数值稳定性和收敛性。这解决了纯粹的神经网络在处理PDE时可能遇到的稳定性和可解释性问题。其重要性在于提供了一个性能优越且易于解释的逆问题求解框架，为数据驱动的PDE求解和识别设定了一个强大的基线，并可能启发更多结合传统数值方法与深度学习的混合模型。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机是开发一种能够有效学习时变偏微分方程（PDEs）中空间变系数的方法，并解决PDE的逆问题。

**Method:** 本研究提出了DeepFDM，一个可微分的有限差分框架。它通过将经典的前向欧拉离散化嵌入到卷积架构中，并通过符合CFL条件的系数参数化来确保稳定性和一阶收敛。模型权重直接对应于PDE系数。

**Result:** DeepFDM在标量PDE基准测试中，与傅里叶神经算子、U-Net和ResNet相比，归一化均方误差小1到2个数量级；所需训练周期减少10-20倍；所需参数减少5-50倍。此外，恢复的系数场与真实参数准确匹配。

**Conclusion:** DeepFDM被确立为一种鲁棒、高效且透明的数据驱动的参数化PDE求解和识别的基线方法。

> **ai_Abstract:** DeepFDM是一个创新的可微分有限差分框架，旨在学习时变偏微分方程中的空间变系数。它将经典的前向欧拉离散化集成到卷积网络中，确保了数值稳定性和收敛性，并使模型权重直接对应于PDE系数，从而提供可解释的逆问题解决方案。在多维标量PDE基准测试中，DeepFDM在误差、训练效率和模型参数量方面显著优于傅里叶神经算子、U-Net和ResNet等主流神经方法，并能准确恢复真实系数。这表明DeepFDM为参数化PDE的数据驱动求解和识别提供了一个高效、鲁棒且透明的新基线。

> **摘要翻译:** 我们提出了DeepFDM，一个可微分的有限差分框架，用于学习时变偏微分方程（PDEs）中的空间变系数。通过将经典的前向欧拉离散化嵌入到卷积架构中，DeepFDM通过符合CFL条件的系数参数化来强制实现稳定性和一阶收敛。模型权重直接对应于PDE系数，从而产生一种可解释的逆问题表述。我们在标量PDE的基准套件上评估了DeepFDM：包括一维、二维和三维空间中的对流、扩散、对流-扩散、反应-扩散和非均匀Burgers方程。在分布内和分布外测试中（通过系数先验之间的Hellinger距离量化），DeepFDM的归一化均方误差比傅里叶神经算子、U-Net和ResNet小1到2个数量级；所需的训练周期减少10-20倍；并且使用的参数减少5-50倍。此外，恢复的系数场准确匹配真实参数。这些结果确立了DeepFDM作为数据驱动的参数化PDE求解和识别的鲁棒、高效和透明的基线。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [610] [Linear Stability Analysis of Physics-Informed Random Projection Neural Networks for ODEs](https://arxiv.org/abs/2408.15393)
> *常微分方程的物理信息随机投影神经网络的线性稳定性分析*

*Gianluca Fabiani, Erik Bollt, Constantinos Siettos, Athanasios N. Yannacopoulos* | **Category: math.NA, cs.LG, cs.NA, math.DS, 65L20, 68T07, 65L04, 37N30** | **Updated: 2025-07-29**

**Keywords:** 物理信息神经网络, 随机投影, 常微分方程, 线性稳定性, 数值分析

**Comment:** 17 pages, 3 figures

> **TL;DR:** 本文对用于求解常微分方程（ODE）的物理信息随机投影神经网络（PI-RPNNs）进行了线性稳定性分析，并证明了其作为数值解法的收敛性和渐近稳定性。

**AI_Comments:** 这篇论文的创新点在于对物理信息随机投影神经网络（PI-RPNNs）的理论基础进行了严谨的线性稳定性分析，填补了该领域的一个空白。通过证明其均匀逼近性、一致性、渐近稳定性和收敛性，为PI-RPNNs在求解（刚性）常微分方程方面的应用提供了坚实的理论支撑。特别是对多配置PI-RPNNs渐近稳定性的证明，具有重要的指导意义。这对于推动物理信息神经网络在科学计算中的可靠性应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在对物理信息随机投影神经网络（PI-RPNNs）进行线性稳定性分析，以评估其在数值求解（刚性）常微分方程初值问题（IVP）时的性能和可靠性。

**Method:** 研究首先证明了PI-RPNNs是常微分方程解的均匀逼近器。接着，通过构造性证明，展示了PI-RPNNs提供了一致且渐近稳定的数值方案，从而证明了其收敛性。特别地，证明了多配置PI-RPNNs能保证渐近稳定性。理论结果通过数值求解基准示例进行验证，并与后向欧拉法、中点法、梯形法则、二阶段高斯方案以及二、三阶段拉道方案进行了比较。

**Result:** 研究证明了PI-RPNNs是常微分方程解的均匀逼近器。PI-RPNNs提供了一致且渐近稳定的数值方案，因此是收敛的方案。多配置PI-RPNNs被证明能保证渐近稳定性。数值示例支持了这些理论结果，并显示出与传统数值方法的良好比较。

**Conclusion:** 物理信息随机投影神经网络（PI-RPNNs）是求解常微分方程初值问题的有效且可靠的数值方法，它们具有均匀逼近性、一致性、渐近稳定性和收敛性，特别是多配置PI-RPNNs能保证渐近稳定性。

> **ai_Abstract:** 本文对物理信息随机投影神经网络（PI-RPNNs）用于求解常微分方程（ODE）的线性稳定性进行了深入分析。研究首先证明了PI-RPNNs能够均匀逼近ODE的解，并通过构造性证明揭示了它们作为数值方案的一致性、渐近稳定性和收敛性。特别强调了多配置PI-RPNNs在保证渐近稳定性方面的优势。通过与多种传统数值方法的对比，数值示例验证了这些理论发现。

> **摘要翻译:** 我们对物理信息随机投影神经网络（PI-RPNNs）进行了线性稳定性分析，用于数值求解（刚性）常微分方程的初值问题（IVP）。我们首先证明了PI-RPNNs是常微分方程解的均匀逼近器。然后，我们提供了一个构造性证明，表明PI-RPNNs提供了稳定且渐近稳定的数值方案，从而证明了其收敛性。特别是，我们证明了多配置PI-RPNNs保证了渐近稳定性。我们的理论结果通过基准示例的数值解进行了说明，其中包括与后向欧拉法、中点法、梯形法则、二阶段高斯方案以及二、三阶段拉道方案的指示性比较。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [622] [Pulsatile Flows for Simplified Smart Fluids with Variable Power-Law: Analysis and Numerics](https://arxiv.org/abs/2507.22449)
> *脉动流对变幂律简化智能流体的分析与数值计算*

*Luigi C. Berselli, Alex Kaltenbach* | **Category: math.NA, cs.NA, math.AP, 35Q35, 76A05, 76D05, 65M60, 35D30, 35K55, 35B10, 76M10, 35Q30** | **Updated: 2025-07-30**

**Keywords:** 脉动流, 智能流体, 变幂律, 非牛顿流体, 时间周期解

**Comment:** 37 pages, 12 figures

> **TL;DR:** 本文研究了具有位置依赖性幂律指数的剪切依赖性非牛顿流体在管道中的时间周期性运动，证明了时间周期解的存在性，并提供了数值方法和基准解。

**AI_Comments:** 这项工作通过引入位置依赖的幂律指数泛化了非牛顿流体模型，并提供了时间周期解的严格数学证明和构造性数值方法。其创新之处在于统一处理了不同指数值，无需辅助牛顿项，为智能流体等实际应用提供了重要的理论和数值基础。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在推广已知的Navier-Stokes和p-流体方程的结果，为电致流变流体或更广义的“智能流体”识别相关的显式基准解，并支持这些流体的实际应用。

**Method:** 研究了具有可变指数流变学的剪切依赖性非牛顿流体在无限管道中的充分发展、时间周期性运动，重点是广义的p(·)-流体模型，其中幂律指数p(Σ)是位置依赖的。通过完全离散的有限差分/-元离散化，提供了变分解的完全构造性存在性证明。

**Result:** 证明了具有给定时间周期流量或压降的时间周期解的存在性，推广了Navier-Stokes和p-流体方程的已知结果。识别了显式解作为基准案例。提供了与数值实验一致的变分解的完全构造性存在性证明。

**Conclusion:** 该方法统一处理了所有p(x)值，无需辅助牛顿项，即使在常数指数情况下也提供了新的见解。理论发现通过数值实验得到了验证。

> **ai_Abstract:** 本文研究了具有位置依赖性幂律指数的剪切依赖性非牛顿流体在管道中的脉动流。作者证明了具有给定流量或压降的时间周期解的存在性，并识别了显式基准解，特别适用于智能流体。通过完全离散化提供了变分解的构造性存在性证明，该方法统一处理了不同幂律指数，无需辅助牛顿项，为实际应用提供了重要见解。

> **摘要翻译:** 我们研究了剪切依赖性非牛顿流体在无限管道 $\Omega:= \mathbb{R}\times \Sigma\subseteq \mathbb{R}^d$, $d\in \{2,3\}$ 中充分发展的时间周期性运动，该管道具有任意横截面 $\Sigma\subseteq \mathbb{R}^{d-1}$，并具有可变指数流变学。重点是一个广义的 $p(\cdot)$-流体模型，其中幂律指数与位置相关（相对于 $\Sigma$），即一个函数 $p\colon \Sigma\to (1,+\infty)$。我们证明了具有给定时间周期流量或压降的时间周期解的存在性，推广了Navier-Stokes和p-流体方程的已知结果。此外，我们确定了显式解，这些解作为基准案例具有相关性，特别是对于电致流变流体或更广义的“智能流体”。为了支持实际应用，我们通过完全离散的有限差分/-元离散化，提供了一个完全构造性的变分解存在性证明，这与我们的数值实验一致。我们的方法统一了所有 $p(\overline{x})\in (1,+\infty)$，$\overline{x}\in \Sigma$ 值的处理，无需辅助牛顿项，即使在常数指数情况下也提供了新的见解。理论发现通过数值实验进行了验证。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [657] [A surrogate model for topology optimisation of elastic structures via parametric autoencoders](https://arxiv.org/abs/2507.22539)
> *基于参数化自编码器的弹性结构拓扑优化代理模型*

*Matteo Giacomini, Antonio Huerta* | **Category: math.NA, cs.AI, cs.CE, cs.LG, cs.NA, math.OC, 49M41, 74P05, 74P15, 74S05, 65M60, 65M30** | **Updated: 2025-07-30**

**Keywords:** 拓扑优化, 代理模型, 参数化自编码器, 弹性结构, 机器学习

**Comment:** 39 pages, 13 figures, 7 tables

> **TL;DR:** 本文提出了一种基于代理模型的拓扑优化算法，用于参数化载荷和边界条件下的线性弹性结构。该方法通过预测初始拓扑并进行后续修正，显著减少了优化迭代次数，同时保持了高精度。

**AI_Comments:** 该论文的创新点在于构建了整个拓扑优化流程的代理模型，而非仅仅代理状态解或优化轨迹。通过结合参数化自编码器进行初始预测，并辅以一个高效的修正步骤，有效平衡了计算效率和设计精度。这种两阶段方法能够有效消除代理模型可能引入的误差和伪影，使其结果更符合物理原理，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统拓扑优化计算成本高昂，尤其是在参数化载荷和边界条件下。本文旨在开发一种高效的代理模型方法，以加速拓扑优化过程，避免重复计算。

**Method:** 该方法提出了一种代理版本的完整优化流程。首先，利用前馈网络和编码器/解码器块（参数化自编码器）预测给定问题配置的准最优拓扑，将输入参数映射到潜在空间。然后，将预测的拓扑作为初始猜测，输入到一个计算高效的算法中，该算法通过惩罚设计变量的中间值并强制满足系统控制方程来修正代理模型引入的潜在误差、消除伪影并细化设计。

**Result:** 该方法使准最优拓扑在目标函数最优值差异低于4%的情况下，平均优化迭代次数减少了53%，即使在超出训练和验证域的推断场景下也能表现良好。

**Conclusion:** 本文提出的基于代理模型的拓扑优化算法能够显著提高计算效率，同时保持设计质量，并通过两阶段方法有效处理代理模型可能引入的误差。

> **ai_Abstract:** 本文提出了一种基于参数化自编码器的代理模型拓扑优化算法，用于在参数化载荷和边界条件下优化线性弹性结构。该方法包含两个阶段：首先利用前馈网络和编码器/解码器预测一个准最优拓扑；然后将该预测结果作为初始猜测输入到高效算法中进行修正和细化。实验结果表明，该方法在保证设计质量的同时，能显著减少优化迭代次数，即使在模型外推能力方面也表现出色。

> **摘要翻译:** 本文提出了一种用于参数化载荷和边界条件下的线性弹性结构的基于代理模型的拓扑优化算法。与学习状态（和伴随）问题的参数化解或优化轨迹作为迭代函数不同，所提出的方法设计了整个优化流程的代理版本。首先，该方法通过前馈网络学习表征系统设置的输入参数与由编码器/解码器块确定的潜在空间之间的映射，从而降低参数化拓扑优化问题的维度并重建拓扑的高维表示，以此预测给定问题配置的准最优拓扑，作为高保真拓扑（通过均匀化方法优化）的代理模型。然后，将预测的拓扑用作计算高效算法的良好初始猜测，该算法惩罚设计变量的中间值，同时强制执行系统的控制方程。此步骤允许该方法纠正代理模型引入的潜在错误，消除伪影，并细化设计，以产生与底层物理一致的拓扑。本文提出了不同的架构，并对所得模型的近似和泛化能力进行了数值评估。准最优拓扑使得高保真优化器的性能超越，平均优化迭代次数减少了53%，同时目标函数最优值差异低于4%，即使在测试模型超出训练和验证域的挑战性场景下也是如此。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [691] [A Structure-Preserving Rational Integrator for the Replicator Dynamics on the Probability Simplex](https://arxiv.org/abs/2507.22609)
> *概率单纯形上复制器动力学的保结构有理积分器*

*Mario Pezzella* | **Category: math.NA, cs.NA, math.DS, 65L05, 65L70, 65Z05, 37M15, 41A20** | **Updated: 2025-07-30**

**Keywords:** 复制器动力学, 有理积分器, 概率单纯形, 保结构, 自适应时间步长

**Comment:** 

> **TL;DR:** 本文提出了一种针对复制器动力学的二次收敛且动态一致的保结构有理积分器，该积分器通过结合两阶段有理逼近和归一化步骤，确保了对概率单纯形的限制、非负性、不变集和平衡点的无条件保持，并实现了二阶精度和自适应时间步长，数值实验验证了其优越性。

**AI_Comments:** 该论文提出了一种创新的保结构有理积分器，其核心在于结合两阶段有理逼近和归一化步骤，这对于保证复制器动力学在概率单纯形上的动态一致性至关重要。二阶精度和自适应时间步长的设计进一步提升了其实用性。数值实验结果显示其在复杂动力学再现和挑战性场景下的优越性，表明其在相关领域具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为复制器动力学引入一个二次收敛且动态一致的积分器，以确保对概率单纯形的限制并无条件保持非负性、不变集和平衡点。

**Method:** 该方案结合了两阶段有理逼近和归一化步骤。通过严格的收敛性分析确定其二阶精度，并设计了一种嵌入式辅助方法用于基于局部误差估计的自适应时间步长。此外，证明了分量比演化所遵循的商法则的离散模拟成立。

**Result:** 该积分器具有二次收敛性，并能无条件保持非负性、不变集和平衡点。数值实验验证了理论结果，表明该方法能够重现复杂的动力学，并在特别具有挑战性的场景中优于成熟的求解器。

**Conclusion:** 本文提出的保结构有理积分器能够有效且准确地模拟复制器动力学，并在复杂和挑战性场景中表现出优越性。

> **ai_Abstract:** 本文提出了一种用于复制器动力学的保结构有理积分器。该方法结合了两阶段有理逼近和归一化步骤，确保了对概率单纯形的限制以及非负性、不变集和平衡点的保持。通过严格的分析，该积分器被证明具有二阶精度，并引入了自适应时间步长机制。数值实验表明，该方法能够有效地再现复杂动力学，并在挑战性场景中超越现有求解器。

> **摘要翻译:** 在这项工作中，我们引入了一种专门为复制器动力学设计的二次收敛且动态一致的积分器。所提出的方案结合了两阶段有理逼近和归一化步骤，以确保限制在概率单纯形内，并无条件地保持非负性、不变集和平衡点。我们提供了严格的收敛性分析以确立该方案的二阶精度，并设计了一种嵌入式辅助方法，用于基于局部误差估计的自适应时间步长。此外，还证明了控制分量比演化的商法则的离散模拟成立。数值实验验证了理论结果，说明了该方法重现复杂动力学以及在特别具有挑战性的场景中优于成熟求解器的能力。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [722] [Randomized Kaczmarz Methods with Beyond-Krylov Convergence](https://arxiv.org/abs/2501.11673)
> *随机Kaczmarz方法与超越Krylov的收敛*

*Michał Dereziński, Deanna Needell, Elizaveta Rebrova, Jiaming Yang* | **Category: math.NA, cs.DS, cs.LG, cs.NA, math.OC, stat.ML** | **Updated: 2025-07-29**

**Keywords:** 随机Kaczmarz方法, Krylov子空间, Kaczmarz++, 异常奇异值, 线性系统求解

**Comment:** SIMAX

> **TL;DR:** 本文提出了Kaczmarz++，一种加速的随机块Kaczmarz算法，它能利用输入中的异常奇异值实现快速的Krylov式收敛，并且在理论上和实验上都展示出优于或与流行Krylov方法相当的性能。

**AI_Comments:** 本文的创新点在于成功地将Kaczmarz方法与Krylov方法的优势结合起来，通过引入一系列新颖的算法改进（如自适应动量加速和记忆化方案），解决了Kaczmarz方法在处理病态系统时收敛速度慢的局限性。这使得随机Kaczmarz方法在某些关键场景下能够与Krylov方法竞争甚至超越它们，对于线性系统求解领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的Kaczmarz方法在处理病态系统时，收敛速度不如Krylov子空间方法，因为后者能利用输入奇异值分布中的异常值实现快速收敛。因此，需要改进Kaczmarz方法以达到Krylov式的收敛性能。

**Method:** 本文引入了Kaczmarz++，一种加速的随机块Kaczmarz算法，它通过利用输入中的异常奇异值来实现快速的Krylov式收敛。为了达到这些结果，本文对Kaczmarz框架引入了几项新颖的算法改进，包括自适应动量加速、Tikhonov正则化投影和一种用于重用先前采样方程块信息的记忆化方案。此外，还为正半定系统开发了优化变体CD++。

**Result:** Kaczmarz++能够利用输入中的异常奇异值，实现快速的Krylov式收敛。对于超定和欠定系统，Kaczmarz++在捕获大的异常奇异值方面比流行的Krylov方法更快。CD++在算术运算方面与CG和GMRES在基准问题集上具有竞争力。

**Conclusion:** 本文提出的Kaczmarz++和CD++算法显著提升了随机Kaczmarz方法的性能，使其能够克服传统Kaczmarz方法的局限性，实现与Krylov方法相当甚至更优的收敛速度和效率，尤其是在处理具有异常奇异值的系统时。

> **ai_Abstract:** 本文针对传统Kaczmarz方法在处理病态系统时收敛速度慢于Krylov方法的问题，提出了Kaczmarz++算法。该算法通过引入自适应动量加速、Tikhonov正则化投影和记忆化方案等创新改进，能够有效利用输入中的异常奇异值，实现快速的Krylov式收敛。研究表明，Kaczmarz++在捕获异常奇异值方面表现优异，且其变体CD++在正半定系统上与CG和GMRES等主流方法具有竞争力，从而提升了随机Kaczmarz方法的性能和应用范围。

> **摘要翻译:** 随机Kaczmarz方法是一系列线性系统求解器，它们通过将迭代器重复投影到随机采样的方程上来实现收敛。尽管在某些情况下有效，例如高度超定的最小二乘问题，但Kaczmarz方法传统上被认为次于Krylov子空间方法，因为后一类求解器可以利用输入奇异值分布中的异常值，在病态系统上实现快速收敛。
在本文中，我们引入了Kaczmarz++，一种加速的随机块Kaczmarz算法，它利用输入中的异常奇异值来实现快速的Krylov式收敛。此外，我们证明了对于超定和欠定系统，Kaczmarz++在捕获大的异常奇异值方面比流行的Krylov方法更快。我们还为正半定系统开发了一种优化变体，称为CD++，并通过经验证明它在一系列基准问题上在算术运算方面与CG和GMRES都具有竞争力。为了达到这些结果，我们对Kaczmarz框架引入了几项新颖的算法改进，包括自适应动量加速、Tikhonov正则化投影和一种用于重用先前采样方程块信息的记忆化方案。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [729] [Tropical solution of discrete best approximation problems](https://arxiv.org/abs/2507.22634)
> *离散最佳逼近问题的热带解*

*Nikolai Krivulin* | **Category: math.NA, cs.NA, 15A80 (Primary), 90C24, 41A50, 41A65, 65D15 (Secondary)** | **Updated: 2025-07-30**

**Keywords:** 热带代数, 离散逼近, Puiseux多项式, 向量方程, 凝聚聚类

**Comment:** 23 pages

> **TL;DR:** 本文提出了一种在热带代数中解决离散最佳逼近问题的方法，通过将问题转化为向量方程，并使用迭代算法和聚类技术来确定多项式的系数和指数。

**AI_Comments:** 该论文创新性地将热带代数中的离散最佳逼近问题转化为向量方程求解，并提出了一种新颖的迭代优化算法。其将系数和指数的确定分离并通过交替优化，结合凝聚聚类技术来最小化误差，是一个值得关注的方法。该方法在处理具有幂等运算的代数系统中的逼近问题时具有潜在的应用价值，特别是与分段线性逼近的关联，拓宽了热带代数在实际问题中的应用范围。论文强调了算法的收敛性和有效性，但未详细说明其计算复杂度和在大规模数据上的表现。

<details>
  <summary>Details</summary>

**Motivation:** 在热带代数设置中，考虑离散最佳逼近问题，即给定未知函数的输入输出对，在热带半域上确定一个由两个Puiseux多项式组成的有理函数进行逼近，目标是根据热带距离函数评估每个单项式的指数和系数以拟合数据。

**Method:** 将问题转化为带有未知向量的向量方程逼近问题。提出了一种算法，通过交替固定方程的一侧并近似另一侧来构建一系列近似解。通过对系数向量进行近似，得到由指数参数化的系数向量和近似误差。利用基于凝聚聚类技术的优化过程最小化误差来找到指数。

**Result:** 该算法在有限步内收敛，并为所考虑的问题提供了合理的解决方案。通过max-plus代数（对应于实函数的分段线性逼近问题）的实例验证了其有效性。

**Conclusion:** 所提出的算法能够有效地解决热带代数中的离散最佳逼近问题，并在有限步内收敛，提供合理的近似解。

> **ai_Abstract:** 本研究探讨了热带代数中的离散最佳逼近问题，旨在用热带有理函数逼近未知函数。通过将问题转化为一个带有未知向量的向量方程，研究者提出了一种迭代算法。该算法通过交替固定方程一侧并优化另一侧来求解，其中系数和误差由指数参数化，指数通过凝聚聚类优化确定。实验结果表明，该算法在有限步内收敛，并能有效解决此类问题，尤其在max-plus代数中对应于分段线性逼近。

> **摘要翻译:** 我们考虑在热带代数设置中的离散最佳逼近问题，该代数涉及幂等运算代数系统的理论和应用。给定在热带半域上定义的未知函数的一组输入-输出对，问题是确定一个由两个Puiseux多项式作为分子和分母形成的有理逼近函数。在指定两个多项式中单项式数量的情况下，逼近旨在评估多项式中每个单项式的指数和系数，以根据热带距离函数拟合数据。为了解决这个问题，我们将其转化为一个带有两侧未知向量的向量方程的逼近问题，其中一侧对应于分子多项式，另一侧对应于分母。每一侧都涉及一个矩阵，其项取决于未知指数，并乘以未知单项式系数的向量。我们提出了一种算法，通过交替将方程的一侧固定到已找到的结果而另一侧保持不变来构建一系列近似解。获得的每个方程都根据系数向量进行近似，这会产生一个由指数参数化的系数向量和近似误差。通过基于凝聚聚类技术的优化过程最小化误差来找到指数。为了说明，我们展示了在max-plus代数（一种实半域，加法定义为最大值，乘法定义为算术加法）中的逼近问题的结果，这对应于实函数的分段线性逼近的普通问题。正如我们的数值经验所示，所提出的算法在有限步内收敛，并为所考虑的问题提供了合理的解决方案。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [754] [Space-time finite element methods for nonlinear wave equations via elliptic regularisation](https://arxiv.org/abs/2507.22757)
> *非线性波动方程的时空有限元方法通过椭圆正则化*

*Lehel Banjai, Emmanuil H. Georgoulis, Brian Hennessy* | **Category: math.NA, cs.NA, 65M60, 65M12, 35L71** | **Updated: 2025-07-30**

**Keywords:** 时空有限元, 非线性波动方程, 椭圆正则化, Galerkin离散化, 稳定性

**Comment:** 24 pages, 6 figures

> **TL;DR:** 本文提出并分析了一种基于De Giorgi椭圆正则化观点的半线性波动方程的新型时空Galerkin离散化方法，证明了其适定性、无条件稳定性和误差界，并通过数值实验验证。

**AI_Comments:** 本文的创新之处在于提出了一种基于De Giorgi椭圆正则化观点的时空Galerkin离散化方法来处理非线性波动方程，这为解决该类问题提供了一个新颖的视角。其重要性在于证明了该方法的适定性和无条件稳定性，这对于数值方法的可靠性至关重要。此外，提供了误差界并进行了数值验证，增强了该方法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是提出并分析一种基于De Giorgi椭圆正则化观点的半线性波动方程的新型协调时空Galerkin离散化方法。

**Method:** 该方法基于De Giorgi椭圆正则化观点的二阶波动方程的变分公式，采用协调时空Galerkin离散化。通过最小化方法证明了其适定性，并对足够光滑的解证明了先验误差界。

**Result:** 该方法被证明是适定的，并且对于所有协调离散化空间的选择都是无条件稳定的。此外，对足够光滑的解证明了先验误差界。数值实验验证了理论发现。

**Conclusion:** 所提出的时空有限元方法，通过椭圆正则化处理非线性波动方程，被证明是适定且无条件稳定的，并具有可证明的误差界，其理论结果得到了数值实验的验证。

> **ai_Abstract:** 本文提出了一种基于De Giorgi椭圆正则化观点的半线性波动方程的时空Galerkin离散化方法。该方法通过最小化途径被证明是适定的，并对所有协调离散化空间无条件稳定。此外，对足够光滑的解给出了先验误差界。研究还关注了方法的条件数和稳定实现，并通过数值实验验证了理论结果。

> **摘要翻译:** 我们提出并分析了一种半线性波动方程的新型协调时空Galerkin离散化方法，该方法基于De Giorgi椭圆正则化观点导出的二阶波动方程的变分公式。通过最小化方法证明了该方法的适定性，并且对于所有协调离散化空间的选择都是无条件稳定的。此外，对足够光滑的解证明了先验误差界。特别关注了该方法的条件数及其稳定实现。提供了数值实验来验证理论发现。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [797] [Helmholtz boundary integral methods and the pollution effect](https://arxiv.org/abs/2507.22797)
> *亥姆霍兹边界积分方法与污染效应*

*Jeffrey Galkowski, Manas Rachh, Euan A. Spence* | **Category: math.NA, cs.NA, math.AP** | **Updated: 2025-07-30**

**Keywords:** 亥姆霍兹方程, 边界积分方法, 污染效应, 大波数, 数值分析

**Comment:** 

> **TL;DR:** 研究了亥姆霍兹边界积分方法在大波数时的精度问题，发现多项式方法存在污染效应，而三角多项式方法则没有。

**AI_Comments:** 这篇论文对亥姆霍兹方程在大波数下的数值求解提供了重要见解，特别是在“污染效应”的理解和避免方面。其创新之处在于首次系统地比较了不同基函数（分段多项式和三角多项式）在不同边界积分方法中的表现，并明确指出了三角多项式在抑制污染效应方面的优势。这些发现对于高频波传播问题的数值模拟具有重要的理论和实际意义，有助于开发更高效和鲁棒的数值算法。

<details>
  <summary>Details</summary>

**Motivation:** 在大波数$k$下，对于亥姆霍兹外部Dirichlet和Neumann问题，标准第二类边界积分方程（BIEs）的近似空间维度$N$需要如何随$k$增长才能保持精度，这是该论文关注的核心问题，特别是“污染效应”的存在。

**Method:** 论文考虑了使用标准第二类边界积分方程求解亥姆霍兹外部Dirichlet和Neumann问题。具体方法包括：Galerkin方法和搭配法（Collocation methods），子空间由分段多项式（2D搭配法，任意维度Galerkin）或三角多项式（2D）组成；以及基于三角多项式的全离散正交（Nyström）方法（2D）。

**Result:** 对于涉及分段多项式的方法，给出了$k$均匀准最优性的充分条件，并证明了Galerkin方法这些条件是必要且充分的。证明了当应用于球体障碍物的Neumann BIEs时，Galerkin方法会受到“污染效应”的影响。对于Dirichlet BIEs，证明了在特定耦合参数下球体也会出现污染，并通过数值实验展示了陷阱域的污染效应。对于所有涉及三角多项式的方法，证明了它们基本上不受污染效应的影响。

**Conclusion:** 该研究首次给出了应用于Dirichlet BIEs的搭配法或Nyström方法的$k$显式收敛结果，以及首次给出了解决标准第二类Neumann BIEs的任何方法的$k$显式收敛结果。这表明三角多项式基函数在处理亥姆霍兹方程的大波数问题时具有优越性，能够避免污染效应。

> **ai_Abstract:** 本文研究了在大波数下使用标准第二类边界积分方程求解亥姆霍兹外部Dirichlet和Neumann问题的数值方法。通过分析Galerkin、搭配法和Nyström方法，论文探讨了近似空间维度$N$与波数$k$的增长关系以保持精度。研究发现，基于分段多项式的方法（特别是Galerkin方法）存在“污染效应”，即$N$的增长速度不足以维持精度；而基于三角多项式的方法则能有效避免此效应。这些是首次针对特定边界积分方法在$k$显式收敛性方面的成果。

> **摘要翻译:** 这篇论文关注使用标准第二类边界积分方程（BIEs）解决大波数$k$和光滑障碍物的亥姆霍兹外部Dirichlet和Neumann问题。我们考虑了Galerkin方法和搭配法——子空间由分段多项式（2D搭配法，任意维度Galerkin）或三角多项式（2D）组成——以及基于三角多项式的全离散正交（又称Nyström）方法（2D）。对于这些方法中的每一种，我们都解决了基本问题：为了在$k\to\infty$时保持精度，$N$（近似空间的维度）必须以多快的速度随$k$增长？对于涉及分段多项式的方法，我们给出了$k$均匀准最优性的充分条件。对于Galerkin方法，我们证明了这些条件实际上是必要且充分的。特别地，我们证明，当应用于障碍物为球体的Neumann BIEs时，Galerkin方法会受到“污染效应”的影响；即$N$以$k^{d-1}$增长不足以实现$k$均匀准最优性。对于Dirichlet BIEs，我们证明了在某些耦合参数选择下，球体也会出现污染，并且我们给出了数值实验，说明了标准耦合参数下陷阱域的污染效应。对于所有涉及三角多项式的方法，我们表明，除了任何$\varepsilon>0$的$k^\varepsilon$潜在因子外，这些方法不受污染效应的影响（即使对于陷阱障碍物）。这些是关于应用于Dirichlet BIEs的搭配法或Nyström方法的$k$显式收敛的首次结果，也是关于用于解决标准第二类Neumann BIEs的任何方法的$k$显式收敛的首次结果。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [833] [Numerical Methods for Solving Nonlinearly Coupled Poisson Equations in Dual-Continuum Modeled Porous Electrodes](https://arxiv.org/abs/2507.22818)
> *双连续体模型多孔电极中非线性耦合泊松方程的数值解法*

*Yuhe Wang, Min Wang, Zhihang Xu* | **Category: math.NA, cs.NA, math-ph, math.MP** | **Updated: 2025-07-30**

**Keywords:** 多孔电极, 泊松方程, 数值方法, 恒电流操作, 双连续体模型

**Comment:** 

> **TL;DR:** 本文提出了求解双连续体模型多孔电极中非线性耦合泊松方程的数值方法，特别关注恒电流操作下的挑战性问题，并证明了超电势解的唯一性。

**AI_Comments:** 本文通过系统地解决多孔电极中非线性耦合泊松方程的数值挑战，特别是在困难的恒电流条件下，做出了重要贡献。其数学上证明了超电势解的唯一性，并引入了三种独特的数值方法（LCM、DSM、GCM），特别是GCM能够在不施加显式参考电势的情况下求解超电势，这具有创新性。这些方法对于其他欠约束非线性系统的通用性进一步提升了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 准确确定多孔电极中的电势（特别是过电势）对于理解电极行为至关重要。然而，在恒电流操作模式下，求解通过Butler-Volmer动力学非线性耦合的泊松方程会形成一个欠约束的奇异系统，带来数值挑战。

**Method:** 本文提出并系统地介绍了三种数值方法来解决解的非唯一性问题：拉格朗日约束法 (LCM)、狄利克雷替代法 (DSM) 和全局约束法 (GCM)。其中，GCM 可以在不施加显式系统参考电势的情况下求解过电势。此外，还开发了分离式和完全耦合的非线性求解策略，并评估了它们在同质和异质电导率情况下的计算性能。

**Result:** 本文从电极与电解质之间的电势差（即过电势）以及个体电势（在共享常数偏移下）方面，数学上建立了解决方案的唯一性。所提出的数值方法能够解决恒电流操作下欠约束奇异系统带来的非唯一性问题，并评估了其计算性能。

**Conclusion:** 所提出的数值方法具有通用性，可用于解决类似欠约束的非线性系统，为多孔电极中非线性耦合泊松方程的求解提供了鲁棒的途径，尤其适用于恒电流操作条件。

> **ai_Abstract:** 本文提出了求解双连续体多孔电极模型中非线性耦合泊松方程的新型数值方法，包括拉格朗日约束法、狄利克雷替代法和全局约束法。该研究解决了恒电流操作下系统欠约束和奇异性带来的独特挑战，通过数学证明了过电势解的唯一性，并提供了鲁棒的求解策略，其中一种方法避免了显式参考电势的设定。文章评估了这些方法在不同电导率情况下的计算性能，并指出其对类似欠约束非线性系统具有通用性。

> **摘要翻译:** 多孔电极广泛应用于电化学系统，其中准确确定电势，特别是过电势，对于理解电极行为至关重要。在宏观尺度上，多孔电极通常采用双连续体方法建模，将多孔固体相和液体电解质视为空间上叠加的域。确定电势分布需要求解两个泊松方程，这些方程通过Butler-Volmer动力学在恒电流和恒电势操作模式下非线性耦合。在恒电流操作下，由于全诺伊曼边界条件，这些方程形成一个欠约束的奇异系统，带来了数值挑战。本文系统地介绍了双连续体多孔电极中非线性耦合泊松方程的数值解法，特别关注恒电流解。我们从电极和电解质之间的电势差（或过电势）以及个体电势（在共享常数偏移下）方面，数学上建立了解决方案的唯一性。为了解决解的非唯一性，我们引入了三种数值方法：（1）拉格朗日约束法（LCM），（2）狄利克雷替代法（DSM），和（3）全局约束法（GCM），其中GCM能够在不施加显式系统参考电势的情况下求解过电势。此外，我们还开发了分离式和完全耦合的非线性求解策略，并评估了它们在同质和异质电导率情况下的计算性能。所提出的数值方法对于解决类似的欠约束非线性系统具有通用性。Python 实现可在 https://github.com/harrywang1129/porous_electrode_solver 获得。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [867] [Dynamic analysis of free-free Timoshenko beams on elastic foundation under transverse transient ground deformation](https://arxiv.org/abs/2507.22850)
> *弹性地基上横向瞬态地面变形下自由-自由铁木辛柯梁的动力分析*

*Gersena Banushi* | **Category: math.NA, cs.NA** | **Updated: 2025-07-30**

**Keywords:** 瞬态地面变形, Timoshenko梁, Winkler地基, 动力分析, 半解析模型

**Comment:** Key words: buried Timoshenko beam, semi-analytical model, dynamic
  amplification, transient ground deformation (TGD), modal analysis

> **TL;DR:** 本研究开发了一种基于Timoshenko梁和Winkler地基理论的半解析模型，用于分析埋地直梁在横向瞬态地面变形下的动态响应，并发现振动频谱分为四个部分，且在过渡频率处振动模式特性会发生变化，对系统动态响应产生显著影响。

**AI_Comments:** 该论文提出了一种创新的半解析模型，能够更准确地分析埋地结构在瞬态地面变形下的动态响应，弥补了现有简化模型在惯性和界面位移方面的不足。其通过揭示振动频谱的复杂性和过渡频率的影响，加深了对土-结构相互作用动态行为的理解，对于地下基础设施的抗震设计和安全评估具有重要意义。模型的验证也显示出其较高的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有设计方法基于简化的解析模型，忽略了系统惯性和土-结构界面的相对位移，这对于需要精确动态分析的大直径埋地管道和隧道可能不适用。因此，需要开发新的模型来准确分析埋地结构在瞬态地面变形下的动态响应。

**Method:** 本研究开发了一种基于Timoshenko梁和Winkler地基理论的新型半解析模型，用于分析埋地直梁在横向瞬态地面变形下的动态响应。通过闭式解析解分析了振动频谱，并通过案例研究（不同长度和运行条件下的埋地钢水管道）与有限元分析结果进行比较验证。

**Result:** 闭式解析解揭示振动频谱分为四个部分，由三个过渡频率分隔。在每个过渡频率处，振动模式的振荡特性发生变化，显著影响系统动态响应。与有限元分析结果比较显示出极好的一致性。频率响应分析揭示，在接近系统基频的强制频率下，土-结构相互作用会发生动态放大。

**Conclusion:** 所提出的方法为评估影响埋地梁动态行为的主要因素提供了一个鲁棒的分析框架，加深了对系统在各种地面振动源下响应的理解。对于可能落在地震波主导频率范围内的强制频率，需要精确的动态分析。

> **ai_Abstract:** 本研究提出了一种基于Timoshenko梁和Winkler地基理论的新型半解析模型，用于精确分析埋地直梁在横向瞬态地面变形下的动态响应。该模型克服了现有简化方法忽略惯性和界面相对位移的不足。研究发现振动频谱被三个过渡频率分为四部分，且在这些频率处振动模式特性会显著改变系统响应。通过与有限元分析的对比验证了模型的有效性，并揭示了在特定强制频率下土-结构相互作用的动态放大效应，强调了在地震等场景下进行精确动态分析的重要性。该方法为评估埋地梁动态行为提供了坚实的分析框架。

> **摘要翻译:** 地下基础设施，如管道和隧道，可能容易受到由地震和交通载荷等不同振动源引起的瞬态地面变形（TGD）的影响。当前的设计方法基于简单的解析模型，将土壤运动理想化为行进的正弦波，忽略了系统的惯性和土-结构界面的相对位移。然而，对于需要精确动态分析的埋地大直径管道和隧道，这种假设可能不成立。为了分析埋地直梁在横向TGD作用下的动态响应，本研究开发了一种基于Winkler地基理论上Timoshenko梁的新型半解析模型。闭式解析解揭示振动频谱分为四个部分，由三个过渡频率分隔。在每个过渡频率处，振动模式的振荡特性发生变化，显著影响系统的动态响应。为了验证所提出模型的有效性，本研究分析了一个案例研究，即不同长度和运行条件下的埋地钢水管道在横向TGD作用下的情况。获得的解析解与有限元分析结果的比较显示出两种方法之间极好的一致性。频率响应分析揭示，在接近系统基频的强制频率下，土-结构相互作用会发生动态放大。这些频率可能落在表征地震波的主导频率范围内，需要精确的动态分析。所提出的方法为评估影响埋地梁动态行为的主要因素提供了一个鲁棒的分析框架，加深了对系统在各种地面振动源下响应的理解。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [902] [Numerical Fredholm determinants for matrix-valued kernels on the real line](https://arxiv.org/abs/2507.22875)
> *实数线上矩阵值核的数值Fredholm行列式*

*Erika Gallo, John Zweck, Yuri Latushkin* | **Category: math.NA, cs.NA, math.FA, math.SP, 65R20, 65F40 (Primary) 47G10 (Secondary)** | **Updated: 2025-07-30**

**Keywords:** Fredholm行列式, 矩阵值核, 数值方法, 误差估计, 积分算子

**Comment:** 29 pages, 2 figures

> **TL;DR:** 本文分析了一种计算实数线上矩阵值核的Fredholm行列式的数值方法，通过截断核到有限区间并应用求积规则进行近似，并推导了截断误差和求积误差估计，扩展了Bornemann的工作。

**AI_Comments:** 本文的创新之处在于将Fredholm行列式的数值计算方法从标量值核扩展到更复杂的矩阵值核，并且是从有限区间推广到整个实数线。这对于处理更广泛的积分算子问题具有重要意义。通过提供严格的误差估计（截断误差和求积误差），增强了方法的可靠性和理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发和分析一种数值方法，用于计算实数线上由矩阵值核定义的迹类和Hilbert-Schmidt积分算子的Fredholm行列式。

**Method:** 该方法通过将算子的核截断到有限区间，然后应用求积规则来近似Fredholm行列式。在核呈指数衰减的假设下，推导了实数线上算子的Fredholm行列式与其在有限区间上的截断之间的估计。进一步，推导了通过自适应复合辛普森求积规则获得的数值近似与有限区间上矩阵值核的Fredholm行列式之间的求积误差估计。

**Result:** 导出了将实数线上算子的Fredholm行列式与其在有限区间上的截断相关的估计，以及将有限区间上矩阵值核的Fredholm行列式与其数值近似相关的求积误差估计。这些结果扩展了Bornemann先前关于有限区间上标量值核的工作。提供了Birman-Schwinger算子的数值结果。

**Conclusion:** 本文成功地分析了一种计算实数线上矩阵值核的Fredholm行列式的数值方法，并提供了误差估计，有效扩展了现有理论，并通过具体算子验证了其有效性。

> **ai_Abstract:** 本文介绍了一种计算实数线上矩阵值核的Fredholm行列式的数值方法。该方法通过将算子核截断至有限区间并结合求积规则进行近似。研究在核指数衰减的条件下，推导了截断误差和采用自适应复合辛普森求积规则的求积误差估计。此工作扩展了现有理论，从标量值核推广到矩阵值核，并提供了Birman-Schwinger算子的数值应用。

> **摘要翻译:** 我们分析了一种数值方法，用于计算实数线上由矩阵值核定义的迹类和Hilbert Schmidt积分算子的Fredholm行列式。通过这种方法，Fredholm行列式由一个通过将算子核截断到有限区间然后应用求积规则构建的矩阵的行列式来近似。在核呈指数衰减的假设下，我们推导了一个估计，将实数线上算子的Fredholm行列式与其在有限区间上的截断相关联。然后，我们推导了一个求积误差估计，将有限区间上矩阵值核的Fredholm行列式与其通过自适应复合辛普森求积规则获得的数值近似相关联。这些结果扩展了Bornemann的分析，后者专注于有限区间上由标量值核定义的迹类算子的Fredholm行列式。提供了表征非线性波动方程平稳解稳定性的Birman-Schwinger算子的数值结果。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [12] [Mmm whatcha say? Uncovering distal and proximal context effects in first and second-language word perception using psychophysical reverse correlation](https://arxiv.org/abs/2406.05515)
> *嗯，你说什么？使用心理物理反向关联揭示第一语言和第二语言词语感知中的远端和近端语境效应*

*Paige Tuttösí, H. Henny Yeung, Yue Wang, Fenqi Wang, Guillaume Denis, Jean-Julien Aucouturier, Angelica Lim* | **Category: cs.SD, cs.CL, eess.AS** | **Updated: 2025-07-30**

**Keywords:** 声学语境效应, 言语感知, 反向关联, 第二语言, 元音感知

**Comment:** Accepted to INTERSPEECH 2024 Project Webpage :
  https://rosielab.github.io/vocal_ambiguity/ Code:
  https://github.com/neuro-team-femto/vocal_ambiguity Data :
  https://zenodo.org/records/12761242

> **TL;DR:** 声学语境效应以近端一致和远端对比两种方式影响元音感知，且第一语言和第二语言使用者表现出惊人相似的感知模式。

**AI_Comments:** 本论文引入了一种新颖的心理物理反向关联方法，这对研究跨各种参数的声学语境效应具有重要的方法论贡献。其发现第一语言和第二语言使用者表现出相似的感知特征，挑战了关于语言背景在言语感知中存在差异的普遍假设。

<details>
  <summary>Details</summary>

**Motivation:** 声学语境效应在言语感知中已有充分记录，但它们如何与语言背景（第一语言和第二语言）相互作用仍不清楚。

**Method:** 研究采用心理物理反向关联方法，系统地改变了第二语言（L2）英语和法语使用者元音对周围短语的音高和语速。通过这种数据驱动的方式，重建了偏向感知的韵律特征。共测试了25名英语和法语使用者。

**Result:** 元音感知受到周围音高和语速的矛盾效应影响：一个在目标前0.2秒的近端一致效应和一个长达1秒的远端对比效应。第一语言和第二语言使用者在感知中表现出惊人相似的韵律特征。

**Conclusion:** 声学语境效应，包括近端和远端效应，对第一语言和第二语言使用者的元音感知有相似的影响。本研究提供了一种调查跨刺激、时间尺度和声学领域的声学语境效应的新方法。

> **ai_Abstract:** 本研究利用一种新颖的心理物理反向关联方法，探讨了声学语境（音高、语速）如何影响第一语言（L1）和第二语言（L2）使用者的元音感知。结果显示，感知受到近端一致效应（目标前0.2秒）和远端对比效应（最远1秒前）的双重影响，并且L1和L2使用者在感知中表现出惊人相似的韵律特征。

> **摘要翻译:** 声学语境效应，即周围音高、语速或音色变化影响声音感知，在言语感知中已有充分记录，但它们如何与语言背景相互作用仍不清楚。我们使用反向关联方法，系统地改变了英语（/i/-/I/）和法语（/u/-/y/）第二语言（L2）使用者不同元音对周围短语的音高和语速，从而以数据驱动的方式重建了偏向其感知的韵律特征。在测试英语和法语使用者（n=25）后，我们发现元音感知确实受到周围音高和语速的矛盾效应影响：一个在目标前0.2秒的近端一致效应和一个长达1秒的远端对比效应；并发现第一语言和第二语言使用者在感知中表现出惊人相似的韵律特征。我们提供了一种新颖的方法来研究跨刺激、时间尺度和声学领域的声学语境效应。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [54] [BENYO-S2ST-Corpus-1: A Bilingual English-to-Yoruba Direct Speech-to-Speech Translation Corpus](https://arxiv.org/abs/2507.09342)
> *BENYO-S2ST-Corpus-1：一个双语英语-约鲁巴语直接语音到语音翻译语料库*

*Emmanuel Adetiba, Abdultaofeek Abayomi, Raymond J. Kala, Ayodele H. Ifijeh, Oluwatobi E. Dare, Olabode Idowu-Bismark, Gabriel O. Sobola, Joy N. Adetiba, Monsurat Adepeju Lateef, Heather Cole-Lewis* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-30**

**Keywords:** 语音到语音翻译, 语料库, 低资源语言, 约鲁巴语, 数据集

**Comment:** 

> **TL;DR:** 本研究构建了BENYO-S2ST-Corpus-1，一个大规模英语到约鲁巴语的直接语音到语音翻译语料库，旨在解决低资源语言对的数据短缺问题，并提出了一种低成本的语料库创建方法。

**AI_Comments:** 这项工作通过构建BENYO-S2ST-Corpus-1，显著解决了英语到约鲁巴语等高资源到低资源语言对的S2ST数据短缺问题。其创新之处在于开发了一种低成本的混合架构来创建大规模语料库，并利用了AI模型进行数据生成和音频增强。该语料库的发布及其概念验证模型YoruTTS-1.5，对于推动低资源语言的语音技术发展具有重要意义，有助于弥合数字鸿沟。

<details>
  <summary>Details</summary>

**Motivation:** 英语到约鲁巴语等高资源到低资源语言对的语音到语音翻译（S2ST）数据集严重短缺。

**Method:** 研究团队开发了一种混合架构，用于低成本大规模直接S2ST语料库创建。他们利用了YORULECT语料库中的非S2ST标准约鲁巴语实时音频和转录文本，以及对应的标准英语转录文本。由于YORULECT语料库没有配对的英语音频，他们使用预训练的AI模型（Facebook MMS）生成了标准英语音频。此外，他们还开发了一种名为AcoustAug的音频增强算法，基于三种潜在声学特征从原始音频中生成增强音频。

**Result:** BENYO-S2ST-Corpus-1包含每种语言12,032个音频样本，总样本量为24,064。两种语言的总音频时长为41.20小时。作为概念验证，研究人员使用所创建的语料库和Coqui框架构建了一个预训练的约鲁巴语文本到语音（TTS）模型YoruTTS-1.5。YoruTTS-1.5在1,000个epochs后F0 RMSE值为63.54，表明与参考实时音频具有中等基频相似度。

**Conclusion:** 本研究提出的语料库架构可供研究人员和开发者利用，以整理针对多语言高资源到低资源非洲语言的数据集，从而弥合高低资源语言对之间在翻译方面的巨大数字鸿沟。BENYO-S2ST-Corpus-1和YoruTTS-1.5已公开可用。

> **ai_Abstract:** 本研究旨在解决英语到约鲁巴语等高资源到低资源语言对的语音到语音翻译（S2ST）数据集严重短缺问题。为此，研究人员开发了一种低成本的混合架构，并基于此构建了BENYO-S2ST-Corpus-1，一个包含24,064个样本、总时长41.20小时的双语英语-约鲁巴语直接S2ST语料库。该语料库通过利用现有约鲁巴语音频和文本，并使用AI模型生成英语音频，以及开发音频增强算法来实现。该语料库不仅可用于构建S2ST模型，还能改进现有模型。作为概念验证，研究人员利用该语料库构建了一个约鲁巴语文本到语音模型YoruTTS-1.5。该语料库架构有望帮助弥合非洲高低资源语言间的数字鸿沟。

> **摘要翻译:** 语音到语音翻译（S2ST）数据集对于英语到约鲁巴语等高资源到低资源语言对存在严重短缺。因此，在本研究中，我们整理了双语英语到约鲁巴语语音到语音翻译语料库版本1（BENYO-S2ST-Corpus-1）。该语料库基于我们为大规模直接S2ST语料库创建而开发的混合架构，旨在降低成本。为了实现这一目标，我们利用了YORULECT语料库中非语音到语音的标准约鲁巴语（SY）实时音频和转录文本，以及相应的标准英语（SE）转录文本。YORULECT语料库规模较小（1,504个样本），并且没有配对的英语音频。因此，我们使用预训练的AI模型（即Facebook MMS）生成了SE音频。我们还开发了一种名为AcoustAug的音频增强算法，基于三种潜在声学特征从两种语言的原始音频中生成增强音频。BENYO-S2ST-Corpus-1每种语言有12,032个音频样本，总样本量为24,064。两种语言的总音频时长为41.20小时。这个规模相当可观。除了构建S2ST模型外，BENYO-S2ST-Corpus-1还可以用于构建预训练模型或改进现有模型。所创建的语料库和Coqui框架被用于构建一个预训练的约鲁巴语TTS模型（名为YoruTTS-1.5），作为概念验证。YoruTTS-1.5在1,000个epochs后F0 RMSE值为63.54，表明与参考实时音频具有中等基频相似度。最终，本研究中的语料库架构可被研究人员和开发者利用，以整理多语言高资源到低资源非洲语言的数据集。这将弥合高低资源语言对之间在翻译方面的巨大数字鸿沟。BENYO-S2ST-Corpus-1和YoruTTS-1.5可在（https://bit.ly/40bGMwi）公开获取。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [152] [Whilter: A Whisper-based Data Filter for "In-the-Wild" Speech Corpora Using Utterance-level Multi-Task Classification](https://arxiv.org/abs/2507.21642)
> *Whilter：一种基于Whisper的“野外”语音语料库数据过滤器，采用话语级多任务分类*

*William Ravenscroft, George Close, Kit Bower-Morris, Jamie Stacey, Dmitry Sityaev, Kris Y. Hong* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-07-29**

**Keywords:** 语音数据过滤, 野外语音, 多任务分类, Whisper编码器, 语音语料库

**Comment:** Accepted for Interspeech 2025

> **TL;DR:** Whilter是一种基于Whisper的多任务分类模型，用于过滤“野外”语音数据集中不需要的特征，例如多说话人、非目标语言和音乐，并表现出良好的性能和处理效率。

**AI_Comments:** Whilter的创新之处在于利用了Whisper编码器并设计了多任务分类框架来解决“野外”语音数据质量问题，这对于提高语音模型在真实世界场景中的鲁棒性至关重要。其在处理效率上的提升也很有价值。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，由于对能够从无标签数据中学习有用特征的模型（如语音识别或合成）的兴趣增加，大规模“野外”语音数据集变得越来越普遍。然而，这些数据集通常包含不理想的特征，例如多说话人、非目标语言和音乐，这可能会影响模型学习。因此需要一种解决方案来识别这些不理想的样本。

**Method:** 提出Whilter模型作为一种多任务解决方案来识别不理想的语音样本。Whilter使用一个Whisper编码器和一个基于注意力的分类器，一次性解决五个不同的分类问题。此外，还发布了一个针对两个流行“野外”语料库子集的标注数据集。

**Result:** Whilter在五个子任务中的三个上取得了高于85%的F1分数和6.5%至7.8%的等错误率。在语音特定类别上，其性能优于最先进的BEATs分类器，并且与单任务替代方案的组合相比，处理时间显著减少。

**Conclusion:** Whilter模型能够有效且高效地过滤“野外”语音语料库中的不良样本，并通过多任务分类和Whisper编码器实现了卓越的性能和处理速度优势。

> **ai_Abstract:** 本文提出了Whilter模型，一个基于Whisper编码器和注意力分类器的多任务解决方案，旨在从大规模“野外”语音数据集中过滤掉多说话人、非目标语言和音乐等不良特征。该模型能够同时解决五个分类问题，并在三个子任务上取得了超过85%的F1分数和较低的等错误率，性能优于现有技术，同时显著减少了处理时间。研究还发布了一个新的标注数据集。

> **摘要翻译:** 近年来，由于对能够从无标签数据中学习有用特征的模型（如语音识别或合成）的兴趣增加，大规模“野外”语音数据集变得越来越普遍。这些数据集通常包含不理想的特征，例如多说话人、非目标语言和音乐，这可能会影响模型学习。Whilter模型被提议作为一种多任务解决方案来识别这些不理想的样本。Whilter使用一个Whisper编码器和一个基于注意力的分类器，一次性解决五个不同的分类问题。此外，还发布了一个针对两个流行“野外”语料库子集的标注数据集。Whilter在五个子任务中的三个上取得了高于85%的F1分数和6.5%至7.8%的等错误率，在语音特定类别上优于最先进的BEATs分类器，并且与单任务替代方案的组合相比，处理时间显著减少。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [428] [Hyperbolic Embeddings for Order-Aware Classification of Audio Effect Chains](https://arxiv.org/abs/2507.20624)
> *用于音频效果链顺序感知分类的双曲嵌入*

*Aogu Wada, Tomohiko Nakamura, Hiroshi Saruwatari* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-28**

**Keywords:** 双曲嵌入, 音频效果链, 顺序感知分类, 神经网络, 湿信号

**Comment:** 7 pages, 3 figures, accepted for the 28th International Conference on
  Digital Audio Effects (DAFx25)

> **TL;DR:** 本研究提出了一种基于神经网络的方法，通过将湿信号嵌入双曲空间来识别音频效果链的类型和顺序，实验证明其性能优于欧几里得空间对应方法。

**AI_Comments:** 该论文的创新点在于首次将双曲嵌入应用于音频效果链的顺序感知分类任务。利用双曲空间来建模音频效果链的树状结构和非交换性质，有效地解决了传统方法难以处理的效果顺序问题。这为音频信号处理中的复杂顺序依赖性建模提供了新的视角和有效工具，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 音频效果链中效果的顺序对最终音色至关重要，特别是对于非线性或时变处理器。然而，大多数现有研究主要关注从湿信号中估计效果类型及其参数，而忽略了效果顺序这一关键因素。本研究旨在填补这一空白，将音频效果链识别任务定义为同时估计效果类型和顺序。

**Method:** 本研究提出了一种基于神经网络的方法，将湿信号嵌入双曲空间，并对音频效果链进行分类。选择双曲空间是因为其指数扩张特性，能比欧几里得空间更有效地表示树状结构数据，而音频效果链可被视为树状结构（效果为节点，顺序为边）。双曲空间特别适合建模有序音频效果组合的指数增长和非交换性质。

**Result:** 使用吉他声音进行的实验表明，在适当的曲率下，所提出的方法优于其欧几里得空间的对应方法。基于效果类型和链长度的进一步分析突出显示了该方法在捕获音频效果顺序方面的有效性。

**Conclusion:** 本研究证明了双曲嵌入在音频效果链的顺序感知分类任务中的有效性，尤其是在处理效果顺序对最终音色影响显著的复杂组合时。

> **ai_Abstract:** 本研究提出了一种新颖的神经网络方法，用于从湿信号中识别音频效果链的类型和顺序。与以往仅关注效果类型和参数的研究不同，本方法利用双曲空间来嵌入音频信号，以有效捕捉效果链的顺序信息。由于音频效果链的树状结构和顺序的非交换性，双曲空间的指数扩张特性使其特别适合此任务。实验结果表明，该方法在吉他声音数据集上表现优于传统的欧几里得空间方法，并能有效捕获效果顺序。

> **摘要翻译:** 音频效果（AFXs）是音乐制作中不可或缺的工具，常以链式应用来塑造音色和动态。效果链中AFXs的顺序在决定最终声音方面起着关键作用，尤其当涉及非线性（例如失真）或时变（例如合唱）处理器时。尽管其重要性，大多数AFX相关研究主要集中于从湿信号中估计效果类型及其参数。为弥补这一空白，我们将AFX链识别表述为从湿信号中联合估计AFX类型及其顺序的任务。我们提出了一种基于神经网络的方法，将湿信号嵌入双曲空间并对其AFX链进行分类。由于其指数扩张特性，双曲空间比欧几里得空间能更有效地表示树状结构数据。由于AFX链可以表示为树，其中AFXs是节点，边编码效果顺序，因此双曲空间非常适合建模有序AFX组合的指数增长和非交换性质，其中效果顺序的变化可能导致不同的最终声音。使用吉他声音进行的实验表明，在适当的曲率下，所提出的方法优于其欧几里得对应方法。基于AFX类型和链长度的进一步分析突出了所提出方法在捕获AFX顺序方面的有效性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [454] [Combolutional Neural Networks](https://arxiv.org/abs/2507.21202)
> *组合卷积神经网络*

*Cameron Churchwell, Minje Kim, Paris Smaragdis* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-07-28**

**Keywords:** 组合卷积层, 音频处理, 谐波分析, 深度学习, 归纳偏置

**Comment:** 4 pages, 3 figures, accepted to WASPAA 2025

> **TL;DR:** 本文提出了一种名为组合卷积层的新型神经网络层，用于音频处理，该层结合了IIR梳状滤波器和包络检测器，以有效提取谐波特征，并在多个音频任务中表现出优于传统卷积层的性能，同时具有低参数量、高效CPU推理和更好的可解释性。

**AI_Comments:** 本文提出了一种新颖的神经网络层，即组合卷积层，它专门针对音频数据的谐波特征提取进行了优化。这种方法在处理音频时，通过引入特定的归纳偏置（IIR梳状滤波器和包络检测器），解决了传统卷积层在精确谐波分析上的潜在不足。其创新之处在于将信号处理领域的概念融入到深度学习架构中，实现了在时域内直接提取谐波信息。该方法的优点在于参数量少、计算效率高（特别是CPU推理）以及更好的模型可解释性，这对于资源受限或需要模型透明度的应用场景具有重要意义。然而，抽象中未详细说明其在非常规音频任务或非谐波特征提取方面的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 在机器学习模型设计中，选择合适的归纳偏置至关重要，尤其是在处理音频数据时，即使是短音频片段也可能包含数百万个样本。现有方法可能在精确谐波分析方面存在局限性或效率问题。

**Method:** 本文提出了一种名为“组合卷积层”（combolutional layer）的新型层，它是一个学习延迟的IIR梳状滤波器和融合包络检测器，用于在时域中提取谐波特征。

**Result:** 研究发现，组合卷积层在需要精确谐波分析的音频任务（如钢琴转录、说话人分类和音高检测）中，可以有效替代传统的卷积层。此外，与现有前端相比，组合卷积层具有参数量少、CPU推理高效、严格实值计算和可解释性提高等优点。

**Conclusion:** 组合卷积层是一种用于音频任务的有效替代方案，特别是在需要精确谐波分析的场景中，它在性能上优于传统卷积层，并具有多项计算和解释性优势。

> **ai_Abstract:** 本文介绍了一种新型的组合卷积层，专为音频处理设计，通过结合IIR梳状滤波器和包络检测器，在时域中高效提取谐波特征。该层在钢琴转录、说话人分类和音高检测等音频信息检索任务中表现出色，可有效替代传统卷积层，并具有低参数量、高CPU推理效率和更强的可解释性等优势。

> **摘要翻译:** 选择合适的归纳偏置是机器学习模型设计中的重要一步，尤其是在处理音频时，即使是短片段也可能包含数百万个样本。为此，我们提出了组合卷积层：一个学习延迟的IIR梳状滤波器和融合包络检测器，它可以在时域中提取谐波特征。我们展示了组合卷积层在三个信息检索任务上的有效性，评估了其相对于其他音频前端的计算成本，并提供了高效的训练实现。我们发现，在需要精确谐波分析的音频任务中，例如钢琴转录、说话人分类和音高检测，组合卷积层是卷积层的有效替代品。此外，组合卷积层相对于现有前端还具有其他几个关键优势，即：参数数量少、CPU推理高效、严格实值计算和可解释性提高。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [475] [Text-Driven Voice Conversion via Latent State-Space Modeling](https://arxiv.org/abs/2503.20999)
> *文本驱动的潜在状态空间模型语音转换*

*Wen Li, Sofia Martinez, Priyanka Shah* | **Category: cs.SD, cs.GR, eess.AS** | **Updated: 2025-07-30**

**Keywords:** 文本驱动语音转换, 潜在状态空间, LSS-VC, 风格控制, mamba

**Comment:** arXiv admin note: This paper has been withdrawn by arXiv due to
  disputed and unverifiable authorship and affiliation

> **TL;DR:** 本文提出了一种名为LSS-VC的潜在状态空间方法，用于文本驱动的语音转换，实现了对音色和韵律的精细控制，并在主客观指标上优于现有基线。

**AI_Comments:** 该论文的创新点在于将潜在状态空间模型（受mamba启发）引入文本驱动的语音转换领域，并通过自适应跨模态融合机制实现了对语音风格的精细化和可解释性控制，有效解决了现有方法在风格控制灵活性上的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本驱动的语音转换方法严重依赖直接的文本到语音训练，限制了它们在控制细微风格元素或音色特征方面的灵活性。

**Method:** 本文提出了一种新颖的潜在状态空间方法（LSS-VC），将每个发音视为连续潜在空间中演化的动态系统。该方法借鉴了mamba，并适应性地将其应用于语音风格转换。它学习一个语音潜在流形，其中风格和内容可以通过文本风格提示独立操作，并提出一种自适应跨模态融合机制，将风格信息注入语音潜在表示。

**Result:** 实验表明，LSS-VC在主观和客观质量指标上显著优于现有基线，同时提供了更平滑的风格转换、更少的伪影和更精确的基于文本的风格控制。

**Conclusion:** 本文提出的LSS-VC方法通过引入潜在状态空间建模和自适应跨模态融合机制，有效解决了文本驱动语音转换中风格控制灵活性不足的问题，实现了高质量、精细可控的语音转换。

> **ai_Abstract:** 本文提出了一种名为LSS-VC的文本驱动语音转换新方法，该方法基于潜在状态空间模型，将发音视为连续潜在空间中的动态系统。受mamba图像风格迁移的启发，LSS-VC学习一个语音潜在流形，通过文本提示独立操作风格和内容。通过自适应跨模态融合机制，LSS-VC能实现对说话人身份、语速和重音的精细控制。实验证明，该方法在质量、风格转换平滑性、伪影减少和文本控制精度方面均优于现有基线。

> **摘要翻译:** 文本驱动的语音转换允许使用文本描述自定义说话人特征和韵律元素。然而，大多数现有方法严重依赖直接的文本到语音训练，限制了它们在控制细微风格元素或音色特征方面的灵活性。在本文中，我们提出了一种新颖的**潜在状态空间**方法，用于文本驱动的语音转换（**LSS-VC**）。我们的方法将每个发音视为连续潜在空间中演化的动态系统。借鉴mamba（它引入了状态空间模型以实现高效的文本驱动**图像**风格迁移），我们为**语音**风格转换调整了一种松散相关的方法。具体来说，我们学习了一个语音潜在流形，其中风格和内容可以通过文本风格提示独立操作。我们提出了一种自适应跨模态融合机制，将风格信息注入语音潜在表示，从而实现对说话人身份、语速和重音的可解释和细粒度控制。广泛的实验表明，我们的方法在主观和客观质量指标上显著优于近期基线，同时提供了更平滑的风格转换、减少了伪影，并实现了更精确的基于文本的风格控制。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [593] [Relationship between objective and subjective perceptual measures of speech in individuals with head and neck cancer](https://arxiv.org/abs/2507.21426)
> *头颈癌患者言语客观与主观感知测量之间的关系*

*Bence Mark Halpern, Thomas Tienkamp, Teja Rebernik, Rob J. J. H. van Son, Martijn Wieling, Defne Abur, Tomoki Toda* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-29**

**Keywords:** 头颈癌, 言语评估, 可懂度, 客观测量, 主观感知

**Comment:** 5 pages, 1 figure, 1 table. Accepted at Interspeech 2025

> **TL;DR:** 本研究探讨了头颈癌患者言语的主观感知评估与客观声学测量之间的关系，发现主观可懂度、发音和音质之间存在强相关性，且客观可懂度与语速与主观测量一致。结果表明，单一的可懂度测量可能足以用于接受同步放化疗的头颈癌患者的临床监测。

**AI_Comments:** 这项研究的创新之处在于其针对头颈癌患者这一特定群体，探讨了言语评估中主观与客观测量的关系。其重要性在于提出了一种简化临床监测的可能性，即单一的可懂度测量可能足以评估治疗效果，这可能为临床实践带来更高的效率和便利性。

<details>
  <summary>Details</summary>

**Motivation:** 有意义的言语评估在临床语音学和治疗监测中至关重要。本研究旨在检查大型头颈癌（HNC）数据集中感知言语评估与客观声学测量之间的联系。

**Method:** 本研究在一个大型头颈癌（HNC）数据集中进行。训练有素的听众对言语的可懂度、发音、音质、发声、语速、鼻音和背景噪音进行了评分。研究考察了主观感知评估与客观声学测量之间的关联。

**Result:** 研究发现主观可懂度、发音和音质之间存在强相关性，这可能是由于说话者群体中言语症状的共同潜在原因。言语可懂度和语速的客观测量结果与它们的主观对应测量结果一致。

**Conclusion:** 研究结果表明，对于接受同步放化疗的头颈癌患者的临床监测，单一的可懂度测量可能就足够了。

> **ai_Abstract:** 本研究调查了头颈癌患者言语的主观感知评估与客观声学测量之间的关系。研究发现，主观可懂度、发音和音质之间存在强相关性，且客观可懂度与语速的测量结果与主观评估一致。研究结果表明，单一的可懂度测量可能足以用于接受同步放化疗的头颈癌患者的临床监测。

> **摘要翻译:** 有意义的言语评估在临床语音学和治疗监测中至关重要。本研究在一个大型头颈癌（HNC）数据集中检查了感知言语评估与客观声学测量之间的联系。训练有素的听众对言语的可懂度、发音、音质、发声、语速、鼻音和背景噪音进行了评分。主观可懂度、发音和音质之间存在强相关性，这可能是由于我们说话者群体中言语症状的共同潜在原因。言语可懂度和语速的客观测量结果与它们的主观对应测量结果一致。我们的结果表明，对于接受同步放化疗的头颈癌患者的临床监测，单一的可懂度测量可能就足够了。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [649] [SpeechFake: A Large-Scale Multilingual Speech Deepfake Dataset Incorporating Cutting-Edge Generation Methods](https://arxiv.org/abs/2507.21463)
> *SpeechFake：一个包含尖端生成方法的大规模多语言语音深度伪造数据集*

*Wen Huang, Yanmei Gu, Zhiming Wang, Huijia Zhu, Yanmin Qian* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-29**

**Keywords:** 语音深度伪造, 大规模数据集, 多语言, 语音合成, 深度伪造检测

**Comment:** Published in ACL 2025. Dataset available at:
  https://github.com/YMLLG/SpeechFake

> **TL;DR:** SpeechFake是一个大规模多语言语音深度伪造数据集，旨在解决现有数据集的局限性，并提升深度伪造检测系统的泛化能力。

**AI_Comments:** SpeechFake数据集通过其前所未有的大规模（300万样本，3000小时）和高多样性（40种生成工具，46种语言，多种生成技术）解决了当前语音深度伪造检测领域数据集不足的痛点。它整合了最新的生成方法，并强调了多语言和多生成技术的重要性，这将极大地促进更鲁棒、泛化能力更强的检测模型的发展。该数据集的发布及其对检测性能影响因素的探索，对整个语音安全领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着语音生成技术的发展，深度伪造音频的滥用风险日益突出，因此迫切需要强大的检测系统。然而，现有许多语音深度伪造数据集规模和多样性有限，难以训练出能很好泛化到未知深度伪造的检测模型。

**Method:** 本文介绍了SpeechFake数据集，一个专为语音深度伪造检测设计的大规模数据集。该数据集包含超过300万个深度伪造样本，总计3000多小时的音频，使用40种不同的语音合成工具生成，涵盖文本到语音、语音转换和神经声码器等多种尖端生成技术，并支持46种语言。论文详细介绍了数据集的创建、组成和统计数据，并提供了基于SpeechFake训练的基线检测模型结果。

**Result:** 基于SpeechFake训练的检测模型在自身测试集和各种未见测试集上均表现出强大的性能。实验还深入探讨了生成方法、语言多样性和说话人变异如何影响检测性能。

**Conclusion:** SpeechFake数据集将成为推动语音深度伪造检测发展和开发更鲁棒模型以应对不断演进的生成技术的宝贵资源。

> **ai_Abstract:** 本文介绍了SpeechFake，一个为应对现有数据集规模和多样性不足而设计的大规模多语言语音深度伪造数据集。该数据集包含超过300万个样本和3000小时音频，由40种工具生成，涵盖文本到语音、语音转换和神经声码器等多种尖端技术，并支持46种语言。研究者详细介绍了数据集的创建与组成，并展示了基于该数据集训练的检测模型在未知样本上的强大泛化能力。此外，论文还分析了生成方法、语言和说话人变异对检测性能的影响，旨在为语音深度伪造检测领域提供宝贵资源。

> **摘要翻译:** 随着语音生成技术的发展，通过深度伪造音频滥用的风险已成为一个紧迫的问题，这凸显了对强大检测系统的关键需求。然而，许多现有语音深度伪造数据集在规模和多样性上存在局限性，这使得训练能够很好地泛化到未知深度伪造的模型变得具有挑战性。为了解决这些差距，我们引入了SpeechFake，一个专为语音深度伪造检测设计的大规模数据集。SpeechFake包含超过300万个深度伪造样本，总计超过3000小时的音频，使用40种不同的语音合成工具生成。该数据集涵盖了广泛的生成技术，包括文本到语音、语音转换和神经声码器，并结合了最新的尖端方法。它还提供多语言支持，涵盖46种语言。在本文中，我们提供了数据集创建、组成和统计数据的详细概述。我们还通过在SpeechFake上训练检测模型来展示基线结果，证明了其在自身测试集和各种未见测试集上的强大性能。此外，我们进行了实验，严格探索生成方法、语言多样性和说话人变异如何影响检测性能。我们相信SpeechFake将成为推进语音深度伪造检测和开发更鲁棒模型以应对不断演进的生成技术的宝贵资源。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [705] [Multi-Microphone and Multi-Modal Emotion Recognition in Reverberant Environment](https://arxiv.org/abs/2409.09545)
> *混响环境下多麦克风多模态情感识别*

*Ohad Cohen, Gershon Hazan, Sharon Gannot* | **Category: cs.SD, cs.LG, eess.AS** | **Updated: 2025-07-28**

**Keywords:** 情感识别, 多模态, 多麦克风, 混响, HTS-AT

**Comment:** 5 pages, 4 figures, 2 tables. Accepted to EUSIPCO 2025

> **TL;DR:** 本文提出了一种多麦克风多模态情感识别系统，通过结合改进的HTS-AT处理多通道音频和R(2+1)D CNN处理视频，显著提高了混响环境下的情感识别准确率。

**AI_Comments:** 这项研究的创新之处在于其将多麦克风音频处理与视频分析相结合，以应对混响环境下的情感识别挑战。其重要性在于提升了在非理想声学条件下的情感识别准确性，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在具有挑战性的声学条件下提高情感识别的准确性。

**Method:** 该方法结合了用于多通道音频处理的改进和扩展的分层令牌语义音频Transformer (HTS-AT) 和用于视频分析的R(2+1)D卷积神经网络 (CNN) 模型。在经过混响处理的RAVDESS数据集上，使用合成和真实世界的房间脉冲响应（RIRs）进行了评估。

**Result:** 与单模态方法相比，整合音频和视频模态产生了优越的性能，尤其是在具有挑战性的声学条件下。此外，使用多个麦克风的多模态（视听）方法优于其单麦克风对应方法。

**Conclusion:** 多模态（视听）方法，特别是结合多麦克风输入，在混响环境中能显著提高情感识别的准确性。

> **ai_Abstract:** 本文介绍了一种多模态情感识别（MER）系统，旨在解决混响环境下的情感识别挑战。该系统结合了用于多通道音频的改进型HTS-AT模型和用于视频的R(2+1)D CNN模型。实验结果表明，在具有挑战性的声学条件下，多模态方法（特别是结合多麦克风）比单模态或单麦克风方法表现更优越。

> **摘要翻译:** 本文提出了一种多模态情感识别（MER）系统，旨在提高具有挑战性的声学条件下的情感识别准确性。我们的方法结合了用于多通道音频处理的改进和扩展的分层令牌语义音频Transformer（HTS-AT）与用于视频分析的R(2+1)D卷积神经网络（CNN）模型。我们在经过混响处理的Ryerson情感语音和歌曲视听数据库（RAVDESS）数据集上，使用合成和真实世界的房间脉冲响应（RIRs）评估了我们提出的方法。我们的结果表明，与单模态方法相比，整合音频和视频模态产生了优越的性能，尤其是在具有挑战性的声学条件下。此外，我们表明利用多个麦克风的多模态（视听）方法优于其单麦克风对应方法。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [734] [Quantum-Inspired Audio Unlearning: Towards Privacy-Preserving Voice Biometrics](https://arxiv.org/abs/2507.22208)
> *量子启发式音频遗忘：迈向隐私保护语音生物识别*

*Shreyansh Pathak, Sonu Shreshtha, Richa Singh, Mayank Vatsa* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-29**

**Keywords:** 音频遗忘, 隐私保护, 语音生物识别, 量子启发, 数据擦除

**Comment:** 9 pages, 2 figures, 5 tables, Accepted at IJCB 2025 (Osaka, Japan)

> **TL;DR:** QPAudioEraser是一种量子启发式音频遗忘框架，旨在高效擦除语音生物识别模型中的个人语音签名，同时最小化对模型效用的影响。

**AI_Comments:** 该论文的创新点在于将量子启发概念引入音频数据遗忘领域，特别是其提出的四阶段框架，针对音频信号的特性进行了优化。这对于满足日益增长的隐私法规要求和保护用户敏感语音数据具有重要意义。其在保持模型效用方面表现出色，解决了传统遗忘方法在音频领域应用时的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 语音生物识别系统的广泛应用增加了敏感语音数据的隐私风险。为了遵守GDPR等隐私法规，需要从已训练的生物识别模型中高效擦除个人特定的语音签名。现有针对视觉数据的遗忘方法无法有效处理音频信号的序列性、时序性和高维度特性，导致扬声器和口音擦除无效或不完整。

**Method:** 本文提出了QPAudioEraser，一个量子启发式音频遗忘框架。该方法分为四个阶段：1) 使用破坏性干涉进行权重初始化以抵消目标特征；2) 基于叠加的标签转换以模糊类别身份；3) 不确定性最大化的量子损失函数；4) 纠缠启发式地混合相关权重以保留模型知识。

**Result:** QPAudioEraser在AudioMNIST、Speech Commands、LibriSpeech和Speech Accent Archive数据集上，使用ResNet18、ViT和CNN架构进行了全面评估，表现出卓越性能。该框架实现了目标数据的完全擦除（遗忘准确率0%），同时对模型效用影响最小，保留数据性能下降低至0.05%。QPAudioEraser在单类别、多类别、序列和口音级别擦除场景中始终优于传统基线。

**Conclusion:** QPAudioEraser作为一种稳健的隐私保护解决方案，能够完全擦除目标数据，同时对模型效用影响最小，在各种擦除场景下均优于传统方法。

> **ai_Abstract:** 本文提出QPAudioEraser，一个量子启发式音频遗忘框架，旨在解决语音生物识别系统中隐私数据擦除的挑战。针对现有方法在处理音频数据时效率低下的问题，QPAudioEraser通过四个阶段（权重初始化、标签转换、量子损失函数和权重混合）实现目标语音数据的完全擦除，同时最大限度地保留模型效用。实验结果表明，该框架在多种数据集和模型架构上均能实现0%的遗忘准确率，并保持极低的性能下降，优于传统基线，为隐私保护语音生物识别提供了一个鲁棒的解决方案。

> **摘要翻译:** 语音启用认证和音频生物识别系统的广泛采用显著增加了与敏感语音数据相关的隐私漏洞。遵守GDPR的被遗忘权和印度DPDP法案等隐私法规，要求对已训练的生物识别模型中特定个人的语音签名进行有针对性且高效的擦除。现有为视觉数据设计的遗忘方法无法充分处理音频信号的序列性、时序性和高维度特性，导致扬声器和口音擦除无效或不完整。为解决此问题，我们引入了QPAudioEraser，一个量子启发式音频遗忘框架。我们的四阶段方法包括：(1) 使用破坏性干涉进行权重初始化以抵消目标特征，(2) 基于叠加的标签转换以模糊类别身份，(3) 不确定性最大化的量子损失函数，以及 (4) 纠缠启发式地混合相关权重以保留模型知识。在AudioMNIST、Speech Commands、LibriSpeech和Speech Accent Archive数据集上，使用ResNet18、ViT和CNN架构进行的全面评估验证了QPAudioEraser的卓越性能。该框架实现了目标数据的完全擦除（0%遗忘准确率），同时对模型效用影响最小，保留数据性能下降低至0.05%。QPAudioEraser在单类别、多类别、序列和口音级别擦除场景中始终超越传统基线，确立了所提出的方法作为一种稳健的隐私保护解决方案。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [768] [A Two-Step Learning Framework for Enhancing Sound Event Localization and Detection](https://arxiv.org/abs/2507.22322)
> *一种增强声音事件定位与检测的两步学习框架*

*Hogeon Yu* | **Category: cs.SD, eess.AS** | **Updated: 2025-07-30**

**Keywords:** 声音事件定位与检测, 两步学习, 空间音频, 深度学习, 特征融合

**Comment:** 5pages, 2figures

> **TL;DR:** 本文提出了一种两步学习框架，通过引入轨迹重排序格式并分别训练声音事件检测（SED）和到达方向（DoA）网络，然后有效融合两类特征，以克服现有单分支和双分支SELD方法的局限性，从而提高声音事件定位和检测的性能。

**AI_Comments:** 该论文通过提出一个两步学习框架，巧妙地解决了现有SELD方法中优化冲突和信息交换受限的核心问题。其创新点在于引入轨迹重排序格式来维持时间一致性，以及通过独立训练和后续融合来优化SED和DoA任务，这对于提升空间音频处理的精度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的声音事件定位与检测（SELD）方法存在局限性：单分支模型共享声音事件检测（SED）和到达方向（DoA）表示，导致优化冲突；双分支模型虽然分离任务，但限制了信息交换。

**Method:** 本文提出了一种两步学习框架：首先，引入一种轨迹重排序格式，以保持时间一致性并防止事件在轨迹间重新分配。其次，分别训练SED和DoA网络，以防止干扰并确保特定任务的特征学习。最后，有效融合DoA和SED特征，以增强SELD性能，提供更好的空间和事件表示。

**Result:** 在2023 DCASE挑战赛任务3数据集上的实验验证了该框架，表明它能够克服单分支和双分支方法的局限性，并改善事件分类和定位性能。

**Conclusion:** 该两步学习框架通过解决现有SELD方法的优化冲突和信息交换限制，有效提升了声音事件定位与检测的性能。

> **ai_Abstract:** 本文提出了一种新颖的两步学习框架，旨在解决现有声音事件定位与检测（SELD）方法中单分支和双分支架构的局限性。该框架首先引入轨迹重排序格式以保持时间一致性，随后独立训练声音事件检测（SED）和到达方向（DoA）网络以避免干扰并学习任务特定特征，最后有效融合SED和DoA特征以提升SELD性能。实验结果证明了该框架在改善事件分类和定位方面的有效性。

> **摘要翻译:** 声音事件定位与检测（SELD）在空间音频处理中至关重要，它使系统能够检测声音事件并估计其3D方向。现有的SELD方法使用单分支或双分支架构：单分支模型共享SED和DoA表示，导致优化冲突；而双分支模型则分离任务但限制了信息交换。为了解决这个问题，我们提出了一种两步学习框架。首先，我们引入了一种轨迹重排序格式，以保持时间一致性，防止事件在轨迹间重新分配。其次，我们训练SED和DoA网络，以防止干扰并确保特定任务的特征学习。最后，我们有效地融合DoA和SED特征，以通过更好的空间和事件表示来增强SELD性能。在2023 DCASE挑战赛任务3数据集上的实验验证了我们的框架，表明它能够克服单分支和双分支的局限性并改善事件分类和定位。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [769] [Latent Swap Joint Diffusion for 2D Long-Form Latent Generation](https://arxiv.org/abs/2502.05130)
> *潜在交换联合扩散用于2D长形式潜在生成*

*Yusheng Dai, Chenxi Wang, Chang Li, Chen Wang, Jun Du, Kewei Li, Ruoyu Wang, Jiefeng Ma, Lei Sun, Jianqing Gao* | **Category: cs.SD, cs.AI, cs.CV, cs.MM, eess.AS** | **Updated: 2025-07-29**

**Keywords:** 潜在交换, 联合扩散, 长形式生成, 音频生成, 全景图生成

**Comment:** 

> **TL;DR:** 本文提出了一种名为SaFa的新型潜在交换联合扩散方法，用于生成无缝连贯的长形式内容（如音频频谱和全景图），解决了现有方法在高频分量抑制和跨视图一致性方面的问题，并显著提升了性能和效率。

**AI_Comments:** 本文提出的SaFa方法通过创新的潜在交换联合扩散机制，有效解决了长形式内容生成中的关键挑战。其创新点在于引入了“自循环潜在交换”来自适应增强高频分量，以及“参考引导潜在交换”来确保全局跨视图一致性。这种模态无关的设计使其不仅在音频生成中表现出色，还在全景图生成中实现了显著的速度提升和泛化能力。该方法为高质量、长持续时间的多模态内容生成提供了重要的技术进步。

<details>
  <summary>Details</summary>

**Motivation:** 现有联合扩散方法在基于频谱的音频生成中存在频谱混叠问题，通过对梅尔频谱和RGB图像的VAE潜在表示进行比较分析，发现问题源于去噪过程中平均操作对高频分量的过度抑制。

**Method:** 本文引入了Swap Forward (SaFa)，这是一种模态无关且高效的方法，通过跨多视图的潜在交换联合扩散来生成无缝连贯的长频谱和全景图。为解决高频抑制问题，提出了自循环潜在交换（Self-Loop Latent Swap），这是一种应用于相邻视图重叠区域的帧级双向交换，它利用相邻子视图的逐步差异化轨迹，自适应地增强高频分量并避免频谱失真。此外，为了改善非重叠区域的全局跨视图一致性，引入了参考引导潜在交换（Reference-Guided Latent Swap），这是一种单向潜在交换操作符，提供集中的参考轨迹来同步子视图扩散。通过优化交换时机和间隔，可以在仅向前的方式下实现跨视图的相似性-多样性平衡。

**Result:** 定量和定性实验表明，SaFa在音频生成方面显著优于现有联合扩散方法，甚至超过了基于训练的方法（使用U-Net和DiT模型），并能有效适应更长的长度。它也很好地适用于全景图生成，实现了可比较的性能，同时速度快2到20倍，并具有更强的模型泛化能力。

**Conclusion:** SaFa方法通过创新的潜在交换机制，成功解决了长形式内容生成中高频分量抑制和跨视图一致性问题，在音频和全景图生成方面表现出卓越的性能、效率和泛化能力，为高质量长形式内容生成提供了有效途径。

> **ai_Abstract:** 本文提出了一种新颖的潜在交换联合扩散方法——Swap Forward (SaFa)，专为2D长形式潜在生成设计。该方法通过引入自循环潜在交换和参考引导潜在交换机制，有效解决了现有方法在长形式音频频谱和全景图生成中遇到的高频分量抑制和跨视图一致性问题。SaFa利用帧级双向交换在重叠区域增强高频，并通过单向交换提供中心参考以同步扩散，从而在保持相似性与多样性平衡的同时，实现了无缝连贯的长形式内容生成。实验证明，SaFa在音频和全景图生成方面均显著优于现有方法，展现出更高的性能、效率和模型泛化能力。

> **摘要翻译:** 本文介绍了Swap Forward (SaFa)，这是一种模态无关且高效的方法，通过跨多视图的潜在交换联合扩散来生成无缝连贯的长频谱和全景图。我们首先研究了现有联合扩散方法在基于频谱的音频生成中引起的频谱混叠问题。通过对梅尔频谱和RGB图像的VAE潜在表示进行比较分析，我们发现问题源于去噪过程中平均操作对高频分量的过度抑制。为了解决这个问题，我们提出了自循环潜在交换（Self-Loop Latent Swap），这是一种应用于相邻视图重叠区域的帧级双向交换。利用相邻子视图的逐步差异化轨迹，这种交换操作符自适应地增强高频分量并避免频谱失真。此外，为了改善非重叠区域的全局跨视图一致性，我们引入了参考引导潜在交换（Reference-Guided Latent Swap），这是一种单向潜在交换操作符，提供集中的参考轨迹来同步子视图扩散。通过优化交换时机和间隔，我们可以在仅向前的方式下实现跨视图的相似性-多样性平衡。定量和定性实验表明，SaFa在音频生成方面显著优于现有联合扩散方法，甚至超过了基于训练的方法（使用U-Net和DiT模型），并能有效适应更长的长度。它也很好地适用于全景图生成，实现了可比较的性能，同时速度快2到20倍，并具有更强的模型泛化能力。更多生成演示可在 https://swapforward.github.io/ 查看。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [804] [Adaptive Duration Model for Text Speech Alignment](https://arxiv.org/abs/2507.22612)
> *文本语音对齐的自适应持续时间模型*

*Junjie Cao* | **Category: cs.SD, cs.AI, eess.AS** | **Updated: 2025-07-30**

**Keywords:** 文本语音对齐, 持续时间模型, 神经TTS, 自适应, 零样本TTS

**Comment:** 4 pages, 3 figures, 2 tables

> **TL;DR:** 提出了一种新的自适应持续时间模型，用于改善文本到语音对齐的准确性和鲁棒性，解决了现有TTS模型在长文本和域外文本对齐上的脆性问题。

**AI_Comments:** 这篇论文通过引入一个自适应的持续时间模型，有效解决了当前TTS模型在文本语音对齐方面的核心痛点，即对齐的脆性和对长文本及域外文本的泛化能力不足。其创新点在于提供了一种灵活的音素级别持续时间分布预测，这对于提高TTS系统的自然度和鲁棒性至关重要。11.3%的对齐准确率提升以及对零样本TTS鲁棒性的改善，表明该方法具有显著的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有自回归TTS模型的注意力机制在文本语音对齐时易碎，难以泛化到长语篇和域外文本，导致漏词或重复词。非自回归TTS模型则依赖外部持续时间模型。

**Method:** 提出了一种新颖的持续时间预测框架，该框架可以根据给定的文本提供折衷的音素级别持续时间分布。

**Result:** 该模型与现有基线模型相比，预测更精确，条件适应能力更强。在对齐准确性方面大约有11.3%的改进，并使零样本TTS模型的性能对提示音频和输入音频之间的不匹配更具鲁棒性。

**Conclusion:** 新提出的自适应持续时间模型显著改善了文本语音对齐的准确性和鲁棒性，尤其在处理长文本和零样本TTS场景中表现出色。

> **ai_Abstract:** 本文提出了一种新颖的自适应持续时间预测框架，旨在解决现有神经文本到语音（TTS）模型在文本语音对齐上的脆性和泛化问题。该框架能够为给定文本提供音素级别的持续时间分布，并在实验中展现出比现有基线模型更精确的预测和更强的条件适应能力。数值结果显示，该模型将对齐准确率提高了约11.3%，并增强了零样本TTS模型在音频不匹配情况下的鲁棒性。

> **摘要翻译:** 文本到语音对齐是神经文本到语音（TTS）模型的关键组成部分。自回归TTS模型通常使用注意力机制在线学习这些对齐。然而，这些对齐往往不稳定，并且难以泛化到长语篇和域外文本，导致漏词或重复词。大多数非自回归端到端TTS模型依赖于从外部来源提取的持续时间，并使用额外的持续时间模型进行对齐。在本文中，我们提出了一种新颖的持续时间预测框架，该框架可以根据给定文本提供折衷的音素级别持续时间分布。在我们的实验中，所提出的持续时间模型与之前的基线模型相比，具有更精确的预测和条件适应能力。在数值上，它在对齐准确性方面大约有11.3%的改进，并使零样本TTS模型的性能对提示音频和输入音频之间的不匹配更具鲁棒性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [817] [Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models](https://arxiv.org/abs/2507.08128)
> *Audio Flamingo 3：推进音频智能的完全开源大型音频语言模型*

*Arushi Goel, Sreyan Ghosh, Jaehyeon Kim, Sonal Kumar, Zhifeng Kong, Sang-gil Lee, Chao-Han Huck Yang, Ramani Duraiswami, Dinesh Manocha, Rafael Valle, Bryan Catanzaro* | **Category: cs.SD, cs.AI, cs.CL, eess.AS** | **Updated: 2025-07-28**

**Keywords:** 音频语言模型, 开源, 音频智能, 语音理解, SOTA

**Comment:** Code, Datasets, and Models:
  https://research.nvidia.com/labs/adlr/AF3/ ; Updates in v2: Updated results
  for new thinking mode ckpts, added qualitative figure, added note on fully
  open claim, add email ID for corresponding authors

> **TL;DR:** Audio Flamingo 3 (AF3) 是一个完全开源的大型音频语言模型，在20多个音频理解和推理基准测试中达到了新的SOTA，甚至超越了闭源模型。

**AI_Comments:** 该论文介绍了完全开源的大型音频语言模型Audio Flamingo 3，其创新之处在于统一的音频编码器、灵活的链式思考能力、多模态交互以及长音频理解。最重要的是，它仅使用开源数据就超越了许多在更大数据集上训练的闭源模型，这对于推动开放研究和实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在推进音频智能，实现对语音、声音和音乐的推理和理解，并构建一个完全开源的最先进大型音频语言模型。

**Method:** 该方法引入了AF-Whisper，一个统一的音频编码器，采用新颖的策略进行语音、声音和音乐三模态的联合表示学习。模型支持灵活的按需思考（链式思考）、多轮多音频聊天、长达10分钟的长音频理解和推理，以及语音到语音交互。为实现这些能力，研究人员提出了多个大规模训练数据集，包括AudioSkills-XL、LongAudio-XL、AF-Think和AF-Chat，并采用新颖的五阶段课程式训练策略，仅使用开源音频数据训练AF3。

**Result:** Audio Flamingo 3在20多个（长）音频理解和推理基准测试中取得了新的SOTA结果，超越了在更大数据集上训练的开源和闭源模型。

**Conclusion:** Audio Flamingo 3通过其创新的架构和训练策略，显著提升了音频智能领域的推理和理解能力，并在多个基准测试中确立了新的最先进水平，证明了开源模型的强大潜力。

> **ai_Abstract:** Audio Flamingo 3 (AF3) 是一个完全开源的最先进大型音频语言模型，旨在提升语音、声音和音乐的推理和理解能力。它引入了统一的AF-Whisper音频编码器，支持灵活的链式思考、多轮多音频聊天、长音频理解和语音到语音交互。该模型通过新颖的大规模数据集和五阶段课程式训练策略进行训练，仅使用开源数据就在20多个音频理解和推理基准测试中取得了新的SOTA，超越了现有开源和闭源模型。

> **摘要翻译:** 我们提出了Audio Flamingo 3 (AF3)，一个完全开源的最先进（SOTA）大型音频语言模型，它推进了语音、声音和音乐的推理和理解能力。AF3引入了：(i) AF-Whisper，一个统一的音频编码器，采用新颖的策略进行语音、声音和音乐全部三种模态的联合表示学习；(ii) 灵活的按需思考，允许模型在回答前进行链式思考式的推理；(iii) 多轮、多音频聊天；(iv) 长达10分钟的长音频理解和推理（包括语音）；以及 (v) 语音到语音交互。为了实现这些能力，我们提出了几个通过新颖策略策划的大规模训练数据集，包括AudioSkills-XL、LongAudio-XL、AF-Think和AF-Chat，并采用新颖的五阶段课程式训练策略来训练AF3。AF3仅使用开源音频数据进行训练，在20多个（长）音频理解和推理基准测试中取得了新的SOTA结果，超越了在更大数据集上训练的开源和闭源模型。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [839] [Next Tokens Denoising for Speech Synthesis](https://arxiv.org/abs/2507.22746)
> *语音合成的下一令牌去噪*

*Yanqing Liu, Ruiqing Xue, Chong Zhang, Yufei Liu, Gang Wang, Bohan Li, Yao Qian, Lei He, Shujie Liu, Sheng Zhao* | **Category: cs.SD, cs.CL, eess.AS** | **Updated: 2025-07-30**

**Keywords:** 语音合成, 自回归模型, 扩散模型, 流匹配, 去噪

**Comment:** 

> **TL;DR:** Dragon-FM是一种新的文本到语音（TTS）模型，它结合了自回归（AR）和流匹配，以克服传统AR和扩散模型的局限性，实现高效、高质量的语音合成，尤其适用于长篇内容。

**AI_Comments:** Dragon-FM的创新之处在于其独特地结合了自回归模型和流匹配范式，有效解决了现有AR模型在未来上下文利用和生成速度上的不足，以及扩散模型在KV缓存上的挑战。其分块处理和混合建模（连续与离散）的方法，使其在生成长篇、高质量语音内容方面展现出显著的效率和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 自回归（AR）模型依赖因果注意力，无法利用未来上下文，且生成速度慢。扩散模型则在键值（KV）缓存方面存在问题。

**Method:** 本文提出了Dragon-FM，一种结合了AR和流匹配的新型文本到语音（TTS）设计。该模型以12.5令牌/秒的速度分块处理48 kHz音频编解码器令牌，实现跨块的AR建模以确保全局连贯性，并利用块内并行流匹配进行快速迭代去噪。这使得模型能够跨块利用KV缓存，并在每个块内整合未来上下文，同时弥合了连续和离散特征建模的鸿沟。

**Result:** 实验证明，该模型能够高效生成高质量的零样本播客。其高效编解码器和快速块自回归架构使其特别适用于生成扩展内容。

**Conclusion:** Dragon-FM通过结合自回归和流匹配，成功克服了现有生成模型（AR和扩散）的局限性，实现了高效、高质量且支持长篇内容的语音合成。

> **ai_Abstract:** 本文介绍了Dragon-FM，一种创新的文本到语音（TTS）模型，旨在克服传统自回归（AR）和扩散模型的局限性。Dragon-FM通过将AR建模与流匹配相结合，以分块方式处理音频令牌，实现了跨块的全局连贯性和块内的快速去噪。这种设计使得模型能够有效利用KV缓存并整合未来上下文，同时支持连续和离散特征的建模。实验证明，Dragon-FM能够高效生成高质量的零样本播客，并特别适用于长篇内容的合成。

> **摘要翻译:** 虽然扩散模型和自回归（AR）模型在生成建模方面取得了显著进展，但它们各自存在明显的局限性。依赖因果注意力的AR模型无法利用未来上下文，并且生成速度慢。相反，扩散模型在键值（KV）缓存方面存在困难。为了克服这些挑战，我们引入了Dragon-FM，一种新颖的文本到语音（TTS）设计，它统一了AR和流匹配。该模型以紧凑的每秒12.5个令牌的速度分块处理48 kHz音频编解码器令牌。这种设计使得AR模型能够跨块建模，确保全局连贯性，同时块内并行流匹配促进了快速迭代去噪。因此，所提出的模型可以跨块利用KV缓存，并在每个块内整合未来上下文。此外，它弥合了连续和离散特征建模之间的鸿沟，证明了连续AR流匹配可以预测具有有限标量量化器的离散令牌。这种高效的编解码器和快速的块自回归架构也使得所提出的模型在生成扩展内容方面特别有效。我们工作在播客数据集上的演示实验证明了其高效生成高质量零样本播客的能力。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [24] [Prophecies all the Way: Game-based Model-Checking for HyperQPTL beyond $\forall^*\exists^*$](https://arxiv.org/abs/2504.08575)
> *一路预言：超越$\forall^*\exists^*$的HyperQPTL的基于博弈的模型检测*

*Sarah Winter, Martin Zimmermann* | **Category: cs.LO, cs.FL** | **Updated: 2025-07-29**

**Keywords:** 模型检测, HyperQPTL, 博弈论, 超性质, Skolem函数

**Comment:** 

> **TL;DR:** 本文将基于博弈的模型检测方法扩展到完整的HyperQPTL逻辑，该逻辑具有任意量词前缀，并能表达所有$\omega$-正则超性质，同时通过前瞻传感器实现Skolem函数。

**AI_Comments:** 本文通过将基于博弈的模型检测方法推广到更具表达力的HyperQPTL逻辑，做出了重要贡献。采用不完全信息博弈是其创新之处，而获得Skolem函数的有限状态实现则为解释性质违规提供了实用的工具，对于安全和隐私相关的复杂超性质验证具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** HyperLTL的模型检测问题虽然可判定，但复杂度为TOWER完备，且现有的基于博弈的方法仅限于其$\forall^*\exists^*$-片段。本研究旨在将基于博弈的方法扩展到功能更强大的完整HyperQPTL逻辑，以处理任意量词前缀和命题量化。

**Method:** 本文采用不完全信息博弈（imperfect information-games）将基于博弈的方法扩展到完整的HyperQPTL。作为该算法的副产品，通过带有前瞻的传感器（transducers with lookahead）获得了Skolem函数的有限状态实现。

**Result:** 该方法成功将基于博弈的模型检测扩展到完整的HyperQPTL，使其能够处理任意量词前缀和命题量化，并表达所有$\omega$-正则超性质。此外，还获得了Skolem函数的有限状态实现，用于解释HyperQPTL性质的满足或违反。

**Conclusion:** 本文成功地将基于博弈的模型检测方法推广到完整的HyperQPTL逻辑，显著提升了模型检测对复杂超性质（hyperproperty）的处理能力，并提供了实用的Skolem函数实现。

> **ai_Abstract:** 该论文将基于博弈的模型检测方法扩展到完整的HyperQPTL逻辑，该逻辑能够处理任意量词前缀和命题量化，并可以表达所有$\omega$-正则超性质。通过采用不完全信息博弈，这项工作为HyperLTL的传统自动机理论方法提供了一种替代方案，并且作为副产品，获得了Skolem函数的有限状态实现，用于解释性质的满足或违反。

> **摘要翻译:** HyperLTL是一种时序逻辑，用于表达轨迹集合的性质，应用于基于信息流的安全和隐私，其模型检测问题是可判定的，但复杂度为TOWER完备。虽然完整的HyperLTL的经典模型检测算法是基于自动机的，但最近为$\forall^*\exists^*$-片段提出了一种基于博弈的替代方法。
本文采用不完全信息博弈，将基于博弈的方法扩展到完整的HyperQPTL，该逻辑具有任意量词前缀和对命题的量化，并且可以表达所有$\omega$-正则超性质。作为我们基于博弈算法的副产品，我们通过带有前瞻的传感器获得了Skolem函数的有限状态实现，这些实现可以解释HyperQPTL性质的满足或违反。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [741] [Semantic Numeration Systems as Dynamical Systems](https://arxiv.org/abs/2507.21295)
> *语义计数系统作为动力系统*

*Alexander Yu. Chunikhin* | **Category: cs.LO, cs.AI, 11A63, 47S20, 68Q55** | **Updated: 2025-07-28**

**Keywords:** 语义计数系统, 动力系统, 基数抽象对象, 配置矩阵, 线性离散系统

**Comment:** 11 pages, 6 figures

> **TL;DR:** 论文将基数语义抽象对象视为具有非线性控制的线性离散动力系统，并提供了其状态方程。

**AI_Comments:** 这篇论文的创新点在于将抽象的语义计数系统与动力系统理论相结合，这为理解和分析复杂的语义结构提供了一个新的数学框架。通过引入“基数抽象对象”和“配置矩阵”的概念，并将其视为动力系统，可能为语义系统的行为分析和控制提供了新的工具。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在通过将语义计数系统中的基数抽象对象建模为动力系统，来分析和理解其行为。

**Method:** 论文提出将基数抽象对象（CAO）视为一个具有非线性控制的线性离散动力系统。在理想可观测性假设下，提供了CAO在平稳和非平稳情况下的状态方程。

**Result:** 论文展示了配置矩阵的基本作用，该矩阵结合了关于CAO中基数语义运算符类型、参数和连接拓扑的信息。

**Conclusion:** 论文通过将基数抽象对象建模为动力系统，并强调配置矩阵的作用，为语义计数系统理论提供了一个新的视角和分析框架。

> **ai_Abstract:** 本文简要概述了语义计数系统理论的基础概念，并提出将由基数语义算子形成的基数抽象对象（CAO）建模为具有非线性控制的线性离散动力系统。在理想可观测性假设下，论文推导了CAO在平稳和非平稳情况下的状态方程，并强调了结合运算符类型、参数和连接拓扑信息的配置矩阵的关键作用。

> **摘要翻译:** 语义计数系统理论的基础概念被简要概述。基数语义算子的作用在一个属于基数语义多重性的基数抽象实体集合上展开。由它们以特定连接拓扑形成的基数抽象对象（CAO）被提议视为一个具有非线性控制的线性离散动力系统。在理想可观测性假设下，提供了CAO在平稳和非平稳情况下的状态方程。展示了配置矩阵的基本作用，该矩阵结合了关于CAO中基数语义算子类型、参数和连接拓扑的信息。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [51] [On Post-Quantum Cryptography Authentication for Quantum Key Distribution](https://arxiv.org/abs/2507.21325)
> *关于量子密钥分发中的后量子密码学认证*

*Juan Antonio Vieira Giestinhas, Timothy Spiller* | **Category: quant-ph, cs.CR, 94A60, 94A62, 81P45, 81P94, E.3** | **Updated: 2025-07-28**

**Keywords:** 量子密钥分发, 后量子密码学, 认证, 可扩展性, 公钥基础设施

**Comment:** 

> **TL;DR:** 该论文提出使用结合后量子密码学（PQC）的公钥基础设施（PKI）来解决量子密钥分发（QKD）网络中传统预共享密钥认证方案的可扩展性问题，从而实现安全且可扩展的量子网络。

**AI_Comments:** 该论文提出了一个重要且及时的解决方案，解决了量子密钥分发（QKD）网络在扩展性方面的关键挑战。其创新之处在于将公钥基础设施（PKI）与后量子密码学（PQC）相结合，这不仅解决了传统预共享密钥方法的局限性，还前瞻性地考虑了量子计算对现有密码学的威胁。这种方法为未来大规模、安全的量子网络奠定了基础，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的量子密钥分发（QKD）网络认证依赖预共享密钥，但随着网络规模的增长，所需密钥数量呈二次方增长，导致该方法变得不切实际且缺乏可扩展性。

**Method:** 该论文提出将公钥基础设施（PKI）与后量子密码学（PQC）相结合，以实现QKD流量的远程认证。这种方法利用PQC算法的抗量子攻击特性，旨在提供类似于SIGMA或TLS协议的认证、机密性和完整性。

**Result:** 通过结合PKI和PQC，实现了QKD用户的远程认证，从而能够在特定假设下获得信息理论安全（ITS）密钥。这种方法能够确保量子网络的安全性和可扩展性，并可抵御有界对手的攻击。

**Conclusion:** 结合后量子密码学（PQC）的公钥基础设施（PKI）为量子密钥分发（QKD）网络提供了一种可扩展且安全的认证解决方案，克服了传统预共享密钥方法的局限性，并能抵御量子攻击。

> **ai_Abstract:** 该论文探讨了量子密钥分发（QKD）网络中认证的可扩展性问题。传统上，QKD网络依赖预共享密钥进行认证，但这在大型网络中会因密钥数量的二次方增长而变得不切实际。为解决此问题，作者提出了一种结合公钥基础设施（PKI）和后量子密码学（PQC）的方案。这种方法允许用户远程认证QKD流量，并在特定假设下获得信息理论安全（ITS）密钥。与依赖经典算法的传统PKI不同，该方案利用抗量子攻击的PQC算法。最终目标是确保量子网络的安全性和可扩展性，实现认证、机密性和完整性，以抵御有界对手的攻击。

> **摘要翻译:** 量子密钥分发（QKD）用户加入量子网络的传统方式是通过预共享密钥材料进行身份验证。虽然这种方法对于小型网络来说足够，但随着网络的增长，由于所需预共享密钥数量的总二次方增加，它变得不切实际。为了解决这个可扩展性问题，公钥基础设施（PKI）与后量子密码学（PQC）相结合提供了一种更具可扩展性的解决方案，允许用户远程验证QKD流量，以便在所提出的假设下获得信息理论安全（ITS）密钥。与依赖RSA等经典密码算法的传统PKI不同，本文提出的方法利用了被认为能够抵抗量子攻击的PQC算法。与SIGMA或TLS协议类似，可以实现针对有界对手的认证、机密性和完整性，以确保安全和可扩展的量子网络。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [110] [An em algorithm for quantum Boltzmann machines](https://arxiv.org/abs/2507.21569)
> *量子玻尔兹曼机的EM算法*

*Takeshi Kimura, Kohtaro Kato, Masahito Hayashi* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 量子玻尔兹曼机, EM算法, 信息几何, 量子机器学习, 稳定学习

**Comment:** Main text: 10 pages, 2 figures. Appendix: 3 pages, 1 figure

> **TL;DR:** 本文提出了一种用于训练量子玻尔兹曼机的量子EM算法，该算法是期望最大化（EM）算法的信息几何扩展，在半量子受限玻尔兹曼机上实现了稳定的学习，并在多个基准数据集上优于基于梯度的训练方法，展示了信息几何优化在量子机器学习中的潜力。

**AI_Comments:** 该论文的创新之处在于将信息几何的EM算法引入到量子玻尔兹曼机的训练中，为量子机器学习提供了一种新的优化范式。其优势在于克服了传统梯度方法在量子领域可能遇到的非对易性或梯度消失问题，提高了训练的稳定性和收敛性。这对于推动量子机器学习的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于梯度的量子机器学习方法可能面临非对易性或梯度消失等问题，因此需要一种更稳定、收敛性更好的替代方案。

**Method:** 开发了一种量子版本的EM算法（信息几何扩展的期望最大化算法），并将其应用于半量子受限玻尔兹曼机，其中量子效应仅限于隐藏层。这种结构允许解析更新规则，同时保留量子表达能力。

**Result:** 在基准数据集上的数值实验表明，所提出的方法实现了稳定的学习，并在多个情况下优于基于梯度的训练。这些结果证明了信息几何优化在量子机器学习中的潜力。

**Conclusion:** 信息几何优化在量子机器学习中具有巨大潜力，尤其是在标准方法因非对易性或梯度消失而面临挑战的情况下，量子EM算法提供了一种有效的解决方案。

> **ai_Abstract:** 本文提出了一种用于训练量子玻尔兹曼机的量子EM算法，该算法是期望最大化（EM）算法的信息几何扩展。该算法在半量子受限玻尔兹曼机上实现，通过将量子效应限制在隐藏层来获得解析更新规则并保持量子表达能力。数值实验表明，该方法实现了稳定的学习，并在多个基准数据集上优于基于梯度的训练，展示了信息几何优化在量子机器学习中的应用前景，尤其是在传统方法面临挑战的场景下。

> **摘要翻译:** 我们开发了一种用于训练量子玻尔兹曼机的量子版EM算法。EM算法是众所周知的期望最大化（EM）算法的信息几何扩展，提供了一种结构化的替代方案，以替代基于梯度的方法，在稳定性和收敛性方面具有潜在优势。我们在半量子受限玻尔兹曼机上实现了该算法，其中量子效应仅限于隐藏层。这种结构使得解析更新规则成为可能，同时保留了量子表达能力。在基准数据集上的数值实验表明，所提出的方法实现了稳定的学习，并在多个情况下优于基于梯度的训练。这些结果证明了信息几何优化在量子机器学习中的潜力，特别是在标准方法因非对易性或梯度消失而难以应用的环境中。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [120] [A Grover-Based Quantum Algorithm for Solving Perfect Mazes via Fitness-Guided Search](https://arxiv.org/abs/2507.21937)
> *一种基于格罗弗算法的通过适应度引导搜索解决完美迷宫的量子算法*

*Michelle L. Wu* | **Category: quant-ph, cs.ET, math.QA, 81P68, 68Q12, F.1.2; F.2.2; I.2.8** | **Updated: 2025-07-30**

**Keywords:** 量子算法, 迷宫求解, 格罗弗算法, 路径查找, 适应度引导搜索

**Comment:** This revision addresses privacy concerns, intellectual property
  rights, and removes personally identifiable information along with
  institutionally affiliated acknowledgements. No changes were made to the
  scientific and mathematical contents

> **TL;DR:** 该论文提出了一种基于格罗弗振幅放大算法的量子算法，通过将路径查找任务转换为结构化搜索问题来解决完美迷宫，并展示了其高效的资源扩展性。

**AI_Comments:** 这篇论文的创新点在于将量子算法（特别是格罗弗算法）应用于迷宫路径查找这一经典问题，并引入了“适应度引导搜索”的概念。通过量子叠加和适应度算子，它提供了一种潜在加速路径发现的方法。其高效的资源扩展性和对其他搜索领域的普适性是其重要性所在，为未来的量子路径规划和导航算法奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是通过将路径查找任务转化为结构化搜索问题，开发一种量子算法来解决完美迷宫。

**Method:** 该算法基于格罗弗振幅放大，将所有候选路径叠加编码，并使用基于量子算术的可逆适应度算子评估其与目标的接近程度。一个与格罗弗算法兼容的预言机标记高适应度状态，并通过自适应截止策略迭代地优化搜索。

**Result:** 资源分析表明，该算法的效率随迷宫大小和路径长度呈有效扩展。

**Conclusion:** 该框架可作为量子混合路径查找和规划的基础，并且该方法易于扩展到其他搜索领域，包括树状或非循环图上的导航。

> **ai_Abstract:** 本文提出了一种基于格罗弗振幅放大的量子算法，用于解决完美迷宫中的路径查找问题。该算法通过将候选路径编码为叠加态，并利用量子算术的适应度算子进行评估，结合格罗弗预言机和自适应截止策略进行迭代搜索。研究结果表明，该算法在资源消耗方面随迷宫大小和路径长度高效扩展，为量子混合路径查找和规划提供了基础，并具有向其他图搜索领域扩展的潜力。

> **摘要翻译:** 我们提出了一种量子算法，通过将路径查找任务转换为结构化搜索问题来解决完美迷宫。该算法基于格罗弗振幅放大，将所有候选路径叠加编码，并使用基于量子算术的可逆适应度算子评估其与目标的接近程度。一个与格罗弗算法兼容的预言机标记高适应度状态，并通过自适应截止策略迭代地优化搜索。我们提供了形式化定义、酉构造和收敛性保证，以及资源分析，显示了其在迷宫大小和路径长度方面的有效扩展。该框架可作为量子混合路径查找和规划的基础。从编码到放大，包括预言机设计和适应度评估，都指定了完整的算法流程。该方法易于扩展到其他搜索领域，包括树状或非循环图上的导航。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [382] [Data-driven quantum Koopman method for simulating nonlinear dynamics](https://arxiv.org/abs/2507.21890)
> *数据驱动的量子Koopman方法用于模拟非线性动力学*

*Baoyang Zhang, Zhen Lu, Yaomin Zhao, Yue Yang* | **Category: quant-ph, cs.AI, cs.LG, physics.comp-ph, physics.flu-dyn** | **Updated: 2025-07-29**

**Keywords:** 量子Koopman方法, 非线性动力学, 数据驱动, 量子模拟, Koopman算子

**Comment:** 

> **TL;DR:** 该论文提出了一种数据驱动的量子Koopman方法（QKM），通过将非线性动力学转化为高维可观测空间中的线性酉演化，从而实现量子加速模拟非线性系统。

**AI_Comments:** 这项工作通过结合深度学习的全局线性化能力和量子算法的酉动力学演化优势，为非线性动力学的量子模拟提供了一个创新且实用的框架。其亮点在于通过Koopman算子理论将非线性问题转化为线性酉演化，解决了量子计算在非线性领域应用的固有挑战。该方法的数据驱动特性和对量子硬件的优化设计使其具有重要的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算在模拟某些物理系统方面具有潜在的指数级加速，但其应用于非线性动力学受限于酉演化的要求。本文旨在弥补这一差距，实现非线性动力学的量子模拟。

**Method:** 本文提出了量子Koopman方法（QKM），一个数据驱动的框架。它利用Koopman算子理论将非线性动力学转化为高维可观测空间中的线性酉演化。该方法使用深度自编码器将系统状态映射到希尔伯特空间，在简化的嵌入空间中，状态表示被分解为模数和相位分量。演化由一组仅作用于相位的酉Koopman算子控制，这些算子由系数从数据中学习的对角哈密顿量构建，旨在实现量子硬件上的高效实现。

**Result:** QKM在各种非线性系统中得到验证。对于反应扩散系统和剪切流，其预测的相对误差保持在6%以下，并捕获了二维湍流中的关键统计数据。算子的计算复杂度与可观测空间维度呈对数关系。

**Conclusion:** 这项工作为非线性现象的量子加速模拟建立了一条实用的途径，探索了一个建立在深度学习（用于全局线性化）和量子算法（用于酉动力学演化）协同作用之上的框架。

> **ai_Abstract:** 本文提出了一种数据驱动的量子Koopman方法（QKM），旨在克服量子计算在模拟非线性动力学中受限于酉演化的挑战。通过利用Koopman算子理论和深度自编码器，QKM将非线性系统在高维可观测空间中线性化为酉演化，并通过学习数据构建作用于相位的酉Koopman算子，实现高效的量子硬件实现。该方法在多种非线性系统中得到验证，展现出较低的预测误差，并为非线性现象的量子加速模拟提供了一条实用途径。

> **摘要翻译:** 量子计算为模拟某些物理系统提供了潜在的指数级加速，但其应用于非线性动力学固有地受到酉演化要求的限制。我们提出了量子Koopman方法（QKM），这是一个数据驱动的框架，通过将非线性动力学转化为高维可观测空间中的线性酉演化来弥合这一差距。利用Koopman算子理论实现全局线性化，我们的方法使用深度自编码器将系统状态映射到一系列希尔伯特空间中。在简化的嵌入空间中，状态表示被分解为模数和相位分量，演化由一组仅作用于相位的酉Koopman算子控制。这些算子由从数据中学习系数的对角哈密顿量构建，这种结构旨在量子硬件上高效实现。这种架构支持直接多步预测，并且算子的计算复杂度与可观测空间维度呈对数关系。QKM在各种非线性系统中得到验证。其预测在反应扩散系统和剪切流中保持相对误差低于6%，并捕获了二维湍流中的关键统计数据。这项工作为非线性现象的量子加速模拟建立了一条实用的途径，探索了一个建立在深度学习用于全局线性化和量子算法用于酉动力学演化协同作用之上的框架。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [385] [Unitary Complexity and the Uhlmann Transformation Problem](https://arxiv.org/abs/2306.13073)
> *幺正复杂性与乌尔曼变换问题*

*John Bostanci, Yuval Efron, Tony Metger, Alexander Poremba, Luowen Qian, Henry Yuen* | **Category: quant-ph, cs.CC, cs.CR** | **Updated: 2025-07-29**

**Keywords:** 幺正复杂性, 乌尔曼变换问题, 量子信息处理, 态变换, 计算复杂性

**Comment:** 96 pages. Technical changes: the definitions of unitaryBQP,
  unitaryQIP, etc, updated to be uniform in the error parameter. The
  zero-knowledge completeness result simplified, and a (weak) polarization
  lemma for Uhlmann transformations was added. Editorial changes: many sections
  slimmed down, revised, and polished. Comments welcome

> **TL;DR:** 引入幺正复杂性框架，研究量子态变换问题，形式化乌尔曼变换问题并揭示其复杂性关系，为量子信息处理任务的计算复杂性研究提供了新途径。

**AI_Comments:** 本文创新性地提出了幺正合成问题框架和幺正复杂性类，为研究量子态变换任务的计算复杂性提供了全新的理论工具。通过将乌尔曼定理算法化为乌尔曼变换问题，成功地将这一理论问题与实际的量子信息处理任务建立了联系，展现了其在理解量子计算难度方面的巨大潜力。这项工作对于推动量子复杂性理论的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 量子信息处理中的态变换任务（如量子信息压缩、破解量子承诺）是基本任务，但其计算难度难以用传统复杂性理论来刻画，因为传统理论侧重于经典输入输出的任务。

**Method:** 引入了幺正合成问题框架，包括归约和幺正复杂性类概念。利用该框架研究通过局部操作将纠缠态转换为另一纠缠态的复杂性，并将其形式化为乌尔曼变换问题（乌尔曼定理的算法版本）。

**Result:** 证明了乌尔曼变换问题的复杂性与多项式空间量子计算以及零知识协议之间的结构性关系。

**Conclusion:** 乌尔曼变换问题能够刻画多种量子信息处理任务的复杂性，包括解码噪声量子信道、破解可伪造量子密码假设、在量子交互式证明中实现最优证明者策略以及解码黑洞霍金辐射。因此，该幺正复杂性框架为研究许多自然量子信息处理任务的计算复杂性提供了新途径。

> **ai_Abstract:** 本文针对传统复杂性理论难以刻画量子态变换任务计算难度的问题，提出了一种幺正合成问题框架，并引入了幺正复杂性类概念。该框架用于研究通过局部操作实现纠缠态变换的复杂性，并将其形式化为乌尔曼变换问题。研究证明了乌尔曼变换问题与多项式空间量子计算及零知识协议之间的结构性关系。该框架及其定义的乌尔曼变换问题，为理解和分析多种量子信息处理任务（如量子信道解码、量子密码破解、量子交互式证明策略以及黑洞辐射解码）的计算复杂性提供了新的途径和工具。

> **摘要翻译:** 态变换问题，如压缩量子信息或破解量子承诺，是基本的量子任务。然而，它们的计算难度无法轻易地使用专注于经典输入和输出的传统复杂性理论来刻画。
为了研究此类态变换任务的复杂性，我们引入了一个幺正合成问题框架，包括归约和幺正复杂性类的概念。我们利用这个框架研究通过局部操作将一个纠缠态转换为另一个纠缠态的复杂性。我们将其形式化为乌尔曼变换问题，这是乌尔曼定理的算法版本。然后，我们证明了将乌尔曼变换问题的复杂性、多项式空间量子计算和零知识协议联系起来的结构性结果。
乌尔曼变换问题使我们能够刻画各种量子信息处理任务的复杂性，包括解码噪声量子信道、破解可伪造的量子密码假设、在量子交互式证明中实现最优证明者策略以及解码黑洞的霍金辐射。因此，我们的幺正复杂性框架为研究许多自然量子信息处理任务的计算复杂性提供了新途径。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [420] [Quantum Boltzmann Machines using Parallel Annealing for Medical Image Classification](https://arxiv.org/abs/2507.14116)
> *量子玻尔兹曼机在医学图像分类中的并行退火应用*

*Daniëlle Schuman, Mark V. Seebode, Tobias Rohe, Maximilian Balthasar Mansky, Michael Schroedl-Baumann, Jonas Stein, Claudia Linnhoff-Popien, Florian Krellner* | **Category: quant-ph, cs.ET, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 量子玻尔兹曼机,并行退火,医学图像分类,量子机器学习,NISQ

**Comment:** 12 pages, 5 figures (10 if counting subfigures), 2 tables. To be
  published in the proceedings of the 2025 IEEE International Conference on
  Quantum Computing and Engineering (QCE)

> **TL;DR:** 本文提出了一种改进的并行量子退火方法，用于监督训练量子玻尔兹曼机，并在医学图像分类上取得了与CNN相当的结果，同时显著减少了训练时间。

**AI_Comments:** 这篇论文在量子机器学习领域具有重要意义，尤其是在NISQ时代。其创新点在于将并行量子退火应用于监督学习设置下的QBM训练，并成功地将其应用于实际的医学图像分类任务。通过显著降低训练成本和时间，该研究为量子机器学习的实际应用铺平了道路，并展示了其在处理复杂数据集方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统量子玻尔兹曼机（QBM）训练需要大量量子处理单元（QPU）时间，成本高昂，限制了其在NISQ时代的实际应用。

**Method:** 本文提出了一种改进的并行量子退火方法，用于监督训练量子玻尔兹曼机（QBMs）。该方法通过节省用于编码输入的量子比特，并在MedMNIST医学图像数据集上进行测试，以实现更接近实际应用。

**Result:** 使用该方法的QBM在医学图像分类上取得了与相似大小的卷积神经网络（CNNs）相当的合理结果，且所需的训练周期（epochs）明显少于经典模型。并行退火技术相比常规基于退火的BM执行速度提升了近70%。

**Conclusion:** 本文提出的并行退火方法使得量子玻尔兹曼机在医学图像分类中的应用更接近实际，显示了其在效率和性能上的潜力。

> **ai_Abstract:** 本文提出了一种改进的并行量子退火方法，用于监督训练量子玻尔兹曼机（QBMs），以解决现有QBM训练成本高昂的问题。该方法通过优化量子比特使用，并在医学图像分类任务上进行验证。实验结果显示，该方法训练的QBM在性能上与传统CNN相当，同时显著减少了训练周期，并实现了近70%的速度提升，从而推动了QBM在实际应用中的可行性。

> **摘要翻译:** 利用量子退火器抽取的样本固有地遵循玻尔兹曼类分布这一事实，基于退火的量子玻尔兹曼机（QBMs）在量子研究社区中日益普及。尽管它们在量子加速方面前景广阔，但目前其使用仍然是一项昂贵的尝试，因为训练它们需要大量的QPU时间。这限制了它们在NISQ时代的适用性。遵循Noè等人（2024）的思路，他们试图通过将并行量子退火纳入其QBM的无监督训练来减轻这一成本，本文提出了一种改进的并行量子退火版本，我们将其用于监督设置下的QBM训练。通过节省用于编码输入的量子比特，后一种设置使我们能够在MedMNIST数据集（Yang等人，2023）的医学图像上测试我们的方法，从而使该技术更接近现实世界的适用性。我们的实验表明，使用我们方法的QBM已经取得了合理的结果，与相似大小的卷积神经网络（CNNs）的结果相当，且所需的训练周期明显少于这些经典模型。我们的并行退火技术相比常规基于退火的BM执行速度提升了近70%。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [436] [Supervised Quantum Image Processing](https://arxiv.org/abs/2507.22039)
> *监督量子图像处理*

*Marco Parigi, Mehran Khosrojerdi, Filippo Caruso, Leonardo Banchi* | **Category: quant-ph, cs.AI, cs.CV, cs.LG, 81P68, 81P70, 81P40, 68Q12, 68T01, I.2; I.4; J.2** | **Updated: 2025-07-29**

**Keywords:** 量子图像处理, 量子图像表示, 数据压缩, 量子核, 二分类

**Comment:** 13 pages, 11 figures

> **TL;DR:** 本文比较了四种量子图像表示的压缩性能，发现FRQI压缩率最高；并发现量子核在二分类问题上能提供与经典方法相当的准确性，但图像存储资源需求呈指数级减少。

**AI_Comments:** 这项工作在量子图像处理领域具有重要意义，因为它不仅比较了现有量子图像表示的压缩效率，还首次将监督学习中的量子核应用于图像分类问题，并证明了其在资源效率方面的显著优势。特别是在图像存储方面实现指数级减少，这对于处理大规模图像数据具有巨大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 面对大数据和人工智能时代日益增长的数据量和复杂计算挑战，需要提高数据存储、处理和分析的效率。量子图像处理 (QIP) 结合量子信息科学和图像处理，有望利用量子计算的能力缓解这些挑战。

**Method:** 本文首先比较了四种不同的量子图像表示（QImRs）：张量网络表示 (TNR)、量子图像的灵活表示 (FRQI)、新型增强量子表示 (NEQR) 和量子概率图像编码 (QPIE) 的压缩特性。其次，研究了二分类问题中准确性和内存之间的权衡，评估了基于QImRs的量子核与经典线性核的性能。

**Result:** 模拟结果显示，FRQI比TNR、NEQR和QPIE具有更高的图像信息压缩率。此外，研究表明量子核在分类平均准确性方面与经典线性核相当，但在图像存储方面所需资源呈指数级减少。

**Conclusion:** 量子图像处理，特别是使用量子核，在图像信息压缩和存储效率方面具有显著优势，同时能保持与经典方法相当的分类准确性，有望解决大数据时代的数据存储和处理挑战。

> **ai_Abstract:** 本文探讨了量子图像处理（QIP）在大数据背景下提高数据存储和处理效率的潜力。研究比较了四种量子图像表示（QImRs）的压缩性能，发现FRQI具有最高压缩率。同时，评估了基于QImRs的量子核在二分类问题中的表现，结果显示量子核在保持与经典方法相当的分类准确性的同时，能显著减少图像存储资源需求。

> **摘要翻译:** 在大数据和人工智能时代，日益增长的数据量和解决越来越复杂计算挑战的需求是提高数据存储、处理和分析效率的两个驱动力。量子图像处理（QIP）是量子信息科学和图像处理之间的交叉领域，它有潜力通过利用量子计算的能力来缓解其中一些挑战。在这项工作中，我们比较并检查了四种不同量子图像表示（QImRs）的压缩特性：即张量网络表示（TNR）、量子图像的灵活表示（FRQI）、新型增强量子表示（NEQR）和量子概率图像编码（QPIE）。我们的模拟表明，FRQI比TNR、NEQR和QPIE能够实现更高的图像信息压缩。此外，我们研究了二分类问题中准确性和内存之间的权衡，评估了基于QImRs的量子核与经典线性核的性能。我们的结果表明，量子核提供了可比的分类平均准确性，但图像存储所需的资源呈指数级减少。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [538] [Benchmarking a Tunable Quantum Neural Network on Trapped-Ion and Superconducting Hardware](https://arxiv.org/abs/2507.21222)
> *在离子阱和超导硬件上基准测试可调谐量子神经网络*

*Djamil Lakhdar-Hamina, Xingxin Liu, Richard Barney, Sarah H. Miller, Alaina M. Green, Norbert M. Linke, Victor Galitski* | **Category: quant-ph, cond-mat.dis-nn, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 量子神经网络, 离子阱, 超导硬件, MNIST, 量子优势

**Comment:** 6 pages, 3 figures

> **TL;DR:** 该论文在离子阱和超导量子计算机上实现了量子神经网络，用于MNIST图像分类。研究表明适度的量子不确定性可以提高性能，但物理噪声会影响边缘情况。它还对噪声进行了基准测试，并提出这种方法可能带来量子优势。

**AI_Comments:** 该论文在两种不同的量子硬件平台（离子阱和超导）上实验性地实现了量子神经网络，用于图像分类这一实际任务，具有创新性。其重要性在于探索了近期量子计算中量子效应（不确定性）与实际挑战（物理噪声）之间的相互作用。研究发现量子不确定性可以提高性能，但物理噪声显著影响“边缘”情况，这突出了设计鲁棒量子算法的关键方面。该工作也为在机器学习中潜在地实现量子优势提供了途径。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探索量子神经网络在图像分类等任务中的潜力，并调查量子特征是否能相对于经典方法提供优势，特别是在当前量子硬件限制和噪声背景下。它还旨在理解量子不确定性和物理噪声对网络性能的影响。

**Method:** 该研究在离子阱和IBM超导量子计算机上实现了一个神经网络的量子泛化版本，用于MNIST图像分类。网络的正向传播涉及量子比特旋转，其角度取决于前一层的测量结果。网络通过模拟进行训练，但推断是在量子硬件上实验性地执行的。一个插值参数'a'控制经典到量子的对应关系，其中'a'在经典极限下为零。此外，通过在神经网络电路中插入额外的单量子比特和双量子比特门对，进一步对物理噪声进行了基准测试。

**Result:** 增加插值参数'a'（引入量子不确定性）在中等值时可以提高网络性能。对于经典神经网络无法分类的边缘图像，量子网络观察到与模拟行为的强烈偏差，这归因于物理噪声，导致输出在分类能量景观的附近最小值之间波动。对于清晰的图像，这种对物理噪声的强烈敏感性是不存在的。

**Conclusion:** 该工作为当前设备上更复杂的量子神经网络提供了跳板。尽管该方法植根于标准经典机器学习，但扩展此类网络可能无法通过经典模拟实现，并可能为近期量子优势提供途径。物理噪声是一个重要因素，尤其对于“边缘”分类任务。

> **ai_Abstract:** 本文在离子阱和超导量子计算机上对可调谐量子神经网络进行了基准测试，用于MNIST图像分类。该网络的正向传播机制涉及基于前一层测量的量子比特旋转。虽然通过模拟进行训练，但推断是在实验中执行的。研究引入了一个插值参数“a”来控制经典到量子的对应关系，表明适度的量子不确定性（增加“a”）可以提高性能。然而，对于难以分类的边缘图像，量子网络由于物理噪声而表现出与模拟行为的显著偏差，导致输出波动。论文还通过添加门对来基准测试物理噪声，并提出尽管植根于经典机器学习，但扩展此类量子神经网络可能导致经典上无法模拟的系统并实现近期量子优势。

> **摘要翻译:** 我们在一台离子阱和一台IBM超导量子计算机上实现了一种神经网络的量子泛化，用于分类MNIST图像，这是计算机视觉中常见的基准。网络的正向传播涉及量子比特旋转，其角度取决于前一层测量的结果。网络通过模拟进行训练，但推断是在量子硬件上实验性地执行的。经典到量子的对应关系由插值参数$a$控制，在经典极限下，$a$为零。增加$a$会引入量子不确定性到测量中，这表明在中等插值参数值下可以提高网络性能。然后我们关注那些经典神经网络无法分类但量子网络能正确检测的特定图像。对于这些边界情况，我们观察到与模拟行为的强烈偏差。我们将其归因于物理噪声，这导致输出在分类能量景观的附近最小值之间波动。对于清晰的图像，这种对物理噪声的强烈敏感性是不存在的。我们通过在神经网络电路中插入额外的单量子比特和双量子比特门对来进一步基准测试物理噪声。我们的工作为当前设备上更复杂的量子神经网络提供了跳板：虽然该方法植根于标准经典机器学习，但扩展此类网络可能无法通过经典模拟实现，并可能为近期量子优势提供途径。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [554] [Meta-Designing Quantum Experiments with Language Models](https://arxiv.org/abs/2406.02470)
> *使用语言模型进行量子实验的元设计*

*Sören Arlt, Haonan Duan, Felix Li, Sang Michael Xie, Yuhuai Wu, Mario Krenn* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 元设计, 量子实验, 语言模型, 人工智能, 自动化发现

**Comment:** 8+23 pages, 5 figures

> **TL;DR:** 本文提出了一种名为“元设计”的新策略，利用基于Transformer的语言模型生成人类可读的Python代码，以自动化发现量子实验的通用设计概念，从而在解决复杂科学问题的同时提供更深层次的物理原理洞察。

**AI_Comments:** 该论文的创新点在于提出了“元设计”的概念，利用语言模型生成人类可读的代码来自动化发现科学实验的通用设计概念。这不仅解决了传统AI解决方案缺乏可解释性的问题，还使得科学家能够获得更深层次的物理洞察，并能推广到更复杂的实验。其重要性在于为AI在科学发现中的应用开辟了新的途径，特别是在需要理解和泛化能力的领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人工智能在解决复杂科学问题（如量子物理中量子态的生成实验）时，虽然能发现解决方案，但却难以提供对底层物理原理的洞察，也无法自动化发现通用的设计概念。

**Method:** 研究人员训练了一个基于Transformer的语言模型，使其能够创建人类可读的Python代码。这种代码可以一次性解决一整类问题，这种策略被称为“元设计”。

**Result:** 通过“元设计”方法，研究人员发现了重要量子态（例如凝聚态物理中的量子态）以前未知的实验泛化。

**Conclusion:** “元设计”的基础方法可以自然地扩展到材料科学或工程等其他领域。

> **ai_Abstract:** 本文提出了一种名为“元设计”的新策略，旨在解决人工智能在解决量子物理问题时缺乏对底层物理原理洞察的挑战。通过训练一个基于Transformer的语言模型生成人类可读的Python代码，该模型能够一次性解决一整类量子实验设计问题。这种方法不仅有助于科学家深入理解，还能促进对更大规模实验的推断，并成功发现了重要量子态的未知实验泛化。该方法具有推广至材料科学和工程等其他领域的潜力。

> **摘要翻译:** 人工智能（AI）可以解决超越人类能力的复杂科学问题，但由此产生的解决方案对底层物理原理的洞察力甚少。一个突出的例子是量子物理，计算机可以发现生成特定量子态的实验，但如何自动化地发现通用设计概念尚不清楚。在此，我们通过训练一个基于Transformer的语言模型来创建人类可读的Python代码，从而一次性解决一整类问题，以此应对这一挑战。这种我们称之为元设计的策略，使科学家能够获得更深入的理解，并无需额外的优化即可推断出更大的实验。为了证明我们方法的有效性，我们揭示了重要量子态（例如凝聚态物理中的量子态）以前未知的实验泛化。元设计的基础方法可以自然地扩展到材料科学或工程等领域。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [638] [Quantum enhanced stratification of Breast Cancer: exploring quantum expressivity for real omics data](https://arxiv.org/abs/2409.14089)
> *量子增强乳腺癌分层：探索量子表达能力在真实组学数据中的应用*

*Valeria Repetto, Elia Giuseppe Ceroni, Giuseppe Buonaiuto, Romina D'Aurizio* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 量子机器学习, 乳腺癌, 量子核, 精准肿瘤学, NISQ

**Comment:** 10 pages, 6 figures

> **TL;DR:** 本研究探索了量子核（QK）在乳腺癌分子分型中的应用，发现QK在数据量有限的情况下表现出与经典方法相当或更好的分层能力，并且对NISQ设备的噪声具有一定弹性，表明其在精准肿瘤学中的应用潜力。

**AI_Comments:** 这项研究具有创新性，因为它将量子机器学习应用于真实的医学组学数据，特别是在乳腺癌分层中，这在当前QML应用仍处于早期阶段的医学领域是一个重要的进展。它不仅展示了量子核在有限数据情况下的潜力，还考虑了NISQ设备的噪声影响，并提出了一种对噪声具有鲁棒性的编码策略，这对于QML的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管量子机器学习（QML）被认为是NISQ时代量子计算最具前景的应用之一，但其在医学和生物学领域的探索仍处于起步阶段，鲜有实例。本研究旨在评估量子核（QK）能否有效分类基于分子特征的乳腺癌（BC）患者亚型。

**Method:** 研究通过启发式探索不同纠缠级别的编码配置，评估量子核（QK）对乳腺癌患者亚型进行分类的有效性，以权衡核的表达能力和性能。此外，还在量子处理单元（QPU）上进行了实验，以评估噪声对结果的影响。

**Result:** 量子核（QK）在使用更少数据点的情况下，获得了与经典方法相当的聚类结果，并且能够拟合更多数量的簇。此外，表达能力较低的编码对噪声表现出更高的弹性。

**Conclusion:** 量子核（QK）方法在精准肿瘤学中显示出应用前景，尤其是在数据集大小有限且经典方法难以实现复杂分子数据精细非平凡分层的情况下。研究还表明，计算流程可以在NISQ设备上可靠地实现。

> **ai_Abstract:** 本研究旨在探索量子机器学习在医学领域的应用潜力，特别是评估量子核（QK）在乳腺癌分子分型中的有效性。通过对不同编码配置的启发式探索，研究发现QK在处理真实组学数据时，即便使用更少的数据点，也能达到与经典方法相当或更好的聚类效果，并能识别更多簇。实验结果还表明，较低表达能力的编码对量子处理单元（QPU）上的噪声具有较强的鲁棒性，这表明该计算流程在噪声中等规模量子（NISQ）设备上具有可靠性。研究结论指出，量子核方法在数据量受限且需要精细分层的精准肿瘤学领域具有重要应用前景。

> **摘要翻译:** 量子机器学习（QML）被认为是噪声中等规模量子（NISQ）时代量子计算最具前景的应用之一，因为它被认为在不久的将来会产生影响。尽管有前景的理论假设，但QML如何促进医学和生物学领域新发现的探索仍处于起步阶段，鲜有实例。在这项研究中，我们旨在评估量子核（QK）是否能根据分子特征有效分类乳腺癌（BC）患者的亚型。我们对不同纠缠级别的编码配置进行了启发式探索，以确定核表达能力和性能之间的权衡。我们的结果表明，QK在数据点更少的情况下，能达到与经典方法相当的聚类结果，并且能够拟合更多数量的簇。此外，我们在量子处理单元（QPU）上进行了实验，以评估噪声对结果的影响。我们发现，表达能力较低的编码对噪声表现出更高的弹性，这表明计算流程可以在NISQ设备上可靠地实现。我们的发现表明，QK方法在精准肿瘤学中显示出应用前景，特别是在数据集大小有限且经典方法难以实现复杂分子数据精细非平凡分层的情况下。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [88] [Nonparametric Sparse Online Learning of the Koopman Operator](https://arxiv.org/abs/2405.07432)
> *Koopman算子的非参数稀疏在线学习*

*Boya Hou, Sina Sanjari, Nathan Dahlin, Alec Koppel, Subhonmesh Bose* | **Category: stat.ML, cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-29**

**Keywords:** Koopman算子, 在线学习, 稀疏学习, 非参数, 随机逼近

**Comment:** 47 pages, 6 figures

> **TL;DR:** 本文提出了一种稀疏在线学习算法，用于迭代学习Koopman算子，解决了现有方法依赖批量数据的问题，并提供了收敛性保证。

**AI_Comments:** 本文的创新之处在于提出了一个在线学习框架来学习Koopman算子，摆脱了传统批量数据依赖的限制，使其更适用于实时或流数据场景。在理论上，它提供了严格的收敛性保证，并且考虑了实际中常见的模型错误指定问题，增强了算法的鲁棒性。这对于理解和预测复杂非线性系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据驱动的Koopman算子学习方法依赖于批量数据，限制了其在处理顺序到达数据时的应用。

**Method:** 本文提出了一种稀疏在线学习算法，通过随机逼近迭代学习Koopman算子，并显式控制模型复杂度。该方法通过研究Koopman算子在再生核希尔伯特空间（RKHS）上的作用，并处理动力学可能超出所选RKHS的错误指定情景。在这种情景下，将Koopman算子与条件均值嵌入（CME）算子关联起来。

**Result:** 该学习算法在错误指定情景下，对于基于轨迹的采样（数据随时间顺序到达）建立了渐近和有限时间收敛性保证。数值实验证明了该算法学习未知非线性动力学的能力。

**Conclusion:** 本文提出的稀疏在线学习算法能够有效学习Koopman算子，解决了批量数据依赖问题，并在理论上提供了收敛性保证，在实践中展示了其学习非线性动力学的能力。

> **ai_Abstract:** 本文提出了一种非参数稀疏在线学习算法，用于迭代学习Koopman算子。该算法通过随机逼近在再生核希尔伯特空间（RKHS）上操作，解决了现有方法依赖批量数据的问题，并处理了动力学可能超出RKHS的错误指定情景。研究建立了该算法在错误指定设置下，对于顺序到达数据的渐近和有限时间收敛性保证。数值实验验证了其学习未知非线性动力学的能力。

> **摘要翻译:** Koopman算子为表示一般非线性动力学系统的动力学提供了一个强大的框架。然而，现有的数据驱动的Koopman算子学习方法依赖于批量数据。在这项工作中，我们提出了一种稀疏在线学习算法，通过随机逼近迭代学习Koopman算子，并对模型复杂性进行明确控制，同时提供可证明的收敛性保证。具体来说，我们通过Koopman算子在再生核希尔伯特空间（RKHS）上的作用来研究它，并解决了动力学可能超出所选RKHS的错误指定情景。在这种错误指定设置中，我们将Koopman算子与条件均值嵌入（CME）算子关联起来。我们进一步为我们的学习算法在错误指定设置下，在数据随时间顺序到达的基于轨迹的采样中，建立了渐近和有限时间收敛性保证。数值实验证明了该算法学习未知非线性动力学的能力。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [193] [An Equal-Probability Partition of the Sample Space: A Non-parametric Inference from Finite Samples](https://arxiv.org/abs/2507.21712)
> *样本空间的等概率划分：基于有限样本的非参数推断*

*Urban Eriksson* | **Category: stat.ML, cs.LG, stat.ME** | **Updated: 2025-07-29**

**Keywords:** 等概率划分, 非参数推断, 有限样本, 序统计量, 离散熵

**Comment:** 

> **TL;DR:** 本文提出，有限样本点将样本空间划分为N+1个等概率质量的区间，并基于此进行非参数推断，量化了样本信息。

**AI_Comments:** 这项工作提供了一种新颖的视角来理解有限样本中包含的信息量，通过引入等概率划分的概念，为非参数推断提供了一个稳健的框架。其创新点在于将样本点直接转化为具有明确概率质量的区间，并量化了由此获得的信息熵，这与传统的连续变量信息理论有所区别。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探究如何从有限的N个观测样本中推断任意连续概率分布的性质。

**Method:** 该研究的核心发现是，N个排序后的样本点将实线划分为N+1个线段，每个线段的预期概率质量恰好为1/(N+1)。这一非参数结果源于序统计量的基本性质。

**Result:** 每个线段的预期概率质量为1/(N+1)，且这种等概率划分产生了log2(N+1)比特的离散熵，量化了从样本中获得的信息。研究还将这种基于划分的框架与传统ECDF进行了比较。

**Conclusion:** 这种等概率划分的框架对稳健的非参数推断具有重要意义，尤其是在密度和尾部估计方面。

> **ai_Abstract:** 本文提出了一种基于有限样本的非参数推断方法。研究发现，N个排序后的样本点将样本空间划分为N+1个等概率质量的线段，每个线段的预期概率质量为1/(N+1)。这一发现基于序统计量，与底层分布无关。这种划分方法产生了一个离散熵，用于量化样本信息，并被认为对稳健的非参数推断，尤其是密度和尾部估计具有重要意义。

> **摘要翻译:** 本文研究了从有限的N个观测样本中可以推断出任意连续概率分布的什么信息。核心发现是，N个排序后的样本点将实线划分为N+1个线段，每个线段的预期概率质量恰好为1/(N+1)。这一非参数结果源于序统计量的基本性质，并且无论底层分布的形状如何都成立。这种等概率划分产生了log2(N+1)比特的离散熵，量化了从样本中获得的信息，并与香农对连续变量的结果形成对比。我将这种基于划分的框架与传统的ECDF进行了比较，并讨论了其对稳健非参数推断的含义，特别是在密度和尾部估计方面。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [334] [MIBoost: A Gradient Boosting Algorithm for Variable Selection After Multiple Imputation](https://arxiv.org/abs/2507.21807)
> *MIBoost：一种多重插补后变量选择的梯度提升算法*

*Robert Kuchen* | **Category: stat.ML, cs.LG, 62J07, 62H12, 62F07** | **Updated: 2025-07-29**

**Keywords:** 多重插补, 变量选择, 梯度提升, MIBoost, 统计学习

**Comment:** 21 pages, 2 algorithms, includes a simulation study

> **TL;DR:** MIBoost是一种新的梯度提升算法，用于在多重插补数据中进行统一变量选择，其预测性能与现有方法相当。

**AI_Comments:** 这篇论文的创新点在于将“统一系数”或“单一损失函数”的原则从LASSO和弹性网络扩展到了梯度提升算法，为处理多重插补后的变量选择提供了一个新的、统一的框架。其重要性在于解决了多重插补数据下模型选择的实际难题，提供了一个易于实现且性能良好的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的处理多重插补数据中的模型选择方法存在问题：简单策略次优，复杂方法难以实现，导致在多重插补数据集上进行模型选择时存在争议。

**Method:** 提出MIBoost，这是一种将“单一损失函数”原则扩展到分量梯度提升框架的新算法，通过在插补数据集上采用统一的变量选择机制。

**Result:** 模拟研究表明，MIBoost的预测性能与最近提出的方法相当。

**Conclusion:** MIBoost为多重插补后的变量选择提供了一个有效的梯度提升解决方案，其性能与现有先进方法相当。

> **ai_Abstract:** 该论文提出了一种名为MIBoost的新型梯度提升算法，用于解决多重插补数据中变量选择的挑战。针对现有方法在多重插补数据中进行模型选择的局限性（简单方法次优，复杂方法难实现），MIBoost通过将单一损失函数原则扩展到梯度提升框架，实现了在多个插补数据集上统一的变量选择机制。模拟研究表明，MIBoost的预测性能与近期提出的先进方法相当。

> **摘要翻译:** 用于自动化变量选择的统计学习方法，如LASSO、弹性网络或梯度提升，已成为构建强大预测模型的日益流行的工具。然而，在实践中，分析常常因缺失数据而复杂化。处理缺失数据最广泛使用的方法是多重插补，它创建了几个完整的数据集。然而，关于在存在多个插补数据集的情况下如何进行模型选择，目前仍存在争议。简单的策略，例如跨数据集汇集模型，已被证明具有次优特性。尽管存在更复杂的方法，但它们通常难以实现，因此未被广泛应用。相比之下，最近的两种方法通过定义一个单一的损失函数来修改正则化方法LASSO和弹性网络，从而在所有插补数据中产生一组统一的系数。我们的主要贡献是将这一原则扩展到分量梯度提升框架，提出了MIBoost，这是一种在插补数据集上采用统一变量选择机制的新算法。模拟研究表明，我们的方法产生的预测性能与这些最近提出的方法相当。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [508] [Active learning for level set estimation under input uncertainty and its extensions](https://arxiv.org/abs/1909.06064)
> *主动学习用于输入不确定性下的水平集估计及其扩展*

*Yu Inatsu, Masayuki Karasuyama, Keiichi Inoue, Ichiro Takeuchi* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 水平集估计, 输入不确定性, 主动学习, 理论保证, 工业应用

**Comment:** 38 pages, 12 figures

> **TL;DR:** 本文提出了在输入不确定性条件下进行水平集估计的主动学习方法，并提供了理论保证，适用于多种相关挑战。

**AI_Comments:** 本文的创新点在于提出了一个处理输入不确定性下水平集估计问题的通用框架和具有理论保证的主动学习方法，这对于提高LSE在实际工业应用中的鲁棒性和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 制造业中，确定产品满足所需特性的条件是一个基本问题。这可以看作是水平集估计（LSE）问题。尽管LSE方法众多，但在实际应用中仍存在许多问题，其中之一是输入条件无法精确控制，即输入不确定性下的LSE问题。

**Method:** 论文引入了一个处理LSE问题中输入不确定性的基本框架，并提出了具有理论保证的有效方法。

**Result:** 将所提出的方法应用于人工数据和真实数据，以证明其适用性和有效性。

**Conclusion:** 所提出的方法和理论可以普遍应用于与输入不确定性下LSE相关的各种挑战，例如依赖成本的输入不确定性以及未知输入不确定性。

> **ai_Abstract:** 本文关注在输入条件不确定情况下进行水平集估计（LSE）的实际挑战。作者提出了一个处理此类问题的新框架，并开发了具有理论保证的高效主动学习方法。这些方法被证明适用于各种与输入不确定性相关的LSE问题，并通过人工和真实数据验证了其有效性。

> **摘要翻译:** 在什么条件下产品能满足期望的特性，是制造业中的一个基本问题。如果条件和特性分别被视为黑盒函数的输入和输出，这项任务可以被解释为水平集估计（LSE）问题——即识别函数值高于（或低于）某个阈值的输入区域的问题。尽管迄今为止已经开发了各种LSE问题的方法，但它们的实际使用仍有许多问题需要解决。作为其中一个问题，我们考虑输入条件无法精确控制的情况，即输入不确定性下的LSE问题。我们引入了一个处理LSE问题中输入不确定性的基本框架，然后提出了具有适当理论保证的有效方法。所提出的方法和理论可以普遍应用于与输入不确定性下LSE相关的各种挑战，例如依赖成本的输入不确定性和未知输入不确定性。我们将所提出的方法应用于人工和真实数据，以证明其适用性和有效性。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [582] [BEACON: A Bayesian Optimization Strategy for Novelty Search in Expensive Black-Box Systems](https://arxiv.org/abs/2406.03616)
> *BEACON：一种用于昂贵黑盒系统中新颖性搜索的贝叶斯优化策略*

*Wei-Ting Tang, Ankush Chakrabarty, Joel A. Paulson* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 新颖性搜索, 贝叶斯优化, 黑盒系统, 多输出高斯过程, 样本效率

**Comment:** 

> **TL;DR:** BEACON是一种新的贝叶斯优化方法，用于在昂贵黑盒系统中进行高效的新颖性搜索，它通过多输出高斯过程建模并显著优于现有基线。

**AI_Comments:** BEACON的创新之处在于将贝叶斯优化引入新颖性搜索，解决了传统进化策略在昂贵黑盒系统中的采样效率问题。其利用MOGP建模不透明的输入-行为关系并平衡探索-利用的能力，使其在资源受限的AI驱动发现与设计任务中具有重要应用价值。该方法的可扩展性也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有新颖性搜索方法（如进化策略）需要大量输入空间采样，这使得它们不适用于评估成本高昂且输入到行为关系不透明的黑盒系统。

**Method:** 本文引入了BEACON，这是一种样本高效、受贝叶斯优化启发的新颖性搜索方法。BEACON使用多输出高斯过程（MOGPs）对输入到行为的映射进行建模，并通过最大化从MOGP后验样本计算得到的新颖性度量来选择新的输入，从而有效平衡探索与利用的权衡。该方法利用后验采样和高维GP建模的最新进展，可扩展到大型输入空间和数据集。

**Result:** BEACON在十个合成基准和八个真实世界任务（包括清洁能源应用的多种材料设计）上进行了评估。结果表明，BEACON显著优于现有新颖性搜索基线，在严格的评估预算下持续发现更广泛的行为集。

**Conclusion:** BEACON为昂贵黑盒系统中的新颖性搜索提供了一种更高效、更强大的解决方案，克服了现有方法的局限性，并能在有限预算内发现更多样化的行为。

> **ai_Abstract:** 本文介绍了BEACON，一种针对昂贵黑盒系统的新颖性搜索贝叶斯优化策略。针对现有方法在资源受限环境中的低效问题，BEACON利用多输出高斯过程建模输入-行为关系，并通过最大化后验样本的新颖性指标来平衡探索与利用。实验证明，BEACON在多个合成和真实世界任务中，以更少的评估预算发现更多样化的行为，显著优于现有基线。

> **摘要翻译:** 新颖性搜索（NS）是一类探索算法，旨在通过模拟或实验发现多样化的系统行为。这种多样性对于许多AI驱动的发现和设计任务至关重要，包括材料和药物开发、神经架构搜索和强化学习。然而，现有NS方法通常依赖于进化策略和其他元启发式算法，这些算法需要密集的输入空间采样，因此对于昂贵的黑盒系统来说不切实际。在这项工作中，我们引入了BEACON，一种样本高效、受贝叶斯优化启发的新颖性搜索方法，专为输入到行为关系不透明且评估成本高昂的设置而设计。BEACON使用多输出高斯过程（MOGP）对这种映射进行建模，并通过最大化从MOGP后验样本计算得到的新颖性度量来选择新的输入，从而有效平衡探索与利用的权衡。通过利用后验采样和高维GP建模的最新进展，我们的方法对大型输入空间和数据集仍然具有可扩展性。我们在十个合成基准和八个真实世界任务（包括清洁能源应用的多种材料设计）上评估了BEACON。我们的结果表明，BEACON显著优于现有NS基线，在严格的评估预算下始终发现更广泛的行为集。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [693] [Robust Matrix Completion for Discrete Rating-Scale Data: Coping with Fake Profiles in Recommender Systems](https://arxiv.org/abs/2412.20802)
> *鲁棒矩阵补全用于离散评分数据：应对推荐系统中的虚假档案*

*Aurore Archimbaud, Andreas Alfons, Ines Wilms* | **Category: stat.ML, cs.LG, stat.CO, stat.ME** | **Updated: 2025-07-29**

**Keywords:** 矩阵补全, 推荐系统, 离散数据, 虚假档案, 鲁棒性

**Comment:** 

> **TL;DR:** 本文提出了一种名为RDMC的鲁棒离散矩阵补全方法，用于推荐系统，以处理离散评分数据和虚假档案，并提供评估真实场景下矩阵补全方法的蓝图。

**AI_Comments:** 本文的创新之处在于提出了一种能够同时处理离散评分数据和推荐系统中虚假档案的鲁棒矩阵补全方法。其重要性体现在解决了推荐系统在实际应用中经常被忽视的关键挑战，并为未来研究提供了实用的评估框架，对于提高推荐系统的可靠性和抗操纵性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 推荐系统中的矩阵补全面临几个被忽视的挑战：(i)评分数据的离散性，(ii)恶意用户创建虚假档案进行操纵，以及(iii)非随机缺失模式。本研究旨在解决这些问题。

**Method:** 提出了一种名为“鲁棒离散矩阵补全 (RDMC)”的新型矩阵补全方法。该方法专门设计用于处理稀疏评分数据的离散性，并在存在对抗性操纵（虚假档案）的情况下保持可靠性。

**Result:** 通过精心设计的实验和现实案例研究对RDMC进行了评估。此外，本工作为未来研究如何在现实场景下评估推荐系统中的矩阵补全方法提供了一个统计学上可靠的蓝图。

**Conclusion:** 本文提出并评估了RDMC方法，有效应对了推荐系统中离散评分数据和虚假档案的挑战，并为未来评估推荐系统矩阵补全方法提供了实践指导。

> **ai_Abstract:** 本文提出了一种名为鲁棒离散矩阵补全（RDMC）的新型矩阵补全方法，旨在解决推荐系统中离散评分数据和虚假档案带来的挑战。该方法通过实验和案例研究进行了评估，并为在现实场景下评估推荐系统中的矩阵补全方法提供了统计学上可靠的指导。

> **摘要翻译:** 推荐系统是数字环境中连接用户与更符合其偏好内容的重要工具。矩阵补全是此类系统中广泛使用的统计框架，旨在通过利用部分填充的用户-项目评分矩阵中的观测评分来预测用户对他们尚未评分项目的偏好。推荐系统中矩阵补全的实际应用必须解决几个经常被忽视的挑战：(i)评分数据的离散性质，(ii)恶意用户通过创建虚假档案来操纵系统以谋取利益，以及(iii)非随机缺失模式，即用户更倾向于评价他们期望喜欢的产品。本文的目标是双重的。首先，我们提出了一种新颖的矩阵补全方法——鲁棒离散矩阵补全（RDMC），专门设计用于处理稀疏评分数据的离散性质，并在存在对抗性操纵的情况下保持可靠。我们通过精心设计的实验和现实案例研究评估了RDMC。因此，其次，我们的工作为未来研究如何在现实场景下评估推荐系统中的矩阵补合方法提供了一个统计学上可靠的蓝图。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [706] [Graph neural networks for residential location choice: connection to classical logit models](https://arxiv.org/abs/2507.21334)
> *图神经网络在居住地选择中的应用：与经典Logit模型的联系*

*Zhanhong Cheng, Lingqian Hu, Yuheng Bu, Yuqi Zhou, Shenhao Wang* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 图神经网络, 离散选择模型, 居住地选择, Logit模型, 空间相关性

**Comment:** 

> **TL;DR:** 本文提出使用图神经网络（GNN）分析居住地选择，以解决现有深度学习方法无法捕捉选择备选项之间关系的问题。GNN-DCM模型在理论上包含了嵌套Logit和空间相关Logit模型，并在实证中超越了基准模型，展现了其在复杂空间选择背景下的潜力。

**AI_Comments:** 本文的创新点在于将图神经网络引入离散选择分析，特别是针对居住地选择问题，有效地解决了传统深度学习方法在处理选择备选项之间关系方面的不足。其理论贡献在于明确了GNN-DCMs与经典Logit模型的联系，提升了模型的可解释性。实证结果也验证了其优越的预测性能和解释能力，为复杂空间选择背景下的建模提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习方法在离散选择分析中无法明确捕捉选择备选项之间的关系，而这在经典离散选择模型中是一个长期关注的焦点。

**Method:** 本文引入图神经网络（GNN）作为分析居住地选择的新颖框架，提出了基于GNN的离散选择模型（GNN-DCMs）。理论上，证明了GNN-DCMs将嵌套Logit（NL）模型和空间相关Logit（SCL）模型作为两种特定情况纳入，并通过备选项效用之间的消息传递提供了新的算法解释。实证上，将GNN-DCMs与基准MNL、SCL和前馈神经网络进行了比较。

**Result:** GNN-DCMs在预测芝加哥77个社区的居住地选择方面优于基准MNL、SCL和前馈神经网络。在模型解释方面，GNN-DCMs能够捕捉个体异质性并表现出空间感知的替代模式。

**Conclusion:** GNN-DCMs作为一种统一且富有表现力的框架，在复杂的空间选择背景下，具有协同离散选择建模和深度学习的潜力。

> **ai_Abstract:** 本文提出了一种基于图神经网络（GNN）的离散选择模型（GNN-DCMs），用于分析居住地选择。该模型旨在解决现有深度学习方法无法有效捕捉选择备选项之间关系的问题。GNN-DCMs在理论上被证明包含了嵌套Logit和空间相关Logit模型，并通过消息传递提供了新的解释。实证研究表明，GNN-DCMs在预测居住地选择方面优于传统Logit模型和前馈神经网络，并能捕捉个体异质性和空间替代模式。研究结果强调了GNN-DCMs在结合离散选择建模和深度学习方面的潜力。

> **摘要翻译:** 研究人员已将深度学习应用于经典的离散选择分析，因为它能够捕捉复杂的特征关系并实现更高的预测性能。然而，现有的深度学习方法无法明确捕捉选择备选项之间的关系，而这在经典离散选择模型中是一个长期关注的焦点。为了弥补这一空白，本文引入图神经网络（GNN）作为分析居住地选择的新颖框架。基于GNN的离散选择模型（GNN-DCMs）为神经网络提供了一种结构化方法，以捕捉空间备选项之间的依赖关系，同时与经典随机效用理论保持清晰的联系。理论上，我们证明了GNN-DCMs将嵌套Logit（NL）模型和空间相关Logit（SCL）模型作为两种特定情况纳入，通过备选项效用之间的消息传递产生了新颖的算法解释。在实证上，GNN-DCMs在预测芝加哥77个社区的居住地选择方面优于基准MNL、SCL和前馈神经网络。在模型解释方面，GNN-DCMs能够捕捉个体异质性并表现出空间感知的替代模式。总的来说，这些结果突出了GNN-DCMs作为一种统一且富有表现力的框架，在复杂的空间选择背景下，具有协同离散选择建模和深度学习的潜力。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [750] [A Review on Self-Supervised Learning for Time Series Anomaly Detection: Recent Advances and Open Challenges](https://arxiv.org/abs/2501.15196)
> *时间序列异常检测中自监督学习综述：最新进展与开放挑战*

*Aitor Sánchez-Ferrera, Borja Calvo, Jose A. Lozano* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 自监督学习, 时间序列异常检测, 综述, 分类, 无监督方法

**Comment:** 

> **TL;DR:** 本文综述了时间序列异常检测中自监督学习的最新方法，并提出了分类体系。

**AI_Comments:** 这篇综述文章及时地梳理了时间序列异常检测领域中自监督学习的最新进展。其创新之处在于提出了一个分类体系，有助于读者理解该领域内方法的多元性。这对于研究人员和实践者来说都具有重要价值，因为它提供了对新兴解决方案的全面概览，并指明了潜在的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 时间序列异常检测由于其序列性和动态性面临挑战，传统无监督方法泛化能力差，容易过拟合。自监督学习被视为解决这些问题和提升异常检测性能的潜在方案。

**Method:** 本文对时间序列异常检测中利用自监督学习的最新方法进行了全面综述，并提出了一个分类体系，根据主要特征对这些方法进行分类。

**Result:** 提出了一个分类体系，用于根据主要特征对时间序列自监督学习异常检测方法进行分类，有助于清晰理解该领域的多样性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文综述了时间序列异常检测中自监督学习的最新进展。鉴于传统无监督方法在泛化能力上的不足，自监督技术被视为一种有效解决方案。文中提出了一个分类体系，旨在清晰地理解这些方法的特点和多样性，并提供了相关信息和资源。

> **摘要翻译:** 时间序列异常检测由于时间依赖数据的序列性和动态性而面临各种挑战。传统的无监督方法在泛化方面经常遇到困难，通常会对训练期间观察到的已知正常模式过拟合，并且难以适应未见的正常情况。针对这一局限性，时间序列的自监督技术作为解决这一障碍和提高异常检测器性能的潜在方案受到了关注。本文全面回顾了利用自监督学习进行时间序列异常检测的最新方法。本文提出了一个分类体系，根据其主要特征对这些方法进行分类，有助于清晰理解该领域的多样性。本调查中包含的信息，以及将定期更新的附加详细信息，可在以下GitHub存储库中获取：https://github.com/Aitorzan3/Awesome-Self-Supervised-Time-Series-Anomaly-Detection。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [778] [Heterogeneous Treatment Effect in Time-to-Event Outcomes: Harnessing Censored Data with Recursively Imputed Trees](https://arxiv.org/abs/2502.01575)
> *时间事件结果中的异质性治疗效果：利用递归插补树处理审查数据*

*Tomer Meir, Uri Shalit, Malka Gorfine* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 异质性治疗效果, 生存分析, 审查数据, 工具变量, 递归插补树

**Comment:** 

> **TL;DR:** 本文提出MISTR，一种新的非参数方法，用于在生存数据中估计异质性治疗效果，特别是在严重审查和存在工具变量的情况下，解决了现有方法的局限性。

**AI_Comments:** 该论文的创新之处在于提出了MISTR，一个非参数方法，首次实现了在存在工具变量的情况下对未观测混杂因素的HTE估计。它通过递归插补生存树巧妙地处理了审查数据，避免了对审查机制的直接建模，这对于在存在严重审查的罕见结局问题中尤其重要。MISTR的提出显著提升了生存数据中HTE估计的鲁棒性和适用性，为医学等领域提供了更可靠的个性化治疗效果评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 在医学等领域，根据个体需求定制治疗方案是一个核心目标，其中估计异质性治疗效果（HTE）至关重要。然而，现有方法在处理生存数据中的右侧审查时，常因假设完全观测而导致偏差和低效，尤其在严重审查下表现不佳，且大多数方法无法处理工具变量，这限制了其在因果推断中的应用。

**Method:** 本文引入了生存治疗响应多重插补（MISTR），这是一种新颖、通用且非参数的方法，用于估计生存数据中的HTE。MISTR利用递归插补生存树来处理审查数据，而无需直接建模审查机制。

**Result:** 通过广泛的模拟和对两个真实世界数据集（AIDS临床试验组协议175和伊利诺伊州失业数据集）的分析，结果表明MISTR在无隐藏混杂因素设置下，在严重审查情况下优于现有方法，并能扩展到工具变量设置。

**Conclusion:** 据作者所知，MISTR是第一个通过工具变量估计存在未观测混杂因素的HTE的非参数方法。

> **ai_Abstract:** 本研究提出了一种名为MISTR（生存治疗响应多重插补）的新型非参数方法，旨在解决生存数据中异质性治疗效果（HTE）估计的挑战。MISTR通过利用递归插补生存树来有效处理审查数据，避免了直接建模审查机制的复杂性。该方法旨在克服现有HTE估计方法在严重审查条件下的局限性，并首次扩展到能够处理工具变量的情况。通过广泛的模拟和对真实世界数据集的分析，研究证明MISTR在处理严重审查数据时优于现有方法，并在存在工具变量的设置中展现出其能力，填补了该领域非参数HTE估计的空白。

> **摘要翻译:** 根据个体需求定制治疗方案是医学等领域的核心目标。实现这一目标的关键一步是估计异质性治疗效果（HTE）——治疗对不同亚组的影响方式。虽然至关重要，但在生存数据中，HTE估计具有挑战性，其中事件发生的时间（例如死亡）是关键。现有方法通常假设完全观测，而由于右侧审查，这一假设在生存数据中被违反，导致偏差和低效。Cui等人（2023）提出了一种在无隐藏混杂因素下，结合因果生存森林和增强逆审查加权估计器的双重稳健方法，用于生存数据中的HTE估计。然而，我们发现它在严重审查下表现不佳，这在肌萎缩侧索硬化症（ALS）等罕见结局问题中很常见。此外，大多数现有方法无法处理工具变量，而工具变量是因果推断工具箱中的关键工具。我们引入了生存治疗响应多重插补（MISTR），这是一种新颖、通用且非参数的方法，用于估计生存数据中的HTE。MISTR使用递归插补生存树来处理审查数据，而无需直接建模审查机制。通过广泛的模拟和对两个真实世界数据集——AIDS临床试验组协议175和伊利诺伊州失业数据集的分析，我们表明MISTR在无隐藏混杂因素设置下，在严重审查情况下优于现有方法，并能扩展到工具变量设置。据我们所知，MISTR是第一个通过工具变量估计存在未观测混杂因素的HTE的非参数方法。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [783] [From Sublinear to Linear: Fast Convergence in Deep Networks via Locally Polyak-Lojasiewicz Regions](https://arxiv.org/abs/2507.21429)
> *从次线性到线性：通过局部Polyak-Lojasiewicz区域实现深度网络的快速收敛*

*Agnideep Aich, Ashit Baran Aich, Bruce Wade* | **Category: stat.ML, cs.LG, 68T07, 90C26, 65K10** | **Updated: 2025-07-29**

**Keywords:** 深度学习, 梯度下降, 线性收敛, Polyak-Lojasiewicz, 神经正切核

**Comment:** 

> **TL;DR:** 本文通过引入局部Polyak-Lojasiewicz区域（LPLR）并证明其在NTK稳定假设下存在于深度网络中，解释了梯度下降在深度学习中实现线性收敛的现象，弥合了理论与实践之间的差距。

**AI_Comments:** 本文创新性地引入了局部Polyak-Lojasiewicz区域（LPLR）的概念，并利用神经正切核（NTK）的稳定性，首次从理论上解释了深度神经网络中梯度下降的线性收敛现象，弥合了理论与实践之间的长期差距。其重要性在于为深度学习优化提供了更坚实的理论基础，对理解深度学习的训练效率具有深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 梯度下降在深度神经网络非凸损失景观上的收敛性是一个基本的理论挑战。现有理论表明梯度下降在局部准凸区域以次线性速率收敛，但这无法解释实践中观察到的指数级收敛速率。

**Method:** 通过证明在神经正切核（NTK）稳定性假设下，局部准凸区域满足局部Polyak-Lojasiewicz（PL）条件。引入局部Polyak-Lojasiewicz区域（LPLR）的概念，并证明了适当初始化的有限宽度网络在初始化附近存在此类区域。通过实验验证了LPLR结构在实际深度学习场景中的稳健性。

**Result:** 梯度下降在LPLR内实现线性收敛，这是首次提供与经验观察速率相匹配的有限宽度保证。LPLR结构在全连接网络和ResNet架构等多种设置中都能稳健出现。

**Conclusion:** 通过NTK框架将局部损失景观几何与快速优化严格联系起来，为深度学习中基于梯度的优化Remarkable效率提供了明确的理论解释。

> **ai_Abstract:** 本文旨在弥合梯度下降在深度神经网络中理论收敛速率（次线性）与实践中观察到的快速（指数/线性）收敛之间的差距。作者引入了局部Polyak-Lojasiewicz区域（LPLR）的概念，并证明在神经正切核（NTK）稳定性假设下，深度网络在初始化附近存在这些区域。研究表明，在LPLR内，梯度下降能够实现线性收敛，这为有限宽度网络提供了首个与经验观察相符的收敛速率保证。该理论通过在不同网络架构上的实验得到验证，证实了LPLR结构在实际深度学习场景中的普遍存在，从而为深度学习中梯度优化的效率提供了理论解释。

> **摘要翻译:** 梯度下降（GD）在深度神经网络（DNNs）非凸损失景观上的收敛性提出了一个基础的理论挑战。虽然最近的工作已经证实GD在局部准凸区域（LQCRs）内以次线性速率收敛到驻点，但这未能解释实践中一直观察到的指数级收敛速率。在本文中，我们通过证明在神经正切核（NTK）稳定性这一温和假设下，这些相同的区域满足局部Polyak-Lojasiewicz（PL）条件，从而解决了这一差异。我们引入了局部Polyak-Lojasiewicz区域（LPLR）的概念，其中梯度范数的平方下界了次优性差距，并证明了适当初始化的有限宽度网络在初始化附近存在此类区域，并确立了GD在LPLR内实现线性收敛，提供了第一个与经验观察速率相匹配的有限宽度保证。我们在各种设置中验证了我们的理论，从全连接网络上的受控实验到使用随机方法训练的现代ResNet架构，证明了LPLR结构在实际深度学习场景中稳健地出现。通过NTK框架将局部景观几何与快速优化严格连接起来，我们的工作为深度学习中基于梯度的优化Remarkable效率提供了明确的理论解释。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [799] [Extracting Interpretable Models from Tree Ensembles: Computational and Statistical Perspectives](https://arxiv.org/abs/2506.20114)
> *从树集成中提取可解释模型：计算和统计视角*

*Brian Liu, Rahul Mazumder, Peter Radchenko* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 树集成, 模型可解释性, 决策规则提取, 优化算法, 预测误差界限

**Comment:** 

> **TL;DR:** 提出一种从树集成中提取紧凑决策规则集的方法，该方法可解释、准确，并提供计算和统计保证。

**AI_Comments:** 这项工作的创新之处在于提出了一种能够灵活控制规则复杂度的估计器，并提供了严谨的理论（非渐近预测误差界限）和实验验证。它解决了树集成模型“黑箱”问题的关键挑战，对于需要模型透明度的应用领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 树集成模型虽然预测准确且能捕捉复杂交互，但难以解释，可能无法揭示数据中有用的关系。

**Method:** 提出一种估计器，用于从树集成中提取紧凑的决策规则集。该估计器能够灵活地同时控制提取规则的数量和每条规则的交互深度。开发了定制的精确算法来解决优化问题，以及近似算法来计算正则化路径。

**Result:** 提取的模型准确且可手动检查以揭示预测变量和响应之间的关系。提出的方法在预测性能上与“预言机”相当，并且在实验中优于现有规则提取算法。

**Conclusion:** 该研究提出了一种有效且可解释的方法，用于从树集成中提取决策规则，并在计算和统计上表现出色，优于现有算法。

> **ai_Abstract:** 本研究提出了一种新颖的估计器，旨在从复杂的树集成模型中提取紧凑且可解释的决策规则集。该方法通过灵活控制规则数量和交互深度来提高准确性，并开发了高效的优化算法。实验和理论分析表明，该估计器在预测性能上与最优方法相当，并优于现有规则提取算法，有效解决了树集成模型可解释性差的问题。

> **摘要翻译:** 树集成是非参数方法，因其准确性和捕捉复杂交互的能力而广受认可。虽然这些模型在预测方面表现出色，但它们难以解释，并且可能无法揭示数据中有用的关系。我们提出了一种估计器，用于从树集成中提取紧凑的决策规则集。提取的模型准确且可以手动检查，以揭示预测变量和响应之间的关系。我们估计器的一个关键新颖之处在于，它能够灵活地共同控制提取的规则数量和每条规则的交互深度，从而提高准确性。我们开发了一种定制的精确算法来有效解决我们估计器底层的优化问题，并开发了一种近似算法来计算正则化路径，即对应不同模型大小的解序列。我们还为我们提出的方法建立了新颖的非渐近预测误差界限，并将其与在相同复杂性约束下选择集成中规则的最佳数据依赖线性组合的预言机进行比较。这些界限表明，我们估计器的大样本预测性能与预言机相当。通过实验，我们证明我们的估计器优于现有的规则提取算法。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [818] [Measuring Sample Quality with Copula Discrepancies](https://arxiv.org/abs/2507.21434)
> *测量样本质量与Copula差异*

*Agnideep Aich, Ashit Baran Aich, Bruce Wade* | **Category: stat.ML, cs.LG, 62H05, 62H12, 65C05, 68T05** | **Updated: 2025-07-29**

**Keywords:** Copula Discrepancy, Sample Quality, MCMC, Dependence Structure, Approximate Inference

**Comment:** 

> **TL;DR:** 针对偏置MCMC采样器中传统样本质量度量失效的问题，本文引入Copula差异（CD），一种计算高效且原理清晰的诊断方法，用于独立于边缘分布评估样本依赖结构，并在超参数选择和尾部依赖检测方面表现出色，计算开销远低于现有方法。

**AI_Comments:** 这篇论文的创新点在于提出了Copula差异（CD）作为一种新的样本质量诊断方法，特别针对现代近似推断中偏置MCMC采样器的问题。其重要性体现在能够独立于边缘分布评估和量化样本的依赖结构，填补了传统方法和现有Stein诊断的空白。CD的计算效率高，且在实际应用中（如超参数选择和尾部依赖检测）表现出色，具有重要的实用价值。它为MCMC实践者提供了急需的工具，并为未来结构感知样本质量评估奠定了理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 现代贝叶斯机器学习中的可扩展MCMC算法（如SGLD）为了计算速度牺牲了渐近精确性，导致传统样本质量度量在应用于偏置采样器时失效。虽然强大的基于Stein的诊断方法可以检测分布不匹配，但它们无法直接评估依赖结构，而依赖结构往往是多元问题中的主要推断目标。

**Method:** 本文引入了Copula差异（CD），这是一种利用Sklar定理来隔离和量化样本依赖结构保真度（独立于其边缘分布）的诊断方法。理论框架提供了第一个专门为近似推断时代设计的结构感知诊断。经验上，展示了基于矩的CD在偏置MCMC的超参数选择中优于标准诊断方法（如有效样本量），并且鲁棒的基于MLE的变体可以检测尾部依赖中微妙但关键的不匹配。

**Result:** 基于矩的CD在偏置MCMC的超参数选择中显著优于传统诊断方法（如有效样本量），能够正确识别最佳配置。鲁棒的基于MLE的CD变体可以检测到尾部依赖中微妙但关键的不匹配，这些不匹配对于基于秩相关的方法是不可见的，能够区分具有相同Kendall's tau但根本上不同的极端事件行为的样本。CD的计算开销比现有Stein差异低几个数量级。

**Conclusion:** Copula差异（CD）为MCMC实践者提供了直接的实用价值，并为下一代结构感知样本质量评估奠定了理论基础。它解决了传统方法在偏置采样器中失效以及Stein方法无法评估依赖结构的问题。

> **ai_Abstract:** 本文提出Copula差异（CD），一种新型的样本质量诊断工具，旨在解决偏置MCMC算法中传统度量失效以及现有Stein诊断无法评估依赖结构的问题。CD利用Sklar定理独立于边缘分布量化样本的依赖结构。实验证明，CD在MCMC超参数选择和检测尾部依赖方面表现优异，且计算效率高，为近似推断时代的样本质量评估提供了新的有效方法。

> **摘要翻译:** 现代贝叶斯机器学习中支撑可扩展马尔可夫链蒙特卡洛（MCMC）算法，例如随机梯度朗之万动力学（SGLD），为了计算速度牺牲了渐近精确性，从而产生了一个关键的诊断空白：当应用于偏置采样器时，传统的样本质量度量会彻底失效。虽然强大的基于Stein的诊断方法可以检测分布不匹配，但它们无法直接评估依赖结构，而依赖结构往往是多元问题中的主要推断目标。我们引入了Copula差异（CD），这是一种原理清晰且计算高效的诊断方法，它利用Sklar定理来隔离和量化样本依赖结构的保真度，独立于其边缘分布。我们的理论框架提供了第一个专门为近似推断时代设计的结构感知诊断。经验上，我们证明了基于矩的CD在偏置MCMC的超参数选择中显著优于标准诊断方法（如有效样本量），能够正确识别传统方法失效的最佳配置。此外，我们鲁棒的基于MLE的变体可以检测到尾部依赖中微妙但关键的不匹配，这些不匹配对于基于秩相关的方法是不可见的，能够区分具有相同Kendall's tau但根本上不同的极端事件行为的样本。CD的计算开销比现有Stein差异低几个数量级，为MCMC实践者提供了直接的实用价值，并为下一代结构感知样本质量评估奠定了理论基础。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [853] [From Global to Local: A Scalable Benchmark for Local Posterior Sampling](https://arxiv.org/abs/2507.21449)
> *从全局到局部：一个可扩展的局部后验采样基准*

*Rohan Hitchcock, Jesse Hoogland* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-29**

**Keywords:** SGMCMC, 局部后验采样, 退化, 神经网络, 基准

**Comment:** 25 pages

> **TL;DR:** 本文提出了一种新的可扩展基准，用于评估随机梯度MCMC（SGMCMC）算法的局部采样性能，并发现RMSProp预处理的SGLD在表示后验分布的局部几何方面最有效。

**AI_Comments:** 本文的创新点在于提出了将随机梯度MCMC（SGMCMC）算法的研究重点从全局收敛性转向局部采样性能，并为此构建了一个实用的可扩展基准。这对于理解和改进SGMCMC在神经网络等复杂退化损失景观中的应用具有重要意义。尽管缺乏全局理论保证是一个局限性，但其经验结果证明了在大型模型中获取局部信息的有效性，为未来的研究提供了新的方向和工具。

<details>
  <summary>Details</summary>

**Motivation:** 神经网络损失景观的退化是一个固有特征，但目前尚不清楚随机梯度MCMC（SGMCMC）算法如何与这种退化相互作用。当前的SGMCMC算法的全局收敛性保证依赖的假设可能与退化的损失景观不兼容。因此，需要将重点从全局后验采样转向局部后验采样。

**Method:** 引入了一种新颖的可扩展基准，用于评估SGMCMC算法的局部采样性能。该方法对多种常见算法进行了评估。

**Result:** RMSProp预处理的SGLD在忠实地表示后验分布的局部几何方面最有效。尽管缺乏关于全局采样器收敛性的理论保证，但经验结果表明，能够在具有高达O(100M)参数的模型中提取出非平凡的局部信息。

**Conclusion:** 尽管缺乏全局采样器收敛性的理论保证，但通过引入新的局部采样基准和实证评估，证明了在大型模型中提取非平凡局部信息的能力，并发现RMSProp预处理的SGLD表现最佳。

> **ai_Abstract:** 本文针对SGMCMC算法在神经网络退化损失景观中的表现问题，指出现有全局收敛性保证的局限性。为解决这一问题，作者提出将研究重点转向局部后验采样，并为此开发了一个可扩展的新型基准。通过对多种SGMCMC算法的评估，研究发现RMSProp预处理的SGLD在准确表示后验分布的局部几何方面表现最佳。尽管缺乏全局收敛的理论保证，但实验证明该方法能够从亿级参数模型中提取有价值的局部信息。

> **摘要翻译:** 退化是神经网络损失景观的一个固有特征，但随机梯度MCMC（SGMCMC）算法如何与这种退化相互作用尚不清楚。特别是，当前常见SGMCMC算法的全局收敛性保证依赖的假设可能与退化的损失景观不兼容。在本文中，我们认为这一差距需要将重点从全局后验采样转向局部后验采样，作为第一步，我们引入了一种新颖的可扩展基准，用于评估SGMCMC算法的局部采样性能。我们评估了许多常见算法，发现RMSProp预处理的SGLD在忠实地表示后验分布的局部几何方面最有效。尽管我们缺乏关于全局采样器收敛性的理论保证，但我们的经验结果表明，我们能够在具有高达O(100M)参数的模型中提取出非平凡的局部信息。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [888] [Stochastic forest transition model dynamics and parameter estimation via deep learning](https://arxiv.org/abs/2507.21486)
> *随机森林转型模型动力学与基于深度学习的参数估计*

*Satoshi Kumabe, Tianyu Song, Ton Viet Ta* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 森林转型, 随机微分方程, 深度学习, 参数估计, 土地利用变化

**Comment:** 

> **TL;DR:** 本研究开发了一个随机微分方程模型来描述森林转型，并提出了一种新的深度学习方法来估计模型参数，从而理解森林转型动态和预测未来趋势。

**AI_Comments:** 该研究的创新点在于结合了随机微分方程模型来模拟复杂的森林转型动态，并开创性地使用深度学习技术解决了模型参数估计的难题。这种方法有望提高森林转型预测的准确性和效率，对森林管理和政策制定具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 森林转型（森林、农业用地和废弃地之间的动态转变）是一个复杂现象，需要深入理解其动力学。

**Method:** 研究开发了一个随机微分方程模型来捕捉森林转型的复杂动力学。为了解决参数估计的挑战，提出了一种新颖的深度学习方法，该方法可以从包含森林和农业用地比例时间序列观测的单个样本中估计所有模型参数。

**Result:** 模型建立了全局正解的存在性，并通过数值分析评估了模型参数对砍伐森林激励的影响。提出的深度学习方法能够从单个时间序列样本中估计所有模型参数。

**Conclusion:** 这种创新方法使我们能够理解森林转型动力学和任何未来时间的森林砍伐趋势。

> **ai_Abstract:** 本文开发了一个随机微分方程模型来描述森林、农业和废弃土地之间的复杂转型动态。为解决模型参数估计难题，研究提出了一种创新的深度学习方法，能够仅通过单个时间序列样本估算出所有模型参数。该方法有助于理解森林转型动态并预测未来的森林砍伐趋势。

> **摘要翻译:** 森林转型，以森林、农业和废弃土地之间的动态转变为特征，是复杂的现象。本研究开发了一个随机微分方程模型来捕捉这些转型的复杂动力学。我们建立了模型全局正解的存在性，并进行了数值分析以评估模型参数对森林砍伐激励的影响。为了解决参数估计的挑战，我们提出了一种新颖的深度学习方法，该方法可以从包含森林和农业土地比例时间序列观测的单个样本中估计所有模型参数。这种创新方法使我们能够理解森林转型动力学和任何未来时间的森林砍伐趋势。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [103] [diffSPH: Differentiable Smoothed Particle Hydrodynamics for Adjoint Optimization and Machine Learning](https://arxiv.org/abs/2507.21684)
> *diffSPH：用于伴随优化和机器学习的可微分光滑粒子流体动力学*

*Rene Winchenbach, Nils Thuerey* | **Category: physics.flu-dyn, cs.AI, cs.LG, I.2.0; I.6.0; G.1.4** | **Updated: 2025-07-29**

**Keywords:** diffSPH, 可微分SPH, 计算流体动力学, 伴随优化, 机器学习

**Comment:** 

> **TL;DR:** diffSPH是一个基于PyTorch的开源可微分光滑粒子流体动力学（SPH）框架，旨在促进计算流体动力学（CFD）中的优化和机器学习应用。

**AI_Comments:** diffSPH的创新之处在于其将光滑粒子流体动力学（SPH）与可微分编程相结合，并基于PyTorch实现，从而能够利用GPU加速进行高效计算。这使得在计算流体动力学（CFD）领域应用伴随优化和机器学习成为可能，解决了传统求解器中难以处理的优化问题（如粒子偏移）。该框架为CFD社区提供了一个强大的工具，有望推动该领域在数据驱动模拟和逆问题解决方面的发展。其开源、可读性、可用性和可扩展性也为其广泛采用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在开发一个可微分的光滑粒子流体动力学（SPH）框架，以促进计算流体动力学（CFD）中的优化和机器学习应用，包括训练神经网络和开发混合模型。

**Method:** 本文提出了diffSPH，一个全新的开源可微分光滑粒子流体动力学（SPH）框架，完全基于PyTorch开发并支持GPU加速。该框架围绕微分设计，支持可压缩（带激波捕获和多相流）、弱可压缩（带边界处理和自由表面流）以及不可压缩物理方案。它通过最小化物理和正则化损失项，采用新颖的目标导向方法来解决粒子偏移问题。

**Result:** diffSPH框架通过多项应用展示了其独特的能力，包括通过新颖的目标导向方法解决粒子偏移问题（传统求解器中通常难以解决），优化初始条件和物理参数以匹配目标轨迹，进行形状优化，实现求解器在环设置以模拟高阶积分，以及演示了通过数百个完整模拟步骤的梯度传播。

**Conclusion:** 这项工作为计算流体动力学（CFD）社区提供了一个基础平台，用于开发和部署新型神经网络和伴随优化应用，同时优先考虑了可读性、可用性和可扩展性。

> **ai_Abstract:** diffSPH是一个基于PyTorch并支持GPU加速的开源可微分光滑粒子流体动力学（SPH）框架。它专为计算流体动力学（CFD）中的优化和机器学习应用而设计，包括神经网络训练和混合模型开发。该框架支持多种流体物理方案，并能有效解决粒子偏移等挑战。通过优化初始条件、形状优化和梯度传播等应用，diffSPH为CFD社区提供了开发和部署新颖神经网络和伴随优化应用的基础平台。

> **摘要翻译:** 我们提出了diffSPH，一个全新的开源可微分光滑粒子流体动力学（SPH）框架，完全在PyTorch中开发并支持GPU加速。diffSPH的核心设计围绕微分，旨在促进计算流体动力学（CFD）中的优化和机器学习（ML）应用，包括训练神经网络和开发混合模型。其可微分的SPH核心以及针对可压缩（带激波捕获和多相流）、弱可压缩（带边界处理和自由表面流）和不可压缩物理的方案，使其能够应用于广泛的领域。我们通过多个应用展示了该框架的独特能力，包括通过一种新颖的、目标导向的方法最小化物理和正则化损失项来解决粒子偏移问题，这在传统求解器中通常难以处理。其他示例包括优化初始条件和物理参数以匹配目标轨迹、形状优化、实现求解器在环设置以模拟高阶积分，以及演示通过数百个完整模拟步骤的梯度传播。这项工作优先考虑了可读性、可用性和可扩展性，为CFD社区开发和部署新型神经网络和伴随优化应用提供了一个基础平台。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [130] [Robust Capacity Expansion Modelling for Renewable Energy Systems under Weather Uncertainty](https://arxiv.org/abs/2504.06750)
> *恶劣天气不确定性下可再生能源系统鲁棒容量扩展建模*

*Sebastian Kebrich, Felix Engelhardt, David Franzmann, Christina Büsing, Jochen Linßen, Heidi Heinrichs* | **Category: math.OC, cs.SY, eess.SY, 90C10, 90C15, 90C90, I.6** | **Updated: 2025-07-29**

**Keywords:** 可再生能源系统, 容量扩展规划, 天气不确定性, 迭代算法, 供电安全

**Comment:** 

> **TL;DR:** 提出一种迭代算法，用于在天气不确定性下进行可再生能源系统容量扩展规划，以确保在所有天气年份下的供电安全，成本略有增加。

**AI_Comments:** 这篇论文的创新点在于提出了一个迭代优化算法来解决可再生能源系统在面对多变天气条件下的容量扩展问题，特别是考虑了“黑暗无风期”等极端情况。其重要性在于为未来以可再生能源为主导的电网规划提供了更鲁棒的解决方案，有助于提高电网的可靠性和韧性。通过量化成本增加，也为决策者提供了具体的参考。

<details>
  <summary>Details</summary>

**Motivation:** 未来温室气体中性能源系统将由受不确定天气条件影响的可再生能源技术主导，需要解决天气不确定性下的容量扩展规划问题。

**Method:** 本文提出了一种迭代算法，用于在天气不确定性下进行容量扩展规划（CAPEX）。该算法在面对多个可能的天气年份时，评估基于单一年份数据得出的CAPEX解决方案的质量，并在检测到供应缺口时迭代修改CAPEX优化问题。这些修改旨在获得具有足够备用容量以克服（寒冷）黑暗无风期以及在所有年份中提供足够年度总能源供应的解决方案。

**Result:** 在德国能源系统模型上的计算研究表明，该迭代算法找到的解决方案能够保证所有考虑天气年份的供电安全，与初始解决方案相比，总年度成本增加了1.6-2.9%。结果还强调了使用非典型时间序列（包括黑暗无风期和寒冷期效应）评估能源系统模型可行性的重要性。

**Conclusion:** 该迭代算法能够有效地在天气不确定性下进行可再生能源系统的容量扩展规划，以确保供电安全，且成本增加幅度可控。同时，强调了在能源系统模型评估中考虑极端天气事件的重要性。

> **ai_Abstract:** 本文提出了一种迭代算法，用于在天气不确定性下对可再生能源系统进行鲁棒的容量扩展规划。该算法通过迭代修改优化问题来解决由单一天气年份数据带来的供应缺口问题，从而确保在多种天气情景下（包括极端寒冷和无风期）的供电安全。在德国能源系统的案例研究表明，该方法能在总成本略微增加（1.6-2.9%）的情况下显著提高供电可靠性，并强调了考虑非典型天气模式的重要性。

> **摘要翻译:** 未来的温室气体中性能源系统将由可再生能源技术主导，其能源输出受不确定的天气条件影响。这项工作提出了一种在天气不确定性下进行容量扩展规划（CAPEX）的算法。当面对多个可能的天气年份时，评估基于单一年份数据得出的CAPEX解决方案的质量，并在所有年份中进行评估，当检测到供应缺口时，迭代修改CAPEX优化问题。这些修改会产生具有足够备用容量的解决方案，以克服（寒冷）黑暗无风期，并在所有年份中提供足够的年度总能源供应。对德国能源系统模型进行的计算研究表明，与初始解决方案相比，该迭代算法找到的解决方案能够保证所有考虑天气年份的供电安全，总年度成本增加了1.6-2.9%。结果还强调了使用非典型时间序列（包括黑暗无风期和寒冷期效应）评估能源系统模型可行性的重要性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [236] [Riemannian Optimization on Tree Tensor Networks with Application in Machine Learning](https://arxiv.org/abs/2507.21726)
> *黎曼优化在树张量网络中的机器学习应用*

*Marius Willner, Marco Trenti, Dirk Lebiedz* | **Category: math.OC, cond-mat.other, cs.LG, 15A69, 53C20, 65K10** | **Updated: 2025-07-29**

**Keywords:** 树张量网络, 黎曼优化, 微分几何, 机器学习, 核学习

**Comment:** 24 pages, 6 figures, 4 pseudo-code algorithms, 1 table

> **TL;DR:** 本文对树张量网络（TTN）的微分几何进行了形式分析，并开发了利用其内在商结构的黎曼优化算法和用于核学习的BP算法，通过机器学习任务验证了方法的有效性。

**AI_Comments:** 本文的创新点在于首次对树张量网络的微分几何进行了形式分析，并基于此提出了针对其内在商结构的高效黎曼优化算法，以及在核学习背景下的反向传播算法。这为TTNs的优化和在机器学习领域的应用提供了坚实的理论基础和实用的算法工具。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于树张量网络（TTNs）在低秩近似和量子多体模拟中的广泛应用，本文旨在对TTNs的微分几何进行形式分析，并在此基础上开发高效的优化算法。

**Method:** 本文首先对树张量网络（TTNs）的微分几何进行了形式分析。在此基础上，开发了利用TTNs内在商结构的高效一阶和二阶优化算法。此外，还设计了一种用于在核学习设置中训练TTNs的反向传播算法。

**Result:** 通过在代表性的机器学习任务上的数值实验，验证了所提出方法的有效性。

**Conclusion:** 本文提出的基于微分几何的黎曼优化和反向传播算法能够有效地优化树张量网络，并在机器学习任务中表现出良好的性能。

> **ai_Abstract:** 本文深入分析了树张量网络（TTNs）的微分几何结构，并基于此开发了高效的一阶和二阶黎曼优化算法。同时，提出了一种适用于核学习环境的TTN反向传播训练算法。所有方法均通过在机器学习任务中的数值实验得到了验证。

> **摘要翻译:** 树张量网络（TTNs）广泛应用于低秩近似和量子多体模拟。在这项工作中，我们对TTNs底层的微分几何进行了形式分析。在此基础上，我们开发了利用TTNs内在商结构的高效一阶和二阶优化算法。此外，我们还设计了一种用于在核学习设置中训练TTNs的反向传播算法。我们通过在代表性的机器学习任务上的数值实验验证了我们的方法。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [314] [Free-Gate: Planning, Control And Policy Composition via Free Energy Gating](https://arxiv.org/abs/2412.06636)
> *Free-Gate：基于自由能门控的规划、控制与策略组合*

*Francesca Rossi, Émiland Garrabé, Giovanni Russo* | **Category: math.OC, cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-30**

**Keywords:** Free-Gate, 策略组合, 自由能, 最优控制, 机器人导航

**Comment:** 15 pages, 2 figures

> **TL;DR:** Free-Gate通过自由能门控机制优化组合控制原语，解决复杂规划与控制任务。

**AI_Comments:** Free-Gate的创新之处在于其将策略组合问题转化为一个凸的自由能最小化问题，即使在复杂的非凸和非线性环境下也能保持凸性，这大大简化了优化。其重要性在于能够通过组合简单的原语实现复杂的行为，为机器人规划和控制提供了新的有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决如何最优地组合一组基本原语来应对规划和控制任务的问题。

**Method:** 本文提出了一种名为Free-Gate的自由能计算模型，用于通过策略组合进行规划和控制。该模型通过最小化变分自由能的门控机制来组合控制原语。这个问题被表述为一个有限视界最优控制问题，并且被证明即使在状态/动作成本非凸、环境非线性、随机且非平稳的情况下，该问题仍然是凸的。作者开发了一种算法来计算最优的原语组合。

**Result:** 通过在有障碍物环境中的机器人导航应用的计算机模拟和硬件实验，证明了Free-Gate的有效性。实验结果表明，尽管机器人只拥有单独无法完成任务的简单运动原语，Free-Gate仍能使其成功导航到目的地。

**Conclusion:** Free-Gate能够有效地组合简单的控制原语，以实现单独原语无法完成的复杂规划和控制任务。

> **ai_Abstract:** Free-Gate是一个基于自由能门控的计算模型，用于通过最优组合控制原语来解决复杂的规划和控制任务。该方法将组合问题建模为凸的有限视界最优控制，即使在非凸成本和复杂环境下也成立。实验证明，Free-Gate能使机器人利用简单的运动原语成功完成复杂的导航任务。

> **摘要翻译:** 我们考虑了最优组合一组原语来解决规划和控制任务的问题。为了解决这个问题，我们引入了一种通过策略组合进行规划和控制的自由能计算模型：Free-Gate。在Free-Gate中，控制原语通过最小化变分自由能的门控机制进行组合。这种组合问题被表述为一个有限视界最优控制问题，我们证明即使成本在状态/动作上不是凸的，并且环境是非线性、随机和非平稳的，该问题仍然是凸的。我们开发了一种算法来计算最优原语组合，并通过在有障碍物环境中的机器人导航应用的计算机模拟和硬件实验证明了其有效性。实验突出表明，尽管机器人只有单独无法完成任务的简单运动原语，Free-Gate仍能使其导航到目的地。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [349] [Coordinated vehicle dispatching and charging scheduling for an electric ride-hailing fleet under charging congestion and dynamic prices](https://arxiv.org/abs/2412.09978)
> *充电拥堵和动态价格下电动网约车队的车队调度与充电调度协同*

*Tai-Yu Ma, Richard D. Connors, Francesco Viti* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-30**

**Keywords:** 电动网约车队, 充电调度, 充电拥堵, 动态价格, 混合整数线性规划

**Comment:** 

> **TL;DR:** 本研究开发了一种名为CongestionAware的动态充电调度方法，用于电动网约车队，旨在通过预测车辆能源需求和协调实时充电操作来避免充电站长时间等待，并在充电拥堵和动态价格下提高系统总利润。该方法在NYC黄的士数据上进行了测试，结果显示相比基准策略，利润和服务率有显著提升。

**AI_Comments:** 本论文的创新之处在于提出了一个考虑充电拥堵和动态价格的动态充电调度方法，并通过顺序混合整数线性规划模型实现了日间计划的动态调整。这解决了现有研究中对充电基础设施利用率过度乐观估计的问题，使其更贴近实际运营场景。其重要性在于为电动网约车队的运营提供了更高效、更经济的充电策略，对提升网约车系统的盈利能力和可持续发展具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究假设能源价格恒定且充电站容量无限，或未明确考虑充电站的车辆排队问题，导致对充电基础设施利用率的过度乐观估计。为了有效利用充电站容量并提高电动网约车队的盈利能力，本研究旨在解决充电拥堵和动态价格下的车辆调度和充电调度问题。

**Method:** 本研究开发了一种名为CongestionAware的动态充电调度方法。该方法基于顺序混合整数线性规划模型，根据车辆经历的充电等待时间和能源消耗，制定车辆的日间充电计划。这些充电计划在一天内根据车辆的能源需求和充电站拥堵情况进行调整。该充电策略使用NYC黄的士数据在曼哈顿区域测试，车队规模为100辆，每日客户量为3000和4000。

**Result:** 计算结果表明，我们的CongestionAware策略在每日4000名客户的情况下，相比不同的基准策略，利润提高了高达15.06%，服务率提高了19.16%。

**Conclusion:** CongestionAware策略通过有效协调电动网约车队的充电调度，显著提高了系统利润和服务率，尤其是在存在充电拥堵和动态价格的情况下，证明了其在实际应用中的优越性。

> **ai_Abstract:** 本研究提出了一种名为CongestionAware的动态充电调度方法，旨在解决电动网约车队在充电拥堵和动态价格下的车辆调度和充电问题。该方法通过一个顺序混合整数线性规划模型，根据车辆的能源需求和充电站拥堵情况，制定并动态调整充电计划，以减少等待时间并提高系统利润。在纽约市出租车数据上的测试结果显示，与现有基准策略相比，该方法在利润和服务率方面均取得了显著提升。

> **摘要翻译:** 有效利用充电站容量在提高使用电动汽车的网约车系统的盈利能力方面发挥着重要作用。现有研究假设能源价格恒定且充电站容量无限，或未明确考虑充电站的车辆排队问题，导致对充电基础设施利用率的过度乐观估计。在本研究中，我们开发了一种动态充电调度方法（命名为CongestionAware），该方法预测车辆的能源需求并协调其充电操作与实时能源价格，以避免在充电站长时间等待并增加系统的总利润。提出了一种顺序混合整数线性规划模型，根据车辆经历的充电等待时间和能源消耗来制定车辆的日间充电计划。获得的充电计划在一天内根据车辆的能源需求和充电站拥堵情况进行调整。所开发的充电策略使用纽约市黄色出租车数据在曼哈顿区域进行测试，车队规模为100辆，每天客户量分别为3000和4000。计算结果表明，我们的CongestionAware策略在每天4000名客户的情况下，相比不同的基准策略，利润提高了高达+15.06%，服务率提高了+19.16%。对不同的系统参数进行了敏感性分析，并讨论了管理见解。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [413] [Distributionally Robust LQG with Kullback-Leibler Ambiguity Sets](https://arxiv.org/abs/2505.08370)
> *基于Kullback-Leibler模糊集的分布鲁棒LQG*

*Marta Fochesato, Lucia Falconi, Mattia Zorzi, Augusto Ferrante, John Lygeros* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-30**

**Keywords:** 分布鲁棒优化, LQG控制器, Kullback-Leibler模糊集, 线性控制, 模型不确定性

**Comment:** 

> **TL;DR:** 本文提出了一种针对过程和测量噪声分布不确定性的分布鲁棒LQG控制器，其最优控制策略仍为线性，并提供了一个可收敛的计算方案。

**AI_Comments:** 本文在LQG控制器的鲁棒性方面做出了重要贡献，通过引入分布鲁棒优化和Kullback-Leibler模糊集，有效解决了模型不确定性问题。其创新点在于证明了鲁棒控制器仍保持线性结构，并提供了可行的计算方法，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 标准线性二次高斯 (LQG) 控制器对现实世界中常见的模型误差具有固有的脆弱性。

**Method:** 本文对离散时间部分可观测随机线性系统进行了鲁棒化处理，以应对过程和测量噪声的分布不确定性。其分布鲁棒公式通过为有限视野轨迹的每个时间步单独定义基于相对熵的模糊集来指定允许的扰动，并最小化所有允许分布下的最坏情况成本。对于内生不确定性，提出了一种基于动态规划的近似方案。

**Result:** 结果表明，最优控制策略仍然是线性的，与标准LQG相同。推导出了一个基于迭代最佳响应的计算方案，该方案被证明可收敛到鞍点集。

**Conclusion:** 本文成功地提出了一个分布鲁棒LQG控制器，能够有效应对模型不确定性，并证明了其最优策略的线性性质和计算方案的收敛性。

> **ai_Abstract:** 本文针对标准LQG控制器在模型误差下的脆弱性问题，提出了一种分布鲁棒LQG控制器。该控制器考虑离散时间部分可观测随机线性系统，通过定义基于相对熵的模糊集来处理过程和测量噪声的分布不确定性，并最小化最坏情况成本。研究表明，最优控制策略仍为线性，并提供了一个基于迭代最佳响应的计算方案，该方案被证明收敛。此外，还探讨了内生不确定性，并提出了基于动态规划的近似方法。

> **摘要翻译:** 线性二次高斯 (LQG) 控制器已知对现实世界中常见的模型误差具有固有的脆弱性。我们考虑离散时间部分可观测随机线性系统，并提供了一种针对过程和测量噪声分布不确定性的标准LQG鲁棒化方法。我们的分布鲁棒公式通过为有限视野轨迹的每个时间步单独定义基于相对熵的模糊集来指定允许的扰动，并最小化所有允许分布下的最坏情况成本。我们证明了最优控制策略仍然是线性的，与标准LQG相同，并推导出了一个基于迭代最佳响应的计算方案，该方案被证明可收敛到鞍点集。最后，我们考虑通过依赖于决策的模糊集捕获的内生不确定性情况，并提出了一种基于动态规划的近似方案。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [513] [Sliding Mode Control for Uncertain Systems with Time-Varying Delays via Predictor Feedback and Super-Twisting Observer](https://arxiv.org/abs/2507.21281)
> *基于预测器反馈和超扭曲观测器的不确定时变延迟系统滑模控制*

*Hardy Pinto, Tiago Roux Oliveira, Liu Hsu* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-28**

**Keywords:** 滑模控制, 时变延迟, 预测器反馈, 超扭曲观测器, 不确定系统

**Comment:** 15 pages, 8 figures

> **TL;DR:** 本文提出了一种结合预测器反馈和超扭曲观测器的新型滑模控制策略，用于稳定具有时变延迟和未知扰动的不确定系统。

**AI_Comments:** 该论文的创新之处在于将预测器反馈与超扭曲观测器相结合，并应用于滑模控制框架中，以解决同时存在时变延迟、未知扰动和部分状态不可测量的复杂系统。超扭曲算法的运用显著增强了系统对参数不确定性的鲁棒性，并能在无需先验知识的情况下重建故障信号，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为受已知时变测量延迟、匹配未知非线性扰动（可能包括执行器故障）以及部分状态不可实时测量的线性时不变系统，提供一种新的稳定控制策略。

**Method:** 该方法结合了开环预测器和基于超扭曲算法设计的状态观测器，以补偿延迟并估计未测量的状态分量。在此基础上，制定了滑模控制律，以实现理想滑模并确保全局稳定。

**Result:** 数值模拟结果表明了所提出方法的有效性。

**Conclusion:** 由于集成了超扭曲观测器，所提出的滑模控制律能够对更广泛的扰动、未建模扰动、参数不确定性和延迟实现全局稳定。

> **ai_Abstract:** 本文提出了一种新颖的稳定控制策略，用于处理具有已知时变测量延迟、匹配未知非线性扰动（包括执行器故障）且部分状态不可测量的线性时不变系统。该方法结合了开环预测器以补偿延迟，以及基于超扭曲算法的状态观测器以估计未测状态并重建故障信号。在此基础上，设计了滑模控制律，利用超扭曲观测器的集成，确保了系统在广泛扰动、不确定性和延迟下的全局稳定性和鲁棒性。数值模拟验证了该方法的有效性。

> **摘要翻译:** 本文介绍了一种用于线性时不变系统的新型稳定控制策略，该系统受到已知时变测量延迟和匹配的未知非线性扰动（可能包括执行器故障）的影响。考虑到部分状态向量无法进行实时测量。为了解决这个问题，所提出的方法将开环预测器与使用超扭曲算法设计的状态观测器相结合，旨在补偿延迟并估计未测量的状态分量。具体而言，基于非线性观测器的框架能够重建未建模的故障信号，而无需假设它们源自已知的外部系统，从而提供了对参数不确定性的鲁棒性。同时，预测器及时转发延迟输出。随后，由于超扭曲观测器的集成，制定了滑模控制律，以强制执行理想的滑模并确保全局稳定，即使在更广泛的扰动、未建模扰动、参数不确定性和延迟下也是如此。数值模拟说明了所提出方法的效率。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [572] [On Policy Stochasticity in Mutual Information Optimal Control of Linear Systems](https://arxiv.org/abs/2507.21543)
> *线性系统互信息最优控制中的策略随机性*

*Shoju Enami, Kenji Kashima* | **Category: math.OC, cs.LG, cs.SY, eess.SY** | **Updated: 2025-07-29**

**Keywords:** 互信息最优控制, 策略随机性, 温度参数, 线性系统, 最优控制

**Comment:** 17 pages

> **TL;DR:** 本文研究了互信息最优控制中温度参数与策略随机性之间的关系，并推导了使策略随机或确定性的条件。

**AI_Comments:** 这项研究通过理论分析和数值验证，填补了互信息最优控制领域中温度参数与策略随机性关系理解的空白，对于深入理解和应用互信息最优控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 最大熵最优控制中温度参数与策略随机性的关系已明确，但在互信息最优控制中，这一关系仍未被探索，因此有必要进行理论澄清。

**Method:** 本文扩展了互信息最优控制问题(MIOCP)的现有研究，建立了MIOCP最优策略的存在性，并推导了使最优策略及交替优化算法获得的策略变为随机或确定性的温度参数条件。通过数值实验验证了理论结果的有效性。

**Result:** 成功推导了在不同温度参数下，互信息最优控制中最优策略以及通过交替优化算法获得的策略变为随机或确定性的条件。

**Conclusion:** 本文澄清了互信息最优控制中温度参数与策略随机性之间的关键关系，为该领域的理论发展提供了重要基础。

> **ai_Abstract:** 本文研究了离散时间线性系统互信息最优控制中温度参数与策略随机性之间的关系。文章扩展了现有研究，建立了最优策略的存在性，并详细推导了在不同温度参数下，最优策略以及由交替优化算法得到的策略从随机性到确定性转变的条件。这些理论发现通过数值实验得到了验证。

> **摘要翻译:** 近年来，互信息最优控制被提出作为最大熵最优控制的扩展。这两种方法都引入了正则化项以使策略具有随机性，并且从理论上阐明温度参数（即正则化项的系数）与策略随机性之间的关系非常重要。与最大熵最优控制不同，这种关系在互信息最优控制中尚未被探索。在本文中，我们研究了离散时间线性系统互信息最优控制问题（MIOCP）的这种关系。在扩展了MIOCP先前研究的结果之后，我们建立了MIOCP最优策略的存在性，然后推导了使最优策略变为随机和确定性的相应温度参数条件。此外，我们还推导了使通过交替优化算法获得的策略变为随机和确定性的相应温度参数条件。理论结果的有效性通过数值实验得到了证明。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [628] [Adaptive Benders decomposition and enhanced SDDP for multistage stochastic programs with block-separable multistage recourse](https://arxiv.org/abs/2507.21624)
> *自适应Benders分解和增强型SDDP用于具有块可分离多阶段追索权的多阶段随机规划*

*Nicolò Mazzi, Ken Mckinnon, Hongyu Zhang* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-29**

**Keywords:** 多阶段随机规划, 自适应Benders分解, 增强型SDDP, 块可分离追索权, 电力系统规划

**Comment:** 

> **TL;DR:** 提出了一种结合自适应Benders分解和增强型SDDP的算法，用于高效解决具有块可分离多阶段追索权的多阶段随机规划问题。

**AI_Comments:** 本文的创新之处在于首次提出了解决具有块可分离多阶段随机规划问题的算法，这填补了该领域的空白。通过结合自适应Benders分解和增强型SDDP，提高了复杂随机规划问题的求解效率和收敛性。在电力系统投资规划中的应用也展示了其重要的实际价值，特别是强调了随机性在决策中的作用。

<details>
  <summary>Details</summary>

**Motivation:** 解决具有块可分离多阶段追索权的多阶段随机规划问题，其中每个追索权问题本身也是一个具有阶段独立不确定性的多阶段随机规划，并提高求解效率。

**Method:** 算法首先使用自适应Benders分解将完整问题分解为简化主问题和子问题。然后，子问题通过增强型SDDP求解。增强包括：(1) 每次迭代的有效界限，(2) 路径探索规则，(3) 子问题之间的切割共享，以及 (4) 保证的$\delta$-最优收敛。子问题的切割通过调用自适应预言机进行共享。

**Result:** 案例研究结果表明：(1) 所提出的算法可以有效解决这类问题；(2) 确定性风力建模低估了目标函数；(3) 风力随机建模导致了不同的投资决策。

**Conclusion:** 本文的主要贡献是首次提出了解决这类问题（具有块可分离多阶段追索权的多阶段随机规划）的算法。

> **ai_Abstract:** 本文提出了一种新颖的算法，用于高效求解具有块可分离多阶段追索权的多阶段随机规划问题。该算法结合了自适应Benders分解来分解问题，并使用增强型SDDP来求解子问题，其中SDDP的增强功能包括有效界限、路径探索、切割共享和保证收敛性。研究通过一个电力系统投资规划案例证明了算法的有效性，并指出随机风力建模对于投资决策的重要性。

> **摘要翻译:** 本文提出了一种算法，用于高效解决具有块可分离追索权的多阶段随机规划问题，其中每个追索权问题都是一个具有阶段独立不确定性的多阶段随机规划。该算法首先使用自适应Benders分解将完整问题分解为简化主问题和子问题。然后，子问题通过增强型SDDP求解。增强包括：(1) 每次迭代的有效界限，(2) 路径探索规则，(3) 子问题之间的切割共享，以及 (4) 保证的$\delta$-最优收敛。子问题的切割通过调用自适应预言机进行共享。本文的关键贡献是首次提出了解决这类问题的算法。该算法在具有多时间尺度不确定性的电力系统投资规划问题上进行了演示。案例研究结果表明：(1) 所提出的算法可以有效解决这类问题；(2) 确定性风力建模低估了目标函数；(3) 风力随机建模导致了不同的投资决策。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [832] [Modified Smith predictor for unstable linear systems](https://arxiv.org/abs/2507.22243)
> *针对不稳定线性系统的改进史密斯预测器*

*Anton Pyrkin, Konstantin Kalinin* | **Category: math.OC, cs.RO, cs.SY, eess.SY, math.DS** | **Updated: 2025-07-29**

**Keywords:** 史密斯预测器, 不稳定系统, 输入延迟, 控制算法, 系统稳定性

**Comment:** in Russian language

> **TL;DR:** 提出了一种针对输入延迟不稳定线性系统的新型改进史密斯预测器控制算法，该算法易于实现，并能有效稳定系统。

**AI_Comments:** 该论文的创新点在于提出了一种易于实现且无需复杂积分方法的改进史密斯预测器，解决了传统史密斯预测器在不稳定系统和延迟系统中的应用复杂性问题。其重要性在于提供了一种有效且实用的控制策略，对于工业控制领域具有潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决具有输入延迟的不稳定线性系统的控制问题，并提供一种比现有方法更简单易实现的控制算法。

**Method:** 设计了一种对史密斯预测器进行修改的控制律，该控制律无需复杂的积分方法即可实现。

**Result:** 有效解决了闭环系统的稳定性问题，确保了所有状态变量的有界性以及平衡点的指数稳定性。

**Conclusion:** 论文提出了一种针对输入延迟不稳定线性系统的新型改进史密斯预测器控制算法，该算法简单易实现，并能有效稳定系统，确保状态变量有界和平衡点指数稳定。

> **ai_Abstract:** 本文提出了一种针对具有输入延迟的不稳定线性系统的新型控制算法。该算法是对史密斯预测器的改进，其特点是实现简单，无需复杂的积分方法。结果表明，该算法能有效解决闭环系统的稳定性问题，确保所有状态变量有界，并使平衡点达到指数稳定性。

> **摘要翻译:** 这篇论文提出了一种针对具有输入延迟的不稳定线性系统的新型控制算法。与已知同类算法相比，所设计的控制律是史密斯预测器的一种改进，并且是最简单的实现方式，无需复杂的积分方法。同时，有效解决了闭环系统的稳定性问题，确保了所有状态变量的有界性以及平衡点的指数稳定性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [841] [Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control. I: Penalty Approach](https://arxiv.org/abs/2507.18114)
> *组稀疏反馈线性二次最优控制的非凸优化框架。一：罚函数方法*

*Lechen Feng, Xun Li, Yuan-Hua Ni* | **Category: math.OC, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 非凸优化, 组稀疏控制, 线性二次问题, 罚函数方法, PALM算法

**Comment:** 

> **TL;DR:** 本文提出了一个统一的非凸优化框架，用于无限时域线性二次（LQ）问题中的组稀疏反馈控制器设计。该框架通过直接处理具有组 $\ell_0$ 范数正则化的非凸优化问题，并引入了一种基于罚函数的近端交替线性化最小化（PALM）算法，实现了对组稀疏反馈增益的直接设计，并提供了理论收敛保证。

**AI_Comments:** 该论文的创新之处在于直接处理了组稀疏控制中的非凸优化问题，通过引入组 $\ell_0$ 范数正则化和基于罚函数的PALM算法，并提供了严格的理论收敛保证。这显著优于依赖凸松弛或受限于结构假设的现有方法，为大规模系统的稀疏控制设计提供了更直接和可靠的途径。

<details>
  <summary>Details</summary>

**Motivation:** 在大规模系统中实现可伸缩和结构感知控制的需求，尤其是在分布式线性二次（DFT-LQ）和稀疏反馈线性二次（SF-LQ）问题中。现有方法依赖凸松弛或仅限于块对角结构，存在局限性。

**Method:** 开发了一个统一的非凸优化框架，将控制器综合直接表述为具有组 $\ell_0$ 范数正则化的有限维非凸优化问题。提出了一个基于罚函数的近端交替线性化最小化（PALM）算法，并提供了严格的收敛性分析，克服了目标函数缺乏强制性的问题。建立了DFT-LQ和SF-LQ问题之间的联系，并将其纳入统一框架。

**Result:** 所提出的方法允许所有子问题都有高效的求解器，并保证全局收敛到临界点。实现了具有理论保证的组稀疏反馈增益的直接设计，无需借助凸代理或限制性结构假设。

**Conclusion:** 本文通过提供一个统一的非凸优化框架和一种鲁棒的基于罚函数的PALM算法，填补了文献中的关键空白，使得能够直接设计具有理论保证的组稀疏反馈控制器，克服了现有方法的局限性。

> **ai_Abstract:** 本文提出了一个统一的非凸优化框架，用于在无限时域线性二次（LQ）问题中设计组稀疏反馈控制器。该框架旨在解决大规模系统中可伸缩和结构感知控制的需求，通过组 $\ell_0$ 范数正则化直接将控制器综合表述为非凸优化问题，避免了传统凸松弛的局限性。文中提出了一种基于罚函数的近端交替线性化最小化（PALM）算法，并提供了严格的收敛性分析，保证了全局收敛到临界点，从而实现了具有理论保证的组稀疏反馈增益的直接设计。

> **摘要翻译:** 本文开发了一种统一的非凸优化框架，用于设计无限时域线性二次 (LQ) 问题中的组稀疏反馈控制器。我们解决了经典 LQ 问题的两个突出扩展：具有固定通信拓扑的分布式 LQ 问题 (DFT-LQ) 和稀疏反馈 LQ 问题 (SF-LQ)，两者都源于大规模系统中对可伸缩和结构感知控制的需求。与依赖凸松弛或仅限于块对角结构的现有方法不同，我们直接将控制器综合表述为具有组 $\ell_0$ 范数正则化的有限维非凸优化问题，捕获一般的稀疏模式。我们建立了 DFT-LQ 和 SF-LQ 问题之间的联系，表明两者都可以在我们统一的框架内解决。此外，我们提出了一种基于罚函数的近端交替线性化最小化 (PALM) 算法，并在温和假设下提供了严格的收敛性分析，克服了目标函数缺乏强制性的问题。所提出的方法允许所有子问题都有高效的求解器，并保证全局收敛到临界点。我们的结果填补了文献中的一个关键空白，通过直接设计具有理论保证的组稀疏反馈增益，而无需借助凸代理或限制性结构假设。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [868] [Resilient State Recovery using Prior Measurement Support Information](https://arxiv.org/abs/2507.22340)
> *基于先验测量支持信息的弹性状态恢复*

*Yu Zheng, Olugbenga Moses Anubi, Warren E. Dixon* | **Category: math.OC, cs.SY, eess.SY** | **Updated: 2025-07-30**

**Keywords:** 弹性状态恢复, 网络物理系统, 先验信息, 加权$\ell_1$观测器, 误差校正

**Comment:** To be published in SIAM Journal on Control and Optimization

> **TL;DR:** 本文通过引入数据驱动的先验信息，提高了网络物理系统状态恢复的弹性，并量化了先验信息精度与估计器弹性之间的关系。

**AI_Comments:** 本文的创新点在于引入数据驱动的先验信息来增强网络物理系统状态恢复的弹性，并通过严谨的数学分析，量化了先验信息精度对估计器弹性的影响。这为设计更鲁棒的弹性估计器提供了理论依据和实用指导，突破了传统方法50%受损率的限制，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 网络物理系统的弹性状态恢复面临通信、计算和物理层紧密耦合的独特挑战。现有方法在测量节点受损比例超过50%时，估计器的弹性受限，无法实现精确状态恢复。

**Method:** 将攻击建模为测量稀疏子集的附加对抗信号，将弹性恢复问题公式化为误差校正问题。通过引入数据驱动的先验信息来提高观测器弹性，并分析性地建立了先验信息精度与估计器弹性之间的桥梁，量化了加权$\ell_1$观测器估计误差与支持先验精度之间的关系。

**Result:** 量化了估计器弹性与先验信息精度之间的关系，为估计器的权重设计提供了指导，以实现最优弹性。

**Conclusion:** 通过整合数据驱动的先验信息，可以显著提高网络物理系统状态恢复的弹性，并且所建立的量化关系有助于设计最优弹性估计器。

> **ai_Abstract:** 本文研究了网络物理系统的弹性状态恢复问题，指出现有方法在面对超过50%测量节点受损时弹性不足。为解决此问题，作者提出通过整合数据驱动的先验信息来提高观测器弹性。研究工作建立了先验信息精度与估计器弹性之间的分析性桥梁，并通过量化加权$\ell_1$观测器估计误差与支持先验精度的关系，为实现最优弹性提供了估计器权重设计的指导。

> **摘要翻译:** 网络物理系统的弹性状态恢复由于通信、计算和系统底层物理之间的紧密耦合所带来的独特挑战而受到了广泛的研究关注。通过将攻击建模为对测量稀疏子集的附加对抗信号，这个弹性恢复问题可以被公式化为一个误差校正问题。为了实现精确的状态恢复，大多数现有结果要求受损的测量节点少于50%，这限制了估计器的弹性。在本文中，我们展示了通过整合数据驱动的先验信息可以进一步提高观测器弹性。我们提供了先验信息精度与估计器弹性之间的分析桥梁。通过量化加权$\ell_1$观测器估计误差与支持先验精度之间的关系。这种量化关系为估计器的权重设计提供了指导，以实现最优弹性。为了验证理论主张，本文提供了多项数值模拟和一个应用案例研究。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [903] [Set Invariance with Probability One for Controlled Diffusion: Score-based Approach](https://arxiv.org/abs/2507.22385)
> *受控扩散的概率为一集不变性：基于分数的方法*

*Wenqing Wang, Alexis M. H. Teter, Murat Arcak, Abhishek Halder* | **Category: math.OC, cs.LG, cs.SY, eess.SY, math.PR, stat.ME** | **Updated: 2025-07-30**

**Keywords:** 受控扩散, 集不变性, 概率为一, 分数向量场, 马尔可夫控制器

**Comment:** 

> **TL;DR:** 本文推导了受控扩散实现概率为一集不变性的充要条件，基于分数向量场，并提出了一种可验证控制器存在性的测试方法。

**AI_Comments:** 本文为受控扩散的概率为一集不变性这一基础控制理论问题提供了严谨的数学框架（充要条件）。其“基于分数的方法”是一个新颖的视角，将其与对数似然梯度联系起来。结果的建设性（能够刻画控制器）增加了重要的实践价值。对有限和无限时间域的考量，以及对目标命中约束的包含，体现了研究的全面性。

<details>
  <summary>Details</summary>

**Motivation:** 确定在给定受控扩散和集合的情况下，何时能够保证概率为一的受控集不变性。

**Method:** 通过推导特定对数似然梯度（即分数向量场）的充要条件，分别针对有限时间域和无限时间域两种情况。这些条件构成了一个基于分数的测试，可以验证或证伪马尔可夫控制器的存在性。计算涉及求解Dirichlet边值问题。

**Result:** 当问题数据通过测试时，可以描述所有保证所需集不变性的控制器；当测试失败时，则不存在能实现概率为一集不变性的控制器。结果通过半解析和数值示例进行了说明。

**Conclusion:** 本文提供了一种确定受控扩散是否能实现概率为一集不变性的基于分数的充要条件和测试方法，并能刻画相应的控制器。

> **ai_Abstract:** 本文研究了受控扩散中概率为一的受控集不变性问题。作者推导了基于分数向量场的充要条件，适用于有限和无限时间域，从而建立了一个能够验证或否证马尔可器控制器存在性的测试。该研究还具有建设性，即当控制器存在时，能够描述所有满足条件的控制器；反之，则证明其不存在。所提出的测试涉及求解Dirichlet边值问题，并通过多个示例进行了验证。

> **摘要翻译:** 给定一个受控扩散和一个连通、有界、Lipschitz集，何时能够保证概率为一的受控集不变性？在这项工作中，我们通过推导在两种情况下（给定有限时间域和无限时间域）特定对数似然的梯度（即分数向量场）的充要条件来回答这个问题。推导出的条件构成了一个基于分数的测试，可以证明性地认证或证伪给定受控集不变性问题数据的马尔可夫控制器的存在性。我们的结果是建设性的，即当问题数据通过所提出的测试时，我们描述了所有能保证所需集不变性的控制器。当问题数据未能通过所提出的测试时，则不存在能够以概率一实现所需集不变性的控制器。所提出的测试中的计算涉及求解某些Dirichlet边值问题，在有限时间域的情况下，还可以考虑在最终时间点击中目标子集的额外约束。我们通过几个半解析和数值示例来说明结果。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [934] [Decentralized Modeling of Vehicular Maneuvers and Interactions at Urban Junctions](https://arxiv.org/abs/2507.21547)
> *城市路口车辆机动和交互的去中心化建模*

*Saeed Rahmani, Simeon C. Calvert, Bart van Arem* | **Category: math.OC, cs.RO, cs.SY, eess.SY** | **Updated: 2025-07-29**

**Keywords:** 去中心化建模, 城市路口, 车辆交互, 轨迹规划, 混合自主交通

**Comment:** Manuscript under review

> **TL;DR:** 本文提出了一种用于城市路口车辆轨迹规划和去中心化控制的建模框架，解决了现有方法在混合自主交通中对非合作交互和车辆动力学建模的局限性，并通过双层结构实现了准确和真实的车辆行为建模。

**AI_Comments:** 该论文的创新之处在于提出了一个去中心化的双层建模框架，有效克服了传统方法对中央控制和信息共享的依赖。通过将运动学明确整合到两层控制中，并考虑了随机操作元素，显著增强了模型在混合自主交通环境中的真实性和适用性，尤其对于安全分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在自动驾驶汽车安全高效部署之前，对其在混合自主交通中的建模和评估至关重要，尤其是在复杂的城市路口。现有建模方法在统一的数学框架内表述非合作交互和车辆动力学方面存在局限性，且通常假设预定义路径或依赖合作和中央可控性，限制了其在混合自主交通中的真实性和适用性。

**Method:** 本文提出了一种用于城市路口轨迹规划和去中心化车辆控制的建模框架。该框架采用双层结构：上层使用高效图搜索算法和自定义启发式函数生成运动学可行的参考轨迹；下层采用预测控制器进行轨迹跟踪和优化。该框架不要求中央可控性或车辆间知识共享，并在两层中明确纳入车辆运动学，使用加速度和转向角作为控制变量。其去中心化结构能适应操作和随机元素。

**Result:** 数值和仿真实验在不同场景下（包括无信号交叉口和环形交叉口）验证了该框架在建模城市路口准确和真实的车辆机动和交互方面的能力。

**Conclusion:** 该去中心化建模框架能够准确、真实地模拟城市路口的车辆机动和交互，解决了现有方法的局限性，并适用于交通效率、环境影响和运动舒适度分析以及安全分析。

> **ai_Abstract:** 本文提出了一种去中心化的建模框架，用于在城市路口进行车辆轨迹规划和控制，旨在解决现有方法在混合自主交通中对非合作交互和车辆动力学建模的不足。该框架采用双层结构：上层通过图搜索生成运动学可行的参考轨迹，下层则利用预测控制器进行轨迹跟踪和优化。其核心优势在于无需中央控制或车辆间信息共享，并能有效处理车辆运动学和随机因素。实验证明，该框架能准确、真实地模拟城市路口的车辆行为，适用于深入的交通效率、环境影响和安全分析。

> **摘要翻译:** 在自动驾驶汽车（AVs）安全高效部署之前，对其在混合自主交通中的建模和评估至关重要。这在发生复杂多智能体交互的城市路口尤为重要。当前用于城市路口车辆机动和交互建模的方法在统一的数学框架内表述非合作交互和车辆动力学方面存在局限性。先前的研究要么假设预定义路径，要么依赖合作和中央可控性，限制了它们在混合自主交通中的真实性和适用性。本文通过提出一种用于城市路口轨迹规划和去中心化车辆控制的建模框架来解决这些局限性。该框架采用双层结构：上层使用高效图搜索算法和自定义启发式函数生成运动学可行的参考轨迹；下层采用预测控制器进行轨迹跟踪和优化。与现有方法不同，我们的框架不要求中央可控性或车辆间知识共享。车辆运动学在两层中都明确纳入，并使用加速度和转向角作为控制变量。这种直观的表述有助于分析交通效率、环境影响和运动舒适度。该框架的去中心化结构适应了操作和随机元素，例如车辆的检测范围、感知不确定性和反应延迟，使模型适用于安全分析。跨越不同场景（包括无信号交叉口和环形交叉口）的数值和仿真实验证明了该框架在建模各种城市路口准确和真实的车辆机动和交互方面的能力。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='cscc'></a>
## cs.CC 

### [165] [Cell-Probe Lower Bounds via Semi-Random CSP Refutation: Simplified and the Odd-Locality Case](https://arxiv.org/abs/2507.22265)
> *单元探针下界通过半随机CSP驳斥：简化与奇数局部性情况*

*Venkatesan Guruswami, Xin Lyu, Weiqiang Yuan* | **Category: cs.CC, cs.CR, cs.DS** | **Updated: 2025-07-29**

**Keywords:** 单元探针下界, CSP驳斥, XOR驳斥, 去随机化, 奇数元情况

**Comment:** Comments welcome

> **TL;DR:** 本文通过简化XOR驳斥并处理奇数元情况，改进了单元探针模型中的一些下界，并实现了半随机K-XOR驳斥分析的完全去随机化。

**AI_Comments:** 本文通过引入更精简的XOR驳斥归约和对奇数元情况的有效处理，进一步推进了单元探针下界的研究，并完成了对半随机CSP驳斥分析的全面去随机化。这项工作不仅在理论上填补了偶数元去随机化的空白，也为数据结构和电路复杂性理论提供了重要的工具和见解。

<details>
  <summary>Details</summary>

**Motivation:** 之前的研究建立了静态数据结构下界、NC0电路的范围避免与伪随机CSP实例驳斥之间的联系，并改进了一些长期存在的下界。本文的动机是进一步改进这些下界，特别是通过更精简的方法和处理奇数元情况。

**Method:** 采用更精简的归约到XOR驳斥，并处理了奇数元（odd-arity）情况。这可以看作是对现有半随机k-XOR驳斥分析的完全去随机化。技术上，证明了任何大幅扩展其输入的常数深度多输出电路，其输出很可能远离从具有足够独立性的分布中采样的字符串，且这可以被有效认证。

**Result:** 改进了单元探针/位探针模型中某些情况的下界。实现了最先进的半随机k-XOR驳斥分析的完全去随机化。此外，通过视角转换，这些结果可应用于单元探针下界和NC0电路的范围避免算法。

**Conclusion:** 本文通过简化方法和处理奇数元情况，成功改进了单元探针下界，并完成了对现有半随机k-XOR驳斥分析的去随机化，为数据结构下界和电路分析提供了新的工具。

> **ai_Abstract:** 本文在Korten等人工作的基础上，通过将问题更精简地归约到XOR驳斥并处理奇数元情况，改进了单元探针/位探针模型中的下界。该工作实现了对现有半随机k-XOR驳斥分析的完全去随机化，并证明了常数深度电路的输出特性，为单元探针下界和NC0电路的范围避免算法提供了新的应用。

> **摘要翻译:** 一项近期工作 (Korten, Pitassi, and Impagliazzo, FOCS 2025) 在静态数据结构下界、NC0电路的范围避免以及伪随机CSP实例的驳斥之间建立了深刻的联系，从而改进了单元探针/位探针模型中一些长期存在的下界。在此，我们通过更精简地归约到XOR驳斥，并结合对奇数元情况的处理，改进了某些情况下的这些下界。我们的结果可以被视为对最先进的半随机k-XOR驳斥分析 (Guruswami, Kothari and Manohar, STOC 2022, Hsieh, Kothari and Mohanty, SODA 2023) 的完全去随机化，这补充了Korten等人获得的偶数元情况的去随机化。作为我们主要的技术陈述，我们表明对于任何大幅扩展其输入的常数深度多输出电路，其输出极有可能远离从具有足够独立性的分布中采样的字符串，并且这可以被有效认证。通过适当的视角转换，这为单元探针下界和NC0电路的范围避免算法提供了应用。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

### [331] [Improved Hardness of BDD and SVP Under Gap-(S)ETH](https://arxiv.org/abs/2109.04025)
> *在Gap-(S)ETH假设下BDD和SVP的改进硬度*

*Huck Bennett, Chris Peikert, Yi Tang* | **Category: cs.CC, cs.CR, cs.DS** | **Updated: 2025-07-28**

**Keywords:** 格问题, BDD, SVP, Gap-ETH, 计算硬度

**Comment:** ITCS 2022. Updated to address (non-)existence of exponential kissing
  number lattices

> **TL;DR:** 在Gap-(S)ETH变体假设下，本文展示了BDD和SVP在$l_p$范数下更精细的硬度结果。

**AI_Comments:** 本文通过引入Gap-(S)ETH假设，为BDD和SVP这两个重要的格问题在不同$l_p$范数下提供了更精细的计算硬度下界。这些结果对于理解格问题的内在复杂性及其在密码学等领域的安全性具有重要意义。论文详细列举了四项具体的硬度结果，涵盖了不同的$p$值、近似因子和时间复杂度。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在展示在Gap-(S)ETH（Gap-(S)强指数时间假设）变体假设下，有界距离解码（BDD）和近似最短向量问题（SVP）这两个关键格问题在$l_p$范数下的改进细粒度硬度。

**Method:** 本文的研究方法是基于Gap（强）指数时间假设（Gap-(S)ETH）的变体来证明BDD和SVP的计算硬度。

**Result:** 1. 对于所有$p 	ext{属于} [1, 	ext{无穷大})$，如果非均匀Gap-ETH成立且$c_{\mathsf{kn}} > 0$，则对于任何常数$\alpha > \alpha_{\mathsf{kn}}$（其中$\alpha_{\mathsf{kn}} = 2^{-c_{\mathsf{kn}}}$且$c_{\mathsf{kn}}$是$l_2$亲吻数常数），不存在$2^{o(n)}$时间的$\mathrm{BDD}_{p, \alpha}$算法。
2. 对于所有$p 	ext{属于} [1, 	ext{无穷大})$，除非随机Gap-ETH是错误的，否则对于任何常数$\alpha > \alpha^{\ddagger}_p$（其中$\alpha^{\ddagger}_p$是明确的，且对于$1 \leq p \leq 2$有$\alpha^{\ddagger}_p = 1$，对于所有$p > 2$有$\alpha^{\ddagger}_p < 1$，并且当$p \to \text{无穷大}$时$\alpha^{\ddagger}_p \to 1/2$），不存在$2^{o(n)}$时间的$\mathrm{BDD}_{p, \alpha}$算法。
3. 对于所有$p 	ext{属于} [1, \text{无穷大}) \setminus 2 \mathbb{Z}$和所有$C > 1$，如果$c_{\mathsf{kn}} > 0$且非均匀Gap-SETH成立，则对于任何常数$\alpha > \alpha^{\dagger}_{p, C}$（其中$\alpha^{\dagger}_{p, C}$是明确的，且对于任何固定的$p \in [1, \text{无穷大})$当$C \to \text{无穷大}$时$\alpha^{\dagger}_{p, C} \to 1$），不存在$2^{n/C}$时间的$\mathrm{BDD}_{p, \alpha}$算法。
4. 对于所有$p > p_0 \approx 2.1397$， $p \notin 2\mathbb{Z}$，和所有$C > C_p$，除非随机Gap-SETH是错误的，否则对于某个常数$\gamma > 1$（其中$C_p > 1$是明确的，且当$p \to \text{无穷大}$时$C_p \to 1$），不存在$2^{n/C}$时间的$\mathrm{SVP}_{p, \gamma}$算法。

**Conclusion:** 本文在Gap-(S)ETH变体假设下，为$l_p$范数下的有界距离解码（BDD）和近似最短向量问题（SVP）提供了更强的细粒度计算硬度下界。

> **ai_Abstract:** 本文在Gap-(S)ETH（Gap-(S)强指数时间假设）的变体假设下，研究了$l_p$范数下有界距离解码（BDD）和近似最短向量问题（SVP）的细粒度计算硬度。研究结果表明，在特定条件下，对于BDD和SVP问题，不存在在多项式时间内或指数时间中具有次线性指数的算法，为这些关键格问题的计算复杂性提供了更强的理论下界，并明确了这些硬度结果依赖的具体参数和假设。

> **摘要翻译:** 我们展示了在$l_p$范数下两个关键格问题——有界距离解码到最小距离的$\alpha$因子内（$\mathrm{BDD}_{p, \alpha}$）和$\gamma$近似最短向量问题（决策型）（$\mathrm{SVP}_{p,\gamma}$）——的改进细粒度硬度，假设存在Gap（强）指数时间假设（Gap-(S)ETH）的变体。具体来说，我们展示了：
1. 对于所有$p \in [1, \infty)$，如果$c_{\mathsf{kn}} > 0$且非均匀Gap-ETH成立，则对于任何常数$\alpha > \alpha_{\mathsf{kn}}$，其中$\alpha_{\mathsf{kn}} = 2^{-c_{\mathsf{kn}}}$且$c_{\mathsf{kn}}$是$l_2$亲吻数常数，不存在$2^{o(n)}$时间的$\mathrm{BDD}_{p, \alpha}$算法。
2. 对于所有$p \in [1, \infty)$，除非随机Gap-ETH是错误的，否则对于任何常数$\alpha > \alpha^{\ddagger}_p$，其中$\alpha^{\ddagger}_p$是明确的，且对于$1 \leq p \leq 2$有$\alpha^{\ddagger}_p = 1$，对于所有$p > 2$有$\alpha^{\ddagger}_p < 1$，并且当$p \to \infty$时$\alpha^{\ddagger}_p \to 1/2$，不存在$2^{o(n)}$时间的$\mathrm{BDD}_{p, \alpha}$算法。
3. 对于所有$p \in [1, \infty) \setminus 2 \mathbb{Z}$和所有$C > 1$，如果$c_{\mathsf{kn}} > 0$且非均匀Gap-SETH成立，则对于任何常数$\alpha > \alpha^{\dagger}_{p, C}$，其中$\alpha^{\dagger}_{p, C}$是明确的，且对于任何固定的$p \in [1, \infty)$当$C \to \infty$时$\alpha^{\dagger}_{p, C} \to 1$，不存在$2^{n/C}$时间的$\mathrm{BDD}_{p, \alpha}$算法。
4. 对于所有$p > p_0 \approx 2.1397$， $p \notin 2\mathbb{Z}$，和所有$C > C_p$，除非随机Gap-SETH是错误的，否则对于某个常数$\gamma > 1$，其中$C_p > 1$是明确的，且当$p \to \infty$时$C_p \to 1$，不存在$2^{n/C}$时间的$\mathrm{SVP}_{p, \gamma}$算法。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

<a id='physicsdata-an'></a>
## physics.data-an 

### [187] [Towards a Large Physics Benchmark](https://arxiv.org/abs/2507.21695)
> *迈向大型物理学基准*

*Kristian G. Barman, Sascha Caron, Faegheh Hasibi, Eugene Shalugin, Yoris Marcet, Johannes Otte, Henk W. de Regt, Merijn Moody* | **Category: physics.data-an, cs.AI, hep-ph, physics.comp-ph, physics.hist-ph** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 物理学, 基准, 科学理解, 人工智能

**Comment:** 

> **TL;DR:** 本文提出了一个大型物理学基准框架，旨在评估和引导基础物理领域大型语言模型的发展。

**AI_Comments:** 该论文的创新之处在于其“活”的基准概念，通过邀请物理学家持续贡献问题来确保基准的动态更新和长期相关性。其次，其多维度的专家评分系统（正确性、难度、惊喜度）以及涵盖概念理解、数学推导和复杂问题解决的三种问题形式，使得对LLM在物理领域的评估更为全面和深入。这对于引导AI在基础物理研究中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开发一个基准框架，用于评估、监控和引导基础物理领域大型语言模型（LLM）的发展。

**Method:** 该基准框架基于科学理解和创造力的哲学概念，并开发了一个评分系统，由专家根据正确性、难度和惊喜度对问题进行评分。问题形式包括多项选择题、分析问题和开放式任务。为确保持续相关性，提出了一个“活”的基准概念，鼓励物理学家贡献问题。

**Result:** 当前的数据库包含多样化的例子，包括一个用于分类高能物理事件（如四顶夸克信号）的机器学习挑战。

**Conclusion:** 希望这个基准能够实现有针对性的人工智能开发，从而对基础物理研究做出有意义的贡献。

> **ai_Abstract:** 本文介绍了一个名为“大型物理学基准”的评估框架，旨在指导基础物理领域大型语言模型（LLM）的开发。该基准基于科学理解和创造力概念，采用专家评分系统，问题涵盖多项选择、分析推导和开放式问题解决等多种形式。它还提出了一个“活”的基准概念，鼓励物理学家持续贡献问题，以确保其相关性，并期望能促进对基础物理研究有益的AI发展。

> **摘要翻译:** 我们引入了一个由科学界开发并服务于科学界的基准框架，旨在评估、监控和引导基础物理领域大型语言模型的发展。基于科学理解和创造力的哲学概念，我们开发了一个评分系统，其中每个问题都由专家根据其正确性、难度和惊喜度进行评分。问题分为三种形式：(i) 用于概念理解的多项选择题，(ii) 需要数学推导的分析问题，以及 (iii) 需要复杂问题解决的开放式任务。我们目前的数据库包含多样化的例子，包括一个用于分类高能物理事件（如四顶夸克信号）的机器学习挑战。为了确保持续的相关性，我们提出了一个“活”的基准，物理学家可以贡献问题，例如与新出版物一同贡献。我们邀请通过：http://www.physicsbenchmarks.org/ 贡献。我们希望这个基准能够实现有针对性的人工智能开发，从而对基础物理研究做出有意义的贡献。

</details>

[⬆️ 返回分类顶部](#physicsdata-an) | [⬆️ 返回总目录](#toc)

---

<a id='physicscomp-ph'></a>
## physics.comp-ph 

### [208] [Designing quantum chemistry algorithms with just-in-time compilation](https://arxiv.org/abs/2507.09772)
> *使用即时编译设计量子化学算法*

*Xiaojie Wu, Qiming Sun, Yuanheng Wang* | **Category: physics.comp-ph, cs.NA, math.NA** | **Updated: 2025-07-30**

**Keywords:** 即时编译, 量子化学, 电子排斥积分, 高斯型轨道, CUDA

**Comment:** 10 pages, 7 figures

> **TL;DR:** 本文将即时编译（JIT）引入高斯型轨道（GTO）的积分核，显著提高了电子排斥积分计算的效率，实现了高达4倍的加速。

**AI_Comments:** 本文的创新点在于将即时编译（JIT）引入量子化学中的积分核计算，并针对高角动量轨道设计了新的算法，显著提升了电子排斥积分计算的效率。其紧凑的CUDA实现和对单精度算术的支持也显示了其工程上的优化。这种方法对于加速大规模量子化学模拟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高电子排斥积分计算的效率，特别是针对高斯型轨道（GTO）的积分核。

**Method:** 引入了针对高斯型轨道（GTO）积分核的即时编译（JIT），并结合了一种针对高角动量轨道的新算法。核心CUDA实现代码量小，并支持单精度算术。

**Result:** 对于小型6-31G*基组，基于JIT的算法在NVIDIA A100-80G GPU上比GPU4PySCF v1.4提速2倍。通过结合新算法，大型def2-TZVPP基组的JK评估效率提高了高达4倍。单精度实现比现有最先进技术提速3倍。核心CUDA实现代码量约为1,000行。

**Conclusion:** 通过引入即时编译和针对高角动量轨道的新算法，显著提高了量子化学中电子排斥积分计算的效率，尤其是在GPU上。

> **ai_Abstract:** 本文提出将即时编译（JIT）应用于高斯型轨道（GTO）的积分核，以提升电子排斥积分计算的效率。研究表明，该方法在小型6-31G*基组上可实现2倍加速，对于大型def2-TZVPP基组，结合新算法后可提升效率高达4倍。此外，单精度实现比现有技术快3倍，且核心CUDA代码量紧凑。

> **摘要翻译:** 我们引入了即时编译（JIT）到高斯型轨道（GTO）的积分核中，以提高电子排斥积分计算的效率。对于库仑和交换（JK）矩阵，基于JIT的算法在NVIDIA A100-80G GPU上，对于小型6-31G*基组，比GPU4PySCF v1.4实现了2倍的加速。通过引入一种为高角动量轨道设计的新算法，大型def2-TZVPP基组的JK评估效率提高了高达4倍。核心CUDA实现紧凑，仅包含约1,000行代码，包括对单精度算术的支持。此外，单精度实现比之前的最先进技术实现了3倍的加速。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-biogn'></a>
## q-bio.GN 

### [229] [EnTao-GPM: DNA Foundation Model for Predicting the Germline Pathogenic Mutations](https://arxiv.org/abs/2507.21706)
> *EnTao-GPM：用于预测种系致病性突变的DNA基础模型*

*Zekai Lin, Haoran Sun, Yucheng Guo, Yujie Yang, Yanwen Wang, Bozhen Hu, Chonghang Ye, Qirong Yang, Fan Zhong, Xiaoming Zhang, Lei Liu* | **Category: q-bio.GN, cs.AI** | **Updated: 2025-07-29**

**Keywords:** DNA基础模型, 致病性突变, 种系突变, 精准医疗, 基因检测

**Comment:** 

> **TL;DR:** EnTao-GPM是一个DNA基础模型，通过跨物种预训练、种系突变特化和可解释框架，解决了精准医疗中区分致病性突变的挑战，并在突变分类中表现出卓越的准确性。

**AI_Comments:** 这篇论文提出了一种创新的DNA基础模型EnTao-GPM，通过结合跨物种学习、大规模临床数据微调和LLM驱动的可解释性，有效解决了致病性突变识别这一精准医疗中的核心难题。其创新性在于将DNA序列分析提升到“基础模型”的高度，并通过多物种数据增强了模型的泛化能力和对非编码区变异的理解。该模型在准确性上的提升，以及其提供的可解释性，对于临床诊断和个性化治疗具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在精准医疗中，区分致病性突变和良性多态性仍然是一个关键挑战。

**Method:** EnTao-GPM通过三项创新解决此问题：1. 跨物种靶向预训练：在与疾病相关的哺乳动物基因组（人、猪、鼠）上进行预训练，利用进化保守性增强对致病性基序（尤其在非编码区）的解释。2. 种系突变特化：在ClinVar和HGMD数据集上进行微调，提高对SNVs和非SNVs的准确性。3. 可解释的临床框架：整合DNA序列嵌入与基于LLM的统计解释，提供可操作的见解。

**Result:** 经ClinVar验证，EnTao-GPM在突变分类中表现出卓越的准确性。

**Conclusion:** EnTao-GPM通过实现更快、更准确、更易于获取的临床诊断（如变异评估、风险识别、个性化治疗）和研究解释，彻底改变了基因检测，从而推动了精准医疗的发展。

> **ai_Abstract:** EnTao-GPM是一个由复旦大学和BioMap开发的DNA基础模型，旨在解决精准医疗中区分致病性突变和良性多态性的难题。该模型通过在多种哺乳动物基因组上进行跨物种预训练、在ClinVar和HGMD数据集上进行种系突变特化微调，以及构建一个结合DNA序列嵌入和LLM解释的可解释临床框架来实现其目标。EnTao-GPM在突变分类中展现出卓越的准确性，有望加速和优化基因检测在临床诊断和研究中的应用，从而推进个性化医疗。

> **摘要翻译:** 区分致病性突变和良性多态性仍然是精准医疗中的一个关键挑战。由复旦大学和BioMap开发的EnTao-GPM通过三项创新解决了这个问题：(1) 在与疾病相关的哺乳动物基因组（人、猪、鼠）上进行跨物种靶向预训练，利用进化保守性增强对致病性基序的解释，尤其是在非编码区域；(2) 通过在ClinVar和HGMD上进行微调实现种系突变特化，提高对单核苷酸变异（SNVs）和非单核苷酸变异的准确性；(3) 整合DNA序列嵌入和基于大型语言模型（LLM）的统计解释，提供可操作见解的可解释临床框架。经ClinVar验证，EnTao-GPM在突变分类中表现出卓越的准确性。它通过实现更快、更准确、更易于获取的临床诊断（例如，变异评估、风险识别、个性化治疗）和研究解释，彻底改变了基因检测，从而推动了精准医疗的发展。

</details>

[⬆️ 返回分类顶部](#q-biogn) | [⬆️ 返回总目录](#toc)

---

<a id='nlinao'></a>
## nlin.AO 

### [232] [Higher-Order Kuramoto Oscillator Network for Dense Associative Memory](https://arxiv.org/abs/2507.21984)
> *高阶Kuramoto振子网络用于密集联想记忆*

*Jona Nagerl, Natalia G. Berloff* | **Category: nlin.AO, cond-mat.dis-nn, cond-mat.stat-mech, cs.ET, cs.LG** | **Updated: 2025-07-29**

**Keywords:** Kuramoto模型, 联想记忆, 高阶耦合, 平均场理论, 记忆容量

**Comment:** 13 pages, 7 figures

> **TL;DR:** 引入结合高阶耦合的广义Kuramoto模型，实现高容量、鲁棒的密集联想记忆，并揭示其相图和超线性记忆容量。

**AI_Comments:** 这项工作通过引入高阶耦合，显著提升了Kuramoto模型作为联想记忆的能力，实现了超线性记忆容量，并揭示了其复杂的动力学相变。它创新性地弥合了Kuramoto同步与Hopfield网络之间的鸿沟，为构建新型模拟联想记忆硬件提供了理论指导，具有重要的理论和潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 经典的Kuramoto模型仅包含两两相互作用，限制了其作为密集联想记忆的能力，需要引入高阶耦合来克服这一限制。

**Method:** 本文引入结合二次谐波（两两）和四次谐波（四阶）耦合的广义Kuramoto模型，其灵感来源于密集Hopfield记忆理论。研究利用平均场理论及其动力学近似进行分析，并通过大规模振子网络模拟验证理论预测。

**Result:** 研究获得了密集联想记忆模型的相图，该相图显示一个三临界点，记忆检索的连续发生在此点被不连续、滞后性跃迁所取代。在四阶主导区域，系统支持对应于存储记忆模式的双稳态锁相状态，记忆态与非相干态之间存在可观的能量势垒。分析确定了该双稳态区域，并表明从记忆态（由于噪声）的逃逸时间随网络规模呈指数增长，表明鲁棒存储。高阶耦合实现了记忆容量随系统规模的超线性扩展，远超仅有两两耦合振子的限制。大规模模拟证实了快速模式检索和鲁棒存储。

**Conclusion:** 本研究将Kuramoto同步与现代Hopfield记忆联系起来，为在振子系统中实现高容量、模拟联想记忆的实验实现提供了方向。

> **ai_Abstract:** 本文提出一种结合高阶耦合（二次谐波和四次谐波）的广义Kuramoto模型，用于构建密集联想记忆网络。研究利用平均场理论和大规模模拟，揭示了该模型的相图，发现了记忆检索从连续到不连续的转变。结果表明，高阶耦合能实现记忆容量的超线性增长和鲁棒存储，为基于振子系统实现高容量模拟联想记忆提供了理论基础。

> **摘要翻译:** 相振子网络如果能结合超越经典Kuramoto模型的两两相互作用的高阶耦合，就可以作为密集联想记忆。本文引入了一种广义Kuramoto模型，结合了二次谐波（两两）和四次谐波（四阶）耦合，其灵感来源于密集Hopfield记忆理论。利用平均场理论及其动力学近似，我们获得了密集联想记忆模型的相图，该相图显示一个三临界点，在此点处，记忆检索的连续发生被不连续、滞后性跃迁所取代。在四阶主导区域，系统支持对应于存储记忆模式的双稳态锁相状态，记忆态与非相干态之间存在可观的能量势垒。我们分析性地确定了这个双稳态区域，并表明从记忆态（由于噪声）的逃逸时间随网络规模呈指数增长，表明鲁棒存储。将理论扩展到有限记忆负载，我们表明高阶耦合实现了记忆容量随系统规模的超线性扩展，远远超过仅有两两耦合振子的限制。振子网络的大规模模拟证实了我们的理论预测，展示了快速模式检索和许多相位模式的鲁棒存储。这些结果将Kuramoto同步与现代Hopfield记忆联系起来，指向振子系统中高容量、模拟联想记忆的实验实现。

</details>

[⬆️ 返回分类顶部](#nlinao) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [249] [AI-Driven Generation of Data Contracts in Modern Data Engineering Systems](https://arxiv.org/abs/2507.21056)
> *AI驱动的现代数据工程系统中数据契约的生成*

*Harshraj Bhoite* | **Category: cs.DB, cs.AI** | **Updated: 2025-05-04**

**Keywords:** 数据契约, 大型语言模型, AI驱动, 数据工程, 数据治理

**Comment:** 

> **TL;DR:** 该研究提出了一个由AI驱动的框架，利用微调的大型语言模型自动生成数据契约，显著提高了准确性并减少了人工工作量，从而实现了可扩展的敏捷数据治理。

**AI_Comments:** 这项工作通过利用LLMs自动化数据契约的生成，解决了数据工程中一个关键的痛点，即手动契约维护的复杂性和高成本。其创新之处在于将参数高效微调方法应用于结构化数据领域，并展示了在实际数据平台中的集成潜力。虽然取得了显著的效率提升，但文章也坦诚地指出了幻觉、版本控制和持续学习等挑战，这对于实际部署和长期维护至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 随着数据管道复杂性的增长，手动编写和维护数据契约变得容易出错且劳动密集。

**Method:** 提出了一个AI驱动的框架，利用大型语言模型（LLMs）自动生成数据契约。该系统利用LoRA和PEFT等参数高效微调方法，使LLMs适应结构化数据领域，并从示例数据或模式描述中输出经过验证的契约定义（如JSON Schema和Avro）。

**Result:** 在合成和真实世界数据集上的实验结果表明，微调后的LLMs在生成有效契约方面取得了高准确性，并将人工工作量减少了70%以上。

**Conclusion:** 生成式AI能够通过弥合企业数据管理中意图与实现之间的差距，实现可扩展、敏捷的数据治理。

> **ai_Abstract:** 本研究提出了一个AI驱动的框架，利用经过参数高效微调（如LoRA和PEFT）的大型语言模型，自动生成现代数据工程系统中的数据契约。该系统能够从样本数据或模式描述中输出有效的契约定义，并已集成到主流数据平台。实验证明，该方法能高精度生成契约，并将人工工作量减少70%以上，从而实现可扩展的敏捷数据治理，尽管仍面临幻觉、版本控制和持续学习等挑战。

> **摘要翻译:** 数据契约规范了数据生产者和消费者之间关于模式、语义和质量预期的协议。随着数据管道复杂性的增长，手动编写和维护契约变得容易出错且劳动密集。我们提出了一个由AI驱动的框架，用于利用大型语言模型（LLMs）自动生成数据契约。我们的系统利用参数高效微调方法，包括LoRA和PEFT，使LLMs适应结构化数据领域。这些模型接受示例数据或模式描述，并以JSON Schema和Avro等格式输出经过验证的契约定义。我们将此框架集成到现代数据平台（例如Databricks、Snowflake）中，以大规模自动化契约执行。在合成和真实世界数据集上的实验结果表明，微调后的LLMs在生成有效契约方面取得了高准确性，并将人工工作量减少了70%以上。我们还讨论了幻觉、版本控制和持续学习等关键挑战。这项工作表明，生成式AI可以通过弥合企业数据管理中意图与实现之间的差距，实现可扩展、敏捷的数据治理。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [285] [CleANN: Efficient Full Dynamism in Graph-based Approximate Nearest Neighbor Search](https://arxiv.org/abs/2507.19802)
> *CleANN：图基近似最近邻搜索中的高效全动态性*

*Ziyu Zhang, Yuanhao Wei, Joshua Engels, Julian Shun* | **Category: cs.DB, cs.DC, cs.DS, cs.IR** | **Updated: 2025-07-26**

**Keywords:** 近似最近邻搜索, 图基索引, 全动态性, CleANN, 向量数据库

**Comment:** 

> **TL;DR:** CleANN是一个新的图基ANNS系统，首次在全动态（插入、删除、搜索）工作负载下，在保持查询质量的同时实现了显著的吞吐量提升。

**AI_Comments:** CleANN系统在解决图基ANNS中全动态性挑战方面取得了显著进展。其创新点在于引入了三个相互协作的组件，特别是半懒惰内存清理，有效管理了动态更新带来的复杂性。该研究填补了现有动态ANNS索引在效率和质量上的空白，对于需要实时数据更新的向量数据库应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图基近似最近邻搜索（ANNS）索引大多是为静态场景设计的，无法有效支持数据更新。现有动态图基索引存在查询质量随更新下降或图结构更新成本高昂的问题，而全动态性对于使用向量数据库的应用至关重要。

**Method:** 我们提出了CleANN系统，包含三个主要组件：1) 工作负载感知链接，将不同的搜索树后代连接起来以应对分布偏移；2) 查询自适应的即时邻居整合，以高效处理已删除节点；3) 半懒惰内存清理，用于清除数据结构中的陈旧信息并减少前两个组件的工作量。

**Result:** CleANN在全动态工作负载下的查询质量至少与静态构建的索引相当。在并发运行所有类型查询的内存设置下，CleANN在百万级真实世界数据集上实现了7-1200倍的吞吐量提升，同时保持了相同的召回率。

**Conclusion:** CleANN是第一个在全动态性下实现高效且保持质量的并发ANNS索引，解决了现有动态图基ANNS索引的痛点。

> **ai_Abstract:** 该论文提出了CleANN，一个用于图基近似最近邻搜索（ANNS）的新系统，旨在解决现有方法在全动态工作负载（插入、删除、搜索）下的效率和质量下降问题。CleANN通过工作负载感知链接、查询自适应邻居整合和半懒惰内存清理三个核心组件，实现了在保持高查询质量的同时，显著提升了吞吐量。实验结果表明，CleANN的性能与静态构建的索引相当，并在并发全动态场景下实现了7-1200倍的吞吐量提升，是首个达到此效率和质量的并发ANNS索引。

> **摘要翻译:** 近似最近邻搜索（ANNS）已成为各种AI工作负载中其他基础数据任务的典型算法问题。基于图的ANNS索引在索引成本、查询效率和查询近似质量方面具有出色的经验权衡。大多数现有基于图的索引是为静态场景设计的，即索引构建后数据没有更新。然而，全动态性（插入、删除和搜索）对于在利用向量数据库的应用程序中提供最新响应至关重要。期望索引能够高效地并发支持更新和搜索查询。现有动态基于图的索引至少存在以下问题之一：(1) 随着更新的发生，查询质量会下降；(2) 用于在更新时维护索引质量的图结构更新是全局的，因此成本高昂。为了解决这些问题，我们提出了CleANN系统，它由三个主要组件组成：(1) 工作负载感知链接，将不同的搜索树后代连接起来以应对分布偏移；(2) 查询自适应的即时邻居整合，以高效处理已删除节点；(3) 半懒惰内存清理，用于清除数据结构中的陈旧信息并减少前两个组件的工作量。我们在7个不同的数据集上对CleANN进行了全动态工作负载评估，发现CleANN的查询质量至少与使用相应数据静态构建的索引一样好。在内存设置下，使用56个超线程，所有类型的查询并发运行，在相同的召回水平下，CleANN在百万级真实世界数据集上实现了7-1200倍的吞吐量提升。据我们所知，CleANN是第一个在全动态性下保持质量的同时实现这种效率的并发ANNS索引。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [455] [AgileDART: An Agile and Scalable Edge Stream Processing Engine](https://arxiv.org/abs/2407.14953)
> *AgileDART：一个敏捷且可扩展的边缘流处理引擎*

*Cheng-Wei Ching, Xin Chen, Chaeeun Kim, Tongze Wang, Dong Chen, Dilma Da Silva, Liting Hu* | **Category: cs.DB, cs.DC** | **Updated: 2025-07-29**

**Keywords:** 边缘流处理, 可扩展性, 敏捷, 分布式哈希表, Bandit算法

**Comment:** Published in IEEE Transactions on Mobile Computing

> **TL;DR:** AgileDART是一个敏捷且可扩展的边缘流处理引擎，解决了传统系统在处理大规模、低延迟、动态异构边缘数据流时的不足。

**AI_Comments:** AgileDART的创新点在于其动态数据流抽象和基于bandit的路径规划模型，这些机制使其能够有效地应对边缘计算环境的挑战，如资源限制、网络异构性和动态性。其将DHT与流处理结合以实现操作符的自适应管理，以及利用强化学习（bandit）进行网络路径优化，是解决边缘流处理复杂性的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 边缘应用产生大量的传感器数据流，需要快速处理以获取可操作的智能。然而，传统的数据处理系统不适合这些边缘应用，因为它们往往在处理大量并发流查询时扩展性不佳，在有限的边缘计算资源下不支持低延迟处理，并且无法适应边缘计算环境中常见的异构性和动态性。

**Method:** 本文提出了AgileDART，其核心方法包括：1. 一个动态数据流抽象，利用基于分布式哈希表的对等覆盖网络，自主放置、链接和扩展流操作符，以减少查询延迟、适应工作负载变化和从故障中恢复。2. 一个基于bandit的路径规划模型，重新规划数据混洗路径以适应不可靠和异构的边缘网络。

**Result:** AgileDART在查询延迟方面优于Storm和EdgeWise，并在处理许多实际边缘流应用程序查询时显著提高了可扩展性和适应性。

**Conclusion:** AgileDART成功地提供了一个敏捷且可扩展的解决方案，用于在动态、异构的边缘环境中高效处理大规模并发的低延迟边缘流查询。

> **ai_Abstract:** 本文提出了AgileDART，一个专为边缘环境设计的敏捷且可扩展的流处理引擎。针对传统系统在处理大规模、低延迟、动态异构边缘数据流时的不足，AgileDART引入了动态数据流抽象和基于bandit的路径规划模型。前者利用DHT实现流操作符的自主放置、链接和扩展，以优化延迟、适应负载和故障恢复；后者则优化数据混洗路径以适应边缘网络。实验证明，AgileDART在查询延迟、可扩展性和适应性方面均优于现有系统。

> **摘要翻译:** 边缘应用产生大量的传感器数据，规模巨大，这些海量数据流必须在短时间内处理以获取可操作的智能。然而，传统的数据处理系统不适合这些边缘应用，因为它们往往在处理大量并发流查询时扩展性不佳，在有限的边缘计算资源下不支持低延迟处理，并且无法适应边缘计算环境中常见的异构性和动态性。因此，我们提出了AgileDART，一个敏捷且可扩展的边缘流处理引擎，它能够在动态、异构的边缘环境中，以大规模方式实现许多并发运行的低延迟边缘应用程序查询的快速流处理。我们工作的新颖之处在于一个动态数据流抽象，它利用基于分布式哈希表的对等覆盖网络来自主放置、链接和扩展流操作符，以减少查询延迟、适应工作负载变化和从故障中恢复；以及一个基于bandit的路径规划模型，它重新规划数据混洗路径以适应不可靠和异构的边缘网络。我们表明，AgileDART在查询延迟方面优于Storm和EdgeWise，并在处理许多实际边缘流应用程序查询时显著提高了可扩展性和适应性。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matstat-mech'></a>
## cond-mat.stat-mech 

### [260] [Learning Kinetic Monte Carlo stochastic dynamics with Deep Generative Adversarial Networks](https://arxiv.org/abs/2507.21763)
> *使用深度生成对抗网络学习动力学蒙特卡罗随机动力学*

*Daniele Lanzoni, Olivier Pierre-Louis, Roberto Bergamaschini, Francesco Montalenti* | **Category: cond-mat.stat-mech, cond-mat.mtrl-sci, cs.AI, cs.LG, physics.comp-ph** | **Updated: 2025-07-29**

**Keywords:** 生成对抗网络, 动力学蒙特卡罗, 随机动力学, 热波动, 计算物理

**Comment:** 15 pages, 8 figures, 2 appendices

> **TL;DR:** 本文展示了如何利用生成对抗网络（GANs）学习随机动力学，以替代传统模型并捕捉热波动，显著降低计算成本并准确再现系统特性。

**AI_Comments:** 该论文创新性地将深度生成对抗网络应用于学习复杂的随机动力学，为传统动力学蒙特卡罗模拟提供了一个高效且准确的替代方案。其通过条件GAN捕捉热波动并再现标度律的能力，展示了GANs在物理系统建模方面的巨大潜力，对于降低计算成本具有重要意义。论文也探讨了模型的局限性和未来发展方向，体现了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 传统模型在捕捉热波动和处理多粒子系统时可能存在计算成本高的问题，因此需要一种更高效的方法来学习随机动力学并替代传统模型。

**Method:** 研究人员构建了一个基于动力学蒙特卡罗（KMC）模拟的数据集，并训练了一个条件生成对抗网络（GAN）来随机传播系统状态。论文还讨论了相对于标准GANs的改进，以促进收敛和提高准确性。

**Result:** 训练后的网络能够定量地再现平衡和动力学特性，包括标度律，与精确值偏差仅为几个百分点。此外，该方法能够以较低的计算成本生成新的序列。

**Conclusion:** 生成对抗网络可以有效地学习随机动力学，作为传统模型的替代品，同时捕捉热波动，并能准确、高效地再现系统特性。

> **ai_Abstract:** 本文提出了一种利用深度生成对抗网络（GANs）学习动力学蒙特卡罗随机动力学的方法，旨在替代传统模型并有效捕捉热波动。研究人员通过构建基于动力学蒙特卡罗模拟的数据集，训练了一个条件GAN来模拟二维多粒子系统的状态随时间传播，特别是表面台阶波动和时间依赖性粗糙度。该方法通过对标准GANs的修改，提升了收敛性和准确性，并成功实现了以较低计算成本生成新序列。实验结果表明，该模型能定量准确地再现系统的平衡和动力学特性，包括标度律，且偏差仅为数个百分点。

> **摘要翻译:** 我们展示了生成对抗网络（GANs）可以有效地用于学习随机动力学，替代传统模型同时捕捉热波动。具体来说，我们将该应用展示在一个二维多粒子系统上，重点关注表面台阶波动以及相关的随时间变化的粗糙度。在构建了基于动力学蒙特卡罗模拟的数据集后，训练了一个条件GAN来随机传播系统状态，从而能够以降低的计算成本生成新的序列。论文讨论了相对于标准GANs的改进，这些改进有助于收敛并提高准确性。经验证，训练后的网络能够定量地再现平衡和动力学特性，包括标度律，与精确值的偏差仅为几个百分点。论文批判性地讨论了外推限制和未来展望。

</details>

[⬆️ 返回分类顶部](#cond-matstat-mech) | [⬆️ 返回总目录](#toc)

---

### [665] [Collaborative filtering based on nonnegative/binary matrix factorization](https://arxiv.org/abs/2410.10381)
> *基于非负/二元矩阵分解的协同过滤*

*Yukino Terui, Yuka Inoue, Yohei Hamakawa, Kosuke Tatsumura, Kazue Kudo* | **Category: cond-mat.stat-mech, cs.IR, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 协同过滤, 非负/二元矩阵分解, 稀疏数据, Ising机, 推荐系统

**Comment:** 12 pages, 8 figures

> **TL;DR:** 本文提出了一种改进的非负/二元矩阵分解（NBMF）算法，专门用于稀疏数据协同过滤，通过掩码未评分项并利用低延迟Ising机来提高预测准确性和计算效率。

**AI_Comments:** 该论文的创新点在于将NBMF算法改进以适应协同过滤中的稀疏数据问题，并通过掩码未评分项和引入Ising机来优化性能。这种结合稀疏数据处理和硬件加速的方法具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 协同过滤需要根据评分数据利用用户-项目相似性生成推荐，但评分数据通常包含大量未评分项目。为了预测这些未评分项目的分数，需要有效的矩阵分解技术。

**Method:** 本文提出了一种改进的非负/二元矩阵分解（NBMF）算法，专为稀疏数据协同过滤设计。该方法通过掩码评分矩阵中的未评分条目来提高预测准确性，并利用低延迟Ising机来缩短计算时间。

**Result:** 改进的方法提高了预测准确性，并且在计算时间方面具有优势。

**Conclusion:** 所提出的改进NBMF算法对协同过滤任务是有益的，尤其是在处理稀疏数据和追求计算效率方面。

> **ai_Abstract:** 本文提出了一种改进的非负/二元矩阵分解（NBMF）算法，用于处理协同过滤中的稀疏评分数据。该方法通过掩码未评分条目来提高预测准确性，并利用低延迟Ising机加速计算，从而在性能和效率上都展现出优势。

> **摘要翻译:** 协同过滤通过利用基于评分数据的用户-项目相似性来生成推荐，这些数据通常包含大量未评分项目。为了预测未评分项目的分数，通常采用非负矩阵分解（NMF）等矩阵分解技术。非负/二元矩阵分解（NBMF）是NMF的扩展，它将非负矩阵近似为非负矩阵和二元矩阵的乘积。虽然以前的研究主要将NBMF应用于图像等密集数据，但本文提出了一种针对稀疏数据协同过滤的改进NBMF算法。在改进的方法中，评分矩阵中的未评分条目被掩码，从而提高了预测准确性。此外，在NBMF中利用低延迟Ising机在计算时间方面具有优势，使得所提出的方法具有益处。

</details>

[⬆️ 返回分类顶部](#cond-matstat-mech) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matmtrl-sci'></a>
## cond-mat.mtrl-sci 

### [271] [Unified machine-learning framework for property prediction and time-evolution simulation of strained alloy microstructure](https://arxiv.org/abs/2507.21760)
> *应变合金微观结构特性预测与时间演化模拟的统一机器学习框架*

*Andrea Fantasia, Daniele Lanzoni, Niccolò Di Eugenio, Angelo Monteleone, Roberto Bergamaschini, Francesco Montalenti* | **Category: cond-mat.mtrl-sci, cond-mat.mes-hall, cs.LG, physics.comp-ph** | **Updated: 2025-07-29**

**Keywords:** 机器学习, 合金微观结构, 时间演化, 旋节分解, 卷积循环神经网络

**Comment:** 19 pages, 9 figures

> **TL;DR:** 本文提出了一个统一的机器学习框架，用于预测应变合金微观结构的演化，并能同时提取弹性参数。该框架通过卷积循环神经网络在旋节分解现象中得到验证，并展现出良好的准确性、可扩展性和时间外推能力。

**AI_Comments:** 该论文的创新之处在于提出了一个统一的机器学习级联框架，能够同时处理参数提取和时间演化预测这两个复杂任务，尤其在应变合金微观结构演化领域。其通用性和从实验视频中推断未知参数的潜力，为材料科学研究提供了一个强大的新工具，有望加速新材料的发现和设计。模型在临界条件下的准确性以及时间外推能力是其显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 为了方便地处理弹性场作用下合金微观结构的时间演化问题，并同时提取弹性参数和预测微观结构演化。

**Method:** 研究人员引入了一个统一的机器学习框架，该框架通过级联方式执行两项任务：从短轨迹中提取弹性参数，以及预测微观结构在这些参数影响下的进一步演化。具体通过聚焦于具有晶格失配eta的旋节分解现象进行演示，并使用卷积循环神经网络（CRNN）架构，将其预测结果与相场模拟提供的真实演化进行广泛比较。

**Result:** 所提出的级联模型在广泛的失配条件下，能够准确预测eta和完整的微观结构演化，即使在接近旋节分解的临界条件时也是如此。研究还证明了该框架对于更大计算域尺寸的可扩展性，以及在时间上的轻微外推误差（对于比训练采样时间长五倍的时间序列）。

**Conclusion:** 本文提出的统一机器学习框架具有通用性，可以应用于超越本研究中作为示例的原型系统。它能够准确预测应变合金的微观结构演化和相关参数，并且具有从实验视频中推断未知外部参数的潜力。

> **ai_Abstract:** 本文提出了一种统一的机器学习框架，专门用于模拟和预测弹性场作用下合金微观结构的时间演化。该框架能够同时提取弹性参数并预测微观结构未来的演变。研究通过旋节分解现象进行了验证，并利用卷积循环神经网络与相场模拟结果进行对比，显示出其在预测晶格失配参数和微观结构演化方面的准确性。此外，该模型还展现了良好的可扩展性和时间外推能力，并且具有通用性，有望应用于更广泛的材料系统，甚至利用实验视频进行参数推断。

> **摘要翻译:** 我们引入了一个统一的机器学习框架，旨在方便地解决弹性场影响下合金微观结构的时间演化问题。这种方法允许从短轨迹中同时提取弹性参数，并预测在这些参数影响下微观结构的进一步演化。通过关注存在晶格失配eta的旋节分解现象进行演示，并对相场模拟提供的真实演化与合适的卷积循环神经网络架构的预测结果进行了广泛比较。这两个任务随后可以在级联框架中执行。在广泛的失配条件下，本文提出的级联模型能够准确预测eta和完整的相应微观结构演化，即使在接近旋节分解的临界条件时也是如此。研究证明了对更大计算域尺寸的可扩展性，以及在时间上的轻微外推误差（对于比训练采样时间长五倍的时间序列）。所提出的框架具有通用性，可以应用于超越这里作为示例的特定原型系统。有趣的是，实验视频可以用于推断未知的外部参数，然后在模拟进一步的时间演化。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

### [388] [Reducing Data Requirements for Sequence-Property Prediction in Copolymer Compatibilizers via Deep Neural Network Tuning](https://arxiv.org/abs/2507.21902)
> *通过深度神经网络调优减少共聚物增容剂序列-性质预测的数据需求*

*Md Mushfiqul Islam, Nishat N. Labiba, Lawrence O. Hall, David S. Simmons* | **Category: cond-mat.mtrl-sci, cond-mat.soft, cond-mat.stat-mech, cs.LG, physics.chem-ph** | **Updated: 2025-07-29**

**Keywords:** 深度神经网络, 序列-性质预测, 共聚物增容剂, 数据需求, 迁移学习

**Comment:** 23 pages, 6 figures

> **TL;DR:** 本研究提出了一种深度神经网络的“预训练-调优”策略，显著减少了合成序列控制聚合物（特别是增容剂）序列-性质预测所需的数据量，使其能从低精度数据快速适应高精度预测。

**AI_Comments:** 这项研究的创新点在于提出了“预训练-调优”的深度学习策略，有效解决了合成序列控制聚合物设计中数据稀缺的痛点。其重要性在于，该方法能够大幅降低研发成本和时间，加速新型功能性聚合物材料的发现与应用，尤其在增容剂等领域具有巨大潜力。长远来看，它为结合AI与模拟数据进行原子级材料设计提供了可行路径。

<details>
  <summary>Details</summary>

**Motivation:** 合成序列控制聚合物的设计极具挑战性，因为它们缺乏像蛋白质设计那样大量相关的演化分子数据集。现有方法在不同条件下进行材料设计时，需要为每种条件创建完全独立的数据集，这导致数据需求巨大。

**Method:** 研究报告了一种新的人工智能策略，通过训练一个深度神经网络，使其首先利用一套条件下的低精度序列/界面张力关系数据进行训练，然后可以快速地针对另一套不同条件下的高精度预测进行调优，从而大幅减少所需的数据量。该方法被称为“预训练-调优”（priming-and-tuning）方法。

**Result:** 该方法显著减少了加速材料设计所需的数据量，并允许一个单一的低精度父数据集极大地加速整个相关系统群中的预测和设计。这使得在不同条件下进行序列-性质预测时，所需数据远少于常规需求。

**Conclusion:** “预训练-调优”方法能够极大地减少合成序列控制聚合物设计所需的数据量，有望通过利用快速、粗略模拟的AI洞察力来引导定量原子级设计。

> **ai_Abstract:** 本研究提出一种基于深度神经网络的“预训练-调优”人工智能策略，旨在解决合成序列控制聚合物（特别是增容剂）设计中数据量不足的挑战。通过在低精度数据集上训练模型，并快速调优以适应高精度预测条件，该方法显著减少了序列-性质预测所需的数据量，使得单一低精度数据集能够加速多个相关系统中的材料设计，为聚合物科学的发展提供了新的途径。

> **摘要翻译:** 合成序列控制聚合体有望通过结合合成聚合物的化学多功能性与生物蛋白质精确的序列介导功能来改变高分子科学。然而，这些材料的设计已被证明异常具有挑战性，因为它们缺乏大量密切相关的演化分子数据集，而这些数据集加速了蛋白质的设计。在此，我们报告了一种新的人工智能策略，可显著减少加速这些材料设计所需的数据量。我们专注于连接增容剂分子的重复单元序列与其降低不同聚合物域之间界面张力的能力的数据。这些分子（对于混合废弃聚合物回收等应用至关重要）的最佳序列强烈依赖于浓度和聚合物的化学细节等变量。使用当前方法，这将需要一个完全不同的数据集才能在每种条件下进行设计。在这里，我们展示了一个在某一套条件下针对序列/界面张力关系的低精度数据训练的深度神经网络，可以快速调优以在另一套不同条件下进行更高精度的预测，所需数据远少于通常所需。这种预训练-调优方法应该允许一个单一的低精度父数据集极大地加速整个相关系统群中的预测和设计。从长远来看，它也可能提供一种通过快速、粗略模拟的AI洞察力来引导定量原子级设计的方法。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

### [820] [Testing the spin-bath view of self-attention: A Hamiltonian analysis of GPT-2 Transformer](https://arxiv.org/abs/2507.00683)
> *测试自注意力机制的自旋浴视图：GPT-2 Transformer的哈密顿量分析*

*Satadeep Bhattacharjee, Seung-Cheol Lee* | **Category: cond-mat.mtrl-sci, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 自旋浴, 自注意力, GPT-2, 哈密顿量, 可解释性

**Comment:** 

> **TL;DR:** 本文在生产级GPT-2模型中实证检验了将大语言模型注意力机制视为自旋浴系统的物理学框架，发现理论预测与模型行为高度相关，首次提供了该自旋浴类比的强有力证据，为LLM的解释性和新模型开发提供了物理学基础。

**AI_Comments:** 这篇论文的创新之处在于，它首次在生产级大型语言模型（GPT-2）中提供了强有力的经验证据，支持将自注意力机制视为一个物理学中的自旋浴系统。这不仅将AI的内部机制与凝聚态物理学建立了深层联系，提供了一种全新的、基于物理学的可解释性视角，也为未来开发新型、更具理论基础的生成模型奠定了基础。其重要性在于，它可能为理解和设计更鲁棒、可预测的AI模型开辟新途径，超越纯粹的工程优化。

<details>
  <summary>Details</summary>

**Motivation:** 最近提出的物理学框架将大语言模型的注意力机制建模为相互作用的二体自旋系统，为重复和偏见等现象提供了第一性原理的解释。本文旨在基于此假设，对生产级GPT-2模型进行实证检验。

**Method:** 作者从生产级GPT-2模型中提取了完整的Query-Key权重矩阵，并为每个注意力头推导了相应的有效哈密顿量。基于这些哈密顿量，获得了分析相界和Logit间隙标准，以预测给定上下文下哪个token应主导下一个token的分布。通过对20个事实回忆提示中的144个注意力头进行系统评估，并进行了目标性消融实验。

**Result:** 理论Logit间隙与模型的经验token排名之间存在强烈的负相关性（r≈-0.70，p<10^-3）。目标性消融实验进一步表明，抑制与自旋浴预测最一致的注意力头会引起输出概率的预期变化，证实了因果关系而非巧合关联。

**Conclusion:** 本研究的发现首次为生产级模型中的自旋浴类比提供了强有力的经验证据。这项工作利用了上下文场视角，提供了基于物理学的可解释性，并激励了连接理论凝聚态物理和人工智能的新型生成模型的发展。

> **ai_Abstract:** 本文实证检验了将大语言模型（LLM）注意力机制建模为相互作用的二体自旋系统的物理学框架，该框架由Huo和Johnson提出。研究人员从生产级GPT-2模型中提取Query-Key权重矩阵，并推导了每个注意力头的有效哈密顿量。通过分析这些哈密顿量，他们获得了预测下一个token分布的Logit间隙标准。对GPT-2模型144个注意力头的系统评估显示，理论Logit间隙与模型经验token排名之间存在显著负相关（r≈-0.70）。进一步的消融实验证实了这种物理学模型与LLM行为之间的因果关系。这些发现首次为生产级模型中的自旋浴类比提供了强有力的经验证据，为LLM提供了基于物理学的可解释性，并为开发连接凝聚态物理与人工智能的新型生成模型提供了动力。

> **摘要翻译:** 霍和约翰逊最近提出的基于物理学的框架将大语言模型（LLM）的注意力机制建模为一个相互作用的二体自旋系统，为重复和偏见等现象提供了第一性原理的解释。基于这一假设，我们从生产级GPT-2模型中提取了完整的Query-Key权重矩阵，并为每个注意力头推导了相应的有效哈密顿量。从这些哈密顿量中，我们获得了分析相界和Logit间隙标准，这些标准可以预测在给定上下文中哪个token应该主导下一个token的分布。对20个事实回忆提示中的144个注意力头进行的系统评估揭示了理论Logit间隙与模型的经验token排名之间存在强烈的负相关性（r≈-0.70，p<10^-3）。目标性消融实验进一步表明，抑制与自旋浴预测最一致的注意力头会引起输出概率的预期变化，证实了因果关系而非巧合关联。总而言之，我们的发现首次为生产级模型中的自旋浴类比提供了强有力的经验证据。在这项工作中，我们利用了上下文场视角，这提供了基于物理学的可解释性，并激励了连接理论凝聚态物理和人工智能的新型生成模型的发展。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

<a id='statap'></a>
## stat.AP 

### [306] [Domain Generalization and Adaptation in Intensive Care with Anchor Regression](https://arxiv.org/abs/2507.21783)
> *重症监护中的领域泛化与适应与锚点回归*

*Malte Londschien, Manuel Burger, Gunnar Rätsch, Peter Bühlmann* | **Category: stat.AP, cs.LG, stat.ME, stat.ML** | **Updated: 2025-07-29**

**Keywords:** 领域泛化, 锚点回归, 重症监护, 分布偏移, 领域适应

**Comment:** 

> **TL;DR:** 本文通过锚点回归及其新扩展方法，在大规模ICU数据上研究了领域泛化，并提出了一个量化外部数据效用的框架，以改善模型在不同医院的性能下降问题。

**AI_Comments:** 这项研究通过引入因果启发式方法（锚点回归和锚点提升）来解决临床模型在跨医院部署时的领域泛化问题，具有重要意义。其创新之处在于提出了一种新颖的树基非线性扩展——锚点提升，并进行了大规模数据集验证。此外，提出的外部数据效用量化框架为实际应用提供了指导，有助于更好地利用大型异构数据。该方法对理论假设的鲁棒性也增加了其在实际临床场景中的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 临床预测模型在部署到新医院时，由于分布偏移，性能常常下降。

**Method:** 本文在大规模异构多中心重症监护病房（ICU）数据上进行了因果启发式领域泛化研究。应用了锚点回归并引入了锚点提升（一种新颖的、基于树的非线性扩展），在一个包含来自九个不同ICU数据库的40万患者的大型数据集上进行。此外，提出了一种新的概念框架来量化大型外部数据集的效用。

**Result:** 锚点正则化持续改善了分布外（OOD）性能，特别是对于最不相似的目标域。这些方法似乎对理论假设的违反（如锚点外生性）具有鲁棒性。通过评估性能作为可用目标域数据的函数，确定了三种状态：(i) 领域泛化状态，仅应使用外部模型；(ii) 领域适应状态，重新拟合外部模型是最佳选择；(iii) 数据丰富状态，外部数据不提供额外价值。

**Conclusion:** 锚点回归及其扩展方法能有效改善临床预测模型在不同ICU环境下的泛化性能，并且提出的框架有助于理解和利用大型外部数据集的价值。

> **ai_Abstract:** 本研究旨在解决临床预测模型在不同医院部署时因数据分布偏移导致的性能下降问题。通过在大规模ICU数据集上应用因果启发式领域泛化方法，包括锚点回归及其新颖的树基扩展——锚点提升，研究表明锚点正则化能持续提升模型在分布外数据上的表现，尤其是在差异较大的目标域。该方法对理论假设的违反具有鲁棒性。此外，论文还提出了一个概念框架，用于量化大型外部数据集的效用，并根据目标域数据的可用性识别出三种不同的模型使用策略：纯领域泛化、领域适应和数据丰富。

> **摘要翻译:** 由于分布偏移，临床预测模型在部署到新医院时性能常常下降。本文对异构多中心重症监护病房（ICU）数据上的因果启发式领域泛化进行了大规模研究。我们应用了锚点回归，并引入了锚点提升（一种新颖的、基于树的非线性扩展），在一个包含来自九个不同ICU数据库的40万患者的大型数据集上进行。锚点正则化持续改善了分布外（OOD）性能，特别是对于最不相似的目标域。这些方法似乎对理论假设的违反（如锚点外生性）具有鲁棒性。此外，我们提出了一种新的概念框架来量化大型外部数据集的效用。通过评估性能作为可用目标域数据的函数，我们确定了三种状态：(i) 领域泛化状态，仅应使用外部模型；(ii) 领域适应状态，重新拟合外部模型是最佳选择；(iii) 数据丰富状态，外部数据不提供额外价值。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [670] [Predicting VBAC Outcomes from U.S. Natality Data using Deep and Classical Machine Learning Models](https://arxiv.org/abs/2507.21330)
> *使用深度和经典机器学习模型从美国出生率数据预测VBAC结果*

*Ananya Anand* | **Category: stat.AP, cs.LG** | **Updated: 2025-07-28**

**Keywords:** VBAC预测, 机器学习, 出生率数据, TOLAC, 深度学习

**Comment:** 12 pages, 10 figures, 1 table

> **TL;DR:** 本研究使用深度和经典机器学习模型，基于美国出生率数据，预测剖宫产后阴道分娩（VBAC）的结果，旨在为产前咨询和降低分娩风险提供支持。

**AI_Comments:** 该研究的创新之处在于利用大规模真实世界出生率数据来预测VBAC，并比较了深度学习和经典机器学习模型的性能。其重要性在于提供了一种可扩展且实用的工具，有助于改善产前咨询和降低分娩风险，特别是在资源有限的地区。然而，模型的AUC值虽然适中，但可能仍有提升空间，且其在实际临床应用中的具体影响和接受度需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测剖宫产后试验性分娩（TOLAC）的结果对于指导产前咨询和最大程度地降低分娩相关风险至关重要。

**Method:** 本研究使用来自CDC WONDER出生率数据集（2017-2023年）的643,029例TOLAC病例，构建了监督机器学习模型来预测VBAC。数据经过筛选，仅包含单胎妊娠、一次或两次既往剖宫产以及47个产前特征的完整数据。训练了三种分类器：逻辑回归、XGBoost和多层感知器（MLP）。为解决类别不平衡问题，MLP应用了类别加权，XGBoost实现了自定义损失函数。评估指标包括ROC曲线、混淆矩阵和精确召回分析。

**Result:** MLP表现最佳，AUC为0.7287，紧随其后的是XGBoost（AUC = 0.727），两者均优于逻辑回归基线（AUC = 0.709）。逻辑回归系数突出显示孕妇BMI、教育程度、产次、合并症和产前护理指标是关键预测因子。

**Conclusion:** 总的来说，结果表明常规收集的早期妊娠变量可以支持可扩展且性能适中的VBAC预测模型。这些模型在临床决策支持中具有潜在的实用性，特别是在缺乏专业产时数据的环境中。

> **ai_Abstract:** 本研究利用2017-2023年美国CDC WONDER出生率数据集中的64万余例TOLAC病例，开发并评估了基于深度学习（MLP）和经典机器学习（XGBoost、逻辑回归）的VBAC预测模型。研究发现，MLP和XGBoost在预测性能上优于逻辑回归，AUC分别达到0.7287和0.727。模型显示，常规收集的早期妊娠变量（如BMI、教育、产次、合并症和产前护理）可有效支持VBAC预测，为临床决策提供支持，尤其适用于缺乏专业产时数据的环境。

> **摘要翻译:** 准确预测剖宫产后试验性分娩（TOLAC）的结果对于指导产前咨询和最大程度地降低分娩相关风险至关重要。本研究提出了监督机器学习模型，利用CDC WONDER出生率数据集（2017-2023年）中的643,029例TOLAC病例来预测剖宫产后阴道分娩（VBAC）。在筛选出单胎妊娠、一次或两次既往剖宫产以及47个产前特征的完整数据后，训练了三种分类器：逻辑回归、XGBoost和多层感知器（MLP）。MLP取得了最高性能，AUC为0.7287，紧随其后的是XGBoost（AUC = 0.727），两者均超过了逻辑回归基线（AUC = 0.709）。为了解决类别不平衡问题，对MLP应用了类别加权，并在XGBoost中实现了自定义损失函数。评估指标包括ROC曲线、混淆矩阵和精确召回分析。逻辑回归系数突出显示孕妇BMI、教育程度、产次、合并症和产前护理指标是关键预测因子。总的来说，结果表明常规收集的早期妊娠变量可以支持可扩展且性能适中的VBAC预测模型。这些模型在临床决策支持中具有潜在的实用性，特别是在缺乏专业产时数据的环境中。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

<a id='econem'></a>
## econ.EM 

### [327] [Can large language models assist choice modelling? Insights into prompting strategies and current models capabilities](https://arxiv.org/abs/2507.21790)
> *大型语言模型能否辅助选择建模？提示策略与当前模型能力的洞察*

*Georges Sfeir, Gabriel Nova, Stephane Hess, Sander van Cranenburgh* | **Category: econ.EM, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 大型语言模型, 选择建模, 提示策略, 多项Logit模型, 模型规范

**Comment:** 32 pages, 6 figures, 14 tables

> **TL;DR:** 本文系统性探讨了大型语言模型（LLMs）在选择建模中辅助模型规范和估计的潜力，发现专有LLMs表现良好，特别是Claude 4 Sonnet和GPT系列，并提供了集成LLMs到建模工作流的实用指导。

**AI_Comments:** 这项研究具有重要的实践意义，它系统性地评估了LLMs在复杂建模任务中的能力，特别是强调了提示策略和数据提供方式对LLM表现的影响。发现专有模型表现优于开源模型，以及GPT o3的自估计能力是亮点。这项工作为将LLMs集成到专业领域工作流提供了初步的、有价值的指导和见解，但同时也指出了当前模型的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）已被广泛应用于不同学科的各种工作流程中，然而它们在选择建模领域的潜力尚未得到充分探索。本研究旨在检验LLMs作为辅助代理在多项Logit模型（Multinomial Logit models）的规范以及在技术可行的情况下进行估计的潜力。

**Method:** 研究实施了一个系统的实验框架，涉及六个领先LLMs（ChatGPT、Claude、DeepSeek、Gemini、Gemma和Llama）的十三个版本。这些模型在五种实验配置下进行评估，配置维度包括：建模目标（建议与建议并估计MNL模型）、提示策略（零样本与思维链）和信息可用性（完整数据集与仅数据字典）。每个LLM建议的规范都根据拟合优度指标、行为合理性和模型复杂性进行实现、估计和评估。

**Result:** 研究发现，专有LLMs能够生成有效且行为合理的效用规范，尤其是在结构化提示的引导下。开源模型如Llama和Gemma在生成有意义的规范方面表现不佳。Claude 4 Sonnet持续生成拟合最佳且最复杂的模型，而GPT模型建议的模型具有稳健和稳定的建模结果。一些LLMs在仅提供数据字典时表现更好，这表明限制原始数据访问可能增强其内部推理能力。在所有LLMs中，GPT o3是唯一能够通过执行自生成代码正确估计其自身规范的模型。

**Conclusion:** 研究结果展示了大型语言模型作为选择建模中辅助代理的潜力和当前局限性，不仅适用于模型规范，也适用于支持建模决策和估计。本研究为将这些工具集成到选择建模师的工作流程中提供了实用指导。

> **ai_Abstract:** 本文系统性地探究了大型语言模型（LLMs）在选择建模中辅助多项Logit模型规范和估计的潜力。通过对六大主流LLMs的十三种版本在不同提示策略和数据可用性下的评估，研究发现专有LLMs在生成有效且行为合理的模型规范方面表现出色，尤其是在结构化提示下。Claude 4 Sonnet和GPT模型展现出较强的能力，其中GPT o3甚至能通过自生成代码进行模型估计。研究还指出，限制原始数据访问可能提升LLMs的推理能力。总体而言，该工作揭示了LLMs在选择建模中的应用前景与现有局限，并提供了实践指导。

> **摘要翻译:** 大型语言模型（LLMs）被广泛用于支持不同学科的各种工作流程，但它们在选择建模中的潜力仍相对未被探索。这项工作探讨了LLMs作为辅助代理在多项Logit模型（Multinomial Logit models）的规范以及在技术可行的情况下进行估计的潜力。我们实施了一个系统的实验框架，涉及六个领先LLMs（ChatGPT、Claude、DeepSeek、Gemini、Gemma和Llama）的十三个版本，并在五种实验配置下进行评估。这些配置在三个维度上有所不同：建模目标（建议与建议并估计MNL模型）；提示策略（零样本与思维链）；以及信息可用性（完整数据集与仅数据字典）。每个LLM建议的规范都根据拟合优度指标、行为合理性和模型复杂性进行实现、估计和评估。研究结果表明，专有LLMs可以生成有效且行为合理的效用规范，尤其是在结构化提示的引导下。Llama和Gemma等开源模型难以生成有意义的规范。Claude 4 Sonnet持续生成拟合最佳且最复杂的模型，而GPT模型建议的模型具有稳健和稳定的建模结果。一些LLMs在仅提供数据字典时表现更好，这表明限制原始数据访问可能增强内部推理能力。在所有LLMs中，GPT o3是唯一能够通过执行自生成代码正确估计其自身规范的模型。总的来说，结果展示了LLMs作为选择建模中的辅助代理的潜力和当前局限性，不仅适用于模型规范，也适用于支持建模决策和估计，并为将这些工具集成到选择建模师的工作流程中提供了实用指导。

</details>

[⬆️ 返回分类顶部](#econem) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [355] [Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division](https://arxiv.org/abs/2507.14957)
> *探测EFX通过PMMS：离散公平分配中的（非）存在性结果*

*Jarosław Byrka, Franciszek Malinka, Tomasz Ponitka* | **Category: cs.GT, cs.AI, cs.DS** | **Updated: 2025-07-30**

**Keywords:** 公平分配, EFX, PMMS, 不可分割物品, 存在性

**Comment:** 27 pages, 4 figures

> **TL;DR:** 本文研究了不可分割物品的公平分配，证明了PMMS分配在某些情况下不存在，从而区分了EFX和PMMS。同时，为几种特殊的估值情况证明了EFX或PMMS分配的存在性，并提供了多项式时间算法。

**AI_Comments:** 这篇论文在公平分配领域的核心开放问题——EFX和PMMS的研究上取得了重要进展。其创新点在于首次明确区分了EFX和PMMS的存在性，并通过构造性证明为多种特殊但重要的估值场景提供了公平分配的存在性保证和可行的多项式时间算法。这对于理论研究和实际应用都具有重要意义，尤其是在处理特定类型估值时的公平分配方案设计。

<details>
  <summary>Details</summary>

**Motivation:** 公平分配中的EFX问题是核心开放问题，PMMS是EFX的更强变体。理解这两种分配概念的存在性及其关系对于理论研究和实际应用都至关重要。

**Method:** 通过构造反例证明PMMS分配的非存在性，从而分离EFX和PMMS。对于特定类型的估值函数，通过构造性证明方法，建立EFX和PMMS分配的存在性，并为这些存在性结果提供了多项式时间算法。

**Result:** 构建了一个三代理实例，其中不存在PMMS分配，从而正式区分了EFX和PMMS。证明了在个性化双值估值下EFX分配的存在性。证明了在个性化双值估值且$a_i$可被$b_i$整除时PMMS分配的存在性。证明了在二值MMS可行估值下PMMS分配的存在性，即使没有估值的单调性假设。证明了在对需求估值下PMMS分配的存在性。所有的存在性证明都是建设性的，并提供了多项式时间算法。

**Conclusion:** 本文通过证明PMMS的非存在性来区分EFX和PMMS，并通过构造性方法证明了在多种重要特殊估值情况下EFX或PMMS分配的存在性，为公平分配领域的核心问题提供了新的见解和算法。

> **ai_Abstract:** 本文深入研究了不可分割物品的公平分配问题，特别是EFX和PMMS。研究首先通过构造反例证明了PMMS分配在特定条件下不存在，从而明确区分了EFX和PMMS。接着，论文针对个性化双值估值、二值MMS可行估值和对需求估值等三种重要特殊情况，通过构造性方法证明了EFX或PMMS分配的存在性，并提供了相应的多项式时间算法。这些结果为理解和解决公平分配中的核心挑战提供了新的理论基础和实用工具。

> **摘要翻译:** 我们研究了不可分割物品的公平分配，并为EFX问题和PMMS问题提供了新的见解。EFX问题被广泛认为是公平分配中的核心开放问题，而PMMS问题是EFX的一个严格更强的变体。我们的第一个结果构建了一个三代理实例，其中包含两种单调估值和一种加性估值，但不存在PMMS分配。由于已知在这些假设下EFX分配是存在的，这正式确立了EFX和PMMS之间的分离。
我们证明了三种重要特殊情况下公平分配的存在性。我们表明，对于个性化双值估值，即对于每个代理i，存在值$a_i > b_i$，使得代理i将值$v_i(\{g\}) \in \{a_i, b_i\}$分配给每个物品g，EFX分配是存在的。当$a_i$可以被$b_i$整除时，我们为PMMS分配建立了类似的存在性结果。我们还证明了对于二值MMS可行估值，即每个捆绑S的值$v_i(S) \in \{0, 1\}$，PMMS分配是存在的。值得注意的是，这一结果甚至在不假设估值单调性的情况下也成立，因此适用于家务和混合物品的公平分配。最后，我们研究了一类称为对需求估值的估值，它将广受研究的单位需求估值扩展到每个代理最多从两件物品中获得价值的情况，并且我们表明在此设置下PMMS分配是存在的。我们的证明是建设性的，并且我们为所有三种存在性结果提供了多项式时间算法。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [843] [Games on Graphs: From Logic and Automata to Algorithms](https://arxiv.org/abs/2305.10546)
> *图上博弈：从逻辑与自动机到算法*

*Nathanaël Fijalkow, C. Aiswarya, Guy Avni, Nathalie Bertrand, Patricia Bouyer, Romain Brenguier, Arnaud Carayol, Antonio Casares, John Fearnley, Paul Gastin, Hugo Gimbert, Thomas A. Henzinger, Florian Horn, Rasmus Ibsen-Jensen, Nicolas Markey, Benjamin Monmege, Petr Novotný, Pierre Ohlmann, Mickael Randour, Ocan Sankur, Sylvain Schmitz, Olivier Serre, Mateusz Skomra, Nathalie Sznajder, Pierre Vandenhove* | **Category: cs.GT, cs.FL, cs.LO** | **Updated: 2025-07-29**

**Keywords:** 图上博弈, 无限持续博弈, 自动机, 逻辑, 程序验证

**Comment:** 621 pages. Coordinator: Nathana\"el Fijalkow

> **TL;DR:** 本书全面介绍了图上无限持续博弈的研究领域及其在程序验证、综合及其他邻近领域的应用。

**AI_Comments:** 本书的创新之处在于其作为一本综合性著作，系统地整合了图上博弈这一跨学科领域的研究成果。其重要性体现在该领域在程序验证、综合以及多个邻近研究社区中的广泛应用和深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 本书旨在全面介绍图上无限持续博弈的研究领域，该领域在历史上起源于自动机和逻辑研究，后来对程序验证和综合变得非常重要，并且在优化、强化学习、模型理论和集合论等邻近研究社区中也有应用。

**Method:** 本书旨在全面呈现图上无限持续博弈的研究领域，而非提出新的研究方法。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本书全面概述了图上无限持续博弈的研究领域。该领域起源于自动机和逻辑，并发展成为程序验证和综合的关键工具，同时在优化、强化学习、模型理论和集合论等多个相关学科中也发现了广泛应用。

> **摘要翻译:** 本书的目标是全面介绍关于图上无限持续博弈的研究领域。从历史上看，这些博弈模型出现在自动机和逻辑的研究中，后来对程序验证和综合变得非常重要。它们还有许多其他应用，特别是本书中研究的一些模型是在优化、强化学习、模型理论和集合论等邻近研究社区中引入和研究的。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [362] [Representations in vision and language converge in a shared, multidimensional space of perceived similarities](https://arxiv.org/abs/2507.21871)
> *视觉和语言中的表征在一个共享的、多维的感知相似性空间中趋同*

*Katerina Marie Simkova, Adrien Doerig, Clayton Hickey, Ian Charest* | **Category: q-bio.NC, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 视觉表征, 语言表征, 感知相似性, 大型语言模型, fMRI

**Comment:** 51 pages, 15 figures

> **TL;DR:** 视觉和语言的相似性判断在行为和大脑层面都趋同，并且与大型语言模型（LLMs）的嵌入空间一致，表明存在一个共享的、跨模态的表征结构。

**AI_Comments:** 本研究通过结合行为学、神经影像学和计算模型的方法，为视觉和语言表征的跨模态共享性提供了强有力的证据。其创新之处在于证明了这种共享性不仅存在于大脑层面，也体现在人类行为中，并与LLMs的表征空间相吻合，为理解人类概念形成机制和多模态AI的发展提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有证据表明大型语言模型（LLMs）的语义特征空间能很好地预测视觉和语言的大脑表征，但这未能阐明这种共享空间如何在人类行为中体现。

**Method:** 63名参与者对100张自然场景图像和100个对应句子标题进行了行为相似性判断，并测量了fMRI大脑反应。此外，训练计算模型将图像映射到LLM嵌入，并与类别训练模型和AlexNet进行比较。

**Result:** 视觉和语言的相似性判断在行为层面趋同，并预测了由自然场景图像引起的相似fMRI大脑反应网络。将图像映射到LLM嵌入的计算模型在解释行为相似性结构方面优于类别训练模型和AlexNet。

**Conclusion:** 人类的视觉和语言相似性判断基于一个共享的、与模态无关的表征结构，该结构反映了视觉系统编码经验的方式。感官系统和人工系统之间的趋同表明概念表征的形成并非任意，而是反映外部世界稳定关系属性的结构化表征。

> **ai_Abstract:** 本研究探讨了人类视觉和语言表征如何在一个共享的、多维空间中趋同。通过行为相似性判断、fMRI数据和计算模型，研究发现视觉和语言的相似性判断在行为和大脑层面均趋同，且与大型语言模型（LLMs）的嵌入空间高度一致。这表明人类的感官系统可能共享一个模态无关的表征结构，该结构反映了外部世界的稳定关系属性。

> **摘要翻译:** 人类可以毫不费力地描述他们所看到的东西，但建立视觉和语言之间共享的表征格式仍然是一个重大挑战。新兴证据表明，人类大脑在视觉和语言方面的表征可以通过从大型语言模型（LLMs）获得的语义特征空间很好地预测。这提出了感官系统在其将输入转换为共享的、类似嵌入的表征空间的内在能力方面趋同的可能性。然而，这种空间如何在人类行为中体现仍不清楚。为了调查这一点，63名参与者分别对100张自然场景图像和来自自然场景数据集的100个相应句子标题进行了行为相似性判断。我们发现，视觉和语言的相似性判断不仅在行为层面趋同，而且还预测了通过观看自然场景图像所诱发的惊人相似的fMRI大脑反应网络。此外，训练用于将图像映射到LLM嵌入的计算模型在解释行为相似性结构方面优于类别训练模型和AlexNet对照组。这些发现表明，人类的视觉和语言相似性判断基于一个共享的、与模态无关的表征结构，该结构反映了视觉系统编码经验的方式。感官系统和人工系统之间的趋同表明概念表征的共同能力是如何形成的——不是作为第一阶、模态特定输入的任意产物，而是作为反映外部世界稳定关系属性的结构化表征。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

### [404] [Make Silence Speak for Itself: a multi-modal learning analytic approach with neurophysiological data](https://arxiv.org/abs/2507.21063)
> *让沉默为自己发声：一种结合神经生理数据的多模态学习分析方法*

*Mingxuan Gao, Jingjing Chen, Yun Long, Xiaomeng Xu, Yu Zhang* | **Category: q-bio.NC, cs.CY** | **Updated: 2025-05-23**

**Keywords:** 课堂沉默, 神经生理学, 多模态学习分析, 学习状态, 成就差异

**Comment:** 25 pages, 6 figures

> **TL;DR:** 本研究通过多模态数据（脑电、皮电、心率和视频）分析了课堂沉默，发现不同成就学生在不同类型沉默下的生理反应差异，挑战了沉默等同于被动的传统观念。

**AI_Comments:** 创新点在于将神经生理数据与课堂沉默研究相结合，并提出了新的沉默分类框架，深化了对沉默作为积极学习行为的理解。研究结果对教育实践具有潜在意义，有助于教师更好地识别和利用学生的沉默状态。

<details>
  <summary>Details</summary>

**Motivation:** 课堂沉默普遍存在，但其隐含性质限制了对学生潜在学习状态的清晰理解。

**Method:** 本研究提出了一种基于课堂事件和学生状态的课堂沉默分类框架，并检查了神经生理学标记（EEG、EDA、心率）以揭示不同成就组在沉默状态下的异同。研究样本为54名中学生，在34节数学课中同时记录了EEG、EDA、心率信号以及课堂行为的视频编码。

**Result:** 高成就学生在开放提问中的策略性沉默与主动发言相比，平均EDA特征无显著差异，但策略性沉默期间EEG高频RPSD更高。在高成就学生在定向提问中的结构性沉默期间，听讲时心率显著高于小组活动。高成就和中等成就学生在提问中的结构性沉默期间，心率和EDA张力成分均高于教学期间。高成就学生在结构性沉默期间的EEG高频RPSD低于策略性沉默，此模式未在其他组观察到，突显了群体异质性。

**Conclusion:** 研究结果有助于验证沉默的复杂性，挑战了其与被动性相关的传统观念，并提供了一个新颖的分类框架和初步的实证证据，以加深对课堂环境中沉默学习行为的理解。

> **ai_Abstract:** 本研究采用多模态学习分析方法，结合神经生理数据（EEG、EDA、心率）和视频编码，对课堂沉默进行了深入探究。研究提出了一个基于课堂事件和学生状态的沉默分类框架，并分析了不同成就学生在策略性沉默和结构性沉默下的生理反应差异。结果表明，沉默并非简单的被动状态，而是复杂的学习行为，不同成就学生在不同类型的沉默中表现出独特的神经生理特征，挑战了传统观念，为理解课堂沉默提供了新的视角。

> **摘要翻译:** 背景：沉默在课堂中是普遍现象，但其隐含性质限制了对学生潜在学习状态的清晰理解。目的：本研究提出了一种细致的框架，根据课堂事件和学生状态对课堂沉默进行分类，并检查神经生理学标记以揭示不同成就组在沉默状态下的异同。样本：该研究涉及54名中学生，在34节数学课中进行，同时记录了脑电图 (EEG)、皮电活动 (EDA) 和心率信号，并对课堂行为进行视频编码。结果：我们发现，高成就学生在开放提问中的策略性沉默（即学生有意识地选择沉默）与主动发言之间，平均EDA特征没有显著差异，但在策略性沉默期间表现出更高的EEG高频相对功率谱密度 (RPSD)。在定向提问中的结构性沉默（即学生遵循外部指令保持沉默）期间，与小组活动相比，他们在听讲时表现出显著更高的心率，表明参与度更高。高成就和中等成就学生在提问中的结构性沉默期间，心率和EDA张力成分均高于教学期间。此外，高成就学生在结构性沉默期间的EEG高频RPSD低于策略性沉默，其他组未观察到此模式，突显了群体异质性。结论：研究结果有助于验证沉默的复杂性，挑战了其与被动性相关的传统观念，并提供了一个新颖的分类框架以及初步的实证证据，以加深对课堂环境中沉默学习行为的理解。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

### [516] [Signed Higher-Order Interactions for Brain Disorder Diagnosis via Multi-Channel Transformers](https://arxiv.org/abs/2507.20205)
> *经由多通道Transformer的带符号高阶交互用于脑疾病诊断*

*Dengyi Zhao, Zhiheng Zhou, Guiying Yan, Dongxiao Yu, Xingqin Qi* | **Category: q-bio.NC, cs.GR** | **Updated: 2025-07-30**

**Keywords:** 高阶交互, 脑疾病诊断, 功能性磁共振成像, Transformer, 持久同调

**Comment:** 

> **TL;DR:** 提出HOI-Brain框架，利用带符号高阶交互和多通道Transformer从fMRI数据中诊断脑疾病，克服了传统方法忽视高阶交互的局限性，并表现出优越的性能和可解释性。

**AI_Comments:** 这篇论文的创新点在于其突破了传统图模型仅关注成对或三元交互的局限，首次引入了“带符号高阶交互”的概念，并通过结合持久同调理论和多通道Transformer，有效地从fMRI数据中提取和整合了复杂的拓扑特征。这种方法不仅提升了脑疾病诊断的准确性，还提供了更深层次的生物学解释，对于理解全脑通信模式具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于图的深度学习模型主要关注脑区之间的成对或三元交互，忽视了带符号的高阶交互，限制了对全脑通信的全面理解，而这对于脑疾病诊断至关重要。

**Method:** 提出HOI-Brain框架。首先，引入基于时间导数乘积的共波动度量来检测具有时间分辨率的高阶交互。然后，区分正负协同交互，并将其编码到带符号加权单纯复形中。接着，利用持久同调理论对这些复形应用两种过滤过程，以时空方式提取带符号的高维神经组织。最后，提出一个多通道脑Transformer来整合异构拓扑特征。

**Result:** 在阿尔茨海默病、帕金森综合征和自闭症谱系障碍数据集上的实验证明了该框架的优越性、有效性和可解释性。识别出的关键脑区和高阶模式与神经科学文献一致，提供了有意义的生物学见解。

**Conclusion:** 该研究成功开发并验证了HOI-Brain框架，该框架通过利用带符号的高阶交互和多通道Transformer，显著提高了脑疾病诊断的准确性和可解释性，并为神经科学研究提供了新的生物学见解。

> **ai_Abstract:** 本文提出了HOI-Brain，一个利用带符号高阶交互和多通道Transformer进行脑疾病诊断的新框架。该框架通过引入时间导数乘积的共波动度量来检测高阶交互，并将其编码为带符号加权单纯复形。结合持久同调理论提取时空高维神经组织特征，并使用多通道Transformer整合这些特征。实验结果表明，HOI-Brain在阿尔茨海默病、帕金森综合征和自闭症谱系障碍的诊断中表现出优越性、有效性和良好的可解释性，且识别出的模式与神经科学发现一致。

> **摘要翻译:** 准确表征大脑区域的高阶交互并从功能性磁共振成像数据中提取可解释的组织模式对于脑疾病诊断至关重要。当前基于图的深度学习模型主要关注成对或三元模式，同时忽视了带符号的高阶交互，限制了对全脑通信的全面理解。我们提出了HOI-Brain，一个新颖的计算框架，利用fMRI数据中的带符号高阶交互和组织模式进行脑疾病诊断。首先，我们引入了一种基于时间导数乘积的共波动度量来检测具有时间分辨率的高阶交互。然后，我们区分正负协同交互，并将它们编码在带符号加权单纯复形中，以揭示大脑通信的见解。利用持久同调理论，我们对这些复形应用两种过滤过程，以时空方式提取带符号的高维神经组织。最后，我们提出了一个多通道脑Transformer来整合异构拓扑特征。在阿尔茨海默病、帕金森综合征和自闭症谱系障碍数据集上的实验证明了我们框架的优越性、有效性和可解释性。识别出的关键脑区和高阶模式与神经科学文献一致，提供了有意义的生物学见解。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='mathat'></a>
## math.AT 

### [412] [Exploring the Stratified Space Structure of an RL Game with the Volume Growth Transform](https://arxiv.org/abs/2507.22010)
> *探索RL游戏中分层空间结构与体积增长变换*

*Justin Curry, Brennan Lagasse, Ngoc B. Lam, Gregory Cox, David Rosenbluth, Alberto Speranzon* | **Category: math.AT, cs.AI, cs.CG, cs.LG, math.DG, 58A35** | **Updated: 2025-07-29**

**Keywords:** 强化学习, Transformer模型, 嵌入空间, 分层空间, 体积增长变换

**Comment:** 17 pages and 8 figures. Preliminary report. Feedback welcome!

> **TL;DR:** 研究发现强化学习（RL）游戏中Transformer模型的嵌入空间是分层空间，其局部维度变化与智能体行为和环境复杂性相关，为RL游戏复杂性提供了新的几何指标。

**AI_Comments:** 这项研究通过将体积增长变换从LLM领域引入RL领域，为理解RL智能体潜在表征的几何结构提供了新视角，具有创新性。其发现RL嵌入空间是分层而非流形，并揭示了维度变化与智能体行为和环境复杂性的关联，为RL的复杂性度量提供了潜在的新方法。这有助于未来设计更高效、可解释的RL模型。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探索在特定强化学习（RL）游戏（智能体需收集金币并避开动态障碍物）中，Transformer模型如何嵌入视觉输入，并分析其嵌入空间的结构。

**Method:** 研究方法是：1. 将Robinson等人针对大型语言模型（LLMs）的体积增长变换（volume growth transform）研究方法应用于RL设置。2. 通过证明相当普遍的体积增长曲线可以通过分层空间实现，从而强化了Robinson的方法。3. 对RL智能体的潜在表征进行分析，观察其局部维度如何随行为和环境变化而变化。

**Result:** 研究发现：1. 视觉金币收集游戏的token嵌入空间不是一个流形，而是更好地被建模为一个分层空间，其中局部维度可以从一个点到另一个点变化。2. 强化学习智能体在行动时，其潜在表征在低局部维度时期（遵循固定子策略）和高局部维度爆发时期（实现子目标或环境复杂性增加）之间交替。

**Conclusion:** 研究结果表明，分层潜在空间中维度的分布可能为强化学习游戏的复杂性提供一个新的几何指标。

> **ai_Abstract:** 本文研究了强化学习（RL）游戏中Transformer模型对视觉输入的嵌入空间结构。通过将体积增长变换方法应用于RL设置，研究发现该嵌入空间并非流形，而更适合建模为局部维度可变的分层空间。进一步分析揭示，RL智能体的潜在表征维度会根据其行为（如遵循策略或达成子目标）和环境复杂性（如障碍物增多）进行周期性变化。这项工作提出，分层潜在空间中维度的分布可作为衡量RL游戏复杂性的新型几何指标。

> **摘要翻译:** 在这项工作中，我们探索了为玩特定强化学习（RL）游戏而训练的Transformer模型的嵌入空间结构。具体来说，我们研究了基于Transformer的近端策略优化（PPO）模型如何在智能体必须收集“金币”同时避开由“聚光灯”组成的动态障碍物的简单环境中嵌入视觉输入。通过将Robinson等人针对LLM的体积增长变换研究方法应用于RL设置，我们发现我们的视觉金币收集游戏的token嵌入空间也不是一个流形，而是更好地被建模为一个分层空间，其中局部维度可以从一个点到另一个点变化。我们通过证明相当普遍的体积增长曲线可以通过分层空间实现，从而进一步强化了Robinson的方法。最后，我们进行了一项分析，表明当RL智能体行动时，其潜在表征在低局部维度时期（遵循固定子策略）和高局部维度爆发时期（智能体实现子目标，例如收集一个物体；或环境复杂性增加，例如出现更多障碍物）之间交替。因此，我们的工作表明，分层潜在空间中维度的分布可能为RL游戏的复杂性提供一个新的几何指标。

</details>

[⬆️ 返回分类顶部](#mathat) | [⬆️ 返回总目录](#toc)

---

<a id='q-finpm'></a>
## q-fin.PM 

### [456] [End-to-End Large Portfolio Optimization for Variance Minimization with Neural Networks through Covariance Cleaning](https://arxiv.org/abs/2507.01918)
> *通过协方差清洗实现神经网络端到端大投资组合方差最小化优化*

*Christian Bongiorno, Efstratios Manolakis, Rosario Nunzio Mantegna* | **Category: q-fin.PM, cs.AI, math.OC, physics.data-an, stat.ML, 91G10 (Primary) 68T07, 91G60, 62P05 (Secondary), I.2.6; I.5.1; G.3; J.4** | **Updated: 2025-07-29**

**Keywords:** 投资组合优化, 方差最小化, 神经网络, 协方差清洗, 机器学习

**Comment:** 

> **TL;DR:** 本文开发了一种旋转不变神经网络，通过联合学习历史收益的滞后变换以及大型股票协方差矩阵的特征值和边际波动性的正则化，提供全局最小方差投资组合，并在样本外测试中表现优于现有分析方法。

**AI_Comments:** 该论文的创新之处在于将神经网络应用于大规模投资组合的协方差清洗和方差最小化问题，并明确强调了其模型的旋转不变性和可解释性，避免了传统黑箱模型的缺点。其在样本外测试中表现出的优异泛化能力和在现实交易条件下的稳健性，表明了其在实际资产管理中的巨大潜力。特别是其能够处理千只股票规模的投资组合，并超越了最先进的分析方法，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的投资组合优化方法在处理大型股票协方差矩阵时存在局限性，特别是在最小化方差方面。本文旨在开发一种新的端到端神经网络方法来解决这一问题，以提供更优的全局最小方差投资组合。

**Method:** 开发了一种旋转不变神经网络，该网络通过联合学习如何对历史收益进行滞后变换，以及如何对大型股票协方差矩阵的特征值和边际波动性进行正则化，从而提供全局最小方差投资组合。该模型架构模仿全局最小方差解决方案的分析形式，且与维度无关，能够在一个模型上进行校准并应用于不同规模的股票面板。损失函数是未来实现的最小投资组合方差，并在实际日收益数据上进行端到端优化。

**Result:** 在2000年1月至2024年12月的样本外测试中，该估计器系统性地实现了比最佳分析竞争对手（包括最先进的非线性收缩方法）更低的实际波动性、更小的最大回撤和更高的夏普比率。即使在长期持仓约束下，其学习到的协方差表示在通用优化器中也能保持性能优势。在考虑市场订单、经验滑点、交易费用和杠杆融资费用的高度现实的实施框架下，这些收益依然持续存在，并在市场剧烈压力期间保持稳定。

**Conclusion:** 该研究成功开发了一种端到端神经网络模型，通过协方差清洗实现了大型投资组合的方差最小化，并在实际市场条件下展现出卓越的样本外泛化能力和性能优势，即使在考虑交易成本和市场压力的情况下也表现稳健。

> **ai_Abstract:** 本文提出了一种旋转不变神经网络，用于通过协方差清洗实现大型投资组合的方差最小化。该模型通过联合学习历史收益变换和协方差矩阵的正则化，提供全局最小方差投资组合。它具有良好的可解释性，并能跨维度泛化。在真实日收益数据上的端到端优化显示，该模型在样本外测试中表现出更低的波动性、更小的最大回撤和更高的夏普比率，显著优于现有分析方法。即使在考虑现实交易约束和市场压力下，其性能优势依然保持。

> **摘要翻译:** 我们开发了一种旋转不变神经网络，通过联合学习如何对历史收益进行滞后变换以及如何对大型股票协方差矩阵的特征值和边际波动性进行正则化，从而提供全局最小方差投资组合。这种明确的数学映射提供了每个模块作用的清晰可解释性，因此该模型不能被视为一个纯粹的黑箱。该架构模仿全局最小方差解决方案的分析形式，但与维度无关，因此一个单一模型可以在数百只股票的面板上进行校准，并且无需重新训练即可应用于一千只美国股票——这种跨截面跳跃展示了稳健的样本外泛化能力。损失函数是未来实现的最小投资组合方差，并在实际日收益数据上进行端到端优化。在2000年1月至2024年12月的样本外测试中，该估计器系统性地实现了比最佳分析竞争对手（包括最先进的非线性收缩方法）更低的实际波动性、更小的最大回撤和更高的夏普比率。此外，尽管该模型是端到端训练以产生一个无约束（多空）最小方差投资组合，但我们表明其学习到的协方差表示可以在长期持仓约束下的通用优化器中使用，其相对于竞争估计器的性能优势几乎没有损失。当策略在高度现实的实施框架下执行时，这些收益依然持续存在，该框架模拟了拍卖市场订单、经验滑点、交易费用和杠杆融资费用，并且在市场剧烈压力期间保持稳定。

</details>

[⬆️ 返回分类顶部](#q-finpm) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [503] [An empirical comparison of some outlier detection methods with longitudinal data](https://arxiv.org/abs/2507.21203)
> *纵向数据中一些异常值检测方法的实证比较*

*Marcello D'Orazio* | **Category: stat.ME, cs.LG, stat.AP** | **Updated: 2025-07-28**

**Keywords:** 异常值检测, 纵向数据, 机器学习, 数据挖掘, 实证比较

**Comment:** 

> **TL;DR:** 本文对纵向数据中异常值检测方法进行了实证比较，对比了传统统计方法与数据挖掘和机器学习方法，发现后者通常更灵活且有时更有效。

**AI_Comments:** 这项研究通过实证比较，为纵向数据中的异常值检测提供了有价值的见解。其创新点在于将传统统计方法与新兴的数据挖掘和机器学习技术进行对比。研究强调了新方法在灵活性和多维数据处理方面的优势，这对于处理复杂数据集具有重要意义。局限性在于所有方法都需要用户进行参数调优，这可能需要专业知识和经验。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究纵向数据中的异常值检测问题，并通过实证比较不同方法的性能。

**Method:** 该研究将官方统计中常用的异常值检测方法与数据挖掘和机器学习领域基于观测距离或二元划分树的方法进行比较。通过将这些方法应用于与不同类型统计单位相关的面板调查数据来完成实证分析。

**Result:** 传统方法简单直接，可直接识别潜在异常值，但有特定假设。最新方法提供异常值可能性得分。所有方法都需要调参。最新方法比传统方法更灵活，有时更有效，并且可以应用于多维数据。

**Conclusion:** 在纵向数据中，最新（数据挖掘和机器学习）的异常值检测方法比传统方法更灵活，有时也更有效，并且能够处理多维数据。

> **ai_Abstract:** 本文对纵向数据中的异常值检测方法进行了实证比较。研究对比了官方统计中的传统方法与数据挖掘及机器学习领域的新方法，后者基于观测距离或二元划分树。通过在面板调查数据上应用这些方法，发现传统方法虽然简单直接但有假设限制，而新方法提供异常值分数，更灵活，有时更有效，并支持多维数据分析，尽管所有方法都需要参数调优。

> **摘要翻译:** 本文探讨了纵向数据中异常值检测的问题。它将官方统计中常用的方法与数据挖掘和机器学习领域中基于观测值之间距离或二元划分树的方法进行了比较。通过将这些方法应用于与不同类型统计单位相关的面板调查数据来实现这一目标。传统方法相当简单，可以直接识别潜在异常值，但它们需要特定的假设。相比之下，最新方法只提供一个分数，其大小与异常值存在的可能性直接相关。所有方法都要求用户设置多个调整参数。然而，最新方法比传统方法更灵活，有时也更有效。此外，这些方法可以应用于多维数据。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [749] [Derivative Estimation from Coarse, Irregular, Noisy Samples: An MLE-Spline Approach](https://arxiv.org/abs/2507.22176)
> *从粗糙、不规则、带噪声样本中估计导数：一种MLE-样条方法*

*Konstantin E. Avrachenkov, Leonid B. Freidovich* | **Category: stat.ME, cs.SY, eess.SY, math.OC, math.PR** | **Updated: 2025-07-29**

**Keywords:** 数值微分, 最大似然估计, 样条函数, 噪声采样, 在线算法

**Comment:** 

> **TL;DR:** 本文提出了一种基于最大似然估计（MLE）和样条函数的方法，用于在粗糙、不均匀和高噪声采样条件下进行数值微分，并开发了在线算法，在仿真中表现优于现有方法。

**AI_Comments:** 这项研究的创新之处在于结合了最大似然估计和样条函数来解决在恶劣采样条件下（粗糙、不规则、高噪声）的导数估计问题。其提出的在线算法和两种公式（二次和零阶）在实用性上具有优势，特别是对于那些无法实现高采样率的系统具有重要意义。该方法在仿真中表现出的优越性表明了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在解决在粗糙、非均匀采样和高斯噪声条件下进行数值微分的挑战，尤其适用于高采样率不切实际的系统。

**Method:** 通过对高阶导数施加L2范数约束，获得了一个最大似然估计器，从而得到了基于样条的解决方案。引入了二次样条的非标准参数化，并开发了递归在线算法。提供了二次和零阶两种公式，以权衡平滑度和计算速度。

**Result:** 仿真结果表明，在粗糙采样和高噪声条件下，该方法在性能上优于高增益观测器和超扭曲微分器。

**Conclusion:** 该MLE-样条方法在处理粗糙、不规则、带噪声样本的导数估计问题上表现出色，尤其适用于无法实现高采样率的系统。

> **ai_Abstract:** 本文提出了一种结合最大似然估计（MLE）和样条函数的新方法，用于在粗糙、不均匀且存在高斯噪声的采样条件下进行数值微分。该方法通过对高阶导数施加L2范数约束，并引入二次样条的非标准参数化，开发了递归在线算法。通过提供二次和零阶两种公式，实现了平滑度和计算速度的平衡。仿真结果显示，在低采样率和高噪声环境下，该方法相比传统微分器表现出卓越的性能，特别适用于难以提高采样率的系统。

> **摘要翻译:** 我们解决了在粗糙、非均匀采样和高斯噪声下的数值微分问题。通过对高阶导数施加L2范数约束，获得了最大似然估计器，从而得到了基于样条的解决方案。我们引入了二次样条的非标准参数化，并开发了递归在线算法。二次和零阶两种公式提供了平滑度和计算速度之间的权衡。仿真结果表明，在粗糙采样和高噪声条件下，该方法在性能上优于高增益观测器和超扭曲微分器，有益于高采样率不切实际的系统。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='physicschem-ph'></a>
## physics.chem-ph 

### [526] [Image Super-resolution Inspired Electron Density Prediction](https://arxiv.org/abs/2402.12335)
> *图像超分辨率启发下的电子密度预测*

*Chenghan Li, Or Sharir, Shunyue Yuan, Garnet K. Chan* | **Category: physics.chem-ph, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 电子密度预测, 图像超分辨率, 卷积神经网络, 量子力学, 分子对称性

**Comment:** 

> **TL;DR:** 该论文受图像超分辨率启发，使用卷积残差网络预测电子密度，将粗略猜测转化为准确的量子力学密度，性能优于现有方法，并能直接应用于新分子和元素。

**AI_Comments:** 该研究的创新之处在于将图像超分辨率的理念应用于电子密度预测这一物理问题，这是一种新颖的跨学科方法。模型因实空间输入而固有的等变性是一个显著优势，其对未见分子和元素的泛化能力也十分重要。这可能为计算化学和材料科学开辟新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 受图像超分辨率启发，该研究旨在将粗略的分子密度猜测转化为准确的基态量子力学密度，以提高电子密度预测的准确性。

**Method:** 研究将电子密度视为三维灰度图像，并使用一个卷积残差网络将粗略生成的分子密度猜测转换为准确的基态量子力学密度。模型输入是实空间密度，确保了对分子对称变换的等变性。

**Result:** 该模型优于所有先前的密度预测方法。预测结果对分子对称变换具有等变性。模型可以直接应用于未见的分子构象和化学元素。对有限新数据进行微调，即使在稀有元素和电荷态等挑战性情况下也能提供高精度。

**Conclusion:** 这项工作为借鉴图像处理的既有思想来学习实空间物理量提供了新途径。

> **ai_Abstract:** 该论文提出了一种新颖的电子密度预测方法，将电子密度视为三维灰度图像，并引入了受图像超分辨率技术启发的卷积残差网络。该模型能有效地将初步的密度猜测转化为精确的量子力学密度，表现优于现有方法。其基于实空间密度输入的设计确保了对分子对称性的等变性，且其简洁性使其可以直接应用于新的分子构象和元素，通过微调在复杂情况下也能保持高精度。这项研究为将图像处理概念应用于学习实空间物理量开辟了新的方向。

> **摘要翻译:** 受到图像超分辨率领域的启发，我们将电子密度视为三维灰度图像，并使用卷积残差网络将粗略且简单生成的分子密度猜测转化为准确的基态量子力学密度。我们发现该模型优于所有先前的密度预测方法。由于输入本身是实空间密度，即使模型不是为此构建的，预测也对分子对称变换具有等变性。由于其简单性，该模型直接适用于未见的分子构象和化学元素。我们表明，即使在稀有元素和电荷态等具有挑战性的情况下，对有限新数据进行微调也能提供高精度。我们的工作为借鉴图像处理的既有思想学习实空间物理量提供了新途径。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-biobm'></a>
## q-bio.BM 

### [547] [AMix-1: A Pathway to Test-Time Scalable Protein Foundation Model](https://arxiv.org/abs/2507.08920)
> *AMix-1：通向测试时可扩展蛋白质基础模型的路径*

*Changze Lv, Jiang Zhou, Siyu Long, Lihao Wang, Jiangtao Feng, Dongyu Xue, Yu Pei, Hao Wang, Zherui Zhang, Yuchen Cai, Zhiqiang Gao, Ziyuan Ma, Jiakai Hu, Chaochen Gao, Jingjing Gong, Yuxuan Song, Shuyi Zhang, Xiaoqing Zheng, Deyi Xiong, Lei Bai, Wanli Ouyang, Ya-Qin Zhang, Wei-Ying Ma, Bowen Zhou, Hao Zhou* | **Category: q-bio.BM, cs.AI** | **Updated: 2025-07-29**

**Keywords:** 蛋白质基础模型, AMix-1, 贝叶斯流网络, 上下文学习, 蛋白质设计, 测试时缩放

**Comment:** 

> **TL;DR:** 本文介绍了AMix-1，一个基于贝叶斯流网络和系统训练方法的蛋白质基础模型，实现了测试时可扩展的蛋白质设计，并成功设计出活性显著提升的蛋白质变体，为下一代“实验室循环”蛋白质设计奠定了基础。

**AI_Comments:** 这篇论文通过引入AMix-1模型及其系统训练方法，在蛋白质基础模型领域取得了显著进展。其创新点在于结合了贝叶斯流网络、预训练缩放律、上下文学习以及特别的“测试时缩放算法”，实现了模型在蛋白质设计方面的可扩展性和高效性。成功设计出活性大幅提升的蛋白质变体，并提出“实验室循环”蛋白质设计概念，显示了其在推动蛋白质工程边界方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发一个可扩展的蛋白质基础模型，以推动蛋白质工程的边界，并为下一代“实验室循环”蛋白质设计奠定基础。

**Method:** 提出了AMix-1蛋白质基础模型，该模型基于贝叶斯流网络，并采用系统训练方法，包括预训练缩放律、涌现能力分析、上下文学习机制和测试时缩放算法。通过建立预测缩放律和揭示结构理解的逐步涌现，构建了一个17亿参数的模型。进一步设计了基于多序列比对（MSA）的上下文学习策略，将蛋白质设计统一到通用框架中。此外，还为AMix-1引入了进化测试时缩放算法，用于计算机模拟的定向进化。

**Result:** 构建了一个强大的17亿参数的AMix-1蛋白质基础模型。通过MSA-based上下文学习框架，成功设计出活性比野生型提高高达50倍的AmeR变体。进化测试时缩放算法在增加验证预算时，实现了显著且可扩展的性能提升。

**Conclusion:** AMix-1通过其创新的模型架构和训练方法，特别是测试时可扩展的蛋白质设计能力，为下一代“实验室循环”蛋白质设计奠定了基础，极大地推动了蛋白质工程的发展。

> **ai_Abstract:** 本文介绍了AMix-1，一个基于贝叶斯流网络和系统训练方法的蛋白质基础模型，旨在实现测试时可扩展性。该模型通过预测缩放律和涌现能力分析构建了一个17亿参数的模型。通过基于多序列比对（MSA）的上下文学习策略，AMix-1能够统一蛋白质设计并生成结构功能连贯的蛋白质，成功设计出活性提升50倍的AmeR变体。此外，引入的进化测试时缩放算法为计算机模拟的定向进化提供了可扩展的性能增益，为未来“实验室循环”蛋白质设计奠定了基础。

> **摘要翻译:** 我们引入了AMix-1，一个强大的蛋白质基础模型，它建立在贝叶斯流网络之上，并由系统的训练方法赋能，该方法包括预训练缩放律、涌现能力分析、上下文学习机制和测试时缩放算法。为了保证稳健的可扩展性，我们建立了一个预测缩放律，并通过损失视角揭示了结构理解的逐步涌现，最终形成了一个强大的17亿参数模型。在此基础上，我们设计了一种基于多序列比对（MSA）的上下文学习策略，将蛋白质设计统一到一个通用框架中，其中AMix-1能够识别MSA中的深层进化信号，并持续生成结构和功能上连贯的蛋白质。该框架成功设计出显著改进的AmeR变体，其活性比野生型提高了高达50倍。为了推动蛋白质工程的边界，我们进一步通过进化测试时缩放算法赋能AMix-1进行计算机模拟的定向进化，该算法在验证预算增加时提供了实质性、可扩展的性能增益，为下一代“实验室循环”蛋白质设计奠定了基础。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matdis-nn'></a>
## cond-mat.dis-nn 

### [552] [Amorphous Solid Model of Vectorial Hopfield Neural Networks](https://arxiv.org/abs/2507.22787)
> *矢量霍普菲尔德神经网络的无定形固体模型*

*F. Gallavotti, A. Zaccone* | **Category: cond-mat.dis-nn, cond-mat.soft, cond-mat.stat-mech, cs.LG, cs.NE** | **Updated: 2025-07-30**

**Keywords:** 霍普菲尔德神经网络, 矢量模型, 无定形固体, 联想记忆, 记忆容量

**Comment:** 

> **TL;DR:** 该研究提出了一种将霍普菲尔德神经网络扩展到矢量形式的新模型，其灵感来源于无定形固体理论，并展示了其增强的记忆容量和与无定形固体物理学的联系。

**AI_Comments:** 该论文的创新之处在于将霍普菲尔德神经网络与无定形固体物理理论相结合，通过引入矢量神经状态和借鉴其结构特性，显著提升了模型的记忆容量。这种跨学科的方法为理解复杂系统中的联想记忆机制提供了新的视角，并揭示了记忆容量与物理结构参数（如配位数）之间的定量关系，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是探索霍普菲尔德联想记忆模型的矢量扩展，并将其与无定形固体理论联系起来，以期理解具有连续取向自由度的系统中联想记忆机制。

**Method:** 该论文提出了一种霍普菲尔德联想记忆模型的矢量扩展，其中二元神经状态被单位矢量（在S^2球面上）取代。通过存储模式矢量的外积，使用广义赫布学习规则创建了块状结构的权重矩阵。该模型通过量化结构特性（如能量景观、各向异性相关性、有序-无序转变）和记忆容量与配位数Z的标度关系进行了分析。

**Result:** 该模型展现出无序材料的量化结构特性，包括：存储模式的深能量最小值与随机配置之间的能量间隙（约7单位），权重矩阵中编码的强各向异性相关性（各向异性比约10^2），以及受模式密度控制的有序-无序转变。与二元网络相比，其记忆容量得到增强（全连接网络γc ≈ 0.55，而二元网络γc ≈ 0.138），并出现了取向相关性。此外，还揭示了记忆容量与配位数Z的标度关系：γc ~ (Z-6)，这与3D中心力弹簧网络中剪切模量G ~ (Z-6)的标度关系非常相似。

**Conclusion:** 该研究表明，所提出的矢量霍普菲尔德模型在记忆容量方面有所增强，并建立了联想记忆机制与无定形固体物理学之间的联系，特别是在具有连续取向自由度的系统中。

> **ai_Abstract:** 本文提出了一种基于无定形固体理论的矢量化霍普菲尔德神经网络模型，该模型使用单位矢量代替二元神经状态。研究发现，该模型展现出无序材料的典型结构特性，包括能量景观、各向异性相关性和有序-无序转变。与传统二元网络相比，其记忆容量显著提高，并揭示了记忆容量与配位数Z的标度关系，从而建立了联想记忆与无定形固体物理学之间的深层联系。

> **摘要翻译:** 我们提出了一种受无定形固体理论启发的霍普菲尔德联想记忆模型的矢量扩展，其中二元神经状态被S^2球面上R^3中的单位矢量si取代。广义赫布学习规则通过存储模式矢量的外积创建了块状结构的权重矩阵，类似于无定形固体中的赫斯矩阵结构。我们证明了该模型表现出无序材料特有的可量化结构特性：存储模式与随机配置的能量景观具有深谷（能量间隙约7单位），权重矩阵中编码的强各向异性相关性（各向异性比约10^2），以及由模式密度γ = P/(N·d)控制的有序-无序转变。与二元网络（γc ≈ 0.138）相比，增强的记忆容量（全连接网络γc ≈ 0.55）和取向相关性的出现，建立了联想记忆机制与无定形固体物理学之间的联系，特别是在具有连续取向自由度的系统中。我们还揭示了记忆容量随配位数Z的标度关系：从3D弹性网络的等静点Zc = 6开始，γc ~ (Z-6)，这与3D中心力弹簧网络中剪切模量G ~ (Z-6)的标度关系非常相似。

</details>

[⬆️ 返回分类顶部](#cond-matdis-nn) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matsoft'></a>
## cond-mat.soft 

### [566] [Multiscale geometrical and topological learning in the analysis of soft matter collective dynamics](https://arxiv.org/abs/2507.21265)
> *软物质集体动力学分析中的多尺度几何与拓扑学习*

*Tetiana Orlova, Amaranta Membrillo Solis, Hayley R. O. Sohn, Tristan Madeleine, Giampaolo D'Alessandro, Ivan I. Smalyukh, Malgosia Kaczmarek, Jacek Brodzki* | **Category: cond-mat.soft, cond-mat.mtrl-sci, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 多尺度, 几何学习, 拓扑数据分析, 软物质, 集体动力学

**Comment:** 13 pages, 6 figures

> **TL;DR:** 本文提出一种结合多尺度几何与拓扑数据分析（TDA）的新方法，用于从实验图像中理解复杂软物质系统的集体动力学和演变。

**AI_Comments:** 本文的创新之处在于将几何数据分析与拓扑数据分析（特别是引入$\Psi$-函数）相结合，以处理多尺度复杂动态系统。其方法具有高度通用性，能够应用于多种自组装系统，并有望将图像分析结果与真实世界的物理、化学或生物现象建立联系，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 通过分析实验图像中的模式来理解动态多体系统的行为和演变是一种有前景的方法，适用于各种生命和非生命的自组装系统。

**Method:** 本文采用联合几何和拓扑数据分析（TDA）框架来研究系统，通过在TDA方法中引入一个鲁棒的数值拓扑描述符——$\Psi$-函数，该函数与单个拓扑孤子的时空变化及其不同空间组织区域的出现有关。此外，还使用基于从斯格明子集合图像生成的矢量场分析的几何方法。

**Result:** 所提出的方法非常通用，可以表征系统在个体模式形成主体和作为一个整体的行为，从而将图像数据分析的结果与现实世界中发生的物理、化学或生物系统过程联系起来。

**Conclusion:** 本文提出的多尺度几何与拓扑学习方法提供了一个通用且强大的框架，能够有效分析软物质的集体动力学，并将其与真实世界的物理、化学或生物过程联系起来。

> **ai_Abstract:** 本文介绍了一种结合几何和拓扑数据分析（TDA）的新方法，用于研究软物质的集体动力学，以液晶斯格明子为例。该方法引入了$\Psi$-函数作为鲁棒的拓扑描述符，并利用矢量场分析来深入理解系统的非线性物理机制。这种通用方法能够从个体和整体层面表征系统行为，并将图像数据分析结果与真实的物理、化学或生物过程联系起来。

> **摘要翻译:** 通过分析实验捕获图像中的模式来理解动态多体系统的行为和演变是一种有前景的方法，适用于各种生命和非生命的自组装系统。这里研究的移动液晶斯格明子阵列是分层组织材料的代表性例子，它们表现出由多尺度过程驱动的复杂时空动力学。联合几何和拓扑数据分析（TDA）通过在多个尺度上捕获数据的潜在结构，为研究此类系统提供了一个强大的框架。在TDA方法中，我们引入了$\Psi$-函数，这是一个鲁棒的数值拓扑描述符，它与单个拓扑孤子的大小和形状的时空变化以及其不同空间组织区域的出现都有关。基于从斯格明子集合图像生成的矢量场分析的几何方法，为理解系统对外部刺激的非线性物理机制提供了见解，并为与理论预测进行比较提供了基础。这里提出的方法非常通用，可以在个体模式形成主体和作为一个整体的层面上表征系统行为，从而将图像数据分析的结果与现实世界中发生的物理、化学或生物系统过程联系起来。

</details>

[⬆️ 返回分类顶部](#cond-matsoft) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phim'></a>
## astro-ph.IM 

### [636] [Generative imaging for radio interferometry with fast uncertainty quantification](https://arxiv.org/abs/2507.21270)
> *用于射电干涉测量的快速不确定性量化生成成像*

*Matthijs Mars, Tobías I. Liaudat, Jessica J. Whitney, Marta M. Betcke, Jason D. McEwen* | **Category: astro-ph.IM, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 生成成像, 射电干涉测量, 不确定性量化, 生成对抗网络, RI-GAN

**Comment:** 

> **TL;DR:** 本文提出了一种名为RI-GAN的生成神经网络框架，用于射电干涉测量的高效、高质量图像重建，并提供快速不确定性量化，以解决现有方法计算成本高昂且缺乏不确定性量化的问题。

**AI_Comments:** 该论文的创新点在于将生成对抗网络（GAN）应用于射电干涉测量图像重建，并特别关注了不确定性量化问题。通过结合GU-Net将测量算子嵌入网络，并利用Wasserstein GAN和正则化项解决GAN训练中的稳定性及模式崩溃问题，显著提高了重建效率和质量。其提供的不确定性量化对于科学分析至关重要，是现有迭代方法的一大改进。该工作对于下一代射电望远镜的成像技术具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型射电干涉望远镜（特别是SKA）的兴起，对计算效率高的图像重建技术的需求日益增长。现有重建方法（如CLEAN算法或近端优化方法）本质上是迭代的，需要大量计算，并且要么不提供不确定性量化，要么需要巨大的计算开销才能实现。

**Method:** 本文探索使用生成神经网络，通过RI-GAN框架实现高效的后验分布近似采样，以进行高质量重建和不确定性量化。RI-GAN基于正则化条件生成对抗网络（rcGAN）框架，并集成了梯度U-Net（GU-Net）架构，这是一种将测量算子直接嵌入网络的混合重建模型。该框架结合了Wasserstein GAN以提高训练稳定性，并使用正则化项来对抗条件GAN常见的模式崩溃问题。

**Result:** 所提出的方法以脏图像和观测的点扩散函数（PSF）作为输入，提供了高效、高质量的图像重建，这些重建对不同的可见度覆盖具有鲁棒性，能够泛化到动态范围增加的图像，并提供信息丰富的不确定性量化。

**Conclusion:** 本文的方法在计算高效、可扩展和不确定性感知的新一代射电望远镜成像方面迈出了重要一步。

> **ai_Abstract:** 本文针对大型射电干涉望远镜对高效图像重建的需求，提出了一种名为RI-GAN的生成神经网络框架。该框架基于正则化条件GAN并融入梯度U-Net架构，通过Wasserstein GAN和正则化项解决了传统方法计算量大、缺乏不确定性量化的问题。RI-GAN能够从脏图像和PSF生成高效、高质量且对不同可见度鲁棒的图像重建，并提供有用的不确定性量化，为未来射电望远镜的成像技术发展奠定了基础。

> **摘要翻译:** 随着大型射电干涉望远镜，特别是SKA的兴起，对计算效率高的图像重建技术的需求日益增长。现有的重建方法，如CLEAN算法或近端优化方法，本质上是迭代的，需要大量计算。这些方法要么不提供不确定性量化，要么需要巨大的计算开销才能实现。学习型重建方法在提供高效、高质量重建方面显示出前景。在本文中，我们探索使用生成神经网络，通过高效地近似采样后验分布，实现高质量重建和不确定性量化。我们的RI-GAN框架，建立在正则化条件生成对抗网络（rcGAN）框架之上，通过集成梯度U-Net（GU-Net）架构——一种将测量算子直接嵌入网络的混合重建模型。该框架使用Wasserstein GANs来提高训练稳定性，并结合正则化项来对抗模式崩溃，这些都是条件GANs的典型问题。这种方法以脏图像和观测的点扩散函数（PSF）作为输入，提供高效、高质量的图像重建，这些重建对不同的可见度覆盖具有鲁棒性，能够泛化到动态范围增加的图像，并提供信息丰富的不确定性量化。我们的方法是朝着下一代射电望远镜计算高效、可扩展和不确定性感知的成像迈出的重要一步。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [642] [Efficient Sub-pixel Motion Compensation in Learned Video Codecs](https://arxiv.org/abs/2507.21926)
> *学习型视频编解码器中的高效亚像素运动补偿*

*Théo Ladune, Thomas Leguay, Pierrick Philippe, Gordon Clare, Félix Henry* | **Category: cs.MM, eess.IV** | **Updated: 2025-07-29**

**Keywords:** 亚像素运动补偿, 学习型视频编解码器, 压缩性能, 解码复杂度, 插值滤波器

**Comment:** 

> **TL;DR:** 本文通过借鉴传统编解码器的方法，改进了学习型视频编解码器中的亚像素运动补偿，从而显著提升了压缩性能并降低了解码复杂度。

**AI_Comments:** 该论文的创新之处在于将传统视频编解码器中经过验证的亚像素运动补偿技术（如先进插值滤波器和块级运动信息）引入到新兴的学习型编解码器中。这解决了学习型编解码器在此方面相对简单的问题，显著提升了其压缩效率和解码性能。其重要性在于为学习型视频编码器的进一步发展提供了清晰的优化方向，并展示了融合传统与AI技术的潜力。所有贡献开源也增加了其影响力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的视频编解码器（如HEVC和VVC）在亚像素运动补偿方面进行了精细优化，而学习型编解码器目前仅通过简单的双线性滤波实现亚像素运动补偿，这导致其性能有待提升。

**Method:** 本文通过引入更先进的插值滤波器、基于块的运动信息和有限运动精度来改进学习型编解码器的运动补偿机制，借鉴了传统编解码器的方法。

**Result:** 在Cool-chic视频编解码器上的实验结果显示，码率降低了10%以上，并且运动相关的解码复杂度从每像素391 MAC降低到214 MAC。

**Conclusion:** 通过借鉴传统编解码器的方法，为学习型视频编解码器引入更先进的运动补偿技术，可以显著提高压缩效率并降低解码复杂度。

> **ai_Abstract:** 本文提出了一种改进学习型视频编解码器中亚像素运动补偿的方法，通过借鉴传统编解码器（如HEVC和VVC）的先进技术，包括使用更复杂的插值滤波器、基于块的运动信息和有限运动精度。实验证明，这些改进在Cool-chic编解码器上实现了超过10%的码率降低，并将运动相关解码复杂度从391 MAC/像素降至214 MAC/像素，显著提升了压缩效率和解码性能。

> **摘要翻译:** 运动补偿是视频编解码器的关键组成部分。传统的编解码器（HEVC和VVC）对这一编码步骤进行了精心完善，重点关注亚像素运动补偿。另一方面，学习型编解码器通过简单的双线性滤波实现亚像素运动补偿。本文旨在通过借鉴传统编解码器的方法来改进学习型编解码器的运动补偿。研究表明，使用更先进的插值滤波器、基于块的运动信息和有限的运动精度可以带来更好的压缩性能和更低的解码复杂度。在Cool-chic视频编解码器上提供了实验结果，我们展示了码率下降超过10%，并且运动相关的解码复杂度从每像素391 MAC降低到每像素214 MAC。所有贡献均已开源，网址为https://github.com/Orange-OpenSource/Cool-Chic

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [811] [Sync-TVA: A Graph-Attention Framework for Multimodal Emotion Recognition with Cross-Modal Fusion](https://arxiv.org/abs/2507.21395)
> *Sync-TVA：一种用于多模态情感识别的图注意力框架与跨模态融合*

*Zeyu Deng, Yanhui Lu, Jiashu Liao, Shuang Wu, Chongfeng Wei* | **Category: cs.MM, cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-29**

**Keywords:** 多模态情感识别, 图注意力网络, 跨模态融合, 动态增强, 情感智能系统

**Comment:** 

> **TL;DR:** Sync-TVA是一个图注意力框架，通过动态增强和结构化跨模态融合，解决了多模态情感识别中有限的跨模态交互和不平衡的模态贡献问题，并在MELD和IEMOCAP数据集上取得了SOTA性能。

**AI_Comments:** Sync-TVA的创新之处在于其结合了模态特定的动态增强和结构化的跨模态图融合，这有效地解决了多模态情感识别中常见的模态交互不足和贡献不平衡的挑战。其在类别不平衡条件下的优异表现尤其值得关注，这表明该模型在实际应用中具有更强的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态情感识别方法存在跨模态交互有限和模态贡献不平衡的问题，阻碍了情感智能系统的发展。

**Method:** 我们提出了Sync-TVA，一个端到端的图注意力框架。它包含：1. 针对每种模态的动态增强模块；2. 构建异构跨模态图以建模文本、音频和视觉特征之间的语义关系；3. 跨注意力融合机制，用于对齐多模态线索以进行鲁棒的情感推断。

**Result:** 在MELD和IEMOCAP数据集上的实验表明，Sync-TVA在准确率和加权F1分数上均持续优于最先进的模型，尤其是在类别不平衡的条件下。

**Conclusion:** Sync-TVA通过其模态特定动态增强和结构化跨模态融合机制，有效解决了多模态情感识别中的挑战，并在多个数据集上取得了显著的性能提升。

> **ai_Abstract:** 本文提出了Sync-TVA，一个用于多模态情感识别的图注意力框架。该框架通过为每种模态设计动态增强模块，并构建异构跨模态图来建模文本、音频和视觉特征间的语义关系，同时利用跨注意力融合机制对齐多模态信息，有效解决了现有方法中跨模态交互不足和模态贡献不平衡的问题。实验证明，Sync-TVA在MELD和IEMOCAP数据集上，尤其是在类别不平衡情境下，性能显著优于现有SOTA模型。

> **摘要翻译:** 多模态情感识别（MER）对于实现能够感知和响应人类情感的情感智能系统至关重要。然而，现有方法存在跨模态交互有限和模态贡献不平衡的问题。为了解决这些问题，我们提出了Sync-TVA，一个端到端图注意力框架，其特点是模态特定的动态增强和结构化跨模态融合。我们的设计为每种模态整合了一个动态增强模块，并构建了异构跨模态图，以建模文本、音频和视觉特征之间的语义关系。跨注意力融合机制进一步对齐多模态线索，以实现鲁棒的情感推断。在MELD和IEMOCAP上的实验表明，在准确率和加权F1分数方面，Sync-TVA均持续优于最先进的模型，尤其是在类别不平衡的条件下。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [873] [Music-Aligned Holistic 3D Dance Generation via Hierarchical Motion Modeling](https://arxiv.org/abs/2507.14915)
> *音乐对齐的全身3D舞蹈生成通过分层运动建模*

*Xiaojie Li, Ronghui Li, Shukai Fang, Shuzhao Xie, Xiaoyang Guo, Jiaqing Zhou, Junkun Peng, Zhi Wang* | **Category: cs.MM, cs.SD, eess.AS** | **Updated: 2025-07-29**

**Keywords:** 3D舞蹈生成, 音乐对齐, 全身运动建模, 数据集, 深度学习

**Comment:** 

> **TL;DR:** 本文引入SoulDance数据集和SoulNet框架，通过分层建模和音乐对齐，成功生成高质量、音乐协调的全身3D舞蹈序列，显著优于现有方法。

**AI_Comments:** 这篇论文的创新点在于构建了首个高精度全身3D舞蹈数据集SoulDance，并提出了一个端到端的SoulNet框架。该框架通过分层运动建模和引入跨模态对齐先验，有效解决了全身舞蹈生成中的数据稀缺、跨模态对齐和复杂运动依赖建模等核心难题，具有重要的研究价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 生成协调、音乐对齐的全身舞蹈面临挑战：缺乏全身3D舞蹈数据集，音乐与舞蹈的跨模态对齐困难，以及身体、手、面部之间相互依赖运动建模的复杂性。

**Method:** 引入SoulDance，一个高精度音乐-舞蹈配对数据集。在此基础上，提出SoulNet框架，其包含三个主要组件：1) 分层残差矢量量化，用于建模身体、手、面部之间复杂、细粒度的运动依赖；2) 音乐对齐生成模型，用于组合这些分层运动单元；3) 音乐-运动检索模块，一个预训练的跨模态模型，作为音乐-舞蹈对齐的先验。

**Result:** 大量实验表明，SoulNet在生成高质量、音乐协调且对齐的全身3D舞蹈序列方面显著超越了现有方法。

**Conclusion:** SoulDance数据集和SoulNet框架有效解决了音乐对齐全身3D舞蹈生成中的挑战，并取得了最先进的性能。

> **ai_Abstract:** 本文针对音乐对齐的全身3D舞蹈生成面临的数据稀缺、跨模态对齐和复杂运动建模挑战，提出了高精度SoulDance数据集和创新的SoulNet框架。SoulNet通过分层残差矢量量化、音乐对齐生成模型和音乐-运动检索模块，成功实现了高质量、音乐协调且对齐的全身3D舞蹈序列生成，并在实验中展现出优于现有方法的性能。

> **摘要翻译:** 良好协调、与音乐对齐的全身舞蹈能增强情感表达和观众参与度。然而，生成此类舞蹈仍然充满挑战，原因在于全身3D舞蹈数据集的稀缺性、音乐与舞蹈之间实现跨模态对齐的难度，以及身体、手和面部之间相互依赖运动建模的复杂性。为了解决这些挑战，我们引入了SoulDance，一个通过专业动作捕捉系统捕获的高精度音乐-舞蹈配对数据集，其中包含精心标注的全身舞蹈动作。在此数据集的基础上，我们提出了SoulNet，一个旨在生成音乐对齐、运动协调的全身舞蹈序列的框架。SoulNet包含三个主要组成部分：(1) 分层残差矢量量化，用于建模身体、手和面部之间复杂、细粒度的运动依赖；(2) 音乐对齐生成模型，用于将这些分层运动单元组合成富有表现力且协调的全身舞蹈；(3) 音乐-运动检索模块，一个预训练的跨模态模型，作为音乐-舞蹈对齐的先验，确保在整个生成过程中生成的舞蹈与输入音乐之间的时间同步和语义连贯性。大量实验表明，SoulNet在生成高质量、音乐协调且对齐的全身3D舞蹈序列方面显著超越了现有方法。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [658] [Machine learning-based multimodal prognostic models integrating pathology images and high-throughput omic data for overall survival prediction in cancer: a systematic review](https://arxiv.org/abs/2507.16876)
> *基于机器学习的多模态预后模型整合病理图像和高通量组学数据用于癌症总生存期预测：一项系统综述*

*Charlotte Jennings, Andrew Broad, Lucy Godson, Emily Clarke, David Westhead, Darren Treanor* | **Category: q-bio.QM, cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 机器学习, 多模态, 癌症预后, 总生存期, 系统综述

**Comment:** Main article (50 pages, inc 3 tables, 4 figures). Supplementary
  material included with additional methodological information and data

> **TL;DR:** 该系统综述评估了整合病理图像和组学数据进行癌症总生存期预测的机器学习模型。发现多模态模型表现良好但方法学严谨性不足，缺乏外部验证和临床实用性关注。

**AI_Comments:** 该系统综述揭示了癌症多模态预后模型研究的当前进展和关键局限性。其重要性在于指出了该领域未来发展和改进的方向，特别是强调了方法学严谨性、外部验证和临床实用性的重要性，这对于推动研究成果向临床转化至关重要。发现所有研究都存在不明确/高偏倚是一个值得关注的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 多模态机器学习整合组织病理学和分子数据在癌症预后方面显示出前景，因此有必要系统回顾结合全玻片图像（WSI）和高通量组学数据预测总生存期的研究。

**Method:** 本研究对EMBASE、PubMed和Cochrane CENTRAL数据库进行了系统检索（截至2024年12月8日），并进行了引文筛选以识别符合条件的研究。数据提取使用CHARMS工具，偏倚评估采用PROBAST+AI，综合分析遵循SWiM和PRISMA 2020指南。协议已在PROSPERO注册（CRD42024594745）。

**Result:** 共识别出48项研究（均自2017年以来），涵盖19种癌症类型，所有研究均使用了The Cancer Genome Atlas数据。研究方法包括正则化Cox回归（4项）、经典机器学习（13项）和深度学习（31项）。报告的c指数范围为0.550-0.857；多模态模型通常优于单模态模型。然而，所有研究都显示出不明确/高偏倚，外部验证有限，并且很少关注临床实用性。

**Conclusion:** 多模态WSI-组学生存预测是一个快速发展的领域，结果喜人，但需要改进方法学严谨性、扩大数据集和进行临床评估。

> **ai_Abstract:** 本系统综述旨在评估和总结将机器学习应用于整合病理图像和高通量组学数据以预测癌症总生存期的研究。通过系统检索和筛选，共纳入48项研究，发现多模态模型在预测性能上优于单模态模型，但普遍存在方法学偏倚高、外部验证不足以及对临床实用性关注度低的问题。研究强调，尽管该领域发展迅速且结果有前景，但未来需要加强方法学严谨性、使用更广泛的数据集并进行充分的临床评估。

> **摘要翻译:** 多模态机器学习整合组织病理学和分子数据在癌症预后方面显示出前景。我们系统回顾了结合全玻片图像（WSI）和高通量组学数据预测总生存期的研究。对EMBASE、PubMed和Cochrane CENTRAL数据库（截至2024年12月8日）的检索以及引文筛选，识别出符合条件的研究。数据提取使用CHARMS工具；偏倚评估采用PROBAST+AI；综合分析遵循SWiM和PRISMA 2020指南。协议已在PROSPERO注册（CRD42024594745）。
共48项研究（均自2017年以来），涵盖19种癌症类型，符合标准；所有研究均使用了The Cancer Genome Atlas数据。方法包括正则化Cox回归（n=4）、经典机器学习（n=13）和深度学习（n=31）。报告的c指数范围为0.550-0.857；多模态模型通常优于单模态模型。然而，所有研究都显示出不明确/高偏倚，外部验证有限，并且很少关注临床实用性。
多模态WSI-组学生存预测是一个快速发展的领域，结果喜人，但需要改进方法学严谨性、扩大数据集和进行临床评估。
由NPIC、英国利兹教学医院NHS信托基金资助（项目104687），并得到UKRI工业战略挑战基金的支持。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [683] [A Graphical Method for Designing Time-Optimal Non-Cartesian Gradient Waveforms](https://arxiv.org/abs/2507.21625)
> *一种设计时间最优非笛卡尔梯度波形的图形方法*

*Rui Luo, Hongzhang Huang, Qinfang Miao, Jian Xu, Peng Hu, Haikun Qi* | **Category: physics.med-ph, cs.SY, eess.SY** | **Updated: 2025-07-29**

**Keywords:** 非笛卡尔MRI, 梯度波形设计, 时间最优, g-空间, 图形方法

**Comment:** 

> **TL;DR:** 本文提出了一种快速通用的图形方法，用于设计非笛卡尔MRI的时间最优梯度波形，显著减少了计算时间和梯度变化率过冲。

**AI_Comments:** 该研究通过引入“g-空间”和几何求解方法，将复杂的梯度波形设计问题转化为直观的图形问题，这体现了其创新性。它解决了现有非笛卡尔MRI梯度设计方法计算耗时和适用性受限的痛点，为临床MR扫描的效率和质量提升提供了潜在价值。特别是其声称的计算时间大幅减少和过冲抑制，对于实时或快速成像应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 非笛卡尔MRI面临设计时间最优且硬件兼容的梯度波形的挑战。目前主流方法仅适用于特定轨迹或计算耗时。

**Method:** 该方法将梯度波形投影到g-空间，将寻找下一个梯度向量的问题简化为线与圆的交点求解。为处理高曲率轨迹，引入了前向和后向扫描（FBS）策略，并提出轨迹重参数化以确保轨迹保真度。

**Result:** 在模拟和真实MR采集（体模和人膝）中，该方法对多种非笛卡尔轨迹均表现出可行性，实现了准确快速的梯度波形设计，与现有方法相比，显著减少了计算时间和梯度变化率过冲。

**Conclusion:** 该图形方法能够准确快速地设计非笛卡尔梯度波形，解决了现有方法的计算耗时和特异性问题，具有普适性和高效性。

> **ai_Abstract:** 本文提出了一种创新的图形方法，用于为任意非笛卡尔MRI轨迹设计时间最优、硬件兼容的梯度波形。该方法通过将梯度波形投影到g-空间，并将梯度向量寻找问题简化为几何交点问题，并结合前向和后向扫描策略及轨迹重参数化，显著提高了计算效率和设计准确性。实验证明，与现有最优控制方法相比，该方法在计算时间上大幅减少，并有效抑制了梯度变化率过冲。

> **摘要翻译:** 非笛卡尔MRI面临的一个基本挑战是需要为给定的k空间轨迹设计时间最优且硬件兼容的梯度波形。目前主流的方法要么只适用于某些轨迹，要么需要大量的计算时间。在本文中，我们旨在开发一种快速通用的方法，能够为满足梯度变化率和梯度约束的任意非笛卡尔轨迹生成时间最优的梯度波形。在所提出的方法中，梯度波形被投影到一个由沿空间方向的梯度定义的空间中，称为g空间。在构建的g空间中，在期望的梯度变化率限制和期望方向下，根据当前梯度向量找到下一个梯度向量的问题被简化为找到一条直线和一个圆的交点。为了处理曲率增加的轨迹，引入了前向和后向扫描（FBS）策略，该策略确保了上述几何问题对于任意轨迹的解的存在性。此外，提出了轨迹重参数化以确保轨迹保真度。我们将所提出的方法与以前的最优控制方法在模拟中进行了比较，并在体模和人膝的真实MR采集中验证了其对各种非笛卡尔轨迹的可行性。与以前的方法相比，所提出的方法能够实现准确快速的梯度波形设计，显著减少了计算时间和梯度变化率过冲。本研究的源代码将在发表后公开。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='csdl'></a>
## cs.DL 

### [702] [Not Here, Go There: Analyzing Redirection Patterns on the Web](https://arxiv.org/abs/2507.22019)
> *不在这里，去那里：分析网络上的重定向模式*

*Kritika Garg, Sawood Alam, Dietrich Ayala, Michele C. Weigle, Michael L. Nelson* | **Category: cs.DL, cs.IR, cs.NI** | **Updated: 2025-07-29**

**Keywords:** URI重定向, 网络管理, SEO, 数字保存, 404错误

**Comment:** Extended version of the paper accepted at the 2025 ACM Web Science
  Conference (WebSci 2025)

> **TL;DR:** 本研究分析了1100万个URI重定向模式，发现50%成功，50%出现错误，揭示了规范和非规范重定向、“汇聚”URI以及自定义404页面的普遍性及其对网络可用性、SEO和数字保存的影响。

**AI_Comments:** 这项研究通过分析大规模真实世界数据，深入揭示了URI重定向的复杂性和实际影响，具有重要的实践意义。其创新之处在于量化了重定向的成功率与失败率，并识别了“汇聚”URI和软404等具体模式，这些都是网络管理中常被忽视但关键的方面。研究结果直接指向了网络效率、SEO和数字内容保存中的痛点，为改进相关实践提供了明确的指导。

<details>
  <summary>Details</summary>

**Motivation:** URI重定向是网络管理不可或缺的一部分，支持结构性变化、SEO优化和安全性。然而，它们的复杂性影响可用性、SEO性能和数字保存，因此有必要分析重定向模式及其影响。

**Method:** 本研究分析了1100万个独特的重定向URI，每个URI跟踪重定向最多10跳，以揭示重定向实践的模式和影响。

**Result:** 研究发现50%的URI成功终止，而50%导致错误，其中0.06%超过10跳。规范重定向（如HTTP到HTTPS）很普遍。非规范重定向（涉及域名或路径更改）突出了重要的网络迁移、品牌重塑和安全风险。发现了“汇聚”URI模式。还识别了62,000个自定义404 URI，其中近一半是软404。

**Conclusion:** URI重定向在塑造网络方面发挥着关键作用，但同时也暴露出过时URI、服务器不稳定和错误处理不当等挑战。本研究提供了URI重定向实践的详细分析，揭示了其普遍性、类型和结果，有助于网站管理员、研究人员和数字档案管理员提高网络可用性、优化资源分配和保护在线内容。

> **ai_Abstract:** 本研究对1100万个URI重定向模式进行了大规模分析，揭示了重定向在网络管理中的关键作用及其对可用性、SEO和数字保存的影响。研究发现，尽管重定向被广泛用于支持结构变化和优化，但仍有50%的重定向以错误告终，包括链条过长。论文详细探讨了规范和非规范重定向的普遍性，识别了如“汇聚”URI和软404等特定模式，这些模式对网络效率和用户体验构成挑战。研究结果为网站管理员、研究人员和数字档案管理员提供了宝贵见解，以改进网络实践并保护在线内容。

> **摘要翻译:** URI重定向是网络管理不可或缺的一部分，支持结构性变化、SEO优化和安全性。然而，它们的复杂性影响可用性、SEO性能和数字保存。本研究分析了1100万个独特的重定向URI，每个URI跟踪重定向最多10跳，以揭示重定向实践的模式和影响。我们的发现显示，50%的URI成功终止，而50%导致错误，其中0.06%超过10跳。规范重定向，如HTTP到HTTPS的转换，很普遍，反映了对SEO最佳实践的遵守。非规范重定向，通常涉及域名或路径更改，突出了重要的网络迁移、品牌重塑和安全风险。显著的模式包括“汇聚”URI，即多个重定向汇聚于此，范围从全球网站的流量整合到蓄意的“Rickrolling”。该研究还识别了62,000个自定义404 URI，其中近一半是软404，这可能会损害SEO和用户体验。这些发现强调了URI重定向在塑造网络方面的关键作用，同时也暴露出过时URI、服务器不稳定和错误处理不当等挑战。这项研究对URI重定向实践进行了详细分析，提供了对其普遍性、类型和结果的见解。通过检查大量数据集，我们强调了重定向链中的低效率，并检查了“汇聚”URI和自定义错误页面等模式的使用。这些信息可以帮助网站管理员、研究人员和数字档案管理员改善网络可用性、优化资源分配和保护有价值的在线内容。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [740] [On the Feasibility of SCL-Band Transmission over G.654.E-Compliant Long-Haul Fibre Links](https://arxiv.org/abs/2507.21865)
> *SCL波段在符合G.654.E标准的超长距离光纤链路上传输的可行性研究*

*Jiaqian Yang, Eric Sillekens, Ronit Sohanpal, Mingming Tan, Dini Pratiwi, Henrique Buglia, Romulo Aparecido, John D. Downie, Sergejs Makovejs, Lidia Galdino, Wladek Forysiak, Polina Bayvel, Robert I. Killey* | **Category: physics.optics, cs.SY, eess.SY** | **Updated: 2025-07-29**

**Keywords:** SCL波段, G.654.E光纤, 长距离传输, 信息速率, 光通信

**Comment:** 4 pages, 6 figures, accepted for oral presentation at European
  Conference on Optical Communication 2025

> **TL;DR:** 首次成功演示了SCL波段在G.654.E光纤上进行超长距离传输，在1552公里距离上实现了100.8 Tb/s的传输速率，且性能可与G.652.D光纤相媲美。

**AI_Comments:** 该研究的创新之处在于首次证明了SCL波段在G.654.E光纤上的长距离传输可行性，这对于未来超高速、超长距离光通信系统的发展具有重要意义。特别是在截止波长限制下仍能实现高性能传输，凸显了G.654.E光纤在特定波段的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探索SCL波段在新型G.654.E光纤上进行超长距离传输的可行性，尽管这种光纤的截止波长为1520 nm，但其超低损耗和低非线性特性可能带来优势。

**Method:** 通过实验演示了SCL波段在符合G.654.E标准的超长距离光纤上的首次传输。

**Result:** 在1552公里的距离上实现了100.8 Tb/s (GMI) 的传输速率。研究发现，在块状放大条件下，其可实现信息速率与采用分布式拉曼放大的G.652.D标准光纤链路相当。

**Conclusion:** 尽管G.654.E光纤的截止波长为1520 nm，但由于其超低损耗和低非线性特性，SCL波段在该光纤上的传输性能非常优异，在块状放大条件下，其可实现信息速率可与G.652.D光纤链路（采用分布式拉曼放大）相媲美。

> **ai_Abstract:** 本论文首次展示了SCL波段在符合G.654.E标准的光纤上进行超长距离传输的实验结果。尽管该光纤的截止波长为1520 nm，研究仍成功在1552公里距离上达到了100.8 Tb/s (GMI) 的传输速率。文章指出，得益于G.654.E光纤的超低损耗和低非线性，其在块状放大条件下的可实现信息速率能够与采用分布式拉曼放大的G.652.D光纤链路相媲美。

> **摘要翻译:** 我们首次演示了使用符合G.654.E标准光纤的SCL波段长距离传输，尽管其截止波长为1520 nm，但在1552公里距离上实现了100.8 Tb/s (GMI) 的传输速率。由于该光纤的超低损耗和低非线性特性，块状放大下可实现的信息速率与采用分布式拉曼放大的G.652.D标准光纤链路相当。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [901] [Generalized De Bruijn Words, Invertible Necklaces, and the Burrows-Wheeler Transform](https://arxiv.org/abs/2502.12844)
> *广义德布鲁因词、可逆项链和Burrows-Wheeler变换*

*Gabriele Fici, Estéban Gabory* | **Category: math.CO, cs.DM, cs.DS, cs.FL** | **Updated: 2025-07-29**

**Keywords:** 广义德布鲁因词, 可逆项链, Burrows-Wheeler变换, 哈密顿循环, 有限域正规基

**Comment:** Submitted

> **TL;DR:** 本文定义了广义德布鲁因词和可逆项链，并揭示了它们与哈密顿循环、有限域正规基以及Burrows-Wheeler变换之间的多种对应关系。

**AI_Comments:** 这篇论文的创新之处在于它在组合学（德布鲁因词、项链）、信息理论（BWT）和抽象代数（有限域、群论）之间建立了意想不到且深刻的联系。这种跨学科的桥梁为理解这些结构提供了新的视角，并可能在编码理论、网络设计和数据压缩等领域找到潜在应用。其通过严谨的数学证明揭示了不同概念间的内在统一性，是一项纯粹而重要的理论工作。

<details>
  <summary>Details</summary>

**Motivation:** 论文通过引入广义德布鲁因词和可逆项链的概念，旨在探索这些组合结构与图论、抽象代数（有限域正规基）以及信息压缩（Burrows-Wheeler变换）之间的深刻联系。其动机在于建立这些看似不同领域之间的桥梁，揭示它们内在的数学对应关系。

**Method:** 定义了广义德布鲁因词和可逆项链；证明了广义德布鲁因词与广义德布鲁因图中的哈密顿循环之间的一对一对应关系；证明了可逆项链与有限域的正规基之间的对应关系，并证明其形成阿贝尔群；利用抽象代数建立了广义德布鲁因词和可逆项链之间的联系；通过具体例子展示了二元德布鲁因词、二元项链、可逆BWT矩阵和有限域正规基之间的对应关系。

**Result:** 广义德布鲁因词与广义德布鲁因图中的哈密顿循环存在一对一对应关系；当字母表大小为素数p时，长度为n的可逆项链对应于有限域F_p^n的正规基，并且它们构成一个同构于Reutenauer群RG_p^n的阿贝尔群；建立了广义德布鲁因词和可逆项链之间的联系；特别揭示了二元德布鲁因词、二元项链、可逆BWT矩阵和有限域正规基之间的对应关系。

**Conclusion:** 论文成功地建立了广义德布鲁因词和可逆项链与图论、抽象代数及Burrows-Wheeler变换之间的多重深层数学对应关系，揭示了这些看似不同概念间的统一性，为相关领域的研究提供了新的视角和工具。

> **ai_Abstract:** 这篇论文引入了广义德布鲁因词和可逆项链的概念，并探讨了它们与Burrows-Wheeler变换、图论中的哈密顿循环以及抽象代数中有限域正规基之间的深刻联系。研究表明，广义德布鲁因词与广义德布鲁因图的哈密顿循环一一对应；当字母表大小为素数p时，可逆项链与有限域F_p^n的正规基对应，并构成一个阿贝尔群。论文还利用抽象代数知识，搭建了广义德布鲁因词和可逆项链之间的桥梁，并特别展示了二元条件下这些概念与可逆BWT矩阵的对应关系。

> **摘要翻译:** 我们定义广义德布鲁因词为那些其Burrows-Wheeler变换是字母表排列的串联的词。我们证明广义德布鲁因词与20世纪80年代早期在网络设计背景下引入的广义德布鲁因图中的哈密顿循环之间存在一对一的对应关系。当字母表的大小为素数p时，我们定义可逆项链为那些其BWT矩阵是非奇异的项链。我们证明长度为n的可逆项链对应于有限域F_p^n的正规基，并且它们形成一个与Reutenauer群RG_p^n同构的阿贝尔群。利用抽象代数中的已知结果，我们可以在广义德布鲁因词和可逆项链之间建立一座桥梁。特别地，我们强调了阶数为d+1的二元德布鲁因词、长度为2^d且包含奇数个1的二元项链、大小为2^d x 2^d的可逆BWT矩阵以及有限域F_{2^{2^d}}的正规基之间的对应关系。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [906] [Green building blocks reveal the complex anatomy of climate change mitigation technologies](https://arxiv.org/abs/2504.06834)
> *绿色积木揭示了气候变化缓解技术的复杂结构*

*Yang Li, Frank Neffke* | **Category: physics.soc-ph, cs.SI** | **Updated: 2025-07-29**

**Keywords:** 绿色积木, 气候变化缓解, 创新, 国际合作, 专利

**Comment:** 

> **TL;DR:** 该研究通过比较绿色和非绿色专利，识别出“绿色积木”（GBBs），并构建了一个网络来分析气候变化缓解技术的创新，发现国际合作对于实现全球气候目标至关重要，而经济民族主义对此构成威胁。

**AI_Comments:** 这篇论文的创新点在于提出了“绿色积木”的概念，并通过网络分析的方法，从专利数据中揭示了气候变化缓解技术的复杂结构和国际合作的重要性。其重要性在于为政策制定者提供了量化证据，强调了在应对气候变化时国际合作的不可或缺性，并警示了经济民族主义的潜在危害。

<details>
  <summary>Details</summary>

**Motivation:** 实现净零排放需要快速创新，但所需的技术知识分散在不同行业和国家。本研究旨在通过识别和分析“绿色积木”来理解气候变化缓解技术的复杂性，并揭示创新模式。

**Method:** 通过比较功能相似的绿色和非绿色专利，识别出“绿色积木”（GBBs），这些是可减少现有技术碳足迹的模块化组件。将这些GBBs描绘成一个网络，连接问题（非绿色技术）与缓解其气候影响的GBBs。分析该网络中的节点度，并预测企业如何开发绿色技术以及形成何种联盟。

**Result:** “绿色积木”描绘了绿色转型的解剖结构，形成一个将问题与缓解其气候影响的GBBs连接起来的网络。该网络中的节点度高度不均等，表明气候变化缓解创新的范围在不同领域差异很大。网络还有助于预测企业开发哪些绿色技术以及形成哪些联盟。研究揭示了对国际合作的关键依赖性：84%的美国、87%的德国和92%的中国企业的最佳创新伙伴是外国公司。这提供了量化证据，表明日益增长的经济民族主义威胁着实现全球气候目标所需的创新速度。

**Conclusion:** 日益增长的经济民族主义对实现全球气候目标所需的创新速度构成了威胁，因为大多数国家（如美国、德国和中国）的企业在气候变化缓解技术创新方面严重依赖国际合作。

> **ai_Abstract:** 该研究通过比较绿色和非绿色专利，识别出可减少碳足迹的“绿色积木”（GBBs）。研究将GBBs及其相关技术构建成一个网络，揭示了气候变化缓解创新的复杂结构和领域差异。结果表明，企业在绿色技术创新上高度依赖国际合作，并量化指出经济民族主义对全球气候目标构成威胁。

> **摘要翻译:** 实现净零排放需要快速创新，然而所需的技术诀窍分散在各个行业和国家。通过比较功能相似的绿色和非绿色专利，我们识别出“绿色积木”（GBBs）：这些是模块化组件，可以添加以减少现有技术的碳足迹。这些GBBs将绿色转型的解剖结构描绘为一个网络，它将问题——非绿色技术——与缓解其气候变化影响的GBBs连接起来。该网络中的节点度高度不均等，表明气候变化缓解创新的范围在不同领域差异很大。该网络还有助于预测企业自行开发哪些绿色技术，以及它们为此组建哪些联盟。这揭示了对国际合作的关键依赖性：84%的美国、87%的德国和92%的中国企业的最佳创新伙伴是外国公司，这提供了量化证据，表明日益增长的经济民族主义威胁着实现全球气候目标所需的创新速度。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

