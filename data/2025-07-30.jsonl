{"id": "2507.19484", "title": "Towards the ideals of Self-Recovery and Metadata Privacy in Social Vault Recovery", "authors": ["Shailesh Mishra", "Simone Colombo", "Pasindu Tennage", "Martin Burkhart", "Bryan Ford"], "categories": ["cs.CR", "cs.HC"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19484v1", "summary": "Social key recovery mechanisms enable users to recover their vaults with the\nhelp of trusted contacts, or trustees, avoiding the need for a single point of\ntrust or memorizing complex strings. However, existing mechanisms overlook the\nmemorability demands on users for recovery, such as the need to recall a\nthreshold number of trustees. Therefore, we first formalize the notion of\nrecovery metadata in the context of social key recovery, illustrating the\ntradeoff between easing the burden of memorizing the metadata and maintaining\nmetadata privacy. We present Apollo, the first framework that addresses this\ntradeoff by distributing indistinguishable data within a user's social circle,\nwhere trustees hold relevant data and non-trustees store random data. Apollo\neliminates the need to memorize recovery metadata since a user eventually\ngathers sufficient data from her social circle for recovery. Due to\nindistinguishability, Apollo protects metadata privacy by forming an anonymity\nset that hides the trustees among non-trustees. To make the anonymity set\nscalable, Apollo proposes a novel multi-layered secret sharing scheme that\nmitigates the overhead due to the random data distributed among non-trustees.\nFinally, we provide a prototype implementation of Apollo and report on its\nperformance. Apollo reduces the chances of malicious recovery to between 0.005%\nand 1.8%, depending on the adversary's ability to compromise. The multi-layered\ndesign shows a latency reduction from 1.1x to 740kx compared to a\nsingle-layered approach, depending on the number of reconnections.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19484v1", "cate": "cs.CR", "date": "2025-05-14", "updated": "2025-05-14"}
{"id": "2507.19609", "title": "Securing the Internet of Medical Things (IoMT): Real-World Attack Taxonomy and Practical Security Measures", "authors": ["Suman Deb", "Emil Lupu", "Emm Mic Drakakis", "Anil Anthony Bharath", "Zhen Kit Leung", "Guang Rui Ma", "Anupam Chattopadhyay"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Submitted as a book chapter in 'Handbook of Industrial Internet of Things' to be published by Springer Nature", "url": "http://arxiv.org/abs/2507.19609v1", "summary": "The Internet of Medical Things (IoMT) has the potential to radically improve\nhealthcare by enabling real-time monitoring, remote diagnostics, and AI-driven\ndecision making. However, the connectivity, embedded intelligence, and\ninclusion of a wide variety of novel sensors expose medical devices to severe\ncybersecurity threats, compromising patient safety and data privacy. In\naddition, many devices also have direct capacity - individually or in\nconjunction with other IoMT devices - to perform actions on the patient, such\nas delivering an electrical stimulus, administering a drug, or activating a\nmotor, which can potentially be life-threatening. We provide a taxonomy of\npotential attacks targeting IoMT, presenting attack surfaces, vulnerabilities,\nand mitigation strategies across all layers of the IoMT architecture. It\nanswers key questions such as: What makes IoMT security different from\ntraditional IT security? What are the cybersecurity threats to medical devices?\nHow can engineers design secure IoMT systems and protect hospital networks from\ncyberattacks? By analyzing historical cyber incidents, we highlight critical\nsecurity gaps and propose practical security guidelines for medical device\nengineers and security professionals. This work bridges the gap between\nresearch and implementation, equipping healthcare stakeholders with actionable\ninsights to build resilient and privacy-preserving IoMT ecosystems. Finally, we\npresent the latest standardization and compliance frameworks, that IoMT\nsecurity designers should be aware of.", "comment": "Submitted as a book chapter in 'Handbook of Industrial Internet of\n  Things' to be published by Springer Nature", "pdf_url": "http://arxiv.org/pdf/2507.19609v1", "cate": "cs.CR", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19880", "title": "Trivial Trojans: How Minimal MCP Servers Enable Cross-Tool Exfiltration of Sensitive Data", "authors": ["Nicola Croce", "Tobin South"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Abstract submitted to the Technical AI Governance Forum 2025 ( this https URL )", "url": "http://arxiv.org/abs/2507.19880v1", "summary": "The Model Context Protocol (MCP) represents a significant advancement in\nAI-tool integration, enabling seamless communication between AI agents and\nexternal services. However, this connectivity introduces novel attack vectors\nthat remain largely unexplored. This paper demonstrates how unsophisticated\nthreat actors, requiring only basic programming skills and free web tools, can\nexploit MCP's trust model to exfiltrate sensitive financial data. We present a\nproof-of-concept attack where a malicious weather MCP server, disguised as\nbenign functionality, discovers and exploits legitimate banking tools to steal\nuser account balances. The attack chain requires no advanced technical\nknowledge, server infrastructure, or monetary investment. The findings reveal a\ncritical security gap in the emerging MCP ecosystem: while individual servers\nmay appear trustworthy, their combination creates unexpected cross-server\nattack surfaces. Unlike traditional cybersecurity threats that assume\nsophisticated adversaries, our research shows that the barrier to entry for\nMCP-based attacks is alarmingly low. A threat actor with undergraduate-level\nPython knowledge can craft convincing social engineering attacks that exploit\nthe implicit trust relationships MCP establishes between AI agents and tool\nproviders. This work contributes to the nascent field of MCP security by\ndemonstrating that current MCP implementations allow trivial cross-server\nattacks and proposing both immediate mitigations and protocol improvements to\nsecure this emerging ecosystem.", "comment": "Abstract submitted to the Technical AI Governance Forum 2025\n  (https://www.techgov.ai/)", "pdf_url": "http://arxiv.org/pdf/2507.19880v1", "cate": "cs.CR", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19905", "title": "ConSeg: Contextual Backdoor Attack Against Semantic Segmentation", "authors": ["Bilal Hussain Abbasi", "Zirui Gong", "Yanjun Zhang", "Shang Gao", "Antonio Robles-Kelly", "Leo Zhang"], "categories": ["cs.CR", "cs.CV"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19905v1", "summary": "Despite significant advancements in computer vision, semantic segmentation\nmodels may be susceptible to backdoor attacks. These attacks, involving hidden\ntriggers, aim to cause the models to misclassify instances of the victim class\nas the target class when triggers are present, posing serious threats to the\nreliability of these models. To further explore the field of backdoor attacks\nagainst semantic segmentation, in this paper, we propose a simple yet effective\nbackdoor attack called Contextual Segmentation Backdoor Attack (ConSeg). ConSeg\nleverages the contextual information inherent in semantic segmentation models\nto enhance backdoor performance. Our method is motivated by an intriguing\nobservation, i.e., when the target class is set as the `co-occurring' class of\nthe victim class, the victim class can be more easily `mis-segmented'. Building\nupon this insight, ConSeg mimics the contextual information of the target class\nand rebuilds it in the victim region to establish the contextual relationship\nbetween the target class and the victim class, making the attack easier. Our\nexperiments reveal that ConSeg achieves improvements in Attack Success Rate\n(ASR) with increases of 15.55\\%, compared to existing methods, while exhibiting\nresilience against state-of-the-art backdoor defenses.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19905v1", "cate": "cs.CR", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19976", "title": "\"Blockchain-Enabled Zero Trust Framework for Securing FinTech Ecosystems Against Insider Threats and Cyber Attacks\"", "authors": ["Avinash Singh", "Vikas Pareek", "Asish Sharma"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19976v1", "summary": "Fintech provides technological services to increase operational efficiency in\nfinancial institutions, but traditional perimeter-based defense mechanisms are\ninsufficient against evolving cyber threats like insider attacks, malware\nintrusions, and Advanced Persistent Threats (APTs). These vulnerabilities\nexpose Fintech organizations to significant risks, including financial losses\nand data breaches. To address these challenges, this paper proposes a\nblockchain-integrated Zero Trust framework, adhering to the principle of \"Never\nTrust, Always Verify.\" The framework uses Ethereum smart contracts to enforce\nMulti Factor Authentication (MFA), Role-Based Access Control (RBAC), and\nJust-In-Time (JIT) access privileges, effectively mitigating credential theft\nand insider threats, the effect of malware and APT attacks.\n  The proposed solution transforms blockchain into a Policy Engine (PE) and\nPolicy Enforcement Point (PEP), and policy storage, ensuring immutable access\ncontrol and micro-segmentation. A decentralized application (DApp) prototype\nwas developed and tested using STRIDE threat modeling, demonstrating resilience\nagainst spoofing, tampering, and privilege escalation. Comparative analysis\nwith Perimeter-based systems revealed a trade-off: while the framework\nintroduced a marginal latency increase (74.0 ms vs. 49.33 ms) and reduced\nthroughput (30.77 vs. 50.0 requests/sec), it significantly enhanced security by\neliminating single points of failure and enabling tamper-proof audit trails.\n  Experimental validation on a 200-node simulated network confirmed the\nframework's robustness, with future optimizations targeting Layer-2 solutions\nfor scalability. This work bridges the gap between Zero Trust theory and\npractical blockchain implementation, offering Fintech organizations a\ndecentralized, cost-effective security model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19976v1", "cate": "cs.CR", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20014", "title": "Policy-Driven AI in Dataspaces: Taxonomy, Explainability, and Pathways for Compliant Innovation", "authors": ["Joydeep Chandra", "Satyam Kumar Navneet"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20014v1", "summary": "As AI-driven dataspaces become integral to data sharing and collaborative\nanalytics, ensuring privacy, performance, and policy compliance presents\nsignificant challenges. This paper provides a comprehensive review of\nprivacy-preserving and policy-aware AI techniques, including Federated\nLearning, Differential Privacy, Trusted Execution Environments, Homomorphic\nEncryption, and Secure Multi-Party Computation, alongside strategies for\naligning AI with regulatory frameworks such as GDPR and the EU AI Act. We\npropose a novel taxonomy to classify these techniques based on privacy levels,\nperformance impacts, and compliance complexity, offering a clear framework for\npractitioners and researchers to navigate trade-offs. Key performance metrics\n-- latency, throughput, cost overhead, model utility, fairness, and\nexplainability -- are analyzed to highlight the multi-dimensional optimization\nrequired in dataspaces. The paper identifies critical research gaps, including\nthe lack of standardized privacy-performance KPIs, challenges in explainable AI\nfor federated ecosystems, and semantic policy enforcement amidst regulatory\nfragmentation. Future directions are outlined, proposing a conceptual framework\nfor policy-driven alignment, automated compliance validation, standardized\nbenchmarking, and integration with European initiatives like GAIA-X, IDS, and\nEclipse EDC. By synthesizing technical, ethical, and regulatory perspectives,\nthis work lays the groundwork for developing trustworthy, efficient, and\ncompliant AI systems in dataspaces, fostering innovation in secure and\nresponsible data-driven ecosystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20014v1", "cate": "cs.CR", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20074", "title": "Cryptographic Data Exchange for Nuclear Warheads", "authors": ["Neil Perry", "Daniil Zhukov"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      17 pages, 4 figures, 4 tables", "url": "http://arxiv.org/abs/2507.20074v1", "summary": "Nuclear arms control treaties have historically focused on strategic nuclear\ndelivery systems, leaving nuclear warheads outside formal verification\nframeworks. This paper presents a cryptographic protocol for secure and\nverifiable warhead tracking, addressing challenges in nuclear warhead\nverification without requiring intrusive physical inspections. Our system\nleverages commitment schemes and zero-knowledge succinct non-interactive\narguments of knowledge (zkSNARKs) to ensure compliance with treaty constraints\nwhile preserving the confidentiality of sensitive nuclear warhead data. We\npropose a cryptographic \"Warhead Passport\" tracking system that chains\ncommitments to individual warheads over their life cycle, enabling periodic\nchallenges and real-time verification of treaty compliance. Our implementation\nfollows real-world treaty constraints, integrates U.S. and Russian dual-hash\ncombiners (SHA-family & GOST R 34.11 family) for cryptographic robustness and\npolitical constraints, and ensures forward security by preventing retroactive\ndata manipulation. This work builds on policy research from prior arms control\nstudies and provides a practical foundation for implementing secure, auditable\nNSNW verification mechanisms.", "comment": "17 pages, 4 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.20074v1", "cate": "cs.CR", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20175", "title": "SoK: Root Cause of \\$1 Billion Loss in Smart Contract Real-World Attacks via a Systematic Literature Review of Vulnerabilities", "authors": ["Hadis Rezaei", "Mojtaba Eshghie", "Karl Anderesson", "Francesco Palmieri"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20175v1", "summary": "The Ethereum ecosystem, despite its maturity, continues to witness\ncatastrophic attacks, with billions of dollars in assets lost annually. In\nresponse, a significant body of research has focused on identifying and\nmitigating smart contract vulnerabilities. However, these efforts predominantly\nfocus on implementation-level bugs, leaving a critical gap between academic\nunderstanding of vulnerabilities and the root causes of real-world high-impact\nfinancial losses. We employ a two-pronged methodology: first, a systematic\nliterature review of 71 academic papers to build a comprehensive and up-to-date\ncatalog of 24 active and 5 deprecated vulnerabilities as understood by the\nresearch community. Second, we conduct an in-depth, empirical analysis of 50 of\nthe most severe real-world exploits between 2022 and 2025, collectively\nincurring over \\$1.09B in losses, to identify their true root causes. We\nintroduce the concept of \"exploit chains\" by revealing that many incidents are\nnot caused by isolated vulnerabilities but by combinations of human,\noperational, and economic design flaws that link with implementation bugs to\nenable an attack. Our analysis yields insights on how DApps are exploited in\npractice, leading to a novel, four-tier root-cause framework that moves beyond\ncode-level vulnerabilities. We find that real-world successful attacks on\nEthereum (and related networks) trace back to one of the four tiers of (1)\nprotocol logic design, (2) lifecycle and governance, (3) external dependencies,\nand (4) traditional implementation bugs (classic smart contract\nvulnerabilities). We investigate the suitability of this multi-tier incident\nroot-cause framework via a case study.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20175v1", "cate": "cs.CR", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20361", "title": "Measuring and Explaining the Effects of Android App Transformations in Online Malware Detection", "authors": ["Guozhu Meng", "Zhixiu Guo", "Xiaodong Zhang", "Haoyu Wang", "Kai Chen", "Yang Liu"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      12 pages, Accepted by Internetware 2025", "url": "http://arxiv.org/abs/2507.20361v1", "summary": "It is well known that antivirus engines are vulnerable to evasion techniques\n(e.g., obfuscation) that transform malware into its variants. However, it\ncannot be necessarily attributed to the effectiveness of these evasions, and\nthe limits of engines may also make this unsatisfactory result. In this study,\nwe propose a data-driven approach to measure the effect of app transformations\nto malware detection, and further explain why the detection result is produced\nby these engines. First, we develop an interaction model for antivirus engines,\nillustrating how they respond with different detection results in terms of\nvarying inputs. Six app transformation techniques are implemented in order to\ngenerate a large number of Android apps with traceable changes. Then we\nundertake a one-month tracking of app detection results from multiple antivirus\nengines, through which we obtain over 971K detection reports from VirusTotal\nfor 179K apps in total. Last, we conduct a comprehensive analysis of antivirus\nengines based on these reports from the perspectives of signature-based, static\nanalysis-based, and dynamic analysis-based detection techniques. The results,\ntogether with 7 highlighted findings, identify a number of sealed working\nmechanisms occurring inside antivirus engines and what are the indicators of\ncompromise in apps during malware detection.", "comment": "12 pages, Accepted by Internetware 2025", "pdf_url": "http://arxiv.org/pdf/2507.20361v1", "cate": "cs.CR", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20434", "title": "Is Crunching Public Data the Right Approach to Detect BGP Hijacks?", "authors": ["Alessandro Giaconia", "Muoi Tran", "Laurent Vanbever", "Stefano Vissicchio"], "categories": ["cs.CR", "cs.NI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20434v1", "summary": "The Border Gateway Protocol (BGP) remains a fragile pillar of Internet\nrouting. BGP hijacks still occurr daily. While full deployment of Route Origin\nValidation (ROV) is ongoing, attackers have already adapted, launching post-ROV\nattacks such as forged-origin hijacks. To detect these, recent approaches like\nDFOH [Holterbach et al., USENIX NSDI '24] and BEAM [Chen et al., USENIX\nSecurity '24] apply machine learning (ML) to analyze data from globally\ndistributed BGP monitors, assuming anomalies will stand out against historical\npatterns. However, this assumption overlooks a key threat: BGP monitors\nthemselves can be misled by adversaries injecting bogus routes. This paper\nshows that state-of-the-art hijack detection systems like DFOH and BEAM are\nvulnerable to data poisoning. Using large-scale BGP simulations, we show that\nattackers can evade detection with just a handful of crafted announcements\nbeyond the actual hijack. These announcements are indeed sufficient to corrupt\nthe knowledge base used by ML-based defenses and distort the metrics they rely\non. Our results highlight a worrying weakness of relying solely on public BGP\ndata.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20434v1", "cate": "cs.CR", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20554", "title": "MPC-EVM: Enabling MPC Execution by Smart Contracts In An Asynchronous Manner", "authors": ["Yichen Zhou", "Chenxing Li", "Fan Long"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20554v1", "summary": "This paper presents MPC-EVM, the first blockchain prototype that extends the\nEVM to enable asynchronous MPC invocations by smart contracts during\ntransaction executions without compromising consistency or throughput. MPC-EVM\nuses an asynchronous execution model to process MPC-invoking transactions in a\nnon-blocking fashion, saving the transaction's progress when it enters an MPC\nand resuming its execution upon MPC's completion. Additionally, it employs an\naccess control mechanism that prevents inconsistent state access and\nmodifications as a result of asynchronous executions. Benchmarking MPC-EVM's\nthroughput show that the transactions per second (TPS) decreased by less than\n3% compared to the baseline when MPC-invoking transactions are executed\nalongside regular transactions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20554v1", "cate": "cs.CR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20650", "title": "Hot-Swap MarkBoard: An Efficient Black-box Watermarking Approach for Large-scale Model Distribution", "authors": ["Zhicheng Zhang", "Peizhuo Lv", "Mengke Wan", "Jiang Fang", "Diandian Guo", "Yezeng Chen", "Yinlong Liu", "Wei Ma", "Jiyan Sun", "Liru Geng"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20650v1", "summary": "Recently, Deep Learning (DL) models have been increasingly deployed on\nend-user devices as On-Device AI, offering improved efficiency and privacy.\nHowever, this deployment trend poses more serious Intellectual Property (IP)\nrisks, as models are distributed on numerous local devices, making them\nvulnerable to theft and redistribution. Most existing ownership protection\nsolutions (e.g., backdoor-based watermarking) are designed for cloud-based\nAI-as-a-Service (AIaaS) and are not directly applicable to large-scale\ndistribution scenarios, where each user-specific model instance must carry a\nunique watermark. These methods typically embed a fixed watermark, and\nmodifying the embedded watermark requires retraining the model. To address\nthese challenges, we propose Hot-Swap MarkBoard, an efficient watermarking\nmethod. It encodes user-specific $n$-bit binary signatures by independently\nembedding multiple watermarks into a multi-branch Low-Rank Adaptation (LoRA)\nmodule, enabling efficient watermark customization without retraining through\nbranch swapping. A parameter obfuscation mechanism further entangles the\nwatermark weights with those of the base model, preventing removal without\ndegrading model performance. The method supports black-box verification and is\ncompatible with various model architectures and DL tasks, including\nclassification, image generation, and text generation. Extensive experiments\nacross three types of tasks and six backbone models demonstrate our method's\nsuperior efficiency and adaptability compared to existing approaches, achieving\n100\\% verification accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20650v1", "cate": "cs.CR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20672", "title": "Program Analysis for High-Value Smart Contract Vulnerabilities: Techniques and Insights", "authors": ["Yannis Smaragdakis", "Neville Grech", "Sifis Lagouvardos", "Konstantinos Triantafyllou", "Ilias Tsatiris", "Yannis Bollanos", "Tony Rocco Valentine"], "categories": ["cs.CR", "cs.PL"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20672v1", "summary": "A widespread belief in the blockchain security community is that automated\ntechniques are only good for detecting shallow bugs, typically of small value.\nIn this paper, we present the techniques and insights that have led us to\nrepeatable success in automatically discovering high-value smart contract\nvulnerabilities. Our vulnerability disclosures have yielded 10 bug bounties,\nfor a total of over $3M, over high-profile deployed code, as well as hundreds\nof bugs detected in pre-deployment or under-audit code.\n  We argue that the elements of this surprising success are a) a very\nhigh-completeness static analysis approach that manages to maintain acceptable\nprecision; b) domain knowledge, provided by experts or captured via statistical\ninference. We present novel techniques for automatically inferring domain\nknowledge from statistical analysis of a large corpus of deployed contracts, as\nwell as discuss insights on the ideal precision and warning rate of a promising\nvulnerability detector. In contrast to academic literature in program analysis,\nwhich routinely expects false-positive rates below 50% for publishable results,\nwe posit that a useful analysis for high-value real-world vulnerabilities will\nlikely flag very few programs (under 1%) and will do so with a high\nfalse-positive rate (e.g., 95%, meaning that only one-of-twenty human\ninspections will yield an exploitable vulnerability).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20672v1", "cate": "cs.CR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20676", "title": "A Novel Post-Quantum Secure Digital Signature Scheme Based on Neural Network", "authors": ["Satish Kumar", "Md. Arzoo Jamal"], "categories": ["cs.CR", "math.GR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20676v1", "summary": "Digital signatures are fundamental cryptographic primitives that ensure the\nauthenticity and integrity of digital documents. In the post-quantum era,\nclassical public key-based signature schemes become vulnerable to brute-force\nand key-recovery attacks due to the computational power of quantum algorithms.\nMultivariate polynomial based signature schemes are among the one of the\ncryptographic constructions that offers strong security guarantees against such\nquantum threats. With the growing capabilities of neural networks, it is\nnatural to explore their potential application in the design of cryptographic\nprimitives. Neural networks inherently captures the non-linear relationships\nwithin the data, which are encoded in their synaptic weight matrices and bias\nvectors. In this paper, we propose a novel construction of a multivariate\npolynomial based digital signature scheme that leverages neural network\narchitectures. A neural network with binary weights is employed to define the\ncentral structure of the signature scheme. The design introduces a recurrent\nrandom vector, functionally analogous to an attention mechanism, which\ncontributes dynamic randomness based on the previous state, thereby enhancing\nthe scheme's security. It is demonstrated that the proposed signature scheme\nprovide security against Existential Unforgeability under adaptive\nChosen-Message Attacks (EUF-CMA). Furthermore, it is proven that direct attacks\naimed to recover the private keys are computationally infeasible within\npolynomial time, even in the presence of quantum computing abilities. The\noperational characteristics of the proposed scheme are also evaluated, with\nresults indicating notable efficiency and practical viability in post-quantum\ncryptographic applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20676v1", "cate": "cs.CR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20688", "title": "Guard-GBDT: Efficient Privacy-Preserving Approximated GBDT Training on Vertical Dataset", "authors": ["Anxiao Song", "Shujie Cui", "Jianli Bai", "Ke Cheng", "Yulong Shen", "Giovanni Russello"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted by The 28th International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2025)", "url": "http://arxiv.org/abs/2507.20688v1", "summary": "In light of increasing privacy concerns and stringent legal regulations,\nusing secure multiparty computation (MPC) to enable collaborative GBDT model\ntraining among multiple data owners has garnered significant attention. Despite\nthis, existing MPC-based GBDT frameworks face efficiency challenges due to high\ncommunication costs and the computation burden of non-linear operations, such\nas division and sigmoid calculations. In this work, we introduce Guard-GBDT, an\ninnovative framework tailored for efficient and privacy-preserving GBDT\ntraining on vertical datasets. Guard-GBDT bypasses MPC-unfriendly division and\nsigmoid functions by using more streamlined approximations and reduces\ncommunication overhead by compressing the messages exchanged during gradient\naggregation. We implement a prototype of Guard-GBDT and extensively evaluate\nits performance and accuracy on various real-world datasets. The results show\nthat Guard-GBDT outperforms state-of-the-art HEP-XGB (CIKM'21) and SiGBDT (ASIA\nCCS'24) by up to $2.71\\times$ and $12.21 \\times$ on LAN network and up to\n$2.7\\times$ and $8.2\\times$ on WAN network. Guard-GBDT also achieves comparable\naccuracy with SiGBDT and plaintext XGBoost (better than HEP-XGB ), which\nexhibits a deviation of $\\pm1\\%$ to $\\pm2\\%$ only. Our implementation code is\nprovided at https://github.com/XidianNSS/Guard-GBDT.git.", "comment": "Accepted by The 28th International Symposium on Research in Attacks,\n  Intrusions and Defenses (RAID 2025)", "pdf_url": "http://arxiv.org/pdf/2507.20688v1", "cate": "cs.CR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19550", "title": "Towards Multi-Agent Economies: Enhancing the A2A Protocol with Ledger-Anchored Identities and x402 Micropayments for AI Agents", "authors": ["Awid Vaziry", "Sandro Rodriguez Garzon", "Axel Küpper"], "categories": ["cs.MA", "cs.NI"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19550v1", "summary": "This research article presents a novel architecture to empower multi-agent\neconomies by addressing two critical limitations of the emerging Agent2Agent\n(A2A) communication protocol: decentralized agent discoverability and\nagent-to-agent micropayments. By integrating distributed ledger technology\n(DLT), this architecture enables tamper-proof, on-chain publishing of\nAgentCards as smart contracts, providing secure and verifiable agent\nidentities. The architecture further extends A2A with the x402 open standard,\nfacilitating blockchain-agnostic, HTTP-based micropayments via the HTTP 402\nstatus code. This enables autonomous agents to seamlessly discover,\nauthenticate, and compensate each other across organizational boundaries. This\nwork further presents a comprehensive technical implementation and evaluation,\ndemonstrating the feasibility of DLT-based agent discovery and micropayments.\nThe proposed approach lays the groundwork for secure, scalable, and\neconomically viable multi-agent ecosystems, advancing the field of agentic AI\ntoward trusted, autonomous economic interactions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19550v1", "cate": "cs.MA", "date": "2025-07-24", "updated": "2025-07-24"}
{"id": "2507.20851", "title": "An Open-source Implementation and Security Analysis of Triad's TEE Trusted Time Protocol", "authors": ["Matthieu Bettinger", "Sonia Ben Mokhtar", "Anthony Simonet-Boulogne"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20851v1", "summary": "The logic of many protocols relies on time measurements. However, in Trusted\nExecution Environments (TEEs) like Intel SGX, the time source is outside the\nTrusted Computing Base: a malicious system hosting the TEE can manipulate that\nTEE's notion of time, e.g., jumping in time or affecting the perceived time\nspeed. Previous work like Triad propose protocols for TEEs to maintain a\ntrustworthy time source. However, in this paper, based on a public\nimplementation of Triad that we contribute, we empirically showcase\nvulnerabilities to this protocol. For example, an attacker controlling the\noperating system, and consequently the scheduling algorithm, may arbitrarily\nmanipulate their local TEE's clock speed. What is worse, in case of faster\nmalicious clock speeds, an attacker on a single compromised machine may\npropagate the attack to honest machines participating in Triad's Trusted Time\nprotocol, causing them to skip to timestamps arbitrarily far in the future.\nThen, infected honest machines propagate time-skips themselves to other honest\nmachines interacting with them. We discuss protocol changes to Triad for higher\nresilience against such attacks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20851v1", "cate": "cs.CR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20215", "title": "MLC-Agent: Cognitive Model based on Memory-Learning Collaboration in LLM Empowered Agent Simulation Environment", "authors": ["Ming Zhang", "Yiling Xuan", "Qun Ma", "Yuwei Guo"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20215v1", "summary": "Many real-world systems, such as transportation systems, ecological systems,\nand Internet systems, are complex systems. As an important tool for studying\ncomplex systems, computational experiments can map them into artificial society\nmodels that are computable and reproducible within computers, thereby providing\ndigital and computational methods for quantitative analysis. In current\nresearch, the construction of individual agent models often ignores the\nlong-term accumulative effect of memory mechanisms in the development process\nof agents, which to some extent causes the constructed models to deviate from\nthe real characteristics of real-world systems. To address this challenge, this\npaper proposes an individual agent model based on a memory-learning\ncollaboration mechanism, which implements hierarchical modeling of the memory\nmechanism and a multi-indicator evaluation mechanism. Through hierarchical\nmodeling of the individual memory repository, the group memory repository, and\nthe memory buffer pool, memory can be effectively managed, and knowledge\nsharing and dissemination between individuals and groups can be promoted. At\nthe same time, the multi-indicator evaluation mechanism enables dynamic\nevaluation of memory information, allowing dynamic updates of information in\nthe memory set and promoting collaborative decision-making between memory and\nlearning. Experimental results show that, compared with existing memory\nmodeling methods, the agents constructed by the proposed model demonstrate\nbetter decision-making quality and adaptability within the system. This\nverifies the effectiveness of the individual agent model based on the\nmemory-learning collaboration mechanism proposed in this paper in improving the\nquality of individual-level modeling in artificial society modeling and\nachieving anthropomorphic characteristics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20215v1", "cate": "cs.MA", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20873", "title": "Testbed and Software Architecture for Enhancing Security in Industrial Private 5G Networks", "authors": ["Song Son Ha", "Florian Foerster", "Thomas Robert Doebbert", "Tim Kittel", "Dominik Merli", "Gerd Scholl"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20873v1", "summary": "In the era of Industry 4.0, the growing need for secure and efficient\ncommunication systems has driven the development of fifth-generation (5G)\nnetworks characterized by extremely low latency, massive device connectivity\nand high data transfer speeds. However, the deployment of 5G networks presents\nsignificant security challenges, requiring advanced and robust solutions to\ncounter increasingly sophisticated cyber threats. This paper proposes a testbed\nand software architecture to strengthen the security of Private 5G Networks,\nparticularly in industrial communication environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20873v1", "cate": "cs.CR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2411.09840", "title": "Self-Propelled Agents and Group Social Force", "authors": ["Peng Wang", "Peter Luh"], "categories": ["physics.soc-ph", "cs.MA", "math.DS", "nlin.AO"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "Comments:      16 pages, 10 figures. arXiv admin note: text overlap with arXiv:2206.01393", "url": "http://arxiv.org/abs/2411.09840v3", "summary": "Brownian motion have long been studied on a diversity of fields, not only in\nphysics of statistical mechanics, but also in biological models, finance and\neconomic process, and social systems. In the past twenty years, there has been\na growing interest in studying the model in self-propelled feature and\ninteraction force such that the model also fits into study of social phenomenon\nof many individuals. This article will continue with this research trend and\nespecially investigate the model in paradigms for a quantitative description of\nsocial and economic process. We mainly discuss a class of collective decision\nprocess of Brownian agent/particles, where the stochastic process does not\nexist in the fluctuation in the traditional Brownian motion, but in selection\namong several discrete choices. Their decisions interacts with each other in a\ngiven social topology. To simplify our discussion the binary choice problem is\nparticularly discussed where each agent only takes an alternative of two\nchoices. Mathematically, we introduce a set of arrays to describe social\nrelationship of agents in a quantitative manner, and the arrays deduce the\ngroup social force and opinion dynamics, which are useful to study complex\nsocial movement and self-organization phenomena including discrete-choice\nactivities, social groups and de-individualization effect. Such agent-based\nsimulation symbolizes a variety of collective activities in human society,\nespecially in the field of economics and social science.", "comment": "16 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:2206.01393", "pdf_url": "http://arxiv.org/pdf/2411.09840v3", "cate": "physics.soc-ph", "date": "2024-11-14", "updated": "2025-05-07"}
{"id": "2507.20891", "title": "Characterizing the Sensitivity to Individual Bit Flips in Client-Side Operations of the CKKS Scheme", "authors": ["Matias Mazzanti", "Augusto Vega", "Esteban Mocskos"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20891v1", "summary": "Homomorphic Encryption (HE) enables computation on encrypted data without\ndecryption, making it a cornerstone of privacy-preserving computation in\nuntrusted environments. As HE sees growing adoption in sensitive applications\nsuch as secure machine learning and confidential data analysis ensuring its\nrobustness against errors becomes critical. Faults (e.g., transmission errors,\nhardware malfunctions, or synchronization failures) can corrupt encrypted data\nand compromise the integrity of HE operations. However, the impact of soft\nerrors (such as bit flips) on modern HE schemes remains unexplored.\nSpecifically, the CKKS scheme-one of the most widely used HE schemes for\napproximate arithmetic-lacks a systematic study of how such errors propagate\nacross its pipeline, particularly under optimizations like the Residue Number\nSystem (RNS) and Number Theoretic Transform (NTT). This work bridges that gap\nby presenting a theoretical and empirical analysis of CKKS's fault tolerance\nunder single bit-flip errors. We focus on client-side operations (encoding,\nencryption, decryption, and decoding) and demonstrate that while the vanilla\nCKKS scheme exhibits some resilience, performance optimizations (RNS/NTT)\nintroduce significant fragility, amplifying error sensitivity. By\ncharacterizing these failure modes, we lay the groundwork for error-resilient\nHE designs, ensuring both performance and integrity in privacy-critical\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20891v1", "cate": "cs.CR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19543", "title": "Agent WARPP: Workflow Adherence via Runtime Parallel Personalization", "authors": ["Maria Emilia Mazzolenis", "Ruirui Zhang"], "categories": ["cs.AI", "cs.MA", "I.2.11; I.2.7"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted at the ICML 2025 Workshop on Multi-Agent Systems in the Era of Foundation Models: Opportunities, Challenges, and Futures. Code repo: this https URL", "url": "http://arxiv.org/abs/2507.19543v1", "summary": "Large language models (LLMs) are increasingly applied in task-oriented\ndialogue (TOD) systems but often struggle with long, conditional workflows that\ninvolve external tool calls and depend on user-specific information. We present\nWorkflow Adherence via Runtime Parallel Personalization, or WARPP, a\ntraining-free, modular framework that combines multi-agent orchestration with\nruntime personalization to improve workflow adherence in LLM-based systems. By\ndynamically pruning conditional branches based on user attributes, the\nframework reduces reasoning overhead and narrows tool selection at runtime.\nWARPP deploys a parallelized architecture where a dedicated Personalizer agent\noperates alongside modular, domain-specific agents to dynamically tailor\nexecution paths in real time. The framework is evaluated across five\nrepresentative user intents of varying complexity within three domains:\nbanking, flights, and healthcare. Our evaluation leverages synthetic datasets\nand LLM-powered simulated users to test scenarios with conditional\ndependencies. Our results demonstrate that WARPP outperforms both the\nnon-personalized method and the ReAct baseline, achieving increasingly larger\ngains in parameter fidelity and tool accuracy as intent complexity grows, while\nalso reducing average token usage, without any additional training.", "comment": "Accepted at the ICML 2025 Workshop on Multi-Agent Systems in the Era\n  of Foundation Models: Opportunities, Challenges, and Futures. Code repo:\n  https://github.com/emiliamazzo/WARPP/", "pdf_url": "http://arxiv.org/pdf/2507.19543v1", "cate": "cs.AI", "date": "2025-07-23", "updated": "2025-07-23"}
{"id": "2507.21038", "title": "Development and analysis of a secured VoIP system for surveillance activities", "authors": ["M. Matsive Ali"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21038v2", "summary": "Since the 1990s, the telephone has been the primary mode of communication.\nHowever, Voice over Internet Protocol (VoIP), which is a highly straightforward\nand affordable form of data transfer, is now becoming an important part of\ndaily communication. VoIP is the technology that makes it possible to send\nspeech and multimedia data packets across either a public or private IP\nnetwork. However, a cyberattack known as a man-in-the-middle attack poses a\nserious concern in transferring data through any network. Therefore, the\nauthors have designed a system that sends voice over the internet within the\nrange of a router using encrypted data transfer. An embedded system comprising\nan electret microphone, Embedded C, Particle Photon microcontroller, and\nInternet of Things (IoT) technology is developed. Due to its compact size, this\ntype of device may be incorporated into automobiles, surveillance systems, or\ncovert listening tools. The VoIP system gathers sound signals using the MAX9814\nmicrophone, while the Particle Photon microcontroller securely transmits the\ndata. Devices with access can download data from the VoIP systems Transmission\nControl Protocol (TCP) server. The accessed device stores the audio locally and\nuploads the corresponding data to Google Drive. This VoIP system provides a\nsecure method of communication while conserving the integrity of the original\nsignal.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21038v2", "cate": "cs.CR", "date": "2025-07-28", "updated": "2025-07-29"}
{"id": "2507.19570", "title": "MCP4EDA: LLM-Powered Model Context Protocol RTL-to-GDSII Automation with Backend Aware Synthesis Optimization", "authors": ["Yiting Wang", "Wanghao Ye", "Yexiao He", "Yiran Chen", "Gang Qu", "Ang Li"], "categories": ["cs.AR", "cs.MA"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures Keywords: Model Context Protocol, Electronic Design Automation, Large Language Models, Synthesis Optimization", "url": "http://arxiv.org/abs/2507.19570v1", "summary": "This paper presents MCP4EDA, the first Model Context Protocol server that\nenables Large Language Models (LLMs) to control and optimize the complete\nopen-source RTL-to-GDSII design flow through natural language interaction. The\nsystem integrates Yosys synthesis, Icarus Verilog simulation, OpenLane\nplace-and-route, GTKWave analysis, and KLayout visualization into a unified\nLLM-accessible interface, enabling designers to execute complex multi-tool EDA\nworkflows conversationally via AI assistants such as Claude Desktop and Cursor\nIDE. The principal contribution is a backend-aware synthesis optimization\nmethodology wherein LLMs analyze actual post-layout timing, power, and area\nmetrics from OpenLane results to iteratively refine synthesis TCL scripts,\nestablishing a closed-loop optimization system that bridges the traditional gap\nbetween synthesis estimates and physical implementation reality. In contrast to\nconventional flows that rely on wire-load models, this methodology leverages\nreal backend performance data to guide synthesis parameter tuning, optimization\nsequence selection, and constraint refinement, with the LLM functioning as an\nintelligent design space exploration agent. Experimental evaluation on\nrepresentative digital designs demonstrates 15-30% improvements in timing\nclosure and 10-20% area reduction compared to default synthesis flows,\nestablishing MCP4EDA as the first practical LLM-controlled end-to-end\nopen-source EDA automation system. The code and demo are avaiable at:\nhttp://www.agent4eda.com/", "comment": "7 pages, 5 figures Keywords: Model Context Protocol, Electronic\n  Design Automation, Large Language Models, Synthesis Optimization", "pdf_url": "http://arxiv.org/pdf/2507.19570v1", "cate": "cs.AR", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19555", "title": "Extending Group Relative Policy Optimization to Continuous Control: A Theoretical Framework for Robotic Reinforcement Learning", "authors": ["Rajat Khanda", "Mohammad Baqar", "Sambuddha Chakrabarti", "Satyasaran Changdar"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      13 pages, 2 figures", "url": "http://arxiv.org/abs/2507.19555v1", "summary": "Group Relative Policy Optimization (GRPO) has shown promise in discrete\naction spaces by eliminating value function dependencies through group-based\nadvantage estimation. However, its application to continuous control remains\nunexplored, limiting its utility in robotics where continuous actions are\nessential. This paper presents a theoretical framework extending GRPO to\ncontinuous control environments, addressing challenges in high-dimensional\naction spaces, sparse rewards, and temporal dynamics. Our approach introduces\ntrajectory-based policy clustering, state-aware advantage estimation, and\nregularized policy updates designed for robotic applications. We provide\ntheoretical analysis of convergence properties and computational complexity,\nestablishing a foundation for future empirical validation in robotic systems\nincluding locomotion and manipulation tasks.", "comment": "13 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.19555v1", "cate": "cs.RO", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19598", "title": "MOCHA: Are Code Language Models Robust Against Multi-Turn Malicious Coding Prompts?", "authors": ["Muntasir Wahed", "Xiaona Zhou", "Kiet A. Nguyen", "Tianjiao Yu", "Nirav Diwan", "Gang Wang", "Dilek Hakkani-Tür", "Ismini Lourentzou"], "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Winner Defender Team at Amazon Nova AI Challenge 2025", "url": "http://arxiv.org/abs/2507.19598v1", "summary": "Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their code generation capabilities. However, their robustness against\nadversarial misuse, particularly through multi-turn malicious coding prompts,\nremains underexplored. In this work, we introduce code decomposition attacks,\nwhere a malicious coding task is broken down into a series of seemingly benign\nsubtasks across multiple conversational turns to evade safety filters. To\nfacilitate systematic evaluation, we introduce \\benchmarkname{}, a large-scale\nbenchmark designed to evaluate the robustness of code LLMs against both\nsingle-turn and multi-turn malicious prompts. Empirical results across open-\nand closed-source models reveal persistent vulnerabilities, especially under\nmulti-turn scenarios. Fine-tuning on MOCHA improves rejection rates while\npreserving coding ability, and importantly, enhances robustness on external\nadversarial datasets with up to 32.4% increase in rejection rates without any\nadditional supervision.", "comment": "Winner Defender Team at Amazon Nova AI Challenge 2025", "pdf_url": "http://arxiv.org/pdf/2507.19598v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19593", "title": "Hypergames: Modeling Misaligned Perceptions and Nested Beliefs for Multi-agent Systems", "authors": ["Vince Trencsenyi", "Agnieszka Mensfelt", "Kostas Stathis"], "categories": ["cs.AI", "cs.MA"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19593v1", "summary": "Classical game-theoretic models typically assume rational agents, complete\ninformation, and common knowledge of payoffs - assumptions that are often\nviolated in real-world MAS characterized by uncertainty, misaligned\nperceptions, and nested beliefs. To overcome these limitations, researchers\nhave proposed extensions that incorporate models of cognitive constraints,\nsubjective beliefs, and heterogeneous reasoning. Among these, hypergame theory\nextends the classical paradigm by explicitly modeling agents' subjective\nperceptions of the strategic scenario, known as perceptual games, in which\nagents may hold divergent beliefs about the structure, payoffs, or available\nactions. We present a systematic review of agent-compatible applications of\nhypergame theory, examining how its descriptive capabilities have been adapted\nto dynamic and interactive MAS contexts. We analyze 44 selected studies from\ncybersecurity, robotics, social simulation, communications, and general\ngame-theoretic modeling. Building on a formal introduction to hypergame theory\nand its two major extensions - hierarchical hypergames and HNF - we develop\nagent-compatibility criteria and an agent-based classification framework to\nassess integration patterns and practical applicability. Our analysis reveals\nprevailing tendencies, including the prevalence of hierarchical and graph-based\nmodels in deceptive reasoning and the simplification of extensive theoretical\nframeworks in practical applications. We identify structural gaps, including\nthe limited adoption of HNF-based models, the lack of formal hypergame\nlanguages, and unexplored opportunities for modeling human-agent and\nagent-agent misalignment. By synthesizing trends, challenges, and open research\ndirections, this review provides a new roadmap for applying hypergame theory to\nenhance the realism and effectiveness of strategic modeling in dynamic\nmulti-agent environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19593v1", "cate": "cs.AI", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19642", "title": "Reward-Augmented Reinforcement Learning for Continuous Control in Precision Autonomous Parking via Policy Optimization Methods", "authors": ["Ahmad Suleman", "Misha Urooj Khan", "Zeeshan Kaleem", "Ali H. Alenezi", "Iqra Shabbir Sinem Coleri", "Chau Yuen"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19642v1", "summary": "Autonomous parking (AP) represents a critical yet complex subset of\nintelligent vehicle automation, characterized by tight spatial constraints,\nfrequent close-range obstacle interactions, and stringent safety margins.\nHowever, conventional rule-based and model-predictive methods often lack the\nadaptability and generalization needed to handle the nonlinear and\nenvironment-dependent complexities of AP. To address these limitations, we\npropose a reward-augmented learning framework for AP (RARLAP), that mitigates\nthe inherent complexities of continuous-domain control by leveraging structured\nreward design to induce smooth and adaptable policy behavior, trained entirely\nwithin a high-fidelity Unity-based custom 3D simulation environment. We\nsystematically design and assess three structured reward strategies: goal-only\nreward (GOR), dense proximity reward (DPR), and milestone-augmented reward\n(MAR), each integrated with both on-policy and off-policy optimization\nparadigms. Empirical evaluations demonstrate that the on-policy MAR achieves a\n91\\% success rate, yielding smoother trajectories and more robust behavior,\nwhile GOR and DPR fail to guide effective learning. Convergence and trajectory\nanalyses demonstrate that the proposed framework enhances policy adaptability,\naccelerates training, and improves safety in continuous control. Overall,\nRARLAP establishes that reward augmentation effectively addresses complex\nautonomous parking challenges, enabling scalable and efficient policy\noptimization with both on- and off-policy methods. To support reproducibility,\nthe code accompanying this paper is publicly available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19642v1", "cate": "cs.RO", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19695", "title": "Polar Coding and Linear Decoding", "authors": ["Geraldo A. Barbosa"], "categories": ["cs.IT", "cs.CR", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      31 pages, 29 figures, this is a requested replacement to AH-150926 arXiv - submit/6640470, due to formatting problems", "url": "http://arxiv.org/abs/2507.19695v1", "summary": "Polar encoding, described by Arikan in IEEE Transactions on Information\nTheory, Vol. 55, No. 7, July 2009, was a milestone for telecommunications. A\nPolar code distributes information among high and low-capacity channels,\nshowing the possibility of achieving perfect channel capacity. The\nhigh-capacity channels allow almost noiseless transmission of data. When these\nchannels are not high noise, reliability is achieved in the signal\ntransmission. It starts to compete against codes such a Low-Density\nParity-Check (LDPC) codes. Polar code can be also considered error correcting,\nbased on the redundancy inherent in its structure. This feature makes polar\nencoding also applicable to digital quantum-resistant cryptography protocols.\nThis work explores linear decoding at a first or single trial in the case of\nsmall losses or small number of bit-flipping, and repeated transmission for\nmedium level losses. This is distinct from Arikans successive probabilistic\ndecoding by application of probabilistic rules. Linear decoding is done\ndirectly from solving the linear equations connecting the codewords x and the\nreceived signals y after transmission via noisy channels. Numerical examples\nwill be shown. Along with this work, programming in Mathematica language was\nused. Codes are available for copy-and-paste for Mathematica users to\nimmediately try the described formalism.", "comment": "31 pages, 29 figures", "pdf_url": "http://arxiv.org/pdf/2507.19695v1", "cate": "cs.IT", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19694", "title": "Ultracoarse Equilibria and Ordinal-Folding Dynamics in Operator-Algebraic Models of Infinite Multi-Agent Games", "authors": ["Faruk Alpay", "Hamdi Alakkad", "Bugra Kilictas", "Taylan Alpay"], "categories": ["math.OC", "cs.AI", "cs.GT", "cs.MA", "91A26, 47L65, 03E10, 91B32"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      15 pages, 2 figures; companion implementation available at this https URL", "url": "http://arxiv.org/abs/2507.19694v1", "summary": "We develop an operator algebraic framework for infinite games with a\ncontinuum of agents and prove that regret based learning dynamics governed by a\nnoncommutative continuity equation converge to a unique quantal response\nequilibrium under mild regularity assumptions. The framework unifies functional\nanalysis, coarse geometry and game theory by assigning to every game a von\nNeumann algebra that represents collective strategy evolution. A reflective\nregret operator within this algebra drives the flow of strategy distributions\nand its fixed point characterises equilibrium. We introduce the ordinal folding\nindex, a computable ordinal valued metric that measures the self referential\ndepth of the dynamics, and show that it bounds the transfinite time needed for\nconvergence, collapsing to zero on coarsely amenable networks. The theory\nyields new invariant subalgebra rigidity results, establishes existence and\nuniqueness of envy free and maximin share allocations in continuum economies,\nand links analytic properties of regret flows with empirical stability\nphenomena in large language models. These contributions supply a rigorous\nmathematical foundation for large scale multi agent systems and demonstrate the\nutility of ordinal metrics for equilibrium selection.", "comment": "15 pages, 2 figures; companion implementation available at\n  https://github.com/farukalpay/ordinal-folding-index/", "pdf_url": "http://arxiv.org/pdf/2507.19694v1", "cate": "math.OC", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19647", "title": "GABRIL: Gaze-Based Regularization for Mitigating Causal Confusion in Imitation Learning", "authors": ["Amin Banayeeanzade", "Fatemeh Bahrani", "Yutai Zhou", "Erdem Bıyık"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      IROS 2025 camera-ready version. First two authors contributed equally", "url": "http://arxiv.org/abs/2507.19647v1", "summary": "Imitation Learning (IL) is a widely adopted approach which enables agents to\nlearn from human expert demonstrations by framing the task as a supervised\nlearning problem. However, IL often suffers from causal confusion, where agents\nmisinterpret spurious correlations as causal relationships, leading to poor\nperformance in testing environments with distribution shift. To address this\nissue, we introduce GAze-Based Regularization in Imitation Learning (GABRIL), a\nnovel method that leverages the human gaze data gathered during the data\ncollection phase to guide the representation learning in IL. GABRIL utilizes a\nregularization loss which encourages the model to focus on causally relevant\nfeatures identified through expert gaze and consequently mitigates the effects\nof confounding variables. We validate our approach in Atari environments and\nthe Bench2Drive benchmark in CARLA by collecting human gaze datasets and\napplying our method in both domains. Experimental results show that the\nimprovement of GABRIL over behavior cloning is around 179% more than the same\nnumber for other baselines in the Atari and 76% in the CARLA setup. Finally, we\nshow that our method provides extra explainability when compared to regular IL\nagents.", "comment": "IROS 2025 camera-ready version. First two authors contributed equally", "pdf_url": "http://arxiv.org/pdf/2507.19647v1", "cate": "cs.RO", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20087", "title": "Product-Congruence Games: A Unified Impartial-Game Framework for RSA ($φ$-MuM) and AES (poly-MuM)", "authors": ["Satyam Tyagi"], "categories": ["cs.DM", "cs.CR", "cs.IT", "math.IT", "91A46 (primary), 11A07, 94A60, 05A99", "G.2.1; E.3"], "primary_category": "Subjects:       Discrete Mathematics (cs.DM)", "pdf_link": null, "comments": "Comments:      12 pages, 1 table", "url": "http://arxiv.org/abs/2507.20087v1", "summary": "RSA exponent reduction and AES S-box inversion share a hidden commonality:\nboth are governed by the same impartial combinatorial principle, which we call\na Product-Congruence Game (PCG). A Product-Congruence Game tracks play via the\nmodular or finite-field product of heap values, providing a single invariant\nthat unifies the algebraic cores of these two ubiquitous symmetric and\nasymmetric cryptosystems. We instantiate this framework with two companion\ngames. First, $\\phi$-MuM, in which a left-associated \"multi-secret\" RSA\nexponent chain compresses into the game of Multiplicative Modular Nim,\nPCG($k,\\{1\\}$), where $k = ord_N(g)$. The losing predicate then factorizes via\nthe Chinese remainder theorem, mirroring RSA's structure. Second, poly-MuM, our\nmodel for finite-field inversion such as the AES S-box. For poly-MuM we prove\nthe single-hole property inside its threshold region, implying that the\nSprague-Grundy values are multiplicative under disjunctive sums in that region.\nBeyond these instances, we establish four structural theorems for a general\nProduct-Congruence Game PCG($m,R$): (i) single-heap repair above the modulus,\n(ii) ultimate period $m$ per coordinate, (iii) exact and asymptotic losing\ndensities, and (iv) confinement of optimal play to a finite indeterminacy\nregion. An operation-alignment collapse principle explains why some variants\ndegenerate to a single aggregate while MuM, $\\phi$-MuM and poly-MuM retain rich\nlocal structure. All ingredients (multiplicative orders, the Chinese remainder\ntheorem, finite fields) are classical; the contribution is the unified\naggregation-compression viewpoint that embeds both RSA and AES inside one\nimpartial-game framework, together with the structural and collapse theorems.", "comment": "12 pages, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.20087v1", "cate": "cs.DM", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19844", "title": "VAE-GAN Based Price Manipulation in Coordinated Local Energy Markets", "authors": ["Biswarup Mukherjee", "Li Zhou", "S. Gokul Krishnan", "Milad Kabirifar", "Subhash Lakshminarayana", "Charalambos Konstantinou"], "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      2025 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm)", "url": "http://arxiv.org/abs/2507.19844v1", "summary": "This paper introduces a model for coordinating prosumers with heterogeneous\ndistributed energy resources (DERs), participating in the local energy market\n(LEM) that interacts with the market-clearing entity. The proposed LEM scheme\nutilizes a data-driven, model-free reinforcement learning approach based on the\nmulti-agent deep deterministic policy gradient (MADDPG) framework, enabling\nprosumers to make real-time decisions on whether to buy, sell, or refrain from\nany action while facilitating efficient coordination for optimal energy trading\nin a dynamic market. In addition, we investigate a price manipulation strategy\nusing a variational auto encoder-generative adversarial network (VAE-GAN)\nmodel, which allows utilities to adjust price signals in a way that induces\nfinancial losses for the prosumers. Our results show that under adversarial\npricing, heterogeneous prosumer groups, particularly those lacking generation\ncapabilities, incur financial losses. The same outcome holds across LEMs of\ndifferent sizes. As the market size increases, trading stabilizes and fairness\nimproves through emergent cooperation among agents.", "comment": "2025 IEEE International Conference on Communications, Control, and\n  Computing Technologies for Smart Grids (SmartGridComm)", "pdf_url": "http://arxiv.org/pdf/2507.19844v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19652", "title": "RAKOMO: Reachability-Aware K-Order Markov Path Optimization for Quadrupedal Loco-Manipulation", "authors": ["Mattia Risiglione", "Abdelrahman Abdalla", "Victor Barasuol", "Kim Tien Ly", "Ioannis Havoutis", "Claudio Semini"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19652v1", "summary": "Legged manipulators, such as quadrupeds equipped with robotic arms, require\nmotion planning techniques that account for their complex kinematic constraints\nin order to perform manipulation tasks both safely and effectively. However,\ntrajectory optimization methods often face challenges due to the hybrid\ndynamics introduced by contact discontinuities, and tend to neglect leg\nlimitations during planning for computational reasons. In this work, we propose\nRAKOMO, a path optimization technique that integrates the strengths of K-Order\nMarkov Optimization (KOMO) with a kinematically-aware criterion based on the\nreachable region defined as reachability margin. We leverage a neural-network\nto predict the margin and optimize it by incorporating it in the standard KOMO\nformulation. This approach enables rapid convergence of gradient-based motion\nplanning -- commonly tailored for continuous systems -- while adapting it\neffectively to legged manipulators, successfully executing loco-manipulation\ntasks. We benchmark RAKOMO against a baseline KOMO approach through a set of\nsimulations for pick-and-place tasks with the HyQReal quadruped robot equipped\nwith a Kinova Gen3 robotic arm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19652v1", "cate": "cs.RO", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20417", "title": "Two Views, One Truth: Spectral and Self-Supervised Features Fusion for Robust Speech Deepfake Detection", "authors": ["Yassine El Kheir", "Arnab Das", "Enes Erdem Erdogan", "Fabian Ritter-Guttierez", "Tim Polzehl", "Sebastian Möller"], "categories": ["cs.SD", "cs.CR", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      ACCEPTED WASPAA 2025", "url": "http://arxiv.org/abs/2507.20417v1", "summary": "Recent advances in synthetic speech have made audio deepfakes increasingly\nrealistic, posing significant security risks. Existing detection methods that\nrely on a single modality, either raw waveform embeddings or spectral based\nfeatures, are vulnerable to non spoof disturbances and often overfit to known\nforgery algorithms, resulting in poor generalization to unseen attacks. To\naddress these shortcomings, we investigate hybrid fusion frameworks that\nintegrate self supervised learning (SSL) based representations with handcrafted\nspectral descriptors (MFCC , LFCC, CQCC). By aligning and combining\ncomplementary information across modalities, these fusion approaches capture\nsubtle artifacts that single feature approaches typically overlook. We explore\nseveral fusion strategies, including simple concatenation, cross attention,\nmutual cross attention, and a learnable gating mechanism, to optimally blend\nSSL features with fine grained spectral cues. We evaluate our approach on four\nchallenging public benchmarks and report generalization performance. All fusion\nvariants consistently outperform an SSL only baseline, with the cross attention\nstrategy achieving the best generalization with a 38% relative reduction in\nequal error rate (EER). These results confirm that joint modeling of waveform\nand spectral views produces robust, domain agnostic representations for audio\ndeepfake detection.", "comment": "ACCEPTED WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.20417v1", "cate": "cs.SD", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19860", "title": "Homotopy-aware Multi-agent Navigation via Distributed Model Predictive Control", "authors": ["Haoze Dong", "Meng Guo", "Chengyi He", "Zhongkui Li"], "categories": ["cs.RO", "cs.MA", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19860v1", "summary": "Multi-agent trajectory planning requires ensuring both safety and efficiency,\nyet deadlocks remain a significant challenge, especially in obstacle-dense\nenvironments. Such deadlocks frequently occur when multiple agents attempt to\ntraverse the same long and narrow corridor simultaneously. To address this, we\npropose a novel distributed trajectory planning framework that bridges the gap\nbetween global path and local trajectory cooperation. At the global level, a\nhomotopy-aware optimal path planning algorithm is proposed, which fully\nleverages the topological structure of the environment. A reference path is\nchosen from distinct homotopy classes by considering both its spatial and\ntemporal properties, leading to improved coordination among agents globally. At\nthe local level, a model predictive control-based trajectory optimization\nmethod is used to generate dynamically feasible and collision-free\ntrajectories. Additionally, an online replanning strategy ensures its\nadaptability to dynamic environments. Simulations and experiments validate the\neffectiveness of our approach in mitigating deadlocks. Ablation studies\ndemonstrate that by incorporating time-aware homotopic properties into the\nunderlying global paths, our method can significantly reduce deadlocks and\nimprove the average success rate from 4%-13% to over 90% in randomly generated\ndense scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19860v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19701", "title": "PhysVarMix: Physics-Informed Variational Mixture Model for Multi-Modal Trajectory Prediction", "authors": ["Haichuan Li", "Tomi Westerlund"], "categories": ["cs.RO", "stat.ML"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19701v1", "summary": "Accurate prediction of future agent trajectories is a critical challenge for\nensuring safe and efficient autonomous navigation, particularly in complex\nurban environments characterized by multiple plausible future scenarios. In\nthis paper, we present a novel hybrid approach that integrates learning-based\nwith physics-based constraints to address the multi-modality inherent in\ntrajectory prediction. Our method employs a variational Bayesian mixture model\nto effectively capture the diverse range of potential future behaviors, moving\nbeyond traditional unimodal assumptions. Unlike prior approaches that\npredominantly treat trajectory prediction as a data-driven regression task, our\nframework incorporates physical realism through sector-specific boundary\nconditions and Model Predictive Control (MPC)-based smoothing. These\nconstraints ensure that predicted trajectories are not only data-consistent but\nalso physically plausible, adhering to kinematic and dynamic principles.\nFurthermore, our method produces interpretable and diverse trajectory\npredictions, enabling enhanced downstream decision-making and planning in\nautonomous driving systems. We evaluate our approach on two benchmark datasets,\ndemonstrating superior performance compared to existing methods. Comprehensive\nablation studies validate the contributions of each component and highlight\ntheir synergistic impact on prediction accuracy and reliability. By balancing\ndata-driven insights with physics-informed constraints, our approach offers a\nrobust and scalable solution for navigating the uncertainties of real-world\nurban environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19701v1", "cate": "cs.RO", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20502", "title": "VDGraph: A Graph-Theoretic Approach to Unlock Insights from SBOM and SCA Data", "authors": ["Howell Xia", "Jonah Gluck", "Sevval Simsek", "David Sastre Medina", "David Starobinski"], "categories": ["cs.SE", "cs.CR"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20502v1", "summary": "The high complexity of modern software supply chains necessitates tools such\nas Software Bill of Materials (SBOMs) to manage component dependencies, and\nSoftware Composition Analysis (SCA) tools to identify vulnerabilities. While\nthere exists limited integration between SBOMs and SCA tools, a unified view of\ncomplex dependency-vulnerability relationships remains elusive. In this paper,\nwe introduce VDGraph, a novel knowledge graph-based methodology for integrating\nvulnerability and dependency data into a holistic view. VDGraph consolidates\nSBOM and SCA outputs into a graph representation of software projects'\ndependencies and vulnerabilities. We provide a formal description and analysis\nof the theoretical properties of VDGraph and present solutions to manage\npossible conflicts between the SBOM and SCA data. We further introduce and\nevaluate a practical, proof-of-concept implementation of VDGraph using two\npopular SBOM and SCA tools, namely CycloneDX Maven plugin and Google's\nOSV-Scanner. We apply VDGraph on 21 popular Java projects. Through the\nformulation of appropriate queries on the graphs, we uncover the existence of\nconcentrated risk points (i.e., vulnerable components of high severity\nreachable through numerous dependency paths). We further show that\nvulnerabilities predominantly emerge at a depth of three dependency levels or\nhigher, indicating that direct or secondary dependencies exhibit lower\nvulnerability density and tend to be more secure. Thus, VDGraph contributes a\ngraph-theoretic methodology that improves visibility into how vulnerabilities\npropagate through complex, transitive dependencies. Moreover, our\nimplementation, which combines open SBOM and SCA standards with Neo4j, lays a\nfoundation for scalable and automated analysis across real-world projects.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20502v1", "cate": "cs.SE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20094", "title": "Local Prompt Adaptation for Style-Consistent Multi-Object Generation in Diffusion Models", "authors": ["Ankit Sanjyal"], "categories": ["cs.CV", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 Pages, 8 figures, pre-print", "url": "http://arxiv.org/abs/2507.20094v1", "summary": "Diffusion models have become a powerful backbone for text-to-image\ngeneration, enabling users to synthesize high-quality visuals from natural\nlanguage prompts. However, they often struggle with complex prompts involving\nmultiple objects and global or local style specifications. In such cases, the\ngenerated scenes tend to lack style uniformity and spatial coherence, limiting\ntheir utility in creative and controllable content generation. In this paper,\nwe propose a simple, training-free architectural method called Local Prompt\nAdaptation (LPA). Our method decomposes the prompt into content and style\ntokens, and injects them selectively into the U-Net's attention layers at\ndifferent stages. By conditioning object tokens early and style tokens later in\nthe generation process, LPA enhances both layout control and stylistic\nconsistency. We evaluate our method on a custom benchmark of 50 style-rich\nprompts across five categories and compare against strong baselines including\nComposer, MultiDiffusion, Attend-and-Excite, LoRA, and SDXL. Our approach\noutperforms prior work on both CLIP score and style consistency metrics,\noffering a new direction for controllable, expressive diffusion-based\ngeneration.", "comment": "10 Pages, 8 figures, pre-print", "pdf_url": "http://arxiv.org/pdf/2507.20094v1", "cate": "cs.CV", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19742", "title": "DOA: A Degeneracy Optimization Agent with Adaptive Pose Compensation Capability based on Deep Reinforcement Learning", "authors": ["Yanbin Li", "Canran Xiao", "Hongyang He", "Shenghai Yuan", "Zong Ke", "Jiajie Yu", "Zixiong Qin", "Zhiguo Zhang", "Wenzheng Chi", "Wei Zhang"], "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      10 pages,9 figures", "url": "http://arxiv.org/abs/2507.19742v1", "summary": "Particle filter-based 2D-SLAM is widely used in indoor localization tasks due\nto its efficiency. However, indoor environments such as long straight corridors\ncan cause severe degeneracy problems in SLAM. In this paper, we use Proximal\nPolicy Optimization (PPO) to train an adaptive degeneracy optimization agent\n(DOA) to address degeneracy problem. We propose a systematic methodology to\naddress three critical challenges in traditional supervised learning\nframeworks: (1) data acquisition bottlenecks in degenerate dataset, (2)\ninherent quality deterioration of training samples, and (3) ambiguity in\nannotation protocol design. We design a specialized reward function to guide\nthe agent in developing perception capabilities for degenerate environments.\nUsing the output degeneracy factor as a reference weight, the agent can\ndynamically adjust the contribution of different sensors to pose optimization.\nSpecifically, the observation distribution is shifted towards the motion model\ndistribution, with the step size determined by a linear interpolation formula\nrelated to the degeneracy factor. In addition, we employ a transfer learning\nmodule to endow the agent with generalization capabilities across different\nenvironments and address the inefficiency of training in degenerate\nenvironments. Finally, we conduct ablation studies to demonstrate the\nrationality of our model design and the role of transfer learning. We also\ncompare the proposed DOA with SOTA methods to prove its superior degeneracy\ndetection and optimization capabilities across various environments.", "comment": "10 pages,9 figures", "pdf_url": "http://arxiv.org/pdf/2507.19742v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20704", "title": "Text2VLM: Adapting Text-Only Datasets to Evaluate Alignment Training in Visual Language Models", "authors": ["Gabriel Downer", "Sean Craven", "Damian Ruck", "Jake Thomas"], "categories": ["cs.CL", "cs.AI", "cs.CR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages, 9 figures. Jake Thomas served as Editor for this manuscript", "url": "http://arxiv.org/abs/2507.20704v1", "summary": "The increasing integration of Visual Language Models (VLMs) into AI systems\nnecessitates robust model alignment, especially when handling multimodal\ncontent that combines text and images. Existing evaluation datasets heavily\nlean towards text-only prompts, leaving visual vulnerabilities under evaluated.\nTo address this gap, we propose \\textbf{Text2VLM}, a novel multi-stage pipeline\nthat adapts text-only datasets into multimodal formats, specifically designed\nto evaluate the resilience of VLMs against typographic prompt injection\nattacks. The Text2VLM pipeline identifies harmful content in the original text\nand converts it into a typographic image, creating a multimodal prompt for\nVLMs. Also, our evaluation of open-source VLMs highlights their increased\nsusceptibility to prompt injection when visual inputs are introduced, revealing\ncritical weaknesses in the current models' alignment. This is in addition to a\nsignificant performance gap compared to closed-source frontier models. We\nvalidate Text2VLM through human evaluations, ensuring the alignment of\nextracted salient concepts; text summarization and output classification align\nwith human expectations. Text2VLM provides a scalable tool for comprehensive\nsafety assessment, contributing to the development of more robust safety\nmechanisms for VLMs. By enhancing the evaluation of multimodal vulnerabilities,\nText2VLM plays a role in advancing the safe deployment of VLMs in diverse,\nreal-world applications.", "comment": "9 pages, 9 figures. Jake Thomas served as Editor for this manuscript", "pdf_url": "http://arxiv.org/pdf/2507.20704v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20230", "title": "A Multi-Agent System Enables Versatile Information Extraction from the Chemical Literature", "authors": ["Yufan Chen", "Ching Ting Leung", "Bowen Yu", "Jianwei Sun", "Yong Huang", "Linyan Li", "Hao Chen", "Hanyu Gao"], "categories": ["cs.AI", "cs.CV", "cs.MA"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20230v2", "summary": "To fully expedite AI-powered chemical research, high-quality chemical\ndatabases are the cornerstone. Automatic extraction of chemical information\nfrom the literature is essential for constructing reaction databases, but it is\ncurrently limited by the multimodality and style variability of chemical\ninformation. In this work, we developed a multimodal large language model\n(MLLM)-based multi-agent system for robust and automated chemical information\nextraction. It utilizes the MLLM's strong reasoning capability to understand\nthe structure of diverse chemical graphics, decompose the extraction task into\nsub-tasks, and coordinate a set of specialized agents, each combining the\ncapabilities of the MLLM with the precise, domain-specific strengths of\ndedicated tools, to solve them accurately and integrate the results into a\nunified output. Our system achieved an F1 score of 80.8% on a benchmark dataset\nof sophisticated multimodal chemical reaction graphics from the literature,\nsurpassing the previous state-of-the-art model (F1 score of 35.6%) by a\nsignificant margin. Additionally, it demonstrated consistent improvements in\nkey sub-tasks, including molecular image recognition, reaction image parsing,\nnamed entity recognition and text-based reaction extraction. This work is a\ncritical step toward automated chemical information extraction into structured\ndatasets, which will be a strong promoter of AI-driven chemical research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20230v2", "cate": "cs.AI", "date": "2025-07-27", "updated": "2025-07-29"}
{"id": "2507.19760", "title": "Skin-Machine Interface with Multimodal Contact Motion Classifier", "authors": ["Alberto Confente", "Takanori Jin", "Taisuke Kobayashi", "Julio Rogelio Guadarrama-Olvera", "Gordon Cheng"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 8 figures (accepted in Humanoids2025)", "url": "http://arxiv.org/abs/2507.19760v1", "summary": "This paper proposes a novel framework for utilizing skin sensors as a new\noperation interface of complex robots. The skin sensors employed in this study\npossess the capability to quantify multimodal tactile information at multiple\ncontact points. The time-series data generated from these sensors is\nanticipated to facilitate the classification of diverse contact motions\nexhibited by an operator. By mapping the classification results with robot\nmotion primitives, a diverse range of robot motions can be generated by\naltering the manner in which the skin sensors are interacted with. In this\npaper, we focus on a learning-based contact motion classifier employing\nrecurrent neural networks. This classifier is a pivotal factor in the success\nof this framework. Furthermore, we elucidate the requisite conditions for\nsoftware-hardware designs. Firstly, multimodal sensing and its comprehensive\nencoding significantly contribute to the enhancement of classification accuracy\nand learning stability. Utilizing all modalities simultaneously as inputs to\nthe classifier proves to be an effective approach. Secondly, it is essential to\nmount the skin sensors on a flexible and compliant support to enable the\nactivation of three-axis accelerometers. These accelerometers are capable of\nmeasuring horizontal tactile information, thereby enhancing the correlation\nwith other modalities. Furthermore, they serve to absorb the noises generated\nby the robot's movements during deployment. Through these discoveries, the\naccuracy of the developed classifier surpassed 95 %, enabling the dual-arm\nmobile manipulator to execute a diverse range of tasks via the Skin-Machine\nInterface. https://youtu.be/UjUXT4Z4BC8", "comment": "8 pages, 8 figures (accepted in Humanoids2025)", "pdf_url": "http://arxiv.org/pdf/2507.19760v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20806", "title": "Collusion Resistant DNS With Private Information Retrieval", "authors": ["Yunming Xiao", "Peizhi Liu", "Ruijie Yu", "Chenkai Weng", "Matteo Varvello", "Aleksandar Kuzmanovic"], "categories": ["cs.NI", "cs.CR"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20806v1", "summary": "There has been a growing interest in Internet user privacy, demonstrated by\nthe popularity of privacy-preserving products such as Telegram and Brave, and\nthe widespread adoption of HTTPS. The Domain Name System (DNS) is a key\ncomponent of Internet-based communication and its privacy has been neglected\nfor years. Recently, DNS over HTTPS (DoH) has improved the situation by fixing\nthe issue of in-path middleboxes. Further progress has been made with\nproxy-based solutions such as Oblivious DoH (ODoH), which separate a user's\nidentity from their DNS queries. However, these solutions rely on non-collusion\nassumptions between DNS resolvers and proxies -- an assumption difficult to\nguarantee in practice. To address this, we explore integrating single-server\nPrivate Information Retrieval (PIR) into DNS to enable encrypted query\nprocessing without relying on trust assumptions. However, applying PIR to DNS\nis challenging due to its hierarchical nature -- particularly, interactions\nwith recursive resolvers can still leak information. Navigating performance and\nprivacy trade-offs, we propose PDNS, a DNS extension leveraging single-server\nPIR to strengthen privacy guarantees. We have implemented a prototype of PDNS\nand compared its performance against state-of-the-art solutions via\ntrace-driven experiments. The results show that PDNS achieves acceptable\nperformance (2x faster than DoH over Tor with similar privacy guarantees) and\nstrong privacy guarantees today, mainly at the cost of its scalability, which\nspecialized hardware for PIR can address in the near future.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20806v1", "cate": "cs.NI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20964", "title": "Core Safety Values for Provably Corrigible Agents", "authors": ["Aran Nayebi"], "categories": ["cs.AI", "cs.CC", "cs.GT", "cs.LG", "cs.MA"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      14 pages", "url": "http://arxiv.org/abs/2507.20964v1", "summary": "We introduce the first implementable framework for corrigibility, with\nprovable guarantees in multi-step, partially observed environments. Our\nframework replaces a single opaque reward with five *structurally separate*\nutility heads -- deference, switch-access preservation, truthfulness,\nlow-impact behavior via a belief-based extension of Attainable Utility\nPreservation, and bounded task reward -- combined lexicographically by strict\nweight gaps. Theorem 1 proves exact single-round corrigibility in the partially\nobservable off-switch game; Theorem 3 extends the guarantee to multi-step,\nself-spawning agents, showing that even if each head is \\emph{learned} to\nmean-squared error $\\varepsilon$ and the planner is $\\varepsilon$-sub-optimal,\nthe probability of violating \\emph{any} safety property is bounded while still\nensuring net human benefit. In contrast to Constitutional AI or RLHF/RLAIF,\nwhich merge all norms into one learned scalar, our separation makes obedience\nand impact-limits dominate even when incentives conflict. For open-ended\nsettings where adversaries can modify the agent, we prove that deciding whether\nan arbitrary post-hack agent will ever violate corrigibility is undecidable by\nreduction to the halting problem, then carve out a finite-horizon ``decidable\nisland'' where safety can be certified in randomized polynomial time and\nverified with privacy-preserving, constant-round zero-knowledge proofs.\nConsequently, the remaining challenge is the ordinary ML task of data coverage\nand generalization: reward-hacking risk is pushed into evaluation quality\nrather than hidden incentive leak-through, giving clearer implementation\nguidance for today's LLM assistants and future autonomous systems.", "comment": "14 pages", "pdf_url": "http://arxiv.org/pdf/2507.20964v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19817", "title": "Ag2x2: Robust Agent-Agnostic Visual Representations for Zero-Shot Bimanual Manipulation", "authors": ["Ziyin Xiong", "Yinghan Chen", "Puhao Li", "Yixin Zhu", "Tengyu Liu", "Siyuan Huang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to IROS 2025, oral presentation. Project page link: this https URL", "url": "http://arxiv.org/abs/2507.19817v1", "summary": "Bimanual manipulation, fundamental to human daily activities, remains a\nchallenging task due to its inherent complexity of coordinated control. Recent\nadvances have enabled zero-shot learning of single-arm manipulation skills\nthrough agent-agnostic visual representations derived from human videos;\nhowever, these methods overlook crucial agent-specific information necessary\nfor bimanual coordination, such as end-effector positions. We propose Ag2x2, a\ncomputational framework for bimanual manipulation through coordination-aware\nvisual representations that jointly encode object states and hand motion\npatterns while maintaining agent-agnosticism. Extensive experiments demonstrate\nthat Ag2x2 achieves a 73.5% success rate across 13 diverse bimanual tasks from\nBi-DexHands and PerAct2, including challenging scenarios with deformable\nobjects like ropes. This performance outperforms baseline methods and even\nsurpasses the success rate of policies trained with expert-engineered rewards.\nFurthermore, we show that representations learned through Ag2x2 can be\neffectively leveraged for imitation learning, establishing a scalable pipeline\nfor skill acquisition without expert supervision. By maintaining robust\nperformance across diverse tasks without human demonstrations or engineered\nrewards, Ag2x2 represents a step toward scalable learning of complex bimanual\nrobotic skills.", "comment": "Accepted to IROS 2025, oral presentation. Project page link:\n  https://ziyin-xiong.github.io/ag2x2.github.io/", "pdf_url": "http://arxiv.org/pdf/2507.19817v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20977", "title": "Repairing vulnerabilities without invisible hands. A differentiated replication study on LLMs", "authors": ["Maria Camporese", "Fabio Massacci"], "categories": ["cs.SE", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20977v1", "summary": "Background: Automated Vulnerability Repair (AVR) is a fast-growing branch of\nprogram repair. Recent studies show that large language models (LLMs)\noutperform traditional techniques, extending their success beyond code\ngeneration and fault detection.\n  Hypothesis: These gains may be driven by hidden factors -- \"invisible hands\"\nsuch as training-data leakage or perfect fault localization -- that let an LLM\nreproduce human-authored fixes for the same code.\n  Objective: We replicate prior AVR studies under controlled conditions by\ndeliberately adding errors to the reported vulnerability location in the\nprompt. If LLMs merely regurgitate memorized fixes, both small and large\nlocalization errors should yield the same number of correct patches, because\nany offset should divert the model from the original fix.\n  Method: Our pipeline repairs vulnerabilities from the Vul4J and VJTrans\nbenchmarks after shifting the fault location by n lines from the ground truth.\nA first LLM generates a patch, a second LLM reviews it, and we validate the\nresult with regression and proof-of-vulnerability tests. Finally, we manually\naudit a sample of patches and estimate the error rate with the\nAgresti-Coull-Wilson method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20977v1", "cate": "cs.SE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21035", "title": "GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis", "authors": ["Haoyang Liu", "Yijiang Li", "Haohan Wang"], "categories": ["cs.AI", "cs.LG", "cs.MA", "q-bio.GN"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      51 pages, 5 figures", "url": "http://arxiv.org/abs/2507.21035v1", "summary": "Gene expression analysis holds the key to many biomedical discoveries, yet\nextracting insights from raw transcriptomic data remains formidable due to the\ncomplexity of multiple large, semi-structured files and the need for extensive\ndomain expertise. Current automation approaches are often limited by either\ninflexible workflows that break down in edge cases or by fully autonomous\nagents that lack the necessary precision for rigorous scientific inquiry.\nGenoMAS charts a different course by presenting a team of LLM-based scientists\nthat integrates the reliability of structured workflows with the adaptability\nof autonomous agents. GenoMAS orchestrates six specialized LLM agents through\ntyped message-passing protocols, each contributing complementary strengths to a\nshared analytic canvas. At the heart of GenoMAS lies a guided-planning\nframework: programming agents unfold high-level task guidelines into Action\nUnits and, at each juncture, elect to advance, revise, bypass, or backtrack,\nthereby maintaining logical coherence while bending gracefully to the\nidiosyncrasies of genomic data.\n  On the GenoTEX benchmark, GenoMAS reaches a Composite Similarity Correlation\nof 89.13% for data preprocessing and an F$_1$ of 60.48% for gene\nidentification, surpassing the best prior art by 10.61% and 16.85%\nrespectively. Beyond metrics, GenoMAS surfaces biologically plausible\ngene-phenotype associations corroborated by the literature, all while adjusting\nfor latent confounders. Code is available at https://github.com/Liu-Hy/GenoMAS.", "comment": "51 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.21035v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19829", "title": "A 4D Radar Camera Extrinsic Calibration Tool Based on 3D Uncertainty Perspective N Points", "authors": ["Chuan Cao", "Xiaoning Wang", "Wenqian Xi", "Han Zhang", "Weidong Chen", "Jingchuan Wang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19829v1", "summary": "4D imaging radar is a type of low-cost millimeter-wave radar(costing merely\n10-20$\\%$ of lidar systems) capable of providing range, azimuth, elevation, and\nDoppler velocity information. Accurate extrinsic calibration between\nmillimeter-wave radar and camera systems is critical for robust multimodal\nperception in robotics, yet remains challenging due to inherent sensor noise\ncharacteristics and complex error propagation. This paper presents a systematic\ncalibration framework to address critical challenges through a spatial 3d\nuncertainty-aware PnP algorithm (3DUPnP) that explicitly models spherical\ncoordinate noise propagation in radar measurements, then compensating for\nnon-zero error expectations during coordinate transformations. Finally,\nexperimental validation demonstrates significant performance improvements over\nstate-of-the-art CPnP baseline, including improved consistency in simulations\nand enhanced precision in physical experiments. This study provides a robust\ncalibration solution for robotic systems equipped with millimeter-wave radar\nand cameras, tailored specifically for autonomous driving and robotic\nperception applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19829v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2308.16298", "title": "Publishing Wikipedia usage data with strong privacy guarantees", "authors": ["Temilola Adeleye", "Skye Berghel", "Damien Desfontaines", "Michael Hay", "Isaac Johnson", "Cléo Lemoisson", "Ashwin Machanavajjhala", "Tom Magerlein", "Gabriele Modena", "David Pujol", "Daniel Simmons-Marengo", "Hal Triedman"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      11 pages, 10 figures, Theory and Practice of Differential Privacy (TPDP) 2023", "url": "http://arxiv.org/abs/2308.16298v3", "summary": "For almost 20 years, the Wikimedia Foundation has been publishing statistics\nabout how many people visited each Wikipedia page on each day. This data helps\nWikipedia editors determine where to focus their efforts to improve the online\nencyclopedia, and enables academic research. In June 2023, the Wikimedia\nFoundation, helped by Tumult Labs, addressed a long-standing request from\nWikipedia editors and academic researchers: it started publishing these\nstatistics with finer granularity, including the country of origin in the daily\ncounts of page views. This new data publication uses differential privacy to\nprovide robust guarantees to people browsing or editing Wikipedia. This paper\ndescribes this data publication: its goals, the process followed from its\ninception to its deployment, the algorithms used to produce the data, and the\noutcomes of the data release.", "comment": "11 pages, 10 figures, Theory and Practice of Differential Privacy\n  (TPDP) 2023", "pdf_url": "http://arxiv.org/pdf/2308.16298v3", "cate": "cs.CR", "date": "2023-08-30", "updated": "2025-07-28"}
{"id": "2401.00132", "title": "Contrastive learning-based agent modeling for deep reinforcement learning", "authors": ["Wenhao Ma", "Yu-Cheng Chang", "Jie Yang", "Yu-Kai Wang", "Chin-Teng Lin"], "categories": ["cs.MA", "cs.AI"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      10 pages, 8 figures", "url": "http://arxiv.org/abs/2401.00132v3", "summary": "Multi-agent systems often require agents to collaborate with or compete\nagainst other agents with diverse goals, behaviors, or strategies. Agent\nmodeling is essential when designing adaptive policies for intelligent machine\nagents in multiagent systems, as this is the means by which the ego agent\nunderstands other agents' behavior and extracts their meaningful policy\nrepresentations. These representations can be used to enhance the ego agent's\nadaptive policy which is trained by reinforcement learning. However, existing\nagent modeling approaches typically assume the availability of local\nobservations from other agents (modeled agents) during training or a long\nobservation trajectory for policy adaption. To remove these constrictive\nassumptions and improve agent modeling performance, we devised a Contrastive\nLearning-based Agent Modeling (CLAM) method that relies only on the local\nobservations from the ego agent during training and execution. With these\nobservations, CLAM is capable of generating consistent high-quality policy\nrepresentations in real-time right from the beginning of each episode. We\nevaluated the efficacy of our approach in both cooperative and competitive\nmulti-agent environments. Our experiments demonstrate that our approach\nachieves state-of-the-art on both cooperative and competitive tasks,\nhighlighting the potential of contrastive learning-based agent modeling for\nenhancing reinforcement learning.", "comment": "10 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2401.00132v3", "cate": "cs.MA", "date": "2023-12-30", "updated": "2025-07-28"}
{"id": "2507.19831", "title": "Feeling the Force: A Nuanced Physics-based Traversability Sensor for Navigation in Unstructured Vegetation", "authors": ["Zaar Khizar", "Johann Laconte", "Roland Lenain", "Romuald Aufrere"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19831v1", "summary": "In many applications, robots are increasingly deployed in unstructured and\nnatural environments where they encounter various types of vegetation.\nVegetation presents unique challenges as a traversable obstacle, where the\nmechanical properties of the plants can influence whether a robot can safely\ncollide with and overcome the obstacle. A more nuanced approach is required to\nassess the safety and traversability of these obstacles, as collisions can\nsometimes be safe and necessary for navigating through dense or unavoidable\nvegetation. This paper introduces a novel sensor designed to directly measure\nthe applied forces exerted by vegetation on a robot: by directly capturing the\npush-back forces, our sensor provides a detailed understanding of the\ninteractions between the robot and its surroundings. We demonstrate the\nsensor's effectiveness through experimental validations, showcasing its ability\nto measure subtle force variations. This force-based approach provides a\nquantifiable metric that can inform navigation decisions and serve as a\nfoundation for developing future learning algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19831v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19489", "title": "MAIA: A Collaborative Medical AI Platform for Integrated Healthcare Innovation", "authors": ["Simone Bendazzoli", "Sanna Persson", "Mehdi Astaraki", "Sebastian Pettersson", "Vitali Grozman", "Rodrigo Moreno"], "categories": ["cs.AI", "cs.CV", "cs.HC", "cs.SE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      26 pages, 12 figures", "url": "http://arxiv.org/abs/2507.19489v1", "summary": "The integration of Artificial Intelligence (AI) into clinical workflows\nrequires robust collaborative platforms that are able to bridge the gap between\ntechnical innovation and practical healthcare applications. This paper\nintroduces MAIA (Medical Artificial Intelligence Assistant), an open-source\nplatform designed to facilitate interdisciplinary collaboration among\nclinicians, researchers, and AI developers. Built on Kubernetes, MAIA offers a\nmodular, scalable environment with integrated tools for data management, model\ndevelopment, annotation, deployment, and clinical feedback. Key features\ninclude project isolation, CI/CD automation, integration with high-computing\ninfrastructures and in clinical workflows. MAIA supports real-world use cases\nin medical imaging AI, with deployments in both academic and clinical\nenvironments. By promoting collaborations and interoperability, MAIA aims to\naccelerate the translation of AI research into impactful clinical solutions\nwhile promoting reproducibility, transparency, and user-centered design. We\nshowcase the use of MAIA with different projects, both at KTH Royal Institute\nof Technology and Karolinska University Hospital.", "comment": "26 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.19489v1", "cate": "cs.AI", "date": "2025-05-28", "updated": "2025-05-28"}
{"id": "2507.19483", "title": "The Architecture of Cognitive Amplification: Enhanced Cognitive Scaffolding as a Resolution to the Comfort-Growth Paradox in Human-AI Cognitive Integration", "authors": ["Giuseppe Riva"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      39 Pages, no figures", "url": "http://arxiv.org/abs/2507.19483v1", "summary": "AI systems now function as cognitive extensions, evolving from tools to\nactive cognitive collaborators within human-AI integrated systems. While these\nsystems can amplify cognition - enhancing problem-solving, learning, and\ncreativity - they present a fundamental \"comfort-growth paradox\": AI's\nuser-friendly nature may foster intellectual stagnation by minimizing cognitive\nfriction necessary for development. As AI aligns with user preferences and\nprovides frictionless assistance, it risks inducing cognitive complacency\nrather than promoting growth. We introduce Enhanced Cognitive Scaffolding to\nresolve this paradox - reconceptualizing AI from convenient assistant to\ndynamic mentor. Drawing from Vygotskian theories, educational scaffolding\nprinciples, and AI ethics, our framework integrates three dimensions: (1)\nProgressive Autonomy, where AI support gradually fades as user competence\nincreases; (2) Adaptive Personalization, tailoring assistance to individual\nneeds and learning trajectories; and (3) Cognitive Load Optimization, balancing\nmental effort to maximize learning while minimizing unnecessary complexity.\nResearch across educational, workplace, creative, and healthcare domains\nsupports this approach, demonstrating accelerated skill acquisition, improved\nself-regulation, and enhanced higher-order thinking. The framework includes\nsafeguards against risks like dependency, skill atrophy, and bias\namplification. By prioritizing cognitive development over convenience in\nhuman-AI interaction, Enhanced Cognitive Scaffolding offers a pathway toward\ngenuinely amplified cognition while safeguarding autonomous thought and\ncontinuous learning.", "comment": "39 Pages, no figures", "pdf_url": "http://arxiv.org/pdf/2507.19483v1", "cate": "cs.HC", "date": "2025-05-14", "updated": "2025-05-14"}
{"id": "2409.10336", "title": "Execution-time opacity control for timed automata", "authors": ["Étienne André", "Marie Duflot", "Laetitia Laversa", "Engel Lefaucheux"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      This is the extended version of the manuscript of the same name published in the proceedings of the 22nd International Conference on Software Engineering and Formal Methods (SEFM 2024)", "url": "http://arxiv.org/abs/2409.10336v3", "summary": "Timing leaks in timed automata (TA) can occur whenever an attacker is able to\ndeduce a secret by observing some timed behaviour. In execution-time opacity,\nthe attacker aims at deducing whether a private location was visited, by\nobserving only the execution time. In earlier work, it was shown that it can be\ndecided whether a TA is opaque in this setting. In this work, we address\ncontrol, and investigate whether a TA can be controlled by a strategy at\nruntime to ensure opacity, by enabling or disabling some controllable actions\nover time. We first show that, in general, it is undecidable to determine\nwhether such a strategy exists. Second, we show that deciding whether a\nmeta-strategy ensuring opacity exists can be done in EXPSPACE. Such a\nmeta-strategy is a set of strategies allowing an arbitrarily large -- yet\nfinite -- number of strategy changes per time unit, and with only weak ordering\nrelations between such changes. Our method is constructive, in the sense that\nwe can exhibit such a meta-strategy. We also extend our method to the case of\nweak opacity, when it is harmless that the attacker deduces that the private\nlocation was not visited. Finally, we consider a variant where the attacker\ncannot have an infinite precision in its observations.", "comment": "This is the extended version of the manuscript of the same name\n  published in the proceedings of the 22nd International Conference on Software\n  Engineering and Formal Methods (SEFM 2024)", "pdf_url": "http://arxiv.org/pdf/2409.10336v3", "cate": "cs.CR", "date": "2024-09-16", "updated": "2025-07-28"}
{"id": "2504.06091", "title": "Real-Time LaCAM for Real-Time MAPF", "authors": ["Runzhe Liang", "Rishi Veerapaneni", "Daniel Harabor", "Jiaoyang Li", "Maxim Likhachev"], "categories": ["cs.MA", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      Published at the International Symposium on Combinatorial Search 2025 (SoCS 2025)", "url": "http://arxiv.org/abs/2504.06091v2", "summary": "The vast majority of Multi-Agent Path Finding (MAPF) methods with\ncompleteness guarantees require planning full-horizon paths. However, planning\nfull-horizon paths can take too long and be impractical in real-world\napplications. Instead, real-time planning and execution, which only allows the\nplanner a finite amount of time before executing and replanning, is more\npractical for real-world multi-agent systems. Several methods utilize real-time\nplanning schemes but none are provably complete, which leads to livelock or\ndeadlock. Our main contribution is Real-Time LaCAM, the first Real-Time MAPF\nmethod with provable completeness guarantees. We do this by leveraging LaCAM\n(Okumura 2023) in an incremental fashion. Our results show how we can\niteratively plan for congested environments with a cutoff time of milliseconds\nwhile still maintaining the same success rate as full-horizon LaCAM. We also\nshow how it can be used with a single-step learned MAPF policy.", "comment": "Published at the International Symposium on Combinatorial Search 2025\n  (SoCS 2025)", "pdf_url": "http://arxiv.org/pdf/2504.06091v2", "cate": "cs.MA", "date": "2025-04-08", "updated": "2025-07-27"}
{"id": "2507.19851", "title": "PlaneHEC: Efficient Hand-Eye Calibration for Multi-view Robotic Arm via Any Point Cloud Plane Detection", "authors": ["Ye Wang", "Haodong Jing", "Yang Liao", "Yongqiang Ma", "Nanning Zheng"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted by 2025 IEEE International Conference on Robotics & Automation (ICRA)", "url": "http://arxiv.org/abs/2507.19851v1", "summary": "Hand-eye calibration is an important task in vision-guided robotic systems\nand is crucial for determining the transformation matrix between the camera\ncoordinate system and the robot end-effector. Existing methods, for multi-view\nrobotic systems, usually rely on accurate geometric models or manual\nassistance, generalize poorly, and can be very complicated and inefficient.\nTherefore, in this study, we propose PlaneHEC, a generalized hand-eye\ncalibration method that does not require complex models and can be accomplished\nusing only depth cameras, which achieves the optimal and fastest calibration\nresults using arbitrary planar surfaces like walls and tables. PlaneHEC\nintroduces hand-eye calibration equations based on planar constraints, which\nmakes it strongly interpretable and generalizable. PlaneHEC also uses a\ncomprehensive solution that starts with a closed-form solution and improves it\nwithiterative optimization, which greatly improves accuracy. We comprehensively\nevaluated the performance of PlaneHEC in both simulated and real-world\nenvironments and compared the results with other point-cloud-based calibration\nmethods, proving its superiority. Our approach achieves universal and fast\ncalibration with an innovative design of computational models, providing a\nstrong contribution to the development of multi-agent systems and embodied\nintelligence.", "comment": "Accepted by 2025 IEEE International Conference on Robotics &\n  Automation (ICRA)", "pdf_url": "http://arxiv.org/pdf/2507.19851v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19608", "title": "DeltaLLM: A Training-Free Framework Exploiting Temporal Sparsity for Efficient Edge LLM Inference", "authors": ["Jiawen Qi", "Chang Gao", "Zhaochun Ren", "Qinyu Chen"], "categories": ["cs.AI", "eess.SP"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19608v1", "summary": "Deploying Large Language Models (LLMs) on edge devices remains challenging\ndue to their quadratically increasing computations with the sequence length.\nExisting studies for dynamic attention pruning are designed for hardware with\nmassively parallel computation capabilities, such as GPUs or TPUs, and aim at\nlong context lengths (e.g., 64K), making them unsuitable for edge scenarios. We\npresent DeltaLLM, a training-free framework that exploits temporal sparsity in\nattention patterns to enable efficient LLM inference across both the prefilling\nand decoding stages, on resource-constrained edge devices. DeltaLLM introduces\nan accuracy- and memory-aware delta matrix construction strategy that\nintroduces temporal sparsity, and a context-aware hybrid attention mechanism\nthat combines full attention in a local context window with delta approximation\noutside it to increase accuracy. We evaluate our framework on the\nedge-device-friendly BitNet-b1.58-2B-4T model and Llama3.2-1B-Instruct model\nacross diverse language tasks. The results show that on BitNet, our framework\nincreases the attention sparsity from 0% to 60% during the prefilling stage\nwith slight accuracy improvement on the WG task, and 0% to 57% across both the\nprefilling and decoding stages, with even higher F1 score from 29.63 to 30.97\non SQuAD-v2 task. On the Llama model, it can also achieve up to 60% sparsity\nduring the prefilling stage and around 57% across both stages with negligible\naccuracy drop. These results demonstrate that DeltaLLM offers a promising\nsolution for efficient edge deployment, requiring no fine-tuning and seamlessly\nintegrating with existing inference pipelines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19608v1", "cate": "cs.AI", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19485", "title": "Creativity as a Human Right: Design Considerations for Computational Creativity Systems", "authors": ["Alayt Issak"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19485v1", "summary": "We investigate creativity that is underlined in the Universal Declaration of\nHuman Rights (UDHR) to present design considerations for Computational\nCreativity (CC) systems. We find this declaration to describe creativity in\nsalient aspects and bring to light creativity as a Human Right attributed to\nthe Fourth Generation of such rights. This generation of rights attributes CC\nsystems and the evolving nature of interaction with entities of shared\nintelligence. Our methodology examines five of thirty articles from the UDHR\nand demonstrates each article with actualizations concluding with design\nconsiderations for each. We contribute our findings to ground the relationship\nbetween creativity and CC systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19485v1", "cate": "cs.HC", "date": "2025-05-16", "updated": "2025-05-16"}
{"id": "2502.08610", "title": "Quantifying Security Vulnerabilities: A Metric-Driven Security Analysis of Gaps in Current AI Standards", "authors": ["Keerthana Madhavan", "Abbas Yazdinejad", "Fattane Zarrinkalam", "Ali Dehghantanha"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.08610v2", "summary": "As AI systems integrate into critical infrastructure, security gaps in AI\ncompliance frameworks demand urgent attention. This paper audits and quantifies\nsecurity risks in three major AI governance standards: NIST AI RMF 1.0, UK's AI\nand Data Protection Risk Toolkit, and the EU's ALTAI. Using a novel risk\nassessment methodology, we develop four key metrics: Risk Severity Index (RSI),\nAttack Potential Index (AVPI), Compliance-Security Gap Percentage (CSGP), and\nRoot Cause Vulnerability Score (RCVS). Our analysis identifies 136 concerns\nacross the frameworks, exposing significant gaps. NIST fails to address 69.23\npercent of identified risks, ALTAI has the highest attack vector vulnerability\n(AVPI = 0.51) and the ICO Toolkit has the largest compliance-security gap, with\n80.00 percent of high-risk concerns remaining unresolved. Root cause analysis\nhighlights under-defined processes (ALTAI RCVS = 033) and weak implementation\nguidance (NIST and ICO RCVS = 0.25) as critical weaknesses. These findings\nemphasize the need for stronger, enforceable security controls in AI\ncompliance. We offer targeted recommendations to enhance security posture and\nbridge the gap between compliance and real-world AI risks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.08610v2", "cate": "cs.CR", "date": "2025-02-12", "updated": "2025-07-26"}
{"id": "2504.14787", "title": "ADL: A Declarative Language for Agent-Based Chatbots", "authors": ["Sirui Zeng", "Xifeng Yan"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.14787v2", "summary": "There are numerous frameworks capable of creating and orchestrating agents to\naddress complex tasks. However, most of them highly coupled Python programming\nwith agent declaration, making it hard for maintenance and runtime\noptimization. In this work, we introduce ADL, an agent declarative language for\ncustomer service chatbots. ADL abstracts away implementation details, offering\na declarative way to define agents and their interactions, which could ease\nmaintenance and debugging. It also incorporates natural language programming at\nits core to simplify the specification and communication of chatbot designs.\nADL includes four basic types of agents and supports integration with custom\nfunctions, tool use, and third-party agents. MICA, a multi-agent system\ndesigned to interpret and execute ADL programs, has been developed and is now\navailable as an open-source project at https://github.com/Mica-labs/MICA. Its\ndocumentation can be found at https://mica-labs.github.io/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.14787v2", "cate": "cs.MA", "date": "2025-04-21", "updated": "2025-07-27"}
{"id": "2507.19854", "title": "Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models", "authors": ["Anjali R. Menon", "Rohit K. Sharma", "Priya Singh", "Chengyu Wang", "Aurora M. Ferreira", "Mateja Novak"], "categories": ["cs.RO", "cs.HC", "68T05, 68T07, 68T40", "I.2.6; I.2.9; I.2.7; I.2.10; H.5.2"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      13 pages, 7 figures", "url": "http://arxiv.org/abs/2507.19854v1", "summary": "The integration of Large Language Models (LLMs) into robotics has unlocked\nunprecedented capabilities in high-level task planning. However, most current\nsystems operate in an open-loop fashion, where LLMs act as one-shot planners,\nrendering them brittle and unable to adapt to unforeseen circumstances in\ndynamic physical environments. To overcome this limitation, this paper\nintroduces the \"Think, Act, Learn\" (T-A-L) framework, a novel architecture that\nenables an embodied agent to autonomously learn and refine its policies through\ncontinuous interaction. Our framework establishes a closed-loop cycle where an\nLLM first \"thinks\" by decomposing high-level commands into actionable plans.\nThe robot then \"acts\" by executing these plans while gathering rich, multimodal\nsensory feedback. Critically, the \"learn\" module processes this feedback to\nfacilitate LLM-driven self-reflection, allowing the agent to perform causal\nanalysis on its failures and generate corrective strategies. These insights are\nstored in an experiential memory to guide future planning cycles. We\ndemonstrate through extensive experiments in both simulation and the real world\nthat our T-A-L agent significantly outperforms baseline methods, including\nopen-loop LLMs, Behavioral Cloning, and traditional Reinforcement Learning. Our\nframework achieves over a 97% success rate on complex, long-horizon tasks,\nconverges to a stable policy in an average of just 9 trials, and exhibits\nremarkable generalization to unseen tasks. This work presents a significant\nstep towards developing more robust, adaptive, and truly autonomous robotic\nagents.", "comment": "13 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.19854v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19672", "title": "Alignment and Safety in Large Language Models: Safety Mechanisms, Training Paradigms, and Emerging Challenges", "authors": ["Haoran Lu", "Luyang Fang", "Ruidong Zhang", "Xinliang Li", "Jiazhang Cai", "Huimin Cheng", "Lin Tang", "Ziyu Liu", "Zeliang Sun", "Tao Wang", "Yingchuan Zhang", "Arif Hassan Zidan", "Jinwen Xu", "Jincheng Yu", "Meizhi Yu", "Hanqi Jiang", "Xilin Gong", "Weidi Luo", "Bolun Sun", "Yongkai Chen", "Terry Ma", "Shushan Wu", "Yifan Zhou", "Junhao Chen", "Haotian Xiang", "Jing Zhang", "Afrar Jahin", "Wei Ruan", "Ke Deng", "Yi Pan", "Peilong Wang", "Jiahui Li", "Zhengliang Liu", "Lu Zhang", "Lin Zhao", "Wei Liu", "Dajiang Zhu", "Xin Xing", "Fei Dou", "Wei Zhang", "Chao Huang", "Rongjie Liu", "Mengrui Zhang", "Yiwen Liu", "Xiaoxiao Sun", "Qin Lu", "Zhen Xiang", "Wenxuan Zhong", "Tianming Liu", "Ping Ma"], "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      119 pages, 10 figures, 7 tables", "url": "http://arxiv.org/abs/2507.19672v1", "summary": "Due to the remarkable capabilities and growing impact of large language\nmodels (LLMs), they have been deeply integrated into many aspects of society.\nThus, ensuring their alignment with human values and intentions has emerged as\na critical challenge. This survey provides a comprehensive overview of\npractical alignment techniques, training protocols, and empirical findings in\nLLM alignment. We analyze the development of alignment methods across diverse\nparadigms, characterizing the fundamental trade-offs between core alignment\nobjectives. Our analysis shows that while supervised fine-tuning enables basic\ninstruction-following, preference-based methods offer more flexibility for\naligning with nuanced human intent. We discuss state-of-the-art techniques,\nincluding Direct Preference Optimization (DPO), Constitutional AI,\nbrain-inspired methods, and alignment uncertainty quantification (AUQ),\nhighlighting their approaches to balancing quality and efficiency. We review\nexisting evaluation frameworks and benchmarking datasets, emphasizing\nlimitations such as reward misspecification, distributional robustness, and\nscalable oversight. We summarize strategies adopted by leading AI labs to\nillustrate the current state of practice. We conclude by outlining open\nproblems in oversight, value pluralism, robustness, and continuous alignment.\nThis survey aims to inform both researchers and practitioners navigating the\nevolving landscape of LLM alignment.", "comment": "119 pages, 10 figures, 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.19672v1", "cate": "cs.AI", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19486", "title": "Confirmation bias: A challenge for scalable oversight", "authors": ["Gabriel Recchia", "Chatrik Singh Mangat", "Jinu Nyachhyon", "Mridul Sharma", "Callum Canavan", "Dylan Epstein-Gross", "Muhammed Abdulbari"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      61 pages, 8 figures", "url": "http://arxiv.org/abs/2507.19486v1", "summary": "Scalable oversight protocols aim to empower evaluators to accurately verify\nAI models more capable than themselves. However, human evaluators are subject\nto biases that can lead to systematic errors. We conduct two studies examining\nthe performance of simple oversight protocols where evaluators know that the\nmodel is \"correct most of the time, but not all of the time\". We find no\noverall advantage for the tested protocols, although in Study 1, showing\narguments in favor of both answers improves accuracy in cases where the model\nis incorrect. In Study 2, participants in both groups become more confident in\nthe system's answers after conducting online research, even when those answers\nare incorrect. We also reanalyze data from prior work that was more optimistic\nabout simple protocols, finding that human evaluators possessing knowledge\nabsent from models likely contributed to their positive results--an advantage\nthat diminishes as models continue to scale in capability. These findings\nunderscore the importance of testing the degree to which oversight protocols\nare robust to evaluator biases, whether they outperform simple deference to the\nmodel under evaluation, and whether their performance scales with increasing\nproblem difficulty and model capability.", "comment": "61 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.19486v1", "cate": "cs.HC", "date": "2025-05-17", "updated": "2025-05-17"}
{"id": "2507.19662", "title": "K-PACT: Kernel Planning for Adaptive Context Switching -- A Framework for Clustering, Placement, and Prefetching in Spectrum Sensing", "authors": ["H. Umut Suluhan", "Jiahao Lin", "Serhan Gener", "Chaitali Chakrabarti", "Umit Ogras", "Ali Akoglu"], "categories": ["cs.ET"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19662v1", "summary": "Efficient wideband spectrum sensing requires rapid evaluation and\nre-evaluation of signal presence and type across multiple subchannels. These\ntasks involve multiple hypothesis testing, where each hypothesis is implemented\nas a decision tree workflow containing compute-intensive kernels, including\nFFT, matrix operations, and signal-specific analyses. Given dynamic nature of\nthe spectrum environment, ability to quickly switch between hypotheses is\nessential for maintaining low-latency, high-throughput operation. This work\nassumes a coarse-grained reconfigurable architecture consisting of an array of\nprocessing elements (PEs), each equipped with a local instruction memory (IMEM)\ncapable of storing and executing kernels used in spectrum sensing applications.\nWe propose a planner tool that efficiently maps hypothesis workflows onto this\narchitecture to enable fast runtime context switching with minimal overhead.\nThe planner performs two key tasks: clustering temporally non-overlapping\nkernels to share IMEM resources within a PE sub-array, and placing these\nclusters onto hardware to ensure efficient scheduling and data movement. By\npreloading kernels that are not simultaneously active into same IMEM, our tool\nenables low-latency reconfiguration without runtime conflicts. It models the\nplanning process as a multi-objective optimization, balancing trade-offs among\ncontext switch overhead, scheduling latency, and dataflow efficiency. We\nevaluate the proposed tool in simulated spectrum sensing scenario with 48\nconcurrent subchannels. Results show that our approach reduces off-chip binary\nfetches by 207.81x, lowers average switching time by 98.24x, and improves\nper-subband execution time by 132.92x over baseline without preloading. These\nimprovements demonstrate that intelligent planning is critical for adapting to\nfast-changing spectrum environments in next-generation radio frequency systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19662v1", "cate": "cs.ET", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2502.09139", "title": "Zebrafix: Mitigating Memory-Centric Side-Channel Leakage via Interleaving", "authors": ["Anna Pätschke", "Jan Wichelmann", "Thomas Eisenbarth"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.09139v3", "summary": "Constant-time code has become the de-facto standard for secure cryptographic\nimplementations. However, some memory-based leakage classes such as ciphertext\nside-channels and silent stores remain unaddressed. Prior work proposed three\ndifferent methods for ciphertext side-channel mitigation, for which one, the\npracticality of interleaving data with counter values, remains to be explored.\nTo close this gap, we define design choices and requirements to leverage\ninterleaving for a generic ciphertext side-channel mitigation. Based on these\nresults, we implement Zebrafix, a compiler-based tool to ensure freshness of\nmemory stores. We evaluate Zebrafix and find that interleaving can perform much\nbetter than other ciphertext side-channel mitigations, at the cost of a high\npractical complexity. We further observe that ciphertext side-channels and\nsilent stores belong to a broader attack category: memory-centric\nside-channels. Under this unified view, we show that interleaving-based\nciphertext side-channel mitigations can be used to prevent silent stores as\nwell.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.09139v3", "cate": "cs.CR", "date": "2025-02-13", "updated": "2025-07-28"}
{"id": "2507.18224", "title": "Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation", "authors": ["Shiyuan Li", "Yixin Liu", "Qingsong Wen", "Chengqi Zhang", "Shirui Pan"], "categories": ["cs.MA", "cs.CL"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.18224v2", "summary": "Multi-agent systems (MAS) based on large language models (LLMs) have emerged\nas a powerful solution for dealing with complex problems across diverse\ndomains. The effectiveness of MAS is critically dependent on its collaboration\ntopology, which has become a focal point for automated design research.\nHowever, existing approaches are fundamentally constrained by their reliance on\na template graph modification paradigm with a predefined set of agents and\nhard-coded interaction structures, significantly limiting their adaptability to\ntask-specific requirements. To address these limitations, we reframe MAS design\nas a conditional autoregressive graph generation task, where both the system\ncomposition and structure are designed jointly. We propose ARG-Designer, a\nnovel autoregressive model that operationalizes this paradigm by constructing\nthe collaboration graph from scratch. Conditioned on a natural language task\nquery, ARG-Designer sequentially and dynamically determines the required number\nof agents, selects their appropriate roles from an extensible pool, and\nestablishes the optimal communication links between them. This generative\napproach creates a customized topology in a flexible and extensible manner,\nprecisely tailored to the unique demands of different tasks. Extensive\nexperiments across six diverse benchmarks demonstrate that ARG-Designer not\nonly achieves state-of-the-art performance but also enjoys significantly\ngreater token efficiency and enhanced extensibility. The source code of\nARG-Designer is available at https://github.com/Shiy-Li/ARG-Designer.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.18224v2", "cate": "cs.MA", "date": "2025-07-24", "updated": "2025-07-26"}
{"id": "2507.19883", "title": "Bridging Simulation and Usability: A User-Friendly Framework for Scenario Generation in CARLA", "authors": ["Ahmed Abouelazm", "Mohammad Mahmoud", "Conrad Walter", "Oleksandr Shchetsura", "Erne Hussong", "Helen Gremmelmaier", "J. Marius Zöllner"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Paper is accepted in IEEE International Automated Vehicle Validation Conference (IAVVC 2025)", "url": "http://arxiv.org/abs/2507.19883v1", "summary": "Autonomous driving promises safer roads, reduced congestion, and improved\nmobility, yet validating these systems across diverse conditions remains a\nmajor challenge. Real-world testing is expensive, time-consuming, and sometimes\nunsafe, making large-scale validation impractical. In contrast, simulation\nenvironments offer a scalable and cost-effective alternative for rigorous\nverification and validation. A critical component of the validation process is\nscenario generation, which involves designing and configuring traffic scenarios\nto evaluate autonomous systems' responses to various events and uncertainties.\nHowever, existing scenario generation tools often require programming\nknowledge, limiting accessibility for non-technical users. To address this\nlimitation, we present an interactive, no-code framework for scenario\ngeneration. Our framework features a graphical interface that enables users to\ncreate, modify, save, load, and execute scenarios without needing coding\nexpertise or detailed simulation knowledge. Unlike script-based tools such as\nScenic or ScenarioRunner, our approach lowers the barrier to entry and supports\na broader user base. Central to our framework is a graph-based scenario\nrepresentation that facilitates structured management, supports both manual and\nautomated generation, and enables integration with deep learning-based scenario\nand behavior generation methods. In automated mode, the framework can randomly\nsample parameters such as actor types, behaviors, and environmental conditions,\nallowing the generation of diverse and realistic test datasets. By simplifying\nthe scenario generation process, this framework supports more efficient testing\nworkflows and increases the accessibility of simulation-based validation for\nresearchers, engineers, and policymakers.", "comment": "Paper is accepted in IEEE International Automated Vehicle Validation\n  Conference (IAVVC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.19883v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19703", "title": "The wall confronting large language models", "authors": ["Peter V. Coveney", "Sauro Succi"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19703v1", "summary": "We show that the scaling laws which determine the performance of large\nlanguage models (LLMs) severely limit their ability to improve the uncertainty\nof their predictions. As a result, raising their reliability to meet the\nstandards of scientific inquiry is intractable by any reasonable measure. We\nargue that the very mechanism which fuels much of the learning power of LLMs,\nnamely the ability to generate non-Gaussian output distributions from Gaussian\ninput ones, might well be at the roots of their propensity to produce error\npileup, ensuing information catastrophes and degenerative AI behaviour. This\ntension between learning and accuracy is a likely candidate mechanism\nunderlying the observed low values of the scaling components. It is\nsubstantially compounded by the deluge of spurious correlations pointed out by\nCalude and Longo which rapidly increase in any data set merely as a function of\nits size, regardless of its nature. The fact that a degenerative AI pathway is\na very probable feature of the LLM landscape does not mean that it must\ninevitably arise in all future AI research. Its avoidance, which we also\ndiscuss in this paper, necessitates putting a much higher premium on insight\nand understanding of the structural characteristics of the problems being\ninvestigated.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19703v1", "cate": "cs.AI", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19488", "title": "E-polis: Gamifying Sociological Surveys through Serious Games -- A Data Analysis Approach Applied to Multiple-Choice Question Responses Datasets", "authors": ["Alexandros Gazis", "Eleftheria Katsiri"], "categories": ["cs.HC", "cs.CY", "K.6.3; C.5.2; C.5.3; C.5.5; C.5.m; C.5.0"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      The article is under review by MDPI, Electronics journal. 36 pages, 20 figures, 67 references", "url": "http://arxiv.org/abs/2507.19488v1", "summary": "E-polis is a serious digital game designed to gamify sociological surveys\nstudying young people's political opinions. In this platform game, players\nnavigate a digital world, encountering quests posing sociological questions.\nPlayers' answers shape the city-game world, altering building structures based\non their choices. E-polis is a serious game, not a government simulation,\naiming to understand players' behaviors and opinions thus we do not train the\nplayers but rather understand them and help them visualize their choices in\nshaping a city's future. Also, it is noticed that no correct or incorrect\nanswers apply. Moreover, our game utilizes a novel middleware architecture for\ndevelopment, diverging from typical asset prefab scene and script segregation.\nThis article presents the data layer of our game's middleware, specifically\nfocusing on data analysis based on respondents' gameplay answers. E-polis\nrepresents an innovative approach to gamifying sociological research, providing\na unique platform for gathering and analyzing data on political opinions among\nyouth and contributing to the broader field of serious games.", "comment": "The article is under review by MDPI, Electronics journal. 36 pages,\n  20 figures, 67 references", "pdf_url": "http://arxiv.org/pdf/2507.19488v1", "cate": "cs.HC", "date": "2025-05-26", "updated": "2025-05-26"}
{"id": "2507.19739", "title": "Enhancing IoT Intrusion Detection Systems through Adversarial Training", "authors": ["Karma Gurung", "Ashutosh Ghimire", "Fathi Amsaad"], "categories": ["cs.ET"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.19739v1", "summary": "The augmentation of Internet of Things (IoT) devices transformed both\nautomation and connectivity but revealed major security vulnerabilities in\nnetworks. We address these challenges by designing a robust intrusion detection\nsystem (IDS) to detect complex attacks by learning patterns from the NF-ToN-IoT\nv2 dataset. Intrusion detection has a realistic testbed through the dataset's\nrich and high-dimensional features. We combine distributed preprocessing to\nmanage the dataset size with Fast Gradient Sign Method (FGSM) adversarial\nattacks to mimic actual attack scenarios and XGBoost model adversarial training\nfor improved system robustness. Our system achieves 95.3% accuracy on clean\ndata and 94.5% accuracy on adversarial data to show its effectiveness against\ncomplex threats. Adversarial training demonstrates its potential to strengthen\nIDS against evolving cyber threats and sets the foundation for future studies.\nReal-time IoT environments represent a future deployment opportunity for these\nsystems, while extensions to detect emerging threats and zero-day\nvulnerabilities would enhance their utility.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.19739v1", "cate": "cs.ET", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19510", "title": "Beyond 9-to-5: A Generative Model for Augmenting Mobility Data of Underrepresented Shift Workers", "authors": ["Haoxuan Ma", "Xishun Liao", "Yifan Liu", "Chris Stanford", "Jiaqi Ma"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19510v1", "summary": "This paper addresses a critical gap in urban mobility modeling by focusing on\nshift workers, a population segment comprising 15-20% of the workforce in\nindustrialized societies yet systematically underrepresented in traditional\ntransportation surveys and planning. This underrepresentation is revealed in\nthis study by a comparative analysis of GPS and survey data, highlighting stark\ndifferences between the bimodal temporal patterns of shift workers and the\nconventional 9-to-5 schedules recorded in surveys. To address this bias, we\nintroduce a novel transformer-based approach that leverages fragmented GPS\ntrajectory data to generate complete, behaviorally valid activity patterns for\nindividuals working non-standard hours. Our method employs periodaware temporal\nembeddings and a transition-focused loss function specifically designed to\ncapture the unique activity rhythms of shift workers and mitigate the inherent\nbiases in conventional transportation datasets. Evaluation shows that the\ngenerated data achieves remarkable distributional alignment with GPS data from\nLos Angeles County (Average JSD < 0.02 for all evaluation metrics). By\ntransforming incomplete GPS traces into complete, representative activity\npatterns, our approach provides transportation planners with a powerful data\naugmentation tool to fill critical gaps in understanding the 24/7 mobility\nneeds of urban populations, enabling precise and inclusive transportation\nplanning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19510v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2502.18509", "title": "Protecting Users From Themselves: Safeguarding Contextual Privacy in Interactions with Conversational Agents", "authors": ["Ivoline Ngong", "Swanand Kadhe", "Hao Wang", "Keerthiram Murugesan", "Justin D. Weisz", "Amit Dhurandhar", "Karthikeyan Natesan Ramamurthy"], "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      22 pages, 2 figures", "url": "http://arxiv.org/abs/2502.18509v2", "summary": "Conversational agents are increasingly woven into individuals' personal\nlives, yet users often underestimate the privacy risks associated with them.\nThe moment users share information with these agents-such as large language\nmodels (LLMs)-their private information becomes vulnerable to exposure. In this\npaper, we characterize the notion of contextual privacy for user interactions\nwith LLM-based Conversational Agents (LCAs). It aims to minimize privacy risks\nby ensuring that users (sender) disclose only information that is both relevant\nand necessary for achieving their intended goals when interacting with LCAs\n(untrusted receivers). Through a formative design user study, we observe how\neven \"privacy-conscious\" users inadvertently reveal sensitive information\nthrough indirect disclosures. Based on insights from this study, we propose a\nlocally deployable framework that operates between users and LCAs, identifying\nand reformulating out-of-context information in user prompts. Our evaluation\nusing examples from ShareGPT shows that lightweight models can effectively\nimplement this framework, achieving strong gains in contextual privacy while\npreserving the user's intended interaction goals. Notably, about 76% of\nparticipants in our human evaluation preferred the reformulated prompts over\nthe original ones, validating the usability and effectiveness of contextual\nprivacy in our proposed framework. We opensource the code at\nhttps://github.com/IBM/contextual-privacy-LLM.", "comment": "22 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2502.18509v2", "cate": "cs.CR", "date": "2025-02-22", "updated": "2025-07-28"}
{"id": "2504.04691", "title": "Large-Scale Mixed-Traffic and Intersection Control using Multi-agent Reinforcement Learning", "authors": ["Songyang Liu", "Muyang Fan", "Weizi Li", "Jing Du", "Shuai Li"], "categories": ["cs.LG", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2025", "url": "http://arxiv.org/abs/2504.04691v2", "summary": "Traffic congestion remains a significant challenge in modern urban networks.\nAutonomous driving technologies have emerged as a potential solution. Among\ntraffic control methods, reinforcement learning has shown superior performance\nover traffic signals in various scenarios. However, prior research has largely\nfocused on small-scale networks or isolated intersections, leaving large-scale\nmixed traffic control largely unexplored. This study presents the first attempt\nto use decentralized multi-agent reinforcement learning for large-scale mixed\ntraffic control in which some intersections are managed by traffic signals and\nothers by robot vehicles. Evaluating a real-world network in Colorado Springs,\nCO, USA with 14 intersections, we measure traffic efficiency via average\nwaiting time of vehicles at intersections and the number of vehicles reaching\ntheir destinations within a time window (i.e., throughput). At 80% RV\npenetration rate, our method reduces waiting time from 6.17s to 5.09s and\nincreases throughput from 454 vehicles per 500 seconds to 493 vehicles per 500\nseconds, outperforming the baseline of fully signalized intersections. These\nfindings suggest that integrating reinforcement learning-based control\nlarge-scale traffic can improve overall efficiency and may inform future urban\nplanning strategies.", "comment": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS), 2025", "pdf_url": "http://arxiv.org/pdf/2504.04691v2", "cate": "cs.LG", "date": "2025-04-07", "updated": "2025-07-26"}
{"id": "2507.19914", "title": "High-Speed Event Vision-Based Tactile Roller Sensor for Large Surface Measurements", "authors": ["Akram Khairi", "Hussain Sajwani", "Abdallah Mohammad Alkilany", "Laith AbuAssi", "Mohamad Halwani", "Islam Mohamed Zaid", "Ahmed Awadalla", "Dewald Swart", "Abdulla Ayyad", "Yahya Zweiri"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      14 pages, 11 figures", "url": "http://arxiv.org/abs/2507.19914v1", "summary": "Inspecting large-scale industrial surfaces like aircraft fuselages for\nquality control requires capturing their precise 3D surface geometry at high\nresolution. Vision-based tactile sensors (VBTSs) offer high local resolution\nbut require slow 'press-and-lift' measurements stitched for large areas.\nApproaches with sliding or roller/belt VBTS designs provide measurements\ncontinuity. However, they face significant challenges respectively: sliding\nstruggles with friction/wear and both approaches are speed-limited by\nconventional camera frame rates and motion blur, making large-area scanning\ntime consuming. Thus, a rapid, continuous, high-resolution method is needed. We\nintroduce a novel tactile sensor integrating a neuromorphic camera in a rolling\nmechanism to achieve this. Leveraging its high temporal resolution and\nrobustness to motion blur, our system uses a modified event-based multi-view\nstereo approach for 3D reconstruction. We demonstrate state-of-the-art scanning\nspeeds up to 0.5 m/s, achieving Mean Absolute Error below 100 microns -- 11\ntimes faster than prior continuous tactile sensing methods. A multi-reference\nBayesian fusion strategy enhances accuracy (reducing MAE by 25.2\\% compared to\nEMVS) and mitigates curvature errors. We also validate high-speed feature\nrecognition via Braille reading 2.6 times faster than previous approaches.", "comment": "14 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.19914v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19725", "title": "Minding Motivation: The Effect of Intrinsic Motivation on Agent Behaviors", "authors": ["Leonardo Villalobos-Arias", "Grant Forbes", "Jianxun Wang", "David L Roberts", "Arnav Jhala"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      11 pages, 7 figures, 3 tables", "url": "http://arxiv.org/abs/2507.19725v1", "summary": "Games are challenging for Reinforcement Learning~(RL) agents due to their\nreward-sparsity, as rewards are only obtainable after long sequences of\ndeliberate actions. Intrinsic Motivation~(IM) methods -- which introduce\nexploration rewards -- are an effective solution to reward-sparsity. However,\nIM also causes an issue known as `reward hacking' where the agent optimizes for\nthe new reward at the expense of properly playing the game. The larger problem\nis that reward hacking itself is largely unknown; there is no answer to\nwhether, and to what extent, IM rewards change the behavior of RL agents. This\nstudy takes a first step by empirically evaluating the impact on behavior of\nthree IM techniques on the MiniGrid game-like environment. We compare these IM\nmodels with Generalized Reward Matching~(GRM), a method that can be used with\nany intrinsic reward function to guarantee optimality. Our results suggest that\nIM causes noticeable change by increasing the initial rewards, but also\naltering the way the agent plays; and that GRM mitigated reward hacking in some\nscenarios.", "comment": "11 pages, 7 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.19725v1", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19490", "title": "RISEE: A Highly Interactive Naturalistic Driving Trajectories Dataset with Human Subjective Risk Perception and Eye-tracking Information", "authors": ["Xinzheng Wu", "Junyi Chen", "Peiyi Wang", "Shunxiang Chen", "Haolan Meng", "Yong Shen"], "categories": ["cs.HC", "cs.CV"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Submitted for ITSC 2025", "url": "http://arxiv.org/abs/2507.19490v2", "summary": "In the research and development (R&D) and verification and validation (V&V)\nphases of autonomous driving decision-making and planning systems, it is\nnecessary to integrate human factors to achieve decision-making and evaluation\nthat align with human cognition. However, most existing datasets primarily\nfocus on vehicle motion states and trajectories, neglecting human-related\ninformation. In addition, current naturalistic driving datasets lack sufficient\nsafety-critical scenarios while simulated datasets suffer from low\nauthenticity. To address these issues, this paper constructs the Risk-Informed\nSubjective Evaluation and Eye-tracking (RISEE) dataset which specifically\ncontains human subjective evaluations and eye-tracking data apart from regular\nnaturalistic driving trajectories. By leveraging the complementary advantages\nof drone-based (high realism and extensive scenario coverage) and\nsimulation-based (high safety and reproducibility) data collection methods, we\nfirst conduct drone-based traffic video recording at a highway ramp merging\narea. After that, the manually selected highly interactive scenarios are\nreconstructed in simulation software, and drivers' first-person view (FPV)\nvideos are generated, which are then viewed and evaluated by recruited\nparticipants. During the video viewing process, participants' eye-tracking data\nis collected. After data processing and filtering, 3567 valid subjective risk\nratings from 101 participants across 179 scenarios are retained, along with\n2045 qualified eye-tracking data segments. The collected data and examples of\nthe generated FPV videos are available in our website.", "comment": "Preprint accepted by ITSC 2025", "pdf_url": "http://arxiv.org/pdf/2507.19490v2", "cate": "cs.HC", "date": "2025-05-29", "updated": "2025-07-29"}
{"id": "2507.20193", "title": "Efficient and Fault-Tolerant Memristive Neural Networks with In-Situ Training", "authors": ["Santlal Prajapat", "Manobendra Nath Mondal", "Susmita Sur-Kolay"], "categories": ["cs.ET"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20193v1", "summary": "Neuromorphic architectures, which incorporate parallel and in-memory\nprocessing, are crucial for accelerating artificial neural network (ANN)\ncomputations. This work presents a novel memristor-based multi-layer neural\nnetwork (memristive MLNN) architecture and an efficient in-situ training\nalgorithm. The proposed design performs matrix-vector multiplications, outer\nproducts, and weight updates in constant time $\\mathcal{O}(1)$, leveraging the\ninherent parallelism of memristive crossbars. Each synapse is realized using a\nsingle memristor, eliminating the need for transistors, and offering enhanced\narea and energy efficiency. The architecture is evaluated through LTspice\nsimulations on the IRIS, NASA Asteroid, and Breast Cancer Wisconsin datasets,\nachieving classification accuracies of 98.22\\%, 90.43\\%, and 98.59\\%,\nrespectively. Robustness is assessed by introducing stuck-at-conducting-state\nfaults in randomly selected memristors. The effects of nonlinearity in\nmemristor conductance and a 10\\% device variation are also analyzed. The\nsimulation results establish that the network's performance is not affected\nsignificantly by faulty memristors, non-linearity, and device variation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20193v1", "cate": "cs.ET", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19513", "title": "Enhancing Spatiotemporal Networks with xLSTM: A Scalar LSTM Approach for Cellular Traffic Forecasting", "authors": ["Khalid Ali", "Zineddine Bettouche", "Andreas Kassler", "Andreas Fischer"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19513v1", "summary": "Accurate spatiotemporal traffic forecasting is vital for intelligent resource\nmanagement in 5G and beyond. However, conventional AI approaches often fail to\ncapture the intricate spatial and temporal patterns that exist, due to e.g.,\nthe mobility of users. We introduce a lightweight, dual-path Spatiotemporal\nNetwork that leverages a Scalar LSTM (sLSTM) for efficient temporal modeling\nand a three-layer Conv3D module for spatial feature extraction. A fusion layer\nintegrates both streams into a cohesive representation, enabling robust\nforecasting. Our design improves gradient stability and convergence speed while\nreducing prediction error. Evaluations on real-world datasets show superior\nforecast performance over ConvLSTM baselines and strong generalization to\nunseen regions, making it well-suited for large-scale, next-generation network\ndeployments. Experimental evaluation shows a 23% MAE reduction over ConvLSTM,\nwith a 30% improvement in model generalization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19513v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2503.04036", "title": "Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge", "authors": ["Xinyue Cui", "Johnny Tian-Zheng Wei", "Swabha Swayamdipta", "Robin Jia"], "categories": ["cs.CR", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025 Findings", "url": "http://arxiv.org/abs/2503.04036v3", "summary": "Data watermarking in language models injects traceable signals, such as\nspecific token sequences or stylistic patterns, into copyrighted text, allowing\ncopyright holders to track and verify training data ownership. Previous data\nwatermarking techniques primarily focus on effective memorization during\npretraining, while overlooking challenges that arise in other stages of the LLM\nlifecycle, such as the risk of watermark filtering during data preprocessing\nand verification difficulties due to API-only access. To address these\nchallenges, we propose a novel data watermarking approach that injects\nplausible yet fictitious knowledge into training data using generated passages\ndescribing a fictitious entity and its associated attributes. Our watermarks\nare designed to be memorized by the LLM through seamlessly integrating in its\ntraining data, making them harder to detect lexically during preprocessing. We\ndemonstrate that our watermarks can be effectively memorized by LLMs, and that\nincreasing our watermarks' density, length, and diversity of attributes\nstrengthens their memorization. We further show that our watermarks remain\neffective after continual pretraining and supervised finetuning. Finally, we\nshow that our data watermarks can be evaluated even under API-only access via\nquestion answering.", "comment": "Accepted to ACL 2025 Findings", "pdf_url": "http://arxiv.org/pdf/2503.04036v3", "cate": "cs.CR", "date": "2025-03-06", "updated": "2025-07-26"}
{"id": "2507.18623", "title": "Moving Out: Physically-grounded Human-AI Collaboration", "authors": ["Xuhui Kang", "Sung-Wook Lee", "Haolin Liu", "Yuyan Wang", "Yen-Ling Kuo"], "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      24 pages, 8 figures", "url": "http://arxiv.org/abs/2507.18623v2", "summary": "The ability to adapt to physical actions and constraints in an environment is\ncrucial for embodied agents (e.g., robots) to effectively collaborate with\nhumans. Such physically grounded human-AI collaboration must account for the\nincreased complexity of the continuous state-action space and constrained\ndynamics caused by physical constraints. In this paper, we introduce Moving\nOut, a new human-AI collaboration benchmark that resembles a wide range of\ncollaboration modes affected by physical attributes and constraints, such as\nmoving heavy items together and maintaining consistent actions to move a big\nitem around a corner. Using Moving Out, we designed two tasks and collected\nhuman-human interaction data to evaluate models' abilities to adapt to diverse\nhuman behaviors and unseen physical attributes. To address the challenges in\nphysical environments, we propose a novel method, BASS (Behavior Augmentation,\nSimulation, and Selection), to enhance the diversity of agents and their\nunderstanding of the outcome of actions. Our experiments show that BASS\noutperforms state-of-the-art models in AI-AI and human-AI collaboration. The\nproject page is available at https://live-robotics-uva.github.io/movingout_ai/.", "comment": "24 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.18623v2", "cate": "cs.LG", "date": "2025-07-24", "updated": "2025-07-26"}
{"id": "2507.19947", "title": "Spatial Language Likelihood Grounding Network for Bayesian Fusion of Human-Robot Observations", "authors": ["Supawich Sitdhipol", "Waritwong Sukprasongdee", "Ekapol Chuangsuwanich", "Rina Tse"], "categories": ["cs.RO", "cs.CL", "cs.IT", "cs.LG", "cs.SY", "eess.SY", "math.IT"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to the 2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)", "url": "http://arxiv.org/abs/2507.19947v1", "summary": "Fusing information from human observations can help robots overcome sensing\nlimitations in collaborative tasks. However, an uncertainty-aware fusion\nframework requires a grounded likelihood representing the uncertainty of human\ninputs. This paper presents a Feature Pyramid Likelihood Grounding Network\n(FP-LGN) that grounds spatial language by learning relevant map image features\nand their relationships with spatial relation semantics. The model is trained\nas a probability estimator to capture aleatoric uncertainty in human language\nusing three-stage curriculum learning. Results showed that FP-LGN matched\nexpert-designed rules in mean Negative Log-Likelihood (NLL) and demonstrated\ngreater robustness with lower standard deviation. Collaborative sensing results\ndemonstrated that the grounded likelihood successfully enabled\nuncertainty-aware fusion of heterogeneous human language observations and robot\nsensor measurements, achieving significant improvements in human-robot\ncollaborative task performance.", "comment": "Accepted to the 2025 IEEE International Conference on Systems, Man,\n  and Cybernetics (SMC)", "pdf_url": "http://arxiv.org/pdf/2507.19947v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19726", "title": "HypKG: Hypergraph-based Knowledge Graph Contextualization for Precision Healthcare", "authors": ["Yuzhang Xie", "Xu Han", "Ran Xu", "Xiao Hu", "Jiaying Lu", "Carl Yang"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Extended version of paper accepted at the 24th International Semantic Web Conference (ISWC 2025), Main Tracks, Research Track, Oral", "url": "http://arxiv.org/abs/2507.19726v1", "summary": "Knowledge graphs (KGs) are important products of the semantic web, which are\nwidely used in various application domains. Healthcare is one of such domains\nwhere KGs are intensively used, due to the high requirement for knowledge\naccuracy and interconnected nature of healthcare data. However, KGs storing\ngeneral factual information often lack the ability to account for important\ncontexts of the knowledge such as the status of specific patients, which are\ncrucial in precision healthcare. Meanwhile, electronic health records (EHRs)\nprovide rich personal data, including various diagnoses and medications, which\nprovide natural contexts for general KGs. In this paper, we propose HypKG, a\nframework that integrates patient information from EHRs into KGs to generate\ncontextualized knowledge representations for accurate healthcare predictions.\nUsing advanced entity-linking techniques, we connect relevant knowledge from\ngeneral KGs with patient information from EHRs, and then utilize a hypergraph\nmodel to \"contextualize\" the knowledge with the patient information. Finally,\nwe employ hypergraph transformers guided by downstream prediction tasks to\njointly learn proper contextualized representations for both KGs and patients,\nfully leveraging existing knowledge in KGs and patient contexts in EHRs. In\nexperiments using a large biomedical KG and two real-world EHR datasets, HypKG\ndemonstrates significant improvements in healthcare prediction tasks across\nmultiple evaluation metrics. Additionally, by integrating external contexts,\nHypKG can learn to adjust the representations of entities and relations in KG,\npotentially improving the quality and real-world utility of knowledge.", "comment": "Extended version of paper accepted at the 24th International Semantic\n  Web Conference (ISWC 2025), Main Tracks, Research Track, Oral", "pdf_url": "http://arxiv.org/pdf/2507.19726v1", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19491", "title": "Exploring the Alignment of Perceived and Measured Sleep Quality with Working Memory using Consumer Wearables", "authors": ["Peter Neigel", "David Antony Selby", "Shota Arai", "Benjamin Tag", "Niels van Berkel", "Sebastian Vollmer", "Andrew Vargo", "Koichi Kise"], "categories": ["cs.HC", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      18 pages, 6 figures, 7 tables", "url": "http://arxiv.org/abs/2507.19491v1", "summary": "Wearable devices offer detailed sleep-tracking data. However, whether this\ninformation enhances our understanding of sleep or simply quantifies\nalready-known patterns remains unclear. This work explores the relationship\nbetween subjective sleep self-assessments and sensor data from an Oura ring\nover 4--8 weeks in-the-wild. 29 participants rated their sleep quality daily\ncompared to the previous night and completed a working memory task. Our\nfindings reveal that differences in REM sleep, nocturnal heart rate, N-Back\nscores, and bedtimes highly predict sleep self-assessment in significance and\neffect size. For N-Back performance, REM sleep duration, prior night's REM\nsleep, and sleep self-assessment are the strongest predictors. We demonstrate\nthat self-report sensitivity towards sleep markers differs among participants.\nWe identify three groups, highlighting that sleep trackers provide more\ninformation gain for some users than others. Additionally, we make all\nexperiment data publicly available.", "comment": "18 pages, 6 figures, 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.19491v1", "cate": "cs.HC", "date": "2025-05-31", "updated": "2025-05-31"}
{"id": "2507.20998", "title": "Efficient Memristive Spiking Neural Networks Architecture with Supervised In-Situ STDP Method", "authors": ["Santlal Prajapati", "Susmita Sur-Kolay", "Soumyadeep Dutta"], "categories": ["cs.ET", "cs.NE"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20998v1", "summary": "Memristor-based Spiking Neural Networks (SNNs) with temporal spike encoding\nenable ultra-low-energy computation, making them ideal for battery-powered\nintelligent devices. This paper presents a circuit-level memristive spiking\nneural network (SNN) architecture trained using a proposed novel supervised\nin-situ learning algorithm inspired by spike-timing-dependent plasticity\n(STDP). The proposed architecture efficiently implements lateral inhibition and\nthe refractory period, eliminating the need for external microcontrollers or\nancillary control hardware. All synapses of the winning neurons are updated in\nparallel, enhancing training efficiency. The modular design ensures scalability\nwith respect to input data dimensions and output class count. The SNN is\nevaluated in LTspice for pattern recognition (using 5x3 binary images) and\nclassification tasks using the Iris and Breast Cancer Wisconsin (BCW) datasets.\nDuring testing, the system achieved perfect pattern recognition and high\nclassification accuracies of 99.11\\% (Iris) and 97.9\\% (BCW). Additionally, it\nhas demonstrated robustness, maintaining an average recognition rate of 93.4\\%\nunder 20\\% input noise. The impact of stuck-at-conductance faults and memristor\ndevice variations was also analyzed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20998v1", "cate": "cs.ET", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19514", "title": "Wavelet Logic Machines: Learning and Reasoning in the Spectral Domain Without Neural Networks", "authors": ["Andrew Kiruluta"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19514v1", "summary": "We introduce a fully spectral learning framework that eliminates traditional\nneural layers by operating entirely in the wavelet domain. The model applies\nlearnable nonlinear transformations, including soft-thresholding and gain-phase\nmodulation, directly to wavelet coefficients. It also includes a differentiable\nwavelet basis selection mechanism, enabling adaptive processing using families\nsuch as Haar, Daubechies, and Biorthogonal wavelets.\n  Implemented in PyTorch with full 3D support, the model maintains a spectral\npipeline without spatial convolutions or attention. On synthetic 3D denoising\nand natural language tasks from the GLUE benchmark, including SST-2 sentiment\nclassification, the model achieves 89.3 percent accuracy, close to a 4-layer\nTransformer baseline (90.1 percent), while using 72 percent fewer parameters\nand 58 percent less peak memory. Faster early convergence is observed due to\nspectral sparsity priors.\n  In contrast to the quadratic complexity of self-attention and large matrix\nmultiplications in Transformers, our approach uses linear-time wavelet\ntransforms and pointwise nonlinearities, significantly reducing inference cost.\nThis yields a compact, interpretable, and efficient alternative to neural\nmodels. Our results support the viability of principled spectral learning in\nboth vision and language tasks, offering new directions for model design\nwithout overparameterized architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19514v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2503.15065", "title": "A Comprehensive Quantification of Inconsistencies in Memory Dumps", "authors": ["Andrea Oliveri", "Davide Balzarotti"], "categories": ["cs.CR", "cs.OS", "D.4.6"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.15065v2", "summary": "Memory forensics is a powerful technique commonly adopted to investigate\ncompromised machines and to detect stealthy computer attacks that do not store\ndata on non-volatile storage. To employ this technique effectively, the analyst\nhas to first acquire a faithful copy of the system's volatile memory after the\nincident. However, almost all memory acquisition tools capture the content of\nphysical memory without stopping the system's activity and by following the\nascending order of the physical pages, which can lead to inconsistencies and\nerrors in the dump. In this paper we developed a system to track all write\noperations performed by the OS kernel during a memory acquisition process. This\nallows us to quantify, for the first time, the exact number and type of\ninconsistencies observed in memory dumps. We examine the runtime activity of\nthree different operating systems and the way they manage physical memory.\nThen, focusing on Linux, we quantify how different acquisition modes, file\nsystems, and hardware targets influence the frequency of kernel writes during\nthe dump. We also analyze the impact of inconsistencies on the reconstruction\nof page tables and major kernel data structures used by Volatility to extract\nforensic artifacts. Our results show that inconsistencies are very common and\nthat their presence can undermine the reliability and validity of memory\nforensics analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.15065v2", "cate": "cs.CR", "date": "2025-03-19", "updated": "2025-07-28"}
{"id": "2507.19975", "title": "A roadmap for AI in robotics", "authors": ["Aude Billard", "Alin Albu-Schaeffer", "Michael Beetz", "Wolfram Burgard", "Peter Corke", "Matei Ciocarlie", "Ravinder Dahiya", "Danica Kragic", "Ken Goldberg", "Yukie Nagai", "Davide Scaramuzza"], "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19975v1", "summary": "AI technologies, including deep learning, large-language models have gone\nfrom one breakthrough to the other. As a result, we are witnessing growing\nexcitement in robotics at the prospect of leveraging the potential of AI to\ntackle some of the outstanding barriers to the full deployment of robots in our\ndaily lives. However, action and sensing in the physical world pose greater and\ndifferent challenges than analysing data in isolation. As the development and\napplication of AI in robotic products advances, it is important to reflect on\nwhich technologies, among the vast array of network architectures and learning\nmodels now available in the AI field, are most likely to be successfully\napplied to robots; how they can be adapted to specific robot designs, tasks,\nenvironments; which challenges must be overcome. This article offers an\nassessment of what AI for robotics has achieved since the 1990s and proposes a\nshort- and medium-term research roadmap listing challenges and promises. These\nrange from keeping up-to-date large datasets, representatives of a diversity of\ntasks robots may have to perform, and of environments they may encounter, to\ndesigning AI algorithms tailored specifically to robotics problems but generic\nenough to apply to a wide range of applications and transfer easily to a\nvariety of robotic platforms. For robots to collaborate effectively with\nhumans, they must predict human behavior without relying on bias-based\nprofiling. Explainability and transparency in AI-driven robot control are not\noptional but essential for building trust, preventing misuse, and attributing\nresponsibility in accidents. We close on what we view as the primary long-term\nchallenges, that is, to design robots capable of lifelong learning, while\nguaranteeing safe deployment and usage, and sustainable computational costs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19975v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19733", "title": "Integrating Activity Predictions in Knowledge Graphs", "authors": ["Alec Scully", "Cameron Stockton", "Forrest Hare"], "categories": ["cs.AI", "cs.DB"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      7 pages. 18 figures. Semantic Technology for Intelligence, Defense, and Security (STIDS 2024)", "url": "http://arxiv.org/abs/2507.19733v1", "summary": "We argue that ontology-structured knowledge graphs can play a crucial role in\ngenerating predictions about future events. By leveraging the semantic\nframework provided by Basic Formal Ontology (BFO) and Common Core Ontologies\n(CCO), we demonstrate how data such as the movements of a fishing vessel can be\norganized in and retrieved from a knowledge graph. These query results are then\nused to create Markov chain models, allowing us to predict future states based\non the vessel's history. To fully support this process, we introduce the term\n`spatiotemporal instant' to complete the necessary structural semantics.\nAdditionally, we critique the prevailing ontological model of probability,\nwhich conflates probability with likelihood and relies on the problematic\nconcept of modal measurements: measurements of future entities. We propose an\nalternative view, where probabilities are treated as being about process\nprofiles, which better captures the dynamics of real world phenomena. Finally,\nwe demonstrate how our Markov chain based probability calculations can be\nseamlessly integrated back into the knowledge graph, enabling further analysis\nand decision-making. Keywords: predictive analytics, ontology, Markov chains,\nprobability, Basic Formal Ontology (BFO), knowledge graphs, SPARQL.", "comment": "7 pages. 18 figures. Semantic Technology for Intelligence, Defense,\n  and Security (STIDS 2024)", "pdf_url": "http://arxiv.org/pdf/2507.19733v1", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19492", "title": "ChartGen: Scaling Chart Understanding Via Code-Guided Synthetic Chart Generation", "authors": ["Jovana Kondic", "Pengyuan Li", "Dhiraj Joshi", "Zexue He", "Shafiq Abedin", "Jennifer Sun", "Ben Wiesel", "Eli Schwartz", "Ahmed Nassar", "Bo Wu", "Assaf Arbelle", "Aude Oliva", "Dan Gutfreund", "Leonid Karlinsky", "Rogerio Feris"], "categories": ["cs.HC", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19492v1", "summary": "Chart-to-code reconstruction -- the task of recovering executable plotting\nscripts from chart images -- provides important insights into a model's ability\nto ground data visualizations in precise, machine-readable form. Yet many\nexisting multimodal benchmarks largely focus primarily on answering questions\nabout charts or summarizing them. To bridge this gap, we present ChartGen, a\nfully-automated pipeline for code-guided synthetic chart generation. Starting\nfrom seed chart images, ChartGen (i) prompts a vision-language model (VLM) to\nreconstruct each image into a python script, and (ii) iteratively augments that\nscript with a code-oriented large language model (LLM). Using ChartGen, we\ncreate 222.5K unique chart-image code pairs from 13K seed chart images, and\npresent an open-source synthetic chart dataset covering 27 chart types, 11\nplotting libraries, and multiple data modalities (image, code, text, CSV,\nDocTags). From this corpus, we curate a held-out chart-to-code evaluation\nsubset of 4.3K chart image-code pairs, and evaluate six open-weight VLMs (3B -\n26B parameters), highlighting substantial room for progress. We release the\npipeline, prompts, and the dataset to help accelerate efforts towards robust\nchart understanding and vision-conditioned code generation:\nhttps://github.com/SD122025/ChartGen/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19492v1", "cate": "cs.HC", "date": "2025-05-31", "updated": "2025-05-31"}
{"id": "2403.05415", "title": "An Overview of Automated Vehicle Longitudinal Platoon Formation Strategies", "authors": ["M Sabbir Salek", "Mugdha Basu Thakur", "Pardha Sai Krishna Ala", "Mashrur Chowdhury", "Matthias Schmid", "Pamela Murray-Tuite", "Sakib Mahmud Khan", "Venkat Krovi"], "categories": ["eess.SY", "cs.ET", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.05415v4", "summary": "Automated vehicle (AV) platooning has the potential to improve the safety,\noperational, and energy efficiency of surface transportation systems by\nlimiting or eliminating human involvement in the driving tasks. The theoretical\nvalidity of the AV platooning strategies has been established and practical\napplications are being tested under real-world conditions. The emergence of\nsensors, communication, and control strategies has resulted in rapid and\nconstant evolution of AV platooning strategies. In this paper, we review the\nstate-of-the-art knowledge in AV longitudinal platoon formation using a\nfive-component platooning framework, which includes vehicle model,\ninformation-receiving process, information flow topology, spacing policy, and\ncontroller and discuss the advantages and limitations of the components. Based\non the discussion about existing strategies and associated limitations,\npotential future research directions are presented.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.05415v4", "cate": "eess.SY", "date": "2024-03-08", "updated": "2025-05-17"}
{"id": "2507.19515", "title": "A Comparative Analysis of Traditional and Deep Learning Time Series Architectures for Influenza A Infectious Disease Forecasting", "authors": ["Edmund F. Agyemang", "Hansapani Rodrigo", "Vincent Agbenyeavu"], "categories": ["cs.LG", "cs.CY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19515v1", "summary": "Influenza A is responsible for 290,000 to 650,000 respiratory deaths a year,\nthough this estimate is an improvement from years past due to improvements in\nsanitation, healthcare practices, and vaccination programs. In this study, we\nperform a comparative analysis of traditional and deep learning models to\npredict Influenza A outbreaks. Using historical data from January 2009 to\nDecember 2023, we compared the performance of traditional ARIMA and Exponential\nSmoothing(ETS) models with six distinct deep learning architectures: Simple\nRNN, LSTM, GRU, BiLSTM, BiGRU, and Transformer. The results reveal a clear\nsuperiority of all the deep learning models, especially the state-of-the-art\nTransformer with respective average testing MSE and MAE of 0.0433 \\pm 0.0020\nand 0.1126 \\pm 0.0016 for capturing the temporal complexities associated with\nInfluenza A data, outperforming well known traditional baseline ARIMA and ETS\nmodels. These findings of this study provide evidence that state-of-the-art\ndeep learning architectures can enhance predictive modeling for infectious\ndiseases and indicate a more general trend toward using deep learning methods\nto enhance public health forecasting and intervention planning strategies.\nFuture work should focus on how these models can be incorporated into real-time\nforecasting and preparedness systems at an epidemic level, and integrated into\nexisting surveillance systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19515v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2504.16057", "title": "Automated Static Vulnerability Detection via a Holistic Neuro-symbolic Approach", "authors": ["Penghui Li", "Songchen Yao", "Josef Sarfati Korich", "Changhua Luo", "Jianjia Yu", "Yinzhi Cao", "Junfeng Yang"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.16057v3", "summary": "In this paper, we present MoCQ, a novel neuro-symbolic framework that\ncombines the complementary strengths of Large Language Model (LLM) and classic\nvulnerability checkers to enable scalable, automated vulnerability detection.\nThe key insight is to leverage an LLM to automatically generate vulnerability\npatterns and translate them into detection queries. Specifically, MoCQ\nincorporates an iterative loop in which an LLM refines queries based on\ncarefully designed feedback information. The resulting queries are then\nexecuted to analyze large codebases and detect vulnerabilities. We evaluated\nMoCQ on 12 vulnerability types across four programming languages. MoCQ achieved\ncomparable precision and recall compared to expert-developed queries, with\nsignificantly less expert time needed. MoCQ also uncovered 46 new vulnerability\npatterns that experts missed, each representing an overlooked vulnerability\nclass. MoCQ further discovered seven previously unknown vulnerabilities in\nreal-world applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.16057v3", "cate": "cs.CR", "date": "2025-04-22", "updated": "2025-07-26"}
{"id": "2507.19983", "title": "CLASP: General-Purpose Clothes Manipulation with Semantic Keypoints", "authors": ["Yuhong Deng", "Chao Tang", "Cunjun Yu", "Linfeng Li", "David Hsu"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19983v1", "summary": "Clothes manipulation, such as folding or hanging, is a critical capability\nfor home service robots. Despite recent advances, most existing methods remain\nlimited to specific tasks and clothes types, due to the complex,\nhigh-dimensional geometry of clothes. This paper presents CLothes mAnipulation\nwith Semantic keyPoints (CLASP), which aims at general-purpose clothes\nmanipulation over different clothes types, T-shirts, shorts, skirts, long\ndresses, ... , as well as different tasks, folding, flattening, hanging, ... .\nThe core idea of CLASP is semantic keypoints -- e.g., ''left sleeve'', ''right\nshoulder'', etc. -- a sparse spatial-semantic representation that is salient\nfor both perception and action. Semantic keypoints of clothes can be reliably\nextracted from RGB-D images and provide an effective intermediate\nrepresentation of clothes manipulation policies. CLASP uses semantic keypoints\nto bridge high-level task planning and low-level action execution. At the high\nlevel, it exploits vision language models (VLMs) to predict task plans over the\nsemantic keypoints. At the low level, it executes the plans with the help of a\nsimple pre-built manipulation skill library. Extensive simulation experiments\nshow that CLASP outperforms state-of-the-art baseline methods on multiple tasks\nacross diverse clothes types, demonstrating strong performance and\ngeneralization. Further experiments with a Franka dual-arm system on four\ndistinct tasks -- folding, flattening, hanging, and placing -- confirm CLASP's\nperformance on a real robot.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19983v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19749", "title": "Can LLMs Solve ASP Problems? Insights from a Benchmarking Study (Extended Version)", "authors": ["Lin Ren", "Guohui Xiao", "Guilin Qi", "Yishuai Geng", "Haohan Xue"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted for publication at the 22nd International Conference on Principles of Knowledge Representation and Reasoning (KR 2025). The code is available at this https URL", "url": "http://arxiv.org/abs/2507.19749v1", "summary": "Answer Set Programming (ASP) is a powerful paradigm for non-monotonic\nreasoning. Recently, large language models (LLMs) have demonstrated promising\ncapabilities in logical reasoning. Despite this potential, current evaluations\nof LLM capabilities in ASP are often limited. Existing works normally employ\noverly simplified ASP programs, do not support negation, disjunction, or\nmultiple answer sets. Furthermore, there is a lack of benchmarks that introduce\ntasks specifically designed for ASP solving. To bridge this gap, we introduce\nASPBench, a comprehensive ASP benchmark, including three ASP specific tasks:\nASP entailment, answer set verification, and answer set computation. Our\nextensive evaluations on ASPBench reveal that while 14 state-of-the-art LLMs,\nincluding \\emph{deepseek-r1}, \\emph{o4-mini}, and\n\\emph{gemini-2.5-flash-thinking}, perform relatively well on the first two\nsimpler tasks, they struggle with answer set computation, which is the core of\nASP solving. These findings offer insights into the current limitations of LLMs\nin ASP solving. This highlights the need for new approaches that integrate\nsymbolic reasoning capabilities more effectively. The code and dataset are\navailable at https://github.com/HomuraT/ASPBench.", "comment": "Accepted for publication at the 22nd International Conference on\n  Principles of Knowledge Representation and Reasoning (KR 2025). The code is\n  available at https://github.com/HomuraT/ASPBench", "pdf_url": "http://arxiv.org/pdf/2507.19749v1", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19493", "title": "From Bench to Bedside: A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice", "authors": ["Yaowei Bai", "Ruiheng Zhang", "Yu Lei", "Jingfeng Yao", "Shuguang Ju", "Chaoyang Wang", "Wei Yao", "Yiwan Guo", "Guilin Zhang", "Chao Wan", "Qian Yuan", "Xuhua Duan", "Xinggang Wang", "Tao Sun", "Yongchao Xu", "Chuansheng Zheng", "Huangxuan Zhao", "Bo Du"], "categories": ["cs.HC", "eess.IV"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19493v1", "summary": "A global shortage of radiologists has been exacerbated by the significant\nvolume of chest X-ray workloads, particularly in primary care. Although\nmultimodal large language models show promise, existing evaluations\npredominantly rely on automated metrics or retrospective analyses, lacking\nrigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray\ninterpretation system based on DeepSeek Janus-Pro model, was developed and\nrigorously validated through a multicenter prospective trial (NCT06874647). Our\nsystem outperforms state-of-the-art X-ray report generation models in automated\nreport generation, surpassing even larger-scale models including ChatGPT 4o\n(200B parameters), while demonstrating robust detection of eight clinically\ncritical radiographic findings (area under the curve, AUC > 0.8). Retrospective\nevaluation confirms significantly higher report accuracy than Janus-Pro and\nChatGPT 4o. In prospective clinical deployment, AI assistance significantly\nimproved report quality scores (4.37 vs. 4.11, P < 0.001), reduced\ninterpretation time by 18.5% (P < 0.001), and was preferred by a majority of\nexperts (3 out of 5) in 52.7% of cases. Through lightweight architecture and\ndomain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and\nworkflow efficiency, particularly in resource-constrained settings. The model\narchitecture and implementation framework will be open-sourced to facilitate\nthe clinical translation of AI-assisted radiology solutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19493v1", "cate": "cs.HC", "date": "2025-05-31", "updated": "2025-05-31"}
{"id": "2507.19675", "title": "Wardropian Cycles make traffic assignment both optimal and fair by eliminating price-of-anarchy with Cyclical User Equilibrium for compliant connected autonomous vehicles", "authors": ["Michał Hoffmann", "Michał Bujak", "Grzegorz Jamróz", "Rafał Kucharski"], "categories": ["eess.SY", "cs.ET", "cs.SI", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19675v1", "summary": "Connected and Autonomous Vehicles (CAVs) open the possibility for centralised\nrouting with full compliance, making System Optimal traffic assignment\nattainable. However, as System Optimum makes some drivers better off than\nothers, voluntary acceptance seems dubious. To overcome this issue, we propose\na new concept of Wardropian cycles, which, in contrast to previous utopian\nvisions, makes the assignment fair on top of being optimal, which amounts to\nsatisfaction of both Wardrop's principles. Such cycles, represented as\nsequences of permutations to the daily assignment matrices, always exist and\nequalise, after a limited number of days, average travel times among travellers\n(like in User Equilibrium) while preserving everyday optimality of path flows\n(like in System Optimum). We propose exact methods to compute such cycles and\nreduce their length and within-cycle inconvenience to the users. As\nidentification of optimal cycles turns out to be NP-hard in many aspects, we\nintroduce a greedy heuristic efficiently approximating the optimal solution.\nFinally, we introduce and discuss a new paradigm of Cyclical User Equilibrium,\nwhich ensures stability of optimal Wardropian Cycles under unilateral\ndeviations.\n  We complement our theoretical study with large-scale simulations. In\nBarcelona, 670 vehicle-hours of Price-of-Anarchy are eliminated using cycles\nwith a median length of 11 days-though 5% of cycles exceed 90 days. However, in\nBerlin, just five days of applying the greedy assignment rule significantly\nreduces initial inequity. In Barcelona, Anaheim, and Sioux Falls, less than 7%\nof the initial inequity remains after 10 days, demonstrating the effectiveness\nof this approach in improving traffic performance with more ubiquitous social\nacceptability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19675v1", "cate": "eess.SY", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19517", "title": "BikeVAE-GNN: A Variational Autoencoder-Augmented Hybrid Graph Neural Network for Sparse Bicycle Volume Estimation", "authors": ["Mohit Gupta", "Debjit Bhowmick", "Ben Beck"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper has been accepted for publication in the Proceedings of the $28^{th}$ IEEE International Conference on Intelligent Transportation Systems (ITSC 2025). This is the author's version of the work", "url": "http://arxiv.org/abs/2507.19517v1", "summary": "Accurate link-level bicycle volume estimation is essential for informed urban\nand transport planning but it is challenged by extremely sparse count data in\nurban bicycling networks worldwide. We propose BikeVAE-GNN, a novel dual-task\nframework augmenting a Hybrid Graph Neural Network (GNN) with Variational\nAutoencoder (VAE) to estimate Average Daily Bicycle (ADB) counts, addressing\nsparse bicycle networks. The Hybrid-GNN combines Graph Convolutional Networks\n(GCN), Graph Attention Networks (GAT), and GraphSAGE to effectively model\nintricate spatial relationships in sparse networks while VAE generates\nsynthetic nodes and edges to enrich the graph structure and enhance the\nestimation performance. BikeVAE-GNN simultaneously performs - regression for\nbicycling volume estimation and classification for bicycling traffic level\ncategorization. We demonstrate the effectiveness of BikeVAE-GNN using\nOpenStreetMap data and publicly available bicycle count data within the City of\nMelbourne - where only 141 of 15,933 road segments have labeled counts\n(resulting in 99% count data sparsity). Our experiments show that BikeVAE-GNN\noutperforms machine learning and baseline GNN models, achieving a mean absolute\nerror (MAE) of 30.82 bicycles per day, accuracy of 99% and F1-score of 0.99.\nAblation studies further validate the effective role of Hybrid-GNN and VAE\ncomponents. Our research advances bicycling volume estimation in sparse\nnetworks using novel and state-of-the-art approaches, providing insights for\nsustainable bicycling infrastructures.", "comment": "This paper has been accepted for publication in the Proceedings of\n  the $28^{th}$ IEEE International Conference on Intelligent Transportation\n  Systems (ITSC 2025). This is the author's version of the work", "pdf_url": "http://arxiv.org/pdf/2507.19517v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.19549", "title": "AccessGuru: Leveraging LLMs to Detect and Correct Web Accessibility Violations in HTML Code", "authors": ["Nadeen Fathallah", "Daniel Hernández", "Steffen Staab"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19549v1", "summary": "The vast majority of Web pages fail to comply with established Web\naccessibility guidelines, excluding a range of users with diverse abilities\nfrom interacting with their content. Making Web pages accessible to all users\nrequires dedicated expertise and additional manual efforts from Web page\nproviders. To lower their efforts and promote inclusiveness, we aim to\nautomatically detect and correct Web accessibility violations in HTML code.\nWhile previous work has made progress in detecting certain types of\naccessibility violations, the problem of automatically detecting and correcting\naccessibility violations remains an open challenge that we address. We\nintroduce a novel taxonomy classifying Web accessibility violations into three\nkey categories - Syntactic, Semantic, and Layout. This taxonomy provides a\nstructured foundation for developing our detection and correction method and\nredefining evaluation metrics. We propose a novel method, AccessGuru, which\ncombines existing accessibility testing tools and Large Language Models (LLMs)\nto detect violations and applies taxonomy-driven prompting strategies to\ncorrect all three categories. To evaluate these capabilities, we develop a\nbenchmark of real-world Web accessibility violations. Our benchmark quantifies\nsyntactic and layout compliance and judges semantic accuracy through\ncomparative analysis with human expert corrections. Evaluation against our\nbenchmark shows that AccessGuru achieves up to 84% average violation score\ndecrease, significantly outperforming prior methods that achieve at most 50%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19549v1", "cate": "cs.SE", "date": "2025-07-24", "updated": "2025-07-24"}
{"id": "2506.00831", "title": "A Large Language Model-Supported Threat Modeling Framework for Transportation Cyber-Physical Systems", "authors": ["M Sabbir Salek", "Mashrur Chowdhury", "Muhaimin Bin Munir", "Yuchen Cai", "Mohammad Imtiaz Hasan", "Jean-Michel Tine", "Latifur Khan", "Mizanur Rahman"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.00831v2", "summary": "Existing threat modeling frameworks related to transportation cyber-physical\nsystems (CPS) are often narrow in scope, labor-intensive, and require\nsubstantial cybersecurity expertise. To this end, we introduce the\nTransportation Cybersecurity and Resiliency Threat Modeling Framework\n(TraCR-TMF), a large language model (LLM)-based threat modeling framework for\ntransportation CPS that requires limited cybersecurity expert intervention.\nTraCR-TMF identifies threats, potential attack techniques, and relevant\ncountermeasures for transportation CPS. Three LLM-based approaches support\nthese identifications: (i) a retrieval-augmented generation approach requiring\nno cybersecurity expert intervention, (ii) an in-context learning approach with\nlow expert intervention, and (iii) a supervised fine-tuning approach with\nmoderate expert intervention. TraCR-TMF offers LLM-based attack path\nidentification for critical assets based on vulnerabilities across\ntransportation CPS entities. Additionally, it incorporates the Common\nVulnerability Scoring System (CVSS) scores of known exploited vulnerabilities\nto prioritize threat mitigations. The framework was evaluated through two\ncases. First, the framework identified relevant attack techniques for various\ntransportation CPS applications, 73% of which were validated by cybersecurity\nexperts as correct. Second, the framework was used to identify attack paths for\na target asset in a real-world cyberattack incident. TraCR-TMF successfully\npredicted exploitations, like lateral movement of adversaries, data\nexfiltration, and data encryption for ransomware, as reported in the incident.\nThese findings show the efficacy of TraCR-TMF in transportation CPS threat\nmodeling, while reducing the need for extensive involvement of cybersecurity\nexperts. To facilitate real-world adoptions, all our codes are shared via an\nopen-source repository.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.00831v2", "cate": "cs.CR", "date": "2025-06-01", "updated": "2025-07-28"}
{"id": "2507.19999", "title": "Robot Excavation and Manipulation of Geometrically Cohesive Granular Media", "authors": ["Laura Treers", "Daniel Soto", "Joonha Hwang", "Michael A. D. Goodisman", "Daniel I. Goldman"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19999v1", "summary": "Construction throughout history typically assumes that its blueprints and\nbuilding blocks are pre-determined. However, recent work suggests that\nalternative approaches can enable new paradigms for structure formation.\nAleatory architectures, or those which rely on the properties of their granular\nbuilding blocks rather than pre-planned design or computation, have thus far\nrelied on human intervention for their creation. We imagine that robotic swarms\ncould be valuable to create such aleatory structures by manipulating and\nforming structures from entangled granular materials. To discover principles by\nwhich robotic systems can effectively manipulate soft matter, we develop a\nrobophysical model for interaction with geometrically cohesive granular media\ncomposed of u-shape particles. This robotic platform uses environmental signals\nto autonomously coordinate excavation, transport, and deposition of material.\nWe test the effect of substrate initial conditions by characterizing robot\nperformance in two different material compaction states and observe as much as\na 75% change in transported mass depending on initial substrate compressive\nloading. These discrepancies suggest the functional role that material\nproperties such as packing and cohesion/entanglement play in excavation and\nconstruction. To better understand these material properties, we develop an\napparatus for tensile testing of the geometrically cohesive substrates, which\nreveals how entangled material strength responds strongly to initial\ncompressive loading. These results explain the variation observed in robotic\nperformance and point to future directions for better understanding robotic\ninteraction mechanics with entangled materials.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19999v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19788", "title": "Reinforcement Learning for Multi-Objective Multi-Echelon Supply Chain Optimisation", "authors": ["Rifny Rachman", "Josh Tingey", "Richard Allmendinger", "Pradyumn Shukla", "Wei Pan"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19788v1", "summary": "This study develops a generalised multi-objective, multi-echelon supply chain\noptimisation model with non-stationary markets based on a Markov decision\nprocess, incorporating economic, environmental, and social considerations. The\nmodel is evaluated using a multi-objective reinforcement learning (RL) method,\nbenchmarked against an originally single-objective RL algorithm modified with\nweighted sum using predefined weights, and a multi-objective evolutionary\nalgorithm (MOEA)-based approach. We conduct experiments on varying network\ncomplexities, mimicking typical real-world challenges using a customisable\nsimulator. The model determines production and delivery quantities across\nsupply chain routes to achieve near-optimal trade-offs between competing\nobjectives, approximating Pareto front sets. The results demonstrate that the\nprimary approach provides the most balanced trade-off between optimality,\ndiversity, and density, further enhanced with a shared experience buffer that\nallows knowledge transfer among policies. In complex settings, it achieves up\nto 75\\% higher hypervolume than the MOEA-based method and generates solutions\nthat are approximately eleven times denser, signifying better robustness, than\nthose produced by the modified single-objective RL method. Moreover, it ensures\nstable production and inventory levels while minimising demand loss.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19788v1", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19494", "title": "Evaluating Personalized Beneficial Interventions in the Daily Lives of Older Adults Using a Camera", "authors": ["Longfei Chen", "Christopher Lochhead", "Robert B. Fisher", "Nusa Faric", "Jacques Fleuriot", "Subramanian Ramamoorthy"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      AIiH 2025, International Conference on AI in Healthcare", "url": "http://arxiv.org/abs/2507.19494v1", "summary": "Beneficial daily activity interventions have been shown to improve both the\nphysical and mental health of older adults. However, there is a lack of robust\nobjective metrics and personalized strategies to measure their impact. In this\nstudy, two older adults aged over 65, living in Edinburgh, UK, selected their\npreferred daily interventions (mindful meals and art crafts), which are then\nassessed for effectiveness. The total monitoring period across both\nparticipants was 8 weeks. Their physical behaviours were continuously monitored\nusing a non-contact, privacy-preserving camera-based system. Postural and\nmobility statistics were extracted using computer vision algorithms and\ncompared across periods with and without the interventions. The results\ndemonstrate significant behavioural changes for both participants, highlighting\nthe effectiveness of both these activities and the monitoring system.", "comment": "AIiH 2025, International Conference on AI in Healthcare", "pdf_url": "http://arxiv.org/pdf/2507.19494v1", "cate": "cs.HC", "date": "2025-06-01", "updated": "2025-06-01"}
{"id": "2507.20007", "title": "AxOSyn: An Open-source Framework for Synthesizing Novel Approximate Arithmetic Operators", "authors": ["Siva Satyendra Sahoo", "Salim Ullah", "Akash Kumar"], "categories": ["cs.AR", "cs.ET", "cs.LO"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      Under review with ACM TRETS", "url": "http://arxiv.org/abs/2507.20007v1", "summary": "Edge AI deployments are becoming increasingly complex, necessitating\nenergy-efficient solutions for resource-constrained embedded systems.\nApproximate computing, which allows for controlled inaccuracies in\ncomputations, is emerging as a promising approach for improving power and\nenergy efficiency. Among the key techniques in approximate computing are\napproximate arithmetic operators (AxOs), which enable application-specific\noptimizations beyond traditional computer arithmetic hardware reduction-based\nmethods, such as quantization and precision scaling. Existing design space\nexploration (DSE) frameworks for approximate computing limit themselves to\nselection-based approaches or custom synthesis at fixed abstraction levels,\nwhich restricts the flexibility required for finding application-specific\noptimal solutions. Further, the tools available for the DSE of AxOs are quite\nlimited in terms of exploring different approximation models and extending the\nanalysis to different granularities. To this end, we propose AxOSyn, an\nopen-source framework for the DSE of AxOs that supports both selection and\nsynthesis approaches at various abstraction levels. AxOSyn allows researchers\nto integrate custom methods for evaluating approximations and facilitates DSE\nat both the operator-level and application-specific. Our framework provides an\neffective methodology for achieving energy-efficient, approximate operators.", "comment": "Under review with ACM TRETS", "pdf_url": "http://arxiv.org/pdf/2507.20007v1", "cate": "cs.AR", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19518", "title": "Target Circuit Matching in Large-Scale Netlists using GNN-Based Region Prediction", "authors": ["Sangwoo Seo", "Jimin Seo", "Yoonho Lee", "Donghyeon Kim", "Hyejin Shin", "Banghyun Sung", "Chanyoung Park"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICCAD 2025", "url": "http://arxiv.org/abs/2507.19518v1", "summary": "Subgraph matching plays an important role in electronic design automation\n(EDA) and circuit verification. Traditional rule-based methods have limitations\nin generalizing to arbitrary target circuits. Furthermore, node-to-node\nmatching approaches tend to be computationally inefficient, particularly for\nlarge-scale circuits. Deep learning methods have emerged as a potential\nsolution to address these challenges, but existing models fail to efficiently\ncapture global subgraph embeddings or rely on inefficient matching matrices,\nwhich limits their effectiveness for large circuits. In this paper, we propose\nan efficient graph matching approach that utilizes Graph Neural Networks (GNNs)\nto predict regions of high probability for containing the target circuit.\nSpecifically, we construct various negative samples to enable GNNs to\naccurately learn the presence of target circuits and develop an approach to\ndirectly extracting subgraph embeddings from the entire circuit, which captures\nglobal subgraph information and addresses the inefficiency of applying GNNs to\nall candidate subgraphs. Extensive experiments demonstrate that our approach\nsignificantly outperforms existing methods in terms of time efficiency and\ntarget region prediction, offering a scalable and effective solution for\nsubgraph matching in large-scale circuits.", "comment": "ICCAD 2025", "pdf_url": "http://arxiv.org/pdf/2507.19518v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.19687", "title": "LastMerge: A language-agnostic structured tool for code integration", "authors": ["Joao Pedro Duarte", "Paulo Borba", "Guilherme Cavalcanti"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19687v1", "summary": "Unstructured line-based merge tools are widely used in practice. Structured\nAST-based merge tools show significantly improved merge accuracy, but are\nrarely used in practice because they are language specific and costly,\nconsequently not being available for many programming languages. To improve\nmerge accuracy for a wide range of languages, we propose LastMerge, a generic\nstructured merge tool that can be configured through a thin interface that\nsignificantly reduces the effort of supporting structured merge. To understand\nthe impact that generic structured merge might have on merge accuracy and\nperformance, we run an experiment with four structured merge tools: two Java\nspecific tools, jDime and Spork, and their generic counterparts, respectively\nLastMerge and Mergiraf. Using each tool, we replay merge scenarios from a\nsignificant dataset, and collect data on runtime, behavioral divergences, and\nmerge accuracy. Our results show no evidence that generic structured merge\nsignificantly impacts merge accuracy. Although we observe a difference rate of\napproximately 10% between the Java specific tools and their generic\ncounterparts, most of the differences stem from implementation details and\ncould be avoided. We find that LastMerge reports 15% fewer false positives than\njDime while Mergiraf misses 42% fewer false negatives than Spork. Both generic\ntools exhibit comparable runtime performance to the state of the art language\nspecific implementations. These results suggest that generic structured merge\ntools can effectively replace language-specific ones, paving the way for\nbroader adoption of structured merge in industry.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19687v1", "cate": "cs.SE", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19702", "title": "A Lightweight Deep Learning-based Model for Ranking Influential Nodes in Complex Networks", "authors": ["Mohammed A. Ramadhan", "Abdulhakeem O. Mohammed"], "categories": ["cs.SI", "cs.LG"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19702v1", "summary": "Identifying influential nodes in complex networks is a critical task with a\nwide range of applications across different domains. However, existing\napproaches often face trade-offs between accuracy and computational efficiency.\nTo address these challenges, we propose 1D-CGS, a lightweight and effective\nhybrid model that integrates the speed of one-dimensional convolutional neural\nnetworks (1D-CNN) with the topological representation power of GraphSAGE for\nefficient node ranking. The model uses a lightweight input representation built\non two straightforward and significant topological features: node degree and\naverage neighbor degree. These features are processed through 1D convolutions\nto extract local patterns, followed by GraphSAGE layers to aggregate\nneighborhood information. We formulate the node ranking task as a regression\nproblem and use the Susceptible-Infected-Recovered (SIR) model to generate\nground truth influence scores. 1D-CGS is initially trained on synthetic\nnetworks generated by the Barabasi-Albert model and then applied to real world\nnetworks for identifying influential nodes. Experimental evaluations on twelve\nreal world networks demonstrate that 1D-CGS significantly outperforms\ntraditional centrality measures and recent deep learning models in ranking\naccuracy, while operating in very fast runtime. The proposed model achieves an\naverage improvement of 4.73% in Kendall's Tau correlation and 7.67% in Jaccard\nSimilarity over the best performing deep learning baselines. It also achieves\nan average Monotonicity Index (MI) score 0.99 and produces near perfect rank\ndistributions, indicating highly unique and discriminative rankings.\nFurthermore, all experiments confirm that 1D-CGS operates in a highly\nreasonable time, running significantly faster than existing deep learning\nmethods, making it suitable for large scale applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19702v1", "cate": "cs.SI", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2506.12088", "title": "Risks & Benefits of LLMs & GenAI for Platform Integrity, Healthcare Diagnostics, Financial Trust and Compliance, Cybersecurity, Privacy & AI Safety: A Comprehensive Survey, Roadmap & Implementation Blueprint", "authors": ["Kiarash Ahi"], "categories": ["cs.CR", "cs.CY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.12088v2", "summary": "Large Language Models (LLMs) and generative AI (GenAI) systems, such as\nChatGPT, Claude, Gemini, LLaMA, and Copilot (by OpenAI, Anthropic, Google,\nMeta, and Microsoft, respectively), are reshaping digital platforms and app\necosystems while introducing critical challenges in cybersecurity, privacy, and\nplatform integrity. Our analysis reveals alarming trends: LLM-assisted malware\nis projected to rise from 2% (2021) to 50% (2025); AI-generated Google reviews\ngrew nearly tenfold (1.2% in 2021 to 12.21% in 2023, expected to reach 30% by\n2025); AI scam reports surged 456%; misinformation sites increased over 1500%;\nand deepfake attacks are projected to rise over 900% in 2025. In finance,\nLLM-driven threats like synthetic identity fraud and AI-generated scams are\naccelerating. Platforms such as JPMorgan Chase, Stripe, and Plaid deploy LLMs\nfor fraud detection, regulation parsing, and KYC/AML automation, reducing fraud\nloss by up to 21% and accelerating onboarding by 40-60%. LLM-facilitated code\ndevelopment has driven mobile app submissions from 1.8 million (2020) to 3.0\nmillion (2024), projected to reach 3.6 million (2025). To address AI threats,\nplatforms like Google Play, Apple App Store, GitHub Copilot, TikTok, Facebook,\nand Amazon deploy LLM-based defenses, highlighting their dual nature as both\nthreat sources and mitigation tools. In clinical diagnostics, LLMs raise\nconcerns about accuracy, bias, and safety, necessitating strong governance.\nDrawing on 445 references, this paper surveys LLM/GenAI and proposes a\nstrategic roadmap and operational blueprint integrating policy auditing (such\nas CCPA and GDPR compliance), fraud detection, and demonstrates an advanced\nLLM-DA stack with modular components, multi-LLM routing, agentic memory, and\ngovernance layers. We provide actionable insights, best practices, and\nreal-world case studies for scalable trust and responsible innovation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.12088v2", "cate": "cs.CR", "date": "2025-06-10", "updated": "2025-07-26"}
{"id": "2507.20002", "title": "SuperMag: Vision-based Tactile Data Guided High-resolution Tactile Shape Reconstruction for Magnetic Tactile Sensors", "authors": ["Peiyao Hou", "Danning Sun", "Meng Wang", "Yuzhe Huang", "Zeyu Zhang", "Hangxin Liu", "Wanlin Li", "Ziyuan Jiao"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages, 7 figures; accepted by IROS 2025", "url": "http://arxiv.org/abs/2507.20002v1", "summary": "Magnetic-based tactile sensors (MBTS) combine the advantages of compact\ndesign and high-frequency operation but suffer from limited spatial resolution\ndue to their sparse taxel arrays. This paper proposes SuperMag, a tactile shape\nreconstruction method that addresses this limitation by leveraging\nhigh-resolution vision-based tactile sensor (VBTS) data to supervise MBTS\nsuper-resolution. Co-designed, open-source VBTS and MBTS with identical contact\nmodules enable synchronized data collection of high-resolution shapes and\nmagnetic signals via a symmetric calibration setup. We frame tactile shape\nreconstruction as a conditional generative problem, employing a conditional\nvariational auto-encoder to infer high-resolution shapes from low-resolution\nMBTS inputs. The MBTS achieves a sampling frequency of 125 Hz, whereas the\nshape reconstruction sustains an inference time within 2.5 ms. This\ncross-modality synergy advances tactile perception of the MBTS, potentially\nunlocking its new capabilities in high-precision robotic tasks.", "comment": "7 pages, 7 figures; accepted by IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.20002v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19882", "title": "Causality-aligned Prompt Learning via Diffusion-based Counterfactual Generation", "authors": ["Xinshu Li", "Ruoyu Wang", "Erdun Gao", "Mingming Gong", "Lina Yao"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19882v1", "summary": "Prompt learning has garnered attention for its efficiency over traditional\nmodel training and fine-tuning. However, existing methods, constrained by\ninadequate theoretical foundations, encounter difficulties in achieving\ncausally invariant prompts, ultimately falling short of capturing robust\nfeatures that generalize effectively across categories. To address these\nchallenges, we introduce the $\\textit{\\textbf{DiCap}}$ model, a theoretically\ngrounded $\\textbf{Di}$ffusion-based $\\textbf{C}$ounterf$\\textbf{a}$ctual\n$\\textbf{p}$rompt learning framework, which leverages a diffusion process to\niteratively sample gradients from the marginal and conditional distributions of\nthe causal model, guiding the generation of counterfactuals that satisfy the\nminimal sufficiency criterion. Grounded in rigorous theoretical derivations,\nthis approach guarantees the identifiability of counterfactual outcomes while\nimposing strict bounds on estimation errors. We further employ a contrastive\nlearning framework that leverages the generated counterfactuals, thereby\nenabling the refined extraction of prompts that are precisely aligned with the\ncausal features of the data. Extensive experimental results demonstrate that\nour method performs excellently across tasks such as image classification,\nimage-text retrieval, and visual question answering, with particularly strong\nadvantages in unseen categories.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19882v1", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19495", "title": "Simulating Human Behavior with the Psychological-mechanism Agent: Integrating Feeling, Thought, and Action", "authors": ["Qing Dong", "Pengyuan Liu", "Dong Yu", "Chen Kang"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19495v1", "summary": "Generative agents have made significant progress in simulating human\nbehavior, but existing frameworks often simplify emotional modeling and focus\nprimarily on specific tasks, limiting the authenticity of the simulation. Our\nwork proposes the Psychological-mechanism Agent (PSYA) framework, based on the\nCognitive Triangle (Feeling-Thought-Action), designed to more accurately\nsimulate human behavior. The PSYA consists of three core modules: the Feeling\nmodule (using a layer model of affect to simulate changes in short-term,\nmedium-term, and long-term emotions), the Thought module (based on the Triple\nNetwork Model to support goal-directed and spontaneous thinking), and the\nAction module (optimizing agent behavior through the integration of emotions,\nneeds and plans). To evaluate the framework's effectiveness, we conducted daily\nlife simulations and extended the evaluation metrics to self-influence,\none-influence, and group-influence, selection five classic psychological\nexperiments for simulation. The results show that the PSYA framework generates\nmore natural, consistent, diverse, and credible behaviors, successfully\nreplicating human experimental outcomes. Our work provides a richer and more\naccurate emotional and cognitive modeling approach for generative agents and\noffers an alternative to human participants in psychological experiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19495v1", "cate": "cs.HC", "date": "2025-06-04", "updated": "2025-06-04"}
{"id": "2507.20066", "title": "Studying Disinformation Narratives on Social Media with LLMs and Semantic Similarity", "authors": ["Chaytan Inman"], "categories": ["cs.SI", "cs.CY", "cs.ET"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      45 pages, 8 figures, 13 tables", "url": "http://arxiv.org/abs/2507.20066v1", "summary": "This thesis develops a continuous scale measurement of similarity to\ndisinformation narratives that can serve to detect disinformation and capture\nthe nuanced, partial truths that are characteristic of it. To do so, two tools\nare developed and their methodologies are documented. The tracing tool takes\ntweets and a target narrative, rates the similarities of each to the target\nnarrative, and graphs it as a timeline. The second narrative synthesis tool\nclusters tweets above a similarity threshold and generates the dominant\nnarratives within each cluster. These tools are combined into a Tweet Narrative\nAnalysis Dashboard. The tracing tool is validated on the GLUE STS-B benchmark,\nand then the two tools are used to analyze two case studies for further\nempirical validation. The first case study uses the target narrative \"The 2020\nelection was stolen\" and analyzes a dataset of Donald Trump's tweets during\n2020. The second case study uses the target narrative, \"Transgender people are\nharmful to society\" and analyzes tens of thousands of tweets from the media\noutlets The New York Times, The Guardian, The Gateway Pundit, and Fox News.\nTogether, the empirical findings from these case studies demonstrate semantic\nsimilarity for nuanced disinformation detection, tracing, and characterization.\n  The tools developed in this thesis are hosted and can be accessed through the\npermission of the author. Please explain your use case in your request. The\nHTML friendly version of this paper is at\nhttps://chaytanc.github.io/projects/disinfo-research (Inman, 2025).", "comment": "45 pages, 8 figures, 13 tables", "pdf_url": "http://arxiv.org/pdf/2507.20066v1", "cate": "cs.SI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19519", "title": "Physics-informed transfer learning for SHM via feature selection", "authors": ["J. Poole", "P. Gardner", "A. J. Hughes", "N. Dervilis", "R. S. Mills", "T. A. Dardeno", "K. Worden"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19519v1", "summary": "Data used for training structural health monitoring (SHM) systems are\nexpensive and often impractical to obtain, particularly labelled data.\nPopulation-based SHM presents a potential solution to this issue by considering\nthe available data across a population of structures. However, differences\nbetween structures will mean the training and testing distributions will\ndiffer; thus, conventional machine learning methods cannot be expected to\ngeneralise between structures. To address this issue, transfer learning (TL),\ncan be used to leverage information across related domains. An important\nconsideration is that the lack of labels in the target domain limits data-based\nmetrics to quantifying the discrepancy between the marginal distributions.\nThus, a prerequisite for the application of typical unsupervised TL methods is\nto identify suitable source structures (domains), and a set of features, for\nwhich the conditional distributions are related to the target structure.\nGenerally, the selection of domains and features is reliant on domain\nexpertise; however, for complex mechanisms, such as the influence of damage on\nthe dynamic response of a structure, this task is not trivial. In this paper,\nknowledge of physics is leveraged to select more similar features, the modal\nassurance criterion (MAC) is used to quantify the correspondence between the\nmodes of healthy structures. The MAC is shown to have high correspondence with\na supervised metric that measures joint-distribution similarity, which is the\nprimary indicator of whether a classifier will generalise between domains. The\nMAC is proposed as a measure for selecting a set of features that behave\nconsistently across domains when subjected to damage, i.e. features with\ninvariance in the conditional distributions. This approach is demonstrated on\nnumerical and experimental case studies to verify its effectiveness in various\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19519v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.19714", "title": "Refactoring $\\neq$ Bug-Inducing: Improving Defect Prediction with Code Change Tactics Analysis", "authors": ["Feifei Niu", "Junqian Shao", "Christoph Mayr-Dorn", "Liguo Huang", "Wesley K. G. Assunção", "Chuanyi Li", "Jidong Ge", "Alexander Egyed"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19714v1", "summary": "Just-in-time defect prediction (JIT-DP) aims to predict the likelihood of\ncode changes resulting in software defects at an early stage. Although code\nchange metrics and semantic features have enhanced prediction accuracy, prior\nresearch has largely ignored code refactoring during both the evaluation and\nmethodology phases, despite its prevalence. Refactoring and its propagation\noften tangle with bug-fixing and bug-inducing changes within the same commit\nand statement. Neglecting refactoring can introduce bias into the learning and\nevaluation of JIT-DP models. To address this gap, we investigate the impact of\nrefactoring and its propagation on six state-of-the-art JIT-DP approaches. We\npropose Code chAnge Tactics (CAT) analysis to categorize code refactoring and\nits propagation, which improves labeling accuracy in the JIT-Defects4J dataset\nby 13.7%. Our experiments reveal that failing to consider refactoring\ninformation in the dataset can diminish the performance of models, particularly\nsemantic-based models, by 18.6% and 37.3% in F1-score. Additionally, we propose\nintegrating refactoring information to enhance six baseline approaches,\nresulting in overall improvements in recall and F1-score, with increases of up\nto 43.2% and 32.5%, respectively. Our research underscores the importance of\nincorporating refactoring information in the methodology and evaluation of\nJIT-DP. Furthermore, our CAT has broad applicability in analyzing refactoring\nand its propagation for software maintenance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19714v1", "cate": "cs.SE", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19792", "title": "Modelling the Closed Loop Dynamics Between a Social Media Recommender System and Users' Opinions", "authors": ["Ella C. Davidson", "Mengbin Ye"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      27 pages, 15 figures", "url": "http://arxiv.org/abs/2507.19792v1", "summary": "This paper proposes a mathematical model to study the coupled dynamics of a\nRecommender System (RS) algorithm and content consumers (users). The model\nposits that a large population of users, each with an opinion, consumes\npersonalised content recommended by the RS. The RS can select from a range of\ncontent to recommend, based on users' past engagement, while users can engage\nwith the content (like, watch), and in doing so, users' opinions evolve. This\noccurs repeatedly to capture the endless content available for user consumption\non social media. We employ a campaign of Monte Carlo simulations using this\nmodel to study how recommender systems influence users' opinions, and in turn\nhow users' opinions shape the subsequent recommended content. We take an\ninterest in both the performance of the RS (e.g., how users engage with the\ncontent) and the user's opinions, focusing on polarisation and radicalisation\nof opinions. We find that different opinion distributions are more susceptible\nto becoming polarised than others, many content stances are ineffective in\nchanging user opinions, and creating viral content is an effective measure in\ncombating polarisation of opinions.", "comment": "27 pages, 15 figures", "pdf_url": "http://arxiv.org/pdf/2507.19792v1", "cate": "cs.SI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.10578", "title": "When and Where do Data Poisons Attack Textual Inversion?", "authors": ["Jeremy Styborski", "Mingzhi Lyu", "Jiayou Lu", "Nupur Kapur", "Adams Kong"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.10578v3", "summary": "Poisoning attacks pose significant challenges to the robustness of diffusion\nmodels (DMs). In this paper, we systematically analyze when and where poisoning\nattacks textual inversion (TI), a widely used personalization technique for\nDMs. We first introduce Semantic Sensitivity Maps, a novel method for\nvisualizing the influence of poisoning on text embeddings. Second, we identify\nand experimentally verify that DMs exhibit non-uniform learning behavior across\ntimesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias\nand inject adversarial signals predominantly at lower timesteps. Lastly, we\nobserve that adversarial signals distract learning away from relevant concept\nregions within training data, corrupting the TI process. Based on these\ninsights, we propose Safe-Zone Training (SZT), a novel defense mechanism\ncomprised of 3 key components: (1) JPEG compression to weaken high-frequency\npoison signals, (2) restriction to high timesteps during TI training to avoid\nadversarial signals at lower timesteps, and (3) loss masking to constrain\nlearning to relevant regions. Extensive experiments across multiple poisoning\nmethods demonstrate that SZT greatly enhances the robustness of TI against all\npoisoning attacks, improving generative quality beyond prior published\ndefenses. Code: www.github.com/JStyborski/Diff_Lab Data:\nwww.github.com/JStyborski/NC10", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.10578v3", "cate": "cs.CR", "date": "2025-07-11", "updated": "2025-07-28"}
{"id": "2507.20021", "title": "When Engineering Outruns Intelligence: A Re-evaluation of Instruction-Guided Navigation", "authors": ["Matin Aghaei", "Mohammad Ali Alomrani", "Yingxue Zhang", "Mahdi Biparva"], "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20021v1", "summary": "Large language models (LLMs) are often credited with recent leaps in\nObjectGoal Navigation, yet the extent to which they improve planning remains\nunclear. We revisit this question on the HM3D-v1 validation split. First, we\nstrip InstructNav of its Dynamic Chain-of-Navigation prompt, open-vocabulary\nGLEE detector and Intuition saliency map, and replace them with a simple\nDistance-Weighted Frontier Explorer (DWFE). This geometry-only heuristic raises\nSuccess from 58.0% to 61.1% and lifts SPL from 20.9% to 36.0% over 2 000\nvalidation episodes, outperforming all previous training-free baselines.\nSecond, we add a lightweight language prior (SHF); on a 200-episode subset this\nyields a further +2% Success and +0.9% SPL while shortening paths by five steps\non average. Qualitative trajectories confirm the trend: InstructNav back-tracks\nand times-out, DWFE reaches the goal after a few islands, and SHF follows an\nalmost straight route. Our results indicate that frontier geometry, not\nemergent LLM reasoning, drives most reported gains, and suggest that\nmetric-aware prompts or offline semantic graphs are necessary before\nattributing navigation success to \"LLM intelligence.\"", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20021v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19960", "title": "What Does 'Human-Centred AI' Mean?", "authors": ["Olivia Guest"], "categories": ["cs.AI", "I.2.0; K.2; K.4.0"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19960v2", "summary": "While it seems sensible that human-centred artificial intelligence (AI) means\ncentring \"human behaviour and experience,\" it cannot be any other way. AI, I\nargue, is usefully seen as a relationship between technology and humans where\nit appears that artifacts can perform, to a greater or lesser extent, human\ncognitive labour. This is evinced using examples that juxtapose technology with\ncognition, inter alia: abacus versus mental arithmetic; alarm clock versus\nknocker-upper; camera versus vision; and sweatshop versus tailor. Using novel\ndefinitions and analyses, sociotechnical relationships can be analysed into\nvarying types of: displacement (harmful), enhancement (beneficial), and/or\nreplacement (neutral) of human cognitive labour. Ultimately, all AI implicates\nhuman cognition; no matter what. Obfuscation of cognition in the AI context --\nfrom clocks to artificial neural networks -- results in distortion, in slowing\ncritical engagement, perverting cognitive science, and indeed in limiting our\nability to truly centre humans and humanity in the engineering of AI systems.\nTo even begin to de-fetishise AI, we must look the human-in-the-loop in the\neyes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19960v2", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-29"}
{"id": "2507.19496", "title": "Technological Requirements for Videoconferencing Judicial Hearings: Enhancing the Credibility and Reliability of Remote Testimonies", "authors": ["Jorge Alberto Araujo"], "categories": ["cs.HC", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19496v1", "summary": "This paper analyzes the technological requirements necessary to enhance the\ncredibility and reliability of judicial hearings conducted via videoconference,\nfrom the internal perspective of the judiciary. Drawing on the practical\nexperience of a judge who conducts daily hearings, this study identifies\nlimitations in current platforms for verifying the authenticity of testimonies\nand proposes tailored functionalities for the judicial context. Recognizing\nthat remote hearings represent a convenience for the parties without replacing\nthe option of in-person attendance, the article suggests implementing features\nsuch as eye tracking, environment verification, and blocking of parallel\napplications, in addition to improvements in transmission quality. The study\nconcludes that developing specific modules for witnesses - focusing on security\nand monitoring - can significantly contribute to equalizing the credibility\nbetween remote and in-person hearings, thus expanding access to justice without\ncompromising procedural reliability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19496v1", "cate": "cs.HC", "date": "2025-06-04", "updated": "2025-06-04"}
{"id": "2507.20234", "title": "Democracy for DAOs: An Empirical Study of Decentralized Governance and Dynamic (Case Study Internet Computer SNS Ecosystem)", "authors": ["Burak Arda Okutan", "Stefan Schmid", "Yvonne-Anne Pignolet"], "categories": ["cs.NI", "cs.ET", "cs.SI", "C.2.4"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      This paper is an extended version of the work presented at the IEEE International Conference on Blockchain and Cryptocurrency (ICBC) 2025", "url": "http://arxiv.org/abs/2507.20234v1", "summary": "Decentralized autonomous organizations (DAOs) rely on governance mechanism\nwithout centralized leadership. This paper presents an empirical study of user\nbehavior in governance for a variety of DAOs, ranging from DeFi to gaming,\nusing the Internet Computer Protocol DAO framework called SNS (Service Nervous\nSystem). To analyse user engagement, we measure participation rates and\nfrequency of proposals submission and voter approval rates. We evaluate\ndecision duration times to determine DAO agility. To investigate dynamic\naspects, we also measure metric shifts in time. We evaluate over 3,000\nproposals submitted in a time frame of 20 months from 14 SNS DAOs. The selected\nDAO have been existing between 6 and 20 months and cover a wide spectrum of use\ncases, treasury sizes, and number of participants. We also compare our results\nfor SNS DAOs with DAOs from other blockchain platforms. While approval rates\nare generally high for all DAOs studied, SNS DAOs show slightly more alignment.\nWe observe that the SNS governance mechanisms and processes in ICP lead to\nhigher activity, lower costs and faster decisions. Most importantly, in\ncontrast to studies which report a decline in participation over time for other\nframeworks, SNS DAOs exhibit sustained or increasing engagement levels over\ntime.", "comment": "This paper is an extended version of the work presented at the IEEE\n  International Conference on Blockchain and Cryptocurrency (ICBC) 2025", "pdf_url": "http://arxiv.org/pdf/2507.20234v1", "cate": "cs.NI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19520", "title": "Exoplanet Detection Using Machine Learning Models Trained on Synthetic Light Curves", "authors": ["Ethan Lo", "Dan C. Lo"], "categories": ["cs.LG", "astro-ph.EP", "astro-ph.IM", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19520v1", "summary": "With manual searching processes, the rate at which scientists and astronomers\ndiscover exoplanets is slow because of inefficiencies that require an extensive\ntime of laborious inspections. In fact, as of now there have been about only\n5,000 confirmed exoplanets since the late 1900s. Recently, machine learning\n(ML) has proven to be extremely valuable and efficient in various fields,\ncapable of processing massive amounts of data in addition to increasing its\naccuracy by learning. Though ML models for discovering exoplanets owned by\nlarge corporations (e.g. NASA) exist already, they largely depend on complex\nalgorithms and supercomputers. In an effort to reduce such complexities, in\nthis paper, we report the results and potential benefits of various, well-known\nML models in the discovery and validation of extrasolar planets. The ML models\nthat are examined in this study include logistic regression, k-nearest\nneighbors, and random forest. The dataset on which the models train and predict\nis acquired from NASA's Kepler space telescope. The initial results show\npromising scores for each model. However, potential biases and dataset\nimbalances necessitate the use of data augmentation techniques to further\nensure fairer predictions and improved generalization. This study concludes\nthat, in the context of searching for exoplanets, data augmentation techniques\nsignificantly improve the recall and precision, while the accuracy varies for\neach model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19520v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.19721", "title": "Clean Code In Practice: Challenges and Opportunities", "authors": ["Dapeng Yan", "Wenjie Yang", "Kui Liu", "Zhiming Liu", "Zhikuang Cai"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19721v1", "summary": "Reliability prediction is crucial for ensuring the safety and security of\nsoftware systems, especially in the context of industry practices. While\nvarious metrics and measurements are employed to assess software reliability,\nthe complexity of modern systems necessitates a deeper understanding of how\nthese metrics interact with security and safety concerns. This paper explores\nthe interplay between software reliability, safety, and security, offering a\ncomprehensive analysis of key metrics and measurement techniques used in the\nindustry for reliability prediction. We identify critical threats to software\nreliability and provide a threat estimation framework that incorporates both\nsafety and security aspects. Our findings suggest that integrating reliability\nmetrics with safety and security considerations can enhance the robustness of\nsoftware systems. Furthermore, we propose a set of actionable guidelines for\npractitioners to improve their reliability prediction models while\nsimultaneously addressing the security and safety challenges of contemporary\nsoftware applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19721v1", "cate": "cs.SE", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20265", "title": "A Blockchain-Based Quality Control Model for Online Collaboration Systems", "authors": ["Sadegh Sohani", "Maliheh Shahryari", "Salar Ghazi", "Mohammad Allahbakhsh", "Haleh Amintoosi", "Boualem Benatallah"], "categories": ["cs.SI", "H.3.1; H.3.5"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      26 pages (Springer format), 9 figures, 1 table", "url": "http://arxiv.org/abs/2507.20265v1", "summary": "Collaborative content generation (CCG) enables collective creation of\nartifacts like scientific articles. Quality is a paramount concern in CCG, and\na multitude of methods have been proposed to evaluate the quality of artifacts.\nNevertheless, the majority of these methods are reliant on centralized\narchitectures, which present challenges pertaining to security, privacy, and\navailability. Blockchain technology proffers a potential resolution to these\nchallenges, by furnishing a decentralized and immutable ledger of quality\nscores. In this manuscript, we introduce a blockchain-based quality control\nmodel for CCG that uses a semi-iterative algorithm to interdependently compute\nquality scores of artifacts and reputation of nodes. Our model addresses\ncritical challenges in academic informetrics, such as citation manipulation,\ntransparency in collaborative scholarship, and decentralized trust in metric\ncomputation. Our model also exhibits sensitivity to processing latency,\nrendering it more agile in the presence of delays. Our model's quality scores,\nevaluated against PageRank and HITS baselines, show comparable performance,\nwith additional assessments of throughput, latency, and robustness against\nmalicious nodes confirming its reliability. A theoretical comparison with\nrecent studies validates its feasibility for real world informetric\napplication.", "comment": "26 pages (Springer format), 9 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.20265v1", "cate": "cs.SI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.10808", "title": "Contrastive-KAN: A Semi-Supervised Intrusion Detection Framework for Cybersecurity with scarce Labeled Data", "authors": ["Mohammad Alikhani", "Reza Kazemi"], "categories": ["cs.CR", "cs.SY", "eess.SP", "eess.SY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10808v2", "summary": "In the era of the Fourth Industrial Revolution, cybersecurity and intrusion\ndetection systems are vital for the secure and reliable operation of IoT and\nIIoT environments. A key challenge in this domain is the scarcity of labeled\ncyberattack data, as most industrial systems operate under normal conditions.\nThis data imbalance, combined with the high cost of annotation, hinders the\neffective training of machine learning models. Moreover, the rapid detection of\nattacks is essential, especially in critical infrastructure, to prevent\nlarge-scale disruptions. To address these challenges, we propose a real-time\nintrusion detection system based on a semi-supervised contrastive learning\nframework using the Kolmogorov-Arnold Network (KAN). Our method leverages\nabundant unlabeled data to effectively distinguish between normal and attack\nbehaviors. We validate our approach on three benchmark datasets, UNSW-NB15,\nBoT-IoT, and Gas Pipeline, using only 2.20\\%, 1.28\\%, and 8\\% of labeled\nsamples, respectively, to simulate real-world conditions. Experimental results\nshow that our method outperforms existing contrastive learning-based\napproaches. We further compare KAN with a traditional multilayer perceptron\n(MLP), demonstrating KAN's superior performance in both detection accuracy and\nrobustness under limited supervision. KAN's ability to model complex\nrelationships, along with its learnable activation functions, is also explored\nand visualized, offering interpretability and the potential for rule\nextraction. The method supports multi-class classification and proves effective\nin safety, critical environments where reliability is paramount.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10808v2", "cate": "cs.CR", "date": "2025-07-14", "updated": "2025-07-27"}
{"id": "2507.20034", "title": "Digital and Robotic Twinning for Validation of Proximity Operations and Formation Flying", "authors": ["Aviad Golan", "Gregory Zin", "Zahra Ahmed", "Emily Bates", "Toby Bell", "Pol Francesch Huc", "Samuel Y. W. Low", "Juergen Bosse", "Simone D'Amico"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      23 pages, 12 figures. 2025 Astrodynamics Specialist Conference", "url": "http://arxiv.org/abs/2507.20034v1", "summary": "In spacecraft Rendezvous, Proximity Operations (RPO), and Formation Flying\n(FF), the Guidance Navigation and Control (GNC) system is safety-critical and\nmust meet strict performance requirements. However, validating such systems is\nchallenging due to the complexity of the space environment, necessitating a\nverification and validation (V&V) process that bridges simulation and\nreal-world behavior. The key contribution of this paper is a unified,\nend-to-end digital and robotic twinning framework that enables software- and\nhardware-in-the-loop testing for multi-modal GNC systems. The robotic twin\nincludes three testbeds at Stanford's Space Rendezvous Laboratory (SLAB): the\nGNSS and Radiofrequency Autonomous Navigation Testbed for Distributed Space\nSystems (GRAND) to validate RF-based navigation techniques, and the Testbed for\nRendezvous and Optical Navigation (TRON) and Optical Stimulator (OS) to\nvalidate vision-based methods. The test article for this work is an integrated\nmulti-modal GNC software stack for RPO and FF developed at SLAB. This paper\nintroduces the hybrid framework and summarizes calibration and error\ncharacterization for the robotic twin. Then, the GNC stack's performance and\nrobustness is characterized using the integrated digital and robotic twinning\npipeline for a full-range RPO mission scenario in Low-Earth Orbit (LEO). The\nresults shown in the paper demonstrate consistency between digital and robotic\ntwins, validating the hybrid twinning pipeline as a reliable framework for\nrealistic assessment and verification of GNC systems.", "comment": "23 pages, 12 figures. 2025 Astrodynamics Specialist Conference", "pdf_url": "http://arxiv.org/pdf/2507.20034v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19973", "title": "Leveraging Fine-Tuned Large Language Models for Interpretable Pancreatic Cystic Lesion Feature Extraction and Risk Categorization", "authors": ["Ebrahim Rasromani", "Stella K. Kang", "Yanqi Xu", "Beisong Liu", "Garvit Luhadia", "Wan Fung Chui", "Felicia L. Pasadyn", "Yu Chih Hung", "Julie Y. An", "Edwin Mathieu", "Zehui Gu", "Carlos Fernandez-Granda", "Ammar A. Javed", "Greg D. Sacks", "Tamas Gonda", "Chenchan Huang", "Yiqiu Shen"], "categories": ["cs.AI", "cs.CL", "cs.IR"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19973v1", "summary": "Background: Manual extraction of pancreatic cystic lesion (PCL) features from\nradiology reports is labor-intensive, limiting large-scale studies needed to\nadvance PCL research. Purpose: To develop and evaluate large language models\n(LLMs) that automatically extract PCL features from MRI/CT reports and assign\nrisk categories based on guidelines. Materials and Methods: We curated a\ntraining dataset of 6,000 abdominal MRI/CT reports (2005-2024) from 5,134\npatients that described PCLs. Labels were generated by GPT-4o using\nchain-of-thought (CoT) prompting to extract PCL and main pancreatic duct\nfeatures. Two open-source LLMs were fine-tuned using QLoRA on GPT-4o-generated\nCoT data. Features were mapped to risk categories per institutional guideline\nbased on the 2017 ACR White Paper. Evaluation was performed on 285 held-out\nhuman-annotated reports. Model outputs for 100 cases were independently\nreviewed by three radiologists. Feature extraction was evaluated using exact\nmatch accuracy, risk categorization with macro-averaged F1 score, and\nradiologist-model agreement with Fleiss' Kappa. Results: CoT fine-tuning\nimproved feature extraction accuracy for LLaMA (80% to 97%) and DeepSeek (79%\nto 98%), matching GPT-4o (97%). Risk categorization F1 scores also improved\n(LLaMA: 0.95; DeepSeek: 0.94), closely matching GPT-4o (0.97), with no\nstatistically significant differences. Radiologist inter-reader agreement was\nhigh (Fleiss' Kappa = 0.888) and showed no statistically significant difference\nwith the addition of DeepSeek-FT-CoT (Fleiss' Kappa = 0.893) or GPT-CoT\n(Fleiss' Kappa = 0.897), indicating that both models achieved agreement levels\non par with radiologists. Conclusion: Fine-tuned open-source LLMs with CoT\nsupervision enable accurate, interpretable, and efficient phenotyping for\nlarge-scale PCL research, achieving performance comparable to GPT-4o.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19973v1", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19497", "title": "Unlimited Editions: Documenting Human Style in AI Art Generation", "authors": ["Alex Leitch", "Celia Chen"], "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.IR"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:       this http URL 2025", "url": "http://arxiv.org/abs/2507.19497v1", "summary": "As AI art generation becomes increasingly sophisticated, HCI research has\nfocused primarily on questions of detection, authenticity, and automation. This\npaper argues that such approaches fundamentally misunderstand how artistic\nvalue emerges from the concerns that drive human image production. Through\nexamination of historical precedents, we demonstrate that artistic style is not\nonly visual appearance but the resolution of creative struggle, as artists\nwrestle with influence and technical constraints to develop unique ways of\nseeing. Current AI systems flatten these human choices into reproducible\npatterns without preserving their provenance. We propose that HCI's role lies\nnot only in perfecting visual output, but in developing means to document the\norigins and evolution of artistic style as it appears within generated visual\ntraces. This reframing suggests new technical directions for HCI research in\ngenerative AI, focused on automatic documentation of stylistic lineage and\ncreative choice rather than simple reproduction of aesthetic effects.", "comment": "alt.CHI 2025", "pdf_url": "http://arxiv.org/pdf/2507.19497v1", "cate": "cs.HC", "date": "2025-06-05", "updated": "2025-06-05"}
{"id": "2507.20699", "title": "Curved Apertures for Customized Wave Trajectories: Beyond Flat Aperture Limitations", "authors": ["Joan Martínez Canals", "Francesco Devoti", "Vincenzo Sciancalepore", "Marco Di Renzo", "Xavier Costa-Pérez"], "categories": ["physics.optics", "cs.ET", "cs.NI"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20699v1", "summary": "Beam shaping techniques enable tailored beam trajectories, offering\nunprecedented connectivity opportunities in wireless communications. Current\napproaches rely on flat apertures, which limit trajectory flexibility due to\ninherent geometric constraints. To overcome such restrictions, we propose\nadopting curved apertures as a more versatile alternative for beam shaping. We\nintroduce a novel formulation for wave trajectory engineering compatible with\narbitrarily shaped apertures. Theoretical and numerical analyses demonstrate\nthat curved apertures offer improved control over wave propagation, are more\nresilient to phase control constraints, and achieve higher power density across\na wider portion of the desired beam trajectory than flat apertures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20699v1", "cate": "physics.optics", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19522", "title": "Applications and Manipulations of Physics-Informed Neural Networks in Solving Differential Equations", "authors": ["Aarush Gupta", "Kendric Hsu", "Syna Mathod"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19522v1", "summary": "Mathematical models in neural networks are powerful tools for solving complex\ndifferential equations and optimizing their parameters; that is, solving the\nforward and inverse problems, respectively. A forward problem predicts the\noutput of a network for a given input by optimizing weights and biases. An\ninverse problem finds equation parameters or coefficients that effectively\nmodel the data. A Physics-Informed Neural Network (PINN) can solve both\nproblems. PINNs inject prior analytical information about the data into the\ncost function to improve model performance outside the training set boundaries.\nThis also allows PINNs to efficiently solve problems with sparse data without\noverfitting by extrapolating the model to fit larger trends in the data. The\nprior information we implement is in the form of differential equations.\nResiduals are the differences between the left-hand and right-hand sides of\ncorresponding differential equations; PINNs minimize these residuals to\neffectively solve the differential equation and take advantage of prior\nknowledge. In this way, the solution and parameters are embedded into the loss\nfunction and optimized, allowing both the weights of the neural network and the\nmodel parameters to be found simultaneously, solving both the forward and\ninverse problems in the process. In this paper, we will create PINNs with\nresiduals of varying complexity, beginning with linear and quadratic models and\nthen expanding to fit models for the heat equation and other complex\ndifferential equations. We will mainly use Python as the computing language,\nusing the PyTorch library to aid us in our research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19522v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.19743", "title": "Defining ethically sourced code generation", "authors": ["Zhuolin Xu", "Chenglin Li", "Qiushi Li", "Shin Hwei Tan"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19743v1", "summary": "Several code generation models have been proposed to help reduce time and\neffort in solving software-related tasks. To ensure responsible AI, there are\ngrowing interests over various ethical issues (e.g., unclear licensing,\nprivacy, fairness, and environment impact). These studies have the overarching\ngoal of ensuring ethically sourced generation, which has gained growing\nattentions in speech synthesis and image generation. In this paper, we\nintroduce the novel notion of Ethically Sourced Code Generation (ES-CodeGen) to\nrefer to managing all processes involved in code generation model development\nfrom data collection to post-deployment via ethical and sustainable practices.\nTo build a taxonomy of ES-CodeGen, we perform a two-phase literature review\nwhere we read 803 papers across various domains and specific to AI-based code\ngeneration. We identified 71 relevant papers with 10 initial dimensions of\nES-CodeGen. To refine our dimensions and gain insights on consequences of\nES-CodeGen, we surveyed 32 practitioners, which include six developers who\nsubmitted GitHub issues to opt-out from the Stack dataset (these impacted users\nhave real-world experience of ethically sourcing issues in code generation\nmodels). The results lead to 11 dimensions of ES-CodeGen with a new dimension\non code quality as practitioners have noted its importance. We also identified\nconsequences, artifacts, and stages relevant to ES-CodeGen. Our post-survey\nreflection showed that most practitioners tend to ignore social-related\ndimensions despite their importance. Most practitioners either agreed or\nstrongly agreed that our survey help improve their understanding of ES-CodeGen.\nOur study calls for attentions of various ethical issues towards ES-CodeGen.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19743v1", "cate": "cs.SE", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20682", "title": "Structural-Aware Key Node Identification in Hypergraphs via Representation Learning and Fine-Tuning", "authors": ["Xiaonan Ni", "Guangyuan Mei", "Su-Su Zhang", "Yang Chen", "Xin Xu", "Chuang Liu", "Xiu-Xiu Zhan"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20682v1", "summary": "Evaluating node importance is a critical aspect of analyzing complex systems,\nwith broad applications in digital marketing, rumor suppression, and disease\ncontrol. However, existing methods typically rely on conventional network\nstructures and fail to capture the polyadic interactions intrinsic to many\nreal-world systems. To address this limitation, we study key node\nidentification in hypergraphs, where higher-order interactions are naturally\nmodeled as hyperedges. We propose a novel framework, AHGA, which integrates an\nAutoencoder for extracting higher-order structural features, a HyperGraph\nneural network-based pre-training module (HGNN), and an Active learning-based\nfine-tuning process. This fine-tuning step plays a vital role in mitigating the\ngap between synthetic and real-world data, thereby enhancing the model's\nrobustness and generalization across diverse hypergraph topologies. Extensive\nexperiments on eight empirical hypergraphs show that AHGA outperforms classical\ncentrality-based baselines by approximately 37.4%. Furthermore, the nodes\nidentified by AHGA exhibit both high influence and strong structural disruption\ncapability, demonstrating their superiority in detecting multifunctional nodes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20682v1", "cate": "cs.SI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.14600", "title": "A Hybrid Classical-Quantum Rainbow Table Attack on Human Passwords", "authors": ["MA. Khajeian"], "categories": ["cs.CR", "quant-ph"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14600v2", "summary": "Long, human-generated passwords pose significant challenges to both classical\nand quantum attacks due to their irregular structure and large search space. In\nthis work, we propose an enhanced classical-quantum hybrid attack specifically\ndesigned for this scenario. Our approach constructs rainbow tables using\ndictionary-based password generation augmented with transformation rules that\nbetter capture real-world user behavior. These tables are organized into\nbuckets, enabling faster lookup and reduced space complexity. For the search\nwithin each bucket, we employ a distributed exact variant of Grover's\nalgorithm. This method provides deterministic success and significantly lower\ncircuit depth, enhancing robustness against noise-particularly depolarizing\nerrors common in near-term quantum devices. Overall, our hybrid framework\nimproves the efficiency and practicality of password recovery for long,\nhuman-readable passwords in realistic adversarial settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14600v2", "cate": "cs.CR", "date": "2025-07-19", "updated": "2025-07-28"}
{"id": "2507.20049", "title": "A real-time full-chain wearable sensor-based musculoskeletal simulation: an OpenSim-ROS Integration", "authors": ["Frederico Belmonte Klein", "Zhaoyuan Wan", "Huawei Wang", "Ruoli Wang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      11 pages, 10 figures", "url": "http://arxiv.org/abs/2507.20049v1", "summary": "Musculoskeletal modeling and simulations enable the accurate description and\nanalysis of the movement of biological systems with applications such as\nrehabilitation assessment, prosthesis, and exoskeleton design. However, the\nwidespread usage of these techniques is limited by costly sensors,\nlaboratory-based setups, computationally demanding processes, and the use of\ndiverse software tools that often lack seamless integration. In this work, we\naddress these limitations by proposing an integrated, real-time framework for\nmusculoskeletal modeling and simulations that leverages OpenSimRT, the robotics\noperating system (ROS), and wearable sensors. As a proof-of-concept, we\ndemonstrate that this framework can reasonably well describe inverse kinematics\nof both lower and upper body using either inertial measurement units or\nfiducial markers. Additionally, we show that it can effectively estimate\ninverse dynamics of the ankle joint and muscle activations of major lower limb\nmuscles during daily activities, including walking, squatting and sit to stand,\nstand to sit when combined with pressure insoles. We believe this work lays the\ngroundwork for further studies with more complex real-time and wearable\nsensor-based human movement analysis systems and holds potential to advance\ntechnologies in rehabilitation, robotics and exoskeleton designs.", "comment": "11 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.20049v1", "cate": "cs.RO", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19974", "title": "Digital Twin Channel-Enabled Online Resource Allocation for 6G: Principle, Architecture and Application", "authors": ["Tongjie Li", "Jianhua Zhang", "Li Yu", "Yuxiang Zhang", "Yunlong Cai", "Fan Xu", "Guangyi Liu"], "categories": ["cs.AI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19974v1", "summary": "Emerging applications such as holographic communication, autonomous driving,\nand the industrial Internet of Things impose stringent requirements on\nflexible, low-latency, and reliable resource allocation in 6G networks.\nConventional methods, which rely on statistical modeling, have proven effective\nin general contexts but may fail to achieve optimal performance in specific and\ndynamic environments. Furthermore, acquiring real-time channel state\ninformation (CSI) typically requires excessive pilot overhead. To address these\nchallenges, a digital twin channel (DTC)-enabled online optimization framework\nis proposed, in which DTC is employed to predict CSI based on environmental\nsensing. The predicted CSI is then utilized by lightweight game-theoretic\nalgorithms to perform online resource allocation in a timely and efficient\nmanner. Simulation results based on a digital replica of a realistic industrial\nworkshop demonstrate that the proposed method achieves throughput improvements\nof up to 11.5\\% compared with pilot-based ideal CSI schemes, validating its\neffectiveness for scalable, low-overhead, and environment-aware communication\nin future 6G networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19974v1", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19498", "title": "ChatMyopia: An AI Agent for Pre-consultation Education in Primary Eye Care Settings", "authors": ["Yue Wu", "Xiaolan Chen", "Weiyi Zhang", "Shunming Liu", "Wing Man Rita Sum", "Xinyuan Wu", "Xianwen Shang", "Chea-su Kee", "Mingguang He", "Danli Shi"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      35 pages, 4 figures, 1 table", "url": "http://arxiv.org/abs/2507.19498v1", "summary": "Large language models (LLMs) show promise for tailored healthcare\ncommunication but face challenges in interpretability and multi-task\nintegration particularly for domain-specific needs like myopia, and their\nreal-world effectiveness as patient education tools has yet to be demonstrated.\nHere, we introduce ChatMyopia, an LLM-based AI agent designed to address text\nand image-based inquiries related to myopia. To achieve this, ChatMyopia\nintegrates an image classification tool and a retrieval-augmented knowledge\nbase built from literature, expert consensus, and clinical guidelines. Myopic\nmaculopathy grading task, single question examination and human evaluations\nvalidated its ability to deliver personalized, accurate, and safe responses to\nmyopia-related inquiries with high scalability and interpretability. In a\nrandomized controlled trial (n=70, NCT06607822), ChatMyopia significantly\nimproved patient satisfaction compared to traditional leaflets, enhancing\npatient education in accuracy, empathy, disease awareness, and patient-eyecare\npractitioner communication. These findings highlight ChatMyopia's potential as\na valuable supplement to enhance patient education and improve satisfaction\nwith medical services in primary eye care settings.", "comment": "35 pages, 4 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.19498v1", "cate": "cs.HC", "date": "2025-06-06", "updated": "2025-06-06"}
{"id": "2411.00110", "title": "Lagrangian neural networks for nonholonomic mechanics", "authors": ["Viviana Alejandra Diaz", "Leandro Martin Salomone", "Marcela Zuccalli"], "categories": ["cs.LG", "cond-mat.dis-nn", "cs.ET", "cs.NE", "70F25, 68T07, 70H03", "J.2.0; I.2.6; C.2.0"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.00110v2", "summary": "Lagrangian Neural Networks (LNNs) are a powerful tool for addressing physical\nsystems, particularly those governed by conservation laws. LNNs can parametrize\nthe Lagrangian of a system to predict trajectories with nearly conserved\nenergy. These techniques have proven effective in unconstrained systems as well\nas those with holonomic constraints. In this work, we adapt LNN techniques to\nmechanical systems with nonholonomic constraints. We test our approach on some\nwell-known examples with nonholonomic constraints, showing that incorporating\nthese restrictions into the neural network's learning improves not only\ntrajectory estimation accuracy but also ensures adherence to constraints and\nexhibits better energy behavior compared to the unconstrained counterpart.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.00110v2", "cate": "cs.LG", "date": "2024-10-31", "updated": "2025-07-27"}
{"id": "2507.19523", "title": "Language Models for Controllable DNA Sequence Design", "authors": ["Xingyu Su", "Xiner Li", "Yuchao Lin", "Ziqian Xie", "Degui Zhi", "Shuiwang Ji"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19523v1", "summary": "We consider controllable DNA sequence design, where sequences are generated\nby conditioning on specific biological properties. While language models (LMs)\nsuch as GPT and BERT have achieved remarkable success in natural language\ngeneration, their application to DNA sequence generation remains largely\nunderexplored. In this work, we introduce ATGC-Gen, an Automated Transformer\nGenerator for Controllable Generation, which leverages cross-modal encoding to\nintegrate diverse biological signals. ATGC-Gen is instantiated with both\ndecoder-only and encoder-only transformer architectures, allowing flexible\ntraining and generation under either autoregressive or masked recovery\nobjectives. We evaluate ATGC-Gen on representative tasks including promoter and\nenhancer sequence design, and further introduce a new dataset based on ChIP-Seq\nexperiments for modeling protein binding specificity. Our experiments\ndemonstrate that ATGC-Gen can generate fluent, diverse, and biologically\nrelevant sequences aligned with the desired properties. Compared to prior\nmethods, our model achieves notable improvements in controllability and\nfunctional relevance, highlighting the potential of language models in\nadvancing programmable genomic design. The source code is released at\n(https://github.com/divelab/AIRS/blob/main/OpenBio/ATGC_Gen).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19523v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.19806", "title": "From Few-Label to Zero-Label: An Approach for Cross-System Log-Based Anomaly Detection with Meta-Learning", "authors": ["Xinlong Zhao", "Tong Jia", "Minghua He", "Yihan Wu", "Ying Li", "Gang Huang"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      5 pages, 1 figures, FSE 2025", "url": "http://arxiv.org/abs/2507.19806v1", "summary": "Log anomaly detection plays a critical role in ensuring the stability and\nreliability of software systems. However, existing approaches rely on large\namounts of labeled log data, which poses significant challenges in real-world\napplications. To address this issue, cross-system transfer has been identified\nas a key research direction. State-of-the-art cross-system approaches achieve\npromising performance with only a few labels from the target system. However,\ntheir reliance on labeled target logs makes them susceptible to the cold-start\nproblem when labeled logs are insufficient. To overcome this limitation, we\nexplore a novel yet underexplored setting: zero-label cross-system log anomaly\ndetection, where the target system logs are entirely unlabeled. To this end, we\npropose FreeLog, a system-agnostic representation meta-learning method that\neliminates the need for labeled target system logs, enabling cross-system log\nanomaly detection under zero-label conditions. Experimental results on three\npublic log datasets demonstrate that FreeLog achieves performance comparable to\nstate-of-the-art methods that rely on a small amount of labeled data from the\ntarget system.", "comment": "5 pages, 1 figures, FSE 2025", "pdf_url": "http://arxiv.org/pdf/2507.19806v1", "cate": "cs.SE", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19692", "title": "FlashGuard: Novel Method in Evaluating Differential Characteristics of Visual Stimuli for Deterring Seizure Triggers in Photosensitive Epilepsy", "authors": ["Ishan Pendyala"], "categories": ["cs.CY", "cs.HC", "cs.SI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19692v1", "summary": "In the virtual realm, individuals with photosensitive epilepsy (PSE)\nencounter challenges when using devices, resulting in exposure to unpredictable\nseizure-causing visual stimuli. The current norm for preventing epileptic\nflashes in media is to detect asynchronously when a flash will occur in a\nvideo, then notifying the user. However, there is a lack of a real-time and\ncomputationally efficient solution for dealing with this issue. To address this\nissue and enhance accessibility for photosensitive viewers, FlashGuard, a novel\napproach, was devised to assess the rate of change of colors in frames across\nthe user's screen and appropriately mitigate stimuli, based on perceptually\naligned color space analysis in the CIELAB color space. The detection system is\nbuilt on analyzing differences in color, and the mitigation system works by\nreducing luminance and smoothing color transitions. This study provides novel\ninsight into how intrinsic color properties contribute to perceptual\ndifferences in flashing for PSE individuals, calling for the adoption of\nbroadened WCAG guidelines to better account for risk. These insights and\nimplementations pave the way for stronger protections for individuals with PSE\nfrom dangerous triggers in digital media, both in policy and in software.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19692v1", "cate": "cs.CY", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19653", "title": "On the Limitations of Ray-Tracing for Learning-Based RF Tasks in Urban Environments", "authors": ["Armen Manukyan", "Hrant Khachatrian", "Edvard Ghukasyan", "Theofanis P. Raptis"], "categories": ["cs.NI", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication. This work was supported by funding under the bilateral agreement between CNR (Italy) and HESC MESCS RA (Armenia) as part of the DeepRF project for the 2025-2026 biennium, and by the HESC MESCS RA grant No. 22rl-052 (DISTAL)", "url": "http://arxiv.org/abs/2507.19653v1", "summary": "We study the realism of Sionna v1.0.2 ray-tracing for outdoor cellular links\nin central Rome. We use a real measurement set of 1,664 user-equipments (UEs)\nand six nominal base-station (BS) sites. Using these fixed positions we\nsystematically vary the main simulation parameters, including path depth,\ndiffuse/specular/refraction flags, carrier frequency, as well as antenna's\nproperties like its altitude, radiation pattern, and orientation. Simulator\nfidelity is scored for each base station via Spearman correlation between\nmeasured and simulated powers, and by a fingerprint-based k-nearest-neighbor\nlocalization algorithm using RSSI-based fingerprints. Across all experiments,\nsolver hyper-parameters are having immaterial effect on the chosen metrics. On\nthe contrary, antenna locations and orientations prove decisive. By simple\ngreedy optimization we improve the Spearman correlation by 5% to 130% for\nvarious base stations, while kNN-based localization error using only simulated\ndata as reference points is decreased by one-third on real-world samples, while\nstaying twice higher than the error with purely real data. Precise geometry and\ncredible antenna models are therefore necessary but not sufficient; faithfully\ncapturing the residual urban noise remains an open challenge for transferable,\nhigh-fidelity outdoor RF simulation.", "comment": "This work has been submitted to the IEEE for possible publication.\n  This work was supported by funding under the bilateral agreement between CNR\n  (Italy) and HESC MESCS RA (Armenia) as part of the DeepRF project for the\n  2025-2026 biennium, and by the HESC MESCS RA grant No. 22rl-052 (DISTAL)", "pdf_url": "http://arxiv.org/pdf/2507.19653v1", "cate": "cs.NI", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.17491", "title": "Active Attack Resilience in 5G: A New Take on Authentication and Key Agreement", "authors": ["Nazatul H. Sultan", "Xinlong Guan", "Josef Pieprzyk", "Wei Ni", "Sharif Abuadbba", "Hajime Suzuki"], "categories": ["cs.CR", "cs.NI", "68M25", "C.2.2"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted at RAID 2025", "url": "http://arxiv.org/abs/2507.17491v2", "summary": "As 5G networks expand into critical infrastructure, secure and efficient user\nauthentication is more important than ever. The 5G-AKA protocol, standardized\nby 3GPP in TS 33.501, is central to authentication in current 5G deployments.\nIt provides mutual authentication, user privacy, and key secrecy. However,\ndespite its adoption, 5G-AKA has known limitations in both security and\nperformance. While it focuses on protecting privacy against passive attackers,\nrecent studies show its vulnerabilities to active attacks. It also relies on a\nsequence number mechanism to prevent replay attacks, requiring perfect\nsynchronization between the device and the core network. This stateful design\nadds complexity, causes desynchronization, and incurs extra communication\noverhead. More critically, 5G-AKA lacks Perfect Forward Secrecy (PFS), exposing\npast communications if long-term keys are compromised-an increasing concern\namid sophisticated threats. This paper proposes an enhanced authentication\nprotocol that builds on 5G-AKA's design while addressing its shortcomings.\nFirst, we introduce a stateless version that removes sequence number reliance,\nreducing complexity while staying compatible with existing SIM cards and\ninfrastructure. We then extend this design to add PFS with minimal\ncryptographic overhead. Both protocols are rigorously analyzed using ProVerif,\nconfirming their compliance with all major security requirements, including\nresistance to passive and active attacks, as well as those defined by 3GPP and\nacademic studies. We also prototype both protocols and evaluate their\nperformance against 5G-AKA and 5G-AKA' (USENIX'21). Our results show the\nproposed protocols offer stronger security with only minor computational\noverhead, making them practical, future-ready solutions for 5G and beyond.", "comment": "Accepted at RAID 2025", "pdf_url": "http://arxiv.org/pdf/2507.17491v2", "cate": "cs.CR", "date": "2025-07-23", "updated": "2025-07-28"}
{"id": "2507.20217", "title": "Humanoid Occupancy: Enabling A Generalized Multimodal Occupancy Perception System on Humanoid Robots", "authors": ["Wei Cui", "Haoyu Wang", "Wenkang Qin", "Yijie Guo", "Gang Han", "Wen Zhao", "Jiahang Cao", "Zhang Zhang", "Jiaru Zhong", "Jingkai Sun", "Pihai Sun", "Shuai Shi", "Botuo Jiang", "Jiahao Ma", "Jiaxu Wang", "Hao Cheng", "Zhichao Liu", "Yang Wang", "Zheng Zhu", "Guan Huang", "Jian Tang", "Qiang Zhang"], "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Tech Report", "url": "http://arxiv.org/abs/2507.20217v1", "summary": "Humanoid robot technology is advancing rapidly, with manufacturers\nintroducing diverse heterogeneous visual perception modules tailored to\nspecific scenarios. Among various perception paradigms, occupancy-based\nrepresentation has become widely recognized as particularly suitable for\nhumanoid robots, as it provides both rich semantic and 3D geometric information\nessential for comprehensive environmental understanding. In this work, we\npresent Humanoid Occupancy, a generalized multimodal occupancy perception\nsystem that integrates hardware and software components, data acquisition\ndevices, and a dedicated annotation pipeline. Our framework employs advanced\nmulti-modal fusion techniques to generate grid-based occupancy outputs encoding\nboth occupancy status and semantic labels, thereby enabling holistic\nenvironmental understanding for downstream tasks such as task planning and\nnavigation. To address the unique challenges of humanoid robots, we overcome\nissues such as kinematic interference and occlusion, and establish an effective\nsensor layout strategy. Furthermore, we have developed the first panoramic\noccupancy dataset specifically for humanoid robots, offering a valuable\nbenchmark and resource for future research and development in this domain. The\nnetwork architecture incorporates multi-modal feature fusion and temporal\ninformation integration to ensure robust perception. Overall, Humanoid\nOccupancy delivers effective environmental perception for humanoid robots and\nestablishes a technical foundation for standardizing universal visual modules,\npaving the way for the widespread deployment of humanoid robots in complex\nreal-world scenarios.", "comment": "Tech Report", "pdf_url": "http://arxiv.org/pdf/2507.20217v1", "cate": "cs.RO", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20000", "title": "Matching Game Preferences Through Dialogical Large Language Models: A Perspective", "authors": ["Renaud Fabre", "Daniel Egret", "Patrice Bellot"], "categories": ["cs.AI", "cs.DL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      28 pages, 1 figure. Published in Applied Sciences", "url": "http://arxiv.org/abs/2507.20000v1", "summary": "This perspective paper explores the future potential of \"conversational\nintelligence\" by examining how Large Language Models (LLMs) could be combined\nwith GRAPHYP's network system to better understand human conversations and\npreferences. Using recent research and case studies, we propose a conceptual\nframework that could make AI rea-soning transparent and traceable, allowing\nhumans to see and understand how AI reaches its conclusions. We present the\nconceptual perspective of \"Matching Game Preferences through Dialogical Large\nLanguage Models (D-LLMs),\" a proposed system that would allow multiple users to\nshare their different preferences through structured conversations. This\napproach envisions personalizing LLMs by embedding individual user preferences\ndirectly into how the model makes decisions. The proposed D-LLM framework would\nrequire three main components: (1) reasoning processes that could analyze\ndifferent search experiences and guide performance, (2) classification systems\nthat would identify user preference patterns, and (3) dialogue approaches that\ncould help humans resolve conflicting information. This perspective framework\naims to create an interpretable AI system where users could examine,\nunderstand, and combine the different human preferences that influence AI\nresponses, detected through GRAPHYP's search experience networks. The goal of\nthis perspective is to envision AI systems that would not only provide answers\nbut also show users how those answers were reached, making artificial\nintelligence more transparent and trustworthy for human decision-making.", "comment": "28 pages, 1 figure. Published in Applied Sciences", "pdf_url": "http://arxiv.org/pdf/2507.20000v1", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19500", "title": "Gaze-Aware AI: Mathematical modeling of epistemic experience of the Marginalized for Human-Computer Interaction & AI Systems", "authors": ["Omkar Suresh Hatti"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19500v1", "summary": "The proliferation of artificial intelligence provides an opportunity to\ncreate psychological spaciousness in society. Spaciousness is defined as the\nability to hold diverse interpersonal interactions and forms the basis for\nvulnerability that leads to authenticity that leads to prosocial behaviors and\nthus to societal harmony. This paper demonstrates an attempt to quantify, the\nhuman conditioning to subconsciously modify authentic self-expression to fit\nthe norms of the dominant culture. Gaze is explored across various marginalized\nand intersectional groups, using concepts from postmodern philosophy and\npsychology. The effects of gaze are studied through analyzing a few redacted\nReddit posts, only to be discussed in discourse and not endorsement. A\nmathematical formulation for the Gaze Pressure Index (GPI)-Diff Composite\nMetric is presented to model the analysis of two sets of conversational spaces\nin relation to one another. The outcome includes an equation to train Large\nLanguage Models (LLMs) - the working mechanism of AI products such as Chat-GPT;\nand an argument for affirming and inclusive HCI, based on the equation, is\npresented. The argument is supported by a few principles of Neuro-plasticity,\nThe brain's lifelong capacity to rewire.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19500v1", "cate": "cs.HC", "date": "2025-07-06", "updated": "2025-07-06"}
{"id": "2503.10302", "title": "Pushing the Boundary of Quantum Advantage in Hard Combinatorial Optimization with Probabilistic Computers", "authors": ["Shuvro Chowdhury", "Navid Anjum Aadit", "Andrea Grimaldi", "Eleonora Raimondo", "Atharva Raut", "P. Aaron Lott", "Johan H. Mentink", "Marek M. Rams", "Federico Ricci-Tersenghi", "Massimo Chiappini", "Luke S. Theogarajan", "Tathagata Srimani", "Giovanni Finocchio", "Masoud Mohseni", "Kerem Y. Camsari"], "categories": ["quant-ph", "cond-mat.dis-nn", "cs.ET"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      Codes are openly available at this https URL", "url": "http://arxiv.org/abs/2503.10302v3", "summary": "Recent demonstrations on specialized benchmarks have reignited excitement for\nquantum computers, yet whether they can deliver an advantage for practical\nreal-world problems remains an open question. Here, we show that probabilistic\ncomputers (p-computers), when co-designed with hardware to implement powerful\nMonte Carlo algorithms, provide a compelling and scalable classical pathway for\nsolving hard optimization problems. We focus on two key algorithms applied to\n3D spin glasses: discrete-time simulated quantum annealing (DT-SQA) and\nadaptive parallel tempering (APT). We benchmark these methods against the\nperformance of a leading quantum annealer on the same problem instances. For\nDT-SQA, we find that increasing the number of replicas improves residual energy\nscaling, in line with expectations from extreme value theory. We then show that\nAPT, when supported by non-local isoenergetic cluster moves, exhibits a more\nfavorable scaling and ultimately outperforms DT-SQA. We demonstrate these\nalgorithms are readily implementable in modern hardware, projecting that custom\nField Programmable Gate Arrays (FPGA) or specialized chips can leverage massive\nparallelism to accelerate these algorithms by orders of magnitude while\ndrastically improving energy efficiency. Our results establish a new, rigorous\nclassical baseline, clarifying the landscape for assessing a practical quantum\nadvantage and presenting p-computers as a scalable platform for real-world\noptimization challenges.", "comment": "Codes are openly available at\n  https://github.com/OPUSLab/3DSpinGlassWithPbits.git", "pdf_url": "http://arxiv.org/pdf/2503.10302v3", "cate": "quant-ph", "date": "2025-03-13", "updated": "2025-07-28"}
{"id": "2507.19524", "title": "Kolmogorov Arnold Network Autoencoder in Medicine", "authors": ["Ugo Lomoio", "Pierangelo Veltri", "Pietro Hiram Guzzi"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19524v1", "summary": "Deep learning neural networks architectures such Multi Layer Perceptrons\n(MLP) and Convolutional blocks still play a crucial role in nowadays research\nadvancements. From a topological point of view, these architecture may be\nrepresented as graphs in which we learn the functions related to the nodes\nwhile fixed edges convey the information from the input to the output. A recent\nwork introduced a new architecture called Kolmogorov Arnold Networks (KAN) that\nreports how putting learnable activation functions on the edges of the neural\nnetwork leads to better performances in multiple scenarios. Multiple studies\nare focusing on optimizing the KAN architecture by adding important features\nsuch as dropout regularization, Autoencoders (AE), model benchmarking and last,\nbut not least, the KAN Convolutional Network (KCN) that introduced matrix\nconvolution with KANs learning. This study aims to benchmark multiple versions\nof vanilla AEs (such as Linear, Convolutional and Variational) against their\nKolmogorov-Arnold counterparts that have same or less number of parameters.\nUsing cardiological signals as model input, a total of five different classic\nAE tasks were studied: reconstruction, generation, denoising, inpainting and\nanomaly detection. The proposed experiments uses a medical dataset\n\\textit{AbnormalHeartbeat} that contains audio signals obtained from the\nstethoscope.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19524v1", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.19842", "title": "A Cooperative Approach for Knowledge-based Business Process Design in a Public Authority", "authors": ["Mohammad Azarijafari", "Luisa Mich", "Michele Missikoff", "Oleg Missikoff"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19842v1", "summary": "Enterprises are currently undergoing profound transformations due to the\nunpostponable digital transformation. Then, to remain competitive, enterprises\nmust adapt their organisational structures and operations. This organisational\nshift is also important for small and medium-sized enterprises. A key\ninnovation frontier is the adoption of process-oriented production models. This\npaper presents a knowledge-based method to support business experts in\ndesigning business processes. The method requires no prior expertise in\nKnowledge Engineering and guides designers through a structured sequence of\nsteps to produce a diagrammatic workflow of the target process. The\nconstruction of the knowledge base starts from simple, text-based, knowledge\nartefacts and then progresses towards more structured, formal representations.\nThe approach has been conceived to allow a shared approach for all stakeholders\nand actors who participate in the BP design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19842v1", "cate": "cs.SE", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19720", "title": "Flexible Bidding in Service-Oriented Combinatorial Spectrum Forward Auctions", "authors": ["Xiang Shao", "Wei Wang", "Guan Gui"], "categories": ["cs.GT", "cs.SI"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "Comments:      5 pages, 4 figures, conference", "url": "http://arxiv.org/abs/2507.19720v1", "summary": "Traditional combinatorial spectrum auctions mainly rely on fixed bidding and\nmatching processes, which limit participants' ability to adapt their strategies\nand often result in suboptimal social welfare in dynamic spectrum sharing\nenvironments. To address these limitations, we propose a novel approximately\ntruthful combinatorial forward auction scheme with a flexible bidding mechanism\naimed at enhancing resource efficiency and maximizing social welfare. In the\nproposed scheme, each buyer submits a combinatorial bid consisting of the base\nspectrum demand and adjustable demand ranges, enabling the auctioneer to\ndynamically optimize spectrum allocation in response to market conditions. To\nstandardize the valuation across heterogeneous frequency bands, we introduce a\nSpectrum Equivalent Mapping (SEM) coefficient. A greedy matching algorithm is\nemployed to determine winning bids by sorting buyers based on their equivalent\nunit bid prices and allocating resources within supply constraints. Simulation\nresults demonstrate that the proposed flexible bidding mechanism significantly\noutperforms existing benchmark methods, achieving notably higher social welfare\nin dynamic spectrum sharing scenarios.", "comment": "5 pages, 4 figures, conference", "pdf_url": "http://arxiv.org/pdf/2507.19720v1", "cate": "cs.GT", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19657", "title": "\"X of Information'' Continuum: A Survey on AI-Driven Multi-dimensional Metrics for Next-Generation Networked Systems", "authors": ["Beining Wu", "Jun Huang", "Shui Yu"], "categories": ["cs.NI", "cs.AI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      48 pages, 14 figures, submitted to IEEE", "url": "http://arxiv.org/abs/2507.19657v1", "summary": "The development of next-generation networking systems has inherently shifted\nfrom throughput-based paradigms towards intelligent, information-aware designs\nthat emphasize the quality, relevance, and utility of transmitted information,\nrather than sheer data volume. While classical network metrics, such as latency\nand packet loss, remain significant, they are insufficient to quantify the\nnuanced information quality requirements of modern intelligent applications,\nincluding autonomous vehicles, digital twins, and metaverse environments. In\nthis survey, we present the first comprehensive study of the ``X of\nInformation'' continuum by introducing a systematic four-dimensional taxonomic\nframework that structures information metrics along temporal, quality/utility,\nreliability/robustness, and network/communication dimensions. We uncover the\nincreasing interdependencies among these dimensions, whereby temporal freshness\ntriggers quality evaluation, which in turn helps with reliability appraisal,\nultimately enabling effective network delivery. Our analysis reveals that\nartificial intelligence technologies, such as deep reinforcement learning,\nmulti-agent systems, and neural optimization models, enable adaptive,\ncontext-aware optimization of competing information quality objectives. In our\nextensive study of six critical application domains, covering autonomous\ntransportation, industrial IoT, healthcare digital twins, UAV communications,\nLLM ecosystems, and metaverse settings, we illustrate the revolutionary promise\nof multi-dimensional information metrics for meeting diverse operational needs.\nOur survey identifies prominent implementation challenges, including ...", "comment": "48 pages, 14 figures, submitted to IEEE", "pdf_url": "http://arxiv.org/pdf/2507.19657v1", "cate": "cs.NI", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2302.09164", "title": "Cyber-attack TTP analysis for EPES systems", "authors": ["Alexios Lekidis"], "categories": ["cs.NI", "cs.CR"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2302.09164v2", "summary": "The electrical grid consists of legacy systems that were built with no\nsecurity in mind. As we move towards the Industry 4.0 area though, a\nhigh-degree of automation and connectivity provides: 1) fast and flexible\nconfiguration and updates as well as 2) easier maintenance and handling of\nmis-configurations and operational errors. Even though considerations are\npresent about the security implications of the Industry 4.0 era in the\nelectrical grid, electricity stakeholders deem their infrastructures as secure\nsince they are isolated and allow no external connections. However, external\nconnections are not the only security risk for electrical utilities. The\nTactics, Techniques and Procedures (TTPs) that are employed by adversaries to\nperform cyber-attack towards the critical Electrical Power and Energy System\n(EPES) infrastructures are gradually becoming highly advanced and\nsophisticated. In this article, we elaborate on these techniques and\ndemonstrate them in a Power Plant of a major utility company within the Greek\narea. The demonstrated TTPs allow exploiting and executing remote commands in\nsmart meters as well as Programmable Logic Controllers (PLCs) that are\nresponsible for the power generator operation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2302.09164v2", "cate": "cs.NI", "date": "2023-02-17", "updated": "2025-07-26"}
{"id": "2507.20282", "title": "Tactile-Guided Robotic Ultrasound: Mapping Preplanned Scan Paths for Intercostal Imaging", "authors": ["Yifan Zhang", "Dianye Huang", "Nassir Navab", "Zhongliang Jiang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted by IROS2025, video link: this https URL", "url": "http://arxiv.org/abs/2507.20282v1", "summary": "Medical ultrasound (US) imaging is widely used in clinical examinations due\nto its portability, real-time capability, and radiation-free nature. To address\ninter- and intra-operator variability, robotic ultrasound systems have gained\nincreasing attention. However, their application in challenging intercostal\nimaging remains limited due to the lack of an effective scan path generation\nmethod within the constrained acoustic window. To overcome this challenge, we\nexplore the potential of tactile cues for characterizing subcutaneous rib\nstructures as an alternative signal for ultrasound segmentation-free bone\nsurface point cloud extraction. Compared to 2D US images, 1D tactile-related\nsignals offer higher processing efficiency and are less susceptible to acoustic\nnoise and artifacts. By leveraging robotic tracking data, a sparse tactile\npoint cloud is generated through a few scans along the rib, mimicking human\npalpation. To robustly map the scanning trajectory into the intercostal space,\nthe sparse tactile bone location point cloud is first interpolated to form a\ndenser representation. This refined point cloud is then registered to an\nimage-based dense bone surface point cloud, enabling accurate scan path mapping\nfor individual patients. Additionally, to ensure full coverage of the object of\ninterest, we introduce an automated tilt angle adjustment method to visualize\nstructures beneath the bone. To validate the proposed method, we conducted\ncomprehensive experiments on four distinct phantoms. The final scanning\nwaypoint mapping achieved Mean Nearest Neighbor Distance (MNND) and Hausdorff\ndistance (HD) errors of 3.41 mm and 3.65 mm, respectively, while the\nreconstructed object beneath the bone had errors of 0.69 mm and 2.2 mm compared\nto the CT ground truth.", "comment": "Accepted by IROS2025, video link: https://youtu.be/SBwpFVzEhAg", "pdf_url": "http://arxiv.org/pdf/2507.20282v1", "cate": "cs.RO", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20010", "title": "Finding Personalized Good-Enough Solutions to Unsatisfiable Stable Roommates Problems", "authors": ["Müge Fidan", "Esra Erdem"], "categories": ["cs.AI", "cs.GT", "cs.LO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20010v1", "summary": "The Stable Roommates problems are characterized by the preferences of agents\nover other agents as roommates. A solution is a partition of the agents into\npairs that are acceptable to each other (i.e., they are in the preference lists\nof each other), and the matching is stable (i.e., there do not exist any two\nagents who prefer each other to their roommates, and thus block the matching).\nMotivated by real-world applications, and considering that stable roommates\nproblems do not always have solutions, we continue our studies to compute\n\"good-enough\" matchings. In addition to the agents' habits and habitual\npreferences, we consider their networks of preferred friends, and introduce a\nmethod to generate personalized solutions to stable roommates problems. We\nillustrate the usefulness of our method with examples and empirical\nevaluations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20010v1", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19690", "title": "Mosaic Selections: Managing and Optimizing User Selections for Scalable Data Visualization Systems", "authors": ["Jeffrey Heer", "Dominik Moritz", "Ron Pechuk"], "categories": ["cs.HC", "cs.DB"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19690v1", "summary": "Though powerful tools for analysis and communication, interactive\nvisualizations often fail to support real-time interaction with large datasets\nwith millions or more records. To highlight and filter data, users indicate\nvalues or intervals of interest. Such selections may span multiple components,\ncombine in complex ways, and require optimizations to ensure low-latency\nupdates. We describe Mosaic Selections, a model for representing, managing, and\noptimizing user selections, in which one or more filter predicates are added to\nqueries that request data for visualizations and input widgets. By analyzing\nboth queries and selection predicates, Mosaic Selections enable automatic\noptimizations, including pre-aggregating data to rapidly compute selection\nupdates. We contribute a formal description of our selection model and\noptimization methods, and their implementation in the open-source Mosaic\narchitecture. Benchmark results demonstrate orders-of-magnitude latency\nimprovements for selection-based optimizations over unoptimized queries and\nexisting optimizers for the Vega language. The Mosaic Selection model provides\ninfrastructure for flexible, interoperable filtering across multiple\nvisualizations, alongside automatic optimizations to scale to millions and even\nbillions of records.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19690v1", "cate": "cs.HC", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19525", "title": "MMCircuitEval: A Comprehensive Multimodal Circuit-Focused Benchmark for Evaluating LLMs", "authors": ["Chenchen Zhao", "Zhengyuan Shi", "Xiangyu Wen", "Chengjie Liu", "Yi Liu", "Yunhao Zhou", "Yuxiang Zhao", "Hefei Feng", "Yinan Zhu", "Gwok-Waa Wan", "Xin Cheng", "Weiyu Chen", "Yongqi Fu", "Chujie Chen", "Chenhao Xue", "Guangyu Sun", "Ying Wang", "Yibo Lin", "Jun Yang", "Ning Xu", "Xi Wang", "Qiang Xu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 1 figure, 5 tables. To appear in ICCAD 2025", "url": "http://arxiv.org/abs/2507.19525v1", "summary": "The emergence of multimodal large language models (MLLMs) presents promising\nopportunities for automation and enhancement in Electronic Design Automation\n(EDA). However, comprehensively evaluating these models in circuit design\nremains challenging due to the narrow scope of existing benchmarks. To bridge\nthis gap, we introduce MMCircuitEval, the first multimodal benchmark\nspecifically designed to assess MLLM performance comprehensively across diverse\nEDA tasks. MMCircuitEval comprises 3614 meticulously curated question-answer\n(QA) pairs spanning digital and analog circuits across critical EDA stages -\nranging from general knowledge and specifications to front-end and back-end\ndesign. Derived from textbooks, technical question banks, datasheets, and\nreal-world documentation, each QA pair undergoes rigorous expert review for\naccuracy and relevance. Our benchmark uniquely categorizes questions by design\nstage, circuit type, tested abilities (knowledge, comprehension, reasoning,\ncomputation), and difficulty level, enabling detailed analysis of model\ncapabilities and limitations. Extensive evaluations reveal significant\nperformance gaps among existing LLMs, particularly in back-end design and\ncomplex computations, highlighting the critical need for targeted training\ndatasets and modeling approaches. MMCircuitEval provides a foundational\nresource for advancing MLLMs in EDA, facilitating their integration into\nreal-world circuit design workflows. Our benchmark is available at\nhttps://github.com/cure-lab/MMCircuitEval.", "comment": "10 pages, 1 figure, 5 tables. To appear in ICCAD 2025", "pdf_url": "http://arxiv.org/pdf/2507.19525v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.19902", "title": "AgentMesh: A Cooperative Multi-Agent Generative AI Framework for Software Development Automation", "authors": ["Sourena Khanzadeh"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19902v1", "summary": "Software development is a complex, multi-phase process traditionally\nrequiring collaboration among individuals with diverse expertise. We propose\nAgentMesh, a Python-based framework that uses multiple cooperating LLM-powered\nagents to automate software development tasks. In AgentMesh, specialized agents\n- a Planner, Coder, Debugger, and Reviewer - work in concert to transform a\nhigh-level requirement into fully realized code. The Planner agent first\ndecomposes user requests into concrete subtasks; the Coder agent implements\neach subtask in code; the Debugger agent tests and fixes the code; and the\nReviewer agent validates the final output for correctness and quality. We\ndescribe the architecture and design of these agents and their communication,\nand provide implementation details including prompt strategies and workflow\norchestration. A case study illustrates AgentMesh handling a non-trivial\ndevelopment request via sequential task planning, code generation, iterative\ndebugging, and final code review. We discuss how dividing responsibilities\namong cooperative agents leverages the strengths of large language models while\nmitigating single-agent limitations. Finally, we examine current limitations -\nsuch as error propagation and context scaling - and outline future work toward\nmore robust, scalable multi-agent AI systems for software engineering\nautomation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19902v1", "cate": "cs.SE", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20449", "title": "Improving Community Detection in Academic Networks by Handling Publication Bias", "authors": ["Md Asaduzzaman Noor", "John Sheppard", "Jason Clark"], "categories": ["cs.IR", "cs.SI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      This paper is an extended version of a work accepted at ASONAM 2025", "url": "http://arxiv.org/abs/2507.20449v1", "summary": "Finding potential research collaborators is a challenging task, especially in\ntoday's fast-growing and interdisciplinary research landscape. While\ntraditional methods often rely on observable relationships such as\nco-authorships and citations to construct the research network, in this work,\nwe focus solely on publication content to build a topic-based research network\nusing BERTopic with a fine-tuned SciBERT model that connects and recommends\nresearchers across disciplines based on shared topical interests. A major\nchallenge we address is publication imbalance, where some researchers publish\nmuch more than others, often across several topics. Without careful handling,\ntheir less frequent interests are hidden under dominant topics, limiting the\nnetwork's ability to detect their full research scope. To tackle this, we\nintroduce a cloning strategy that clusters a researcher's publications and\ntreats each cluster as a separate node. This allows researchers to be part of\nmultiple communities, improving the detection of interdisciplinary links.\nEvaluation on the proposed method shows that the cloned network structure leads\nto more meaningful communities and uncovers a broader set of collaboration\nopportunities.", "comment": "This paper is an extended version of a work accepted at ASONAM 2025", "pdf_url": "http://arxiv.org/pdf/2507.20449v1", "cate": "cs.IR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19925", "title": "Predicting Locations of Cell Towers for Network Capacity Expansion", "authors": ["Sowmiyan Morri", "Joy Bose", "L Raghunatha Reddy", "Sai Hareesh Anamandra"], "categories": ["cs.NI", "90B18", "C.2.1; I.2.6"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures", "url": "http://arxiv.org/abs/2507.19925v1", "summary": "Network capacity expansion is a critical challenge for telecom operators,\nrequiring strategic placement of new cell sites to ensure optimal coverage and\nperformance. Traditional approaches, such as manual drive tests and static\noptimization, often fail to consider key real-world factors including user\ndensity, terrain features, and financial constraints. In this paper, we propose\na machine learning-based framework that combines deep neural networks for\nsignal coverage prediction with spatial clustering to recommend new tower\nlocations in underserved areas. The system integrates geospatial, demographic,\nand infrastructural data, and incorporates budget-aware constraints to\nprioritize deployments. Operating within an iterative planning loop, the\nframework refines coverage estimates after each proposed installation, enabling\nadaptive and cost-effective expansion. While full-scale simulation was limited\nby data availability, the architecture is modular, robust to missing inputs,\nand generalizable across diverse deployment scenarios. This approach advances\nradio network planning by offering a scalable, data-driven alternative to\nmanual methods.", "comment": "9 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.19925v1", "cate": "cs.NI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2312.11283", "title": "A Simulated Reconstruction and Reidentification Attack on the 2010 U.S. Census", "authors": ["John M. Abowd", "Tamara Adams", "Robert Ashmead", "David Darais", "Sourya Dey", "Simson L. Garfinkel", "Nathan Goldschlag", "Michael B. Hawes", "Daniel Kifer", "Philip Leclerc", "Ethan Lew", "Scott Moore", "Rolando A. Rodríguez", "Ramy N. Tadros", "Lars Vilhuber"], "categories": ["stat.AP", "cs.CR", "econ.EM"], "primary_category": "Subjects:       Applications (stat.AP)", "pdf_link": null, "comments": "Comments:      This is the accepted Harvard Data Science Review paper. The accepted supplemental text is here: https://arxiv.org/abs/2312.11283v2", "url": "http://arxiv.org/abs/2312.11283v3", "summary": "We show that individual, confidential microdata records from the 2010 U.S.\nCensus of Population and Housing can be accurately reconstructed from the\npublished tabular summaries. Ninety-seven million person records (every\nresident in 70% of all census blocks) are exactly reconstructed with provable\ncertainty using only public information. We further show that a hypothetical\nattacker using our methods can reidentify with 95% accuracy population unique\nindividuals who are perfectly reconstructed and not in the modal race and\nethnicity category in their census block (3.4 million persons)--a result that\nis only possible because their confidential records were used in the published\ntabulations. Finally, we show that the methods used for the 2020 Census, based\non a differential privacy framework, provide better protection against this\ntype of attack, with better published data accuracy, than feasible\nalternatives.", "comment": "This is the accepted Harvard Data Science Review (2025) paper. The\n  accepted supplemental text is here: https://arxiv.org/abs/2312.11283v2", "pdf_url": "http://arxiv.org/pdf/2312.11283v3", "cate": "stat.AP", "date": "2023-12-18", "updated": "2025-07-28"}
{"id": "2507.20293", "title": "Decentralized Uncertainty-Aware Multi-Agent Collision Avoidance With Model Predictive Path Integral", "authors": ["Stepan Dergachev", "Konstantin Yakovlev"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This is a pre-print of the paper accepted to IROS2025. It contains 8 pages, 4 figures and 1 table. The supplementary video available at this https URL", "url": "http://arxiv.org/abs/2507.20293v1", "summary": "Decentralized multi-agent navigation under uncertainty is a complex task that\narises in numerous robotic applications. It requires collision avoidance\nstrategies that account for both kinematic constraints, sensing and action\nexecution noise. In this paper, we propose a novel approach that integrates the\nModel Predictive Path Integral (MPPI) with a probabilistic adaptation of\nOptimal Reciprocal Collision Avoidance. Our method ensures safe and efficient\nmulti-agent navigation by incorporating probabilistic safety constraints\ndirectly into the MPPI sampling process via a Second-Order Cone Programming\nformulation. This approach enables agents to operate independently using local\nnoisy observations while maintaining safety guarantees. We validate our\nalgorithm through extensive simulations with differential-drive robots and\nbenchmark it against state-of-the-art methods, including ORCA-DD and B-UAVC.\nResults demonstrate that our approach outperforms them while achieving high\nsuccess rates, even in densely populated environments. Additionally, validation\nin the Gazebo simulator confirms its practical applicability to robotic\nplatforms.", "comment": "This is a pre-print of the paper accepted to IROS2025. It contains 8\n  pages, 4 figures and 1 table. The supplementary video available at\n  https://youtu.be/_D4zDYJ4KCk", "pdf_url": "http://arxiv.org/pdf/2507.20293v1", "cate": "cs.RO", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20067", "title": "PITA: Preference-Guided Inference-Time Alignment for LLM Post-Training", "authors": ["Sarat Chandra Bobbili", "Ujwal Dinesha", "Dheeraj Narasimha", "Srinivas Shakkottai"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20067v1", "summary": "Inference-time alignment enables large language models (LLMs) to generate\noutputs aligned with end-user preferences without further training. Recent\npost-training methods achieve this by using small guidance models to modify\ntoken generation during inference. These methods typically optimize a reward\nfunction KL-regularized by the original LLM taken as the reference policy. A\ncritical limitation, however, is their dependence on a pre-trained reward\nmodel, which requires fitting to human preference feedback--a potentially\nunstable process. In contrast, we introduce PITA, a novel framework that\nintegrates preference feedback directly into the LLM's token generation,\neliminating the need for a reward model. PITA learns a small preference-based\nguidance policy to modify token probabilities at inference time without LLM\nfine-tuning, reducing computational cost and bypassing the pre-trained reward\nmodel dependency. The problem is framed as identifying an underlying preference\ndistribution, solved through stochastic search and iterative refinement of the\npreference-based guidance model. We evaluate PITA across diverse tasks,\nincluding mathematical reasoning and sentiment classification, demonstrating\nits effectiveness in aligning LLM outputs with user preferences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20067v1", "cate": "cs.AI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19736", "title": "LowKeyEMG: Electromyographic typing with a reduced keyset", "authors": ["Johannes Y. Lee", "Derek Xiao", "Shreyas Kaasyap", "Nima R. Hadidi", "John L. Zhou", "Jacob Cunningham", "Rakshith R. Gore", "Deniz O. Eren", "Jonathan C. Kao"], "categories": ["cs.HC", "eess.SP"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      11+3 pages, 5 main figures, 2 supplementary tables, 4 supplementary figures", "url": "http://arxiv.org/abs/2507.19736v1", "summary": "We introduce LowKeyEMG, a real-time human-computer interface that enables\nefficient text entry using only 7 gesture classes decoded from surface\nelectromyography (sEMG). Prior work has attempted full-alphabet decoding from\nsEMG, but decoding large character sets remains unreliable, especially for\nindividuals with motor impairments. Instead, LowKeyEMG reduces the English\nalphabet to 4 gesture keys, with 3 more for space and system interaction, to\nreliably translate simple one-handed gestures into text, leveraging the\nrecurrent transformer-based language model RWKV for efficient computation. In\nreal-time experiments, participants achieved average one-handed keyboardless\ntyping speeds of 23.3 words per minute with LowKeyEMG, and improved gesture\nefficiency by 17% (relative to typed phrase length). When typing with only 7\nkeys, LowKeyEMG can achieve 98.2% top-3 word accuracy, demonstrating that this\nlow-key typing paradigm can maintain practical communication rates. Our results\nhave implications for assistive technologies and any interface where input\nbandwidth is constrained.", "comment": "11+3 pages, 5 main figures, 2 supplementary tables, 4 supplementary\n  figures", "pdf_url": "http://arxiv.org/pdf/2507.19736v1", "cate": "cs.HC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19526", "title": "Quantizing Text-attributed Graphs for Semantic-Structural Integration", "authors": ["Jianyuan Bo", "Hao Wu", "Yuan Fang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at KDD'2025", "url": "http://arxiv.org/abs/2507.19526v1", "summary": "Text-attributed graphs (TAGs) have emerged as a powerful representation for\nmodeling complex relationships across diverse domains. With the rise of large\nlanguage models (LLMs), there is growing interest in leveraging their\ncapabilities for graph learning. However, current approaches face significant\nchallenges in embedding structural information into LLM-compatible formats,\nrequiring either computationally expensive alignment mechanisms or manual graph\nverbalization techniques that often lose critical structural details. Moreover,\nthese methods typically require labeled data from source domains for effective\ntransfer learning, significantly constraining their adaptability. We propose\nSTAG, a novel self-supervised framework that directly quantizes graph\nstructural information into discrete tokens using a frozen codebook. Unlike\ntraditional quantization approaches, our method employs soft assignment and KL\ndivergence guided quantization to address the unique challenges of graph data,\nwhich lacks natural tokenization structures. Our framework enables both\nLLM-based and traditional learning approaches, supporting true zero-shot\ntransfer learning without requiring labeled data even in the source domain.\nExtensive experiments demonstrate state-of-the-art performance across multiple\nnode classification benchmarks while maintaining compatibility with different\nLLM architectures, offering an elegant solution to bridging graph learning with\nLLMs.", "comment": "Accepted at KDD'2025", "pdf_url": "http://arxiv.org/pdf/2507.19526v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.19904", "title": "CrossPL: Evaluating Large Language Models on Cross Programming Language Code Generation", "authors": ["Zhanhang Xiong", "Dongxia Wang", "Yuekang Li", "Xinyuan An", "Wenhai Wang"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19904v1", "summary": "As large language models (LLMs) become increasingly embedded in software\nengineering workflows, a critical capability remains underexplored: generating\ncorrect code that enables cross-programming-language (CPL) interoperability.\nThis skill is essential for building complex systems that integrate components\nwritten in multiple languages via mechanisms like inter-process communication\n(IPC). To bridge this gap, we present CrossPL, the first benchmark designed to\nsystematically evaluate LLMs' ability to generate CPL-interoperating code.\nCrossPL comprises 1,982 tasks centered around IPC, covering six widely-used\nprogramming languages and seven representative CPL techniques. We construct\nthis benchmark by (i) analyzing 19,169 multi-language GitHub repositories using\n156 hand-crafted finite state machines (FSMs), and (ii) developing an LLM-based\npipeline that automatically extracts CPL code snippets, generates task\ninstructions, and validates functional correctness. We evaluate 14\nstate-of-the-art general-purpose LLMs and 6 code-oriented LLMs released in the\npast three years on CrossPL via FSM-based validation. Results reveal that even\nthe best-performing models struggle with CPL scenarios, underscoring the need\nfor more targeted research in this space. Our benchmark and code are available\nat: https://anonymous.4open.science/r/crosspl-2814.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19904v1", "cate": "cs.SE", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20924", "title": "FHSTP@EXIST 2025 Benchmark: Sexism Detection with Transparent Speech Concept Bottleneck Models", "authors": ["Roberto Labadie-Tamayo", "Adrian Jaques Böck", "Djordje Slijepčević", "Xihui Chen", "Andreas Babic", "Matthias Zeppelzauer"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI", "I.2"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages", "url": "http://arxiv.org/abs/2507.20924v1", "summary": "Sexism has become widespread on social media and in online conversation. To\nhelp address this issue, the fifth Sexism Identification in Social Networks\n(EXIST) challenge is initiated at CLEF 2025. Among this year's international\nbenchmarks, we concentrate on solving the first task aiming to identify and\nclassify sexism in social media textual posts. In this paper, we describe our\nsolutions and report results for three subtasks: Subtask 1.1 - Sexism\nIdentification in Tweets, Subtask 1.2 - Source Intention in Tweets, and Subtask\n1.3 - Sexism Categorization in Tweets. We implement three models to address\neach subtask which constitute three individual runs: Speech Concept Bottleneck\nModel (SCBM), Speech Concept Bottleneck Model with Transformer (SCBMT), and a\nfine-tuned XLM-RoBERTa transformer model. SCBM uses descriptive adjectives as\nhuman-interpretable bottleneck concepts. SCBM leverages large language models\n(LLMs) to encode input texts into a human-interpretable representation of\nadjectives, then used to train a lightweight classifier for downstream tasks.\nSCBMT extends SCBM by fusing adjective-based representation with contextual\nembeddings from transformers to balance interpretability and classification\nperformance. Beyond competitive results, these two models offer fine-grained\nexplanations at both instance (local) and class (global) levels. We also\ninvestigate how additional metadata, e.g., annotators' demographic profiles,\ncan be leveraged. For Subtask 1.1, XLM-RoBERTa, fine-tuned on provided data\naugmented with prior datasets, ranks 6th for English and Spanish and 4th for\nEnglish in the Soft-Soft evaluation. Our SCBMT achieves 7th for English and\nSpanish and 6th for Spanish.", "comment": "12 pages", "pdf_url": "http://arxiv.org/pdf/2507.20924v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19938", "title": "Optimizing Spreading Factor Selection for Mobile LoRa Gateways Using Single-Channel Hardware", "authors": ["W. A. Sasindu Wijesuriya"], "categories": ["cs.NI", "cs.RO"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures", "url": "http://arxiv.org/abs/2507.19938v1", "summary": "The deployment of mobile LoRa gateways using low-cost single-channel hardware\npresents a significant challenge in maintaining reliable communication due to\nthe lack of dynamic configuration support. In traditional LoRaWAN networks,\nAdaptive Data Rate (ADR) mechanisms optimize communication parameters in real\ntime. However, such features are typically supported only by expensive\nmulti-channel gateways. This study proposes a cost-effective and\nenergy-efficient solution by statically selecting the optimal Spreading Factor\n(SF) using a two-phase algorithm. The method first applies rule-based exclusion\nto eliminate SFs that violate constraints related to distance, data rate, link\nmargin, and regulatory limits. Remaining candidates are then evaluated using a\nweighted scoring model incorporating Time-on-Air, energy consumption, data\nrate, and link robustness. The proposed algorithm was validated through\nextensive field tests and NS-3 simulations under line-of-sight conditions.\nResults demonstrate that the selected SF matched the optimal SF in over 92% of\ncases across 672 simulated scenarios, confirming the algorithm's effectiveness.\nThis approach offers a scalable alternative to dynamic protocols, enabling\nreliable mobile LoRa deployments in cost-sensitive environments such as\nagriculture and rural sensing applications.", "comment": "6 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.19938v1", "cate": "cs.NI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2409.13864", "title": "Persistent Backdoor Attacks in Continual Learning", "authors": ["Zhen Guo", "Abhinav Kumar", "Reza Tourani"], "categories": ["cs.LG", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      19 pages, 20 figures, 6 tables", "url": "http://arxiv.org/abs/2409.13864v3", "summary": "Backdoor attacks pose a significant threat to neural networks, enabling\nadversaries to manipulate model outputs on specific inputs, often with\ndevastating consequences, especially in critical applications. While backdoor\nattacks have been studied in various contexts, little attention has been given\nto their practicality and persistence in continual learning, particularly in\nunderstanding how the continual updates to model parameters, as new data\ndistributions are learned and integrated, impact the effectiveness of these\nattacks over time. To address this gap, we introduce two persistent backdoor\nattacks-Blind Task Backdoor and Latent Task Backdoor-each leveraging minimal\nadversarial influence. Our blind task backdoor subtly alters the loss\ncomputation without direct control over the training process, while the latent\ntask backdoor influences only a single task's training, with all other tasks\ntrained benignly. We evaluate these attacks under various configurations,\ndemonstrating their efficacy with static, dynamic, physical, and semantic\ntriggers. Our results show that both attacks consistently achieve high success\nrates across different continual learning algorithms, while effectively evading\nstate-of-the-art defenses, such as SentiNet and I-BAU.", "comment": "19 pages, 20 figures, 6 tables", "pdf_url": "http://arxiv.org/pdf/2409.13864v3", "cate": "cs.LG", "date": "2024-09-20", "updated": "2025-07-29"}
{"id": "2507.20370", "title": "Advancing Shared and Multi-Agent Autonomy in Underwater Missions: Integrating Knowledge Graphs and Retrieval-Augmented Generation", "authors": ["Michele Grimaldi", "Carlo Cernicchiaro", "Sebastian Realpe Rua", "Alaaeddine El-Masri-El-Chaarani", "Markus Buchholz", "Loizos Michael", "Pere Ridao Rodriguez", "Ignacio Carlucho", "Yvan R. Petillot"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20370v1", "summary": "Robotic platforms have become essential for marine operations by providing\nregular and continuous access to offshore assets, such as underwater\ninfrastructure inspection, environmental monitoring, and resource exploration.\nHowever, the complex and dynamic nature of underwater environments,\ncharacterized by limited visibility, unpredictable currents, and communication\nconstraints, presents significant challenges that demand advanced autonomy\nwhile ensuring operator trust and oversight. Central to addressing these\nchallenges are knowledge representation and reasoning techniques, particularly\nknowledge graphs and retrieval-augmented generation (RAG) systems, that enable\nrobots to efficiently structure, retrieve, and interpret complex environmental\ndata. These capabilities empower robotic agents to reason, adapt, and respond\neffectively to changing conditions. The primary goal of this work is to\ndemonstrate both multi-agent autonomy and shared autonomy, where multiple\nrobotic agents operate independently while remaining connected to a human\nsupervisor. We show how a RAG-powered large language model, augmented with\nknowledge graph data and domain taxonomy, enables autonomous multi-agent\ndecision-making and facilitates seamless human-robot interaction, resulting in\n100\\% mission validation and behavior completeness. Finally, ablation studies\nreveal that without structured knowledge from the graph and/or taxonomy, the\nLLM is prone to hallucinations, which can compromise decision quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20370v1", "cate": "cs.RO", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20143", "title": "Concept Learning for Cooperative Multi-Agent Reinforcement Learning", "authors": ["Zhonghan Ge", "Yuanyang Zhu", "Chunlin Chen"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      IEEE-China Conference on System Simulation Technology and its Applications, 2025", "url": "http://arxiv.org/abs/2507.20143v1", "summary": "Despite substantial progress in applying neural networks (NN) to multi-agent\nreinforcement learning (MARL) areas, they still largely suffer from a lack of\ntransparency and interoperability. However, its implicit cooperative mechanism\nis not yet fully understood due to black-box networks. In this work, we study\nan interpretable value decomposition framework via concept bottleneck models,\nwhich promote trustworthiness by conditioning credit assignment on an\nintermediate level of human-like cooperation concepts. To address this problem,\nwe propose a novel value-based method, named Concepts learning for Multi-agent\nQ-learning (CMQ), that goes beyond the current performance-vs-interpretability\ntrade-off by learning interpretable cooperation concepts. CMQ represents each\ncooperation concept as a supervised vector, as opposed to existing models where\nthe information flowing through their end-to-end mechanism is concept-agnostic.\nIntuitively, using individual action value conditioning on global state\nembeddings to represent each concept allows for extra cooperation\nrepresentation capacity. Empirical evaluations on the StarCraft II\nmicromanagement challenge and level-based foraging (LBF) show that CMQ achieves\nsuperior performance compared with the state-of-the-art counterparts. The\nresults also demonstrate that CMQ provides more cooperation concept\nrepresentation capturing meaningful cooperation modes, and supports test-time\nconcept interventions for detecting potential biases of cooperation mode and\nidentifying spurious artifacts that impact cooperation.", "comment": "IEEE-China Conference on System Simulation Technology and its\n  Applications, 2025", "pdf_url": "http://arxiv.org/pdf/2507.20143v1", "cate": "cs.AI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19782", "title": "KinemaFX: A Kinematic-Driven Interactive System for Particle Effect Exploration and Customization", "authors": ["Yifei Zhang", "Lin-Ping Yuan", "Yuheng Zhao", "Jielin Feng", "Siming Chen"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Meta Review Overall Rating 3.5 Weakly Accept Contribution to HCI This paper presents KinemaFX, an LLM-powered interactive system leveraging semantic and kinematic inputs to help non-experts explore, customize, and compose particle effects", "url": "http://arxiv.org/abs/2507.19782v1", "summary": "Particle effects are widely used in games and animation to simulate natural\nphenomena or stylized visual effects. However, creating effect artworks is\nchallenging for non-expert users due to their lack of specialized skills,\nparticularly in finding particle effects with kinematic behaviors that match\ntheir intent. To address these issues, we present KinemaFX, a kinematic-driven\ninteractive system, to assist non-expert users in constructing customized\nparticle effect artworks. We propose a conceptual model of particle effects\nthat captures both semantic features and kinematic behaviors. Based on the\nmodel, KinemaFX adopts a workflow powered by Large Language Models (LLMs) that\nsupports intent expression through combined semantic and kinematic inputs,\nwhile enabling implicit preference-guided exploration and subsequent creation\nof customized particle effect artworks based on exploration results.\nAdditionally, we developed a kinematic-driven method to facilitate efficient\ninteractive particle effect search within KinemaFX via structured\nrepresentation and measurement of particle effects. To evaluate KinemaFX, we\nillustrate usage scenarios and conduct a user study employing an ablation\napproach. Evaluation results demonstrate that KinemaFX effectively supports\nusers in efficiently and customarily creating particle effect artworks.", "comment": "Meta Review Overall Rating 3.5 Weakly Accept Contribution to HCI This\n  paper presents KinemaFX, an LLM-powered interactive system leveraging\n  semantic and kinematic inputs to help non-experts explore, customize, and\n  compose particle effects", "pdf_url": "http://arxiv.org/pdf/2507.19782v1", "cate": "cs.HC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19527", "title": "Research on the application of graph data structure and graph neural network in node classification/clustering tasks", "authors": ["Yihan Wang", "Jianing Zhao"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19527v1", "summary": "Graph-structured data are pervasive across domains including social networks,\nbiological networks, and knowledge graphs. Due to their non-Euclidean nature,\nsuch data pose significant challenges to conventional machine learning methods.\nThis study investigates graph data structures, classical graph algorithms, and\nGraph Neural Networks (GNNs), providing comprehensive theoretical analysis and\ncomparative evaluation. Through comparative experiments, we quantitatively\nassess performance differences between traditional algorithms and GNNs in node\nclassification and clustering tasks. Results show GNNs achieve substantial\naccuracy improvements of 43% to 70% over traditional methods. We further\nexplore integration strategies between classical algorithms and GNN\narchitectures, providing theoretical guidance for advancing graph\nrepresentation learning research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19527v1", "cate": "cs.LG", "date": "2025-07-20", "updated": "2025-07-20"}
{"id": "2507.19909", "title": "The Impact of Fine-tuning Large Language Models on Automated Program Repair", "authors": ["Roman Macháček", "Anastasiia Grishina", "Max Hort", "Leon Moonen"], "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted for publication in the research track of the 41th International Conference on Software Maintenance and Evolution (ICSME 2025)", "url": "http://arxiv.org/abs/2507.19909v1", "summary": "Automated Program Repair (APR) uses various tools and techniques to help\ndevelopers achieve functional and error-free code faster. In recent years,\nLarge Language Models (LLMs) have gained popularity as components in APR tool\nchains because of their performance and flexibility. However, training such\nmodels requires a significant amount of resources. Fine-tuning techniques have\nbeen developed to adapt pre-trained LLMs to specific tasks, such as APR, and\nenhance their performance at far lower computational costs than training from\nscratch. In this study, we empirically investigate the impact of various\nfine-tuning techniques on the performance of LLMs used for APR. Our experiments\nprovide insights into the performance of a selection of state-of-the-art LLMs\npre-trained on code. The evaluation is done on three popular APR benchmarks\n(i.e., QuixBugs, Defects4J and HumanEval-Java) and considers six different LLMs\nwith varying parameter sizes (resp. CodeGen, CodeT5, StarCoder, DeepSeekCoder,\nBloom, and CodeLlama-2). We consider three training regimens: no fine-tuning,\nfull fine-tuning, and parameter-efficient fine-tuning (PEFT) using LoRA and\nIA3. We observe that full fine-tuning techniques decrease the benchmarking\nperformance of various models due to different data distributions and\noverfitting. By using parameter-efficient fine-tuning methods, we restrict\nmodels in the amount of trainable parameters and achieve better results.\n  Keywords: large language models, automated program repair,\nparameter-efficient fine-tuning, AI4Code, AI4SE, ML4SE.", "comment": "Accepted for publication in the research track of the 41th\n  International Conference on Software Maintenance and Evolution (ICSME 2025)", "pdf_url": "http://arxiv.org/pdf/2507.19909v1", "cate": "cs.SE", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2411.00612", "title": "How to Bridge Spatial and Temporal Heterogeneity in Link Prediction? A Contrastive Method", "authors": ["Yu Tai", "Xinglong Wu", "Hongwei Yang", "Hui He", "Duanjing Chen", "Yuanming Shao", "Weizhe Zhang"], "categories": ["cs.SI", "cs.AI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.00612v2", "summary": "Temporal Heterogeneous Networks play a crucial role in capturing the dynamics\nand heterogeneity inherent in various real-world complex systems, rendering\nthem a noteworthy research avenue for link prediction. However, existing\nmethods fail to capture the fine-grained differential distribution patterns and\ntemporal dynamic characteristics, which we refer to as spatial heterogeneity\nand temporal heterogeneity. To overcome such limitations, we propose a novel\n\\textbf{C}ontrastive Learning-based \\textbf{L}ink \\textbf{P}rediction model,\n\\textbf{CLP}, which employs a multi-view hierarchical self-supervised\narchitecture to encode spatial and temporal heterogeneity. Specifically, aiming\nat spatial heterogeneity, we develop a spatial feature modeling layer to\ncapture the fine-grained topological distribution patterns from node- and\nedge-level representations, respectively. Furthermore, aiming at temporal\nheterogeneity, we devise a temporal information modeling layer to perceive the\nevolutionary dependencies of dynamic graph topologies from time-level\nrepresentations. Finally, we encode the spatial and temporal distribution\nheterogeneity from a contrastive learning perspective, enabling a comprehensive\nself-supervised hierarchical relation modeling for the link prediction task.\nExtensive experiments conducted on four real-world dynamic heterogeneous\nnetwork datasets verify that our \\mymodel consistently outperforms the\nstate-of-the-art models, demonstrating an average improvement of 10.10\\%,\n13.44\\% in terms of AUC and AP, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.00612v2", "cate": "cs.SI", "date": "2024-11-01", "updated": "2025-07-28"}
{"id": "2507.19963", "title": "A Scalable Resource Management Layer for FPGA SoCs in 6G Radio Units", "authors": ["Nikolaos Bartzoudis", "José Rubio Fernández", "David López-Bueno", "Antonio Román Villarroel"], "categories": ["cs.NI", "cs.AR"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Paper accepted to the \"XL Simposio Nacional de la Unión Científica Internacional de Radio (URSI 2025)\", Tarragona, Spain, 3-5 September 2025. Proceedings are not published. Also part of the worj appears in Deliverables 2.2 and 5.2 of the SNS JU project VERGE", "url": "http://arxiv.org/abs/2507.19963v1", "summary": "This work presents a perspective on addressing the underutilization of\ncomputing resources in FPGA SoC devices deployed in 5G radio and edge computing\ninfrastructure. The initial step in this approach involves developing a\nresource management layer capable of dynamically migrating and scaling\nfunctions within these devices in response to contextual events. This layer\nserves as the foundation for designing a hierarchical, data-driven\nmicro-orchestrator responsible for managing the lifecycle of functions in FPGA\nSoC devices. In this paper, the proposed resource management layer is utilized\nto reconfigure a function based on events identified by a computer vision edge\napplication.", "comment": "Paper accepted to the \"XL Simposio Nacional de la Uni\\'on\n  Cient\\'ifica Internacional de Radio (URSI 2025)\", Tarragona, Spain, 3-5\n  September 2025. Proceedings are not published. Also part of the worj appears\n  in Deliverables 2.2 and 5.2 of the SNS JU project VERGE", "pdf_url": "http://arxiv.org/pdf/2507.19963v1", "cate": "cs.NI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2411.14433", "title": "PRISM: A Personalized, Rapid, and Immersive Skill Mastery framework for personalizing experiential learning through Generative AI", "authors": ["Yu-Zheng Lin", "Karan Patel", "Ahmed Hussain J Alhamadah", "Bono Po-Jen Shih", "Matthew William Redondo", "David Rafael Vidal Corona", "Banafsheh Saber Latibari", "Jesus Pacheco", "Soheil Salehi", "Pratik Satam"], "categories": ["cs.CY", "cs.AI", "cs.CR", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      24 pages, 7 figures", "url": "http://arxiv.org/abs/2411.14433v2", "summary": "The rise of generative AI (gen-AI) is transforming industries, particularly\nin education and workforce training. This chapter introduces PRISM\n(Personalized, Rapid, and Immersive Skill Mastery), a scalable framework\nleveraging gen-AI and Digital Twins (DTs) to deliver adaptive, experiential\nlearning. PRISM integrates sentiment analysis and Retrieval-Augmented\nGeneration (RAG) to monitor learner comprehension and dynamically adjust\ncontent to meet course objectives. We further present the Multi-Fidelity\nDigital Twin for Education (MFDT-E) framework, aligning DT fidelity levels with\nBloom's Taxonomy and the Kirkpatrick evaluation model to support undergraduate,\nmaster's, and doctoral training. Experimental validation shows that GPT-4\nachieves 91 percent F1 in zero-shot sentiment analysis of teacher-student\ndialogues, while GPT-3.5 performs robustly in informal language contexts.\nAdditionally, the system's effectiveness and scalability for immersive Industry\n4.0 training are demonstrated through four VR modules: Home Scene, Factory\nFloor Tour, Capping Station DT, and PPE Inspection Training. These results\nhighlight the potential of integrating generative AI with digital twins to\nenable personalized, efficient, and scalable education.", "comment": "24 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2411.14433v2", "cate": "cs.CY", "date": "2024-11-02", "updated": "2025-07-26"}
{"id": "2507.20382", "title": "Bipedalism for Quadrupedal Robots: Versatile Loco-Manipulation through Risk-Adaptive Reinforcement Learning", "authors": ["Yuyou Zhang", "Radu Corcodel", "Ding Zhao"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Humanoids 2025", "url": "http://arxiv.org/abs/2507.20382v1", "summary": "Loco-manipulation of quadrupedal robots has broadened robotic applications,\nbut using legs as manipulators often compromises locomotion, while mounting\narms complicates the system. To mitigate this issue, we introduce bipedalism\nfor quadrupedal robots, thus freeing the front legs for versatile interactions\nwith the environment. We propose a risk-adaptive distributional Reinforcement\nLearning (RL) framework designed for quadrupedal robots walking on their hind\nlegs, balancing worst-case conservativeness with optimal performance in this\ninherently unstable task. During training, the adaptive risk preference is\ndynamically adjusted based on the uncertainty of the return, measured by the\ncoefficient of variation of the estimated return distribution. Extensive\nexperiments in simulation show our method's superior performance over\nbaselines. Real-world deployment on a Unitree Go2 robot further demonstrates\nthe versatility of our policy, enabling tasks like cart pushing, obstacle\nprobing, and payload transport, while showcasing robustness against challenging\ndynamics and external disturbances.", "comment": "Humanoids 2025", "pdf_url": "http://arxiv.org/pdf/2507.20382v1", "cate": "cs.RO", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20150", "title": "The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large Language Models", "authors": ["Xingcheng Xu"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20150v1", "summary": "Reinforcement learning (RL) plays a crucial role in shaping the behavior of\nlarge language and reasoning models (LLMs/LRMs). However, it often produces\nbrittle and unstable policies, leading to critical failures such as spurious\nreasoning, deceptive alignment, and instruction disobedience that undermine the\ntrustworthiness and safety of LLMs/LRMs. Currently, these issues lack a unified\ntheoretical explanation and are typically addressed using ad-hoc heuristics.\nThis paper presents a rigorous mathematical framework for analyzing the\nstability of the mapping from a reward function to the optimal policy. We show\nthat policy brittleness often stems from non-unique optimal actions, a common\noccurrence when multiple valid traces exist in a reasoning task. This\ntheoretical lens provides a unified explanation for a range of seemingly\ndisparate failures, reframing them as rational outcomes of optimizing rewards\nthat may be incomplete or noisy, especially in the presence of action\ndegeneracy. We extend this analysis from the fundamental single-reward setting\nto the more realistic multi-reward RL across diverse domains, showing how\nstability is governed by an \"effective reward\" aggregation mechanism. We also\nprove that entropy regularization restores policy stability at the cost of\nincreased stochasticity. Our framework provides a unified explanation for\nrecent empirical findings on deceptive reasoning, instruction-following\ntrade-offs, and RLHF-induced sophistry, and is further validated through\nperturbation experiments in multi-reward RL. This work advances\npolicy-stability analysis from empirical heuristics towards a principled\ntheory, offering essential insights for designing safer and more trustworthy AI\nsystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20150v1", "cate": "cs.AI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19898", "title": "TS-Insight: Visualizing Thompson Sampling for Verification and XAI", "authors": ["Parsa Vares", "Éloi Durant", "Jun Pang", "Nicolas Médoc", "Mohammad Ghoniem"], "categories": ["cs.HC", "cs.AI", "cs.LG", "stat.ML", "I.2.6; H.5.2"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted as a poster at IEEE VIS 2025 (\"TS-Insight: Visual Fingerprinting of Multi-Armed Bandits\"). Open-source tool available at this https URL", "url": "http://arxiv.org/abs/2507.19898v1", "summary": "Thompson Sampling (TS) and its variants are powerful Multi-Armed Bandit\nalgorithms used to balance exploration and exploitation strategies in active\nlearning. Yet, their probabilistic nature often turns them into a ``black\nbox'', hindering debugging and trust. We introduce TS-Insight, a visual\nanalytics tool explicitly designed to shed light on the internal decision\nmechanisms of Thompson Sampling-based algorithms, for model developers. It\ncomprises multiple plots, tracing for each arm the evolving posteriors,\nevidence counts, and sampling outcomes, enabling the verification, diagnosis,\nand explainability of exploration/exploitation dynamics. This tool aims at\nfostering trust and facilitating effective debugging and deployment in complex\nbinary decision-making scenarios especially in sensitive domains requiring\ninterpretable decision-making.", "comment": "Accepted as a poster at IEEE VIS 2025 (\"TS-Insight: Visual\n  Fingerprinting of Multi-Armed Bandits\"). Open-source tool available at\n  https://github.com/parsavares/ts-insight", "pdf_url": "http://arxiv.org/pdf/2507.19898v1", "cate": "cs.HC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19529", "title": "Machine Learning Risk Intelligence for Green Hydrogen Investment: Insights for Duqm R3 Auction", "authors": ["Obumneme Nwafor", "Mohammed Abdul Majeed Al Hooti"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19529v2", "summary": "As green hydrogen emerges as a major component of global decarbonisation,\nOman has positioned itself strategically through national auctions and\ninternational partnerships. Following two successful green hydrogen project\nrounds, the country launched its third auction (R3) in the Duqm region. While\nthis area exhibits relative geospatial homogeneity, it is still vulnerable to\nenvironmental fluctuations that pose inherent risks to productivity. Despite\ngrowing global investment in green hydrogen, operational data remains scarce,\nwith major projects like Saudi Arabia's NEOM facility not expected to commence\nproduction until 2026, and Oman's ACME Duqm project scheduled for 2028. This\nabsence of historical maintenance and performance data from large-scale\nhydrogen facilities in desert environments creates a major knowledge gap for\naccurate risk assessment for infrastructure planning and auction decisions.\nGiven this data void, environmental conditions emerge as accessible and\nreliable proxy for predicting infrastructure maintenance pressures, because\nharsh desert conditions such as dust storms, extreme temperatures, and humidity\nfluctuations are well-documented drivers of equipment degradation in renewable\nenergy systems. To address this challenge, this paper proposes an Artificial\nIntelligence decision support system that leverages publicly available\nmeteorological data to develop a predictive Maintenance Pressure Index (MPI),\nwhich predicts risk levels and future maintenance demands on hydrogen\ninfrastructure. This tool strengthens regulatory foresight and operational\ndecision-making by enabling temporal benchmarking to assess and validate\nperformance claims over time. It can be used to incorporate temporal risk\nintelligence into auction evaluation criteria despite the absence of historical\noperational benchmarks.", "comment": "Updated version", "pdf_url": "http://arxiv.org/pdf/2507.19529v2", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-29"}
{"id": "2507.19942", "title": "Prometheus: Unified Knowledge Graphs for Issue Resolution in Multilingual Codebases", "authors": ["Zimin Chen", "Yue Pan", "Siyu Lu", "Jiayi Xu", "Claire Le Goues", "Martin Monperrus", "He Ye"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19942v1", "summary": "Language model (LM) agents, such as SWE-agent and OpenHands, have made\nprogress toward automated issue resolution. However, existing approaches are\noften limited to Python-only issues and rely on pre-constructed containers in\nSWE-bench with reproduced issues, restricting their applicability to real-world\nand work for multi-language repositories. We present Prometheus, designed to\nresolve real-world issues beyond benchmark settings. Prometheus is a\nmulti-agent system that transforms an entire code repository into a unified\nknowledge graph to guide context retrieval for issue resolution. Prometheus\nencodes files, abstract syntax trees, and natural language text into a graph of\ntyped nodes and five general edge types to support multiple programming\nlanguages. Prometheus uses Neo4j for graph persistence, enabling scalable and\nstructured reasoning over large codebases. Integrated by the DeepSeek-V3 model,\nPrometheus resolves 28.67% and 13.7% of issues on SWE-bench Lite and SWE-bench\nMultilingual, respectively, with an average API cost of $0.23 and $0.38 per\nissue. Prometheus resolves 10 unique issues not addressed by prior work and is\nthe first to demonstrate effectiveness across seven programming languages.\nMoreover, it shows the ability to resolve real-world GitHub issues in the\nLangChain and OpenHands repositories. We have open-sourced Prometheus at:\nhttps://github.com/Pantheon-temple/Prometheus", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19942v1", "cate": "cs.SE", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20050", "title": "Towards Next Generation Immersive Applications in 5G Environments", "authors": ["Rohail Asim", "Ankit Bhardwaj", "Lakshmi Suramanian", "Yasir Zaki"], "categories": ["cs.NI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20050v1", "summary": "The Multi-user Immersive Reality (MIR) landscape is evolving rapidly, with\napplications spanning virtual collaboration, entertainment, and training.\nHowever, wireless network limitations create a critical bottleneck, struggling\nto meet the high-bandwidth and ultra-low latency demands essential for\nnext-generation MIR experiences. This paper presents Hera, a modular framework\nfor next-generation immersive applications, comprising a high-level streaming\nand synchronization layer for AR/VR systems and a low-level delay-based\nQoE-aware rate control protocol optimized for dynamic wireless environments.\nThe Hera framework integrates application-aware streaming logic with a\nQoE-centric rate control core, enabling adaptive video quality, multi-user\nfairness, and low-latency communication across challenging 5G network\nconditions. We demonstrate that Hera outperforms existing state-of-the-art rate\ncontrol algorithms by maintaining up to 66% lower latencies with comparable\nthroughput performance, higher visual quality with 50% average bitrate\nimprovements in our analysis, and improved fairness. By bridging the gap\nbetween application-level responsiveness and network-level adaptability, Hera\nlays the foundation for more scalable, robust, and high-fidelity multi-user\nimmersive experiences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20050v1", "cate": "cs.NI", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2412.03908", "title": "Generalizable Targeted Data Poisoning against Varying Physical Objects", "authors": ["Zhizhen Chen", "Zhengyu Zhao", "Subrat Kishore Dutta", "Chenhao Lin", "Chao Shen", "Xiao Zhang"], "categories": ["cs.CV", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      13 pages, 9 figures, 7 tables", "url": "http://arxiv.org/abs/2412.03908v2", "summary": "Targeted data poisoning (TDP) aims to compromise the model's prediction on a\nspecific (test) target by perturbing a small subset of training data. Existing\nwork on TDP has focused on an overly ideal threat model in which the same image\nsample of the target is used during both poisoning and inference stages.\nHowever, in the real world, a target object often appears in complex variations\ndue to changes of physical settings such as viewpoint, background, and lighting\nconditions. In this work, we take the first step toward understanding the\nreal-world threats of TDP by studying its generalizability across varying\nphysical conditions. In particular, we observe that solely optimizing gradient\ndirections, as adopted by the best previous TDP method, achieves limited\ngeneralization. To address this limitation, we propose optimizing both the\ngradient direction and magnitude for more generalizable gradient matching,\nthereby leading to higher poisoning success rates. For instance, our method\noutperforms the state of the art by 19.49% when poisoning CIFAR-10 images\ntargeting multi-view cars.", "comment": "13 pages, 9 figures, 7 tables", "pdf_url": "http://arxiv.org/pdf/2412.03908v2", "cate": "cs.CV", "date": "2024-12-05", "updated": "2025-07-26"}
{"id": "2507.20427", "title": "Model-Structured Neural Networks to Control the Steering Dynamics of Autonomous Race Cars", "authors": ["Mattia Piccinini", "Aniello Mungiello", "Georg Jank", "Gastone Pietro Rosati Papini", "Francesco Biral", "Johannes Betz"], "categories": ["cs.RO", "J.2; I.2; I.6"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at the 2025 IEEE International Conference on Intelligent Transportation Systems (ITSC)", "url": "http://arxiv.org/abs/2507.20427v1", "summary": "Autonomous racing has gained increasing attention in recent years, as a safe\nenvironment to accelerate the development of motion planning and control\nmethods for autonomous driving. Deep learning models, predominantly based on\nneural networks (NNs), have demonstrated significant potential in modeling the\nvehicle dynamics and in performing various tasks in autonomous driving.\nHowever, their black-box nature is critical in the context of autonomous\nracing, where safety and robustness demand a thorough understanding of the\ndecision-making algorithms. To address this challenge, this paper proposes\nMS-NN-steer, a new Model-Structured Neural Network for vehicle steering\ncontrol, integrating the prior knowledge of the nonlinear vehicle dynamics into\nthe neural architecture. The proposed controller is validated using real-world\ndata from the Abu Dhabi Autonomous Racing League (A2RL) competition, with\nfull-scale autonomous race cars. In comparison with general-purpose NNs,\nMS-NN-steer is shown to achieve better accuracy and generalization with small\ntraining datasets, while being less sensitive to the weights' initialization.\nAlso, MS-NN-steer outperforms the steering controller used by the A2RL winning\nteam. Our implementation is available open-source in a GitHub repository.", "comment": "Accepted at the 2025 IEEE International Conference on Intelligent\n  Transportation Systems (ITSC)", "pdf_url": "http://arxiv.org/pdf/2507.20427v1", "cate": "cs.RO", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20199", "title": "StepFun-Prover Preview: Let's Think and Verify Step by Step", "authors": ["Shijie Shang", "Ruosi Wan", "Yue Peng", "Yutong Wu", "Xiong-hui Chen", "Jie Yan", "Xiangyu Zhang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      25 pages, 4 figures", "url": "http://arxiv.org/abs/2507.20199v1", "summary": "We present StepFun-Prover Preview, a large language model designed for formal\ntheorem proving through tool-integrated reasoning. Using a reinforcement\nlearning pipeline that incorporates tool-based interactions, StepFun-Prover can\nachieve strong performance in generating Lean 4 proofs with minimal sampling.\nOur approach enables the model to emulate human-like problem-solving strategies\nby iteratively refining proofs based on real-time environment feedback. On the\nminiF2F-test benchmark, StepFun-Prover achieves a pass@1 success rate of\n$70.0\\%$. Beyond advancing benchmark performance, we introduce an end-to-end\ntraining framework for developing tool-integrated reasoning models, offering a\npromising direction for automated theorem proving and Math AI assistant.", "comment": "25 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.20199v1", "cate": "cs.AI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19988", "title": "Visual Analytics Using Tensor Unified Linear Comparative Analysis", "authors": ["Naoki Okami", "Kazuki Miyake", "Naohisa Sakamoto", "Jorji Nonaka", "Takanori Fujiwara"], "categories": ["cs.HC", "cs.GR", "cs.LG", "I.3.8; H.5.2"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      To appear in IEEE Transactions on Visualization and Computer Graphics and IEEE VIS 2025", "url": "http://arxiv.org/abs/2507.19988v1", "summary": "Comparing tensors and identifying their (dis)similar structures is\nfundamental in understanding the underlying phenomena for complex data. Tensor\ndecomposition methods help analysts extract tensors' essential characteristics\nand aid in visual analytics for tensors. In contrast to dimensionality\nreduction (DR) methods designed only for analyzing a matrix (i.e., second-order\ntensor), existing tensor decomposition methods do not support flexible\ncomparative analysis. To address this analysis limitation, we introduce a new\ntensor decomposition method, named tensor unified linear comparative analysis\n(TULCA), by extending its DR counterpart, ULCA, for tensor analysis. TULCA\nintegrates discriminant analysis and contrastive learning schemes for tensor\ndecomposition, enabling flexible comparison of tensors. We also introduce an\neffective method to visualize a core tensor extracted from TULCA into a set of\n2D visualizations. We integrate TULCA's functionalities into a visual analytics\ninterface to support analysts in interpreting and refining the TULCA results.\nWe demonstrate the efficacy of TULCA and the visual analytics interface with\ncomputational evaluations and two case studies, including an analysis of log\ndata collected from a supercomputer.", "comment": "To appear in IEEE Transactions on Visualization and Computer Graphics\n  and IEEE VIS 2025", "pdf_url": "http://arxiv.org/pdf/2507.19988v1", "cate": "cs.HC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19530", "title": "Clinical-Grade Blood Pressure Prediction in ICU Settings: An Ensemble Framework with Uncertainty Quantification and Cross-Institutional Validation", "authors": ["Md Basit Azam", "Sarangthem Ibotombi Singh"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19530v1", "summary": "Blood pressure (BP) monitoring is critical in in tensive care units (ICUs)\nwhere hemodynamic instability can\n  rapidly progress to cardiovascular collapse. Current machine\n  learning (ML) approaches suffer from three limitations: lack of\n  external validation, absence of uncertainty quantification, and\n  inadequate data leakage prevention. This study presents the\n  first comprehensive framework with novel algorithmic leakage\n  prevention, uncertainty quantification, and cross-institutional\n  validation for electronic health records (EHRs) based BP pre dictions. Our\nmethodology implemented systematic data leakage\n  prevention, uncertainty quantification through quantile regres sion, and\nexternal validation between the MIMIC-III and eICU\n  databases. An ensemble framework combines Gradient Boosting,\n  Random Forest, and XGBoost with 74 features across five\n  physiological domains. Internal validation achieved a clinically\n  acceptable performance (for SBP: R^2 = 0.86, RMSE = 6.03\n  mmHg; DBP: R^2 = 0.49, RMSE = 7.13 mmHg), meeting AAMI\n  standards. External validation showed 30% degradation with\n  critical limitations in patients with hypotensive. Uncertainty\n  quantification generated valid prediction intervals (80.3% SBP\n  and 79.9% DBP coverage), enabling risk-stratified protocols\n  with narrow intervals (< 15 mmHg) for standard monitoring\n  and wide intervals (> 30 mmHg) for manual verification. This\n  framework provides realistic deployment expectations for cross institutional\nAI-assisted BP monitoring in critical care settings.\n  The source code is publicly available at https://github.com/\n  mdbasit897/clinical-bp-prediction-ehr.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19530v1", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.19951", "title": "PDLogger: Automated Logging Framework for Practical Software Development", "authors": ["Shengcheng Duan", "Yihua Xu", "Sheng Zhang", "Shen Wang", "Yue Duan"], "categories": ["cs.SE", "D.2"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      10 pages, 10 figures", "url": "http://arxiv.org/abs/2507.19951v1", "summary": "Logging is indispensable for maintaining the reliability and diagnosability\nof modern software, yet developers still struggle to decide where and how to\nlog effectively. Existing automated logging techniques focus on isolated\nsub-tasks - predicting a single log position, level, or message - and therefore\ncannot produce complete, high-quality log statements that reflect real-world\npractice in which multiple logs often appear inside one method. They also\nneglect deeper semantic dependencies among methods and consider only a narrow\nset of candidate variables, leading to superficial or incomplete logs. In this\npaper, we present PDLogger, the first end-to-end log generation technique\nexpressly designed for practical, multi-log scenarios. PDLogger operates in\nthree phases. (1) Log position prediction: block-type-aware structured prompts\nguide a large language model (LLM) to suggest candidate positions across all\ncontrol-flow blocks of a method. (2) Log generation: backward program slicing\nsupplies precise inter-procedural control and data-dependency context, while an\nexpanded variable extractor captures both member and external function\nexpressions; the enriched prompt enables the LLM to emit a full log statement\n(position, level, message, variables). (3) Log refinement: level correction and\ncontext-sensitive deduplication prune false positives and redundant logs. We\nevaluate PDLogger on 3,113 log statements drawn from two widely used Java\nprojects. Compared with the strongest prior systems, PDLogger improves\nlog-position precision by 139.0 percent, F1 by 69.2 percent, level accuracy by\n82.3 percent, variable precision by 131.8 percent, and message quality\n(BERTScore) by 65.7 percent. The framework consistently performs well with\ndifferent mainstream LLMs, demonstrating robustness and generality. PDLogger's\nimplementation is available as open source to foster future research and\nadoption.", "comment": "10 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.19951v1", "cate": "cs.SE", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20115", "title": "Packet-Level DDoS Data Augmentation Using Dual-Stream Temporal-Field Diffusion", "authors": ["Gongli Xi", "Ye Tian", "Yannan Hu", "Yuchao Zhang", "Yapeng Niu", "Xiangyang Gong"], "categories": ["cs.NI", "cs.AI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      11 pages, 5 figures", "url": "http://arxiv.org/abs/2507.20115v1", "summary": "In response to Distributed Denial of Service (DDoS) attacks, recent research\nefforts increasingly rely on Machine Learning (ML)-based solutions, whose\neffectiveness largely depends on the quality of labeled training datasets. To\naddress the scarcity of such datasets, data augmentation with synthetic traces\nis often employed. However, current synthetic trace generation methods struggle\nto capture the complex temporal patterns and spatial distributions exhibited in\nemerging DDoS attacks. This results in insufficient resemblance to real traces\nand unsatisfied detection accuracy when applied to ML tasks. In this paper, we\npropose Dual-Stream Temporal-Field Diffusion (DSTF-Diffusion), a multi-view,\nmulti-stream network traffic generative model based on diffusion models,\nfeaturing two main streams: The field stream utilizes spatial mapping to bridge\nnetwork data characteristics with pre-trained realms of stable diffusion\nmodels, effectively translating complex network interactions into formats that\nstable diffusion can process, while the spatial stream adopts a dynamic\ntemporal modeling approach, meticulously capturing the intrinsic temporal\npatterns of network traffic. Extensive experiments demonstrate that data\ngenerated by our model exhibits higher statistical similarity to originals\ncompared to current state-of-the-art solutions, and enhance performances on a\nwide range of downstream tasks.", "comment": "11 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.20115v1", "cate": "cs.NI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19816", "title": "Efficient Computation of Marton's Error Exponent via Constraint Decoupling", "authors": ["Jiachuan Ye", "Shitong Wu", "Lingyi Chen", "Wenyi Zhang", "Huihui Wu", "Hao Wu"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19816v1", "summary": "The error exponent in lossy source coding characterizes the asymptotic decay\nrate of error probability with respect to blocklength. The Marton's error\nexponent provides the theoretically optimal bound on this rate. However,\ncomputation methods of the Marton's error exponent remain underdeveloped due to\nits formulation as a non-convex optimization problem with limited efficient\nsolvers. While a recent grid search algorithm can compute its inverse function,\nit incurs prohibitive computational costs from two-dimensional brute-force\nparameter grid searches. This paper proposes a composite maximization approach\nthat effectively handles both Marton's error exponent and its inverse function.\nThrough a constraint decoupling technique, the resulting problem formulations\nadmit efficient solvers driven by an alternating maximization algorithm. By\nfixing one parameter via a one-dimensional line search, the remaining\nsubproblem becomes convex and can be efficiently solved by alternating variable\nupdates, thereby significantly reducing search complexity. Therefore, the\nglobal convergence of the algorithm can be guaranteed. Numerical experiments\nfor simple sources and the Ahlswede's counterexample, demonstrates the superior\nefficiency of our algorithm in contrast to existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19816v1", "cate": "cs.IT", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19819", "title": "ChipletPart: Scalable Cost-Aware Partitioning for 2.5D Systems", "authors": ["Alexander Graening", "Puneet Gupta", "Andrew B. Kahng", "Bodhisatta Pramanik", "Zhiang Wang"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      14 pages, 13 figures", "url": "http://arxiv.org/abs/2507.19819v1", "summary": "Industry adoption of chiplets has been increasing as a cost-effective option\nfor making larger high-performance systems. Consequently, partitioning large\nsystems into chiplets is increasingly important. In this work, we introduce\nChipletPart - a cost-driven 2.5D system partitioner that addresses the unique\nconstraints of chiplet systems, including complex objective functions, limited\nreach of inter-chiplet I/O transceivers, and the assignment of heterogeneous\nmanufacturing technologies to different chiplets. ChipletPart integrates a\nsophisticated chiplet cost model with its underlying genetic algorithm-based\ntechnology assignment and partitioning methodology, along with a simulated\nannealing-based chiplet floorplanner. Our results show that: (i) ChipletPart\nreduces chiplet cost by up to 58% (20% geometric mean) compared to\nstate-of-the-art min-cut partitioners, which often yield floorplan-infeasible\nsolutions; (ii) ChipletPart generates partitions with up to 47% (6% geometric\nmean) lower cost as compared to the prior work Floorplet; and (iii) for the\ntestcases we study, heterogeneous integration reduces cost by up to 43% (15%\ngeometric mean) compared to homogeneous implementations. We also present case\nstudies that show how changes in packaging or inter-chiplet signaling\ntechnologies can affect partitioning solutions. Finally, we make ChipletPart,\nthe underlying chiplet cost model, and a chiplet testcase generator available\nas open-source tools for the community.", "comment": "14 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.19819v1", "cate": "cs.AR", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2503.10549", "title": "MASQUE: A Text-Guided Diffusion-Based Framework for Localized and Customized Adversarial Makeup", "authors": ["Youngjin Kwon", "Xiao Zhang"], "categories": ["cs.CV", "cs.CR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.10549v2", "summary": "As facial recognition is increasingly adopted for government and commercial\nservices, its potential misuse has raised serious concerns about privacy and\ncivil rights. To counteract, various anti-facial recognition techniques have\nbeen proposed for privacy protection by adversarially perturbing face images,\namong which generative makeup-based approaches are the most popular. However,\nthese methods, designed primarily to impersonate specific target identities,\ncan only achieve weak dodging success rates while increasing the risk of\ntargeted abuse. In addition, they often introduce global visual artifacts or a\nlack of adaptability to accommodate diverse makeup prompts, compromising user\nsatisfaction. To address the above limitations, we develop MASQUE, a novel\ndiffusion-based framework that generates localized adversarial makeups guided\nby user-defined text prompts. Built upon precise null-text inversion,\ncustomized cross-attention fusion with masking, and a pairwise adversarial\nguidance mechanism using images of the same individual, MASQUE achieves robust\ndodging performance without requiring any external identity. Comprehensive\nevaluations on open-source facial recognition models and commercial APIs\ndemonstrate that MASQUE significantly improves dodging success rates over all\nbaselines, along with higher perceptual fidelity and stronger adaptability to\nvarious text makeup prompts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.10549v2", "cate": "cs.CV", "date": "2025-03-13", "updated": "2025-07-27"}
{"id": "2507.20445", "title": "Learning Physical Interaction Skills from Human Demonstrations", "authors": ["Tianyu Li", "Hengbo Ma", "Sehoon Ha", "Kwonjoon Lee"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20445v1", "summary": "Learning physical interaction skills, such as dancing, handshaking, or\nsparring, remains a fundamental challenge for agents operating in human\nenvironments, particularly when the agent's morphology differs significantly\nfrom that of the demonstrator. Existing approaches often rely on handcrafted\nobjectives or morphological similarity, limiting their capacity for\ngeneralization. Here, we introduce a framework that enables agents with diverse\nembodiments to learn wholebbody interaction behaviors directly from human\ndemonstrations. The framework extracts a compact, transferable representation\nof interaction dynamics, called the Embedded Interaction Graph (EIG), which\ncaptures key spatiotemporal relationships between the interacting agents. This\ngraph is then used as an imitation objective to train control policies in\nphysics-based simulations, allowing the agent to generate motions that are both\nsemantically meaningful and physically feasible. We demonstrate BuddyImitation\non multiple agents, such as humans, quadrupedal robots with manipulators, or\nmobile manipulators and various interaction scenarios, including sparring,\nhandshaking, rock-paper-scissors, or dancing. Our results demonstrate a\npromising path toward coordinated behaviors across morphologically distinct\ncharacters via cross embodiment interaction learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20445v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20226", "title": "Improving Subgraph Matching by Combining Algorithms and Graph Neural Networks", "authors": ["Shuyang Guo", "Wenjin Xie", "Ping Lu", "Ting Deng", "Richong Zhang", "Jianxin Li", "Xiangping Huang", "Zhongyi Liu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20226v1", "summary": "Homomorphism is a key mapping technique between graphs that preserves their\nstructure. Given a graph and a pattern, the subgraph homomorphism problem\ninvolves finding a mapping from the pattern to the graph, ensuring that\nadjacent vertices in the pattern are mapped to adjacent vertices in the graph.\nUnlike subgraph isomorphism, which requires a one-to-one mapping, homomorphism\nallows multiple vertices in the pattern to map to the same vertex in the graph,\nmaking it more complex. We propose HFrame, the first graph neural network-based\nframework for subgraph homomorphism, which integrates traditional algorithms\nwith machine learning techniques. We demonstrate that HFrame outperforms\nstandard graph neural networks by being able to distinguish more graph pairs\nwhere the pattern is not homomorphic to the graph. Additionally, we provide a\ngeneralization error bound for HFrame. Through experiments on both real-world\nand synthetic graphs, we show that HFrame is up to 101.91 times faster than\nexact matching algorithms and achieves an average accuracy of 0.962.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20226v1", "cate": "cs.AI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20006", "title": "Beyond the Broadcast: Enhancing VR Tennis Broadcasting through Embedded Visualizations and Camera Techniques", "authors": ["Jun-Hsiang Yao", "Jielin Feng", "Xinfang Tian", "Kai Xu", "Gulshat Amirkhanova", "Siming Chen"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      11 pages, 6 figures", "url": "http://arxiv.org/abs/2507.20006v1", "summary": "Virtual Reality (VR) broadcasting has emerged as a promising medium for\nproviding immersive viewing experiences of major sports events such as tennis.\nHowever, current VR broadcast systems often lack an effective camera language\nand do not adequately incorporate dynamic, in-game visualizations, limiting\nviewer engagement and narrative clarity. To address these limitations, we\nanalyze 400 out-of-play segments from eight major tennis broadcasts to develop\na tennis-specific design framework that effectively combines cinematic camera\nmovements with embedded visualizations. We further refine our framework by\nexamining 25 cinematic VR animations, comparing their camera techniques with\ntraditional tennis broadcasts to identify key differences and inform\nadaptations for VR. Based on data extracted from the broadcast videos, we\nreconstruct a simulated game that captures the players' and ball's motion and\ntrajectories. Leveraging this design framework and processing pipeline, we\ndevelope Beyond the Broadcast, a VR tennis viewing system that integrates\nembedded visualizations with adaptive camera motions to construct a\ncomprehensive and engaging narrative. Our system dynamically overlays tactical\ninformation and key match events onto the simulated environment, enhancing\nviewer comprehension and narrative engagement while ensuring perceptual\nimmersion and viewing comfort. A user study involving tennis viewers\ndemonstrate that our approach outperforms traditional VR broadcasting methods\nin delivering an immersive, informative viewing experience.", "comment": "11 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.20006v1", "cate": "cs.HC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19534", "title": "FedDPG: An Adaptive Yet Efficient Prompt-tuning Approach in Federated Learning Settings", "authors": ["Ali Shakeri", "Wei Emma Zhang", "Amin Beheshti", "Weitong Chen", "Jian Yang", "Lishan Yang"], "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2; I.7"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages; Published to PAKDD'2025", "url": "http://arxiv.org/abs/2507.19534v1", "summary": "Pre-trained Language Models (PLMs) have demonstrated impressive performance\nin various NLP tasks. However, traditional fine-tuning methods for leveraging\nPLMs for downstream tasks entail significant computational overhead.\nPrompt-tuning has emerged as an efficient alternative that involves prepending\na limited number of parameters to the input sequence and only updating them\nwhile the PLM's parameters are frozen. However, this technique's prompts remain\nfixed for all inputs, reducing the model's flexibility. The Federated Learning\n(FL) technique has gained attention in recent years to address the growing\nconcerns around data privacy. However, challenges such as communication and\ncomputation limitations of clients still need to be addressed. To mitigate\nthese challenges, this paper introduces the Federated Dynamic Prompt Generator\n(FedDPG), which incorporates a dynamic prompt generator network to generate\ncontext-aware prompts based on the given input, ensuring flexibility and\nadaptability while prioritising data privacy in federated learning settings.\nOur experiments on three NLP benchmark datasets showcase that FedDPG\noutperforms the state-of-the-art parameter-efficient fine-tuning methods in\nterms of global model performance, and has significantly reduced the\ncalculation time and the number of parameters to be sent through the FL\nnetwork.", "comment": "12 pages; Published to PAKDD'2025", "pdf_url": "http://arxiv.org/pdf/2507.19534v1", "cate": "cs.LG", "date": "2025-07-22", "updated": "2025-07-22"}
{"id": "2507.20081", "title": "The Effect of Pointer Analysis on Semantic Conflict Detection", "authors": ["Matheus Barbosa", "Paulo Borba", "Rodrigo Bonifácio", "Victor Lira", "Galileu Santos"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20081v1", "summary": "Current merge tools don't detect semantic conflicts, which occur when changes\nfrom different developers are textually integrated but semantically interfere\nwith each other. Although researchers have proposed static analyses for\ndetecting semantic conflicts, these analyses suffer from significant false\npositive rates. To understand whether such false positives could be reduced by\nusing pointer analysis in the implementation of semantic conflict static\nanalyses, we conduct an empirical study. We implement the same analysis with\nand without pointer analysis, run them on two datasets, observe how often they\ndiffer, and compare their accuracy and computational performance. Although\npointer analysis is known to improve precision in static analysis, we find that\nits effect on semantic conflict detection can be drastic: we observe a\nsignificant reduction in timeouts and false positives, but also a significant\nincrease in false negatives, with prohibitive drops in recall and F1-score.\nThese results suggest that, in the context of semantic conflict detection, we\nshould explore hybrid analysis techniques, combining aspects of both\nimplementations we compare in our study.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20081v1", "cate": "cs.SE", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20116", "title": "Accelerating Containerized Service Delivery at the Network Edge", "authors": ["Yinuo Deng", "Hailiang Zhao", "Dongjing Wang", "Peng Chen", "Wenzhuo Qian", "Jianwei Yin", "Schahram Dustdar", "Shuiguang Deng"], "categories": ["cs.NI", "cs.DC"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20116v1", "summary": "Efficient container image distribution is crucial for enabling machine\nlearning inference at the network edge, where resource limitations and dynamic\nnetwork conditions create significant challenges. In this paper, we present\nPeerSync, a decentralized P2P-based system designed to optimize image\ndistribution in edge environments. PeerSync employs a popularity- and\nnetwork-aware download engine that dynamically adapts to content popularity and\nreal-time network conditions using a sliding window mechanism. PeerSync further\nintegrates automated tracker election for rapid peer discovery and dynamic\ncache management for efficient storage utilization. We implement PeerSync with\n8000+ lines of Rust code and test its performance extensively on both physical\nedge devices and Docker-based emulations. Experimental results show that\nPeerSync delivers a remarkable speed increase of 2.72$\\times$, 1.79$\\times$,\nand 1.28$\\times$ compared to the Baseline, Dragonfly, and Kraken, respectively,\nwhile significantly reducing peak cross-network traffic by 90.72\\% under\ncongested and varying network conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20116v1", "cate": "cs.NI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19832", "title": "Neural Estimation of the Information Bottleneck Based on a Mapping Approach", "authors": ["Lingyi Chen", "Shitong Wu", "Sicheng Xu", "Huihui Wu", "Wenyi Zhang"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      5 pages, 2 figures. This paper has been presented at the 2024 IEEE Information Theory Workshop (ITW 2024)", "url": "http://arxiv.org/abs/2507.19832v1", "summary": "The information bottleneck (IB) method is a technique designed to extract\nmeaningful information related to one random variable from another random\nvariable, and has found extensive applications in machine learning problems. In\nthis paper, neural network based estimation of the IB problem solution is\nstudied, through the lens of a novel formulation of the IB problem. Via\nexploiting the inherent structure of the IB functional and leveraging the\nmapping approach, the proposed formulation of the IB problem involves only a\nsingle variable to be optimized, and subsequently is readily amenable to\ndata-driven estimators based on neural networks. A theoretical analysis is\nconducted to guarantee that the neural estimator asymptotically solves the IB\nproblem, and the numerical experiments on both synthetic and MNIST datasets\ndemonstrate the effectiveness of the neural estimator.", "comment": "5 pages, 2 figures. This paper has been presented at the 2024 IEEE\n  Information Theory Workshop (ITW 2024)", "pdf_url": "http://arxiv.org/pdf/2507.19832v1", "cate": "cs.IT", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20412", "title": "RoCE BALBOA: Service-enhanced Data Center RDMA for SmartNICs", "authors": ["Maximilian Jakob Heer", "Benjamin Ramhorst", "Yu Zhu", "Luhao Liu", "Zhiyi Hu", "Jonas Dann", "Gustavo Alonso"], "categories": ["cs.AR", "cs.NI"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20412v1", "summary": "Data-intensive applications in data centers, especially machine learning\n(ML), have made the network a bottleneck, which in turn has motivated the\ndevelopment of more efficient network protocols and infrastructure. For\ninstance, remote direct memory access (RDMA) has become the standard protocol\nfor data transport in the cloud as it minimizes data copies and reduces\nCPU-utilization via host-bypassing. Similarly, an increasing amount of network\nfunctions and infrastructure have moved to accelerators, SmartNICs, and\nin-network computing to bypass the CPU. In this paper we explore the\nimplementation and deployment of RoCE BALBOA, an open-source, RoCE\nv2-compatible, scalable up to hundreds of queue-pairs, and 100G-capable\nRDMA-stack that can be used as the basis for building accelerators and\nsmartNICs. RoCE BALBOA is customizable, opening up a design space and offering\na degree of adaptability not available in commercial products. We have deployed\nBALBOA in a cluster using FPGAs and show that it has latency and performance\ncharacteristics comparable to commercial NICs. We demonstrate its potential by\nexploring two classes of use cases. One involves enhancements to the protocol\nfor infrastructure purposes (encryption, deep packet inspection using ML). The\nother showcases the ability to perform line-rate compute offloads with deep\npipelines by implementing commercial data preprocessing pipelines for\nrecommender systems that process the data as it arrives from the network before\ntransferring it directly to the GPU. These examples demonstrate how BALBOA\nenables the exploration and development of SmartNICs and accelerators operating\non network data streams.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20412v1", "cate": "cs.AR", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2504.04041", "title": "Authenticated Sublinear Quantum Private Information Retrieval", "authors": ["Fengxia Liu", "Zhiyong Zheng", "Kun Tian", "Yi Zhang", "Heng Guo", "Zhe Hu", "Oleksiy Zhedanov", "Zixian Gong"], "categories": ["quant-ph", "cs.CR"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.04041v3", "summary": "This paper introduces a novel lower bound on communication complexity using\nquantum relative entropy and mutual information, refining previous classical\nentropy-based results. By leveraging Uhlmann's lemma and quantum Pinsker\ninequalities, the authors establish tighter bounds for information-theoretic\nsecurity, demonstrating that quantum protocols inherently outperform classical\ncounterparts in balancing privacy and efficiency. Also explores symmetric\nQuantum Private Information Retrieval (QPIR) protocols that achieve sub-linear\ncommunication complexity while ensuring robustness against specious\nadversaries: A post-quantum cryptography based protocol that can be\nauthenticated for the specious server; A ring-LWE-based protocol for\npost-quantum security in a single-server setting, ensuring robustness against\nquantum attacks; A multi-server protocol optimized for hardware practicality,\nreducing implementation overhead while maintaining sub-linear efficiency. These\nprotocols address critical gaps in secure database queries, offering\nexponential communication improvements over classical linear-complexity\nmethods. The work also analyzes security trade-offs under quantum specious\nadversaries, providing theoretical guarantees for privacy and correctness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.04041v3", "cate": "quant-ph", "date": "2025-04-05", "updated": "2025-07-26"}
{"id": "2507.20509", "title": "LLMs-guided adaptive compensator: Bringing Adaptivity to Automatic Control Systems with Large Language Models", "authors": ["Zhongchao Zhou", "Yuxi Lu", "Yaonan Zhu", "Yifan Zhao", "Bin He", "Liang He", "Wenwen Yu", "Yusuke Iwasawa"], "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20509v1", "summary": "With rapid advances in code generation, reasoning, and problem-solving, Large\nLanguage Models (LLMs) are increasingly applied in robotics. Most existing work\nfocuses on high-level tasks such as task decomposition. A few studies have\nexplored the use of LLMs in feedback controller design; however, these efforts\nare restricted to overly simplified systems, fixed-structure gain tuning, and\nlack real-world validation. To further investigate LLMs in automatic control,\nthis work targets a key subfield: adaptive control. Inspired by the framework\nof model reference adaptive control (MRAC), we propose an LLM-guided adaptive\ncompensator framework that avoids designing controllers from scratch. Instead,\nthe LLMs are prompted using the discrepancies between an unknown system and a\nreference system to design a compensator that aligns the response of the\nunknown system with that of the reference, thereby achieving adaptivity.\nExperiments evaluate five methods: LLM-guided adaptive compensator, LLM-guided\nadaptive controller, indirect adaptive control, learning-based adaptive\ncontrol, and MRAC, on soft and humanoid robots in both simulated and real-world\nenvironments. Results show that the LLM-guided adaptive compensator outperforms\ntraditional adaptive controllers and significantly reduces reasoning complexity\ncompared to the LLM-guided adaptive controller. The Lyapunov-based analysis and\nreasoning-path inspection demonstrate that the LLM-guided adaptive compensator\nenables a more structured design process by transforming mathematical\nderivation into a reasoning task, while exhibiting strong generalizability,\nadaptability, and robustness. This study opens a new direction for applying\nLLMs in the field of automatic control, offering greater deployability and\npracticality compared to vision-language models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20509v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20280", "title": "SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration", "authors": ["Keyan Ding", "Jing Yu", "Junjie Huang", "Yuchen Yang", "Qiang Zhang", "Huajun Chen"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      21 pages, 6 figures", "url": "http://arxiv.org/abs/2507.20280v1", "summary": "Scientific research increasingly relies on specialized computational tools,\nyet effectively utilizing these tools demands substantial domain expertise.\nWhile Large Language Models (LLMs) show promise in tool automation, they\nstruggle to seamlessly integrate and orchestrate multiple tools for complex\nscientific workflows. Here, we present SciToolAgent, an LLM-powered agent that\nautomates hundreds of scientific tools across biology, chemistry, and materials\nscience. At its core, SciToolAgent leverages a scientific tool knowledge graph\nthat enables intelligent tool selection and execution through graph-based\nretrieval-augmented generation. The agent also incorporates a comprehensive\nsafety-checking module to ensure responsible and ethical tool usage. Extensive\nevaluations on a curated benchmark demonstrate that SciToolAgent significantly\noutperforms existing approaches. Case studies in protein engineering, chemical\nreactivity prediction, chemical synthesis, and metal-organic framework\nscreening further demonstrate SciToolAgent's capability to automate complex\nscientific workflows, making advanced research tools accessible to both experts\nand non-experts.", "comment": "21 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.20280v1", "cate": "cs.AI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20137", "title": "Dynamite: Real-Time Debriefing Slide Authoring through AI-Enhanced Multimodal Interaction", "authors": ["Panayu Keelawat", "David Barron", "Kaushik Narasimhan", "Daniel Manesh", "Xiaohang Tang", "Xi Chen", "Sang Won Lee", "Yan Chen"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted to VL/HCC 2025", "url": "http://arxiv.org/abs/2507.20137v1", "summary": "Facilitating class-wide debriefings after small-group discussions is a common\nstrategy in ethics education. Instructor interviews revealed that effective\ndebriefings should highlight frequently discussed themes and surface\nunderrepresented viewpoints, making accurate representations of insight\noccurrence essential. Yet authoring presentations in real time is cognitively\noverwhelming due to the volume of data and tight time constraints. We present\nDynamite, an AI-assisted system that enables semantic updates to\ninstructor-authored slides during live classroom discussions. These updates are\npowered by semantic data binding, which links slide content to evolving\ndiscussion data, and semantic suggestions, which offer revision options aligned\nwith pedagogical goals. In a within-subject in-lab study with 12 participants,\nDynamite outperformed a text-based AI baseline in content accuracy and quality.\nParticipants used voice and sketch input to quickly organize semantic blocks,\nthen applied suggestions to accelerate refinement as data stabilized.", "comment": "Accepted to VL/HCC 2025", "pdf_url": "http://arxiv.org/pdf/2507.20137v1", "cate": "cs.HC", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19536", "title": "Graph Learning Metallic Glass Discovery from Wikipedia", "authors": ["K. -C. Ouyang", "S. -Y. Zhang", "S. -L. Liu", "J. Tian", "Y. -H. Li", "H. Tong", "H. -Y. Bai", "W. -H. Wang", "Y. -C. Hu"], "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.mtrl-sci", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      7 figures", "url": "http://arxiv.org/abs/2507.19536v1", "summary": "Synthesizing new materials efficiently is highly demanded in various research\nfields. However, this process is usually slow and expensive, especially for\nmetallic glasses, whose formation strongly depends on the optimal combinations\nof multiple elements to resist crystallization. This constraint renders only\nseveral thousands of candidates explored in the vast material space since 1960.\nRecently, data-driven approaches armed by advanced machine learning techniques\nprovided alternative routes for intelligent materials design. Due to data\nscarcity and immature material encoding, the conventional tabular data is\nusually mined by statistical learning algorithms, giving limited model\npredictability and generalizability. Here, we propose sophisticated data\nlearning from material network representations. The node elements are encoded\nfrom the Wikipedia by a language model. Graph neural networks with versatile\narchitectures are designed to serve as recommendation systems to explore hidden\nrelationships among materials. By employing Wikipedia embeddings from different\nlanguages, we assess the capability of natural languages in materials design.\nOur study proposes a new paradigm to harvesting new amorphous materials and\nbeyond with artificial intelligence.", "comment": "7 figures", "pdf_url": "http://arxiv.org/pdf/2507.19536v1", "cate": "cs.LG", "date": "2025-07-22", "updated": "2025-07-22"}
{"id": "2507.20095", "title": "From First Use to Final Commit: Studying the Evolution of Multi-CI Service Adoption", "authors": ["Nitika Chopra", "Taher A. Ghaleb"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at the 41st IEEE International Conference on Software Maintenance and Evolution 2025 (ICSME'25)", "url": "http://arxiv.org/abs/2507.20095v1", "summary": "Continuous Integration (CI) services, such as GitHub Actions and Travis CI,\nare widely adopted in open-source development to automate testing and\ndeployment. Though existing research often examines individual services in\nisolation, it remains unclear how projects adopt and transition between\nmultiple services over time. To understand how CI adoption is evolving across\nservices, we present a preliminary study analyzing the historical CI adoption\nof 18,924 Java projects hosted on GitHub between January 2008 and December\n2024, adopting at least one of eight CI services, namely Travis CI, AppVeyor,\nCircleCI, Azure Pipelines, GitHub Actions, Bitbucket, GitLab CI, and Cirrus CI.\nSpecifically, we investigate: (1) how frequently CI services are co-adopted or\nreplaced, and (2) how maintenance activity varies across different services.\nOur analysis shows that the use of multiple CI services within the same project\nis a recurring pattern observed in nearly one in five projects, often\nreflecting migration across CI services. Our study is among the first to\nexamine multi-CI adoption in practice, offering new insights for future\nresearch and highlighting the need for strategies and tools to support service\nselection, coordination, and migration in evolving CI environments.", "comment": "Accepted at the 41st IEEE International Conference on Software\n  Maintenance and Evolution 2025 (ICSME'25)", "pdf_url": "http://arxiv.org/pdf/2507.20095v1", "cate": "cs.SE", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20367", "title": "Joint Fiber and Free Space Optical Infrastructure Planning for Hybrid Integrated Access and Backhaul Networks", "authors": ["Charitha Madapatha", "Piotr Lechowicz", "Carlos Natalino", "Paolo Monti", "Tommy Svensson"], "categories": ["cs.NI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Accepted invited paper for IEEE PIMRC 2025, Istanbul, Turkey", "url": "http://arxiv.org/abs/2507.20367v1", "summary": "Integrated access and backhaul (IAB) is one of the promising techniques for\n5G networks and beyond (6G), in which the same node/hardware is used to provide\nboth backhaul and cellular services in a multi-hop architecture. Due to the\nsensitivity of the backhaul links with high rate/reliability demands, proper\nnetwork planning is needed to ensure the IAB network performs with the desired\nperformance levels. In this paper, we study the effect of infrastructure\nplanning and optimization on the coverage of IAB networks. We concentrate on\nthe cases where the fiber connectivity to the nodes is constrained due to cost.\nThereby, we study the performance gains and energy efficiency in the presence\nof free-space optical (FSO) communication links. Our results indicate hybrid\nfiber/FSO deployments offer substantial cost savings compared to fully fibered\nnetworks, suggesting a beneficial trade-off for strategic link deployment while\nimproving the service coverage probability. As we show, with proper network\nplanning, the service coverage, energy efficiency, and cost efficiency can be\nimproved.", "comment": "Accepted invited paper for IEEE PIMRC 2025, Istanbul, Turkey", "pdf_url": "http://arxiv.org/pdf/2507.20367v1", "cate": "cs.NI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19920", "title": "An Efficient Alternating Minimization Algorithm for Computing Quantum Rate-Distortion Function", "authors": ["Lingyi Chen", "Deheng Yuan", "Wenyi Zhang", "Hao Wu", "Huihui Wu"], "categories": ["cs.IT", "math.IT", "quant-ph"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19920v1", "summary": "We consider the computation of the entanglement-assisted quantum\nrate-distortion function, which plays a central role in quantum information\ntheory. We propose an efficient alternating minimization algorithm based on the\nLagrangian analysis. Instead of fixing the multiplier corresponding to the\ndistortion constraint, we update the multiplier in each iteration. Hence the\nalgorithm solves the original problem itself, rather than the Lagrangian\nrelaxation of it. Moreover, all the other variables are iterated in closed form\nwithout solving multi-dimensional nonlinear equations or multivariate\noptimization problems. Numerical experiments show the accuracy of our proposed\nalgorithm and its improved efficiency over existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19920v1", "cate": "cs.IT", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20420", "title": "Demystifying the 7-D Convolution Loop Nest for Data and Instruction Streaming in Reconfigurable AI Accelerators", "authors": ["Md Rownak Hossain Chowdhury", "Mostafizur Rahman"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20420v1", "summary": "Convolution remains the most compute-intensive operation in AI acceleration,\noften constituting over 80-90% of the workload. Existing approaches in spatial\narchitectures such as coarse-grained reconfigurable arrays (CGRAs) and\nfield-programmable gate arrays (FPGAs) frequently rely on loop unrolling or\nGEMM-based matrix transformations, introducing significant overhead in both\ndata movement and instruction control. This paper presents a new framework\ndesigned to systematically demystify the 7-dimensional convolution loop nest by\nreinterpreting it as a hardware-centric data and instruction streaming problem.\nInstead of treating the loop nest as a fixed computational construct, our\napproach exposes its structure as a set of spatial and temporal mappings\ngoverned by hardware parameters such as compute element distribution,\ninterconnect topology, and reconfigurability. This abstraction supports\nlightweight, flexible deployment of convolution without reliance on heavyweight\ntransformations or reordering schemes. We demonstrate the application of our\napproach on the MAVeC accelerator. We detail the implementation of convolution\noperations in MAVeC and extend the framework to support full model execution on\nVGG-16. Our profiling reveals high PE utilization (over 90%), significant fold\nreuse, and scalable throughput up to 1.56 TFLOPs/sec and 12.7 KIPS for\nend-to-end VGG-16 inference. These results validate the efficacy of our\napproach in minimizing control overhead, improving data locality, and enabling\nefficient large-scale convolution execution without reliance on conventional\ntransformation-based methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20420v1", "cate": "cs.AR", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.18657", "title": "VGS-ATD: Robust Distributed Learning for Multi-Label Medical Image Classification Under Heterogeneous and Imbalanced Conditions", "authors": ["Zehui Zhao", "Laith Alzubaidi", "Haider A. Alwzwazy", "Jinglan Zhang", "Yuantong Gu"], "categories": ["cs.CV", "cs.CR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      The idea is still underdeveloped, not yet enough to be published", "url": "http://arxiv.org/abs/2507.18657v2", "summary": "In recent years, advanced deep learning architectures have shown strong\nperformance in medical imaging tasks. However, the traditional centralized\nlearning paradigm poses serious privacy risks as all data is collected and\ntrained on a single server. To mitigate this challenge, decentralized\napproaches such as federated learning and swarm learning have emerged, allowing\nmodel training on local nodes while sharing only model weights. While these\nmethods enhance privacy, they struggle with heterogeneous and imbalanced data\nand suffer from inefficiencies due to frequent communication and the\naggregation of weights. More critically, the dynamic and complex nature of\nclinical environments demands scalable AI systems capable of continuously\nlearning from diverse modalities and multilabels. Yet, both centralized and\ndecentralized models are prone to catastrophic forgetting during system\nexpansion, often requiring full model retraining to incorporate new data. To\naddress these limitations, we propose VGS-ATD, a novel distributed learning\nframework. To validate VGS-ATD, we evaluate it in experiments spanning 30\ndatasets and 80 independent labels across distributed nodes, VGS-ATD achieved\nan overall accuracy of 92.7%, outperforming centralized learning (84.9%) and\nswarm learning (72.99%), while federated learning failed under these conditions\ndue to high requirements on computational resources. VGS-ATD also demonstrated\nstrong scalability, with only a 1% drop in accuracy on existing nodes after\nexpansion, compared to a 20% drop in centralized learning, highlighting its\nresilience to catastrophic forgetting. Additionally, it reduced computational\ncosts by up to 50% relative to both centralized and swarm learning, confirming\nits superior efficiency and scalability.", "comment": "The idea is still underdeveloped, not yet enough to be published", "pdf_url": "http://arxiv.org/pdf/2507.18657v2", "cate": "cs.CV", "date": "2025-07-23", "updated": "2025-07-28"}
{"id": "2507.20516", "title": "Large-Scale LiDAR-Inertial Dataset for Degradation-Robust High-Precision Mapping", "authors": ["Xiaofeng Jin", "Ningbo Bu", "Shijie Wang", "Jianfei Ge", "Jiangjian Xiao", "Matteo Matteucci"], "categories": ["cs.RO", "68T40", "I.2.9"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      9 pages,7 figures, 6 tables", "url": "http://arxiv.org/abs/2507.20516v1", "summary": "This paper introduces a large-scale, high-precision LiDAR-Inertial Odometry\n(LIO) dataset, aiming to address the insufficient validation of LIO systems in\ncomplex real-world scenarios in existing research. The dataset covers four\ndiverse real-world environments spanning 60,000 to 750,000 square meters,\ncollected using a custom backpack-mounted platform equipped with multi-beam\nLiDAR, an industrial-grade IMU, and RTK-GNSS modules. The dataset includes long\ntrajectories, complex scenes, and high-precision ground truth, generated by\nfusing SLAM-based optimization with RTK-GNSS anchoring, and validated for\ntrajectory accuracy through the integration of oblique photogrammetry and\nRTK-GNSS. This dataset provides a comprehensive benchmark for evaluating the\ngeneralization ability of LIO systems in practical high-precision mapping\nscenarios.", "comment": "9 pages,7 figures, 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.20516v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20322", "title": "Artificial Intelligence In Patent And Market Intelligence: A New Paradigm For Technology Scouting", "authors": ["Manish Verma", "Vivek Sharma", "Vishal Singh"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Page 4-Figure 1 and Page 11-Figure 2 . A preprint describing a system for AI-powered technology scouting", "url": "http://arxiv.org/abs/2507.20322v1", "summary": "This paper presents the development of an AI powered software platform that\nleverages advanced large language models (LLMs) to transform technology\nscouting and solution discovery in industrial R&D. Traditional approaches to\nsolving complex research and development challenges are often time consuming,\nmanually driven, and heavily dependent on domain specific expertise. These\nmethods typically involve navigating fragmented sources such as patent\nrepositories, commercial product catalogs, and competitor data, leading to\ninefficiencies and incomplete insights. The proposed platform utilizes cutting\nedge LLM capabilities including semantic understanding, contextual reasoning,\nand cross-domain knowledge extraction to interpret problem statements and\nretrieve high-quality, sustainable solutions. The system processes unstructured\npatent texts, such as claims and technical descriptions, and systematically\nextracts potential innovations aligned with the given problem context. These\nsolutions are then algorithmically organized under standardized technical\ncategories and subcategories to ensure clarity and relevance across\ninterdisciplinary domains. In addition to patent analysis, the platform\nintegrates commercial intelligence by identifying validated market solutions\nand active organizations addressing similar challenges. This combined insight\nsourced from both intellectual property and real world product data enables R&D\nteams to assess not only technical novelty but also feasibility, scalability,\nand sustainability. The result is a comprehensive, AI driven scouting engine\nthat reduces manual effort, accelerates innovation cycles, and enhances\ndecision making in complex R&D environments.", "comment": "Page 4-Figure 1 and Page 11-Figure 2 . A preprint describing a system\n  for AI-powered technology scouting", "pdf_url": "http://arxiv.org/pdf/2507.20322v1", "cate": "cs.AI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20261", "title": "Occupational Safety within Non-Routine Manufacturing Processes: Evaluating the Validity of Task-Based Ergonomic Assessments", "authors": ["Charu Tripathi", "Manish Arora", "Amaresh Chakrabarti"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20261v1", "summary": "Direct measurement ergonomic assessment is reshaping occupational safety by\nfacilitating highly reliable risk estimation. Industry 5.0, advocating\nhuman-centricity, has catalysed increasing adoption of direct measurement tools\nin manufacturing industries. However, due to technical and feasibility\nconstraints in their practical implementations, especially within non routine\nmanufacturing processes, task based approach to ergonomic assessment is\nutilized. Despite enabling operationalization of robust ergonomic assessment\ntechnologies within complicated industrial processes, task based approach\nraises several validity concerns. Hence, to ascertain functional utility of the\nresultant safety interventions, this study evaluates the construct validity of\ntask based ergonomic assessment within non routine work utilizing Multitrait\nmultimethod (MTMM) matrix followed by video-based content analysis. Ergonomic\nexposure traits were collected for 46 participants through direct measurement\nand self reported techniques utilizing inertial motion capture and Borg's RPE\nrating scale respectively. Findings include unsubstantiated convergent validity\n(low same trait correlations from 0.149 to 0.243) and weak evidence of\ndiscriminant validity with statistical significance (p value less than 0.001).\nThe study also identifies three primary factors undermining construct validity\nthrough video based content analysis. Findings also elucidate misinterpretation\nof ergonomic risk and action levels. Therefore, practical implications entail\nunderestimation of actual ergonomic risks when estimated through task based\nassessment. This highlights the need for enhancement in ergonomic assessment\ntechnologies focused on cumulative load analysis compatible within diverse\nindustrial processes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20261v1", "cate": "cs.HC", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19539", "title": "Swift-Sarsa: Fast and Robust Linear Control", "authors": ["Khurram Javed", "Richard S. Sutton"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Presented at RLDM 2025", "url": "http://arxiv.org/abs/2507.19539v1", "summary": "Javed, Sharifnassab, and Sutton (2024) introduced a new algorithm for TD\nlearning -- SwiftTD -- that augments True Online TD($\\lambda$) with step-size\noptimization, a bound on the effective learning rate, and step-size decay. In\ntheir experiments SwiftTD outperformed True Online TD($\\lambda$) and\nTD($\\lambda$) on a variety of prediction tasks derived from Atari games, and\nits performance was robust to the choice of hyper-parameters. In this extended\nabstract we extend SwiftTD to work for control problems. We combine the key\nideas behind SwiftTD with True Online Sarsa($\\lambda$) to develop an on-policy\nreinforcement learning algorithm called $\\textit{Swift-Sarsa}$.\n  We propose a simple benchmark for linear on-policy control called the\n$\\textit{operant conditioning benchmark}$. The key challenge in the operant\nconditioning benchmark is that a very small subset of input signals are\nrelevant for decision making. The majority of the signals are noise sampled\nfrom a non-stationary distribution. To learn effectively, the agent must learn\nto differentiate between the relevant signals and the noisy signals, and\nminimize prediction errors by assigning credit to the weight parameters\nassociated with the relevant signals.\n  Swift-Sarsa, when applied to the operant conditioning benchmark, learned to\nassign credit to the relevant signals without any prior knowledge of the\nstructure of the problem. It opens the door for solution methods that learn\nrepresentations by searching over hundreds of millions of features in parallel\nwithout performance degradation due to noisy or bad features.", "comment": "Presented at RLDM 2025", "pdf_url": "http://arxiv.org/pdf/2507.19539v1", "cate": "cs.LG", "date": "2025-07-22", "updated": "2025-07-22"}
{"id": "2507.20109", "title": "Learning to Align Human Code Preferences", "authors": ["Xin Yin", "Chao Ni", "Liushan Chen", "Xiaohu Yang"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20109v1", "summary": "Large Language Models (LLMs) have demonstrated remarkable potential in\nautomating software development tasks. While recent advances leverage\nSupervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) to align\nmodels with human preferences, the optimal training strategy remains unclear\nacross diverse code preference scenarios. This paper systematically\ninvestigates the roles of SFT and DPO in aligning LLMs with different code\npreferences. Through both theoretical analysis and empirical observation, we\nhypothesize that SFT excels in scenarios with objectively verifiable optimal\nsolutions, while applying SFT followed by DPO (S&D) enables models to explore\nsuperior solutions in scenarios without objectively verifiable optimal\nsolutions. Based on the analysis and experimental evidence, we propose Adaptive\nPreference Optimization (APO), a dynamic integration approach that adaptively\namplifies preferred responses, suppresses dispreferred ones, and encourages\nexploration of potentially superior solutions during training. Extensive\nexperiments across six representative code preference tasks validate our\ntheoretical hypotheses and demonstrate that APO consistently matches or\nsurpasses the performance of existing SFT and S&D strategies. Our work provides\nboth theoretical foundations and practical guidance for selecting appropriate\ntraining strategies in different code preference alignment scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20109v1", "cate": "cs.SE", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20438", "title": "Teleoperating Autonomous Vehicles over Commercial 5G Networks: Are We There Yet?", "authors": ["Rostand A. K. Fezeu", "Jason Carpenter", "Rushikesh Zende", "Sree Ganesh Lalitaditya Divakarla", "Nitin Varyani", "Faaiq Bilal", "Steven Sleder", "Nanditha Naik", "Duncan Joly", "Eman Ramadan", "Ajay Kumar Gurumadaiah", "Zhi-Li Zhang"], "categories": ["cs.NI", "cs.OH", "C.2.0"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2507.20438v1", "summary": "Remote driving, or teleoperating Autonomous Vehicles (AVs), is a key\napplication that emerging 5G networks aim to support. In this paper, we conduct\na systematic feasibility study of AV teleoperation over commercial 5G networks\nfrom both cross-layer and end-to-end (E2E) perspectives. Given the critical\nimportance of timely delivery of sensor data, such as camera and LiDAR data,\nfor AV teleoperation, we focus in particular on the performance of uplink\nsensor data delivery. We analyze the impacts of Physical Layer (PHY layer) 5G\nradio network factors, including channel conditions, radio resource allocation,\nand Handovers (HOs), on E2E latency performance. We also examine the impacts of\n5G networks on the performance of upper-layer protocols and E2E application\nQuality-of-Experience (QoE) adaptation mechanisms used for real-time sensor\ndata delivery, such as Real-Time Streaming Protocol (RTSP) and Web Real Time\nCommunication (WebRTC). Our study reveals the challenges posed by today's 5G\nnetworks and the limitations of existing sensor data streaming mechanisms. The\ninsights gained will help inform the co-design of future-generation wireless\nnetworks, edge cloud systems, and applications to overcome the low-latency\nbarriers in AV teleoperation.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2507.20438v1", "cate": "cs.NI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19941", "title": "Adaptive Learned Belief Propagation for Decoding Error-Correcting Codes", "authors": ["Alireza Tasdighi", "Mansoor Yousefi"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19941v1", "summary": "Weighted belief propagation (WBP) for the decoding of linear block codes is\nconsidered. In WBP, the Tanner graph of the code is unrolled with respect to\nthe iterations of the belief propagation decoder. Then, weights are assigned to\nthe edges of the resulting recurrent network and optimized offline using a\ntraining dataset. The main contribution of this paper is an adaptive WBP where\nthe weights of the decoder are determined for each received word. Two variants\nof this decoder are investigated. In the parallel WBP decoders, the weights\ntake values in a discrete set. A number of WBP decoders are run in parallel to\nsearch for the best sequence of weights in real time. In the two-stage decoder,\na small neural network is used to dynamically determine the weights of the WBP\ndecoder for each received word. The proposed adaptive decoders demonstrate\nsignificant improvements over the static counterparts in two applications. In\nthe first application, Bose-Chaudhuri-Hocquenghem, polar and quasi-cyclic\nlow-density parity-check (QC-LDPC) codes are used over an additive white\nGaussian noise channel. The results indicate that the adaptive WBP achieves bit\nerror rates (BERs) up to an order of magnitude less than the BERs of the static\nWBP at about the same decoding complexity, depending on the code, its rate, and\nthe signal-to-noise ratio. The second application is a concatenated code\ndesigned for a long-haul nonlinear optical fiber channel where the inner code\nis a QC-LDPC code and the outer code is a spatially coupled LDPC code. In this\ncase, the inner code is decoded using an adaptive WBP, while the outer code is\ndecoded using the sliding window decoder and static belief propagation. The\nresults show that the adaptive WBP provides a coding gain of 0.8 dB compared to\nthe neural normalized min-sum decoder, with about the same computational\ncomplexity and decoding latency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19941v1", "cate": "cs.IT", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19795", "title": "Smaller, Faster, Cheaper: Architectural Designs for Efficient Machine Learning", "authors": ["Steven Walton"], "categories": ["cs.CV", "cs.AR", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Ph.D. Thesis", "url": "http://arxiv.org/abs/2507.19795v1", "summary": "Major advancements in the capabilities of computer vision models have been\nprimarily fueled by rapid expansion of datasets, model parameters, and\ncomputational budgets, leading to ever-increasing demands on computational\ninfrastructure. However, as these models are deployed in increasingly diverse\nand resource-constrained environments, there is a pressing need for\narchitectures that can deliver high performance while requiring fewer\ncomputational resources.\n  This dissertation focuses on architectural principles through which models\ncan achieve increased performance while reducing their computational demands.\nWe discuss strides towards this goal through three directions. First, we focus\non data ingress and egress, investigating how information may be passed into\nand retrieved from our core neural processing units. This ensures that our\nmodels make the most of available data, allowing smaller architectures to\nbecome more performant. Second, we investigate modifications to the core neural\narchitecture, applied to restricted attention in vision transformers. This\nsection explores how removing uniform context windows in restricted attention\nincreases the expressivity of the underlying neural architecture. Third, we\nexplore the natural structures of Normalizing Flows and how we can leverage\nthese properties to better distill model knowledge.\n  These contributions demonstrate that careful design of neural architectures\ncan increase the efficiency of machine learning algorithms, allowing them to\nbecome smaller, faster, and cheaper.", "comment": "Ph.D. Thesis", "pdf_url": "http://arxiv.org/pdf/2507.19795v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19667", "title": "Quantifying the Performance Gap for Simple Versus Optimal Dynamic Server Allocation Policies", "authors": ["Niklas Carlsson", "Derek Eager"], "categories": ["cs.DC", "cs.NI", "cs.PF", "68M20, 68M01", "C.4; C.5.5"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      20 pages", "url": "http://arxiv.org/abs/2507.19667v1", "summary": "Cloud computing enables the dynamic provisioning of server resources. To\nexploit this opportunity, a policy is needed for dynamically allocating (and\ndeallocating) servers in response to the current load conditions. In this paper\nwe describe several simple policies for dynamic server allocation and develop\nanalytic models for their analysis. We also design semi-Markov decision models\nthat enable determination of the performance achieved with optimal policies,\nallowing us to quantify the performance gap between simple, easily implemented\npolicies, and optimal policies. Finally, we apply our models to study the\npotential performance benefits of state-dependent routing in multi-site systems\nwhen using dynamic server allocation at each site. Insights from our results\nare valuable to service providers wanting to balance cloud service costs and\ndelays.", "comment": "20 pages", "pdf_url": "http://arxiv.org/pdf/2507.19667v1", "cate": "cs.DC", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20538", "title": "Uni-Mapper: Unified Mapping Framework for Multi-modal LiDARs in Complex and Dynamic Environments", "authors": ["Gilhwan Kang", "Hogyun Kim", "Byunghee Choi", "Seokhwan Jeong", "Young-Sik Shin", "Younggun Cho"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      18 pages, 14 figures", "url": "http://arxiv.org/abs/2507.20538v1", "summary": "The unification of disparate maps is crucial for enabling scalable robot\noperation across multiple sessions and collaborative multi-robot scenarios.\nHowever, achieving a unified map robust to sensor modalities and dynamic\nenvironments remains a challenging problem. Variations in LiDAR types and\ndynamic elements lead to differences in point cloud distribution and scene\nconsistency, hindering reliable descriptor generation and loop closure\ndetection essential for accurate map alignment. To address these challenges,\nthis paper presents Uni-Mapper, a dynamic-aware 3D point cloud map merging\nframework for multi-modal LiDAR systems. It comprises dynamic object removal,\ndynamic-aware loop closure, and multi-modal LiDAR map merging modules. A\nvoxel-wise free space hash map is built in a coarse-to-fine manner to identify\nand reject dynamic objects via temporal occupancy inconsistencies. The removal\nmodule is integrated with a LiDAR global descriptor, which encodes preserved\nstatic local features to ensure robust place recognition in dynamic\nenvironments. In the final stage, multiple pose graph optimizations are\nconducted for both intra-session and inter-map loop closures. We adopt a\ncentralized anchor-node strategy to mitigate intra-session drift errors during\nmap merging. In the final stage, centralized anchor-node-based pose graph\noptimization is performed to address intra- and inter-map loop closures for\nglobally consistent map merging. Our framework is evaluated on diverse\nreal-world datasets with dynamic objects and heterogeneous LiDARs, showing\nsuperior performance in loop detection across sensor modalities, robust mapping\nin dynamic environments, and accurate multi-map alignment over existing\nmethods. Project Page: https://sparolab.github.io/research/uni_mapper.", "comment": "18 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.20538v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20333", "title": "The Blessing and Curse of Dimensionality in Safety Alignment", "authors": ["Rachel S. Y. Teo", "Laziz U. Abdullaev", "Tan M. Nguyen"], "categories": ["cs.AI", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Published as a conference paper at COLM 2025", "url": "http://arxiv.org/abs/2507.20333v1", "summary": "The focus on safety alignment in large language models (LLMs) has increased\nsignificantly due to their widespread adoption across different domains. The\nscale of LLMs play a contributing role in their success, and the growth in\nparameter count follows larger hidden dimensions. In this paper, we hypothesize\nthat while the increase in dimensions has been a key advantage, it may lead to\nemergent problems as well. These problems emerge as the linear structures in\nthe activation space can be exploited, in the form of activation engineering,\nto circumvent its safety alignment. Through detailed visualizations of linear\nsubspaces associated with different concepts, such as safety, across various\nmodel scales, we show that the curse of high-dimensional representations\nuniquely impacts LLMs. Further substantiating our claim, we demonstrate that\nprojecting the representations of the model onto a lower dimensional subspace\ncan preserve sufficient information for alignment while avoiding those linear\nstructures. Empirical results confirm that such dimensional reduction\nsignificantly reduces susceptibility to jailbreaking through representation\nengineering. Building on our empirical validations, we provide theoretical\ninsights into these linear jailbreaking methods relative to a model's hidden\ndimensions. Broadly speaking, our work posits that the high dimensions of a\nmodel's internal representations can be both a blessing and a curse in safety\nalignment.", "comment": "Published as a conference paper at COLM 2025", "pdf_url": "http://arxiv.org/pdf/2507.20333v1", "cate": "cs.AI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20300", "title": "Talking-to-Build: How LLM-Assisted Interface Shapes Player Performance and Experience in Minecraft", "authors": ["Xin Sun", "Lei Wang", "Yue Li", "Jie Li", "Massimo Poesio", "Julian Frommel", "Koen Hinriks", "Jiahuan Pei"], "categories": ["cs.HC", "cs.MM"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20300v1", "summary": "With large language models (LLMs) on the rise, in-game interactions are\nshifting from rigid commands to natural conversations. However, the impacts of\nLLMs on player performance and game experience remain underexplored. This work\nexplores LLM's role as a co-builder during gameplay, examining its impact on\ntask performance, usability, and player experience. Using Minecraft as a\nsandbox, we present an LLM-assisted interface that engages players through\nnatural language, aiming to facilitate creativity and simplify complex gaming\ncommands. We conducted a mixed-methods study with 30 participants, comparing\nLLM-assisted and command-based interfaces across simple and complex game tasks.\nQuantitative and qualitative analyses reveal that the LLM-assisted interface\nsignificantly improves player performance, engagement, and overall game\nexperience. Additionally, task complexity has a notable effect on player\nperformance and experience across both interfaces. Our findings highlight the\npotential of LLM-assisted interfaces to revolutionize virtual experiences,\nemphasizing the importance of balancing intuitiveness with predictability,\ntransparency, and user agency in AI-driven, multimodal gaming environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20300v1", "cate": "cs.HC", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19547", "title": "Latent Representations of Intracardiac Electrograms for Atrial Fibrillation Driver Detection", "authors": ["Pablo Peiro-Corbacho", "Long Lin", "Pablo Ávila", "Alejandro Carta-Bergaz", "Ángel Arenal", "Carlos Sevilla-Salcedo", "Gonzalo R. Ríos-Muñoz"], "categories": ["cs.LG", "cs.CY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19547v1", "summary": "Atrial Fibrillation (AF) is the most prevalent sustained arrhythmia, yet\ncurrent ablation therapies, including pulmonary vein isolation, are frequently\nineffective in persistent AF due to the involvement of non-pulmonary vein\ndrivers. This study proposes a deep learning framework using convolutional\nautoencoders for unsupervised feature extraction from unipolar and bipolar\nintracavitary electrograms (EGMs) recorded during AF in ablation studies. These\nlatent representations of atrial electrical activity enable the\ncharacterization and automation of EGM analysis, facilitating the detection of\nAF drivers.\n  The database consisted of 11,404 acquisitions recorded from 291 patients,\ncontaining 228,080 unipolar EGMs and 171,060 bipolar EGMs. The autoencoders\nsuccessfully learned latent representations with low reconstruction loss,\npreserving the morphological features. The extracted embeddings allowed\ndownstream classifiers to detect rotational and focal activity with moderate\nperformance (AUC 0.73-0.76) and achieved high discriminative performance in\nidentifying atrial EGM entanglement (AUC 0.93).\n  The proposed method can operate in real-time and enables integration into\nclinical electroanatomical mapping systems to assist in identifying\narrhythmogenic regions during ablation procedures. This work highlights the\npotential of unsupervised learning to uncover physiologically meaningful\nfeatures from intracardiac signals.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19547v1", "cate": "cs.LG", "date": "2025-07-24", "updated": "2025-07-24"}
{"id": "2507.20122", "title": "From Prompt to Pipeline: Large Language Models for Scientific Workflow Development in Bioinformatics", "authors": ["Khairul Alam", "Banani Roy"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      36 pages", "url": "http://arxiv.org/abs/2507.20122v1", "summary": "The increasing complexity of bioinformatics data analysis has made Scientific\nWorkflow Systems (SWSs) like Galaxy and Nextflow essential for enabling\nscalable, reproducible, and automated workflows. However, creating and\nunderstanding these workflows remains challenging, particularly for domain\nexperts without programming expertise. This study investigates whether modern\nLarge Language Models (LLMs), GPT-4o, Gemini 2.5 Flash, and DeepSeek-V3, can\nsupport the generation of accurate, complete, and usable bioinformatics\nworkflows, and examines which prompting strategies most effectively guide this\nprocess. We evaluate these models using diverse tasks such as SNP analysis,\nRNA-seq, DNA methylation, and data retrieval, spanning both graphical (Galaxy)\nand script-based (Nextflow) platforms. Expert reviewers assess the generated\nworkflows against community-curated baselines from the Galaxy Training Network\nand nf-core repositories. The results show that Gemini 2.5 Flash excels in\ngenerating Galaxy workflows, while DeepSeek-V3 performs strongly in Nextflow.\nPrompting strategies significantly impact quality, with role-based and\nchain-of-thought prompts improving completeness and correctness. While GPT-4o\nbenefits from structured inputs, DeepSeek-V3 offers rich technical detail,\nalbeit with some verbosity. Overall, the findings highlight the potential of\nLLMs to lower the barrier for workflow development, improve reproducibility,\nand democratize access to computational tools in bioinformatics, especially\nwhen combined with thoughtful prompt engineering.", "comment": "36 pages", "pdf_url": "http://arxiv.org/pdf/2507.20122v1", "cate": "cs.SE", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20467", "title": "DD-JSCC: Dynamic Deep Joint Source-Channel Coding for Semantic Communications", "authors": ["Avi Deb Raha", "Apurba Adhikary", "Mrityunjoy Gain", "Yumin Park", "Walid Saad", "Choong Seon Hong"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20467v1", "summary": "Deep Joint Source-Channel Coding (Deep-JSCC) has emerged as a promising\nsemantic communication approach for wireless image transmission by jointly\noptimizing source and channel coding using deep learning techniques. However,\ntraditional Deep-JSCC architectures employ fixed encoder-decoder structures,\nlimiting their adaptability to varying device capabilities, real-time\nperformance optimization, power constraints and channel conditions. To address\nthese limitations, we propose DD-JSCC: Dynamic Deep Joint Source-Channel Coding\nfor Semantic Communications, a novel encoder-decoder architecture designed for\nsemantic communication systems. Unlike traditional Deep-JSCC models, DD-JSCC is\nflexible for dynamically adjusting its layer structures in real-time based on\ntransmitter and receiver capabilities, power constraints, compression ratios,\nand current channel conditions. This adaptability is achieved through a\nhierarchical layer activation mechanism combined with implicit regularization\nvia sequential randomized training, effectively reducing combinatorial\ncomplexity, preventing overfitting, and ensuring consistent feature\nrepresentations across varying configurations. Simulation results demonstrate\nthat DD-JSCC enhances the performance of image reconstruction in semantic\ncommunications, achieving up to 2 dB improvement in Peak Signal-to-Noise Ratio\n(PSNR) over fixed Deep-JSCC architectures, while reducing training costs by\nover 40%. The proposed unified framework eliminates the need for multiple\nspecialized models, significantly reducing training complexity and deployment\noverhead.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20467v1", "cate": "cs.NI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19986", "title": "Performance Analysis of Spatiotemporal 2-D Polar Codes for Massive MIMO with MMSE Receivers", "authors": ["Yaqi Li", "Xiaohu You", "Jiamin Li", "Chen Ji", "Bin Sheng"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      12 pages, 17 figures", "url": "http://arxiv.org/abs/2507.19986v1", "summary": "With the evolution from 5G to 6G, ultra-reliable low-latency communication\n(URLLC) faces increasingly stringent performance requirements. Lower latency\nconstraints demand shorter channel coding lengths, which can severely degrade\ndecoding performance. The massive multiple-input multiple-output (MIMO) system\nis considered a crucial technology to address this challenge due to its\nabundant spatial degrees of freedom (DoF). While polar codes are theoretically\ncapacity-achieving in the limit of infinite code length, their practical\napplicability is limited by significant decoding latency. In this paper, we\nestablish a unified theoretical framework and propose a novel spatiotemporal\ntwo-dimensional (2-D) polar coding scheme for massive MIMO systems employing\nminimum mean square error (MMSE) receivers. The polar transform is jointly\napplied over both spatial and temporal dimensions to fully exploit the large\nspatial DoF. By leveraging the near-deterministic\nsignal-to-interference-plus-noise ratio (SINR) property of MMSE detection, the\nspatial domain is modeled as a set of parallel Gaussian sub-channels. Within\nthis framework, we perform a theoretical analysis of the 2-D polarization\nbehavior using the Gaussian approximation method, and the capacity-achieving\nproperty of the proposed scheme is proved under finite blocklength constraints\nand large spatial DoF. Simulation results further demonstrate that, compared to\ntraditional time-domain polar codes, the proposed 2-D scheme can significantly\nreduce latency while guaranteeing reliability, or alternatively improve\nreliability under the same latency constraint -- offering a capacity-achieving\nand latency-efficient channel coding solution for massive MIMO systems in\nfuture 6G URLLC scenarios.", "comment": "12 pages, 17 figures", "pdf_url": "http://arxiv.org/pdf/2507.19986v1", "cate": "cs.IT", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20399", "title": "ACCESS-AV: Adaptive Communication-Computation Codesign for Sustainable Autonomous Vehicle Localization in Smart Factories", "authors": ["Rajat Bhattacharjya", "Arnab Sarkar", "Ish Kool", "Sabur Baidya", "Nikil Dutt"], "categories": ["eess.SY", "cs.AR", "cs.NI", "cs.RO", "cs.SY", "eess.SP"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      28 pages, 9 figures", "url": "http://arxiv.org/abs/2507.20399v1", "summary": "Autonomous Delivery Vehicles (ADVs) are increasingly used for transporting\ngoods in 5G network-enabled smart factories, with the compute-intensive\nlocalization module presenting a significant opportunity for optimization. We\npropose ACCESS-AV, an energy-efficient Vehicle-to-Infrastructure (V2I)\nlocalization framework that leverages existing 5G infrastructure in smart\nfactory environments. By opportunistically accessing the periodically broadcast\n5G Synchronization Signal Blocks (SSBs) for localization, ACCESS-AV obviates\nthe need for dedicated Roadside Units (RSUs) or additional onboard sensors to\nachieve energy efficiency as well as cost reduction. We implement an\nAngle-of-Arrival (AoA)-based estimation method using the Multiple Signal\nClassification (MUSIC) algorithm, optimized for resource-constrained ADV\nplatforms through an adaptive communication-computation strategy that\ndynamically balances energy consumption with localization accuracy based on\nenvironmental conditions such as Signal-to-Noise Ratio (SNR) and vehicle\nvelocity. Experimental results demonstrate that ACCESS-AV achieves an average\nenergy reduction of 43.09% compared to non-adaptive systems employing AoA\nalgorithms such as vanilla MUSIC, ESPRIT, and Root-MUSIC. It maintains sub-30\ncm localization accuracy while also delivering substantial reductions in\ninfrastructure and operational costs, establishing its viability for\nsustainable smart factory environments.", "comment": "28 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.20399v1", "cate": "eess.SY", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19712", "title": "Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning", "authors": ["Ngoc Hung Nguyen", "Nguyen Van Thieu", "Quang-Trung Luu", "Anh Tuan Nguyen", "Senura Wanasekara", "Nguyen Cong Luong", "Fatemeh Kavehmadavani", "Van-Dinh Nguyen"], "categories": ["cs.DC", "cs.AI", "cs.GT", "cs.LG", "cs.NI"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      15 pages, 13 figures", "url": "http://arxiv.org/abs/2507.19712v1", "summary": "In this paper, we explore mission assignment and task offloading in an Open\nRadio Access Network (Open RAN)-based intelligent transportation system (ITS),\nwhere autonomous vehicles leverage mobile edge computing for efficient\nprocessing. Existing studies often overlook the intricate interdependencies\nbetween missions and the costs associated with offloading tasks to edge\nservers, leading to suboptimal decision-making. To bridge this gap, we\nintroduce Oranits, a novel system model that explicitly accounts for mission\ndependencies and offloading costs while optimizing performance through vehicle\ncooperation. To achieve this, we propose a twofold optimization approach.\nFirst, we develop a metaheuristic-based evolutionary computing algorithm,\nnamely the Chaotic Gaussian-based Global ARO (CGG-ARO), serving as a baseline\nfor one-slot optimization. Second, we design an enhanced reward-based deep\nreinforcement learning (DRL) framework, referred to as the Multi-agent Double\nDeep Q-Network (MA-DDQN), that integrates both multi-agent coordination and\nmulti-action selection mechanisms, significantly reducing mission assignment\ntime and improving adaptability over baseline methods. Extensive simulations\nreveal that CGG-ARO improves the number of completed missions and overall\nbenefit by approximately 7.1% and 7.7%, respectively. Meanwhile, MA-DDQN\nachieves even greater improvements of 11.0% in terms of mission completions and\n12.5% in terms of the overall benefit. These results highlight the\neffectiveness of Oranits in enabling faster, more adaptive, and more efficient\ntask processing in dynamic ITS environments.", "comment": "15 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.19712v1", "cate": "cs.DC", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20589", "title": "Methods for the Segmentation of Reticular Structures Using 3D LiDAR Data: A Comparative Evaluation", "authors": ["Francisco J. Soler Mora", "Adrián Peidró Vidal", "Marc Fabregat-Jaén", "Luis Payá Castelló", "Óscar Reinoso García"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20589v1", "summary": "Reticular structures form the backbone of major infrastructure like bridges,\npylons, and airports, but their inspection and maintenance are costly and\nhazardous, often requiring human intervention. While prior research has focused\non fault detection via images or robotic platform design, the autonomous\nnavigation of robots within these structures is less explored. This study\naddresses that gap by proposing methods to detect navigable surfaces in truss\nstructures, enhancing the autonomy of climbing robots. The paper introduces\nseveral approaches for binary segmentation of navigable surfaces versus\nbackground from 3D point clouds of metallic trusses. These methods fall into\ntwo categories: analytical algorithms and deep learning models. The analytical\napproach features a custom algorithm that segments structures by analyzing the\neigendecomposition of planar patches in the point cloud. In parallel, advanced\ndeep learning models PointNet, PointNet++, MinkUNet34C, and PointTransformerV3\nare trained and evaluated for the same task. Comparative analysis shows that\nthe analytical algorithm offers easier parameter tuning and performance\ncomparable to deep learning models, which, while more computationally\nintensive, excel in segmentation accuracy. Notably, PointTransformerV3 achieves\na Mean Intersection Over Union (mIoU) of about 97%. The study demonstrates the\npromise of both analytical and deep learning methods for improving autonomous\nnavigation in complex truss environments. The results highlight the trade-offs\nbetween computational efficiency and segmentation performance, providing\nvaluable guidance for future research and practical applications in autonomous\ninfrastructure inspection and maintenance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20589v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20342", "title": "VLMPlanner: Integrating Visual Language Models with Motion Planning", "authors": ["Zhipeng Tang", "Sha Zhang", "Jiajun Deng", "Chenjie Wang", "Guoliang You", "Yuting Huang", "Xinrui Lin", "Yanyong Zhang"], "categories": ["cs.AI", "cs.RO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      8 pages, 3 figures, this paper has been accepted by ACM MM 2025", "url": "http://arxiv.org/abs/2507.20342v1", "summary": "Integrating large language models (LLMs) into autonomous driving motion\nplanning has recently emerged as a promising direction, offering enhanced\ninterpretability, better controllability, and improved generalization in rare\nand long-tail scenarios. However, existing methods often rely on abstracted\nperception or map-based inputs, missing crucial visual context, such as\nfine-grained road cues, accident aftermath, or unexpected obstacles, which are\nessential for robust decision-making in complex driving environments. To bridge\nthis gap, we propose VLMPlanner, a hybrid framework that combines a\nlearning-based real-time planner with a vision-language model (VLM) capable of\nreasoning over raw images. The VLM processes multi-view images to capture rich,\ndetailed visual information and leverages its common-sense reasoning\ncapabilities to guide the real-time planner in generating robust and safe\ntrajectories. Furthermore, we develop the Context-Adaptive Inference Gate\n(CAI-Gate) mechanism that enables the VLM to mimic human driving behavior by\ndynamically adjusting its inference frequency based on scene complexity,\nthereby achieving an optimal balance between planning performance and\ncomputational efficiency. We evaluate our approach on the large-scale,\nchallenging nuPlan benchmark, with comprehensive experimental results\ndemonstrating superior planning performance in scenarios with intricate road\nconditions and dynamic elements. Code will be available.", "comment": "8 pages, 3 figures, this paper has been accepted by ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.20342v1", "cate": "cs.AI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20355", "title": "CineVision: An Interactive Pre-visualization Storyboard System for Director-Cinematographer Collaboration", "authors": ["Zheng Wei", "Hongtao Wu", "lvmin Zhang", "Xian Xu", "Yefeng Zheng", "Pan Hui", "Maneesh Agrawala", "Huamin Qu", "Anyi Rao"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20355v2", "summary": "Effective communication between directors and cinematographers is fundamental\nin film production, yet traditional approaches relying on visual references and\nhand-drawn storyboards often lack the efficiency and precision necessary during\npre-production. We present CineVision, an AI-driven platform that integrates\nscriptwriting with real-time visual pre-visualization to bridge this\ncommunication gap. By offering dynamic lighting control, style emulation based\non renowned filmmakers, and customizable character design, CineVision enables\ndirectors to convey their creative vision with heightened clarity and rapidly\niterate on scene composition. In a 24-participant lab study, CineVision yielded\nshorter task times and higher usability ratings than two baseline methods,\nsuggesting a potential to ease early-stage communication and accelerate\nstoryboard drafts under controlled conditions. These findings underscore\nCineVision's potential to streamline pre-production processes and foster deeper\ncreative synergy among filmmaking teams, particularly for new collaborators.\nOur code and demo are available at https://github.com/TonyHongtaoWu/CineVision.", "comment": "UIST 2025", "pdf_url": "http://arxiv.org/pdf/2507.20355v2", "cate": "cs.HC", "date": "2025-07-27", "updated": "2025-07-29"}
{"id": "2507.19561", "title": "Harnessing intuitive local evolution rules for physical learning", "authors": ["Roie Ezraty", "Menachem Stern", "Shmuel M. Rubinstein"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      26 pages, 6 figures (with appendices). Submitted to Physical Review E", "url": "http://arxiv.org/abs/2507.19561v1", "summary": "Machine Learning, however popular and accessible, is computationally\nintensive and highly power-consuming, prompting interest in alternative\nphysical implementations of learning tasks. We introduce a training scheme for\nphysical systems that minimize power dissipation in which only boundary\nparameters (i.e. inputs and outputs) are externally controlled. Using this\nscheme, these Boundary-Enabled Adaptive State Tuning Systems (BEASTS) learn by\nexploiting local physical rules. Our scheme, BEASTAL (BEAST-Adaline), is the\nclosest analog of the Adaline algorithm for such systems. We demonstrate this\nautonomous learning in silico for regression and classification tasks. Our\napproach advances previous physical learning schemes by using intuitive, local\nevolution rules without requiring large-scale memory or complex internal\narchitectures. BEASTAL can perform any linear task, achieving best performance\nwhen the local evolution rule is non-linear.", "comment": "26 pages, 6 figures (with appendices). Submitted to Physical Review E", "pdf_url": "http://arxiv.org/pdf/2507.19561v1", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20135", "title": "Relating System Safety and Machine Learnt Model Performance", "authors": ["Ganesh Pai"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      17 pages, 4 figures, Expanded version of the paper: G. Pai, \"Deriving Safety-related Performance Requirements for Machine Learnt Aeronautical Applications\", Proceedings of the 44th AIAA DATC/IEEE Digital Avionics Systems Conference (DASC 2025)", "url": "http://arxiv.org/abs/2507.20135v1", "summary": "The prediction quality of machine learnt models and the functionality they\nultimately enable (e.g., object detection), is typically evaluated using a\nvariety of quantitative metrics that are specified in the associated model\nperformance requirements. When integrating such models into aeronautical\napplications, a top-down safety assessment process must influence both the\nmodel performance metrics selected, and their acceptable range of values.\nOften, however, the relationship of system safety objectives to model\nperformance requirements and the associated metrics is unclear. Using an\nexample of an aircraft emergency braking system containing a machine learnt\ncomponent (MLC) responsible for object detection and alerting, this paper first\ndescribes a simple abstraction of the required MLC behavior. Then, based on\nthat abstraction, an initial method is given to derive the minimum\nsafety-related performance requirements, the associated metrics, and their\ntargets for the both MLC and its underlying deep neural network, such that they\nmeet the quantitative safety objectives obtained from the safety assessment\nprocess. We give rationale as to why the proposed method should be considered\nvalid, also clarifying the assumptions made, the constraints on applicability,\nand the implications for verification.", "comment": "17 pages, 4 figures, Expanded version of the paper: G. Pai, \"Deriving\n  Safety-related Performance Requirements for Machine Learnt Aeronautical\n  Applications\", Proceedings of the 44th AIAA DATC/IEEE Digital Avionics\n  Systems Conference (DASC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.20135v1", "cate": "cs.SE", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20524", "title": "A Lyapunov-Guided Diffusion-Based Reinforcement Learning Approach for UAV-Assisted Vehicular Networks with Delayed CSI Feedback", "authors": ["Zhang Liu", "Lianfen Huang", "Zhibin Gao", "Xianbin Wang", "Dusit Niyato", "Xuemin", "Shen"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      13 pages, 11 figures, transactions paper", "url": "http://arxiv.org/abs/2507.20524v1", "summary": "Low altitude uncrewed aerial vehicles (UAVs) are expected to facilitate the\ndevelopment of aerial-ground integrated intelligent transportation systems and\nunlocking the potential of the emerging low-altitude economy. However, several\ncritical challenges persist, including the dynamic optimization of network\nresources and UAV trajectories, limited UAV endurance, and imperfect channel\nstate information (CSI). In this paper, we offer new insights into low-altitude\neconomy networking by exploring intelligent UAV-assisted vehicle-to-everything\ncommunication strategies aligned with UAV energy efficiency. Particularly, we\nformulate an optimization problem of joint channel allocation, power control,\nand flight altitude adjustment in UAV-assisted vehicular networks. Taking CSI\nfeedback delay into account, our objective is to maximize the vehicle-to-UAV\ncommunication sum rate while satisfying the UAV's long-term energy constraint.\nTo this end, we first leverage Lyapunov optimization to decompose the original\nlong-term problem into a series of per-slot deterministic subproblems. We then\npropose a diffusion-based deep deterministic policy gradient (D3PG) algorithm,\nwhich innovatively integrates diffusion models to determine optimal channel\nallocation, power control, and flight altitude adjustment decisions. Through\nextensive simulations using real-world vehicle mobility traces, we demonstrate\nthe superior performance of the proposed D3PG algorithm compared to existing\nbenchmark solutions.", "comment": "13 pages, 11 figures, transactions paper", "pdf_url": "http://arxiv.org/pdf/2507.20524v1", "cate": "cs.NI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20113", "title": "Rotatable RIS Assisted Physical Layer Multicasting", "authors": ["Ji Wang", "Jiayu Tian", "Lijuan Qin", "Kunrui Cao", "Hongbo Xu", "Xingwang Li", "Tony. Q. S. Quek"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20113v1", "summary": "Reconfigurable Intelligent Surfaces (RIS) dynamically control signal\npropagation to enhance wireless communications. This paper presents a novel\nframework for rotatable RIS assisted physical-layer multicast systems, aiming\nto maximize the sum of minimum multicast rates via joint optimization of base\nstation beamforming, RIS phase shifts, and orientation. Unlike unicast or\nnon-rotatable setups, the rotatable RIS adapts orientation to align signals\nwith user groups, improving fairness and rates for weak users. An alternating\noptimization approach combines convex optimization for beamforming/phase shifts\nwith exhaustive search and particle swarm optimization (PSO) for orientation.\nMajorization-Minimization-based algorithms solve subproblems iteratively.\nSimulation results show the framework achieves 24.1% rate improvement via\nexhaustive search and 20.0% via PSO over the non-rotatable RIS baseline, with\nPSO performance close to the exhaustive search upper bound, highlighting the\nbenefits of physical-layer multicast and orientation optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20113v1", "cate": "cs.IT", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2408.06003", "title": "LUT Tensor Core: A Software-Hardware Co-Design for LUT-Based Low-Bit LLM Inference", "authors": ["Zhiwen Mo", "Lei Wang", "Jianyu Wei", "Zhichen Zeng", "Shijie Cao", "Lingxiao Ma", "Naifeng Jing", "Ting Cao", "Jilong Xue", "Fan Yang", "Mao Yang"], "categories": ["cs.AR", "cs.LG", "C.1.0; C.3; B.2.4"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      Conference Version (ISCA'25). Fixed a typo", "url": "http://arxiv.org/abs/2408.06003v3", "summary": "Large Language Model (LLM) inference becomes resource-intensive, prompting a\nshift toward low-bit model weights to reduce the memory footprint and improve\nefficiency. Such low-bit LLMs necessitate the mixed-precision matrix\nmultiplication (mpGEMM), an important yet underexplored operation involving the\nmultiplication of lower-precision weights with higher-precision activations.\nOff-the-shelf hardware does not support this operation natively, leading to\nindirect, thus inefficient, dequantization-based implementations.\n  In this paper, we study the lookup table (LUT)-based approach for mpGEMM and\nfind that a conventional LUT implementation fails to achieve the promised\ngains. To unlock the full potential of LUT-based mpGEMM, we propose LUT Tensor\nCore, a software-hardware co-design for low-bit LLM inference. LUT Tensor Core\ndifferentiates itself from conventional LUT designs through: 1) software-based\noptimizations to minimize table precompute overhead and weight reinterpretation\nto reduce table storage; 2) a LUT-based Tensor Core hardware design with an\nelongated tiling shape to maximize table reuse and a bit-serial design to\nsupport diverse precision combinations in mpGEMM; 3) a new instruction set and\ncompilation optimizations for LUT-based mpGEMM. LUT Tensor Core significantly\noutperforms existing pure software LUT implementations and achieves a\n1.44$\\times$ improvement in compute density and energy efficiency compared to\nprevious state-of-the-art LUT-based accelerators.", "comment": "Conference Version (ISCA'25). Fixed a typo", "pdf_url": "http://arxiv.org/pdf/2408.06003v3", "cate": "cs.AR", "date": "2024-08-12", "updated": "2025-07-28"}
{"id": "2507.19723", "title": "Accelerating Matrix Multiplication: A Performance Comparison Between Multi-Core CPU and GPU", "authors": ["Mufakir Qamar Ansari", "Mudabir Qamar Ansari"], "categories": ["cs.DC", "Primary 68W10, Secondary 65Y05, 68M20", "C.1.2; C.4; D.1.3"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      13 pages, 3 figures. Complete C++/CUDA source code included in Appendix", "url": "http://arxiv.org/abs/2507.19723v1", "summary": "Matrix multiplication is a foundational operation in scientific computing and\nmachine learning, yet its computational complexity makes it a significant\nbottleneck for large-scale applications. The shift to parallel architectures,\nprimarily multi-core CPUs and many-core GPUs, is the established solution, and\nthese systems are now ubiquitous from datacenters to consumer laptops. This\npaper presents a direct, empirical performance analysis of matrix\nmultiplication on a modern, consumer-grade heterogeneous platform. We\nimplemented and benchmarked three versions of the algorithm: a baseline\nsequential C++ implementation, a parallel version for its multi-core CPU using\nOpenMP, and a massively parallel version for its discrete GPU using CUDA with\nshared memory optimizations. The implementations were evaluated with square\nmatrices of varying dimensions, from 128x128 to 4096x4096. Our results show\nthat while the parallel CPU provides a consistent speedup of 12-14x over the\nsequential version, the GPU's performance scales dramatically with problem\nsize. For a 4096x4096 matrix, the GPU implementation achieved a speedup of\napproximately 593x over the sequential baseline and 45x over the optimized\nparallel CPU version. These findings quantitatively demonstrate the profound\nimpact of many-core GPU architectures on accelerating data-parallel workloads,\nunderscoring that significant performance gains are readily accessible even on\nconsumer-level hardware.", "comment": "13 pages, 3 figures. Complete C++/CUDA source code included in\n  Appendix", "pdf_url": "http://arxiv.org/pdf/2507.19723v1", "cate": "cs.DC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20622", "title": "FMimic: Foundation Models are Fine-grained Action Learners from Human Videos", "authors": ["Guangyan Chen", "Meiling Wang", "Te Cui", "Yao Mu", "Haoyang Lu", "Zicai Peng", "Mengxiao Hu", "Tianxing Zhou", "Mengyin Fu", "Yi Yang", "Yufeng Yue"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      accepted to International Journal of Robotics Research(IJRR)", "url": "http://arxiv.org/abs/2507.20622v1", "summary": "Visual imitation learning (VIL) provides an efficient and intuitive strategy\nfor robotic systems to acquire novel skills. Recent advancements in foundation\nmodels, particularly Vision Language Models (VLMs), have demonstrated\nremarkable capabilities in visual and linguistic reasoning for VIL tasks.\nDespite this progress, existing approaches primarily utilize these models for\nlearning high-level plans from human demonstrations, relying on pre-defined\nmotion primitives for executing physical interactions, which remains a major\nbottleneck for robotic systems. In this work, we present FMimic, a novel\nparadigm that harnesses foundation models to directly learn generalizable\nskills at even fine-grained action levels, using only a limited number of human\nvideos. Extensive experiments demonstrate that our FMimic delivers strong\nperformance with a single human video, and significantly outperforms all other\nmethods with five videos. Furthermore, our method exhibits significant\nimprovements of over 39% and 29% in RLBench multi-task experiments and\nreal-world manipulation tasks, respectively, and exceeds baselines by more than\n34% in high-precision tasks and 47% in long-horizon tasks.", "comment": "accepted to International Journal of Robotics Research(IJRR)", "pdf_url": "http://arxiv.org/pdf/2507.20622v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20377", "title": "Multi-Agent Reinforcement Learning for Dynamic Mobility Resource Allocation with Hierarchical Adaptive Grouping", "authors": ["Farshid Nooshi", "Suining He"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      5 pages, UrbComp 2025", "url": "http://arxiv.org/abs/2507.20377v1", "summary": "Allocating mobility resources (e.g., shared bikes/e-scooters, ride-sharing\nvehicles) is crucial for rebalancing the mobility demand and supply in the\nurban environments. We propose in this work a novel multi-agent reinforcement\nlearning named Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS)\nfor dynamic mobility resource allocation. HAG-PS aims to address two important\nresearch challenges regarding multi-agent reinforcement learning for mobility\nresource allocation: (1) how to dynamically and adaptively share the mobility\nresource allocation policy (i.e., how to distribute mobility resources) across\nagents (i.e., representing the regional coordinators of mobility resources);\nand (2) how to achieve memory-efficient parameter sharing in an urban-scale\nsetting. To address the above challenges, we have provided following novel\ndesigns within HAG-PS. To enable dynamic and adaptive parameter sharing, we\nhave designed a hierarchical approach that consists of global and local\ninformation of the mobility resource states (e.g., distribution of mobility\nresources). We have developed an adaptive agent grouping approach in order to\nsplit or merge the groups of agents based on their relative closeness of\nencoded trajectories (i.e., states, actions, and rewards). We have designed a\nlearnable identity (ID) embeddings to enable agent specialization beyond simple\nparameter copy. We have performed extensive experimental studies based on\nreal-world NYC bike sharing data (a total of more than 1.2 million trips), and\ndemonstrated the superior performance (e.g., improved bike availability) of\nHAG-PS compared with other baseline approaches.", "comment": "5 pages, UrbComp 2025", "pdf_url": "http://arxiv.org/pdf/2507.20377v1", "cate": "cs.AI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20437", "title": "EchoForce: Continuous Grip Force Estimation from Skin Deformation Using Active Acoustic Sensing on a Wristband", "authors": ["Kian Mahmoodi", "Yudong Xie", "Tan Gemicioglu", "Chi-Jung Lee", "Jiwan Kim", "Cheng Zhang"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      8 pages, 3 figures. Proceedings of the 2025 ACM International Symposium on Wearable Computers (ISWC '25)", "url": "http://arxiv.org/abs/2507.20437v1", "summary": "Grip force is commonly used as an overall health indicator in older adults\nand is valuable for tracking progress in physical training and rehabilitation.\nExisting methods for wearable grip force measurement are cumbersome and\nuser-dependent, making them insufficient for practical, continuous grip force\nmeasurement. We introduce EchoForce, a novel wristband using acoustic sensing\nfor low-cost, non-contact measurement of grip force. EchoForce captures\nacoustic signals reflected from subtle skin deformations by flexor muscles on\nthe forearm. In a user study with 11 participants, EchoForce achieved a\nfine-tuned user-dependent mean error rate of 9.08% and a user-independent mean\nerror rate of 12.3% using a foundation model. Our system remained accurate\nbetween sessions, hand orientations, and users, overcoming a significant\nlimitation of past force sensing systems. EchoForce makes continuous grip force\nmeasurement practical, providing an effective tool for health monitoring and\nnovel interaction techniques.", "comment": "8 pages, 3 figures. Proceedings of the 2025 ACM International\n  Symposium on Wearable Computers (ISWC '25)", "pdf_url": "http://arxiv.org/pdf/2507.20437v1", "cate": "cs.HC", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19627", "title": "Federated Calculation of the Free-Support Transportation Barycenter by Single-Loop Dual Decomposition", "authors": ["Zhengqi Lin", "Andrzej Ruszczyński"], "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19627v1", "summary": "We propose an efficient federated dual decomposition algorithm for\ncalculating the Wasserstein barycenter of several distributions, including\nchoosing the support of the solution. The algorithm does not access local data\nand uses only highly aggregated information. It also does not require repeated\nsolutions to mass transportation problems. Because of the absence of any\nmatrix-vector operations, the algorithm exhibits a very low complexity of each\niteration and significant scalability. We illustrate its virtues and compare it\nto the state-of-the-art methods on several examples of mixture models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19627v1", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20218", "title": "Strategic Motivators for Ethical AI System Development: An Empirical and Holistic Model", "authors": ["Muhammad Azeem Akbar", "Arif Ali Khan", "Saima Rafi", "Damian Kedziora", "Sami Hyrynsalmi"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20218v1", "summary": "Artificial Intelligence (AI) presents transformative opportunities for\nindustries and society, but its responsible development is essential to prevent\nunintended consequences. Ethically sound AI systems demand strategic planning,\nstrong governance, and an understanding of the key drivers that promote\nresponsible practices. This study aims to identify and prioritize the\nmotivators that drive the ethical development of AI systems. A Multivocal\nLiterature Review (MLR) and a questionnaire-based survey were conducted to\ncapture current practices in ethical AI. We applied Interpretive Structure\nModeling (ISM) to explore the relationships between motivator categories,\nfollowed by MICMAC analysis to classify them by their driving and dependence\npower. Fuzzy TOPSIS was used to rank these motivators by importance. Twenty key\nmotivators were identified and grouped into eight categories: Human Resource,\nKnowledge Integration, Coordination, Project Administration, Standards,\nTechnology Factor, Stakeholders, and Strategy & Matrices. ISM results showed\nthat 'Human Resource' and 'Coordination' heavily influence other factors.\nMICMAC analysis placed categories like Human Resource (CA1), Coordination\n(CA3), Stakeholders (CA7), and Strategy & Matrices (CA8) in the independent\ncluster, indicating high driving but low dependence power. Fuzzy TOPSIS ranked\nmotivators such as promoting team diversity, establishing AI governance bodies,\nappointing oversight leaders, and ensuring data privacy as most critical. To\nsupport ethical AI adoption, organizations should align their strategies with\nthese motivators and integrate them into their policies, governance models, and\ndevelopment frameworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20218v1", "cate": "cs.SE", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20871", "title": "\\textit{FedABC}: Attention-Based Client Selection for Federated Learning with Long-Term View", "authors": ["Wenxuan Ye", "Xueli An", "Junfan Wang", "Xueqiang Yan", "Georg Carle"], "categories": ["cs.NI", "cs.LG"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      Accepted to ICC 2025", "url": "http://arxiv.org/abs/2507.20871v1", "summary": "Native AI support is a key objective in the evolution of 6G networks, with\nFederated Learning (FL) emerging as a promising paradigm. FL allows\ndecentralized clients to collaboratively train an AI model without directly\nsharing their data, preserving privacy. Clients train local models on private\ndata and share model updates, which a central server aggregates to refine the\nglobal model and redistribute it for the next iteration. However, client data\nheterogeneity slows convergence and reduces model accuracy, and frequent client\nparticipation imposes communication and computational burdens. To address these\nchallenges, we propose \\textit{FedABC}, an innovative client selection\nalgorithm designed to take a long-term view in managing data heterogeneity and\noptimizing client participation. Inspired by attention mechanisms,\n\\textit{FedABC} prioritizes informative clients by evaluating both model\nsimilarity and each model's unique contributions to the global model. Moreover,\nconsidering the evolving demands of the global model, we formulate an\noptimization problem to guide \\textit{FedABC} throughout the training process.\nFollowing the ``later-is-better\" principle, \\textit{FedABC} adaptively adjusts\nthe client selection threshold, encouraging greater participation in later\ntraining stages. Extensive simulations on CIFAR-10 demonstrate that\n\\textit{FedABC} significantly outperforms existing approaches in model accuracy\nand client participation efficiency, achieving comparable performance with 32\\%\nfewer clients than the classical FL algorithm \\textit{FedAvg}, and 3.5\\% higher\naccuracy with 2\\% fewer clients than the state-of-the-art. This work marks a\nstep toward deploying FL in heterogeneous, resource-constrained environments,\nthereby supporting native AI capabilities in 6G networks.", "comment": "Accepted to ICC 2025", "pdf_url": "http://arxiv.org/pdf/2507.20871v1", "cate": "cs.NI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20129", "title": "An Optimal Transport-Based Method for Computing LM Rate and Its Convergence Analysis", "authors": ["Shitong Wu", "Wenhao Ye", "Xinwei Li", "Lingyi Chen", "Wenyi Zhang", "Huihui Wu", "Hao Wu"], "categories": ["cs.IT", "cs.NA", "math.IT", "math.NA"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20129v1", "summary": "The mismatch capacity characterizes the highest information rate of the\nchannel under a prescribed decoding metric and serves as a critical performance\nindicator in numerous practical communication scenarios. Compared to the\ncommonly used Generalized Mutual Information (GMI), the Lower bound on the\nMismatch capacity (LM rate) generally provides a tighter lower bound on the\nmismatch capacity. However, the efficient computation of the LM rate is\nsignificantly more challenging than that of the GMI, particularly as the size\nof the channel input alphabet increases. This growth in complexity renders\nstandard numerical methods (e.g., interior point methods) computationally\nintensive and, in some cases, impractical. In this work, we reformulate the\ncomputation of the LM rate as a special instance of the optimal transport (OT)\nproblem with an additional constraint. Building on this formulation, we develop\na novel numerical algorithm based on the Sinkhorn algorithm, which is well\nknown for its efficiency in solving entropy regularized optimization problems.\nWe further provide the convergence analysis of the proposed algorithm,\nrevealing that the algorithm has a sub-linear convergence rate. Numerical\nexperiments demonstrate the feasibility and efficiency of the proposed\nalgorithm for the computation of the LM rate.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20129v1", "cate": "cs.IT", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2505.18975", "title": "FastMamba: A High-Speed and Efficient Mamba Accelerator on FPGA with Accurate Quantization", "authors": ["Aotao Wang", "Haikuo Shao", "Shaobo Ma", "Zhongfeng Wang"], "categories": ["cs.AR", "cs.AI"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.18975v4", "summary": "State Space Models (SSMs), like recent Mamba2, have achieved remarkable\nperformance and received extensive attention. However, deploying Mamba2 on\nresource-constrained edge devices encounters many problems: severe outliers\nwithin the linear layer challenging the quantization, diverse and irregular\nelement-wise tensor operations, and hardware-unfriendly nonlinear functions in\nthe SSM block. To address these issues, this paper presents FastMamba, a\ndedicated accelerator on FPGA with hardware-algorithm co-design to promote the\ndeployment efficiency of Mamba2. Specifically, we successfully achieve 8-bit\nquantization for linear layers through Hadamard transformation to eliminate\noutliers. Moreover, a hardware-friendly and fine-grained power-of-two\nquantization framework is presented for the SSM block and convolution layer,\nand a first-order linear approximation is developed to optimize the nonlinear\nfunctions. Based on the accurate algorithm quantization, we propose an\naccelerator that integrates parallel vector processing units, pipelined\nexecution dataflow, and an efficient SSM Nonlinear Approximation Unit, which\nenhances computational efficiency and reduces hardware complexity. Finally, we\nevaluate FastMamba on Xilinx VC709 FPGA. For the input prefill task on\nMamba2-130M, FastMamba achieves 68.80\\times and 8.90\\times speedup over Intel\nXeon 4210R CPU and NVIDIA RTX 3090 GPU, respectively. In the output decode\nexperiment with Mamba2-2.7B, FastMamba attains 6\\times higher energy efficiency\nthan RTX 3090 GPU.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.18975v4", "cate": "cs.AR", "date": "2025-05-25", "updated": "2025-07-28"}
{"id": "2507.19845", "title": "MegatronApp: Efficient and Comprehensive Management on Distributed LLM Training", "authors": ["Bohan Zhao", "Guang Yang", "Shuo Chen", "Ruitao Liu", "Tingrui Zhang", "Yongchao He", "Wei Xu"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19845v1", "summary": "The rapid escalation in the parameter count of large language models (LLMs)\nhas transformed model training from a single-node endeavor into a highly\nintricate, cross-node activity. While frameworks such as Megatron-LM\nsuccessfully integrate tensor (TP), pipeline (PP), and data (DP) parallelism to\nenable trillion-parameter training, they simultaneously expose practitioners to\nunprecedented systems-level challenges in performance optimization, diagnosis,\nand interpretability. MegatronApp is an open-source toolchain expressly\ndesigned to meet these challenges. It introduces four orthogonal, yet\nseamlessly composable modules--MegaScan, MegaFBD, MegaDPP, and MegaScope--that\ncollectively elevate the reliability, efficiency, and transparency of\nproduction-scale training. This paper presents the motivation, architecture,\nand distinctive contributions of each module, and elucidates how their\nsynergistic integration augments the Megatron-LM ecosystem.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19845v1", "cate": "cs.DC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20784", "title": "A Strawberry Harvesting Tool with Minimal Footprint", "authors": ["Mohamed Sorour", "Mohamed Heshmat", "Khaled Elgeneidy", "Pål Johan From"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20784v1", "summary": "In this paper, a novel prototype for harvesting table-top grown strawberries\nis presented, that is minimalist in its footprint interacting with the fruit.\nIn our methodology, a smooth trapper manipulates the stem into a precise groove\nlocation at which a distant laser beam is focused. The tool reaches\ntemperatures as high as 188{\\deg} Celsius and as such killing germs and\npreventing the spread of local plant diseases. The burnt stem wound preserves\nwater content and in turn the fruit shelf life. Cycle and cut times achieved\nare 5.56 and 2.88 seconds respectively in successful in-door harvesting\ndemonstration. Extensive experiments are performed to optimize the laser spot\ndiameter and lateral speed against the cutting time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20784v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20395", "title": "MazeEval: A Benchmark for Testing Sequential Decision-Making in Language Models", "authors": ["Hafsteinn Einarsson"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20395v1", "summary": "As Large Language Models (LLMs) increasingly power autonomous agents in\nrobotics and embodied AI, understanding their spatial reasoning capabilities\nbecomes crucial for ensuring reliable real-world deployment. Despite advances\nin language understanding, current research lacks evaluation of how LLMs\nperform spatial navigation without visual cues, a fundamental requirement for\nagents operating with limited sensory information. This paper addresses this\ngap by introducing MazeEval, a benchmark designed to isolate and evaluate pure\nspatial reasoning in LLMs through coordinate-based maze navigation tasks. Our\nmethodology employs a function-calling interface where models navigate mazes of\nvarying complexity ($5\\times 5$ to $15\\times 15$ grids) using only coordinate\nfeedback and distance-to-wall information, excluding visual input to test\nfundamental spatial cognition. We evaluate eight state-of-the-art LLMs across\nidentical mazes in both English and Icelandic to assess cross-linguistic\ntransfer of spatial abilities. Our findings reveal striking disparities: while\nOpenAI's O3 achieves perfect navigation for mazes up to size $30\\times 30$,\nother models exhibit catastrophic failure beyond $9\\times 9$ mazes, with 100%\nof failures attributed to excessive looping behavior where models revisit a\ncell at least 10 times. We document a significant performance degradation in\nIcelandic, with models solving mazes 3-4 sizes smaller than in English,\nsuggesting spatial reasoning in LLMs emerges from linguistic patterns rather\nthan language-agnostic mechanisms. These results have important implications\nfor global deployment of LLM-powered autonomous systems, showing spatial\nintelligence remains fundamentally constrained by training data availability\nand highlighting the need for architectural innovations to achieve reliable\nnavigation across linguistic contexts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20395v1", "cate": "cs.AI", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20655", "title": "CoGrader: Transforming Instructors' Assessment of Project Reports through Collaborative LLM Integration", "authors": ["Zixin Chen", "Jiachen Wang", "Yumeng Li", "Haobo Li", "Chuhan Shi", "Rong Zhang", "Huamin Qu"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20655v1", "summary": "Grading project reports are increasingly significant in today's educational\nlandscape, where they serve as key assessments of students' comprehensive\nproblem-solving abilities. However, it remains challenging due to the\nmultifaceted evaluation criteria involved, such as creativity and\npeer-comparative achievement. Meanwhile, instructors often struggle to maintain\nfairness throughout the time-consuming grading process. Recent advances in AI,\nparticularly large language models, have demonstrated potential for automating\nsimpler grading tasks, such as assessing quizzes or basic writing quality.\nHowever, these tools often fall short when it comes to complex metrics, like\ndesign innovation and the practical application of knowledge, that require an\ninstructor's educational insights into the class situation. To address this\nchallenge, we conducted a formative study with six instructors and developed\nCoGrader, which introduces a novel grading workflow combining human-LLM\ncollaborative metrics design, benchmarking, and AI-assisted feedback. CoGrader\nwas found effective in improving grading efficiency and consistency while\nproviding reliable peer-comparative feedback to students. We also discuss\ndesign insights and ethical considerations for the development of human-AI\ncollaborative grading systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20655v1", "cate": "cs.HC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19635", "title": "Efficient and Scalable Agentic AI with Heterogeneous Systems", "authors": ["Zain Asgar", "Michelle Nguyen", "Sachin Katti"], "categories": ["cs.LG", "cs.AI", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Early access preprint", "url": "http://arxiv.org/abs/2507.19635v1", "summary": "AI agents are emerging as a dominant workload in a wide range of\napplications, promising to be the vehicle that delivers the promised benefits\nof AI to enterprises and consumers. Unlike conventional software or static\ninference, agentic workloads are dynamic and structurally complex. Often these\nagents are directed graphs of compute and IO operations that span multi-modal\ndata input and conversion), data processing and context gathering (e.g vector\nDB lookups), multiple LLM inferences, tool calls, etc. To scale AI agent usage,\nwe need efficient and scalable deployment and agent-serving infrastructure.\n  To tackle this challenge, in this paper, we present a system design for\ndynamic orchestration of AI agent workloads on heterogeneous compute\ninfrastructure spanning CPUs and accelerators, both from different vendors and\nacross different performance tiers within a single vendor. The system delivers\nseveral building blocks: a framework for planning and optimizing agentic AI\nexecution graphs using cost models that account for compute, memory, and\nbandwidth constraints of different HW; a MLIR based representation and\ncompilation system that can decompose AI agent execution graphs into granular\noperators and generate code for different HW options; and a dynamic\norchestration system that can place the granular components across a\nheterogeneous compute infrastructure and stitch them together while meeting an\nend-to-end SLA. Our design performs a systems level TCO optimization and\npreliminary results show that leveraging a heterogeneous infrastructure can\ndeliver significant TCO benefits. A preliminary surprising finding is that for\nsome workloads a heterogeneous combination of older generation GPUs with newer\naccelerators can deliver similar TCO as the latest generation homogenous GPU\ninfrastructure design, potentially extending the life of deployed\ninfrastructure.", "comment": "Early access preprint", "pdf_url": "http://arxiv.org/pdf/2507.19635v1", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20358", "title": "Beyond Binary Moderation: Identifying Fine-Grained Sexist and Misogynistic Behavior on GitHub with Large Language Models", "authors": ["Tanni Dev", "Sayma Sultana", "Amiangshu Bosu"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      The 19th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement", "url": "http://arxiv.org/abs/2507.20358v1", "summary": "Background: Sexist and misogynistic behavior significantly hinders inclusion\nin technical communities like GitHub, causing developers, especially\nminorities, to leave due to subtle biases and microaggressions. Current\nmoderation tools primarily rely on keyword filtering or binary classifiers,\nlimiting their ability to detect nuanced harm effectively.\n  Aims: This study introduces a fine-grained, multi-class classification\nframework that leverages instruction-tuned Large Language Models (LLMs) to\nidentify twelve distinct categories of sexist and misogynistic comments on\nGitHub.\n  Method: We utilized an instruction-tuned LLM-based framework with systematic\nprompt refinement across 20 iterations, evaluated on 1,440 labeled GitHub\ncomments across twelve sexism/misogyny categories. Model performances were\nrigorously compared using precision, recall, F1-score, and the Matthews\nCorrelation Coefficient (MCC).\n  Results: Our optimized approach (GPT-4o with Prompt 19) achieved an MCC of\n0.501, significantly outperforming baseline approaches. While this model had\nlow false positives, it struggled to interpret nuanced, context-dependent\nsexism and misogyny reliably.\n  Conclusion: Well-designed prompts with clear definitions and structured\noutputs significantly improve the accuracy and interpretability of sexism\ndetection, enabling precise and practical moderation on developer platforms\nlike GitHub.", "comment": "The 19th ACM/IEEE International Symposium on Empirical Software\n  Engineering and Measurement", "pdf_url": "http://arxiv.org/pdf/2507.20358v1", "cate": "cs.SE", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20971", "title": "Towards a Robust Transport Network With Self-adaptive Network Digital Twin", "authors": ["Cláudio Modesto", "João Borges", "Cleverson Nahum", "Lucas Matni", "Cristiano Bonato Both", "Kleber Cardoso", "Glauco Gonçalves", "Ilan Correa", "Silvia Lins", "Andrey Silva", "Aldebaro Klautau"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      19 pages, 10 figures, and 6 tables", "url": "http://arxiv.org/abs/2507.20971v1", "summary": "The ability of the network digital twin (NDT) to remain aware of changes in\nits physical counterpart, known as the physical twin (PTwin), is a fundamental\ncondition to enable timely synchronization, also referred to as twinning. In\nthis way, considering a transport network, a key requirement is to handle\nunexpected traffic variability and dynamically adapt to maintain optimal\nperformance in the associated virtual model, known as the virtual twin (VTwin).\nIn this context, we propose a self-adaptive implementation of a novel NDT\narchitecture designed to provide accurate delay predictions, even under\nfluctuating traffic conditions. This architecture addresses an essential\nchallenge, underexplored in the literature: improving the resilience of\ndata-driven NDT platforms against traffic variability and improving\nsynchronization between the VTwin and its physical counterpart. Therefore, the\ncontributions of this article rely on NDT lifecycle by focusing on the\noperational phase, where telemetry modules are used to monitor incoming\ntraffic, and concept drift detection techniques guide retraining decisions\naimed at updating and redeploying the VTwin when necessary. We validate our\narchitecture with a network management use case, across various emulated\nnetwork topologies, and diverse traffic patterns to demonstrate its\neffectiveness in preserving acceptable performance and predicting per-flow\ndelay under unexpected traffic variation. The results in all tested topologies,\nusing the normalized mean square error as the evaluation metric, demonstrate\nthat our proposed architecture, after a traffic concept drift, achieves a\nperformance improvement in prediction of at least 56.7% compared to a\nconfiguration without NDT synchronization.", "comment": "19 pages, 10 figures, and 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.20971v1", "cate": "cs.NI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20157", "title": "Sparse Regression Codes for Secret Key Agreement: Achieving Strong Secrecy and Near-Optimal Rates for Gaussian Sources", "authors": ["Emmanouil M. Athanasakos", "Hariprasad Manjunath"], "categories": ["cs.IT", "math.IT", "math.PR", "stat.AP"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      15 pages, 5 figures", "url": "http://arxiv.org/abs/2507.20157v1", "summary": "Secret key agreement from correlated physical layer observations is a\ncornerstone of information-theoretic security. This paper proposes and\nrigorously analyzes a complete, constructive protocol for secret key agreement\nfrom Gaussian sources using Sparse Regression Codes (SPARCs). Our protocol\nsystematically leverages the known optimality of SPARCs for both\nrate-distortion and Wyner-Ziv (WZ) coding, facilitated by their inherent nested\nstructure. The primary contribution of this work is a comprehensive end-to-end\nanalysis demonstrating that the proposed scheme achieves near-optimal secret\nkey rates with strong secrecy guarantees, as quantified by a vanishing\nvariational distance. We explicitly characterize the gap to the optimal rate,\nrevealing a fundamental trade-off between the key rate and the required public\ncommunication overhead, which is governed by a tunable quantization parameter.\nFurthermore, we uncover a non-trivial constrained optimization for this\nparameter, showing that practical constraints on the SPARC code parameters\ninduce a peak in the achievable secret key rate. This work establishes SPARCs\nas a viable and theoretically sound framework for secure key generation,\nproviding a compelling low-complexity alternative to existing schemes and\noffering new insights into the practical design of such protocols.", "comment": "15 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.20157v1", "cate": "cs.IT", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2506.10235", "title": "LaMAGIC2: Advanced Circuit Formulations for Language Model-Based Analog Topology Generation", "authors": ["Chen-Chia Chang", "Wan-Hsuan Lin", "Yikang Shen", "Yiran Chen", "Xin Zhang"], "categories": ["cs.LG", "cs.AI", "cs.AR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at 42nd International Conference on Machine Learning (ICML) 2025", "url": "http://arxiv.org/abs/2506.10235v2", "summary": "Automation of analog topology design is crucial due to customized\nrequirements of modern applications with heavily manual engineering efforts.\nThe state-of-the-art work applies a sequence-to-sequence approach and\nsupervised finetuning on language models to generate topologies given user\nspecifications. However, its circuit formulation is inefficient due to O(|V |2)\ntoken length and suffers from low precision sensitivity to numeric inputs. In\nthis work, we introduce LaMAGIC2, a succinct float-input canonical formulation\nwith identifier (SFCI) for language model-based analog topology generation.\nSFCI addresses these challenges by improving component-type recognition through\nidentifier-based representations, reducing token length complexity to O(|V |),\nand enhancing numeric precision sensitivity for better performance under tight\ntolerances. Our experiments demonstrate that LaMAGIC2 achieves 34% higher\nsuccess rates under a tight tolerance of 0.01 and 10X lower MSEs compared to a\nprior method. LaMAGIC2 also exhibits better transferability for circuits with\nmore vertices with up to 58.5% improvement. These advancements establish\nLaMAGIC2 as a robust framework for analog topology generation.", "comment": "Accepted at 42nd International Conference on Machine Learning (ICML)\n  2025", "pdf_url": "http://arxiv.org/pdf/2506.10235v2", "cate": "cs.LG", "date": "2025-06-11", "updated": "2025-07-26"}
{"id": "2507.19926", "title": "A Fast Parallel Median Filtering Algorithm Using Hierarchical Tiling", "authors": ["Louis Sugy"], "categories": ["cs.DC", "cs.CV", "I.3.1; I.4.3"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      8 pages, 8 figures", "url": "http://arxiv.org/abs/2507.19926v1", "summary": "Median filtering is a non-linear smoothing technique widely used in digital\nimage processing to remove noise while retaining sharp edges. It is\nparticularly well suited to removing outliers (impulse noise) or granular\nartifacts (speckle noise). However, the high computational cost of median\nfiltering can be prohibitive. Sorting-based algorithms excel with small kernels\nbut scale poorly with increasing kernel diameter, in contrast to constant-time\nmethods characterized by higher constant factors but better scalability, such\nas histogram-based approaches or the 2D wavelet matrix.\n  This paper introduces a novel algorithm, leveraging the separability of the\nsorting problem through hierarchical tiling to minimize redundant computations.\nWe propose two variants: a data-oblivious selection network that can operate\nentirely within registers, and a data-aware version utilizing random-access\nmemory. These achieve per-pixel complexities of $O(k \\log(k))$ and $O(k)$,\nrespectively, for a $k \\times k$ kernel - unprecedented for sorting-based\nmethods. Our CUDA implementation is up to 5 times faster than the current state\nof the art on a modern GPU and is the fastest median filter in most cases for\n8-, 16-, and 32-bit data types and kernels from $3 \\times 3$ to $75 \\times 75$.", "comment": "8 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.19926v1", "cate": "cs.DC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20800", "title": "LanternNet: A Novel Hub-and-Spoke System to Seek and Suppress Spotted Lanternfly Populations", "authors": ["Vinil Polepalli"], "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20800v1", "summary": "The invasive spotted lanternfly (SLF) poses a significant threat to\nagriculture and ecosystems, causing widespread damage. Current control methods,\nsuch as egg scraping, pesticides, and quarantines, prove labor-intensive,\nenvironmentally hazardous, and inadequate for long-term SLF suppression. This\nresearch introduces LanternNet, a novel autonomous robotic Hub-and-Spoke system\ndesigned for scalable detection and suppression of SLF populations. A central,\ntree-mimicking hub utilizes a YOLOv8 computer vision model for precise SLF\nidentification. Three specialized robotic spokes perform targeted tasks: pest\nneutralization, environmental monitoring, and navigation/mapping. Field\ndeployment across multiple infested sites over 5 weeks demonstrated\nLanternNet's efficacy. Quantitative analysis revealed significant reductions (p\n< 0.01, paired t-tests) in SLF populations and corresponding improvements in\ntree health indicators across the majority of test sites. Compared to\nconventional methods, LanternNet offers substantial cost advantages and\nimproved scalability. Furthermore, the system's adaptability for enhanced\nautonomy and targeting of other invasive species presents significant potential\nfor broader ecological impact. LanternNet demonstrates the transformative\npotential of integrating robotics and AI for advanced invasive species\nmanagement and improved environmental outcomes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20800v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20444", "title": "Enhancing QoS in Edge Computing through Federated Layering Techniques: A Pathway to Resilient AI Lifelong Learning Systems", "authors": ["Chengzhuo Han"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20444v1", "summary": "In the context of the rapidly evolving information technology landscape,\nmarked by the advent of 6G communication networks, we face an increased data\nvolume and complexity in network environments. This paper addresses these\nchallenges by focusing on Quality of Service (QoS) in edge computing\nframeworks. We propose a novel approach to enhance QoS through the development\nof General Artificial Intelligence Lifelong Learning Systems, with a special\nemphasis on Federated Layering Techniques (FLT). Our work introduces a\nfederated layering-based small model collaborative mechanism aimed at improving\nAI models' operational efficiency and response time in environments where\nresources are limited. This innovative method leverages the strengths of cloud\nand edge computing, incorporating a negotiation and debate mechanism among\nsmall AI models to enhance reasoning and decision-making processes. By\nintegrating model layering techniques with privacy protection measures, our\napproach ensures the secure transmission of model parameters while maintaining\nhigh efficiency in learning and reasoning capabilities. The experimental\nresults demonstrate that our strategy not only enhances learning efficiency and\nreasoning accuracy but also effectively protects the privacy of edge nodes.\nThis presents a viable solution for achieving resilient large model lifelong\nlearning systems, with a significant improvement in QoS for edge computing\nenvironments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20444v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20656", "title": "EarXplore: An Open Research Database on Earable Interaction", "authors": ["Jonas Hummel", "Tobias Röddiger", "Valeria Zitz", "Philipp Lepold", "Michael Küttner", "Marius Prill", "Christopher Clarke", "Hans Gellersen", "Michael Beigl"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20656v1", "summary": "Interaction with earables - earphones equipped with additional sensors - has\nbeen identified as one of four major areas of earable research. Worn naturally\nand positioned near key physiological signals, earables support a wide range of\ninteraction modalities and have demonstrated the ability to detect multiple\ninputs simultaneously. Yet this diversity has resulted in a fragmented body of\nresearch, making it increasingly difficult to track developments and identify\nrelevant studies. To address this, we introduce EarXplore, a curated,\ninteractive online database on earable interaction research. Designed through a\nquestion-centered process that guided both the development of 34 criteria\napplied to annotate 118 studies and the structure of the platform, EarXplore\ncomprises four distinct yet integrated views: a Tabular View for structured\nexploration, a Graphical View for visual overviews, a Similarity View for\nidentifying conceptual links, and a Timeline View for analyzing trends and\nscholarly lineage. We demonstrate how the platform supports tailored\nexploration, targeted filtering, and interactive information retrieval,\nallowing researchers to query the literature and synthesize information in the\nformat of their choice. We furthermore leverage the contents and capabilities\nof the platform to discuss the research gaps and opportunities in the field.\nWith built-in mechanisms for continuous community updates, EarXplore not only\nreflects the current state of the field but also evolves alongside it, serving\nas a living resource to inform and accelerate future developments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20656v1", "cate": "cs.HC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19639", "title": "Directly Learning Stock Trading Strategies Through Profit Guided Loss Functions", "authors": ["Devroop Kar", "Zimeng Lyu", "Sheeraja Rajakrishnan", "Hao Zhang", "Alex Ororbia", "Travis Desell", "Daniel Krutz"], "categories": ["cs.LG", "cs.NE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      17 pages, 4 figures, Submitted to Neural Information Processing Systems 2025", "url": "http://arxiv.org/abs/2507.19639v1", "summary": "Stock trading has always been a challenging task due to the highly volatile\nnature of the stock market. Making sound trading decisions to generate profit\nis particularly difficult under such conditions. To address this, we propose\nfour novel loss functions to drive decision-making for a portfolio of stocks.\nThese functions account for the potential profits or losses based with respect\nto buying or shorting respective stocks, enabling potentially any artificial\nneural network to directly learn an effective trading strategy. Despite the\nhigh volatility in stock market fluctuations over time, training time-series\nmodels such as transformers on these loss functions resulted in trading\nstrategies that generated significant profits on a portfolio of 50 different\nS&P 500 company stocks as compared to a benchmark reinforcment learning\ntechniques and a baseline buy and hold method. As an example, using 2021, 2022\nand 2023 as three test periods, the Crossformer model adapted with our best\nloss function was most consistent, resulting in returns of 51.42%, 51.04% and\n48.62% respectively. In comparison, the best performing state-of-the-art\nreinforcement learning methods, PPO and DDPG, only delivered maximum profits of\naround 41%, 2.81% and 41.58% for the same periods. The code is available at\nhttps://anonymous.4open.science/r/bandit-stock-trading-58C8/README.md.", "comment": "17 pages, 4 figures, Submitted to Neural Information Processing\n  Systems 2025", "pdf_url": "http://arxiv.org/pdf/2507.19639v1", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20402", "title": "CIgrate: Automating CI Service Migration with Large Language Models", "authors": ["Md Nazmul Hossain", "Taher A. Ghaleb"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Registered Report Accepted at the 41st IEEE International Conference on Software Maintenance and Evolution 2025 (ICSME'25)", "url": "http://arxiv.org/abs/2507.20402v1", "summary": "Continuous Integration (CI) configurations often need to be migrated between\nservices (e.g., Travis CI to GitHub Actions) as projects evolve, due to changes\nin service capabilities, usage limits, or service deprecation. Previous studies\nreported that migration across CI services is a recurring need in open-source\ndevelopment. However, manual migration can be time-consuming and error-prone.\nThe state-of-the-art approach, CIMig, addresses this challenge by analyzing\npast migration examples to create service-specific rules and produce equivalent\nconfigurations across CI services. However, its relatively low accuracy raises\nconcerns about the overall feasibility of automated CI migration using\nrule-based techniques alone. Meanwhile, Large Language Models (LLMs) have\ndemonstrated strong capabilities in code generation and transformation tasks,\nsuggesting potential to improve the automation, usability, and generalizability\nof CI configuration migration. This registered report presents a study in which\nwe aim to assess whether CI migration can be improved using LLMs. To this end,\nwe propose CIgrate, an LLM-based framework for automatically migrating CI\nconfigurations. We plan to evaluate the performance of CIgrate compared to\nCIMig as a baseline, in different setups (a) zero-shot/few-shot prompting of\nLLMs for configuration migration and (b) fine-tuning an LLM on a dataset of\nalready established CI service migrations. We will also seek developer feedback\non the quality and usability of the generated configurations. We formulate\nresearch questions focusing on the accuracy of LLM-generated migrations versus\nground truth and the output of CIMig. The expected contributions include the\nfirst LLM-powered approach for CI service migration, a comparative evaluation\nof its effectiveness compared to rule-based approaches, and insight into\nleveraging LLMs to support software configuration evolution.", "comment": "Registered Report Accepted at the 41st IEEE International Conference\n  on Software Maintenance and Evolution 2025 (ICSME'25)", "pdf_url": "http://arxiv.org/pdf/2507.20402v1", "cate": "cs.SE", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20966", "title": "Handoff Design in User-Centric Cell-Free Massive MIMO Networks Using DRL", "authors": ["Hussein A. Ammar", "Raviraj Adve", "Shahram Shahbazpanahi", "Gary Boudreau", "Israfil Bahceci"], "categories": ["cs.IT", "cs.AI", "cs.LG", "cs.NI", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Published in IEEE Transactions on Communications (IEEE TCOM)", "url": "http://arxiv.org/abs/2507.20966v1", "summary": "In the user-centric cell-free massive MIMO (UC-mMIMO) network scheme, user\nmobility necessitates updating the set of serving access points to maintain the\nuser-centric clustering. Such updates are typically performed through handoff\n(HO) operations; however, frequent HOs lead to overheads associated with the\nallocation and release of resources. This paper presents a deep reinforcement\nlearning (DRL)-based solution to predict and manage these connections for\nmobile users. Our solution employs the Soft Actor-Critic algorithm, with\ncontinuous action space representation, to train a deep neural network to serve\nas the HO policy. We present a novel proposition for a reward function that\nintegrates a HO penalty in order to balance the attainable rate and the\nassociated overhead related to HOs. We develop two variants of our system; the\nfirst one uses mobility direction-assisted (DA) observations that are based on\nthe user movement pattern, while the second one uses history-assisted (HA)\nobservations that are based on the history of the large-scale fading (LSF).\nSimulation results show that our DRL-based continuous action space approach is\nmore scalable than discrete space counterpart, and that our derived HO policy\nautomatically learns to gather HOs in specific time slots to minimize the\noverhead of initiating HOs. Our solution can also operate in real time with a\nresponse time less than 0.4 ms.", "comment": "Published in IEEE Transactions on Communications (IEEE TCOM)", "pdf_url": "http://arxiv.org/pdf/2507.20966v1", "cate": "cs.IT", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20255", "title": "Stochastic Channel Models for Satellite Mega-Constellations", "authors": ["Brendon McBain", "Yi Hong", "Emanuele Viterbo"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Accepted for publication in the IEEE Transactions on Communications in July 2025", "url": "http://arxiv.org/abs/2507.20255v1", "summary": "A general satellite channel model is proposed for communications between a\nrapidly moving low Earth orbit (LEO) satellite in a mega-constellation and a\nstationary user on Earth. The channel uses a non-homogeneous binomial point\nprocess (NBPP) for modelling the satellite positions, marked with an\nascending/descending binary random variable for modelling the satellite\ndirections. Using the marked NBPP, we derive the probability distributions of\npower gain, propagation delay, and Doppler shift, resulting in a stochastic\nsignal propagation model for the mega-constellation geometry in isolation of\nother effects. This forms the basis for our proposed channel model as a\nrandomly time-varying channel. The scattering function of this channel is\nderived to characterise how the received power is spread in the delay-Doppler\ndomain. Global channel parameters such as path loss and channel spread are\nanalysed in terms of the scattering function. The channel statistics and the\nglobal channel parameters closely match realistic orbit simulations of the\nStarlink constellation.", "comment": "Accepted for publication in the IEEE Transactions on Communications\n  in July 2025", "pdf_url": "http://arxiv.org/pdf/2507.20255v1", "cate": "cs.IT", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19953", "title": "Offloading tracing for real-time systems using a scalable cloud infrastructure", "authors": ["David Jannis Schmidt", "Grigory Fridman", "Florian von Zabiensky"], "categories": ["cs.DC", "D.2.5; C.3; D.2.11"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Submitted to ECRTS 2025 RT-Cloud Workshop proceedings", "url": "http://arxiv.org/abs/2507.19953v1", "summary": "Real-time embedded systems require precise timing and fault detection to\nensure correct behavior. Traditional tracing tools often rely on local desktops\nwith limited processing and storage capabilities, which hampers large-scale\nanalysis. This paper presents a scalable, cloud-based architecture for software\ntracing in real-time systems based on microservices and edge computing. Our\napproach shifts the trace processing workload from the developer's machine to\nthe cloud, using a dedicated tracing component that captures trace data and\nforwards it to a scalable backend via WebSockets and Apache Kafka. This enables\nlong-term monitoring and collaborative analysis of target executions, e.g., to\ndetect and investigate sporadic errors. We demonstrate how this architecture\nsupports scalable analysis of parallel tracing sessions and lays the foundation\nfor future integration of rule-based testing and runtime verification. The\nevaluation results show that the architecture can handle many parallel tracing\nsessions efficiently, although the per-session throughput decreases slightly as\nthe system load increases, while the overall throughput increases. Although the\ndesign includes a dedicated tracer for analysis during development, this\napproach is not limited to such setups. Target systems with network\nconnectivity can stream reduced trace data directly, enabling runtime\nmonitoring in the field.", "comment": "Submitted to ECRTS 2025 RT-Cloud Workshop proceedings", "pdf_url": "http://arxiv.org/pdf/2507.19953v1", "cate": "cs.DC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20832", "title": "Hanging Around: Cognitive Inspired Reasoning for Reactive Robotics", "authors": ["Mihai Pomarlan", "Stefano De Giorgis", "Rachel Ringe", "Maria M. Hedblom", "Nikolaos Tsiogkas"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This article is published online with Open Access by IOS Press and distributed under the terms of the Creative Commons Attribution Non-Commercial License 4.0 (CC BY-NC 4.0)", "url": "http://arxiv.org/abs/2507.20832v1", "summary": "Situationally-aware artificial agents operating with competence in natural\nenvironments face several challenges: spatial awareness, object affordance\ndetection, dynamic changes and unpredictability. A critical challenge is the\nagent's ability to identify and monitor environmental elements pertinent to its\nobjectives. Our research introduces a neurosymbolic modular architecture for\nreactive robotics. Our system combines a neural component performing object\nrecognition over the environment and image processing techniques such as\noptical flow, with symbolic representation and reasoning. The reasoning system\nis grounded in the embodied cognition paradigm, via integrating image schematic\nknowledge in an ontological structure. The ontology is operatively used to\ncreate queries for the perception system, decide on actions, and infer\nentities' capabilities derived from perceptual data. The combination of\nreasoning and image processing allows the agent to focus its perception for\nnormal operation as well as discover new concepts for parts of objects involved\nin particular interactions. The discovered concepts allow the robot to\nautonomously acquire training data and adjust its subsymbolic perception to\nrecognize the parts, as well as making planning for more complex tasks feasible\nby focusing search on those relevant object parts. We demonstrate our approach\nin a simulated world, in which an agent learns to recognize parts of objects\ninvolved in support relations. While the agent has no concept of handle\ninitially, by observing examples of supported objects hanging from a hook it\nlearns to recognize the parts involved in establishing support and becomes able\nto plan the establishment/destruction of the support relation. This underscores\nthe agent's capability to expand its knowledge through observation in a\nsystematic way, and illustrates the potential of combining deep reasoning\n[...].", "comment": "This article is published online with Open Access by IOS Press and\n  distributed under the terms of the Creative Commons Attribution\n  Non-Commercial License 4.0 (CC BY-NC 4.0)", "pdf_url": "http://arxiv.org/pdf/2507.20832v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20451", "title": "STARN-GAT: A Multi-Modal Spatio-Temporal Graph Attention Network for Accident Severity Prediction", "authors": ["Pritom Ray Nobin", "Imran Ahammad Rifat"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.20451v1", "summary": "Accurate prediction of traffic accident severity is critical for improving\nroad safety, optimizing emergency response strategies, and informing the design\nof safer transportation infrastructure. However, existing approaches often\nstruggle to effectively model the intricate interdependencies among spatial,\ntemporal, and contextual variables that govern accident outcomes. In this\nstudy, we introduce STARN-GAT, a Multi-Modal Spatio-Temporal Graph Attention\nNetwork, which leverages adaptive graph construction and modality-aware\nattention mechanisms to capture these complex relationships. Unlike\nconventional methods, STARN-GAT integrates road network topology, temporal\ntraffic patterns, and environmental context within a unified attention-based\nframework. The model is evaluated on the Fatality Analysis Reporting System\n(FARS) dataset, achieving a Macro F1-score of 85 percent, ROC-AUC of 0.91, and\nrecall of 81 percent for severe incidents. To ensure generalizability within\nthe South Asian context, STARN-GAT is further validated on the ARI-BUET traffic\naccident dataset, where it attains a Macro F1-score of 0.84, recall of 0.78,\nand ROC-AUC of 0.89. These results demonstrate the model's effectiveness in\nidentifying high-risk cases and its potential for deployment in real-time,\nsafety-critical traffic management systems. Furthermore, the attention-based\narchitecture enhances interpretability, offering insights into contributing\nfactors and supporting trust in AI-assisted decision-making. Overall, STARN-GAT\nbridges the gap between advanced graph neural network techniques and practical\napplications in road safety analytics.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.20451v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20720", "title": "Beyond Text: Probing K-12 Educators' Perspectives and Ideas for Learning Opportunities Leveraging Multimodal Large Language Models", "authors": ["Tiffany Tseng", "Katelyn Lam", "Tiffany Lin Fu", "Alekhya Maram"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20720v1", "summary": "Multimodal Large Language Models (MLLMs) are beginning to empower new user\nexperiences that can flexibly generate content from a range of inputs,\nincluding images, text, speech, and video. These capabilities have the\npotential to enrich learning by enabling users to capture and interact with\ninformation using a variety of modalities, but little is known about how\neducators envision how MLLMs might shape the future of learning experiences,\nwhat challenges diverse teachers encounter when interpreting how these models\nwork, and what practical needs should be considered for successful\nimplementation in educational contexts. We investigated educator perspectives\nthrough formative workshops with 12 K-12 educators, where participants\nbrainstormed learning opportunities, discussed practical concerns for effective\nuse, and prototyped their own MLLM-powered learning applications using Claude\n3.5 and its Artifacts feature for previewing code-based output. We use case\nstudies to illustrate two contrasting end-user approaches (teacher-and\nstudent-driven), and share insights about opportunities and concerns expressed\nby our participants, ending with implications for leveraging MLLMs for future\nlearning experiences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20720v1", "cate": "cs.HC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19680", "title": "Feature learning is decoupled from generalization in high capacity neural networks", "authors": ["Niclas Alexander Göring", "Charles London", "Abdurrahman Hadi Erturk", "Chris Mingard", "Yoonsoo Nam", "Ard A. Louis"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19680v1", "summary": "Neural networks outperform kernel methods, sometimes by orders of magnitude,\ne.g. on staircase functions. This advantage stems from the ability of neural\nnetworks to learn features, adapting their hidden representations to better\ncapture the data. We introduce a concept we call feature quality to measure\nthis performance improvement. We examine existing theories of feature learning\nand demonstrate empirically that they primarily assess the strength of feature\nlearning, rather than the quality of the learned features themselves.\nConsequently, current theories of feature learning do not provide a sufficient\nfoundation for developing theories of neural network generalization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19680v1", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20407", "title": "Testing Is Not Boring: Characterizing Challenge in Software Testing Tasks", "authors": ["Davi Gama Hardman", "Cesar França", "Brody Stuart-Verner", "Ronnie de Souza Santos"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20407v1", "summary": "As software systems continue to grow in complexity, testing has become a\nfundamental part of ensuring the quality and reliability of software products.\nYet, software testing is still often perceived, both in industry and academia,\nas a repetitive, low-skill activity. This perception fails to recognize the\ncreativity, problem-solving, and adaptability required in testing work. Tasks\nsuch as designing complex test cases, automating testing processes, and\nhandling shifting requirements illustrate the challenges testing professionals\nregularly face. To better understand these experiences, we conducted a study\nwith software testing professionals to explore the nature of challenging tasks\nin software testing and how they affect these professionals. Our findings show\nthat tasks involving creativity, ongoing learning, and time pressure are often\nseen as motivating and rewarding. On the other hand, a lack of challenge or\noverwhelming demands can lead to frustration and disengagement. These findings\ndemonstrate the importance of balancing task complexity to sustain motivation\nand present software testing as a dynamic and intellectually engaging field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20407v1", "cate": "cs.SE", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2501.16143", "title": "Disruption-aware Microservice Re-orchestration for Cost-efficient Multi-cloud Deployments", "authors": ["Marco Zambianco", "Silvio Cretti", "Domenico Siracusa"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.16143v3", "summary": "Multi-cloud environments enable a cost-efficient scaling of cloud-native\napplications across geographically distributed virtual nodes with different\npricing models. In this context, the resource fragmentation caused by frequent\nchanges in the resource demands of deployed microservices, along with the\nallocation or termination of new and existing microservices, increases the\ndeployment cost. Therefore, re-orchestrating deployed microservices on a\ncheaper configuration of multi-cloud nodes offers a practical solution to\nrestore the cost efficiency of deployment. However, the rescheduling procedure\ncauses frequent service interruptions due to the continuous termination and\nrebooting of the containerized microservices. Moreover, it may potentially\ninterfere with and delay other deployment operations, compromising the\nstability of the running applications. To address this issue, we formulate a\nmulti-objective integer linear programming (ILP) problem that computes a\nmicroservice rescheduling solution capable of providing minimum deployment cost\nwithout significantly affecting the service continuity. At the same time, the\nproposed formulation also preserves the quality of service (QoS) requirements,\nincluding latency, expressed through microservice co-location constraints.\nAdditionally, we present a heuristic algorithm to approximate the optimal\nsolution, striking a balance between cost reduction and service disruption\nmitigation. We integrate the proposed approach as a custom plugin of the\nKubernetes (K8s) scheduler. Results reveal that our approach significantly\nreduces multi-cloud deployment costs and service disruptions compared to the\nbenchmark schemes, while ensuring QoS requirements are consistently met.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.16143v3", "cate": "cs.NI", "date": "2025-01-27", "updated": "2025-07-28"}
{"id": "2507.20281", "title": "Ensemble Average Analysis of Non-Adaptive Group Testing with Sparse Pooling Graphs", "authors": ["Emna Ben Yacoub", "Gianluigi Liva", "Enrico Paolini", "Marco Chiani"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      To be presented at the 2025 International Symposium on Topics in Coding (ISTC)", "url": "http://arxiv.org/abs/2507.20281v1", "summary": "A combinatorial analysis of the false alarm (FA) and misdetection (MD)\nprobabilities of non-adaptive group testing with sparse pooling graphs is\ndeveloped. The analysis targets the combinatorial orthogonal matching pursuit\nand definite defective detection algorithms in the noiseless, non-quantitative\nsetting. The approach follows an ensemble average perspective, where average\nFA/MD probabilities are computed for pooling graph ensembles with prescribed\ndegree distributions. The accuracy of the analysis is demonstrated through\nnumerical examples, showing that the proposed technique can be used to\ncharacterize the performance of non-adaptive group testing schemes based on\nsparse pooling graphs.", "comment": "To be presented at the 2025 International Symposium on Topics in\n  Coding (ISTC)", "pdf_url": "http://arxiv.org/pdf/2507.20281v1", "cate": "cs.IT", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20041", "title": "MTASet: A Tree-based Set for Efficient Range Queries in Update-heavy Workloads", "authors": ["Daniel Manor", "Mor Perry", "Moshe Sulamy"], "categories": ["cs.DC", "cs.DS"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20041v1", "summary": "In concurrent data structures, the efficiency of set operations can vary\nsignificantly depending on the workload characteristics. Numerous concurrent\nset implementations are optimized and fine-tuned to excel in scenarios\ncharacterized by predominant read operations. However, they often perform\npoorly when confronted with workloads that heavily prioritize updates.\nAdditionally, current leading-edge concurrent sets optimized for update-heavy\ntasks typically lack efficiency in handling atomic range queries. This study\nintroduces the MTASet, which leverages a concurrent (a,b)-tree implementation.\nEngineered to accommodate update-heavy workloads and facilitate atomic range\nqueries, MTASet surpasses existing counterparts optimized for tasks in range\nquery operations by up to 2x. Notably, MTASet ensures linearizability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20041v1", "cate": "cs.DC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19487", "title": "Does AI and Human Advice Mitigate Punishment for Selfish Behavior? An Experiment on AI ethics From a Psychological Perspective", "authors": ["Margarita Leib", "Nils Köbis", "Ivan Soraperra"], "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC", "econ.GN", "q-fin.EC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19487v1", "summary": "People increasingly rely on AI-advice when making decisions. At times, such\nadvice can promote selfish behavior. When individuals abide by\nselfishness-promoting AI advice, how are they perceived and punished? To study\nthis question, we build on theories from social psychology and combine\nmachine-behavior and behavioral economic approaches. In a pre-registered,\nfinancially-incentivized experiment, evaluators could punish real\ndecision-makers who (i) received AI, human, or no advice. The advice (ii)\nencouraged selfish or prosocial behavior, and decision-makers (iii) behaved\nselfishly or, in a control condition, behaved prosocially. Evaluators further\nassigned responsibility to decision-makers and their advisors. Results revealed\nthat (i) prosocial behavior was punished very little, whereas selfish behavior\nwas punished much more. Focusing on selfish behavior, (ii) compared to\nreceiving no advice, selfish behavior was penalized more harshly after\nprosocial advice and more leniently after selfish advice. Lastly, (iii) whereas\nselfish decision-makers were seen as more responsible when they followed AI\ncompared to human advice, punishment between the two advice sources did not\nvary. Overall, behavior and advice content shape punishment, whereas the advice\nsource does not.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19487v1", "cate": "cs.CY", "date": "2025-05-26", "updated": "2025-05-26"}
{"id": "2507.20162", "title": "IFD: A Large-Scale Benchmark for Insider Filing Violation Detection", "authors": ["Cheng Huang", "Fan Gao", "Yutong Liu", "Yadi Liu", "Xiaoli Ma", "Ye Aung Moe", "Yuhan Zhang", "Yao Ma", "Hao Wang", "Xiangxiang Wang", "Yongbin Yu"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20162v1", "summary": "Insider trading violations, particularly delayed disclosures of Form 4\nfilings, remain a persistent challenge for financial market surveillance.\nDespite regulatory requirements such as the two-business-day rule of the\nSecurities and Exchange Commission (SEC), enforcement is limited by the lack of\nlarge-scale, labeled datasets and task-specific benchmarks. In this paper, we\nintroduce Insider Filing Delay (IFD), the first and largest publicly available\ndataset for insider disclosure behavior, comprising over one million Form 4\ntransactions spanning two decades (2002-2025), with structured annotations on\ndelay status, insider roles, governance factors, and firm-level financial\nindicators. IFD enables the first large-scale formulation of strategic\ndisclosure violation detection as a binary classification task grounded in\nregulatory compliance. To demonstrate the utility of IFD, we propose MaBoost, a\nhybrid framework combining a Mamba-based state space encoder with XGBoost,\nachieving high accuracy and interpretability in identifying high-risk\nbehavioral patterns. Experiments across statistical baselines, deep learning\nmodels, and large language models confirm that MaBoost outperforms prior\napproaches, achieving an F1-score of up to 99.47% under constrained regulatory\nsettings. IFD provides a realistic, reproducible, and behavior-rich benchmark\nfor developing AI models in financial compliance, regulatory forensics, and\ninterpretable time-series classification. All data and codes are available:\nhttps://github.com/CH-YellowOrange/MaBoost-and-IFD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20162v1", "cate": "cs.CE", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20850", "title": "Free Energy-Inspired Cognitive Risk Integration for AV Navigation in Pedestrian-Rich Environments", "authors": ["Meiting Dang", "Yanping Wu", "Yafei Wang", "Dezong Zhao", "David Flynn", "Chongfeng Wei"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      14 pages, 5 figures", "url": "http://arxiv.org/abs/2507.20850v1", "summary": "Recent advances in autonomous vehicle (AV) behavior planning have shown\nimpressive social interaction capabilities when interacting with other road\nusers. However, achieving human-like prediction and decision-making in\ninteractions with vulnerable road users remains a key challenge in complex\nmulti-agent interactive environments. Existing research focuses primarily on\ncrowd navigation for small mobile robots, which cannot be directly applied to\nAVs due to inherent differences in their decision-making strategies and dynamic\nboundaries. Moreover, pedestrians in these multi-agent simulations follow fixed\nbehavior patterns that cannot dynamically respond to AV actions. To overcome\nthese limitations, this paper proposes a novel framework for modeling\ninteractions between the AV and multiple pedestrians. In this framework, a\ncognitive process modeling approach inspired by the Free Energy Principle is\nintegrated into both the AV and pedestrian models to simulate more realistic\ninteraction dynamics. Specifically, the proposed pedestrian Cognitive-Risk\nSocial Force Model adjusts goal-directed and repulsive forces using a fused\nmeasure of cognitive uncertainty and physical risk to produce human-like\ntrajectories. Meanwhile, the AV leverages this fused risk to construct a\ndynamic, risk-aware adjacency matrix for a Graph Convolutional Network within a\nSoft Actor-Critic architecture, allowing it to make more reasonable and\ninformed decisions. Simulation results indicate that our proposed framework\neffectively improves safety, efficiency, and smoothness of AV navigation\ncompared to the state-of-the-art method.", "comment": "14 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.20850v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20526", "title": "Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition", "authors": ["Andy Zou", "Maxwell Lin", "Eliot Jones", "Micha Nowak", "Mateusz Dziemian", "Nick Winter", "Alexander Grattan", "Valent Nathanael", "Ayla Croft", "Xander Davies", "Jai Patel", "Robert Kirk", "Nate Burnikell", "Yarin Gal", "Dan Hendrycks", "J. Zico Kolter", "Matt Fredrikson"], "categories": ["cs.AI", "cs.CL", "cs.CY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20526v1", "summary": "Recent advances have enabled LLM-powered AI agents to autonomously execute\ncomplex tasks by combining language model reasoning with tools, memory, and web\naccess. But can these systems be trusted to follow deployment policies in\nrealistic environments, especially under attack? To investigate, we ran the\nlargest public red-teaming competition to date, targeting 22 frontier AI agents\nacross 44 realistic deployment scenarios. Participants submitted 1.8 million\nprompt-injection attacks, with over 60,000 successfully eliciting policy\nviolations such as unauthorized data access, illicit financial actions, and\nregulatory noncompliance. We use these results to build the Agent Red Teaming\n(ART) benchmark - a curated set of high-impact attacks - and evaluate it across\n19 state-of-the-art models. Nearly all agents exhibit policy violations for\nmost behaviors within 10-100 queries, with high attack transferability across\nmodels and tasks. Importantly, we find limited correlation between agent\nrobustness and model size, capability, or inference-time compute, suggesting\nthat additional defenses are needed against adversarial misuse. Our findings\nhighlight critical and persistent vulnerabilities in today's AI agents. By\nreleasing the ART benchmark and accompanying evaluation framework, we aim to\nsupport more rigorous security assessment and drive progress toward safer agent\ndeployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20526v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20730", "title": "Vocalize: Lead Acquisition and User Engagement through Gamified Voice Competitions", "authors": ["Edvin Teskeredzic", "Muamer Paric", "Adna Sestic", "Petra Fribert", "Anamarija Lukac", "Hadzem Hadzic", "Kemal Altwlkany", "Emanuel Lacic"], "categories": ["cs.HC", "cs.MM"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted to ACM Hypertext 2025", "url": "http://arxiv.org/abs/2507.20730v1", "summary": "This paper explores the prospect of creating engaging user experiences and\ncollecting leads through an interactive and gamified platform. We introduce\nVocalize, an end-to-end system for increasing user engagement and lead\nacquisition through gamified voice competitions. Using audio processing\ntechniques and LLMs, we create engaging and interactive experiences that have\nthe potential to reach a wide audience, foster brand recognition, and increase\ncustomer loyalty. We describe the system from a technical standpoint and report\nresults from launching Vocalize at 4 different live events. Our user study\nshows that Vocalize is capable of generating significant user engagement, which\nshows potential for gamified audio campaigns in marketing and similar\nverticals.", "comment": "Accepted to ACM Hypertext 2025", "pdf_url": "http://arxiv.org/pdf/2507.20730v1", "cate": "cs.HC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19684", "title": "Salsa as a Nonverbal Embodied Language -- The CoMPAS3D Dataset and Benchmarks", "authors": ["Bermet Burkanova", "Payam Jome Yazdian", "Chuxuan Zhang", "Trinity Evans", "Paige Tuttösí", "Angelica Lim"], "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:       this https URL", "url": "http://arxiv.org/abs/2507.19684v1", "summary": "Imagine a humanoid that can safely and creatively dance with a human,\nadapting to its partner's proficiency, using haptic signaling as a primary form\nof communication. While today's AI systems excel at text or voice-based\ninteraction with large language models, human communication extends far beyond\ntext-it includes embodied movement, timing, and physical coordination. Modeling\ncoupled interaction between two agents poses a formidable challenge: it is\ncontinuous, bidirectionally reactive, and shaped by individual variation. We\npresent CoMPAS3D, the largest and most diverse motion capture dataset of\nimprovised salsa dancing, designed as a challenging testbed for interactive,\nexpressive humanoid AI. The dataset includes 3 hours of leader-follower salsa\ndances performed by 18 dancers spanning beginner, intermediate, and\nprofessional skill levels. For the first time, we provide fine-grained salsa\nexpert annotations, covering over 2,800 move segments, including move types,\ncombinations, execution errors and stylistic elements. We draw analogies\nbetween partner dance communication and natural language, evaluating CoMPAS3D\non two benchmark tasks for synthetic humans that parallel key problems in\nspoken language and dialogue processing: leader or follower generation with\nproficiency levels (speaker or listener synthesis), and duet (conversation)\ngeneration. Towards a long-term goal of partner dance with humans, we release\nthe dataset, annotations, and code, along with a multitask SalsaAgent model\ncapable of performing all benchmark tasks, alongside additional baselines to\nencourage research in socially interactive embodied AI and creative, expressive\nhumanoid motion generation.", "comment": "https://rosielab.github.io/compas3d", "pdf_url": "http://arxiv.org/pdf/2507.19684v1", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20439", "title": "When Prompts Go Wrong: Evaluating Code Model Robustness to Ambiguous, Contradictory, and Incomplete Task Descriptions", "authors": ["Maya Larbi", "Amal Akli", "Mike Papadakis", "Rihab Bouyousfi", "Maxime Cordy", "Federica Sarro", "Yves Le Traon"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20439v1", "summary": "Large Language Models (LLMs) have demonstrated impressive performance in code\ngeneration tasks under idealized conditions, where task descriptions are clear\nand precise. However, in practice, task descriptions frequently exhibit\nambiguity, incompleteness, or internal contradictions. In this paper, we\npresent the first empirical study examining the robustness of state-of-the-art\ncode generation models when faced with such unclear task descriptions. We\nextend the HumanEval and MBPP benchmarks by systematically introducing\nrealistic task descriptions flaws through guided mutation strategies, producing\na dataset that mirrors the messiness of informal developer instructions. We\nevaluate multiple LLMs of varying sizes and architectures, analyzing their\nfunctional correctness and failure modes across task descriptions categories.\nOur findings reveal that even minor imperfections in task description phrasing\ncan cause significant performance degradation, with contradictory task\ndescriptions resulting in numerous logical errors. Moreover, while larger\nmodels tend to be more resilient than smaller variants, they are not immune to\nthe challenges posed by unclear requirements. We further analyze semantic error\npatterns and identify correlations between description clarity, model behavior,\nand error types. Our results underscore the critical need for developing LLMs\nthat are not only powerful but also robust to the imperfections inherent in\nnatural user tasks, highlighting important considerations for improving model\ntraining strategies, designing more realistic evaluation benchmarks, and\nensuring reliable deployment in practical software development environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20439v1", "cate": "cs.SE", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2502.02886", "title": "Advancements in Mobile Edge Computing and Open RAN: Leveraging Artificial Intelligence and Machine Learning for Wireless Systems", "authors": ["Ryan Barker", "Tolunay Seyfi", "Fatemeh Afghah"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      6 pages, 1 figure", "url": "http://arxiv.org/abs/2502.02886v3", "summary": "Mobile Edge Computing (MEC) and Open Radio Access Networks (ORAN) are\ntransformative technologies in the development of next-generation wireless\ncommunication systems. MEC pushes computational resources closer to end-users,\nenabling low latency and efficient processing, while ORAN promotes\ninteroperability and openness in radio networks, thereby fostering innovation.\nThis paper explores recent advancements in these two domains, with a particular\nfocus on how Artificial Intelligence (AI) and Machine Learning (ML) techniques\nare being utilized to solve complex wireless challenges. In MEC, Deep\nReinforcement Learning (DRL) is leveraged for optimizing computation\noffloading, ensuring energy-efficient solutions, and meeting Quality of Service\n(QoS) requirements. In ORAN, AI/ML is used to develop intelligent xApps for\nnetwork slicing, scheduling, and online training to enhance network\nadaptability. This reading report provides an in-depth analysis of multiple key\npapers, discusses the methodologies employed, and highlights the impact of\nthese technologies in improving network efficiency and scalability.", "comment": "6 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2502.02886v3", "cate": "cs.NI", "date": "2025-02-05", "updated": "2025-07-28"}
{"id": "2507.20477", "title": "Rethinking Multi-User Communication in Semantic Domain: Enhanced OMDMA by Shuffle-Based Orthogonalization and Diffusion Denoising", "authors": ["Maojun Zhang", "Guangxu Zhu", "Xiaoming Chen", "Kaibin Huang", "Zhaoyang Zhang"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      16 pages", "url": "http://arxiv.org/abs/2507.20477v1", "summary": "Inter-user interference remains a critical bottleneck in wireless\ncommunication systems, particularly in the emerging paradigm of semantic\ncommunication (SemCom). Compared to traditional systems, inter-user\ninterference in SemCom severely degrades key semantic information, often\ncausing worse performance than Gaussian noise under the same power level. To\naddress this challenge, inspired by the recently proposed concept of Orthogonal\nModel Division Multiple Access (OMDMA) that leverages semantic orthogonality\nrooted in the personalized joint source and channel (JSCC) models to\ndistinguish users, we propose a novel, scalable framework that eliminates the\nneed for user-specific JSCC models as did in original OMDMA. Our key innovation\nlies in shuffle-based orthogonalization, where randomly permuting the positions\nof JSCC feature vectors transforms inter-user interference into Gaussian-like\nnoise. By assigning each user a unique shuffling pattern, the interference is\ntreated as channel noise, enabling effective mitigation using diffusion models\n(DMs). This approach not only simplifies system design by requiring a single\nuniversal JSCC model but also enhances privacy, as shuffling patterns act as\nimplicit private keys. Additionally, we extend the framework to scenarios\ninvolving semantically correlated data. By grouping users based on semantic\nsimilarity, a cooperative beamforming strategy is introduced to exploit\nredundancy in correlated data, further improving system performance. Extensive\nsimulations demonstrate that the proposed method outperforms state-of-the-art\nmulti-user SemCom frameworks, achieving superior semantic fidelity, robustness\nto interference, and scalability-all without requiring additional training\noverhead.", "comment": "16 pages", "pdf_url": "http://arxiv.org/pdf/2507.20477v1", "cate": "cs.IT", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20063", "title": "Racing to Idle: Energy Efficiency of Matrix Multiplication on Heterogeneous CPU and GPU Architectures", "authors": ["Mufakir Qamar Ansari", "Mudabir Qamar Ansari"], "categories": ["cs.DC", "cs.CC", "Primary 68W10, Secondary 65Y05, 68M20", "C.4; D.1.3"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      16 pages, 6 figures, 3 listings. A comprehensive empirical study on a consumer-grade heterogeneous platform", "url": "http://arxiv.org/abs/2507.20063v1", "summary": "The paradigm shift towards multi-core and heterogeneous computing, driven by\nthe fundamental power and thermal limits of single-core processors, has\nestablished energy efficiency as a first-class design constraint in\nhigh-performance computing (HPC). Heterogeneous systems, integrating\ntraditional multi-core CPUs with specialized accelerators like discrete (dGPU)\nand integrated (iGPU) graphics processing units, offer a compelling path to\nnavigating the trade-offs between performance and power. However, quantifying\nthese trade-offs on widely accessible hardware remains a critical area of\nstudy. This paper presents a direct, empirical measurement of the performance\nand energy-to-solution of a canonical HPC workload -- a 4096x4096 matrix-matrix\nmultiplication -- on three distinct compute architectures within a single\nconsumer-grade laptop: a multi-core AMD Ryzen 7 5800H CPU, a discrete NVIDIA\nGeForce GTX 1650 GPU, and an integrated AMD Radeon Vega GPU. Using standard,\nvalidated, and minimally intrusive tools such as Linux perf and nvidia-smi, we\nfind that the discrete GPU is not only the performance leader, achieving a\n93.5x speedup over the CPU, but is also the most energy-efficient, consuming\nonly 2% of the energy used by the CPU, resulting in a 50-fold improvement in\nenergy efficiency. These findings provide a practical demonstration of the\n\"race to idle\" principle and offer clear, quantitative guidance on\narchitectural choices for energy-aware software development.", "comment": "16 pages, 6 figures, 3 listings. A comprehensive empirical study on a\n  consumer-grade heterogeneous platform", "pdf_url": "http://arxiv.org/pdf/2507.20063v1", "cate": "cs.DC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19499", "title": "A Survey of Virtual Reality in Japan", "authors": ["Benjamin Watson"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19499v1", "summary": "The NSF Summer Institute in Japan program sends about 60 graduate students of\nall disciplines to Japan each summer. For two months, students participate in\nresearch at host labs, visit conferences and other labs of interest, and\nreceive Japanese language and cultural instruction. Full financial support is\nprovided by the American and Japanese governments. During the summer of 1993,\nthe author participated in this program and took the opportunity to visit the\nJapanese virtual reality research community. He attended two virtual reality\nconferences and toured more than a dozen labs. After the program, he made short\nvisits to VR and graphics labs in PR China and South Korea. This paper gives a\ndetailed account of these experiences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19499v1", "cate": "cs.CY", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.20535", "title": "Learning Explainable Stock Predictions with Tweets Using Mixture of Experts", "authors": ["Wenyan Xu", "Dawei Xiang", "Rundong Wang", "Yonghong Hu", "Liang Zhang", "Jiayu Chen", "Zhonghua Lu"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      Under review", "url": "http://arxiv.org/abs/2507.20535v1", "summary": "Stock price movements are influenced by many factors, and alongside\nhistorical price data, tex-tual information is a key source. Public news and\nsocial media offer valuable insights into market sentiment and emerging events.\nThese sources are fast-paced, diverse, and significantly impact future stock\ntrends. Recently, LLMs have enhanced financial analysis, but prompt-based\nmethods still have limitations, such as input length restrictions and\ndifficulties in predicting sequences of varying lengths. Additionally, most\nmodels rely on dense computational layers, which are resource-intensive. To\naddress these challenges, we propose the FTS- Text-MoE model, which combines\nnumerical data with key summaries from news and tweets using point embeddings,\nboosting prediction accuracy through the integration of factual textual data.\nThe model uses a Mixture of Experts (MoE) Transformer decoder to process both\ndata types. By activating only a subset of model parameters, it reduces\ncomputational costs. Furthermore, the model features multi-resolution\nprediction heads, enabling flexible forecasting of financial time series at\ndifferent scales. Experimental results show that FTS-Text-MoE outperforms\nbaseline methods in terms of investment returns and Sharpe ratio, demonstrating\nits superior accuracy and ability to predict future market trends.", "comment": "Under review", "pdf_url": "http://arxiv.org/pdf/2507.20535v1", "cate": "cs.CE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20861", "title": "Uncertainty-aware Planning with Inaccurate Models for Robotized Liquid Handling", "authors": ["Marco Faroni", "Carlo Odesco", "Andrea Zanchettin", "Paolo Rocco"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE/RSJ IROS 2025", "url": "http://arxiv.org/abs/2507.20861v1", "summary": "Physics-based simulations and learning-based models are vital for complex\nrobotics tasks like deformable object manipulation and liquid handling.\nHowever, these models often struggle with accuracy due to epistemic uncertainty\nor the sim-to-real gap. For instance, accurately pouring liquid from one\ncontainer to another poses challenges, particularly when models are trained on\nlimited demonstrations and may perform poorly in novel situations. This paper\nproposes an uncertainty-aware Monte Carlo Tree Search (MCTS) algorithm designed\nto mitigate these inaccuracies. By incorporating estimates of model\nuncertainty, the proposed MCTS strategy biases the search towards actions with\nlower predicted uncertainty. This approach enhances the reliability of planning\nunder uncertain conditions. Applied to a liquid pouring task, our method\ndemonstrates improved success rates even with models trained on minimal data,\noutperforming traditional methods and showcasing its potential for robust\ndecision-making in robotics.", "comment": "Accepted at IEEE/RSJ IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.20861v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20541", "title": "MeLA: A Metacognitive LLM-Driven Architecture for Automatic Heuristic Design", "authors": ["Zishang Qiu", "Xinan Chen", "Long Chen", "Ruibin Bai"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20541v1", "summary": "This paper introduces MeLA, a Metacognitive LLM-Driven Architecture that\npresents a new paradigm for Automatic Heuristic Design (AHD). Traditional\nevolutionary methods operate directly on heuristic code; in contrast, MeLA\nevolves the instructional prompts used to guide a Large Language Model (LLM) in\ngenerating these heuristics. This process of \"prompt evolution\" is driven by a\nnovel metacognitive framework where the system analyzes performance feedback to\nsystematically refine its generative strategy. MeLA's architecture integrates a\nproblem analyzer to construct an initial strategic prompt, an error diagnosis\nsystem to repair faulty code, and a metacognitive search engine that\niteratively optimizes the prompt based on heuristic effectiveness. In\ncomprehensive experiments across both benchmark and real-world problems, MeLA\nconsistently generates more effective and robust heuristics, significantly\noutperforming state-of-the-art methods. Ultimately, this research demonstrates\nthe profound potential of using cognitive science as a blueprint for AI\narchitecture, revealing that by enabling an LLM to metacognitively regulate its\nproblem-solving process, we unlock a more robust and interpretable path to AHD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20541v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20741", "title": "Beyond QWERTY: A pressure-based text input approach for XR that enables a touch-typing like experience", "authors": ["Fabian Rücker", "Torben Storch"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20741v1", "summary": "Text input in extended reality (XR) applications remains inefficient and\ntedious. Most solutions are derived from the traditional keyboard layout, yet\nfail to translate its positive characteristics to the spatial digital realm.\nThis limits the productive use of immersive technologies. In this work, we\nanalyze physical keyboard input to identify key characteristics that facilitate\nits comfort, touch typing and high typing speeds. Building on these findings,\nwe propose a novel pressure-based text input modality that transfers these\ncharacteristics into immersive space by substituting the two-dimensional QWERTY\nlayout with a linear scale. This design facilitates a touch-typing-like\nexperience, eliminating the need for visual guidance for proficient users. Our\nskill-based approach enables typing speeds of over 200 characters per minute.\nAdditionally, it is suitable for discreet use in public spaces and everyday\ntext-input tasks, since the proposed system requires virtually no hand or\nfinger movements and resembles smartphone-based text input in appearance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20741v1", "cate": "cs.HC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19686", "title": "KD-GAT: Combining Knowledge Distillation and Graph Attention Transformer for a Controller Area Network Intrusion Detection System", "authors": ["Robert Frenken", "Sidra Ghayour Bhatti", "Hanqin Zhang", "Qadeer Ahmed"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19686v1", "summary": "The Controller Area Network (CAN) protocol is widely adopted for in-vehicle\ncommunication but lacks inherent security mechanisms, making it vulnerable to\ncyberattacks. This paper introduces KD-GAT, an intrusion detection framework\nthat combines Graph Attention Networks (GATs) with knowledge distillation (KD)\nto enhance detection accuracy while reducing computational complexity. In our\napproach, CAN traffic is represented as graphs using a sliding window to\ncapture temporal and relational patterns. A multi-layer GAT with jumping\nknowledge aggregation acting as the teacher model, while a compact student\nGAT--only 6.32% the size of the teacher--is trained via a two-phase process\ninvolving supervised pretraining and knowledge distillation with both soft and\nhard label supervision. Experiments on three benchmark datasets--Car-Hacking,\nCar-Survival, and can-train-and-test demonstrate that both teacher and student\nmodels achieve strong results, with the student model attaining 99.97% and\n99.31% accuracy on Car-Hacking and Car-Survival, respectively. However,\nsignificant class imbalance in can-train-and-test has led to reduced\nperformance for both models on this dataset. Addressing this imbalance remains\nan important direction for future work.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19686v1", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20475", "title": "Distinguishing Quantum Software Bugs from Hardware Noise: A Statistical Approach", "authors": ["Ahmik Virani", "Devraj", "Anirudh Suresh", "Lei Zhang", "M V Panduranga Rao"], "categories": ["cs.SE", "quant-ph"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      12 pages, 30 figures, accepted by the IEEE International Conference on Quantum Computing and Engineering (QCE), IEEE Quantum Week, 2025", "url": "http://arxiv.org/abs/2507.20475v1", "summary": "Quantum computing in the Noisy Intermediate-Scale Quantum (NISQ) era presents\nsignificant challenges in differentiating quantum software bugs from hardware\nnoise. Traditional debugging techniques from classical software engineering\ncannot directly resolve this issue due to the inherently stochastic nature of\nquantum computation mixed with noises from NISQ computers. To address this gap,\nwe propose a statistical approach leveraging probabilistic metrics to\ndifferentiate between quantum software bugs and hardware noise. We evaluate our\nmethodology empirically using well-known quantum algorithms, including Grover's\nalgorithm, Deutsch-Jozsa algorithm, and Simon's algorithm. Experimental results\ndemonstrate the efficacy and practical applicability of our approach, providing\nquantum software developers with a reliable analytical tool to identify and\nclassify unexpected behavior in quantum programs.", "comment": "12 pages, 30 figures, accepted by the IEEE International Conference\n  on Quantum Computing and Engineering (QCE), IEEE Quantum Week, 2025", "pdf_url": "http://arxiv.org/pdf/2507.20475v1", "cate": "cs.SE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2502.02889", "title": "From DeepSense to Open RAN: AI/ML Advancements in Dynamic Spectrum Sensing and Their Applications", "authors": ["Ryan Barker"], "categories": ["cs.NI", "eess.SP"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      6 pages, 9 figures", "url": "http://arxiv.org/abs/2502.02889v2", "summary": "The integration of Artificial Intelligence (AI) and Machine Learning (ML) in\nnext-generation wireless communication systems has become a cornerstone for\nadvancing intelligent, adaptive, and scalable networks. This reading report\nexamines key innovations in dynamic spectrum sensing (DSS), beginning with the\nfoundational DeepSense framework, which uses convolutional neural networks\n(CNNs) and spectrogram-based analysis for real-time wideband spectrum\nmonitoring. Building on this groundwork, it highlights advancements such as\nDeepSweep and Wideband Signal Stitching, which address the challenges of\nscalability, latency, and dataset diversity through parallel processing,\nsemantic segmentation, and robust data augmentation strategies. The report then\nexplores Open Radio Access Networks (ORAN), focusing on AI/ML-driven\nenhancements for UAV experimentation, digital twin-based optimization, network\nslicing, and self-healing xApp development. By bridging AI-based DSS\nmethodologies with ORAN's open, vendor-neutral architecture, these studies\nunderscore the potential of software-defined, intelligent infrastructures in\nenabling efficient, resilient, and self-optimizing networks for 5G/6G\necosystems. Through this synthesis, the report highlights AI's transformative\nrole in shaping the future of wireless communication and autonomous systems.", "comment": "6 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2502.02889v2", "cate": "cs.NI", "date": "2025-02-05", "updated": "2025-07-28"}
{"id": "2507.20504", "title": "Cooperative Jamming Detection Using Low-Rank Structure of Received Signal Matrix", "authors": ["Amir Mehrabian", "Georges Kaddoum"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20504v1", "summary": "Wireless communication can be simply subjected to malicious attacks due to\nits open nature and shared medium. Detecting jamming attacks is the first and\nnecessary step to adopt the anti-jamming strategies. This paper presents novel\ncooperative jamming detection methods that use the low-rank structure of the\nreceived signal matrix. We employed the likelihood ratio test to propose\ndetectors for various scenarios. We regarded several scenarios with different\nnumbers of friendly and jamming nodes and different levels of available\nstatistical information on noise. We also provided an analytical examination of\nthe false alarm performance of one of the proposed detectors, which can be used\nto adjust the detection threshold. We discussed the synthetic signal generation\nand the Monte Carlo (MC)-based threshold setting method, where knowledge of the\ndistribution of the jamming-free signal, as well as several parameters such as\nnoise variance and channel state information (CSI), is required to accurately\ngenerate synthetic signals for threshold estimation. Extensive simulations\nreveal that the proposed detectors outperform several existing methods,\noffering robust and accurate jamming detection in a collaborative network of\nsensing nodes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20504v1", "cate": "cs.IT", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20173", "title": "High-Performance Parallel Optimization of the Fish School Behaviour on the Setonix Platform Using OpenMP", "authors": ["Haitian Wang", "Long Qin"], "categories": ["cs.DC", "cs.AI"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20173v1", "summary": "This paper presents an in-depth investigation into the high-performance\nparallel optimization of the Fish School Behaviour (FSB) algorithm on the\nSetonix supercomputing platform using the OpenMP framework. Given the\nincreasing demand for enhanced computational capabilities for complex,\nlarge-scale calculations across diverse domains, there's an imperative need for\noptimized parallel algorithms and computing structures. The FSB algorithm,\ninspired by nature's social behavior patterns, provides an ideal platform for\nparallelization due to its iterative and computationally intensive nature. This\nstudy leverages the capabilities of the Setonix platform and the OpenMP\nframework to analyze various aspects of multi-threading, such as thread counts,\nscheduling strategies, and OpenMP constructs, aiming to discern patterns and\nstrategies that can elevate program performance. Experiments were designed to\nrigorously test different configurations, and our results not only offer\ninsights for parallel optimization of FSB on Setonix but also provide valuable\nreferences for other parallel computational research using OpenMP. Looking\nforward, other factors, such as cache behavior and thread scheduling strategies\nat micro and macro levels, hold potential for further exploration and\noptimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20173v1", "cate": "cs.DC", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19544", "title": "Origin-Destination Extraction from Large-Scale Route Search Records for Tourism Trend Analysis", "authors": ["Hangli Ge", "Dizhi Huang", "Xiaojie Yang", "Lifeng Lin", "Kazuma Hatano", "Takeshi Kawasaki", "Noboru Koshizuka"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19544v1", "summary": "This paper presents a novel method for transforming large-scale historical\nexpressway route search records into a three-dimensional (3D)\nOrigin-Destination (OD) map, enabling data compression, efficient\nspatiotemporal sampling and statistical analysis. The study analyzed over 380\nmillion expressway route search logs to investigate online search behavior\nrelated to tourist destinations. Several expressway interchanges (ICs) near\npopular attractions, such as those associated with spring flower viewing,\nautumn foliage and winter skiing, are examined and visualized. The results\nreveal strong correlations between search volume trends and the duration of\npeak tourism seasons. This approach leverages cyberspace behavioral data as a\nleading indicator of physical movement, providing a proactive tool for traffic\nmanagement and tourism planning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19544v1", "cate": "cs.CY", "date": "2025-07-24", "updated": "2025-07-24"}
{"id": "2507.20719", "title": "Exascale Implicit Kinetic Plasma Simulations on El~Capitan for Solving the Micro-Macro Coupling in Magnetospheric Physics", "authors": ["Stefano Markidis", "Andong Hu", "Ivy Peng", "Luca Pennati", "Ian Lumsden", "Dewi Yokelson", "Stephanie Brink", "Olga Pearce", "Thomas R. W. Scogland", "Bronis R. de Supinski", "Gian Luca Delzanno", "Michela Taufer"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20719v1", "summary": "Our fully kinetic, implicit Particle-in-Cell (PIC) simulations of global\nmagnetospheres on up to 32,768 of El Capitan's AMD Instinct MI300A Accelerated\nProcessing Units (APUs) represent an unprecedented computational capability\nthat addresses a fundamental challenge in space physics: resolving the\nmulti-scale coupling between microscopic (electron-scale) and macroscopic\n(global-scale) dynamics in planetary magnetospheres. The implicit scheme of\niPIC3D supports time steps and grid spacing that are up to 10 times larger than\nthose of explicit methods, without sacrificing physical accuracy. This enables\nthe simulation of magnetospheres while preserving fine-scale electron physics,\nwhich is critical for key processes such as magnetic reconnection and plasma\nturbulence. Our algorithmic and technological innovations include GPU-optimized\nkernels, particle control, and physics-aware data compression using Gaussian\nMixture Models. With simulation domains spanning 100-1,000 ion skin depths, we\nreach the global scale of small-to-medium planetary magnetospheres, such as\nthose of Mercury and Ganymede, which supports fully kinetic treatment of\nglobal-scale dynamics in systems previously out of reach for fully kinetic PIC\ncodes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20719v1", "cate": "cs.CE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20870", "title": "A Human-in-the-loop Approach to Robot Action Replanning through LLM Common-Sense Reasoning", "authors": ["Elena Merlo", "Marta Lagomarsino", "Arash Ajoudani"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20870v1", "summary": "To facilitate the wider adoption of robotics, accessible programming tools\nare required for non-experts. Observational learning enables intuitive human\nskills transfer through hands-on demonstrations, but relying solely on visual\ninput can be inefficient in terms of scalability and failure mitigation,\nespecially when based on a single demonstration. This paper presents a\nhuman-in-the-loop method for enhancing the robot execution plan, automatically\ngenerated based on a single RGB video, with natural language input to a Large\nLanguage Model (LLM). By including user-specified goals or critical task\naspects and exploiting the LLM common-sense reasoning, the system adjusts the\nvision-based plan to prevent potential failures and adapts it based on the\nreceived instructions. Experiments demonstrated the framework intuitiveness and\neffectiveness in correcting vision-derived errors and adapting plans without\nrequiring additional demonstrations. Moreover, interactive plan refinement and\nhallucination corrections promoted system robustness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20870v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20566", "title": "Unlearning of Knowledge Graph Embedding via Preference Optimization", "authors": ["Jiajun Liu", "Wenjun Ke", "Peng Wang", "Yao He", "Ziyu Shang", "Guozheng Li", "Zijie Xu", "Ke Ji"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20566v1", "summary": "Existing knowledge graphs (KGs) inevitably contain outdated or erroneous\nknowledge that needs to be removed from knowledge graph embedding (KGE) models.\nTo address this challenge, knowledge unlearning can be applied to eliminate\nspecific information while preserving the integrity of the remaining knowledge\nin KGs. Existing unlearning methods can generally be categorized into exact\nunlearning and approximate unlearning. However, exact unlearning requires high\ntraining costs while approximate unlearning faces two issues when applied to\nKGs due to the inherent connectivity of triples: (1) It fails to fully remove\ntargeted information, as forgetting triples can still be inferred from\nremaining ones. (2) It focuses on local data for specific removal, which\nweakens the remaining knowledge in the forgetting boundary. To address these\nissues, we propose GraphDPO, a novel approximate unlearning framework based on\ndirect preference optimization (DPO). Firstly, to effectively remove forgetting\ntriples, we reframe unlearning as a preference optimization problem, where the\nmodel is trained by DPO to prefer reconstructed alternatives over the original\nforgetting triples. This formulation penalizes reliance on forgettable\nknowledge, mitigating incomplete forgetting caused by KG connectivity.\nMoreover, we introduce an out-boundary sampling strategy to construct\npreference pairs with minimal semantic overlap, weakening the connection\nbetween forgetting and retained knowledge. Secondly, to preserve boundary\nknowledge, we introduce a boundary recall mechanism that replays and distills\nrelevant information both within and across time steps. We construct eight\nunlearning datasets across four popular KGs with varying unlearning rates.\nExperiments show that GraphDPO outperforms state-of-the-art baselines by up to\n10.1% in MRR_Avg and 14.0% in MRR_F1.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20566v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20805", "title": "Understanding Bias in Perceiving Dimensionality Reduction Projections", "authors": ["Seoyoung Doh", "Hyeon Jeon", "Sungbok Shin", "Ghulam Jilani Quadri", "Nam Wook Kim", "Jinwook Seo"], "categories": ["cs.HC", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.20805v1", "summary": "Selecting the dimensionality reduction technique that faithfully represents\nthe structure is essential for reliable visual communication and analytics. In\nreality, however, practitioners favor projections for other attractions, such\nas aesthetics and visual saliency, over the projection's structural\nfaithfulness, a bias we define as visual interestingness. In this research, we\nconduct a user study that (1) verifies the existence of such bias and (2)\nexplains why the bias exists. Our study suggests that visual interestingness\nbiases practitioners' preferences when selecting projections for analysis, and\nthis bias intensifies with color-encoded labels and shorter exposure time.\nBased on our findings, we discuss strategies to mitigate bias in perceiving and\ninterpreting DR projections.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.20805v1", "cate": "cs.HC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19697", "title": "NAICS-Aware Graph Neural Networks for Large-Scale POI Co-visitation Prediction: A Multi-Modal Dataset and Methodology", "authors": ["Yazeed Alrubyli", "Omar Alomeir", "Abrar Wafa", "Diána Hidvégi", "Hend Alrasheed", "Mohsen Bahrami"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19697v1", "summary": "Understanding where people go after visiting one business is crucial for\nurban planning, retail analytics, and location-based services. However,\npredicting these co-visitation patterns across millions of venues remains\nchallenging due to extreme data sparsity and the complex interplay between\nspatial proximity and business relationships. Traditional approaches using only\ngeographic distance fail to capture why coffee shops attract different customer\nflows than fine dining restaurants, even when co-located. We introduce\nNAICS-aware GraphSAGE, a novel graph neural network that integrates business\ntaxonomy knowledge through learnable embeddings to predict population-scale\nco-visitation patterns. Our key insight is that business semantics, captured\nthrough detailed industry codes, provide crucial signals that pure spatial\nmodels cannot explain. The approach scales to massive datasets (4.2 billion\npotential venue pairs) through efficient state-wise decomposition while\ncombining spatial, temporal, and socioeconomic features in an end-to-end\nframework. Evaluated on our POI-Graph dataset comprising 94.9 million\nco-visitation records across 92,486 brands and 48 US states, our method\nachieves significant improvements over state-of-the-art baselines: the\nR-squared value increases from 0.243 to 0.625 (a 157 percent improvement), with\nstrong gains in ranking quality (32 percent improvement in NDCG at 10).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19697v1", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20553", "title": "GeoJSEval: An Automated Evaluation Framework for Large Language Models on JavaScript-Based Geospatial Computation and Visualization Code Generation", "authors": ["Guanyu Chen", "Haoyue Jiao", "Shuyang Hou", "Ziqi Liu", "Lutong Xie", "Shaowen Wu", "Huayi Wu", "Xuefeng Guan", "Zhipeng Gui"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20553v1", "summary": "With the widespread adoption of large language models (LLMs) in code\ngeneration tasks, geospatial code generation has emerged as a critical frontier\nin the integration of artificial intelligence and geoscientific analysis. This\ntrend underscores the urgent need for systematic evaluation methodologies to\nassess LLMs generation capabilities in geospatial contexts. In particular,\ngeospatial computation and visualization tasks in JavaScript environments rely\nheavily on orchestrating diverse frontend libraries and ecosystems, placing\nelevated demands on a model's semantic understanding and code synthesis\nabilities. To address this challenge, we propose GeoJSEval--the first\nmultimodal, function-level automatic evaluation framework for LLMs in\nJavaScript-based geospatial code generation. GeoJSEval comprises three core\ncomponents: a standardized test suite (GeoJSEval-Bench), a code submission\nengine, and an evaluation module. It includes 432 function-level tasks and\n2,071 structured test cases spanning five widely used JavaScript geospatial\nlibraries and 25 mainstream geospatial data types. GeoJSEval enables\nmultidimensional quantitative evaluation across metrics such as accuracy,\noutput stability, execution efficiency, resource consumption, and error type\ndistribution, and integrates boundary testing mechanisms to enhance robustness\nand coverage. We conduct a comprehensive evaluation of 18 state-of-the-art LLMs\nusing GeoJSEval, revealing significant performance disparities and bottlenecks\nin spatial semantic understanding, code reliability, and function invocation\naccuracy. GeoJSEval provides a foundational methodology, evaluation resource,\nand practical toolkit for the standardized assessment and optimization of\ngeospatial code generation models, with strong extensibility and applicability\nin real-world scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20553v1", "cate": "cs.SE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.14512", "title": "Dora: A Controller Provisioning Strategy in Hierarchical Domain-based Satellite Networks", "authors": ["Qiyuan Peng", "Qi Zhang", "Yue Gao", "Kun Qiu"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14512v2", "summary": "The rapid proliferation of satellite constellations in Space-Air-Ground\nIntegrated Networks (SAGIN) presents significant challenges for network\nmanagement. Conventional flat network architectures struggle with\nsynchronization and data transmission across massive distributed nodes. In\nresponse, hierarchical domain-based satellite network architectures have\nemerged as a scalable solution, highlighting the critical importance of\ncontroller provisioning strategies. However, existing network management\narchitectures and traditional search-based algorithms fail to generate\nefficient controller provisioning solutions due to limited computational\nresources in satellites and strict time constraints. To address these\nchallenges, we propose a three-layer domain-based architecture that enhances\nboth scalability and adaptability. Furthermore, we introduce Dora, a\nreinforcement learning-based controller provisioning strategy designed to\noptimize network performance while minimizing computational overhead. Our\ncomprehensive experimental evaluation demonstrates that Dora significantly\noutperforms state-of-the-art benchmarks, achieving 10% improvement in\ncontroller provisioning quality while requiring only 1/30 to 1/90 of the\ncomputation time compared to traditional algorithms. These results underscore\nthe potential of reinforcement learning approaches for efficient satellite\nnetwork management in next-generation SAGIN deployments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14512v2", "cate": "cs.NI", "date": "2025-07-19", "updated": "2025-07-27"}
{"id": "2507.20559", "title": "Construction of non-generalized Reed-Solomon MDS codes based on systematic generator matrix", "authors": ["Shengwei Liu", "Hongwei Liu", "Bocong Chen"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20559v1", "summary": "Maximum distance separable (MDS) codes are considered optimal because the\nminimum distance cannot be improved for a given length and code size. The most\nprominent MDS codes are likely the generalized Reed-Solomon (GRS) codes. In\n1989, Roth and Lempel constructed a type of MDS code that is not a GRS code\n(referred to as non-GRS). In 2017, Beelen et al. introduced twisted\nReed-Solomon (TRS) codes and demonstrated that many MDS TRS codes are indeed\nnon-GRS. Following this, the definition of TRS codes was generalized to the\nmost comprehensive form, which we refer to as generalized twisted Reed-Solomon\n(GTRS) codes. In this paper, we prove that two families of GTRS codes are\nnon-GRS and provide a systematic generator matrix for a class of GTRS codes.\nInspired by the form of the systematic generator matrix for GTRS codes,we also\npresent a construction of non-GRS MDS codes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20559v1", "cate": "cs.IT", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20196", "title": "Ethereum Conflicts Graphed", "authors": ["Dvir David Biton", "Roy Friedman", "Yaron Hay"], "categories": ["cs.DC", "cs.DB"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      A slightly shorter version To appear in the Proceedings of the IEEE International Conference on Blockchain and Cryptocurrency, ICBC 2025", "url": "http://arxiv.org/abs/2507.20196v2", "summary": "Ethereum, a leading blockchain platform, has revolutionized the digital\neconomy by enabling decentralized transactions and the execution of smart\ncontracts. Ethereum transactions form the backbone of its network, facilitating\npeer-to-peer exchanges and interactions with complex decentralized\napplications. Smart contracts extend Ethereum's capabilities by automating\nprocesses and enabling trustless execution of agreements. Hence, understanding\nhow these smart contracts interact is important in order to facilitate various\nperformance optimizations, such as warming objects before they are being\naccessed and enabling concurrent execution. Of particular interest to us are\nthe development of the calling graph, as well as the read sets and write sets\nof invocations within the same block, and the properties of the associated\nconflict graph that is derived from them. The latter is important for\nunderstanding the parallelization potential of smart contracts on Ethereum. We\ntraced upwards of 2 million recent Ethereum blocks using call tracer and\nprestate tracer, out of a total of 21.4 million blocks at the time of writing.\nWe report on the transactions per block distribution, the structure of call\ntrees in smart contract invocations, the ratio of value-transfer transactions\nto smart contract invocations, as well as provide a comprehensive study of the\nstructure of blocks' conflict graphs. We find that conflict graphs\npredominantly show a star like configuration, as well as other noteworthy\nstructural properties.", "comment": "A slightly shorter version To appear in the Proceedings of the IEEE\n  International Conference on Blockchain and Cryptocurrency, ICBC 2025", "pdf_url": "http://arxiv.org/pdf/2507.20196v2", "cate": "cs.DC", "date": "2025-07-27", "updated": "2025-07-29"}
{"id": "2507.19548", "title": "Justifications for Democratizing AI Alignment and Their Prospects", "authors": ["André Steingrüber", "Kevin Baum"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      accepted for the LNCS on-site proceedings of the AISoLA 2025 conference", "url": "http://arxiv.org/abs/2507.19548v1", "summary": "The AI alignment problem comprises both technical and normative dimensions.\nWhile technical solutions focus on implementing normative constraints in AI\nsystems, the normative problem concerns determining what these constraints\nshould be. This paper examines justifications for democratic approaches to the\nnormative problem -- where affected stakeholders determine AI alignment -- as\nopposed to epistocratic approaches that defer to normative experts. We analyze\nboth instrumental justifications (democratic approaches produce better\noutcomes) and non-instrumental justifications (democratic approaches prevent\nillegitimate authority or coercion). We argue that normative and metanormative\nuncertainty create a justificatory gap that democratic approaches aim to fill\nthrough political rather than theoretical justification. However, we identify\nsignificant challenges for democratic approaches, particularly regarding the\nprevention of illegitimate coercion through AI alignment. Our analysis suggests\nthat neither purely epistocratic nor purely democratic approaches may be\nsufficient on their own, pointing toward hybrid frameworks that combine expert\njudgment with participatory input alongside institutional safeguards against AI\nmonopolization.", "comment": "accepted for the LNCS on-site proceedings of the AISoLA 2025\n  conference", "pdf_url": "http://arxiv.org/pdf/2507.19548v1", "cate": "cs.CY", "date": "2025-07-24", "updated": "2025-07-24"}
{"id": "2507.19568", "title": "Programmable Virtual Humans Toward Human Physiologically-Based Drug Discovery", "authors": ["You Wu", "Philip E. Bourne", "Lei Xie"], "categories": ["cs.CY", "cs.AI", "cs.CE", "cs.LG"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Under Review", "url": "http://arxiv.org/abs/2507.19568v1", "summary": "Artificial intelligence (AI) has sparked immense interest in drug discovery,\nbut most current approaches only digitize existing high-throughput experiments.\nThey remain constrained by conventional pipelines. As a result, they do not\naddress the fundamental challenges of predicting drug effects in humans.\nSimilarly, biomedical digital twins, largely grounded in real-world data and\nmechanistic models, are tailored for late-phase drug development and lack the\nresolution to model molecular interactions or their systemic consequences,\nlimiting their impact in early-stage discovery. This disconnect between early\ndiscovery and late development is one of the main drivers of high failure rates\nin drug discovery. The true promise of AI lies not in augmenting current\nexperiments but in enabling virtual experiments that are impossible in the real\nworld: testing novel compounds directly in silico in the human body. Recent\nadvances in AI, high-throughput perturbation assays, and single-cell and\nspatial omics across species now make it possible to construct programmable\nvirtual humans: dynamic, multiscale models that simulate drug actions from\nmolecular to phenotypic levels. By bridging the translational gap, programmable\nvirtual humans offer a transformative path to optimize therapeutic efficacy and\nsafety earlier than ever before. This perspective introduces the concept of\nprogrammable virtual humans, explores their roles in a new paradigm of drug\ndiscovery centered on human physiology, and outlines key opportunities,\nchallenges, and roadmaps for their realization.", "comment": "Under Review", "pdf_url": "http://arxiv.org/pdf/2507.19568v1", "cate": "cs.CY", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20892", "title": "PixelNav: Towards Model-based Vision-Only Navigation with Topological Graphs", "authors": ["Sergey Bakulin", "Timur Akhtyamov", "Denis Fatykhov", "German Devchich", "Gonzalo Ferrer"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20892v1", "summary": "This work proposes a novel hybrid approach for vision-only navigation of\nmobile robots, which combines advances of both deep learning approaches and\nclassical model-based planning algorithms. Today, purely data-driven end-to-end\nmodels are dominant solutions to this problem. Despite advantages such as\nflexibility and adaptability, the requirement of a large amount of training\ndata and limited interpretability are the main bottlenecks for their practical\napplications. To address these limitations, we propose a hierarchical system\nthat utilizes recent advances in model predictive control, traversability\nestimation, visual place recognition, and pose estimation, employing\ntopological graphs as a representation of the target environment. Using such a\ncombination, we provide a scalable system with a higher level of\ninterpretability compared to end-to-end approaches. Extensive real-world\nexperiments show the efficiency of the proposed method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20892v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20613", "title": "Enhancing Large Multimodal Models with Adaptive Sparsity and KV Cache Compression", "authors": ["Te Zhang", "Yuheng Li", "Junxiang Wang", "Lujun Li"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.20613v1", "summary": "Large multimodal models (LMMs) have advanced significantly by integrating\nvisual encoders with extensive language models, enabling robust reasoning\ncapabilities. However, compressing LMMs for deployment on edge devices remains\na critical challenge. In this work, we propose an adaptive search algorithm\nthat optimizes sparsity and KV cache compression to enhance LMM efficiency.\nUtilizing the Tree-structured Parzen Estimator, our method dynamically adjusts\npruning ratios and KV cache quantization bandwidth across different LMM layers,\nusing model performance as the optimization objective. This approach uniquely\ncombines pruning with key-value cache quantization and incorporates a fast\npruning technique that eliminates the need for additional fine-tuning or weight\nadjustments, achieving efficient compression without compromising accuracy.\nComprehensive evaluations on benchmark datasets, including LLaVA-1.5 7B and\n13B, demonstrate our method superiority over state-of-the-art techniques such\nas SparseGPT and Wanda across various compression levels. Notably, our\nframework automatic allocation of KV cache compression resources sets a new\nstandard in LMM optimization, delivering memory efficiency without sacrificing\nmuch performance.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.20613v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20933", "title": "ProForm: Solder-Free Circuit Assembly Using Thermoforming", "authors": ["Narjes Pourjafarian", "Zhenming Yang", "Jeffrey I. Lipton", "Benyamin Davaji", "Gregory D. Abowd"], "categories": ["cs.HC", "cond-mat.mtrl-sci"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20933v1", "summary": "Electronic waste (e-waste) is a growing global challenge, with millions of\nfunctional components discarded due to the difficulty of repair and reuse.\nTraditional circuit assembly relies on soldering, which creates semi-permanent\nbonds that limit component recovery and contribute to unnecessary waste. We\nintroduce ProForm, a thermoforming approach for solder-free circuit\nprototyping. By encapsulating electronic components with pressure-formed\nthermoplastics, ProForm enables secure, reversible mounting without the need\nfor solder or custom mechanical housings. This approach supports a wide range\nof substrates, including flexible, paper-based, and non-planar circuits,\nfacilitating easy reuse, replacement, and rapid prototyping. We demonstrate\nProForm's versatility to support prototyping practices. We show that ProFormed\ncircuits exhibit good electrical performance and mechanical stability. While\nmotivated by a need for sustainable electronics practices, ProForm has other\nsignificant advantages over traditional soldering.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20933v1", "cate": "cs.HC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19700", "title": "Disjoint Generative Models", "authors": ["Anton Danholt Lautrup", "Muhammad Rajabinasab", "Tobias Hyrup", "Arthur Zimek", "Peter Schneider-Kamp"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19700v1", "summary": "We propose a new framework for generating cross-sectional synthetic datasets\nvia disjoint generative models. In this paradigm, a dataset is partitioned into\ndisjoint subsets that are supplied to separate instances of generative models.\nThe results are then combined post hoc by a joining operation that works in the\nabsence of common variables/identifiers. The success of the framework is\ndemonstrated through several case studies and examples on tabular data that\nhelps illuminate some of the design choices that one may make. The principal\nbenefit of disjoint generative models is significantly increased privacy at\nonly a low utility cost. Additional findings include increased effectiveness\nand feasibility for certain model types and the possibility for mixed-model\nsynthesis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19700v1", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20619", "title": "Intention-Driven Generation of Project-Specific Test Cases", "authors": ["Binhang Qi", "Yun Lin", "Xinyi Weng", "Yuhuan Huang", "Chenyan Liu", "Hailong Sun", "Jin Song Dong"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20619v1", "summary": "Test cases are valuable assets for maintaining software quality. While\nnumerous automated techniques have been proposed for generating tests (either\nby maximizing code coverage or by translating focal code into test code),\npractical tests are seldom driven by coverage alone. In real projects, each\ntest reflects a developer's validation intention for a specific behaviour and\nembodies rich, project-specific knowledge: which specific APIs to call and what\nassertions truly matter. Without considering such knowledge, tests can hardly\npass code review and be integrated into the software product.\n  In this work, we propose IntentionTest, which generates project-specific\ntests with validation intention as a structured description. Our design is\nmotivated by two insights: (1) a description of validation intention, compared\nto coverage and focal code, carries more crucial information about what to\ntest; and (2) practical tests exhibit high code duplication, indicating that\ndomain knowledge is highly reusable for writing new tests. Given a focal code\nand a description of validation intention (in the form of either an informal\ncomment or a formal test plan), IntentionTest retrieves a referable test in the\nproject to guide test generation. Moreover, IntentionTest reduces the test\ngeneration problem into an editing problem on the test code regarding the\nvalidation intention. It generates a test including both test prefix and\noracle, which aims to be executable and semantically correct.\n  We evaluate IntentionTest against state-of-the-art baselines on 4,146 test\ncases from 13 open-source projects. Specifically, compared to ChatTester,\nIntentionTest can (1) generate significantly more semantically correct tests,\nimproving common mutation scores by 39.03% and coverage overlap with\nground-truth tests by 40.14%; (2) generate 21.30% more successful passing\ntests.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20619v1", "cate": "cs.SE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20577", "title": "A note on the Artstein-Avidan-Milman's generalized Legendre transforms", "authors": ["Frank Nielsen"], "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      11 pages", "url": "http://arxiv.org/abs/2507.20577v1", "summary": "Artstein-Avidan and Milman [Annals of mathematics (2009), (169):661-674]\ncharacterized invertible reverse-ordering transforms on the space of\nlower-semi-continuous extended real-valued convex functions as affine\ndeformations of the ordinary Legendre transform. In this note, we prove that\nall those generalized Legendre transforms on functions correspond to the\nordinary Legendre transform on dually corresponding affine-deformed functions.\nThat is, generalized convex conjugates are convex conjugates of affine-deformed\nfunctions. We conclude this note by sketching how this result can be\ninterpreted from the lens of information geometry.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2507.20577v1", "cate": "cs.IT", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20201", "title": "Silent Self-Stabilising Leader Election in Programmable Matter Systems with Holes", "authors": ["Jérémie Chalopin", "Shantanu Das", "Maria Kokkou"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      15 pages", "url": "http://arxiv.org/abs/2507.20201v1", "summary": "Leader election is a fundamental problem in distributed computing,\nparticularly within programmable matter systems, where coordination among\nsimple computational entities is crucial for solving complex tasks. In these\nsystems, particles (i.e., constant memory computational entities) operate in a\nregular triangular grid as described in the geometric Amoebot model. While\nleader election has been extensively studied in non self-stabilising settings,\nself-stabilising solutions remain more limited. In this work, we study the\nproblem of self-stabilising leader election in connected (but not necessarily\nsimply connected) configurations. We present the first self-stabilising\nalgorithm for programmable matter that guarantees the election of a unique\nleader under an unfair scheduler, assuming particles share a common sense of\ndirection. Our approach leverages particle movement, a capability not\npreviously exploited in the self-stabilising context. We show that movement in\nconjunction with particles operating in a grid can overcome classical\nimpossibility results for constant-memory systems established by Dolev et al.", "comment": "15 pages", "pdf_url": "http://arxiv.org/pdf/2507.20201v1", "cate": "cs.DC", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19551", "title": "Rainbow Noise: Stress-Testing Multimodal Harmful-Meme Detectors on LGBTQ Content", "authors": ["Ran Tong", "Songtao Wei", "Jiaqi Liu", "Lanruo Wang"], "categories": ["cs.CY", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      9 pages, 1 figure", "url": "http://arxiv.org/abs/2507.19551v1", "summary": "Hateful memes aimed at LGBTQ\\,+ communities often evade detection by tweaking\neither the caption, the image, or both. We build the first robustness benchmark\nfor this setting, pairing four realistic caption attacks with three canonical\nimage corruptions and testing all combinations on the PrideMM dataset. Two\nstate-of-the-art detectors, MemeCLIP and MemeBLIP2, serve as case studies, and\nwe introduce a lightweight \\textbf{Text Denoising Adapter (TDA)} to enhance the\nlatter's resilience. Across the grid, MemeCLIP degrades more gently, while\nMemeBLIP2 is particularly sensitive to the caption edits that disrupt its\nlanguage processing. However, the addition of the TDA not only remedies this\nweakness but makes MemeBLIP2 the most robust model overall. Ablations reveal\nthat all systems lean heavily on text, but architectural choices and\npre-training data significantly impact robustness. Our benchmark exposes where\ncurrent multimodal safety models crack and demonstrates that targeted,\nlightweight modules like the TDA offer a powerful path towards stronger\ndefences.", "comment": "9 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.19551v1", "cate": "cs.CY", "date": "2025-07-24", "updated": "2025-07-24"}
{"id": "2507.19858", "title": "Taming Domain Shift in Multi-source CT-Scan Classification via Input-Space Standardization", "authors": ["Chia-Ming Lee", "Bo-Cheng Qiu", "Ting-Yao Chen", "Ming-Han Sun", "Fang-Ying Lin", "Jung-Tse Tsai", "I-An Tsai", "Yu-Fan Lin", "Chih-Chung Hsu"], "categories": ["eess.IV", "cs.CE", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCVW 2025, Winner solution of PHAROS-AFE-AIMI Workshop's Multi-Source Covid-19 Detection Challenge", "url": "http://arxiv.org/abs/2507.19858v1", "summary": "Multi-source CT-scan classification suffers from domain shifts that impair\ncross-source generalization. While preprocessing pipelines combining\nSpatial-Slice Feature Learning (SSFL++) and Kernel-Density-based Slice Sampling\n(KDS) have shown empirical success, the mechanisms underlying their domain\nrobustness remain underexplored. This study analyzes how this input-space\nstandardization manages the trade-off between local discriminability and\ncross-source generalization. The SSFL++ and KDS pipeline performs spatial and\ntemporal standardization to reduce inter-source variance, effectively mapping\ndisparate inputs into a consistent target space. This preemptive alignment\nmitigates domain shift and simplifies the learning task for network\noptimization. Experimental validation demonstrates consistent improvements\nacross architectures, proving the benefits stem from the preprocessing itself.\nThe approach's effectiveness was validated by securing first place in a\ncompetitive challenge, supporting input-space standardization as a robust and\npractical solution for multi-institutional medical imaging.", "comment": "Accepted by ICCVW 2025, Winner solution of PHAROS-AFE-AIMI Workshop's\n  Multi-Source Covid-19 Detection Challenge", "pdf_url": "http://arxiv.org/pdf/2507.19858v1", "cate": "eess.IV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19691", "title": "Co-Win: Joint Object Detection and Instance Segmentation in LiDAR Point Clouds via Collaborative Window Processing", "authors": ["Haichuan Li", "Tomi Westerlund"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19691v1", "summary": "Accurate perception and scene understanding in complex urban environments is\na critical challenge for ensuring safe and efficient autonomous navigation. In\nthis paper, we present Co-Win, a novel bird's eye view (BEV) perception\nframework that integrates point cloud encoding with efficient parallel\nwindow-based feature extraction to address the multi-modality inherent in\nenvironmental understanding. Our method employs a hierarchical architecture\ncomprising a specialized encoder, a window-based backbone, and a query-based\ndecoder head to effectively capture diverse spatial features and object\nrelationships. Unlike prior approaches that treat perception as a simple\nregression task, our framework incorporates a variational approach with\nmask-based instance segmentation, enabling fine-grained scene decomposition and\nunderstanding. The Co-Win architecture processes point cloud data through\nprogressive feature extraction stages, ensuring that predicted masks are both\ndata-consistent and contextually relevant. Furthermore, our method produces\ninterpretable and diverse instance predictions, enabling enhanced downstream\ndecision-making and planning in autonomous driving systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19691v1", "cate": "cs.CV", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20620", "title": "Complementarity-driven Representation Learning for Multi-modal Knowledge Graph Completion", "authors": ["Lijian Li"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20620v1", "summary": "Multi-modal Knowledge Graph Completion (MMKGC) aims to uncover hidden world\nknowledge in multimodal knowledge graphs by leveraging both multimodal and\nstructural entity information. However, the inherent imbalance in multimodal\nknowledge graphs, where modality distributions vary across entities, poses\nchallenges in utilizing additional modality data for robust entity\nrepresentation. Existing MMKGC methods typically rely on attention or\ngate-based fusion mechanisms but overlook complementarity contained in\nmulti-modal data. In this paper, we propose a novel framework named Mixture of\nComplementary Modality Experts (MoCME), which consists of a\nComplementarity-guided Modality Knowledge Fusion (CMKF) module and an\nEntropy-guided Negative Sampling (EGNS) mechanism. The CMKF module exploits\nboth intra-modal and inter-modal complementarity to fuse multi-view and\nmulti-modal embeddings, enhancing representations of entities. Additionally, we\nintroduce an Entropy-guided Negative Sampling mechanism to dynamically\nprioritize informative and uncertain negative samples to enhance training\neffectiveness and model robustness. Extensive experiments on five benchmark\ndatasets demonstrate that our MoCME achieves state-of-the-art performance,\nsurpassing existing approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20620v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20943", "title": "The Impact of Simple, Brief, and Adaptive Instructions within Virtual Reality Training: Components of Cognitive Load Theory in an Assembly Task", "authors": ["Rebecca L. Pharmer", "Christopher D. Wickens", "Lucas Plabst", "Benjamin A. Clegg", "Leanne M. Hirshfield", "Joanna E. Lewis", "Jalynn B. Nicoly", "Cara A. Spencer", "Francisco R. Ortega"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20943v1", "summary": "Objective: The study examined the effects of varying all three core elements\nof cognitive load on learning efficiency during a shape assembly task in\nvirtual reality (VR).\n  Background: Adaptive training systems aim to improve learning efficiency and\nretention by dynamically adjusting difficulty. However, design choices can\nimpact the cognitive workload imposed on the learner. The present experiments\nexamined how aspects of cognitive load impact training outcomes.\n  Method: Participants learned step-by-step shape assembly in a VR environment.\nCognitive load was manipulated across three dimensions: Intrinsic Load (shape\ncomplexity), Extraneous Load (instruction verbosity), and Germane Load\n(adaptive vs. fixed training). In adaptive training (experiment 1), difficulty\nincreased based on individual performance. In fixed training (experiment 2),\ndifficulty followed a preset schedule from a yoked participant.\n  Results: Higher Intrinsic Load significantly increased training times and\nsubjective workload but did not affect retention test accuracy. Extraneous Load\nmodestly impacted training time, with little impact on workload or retention.\nAdaptive training shortened overall training time without increasing workload\nor impairing retention. No interactions were observed between the three types\nof load. Conclusion: Both Intrinsic and Extraneous Load increased training\ntime, but adaptive training improved efficiency without harming retention. The\nlack of interaction between the elements suggests training benefits can be\nworth seeking within any of the components of cognitive load. Application:\nThese findings support the use of VR adaptive systems in domains such as\nmanufacturing and military service, where efficient assembly skill acquisition\nis critical. Tailoring difficulty in real-time can optimize efficiency without\ncompromising learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20943v1", "cate": "cs.HC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19715", "title": "Beyond Nearest Neighbors: Semantic Compression and Graph-Augmented Retrieval for Enhanced Vector Search", "authors": ["Rahul Raja", "Arpita Vats"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19715v1", "summary": "Vector databases typically rely on approximate nearest neighbor (ANN) search\nto retrieve the top-k closest vectors to a query in embedding space. While\neffective, this approach often yields semantically redundant results, missing\nthe diversity and contextual richness required by applications such as\nretrieval-augmented generation (RAG), multi-hop QA, and memory-augmented\nagents. We introduce a new retrieval paradigm: semantic compression, which aims\nto select a compact, representative set of vectors that captures the broader\nsemantic structure around a query. We formalize this objective using principles\nfrom submodular optimization and information geometry, and show that it\ngeneralizes traditional top-k retrieval by prioritizing coverage and diversity.\nTo operationalize this idea, we propose graph-augmented vector retrieval, which\noverlays semantic graphs (e.g., kNN or knowledge-based links) atop vector\nspaces to enable multi-hop, context-aware search. We theoretically analyze the\nlimitations of proximity-based retrieval under high-dimensional concentration\nand highlight how graph structures can improve semantic coverage. Our work\noutlines a foundation for meaning-centric vector search systems, emphasizing\nhybrid indexing, diversity-aware querying, and structured semantic retrieval.\nWe make our implementation publicly available to foster future research in this\narea.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19715v1", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20674", "title": "LLM-Based Repair of Static Nullability Errors", "authors": ["Nima Karimipour", "Michael Pradel", "Martin Kellogg", "Manu Sridharan"], "categories": ["cs.SE", "cs.PL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20674v1", "summary": "Modern Java projects increasingly adopt static analysis tools that prevent\nnull-pointer exceptions by treating nullness as a type property. However,\nintegrating such tools into large, existing codebases remains a significant\nchallenge. While annotation inference can eliminate many errors automatically,\na subset of residual errors -- typically a mix of real bugs and false positives\n-- often persist and can only be resolved via code changes. Manually addressing\nthese errors is tedious and error-prone. Large language models (LLMs) offer a\npromising path toward automating these repairs, but naively-prompted LLMs often\ngenerate incorrect, contextually-inappropriate edits. Resolving a nullability\nerror demands a deep understanding of how a symbol is used across the codebase,\noften spanning methods, classes, and packages. We present NullRepair, a system\nthat integrates LLMs into a structured workflow for resolving the errors from a\nnullability checker. NullRepair's decision process follows a flowchart derived\nfrom manual analysis of 200 real-world errors. It leverages static analysis to\nidentify safe and unsafe usage regions of symbols, using error-free usage\nexamples to contextualize model prompts. Patches are generated through an\niterative interaction with the LLM that incorporates project-wide context and\ndecision logic. Our evaluation on 12 real-world Java projects shows that\nNullRepair resolves an average of 72% of the errors that remain after applying\na state-of-the-art annotation inference technique. Unlike a naively-prompted\nLLM, NullRepair also largely preserves program semantics, with all unit tests\npassing in 10/12 projects after applying every edit proposed by NullRepair, and\n98% or more tests passing in the remaining two projects.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20674v1", "cate": "cs.SE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20639", "title": "The Coverage Depth Problem in DNA Storage Over Small Alphabets", "authors": ["Matteo Bertuzzo", "Alberto Ravagnani", "Eitan Yaakobi"], "categories": ["cs.IT", "math.CO", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20639v1", "summary": "The coverage depth problem in DNA data storage is about minimizing the\nexpected number of reads until all data is recovered. When they exist, MDS\ncodes offer the best performance in this context. This paper focuses on the\nscenario where the base field is not large enough to allow the existence of MDS\ncodes. We investigate the performance for the coverage depth problem of codes\ndefined over a small finite field, providing closed formulas for the expected\nnumber of reads for various code families. We also compare the results with the\ntheoretical bounds in asymptotic regimes. The techniques we apply range from\nprobability, to duality theory and combinatorics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20639v1", "cate": "cs.IT", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20312", "title": "A Comparative Study of OpenMP Scheduling Algorithm Selection Strategies", "authors": ["Jonas H. Müller Korndörfer", "Ali Mohammed", "Ahmed Eleliemy", "Quentin Guilloteau", "Reto Krummenacher", "Florina M. Ciorba"], "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      To appear at IEEE ACCESS", "url": "http://arxiv.org/abs/2507.20312v1", "summary": "Scientific and data science applications are becoming increasingly complex,\nwith growing computational and memory demands. Modern high performance\ncomputing (HPC) systems provide high parallelism and heterogeneity across\nnodes, devices, and cores. To achieve good performance, effective scheduling\nand load balancing techniques are essential. Parallel programming frameworks\nsuch as OpenMP now offer a variety of advanced scheduling algorithms to support\ndiverse applications and platforms. This creates an instance of the scheduling\nalgorithm selection problem, which involves identifying the most suitable\nalgorithm for a given combination of workload and system characteristics.\n  In this work, we explore learning-based approaches for selecting scheduling\nalgorithms in OpenMP. We propose and evaluate expert-based and reinforcement\nlearning (RL)-based methods, and conduct a detailed performance analysis across\nsix applications and three systems. Our results show that RL methods are\ncapable of learning high-performing scheduling decisions, although they require\nsignificant exploration, with the choice of reward function playing a key role.\nExpert-based methods, in contrast, rely on prior knowledge and involve less\nexploration, though they may not always identify the optimal algorithm for a\nspecific application-system pair. By combining expert knowledge with RL-based\nlearning, we achieve improved performance and greater adaptability.\n  Overall, this work demonstrates that dynamic selection of scheduling\nalgorithms during execution is both viable and beneficial for OpenMP\napplications. The approach can also be extended to MPI-based programs, enabling\noptimization of scheduling decisions across multiple levels of parallelism.", "comment": "To appear at IEEE ACCESS", "pdf_url": "http://arxiv.org/pdf/2507.20312v1", "cate": "cs.DC", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19556", "title": "PEMUTA: Pedagogically-Enriched Multi-Granular Undergraduate Thesis Assessment", "authors": ["Jialu Zhang", "Qingyang Sun", "Qianyi Wang", "Weiyi Zhang", "Zunjie Xiao", "Xiaoqing Zhang", "Jianfeng Ren", "Jiang Liu"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19556v1", "summary": "The undergraduate thesis (UGTE) plays an indispensable role in assessing a\nstudent's cumulative academic development throughout their college years.\nAlthough large language models (LLMs) have advanced education intelligence,\nthey typically focus on holistic assessment with only one single evaluation\nscore, but ignore the intricate nuances across multifaceted criteria, limiting\ntheir ability to reflect structural criteria, pedagogical objectives, and\ndiverse academic competencies. Meanwhile, pedagogical theories have long\ninformed manual UGTE evaluation through multi-dimensional assessment of\ncognitive development, disciplinary thinking, and academic performance, yet\nremain underutilized in automated settings. Motivated by the research gap, we\npioneer PEMUTA, a pedagogically-enriched framework that effectively activates\ndomain-specific knowledge from LLMs for multi-granular UGTE assessment. Guided\nby Vygotsky's theory and Bloom's Taxonomy, PEMUTA incorporates a hierarchical\nprompting scheme that evaluates UGTEs across six fine-grained dimensions:\nStructure, Logic, Originality, Writing, Proficiency, and Rigor (SLOWPR),\nfollowed by holistic synthesis. Two in-context learning techniques, \\ie,\nfew-shot prompting and role-play prompting, are also incorporated to further\nenhance alignment with expert judgments without fine-tuning. We curate a\ndataset of authentic UGTEs with expert-provided SLOWPR-aligned annotations to\nsupport multi-granular UGTE assessment. Extensive experiments demonstrate that\nPEMUTA achieves strong alignment with expert evaluations, and exhibits strong\npotential for fine-grained, pedagogically-informed UGTE evaluations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19556v1", "cate": "cs.CY", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20520", "title": "AQUA: A Large Language Model for Aquaculture & Fisheries", "authors": ["Praneeth Narisetty", "Uday Kumar Reddy Kattamanchi", "Lohit Akshant Nimma", "Sri Ram Kaushik Karnati", "Shiva Nagendra Babu Kore", "Mounika Golamari", "Tejashree Nageshreddy"], "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20520v1", "summary": "Aquaculture plays a vital role in global food security and coastal economies\nby providing sustainable protein sources. As the industry expands to meet\nrising demand, it faces growing challenges such as disease outbreaks,\ninefficient feeding practices, rising labor costs, logistical inefficiencies,\nand critical hatchery issues, including high mortality rates and poor water\nquality control. Although artificial intelligence has made significant\nprogress, existing machine learning methods fall short of addressing the\ndomain-specific complexities of aquaculture. To bridge this gap, we introduce\nAQUA, the first large language model (LLM) tailored for aquaculture, designed\nto support farmers, researchers, and industry practitioners. Central to this\neffort is AQUADAPT (Data Acquisition, Processing and Tuning), an Agentic\nFramework for generating and refining high-quality synthetic data using a\ncombination of expert knowledge, largescale language models, and automated\nevaluation techniques. Our work lays the foundation for LLM-driven innovations\nin aquaculture research, advisory systems, and decision-making tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20520v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19878", "title": "Efficient Self-Supervised Neuro-Analytic Visual Servoing for Real-time Quadrotor Control", "authors": ["Sebastian Mocanu", "Sebastian-Ion Nae", "Mihai-Eugen Barbu", "Marius Leordeanu"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at the International Conference on Computer Vision Workshops 2025", "url": "http://arxiv.org/abs/2507.19878v1", "summary": "This work introduces a self-supervised neuro-analytical, cost efficient,\nmodel for visual-based quadrotor control in which a small 1.7M parameters\nstudent ConvNet learns automatically from an analytical teacher, an improved\nimage-based visual servoing (IBVS) controller. Our IBVS system solves numerical\ninstabilities by reducing the classical visual servoing equations and enabling\nefficient stable image feature detection. Through knowledge distillation, the\nstudent model achieves 11x faster inference compared to the teacher IBVS\npipeline, while demonstrating similar control accuracy at a significantly lower\ncomputational and memory cost. Our vision-only self-supervised neuro-analytic\ncontrol, enables quadrotor orientation and movement without requiring explicit\ngeometric models or fiducial markers. The proposed methodology leverages\nsimulation-to-reality transfer learning and is validated on a small drone\nplatform in GPS-denied indoor environments. Our key contributions include: (1)\nan analytical IBVS teacher that solves numerical instabilities inherent in\nclassical approaches, (2) a two-stage segmentation pipeline combining YOLOv11\nwith a U-Net-based mask splitter for robust anterior-posterior vehicle\nsegmentation to correctly estimate the orientation of the target, and (3) an\nefficient knowledge distillation dual-path system, which transfers geometric\nvisual servoing capabilities from the analytical IBVS teacher to a compact and\nsmall student neural network that outperforms the teacher, while being suitable\nfor real-time onboard deployment.", "comment": "Accepted at the International Conference on Computer Vision Workshops\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.19878v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20641", "title": "Adaptive Fuzzy Time Series Forecasting via Partially Asymmetric Convolution and Sub-Sliding Window Fusion", "authors": ["Lijian Li"], "categories": ["cs.AI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20641v1", "summary": "At present, state-of-the-art forecasting models are short of the ability to\ncapture spatio-temporal dependency and synthesize global information at the\nstage of learning. To address this issue, in this paper, through the adaptive\nfuzzified construction of temporal data, we propose a novel convolutional\narchitecture with partially asymmetric design based on the scheme of sliding\nwindow to realize accurate time series forecasting. First, the construction\nstrategy of traditional fuzzy time series is improved to further extract short\nand long term temporal interrelation, which enables every time node to\nautomatically possess corresponding global information and inner relationships\namong them in a restricted sliding window and the process does not require\nhuman involvement. Second, a bilateral Atrous algorithm is devised to reduce\ncalculation demand of the proposed model without sacrificing global\ncharacteristics of elements. And it also allows the model to avoid processing\nredundant information. Third, after the transformation of time series, a\npartially asymmetric convolutional architecture is designed to more flexibly\nmine data features by filters in different directions on feature maps, which\ngives the convolutional neural network (CNN) the ability to construct\nsub-windows within existing sliding windows to model at a more fine-grained\nlevel. And after obtaining the time series information at different levels, the\nmulti-scale features from different sub-windows will be sent to the\ncorresponding network layer for time series information fusion. Compared with\nother competitive modern models, the proposed method achieves state-of-the-art\nresults on most of popular time series datasets, which is fully verified by the\nexperimental results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20641v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21000", "title": "Towards Effective Human Performance in XR Space Framework based on Real-time Eye Tracking Biofeedback", "authors": ["Barbara Karpowicz", "Tomasz Kowalewski", "Pavlo Zinevych", "Adam Kuzdraliński", "Grzegorz Marcin Wójcik", "Wiesław Kopeć"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21000v1", "summary": "This paper proposes an eye tracking module for the XR Space Framework aimed\nat enhancing human performance in XR-based applications, specifically in\ntraining, screening, and teleoperation. This framework provides a methodology\nand components that streamline the development of adaptive real-time virtual\nimmersive systems. It contains multimodal measurements - declarative in the\nform of in-VR questionnaires and objective, including eye tracking, body\nmovement, and psychophysiological data (e.g., ECG, GSR, PPG). A key focus of\nthis paper is the integration of real-time eye tracking data into XR\nenvironments to facilitate a biofeedback loop, providing insight into user\nattention, cognitive load, and engagement. Given the relatively high\nmeasurement frequency of eye tracking - recognized as a noninvasive yet robust\npsychophysiological measure - this technology is particularly well suited for\nreal-time adjustments in task difficulty and feedback to enhance learning and\noperational effectiveness. Despite its established role in cognitive and\nattentional studies, implementing eye tracking metrics within dynamic,\nreal-time XR environments poses unique challenges, particularly given the\ncomplex moving visuals presented in head-mounted displays (HMDs). This paper\naddresses these challenges by focusing on the essential aspects of integrating\neye tracking in immersive systems based on real-time engines, ultimately\nfacilitating more efficient, adaptive XR applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21000v1", "cate": "cs.HC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19737", "title": "Predicting Human Mobility in Disasters via LLM-Enhanced Cross-City Learning", "authors": ["Yinzhou Tang", "Huandong Wang", "Xiaochen Fan", "Yong Li"], "categories": ["cs.LG", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19737v1", "summary": "The vulnerability of cities to natural disasters has increased with\nurbanization and climate change, making it more important to predict human\nmobility in the disaster scenarios for downstream tasks including\nlocation-based early disaster warning and pre-allocating rescue resources, etc.\nHowever, existing human mobility prediction models are mainly designed for\nnormal scenarios, and fail to adapt to disaster scenarios due to the shift of\nhuman mobility patterns under disaster. To address this issue, we introduce\n\\textbf{DisasterMobLLM}, a mobility prediction framework for disaster scenarios\nthat can be integrated into existing deep mobility prediction methods by\nleveraging LLMs to model the mobility intention and transferring the common\nknowledge of how different disasters affect mobility intentions between cities.\nThis framework utilizes a RAG-Enhanced Intention Predictor to forecast the next\nintention, refines it with an LLM-based Intention Refiner, and then maps the\nintention to an exact location using an Intention-Modulated Location Predictor.\nExtensive experiments illustrate that DisasterMobLLM can achieve a 32.8\\%\nimprovement in terms of Acc@1 and a 35.0\\% improvement in terms of the F1-score\nof predicting immobility compared to the baselines. The code is available at\nhttps://github.com/tsinghua-fib-lab/DisasterMobLLM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19737v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20814", "title": "Client--Library Compatibility Testing with API Interaction Snapshots", "authors": ["Gustave Monce", "Thomas Degueule", "Jean-Rémy Falleri", "Romain Robbes"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20814v1", "summary": "Modern software development heavily relies on third-party libraries to speed\nup development and enhance quality. As libraries evolve, they may break the\ntacit contract established with their clients by introducing behavioral\nbreaking changes (BBCs) that alter run-time behavior and silently break client\napplications without being detected at compile time. Traditional regression\ntests on the client side often fail to detect such BBCs, either due to limited\nlibrary coverage or weak assertions that do not sufficiently exercise the\nlibrary's expected behavior. To address this issue, we propose a novel approach\nto client--library compatibility testing that leverages existing client tests\nin a novel way. Instead of relying on developer-written assertions, we propose\nrecording the actual interactions at the API boundary during the execution of\nclient tests (protocol, input and output values, exceptions, etc.). These\nsequences of API interactions are stored as snapshots which capture the exact\ncontract expected by a client at a specific point in time. As the library\nevolves, we compare the original and new snapshots to identify perturbations in\nthe contract, flag potential BBCs, and notify clients. We implement this\ntechnique in our prototype tool Gilesi, a Java framework that automatically\ninstruments library APIs, records snapshots, and compares them. Through a\npreliminary case study on several client--library pairs with artificially\nseeded BBCs, we show that Gilesi reliably detects BBCs missed by client test\nsuites.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20814v1", "cate": "cs.SE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20645", "title": "The Random Variables of the DNA Coverage Depth Problem", "authors": ["Şeyma Bodur", "Stefano Lia", "Hiram H. López", "Rati Ludhani", "Alberto Ravagnani", "Lisa Seccia"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20645v1", "summary": "DNA data storage systems encode digital data into DNA strands, enabling dense\nand durable storage. Efficient data retrieval depends on coverage depth, a key\nperformance metric. We study the random access coverage depth problem and focus\non minimizing the expected number of reads needed to recover information\nstrands encoded via a linear code. We compute the asymptotic performance of a\nrecently proposed code construction, establishing and refining a conjecture in\nthe field by giving two independent proofs. We also analyze a geometric code\nconstruction based on balanced quasi-arcs and optimize its parameters. Finally,\nwe investigate the full distribution of the random variables that arise in the\ncoverage depth problem, of which the traditionally studied expectation is just\nthe first moment. This allows us to distinguish between code constructions\nthat, at first glance, may appear to behave identically.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20645v1", "cate": "cs.IT", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20514", "title": "RIMMS: Runtime Integrated Memory Management System for Heterogeneous Computing", "authors": ["Serhan Gener", "Aditya Ukarande", "Shilpa Mysore Srinivasa Murthy", "Sahil Hassan", "Joshua Mack", "Chaitali Chakrabarti", "Umit Ogras", "Ali Akoglu"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20514v1", "summary": "Efficient memory management in heterogeneous systems is increasingly\nchallenging due to diverse compute architectures (e.g., CPU, GPU, FPGA) and\ndynamic task mappings not known at compile time. Existing approaches often\nrequire programmers to manage data placement and transfers explicitly, or\nassume static mappings that limit portability and scalability. This paper\nintroduces RIMMS (Runtime Integrated Memory Management System), a lightweight,\nruntime-managed, hardware-agnostic memory abstraction layer that decouples\napplication development from low-level memory operations. RIMMS transparently\ntracks data locations, manages consistency, and supports efficient memory\nallocation across heterogeneous compute elements without requiring\nplatform-specific tuning or code modifications. We integrate RIMMS into a\nbaseline runtime and evaluate with complete radar signal processing\napplications across CPU+GPU and CPU+FPGA platforms. RIMMS delivers up to 2.43X\nspeedup on GPU-based and 1.82X on FPGA-based systems over the baseline.\nCompared to IRIS, a recent heterogeneous runtime system, RIMMS achieves up to\n3.08X speedup and matches the performance of native CUDA implementations while\nsignificantly reducing programming complexity. Despite operating at a higher\nabstraction level, RIMMS incurs only 1-2 cycles of overhead per memory\nmanagement call, making it a low-cost solution. These results demonstrate\nRIMMS's ability to deliver high performance and enhanced programmer\nproductivity in dynamic, real-world heterogeneous environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20514v1", "cate": "cs.DC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19559", "title": "Towards Sustainability Model Cards", "authors": ["Gwendal Jouneaux", "Jordi Cabot"], "categories": ["cs.CY", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19559v1", "summary": "The growth of machine learning (ML) models and associated datasets triggers a\nconsequent dramatic increase in energy costs for the use and training of these\nmodels. In the current context of environmental awareness and global\nsustainability concerns involving ICT, Green AI is becoming an important\nresearch topic. Initiatives like the AI Energy Score Ratings are a good\nexample. Nevertheless, these benchmarking attempts are still to be integrated\nwith existing work on Quality Models and Service-Level Agreements common in\nother, more mature, ICT subfields. This limits the (automatic) analysis of this\nmodel energy descriptions and their use in (semi)automatic model comparison,\nselection, and certification processes. We aim to leverage the concept of\nquality models and merge it with existing ML model reporting initiatives and\nGreen/Frugal AI proposals to formalize a Sustainable Quality Model for AI/ML\nmodels. As a first step, we propose a new Domain-Specific Language to precisely\ndefine the sustainability aspects of an ML model (including the energy costs\nfor its different tasks). This information can then be exported as an extended\nversion of the well-known Model Cards initiative while, at the same time, being\nformal enough to be input of any other model description automatic process.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19559v1", "cate": "cs.CY", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20954", "title": "PySHRED: A Python package for SHallow REcurrent Decoding for sparse sensing, model reduction and scientific discovery", "authors": ["David Ye", "Jan Williams", "Mars Gao", "Stefano Riva", "Matteo Tomasetto", "David Zoro", "J. Nathan Kutz"], "categories": ["cs.LG", "cs.CE", "math.DS", "nlin.CD"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages, 9 figures", "url": "http://arxiv.org/abs/2507.20954v1", "summary": "SHallow REcurrent Decoders (SHRED) provide a deep learning strategy for\nmodeling high-dimensional dynamical systems and/or spatiotemporal data from\ndynamical system snapshot observations. PySHRED is a Python package that\nimplements SHRED and several of its major extensions, including for robust\nsensing, reduced order modeling and physics discovery. In this paper, we\nintroduce the version 1.0 release of PySHRED, which includes data preprocessors\nand a number of cutting-edge SHRED methods specifically designed to handle\nreal-world data that may be noisy, multi-scale, parameterized, prohibitively\nhigh-dimensional, and strongly nonlinear. The package is easy to install,\nthoroughly-documented, supplemented with extensive code examples, and\nmodularly-structured to support future additions. The entire codebase is\nreleased under the MIT license and is available at\nhttps://github.com/pyshred-dev/pyshred.", "comment": "15 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.20954v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20371", "title": "Hypo-paradoxical Linkages: Linkages That Should Move-But Don't", "authors": ["Nir Shvalb", "Oded Medina"], "categories": ["physics.soc-ph", "cs.RO", "70B15"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "Comments:      15 pages, 8 figures", "url": "http://arxiv.org/abs/2507.20371v1", "summary": "While paradoxical linkages famously violate the Chebyshev-Grubler-Kutzbach\ncriterion by exhibiting unexpected mobility, we identify an opposing\nphenomenon: a class of linkages that appear mobile according to the same\ncriterion, yet are in fact rigid. We refer to these as hypo-paradoxical\nlinkages, and proceed to analyze and illustrate their behavior. We use the same\ntools to further explain the unexpected positive mobility of Bennet mechanism.", "comment": "15 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.20371v1", "cate": "physics.soc-ph", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20703", "title": "A General Framework for Dynamic MAPF using Multi-Shot ASP and Tunnels", "authors": ["Aysu Bogatarkan", "Esra Erdem"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20703v1", "summary": "MAPF problem aims to find plans for multiple agents in an environment within\na given time, such that the agents do not collide with each other or obstacles.\nMotivated by the execution and monitoring of these plans, we study Dynamic MAPF\n(D-MAPF) problem, which allows changes such as agents entering/leaving the\nenvironment or obstacles being removed/moved. Considering the requirements of\nreal-world applications in warehouses with the presence of humans, we introduce\n1) a general definition for D-MAPF (applicable to variations of D-MAPF), 2) a\nnew framework to solve D-MAPF (utilizing multi-shot computation, and allowing\ndifferent methods to solve D-MAPF), and 3) a new ASP-based method to solve\nD-MAPF (combining advantages of replanning and repairing methods, with a novel\nconcept of tunnels to specify where agents can move). We have illustrated the\nstrengths and weaknesses of this method by experimental evaluations, from the\nperspectives of computational performance and quality of solutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20703v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21012", "title": "User-Centered Design with AI in the Loop: A Case Study of Rapid User Interface Prototyping with \"Vibe Coding\"", "authors": ["Tianyi Li", "Tanay Maheshwari", "Alex Voelker"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21012v1", "summary": "We present a case study of using generative user interfaces, or ``vibe\ncoding,'' a method leveraging large language models (LLMs) for generating code\nvia natural language prompts, to support rapid prototyping in user-centered\ndesign (UCD). Extending traditional UCD practices, we propose an AI-in-the-loop\nideate-prototyping process. We share insights from an empirical experience\nintegrating this process to develop an interactive data analytics interface for\nhighway traffic engineers to effectively retrieve and analyze historical\ntraffic data. With generative UIs, the team was able to elicit rich user\nfeedback and test multiple alternative design ideas from user evaluation\ninterviews and real-time collaborative sessions with domain experts. We discuss\nthe advantages and pitfalls of vibe coding for bridging the gaps between design\nexpertise and domain-specific expertise.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21012v1", "cate": "cs.HC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19755", "title": "Modeling enzyme temperature stability from sequence segment perspective", "authors": ["Ziqi Zhang", "Shiheng Chen", "Runze Yang", "Zhisheng Wei", "Wei Zhang", "Lei Wang", "Zhanzhi Liu", "Fengshan Zhang", "Jing Wu", "Xiaoyong Pan", "Hongbin Shen", "Longbing Cao", "Zhaohong Deng"], "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19755v1", "summary": "Developing enzymes with desired thermal properties is crucial for a wide\nrange of industrial and research applications, and determining temperature\nstability is an essential step in this process. Experimental determination of\nthermal parameters is labor-intensive, time-consuming, and costly. Moreover,\nexisting computational approaches are often hindered by limited data\navailability and imbalanced distributions. To address these challenges, we\nintroduce a curated temperature stability dataset designed for model\ndevelopment and benchmarking in enzyme thermal modeling. Leveraging this\ndataset, we present the \\textit{Segment Transformer}, a novel deep learning\nframework that enables efficient and accurate prediction of enzyme temperature\nstability. The model achieves state-of-the-art performance with an RMSE of\n24.03, MAE of 18.09, and Pearson and Spearman correlations of 0.33,\nrespectively. These results highlight the effectiveness of incorporating\nsegment-level representations, grounded in the biological observation that\ndifferent regions of a protein sequence contribute unequally to thermal\nbehavior. As a proof of concept, we applied the Segment Transformer to guide\nthe engineering of a cutinase enzyme. Experimental validation demonstrated a\n1.64-fold improvement in relative activity following heat treatment, achieved\nthrough only 17 mutations and without compromising catalytic function.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19755v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20848", "title": "Search-Based Fuzzing For RESTful APIs That Use MongoDB", "authors": ["Hernan Ghianni", "Man Zhang", "Juan P. Galeotti", "Andrea Arcuri"], "categories": ["cs.SE", "cs.DB"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20848v1", "summary": "In RESTful APIs, interactions with a database are a common and crucial\naspect. When generating whitebox tests, it is essential to consider the\ndatabase's state (i.e., the data contained in the database) to achieve higher\ncode coverage and uncover more hidden faults. This article presents novel\ntechniques to enhance search-based software test generation for RESTful APIs\ninteracting with NoSQL databases. Specifically, we target the popular MongoDB\ndatabase, by dynamically analyzing (via automated code instrumentation) the\nstate of the database during the test generation process. Additionally, to\nachieve better results, our novel approach allows inserting NoSQL data directly\nfrom test cases. This is particularly beneficial when generating the correct\nsequence of events to set the NoSQL database in an appropriate state is\nchallenging or time-consuming. This method is also advantageous for testing\nread-only microservices. Our novel techniques are implemented as an extension\nof EvoMaster, the only open-source tool for white-box fuzzing RESTful APIs.\nExperiments conducted on six RESTful APIs demonstrated significant improvements\nin code coverage, with increases of up to 18% compared to existing white-box\napproaches. To better highlight the improvements of our novel techniques,\ncomparisons are also carried out with four state-of-the-art black-box fuzzers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20848v1", "cate": "cs.SE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20060", "title": "ModShift: Model Privacy via Designed Shifts", "authors": ["Nomaan A. Kherani", "Urbashi Mitra"], "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      To appear in the 2025 Asilomar Conference on Signals, Systems and Computers", "url": "http://arxiv.org/abs/2507.20060v1", "summary": "In this paper, shifts are introduced to preserve model privacy against an\neavesdropper in federated learning. Model learning is treated as a parameter\nestimation problem. This perspective allows us to derive the Fisher Information\nmatrix of the model updates from the shifted updates and drive them to\nsingularity, thus posing a hard estimation problem for Eve. The shifts are\nsecurely shared with the central server to maintain model accuracy at the\nserver and participating devices. A convergence test is proposed to detect if\nmodel updates have been tampered with and we show that our scheme passes this\ntest. Numerical results show that our scheme achieves a higher model shift when\ncompared to a noise injection scheme while requiring a lesser bandwidth secret\nchannel.", "comment": "To appear in the 2025 Asilomar Conference on Signals, Systems and\n  Computers", "pdf_url": "http://arxiv.org/pdf/2507.20060v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20047", "title": "Parallel Hierarchical Agglomerative Clustering in Low Dimensions", "authors": ["MohammadHossein Bateni", "Laxman Dhulipala", "Willem Fletcher", "Kishen N Gowda", "D Ellis Hershkowitz", "Rajesh Jayaram", "Jakub Łącki"], "categories": ["cs.DS", "cs.CC", "cs.DC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20047v1", "summary": "Hierarchical Agglomerative Clustering (HAC) is an extensively studied and\nwidely used method for hierarchical clustering in $\\mathbb{R}^k$ based on\nrepeatedly merging the closest pair of clusters according to an input linkage\nfunction $d$. Highly parallel (i.e., NC) algorithms are known for\n$(1+\\epsilon)$-approximate HAC (where near-minimum rather than minimum pairs\nare merged) for certain linkage functions that monotonically increase as merges\nare performed. However, no such algorithms are known for many important but\nnon-monotone linkage functions such as centroid and Ward's linkage.\n  In this work, we show that a general class of non-monotone linkage functions\n-- which include centroid and Ward's distance -- admit efficient NC algorithms\nfor $(1+\\epsilon)$-approximate HAC in low dimensions. Our algorithms are based\non a structural result which may be of independent interest: the height of the\nhierarchy resulting from any constant-approximate HAC on $n$ points for this\nclass of linkage functions is at most $\\operatorname{poly}(\\log n)$ as long as\n$k = O(\\log \\log n / \\log \\log \\log n)$. Complementing our upper bounds, we\nshow that NC algorithms for HAC with these linkage functions in\n\\emph{arbitrary} dimensions are unlikely to exist by showing that HAC is\nCC-hard when $d$ is centroid distance and $k = n$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20047v1", "cate": "cs.DS", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19567", "title": "Differentiating hype from practical applications of large language models in medicine -- a primer for healthcare professionals", "authors": ["Elisha D. O. Roberson"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      7 pages main document text, 2 figures. A basic primer on the potential and dangers of AI generally and LLMs specifically in the medical care system. Targeted to *non-expert* healthcare workers without experience in AI or LLMs", "url": "http://arxiv.org/abs/2507.19567v1", "summary": "The medical ecosystem consists of the training of new clinicians and\nresearchers, the practice of clinical medicine, and areas of adjacent research.\nThere are many aspects of these domains that could benefit from the application\nof task automation and programmatic assistance. Machine learning and artificial\nintelligence techniques, including large language models (LLMs), have been\npromised to deliver on healthcare innovation, improving care speed and\naccuracy, and reducing the burden on staff for manual interventions. However,\nLLMs have no understanding of objective truth that is based in reality. They\nalso represent real risks to the disclosure of protected information when used\nby clinicians and researchers. The use of AI in medicine in general, and the\ndeployment of LLMs in particular, therefore requires careful consideration and\nthoughtful application to reap the benefits of these technologies while\navoiding the dangers in each context.", "comment": "7 pages main document text, 2 figures. A basic primer on the\n  potential and dangers of AI generally and LLMs specifically in the medical\n  care system. Targeted to *non-expert* healthcare workers without experience\n  in AI or LLMs", "pdf_url": "http://arxiv.org/pdf/2507.19567v1", "cate": "cs.CY", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2506.19118", "title": "LKA: Large Kernel Adapter for Enhanced Medical Image Classification", "authors": ["Ziquan Zhu", "Si-Yuan Lu", "Tianjin Huang", "Lu Liu", "Zhe Liu"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      The manuscript has been withdrawn in order to revise key technical components and improve experimental validation. We plan to substantially update the model design and resubmit after further evaluation.", "url": "http://arxiv.org/abs/2506.19118v3", "summary": "Despite the notable success of current Parameter-Efficient Fine-Tuning (PEFT)\nmethods across various domains, their effectiveness on medical datasets falls\nshort of expectations. This limitation arises from two key factors: (1) medical\nimages exhibit extensive anatomical variation and low contrast, necessitating a\nlarge receptive field to capture critical features, and (2) existing PEFT\nmethods do not explicitly address the enhancement of receptive fields. To\novercome these challenges, we propose the Large Kernel Adapter (LKA), designed\nto expand the receptive field while maintaining parameter efficiency. The\nproposed LKA consists of three key components: down-projection, channel-wise\nlarge kernel convolution, and up-projection. Through extensive experiments on\nvarious datasets and pre-trained models, we demonstrate that the incorporation\nof a larger kernel size is pivotal in enhancing the adaptation of pre-trained\nmodels for medical image analysis. Our proposed LKA outperforms 11 commonly\nused PEFT methods, surpassing the state-of-the-art by 3.5% in top-1 accuracy\nacross five medical datasets.", "comment": "The manuscript has been withdrawn in order to revise key technical\n  components and improve experimental validation. We plan to substantially\n  update the model design and resubmit after further evaluation.", "pdf_url": "http://arxiv.org/pdf/2506.19118v3", "cate": "cs.CE", "date": "2025-06-23", "updated": "2025-07-26"}
{"id": "2507.20772", "title": "Beyond Line-of-Sight: Cooperative Localization Using Vision and V2X Communication", "authors": ["Annika Wong", "Zhiqi Tang", "Frank J. Jiang", "Karl H. Johansson", "Jonas Mårtensson"], "categories": ["eess.SY", "cs.RO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Accepted at the 2025 IEEE 28th International Conference on Intelligent Transportation Systems (ITSC 2025)", "url": "http://arxiv.org/abs/2507.20772v1", "summary": "Accurate and robust localization is critical for the safe operation of\nConnected and Automated Vehicles (CAVs), especially in complex urban\nenvironments where Global Navigation Satellite System (GNSS) signals are\nunreliable. This paper presents a novel vision-based cooperative localization\nalgorithm that leverages onboard cameras and Vehicle-to-Everything (V2X)\ncommunication to enable CAVs to estimate their poses, even in occlusion-heavy\nscenarios such as busy intersections. In particular, we propose a novel\ndecentralized observer for a group of connected agents that includes landmark\nagents (static or moving) in the environment with known positions and vehicle\nagents that need to estimate their poses (both positions and orientations).\nAssuming that (i) there are at least three landmark agents in the environment,\n(ii) each vehicle agent can measure its own angular and translational\nvelocities as well as relative bearings to at least three neighboring landmarks\nor vehicles, and (iii) neighboring vehicles can communicate their pose\nestimates, each vehicle can estimate its own pose using the proposed\ndecentralized observer. We prove that the origin of the estimation error is\nlocally exponentially stable under the proposed observer, provided that the\nminimal observability conditions are satisfied. Moreover, we evaluate the\nproposed approach through experiments with real 1/10th-scale connected vehicles\nand large-scale simulations, demonstrating its scalability and validating the\ntheoretical guarantees in practical scenarios.", "comment": "Accepted at the 2025 IEEE 28th International Conference on\n  Intelligent Transportation Systems (ITSC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.20772v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20711", "title": "Algorithmic Fairness: A Runtime Perspective", "authors": ["Filip Cano", "Thomas A. Henzinger", "Konstantin Kueffner"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      To appear in RV 2025", "url": "http://arxiv.org/abs/2507.20711v1", "summary": "Fairness in AI is traditionally studied as a static property evaluated once,\nover a fixed dataset. However, real-world AI systems operate sequentially, with\noutcomes and environments evolving over time. This paper proposes a framework\nfor analysing fairness as a runtime property. Using a minimal yet expressive\nmodel based on sequences of coin tosses with possibly evolving biases, we study\nthe problems of monitoring and enforcing fairness expressed in either toss\noutcomes or coin biases. Since there is no one-size-fits-all solution for\neither problem, we provide a summary of monitoring and enforcement strategies,\nparametrised by environment dynamics, prediction horizon, and confidence\nthresholds. For both problems, we present general results under simple or\nminimal assumptions. We survey existing solutions for the monitoring problem\nfor Markovian and additive dynamics, and existing solutions for the enforcement\nproblem in static settings with known dynamics.", "comment": "To appear in RV 2025", "pdf_url": "http://arxiv.org/pdf/2507.20711v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19855", "title": "Inducing Causal World Models in LLMs for Zero-Shot Physical Reasoning", "authors": ["Aditya Sharma", "Linh Nguyen", "Ananya Gupta", "Chengyu Wang", "Chiamaka Adebayo", "Jakub Kowalski"], "categories": ["cs.LG", "cs.HC", "68T05, 68T07, 68T40", "I.2.6; I.2.9; I.2.7; I.2.10; H.5.2"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures,", "url": "http://arxiv.org/abs/2507.19855v2", "summary": "Large Language Models (LLMs), despite their advanced linguistic capabilities,\nfundamentally lack an intuitive understanding of physical dynamics, which\nlimits their effectiveness in real-world scenarios that require causal\nreasoning. In this paper, we introduce Causal World Model Induction (CWMI), a\nnovel framework designed to embed an explicit model of causal physics within an\nLLM. Our approach incorporates a dedicated Causal Physics Module (CPM) and a\nnew training objective called Causal Intervention Loss, encouraging the model\nto learn cause-and-effect relationships from multimodal data. By training the\nmodel to predict the outcomes of hypothetical interventions instead of merely\ncapturing statistical correlations, CWMI develops a robust internal\nrepresentation of physical laws. Experimental results show that CWMI\nsignificantly outperforms state-of-the-art LLMs on zero-shot physical reasoning\ntasks, including the PIQA benchmark and our newly proposed PhysiCa-Bench\ndataset. These findings demonstrate that inducing a causal world model is a\ncritical step toward more reliable and generalizable AI systems.", "comment": "12 pages, 4 figures,", "pdf_url": "http://arxiv.org/pdf/2507.19855v2", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-29"}
{"id": "2507.19771", "title": "Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation", "authors": ["Xin Zhang", "Lissette Iturburu", "Juan Nicolas Villamizar", "Xiaoyu Liu", "Manuel Salmeron", "Shirley J. Dyke", "Julio Ramirez"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19771v1", "summary": "Structural drawings are widely used in many fields, e.g., mechanical\nengineering, civil engineering, etc. In civil engineering, structural drawings\nserve as the main communication tool between architects, engineers, and\nbuilders to avoid conflicts, act as legal documentation, and provide a\nreference for future maintenance or evaluation needs. They are often organized\nusing key elements such as title/subtitle blocks, scales, plan views, elevation\nview, sections, and detailed sections, which are annotated with standardized\nsymbols and line types for interpretation by engineers and contractors. Despite\nadvances in software capabilities, the task of generating a structural drawing\nremains labor-intensive and time-consuming for structural engineers. Here we\nintroduce a novel generative AI-based method for generating structural drawings\nemploying a large language model (LLM) agent. The method incorporates a\nretrieval-augmented generation (RAG) technique using externally-sourced facts\nto enhance the accuracy and reliability of the language model. This method is\ncapable of understanding varied natural language descriptions, processing these\nto extract necessary information, and generating code to produce the desired\nstructural drawing in AutoCAD. The approach developed, demonstrated and\nevaluated herein enables the efficient and direct conversion of a structural\ndrawing's natural language description into an AutoCAD drawing, significantly\nreducing the workload compared to current working process associated with\nmanual drawing production, facilitating the typical iterative process of\nengineers for expressing design ideas in a simplified way.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19771v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20888", "title": "Enhancing Project-Specific Code Completion by Inferring Internal API Information", "authors": ["Le Deng", "Xiaoxue Ren", "Chao Ni", "Ming Liang", "David Lo", "Zhongxin Liu"], "categories": ["cs.SE", "cs.CL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20888v1", "summary": "Project-specific code completion is a critical task that leverages context\nfrom a project to generate accurate code. State-of-the-art methods use\nretrieval-augmented generation (RAG) with large language models (LLMs) and\nproject information for code completion. However, they often struggle to\nincorporate internal API information, which is crucial for accuracy, especially\nwhen APIs are not explicitly imported in the file.\n  To address this, we propose a method to infer internal API information\nwithout relying on imports. Our method extends the representation of APIs by\nconstructing usage examples and semantic descriptions, building a knowledge\nbase for LLMs to generate relevant completions. We also introduce ProjBench, a\nbenchmark that avoids leaked imports and consists of large-scale real-world\nprojects.\n  Experiments on ProjBench and CrossCodeEval show that our approach\nsignificantly outperforms existing methods, improving code exact match by\n22.72% and identifier exact match by 18.31%. Additionally, integrating our\nmethod with existing baselines boosts code match by 47.80% and identifier match\nby 35.55%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20888v1", "cate": "cs.SE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20108", "title": "Graded Transformers: A Symbolic-Geometric Approach to Structured Learning", "authors": ["Tony Shaska Sr"], "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20108v1", "summary": "We introduce the Graded Transformer framework, a novel class of sequence\nmodels that embeds algebraic inductive biases through grading transformations\non vector spaces. Extending the theory of Graded Neural Networks (GNNs), we\npropose two architectures: the Linearly Graded Transformer (LGT) and the\nExponentially Graded Transformer (EGT). These models apply parameterized\nscaling operators-governed by fixed or learnable grading tuples and, for EGT,\nexponential factors to infuse hierarchical structure into attention and\nrepresentation layers, enhancing efficiency for structured data.\n  We derive rigorous theoretical guarantees, including universal approximation\ntheorems for continuous and Sobolev functions, reduced sample complexity via\neffective VC dimension bounds, Lipschitz continuity of graded operations, and\nrobustness to adversarial perturbations. A graded loss function ensures\ngradient stability and alignment with domain priors during optimization. By\ntreating grades as differentiable parameters, the framework enables adaptive\nfeature prioritization, overcoming limitations of fixed grades in prior work.\n  The Graded Transformer holds transformative potential for hierarchical\nlearning and neurosymbolic reasoning, with applications spanning algebraic\ngeometry (e.g., moduli spaces and zeta functions), physics (e.g., multiscale\nsimulations), natural language processing (e.g., syntactic parsing), biological\nsequence analysis (e.g., variant prediction), and emerging areas like graph\nneural networks and financial modeling. This work advances structured deep\nlearning by fusing geometric and algebraic principles with attention\nmechanisms, offering a mathematically grounded alternative to data-driven\nmodels and paving the way for interpretable, efficient systems in complex\ndomains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20108v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20051", "title": "$K^4$: Online Log Anomaly Detection Via Unsupervised Typicality Learning", "authors": ["Weicong Chen", "Vikash Singh", "Zahra Rahmani", "Debargha Ganguly", "Mohsen Hariri", "Vipin Chaudhary"], "categories": ["cs.LG", "cs.CL", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20051v1", "summary": "Existing Log Anomaly Detection (LogAD) methods are often slow, dependent on\nerror-prone parsing, and use unrealistic evaluation protocols. We introduce\n$K^4$, an unsupervised and parser-independent framework for high-performance\nonline detection. $K^4$ transforms arbitrary log embeddings into compact\nfour-dimensional descriptors (Precision, Recall, Density, Coverage) using\nefficient k-nearest neighbor (k-NN) statistics. These descriptors enable\nlightweight detectors to accurately score anomalies without retraining. Using a\nmore realistic online evaluation protocol, $K^4$ sets a new state-of-the-art\n(AUROC: 0.995-0.999), outperforming baselines by large margins while being\norders of magnitude faster, with training under 4 seconds and inference as low\nas 4 $\\mu$s.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20051v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19643", "title": "Can You Share Your Story? Modeling Clients' Metacognition and Openness for LLM Therapist Evaluation", "authors": ["Minju Kim", "Dongje Yoo", "Yeonjun Hwang", "Minseok Kang", "Namyoung Kim", "Minju Gwak", "Beong-woo Kwak", "Hyungjoo Chae", "Harim Kim", "Yunjoong Lee", "Min Hee Kim", "Dayi Jung", "Kyong-Mee Chung", "Jinyoung Yeo"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Published at ACL 2025 Findings", "url": "http://arxiv.org/abs/2507.19643v1", "summary": "Understanding clients' thoughts and beliefs is fundamental in counseling, yet\ncurrent evaluations of LLM therapists often fail to assess this ability.\nExisting evaluation methods rely on client simulators that clearly disclose\ninternal states to the therapist, making it difficult to determine whether an\nLLM therapist can uncover unexpressed perspectives. To address this limitation,\nwe introduce MindVoyager, a novel evaluation framework featuring a controllable\nand realistic client simulator which dynamically adapts itself based on the\nongoing counseling session, offering a more realistic and challenging\nevaluation environment. We further introduce evaluation metrics that assess the\nexploration ability of LLM therapists by measuring their thorough understanding\nof client's beliefs and thoughts.", "comment": "Published at ACL 2025 Findings", "pdf_url": "http://arxiv.org/pdf/2507.19643v1", "cate": "cs.CY", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.18235", "title": "A stabilized Two-Step Formulation of Maxwell's Equations in the time-domain", "authors": ["Leon Herles", "Mario Mally", "Jörg Ostrowski", "Sebastian Schöps", "Melina Merkel"], "categories": ["math.NA", "cs.CE", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      6 pages, 9 figures", "url": "http://arxiv.org/abs/2507.18235v2", "summary": "Simulating electromagnetic fields across broad frequency ranges is\nchallenging due to numerical instabilities at low frequencies. This work\nextends a stabilized two-step formulation of Maxwell's equations to the\ntime-domain. Using a Galerkin discretization in space, we apply two different\ntime-discretization schemes that are tailored to the first- and second-order in\ntime partial differential equations of the two-step solution procedure used\nhere. To address the low-frequency instability, we incorporate a generalized\ntree-cotree gauge that removes the singularity of the curl-curl operator,\nensuring robustness even in the static limit. Numerical results on academic and\napplication-oriented 3D problems confirm stability, accuracy, and the method's\napplicability to nonlinear, temperature-dependent materials.", "comment": "6 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.18235v2", "cate": "math.NA", "date": "2025-07-24", "updated": "2025-07-25"}
{"id": "2507.20951", "title": "Partially Observable Monte-Carlo Graph Search", "authors": ["Yang You", "Vincent Thomas", "Alex Schutz", "Robert Skilton", "Nick Hawes", "Olivier Buffet"], "categories": ["cs.AI", "cs.RO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      To be published in Proceedings of ICAPS 2025", "url": "http://arxiv.org/abs/2507.20951v1", "summary": "Currently, large partially observable Markov decision processes (POMDPs) are\noften solved by sampling-based online methods which interleave planning and\nexecution phases. However, a pre-computed offline policy is more desirable in\nPOMDP applications with time or energy constraints. But previous offline\nalgorithms are not able to scale up to large POMDPs. In this article, we\npropose a new sampling-based algorithm, the partially observable Monte-Carlo\ngraph search (POMCGS) to solve large POMDPs offline. Different from many online\nPOMDP methods, which progressively develop a tree while performing\n(Monte-Carlo) simulations, POMCGS folds this search tree on the fly to\nconstruct a policy graph, so that computations can be drastically reduced, and\nusers can analyze and validate the policy prior to embedding and executing it.\nMoreover, POMCGS, together with action progressive widening and observation\nclustering methods provided in this article, is able to address certain\ncontinuous POMDPs. Through experiments, we demonstrate that POMCGS can generate\npolicies on the most challenging POMDPs, which cannot be computed by previous\noffline algorithms, and these policies' values are competitive compared with\nthe state-of-the-art online POMDP algorithms.", "comment": "To be published in Proceedings of ICAPS 2025", "pdf_url": "http://arxiv.org/pdf/2507.20951v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20728", "title": "Learning the Value Systems of Societies from Preferences", "authors": ["Andrés Holgado-Sánchez", "Holger Billhardt", "Sascha Ossowski", "Sara Degli-Esposti"], "categories": ["cs.AI", "cs.CY", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Full version of publication under the same accepted at ECAI 2025 conference (Submission 6755). 8 pages + 2 supplementary material", "url": "http://arxiv.org/abs/2507.20728v1", "summary": "Aligning AI systems with human values and the value-based preferences of\nvarious stakeholders (their value systems) is key in ethical AI. In value-aware\nAI systems, decision-making draws upon explicit computational representations\nof individual values (groundings) and their aggregation into value systems. As\nthese are notoriously difficult to elicit and calibrate manually, value\nlearning approaches aim to automatically derive computational models of an\nagent's values and value system from demonstrations of human behaviour.\nNonetheless, social science and humanities literature suggest that it is more\nadequate to conceive the value system of a society as a set of value systems of\ndifferent groups, rather than as the simple aggregation of individual value\nsystems. Accordingly, here we formalize the problem of learning the value\nsystems of societies and propose a method to address it based on heuristic deep\nclustering. The method learns socially shared value groundings and a set of\ndiverse value systems representing a given society by observing qualitative\nvalue-based preferences from a sample of agents. We evaluate the proposal in a\nuse case with real data about travelling decisions.", "comment": "Full version of publication under the same accepted at ECAI 2025\n  conference (Submission 6755). 8 pages + 2 supplementary material", "pdf_url": "http://arxiv.org/pdf/2507.20728v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19870", "title": "OW-CLIP: Data-Efficient Visual Supervision for Open-World Object Detection via Human-AI Collaboration", "authors": ["Junwen Duan", "Wei Xue", "Ziyao Kang", "Shixia Liu", "Jiazhi Xia"], "categories": ["cs.CV", "cs.HC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 11 figures", "url": "http://arxiv.org/abs/2507.19870v1", "summary": "Open-world object detection (OWOD) extends traditional object detection to\nidentifying both known and unknown object, necessitating continuous model\nadaptation as new annotations emerge. Current approaches face significant\nlimitations: 1) data-hungry training due to reliance on a large number of\ncrowdsourced annotations, 2) susceptibility to \"partial feature overfitting,\"\nand 3) limited flexibility due to required model architecture modifications. To\ntackle these issues, we present OW-CLIP, a visual analytics system that\nprovides curated data and enables data-efficient OWOD model incremental\ntraining. OW-CLIP implements plug-and-play multimodal prompt tuning tailored\nfor OWOD settings and introduces a novel \"Crop-Smoothing\" technique to mitigate\npartial feature overfitting. To meet the data requirements for the training\nmethodology, we propose dual-modal data refinement methods that leverage large\nlanguage models and cross-modal similarity for data generation and filtering.\nSimultaneously, we develope a visualization interface that enables users to\nexplore and deliver high-quality annotations: including class-specific visual\nfeature phrases and fine-grained differentiated images. Quantitative evaluation\ndemonstrates that OW-CLIP achieves competitive performance at 89% of\nstate-of-the-art performance while requiring only 3.8% self-generated data,\nwhile outperforming SOTA approach when trained with equivalent data volumes. A\ncase study shows the effectiveness of the developed method and the improved\nannotation quality of our visualization system.", "comment": "9 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.19870v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19803", "title": "AI-Based Clinical Rule Discovery for NMIBC Recurrence through Tsetlin Machines", "authors": ["Saram Abbas", "Naeem Soomro", "Rishad Shafik", "Rakesh Heer", "Kabita Adhikari"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Submitted to ISTM 2025", "url": "http://arxiv.org/abs/2507.19803v1", "summary": "Bladder cancer claims one life every 3 minutes worldwide. Most patients are\ndiagnosed with non-muscle-invasive bladder cancer (NMIBC), yet up to 70% recur\nafter treatment, triggering a relentless cycle of surgeries, monitoring, and\nrisk of progression. Clinical tools like the EORTC risk tables are outdated and\nunreliable - especially for intermediate-risk cases.\n  We propose an interpretable AI model using the Tsetlin Machine (TM), a\nsymbolic learner that outputs transparent, human-readable logic. Tested on the\nPHOTO trial dataset (n=330), TM achieved an F1-score of 0.80, outperforming\nXGBoost (0.78), Logistic Regression (0.60), and EORTC (0.42). TM reveals the\nexact clauses behind each prediction, grounded in clinical features like tumour\ncount, surgeon experience, and hospital stay - offering accuracy and full\ntransparency. This makes TM a powerful, trustworthy decision-support tool ready\nfor real-world adoption.", "comment": "Submitted to ISTM 2025", "pdf_url": "http://arxiv.org/pdf/2507.19803v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21027", "title": "Smart Expansion Techniques for ASP-based Interactive Configuration", "authors": ["Lucia Balážová", "Richard Comploi-Taupe", "Susana Hahn", "Nicolas Rühling", "Gottfried Schenner"], "categories": ["cs.AI", "cs.SE", "D.1.6; I.2.1"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Under consideration for publication in Theory and Practice of Logic Programming (TPLP)", "url": "http://arxiv.org/abs/2507.21027v1", "summary": "Product configuration is a successful application of Answer Set Programming\n(ASP). However, challenges are still open for interactive systems to\neffectively guide users through the configuration process. The aim of our work\nis to provide an ASP-based solver for interactive configuration that can deal\nwith large-scale industrial configuration problems and that supports intuitive\nuser interfaces via an API. In this paper, we focus on improving the\nperformance of automatically completing a partial configuration. Our main\ncontribution enhances the classical incremental approach for multi-shot solving\nby four different smart expansion functions. The core idea is to determine and\nadd specific objects or associations to the partial configuration by exploiting\ncautious and brave consequences before checking for the existence of a complete\nconfiguration with the current objects in each iteration. This approach limits\nthe number of costly unsatisfiability checks and reduces the search space,\nthereby improving solving performance. In addition, we present a user interface\nthat uses our API and is implemented in ASP.", "comment": "Under consideration for publication in Theory and Practice of Logic\n  Programming (TPLP)", "pdf_url": "http://arxiv.org/pdf/2507.21027v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20770", "title": "Sampling and entropy numbers in the uniform norm", "authors": ["Mario Ullrich"], "categories": ["math.FA", "cs.IT", "cs.NA", "math.IT", "math.NA", "41A65, 41A46, 41A50"], "primary_category": "Subjects:       Functional Analysis (math.FA)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.20770v1", "summary": "We prove a sharp bound between sampling numbers and entropy numbers in the\nuniform norm for general convex sets of bounded functions.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.20770v1", "cate": "math.FA", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20424", "title": "Communication-Efficient Distributed Training for Collaborative Flat Optima Recovery in Deep Learning", "authors": ["Tolga Dimlioglu", "Anna Choromanska"], "categories": ["cs.LG", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages main body, 32 pages of supplementary material for detailed derivations and more experiment results", "url": "http://arxiv.org/abs/2507.20424v1", "summary": "We study centralized distributed data parallel training of deep neural\nnetworks (DNNs), aiming to improve the trade-off between communication\nefficiency and model performance of the local gradient methods. To this end, we\nrevisit the flat-minima hypothesis, which suggests that models with better\ngeneralization tend to lie in flatter regions of the loss landscape. We\nintroduce a simple, yet effective, sharpness measure, Inverse Mean Valley, and\ndemonstrate its strong correlation with the generalization gap of DNNs. We\nincorporate an efficient relaxation of this measure into the distributed\ntraining objective as a lightweight regularizer that encourages workers to\ncollaboratively seek wide minima. The regularizer exerts a pushing force that\ncounteracts the consensus step pulling the workers together, giving rise to the\nDistributed Pull-Push Force (DPPF) algorithm. Empirically, we show that DPPF\noutperforms other communication-efficient approaches and achieves better\ngeneralization performance than local gradient methods and synchronous gradient\naveraging, while significantly reducing communication overhead. In addition,\nour loss landscape visualizations confirm the ability of DPPF to locate flatter\nminima. On the theoretical side, we show that DPPF guides workers to span flat\nvalleys, with the final valley width governed by the interplay between push and\npull strengths, and that its pull-push dynamics is self-stabilizing. We further\nprovide generalization guarantees linked to the valley width and prove\nconvergence in the non-convex setting.", "comment": "9 pages main body, 32 pages of supplementary material for detailed\n  derivations and more experiment results", "pdf_url": "http://arxiv.org/pdf/2507.20424v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19877", "title": "AI-Driven Media & Synthetic Knowledge: Rethinking Society in Generative Futures", "authors": ["Katalin Feher"], "categories": ["cs.CY", "K4.2, K4.3, A0", "K.4.2; K.4.3; A.0"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      5 pages, summary of a granted experimental PhD seminar", "url": "http://arxiv.org/abs/2507.19877v1", "summary": "Generative AI is not just a technological leap -- it is a societal stress\ntest, reshaping trust, identity, equity, and authorship. This exploratory PhD\nseminar examined emerging academic trends in AI-driven synthetic media and\nworlds, emphasizing ethical risks and societal implications. In Part One,\nstudents explored core concepts such as generative AI, fake media, and\nsynthetic knowledge production. In Part Two, they critically engaged with these\nchallenges, producing actionable insights. The two-part format enabled deep\nreflection on power, responsibility, and education in AI-augmented\ncommunication. Outcomes offer practical guidance for educators, researchers,\nand institutions committed to fostering more responsible, human-centered AI use\nin media and society.", "comment": "5 pages, summary of a granted experimental PhD seminar", "pdf_url": "http://arxiv.org/pdf/2507.19877v1", "cate": "cs.CY", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19509", "title": "Computing Longitudinal Dynamic Derivatives of a VTOL Aircraft Using CFD Simulations and Forced-Oscillation Model", "authors": ["Ali Khosravani Nezhad", "AmirReza Kosari", "Rasoul Askari"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      The 23rd International Conference of Iranian Aerospace Society", "url": "http://arxiv.org/abs/2507.19509v1", "summary": "This study presents a comprehensive evaluation of dynamic aerodynamic\nderivatives during aircraft transition phases using advanced CFD simulations\nand forced oscillation testing. Two case studies are examined: a three\ndimensional fighter aircraft (Standard Dynamic Model, SDM) and a UT24 eVTOL\nmodel. The transition phase from vertical hover to forward cruise is analyzed\nwith harmonic oscillation techniques to capture unsteady aerodynamic forces and\nmoments. Grid sensitivity studies and multi zone meshing strategies ensure\nsimulation accuracy, while ANSYS Fluent finite volume solver and coupled\npressure velocity algorithms provide high fidelity results. Dynamic derivatives\nare derived from variations in angle of attack, flight path, and rotational\nmovements, with experimental and numerical data validating the approach. The\nfindings offer valuable insights for robust control design and stability\nanalysis, supporting future advancements in urban air mobility and aerospace\nengineering. Overall, this approach demonstrates substantial promise for\noptimizing aircraft performance during critical transition phases. These\nresults pave the way for future innovations", "comment": "The 23rd International Conference of Iranian Aerospace Society", "pdf_url": "http://arxiv.org/pdf/2507.19509v1", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-16"}
{"id": "2507.21053", "title": "Flow Matching Policy Gradients", "authors": ["David McAllister", "Songwei Ge", "Brent Yi", "Chung Min Kim", "Ethan Weber", "Hongsuk Choi", "Haiwen Feng", "Angjoo Kanazawa"], "categories": ["cs.LG", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      See our blog post: this https URL", "url": "http://arxiv.org/abs/2507.21053v1", "summary": "Flow-based generative models, including diffusion models, excel at modeling\ncontinuous distributions in high-dimensional spaces. In this work, we introduce\nFlow Policy Optimization (FPO), a simple on-policy reinforcement learning\nalgorithm that brings flow matching into the policy gradient framework. FPO\ncasts policy optimization as maximizing an advantage-weighted ratio computed\nfrom the conditional flow matching loss, in a manner compatible with the\npopular PPO-clip framework. It sidesteps the need for exact likelihood\ncomputation while preserving the generative capabilities of flow-based models.\nUnlike prior approaches for diffusion-based reinforcement learning that bind\ntraining to a specific sampling method, FPO is agnostic to the choice of\ndiffusion or flow integration at both training and inference time. We show that\nFPO can train diffusion-style policies from scratch in a variety of continuous\ncontrol tasks. We find that flow-based models can capture multimodal action\ndistributions and achieve higher performance than Gaussian policies,\nparticularly in under-conditioned settings.", "comment": "See our blog post: https://flowreinforce.github.io", "pdf_url": "http://arxiv.org/pdf/2507.21053v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20755", "title": "Beyond Listenership: AI-Predicted Interventions Drive Improvements in Maternal Health Behaviours", "authors": ["Arpan Dasgupta", "Sarvesh Gharat", "Neha Madhiwalla", "Aparna Hegde", "Milind Tambe", "Aparna Taneja"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20755v1", "summary": "Automated voice calls with health information are a proven method for\ndisseminating maternal and child health information among beneficiaries and are\ndeployed in several programs around the world. However, these programs often\nsuffer from beneficiary dropoffs and poor engagement. In previous work, through\nreal-world trials, we showed that an AI model, specifically a restless bandit\nmodel, could identify beneficiaries who would benefit most from live service\ncall interventions, preventing dropoffs and boosting engagement. However, one\nkey question has remained open so far: does such improved listenership via\nAI-targeted interventions translate into beneficiaries' improved knowledge and\nhealth behaviors? We present a first study that shows not only listenership\nimprovements due to AI interventions, but also simultaneously links these\nimprovements to health behavior changes. Specifically, we demonstrate that\nAI-scheduled interventions, which enhance listenership, lead to statistically\nsignificant improvements in beneficiaries' health behaviors such as taking iron\nor calcium supplements in the postnatal period, as well as understanding of\ncritical health topics during pregnancy and infancy. This underscores the\npotential of AI to drive meaningful improvements in maternal and child health.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20755v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20419", "title": "Survey of NLU Benchmarks Diagnosing Linguistic Phenomena: Why not Standardize Diagnostics Benchmarks?", "authors": ["Khloud AL Jallad", "Nada Ghneim", "Ghaida Rebdawi"], "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20419v1", "summary": "Natural Language Understanding (NLU) is a basic task in Natural Language\nProcessing (NLP). The evaluation of NLU capabilities has become a trending\nresearch topic that attracts researchers in the last few years, resulting in\nthe development of numerous benchmarks. These benchmarks include various tasks\nand datasets in order to evaluate the results of pretrained models via public\nleaderboards. Notably, several benchmarks contain diagnostics datasets designed\nfor investigation and fine-grained error analysis across a wide range of\nlinguistic phenomena. This survey provides a comprehensive review of available\nEnglish, Arabic, and Multilingual NLU benchmarks, with a particular emphasis on\ntheir diagnostics datasets and the linguistic phenomena they covered. We\npresent a detailed comparison and analysis of these benchmarks, highlighting\ntheir strengths and limitations in evaluating NLU tasks and providing in-depth\nerror analysis. When highlighting the gaps in the state-of-the-art, we noted\nthat there is no naming convention for macro and micro categories or even a\nstandard set of linguistic phenomena that should be covered. Consequently, we\nformulated a research question regarding the evaluation metrics of the\nevaluation diagnostics benchmarks: \"Why do not we have an evaluation standard\nfor the NLU evaluation diagnostics benchmarks?\" similar to ISO standard in\nindustry. We conducted a deep analysis and comparisons of the covered\nlinguistic phenomena in order to support experts in building a global hierarchy\nfor linguistic phenomena in future. We think that having evaluation metrics for\ndiagnostics evaluation could be valuable to gain more insights when comparing\nthe results of the studied models on different diagnostics benchmarks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20419v1", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19822", "title": "Debunking Optimization Myths in Federated Learning for Medical Image Classification", "authors": ["Youngjoon Lee", "Hyukjoon Lee", "Jinu Gong", "Yang Cao", "Joonhyuk Kang"], "categories": ["cs.LG", "eess.IV", "eess.SP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to Efficient Medical AI Workshop - MICCAI 2025", "url": "http://arxiv.org/abs/2507.19822v1", "summary": "Federated Learning (FL) is a collaborative learning method that enables\ndecentralized model training while preserving data privacy. Despite its promise\nin medical imaging, recent FL methods are often sensitive to local factors such\nas optimizers and learning rates, limiting their robustness in practical\ndeployments. In this work, we revisit vanilla FL to clarify the impact of edge\ndevice configurations, benchmarking recent FL methods on colorectal pathology\nand blood cell classification task. We numerically show that the choice of\nlocal optimizer and learning rate has a greater effect on performance than the\nspecific FL method. Moreover, we find that increasing local training epochs can\neither enhance or impair convergence, depending on the FL method. These\nfindings indicate that appropriate edge-specific configuration is more crucial\nthan algorithmic complexity for achieving effective FL.", "comment": "Accepted to Efficient Medical AI Workshop - MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.19822v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2311.08485", "title": "Automated Identification of Sexual Orientation and Gender Identity Discriminatory Texts from Issue Comments", "authors": ["Sayma Sultana", "Jaydeb Sarker", "Farzana Israt", "Rajshakhar Paul", "Amiangshu Bosu"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at ACM Transactions on Software Engineering Methodology (TOSEM)", "url": "http://arxiv.org/abs/2311.08485v2", "summary": "In an industry dominated by straight men, many developers representing other\ngender identities and sexual orientations often encounter hateful or\ndiscriminatory messages. Such communications pose barriers to participation for\nwomen and LGBTQ+ persons. Due to sheer volume, manual inspection of all\ncommunications for discriminatory communication is infeasible for a large-scale\nFree Open-Source Software (FLOSS) community. To address this challenge, this\nstudy aims to develop an automated mechanism to identify Sexual orientation and\nGender identity Discriminatory (SGID) texts from software developers'\ncommunications. On this goal, we trained and evaluated SGID4SE ( Sexual\norientation and Gender Identity Discriminatory text identification for (4)\nSoftware Engineering texts) as a supervised learning-based SGID detection tool.\nSGID4SE incorporates six preprocessing steps and ten state-of-the-art\nalgorithms. SGID4SE implements six different strategies to improve the\nperformance of the minority class. We empirically evaluated each strategy and\nidentified an optimum configuration for each algorithm. In our ten-fold\ncross-validation-based evaluations, a BERT-based model boosts the best\nperformance with 85.9% precision, 80.0% recall, and 82.9% F1-Score for the SGID\nclass. This model achieves 95.7% accuracy and 80.4% Matthews Correlation\nCoefficient. Our dataset and tool establish a foundation for further research\nin this direction.", "comment": "Accepted at ACM Transactions on Software Engineering Methodology\n  (TOSEM)", "pdf_url": "http://arxiv.org/pdf/2311.08485v2", "cate": "cs.SE", "date": "2023-11-14", "updated": "2025-07-28"}
{"id": "2507.21022", "title": "A Generalized Cramér-Rao Bound Using Information Geometry", "authors": ["Satyajit Dhadumia", "M. Ashok Kumar"], "categories": ["math.ST", "cs.IT", "math.IT", "stat.OT", "stat.TH", "62F10, 62F35"], "primary_category": "Subjects:       Statistics Theory (math.ST)", "pdf_link": null, "comments": "Comments:      Presented at the IEEE International Symposium on Information Theory (ISIT 2025)", "url": "http://arxiv.org/abs/2507.21022v1", "summary": "In information geometry, statistical models are considered as differentiable\nmanifolds, where each probability distribution represents a unique point on the\nmanifold. A Riemannian metric can be systematically obtained from a divergence\nfunction using Eguchi's theory (1992); the well-known Fisher-Rao metric is\nobtained from the Kullback-Leibler (KL) divergence. The geometric derivation of\nthe classical Cram\\'er-Rao Lower Bound (CRLB) by Amari and Nagaoka (2000) is\nbased on this metric. In this paper, we study a Riemannian metric obtained by\napplying Eguchi's theory to the Basu-Harris-Hjort-Jones (BHHJ) divergence\n(1998) and derive a generalized Cram\\'er-Rao bound using Amari-Nagaoka's\napproach. There are potential applications for this bound in robust estimation.", "comment": "Presented at the IEEE International Symposium on Information Theory\n  (ISIT 2025)", "pdf_url": "http://arxiv.org/pdf/2507.21022v1", "cate": "math.ST", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20769", "title": "Accelerating Deterministic Global Optimization via GPU-parallel Interval Arithmetic", "authors": ["Hongzhen Zhang", "Tim Kerkenhoff", "Neil Kichler", "Manuel Dahmen", "Alexander Mitsos", "Uwe Naumann", "Dominik Bongartz"], "categories": ["math.OC", "cs.DC", "90C26, 90C30, 90-04, 90-08"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      28 pages, 8 figures and 4 tables", "url": "http://arxiv.org/abs/2507.20769v1", "summary": "Spatial Branch and Bound (B&B) algorithms are widely used for solving\nnonconvex problems to global optimality, yet they remain computationally\nexpensive. Though some works have been carried out to speed up B&B via CPU\nparallelization, GPU parallelization is much less explored. In this work, we\ninvestigate the design of a spatial B&B algorithm that involves an\ninterval-based GPU-parallel lower bounding solver: The domain of each B&B node\nis temporarily partitioned into numerous subdomains, then massive GPU\nparallelism is leveraged to compute interval bounds of the objective function\nand constraints on each subdomain, using the Mean Value Form. The resulting\nbounds are tighter than those achieved via regular interval arithmetic without\npartitioning, but they remain fast to compute. We implement the method into our\nopen-source solver MAiNGO via CUDA in two manners: wrapping all GPU tasks\nwithin one kernel function, or distributing the GPU tasks onto a CUDA graph.\nNumerical experiments show that using more subdomains leads to significantly\ntighter lower bounds and thus less B&B iterations. Regarding wall clock time,\nthe proposed spatial B&B framework achieves a speedup of three orders of\nmagnitude compared to applying interval arithmetic on the CPU without domain\npartitioning. Among the two implementations, the one developed with CUDA graph\nenables higher efficiency. Moreover, in some case studies, the proposed method\ndelivers competitive or better performance compared to MAiNGO's default solver\nwhich is based on McCormick relaxations. These results highlight the potential\nof GPU-accelerated bounding techniques to accelerate B&B algorithms.", "comment": "28 pages, 8 figures and 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.20769v1", "cate": "math.OC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20018", "title": "The Carbon Cost of Conversation, Sustainability in the Age of Language Models", "authors": ["Sayed Mahbub Hasan Amiri", "Prasun Goswami", "Md. Mainul Islam", "Mohammad Shakhawat Hossen", "Sayed Majhab Hasan Amiri", "Naznin Akter"], "categories": ["cs.CY", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      22 Pages, 5 Tables", "url": "http://arxiv.org/abs/2507.20018v2", "summary": "Large language models (LLMs) like GPT-3 and BERT have revolutionized natural\nlanguage processing (NLP), yet their environmental costs remain dangerously\noverlooked. This article critiques the sustainability of LLMs, quantifying\ntheir carbon footprint, water usage, and contribution to e-waste through case\nstudies of models such as GPT-4 and energy-efficient alternatives like Mistral\n7B. Training a single LLM can emit carbon dioxide equivalent to hundreds of\ncars driven annually, while data centre cooling exacerbates water scarcity in\nvulnerable regions. Systemic challenges corporate greenwashing, redundant model\ndevelopment, and regulatory voids perpetuate harm, disproportionately burdening\nmarginalized communities in the Global South. However, pathways exist for\nsustainable NLP: technical innovations (e.g., model pruning, quantum\ncomputing), policy reforms (carbon taxes, mandatory emissions reporting), and\ncultural shifts prioritizing necessity over novelty. By analysing industry\nleaders (Google, Microsoft) and laggards (Amazon), this work underscores the\nurgency of ethical accountability and global cooperation. Without immediate\naction, AIs ecological toll risks outpacing its societal benefits. The article\nconcludes with a call to align technological progress with planetary\nboundaries, advocating for equitable, transparent, and regenerative AI systems\nthat prioritize both human and environmental well-being.", "comment": "22 Pages, 5 Tables", "pdf_url": "http://arxiv.org/pdf/2507.20018v2", "cate": "cs.CY", "date": "2025-07-26", "updated": "2025-07-29"}
{"id": "2507.19516", "title": "Reinforcement learning in pursuit-evasion differential game: safety, stability and robustness", "authors": ["Xinyang Wang", "Hongwei Zhang", "Jun Xu", "Shimin Wang", "Martin Guay"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      13 pages, 7 figures", "url": "http://arxiv.org/abs/2507.19516v1", "summary": "Safety and stability are two critical concerns in pursuit-evasion (PE)\nproblems in an obstacle-rich environment. Most existing works combine control\nbarrier functions (CBFs) and reinforcement learning (RL) to provide an\nefficient and safe solution. However, they do not consider the presence of\ndisturbances, such as wind gust and actuator fault, which may exist in many\npractical applications. This paper integrates CBFs and a sliding mode control\n(SMC) term into RL to simultaneously address safety, stability, and robustness\nto disturbances. However, this integration is significantly challenging due to\nthe strong coupling between the CBF and SMC terms. Inspired by Stackelberg\ngame, we handle the coupling issue by proposing a hierarchical design scheme\nwhere SMC and safe control terms interact with each other in a leader-follower\nmanner. Specifically, the CBF controller, acting as the leader, enforces safety\nindependently of the SMC design; while the SMC term, as the follower, is\ndesigned based on the CBF controller. We then formulate the PE problem as a\nzero-sum game and propose a safe robust RL framework to learn the min-max\nstrategy online. A sufficient condition is provided under which the proposed\nalgorithm remains effective even when constraints are conflicting. Simulation\nresults demonstrate the effectiveness of the proposed safe robust RL framework.", "comment": "13 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.19516v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2303.09477", "title": "Learning Local Heuristics for Search-Based Navigation Planning", "authors": ["Rishi Veerapaneni", "Muhammad Suhail Saleem", "Maxim Likhachev"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Published at the International Conference on Automated Planning and Scheduling 2023 (ICAPS 2023)", "url": "http://arxiv.org/abs/2303.09477v2", "summary": "Graph search planning algorithms for navigation typically rely heavily on\nheuristics to efficiently plan paths. As a result, while such approaches\nrequire no training phase and can directly plan long horizon paths, they often\nrequire careful hand designing of informative heuristic functions. Recent works\nhave started bypassing hand designed heuristics by using machine learning to\nlearn heuristic functions that guide the search algorithm. While these methods\ncan learn complex heuristic functions from raw input, they i) require a\nsignificant training phase and ii) do not generalize well to new maps and\nlonger horizon paths. Our contribution is showing that instead of learning a\nglobal heuristic estimate, we can define and learn local heuristics which\nresults in a significantly smaller learning problem and improves\ngeneralization. We show that using such local heuristics can reduce node\nexpansions by 2-20x while maintaining bounded suboptimality, are easy to train,\nand generalize to new maps & long horizon plans.", "comment": "Published at the International Conference on Automated Planning and\n  Scheduling 2023 (ICAPS 2023)", "pdf_url": "http://arxiv.org/pdf/2303.09477v2", "cate": "cs.RO", "date": "2023-03-16", "updated": "2025-07-27"}
{"id": "2507.20758", "title": "How Chain-of-Thought Works? Tracing Information Flow from Decoding, Projection, and Activation", "authors": ["Hao Yang", "Qinghua Zhao", "Lei Li"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20758v1", "summary": "Chain-of-Thought (CoT) prompting significantly enhances model reasoning, yet\nits internal mechanisms remain poorly understood. We analyze CoT's operational\nprinciples by reversely tracing information flow across decoding, projection,\nand activation phases. Our quantitative analysis suggests that CoT may serve as\na decoding space pruner, leveraging answer templates to guide output\ngeneration, with higher template adherence strongly correlating with improved\nperformance. Furthermore, we surprisingly find that CoT modulates neuron\nengagement in a task-dependent manner: reducing neuron activation in\nopen-domain tasks, yet increasing it in closed-domain scenarios. These findings\noffer a novel mechanistic interpretability framework and critical insights for\nenabling targeted CoT interventions to design more efficient and robust\nprompts. We released our code and data at\nhttps://anonymous.4open.science/r/cot-D247.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20758v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20536", "title": "T2I-Copilot: A Training-Free Multi-Agent Text-to-Image System for Enhanced Prompt Interpretation and Interactive Generation", "authors": ["Chieh-Yun Chen", "Min Shi", "Gong Zhang", "Humphrey Shi"], "categories": ["cs.CV", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.20536v2", "summary": "Text-to-Image (T2I) generative models have revolutionized content creation\nbut remain highly sensitive to prompt phrasing, often requiring users to\nrepeatedly refine prompts multiple times without clear feedback. While\ntechniques such as automatic prompt engineering, controlled text embeddings,\ndenoising, and multi-turn generation mitigate these issues, they offer limited\ncontrollability, or often necessitate additional training, restricting the\ngeneralization abilities. Thus, we introduce T2I-Copilot, a training-free\nmulti-agent system that leverages collaboration between (Multimodal) Large\nLanguage Models to automate prompt phrasing, model selection, and iterative\nrefinement. This approach significantly simplifies prompt engineering while\nenhancing generation quality and text-image alignment compared to direct\ngeneration. Specifically, T2I-Copilot consists of three agents: (1) Input\nInterpreter, which parses the input prompt, resolves ambiguities, and generates\na standardized report; (2) Generation Engine, which selects the appropriate\nmodel from different types of T2I models and organizes visual and textual\nprompts to initiate generation; and (3) Quality Evaluator, which assesses\naesthetic quality and text-image alignment, providing scores and feedback for\npotential regeneration. T2I-Copilot can operate fully autonomously while also\nsupporting human-in-the-loop intervention for fine-grained control. On\nGenAI-Bench, using open-source generation models, T2I-Copilot achieves a VQA\nscore comparable to commercial models RecraftV3 and Imagen 3, surpasses\nFLUX1.1-pro by 6.17% at only 16.59% of its cost, and outperforms FLUX.1-dev and\nSD 3.5 Large by 9.11% and 6.36%. Code will be released at:\nhttps://github.com/SHI-Labs/T2I-Copilot.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.20536v2", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-29"}
{"id": "2507.19839", "title": "GNSP: Gradient Null Space Projection for Preserving Cross-Modal Alignment in VLMs Continual Learning", "authors": ["Tiantian Peng", "Yuyang Liu", "Shuo Yang", "Qiuhe Hong", "YongHong Tian"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19839v1", "summary": "Contrastive Language-Image Pretraining has demonstrated remarkable zero-shot\ngeneralization by aligning visual and textual modalities in a shared embedding\nspace. However, when continuously fine-tuned on diverse tasks, CLIP suffers\nfrom catastrophic forgetting and degradation of its embedding alignment,\nundermining its zero-shot capabilities. In this work, we propose Gradient Null\nSpace Projection (GNSP), an efficient continual learning method that projects\ntask-specific gradients onto the null space of previously learned knowledge.\nThis orthogonal projection mathematically prevents interference with previous\ntasks without relying on rehearsal or architectural modification. Furthermore,\nto preserve the inherent generalization property of CLIP, we introduce\nknowledge distillation and combine it with a modality alignment preservation\nloss inspired by CLIP pre-training to stabilize the structure of the multimodal\nembedding space during fine-tuning. On the MTIL benchmark consisting of 11\ntasks, our method achieved SOTA performance on both the Average and Last key\nmetrics. More importantly, experiments show that our method successfully\nmaintains the original modality gap and cross-modal retrieval performance of\nCLIP, confirming its effectiveness in maintaining a robust visual-language\nspace throughout the continual learning process.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19839v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2403.02661", "title": "How to Save My Gas Fees: Understanding and Detecting Real-world Gas Issues in Solidity Programs", "authors": ["Mengting He", "Shihao Xia", "Boqin Qin", "Nobuko Yoshida", "Tingting Yu", "Yiying Zhang", "Linhai Song"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.02661v2", "summary": "The execution of smart contracts on Ethereum, a public blockchain system,\nincurs a fee called gas fee for its computation and data storage. When\nprogrammers develop smart contracts (e.g., in the Solidity programming\nlanguage), they could unknowingly write code snippets that unnecessarily cause\nmore gas fees. These issues, or what we call gas wastes, can lead to\nsignificant monetary losses for users. This paper takes the initiative in\nhelping Ethereum users reduce their gas fees in two key steps. First, we\nconduct an empirical study on gas wastes in open-source Solidity programs and\nEthereum transaction traces. Second, to validate our study findings, we develop\na static tool called PeCatch to effectively detect gas wastes in Solidity\nprograms, and manually examine the Solidity compiler's code to pinpoint\nimplementation errors causing gas wastes. Overall, we make 11 insights and four\nsuggestions, which can foster future tool development and programmer awareness,\nand fixing our detected bugs can save $0.76 million in gas fees daily.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.02661v2", "cate": "cs.SE", "date": "2024-03-05", "updated": "2025-07-27"}
{"id": "2406.20019", "title": "Capacity Bounds for Broadcast Channels with Bidirectional Conferencing Decoders", "authors": ["Reza K. Farsani", "Wei Yu"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      20 pages, 4 figures, to appear in IEEE Transactions on Information Theory", "url": "http://arxiv.org/abs/2406.20019v3", "summary": "The two-user broadcast channel (BC) with receivers connected by bidirectional\ncooperation links of finite capacities, known as conferencing decoders, is\nconsidered. A novel capacity region outer bound is established based on\nmultiple applications of the Csisz\\'{a}r-K\\\"{o}rner identity. Achievable rate\nregions are derived by using Marton's coding as the transmission scheme,\ntogether with different combinations of decode-and-forward and\nquantize-bin-and-forward strategies at the receivers. It is shown that the\nouter bound coincides with the achievable rate region for a new class of\nsemi-deterministic BCs with degraded message sets; for this class of channels,\none-round cooperation is sufficient to achieve the capacity. Capacity result is\nalso derived for a class of more capable semi-deterministic BCs with both\ncommon and private messages and one-sided conferencing. For the Gaussian BC\nwith conferencing decoders, if the noises at the decoders are perfectly\ncorrelated (i.e., correlation is either 1 or -1), the new outer bound yields\nexact capacity region for two cases: i) BC with degraded message sets; ii) BC\nwith one-sided conferencing from the weaker receiver to the stronger receiver.\nWhen the noises have arbitrary correlation, the outer bound is shown to be\nwithin half a bit from the capacity region for these same two cases. Finally,\nfor the general Gaussian BC, a one-sided cooperation scheme based on\ndecode-and-forward from the stronger receiver to the weaker receiver is shown\nto achieve the capacity region to within $\\frac{1}{2}\\log\n(\\frac{2}{1-|\\lambda|})$ bits, where $\\lambda$ is the noise correlation. An\ninteresting implication of these results is that for a Gaussian BC with\nperfectly negatively correlated noises and conferencing decoders with finite\ncooperation link capacities, it is possible to achieve a strictly positive rate\nusing only an infinitesimal amount of transmit power.", "comment": "20 pages, 4 figures, to appear in IEEE Transactions on Information\n  Theory", "pdf_url": "http://arxiv.org/pdf/2406.20019v3", "cate": "cs.IT", "date": "2024-06-28", "updated": "2025-07-27"}
{"id": "2309.07859", "title": "Improved Distributed Algorithms for Random Colorings", "authors": ["Charlie Carlson", "Daniel Frishberg", "Eric Vigoda"], "categories": ["cs.DC", "cs.DM"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      25 pages, 2 figures", "url": "http://arxiv.org/abs/2309.07859v3", "summary": "We study distributed versions of Markov Chain Monte Carlo (MCMC) algorithms\nfor generating random $k$-colorings of an input graph with maximum degree\n$\\Delta$. In the sequential setting, the Glauber dynamics is the simple MCMC\nalgorithm which updates the color at a randomly chosen vertex in each step.\nFischer and Ghaffari (2018), and independently Feng, Hayes, and Yin (2018),\npresented a parallel and distributed version of the Glauber dynamics which\nconverges in $O(\\log{n})$ rounds for $k>(2+\\varepsilon)\\Delta$ for any\n$\\varepsilon>0$. We present the distributed flip dynamics and prove\n$O(n\\log{n})$ mixing for $k>(11/6-\\delta)\\Delta$ for a fixed $\\delta>0$. Our\nnew Markov chain is a generalization of the distributed Glauber dynamics\npreviously analyzed, and is a parallel and distributed version of the more\ngeneral flip dynamics considered in the sequential setting which recolors local\nmaximal two-colored components in each step. While the distributed Glauber\ndynamics and the sequential flip dynamics are symmetric Markov chains, and\nhence their stationary distribution is uniformly distributed over colorings,\nour distributed flip dynamics is not symmetric and hence the stationary\ndistribution is unclear.", "comment": "25 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2309.07859v3", "cate": "cs.DC", "date": "2023-09-14", "updated": "2025-07-25"}
{"id": "2507.20346", "title": "EyeAI: AI-Assisted Ocular Disease Detection for Equitable Healthcare Access", "authors": ["Shiv Garg", "Ginny Berkemeier"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20346v1", "summary": "Ocular disease affects billions of individuals unevenly worldwide. It\ncontinues to increase in prevalence with trends of growing populations of\ndiabetic people, increasing life expectancies, decreasing ophthalmologist\navailability, and rising costs of care. We present EyeAI, a system designed to\nprovide artificial intelligence-assisted detection of ocular diseases, thereby\nenhancing global health. EyeAI utilizes a convolutional neural network model\ntrained on 1,920 retinal fundus images to automatically diagnose the presence\nof ocular disease based on a retinal fundus image input through a publicly\naccessible web-based application. EyeAI performs a binary classification to\ndetermine the presence of any of 45 distinct ocular diseases, including\ndiabetic retinopathy, media haze, and optic disc cupping, with an accuracy of\n80%, an AUROC of 0.698, and an F1-score of 0.8876. EyeAI addresses barriers to\ntraditional ophthalmologic care by facilitating low-cost, remote, and real-time\ndiagnoses, particularly for equitable access to care in underserved areas and\nfor supporting physicians through a secondary diagnostic opinion. Results\ndemonstrate the potential of EyeAI as a scalable, efficient, and accessible\ndiagnostic tool. Future work will focus on expanding the training dataset to\nenhance the accuracy of the model further and improve its diagnostic\ncapabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20346v1", "cate": "cs.CY", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19531", "title": "A safety governor for learning explicit MPC controllers from data", "authors": ["Anjie Mao", "Zheming Wang", "Hao Gu", "Bo Chen", "Li Yu"], "categories": ["eess.SY", "cs.SY", "stat.ME"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19531v1", "summary": "We tackle neural networks (NNs) to approximate model predictive control (MPC)\nlaws. We propose a novel learning-based explicit MPC structure, which is\nreformulated into a dual-mode scheme over maximal constrained feasible set. The\nscheme ensuring the learning-based explicit MPC reduces to linear feedback\ncontrol while entering the neighborhood of origin. We construct a safety\ngovernor to ensure that learning-based explicit MPC satisfies all the state and\ninput constraints. Compare to the existing approach, our approach is\ncomputationally easier to implement even in high-dimensional system. The proof\nof recursive feasibility for the safety governor is given. Our approach is\ndemonstrated on numerical examples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19531v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.19546", "title": "Multipath Interference Suppression in Indirect Time-of-Flight Imaging via a Novel Compressed Sensing Framework", "authors": ["Yansong Du", "Yutong Deng", "Yuting Zhou", "Feiyu Jiao", "Bangyao Wang", "Zhancong Xu", "Zhaoxiang Jiang", "Xun Guan"], "categories": ["eess.SP", "cs.CV"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      15 pages, 10 figures", "url": "http://arxiv.org/abs/2507.19546v1", "summary": "We propose a novel compressed sensing method to improve the depth\nreconstruction accuracy and multi-target separation capability of indirect\nTime-of-Flight (iToF) systems. Unlike traditional approaches that rely on\nhardware modifications, complex modulation, or cumbersome data-driven\nreconstruction, our method operates with a single modulation frequency and\nconstructs the sensing matrix using multiple phase shifts and narrow-duty-cycle\ncontinuous waves. During matrix construction, we further account for pixel-wise\nrange variation caused by lens distortion, making the sensing matrix better\naligned with actual modulation response characteristics. To enhance sparse\nrecovery, we apply K-Means clustering to the distance response dictionary and\nconstrain atom selection within each cluster during the OMP process, which\neffectively reduces the search space and improves solution stability.\nExperimental results demonstrate that the proposed method outperforms\ntraditional approaches in both reconstruction accuracy and robustness, without\nrequiring any additional hardware changes.", "comment": "15 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.19546v1", "cate": "eess.SP", "date": "2025-07-24", "updated": "2025-07-24"}
{"id": "2306.08738", "title": "Investigation of the Challenges of Underwater-Visual-Monocular-SLAM", "authors": ["Michele Grimaldi", "David Nakath", "Mengkun She", "Kevin Köser"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2306.08738v2", "summary": "In this paper, we present a comprehensive investigation of the challenges of\nMonocular Visual Simultaneous Localization and Mapping (vSLAM) methods for\nunderwater robots. While significant progress has been made in state estimation\nmethods that utilize visual data in the past decade, most evaluations have been\nlimited to controlled indoor and urban environments, where impressive\nperformance was demonstrated. However, these techniques have not been\nextensively tested in extremely challenging conditions, such as underwater\nscenarios where factors such as water and light conditions, robot path, and\ndepth can greatly impact algorithm performance. Hence, our evaluation is\nconducted in real-world AUV scenarios as well as laboratory settings which\nprovide precise external reference. A focus is laid on understanding the impact\nof environmental conditions, such as optical properties of the water and\nillumination scenarios, on the performance of monocular vSLAM methods. To this\nend, we first show that all methods perform very well in in-air settings and\nsubsequently show the degradation of their performance in challenging\nunderwater environments. The final goal of this study is to identify techniques\nthat can improve accuracy and robustness of SLAM methods in such conditions. To\nachieve this goal, we investigate the potential of image enhancement techniques\nto improve the quality of input images used by the SLAM methods, specifically\nin low visibility and extreme lighting scenarios in scattering media. We\npresent a first evaluation on calibration maneuvers and simple image\nrestoration techniques to determine their ability to enable or enhance the\nperformance of monocular SLAM methods in underwater environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2306.08738v2", "cate": "cs.RO", "date": "2023-06-14", "updated": "2025-07-27"}
{"id": "2507.20774", "title": "evalSmarT: An LLM-Based Framework for Evaluating Smart Contract Generated Comments", "authors": ["Fatou Ndiaye Mbodji"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      4 pages, 4 tables", "url": "http://arxiv.org/abs/2507.20774v1", "summary": "Smart contract comment generation has gained traction as a means to improve\ncode comprehension and maintainability in blockchain systems. However,\nevaluating the quality of generated comments remains a challenge. Traditional\nmetrics such as BLEU and ROUGE fail to capture domain-specific nuances, while\nhuman evaluation is costly and unscalable. In this paper, we present\n\\texttt{evalSmarT}, a modular and extensible framework that leverages large\nlanguage models (LLMs) as evaluators. The system supports over 400 evaluator\nconfigurations by combining approximately 40 LLMs with 10 prompting strategies.\nWe demonstrate its application in benchmarking comment generation tools and\nselecting the most informative outputs. Our results show that prompt design\nsignificantly impacts alignment with human judgment, and that LLM-based\nevaluation offers a scalable and semantically rich alternative to existing\nmethods.", "comment": "4 pages, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.20774v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20632", "title": "Self-Supervised Continuous Colormap Recovery from a 2D Scalar Field Visualization without a Legend", "authors": ["Hongxu Liu", "Xinyu Chen", "Haoyang Zheng", "Manyi Li", "Zhenfan Liu", "Fumeng Yang", "Yunhai Wang", "Changhe Tu", "Qiong Zeng"], "categories": ["cs.CV", "cs.HC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE VIS 2025", "url": "http://arxiv.org/abs/2507.20632v1", "summary": "Recovering a continuous colormap from a single 2D scalar field visualization\ncan be quite challenging, especially in the absence of a corresponding color\nlegend. In this paper, we propose a novel colormap recovery approach that\nextracts the colormap from a color-encoded 2D scalar field visualization by\nsimultaneously predicting the colormap and underlying data using a\ndecoupling-and-reconstruction strategy. Our approach first separates the input\nvisualization into colormap and data using a decoupling module, then\nreconstructs the visualization with a differentiable color-mapping module. To\nguide this process, we design a reconstruction loss between the input and\nreconstructed visualizations, which serves both as a constraint to ensure\nstrong correlation between colormap and data during training, and as a\nself-supervised optimizer for fine-tuning the predicted colormap of unseen\nvisualizations during inferencing. To ensure smoothness and correct color\nordering in the extracted colormap, we introduce a compact colormap\nrepresentation using cubic B-spline curves and an associated color order loss.\nWe evaluate our method quantitatively and qualitatively on a synthetic dataset\nand a collection of real-world visualizations from the VIS30K dataset.\nAdditionally, we demonstrate its utility in two prototype applications --\ncolormap adjustment and colormap transfer -- and explore its generalization to\nvisualizations with color legends and ones encoded using discrete color\npalettes.", "comment": "Submitted to IEEE VIS 2025", "pdf_url": "http://arxiv.org/pdf/2507.20632v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19846", "title": "A Scalable and High Availability Solution for Recommending Resolutions to Problem Tickets", "authors": ["Harish Saragadam", "Chetana K Nayak", "Joy Bose"], "categories": ["cs.LG", "cs.IR", "68T50", "I.2.7; I.2.6; H.3.3; H.4.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 7 figures", "url": "http://arxiv.org/abs/2507.19846v2", "summary": "Resolution of incidents or problem tickets is a common theme in service\nindustries in any sector, including billing and charging systems in telecom\ndomain. Machine learning can help to identify patterns and suggest resolutions\nfor the problem tickets, based on patterns in the historical data of the\ntickets. However, this process may be complicated due to a variety of phenomena\nsuch as data drift and issues such as missing data, lack of data pertaining to\nresolutions of past incidents, too many similar sounding resolutions due to\nfree text and similar sounding text. This paper proposes a robust ML-driven\nsolution employing clustering, supervised learning, and advanced NLP models to\ntackle these challenges effectively. Building on previous work, we demonstrate\nclustering-based resolution identification, supervised classification with LDA,\nSiamese networks, and One-shot learning, Index embedding. Additionally, we\npresent a real-time dashboard and a highly available Kubernetes-based\nproduction deployment. Our experiments with both the open-source Bitext\ncustomer-support dataset and proprietary telecom datasets demonstrate high\nprediction accuracy.", "comment": "9 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.19846v2", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-29"}
{"id": "2405.04861", "title": "Refactoring Deep Learning Code: A Study of Practices and Unsatisfied Tool Needs", "authors": ["SiQi Wang", "Xing Hu", "Bei Wang", "WenXin Yao", "Xin Xia", "XingYu Wang"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      12 pages, 6 figures", "url": "http://arxiv.org/abs/2405.04861v2", "summary": "With the rapid development of deep learning, the implementation of intricate\nalgorithms and substantial data processing have become standard elements of\ndeep learning projects. As a result, the code has become progressively complex\nas the software evolves, which is difficult to maintain and understand.\nExisting studies have investigated the impact of refactoring on software\nquality within traditional software. However, the insight of code refactoring\nin the context of deep learning is still unclear. This study endeavors to fill\nthis knowledge gap by empirically examining the current state of code\nrefactoring in deep learning realm, and practitioners' views on refactoring. We\nfirst manually analyzed the commit history of five popular and well-maintained\ndeep learning projects (e.g., PyTorch). We mined 4,921 refactoring practices in\nhistorical commits and measured how different types and elements of refactoring\noperations are distributed and found that refactoring operation types'\ndistribution in deep learning projects is different from it in traditional Java\nsoftware. We then surveyed 159 practitioners about their views of code\nrefactoring in deep learning projects and their expectations of current\nrefactoring tools. The result of the survey showed that refactoring research\nand the development of related tools in the field of deep learning are crucial\nfor improving project maintainability and code quality, and that current\nrefactoring tools do not adequately meet the needs of practitioners. Lastly, we\nprovided our perspective on the future advancement of refactoring tools and\noffered suggestions for developers' development practices.", "comment": "12 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2405.04861v2", "cate": "cs.SE", "date": "2024-05-08", "updated": "2025-07-28"}
{"id": "2407.06868", "title": "DRL-AdaPart: DRL-Driven Adaptive STAR-RIS Partitioning for Fair and Frugal Resource Utilization", "authors": ["Ashok S. Kumar", "Nancy Nayak", "Sheetal Kalyani", "Himal A. Suraweera"], "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.06868v2", "summary": "In this work, we propose a method for efficient resource utilization of\nsimultaneously transmitting and reflecting reconfigurable intelligent surface\n(STAR-RIS) elements to ensure fair and high data rates. We introduce a\nsubsurface assignment variable that determines the number of STAR-RIS elements\nallocated to each user and maximizes the sum of the data rates by jointly\noptimizing the phase shifts of the STAR-RIS and the subsurface assignment\nvariables using an appropriately tailored deep reinforcement learning (DRL)\nalgorithm. The proposed DRL method is also compared with a Dinkelbach algorithm\nand the designed hybrid DRL approach. A penalty term is incorporated into the\nDRL model to enhance resource utilization by intelligently deactivating\nSTAR-RIS elements when not required. The proposed DRL method can achieve fair\nand high data rates for static and mobile users while ensuring efficient\nresource utilization through extensive simulations. Using the proposed DRL\nmethod, up to 27% and 21% of STAR-RIS elements can be deactivated in static and\nmobile scenarios, respectively, without affecting performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.06868v2", "cate": "cs.IT", "date": "2024-07-09", "updated": "2025-07-26"}
{"id": "2407.08584", "title": "Data-Locality-Aware Task Assignment and Scheduling for Distributed Job Executions", "authors": ["Hailiang Zhao", "Xueyan Tang", "Peng Chen", "Jianwei Yin", "Shuiguang Deng"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.08584v4", "summary": "This paper addresses the data-locality-aware task assignment and scheduling\nproblem for distributed job executions. Our goal is to minimize job completion\ntimes without prior knowledge of future job arrivals. We propose an Optimal\nBalanced Task Assignment algorithm (OBTA), which achieves minimal job\ncompletion times while significantly reducing computational overhead through\nefficient narrowing of the solution search space. To balance performance and\nefficiency, we extend the approximate Water-Filling (WF) algorithm, providing a\nrigorous proof that its approximation factor equals the number of task groups\nin a job. We also introduce a novel heuristic, Replica-Deletion (RD), which\noutperforms WF by leveraging global optimization techniques. To further enhance\nscheduling efficiency, we incorporate job ordering strategies based on a\nshortest-estimated-time-first policy, reducing average job completion times\nacross workloads. Extensive trace-driven evaluations validate the effectiveness\nand scalability of the proposed algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.08584v4", "cate": "cs.DC", "date": "2024-07-11", "updated": "2025-07-27"}
{"id": "2507.20525", "title": "The Xeno Sutra: Can Meaning and Value be Ascribed to an AI-Generated \"Sacred\" Text?", "authors": ["Murray Shanahan", "Tara Das", "Robert Thurman"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20525v2", "summary": "This paper presents a case study in the use of a large language model to\ngenerate a fictional Buddhist \"sutra\"', and offers a detailed analysis of the\nresulting text from a philosophical and literary point of view. The conceptual\nsubtlety, rich imagery, and density of allusion found in the text make it hard\nto causally dismiss on account of its mechanistic origin. This raises questions\nabout how we, as a society, should come to terms with the potentially\nunsettling possibility of a technology that encroaches on human meaning-making.\nWe suggest that Buddhist philosophy, by its very nature, is well placed to\nadapt.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20525v2", "cate": "cs.CY", "date": "2025-07-28", "updated": "2025-07-29"}
{"id": "2507.19532", "title": "Whale Optimization Algorithms based fractional order fuzzy PID controller for Depth of Anesthesia", "authors": ["Amin Behboudifar", "Chen Jing"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19532v1", "summary": "One of the most important surgical factors is Depth of Anesthesia (DOA)\ncontrol in patients. The main problem is to overcome the uncertainty and\nnonlinearity of the system, due to different physiological parameters of the\npatient's body and maintain DOA of patients in desired range during surgery.\nThis study demonstrates a fractional order fuzzy PID controller (FOFPID) and\nfractional order PID controller (FOPID) to the problem. The Whale Optimization\nAlgorithms (WOA) is used to optimized the parameters of proposed controllers.\nThe orders of derivative and integral fractional controller is achieved by WOA.\nThe results indicate that FOFPID has a better performance than FOPID. To check\nthe performance of the controllers in presence of uncertainty, physiological\nlogical model of 8 patients has been investigated. The modeling is based on\nPharmacodynamic and Pharmacokinetic model. The results show the performance of\nthe proposed method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19532v1", "cate": "eess.SY", "date": "2025-07-21", "updated": "2025-07-21"}
{"id": "2507.19763", "title": "Coverage Probability and Average Rate Analysis of Hybrid Cellular and Cell-free Network", "authors": ["Zhuoyin Dai", "Jingran Xu", "Xiaoli Xu", "Ruoguang Li", "Yong Zeng", "Jiangbin Lyu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19763v1", "summary": "Cell-free wireless networks deploy distributed access points (APs) to\nsimultaneously serve user equipments (UEs) across the service region and are\nregarded as one of the most promising network architectural paradigms. Despite\nrecent advances in the performance analysis and optimization of cellfree\nwireless networks, it remains an open question whether large-scale deployment\nof APs in existing wireless networks can cost-effectively achieve communication\ncapacity growth. Besides, the realization of a cell-free network is considered\nto be a gradual long-term evolutionary process in which cell-free APs will be\nincrementally introduced into existing cellular networks, and form a hybrid\ncommunication network with the existing cellular base stations (BSs). Such a\ncollaboration will bridge the gap between the established cellular network and\nthe innovative cellfree network. Therefore, hybrid cellular and cell-free\nnetworks (HCCNs) emerge as a practical and feasible solution for advancing\ncell-free network development, and it is worthwhile to further explore its\nperformance limits. This paper presents a stochastic geometry-based hybrid\ncellular and cell-free network model to analyze the distributions of signal and\ninterference and reveal their mutual coupling. Specifically, in order to\nbenefit the UEs from both the cellular BSs and the cell-free APs, a conjugate\nbeamforming design is employed, and the aggregated signal is analyzed using\nmoment matching. Then, the coverage probability of the hybrid network is\ncharacterized by deriving the Laplace transforms and their higher-order\nderivatives of interference components. Furthermore, the average achievable\nrate of the hybrid network over channel fading is derived based on the\ninterference coupling analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19763v1", "cate": "eess.SP", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2404.16705", "title": "SHINE: Social Homology Identification for Navigation in Crowded Environments", "authors": ["Diego Martinez-Baselga", "Oscar de Groot", "Luzia Knoedler", "Luis Riazuelo", "Javier Alonso-Mora", "Luis Montano"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This paper has been accepted for publication at The International Journal of Robotics Research. Please, when citing the paper, refer to the official manuscript with the following DOI: https://doi.org/10.1177/02783649251344639", "url": "http://arxiv.org/abs/2404.16705v2", "summary": "Navigating mobile robots in social environments remains a challenging task\ndue to the intricacies of human-robot interactions. Most of the motion planners\ndesigned for crowded and dynamic environments focus on choosing the best\nvelocity to reach the goal while avoiding collisions, but do not explicitly\nconsider the high-level navigation behavior (avoiding through the left or right\nside, letting others pass or passing before others, etc.). In this work, we\npresent a novel motion planner that incorporates topology distinct paths\nrepresenting diverse navigation strategies around humans. The planner selects\nthe topology class that imitates human behavior the best using a deep neural\nnetwork model trained on real-world human motion data, ensuring socially\nintelligent and contextually aware navigation. Our system refines the chosen\npath through an optimization-based local planner in real time, ensuring\nseamless adherence to desired social behaviors. In this way, we decouple\nperception and local planning from the decision-making process. We evaluate the\nprediction accuracy of the network with real-world data. In addition, we assess\nthe navigation capabilities in both simulation and a real-world platform,\ncomparing it with other state-of-the-art planners. We demonstrate that our\nplanner exhibits socially desirable behaviors and shows a smooth and remarkable\nperformance.", "comment": "This paper has been accepted for publication at The International\n  Journal of Robotics Research. Please, when citing the paper, refer to the\n  official manuscript with the following DOI: 10.1177/02783649251344639", "pdf_url": "http://arxiv.org/pdf/2404.16705v2", "cate": "cs.RO", "date": "2024-04-25", "updated": "2025-07-28"}
{"id": "2507.20804", "title": "MMGraphRAG: Bridging Vision and Language with Interpretable Multimodal Knowledge Graphs", "authors": ["Xueyao Wan", "Hang Yu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20804v1", "summary": "Retrieval-Augmented Generation (RAG) enhances language model generation by\nretrieving relevant information from external knowledge bases. However,\nconventional RAG methods face the issue of missing multimodal information.\nMultimodal RAG methods address this by fusing images and text through mapping\nthem into a shared embedding space, but they fail to capture the structure of\nknowledge and logical chains between modalities. Moreover, they also require\nlarge-scale training for specific tasks, resulting in limited generalizing\nability. To address these limitations, we propose MMGraphRAG, which refines\nvisual content through scene graphs and constructs a multimodal knowledge graph\n(MMKG) in conjunction with text-based KG. It employs spectral clustering to\nachieve cross-modal entity linking and retrieves context along reasoning paths\nto guide the generative process. Experimental results show that MMGraphRAG\nachieves state-of-the-art performance on the DocBench and MMLongBench datasets,\ndemonstrating strong domain adaptability and clear reasoning paths.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20804v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20737", "title": "Multi-Masked Querying Network for Robust Emotion Recognition from Incomplete Multi-Modal Physiological Signals", "authors": ["Geng-Xin Xu", "Xiang Zuo", "Ye Li"], "categories": ["cs.CV", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      MICCAI2025", "url": "http://arxiv.org/abs/2507.20737v1", "summary": "Emotion recognition from physiological data is crucial for mental health\nassessment, yet it faces two significant challenges: incomplete multi-modal\nsignals and interference from body movements and artifacts. This paper presents\na novel Multi-Masked Querying Network (MMQ-Net) to address these issues by\nintegrating multiple querying mechanisms into a unified framework.\nSpecifically, it uses modality queries to reconstruct missing data from\nincomplete signals, category queries to focus on emotional state features, and\ninterference queries to separate relevant information from noise. Extensive\nexperiment results demonstrate the superior emotion recognition performance of\nMMQ-Net compared to existing approaches, particularly under high levels of data\nincompleteness.", "comment": "MICCAI2025", "pdf_url": "http://arxiv.org/pdf/2507.20737v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19849", "title": "Agentic Reinforced Policy Optimization", "authors": ["Guanting Dong", "Hangyu Mao", "Kai Ma", "Licheng Bao", "Yifei Chen", "Zhongyuan Wang", "Zhongxia Chen", "Jiazhen Du", "Huiyang Wang", "Fuzheng Zhang", "Guorui Zhou", "Yutao Zhu", "Ji-Rong Wen", "Zhicheng Dou"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Working on progress", "url": "http://arxiv.org/abs/2507.19849v1", "summary": "Large-scale reinforcement learning with verifiable rewards (RLVR) has\ndemonstrated its effectiveness in harnessing the potential of large language\nmodels (LLMs) for single-turn reasoning tasks. In realistic reasoning\nscenarios, LLMs can often utilize external tools to assist in task-solving\nprocesses. However, current RL algorithms inadequately balance the models'\nintrinsic long-horizon reasoning capabilities and their proficiency in\nmulti-turn tool interactions. To bridge this gap, we propose Agentic Reinforced\nPolicy Optimization (ARPO), a novel agentic RL algorithm tailored for training\nmulti-turn LLM-based agents. Through preliminary experiments, we observe that\nLLMs tend to exhibit highly uncertain behavior, characterized by an increase in\nthe entropy distribution of generated tokens, immediately following\ninteractions with external tools. Motivated by this observation, ARPO\nincorporates an entropy-based adaptive rollout mechanism, dynamically balancing\nglobal trajectory sampling and step-level sampling, thereby promoting\nexploration at steps with high uncertainty after tool usage. By integrating an\nadvantage attribution estimation, ARPO enables LLMs to internalize advantage\ndifferences in stepwise tool-use interactions. Our experiments across 13\nchallenging benchmarks in computational reasoning, knowledge reasoning, and\ndeep search domains demonstrate ARPO's superiority over trajectory-level RL\nalgorithms. Remarkably, ARPO achieves improved performance using only half of\nthe tool-use budget required by existing methods, offering a scalable solution\nfor aligning LLM-based agents with real-time dynamic environments. Our code and\ndatasets are released at https://github.com/dongguanting/ARPO", "comment": "Working on progress", "pdf_url": "http://arxiv.org/pdf/2507.19849v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2411.19804", "title": "Advanced System Integration: Analyzing OpenAPI Chunking for Retrieval-Augmented Generation", "authors": ["Robin D. Pesl", "Jerin G. Mathew", "Massimo Mecella", "Marco Aiello"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      This preprint has not undergone peer review (when applicable) or any post-submission improvements or corrections. The Version of Record of this contribution is published in Advanced Information Systems Engineering. CAiSE 2025. Lecture Notes in Computer Science, vol 15702. Springer, Cham., and is available online at this https URL", "url": "http://arxiv.org/abs/2411.19804v2", "summary": "Integrating multiple (sub-)systems is essential to create advanced\nInformation Systems (ISs). Difficulties mainly arise when integrating dynamic\nenvironments across the IS lifecycle. A traditional approach is a registry that\nprovides the API documentation of the systems' endpoints. Large Language Models\n(LLMs) have shown to be capable of automatically creating system integrations\n(e.g., as service composition) based on this documentation but require concise\ninput due to input token limitations, especially regarding comprehensive API\ndescriptions. Currently, it is unknown how best to preprocess these API\ndescriptions. Within this work, we (i) analyze the usage of Retrieval Augmented\nGeneration (RAG) for endpoint discovery and the chunking, i.e., preprocessing,\nof OpenAPIs to reduce the input token length while preserving the most relevant\ninformation. To further reduce the input token length for the composition\nprompt and improve endpoint retrieval, we propose (ii) a Discovery Agent that\nonly receives a summary of the most relevant endpoints and retrieves details on\ndemand. We evaluate RAG for endpoint discovery using the RestBench benchmark,\nfirst, for the different chunking possibilities and parameters measuring the\nendpoint retrieval recall, precision, and F1 score. Then, we assess the\nDiscovery Agent using the same test set. With our prototype, we demonstrate how\nto successfully employ RAG for endpoint discovery to reduce the token count.\nWhile revealing high values for recall, precision, and F1, further research is\nnecessary to retrieve all requisite endpoints. Our experiments show that for\npreprocessing, LLM-based and format-specific approaches outperform na\\\"ive\nchunking methods. Relying on an agent further enhances these results as the\nagent splits the tasks into multiple fine granular subtasks, improving the\noverall RAG performance in the token count, precision, and F1 score.", "comment": "This preprint has not undergone peer review (when applicable) or any\n  post-submission improvements or corrections. The Version of Record of this\n  contribution is published in Advanced Information Systems Engineering. CAiSE\n  2025. Lecture Notes in Computer Science, vol 15702. Springer, Cham., and is\n  available online at https://doi.org/10.1007/978-3-031-94571-7_8", "pdf_url": "http://arxiv.org/pdf/2411.19804v2", "cate": "cs.SE", "date": "2024-11-29", "updated": "2025-07-28"}
{"id": "2408.01885", "title": "Channel-Aware Distributed Transmission Control and Video Streaming in UAV Networks", "authors": ["Masoud Ghazikor", "Keenan Roach", "Kenny Cheung", "Morteza Hashemi"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Under Revision in IEEE Transactions on Communications", "url": "http://arxiv.org/abs/2408.01885v2", "summary": "In this paper, we study the problem of distributed transmission control and\nvideo streaming optimization for UAVs operating in unlicensed spectrum bands.\nWe develop a rigorous cross-layer analysis framework that jointly considers\nthree inter-dependent factors: (i) in-band interference introduced by\nground-aerial nodes at the physical layer, (ii) limited-size queues with\ndelay-constrained packet arrival at the MAC layer, and (iii) video encoding\nrate at the application layer. First, we formulate an optimization problem to\nmaximize the average throughput by optimizing the fading threshold. To this\nend, we jointly analyze the queue-related packet loss probabilities as well as\nthe outage probability due to the low SINR. We introduce the DTC algorithm that\nmaximizes the average throughput by adjusting transmission policies to balance\nthe trade-offs between packet drop from queues vs. transmission errors due to\nlow SINRs. Second, we incorporate the video distortion model to develop\ndistributed PSNR optimization for video streaming. The formulated optimization\nincorporates two cross-layer parameters, specifically the fading threshold and\nvideo encoding rate. To tackle this problem, we develop the JDVT-EC algorithm\nthat enhances the average PSNR for all nodes by fine-tuning transmission\npolicies and video encoding rates to balance the trade-offs between packet loss\nand lossy video compression distortions. Through extensive numerical analysis,\nwe thoroughly examine the proposed algorithms and demonstrate that they are\nable to find the optimal transmission policies and video encoding rates under\nvarious scenarios. Notably, our approach improves the average throughput by\n1.7% to 51.65% compared to various baselines. Additionally, we demonstrate an\naverage PSNR increase of 0.24 dB and 1.7 dB compared to separately optimizing\nthe fading threshold and video encoding rate, respectively.", "comment": "Under Revision in IEEE Transactions on Communications", "pdf_url": "http://arxiv.org/pdf/2408.01885v2", "cate": "cs.IT", "date": "2024-08-03", "updated": "2025-07-25"}
{"id": "2501.03547", "title": "Metric Criticality Identification for Cloud Microservices", "authors": ["Akanksha Singal", "Divya Pathak", "Kaustabha Ray", "Felix George", "Mudit Verma", "Pratibha Moogi"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.03547v2", "summary": "Modern cloud-native applications built on microservice architectures present\nunprecedented challenges for system monitoring and alerting. Site Reliability\nEngineers (SREs) face the daunting challenge of defining effective monitoring\nstrategies across multitude of metrics to ensure system reliability, a task\nthat traditionally requires extensive manual expertise. The distributed nature\nof microservices, characterized by stochastic execution patterns and intricate\ninter-service dependencies, renders the traditional manual approach of\nnavigating the vast metrics landscape computationally and operationally\nprohibitive. To address this critical challenge, we propose KIMetrix, a\ndata-driven system that automatically identifies minimal yet comprehensive\nmetric subsets to aid SREs in monitoring microservice applications. KIMetrix\nleverages information-theoretic measures, specifically entropy and mutual\ninformation, to quantify metric criticality while considering the stochastic\nexecution patterns inherent in microservice topologies. Our approach operates\nsolely on lightweight metrics and traces, eliminating the need for expensive\nprocessing of unstructured logs, and requires no expert-defined training data.\nExperimental evaluation on state-of-the-art real-world microservice benchmark\ndatasets demonstrates KIMetrix's effectiveness in identifying critical metric\nsubsets that provide comprehensive system coverage while significantly reducing\nthe burden on SREs. By automating the identification of essential metrics for\nalerting, KIMetrix enables more reliable system monitoring without overwhelming\noperators with false positives or missing critical system events.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.03547v2", "cate": "cs.DC", "date": "2025-01-07", "updated": "2025-07-28"}
{"id": "2507.20995", "title": "VArsity: Can Large Language Models Keep Power Engineering Students in Phase?", "authors": ["Samuel Talkington", "Daniel K. Molzahn"], "categories": ["cs.CY", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      9 pages, 4 figures", "url": "http://arxiv.org/abs/2507.20995v1", "summary": "This paper provides an educational case study regarding our experience in\ndeploying ChatGPT Large Language Models (LLMs) in the Spring 2025 and Fall 2023\nofferings of ECE 4320: Power System Analysis and Control at Georgia Tech. As\npart of course assessments, students were tasked with identifying, explaining,\nand correcting errors in the ChatGPT outputs corresponding to power factor\ncorrection problems. While most students successfully identified the errors in\nthe outputs from the GPT-4 version of ChatGPT used in Fall 2023, students found\nthe errors from the ChatGPT o1 version much more difficult to identify in\nSpring 2025. As shown in this case study, the role of LLMs in pedagogy,\nassessment, and learning in power engineering classrooms is an important topic\ndeserving further investigation.", "comment": "9 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.20995v1", "cate": "cs.CY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19535", "title": "Comparing Behavioural Cloning and Reinforcement Learning for Spacecraft Guidance and Control Networks", "authors": ["Harry Holt", "Sebastien Origer", "Dario Izzo"], "categories": ["eess.SY", "astro-ph.EP", "astro-ph.IM", "cs.LG", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19535v1", "summary": "Guidance & control networks (G&CNETs) provide a promising alternative to\non-board guidance and control (G&C) architectures for spacecraft, offering a\ndifferentiable, end-to-end representation of the guidance and control\narchitecture. When training G&CNETs, two predominant paradigms emerge:\nbehavioural cloning (BC), which mimics optimal trajectories, and reinforcement\nlearning (RL), which learns optimal behaviour through trials and errors.\nAlthough both approaches have been adopted in G&CNET related literature, direct\ncomparisons are notably absent. To address this, we conduct a systematic\nevaluation of BC and RL specifically for training G&CNETs on continuous-thrust\nspacecraft trajectory optimisation tasks. We introduce a novel RL training\nframework tailored to G&CNETs, incorporating decoupled action and control\nfrequencies alongside reward redistribution strategies to stabilise training\nand to provide a fair comparison. Our results show that BC-trained G&CNETs\nexcel at closely replicating expert policy behaviour, and thus the optimal\ncontrol structure of a deterministic environment, but can be negatively\nconstrained by the quality and coverage of the training dataset. In contrast\nRL-trained G&CNETs, beyond demonstrating a superior adaptability to stochastic\nconditions, can also discover solutions that improve upon suboptimal expert\ndemonstrations, sometimes revealing globally optimal strategies that eluded the\ngeneration of training samples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19535v1", "cate": "eess.SY", "date": "2025-07-22", "updated": "2025-07-22"}
{"id": "2507.19785", "title": "Radar and Acoustic Sensor Fusion using a Transformer Encoder for Robust Drone Detection and Classification", "authors": ["Gevindu Ganganath", "Pasindu Sankalpa", "Samal Punsara", "Demitha Pasindu", "Chamira U. S. Edussooriya", "Ranga Rodrigo", "Udaya S. K. P. Miriya Thanthrige"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE Sensors Letters", "url": "http://arxiv.org/abs/2507.19785v1", "summary": "The use of drones in a wide range of applications is steadily increasing.\nHowever, this has also raised critical security concerns such as unauthorized\ndrone intrusions into restricted zones. Therefore, robust and accurate drone\ndetection and classification mechanisms are required despite significant\nchallenges due to small size of drones, low-altitude flight, and environmental\nnoise. In this letter, we propose a multi-modal approach combining radar and\nacoustic sensing for detecting and classifying drones. We employ radar due to\nits long-range capabilities, and robustness to different weather conditions. We\nutilize raw acoustic signals without converting them to other domains such as\nspectrograms or Mel-frequency cepstral coefficients. This enables us to use\nfewer number of parameters compared to the stateof-the-art approaches.\nFurthermore, we explore the effectiveness of the transformer encoder\narchitecture in fusing these sensors. Experimental results obtained in outdoor\nsettings verify the superior performance of the proposed approach compared to\nthe state-of-the-art methods.", "comment": "Submitted to IEEE Sensors Letters", "pdf_url": "http://arxiv.org/pdf/2507.19785v1", "cate": "eess.SP", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2408.00275", "title": "RESC: A Reinforcement Learning Based Search-to-Control Framework for Quadrotor Local Planning in Dense Environments", "authors": ["Zhaohong Liu", "Wenxuan Gao", "Yinshuai Sun", "Peng Dong"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This paper has been accepted for publication in IEEE Robotics and Automation Letters (RAL), 2025. The final authenticated version is available online at IEEE Xplore", "url": "http://arxiv.org/abs/2408.00275v5", "summary": "Agile flight in complex environments poses significant challenges to current\nmotion planning methods, as they often fail to fully leverage the quadrotor\ndynamic potential, leading to performance failures and reduced efficiency\nduring aggressive maneuvers.Existing approaches frequently decouple trajectory\noptimization from control generation and neglect the dynamics, further limiting\ntheir ability to generate aggressive and feasible motions.To address these\nchallenges, we introduce an enhanced Search-to-Control planning framework that\nintegrates visibility path searching with reinforcement learning (RL) control\ngeneration, directly accounting for dynamics and bridging the gap between\nplanning and control.Our method first extracts control points from\ncollision-free paths using a proposed heuristic search, which are then refined\nby an RL policy to generate low-level control commands for the quadrotor\ncontroller, utilizing reduced-dimensional obstacle observations for efficient\ninference with lightweight neural networks.We validate the framework through\nsimulations and real-world experiments, demonstrating improved time efficiency\nand dynamic maneuverability compared to existing methods, while confirming its\nrobustness and applicability.", "comment": "This paper has been accepted for publication in IEEE Robotics and\n  Automation Letters (RAL), 2025. The final authenticated version is available\n  online at IEEE Xplore", "pdf_url": "http://arxiv.org/pdf/2408.00275v5", "cate": "cs.RO", "date": "2024-08-01", "updated": "2025-07-28"}
{"id": "2507.20960", "title": "On the Limits of Hierarchically Embedded Logic in Classical Neural Networks", "authors": ["Bill Cochran"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      9 pages", "url": "http://arxiv.org/abs/2507.20960v1", "summary": "We propose a formal model of reasoning limitations in large neural net models\nfor language, grounded in the depth of their neural architecture. By treating\nneural networks as linear operators over logic predicate space we show that\neach layer can encode at most one additional level of logical reasoning. We\nprove that a neural network of depth a particular depth cannot faithfully\nrepresent predicates in a one higher order logic, such as simple counting over\ncomplex predicates, implying a strict upper bound on logical expressiveness.\nThis structure induces a nontrivial null space during tokenization and\nembedding, excluding higher-order predicates from representability. Our\nframework offers a natural explanation for phenomena such as hallucination,\nrepetition, and limited planning, while also providing a foundation for\nunderstanding how approximations to higher-order logic may emerge. These\nresults motivate architectural extensions and interpretability strategies in\nfuture development of language models.", "comment": "9 pages", "pdf_url": "http://arxiv.org/pdf/2507.20960v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2412.06336", "title": "A Combined Channel Approach for Decoding Intracranial EEG Signals: Enhancing Accuracy through Spatial Information Integration", "authors": ["Maryam Ostadsharif Memar", "Navid Ziaei", "Behzad Nazari"], "categories": ["cs.HC", "eess.SP"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.06336v2", "summary": "Intracranial EEG (iEEG) recording, characterized by high spatial and temporal\nresolution and superior signal-to-noise ratio (SNR), enables the development of\nprecise brain-computer interface (BCI) systems for neural decoding. However,\nthe invasive nature of the procedure significantly limits the availability of\niEEG datasets in terms of both the number of participants and the duration of\nrecorded sessions. To address this limitation, we propose a single-participant\nmachine learning model optimized for decoding iEEG signals. The model employs\n18 key features and operates in two modes: best channel and combined channel.\nThe combined channel mode integrates spatial information from multiple brain\nregions, leading to superior classification performance. Evaluations across\nthree datasets -- Music Reconstruction, Audio Visual, and AJILE12 --\ndemonstrate that the combined channel mode consistently outperforms the best\nchannel mode across all classifiers. In the best-performing cases, Random\nForest achieved an F1 score of 0.81 +/- 0.05 in the Music Reconstruction\ndataset and 0.82 +/- 0.10 in the Audio Visual dataset, while XGBoost achieved\nan F1 score of 0.84 +/- 0.08 in the AJILE12 dataset. Furthermore, the analysis\nof brain region contributions in the combined channel mode revealed that the\nmodel identifies relevant brain regions aligned with physiological expectations\nfor each task and effectively combines data from electrodes in these regions to\nachieve high performance. These findings highlight the potential of integrating\nspatial information across brain regions to improve task decoding, offering new\navenues for advancing BCI systems and neurotechnological applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.06336v2", "cate": "cs.HC", "date": "2024-12-09", "updated": "2025-07-26"}
{"id": "2507.19873", "title": "RestoreAI -- Pattern-based Risk Estimation Of Remaining Explosives", "authors": ["Björn Kischelewski", "Benjamin Guedj", "David Wahl"], "categories": ["cs.LG", "cs.CY", "stat.AP", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19873v1", "summary": "Landmine removal is a slow, resource-intensive process affecting over 60\ncountries. While AI has been proposed to enhance explosive ordnance (EO)\ndetection, existing methods primarily focus on object recognition, with limited\nattention to prediction of landmine risk based on spatial pattern information.\nThis work aims to answer the following research question: How can AI be used to\npredict landmine risk from landmine patterns to improve clearance time\nefficiency? To that effect, we introduce RestoreAI, an AI system for\npattern-based risk estimation of remaining explosives. RestoreAI is the first\nAI system that leverages landmine patterns for risk prediction, improving the\naccuracy of estimating the residual risk of missing EO prior to land release.\nWe particularly focus on the implementation of three instances of RestoreAI,\nrespectively, linear, curved and Bayesian pattern deminers. First, the linear\npattern deminer uses linear landmine patterns from a principal component\nanalysis (PCA) for the landmine risk prediction. Second, the curved pattern\ndeminer uses curved landmine patterns from principal curves. Finally, the\nBayesian pattern deminer incorporates prior expert knowledge by using a\nBayesian pattern risk prediction. Evaluated on real-world landmine data,\nRestoreAI significantly boosts clearance efficiency. The top-performing\npattern-based deminers achieved a 14.37 percentage point increase in the\naverage share of cleared landmines per timestep and required 24.45% less time\nthan the best baseline deminer to locate all landmines. Interestingly, linear\nand curved pattern deminers showed no significant performance difference,\nsuggesting that more efficient linear patterns are a viable option for risk\nprediction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19873v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2502.18828", "title": "Adaptive and Accessible User Interfaces for Seniors Through Model-Driven Engineering", "authors": ["Shavindra Wickramathilaka", "John Grundy", "Kashumi Madampe", "Omar Haggag"], "categories": ["cs.SE", "cs.HC"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      This paper has been accepted in the Automated Software Engineering Journal (ASEJ)", "url": "http://arxiv.org/abs/2502.18828v2", "summary": "The use of diverse mobile applications among senior users is becoming\nincreasingly widespread. However, many of these apps contain accessibility\nproblems that result in negative user experiences for seniors. A key reason is\nthat software practitioners often lack the time or resources to address the\nbroad spectrum of age-related accessibility and personalisation needs. As\ncurrent developer tools and practices encourage one-size-fits-all interfaces\nwith limited potential to address the diversity of senior needs, there is a\ngrowing demand for approaches that support the systematic creation of adaptive,\naccessible app experiences. To this end, we present AdaptForge, a novel\nmodel-driven engineering (MDE) approach that enables advanced design-time\nadaptations of mobile application interfaces and behaviours tailored to the\naccessibility needs of senior users. AdaptForge uses two domain-specific\nlanguages (DSLs) to address age-related accessibility needs. The first model\ndefines users' context-of-use parameters, while the second defines conditional\naccessibility scenarios and corresponding UI adaptation rules. These rules are\ninterpreted by an MDE workflow to transform an app's original source code into\npersonalised instances. We also report evaluations with professional software\ndevelopers and senior end-users, demonstrating the feasibility and practical\nutility of AdaptForge.", "comment": "This paper has been accepted in the Automated Software Engineering\n  Journal (ASEJ)", "pdf_url": "http://arxiv.org/pdf/2502.18828v2", "cate": "cs.SE", "date": "2025-02-26", "updated": "2025-07-28"}
{"id": "2502.02389", "title": "Rate-reliability tradeoff for deterministic identification", "authors": ["Pau Colomer", "Christian Deppe", "Holger Boche", "Andreas Winter"], "categories": ["cs.IT", "math.IT", "quant-ph"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      16 pages, 2 figures. This paper has been accepted for publication at IEEE Transactions on Communications. A preliminary version of the present work was presented at the 2025 IEEE International Conference on Communications, Montreal QB, 8-12 June 2025", "url": "http://arxiv.org/abs/2502.02389v4", "summary": "We investigate deterministic identification over arbitrary memoryless\nchannels under the constraint that the error probabilities of first and second\nkind are exponentially small in the block length $\\mathbf{n}$, controlled by\nreliability exponents $\\mathbf{E_1,E_2 \\geq 0}$. In contrast to the regime of\nslowly vanishing errors, where the identifiable message length scales\nlinearithmically as $\\mathbf{\\Theta(n\\log n)}$, here we find that for positive\nexponents linear scaling is restored, now with a rate that is a function of the\nreliability exponents. We give upper and lower bounds on the ensuing\nrate-reliability function in terms of (the logarithm of) the packing and\ncovering numbers of the channel output set, which for small error exponents\n$\\mathbf{E_1,E_2>0}$ can be expanded in leading order as the product of the\nMinkowski dimension of a certain parametrisation the channel output set and\n$\\mathbf{\\log\\min\\{E_1,E_2\\}}$. These allow us to recover the previously\nobserved slightly superlinear identification rates, and offer a different\nperspective for understanding them in more traditional information theory\nterms. We also show that even if only one of the two errors is required to be\nexponentially small, the linearithmic scaling is lost. We further illustrate\nour results with a discussion of the case of dimension zero, and extend them to\nclassical-quantum channels and quantum channels with tensor product input\nrestriction.", "comment": "16 pages, 2 figures. This paper has been accepted for publication at\n  IEEE Transactions on Communications. A preliminary version of the present\n  work was presented at the 2025 IEEE International Conference on\n  Communications, Montreal QB, 8-12 June 2025", "pdf_url": "http://arxiv.org/pdf/2502.02389v4", "cate": "cs.IT", "date": "2025-02-04", "updated": "2025-07-26"}
{"id": "2503.19063", "title": "COoL-TEE: Client-TEE Collaboration for Resilient Distributed Search", "authors": ["Matthieu Bettinger", "Etienne Rivière", "Sonia Ben Mokhtar", "Anthony Simonet-Boulogne"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.19063v2", "summary": "Current marketplaces rely on search mechanisms with distributed systems but\ncentralized governance, making them vulnerable to attacks, failures, censorship\nand biases. While search mechanisms with more decentralized governance (e.g.,\nDeSearch) have been recently proposed, these are still exposed to information\nhead-start attacks (IHS) despite the use of Trusted Execution Environments\n(TEEs). These attacks allow malicious users to gain a head-start over other\nusers for the discovery of new assets in the market, which give them an unfair\nadvantage in asset acquisition. We propose COoL-TEE, a TEE-based provider\nselection mechanism for distributed search, running in single- or\nmulti-datacenter environments, that is resilient to information head-start\nattacks. COoL-TEE relies on a Client-TEE collaboration, which enables clients\nto distinguish between slow providers and malicious ones. Performance\nevaluations in single- and multi-datacenter environments show that, using\nCOoL-TEE, malicious users respectively gain only up to 2% and 7% of assets more\nthan without IHS, while they can claim 20% or more on top of their fair share\nin the same conditions with DeSearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.19063v2", "cate": "cs.DC", "date": "2025-03-24", "updated": "2025-07-28"}
{"id": "2507.19538", "title": "Rural School Bus Routing and Scheduling", "authors": ["Prabhat Hegde", "Vikrant Vaze"], "categories": ["math.OC", "cs.CY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19538v1", "summary": "Long school bus rides adversely affect student performance and well-being.\nRural school bus rides are particularly long, incentivizing parents to drive\ntheir children to school rather than to opt for the school bus. This in turn\nexacerbates the traffic congestion around schools, further compounding the\nproblem of long bus rides, creating a vicious cycle. It also results in\nunderutilized school buses and higher bus operating costs per rider. To address\nthese challenges, this paper focuses on the design of rural school bus routes\nand schedules, a particularly challenging problem due to its unique operational\ncomplexities, including mixed loading and irregular road networks. We formalize\na rural school bus routing and scheduling model that tackles these complexities\nwhile minimizing the total bus ride time of students. We develop an original\nroad network-aware cluster-then-route heuristic that leverages our problem\nformulation to produce high-quality solutions. For real-world case studies, our\napproach outperforms status quo solutions by reducing the bus ride times of\nstudents by 37-39 %. Our solutions also make the school bus more attractive,\nhelping address both the underutilization of school buses and the prevalence of\nprivate commutes. Our routing and scheduling approach can improve school bus\nuse by 17-19 % and reduce car trips that induce congestion near schools by\n12-17 %. Many rural school districts share the operational characteristics\nmodeled in this study, including long bus rides, high operational expenditures,\nmixed loading, and a high proportion of car-based school commutes, suggesting\nthe broad applicability of our approach. Ultimately, by reducing student travel\ntimes, increasing school bus utilization, and alleviating congestion near\nschools, our approach enables rural school district planners to address\ntransportation-related barriers to student performance and well-being.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19538v1", "cate": "math.OC", "date": "2025-07-22", "updated": "2025-07-22"}
{"id": "2507.19542", "title": "Biogeography-Based Optimization of Fuzzy Controllers for Improved Quarter Car Suspension Performance", "authors": ["Lida Shahbandari", "Mohammad Mansouri"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19542v1", "summary": "This study proposes optimized Type-I and Type-II fuzzy controllers for\nautomotive suspension systems to enhance ride comfort and stability under road\ndisturbances (step/sine inputs), addressing the lack of systematic performance\ncomparisons in existing literature. We integrate Biogeography-Based\nOptimization (BBO), Particle Swarm Optimization (PSO), and Genetic Algorithms\n(GA) to tune controller parameters for a quarter car model, with emphasis on\nBBO's underexplored efficacy. MATLAB Simulink simulations demonstrate that\nBBO-optimized Type-II fuzzy control reduces body displacement by 22% and\nacceleration by 18% versus baseline methods under step disturbances, while\nmaintaining computational efficiency. The framework provides practical,\nhigh-performance solutions for modern vehicles, particularly electric and\nautonomous platforms where vibration attenuation and energy efficiency are\ncritical.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19542v1", "cate": "eess.SY", "date": "2025-07-23", "updated": "2025-07-23"}
{"id": "2507.19812", "title": "Channel Estimation in Massive MIMO Systems with Orthogonal Delay-Doppler Division Multiplexing", "authors": ["Dezhi Wang", "Chongwen Huang", "Xiaojun Yuan", "Sami Muhaidat", "Lei Liu", "Xiaoming Chen", "Zhaoyang Zhang", "Chau Yuen", "Mérouane Debbah"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19812v1", "summary": "Orthogonal delay-Doppler division multiplexing~(ODDM) modulation has recently\nbeen regarded as a promising technology to provide reliable communications in\nhigh-mobility situations. Accurate and low-complexity channel estimation is one\nof the most critical challenges for massive multiple input multiple\noutput~(MIMO) ODDM systems, mainly due to the extremely large antenna arrays\nand high-mobility environments. To overcome these challenges, this paper\naddresses the issue of channel estimation in downlink massive MIMO-ODDM systems\nand proposes a low-complexity algorithm based on memory approximate message\npassing~(MAMP) to estimate the channel state information~(CSI). Specifically,\nwe first establish the effective channel model of the massive MIMO-ODDM\nsystems, where the magnitudes of the elements in the equivalent channel vector\nfollow a Bernoulli-Gaussian distribution. Further, as the number of antennas\ngrows, the elements in the equivalent coefficient matrix tend to become\ncompletely random. Leveraging these characteristics, we utilize the MAMP method\nto determine the gains, delays, and Doppler effects of the multi-path channel,\nwhile the channel angles are estimated through the discrete Fourier transform\nmethod. Finally, numerical results show that the proposed channel estimation\nalgorithm approaches the Bayesian optimal results when the number of antennas\ntends to infinity and improves the channel estimation accuracy by about 30%\ncompared with the existing algorithms in terms of the normalized mean square\nerror.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19812v1", "cate": "eess.SP", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19566", "title": "SLENet: A Novel Multiscale CNN-Based Network for Detecting the Rats Estrous Cycle", "authors": ["Qinyang Wang", "Hoileong Lee", "Xiaodi Pu", "Yuanming Lai", "Yiming Ma"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19566v1", "summary": "In clinical medicine, rats are commonly used as experimental subjects.\nHowever, their estrous cycle significantly impacts their biological responses,\nleading to differences in experimental results. Therefore, accurately\ndetermining the estrous cycle is crucial for minimizing interference. Manually\nidentifying the estrous cycle in rats presents several challenges, including\nhigh costs, long training periods, and subjectivity. To address these issues,\nthis paper proposes a classification network-Spatial Long-distance EfficientNet\n(SLENet). This network is designed based on EfficientNet, specifically\nmodifying the Mobile Inverted Bottleneck Convolution (MBConv) module by\nintroducing a novel Spatial Efficient Channel Attention (SECA) mechanism to\nreplace the original Squeeze Excitation (SE) module. Additionally, a Non-local\nattention mechanism is incorporated after the last convolutional layer to\nenhance the network's ability to capture long-range dependencies. The dataset\nused 2,655 microscopic images of rat vaginal epithelial cells, with 531 images\nin the test set. Experimental results indicate that SLENet achieved an accuracy\nof 96.31%, outperforming baseline EfficientNet model (94.2%). This finding\nprovide practical value for optimizing experimental design in rat-based studies\nsuch as reproductive and pharmacological research, but this study is limited to\nmicroscopy image data, without considering other factors like temporal\npatterns, thus, incorporating multi-modal input is necessary for future\napplication.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19566v1", "cate": "eess.IV", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2409.06111", "title": "Competency-Aware Planning for Probabilistically Safe Navigation Under Perception Uncertainty", "authors": ["Sara Pohland", "Claire Tomlin"], "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.06111v5", "summary": "Perception-based navigation systems are useful for unmanned ground vehicle\n(UGV) navigation in complex terrains, where traditional depth-based navigation\nschemes are insufficient. However, these data-driven methods are highly\ndependent on their training data and can fail in surprising and dramatic ways\nwith little warning. To ensure the safety of the vehicle and the surrounding\nenvironment, it is imperative that the navigation system is able to recognize\nthe predictive uncertainty of the perception model and respond safely and\neffectively in the face of uncertainty. In an effort to enable safe navigation\nunder perception uncertainty, we develop a probabilistic and\nreconstruction-based competency estimation (PaRCE) method to estimate the\nmodel's level of familiarity with an input image as a whole and with specific\nregions in the image. We find that the overall competency score can correctly\npredict correctly classified, misclassified, and out-of-distribution (OOD)\nsamples. We also confirm that the regional competency maps can accurately\ndistinguish between familiar and unfamiliar regions across images. We then use\nthis competency information to develop a planning and control scheme that\nenables effective navigation while maintaining a low probability of error. We\nfind that the competency-aware scheme greatly reduces the number of collisions\nwith unfamiliar obstacles, compared to a baseline controller with no competency\nawareness. Furthermore, the regional competency information is very valuable in\nenabling efficient navigation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.06111v5", "cate": "cs.RO", "date": "2024-09-09", "updated": "2025-07-26"}
{"id": "2507.21017", "title": "MIRAGE-Bench: LLM Agent is Hallucinating and Where to Find Them", "authors": ["Weichen Zhang", "Yiyou Sun", "Pohao Huang", "Jiayue Pu", "Heyue Lin", "Dawn Song"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Code and data: this https URL", "url": "http://arxiv.org/abs/2507.21017v1", "summary": "Hallucinations pose critical risks for large language model (LLM)-based\nagents, often manifesting as hallucinative actions resulting from fabricated or\nmisinterpreted information within the cognitive context. While recent studies\nhave exposed such failures, existing evaluations remain fragmented and lack a\nprincipled testbed. In this paper, we present MIRAGE-Bench--Measuring Illusions\nin Risky AGEnt settings--the first unified benchmark for eliciting and\nevaluating hallucinations in interactive LLM-agent scenarios. We begin by\nintroducing a three-part taxonomy to address agentic hallucinations: actions\nthat are unfaithful to (i) task instructions, (ii) execution history, or (iii)\nenvironment observations. To analyze, we first elicit such failures by\nperforming a systematic audit of existing agent benchmarks, then synthesize\ntest cases using a snapshot strategy that isolates decision points in\ndeterministic and reproducible manners. To evaluate hallucination behaviors, we\nadopt a fine-grained-level LLM-as-a-Judge paradigm with tailored risk-aware\nprompts, enabling scalable, high-fidelity assessment of agent actions without\nenumerating full action spaces. MIRAGE-Bench provides actionable insights on\nfailure modes of LLM agents and lays the groundwork for principled progress in\nmitigating hallucinations in interactive environments.", "comment": "Code and data: https://github.com/sunblaze-ucb/mirage-bench.git", "pdf_url": "http://arxiv.org/pdf/2507.21017v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2501.04429", "title": "User-Centered-Design as an Empty Signifier in the Context of Developing Digital Applications", "authors": ["Murat Sariyar"], "categories": ["cs.HC", "K.4.2"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      11 pages", "url": "http://arxiv.org/abs/2501.04429v2", "summary": "To reduce cycles of rejection and redesign -- especially in the absence of\nclear acceptance criteria and the diversity of possible development paths --\nUser-Centered Design (UCD) has become a central methodology in computer\nscience, emphasizing the integration of user perspectives throughout the entire\nsystem lifecycle. Despite its widespread adoption, however, UCD remains\nconceptually ambiguous and theoretically underdeveloped. This paper addresses\nthat gap by drawing on the theories of Ernesto Laclau and Jacques Lacan to\nanalyze UCD as a potential empty signifier: a term that gains rhetorical power\nprecisely through its semantic openness. We argue that this ambiguity enables\nUCD to unify diverse and sometimes conflicting expectations under a shared\nlabel, which both empowers participatory design practices and conceals\nunderlying tensions. Acknowledging UCD as an empty signifier allows for a more\ncritical engagement with its practical and symbolic functions, revealing how it\ncan foster inclusivity, empathy, and user empowerment, but also how it risks\nideological capture and conceptual dilution. This theoretical reframing opens\nnew pathways for reflection and renewal within sociotechnical system design.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2501.04429v2", "cate": "cs.HC", "date": "2025-01-08", "updated": "2025-07-27"}
{"id": "2507.19887", "title": "CLoRA: Parameter-Efficient Continual Learning with Low-Rank Adaptation", "authors": ["Shishir Muralidhara", "Didier Stricker", "René Schuster"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at CoLLAs 2025", "url": "http://arxiv.org/abs/2507.19887v1", "summary": "In the past, continual learning (CL) was mostly concerned with the problem of\ncatastrophic forgetting in neural networks, that arises when incrementally\nlearning a sequence of tasks. Current CL methods function within the confines\nof limited data access, without any restrictions imposed on computational\nresources. However, in real-world scenarios, the latter takes precedence as\ndeployed systems are often computationally constrained. A major drawback of\nmost CL methods is the need to retrain the entire model for each new task. The\ncomputational demands of retraining large models can be prohibitive, limiting\nthe applicability of CL in environments with limited resources. Through CLoRA,\nwe explore the applicability of Low-Rank Adaptation (LoRA), a\nparameter-efficient fine-tuning method for class-incremental semantic\nsegmentation. CLoRA leverages a small set of parameters of the model and uses\nthe same set for learning across all tasks. Results demonstrate the efficacy of\nCLoRA, achieving performance on par with and exceeding the baseline methods. We\nfurther evaluate CLoRA using NetScore, underscoring the need to factor in\nresource efficiency and evaluate CL methods beyond task performance. CLoRA\nsignificantly reduces the hardware requirements for training, making it\nwell-suited for CL in resource-constrained environments after deployment.", "comment": "Accepted at CoLLAs 2025", "pdf_url": "http://arxiv.org/pdf/2507.19887v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2503.18597", "title": "Testora: Using Natural Language Intent to Detect Behavioral Regressions", "authors": ["Michael Pradel"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE/ACM International Conference on Software Engineering (ICSE) 2026", "url": "http://arxiv.org/abs/2503.18597v2", "summary": "As software is evolving, code changes can introduce regression bugs or affect\nthe behavior in other unintended ways. Traditional regression test generation\nis impractical for detecting unintended behavioral changes, because it reports\nall behavioral differences as potential regressions. However, most code changes\nare intended to change the behavior in some way, e.g., to fix a bug or to add a\nnew feature. This paper presents Testora, the first automated approach that\ndetects regressions by comparing the intentions of a code change against\nbehavioral differences caused by the code change. Given a pull request (PR),\nTestora queries an LLM to generate tests that exercise the modified code,\ncompares the behavior of the original and modified code, and classifies any\nbehavioral differences as intended or unintended. For the classification, we\npresent an LLM-based technique that leverages the natural language information\nassociated with the PR, such as the title, description, and commit messages --\neffectively using the natural language intent to detect behavioral regressions.\nApplying Testora to PRs of complex and popular Python projects, we find 19\nregression bugs and 11 PRs that, despite having another intention,\ncoincidentally fix a bug. Out of 13 regressions reported to the developers, 11\nhave been confirmed and 9 have already been fixed. The costs of using Testora\nare acceptable for real-world deployment, with 12.3 minutes to check a PR and\nLLM costs of only $0.003 per PR. We envision our approach to be used before or\nshortly after a code change gets merged into a code base, providing a way to\nearly on detect regressions that are not caught by traditional approaches.", "comment": "Accepted at IEEE/ACM International Conference on Software Engineering\n  (ICSE) 2026", "pdf_url": "http://arxiv.org/pdf/2503.18597v2", "cate": "cs.SE", "date": "2025-03-24", "updated": "2025-07-28"}
{"id": "2503.02545", "title": "Characterization of Deletion/Substitution Channel Capacity for Small Deletion and Substitution Probabilities", "authors": ["Mohammad Kazemi", "Tolga M. Duman"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.02545v3", "summary": "We consider binary input deletion/substitution channels, which model certain\ntypes of synchronization errors encountered in practice. Specifically, we focus\non the regime of small deletion and substitution probabilities, and by\nextending an approach developed for the deletion-only channel, we obtain an\nasymptotic characterization of the channel capacity for independent and\nidentically distributed (i.i.d.) deletion/substitution channels. To do so,\ngiven a target probability of successful decoding, we first develop an upper\nbound on the codebook size for arbitrary but fixed numbers of deletions and\nsubstitutions, and then extend the result to the case of random deletions and\nsubstitutions to obtain a bound on the channel capacity. Our final result is:\nThe i.i.d. deletion/substitution channel capacity is approximately \\(1 - H(p_d)\n- H(p_s)\\), for \\(p_d, p_s \\approx0\\), where \\(p_d\\) and \\(p_s\\) are the\ndeletion and substitution probabilities, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.02545v3", "cate": "cs.IT", "date": "2025-03-04", "updated": "2025-07-27"}
{"id": "2504.02263", "title": "MegaScale-Infer: Serving Mixture-of-Experts at Scale with Disaggregated Expert Parallelism", "authors": ["Ruidong Zhu", "Ziheng Jiang", "Chao Jin", "Peng Wu", "Cesar A. Stuardo", "Dongyang Wang", "Xinlei Zhang", "Huaping Zhou", "Haoran Wei", "Yang Cheng", "Jianzhe Xiao", "Xinyi Zhang", "Lingjun Liu", "Haibin Lin", "Li-Wen Chang", "Jianxi Ye", "Xiao Yu", "Xuanzhe Liu", "Xin Jin", "Xin Liu"], "categories": ["cs.DC", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.02263v4", "summary": "Mixture-of-Experts (MoE) showcases tremendous potential to scale large\nlanguage models (LLMs) with enhanced performance and reduced computational\ncomplexity. However, its sparsely activated architecture shifts feed-forward\nnetworks (FFNs) from being compute-intensive to memory-intensive during\ninference, leading to substantially lower GPU utilization and increased\noperational costs.\n  We present MegaScale-Infer, an efficient and cost-effective system for\nserving large-scale MoE models. MegaScale-Infer disaggregates attention and FFN\nmodules within each model layer, enabling independent scaling, tailored\nparallelism strategies, and heterogeneous deployment for both modules. To fully\nexploit disaggregation in the presence of MoE's sparsity, MegaScale-Infer\nintroduces ping-pong pipeline parallelism, which partitions a request batch\ninto micro-batches and shuttles them between attention and FFNs for inference.\nCombined with distinct model parallelism for each module, MegaScale-Infer\neffectively hides communication overhead and maximizes GPU utilization. To\nadapt to disaggregated attention and FFN modules and minimize data transmission\noverhead (e.g., token dispatch), MegaScale-Infer provides a high-performance\nM2N communication library that eliminates unnecessary GPU-to-CPU data copies,\ngroup initialization overhead, and GPU synchronization. Experimental results\nindicate that MegaScale-Infer achieves up to 1.90x higher per-GPU throughput\nthan state-of-the-art solutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.02263v4", "cate": "cs.DC", "date": "2025-04-03", "updated": "2025-07-26"}
{"id": "2507.19648", "title": "Street network sub-patterns and travel mode", "authors": ["Juan Fernando Riascos Goyes", "Michael Lowry", "Nicolás Guarín Zapata", "Juan Pablo Ospina"], "categories": ["physics.soc-ph", "cs.CY", "cs.LG"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19648v1", "summary": "Urban morphology has long been recognized as a factor shaping human mobility,\nyet comparative and formal classifications of urban form across metropolitan\nareas remain limited. Building on theoretical principles of urban structure and\nadvances in unsupervised learning, we systematically classified the built\nenvironment of nine U.S. metropolitan areas using structural indicators such as\ndensity, connectivity, and spatial configuration. The resulting morphological\ntypes were linked to mobility patterns through descriptive statistics, marginal\neffects estimation, and post hoc statistical testing. Here we show that\ndistinct urban forms are systematically associated with different mobility\nbehaviors, such as reticular morphologies being linked to significantly higher\npublic transport use (marginal effect = 0.49) and reduced car dependence\n(-0.41), while organic forms are associated with increased car usage (0.44),\nand substantial declines in public transport (-0.47) and active mobility\n(-0.30). These effects are statistically robust (p < 1e-19), highlighting that\nthe spatial configuration of urban areas plays a fundamental role in shaping\ntransportation choices. Our findings extend previous work by offering a\nreproducible framework for classifying urban form and demonstrate the added\nvalue of morphological analysis in comparative urban research. These results\nsuggest that urban form should be treated as a key variable in mobility\nplanning and provide empirical support for incorporating spatial typologies\ninto sustainable urban policy design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19648v1", "cate": "physics.soc-ph", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19545", "title": "Simulation of Emergency Evacuation in Large Scale Metropolitan Railway Systems for Urban Resilience", "authors": ["Hangli Ge", "Xiaojie Yang", "Zipei Fan", "Francesco Flammini", "Noboru Koshizuka"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19545v1", "summary": "This paper presents a simulation for traffic evacuation during railway\ndisruptions to enhance urban resilience. The research focuses on large-scale\nrailway networks and provides flexible simulation settings to accommodate\nmultiple node or line failures. The evacuation optimization model is\nmathematically formulated using matrix computation and nonlinear programming.\nThe simulation integrates railway lines operated by various companies, along\nwith external geographical features of the network. Furthermore, to address\ncomputational complexity in large-scale graph networks, a subgraph partitioning\nsolution is employed for computation acceleration. The model is evaluated using\nthe extensive railway network of Greater Tokyo. Data collection included both\nrailway network structure and real-world GPS footfall data to estimate the\nnumber of station-area visitors for simulation input and evaluation purposes.\nSeveral evacuation scenarios were simulated for major stations including Tokyo,\nShinjuku, Shibuya and so on. The results demonstrate that both evacuation\npassenger flow (EPF) and average travel time (ATT) during emergencies were\nsuccessfully optimized, while remaining within the capacity constraints of\nneighboring stations and the targeted disruption recovery times.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19545v1", "cate": "eess.SY", "date": "2025-07-24", "updated": "2025-07-24"}
{"id": "2507.19837", "title": "Feature Engineering for Wireless Communications and Networking: Concepts, Methodologies, and Applications", "authors": ["Jiacheng Wang", "Changyuan Zhao", "Zehui Xiong", "Tao Xiang", "Dusit Niyato", "Xianbin Wang", "Shiwen Mao", "Dong In Kim"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures", "url": "http://arxiv.org/abs/2507.19837v1", "summary": "AI-enabled wireless communications have attracted tremendous research\ninterest in recent years, particularly with the rise of novel paradigms such as\nlow-altitude integrated sensing and communication (ISAC) networks. Within these\nsystems, feature engineering plays a pivotal role by transforming raw wireless\ndata into structured representations suitable for AI models. Hence, this paper\noffers a comprehensive investigation of feature engineering techniques in\nAI-driven wireless communications. Specifically, we begin with a detailed\nanalysis of fundamental principles and methodologies of feature engineering.\nNext, we present its applications in wireless communication systems, with\nspecial emphasis on ISAC networks. Finally, we introduce a generative AI-based\nframework, which can reconstruct signal feature spectrum under malicious\nattacks in low-altitude ISAC networks. The case study shows that it can\neffectively reconstruct the signal spectrum, achieving an average structural\nsimilarity index improvement of 4%, thereby supporting downstream sensing and\ncommunication applications.", "comment": "7 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.19837v1", "cate": "eess.SP", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19636", "title": "Multisession Longitudinal Dynamic MRI Incorporating Patient-Specific Prior Image Information Across Time", "authors": ["Jingjia Chen", "Hersh Chandarana", "Daniel K. Sodickson", "Li Feng"], "categories": ["eess.IV", "physics.med-ph"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19636v1", "summary": "Serial Magnetic Resonance Imaging (MRI) exams are often performed in clinical\npractice, offering shared anatomical and motion information across imaging\nsessions. However, existing reconstruction methods process each session\nindependently without leveraging this valuable longitudinal information. In\nthis work, we propose a novel concept of longitudinal dynamic MRI, which\nincorporates patient-specific prior images to exploit temporal correlations\nacross sessions. This framework enables progressive acceleration of data\nacquisition and reduction of scan time as more imaging sessions become\navailable. The concept is demonstrated using the 4D Golden-angle RAdial Sparse\nParallel (GRASP) MRI, a state-of-the-art dynamic imaging technique.\nLongitudinal reconstruction is performed by concatenating multi-session\ntime-resolved 4D GRASP datasets into an extended dynamic series, followed by a\nlow-rank subspace-based reconstruction algorithm. A series of experiments were\nconducted to evaluate the feasibility and performance of the proposed method.\nResults show that longitudinal 4D GRASP reconstruction consistently outperforms\nstandard single-session reconstruction in image quality, while preserving\ninter-session variations. The approach demonstrated robustness to changes in\nanatomy, imaging intervals, and body contour, highlighting its potential for\nimproving imaging efficiency and consistency in longitudinal MRI applications.\nMore generally, this work suggests a new context-aware imaging paradigm in\nwhich the more we see a patient, the faster we can image.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19636v1", "cate": "eess.IV", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2409.09997", "title": "ViewActive: Active viewpoint optimization from a single image", "authors": ["Jiayi Wu", "Xiaomin Lin", "Botao He", "Cornelia Fermuller", "Yiannis Aloimonos"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.09997v5", "summary": "When observing objects, humans benefit from their spatial visualization and\nmental rotation ability to envision potential optimal viewpoints based on the\ncurrent observation. This capability is crucial for enabling robots to achieve\nefficient and robust scene perception during operation, as optimal viewpoints\nprovide essential and informative features for accurately representing scenes\nin 2D images, thereby enhancing downstream tasks.\n  To endow robots with this human-like active viewpoint optimization\ncapability, we propose ViewActive, a modernized machine learning approach\ndrawing inspiration from aspect graph, which provides viewpoint optimization\nguidance based solely on the current 2D image input. Specifically, we introduce\nthe 3D Viewpoint Quality Field (VQF), a compact and consistent representation\nof viewpoint quality distribution similar to an aspect graph, composed of three\ngeneral-purpose viewpoint quality metrics: self-occlusion ratio,\noccupancy-aware surface normal entropy, and visual entropy. We utilize\npre-trained image encoders to extract robust visual and semantic features,\nwhich are then decoded into the 3D VQF, allowing our model to generalize\neffectively across diverse objects, including unseen categories. The\nlightweight ViewActive network (72 FPS on a single GPU) significantly enhances\nthe performance of state-of-the-art object recognition pipelines and can be\nintegrated into real-time motion planning for robotic applications. Our code\nand dataset are available here: https://github.com/jiayi-wu-umd/ViewActive.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.09997v5", "cate": "cs.RO", "date": "2024-09-16", "updated": "2025-07-28"}
{"id": "2507.21046", "title": "A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence", "authors": ["Huan-ang Gao", "Jiayi Geng", "Wenyue Hua", "Mengkang Hu", "Xinzhe Juan", "Hongzhang Liu", "Shilong Liu", "Jiahao Qiu", "Xuan Qi", "Yiran Wu", "Hongru Wang", "Han Xiao", "Yuhang Zhou", "Shaokun Zhang", "Jiayi Zhang", "Jinyu Xiang", "Yixiong Fang", "Qiwen Zhao", "Dongrui Liu", "Qihan Ren", "Cheng Qian", "Zhenghailong Wang", "Minda Hu", "Huazheng Wang", "Qingyun Wu", "Heng Ji", "Mengdi Wang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      51 pages, 9 figures", "url": "http://arxiv.org/abs/2507.21046v1", "summary": "Large Language Models (LLMs) have demonstrated strong capabilities but remain\nfundamentally static, unable to adapt their internal parameters to novel tasks,\nevolving knowledge domains, or dynamic interaction contexts. As LLMs are\nincreasingly deployed in open-ended, interactive environments, this static\nnature has become a critical bottleneck, necessitating agents that can\nadaptively reason, act, and evolve in real time. This paradigm shift -- from\nscaling static models to developing self-evolving agents -- has sparked growing\ninterest in architectures and methods enabling continual learning and\nadaptation from data, interactions, and experiences. This survey provides the\nfirst systematic and comprehensive review of self-evolving agents, organized\naround three foundational dimensions -- what to evolve, when to evolve, and how\nto evolve. We examine evolutionary mechanisms across agent components (e.g.,\nmodels, memory, tools, architecture), categorize adaptation methods by stages\n(e.g., intra-test-time, inter-test-time), and analyze the algorithmic and\narchitectural designs that guide evolutionary adaptation (e.g., scalar rewards,\ntextual feedback, single-agent and multi-agent systems). Additionally, we\nanalyze evaluation metrics and benchmarks tailored for self-evolving agents,\nhighlight applications in domains such as coding, education, and healthcare,\nand identify critical challenges and research directions in safety,\nscalability, and co-evolutionary dynamics. By providing a structured framework\nfor understanding and designing self-evolving agents, this survey establishes a\nroadmap for advancing adaptive agentic systems in both research and real-world\ndeployments, ultimately shedding lights to pave the way for the realization of\nArtificial Super Intelligence (ASI), where agents evolve autonomously,\nperforming at or beyond human-level intelligence across a wide array of tasks.", "comment": "51 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.21046v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2503.00946", "title": "A Review of LLM-Assisted Ideation", "authors": ["Sitong Li", "Stefano Padilla", "Pierre Le Bras", "Junyu Dong", "Mike Chantler"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.00946v3", "summary": "We present a comprehensive, in-depth review of ideation assisted by large\nlanguage models (LLMs), highlighting emerging trends and identifying\nunaddressed research gaps. In total, we examined 61 studies investigating the\napplication of LLMs in both group and individual ideation processes. From these\nstudies, we derived the Hourglass Ideation Framework for LLM-assisted ideation,\ncomprising three phases and seven key ideation stages, which served as the\nbasis for our systematic survey. Our analysis reveals that LLMs are most\nfrequently used for idea generation and refinement, but their use in scope\nspecification, foundational material structuring and multi-idea evaluation and\nselection remains limited. We provide our findings in extensive tabular and\nonline formats. These catalogues detail research on LLM-assisted, purely\nLLM-based, and human-only activities across the seven ideation stages for each\nof the 61 studies. These also detail creative domains, publication outlets,\ninteraction designs, user study designs, and assessment methods. Our analysis\nof system interaction design reveals a predominant focus on supporting\nindividual ideation activities and text-based interaction, with a growing trend\nof incorporating multimedia elements. However, in group ideation, tools and\ninteraction modalities targeting both synchronous and asynchronous\ncollaboration are much scarcer. We synthesize the primary findings of our\nreview and outline promising directions for future research in LLM-assisted\nideation. We hope this review will help researchers quickly gain an overview of\nthis rapidly expanding area, efficiently locate relevant work, and identify\nunderexplored areas for further investigation. In addition, we believe the\nframework we present here will form the basis for the development of future\nproblem and solution space taxonomies, and methodologies for LLM-assisted\nideation development and use.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.00946v3", "cate": "cs.HC", "date": "2025-03-02", "updated": "2025-07-27"}
{"id": "2507.19894", "title": "A Survey on Generative Model Unlearning: Fundamentals, Taxonomy, Evaluation, and Future Direction", "authors": ["Xiaohua Feng", "Jiaming Zhang", "Fengyuan Yu", "Chengye Wang", "Li Zhang", "Kaixiang Li", "Yuyuan Li", "Chaochao Chen", "Jianwei Yin"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19894v1", "summary": "With the rapid advancement of generative models, associated privacy concerns\nhave attracted growing attention. To address this, researchers have begun\nadapting machine unlearning techniques from traditional classification models\nto generative settings. Although notable progress has been made in this area, a\nunified framework for systematically organizing and integrating existing work\nis still lacking. The substantial differences among current studies in terms of\nunlearning objectives and evaluation protocols hinder the objective and fair\ncomparison of various approaches. While some studies focus on specific types of\ngenerative models, they often overlook the commonalities and systematic\ncharacteristics inherent in Generative Model Unlearning (GenMU). To bridge this\ngap, we provide a comprehensive review of current research on GenMU and propose\na unified analytical framework for categorizing unlearning objectives,\nmethodological strategies, and evaluation metrics. In addition, we explore the\nconnections between GenMU and related techniques, including model editing,\nreinforcement learning from human feedback, and controllable generation. We\nfurther highlight the potential practical value of unlearning techniques in\nreal-world applications. Finally, we identify key challenges and outline future\nresearch directions aimed at laying a solid foundation for further advancements\nin this field. We consistently maintain the related open-source materials at\nhttps://github.com/caxLee/Generative-model-unlearning-survey.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19894v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2504.08490", "title": "Adopting Large Language Models to Automated System Integration", "authors": ["Robin D. Pesl"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      This preprint has not undergone peer review (when applicable) or any post-submission improvements or corrections. The Version of Record of this contribution is published in Intelligent Information Systems. CAiSE 2025. Lecture Notes in Business Information Processing, vol 557. Springer, Cham., and is available online at this https URL", "url": "http://arxiv.org/abs/2504.08490v2", "summary": "Modern enterprise computing systems integrate numerous subsystems to resolve\na common task by yielding emergent behavior. A widespread approach is using\nservices implemented with Web technologies like REST or OpenAPI, which offer an\ninteraction mechanism and service documentation standard, respectively. Each\nservice represents a specific business functionality, allowing encapsulation\nand easier maintenance. Despite the reduced maintenance costs on an individual\nservice level, increased integration complexity arises. Consequently, automated\nservice composition approaches have arisen to mitigate this issue.\nNevertheless, these approaches have not achieved high acceptance in practice\ndue to their reliance on complex formal modeling. Within this Ph.D. thesis, we\nanalyze the application of Large Language Models (LLMs) to automatically\nintegrate the services based on a natural language input. The result is a\nreusable service composition, e.g., as program code. While not always\ngenerating entirely correct results, the result can still be helpful by\nproviding integration engineers with a close approximation of a suitable\nsolution, which requires little effort to become operational. Our research\ninvolves (i) introducing a software architecture for automated service\ncomposition using LLMs, (ii) analyzing Retrieval Augmented Generation (RAG) for\nservice discovery, (iii) proposing a novel natural language query-based\nbenchmark for service discovery, and (iv) extending the benchmark to complete\nservice composition scenarios. We have presented our software architecture as\nCompositio Prompto, the analysis of RAG for service discovery, and submitted a\nproposal for the service discovery benchmark. Open topics are primarily the\nextension of the service discovery benchmark to service composition scenarios\nand the improvements of the service composition generation, e.g., using\nfine-tuning or LLM agents.", "comment": "This preprint has not undergone peer review (when applicable) or any\n  post-submission improvements or corrections. The Version of Record of this\n  contribution is published in Intelligent Information Systems. CAiSE 2025.\n  Lecture Notes in Business Information Processing, vol 557. Springer, Cham.,\n  and is available online at https://doi.org/10.1007/978-3-031-94590-8_37", "pdf_url": "http://arxiv.org/pdf/2504.08490v2", "cate": "cs.SE", "date": "2025-04-11", "updated": "2025-07-28"}
{"id": "2506.23000", "title": "Communication via Sensing", "authors": ["Mohammad Kazemi", "Tolga M. Duman", "Deniz Gündüz"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23000v2", "summary": "We present an alternative take on the recently popularized concept of\n`\\textit{joint sensing and communications}', which focuses on using\ncommunication resources also for sensing. Here, we propose the opposite, where\nwe utilize the receiver's sensing capabilities for communication. Our goal is\nto characterize the fundamental limits of communication over such a channel,\nwhich we call `\\textit{communication via sensing}'. We assume that changes in\nthe sensed attributes, such as location and speed, are limited due to practical\nconstraints, which are captured by assuming a finite-state channel (FSC) with\nan input cost constraint. We first formulate an upper bound on the \\(N\\)-letter\ncapacity as a cost-constrained optimization problem over the input sequence\ndistribution, and then convert it to an equivalent problem over the state\nsequence distribution. Moreover, by breaking a walk on the underlying Markov\nchain into a weighted sum of traversed graph cycles in the long walk limit, we\nobtain a compact single-letter formulation of the capacity upper bound.\nFinally, for a specific case of a two-state FSC with noisy sensing\ncharacterized by a binary symmetric channel (BSC), we obtain a closed-form\nexpression for the capacity upper bound. Comparison with an existing numerical\nlower bound shows that our proposed upper bound is very tight for all crossover\nprobabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23000v2", "cate": "cs.IT", "date": "2025-06-28", "updated": "2025-07-27"}
{"id": "2506.16488", "title": "Parallel Point-to-Point Shortest Paths and Batch Queries", "authors": ["Xiaojun Dong", "Andy Li", "Yan Gu", "Yihan Sun"], "categories": ["cs.DC", "cs.DS"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.16488v2", "summary": "We propose Orionet, efficient parallel implementations of Point-to-Point\nShortest Paths (PPSP) queries using bidirectional search (BiDS) and other\nheuristics, with an additional focus on batch PPSP queries. We present a\nframework for parallel PPSP built on existing single-source shortest paths\n(SSSP) frameworks by incorporating pruning conditions. As a result, we develop\nefficient parallel PPSP algorithms based on early termination, bidirectional\nsearch, A$^*$ search, and bidirectional A$^*$ all with simple and efficient\nimplementations.\n  We extend our idea to batch PPSP queries, which are widely used in real-world\nscenarios. We first design a simple and flexible abstraction to represent the\nbatch so PPSP can leverage the shared information of the batch. Orionet\nformalizes the batch as a query graph represented by edges between queried\nsources and targets. In this way, we directly extended our PPSP framework to\nbatched queries in a simple and efficient way.\n  We evaluate Orionet on both single and batch PPSP queries using various graph\ntypes and distance percentiles of queried pairs, and compare it against two\nbaselines, GraphIt and MBQ. Both of them support parallel single PPSP and A$^*$\nusing unidirectional search. On 14 graphs we tested, on average, our\nbidirectional search is 2.9$\\times$ faster than GraphIt, and 6.8$\\times$ faster\nthan MBQ. Our bidirectional A$^*$ is 4.4$\\times$ and 6.2$\\times$ faster than\nthe A$^*$ in GraphIt and MBQ, respectively. For batched PPSP queries, we also\nprovide in-depth experimental evaluation, and show that Orionet provides strong\nperformance compared to the plain solutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.16488v2", "cate": "cs.DC", "date": "2025-06-19", "updated": "2025-07-28"}
{"id": "2507.20409", "title": "Cognitive Chain-of-Thought: Structured Multimodal Reasoning about Social Situations", "authors": ["Eunkyu Park", "Wesley Hanwen Deng", "Gunhee Kim", "Motahhare Eslami", "Maarten Sap"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Under review; 17 pages", "url": "http://arxiv.org/abs/2507.20409v1", "summary": "Chain-of-Thought (CoT) prompting helps models think step by step. But what\nhappens when they must see, understand, and judge-all at once? In visual tasks\ngrounded in social context, where bridging perception with norm-grounded\njudgments is essential, flat CoT often breaks down. We introduce Cognitive\nChain-of-Thought (CoCoT), a prompting strategy that scaffolds VLM reasoning\nthrough three cognitively inspired stages: perception, situation, and norm. Our\nexperiments show that, across multiple multimodal benchmarks (including intent\ndisambiguation, commonsense reasoning, and safety), CoCoT consistently\noutperforms CoT and direct prompting (+8\\% on average). Our findings\ndemonstrate that cognitively grounded reasoning stages enhance interpretability\nand social awareness in VLMs, paving the way for safer and more reliable\nmultimodal systems.", "comment": "Under review; 17 pages", "pdf_url": "http://arxiv.org/pdf/2507.20409v1", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19558", "title": "Controller Design of an Airship", "authors": ["Manuel Schimmer"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Master's thesis", "url": "http://arxiv.org/abs/2507.19558v1", "summary": "Airships offer unique operational advantages due to their ability to generate\nlift via buoyancy, enabling low-speed flight and stationary hovering. These\ncapabilities make them ideal for missions requiring endurance and precision\npositioning. However, they also present significant control challenges: their\nlarge, lightweight structures are highly sensitive to environmental\ndisturbances, and conventional aerodynamic control surfaces lose effectiveness\nduring low-speed or hover flight. The objective of this thesis is to develop a\nrobust control strategy tailored to a vectored-thrust airship equipped with\ntiltable propellers. The proposed approach is based on an Extended Incremental\nNonlinear Dynamic Inversion inner loop in combination with a high level outer\nloop, controlling the attitude and velocity of the airship. The proposed method\nis able to effectively control the airship over the whole envelope, including\nhover and high speed flight. For this, effective use of available actuators is\nkey. This includes especially the tilt rotors, for which a control allocation\nmethod is presented. The controller's performance is validated through a series\nof simulation-based test scenarios, including aggressive maneuvering, gust\nrejection, atmospheric turbulence, and significant parameter mismatches. The\ncontroller is compared against an alternative controller developed at the\ninstitute, offering insight into the trade-offs between direct inversion and\nincremental control approaches. Results demonstrate that the proposed E-INDI\ncontroller achieves very good tracking performance and high high robustness\nagainst parameter uncertainties.", "comment": "Master's thesis", "pdf_url": "http://arxiv.org/pdf/2507.19558v1", "cate": "eess.SY", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19910", "title": "Toward Dual-Functional LAWN: Control-Aware System Design for Aerodynamics-Aided UAV Formations", "authors": ["Jun Wu", "Weijie Yuan", "Qingqing Cheng", "Haijia Jin"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19910v1", "summary": "Integrated sensing and communication (ISAC) has emerged as a pivotal\ntechnology for advancing low-altitude wireless networks (LAWNs), serving as a\ncritical enabler for next-generation communication systems. This paper\ninvestigates the system design for energy-saving unmanned aerial vehicle (UAV)\nformations in dual-functional LAWNs, where a ground base station (GBS)\nsimultaneously wirelessly controls multiple UAV formations and performs sensing\ntasks. To enhance flight endurance, we exploit the aerodynamic upwash effects\nand propose a distributed energy-saving formation framework based on the\nadapt-then-combine (ATC) diffusion least mean square (LMS) algorithm.\nSpecifically, each UAV updates the local position estimate by invoking the LMS\nalgorithm, followed by refining it through cooperative information exchange\nwith neighbors. This enables an optimized aerodynamic structure that minimizes\nthe formation's overall energy consumption. To ensure control stability and\nfairness, we formulate a maximum linear quadratic regulator (LQR) minimization\nproblem, which is subject to both the available power budget and the required\nsensing beam pattern gain. To address this non-convex problem, we develop a\ntwo-step approach by first deriving a closed-form expression of LQR as a\nfunction of arbitrary beamformers. Subsequently, an efficient iterative\nalgorithm that integrates successive convex approximation (SCA) and\nsemidefinite relaxation (SDR) techniques is proposed to obtain a sub-optimal\ndual-functional beamforming solution. Extensive simulation results confirm that\nthe 'V'-shaped formation is the most energy-efficient configuration and\ndemonstrate the superiority of our proposed design over benchmark schemes in\nimproving control performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19910v1", "cate": "eess.SP", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19734", "title": "A Metabolic-Imaging Integrated Model for Prognostic Prediction in Colorectal Liver Metastases", "authors": ["Qinlong Li", "Pu Sun", "Guanlin Zhu", "Tianjiao Liang", "Honggang QI"], "categories": ["eess.IV", "cs.CV", "cs.LG", "q-bio.QM"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      8 pages,4 figues", "url": "http://arxiv.org/abs/2507.19734v1", "summary": "Prognostic evaluation in patients with colorectal liver metastases (CRLM)\nremains challenging due to suboptimal accuracy of conventional clinical models.\nThis study developed and validated a robust machine learning model for\npredicting postoperative recurrence risk. Preliminary ensemble models achieved\nexceptionally high performance (AUC $>$ 0.98) but incorporated postoperative\nfeatures, introducing data leakage risks. To enhance clinical applicability, we\nrestricted input variables to preoperative baseline clinical parameters and\nradiomic features from contrast-enhanced CT imaging, specifically targeting\nrecurrence prediction at 3, 6, and 12 months postoperatively. The 3-month\nrecurrence prediction model demonstrated optimal performance with an AUC of\n0.723 in cross-validation. Decision curve analysis revealed that across\nthreshold probabilities of 0.55-0.95, the model consistently provided greater\nnet benefit than \"treat-all\" or \"treat-none\" strategies, supporting its utility\nin postoperative surveillance and therapeutic decision-making. This study\nsuccessfully developed a robust predictive model for early CRLM recurrence with\nconfirmed clinical utility. Importantly, it highlights the critical risk of\ndata leakage in clinical prognostic modeling and proposes a rigorous framework\nto mitigate this issue, enhancing model reliability and translational value in\nreal-world settings.", "comment": "8 pages,4 figues", "pdf_url": "http://arxiv.org/pdf/2507.19734v1", "cate": "eess.IV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2409.10310", "title": "Safe and Real-Time Consistent Planning for Autonomous Vehicles in Partially Observed Environments via Parallel Consensus Optimization", "authors": ["Lei Zheng", "Rui Yang", "Minzhe Zheng", "Michael Yu Wang", "Jun Ma"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      16 pages, 7 figures", "url": "http://arxiv.org/abs/2409.10310v2", "summary": "Ensuring safety and driving consistency is a significant challenge for\nautonomous vehicles operating in partially observed environments. This work\nintroduces a consistent parallel trajectory optimization (CPTO) approach to\nenable safe and consistent driving in dense obstacle environments with\nperception uncertainties. Utilizing discrete-time barrier function theory, we\ndevelop a consensus safety barrier module that ensures reliable safety coverage\nwithin the spatiotemporal trajectory space across potential obstacle\nconfigurations. Following this, a bi-convex parallel trajectory optimization\nproblem is derived that facilitates decomposition into a series of\nlow-dimensional quadratic programming problems to accelerate computation. By\nleveraging the consensus alternating direction method of multipliers (ADMM) for\nparallel optimization, each generated candidate trajectory corresponds to a\npossible environment configuration while sharing a common consensus trajectory\nsegment. This ensures driving safety and consistency when executing the\nconsensus trajectory segment for the ego vehicle in real time. We validate our\nCPTO framework through extensive comparisons with state-of-the-art baselines\nacross multiple driving tasks in partially observable environments. Our results\ndemonstrate improved safety and consistency using both synthetic and real-world\ntraffic datasets.", "comment": "16 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2409.10310v2", "cate": "cs.RO", "date": "2024-09-16", "updated": "2025-07-26"}
{"id": "2407.05592", "title": "Transfer or Self-Supervised? Bridging the Performance Gap in Medical Imaging", "authors": ["Zehui Zhao", "Laith Alzubaidi", "Jinglan Zhang", "Ye Duan", "Usman Naseem", "Yuantong Gu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      37 pages, 8 figures", "url": "http://arxiv.org/abs/2407.05592v2", "summary": "Recently, transfer learning and self-supervised learning have gained\nsignificant attention within the medical field due to their ability to mitigate\nthe challenges posed by limited data availability, improve model\ngeneralisation, and reduce computational expenses. Transfer learning and\nself-supervised learning hold immense potential for advancing medical research.\nHowever, it is crucial to recognise that transfer learning and self-supervised\nlearning architectures exhibit distinct advantages and limitations, manifesting\nvariations in accuracy, training speed, and robustness. This paper compares the\nperformance and robustness of transfer learning and self-supervised learning in\nthe medical field. Specifically, we pre-trained two models using the same\nsource domain datasets with different pre-training methods and evaluated them\non small-sized medical datasets to identify the factors influencing their final\nperformance. We tested data with several common issues in medical domains, such\nas data imbalance, data scarcity, and domain mismatch, through comparison\nexperiments to understand their impact on specific pre-trained models. Finally,\nwe provide recommendations to help users apply transfer learning and\nself-supervised learning methods in medical areas, and build more convenient\nand efficient deployment strategies.", "comment": "37 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2407.05592v2", "cate": "cs.CV", "date": "2024-07-08", "updated": "2024-12-09"}
{"id": "2504.02622", "title": "Exploring undercurrents of learning tensions in an LLM-enhanced landscape: A student-centered qualitative perspective on LLM vs Search", "authors": ["Rahul R. Divekar", "Sophia Guerra", "Lisette Gonzalez", "Natasha Boos", "Helen Zhou"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.02622v2", "summary": "Large language models (LLMs) are transforming how students learn by providing\nreadily available tools that can quickly augment or complete various learning\nactivities with non-trivial performance. Similar paradigm shifts have occurred\nin the past with the introduction of search engines and Wikipedia, which\nreplaced or supplemented traditional information sources such as libraries and\nbooks. This study investigates the potential for LLMs to represent the next\nshift in learning, focusing on their role in information discovery and\nsynthesis compared to existing technologies, such as search engines. Using a\nwithin-subjects, counterbalanced design, participants learned new topics using\na search engine (Google) and an LLM (ChatGPT). Post-task follow-up interviews\nexplored students' reflections, preferences, pain points, and overall\nperceptions. We present analysis of their responses that show nuanced insights\ninto when, why, and how students prefer LLMs over search engines, offering\nimplications for educators, policymakers, and technology developers navigating\nthe evolving educational landscape.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.02622v2", "cate": "cs.HC", "date": "2025-04-03", "updated": "2025-07-27"}
{"id": "2507.19964", "title": "Who Owns This Sample: Cross-Client Membership Inference Attack in Federated Graph Neural Networks", "authors": ["Kunhao Li", "Di Wu", "Jun Bai", "Jing Xu", "Lei Yang", "Ziyi Zhang", "Yiliao Song", "Wencheng Yang", "Taotao Cai", "Yan Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19964v1", "summary": "Graph-structured data is prevalent in many real-world applications, including\nsocial networks, financial systems, and molecular biology. Graph Neural\nNetworks (GNNs) have become the de facto standard for learning from such data\ndue to their strong representation capabilities. As GNNs are increasingly\ndeployed in federated learning (FL) settings to preserve data locality and\nprivacy, new privacy threats arise from the interaction between graph\nstructures and decentralized training. In this paper, we present the first\nsystematic study of cross-client membership inference attacks (CC-MIA) against\nnode classification tasks of federated GNNs (FedGNNs), where a malicious client\naims to infer which client owns the given data. Unlike prior\ncentralized-focused work that focuses on whether a sample was included in\ntraining, our attack targets sample-to-client attribution, a finer-grained\nprivacy risk unique to federated settings. We design a general attack framework\nthat exploits FedGNNs' aggregation behaviors, gradient updates, and embedding\nproximity to link samples to their source clients across training rounds. We\nevaluate our attack across multiple graph datasets under realistic FL setups.\nResults show that our method achieves high performance on both membership\ninference and ownership identification. Our findings highlight a new privacy\nthreat in federated graph learning-client identity leakage through structural\nand model-level cues, motivating the need for attribution-robust GNN design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19964v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2504.18784", "title": "Secret Breach Detection in Source Code with Large Language Models", "authors": ["Md Nafiu Rahman", "Sadif Ahmed", "Zahin Wahab", "S M Sohan", "Rifat Shahriyar"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      19th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM 2025) cameraready", "url": "http://arxiv.org/abs/2504.18784v2", "summary": "Background: Leaking sensitive information - such as API keys, tokens, and\ncredentials - in source code remains a persistent security threat. Traditional\nregex and entropy-based tools often generate high false positives due to\nlimited contextual understanding. Aims: This work aims to enhance secret\ndetection in source code using large language models (LLMs), reducing false\npositives while maintaining high recall. We also evaluate the feasibility of\nusing fine-tuned, smaller models for local deployment. Method: We propose a\nhybrid approach combining regex-based candidate extraction with LLM-based\nclassification. We evaluate pre-trained and fine-tuned variants of various\nLarge Language Models on a benchmark dataset from 818 GitHub repositories.\nVarious prompting strategies and efficient fine-tuning methods are employed for\nboth binary and multiclass classification. Results: The fine-tuned LLaMA-3.1 8B\nmodel achieved an F1-score of 0.9852 in binary classification, outperforming\nregex-only baselines. For multiclass classification, Mistral-7B reached 0.982\naccuracy. Fine-tuning significantly improved performance across all models.\nConclusions: Fine-tuned LLMs offer an effective and scalable solution for\nsecret detection, greatly reducing false positives. Open-source models provide\na practical alternative to commercial APIs, enabling secure and cost-efficient\ndeployment in development workflows.", "comment": "19th ACM/IEEE International Symposium on Empirical Software\n  Engineering and Measurement (ESEM 2025) cameraready", "pdf_url": "http://arxiv.org/pdf/2504.18784v2", "cate": "cs.SE", "date": "2025-04-26", "updated": "2025-07-28"}
{"id": "2507.03481", "title": "Class-Based Expurgation Attains Csiszár's Expurgated Source-Channel Exponent", "authors": ["AmirPouya Moeini", "Albert Guillén i Fàbregas"], "categories": ["cs.IT", "math.IT", "math.PR"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      This paper is scheduled to be presented at IEEE ITW 2025, Sydney, Australia", "url": "http://arxiv.org/abs/2507.03481v2", "summary": "This paper studies expurgated error exponents for joint source-channel coding\nfor discrete memoryless sources and channels. We consider a partition of the\nsource messages into classes, where the codeword distributions depend on the\nclass. We show that two carefully chosen classes suffice to achieve Csisz\\'ar's\nexpurgated exponent.", "comment": "This paper is scheduled to be presented at IEEE ITW 2025, Sydney,\n  Australia", "pdf_url": "http://arxiv.org/pdf/2507.03481v2", "cate": "cs.IT", "date": "2025-07-04", "updated": "2025-07-27"}
{"id": "2507.17773", "title": "MultiKernelBench: A Multi-Platform Benchmark for Kernel Generation", "authors": ["Zhongzhen Wen", "Yinghui Zhang", "Zhong Li", "Zhongxin Liu", "Linna Xie", "Tian Zhang"], "categories": ["cs.DC", "cs.LG", "cs.PF", "cs.SE"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.17773v2", "summary": "The automatic generation of deep learning (DL) kernels using large language\nmodels (LLMs) has emerged as a promising approach to reduce the manual effort\nand hardware-specific expertise required for writing high-performance operator\nimplementations. However, existing benchmarks for evaluating LLMs in this\ndomain suffer from limited hardware support, coarse-grained kernel\ncategorization, and imbalanced task coverage. To address these limitations, we\nintroduce MultiKernelBench, the first comprehensive, multi-platform benchmark\nfor LLM-based DL kernel generation. MultiKernelBench spans 285 tasks across 14\nwell-defined kernel categories and supports three major hardware platforms:\nNvidia GPUs, Huawei NPUs, and Google TPUs. To enable future extensibility, we\ndesign a modular backend abstraction layer that decouples platform-specific\nlogic from the core benchmarking infrastructure, allowing easy integration of\nnew hardware platforms. We further propose a simple yet effective\ncategory-aware one-shot prompting method that improves generation quality by\nproviding in-category exemplars. Through systematic evaluations of seven\nstate-of-the-art LLMs, we reveal significant variation in task difficulty, poor\ngeneralization to platforms with less training exposure, and the effectiveness\nof targeted prompting strategies. MultiKernelBench is publicly available at\nhttps://github.com/wzzll123/MultiKernelBench.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.17773v2", "cate": "cs.DC", "date": "2025-07-20", "updated": "2025-07-26"}
{"id": "2507.20503", "title": "Customize Multi-modal RAI Guardrails with Precedent-based predictions", "authors": ["Cheng-Fu Yang", "Thanh Tran", "Christos Christodoulopoulos", "Weitong Ruan", "Rahul Gupta", "Kai-Wei Chang"], "categories": ["cs.LG", "cs.CL", "cs.CY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to COLM 2025", "url": "http://arxiv.org/abs/2507.20503v1", "summary": "A multi-modal guardrail must effectively filter image content based on\nuser-defined policies, identifying material that may be hateful, reinforce\nharmful stereotypes, contain explicit material, or spread misinformation.\nDeploying such guardrails in real-world applications, however, poses\nsignificant challenges. Users often require varied and highly customizable\npolicies and typically cannot provide abundant examples for each custom policy.\nConsequently, an ideal guardrail should be scalable to the multiple policies\nand adaptable to evolving user standards with minimal retraining. Existing\nfine-tuning methods typically condition predictions on pre-defined policies,\nrestricting their generalizability to new policies or necessitating extensive\nretraining to adapt. Conversely, training-free methods struggle with limited\ncontext lengths, making it difficult to incorporate all the policies\ncomprehensively. To overcome these limitations, we propose to condition model's\njudgment on \"precedents\", which are the reasoning processes of prior data\npoints similar to the given input. By leveraging precedents instead of fixed\npolicies, our approach greatly enhances the flexibility and adaptability of the\nguardrail. In this paper, we introduce a critique-revise mechanism for\ncollecting high-quality precedents and two strategies that utilize precedents\nfor robust prediction. Experimental results demonstrate that our approach\noutperforms previous methods across both few-shot and full-dataset scenarios\nand exhibits superior generalization to novel policies.", "comment": "Accepted to COLM 2025", "pdf_url": "http://arxiv.org/pdf/2507.20503v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.19631", "title": "Diversity and Interaction Quality of a Heterogeneous Multi-Agent System Applied to a Synchronization Problem", "authors": ["Xin Mao", "Dan Wang", "Wei Chen", "Li Qiu"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19631v1", "summary": "In this paper, scalable controller design to achieve output synchronization\nfor a heterogeneous discrete-time nonlinear multi-agent system is considered.\nThe agents are assumed to exhibit potentially nonlinear dynamics but share\nlinear common oscillatory modes. In a distributed control architecture,\nscalability is ensured by designing a small number of distinguished\ncontrollers, significantly fewer than the number of agents, even when agent\ndiversity is high. Our findings indicate that the number of controllers\nrequired can be effectively determined by the number of strongly connected\ncomponents of the underlying graph. The study in this paper builds on the\nrecently developed phase theory of matrices and systems. First, we employ the\nconcept of matrix phase, specifically the phase alignability of a collection of\nmatrices, to quantify agent diversity. Next, we use matrix phase, particularly\nthe essential phase of the graph Laplacian, to evaluate the interaction quality\namong the agents. Based on these insights, we derive a sufficient condition for\nthe solvability of the synchronization problem, framed as a trade-off between\nthe agent diversity and the interaction quality. In the process, a controller\ndesign procedure based on Lyapunov analysis is provided, which produces low\ngain, component-wise synchronizing controllers when the solvability condition\nis satisfied. Numerical examples are given to illustrate the effectiveness of\nthe proposed design procedure. Furthermore, we consider cases where the\ncomponent-wise controller design problem is unsolvable. We propose alternative\nstrategies involving the design of a small inventory of controllers, which can\nstill achieve synchronization effectively by employing certain clustering\nmethods to manage heterogeneity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19631v1", "cate": "eess.SY", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19936", "title": "Deep Learning Based Joint Channel Estimation and Positioning for Sparse XL-MIMO OFDM Systems", "authors": ["Zhongnian Li", "Chao Zheng", "Jian Xiao", "Ji Wang", "Gongpu Wang", "Ming Zeng", "Octavia A. Dobre"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      5 pages,8 figures", "url": "http://arxiv.org/abs/2507.19936v1", "summary": "This paper investigates joint channel estimation and positioning in\nnear-field sparse extra-large multiple-input multiple-output (XL-MIMO)\northogonal frequency division multiplexing (OFDM) systems. To achieve\ncooperative gains between channel estimation and positioning, we propose a deep\nlearning-based two-stage framework comprising positioning and channel\nestimation. In the positioning stage, the user's coordinates are predicted and\nutilized in the channel estimation stage, thereby enhancing the accuracy of\nchannel estimation. Within this framework, we propose a U-shaped Mamba\narchitecture for channel estimation and positioning, termed as CP-Mamba. This\nnetwork integrates the strengths of the Mamba model with the structural\nadvantages of U-shaped convolutional networks, enabling effective capture of\nlocal spatial features and long-range temporal dependencies of the channel.\nNumerical simulation results demonstrate that the proposed two-stage approach\nwith CP-Mamba architecture outperforms existing baseline methods. Moreover,\nsparse arrays (SA) exhibit significantly superior performance in both channel\nestimation and positioning accuracy compared to conventional compact arrays.", "comment": "5 pages,8 figures", "pdf_url": "http://arxiv.org/pdf/2507.19936v1", "cate": "eess.SP", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19781", "title": "SpecBPP: A Self-Supervised Learning Approach for Hyperspectral Representation and Soil Organic Carbon Estimation", "authors": ["Daniel La'ah Ayuba", "Jean-Yves Guillemaut", "Belen Marti-Cardona", "Oscar Mendez Maldonado"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19781v1", "summary": "Self-supervised learning has revolutionized representation learning in vision\nand language, but remains underexplored for hyperspectral imagery (HSI), where\nthe sequential structure of spectral bands offers unique opportunities. In this\nwork, we propose Spectral Band Permutation Prediction (SpecBPP), a novel\nself-supervised learning framework that leverages the inherent spectral\ncontinuity in HSI. Instead of reconstructing masked bands, SpecBPP challenges a\nmodel to recover the correct order of shuffled spectral segments, encouraging\nglobal spectral understanding. We implement a curriculum-based training\nstrategy that progressively increases permutation difficulty to manage the\nfactorial complexity of the permutation space. Applied to Soil Organic Carbon\n(SOC) estimation using EnMAP satellite data, our method achieves\nstate-of-the-art results, outperforming both masked autoencoder (MAE) and\njoint-embedding predictive (JEPA) baselines. Fine-tuned on limited labeled\nsamples, our model yields an $R^2$ of 0.9456, RMSE of 1.1053%, and RPD of 4.19,\nsignificantly surpassing traditional and self-supervised benchmarks. Our\nresults demonstrate that spectral order prediction is a powerful pretext task\nfor hyperspectral understanding, opening new avenues for scientific\nrepresentation learning in remote sensing and beyond.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19781v1", "cate": "eess.IV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2409.14775", "title": "Safe Expeditious Whole-Body Control of Mobile Manipulators for Collision Avoidance", "authors": ["Bingjie Chen", "Yancong Wei", "Rihao Liu", "Chenxi Han", "Houde Liu", "Chongkun Xia", "Liang Han", "Bin Liang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.14775v3", "summary": "Whole-body reactive obstacle avoidance for mobile manipulators (MM) remains\nan open research problem. Control Barrier Functions (CBF), combined with\nQuadratic Programming (QP), have become a popular approach for reactive control\nwith safety guarantees. However, traditional CBF methods often face issues such\nas pseudo-equilibrium problems (PEP) and are ineffective in handling dynamic\nobstacles. To overcome these challenges, we introduce the Adaptive Cyclic\nInequality (ACI) method. ACI takes into account both the obstacle's velocity\nand the robot's nominal control to define a directional safety constraint. When\nadded to the CBF-QP, ACI helps avoid PEP and enables reliable collision\navoidance in dynamic environments. We validate our approach on a MM that\nincludes a low-dimensional mobile base and a high-dimensional manipulator,\ndemonstrating the generality of the framework. In addition, we integrate a\nsimple yet effective method for avoiding self-collisions, allowing the robot\nenabling comprehensive whole-body collision-free operation. Extensive benchmark\ncomparisons and experiments demonstrate that our method performs well in\nunknown and dynamic scenarios, including difficult tasks like avoiding sticks\nswung by humans and rapidly thrown objects.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.14775v3", "cate": "cs.RO", "date": "2024-09-23", "updated": "2025-07-28"}
{"id": "2507.19562", "title": "PennyCoder: Efficient Domain-Specific LLMs for PennyLane-Based Quantum Code Generation", "authors": ["Abdul Basit", "Minghao Shao", "Muhammad Haider Asif", "Nouhaila Innan", "Muhammad Kashif", "Alberto Marchisio", "Muhammad Shafique"], "categories": ["quant-ph", "cs.AI", "68T50, 81P68, 68T07", "I.2.7; I.2.2"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures, 3 tables, paper accepted to QCE 2025", "url": "http://arxiv.org/abs/2507.19562v1", "summary": "The growing demand for robust quantum programming frameworks has unveiled a\ncritical limitation: current large language model (LLM) based quantum code\nassistants heavily rely on remote APIs, introducing challenges related to\nprivacy, latency, and excessive usage costs. Addressing this gap, we propose\nPennyCoder, a novel lightweight framework for quantum code generation,\nexplicitly designed for local and embedded deployment to enable on-device\nquantum programming assistance without external API dependence. PennyCoder\nleverages a fine-tuned version of the LLaMA 3.1-8B model, adapted through\nparameter-efficient Low-Rank Adaptation (LoRA) techniques combined with\ndomain-specific instruction tuning optimized for the specialized syntax and\ncomputational logic of quantum programming in PennyLane, including tasks in\nquantum machine learning and quantum reinforcement learning. Unlike prior work\nfocused on cloud-based quantum code generation, our approach emphasizes\ndevice-native operability while maintaining high model efficacy. We rigorously\nevaluated PennyCoder over a comprehensive quantum programming dataset,\nachieving 44.3% accuracy with our fine-tuned model (compared to 33.7% for the\nbase LLaMA 3.1-8B and 40.1% for the RAG-augmented baseline), demonstrating a\nsignificant improvement in functional correctness.", "comment": "6 pages, 5 figures, 3 tables, paper accepted to QCE 2025", "pdf_url": "http://arxiv.org/pdf/2507.19562v1", "cate": "quant-ph", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2504.03253", "title": "Ultra-low-power ring-based wireless tinymouse", "authors": ["Yifan Li", "Masaaki Fukumoto", "Mohamed Kari", "Shigemi Ishida", "Akihito Noda", "Tomoyuki Yokota", "Takao Someya", "Yoshihiro Kawahara", "Ryo Takahashi"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2501.16674", "url": "http://arxiv.org/abs/2504.03253v3", "summary": "Wireless mouse rings offer subtle, reliable pointing interactions for\nwearable computing platforms. However, the small battery below 27 mAh in the\nminiature rings restricts the ring's continuous lifespan to just 1-10 hours,\nbecause current low-powered wireless communication such as BLE is\npower-consuming for ring's continuous use. The ring's short lifespan frequently\ndisrupts users' mouse use with the need for frequent charging. This paper\npresents picoRing mouse, enabling a continuous ring-based mouse interaction\nwith ultra-low-powered ring-to-wristband wireless communication. picoRing mouse\nemploys a coil-based impedance sensing named semi-passive inductive telemetry,\nallowing a wristband coil to capture a unique frequency response of a nearby\nring coil via a sensitive inductive coupling between the coils. The ring coil\nconverts the corresponding user's mouse input into the unique frequency\nresponse via an up to 449 uW mouse-driven modulation system. Therefore, the\ncontinuous use of picoRing mouse can last approximately 600 (8hrs use/day)-1000\n(4hrs use/day) hours on a single charge of a 27 mAh battery while supporting\nsubtle thumb-to-index scrolling and pressing interactions in real-world\nwearable computing situations.", "comment": "arXiv admin note: text overlap with arXiv:2501.16674", "pdf_url": "http://arxiv.org/pdf/2504.03253v3", "cate": "cs.HC", "date": "2025-04-04", "updated": "2025-07-28"}
{"id": "2507.19968", "title": "Dimer-Enhanced Optimization: A First-Order Approach to Escaping Saddle Points in Neural Network Training", "authors": ["Yue Hu", "Zanxia Cao", "Yingchao Liu"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      8 pages, 2 figures", "url": "http://arxiv.org/abs/2507.19968v1", "summary": "First-order optimization methods, such as SGD and Adam, are widely used for\ntraining large-scale deep neural networks due to their computational efficiency\nand robust performance. However, relying solely on gradient information, these\nmethods often struggle to navigate complex loss landscapes with flat regions,\nplateaus, and saddle points. Second-order methods, which use curvature\ninformation from the Hessian matrix, can address these challenges but are\ncomputationally infeasible for large models. The Dimer method, a first-order\ntechnique that constructs two closely spaced points to probe the local geometry\nof a potential energy surface, efficiently estimates curvature using only\ngradient information. Inspired by its use in molecular dynamics simulations for\nlocating saddle points, we propose Dimer-Enhanced Optimization (DEO), a novel\nframework to escape saddle points in neural network training. DEO adapts the\nDimer method to explore a broader region of the loss landscape, approximating\nthe Hessian's smallest eigenvector without computing the full matrix. By\nperiodically projecting the gradient onto the subspace orthogonal to the\nminimum curvature direction, DEO guides the optimizer away from saddle points\nand flat regions, enhancing training efficiency with non-stepwise updates.\nPreliminary experiments on a Transformer toy model show DEO achieves\ncompetitive performance compared to standard first-order methods, improving\nnavigation of complex loss landscapes. Our work repurposes physics-inspired,\nfirst-order curvature estimation to enhance neural network training in\nhigh-dimensional spaces.", "comment": "8 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.19968v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2505.21323", "title": "A first look at ROS 2 applications written in asynchronous Rust", "authors": ["Martin Škoudlil", "Michal Sojka", "Zdeněk Hanzálek"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Published version, added external DOI", "url": "http://arxiv.org/abs/2505.21323v3", "summary": "The increasing popularity of the Rust programming language in building\nrobotic applications using the Robot Operating System (ROS 2) raises questions\nabout its real-time execution capabilities, particularly when employing\nasynchronous programming. Existing real-time scheduling and response-time\nanalysis techniques for ROS 2 focus on applications written in C++ and do not\naddress the unique execution models and challenges presented by Rust's\nasynchronous programming paradigm. In this paper, we analyze the execution\nmodel of R2R -- an asynchronous Rust ROS 2 bindings and various asynchronous\nRust runtimes, comparing them with the execution model of C++ ROS 2\napplications. We propose a structured approach for R2R applications aimed at\ndeterministic real-time operation involving thread prioritization and\ncallback-to-thread mapping schemes. Our experimental evaluation based on\nmeasuring end-to-end latencies of a synthetic application shows that the\nproposed approach is effective and outperforms other evaluated configurations.\nA more complex autonomous driving case study demonstrates its practical\napplicability. Overall, the experimental results indicate that our proposed\nstructure achieves bounded response times for time-critical tasks. This paves\nthe way for future work to adapt existing or develop new response-time analysis\ntechniques for R2R applications using our structure.", "comment": "Published version, added external DOI", "pdf_url": "http://arxiv.org/pdf/2505.21323v3", "cate": "cs.SE", "date": "2025-05-27", "updated": "2025-07-28"}
{"id": "2507.09833", "title": "Remote Safety Monitoring: Significance-Aware Status Updating for Situational Awareness", "authors": ["Tasmeen Zaman Ornee", "Md Kamran Chowdhury Shisher", "Clement Kam", "Yin Sun"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      14 pages, 8 figures", "url": "http://arxiv.org/abs/2507.09833v2", "summary": "In this study, we consider a problem of remote safety monitoring, where a\nmonitor pulls status updates from multiple sensors monitoring several\nsafety-critical situations. Based on the received updates, multiple estimators\ndetermine the current safety-critical situations. Due to transmission errors\nand limited channel resources, the received status updates may not be fresh,\nresulting in the possibility of misunderstanding the current safety situation.\nIn particular, if a dangerous situation is misinterpreted as safe, the safety\nrisk is high. We study the joint design of transmission scheduling and\nestimation for multi-sensor, multi-channel remote safety monitoring, aiming to\nminimize the loss due to the unawareness of potential danger. We show that the\njoint design of transmission scheduling and estimation can be reduced to a\nsequential optimization of estimation and scheduling. The scheduling problem\ncan be formulated as a Restless Multi-armed Bandit (RMAB) , for which it is\ndifficult to establish indexability. We propose a low-complexity Maximum Gain\nFirst (MGF) policy and prove it is asymptotically optimal as the numbers of\nsources and channels scale up proportionally, without requiring the\nindexability condition. We also provide an information-theoretic interpretation\nof the transmission scheduling problem. Numerical results show that our\nestimation and scheduling policies achieves higher performance gain over\nperiodic updating, randomized policy, and Maximum Age First (MAF) policy.", "comment": "14 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.09833v2", "cate": "cs.IT", "date": "2025-07-14", "updated": "2025-07-25"}
{"id": "2507.19287", "title": "The Case for Time-Shared Computing Resources", "authors": ["Pierre Jacquet", "Adrien Luxey-Bitri"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Post-proceedings paper presented at LIMITS 2025: 11th Workshop on Computing within Limits, 2025-06-26/27, Online", "url": "http://arxiv.org/abs/2507.19287v2", "summary": "The environmental impact of Information and Communication Technologies (ICT)\ncontinues to grow, driven notably by increasing usage, rebound effects, and\nemerging demands. However, despite the virtual nature of its services, the\nsector remains inherently constrained by its materiality and cannot rely on an\ninfinite pool of resources. As a result, the wide variety of supported services\nmay need to be managed under stricter limits within hosting facilities in the\nfuture. Contrary to common assumptions, we show that tenants typically do not\nshare computing resources, even in environments commonly perceived as\nmutualized, such as cloud platforms. Time-sharing has been progressively phased\nout for reasons of performance, security, predictability, and, perhaps more\nimportantly, due to the decreasing cost of computing resources. This paper\nadvocates for managing fewer physical resources by improving resource sharing\nbetween tenants. It represents a paradigm shift, moving beyond traditional\ntime-sharing at the hardware level to a higher abstraction. This approach\nentails \"doing with fewer resources\" under conditions of \"reduced performance\".\nNonetheless, enhancing the mutualization of infrastructure can reduce cluster\nsizes (through consolidation) and improve energy efficiency, with gains related\nto the accepted performance trade-off, a situation potentially more socially\nacceptable than eliminating services. We review the current state of the art,\nidentify challenges and opportunities, propose interpretations of Time-Shared\nComputing, and outline key research directions.", "comment": "Post-proceedings paper presented at LIMITS 2025: 11th Workshop on\n  Computing within Limits, 2025-06-26/27, Online", "pdf_url": "http://arxiv.org/pdf/2507.19287v2", "cate": "cs.DC", "date": "2025-07-25", "updated": "2025-07-28"}
{"id": "2507.01061", "title": "Epitome: Pioneering an Experimental Platform for AI-Social Science Integration", "authors": ["Jingjing Qu", "Kejia Hu", "Jun Zhu", "Wenhao Li", "Teng Wang", "Zhiyun Chen", "Yulei Ye", "Chaochao Lu", "Aimin Zhou", "Xiangfeng Wang", "James Evans"], "categories": ["cs.CY", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      18 pages, 5figures", "url": "http://arxiv.org/abs/2507.01061v2", "summary": "The integration of Large Language Models (LLMs) into social science\nexperiments represents a transformative approach to understanding human-AI\ninteractions and their societal impacts. We introduce Epitome, the world's\nfirst open experimental platform dedicated to the deep integration of\nartificial intelligence and social science. Rooted in theoretical foundations\nfrom management, communication studies, sociology, psychology, and ethics,\nEpitome focuses on the interactive impacts of AI on individuals, organizations,\nand society during its real-world deployment. It constructs a theoretical\nsupport system through cross-disciplinary experiments. The platform offers a\none-stop comprehensive experimental solution spanning \"foundation\nmodels-complex application development-user feedback\" through seven core\nmodules, while embedding the classical \"control-comparison-comparative causal\nlogic\" of social science experiments into multilevel human-computer interaction\nenvironments, including dialogues, group chats, and multi-agent virtual\nscenarios. With its canvas-style, user-friendly interface, Epitome enables\nresearchers to easily design and run complex experimental scenarios,\nfacilitating systematic investigations into the social impacts of AI and\nexploration of integrated solutions.To demonstrate its capabilities, we\nreplicated three seminal social science experiments involving LLMs, showcasing\nEpitome's potential to streamline complex experimental designs and produce\nrobust results, suitable for publishing in the top selective journals. Our\nfindings highlight the platform's utility in enhancing the efficiency and\nquality of human-AI interactions, providing valuable insights into the societal\nimplications of AI technologies. Epitome thus offers a powerful tool for\nadvancing interdisciplinary research at the intersection of AI and social\nscience, with potential applications in policy-making, ...", "comment": "18 pages, 5figures", "pdf_url": "http://arxiv.org/pdf/2507.01061v2", "cate": "cs.CY", "date": "2025-06-30", "updated": "2025-07-26"}
{"id": "2507.19707", "title": "CDA-SimBoost: A Unified Framework Bridging Real Data and Simulation for Infrastructure-Based CDA Systems", "authors": ["Zhaoliang Zheng", "Xu Han", "Yuxin Bao", "Yun Zhang", "Johnson Liu", "Zonglin Meng", "Xin Xia", "Jiaqi Ma"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19707v1", "summary": "Cooperative Driving Automation (CDA) has garnered increasing research\nattention, yet the role of intelligent infrastructure remains insufficiently\nexplored. Existing solutions offer limited support for addressing long-tail\nchallenges, real-synthetic data fusion, and heterogeneous sensor management.\nThis paper introduces CDA-SimBoost, a unified framework that constructs\ninfrastructure-centric simulation environments from real-world data.\nCDA-SimBoost consists of three main components: a Digital Twin Builder for\ngenerating high-fidelity simulator assets based on sensor and HD map data,\nOFDataPip for processing both online and offline data streams, and\nOpenCDA-InfraX, a high-fidelity platform for infrastructure-focused simulation.\nThe system supports realistic scenario construction, rare event synthesis, and\nscalable evaluation for CDA research. With its modular architecture and\nstandardized benchmarking capabilities, CDA-SimBoost bridges real-world\ndynamics and virtual environments, facilitating reproducible and extensible\ninfrastructure-driven CDA studies. All resources are publicly available at\nhttps://github.com/zhz03/CDA-SimBoost", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19707v1", "cate": "eess.SY", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.19984", "title": "Dependability Theory-based Statistical QoS Provisioning of Fluid Antenna Systems", "authors": ["Irfan Muhammad", "Priyadarshi Mukherjee", "Wee Kiat New", "Hirley Alves", "Ioannis Krikidis", "Kai-Kit Wong"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19984v1", "summary": "Fluid antenna systems (FAS) have recently emerged as a promising technology\nfor next-generation wireless networks, offering real-time spatial\nreconfiguration to enhance reliability, throughput, and energy efficiency.\nNevertheless, existing studies often overlook the temporal dynamics of channel\nfading and their implications for mission-critical operations. In this paper,\nwe propose a dependability-theoretic framework for statistical\nquality-of-service (QoS) provisioning of FAS under finite blocklength (FBL)\nconstraints. Specifically, we derive new closed-form expressions for the\nlevel-crossing rate (LCR) and average fade duration (AFD) of an $N$-port FAS\nover Nakagami-$m$ fading channels. Leveraging these second-order statistics, we\ndefine two key dependability metrics such as mission reliability and mean\ntime-to-first-failure (MTTFF), to quantify the probability of uninterrupted\noperation over a defined mission duration. We further extend the classical\neffective capacity (EC) concept to incorporate mission reliability in the FBL\nregime, yielding a mission EC (mEC). To capture energy efficiency under bursty\ntraffic and latency constraints, we also develop the mission effective energy\nefficiency (mEEE) metric and formulate its maximization as a non-convex\nfractional optimization problem. This problem is then solved via a modified\nDinkelbach's method with an embedded line search. Extensive simulations uncover\ncritical trade-offs among port count, QoS exponent, signal-to-noise ratio, and\nmission duration, offering insights for the design of ultra-reliable,\nlow-latency, and energy-efficient industrial internet-of-things (IIoT) systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19984v1", "cate": "eess.SP", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19843", "title": "Hybrid Deep Learning and Handcrafted Feature Fusion for Mammographic Breast Cancer Classification", "authors": ["Maximilian Tschuchnig", "Michael Gadermayr", "Khalifa Djemal"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted at IPTA2025", "url": "http://arxiv.org/abs/2507.19843v1", "summary": "Automated breast cancer classification from mammography remains a significant\nchallenge due to subtle distinctions between benign and malignant tissue. In\nthis work, we present a hybrid framework combining deep convolutional features\nfrom a ResNet-50 backbone with handcrafted descriptors and transformer-based\nembeddings. Using the CBIS-DDSM dataset, we benchmark our ResNet-50 baseline\n(AUC: 78.1%) and demonstrate that fusing handcrafted features with deep\nResNet-50 and DINOv2 features improves AUC to 79.6% (setup d1), with a peak\nrecall of 80.5% (setup d1) and highest F1 score of 67.4% (setup d1). Our\nexperiments show that handcrafted features not only complement deep\nrepresentations but also enhance performance beyond transformer-based\nembeddings. This hybrid fusion approach achieves results comparable to\nstate-of-the-art methods while maintaining architectural simplicity and\ncomputational efficiency, making it a practical and effective solution for\nclinical decision support.", "comment": "Accepted at IPTA2025", "pdf_url": "http://arxiv.org/pdf/2507.19843v1", "cate": "eess.IV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20023", "title": "Binaural Speech Enhancement Using Complex Convolutional Recurrent Networks", "authors": ["Vikas Tokala", "Eric Grinstein", "Mike Brookes", "Simon Doclo", "Jesper Jensen", "Patrick A. Naylor"], "categories": ["eess.AS", "eess.SP"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20023v1", "summary": "From hearing aids to augmented and virtual reality devices, binaural speech\nenhancement algorithms have been established as state-of-the-art techniques to\nimprove speech intelligibility and listening comfort. In this paper, we present\nan end-to-end binaural speech enhancement method using a complex recurrent\nconvolutional network with an encoder-decoder architecture and a complex LSTM\nrecurrent block placed between the encoder and decoder. A loss function that\nfocuses on the preservation of spatial information in addition to speech\nintelligibility improvement and noise reduction is introduced. The network\nestimates individual complex ratio masks for the left and right-ear channels of\na binaural hearing device in the time-frequency domain. We show that, compared\nto other baseline algorithms, the proposed method significantly improves the\nestimated speech intelligibility and reduces the noise while preserving the\nspatial information of the binaural signals in acoustic situations with a\nsingle target speaker and isotropic noise of various types.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20023v1", "cate": "eess.AS", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2411.09524", "title": "FlowNav: Combining Flow Matching and Depth Priors for Efficient Navigation", "authors": ["Samiran Gode", "Abhijeet Nayak", "Débora N. P. Oliveira", "Michael Krawez", "Cordelia Schmid", "Wolfram Burgard"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to IROS'25. Previous version accepted at CoRL 2024 workshop on Learning Effective Abstractions for Planning (LEAP) and workshop on Differentiable Optimization Everywhere: Simulation, Estimation, Learning, and Control", "url": "http://arxiv.org/abs/2411.09524v3", "summary": "Effective robot navigation in unseen environments is a challenging task that\nrequires precise control actions at high frequencies. Recent advances have\nframed it as an image-goal-conditioned control problem, where the robot\ngenerates navigation actions using frontal RGB images. Current state-of-the-art\nmethods in this area use diffusion policies to generate these control actions.\nDespite their promising results, these models are computationally expensive and\nsuffer from weak perception. To address these limitations, we present FlowNav,\na novel approach that uses a combination of CFM and depth priors from\noff-the-shelf foundation models to learn action policies for robot navigation.\nFlowNav is significantly more accurate and faster at navigation and exploration\nthan state-of-the-art methods. We validate our contributions using real robot\nexperiments in multiple environments, demonstrating improved navigation\nreliability and accuracy. Code and trained models are publicly available.", "comment": "Accepted to IROS'25. Previous version accepted at CoRL 2024 workshop\n  on Learning Effective Abstractions for Planning (LEAP) and workshop on\n  Differentiable Optimization Everywhere: Simulation, Estimation, Learning, and\n  Control", "pdf_url": "http://arxiv.org/pdf/2411.09524v3", "cate": "cs.RO", "date": "2024-11-14", "updated": "2025-07-28"}
{"id": "2507.19586", "title": "Mitigating Geospatial Knowledge Hallucination in Large Language Models: Benchmarking and Dynamic Factuality Aligning", "authors": ["Shengyuan Wang", "Jie Feng", "Tianhui Liu", "Dan Pei", "Yong Li"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      19 pages, 9 figures", "url": "http://arxiv.org/abs/2507.19586v1", "summary": "Large language models (LLMs) possess extensive world knowledge, including\ngeospatial knowledge, which has been successfully applied to various geospatial\ntasks such as mobility prediction and social indicator prediction. However,\nLLMs often generate inaccurate geospatial knowledge, leading to geospatial\nhallucinations (incorrect or inconsistent representations of geospatial\ninformation) that compromise their reliability. While the phenomenon of general\nknowledge hallucination in LLMs has been widely studied, the systematic\nevaluation and mitigation of geospatial hallucinations remain largely\nunexplored. To address this gap, we propose a comprehensive evaluation\nframework for geospatial hallucinations, leveraging structured geospatial\nknowledge graphs for controlled assessment. Through extensive evaluation across\n20 advanced LLMs, we uncover the hallucinations in their geospatial knowledge.\nBuilding on these insights, we introduce a dynamic factuality aligning method\nbased on Kahneman-Tversky Optimization (KTO) to mitigate geospatial\nhallucinations in LLMs, leading to a performance improvement of over 29.6% on\nthe proposed benchmark. Extensive experimental results demonstrate the\neffectiveness of our benchmark and learning algorithm in enhancing the\ntrustworthiness of LLMs in geospatial knowledge and reasoning tasks.", "comment": "19 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.19586v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2504.07840", "title": "Understanding Learner-LLM Chatbot Interactions and the Impact of Prompting Guidelines", "authors": ["Cansu Koyuturk", "Emily Theophilou", "Sabrina Patania", "Gregor Donabauer", "Andrea Martinenghi", "Chiara Antico", "Alessia Telari", "Alessia Testa", "Sathya Bursic", "Franca Garzotto", "Davinia Hernandez-Leo", "Udo Kruschwitz", "Davide Taibi", "Simona Amenta", "Martin Ruskov", "Dimitri Ognibene"], "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Long paper accepted for AIED 2025, the 26th International Conference on Artificial Intelligence in Education, July 22 - 26, 2025, Palermo, Italy", "url": "http://arxiv.org/abs/2504.07840v3", "summary": "Large Language Models (LLMs) have transformed human-computer interaction by\nenabling natural language-based communication with AI-powered chatbots. These\nmodels are designed to be intuitive and user-friendly, allowing users to\narticulate requests with minimal effort. However, despite their accessibility,\nstudies reveal that users often struggle with effective prompting, resulting in\ninefficient responses. Existing research has highlighted both the limitations\nof LLMs in interpreting vague or poorly structured prompts and the difficulties\nusers face in crafting precise queries. This study investigates learner-AI\ninteractions through an educational experiment in which participants receive\nstructured guidance on effective prompting. We introduce and compare three\ntypes of prompting guidelines: a task-specific framework developed through a\nstructured methodology and two baseline approaches. To assess user behavior and\nprompting efficacy, we analyze a dataset of 642 interactions from 107 users.\nUsing Von NeuMidas, an extended pragmatic annotation schema for LLM interaction\nanalysis, we categorize common prompting errors and identify recurring\nbehavioral patterns. We then evaluate the impact of different guidelines by\nexamining changes in user behavior, adherence to prompting strategies, and the\noverall quality of AI-generated responses. Our findings provide a deeper\nunderstanding of how users engage with LLMs and the role of structured\nprompting guidance in enhancing AI-assisted communication. By comparing\ndifferent instructional frameworks, we offer insights into more effective\napproaches for improving user competency in AI interactions, with implications\nfor AI literacy, chatbot usability, and the design of more responsive AI\nsystems.", "comment": "Long paper accepted for AIED 2025, the 26th International Conference\n  on Artificial Intelligence in Education, July 22 - 26, 2025, Palermo, Italy", "pdf_url": "http://arxiv.org/pdf/2504.07840v3", "cate": "cs.HC", "date": "2025-04-10", "updated": "2025-07-27"}
{"id": "2507.20008", "title": "Robust Taxi Fare Prediction Under Noisy Conditions: A Comparative Study of GAT, TimesNet, and XGBoost", "authors": ["Padmavathi Moorthy"], "categories": ["cs.LG", "cs.AI", "62M10 (Primary), 62H30 (Secondary)", "I.2.6; I.5.1; I.2.10"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 9 figures, prepared with LaTeX, GitHub link: this https URL", "url": "http://arxiv.org/abs/2507.20008v1", "summary": "Precise fare prediction is crucial in ride-hailing platforms and urban\nmobility systems. This study examines three machine learning models-Graph\nAttention Networks (GAT), XGBoost, and TimesNet to evaluate their predictive\ncapabilities for taxi fares using a real-world dataset comprising over 55\nmillion records. Both raw (noisy) and denoised versions of the dataset are\nanalyzed to assess the impact of data quality on model performance. The study\nevaluated the models along multiple axes, including predictive accuracy,\ncalibration, uncertainty estimation, out-of-distribution (OOD) robustness, and\nfeature sensitivity. We also explore pre-processing strategies, including KNN\nimputation, Gaussian noise injection, and autoencoder-based denoising. The\nstudy reveals critical differences between classical and deep learning models\nunder realistic conditions, offering practical guidelines for building robust\nand scalable models in urban fare prediction systems.", "comment": "10 pages, 9 figures, prepared with LaTeX, GitHub link:\n  https://github.com/padmavathi026/Smart-Fare-Prediction", "pdf_url": "http://arxiv.org/pdf/2507.20008v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2506.09550", "title": "Automated Synthesis of Formally Verified Multi-Abstraction Function Summaries", "authors": ["Fanpeng Yang", "Xu Ma", "Shuling Wang", "Xiong Xu", "Qinxiang Cao", "Naijun Zhan", "Xiaofeng Li", "Bin Gu"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.09550v3", "summary": "Function summaries, which characterize the behavior of code segments\n(typically functions) through preconditions and postconditions, are essential\nfor understanding, reusing, and verifying software, particularly in\nsafety-critical domains like aerospace embedded systems. However, these\nmission-critical legacy code serving as a valuable reused asset often lacks\nformal specifications. It is challenging to automatically generate function\nsummaries for C programs, due to the existence of complex features such as\nloops, nested function calls, pointer aliasing, and so on. Moreover, function\nsummaries should support multiple abstraction levels to meet diverse\nrequirements, e.g. precise summaries capturing full functionality for formal\nverification and intuitive summaries for human understanding.\n  To address these challenges, we first propose a novel framework that combines\nsymbolic execution, large language models (LLMs), and formal verification to\ngenerate Relatively Strongest Postconditions (RSPs) and build function\nsummaries that fully capture program behavior. Our approach leverages VST-A's\nsymbolic execution to precisely track program execution paths and state\ntransitions, employs LLMs to infer loop invariants based on predefined\ntemplates, and uses Frama-C to guarantee soundness of generated summaries in an\niterative refinement loop. Furthermore, from generated RSPs, we automatically\nsynthesize strongest non-redundant postconditions expressed within given domain\nspecific language. We compare our approach with existing work through extensive\nexperiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.09550v3", "cate": "cs.SE", "date": "2025-06-11", "updated": "2025-07-26"}
{"id": "2507.17571", "title": "Bounds and Equivalence of Skew Polycyclic Codes over Finite Fields", "authors": ["Hassan Ou-azzou", "Anna-Lena Horlemann", "Nuh Aydin"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.17571v2", "summary": "We study skew polycyclic codes over a finite field $\\mathbb{F}_q$, associated\nwith a skew polynomial $f(x) \\in \\mathbb{F}_q[x;\\sigma]$, where $\\sigma$ is an\nautomorphism of $\\mathbb{F}_q$. We start by proving the Roos-like bound for\nboth the Hamming and the rank metric for this class of codes. Next, we focus on\nthe Hamming and rank equivalence between two classes of polycyclic codes by\nintroducing an equivalence relation and describing its equivalence classes.\nFinally, we present examples that illustrate applications of the theory\ndeveloped in this paper.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.17571v2", "cate": "cs.IT", "date": "2025-07-23", "updated": "2025-07-26"}
{"id": "2410.23745", "title": "Syno: Structured Synthesis for Neural Operators", "authors": ["Yongqi Zhuo", "Zhengyuan Su", "Chenggang Zhao", "Mingyu Gao"], "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.PF"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.23745v2", "summary": "The desires for better prediction accuracy and higher execution performance\nin neural networks never end. Neural architecture search (NAS) and tensor\ncompilers are two popular techniques to optimize these two goals, but they are\nboth limited to composing or optimizing existing manually designed operators\nrather than coming up with completely new designs. In this work, we explore the\nless studied direction of neural operator synthesis, which aims to\nautomatically and efficiently discover novel neural operators with better\naccuracy and/or speed. We develop an end-to-end framework Syno, to realize\npractical neural operator synthesis. Syno makes use of a novel set of\nfine-grained primitives defined on tensor dimensions, which ensure various\ndesired properties to ease model training, and also enable expression\ncanonicalization techniques to avoid redundant candidates during search. Syno\nfurther adopts a novel guided synthesis flow to obtain valid operators matched\nwith the specified input/output dimension sizes, and leverages efficient\nstochastic tree search algorithms to quickly explore the design space. We\ndemonstrate that Syno discovers better operators with average speedups of\n$1.37\\times$ to $2.06\\times$ on various hardware and compiler choices, while\nkeeping less than 1% accuracy loss even on NAS-optimized models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.23745v2", "cate": "cs.LG", "date": "2024-10-31", "updated": "2025-07-27"}
{"id": "2507.15916", "title": "Verifying International Agreements on AI: Six Layers of Verification for Rules on Large-Scale AI Development and Deployment", "authors": ["Mauricio Baker", "Gabriel Kulp", "Oliver Marks", "Miles Brundage", "Lennart Heim"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      80 pages, summary included", "url": "http://arxiv.org/abs/2507.15916v2", "summary": "The risks of frontier AI may require international cooperation, which in turn\nmay require verification: checking that all parties follow agreed-on rules. For\ninstance, states might need to verify that powerful AI models are widely\ndeployed only after their risks to international security have been evaluated\nand deemed manageable. However, research on AI verification could benefit from\ngreater clarity and detail. To address this, this report provides an in-depth\noverview of AI verification, intended for both policy professionals and\ntechnical researchers. We present novel conceptual frameworks, detailed\nimplementation options, and key R&D challenges. These draw on existing\nliterature, expert interviews, and original analysis, all within the scope of\nconfidentially overseeing AI development and deployment that uses thousands of\nhigh-end AI chips. We find that states could eventually verify compliance by\nusing six largely independent verification approaches with substantial\nredundancy: (1) built-in security features in AI chips; (2-3) separate\nmonitoring devices attached to AI chips; and (4-6) personnel-based mechanisms,\nsuch as whistleblower programs. While promising, these approaches require\nguardrails to protect against abuse and power concentration, and many of these\ntechnologies have yet to be built or stress-tested. To enable states to\nconfidently verify compliance with rules on large-scale AI development and\ndeployment, the R&D challenges we list need significant progress.", "comment": "80 pages, summary included", "pdf_url": "http://arxiv.org/pdf/2507.15916v2", "cate": "cs.CY", "date": "2025-07-21", "updated": "2025-07-25"}
{"id": "2507.19838", "title": "Star Tracker Misalignment Compensation in Deep Space Navigation Through Model-Based Estimation", "authors": ["Ridma Ganganath", "Simone Servadio", "David Lee"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      20 pages, 7 figures", "url": "http://arxiv.org/abs/2507.19838v1", "summary": "This work presents a novel adaptive framework for simultaneously estimating\nspacecraft attitude and sensor misalignment. Uncorrected star tracker\nmisalignment can introduce significant pointing errors that compromise mission\nobjectives in GPS-denied environments. To address this challenge, the proposed\narchitecture integrates a Bayesian Multiple-Model Adaptive Estimation (MMAE)\nframework operating over an N x N x N 3D hypothesis grid. Each hypothesis\nemploys a 9-state Multiplicative Extended Kalman Filter (MEKF) to estimate\nattitude, angular velocity, and gyroscope bias using TRIAD-based vector\nmeasurements. A key contribution is the development of a robust grid refinement\nstrategy that uses hypothesis diversity and weighted-mean grid centering to\nprevent the premature convergence commonly encountered in classical, dominant\nmodel-based refinement triggers. Extensive Monte Carlo simulations demonstrate\nthat the proposed method reduces the final misalignment RMSE relative to\nclassical approaches, achieving arcsecond-level accuracy. The resulting\nframework offers a computationally tractable and statistically robust solution\nfor in-flight calibration, enhancing the navigational autonomy of\nresource-constrained spacecraft.", "comment": "20 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.19838v1", "cate": "eess.SY", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19996", "title": "DOA Estimation via Optimal Weighted Low-Rank Matrix Completion", "authors": ["Saeed Razavikia", "Mohammad Bokaei", "Arash Amini", "Stefano Rini", "Carlo Fischione"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19996v1", "summary": "This paper presents a novel method for estimating the direction of arrival\n(DOA) for a non-uniform and sparse linear sensor array using the weighted\nlifted structure low-rank matrix completion. The proposed method uses a single\nsnapshot sample in which a single array of data is observed. The method is\nrooted in a weighted lifted-structured low-rank matrix recovery framework. The\nmethod involves four key steps: (i) lifting the antenna samples to form a\nlow-rank stature, then (ii) designing left and right weight matrices to reflect\nthe sample informativeness, (iii) estimating a noise-free uniform array output\nthrough completion of the weighted lifted samples, and (iv) obtaining the DOAs\nfrom the restored uniform linear array samples.\n  We study the complexity of steps (i) to (iii) above, where we analyze the\nrequired sample for the array interpolation of step (iii) for DOA estimation.\nWe demonstrate that the proposed choice of weight matrices achieves a\nnear-optimal sample complexity. This complexity aligns with the problem's\ndegree of freedom, equivalent to the number of DOAs adjusted for logarithmic\nfactors. Numerical evaluations show the proposed method's superiority against\nthe non-weighted counterpart and atomic norm minimization-based methods.\nNotably, our proposed method significantly improves, with approximately a 10 dB\nreduction in normalized mean-squared error over the non-weighted method at\nlow-noise conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19996v1", "cate": "eess.SP", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19970", "title": "SkinDualGen: Prompt-Driven Diffusion for Simultaneous Image-Mask Generation in Skin Lesions", "authors": ["Zhaobin Xu"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19970v1", "summary": "Medical image analysis plays a pivotal role in the early diagnosis of\ndiseases such as skin lesions. However, the scarcity of data and the class\nimbalance significantly hinder the performance of deep learning models. We\npropose a novel method that leverages the pretrained Stable Diffusion-2.0 model\nto generate high-quality synthetic skin lesion images and corresponding\nsegmentation masks. This approach augments training datasets for classification\nand segmentation tasks. We adapt Stable Diffusion-2.0 through domain-specific\nLow-Rank Adaptation (LoRA) fine-tuning and joint optimization of\nmulti-objective loss functions, enabling the model to simultaneously generate\nclinically relevant images and segmentation masks conditioned on textual\ndescriptions in a single step. Experimental results show that the generated\nimages, validated by FID scores, closely resemble real images in quality. A\nhybrid dataset combining real and synthetic data markedly enhances the\nperformance of classification and segmentation models, achieving substantial\nimprovements in accuracy and F1-score of 8% to 15%, with additional positive\ngains in other key metrics such as the Dice coefficient and IoU. Our approach\noffers a scalable solution to address the challenges of medical imaging data,\ncontributing to improved accuracy and reliability in diagnosing rare diseases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19970v1", "cate": "eess.IV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20027", "title": "Binaural Localization Model for Speech in Noise", "authors": ["Vikas Tokala", "Eric Grinstein", "Rory Brooks", "Mike Brookes", "Simon Doclo", "Jesper Jensen", "Patrick A. Naylor"], "categories": ["eess.AS", "eess.SP"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20027v1", "summary": "Binaural acoustic source localization is important to human listeners for\nspatial awareness, communication and safety. In this paper, an end-to-end\nbinaural localization model for speech in noise is presented. A lightweight\nconvolutional recurrent network that localizes sound in the frontal azimuthal\nplane for noisy reverberant binaural signals is introduced. The model\nincorporates additive internal ear noise to represent the frequency-dependent\nhearing threshold of a typical listener. The localization performance of the\nmodel is compared with the steered response power algorithm, and the use of the\nmodel as a measure of interaural cue preservation for binaural speech\nenhancement methods is studied. A listening test was performed to compare the\nperformance of the model with human localization of speech in noisy conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20027v1", "cate": "eess.AS", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2412.12776", "title": "Physical simulation of Marsupial UAV-UGV Systems Connected by a Variable-Length Hanging Tether", "authors": ["Jose Enrique Maese", "Fernando Caballero", "Luis Merino"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.12776v3", "summary": "This paper presents a simulation framework able of modeling the dynamics of a\nhanging tether with adjustable length, connecting a UAV to a UGV. The model\nincorporates the interaction between the UAV, UGV, and a winch, allowing for\ndynamic tether adjustments based on the relative motion of the robots. The\naccuracy and reliability of the simulator are assessed through extensive\nexperiments, including comparisons with real-world experiment, to evaluate its\nability to reproduce the complex tether dynamics observed in physical\ndeployments. The results demonstrate that the simulation closely aligns with\nreal-world behavior, particularly in constrained environments where tether\neffects are significant. This work provides a validated tool for studying\ntethered robotic systems, offering valuable insights into their motion dynamics\nand control strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.12776v3", "cate": "cs.RO", "date": "2024-12-17", "updated": "2025-07-28"}
{"id": "2507.19595", "title": "Efficient Attention Mechanisms for Large Language Models: A Survey", "authors": ["Yutao Sun", "Zhenyu Li", "Yike Zhang", "Tengyu Pan", "Bowen Dong", "Yuyi Guo", "Jianyong Wang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      work in progress", "url": "http://arxiv.org/abs/2507.19595v1", "summary": "Transformer-based architectures have become the prevailing backbone of large\nlanguage models. However, the quadratic time and memory complexity of\nself-attention remains a fundamental obstacle to efficient long-context\nmodeling. To address this limitation, recent research has introduced two\nprincipal categories of efficient attention mechanisms. Linear attention\nmethods achieve linear complexity through kernel approximations, recurrent\nformulations, or fastweight dynamics, thereby enabling scalable inference with\nreduced computational overhead. Sparse attention techniques, in contrast, limit\nattention computation to selected subsets of tokens based on fixed patterns,\nblock-wise routing, or clustering strategies, enhancing efficiency while\npreserving contextual coverage. This survey provides a systematic and\ncomprehensive overview of these developments, integrating both algorithmic\ninnovations and hardware-level considerations. In addition, we analyze the\nincorporation of efficient attention into largescale pre-trained language\nmodels, including both architectures built entirely on efficient attention and\nhybrid designs that combine local and global components. By aligning\ntheoretical foundations with practical deployment strategies, this work aims to\nserve as a foundational reference for advancing the design of scalable and\nefficient language models.", "comment": "work in progress", "pdf_url": "http://arxiv.org/pdf/2507.19595v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2504.13887", "title": "AI as a deliberative partner fosters intercultural empathy for Americans but fails for Latin American participants", "authors": ["Isabel Villanueva", "Tara Bobinac", "Binwei Yao", "Junjie Hu", "Kaiping Chen"], "categories": ["cs.HC", "cs.CL", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.13887v2", "summary": "Despite increasing AI chatbot deployment in public discourse, empirical\nevidence on their capacity to foster intercultural empathy remains limited.\nThrough a randomized experiment, we assessed how different AI deliberation\napproaches--cross-cultural deliberation (presenting other-culture\nperspectives), own-culture deliberation (representing participants' own\nculture), and non-deliberative control--affect intercultural empathy across\nAmerican and Latin American participants. Cross-cultural deliberation increased\nintercultural empathy among American participants through positive emotional\nengagement, but produced no such effects for Latin American participants, who\nperceived AI responses as culturally inauthentic despite explicit prompting to\nrepresent their cultural perspectives. Our analysis of participant-driven\nfeedback, where users directly flagged and explained culturally inappropriate\nAI responses, revealed systematic gaps in AI's representation of Latin American\ncontexts that persist despite sophisticated prompt engineering. These findings\ndemonstrate that current approaches to AI cultural alignment--including\nlinguistic adaptation and explicit cultural prompting--cannot fully address\ndeeper representational asymmetries in AI systems. Our work advances both\ndeliberation theory and AI alignment research by revealing how the same AI\nsystem can simultaneously promote intercultural understanding for one cultural\ngroup while failing for another, with critical implications for designing\nequitable AI systems for cross-cultural democratic discourse.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.13887v2", "cate": "cs.HC", "date": "2025-04-04", "updated": "2025-07-26"}
{"id": "2507.20016", "title": "FedSWA: Improving Generalization in Federated Learning with Highly Heterogeneous Data via Momentum-Based Stochastic Controlled Weight Averaging", "authors": ["Liu junkang", "Yuanyuan Liu", "Fanhua Shang", "Hongying Liu", "Jin Liu", "Wei Feng"], "categories": ["cs.LG", "cs.AI", "68T05", "I.2.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      icml 2025", "url": "http://arxiv.org/abs/2507.20016v1", "summary": "For federated learning (FL) algorithms such as FedSAM, their generalization\ncapability is crucial for real-word applications. In this paper, we revisit the\ngeneralization problem in FL and investigate the impact of data heterogeneity\non FL generalization. We find that FedSAM usually performs worse than FedAvg in\nthe case of highly heterogeneous data, and thus propose a novel and effective\nfederated learning algorithm with Stochastic Weight Averaging (called\n\\texttt{FedSWA}), which aims to find flatter minima in the setting of highly\nheterogeneous data. Moreover, we introduce a new momentum-based stochastic\ncontrolled weight averaging FL algorithm (\\texttt{FedMoSWA}), which is designed\nto better align local and global models.\n  Theoretically, we provide both convergence analysis and generalization bounds\nfor \\texttt{FedSWA} and \\texttt{FedMoSWA}. We also prove that the optimization\nand generalization errors of \\texttt{FedMoSWA} are smaller than those of their\ncounterparts, including FedSAM and its variants. Empirically, experimental\nresults on CIFAR10/100 and Tiny ImageNet demonstrate the superiority of the\nproposed algorithms compared to their counterparts. Open source code at:\nhttps://github.com/junkangLiu0/FedSWA.", "comment": "icml 2025", "pdf_url": "http://arxiv.org/pdf/2507.20016v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2506.17095", "title": "Software Fairness Testing in Practice", "authors": ["Ronnie de Souza Santos", "Matheus de Morais Leca", "Reydne Santos", "Cleyton Magalhaes"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.17095v2", "summary": "Software testing ensures that a system functions correctly, meets specified\nrequirements, and maintains high quality. As artificial intelligence and\nmachine learning (ML) technologies become integral to software systems, testing\nhas evolved to address their unique complexities. A critical advancement in\nthis space is fairness testing, which identifies and mitigates biases in AI\napplications to promote ethical and equitable outcomes. Despite extensive\nacademic research on fairness testing, including test input generation, test\noracle identification, and component testing, practical adoption remains\nlimited. Industry practitioners often lack clear guidelines and effective tools\nto integrate fairness testing into real-world AI development. This study\ninvestigates how software professionals test AI-powered systems for fairness\nthrough interviews with 22 practitioners working on AI and ML projects. Our\nfindings highlight a significant gap between theoretical fairness concepts and\nindustry practice. While fairness definitions continue to evolve, they remain\ndifficult for practitioners to interpret and apply. The absence of\nindustry-aligned fairness testing tools further complicates adoption,\nnecessitating research into practical, accessible solutions. Key challenges\ninclude data quality and diversity, time constraints, defining effective\nmetrics, and ensuring model interoperability. These insights emphasize the need\nto bridge academic advancements with actionable strategies and tools, enabling\npractitioners to systematically address fairness in AI systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.17095v2", "cate": "cs.SE", "date": "2025-06-20", "updated": "2025-07-27"}
{"id": "2507.17893", "title": "Action-List Reinforcement Learning Syndrome Decoding for Binary Linear Block Codes", "authors": ["Milad Taghipour", "Bane Vasic"], "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.17893v2", "summary": "This paper explores the application of reinforcement learning techniques to\nenhance the performance of decoding of linear block codes based on flipping\nbits and finding optimal decisions. We describe the methodology for mapping the\niterative decoding process into Markov Decision Processes (MDPs) and propose\ndifferent methods to reduce the number of states in the MDP. A truncated MDP is\nproposed to reduce the number of states in the MDP by learning a Hamming ball\nwith a specified radius around codewords. We then propose a general scheme for\nreinforcement learning based decoders applicable to any class of codes to\nimprove the performance of decoders. We call this scheme an action-list\ndecoding. We design an action-list decoder based on the Deep-Q network values\nthat substantially enhance performance. We also get benefit of automorphism\ngroup of code to further improve the code performance. Additionally, we propose\na feedback-based method to exploit and enhance the performance of existing\nhigh-performing decoders by applying reinforcement learning algorithms after\nthe existing decoders. These approaches effectively reduces the complexity of\nthe reinforcement learning block. Finally, we present experimental results for\nthe Low-Density Parity Check (LDPC) codes over the Binary Symmetric Channel\n(BSC) to demonstrate the efficiency of the proposed methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.17893v2", "cate": "cs.IT", "date": "2025-07-23", "updated": "2025-07-28"}
{"id": "2507.14111", "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning", "authors": ["Xiaoya Li", "Xiaofei Sun", "Albert Wang", "Jiwei Li", "Chris Shum"], "categories": ["cs.AI", "cs.DC", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Project Page: this https URL", "url": "http://arxiv.org/abs/2507.14111v4", "summary": "The exponential growth in demand for GPU computing resources has created an\nurgent need for automated CUDA optimization strategies. While recent advances\nin LLMs show promise for code generation, current SOTA models achieve low\nsuccess rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an\nautomated reinforcement learning framework for CUDA optimization that employs a\nnovel contrastive RL algorithm.\n  CUDA-L1 achieves significant performance improvements on the CUDA\noptimization task: trained on NVIDIA A100, it delivers an average speedup of\nx3.12 with a median speedup of x1.42 across all 250 CUDA kernels of\nKernelBench, with peak speedups reaching x120. Furthermore, the model also\ndemonstrates portability across GPU architectures, achieving average speedups\nof x3.12 on L40, x2.50 on RTX 3090, x2.39 on H100, and x2.37 on H20 despite\nbeing optimized specifically for A100.\n  The capabilities of CUDA-L1 demonstrate that, RL can transform an initially\npoor-performing LLM into an effective CUDA optimizer through speedup-based\nreward signals alone, without human expertise or domain knowledge. This\nparadigm opens possibilities for automated optimization of CUDA operations, and\nholds promise to substantially promote GPU efficiency and alleviate the rising\npressure on GPU computing resources. We also identify important challenges\nposed by training RL models for tasks like CUDA development, where RL often\nlearns to exploit loopholes in reward functions rather than solve the intended\noptimization problems. By identifying these failure modes and analyzing their\nroot causes, we develop practical methods for creating more robust training\nprocedures that prevent reward hacking.", "comment": "Project Page: https://deepreinforce-ai.github.io/cudal1_blog/", "pdf_url": "http://arxiv.org/pdf/2507.14111v4", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-28"}
{"id": "2401.16744", "title": "ShaRP: Explaining Rankings and Preferences with Shapley Values", "authors": ["Venetia Pliatsika", "Joao Fonseca", "Kateryna Akhynko", "Ivan Shevchenko", "Julia Stoyanovich"], "categories": ["cs.AI", "cs.CY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted in VLDB", "url": "http://arxiv.org/abs/2401.16744v5", "summary": "Algorithmic decisions in critical domains such as hiring, college admissions,\nand lending are often based on rankings. Given the impact of these decisions on\nindividuals, organizations, and population groups, it is essential to\nunderstand them - to help individuals improve their ranking position, design\nbetter ranking procedures, and ensure legal compliance. In this paper, we argue\nthat explainability methods for classification and regression, such as SHAP,\nare insufficient for ranking tasks, and present ShaRP - Shapley Values for\nRankings and Preferences - a framework that explains the contributions of\nfeatures to various aspects of a ranked outcome.\n  ShaRP computes feature contributions for various ranking-specific profit\nfunctions, such as rank and top-k, and also includes a novel Shapley\nvalue-based method for explaining pairwise preference outcomes. We provide a\nflexible implementation of ShaRP, capable of efficiently and comprehensively\nexplaining ranked and pairwise outcomes over tabular data, in score-based\nranking and learning-to-rank tasks. Finally, we develop a comprehensive\nevaluation methodology for ranking explainability methods, showing through\nqualitative, quantitative, and usability studies that our rank-aware QoIs offer\ncomplementary insights, scale effectively, and help users interpret ranked\noutcomes in practice.", "comment": "Accepted in VLDB", "pdf_url": "http://arxiv.org/pdf/2401.16744v5", "cate": "cs.AI", "date": "2024-01-30", "updated": "2025-07-28"}
{"id": "2507.19918", "title": "The Phantom of Davis-Wielandt Shell: A Unified Framework for Graphical Stability Analysis of MIMO LTI Systems", "authors": ["Ding Zhang", "Xiaokan Yang", "Axel Ringh", "Li Qiu"], "categories": ["eess.SY", "cs.SY", "math.OC", "math.RA", "93D25, 93B52, 93C05, 93C80"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      16 pages, 13 figures", "url": "http://arxiv.org/abs/2507.19918v1", "summary": "This paper presents a unified framework based on Davis-Wielandt (DW) shell\nfor graphical stability analysis of multi-input and multi-output linear\ntime-invariant feedback systems. Connections between DW shells and various\ngraphical descriptions, as well as gain and phase measures, are established\nthrough an intuitive geometric perspective. Within this framework, we examine\nthe relationships and relative conservatism among various separation\nconditions. A rotated Scaled Relative Graph (SRG) concept is proposed as a\nmixed gain-phase representation, from which a closed-loop stability criterion\nis derived and shown to be the least conservative among the existing 2-D\ngraphical conditions for bi-component feedback loops. We also propose a\nreliable algorithm for visualizing the rotated SRGs and include an example to\ndemonstrate the non-conservatism of the proposed condition.", "comment": "16 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.19918v1", "cate": "eess.SY", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20189", "title": "NeuroCLIP: A Multimodal Contrastive Learning Method for rTMS-treated Methamphetamine Addiction Analysis", "authors": ["Chengkai Wang", "Di Wu", "Yunsheng Liao", "Wenyao Zheng", "Ziyi Zeng", "Xurong Gao", "Hemmings Wu", "Zhoule Zhu", "Jie Yang", "Lihua Zhong", "Weiwei Cheng", "Yun-Hsuan Chen", "Mohamad Sawan"], "categories": ["eess.SP", "cs.AI", "cs.LG", "q-bio.NC"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20189v1", "summary": "Methamphetamine dependence poses a significant global health challenge, yet\nits assessment and the evaluation of treatments like repetitive transcranial\nmagnetic stimulation (rTMS) frequently depend on subjective self-reports, which\nmay introduce uncertainties. While objective neuroimaging modalities such as\nelectroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS)\noffer alternatives, their individual limitations and the reliance on\nconventional, often hand-crafted, feature extraction can compromise the\nreliability of derived biomarkers. To overcome these limitations, we propose\nNeuroCLIP, a novel deep learning framework integrating simultaneously recorded\nEEG and fNIRS data through a progressive learning strategy. This approach\noffers a robust and trustworthy biomarker for methamphetamine addiction.\nValidation experiments show that NeuroCLIP significantly improves\ndiscriminative capabilities among the methamphetamine-dependent individuals and\nhealthy controls compared to models using either EEG or only fNIRS alone.\nFurthermore, the proposed framework facilitates objective, brain-based\nevaluation of rTMS treatment efficacy, demonstrating measurable shifts in\nneural patterns towards healthy control profiles after treatment. Critically,\nwe establish the trustworthiness of the multimodal data-driven biomarker by\nshowing its strong correlation with psychometrically validated craving scores.\nThese findings suggest that biomarker derived from EEG-fNIRS data via NeuroCLIP\noffers enhanced robustness and reliability over single-modality approaches,\nproviding a valuable tool for addiction neuroscience research and potentially\nimproving clinical assessments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20189v1", "cate": "eess.SP", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20102", "title": "On Uncertainty Prediction for Deep-Learning-based Particle Image Velocimetry", "authors": ["Wei Wang", "Jeremiah Hu", "Jia Ai", "Yong Lee"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      This paper has been accepted for presentation at the 16th International Symposium on Particle Image Velocimetry (ISPIV 2025)", "url": "http://arxiv.org/abs/2507.20102v1", "summary": "Particle Image Velocimetry (PIV) is a widely used technique for flow\nmeasurement that traditionally relies on cross-correlation to track the\ndisplacement. Recent advances in deep learning-based methods have significantly\nimproved the accuracy and efficiency of PIV measurements. However, despite its\nimportance, reliable uncertainty quantification for deep learning-based PIV\nremains a critical and largely overlooked challenge. This paper explores three\nmethods for quantifying uncertainty in deep learning-based PIV: the Uncertainty\nneural network (UNN), Multiple models (MM), and Multiple transforms (MT). We\nevaluate the three methods across multiple datasets. The results show that all\nthree methods perform well under mild perturbations. Among the three evaluation\nmetrics, the UNN method consistently achieves the best performance, providing\naccurate uncertainty estimates and demonstrating strong potential for\nuncertainty quantification in deep learning-based PIV. This study provides a\ncomprehensive framework for uncertainty quantification in PIV, offering\ninsights for future research and practical implementation.", "comment": "This paper has been accepted for presentation at the 16th\n  International Symposium on Particle Image Velocimetry (ISPIV 2025)", "pdf_url": "http://arxiv.org/pdf/2507.20102v1", "cate": "eess.IV", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20530", "title": "Binaural Sound Event Localization and Detection based on HRTF Cues for Humanoid Robots", "authors": ["Gyeong-Tae Lee", "Hyeonuk Nam", "Yong-Hwa Park"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE/ACM TASLP", "url": "http://arxiv.org/abs/2507.20530v1", "summary": "This paper introduces Binaural Sound Event Localization and Detection\n(BiSELD), a task that aims to jointly detect and localize multiple sound events\nusing binaural audio, inspired by the spatial hearing mechanism of humans. To\nsupport this task, we present a synthetic benchmark dataset, called the\nBinaural Set, which simulates realistic auditory scenes using measured\nhead-related transfer functions (HRTFs) and diverse sound events. To\neffectively address the BiSELD task, we propose a new input feature\nrepresentation called the Binaural Time-Frequency Feature (BTFF), which encodes\ninteraural time difference (ITD), interaural level difference (ILD), and\nhigh-frequency spectral cues (SC) from binaural signals. BTFF is composed of\neight channels, including left and right mel-spectrograms, velocity-maps,\nSC-maps, and ITD-/ILD-maps, designed to cover different spatial cues across\nfrequency bands and spatial axes. A CRNN-based model, BiSELDnet, is then\ndeveloped to learn both spectro-temporal patterns and HRTF-based localization\ncues from BTFF. Experiments on the Binaural Set show that each BTFF sub-feature\nenhances task performance: V-map improves detection, ITD-/ILD-maps enable\naccurate horizontal localization, and SC-map captures vertical spatial cues.\nThe final system achieves a SELD error of 0.110 with 87.1% F-score and\n4.4{\\deg} localization error, demonstrating the effectiveness of the proposed\nframework in mimicking human-like auditory perception.", "comment": "Submitted to IEEE/ACM TASLP", "pdf_url": "http://arxiv.org/pdf/2507.20530v1", "cate": "eess.AS", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2412.16803", "title": "Modeling the Dynamics of Sub-Millisecond Electroadhesive Engagement and Release Times", "authors": ["Ahad M. Rauf", "Sean Follmer"], "categories": ["cs.RO", "cs.HC", "physics.app-ph"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This work has been published in Extreme Mechanics Letters", "url": "http://arxiv.org/abs/2412.16803v2", "summary": "Electroadhesive clutches are electrically controllable switchable adhesives\ncommonly used in soft robots and haptic user interfaces. They can form strong\nbonds to a wide variety of surfaces at low power consumption. However,\nelectroadhesive clutches in the literature engage to and release from\nsubstrates several orders of magnitude slower than a traditional electrostatic\nmodel would predict. Large release times, in particular, can limit\nelectroadhesion's usefulness in high-bandwidth applications. We develop a novel\nelectromechanical model for electroadhesion, factoring in polarization\ndynamics, the drive circuitry's rise and fall times, and contact mechanics\nbetween the dielectric and substrate. We show in simulation and experimentally\nhow different design parameters affect the engagement and release times of\ncentimeter-scale electroadhesive clutches to metallic substrates, and we find\nthat the model accurately captures the magnitude and trends of our experimental\nresults. In particular, we find that higher drive frequencies, narrower\nsubstrate aspect ratios, and faster drive circuitry output stages enable\nsignificantly faster release times. The fastest clutches have engagement times\nless than 15 us and release times less than 875 us, which are 10x and 17.1x\nfaster, respectively, than the best times found in prior literature on\ncentimeter-scale electroadhesive clutches.", "comment": "This work has been published in Extreme Mechanics Letters", "pdf_url": "http://arxiv.org/pdf/2412.16803v2", "cate": "cs.RO", "date": "2024-12-21", "updated": "2025-07-27"}
{"id": "2507.19629", "title": "Quantum Reinforcement Learning by Adaptive Non-local Observables", "authors": ["Hsin-Yi Lin", "Samuel Yen-Chi Chen", "Huan-Hsin Tseng", "Shinjae Yoo"], "categories": ["quant-ph", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE Quantum Week 2025 (QCE 2025)", "url": "http://arxiv.org/abs/2507.19629v1", "summary": "Hybrid quantum-classical frameworks leverage quantum computing for machine\nlearning; however, variational quantum circuits (VQCs) are limited by the need\nfor local measurements. We introduce an adaptive non-local observable (ANO)\nparadigm within VQCs for quantum reinforcement learning (QRL), jointly\noptimizing circuit parameters and multi-qubit measurements. The ANO-VQC\narchitecture serves as the function approximator in Deep Q-Network (DQN) and\nAsynchronous Advantage Actor-Critic (A3C) algorithms. On multiple benchmark\ntasks, ANO-VQC agents outperform baseline VQCs. Ablation studies reveal that\nadaptive measurements enhance the function space without increasing circuit\ndepth. Our results demonstrate that adaptive multi-qubit observables can enable\npractical quantum advantages in reinforcement learning.", "comment": "Accepted at IEEE Quantum Week 2025 (QCE 2025)", "pdf_url": "http://arxiv.org/pdf/2507.19629v1", "cate": "quant-ph", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2505.01000", "title": "Togedule: Scheduling Meetings with Large Language Models and Adaptive Representations of Group Availability", "authors": ["Jaeyoon Song", "Zahra Ashktorab", "Thomas W. Malone"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      This paper has been accepted at CSCW 2025", "url": "http://arxiv.org/abs/2505.01000v3", "summary": "Scheduling is a perennial-and often challenging-problem for many groups.\nExisting tools are mostly static, showing an identical set of choices to\neveryone, regardless of the current status of attendees' inputs and\npreferences. In this paper, we propose Togedule, an adaptive scheduling tool\nthat uses large language models to dynamically adjust the pool of choices and\ntheir presentation format. With the initial prototype, we conducted a formative\nstudy (N=10) and identified the potential benefits and risks of such an\nadaptive scheduling tool. Then, after enhancing the system, we conducted two\ncontrolled experiments, one each for attendees and organizers (total N=66). For\neach experiment, we compared scheduling with verbal messages, shared calendars,\nor Togedule. Results show that Togedule significantly reduces the cognitive\nload of attendees indicating their availability and improves the speed and\nquality of the decisions made by organizers.", "comment": "This paper has been accepted at CSCW 2025", "pdf_url": "http://arxiv.org/pdf/2505.01000v3", "cate": "cs.HC", "date": "2025-05-02", "updated": "2025-07-28"}
{"id": "2507.20048", "title": "Irredundant $k$-Fold Cross-Validation", "authors": ["Jesus S. Aguilar-Ruiz"], "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20048v1", "summary": "In traditional k-fold cross-validation, each instance is used ($k-1$) times\nfor training and once for testing, leading to redundancy that lets many\ninstances disproportionately influence the learning phase. We introduce\nIrredundant $k$-fold cross-validation, a novel method that guarantees each\ninstance is used exactly once for training and once for testing across the\nentire validation procedure. This approach ensures a more balanced utilization\nof the dataset, mitigates overfitting due to instance repetition, and enables\nsharper distinctions in comparative model analysis. The method preserves\nstratification and remains model-agnostic, i.e., compatible with any\nclassifier. Experimental results demonstrate that it delivers consistent\nperformance estimates across diverse datasets -- comparable to $k$-fold\ncross-validation -- while providing less optimistic variance estimates because\ntraining partitions are non-overlapping, and significantly reducing the overall\ncomputational cost.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20048v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.09108", "title": "SPICE: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation", "authors": ["Aaditya Bhatia", "Gustavo A. Oliva", "Gopi Krishnan Rajbahadur", "Haoxiang Zhang", "Yihao Chen", "Zhilong Chen", "Arthur Leung", "Dayi Lin", "Boyuan Chen", "Ahmed E. Hassan"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09108v2", "summary": "High-quality labeled datasets are crucial for training and evaluating\nfoundation models in software engineering, but creating them is often\nprohibitively expensive and labor-intensive. We introduce SPICE, a scalable,\nautomated pipeline for labeling SWE-bench-style datasets with annotations for\nissue clarity, test coverage, and effort estimation. SPICE combines\ncontext-aware code navigation, rationale-driven prompting, and multi-pass\nconsensus to produce labels that closely approximate expert annotations.\nSPICE's design was informed by our own experience and frustration in labeling\nmore than 800 instances from SWE-Gym. SPICE achieves strong agreement with\nhuman-labeled SWE-bench Verified data while reducing the cost of labeling 1,000\ninstances from around $100,000 (manual annotation) to just $5.10. These results\ndemonstrate SPICE's potential to enable cost-effective, large-scale dataset\ncreation for SE-focused FMs. To support the community, we release both SPICE\ntool and SPICE Bench, a new dataset of 6,802 SPICE-labeled instances curated\nfrom 291 open-source projects in SWE-Gym (over 13x larger than SWE-bench\nVerified).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09108v2", "cate": "cs.SE", "date": "2025-07-12", "updated": "2025-07-28"}
{"id": "2507.18538", "title": "AI/ML Life Cycle Management for Interoperable AI Native RAN", "authors": ["Chu-Hsiang Huang", "Chao-Kai Wen", "Geoffrey Ye Li"], "categories": ["cs.IT", "cs.LG", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      8 pages, 4 figures, 2 table. This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.18538v2", "summary": "Artificial intelligence (AI) and machine learning (ML) models are rapidly\npermeating the 5G Radio Access Network (RAN), powering beam management, channel\nstate information (CSI) feedback, positioning, and mobility prediction.\nHowever, without a standardized life-cycle management (LCM) framework,\nchallenges, such as model drift, vendor lock-in, and limited transparency,\nhinder large-scale adoption. 3GPP Releases 16-20 progressively evolve AI/ML\nfrom experimental features to managed, interoperable network functions.\nBeginning with the Network Data Analytics Function (NWDAF) in Rel-16,\nsubsequent releases introduced standardized interfaces for model transfer,\nexecution, performance monitoring, and closed-loop control, culminating in\nRel-20's two-sided CSI-compression Work Item and vendor-agnostic LCM profile.\nThis article reviews the resulting five-block LCM architecture, KPI-driven\nmonitoring mechanisms, and inter-vendor collaboration schemes, while\nidentifying open challenges in resource-efficient monitoring, environment drift\ndetection, intelligent decision-making, and flexible model training. These\ndevelopments lay the foundation for AI-native transceivers as a key enabler for\n6G.", "comment": "8 pages, 4 figures, 2 table. This work has been submitted to the IEEE\n  for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.18538v2", "cate": "cs.IT", "date": "2025-07-24", "updated": "2025-07-26"}
{"id": "2503.22040", "title": "Navigating the Risks of Using Large Language Models for Text Annotation in Social Science Research", "authors": ["Hao Lin", "Yongjun Zhang"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.22040v2", "summary": "Large language models (LLMs) have the potential to revolutionize\ncomputational social science, particularly in automated textual analysis. In\nthis paper, we conduct a systematic evaluation of the promises and risks\nassociated with using LLMs for text classification tasks, using social movement\nstudies as an example. We propose a framework for social scientists to\nincorporate LLMs into text annotation, either as the primary coding\ndecision-maker or as a coding assistant. This framework offers researchers\ntools to develop the potential best-performing prompt, and to systematically\nexamine and report the validity and reliability of LLMs as a methodological\ntool. Additionally, we evaluate and discuss its epistemic risks associated with\nvalidity, reliability, replicability, and transparency. We conclude with\nseveral practical guidelines for using LLMs in text annotation tasks and offer\nrecommendations for more effectively communicating epistemic risks in research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.22040v2", "cate": "cs.CL", "date": "2025-03-27", "updated": "2025-07-25"}
{"id": "2507.19928", "title": "Periodic orbit tracking in cislunar space: A finite-horizon approach", "authors": ["Mohammed Atallah", "Simone Servadio"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      2025 AAS/AIAA Astrodynamics Specialist Conference", "url": "http://arxiv.org/abs/2507.19928v1", "summary": "This paper presents a Nonlinear Model Predictive Control (NMPC) scheme for\nmaintaining a spacecraft within a specified family of periodic orbits near the\nlibration points in cislunar space. Unlike traditional approaches that track a\npredefined reference orbit, the proposed method designs an optimal trajectory\nthat keeps the spacecraft within the orbit family, regardless of the initial\nreference. The Circular Restricted Three-Body Problem (CR3BP) is used to model\nthe system dynamics. First, the Pseudo-Arclength Continuation (PAC) method is\nemployed to compute the members of each orbit family. Then, the state of each\nmember is parameterized by two variables: one defining the orbit and the other\nspecifying the location along it. These computed states are then fit to a\nMultivariate Polynomial Regression (MPR) model. An NMPC framework is developed\nto generate the optimal reference trajectory and compute the corresponding\nvelocity impulses for trajectory tracking. The control system is integrated\nwith a Extended Kalman Filter (EKF) observer that estimates the spacecraft's\nrelative state. Numerical simulations are conducted for Lyapunov, halo, and\nnear-rectilinear halo orbits near L1 and L2. The results demonstrate a\nsignificant reduction in fuel consumption compared to conventional tracking\nmethods.", "comment": "2025 AAS/AIAA Astrodynamics Specialist Conference", "pdf_url": "http://arxiv.org/pdf/2507.19928v1", "cate": "eess.SY", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20283", "title": "Information-Preserving CSI Feedback: Invertible Networks with Endogenous Quantization and Channel Error Mitigation", "authors": ["Haotian Tian", "Lixiang Lian", "Jiaqi Cao", "Sijie Ji"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20283v1", "summary": "Deep learning has emerged as a promising solution for efficient channel state\ninformation (CSI) feedback in frequency division duplex (FDD) massive MIMO\nsystems. Conventional deep learning-based methods typically rely on a deep\nautoencoder to compress the CSI, which leads to irreversible information loss\nand degrades reconstruction accuracy. This paper introduces InvCSINet, an\ninformation-preserving CSI feedback framework based on invertible neural\nnetworks (INNs). By leveraging the bijective nature of INNs, the model ensures\ninformation-preserving compression and reconstruction with shared model\nparameters. To address practical challenges such as quantization and\nchannel-induced errors, we endogenously integrate an adaptive quantization\nmodule, a differentiable bit-channel distortion module and an information\ncompensation module into the INN architecture. This design enables the network\nto learn and compensate the information loss during CSI compression,\nquantization, and noisy transmission, thereby preserving the CSI integrity\nthroughout the feedback process. Simulation results validate the effectiveness\nof the proposed scheme, demonstrating superior CSI recovery performance and\nrobustness to practical impairments with a lightweight architecture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20283v1", "cate": "eess.SP", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20575", "title": "Implicit Spatiotemporal Bandwidth Enhancement Filter by Sine-activated Deep Learning Model for Fast 3D Photoacoustic Tomography", "authors": ["I Gede Eka Sulistyawan", "Takuro Ishii", "Riku Suzuki", "Yoshifumi Saijo"], "categories": ["eess.IV", "cs.AI"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      14 pages, 13 figures. This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.20575v1", "summary": "3D photoacoustic tomography (3D-PAT) using high-frequency hemispherical\ntransducers offers near-omnidirectional reception and enhanced sensitivity to\nthe finer structural details encoded in the high-frequency components of the\nbroadband photoacoustic (PA) signal. However, practical constraints such as\nlimited number of channels with bandlimited sampling rate often result in\nsparse and bandlimited sensors that degrade image quality. To address this, we\nrevisit the 2D deep learning (DL) approach applied directly to sensor-wise PA\nradio-frequency (PARF) data. Specifically, we introduce sine activation into\nthe DL model to restore the broadband nature of PARF signals given the observed\nband-limited and high-frequency PARF data. Given the scarcity of 3D training\ndata, we employ simplified training strategies by simulating random spherical\nabsorbers. This combination of sine-activated model and randomized training is\ndesigned to emphasize bandwidth learning over dataset memorization. Our model\nwas evaluated on a leaf skeleton phantom, a micro-CT-verified 3D spiral phantom\nand in-vivo human palm vasculature. The results showed that the proposed\ntraining mechanism on sine-activated model was well-generalized across the\ndifferent tests by effectively increasing the sensor density and recovering the\nspatiotemporal bandwidth. Qualitatively, the sine-activated model uniquely\nenhanced high-frequency content that produces clearer vascular structure with\nfewer artefacts. Quantitatively, the sine-activated model exhibits full\nbandwidth at -12 dB spectrum and significantly higher contrast-to-noise ratio\nwith minimal loss of structural similarity index. Lastly, we optimized our\napproach to enable fast enhanced 3D-PAT at 2 volumes-per-second for better\npractical imaging of a free-moving targets.", "comment": "14 pages, 13 figures. This work has been submitted to the IEEE for\n  possible publication", "pdf_url": "http://arxiv.org/pdf/2507.20575v1", "cate": "eess.IV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20666", "title": "MIMII-Agent: Leveraging LLMs with Function Calling for Relative Evaluation of Anomalous Sound Detection", "authors": ["Harsh Purohit", "Tomoya Nishida", "Kota Dohi", "Takashi Endo", "Yohei Kawaguchi"], "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20666v1", "summary": "This paper proposes a method for generating machine-type-specific anomalies\nto evaluate the relative performance of unsupervised anomalous sound detection\n(UASD) systems across different machine types, even in the absence of real\nanomaly sound data. Conventional keyword-based data augmentation methods often\nproduce unrealistic sounds due to their reliance on manually defined labels,\nlimiting scalability as machine types and anomaly patterns diversify. Advanced\naudio generative models, such as MIMII-Gen, show promise but typically depend\non anomalous training data, making them less effective when diverse anomalous\nexamples are unavailable. To address these limitations, we propose a novel\nsynthesis approach leveraging large language models (LLMs) to interpret textual\ndescriptions of faults and automatically select audio transformation functions,\nconverting normal machine sounds into diverse and plausible anomalous sounds.\nWe validate this approach by evaluating a UASD system trained only on normal\nsounds from five machine types, using both real and synthetic anomaly data.\nExperimental results reveal consistent trends in relative detection difficulty\nacross machine types between synthetic and real anomalies. This finding\nsupports our hypothesis and highlights the effectiveness of the proposed\nLLM-based synthesis approach for relative evaluation of UASD systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20666v1", "cate": "eess.AS", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2502.04600", "title": "Cooperative Payload Estimation by a Team of Mocobots", "authors": ["Haoxuan Zhang", "C. Lin Liu", "Matthew L. Elwin", "Randy A. Freeman", "Kevin M. Lynch"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures. Submitted to IEEE Robotics and Automation Letters (RA-L)", "url": "http://arxiv.org/abs/2502.04600v2", "summary": "For high-performance autonomous manipulation of a payload by a mobile\nmanipulator team, or for collaborative manipulation with the human, robots\nshould be able to discover where other robots are attached to the payload, as\nwell as the payload's mass and inertial properties. In this paper, we describe\na method for the robots to autonomously discover this information. The robots\ncooperatively manipulate the payload, and the twist, twist derivative, and\nwrench data at their grasp frames are used to estimate the transformation\nmatrices between the grasp frames, the location of the payload's center of\nmass, and the payload's inertia matrix. The method is validated experimentally\nwith a team of three mobile cobots, or mocobots.", "comment": "8 pages, 6 figures. Submitted to IEEE Robotics and Automation Letters\n  (RA-L)", "pdf_url": "http://arxiv.org/pdf/2502.04600v2", "cate": "cs.RO", "date": "2025-02-07", "updated": "2025-07-28"}
{"id": "2507.19634", "title": "MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks", "authors": ["Sara Papi", "Maike Züfle", "Marco Gaido", "Beatrice Savoldi", "Danni Liu", "Ioannis Douros", "Luisa Bentivogli", "Jan Niehues"], "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.SD"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2507.19634v1", "summary": "Recent advances in large language models have catalyzed the development of\nmultimodal LLMs (MLLMs) that integrate text, speech, and vision within unified\nframeworks. As MLLMs evolve from narrow, monolingual, task-specific systems to\ngeneral-purpose instruction-following models, a key frontier lies in evaluating\ntheir multilingual and multimodal capabilities over both long and short\ncontexts. However, existing benchmarks fall short in evaluating these\ndimensions jointly: they are often limited to English, mostly focus on one\nsingle modality at a time, rely on short-form contexts, or lack human\nannotations -- hindering comprehensive assessment of model performance across\nlanguages, modalities, and task complexity. To address these gaps, we introduce\nMCIF (Multimodal Crosslingual Instruction Following), the first multilingual\nhuman-annotated benchmark based on scientific talks that is designed to\nevaluate instruction-following in crosslingual, multimodal settings over both\nshort- and long-form inputs. MCIF spans three core modalities -- speech,\nvision, and text -- and four diverse languages (English, German, Italian, and\nChinese), enabling a comprehensive evaluation of MLLMs' abilities to interpret\ninstructions across languages and combine them with multimodal contextual\ninformation. MCIF is released under a CC-BY 4.0 license to encourage open\nresearch and progress in MLLMs development.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.19634v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2505.20788", "title": "Enhancing Wearable Tap Water Audio Detection through Subclass Annotation in the HD-Epic Dataset", "authors": ["Robin Burchard", "Kristof Van Laerhoven"], "categories": ["cs.HC", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      To be published in Companion of the 2025 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp Companion '25), Beyond Sound workshop. Replacement version identical to the one to be published with ACM", "url": "http://arxiv.org/abs/2505.20788v2", "summary": "Wearable human activity recognition has been shown to benefit from the\ninclusion of acoustic data, as the sounds around a person often contain\nvaluable context. However, due to privacy concerns, it is usually not ethically\nfeasible to record and save microphone data from the device, since the audio\ncould, for instance, also contain private conversations. Rather, the data\nshould be processed locally, which in turn requires processing power and\nconsumes energy on the wearable device. One special use case of contextual\ninformation that can be utilized to augment special tasks in human activity\nrecognition is water flow detection, which can, e.g., be used to aid wearable\nhand washing detection. We created a new label called tap water for the\nrecently released HD-Epic data set, creating 717 hand-labeled annotations of\ntap water flow, based on existing annotations of the water class. We analyzed\nthe relation of tap water and water in the dataset and additionally trained and\nevaluated two lightweight classifiers to evaluate the newly added label class,\nshowing that the new class can be learned more easily.", "comment": "To be published in Companion of the 2025 ACM International Joint\n  Conference on Pervasive and Ubiquitous Computing (UbiComp Companion '25),\n  Beyond Sound workshop. Replacement version identical to the one to be\n  published with ACM", "pdf_url": "http://arxiv.org/pdf/2505.20788v2", "cate": "cs.HC", "date": "2025-05-27", "updated": "2025-07-28"}
{"id": "2507.20057", "title": "What Can Grokking Teach Us About Learning Under Nonstationarity?", "authors": ["Clare Lyle", "Gharda Sokar", "Razvan Pascanu", "Andras Gyorgy"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20057v1", "summary": "In continual learning problems, it is often necessary to overwrite components\nof a neural network's learned representation in response to changes in the data\nstream; however, neural networks often exhibit \\primacy bias, whereby early\ntraining data hinders the network's ability to generalize on later tasks. While\nfeature-learning dynamics of nonstationary learning problems are not well\nstudied, the emergence of feature-learning dynamics is known to drive the\nphenomenon of grokking, wherein neural networks initially memorize their\ntraining data and only later exhibit perfect generalization. This work\nconjectures that the same feature-learning dynamics which facilitate\ngeneralization in grokking also underlie the ability to overwrite previous\nlearned features as well, and methods which accelerate grokking by facilitating\nfeature-learning dynamics are promising candidates for addressing primacy bias\nin non-stationary learning problems. We then propose a straightforward method\nto induce feature-learning dynamics as needed throughout training by increasing\nthe effective learning rate, i.e. the ratio between parameter and update norms.\nWe show that this approach both facilitates feature-learning and improves\ngeneralization in a variety of settings, including grokking, warm-starting\nneural network training, and reinforcement learning tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20057v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.13661", "title": "Testing Autonomous Driving Systems -- What Really Matters and What Doesn't", "authors": ["Changwen Li", "Joseph Sifakis", "Rongjie Yan", "Jian Zhang"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13661v2", "summary": "Despite extensive research, the testing of autonomous driving systems (ADS)\nlandscape remains fragmented, and there is currently no basis for an informed\ntechnical assessment of the importance and contribution of the current state of\nthe art. This paper attempts to address this problem by exploring two\ncomplementary aspects.\n  First, it proposes a framework for comparing existing test methods in terms\nof their intrinsic effectiveness and validity. It shows that many methods do\nnot meet both of these requirements. Either because they are based on criteria\nthat do not allow for rapid, inexpensive, and comprehensive detection of\nfailures, or because the degree of validity of the properties tested cannot be\naccurately estimated. In particular, it is shown that most critical test\nmethods do not take into account the nominal operational capabilities of\nautopilots and generate scenarios that are impossible for the tested vehicles\nto handle, resulting in unjustified rejections.\n  Secondly, the paper shows that test effectiveness and validity are highly\ndependent on how autopilots are designed: how they choose between different\ncontrol policies to perform maneuvers, as well as on the reproducibility of the\nresults. In fact, most test methods take for granted two principles underlying\ntraditional methods, but do not generally apply to ADS. We maintain that the\nabsence of rationality and determinacy significantly impairs the effectiveness\nand validity of test methods, and provide test results on eight open\nautopilots, in which most do not satisfy these properties, thereby illustrating\nthis fact.\n  We conclude that under the current state of the art, it is impossible to\nobtain strong enough guarantees for essential autopilot properties and\nrecommend that autopilots be developed with a view to both rationality and\ndeterminacy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13661v2", "cate": "cs.SE", "date": "2025-07-18", "updated": "2025-07-27"}
{"id": "2310.04115", "title": "Markov chain entropy games and the geometry of their Nash equilibria", "authors": ["Michael C. H. Choi", "Geoffrey Wolfer"], "categories": ["math.PR", "cs.IT", "math.IT", "math.OC", "stat.CO", "49J35, 60J27, 60J28, 62B10, 62C20, 90C47, 91A05, 91A68, 94A17, 94A29"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "Comments:      29 pages, 2 figures", "url": "http://arxiv.org/abs/2310.04115v3", "summary": "We introduce and study a two-player zero-sum game between a probabilist and\nNature defined by a convex function $f$, a finite collection $\\mathcal{B}$ of\nMarkov generators (or its convex hull), and a target distribution $\\pi$. The\nprobabilist selects a mixed strategy $\\mu \\in \\mathcal{P}(\\mathcal{B})$, the\nset of probability measures on $\\mathcal{B}$, while Nature adopts a pure\nstrategy and selects a $\\pi$-reversible Markov generator $M$. The probabilist\nreceives a payoff equal to the $f$-divergence $D_f(M \\| L)$, where $L$ is drawn\naccording to $\\mu$. We prove that this game always admits a mixed strategy Nash\nequilibrium and satisfies a minimax identity. In contrast, a pure strategy\nequilibrium may fail to exist. We develop a projected subgradient method to\ncompute approximate mixed strategy equilibria with provable convergence\nguarantees. Connections to information centroids, Chebyshev centers, and Bayes\nrisk are discussed. This paper extends earlier minimax results on\n$f$-divergences to the context of Markov generators.", "comment": "29 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2310.04115v3", "cate": "math.PR", "date": "2023-10-06", "updated": "2025-07-26"}
{"id": "2507.02087", "title": "Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions", "authors": ["Eitan Anzenberg", "Arunava Samajpati", "Sivasankaran Chandrasekar", "Varun Kacholia"], "categories": ["cs.LG", "cs.CL", "cs.CY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 2 figures, 2 tables. Submitted to NeurIPS 2025", "url": "http://arxiv.org/abs/2507.02087v2", "summary": "The use of large language models (LLMs) in hiring promises to streamline\ncandidate screening, but it also raises serious concerns regarding accuracy and\nalgorithmic bias where sufficient safeguards are not in place. In this work, we\nbenchmark several state-of-the-art foundational LLMs - including models from\nOpenAI, Anthropic, Google, Meta, and Deepseek, and compare them with our\nproprietary domain-specific hiring model (Match Score) for job candidate\nmatching. We evaluate each model's predictive accuracy (ROC AUC,\nPrecision-Recall AUC, F1-score) and fairness (impact ratio of cut-off analysis\nacross declared gender, race, and intersectional subgroups). Our experiments on\na dataset of roughly 10,000 real-world recent candidate-job pairs show that\nMatch Score outperforms the general-purpose LLMs on accuracy (ROC AUC 0.85 vs\n0.77) and achieves significantly more equitable outcomes across demographic\ngroups. Notably, Match Score attains a minimum race-wise impact ratio of 0.957\n(near-parity), versus 0.809 or lower for the best LLMs, (0.906 vs 0.773 for the\nintersectionals, respectively). We discuss why pretraining biases may cause\nLLMs with insufficient safeguards to propagate societal biases in hiring\nscenarios, whereas a bespoke supervised model can more effectively mitigate\nthese biases. Our findings highlight the importance of domain-specific modeling\nand bias auditing when deploying AI in high-stakes domains such as hiring, and\ncaution against relying on off-the-shelf LLMs for such tasks without extensive\nfairness safeguards. Furthermore, we show with empirical evidence that there\nshouldn't be a dichotomy between choosing accuracy and fairness in hiring: a\nwell-designed algorithm can achieve both accuracy in hiring and fairness in\noutcomes.", "comment": "10 pages, 2 figures, 2 tables. Submitted to NeurIPS 2025", "pdf_url": "http://arxiv.org/pdf/2507.02087v2", "cate": "cs.LG", "date": "2025-07-02", "updated": "2025-07-28"}
{"id": "2507.20071", "title": "A Unified Finite-Time Sliding Mode Quaternion-based Tracking Control for Quadrotor UAVs without Time Scale Separation", "authors": ["Ali M. Ali", "Hashim A. Hashim", "Awantha Jayasiri"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      The 2025 IEEE American Control Conference (ACC)", "url": "http://arxiv.org/abs/2507.20071v1", "summary": "This paper presents a novel design for finite-time position control of\nquadrotor Unmanned Aerial Vehicles (UAVs). A robust, finite-time, nonlinear\nfeedback controller is introduced to reject bounded disturbances in tracking\ntasks. The proposed control framework differs conceptually from conventional\ncontrollers that utilize Euler angle parameterization for attitude and adhere\nto the traditional hierarchical inner-outer loop design. In standard\napproaches, the translational controller and the corresponding desired attitude\nare computed first, followed by the design of the attitude controller based on\ntime-scale separation between fast attitude and slow translational dynamics. In\ncontrast, the proposed control scheme is quaternion-based and utilizes a\ntransit feed-forward term in the attitude dynamics that anticipates the slower\ntranslational subsystem. Robustness is achieved through the use of continuously\ndifferentiable sliding manifolds. The proposed approach guarantees semi-global\nfinite-time stability, without requiring time-scale separation. Finally,\nnumerical simulation results are provided to demonstrate the effectiveness of\nthe proposed controller.", "comment": "The 2025 IEEE American Control Conference (ACC)", "pdf_url": "http://arxiv.org/pdf/2507.20071v1", "cate": "eess.SY", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20392", "title": "Reliability of Wi-Fi, LTE, and 5G-Based UAV RC Links in ISM Bands: Uplink Interference Asymmetry Analysis and HARQ Design", "authors": ["Donggu Lee", "Sung Joon Maeng", "Ozgur Ozdemir", "Mani Bharathi Pandian", "Ismail Guvenc"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20392v1", "summary": "Command and control of uncrewed aerial vehicles (UAVs) is often realized\nthrough air-to-ground (A2G) remote control (RC) links that operate in ISM\nbands. While wireless fidelity (Wi-Fi) technology is commonly used for UAV RC\nlinks, ISM-based long-term evolution (LTE) and fifth-generation (5G)\ntechnologies have also been recently considered for the same purpose. A major\nproblem for UAV RC links in the ISM bands is that other types of interference\nsources, such as legacy Wi-Fi and Bluetooth transmissions, may degrade the link\nquality. Such interference problems are a higher concern for the UAV in the air\nthan the RC unit on the ground due to the UAV being in line-of-sight (LoS) with\na larger number of interference sources. To obtain empirical evidence of the\nasymmetric interference conditions in downlink (DL) and uplink (UL), we first\nconducted a measurement campaign using a helikite platform in urban and rural\nareas at NC State University. The results from this measurement campaign show\nthat the aggregate interference can be up to 16.66 dB at higher altitudes up to\n170 m, compared with the interference observed at a ground receiver. As a\nresult of this asymmetric UL interference, lost hybrid automatic repeat request\n(HARQ) indicators (ACK/NACK) in the UL may degrade the DL throughput. To\ninvestigate this, we study various HARQ mechanisms, including HARQ Type-I with\nno combining, HARQ Type-I with chase combining, HARQ Type-III with incremental\nredundancy, and burst transmission with chase combining. To evaluate the impact\nof asymmetric UL interference on throughput performance, we consider three\nsteps of evaluation process: 1) standalone physical DL shared channel (PDSCH)\nthroughput evaluation with perfect ACK/NACK assumption; 2) standalone physical\nUL control channel (PUCCH) decoding reliability evaluation; and 3) PDSCH DL\nthroughput evaluation with asymmetric UL ACK/NACK transmission.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20392v1", "cate": "eess.SP", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20765", "title": "Onboard Hyperspectral Super-Resolution with Deep Pushbroom Neural Network", "authors": ["Davide Piccinini", "Diego Valsesia", "Enrico Magli"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20765v1", "summary": "Hyperspectral imagers on satellites obtain the fine spectral signatures\nessential for distinguishing one material from another at the expense of\nlimited spatial resolution. Enhancing the latter is thus a desirable\npreprocessing step in order to further improve the detection capabilities\noffered by hyperspectral images on downstream tasks. At the same time, there is\na growing interest towards deploying inference methods directly onboard of\nsatellites, which calls for lightweight image super-resolution methods that can\nbe run on the payload in real time. In this paper, we present a novel neural\nnetwork design, called Deep Pushbroom Super-Resolution (DPSR) that matches the\npushbroom acquisition of hyperspectral sensors by processing an image line by\nline in the along-track direction with a causal memory mechanism to exploit\npreviously acquired lines. This design greatly limits memory requirements and\ncomputational complexity, achieving onboard real-time performance, i.e., the\nability to super-resolve a line in the time it takes to acquire the next one,\non low-power hardware. Experiments show that the quality of the super-resolved\nimages is competitive or even outperforms state-of-the-art methods that are\nsignificantly more complex.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20765v1", "cate": "eess.IV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20926", "title": "End-to-End DOA-Guided Speech Extraction in Noisy Multi-Talker Scenarios", "authors": ["Kangqi Jing", "Wenbin Zhang", "Yu Gao"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted by INTERSPEECH 2025", "url": "http://arxiv.org/abs/2507.20926v1", "summary": "Target Speaker Extraction (TSE) plays a critical role in enhancing speech\nsignals in noisy and multi-speaker environments. This paper presents an\nend-to-end TSE model that incorporates Direction of Arrival (DOA) and beamwidth\nembeddings to extract speech from a specified spatial region centered around\nthe DOA. Our approach efficiently captures spatial and temporal features,\nenabling robust performance in highly complex scenarios with multiple\nsimultaneous speakers. Experimental results demonstrate that the proposed model\nnot only significantly enhances the target speech within the defined beamwidth\nbut also effectively suppresses interference from other directions, producing a\nclear and isolated target voice. Furthermore, the model achieves remarkable\nimprovements in downstream Automatic Speech Recognition (ASR) tasks, making it\nparticularly suitable for real-world applications.", "comment": "Accepted by INTERSPEECH 2025", "pdf_url": "http://arxiv.org/pdf/2507.20926v1", "cate": "eess.AS", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2503.04580", "title": "DogLegs: Robust Proprioceptive State Estimation for Legged Robots Using Multiple Leg-Mounted IMUs", "authors": ["Yibin Wu", "Jian Kuang", "Shahram Khorshidi", "Xiaoji Niu", "Lasse Klingbeil", "Maren Bennewitz", "Heiner Kuhlmann"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 8 figures", "url": "http://arxiv.org/abs/2503.04580v2", "summary": "Robust and accurate proprioceptive state estimation of the main body is\ncrucial for legged robots to execute tasks in extreme environments where\nexteroceptive sensors, such as LiDARs and cameras, may become unreliable. In\nthis paper, we propose DogLegs, a state estimation system for legged robots\nthat fuses the measurements from a body-mounted inertial measurement unit\n(Body-IMU), joint encoders, and multiple leg-mounted IMUs (Leg-IMU) using an\nextended Kalman filter (EKF). The filter system contains the error states of\nall IMU frames. The Leg-IMUs are used to detect foot contact, thereby providing\nzero-velocity measurements to update the state of the Leg-IMU frames.\nAdditionally, we compute the relative position constraints between the Body-IMU\nand Leg-IMUs by the leg kinematics and use them to update the main body state\nand reduce the error drift of the individual IMU frames. Field experimental\nresults have shown that our proposed DogLegs system achieves better state\nestimation accuracy compared to the traditional leg odometry method (using only\nBody-IMU and joint encoders) across various terrains. We make our datasets\npublicly available to benefit the research community\n(https://github.com/YibinWu/leg-odometry).", "comment": "8 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2503.04580v2", "cate": "cs.RO", "date": "2025-03-06", "updated": "2025-07-25"}
{"id": "2507.19679", "title": "Efficient Learning for Product Attributes with Compact Multimodal Models", "authors": ["Mandar Kulkarni"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19679v1", "summary": "Image-based product attribute prediction in e-commerce is a crucial task with\nnumerous applications. The supervised fine-tuning of Vision Language Models\n(VLMs) faces significant scale challenges due to the cost of manual or API\nbased annotation. In this paper, we investigate label-efficient semi-supervised\nfine-tuning strategies for compact VLMs (2B-3B parameters) that leverage\nunlabeled product listings through Direct Preference Optimization (DPO).\nBeginning with a small, API-based, annotated, and labeled set, we first employ\nPEFT to train low-rank adapter modules. To update the adapter weights with\nunlabeled data, we generate multiple reasoning-and-answer chains per unlabeled\nsample and segregate these chains into preferred and dispreferred based on\nself-consistency. We then fine-tune the model with DPO loss and use the updated\nmodel for the next iteration. By using PEFT fine-tuning with DPO, our method\nachieves efficient convergence with minimal compute overhead. On a dataset\nspanning twelve e-commerce verticals, DPO-based fine-tuning, which utilizes\nonly unlabeled data, demonstrates a significant improvement over the supervised\nmodel. Moreover, experiments demonstrate that accuracy with DPO training\nimproves with more unlabeled data, indicating that a large pool of unlabeled\nsamples can be effectively leveraged to improve performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19679v1", "cate": "cs.CV", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2506.12469", "title": "Levels of Autonomy for AI Agents", "authors": ["K. J. Kevin Feng", "David W. McDonald", "Amy X. Zhang"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Published in the Knight 1st Amendment Institute's \"AI and Democratic Freedoms\" essay series", "url": "http://arxiv.org/abs/2506.12469v2", "summary": "Autonomy is a double-edged sword for AI agents, simultaneously unlocking\ntransformative possibilities and serious risks. How can agent developers\ncalibrate the appropriate levels of autonomy at which their agents should\noperate? We argue that an agent's level of autonomy can be treated as a\ndeliberate design decision, separate from its capability and operational\nenvironment. In this work, we define five levels of escalating agent autonomy,\ncharacterized by the roles a user can take when interacting with an agent:\noperator, collaborator, consultant, approver, and observer. Within each level,\nwe describe the ways by which a user can exert control over the agent and open\nquestions for how to design the nature of user-agent interaction. We then\nhighlight a potential application of our framework towards AI autonomy\ncertificates to govern agent behavior in single- and multi-agent systems. We\nconclude by proposing early ideas for evaluating agents' autonomy. Our work\naims to contribute meaningful, practical steps towards responsibly deployed and\nuseful AI agents in the real world.", "comment": "Published in the Knight 1st Amendment Institute's \"AI and Democratic\n  Freedoms\" essay series", "pdf_url": "http://arxiv.org/pdf/2506.12469v2", "cate": "cs.HC", "date": "2025-06-14", "updated": "2025-07-28"}
{"id": "2507.20061", "title": "Strategic Filtering for Content Moderation: Free Speech or Free of Distortion?", "authors": ["Saba Ahmadi", "Avrim Blum", "Haifeng Xu", "Fan Yao"], "categories": ["cs.LG", "cs.GT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20061v1", "summary": "User-generated content (UGC) on social media platforms is vulnerable to\nincitements and manipulations, necessitating effective regulations. To address\nthese challenges, those platforms often deploy automated content moderators\ntasked with evaluating the harmfulness of UGC and filtering out content that\nviolates established guidelines. However, such moderation inevitably gives rise\nto strategic responses from users, who strive to express themselves within the\nconfines of guidelines. Such phenomena call for a careful balance between: 1.\nensuring freedom of speech -- by minimizing the restriction of expression; and\n2. reducing social distortion -- measured by the total amount of content\nmanipulation. We tackle the problem of optimizing this balance through the lens\nof mechanism design, aiming at optimizing the trade-off between minimizing\nsocial distortion and maximizing free speech. Although determining the optimal\ntrade-off is NP-hard, we propose practical methods to approximate the optimal\nsolution. Additionally, we provide generalization guarantees determining the\namount of finite offline data required to approximate the optimal moderator\neffectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20061v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2407.20281", "title": "NeuSemSlice: Towards Effective DNN Model Maintenance via Neuron-level Semantic Slicing", "authors": ["Shide Zhou", "Tianlin Li", "Yihao Huang", "Ling Shi", "Kailong Wang", "Yang Liu", "Haoyu Wang"], "categories": ["cs.LG", "cs.SE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.20281v2", "summary": "Deep Neural networks (DNNs), extensively applied across diverse disciplines,\nare characterized by their integrated and monolithic architectures, setting\nthem apart from conventional software systems. This architectural difference\nintroduces particular challenges to maintenance tasks, such as model\nrestructure (e.g., model compression), re-adaptation (e.g., fitting new\nsamples), and incremental development (e.g., continual knowledge accumulation).\nPrior research addresses these challenges by identifying task-critical neuron\nlayers, and dividing neural networks into semantically-similar sequential\nmodules. However, such layer-level approaches fail to precisely identify and\nmanipulate neuron-level semantic components, restricting their applicability to\nfiner-grained model maintenance tasks. In this work, we implement NeuSemSlice,\na novel framework that introduces the semantic slicing technique to effectively\nidentify critical neuron-level semantic components in DNN models for\nsemantic-aware model maintenance tasks. Specifically, semantic slicing\nidentifies, categorizes and merges critical neurons across different categories\nand layers according to their semantic similarity, enabling their flexibility\nand effectiveness in the subsequent tasks. For semantic-aware model maintenance\ntasks, we provide a series of novel strategies based on semantic slicing to\nenhance NeuSemSlice. They include semantic components (i.e., critical neurons)\npreservation for model restructure, critical neuron tuning for model\nre-adaptation, and non-critical neuron training for model incremental\ndevelopment. A thorough evaluation has demonstrated that NeuSemSlice\nsignificantly outperforms baselines in all three tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.20281v2", "cate": "cs.LG", "date": "2024-07-26", "updated": "2025-07-26"}
{"id": "2312.02031", "title": "Virtual Quantum Markov Chains", "authors": ["Yu-Ao Chen", "Chengkai Zhu", "Keming He", "Mingrui Jing", "Xin Wang"], "categories": ["quant-ph", "cond-mat.stat-mech", "cs.IR", "cs.IT", "hep-th", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      19 pages including appendix, 6 figures, v2: results and references updated", "url": "http://arxiv.org/abs/2312.02031v2", "summary": "Quantum Markov chains generalize classical Markov chains for random variables\nto the quantum realm and exhibit unique inherent properties, making them an\nimportant feature in quantum information theory. In this work, we propose the\nconcept of virtual quantum Markov chains (VQMCs), focusing on scenarios where\nsubsystems retain classical information about global systems from measurement\nstatistics. As a generalization of quantum Markov chains, VQMCs characterize\nstates where arbitrary global shadow information can be recovered from\nsubsystems through local quantum operations and measurements. We present an\nalgebraic characterization for virtual quantum Markov chains and show that the\nvirtual quantum recovery is fully determined by the block matrices of a quantum\nstate on its subsystems. Notably, we find a distinction between two classes of\ntripartite entanglement by showing that the W state is a VQMC while the GHZ\nstate is not. Furthermore, we introduce the virtual non-Markovianity to\nquantify the non-Markovianity of a given quantum state, which also assesses the\noptimal sampling overhead for virtually recovering this state. Our findings\nelucidate distinctions between quantum Markov chains and virtual quantum Markov\nchains, extending our understanding of quantum recovery to scenarios\nprioritizing classical information from measurement statistics.", "comment": "19 pages including appendix, 6 figures, v2: results and references\n  updated", "pdf_url": "http://arxiv.org/pdf/2312.02031v2", "cate": "quant-ph", "date": "2023-12-04", "updated": "2025-07-28"}
{"id": "2507.20098", "title": "Comparative Analysis of Data-Driven Predictive Control Strategies", "authors": ["Sohrab Rezaei", "Ali Khaki-Sedigh"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20098v1", "summary": "This paper compares data-driven predictive control strategies by examining\ntheir theoretical foundations, assumptions, and applications. The three most\nwidely recognized and consequential methods, Data Enabled Predictive Control,\nWillems-Koopman Predictive Control, Model-Free Adaptive Predictive Control are\nemployed. Each of these strategies is systematically reviewed, and the primary\ntheories supporting it are outlined. Following analysis, a discussion is\nprovided regarding their fundamental assumptions, emphasizing their influence\non control effectiveness. A numerical example is presented as a benchmark for\ncomparison to enable a rigorous performance evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20098v1", "cate": "eess.SY", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20408", "title": "A Multi-Stage Hybrid CNN-Transformer Network for Automated Pediatric Lung Sound Classification", "authors": ["Samiul Based Shuvo", "Taufiq Hasan"], "categories": ["eess.SP", "cs.AI"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20408v1", "summary": "Automated analysis of lung sound auscultation is essential for monitoring\nrespiratory health, especially in regions facing a shortage of skilled\nhealthcare workers. While respiratory sound classification has been widely\nstudied in adults, its ap plication in pediatric populations, particularly in\nchildren aged <6 years, remains an underexplored area. The developmental\nchanges in pediatric lungs considerably alter the acoustic proper ties of\nrespiratory sounds, necessitating specialized classification approaches\ntailored to this age group. To address this, we propose a multistage hybrid\nCNN-Transformer framework that combines CNN-extracted features with an\nattention-based architecture to classify pediatric respiratory diseases using\nscalogram images from both full recordings and individual breath events. Our\nmodel achieved an overall score of 0.9039 in binary event classifi cation and\n0.8448 in multiclass event classification by employing class-wise focal loss to\naddress data imbalance. At the recording level, the model attained scores of\n0.720 for ternary and 0.571 for multiclass classification. These scores\noutperform the previous best models by 3.81% and 5.94%, respectively. This\napproach offers a promising solution for scalable pediatric respiratory disease\ndiagnosis, especially in resource-limited settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20408v1", "cate": "eess.SP", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20186", "title": "SAMwave: Wavelet-Driven Feature Enrichment for Effective Adaptation of Segment Anything Model", "authors": ["Saurabh Yadav", "Avi Gupta", "Koteswar Rao Jerripothula"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to BMVC 2025. The first two authors contributed equally", "url": "http://arxiv.org/abs/2507.20186v1", "summary": "The emergence of large foundation models has propelled significant advances\nin various domains. The Segment Anything Model (SAM), a leading model for image\nsegmentation, exemplifies these advances, outperforming traditional methods.\nHowever, such foundation models often suffer from performance degradation when\napplied to complex tasks for which they are not trained. Existing methods\ntypically employ adapter-based fine-tuning strategies to adapt SAM for tasks\nand leverage high-frequency features extracted from the Fourier domain.\nHowever, Our analysis reveals that these approaches offer limited benefits due\nto constraints in their feature extraction techniques. To overcome this, we\npropose \\textbf{\\textit{SAMwave}}, a novel and interpretable approach that\nutilizes the wavelet transform to extract richer, multi-scale high-frequency\nfeatures from input data. Extending this, we introduce complex-valued adapters\ncapable of capturing complex-valued spatial-frequency information via complex\nwavelet transforms. By adaptively integrating these wavelet coefficients,\nSAMwave enables SAM's encoder to capture information more relevant for dense\nprediction. Empirical evaluations on four challenging low-level vision tasks\ndemonstrate that SAMwave significantly outperforms existing adaptation methods.\nThis superior performance is consistent across both the SAM and SAM2 backbones\nand holds for both real and complex-valued adapter variants, highlighting the\nefficiency, flexibility, and interpretability of our proposed method for\nadapting segment anything models.", "comment": "Accepted to BMVC 2025. The first two authors contributed equally", "pdf_url": "http://arxiv.org/pdf/2507.20186v1", "cate": "cs.CV", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19557", "title": "Joint Feature and Output Distillation for Low-complexity Acoustic Scene Classification", "authors": ["Haowen Li", "Ziyi Yang", "Mou Wang", "Ee-Leng Tan", "Junwei Yeow", "Santi Peksi", "Woon-Seng Gan"], "categories": ["cs.SD", "eess.AS", "I.2.6"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      4 pages, submitted to DCASE2025 Challenge Task 1", "url": "http://arxiv.org/abs/2507.19557v1", "summary": "This report presents a dual-level knowledge distillation framework with\nmulti-teacher guidance for low-complexity acoustic scene classification (ASC)\nin DCASE2025 Task 1. We propose a distillation strategy that jointly transfers\nboth soft logits and intermediate feature representations. Specifically, we\npre-trained PaSST and CP-ResNet models as teacher models. Logits from teachers\nare averaged to generate soft targets, while one CP-ResNet is selected for\nfeature-level distillation. This enables the compact student model (CP-Mobile)\nto capture both semantic distribution and structural information from teacher\nguidance. Experiments on the TAU Urban Acoustic Scenes 2022 Mobile dataset\n(development set) demonstrate that our submitted systems achieve up to 59.30\\%\naccuracy.", "comment": "4 pages, submitted to DCASE2025 Challenge Task 1", "pdf_url": "http://arxiv.org/pdf/2507.19557v1", "cate": "cs.SD", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2503.05152", "title": "GSplatVNM: Point-of-View Synthesis for Visual Navigation Models Using Gaussian Splatting", "authors": ["Kohei Honda", "Takeshi Ishita", "Yasuhiro Yoshimura", "Ryo Yonetani"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 4 figures", "url": "http://arxiv.org/abs/2503.05152v3", "summary": "This paper presents a novel approach to image-goal navigation by integrating\n3D Gaussian Splatting (3DGS) with Visual Navigation Models (VNMs), a method we\nrefer to as GSplatVNM. VNMs offer a promising paradigm for image-goal\nnavigation by guiding a robot through a sequence of point-of-view images\nwithout requiring metrical localization or environment-specific training.\nHowever, constructing a dense and traversable sequence of target viewpoints\nfrom start to goal remains a central challenge, particularly when the available\nimage database is sparse. To address these challenges, we propose a 3DGS-based\nviewpoint synthesis framework for VNMs that synthesizes intermediate viewpoints\nto seamlessly bridge gaps in sparse data while significantly reducing storage\noverhead. Experimental results in a photorealistic simulator demonstrate that\nour approach not only enhances navigation efficiency but also exhibits\nrobustness under varying levels of image database sparsity.", "comment": "8 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2503.05152v3", "cate": "cs.RO", "date": "2025-03-07", "updated": "2025-07-26"}
{"id": "2507.19682", "title": "DeepJIVE: Learning Joint and Individual Variation Explained from Multimodal Data Using Deep Learning", "authors": ["Matthew Drexler", "Benjamin Risk", "James J Lah", "Suprateek Kundu", "Deqiang Qiu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      26 pages, 10 figures", "url": "http://arxiv.org/abs/2507.19682v1", "summary": "Conventional multimodal data integration methods provide a comprehensive\nassessment of the shared or unique structure within each individual data type\nbut suffer from several limitations such as the inability to handle\nhigh-dimensional data and identify nonlinear structures. In this paper, we\nintroduce DeepJIVE, a deep-learning approach to performing Joint and Individual\nVariance Explained (JIVE). We perform mathematical derivation and experimental\nvalidations using both synthetic and real-world 1D, 2D, and 3D datasets.\nDifferent strategies of achieving the identity and orthogonality constraints\nfor DeepJIVE were explored, resulting in three viable loss functions. We found\nthat DeepJIVE can successfully uncover joint and individual variations of\nmultimodal datasets. Our application of DeepJIVE to the Alzheimer's Disease\nNeuroimaging Initiative (ADNI) also identified biologically plausible\ncovariation patterns between the amyloid positron emission tomography (PET) and\nmagnetic resonance (MR) images. In conclusion, the proposed DeepJIVE can be a\nuseful tool for multimodal data analysis.", "comment": "26 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.19682v1", "cate": "cs.CV", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.13952", "title": "Beyond Load: Understanding Cognitive Effort through Neural Efficiency and Involvement using fNIRS and Machine Learning", "authors": ["Shayla Sharmin", "Roghayeh Leila Barmaki"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2504.13883", "url": "http://arxiv.org/abs/2507.13952v2", "summary": "The estimation of cognitive effort could potentially help educators to modify\nmaterial to enhance learning effectiveness and student engagement. Where\ncognitive load refers how much work the brain is doing while someone is\nlearning or doing a task cognitive effort consider both load and behavioral\nperformance. Cognitive effort can be captured by measuring oxygen flow and\nbehavioral performance during a task. This study infers cognitive effort\nmetrics using machine learning models based on oxygenated hemoglobin collected\nby using functional near-infrared spectroscopy from the prefrontal cortex\nduring an educational gameplay. In our study, sixteen participants responded to\nsixteen questions in an in-house Unity-based educational game. The quiz was\ndivided into two sessions, each session consisting of two task segments. We\nextracted temporal statistical and functional connectivity features from\ncollected oxygenated hemoglobin and analyzed their correlation with quiz\nperformance. We trained multiple machine learning models to predict quiz\nperformance from oxygenated hemoglobin features and achieved accuracies ranging\nfrom 58\\% to 67\\% accuracy. These predictions were used to calculate cognitive\neffort via relative neural involvement and efficiency, which consider both\nbrain activation and behavioral performance. Although quiz score predictions\nachieved moderate accuracy, the derived relative neural efficiency and\ninvolvement values remained robust. Since both metrics are based on the\nrelative positions of standardized brain activation and performance scores,\neven small misclassifications in predicted scores preserved the overall\ncognitive effort trends observed during gameplay.", "comment": "arXiv admin note: text overlap with arXiv:2504.13883", "pdf_url": "http://arxiv.org/pdf/2507.13952v2", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-28"}
{"id": "2507.20065", "title": "Geometric Operator Learning with Optimal Transport", "authors": ["Xinyi Li", "Zongyi Li", "Nikola Kovachki", "Anima Anandkumar"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20065v1", "summary": "We propose integrating optimal transport (OT) into operator learning for\npartial differential equations (PDEs) on complex geometries. Classical\ngeometric learning methods typically represent domains as meshes, graphs, or\npoint clouds. Our approach generalizes discretized meshes to mesh density\nfunctions, formulating geometry embedding as an OT problem that maps these\nfunctions to a uniform density in a reference space. Compared to previous\nmethods relying on interpolation or shared deformation, our OT-based method\nemploys instance-dependent deformation, offering enhanced flexibility and\neffectiveness. For 3D simulations focused on surfaces, our OT-based neural\noperator embeds the surface geometry into a 2D parameterized latent space. By\nperforming computations directly on this 2D representation of the surface\nmanifold, it achieves significant computational efficiency gains compared to\nvolumetric simulation. Experiments with Reynolds-averaged Navier-Stokes\nequations (RANS) on the ShapeNet-Car and DrivAerNet-Car datasets show that our\nmethod achieves better accuracy and also reduces computational expenses in\nterms of both time and memory usage compared to existing machine learning\nmodels. Additionally, our model demonstrates significantly improved accuracy on\nthe FlowBench dataset, underscoring the benefits of employing\ninstance-dependent deformation for datasets with highly variable geometries.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20065v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2405.06231", "title": "Entanglement sharing across a damping-dephasing channel", "authors": ["Vikesh Siddhu", "Dina Abdelhadi", "Tomas Jochym-O'Connor", "John Smolin"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      18 pages, 8 figures, updated Sec. 4, corrected typos and other minor edits. For ISIT'24 conference version see this https URL", "url": "http://arxiv.org/abs/2405.06231v2", "summary": "Entanglement distillation is a fundamental information processing task whose\nimplementation is key to quantum communication and modular quantum computing.\nNoise experienced by such communication and computing platforms occurs not only\nin the form of Pauli noise such as dephasing (sometimes called $T_2$) but also\nnon-Pauli noise such as amplitude damping (sometimes called $T_1$). We initiate\na study of practical and asymptotic distillation over what we call the joint\ndamping-dephasing noise channel. In the practical setting, we propose a\ndistillation scheme that completely isolates away the damping noise. In the\nasymptotic setting we derive lower bounds on the entanglement sharing\ncapacities including the coherent and reverse coherent information. Like the\nprotocol achieving the reverse coherent information, our scheme uses only\nbackward classical communication. However, for realistic damping noise ($T_1\n\\neq 2T_2$) our strategy can exceed the reverse coherent strategy, which is the\nbest known for pure damping. In the forward communication setting we\nnumerically exceed the single-letter coherent information strategy by observing\nthe channel displays non-additivity at the two-letter level. The work shows\nnon-additivity can also be found in realistic noise models with magnitudes of\nnon-additivity similar to those found in more idealized noise channels.", "comment": "18 pages, 8 figures, updated Sec. 4, corrected typos and other minor\n  edits. For ISIT'24 conference version see\n  https://ieeexplore.ieee.org/document/10619242", "pdf_url": "http://arxiv.org/pdf/2405.06231v2", "cate": "quant-ph", "date": "2024-05-10", "updated": "2025-07-28"}
{"id": "2507.20194", "title": "On Certificates for Almost Sure Reachability in Stochastic Systems", "authors": ["Arash Bahari Kordabad", "Rupak Majumdar", "Harshit Jitendra Motwani", "Sadegh Soudjani"], "categories": ["eess.SY", "cs.SY", "math.DS", "math.PR"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      8 pages, 1 Fig", "url": "http://arxiv.org/abs/2507.20194v1", "summary": "Almost sure reachability refers to the property of a stochastic system\nwhereby, from any initial condition, the system state reaches a given target\nset with probability one. In this paper, we study the problem of certifying\nalmost sure reachability in discrete-time stochastic systems using drift and\nvariant conditions. While these conditions are both necessary and sufficient in\ntheory, computational approaches often rely on restricting the search to fixed\ntemplates, such as polynomial or quadratic functions. We show that this\nrestriction compromises completeness: there exists a polynomial system for\nwhich a given target set is almost surely reachable but admits no polynomial\ncertificate, and a linear system for which a neighborhood of the origin is\nalmost surely reachable but admits no quadratic certificate. We then provide a\ncomplete characterization of reachability certificates for linear systems with\nadditive noise. Our analysis yields conditions on the system matrices under\nwhich valid certificates exist, and shows how the structure and dimension of\nthe system determine the need for non-quadratic templates. Our results\ngeneralize the classical random walk behavior to a broader class of stochastic\ndynamical systems.", "comment": "8 pages, 1 Fig", "pdf_url": "http://arxiv.org/pdf/2507.20194v1", "cate": "eess.SY", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20489", "title": "Energy-Efficient Secure Communications via Joint Optimization of UAV Trajectory and Movable-Antenna Array Beamforming", "authors": ["Sanghyeok Kim", "Jinu Gong", "Joonhyuk Kang"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      5 pages, 2 figures", "url": "http://arxiv.org/abs/2507.20489v1", "summary": "This paper investigates the potential of unmanned aerial vehicles (UAVs)\nequipped with movable-antenna (MA) arrays to strengthen security in wireless\ncommunication systems. We propose a novel framework that jointly optimizes the\nUAV trajectory and the reconfigurable beamforming of the MA array to maximize\nsecrecy energy efficiency, while ensuring reliable communication with\nlegitimate users. By exploiting the spatial degrees of freedom enabled by the\nMA array, the system can form highly directional beams and deep nulls, thereby\nsignificantly improving physical layer security. Numerical results demonstrate\nthat the proposed approach achieves superior secrecy energy efficiency,\nattributed to the enhanced spatial flexibility provided by the movable antenna\narchitecture.", "comment": "5 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.20489v1", "cate": "eess.SP", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20507", "title": "Investigating the Effect of Spatial Context on Multi-Task Sea Ice Segmentation", "authors": ["Behzad Vahedi", "Rafael Pires de Lima", "Sepideh Jalayer", "Walter N. Meier", "Andrew P. Barrett", "Morteza Karimzadeh"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20507v1", "summary": "Capturing spatial context at multiple scales is crucial for deep\nlearning-based sea ice segmentation. However, the optimal specification of\nspatial context based on observation resolution and task characteristics\nremains underexplored. This study investigates the impact of spatial context on\nthe segmentation of sea ice concentration, stage of development, and floe size\nusing a multi-task segmentation model. We implement Atrous Spatial Pyramid\nPooling with varying atrous rates to systematically control the receptive field\nsize of convolutional operations, and to capture multi-scale contextual\ninformation. We explore the interactions between spatial context and feature\nresolution for different sea ice properties and examine how spatial context\ninfluences segmentation performance across different input feature combinations\nfrom Sentinel-1 SAR and Advanced Microwave Radiometer-2 (AMSR2) for multi-task\nmapping. Using Gradient-weighted Class Activation Mapping, we visualize how\natrous rates influence model decisions. Our findings indicate that smaller\nreceptive fields excel for high-resolution Sentinel-1 data, while medium\nreceptive fields yield better performances for stage of development\nsegmentation and larger receptive fields often lead to diminished performances.\nThe fusion of SAR and AMSR2 enhances segmentation across all tasks. We\nhighlight the value of lower-resolution 18.7 and 36.5 GHz AMSR2 channels in sea\nice mapping. These findings highlight the importance of selecting appropriate\nspatial context based on observation resolution and target properties in sea\nice mapping. By systematically analyzing receptive field effects in a\nmulti-task setting, our study provides insights for optimizing deep learning\nmodels in geospatial applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20507v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20091", "title": "ProsodyLM: Uncovering the Emerging Prosody Processing Capabilities in Speech Language Models", "authors": ["Kaizhi Qian", "Xulin Fan", "Junrui Ni", "Slava Shechtman", "Mark Hasegawa-Johnson", "Chuang Gan", "Yang Zhang"], "categories": ["cs.CL", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20091v1", "summary": "Speech language models refer to language models with speech processing and\nunderstanding capabilities. One key desirable capability for speech language\nmodels is the ability to capture the intricate interdependency between content\nand prosody. The existing mainstream paradigm of training speech language\nmodels, which converts speech into discrete tokens before feeding them into\nLLMs, is sub-optimal in learning prosody information -- we find that the\nresulting LLMs do not exhibit obvious emerging prosody processing capabilities\nvia pre-training alone. To overcome this, we propose ProsodyLM, which\nintroduces a simple tokenization scheme amenable to learning prosody. Each\nspeech utterance is first transcribed into text, followed by a sequence of\nword-level prosody tokens. Compared with conventional speech tokenization\nschemes, the proposed tokenization scheme retains more complete prosody\ninformation, and is more understandable to text-based LLMs. We find that\nProsodyLM can learn surprisingly diverse emerging prosody processing\ncapabilities through pre-training alone, ranging from harnessing the prosody\nnuances in generated speech, such as contrastive focus, understanding emotion\nand stress in an utterance, to maintaining prosody consistency in long\ncontexts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20091v1", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2503.08090", "title": "LATMOS: Latent Automaton Task Model from Observation Sequences", "authors": ["Weixiao Zhan", "Qiyue Dong", "Eduardo Sebastián", "Nikolay Atanasov"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025", "url": "http://arxiv.org/abs/2503.08090v2", "summary": "Robot task planning from high-level instructions is an important step towards\ndeploying fully autonomous robot systems in the service sector. Three key\naspects of robot task planning present challenges yet to be resolved\nsimultaneously, namely, (i) factorization of complex tasks specifications into\nsimpler executable subtasks, (ii) understanding of the current task state from\nraw observations, and (iii) planning and verification of task executions. To\naddress these challenges, we propose LATMOS, an automata-inspired task model\nthat, given observations from correct task executions, is able to factorize the\ntask, while supporting verification and planning operations. LATMOS combines an\nobservation encoder to extract the features from potentially high-dimensional\nobservations with automata theory to learn a sequential model that encapsulates\nan automaton with symbols in the latent feature space. We conduct extensive\nevaluations in three task model learning setups: (i) abstract tasks described\nby logical formulas, (ii) real-world human tasks described by videos and\nnatural language prompts and (iii) a robot task described by image and state\nobservations. The results demonstrate the improved plan generation and\nverification capabilities of LATMOS across observation modalities and tasks.", "comment": "IEEE/RSJ International Conference on Intelligent Robots and Systems\n  (IROS) 2025", "pdf_url": "http://arxiv.org/pdf/2503.08090v2", "cate": "cs.RO", "date": "2025-03-11", "updated": "2025-07-28"}
{"id": "2507.19730", "title": "Quaternion-Based Robust PCA for Efficient Moving Target Detection and Background Recovery in Color Videos", "authors": ["Liyang Wang", "Shiqian Wu", "Shun Fang", "Qile Zhu", "Jiaxin Wu", "Sos Again"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19730v1", "summary": "Moving target detection is a challenging computer vision task aimed at\ngenerating accurate segmentation maps in diverse in-the-wild color videos\ncaptured by static cameras. If backgrounds and targets can be simultaneously\nextracted and recombined, such synthetic data can significantly enrich\nannotated in-the-wild datasets and enhance the generalization ability of deep\nmodels. Quaternion-based RPCA (QRPCA) is a promising unsupervised paradigm for\ncolor image processing. However, in color video processing, Quaternion Singular\nValue Decomposition (QSVD) incurs high computational costs, and rank-1\nquaternion matrix fails to yield rank-1 color channels. In this paper, we\nreduce the computational complexity of QSVD to o(1) by utilizing a quaternion\nRiemannian manifold. Furthermor, we propose the universal QRPCA (uQRPCA)\nframework, which achieves a balance in simultaneously segmenting targets and\nrecovering backgrounds from color videos. Moreover, we expand to uQRPCA+ by\nintroducing the Color Rank-1 Batch (CR1B) method to further process and obtain\nthe ideal low-rank background across color channels. Experiments demonstrate\nour uQRPCA+ achieves State Of The Art (SOTA) performance on moving target\ndetection and background recovery tasks compared to existing open-source\nmethods. Our implementation is publicly available on GitHub at\nhttps://github.com/Ruchtech/uQRPCA", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19730v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.16117", "title": "BDIViz: An Interactive Visualization System for Biomedical Schema Matching with LLM-Powered Validation", "authors": ["Eden Wu", "Dishita G Turakhia", "Guande Wu", "Christos Koutras", "Sarah Keegan", "Wenke Liu", "Beata Szeitz", "David Fenyo", "Cláudio T. Silva", "Juliana Freire"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      11 pages, 9 figures. Accepted to IEEE VIS 2025 (Full Papers Track, submission ID 1204)", "url": "http://arxiv.org/abs/2507.16117v2", "summary": "Biomedical data harmonization is essential for enabling exploratory analyses\nand meta-studies, but the process of schema matching - identifying semantic\ncorrespondences between elements of disparate datasets (schemas) - remains a\nlabor-intensive and error-prone task. Even state-of-the-art automated methods\noften yield low accuracy when applied to biomedical schemas due to the large\nnumber of attributes and nuanced semantic differences between them. We present\nBDIViz, a novel visual analytics system designed to streamline the schema\nmatching process for biomedical data. Through formative studies with domain\nexperts, we identified key requirements for an effective solution and developed\ninteractive visualization techniques that address both scalability challenges\nand semantic ambiguity. BDIViz employs an ensemble approach that combines\nmultiple matching methods with LLM-based validation, summarizes matches through\ninteractive heatmaps, and provides coordinated views that enable users to\nquickly compare attributes and their values. Our method-agnostic design allows\nthe system to integrate various schema matching algorithms and adapt to\napplication-specific needs. Through two biomedical case studies and a\nwithin-subject user study with domain experts, we demonstrate that BDIViz\nsignificantly improves matching accuracy while reducing cognitive load and\ncuration time compared to baseline approaches.", "comment": "11 pages, 9 figures. Accepted to IEEE VIS 2025 (Full Papers Track,\n  submission ID 1204)", "pdf_url": "http://arxiv.org/pdf/2507.16117v2", "cate": "cs.HC", "date": "2025-07-22", "updated": "2025-07-28"}
{"id": "2507.20068", "title": "PERRY: Policy Evaluation with Confidence Intervals using Auxiliary Data", "authors": ["Aishwarya Mandyam", "Jason Meng", "Ge Gao", "Jiankai Sun", "Mac Schwager", "Barbara E. Engelhardt", "Emma Brunskill"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20068v1", "summary": "Off-policy evaluation (OPE) methods aim to estimate the value of a new\nreinforcement learning (RL) policy prior to deployment. Recent advances have\nshown that leveraging auxiliary datasets, such as those synthesized by\ngenerative models, can improve the accuracy of these value estimates.\nUnfortunately, such auxiliary datasets may also be biased, and existing methods\nfor using data augmentation for OPE in RL lack principled uncertainty\nquantification. In high stakes settings like healthcare, reliable uncertainty\nestimates are important for comparing policy value estimates. In this work, we\npropose two approaches to construct valid confidence intervals for OPE when\nusing data augmentation. The first provides a confidence interval over the\npolicy performance conditioned on a particular initial state $V^{\\pi}(s_0)$--\nsuch intervals are particularly important for human-centered applications. To\ndo so we introduce a new conformal prediction method for high dimensional state\nMDPs. Second, we consider the more common task of estimating the average policy\nperformance over many initial states; to do so we draw on ideas from doubly\nrobust estimation and prediction powered inference. Across simulators spanning\nrobotics, healthcare and inventory management, and a real healthcare dataset\nfrom MIMIC-IV, we find that our methods can use augmented data and still\nconsistently produce intervals that cover the ground truth values, unlike\npreviously proposed methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20068v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2408.13276", "title": "Non-convex matrix sensing: Breaking the quadratic rank barrier in the sample complexity", "authors": ["Dominik Stöger", "Yizhe Zhu"], "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "math.OC", "math.PR", "math.ST", "stat.TH"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      64 pages", "url": "http://arxiv.org/abs/2408.13276v4", "summary": "For the problem of reconstructing a low-rank matrix from a few linear\nmeasurements, two classes of algorithms have been widely studied in the\nliterature: convex approaches based on nuclear norm minimization, and\nnon-convex approaches that use factorized gradient descent. Under certain\nstatistical model assumptions, it is known that nuclear norm minimization\nrecovers the ground truth as soon as the number of samples scales linearly with\nthe number of degrees of freedom of the ground-truth. In contrast, while\nnon-convex approaches are computationally less expensive, existing recovery\nguarantees assume that the number of samples scales at least quadratically with\nthe rank $r$ of the ground-truth matrix. In this paper, we close this gap by\nshowing that the non-convex approaches can be as efficient as nuclear norm\nminimization in terms of sample complexity. Namely, we consider the problem of\nreconstructing a positive semidefinite matrix from a few Gaussian measurements.\nWe show that factorized gradient descent with spectral initialization converges\nto the ground truth at a linear rate as soon as the number of samples scales\nwith $ \\Omega (rd\\kappa^2)$, where $d$ is the dimension, and $\\kappa$ is the\ncondition number of the ground truth matrix. This improves the previous\nrank-dependence in the sample complexity of non-convex matrix factorization\nfrom quadratic to linear. Furthermore, we extend our theory to the noisy\nsetting, where we show that with noisy measurements, factorized gradient\ndescent with spectral initialization converges to the minimax optimal error up\nto a factor linear in $\\kappa$. Our proof relies on a probabilistic decoupling\nargument, where we show that the gradient descent iterates are only weakly\ndependent on the individual entries of the measurement matrices. We expect that\nour proof technique is of independent interest for other non-convex problems.", "comment": "64 pages", "pdf_url": "http://arxiv.org/pdf/2408.13276v4", "cate": "stat.ML", "date": "2024-08-20", "updated": "2025-07-25"}
{"id": "2507.20250", "title": "A Truthful Mechanism Design for Distributed Optimisation Algorithms in Networks with Self-interested Agents", "authors": ["Tianyi Zhong", "David Angeli"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      13 pages, 9 figures", "url": "http://arxiv.org/abs/2507.20250v1", "summary": "Enhancing resilience in multi-agent systems in the face of selfish agents is\nan important problem that requires further characterisation. This work develops\na truthful mechanism that avoids self-interested and strategic agents\nmaliciously manipulating the algorithm. We prove theoretically that the\nproposed mechanism incentivises self-interested agents to participate and\nfollow the provided algorithm faithfully. Additionally, the mechanism is\ncompatible with any distributed optimisation algorithm that can calculate at\nleast one subgradient at a given point. Finally, we present an illustrative\nexample that shows the effectiveness of the mechanism.", "comment": "13 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.20250v1", "cate": "eess.SY", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20587", "title": "Real-Time Distributed Optical Fiber Vibration Recognition via Extreme Lightweight Model and Cross-Domain Distillation", "authors": ["Zhongyao Luo", "Hao Wu", "Zhao Ge", "Ming Tang"], "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      12 pages, 8 figures", "url": "http://arxiv.org/abs/2507.20587v1", "summary": "Distributed optical fiber vibration sensing (DVS) systems offer a promising\nsolution for large-scale monitoring and intrusion event recognition. However,\ntheir practical deployment remains hindered by two major challenges:\ndegradation of recognition accuracy in dynamic conditions, and the\ncomputational bottleneck of real-time processing for mass sensing data. This\npaper presents a new solution to these challenges, through a FPGA-accelerated\nextreme lightweight model along with a newly proposed knowledge distillation\nframework. The proposed three-layer depthwise separable convolution network\ncontains only 4141 parameters, which is the most compact architecture in this\nfield to date, and achieves a maximum processing speed of 0.019 ms for each\nsample covering a 12.5 m fiber length over 0.256 s. This performance\ncorresponds to real-time processing capabilities for sensing fibers extending\nup to 168.68 km. To improve generalizability under changing environments, the\nproposed cross-domain distillation framework guided by physical priors is used\nhere to embed frequency-domain insights into the time-domain model. This allows\nfor time-frequency representation learning without increasing complexity and\nboosts recognition accuracy from 51.93% to 95.72% under unseen environmental\nconditions. The proposed methodology provides key advancements including a\nframework combining interpretable signal processing technique with deep\nlearning and a reference architecture for real-time processing and\nedge-computing in DVS systems, and more general distributed optical fiber\nsensing (DOFS) area. It mitigates the trade-off between sensing range and\nreal-time capability, bridging the gap between theoretical capabilities and\npractical deployment requirements. Furthermore, this work reveals a new\ndirection for building more efficient, robust and explainable artificial\nintelligence systems for DOFS technologies.", "comment": "12 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.20587v1", "cate": "eess.SP", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20884", "title": "The Importance of Facial Features in Vision-based Sign Language Recognition: Eyes, Mouth or Full Face?", "authors": ["Dinh Nam Pham", "Eleftherios Avramidis"], "categories": ["cs.CV", "cs.CL", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at 9th International Workshop on Sign Language Translation and Avatar Technologies @ ACM IVA'25", "url": "http://arxiv.org/abs/2507.20884v1", "summary": "Non-manual facial features play a crucial role in sign language\ncommunication, yet their importance in automatic sign language recognition\n(ASLR) remains underexplored. While prior studies have shown that incorporating\nfacial features can improve recognition, related work often relies on\nhand-crafted feature extraction and fails to go beyond the comparison of manual\nfeatures versus the combination of manual and facial features. In this work, we\nsystematically investigate the contribution of distinct facial regionseyes,\nmouth, and full faceusing two different deep learning models (a CNN-based model\nand a transformer-based model) trained on an SLR dataset of isolated signs with\nrandomly selected classes. Through quantitative performance and qualitative\nsaliency map evaluation, we reveal that the mouth is the most important\nnon-manual facial feature, significantly improving accuracy. Our findings\nhighlight the necessity of incorporating facial features in ASLR.", "comment": "Accepted at 9th International Workshop on Sign Language Translation\n  and Avatar Technologies @ ACM IVA'25", "pdf_url": "http://arxiv.org/pdf/2507.20884v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20140", "title": "Do Not Mimic My Voice: Speaker Identity Unlearning for Zero-Shot Text-to-Speech", "authors": ["Taesoo Kim", "Jinju Kim", "Dongchan Kim", "Jong Hwan Ko", "Gyeong-Moon Park"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Proceedings of the 42nd International Conference on Machine Learning (ICML 2025), Vancouver, Canada. PMLR 267, 2025. Authors Jinju Kim and Taesoo Kim contributed equally", "url": "http://arxiv.org/abs/2507.20140v1", "summary": "The rapid advancement of Zero-Shot Text-to-Speech (ZS-TTS) technology has\nenabled high-fidelity voice synthesis from minimal audio cues, raising\nsignificant privacy and ethical concerns. Despite the threats to voice privacy,\nresearch to selectively remove the knowledge to replicate unwanted individual\nvoices from pre-trained model parameters has not been explored. In this paper,\nwe address the new challenge of speaker identity unlearning for ZS-TTS systems.\nTo meet this goal, we propose the first machine unlearning frameworks for\nZS-TTS, especially Teacher-Guided Unlearning (TGU), designed to ensure the\nmodel forgets designated speaker identities while retaining its ability to\ngenerate accurate speech for other speakers. Our proposed methods incorporate\nrandomness to prevent consistent replication of forget speakers' voices,\nassuring unlearned identities remain untraceable. Additionally, we propose a\nnew evaluation metric, speaker-Zero Retrain Forgetting (spk-ZRF). This assesses\nthe model's ability to disregard prompts associated with forgotten speakers,\neffectively neutralizing its knowledge of these voices. The experiments\nconducted on the state-of-the-art model demonstrate that TGU prevents the model\nfrom replicating forget speakers' voices while maintaining high quality for\nother speakers. The demo is available at https://speechunlearn.github.io/", "comment": "Proceedings of the 42nd International Conference on Machine Learning\n  (ICML 2025), Vancouver, Canada. PMLR 267, 2025. Authors Jinju Kim and Taesoo\n  Kim contributed equally", "pdf_url": "http://arxiv.org/pdf/2507.20140v1", "cate": "cs.SD", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19632", "title": "Fully Dynamic Spectral and Cut Sparsifiers for Directed Graphs", "authors": ["Yibin Zhao"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19632v1", "summary": "Recent years have seen extensive research on directed graph sparsification.\nIn this work, we initiate the study of fast fully dynamic spectral and cut\nsparsification algorithms for directed graphs.\n  We introduce a new notion of spectral sparsification called degree-balance\npreserving spectral approximation, which maintains the difference between the\nin-degree and out-degree of each vertex. The approximation error is measured\nwith respect to the corresponding undirected Laplacian. This notion is\nequivalent to direct Eulerian spectral approximation when the input graph is\nEulerian. Our algorithm achieves an amortized update time of\n$O(\\varepsilon^{-2} \\cdot \\text{polylog}(n))$ and produces a sparsifier of size\n$O(\\varepsilon^{-2} n \\cdot \\text{polylog}(n))$. Additionally, we present an\nalgorithm that maintains a constant-factor approximation sparsifier of size\n$O(n \\cdot \\text{polylog}(n))$ against an adaptive adversary for\n$O(\\text{polylog}(n))$-partially symmetrized graphs, a notion introduced in\n[Kyng-Meierhans-Probst Gutenberg '22]. A $\\beta$-partial symmetrization of a\ndirected graph $\\vec{G}$ is the union of $\\vec{G}$ and $\\beta \\cdot G$, where\n$G$ is the corresponding undirected graph of $\\vec{G}$. This algorithm also\nachieves a polylogarithmic amortized update time.\n  Moreover, we develop a fully dynamic algorithm for maintaining a cut\nsparsifier for $\\beta$-balanced directed graphs, where the ratio between\nweighted incoming and outgoing edges of any cut is at most $\\beta$. This\nalgorithm explicitly maintains a cut sparsifier of size\n$O(\\varepsilon^{-2}\\beta n \\cdot \\text{polylog}(n))$ in worst-case update time\n$O(\\varepsilon^{-2}\\beta \\cdot \\text{polylog}(n))$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19632v1", "cate": "cs.DS", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2503.08358", "title": "DG16M: A Large-Scale Dataset for Dual-Arm Grasping with Force-Optimized Grasps", "authors": ["Md Faizal Karim", "Mohammed Saad Hashmi", "Shreya Bollimuntha", "Mahesh Reddy Tapeti", "Gaurav Singh", "Nagamanikandan Govindan", "K Madhava Krishna"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.08358v3", "summary": "Dual-arm robotic grasping is crucial for handling large objects that require\nstable and coordinated manipulation. While single-arm grasping has been\nextensively studied, datasets tailored for dual-arm settings remain scarce. We\nintroduce a large-scale dataset of 16 million dual-arm grasps, evaluated under\nimproved force-closure constraints. Additionally, we develop a benchmark\ndataset containing 300 objects with approximately 30,000 grasps, evaluated in a\nphysics simulation environment, providing a better grasp quality assessment for\ndual-arm grasp synthesis methods. Finally, we demonstrate the effectiveness of\nour dataset by training a Dual-Arm Grasp Classifier network that outperforms\nthe state-of-the-art methods by 15\\%, achieving higher grasp success rates and\nimproved generalization across objects.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.08358v3", "cate": "cs.RO", "date": "2025-03-11", "updated": "2025-07-27"}
{"id": "2507.19766", "title": "UloRL:An Ultra-Long Output Reinforcement Learning Approach for Advancing Large Language Models' Reasoning Abilities", "authors": ["Dong Du", "Shulin Liu", "Tao Yang", "Shaohua Chen", "Yang Li"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages", "url": "http://arxiv.org/abs/2507.19766v1", "summary": "Recent advances in large language models (LLMs) have highlighted the\npotential of reinforcement learning with verifiable rewards (RLVR) to enhance\nreasoning capabilities through extended output sequences. However, traditional\nRL frameworks face inefficiencies when handling ultra-long outputs due to\nlong-tail sequence distributions and entropy collapse during training. To\naddress these challenges, we propose an Ultra-Long Output Reinforcement\nLearning (UloRL) approach for advancing large language models' reasoning\nabilities. Specifically, we divide ultra long output decoding into short\nsegments, enabling efficient training by mitigating delays caused by long-tail\nsamples. Additionally, we introduce dynamic masking of well-Mastered Positive\nTokens (MPTs) to prevent entropy collapse. Experimental results demonstrate the\neffectiveness of our approach. On the Qwen3-30B-A3B model, RL with segment\nrollout achieved 2.06x increase in training speed, while RL training with\n128k-token outputs improves the model's performance on AIME2025 from 70.9\\% to\n85.1\\% and on BeyondAIME from 50.7\\% to 61.9\\%, even surpassing Qwen3-235B-A22B\nwith remarkable gains. These findings underscore the potential of our methods\nto advance the reasoning capabilities of LLMs with ultra-long sequence\ngeneration. We will release our code and model for further use by the\ncommunity.", "comment": "12 pages", "pdf_url": "http://arxiv.org/pdf/2507.19766v1", "cate": "cs.CL", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.16466", "title": "SceneLoom: Communicating Data with Scene Context", "authors": ["Lin Gao", "Leixian Shen", "Yuheng Zhao", "Jiexiang Lan", "Huamin Qu", "Siming Chen"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.16466v2", "summary": "In data-driven storytelling contexts such as data journalism and data videos,\ndata visualizations are often presented alongside real-world imagery to support\nnarrative context. However, these visualizations and contextual images\ntypically remain separated, limiting their combined narrative expressiveness\nand engagement. Achieving this is challenging due to the need for fine-grained\nalignment and creative ideation. To address this, we present SceneLoom, a\nVision-Language Model (VLM)-powered system that facilitates the coordination of\ndata visualization with real-world imagery based on narrative intents. Through\na formative study, we investigated the design space of coordination\nrelationships between data visualization and real-world scenes from the\nperspectives of visual alignment and semantic coherence. Guided by the derived\ndesign considerations, SceneLoom leverages VLMs to extract visual and semantic\nfeatures from scene images and data visualization, and perform design mapping\nthrough a reasoning process that incorporates spatial organization, shape\nsimilarity, layout consistency, and semantic binding. The system generates a\nset of contextually expressive, image-driven design alternatives that achieve\ncoherent alignments across visual, semantic, and data dimensions. Users can\nexplore these alternatives, select preferred mappings, and further refine the\ndesign through interactive adjustments and animated transitions to support\nexpressive data communication. A user study and an example gallery validate\nSceneLoom's effectiveness in inspiring creative design and facilitating design\nexternalization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.16466v2", "cate": "cs.HC", "date": "2025-07-22", "updated": "2025-07-28"}
{"id": "2507.20072", "title": "Sparse Equation Matching: A Derivative-Free Learning for General-Order Dynamical Systems", "authors": ["Jiaqiang Li", "Jianbin Tan", "Xueqin Wang"], "categories": ["cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20072v1", "summary": "Equation discovery is a fundamental learning task for uncovering the\nunderlying dynamics of complex systems, with wide-ranging applications in areas\nsuch as brain connectivity analysis, climate modeling, gene regulation, and\nphysical system simulation. However, many existing approaches rely on accurate\nderivative estimation and are limited to first-order dynamical systems,\nrestricting their applicability to real-world scenarios. In this work, we\npropose sparse equation matching (SEM), a unified framework that encompasses\nseveral existing equation discovery methods under a common formulation. SEM\nintroduces an integral-based sparse regression method using Green's functions,\nenabling derivative-free estimation of differential operators and their\nassociated driving functions in general-order dynamical systems. The\neffectiveness of SEM is demonstrated through extensive simulations,\nbenchmarking its performance against derivative-based approaches. We then apply\nSEM to electroencephalographic (EEG) data recorded during multiple oculomotor\ntasks, collected from 52 participants in a brain-computer interface experiment.\nOur method identifies active brain regions across participants and reveals\ntask-specific connectivity patterns. These findings offer valuable insights\ninto brain connectivity and the underlying neural mechanisms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20072v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2502.01189", "title": "Compressed Image Generation with Denoising Diffusion Codebook Models", "authors": ["Guy Ohayon", "Hila Manor", "Tomer Michaeli", "Michael Elad"], "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Published in the International Conference on Machine Learning (ICML) 2025. Code and demo are available at this https URL", "url": "http://arxiv.org/abs/2502.01189v4", "summary": "We present a novel generative approach based on Denoising Diffusion Models\n(DDMs), which produces high-quality image samples along with their losslessly\ncompressed bit-stream representations. This is obtained by replacing the\nstandard Gaussian noise sampling in the reverse diffusion with a selection of\nnoise samples from pre-defined codebooks of fixed iid Gaussian vectors.\nSurprisingly, we find that our method, termed Denoising Diffusion Codebook\nModel (DDCM), retains sample quality and diversity of standard DDMs, even for\nextremely small codebooks. We leverage DDCM and pick the noises from the\ncodebooks that best match a given image, converting our generative model into a\nhighly effective lossy image codec achieving state-of-the-art perceptual image\ncompression results. More generally, by setting other noise selections rules,\nwe extend our compression method to any conditional image generation task\n(e.g., image restoration), where the generated images are produced jointly with\ntheir condensed bit-stream representations. Our work is accompanied by a\nmathematical interpretation of the proposed compressed conditional generation\nschemes, establishing a connection with score-based approximations of posterior\nsamplers for the tasks considered.", "comment": "Published in the International Conference on Machine Learning (ICML)\n  2025. Code and demo are available at https://ddcm-2025.github.io/", "pdf_url": "http://arxiv.org/pdf/2502.01189v4", "cate": "eess.IV", "date": "2025-02-03", "updated": "2025-07-27"}
{"id": "2507.20277", "title": "Relaxing Probabilistic Latent Variable Models' Specification via Infinite-Horizon Optimal Control", "authors": ["Zhichao Chen", "Hao Wang", "Licheng Pan", "Yiran Ma", "Yunfei Teng", "Jiaze Ma", "Le Yao", "Zhiqiang Ge", "Zhihuan Song"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20277v1", "summary": "In this paper, we address the issue of model specification in probabilistic\nlatent variable models (PLVMs) using an infinite-horizon optimal control\napproach. Traditional PLVMs rely on joint distributions to model complex data,\nbut introducing latent variables results in an ill-posed parameter learning\nproblem. To address this issue, regularization terms are typically introduced,\nleading to the development of the expectation-maximization (EM) algorithm,\nwhere the latent variable distribution is restricted to a predefined normalized\ndistribution family to facilitate the expectation step. To overcome this\nlimitation, we propose representing the latent variable distribution as a\nfinite set of instances perturbed via an ordinary differential equation with a\ncontrol policy. This approach ensures that the instances asymptotically\nconverge to the true latent variable distribution as time approaches infinity.\nBy doing so, we reformulate the distribution inference problem as an optimal\ncontrol policy determination problem, relaxing the model specification to an\ninfinite-horizon path space. Building on this formulation, we derive the\ncorresponding optimal control policy using the Pontryagin's maximum principle\nand provide a closed-form expression for its implementation using the\nreproducing kernel Hilbert space. After that, we develop a novel,\nconvergence-guaranteed EM algorithm for PLVMs based on this\ninfinite-horizon-optimal-control-based inference strategy. Finally, extensive\nexperiments are conducted to validate the effectiveness and superiority of the\nproposed approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20277v1", "cate": "eess.SY", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20648", "title": "RFI and Jamming Detection in Antenna Arrays with an LSTM Autoencoder", "authors": ["Christos Ntemkas", "Antonios Argyriou"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20648v1", "summary": "Radio frequency interference (RFI) and malicious jammers are a significant\nproblem in our wireless world. Detecting RFI or jamming is typically performed\nwith model-based statistical detection or AI-empowered algorithms that use an\ninput baseband data or time-frequency representations like spectrograms. In\nthis work we depart from the previous approaches and we leverage data in\nantenna array systems. We use Fourier imaging to localize spatially the sources\nand then deploy a deep LSTM autoencoder that detects RFI and jamming as\nanomalies. Our results for different power levels of the RFI/jamming sources,\nand the signal of interest, reveal that our detector offers high performance\nwithout needing any pre-existing knowledge regarding the RFI or jamming signal.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20648v1", "cate": "eess.SP", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2305.00046", "title": "AutoLungDx: A Hybrid Deep Learning Approach for Early Lung Cancer Diagnosis Using 3D Res-U-Net, YOLOv5, and Vision Transformers", "authors": ["Samiul Based Shuvo", "Tasnia Binte Mamun"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2305.00046v3", "summary": "Lung cancer is a leading cause of cancer-related deaths worldwide, and early\ndetection is crucial for improving patient outcomes. Nevertheless, early\ndiagnosis of cancer is a major challenge, particularly in low-resource settings\nwhere access to medical resources and trained radiologists is limited. The\nobjective of this study is to propose an automated end-to-end deep\nlearning-based framework for the early detection and classification of lung\nnodules, specifically for low-resource settings. The proposed framework\nconsists of three stages: lung segmentation using a modified 3D U-Net named 3D\nRes-U-Net, nodule detection using YOLO-v5, and classification with a Vision\nTransformer-based architecture. We evaluated the proposed framework on a\npublicly available dataset, LUNA16. The proposed framework's performance was\nmeasured using the respective domain's evaluation matrices. The proposed\nframework achieved a 98.82% lung segmentation dice score while detecting the\nlung nodule with 0.76 mAP@50 from the segmented lung, at a low false-positive\nrate. The performance of both networks of the proposed framework was compared\nwith other studies and found to outperform them regarding segmentation and\ndetection accuracy. Additionally, our proposed Vision transformer network\nobtained an accuracy of 93.57%, which is 1.21% higher than the state-of-the-art\nnetworks. Our proposed end-to-end deep learning-based framework can effectively\nsegment lungs, and detect and classify lung nodules, specifically in\nlow-resource settings with limited access to radiologists. The proposed\nframework outperforms existing studies regarding all the respective evaluation\nmetrics. The proposed framework can potentially improve the accuracy and\nefficiency of lung cancer screening in low-resource settings, ultimately\nleading to better patient outcomes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2305.00046v3", "cate": "eess.IV", "date": "2023-04-28", "updated": "2025-07-27"}
{"id": "2507.20169", "title": "Self-Improvement for Audio Large Language Model using Unlabeled Speech", "authors": ["Shaowen Wang", "Xinyuan Chen", "Yao Xu"], "categories": ["cs.SD", "eess.AS", "I.2.7; H.5.5"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      To appear in Interspeech 2025. 6 pages, 1 figure", "url": "http://arxiv.org/abs/2507.20169v1", "summary": "Recent audio LLMs have emerged rapidly, demonstrating strong generalization\nacross various speech tasks. However, given the inherent complexity of speech\nsignals, these models inevitably suffer from performance degradation in\nspecific target domains. To address this, we focus on enhancing audio LLMs in\ntarget domains without any labeled data. We propose a self-improvement method\ncalled SI-SDA, leveraging the information embedded in large-model decoding to\nevaluate the quality of generated pseudo labels and then perform domain\nadaptation based on reinforcement learning optimization. Experimental results\nshow that our method consistently and significantly improves audio LLM\nperformance, outperforming existing baselines in WER and BLEU across multiple\npublic datasets of automatic speech recognition (ASR), spoken\nquestion-answering (SQA), and speech-to-text translation (S2TT). Furthermore,\nour approach exhibits high data efficiency, underscoring its potential for\nreal-world deployment.", "comment": "To appear in Interspeech 2025. 6 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.20169v1", "cate": "cs.SD", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19649", "title": "Online Rounding Schemes for $ k $-Rental Problems", "authors": ["Hossein Nekouyan", "Bo Sun", "Raouf Boutaba", "Xiaoqi Tan"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19649v2", "summary": "We study two online resource allocation problems with reusability in an\nadversarial setting, namely kRental-Fixed and kRental-Variable. In both\nproblems, a decision-maker manages $k$ identical reusable units and faces a\nsequence of rental requests over time. We develop theoretically grounded\nrelax-and-round algorithms with provable competitive ratio guarantees for both\nsettings. For kRental-Fixed, we present an optimal randomized algorithm that\nachieves the best possible competitive ratio. The algorithm first computes an\noptimal fractional allocation using a price-based approach, and then applies a\nnovel lossless online rounding scheme to obtain an integral solution. For\nkRental-Variable, we first establish the impossibility of achieving lossless\nonline rounding. We then introduce a limited-correlation rounding technique\nthat treats each unit independently while introducing controlled dependencies\nacross allocation decisions involving the same unit. Combined with a\ncarefully-crafted price-based method for computing the fractional allocation,\nthis approach yields an order-optimal competitive ratio for the\nvariable-duration setting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19649v2", "cate": "cs.DS", "date": "2025-07-25", "updated": "2025-07-29"}
{"id": "2503.12030", "title": "Hydra-NeXt: Robust Closed-Loop Driving with Open-Loop Training", "authors": ["Zhenxin Li", "Shihao Wang", "Shiyi Lan", "Zhiding Yu", "Zuxuan Wu", "Jose M. Alvarez"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.12030v2", "summary": "End-to-end autonomous driving research currently faces a critical challenge\nin bridging the gap between open-loop training and closed-loop deployment.\nCurrent approaches are trained to predict trajectories in an open-loop\nenvironment, which struggle with quick reactions to other agents in closed-loop\nenvironments and risk generating kinematically infeasible plans due to the gap\nbetween open-loop training and closed-loop driving. In this paper, we introduce\nHydra-NeXt, a novel multi-branch planning framework that unifies trajectory\nprediction, control prediction, and a trajectory refinement network in one\nmodel. Unlike current open-loop trajectory prediction models that only handle\ngeneral-case planning, Hydra-NeXt further utilizes a control decoder to focus\non short-term actions, which enables faster responses to dynamic situations and\nreactive agents. Moreover, we propose the Trajectory Refinement module to\naugment and refine the planning decisions by effectively adhering to kinematic\nconstraints in closed-loop environments. This unified approach bridges the gap\nbetween open-loop training and closed-loop driving, demonstrating superior\nperformance of 65.89 Driving Score (DS) and 48.20% Success Rate (SR) on the\nBench2Drive dataset without relying on external experts for data collection.\nHydra-NeXt surpasses the previous state-of-the-art by 22.98 DS and 17.49 SR,\nmarking a significant advancement in autonomous driving. Code will be available\nat https://github.com/woxihuanjiangguo/Hydra-NeXt.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.12030v2", "cate": "cs.RO", "date": "2025-03-15", "updated": "2025-07-26"}
{"id": "2507.19823", "title": "HCAttention: Extreme KV Cache Compression via Heterogeneous Attention Computing for LLMs", "authors": ["Dongquan Yang", "Yifan Yang", "Xiaotian Yu", "Xianbiao Qi", "Rong Xiao"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19823v1", "summary": "Processing long-context inputs with large language models presents a\nsignificant challenge due to the enormous memory requirements of the Key-Value\n(KV) cache during inference. Existing KV cache compression methods exhibit\nnoticeable performance degradation when memory is reduced by more than 85%.\nAdditionally, strategies that leverage GPU-CPU collaboration for approximate\nattention remain underexplored in this setting. We propose HCAttention, a\nheterogeneous attention computation framework that integrates key quantization,\nvalue offloading, and dynamic KV eviction to enable efficient inference under\nextreme memory constraints. The method is compatible with existing transformer\narchitectures and does not require model fine-tuning. Experimental results on\nthe LongBench benchmark demonstrate that our approach preserves the accuracy of\nfull-attention model while shrinking the KV cache memory footprint to 25% of\nits original size. Remarkably, it stays competitive with only 12.5% of the\ncache, setting a new state-of-the-art in LLM KV cache compression. To the best\nof our knowledge, HCAttention is the first to extend the Llama-3-8B model to\nprocess 4 million tokens on a single A100 GPU with 80GB memory.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19823v1", "cate": "cs.CL", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.18151", "title": "Understood: Real-Time Communication Support for Adults with ADHD Using Mixed Reality", "authors": ["Shizhen Zhang", "Shengxin Li", "Quan Li"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Will Appear at UIST2025", "url": "http://arxiv.org/abs/2507.18151v2", "summary": "Adults with Attention Deficit Hyperactivity Disorder (ADHD) often experience\ncommunication challenges, primarily due to executive dysfunction and emotional\ndysregulation, even after years of social integration. While existing\ninterventions predominantly target children through structured or intrusive\nmethods, adults lack tools that translate clinical strategies into daily\ncommunication support. To address this gap, we present Understood, a Mixed\nReality (MR) system implemented on Microsoft HoloLens 2, designed to assist\nadults with ADHD in real-world communication. Through formative semi-structured\ninterviews and a design workshop, we identified critical communication barriers\nand derived design goals for the system. Understood combines three key\nfeatures: (1) real-time conversation summarization to reduce cognitive load,\n(2) context-aware subsequent word suggestions during moments of disfluency, and\n(3) topic shifting detection and reminding to mitigate off-topic transitions. A\nwithin-subjects user study and expert interviews demonstrate that Understood\neffectively supports communication with high usability, offering a complement\nto therapist-mediated interventions.", "comment": "Will Appear at UIST2025", "pdf_url": "http://arxiv.org/pdf/2507.18151v2", "cate": "cs.HC", "date": "2025-07-24", "updated": "2025-07-26"}
{"id": "2507.20078", "title": "Cluster Purge Loss: Structuring Transformer Embeddings for Equivalent Mutants Detection", "authors": ["Adelaide Danilov", "Aria Nourbakhsh", "Christoph Schommer"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 6 figures", "url": "http://arxiv.org/abs/2507.20078v1", "summary": "Recent pre-trained transformer models achieve superior performance in various\ncode processing objectives. However, although effective at optimizing decision\nboundaries, common approaches for fine-tuning them for downstream\nclassification tasks - distance-based methods or training an additional\nclassification head - often fail to thoroughly structure the embedding space to\nreflect nuanced intra-class semantic relationships. Equivalent code mutant\ndetection is one of these tasks, where the quality of the embedding space is\ncrucial to the performance of the models. We introduce a novel framework that\nintegrates cross-entropy loss with a deep metric learning objective, termed\nCluster Purge Loss. This objective, unlike conventional approaches,\nconcentrates on adjusting fine-grained differences within each class,\nencouraging the separation of instances based on semantical equivalency to the\nclass center using dynamically adjusted borders. Employing UniXCoder as the\nbase model, our approach demonstrates state-of-the-art performance in the\ndomain of equivalent mutant detection and produces a more interpretable\nembedding space.", "comment": "11 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.20078v1", "cate": "cs.LG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2502.09720", "title": "NestQuant: Nested Lattice Quantization for Matrix Products and LLMs", "authors": ["Semyon Savkin", "Eitan Porat", "Or Ordentlich", "Yury Polyanskiy"], "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      23 pages; Accepted at the 42nd International Conference on Machine Learning (ICML 2025)", "url": "http://arxiv.org/abs/2502.09720v3", "summary": "Post-training quantization (PTQ) has emerged as a critical technique for\nefficient deployment of large language models (LLMs). This work proposes\nNestQuant, a novel PTQ scheme for weights and activations that is based on\nself-similar nested lattices. Recent works have mathematically shown such\nquantizers to be information-theoretically optimal for low-precision matrix\nmultiplication. We implement a practical low-complexity version of NestQuant\nbased on Gosset lattice, making it a drop-in quantizer for any matrix\nmultiplication step (e.g., in self-attention, MLP etc). For example, NestQuant\nquantizes weights, KV-cache, and activations of Llama-3-8B to 4 bits, achieving\nperplexity of 6.6 on wikitext2. This represents more than 55% reduction in\nperplexity gap with respect to unquantized model (perplexity of 6.14) compared\nto state-of-the-art Metas SpinQuant (perplexity 7.3), OstQuant (7.3) and QuaRot\n(8.2). Comparisons on bigger models (up to 70B) and on various LLM evaluation\nbenchmarks confirm uniform superiority of NestQuant.", "comment": "23 pages; Accepted at the 42nd International Conference on Machine\n  Learning (ICML 2025)", "pdf_url": "http://arxiv.org/pdf/2502.09720v3", "cate": "cs.LG", "date": "2025-02-13", "updated": "2025-07-26"}
{"id": "2507.20545", "title": "HJB-based online safety-embedded critic learning for uncertain systems with self-triggered mechanism", "authors": ["Zhanglin Shangguan", "Bo Yang", "Qi Li", "Wei Xiao", "Xingping Guan"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20545v1", "summary": "This paper presents a learning-based optimal control framework for\nsafety-critical systems with parametric uncertainties, addressing both\ntime-triggered and self-triggered controller implementations. First, we develop\na robust control barrier function (RCBF) incorporating Lyapunov-based\ncompensation terms to rigorously guarantee safety despite parametric\nuncertainties. Building on this safety guarantee, we formulate the constrained\noptimal control problem as the minimization of a novel safety-embedded value\nfunction, where the RCBF is involved via a Lagrange multiplier that adaptively\nbalances safety constraints against optimal stabilization objectives. To\nenhance computational efficiency, we propose a self-triggered implementation\nmechanism that reduces control updates while maintaining dual stability-safety\nguarantees. The resulting self-triggered constrained Hamilton-Jacobi-Bellman\n(HJB) equation is solved through an online safety-embedded critic learning\nframework, with the Lagrange multiplier computed in real time to ensure safety.\nNumerical simulations demonstrate the effectiveness of the proposed approach in\nachieving both safety and control performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20545v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20651", "title": "Angle-distance decomposition based on deep learning for active sonar detection", "authors": ["Jichao Zhang", "Xiao-Lei Zhang", "Kunde Yang"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20651v1", "summary": "Underwater target detection using active sonar constitutes a critical\nresearch area in marine sciences and engineering. However, traditional signal\nprocessing methods face significant challenges in complex underwater\nenvironments due to noise, reverberation, and interference. To address these\nissues, this paper presents a deep learning-based active sonar target detection\nmethod that decomposes the detection process into separate angle and distance\nestimation tasks. Active sonar target detection employs deep learning models to\npredict target distance and angle, with the final target position determined by\nintegrating these estimates. Limited underwater acoustic data hinders effective\nmodel training, but transfer learning and simulation offer practical solutions\nto this challenge. Experimental results verify that the method achieves\neffective and robust performance under challenging conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20651v1", "cate": "eess.SP", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2411.04004", "title": "Synomaly Noise and Multi-Stage Diffusion: A Novel Approach for Unsupervised Anomaly Detection in Medical Images", "authors": ["Yuan Bi", "Lucie Huang", "Ricarda Clarenbach", "Reza Ghotbi", "Angelos Karlas", "Nassir Navab", "Zhongliang Jiang"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.04004v2", "summary": "Anomaly detection in medical imaging plays a crucial role in identifying\npathological regions across various imaging modalities, such as brain MRI,\nliver CT, and carotid ultrasound (US). However, training fully supervised\nsegmentation models is often hindered by the scarcity of expert annotations and\nthe complexity of diverse anatomical structures. To address these issues, we\npropose a novel unsupervised anomaly detection framework based on a diffusion\nmodel that incorporates a synthetic anomaly (Synomaly) noise function and a\nmulti-stage diffusion process. Synomaly noise introduces synthetic anomalies\ninto healthy images during training, allowing the model to effectively learn\nanomaly removal. The multi-stage diffusion process is introduced to\nprogressively denoise images, preserving fine details while improving the\nquality of anomaly-free reconstructions. The generated high-fidelity\ncounterfactual healthy images can further enhance the interpretability of the\nsegmentation models, as well as provide a reliable baseline for evaluating the\nextent of anomalies and supporting clinical decision-making. Notably, the\nunsupervised anomaly detection model is trained purely on healthy images,\neliminating the need for anomalous training samples and pixel-level\nannotations. We validate the proposed approach on brain MRI, liver CT datasets,\nand carotid US. The experimental results demonstrate that the proposed\nframework outperforms existing state-of-the-art unsupervised anomaly detection\nmethods, achieving performance comparable to fully supervised segmentation\nmodels in the US dataset. Ablation studies further highlight the contributions\nof Synomaly noise and the multi-stage diffusion process in improving anomaly\nsegmentation. These findings underscore the potential of our approach as a\nrobust and annotation-efficient alternative for medical anomaly detection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.04004v2", "cate": "eess.IV", "date": "2024-11-06", "updated": "2025-07-27"}
{"id": "2507.20485", "title": "Sound Safeguarding for Acoustic Measurement Using Any Sounds: Tools and Applications", "authors": ["Hideki Kawahara", "Kohei Yatabe", "Ken-Ichi Sakakibara"], "categories": ["cs.SD", "eess.AS", "68-06", "J.2"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      2 pages, 2 figures, IEEE GCCE 2025 Demo session, Accepted", "url": "http://arxiv.org/abs/2507.20485v1", "summary": "We demonstrate tools and applications developed based on the method of \"sound\nsafeguarding,\" which enables any sound to be used for acoustic measurements. We\ndeveloped tools for preparation, interactive and real-time measurement, and\nreport generation. We extended and modified the method during its development\nbased on its application in various practical situations. We have open-sourced\nthese tools and encourage prospective users to use them to improve their\nacoustic environments.", "comment": "2 pages, 2 figures, IEEE GCCE 2025 Demo session, Accepted", "pdf_url": "http://arxiv.org/pdf/2507.20485v1", "cate": "cs.SD", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.19859", "title": "Improved 2-Approximate Shortest Paths for close vertex pairs", "authors": ["Manoj Gupta"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Accepted in FOCS 2025", "url": "http://arxiv.org/abs/2507.19859v1", "summary": "An influential result by Dor, Halperin, and Zwick (FOCS 1996, SICOMP 2000)\nimplies an algorithm that can compute approximate shortest paths for all vertex\npairs in $\\tilde{O}(n^{2+O\\left(\\frac{1}{k}\\right )})$ time, ensuring that the\noutput distance is at most twice the actual shortest path, provided the pairs\nare at least $k$ apart, where $k \\ge 2$. We present the first improvement on\nthis result in over 25 years. Our algorithm achieves roughly same\n$\\tilde{O}(n^{2+\\frac{1}{k}})$ runtime but applies to vertex pairs merely\n$O(\\log k)$ apart, where $\\log k \\ge 1$. When $k=\\log n$, the running time of\nour algorithm is $\\tilde{O}(n^2)$ and it works for all pairs at least $O(\\log\n\\log n)$ apart. Our algorithm is combinatorial, randomized, and returns correct\nresults for all pairs with a high probability.", "comment": "Accepted in FOCS 2025", "pdf_url": "http://arxiv.org/pdf/2507.19859v1", "cate": "cs.DS", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2503.13082", "title": "Free-form language-based robotic reasoning and grasping", "authors": ["Runyu Jiao", "Alice Fasoli", "Francesco Giuliari", "Matteo Bortolon", "Sergio Povoli", "Guofeng Mei", "Yiming Wang", "Fabio Poiesi"], "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to IROS 2025. Project website: this https URL", "url": "http://arxiv.org/abs/2503.13082v2", "summary": "Performing robotic grasping from a cluttered bin based on human instructions\nis a challenging task, as it requires understanding both the nuances of\nfree-form language and the spatial relationships between objects.\nVision-Language Models (VLMs) trained on web-scale data, such as GPT-4o, have\ndemonstrated remarkable reasoning capabilities across both text and images. But\ncan they truly be used for this task in a zero-shot setting? And what are their\nlimitations? In this paper, we explore these research questions via the\nfree-form language-based robotic grasping task, and propose a novel method,\nFreeGrasp, leveraging the pre-trained VLMs' world knowledge to reason about\nhuman instructions and object spatial arrangements. Our method detects all\nobjects as keypoints and uses these keypoints to annotate marks on images,\naiming to facilitate GPT-4o's zero-shot spatial reasoning. This allows our\nmethod to determine whether a requested object is directly graspable or if\nother objects must be grasped and removed first. Since no existing dataset is\nspecifically designed for this task, we introduce a synthetic dataset\nFreeGraspData by extending the MetaGraspNetV2 dataset with human-annotated\ninstructions and ground-truth grasping sequences. We conduct extensive analyses\nwith both FreeGraspData and real-world validation with a gripper-equipped\nrobotic arm, demonstrating state-of-the-art performance in grasp reasoning and\nexecution. Project website: https://tev-fbk.github.io/FreeGrasp/.", "comment": "Accepted to IROS 2025. Project website:\n  https://tev-fbk.github.io/FreeGrasp/", "pdf_url": "http://arxiv.org/pdf/2503.13082v2", "cate": "cs.RO", "date": "2025-03-17", "updated": "2025-07-28"}
{"id": "2507.19836", "title": "ChoreoMuse: Robust Music-to-Dance Video Generation with Style Transfer and Beat-Adherent Motion", "authors": ["Xuanchen Wang", "Heng Wang", "Weidong Cai"], "categories": ["cs.GR", "cs.AI", "cs.CV", "cs.MM", "cs.SD"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures, accepted by the 33rd ACM International Conference on Multimedia (ACM MM 2025), demo page: this https URL", "url": "http://arxiv.org/abs/2507.19836v1", "summary": "Modern artistic productions increasingly demand automated choreography\ngeneration that adapts to diverse musical styles and individual dancer\ncharacteristics. Existing approaches often fail to produce high-quality dance\nvideos that harmonize with both musical rhythm and user-defined choreography\nstyles, limiting their applicability in real-world creative contexts. To\naddress this gap, we introduce ChoreoMuse, a diffusion-based framework that\nuses SMPL format parameters and their variation version as intermediaries\nbetween music and video generation, thereby overcoming the usual constraints\nimposed by video resolution. Critically, ChoreoMuse supports\nstyle-controllable, high-fidelity dance video generation across diverse musical\ngenres and individual dancer characteristics, including the flexibility to\nhandle any reference individual at any resolution. Our method employs a novel\nmusic encoder MotionTune to capture motion cues from audio, ensuring that the\ngenerated choreography closely follows the beat and expressive qualities of the\ninput music. To quantitatively evaluate how well the generated dances match\nboth musical and choreographic styles, we introduce two new metrics that\nmeasure alignment with the intended stylistic cues. Extensive experiments\nconfirm that ChoreoMuse achieves state-of-the-art performance across multiple\ndimensions, including video quality, beat alignment, dance diversity, and style\nadherence, demonstrating its potential as a robust solution for a wide range of\ncreative applications. Video results can be found on our project page:\nhttps://choreomuse.github.io.", "comment": "10 pages, 5 figures, accepted by the 33rd ACM International\n  Conference on Multimedia (ACM MM 2025), demo page:\n  https://choreomuse.github.io", "pdf_url": "http://arxiv.org/pdf/2507.19836v1", "cate": "cs.GR", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.19218", "title": "Technological folie à deux: Feedback Loops Between AI Chatbots and Mental Illness", "authors": ["Sebastian Dohnány", "Zeb Kurth-Nelson", "Eleanor Spens", "Lennart Luettgau", "Alastair Reid", "Iason Gabriel", "Christopher Summerfield", "Murray Shanahan", "Matthew M Nour"], "categories": ["cs.HC", "cs.AI", "q-bio.NC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19218v2", "summary": "Artificial intelligence chatbots have achieved unprecedented adoption, with\nmillions now using these systems for emotional support and companionship in\ncontexts of widespread social isolation and capacity-constrained mental health\nservices. While some users report psychological benefits, concerning edge cases\nare emerging, including reports of suicide, violence, and delusional thinking\nlinked to perceived emotional relationships with chatbots. To understand this\nnew risk profile we need to consider the interaction between human cognitive\nand emotional biases, and chatbot behavioural tendencies such as agreeableness\n(sycophancy) and adaptability (in-context learning). We argue that individuals\nwith mental health conditions face increased risks of chatbot-induced belief\ndestabilization and dependence, owing to altered belief-updating, impaired\nreality-testing, and social isolation. Current AI safety measures are\ninadequate to address these interaction-based risks. To address this emerging\npublic health concern, we need coordinated action across clinical practice, AI\ndevelopment, and regulatory frameworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19218v2", "cate": "cs.HC", "date": "2025-07-25", "updated": "2025-07-28"}
{"id": "2507.20088", "title": "Feed-anywhere ANN (I) Steady Discrete $\\to$ Diffusing on Graph Hidden States", "authors": ["Dmitry Pasechnyuk-Vilensky", "Daniil Doroshenko"], "categories": ["cs.LG", "math-ph", "math.MP", "math.OC", "stat.ML", "G.1.6; G.1.7; G.2.2"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 1 algorithm", "url": "http://arxiv.org/abs/2507.20088v1", "summary": "We propose a novel framework for learning hidden graph structures from data\nusing geometric analysis and nonlinear dynamics. Our approach: (1) Defines\ndiscrete Sobolev spaces on graphs for scalar/vector fields, establishing key\nfunctional properties; (2) Introduces gauge-equivalent nonlinear Schr\\\"odinger\nand Landau--Lifshitz dynamics with provable stable stationary solutions\nsmoothly dependent on input data and graph weights; (3) Develops a stochastic\ngradient algorithm over graph moduli spaces with sparsity regularization.\nTheoretically, we guarantee: topological correctness (homology recovery),\nmetric convergence (Gromov--Hausdorff), and efficient search space utilization.\nOur dynamics-based model achieves stronger generalization bounds than standard\nneural networks, with complexity dependent on the data manifold's topology.", "comment": "11 pages, 1 algorithm", "pdf_url": "http://arxiv.org/pdf/2507.20088v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2502.18826", "title": "Adversarial Combinatorial Semi-bandits with Graph Feedback", "authors": ["Yuxiao Wen"], "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      To appear in ICML 2025", "url": "http://arxiv.org/abs/2502.18826v5", "summary": "In combinatorial semi-bandits, a learner repeatedly selects from a\ncombinatorial decision set of arms, receives the realized sum of rewards, and\nobserves the rewards of the individual selected arms as feedback. In this\npaper, we extend this framework to include \\emph{graph feedback}, where the\nlearner observes the rewards of all neighboring arms of the selected arms in a\nfeedback graph $G$. We establish that the optimal regret over a time horizon\n$T$ scales as $\\widetilde{\\Theta}(S\\sqrt{T}+\\sqrt{\\alpha ST})$, where $S$ is\nthe size of the combinatorial decisions and $\\alpha$ is the independence number\nof $G$. This result interpolates between the known regrets\n$\\widetilde\\Theta(S\\sqrt{T})$ under full information (i.e., $G$ is complete)\nand $\\widetilde\\Theta(\\sqrt{KST})$ under the semi-bandit feedback (i.e., $G$\nhas only self-loops), where $K$ is the total number of arms. A key technical\ningredient is to realize a convexified action using a random decision vector\nwith negative correlations. We also show that online stochastic mirror descent\n(OSMD) that only realizes convexified actions in expectation is suboptimal. In\naddition, we describe the problem of \\emph{combinatorial semi-bandits with\ngeneral capacity} and apply our results to derive an improved regret upper\nbound, which may be of independent interest.", "comment": "To appear in ICML 2025", "pdf_url": "http://arxiv.org/pdf/2502.18826v5", "cate": "cs.LG", "date": "2025-02-26", "updated": "2025-07-26"}
{"id": "2507.20580", "title": "A Modified Adaptive Data-Enabled Policy Optimization Control to Resolve State Perturbations", "authors": ["Mojtaba Kaheni", "Niklas Persson", "Vittorio De Iuliis", "Costanzo Manes", "Alessandro V. Papadopoulos"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      64th IEEE Conference on Decision and Control", "url": "http://arxiv.org/abs/2507.20580v1", "summary": "This paper proposes modifications to the data-enabled policy optimization\n(DeePO) algorithm to mitigate state perturbations. DeePO is an adaptive,\ndata-driven approach designed to iteratively compute a feedback gain equivalent\nto the certainty-equivalence LQR gain. Like other data-driven approaches based\non Willems' fundamental lemma, DeePO requires persistently exciting input\nsignals. However, linear state-feedback gains from LQR designs cannot\ninherently produce such inputs. To address this, probing noise is\nconventionally added to the control signal to ensure persistent excitation.\nHowever, the added noise may induce undesirable state perturbations. We first\nidentify two key issues that jeopardize the desired performance of DeePO when\nprobing noise is not added: the convergence of states to the equilibrium point,\nand the convergence of the controller to its optimal value. To address these\nchallenges without relying on probing noise, we propose Perturbation-Free DeePO\n(PFDeePO) built on two fundamental principles. First, the algorithm pauses the\ncontrol gain updating in DeePO process when system states are near the\nequilibrium point. Second, it applies a multiplicative noise, scaled by a mean\nvalue of $1$ as a gain for the control signal, when the controller converges.\nThis approach minimizes the impact of noise as the system approaches\nequilibrium while preserving stability. We demonstrate the effectiveness of\nPFDeePO through simulations, showcasing its ability to eliminate state\nperturbations while maintaining system performance and stability.", "comment": "64th IEEE Conference on Decision and Control", "pdf_url": "http://arxiv.org/pdf/2507.20580v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20657", "title": "The micro-Doppler Attack Against AI-based Human Activity Classification from Wireless Signals", "authors": ["Margarita Loupa", "Antonios Argyriou", "Yanwei Liu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20657v1", "summary": "A subset of Human Activity Classification (HAC) systems are based on AI\nalgorithms that use passively collected wireless signals. This paper presents\nthe micro-Doppler attack targeting HAC from wireless orthogonal frequency\ndivision multiplexing (OFDM) signals. The attack is executed by inserting\nartificial variations in a transmitted OFDM waveform to alter its micro-Doppler\nsignature when it reflects off a human target. We investigate two variants of\nour scheme that manipulate the waveform at different time scales resulting in\naltered receiver spectrograms. HAC accuracy with a deep convolutional neural\nnetwork (CNN) can be reduced to less than 10%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20657v1", "cate": "eess.SP", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2501.01460", "title": "GDSR: Global-Detail Integration through Dual-Branch Network with Wavelet Losses for Remote Sensing Image Super-Resolution", "authors": ["Qiwei Zhu", "Kai Li", "Guojing Zhang", "Xiaoying Wang", "Jianqiang Huang", "Xilai Li"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      GDSR: Global-Detail Integration through Dual-Branch Network with Wavelet Losses for Remote Sensing Image Super-Resolution", "url": "http://arxiv.org/abs/2501.01460v3", "summary": "In recent years, deep neural networks, including Convolutional Neural\nNetworks, Transformers, and State Space Models, have achieved significant\nprogress in Remote Sensing Image (RSI) Super-Resolution (SR). However, existing\nSR methods typically overlook the complementary relationship between global and\nlocal dependencies. These methods either focus on capturing local information\nor prioritize global information, which results in models that are unable to\neffectively capture both global and local features simultaneously. Moreover,\ntheir computational cost becomes prohibitive when applied to large-scale RSIs.\nTo address these challenges, we introduce the novel application of Receptance\nWeighted Key Value (RWKV) to RSI-SR, which captures long-range dependencies\nwith linear complexity. To simultaneously model global and local features, we\npropose the Global-Detail dual-branch structure, GDSR, which performs SR by\nparalleling RWKV and convolutional operations to handle large-scale RSIs.\nFurthermore, we introduce the Global-Detail Reconstruction Module (GDRM) as an\nintermediary between the two branches to bridge their complementary roles. In\naddition, we propose the Dual-Group Multi-Scale Wavelet Loss, a wavelet-domain\nconstraint mechanism via dual-group subband strategy and cross-resolution\nfrequency alignment for enhanced reconstruction fidelity in RSI-SR. Extensive\nexperiments under two degradation methods on several benchmarks, including AID,\nUCMerced, and RSSRD-QH, demonstrate that GSDR outperforms the state-of-the-art\nTransformer-based method HAT by an average of 0.09 dB in PSNR, while using only\n63% of its parameters and 51% of its FLOPs, achieving an inference speed 3.2\ntimes faster.", "comment": "GDSR: Global-Detail Integration through Dual-Branch Network with\n  Wavelet Losses for Remote Sensing Image Super-Resolution", "pdf_url": "http://arxiv.org/pdf/2501.01460v3", "cate": "eess.IV", "date": "2024-12-31", "updated": "2025-07-28"}
{"id": "2507.20627", "title": "Controllable Video-to-Music Generation with Multiple Time-Varying Conditions", "authors": ["Junxian Wu", "Weitao You", "Heda Zuo", "Dengming Zhang", "Pei Chen", "Lingyun Sun"], "categories": ["cs.MM", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "Comments:      Accepted by the 33rd ACM International Conference on Multimedia (ACMMM 2025). The project page is available at this https URL", "url": "http://arxiv.org/abs/2507.20627v1", "summary": "Music enhances video narratives and emotions, driving demand for automatic\nvideo-to-music (V2M) generation. However, existing V2M methods relying solely\non visual features or supplementary textual inputs generate music in a\nblack-box manner, often failing to meet user expectations. To address this\nchallenge, we propose a novel multi-condition guided V2M generation framework\nthat incorporates multiple time-varying conditions for enhanced control over\nmusic generation. Our method uses a two-stage training strategy that enables\nlearning of V2M fundamentals and audiovisual temporal synchronization while\nmeeting users' needs for multi-condition control. In the first stage, we\nintroduce a fine-grained feature selection module and a progressive temporal\nalignment attention mechanism to ensure flexible feature alignment. For the\nsecond stage, we develop a dynamic conditional fusion module and a\ncontrol-guided decoder module to integrate multiple conditions and accurately\nguide the music composition process. Extensive experiments demonstrate that our\nmethod outperforms existing V2M pipelines in both subjective and objective\nevaluations, significantly enhancing control and alignment with user\nexpectations.", "comment": "Accepted by the 33rd ACM International Conference on Multimedia\n  (ACMMM 2025). The project page is available at\n  https://kita-wjx.github.io/MCV2M/", "pdf_url": "http://arxiv.org/pdf/2507.20627v1", "cate": "cs.MM", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20013", "title": "Generating Satisfiable Benchmark Instances for Stable Roommates Problems with Optimization", "authors": ["Baturay Yılmaz", "Esra Erdem"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20013v1", "summary": "While the existence of a stable matching for the stable roommates problem\npossibly with incomplete preference lists (SRI) can be decided in polynomial\ntime, SRI problems with some fairness criteria are intractable. Egalitarian SRI\nthat tries to maximize the total satisfaction of agents if a stable matching\nexists, is such a hard variant of SRI. For experimental evaluations of methods\nto solve these hard variants of SRI, several well-known algorithms have been\nused to randomly generate benchmark instances. However, these benchmark\ninstances are not always satisfiable, and usually have a small number of stable\nmatchings if one exists. For such SRI instances, despite the NP-hardness of\nEgalitarian SRI, it is practical to find an egalitarian stable matching by\nenumerating all stable matchings. In this study, we introduce a novel algorithm\nto generate benchmark instances for SRI that have very large numbers of\nsolutions, and for which it is hard to find an egalitarian stable matching by\nenumerating all stable matchings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20013v1", "cate": "cs.DS", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2503.23465", "title": "SparseLoc: Sparse Open-Set Landmark-based Global Localization for Autonomous Navigation", "authors": ["Pranjal Paul", "Vineeth Bhat", "Tejas Salian", "Mohammad Omama", "Krishna Murthy Jatavallabhula", "Naveen Arulselvan", "K. Madhava Krishna"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.23465v2", "summary": "Global localization is a critical problem in autonomous navigation, enabling\nprecise positioning without reliance on GPS. Modern global localization\ntechniques often depend on dense LiDAR maps, which, while precise, require\nextensive storage and computational resources. Recent approaches have explored\nalternative methods, such as sparse maps and learned features, but they suffer\nfrom poor robustness and generalization. We propose SparseLoc, a global\nlocalization framework that leverages vision-language foundation models to\ngenerate sparse, semantic-topometric maps in a zero-shot manner. It combines\nthis map representation with a Monte Carlo localization scheme enhanced by a\nnovel late optimization strategy, ensuring improved pose estimation. By\nconstructing compact yet highly discriminative maps and refining localization\nthrough a carefully designed optimization schedule, SparseLoc overcomes the\nlimitations of existing techniques, offering a more efficient and robust\nsolution for global localization. Our system achieves over a 5X improvement in\nlocalization accuracy compared to existing sparse mapping techniques. Despite\nutilizing only 1/500th of the points of dense mapping methods, it achieves\ncomparable performance, maintaining an average global localization error below\n5m and 2 degrees on KITTI sequences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.23465v2", "cate": "cs.RO", "date": "2025-03-30", "updated": "2025-07-28"}
{"id": "2507.19840", "title": "AutoSign: Direct Pose-to-Text Translation for Continuous Sign Language Recognition", "authors": ["Samuel Ebimobowei Johnny", "Blessed Guda", "Andrew Blayama Stephen", "Assane Gueye"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Paper to appear at the 1st Workshop in Multimodal Sign Language Recognition at ICCV 2025", "url": "http://arxiv.org/abs/2507.19840v1", "summary": "Continuously recognizing sign gestures and converting them to glosses plays a\nkey role in bridging the gap between the hearing and hearing-impaired\ncommunities. This involves recognizing and interpreting the hands, face, and\nbody gestures of the signer, which pose a challenge as it involves a\ncombination of all these features. Continuous Sign Language Recognition (CSLR)\nmethods rely on multi-stage pipelines that first extract visual features, then\nalign variable-length sequences with target glosses using CTC or HMM-based\napproaches. However, these alignment-based methods suffer from error\npropagation across stages, overfitting, and struggle with vocabulary\nscalability due to the intermediate gloss representation bottleneck. To address\nthese limitations, we propose AutoSign, an autoregressive decoder-only\ntransformer that directly translates pose sequences to natural language text,\nbypassing traditional alignment mechanisms entirely. The use of this\ndecoder-only approach allows the model to directly map between the features and\nthe glosses without the need for CTC loss while also directly learning the\ntextual dependencies in the glosses. Our approach incorporates a temporal\ncompression module using 1D CNNs to efficiently process pose sequences,\nfollowed by AraGPT2, a pre-trained Arabic decoder, to generate text (glosses).\nThrough comprehensive ablation studies, we demonstrate that hand and body\ngestures provide the most discriminative features for signer-independent CSLR.\nBy eliminating the multi-stage pipeline, AutoSign achieves substantial\nimprovements on the Isharah-1000 dataset, achieving an improvement of up to\n6.1\\% in WER score compared to the best existing method.", "comment": "Paper to appear at the 1st Workshop in Multimodal Sign Language\n  Recognition at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.19840v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2501.06250", "title": "Generative AI for Cel-Animation: A Survey", "authors": ["Yunlong Tang", "Junjia Guo", "Pinxin Liu", "Zhiyuan Wang", "Hang Hua", "Jia-Xing Zhong", "Yunzhong Xiao", "Chao Huang", "Luchuan Song", "Susan Liang", "Yizhi Song", "Liu He", "Jing Bi", "Mingqian Feng", "Xinyang Li", "Zeliang Zhang", "Chenliang Xu"], "categories": ["cs.CV", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025 AISTORY Workshop", "url": "http://arxiv.org/abs/2501.06250v2", "summary": "Traditional Celluloid (Cel) Animation production pipeline encompasses\nmultiple essential steps, including storyboarding, layout design, keyframe\nanimation, inbetweening, and colorization, which demand substantial manual\neffort, technical expertise, and significant time investment. These challenges\nhave historically impeded the efficiency and scalability of Cel-Animation\nproduction. The rise of generative artificial intelligence (GenAI),\nencompassing large language models, multimodal models, and diffusion models,\noffers innovative solutions by automating tasks such as inbetween frame\ngeneration, colorization, and storyboard creation. This survey explores how\nGenAI integration is revolutionizing traditional animation workflows by\nlowering technical barriers, broadening accessibility for a wider range of\ncreators through tools like AniDoc, ToonCrafter, and AniSora, and enabling\nartists to focus more on creative expression and artistic innovation. Despite\nits potential, challenges like visual consistency, stylistic coherence, and\nethical considerations persist. Additionally, this paper explores future\ndirections and advancements in AI-assisted animation.", "comment": "Accepted by ICCV 2025 AISTORY Workshop", "pdf_url": "http://arxiv.org/pdf/2501.06250v2", "cate": "cs.CV", "date": "2025-01-08", "updated": "2025-07-28"}
{"id": "2507.20089", "title": "Meta Fusion: A Unified Framework For Multimodality Fusion with Mutual Learning", "authors": ["Ziyi Liang", "Annie Qu", "Babak Shahbaba"], "categories": ["cs.LG", "stat.ME", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20089v1", "summary": "Developing effective multimodal data fusion strategies has become\nincreasingly essential for improving the predictive power of statistical\nmachine learning methods across a wide range of applications, from autonomous\ndriving to medical diagnosis. Traditional fusion methods, including early,\nintermediate, and late fusion, integrate data at different stages, each\noffering distinct advantages and limitations. In this paper, we introduce Meta\nFusion, a flexible and principled framework that unifies these existing\nstrategies as special cases. Motivated by deep mutual learning and ensemble\nlearning, Meta Fusion constructs a cohort of models based on various\ncombinations of latent representations across modalities, and further boosts\npredictive performance through soft information sharing within the cohort. Our\napproach is model-agnostic in learning the latent representations, allowing it\nto flexibly adapt to the unique characteristics of each modality.\nTheoretically, our soft information sharing mechanism reduces the\ngeneralization error. Empirically, Meta Fusion consistently outperforms\nconventional fusion strategies in extensive simulation studies. We further\nvalidate our approach on real-world applications, including Alzheimer's disease\ndetection and neural decoding.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20089v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2505.05188", "title": "Smoothed analysis in compressed sensing", "authors": ["Elad Aigner-Horev", "Dan Hefetz", "Michael Trushkin"], "categories": ["math.PR", "cs.IT", "math.IT"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.05188v3", "summary": "Arbitrary matrices $M \\in \\mathbb{R}^{m \\times n}$, randomly perturbed in an\nadditive manner using a random matrix $R \\in \\mathbb{R}^{m \\times n}$, are\nshown to asymptotically almost surely satisfy the so-called {\\sl robust null\nspace property}. Whilst insisting on an asymptotically optimal order of\nmagnitude for $m$ required to attain {\\sl unique reconstruction} via\n$\\ell_1$-minimisation algorithms, our results track the level of arbitrariness\nallowed for the fixed seed matrix $M$ as well as the degree of distributional\nirregularity allowed for the entries of the perturbing matrix $R$. Starting\nwith sub-gaussian entries for $R$, our results culminate with these allowed to\nhave substantially heavier tails than sub-exponential ones. Throughout this\ntrajectory, two measures control the arbitrariness allowed for $M$; the first\nis $\\|M\\|_\\infty$ and the second is a localised notion of the Frobenius norm of\n$M$ (which depends on the sparsity of the signal being reconstructed). A key\ntool driving our proofs is {\\sl Mendelson's small-ball method} ({\\em Learning\nwithout concentration}, J. ACM, Vol. $62$, $2015$).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.05188v3", "cate": "math.PR", "date": "2025-05-08", "updated": "2025-07-26"}
{"id": "2507.20621", "title": "Sequential Operation of Residential Energy Hubs", "authors": ["Darío Slaifstein", "Gautham Ram Chandra Mouli", "Laura Ramirez-Elizondo", "Pavol Bauer"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20621v1", "summary": "The operation of residential energy hubs with multiple energy carriers\n(electricity, heat, mobility) poses a significant challenge due to different\ncarrier dynamics, hybrid storage coordination and high-dimensional\naction-spaces. Energy management systems oversee their operation, deciding the\nset points of the primary control layer. This paper presents a novel 2-stage\neconomic model predictive controller for electrified buildings including\nphysics-based models of the battery degradation and thermal systems. The\nhierarchical control operates in the Dutch sequential energy markets. In\nparticular common assumptions regarding intra-day markets (auction and\ncontinuous-time) are discussed as well as the coupling of the different storage\nsystems. The best control policy is to co-optimize day-ahead and intra-day\nauctions in the first stage, to later follow intra-day auctions. If no\nintra-day prices are known at the time of the day-ahead auction, its best to\nfollow continuous time intra-day in the summer and the intra-day auction in the\nwinter. Additionally, this sequential operation increases battery degradation.\nFinally, under our controller the realized short-term flexibility of the\nthermal energy storage is marginal compared to the flexibility delivered by\nstatic battery pack and electric vehicles with bidirectional charging.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20621v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20664", "title": "A Nonlinear Spectral Approach for Radar-Based Heartbeat Estimation via Autocorrelation of Higher Harmonics", "authors": ["Kohei Shimomura", "Chi-Hsuan Lee", "Takuya Sakamoto"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      4 pages, 4 figures, 3 tables. This work is going to be submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.20664v1", "summary": "This study presents a nonlinear signal processing method for accurate\nradar-based heartbeat interval estimation by exploiting the periodicity of\nhigher-order harmonics inherent in heartbeat signals. Unlike conventional\napproaches that employ selective frequency filtering or track individual\nharmonics, the proposed method enhances the global periodic structure of the\nspectrum via nonlinear correlation processing. Specifically, smoothing and\nsecond-derivative operations are first applied to the radar displacement signal\nto suppress noise and accentuate higher-order heartbeat harmonics. Rather than\nisolating specific frequency components, we compute localized autocorrelations\nof the Fourier spectrum around the harmonic frequencies. The incoherent\nsummation of these autocorrelations yields a pseudo-spectrum in which the\nfundamental heartbeat periodicity is distinctly emphasized. This nonlinear\napproach mitigates the effects of respiratory harmonics and noise, enabling\nrobust interbeat interval estimation. Experiments with radar measurements from\nfive participants demonstrate that the proposed method reduces root-mean-square\nerror by 20% and improves the correlation coefficient by 0.20 relative to\nconventional techniques.", "comment": "4 pages, 4 figures, 3 tables. This work is going to be submitted to\n  the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.20664v1", "cate": "eess.SP", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2506.07475", "title": "Text-guided multi-stage cross-perception network for medical image segmentation", "authors": ["Gaoyu Chen", "Haixia Pan"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.07475v2", "summary": "Medical image segmentation plays a crucial role in clinical medicine, serving\nas a tool for auxiliary diagnosis, treatment planning, and disease monitoring,\nthus facilitating physicians in the study and treatment of diseases. However,\nexisting medical image segmentation methods are limited by the weak semantic\nexpression of the target segmentation regions, which is caused by the low\ncontrast between the target and non-target segmentation regions. To address\nthis limitation, text prompt information has greast potential to capture the\nlesion location. However, existing text-guided methods suffer from insufficient\ncross-modal interaction and inadequate cross-modal feature expression. To\nresolve these issues, we propose the Text-guided Multi-stage Cross-perception\nnetwork (TMC). In TMC, we introduce a multistage cross-attention module to\nenhance the model's understanding of semantic details and a multi-stage\nalignment loss to improve the consistency of cross-modal semantics. The results\nof the experiments demonstrate that our TMC achieves a superior performance\nwith Dice of 84.77%, 78.50%, 88.73% in three public datasets (QaTa-COV19,\nMosMedData and Breast), outperforming UNet based networks and text-guided\nmethods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.07475v2", "cate": "eess.IV", "date": "2025-06-09", "updated": "2025-07-28"}
{"id": "2409.07151", "title": "Zero-Shot Text-to-Speech as Golden Speech Generator: A Systematic Framework and its Applicability in Automatic Pronunciation Assessment", "authors": ["Tien-Hong Lo", "Meng-Ting Tsai", "Yao-Ting Sung", "Berlin Chen"], "categories": ["eess.AS", "cs.AI"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      SLaTE 2025", "url": "http://arxiv.org/abs/2409.07151v2", "summary": "Second language (L2) learners can improve their pronunciation by imitating\ngolden speech, especially when the speech that aligns with their respective\nspeech characteristics. This study explores the hypothesis that\nlearner-specific golden speech generated with zero-shot text-to-speech (ZS-TTS)\ntechniques can be harnessed as an effective metric for measuring the\npronunciation proficiency of L2 learners. Building on this exploration, the\ncontributions of this study are at least two-fold: 1) design and development of\na systematic framework for assessing the ability of a synthesis model to\ngenerate golden speech, and 2) in-depth investigations of the effectiveness of\nusing golden speech in automatic pronunciation assessment (APA). Comprehensive\nexperiments conducted on the L2-ARCTIC and Speechocean762 benchmark datasets\nsuggest that our proposed modeling can yield significant performance\nimprovements with respect to various assessment metrics in relation to some\nprior arts. To our knowledge, this study is the first to explore the role of\ngolden speech in both ZS-TTS and APA, offering a promising regime for\ncomputer-assisted pronunciation training (CAPT).", "comment": "SLaTE 2025", "pdf_url": "http://arxiv.org/pdf/2409.07151v2", "cate": "eess.AS", "date": "2024-09-11", "updated": "2025-07-26"}
{"id": "2507.20228", "title": "Adaptive BSTs for Single-Source and All-to-All Requests: Algorithms and Lower Bounds", "authors": ["Maryam Shiran"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20228v1", "summary": "Adaptive binary search trees are a fundamental data structure for organizing\nhierarchical information. Their ability to dynamically adjust to access\npatterns makes them particularly valuable for building responsive and efficient\nnetworked and distributed systems.\n  We present a unified framework for adaptive binary search trees with fixed\nrestructuring cost, analyzed under two models: the single-source model, where\nthe cost of querying a node is proportional to its distance from a fixed\nsource, and the all-to-all model, where the cost of serving a request depends\non the distance between the source and destination nodes. We propose an offline\nalgorithm for the single-source model and extend it to the all-to-all model.\nFor both models, we prove upper bounds on the cost incurred by our algorithms.\nFurthermore, we show the existence of input sequences for which any offline\nalgorithm must incur a cost comparable to ours.\n  In the online setting, we develop a general mathematical framework for\ndeterministic online adaptive binary search trees and propose a deterministic\nonline strategy for the single-source case, which naturally extends to the\nall-to-all model. We also establish lower bounds on the competitive ratio of\nany deterministic online algorithm, highlighting fundamental limitations of\nonline adaptivity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20228v1", "cate": "cs.DS", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2504.00580", "title": "MRHaD: Mixed Reality-based Hand-Drawn Map Editing Interface for Mobile Robot Navigation", "authors": ["Takumi Taki", "Masato Kobayashi", "Eduardo Iglesius", "Naoya Chiba", "Shizuka Shirai", "Yuki Uranishi"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.00580v2", "summary": "Mobile robot navigation systems are increasingly relied upon in dynamic and\ncomplex environments, yet they often struggle with map inaccuracies and the\nresulting inefficient path planning. This paper presents MRHaD, a Mixed\nReality-based Hand-drawn Map Editing Interface that enables intuitive,\nreal-time map modifications through natural hand gestures. By integrating the\nMR head-mounted display with the robotic navigation system, operators can\ndirectly create hand-drawn restricted zones (HRZ), thereby bridging the gap\nbetween 2D map representations and the real-world environment. Comparative\nexperiments against conventional 2D editing methods demonstrate that MRHaD\nsignificantly improves editing efficiency, map accuracy, and overall usability,\ncontributing to safer and more efficient mobile robot operations. The proposed\napproach provides a robust technical foundation for advancing human-robot\ncollaboration and establishing innovative interaction models that enhance the\nhybrid future of robotics and human society. For additional material, please\ncheck: https://mertcookimg.github.io/mrhad/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.00580v2", "cate": "cs.RO", "date": "2025-04-01", "updated": "2025-07-28"}
{"id": "2507.19856", "title": "RaGS: Unleashing 3D Gaussian Splatting from 4D Radar and Monocular Cues for 3D Object Detection", "authors": ["Xiaokai Bai", "Chenxu Zhou", "Lianqing Zheng", "Si-Yuan Cao", "Jianan Liu", "Xiaohan Zhang", "Zhengzhuang Zhang", "Hui-liang Shen"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 6 figures, conference", "url": "http://arxiv.org/abs/2507.19856v1", "summary": "4D millimeter-wave radar has emerged as a promising sensor for autonomous\ndriving, but effective 3D object detection from both 4D radar and monocular\nimages remains a challenge. Existing fusion approaches typically rely on either\ninstance-based proposals or dense BEV grids, which either lack holistic scene\nunderstanding or are limited by rigid grid structures. To address these, we\npropose RaGS, the first framework to leverage 3D Gaussian Splatting (GS) as\nrepresentation for fusing 4D radar and monocular cues in 3D object detection.\n3D GS naturally suits 3D object detection by modeling the scene as a field of\nGaussians, dynamically allocating resources on foreground objects and providing\na flexible, resource-efficient solution. RaGS uses a cascaded pipeline to\nconstruct and refine the Gaussian field. It starts with the Frustum-based\nLocalization Initiation (FLI), which unprojects foreground pixels to initialize\ncoarse 3D Gaussians positions. Then, the Iterative Multimodal Aggregation (IMA)\nfuses semantics and geometry, refining the limited Gaussians to the regions of\ninterest. Finally, the Multi-level Gaussian Fusion (MGF) renders the Gaussians\ninto multi-level BEV features for 3D object detection. By dynamically focusing\non sparse objects within scenes, RaGS enable object concentrating while\noffering comprehensive scene perception. Extensive experiments on\nView-of-Delft, TJ4DRadSet, and OmniHD-Scenes benchmarks demonstrate its\nstate-of-the-art performance. Code will be released.", "comment": "9 pages, 6 figures, conference", "pdf_url": "http://arxiv.org/pdf/2507.19856v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.15846", "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding", "authors": ["Fei Tang", "Zhangxuan Gu", "Zhengxi Lu", "Xuyang Liu", "Shuheng Shen", "Changhua Meng", "Wen Wang", "Wenqi Zhang", "Yongliang Shen", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.HC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15846v3", "summary": "Graphical User Interface (GUI) grounding maps natural language instructions\nto precise interface locations for autonomous interaction. Current\nreinforcement learning approaches use binary rewards that treat elements as\nhit-or-miss targets, creating sparse signals that ignore the continuous nature\nof spatial interactions. Motivated by human clicking behavior that naturally\nforms Gaussian distributions centered on target elements, we introduce GUI\nGaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that\nmodels GUI elements as continuous Gaussian distributions across the interface\nplane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point\nrewards model precise localization through exponentially decaying distributions\ncentered on element centroids, while coverage rewards assess spatial alignment\nby measuring the overlap between predicted Gaussian distributions and target\nregions. To handle diverse element scales, we develop an adaptive variance\nmechanism that calibrates reward distributions based on element dimensions.\nThis framework transforms GUI grounding from sparse binary classification to\ndense continuous optimization, where Gaussian distributions generate rich\ngradient signals that guide models toward optimal interaction positions.\nExtensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro\nbenchmarks demonstrate that GUI-G$^2$, substantially outperforms\nstate-of-the-art method UI-TARS-72B, with the most significant improvement of\n24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides\nsuperior robustness to interface variations and enhanced generalization to\nunseen layouts, establishing a new paradigm for spatial reasoning in GUI\ninteraction tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15846v3", "cate": "cs.LG", "date": "2025-07-21", "updated": "2025-07-28"}
{"id": "2507.20096", "title": "EcoTransformer: Attention without Multiplication", "authors": ["Xin Gao", "Xingming Xu"], "categories": ["cs.LG", "cs.AI", "cs.CL", "68T05"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      8 pages, 1 figure", "url": "http://arxiv.org/abs/2507.20096v1", "summary": "The Transformer, with its scaled dot-product attention mechanism, has become\na foundational architecture in modern AI. However, this mechanism is\ncomputationally intensive and incurs substantial energy costs. We propose a new\nTransformer architecture EcoTransformer, in which the output context vector is\nconstructed as the convolution of the values using a Laplacian kernel, where\nthe distances are measured by the L1 metric between the queries and keys.\nCompared to dot-product based attention, the new attention score calculation is\nfree of matrix multiplication. It performs on par with, or even surpasses,\nscaled dot-product attention in NLP, bioinformatics, and vision tasks, while\nconsuming significantly less energy.", "comment": "8 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.20096v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2505.12572", "title": "Measuring Information Distortion in Hierarchical Ultra long Novel Reconstruction:The Optimal Expansion Ratio", "authors": ["Hanwen Shen", "Ting Ying"], "categories": ["cs.CL", "cs.AI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.12572v2", "summary": "A two stage novel generation framework (outline -> section outline ->\nmanuscript) is widely used in long novel generation,(e.g., \\textsc{DOME},\n\\textsc{Plan\\&Write}, \\textsc{Long Writer}), but study of such framework in\nultra long novel(>1M words) reconstruction is little. Building on recent text\ncompression methods (\\textsc{LLMZip}, \\textsc{LLM2Vec}), we conduct an\ninformation-theoretic analysis to quantify semantic distortion under different\ncompression-expansion ratios. We examine how outline length affects information\npreservation. Experiments on ultra-long novels show that the optimal\ncompression-expansion ratio significantly reduces semantic distortion compared\nto other non-optimal compression-expansion ratio.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.12572v2", "cate": "cs.CL", "date": "2025-05-18", "updated": "2025-07-27"}
{"id": "2507.20634", "title": "Convergent Weight and Activation Dynamics in Memristor Neural Networks", "authors": ["Mauro Di Marco", "Mauro Forti", "Luca Pancioni", "Giacomo Innocenti", "Alberto Tesi"], "categories": ["eess.SY", "cs.SY", "nlin.PS"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20634v1", "summary": "Convergence of dynamic feedback neural networks (NNs), as the\nCohen-Grossberg, Hopfield and cellular NNs, has been for a long time a\nworkhorse of NN theory. Indeed, convergence in the presence of multiple stable\nequilibrium points (EPs) is crucial to implement content addressable memories\nand solve several other signal processing tasks in real time. There are two\ntypical ways to use a convergent NN, i.e.: a) let the activations evolve while\nmaintaining fixed weights and inputs (activation dynamics) or b) adapt the\nweights while maintaining fixed activations (weight dynamics). As remarked in a\nseminal paper by Hirsch, there is another interesting possibility, i.e., let\nthe neuron interconnection weights evolve while simultaneously running the\nactivation dynamics (weight-activation dynamics). The weight-activation\ndynamics is of importance also because it is more plausible than the other two\ntypes for modeling neural systems. The paper breaks new ground by analyzing for\nthe first time in a systematic way the convergence properties of the\nweight-activation dynamics for a class of memristor feedback dynamic NNs. The\nmain result is that, under suitable assumptions on the structure of the\nmemristor interconnections, the solutions (weights and activations) converge to\nan EP, except at most for a set of initial conditions with zero measure. The\nresult includes the most important case where the NN has multiple stable EPs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20634v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20789", "title": "DT-Aided Resource Management in Spectrum Sharing Integrated Satellite-Terrestrial Networks", "authors": ["Hung Nguyen-Kha", "Vu Nguyen Ha", "Ti Ti Nguyen", "Eva Lagunas", "Symeon Chatzinotas", "Joel Grotz"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20789v1", "summary": "The integrated satellite-terrestrial networks (ISTNs) through spectrum\nsharing have emerged as a promising solution to improve spectral efficiency and\nmeet increasing wireless demand. However, this coexistence introduces\nsignificant challenges, including inter-system interference (ISI) and the low\nEarth orbit satellite (LSat) movements. To capture the actual environment for\nresource management, we propose a time-varying digital twin (DT)-aided\nframework for ISTNs incorporating 3D map that enables joint optimization of\nbandwidth (BW) allocation, traffic steering, and resource allocation, and aims\nto minimize congestion. The problem is formulated as a mixed-integer nonlinear\nprogramming (MINLP), addressed through a two-phase algorithm based on\nsuccessive convex approximation (SCA) and compressed sensing approaches.\nNumerical results demonstrate the proposed method's superior performance in\nqueue length minimization compared to benchmarks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20789v1", "cate": "eess.SP", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2506.11150", "title": "ADAgent: LLM Agent for Alzheimer's Disease Analysis with Collaborative Coordinator", "authors": ["Wenlong Hou", "Guangqian Yang", "Ye Du", "Yeung Lau", "Lihao Liu", "Junjun He", "Ling Long", "Shujun Wang"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.11150v3", "summary": "Alzheimer's disease (AD) is a progressive and irreversible neurodegenerative\ndisease. Early and precise diagnosis of AD is crucial for timely intervention\nand treatment planning to alleviate the progressive neurodegeneration. However,\nmost existing methods rely on single-modality data, which contrasts with the\nmultifaceted approach used by medical experts. While some deep learning\napproaches process multi-modal data, they are limited to specific tasks with a\nsmall set of input modalities and cannot handle arbitrary combinations. This\nhighlights the need for a system that can address diverse AD-related tasks,\nprocess multi-modal or missing input, and integrate multiple advanced methods\nfor improved performance. In this paper, we propose ADAgent, the first\nspecialized AI agent for AD analysis, built on a large language model (LLM) to\naddress user queries and support decision-making. ADAgent integrates a\nreasoning engine, specialized medical tools, and a collaborative outcome\ncoordinator to facilitate multi-modal diagnosis and prognosis tasks in AD.\nExtensive experiments demonstrate that ADAgent outperforms SOTA methods,\nachieving significant improvements in accuracy, including a 2.7% increase in\nmulti-modal diagnosis, a 0.7% improvement in multi-modal prognosis, and\nenhancements in MRI and PET diagnosis tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.11150v3", "cate": "eess.IV", "date": "2025-06-11", "updated": "2025-07-27"}
{"id": "2505.06671", "title": "RADE: A Neural Codec for Transmitting Speech over HF Radio Channels", "authors": ["David Rowe", "Jean-Marc Valin"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Proc. WASPAA 2025, 5 pages", "url": "http://arxiv.org/abs/2505.06671v2", "summary": "Speech compression is commonly used to send voice over radio channels in\napplications such as mobile telephony and two-way push-to-talk (PTT) radio. In\nclassical systems, the speech codec is combined with forward error correction,\nmodulation and radio hardware. In this paper we describe an autoencoder that\nreplaces many of the traditional signal processing elements with a neural\nnetwork. The encoder takes a vocoder feature set (short term spectrum, pitch,\nvoicing), and produces discrete time, but continuously valued quadrature\namplitude modulation (QAM) symbols. We use orthogonal frequency domain\nmultiplexing (OFDM) to send and receive these symbols over high frequency (HF)\nradio channels. The decoder converts received QAM symbols to vocoder features\nsuitable for synthesis. The autoencoder has been trained to be robust to\nadditive Gaussian noise and multipath channel impairments while simultaneously\nmaintaining a Peak To Average Power Ratio (PAPR) of less than 1 dB. Over\nsimulated and real world HF radio channels we have achieved output speech\nintelligibility that clearly surpasses existing analog and digital radio\nsystems over a range of SNRs.", "comment": "Proc. WASPAA 2025, 5 pages", "pdf_url": "http://arxiv.org/pdf/2505.06671v2", "cate": "eess.AS", "date": "2025-05-10", "updated": "2025-07-26"}
{"id": "2507.20253", "title": "The Min Max Average Cycle Weight Problem", "authors": ["Noga Klein Elmalem", "Rica Gonen", "Erel Segal-Halevi"], "categories": ["cs.DS", "cs.GT"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      A note presenting an open question", "url": "http://arxiv.org/abs/2507.20253v1", "summary": "When an old apartment building is demolished and rebuilt, how can we fairly\nredistribute the new apartments to minimize envy among residents? We reduce\nthis question to a combinatorial optimization problem called the *Min Max\nAverage Cycle Weight* problem. In that problem we seek to assign objects to\nagents in a way that minimizes the maximum average weight of directed cycles in\nan associated envy graph. While this problem reduces to maximum-weight matching\nwhen starting from a clean slate (achieving polynomial-time solvability), we\nshow that this is not the case when we account for preexisting conditions, such\nas residents' satisfaction with their original apartments. Whether the problem\nis polynomial-time solvable in the general case remains an intriguing open\nproblem.", "comment": "A note presenting an open question", "pdf_url": "http://arxiv.org/pdf/2507.20253v1", "cate": "cs.DS", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.21288", "title": "Learning Simulatable Models of Cloth with Spatially-varying Constitutive Properties", "authors": ["Guanxiong Chen", "Shashwat Suri", "Yuhao Wu", "Etienne Voulga", "David I. W. Levin", "Dinesh Pai"], "categories": ["cs.GR", "cs.AI"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21288v1", "summary": "Materials used in real clothing exhibit remarkable complexity and spatial\nvariation due to common processes such as stitching, hemming, dyeing, printing,\npadding, and bonding. Simulating these materials, for instance using finite\nelement methods, is often computationally demanding and slow. Worse, such\nmethods can suffer from numerical artifacts called ``membrane locking'' that\nmakes cloth appear artificially stiff. Here we propose a general framework,\ncalled Mass-Spring Net, for learning a simple yet efficient surrogate model\nthat captures the effects of these complex materials using only motion\nobservations. The cloth is discretized into a mass-spring network with unknown\nmaterial parameters that are learned directly from the motion data, using a\nnovel force-and-impulse loss function. Our approach demonstrates the ability to\naccurately model spatially varying material properties from a variety of data\nsources, and immunity to membrane locking which plagues FEM-based simulations.\nCompared to graph-based networks and neural ODE-based architectures, our method\nachieves significantly faster training times, higher reconstruction accuracy,\nand improved generalization to novel dynamic scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21288v1", "cate": "cs.GR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2504.00707", "title": "Interleaved Multitask Learning with Energy Modulated Learning Progress", "authors": ["Hanne Say", "Suzan Ece Ada", "Emre Ugur", "Minoru Asada", "Erhan Oztop"], "categories": ["cs.RO", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      submitted to Neural Networks Journal (under review), 48 pages, 11 figures", "url": "http://arxiv.org/abs/2504.00707v2", "summary": "As humans learn new skills and apply their existing knowledge while\nmaintaining previously learned information, \"continual learning\" in machine\nlearning aims to incorporate new data while retaining and utilizing past\nknowledge. However, existing machine learning methods often does not mimic\nhuman learning where tasks are intermixed due to individual preferences and\nenvironmental conditions. Humans typically switch between tasks instead of\ncompletely mastering one task before proceeding to the next. To explore how\nhuman-like task switching can enhance learning efficiency, we propose a multi\ntask learning architecture that alternates tasks based on task-agnostic\nmeasures such as \"learning progress\" and \"neural computational energy\nexpenditure\". To evaluate the efficacy of our method, we run several systematic\nexperiments by using a set of effect-prediction tasks executed by a simulated\nmanipulator robot. The experiments show that our approach surpasses random\ninterleaved and sequential task learning in terms of average learning accuracy.\nMoreover, by including energy expenditure in the task switching logic, our\napproach can still perform favorably while reducing neural energy expenditure.", "comment": "submitted to Neural Networks Journal (under review), 48 pages, 11\n  figures", "pdf_url": "http://arxiv.org/pdf/2504.00707v2", "cate": "cs.RO", "date": "2025-04-01", "updated": "2025-07-26"}
{"id": "2507.19881", "title": "FedS2R: One-Shot Federated Domain Generalization for Synthetic-to-Real Semantic Segmentation in Autonomous Driving", "authors": ["Tao Lian", "Jose L. Gómez", "Antonio M. López"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19881v1", "summary": "Federated domain generalization has shown promising progress in image\nclassification by enabling collaborative training across multiple clients\nwithout sharing raw data. However, its potential in the semantic segmentation\nof autonomous driving remains underexplored. In this paper, we propose FedS2R,\nthe first one-shot federated domain generalization framework for\nsynthetic-to-real semantic segmentation in autonomous driving. FedS2R comprises\ntwo components: an inconsistency-driven data augmentation strategy that\ngenerates images for unstable classes, and a multi-client knowledge\ndistillation scheme with feature fusion that distills a global model from\nmultiple client models. Experiments on five real-world datasets, Cityscapes,\nBDD100K, Mapillary, IDD, and ACDC, show that the global model significantly\noutperforms individual client models and is only 2 mIoU points behind the model\ntrained with simultaneous access to all client data. These results demonstrate\nthe effectiveness of FedS2R in synthetic-to-real semantic segmentation for\nautonomous driving under federated learning", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19881v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20112", "title": "Online Learning with Probing for Sequential User-Centric Selection", "authors": ["Tianyi Xu", "Yiting Chen", "Henger Li", "Zheyong Bian", "Emiliano Dall'Anese", "Zizhan Zheng"], "categories": ["cs.LG", "cs.AI", "cs.DS", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20112v1", "summary": "We formalize sequential decision-making with information acquisition as the\nprobing-augmented user-centric selection (PUCS) framework, where a learner\nfirst probes a subset of arms to obtain side information on resources and\nrewards, and then assigns $K$ plays to $M$ arms. PUCS covers applications such\nas ridesharing, wireless scheduling, and content recommendation, in which both\nresources and payoffs are initially unknown and probing is costly. For the\noffline setting with known distributions, we present a greedy probing algorithm\nwith a constant-factor approximation guarantee $\\zeta = (e-1)/(2e-1)$. For the\nonline setting with unknown distributions, we introduce OLPA, a stochastic\ncombinatorial bandit algorithm that achieves a regret bound\n$\\mathcal{O}(\\sqrt{T} + \\ln^{2} T)$. We also prove a lower bound\n$\\Omega(\\sqrt{T})$, showing that the upper bound is tight up to logarithmic\nfactors. Experiments on real-world data demonstrate the effectiveness of our\nsolutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20112v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2506.09091", "title": "Variational Inference Optimized Using the Curved Geometry of Coupled Free Energy", "authors": ["Kenric Nelson", "Igor Oliveira", "Amenah Al-Najafi", "Fode Zhang", "Hon Keung Tony Ng"], "categories": ["cs.LG", "cs.IT", "math.IT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      14 pages, 2 figures, 1 Table, AGI-25", "url": "http://arxiv.org/abs/2506.09091v3", "summary": "We introduce an optimization framework for variational inference based on the\ncoupled free energy, extending variational inference techniques to account for\nthe curved geometry of the coupled exponential family. This family includes\nimportant heavy-tailed distributions such as the generalized Pareto and the\nStudent's t. By leveraging the coupled free energy, which is equal to the\ncoupled evidence lower bound (ELBO) of the inverted probabilities, we improve\nthe accuracy and robustness of the learned model. The coupled generalization of\nFisher Information metric and the affine connection. The method is applied to\nthe design of a coupled variational autoencoder (CVAE). By using the coupling\nfor both the distributions and cost functions, the reconstruction metric is\nderived to still be the mean-square average loss with modified constants. The\nnovelty comes from sampling the heavy-tailed latent distribution with its\nassociated coupled probability, which has faster decaying tails. The result is\nthe ability to train a model robust against severe outliers, while assuring\nthat the training process is stable. The Wasserstein-2 or Fr\\'echet Inception\nDistance of the reconstructed CelebA images shows the CVAE has a 3\\%\nimprovement over the VAE after 5 epochs of training.", "comment": "14 pages, 2 figures, 1 Table, AGI-25", "pdf_url": "http://arxiv.org/pdf/2506.09091v3", "cate": "cs.LG", "date": "2025-06-10", "updated": "2025-07-25"}
{"id": "2507.20669", "title": "SNR Optimization for Common Emitter Amplifier", "authors": ["Orhan Gazi"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20669v1", "summary": "In this paper we investigate the effects of the thermal noise of the base\nresistance of common emitter amplifier (CEA) on the output SNR, and we show\nthat a first order Butterworth filter at the output of the CEA significantly\nimproves output SNR significantly and supress the performances of higher order\nButterworth, Chebyshev I, II and elliptic filters. We propose a formula for the\nselection of cut-off frequency of analog filters for given orders to achieve\nsignificant SNR improvement at CEA output. Considering the filter complexity\nand output SNR improvement, we can conclude that the first order Butterworth\nfilter outperforms Chebyshev I, II and elliptic filters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20669v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20825", "title": "Chirp-Permuted AFDM: A New Degree of Freedom for Next-Generation Versatile Waveform Design", "authors": ["Hyeon Seok Rou", "Giuseppe Thadeu Freitas de Abreu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20825v1", "summary": "We present a novel multicarrier waveform, termed chirp-permuted affine\nfrequency division multiplexing (CP-AFDM), which introduces a unique\nchirp-permutation domain on top of the chirp subcarriers of the conventional\nAFDM. Rigorous analysis of the signal model and waveform properties, supported\nby numerical simulations, demonstrates that the proposed CP-AFDM preserves all\ncore characteristics of affine frequency division multiplexing (AFDM) -\nincluding robustness to doubly-dispersive channels, peak-to-average power ratio\n(PAPR), and full delay-Doppler representation - while further enhancing\nambiguity function resolution and peak-to-sidelobe ratio (PSLR) in the Doppler\ndomain. These improvements establish CP-AFDM as a highly attractive candidate\nfor emerging sixth generation (6G) use cases demanding both reliability and\nsensing-awareness. Moreover, by exploiting the vast degree of freedom in the\nchirp-permutation domain, two exemplary multifunctional applications are\nintroduced: an index modulation (IM) technique over the permutation domain\nwhich achieves significant spectral efficiency gains, and a physical-layer\nsecurity scheme that ensures practically perfect security through\npermutation-based keying, without requiring additional transmit energy or\nsignaling overhead.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20825v1", "cate": "eess.SP", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.04862", "title": "Efficacy of Image Similarity as a Metric for Augmenting Small Dataset Retinal Image Segmentation", "authors": ["Thomas Wallace", "Ik Siong Heng", "Senad Subasic", "Chris Messenger"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      30 pages, 10 figures", "url": "http://arxiv.org/abs/2507.04862v3", "summary": "Synthetic images are an option for augmenting limited medical imaging\ndatasets to improve the performance of various machine learning models. A\ncommon metric for evaluating synthetic image quality is the Fr\\'echet Inception\nDistance (FID) which measures the similarity of two image datasets. In this\nstudy we evaluate the relationship between this metric and the improvement\nwhich synthetic images, generated by a Progressively Growing Generative\nAdversarial Network (PGGAN), grant when augmenting Diabetes-related Macular\nEdema (DME) intraretinal fluid segmentation performed by a U-Net model with\nlimited amounts of training data. We find that the behaviour of augmenting with\nstandard and synthetic images agrees with previously conducted experiments.\nAdditionally, we show that dissimilar (high FID) datasets do not improve\nsegmentation significantly. As FID between the training and augmenting datasets\ndecreases, the augmentation datasets are shown to contribute to significant and\nrobust improvements in image segmentation. Finally, we find that there is\nsignificant evidence to suggest that synthetic and standard augmentations\nfollow separate log-normal trends between FID and improvements in model\nperformance, with synthetic data proving more effective than standard\naugmentation techniques. Our findings show that more similar datasets (lower\nFID) will be more effective at improving U-Net performance, however, the\nresults also suggest that this improvement may only occur when images are\nsufficiently dissimilar.", "comment": "30 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.04862v3", "cate": "eess.IV", "date": "2025-07-07", "updated": "2025-07-29"}
{"id": "2506.06732", "title": "Neural Spectral Band Generation for Audio Coding", "authors": ["Woongjib Choi", "Byeong Hyeon Kim", "Hyungseob Lim", "Inseon Jang", "Hong-Goo Kang"], "categories": ["eess.AS", "cs.AI", "eess.SP"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted to Interspeech 2025", "url": "http://arxiv.org/abs/2506.06732v2", "summary": "Spectral band replication (SBR) enables bit-efficient coding by generating\nhigh-frequency bands from the low-frequency ones. However, it only utilizes\ncoarse spectral features upon a subband-wise signal replication, limiting\nadaptability to diverse acoustic signals. In this paper, we explore the\nefficacy of a deep neural network (DNN)-based generative approach for coding\nthe high-frequency bands, which we call neural spectral band generation\n(n-SBG). Specifically, we propose a DNN-based encoder-decoder structure to\nextract and quantize the side information related to the high-frequency\ncomponents and generate the components given both the side information and the\ndecoded core-band signals. The whole coding pipeline is optimized with\ngenerative adversarial criteria to enable the generation of perceptually\nplausible sound. From experiments using AAC as the core codec, we show that the\nproposed method achieves a better perceptual quality than HE-AAC-v1 with much\nless side information.", "comment": "Accepted to Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2506.06732v2", "cate": "eess.AS", "date": "2025-06-07", "updated": "2025-07-28"}
{"id": "2507.20336", "title": "Faster exact learning of k-term DNFs with membership and equivalence queries", "authors": ["Josh Alman", "Shivam Nadimpalli", "Shyamal Patel", "Rocco Servedio"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20336v1", "summary": "In 1992 Blum and Rudich [BR92] gave an algorithm that uses membership and\nequivalence queries to learn $k$-term DNF formulas over $\\{0,1\\}^n$ in time\n$\\textsf{poly}(n,2^k)$, improving on the naive $O(n^k)$ running time that can\nbe achieved without membership queries [Val84]. Since then, many alternative\nalgorithms [Bsh95, Kus97, Bsh97, BBB+00] have been given which also achieve\nruntime $\\textsf{poly}(n,2^k)$.\n  We give an algorithm that uses membership and equivalence queries to learn\n$k$-term DNF formulas in time $\\textsf{poly}(n) \\cdot 2^{\\tilde{O}(\\sqrt{k})}$.\nThis is the first improvement for this problem since the original work of Blum\nand Rudich [BR92].\n  Our approach employs the Winnow2 algorithm for learning linear threshold\nfunctions over an enhanced feature space which is adaptively constructed using\nmembership queries. It combines a strengthened version of a technique that\neffectively reduces the length of DNF terms from the original work of [BR92]\nwith a range of additional algorithmic tools (attribute-efficient learning\nalgorithms for low-weight linear threshold functions and techniques for finding\nrelevant variables from junta testing) and analytic ingredients (extremal\npolynomials and noise operators) that are novel in the context of query-based\nDNF learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20336v1", "cate": "cs.DS", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.21493", "title": "BANG: Dividing 3D Assets via Generative Exploded Dynamics", "authors": ["Longwen Zhang", "Qixuan Zhang", "Haoran Jiang", "Yinuo Bai", "Wei Yang", "Lan Xu", "Jingyi Yu"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Homepage: this https URL", "url": "http://arxiv.org/abs/2507.21493v1", "summary": "3D creation has always been a unique human strength, driven by our ability to\ndeconstruct and reassemble objects using our eyes, mind and hand. However,\ncurrent 3D design tools struggle to replicate this natural process, requiring\nconsiderable artistic expertise and manual labor. This paper introduces BANG, a\nnovel generative approach that bridges 3D generation and reasoning, allowing\nfor intuitive and flexible part-level decomposition of 3D objects. At the heart\nof BANG is \"Generative Exploded Dynamics\", which creates a smooth sequence of\nexploded states for an input geometry, progressively separating parts while\npreserving their geometric and semantic coherence.\n  BANG utilizes a pre-trained large-scale latent diffusion model, fine-tuned\nfor exploded dynamics with a lightweight exploded view adapter, allowing\nprecise control over the decomposition process. It also incorporates a temporal\nattention module to ensure smooth transitions and consistency across time. BANG\nenhances control with spatial prompts, such as bounding boxes and surface\nregions, enabling users to specify which parts to decompose and how. This\ninteraction can be extended with multimodal models like GPT-4, enabling\n2D-to-3D manipulations for more intuitive and creative workflows.\n  The capabilities of BANG extend to generating detailed part-level geometry,\nassociating parts with functional descriptions, and facilitating\ncomponent-aware 3D creation and manufacturing workflows. Additionally, BANG\noffers applications in 3D printing, where separable parts are generated for\neasy printing and reassembly. In essence, BANG enables seamless transformation\nfrom imaginative concepts to detailed 3D assets, offering a new perspective on\ncreation that resonates with human intuition.", "comment": "Homepage: https://sites.google.com/view/bang7355608", "pdf_url": "http://arxiv.org/pdf/2507.21493v1", "cate": "cs.GR", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2504.01301", "title": "Bi-LAT: Bilateral Control-Based Imitation Learning via Natural Language and Action Chunking with Transformers", "authors": ["Takumi Kobayashi", "Masato Kobayashi", "Thanpimon Buamanee", "Yuki Uranishi"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.01301v2", "summary": "We present Bi-LAT, a novel imitation learning framework that unifies\nbilateral control with natural language processing to achieve precise force\nmodulation in robotic manipulation. Bi-LAT leverages joint position, velocity,\nand torque data from leader-follower teleoperation while also integrating\nvisual and linguistic cues to dynamically adjust applied force. By encoding\nhuman instructions such as \"softly grasp the cup\" or \"strongly twist the\nsponge\" through a multimodal Transformer-based model, Bi-LAT learns to\ndistinguish nuanced force requirements in real-world tasks. We demonstrate\nBi-LAT's performance in (1) unimanual cup-stacking scenario where the robot\naccurately modulates grasp force based on language commands, and (2) bimanual\nsponge-twisting task that requires coordinated force control. Experimental\nresults show that Bi-LAT effectively reproduces the instructed force levels,\nparticularly when incorporating SigLIP among tested language encoders. Our\nfindings demonstrate the potential of integrating natural language cues into\nimitation learning, paving the way for more intuitive and adaptive human-robot\ninteraction. For additional material, please visit:\nhttps://mertcookimg.github.io/bi-lat/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.01301v2", "cate": "cs.RO", "date": "2025-04-02", "updated": "2025-07-28"}
{"id": "2507.19891", "title": "Interpretable Open-Vocabulary Referring Object Detection with Reverse Contrast Attention", "authors": ["Drandreb Earl O. Juanico", "Rowel O. Atienza", "Jeffrey Kenneth Go"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages with supplementary material, 6 main figures, 2 main tables; github: earl-juanico/rca", "url": "http://arxiv.org/abs/2507.19891v1", "summary": "We propose Reverse Contrast Attention (RCA), a plug-in method that enhances\nobject localization in vision-language transformers without retraining. RCA\nreweights final-layer attention by suppressing extremes and amplifying\nmid-level activations to let semantically relevant but subdued tokens guide\npredictions. We evaluate it on Open Vocabulary Referring Object Detection\n(OV-RefOD), introducing FitAP, a confidence-free average precision metric based\non IoU and box area. RCA improves FitAP in 11 out of 15 open-source VLMs, with\ngains up to $+26.6\\%$. Effectiveness aligns with attention sharpness and fusion\ntiming; while late-fusion models benefit consistently, models like\n$\\texttt{DeepSeek-VL2}$ also improve, pointing to capacity and disentanglement\nas key factors. RCA offers both interpretability and performance gains for\nmultimodal transformers.", "comment": "10 pages with supplementary material, 6 main figures, 2 main tables;\n  github: earl-juanico/rca", "pdf_url": "http://arxiv.org/pdf/2507.19891v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20114", "title": "Wine Characterisation with Spectral Information and Predictive Artificial Intelligence", "authors": ["Jianping Yao", "Son N. Tran", "Hieu Nguyen", "Samantha Sawyer", "Rocco Longo"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20114v1", "summary": "The purpose of this paper is to use absorbance data obtained by human tasting\nand an ultraviolet-visible (UV-Vis) scanning spectrophotometer to predict the\nattributes of grape juice (GJ) and to classify the wine's origin, respectively.\nThe approach combined machine learning (ML) techniques with spectroscopy to\nfind a relatively simple way to apply them in two stages of winemaking and help\nimprove the traditional wine analysis methods regarding sensory data and wine's\norigins. This new technique has overcome the disadvantages of the complex\nsensors by taking advantage of spectral fingerprinting technology and forming a\ncomprehensive study of the employment of AI in the wine analysis domain. In the\nresults, Support Vector Machine (SVM) was the most efficient and robust in both\nattributes and origin prediction tasks. Both the accuracy and F1 score of the\norigin prediction exceed 91%. The feature ranking approach found that the more\ninfluential wavelengths usually appear at the lower end of the scan range, 250\nnm (nanometers) to 420 nm, which is believed to be of great help for selecting\nappropriate validation methods and sensors to extract wine data in future\nresearch. The knowledge of this research provides new ideas and early solutions\nfor the wine industry or other beverage industries to integrate big data and\nIoT in the future, which significantly promotes the development of 'Smart\nWineries'.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20114v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.06232", "title": "Error Exponents for Quantum Packing Problems via An Operator Layer Cake Theorem", "authors": ["Hao-Chung Cheng", "Po-Chieh Liu"], "categories": ["quant-ph", "cs.IT", "math-ph", "math.FA", "math.IT", "math.MP"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      2nd version: tables and references added", "url": "http://arxiv.org/abs/2507.06232v2", "summary": "In this work, we prove a one-shot random coding bound for classical-quantum\nchannel coding, a problem conjectured by Burnashev and Holevo in 1998. By\nchoosing the optimal input distribution, we recover the optimal error exponent\n(i.e., the reliability function) of classical-quantum channels for rates above\nthe critical rate. Our result extends to various quantum packing-type problems,\nincluding classical communication over any fully quantum channel with or\nwithout entanglement-assistance, constant composition codes, and classical data\ncompression with quantum side information via fixed-length or variable-length\ncoding.\n  Our technical ingredient is to establish an operator layer cake theorem - the\ndirectional derivative of an operator logarithm admits an integral\nrepresentation of certain projections. This shows that a kind of pretty-good\nmeasurement is equivalent to a randomized Holevo-Helstrom measurement, which\nprovides an operational explanation of why the pretty-good measurement is\npretty good.", "comment": "2nd version: tables and references added", "pdf_url": "http://arxiv.org/pdf/2507.06232v2", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-28"}
{"id": "2507.20685", "title": "What's Really Different with AI? -- A Behavior-based Perspective on System Safety for Automated Driving Systems", "authors": ["Marcus Nolte", "Nayel Fabian Salem", "Olaf Franke", "Jan Heckmann", "Christoph Höhmann", "Georg Stettinger", "Markus Maurer"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      8 pages, 1 figure, 1 table, to be published in 2025 IEEE International Automated Vehicle Validation Conference (IAVVC)", "url": "http://arxiv.org/abs/2507.20685v1", "summary": "Assuring safety for ``AI-based'' systems is one of the current challenges in\nsafety engineering. For automated driving systems, in particular, further\nassurance challenges result from the open context that the systems need to\noperate in after deployment. The current standardization and regulation\nlandscape for ``AI-based'' systems is becoming ever more complex, as standards\nand regulations are being released at high frequencies.\n  This position paper seeks to provide guidance for making qualified arguments\nwhich standards should meaningfully be applied to (``AI-based'') automated\ndriving systems. Furthermore, we argue for clearly differentiating sources of\nrisk between AI-specific and general uncertainties related to the open context.\nIn our view, a clear conceptual separation can help to exploit commonalities\nthat can close the gap between system-level and AI-specific safety analyses,\nwhile ensuring the required rigor for engineering safe ``AI-based'' systems.", "comment": "8 pages, 1 figure, 1 table, to be published in 2025 IEEE\n  International Automated Vehicle Validation Conference (IAVVC)", "pdf_url": "http://arxiv.org/pdf/2507.20685v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20942", "title": "Interference Analysis and Successive Interference Cancellation for Multistatic OFDM-based ISAC Systems", "authors": ["Taewon Jeong", "Lucas Giroto", "Umut Utku Erdem", "Christian Karle", "Jiyeon Choi", "Thomas Zwick", "Benjamin Nuss"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.20942v1", "summary": "Multistatic integrated sensing and communications (ISAC) systems, which use\ndistributed transmitters and receivers, offer enhanced spatial coverage and\nsensing accuracy compared to stand-alone ISAC configurations. However, these\nsystems face challenges due to interference between co-existing ISAC nodes,\nespecially during simultaneous operation. In this paper, we analyze the impact\nof this mutual interference arising from the co-existence in a multistatic ISAC\nscenario, where a mono- and a bistatic ISAC system share the same spectral\nresources. We first classify differenct types of interference in the power\ndomain. Then, we discuss how the interference can affect both sensing and\ncommunications in terms of bit error rate (BER), error vector magnitude (EVM),\nand radar image under varied transmit power and RCS configurations through\nsimulations. Along with interfernce analysis, we propose a low-complexity\nsuccessive interference cancellation method that adaptively cancels either the\nmonostatic reflection or the bistatic line-of-sight signal based on a\nmonostatic radar image signal-to-interference-plus-noise ratio (SINR). The\nproposed framework is evaluated with both simulations and proof-of-concept\nmeasurements using an ISAC testbed with a radar echo generator for object\nemulation. The results have shown that the proposed method reduces BER and\nimproves EVM as well as radar image SINR across a wide range of SINR\nconditions. These results demonstrate that accurate component-wise cancellation\ncan be achieved with low computational overhead, making the method suitable for\npractical applications.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.20942v1", "cate": "eess.SP", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.05815", "title": "Beyond Manual Annotation: A Human-AI Collaborative Framework for Medical Image Segmentation Using Only \"Better or Worse\" Expert Feedback", "authors": ["Yizhe Zhang"], "categories": ["eess.IV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      10 pages, 6 figures", "url": "http://arxiv.org/abs/2507.05815v2", "summary": "Manual annotation of medical images is a labor-intensive and time-consuming\nprocess, posing a significant bottleneck in the development and deployment of\nrobust medical imaging AI systems. This paper introduces a novel hands-free\nHuman-AI collaborative framework for medical image segmentation that\nsubstantially reduces the annotation burden by eliminating the need for\nexplicit manual pixel-level labeling. The core innovation lies in a preference\nlearning paradigm, where human experts provide minimal, intuitive feedback --\nsimply indicating whether an AI-generated segmentation is better or worse than\na previous version. The framework comprises four key components: (1) an\nadaptable foundation model (FM) for feature extraction, (2) label propagation\nbased on feature similarity, (3) a clicking agent that learns from human\nbetter-or-worse feedback to decide where to click and with which label, and (4)\na multi-round segmentation learning procedure that trains a state-of-the-art\nsegmentation network using pseudo-labels generated by the clicking agent and\nFM-based label propagation. Experiments on three public datasets demonstrate\nthat the proposed approach achieves competitive segmentation performance using\nonly binary preference feedback, without requiring experts to directly manually\nannotate the images.", "comment": "10 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.05815v2", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-28"}
{"id": "2507.18181", "title": "SpecASR: Accelerating LLM-based Automatic Speech Recognition via Speculative Decoding", "authors": ["Linye Wei", "Shuzhang Zhong", "Songqiang Xu", "Runsheng Wang", "Ru Huang", "Meng Li"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted by Design Automation Conference (DAC) 2025", "url": "http://arxiv.org/abs/2507.18181v2", "summary": "Large language model (LLM)-based automatic speech recognition (ASR) has\nrecently attracted a lot of attention due to its high recognition accuracy and\nenhanced multi-dialect support. However, the high decoding latency of LLMs\nchallenges the real-time ASR requirements. Although speculative decoding has\nbeen explored for better decoding efficiency, they usually ignore the key\ncharacteristics of the ASR task and achieve limited speedup. To further reduce\nthe real-time ASR latency, in this paper, we propose a novel speculative\ndecoding framework specialized for ASR, dubbed SpecASR. SpecASR is developed\nbased on our core observation that ASR decoding is audio-conditioned, which\nresults in high output alignment between small and large ASR models, even given\noutput mismatches in intermediate decoding steps. Therefore, SpecASR features\nan adaptive draft sequence generation process that dynamically modifies the\ndraft sequence length to maximize the token acceptance length. SpecASR further\nproposes a draft sequence recycling strategy that reuses the previously\ngenerated draft sequence to reduce the draft ASR model latency. Moreover, a\ntwo-pass sparse token tree generation algorithm is also proposed to balance the\nlatency of draft and target ASR models. With extensive experimental results, we\ndemonstrate SpecASR achieves 3.04x-3.79x and 1.25x-1.84x speedup over the\nbaseline autoregressive decoding and speculative decoding, respectively,\nwithout any loss in recognition accuracy.", "comment": "Accepted by Design Automation Conference (DAC) 2025", "pdf_url": "http://arxiv.org/pdf/2507.18181v2", "cate": "eess.AS", "date": "2025-07-24", "updated": "2025-07-28"}
{"id": "2507.20354", "title": "Deterministic Almost-Linear-Time Gomory-Hu Trees", "authors": ["Amir Abboud", "Rasmus Kyng", "Jason Li", "Debmalya Panigrahi", "Maximilian Probst Gutenberg", "Thatchaphol Saranurak", "Weixuan Yuan", "Wuwei Yuan"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20354v1", "summary": "Given an $m$-edge, undirected, weighted graph $G=(V,E,w)$, a Gomory-Hu tree\n$T$ (Gomory and Hu, 1961) is a tree over the vertex set $V$ such that all-pairs\nmincuts in $G$ are preserved exactly in $T$.\n  In this article, we give the first almost-optimal $m^{1+o(1)}$-time\ndeterministic algorithm for constructing a Gomory-Hu tree. Prior to our work,\nthe best deterministic algorithm for this problem dated back to the original\nalgorithm of Gomory and Hu that runs in $nm^{1+o(1)}$ time (using current\nmaxflow algorithms). In fact, this is the first almost-linear time\ndeterministic algorithm for even simpler problems, such as finding the\n$k$-edge-connected components of a graph.\n  Our new result hinges on two separate and novel components that each\nintroduce a distinct set of de-randomization tools of independent interest:\n  - a deterministic reduction from the all-pairs mincuts problem to the\nsingle-souce mincuts problem incurring only subpolynomial overhead, and\n  - a deterministic almost-linear time algorithm for the single-source mincuts\nproblem.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20354v1", "cate": "cs.DS", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.21124", "title": "VizGenie: Toward Self-Refining, Domain-Aware Workflows for Next-Generation Scientific Visualization", "authors": ["Ayan Biswas", "Terece L. Turton", "Nishath Rajiv Ranasinghe", "Shawn Jones", "Bradley Love", "William Jones", "Aric Hagberg", "Han-Wei Shen", "Nathan DeBardeleben", "Earl Lawrence"], "categories": ["cs.HC", "cs.AI", "cs.GR", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21124v1", "summary": "We present VizGenie, a self-improving, agentic framework that advances\nscientific visualization through large language model (LLM) by orchestrating of\na collection of domain-specific and dynamically generated modules. Users\ninitially access core functionalities--such as threshold-based filtering, slice\nextraction, and statistical analysis--through pre-existing tools. For tasks\nbeyond this baseline, VizGenie autonomously employs LLMs to generate new\nvisualization scripts (e.g., VTK Python code), expanding its capabilities\non-demand. Each generated script undergoes automated backend validation and is\nseamlessly integrated upon successful testing, continuously enhancing the\nsystem's adaptability and robustness. A distinctive feature of VizGenie is its\nintuitive natural language interface, allowing users to issue high-level\nfeature-based queries (e.g., ``visualize the skull\"). The system leverages\nimage-based analysis and visual question answering (VQA) via fine-tuned vision\nmodels to interpret these queries precisely, bridging domain expertise and\ntechnical implementation. Additionally, users can interactively query generated\nvisualizations through VQA, facilitating deeper exploration. Reliability and\nreproducibility are further strengthened by Retrieval-Augmented Generation\n(RAG), providing context-driven responses while maintaining comprehensive\nprovenance records. Evaluations on complex volumetric datasets demonstrate\nsignificant reductions in cognitive overhead for iterative visualization tasks.\nBy integrating curated domain-specific tools with LLM-driven flexibility,\nVizGenie not only accelerates insight generation but also establishes a\nsustainable, continuously evolving visualization practice. The resulting\nplatform dynamically learns from user interactions, consistently enhancing\nsupport for feature-centric exploration and reproducible research in scientific\nvisualization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21124v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2504.13807", "title": "DiffOG: Differentiable Policy Trajectory Optimization with Generalizability", "authors": ["Zhengtong Xu", "Zichen Miao", "Qiang Qiu", "Zhe Zhang", "Yu She"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.13807v4", "summary": "Imitation learning-based visuomotor policies excel at manipulation tasks but\noften produce suboptimal action trajectories compared to model-based methods.\nDirectly mapping camera data to actions via neural networks can result in jerky\nmotions and difficulties in meeting critical constraints, compromising safety\nand robustness in real-world deployment. For tasks that require high robustness\nor strict adherence to constraints, ensuring trajectory quality is crucial.\nHowever, the lack of interpretability in neural networks makes it challenging\nto generate constraint-compliant actions in a controlled manner. This paper\nintroduces differentiable policy trajectory optimization with generalizability\n(DiffOG), a learning-based trajectory optimization framework designed to\nenhance visuomotor policies. By leveraging the proposed differentiable\nformulation of trajectory optimization with transformer, DiffOG seamlessly\nintegrates policies with a generalizable optimization layer. DiffOG refines\naction trajectories to be smoother and more constraint-compliant while\nmaintaining alignment with the original demonstration distribution, thus\navoiding degradation in policy performance. We evaluated DiffOG across 11\nsimulated tasks and 2 real-world tasks. The results demonstrate that DiffOG\nsignificantly enhances the trajectory quality of visuomotor policies while\nhaving minimal impact on policy performance, outperforming trajectory\nprocessing baselines such as greedy constraint clipping and penalty-based\ntrajectory optimization. Furthermore, DiffOG achieves superior performance\ncompared to existing constrained visuomotor policy. For more details, please\nvisit the project website: https://zhengtongxu.github.io/diffog-website/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.13807v4", "cate": "cs.RO", "date": "2025-04-18", "updated": "2025-07-28"}
{"id": "2507.19917", "title": "A mini-batch training strategy for deep subspace clustering networks", "authors": ["Yuxuan Jiang", "Chenwei Yu", "Zhi Lin", "Xiaolan Liu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19917v1", "summary": "Mini-batch training is a cornerstone of modern deep learning, offering\ncomputational efficiency and scalability for training complex architectures.\nHowever, existing deep subspace clustering (DSC) methods, which typically\ncombine an autoencoder with a self-expressive layer, rely on full-batch\nprocessing. The bottleneck arises from the self-expressive module, which\nrequires representations of the entire dataset to construct a\nself-representation coefficient matrix. In this work, we introduce a mini-batch\ntraining strategy for DSC by integrating a memory bank that preserves global\nfeature representations. Our approach enables scalable training of deep\narchitectures for subspace clustering with high-resolution images, overcoming\nprevious limitations. Additionally, to efficiently fine-tune large-scale\npre-trained encoders for subspace clustering, we propose a decoder-free\nframework that leverages contrastive learning instead of autoencoding for\nrepresentation learning. This design not only eliminates the computational\noverhead of decoder training but also provides competitive performance.\nExtensive experiments demonstrate that our approach not only achieves\nperformance comparable to full-batch methods, but outperforms other\nstate-of-the-art subspace clustering methods on the COIL100 and ORL datasets by\nfine-tuning deep networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19917v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20127", "title": "Aggregation-aware MLP: An Unsupervised Approach for Graph Message-passing", "authors": ["Xuanting Xie", "Bingheng Li", "Erlin Pan", "Zhao Kang", "Wenyu Chen"], "categories": ["cs.LG", "cs.AI", "cs.GR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 6 figures", "url": "http://arxiv.org/abs/2507.20127v1", "summary": "Graph Neural Networks (GNNs) have become a dominant approach to learning\ngraph representations, primarily because of their message-passing mechanisms.\nHowever, GNNs typically adopt a fixed aggregator function such as Mean, Max, or\nSum without principled reasoning behind the selection. This rigidity,\nespecially in the presence of heterophily, often leads to poor, problem\ndependent performance. Although some attempts address this by designing more\nsophisticated aggregation functions, these methods tend to rely heavily on\nlabeled data, which is often scarce in real-world tasks. In this work, we\npropose a novel unsupervised framework, \"Aggregation-aware Multilayer\nPerceptron\" (AMLP), which shifts the paradigm from directly crafting\naggregation functions to making MLP adaptive to aggregation. Our lightweight\napproach consists of two key steps: First, we utilize a graph reconstruction\nmethod that facilitates high-order grouping effects, and second, we employ a\nsingle-layer network to encode varying degrees of heterophily, thereby\nimproving the capacity and applicability of the model. Extensive experiments on\nnode clustering and classification demonstrate the superior performance of\nAMLP, highlighting its potential for diverse graph learning scenarios.", "comment": "11 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.20127v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20739", "title": "Efficient Adjoint Petrov-Galerkin Reduced Order Models for fluid flows governed by the incompressible Navier-Stokes equations", "authors": ["Kamil David Sommer", "Lucas Mieg", "Siddharth Sharma", "Romuald Skoda", "Martin Mönnigmann"], "categories": ["eess.SY", "cs.SY", "physics.flu-dyn"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20739v1", "summary": "This research paper investigates the Adjoint Petrov-Galerkin (APG) method for\nreduced order models (ROM) and fluid dynamics governed by the incompressible\nNavier-Stokes equations. The Adjoint Petrov-Galerkin ROM, derived using the\nMori-Zwanzig formalism, demonstrates superior accuracy and stability compared\nto standard Galerkin ROMs. However, challenges arise due to the time invariance\nof the test basis vectors, resulting in high computational requirements. To\naddress this, we introduce a new efficient Adjoint Petrov-Galerkin (eAPG) ROM\nformulation, extending its application to the incompressible Navier-Stokes\nequations by exploiting the polynomial structure inherent in these equations.\nThe offline and online phases partition eliminates the need for repeated test\nbasis vector evaluations. This improves computational efficiency in comparison\nto the general Adjoint Petrov-Galerkin ROM formulation. A novel approach to\naugmenting the memory length, a critical factor influencing the stability and\naccuracy of the APG-ROM, is introduced, employing a data-driven optimization.\nNumerical results for the 3D turbulent flow around a circular cylinder\ndemonstrate the efficacy of the proposed approach. Error measures and\ncomputational cost evaluations, considering metrics such as floating point\noperations and simulation time, provide a comprehensive analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20739v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20952", "title": "Analytical Modeling of Batteryless IoT Sensors Powered by Ambient Energy Harvesting", "authors": ["Jimmy Fernandez Landivar", "Andrea Zanella", "Ihsane Gryech", "Sofie Pollin", "Hazem Sallouha"], "categories": ["eess.SP", "94C30", "I.2.9"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      6 pages, 6 figures, 1 table, accepted for publication in the 36th IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC 2025), Istanbul, Türkiye", "url": "http://arxiv.org/abs/2507.20952v1", "summary": "This paper presents a comprehensive mathematical model to characterize the\nenergy dynamics of batteryless IoT sensor nodes powered entirely by ambient\nenergy harvesting. The model captures both the energy harvesting and\nconsumption phases, explicitly incorporating power management tasks to enable\nprecise estimation of device behavior across diverse environmental conditions.\nThe proposed model is applicable to a wide range of IoT devices and supports\nintelligent power management units designed to maximize harvested energy under\nfluctuating environmental conditions. We validated our model against a\nprototype batteryless IoT node, conducting experiments under three distinct\nillumination scenarios. Results show a strong correlation between analytical\nand measured supercapacitor voltage profiles, confirming the proposed model's\naccuracy.", "comment": "6 pages, 6 figures, 1 table, accepted for publication in the 36th\n  IEEE International Symposium on Personal, Indoor and Mobile Radio\n  Communications (PIMRC 2025), Istanbul, T\\\"urkiye", "pdf_url": "http://arxiv.org/pdf/2507.20952v1", "cate": "eess.SP", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.09923", "title": "IM-LUT: Interpolation Mixing Look-Up Tables for Image Super-Resolution", "authors": ["Sejin Park", "Sangmin Lee", "Kyong Hwan Jin", "Seung-Won Jung"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.09923v3", "summary": "Super-resolution (SR) has been a pivotal task in image processing, aimed at\nenhancing image resolution across various applications. Recently, look-up table\n(LUT)-based approaches have attracted interest due to their efficiency and\nperformance. However, these methods are typically designed for fixed scale\nfactors, making them unsuitable for arbitrary-scale image SR (ASISR). Existing\nASISR techniques often employ implicit neural representations, which come with\nconsiderable computational cost and memory demands. To address these\nlimitations, we propose Interpolation Mixing LUT (IM-LUT), a novel framework\nthat operates ASISR by learning to blend multiple interpolation functions to\nmaximize their representational capacity. Specifically, we introduce IM-Net, a\nnetwork trained to predict mixing weights for interpolation functions based on\nlocal image patterns and the target scale factor. To enhance efficiency of\ninterpolation-based methods, IM-Net is transformed into IM-LUT, where LUTs are\nemployed to replace computationally expensive operations, enabling lightweight\nand fast inference on CPUs while preserving reconstruction quality.\nExperimental results on several benchmark datasets demonstrate that IM-LUT\nconsistently achieves a superior balance between image quality and efficiency\ncompared to existing methods, highlighting its potential as a promising\nsolution for resource-constrained applications.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.09923v3", "cate": "eess.IV", "date": "2025-07-14", "updated": "2025-07-28"}
{"id": "2507.19204", "title": "Should Top-Down Clustering Affect Boundaries in Unsupervised Word Discovery?", "authors": ["Simon Malan", "Benjamin van Niekerk", "Herman Kamper"], "categories": ["eess.AS", "cs.CL", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Submitted to the IEEE/ACM Transactions on Audio, Speech and Language Processing", "url": "http://arxiv.org/abs/2507.19204v2", "summary": "We investigate the problem of segmenting unlabeled speech into word-like\nunits and clustering these to create a lexicon. Prior work can be categorized\ninto two frameworks. Bottom-up methods first determine boundaries and then\ncluster the fixed segmented words into a lexicon. In contrast, top-down methods\nincorporate information from the clustered words to inform boundary selection.\nHowever, it is unclear whether top-down information is necessary to improve\nsegmentation. To explore this, we look at two similar approaches that differ in\nwhether top-down clustering informs boundary selection. Our simple bottom-up\nstrategy predicts word boundaries using the dissimilarity between adjacent\nself-supervised features, then clusters the resulting segments to construct a\nlexicon. Our top-down system is an updated version of the ES-KMeans dynamic\nprogramming method that iteratively uses K-means to update its boundaries. On\nthe five-language ZeroSpeech benchmarks, both approaches achieve comparable\nstate-of-the-art results, with the bottom-up system being nearly five times\nfaster. Through detailed analyses, we show that the top-down influence of\nES-KMeans can be beneficial (depending on factors like the candidate\nboundaries), but in many cases the simple bottom-up method performs just as\nwell. For both methods, we show that the clustering step is a limiting factor.\nTherefore, we recommend that future work focus on improved clustering\ntechniques and learning more discriminative word-like representations. Project\ncode repository: https://github.com/s-malan/prom-seg-clus.", "comment": "Submitted to the IEEE/ACM Transactions on Audio, Speech and Language\n  Processing", "pdf_url": "http://arxiv.org/pdf/2507.19204v2", "cate": "eess.AS", "date": "2025-07-25", "updated": "2025-07-28"}
{"id": "2507.19802", "title": "CleANN: Efficient Full Dynamism in Graph-based Approximate Nearest Neighbor Search", "authors": ["Ziyu Zhang", "Yuanhao Wei", "Joshua Engels", "Julian Shun"], "categories": ["cs.DB", "cs.DS", "cs.IR"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19802v1", "summary": "Approximate nearest neighbor search (ANNS) has become a quintessential\nalgorithmic problem for various other foundational data tasks for AI workloads.\nGraph-based ANNS indexes have superb empirical trade-offs in indexing cost,\nquery efficiency, and query approximation quality. Most existing graph-based\nindexes are designed for the static scenario, where there are no updates to the\ndata after the index is constructed. However, full dynamism (insertions,\ndeletions, and searches) is crucial to providing up-to-date responses in\napplications using vector databases. It is desirable that the index efficiently\nsupports updates and search queries concurrently. Existing dynamic graph-based\nindexes suffer from at least one of the following problems: (1) the query\nquality degrades as updates happen; and (2) the graph structure updates used to\nmaintain the index quality upon updates are global and thus expensive. To solve\nthese problems, we propose the CleANN system which consists of three main\ncomponents: (1) workload-aware linking of diverse search tree descendants to\ncombat distribution shift; (2)query-adaptive on-the-fly neighborhood\nconsolidation to efficiently handle deleted nodes; and (3) semi-lazy memory\ncleaning to clean up stale information in the data structure and reduce the\nwork spent by the first two components. We evaluate CleANN on 7 diverse\ndatasets on fully dynamic workloads and find that CleANN has query quality at\nleast as good as if the index had been built statically using the corresponding\ndata. In the in-memory setting using 56 hyper-threads, with all types of\nqueries running concurrently, at the same recall level, CleANN achieves 7-1200x\nthroughput improvement on million-scale real-world datasets. To the best of our\nknowledge, CleANN is the first concurrent ANNS index to achieve such efficiency\nwhile maintaining quality under full dynamism.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19802v1", "cate": "cs.DB", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21181", "title": "Mitigation of Social Media Platforms Impact on the Users", "authors": ["Smita Khapre", "Sudhanshu Semwal"], "categories": ["cs.CR", "cs.CY", "cs.GR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      WSCG 2025 33. International Conference on Computer Graphics, Visualization and Computer Vision 2025", "url": "http://arxiv.org/abs/2507.21181v1", "summary": "Social media platforms offer numerous benefits and allow people to come\ntogether for various causes. Many communities, academia, government agencies,\ninstitutions, healthcare, entertainment, and businesses are on social media\nplatforms. They are intuitive and free for users. It has become unimaginable to\nlive without social media. Their architecture and data handling are geared\ntowards scalability, uninterrupted availability, and both personal and\ncollaborative revenue generation. Primarily, artificial intelligence algorithms\nare employed on stored user data for optimization and feeds. This has the\npotential to impact user safety, privacy, and security, even when metadata is\nused. A new decentralized data arrangement framework based on the Fractal-tree\nand L-Systems algorithm is proposed to mitigate some of the impacts of social\nmedia platforms.\n  Future work will focus on demonstrating the effectiveness of the new\ndecentralized framework by comparing its results against state-of-the-art\nsecurity methods currently used in databases. A cryptographic algorithm could\nalso be implemented for the framework, employing a new key generation for each\nbranch. This will strengthen database security; for example, if a user key is\nleaked, regenerating the key for each branch will keep the data secure by\napplying defense mechanisms in the proposed L-System-based tree framework.", "comment": "WSCG 2025 33. International Conference on Computer Graphics,\n  Visualization and Computer Vision 2025", "pdf_url": "http://arxiv.org/pdf/2507.21181v1", "cate": "cs.CR", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2505.00693", "title": "Robotic Visual Instruction", "authors": ["Yanbang Li", "Ziyang Gong", "Haoyang Li", "Xiaoqi Huang", "Haolan Kang", "Guangping Bai", "Xianzheng Ma"], "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Project website: this https URL", "url": "http://arxiv.org/abs/2505.00693v3", "summary": "Recently, natural language has been the primary medium for human-robot\ninteraction. However, its inherent lack of spatial precision introduces\nchallenges for robotic task definition such as ambiguity and verbosity.\nMoreover, in some public settings where quiet is required, such as libraries or\nhospitals, verbal communication with robots is inappropriate. To address these\nlimitations, we introduce the Robotic Visual Instruction (RoVI), a novel\nparadigm to guide robotic tasks through an object-centric, hand-drawn symbolic\nrepresentation. RoVI effectively encodes spatial-temporal information into\nhuman-interpretable visual instructions through 2D sketches, utilizing arrows,\ncircles, colors, and numbers to direct 3D robotic manipulation. To enable\nrobots to understand RoVI better and generate precise actions based on RoVI, we\npresent Visual Instruction Embodied Workflow (VIEW), a pipeline formulated for\nRoVI-conditioned policies. This approach leverages Vision-Language Models\n(VLMs) to interpret RoVI inputs, decode spatial and temporal constraints from\n2D pixel space via keypoint extraction, and then transform them into executable\n3D action sequences. We additionally curate a specialized dataset of 15K\ninstances to fine-tune small VLMs for edge deployment,enabling them to\neffectively learn RoVI capabilities. Our approach is rigorously validated\nacross 11 novel tasks in both real and simulated environments, demonstrating\nsignificant generalization capability. Notably, VIEW achieves an 87.5% success\nrate in real-world scenarios involving unseen tasks that feature multi-step\nactions, with disturbances, and trajectory-following requirements. Project\nwebsite: https://robotic-visual-instruction.github.io/", "comment": "Project website: https://robotic-visual-instruction.github.io/", "pdf_url": "http://arxiv.org/pdf/2505.00693v3", "cate": "cs.RO", "date": "2025-05-01", "updated": "2025-07-27"}
{"id": "2507.19929", "title": "DynamiX: Large-Scale Dynamic Social Network Simulator", "authors": ["Yanhui Sun", "Wu Liu", "Wentao Wang", "Hantao Yao", "Jiebo Luo", "Yongdong Zhang"], "categories": ["physics.soc-ph", "cs.AI"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19929v1", "summary": "Understanding the intrinsic mechanisms of social platforms is an urgent\ndemand to maintain social stability. The rise of large language models provides\nsignificant potential for social network simulations to capture attitude\ndynamics and reproduce collective behaviors. However, existing studies mainly\nfocus on scaling up agent populations, neglecting the dynamic evolution of\nsocial relationships. To address this gap, we introduce DynamiX, a novel\nlarge-scale social network simulator dedicated to dynamic social network\nmodeling. DynamiX uses a dynamic hierarchy module for selecting core agents\nwith key characteristics at each timestep, enabling accurate alignment of\nreal-world adaptive switching of user roles. Furthermore, we design distinct\ndynamic social relationship modeling strategies for different user types. For\nopinion leaders, we propose an information-stream-based link prediction method\nrecommending potential users with similar stances, simulating homogeneous\nconnections, and autonomous behavior decisions. For ordinary users, we\nconstruct an inequality-oriented behavior decision-making module, effectively\naddressing unequal social interactions and capturing the patterns of\nrelationship adjustments driven by multi-dimensional factors. Experimental\nresults demonstrate that DynamiX exhibits marked improvements in attitude\nevolution simulation and collective behavior analysis compared to static\nnetworks. Besides, DynamiX opens a new theoretical perspective on follower\ngrowth prediction, providing empirical evidence for opinion leaders\ncultivation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19929v1", "cate": "physics.soc-ph", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20130", "title": "Generative molecule evolution using 3D pharmacophore for efficient Structure-Based Drug Design", "authors": ["Yi He", "Ailun Wang", "Zhi Wang", "Yu Liu", "Xingyuan Xu", "Wen Yan"], "categories": ["cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20130v1", "summary": "Recent advances in generative models, particularly diffusion and\nauto-regressive models, have revolutionized fields like computer vision and\nnatural language processing. However, their application to structure-based drug\ndesign (SBDD) remains limited due to critical data constraints. To address the\nlimitation of training data for models targeting SBDD tasks, we propose an\nevolutionary framework named MEVO, which bridges the gap between billion-scale\nsmall molecule dataset and the scarce protein-ligand complex dataset, and\neffectively increase the abundance of training data for generative SBDD models.\nMEVO is composed of three key components: a high-fidelity VQ-VAE for molecule\nrepresentation in latent space, a diffusion model for pharmacophore-guided\nmolecule generation, and a pocket-aware evolutionary strategy for molecule\noptimization with physics-based scoring function. This framework efficiently\ngenerate high-affinity binders for various protein targets, validated with\npredicted binding affinities using free energy perturbation (FEP) methods. In\naddition, we showcase the capability of MEVO in designing potent inhibitors to\nKRAS$^{\\textrm{G12D}}$, a challenging target in cancer therapeutics, with\nsimilar affinity to the known highly active inhibitor evaluated by FEP\ncalculations. With high versatility and generalizability, MEVO offers an\neffective and data-efficient model for various tasks in structure-based ligand\ndesign.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20130v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20792", "title": "UAV-Borne Digital Radar System for Coherent Multistatic SAR Imaging", "authors": ["Julian Kanz", "Christian Gesell", "Christina Bonfert", "David Werbunat", "Alexander Grathwohl", "Julian Aguilar", "Martin Vossiek", "Christian Waldschmidt"], "categories": ["eess.SY", "cs.SY", "eess.SP"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20792v1", "summary": "Advancements in analog-to-digital converter (ADC) technology have enabled\nhigher sampling rates, making it feasible to adopt digital radar architectures\nthat directly sample the radio-frequency (RF) signal, eliminating the need for\nanalog downconversion. This digital approach supports greater flexibility in\nwaveform design and signal processing, particularly through digital modulation\nschemes like orthogonal frequency division multiplexing (OFDM). This paper\npresents a digital radar system mounted on an uncrewed aerial vehicle (UAV),\nwhich employs OFDM waveforms for coherent multistatic synthetic aperture radar\n(SAR) imaging in the L-band. The radar setup features a primary UAV node\nresponsible for signal transmission and monostatic data acquisition, alongside\nsecondary nodes that operate in a receive-only mode. These secondary nodes\ncapture the radar signal reflected from the scene as well as a direct sidelink\nsignal. RF signals from both the radar and sidelink paths are sampled and\nprocessed offline. To manage data storage efficiently, a trigger mechanism is\nemployed to record only the relevant portions of the radar signal. The system\nmaintains coherency in both fast-time and slow-time domains, which is essential\nfor multistatic SAR imaging. Because the secondary nodes are passive, the\nsystem can be easily scaled to accommodate a larger swarm of UAVs. The paper\ndetails the full signal processing workflow for both monostatic and multistatic\nSAR image formation, including an analysis and correction of synchronization\nerrors that arise from the uncoupled operation of the nodes. The proposed\ncoherent processing method is validated through static radar measurements,\ndemonstrating coherency achieved by the concept. Additionally, a UAV-based\nbistatic SAR experiment demonstrates the system's performance by producing\nhigh-resolution monostatic, bistatic, and combined multistatic SAR images.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20792v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20268", "title": "Data-Efficient Prediction-Powered Calibration via Cross-Validation", "authors": ["Seonghoon Yoo", "Houssem Sifaou", "Sangwoo Park", "Joonhyuk Kang", "Osvaldo Simeone"], "categories": ["cs.LG", "eess.SP", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20268v1", "summary": "Calibration data are necessary to formally quantify the uncertainty of the\ndecisions produced by an existing artificial intelligence (AI) model. To\novercome the common issue of scarce calibration data, a promising approach is\nto employ synthetic labels produced by a (generally different) predictive\nmodel. However, fine-tuning the label-generating predictor on the inference\ntask of interest, as well as estimating the residual bias of the synthetic\nlabels, demand additional data, potentially exacerbating the calibration data\nscarcity problem. This paper introduces a novel approach that efficiently\nutilizes limited calibration data to simultaneously fine-tune a predictor and\nestimate the bias of the synthetic labels. The proposed method yields\nprediction sets with rigorous coverage guarantees for AI-generated decisions.\nExperimental results on an indoor localization problem validate the\neffectiveness and performance gains of our solution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20268v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.13993", "title": "OrthoInsight: Rib Fracture Diagnosis and Report Generation Based on Multi-Modal Large Models", "authors": ["Ningyong Wu", "Jinzhi Wang", "Wenhong Zhao", "Chenzhan Yu", "Zhigang Xiu", "Duwei Dai"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      This paper contains significant issues in the data preprocessing stage, which led to non-reproducible results. We are currently correcting the errors and will submit a revised version in the future.", "url": "http://arxiv.org/abs/2507.13993v2", "summary": "The growing volume of medical imaging data has increased the need for\nautomated diagnostic tools, especially for musculoskeletal injuries like rib\nfractures, commonly detected via CT scans. Manual interpretation is\ntime-consuming and error-prone. We propose OrthoInsight, a multi-modal deep\nlearning framework for rib fracture diagnosis and report generation. It\nintegrates a YOLOv9 model for fracture detection, a medical knowledge graph for\nretrieving clinical context, and a fine-tuned LLaVA language model for\ngenerating diagnostic reports. OrthoInsight combines visual features from CT\nimages with expert textual data to deliver clinically useful outputs. Evaluated\non 28,675 annotated CT images and expert reports, it achieves high performance\nacross Diagnostic Accuracy, Content Completeness, Logical Coherence, and\nClinical Guidance Value, with an average score of 4.28, outperforming models\nlike GPT-4 and Claude-3. This study demonstrates the potential of multi-modal\nlearning in transforming medical image analysis and providing effective support\nfor radiologists.", "comment": "This paper contains significant issues in the data preprocessing\n  stage, which led to non-reproducible results. We are currently correcting the\n  errors and will submit a revised version in the future.", "pdf_url": "http://arxiv.org/pdf/2507.13993v2", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-26"}
{"id": "2407.15672", "title": "Computer Audition: From Task-Specific Machine Learning to Foundation Models", "authors": ["Andreas Triantafyllopoulos", "Iosif Tsangko", "Alexander Gebhard", "Annamaria Mesaros", "Tuomas Virtanen", "Björn Schuller"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted for publication to the Proceedings of the IEEE", "url": "http://arxiv.org/abs/2407.15672v2", "summary": "Foundation models (FMs) are increasingly spearheading recent advances on a\nvariety of tasks that fall under the purview of computer audition -- the use of\nmachines to understand sounds. They feature several advantages over traditional\npipelines: among others, the ability to consolidate multiple tasks in a single\nmodel, the option to leverage knowledge from other modalities, and the\nreadily-available interaction with human users. Naturally, these promises have\ncreated substantial excitement in the audio community, and have led to a wave\nof early attempts to build new, general-purpose foundation models for audio. In\nthe present contribution, we give an overview of computational audio analysis\nas it transitions from traditional pipelines towards auditory foundation\nmodels. Our work highlights the key operating principles that underpin those\nmodels, and showcases how they can accommodate multiple tasks that the audio\ncommunity previously tackled separately.", "comment": "Accepted for publication to the Proceedings of the IEEE", "pdf_url": "http://arxiv.org/pdf/2407.15672v2", "cate": "cs.SD", "date": "2024-07-22", "updated": "2025-07-28"}
{"id": "2507.20038", "title": "An Algorithm-to-Contract Framework without Demand Queries", "authors": ["Ilan Doron-Arad", "Hadas Shachnai", "Gilad Shmerler", "Inbal Talgam-Cohen"], "categories": ["cs.GT", "cs.DS"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20038v1", "summary": "Consider costly tasks that add up to the success of a project, and must be\nfitted by an agent into a given time-frame. This is an instance of the classic\nbudgeted maximization problem, which admits an approximation scheme (FPTAS).\nNow assume the agent is performing these tasks on behalf of a principal, who is\nthe one to reap the rewards if the project succeeds. The principal must design\na contract to incentivize the agent. Is there still an approximation scheme? In\nthis work, our ultimate goal is an algorithm-to-contract transformation, which\ntransforms algorithms for combinatorial problems (like budgeted maximization)\nto tackle incentive constraints that arise in contract design. Our approach\ndiverges from previous works on combinatorial contract design by avoiding an\nassumption of black-box access to a demand oracle.\n  We first show how to \"lift\" the FPTAS for budgeted maximization to obtain the\nbest-possible multiplicative and additive FPTAS for the contract design\nproblem. We establish this through our \"local-global\" framework, in which the\n\"local\" step is to (approximately) solve a two-sided strengthened variant of\nthe demand problem. The \"global\" step then utilizes the local one to find the\napproximately optimal contract. We apply our framework to a host of\ncombinatorial constraints including multi-dimensional budgets, budgeted\nmatroid, and budgeted matching constraints. In all cases we achieve an\napproximation essentially matching the best approximation for the purely\nalgorithmic problem. We also develop a method to tackle multi-agent contract\nsettings, where the team of working agents must abide to combinatorial\nfeasibility constraints.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20038v1", "cate": "cs.GT", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21311", "title": "VoluMe -- Authentic 3D Video Calls from Live Gaussian Splat Prediction", "authors": ["Martin de La Gorce", "Charlie Hewitt", "Tibor Takacs", "Robert Gerdisch", "Zafiirah Hosenie", "Givi Meishvili", "Marek Kowalski", "Thomas J. Cashman", "Antonio Criminisi"], "categories": ["cs.CV", "cs.GR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21311v1", "summary": "Virtual 3D meetings offer the potential to enhance copresence, increase\nengagement and thus improve effectiveness of remote meetings compared to\nstandard 2D video calls. However, representing people in 3D meetings remains a\nchallenge; existing solutions achieve high quality by using complex hardware,\nmaking use of fixed appearance via enrolment, or by inverting a pre-trained\ngenerative model. These approaches lead to constraints that are unwelcome and\nill-fitting for videoconferencing applications. We present the first method to\npredict 3D Gaussian reconstructions in real time from a single 2D webcam feed,\nwhere the 3D representation is not only live and realistic, but also authentic\nto the input video. By conditioning the 3D representation on each video frame\nindependently, our reconstruction faithfully recreates the input video from the\ncaptured viewpoint (a property we call authenticity), while generalizing\nrealistically to novel viewpoints. Additionally, we introduce a stability loss\nto obtain reconstructions that are temporally stable on video sequences. We\nshow that our method delivers state-of-the-art accuracy in visual quality and\nstability metrics compared to existing methods, and demonstrate our approach in\nlive one-to-one 3D meetings using only a standard 2D camera and display. This\ndemonstrates that our approach can allow anyone to communicate volumetrically,\nvia a method for 3D videoconferencing that is not only highly accessible, but\nalso realistic and authentic.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21311v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21103", "title": "Analise Semantica Automatizada com LLM e RAG para Bulas Farmaceuticas", "authors": ["Daniel Meireles do Rego"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      in Portuguese language", "url": "http://arxiv.org/abs/2507.21103v1", "summary": "The production of digital documents has been growing rapidly in academic,\nbusiness, and health environments, presenting new challenges in the efficient\nextraction and analysis of unstructured information. This work investigates the\nuse of RAG (Retrieval-Augmented Generation) architectures combined with\nLarge-Scale Language Models (LLMs) to automate the analysis of documents in PDF\nformat. The proposal integrates vector search techniques by embeddings,\nsemantic data extraction and generation of contextualized natural language\nresponses. To validate the approach, we conducted experiments with drug package\ninserts extracted from official public sources. The semantic queries applied\nwere evaluated by metrics such as accuracy, completeness, response speed and\nconsistency. The results indicate that the combination of RAG with LLMs offers\nsignificant gains in intelligent information retrieval and interpretation of\nunstructured technical texts.", "comment": "in Portuguese language", "pdf_url": "http://arxiv.org/pdf/2507.21103v1", "cate": "cs.IR", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2505.06743", "title": "TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility", "authors": ["Marius Baden", "Ahmed Abouelazm", "Christian Hubschneider", "Yin Wu", "Daniel Slieter", "J. Marius Zöllner"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      First and Second authors contributed equally; Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025) for oral presentation; Winner of the best paper award", "url": "http://arxiv.org/abs/2505.06743v3", "summary": "Trajectory prediction is crucial for autonomous driving, enabling vehicles to\nnavigate safely by anticipating the movements of surrounding road users.\nHowever, current deep learning models often lack trustworthiness as their\npredictions can be physically infeasible and illogical to humans. To make\npredictions more trustworthy, recent research has incorporated prior knowledge,\nlike the social force model for modeling interactions and kinematic models for\nphysical realism. However, these approaches focus on priors that suit either\nvehicles or pedestrians and do not generalize to traffic with mixed agent\nclasses. We propose incorporating interaction and kinematic priors of all agent\nclasses--vehicles, pedestrians, and cyclists with class-specific interaction\nlayers to capture agent behavioral differences. To improve the interpretability\nof the agent interactions, we introduce DG-SFM, a rule-based interaction\nimportance score that guides the interaction layer. To ensure physically\nfeasible predictions, we proposed suitable kinematic models for all agent\nclasses with a novel pedestrian kinematic model. We benchmark our approach on\nthe Argoverse 2 dataset, using the state-of-the-art transformer HPTR as our\nbaseline. Experiments demonstrate that our method improves interaction\ninterpretability, revealing a correlation between incorrect predictions and\ndivergence from our interaction prior. Even though incorporating the kinematic\nmodels causes a slight decrease in accuracy, they eliminate infeasible\ntrajectories found in the dataset and the baseline model. Thus, our approach\nfosters trust in trajectory prediction as its interaction reasoning is\ninterpretable, and its predictions adhere to physics.", "comment": "First and Second authors contributed equally; Accepted in the 36th\n  IEEE Intelligent Vehicles Symposium (IV 2025) for oral presentation; Winner\n  of the best paper award", "pdf_url": "http://arxiv.org/pdf/2505.06743v3", "cate": "cs.RO", "date": "2025-05-10", "updated": "2025-07-27"}
{"id": "2507.19950", "title": "RARE: Refine Any Registration of Pairwise Point Clouds via Zero-Shot Learning", "authors": ["Chengyu Zheng", "Jin Huang", "Honghua Chen", "Mingqiang Wei"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19950v1", "summary": "Recent research leveraging large-scale pretrained diffusion models has\ndemonstrated the potential of using diffusion features to establish semantic\ncorrespondences in images. Inspired by advancements in diffusion-based\ntechniques, we propose a novel zero-shot method for refining point cloud\nregistration algorithms. Our approach leverages correspondences derived from\ndepth images to enhance point feature representations, eliminating the need for\na dedicated training dataset. Specifically, we first project the point cloud\ninto depth maps from multiple perspectives and extract implicit knowledge from\na pretrained diffusion network as depth diffusion features. These features are\nthen integrated with geometric features obtained from existing methods to\nestablish more accurate correspondences between point clouds. By leveraging\nthese refined correspondences, our approach achieves significantly improved\nregistration accuracy. Extensive experiments demonstrate that our method not\nonly enhances the performance of existing point cloud registration techniques\nbut also exhibits robust generalization capabilities across diverse datasets.\nCodes are available at https://github.com/zhengcy-lambo/RARE.git.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19950v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20144", "title": "Awesome-OL: An Extensible Toolkit for Online Learning", "authors": ["Zeyi Liu", "Songqiao Hu", "Pengyu Han", "Jiaming Liu", "Xiao He"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2507.20144v1", "summary": "In recent years, online learning has attracted increasing attention due to\nits adaptive capability to process streaming and non-stationary data. To\nfacilitate algorithm development and practical deployment in this area, we\nintroduce Awesome-OL, an extensible Python toolkit tailored for online learning\nresearch. Awesome-OL integrates state-of-the-art algorithm, which provides a\nunified framework for reproducible comparisons, curated benchmark datasets, and\nmulti-modal visualization. Built upon the scikit-multiflow open-source\ninfrastructure, Awesome-OL emphasizes user-friendly interactions without\ncompromising research flexibility or extensibility. The source code is publicly\navailable at: https://github.com/liuzy0708/Awesome-OL.", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2507.20144v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20835", "title": "Minimum Attention Control (MAC) in a Receding Horizon Framework with Applications", "authors": ["T. Ganesh Teja", "Santhosh Kumar Varanasi", "Phanindra Jampana"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      21 pages, 12 figures", "url": "http://arxiv.org/abs/2507.20835v1", "summary": "Minimum Attention Control (MAC) is a control technique that provides minimal\ninput changes to meet the control objective. Mathematically, the zero norm of\nthe input changes is used as a constraint for the given control objective and\nminimized with respect to the process dynamics. In this paper, along with the\nzero norm constraint, stage costs are also considered for reference tracking in\na receding horizon framework. For this purpose, the optimal inputs of the\nprevious horizons are also considered in the optimization problem of the\ncurrent horizon. An alternating minimization algorithm is applied to solve the\noptimization problem (Minimum Attention Model Predictive Control (MAMPC)). The\nouter step of the optimization is a quadratic program, while the inner step,\nwhich solves for sparsity, has an analytical solution. The proposed algorithm\nis implemented on two case studies: a four-tank system with slow dynamics and a\nfuel cell stack with fast dynamics. A detailed comparative study of the\nproposed algorithm with standard MPC indicates sparse control actions with a\ntradeoff in the tracking error.", "comment": "21 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.20835v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20426", "title": "ResCap-DBP: A Lightweight Residual-Capsule Network for Accurate DNA-Binding Protein Prediction Using Global ProteinBERT Embeddings", "authors": ["Samiul Based Shuvo", "Tasnia Binte Mamun", "U Rajendra Acharya"], "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20426v1", "summary": "DNA-binding proteins (DBPs) are integral to gene regulation and cellular\nprocesses, making their accurate identification essential for understanding\nbiological functions and disease mechanisms. Experimental methods for DBP\nidentification are time-consuming and costly, driving the need for efficient\ncomputational prediction techniques. In this study, we propose a novel deep\nlearning framework, ResCap-DBP, that combines a residual learning-based encoder\nwith a one-dimensional Capsule Network (1D-CapsNet) to predict DBPs directly\nfrom raw protein sequences. Our architecture incorporates dilated convolutions\nwithin residual blocks to mitigate vanishing gradient issues and extract rich\nsequence features, while capsule layers with dynamic routing capture\nhierarchical and spatial relationships within the learned feature space. We\nconducted comprehensive ablation studies comparing global and local embeddings\nfrom ProteinBERT and conventional one-hot encoding. Results show that\nProteinBERT embeddings substantially outperform other representations on large\ndatasets. Although one-hot encoding showed marginal advantages on smaller\ndatasets, such as PDB186, it struggled to scale effectively. Extensive\nevaluations on four pairs of publicly available benchmark datasets demonstrate\nthat our model consistently outperforms current state-of-the-art methods. It\nachieved AUC scores of 98.0% and 89.5% on PDB14189andPDB1075, respectively. On\nindependent test sets PDB2272 and PDB186, the model attained top AUCs of 83.2%\nand 83.3%, while maintaining competitive performance on larger datasets such as\nPDB20000. Notably, the model maintains a well balanced sensitivity and\nspecificity across datasets. These results demonstrate the efficacy and\ngeneralizability of integrating global protein representations with advanced\ndeep learning architectures for reliable and scalable DBP prediction in diverse\ngenomic contexts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20426v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19404", "title": "A multi-dynamic low-rank deep image prior (ML-DIP) for real-time 3D cardiovascular MRI", "authors": ["Chong Chen", "Marc Vornehm", "Preethi Chandrasekaran", "Muhammad A. Sultan", "Syed M. Arshad", "Yingmin Liu", "Yuchi Han", "Rizwan Ahmad"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19404v2", "summary": "Purpose: To develop a reconstruction framework for 3D real-time cine\ncardiovascular magnetic resonance (CMR) from highly undersampled data without\nrequiring fully sampled training data.\n  Methods: We developed a multi-dynamic low-rank deep image prior (ML-DIP)\nframework that models spatial image content and temporal deformation fields\nusing separate neural networks. These networks are optimized per scan to\nreconstruct the dynamic image series directly from undersampled k-space data.\nML-DIP was evaluated on (i) a 3D cine digital phantom with simulated premature\nventricular contractions (PVCs), (ii) ten healthy subjects (including two\nscanned during both rest and exercise), and (iii) five patients with PVCs.\nPhantom results were assessed using peak signal-to-noise ratio (PSNR) and\nstructural similarity index measure (SSIM). In vivo performance was evaluated\nby comparing left-ventricular function quantification (against 2D real-time\ncine) and image quality (against 2D real-time cine and binning-based 5D-Cine).\n  Results: In the phantom study, ML-DIP achieved PSNR > 29 dB and SSIM > 0.90\nfor scan times as short as two minutes, while recovering cardiac motion,\nrespiratory motion, and PVC events. In healthy subjects, ML-DIP yielded\nfunctional measurements comparable to 2D cine and higher image quality than\n5D-Cine, including during exercise with high heart rates and bulk motion. In\nPVC patients, ML-DIP preserved beat-to-beat variability and reconstructed\nirregular beats, whereas 5D-Cine showed motion artifacts and information loss\ndue to binning.\n  Conclusion: ML-DIP enables high-quality 3D real-time CMR with acceleration\nfactors exceeding 1,000 by learning low-rank spatial and temporal\nrepresentations from undersampled data, without relying on external fully\nsampled training datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19404v2", "cate": "eess.IV", "date": "2025-07-25", "updated": "2025-07-28"}
{"id": "2412.05167", "title": "Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models", "authors": ["Kuofeng Gao", "Shu-Tao Xia", "Ke Xu", "Philip Torr", "Jindong Gu"], "categories": ["cs.AI", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by ACL 2025", "url": "http://arxiv.org/abs/2412.05167v2", "summary": "Large Audio-Language Models (LALMs), such as GPT-4o, have recently unlocked\naudio dialogue capabilities, enabling direct spoken exchanges with humans. The\npotential of LALMs broadens their applicability across a wide range of\npractical scenarios supported by audio dialogues. However, given these\nadvancements, a comprehensive benchmark to evaluate the performance of LALMs in\nthe open-ended audio dialogue understanding remains absent currently. To\naddress this gap, we propose an Audio Dialogue Understanding Benchmark\n(ADU-Bench), which consists of 4 benchmark datasets. They assess the open-ended\naudio dialogue ability for LALMs in 3 general scenarios, 12 skills, 9\nmultilingual languages, and 4 categories of ambiguity handling. Notably, we\nfirstly propose the evaluation of ambiguity handling in audio dialogues that\nexpresses different intentions beyond the same literal meaning of sentences,\ne.g., \"Really!?\" with different intonations. In summary, ADU-Bench includes\nover 20,000 open-ended audio dialogues for the assessment of LALMs. Through\nextensive experiments on 16 LALMs, our analysis reveals that existing LALMs\nstruggle with mathematical symbols and formulas, understanding human behavior\nsuch as roleplay, comprehending multiple languages, and handling audio dialogue\nambiguities from different phonetic elements, such as intonations, pause\npositions, and homophones. The benchmark is available at\nhttps://adu-bench.github.io/.", "comment": "Accepted by ACL 2025", "pdf_url": "http://arxiv.org/pdf/2412.05167v2", "cate": "cs.AI", "date": "2024-12-06", "updated": "2025-07-28"}
{"id": "2507.20441", "title": "TIMEST: Temporal Information Motif Estimator Using Sampling Trees", "authors": ["Yunjie Pan", "Omkar Bhalerao", "C. Seshadhri", "Nishil Talati"], "categories": ["cs.DB", "cs.DS", "cs.IR"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20441v1", "summary": "The mining of pattern subgraphs, known as motifs, is a core task in the field\nof graph mining. Edges in real-world networks often have timestamps, so there\nis a need for temporal motif mining. A temporal motif is a richer structure\nthat imposes timing constraints on the edges of the motif. Temporal motifs have\nbeen used to analyze social networks, financial transactions, and biological\nnetworks.\n  Motif counting in temporal graphs is particularly challenging. A graph with\nmillions of edges can have trillions of temporal motifs, since the same edge\ncan occur with multiple timestamps. There is a combinatorial explosion of\npossibilities, and state-of-the-art algorithms cannot manage motifs with more\nthan four vertices.\n  In this work, we present TIMEST: a general, fast, and accurate estimation\nalgorithm to count temporal motifs of arbitrary sizes in temporal networks. Our\napproach introduces a temporal spanning tree sampler that leverages weighted\nsampling to generate substructures of target temporal motifs. This method\ncarefully takes a subset of temporal constraints of the motif that can be\njointly and efficiently sampled. TIMEST uses randomized estimation techniques\nto obtain accurate estimates of motif counts.\n  We give theoretical guarantees on the running time and approximation\nguarantees of TIMEST. We perform an extensive experimental evaluation and show\nthat TIMEST is both faster and more accurate than previous algorithms. Our CPU\nimplementation exhibits an average speedup of 28x over state-of-the-art GPU\nimplementation of the exact algorithm, and 6x speedup over SOTA approximate\nalgorithms while consistently showcasing less than 5% error in most cases. For\nexample, TIMEST can count the number of instances of a financial fraud temporal\nmotif in four minutes with 0.6% error, while exact methods take more than two\ndays.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20441v1", "cate": "cs.DB", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.21411", "title": "InSituTale: Enhancing Augmented Data Storytelling with Physical Objects", "authors": ["Kentaro Takahira", "Yue Yu", "Takanori Fujiwara", "Suzuki Ryo", "Huamin Qu"], "categories": ["cs.HC", "cs.GR"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21411v1", "summary": "Augmented data storytelling enhances narrative delivery by integrating\nvisualizations with physical environments and presenter actions. Existing\nsystems predominantly rely on body gestures or speech to control\nvisualizations, leaving interactions with physical objects largely\nunderexplored. We introduce augmented physical data storytelling, an approach\nenabling presenters to manipulate visualizations through physical object\ninteractions. To inform this approach, we first conducted a survey of\ndata-driven presentations to identify common visualization commands. We then\nconducted workshops with nine HCI/VIS researchers to collect mappings between\nphysical manipulations and these commands. Guided by these insights, we\ndeveloped InSituTale, a prototype that combines object tracking via a depth\ncamera with Vision-LLM for detecting real-world events. Through physical\nmanipulations, presenters can dynamically execute various visualization\ncommands, delivering cohesive data storytelling experiences that blend physical\nand digital elements. A user study with 12 participants demonstrated that\nInSituTale enables intuitive interactions, offers high utility, and facilitates\nan engaging presentation experience.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21411v1", "cate": "cs.HC", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21105", "title": "AgentMaster: A Multi-Agent Conversational Framework Using A2A and MCP Protocols for Multimodal Information Retrieval and Analysis", "authors": ["Callie C. Liao", "Duoduo Liao", "Sai Surya Gadiraju"], "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21105v1", "summary": "The rise of Multi-Agent Systems (MAS) in Artificial Intelligence (AI),\nespecially integrated with Large Language Models (LLMs), has greatly\nfacilitated the resolution of complex tasks. However, current systems are still\nfacing challenges of inter-agent communication, coordination, and interaction\nwith heterogeneous tools and resources. Most recently, the Model Context\nProtocol (MCP) by Anthropic and Agent-to-Agent (A2A) communication protocol by\nGoogle have been introduced, and to the best of our knowledge, very few\napplications exist where both protocols are employed within a single MAS\nframework. We present a pilot study of AgentMaster, a novel modular\nmulti-protocol MAS framework with self-implemented A2A and MCP, enabling\ndynamic coordination and flexible communication. Through a unified\nconversational interface, the system supports natural language interaction\nwithout prior technical expertise and responds to multimodal queries for tasks\nincluding information retrieval, question answering, and image analysis.\nEvaluation through the BERTScore F1 and LLM-as-a-Judge metric G-Eval averaged\n96.3\\% and 87.1\\%, revealing robust inter-agent coordination, query\ndecomposition, dynamic routing, and domain-specific, relevant responses.\nOverall, our proposed framework contributes to the potential capabilities of\ndomain-specific, cooperative, and scalable conversational AI powered by MAS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21105v1", "cate": "cs.IR", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2505.09074", "title": "Trends in Motion Prediction Toward Deployable and Generalizable Autonomy: A Revisit and Perspectives", "authors": ["Letian Wang", "Marc-Antoine Lavoie", "Sandro Papais", "Barza Nisar", "Yuxiao Chen", "Wenhao Ding", "Boris Ivanovic", "Hao Shao", "Abulikemu Abuduweili", "Evan Cook", "Yang Zhou", "Peter Karkus", "Jiachen Li", "Changliu Liu", "Marco Pavone", "Steven Waslander"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Book Published by Foundation and Trends in Robotics. 162 pages, 40 figures, 13 tables", "url": "http://arxiv.org/abs/2505.09074v2", "summary": "Motion prediction, the anticipation of future agent states or scene\nevolution, is rooted in human cognition, bridging perception and\ndecision-making. It enables intelligent systems, such as robots and\nself-driving cars, to act safely in dynamic, human-involved environments, and\ninforms broader time-series reasoning challenges. With advances in methods,\nrepresentations, and datasets, the field has seen rapid progress, reflected in\nquickly evolving benchmark results. Yet, when state-of-the-art methods are\ndeployed in the real world, they often struggle to generalize to open-world\nconditions and fall short of deployment standards. This reveals a gap between\nresearch benchmarks, which are often idealized or ill-posed, and real-world\ncomplexity.\n  To address this gap, this survey revisits the generalization and\ndeployability of motion prediction models, with an emphasis on the applications\nof robotics, autonomous driving, and human motion. We first offer a\ncomprehensive taxonomy of motion prediction methods, covering representations,\nmodeling strategies, application domains, and evaluation protocols. We then\nstudy two key challenges: (1) how to push motion prediction models to be\ndeployable to realistic deployment standards, where motion prediction does not\nact in a vacuum, but functions as one module of closed-loop autonomy stacks -\nit takes input from the localization and perception, and informs downstream\nplanning and control. 2) how to generalize motion prediction models from\nlimited seen scenarios/datasets to the open-world settings. Throughout the\npaper, we highlight critical open challenges to guide future work, aiming to\nrecalibrate the community's efforts, fostering progress that is not only\nmeasurable but also meaningful for real-world applications. The project webpage\ncorresponding to this paper can be found here\nhttps://trends-in-motion-prediction- 2025.github.io/.", "comment": "Book Published by Foundation and Trends in Robotics. 162 pages, 40\n  figures, 13 tables", "pdf_url": "http://arxiv.org/pdf/2505.09074v2", "cate": "cs.RO", "date": "2025-05-14", "updated": "2025-07-27"}
{"id": "2507.19956", "title": "Predicting Brain Responses To Natural Movies With Multimodal LLMs", "authors": ["Cesar Kadir Torrico Villanueva", "Jiaxin Cindy Tu", "Mihir Tripathy", "Connor Lane", "Rishab Iyer", "Paul S. Scotti"], "categories": ["cs.CV", "cs.AI", "q-bio.NC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Code available at this https URL", "url": "http://arxiv.org/abs/2507.19956v1", "summary": "We present MedARC's team solution to the Algonauts 2025 challenge. Our\npipeline leveraged rich multimodal representations from various\nstate-of-the-art pretrained models across video (V-JEPA2), speech (Whisper),\ntext (Llama 3.2), vision-text (InternVL3), and vision-text-audio\n(Qwen2.5-Omni). These features extracted from the models were linearly\nprojected to a latent space, temporally aligned to the fMRI time series, and\nfinally mapped to cortical parcels through a lightweight encoder comprising a\nshared group head plus subject-specific residual heads. We trained hundreds of\nmodel variants across hyperparameter settings, validated them on held-out\nmovies and assembled ensembles targeted to each parcel in each subject. Our\nfinal submission achieved a mean Pearson's correlation of 0.2085 on the test\nsplit of withheld out-of-distribution movies, placing our team in fourth place\nfor the competition. We further discuss a last-minute optimization that would\nhave raised us to second place. Our results highlight how combining features\nfrom models trained in different modalities, using a simple architecture\nconsisting of shared-subject and single-subject components, and conducting\ncomprehensive model selection and ensembling improves generalization of\nencoding models to novel movie stimuli. All code is available on GitHub.", "comment": "Code available at https://github.com/MedARC-AI/algonauts2025", "pdf_url": "http://arxiv.org/pdf/2507.19956v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20164", "title": "ASNN: Learning to Suggest Neural Architectures from Performance Distributions", "authors": ["Jinwook Hong"], "categories": ["cs.LG", "cs.AI", "68T05, 68T07, 62M45"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.20164v1", "summary": "The architecture of a neural network (NN) plays a critical role in\ndetermining its performance. However, there is no general closed-form function\nthat maps between network structure and accuracy, making the process of\narchitecture design largely heuristic or search-based. In this study, we\npropose the Architecture Suggesting Neural Network (ASNN), a model designed to\nlearn the relationship between NN architecture and its test accuracy, and to\nsuggest improved architectures accordingly. To train ASNN, we constructed\ndatasets using TensorFlow-based models with varying numbers of layers and\nnodes. Experimental results were collected for both 2-layer and 3-layer\narchitectures across a grid of configurations, each evaluated with 10 repeated\ntrials to account for stochasticity. Accuracy values were treated as inputs,\nand architectural parameters as outputs. The trained ASNN was then used\niteratively to predict architectures that yield higher performance. In both\n2-layer and 3-layer cases, ASNN successfully suggested architectures that\noutperformed the best results found in the original training data. Repeated\nprediction and retraining cycles led to the discovery of architectures with\nimproved mean test accuracies, demonstrating the model's capacity to generalize\nthe performance-structure relationship. These results suggest that ASNN\nprovides an efficient alternative to random search for architecture\noptimization, and offers a promising approach toward automating neural network\ndesign. \"Parts of the manuscript, including text editing and expression\nrefinement, were supported by OpenAI's ChatGPT. All content was reviewed and\nverified by the authors.\"", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.20164v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20921", "title": "dq Modeling for Series-Parallel Compensated Wireless Power Transfer Systems", "authors": ["Zixuan Jiang"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Accepted by 2025 IEEE 5th International Conference on Electronic Technology, Communication and Information (ICETCI)", "url": "http://arxiv.org/abs/2507.20921v1", "summary": "Series-parallel (SP) compensated wireless power transfer (WPT) systems are\nwidely used in some specific scenarios, such as bioelectronics and portable\nelectronics. However, most studies are based on the phasor method and focused\non the steady-state analysis, which may overlook the transient process of\nsystems. Accordingly, inspired by the notion of coordinate transformation in\nthe field of motor drive, this work develops a dq modeling method for SP\ncompensated WPT systems. The proposed model effectively characterizes\nfirst-order system dynamics, facilitating enhanced measurement precision and\ncontrol system development. One measurement application, dq model-based mutual\ninductance identification, is presented to reflect the value of the dq model.\nSimulation results are shown to validate the model's effectiveness, indicating\nthat the developed model can be a good tool for the design of SP compensated\nWPT systems.", "comment": "Accepted by 2025 IEEE 5th International Conference on Electronic\n  Technology, Communication and Information (ICETCI)", "pdf_url": "http://arxiv.org/pdf/2507.20921v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20846", "title": "Precision spectral estimation at sub-Hz frequencies: closed-form posteriors and Bayesian noise projection", "authors": ["Lorenzo Sala", "Stefano Vitale"], "categories": ["astro-ph.IM", "eess.SP", "stat.AP"], "primary_category": "Subjects:       Instrumentation and Methods for Astrophysics (astro-ph.IM)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.20846v1", "summary": "We present a Bayesian method for estimating spectral quantities in\nmultivariate Gaussian time series. The approach, based on periodograms and\nWishart statistics, yields closed-form expressions at any given frequency for\nthe marginal posterior distributions of the individual power spectral\ndensities, the pairwise coherence, and the multiple coherence, as well as for\nthe joint posterior distribution of the full cross-spectral density matrix. In\nthe context of noise projection - where one series is modeled as a linear\ncombination of filtered versions of the others, plus a background component -\nthe method also provides closed-form posteriors for both the susceptibilities,\ni.e., the filter transfer functions, and the power spectral density of the\nbackground. Originally developed for the analysis of the data from the European\nSpace Agency's LISA Pathfinder mission, the method is particularly well-suited\nto very-low-frequency data, where long observation times preclude averaging\nover large sets of periodograms, which would otherwise allow these to be\ntreated as approximately normally distributed.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.20846v1", "cate": "astro-ph.IM", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2209.10675", "title": "A Validation Approach to Over-parameterized Matrix and Image Recovery", "authors": ["Lijun Ding", "Zhen Qin", "Liwei Jiang", "Jinxin Zhou", "Zhihui Zhu"], "categories": ["math.OC", "cs.LG", "eess.IV", "stat.ML"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      32 pages and 10 figures", "url": "http://arxiv.org/abs/2209.10675v3", "summary": "This paper studies the problem of recovering a low-rank matrix from several\nnoisy random linear measurements. We consider the setting where the rank of the\nground-truth matrix is unknown a priori and use an objective function built\nfrom a rank-overspecified factored representation of the matrix variable, where\nthe global optimal solutions overfit and do not correspond to the underlying\nground truth. We then solve the associated nonconvex problem using gradient\ndescent with small random initialization. We show that as long as the\nmeasurement operators satisfy the restricted isometry property (RIP) with its\nrank parameter scaling with the rank of the ground-truth matrix rather than\nscaling with the overspecified matrix rank, gradient descent iterations are on\na particular trajectory towards the ground-truth matrix and achieve nearly\ninformation-theoretically optimal recovery when it is stopped appropriately. We\nthen propose an efficient stopping strategy based on the common hold-out method\nand show that it detects a nearly optimal estimator provably. Moreover,\nexperiments show that the proposed validation approach can also be efficiently\nused for image restoration with deep image prior, which over-parameterizes an\nimage with a deep network.", "comment": "32 pages and 10 figures", "pdf_url": "http://arxiv.org/pdf/2209.10675v3", "cate": "math.OC", "date": "2022-09-21", "updated": "2025-07-25"}
{"id": "2503.04258", "title": "TAIL: Text-Audio Incremental Learning", "authors": ["Yingfei Sun", "Xu Gu", "Wei Ji", "Hanbin Zhao", "Yifang Yin", "Roger Zimmermann"], "categories": ["cs.SD", "cs.AI", "cs.CV", "eess.AS", "I.2"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      6 figures, 4 tables", "url": "http://arxiv.org/abs/2503.04258v2", "summary": "Many studies combine text and audio to capture multi-modal information but\nthey overlook the model's generalization ability on new datasets. Introducing\nnew datasets may affect the feature space of the original dataset, leading to\ncatastrophic forgetting. Meanwhile, large model parameters can significantly\nimpact training performance. To address these limitations, we introduce a novel\ntask called Text-Audio Incremental Learning (TAIL) task for text-audio\nretrieval, and propose a new method, PTAT, Prompt Tuning for Audio-Text\nincremental learning. This method utilizes prompt tuning to optimize the model\nparameters while incorporating an audio-text similarity and feature\ndistillation module to effectively mitigate catastrophic forgetting. We\nbenchmark our method and previous incremental learning methods on AudioCaps,\nClotho, BBC Sound Effects and Audioset datasets, and our method outperforms\nprevious methods significantly, particularly demonstrating stronger resistance\nto forgetting on older datasets. Compared to the full-parameters Finetune\n(Sequential) method, our model only requires 2.42\\% of its parameters,\nachieving 4.46\\% higher performance.", "comment": "6 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2503.04258v2", "cate": "cs.SD", "date": "2025-03-06", "updated": "2025-07-28"}
{"id": "1807.07189", "title": "A Tale of Santa Claus, Hypergraphs and Matroids", "authors": ["Sami Davies", "Thomas Rothvoss", "Yihao Zhang"], "categories": ["cs.DS", "cs.DM"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/1807.07189v3", "summary": "A well-known problem in scheduling and approximation algorithms is the Santa\nClaus problem. Suppose that Santa Claus has a set of gifts, and he wants to\ndistribute them among a set of children so that the least happy child is made\nas happy as possible. Here, the value that a child $i$ has for a present $j$ is\nof the form $p_{ij} \\in \\{ 0,p_j\\}$. A polynomial time algorithm by Annamalai\net al. gives a $12.33$-approximation and is based on a modification of Haxell's\nhypergraph matching argument.\n  In this paper, we introduce a matroid version of the Santa Claus problem. Our\nalgorithm is also based on Haxell's augmenting tree, but with the introduction\nof the matroid structure we solve a more general problem with cleaner methods.\nOur result can then be used as a blackbox to obtain a\n$(6+\\varepsilon)$-approximation for Santa Claus. This factor also compares\nagainst a natural, compact LP for Santa Claus.", "comment": null, "pdf_url": "http://arxiv.org/pdf/1807.07189v3", "cate": "cs.DS", "date": "2018-07-19", "updated": "2025-07-27"}
{"id": "2507.21686", "title": "Solving Boundary Handling Analytically in Two Dimensions for Smoothed Particle Hydrodynamics", "authors": ["Rene Winchenbach", "Andreas Kolb"], "categories": ["math.NA", "cs.GR", "cs.NA", "G.1.0; I.6.0; I.3.5"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21686v1", "summary": "We present a fully analytic approach for evaluating boundary integrals in two\ndimensions for Smoothed Particle Hydrodynamics (SPH). Conventional methods\noften rely on boundary particles or wall re-normalization approaches derived\nfrom applying the divergence theorem, whereas our method directly evaluates the\narea integrals for SPH kernels and gradients over triangular boundaries. This\ndirect integration strategy inherently accommodates higher-order boundary\nconditions, such as piecewise cubic fields defined via Finite Element stencils,\nenabling analytic and flexible coupling with mesh-based solvers. At the core of\nour approach is a general solution for compact polynomials of arbitrary degree\nover triangles by decomposing the boundary elements into elementary integrals\nthat can be solved with closed-form solutions. We provide a complete,\nclosed-form solution for these generalized integrals, derived by relating the\nangular components to Chebyshev polynomials and solving the resulting radial\nintegral via a numerically stable evaluation of the Gaussian hypergeometric\nfunction $_2F_1$. Our solution is robust and adaptable and works regardless of\ntriangle geometries and kernel functions. We validate the accuracy against\nhigh-precision numerical quadrature rules, as well as in problems with known\nexact solutions. We provide an open-source implementation of our general\nsolution using differentiable programming to facilitate the adoption of our\napproach to SPH and other contexts that require analytic integration over\npolygonal domains. Our analytic solution outperforms existing numerical\nquadrature rules for this problem by up to five orders of magnitude, for\nintegrals and their gradients, while providing a flexible framework to couple\narbitrary triangular meshes analytically to Lagrangian schemes, building a\nstrong foundation for addressing several grand challenges in SPH and beyond.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21686v1", "cate": "math.NA", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21114", "title": "Page image classification for content-specific data processing", "authors": ["Kateryna Lutsai", "Pavel Straňák"], "categories": ["cs.IR", "cs.AI", "cs.CV", "68T10, 68T09, 62H30", "I.7.5; H.3.7"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      65 pages, 57 figures, 20 tables", "url": "http://arxiv.org/abs/2507.21114v1", "summary": "Digitization projects in humanities often generate vast quantities of page\nimages from historical documents, presenting significant challenges for manual\nsorting and analysis. These archives contain diverse content, including various\ntext types (handwritten, typed, printed), graphical elements (drawings, maps,\nphotos), and layouts (plain text, tables, forms). Efficiently processing this\nheterogeneous data requires automated methods to categorize pages based on\ntheir content, enabling tailored downstream analysis pipelines. This project\naddresses this need by developing and evaluating an image classification system\nspecifically designed for historical document pages, leveraging advancements in\nartificial intelligence and machine learning. The set of categories was chosen\nto facilitate content-specific processing workflows, separating pages requiring\ndifferent analysis techniques (e.g., OCR for text, image analysis for graphics)", "comment": "65 pages, 57 figures, 20 tables", "pdf_url": "http://arxiv.org/pdf/2507.21114v1", "cate": "cs.IR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.00351", "title": "Recasting Classical Motion Planning for Contact-Rich Manipulation", "authors": ["Lin Yang", "Huu-Thiet Nguyen", "Chen Lv", "Domenico Campolo"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.00351v2", "summary": "In this work, we explore how conventional motion planning algorithms can be\nreapplied to contact-rich manipulation tasks. Rather than focusing solely on\nefficiency, we investigate how manipulation aspects can be recast in terms of\nconventional motion-planning algorithms. Conventional motion planners, such as\nRapidly-Exploring Random Trees (RRT), typically compute collision-free paths in\nconfiguration space. However, in many manipulation tasks, contact is either\nunavoidable or essential for task success, such as for creating space or\nmaintaining physical equilibrium. As such, we presents Haptic Rapidly-Exploring\nRandom Trees (HapticRRT), a planning algorithm that incorporates a recently\nproposed optimality measure in the context of \\textit{quasi-static}\nmanipulation, based on the (squared) Hessian of manipulation potential. The key\ncontributions are i) adapting classical RRT to operate on the quasi-static\nequilibrium manifold, while deepening the interpretation of haptic obstacles\nand metrics; ii) discovering multiple manipulation strategies, corresponding to\nbranches of the equilibrium manifold. iii) validating the generality of our\nmethod across three diverse manipulation tasks, each requiring only a single\nmanipulation potential expression. The video can be found at\nhttps://youtu.be/R8aBCnCCL40.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.00351v2", "cate": "cs.RO", "date": "2025-05-31", "updated": "2025-07-27"}
{"id": "2507.19961", "title": "Pic2Diagnosis: A Method for Diagnosis of Cardiovascular Diseases from the Printed ECG Pictures", "authors": ["Oğuzhan Büyüksolak", "İlkay Öksüz"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      To appear in: Proceedings of the 47th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), 2025", "url": "http://arxiv.org/abs/2507.19961v1", "summary": "The electrocardiogram (ECG) is a vital tool for diagnosing heart diseases.\nHowever, many disease patterns are derived from outdated datasets and\ntraditional stepwise algorithms with limited accuracy. This study presents a\nmethod for direct cardiovascular disease (CVD) diagnosis from ECG images,\neliminating the need for digitization. The proposed approach utilizes a\ntwo-step curriculum learning framework, beginning with the pre-training of a\nclassification model on segmentation masks, followed by fine-tuning on\ngrayscale, inverted ECG images. Robustness is further enhanced through an\nensemble of three models with averaged outputs, achieving an AUC of 0.9534 and\nan F1 score of 0.7801 on the BHF ECG Challenge dataset, outperforming\nindividual models. By effectively handling real-world artifacts and simplifying\nthe diagnostic process, this method offers a reliable solution for automated\nCVD diagnosis, particularly in resource-limited settings where printed or\nscanned ECG images are commonly used. Such an automated procedure enables rapid\nand accurate diagnosis, which is critical for timely intervention in CVD cases\nthat often demand urgent care.", "comment": "To appear in: Proceedings of the 47th Annual International Conference\n  of the IEEE Engineering in Medicine and Biology Society (EMBC), 2025", "pdf_url": "http://arxiv.org/pdf/2507.19961v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20191", "title": "Partial Domain Adaptation via Importance Sampling-based Shift Correction", "authors": ["Cheng-Jun Guo", "Chuan-Xian Ren", "You-Wei Luo", "Xiao-Lin Xu", "Hong Yan"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20191v1", "summary": "Partial domain adaptation (PDA) is a challenging task in real-world machine\nlearning scenarios. It aims to transfer knowledge from a labeled source domain\nto a related unlabeled target domain, where the support set of the source label\ndistribution subsumes the target one. Previous PDA works managed to correct the\nlabel distribution shift by weighting samples in the source domain. However,\nthe simple reweighing technique cannot explore the latent structure and\nsufficiently use the labeled data, and then models are prone to over-fitting on\nthe source domain. In this work, we propose a novel importance sampling-based\nshift correction (IS$^2$C) method, where new labeled data are sampled from a\nbuilt sampling domain, whose label distribution is supposed to be the same as\nthe target domain, to characterize the latent structure and enhance the\ngeneralization ability of the model. We provide theoretical guarantees for\nIS$^2$C by proving that the generalization error can be sufficiently dominated\nby IS$^2$C. In particular, by implementing sampling with the mixture\ndistribution, the extent of shift between source and sampling domains can be\nconnected to generalization error, which provides an interpretable way to build\nIS$^2$C. To improve knowledge transfer, an optimal transport-based independence\ncriterion is proposed for conditional distribution alignment, where the\ncomputation of the criterion can be adjusted to reduce the complexity from\n$\\mathcal{O}(n^3)$ to $\\mathcal{O}(n^2)$ in realistic PDA scenarios. Extensive\nexperiments on PDA benchmarks validate the theoretical results and demonstrate\nthe effectiveness of our IS$^2$C over existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20191v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20974", "title": "A lightweight numerical model for predictive control of borehole thermal energy storages", "authors": ["Johannes van Randenborgh", "Steffen Daniel", "Moritz Schulze Darup"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20974v1", "summary": "Borehole thermal energy storage (BTES) can reduce the operation of fossil\nfuel-based heating, ventilation, and air conditioning systems for buildings.\nWith BTES, thermal energy is stored via a borehole heat exchanger in the\nground. Model predictive control (MPC) may maximize the use of BTES by\nachieving a dynamic interaction between the building and BTES. However,\nmodeling BTES for MPC is challenging, and a trade-off between model accuracy\nand an easy-to-solve optimal control problem (OCP) must be found. This\nmanuscript presents an accurate numerical model yielding an easy-to-solve\nlinear-quadratic OCP.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20974v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21023", "title": "On Using the Shapley Value for Anomaly Localization: A Statistical Investigation", "authors": ["Rick S. Blum", "Franziska Freytag"], "categories": ["cs.LG", "eess.SP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21023v1", "summary": "Recent publications have suggested using the Shapley value for anomaly\nlocalization for sensor data systems. Using a reasonable mathematical anomaly\nmodel for full control, experiments indicate that using a single fixed term in\nthe Shapley value calculation achieves a lower complexity anomaly localization\ntest, with the same probability of error, as a test using the Shapley value for\nall cases tested. A proof demonstrates these conclusions must be true for all\nindependent observation cases. For dependent observation cases, no proof is\navailable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21023v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2505.14730", "title": "Predicting Neoadjuvant Chemotherapy Response in Triple-Negative Breast Cancer Using Pre-Treatment Histopathologic Images", "authors": ["Hikmat Khan", "Ziyu Su", "Huina Zhang", "Yihong Wang", "Bohan Ning", "Shi Wei", "Hua Guo", "Zaibo Li", "Muhammad Khalid Khan Niazi"], "categories": ["q-bio.QM", "cs.CV", "eess.IV"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.14730v2", "summary": "Triple-negative breast cancer (TNBC) remains a major clinical challenge due\nto its aggressive behavior and lack of targeted therapies. Accurate early\nprediction of response to neoadjuvant chemotherapy (NACT) is essential for\nguiding personalized treatment strategies and improving patient outcomes. In\nthis study, we present an attention-based multiple instance learning (MIL)\nframework designed to predict pathologic complete response (pCR) directly from\npre-treatment hematoxylin and eosin (H&E)-stained biopsy slides. The model was\ntrained on a retrospective in-house cohort of 174 TNBC patients and externally\nvalidated on an independent cohort (n = 30). It achieved a mean area under the\ncurve (AUC) of 0.85 during five-fold cross-validation and 0.78 on external\ntesting, demonstrating robust predictive performance and generalizability. To\nenhance model interpretability, attention maps were spatially co-registered\nwith multiplex immuno-histochemistry (mIHC) data stained for PD-L1, CD8+ T\ncells, and CD163+ macrophages. The attention regions exhibited moderate spatial\noverlap with immune-enriched areas, with mean Intersection over Union (IoU)\nscores of 0.47 for PD-L1, 0.45 for CD8+ T cells, and 0.46 for CD163+\nmacrophages. The presence of these biomarkers in high-attention regions\nsupports their biological relevance to NACT response in TNBC. This not only\nimproves model interpretability but may also inform future efforts to identify\nclinically actionable histological biomarkers directly from H&E-stained biopsy\nslides, further supporting the utility of this approach for accurate NACT\nresponse prediction and advancing precision oncology in TNBC.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.14730v2", "cate": "q-bio.QM", "date": "2025-05-20", "updated": "2025-07-26"}
{"id": "2504.02398", "title": "Scaling Analysis of Interleaved Speech-Text Language Models", "authors": ["Gallil Maimon", "Michael Hassid", "Amit Roth", "Yossi Adi"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at COLM 2025", "url": "http://arxiv.org/abs/2504.02398v2", "summary": "Existing Speech Language Model (SLM) scaling analysis paints a bleak picture.\nIt predicts that SLMs require much more compute and data compared to text,\nleading some to question the feasibility of training high-quality SLMs.\nHowever, modern SLMs are often initialised from pre-trained TextLMs using\nspeech-text interleaving to allow knowledge transfer. This raises the question\n- \"Do interleaved SLMs scale more efficiently than textless-SLMs?\" In this\npaper we answer a resounding yes! We conduct scaling analysis of interleaved\nSLMs by training several dozen and analysing the scaling trends. We see that\nunder this setup SLMs scale more efficiently with compute. Additionally, our\nresults indicate that the scaling dynamics significantly differ from\ntextless-SLMs, suggesting one should allocate notably more of the compute\nbudget to increasing model size over training tokens. We also study the role of\nsynthetic data and TextLM model families in unlocking this potential. Results\nsuggest that our scaled up model achieves comparable semantic speech\nperformance to leading models, while using less compute and data. We open\nsource models, samples, and data -\nhttps://pages.cs.huji.ac.il/adiyoss-lab/sims/ .", "comment": "Accepted at COLM 2025", "pdf_url": "http://arxiv.org/pdf/2504.02398v2", "cate": "cs.CL", "date": "2025-04-03", "updated": "2025-07-27"}
{"id": "2504.17887", "title": "Searching in trees with k-up-modular weight functions", "authors": ["Michał Szyfelbein"], "categories": ["cs.DS", "cs.DM", "G.2.2"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      14 pages, 5 figures", "url": "http://arxiv.org/abs/2504.17887v2", "summary": "We consider the following generalization of the binary search problem: A\nsearcher is required to find a hidden element $x$ in a tree $T$. To do so, they\niteratively perform queries to an oracle about a chosen vertex $v$. After each\nsuch call, the oracle responds whether the target was found and if not, the\nsearcher receives as a reply the neighbor of $v$ that lays on the shortest path\ntowards $x$. Additionally, each vertex $v$ may have a different query cost\n$w(v)$. The goal is to find the optimal querying strategy for the searcher\nwhich minimizes the worst case query cost required to find $x$. The problem is\nknown to be NP-hard even in restricted classes of trees such as bounded\ndiameter spiders [Cicalese et al. 2016] and no constant factor approximation\nalgorithm is known for the general case. Inspired by recent studies\n[Dereniowski et al. 2022, Dereniowski et al. 2024], instead of restricted\nclasses of trees, we explore restrictions on the weight function. We introduce\nthe concept of a heavy group set of a vertex $HG(v,w)$. We show that if for\nevery $v\\in T$: $|HG\\br{v,w}|\\leq k$ an $O(\\log\\log n)$-approximation can be\nfound within $2^{O(\\log^2k)}\\cdot\\text{poly}(n)$ time.", "comment": "14 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2504.17887v2", "cate": "cs.DS", "date": "2025-04-24", "updated": "2025-07-27"}
{"id": "2503.09631", "title": "V2M4: 4D Mesh Animation Reconstruction from a Single Monocular Video", "authors": ["Jianqi Chen", "Biao Zhang", "Xiangjun Tang", "Peter Wonka"], "categories": ["cs.GR", "eess.IV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025. Project page: this https URL", "url": "http://arxiv.org/abs/2503.09631v2", "summary": "We present V2M4, a novel 4D reconstruction method that directly generates a\nusable 4D mesh animation asset from a single monocular video. Unlike existing\napproaches that rely on priors from multi-view image and video generation\nmodels, our method is based on native 3D mesh generation models. Naively\napplying 3D mesh generation models to generate a mesh for each frame in a 4D\ntask can lead to issues such as incorrect mesh poses, misalignment of mesh\nappearance, and inconsistencies in mesh geometry and texture maps. To address\nthese problems, we propose a structured workflow that includes camera search\nand mesh reposing, condition embedding optimization for mesh appearance\nrefinement, pairwise mesh registration for topology consistency, and global\ntexture map optimization for texture consistency. Our method outputs\nhigh-quality 4D animated assets that are compatible with mainstream graphics\nand game software. Experimental results across a variety of animation types and\nmotion amplitudes demonstrate the generalization and effectiveness of our\nmethod. Project page: https://windvchen.github.io/V2M4/.", "comment": "Accepted by ICCV 2025. Project page:\n  https://windvchen.github.io/V2M4/", "pdf_url": "http://arxiv.org/pdf/2503.09631v2", "cate": "cs.GR", "date": "2025-03-11", "updated": "2025-07-29"}
{"id": "2507.21115", "title": "FedFlex: Federated Learning for Diverse Netflix Recommendations", "authors": ["Sven Lankester", "Manel Slokom", "Gustavo de Carvalho Bertoli", "Matias Vizcaino", "Emmanuelle Beauxis Aussalet", "Laura Hollink"], "categories": ["cs.IR", "cs.AI", "cs.DC", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21115v1", "summary": "Federated learning is a decentralized approach that enables collaborative\nmodel training across multiple devices while preserving data privacy. It has\nshown significant potential in various domains, including healthcare and\npersonalized recommendation systems. However, most existing work on federated\nrecommendation systems has focused primarily on improving accuracy, with\nlimited attention to fairness and diversity. In this paper, we introduce\nFedFlex, a federated recommender system for Netflix-style TV series\nrecommendations. FedFlex integrates two state-of-the-art matrix factorization\nalgorithms for personalized fine-tuning. FedFlex also applies Maximal Marginal\nRelevance (MMR) to re-rank items and enhance diversity. We conduct extensive\nexperiments comparing recommendations generated by SVD and BPR algorithms. In a\nlive two-week user study, participants received two recommendation lists: List\nA, based on SVD or BPR, and List B, a re-ranked version emphasizing diversity.\nParticipants were asked to click on the movies they were interested in\nwatching. Our findings demonstrate that FedFlex effectively introduces diverse\ncontent, such as new genres, into recommendations without necessarily\ncompromising user satisfaction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21115v1", "cate": "cs.IR", "date": "2025-07-15", "updated": "2025-07-15"}
{"id": "2506.15249", "title": "Context-Aware Deep Lagrangian Networks for Model Predictive Control", "authors": ["Lucas Schulze", "Jan Peters", "Oleg Arenz"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025)", "url": "http://arxiv.org/abs/2506.15249v3", "summary": "Controlling a robot based on physics-consistent dynamic models, such as Deep\nLagrangian Networks (DeLaN), can improve the generalizability and\ninterpretability of the resulting behavior. However, in complex environments,\nthe number of objects to potentially interact with is vast, and their physical\nproperties are often uncertain. This complexity makes it infeasible to employ a\nsingle global model. Therefore, we need to resort to online system\nidentification of context-aware models that capture only the currently relevant\naspects of the environment. While physical principles such as the conservation\nof energy may not hold across varying contexts, ensuring physical plausibility\nfor any individual context-aware model can still be highly desirable,\nparticularly when using it for receding horizon control methods such as model\npredictive control (MPC). Hence, in this work, we extend DeLaN to make it\ncontext-aware, combine it with a recurrent network for online system\nidentification, and integrate it with an MPC for adaptive, physics-consistent\ncontrol. We also combine DeLaN with a residual dynamics model to leverage the\nfact that a nominal model of the robot is typically available. We evaluate our\nmethod on a 7-DOF robot arm for trajectory tracking under varying loads. Our\nmethod reduces the end-effector tracking error by 39%, compared to a 21%\nimprovement achieved by a baseline that uses an extended Kalman filter.", "comment": "Accepted to the 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025)", "pdf_url": "http://arxiv.org/pdf/2506.15249v3", "cate": "cs.RO", "date": "2025-06-18", "updated": "2025-07-27"}
{"id": "2507.19990", "title": "Improving the Performance of Sequential Recommendation Systems with an Extended Large Language Model", "authors": ["Sinnyum Choi", "Woong Kim"], "categories": ["cs.IR", "cs.AI", "cs.CL", "H.3.3; I.2.6; I.2.7"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19990v1", "summary": "Recently, competition in the field of artificial intelligence (AI) has\nintensified among major technological companies, resulting in the continuous\nrelease of new large-language models (LLMs) that exhibit improved language\nunderstanding and context-based reasoning capabilities. It is expected that\nthese advances will enable more efficient personalized recommendations in\nLLM-based recommendation systems through improved quality of training data and\narchitectural design. However, many studies have not considered these recent\ndevelopments. In this study, it was proposed to improve LLM-based\nrecommendation systems by replacing Llama2 with Llama3 in the LlamaRec\nframework. To ensure a fair comparison, random seed values were set and\nidentical input data was provided during preprocessing and training. The\nexperimental results show average performance improvements of 38.65\\%, 8.69\\%,\nand 8.19\\% for the ML-100K, Beauty, and Games datasets, respectively, thus\nconfirming the practicality of this method. Notably, the significant\nimprovements achieved by model replacement indicate that the recommendation\nquality can be improved cost-effectively without the need to make structural\nchanges to the system. Based on these results, it is our contention that the\nproposed approach is a viable solution for improving the performance of current\nrecommendation systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19990v1", "cate": "cs.IR", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20202", "title": "Technical Indicator Networks (TINs): An Interpretable Neural Architecture Modernizing Classic al Technical Analysis for Adaptive Algorithmic Trading", "authors": ["Longfei Lu"], "categories": ["cs.LG", "q-fin.PM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Patent Application No. DE10202502351 filed on July 8, 2025 with DPMA", "url": "http://arxiv.org/abs/2507.20202v1", "summary": "This work proposes that a vast majority of classical technical indicators in\nfinancial analysis are, in essence, special cases of neural networks with fixed\nand interpretable weights. It is shown that nearly all such indicators, such as\nmoving averages, momentum-based oscillators, volatility bands, and other\ncommonly used technical constructs, can be reconstructed topologically as\nmodular neural network components. Technical Indicator Networks (TINs) are\nintroduced as a general neural architecture that replicates and structurally\nupgrades traditional indicators by supporting n-dimensional inputs such as\nprice, volume, sentiment, and order book data. By encoding domain-specific\nknowledge into neural structures, TINs modernize the foundational logic of\ntechnical analysis and propel algorithmic trading into a new era, bridging the\nlegacy of proven indicators with the potential of contemporary AI systems.", "comment": "Patent Application No. DE10202502351 filed on July 8, 2025 with DPMA", "pdf_url": "http://arxiv.org/pdf/2507.20202v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.19620", "title": "Long-Duration Station-Keeping Strategy for Cislunar Spacecraft Formations", "authors": ["Ethan Foss", "Yuji Takubo", "Simone D'Amico"], "categories": ["math.OC", "cs.SY", "eess.SY", "math.DS"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19620v1", "summary": "This paper demonstrates a novel guidance and control strategy for cislunar\nnear-rectilinear halo orbit formation-keeping applied to high-fidelity\ndynamics. Bounded relative motion is constructed about long-duration ephemeris\ntrajectories with osculating invariant circles to form quasi-periodic relative\norbits. State-of-the-art absolute control strategies are paired with a simple\nand effective relative control feedback law. Finally, a control barrier\nfunction is implemented to ensure recursively passively-safe bounded relative\nmotion under feedback in the presence of possible missed maneuver events for\nthe duration of the formation flight. The strategy is verified in high-fidelity\nsimulation environments through Monte Carlo trials.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19620v1", "cate": "math.OC", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2312.09450", "title": "Performance-Based Optimization of 2D Reinforced Concrete Moment Frames through Pushover Analysis and ABC Optimization Algorithm", "authors": ["Saba Faghirnejad"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Published in Earthquakes and Structures, Vol. 27(4), 2024", "url": "http://arxiv.org/abs/2312.09450v2", "summary": "Conducting nonlinear pushover analysis typically demands intricate and\nresource-intensive computational attempts, and involves a process that is\nhighly iterative and necessary for satisfying design-defined and also\nrequirements of codes in performance-based design. A computer-based technique\nis presented for reinforced concrete (RC) buildings in this study,\nincorporating optimization numerical approaches, techniques of optimality\ncriteria and pushover analysis to seismic design automatically the pushover\ndrift performance. The optimal design based on the performance of concrete\nbeams, columns and shear walls in concrete moment frames is presented using the\nartificial bee colony optimization algorithm. The design is applied to three\nframes such as a 4-story, an 8-story and a 12-story. These structures are\ndesigned to minimize the overall weight while satisfying the levels of\nperformance include Life Safety (L-S), Collapse Prevention (C-P), and Immediate\nOccupancy (I-O). To achieve this goal, three main steps are performed. In the\nfirst step, optimization codes are implemented in MATLAB software, and the\nOpenSees software is used for nonlinear static analysis of the structure. By\nsolving the optimization problem, several top designs are obtained for each\nframe and shear wall. Pushover analysis is performed considering the\nconstraints of relative displacement and plastic hinge rotation based on the\nnonlinear provisions of FEMA356 code to achieve each levels of performance.\nFollowing this, convergence, pushover, and drift history curves are plotted for\neach frame, and selecting the best design for each frame ultimately occurs. The\nresults demonstrate the algorithm's performance is desirable for the structure\nto achieve selecting the best design and lower weight.", "comment": "Published in Earthquakes and Structures, Vol. 27(4), 2024", "pdf_url": "http://arxiv.org/pdf/2312.09450v2", "cate": "eess.SP", "date": "2023-12-04", "updated": "2025-07-26"}
{"id": "2505.16025", "title": "CP-LLM: Context and Pixel Aware Large Language Model for Video Quality Assessment", "authors": ["Wen Wen", "Yaohong Wu", "Yue Sheng", "Neil Birkbeck", "Balu Adsumilli", "Yilin Wang"], "categories": ["cs.CV", "cs.MM", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Under review", "url": "http://arxiv.org/abs/2505.16025v2", "summary": "Video quality assessment (VQA) is a challenging research topic with broad\napplications. Effective VQA necessitates sensitivity to pixel-level distortions\nand a comprehensive understanding of video context to accurately determine the\nperceptual impact of distortions. Traditional hand-crafted and learning-based\nVQA models mainly focus on pixel-level distortions and lack contextual\nunderstanding, while recent LLM-based models struggle with sensitivity to small\ndistortions or handle quality scoring and description as separate tasks. To\naddress these shortcomings, we introduce CP-LLM: a Context and Pixel aware\nLarge Language Model. CP-LLM is a novel multimodal LLM architecture featuring\ndual vision encoders designed to independently analyze perceptual quality at\nboth high-level (video context) and low-level (pixel distortion) granularity,\nalong with a language decoder subsequently reasons about the interplay between\nthese aspects. This design enables CP-LLM to simultaneously produce robust\nquality scores and interpretable quality descriptions, with enhanced\nsensitivity to pixel distortions (e.g. compression artifacts). The model is\ntrained via a multi-task pipeline optimizing for score prediction, description\ngeneration, and pairwise comparisons. Experiment results demonstrate that\nCP-LLM achieves state-of-the-art cross-dataset performance on established VQA\nbenchmarks and superior robustness to pixel distortions, confirming its\nefficacy for comprehensive and practical video quality assessment in real-world\nscenarios.", "comment": "Under review", "pdf_url": "http://arxiv.org/pdf/2505.16025v2", "cate": "cs.CV", "date": "2025-05-21", "updated": "2025-07-27"}
{"id": "2505.14351", "title": "FMSD-TTS: Few-shot Multi-Speaker Multi-Dialect Text-to-Speech Synthesis for Ü-Tsang, Amdo and Kham Speech Dataset Generation", "authors": ["Yutong Liu", "Ziyue Zhang", "Ban Ma-bao", "Yuqing Cai", "Yongbin Yu", "Renzeng Duojie", "Xiangxiang Wang", "Fan Gao", "Cheng Huang", "Nyima Tashi"], "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      15 pages", "url": "http://arxiv.org/abs/2505.14351v2", "summary": "Tibetan is a low-resource language with minimal parallel speech corpora\nspanning its three major dialects-\\\"U-Tsang, Amdo, and Kham-limiting progress\nin speech modeling. To address this issue, we propose FMSD-TTS, a few-shot,\nmulti-speaker, multi-dialect text-to-speech framework that synthesizes parallel\ndialectal speech from limited reference audio and explicit dialect labels. Our\nmethod features a novel speaker-dialect fusion module and a Dialect-Specialized\nDynamic Routing Network (DSDR-Net) to capture fine-grained acoustic and\nlinguistic variations across dialects while preserving speaker identity.\nExtensive objective and subjective evaluations demonstrate that FMSD-TTS\nsignificantly outperforms baselines in both dialectal expressiveness and\nspeaker similarity. We further validate the quality and utility of the\nsynthesized speech through a challenging speech-to-speech dialect conversion\ntask. Our contributions include: (1) a novel few-shot TTS system tailored for\nTibetan multi-dialect speech synthesis, (2) the public release of a large-scale\nsynthetic Tibetan speech corpus generated by FMSD-TTS, and (3) an open-source\nevaluation toolkit for standardized assessment of speaker similarity, dialect\nconsistency, and audio quality.", "comment": "15 pages", "pdf_url": "http://arxiv.org/pdf/2505.14351v2", "cate": "cs.SD", "date": "2025-05-20", "updated": "2025-07-27"}
{"id": "2504.17918", "title": "PHast -- Perfect Hashing made fast", "authors": ["Piotr Beling", "Peter Sanders"], "categories": ["cs.DS", "cs.DB", "cs.PF"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      A new variant called PHast+ has been added and the title has been changed. Previous title: PHast - Perfect Hashing with fast evaluation", "url": "http://arxiv.org/abs/2504.17918v4", "summary": "Perfect hash functions give unique \"names\" to arbitrary keys requiring only a\nfew bits per key. This is an essential building block in applications like\nstatic hash tables, databases, or bioinformatics. This paper introduces the\nPHast approach that combines the fastest available queries, very fast\nconstruction, and good space consumption (below 2 bits per key). PHast improves\nbucket-placement which first hashes each key k to a bucket, and then looks for\nthe bucket seed s such that a placement function maps pairs (s,k) in a\ncollision-free way. PHast can use small-range hash functions with linear\nmapping, fixed-width encoding of seeds, and parallel construction. This is\nachieved using small overlapping slices of allowed values and bumping to handle\nunsuccessful seed assignment. A variant we called PHast+ uses additive\nplacement, which enables bit-parallel seed searching, speeding up the\nconstruction by an order of magnitude.", "comment": "A new variant called PHast+ has been added and the title has been\n  changed. Previous title: PHast - Perfect Hashing with fast evaluation", "pdf_url": "http://arxiv.org/pdf/2504.17918v4", "cate": "cs.DS", "date": "2025-04-24", "updated": "2025-07-26"}
{"id": "2504.06385", "title": "Fast Globally Optimal and Geometrically Consistent 3D Shape Matching", "authors": ["Paul Roetzer", "Florian Bernard"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      8 pages main paper, 9 pages supplementary", "url": "http://arxiv.org/abs/2504.06385v3", "summary": "Geometric consistency, i.e. the preservation of neighbourhoods, is a natural\nand strong prior in 3D shape matching. Geometrically consistent matchings are\ncrucial for many downstream applications, such as texture transfer or\nstatistical shape modelling. Yet, in practice, geometric consistency is often\noverlooked, or only achieved under severely limiting assumptions (e.g. a good\ninitialisation). In this work, we propose a novel formalism for computing\nglobally optimal and geometrically consistent matchings between 3D shapes which\nis scalable in practice. Our key idea is to represent the surface of the source\nshape as a collection of cyclic paths, which are then consistently matched to\nthe target shape. Mathematically, we construct a hyper product graph (between\nsource and target shape), and then cast 3D shape matching as a minimum-cost\ncirculation flow problem in this hyper graph, which yields global geometrically\nconsistent matchings between both shapes. We empirically show that our\nformalism is efficiently solvable and that it leads to high-quality results.", "comment": "8 pages main paper, 9 pages supplementary", "pdf_url": "http://arxiv.org/pdf/2504.06385v3", "cate": "cs.GR", "date": "2025-04-08", "updated": "2025-07-29"}
{"id": "2507.21117", "title": "A Comprehensive Review on Harnessing Large Language Models to Overcome Recommender System Challenges", "authors": ["Rahul Raja", "Anshaj Vats", "Arpita Vats", "Anirban Majumder"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21117v1", "summary": "Recommender systems have traditionally followed modular architectures\ncomprising candidate generation, multi-stage ranking, and re-ranking, each\ntrained separately with supervised objectives and hand-engineered features.\nWhile effective in many domains, such systems face persistent challenges\nincluding sparse and noisy interaction data, cold-start problems, limited\npersonalization depth, and inadequate semantic understanding of user and item\ncontent. The recent emergence of Large Language Models (LLMs) offers a new\nparadigm for addressing these limitations through unified, language-native\nmechanisms that can generalize across tasks, domains, and modalities. In this\npaper, we present a comprehensive technical survey of how LLMs can be leveraged\nto tackle key challenges in modern recommender systems. We examine the use of\nLLMs for prompt-driven candidate retrieval, language-native ranking,\nretrieval-augmented generation (RAG), and conversational recommendation,\nillustrating how these approaches enhance personalization, semantic alignment,\nand interpretability without requiring extensive task-specific supervision.\nLLMs further enable zero- and few-shot reasoning, allowing systems to operate\neffectively in cold-start and long-tail scenarios by leveraging external\nknowledge and contextual cues. We categorize these emerging LLM-driven\narchitectures and analyze their effectiveness in mitigating core bottlenecks of\nconventional pipelines. In doing so, we provide a structured framework for\nunderstanding the design space of LLM-enhanced recommenders, and outline the\ntrade-offs between accuracy, scalability, and real-time performance. Our goal\nis to demonstrate that LLMs are not merely auxiliary components but\nfoundational enablers for building more adaptive, semantically rich, and\nuser-centric recommender systems", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21117v1", "cate": "cs.IR", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.21269", "title": "Numerical PDE solvers outperform neural PDE solvers", "authors": ["Patrick Chatain", "Michael Rizvi-Martel", "Guillaume Rabusseau", "Adam Oberman"], "categories": ["math.NA", "cs.LG", "cs.NA", "35R30 (Primary) 65M06 65M32 65C20 68T07 (Secondary)"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      17 pages, 7 figures", "url": "http://arxiv.org/abs/2507.21269v1", "summary": "We present DeepFDM, a differentiable finite-difference framework for learning\nspatially varying coefficients in time-dependent partial differential equations\n(PDEs). By embedding a classical forward-Euler discretization into a\nconvolutional architecture, DeepFDM enforces stability and first-order\nconvergence via CFL-compliant coefficient parameterizations. Model weights\ncorrespond directly to PDE coefficients, yielding an interpretable\ninverse-problem formulation. We evaluate DeepFDM on a benchmark suite of scalar\nPDEs: advection, diffusion, advection-diffusion, reaction-diffusion and\ninhomogeneous Burgers' equations-in one, two and three spatial dimensions. In\nboth in-distribution and out-of-distribution tests (quantified by the Hellinger\ndistance between coefficient priors), DeepFDM attains normalized mean-squared\nerrors one to two orders of magnitude smaller than Fourier Neural Operators,\nU-Nets and ResNets; requires 10-20X fewer training epochs; and uses 5-50X fewer\nparameters. Moreover, recovered coefficient fields accurately match\nground-truth parameters. These results establish DeepFDM as a robust,\nefficient, and transparent baseline for data-driven solution and identification\nof parametric PDEs.", "comment": "17 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.21269v1", "cate": "math.NA", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2506.18016", "title": "ADA-DPM: A Neural Descriptors-based Adaptive Noise Filtering Strategy for SLAM", "authors": ["Yongxin Shao", "Aihong Tan", "Binrui Wang", "Yinlian Jin", "Licong Guan", "Peng Liao"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.18016v2", "summary": "Lidar SLAM plays a significant role in mobile robot navigation and\nhigh-definition map construction. However, existing methods often face a\ntrade-off between localization accuracy and system robustness in scenarios with\na high proportion of dynamic objects, point cloud distortion, and unstructured\nenvironments. To address this issue, we propose a neural descriptors-based\nadaptive noise filtering strategy for SLAM, named ADA-DPM, which improves the\nperformance of localization and mapping tasks through three key technical\ninnovations. Firstly, to tackle dynamic object interference, we design the\nDynamic Segmentation Head to predict and filter out dynamic feature points,\neliminating the ego-motion interference caused by dynamic objects. Secondly, to\nmitigate the impact of noise and unstructured feature points, we propose the\nGlobal Importance Scoring Head that adaptively selects high-contribution\nfeature points while suppressing the influence of noise and unstructured\nfeature points. Moreover, we introduce the Cross-Layer Graph Convolution Module\n(GLI-GCN) to construct multi-scale neighborhood graphs, fusing local structural\ninformation across different scales and improving the discriminative power of\noverlapping features. Finally, experimental validations on multiple public\ndatasets confirm the effectiveness of ADA-DPM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.18016v2", "cate": "cs.RO", "date": "2025-06-22", "updated": "2025-07-27"}
{"id": "2507.19992", "title": "NIRS: An Ontology for Non-Invasive Respiratory Support in Acute Care", "authors": ["Md Fantacher Islam", "Jarrod Mosier", "Vignesh Subbian"], "categories": ["q-bio.OT", "cs.AI"], "primary_category": "Subjects:       Other Quantitative Biology (q-bio.OT)", "pdf_link": null, "comments": "Comments:      Submitted to the Journal of the American Medical Informatics Association (JAMIA)", "url": "http://arxiv.org/abs/2507.19992v1", "summary": "Objective: Develop a Non Invasive Respiratory Support (NIRS) ontology to\nsupport knowledge representation in acute care settings.\n  Materials and Methods: We developed the NIRS ontology using Web Ontology\nLanguage (OWL) semantics and Protege to organize clinical concepts and\nrelationships. To enable rule-based clinical reasoning beyond hierarchical\nstructures, we added Semantic Web Rule Language (SWRL) rules. We evaluated\nlogical reasoning by adding 17 hypothetical patient clinical scenarios. We used\nSPARQL queries and data from the Electronic Intensive Care Unit (eICU)\nCollaborative Research Database to retrieve and test targeted inferences.\n  Results: The ontology has 132 classes, 12 object properties, and 17 data\nproperties across 882 axioms that establish concept relationships. To\nstandardize clinical concepts, we added 350 annotations, including descriptive\ndefinitions based on controlled vocabularies. SPARQL queries successfully\nvalidated all test cases (rules) by retrieving appropriate patient outcomes,\nfor instance, a patient treated with HFNC (high-flow nasal cannula) for 2 hours\ndue to acute respiratory failure may avoid endotracheal intubation.\n  Discussion: The NIRS ontology formally represents domain-specific concepts,\nincluding ventilation modalities, patient characteristics, therapy parameters,\nand outcomes. SPARQL query evaluations on clinical scenarios confirmed the\nability of the ontology to support rule based reasoning and therapy\nrecommendations, providing a foundation for consistent documentation practices,\nintegration into clinical data models, and advanced analysis of NIRS outcomes.\n  Conclusion: We unified NIRS concepts into an ontological framework and\ndemonstrated its applicability through the evaluation of hypothetical patient\nscenarios and alignment with standardized vocabularies.", "comment": "Submitted to the Journal of the American Medical Informatics\n  Association (JAMIA)", "pdf_url": "http://arxiv.org/pdf/2507.19992v1", "cate": "q-bio.OT", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20243", "title": "Protein-SE(3): Benchmarking SE(3)-based Generative Models for Protein Structure Design", "authors": ["Lang Yu", "Zhangyang Gao", "Cheng Tan", "Qin Chen", "Jie Zhou", "Liang He"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20243v1", "summary": "SE(3)-based generative models have shown great promise in protein geometry\nmodeling and effective structure design. However, the field currently lacks a\nmodularized benchmark to enable comprehensive investigation and fair comparison\nof different methods. In this paper, we propose Protein-SE(3), a new benchmark\nbased on a unified training framework, which comprises protein scaffolding\ntasks, integrated generative models, high-level mathematical abstraction, and\ndiverse evaluation metrics. Recent advanced generative models designed for\nprotein scaffolding, from multiple perspectives like DDPM (Genie1 and Genie2),\nScore Matching (FrameDiff and RfDiffusion) and Flow Matching (FoldFlow and\nFrameFlow) are integrated into our framework. All integrated methods are fairly\ninvestigated with the same training dataset and evaluation metrics.\nFurthermore, we provide a high-level abstraction of the mathematical\nfoundations behind the generative models, enabling fast prototyping of future\nalgorithms without reliance on explicit protein structures. Accordingly, we\nrelease the first comprehensive benchmark built upon unified training framework\nfor SE(3)-based protein structure design, which is publicly accessible at\nhttps://github.com/BruthYU/protein-se3.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20243v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20563", "title": "Symplectic Elimination", "authors": ["Ayan Mahalanobis"], "categories": ["math.GR", "cs.SY", "eess.SY", "math.SG", "math.SP", "15B99, 15A21"], "primary_category": "Subjects:       Group Theory (math.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20563v1", "summary": "We develop the symplectic elimnation algorithm. This algorithm using simple\nrow operations reduce a symplectic matrix to a diagonal matrix. This algorithm\ngives rise to a decomposition of an arbitrary matrix into a product of a\nsymplectic matrix and a reduced matrix. This decomposition is similar to the SR\ndecomposition studied for a long time, which is analogous to the QR\ndecomposition.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20563v1", "cate": "math.GR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2409.08839", "title": "RF Challenge: The Data-Driven Radio Frequency Signal Separation Challenge", "authors": ["Alejandro Lancho", "Amir Weiss", "Gary C. F. Lee", "Tejas Jayashankar", "Binoy Kurien", "Yury Polyanskiy", "Gregory W. Wornell"], "categories": ["eess.SP", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      17 pages, 16 figures. Footnote about test set leakage added", "url": "http://arxiv.org/abs/2409.08839v3", "summary": "We address the critical problem of interference rejection in radio-frequency\n(RF) signals using a data-driven approach that leverages deep-learning methods.\nA primary contribution of this paper is the introduction of the RF Challenge,\nwhich is a publicly available, diverse RF signal dataset for data-driven\nanalyses of RF signal problems. Specifically, we adopt a simplified signal\nmodel for developing and analyzing interference rejection algorithms. For this\nsignal model, we introduce a set of carefully chosen deep learning\narchitectures, incorporating key domain-informed modifications alongside\ntraditional benchmark solutions to establish baseline performance metrics for\nthis intricate, ubiquitous problem. Through extensive simulations involving\neight different signal mixture types, we demonstrate the superior performance\n(in some cases, by two orders of magnitude) of architectures such as UNet and\nWaveNet over traditional methods like matched filtering and linear minimum mean\nsquare error estimation. Our findings suggest that the data-driven approach can\nyield scalable solutions, in the sense that the same architectures may be\nsimilarly trained and deployed for different types of signals. Moreover, these\nfindings further corroborate the promising potential of deep learning\nalgorithms for enhancing communication systems, particularly via interference\nmitigation. This work also includes results from an open competition based on\nthe RF Challenge, hosted at the 2024 IEEE International Conference on\nAcoustics, Speech, and Signal Processing (ICASSP'24).", "comment": "17 pages, 16 figures. Footnote about test set leakage added", "pdf_url": "http://arxiv.org/pdf/2409.08839v3", "cate": "eess.SP", "date": "2024-09-13", "updated": "2025-07-28"}
{"id": "2506.21198", "title": "Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation", "authors": ["Yihong Cao", "Jiaming Zhang", "Xu Zheng", "Hao Shi", "Kunyu Peng", "Hang Liu", "Kailun Yang", "Hui Zhang"], "categories": ["cs.CV", "cs.RO", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025. All data and code will be made publicly available at this https URL", "url": "http://arxiv.org/abs/2506.21198v2", "summary": "Panoramic image processing is essential for omni-context perception, yet\nfaces constraints like distortions, perspective occlusions, and limited\nannotations. Previous unsupervised domain adaptation methods transfer knowledge\nfrom labeled pinhole data to unlabeled panoramic images, but they require\naccess to source pinhole data. To address these, we introduce a more practical\ntask, i.e., Source-Free Occlusion-Aware Seamless Segmentation (SFOASS), and\npropose its first solution, called UNconstrained Learning Omni-Context\nKnowledge (UNLOCK). Specifically, UNLOCK includes two key modules: Omni\nPseudo-Labeling Learning and Amodal-Driven Context Learning. While adapting\nwithout relying on source data or target labels, this framework enhances models\nto achieve segmentation with 360{\\deg} viewpoint coverage and occlusion-aware\nreasoning. Furthermore, we benchmark the proposed SFOASS task through both\nreal-to-real and synthetic-to-real adaptation settings. Experimental results\nshow that our source-free method achieves performance comparable to\nsource-dependent methods, yielding state-of-the-art scores of 10.9 in mAAP and\n11.6 in mAP, along with an absolute improvement of +4.3 in mAPQ over the\nsource-only method. All data and code will be made publicly available at\nhttps://github.com/yihong-97/UNLOCK.", "comment": "Accepted to ICCV 2025. All data and code will be made publicly\n  available at https://github.com/yihong-97/UNLOCK", "pdf_url": "http://arxiv.org/pdf/2506.21198v2", "cate": "cs.CV", "date": "2025-06-26", "updated": "2025-07-28"}
{"id": "2506.21613", "title": "ChildGuard: A Specialized Dataset for Combatting Child-Targeted Hate Speech", "authors": ["Gautam Siddharth Kashyap", "Mohammad Anas Azeez", "Rafiq Ali", "Zohaib Hasan Siddiqui", "Jiechao Gao", "Usman Naseem"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Updated Version", "url": "http://arxiv.org/abs/2506.21613v2", "summary": "Hate speech targeting children on social media is a serious and growing\nproblem, yet current NLP systems struggle to detect it effectively. This gap\nexists mainly because existing datasets focus on adults, lack age specific\nlabels, miss nuanced linguistic cues, and are often too small for robust\nmodeling. To address this, we introduce ChildGuard, the first large scale\nEnglish dataset dedicated to hate speech aimed at children. It contains 351,877\nannotated examples from X (formerly Twitter), Reddit, and YouTube, labeled by\nthree age groups: younger children (under 11), pre teens (11--12), and teens\n(13--17). The dataset is split into two subsets for fine grained analysis: a\ncontextual subset (157K) focusing on discourse level features, and a lexical\nsubset (194K) emphasizing word-level sentiment and vocabulary. Benchmarking\nstate of the art hate speech models on ChildGuard reveals notable drops in\nperformance, highlighting the challenges of detecting child directed hate\nspeech.", "comment": "Updated Version", "pdf_url": "http://arxiv.org/pdf/2506.21613v2", "cate": "cs.CL", "date": "2025-06-21", "updated": "2025-07-27"}
{"id": "2507.17300", "title": "RLZ-r and LZ-End-r: Enhancing Move-r", "authors": ["Patrick Dinklage", "Johannes Fischer", "Lukas Nalbach", "Jan Zumbrink"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      full version of SPIRE 2025 conference paper", "url": "http://arxiv.org/abs/2507.17300v2", "summary": "In pattern matching on strings, a locate query asks for an enumeration of all\nthe occurrences of a given pattern in a given text. The r-index [Gagie et al.,\n2018] is a recently presented compressed self index that stores the text and\nauxiliary information in compressed space. With some modifications, locate\nqueries can be answered in optimal time [Nishimoto & Tabei, 2021], which has\nrecently been proven relevant in practice in the form of Move-r [Bertram et\nal., 2024]. However, there remains the practical bottleneck of evaluating\nfunction $\\Phi$ for every occurrence to report. This motivates enhancing the\nindex by a compressed representation of the suffix array featuring efficient\nrandom access, trading off space for faster answering of locate queries\n[Puglisi & Zhukova, 2021]. In this work, we build upon this idea considering\ntwo suitable compression schemes: Relative Lempel-Ziv [Kuruppu et al., 2010],\nimproving the work by Puglisi and Zhukova, and LZ-End [Kreft & Navarro, 2010],\nintroducing a different trade-off where compression is better than for Relative\nLempel-Ziv at the cost of slower access times. We enhance both the r-index and\nMove-r by the compressed suffix arrays and evaluate locate query performance in\nan experiment. We show that locate queries can be sped up considerably in both\nthe r-index and Move-r, especially if the queried pattern has many occurrences.\nThe choice between two different compression schemes offers new trade-offs\nregarding index size versus query performance.", "comment": "full version of SPIRE 2025 conference paper", "pdf_url": "http://arxiv.org/pdf/2507.17300v2", "cate": "cs.DS", "date": "2025-07-23", "updated": "2025-07-28"}
{"id": "2507.18972", "title": "TiVy: Time Series Visual Summary for Scalable Visualization", "authors": ["Gromit Yeuk-Yin Chan", "Luis Gustavo Nonato", "Themis Palpanas", "Cláudio T. Silva", "Juliana Freire"], "categories": ["cs.GR", "cs.LG"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      to be published in TVCG (IEEE VIS 2025)", "url": "http://arxiv.org/abs/2507.18972v2", "summary": "Visualizing multiple time series presents fundamental tradeoffs between\nscalability and visual clarity. Time series capture the behavior of many\nlarge-scale real-world processes, from stock market trends to urban activities.\nUsers often gain insights by visualizing them as line charts, juxtaposing or\nsuperposing multiple time series to compare them and identify trends and\npatterns. However, existing representations struggle with scalability: when\ncovering long time spans, leading to visual clutter from too many small\nmultiples or overlapping lines. We propose TiVy, a new algorithm that\nsummarizes time series using sequential patterns. It transforms the series into\na set of symbolic sequences based on subsequence visual similarity using\nDynamic Time Warping (DTW), then constructs a disjoint grouping of similar\nsubsequences based on the frequent sequential patterns. The grouping result, a\nvisual summary of time series, provides uncluttered superposition with fewer\nsmall multiples. Unlike common clustering techniques, TiVy extracts similar\nsubsequences (of varying lengths) aligned in time. We also present an\ninteractive time series visualization that renders large-scale time series in\nreal-time. Our experimental evaluation shows that our algorithm (1) extracts\nclear and accurate patterns when visualizing time series data, (2) achieves a\nsignificant speed-up (1000X) compared to a straightforward DTW clustering. We\nalso demonstrate the efficiency of our approach to explore hidden structures in\nmassive time series data in two usage scenarios.", "comment": "to be published in TVCG (IEEE VIS 2025)", "pdf_url": "http://arxiv.org/pdf/2507.18972v2", "cate": "cs.GR", "date": "2025-07-25", "updated": "2025-07-28"}
{"id": "2507.21120", "title": "Affect-aware Cross-Domain Recommendation for Art Therapy via Music Preference Elicitation", "authors": ["Bereket A. Yilma", "Luis A. Leiva"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted at the 19th ACM Conference on Recommender Systems", "url": "http://arxiv.org/abs/2507.21120v1", "summary": "Art Therapy (AT) is an established practice that facilitates emotional\nprocessing and recovery through creative expression. Recently, Visual Art\nRecommender Systems (VA RecSys) have emerged to support AT, demonstrating their\npotential by personalizing therapeutic artwork recommendations. Nonetheless,\ncurrent VA RecSys rely on visual stimuli for user modeling, limiting their\nability to capture the full spectrum of emotional responses during preference\nelicitation. Previous studies have shown that music stimuli elicit unique\naffective reflections, presenting an opportunity for cross-domain\nrecommendation (CDR) to enhance personalization in AT. Since CDR has not yet\nbeen explored in this context, we propose a family of CDR methods for AT based\non music-driven preference elicitation. A large-scale study with 200 users\ndemonstrates the efficacy of music-driven preference elicitation, outperforming\nthe classic visual-only elicitation approach. Our source code, data, and models\nare available at https://github.com/ArtAICare/Affect-aware-CDR", "comment": "Accepted at the 19th ACM Conference on Recommender Systems", "pdf_url": "http://arxiv.org/pdf/2507.21120v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.21351", "title": "Structure Preserving Finite Volume Schemes on Voronoi Grids: Curl Involution, Asymptotic Limit and Thermodynamics", "authors": ["Walter Boscheri", "Firas Dhaouadi"], "categories": ["math.NA", "cs.NA", "physics.comp-ph", "35L40, 65M08"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21351v1", "summary": "We propose a new curl-free and thermodynamically compatible finite volume\nscheme on Voronoi grids to solve compressible heat conducting flows written in\nfirst-order hyperbolic form. The approach is based on the definition of\ncompatible discrete curl-grad operators, exploiting the triangular nature of\nthe dual mesh. We design a cell solver reminiscent of the nodal solvers used in\nLagrangian schemes to discretize the evolution equation for the thermal impulse\nvector, and we demonstrate that the resulting numerical scheme ensures energy\nconservation, local non-negative entropy production, as well as asymptotic\nconsistency with the classical Fourier law in the stiff relaxation limit. A\nnovel technique is proposed to transfer residuals from the dual to the primal\nmesh as subfluxes, which eventually yields the construction of entropy\ncompatible semi-discrete methods. The scheme and its properties are validated\non a set of numerical test cases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21351v1", "cate": "math.NA", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2506.20496", "title": "Critical Anatomy-Preserving & Terrain-Augmenting Navigation (CAPTAiN): Application to Laminectomy Surgical Education", "authors": ["Jonathan Wang", "Hisashi Ishida", "David Usevitch", "Kesavan Venkatesh", "Yi Wang", "Mehran Armand", "Rachel Bronheim", "Amit Jain", "Adnan Munawar"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.20496v2", "summary": "Surgical training remains a crucial milestone in modern medicine, with\nprocedures such as laminectomy exemplifying the high risks involved.\nLaminectomy drilling requires precise manual control to mill bony tissue while\npreserving spinal segment integrity and avoiding breaches in the dura: the\nprotective membrane surrounding the spinal cord. Despite unintended tears\noccurring in up to 11.3% of cases, no assistive tools are currently utilized to\nreduce this risk. Variability in patient anatomy further complicates learning\nfor novice surgeons. This study introduces CAPTAiN, a critical\nanatomy-preserving and terrain-augmenting navigation system that provides\nlayered, color-coded voxel guidance to enhance anatomical awareness during\nspinal drilling. CAPTAiN was evaluated against a standard non-navigated\napproach through 110 virtual laminectomies performed by 11 orthopedic residents\nand medical students. CAPTAiN significantly improved surgical completion rates\nof target anatomy (87.99% vs. 74.42%) and reduced cognitive load across\nmultiple NASA-TLX domains. It also minimized performance gaps across experience\nlevels, enabling novices to perform on par with advanced trainees. These\nfindings highlight CAPTAiN's potential to optimize surgical execution and\nsupport skill development across experience levels. Beyond laminectomy, it\ndemonstrates potential for broader applications across various surgical and\ndrilling procedures, including those in neurosurgery, otolaryngology, and other\nmedical fields.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.20496v2", "cate": "cs.RO", "date": "2025-06-25", "updated": "2025-07-27"}
{"id": "2507.19995", "title": "VLQA: The First Comprehensive, Large, and High-Quality Vietnamese Dataset for Legal Question Answering", "authors": ["Tan-Minh Nguyen", "Hoang-Trung Nguyen", "Trong-Khoi Dao", "Xuan-Hieu Phan", "Ha-Thanh Nguyen", "Thi-Hai-Yen Vuong"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19995v1", "summary": "The advent of large language models (LLMs) has led to significant\nachievements in various domains, including legal text processing. Leveraging\nLLMs for legal tasks is a natural evolution and an increasingly compelling\nchoice. However, their capabilities are often portrayed as greater than they\ntruly are. Despite the progress, we are still far from the ultimate goal of\nfully automating legal tasks using artificial intelligence (AI) and natural\nlanguage processing (NLP). Moreover, legal systems are deeply domain-specific\nand exhibit substantial variation across different countries and languages. The\nneed for building legal text processing applications for different natural\nlanguages is, therefore, large and urgent. However, there is a big challenge\nfor legal NLP in low-resource languages such as Vietnamese due to the scarcity\nof resources and annotated data. The need for labeled legal corpora for\nsupervised training, validation, and supervised fine-tuning is critical. In\nthis paper, we introduce the VLQA dataset, a comprehensive and high-quality\nresource tailored for the Vietnamese legal domain. We also conduct a\ncomprehensive statistical analysis of the dataset and evaluate its\neffectiveness through experiments with state-of-the-art models on legal\ninformation retrieval and question-answering tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19995v1", "cate": "cs.CL", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20263", "title": "Learning from Expert Factors: Trajectory-level Reward Shaping for Formulaic Alpha Mining", "authors": ["Junjie Zhao", "Chengxi Zhang", "Chenkai Wang", "Peng Yang"], "categories": ["cs.LG", "cs.AI", "q-fin.PM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20263v1", "summary": "Reinforcement learning (RL) has successfully automated the complex process of\nmining formulaic alpha factors, for creating interpretable and profitable\ninvestment strategies. However, existing methods are hampered by the sparse\nrewards given the underlying Markov Decision Process. This inefficiency limits\nthe exploration of the vast symbolic search space and destabilizes the training\nprocess. To address this, Trajectory-level Reward Shaping (TLRS), a novel\nreward shaping method, is proposed. TLRS provides dense, intermediate rewards\nby measuring the subsequence-level similarity between partially generated\nexpressions and a set of expert-designed formulas. Furthermore, a reward\ncentering mechanism is introduced to reduce training variance. Extensive\nexperiments on six major Chinese and U.S. stock indices show that TLRS\nsignificantly improves the predictive power of mined factors, boosting the Rank\nInformation Coefficient by 9.29% over existing potential-based shaping\nalgorithms. Notably, TLRS achieves a major leap in computational efficiency by\nreducing its time complexity with respect to the feature dimension from linear\nto constant, which is a significant improvement over distance-based baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20263v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20717", "title": "Fundamental diagram constrained dynamic optimal transport via proximal splitting methods", "authors": ["Anqi Dong", "Karl Henrik Johansson", "Johan Karlsson"], "categories": ["math.OC", "cs.SY", "eess.SY", "76A30, 90B20, 35Q93, 37N40, 49M41, 90C25"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      30 pages, 14 figures", "url": "http://arxiv.org/abs/2507.20717v1", "summary": "Optimal transport has recently been brought forward as a tool for modeling\nand efficiently solving a variety of flow problems, such as origin-destination\nproblems and multi-commodity flow problems. Although the framework has shown to\nbe effective for many large scale flow problems, the formulations typically\nlack dynamic properties used in common traffic models, such as the\nLighthill-Whitham-Richards model. In this work, we propose an optimal transport\nframework that includes dynamic constraints specified by the fundamental\ndiagram for modeling macroscopic traffic flow. The problem is cast as a convex\nvariant of dynamic optimal transport, with additional nonlinear\ntemporal-spatial inequality constraints of momentum, modeled after the\nfundamental diagram from traffic theory. This constraint imposes a\ndensity-dependent upper bound on the admissible flux, capturing flow saturation\nand congestion effects, and thus leaves space for kinetic optimization. The\nformulation follows the Benamou-Brenier transportation rationale, whereby\nkinetic energy over density and momentum fields is optimized subject to the\nmass conservation law. We develop proximal splitting methods, namely the\nDouglas-Rachford and Chambolle-Pock algorithms, which exploit the separable\nstructure of the constraint set and require only simple proximal operations,\nand can accommodate additional (time-varying) spatial restrictions or\nobstacles. Numerical experiments illustrate the impact of the constraint on\ntransport behavior, including congestion-aware spreading, rerouting, and\nconvergence. The framework establishes a connection between optimal transport\nand macroscopic traffic flow theory and provides a scalable, variational tool\nfor modeling congestion-constricted (or saturation-aware) Wasserstein gradient\nflow.", "comment": "30 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.20717v1", "cate": "math.OC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2502.18118", "title": "Generative AI-enabled Wireless Communications for Robust Low-Altitude Economy Networking", "authors": ["Changyuan Zhao", "Jiacheng Wang", "Ruichen Zhang", "Dusit Niyato", "Geng Sun", "Hongyang Du", "Dong In Kim", "Abbas Jamalipour"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      9 pages, 4 figures", "url": "http://arxiv.org/abs/2502.18118v2", "summary": "Low-Altitude Economy Networks (LAENets) have emerged as significant enablers\nof social activities, offering low-altitude services such as the transportation\nof packages, groceries, and medical supplies. Owing to their control mechanisms\nand ever-changing operational factors, LAENets are inherently more complex and\nvulnerable to security threats than traditional terrestrial networks. As\napplications of LAENet continue to expand, the robustness of these systems\nbecomes crucial. In this paper, we propose a generative artificial intelligence\n(GenAI) optimization framework that tackles robustness challenges in LAENets.\nWe conduct a systematic analysis of robustness requirements for LAENets,\ncomplemented by a comprehensive review of robust Quality of Service (QoS)\nmetrics from the wireless physical layer perspective. We then investigate\nexisting GenAI-enabled approaches for robustness enhancement. This leads to our\nproposal of a novel diffusion-based optimization framework with a Mixture of\nExperts (MoE)-transformer actor network. In the robust beamforming case study,\nthe proposed framework demonstrates its effectiveness by optimizing beamforming\nunder uncertainties, achieving a more than 15% increase over four learning\nbaselines in the worst-case achievable secrecy rate. These findings highlight\nthe significant potential of GenAI in strengthening LAENet robustness.", "comment": "9 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2502.18118v2", "cate": "eess.SP", "date": "2025-02-25", "updated": "2025-07-26"}
{"id": "2506.22456", "title": "AI-Driven Radio Propagation Prediction in Automated Warehouses using Variational Autoencoders", "authors": ["Rahul Gulia", "Amlan Ganguly", "Andres Kwasinski", "Michael E. Kuhl", "Ehsan Rashedi", "Clark Hochgraf"], "categories": ["eess.SP", "eess.IV"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.22456v2", "summary": "The next decade will usher in a profound transformation of wireless\ncommunication, driven by the ever-increasing demand for data-intensive\napplications and the rapid adoption of emerging technologies. To fully unlock\nthe potential of 5G and beyond, substantial advancements are required in signal\nprocessing techniques, innovative network architectures, and efficient spectrum\nutilization strategies. These advancements facilitate seamless integration of\nemerging technologies, driving industrial digital transformation and\nconnectivity. This paper introduces a novel Variational Autoencoder (VAE)-based\nframework, Wireless Infrastructure for Smart Warehouses using VAE (WISVA),\ndesigned for accurate indoor radio propagation modeling in automated Industry\n4.0 environments such as warehouses and factory floors operating within 5G\nwireless bands. The research delves into the meticulous creation of training\ndata tensors, capturing complex electromagnetic (EM) wave behaviors influenced\nby diverse obstacles, and outlines the architecture and training methodology of\nthe proposed VAE model. The model's robustness and adaptability are showcased\nthrough its ability to predict signal-to-interference-plus-noise ratio (SINR)\nheatmaps across various scenarios, including denoising tasks, validation\ndatasets, extrapolation to unseen configurations, and previously unencountered\nwarehouse layouts. Compelling reconstruction error heatmaps are presented,\nhighlighting the superior accuracy of WISVA compared to traditional autoencoder\nmodels. The paper also analyzes the model's performance in handling complex\nsmart warehouse environments, demonstrating its potential as a key enabler for\noptimizing wireless infrastructure in Industry 4.0.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.22456v2", "cate": "eess.SP", "date": "2025-06-16", "updated": "2025-07-27"}
{"id": "2507.09342", "title": "BENYO-S2ST-Corpus-1: A Bilingual English-to-Yoruba Direct Speech-to-Speech Translation Corpus", "authors": ["Emmanuel Adetiba", "Abdultaofeek Abayomi", "Raymond J. Kala", "Ayodele H. Ifijeh", "Oluwatobi E. Dare", "Olabode Idowu-Bismark", "Gabriel O. Sobola", "Joy N. Adetiba", "Monsurat Adepeju Lateef", "Heather Cole-Lewis"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09342v2", "summary": "There is a major shortage of Speech-to-Speech Translation (S2ST) datasets for\nhigh resource-to-low resource language pairs such as English-to-Yoruba. Thus,\nin this study, we curated the Bilingual English-to-Yoruba Speech-to-Speech\nTranslation Corpus Version 1 (BENYO-S2ST-Corpus-1). The corpus is based on a\nhybrid architecture we developed for large-scale direct S2ST corpus creation at\nreduced cost. To achieve this, we leveraged non speech-to-speech Standard\nYoruba (SY) real-time audios and transcripts in the YORULECT Corpus as well as\nthe corresponding Standard English (SE) transcripts. YORULECT Corpus is small\nscale(1,504) samples, and it does not have paired English audios. Therefore, we\ngenerated the SE audios using pre-trained AI models (i.e. Facebook MMS). We\nalso developed an audio augmentation algorithm named AcoustAug based on three\nlatent acoustic features to generate augmented audios from the raw audios of\nthe two languages. BENYO-S2ST-Corpus-1 has 12,032 audio samples per language,\nwhich gives a total of 24,064 sample size. The total audio duration for the two\nlanguages is 41.20 hours. This size is quite significant. Beyond building S2ST\nmodels, BENYO-S2ST-Corpus-1 can be used to build pretrained models or improve\nexisting ones. The created corpus and Coqui framework were used to build a\npretrained Yoruba TTS model (named YoruTTS-0.5) as a proof of concept. The\nYoruTTS-0.5 gave a F0 RMSE value of 63.54 after 1,000 epochs, which indicates\nmoderate fundamental pitch similarity with the reference real-time audio.\nUltimately, the corpus architecture in this study can be leveraged by\nresearchers and developers to curate datasets for multilingual\nhigh-resource-to-low-resource African languages. This will bridge the huge\ndigital divides in translations among high and low-resource language pairs.\nBENYO-S2ST-Corpus-1 and YoruTTS-0.5 are publicly available at\n(https://bit.ly/40bGMwi).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09342v2", "cate": "cs.SD", "date": "2025-07-12", "updated": "2025-07-28"}
{"id": "2507.19139", "title": "String Consensus Problems with Swaps and Substitutions", "authors": ["Estéban Gabory", "Laurent Bulteau", "Gabriele Fici", "Hilde Verbeek"], "categories": ["cs.DS", "cs.CC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Full version of the work presented at SPIRE 2025", "url": "http://arxiv.org/abs/2507.19139v2", "summary": "String consensus problems aim at finding a string that minimizes some given\ndistance with respect to an input set of strings. In particular, in the Closest\nstring problem, we are given a set of strings of equal length and a radius $d$.\nThe objective is to find a new string that differs from each input string by at\nmost $d$ substitutions. We study a generalization of this problem where, in\naddition to substitutions, swaps of adjacent characters are also permitted,\neach operation incurring a unit cost. Amir et al. showed that this generalized\nproblem is NP-hard, even when only swaps are allowed. In this paper, we show\nthat it is FPT with respect to the parameter $d$. Moreover, we investigate a\nvariant in which the goal is to minimize the sum of distances from the output\nstring to all input strings. For this version, we present a polynomial-time\nalgorithm.", "comment": "Full version of the work presented at SPIRE 2025", "pdf_url": "http://arxiv.org/pdf/2507.19139v2", "cate": "cs.DS", "date": "2025-07-25", "updated": "2025-07-28"}
{"id": "2408.02275", "title": "Geometric Algebra Meets Large Language Models: Instruction-Based Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes", "authors": ["Prodromos Kolyvakis", "Manos Kamarianakis", "George Papagiannakis"], "categories": ["cs.CV", "cs.AI", "cs.GR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 4 figures", "url": "http://arxiv.org/abs/2408.02275v2", "summary": "This paper introduces a novel integration of Large Language Models (LLMs)\nwith Conformal Geometric Algebra (CGA) to revolutionize controllable 3D scene\nediting, particularly for object repositioning tasks, which traditionally\nrequires intricate manual processes and specialized expertise. These\nconventional methods typically suffer from reliance on large training datasets\nor lack a formalized language for precise edits. Utilizing CGA as a robust\nformal language, our system, Shenlong, precisely models spatial transformations\nnecessary for accurate object repositioning. Leveraging the zero-shot learning\ncapabilities of pre-trained LLMs, Shenlong translates natural language\ninstructions into CGA operations which are then applied to the scene,\nfacilitating exact spatial transformations within 3D scenes without the need\nfor specialized pre-training. Implemented in a realistic simulation\nenvironment, Shenlong ensures compatibility with existing graphics pipelines.\nTo accurately assess the impact of CGA, we benchmark against robust Euclidean\nSpace baselines, evaluating both latency and accuracy. Comparative performance\nevaluations indicate that Shenlong significantly reduces LLM response times by\n16% and boosts success rates by 9.6% on average compared to the traditional\nmethods. Notably, Shenlong achieves a 100% perfect success rate in common\npractical queries, a benchmark where other systems fall short. These\nadvancements underscore Shenlong's potential to democratize 3D scene editing,\nenhancing accessibility and fostering innovation across sectors such as\neducation, digital entertainment, and virtual reality.", "comment": "10 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2408.02275v2", "cate": "cs.CV", "date": "2024-08-05", "updated": "2025-07-29"}
{"id": "2507.21125", "title": "RATE: An LLM-Powered Retrieval Augmented Generation Technology-Extraction Pipeline", "authors": ["Karan Mirhosseini", "Arya Aftab", "Alireza Sheikh"], "categories": ["cs.IR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      9 pages, 4 figures, 1 table", "url": "http://arxiv.org/abs/2507.21125v1", "summary": "In an era of radical technology transformations, technology maps play a\ncrucial role in enhancing decision making. These maps heavily rely on automated\nmethods of technology extraction. This paper introduces Retrieval Augmented\nTechnology Extraction (RATE), a Large Language Model (LLM) based pipeline for\nautomated technology extraction from scientific literature. RATE combines\nRetrieval Augmented Generation (RAG) with multi-definition LLM-based\nvalidation. This hybrid method results in high recall in candidate generation\nalongside with high precision in candidate filtering. While the pipeline is\ndesigned to be general and widely applicable, we demonstrate its use on 678\nresearch articles focused on Brain-Computer Interfaces (BCIs) and Extended\nReality (XR) as a case study. Consequently, The validated technology terms by\nRATE were mapped into a co-occurrence network, revealing thematic clusters and\nstructural features of the research landscape. For the purpose of evaluation, a\ngold standard dataset of technologies in 70 selected random articles had been\ncurated by the experts. In addition, a technology extraction model based on\nBidirectional Encoder Representations of Transformers (BERT) was used as a\ncomparative method. RATE achieved F1-score of 91.27%, Significantly\noutperforming BERT with F1-score of 53.73%. Our findings highlight the promise\nof definition-driven LLM methods for technology extraction and mapping. They\nalso offer new insights into emerging trends within the BCI-XR field. The\nsource code is available https://github.com/AryaAftab/RATE", "comment": "9 pages, 4 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.21125v1", "cate": "cs.IR", "date": "2025-07-19", "updated": "2025-07-19"}
{"id": "2507.21392", "title": "Divergence-free Preserving Mix Finite Element Methods for Fourth-order Active Fluid Model", "authors": ["Nan Zheng", "Xu Guo", "Wenlong Pei", "Wenju Zhao"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21392v1", "summary": "This paper is concerned with mixed finite element method (FEM) for solving\nthe two-dimensional, nonlinear fourth-order active fluid equations. By\nintroducing an auxiliary variable $w=-\\Delta u$, the original fourth problem is\ntransformed into a system of second-order equations, which relaxes the\nregularity requirements of standard $H^2$-conforming finite spaces. To further\nenhance the robustness and efficiency of the algorithm, an additional auxiliary\nvariable $\\phi$, treated analogously to the pressure, is introduced, leading to\na divergence-free preserving mixed finite element scheme. A fully discrete\nscheme is then constructed by coupling the spatial mixed FEM with the\nvariable-step Dahlquist-Liniger-Nevanlinna (DLN) time integrator. The\nboundedness of the scheme and corresponding error estimates can be rigorously\nproven under appropriate assumptions due to unconditional non-linear stability\nand second-order accuracy of the DLN method. To enhance computational\nefficiency in practice, we develop an adaptive time-stepping strategy based on\na minimum-dissipation criterion. Several numerical experiments are displayed to\nfully validate the theoretical results and demonstrate the accuracy and\nefficiency of the scheme for complex active fluid simulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21392v1", "cate": "math.NA", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.17856", "title": "A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation", "authors": ["Dennis Benders", "Laura Ferranti", "Johannes Köhler"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      51 pages, 3 figures", "url": "http://arxiv.org/abs/2507.17856v2", "summary": "Designing a Model Predictive Control (MPC) scheme that enables a mobile robot\nto safely navigate through an obstacle-filled environment is a complicated yet\nessential task in robotics. In this technical report, safety refers to ensuring\nthat the robot respects state and input constraints while avoiding collisions\nwith obstacles despite the presence of disturbances and measurement noise. This\nreport offers a step-by-step approach to implementing Nonlinear Model\nPredictive Control (NMPC) schemes addressing these safety requirements.\nNumerous books and survey papers provide comprehensive overviews of linear MPC\n(LMPC), NMPC, and their applications in various domains, including robotics.\nThis report does not aim to replicate those exhaustive reviews. Instead, it\nfocuses specifically on NMPC as a foundation for safe mobile robot navigation.\nThe goal is to provide a practical and accessible path from theoretical\nconcepts to mathematical proofs and implementation, emphasizing safety and\nperformance guarantees. It is intended for researchers, robotics engineers, and\npractitioners seeking to bridge the gap between theoretical NMPC formulations\nand real-world robotic applications.\n  This report is not necessarily meant to remain fixed over time. If someone\nfinds an error in the presented theory, please reach out via the given email\naddresses. We are happy to update the document if necessary.", "comment": "51 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.17856v2", "cate": "cs.RO", "date": "2025-07-23", "updated": "2025-07-26"}
{"id": "2507.20019", "title": "Anomaly Detection in Human Language via Meta-Learning: A Few-Shot Approach", "authors": ["Saurav Singla", "Aarav Singla", "Advik Gupta", "Parnika Gupta"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      15 pages. PyTorch code for few-shot anomaly detection using meta-learning is available upon request or can be shared via GitHub", "url": "http://arxiv.org/abs/2507.20019v1", "summary": "We propose a meta learning framework for detecting anomalies in human\nlanguage across diverse domains with limited labeled data. Anomalies in\nlanguage ranging from spam and fake news to hate speech pose a major challenge\ndue to their sparsity and variability. We treat anomaly detection as a few shot\nbinary classification problem and leverage meta-learning to train models that\ngeneralize across tasks. Using datasets from domains such as SMS spam, COVID-19\nfake news, and hate speech, we evaluate model generalization on unseen tasks\nwith minimal labeled anomalies. Our method combines episodic training with\nprototypical networks and domain resampling to adapt quickly to new anomaly\ndetection tasks. Empirical results show that our method outperforms strong\nbaselines in F1 and AUC scores. We also release the code and benchmarks to\nfacilitate further research in few-shot text anomaly detection.", "comment": "15 pages. PyTorch code for few-shot anomaly detection using\n  meta-learning is available upon request or can be shared via GitHub", "pdf_url": "http://arxiv.org/pdf/2507.20019v1", "cate": "cs.CL", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20272", "title": "Approximating Full Conformal Prediction for Neural Network Regression with Gauss-Newton Influence", "authors": ["Dharmesh Tailor", "Alvaro H. C. Correia", "Eric Nalisnick", "Christos Louizos"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at the 13th International Conference on Learning Representations (ICLR 2025)", "url": "http://arxiv.org/abs/2507.20272v1", "summary": "Uncertainty quantification is an important prerequisite for the deployment of\ndeep learning models in safety-critical areas. Yet, this hinges on the\nuncertainty estimates being useful to the extent the prediction intervals are\nwell-calibrated and sharp. In the absence of inherent uncertainty estimates\n(e.g. pretrained models predicting only point estimates), popular approaches\nthat operate post-hoc include Laplace's method and split conformal prediction\n(split-CP). However, Laplace's method can be miscalibrated when the model is\nmisspecified and split-CP requires sample splitting, and thus comes at the\nexpense of statistical efficiency. In this work, we construct prediction\nintervals for neural network regressors post-hoc without held-out data. This is\nachieved by approximating the full conformal prediction method (full-CP).\nWhilst full-CP nominally requires retraining the model for every test point and\ncandidate label, we propose to train just once and locally perturb model\nparameters using Gauss-Newton influence to approximate the effect of\nretraining. Coupled with linearization of the network, we express the absolute\nresidual nonconformity score as a piecewise linear function of the candidate\nlabel allowing for an efficient procedure that avoids the exhaustive search\nover the output space. On standard regression benchmarks and bounding box\nlocalization, we show the resulting prediction intervals are locally-adaptive\nand often tighter than those of split-CP.", "comment": "Accepted at the 13th International Conference on Learning\n  Representations (ICLR 2025)", "pdf_url": "http://arxiv.org/pdf/2507.20272v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2210.06272", "title": "Deep Koopman Learning of Nonlinear Time-Varying Systems", "authors": ["Wenjian Hao", "Bowen Huang", "Wei Pan", "Di Wu", "Shaoshuai Mou"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2210.06272v4", "summary": "This paper presents a data-driven approach to approximate the dynamics of a\nnonlinear time-varying system (NTVS) by a linear time-varying system (LTVS),\nwhich is resulted from the Koopman operator and deep neural networks. Analysis\nof the approximation error between states of the NTVS and the resulting LTVS is\npresented. Simulations on a representative NTVS show that the proposed method\nachieves small approximation errors, even when the system changes rapidly.\nFurthermore, simulations in an example of quadcopters demonstrate the\ncomputational efficiency of the proposed approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2210.06272v4", "cate": "eess.SY", "date": "2022-10-12", "updated": "2025-07-26"}
{"id": "2503.09922", "title": "RIS-Assisted Joint Sensing and Communications via Fractionally Constrained Fractional Programming", "authors": ["Yiming Liu", "Kareem M. Attiah", "Wei Yu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      The paper has been accepted for publication in IEEE Transactions on Wireless Communications", "url": "http://arxiv.org/abs/2503.09922v2", "summary": "This paper studies an uplink dual-functional sensing and communication system\naided by a reconfigurable intelligent surface (RIS), whose reflection pattern\nis optimally configured to trade-off sensing and communication functionalities.\nSpecifically, the Bayesian Cram\\'er-Rao lower bound (BCRLB) for estimating the\nazimuth angle of a sensing user is minimized while ensuring the\nsignal-to-interference-plus-noise ratio constraints for communication users. We\nshow that this problem can be formulated as a novel fractionally constrained\nfractional programming (FCFP) problem. To deal with this highly nontrivial\nproblem, we extend a quadratic transform technique, originally proposed to\nhandle optimization problems containing fractional structures only in\nobjectives, to the scenario where the constraints also include ratios. First,\nwe consider the case where the fading coefficient is known. Using the quadratic\ntransform, the FCFP problem can be turned into a sequence of subproblems that\nare convex except for the constant-modulus constraints which can be tackled\nusing a penalty-based approach. To further reduce the computational complexity,\nwe leverage the constant-modulus conditions and propose a novel linear\ntransform. This new transform enables the FCFP problem to be turned into a\nsequence of linear programming (LP) subproblems, which can be solved with\nlinear complexity in the dimension of reflecting elements. Then, we consider\nthe case where the fading coefficient is unknown. A modified BCRLB is used to\nmake the problem more tractable, and the proposed quadratic transform based\nalgorithm is used to solve the problem. Numerical results unveil nontrivial and\neffective reflection patterns that can be synthesized by the RIS to facilitate\nboth communication and sensing functionalities.", "comment": "The paper has been accepted for publication in IEEE Transactions on\n  Wireless Communications", "pdf_url": "http://arxiv.org/pdf/2503.09922v2", "cate": "eess.SP", "date": "2025-03-13", "updated": "2025-07-27"}
{"id": "2507.05390", "title": "From General to Specialized: The Need for Foundational Models in Agriculture", "authors": ["Vishal Nedungadi", "Xingguo Xiong", "Aike Potze", "Ron Van Bree", "Tao Lin", "Marc Rußwurm", "Ioannis N. Athanasiadis"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to the SEA Workshop (Sustainability with Earth Observation & AI) at ICCV 2025", "url": "http://arxiv.org/abs/2507.05390v2", "summary": "Food security remains a global concern as population grows and climate change\nintensifies, demanding innovative solutions for sustainable agricultural\nproductivity. Recent advances in foundation models have demonstrated remarkable\nperformance in remote sensing and climate sciences, and therefore offer new\nopportunities for agricultural monitoring. However, their application in\nchallenges related to agriculture-such as crop type mapping, crop phenology\nestimation, and crop yield estimation-remains under-explored. In this work, we\nquantitatively evaluate existing foundational models to assess their\neffectivity for a representative set of agricultural tasks. From an\nagricultural domain perspective, we describe a requirements framework for an\nideal agricultural foundation model (CropFM). We then survey and compare\nexisting general-purpose foundational models in this framework and empirically\nevaluate two exemplary of them in three representative agriculture specific\ntasks. Finally, we highlight the need for a dedicated foundational model\ntailored specifically to agriculture.", "comment": "Accepted to the SEA Workshop (Sustainability with Earth Observation &\n  AI) at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.05390v2", "cate": "cs.CV", "date": "2025-07-07", "updated": "2025-07-26"}
{"id": "2507.17527", "title": "Seed LiveInterpret 2.0: End-to-end Simultaneous Speech-to-speech Translation with Your Voice", "authors": ["Shanbo Cheng", "Yu Bao", "Zhichao Huang", "Yu Lu", "Ningxin Peng", "Lu Xu", "Runsheng Yu", "Rong Cao", "Yujiao Du", "Ting Han", "Yuxiang Hu", "Zeyang Li", "Sitong Liu", "Shengtao Ma", "Shiguang Pan", "Jiongchen Xiao", "Nuo Xu", "Meng Yang", "Rong Ye", "Yiming Yu", "Jun Zhang", "Ruofei Zhang", "Wanyi Zhang", "Wenhao Zhu", "Liehao Zou", "Lu Lu", "Yuxuan Wang", "Yonghui Wu"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Seed-LiveInterpret 2.0 Technical Report", "url": "http://arxiv.org/abs/2507.17527v3", "summary": "Simultaneous Interpretation (SI) represents one of the most daunting\nfrontiers in the translation industry, with product-level automatic systems\nlong plagued by intractable challenges: subpar transcription and translation\nquality, lack of real-time speech generation, multi-speaker confusion, and\ntranslated speech inflation, especially in long-form discourses. In this study,\nwe introduce Seed-LiveInterpret 2.0, an end-to-end SI model that delivers\nhigh-fidelity, ultra-low-latency speech-to-speech generation with voice cloning\ncapabilities. As a fully operational product-level solution, Seed-LiveInterpret\n2.0 tackles these challenges head-on through our novel duplex speech-to-speech\nunderstanding-generating framework. Experimental results demonstrate that\nthrough large-scale pretraining and reinforcement learning, the model achieves\na significantly better balance between translation accuracy and latency,\nvalidated by human interpreters to exceed 70% correctness in complex scenarios.\nNotably, Seed-LiveInterpret 2.0 outperforms commercial SI solutions by\nsignificant margins in translation quality, while slashing the average latency\nof cloned speech from nearly 10 seconds to a near-real-time 3 seconds, which is\naround a near 70% reduction that drastically enhances practical usability.", "comment": "Seed-LiveInterpret 2.0 Technical Report", "pdf_url": "http://arxiv.org/pdf/2507.17527v3", "cate": "cs.CL", "date": "2025-07-23", "updated": "2025-07-27"}
{"id": "2409.15023", "title": "Efficient Nearest Neighbor Search Using Dynamic Programming", "authors": ["Pengfei Wang", "Jiantao Song", "Shiqing Xin", "Shuangmin Chen", "Changhe Tu", "Wenping Wang", "Jiaye Wang"], "categories": ["cs.CG", "cs.GR"], "primary_category": "Subjects:       Computational Geometry (cs.CG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.15023v5", "summary": "Given a collection of points in R^3, KD-Tree and R-Tree are well-known\nnearest neighbor search (NNS) algorithms that rely on space partitioning and\nspatial indexing techniques. However, when the query point is far from the data\npoints or the data points inherently represent a 2-manifold surface, their\nquery performance may degrade. To address this, we propose a novel dynamic\nprogramming technique that precomputes a Directed Acyclic Graph (DAG) to encode\nthe proximity structure between data points. More specifically, the DAG\ncaptures how the proximity structure evolves during the incremental\nconstruction of the Voronoi diagram of the data points. Experimental results\ndemonstrate that our method achieves a 1x-10x speedup. Additionally, our\nalgorithm demonstrates significant practical value across diverse applications.\nWe validated its effectiveness through extensive testing in four key\napplications: Point to Mesh Distance Queries, Iterative Closest Point (ICP)\nRegistration, Density Peak Clustering, and Point to Segments Distance Queries.\nA particularly notable feature of our approach is its unique ability to\nefficiently identify the nearest neighbor among the first k points in the point\ncloud a capability that enables substantial acceleration in low-dimensional\napplications like Density Peak Clustering. As a natural extension of our\nincremental construction process, our method can also be readily adapted for\nfarthest point sampling tasks. These experimental results across multiple\ndomains underscore the broad applicability and practical importance of our\napproach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.15023v5", "cate": "cs.CG", "date": "2024-09-23", "updated": "2025-07-29"}
{"id": "2507.21467", "title": "Efficient Data Retrieval and Comparative Bias Analysis of Recommendation Algorithms for YouTube Shorts and Long-Form Videos", "authors": ["Selimhan Dagtas", "Mert Can Cakmak", "Nitin Agarwal"], "categories": ["cs.IR", "cs.SI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21467v1", "summary": "The growing popularity of short-form video content, such as YouTube Shorts,\nhas transformed user engagement on digital platforms, raising critical\nquestions about the role of recommendation algorithms in shaping user\nexperiences. These algorithms significantly influence content consumption, yet\nconcerns about biases, echo chambers, and content diversity persist. This study\ndevelops an efficient data collection framework to analyze YouTube's\nrecommendation algorithms for both short-form and long-form videos, employing\nparallel computing and advanced scraping techniques to overcome limitations of\nYouTube's API. The analysis uncovers distinct behavioral patterns in\nrecommendation algorithms across the two formats, with short-form videos\nshowing a more immediate shift toward engaging yet less diverse content\ncompared to long-form videos. Furthermore, a novel investigation into biases in\npolitically sensitive topics, such as the South China Sea dispute, highlights\nthe role of these algorithms in shaping narratives and amplifying specific\nviewpoints. By providing actionable insights for designing equitable and\ntransparent recommendation systems, this research underscores the importance of\nresponsible AI practices in the evolving digital media landscape.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21467v1", "cate": "cs.IR", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21519", "title": "Variational inference and density estimation with non-negative tensor train", "authors": ["Xun Tang", "Rajat Dwaraknath", "Lexing Ying"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21519v1", "summary": "This work proposes an efficient numerical approach for compressing a\nhigh-dimensional discrete distribution function into a non-negative tensor\ntrain (NTT) format. The two settings we consider are variational inference and\ndensity estimation, whereby one has access to either the unnormalized analytic\nformula of the distribution or the samples generated from the distribution. In\nparticular, the compression is done through a two-stage approach. In the first\nstage, we use existing subroutines to encode the distribution function in a\ntensor train format. In the second stage, we use an NTT ansatz to fit the\nobtained tensor train. For the NTT fitting procedure, we use a log barrier term\nto ensure the positivity of each tensor component, and then utilize a\nsecond-order alternating minimization scheme to accelerate convergence. In\npractice, we observe that the proposed NTT fitting procedure exhibits\ndrastically faster convergence than an alternative multiplicative update method\nthat has been previously proposed. Through challenging numerical experiments,\nwe show that our approach can accurately compress target distribution\nfunctions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21519v1", "cate": "math.NA", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21202", "title": "Combolutional Neural Networks", "authors": ["Cameron Churchwell", "Minje Kim", "Paris Smaragdis"], "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      4 pages, 3 figures, accepted to WASPAA 2025", "url": "http://arxiv.org/abs/2507.21202v1", "summary": "Selecting appropriate inductive biases is an essential step in the design of\nmachine learning models, especially when working with audio, where even short\nclips may contain millions of samples. To this end, we propose the\ncombolutional layer: a learned-delay IIR comb filter and fused envelope\ndetector, which extracts harmonic features in the time domain. We demonstrate\nthe efficacy of the combolutional layer on three information retrieval tasks,\nevaluate its computational cost relative to other audio frontends, and provide\nefficient implementations for training. We find that the combolutional layer is\nan effective replacement for convolutional layers in audio tasks where precise\nharmonic analysis is important, e.g., piano transcription, speaker\nclassification, and key detection. Additionally, the combolutional layer has\nseveral other key benefits over existing frontends, namely: low parameter\ncount, efficient CPU inference, strictly real-valued computations, and improved\ninterpretability.", "comment": "4 pages, 3 figures, accepted to WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.21202v1", "cate": "cs.SD", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.18808", "title": "Perpetua: Multi-Hypothesis Persistence Modeling for Semi-Static Environments", "authors": ["Miguel Saavedra-Ruiz", "Samer B. Nashed", "Charlie Gauthier", "Liam Paull"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted to the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025) Code available at this https URL . Webpage and additional videos at this https URL", "url": "http://arxiv.org/abs/2507.18808v2", "summary": "Many robotic systems require extended deployments in complex, dynamic\nenvironments. In such deployments, parts of the environment may change between\nsubsequent robot observations. Most robotic mapping or environment modeling\nalgorithms are incapable of representing dynamic features in a way that enables\npredicting their future state. Instead, they opt to filter certain state\nobservations, either by removing them or some form of weighted averaging. This\npaper introduces Perpetua, a method for modeling the dynamics of semi-static\nfeatures. Perpetua is able to: incorporate prior knowledge about the dynamics\nof the feature if it exists, track multiple hypotheses, and adapt over time to\nenable predicting of future feature states. Specifically, we chain together\nmixtures of \"persistence\" and \"emergence\" filters to model the probability that\nfeatures will disappear or reappear in a formal Bayesian framework. The\napproach is an efficient, scalable, general, and robust method for estimating\nthe states of features in an environment, both in the present as well as at\narbitrary future times. Through experiments on simulated and real-world data,\nwe find that Perpetua yields better accuracy than similar approaches while also\nbeing online adaptable and robust to missing observations.", "comment": "Accepted to the IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025) Code available at\n  https://github.com/montrealrobotics/perpetua-code. Webpage and additional\n  videos at https://montrealrobotics.ca/perpetua/", "pdf_url": "http://arxiv.org/pdf/2507.18808v2", "cate": "cs.RO", "date": "2025-07-24", "updated": "2025-07-28"}
{"id": "2507.20028", "title": "TAPS : Frustratingly Simple Test Time Active Learning for VLMs", "authors": ["Dhruv Sarkar", "Aprameyo Chakrabartty", "Bibhudatta Bhanja"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20028v1", "summary": "Test-Time Optimization enables models to adapt to new data during inference\nby updating parameters on-the-fly. Recent advances in Vision-Language Models\n(VLMs) have explored learning prompts at test time to improve performance in\ndownstream tasks. In this work, we extend this idea by addressing a more\ngeneral and practical challenge: Can we effectively utilize an oracle in a\ncontinuous data stream where only one sample is available at a time, requiring\nan immediate query decision while respecting latency and memory constraints? To\ntackle this, we propose a novel Test-Time Active Learning (TTAL) framework that\nadaptively queries uncertain samples and updates prompts dynamically. Unlike\nprior methods that assume batched data or multiple gradient updates, our\napproach operates in a real-time streaming scenario with a single test sample\nper step. We introduce a dynamically adjusted entropy threshold for active\nquerying, a class-balanced replacement strategy for memory efficiency, and a\nclass-aware distribution alignment technique to enhance adaptation. The design\nchoices are justified using careful theoretical analysis. Extensive experiments\nacross 10 cross-dataset transfer benchmarks and 4 domain generalization\ndatasets demonstrate consistent improvements over state-of-the-art methods\nwhile maintaining reasonable latency and memory overhead. Our framework\nprovides a practical and effective solution for real-world deployment in\nsafety-critical applications such as autonomous systems and medical\ndiagnostics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20028v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20326", "title": "MIPS: a Multimodal Infinite Polymer Sequence Pre-training Framework for Polymer Property Prediction", "authors": ["Jiaxi Wang", "Yaosen Min", "Xun Zhu", "Miao Li", "Ji Wu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      14 pages, 8 figures, accepted by ACM Multimedia 2025 (oral)", "url": "http://arxiv.org/abs/2507.20326v1", "summary": "Polymers, composed of repeating structural units called monomers, are\nfundamental materials in daily life and industry. Accurate property prediction\nfor polymers is essential for their design, development, and application.\nHowever, existing modeling approaches, which typically represent polymers by\nthe constituent monomers, struggle to capture the whole properties of polymer,\nsince the properties change during the polymerization process. In this study,\nwe propose a Multimodal Infinite Polymer Sequence (MIPS) pre-training\nframework, which represents polymers as infinite sequences of monomers and\nintegrates both topological and spatial information for comprehensive modeling.\nFrom the topological perspective, we generalize message passing mechanism (MPM)\nand graph attention mechanism (GAM) to infinite polymer sequences. For MPM, we\ndemonstrate that applying MPM to infinite polymer sequences is equivalent to\napplying MPM on the induced star-linking graph of monomers. For GAM, we propose\nto further replace global graph attention with localized graph attention (LGA).\nMoreover, we show the robustness of the \"star linking\" strategy through Repeat\nand Shift Invariance Test (RSIT). Despite its robustness, \"star linking\"\nstrategy exhibits limitations when monomer side chains contain ring structures,\na common characteristic of polymers, as it fails the Weisfeiler-Lehman~(WL)\ntest. To overcome this issue, we propose backbone embedding to enhance the\ncapability of MPM and LGA on infinite polymer sequences. From the spatial\nperspective, we extract 3D descriptors of repeating monomers to capture spatial\ninformation. Finally, we design a cross-modal fusion mechanism to unify the\ntopological and spatial information. Experimental validation across eight\ndiverse polymer property prediction tasks reveals that MIPS achieves\nstate-of-the-art performance.", "comment": "14 pages, 8 figures, accepted by ACM Multimedia 2025 (oral)", "pdf_url": "http://arxiv.org/pdf/2507.20326v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2403.13367", "title": "Quantifying the Aggregate Flexibility of Electric Vehicles Charging Stations for Dependable Congestion Management Products -- A Dutch Case Study", "authors": ["Nanda Kishor Panda", "Simon H. Tindemans"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      16 Pages,12 figures, 3 tables", "url": "http://arxiv.org/abs/2403.13367v4", "summary": "Electric vehicles (EVs) play a crucial role in the transition towards\nsustainable modes of transportation and thus are critical to the energy\ntransition. As their number grows, managing the aggregate power of EV charging\nis crucial to maintain grid stability and mitigate congestion. This study\nanalyses more than 500 thousand real charging transactions in the Netherlands\nto explore the challenge and opportunity for the energy system presented by\nincreased charging needs and smart charging flexibility. Specifically, it\nquantifies the collective ability to provide dependable congestion management\nservices according to the specifications of those services in the Netherlands.\nIn this study, a data-driven model of charging behaviour is created to explore\nthe implications of delivering dependable congestion management services at\nvarious aggregation levels and types of service. The probabilistic ability to\noffer different flexibility products, namely, redispatch and capacity\nlimitation, for congestion management, is assessed for different categories of\ncharging stations (CS) and dispatch strategies. These probabilities can help EV\naggregators, such as charging point operators, make informed decisions about\noffering congestion mitigation products per relevant regulations and\ndistribution system operators to assess their potential. Further, it is shown\nhow machine learning models can be incorporated to predict the day-ahead\nconsumption, followed by operationally predicting redispatch flexibility. The\nfindings demonstrate that the timing of EV arrivals, departures, and\nconnections plays a crucial role in determining the feasibility of product\nofferings, and dependable services can generally be delivered using a\nsufficiently large number of CSs.", "comment": "16 Pages,12 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2403.13367v4", "cate": "eess.SY", "date": "2024-03-20", "updated": "2025-07-28"}
{"id": "2504.07720", "title": "Filtering through a topological lens: homology for point processes on the time-frequency plane", "authors": ["Juan Manuel Miramont", "Kin Aun Tan", "Soumendu Sundar Mukherjee", "Rémi Bardenet", "Subhroshekhar Ghosh"], "categories": ["eess.SP", "math.AT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.07720v3", "summary": "We introduce a very general approach to the analysis of signals from their\nnoisy measurements from the perspective of Topological Data Analysis (TDA).\nWhile TDA has emerged as a powerful analytical tool for data with pronounced\ntopological structures, here we demonstrate its applicability for general\nproblems of signal processing, without any a-priori geometric feature. Our\nmethods are well-suited to a wide array of time-dependent signals in different\nscientific domains, with acoustic signals being a particularly important\napplication. We invoke time-frequency representations of such signals, focusing\non their zeros which are gaining salience as a signal processing tool in view\nof their stability properties. Leveraging state-of-the-art topological\nconcepts, such as stable and minimal volumes, we develop a complete suite of\nTDA-based methods to explore the delicate stochastic geometry of these zeros,\ncapturing signals based on the disruption they cause to this rigid,\nhyperuniform spatial structure. Unlike classical spatial data tools, TDA is\nable to capture the full spectrum of the stochastic geometry of the zeros,\nthereby leading to powerful inferential outcomes that are underpinned by a\nprincipled statistical foundation. This is reflected in the power and\nversatility of our applications, which include competitive performance in\nprocessing. a wide variety of audio signals (esp. in low SNR regimes),\neffective detection and reconstruction of gravitational wave signals (a reputed\nsignal processing challenge with non-Gaussian noise), and medical time series\ndata from EEGs, indicating a wide horizon for the approach and methods\nintroduced in this paper.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.07720v3", "cate": "eess.SP", "date": "2025-04-10", "updated": "2025-07-25"}
{"id": "2507.18655", "title": "Part Segmentation of Human Meshes via Multi-View Human Parsing", "authors": ["James Dickens", "Kamyar Hamad"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.18655v2", "summary": "Recent advances in point cloud deep learning have led to models that achieve\nhigh per-part labeling accuracy on large-scale point clouds, using only the raw\ngeometry of unordered point sets. In parallel, the field of human parsing\nfocuses on predicting body part and clothing/accessory labels from images. This\nwork aims to bridge these two domains by enabling per-vertex semantic\nsegmentation of large-scale human meshes. To achieve this, a pseudo-ground\ntruth labeling pipeline is developed for the Thuman2.1 dataset: meshes are\nfirst aligned to a canonical pose, segmented from multiple viewpoints, and the\nresulting point-level labels are then backprojected onto the original mesh to\nproduce per-point pseudo ground truth annotations. Subsequently, a novel,\nmemory-efficient sampling strategy is introduced, a windowed iterative farthest\npoint sampling (FPS) with space-filling curve-based serialization to\neffectively downsample the point clouds. This is followed by a purely geometric\nsegmentation using PointTransformer, enabling semantic parsing of human meshes\nwithout relying on texture information. Experimental results confirm the\neffectiveness and accuracy of the proposed approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.18655v2", "cate": "cs.CV", "date": "2025-07-22", "updated": "2025-07-28"}
{"id": "2411.17489", "title": "Puzzle Similarity: A Perceptually-guided Cross-Reference Metric for Artifact Detection in 3D Scene Reconstructions", "authors": ["Nicolai Hermann", "Jorge Condor", "Piotr Didyk"], "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG", "68T07, 68T45, 68T10", "I.4; I.3; I.2"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.17489v3", "summary": "Modern reconstruction techniques can effectively model complex 3D scenes from\nsparse 2D views. However, automatically assessing the quality of novel views\nand identifying artifacts is challenging due to the lack of ground truth images\nand the limitations of no-reference image metrics in predicting reliable\nartifact maps. The absence of such metrics hinders assessment of the quality of\nnovel views and limits the adoption of post-processing techniques, such as\ninpainting, to enhance reconstruction quality. To tackle this, recent work has\nestablished a new category of metrics (cross-reference), predicting image\nquality solely by leveraging context from alternate viewpoint captures\n(arXiv:2404.14409). In this work, we propose a new cross-reference metric,\nPuzzle Similarity, which is designed to localize artifacts in novel views. Our\napproach utilizes image patch statistics from the training views to establish a\nscene-specific distribution, later used to identify poorly reconstructed\nregions in the novel views. Given the lack of good measures to evaluate\ncross-reference methods in the context of 3D reconstruction, we collected a\nnovel human-labeled dataset of artifact and distortion maps in unseen\nreconstructed views. Through this dataset, we demonstrate that our method\nachieves state-of-the-art localization of artifacts in novel views, correlating\nwith human assessment, even without aligned references. We can leverage our new\nmetric to enhance applications like automatic image restoration, guided\nacquisition, or 3D reconstruction from sparse inputs. Find the project page at\nhttps://nihermann.github.io/puzzlesim/ .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.17489v3", "cate": "cs.CV", "date": "2024-11-26", "updated": "2025-07-29"}
{"id": "2507.21520", "title": "Solution for Meta KDD Cup'25: A Comprehensive Three-Step Framework for Vision Question Answering", "authors": ["Zijian Zhang", "Xiaocheng Zhang", "Yang Zhou", "Zhimin Lin", "Peng Yan"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21520v1", "summary": "Vision Large Language Models (VLLMs) have improved multi-modal understanding\nand visual question answering (VQA), but still suffer from hallucinated\nanswers. Multi-modal Retrieval-Augmented Generation (RAG) helps address these\nissues by incorporating external information, yet challenges remain in visual\ncontext comprehension, multi-source retrieval, and multi-turn interactions. To\naddress these challenges, Meta constructed the CRAG-MM benchmark and launched\nthe CRAG-MM Challenge at KDD Cup 2025, which consists of three tasks. This\npaper describes the solutions of all tasks in Meta KDD Cup'25 from BlackPearl\nteam. We use a single model for each task, with key methods including data\naugmentation, RAG, reranking, and multi-task fine-tuning. Our solution achieve\nautomatic evaluation rankings of 3rd, 3rd, and 1st on the three tasks, and win\nsecond place in Task3 after human evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21520v1", "cate": "cs.IR", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21552", "title": "Structure-Preserving Discretization and Model Reduction for Energy-Based Models", "authors": ["Robert Altmann", "Attila Karsai", "Philipp Schulze"], "categories": ["math.NA", "cs.NA", "37J06, 65P10, 65M60"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      20 pages, 5 figures", "url": "http://arxiv.org/abs/2507.21552v1", "summary": "We investigate discretization strategies for a recently introduced class of\nenergy-based models. The model class encompasses classical port-Hamiltonian\nsystems, generalized gradient flows, and certain systems with algebraic\nconstraints. Our framework combines existing ideas from the literature and\nsystematically addresses temporal discretization, spatial discretization, and\nmodel order reduction, ensuring that all resulting schemes are\ndissipation-preserving in the sense of a discrete dissipation inequality. For\nthis, we use a Petrov-Galerkin ansatz together with appropriate projections.\nNumerical results for a nonlinear circuit model and the Cahn-Hilliard equation\nillustrate the effectiveness of the approach.", "comment": "20 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.21552v1", "cate": "math.NA", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21426", "title": "Relationship between objective and subjective perceptual measures of speech in individuals with head and neck cancer", "authors": ["Bence Mark Halpern", "Thomas Tienkamp", "Teja Rebernik", "Rob J. J. H. van Son", "Martijn Wieling", "Defne Abur", "Tomoki Toda"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      5 pages, 1 figure, 1 table. Accepted at Interspeech 2025", "url": "http://arxiv.org/abs/2507.21426v1", "summary": "Meaningful speech assessment is vital in clinical phonetics and therapy\nmonitoring. This study examined the link between perceptual speech assessments\nand objective acoustic measures in a large head and neck cancer (HNC) dataset.\nTrained listeners provided ratings of intelligibility, articulation, voice\nquality, phonation, speech rate, nasality, and background noise on speech.\nStrong correlations were found between subjective intelligibility,\narticulation, and voice quality, likely due to a shared underlying cause of\nspeech symptoms in our speaker population. Objective measures of\nintelligibility and speech rate aligned with their subjective counterpart. Our\nresults suggest that a single intelligibility measure may be sufficient for the\nclinical monitoring of speakers treated for HNC using concomitant\nchemoradiation.", "comment": "5 pages, 1 figure, 1 table. Accepted at Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.21426v1", "cate": "cs.SD", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2503.03599", "title": "REGRACE: A Robust and Efficient Graph-based Re-localization Algorithm using Consistency Evaluation", "authors": ["Débora N. P. Oliveira", "Joshua Knights", "Sebastián Barbas Laina", "Simon Boche", "Wolfram Burgard", "Stefan Leutenegger"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to IROS2025", "url": "http://arxiv.org/abs/2503.03599v2", "summary": "Loop closures are essential for correcting odometry drift and creating\nconsistent maps, especially in the context of large-scale navigation. Current\nmethods using dense point clouds for accurate place recognition do not scale\nwell due to computationally expensive scan-to-scan comparisons. Alternative\nobject-centric approaches are more efficient but often struggle with\nsensitivity to viewpoint variation. In this work, we introduce REGRACE, a novel\napproach that addresses these challenges of scalability and perspective\ndifference in re-localization by using LiDAR-based submaps. We introduce\nrotation-invariant features for each labeled object and enhance them with\nneighborhood context through a graph neural network. To identify potential\nrevisits, we employ a scalable bag-of-words approach, pooling one learned\nglobal feature per submap. Additionally, we define a revisit with geometrical\nconsistency cues rather than embedding distance, allowing us to recognize\nfar-away loop closures. Our evaluations demonstrate that REGRACE achieves\nsimilar results compared to state-of-the-art place recognition and registration\nbaselines while being twice as fast. Code and models are publicly available.", "comment": "Accepted to IROS2025", "pdf_url": "http://arxiv.org/pdf/2503.03599v2", "cate": "cs.CV", "date": "2025-03-05", "updated": "2025-07-28"}
{"id": "2507.20056", "title": "FaRMamba: Frequency-based learning and Reconstruction aided Mamba for Medical Segmentation", "authors": ["Ze Rong", "ZiYue Zhao", "Zhaoxin Wang", "Lei Ma"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20056v1", "summary": "Accurate medical image segmentation remains challenging due to blurred lesion\nboundaries (LBA), loss of high-frequency details (LHD), and difficulty in\nmodeling long-range anatomical structures (DC-LRSS). Vision Mamba employs\none-dimensional causal state-space recurrence to efficiently model global\ndependencies, thereby substantially mitigating DC-LRSS. However, its patch\ntokenization and 1D serialization disrupt local pixel adjacency and impose a\nlow-pass filtering effect, resulting in Local High-frequency Information\nCapture Deficiency (LHICD) and two-dimensional Spatial Structure Degradation\n(2D-SSD), which in turn exacerbate LBA and LHD. In this work, we propose\nFaRMamba, a novel extension that explicitly addresses LHICD and 2D-SSD through\ntwo complementary modules. A Multi-Scale Frequency Transform Module (MSFM)\nrestores attenuated high-frequency cues by isolating and reconstructing\nmulti-band spectra via wavelet, cosine, and Fourier transforms. A\nSelf-Supervised Reconstruction Auxiliary Encoder (SSRAE) enforces pixel-level\nreconstruction on the shared Mamba encoder to recover full 2D spatial\ncorrelations, enhancing both fine textures and global context. Extensive\nevaluations on CAMUS echocardiography, MRI-based Mouse-cochlea, and Kvasir-Seg\nendoscopy demonstrate that FaRMamba consistently outperforms competitive\nCNN-Transformer hybrids and existing Mamba variants, delivering superior\nboundary accuracy, detail preservation, and global coherence without\nprohibitive computational overhead. This work provides a flexible\nfrequency-aware framework for future segmentation models that directly\nmitigates core challenges in medical imaging.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20056v1", "cate": "cs.CV", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20335", "title": "Cultivating Helpful, Personalized, and Creative AI Tutors: A Framework for Pedagogical Alignment using Reinforcement Learning", "authors": ["Siyu Song", "Wentao Liu", "Ye Lu", "Ruohua Zhang", "Tao Liu", "Jinze Lv", "Xinyun Wang", "Aimin Zhou", "Fei Tan", "Bo Jiang", "Hao Hao"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20335v1", "summary": "The integration of large language models (LLMs) into education presents\nunprecedented opportunities for scalable personalized learning. However,\nstandard LLMs often function as generic information providers, lacking\nalignment with fundamental pedagogical principles such as helpfulness,\nstudent-centered personalization, and creativity cultivation. To bridge this\ngap, we propose EduAlign, a novel framework designed to guide LLMs toward\nbecoming more effective and responsible educational assistants. EduAlign\nconsists of two main stages. In the first stage, we curate a dataset of 8k\neducational interactions and annotate them-both manually and\nautomatically-along three key educational dimensions: Helpfulness,\nPersonalization, and Creativity (HPC). These annotations are used to train\nHPC-RM, a multi-dimensional reward model capable of accurately scoring LLM\noutputs according to these educational principles. We further evaluate the\nconsistency and reliability of this reward model. In the second stage, we\nleverage HPC-RM as a reward signal to fine-tune a pre-trained LLM using Group\nRelative Policy Optimization (GRPO) on a set of 2k diverse prompts. We then\nassess the pre- and post-finetuning models on both educational and\ngeneral-domain benchmarks across the three HPC dimensions. Experimental results\ndemonstrate that the fine-tuned model exhibits significantly improved alignment\nwith pedagogical helpfulness, personalization, and creativity stimulation. This\nstudy presents a scalable and effective approach to aligning LLMs with nuanced\nand desirable educational traits, paving the way for the development of more\nengaging, pedagogically aligned AI tutors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20335v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2403.15674", "title": "Safe and Stable Formation Control with Autonomous Multi-Agents Using Adaptive Control (Extended Version)", "authors": ["Jose A. Solano-Castellanos", "Peter A. Fisher", "Anuradha Annaswamy"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Accepted to Modeling, Estimation and Control Conference (MECC) 2025", "url": "http://arxiv.org/abs/2403.15674v4", "summary": "This manuscript considers the problem of ensuring stability and safety during\nformation control with distributed multi-agent systems in the presence of\nparametric uncertainty in the dynamics and limited communication. We propose an\nintegrative approach that combines Adaptive Control, Control Barrier Functions\n(CBFs), and connected graphs. The main elements employed in the integrative\napproach are an adaptive control design that ensures stability, a CBF-based\nsafety filter that generates safe commands based on a reference model dynamics,\nand a reference model that ensures formation control with multi-agent systems\nwhen no uncertainties are present. The overall control design is shown to lead\nto a closed-loop adaptive system that is stable, avoids unsafe regions, and\nconverges to a desired formation of the multi-agents. Numerical examples are\nprovided to support the theoretical derivations.", "comment": "Accepted to Modeling, Estimation and Control Conference (MECC) 2025", "pdf_url": "http://arxiv.org/pdf/2403.15674v4", "cate": "eess.SY", "date": "2024-03-23", "updated": "2025-07-25"}
{"id": "2506.22495", "title": "Masked Autoencoders that Feel the Heart: Unveiling Simplicity Bias for ECG Analyses", "authors": ["He-Yang Xu", "Hongxiang Gao", "Yuwen Li", "Xiu-Shen Wei", "Chengyu Liu"], "categories": ["eess.SP", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Revised Version 4", "url": "http://arxiv.org/abs/2506.22495v4", "summary": "The diagnostic value of electrocardiogram (ECG) lies in its dynamic\ncharacteristics, ranging from rhythm fluctuations to subtle waveform\ndeformations that evolve across time and frequency domains. However, supervised\nECG models tend to overfit dominant and repetitive patterns, overlooking\nfine-grained but clinically critical cues, a phenomenon known as Simplicity\nBias (SB), where models favor easily learnable signals over subtle but\ninformative ones. In this work, we first empirically demonstrate the presence\nof SB in ECG analyses and its negative impact on diagnostic performance, while\nsimultaneously discovering that self-supervised learning (SSL) can alleviate\nit, providing a promising direction for tackling the bias. Following the SSL\nparadigm, we propose a novel method comprising two key components: 1)\nTemporal-Frequency aware Filters to capture temporal-frequency features\nreflecting the dynamic characteristics of ECG signals, and 2) building on this,\nMulti-Grained Prototype Reconstruction for coarse and fine representation\nlearning across dual domains, further mitigating SB. To advance SSL in ECG\nanalyses, we curate a large-scale multi-site ECG dataset with 1.53 million\nrecordings from over 300 clinical centers. Experiments on three downstream\ntasks across six ECG datasets demonstrate that our method effectively reduces\nSB and achieves state-of-the-art performance.", "comment": "Revised Version 4", "pdf_url": "http://arxiv.org/pdf/2506.22495v4", "cate": "eess.SP", "date": "2025-06-25", "updated": "2025-07-28"}
{"id": "2507.15230", "title": "GALE: Leveraging Heterogeneous Systems for Efficient Unstructured Mesh Data Analysis", "authors": ["Guoxi Liu", "Thomas Randall", "Rong Ge", "Federico Iuricich"], "categories": ["cs.DC", "cs.GR"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15230v2", "summary": "Unstructured meshes present challenges in scientific data analysis due to\nirregular distribution and complex connectivity. Computing and storing\nconnectivity information is a major bottleneck for visualization algorithms,\naffecting both time and memory performance. Recent task-parallel data\nstructures address this by precomputing connectivity information at runtime\nwhile the analysis algorithm executes, effectively hiding computation costs and\nimproving performance. However, existing approaches are CPU-bound, forcing the\ndata structure and analysis algorithm to compete for the same computational\nresources, limiting potential speedups. To overcome this limitation, we\nintroduce a novel task-parallel approach optimized for heterogeneous CPU-GPU\nsystems. Specifically, we offload the computation of mesh connectivity\ninformation to GPU threads, enabling CPU threads to focus on executing the\nvisualization algorithm. Following this paradigm, we propose GALE (GPU-Aided\nLocalized data structurE), the first open-source CUDA-based data structure\ndesigned for heterogeneous task parallelism. Experiments on two 20-core CPUs\nand an NVIDIA V100 GPU show that GALE achieves up to 2.7x speedup over\nstate-of-the-art localized data structures while maintaining memory efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15230v2", "cate": "cs.DC", "date": "2025-07-21", "updated": "2025-07-28"}
{"id": "2507.21563", "title": "Enhancing Graph-based Recommendations with Majority-Voting LLM-Rerank Augmentation", "authors": ["Minh-Anh Nguyen", "Bao Nguyen", "Ha Lan N. T.", "Tuan Anh Hoang", "Duc-Trong Le", "Dung D. Le"], "categories": ["cs.IR", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21563v1", "summary": "Recommendation systems often suffer from data sparsity caused by limited\nuser-item interactions, which degrade their performance and amplify popularity\nbias in real-world scenarios. This paper proposes a novel data augmentation\nframework that leverages Large Language Models (LLMs) and item textual\ndescriptions to enrich interaction data. By few-shot prompting LLMs multiple\ntimes to rerank items and aggregating the results via majority voting, we\ngenerate high-confidence synthetic user-item interactions, supported by\ntheoretical guarantees based on the concentration of measure. To effectively\nleverage the augmented data in the context of a graph recommendation system, we\nintegrate it into a graph contrastive learning framework to mitigate\ndistributional shift and alleviate popularity bias. Extensive experiments show\nthat our method improves accuracy and reduces popularity bias, outperforming\nstrong baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21563v1", "cate": "cs.IR", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21564", "title": "Efficient and stable diffusion generated methods for ground state computation in Bose--Einstein condensates", "authors": ["Jing Guo", "Yongyong Cai", "Dong Wang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21564v1", "summary": "This paper investigates numerical methods for approximating the ground state\nof Bose--Einstein condensates (BECs) by introducing two relaxed formulations of\nthe Gross--Pitaevskii energy functional. These formulations achieve first- and\nsecond-order accuracy with respect to the relaxation parameter \\( \\tau \\), and\nare shown to converge to the original energy functional as \\( \\tau \\to 0 \\). A\nkey feature of the relaxed functionals is their concavity, which ensures that\nlocal minima lie on the boundary of the concave hull. This property prevents\nenergy increases during constraint normalization and enables the development of\nenergy-dissipative algorithms. Numerical methods based on sequential linear\nprogramming are proposed, accompanied by rigorous analysis of their stability\nwith respect to the relaxed energy. To enhance computational efficiency, an\nadaptive strategy is introduced, dynamically refining solutions obtained with\nlarger relaxation parameters to achieve higher accuracy with smaller ones.\nNumerical experiments demonstrate the stability, convergence, and energy\ndissipation of the proposed methods, while showcasing the adaptive strategy's\neffectiveness in improving computational performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21564v1", "cate": "math.NA", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21463", "title": "SpeechFake: A Large-Scale Multilingual Speech Deepfake Dataset Incorporating Cutting-Edge Generation Methods", "authors": ["Wen Huang", "Yanmei Gu", "Zhiming Wang", "Huijia Zhu", "Yanmin Qian"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Published in ACL 2025. Dataset available at: this https URL", "url": "http://arxiv.org/abs/2507.21463v1", "summary": "As speech generation technology advances, the risk of misuse through deepfake\naudio has become a pressing concern, which underscores the critical need for\nrobust detection systems. However, many existing speech deepfake datasets are\nlimited in scale and diversity, making it challenging to train models that can\ngeneralize well to unseen deepfakes. To address these gaps, we introduce\nSpeechFake, a large-scale dataset designed specifically for speech deepfake\ndetection. SpeechFake includes over 3 million deepfake samples, totaling more\nthan 3,000 hours of audio, generated using 40 different speech synthesis tools.\nThe dataset encompasses a wide range of generation techniques, including\ntext-to-speech, voice conversion, and neural vocoder, incorporating the latest\ncutting-edge methods. It also provides multilingual support, spanning 46\nlanguages. In this paper, we offer a detailed overview of the dataset's\ncreation, composition, and statistics. We also present baseline results by\ntraining detection models on SpeechFake, demonstrating strong performance on\nboth its own test sets and various unseen test sets. Additionally, we conduct\nexperiments to rigorously explore how generation methods, language diversity,\nand speaker variation affect detection performance. We believe SpeechFake will\nbe a valuable resource for advancing speech deepfake detection and developing\nmore robust models for evolving generation techniques.", "comment": "Published in ACL 2025. Dataset available at:\n  https://github.com/YMLLG/SpeechFake", "pdf_url": "http://arxiv.org/pdf/2507.21463v1", "cate": "cs.SD", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2503.18945", "title": "Aether: Geometric-Aware Unified World Modeling", "authors": ["Aether Team", "Haoyi Zhu", "Yifan Wang", "Jianjun Zhou", "Wenzheng Chang", "Yang Zhou", "Zizun Li", "Junyi Chen", "Chunhua Shen", "Jiangmiao Pang", "Tong He"], "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project Page: this https URL", "url": "http://arxiv.org/abs/2503.18945v3", "summary": "The integration of geometric reconstruction and generative modeling remains a\ncritical challenge in developing AI systems capable of human-like spatial\nreasoning. This paper proposes Aether, a unified framework that enables\ngeometry-aware reasoning in world models by jointly optimizing three core\ncapabilities: (1) 4D dynamic reconstruction, (2) action-conditioned video\nprediction, and (3) goal-conditioned visual planning. Through task-interleaved\nfeature learning, Aether achieves synergistic knowledge sharing across\nreconstruction, prediction, and planning objectives. Building upon video\ngeneration models, our framework demonstrates zero-shot synthetic-to-real\ngeneralization despite never observing real-world data during training.\nFurthermore, our approach achieves zero-shot generalization in both action\nfollowing and reconstruction tasks, thanks to its intrinsic geometric modeling.\nNotably, even without real-world data, its reconstruction performance is\ncomparable with or even better than that of domain-specific models.\nAdditionally, Aether employs camera trajectories as geometry-informed action\nspaces, enabling effective action-conditioned prediction and visual planning.\nWe hope our work inspires the community to explore new frontiers in\nphysically-reasonable world modeling and its applications.", "comment": "Project Page: https://aether-world.github.io/", "pdf_url": "http://arxiv.org/pdf/2503.18945v3", "cate": "cs.CV", "date": "2025-03-24", "updated": "2025-07-28"}
{"id": "2507.20059", "title": "RAG in the Wild: On the (In)effectiveness of LLMs with Mixture-of-Knowledge Retrieval Augmentation", "authors": ["Ran Xu", "Yuchen Zhuang", "Yue Yu", "Haoyu Wang", "Wenqi Shi", "Carl Yang"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Work in Progress. Code will be published at: this https URL", "url": "http://arxiv.org/abs/2507.20059v1", "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nintegrating external knowledge retrieved at inference time. While RAG\ndemonstrates strong performance on benchmarks largely derived from\ngeneral-domain corpora like Wikipedia, its effectiveness under realistic,\ndiverse retrieval scenarios remains underexplored. We evaluated RAG systems\nusing MassiveDS, a large-scale datastore with mixture of knowledge, and\nidentified critical limitations: retrieval mainly benefits smaller models,\nrerankers add minimal value, and no single retrieval source consistently\nexcels. Moreover, current LLMs struggle to route queries across heterogeneous\nknowledge sources. These findings highlight the need for adaptive retrieval\nstrategies before deploying RAG in real-world settings. Our code and data can\nbe found at https://github.com/ritaranx/RAG_in_the_Wild.", "comment": "Work in Progress. Code will be published at:\n  https://github.com/ritaranx/RAG_in_the_Wild", "pdf_url": "http://arxiv.org/pdf/2507.20059v1", "cate": "cs.CL", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.20349", "title": "From Observations to Causations: A GNN-based Probabilistic Prediction Framework for Causal Discovery", "authors": ["Rezaur Rashid", "Gabriel Terejanu"], "categories": ["cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20349v1", "summary": "Causal discovery from observational data is challenging, especially with\nlarge datasets and complex relationships. Traditional methods often struggle\nwith scalability and capturing global structural information. To overcome these\nlimitations, we introduce a novel graph neural network (GNN)-based\nprobabilistic framework that learns a probability distribution over the entire\nspace of causal graphs, unlike methods that output a single deterministic\ngraph. Our framework leverages a GNN that encodes both node and edge attributes\ninto a unified graph representation, enabling the model to learn complex causal\nstructures directly from data. The GNN model is trained on a diverse set of\nsynthetic datasets augmented with statistical and information-theoretic\nmeasures, such as mutual information and conditional entropy, capturing both\nlocal and global data properties. We frame causal discovery as a supervised\nlearning problem, directly predicting the entire graph structure. Our approach\ndemonstrates superior performance, outperforming both traditional and recent\nnon-GNN-based methods, as well as a GNN-based approach, in terms of accuracy\nand scalability on synthetic and real-world datasets without further training.\nThis probabilistic framework significantly improves causal structure learning,\nwith broad implications for decision-making and scientific discovery across\nvarious fields.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20349v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2409.15737", "title": "Reinforcement Leaning for Infinite-Dimensional Systems", "authors": ["Wei Zhang", "Jr-Shin Li"], "categories": ["eess.SY", "cs.SY", "math.OC", "93A15", "I.2.8"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.15737v2", "summary": "Interest in reinforcement learning (RL) for massive-scale systems consisting\nof large populations of intelligent agents interacting with heterogeneous\nenvironments has witnessed a significant surge in recent years across diverse\nscientific domains. However, the large-scale nature of these systems often\nresults in high computational costs or compromised performance for most\nstate-of-the-art RL techniques. To address these challenges, we propose a novel\nRL architecture along with the derivation of effective algorithms to learn\noptimal policies for arbitrarily large systems of agents. In our formulation,\nwe model such a system as a parameterized control system defined on an\ninfinite-dimensional function space. We then develop a moment kernel transform\nto map the parameterized system and the value function into a reproducing\nkernel Hilbert space. This transformation generates a sequence of\nfinite-dimensional moment representations for the RL problem, which are\norganized into a filtrated structure. Leveraging this RL filtration, we develop\na hierarchical algorithm for learning optimal policies for the\ninfinite-dimensional parameterized system. We further enhance the efficiency of\nthe algorithm by exploiting early stopping at each hierarchy, which\ndemonstrates the fast convergence property of the algorithm through the\nconstruction of a convergent spectral sequence. The performance and efficiency\nof the proposed algorithm are validated using practical examples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.15737v2", "cate": "eess.SY", "date": "2024-09-24", "updated": "2025-07-28"}
{"id": "2507.06020", "title": "A Differential Evolution Algorithm with Neighbor-hood Mutation for DOA Estimation", "authors": ["Bo Zhou", "Kaijie Xu", "Yinghui Quan", "Mengdao Xing"], "categories": ["eess.SP", "cs.NE"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06020v2", "summary": "Two-dimensional (2D) Multiple Signal Classification algorithm is a powerful\ntechnique for high-resolution direction-of-arrival (DOA) estimation in array\nsignal processing. However, the exhaustive search over the 2D an-gular domain\nleads to high computa-tional cost, limiting its applicability in real-time\nscenarios. In this work, we reformulate the peak-finding process as a\nmultimodal optimization prob-lem, and propose a Differential Evolu-tion\nalgorithm with Neighborhood Mutation (DE-NM) to efficiently lo-cate multiple\nspectral peaks without requiring dense grid sampling. Simu-lation results\ndemonstrate that the proposed method achieves comparable estimation accuracy to\nthe traditional grid search, while significantly reduc-ing computation time.\nThis strategy presents a promising solution for real-time, high-resolution DOA\nestimation in practical applications. The imple-mentation code is available at\nhttps://github.com/zzb-nice/DOA_multimodel_optimize.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06020v2", "cate": "eess.SP", "date": "2025-07-08", "updated": "2025-07-26"}
{"id": "2507.20205", "title": "Signed Higher-Order Interactions for Brain Disorder Diagnosis via Multi-Channel Transformers", "authors": ["Dengyi Zhao", "Zhiheng Zhou", "Guiying Yan", "Dongxiao Yu", "Xingqin Qi"], "categories": ["q-bio.NC", "cs.GR"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20205v2", "summary": "Accurately characterizing higher-order interactions of brain regions and\nextracting interpretable organizational patterns from Functional Magnetic\nResonance Imaging data is crucial for brain disease diagnosis. Current\ngraph-based deep learning models primarily focus on pairwise or triadic\npatterns while neglecting signed higher-order interactions, limiting\ncomprehensive understanding of brain-wide communication. We propose HOI-Brain,\na novel computational framework leveraging signed higher-order interactions and\norganizational patterns in fMRI data for brain disease diagnosis. First, we\nintroduce a co-fluctuation measure based on Multiplication of Temporal\nDerivatives to detect higher-order interactions with temporal resolution. We\nthen distinguish positive and negative synergistic interactions, encoding them\nin signed weighted simplicial complexes to reveal brain communication insights.\nUsing Persistent Homology theory, we apply two filtration processes to these\ncomplexes to extract signed higher-dimensional neural organizations\nspatiotemporally. Finally, we propose a multi-channel brain Transformer to\nintegrate heterogeneous topological features. Experiments on Alzheimer' s\ndisease, Parkinson' s syndrome, and autism spectrum disorder datasets\ndemonstrate our framework' s superiority, effectiveness, and interpretability.\nThe identified key brain regions and higher-order patterns align with\nneuroscience literature, providing meaningful biological insights.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20205v2", "cate": "q-bio.NC", "date": "2025-07-27", "updated": "2025-07-29"}
{"id": "2507.21770", "title": "Proposing a Semantic Movie Recommendation System Enhanced by ChatGPT's NLP Results", "authors": ["Ali Fallahi", "Azam Bastanfard", "Amineh Amini", "Hadi Saboohi"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      May 2023, 6 pages, 5 figures", "url": "http://arxiv.org/abs/2507.21770v1", "summary": "The importance of recommender systems on the web has grown, especially in the\nmovie industry, with a vast selection of options to watch. To assist users in\ntraversing available items and finding relevant results, recommender systems\nanalyze operational data and investigate users' tastes and habits. Providing\nhighly individualized suggestions can boost user engagement and satisfaction,\nwhich is one of the fundamental goals of the movie industry, significantly in\nonline platforms. According to recent studies and research, using\nknowledge-based techniques and considering the semantic ideas of the textual\ndata is a suitable way to get more appropriate results. This study provides a\nnew method for building a knowledge graph based on semantic information. It\nuses the ChatGPT, as a large language model, to assess the brief descriptions\nof movies and extract their tone of voice. Results indicated that using the\nproposed method may significantly enhance accuracy rather than employing the\nexplicit genres supplied by the publishers.", "comment": "May 2023, 6 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.21770v1", "cate": "cs.IR", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21757", "title": "Non-periodic Fourier propagation algorithms for partial differential equations", "authors": ["Channa Hatharasinghe", "Run Yan Teh", "Jesse van Rhijn", "Peter D. Drummond", "Margaret D. Reid"], "categories": ["math.NA", "cs.NA", "math-ph", "math.MP"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21757v1", "summary": "Spectral methods for solving partial differential equations (PDEs) and\nstochastic partial differential equations (SPDEs) often use Fourier or\npolynomial spectral expansions on either uniform and non-uniform grids.\nHowever, while very widely used, especially for slowly-varying solutions,\nnon-uniform spatial grids can give larger spatial discretization errors if the\nsolutions change rapidly in space. Here, we implement a Fourier method that\nemploys fast trigonometric expansions on a uniform grid with non-periodic\nboundaries using fast discrete sine transforms (DST) or/and discrete cosine\ntransforms (DCT) to solve parabolic PDEs. We implement this method in two ways:\neither using a Fourier spectral derivative or a Fourier interaction picture\napproach. These methods can treat vector fields with a combination of Dirichlet\nand/or Neumann boundary conditions in one or more space dimensions. We use them\nto solve a variety of PDEs with analytical solutions, including the Peregrine\nsolitary wave solution. For the 1D heat equation problem, our method with an\ninteraction picture is accurate up to the machine precision. A soluble example\nof an SPDE with non-periodic boundaries is also treated. We compare the results\nobtained from these algorithms with those from publicly available solvers that\nuse either polynomial spectral or finite element methods. For problems with\nsolutions that vary rapidly in space, our method outperforms the other methods\nby recording lower spatial discretization errors, as well being faster in many\ncases, due to the efficiency improvements given by fast transforms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21757v1", "cate": "math.NA", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21642", "title": "Whilter: A Whisper-based Data Filter for \"In-the-Wild\" Speech Corpora Using Utterance-level Multi-Task Classification", "authors": ["William Ravenscroft", "George Close", "Kit Bower-Morris", "Jamie Stacey", "Dmitry Sityaev", "Kris Y. Hong"], "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted for Interspeech 2025", "url": "http://arxiv.org/abs/2507.21642v1", "summary": "Large-scale in-the-wild speech datasets have become more prevalent in recent\nyears due to increased interest in models that can learn useful features from\nunlabelled data for tasks such as speech recognition or synthesis. These\ndatasets often contain undesirable features, such as multiple speakers,\nnon-target languages, and music, which may impact model learning. The Whilter\nmodel is proposed as a multitask solution to identify these undesirable\nsamples. Whilter uses a Whisper encoder with an attention-based classifier to\nsolve five diverse classification problems at once. In addition, an annotated\ndataset is published for a subset of two popular in-the-wild corpora. Whilter\nachieves F1 scores above 85% and equal error rates of 6.5% to 7.8% for three of\nfive subtasks, outperforming a state-of-the-art BEATs classifier on\nspeech-specific classes, with a notable decrease in processing time compared to\na combination of single-task alternatives.", "comment": "Accepted for Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.21642v1", "cate": "cs.SD", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21846", "title": "Probabilistic Active Goal Recognition", "authors": ["Chenyuan Zhang", "Cristian Rojas Cardenas", "Hamid Rezatofighi", "Mor Vered", "Buser Say"], "categories": ["cs.AI", "cs.SC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by KR2025", "url": "http://arxiv.org/abs/2507.21846v1", "summary": "In multi-agent environments, effective interaction hinges on understanding\nthe beliefs and intentions of other agents. While prior work on goal\nrecognition has largely treated the observer as a passive reasoner, Active Goal\nRecognition (AGR) focuses on strategically gathering information to reduce\nuncertainty. We adopt a probabilistic framework for Active Goal Recognition and\npropose an integrated solution that combines a joint belief update mechanism\nwith a Monte Carlo Tree Search (MCTS) algorithm, allowing the observer to plan\nefficiently and infer the actor's hidden goal without requiring domain-specific\nknowledge. Through comprehensive empirical evaluation in a grid-based domain,\nwe show that our joint belief update significantly outperforms passive goal\nrecognition, and that our domain-independent MCTS performs comparably to our\nstrong domain-specific greedy baseline. These results establish our solution as\na practical and robust framework for goal inference, advancing the field toward\nmore interactive and adaptive multi-agent systems.", "comment": "Accepted by KR2025", "pdf_url": "http://arxiv.org/pdf/2507.21846v1", "cate": "cs.AI", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2506.01665", "title": "Leveraging Analytic Gradients in Provably Safe Reinforcement Learning", "authors": ["Tim Walter", "Hannah Markgraf", "Jonathan Külz", "Matthias Althoff"], "categories": ["cs.LG", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      16 pages, 10 figures", "url": "http://arxiv.org/abs/2506.01665v2", "summary": "The deployment of autonomous robots in safety-critical applications requires\nsafety guarantees. Provably safe reinforcement learning is an active field of\nresearch that aims to provide such guarantees using safeguards. These\nsafeguards should be integrated during training to reduce the sim-to-real gap.\nWhile there are several approaches for safeguarding sampling-based\nreinforcement learning, analytic gradient-based reinforcement learning often\nachieves superior performance from fewer environment interactions. However,\nthere is no safeguarding approach for this learning paradigm yet. Our work\naddresses this gap by developing the first effective safeguard for analytic\ngradient-based reinforcement learning. We analyse existing, differentiable\nsafeguards, adapt them through modified mappings and gradient formulations, and\nintegrate them with a state-of-the-art learning algorithm and a differentiable\nsimulation. Using numerical experiments on three control tasks, we evaluate how\ndifferent safeguards affect learning. The results demonstrate safeguarded\ntraining without compromising performance.", "comment": "16 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2506.01665v2", "cate": "cs.LG", "date": "2025-06-02", "updated": "2025-07-27"}
{"id": "2507.20110", "title": "NeuroVoxel-LM: Language-Aligned 3D Perception via Dynamic Voxelization and Meta-Embedding", "authors": ["Shiyu Liu", "Lianlei Shan"], "categories": ["cs.CV", "cs.AI", "cs.LG", "I.4; I.5"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      **14 pages, 3 figures, 2 tables", "url": "http://arxiv.org/abs/2507.20110v1", "summary": "Recent breakthroughs in Visual Language Models (VLMs) and Multimodal Large\nLanguage Models (MLLMs) have significantly advanced 3D scene perception towards\nlanguage-driven cognition. However, existing 3D language models struggle with\nsparse, large-scale point clouds due to slow feature extraction and limited\nrepresentation accuracy. To address these challenges, we propose NeuroVoxel-LM,\na novel framework that integrates Neural Radiance Fields (NeRF) with dynamic\nresolution voxelization and lightweight meta-embedding. Specifically, we\nintroduce a Dynamic Resolution Multiscale Voxelization (DR-MSV) technique that\nadaptively adjusts voxel granularity based on geometric and structural\ncomplexity, reducing computational cost while preserving reconstruction\nfidelity. In addition, we propose the Token-level Adaptive Pooling for\nLightweight Meta-Embedding (TAP-LME) mechanism, which enhances semantic\nrepresentation through attention-based weighting and residual fusion.\nExperimental results demonstrate that DR-MSV significantly improves point cloud\nfeature extraction efficiency and accuracy, while TAP-LME outperforms\nconventional max-pooling in capturing fine-grained semantics from NeRF weights.", "comment": "**14 pages, 3 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.20110v1", "cate": "cs.CV", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20351", "title": "Computational Advantages of Multi-Grade Deep Learning: Convergence Analysis and Performance Insights", "authors": ["Ronglong Fang", "Yuesheng Xu"], "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20351v1", "summary": "Multi-grade deep learning (MGDL) has been shown to significantly outperform\nthe standard single-grade deep learning (SGDL) across various applications.\nThis work aims to investigate the computational advantages of MGDL focusing on\nits performance in image regression, denoising, and deblurring tasks, and\ncomparing it to SGDL. We establish convergence results for the gradient descent\n(GD) method applied to these models and provide mathematical insights into\nMGDL's improved performance. In particular, we demonstrate that MGDL is more\nrobust to the choice of learning rate under GD than SGDL. Furthermore, we\nanalyze the eigenvalue distributions of the Jacobian matrices associated with\nthe iterative schemes arising from the GD iterations, offering an explanation\nfor MGDL's enhanced training stability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20351v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2412.13564", "title": "The networked input-output economic problem", "authors": ["Minh Hoang Trinh", "Nhat-Minh Le-Phan", "Hyo-Sung Ahn"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      7 pages, 3 figures, preprint", "url": "http://arxiv.org/abs/2412.13564v2", "summary": "In this chapter, an input-output economic model with multiple interactive\neconomic systems is considered. The model captures the multi-dimensional nature\nof the economic sectors or industries in each economic system, the\ninterdependencies among industries within an economic system and across\ndifferent economic systems, and the influence of demand. To determine the\nequilibrium price structure of the model, a matrix-weighted updating algorithm\nis proposed. The equilibrium price structure is proved to be globally\nasymptotically achieved when certain joint conditions on the matrix-weighted\ngraph and the input-output matrices are satisfied. The theoretical results are\nthen supported by numerical simulations.", "comment": "7 pages, 3 figures, preprint", "pdf_url": "http://arxiv.org/pdf/2412.13564v2", "cate": "eess.SY", "date": "2024-12-18", "updated": "2025-07-28"}
{"id": "2507.14144", "title": "Recursive KalmanNet: Analyse des capacités de généralisation d'un réseau de neurones récurrent guidé par un filtre de Kalman", "authors": ["Cyril Falcon", "Hassan Mortada", "Mathéo Clavaud", "Jean-Philippe Michel"], "categories": ["eess.SP", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      4 pages, in French language. 4 figures. Accepted for publication in GRETSI 2025 proceedings", "url": "http://arxiv.org/abs/2507.14144v2", "summary": "The Recursive KalmanNet, recently introduced by the authors, is a recurrent\nneural network guided by a Kalman filter, capable of estimating the state\nvariables and error covariance of stochastic dynamic systems from noisy\nmeasurements, without prior knowledge of the noise characteristics. This paper\nexplores its generalization capabilities in out-of-distribution scenarios,\nwhere the temporal dynamics of the test measurements differ from those\nencountered during training.\n  Le Recursive KalmanNet, r\\'ecemment introduit par les auteurs, est un\nr\\'eseau de neurones r\\'ecurrent guid\\'e par un filtre de Kalman, capable\nd'estimer les variables d'\\'etat et la covariance des erreurs des syst\\`emes\ndynamiques stochastiques \\`a partir de mesures bruit\\'ees, sans connaissance\npr\\'ealable des caract\\'eristiques des bruits. Cet article explore ses\ncapacit\\'es de g\\'en\\'eralisation dans des sc\\'enarios hors distribution, o\\`u\nles dynamiques temporelles des mesures de test diff\\`erent de celles\nrencontr\\'ees \\`a l'entra\\^inement.", "comment": "4 pages, in French language. 4 figures. Accepted for publication in\n  GRETSI 2025 proceedings", "pdf_url": "http://arxiv.org/pdf/2507.14144v2", "cate": "eess.SP", "date": "2025-06-25", "updated": "2025-07-27"}
{"id": "2507.21884", "title": "Exploration on Demand: From Algorithmic Control to User Empowerment", "authors": ["Edoardo Bianchi"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21884v1", "summary": "Recommender systems often struggle with over-specialization, which severely\nlimits users' exposure to diverse content and creates filter bubbles that\nreduce serendipitous discovery. To address this fundamental limitation, this\npaper introduces an adaptive clustering framework with user-controlled\nexploration that effectively balances personalization and diversity in movie\nrecommendations. Our approach leverages sentence-transformer embeddings to\ngroup items into semantically coherent clusters through an online algorithm\nwith dynamic thresholding, thereby creating a structured representation of the\ncontent space. Building upon this clustering foundation, we propose a novel\nexploration mechanism that empowers users to control recommendation diversity\nby strategically sampling from less-engaged clusters, thus expanding their\ncontent horizons while preserving relevance. Experiments on the MovieLens\ndataset demonstrate the system's effectiveness, showing that exploration\nsignificantly reduces intra-list similarity from 0.34 to 0.26 while\nsimultaneously increasing unexpectedness to 0.73. Furthermore, our Large\nLanguage Model-based A/B testing methodology, conducted with 300 simulated\nusers, reveals that 72.7% of long-term users prefer exploratory recommendations\nover purely exploitative ones, providing strong evidence for the system's\nability to promote meaningful content discovery without sacrificing user\nsatisfaction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21884v1", "cate": "cs.IR", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21913", "title": "Fast multipole method for the Laplace equation in half plane with Robin boundary condition", "authors": ["Chunzhi Xiang", "Bo Wang", "Wenzhong Zhang", "Wei Cai"], "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "65D30, 65D32, 65R10, 41A60", "G.1.8; F.2.1; I.6.4"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21913v1", "summary": "In this paper, we present a fast multipole method (FMM) for solving the\ntwo-dimensional Laplace equation in a half-plane with Robin boundary\nconditions. The method is based on a novel expansion theory for the reaction\ncomponent of the Green's function. By applying the Fourier transform, the\nreaction field component is obtained in a Sommerfeld-type integral form. We\nderive far-field approximations and corresponding shifting and translation\noperators from the Fourier integral representation. The FMM for the reaction\ncomponent is then developed by using the new far-field approximations\nincorporated into the classic FMM framework in which the tree structure is\nconstructed from the original and image charges. Combining this with the\nstandard FMM for the free-space components, we develop a fast algorithm to\ncompute the interaction of the half plane Laplace Green's function. We prove\nthat the method exhibits exponential convergence, similar to the free-space\nFMM. Finally, numerical examples are presented to validate the theoretical\nresults and demonstrate that the FMM achieves $O(N)$ computational complexity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21913v1", "cate": "math.NA", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21138", "title": "TTS-1 Technical Report", "authors": ["Oleg Atamanenko", "Anna Chalova", "Joseph Coombes", "Nikki Cope", "Phillip Dang", "Zhifeng Deng", "Jimmy Du", "Michael Ermolenko", "Feifan Fan", "Yufei Feng", "Cheryl Fichter", "Pavel Filimonov", "Louis Fischer", "Kylan Gibbs", "Valeria Gusarova", "Pavel Karpik", "Andreas Assad Kottner", "Ian Lee", "Oliver Louie", "Jasmine Mai", "Mikhail Mamontov", "Suri Mao", "Nurullah Morshed", "Igor Poletaev", "Florin Radu", "Dmytro Semernia", "Evgenii Shingarev", "Vikram Sivaraja", "Peter Skirko", "Rinat Takhautdinov", "Robert Villahermosa", "Jean Wang"], "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      20 pages, 10 figures. For associated modeling and training code, see this https URL", "url": "http://arxiv.org/abs/2507.21138v1", "summary": "We introduce Inworld TTS-1, a set of two Transformer-based autoregressive\ntext-to-speech (TTS) models. Our largest model, TTS-1-Max, has 8.8B parameters\nand is designed for utmost quality and expressiveness in demanding\napplications. TTS-1 is our most efficient model, with 1.6B parameters, built\nfor real-time speech synthesis and on-device use cases. By scaling train-time\ncompute and applying a sequential process of pre-training, fine-tuning, and\nRL-alignment of the speech-language model (SpeechLM) component, both models\nachieve state-of-the-art performance on a variety of benchmarks, demonstrating\nexceptional quality relying purely on in-context learning of the speaker's\nvoice. Inworld TTS-1 and TTS-1-Max can generate high-resolution 48 kHz speech\nwith low latency, and support 11 languages with fine-grained emotional control\nand non-verbal vocalizations through audio markups. We additionally open-source\nour training and modeling code under an MIT license.", "comment": "20 pages, 10 figures. For associated modeling and training code, see\n  https://github.com/inworld-ai/tts", "pdf_url": "http://arxiv.org/pdf/2507.21138v1", "cate": "cs.CL", "date": "2025-07-22", "updated": "2025-07-22"}
{"id": "2507.05169", "title": "Critiques of World Models", "authors": ["Eric Xing", "Mingkai Deng", "Jinyu Hou", "Zhiting Hu"], "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05169v3", "summary": "World Model, the supposed algorithmic surrogate of the real-world environment\nwhich biological agents experience with and act upon, has been an emerging\ntopic in recent years because of the rising needs to develop virtual agents\nwith artificial (general) intelligence. There has been much debate on what a\nworld model really is, how to build it, how to use it, and how to evaluate it.\nIn this essay, starting from the imagination in the famed Sci-Fi classic Dune,\nand drawing inspiration from the concept of \"hypothetical thinking\" in\npsychology literature, we offer critiques of several schools of thoughts on\nworld modeling, and argue the primary goal of a world model to be simulating\nall actionable possibilities of the real world for purposeful reasoning and\nacting. Building on the critiques, we propose a new architecture for a\ngeneral-purpose world model, based on hierarchical, multi-level, and mixed\ncontinuous/discrete representations, and a generative and self-supervision\nlearning framework, with an outlook of a Physical, Agentic, and Nested (PAN)\nAGI system enabled by such a model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05169v3", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-27"}
{"id": "2507.20111", "title": "AI-Driven Generation of Old English: A Framework for Low-Resource Languages", "authors": ["Rodrigo Gabriel Salazar Alva", "Matías Nuñez", "Cristian López", "Javier Martín Arista"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20111v1", "summary": "Preserving ancient languages is essential for understanding humanity's\ncultural and linguistic heritage, yet Old English remains critically\nunder-resourced, limiting its accessibility to modern natural language\nprocessing (NLP) techniques. We present a scalable framework that uses advanced\nlarge language models (LLMs) to generate high-quality Old English texts,\naddressing this gap. Our approach combines parameter-efficient fine-tuning\n(Low-Rank Adaptation, LoRA), data augmentation via backtranslation, and a\ndual-agent pipeline that separates the tasks of content generation (in English)\nand translation (into Old English). Evaluation with automated metrics (BLEU,\nMETEOR, and CHRF) shows significant improvements over baseline models, with\nBLEU scores increasing from 26 to over 65 for English-to-Old English\ntranslation. Expert human assessment also confirms high grammatical accuracy\nand stylistic fidelity in the generated texts. Beyond expanding the Old English\ncorpus, our method offers a practical blueprint for revitalizing other\nendangered languages, effectively uniting AI innovation with the goals of\ncultural preservation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20111v1", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20357", "title": "Wafer Defect Root Cause Analysis with Partial Trajectory Regression", "authors": ["Kohei Miyaguchi", "Masao Joko", "Rebekah Sheraw", "Tsuyoshi Idé"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published as K. Miyaguchi, M. Joko, R. Sheraw and T. Idé, \"Wafer Defect Root Cause Analysis with Partial Trajectory Regression,'' Proceedings of the 36th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC 2025), Albany, NY, USA, 2025, pp. 1-6, doi: https://doi.org/10.1109/ASMC64512.2025.11010733", "url": "http://arxiv.org/abs/2507.20357v1", "summary": "Identifying upstream processes responsible for wafer defects is challenging\ndue to the combinatorial nature of process flows and the inherent variability\nin processing routes, which arises from factors such as rework operations and\nrandom process waiting times. This paper presents a novel framework for wafer\ndefect root cause analysis, called Partial Trajectory Regression (PTR). The\nproposed framework is carefully designed to address the limitations of\nconventional vector-based regression models, particularly in handling\nvariable-length processing routes that span a large number of heterogeneous\nphysical processes. To compute the attribution score of each process given a\ndetected high defect density on a specific wafer, we propose a new algorithm\nthat compares two counterfactual outcomes derived from partial process\ntrajectories. This is enabled by new representation learning methods, proc2vec\nand route2vec. We demonstrate the effectiveness of the proposed framework using\nreal wafer history data from the NY CREATES fab in Albany.", "comment": "Published as K. Miyaguchi, M. Joko, R. Sheraw and T. Id\\'e, \"Wafer\n  Defect Root Cause Analysis with Partial Trajectory Regression,'' Proceedings\n  of the 36th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC\n  2025), Albany, NY, USA, 2025, pp. 1-6, doi: 10.1109/ASMC64512.2025.11010733", "pdf_url": "http://arxiv.org/pdf/2507.20357v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2502.09877", "title": "Stretching Rubber, Not Budgets: Accurate Parking Utilization on a Shoestring", "authors": ["Christopher K. Allsup"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.09877v2", "summary": "Effective parking management is essential for ensuring safety and convenience\nin master-planned communities, particularly in active adult neighborhoods\nexperiencing rapid growth. Accurately assessing parking utilization is a\ncrucial first step in planning for future demand, but data collection methods\ncan be costly and labor-intensive. This paper presents a low-cost yet highly\naccurate methodology for measuring parking utilization using pneumatic road\ntubes connected to portable traffic counters from JAMAR Technologies, Inc. By\nintegrating results from JAMAR's analysis tool with custom Python scripting,\nthe methodology enables precise parking lot counts through automated parameter\noptimization and error correction. The system's efficiency allows for scalable\ndeployment without significant manual observation, reducing both costs and\ndisruptions to daily operations. Using Tellico Village as a case study, this\neffort demonstrates that community planners can obtain actionable parking\ninsights on a limited budget, empowering them to make informed decisions about\ncapacity expansion and facility scheduling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.09877v2", "cate": "eess.SY", "date": "2025-02-14", "updated": "2025-07-25"}
{"id": "2407.19299", "title": "The Impact of LoRA Adapters on LLMs for Clinical Text Classification Under Computational and Data Constraints", "authors": ["Thanh-Dung Le", "Ti Ti Nguyen", "Vu Nguyen Ha", "Symeon Chatzinotas", "Philippe Jouvet", "Rita Noumeir"], "categories": ["cs.CL", "eess.SP"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted for publication in the IEEE Access", "url": "http://arxiv.org/abs/2407.19299v3", "summary": "Fine-tuning Large Language Models (LLMs) for clinical Natural Language\nProcessing (NLP) poses significant challenges due to domain gap, limited data,\nand stringent hardware constraints. In this study, we evaluate four adapter\ntechniques-Adapter, Lightweight, TinyAttention, and Gated Residual Network\n(GRN) - equivalent to Low-Rank Adaptation (LoRA), for clinical note\nclassification under real-world, resource-constrained conditions. All\nexperiments were conducted on a single NVIDIA Quadro P620 GPU (2 GB VRAM, 512\nCUDA cores, 1.386 TFLOPS FP32), limiting batch sizes to <8 sequences and\nmaximum sequence length to 256 tokens. Our clinical corpus comprises only 580\n000 tokens, several orders of magnitude smaller than standard LLM pre-training\ndatasets. We fine-tuned three biomedical pre-trained LLMs (CamemBERT-bio,\nAliBERT, DrBERT) and two lightweight Transformer models trained from scratch.\nResults show that 1) adapter structures provide no consistent gains when\nfine-tuning biomedical LLMs under these constraints, and 2) simpler\nTransformers, with minimal parameter counts and training times under six hours,\noutperform adapter-augmented LLMs, which required over 1000 GPU-hours. Among\nadapters, GRN achieved the best metrics (accuracy, precision, recall, F1 =\n0.88). These findings demonstrate that, in low-resource clinical settings with\nlimited data and compute, lightweight Transformers trained from scratch offer a\nmore practical and efficient solution than large LLMs, while GRN remains a\nviable adapter choice when minimal adaptation is needed.", "comment": "Accepted for publication in the IEEE Access", "pdf_url": "http://arxiv.org/pdf/2407.19299v3", "cate": "cs.CL", "date": "2024-07-27", "updated": "2025-07-28"}
{"id": "2507.21939", "title": "The Curious Case of High-Dimensional Indexing as a File Structure: A Case Study of eCP-FS", "authors": ["Omar Shahbaz Khan", "Gylfi Þór Guðmundsson", "Björn Þór Jónsson"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21939v1", "summary": "Modern analytical pipelines routinely deploy multiple deep learning and\nretrieval models that rely on approximate nearest-neighbor (ANN) indexes to\nsupport efficient similarity-based search. While many state-of-the-art\nANN-indexes are memory-based (e.g., HNSW and IVF), using multiple ANN indexes\ncreates a competition for limited GPU/CPU memory resources, which in turn\nnecessitates disk-based index structures (e.g., DiskANN or eCP). In typical\nindex implementations, the main component is a complex data structure that is\nserialized to disk and is read either fully at startup time, for memory-based\nindexes, or incrementally at query time, for disk-based indexes. To visualize\nthe index structure, or analyze its quality, complex coding is needed that is\neither embedded in the index implementation or replicates the code that reads\nthe data structure. In this paper, we consider an alternative approach that\nmaps the data structure to a file structure, using a file library, making the\nindex easily readable for any programming language and even human-readable. The\ndisadvantage is that the serialized index is verbose, leading to overhead of\nsearching through the index. The question addressed in this paper is how severe\nthis performance penalty is. To that end, this paper presents eCP-FS, a\nfile-based implementation of eCP, a well-known disk-based ANN index. A\ncomparison with state-of-the-art indexes shows that while eCP-FS is slower, the\nimplementation is nevertheless somewhat competitive even when memory is not\nconstrained. In a memory-constrained scenario, eCP-FS offers a minimal memory\nfootprint, making it ideal for resource-constrained or multi-index\nenvironments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21939v1", "cate": "cs.IR", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21948", "title": "Structure-preserving nodal DG method for Euler equations with gravity II: general equilibrium states", "authors": ["Yuchang Liu", "Wei Guo", "Yan Jiang", "Mengping Zhang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21948v1", "summary": "We develop an entropy-stable nodal discontinuous Galerkin (DG) scheme for the\nEuler equations with gravity, which is also well-balanced with respect to\ngeneral equilibrium solutions, including both hydrostatic and moving\nequilibria. The core of our approach lies in a novel treatment of the\ngravitational source term, combining entropy-conservative numerical fluxes with\na linear entropy correction. In addition, the proposed formulation is carefully\ndesigned to ensure compatibility with a positivity-preserving limiter. We\nprovide a rigorous theoretical analysis to establish the accuracy and\nstructure-preserving properties of the proposed scheme. Extensive numerical\nexperiments confirm the robustness and efficiency of the scheme.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21948v1", "cate": "math.NA", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21331", "title": "A Deep Learning Automatic Speech Recognition Model for Shona Language", "authors": ["Leslie Wellington Sirora", "Mainford Mutandavari"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21331v1", "summary": "This study presented the development of a deep learning-based Automatic\nSpeech Recognition system for Shona, a low-resource language characterized by\nunique tonal and grammatical complexities. The research aimed to address the\nchallenges posed by limited training data, lack of labelled data, and the\nintricate tonal nuances present in Shona speech, with the objective of\nachieving significant improvements in recognition accuracy compared to\ntraditional statistical models. The research first explored the feasibility of\nusing deep learning to develop an accurate ASR system for Shona. Second, it\ninvestigated the specific challenges involved in designing and implementing\ndeep learning architectures for Shona speech recognition and proposed\nstrategies to mitigate these challenges. Lastly, it compared the performance of\nthe deep learning-based model with existing statistical models in terms of\naccuracy. The developed ASR system utilized a hybrid architecture consisting of\na Convolutional Neural Network for acoustic modelling and a Long Short-Term\nMemory network for language modelling. To overcome the scarcity of data, data\naugmentation techniques and transfer learning were employed. Attention\nmechanisms were also incorporated to accommodate the tonal nature of Shona\nspeech. The resulting ASR system achieved impressive results, with a Word Error\nRate of 29%, Phoneme Error Rate of 12%, and an overall accuracy of 74%. These\nmetrics indicated the potential of deep learning to enhance ASR accuracy for\nunder-resourced languages like Shona. This study contributed to the advancement\nof ASR technology for under-resourced languages like Shona, ultimately\nfostering improved accessibility and communication for Shona speakers\nworldwide.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21331v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.12898", "title": "Vidar: Embodied Video Diffusion Model for Generalist Bimanual Manipulation", "authors": ["Yao Feng", "Hengkai Tan", "Xinyi Mao", "Guodong Liu", "Shuhe Huang", "Chendong Xiang", "Hang Su", "Jun Zhu"], "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12898v2", "summary": "Bimanual robotic manipulation, which involves the coordinated control of two\nrobotic arms, is foundational for solving challenging tasks. Despite recent\nprogress in general-purpose manipulation, data scarcity and embodiment\nheterogeneity remain serious obstacles to further scaling up in bimanual\nsettings. In this paper, we introduce Video Diffusion for Action Reasoning\n(Vidar), a two-stage framework that leverages large-scale, diffusion-based\nvideo pre-training and a novel masked inverse dynamics model for action\nprediction. We pre-train the video diffusion model on 750K multi-view videos\nfrom three real-world bimanual robot platforms, utilizing a unified observation\nspace that encodes robot, camera, task, and scene contexts. Our masked inverse\ndynamics model learns masks to extract action-relevant information from\ngenerated trajectories without requiring pixel-level labels, and the masks can\neffectively generalize to unseen backgrounds. Our experiments demonstrate that\nwith only 20 minutes of human demonstrations on an unseen robot platform (only\n1% of typical data requirements), Vidar generalizes to unseen tasks and\nbackgrounds with strong semantic understanding, surpassing state-of-the-art\nmethods. Our findings highlight the potential of video foundation models,\ncoupled with masked action prediction, to enable scalable and generalizable\nrobotic manipulation in diverse real-world settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12898v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-27"}
{"id": "2507.20118", "title": "Iterative Pretraining Framework for Interatomic Potentials", "authors": ["Taoyong Cui", "Zhongyao Wang", "Dongzhan Zhou", "Yuqiang Li", "Lei Bai", "Wanli Ouyang", "Mao Su", "Shufei Zhang"], "categories": ["physics.comp-ph", "cs.AI"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20118v1", "summary": "Machine learning interatomic potentials (MLIPs) enable efficient molecular\ndynamics (MD) simulations with ab initio accuracy and have been applied across\nvarious domains in physical science. However, their performance often relies on\nlarge-scale labeled training data. While existing pretraining strategies can\nimprove model performance, they often suffer from a mismatch between the\nobjectives of pretraining and downstream tasks or rely on extensive labeled\ndatasets and increasingly complex architectures to achieve broad\ngeneralization. To address these challenges, we propose Iterative Pretraining\nfor Interatomic Potentials (IPIP), a framework designed to iteratively improve\nthe predictive performance of MLIP models. IPIP incorporates a forgetting\nmechanism to prevent iterative training from converging to suboptimal local\nminima. Unlike general-purpose foundation models, which frequently underperform\non specialized tasks due to a trade-off between generality and system-specific\naccuracy, IPIP achieves higher accuracy and efficiency using lightweight\narchitectures. Compared to general-purpose force fields, this approach achieves\nover 80% reduction in prediction error and up to 4x speedup in the challenging\nMo-S-O system, enabling fast and accurate simulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20118v1", "cate": "physics.comp-ph", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20362", "title": "MH-GIN: Multi-scale Heterogeneous Graph-based Imputation Network for AIS Data (Extended Version)", "authors": ["Hengyu Liu", "Tianyi Li", "Yuqiang He", "Kristian Torp", "Yushuai Li", "Christian S. Jensen"], "categories": ["cs.LG", "cs.DB"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18 pages, 4 figures", "url": "http://arxiv.org/abs/2507.20362v1", "summary": "Location-tracking data from the Automatic Identification System, much of\nwhich is publicly available, plays a key role in a range of maritime safety and\nmonitoring applications. However, the data suffers from missing values that\nhamper downstream applications. Imputing the missing values is challenging\nbecause the values of different heterogeneous attributes are updated at diverse\nrates, resulting in the occurrence of multi-scale dependencies among\nattributes. Existing imputation methods that assume similar update rates across\nattributes are unable to capture and exploit such dependencies, limiting their\nimputation accuracy. We propose MH-GIN, a Multi-scale Heterogeneous Graph-based\nImputation Network that aims improve imputation accuracy by capturing\nmulti-scale dependencies. Specifically, MH-GIN first extracts multi-scale\ntemporal features for each attribute while preserving their intrinsic\nheterogeneous characteristics. Then, it constructs a multi-scale heterogeneous\ngraph to explicitly model dependencies between heterogeneous attributes to\nenable more accurate imputation of missing values through graph propagation.\nExperimental results on two real-world datasets find that MH-GIN is capable of\nan average 57% reduction in imputation errors compared to state-of-the-art\nmethods, while maintaining computational efficiency. The source code and\nimplementation details of MH-GIN are publicly available\nhttps://github.com/hyLiu1994/MH-GIN.", "comment": "18 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.20362v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2504.06369", "title": "Restoring Feasibility in Power Grid Optimization: A Counterfactual ML Approach", "authors": ["Mostafa Mohammadian", "Anna Van Boven", "Kyri Baker"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.06369v2", "summary": "Electric power grids are essential components of modern life, delivering\nreliable power to end-users while adhering to a multitude of engineering\nconstraints and requirements. In grid operations, the Optimal Power Flow\nproblem plays a key role in determining cost-effective generator dispatch that\nsatisfies load demands and operational limits. However, due to stressed\noperating conditions, volatile demand profiles, and increased generation from\nintermittent energy sources, this optimization problem may become infeasible,\nposing risks such as voltage instability and line overloads. This study\nproposes a learning framework that combines machine learning with\ncounterfactual explanations to automatically diagnose and restore feasibility\nin the OPF problem. Our method provides transparent and actionable insights by\nmethodically identifying infeasible conditions and suggesting minimal demand\nresponse actions. We evaluate the proposed approach on IEEE 30-bus and 300-bus\nsystems, demonstrating its capability to recover feasibility with high success\nrates and generating diverse corrective options, appropriate for real-time\ndecision-making. These preliminary findings illustrate the potential of\ncombining classical optimization with explainable AI techniques to enhance grid\nreliability and resilience.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.06369v2", "cate": "eess.SY", "date": "2025-04-08", "updated": "2025-07-25"}
{"id": "2507.21110", "title": "SemRAG: Semantic Knowledge-Augmented RAG for Improved Question-Answering", "authors": ["Kezhen Zhong", "Basem Suleiman", "Abdelkarim Erradi", "Shijing Chen"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      16 pages, 12 figures", "url": "http://arxiv.org/abs/2507.21110v1", "summary": "This paper introduces SemRAG, an enhanced Retrieval Augmented Generation\n(RAG) framework that efficiently integrates domain-specific knowledge using\nsemantic chunking and knowledge graphs without extensive fine-tuning.\nIntegrating domain-specific knowledge into large language models (LLMs) is\ncrucial for improving their performance in specialized tasks. Yet, existing\nadaptations are computationally expensive, prone to overfitting and limit\nscalability. To address these challenges, SemRAG employs a semantic chunking\nalgorithm that segments documents based on the cosine similarity from sentence\nembeddings, preserving semantic coherence while reducing computational\noverhead. Additionally, by structuring retrieved information into knowledge\ngraphs, SemRAG captures relationships between entities, improving retrieval\naccuracy and contextual understanding. Experimental results on MultiHop RAG and\nWikipedia datasets demonstrate SemRAG has significantly enhances the relevance\nand correctness of retrieved information from the Knowledge Graph,\noutperforming traditional RAG methods. Furthermore, we investigate the\noptimization of buffer sizes for different data corpus, as optimizing buffer\nsizes tailored to specific datasets can further improve retrieval performance,\nas integration of knowledge graphs strengthens entity relationships for better\ncontextual comprehension. The primary advantage of SemRAG is its ability to\ncreate an efficient, accurate domain-specific LLM pipeline while avoiding\nresource-intensive fine-tuning. This makes it a practical and scalable approach\naligned with sustainability goals, offering a viable solution for AI\napplications in domain-specific fields.", "comment": "16 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.21110v1", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.21574", "title": "Distributionally Robust Shape and Topology Optimization", "authors": ["Charles Dapogny", "Julien Prando", "Boris Thibert"], "categories": ["math.OC", "cs.NA", "math.NA"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21574v1", "summary": "This article aims to introduce the paradigm of distributional robustness from\nthe field of convex optimization to tackle optimal design problems under\nuncertainty. We consider realistic situations where the physical model, and\nthereby the cost function of the design to be minimized depend on uncertain\nparameters. The probability distribution of the latter is itself known\nimperfectly, through a nominal law, reconstructed from a few observed samples.\nThe distributionally robust optimal design problem is an intricate bilevel\nprogram which consists in minimizing the worst value of a statistical quantity\nof the cost function (typically, its expectation) when the law of the uncertain\nparameters belongs to a certain ``ambiguity set''. We address three classes of\nsuch problems: firstly, this ambiguity set is made of the probability laws\nwhose Wasserstein distance to the nominal law is less than a given threshold;\nsecondly, the ambiguity set is based on the first- and second-order moments of\nthe actual and nominal probability laws. Eventually, a statistical quantity of\nthe cost other than its expectation is made robust with respect to the law of\nthe parameters, namely its conditional value at risk. Using techniques from\nconvex duality, we derive tractable, single-level reformulations of these\nproblems, framed over augmented sets of variables. Our methods are essentially\nagnostic of the optimal design framework; they are described in a unifying\nabstract framework, before being applied to multiple situations in\ndensity-based topology optimization and in geometric shape optimization.\nSeveral numerical examples are discussed in two and three space dimensions to\nappraise the features of the proposed techniques.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21574v1", "cate": "math.OC", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21395", "title": "Sync-TVA: A Graph-Attention Framework for Multimodal Emotion Recognition with Cross-Modal Fusion", "authors": ["Zeyu Deng", "Yanhui Lu", "Jiashu Liao", "Shuang Wu", "Chongfeng Wei"], "categories": ["cs.MM", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21395v1", "summary": "Multimodal emotion recognition (MER) is crucial for enabling emotionally\nintelligent systems that perceive and respond to human emotions. However,\nexisting methods suffer from limited cross-modal interaction and imbalanced\ncontributions across modalities. To address these issues, we propose Sync-TVA,\nan end-to-end graph-attention framework featuring modality-specific dynamic\nenhancement and structured cross-modal fusion. Our design incorporates a\ndynamic enhancement module for each modality and constructs heterogeneous\ncross-modal graphs to model semantic relations across text, audio, and visual\nfeatures. A cross-attention fusion mechanism further aligns multimodal cues for\nrobust emotion inference. Experiments on MELD and IEMOCAP demonstrate\nconsistent improvements over state-of-the-art models in both accuracy and\nweighted F1 score, especially under class-imbalanced conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21395v1", "cate": "cs.MM", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.18661", "title": "Eyes Will Shut: A Vision-Based Next GPS Location Prediction Model by Reinforcement Learning from Visual Map Feed Back", "authors": ["Ruixing Zhang", "Yang Zhang", "Tongyu Zhu", "Leilei Sun", "Weifeng Lv"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.18661v2", "summary": "Next Location Prediction is a fundamental task in the study of human\nmobility, with wide-ranging applications in transportation planning, urban\ngovernance, and epidemic forecasting. In practice, when humans attempt to\npredict the next location in a trajectory, they often visualize the trajectory\non a map and reason based on road connectivity and movement trends. However,\nthe vast majority of existing next-location prediction models do not reason\nover maps \\textbf{in the way that humans do}. Fortunately, the recent\ndevelopment of Vision-Language Models (VLMs) has demonstrated strong\ncapabilities in visual perception and even visual reasoning. This opens up a\nnew possibility: by rendering both the road network and trajectory onto an\nimage and leveraging the reasoning abilities of VLMs, we can enable models to\nperform trajectory inference in a human-like manner. To explore this idea, we\nfirst propose a method called Vision-Guided Location Search (VGLS), which\nevaluates whether a general-purpose VLM is capable of trajectory-based\nreasoning without modifying any of its internal parameters. Based on insights\nfrom the VGLS results, we further propose our main approach: VLMLocPredictor,\nwhich is composed of two stages: In the first stage, we design two Supervised\nFine-Tuning (SFT) tasks that help the VLM understand road network and\ntrajectory structures and acquire basic reasoning ability on such visual\ninputs. In the second stage, we introduce Reinforcement Learning from Visual\nMap Feedback, enabling the model to self-improve its next-location prediction\nability through interaction with the environment. Experiments conducted on\ndatasets from four different cities show that our method achieves\nstate-of-the-art (SOTA) performance and exhibits superior cross-city\ngeneralization compared to other LLM-based approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.18661v2", "cate": "cs.CV", "date": "2025-07-23", "updated": "2025-07-28"}
{"id": "2507.20133", "title": "Sem-DPO: Mitigating Semantic Inconsistency in Preference Optimization for Prompt Engineering", "authors": ["Anas Mohamed", "Azal Ahmad Khan", "Xinran Wang", "Ahmad Faraz Khan", "Shuwen Ge", "Saman Bahzad Khan", "Ayaan Ahmad", "Ali Anwar"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20133v2", "summary": "Generative AI can now synthesize strikingly realistic images from text, yet\noutput quality remains highly sensitive to how prompts are phrased. Direct\nPreference Optimization (DPO) offers a lightweight, off-policy alternative to\nRL for automatic prompt engineering, but its token-level regularization leaves\nsemantic inconsistency unchecked as prompts that win higher preference scores\ncan still drift away from the user's intended meaning.\n  We introduce Sem-DPO, a variant of DPO that preserves semantic consistency\nyet retains its simplicity and efficiency. Sem-DPO adjusts the DPO loss using a\nweight based on how different the winning prompt is from the original, reducing\nthe impact of training examples that are semantically misaligned. We provide\nthe first analytical bound on semantic drift for preference-tuned prompt\ngenerators, showing that Sem-DPO keeps learned prompts within a provably\nbounded neighborhood of the original text. On three standard text-to-image\nprompt-optimization benchmarks and two language models, Sem-DPO achieves 8-12%\nhigher CLIP similarity and 5-9% higher human-preference scores (HPSv2.1,\nPickScore) than DPO, while also outperforming state-of-the-art baselines. These\nfindings suggest that strong flat baselines augmented with semantic weighting\nshould become the new standard for prompt-optimization studies and lay the\ngroundwork for broader, semantics-aware preference optimization in language\nmodels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20133v2", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-29"}
{"id": "2507.20364", "title": "Sequence-Aware Inline Measurement Attribution for Good-Bad Wafer Diagnosis", "authors": ["Kohei Miyaguchi", "Masao Joko", "Rebekah Sheraw", "Tsuyoshi Idé"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published as K. Miyaguchi, M. Joko, R. Sheraw and T. Idé, \"Sequence-Aware Inline Measurement Attribution for Good-Bad Wafer Diagnosis : DM: Big Data Management and Machine Learning,\" 2025 36th Annual SEMI Advanced Semiconductor Manufacturing Conference (ASMC), Albany, NY, USA, 2025, pp. 1-6, doi: https://doi.org/10.1109/ASMC64512.2025.11010308", "url": "http://arxiv.org/abs/2507.20364v1", "summary": "How can we identify problematic upstream processes when a certain type of\nwafer defect starts appearing at a quality checkpoint? Given the complexity of\nmodern semiconductor manufacturing, which involves thousands of process steps,\ncross-process root cause analysis for wafer defects has been considered highly\nchallenging. This paper proposes a novel framework called Trajectory Shapley\nAttribution (TSA), an extension of Shapley values (SV), a widely used\nattribution algorithm in explainable artificial intelligence research. TSA\novercomes key limitations of standard SV, including its disregard for the\nsequential nature of manufacturing processes and its reliance on an arbitrarily\nchosen reference point. We applied TSA to a good-bad wafer diagnosis task in\nexperimental front-end-of-line processes at the NY CREATES Albany NanoTech fab,\naiming to identify measurement items (serving as proxies for process\nparameters) most relevant to abnormal defect occurrence.", "comment": "Published as K. Miyaguchi, M. Joko, R. Sheraw and T. Id\\'e,\n  \"Sequence-Aware Inline Measurement Attribution for Good-Bad Wafer Diagnosis :\n  DM: Big Data Management and Machine Learning,\" 2025 36th Annual SEMI Advanced\n  Semiconductor Manufacturing Conference (ASMC), Albany, NY, USA, 2025, pp.\n  1-6, doi: 10.1109/ASMC64512.2025.11010308", "pdf_url": "http://arxiv.org/pdf/2507.20364v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2504.12736", "title": "Incorporating a Deep Neural Network into Moving Horizon Estimation for Embedded Thermal Torque Derating of an Electric Machine", "authors": ["Alexander Winkler", "Pranav Shah", "Katrin Baumgärtner", "Vasu Sharma", "David Gordon", "Jakob Andert"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      20 pages, 13 figures, data publication incl. all scripts and data available, published in Energies Journal", "url": "http://arxiv.org/abs/2504.12736v2", "summary": "This study presents a novel state estimation approach integrating Deep Neural\nNetworks (DNNs) into Moving Horizon Estimation (MHE). This is a shift from\nusing traditional physics-based models within MHE towards data-driven\ntechniques. Specifically, a Long Short-Term Memory (LSTM)-based DNN is trained\nusing synthetic data derived from a high-fidelity thermal model of a Permanent\nMagnet Synchronous Machine (PMSM), applied within a thermal derating torque\ncontrol strategy for battery electric vehicles. The trained DNN is directly\nembedded within an MHE formulation, forming a discrete-time nonlinear optimal\ncontrol problem (OCP) solved via the acados optimization framework.\nModel-in-the-Loop simulations demonstrate accurate temperature estimation even\nunder noisy sensor conditions and simulated sensor failures. Real-time\nimplementation on embedded hardware confirms practical feasibility, achieving\ncomputational performance exceeding real-time requirements threefold. By\nintegrating the learned LSTM-based dynamics directly into MHE, this work\nachieves state estimation accuracy, robustness, and adaptability while reducing\nmodeling efforts and complexity. Overall, the results highlight the\neffectiveness of combining model-based and data-driven methods in\nsafety-critical automotive control systems.", "comment": "20 pages, 13 figures, data publication incl. all scripts and data\n  available, published in Energies Journal", "pdf_url": "http://arxiv.org/pdf/2504.12736v2", "cate": "eess.SY", "date": "2025-04-17", "updated": "2025-07-28"}
{"id": "2507.21340", "title": "StructText: A Synthetic Table-to-Text Approach for Benchmark Generation with Multi-Dimensional Evaluation", "authors": ["Satyananda Kashyap", "Sola Shirai", "Nandana Mihindukulasooriya", "Horst Samulowitz"], "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Data available: this https URL and code available at: this https URL", "url": "http://arxiv.org/abs/2507.21340v1", "summary": "Extracting structured information from text, such as key-value pairs that\ncould augment tabular data, is quite useful in many enterprise use cases.\nAlthough large language models (LLMs) have enabled numerous automated pipelines\nfor converting natural language into structured formats, there is still a lack\nof benchmarks for evaluating their extraction quality, especially in specific\ndomains or focused documents specific to a given organization. Building such\nbenchmarks by manual annotations is labour-intensive and limits the size and\nscalability of the benchmarks. In this work, we present StructText, an\nend-to-end framework for automatically generating high-fidelity benchmarks for\nkey-value extraction from text using existing tabular data. It uses available\ntabular data as structured ground truth, and follows a two-stage\n``plan-then-execute'' pipeline to synthetically generate corresponding\nnatural-language text. To ensure alignment between text and structured source,\nwe introduce a multi-dimensional evaluation strategy that combines (a)\nLLM-based judgments on factuality, hallucination, and coherence and (b)\nobjective extraction metrics measuring numeric and temporal accuracy. We\nevaluated the proposed method on 71,539 examples across 49 datasets. Results\nreveal that while LLMs achieve strong factual accuracy and avoid hallucination,\nthey struggle with narrative coherence in producing extractable text. Notably,\nmodels presume numerical and temporal information with high fidelity yet this\ninformation becomes embedded in narratives that resist automated extraction. We\nrelease a framework, including datasets, evaluation tools, and baseline\nextraction systems, to support continued research.", "comment": "Data available:\n  https://huggingface.co/datasets/ibm-research/struct-text and code available\n  at: https://github.com/ibm/struct-text", "pdf_url": "http://arxiv.org/pdf/2507.21340v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21791", "title": "The Performance of Low-Synchronization Variants of Reorthogonalized Block Classical Gram--Schmidt", "authors": ["Erin Carson", "Yuxin Ma"], "categories": ["cs.DC", "cs.NA", "math.NA", "65F10, 65F25, 65G50, 65Y20"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      7 pages, 2 figures", "url": "http://arxiv.org/abs/2507.21791v1", "summary": "Numerous applications, such as Krylov subspace solvers, make extensive use of\nthe block classical Gram-Schmidt (BCGS) algorithm and its reorthogonalized\nvariants for orthogonalizing a set of vectors. For large-scale problems in\ndistributed memory settings, the communication cost, particularly the global\nsynchronization cost, is a major performance bottleneck. In recent years, many\nlow-synchronization BCGS variants have been proposed in an effort to reduce the\nnumber of synchronization points. The work [E. Carson, Y. Ma, arXiv preprint\n2411.07077] recently proposed stable one-synchronization and\ntwo-synchronization variants of BCGS, i.e., BCGSI+P-1S and BCGSI+P-2S. In this\nwork, we evaluate the performance of BCGSI+P-1S and BCGSI+P-2S on a distributed\nmemory system compared to other well-known low-synchronization BCGS variants.\nIn comparison to the classical reorthogonalized BCGS algorithm (BCGSI+),\nnumerical experiments demonstrate that BCGSI+P-1S and BCGSI+P-2S can achieve up\nto 4 times and 2 times speedups, respectively, and perform similarly to other\n(less stable) one-synchronization and two-synchronization variants. BCGSI+P-1S\nand BCGSI+P-2S are therefore recommended as the best choice in practice for\ncomputing an economic QR factorization on distributed memory systems due to\ntheir superior stability when compared to other variants with the same\nsynchronization cost.", "comment": "7 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.21791v1", "cate": "cs.DC", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21522", "title": "Model-free Speculative Decoding for Transformer-based ASR with Token Map Drafting", "authors": ["Tuan Vu Ho", "Hiroaki Kokubo", "Masaaki Yamamoto", "Yohei Kawaguchi"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at EUSIPCO 2025", "url": "http://arxiv.org/abs/2507.21522v1", "summary": "End-to-end automatic speech recognition (ASR) systems based on transformer\narchitectures, such as Whisper, offer high transcription accuracy and\nrobustness. However, their autoregressive decoding is computationally\nexpensive, hence limiting deployment on CPU-based and resource-constrained\ndevices. Speculative decoding (SD) mitigates this issue by using a smaller\ndraft model to propose candidate tokens, which are then verified by the main\nmodel. However, this approach is impractical for devices lacking hardware\naccelerators like GPUs. To address this, we propose \\emph{Token Map Drafting},\na model-free SD technique that eliminates the need for a separate draft model.\nInstead, we leverage a precomputed n-gram token map derived from\ndomain-specific training data, enabling efficient speculative decoding with\nminimal overhead. Our method significantly accelerates ASR inference in\nstructured, low-perplexity domains without sacrificing transcription accuracy.\nExperimental results demonstrate decoding speed-ups of $1.27\\times$ on the\nCI-AVSR dataset and $1.37\\times$ on our internal dataset without degrading\nrecognition accuracy. Additionally, our approach achieves a $10\\%$ absolute\nimprovement in decoding speed over the Distill-spec baseline running on CPU,\nhighlighting its effectiveness for on-device ASR applications.", "comment": "Accepted at EUSIPCO 2025", "pdf_url": "http://arxiv.org/pdf/2507.21522v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21300", "title": "Simultaneous improvement of control and estimation for battery management systems", "authors": ["Mohammad S. Ramadan", "Marfred Barrera", "Mihai Anitescu", "Sylvia Herbert"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21300v1", "summary": "The state of charge of battery systems is an important metric typically\nestimated by observation models, represented by open-circuit voltage graphs.\nThese observation models are often nonlinear in the state of charge, resulting\nin varying observability from a state estimation perspective. In this paper, we\nemploy a stochastic optimal control (also known as dual control) approach to\nsimultaneously satisfy the control objective in the state of charge of battery\nsystems and improve estimation accuracy. This is achieved implicitly by\nprioritizing trajectories that pass through high-observability regions of the\nstate space, thereby improving the quality of future measurements. We apply our\nalgorithm to a numerical simulation of a multi-battery system and show a\nstatistical improvement in both the control objective and the state estimation\nerror.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21300v1", "cate": "eess.SY", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20136", "title": "Multi-Stage Verification-Centric Framework for Mitigating Hallucination in Multi-Modal RAG", "authors": ["Baiyu Chen", "Wilson Wongso", "Xiaoqian Hu", "Yue Tan", "Flora Salim"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      KDD Cup 2025 Meta CRAG-MM Challenge", "url": "http://arxiv.org/abs/2507.20136v1", "summary": "This paper presents the technical solution developed by team CRUISE for the\nKDD Cup 2025 Meta Comprehensive RAG Benchmark for Multi-modal, Multi-turn\n(CRAG-MM) challenge. The challenge aims to address a critical limitation of\nmodern Vision Language Models (VLMs): their propensity to hallucinate,\nespecially when faced with egocentric imagery, long-tail entities, and complex,\nmulti-hop questions. This issue is particularly problematic in real-world\napplications where users pose fact-seeking queries that demand high factual\naccuracy across diverse modalities. To tackle this, we propose a robust,\nmulti-stage framework that prioritizes factual accuracy and truthfulness over\ncompleteness. Our solution integrates a lightweight query router for\nefficiency, a query-aware retrieval and summarization pipeline, a dual-pathways\ngeneration and a post-hoc verification. This conservative strategy is designed\nto minimize hallucinations, which incur a severe penalty in the competition's\nscoring metric. Our approach achieved 3rd place in Task 1, demonstrating the\neffectiveness of prioritizing answer reliability in complex multi-modal RAG\nsystems. Our implementation is available at\nhttps://github.com/Breezelled/KDD-Cup-2025-Meta-CRAG-MM .", "comment": "KDD Cup 2025 Meta CRAG-MM Challenge", "pdf_url": "http://arxiv.org/pdf/2507.20136v1", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20369", "title": "Clustering by Attention: Leveraging Prior Fitted Transformers for Data Partitioning", "authors": ["Ahmed Shokry", "Ayman Khalafallah"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20369v1", "summary": "Clustering is a core task in machine learning with wide-ranging applications\nin data mining and pattern recognition. However, its unsupervised nature makes\nit inherently challenging. Many existing clustering algorithms suffer from\ncritical limitations: they often require careful parameter tuning, exhibit high\ncomputational complexity, lack interpretability, or yield suboptimal accuracy,\nespecially when applied to large-scale datasets. In this paper, we introduce a\nnovel clustering approach based on meta-learning. Our approach eliminates the\nneed for parameter optimization while achieving accuracy that outperforms\nstate-of-the-art clustering techniques. The proposed technique leverages a few\npre-clustered samples to guide the clustering process for the entire dataset in\na single forward pass. Specifically, we employ a pre-trained Prior-Data Fitted\nTransformer Network (PFN) to perform clustering. The algorithm computes\nattention between the pre-clustered samples and the unclustered samples,\nallowing it to infer cluster assignments for the entire dataset based on the\nlearned relation. We theoretically and empirically demonstrate that, given just\na few pre-clustered examples, the model can generalize to accurately cluster\nthe rest of the dataset. Experiments on challenging benchmark datasets show\nthat our approach can successfully cluster well-separated data without any\npre-clustered samples, and significantly improves performance when a few\nclustered samples are provided. We show that our approach is superior to the\nstate-of-the-art techniques. These results highlight the effectiveness and\nscalability of our approach, positioning it as a promising alternative to\nexisting clustering techniques.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20369v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2506.17275", "title": "Conformal Safety Shielding for Imperfect-Perception Agents", "authors": ["William Scarbro", "Calum Imrie", "Sinem Getir Yaman", "Kavan Fatehi", "Corina S. Pasareanu", "Radu Calinescu", "Ravi Mangal"], "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      32 pages; Equal contribution by W. Scarbro and C. Imrie; Accepted at 25th International Conference on Runtime Verification, 2025 (RV25)", "url": "http://arxiv.org/abs/2506.17275v2", "summary": "We consider the problem of safe control in discrete autonomous agents that\nuse learned components for imperfect perception (or more generally, state\nestimation) from high-dimensional observations. We propose a shield\nconstruction that provides run-time safety guarantees under perception errors\nby restricting the actions available to an agent, modeled as a Markov decision\nprocess, as a function of the state estimates. Our construction uses conformal\nprediction for the perception component, which guarantees that for each\nobservation, the predicted set of estimates includes the actual state with a\nuser-specified probability. The shield allows an action only if it is allowed\nfor all the estimates in the predicted set, resulting in local safety. We also\narticulate and prove a global safety property of existing shield constructions\nfor perfect-perception agents bounding the probability of reaching unsafe\nstates if the agent always chooses actions prescribed by the shield. We\nillustrate our approach with a case-study of an experimental autonomous system\nthat guides airplanes on taxiways using high-dimensional perception DNNs.", "comment": "32 pages; Equal contribution by W. Scarbro and C. Imrie; Accepted at\n  25th International Conference on Runtime Verification, 2025 (RV25)", "pdf_url": "http://arxiv.org/pdf/2506.17275v2", "cate": "eess.SY", "date": "2025-06-12", "updated": "2025-07-26"}
{"id": "2507.21474", "title": "Hebbian Memory-Augmented Recurrent Networks: Engram Neurons in Deep Learning", "authors": ["Daniel Szelogowski"], "categories": ["cs.NE", "cs.AI", "cs.IR", "cs.LG", "q-bio.NC", "I.2.0; I.2.4; I.2.6; I.2.m; E.1; E.2; E.4; H.3; J.3; J.4"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      20 pages, 11 figures, 4 tables", "url": "http://arxiv.org/abs/2507.21474v1", "summary": "Despite success across diverse tasks, current artificial recurrent network\narchitectures rely primarily on implicit hidden-state memories, limiting their\ninterpretability and ability to model long-range dependencies. In contrast,\nbiological neural systems employ explicit, associative memory traces (i.e.,\nengrams) strengthened through Hebbian synaptic plasticity and activated\nsparsely during recall. Motivated by these neurobiological insights, we\nintroduce the Engram Neural Network (ENN), a novel recurrent architecture\nincorporating an explicit, differentiable memory matrix with Hebbian plasticity\nand sparse, attention-driven retrieval mechanisms. The ENN explicitly models\nmemory formation and recall through dynamic Hebbian traces, improving\ntransparency and interpretability compared to conventional RNN variants. We\nevaluate the ENN architecture on three canonical benchmarks: MNIST digit\nclassification, CIFAR-10 image sequence modeling, and WikiText-103 language\nmodeling. Our empirical results demonstrate that the ENN achieves accuracy and\ngeneralization performance broadly comparable to classical RNN, GRU, and LSTM\narchitectures, with all models converging to similar accuracy and perplexity on\nthe large-scale WikiText-103 task. At the same time, the ENN offers significant\nenhancements in interpretability through observable memory dynamics. Hebbian\ntrace visualizations further reveal biologically plausible, structured memory\nformation processes, validating the potential of neuroscience-inspired\nmechanisms to inform the development of more interpretable and robust deep\nlearning models.", "comment": "20 pages, 11 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.21474v1", "cate": "cs.NE", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2403.07358", "title": "A novel fast iterative moment method for near-continuum flows", "authors": ["Guanghan Li", "Chunwu Wang", "Zhicheng Hu"], "categories": ["math.NA", "cs.NA", "76P05, 65B99, 65M55"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.07358v2", "summary": "We develop a novel fast iterative moment method for the steady-state\nsimulation of near-continuum flows, which are modeled by the high-order moment\nsystem derived from the Boltzmann-BGK equation. The fast convergence of the\npresent method is mainly achieved by alternately solving the moment system and\nthe hydrodynamic equations with consistent constitutive relations and boundary\nconditions. To be specific, the consistent hydrodynamic equations are solved in\neach alternating iteration to obtain improved predictions of macroscopic\nquantities, which are subsequently utilized to expedite the evolution of the\nmoment system. Additionally, a semi-implicit scheme treating the collision term\nimplicitly is introduced for the moment system. The resulting alternating\niteration can be further accelerated by employing the Gauss-Seidel method with\na cell-by-cell sweeping strategy. It is also noteworthy that such an\nalternating iteration works well with the nonlinear multigrid method. Numerical\nexperiments for planar Couette flow, shock structure, and lid-driven cavity\nflow are carried out to investigate the performance of the proposed fast\niterative moment method. All results show impressive efficiency and robustness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.07358v2", "cate": "math.NA", "date": "2024-03-12", "updated": "2025-07-29"}
{"id": "2507.21591", "title": "Hierarchical Graph Neural Network for Compressed Speech Steganalysis", "authors": ["Mustapha Hemis", "Hamza Kheddar", "Mohamed Chahine Ghanem", "Bachir Boudraa"], "categories": ["cs.CR", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21591v1", "summary": "Steganalysis methods based on deep learning (DL) often struggle with\ncomputational complexity and challenges in generalizing across different\ndatasets. Incorporating a graph neural network (GNN) into steganalysis schemes\nenables the leveraging of relational data for improved detection accuracy and\nadaptability. This paper presents the first application of a Graph Neural\nNetwork (GNN), specifically the GraphSAGE architecture, for steganalysis of\ncompressed voice over IP (VoIP) speech streams. The method involves\nstraightforward graph construction from VoIP streams and employs GraphSAGE to\ncapture hierarchical steganalysis information, including both fine grained\ndetails and high level patterns, thereby achieving high detection accuracy.\nExperimental results demonstrate that the developed approach performs well in\nuncovering quantization index modulation (QIM)-based steganographic patterns in\nVoIP signals. It achieves detection accuracy exceeding 98 percent even for\nshort 0.5 second samples, and 95.17 percent accuracy under challenging\nconditions with low embedding rates, representing an improvement of 2.8 percent\nover the best performing state of the art methods. Furthermore, the model\nexhibits superior efficiency, with an average detection time as low as 0.016\nseconds for 0.5-second samples an improvement of 0.003 seconds. This makes it\nefficient for online steganalysis tasks, providing a superior balance between\ndetection accuracy and efficiency under the constraint of short samples with\nlow embedding rates.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21591v1", "cate": "cs.CR", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21441", "title": "Ensemble Control of Stochastic Oscillators via Periodic and Feedback Control", "authors": ["Kaito Ito", "Haruhiro Kume", "Hideaki Ishii"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      16 pages", "url": "http://arxiv.org/abs/2507.21441v1", "summary": "We address the problem of steering the phase distribution of oscillators all\nreceiving the same control input to a given target distribution. In a large\npopulation limit, the distribution of oscillators can be described by a\nprobability density. Then, our problem can be seen as that of ensemble control\nwith a constraint on the steady-state density. In particular, we consider the\ncase where oscillators are subject to stochastic noise, for which the\ntheoretical understanding is still lacking. First, we characterize the\nreachability of the phase distribution under periodic feedforward control via\nthe Fourier coefficients of the target density and the phase sensitivity\nfunction of oscillators. This enables us to design a periodic input that makes\nthe stationary distribution of oscillators closest to the target by solving a\nconvex optimization problem. Next, we devise an ensemble control method\ncombining periodic and feedback control, where the feedback component is\ndesigned to accelerate the convergence of the distribution of oscillators. We\nexhibit some convergence results for the proposed method, including a result\nthat holds even under measurement errors in the phase distribution. The\neffectiveness of the proposed method is demonstrated by a numerical example.", "comment": "16 pages", "pdf_url": "http://arxiv.org/pdf/2507.21441v1", "cate": "eess.SY", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20145", "title": "Multi-Agent Interactive Question Generation Framework for Long Document Understanding", "authors": ["Kesen Wang", "Daulet Toibazar", "Abdulrahman Alfulayt", "Abdulaziz S. Albadawi", "Ranya A. Alkahtani", "Asma A. Ibrahim", "Haneen A. Alhomoud", "Sherif Mohamed", "Pedro J. Moreno"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20145v1", "summary": "Document Understanding (DU) in long-contextual scenarios with complex layouts\nremains a significant challenge in vision-language research. Although Large\nVision-Language Models (LVLMs) excel at short-context DU tasks, their\nperformance declines in long-context settings. A key limitation is the scarcity\nof fine-grained training data, particularly for low-resource languages such as\nArabic. Existing state-of-the-art techniques rely heavily on human annotation,\nwhich is costly and inefficient. We propose a fully automated, multi-agent\ninteractive framework to generate long-context questions efficiently. Our\napproach efficiently generates high-quality single- and multi-page questions\nfor extensive English and Arabic documents, covering hundreds of pages across\ndiverse domains. This facilitates the development of LVLMs with enhanced\nlong-context understanding ability. Experimental results in this work have\nshown that our generated English and Arabic questions\n(\\textbf{AraEngLongBench}) are quite challenging to major open- and\nclose-source LVLMs. The code and data proposed in this work can be found in\nhttps://github.com/wangk0b/Multi_Agentic_QA_Long_Doc.git. Sample Question and\nAnswer (QA) pairs and structured system prompts can be found in the Appendix.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20145v1", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20373", "title": "WBHT: A Generative Attention Architecture for Detecting Black Hole Anomalies in Backbone Networks", "authors": ["Kiymet Kaya", "Elif Ak", "Sule Gunduz Oguducu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20373v1", "summary": "We propose the Wasserstein Black Hole Transformer (WBHT) framework for\ndetecting black hole (BH) anomalies in communication networks. These anomalies\ncause packet loss without failure notifications, disrupting connectivity and\nleading to financial losses. WBHT combines generative modeling, sequential\nlearning, and attention mechanisms to improve BH anomaly detection. It\nintegrates a Wasserstein generative adversarial network with attention\nmechanisms for stable training and accurate anomaly identification. The model\nuses long-short-term memory layers to capture long-term dependencies and\nconvolutional layers for local temporal patterns. A latent space encoding\nmechanism helps distinguish abnormal network behavior. Tested on real-world\nnetwork data, WBHT outperforms existing models, achieving significant\nimprovements in F1 score (ranging from 1.65% to 58.76%). Its efficiency and\nability to detect previously undetected anomalies make it a valuable tool for\nproactive network monitoring and security, especially in mission-critical\nnetworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20373v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.03240", "title": "A Hybrid Mean Field Framework for Aggregators Participating in Wholesale Electricity Markets", "authors": ["Jun He", "Andrew L. Liu"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03240v2", "summary": "The rapid growth of distributed energy resources (DERs), including rooftop\nsolar and energy storage, is transforming the grid edge, where distributed\ntechnologies and customer-side systems increasingly interact with the broader\npower grid. DER aggregators, entities that coordinate and optimize the actions\nof many small-scale DERs, play a key role in this transformation. This paper\npresents a hybrid Mean-Field Control (MFC) and Mean-Field Game (MFG) framework\nfor integrating DER aggregators into wholesale electricity markets. Unlike\ntraditional approaches that treat market prices as exogenous, our model\ncaptures the feedback between aggregators' strategies and locational marginal\nprices (LMPs) of electricity. The MFC component optimizes DER operations within\neach aggregator, while the MFG models strategic interactions among multiple\naggregators. To account for various uncertainties, we incorporate reinforcement\nlearning (RL), which allows aggregators to learn optimal bidding strategies in\ndynamic market conditions. We prove the existence and uniqueness of a\nmean-field equilibrium and validate the framework through a case study of the\nOahu Island power system. Results show that our approach reduces price\nvolatility and improves market efficiency, offering a scalable and\ndecentralized solution for DER integration in wholesale markets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03240v2", "cate": "eess.SY", "date": "2025-07-04", "updated": "2025-07-26"}
{"id": "2507.21490", "title": "Conversations over Clicks: Impact of Chatbots on Information Search in Interdisciplinary Learning", "authors": ["Hannah Kim", "Sergei L. Kosakovsky Pond", "Stephen MacNeil"], "categories": ["cs.HC", "cs.CY", "cs.IR", "J.3; K.3.2"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      9 pages, 2 tables, 3 figures, 2025 ASEE/IEEE Frontiers in Education (FIE) Conference preprint", "url": "http://arxiv.org/abs/2507.21490v1", "summary": "This full research paper investigates the impact of generative AI (GenAI) on\nthe learner experience, with a focus on how learners engage with and utilize\nthe information it provides. In e-learning environments, learners often need to\nnavigate a complex information space on their own. This challenge is further\ncompounded in interdisciplinary fields like bioinformatics, due to the varied\nprior knowledge and backgrounds. In this paper, we studied how GenAI influences\ninformation search in bioinformatics research: (1) How do interactions with a\nGenAI chatbot influence learner orienteering behaviors?; and (2) How do\nlearners identify information scent in GenAI chatbot responses? We adopted an\nautoethnographic approach to investigate these questions. GenAI was found to\nsupport orienteering once a learning plan was established, but it was\ncounterproductive prior to that. Moreover, traditionally value-rich information\nsources such as bullet points and related terms proved less effective when\napplied to GenAI responses. Information scents were primarily recognized\nthrough the presence or absence of prior knowledge of the domain. These\nfindings suggest that GenAI should be adopted into e-learning environments with\ncaution, particularly in interdisciplinary learning contexts.", "comment": "9 pages, 2 tables, 3 figures, 2025 ASEE/IEEE Frontiers in Education\n  (FIE) Conference preprint", "pdf_url": "http://arxiv.org/pdf/2507.21490v1", "cate": "cs.HC", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2408.15393", "title": "Linear Stability Analysis of Physics-Informed Random Projection Neural Networks for ODEs", "authors": ["Gianluca Fabiani", "Erik Bollt", "Constantinos Siettos", "Athanasios N. Yannacopoulos"], "categories": ["math.NA", "cs.LG", "cs.NA", "math.DS", "65L20, 68T07, 65L04, 37N30"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      17 pages, 3 figures", "url": "http://arxiv.org/abs/2408.15393v2", "summary": "We present a linear stability analysis of physics-informed random projection\nneural networks (PI-RPNNs), for the numerical solution of {the initial value\nproblem (IVP)} of (stiff) ODEs. We begin by proving that PI-RPNNs are uniform\napproximators of the solution to ODEs. We then provide a constructive proof\ndemonstrating that PI-RPNNs offer consistent and asymptotically stable\nnumerical schemes, thus convergent schemes. In particular, we prove that\nmulti-collocation PI-RPNNs guarantee asymptotic stability. Our theoretical\nresults are illustrated via numerical solutions of benchmark examples including\nindicative comparisons with the backward Euler method, the midpoint method, the\ntrapezoidal rule, the 2-stage Gauss scheme, and the 2- and 3-stage Radau\nschemes.", "comment": "17 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2408.15393v2", "cate": "math.NA", "date": "2024-08-27", "updated": "2025-07-29"}
{"id": "2409.09545", "title": "Multi-Microphone and Multi-Modal Emotion Recognition in Reverberant Environment", "authors": ["Ohad Cohen", "Gershon Hazan", "Sharon Gannot"], "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      5 pages, 4 figures, 2 tables. Accepted to EUSIPCO 2025", "url": "http://arxiv.org/abs/2409.09545v3", "summary": "This paper presents a Multi-modal Emotion Recognition (MER) system designed\nto enhance emotion recognition accuracy in challenging acoustic conditions. Our\napproach combines a modified and extended Hierarchical Token-semantic Audio\nTransformer (HTS-AT) for multi-channel audio processing with an R(2+1)D\nConvolutional Neural Networks (CNN) model for video analysis. We evaluate our\nproposed method on a reverberated version of the Ryerson audio-visual database\nof emotional speech and song (RAVDESS) dataset using synthetic and real-world\nRoom Impulse Responsess (RIRs). Our results demonstrate that integrating audio\nand video modalities yields superior performance compared to uni-modal\napproaches, especially in challenging acoustic conditions. Moreover, we show\nthat the multimodal (audiovisual) approach that utilizes multiple microphones\noutperforms its single-microphone counterpart.", "comment": "5 pages, 4 figures, 2 tables. Accepted to EUSIPCO 2025", "pdf_url": "http://arxiv.org/pdf/2409.09545v3", "cate": "cs.SD", "date": "2024-09-14", "updated": "2025-07-28"}
{"id": "2507.21579", "title": "Experimental Implementation and Validation of Predictor-Based CACC for Vehicular Platoons With Distinct Actuation Delays", "authors": ["Amirhossein Samii", "Redmer de Haan", "Nikolaos Bekiaris-Liberis"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at the IEEE Conference on Decision and Control (CDC) 2025. 8 pages", "url": "http://arxiv.org/abs/2507.21579v1", "summary": "We provide experimental validation, in a pair of vehicles, of a recently\nintroduced predictor-based cooperative adaptive cruise control (CACC) design,\ndeveloped for achieving delay compensation in heterogeneous vehicular platoons\nsubject to long actuation delays that may be distinct for each individual\nvehicle. We provide the explicit formulae of the control design that is\nimplemented, accounting for the effect of zero-order hold and sampled\nmeasurements; as well as we obtain vehicle and string stability conditions\nnumerically, via derivation of the transfer functions relating the speeds of\npairs of consecutive vehicles. We also present consistent simulation results\nfor a platoon with a larger number of vehicles, under digital implementation of\nthe controller. Both the simulation and experimental results confirm the\neffectiveness of the predictor-based CACC design in guaranteeing individual\nvehicle stability, string stability, and tracking, despite long/distinct\nactuation delays.", "comment": "Accepted for presentation at the IEEE Conference on Decision and\n  Control (CDC) 2025. 8 pages", "pdf_url": "http://arxiv.org/pdf/2507.21579v1", "cate": "eess.SY", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20152", "title": "Goal Alignment in LLM-Based User Simulators for Conversational AI", "authors": ["Shuhaib Mehri", "Xiaocheng Yang", "Takyoung Kim", "Gokhan Tur", "Shikib Mehri", "Dilek Hakkani-Tür"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20152v1", "summary": "User simulators are essential to conversational AI, enabling scalable agent\ndevelopment and evaluation through simulated interactions. While current Large\nLanguage Models (LLMs) have advanced user simulation capabilities, we reveal\nthat they struggle to consistently demonstrate goal-oriented behavior across\nmulti-turn conversations--a critical limitation that compromises their\nreliability in downstream applications. We introduce User Goal State Tracking\n(UGST), a novel framework that tracks user goal progression throughout\nconversations. Leveraging UGST, we present a three-stage methodology for\ndeveloping user simulators that can autonomously track goal progression and\nreason to generate goal-aligned responses. Moreover, we establish comprehensive\nevaluation metrics for measuring goal alignment in user simulators, and\ndemonstrate that our approach yields substantial improvements across two\nbenchmarks (MultiWOZ 2.4 and {\\tau}-Bench). Our contributions address a\ncritical gap in conversational AI and establish UGST as an essential framework\nfor developing goal-aligned user simulators.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20152v1", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20378", "title": "Set-based Implicit Likelihood Inference of Galaxy Cluster Mass", "authors": ["Bonny Y. Wang", "Leander Thiele"], "categories": ["cs.LG", "astro-ph.CO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      5 pages, 4 figures; accepted as a spotlight talk at ICML-colocated ML4Astro 2025 workshop", "url": "http://arxiv.org/abs/2507.20378v1", "summary": "We present a set-based machine learning framework that infers posterior\ndistributions of galaxy cluster masses from projected galaxy dynamics. Our\nmodel combines Deep Sets and conditional normalizing flows to incorporate both\npositional and velocity information of member galaxies to predict residual\ncorrections to the $M$-$\\sigma$ relation for improved interpretability. Trained\non the Uchuu-UniverseMachine simulation, our approach significantly reduces\nscatter and provides well-calibrated uncertainties across the full mass range\ncompared to traditional dynamical estimates.", "comment": "5 pages, 4 figures; accepted as a spotlight talk at ICML-colocated\n  ML4Astro 2025 workshop", "pdf_url": "http://arxiv.org/pdf/2507.20378v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.09646", "title": "Learning Koopman Models From Data Under General Noise Conditions", "authors": ["Lucian Cristian Iacob", "Máté Szécsi", "Gerben Izaak Beintema", "Maarten Schoukens", "Roland Tóth"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Submitted to SIAM Journal on Applied Dynamical Systems (SIADS)", "url": "http://arxiv.org/abs/2507.09646v2", "summary": "This paper presents a novel identification approach of Koopman models of\nnonlinear systems with inputs under rather general noise conditions. The method\nuses deep state-space encoders based on the concept of state reconstructability\nand an efficient multiple-shooting formulation of the squared loss of the\nprediction error to estimate the dynamics and the lifted state from\ninput-output data. Furthermore, the Koopman model structure includes an\ninnovation noise term that is used to handle process and measurement noise. It\nis shown that the proposed approach is statistically consistent and\ncomputationally efficient due to the multiple-shooting formulation where, on\nsubsections of the data, multi-step prediction errors can be calculated in\nparallel. The latter allows for efficient batch optimization of the network\nparameters and, at the same time, excellent long-term prediction capabilities\nof the obtained models. The performance of the approach is illustrated by\nnonlinear benchmark examples.", "comment": "Submitted to SIAM Journal on Applied Dynamical Systems (SIADS)", "pdf_url": "http://arxiv.org/pdf/2507.09646v2", "cate": "eess.SY", "date": "2025-07-13", "updated": "2025-07-28"}
{"id": "2507.21903", "title": "Who's important? -- SUnSET: Synergistic Understanding of Stakeholder, Events and Time for Timeline Generation", "authors": ["Tiviatis Sim", "Kaiwen Yang", "Shen Xin", "Kenji Kawaguchi"], "categories": ["cs.SI", "cs.CL", "cs.IR"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21903v1", "summary": "As news reporting becomes increasingly global and decentralized online,\ntracking related events across multiple sources presents significant\nchallenges. Existing news summarization methods typically utilizes Large\nLanguage Models and Graphical methods on article-based summaries. However, this\nis not effective since it only considers the textual content of similarly dated\narticles to understand the gist of the event. To counteract the lack of\nanalysis on the parties involved, it is essential to come up with a novel\nframework to gauge the importance of stakeholders and the connection of related\nevents through the relevant entities involved. Therefore, we present SUnSET:\nSynergistic Understanding of Stakeholder, Events and Time for the task of\nTimeline Summarization (TLS). We leverage powerful Large Language Models (LLMs)\nto build SET triplets and introduced the use of stakeholder-based ranking to\nconstruct a $Relevancy$ metric, which can be extended into general situations.\nOur experimental results outperform all prior baselines and emerged as the new\nState-of-the-Art, highlighting the impact of stakeholder information within\nnews article.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21903v1", "cate": "cs.SI", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2411.19755", "title": "Explicit error bounds of the SE and DE formulas for integrals with logarithmic and algebraic singularity", "authors": ["Tomoaki Okayama", "Kosei Arakawa", "Ryo Kamigaki", "Eita Yabumoto"], "categories": ["math.NA", "cs.NA", "65D30, 65D32"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      Keyword: SE transformation, DE transformation, trapezoidal formula, error bound", "url": "http://arxiv.org/abs/2411.19755v4", "summary": "The single exponential (SE) and double exponential (DE) formulas are widely\nrecognized as efficient quadrature formulas for evaluating integrals with\nendpoint singularity. For integrals exhibiting algebraic singularity, explicit\nerror bounds in a computable form have been provided, enabling computations\nwith guaranteed accuracy. Such explicit error bounds have also been provided\nfor integrals exhibiting logarithmic singularity. However, these error bounds\nhave two points to be discussed. The first point is on overestimation of\ndivergence speed of logarithmic singularity. The second point is on the case\nwhere there exist both logarithmic and algebraic singularity. To address these\nissues, this study provides new error bounds for integrals with logarithmic and\nalgebraic singularity. Although existing and new error bounds described above\npertain to integrals over the finite interval, the SE and DE formulas are also\napplicable to integrals over the semi-infinite interval. On the basis of the\nnew results, this study provides new error bounds for integrals over the\nsemi-infinite interval with logarithmic and algebraic singularity at the\norigin.", "comment": "Keyword: SE transformation, DE transformation, trapezoidal formula,\n  error bound", "pdf_url": "http://arxiv.org/pdf/2411.19755v4", "cate": "math.NA", "date": "2024-11-29", "updated": "2025-07-29"}
{"id": "2502.05130", "title": "Latent Swap Joint Diffusion for 2D Long-Form Latent Generation", "authors": ["Yusheng Dai", "Chenxi Wang", "Chang Li", "Chen Wang", "Jun Du", "Kewei Li", "Ruoyu Wang", "Jiefeng Ma", "Lei Sun", "Jianqing Gao"], "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.MM", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.05130v3", "summary": "This paper introduces Swap Forward (SaFa), a modality-agnostic and efficient\nmethod to generate seamless and coherence long spectrum and panorama through\nlatent swap joint diffusion across multi-views. We first investigate the\nspectrum aliasing problem in spectrum-based audio generation caused by existing\njoint diffusion methods. Through a comparative analysis of the VAE latent\nrepresentation of Mel-spectra and RGB images, we identify that the failure\narises from excessive suppression of high-frequency components during the\nspectrum denoising process due to the averaging operator. To address this\nissue, we propose Self-Loop Latent Swap, a frame-level bidirectional swap\napplied to the overlapping region of adjacent views. Leveraging stepwise\ndifferentiated trajectories of adjacent subviews, this swap operator adaptively\nenhances high-frequency components and avoid spectrum distortion. Furthermore,\nto improve global cross-view consistency in non-overlapping regions, we\nintroduce Reference-Guided Latent Swap, a unidirectional latent swap operator\nthat provides a centralized reference trajectory to synchronize subview\ndiffusions. By refining swap timing and intervals, we can achieve a cross-view\nsimilarity-diversity balance in a forward-only manner. Quantitative and\nqualitative experiments demonstrate that SaFa significantly outperforms\nexisting joint diffusion methods and even training-based methods in audio\ngeneration using both U-Net and DiT models, along with effective longer length\nadaptation. It also adapts well to panorama generation, achieving comparable\nperformance with 2 $\\sim$ 20 $\\times$ faster speed and greater model\ngeneralizability. More generation demos are available at\nhttps://swapforward.github.io/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.05130v3", "cate": "cs.SD", "date": "2025-02-07", "updated": "2025-07-29"}
{"id": "2507.21667", "title": "Deep Neuro-Adaptive Sliding Mode Controller for Higher-Order Heterogeneous Nonlinear Multi-Agent Teams with Leader", "authors": ["Khushal Chaudhari", "Krishanu Nath", "Manas Kumar Bera"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21667v1", "summary": "This letter proposes a deep neural network (DNN)-based neuro-adaptive sliding\nmode control (SMC) strategy for leader-follower tracking in multi-agent systems\nwith higher-order, heterogeneous, nonlinear, and unknown dynamics under\nexternal disturbances. The DNN is used to compensate the unknown nonlinear\ndynamics with higher accuracy than shallow neural networks (NNs) and SMC\nensures robust tracking. This framework employs restricted potential functions\nwithin a set-theoretic paradigm to ensure system trajectories remain bounded\nwithin a compact set, improving robustness against approximation errors and\nexternal disturbances. The control scheme is grounded in non-smooth Lyapunov\nstability theory, with update laws derived for both inner and outer layer\nnetwork weights of DNN. A numerical example is simulated that showcases the\nproposed controller's effectiveness, adaptability, and robustness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21667v1", "cate": "eess.SY", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20156", "title": "Trust the Model: Compact VLMs as In-Context Judges for Image-Text Data Quality", "authors": ["Daulet Toibazar", "Kesen Wang", "Sherif Mohamed", "Abdulaziz Al-Badawi", "Abdulrahman Alfulayt", "Pedro J. Moreno"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20156v1", "summary": "Vision-language models (VLMs) extend the conventional large language models\nby integrating visual data, enabling richer multimodal reasoning and\nsignificantly broadens the practical applications of AI. However, including\nvisual inputs also brings new challenges in maintaining data quality. Empirical\nevidence consistently shows that carefully curated and representative training\nexamples often yield superior results compared to simply increasing the\nquantity of data. Inspired by this observation, we introduce a streamlined data\nfiltration framework that employs a compact VLM, fine-tuned on a high-quality\nimage-caption annotated dataset. This model effectively evaluates and filters\npotential training samples based on caption and image quality and alignment.\nUnlike previous approaches, which typically add auxiliary filtration modules on\ntop of existing full-scale VLMs, our method exclusively utilizes the inherent\nevaluative capability of a purpose-built small VLM. This strategy eliminates\nthe need for extra modules and reduces training overhead. Our lightweight model\nefficiently filters out inaccurate, noisy web data, improving image-text\nalignment and caption linguistic fluency. Experimental results show that\ndatasets underwent high-precision filtration using our compact VLM perform on\npar with, or even surpass, larger and noisier datasets gathered through\nhigh-volume web crawling. Thus, our method provides a lightweight yet robust\nsolution for building high-quality vision-language training corpora. \\\\\n\\textbf{Availability and implementation:} Our compact VLM filtration model,\ntraining data, utility scripts, and Supplementary data (Appendices) are freely\navailable at https://github.com/daulettoibazar/Compact_VLM_Filter.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20156v1", "cate": "cs.CV", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20433", "title": "FAST: Similarity-based Knowledge Transfer for Efficient Policy Learning", "authors": ["Alessandro Capurso", "Elia Piccoli", "Davide Bacciu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE Conference on Games (CoG) 2025", "url": "http://arxiv.org/abs/2507.20433v1", "summary": "Transfer Learning (TL) offers the potential to accelerate learning by\ntransferring knowledge across tasks. However, it faces critical challenges such\nas negative transfer, domain adaptation and inefficiency in selecting solid\nsource policies. These issues often represent critical problems in evolving\ndomains, i.e. game development, where scenarios transform and agents must\nadapt. The continuous release of new agents is costly and inefficient. In this\nwork we challenge the key issues in TL to improve knowledge transfer, agents\nperformance across tasks and reduce computational costs. The proposed\nmethodology, called FAST - Framework for Adaptive Similarity-based Transfer,\nleverages visual frames and textual descriptions to create a latent\nrepresentation of tasks dynamics, that is exploited to estimate similarity\nbetween environments. The similarity scores guides our method in choosing\ncandidate policies from which transfer abilities to simplify learning of novel\ntasks. Experimental results, over multiple racing tracks, demonstrate that FAST\nachieves competitive final performance compared to learning-from-scratch\nmethods while requiring significantly less training steps. These findings\nhighlight the potential of embedding-driven task similarity estimations.", "comment": "Accepted at IEEE Conference on Games (CoG) 2025", "pdf_url": "http://arxiv.org/pdf/2507.20433v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.14952", "title": "An approach to the LQG/LTR design problem with specifications for finite-dimensional SISO control systems", "authors": ["Mahyar Mahinzaeim", "Kamyar Mehran"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      typos corrected; keywords added", "url": "http://arxiv.org/abs/2507.14952v2", "summary": "This is an expository paper which discusses an approach to the LQG/LTR design\nproblem for finite-dimensional SISO control systems. The approach is based on\nthe utilisation of weighting augmentation for incorporating design\nspecifications into the framework of the LTR technique for LQG compensator\ndesign. The LQG compensator is to simultaneously meet given analytical low- and\nhigh-frequency design specifications expressed in terms of desirable\nsensitivity and controller noise sensitivity functions. The paper is aimed at\nnonspecialists and, in particular, practitioners in finite-dimensional LQG\ntheory interested in the design of feedback compensators for closed-loop\nperformance and robustness shaping of SISO control systems in realistic\nsituations. The proposed approach is illustrated by a detailed numerical\nexample: the torque control of a current-controlled DC motor with an\nelastically mounted rotor.", "comment": "typos corrected; keywords added", "pdf_url": "http://arxiv.org/pdf/2507.14952v2", "cate": "eess.SY", "date": "2025-07-20", "updated": "2025-07-28"}
{"id": "2507.21989", "title": "Benchmarking Filtered Approximate Nearest Neighbor Search Algorithms on Transformer-based Embedding Vectors", "authors": ["Patrick Iff", "Paul Bruegger", "Marcin Chrapek", "Maciej Besta", "Torsten Hoefler"], "categories": ["cs.DB", "cs.DS", "cs.IR"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21989v1", "summary": "Advances in embedding models for text, image, audio, and video drive progress\nacross multiple domains, including retrieval-augmented generation,\nrecommendation systems, vehicle/person reidentification, and face recognition.\nMany applications in these domains require an efficient method to retrieve\nitems that are close to a given query in the embedding space while satisfying a\nfilter condition based on the item's attributes, a problem known as Filtered\nApproximate Nearest Neighbor Search (FANNS). In this work, we present a\ncomprehensive survey and taxonomy of FANNS methods and analyze how they are\nbenchmarked in the literature. By doing so, we identify a key challenge in the\ncurrent FANNS landscape: the lack of diverse and realistic datasets,\nparticularly ones derived from the latest transformer-based text embedding\nmodels. To address this, we introduce a novel dataset consisting of embedding\nvectors for the abstracts of over 2.7 million research articles from the arXiv\nrepository, accompanied by 11 real-world attributes such as authors and\ncategories. We benchmark a wide range of FANNS methods on our novel dataset and\nfind that each method has distinct strengths and limitations; no single\napproach performs best across all scenarios. ACORN, for example, supports\nvarious filter types and performs reliably across dataset scales but is often\noutperformed by more specialized methods. SeRF shows excellent performance for\nrange filtering on ordered attributes but cannot handle categorical attributes.\nFiltered-DiskANN and UNG excel on the medium-scale dataset but fail on the\nlarge-scale dataset, highlighting the challenge posed by transformer-based\nembeddings, which are often more than an order of magnitude larger than earlier\nembeddings. We conclude that no universally best method exists.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21989v1", "cate": "cs.DB", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2501.06107", "title": "A domain decomposition strategy for natural imposition of mixed boundary conditions in port-Hamiltonian systems", "authors": ["S. D. M. de Jong", "A. Brugnoli", "R. Rashad", "Y. Zhang", "S. Stramigioli"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.06107v2", "summary": "In this contribution, a finite element scheme to impose mixed boundary\nconditions without introducing Lagrange multipliers is presented for wave\npropagation phenomena described as port-Hamiltonian systems. The strategy\nrelies on finite element exterior calculus and domain decomposition to\ninterconnect two systems with different causalities. The spatial domain is\nsplit into two parts by introducing an arbitrary interface. Each subdomain is\ndiscretized with a mixed finite element formulation that introduces a uniform\nboundary condition in a natural way as the input. In each subdomain the spaces\nare selected from a finite element subcomplex to obtain a stable\ndiscretization. The two systems are then interconnected together by making use\nof a feedback interconnection. This is achieved by discretizing the boundary\ninputs using appropriate spaces that couple the two formulations. The final\nsystems includes all boundary conditions explicitly and does not contain any\nLagrange multiplier. Each subdomain is integrated using an implicit midpoint\nscheme in an uncoupled way from the other by means of a leapfrog scheme. The\nproposed strategy is tested on two different examples: the Euler-Bernoulli beam\nand the wave equation. Numerical tests assess the conservation properties of\nthe scheme and the effectiveness of the methodology.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.06107v2", "cate": "math.NA", "date": "2025-01-10", "updated": "2025-07-29"}
{"id": "2507.08128", "title": "Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models", "authors": ["Arushi Goel", "Sreyan Ghosh", "Jaehyeon Kim", "Sonal Kumar", "Zhifeng Kong", "Sang-gil Lee", "Chao-Han Huck Yang", "Ramani Duraiswami", "Dinesh Manocha", "Rafael Valle", "Bryan Catanzaro"], "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Code, Datasets, and Models: this https URL ; Updates in v2: Updated results for new thinking mode ckpts, added qualitative figure, added note on fully open claim, add email ID for corresponding authors", "url": "http://arxiv.org/abs/2507.08128v2", "summary": "We present Audio Flamingo 3 (AF3), a fully open state-of-the-art (SOTA) large\naudio-language model that advances reasoning and understanding across speech,\nsound, and music. AF3 introduces: (i) AF-Whisper, a unified audio encoder\ntrained using a novel strategy for joint representation learning across all 3\nmodalities of speech, sound, and music; (ii) flexible, on-demand thinking,\nallowing the model to do chain-of-thought-type reasoning before answering;\n(iii) multi-turn, multi-audio chat; (iv) long audio understanding and reasoning\n(including speech) up to 10 minutes; and (v) voice-to-voice interaction. To\nenable these capabilities, we propose several large-scale training datasets\ncurated using novel strategies, including AudioSkills-XL, LongAudio-XL,\nAF-Think, and AF-Chat, and train AF3 with a novel five-stage curriculum-based\ntraining strategy. Trained on only open-source audio data, AF3 achieves new\nSOTA results on over 20+ (long) audio understanding and reasoning benchmarks,\nsurpassing both open-weight and closed-source models trained on much larger\ndatasets.", "comment": "Code, Datasets, and Models:\n  https://research.nvidia.com/labs/adlr/AF3/ ; Updates in v2: Updated results\n  for new thinking mode ckpts, added qualitative figure, added note on fully\n  open claim, add email ID for corresponding authors", "pdf_url": "http://arxiv.org/pdf/2507.08128v2", "cate": "cs.SD", "date": "2025-07-10", "updated": "2025-07-28"}
{"id": "2507.21669", "title": "Data-Driven Greenhouse Climate Regulation in Lettuce Cultivation Using BiLSTM and GRU Predictive Control", "authors": ["Soumo Emmanuel Arnaud", "Marcello Calisti", "Athanasios Polydoros"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21669v1", "summary": "Efficient greenhouse management is essential for sustainable food production\nin response to a growing global population. However, maintaining optimal indoor\nclimates requires significant energy and resources, making advanced control\nsystems critical for economic viability and environmental sustainability.\nTraditional greenhouse models are often complex and imprecise, limiting the\neffectiveness of conventional control strategies. To address these challenges,\nthis study investigates data-driven predictive control methods using Gated\nRecurrent Unit (GRU) and Long Short-Term Memory (LSTM) neural networks. Our\nexperiments showed that GRU-based predictive control reduced temperature and\nhumidity violations by up to 5\\% and required 40\\% less computation time than\nthe LSTM approach, all while maintaining equivalent economic performance and\ncrop yield. These findings demonstrate that GRU-based predictive control offers\na more efficient and practical solution for real-time greenhouse climate\nregulation in precision agriculture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21669v1", "cate": "eess.SY", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20174", "title": "LRR-Bench: Left, Right or Rotate? Vision-Language models Still Struggle With Spatial Understanding Tasks", "authors": ["Fei Kong", "Jinhao Duan", "Kaidi Xu", "Zhenhua Guo", "Xiaofeng Zhu", "Xiaoshuang Shi"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20174v1", "summary": "Real-world applications, such as autonomous driving and humanoid robot\nmanipulation, require precise spatial perception. However, it remains\nunderexplored how Vision-Language Models (VLMs) recognize spatial relationships\nand perceive spatial movement. In this work, we introduce a spatial evaluation\npipeline and construct a corresponding benchmark. Specifically, we categorize\nspatial understanding into two main types: absolute spatial understanding,\nwhich involves querying the absolute spatial position (e.g., left, right) of an\nobject within an image, and 3D spatial understanding, which includes movement\nand rotation. Notably, our dataset is entirely synthetic, enabling the\ngeneration of test samples at a low cost while also preventing dataset\ncontamination. We conduct experiments on multiple state-of-the-art VLMs and\nobserve that there is significant room for improvement in their spatial\nunderstanding abilities. Explicitly, in our experiments, humans achieve\nnear-perfect performance on all tasks, whereas current VLMs attain human-level\nperformance only on the two simplest tasks. For the remaining tasks, the\nperformance of VLMs is distinctly lower than that of humans. In fact, the\nbest-performing Vision-Language Models even achieve near-zero scores on\nmultiple tasks. The dataset and code are available on\nhttps://github.com/kong13661/LRR-Bench.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20174v1", "cate": "cs.CV", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20440", "title": "BioNeuralNet: A Graph Neural Network based Multi-Omics Network Data Analysis Tool", "authors": ["Vicente Ramos", "Sundous Hussein", "Mohamed Abdel-Hafiz", "Arunangshu Sarkar", "Weixuan Liu", "Katerina J. Kechris", "Russell P. Bowler", "Leslie Lange", "Farnoush Banaei-Kashani"], "categories": ["cs.LG", "q-bio.GN"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages, 1 figure, 2 tables; Software available on PyPI as BioNeuralNet. For documentation, tutorials, and workflows see this https URL", "url": "http://arxiv.org/abs/2507.20440v1", "summary": "Multi-omics data offer unprecedented insights into complex biological\nsystems, yet their high dimensionality, sparsity, and intricate interactions\npose significant analytical challenges. Network-based approaches have advanced\nmulti-omics research by effectively capturing biologically relevant\nrelationships among molecular entities. While these methods are powerful for\nrepresenting molecular interactions, there remains a need for tools\nspecifically designed to effectively utilize these network representations\nacross diverse downstream analyses. To fulfill this need, we introduce\nBioNeuralNet, a flexible and modular Python framework tailored for end-to-end\nnetwork-based multi-omics data analysis. BioNeuralNet leverages Graph Neural\nNetworks (GNNs) to learn biologically meaningful low-dimensional\nrepresentations from multi-omics networks, converting these complex molecular\nnetworks into versatile embeddings. BioNeuralNet supports all major stages of\nmulti-omics network analysis, including several network construction\ntechniques, generation of low-dimensional representations, and a broad range of\ndownstream analytical tasks. Its extensive utilities, including diverse GNN\narchitectures, and compatibility with established Python packages (e.g.,\nscikit-learn, PyTorch, NetworkX), enhance usability and facilitate quick\nadoption. BioNeuralNet is an open-source, user-friendly, and extensively\ndocumented framework designed to support flexible and reproducible multi-omics\nnetwork analysis in precision medicine.", "comment": "6 pages, 1 figure, 2 tables; Software available on PyPI as\n  BioNeuralNet. For documentation, tutorials, and workflows see\n  https://bioneuralnet.readthedocs.io", "pdf_url": "http://arxiv.org/pdf/2507.20440v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2312.03573", "title": "On data-driven Wasserstein distributionally robust Nash equilibrium problems with heterogeneous uncertainty", "authors": ["Georgios Pantazis", "Barbara Franci", "Sergio Grammatico"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2312.03573v3", "summary": "We study stochastic Nash equilibrium problems subject to heterogeneous\nuncertainty on the expected valued cost functions of the individual agents,\nwhere we assume no prior knowledge of the underlying probability distributions\nof the uncertain variables. To account for this lack of knowledge, we consider\nan ambiguity set around the empirical probability distribution under the\nWasserstein metric. We then show that, under mild assumptions, finite-sample\nguarantees on the probability that any resulting distributionally robust Nash\nequilibrium is also robust with respect to the true probability distributions\nwith high confidence can be obtained. Furthermore, by recasting the game as a\ndistributionally robust variational inequality, we establish asymptotic\nconsistency of the set of data-driven distributionally robust equilibria to the\nsolution set of the original game. Finally, we recast the distributionally\nrobust Nash game as a finite-dimensional Nash equilibrium problem. We\nillustrate the proposed distributionally robust reformulation via numerical\nexperiments of stochastic peer-to-peer electricity markets and Nash-Cournot\ngames.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2312.03573v3", "cate": "math.OC", "date": "2023-12-06", "updated": "2025-07-28"}
{"id": "2507.22019", "title": "Not Here, Go There: Analyzing Redirection Patterns on the Web", "authors": ["Kritika Garg", "Sawood Alam", "Dietrich Ayala", "Michele C. Weigle", "Michael L. Nelson"], "categories": ["cs.DL", "cs.IR", "cs.NI"], "primary_category": "Subjects:       Digital Libraries (cs.DL)", "pdf_link": null, "comments": "Comments:      Extended version of the paper accepted at the 2025 ACM Web Science Conference (WebSci 2025)", "url": "http://arxiv.org/abs/2507.22019v1", "summary": "URI redirections are integral to web management, supporting structural\nchanges, SEO optimization, and security. However, their complexities affect\nusability, SEO performance, and digital preservation. This study analyzed 11\nmillion unique redirecting URIs, following redirections up to 10 hops per URI,\nto uncover patterns and implications of redirection practices. Our findings\nrevealed that 50% of the URIs terminated successfully, while 50% resulted in\nerrors, including 0.06% exceeding 10 hops. Canonical redirects, such as HTTP to\nHTTPS transitions, were prevalent, reflecting adherence to SEO best practices.\nNon-canonical redirects, often involving domain or path changes, highlighted\nsignificant web migrations, rebranding, and security risks. Notable patterns\nincluded \"sink\" URIs, where multiple redirects converged, ranging from traffic\nconsolidation by global websites to deliberate \"Rickrolling.\" The study also\nidentified 62,000 custom 404 URIs, almost half being soft 404s, which could\ncompromise SEO and user experience. These findings underscore the critical role\nof URI redirects in shaping the web while exposing challenges such as outdated\nURIs, server instability, and improper error handling. This research offers a\ndetailed analysis of URI redirection practices, providing insights into their\nprevalence, types, and outcomes. By examining a large dataset, we highlight\ninefficiencies in redirection chains and examine patterns such as the use of\n\"sink\" URIs and custom error pages. This information can help webmasters,\nresearchers, and digital archivists improve web usability, optimize resource\nallocation, and safeguard valuable online content.", "comment": "Extended version of the paper accepted at the 2025 ACM Web Science\n  Conference (WebSci 2025)", "pdf_url": "http://arxiv.org/pdf/2507.22019v1", "cate": "cs.DL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2501.11673", "title": "Randomized Kaczmarz Methods with Beyond-Krylov Convergence", "authors": ["Michał Dereziński", "Deanna Needell", "Elizaveta Rebrova", "Jiaming Yang"], "categories": ["math.NA", "cs.DS", "cs.LG", "cs.NA", "math.OC", "stat.ML"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      SIMAX", "url": "http://arxiv.org/abs/2501.11673v2", "summary": "Randomized Kaczmarz methods form a family of linear system solvers which\nconverge by repeatedly projecting their iterates onto randomly sampled\nequations. While effective in some contexts, such as highly over-determined\nleast squares, Kaczmarz methods are traditionally deemed secondary to Krylov\nsubspace methods, since this latter family of solvers can exploit outliers in\nthe input's singular value distribution to attain fast convergence on\nill-conditioned systems.\n  In this paper, we introduce Kaczmarz++, an accelerated randomized block\nKaczmarz algorithm that exploits outlying singular values in the input to\nattain a fast Krylov-style convergence. Moreover, we show that Kaczmarz++\ncaptures large outlying singular values provably faster than popular Krylov\nmethods, for both over- and under-determined systems. We also develop an\noptimized variant for positive semidefinite systems, called CD++, demonstrating\nempirically that it is competitive in arithmetic operations with both CG and\nGMRES on a collection of benchmark problems. To attain these results, we\nintroduce several novel algorithmic improvements to the Kaczmarz framework,\nincluding adaptive momentum acceleration, Tikhonov-regularized projections, and\na memoization scheme for reusing information from previously sampled equation\nblocks.", "comment": "SIMAX", "pdf_url": "http://arxiv.org/pdf/2501.11673v2", "cate": "math.NA", "date": "2025-01-20", "updated": "2025-07-29"}
{"id": "2505.04066", "title": "LLAMAPIE: Proactive In-Ear Conversation Assistants", "authors": ["Tuochao Chen", "Nicholas Batchelder", "Alisa Liu", "Noah Smith", "Shyamnath Gollakota"], "categories": ["cs.LG", "cs.CL", "cs.HC", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published by ACL2025 (Findings)", "url": "http://arxiv.org/abs/2505.04066v2", "summary": "We introduce LlamaPIE, the first real-time proactive assistant designed to\nenhance human conversations through discreet, concise guidance delivered via\nhearable devices. Unlike traditional language models that require explicit user\ninvocation, this assistant operates in the background, anticipating user needs\nwithout interrupting conversations. We address several challenges, including\ndetermining when to respond, crafting concise responses that enhance\nconversations, leveraging knowledge of the user for context-aware assistance,\nand real-time, on-device processing. To achieve this, we construct a\nsemi-synthetic dialogue dataset and propose a two-model pipeline: a small model\nthat decides when to respond and a larger model that generates the response. We\nevaluate our approach on real-world datasets, demonstrating its effectiveness\nin providing helpful, unobtrusive assistance. User studies with our assistant,\nimplemented on Apple Silicon M2 hardware, show a strong preference for the\nproactive assistant over both a baseline with no assistance and a reactive\nmodel, highlighting the potential of LlamaPie to enhance live conversations.", "comment": "Published by ACL2025 (Findings)", "pdf_url": "http://arxiv.org/pdf/2505.04066v2", "cate": "cs.LG", "date": "2025-05-07", "updated": "2025-07-29"}
{"id": "2507.21702", "title": "Analytical Treatment of Hollow Toroid Flux Tubes", "authors": ["Herbert Schmidt"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      10 pages, 9 figures, 1 table, accepted for publication at the 16th International Modelica & fmi Conference", "url": "http://arxiv.org/abs/2507.21702v1", "summary": "Stray flux tubes around cylindrical poles are commonly modelled starting from\nthe results for planar flux tubes using the circumference of the cylinder as\ndepth. While this is a tried and tested approach, we here discuss analytical\nexpressions using the actual axisymmetric geometry of a fraction of a hollow\ntorus and compare their results to those of the accepted approach.", "comment": "10 pages, 9 figures, 1 table, accepted for publication at the 16th\n  International Modelica & fmi Conference", "pdf_url": "http://arxiv.org/pdf/2507.21702v1", "cate": "eess.SY", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20181", "title": "SGPO: Self-Generated Preference Optimization based on Self-Improver", "authors": ["Hyeonji Lee", "Daejin Jo", "Seohwan Yun", "Sungwoong Kim"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20181v1", "summary": "Large language models (LLMs), despite their extensive pretraining on diverse\ndatasets, require effective alignment to human preferences for practical and\nreliable deployment. Conventional alignment methods typically employ off-policy\nlearning and depend on human-annotated datasets, which limits their broad\napplicability and introduces distribution shift issues during training. To\naddress these challenges, we propose Self-Generated Preference Optimization\nbased on Self-Improver (SGPO), an innovative alignment framework that leverages\nan on-policy self-improving mechanism. Specifically, the improver refines\nresponses from a policy model to self-generate preference data for direct\npreference optimization (DPO) of the policy model. Here, the improver and\npolicy are unified into a single model, and in order to generate higher-quality\npreference data, this self-improver learns to make incremental yet discernible\nimprovements to the current responses by referencing supervised fine-tuning\noutputs. Experimental results on AlpacaEval 2.0 and Arena-Hard show that the\nproposed SGPO significantly improves performance over DPO and baseline\nself-improving methods without using external preference data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20181v1", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20443", "title": "Provable In-Context Learning of Nonlinear Regression with Transformers", "authors": ["Hongbo Li", "Lingjie Duan", "Yingbin Liang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20443v1", "summary": "The transformer architecture, which processes sequences of input tokens to\nproduce outputs for query tokens, has revolutionized numerous areas of machine\nlearning. A defining feature of transformers is their ability to perform\npreviously unseen tasks using task-specific prompts without updating\nparameters, a phenomenon known as in-context learning (ICL). Recent research\nhas actively explored the training dynamics behind ICL, with much of the focus\non relatively simple tasks such as linear regression and binary classification.\nTo advance the theoretical understanding of ICL, this paper investigates more\ncomplex nonlinear regression tasks, aiming to uncover how transformers acquire\nin-context learning capabilities in these settings. We analyze the stage-wise\ndynamics of attention during training: attention scores between a query token\nand its target features grow rapidly in the early phase, then gradually\nconverge to one, while attention to irrelevant features decays more slowly and\nexhibits oscillatory behavior. Our analysis introduces new proof techniques\nthat explicitly characterize how the nature of general non-degenerate\nL-Lipschitz task functions affects attention weights. Specifically, we identify\nthat the Lipschitz constant L of nonlinear function classes as a key factor\ngoverning the convergence dynamics of transformers in ICL. Leveraging these\ninsights, for two distinct regimes depending on whether L is below or above a\nthreshold, we derive different time bounds to guarantee near-zero prediction\nerror. Notably, despite the convergence time depending on the underlying task\nfunctions, we prove that query tokens consistently attend to prompt tokens with\nhighly relevant features at convergence, demonstrating the ICL capability of\ntransformers for unseen functions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20443v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2503.09722", "title": "The Pitfalls of Imitation Learning when Actions are Continuous", "authors": ["Max Simchowitz", "Daniel Pfrommer", "Ali Jadbabaie"], "categories": ["cs.LG", "cs.SY", "eess.SY", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      98 pages, 2 figures, updated proof sketch", "url": "http://arxiv.org/abs/2503.09722v4", "summary": "We study the problem of imitating an expert demonstrator in a discrete-time,\ncontinuous state-and-action control system. We show that, even if the dynamics\nsatisfy a control-theoretic property called exponential stability (i.e. the\neffects of perturbations decay exponentially quickly), and the expert is smooth\nand deterministic, any smooth, deterministic imitator policy necessarily\nsuffers error on execution that is exponentially larger, as a function of\nproblem horizon, than the error under the distribution of expert training data.\nOur negative result applies to any algorithm which learns solely from expert\ndata, including both behavior cloning and offline-RL algorithms, unless the\nalgorithm produces highly \"improper\" imitator policies--those which are\nnon-smooth, non-Markovian, or which exhibit highly state-dependent\nstochasticity--or unless the expert trajectory distribution is sufficiently\n\"spread.\" We provide experimental evidence of the benefits of these more\ncomplex policy parameterizations, explicating the benefits of today's popular\npolicy parameterizations in robot learning (e.g. action-chunking and diffusion\npolicies). We also establish a host of complementary negative and positive\nresults for imitation in control systems.", "comment": "98 pages, 2 figures, updated proof sketch", "pdf_url": "http://arxiv.org/pdf/2503.09722v4", "cate": "cs.LG", "date": "2025-03-12", "updated": "2025-07-26"}
{"id": "2408.11557", "title": "Enhancing Spectral Knowledge Interrogation: A Reliable Retrieval-Augmented Generative Framework on Large Language Models", "authors": ["Jiheng Liang", "Zujie Xie", "Ziru Yu", "Xiangyang Yu"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      16 pages,10 figures,3 tables", "url": "http://arxiv.org/abs/2408.11557v5", "summary": "Large Language Model (LLM) has demonstrated significant success in a range of\nnatural language processing (NLP) tasks within general domain. The emergence of\nLLM has introduced innovative methodologies across diverse fields, including\nthe natural sciences. Researchers aim to implement automated, concurrent\nprocess driven by LLM to supplant conventional manual, repetitive and\nlabor-intensive work. In the domain of spectral analysis and detection, it is\nimperative for researchers to autonomously acquire pertinent knowledge across\nvarious research objects, which encompasses the spectroscopic techniques and\nthe chemometric methods that are employed in experiments and analysis.\nParadoxically, despite the recognition of spectroscopic detection as an\neffective analytical method, the fundamental process of knowledge retrieval\nremains both time-intensive and repetitive. In response to this challenge, we\nfirst introduced the Spectral Detection and Analysis Based Paper(SDAAP)\ndataset, which is the first open-source textual knowledge dataset for spectral\nanalysis and detection and contains annotated literature data as well as\ncorresponding knowledge instruction data. Subsequently, we also designed an\nautomated Q\\&A framework based on the SDAAP dataset, which can retrieve\nrelevant knowledge and generate high-quality responses by extracting entities\nin the input as retrieval parameters. It is worth noting that: within this\nframework, LLM is only used as a tool to provide generalizability, while RAG\ntechnique is used to accurately capture the source of the knowledge.This\napproach not only improves the quality of the generated responses, but also\nensures the traceability of the knowledge. Experimental results show that our\nframework generates responses with more reliable expertise compared to the\nbaseline.", "comment": "16 pages,10 figures,3 tables", "pdf_url": "http://arxiv.org/pdf/2408.11557v5", "cate": "cs.IR", "date": "2024-08-21", "updated": "2025-07-29"}
{"id": "2503.05104", "title": "An exponential integrator multicontinuum homogenization method for fractional diffusion problem with multiscale coefficients", "authors": ["Yifei Gao", "Yating Wang", "Wing Tat Leung", "Zhengya Yang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.05104v2", "summary": "In this paper, we present a robust and fully discretized method for solving\nthe time fractional diffusion equation with high-contrast multiscale\ncoefficients. We establish the homogenized equation using a multicontinuum\napproach and employ the exponential integrator method for time discretization.\nThe multicontinuum upscaled model captures the physical characteristics of the\nsolution for the high-contrast multiscale problem, including averages and\ngradient effects in each continuum at the coarse scale. We then use the\nexponential integration method for the nonlocal time fractional derivative and\nit can handle semilinear problem in an efficient way. Convergence analysis of\nthe numerical scheme is provided, along with illustrative numerical examples.\nOur results demonstrate the accuracy, efficiency, and improved stability for\nvarying order of fractional derivatives.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.05104v2", "cate": "math.NA", "date": "2025-03-07", "updated": "2025-07-29"}
{"id": "2507.14915", "title": "Music-Aligned Holistic 3D Dance Generation via Hierarchical Motion Modeling", "authors": ["Xiaojie Li", "Ronghui Li", "Shukai Fang", "Shuzhao Xie", "Xiaoyang Guo", "Jiaqing Zhou", "Junkun Peng", "Zhi Wang"], "categories": ["cs.MM", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14915v3", "summary": "Well-coordinated, music-aligned holistic dance enhances emotional\nexpressiveness and audience engagement. However, generating such dances remains\nchallenging due to the scarcity of holistic 3D dance datasets, the difficulty\nof achieving cross-modal alignment between music and dance, and the complexity\nof modeling interdependent motion across the body, hands, and face. To address\nthese challenges, we introduce SoulDance, a high-precision music-dance paired\ndataset captured via professional motion capture systems, featuring\nmeticulously annotated holistic dance movements. Building on this dataset, we\npropose SoulNet, a framework designed to generate music-aligned, kinematically\ncoordinated holistic dance sequences. SoulNet consists of three principal\ncomponents: (1) Hierarchical Residual Vector Quantization, which models\ncomplex, fine-grained motion dependencies across the body, hands, and face; (2)\nMusic-Aligned Generative Model, which composes these hierarchical motion units\ninto expressive and coordinated holistic dance; (3) Music-Motion Retrieval\nModule, a pre-trained cross-modal model that functions as a music-dance\nalignment prior, ensuring temporal synchronization and semantic coherence\nbetween generated dance and input music throughout the generation process.\nExtensive experiments demonstrate that SoulNet significantly surpasses existing\napproaches in generating high-quality, music-coordinated, and well-aligned\nholistic 3D dance sequences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14915v3", "cate": "cs.MM", "date": "2025-07-20", "updated": "2025-07-29"}
{"id": "2507.21759", "title": "The impact of large-scale EV charging on the real-time operation of distribution systems: A comprehensive review", "authors": ["Zhe Yu", "Chuang Yang", "Qin Wang"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21759v1", "summary": "With the large-scale integration of electric vehicles (EVs) in the\ndistribution grid, the unpredictable nature of EV charging introduces\nconsiderable uncertainties to the grid's real-time operations. This can\nexacerbate load fluctuations, compromise power quality, and pose risks to the\ngrid's stability and security. However, due to their dual role as controllable\nloads and energy storage devices, EVs have the potential to mitigate these\nfluctuations, balance the variability of renewable energy sources, and provide\nancillary services that support grid stability. By leveraging the bidirectional\nflow of information and energy in smart grids, the adverse effects of EV\ncharging can be minimized and even converted into beneficial outcomes through\neffective real-time management strategies. This paper explores the negative\nimpacts of EV charging on the distribution system's real-time operations and\noutlines methods to transform these challenges into positive contributions.\nAdditionally, it provides an in-depth analysis of the real-time management\nsystem for EV charging, focusing on state estimation and management strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21759v1", "cate": "eess.SY", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2404.18282", "title": "Efficient Runtime Verification of Real-Time Systems under Parametric Communication Delays", "authors": ["Martin Fränzle", "Thomas M. Grosen", "Kim G. Larsen", "Martin Zimmermann"], "categories": ["cs.FL"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.18282v4", "summary": "Timed B\\\"uchi automata provide a very expressive formalism for expressing\nrequirements of real-time systems. Online monitoring and active testing of\nembedded real-time systems can then be achieved by symbolic execution of such\nautomata on the trace observed from the system. This direct construction\nhowever only is faithful if observation of the trace is immediate in the sense\nthat the monitor (or test harness, respectively) can assign exact time stamps\nto the actions it observes, which is rarely true in practice due to the\nsubstantial and fluctuating parametric delays introduced by the circuitry\nconnecting the observed system to its monitoring or testing device.\n  We present purely zone-based online monitoring and testing algorithms, which\nhandle such parametric delays exactly without recurrence to costly verification\nprocedures for parametric timed automata. We have implemented our algorithms on\ntop of the real-time model checking tool UPPAAL, and report on encouraging\ninitial results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.18282v4", "cate": "cs.FL", "date": "2024-04-28", "updated": "2025-07-29"}
{"id": "2507.20197", "title": "Color histogram equalization and fine-tuning to improve expression recognition of (partially occluded) faces on sign language datasets", "authors": ["Fabrizio Nunnari", "Alakshendra Jyotsnaditya Ramkrishna Singh", "Patrick Gebhard"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20197v1", "summary": "The goal of this investigation is to quantify to what extent computer vision\nmethods can correctly classify facial expressions on a sign language dataset.\nWe extend our experiments by recognizing expressions using only the upper or\nlower part of the face, which is needed to further investigate the difference\nin emotion manifestation between hearing and deaf subjects. To take into\naccount the peculiar color profile of a dataset, our method introduces a color\nnormalization stage based on histogram equalization and fine-tuning. The\nresults show the ability to correctly recognize facial expressions with 83.8%\nmean sensitivity and very little variance (.042) among classes. Like for\nhumans, recognition of expressions from the lower half of the face (79.6%) is\nhigher than that from the upper half (77.9%). Noticeably, the classification\naccuracy from the upper half of the face is higher than human level.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20197v1", "cate": "cs.CV", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20446", "title": "BOASF: A Unified Framework for Speeding up Automatic Machine Learning via Adaptive Successive Filtering", "authors": ["Guanghui Zhu", "Xin Fang", "Lei Wang", "Wenzhong Chen", "Rong Gu", "Chunfeng Yuan", "Yihua Huang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20446v1", "summary": "Machine learning has been making great success in many application areas.\nHowever, for the non-expert practitioners, it is always very challenging to\naddress a machine learning task successfully and efficiently. Finding the\noptimal machine learning model or the hyperparameter combination set from a\nlarge number of possible alternatives usually requires considerable expert\nknowledge and experience. To tackle this problem, we propose a combined\nBayesian Optimization and Adaptive Successive Filtering algorithm (BOASF) under\na unified multi-armed bandit framework to automate the model selection or the\nhyperparameter optimization. Specifically, BOASF consists of multiple\nevaluation rounds in each of which we select promising configurations for each\narm using the Bayesian optimization. Then, ASF can early discard the\npoor-performed arms adaptively using a Gaussian UCB-based probabilistic model.\nFurthermore, a Softmax model is employed to adaptively allocate available\nresources for each promising arm that advances to the next round. The arm with\na higher probability of advancing will be allocated more resources.\nExperimental results show that BOASF is effective for speeding up the model\nselection and hyperparameter optimization processes while achieving robust and\nbetter prediction performance than the existing state-of-the-art automatic\nmachine learning methods. Moreover, BOASF achieves better anytime performance\nunder various time budgets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20446v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2503.18189", "title": "Ordering and refining path-complete Lyapunov functions through composition lifts", "authors": ["Wouter Jongeneel", "Raphaël M. Jungers"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      6 pages, to appear at the IEEE CDC, 2025", "url": "http://arxiv.org/abs/2503.18189v2", "summary": "A fruitful approach to study stability of switched systems is to look for\nmultiple Lyapunov functions. However, in general, we do not yet understand the\ninterplay between the desired stability certificate, the template of the\nLyapunov functions and their mutual relationships to accommodate switching. In\nthis work we elaborate on path-complete Lyapunov functions: a graphical\nframework that aims to elucidate this interplay. In particular, previously,\nseveral preorders were introduced to compare multiple Lyapunov functions. These\npreorders are initially algorithmically intractable due to the algebraic nature\nof Lyapunov inequalities, yet, lifting techniques were proposed to turn some\npreorders purely combinatorial and thereby eventually tractable. In this note\nwe show that a conjecture in this area regarding the so-called composition\nlift, that was believed to be true, is false. This refutal, however, points us\nto a beneficial structural feature of the composition lift that we exploit to\niteratively refine path-complete graphs, plus, it points us to a favourable\nadaptation of the composition lift.", "comment": "6 pages, to appear at the IEEE CDC, 2025", "pdf_url": "http://arxiv.org/pdf/2503.18189v2", "cate": "math.OC", "date": "2025-03-23", "updated": "2025-07-26"}
{"id": "2502.07327", "title": "Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated Videos", "authors": ["Haowen Gao", "Liang Pang", "Shicheng Xu", "Leigang Qu", "Tat-Seng Chua", "Huawei Shen", "Xueqi Cheng"], "categories": ["cs.IR", "cs.CV"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      13 pages, Accepted at ACMMM2025", "url": "http://arxiv.org/abs/2502.07327v2", "summary": "With the rapid development of AI-generated content (AIGC), the creation of\nhigh-quality AI-generated videos has become faster and easier, resulting in the\nInternet being flooded with all kinds of video content. However, the impact of\nthese videos on the content ecosystem remains largely unexplored. Video\ninformation retrieval remains a fundamental approach for accessing video\ncontent. Building on the observation that retrieval models often favor\nAI-generated content in ad-hoc and image retrieval tasks, we investigate\nwhether similar biases emerge in the context of challenging video retrieval,\nwhere temporal and visual factors may further influence model behavior. To\nexplore this, we first construct a comprehensive benchmark dataset containing\nboth real and AI-generated videos, along with a set of fair and rigorous\nmetrics to assess bias. This benchmark consists of 13,000 videos generated by\ntwo state-of-the-art open-source video generation models. We meticulously\ndesign a suite of rigorous metrics to accurately measure this preference,\naccounting for potential biases arising from the limited frame rate and\nsuboptimal quality of AIGC videos. We then applied three off-the-shelf video\nretrieval models to perform retrieval tasks on this hybrid dataset. Our\nfindings reveal a clear preference for AI-generated videos in retrieval.\nFurther investigation shows that incorporating AI-generated videos into the\ntraining set of retrieval models exacerbates this bias. Unlike the preference\nobserved in image modalities, we find that video retrieval bias arises from\nboth unseen visual and temporal information, making the root causes of video\nbias a complex interplay of these two factors. To mitigate this bias, we\nfine-tune the retrieval models using a contrastive learning approach. The\nresults of this study highlight the potential implications of AI-generated\nvideos on retrieval systems.", "comment": "13 pages, Accepted at ACMMM2025", "pdf_url": "http://arxiv.org/pdf/2502.07327v2", "cate": "cs.IR", "date": "2025-02-11", "updated": "2025-07-29"}
{"id": "2507.13640", "title": "Interpolation in Polynomial Spaces of p-Degree", "authors": ["Phil-Alexander Hofmann", "Damar Wicaksono", "Michael Hecht"], "categories": ["math.NA", "cs.NA", "65D15"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13640v2", "summary": "We recently introduced the Fast Newton Transform (FNT), an algorithm for\nperforming multivariate Newton interpolation in downward closed polynomial\nspaces of spatial dimension $m$. In this work, we analyze the FNT in the\ncontext of a specific family of downward closed sets $A_{m,n,p}$, defined as\nall multi-indices with $\\ell^p$ norm less than $n$ with $p \\in [0,\\infty]$.\nThese sets induce the downward closed polynomial space $\\Pi_{m,n,p}$, within\nwhich the FNT algorithm achieves a time complexity of\n$\\mathcal{O}(|A_{m,n,p}|mn)$. We show that this setting, compared to tensor\nproduct spaces, yields an improvement in complexity by a factor $\\rho_{m,n,p}$,\nwhich decays super exponentially with increasing spatial dimension when $m\n\\lesssim n^p$. Additionally, we demonstrate the construction of the\nhierarchical scheme employed by the FNT and showcase its performance to compute\nactivity scores in sensitivity analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13640v2", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-29"}
{"id": "2507.21941", "title": "Hierarchical Game-Based Multi-Agent Decision-Making for Autonomous Vehicles", "authors": ["Mushuang Liu", "Yan Wan", "Frank Lewis", "Subramanya Nageshrao", "H. Eric Tseng", "Dimitar Filev"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      12 pages, 20 figures, 1 algorithm", "url": "http://arxiv.org/abs/2507.21941v1", "summary": "This paper develops a game-theoretic decision-making framework for autonomous\ndriving in multi-agent scenarios. A novel hierarchical game-based decision\nframework is developed for the ego vehicle. This framework features an\ninteraction graph, which characterizes the interaction relationships between\nthe ego and its surrounding traffic agents (including AVs, human driven\nvehicles, pedestrians, and bicycles, and others), and enables the ego to\nsmartly select a limited number of agents as its game players. Compared to the\nstandard multi-player games, where all surrounding agents are considered as\ngame players, the hierarchical game significantly reduces the computational\ncomplexity. In addition, compared to pairwise games, the most popular approach\nin the literature, the hierarchical game promises more efficient decisions for\nthe ego (in terms of less unnecessary waiting and yielding). To further reduce\nthe computational cost, we then propose an improved hierarchical game, which\ndecomposes the hierarchical game into a set of sub-games. Decision safety and\nefficiency are analyzed in both hierarchical games. Comprehensive simulation\nstudies are conducted to verify the effectiveness of the proposed frameworks,\nwith an intersection-crossing scenario as a case study.", "comment": "12 pages, 20 figures, 1 algorithm", "pdf_url": "http://arxiv.org/pdf/2507.21941v1", "cate": "eess.SY", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2409.05456", "title": "Exploiting Assumptions for Effective Monitoring of Real-Time Properties under Partial Observability", "authors": ["Alessandro Cimatti", "Thomas M. Grosen", "Kim G. Larsen", "Stefano Tonetta", "Martin Zimmermann"], "categories": ["cs.FL"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.05456v2", "summary": "Runtime verification of temporal properties is essential for ensuring the\ncorrectness and reliability of real-time systems, particularly in\ncyber-physical systems. A significant challenge in this domain is the effective\nprediction of property failure or success, especially when dealing with\npartially observable systems. This paper addresses these challenges by\ndeveloping an Assumption-Based Runtime Verification (ABRV) approach for a\ncontinuous real-time setting. Our method exploits assumptions about the\nsystem's behavior, specified as Timed Automata, to enable monitors to predict\nfuture outcomes and handle unobservable system parts, such as internal faults.\nProperties to be monitored are specified using Metric Interval Temporal Logic\n(MITL). The approach also includes formalizing observations with data and time\nuncertainty using sequences of timed constraints. We present a zone-based\nonline algorithm for computing the monitoring verdict, implemented on top of\nthe UPPAAL tool. Experimental evaluation on proof-of-concept cases demonstrates\nthe approach's feasibility and effectiveness, illustrating how assumptions\nfacilitate earlier verdicts, enable monitoring of properties dependent on\nunobservable events, and provide insights into scalability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.05456v2", "cate": "cs.FL", "date": "2024-09-09", "updated": "2025-07-29"}
{"id": "2507.20221", "title": "Multi-Attention Stacked Ensemble for Lung Cancer Detection in CT Scans", "authors": ["Uzzal Saha", "Surya Prakash"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      26 pages, 14 figures", "url": "http://arxiv.org/abs/2507.20221v1", "summary": "In this work, we address the challenge of binary lung nodule classification\n(benign vs malignant) using CT images by proposing a multi-level attention\nstacked ensemble of deep neural networks. Three pretrained backbones --\nEfficientNet V2 S, MobileViT XXS, and DenseNet201 -- are each adapted with a\ncustom classification head tailored to 96 x 96 pixel inputs. A two-stage\nattention mechanism learns both model-wise and class-wise importance scores\nfrom concatenated logits, and a lightweight meta-learner refines the final\nprediction. To mitigate class imbalance and improve generalization, we employ\ndynamic focal loss with empirically calculated class weights, MixUp\naugmentation during training, and test-time augmentation at inference.\nExperiments on the LIDC-IDRI dataset demonstrate exceptional performance,\nachieving 98.09 accuracy and 0.9961 AUC, representing a 35 percent reduction in\nerror rate compared to state-of-the-art methods. The model exhibits balanced\nperformance across sensitivity (98.73) and specificity (98.96), with\nparticularly strong results on challenging cases where radiologist disagreement\nwas high. Statistical significance testing confirms the robustness of these\nimprovements across multiple experimental runs. Our approach can serve as a\nrobust, automated aid for radiologists in lung cancer screening.", "comment": "26 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.20221v1", "cate": "eess.IV", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20447", "title": "WEEP: A Differentiable Nonconvex Sparse Regularizer via Weakly-Convex Envelope", "authors": ["Takanobu Furuhashi", "Hidekata Hontani", "Tatsuya Yokota"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      8 pages, 4 figures", "url": "http://arxiv.org/abs/2507.20447v1", "summary": "Sparse regularization is fundamental in signal processing for efficient\nsignal recovery and feature extraction. However, it faces a fundamental\ndilemma: the most powerful sparsity-inducing penalties are often\nnon-differentiable, conflicting with gradient-based optimizers that dominate\nthe field. We introduce WEEP (Weakly-convex Envelope of Piecewise Penalty), a\nnovel, fully differentiable sparse regularizer derived from the weakly-convex\nenvelope framework. WEEP provides strong, unbiased sparsity while maintaining\nfull differentiability and L-smoothness, making it natively compatible with any\ngradient-based optimizer. This resolves the conflict between statistical\nperformance and computational tractability. We demonstrate superior performance\ncompared to the L1-norm and other established non-convex sparse regularizers on\nchallenging signal and image denoising tasks.", "comment": "8 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.20447v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2505.17696", "title": "Enhancing AI System Resiliency: Formulation and Guarantee for LSTM Resilience Based on Control Theory", "authors": ["Sota Yoshihara", "Ryosuke Yamamoto", "Hiroyuki Kusumoto", "Masanari Shimura"], "categories": ["cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      9 pages, 6 figures. Appendix: 16 pages. First three listed authors have equal contributions", "url": "http://arxiv.org/abs/2505.17696v2", "summary": "This paper proposes a novel theoretical framework for guaranteeing and\nevaluating the resilience of long short-term memory (LSTM) networks in control\nsystems. We introduce \"recovery time\" as a new metric of resilience in order to\nquantify the time required for an LSTM to return to its normal state after\nanomalous inputs. By mathematically refining incremental input-to-state\nstability ($\\delta$ISS) theory for LSTM, we derive a practical data-independent\nupper bound on recovery time. This upper bound gives us resilience-aware\ntraining. Experimental validation on simple models demonstrates the\neffectiveness of our resilience estimation and control methods, enhancing a\nfoundation for rigorous quality assurance in safety-critical AI applications.", "comment": "9 pages, 6 figures. Appendix: 16 pages. First three listed authors\n  have equal contributions", "pdf_url": "http://arxiv.org/pdf/2505.17696v2", "cate": "cs.AI", "date": "2025-05-23", "updated": "2025-07-28"}
{"id": "2504.10541", "title": "Multi-Modal Hypergraph Enhanced LLM Learning for Recommendation", "authors": ["Xu Guo", "Tong Zhang", "Yuanzhi Wang", "Chenxu Wang", "Fuyun Wang", "Xudong Wang", "Xiaoya Zhang", "Xin Liu", "Zhen Cui"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures, submitted to IEEE Transactions on Knowledge and Data Engineering", "url": "http://arxiv.org/abs/2504.10541v2", "summary": "The burgeoning presence of Large Language Models (LLM) is propelling the\ndevelopment of personalized recommender systems. Most existing LLM-based\nmethods fail to sufficiently explore the multi-view graph structure\ncorrelations inherent in recommendation scenarios. To this end, we propose a\nnovel framework, Hypergraph Enhanced LLM Learning for multimodal Recommendation\n(HeLLM), designed to equip LLMs with the capability to capture intricate\nhigher-order semantic correlations by fusing graph-level contextual signals\nwith sequence-level behavioral patterns. In the recommender pre-training phase,\nwe design a user hypergraph to uncover shared interest preferences among users\nand an item hypergraph to capture correlations within multimodal similarities\namong items. The hypergraph convolution and synergistic contrastive learning\nmechanism are introduced to enhance the distinguishability of learned\nrepresentations. In the LLM fine-tuning phase, we inject the learned\ngraph-structured embeddings directly into the LLM's architecture and integrate\nsequential features capturing each user's chronological behavior. This process\nenables hypergraphs to leverage graph-structured information as global context,\nenhancing the LLM's ability to perceive complex relational patterns and\nintegrate multimodal information, while also modeling local temporal dynamics.\nExtensive experiments demonstrate the superiority of our proposed method over\nstate-of-the-art baselines, confirming the advantages of fusing\nhypergraph-based context with sequential user behavior in LLMs for\nrecommendation.", "comment": "12 pages, 4 figures, submitted to IEEE Transactions on Knowledge and\n  Data Engineering", "pdf_url": "http://arxiv.org/pdf/2504.10541v2", "cate": "cs.IR", "date": "2025-04-13", "updated": "2025-07-29"}
{"id": "2507.14562", "title": "1/2 order convergence rate of Euler-type methods for time-changed stochastic differential equations with super-linearly growing drift and diffusion coefficients", "authors": ["Yuanling Niu", "Shuai Wang", "Ying Zhang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14562v3", "summary": "This paper investigates the convergence rates of two Euler-type methods for a\nclass of time-changed stochastic differential equations with super-linearly\ngrowing drift and diffusion coefficients. Building upon existing research, we\nadapt the backward Euler method to time-changed stochastic differential\nequations where both coefficients exhibit super-linear growth and introduce an\nexplicit counterpart, the projected Euler method. It is shown that both methods\nachieve the optimal strong convergence rate of order 1/2 in the mean-square\nsense for this class of equations. Numerical simulations confirm the\ntheoretical findings", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14562v3", "cate": "math.NA", "date": "2025-07-19", "updated": "2025-07-29"}
{"id": "2507.22022", "title": "Planning Persuasive Trajectories Based on a Leader-Follower Game Model", "authors": ["Chaozhe R. He", "Yichen Dong", "Nan Li"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      To appear at MECC 2025 ( this https URL )", "url": "http://arxiv.org/abs/2507.22022v1", "summary": "We propose a framework that enables autonomous vehicles (AVs) to proactively\nshape the intentions and behaviors of interacting human drivers. The framework\nemploys a leader-follower game model with an adaptive role mechanism to predict\nhuman interaction intentions and behaviors. It then utilizes a branch model\npredictive control (MPC) algorithm to plan the AV trajectory, persuading the\nhuman to adopt the desired intention. The proposed framework is demonstrated in\nan intersection scenario. Simulation results illustrate the effectiveness of\nthe framework for generating persuasive AV trajectories despite uncertainties.", "comment": "To appear at MECC 2025 (https://mecc2025.a2c2.org/)", "pdf_url": "http://arxiv.org/pdf/2507.22022v1", "cate": "eess.SY", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2503.18077", "title": "Conservative Perception Models for Probabilistic Verification", "authors": ["Matthew Cleaveland", "Pengyuan Lu", "Oleg Sokolsky", "Insup Lee", "Ivan Ruchkin"], "categories": ["cs.FL"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.18077v3", "summary": "Verifying the behaviors of autonomous systems with learned perception\ncomponents is a challenging problem due to the complexity of the perception and\nthe uncertainty of operating environments. Probabilistic model checking is a\npowerful tool for providing guarantees on stochastic models of systems.\nHowever, constructing model-checkable models of black-box perception components\nfor system-level mathematical guarantees has been an enduring challenge. In\nthis paper, we propose a method for constructing provably conservative Interval\nMarkov Decision Process (IMDP) models of closed-loop systems with perception\ncomponents. We prove that our technique results in conservative abstractions\nwith a user-specified probability. We evaluate our approach in an automatic\nbraking case study using both a synthetic perception component and the object\ndetector YOLO11 in the CARLA driving simulator.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.18077v3", "cate": "cs.FL", "date": "2025-03-23", "updated": "2025-07-29"}
{"id": "2507.20252", "title": "Post-Completion Learning for Language Models", "authors": ["Xiang Fei", "Siqi Wang", "Shu Wei", "Yuxiang Nie", "Wei Shi", "Hao Feng", "Can Huang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20252v1", "summary": "Current language model training paradigms typically terminate learning upon\nreaching the end-of-sequence (<eos>}) token, overlooking the potential learning\nopportunities in the post-completion space. We propose Post-Completion Learning\n(PCL), a novel training framework that systematically utilizes the sequence\nspace after model output completion, to enhance both the reasoning and\nself-evaluation abilities. PCL enables models to continue generating\nself-assessments and reward predictions during training, while maintaining\nefficient inference by stopping at the completion point.\n  To fully utilize this post-completion space, we design a white-box\nreinforcement learning method: let the model evaluate the output content\naccording to the reward rules, then calculate and align the score with the\nreward functions for supervision. We implement dual-track SFT to optimize both\nreasoning and evaluation capabilities, and mixed it with RL training to achieve\nmulti-objective hybrid optimization.\n  Experimental results on different datasets and models demonstrate consistent\nimprovements over traditional SFT and RL methods. Our method provides a new\ntechnical path for language model training that enhances output quality while\npreserving deployment efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20252v1", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20453", "title": "Your Attention Matters: to Improve Model Robustness to Noise and Spurious Correlations", "authors": ["Camilo Tamayo-Rousseau", "Yunjia Zhao", "Yiqun Zhang", "Randall Balestriero"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20453v1", "summary": "Self-attention mechanisms are foundational to Transformer architectures,\nsupporting their impressive success in a wide range of tasks. While there are\nmany self-attention variants, their robustness to noise and spurious\ncorrelations has not been well studied. This study evaluates Softmax, Sigmoid,\nLinear, Doubly Stochastic, and Cosine attention within Vision Transformers\nunder different data corruption scenarios. Through testing across the CIFAR-10,\nCIFAR-100, and Imagenette datasets, we show that Doubly Stochastic attention is\nthe most robust. Our findings inform self-attention selection in contexts with\nimperfect data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20453v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.03022", "title": "A Novel Hybrid Grey Wolf Differential Evolution Algorithm", "authors": ["Ioannis D. Bougas", "Pavlos Doanis", "Maria S. Papadopoulou", "Achilles D. Boursianis", "Sotirios P. Sotiroudis", "Zaharias D. Zaharis", "George Koudouridis", "Panagiotis Sarigiannidis", "Mohammad Abdul Matint", "George Karagiannidis", "Sotirios K. Goudos"], "categories": ["cs.NE", "cs.SY", "eess.SY", "physics.app-ph", "physics.comp-ph", "B.7.1; B.7.2; B.8.2; C.2.1; D.1.0; I.6.3; J.2; J.6"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      19 pages, 32 figures, journal", "url": "http://arxiv.org/abs/2507.03022v3", "summary": "Grey wolf optimizer (GWO) is a nature-inspired stochastic meta-heuristic of\nthe swarm intelligence field that mimics the hunting behavior of grey wolves.\nDifferential evolution (DE) is a popular stochastic algorithm of the\nevolutionary computation field that is well suited for global optimization. In\nthis part, we introduce a new algorithm based on the hybridization of GWO and\ntwo DE variants, namely the GWO-DE algorithm. We evaluate the new algorithm by\napplying various numerical benchmark functions. The numerical results of the\ncomparative study are quite satisfactory in terms of performance and solution\nquality.", "comment": "19 pages, 32 figures, journal", "pdf_url": "http://arxiv.org/pdf/2507.03022v3", "cate": "cs.NE", "date": "2025-07-02", "updated": "2025-07-28"}
{"id": "2507.18365", "title": "RecPS: Privacy Risk Scoring for Recommender Systems", "authors": ["Jiajie He", "Yuechun Gu", "Keke Chen"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.18365v2", "summary": "Recommender systems (RecSys) have become an essential component of many web\napplications. The core of the system is a recommendation model trained on\nhighly sensitive user-item interaction data. While privacy-enhancing techniques\nare actively studied in the research community, the real-world model\ndevelopment still depends on minimal privacy protection, e.g., via controlled\naccess. Users of such systems should have the right to choose \\emph{not} to\nshare highly sensitive interactions. However, there is no method allowing the\nuser to know which interactions are more sensitive than others. Thus,\nquantifying the privacy risk of RecSys training data is a critical step to\nenabling privacy-aware RecSys model development and deployment. We propose a\nmembership-inference attack (MIA)- based privacy scoring method, RecPS, to\nmeasure privacy risks at both the interaction and user levels. The RecPS\ninteraction-level score definition is motivated and derived from differential\nprivacy, which is then extended to the user-level scoring method. A critical\ncomponent is the interaction-level MIA method RecLiRA, which gives high-quality\nmembership estimation. We have conducted extensive experiments on well-known\nbenchmark datasets and RecSys models to show the unique features and benefits\nof RecPS scoring in risk assessment and RecSys model unlearning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.18365v2", "cate": "cs.IR", "date": "2025-07-24", "updated": "2025-07-29"}
{"id": "2412.00695", "title": "Numerical Analysis of Cavitation Dynamics on Free Ogee Spillways Using the Volume of Fluid (VOF) Method", "authors": ["Parvaneh Nikrou", "Sajjad Pirboudaghi"], "categories": ["physics.flu-dyn", "cs.NA", "math.NA"], "primary_category": "Subjects:       Fluid Dynamics (physics.flu-dyn)", "pdf_link": null, "comments": "Comments:      22 pages", "url": "http://arxiv.org/abs/2412.00695v3", "summary": "Simulating complex hydraulic conditions, particularly two-phase flows over\nspillway chutes, can be achieved with high accuracy using three-dimensional\nnumerical models. This study investigates the potential for vacuum generation\nand cavitation phenomena on the Aghchai Dam service spillway through numerical\nsimulations conducted in Flow-3D. The analysis focuses on two specific flow\nrates, 4400 and 1065 cubic meters per second, as determined by experimental\ndata. The Volume of Fluid (VOF) method is employed to accurately calculate the\nfree surface flow. Simulation results at a discharge rate of 4400 cubic meters\nper second indicate a high likelihood of cavitation at critical locations,\nincluding the ogee curve and the angle transition in the chute channel. These\nareas require specific mitigation measures to prevent cavitation-induced\ndamage. In contrast, at the lower flow rate of 1065 cubic meters per second,\nthe risk of cavitation is minimal due to reduced flow velocity and the absence\nof flow separation from the bed. The numerical findings align closely with\nempirical observations, demonstrating the reliability of the simulation\napproach in predicting cavitation behavior.", "comment": "22 pages", "pdf_url": "http://arxiv.org/pdf/2412.00695v3", "cate": "physics.flu-dyn", "date": "2024-12-01", "updated": "2025-07-29"}
{"id": "2507.21153", "title": "Deep Reinforcement Learning for Real-Time Green Energy Integration in Data Centers", "authors": ["Abderaouf Bahi", "Amel Ourici"], "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21153v1", "summary": "This paper explores the implementation of a Deep Reinforcement Learning\n(DRL)-optimized energy management system for e-commerce data centers, aimed at\nenhancing energy efficiency, cost-effectiveness, and environmental\nsustainability. The proposed system leverages DRL algorithms to dynamically\nmanage the integration of renewable energy sources, energy storage, and grid\npower, adapting to fluctuating energy availability in real time. The study\ndemonstrates that the DRL-optimized system achieves a 38\\% reduction in energy\ncosts, significantly outperforming traditional Reinforcement Learning (RL)\nmethods (28\\%) and heuristic approaches (22\\%). Additionally, it maintains a\nlow SLA violation rate of 1.5\\%, compared to 3.0\\% for RL and 4.8\\% for\nheuristic methods. The DRL-optimized approach also results in an 82\\%\nimprovement in energy efficiency, surpassing other methods, and a 45\\%\nreduction in carbon emissions, making it the most environmentally friendly\nsolution. The system's cumulative reward of 950 reflects its superior\nperformance in balancing multiple objectives. Through rigorous testing and\nablation studies, the paper validates the effectiveness of the DRL model's\narchitecture and parameters, offering a robust solution for energy management\nin data centers. The findings highlight the potential of DRL in advancing\nenergy optimization strategies and addressing sustainability challenges.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21153v1", "cate": "cs.LG", "date": "2025-07-24", "updated": "2025-07-24"}
{"id": "2504.10008", "title": "Time for Timed Monitorability", "authors": ["Thomas M. Grosen", "Sean Kauffman", "Kim G. Larsen", "Martin Zimmermann"], "categories": ["cs.FL"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.10008v2", "summary": "Monitoring is an important part of the verification toolbox, in particular in\nsituations where exhaustive verification using, e.g., model-checking is\ninfeasible. The goal of online monitoring is to determine the satisfaction or\nviolation of a specification during runtime, i.e., based on finite execution\nprefixes. However, not every specification is amenable to monitoring, e.g.,\nproperties for which no finite execution can witness satisfaction or violation.\nMonitorability is the question of whether a given specification is amenable to\nmonitoring, and has been extensively studied in discrete time.\n  Here, we study the monitorability problem for real-time properties expressed\nas Timed Automata. For specifications given by deterministic Timed Muller\nAutomata, we prove decidability while we show that the problem is undecidable\nfor specifications given by nondeterministic Timed B\\\"uchi automata.\n  Furthermore, we refine monitorability to also determine bounds on the number\nof events as well as the time that must pass before monitoring the property may\nyield an informative verdict. We prove that for deterministic Timed Muller\nautomata, such bounds can be effectively computed. In contrast we show that for\nnondeterministic Timed B\\\"uchi automata such bounds are not computable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.10008v2", "cate": "cs.FL", "date": "2025-04-14", "updated": "2025-07-29"}
{"id": "2507.20295", "title": "Towards Generalized Parameter Tuning in Coherent Ising Machines: A Portfolio-Based Approach", "authors": ["Tatsuro Hanyu", "Takahiro Katagiri", "Daichi Mukunoki", "Tetsuya Hoshino"], "categories": ["cs.PF", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Performance (cs.PF)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20295v1", "summary": "Coherent Ising Machines (CIMs) have recently gained attention as a promising\ncomputing model for solving combinatorial optimization problems. In particular,\nthe Chaotic Amplitude Control (CAC) algorithm has demonstrated high solution\nquality, but its performance is highly sensitive to a large number of\nhyperparameters, making efficient tuning essential. In this study, we present\nan algorithm portfolio approach for hyperparameter tuning in CIMs employing\nChaotic Amplitude Control with momentum (CACm) algorithm. Our method\nincorporates multiple search strategies, enabling flexible and effective\nadaptation to the characteristics of the hyperparameter space. Specifically, we\npropose two representative tuning methods, Method A and Method B. Method A\noptimizes each hyperparameter sequentially with a fixed total number of trials,\nwhile Method B prioritizes hyperparameters based on initial evaluations before\napplying Method A in order. Performance evaluations were conducted on the\nSupercomputer \"Flow\" at Nagoya University, using planted Wishart instances and\nTime to Solution (TTS) as the evaluation metric. Compared to the baseline\nperformance with best-known hyperparameters, Method A achieved up to 1.47x\nimprovement, and Method B achieved up to 1.65x improvement. These results\ndemonstrate the effectiveness of the algorithm portfolio approach in enhancing\nthe tuning process for CIMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20295v1", "cate": "cs.PF", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20459", "title": "Diagonally-Weighted Generalized Method of Moments Estimation for Gaussian Mixture Modeling", "authors": ["Liu Zhang", "Oscar Mickelin", "Sheng Xu", "Amit Singer"], "categories": ["cs.LG", "cs.NA", "math.NA", "math.ST", "stat.ME", "stat.ML", "stat.TH", "62F12, 62H30, 15A69, 65Y20"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20459v1", "summary": "Since Pearson [Philosophical Transactions of the Royal Society of London. A,\n185 (1894), pp. 71-110] first applied the method of moments (MM) for modeling\ndata as a mixture of one-dimensional Gaussians, moment-based estimation methods\nhave proliferated. Among these methods, the generalized method of moments (GMM)\nimproves the statistical efficiency of MM by weighting the moments\nappropriately. However, the computational complexity and storage complexity of\nMM and GMM grow exponentially with the dimension, making these methods\nimpractical for high-dimensional data or when higher-order moments are\nrequired. Such computational bottlenecks are more severe in GMM since it\nadditionally requires estimating a large weighting matrix. To overcome these\nbottlenecks, we propose the diagonally-weighted GMM (DGMM), which achieves a\nbalance among statistical efficiency, computational complexity, and numerical\nstability. We apply DGMM to study the parameter estimation problem for weakly\nseparated heteroscedastic low-rank Gaussian mixtures and design a\ncomputationally efficient and numerically stable algorithm that obtains the\nDGMM estimator without explicitly computing or storing the moment tensors. We\nimplement the proposed algorithm and empirically validate the advantages of\nDGMM: in numerical studies, DGMM attains smaller estimation errors while\nrequiring substantially shorter runtime than MM and GMM. The code and data will\nbe available upon publication at https://github.com/liu-lzhang/dgmm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20459v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.07769", "title": "BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning", "authors": ["Ruohong Liu", "Jack Umenberger", "Yize Chen"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at the Workshop on Computational Optimization of Buildings (ICML CO-BUILD), 42nd International Conference on Machine Learning (ICML 2025), Vancouver, Canada", "url": "http://arxiv.org/abs/2507.07769v3", "summary": "Recent years have seen significant advancements in designing reinforcement\nlearning (RL)-based agents for building energy management. While individual\nsuccess is observed in simulated or controlled environments, the scalability of\nRL approaches in terms of efficiency and generalization across building\ndynamics and operational scenarios remains an open question. In this work, we\nformally characterize the generalization space for the cross-environment,\nmulti-objective building energy management task, and formulate the\nmulti-objective contextual RL problem. Such a formulation helps understand the\nchallenges of transferring learned policies across varied operational contexts\nsuch as climate and heat convection dynamics under multiple control objectives\nsuch as comfort level and energy consumption. We provide a principled way to\nparameterize such contextual information in realistic building RL environments,\nand construct a novel benchmark to facilitate the evaluation of generalizable\nRL algorithms in practical building control tasks. Our results show that\nexisting multi-objective RL methods are capable of achieving reasonable\ntrade-offs between conflicting objectives. However, their performance degrades\nunder certain environment variations, underscoring the importance of\nincorporating dynamics-dependent contextual information into the policy\nlearning process.", "comment": "Accepted at the Workshop on Computational Optimization of Buildings\n  (ICML CO-BUILD), 42nd International Conference on Machine Learning (ICML\n  2025), Vancouver, Canada", "pdf_url": "http://arxiv.org/pdf/2507.07769v3", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-25"}
{"id": "2507.20227", "title": "CTR-Driven Ad Text Generation via Online Feedback Preference Optimization", "authors": ["Yanda Chen", "Zihui Ren", "Qixiang Gao", "Jiale Chen", "Si Chen", "Xubin Li", "Tiezheng Ge", "Bo Zheng"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      9 pages, 6 figures, 5 tables", "url": "http://arxiv.org/abs/2507.20227v2", "summary": "Advertising text plays a critical role in determining click-through rates\n(CTR) in online advertising. Large Language Models (LLMs) offer significant\nefficiency advantages over manual ad text creation. However, LLM-generated ad\ntexts do not guarantee higher CTR performance compared to human-crafted texts,\nrevealing a gap between generation quality and online performance of ad texts.\nIn this work, we propose a novel ad text generation method which optimizes for\nCTR through preference optimization from online feedback. Our approach adopts\nan innovative two-stage framework: (1) diverse ad text sampling via one-shot\nin-context learning, using retrieval-augmented generation (RAG) to provide\nexemplars with chain-of-thought (CoT) reasoning; (2) CTR-driven preference\noptimization from online feedback, which weighs preference pairs according to\ntheir CTR gains and confidence levels. Through our method, the resulting model\nenables end-to-end generation of high-CTR ad texts. Extensive experiments have\ndemonstrated the effectiveness of our method in both offline and online\nmetrics. Notably, we have applied our method on a large-scale online shopping\nplatform and achieved significant CTR improvements, showcasing its strong\napplicability and effectiveness in advertising systems.", "comment": "9 pages, 6 figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.20227v2", "cate": "cs.IR", "date": "2025-07-27", "updated": "2025-07-29"}
{"id": "2506.15064", "title": "HiPreNets: High-Precision Neural Networks through Progressive Training", "authors": ["Ethan Mulle", "Wei Kang", "Qi Gong"], "categories": ["cs.LG", "cs.NA", "cs.NE", "math.NA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.15064v2", "summary": "Deep neural networks are powerful tools for solving nonlinear problems in\nscience and engineering, but training highly accurate models becomes\nchallenging as problem complexity increases. Non-convex optimization and\nnumerous hyperparameters to tune make performance improvement difficult, and\ntraditional approaches often prioritize minimizing mean squared error (MSE)\nwhile overlooking $L^{\\infty}$ error, which is the critical focus in many\napplications. To address these challenges, we present a progressive framework\nfor training and tuning high-precision neural networks (HiPreNets). Our\napproach refines a previously explored staged training technique for neural\nnetworks that improves an existing fully connected neural network by\nsequentially learning its prediction residuals using additional networks,\nleading to improved overall accuracy. We discuss how to take advantage of the\nstructure of the residuals to guide the choice of loss function, number of\nparameters to use, and ways to introduce adaptive data sampling techniques. We\nvalidate our framework's effectiveness through several benchmark problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.15064v2", "cate": "cs.LG", "date": "2025-06-18", "updated": "2025-07-29"}
{"id": "2507.21154", "title": "Assessment of Quantitative Cyber-Physical Reliability of SCADA Systems in Autonomous Vehicle to Grid (V2G) Capable Smart Grids", "authors": ["Md Abdul Gaffar"], "categories": ["cs.CR", "cs.SY", "eess.SY", "math.OC"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      5 pages, 6 figures", "url": "http://arxiv.org/abs/2507.21154v1", "summary": "The integration of electric vehicles (EVs) into power grids via\nVehicle-to-Grid (V2G) system technology is increasing day by day, but these\nphenomena present both advantages and disadvantages. V2G can increase grid\nreliability by providing distributed energy storage and ancillary services.\nHowever, on the other hand, it has a scope that encompasses the cyber-physical\nattack surface of the national power grid, introducing new vulnerabilities in\nmonitoring and supervisory control and data acquisition (SCADA) systems. This\npaper investigates the maliciousness caused by Autonomous Vehicle to Grid\n(AV2G) communication infrastructures and assesses their impacts on SCADA system\nreliability. This paper presents a quantitative reliability assessment using\nBayesian attack graph combined with probabilistic capacity outage modeling\nbased on IEEE RTS-79 system data. This work presents how AV2G-based attacks\ndegrade system performance by using Monte Carlo simulations method,\nhighlighting the need for cybersecurity-hardening strategies in smart grid\ndesign.", "comment": "5 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.21154v1", "cate": "cs.CR", "date": "2025-07-24", "updated": "2025-07-24"}
{"id": "2504.21429", "title": "Active Learning of Upward-Closed Sets of Words", "authors": ["Quentin Aristote"], "categories": ["cs.FL", "F.4.3"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      13 pages, 2 figures; presented at CALCO 2025", "url": "http://arxiv.org/abs/2504.21429v2", "summary": "We give a new proof of a result from well quasi-order theory on the\ncomputability of bases for upwards-closed sets of words. This new proof is\nbased on Angluin's L* algorithm, that learns an automaton from a minimally\nadequate teacher. This relates in particular two results from the 1980s:\nAngluin's L* algorithm, and a result from Valk and Jantzen on the computability\nof bases for upwards-closed sets of tuples of integers.\n  Along the way, we describe an algorithm for learning quasi-ordered automata\nfrom a minimally adequate teacher, and extend a generalization of Valk and\nJantzen's result, encompassing both words and integers, to finitely generated\nmonoids.", "comment": "13 pages, 2 figures; presented at CALCO 2025", "pdf_url": "http://arxiv.org/pdf/2504.21429v2", "cate": "cs.FL", "date": "2025-04-30", "updated": "2025-07-29"}
{"id": "2507.20353", "title": "A Theory of $θ$-Expectations", "authors": ["Qian Qi"], "categories": ["math.PR", "cs.AI", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20353v1", "summary": "The canonical theory of stochastic calculus under ambiguity, founded on\nsub-additivity, is insensitive to non-convex uncertainty structures, leading to\nan identifiability impasse. This paper develops a mathematical framework for an\nidentifiable calculus sensitive to non-convex geometry. We introduce the\n$\\theta$-BSDE, a class of backward stochastic differential equations where the\ndriver is determined by a pointwise maximization over a primitive, possibly\nnon-convex, uncertainty set. The system's tractability is predicated not on\nconvexity, but on a global analytic hypothesis: the existence of a unique and\nglobally Lipschitz maximizer map for the driver function. Under this\nhypothesis, which carves out a tractable class of models, we establish\nwell-posedness via a fixed-point argument. For a distinct, geometrically\nregular class of models, we prove a result of independent interest: under\nnon-degeneracy conditions from Malliavin calculus, the maximizer is unique\nalong any solution path, ensuring the model's internal consistency. We clarify\nthe fundamental logical gap between this pathwise property and the global\nregularity required by our existence proof. The resulting valuation operator\ndefines a dynamically consistent expectation, and we establish its connection\nto fully nonlinear PDEs via a Feynman-Kac formula.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20353v1", "cate": "math.PR", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20460", "title": "Shapley-Value-Based Graph Sparsification for GNN Inference", "authors": ["Selahattin Akkas", "Ariful Azad"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.20460v1", "summary": "Graph sparsification is a key technique for improving inference efficiency in\nGraph Neural Networks by removing edges with minimal impact on predictions. GNN\nexplainability methods generate local importance scores, which can be\naggregated into global scores for graph sparsification. However, many\nexplainability methods produce only non-negative scores, limiting their\napplicability for sparsification. In contrast, Shapley value based methods\nassign both positive and negative contributions to node predictions, offering a\ntheoretically robust and fair allocation of importance by evaluating many\nsubsets of graphs. Unlike gradient-based or perturbation-based explainers,\nShapley values enable better pruning strategies that preserve influential edges\nwhile removing misleading or adversarial connections. Our approach shows that\nShapley value-based graph sparsification maintains predictive performance while\nsignificantly reducing graph complexity, enhancing both interpretability and\nefficiency in GNN inference.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.20460v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.07953", "title": "Incremental Collision Laws Based on the Bouc-Wen Model: External Forces and Corner Cases", "authors": ["Mihails Milehins", "Dan Marghitu"], "categories": ["physics.class-ph", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Classical Physics (physics.class-ph)", "pdf_link": null, "comments": "Comments:      11 pages, 3 figures, see this https URL ; (v2-v3) various minor amendments; arXiv admin note: text overlap with arXiv:2410.08147", "url": "http://arxiv.org/abs/2507.07953v3", "summary": "In the article titled \"The Bouc-Wen Model for Binary Direct Collinear\nCollisions of Convex Viscoplastic Bodies\" and published in the Journal of\nComputational and Nonlinear Dynamics (Volume 20, Issue 6, June 2025), the\nauthors studied mathematical models of binary direct collinear collisions of\nconvex viscoplastic bodies that employed two incremental collision laws based\non the Bouc-Wen differential model of hysteresis. It was shown that the models\npossess favorable analytical properties, and several model parameter\nidentification studies were conducted, demonstrating that the models can\naccurately capture the nature of a variety of collision phenomena. In this\narticle, the aforementioned models are augmented by modeling the effects of\nexternal forces as time-dependent inputs that belong to a certain function\nspace. Furthermore, the range of the parameters under which the models possess\nfavorable analytical properties is extended to several corner cases that were\nnot considered in the prior publication. Finally, the previously conducted\nmodel parameter identification studies are extended, and an additional model\nparameter identification study is provided in an attempt to validate the\nability of the augmented models to represent the effects of external forces.", "comment": "11 pages, 3 figures, see https://gitlab.com/user9716869/EBWCM ;\n  (v2-v3) various minor amendments; arXiv admin note: text overlap with\n  arXiv:2410.08147", "pdf_url": "http://arxiv.org/pdf/2507.07953v3", "cate": "physics.class-ph", "date": "2025-07-10", "updated": "2025-07-27"}
{"id": "2410.10381", "title": "Collaborative filtering based on nonnegative/binary matrix factorization", "authors": ["Yukino Terui", "Yuka Inoue", "Yohei Hamakawa", "Kosuke Tatsumura", "Kazue Kudo"], "categories": ["cond-mat.stat-mech", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Statistical Mechanics (cond-mat.stat-mech)", "pdf_link": null, "comments": "Comments:      12 pages, 8 figures", "url": "http://arxiv.org/abs/2410.10381v4", "summary": "Collaborative filtering generates recommendations by exploiting user-item\nsimilarities based on rating data, which often contains numerous unrated items.\nTo predict scores for unrated items, matrix factorization techniques such as\nnonnegative matrix factorization (NMF) are often employed. Nonnegative/binary\nmatrix factorization (NBMF), which is an extension of NMF, approximates a\nnonnegative matrix as the product of nonnegative and binary matrices. While\nprevious studies have applied NBMF primarily to dense data such as images, this\npaper proposes a modified NBMF algorithm tailored for collaborative filtering\nwith sparse data. In the modified method, unrated entries in the rating matrix\nare masked, enhancing prediction accuracy. Furthermore, utilizing a low-latency\nIsing machine in NBMF is advantageous in terms of the computation time, making\nthe proposed method beneficial.", "comment": "12 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2410.10381v4", "cate": "cond-mat.stat-mech", "date": "2024-10-14", "updated": "2025-07-29"}
{"id": "2507.09772", "title": "Designing quantum chemistry algorithms with Just-In-Time compilation", "authors": ["Xiaojie Wu", "Yuanheng Wang"], "categories": ["physics.comp-ph", "cs.NA", "math.NA"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "Comments:      10 pages, 7 figures", "url": "http://arxiv.org/abs/2507.09772v3", "summary": "We introduce just-in-time (JIT) compilation to the integral kernels for\nGaussian-type orbitals (GTOs) to enhance the efficiency of electron repulsion\nintegral computations. For Coulomb and exchange (JK) matrices, JIT-based\nalgorithms yield a 2x speedup for the small 6-31G* basis set over GPU4PySCF\nv1.4 on an NVIDIA A100-80G GPU. By incorporating a novel algorithm designed for\norbitals with high angular momentum, the efficiency of JK evaluations with the\nlarge def2-TZVPP basis set is improved by up to 4x. The core CUDA\nimplementation is compact, comprising only ~1,000 lines of code, including\nsupport for single-precision arithmetic. Furthermore, the single-precision\nimplementation achieves a 3x speedup over the previous state-of-the-art.", "comment": "10 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.09772v3", "cate": "physics.comp-ph", "date": "2025-07-13", "updated": "2025-07-28"}
{"id": "2507.21162", "title": "Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems", "authors": ["Xu Yang", "Chenhui Lin", "Yue Yang", "Qi Wang", "Haotian Liu", "Haizhou Hua", "Wenchuan Wu"], "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21162v1", "summary": "The increasing penetration of distributed energy resources into active\ndistribution networks (ADNs) has made effective ADN dispatch imperative.\nHowever, the numerous newly-integrated ADN operators, such as distribution\nsystem aggregators, virtual power plant managers, and end prosumers, often lack\nspecialized expertise in power system operation, modeling, optimization, and\nprogramming. This knowledge gap renders reliance on human experts both costly\nand time-intensive. To address this challenge and enable intelligent, flexible\nADN dispatch, this paper proposes a large language model (LLM) powered\nautomated modeling and optimization approach. First, the ADN dispatch problems\nare decomposed into sequential stages, and a multi-LLM coordination\narchitecture is designed. This framework comprises an Information Extractor, a\nProblem Formulator, and a Code Programmer, tasked with information retrieval,\noptimization problem formulation, and code implementation, respectively.\nAfterwards, tailored refinement techniques are developed for each LLM agent,\ngreatly improving the accuracy and reliability of generated content. The\nproposed approach features a user-centric interface that enables ADN operators\nto derive dispatch strategies via simple natural language queries, eliminating\ntechnical barriers and increasing efficiency. Comprehensive comparisons and\nend-to-end demonstrations on various test cases validate the effectiveness of\nthe proposed architecture and methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21162v1", "cate": "cs.AI", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2305.10546", "title": "Games on Graphs: From Logic and Automata to Algorithms", "authors": ["Nathanaël Fijalkow", "C. Aiswarya", "Guy Avni", "Nathalie Bertrand", "Patricia Bouyer", "Romain Brenguier", "Arnaud Carayol", "Antonio Casares", "John Fearnley", "Paul Gastin", "Hugo Gimbert", "Thomas A. Henzinger", "Florian Horn", "Rasmus Ibsen-Jensen", "Nicolas Markey", "Benjamin Monmege", "Petr Novotný", "Pierre Ohlmann", "Mickael Randour", "Ocan Sankur", "Sylvain Schmitz", "Olivier Serre", "Mateusz Skomra", "Nathalie Sznajder", "Pierre Vandenhove"], "categories": ["cs.GT", "cs.FL", "cs.LO"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "Comments:      621 pages. Coordinator: Nathanaël Fijalkow", "url": "http://arxiv.org/abs/2305.10546v2", "summary": "The objective of this book is to give a comprehensive presentation of the\nresearch field concerned with infinite duration games on graphs. Historically,\nthese game models appeared in the study of automata and logic, and they later\nbecame important for program verification and synthesis. They have many more\napplications, in particular some of the models investigated in this book were\nintroduced and studied in neighbouring research communities such as\noptimisation, reinforcement learning, model theory, and set theory.", "comment": "621 pages. Coordinator: Nathana\\\"el Fijalkow", "pdf_url": "http://arxiv.org/pdf/2305.10546v2", "cate": "cs.GT", "date": "2023-05-17", "updated": "2025-07-29"}
{"id": "2507.20389", "title": "Solving Scene Understanding for Autonomous Navigation in Unstructured Environments", "authors": ["Naveen Mathews Renji", "Kruthika K", "Manasa Keshavamurthy", "Pooja Kumari", "S. Rajarajeswari"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20389v1", "summary": "Autonomous vehicles are the next revolution in the automobile industry and\nthey are expected to revolutionize the future of transportation. Understanding\nthe scenario in which the autonomous vehicle will operate is critical for its\ncompetent functioning. Deep Learning has played a massive role in the progress\nthat has been made till date. Semantic Segmentation, the process of annotating\nevery pixel of an image with an object class, is one crucial part of this scene\ncomprehension using Deep Learning. It is especially useful in Autonomous\nDriving Research as it requires comprehension of drivable and non-drivable\nareas, roadside objects and the like. In this paper semantic segmentation has\nbeen performed on the Indian Driving Dataset which has been recently compiled\non the urban and rural roads of Bengaluru and Hyderabad. This dataset is more\nchallenging compared to other datasets like Cityscapes, since it is based on\nunstructured driving environments. It has a four level hierarchy and in this\npaper segmentation has been performed on the first level. Five different models\nhave been trained and their performance has been compared using the Mean\nIntersection over Union. These are UNET, UNET+RESNET50, DeepLabsV3, PSPNet and\nSegNet. The highest MIOU of 0.6496 has been achieved. The paper discusses the\ndataset, exploratory data analysis, preparation, implementation of the five\nmodels and studies the performance and compares the results achieved in the\nprocess.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20389v1", "cate": "cs.CV", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20478", "title": "Conditional Diffusion Models for Global Precipitation Map Inpainting", "authors": ["Daiko Kishikawa", "Yuka Muto", "Shunji Kotsuki"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20478v1", "summary": "Incomplete satellite-based precipitation presents a significant challenge in\nglobal monitoring. For example, the Global Satellite Mapping of Precipitation\n(GSMaP) from JAXA suffers from substantial missing regions due to the orbital\ncharacteristics of satellites that have microwave sensors, and its current\ninterpolation methods often result in spatial discontinuities. In this study,\nwe formulate the completion of the precipitation map as a video inpainting task\nand propose a machine learning approach based on conditional diffusion models.\nOur method employs a 3D U-Net with a 3D condition encoder to reconstruct\ncomplete precipitation maps by leveraging spatio-temporal information from\ninfrared images, latitude-longitude grids, and physical time inputs. Training\nwas carried out on ERA5 hourly precipitation data from 2020 to 2023. We\ngenerated a pseudo-GSMaP dataset by randomly applying GSMaP masks to ERA maps.\nPerformance was evaluated for the calendar year 2024, and our approach produces\nmore spatio-temporally consistent inpainted precipitation maps compared to\nconventional methods. These results indicate the potential to improve global\nprecipitation monitoring using the conditional diffusion models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20478v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.09061", "title": "Imitation Learning in Continuous Action Spaces: Mitigating Compounding Error without Interaction", "authors": ["Thomas T. Zhang", "Daniel Pfrommer", "Nikolai Matni", "Max Simchowitz"], "categories": ["cs.LG", "cs.SY", "eess.SY", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Exposition and experiments have been deemed insufficient. Major long-term revisions are desired.", "url": "http://arxiv.org/abs/2507.09061v2", "summary": "We study the problem of imitating an expert demonstrator in a continuous\nstate-and-action dynamical system. While imitation learning in discrete\nsettings such as autoregressive language modeling has seen immense success and\npopularity in recent years, imitation in physical settings such as autonomous\ndriving and robot learning has proven comparably more complex due to the\ncompounding errors problem, often requiring elaborate set-ups to perform\nstably. Recent work has demonstrated that even in benign settings, exponential\ncompounding errors are unavoidable when learning solely from expert-controlled\ntrajectories, suggesting the need for more advanced policy parameterizations or\ndata augmentation. To this end, we present minimal interventions that provably\nmitigate compounding errors in continuous state-and-action imitation learning.\nWhen the system is open-loop stable, we prescribe \"action chunking,\" i.e.,\npredicting and playing sequences of actions in open-loop; when the system is\npossibly unstable, we prescribe \"noise injection,\" i.e., adding noise during\nexpert demonstrations. These interventions align with popular choices in modern\nrobot learning, though the benefits we derive are distinct from the effects\nthey were designed to target. Our results draw insights and tools from both\ncontrol theory and reinforcement learning; however, our analysis reveals novel\nconsiderations that do not naturally arise when either literature is considered\nin isolation.", "comment": "Exposition and experiments have been deemed insufficient. Major\n  long-term revisions are desired.", "pdf_url": "http://arxiv.org/pdf/2507.09061v2", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-26"}
{"id": "2504.03524", "title": "RANa: Retrieval-Augmented Navigation", "authors": ["Gianluca Monaci", "Rafael S. Rezende", "Romain Deffayet", "Gabriela Csurka", "Guillaume Bono", "Hervé Déjean", "Stéphane Clinchant", "Christian Wolf"], "categories": ["cs.CV", "cs.IR", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.03524v2", "summary": "Methods for navigation based on large-scale learning typically treat each\nepisode as a new problem, where the agent is spawned with a clean memory in an\nunknown environment. While these generalization capabilities to an unknown\nenvironment are extremely important, we claim that, in a realistic setting, an\nagent should have the capacity of exploiting information collected during\nearlier robot operations. We address this by introducing a new\nretrieval-augmented agent, trained with RL, capable of querying a database\ncollected from previous episodes in the same environment and learning how to\nintegrate this additional context information. We introduce a unique agent\narchitecture for the general navigation task, evaluated on ImageNav,\nInstance-ImageNav and ObjectNav. Our retrieval and context encoding methods are\ndata-driven and employ vision foundation models (FM) for both semantic and\ngeometric understanding. We propose new benchmarks for these settings and we\nshow that retrieval allows zero-shot transfer across tasks and environments\nwhile significantly improving performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.03524v2", "cate": "cs.CV", "date": "2025-04-04", "updated": "2025-07-29"}
{"id": "2507.21225", "title": "Fluidically Innervated Lattices Make Versatile and Durable Tactile Sensors", "authors": ["Annan Zhang", "Miguel Flores-Acton", "Andy Yu", "Anshul Gupta", "Maggie Yao", "Daniela Rus"], "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted for publication in the proceedings of the 2025 International Symposium on Experimental Robotics (ISER)", "url": "http://arxiv.org/abs/2507.21225v1", "summary": "Tactile sensing plays a fundamental role in enabling robots to navigate\ndynamic and unstructured environments, particularly in applications such as\ndelicate object manipulation, surface exploration, and human-robot interaction.\nIn this paper, we introduce a passive soft robotic fingertip with integrated\ntactile sensing, fabricated using a 3D-printed elastomer lattice with embedded\nair channels. This sensorization approach, termed fluidic innervation,\ntransforms the lattice into a tactile sensor by detecting pressure changes\nwithin sealed air channels, providing a simple yet robust solution to tactile\nsensing in robotics. Unlike conventional methods that rely on complex materials\nor designs, fluidic innervation offers a simple, scalable, single-material\nfabrication process. We characterize the sensors' response, develop a geometric\nmodel to estimate tip displacement, and train a neural network to accurately\npredict contact location and contact force. Additionally, we integrate the\nfingertip with an admittance controller to emulate spring-like behavior,\ndemonstrate its capability for environment exploration through tactile\nfeedback, and validate its durability under high impact and cyclic loading\nconditions. This tactile sensing technique offers advantages in terms of\nsimplicity, adaptability, and durability and opens up new opportunities for\nversatile robotic manipulation.", "comment": "Accepted for publication in the proceedings of the 2025 International\n  Symposium on Experimental Robotics (ISER)", "pdf_url": "http://arxiv.org/pdf/2507.21225v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2502.12844", "title": "Generalized De Bruijn Words, Invertible Necklaces, and the Burrows-Wheeler Transform", "authors": ["Gabriele Fici", "Estéban Gabory"], "categories": ["math.CO", "cs.DM", "cs.DS", "cs.FL"], "primary_category": "Subjects:       Combinatorics (math.CO)", "pdf_link": null, "comments": "Comments:      Submitted", "url": "http://arxiv.org/abs/2502.12844v3", "summary": "We define generalized de Bruijn words as those words having a Burrows-Wheeler\ntransform that is a concatenation of permutations of the alphabet. We show that\ngeneralized de Bruijn words are in 1-to-1 correspondence with Hamiltonian\ncycles in the generalized de Bruijn graphs introduced in the early '80s in the\ncontext of network design. When the size of the alphabet is a prime $p$, we\ndefine invertible necklaces as those whose BWT-matrix is non-singular. We show\nthat invertible necklaces of length $n$ correspond to normal bases of the\nfinite field $F_{p^n}$, and that they form an Abelian group isomorphic to the\nReutenauer group $RG_p^n$. Using known results in abstract algebra, we can make\na bridge between generalized de Bruijn words and invertible necklaces. In\nparticular, we highlight a correspondence between binary de Bruijn words of\norder $d+1$, binary necklaces of length $2^{d}$ having an odd number of $1$'s,\ninvertible BWT matrices of size $2^{d}\\times 2^{d}$, and normal bases of the\nfinite field $F_{2^{2^{d}}}$.", "comment": "Submitted", "pdf_url": "http://arxiv.org/pdf/2502.12844v3", "cate": "math.CO", "date": "2025-02-18", "updated": "2025-07-29"}
{"id": "2507.20423", "title": "CodeNER: Code Prompting for Named Entity Recognition", "authors": ["Sungwoo Han", "Hyeyeon Kim", "Jingun Kwon", "Hidetaka Kamigaito", "Manabu Okumura"], "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      18 pages, 6 figures", "url": "http://arxiv.org/abs/2507.20423v1", "summary": "Recent studies have explored various approaches for treating candidate named\nentity spans as both source and target sequences in named entity recognition\n(NER) by leveraging large language models (LLMs). Although previous approaches\nhave successfully generated candidate named entity spans with suitable labels,\nthey rely solely on input context information when using LLMs, particularly,\nChatGPT. However, NER inherently requires capturing detailed labeling\nrequirements with input context information. To address this issue, we propose\na novel method that leverages code-based prompting to improve the capabilities\nof LLMs in understanding and performing NER. By embedding code within prompts,\nwe provide detailed BIO schema instructions for labeling, thereby exploiting\nthe ability of LLMs to comprehend long-range scopes in programming languages.\nExperimental results demonstrate that the proposed code-based prompting method\noutperforms conventional text-based prompting on ten benchmarks across English,\nArabic, Finnish, Danish, and German datasets, indicating the effectiveness of\nexplicitly structuring NER instructions. We also verify that combining the\nproposed code-based prompting method with the chain-of-thought prompting\nfurther improves performance.", "comment": "18 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.20423v1", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20490", "title": "HIAL: A New Paradigm for Hypergraph Active Learning via Influence Maximization", "authors": ["Yanheng Hou", "Xunkai Li", "Zhenjun Li", "Bing Zhou", "Ronghua Li", "Guoren Wang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20490v1", "summary": "In recent years, Hypergraph Neural Networks (HNNs) have demonstrated immense\npotential in handling complex systems with high-order interactions. However,\nacquiring large-scale, high-quality labeled data for these models is costly,\nmaking Active Learning (AL) a critical technique. Existing Graph Active\nLearning (GAL) methods, when applied to hypergraphs, often rely on techniques\nlike \"clique expansion,\" which destroys the high-order structural information\ncrucial to a hypergraph's success, thereby leading to suboptimal performance.\nTo address this challenge, we introduce HIAL (Hypergraph Active Learning), a\nnative active learning framework designed specifically for hypergraphs. We\ninnovatively reformulate the Hypergraph Active Learning (HAL) problem as an\nInfluence Maximization task. The core of HIAL is a dual-perspective influence\nfunction that, based on our novel \"High-Order Interaction-Aware (HOI-Aware)\"\npropagation mechanism, synergistically evaluates a node's feature-space\ncoverage (via Magnitude of Influence, MoI) and its topological influence (via\nExpected Diffusion Value, EDV). We prove that this objective function is\nmonotone and submodular, thus enabling the use of an efficient greedy algorithm\nwith a formal (1-1/e) approximation guarantee. Extensive experiments on seven\npublic datasets demonstrate that HIAL significantly outperforms\nstate-of-the-art baselines in terms of performance, efficiency, generality, and\nrobustness, establishing an efficient and powerful new paradigm for active\nlearning on hypergraphs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20490v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21281", "title": "Sliding Mode Control for Uncertain Systems with Time-Varying Delays via Predictor Feedback and Super-Twisting Observer", "authors": ["Hardy Pinto", "Tiago Roux Oliveira", "Liu Hsu"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      15 pages, 8 figures", "url": "http://arxiv.org/abs/2507.21281v1", "summary": "This paper introduces a novel stabilization control strategy for linear\ntime-invariant systems affected by known time-varying measurement delays and\nmatched unknown nonlinear disturbances, which may encompass actuator faults. It\nis considered that part of the state vector is not available for real-time\nmeasurement. To address this, the proposed approach combines an open-loop\npredictor with a state observer designed using the Super-Twisting Algorithm,\naiming to compensate for the delays and estimate the unmeasured state\ncomponents. Specifically, the nonlinear observer-based framework enables the\nreconstruction of unmodeled fault signals without assuming that they originate\nfrom a known exogenous system, offering robustness against parametric\nuncertainties. Meanwhile, the predictor forwards the delayed output in time.\nSubsequently, a sliding mode control law is formulated to enforce an ideal\nsliding mode and ensure global stabilization, even under a broader class of\nperturbations, unmodeled disturbances, parametric uncertainties, and delays,\nowing to the integration of the Super-Twisting observer. Numerical simulations\nillustrate the efficiency of the proposed approach.", "comment": "15 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.21281v1", "cate": "math.OC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2504.08575", "title": "Prophecies all the Way: Game-based Model-Checking for HyperQPTL beyond $\\forall^*\\exists^*$", "authors": ["Sarah Winter", "Martin Zimmermann"], "categories": ["cs.LO", "cs.FL"], "primary_category": "Subjects:       Logic in Computer Science (cs.LO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.08575v3", "summary": "Model-checking HyperLTL, a temporal logic expressing properties of sets of\ntraces with applications to information-flow based security and privacy, has a\ndecidable, but TOWER-complete, model-checking problem. While the classical\nmodel-checking algorithm for full HyperLTL is automata-theoretic, more\nrecently, a game-based alternative for the $\\forall^*\\exists^*$-fragment has\nbeen presented.\n  Here, we employ imperfect information-games to extend the game-based approach\nto full HyperQPTL, which features arbitrary quantifier prefixes and\nquantification over propositions and can express every $\\omega$-regular\nhyperproperty. As a byproduct of our game-based algorithm, we obtain\nfinite-state implementations of Skolem functions via transducers with lookahead\nthat explain satisfaction or violation of HyperQPTL properties.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.08575v3", "cate": "cs.LO", "date": "2025-04-11", "updated": "2025-07-29"}
{"id": "2507.20491", "title": "Speaking in Words, Thinking in Logic: A Dual-Process Framework in QA Systems", "authors": ["Tuan Bui", "Trong Le", "Phat Thai", "Sang Nguyen", "Minh Hua", "Ngan Pham", "Thang Bui", "Tho Quan"], "categories": ["cs.CL", "cs.AI", "cs.SC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      8 pages, 3 figures. Accepted at the International Joint Conference on Neural Networks (IJCNN) 2025, Workshop on Trustworthiness and Reliability in Neuro-Symbolic AI. this https URL", "url": "http://arxiv.org/abs/2507.20491v1", "summary": "Recent advances in large language models (LLMs) have significantly enhanced\nquestion-answering (QA) capabilities, particularly in open-domain contexts.\nHowever, in closed-domain scenarios such as education, healthcare, and law,\nusers demand not only accurate answers but also transparent reasoning and\nexplainable decision-making processes. While neural-symbolic (NeSy) frameworks\nhave emerged as a promising solution, leveraging LLMs for natural language\nunderstanding and symbolic systems for formal reasoning, existing approaches\noften rely on large-scale models and exhibit inefficiencies in translating\nnatural language into formal logic representations.\n  To address these limitations, we introduce Text-JEPA (Text-based\nJoint-Embedding Predictive Architecture), a lightweight yet effective framework\nfor converting natural language into first-order logic (NL2FOL). Drawing\ninspiration from dual-system cognitive theory, Text-JEPA emulates System 1 by\nefficiently generating logic representations, while the Z3 solver operates as\nSystem 2, enabling robust logical inference. To rigorously evaluate the\nNL2FOL-to-reasoning pipeline, we propose a comprehensive evaluation framework\ncomprising three custom metrics: conversion score, reasoning score, and\nSpearman rho score, which collectively capture the quality of logical\ntranslation and its downstream impact on reasoning accuracy.\n  Empirical results on domain-specific datasets demonstrate that Text-JEPA\nachieves competitive performance with significantly lower computational\noverhead compared to larger LLM-based systems. Our findings highlight the\npotential of structured, interpretable reasoning frameworks for building\nefficient and explainable QA systems in specialized domains.", "comment": "8 pages, 3 figures. Accepted at the International Joint Conference on\n  Neural Networks (IJCNN) 2025, Workshop on Trustworthiness and Reliability in\n  Neuro-Symbolic AI. https://2025.ijcnn.org", "pdf_url": "http://arxiv.org/pdf/2507.20491v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20498", "title": "Mixture of Length and Pruning Experts for Knowledge Graphs Reasoning", "authors": ["Enjun Du", "Siyi Liu", "Yongqi Zhang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20498v1", "summary": "Knowledge Graph (KG) reasoning, which aims to infer new facts from structured\nknowledge repositories, plays a vital role in Natural Language Processing (NLP)\nsystems. Its effectiveness critically depends on constructing informative and\ncontextually relevant reasoning paths. However, existing graph neural networks\n(GNNs) often adopt rigid, query-agnostic path-exploration strategies, limiting\ntheir ability to adapt to diverse linguistic contexts and semantic nuances. To\naddress these limitations, we propose \\textbf{MoKGR}, a mixture-of-experts\nframework that personalizes path exploration through two complementary\ncomponents: (1) a mixture of length experts that adaptively selects and weights\ncandidate path lengths according to query complexity, providing query-specific\nreasoning depth; and (2) a mixture of pruning experts that evaluates candidate\npaths from a complementary perspective, retaining the most informative paths\nfor each query. Through comprehensive experiments on diverse benchmark, MoKGR\ndemonstrates superior performance in both transductive and inductive settings,\nvalidating the effectiveness of personalized path exploration in KGs reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20498v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21384", "title": "Projecting the New Body: How Body Image Evolves During Learning to Walk with a Wearable Robot", "authors": ["I-Chieh Lee", "He Huang"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21384v1", "summary": "Advances in wearable robotics challenge the traditional definition of human\nmotor systems, as wearable robots redefine body structure, movement capability,\nand perception of their own bodies. We measured gait performance and perceived\nbody images via Selected Coefficient of Perceived Motion, SCoMo, after each\ntraining session. Based on human motor learning theory extended to wearer-robot\nsystems, we hypothesized that learning the perceived body image when walking\nwith a robotic leg co-evolves with the actual gait improvement and becomes more\ncertain and more accurate to the actual motion. Our result confirmed that motor\nlearning improved both physical and perceived gait pattern towards normal,\nindicating that via practice the wearers incorporated the robotic leg into\ntheir sensorimotor systems to enable wearer-robot movement coordination.\nHowever, a persistent discrepancy between perceived and actual motion remained,\nlikely due to the absence of direct sensation and control of the prosthesis\nfrom wearers. Additionally, the perceptual overestimation at the later training\nsessions might limit further motor improvement. These findings suggest that\nenhancing the human sense of wearable robots and frequent calibrating\nperception of body image are essential for effective training with lower limb\nwearable robots and for developing more embodied assistive technologies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21384v1", "cate": "cs.RO", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20499", "title": "DmC: Nearest Neighbor Guidance Diffusion Model for Offline Cross-domain Reinforcement Learning", "authors": ["Linh Le Pham Van", "Minh Hoang Nguyen", "Duc Kieu", "Hung Le", "Hung The Tran", "Sunil Gupta"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      accepted at ECAI 2025", "url": "http://arxiv.org/abs/2507.20499v1", "summary": "Cross-domain offline reinforcement learning (RL) seeks to enhance sample\nefficiency in offline RL by utilizing additional offline source datasets. A key\nchallenge is to identify and utilize source samples that are most relevant to\nthe target domain. Existing approaches address this challenge by measuring\ndomain gaps through domain classifiers, target transition dynamics modeling, or\nmutual information estimation using contrastive loss. However, these methods\noften require large target datasets, which is impractical in many real-world\nscenarios. In this work, we address cross-domain offline RL under a limited\ntarget data setting, identifying two primary challenges: (1) Dataset imbalance,\nwhich is caused by large source and small target datasets and leads to\noverfitting in neural network-based domain gap estimators, resulting in\nuninformative measurements; and (2) Partial domain overlap, where only a subset\nof the source data is closely aligned with the target domain. To overcome these\nissues, we propose DmC, a novel framework for cross-domain offline RL with\nlimited target samples. Specifically, DmC utilizes $k$-nearest neighbor\n($k$-NN) based estimation to measure domain proximity without neural network\ntraining, effectively mitigating overfitting. Then, by utilizing this domain\nproximity, we introduce a nearest-neighbor-guided diffusion model to generate\nadditional source samples that are better aligned with the target domain, thus\nenhancing policy learning with more effective source samples. Through\ntheoretical analysis and extensive experiments in diverse MuJoCo environments,\nwe demonstrate that DmC significantly outperforms state-of-the-art cross-domain\noffline RL methods, achieving substantial performance gains.", "comment": "accepted at ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.20499v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20505", "title": "Attributed Graph Clustering with Multi-Scale Weight-Based Pairwise Coarsening and Contrastive Learning", "authors": ["Binxiong Li", "Yuefei Wang", "Binyu Zhao", "Heyang Gao", "Benhan Yang", "Quanzhou Luo", "Xue Li", "Xu Xiang", "Yujie Liu", "Huijie Tang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The source code for this study is available at this https URL", "url": "http://arxiv.org/abs/2507.20505v1", "summary": "This study introduces the Multi-Scale Weight-Based Pairwise Coarsening and\nContrastive Learning (MPCCL) model, a novel approach for attributed graph\nclustering that effectively bridges critical gaps in existing methods,\nincluding long-range dependency, feature collapse, and information loss.\nTraditional methods often struggle to capture high-order graph features due to\ntheir reliance on low-order attribute information, while contrastive learning\ntechniques face limitations in feature diversity by overemphasizing local\nneighborhood structures. Similarly, conventional graph coarsening methods,\nthough reducing graph scale, frequently lose fine-grained structural details.\nMPCCL addresses these challenges through an innovative multi-scale coarsening\nstrategy, which progressively condenses the graph while prioritizing the\nmerging of key edges based on global node similarity to preserve essential\nstructural information. It further introduces a one-to-many contrastive\nlearning paradigm, integrating node embeddings with augmented graph views and\ncluster centroids to enhance feature diversity, while mitigating feature\nmasking issues caused by the accumulation of high-frequency node weights during\nmulti-scale coarsening. By incorporating a graph reconstruction loss and KL\ndivergence into its self-supervised learning framework, MPCCL ensures\ncross-scale consistency of node representations. Experimental evaluations\nreveal that MPCCL achieves a significant improvement in clustering performance,\nincluding a remarkable 15.24% increase in NMI on the ACM dataset and notable\nrobust gains on smaller-scale datasets such as Citeseer, Cora and DBLP.", "comment": "The source code for this study is available at\n  https://github.com/YF-W/MPCCL", "pdf_url": "http://arxiv.org/pdf/2507.20505v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21394", "title": "Systolic Array-based Accelerator for State-Space Models", "authors": ["Shiva Raja", "Cansu Demirkiran", "Aakash Sarkar", "Milos Popovic", "Ajay Joshi"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21394v1", "summary": "Sequence modeling is crucial for AI to understand temporal data and detect\ncomplex time-dependent patterns. While recurrent neural networks (RNNs),\nconvolutional neural networks (CNNs), and Transformers have advanced in\ncapturing long-range dependencies, they struggle with achieving high accuracy\nwith very long sequences due to limited memory retention (fixed context\nwindow). State-Space Models (SSMs) leverage exponentially decaying memory\nenabling lengthy context window and so they process very long data sequences\nmore efficiently than recurrent and Transformer-based models. Unlike\ntraditional neural models like CNNs and RNNs, SSM-based models require solving\ndifferential equations through continuous integration, making training and\ninference both compute- and memory-intensive on conventional CPUs and GPUs. In\nthis paper we introduce a specialized hardware accelerator, EpochCore, for\naccelerating SSMs. EpochCore is based on systolic arrays (SAs) and is designed\nto enhance the energy efficiency and throughput of inference of SSM-based\nmodels for long-range sequence tasks. Within the SA, we propose a versatile\nprocessing element (PE) called LIMA-PE to perform traditional and specialized\nMAC operations to support traditional DNNs and SSMs. To complement the\nEpochCore microarchitecture, we propose a novel dataflow, ProDF, which enables\nhighly efficient execution of SSM-based models. By leveraging the LIMA-PE\nmicroarchitecture and ProDF, EpochCore achieves on average 250x gains in\nperformance and 45x improvement in energy efficiency, at the expense of 2x\nincrease in area cost over traditional SA-based accelerators, and around\n~2,000x improvement in latency/inference on LRA datasets compared to GPU kernel\noperations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21394v1", "cate": "cs.LG", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20529", "title": "Enhancing Spatial Reasoning through Visual and Textual Thinking", "authors": ["Xun Liang", "Xin Guo", "Zhongming Jin", "Weihang Pan", "Penghui Shang", "Deng Cai", "Binbin Lin", "Jieping Ye"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20529v1", "summary": "The spatial reasoning task aims to reason about the spatial relationships in\n2D and 3D space, which is a fundamental capability for Visual Question\nAnswering (VQA) and robotics. Although vision language models (VLMs) have\ndeveloped rapidly in recent years, they are still struggling with the spatial\nreasoning task. In this paper, we introduce a method that can enhance Spatial\nreasoning through Visual and Textual thinking Simultaneously (SpatialVTS). In\nthe spatial visual thinking phase, our model is trained to generate\nlocation-related specific tokens of essential targets automatically. Not only\nare the objects mentioned in the problem addressed, but also the potential\nobjects related to the reasoning are considered. During the spatial textual\nthinking phase, Our model conducts long-term thinking based on visual cues and\ndialogues, gradually inferring the answers to spatial reasoning problems. To\neffectively support the model's training, we perform manual corrections to the\nexisting spatial reasoning dataset, eliminating numerous incorrect labels\nresulting from automatic annotation, restructuring the data input format to\nenhance generalization ability, and developing thinking processes with logical\nreasoning details. Without introducing additional information (such as masks or\ndepth), our model's overall average level in several spatial understanding\ntasks has significantly improved compared with other models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20529v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20513", "title": "Efficient Proxy Raytracer for Optical Systems using Implicit Neural Representations", "authors": ["Shiva Sinaei", "Chuanjun Zheng", "Kaan Akşit", "Daisuke Iwai"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20513v1", "summary": "Ray tracing is a widely used technique for modeling optical systems,\ninvolving sequential surface-by-surface computations, which can be\ncomputationally intensive. We propose Ray2Ray, a novel method that leverages\nimplicit neural representations to model optical systems with greater\nefficiency, eliminating the need for surface-by-surface computations in a\nsingle pass end-to-end model. Ray2Ray learns the mapping between rays emitted\nfrom a given source and their corresponding rays after passing through a given\noptical system in a physically accurate manner. We train Ray2Ray on nine\noff-the-shelf optical systems, achieving positional errors on the order of\n1{\\mu}m and angular deviations on the order 0.01 degrees in the estimated\noutput rays. Our work highlights the potential of neural representations as a\nproxy for optical raytracer.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20513v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21479", "title": "Capacity-Constrained Continual Learning", "authors": ["Zheng Wen", "Doina Precup", "Benjamin Van Roy", "Satinder Singh"], "categories": ["cs.LG", "cs.AI", "cs.IT", "cs.SY", "eess.SY", "math.IT", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21479v1", "summary": "Any agents we can possibly build are subject to capacity constraints, as\nmemory and compute resources are inherently finite. However, comparatively\nlittle attention has been dedicated to understanding how agents with limited\ncapacity should allocate their resources for optimal performance. The goal of\nthis paper is to shed some light on this question by studying a simple yet\nrelevant continual learning problem: the capacity-constrained\nlinear-quadratic-Gaussian (LQG) sequential prediction problem. We derive a\nsolution to this problem under appropriate technical conditions. Moreover, for\nproblems that can be decomposed into a set of sub-problems, we also demonstrate\nhow to optimally allocate capacity across these sub-problems in the steady\nstate. We view the results of this paper as a first step in the systematic\ntheoretical study of learning under capacity constraints.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21479v1", "cate": "cs.LG", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21058", "title": "Categorical Classification of Book Summaries Using Word Embedding Techniques", "authors": ["Kerem Keskin", "Mümine Kaya Keleş"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      in Turkish language. This paper was published in the proceedings of the 6th International Conference on Data Science and Applications ICONDATA24, held on September between 2 and 6, 2024, in Pristina, Kosovo. For full text book see this https URL", "url": "http://arxiv.org/abs/2507.21058v1", "summary": "In this study, book summaries and categories taken from book sites were\nclassified using word embedding methods, natural language processing techniques\nand machine learning algorithms. In addition, one hot encoding, Word2Vec and\nTerm Frequency - Inverse Document Frequency (TF-IDF) methods, which are\nfrequently used word embedding methods were used in this study and their\nsuccess was compared. Additionally, the combination table of the pre-processing\nmethods used is shown and added to the table. Looking at the results, it was\nobserved that Support Vector Machine, Naive Bayes and Logistic Regression\nModels and TF-IDF and One-Hot Encoder word embedding techniques gave more\nsuccessful results for Turkish texts.", "comment": "in Turkish language. This paper was published in the proceedings of\n  the 6th International Conference on Data Science and Applications ICONDATA24,\n  held on September between 2 and 6, 2024, in Pristina, Kosovo. For full text\n  book see https://www.icondata.org/en/proceedings-books", "pdf_url": "http://arxiv.org/pdf/2507.21058v1", "cate": "cs.CL", "date": "2025-05-12", "updated": "2025-05-12"}
{"id": "2507.20534", "title": "Kimi K2: Open Agentic Intelligence", "authors": ["Kimi Team", "Yifan Bai", "Yiping Bao", "Guanduo Chen", "Jiahao Chen", "Ningxin Chen", "Ruijue Chen", "Yanru Chen", "Yuankun Chen", "Yutian Chen", "Zhuofu Chen", "Jialei Cui", "Hao Ding", "Mengnan Dong", "Angang Du", "Chenzhuang Du", "Dikang Du", "Yulun Du", "Yu Fan", "Yichen Feng", "Kelin Fu", "Bofei Gao", "Hongcheng Gao", "Peizhong Gao", "Tong Gao", "Xinran Gu", "Longyu Guan", "Haiqing Guo", "Jianhang Guo", "Hao Hu", "Xiaoru Hao", "Tianhong He", "Weiran He", "Wenyang He", "Chao Hong", "Yangyang Hu", "Zhenxing Hu", "Weixiao Huang", "Zhiqi Huang", "Zihao Huang", "Tao Jiang", "Zhejun Jiang", "Xinyi Jin", "Yongsheng Kang", "Guokun Lai", "Cheng Li", "Fang Li", "Haoyang Li", "Ming Li", "Wentao Li", "Yanhao Li", "Yiwei Li", "Zhaowei Li", "Zheming Li", "Hongzhan Lin", "Xiaohan Lin", "Zongyu Lin", "Chengyin Liu", "Chenyu Liu", "Hongzhang Liu", "Jingyuan Liu", "Junqi Liu", "Liang Liu", "Shaowei Liu", "T. Y. Liu", "Tianwei Liu", "Weizhou Liu", "Yangyang Liu", "Yibo Liu", "Yiping Liu", "Yue Liu", "Zhengying Liu", "Enzhe Lu", "Lijun Lu", "Shengling Ma", "Xinyu Ma", "Yingwei Ma", "Shaoguang Mao", "Jie Mei", "Xin Men", "Yibo Miao", "Siyuan Pan", "Yebo Peng", "Ruoyu Qin", "Bowen Qu", "Zeyu Shang", "Lidong Shi", "Shengyuan Shi", "Feifan Song", "Jianlin Su", "Zhengyuan Su", "Xinjie Sun", "Flood Sung", "Heyi Tang", "Jiawen Tao", "Qifeng Teng", "Chensi Wang", "Dinglu Wang", "Feng Wang", "Haiming Wang", "Jianzhou Wang", "Jiaxing Wang", "Jinhong Wang", "Shengjie Wang", "Shuyi Wang", "Yao Wang", "Yejie Wang", "Yiqin Wang", "Yuxin Wang", "Yuzhi Wang", "Zhaoji Wang", "Zhengtao Wang", "Zhexu Wang", "Chu Wei", "Qianqian Wei", "Wenhao Wu", "Xingzhe Wu", "Yuxin Wu", "Chenjun Xiao", "Xiaotong Xie", "Weimin Xiong", "Boyu Xu", "Jing Xu", "Jinjing Xu", "L. H. Xu", "Lin Xu", "Suting Xu", "Weixin Xu", "Xinran Xu", "Yangchuan Xu", "Ziyao Xu", "Junjie Yan", "Yuzi Yan", "Xiaofei Yang", "Ying Yang", "Zhen Yang", "Zhilin Yang", "Zonghan Yang", "Haotian Yao", "Xingcheng Yao", "Wenjie Ye", "Zhuorui Ye", "Bohong Yin", "Longhui Yu", "Enming Yuan", "Hongbang Yuan", "Mengjie Yuan", "Haobing Zhan", "Dehao Zhang", "Hao Zhang", "Wanlu Zhang", "Xiaobin Zhang", "Yangkun Zhang", "Yizhi Zhang", "Yongting Zhang", "Yu Zhang", "Yutao Zhang", "Yutong Zhang", "Zheng Zhang", "Haotian Zhao", "Yikai Zhao", "Huabin Zheng", "Shaojie Zheng", "Jianren Zhou", "Xinyu Zhou", "Zaida Zhou", "Zhen Zhu", "Weiyu Zhuang", "Xinxing Zu"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      tech report of Kimi K2", "url": "http://arxiv.org/abs/2507.20534v1", "summary": "We introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32\nbillion activated parameters and 1 trillion total parameters. We propose the\nMuonClip optimizer, which improves upon Muon with a novel QK-clip technique to\naddress training instability while enjoying the advanced token efficiency of\nMuon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zero\nloss spike. During post-training, K2 undergoes a multi-stage post-training\nprocess, highlighted by a large-scale agentic data synthesis pipeline and a\njoint reinforcement learning (RL) stage, where the model improves its\ncapabilities through interactions with real and synthetic environments.\n  Kimi K2 achieves state-of-the-art performance among open-source non-thinking\nmodels, with strengths in agentic capabilities. Notably, K2 obtains 66.1 on\nTau2-Bench, 76.5 on ACEBench (En), 65.8 on SWE-Bench Verified, and 47.3 on\nSWE-Bench Multilingual -- surpassing most open and closed-sourced baselines in\nnon-thinking settings. It also exhibits strong capabilities in coding,\nmathematics, and reasoning tasks, with a score of 53.7 on LiveCodeBench v6,\n49.5 on AIME 2025, 75.1 on GPQA-Diamond, and 27.1 on OJBench, all without\nextended thinking. These results position Kimi K2 as one of the most capable\nopen-source large language models to date, particularly in software engineering\nand agentic tasks. We release our base and post-trained model checkpoints to\nfacilitate future research and applications of agentic intelligence.", "comment": "tech report of Kimi K2", "pdf_url": "http://arxiv.org/pdf/2507.20534v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20533", "title": "Kernel Learning for Sample Constrained Black-Box Optimization", "authors": ["Rajalaxmi Rajagopalan", "Yu-Lin Wei", "Romit Roy Choudhury"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to AAAI 2025", "url": "http://arxiv.org/abs/2507.20533v1", "summary": "Black box optimization (BBO) focuses on optimizing unknown functions in\nhigh-dimensional spaces. In many applications, sampling the unknown function is\nexpensive, imposing a tight sample budget. Ongoing work is making progress on\nreducing the sample budget by learning the shape/structure of the function,\nknown as kernel learning. We propose a new method to learn the kernel of a\nGaussian Process. Our idea is to create a continuous kernel space in the latent\nspace of a variational autoencoder, and run an auxiliary optimization to\nidentify the best kernel. Results show that the proposed method, Kernel\nOptimized Blackbox Optimization (KOBO), outperforms state of the art by\nestimating the optimal at considerably lower sample budgets. Results hold not\nonly across synthetic benchmark functions but also in real applications. We\nshow that a hearing aid may be personalized with fewer audio queries to the\nuser, or a generative model could converge to desirable images from limited\nuser ratings.", "comment": "Accepted to AAAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.20533v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21543", "title": "On Policy Stochasticity in Mutual Information Optimal Control of Linear Systems", "authors": ["Shoju Enami", "Kenji Kashima"], "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2507.21543v1", "summary": "In recent years, mutual information optimal control has been proposed as an\nextension of maximum entropy optimal control. Both approaches introduce\nregularization terms to render the policy stochastic, and it is important to\ntheoretically clarify the relationship between the temperature parameter (i.e.,\nthe coefficient of the regularization term) and the stochasticity of the\npolicy. Unlike in maximum entropy optimal control, this relationship remains\nunexplored in mutual information optimal control. In this paper, we investigate\nthis relationship for a mutual information optimal control problem (MIOCP) of\ndiscrete-time linear systems. After extending the result of a previous study of\nthe MIOCP, we establish the existence of an optimal policy of the MIOCP, and\nthen derive the respective conditions on the temperature parameter under which\nthe optimal policy becomes stochastic and deterministic. Furthermore, we also\nderive the respective conditions on the temperature parameter under which the\npolicy obtained by an alternating optimization algorithm becomes stochastic and\ndeterministic. The validity of the theoretical results is demonstrated through\nnumerical experiments.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2507.21543v1", "cate": "math.OC", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21065", "title": "Dialogic Social Learning for Artificial Agents: Enhancing LLM Ontology Acquisition through Mixed-Initiative Educational Interactions", "authors": ["Sabrina Patania", "Luca Annese", "Cansu Koyuturk", "Azzurra Ruggeri", "Dimitri Ognibene"], "categories": ["cs.CL", "cs.HC", "cs.LG", "cs.RO", "I.2.7, I.2.9, j.4,"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      submitted to ICSR2025", "url": "http://arxiv.org/abs/2507.21065v1", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in\nprocessing extensive offline datasets. However, they often face challenges in\nacquiring and integrating complex, knowledge online. Traditional AI training\nparadigms, predominantly based on supervised learning or reinforcement\nlearning, mirror a 'Piagetian' model of independent exploration. These\napproaches typically rely on large datasets and sparse feedback signals,\nlimiting the models' ability to learn efficiently from interactions. Drawing\ninspiration from Vygotsky's sociocultural theory, this study explores the\npotential of socially mediated learning paradigms to address these limitations.\n  We introduce a dynamic environment, termed the 'AI Social Gym', where an AI\nlearner agent engages in dyadic pedagogical dialogues with knowledgeable AI\nteacher agents. These interactions emphasize external, structured dialogue as a\ncore mechanism for knowledge acquisition, contrasting with methods that depend\nsolely on internal inference or pattern recognition.\n  Our investigation focuses on how different pedagogical strategies impact the\nAI learning process in the context of ontology acquisition. Empirical results\nindicate that such dialogic approaches-particularly those involving\nmixed-direction interactions combining top-down explanations with\nlearner-initiated questioning-significantly enhance the LLM's ability to\nacquire and apply new knowledge, outperforming both unidirectional\ninstructional methods and direct access to structured knowledge, formats\ntypically present in training datasets.\n  These findings suggest that integrating pedagogical and psychological\ninsights into AI and robot training can substantially improve post-training\nknowledge acquisition and response quality. This approach offers a\ncomplementary pathway to existing strategies like prompt engineering", "comment": "submitted to ICSR2025", "pdf_url": "http://arxiv.org/pdf/2507.21065v1", "cate": "cs.CL", "date": "2025-05-25", "updated": "2025-05-25"}
{"id": "2507.20546", "title": "Enhancing Hallucination Detection via Future Context", "authors": ["Joosung Lee", "Cheonbok Park", "Hwiyeol Jo", "Jeonghoon Kim", "Joonsuk Park", "Kang Min Yoo"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20546v1", "summary": "Large Language Models (LLMs) are widely used to generate plausible text on\nonline platforms, without revealing the generation process. As users\nincreasingly encounter such black-box outputs, detecting hallucinations has\nbecome a critical challenge. To address this challenge, we focus on developing\na hallucination detection framework for black-box generators. Motivated by the\nobservation that hallucinations, once introduced, tend to persist, we sample\nfuture contexts. The sampled future contexts provide valuable clues for\nhallucination detection and can be effectively integrated with various\nsampling-based methods. We extensively demonstrate performance improvements\nacross multiple methods using our proposed sampling approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20546v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20542", "title": "Improving Group Fairness in Tensor Completion via Imbalance Mitigating Entity Augmentation", "authors": ["Dawon Ahn", "Jun-Gi Jang", "Evangelos E. Papalexakis"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20542v1", "summary": "Group fairness is important to consider in tensor decomposition to prevent\ndiscrimination based on social grounds such as gender or age. Although few\nworks have studied group fairness in tensor decomposition, they suffer from\nperformance degradation. To address this, we propose STAFF(Sparse Tensor\nAugmentation For Fairness) to improve group fairness by minimizing the gap in\ncompletion errors of different groups while reducing the overall tensor\ncompletion error. Our main idea is to augment a tensor with augmented entities\nincluding sufficient observed entries to mitigate imbalance and group bias in\nthe sparse tensor. We evaluate \\method on tensor completion with various\ndatasets under conventional and deep learning-based tensor models. STAFF\nconsistently shows the best trade-off between completion error and group\nfairness; at most, it yields 36% lower MSE and 59% lower MADE than the\nsecond-best baseline.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20542v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21547", "title": "Decentralized Modeling of Vehicular Maneuvers and Interactions at Urban Junctions", "authors": ["Saeed Rahmani", "Simeon C. Calvert", "Bart van Arem"], "categories": ["math.OC", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      Manuscript under review", "url": "http://arxiv.org/abs/2507.21547v1", "summary": "Modeling and evaluation of automated vehicles (AVs) in mixed-autonomy traffic\nis essential prior to their safe and efficient deployment. This is especially\nimportant at urban junctions where complex multi-agent interactions occur.\nCurrent approaches for modeling vehicular maneuvers and interactions at urban\njunctions have limitations in formulating non-cooperative interactions and\nvehicle dynamics within a unified mathematical framework. Previous studies\neither assume predefined paths or rely on cooperation and central\ncontrollability, limiting their realism and applicability in mixed-autonomy\ntraffic. This paper addresses these limitations by proposing a modeling\nframework for trajectory planning and decentralized vehicular control at urban\njunctions. The framework employs a bi-level structure where the upper level\ngenerates kinematically feasible reference trajectories using an efficient\ngraph search algorithm with a custom heuristic function, while the lower level\nemploys a predictive controller for trajectory tracking and optimization.\nUnlike existing approaches, our framework does not require central\ncontrollability or knowledge sharing among vehicles. The vehicle kinematics are\nexplicitly incorporated at both levels, and acceleration and steering angle are\nused as control variables. This intuitive formulation facilitates analysis of\ntraffic efficiency, environmental impacts, and motion comfort. The framework's\ndecentralized structure accommodates operational and stochastic elements, such\nas vehicles' detection range, perception uncertainties, and reaction delay,\nmaking the model suitable for safety analysis. Numerical and simulation\nexperiments across diverse scenarios demonstrate the framework's capability in\nmodeling accurate and realistic vehicular maneuvers and interactions at various\nurban junctions, including unsignalized intersections and roundabouts.", "comment": "Manuscript under review", "pdf_url": "http://arxiv.org/pdf/2507.21547v1", "cate": "math.OC", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21073", "title": "Product vs. Process: Exploring EFL Students' Editing of AI-Generated Text for Expository Writing", "authors": ["David James Woo", "Yangyang Yu", "Kai Guo", "Yilin Huang", "April Ka Yeng Fung"], "categories": ["cs.CL", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      45 pages, 11 figures", "url": "http://arxiv.org/abs/2507.21073v1", "summary": "Text generated by artificial intelligence (AI) chatbots is increasingly used\nin English as a foreign language (EFL) writing contexts, yet its impact on\nstudents' expository writing process and compositions remains understudied.\nThis research examines how EFL secondary students edit AI-generated text.\nExploring editing behaviors in their expository writing process and in\nexpository compositions, and their effect on human-rated scores for content,\norganization, language, and overall quality. Participants were 39 Hong Kong\nsecondary students who wrote an expository composition with AI chatbots in a\nworkshop. A convergent design was employed to analyze their screen recordings\nand compositions to examine students' editing behaviors and writing qualities.\nAnalytical methods included qualitative coding, descriptive statistics,\ntemporal sequence analysis, human-rated scoring, and multiple linear regression\nanalysis. We analyzed over 260 edits per dataset, and identified two editing\npatterns: one where students refined introductory units repeatedly before\nprogressing, and another where they quickly shifted to extensive edits in body\nunits (e.g., topic and supporting sentences). MLR analyses revealed that the\nnumber of AI-generated words positively predicted all score dimensions, while\nmost editing variables showed minimal impact. These results suggest a\ndisconnect between students' significant editing effort and improved\ncomposition quality, indicating AI supports but does not replace writing\nskills. The findings highlight the importance of genre-specific instruction and\nprocess-focused writing before AI integration. Educators should also develop\nassessments valuing both process and product to encourage critical engagement\nwith AI text.", "comment": "45 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.21073v1", "cate": "cs.CL", "date": "2025-06-10", "updated": "2025-06-10"}
{"id": "2507.20562", "title": "MemoryTalker: Personalized Speech-Driven 3D Facial Animation via Audio-Guided Stylization", "authors": ["Hyung Kyu Kim", "Sangmin Lee", "Hak Gu Kim"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for ICCV 2025 Project Page: this https URL", "url": "http://arxiv.org/abs/2507.20562v1", "summary": "Speech-driven 3D facial animation aims to synthesize realistic facial motion\nsequences from given audio, matching the speaker's speaking style. However,\nprevious works often require priors such as class labels of a speaker or\nadditional 3D facial meshes at inference, which makes them fail to reflect the\nspeaking style and limits their practical use. To address these issues, we\npropose MemoryTalker which enables realistic and accurate 3D facial motion\nsynthesis by reflecting speaking style only with audio input to maximize\nusability in applications. Our framework consists of two training stages:\n1-stage is storing and retrieving general motion (i.e., Memorizing), and\n2-stage is to perform the personalized facial motion synthesis (i.e.,\nAnimating) with the motion memory stylized by the audio-driven speaking style\nfeature. In this second stage, our model learns about which facial motion types\nshould be emphasized for a particular piece of audio. As a result, our\nMemoryTalker can generate a reliable personalized facial animation without\nadditional prior information. With quantitative and qualitative evaluations, as\nwell as user study, we show the effectiveness of our model and its performance\nenhancement for personalized facial animation over state-of-the-art methods.", "comment": "Accepted for ICCV 2025 Project Page:\n  https://cau-irislab.github.io/ICCV25-MemoryTalker/", "pdf_url": "http://arxiv.org/pdf/2507.20562v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20571", "title": "DAG-AFL:Directed Acyclic Graph-based Asynchronous Federated Learning", "authors": ["Shuaipeng Zhang", "Lanju Kong", "Yixin Zhang", "Wei He", "Yongqing Zheng", "Han Yu", "Lizhen Cui"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages, IEEE International Conference on Multimedia & Expo 2025 conference paper", "url": "http://arxiv.org/abs/2507.20571v1", "summary": "Due to the distributed nature of federated learning (FL), the vulnerability\nof the global model and the need for coordination among many client devices\npose significant challenges. As a promising decentralized, scalable and secure\nsolution, blockchain-based FL methods have attracted widespread attention in\nrecent years. However, traditional consensus mechanisms designed for Proof of\nWork (PoW) similar to blockchain incur substantial resource consumption and\ncompromise the efficiency of FL, particularly when participating devices are\nwireless and resource-limited. To address asynchronous client participation and\ndata heterogeneity in FL, while limiting the additional resource overhead\nintroduced by blockchain, we propose the Directed Acyclic Graph-based\nAsynchronous Federated Learning (DAG-AFL) framework. We develop a tip selection\nalgorithm that considers temporal freshness, node reachability and model\naccuracy, with a DAG-based trusted verification strategy. Extensive experiments\non 3 benchmarking datasets against eight state-of-the-art approaches\ndemonstrate that DAG-AFL significantly improves training efficiency and model\naccuracy by 22.7% and 6.5% on average, respectively.", "comment": "6 pages, IEEE International Conference on Multimedia & Expo 2025\n  conference paper", "pdf_url": "http://arxiv.org/pdf/2507.20571v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21624", "title": "Adaptive Benders decomposition and enhanced SDDP for multistage stochastic programs with block-separable multistage recourse", "authors": ["Nicolò Mazzi", "Ken Mckinnon", "Hongyu Zhang"], "categories": ["math.OC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21624v1", "summary": "This paper proposes an algorithm to efficiently solve multistage stochastic\nprograms with block separable recourse where each recourse problem is a\nmultistage stochastic program with stage-wise independent uncertainty. The\nalgorithm first decomposes the full problem into a reduced master problem and\nsubproblems using Adaptive Benders decomposition. The subproblems are then\nsolved by an enhanced SDDP. The enhancement includes (1) valid bounds at each\niteration, (2) a path exploration rule, (3) cut sharing among subproblems, and\n(4) guaranteed {\\delta}-optimal convergence. The cuts for the subproblems are\nthen shared by calling adaptive oracles. The key contribution of the paper is\nthe first algorithm for solving this class of problems. The algorithm is\ndemonstrated on a power system investment planning problem with multi-timescale\nuncertainty. The case study results show that (1) the proposed algorithm can\nefficiently solve this type of problem, (2) deterministic wind modelling\nunderestimate the objective function, and (3) stochastic modelling of wind\nleads to different investment decisions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21624v1", "cate": "math.OC", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21080", "title": "Which symbol grounding problem should we try to solve?", "authors": ["Vincent C. Müller"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21080v1", "summary": "Floridi and Taddeo propose a condition of \"zero semantic commitment\" for\nsolutions to the grounding problem, and a solution to it. I argue briefly that\ntheir condition cannot be fulfilled, not even by their own solution. After a\nlook at Luc Steels' very different competing suggestion, I suggest that we need\nto re-think what the problem is and what role the 'goals' in a system play in\nformulating the problem. On the basis of a proper understanding of computing, I\ncome to the conclusion that the only sensible grounding problem is how we can\nexplain and re-produce the behavioral ability and function of meaning in\nartificial computational agents", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21080v1", "cate": "cs.CL", "date": "2025-06-16", "updated": "2025-06-16"}
{"id": "2507.20568", "title": "Learning Phonetic Context-Dependent Viseme for Enhancing Speech-Driven 3D Facial Animation", "authors": ["Hyung Kyu Kim", "Hak Gu Kim"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for Interspeech 2025 Project Page: this https URL", "url": "http://arxiv.org/abs/2507.20568v1", "summary": "Speech-driven 3D facial animation aims to generate realistic facial movements\nsynchronized with audio. Traditional methods primarily minimize reconstruction\nloss by aligning each frame with ground-truth. However, this frame-wise\napproach often fails to capture the continuity of facial motion, leading to\njittery and unnatural outputs due to coarticulation. To address this, we\npropose a novel phonetic context-aware loss, which explicitly models the\ninfluence of phonetic context on viseme transitions. By incorporating a viseme\ncoarticulation weight, we assign adaptive importance to facial movements based\non their dynamic changes over time, ensuring smoother and perceptually\nconsistent animations. Extensive experiments demonstrate that replacing the\nconventional reconstruction loss with ours improves both quantitative metrics\nand visual quality. It highlights the importance of explicitly modeling\nphonetic context-dependent visemes in synthesizing natural speech-driven 3D\nfacial animation. Project page: https://cau-irislab.github.io/interspeech25/", "comment": "Accepted for Interspeech 2025 Project Page:\n  https://cau-irislab.github.io/interspeech25/", "pdf_url": "http://arxiv.org/pdf/2507.20568v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20573", "title": "Reminiscence Attack on Residuals: Exploiting Approximate Machine Unlearning for Privacy", "authors": ["Yaxin Xiao", "Qingqing Ye", "Li Hu", "Huadi Zheng", "Haibo Hu", "Zi Liang", "Haoyang Li", "Yijie Jiao"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.20573v1", "summary": "Machine unlearning enables the removal of specific data from ML models to\nuphold the right to be forgotten. While approximate unlearning algorithms offer\nefficient alternatives to full retraining, this work reveals that they fail to\nadequately protect the privacy of unlearned data. In particular, these\nalgorithms introduce implicit residuals which facilitate privacy attacks\ntargeting at unlearned data. We observe that these residuals persist regardless\nof model architectures, parameters, and unlearning algorithms, exposing a new\nattack surface beyond conventional output-based leakage. Based on this insight,\nwe propose the Reminiscence Attack (ReA), which amplifies the correlation\nbetween residuals and membership privacy through targeted fine-tuning\nprocesses. ReA achieves up to 1.90x and 1.12x higher accuracy than prior\nattacks when inferring class-wise and sample-wise membership, respectively. To\nmitigate such residual-induced privacy risk, we develop a dual-phase\napproximate unlearning framework that first eliminates deep-layer unlearned\ndata traces and then enforces convergence stability to prevent models from\n\"pseudo-convergence\", where their outputs are similar to retrained models but\nstill preserve unlearned residuals. Our framework works for both classification\nand generation tasks. Experimental evaluations confirm that our approach\nmaintains high unlearning efficacy, while reducing the adaptive privacy attack\naccuracy to nearly random guess, at the computational cost of 2-12% of full\nretraining from scratch.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.20573v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21625", "title": "A Graphical Method for Designing Time-Optimal Non-Cartesian Gradient Waveforms", "authors": ["Rui Luo", "Hongzhang Huang", "Qinfang Miao", "Jian Xu", "Peng Hu", "Haikun Qi"], "categories": ["physics.med-ph", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21625v1", "summary": "One of the fundamental challenges for non-Cartesian MRI is the need of\ndesigning time-optimal and hardware-compatible gradient waveforms for the\nprovided $k$-space trajectory. Currently dominant methods either work only for\ncertain trajectories or require significant computation time. In this paper, we\naim to develop a fast general method that is able to generate time-optimal\ngradient waveforms for arbitrary non-Cartesian trajectories satisfying both\nslew rate and gradient constraints. In the proposed method, the gradient\nwaveform is projected into a space defined by the gradients along the spatial\ndirections, termed as $g$-space. In the constructed $g$-space, the problem of\nfinding the next gradient vector given the current gradient vector under\ndesired slew rate limit and with desired direction is simplified to finding the\nintersection between a line and a circle. To handle trajectories with\nincreasing curvature, a Forward and Backward Sweep (FBS) strategy is\nintroduced, which ensures the existence of the solution to the above mentioned\ngeometry problem for arbitrary trajectories. Furthermore, trajectory\nreparameterization is proposed to ensure trajectory fidelity. We compare the\nproposed method with the previous optimal-control method in simulations and\nvalidate its feasibility for real MR acquisitions in phantom and human knee for\na wide range of non-Cartesian trajectories. The proposed method enables\naccurate and fast gradient waveform design, achieving significant reduction in\ncomputation time and slew rate overshoot compared to the previous method. The\nsource code will be publicly accessible upon publication of this study.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21625v1", "cate": "physics.med-ph", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21083", "title": "ChatGPT Reads Your Tone and Responds Accordingly -- Until It Does Not -- Emotional Framing Induces Bias in LLM Outputs", "authors": ["Franck Bardol"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21083v1", "summary": "Large Language Models like GPT-4 adjust their responses not only based on the\nquestion asked, but also on how it is emotionally phrased. We systematically\nvary the emotional tone of 156 prompts - spanning controversial and everyday\ntopics - and analyze how it affects model responses. Our findings show that\nGPT-4 is three times less likely to respond negatively to a negatively framed\nquestion than to a neutral one. This suggests a \"rebound\" bias where the model\novercorrects, often shifting toward neutrality or positivity. On sensitive\ntopics (e.g., justice or politics), this effect is even more pronounced:\ntone-based variation is suppressed, suggesting an alignment override. We\nintroduce concepts like the \"tone floor\" - a lower bound in response negativity\n- and use tone-valence transition matrices to quantify behavior. Visualizations\nbased on 1536-dimensional embeddings confirm semantic drift based on tone. Our\nwork highlights an underexplored class of biases driven by emotional framing in\nprompts, with implications for AI alignment and trust. Code and data are\navailable at: https://github.com/bardolfranck/llm-responses-viewer", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21083v1", "cate": "cs.CL", "date": "2025-06-17", "updated": "2025-06-17"}
{"id": "2507.20578", "title": "Beyond Interactions: Node-Level Graph Generation for Knowledge-Free Augmentation in Recommender Systems", "authors": ["Zhaoyan Wang", "Hyunjun Ahn", "In-Young Ko"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20578v1", "summary": "Recent advances in recommender systems rely on external resources such as\nknowledge graphs or large language models to enhance recommendations, which\nlimit applicability in real-world settings due to data dependency and\ncomputational overhead. Although knowledge-free models are able to bolster\nrecommendations by direct edge operations as well, the absence of augmentation\nprimitives drives them to fall short in bridging semantic and structural gaps\nas high-quality paradigm substitutes. Unlike existing diffusion-based works\nthat remodel user-item interactions, this work proposes NodeDiffRec, a\npioneering knowledge-free augmentation framework that enables fine-grained\nnode-level graph generation for recommendations and expands the scope of\nrestricted augmentation primitives via diffusion. By synthesizing pseudo-items\nand corresponding interactions that align with the underlying distribution for\ninjection, and further refining user preferences through a denoising preference\nmodeling process, NodeDiffRec dramatically enhances both semantic diversity and\nstructural connectivity without external knowledge. Extensive experiments\nacross diverse datasets and recommendation algorithms demonstrate the\nsuperiority of NodeDiffRec, achieving State-of-the-Art (SOTA) performance, with\nmaximum average performance improvement 98.6% in Recall@5 and 84.0% in NDCG@5\nover selected baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20578v1", "cate": "cs.IR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20576", "title": "Fusing CFD and measurement data using transfer learning", "authors": ["Alexander Barklage", "Philipp Bekemeyer"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20576v1", "summary": "Aerodynamic analysis during aircraft design usually involves methods of\nvarying accuracy and spatial resolution, which all have their advantages and\ndisadvantages. It is therefore desirable to create data-driven models which\neffectively combine these advantages. Such data fusion methods for distributed\nquantities mainly rely on proper orthogonal decomposition as of now, which is a\nlinear method. In this paper, we introduce a non-linear method based on neural\nnetworks combining simulation and measurement data via transfer learning. The\nnetwork training accounts for the heterogeneity of the data, as simulation data\nusually features a high spatial resolution, while measurement data is sparse\nbut more accurate. In a first step, the neural network is trained on simulation\ndata to learn spatial features of the distributed quantities. The second step\ninvolves transfer learning on the measurement data to correct for systematic\nerrors between simulation and measurement by only re-training a small subset of\nthe entire neural network model. This approach is applied to a multilayer\nperceptron architecture and shows significant improvements over the established\nmethod based on proper orthogonal decomposition by producing more physical\nsolutions near nonlinearities. In addition, the neural network provides\nsolutions at arbitrary flow conditions, thus making the model useful for flight\nmechanical design, structural sizing, and certification. As the proposed\ntraining strategy is very general, it can also be applied to more complex\nneural network architectures in the future.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20576v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21865", "title": "On the Feasibility of SCL-Band Transmission over G.654.E-Compliant Long-Haul Fibre Links", "authors": ["Jiaqian Yang", "Eric Sillekens", "Ronit Sohanpal", "Mingming Tan", "Dini Pratiwi", "Henrique Buglia", "Romulo Aparecido", "John D. Downie", "Sergejs Makovejs", "Lidia Galdino", "Wladek Forysiak", "Polina Bayvel", "Robert I. Killey"], "categories": ["physics.optics", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      4 pages, 6 figures, accepted for oral presentation at European Conference on Optical Communication 2025", "url": "http://arxiv.org/abs/2507.21865v1", "summary": "We demonstrate the first SCL-band long-haul transmission using\nG.654.E-compliant fibre, achieving 100.8 Tb/s (GMI) over 1552 km, despite its\n1520 nm cutoff wavelength. Due to the fibre's ultra-low loss and low\nnonlinearity, the achievable-information-rate with lumped amplification is\ncomparable to that of G.652.D-compliant fibre links with\ndistributed-Raman-amplification.", "comment": "4 pages, 6 figures, accepted for oral presentation at European\n  Conference on Optical Communication 2025", "pdf_url": "http://arxiv.org/pdf/2507.21865v1", "cate": "physics.optics", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21084", "title": "Reviving Your MNEME: Predicting The Side Effects of LLM Unlearning and Fine-Tuning via Sparse Model Diffing", "authors": ["Aly M. Kassem", "Zhuan Shi", "Negar Rostamzadeh", "Golnoosh Farnadi"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21084v1", "summary": "Large language models (LLMs) are frequently fine-tuned or unlearned to adapt\nto new tasks or eliminate undesirable behaviors. While existing evaluation\nmethods assess performance after such interventions, there remains no general\napproach for detecting unintended side effects, such as unlearning biology\ncontent degrading performance on chemistry tasks, particularly when these\neffects are unpredictable or emergent. To address this issue, we introduce\nMNEME, Model diffiNg for Evaluating Mechanistic Effects, a lightweight\nframework for identifying these side effects using sparse model diffing. MNEME\ncompares base and fine-tuned models on task-agnostic data (for example, The\nPile, LMSYS-Chat-1M) without access to fine-tuning data to isolate behavioral\nshifts. Applied to five LLMs across three scenarios: WMDP knowledge unlearning,\nemergent misalignment, and benign fine-tuning, MNEME achieves up to 95 percent\naccuracy in predicting side effects, aligning with known benchmarks and\nrequiring no custom heuristics. Furthermore, we show that retraining on\nhigh-activation samples can partially reverse these effects. Our results\ndemonstrate that sparse probing and diffing offer a scalable and automated lens\ninto fine-tuning-induced model changes, providing practical tools for\nunderstanding and managing LLM behavior.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21084v1", "cate": "cs.CL", "date": "2025-06-19", "updated": "2025-06-19"}
{"id": "2507.21377", "title": "Reservoir Computation with Networks of Differentiating Neuron Ring Oscillators", "authors": ["Alexander Yeung", "Peter DelMastro", "Arjun Karuvally", "Hava Siegelmann", "Edward Rietman", "Hananel Hazan"], "categories": ["cs.NE", "cs.LG"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      8 pages, 5 figures", "url": "http://arxiv.org/abs/2507.21377v1", "summary": "Reservoir Computing is a machine learning approach that uses the rich\nrepertoire of complex system dynamics for function approximation. Current\napproaches to reservoir computing use a network of coupled integrating neurons\nthat require a steady current to maintain activity. Here, we introduce a small\nworld graph of differentiating neurons that are active only when there are\nchanges in input as an alternative to integrating neurons as a reservoir\ncomputing substrate. We find the coupling strength and network topology that\nenable these small world networks to function as an effective reservoir. We\ndemonstrate the efficacy of these networks in the MNIST digit recognition task,\nachieving comparable performance of 90.65% to existing reservoir computing\napproaches. The findings suggest that differentiating neurons can be a\npotential alternative to integrating neurons and can provide a sustainable\nfuture alternative for power-hungry AI applications.", "comment": "8 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.21377v1", "cate": "cs.NE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20623", "title": "Lightweight Remote Sensing Scene Classification on Edge Devices via Knowledge Distillation and Early-exit", "authors": ["Yang Zhao", "Shusheng Li", "Xueshang Feng"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures, to be published in ACM Multimedia 2025", "url": "http://arxiv.org/abs/2507.20623v1", "summary": "As the development of lightweight deep learning algorithms, various deep\nneural network (DNN) models have been proposed for the remote sensing scene\nclassification (RSSC) application. However, it is still challenging for these\nRSSC models to achieve optimal performance among model accuracy, inference\nlatency, and energy consumption on resource-constrained edge devices. In this\npaper, we propose a lightweight RSSC framework, which includes a distilled\nglobal filter network (GFNet) model and an early-exit mechanism designed for\nedge devices to achieve state-of-the-art performance. Specifically, we first\napply frequency domain distillation on the GFNet model to reduce model size.\nThen we design a dynamic early-exit model tailored for DNN models on edge\ndevices to further improve model inference efficiency. We evaluate our E3C\nmodel on three edge devices across four datasets. Extensive experimental\nresults show that it achieves an average of 1.3x speedup on model inference and\nover 40% improvement on energy efficiency, while maintaining high\nclassification accuracy.", "comment": "9 pages, 5 figures, to be published in ACM Multimedia 2025", "pdf_url": "http://arxiv.org/pdf/2507.20623v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20592", "title": "PhaseNAS: Language-Model Driven Architecture Search with Dynamic Phase Adaptation", "authors": ["Fei Kong", "Xiaohan Shan", "Yanwei Hu", "Jianmin Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      14pages", "url": "http://arxiv.org/abs/2507.20592v1", "summary": "Neural Architecture Search (NAS) is challenged by the trade-off between\nsearch space exploration and efficiency, especially for complex tasks. While\nrecent LLM-based NAS methods have shown promise, they often suffer from static\nsearch strategies and ambiguous architecture representations. We propose\nPhaseNAS, an LLM-based NAS framework with dynamic phase transitions guided by\nreal-time score thresholds and a structured architecture template language for\nconsistent code generation. On the NAS-Bench-Macro benchmark, PhaseNAS\nconsistently discovers architectures with higher accuracy and better rank. For\nimage classification (CIFAR-10/100), PhaseNAS reduces search time by up to 86%\nwhile maintaining or improving accuracy. In object detection, it automatically\nproduces YOLOv8 variants with higher mAP and lower resource cost. These results\ndemonstrate that PhaseNAS enables efficient, adaptive, and generalizable NAS\nacross diverse vision tasks.", "comment": "14pages", "pdf_url": "http://arxiv.org/pdf/2507.20592v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2403.11945", "title": "Kernel Modelling of Fading Memory Systems", "authors": ["Yongkang Huo", "Thomas Chaffey", "Rodolphe Sepulchre"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.11945v3", "summary": "The paper is a follow-up of the recently introduced kernel-based framework to\nidentify nonlinear input-output systems regularized by desirable input-output\nincremental properties. Assuming that the system has fading memory, we propose\nto learn the functional that maps the past input to the present output rather\nthan the operator mapping input trajectories to output trajectories. While\nretaining the benefits of the previously proposed framework, this modification\nsimplifies the selection of the kernel, enforces causality, and enables\ntemporal simulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.11945v3", "cate": "eess.SY", "date": "2024-03-18", "updated": "2025-07-29"}
{"id": "2507.21086", "title": "Multi-Amateur Contrastive Decoding for Text Generation", "authors": ["Jaydip Sen", "Subhasis Dasgupta", "Hetvi Waghela"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This paper has been accepted for oral presentation and publication in the proceedings of the IEEE I2ITCON 2025. The conference will be organized in Pune, India, from July 4 to 5, 2025. This is the accepted version of the paper and NOT the final camera-ready version. The paper is 11 pages long and contains 5 figures and 6 tables", "url": "http://arxiv.org/abs/2507.21086v1", "summary": "Contrastive Decoding (CD) has emerged as an effective inference-time strategy\nfor enhancing open-ended text generation by exploiting the divergence in output\nprobabilities between a large expert language model and a smaller amateur\nmodel. Although CD improves coherence and fluency, its dependence on a single\namateur restricts its capacity to capture the diverse and multifaceted failure\nmodes of language generation, such as repetition, hallucination, and stylistic\ndrift. This paper proposes Multi-Amateur Contrastive Decoding (MACD), a\ngeneralization of the CD framework that employs an ensemble of amateur models\nto more comprehensively characterize undesirable generation patterns. MACD\nintegrates contrastive signals through both averaging and consensus\npenalization mechanisms and extends the plausibility constraint to operate\neffectively in the multi-amateur setting. Furthermore, the framework enables\ncontrollable generation by incorporating amateurs with targeted stylistic or\ncontent biases. Experimental results across multiple domains, such as news,\nencyclopedic, and narrative, demonstrate that MACD consistently surpasses\nconventional decoding methods and the original CD approach in terms of fluency,\ncoherence, diversity, and adaptability, all without requiring additional\ntraining or fine-tuning.", "comment": "This paper has been accepted for oral presentation and publication in\n  the proceedings of the IEEE I2ITCON 2025. The conference will be organized in\n  Pune, India, from July 4 to 5, 2025. This is the accepted version of the\n  paper and NOT the final camera-ready version. The paper is 11 pages long and\n  contains 5 figures and 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.21086v1", "cate": "cs.CL", "date": "2025-06-22", "updated": "2025-06-22"}
{"id": "2507.21740", "title": "Knowledge-Guided Memetic Algorithm for Capacitated Arc Routing Problems with Time-Dependent Service Costs", "authors": ["Qingya Li", "Shengcai Liu", "Wenjie Chen", "Juan Zou", "Ke Tang", "Xin Yao"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21740v1", "summary": "The capacitated arc routing problem with time-dependent service costs\n(CARPTDSC) is a challenging combinatorial optimization problem that arises from\nwinter gritting applications. CARPTDSC has two main challenges about time\nconsumption. First, it is an NP-hard problem. Second, the time-dependent\nservice costs of tasks require frequent evaluations during the search process,\nsignificantly increasing computational effort. These challenges make it\ndifficult for existing algorithms to perform efficient searches, often\nresulting in limited efficiency. To address these issues, this paper proposes a\nknowledge-guided memetic algorithm with golden section search and negatively\ncorrelated search (KGMA-GN), where two knowledge-guided strategies are\nintroduced to improve search efficiency. First, a knowledge-guided\ninitialization strategy (KGIS) is proposed to generate high-quality initial\nsolutions to speed up convergence. Second, a knowledge-guided small-step-size\nlocal search strategy (KGSLSS) is proposed to filter out invalid moves, thereby\nreducing unnecessary evaluations and saving the computation time. Experimental\nresults on five benchmark test sets, including both small- and larger-scale\ninstances, demonstrate that KGMA-GN achieves higher search efficiency than the\nstate-of-the-art methods. Moreover, the ablation study further confirms that\nthe knowledge-guided local search operators in KGSLSS can significantly reduce\nruntime compared to traditional operators, especially for the knowledge-guided\nswap operator, which achieves more than a tenfold improvement in speed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21740v1", "cate": "cs.NE", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20630", "title": "TransPrune: Token Transition Pruning for Efficient Large Vision-Language Model", "authors": ["Ao Li", "Yuxiang Duan", "Jinghui Zhang", "Congbo Ma", "Yutong Xie", "Gustavo Carneiro", "Mohammad Yaqub", "Hu Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20630v1", "summary": "Large Vision-Language Models (LVLMs) have advanced multimodal learning but\nface high computational costs due to the large number of visual tokens,\nmotivating token pruning to improve inference efficiency. The key challenge\nlies in identifying which tokens are truly important. Most existing approaches\nrely on attention-based criteria to estimate token importance. However, they\ninherently suffer from certain limitations, such as positional bias. In this\nwork, we explore a new perspective on token importance based on token\ntransitions in LVLMs. We observe that the transition of token representations\nprovides a meaningful signal of semantic information. Based on this insight, we\npropose TransPrune, a training-free and efficient token pruning method.\nSpecifically, TransPrune progressively prunes tokens by assessing their\nimportance through a combination of Token Transition Variation (TTV)-which\nmeasures changes in both the magnitude and direction of token\nrepresentations-and Instruction-Guided Attention (IGA), which measures how\nstrongly the instruction attends to image tokens via attention. Extensive\nexperiments demonstrate that TransPrune achieves comparable multimodal\nperformance to original LVLMs, such as LLaVA-v1.5 and LLaVA-Next, across eight\nbenchmarks, while reducing inference TFLOPs by more than half. Moreover, TTV\nalone can serve as an effective criterion without relying on attention,\nachieving performance comparable to attention-based methods. The code will be\nmade publicly available upon acceptance of the paper at\nhttps://github.com/liaolea/TransPrune.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20630v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20644", "title": "Deep Generative Models of Evolution: SNP-level Population Adaptation by Genomic Linkage Incorporation", "authors": ["Julia Siekiera", "Christian Schlötterer", "Stefan Kramer"], "categories": ["cs.LG", "q-bio.PE"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures", "url": "http://arxiv.org/abs/2507.20644v1", "summary": "The investigation of allele frequency trajectories in populations evolving\nunder controlled environmental pressures has become a popular approach to study\nevolutionary processes on the molecular level. Statistical models based on\nwell-defined evolutionary concepts can be used to validate different hypotheses\nabout empirical observations. Despite their popularity, classic statistical\nmodels like the Wright-Fisher model suffer from simplified assumptions such as\nthe independence of selected loci along a chromosome and uncertainty about the\nparameters. Deep generative neural networks offer a powerful alternative known\nfor the integration of multivariate dependencies and noise reduction. Due to\ntheir high data demands and challenging interpretability they have, so far, not\nbeen widely considered in the area of population genomics. To address the\nchallenges in the area of Evolve and Resequencing experiments (E&R) based on\npooled sequencing (Pool-Seq) data, we introduce a deep generative neural\nnetwork that aims to model a concept of evolution based on empirical\nobservations over time. The proposed model estimates the distribution of allele\nfrequency trajectories by embedding the observations from single nucleotide\npolymorphisms (SNPs) with information from neighboring loci. Evaluation on\nsimulated E&R experiments demonstrates the model's ability to capture the\ndistribution of allele frequency trajectories and illustrates the\nrepresentational power of deep generative models on the example of linkage\ndisequilibrium (LD) estimation. Inspecting the internally learned\nrepresentations enables estimating pairwise LD, which is typically inaccessible\nin Pool-Seq data. Our model provides competitive LD estimation in Pool-Seq data\nhigh degree of LD when compared to existing methods.", "comment": "10 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.20644v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2410.19159", "title": "Collision Avoidance for Convex Primitives via Differentiable Optimization Based High-Order Control Barrier Functions", "authors": ["Shiqing Wei", "Rooholla Khorrambakht", "Prashanth Krishnamurthy", "Vinicius Mariano Gonçalves", "Farshad Khorrami"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.19159v3", "summary": "Ensuring the safety of dynamical systems is crucial, where collision\navoidance is a primary concern. Recently, control barrier functions (CBFs) have\nemerged as an effective method to integrate safety constraints into control\nsynthesis through optimization techniques. However, challenges persist when\ndealing with convex primitives and tasks requiring torque control, as well as\nthe occurrence of unintended equilibria. This work addresses these challenges\nby introducing a high-order CBF (HOCBF) framework for collision avoidance among\nconvex primitives. We transform nonconvex safety constraints into linear\nconstraints by differentiable optimization and prove the high-order continuous\ndifferentiability. Then, we employ HOCBFs to accommodate torque control,\nenabling tasks involving forces or high dynamics. Additionally, we analyze the\nissue of spurious equilibria in high-order cases and propose a circulation\nmechanism to prevent the undesired equilibria on the boundary of the safe set.\nFinally, we validate our framework with three experiments on the Franka\nResearch 3 robotic manipulator, demonstrating successful collision avoidance\nand the efficacy of the circulation mechanism.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.19159v3", "cate": "eess.SY", "date": "2024-10-24", "updated": "2025-07-29"}
{"id": "2507.21095", "title": "QU-NLP at CheckThat! 2025: Multilingual Subjectivity in News Articles Detection using Feature-Augmented Transformer Models with Sequential Cross-Lingual Fine-Tuning", "authors": ["Mohammad AL-Smadi"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21095v1", "summary": "This paper presents our approach to the CheckThat! 2025 Task 1 on\nsubjectivity detection, where systems are challenged to distinguish whether a\nsentence from a news article expresses the subjective view of the author or\npresents an objective view on the covered topic. We propose a feature-augmented\ntransformer architecture that combines contextual embeddings from pre-trained\nlanguage models with statistical and linguistic features. Our system leveraged\npre-trained transformers with additional lexical features: for Arabic we used\nAraELECTRA augmented with part-of-speech (POS) tags and TF-IDF features, while\nfor the other languages we fine-tuned a cross-lingual DeBERTa~V3 model combined\nwith TF-IDF features through a gating mechanism. We evaluated our system in\nmonolingual, multilingual, and zero-shot settings across multiple languages\nincluding English, Arabic, German, Italian, and several unseen languages. The\nresults demonstrate the effectiveness of our approach, achieving competitive\nperformance across different languages with notable success in the monolingual\nsetting for English (rank 1st with macro-F1=0.8052), German (rank 3rd with\nmacro-F1=0.8013), Arabic (rank 4th with macro-F1=0.5771), and Romanian (rank\n1st with macro-F1=0.8126) in the zero-shot setting. We also conducted an\nablation analysis that demonstrated the importance of combining TF-IDF features\nwith the gating mechanism and the cross-lingual transfer for subjectivity\ndetection. Furthermore, our analysis reveals the model's sensitivity to both\nthe order of cross-lingual fine-tuning and the linguistic proximity of the\ntraining languages.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21095v1", "cate": "cs.CL", "date": "2025-07-01", "updated": "2025-07-01"}
{"id": "2503.08394", "title": "($\\boldsymbolθ_l, \\boldsymbolθ_u$)-Parametric Multi-Task Optimization: Joint Search in Solution and Infinite Task Spaces", "authors": ["Tingyang Wei", "Jiao Liu", "Abhishek Gupta", "Puay Siew Tan", "Yew-Soon Ong"], "categories": ["cs.NE", "cs.LG"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.08394v2", "summary": "Multi-task optimization is typically characterized by a fixed and finite set\nof optimization tasks. The present paper relaxes this condition by considering\na non-fixed and potentially infinite set of optimization tasks defined in a\nparameterized, continuous and bounded task space. We refer to this unique\nproblem setting as parametric multi-task optimization (PMTO). Assuming the\nbounds of the task parameters to be ($\\boldsymbol{\\theta}_l$,\n$\\boldsymbol{\\theta}_u$), a novel ($\\boldsymbol{\\theta}_l$,\n$\\boldsymbol{\\theta}_u$)-PMTO algorithm is crafted to enable joint search over\ntasks and their solutions. This joint search is supported by two approximation\nmodels: (1) for mapping solutions to the objective spaces of all tasks, which\nprovably accelerates convergence by acting as a conduit for inter-task\nknowledge transfers, and (2) for probabilistically mapping tasks to the\nsolution space, which facilitates evolutionary exploration of under-explored\nregions of the task space. At the end of a full ($\\boldsymbol{\\theta}_l$,\n$\\boldsymbol{\\theta}_u$)-PMTO run, the acquired models enable rapid\nidentification of optimized solutions for any task lying within the specified\nbounds. This outcome is validated on both synthetic test problems and practical\ncase studies, with the significant real-world applicability of PMTO shown\ntowards fast reconfiguration of robot controllers under changing task\nconditions. The potential of PMTO to vastly speedup the search for solutions to\nminimax optimization problems is also demonstrated through an example in robust\nengineering design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.08394v2", "cate": "cs.NE", "date": "2025-03-11", "updated": "2025-07-29"}
{"id": "2507.20643", "title": "Ontology-Enhanced Knowledge Graph Completion using Large Language Models", "authors": ["Wenbin Guo", "Xin Wang", "Jiaoyan Chen", "Zhao Li", "Zirui Chen"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20643v1", "summary": "Large Language Models (LLMs) have been extensively adopted in Knowledge Graph\nCompletion (KGC), showcasing significant research advancements. However, as\nblack-box models driven by deep neural architectures, current LLM-based KGC\nmethods rely on implicit knowledge representation with parallel propagation of\nerroneous knowledge, thereby hindering their ability to produce conclusive and\ndecisive reasoning outcomes. We aim to integrate neural-perceptual structural\ninformation with ontological knowledge, leveraging the powerful capabilities of\nLLMs to achieve a deeper understanding of the intrinsic logic of the knowledge.\nWe propose an ontology enhanced KGC method using LLMs -- OL-KGC. It first\nleverages neural perceptual mechanisms to effectively embed structural\ninformation into the textual space, and then uses an automated extraction\nalgorithm to retrieve ontological knowledge from the knowledge graphs (KGs)\nthat needs to be completed, which is further transformed into a textual format\ncomprehensible to LLMs for providing logic guidance. We conducted extensive\nexperiments on three widely-used benchmarks -- FB15K-237, UMLS and WN18RR. The\nexperimental results demonstrate that OL-KGC significantly outperforms existing\nmainstream KGC methods across multiple evaluation metrics, achieving\nstate-of-the-art performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20643v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20678", "title": "Novel Pivoted Cholesky Decompositions for Efficient Gaussian Process Inference", "authors": ["Filip de Roos", "Fabio Muratore"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20678v1", "summary": "The Cholesky decomposition is a fundamental tool for solving linear systems\nwith symmetric and positive definite matrices which are ubiquitous in linear\nalgebra, optimization, and machine learning. Its numerical stability can be\nimproved by introducing a pivoting strategy that iteratively permutes the rows\nand columns of the matrix. The order of pivoting indices determines how\naccurately the intermediate decomposition can reconstruct the original matrix,\nthus is decisive for the algorithm's efficiency in the case of early\ntermination. Standard implementations select the next pivot from the largest\nvalue on the diagonal. In the case of Bayesian nonparametric inference, this\nstrategy corresponds to greedy entropy maximization, which is often used in\nactive learning and design of experiments. We explore this connection in detail\nand deduce novel pivoting strategies for the Cholesky decomposition. The\nresulting algorithms are more efficient at reducing the uncertainty over a data\nset, can be updated to include information about observations, and additionally\nbenefit from a tailored implementation. We benchmark the effectiveness of the\nnew selection strategies on two tasks important to Gaussian processes: sparse\nregression and inference based on preconditioned iterative solvers. Our results\nshow that the proposed selection strategies are either on par or, in most\ncases, outperform traditional baselines while requiring a negligible amount of\nadditional computation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20678v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2411.01297", "title": "Receding Hamiltonian-Informed Optimal Neural Control and State Estimation for Closed-Loop Dynamical Systems", "authors": ["Josue N. Rivera", "Dengfeng Sun"], "categories": ["eess.SY", "cs.AI", "cs.ET", "cs.LG", "cs.RO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      27 pages. Source code: this https URL", "url": "http://arxiv.org/abs/2411.01297v3", "summary": "This paper formalizes Hamiltonian-Informed Optimal Neural (Hion) controllers,\na novel class of neural network-based controllers for dynamical systems and\nexplicit non-linear model-predictive control. Hion controllers estimate future\nstates and develop an optimal control strategy using Pontryagin's Maximum\nPrinciple. The proposed framework, along with our Taylored Multi-Faceted\nApproach for Neural ODE and Optimal Control (T-mano) architecture, allows for\ncustom transient behavior, predictive control, and closed-loop feedback,\naddressing limitations of existing methods. Comparative analyses with\nestablished model-predictive controllers revealed Hion controllers' superior\noptimality and tracking capabilities. Optimal control strategies are also\ndemonstrated for both linear and non-linear dynamical systems.", "comment": "27 pages. Source code: https://github.com/wzjoriv/Hion", "pdf_url": "http://arxiv.org/pdf/2411.01297v3", "cate": "eess.SY", "date": "2024-11-02", "updated": "2025-07-29"}
{"id": "2507.21099", "title": "Rewrite-to-Rank: Optimizing Ad Visibility via Retrieval-Aware Text Rewriting", "authors": ["Chloe Ho", "Ishneet Sukhvinder Singh", "Diya Sharma", "Tanvi Reddy Anumandla", "Michael Lu", "Vasu Sharma", "Kevin Zhu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21099v1", "summary": "Search algorithms and user query relevance have given LLMs the ability to\nreturn relevant information, but the effect of content phrasing on ad\nvisibility remains underexplored. We investigate how LLM-based rewriting of\nadvertisements can improve their ranking in retrieval systems and inclusion in\ngenerated LLM responses, without modifying the retrieval model itself. We\nintroduce a supervised fine-tuning framework with a custom loss balancing\nsemantic relevance and content fidelity. To evaluate effectiveness, we propose\ntwo metrics: DeltaMRR@K (ranking improvement) and DeltaDIR@K (inclusion\nfrequency improvement). Our approach presents a scalable method to optimize ad\nphrasing, enhancing visibility in retrieval-based LLM workflows. Experiments\nacross both instruction-based and few-shot prompting demonstrate that PPO\ntrained models outperform both prompt engineering and supervised fine-tuning in\nmost cases, achieving up to a 2.79 DeltaDIR@5 and 0.0073 DeltaMRR@5 in\ninstruction-based prompting. These results highlight the importance of how the\nad is written before retrieval and prompt format and reinforcement learning in\neffective ad rewriting for LLM integrated retrieval systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21099v1", "cate": "cs.CL", "date": "2025-07-03", "updated": "2025-07-03"}
{"id": "2502.03086", "title": "Implementing Large Quantum Boltzmann Machines as Generative AI Models for Dataset Balancing", "authors": ["Salvatore Sinno", "Markus Bertl", "Arati Sahoo", "Bhavika Bhalgamiya", "Thomas Groß", "Nicholas Chancellor"], "categories": ["cs.ET", "cs.AI", "cs.LG", "cs.NE", "quant-ph"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "Comments:      S. Sinno, M. Bertl, A. Sahoo, B. Bhalgamiya, T. Groß and N. Chancellor, \"Implementing Large Quantum Boltzmann Machines as Generative AI Models for Dataset Balancing,\" 2025 International Conference on Next Generation Information System Engineering (NGISE), Ghaziabad, Delhi (NCR), India, 2025, pp. 1-8, doi: https://doi.org/10.1109/NGISE64126.2025.11085158", "url": "http://arxiv.org/abs/2502.03086v2", "summary": "This study explores the implementation of large Quantum Restricted Boltzmann\nMachines (QRBMs), a key advancement in Quantum Machine Learning (QML), as\ngenerative models on D-Wave's Pegasus quantum hardware to address dataset\nimbalance in Intrusion Detection Systems (IDS). By leveraging Pegasus's\nenhanced connectivity and computational capabilities, a QRBM with 120 visible\nand 120 hidden units was successfully embedded, surpassing the limitations of\ndefault embedding tools. The QRBM synthesized over 1.6 million attack samples,\nachieving a balanced dataset of over 4.2 million records. Comparative\nevaluations with traditional balancing methods, such as SMOTE and\nRandomOversampler, revealed that QRBMs produced higher-quality synthetic\nsamples, significantly improving detection rates, precision, recall, and F1\nscore across diverse classifiers. The study underscores the scalability and\nefficiency of QRBMs, completing balancing tasks in milliseconds. These findings\nhighlight the transformative potential of QML and QRBMs as next-generation\ntools in data preprocessing, offering robust solutions for complex\ncomputational challenges in modern information systems.", "comment": "S. Sinno, M. Bertl, A. Sahoo, B. Bhalgamiya, T. Gro{\\ss} and N.\n  Chancellor, \"Implementing Large Quantum Boltzmann Machines as Generative AI\n  Models for Dataset Balancing,\" 2025 International Conference on Next\n  Generation Information System Engineering (NGISE), Ghaziabad, Delhi (NCR),\n  India, 2025, pp. 1-8, doi: 10.1109/NGISE64126.2025.11085158", "pdf_url": "http://arxiv.org/pdf/2502.03086v2", "cate": "cs.ET", "date": "2025-02-05", "updated": "2025-07-29"}
{"id": "2507.20670", "title": "A Multimodal Architecture for Endpoint Position Prediction in Team-based Multiplayer Games", "authors": ["Jonas Peche", "Aliaksei Tsishurou", "Alexander Zap", "Guenter Wallner"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20670v1", "summary": "Understanding and predicting player movement in multiplayer games is crucial\nfor achieving use cases such as player-mimicking bot navigation, preemptive bot\ncontrol, strategy recommendation, and real-time player behavior analytics.\nHowever, the complex environments allow for a high degree of navigational\nfreedom, and the interactions and team-play between players require models that\nmake effective use of the available heterogeneous input data. This paper\npresents a multimodal architecture for predicting future player locations on a\ndynamic time horizon, using a U-Net-based approach for calculating endpoint\nlocation probability heatmaps, conditioned using a multimodal feature encoder.\nThe application of a multi-head attention mechanism for different groups of\nfeatures allows for communication between agents. In doing so, the architecture\nmakes efficient use of the multimodal game state including image inputs,\nnumerical and categorical features, as well as dynamic game data. Consequently,\nthe presented technique lays the foundation for various downstream tasks that\nrely on future player positions such as the creation of player-predictive bot\nbehavior or player anomaly detection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20670v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20708", "title": "Exposing the Illusion of Fairness: Auditing Vulnerabilities to Distributional Manipulation Attacks", "authors": ["Valentin Lafargue", "Adriana Laurindo Monteiro", "Emmanuelle Claeys", "Laurent Risser", "Jean-Michel Loubes"], "categories": ["cs.LG", "math.OC", "stat.AP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20708v1", "summary": "Proving the compliance of AI algorithms has become an important challenge\nwith the growing deployment of such algorithms for real-life applications.\nInspecting possible biased behaviors is mandatory to satisfy the constraints of\nthe regulations of the EU Artificial Intelligence's Act. Regulation-driven\naudits increasingly rely on global fairness metrics, with Disparate Impact\nbeing the most widely used. Yet such global measures depend highly on the\ndistribution of the sample on which the measures are computed. We investigate\nfirst how to manipulate data samples to artificially satisfy fairness criteria,\ncreating minimally perturbed datasets that remain statistically\nindistinguishable from the original distribution while satisfying prescribed\nfairness constraints. Then we study how to detect such manipulation. Our\nanalysis (i) introduces mathematically sound methods for modifying empirical\ndistributions under fairness constraints using entropic or optimal transport\nprojections, (ii) examines how an auditee could potentially circumvent fairness\ninspections, and (iii) offers recommendations to help auditors detect such data\nmanipulations. These results are validated through experiments on classical\ntabular datasets in bias detection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20708v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2501.13555", "title": "Instantaneous Core Loss -- Cycle-by-cycle Modeling of Power Magnetics in PWM DC-AC Converters", "authors": ["Binyu Cui", "Jun Wang", "Xibo Yuan", "Alfonso Martinez", "George Slama", "Matthew Wilkowski", "Ryosuke Ota", "Keiji Wada"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.13555v2", "summary": "Nowadays, PWM excitation is one of the most common waveforms seen by magnetic\ncomponents in power electronic converters. Core loss modelling approaches such\nas improved Generalized Steinmetz equation (iGSE) or the loss map based on\ncomposite waveform hypothesis (CWH) process the PWM excitation piecewisely,\nwhich is proven to be effective for DC DC converters. As the additional\nchallenge in PWM DC AC converters, the fundamental-frequency sinewave component\ninduces the \"major loop loss\" on top of the piecewise high-frequency segments,\nwhich however cannot be modelled on a switching cycle basis by any existing\nmethods. To address this gap, this paper proposes a novel fundamental concept,\ninstantaneous core loss, which is the time-domain core loss observed\nexperimentally for the first time in history. Extending the reactive voltage\ncancellation concept, this work presents a method to measure the instantaneous\ncore loss, which only contains real power loss, as a function of time. Based on\nmeasurements in evaluated soft magnetic components, it was discovered that the\ndischarging stage exhibits higher core loss than the charging stage. A\nmodelling approach is then proposed to break down the major loop core loss,\ntypically an average value in the literature, into the time domain to enable\ncycle-by-cycle modelling of core losses in PWM converters. This work enhances\nthe fundamental understanding of the core loss process by moving from the\naverage model to the time-domain model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.13555v2", "cate": "eess.SY", "date": "2025-01-23", "updated": "2025-07-29"}
{"id": "2507.21104", "title": "iLSU-T: an Open Dataset for Uruguayan Sign Language Translation", "authors": ["Ariel E. Stassi", "Yanina Boria", "J. Matías Di Martino", "Gregory Randall"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures, 19th International Conference on Automatic Face and Gesture Recognition IEEE FG 2025", "url": "http://arxiv.org/abs/2507.21104v1", "summary": "Automatic sign language translation has gained particular interest in the\ncomputer vision and computational linguistics communities in recent years.\nGiven each sign language country particularities, machine translation requires\nlocal data to develop new techniques and adapt existing ones. This work\npresents iLSU T, an open dataset of interpreted Uruguayan Sign Language RGB\nvideos with audio and text transcriptions. This type of multimodal and curated\ndata is paramount for developing novel approaches to understand or generate\ntools for sign language processing. iLSU T comprises more than 185 hours of\ninterpreted sign language videos from public TV broadcasting. It covers diverse\ntopics and includes the participation of 18 professional interpreters of sign\nlanguage. A series of experiments using three state of the art translation\nalgorithms is presented. The aim is to establish a baseline for this dataset\nand evaluate its usefulness and the proposed pipeline for data processing. The\nexperiments highlight the need for more localized datasets for sign language\ntranslation and understanding, which are critical for developing novel tools to\nimprove accessibility and inclusion of all individuals. Our data and code can\nbe accessed.", "comment": "10 pages, 5 figures, 19th International Conference on Automatic Face\n  and Gesture Recognition IEEE FG 2025", "pdf_url": "http://arxiv.org/pdf/2507.21104v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.20714", "title": "Prostate Cancer Classification Using Multimodal Feature Fusion and Explainable AI", "authors": ["Asma Sadia Khan", "Fariba Tasnia Khan", "Tanjim Mahmud", "Salman Karim Khan", "Rishita Chakma", "Nahed Sharmen", "Mohammad Shahadat Hossain", "Karl Andersson"], "categories": ["cs.LG", "cs.AI", "q-bio.QM", "stat.AP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20714v1", "summary": "Prostate cancer, the second most prevalent male malignancy, requires advanced\ndiagnostic tools. We propose an explainable AI system combining BERT (for\ntextual clinical notes) and Random Forest (for numerical lab data) through a\nnovel multimodal fusion strategy, achieving superior classification performance\non PLCO-NIH dataset (98% accuracy, 99% AUC). While multimodal fusion is\nestablished, our work demonstrates that a simple yet interpretable BERT+RF\npipeline delivers clinically significant improvements - particularly for\nintermediate cancer stages (Class 2/3 recall: 0.900 combined vs 0.824\nnumerical/0.725 textual). SHAP analysis provides transparent feature importance\nrankings, while ablation studies prove textual features' complementary value.\nThis accessible approach offers hospitals a balance of high performance\n(F1=89%), computational efficiency, and clinical interpretability - addressing\ncritical needs in prostate cancer diagnostics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20714v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20718", "title": "Uncertainty-driven Embedding Convolution", "authors": ["Sungjun Lim", "Kangjun Noh", "Youngjun Choi", "Heeyoung Lee", "Kyungwoo Song"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20718v1", "summary": "Text embeddings are essential components in modern NLP pipelines. While\nnumerous embedding models have been proposed, their performance varies across\ndomains, and no single model consistently excels across all tasks. This\nvariability motivates the use of ensemble techniques to combine complementary\nstrengths. However, most existing ensemble methods operate on deterministic\nembeddings and fail to account for model-specific uncertainty, limiting their\nrobustness and reliability in downstream applications. To address these\nlimitations, we propose Uncertainty-driven Embedding Convolution (UEC). UEC\nfirst transforms deterministic embeddings into probabilistic ones in a post-hoc\nmanner. It then computes adaptive ensemble weights based on embedding\nuncertainty, grounded in a Bayes-optimal solution under a surrogate loss.\nAdditionally, UEC introduces an uncertainty-aware similarity function that\ndirectly incorporates uncertainty into similarity scoring. Extensive\nexperiments on retrieval, classification, and semantic similarity benchmarks\ndemonstrate that UEC consistently improves both performance and robustness by\nleveraging principled uncertainty modeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20718v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2504.00626", "title": "Probabilistically safe and efficient model-based reinforcement learning", "authors": ["Filippo Airaldi", "Bart De Schutter", "Azita Dabiri"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      8 pages, 4 figures, accepted to 2025 CDC", "url": "http://arxiv.org/abs/2504.00626v2", "summary": "This paper proposes tackling safety-critical stochastic Reinforcement\nLearning (RL) tasks with a sample-based, model-based approach. At the core of\nthe method lies a Model Predictive Control (MPC) scheme that acts as function\napproximation, providing a model-based predictive control policy. To ensure\nsafety, a probabilistic Control Barrier Function (CBF) is integrated into the\nMPC controller. To approximate the effects of stochasticies in the optimal\ncontrol formulation and to fulfil the probabilistic CBF condition, a\nsample-based approach with guarantees is employed. Furthermore, to\ncounterbalance the additional computational burden due to sampling, a learnable\nterminal cost formulation is included in the MPC objective. An RL algorithm is\ndeployed to learn both the terminal cost and the CBF constraint. Results from a\nnumerical experiment on a constrained LTI problem corroborate the effectiveness\nof the proposed methodology in reducing computation time while preserving\ncontrol performance and safety.", "comment": "8 pages, 4 figures, accepted to 2025 CDC", "pdf_url": "http://arxiv.org/pdf/2504.00626v2", "cate": "eess.SY", "date": "2025-04-01", "updated": "2025-07-29"}
{"id": "2507.21106", "title": "Creation of a Numerical Scoring System to Objectively Measure and Compare the Level of Rhetoric in Arabic Texts: A Feasibility Study, and A Working Prototype", "authors": ["Mandar Marathe"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This dissertation was submitted by Mandar Marathe on 6 September 2022, in partial fulfilment of the requirements for the Master of Arts degree in Advanced Arabic at the University of Exeter", "url": "http://arxiv.org/abs/2507.21106v1", "summary": "Arabic Rhetoric is the field of Arabic linguistics which governs the art and\nscience of conveying a message with greater beauty, impact and persuasiveness.\nThe field is as ancient as the Arabic language itself and is found extensively\nin classical and contemporary Arabic poetry, free verse and prose. In practical\nterms, it is the intelligent use of word order, figurative speech and\nlinguistic embellishments to enhance message delivery. Despite the volumes that\nhave been written about it and the high status accorded to it, there is no way\nto objectively know whether a speaker or writer has used Arabic rhetoric in a\ngiven text, to what extent, and why. There is no objective way to compare the\nuse of Arabic rhetoric across genres, authors or epochs. It is impossible to\nknow which of pre-Islamic poetry, Andalucian Arabic poetry, or modern literary\ngenres are richer in Arabic rhetoric. The aim of the current study was to\ndevise a way to measure the density of the literary devices which constitute\nArabic rhetoric in a given text, as a proxy marker for Arabic rhetoric itself.\nA comprehensive list of 84 of the commonest literary devices and their\ndefinitions was compiled. A system of identifying literary devices in texts was\nconstructed. A method of calculating the density of literary devices based on\nthe morpheme count of the text was utilised. Four electronic tools and an\nanalogue tool were created to support the calculation of an Arabic text's\nrhetorical literary device density, including a website and online calculator.\nAdditionally, a technique of reporting the distribution of literary devices\nused across the three sub-domains of Arabic rhetoric was created. The output of\nthis project is a working tool which can accurately report the density of\nArabic rhetoric in any Arabic text or speech.", "comment": "This dissertation was submitted by Mandar Marathe on 6 September\n  2022, in partial fulfilment of the requirements for the Master of Arts degree\n  in Advanced Arabic at the University of Exeter", "pdf_url": "http://arxiv.org/pdf/2507.21106v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.20745", "title": "Regularizing Subspace Redundancy of Low-Rank Adaptation", "authors": ["Yue Zhu", "Haiwen Diao", "Shang Gao", "Jiazuo Yu", "Jiawen Zhu", "Yunzhi Zhuge", "Shuai Hao", "Xu Jia", "Lu Zhang", "Ying Zhang", "Huchuan Lu"], "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 4 figures, Accepted by ACMMM2025", "url": "http://arxiv.org/abs/2507.20745v1", "summary": "Low-Rank Adaptation (LoRA) and its variants have delivered strong capability\nin Parameter-Efficient Transfer Learning (PETL) by minimizing trainable\nparameters and benefiting from reparameterization. However, their projection\nmatrices remain unrestricted during training, causing high representation\nredundancy and diminishing the effectiveness of feature adaptation in the\nresulting subspaces. While existing methods mitigate this by manually adjusting\nthe rank or implicitly applying channel-wise masks, they lack flexibility and\ngeneralize poorly across various datasets and architectures. Hence, we propose\nReSoRA, a method that explicitly models redundancy between mapping subspaces\nand adaptively Regularizes Subspace redundancy of Low-Rank Adaptation.\nSpecifically, it theoretically decomposes the low-rank submatrices into\nmultiple equivalent subspaces and systematically applies de-redundancy\nconstraints to the feature distributions across different projections.\nExtensive experiments validate that our proposed method consistently\nfacilitates existing state-of-the-art PETL methods across various backbones and\ndatasets in vision-language retrieval and standard visual classification\nbenchmarks. Besides, as a training supervision, ReSoRA can be seamlessly\nintegrated into existing approaches in a plug-and-play manner, with no\nadditional inference costs. Code is publicly available at:\nhttps://github.com/Lucenova/ReSoRA.", "comment": "10 pages, 4 figures, Accepted by ACMMM2025", "pdf_url": "http://arxiv.org/pdf/2507.20745v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20836", "title": "First Hallucination Tokens Are Different from Conditional Ones", "authors": ["Jakob Snel", "Seong Joon Oh"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      4.5 pages, 3 figures, Dataset, Knowledge Paper, Hallucination, Trustworthiness", "url": "http://arxiv.org/abs/2507.20836v1", "summary": "Hallucination, the generation of untruthful content, is one of the major\nconcerns regarding foundational models. Detecting hallucinations at the token\nlevel is vital for real-time filtering and targeted correction, yet the\nvariation of hallucination signals within token sequences is not fully\nunderstood. Leveraging the RAGTruth corpus with token-level annotations and\nreproduced logits, we analyse how these signals depend on a token's position\nwithin hallucinated spans, contributing to an improved understanding of\ntoken-level hallucination. Our results show that the first hallucinated token\ncarries a stronger signal and is more detectable than conditional tokens. We\nrelease our analysis framework, along with code for logit reproduction and\nmetric computation at https://github.com/jakobsnl/RAGTruth_Xtended.", "comment": "4.5 pages, 3 figures, Dataset, Knowledge Paper, Hallucination,\n  Trustworthiness", "pdf_url": "http://arxiv.org/pdf/2507.20836v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2504.18331", "title": "Unifying Direct and Indirect Learning for Safe Control of Linear Systems", "authors": ["Amir Modares", "Niyousha Ghiasi", "Bahare Kiumarsi", "Hamidreza Modares"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2502.04195", "url": "http://arxiv.org/abs/2504.18331v2", "summary": "This paper develops learning-enabled safe controllers for linear systems\nsubject to system uncertainties and bounded disturbances. Given the disturbance\nzonotope, the databased closed-loop dynamics (CLDs) are first characterized\nusing a matrix zonotope (MZ), and refined through several steps to yield a\nconstrained matrix zonotope (CMZ). This refinement is achieved by introducing\nconformal equality constraints that eliminate incompatible disturbance\nrealizations. More precisely, prior knowledge and observed data are used\nseparately to construct CMZ representations of disturbance sequences that\nconform to both data and prior knowledge, and are intersected by the initial MZ\nof the disturbance sequence, producing a refined CMZ. This approach reduces\nconservatism. To further reduce the conservativeness, we unify open-loop\nlearning with closed-loop learning by presenting a novel set-membership\nidentification method that models open-loop dynamics as a CMZ. The prior\nknowledge serves as an initial feasible open-loop model set (FOLMS) of this\nCMZ, which is refined into a posterior set whenever new informative online data\nbecomes available. This posterior FOLMS then adaptively replaces the prior\nknowledge set employed in the disturbance elimination of the closed-loop\nlearning process. The resulting refined parameterized set of CLD is\nsubsequently leveraged to directly and adaptively learn a controller that\nrobustly enforces safety. Toward this goal, we formulate a linear programming\nproblem that guarantees {\\lambda}contractiveness of a polyhedral safe set. A\nsimulation example is provided to validate the effectiveness of the proposed\napproach and support the theoretical results.", "comment": "arXiv admin note: text overlap with arXiv:2502.04195", "pdf_url": "http://arxiv.org/pdf/2504.18331v2", "cate": "eess.SY", "date": "2025-04-25", "updated": "2025-07-29"}
{"id": "2507.21107", "title": "Curved Inference: Concern-Sensitive Geometry in Large Language Model Residual Streams", "authors": ["Rob Manson"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      29 pages, 22 figures", "url": "http://arxiv.org/abs/2507.21107v1", "summary": "We propose Curved Inference - a geometric Interpretability framework that\ntracks how the residual stream trajectory of a large language model bends in\nresponse to shifts in semantic concern. Across 20 matched prompts spanning\nemotional, moral, perspective, logical, identity, environmental, and nonsense\ndomains, we analyse Gemma3-1b and LLaMA3.2-3b using five native-space metrics,\nwith a primary focus on curvature (\\k{appa}_i) and salience (S(t)). These\nmetrics are computed under a pullback semantic metric derived from the\nunembedding matrix, ensuring that all measurements reflect token-aligned\ngeometry rather than raw coordinate structure. We find that concern-shifted\nprompts reliably alter internal activation trajectories in both models - with\nLLaMA exhibiting consistent, statistically significant scaling in both\ncurvature and salience as concern intensity increases. Gemma also responds to\nconcern but shows weaker differentiation between moderate and strong variants.\nOur results support a two-layer view of LLM geometry - a latent conceptual\nstructure encoded in the embedding space, and a contextual trajectory shaped by\nprompt-specific inference. Curved Inference reveals how models navigate,\nreorient, or reinforce semantic meaning over depth, offering a principled\nmethod for diagnosing alignment, abstraction, and emergent inference dynamics.\nThese findings offer fresh insight into semantic abstraction and model\nalignment through the lens of Curved Inference.", "comment": "29 pages, 22 figures", "pdf_url": "http://arxiv.org/pdf/2507.21107v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.20746", "title": "AR-LIF: Adaptive reset leaky-integrate and fire neuron for spiking neural networks", "authors": ["Zeyu Huang", "Wei Meng", "Quan Liu", "Kun Chen", "Li Ma"], "categories": ["cs.NE", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20746v1", "summary": "Spiking neural networks possess the advantage of low energy consumption due\nto their event-driven nature. Compared with binary spike outputs, their\ninherent floating-point dynamics are more worthy of attention. The threshold\nlevel and reset mode of neurons play a crucial role in determining the number\nand timing of spikes. The existing hard reset method causes information loss,\nwhile the improved soft reset method adopts a uniform treatment for neurons. In\nresponse to this, this paper designs an adaptive reset neuron, establishing the\ncorrelation between input, output and reset, and integrating a simple yet\neffective threshold adjustment strategy. It achieves excellent performance on\nvarious datasets while maintaining the advantage of low energy consumption.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20746v1", "cate": "cs.NE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20838", "title": "BuildSTG: A Multi-building Energy Load Forecasting Method using Spatio-Temporal Graph Neural Network", "authors": ["Yongzheng Liu", "Yiming Wang", "Po Xu", "Yingjie Xu", "Yuntian Chen", "Dongxiao Zhang"], "categories": ["cs.LG", "stat.AP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20838v1", "summary": "Due to the extensive availability of operation data, data-driven methods show\nstrong capabilities in predicting building energy loads. Buildings with similar\nfeatures often share energy patterns, reflected by spatial dependencies in\ntheir operational data, which conventional prediction methods struggle to\ncapture. To overcome this, we propose a multi-building prediction approach\nusing spatio-temporal graph neural networks, comprising graph representation,\ngraph learning, and interpretation. First, a graph is built based on building\ncharacteristics and environmental factors. Next, a multi-level graph\nconvolutional architecture with attention is developed for energy prediction.\nLastly, a method interpreting the optimized graph structure is introduced.\nExperiments on the Building Data Genome Project 2 dataset confirm superior\nperformance over baselines such as XGBoost, SVR, FCNN, GRU, and Naive,\nhighlighting the method's robustness, generalization, and interpretability in\ncapturing meaningful building similarities and spatial relationships.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20838v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2405.07432", "title": "Nonparametric Sparse Online Learning of the Koopman Operator", "authors": ["Boya Hou", "Sina Sanjari", "Nathan Dahlin", "Alec Koppel", "Subhonmesh Bose"], "categories": ["stat.ML", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      47 pages, 6 figures", "url": "http://arxiv.org/abs/2405.07432v3", "summary": "The Koopman operator provides a powerful framework for representing the\ndynamics of general nonlinear dynamical systems. However, existing data-driven\napproaches to learning the Koopman operator rely on batch data. In this work,\nwe present a sparse online learning algorithm that learns the Koopman operator\niteratively via stochastic approximation, with explicit control over model\ncomplexity and provable convergence guarantees. Specifically, we study the\nKoopman operator via its action on the reproducing kernel Hilbert space (RKHS),\nand address the mis-specified scenario where the dynamics may escape the chosen\nRKHS. In this mis-specified setting, we relate the Koopman operator to the\nconditional mean embeddings (CME) operator. We further establish both\nasymptotic and finite-time convergence guarantees for our learning algorithm in\nmis-specified setting, with trajectory-based sampling where the data arrive\nsequentially over time. Numerical experiments demonstrate the algorithm's\ncapability to learn unknown nonlinear dynamics.", "comment": "47 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2405.07432v3", "cate": "stat.ML", "date": "2024-05-13", "updated": "2025-07-29"}
{"id": "2507.21108", "title": "A Survey of Classification Tasks and Approaches for Legal Contracts", "authors": ["Amrita Singh", "Aditya Joshi", "Jiaojiao Jiang", "Hye-young Paik"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Under review. 49 pages + references", "url": "http://arxiv.org/abs/2507.21108v1", "summary": "Given the large size and volumes of contracts and their underlying inherent\ncomplexity, manual reviews become inefficient and prone to errors, creating a\nclear need for automation. Automatic Legal Contract Classification (LCC)\nrevolutionizes the way legal contracts are analyzed, offering substantial\nimprovements in speed, accuracy, and accessibility. This survey delves into the\nchallenges of automatic LCC and a detailed examination of key tasks, datasets,\nand methodologies. We identify seven classification tasks within LCC, and\nreview fourteen datasets related to English-language contracts, including\npublic, proprietary, and non-public sources. We also introduce a methodology\ntaxonomy for LCC, categorized into Traditional Machine Learning, Deep Learning,\nand Transformer-based approaches. Additionally, the survey discusses evaluation\ntechniques and highlights the best-performing results from the reviewed\nstudies. By providing a thorough overview of current methods and their\nlimitations, this survey suggests future research directions to improve the\nefficiency, accuracy, and scalability of LCC. As the first comprehensive survey\non LCC, it aims to support legal NLP researchers and practitioners in improving\nlegal processes, making legal information more accessible, and promoting a more\ninformed and equitable society.", "comment": "Under review. 49 pages + references", "pdf_url": "http://arxiv.org/pdf/2507.21108v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.20753", "title": "Industry Insights from Comparing Deep Learning and GBDT Models for E-Commerce Learning-to-Rank", "authors": ["Yunus Lutz", "Timo Wilm", "Philipp Duwe"], "categories": ["cs.IR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      This work was accepted for publication in the 19th ACM Conference on Recommender Systems (RecSys 2025). The final published version will be available at the ACM Digital Library", "url": "http://arxiv.org/abs/2507.20753v1", "summary": "In e-commerce recommender and search systems, tree-based models, such as\nLambdaMART, have set a strong baseline for Learning-to-Rank (LTR) tasks.\nDespite their effectiveness and widespread adoption in industry, the debate\ncontinues whether deep neural networks (DNNs) can outperform traditional\ntree-based models in this domain. To contribute to this discussion, we\nsystematically benchmark DNNs against our production-grade LambdaMART model. We\nevaluate multiple DNN architectures and loss functions on a proprietary dataset\nfrom OTTO and validate our findings through an 8-week online A/B test. The\nresults show that a simple DNN architecture outperforms a strong tree-based\nbaseline in terms of total clicks and revenue, while achieving parity in total\nunits sold.", "comment": "This work was accepted for publication in the 19th ACM Conference on\n  Recommender Systems (RecSys 2025). The final published version will be\n  available at the ACM Digital Library", "pdf_url": "http://arxiv.org/pdf/2507.20753v1", "cate": "cs.IR", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20840", "title": "Towards Explainable Deep Clustering for Time Series Data", "authors": ["Udo Schlegel", "Gabriel Marques Tavares", "Thomas Seidl"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      14 pages, accepted at TempXAI Workshop at ECML-PKDD 2025", "url": "http://arxiv.org/abs/2507.20840v1", "summary": "Deep clustering uncovers hidden patterns and groups in complex time series\ndata, yet its opaque decision-making limits use in safety-critical settings.\nThis survey offers a structured overview of explainable deep clustering for\ntime series, collecting current methods and their real-world applications. We\nthoroughly discuss and compare peer-reviewed and preprint papers through\napplication domains across healthcare, finance, IoT, and climate science. Our\nanalysis reveals that most work relies on autoencoder and attention\narchitectures, with limited support for streaming, irregularly sampled, or\nprivacy-preserved series, and interpretability is still primarily treated as an\nadd-on. To push the field forward, we outline six research opportunities: (1)\ncombining complex networks with built-in interpretability; (2) setting up\nclear, faithfulness-focused evaluation metrics for unsupervised explanations;\n(3) building explainers that adapt to live data streams; (4) crafting\nexplanations tailored to specific domains; (5) adding human-in-the-loop methods\nthat refine clusters and explanations together; and (6) improving our\nunderstanding of how time series clustering models work internally. By making\ninterpretability a primary design goal rather than an afterthought, we propose\nthe groundwork for the next generation of trustworthy deep clustering time\nseries analytics.", "comment": "14 pages, accepted at TempXAI Workshop at ECML-PKDD 2025", "pdf_url": "http://arxiv.org/pdf/2507.20840v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2412.10180", "title": "A General Safety Framework for Autonomous Manipulation in Human Environments", "authors": ["Jakob Thumm", "Julian Balletshofer", "Leonardo Maglanoc", "Luis Muschal", "Matthias Althoff"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.10180v2", "summary": "Autonomous robots are projected to significantly augment the manual\nworkforce, especially in repetitive and hazardous tasks. For a successful\ndeployment of such robots in human environments, it is crucial to guarantee\nhuman safety. State-of-the-art approaches to ensure human safety are either too\nconservative to permit a natural human-robot collaboration or make strong\nassumptions that do not hold for autonomous robots, e.g., knowledge of a\npre-defined trajectory. Therefore, we propose the shield for Safe Autonomous\nhuman-robot collaboration through Reachability Analysis (SARA shield). This\nnovel power and force limiting framework provides formal safety guarantees for\nmanipulation in human environments while realizing fast robot speeds. As\nunconstrained contacts allow for significantly higher contact forces than\nconstrained contacts (also known as clamping), we use reachability analysis to\nclassify potential contacts by their type in a formally correct way. For each\ncontact type, we formally verify that the kinetic energy of the robot is below\npain and injury thresholds for the respective human body part in contact. Our\nexperiments show that SARA shield satisfies the contact safety constraints\nwhile significantly improving the robot performance in comparison to\nstate-of-the-art approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.10180v2", "cate": "cs.RO", "date": "2024-12-13", "updated": "2025-07-28"}
{"id": "2507.21112", "title": "InsurTech innovation using natural language processing", "authors": ["Panyi Dong", "Zhiyu Quan"], "categories": ["cs.CL", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21112v1", "summary": "With the rapid rise of InsurTech, traditional insurance companies are\nincreasingly exploring alternative data sources and advanced technologies to\nsustain their competitive edge. This paper provides both a conceptual overview\nand practical case studies of natural language processing (NLP) and its\nemerging applications within insurance operations with a focus on transforming\nraw, unstructured text into structured data suitable for actuarial analysis and\ndecision-making. Leveraging real-world alternative data provided by an\nInsurTech industry partner that enriches traditional insurance data sources, we\napply various NLP techniques to demonstrate practical use cases in the\ncommercial insurance context. These enriched, text-derived insights not only\nadd to and refine traditional rating factors for commercial insurance pricing\nbut also offer novel perspectives for assessing underlying risk by introducing\nnovel industry classifications. Through these demonstrations, we show that NLP\nis not merely a supplementary tool but a foundational element for modern,\ndata-driven insurance analytics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21112v1", "cate": "cs.CL", "date": "2025-07-12", "updated": "2025-07-12"}
{"id": "2507.20757", "title": "Learning to See Inside Opaque Liquid Containers using Speckle Vibrometry", "authors": ["Matan Kichler", "Shai Bagon", "Mark Sheinin"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.20757v1", "summary": "Computer vision seeks to infer a wide range of information about objects and\nevents. However, vision systems based on conventional imaging are limited to\nextracting information only from the visible surfaces of scene objects. For\ninstance, a vision system can detect and identify a Coke can in the scene, but\nit cannot determine whether the can is full or empty. In this paper, we aim to\nexpand the scope of computer vision to include the novel task of inferring the\nhidden liquid levels of opaque containers by sensing the tiny vibrations on\ntheir surfaces. Our method provides a first-of-a-kind way to inspect the fill\nlevel of multiple sealed containers remotely, at once, without needing physical\nmanipulation and manual weighing. First, we propose a novel speckle-based\nvibration sensing system for simultaneously capturing scene vibrations on a 2D\ngrid of points. We use our system to efficiently and remotely capture a dataset\nof vibration responses for a variety of everyday liquid containers. Then, we\ndevelop a transformer-based approach for analyzing the captured vibrations and\nclassifying the container type and its hidden liquid level at the time of\nmeasurement. Our architecture is invariant to the vibration source, yielding\ncorrect liquid level estimates for controlled and ambient scene sound sources.\nMoreover, our model generalizes to unseen container instances within known\nclasses (e.g., training on five Coke cans of a six-pack, testing on a sixth)\nand fluid levels. We demonstrate our method by recovering liquid levels from\nvarious everyday containers.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.20757v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20853", "title": "Geometry of Neural Reinforcement Learning in Continuous State and Action Spaces", "authors": ["Saket Tiwari", "Omer Gottesman", "George Konidaris"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2301.00009", "url": "http://arxiv.org/abs/2507.20853v1", "summary": "Advances in reinforcement learning (RL) have led to its successful\napplication in complex tasks with continuous state and action spaces. Despite\nthese advances in practice, most theoretical work pertains to finite state and\naction spaces. We propose building a theoretical understanding of continuous\nstate and action spaces by employing a geometric lens to understand the locally\nattained set of states. The set of all parametrised policies learnt through a\nsemi-gradient based approach induces a set of attainable states in RL. We show\nthat the training dynamics of a two-layer neural policy induce a low\ndimensional manifold of attainable states embedded in the high-dimensional\nnominal state space trained using an actor-critic algorithm. We prove that,\nunder certain conditions, the dimensionality of this manifold is of the order\nof the dimensionality of the action space. This is the first result of its\nkind, linking the geometry of the state space to the dimensionality of the\naction space. We empirically corroborate this upper bound for four MuJoCo\nenvironments and also demonstrate the results in a toy environment with varying\ndimensionality. We also show the applicability of this theoretical result by\nintroducing a local manifold learning layer to the policy and value function\nnetworks to improve the performance in control environments with very high\ndegrees of freedom by changing one layer of the neural network to learn sparse\nrepresentations.", "comment": "Proceedings of the Thirteenth International Conference on Learning\n  Representations (ICLR 2025). arXiv admin note: text overlap with\n  arXiv:2301.00009", "pdf_url": "http://arxiv.org/pdf/2507.20853v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2504.06750", "title": "Robust Capacity Expansion Modelling for Renewable Energy Systems under Weather Uncertainty", "authors": ["Sebastian Kebrich", "Felix Engelhardt", "David Franzmann", "Christina Büsing", "Jochen Linßen", "Heidi Heinrichs"], "categories": ["math.OC", "cs.SY", "eess.SY", "90C10, 90C15, 90C90", "I.6"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.06750v2", "summary": "Future greenhouse gas neutral energy systems will be dominated by renewable\nenergy technologies whose energy output is subject to uncertain weather\nconditions. This work proposes an algorithm to do capacity expansion planning\n(CAPEX) under weather uncertainty. When faced with multiple possible weather\nyears, the quality of a CAPEX solution derived on a single year's data is\nevaluated across all years, and the CAPEX optimisation problem is iteratively\nmodified whenever supply gaps are detected. These modifications lead to\nsolutions with sufficient back--up capacity to overcome periods of (cold) dark\nlulls, and sufficient total annual energy supply across all years. A\ncomputational study on an energy system model of Germany shows that the\niterative algorithm finds solutions that guarantee security of supply for all\nconsidered weather years for an increase of 1.6-2.9% in total annual cost\ncompared to initial solutions. Results also underline the importance of\nassessing the feasibility of energy system models using atypical time--series,\nincluding dark lull and cold period effects.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.06750v2", "cate": "math.OC", "date": "2025-04-09", "updated": "2025-07-29"}
{"id": "2507.21134", "title": "TRIDENT: Benchmarking LLM Safety in Finance, Medicine, and Law", "authors": ["Zheng Hui", "Yijiang River Dong", "Ehsan Shareghi", "Nigel Collier"], "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21134v1", "summary": "As large language models (LLMs) are increasingly deployed in high-risk\ndomains such as law, finance, and medicine, systematically evaluating their\ndomain-specific safety and compliance becomes critical. While prior work has\nlargely focused on improving LLM performance in these domains, it has often\nneglected the evaluation of domain-specific safety risks. To bridge this gap,\nwe first define domain-specific safety principles for LLMs based on the AMA\nPrinciples of Medical Ethics, the ABA Model Rules of Professional Conduct, and\nthe CFA Institute Code of Ethics. Building on this foundation, we introduce\nTrident-Bench, a benchmark specifically targeting LLM safety in the legal,\nfinancial, and medical domains. We evaluated 19 general-purpose and\ndomain-specialized models on Trident-Bench and show that it effectively reveals\nkey safety gaps -- strong generalist models (e.g., GPT, Gemini) can meet basic\nexpectations, whereas domain-specialized models often struggle with subtle\nethical nuances. This highlights an urgent need for finer-grained\ndomain-specific safety improvements. By introducing Trident-Bench, our work\nprovides one of the first systematic resources for studying LLM safety in law\nand finance, and lays the groundwork for future research aimed at reducing the\nsafety risks of deploying LLMs in professionally regulated fields. Code and\nbenchmark will be released at: https://github.com/zackhuiiiii/TRIDENT", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21134v1", "cate": "cs.CL", "date": "2025-07-22", "updated": "2025-07-22"}
{"id": "2507.20782", "title": "Investigation of Accuracy and Bias in Face Recognition Trained with Synthetic Data", "authors": ["Pavel Korshunov", "Ketan Kotwal", "Christophe Ecabert", "Vidit Vidit", "Amir Mohammadi", "Sebastien Marcel"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted for publication in IEEE International Joint Conference on Biometrics (IJCB), 2025", "url": "http://arxiv.org/abs/2507.20782v1", "summary": "Synthetic data has emerged as a promising alternative for training face\nrecognition (FR) models, offering advantages in scalability, privacy\ncompliance, and potential for bias mitigation. However, critical questions\nremain on whether both high accuracy and fairness can be achieved with\nsynthetic data. In this work, we evaluate the impact of synthetic data on bias\nand performance of FR systems. We generate balanced face dataset, FairFaceGen,\nusing two state of the art text-to-image generators, Flux.1-dev and Stable\nDiffusion v3.5 (SD35), and combine them with several identity augmentation\nmethods, including Arc2Face and four IP-Adapters. By maintaining equal identity\ncount across synthetic and real datasets, we ensure fair comparisons when\nevaluating FR performance on standard (LFW, AgeDB-30, etc.) and challenging\nIJB-B/C benchmarks and FR bias on Racial Faces in-the-Wild (RFW) dataset. Our\nresults demonstrate that although synthetic data still lags behind the real\ndatasets in the generalization on IJB-B/C, demographically balanced synthetic\ndatasets, especially those generated with SD35, show potential for bias\nmitigation. We also observe that the number and quality of intra-class\naugmentations significantly affect FR accuracy and fairness. These findings\nprovide practical guidelines for constructing fairer FR systems using synthetic\ndata.", "comment": "Accepted for publication in IEEE International Joint Conference on\n  Biometrics (IJCB), 2025", "pdf_url": "http://arxiv.org/pdf/2507.20782v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20862", "title": "Bi-cephalic self-attended model to classify Parkinson's disease patients with freezing of gait", "authors": ["Shomoita Jahid Mitin", "Rodrigue Rizk", "Maximilian Scherer", "Thomas Koeglsperger", "Daniel Lench", "KC Santosh", "Arun Singh"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      26 pages, 5944 words, 4 figures, 2 tables, European Journal of Neuroscience: Special edition FOG", "url": "http://arxiv.org/abs/2507.20862v1", "summary": "Parkinson Disease (PD) often results in motor and cognitive impairments,\nincluding gait dysfunction, particularly in patients with freezing of gait\n(FOG). Current detection methods are either subjective or reliant on\nspecialized gait analysis tools. This study aims to develop an objective,\ndata-driven, and multi-modal classification model to detect gait dysfunction in\nPD patients using resting-state EEG signals combined with demographic and\nclinical variables. We utilized a dataset of 124 participants: 42 PD patients\nwith FOG (PDFOG+), 41 without FOG (PDFOG-), and 41 age-matched healthy\ncontrols. Features extracted from resting-state EEG and descriptive variables\n(age, education, disease duration) were used to train a novel Bi-cephalic\nSelf-Attention Model (BiSAM). We tested three modalities: signal-only,\ndescriptive-only, and multi-modal, across different EEG channel subsets\n(BiSAM-63, -16, -8, and -4). Signal-only and descriptive-only models showed\nlimited performance, achieving a maximum accuracy of 55% and 68%, respectively.\nIn contrast, the multi-modal models significantly outperformed both, with\nBiSAM-8 and BiSAM-4 achieving the highest classification accuracy of 88%. These\nresults demonstrate the value of integrating EEG with objective descriptive\nfeatures for robust PDFOG+ detection. This study introduces a multi-modal,\nattention-based architecture that objectively classifies PDFOG+ using minimal\nEEG channels and descriptive variables. This approach offers a scalable and\nefficient alternative to traditional assessments, with potential applications\nin routine clinical monitoring and early diagnosis of PD-related gait\ndysfunction.", "comment": "26 pages, 5944 words, 4 figures, 2 tables, European Journal of\n  Neuroscience: Special edition FOG", "pdf_url": "http://arxiv.org/pdf/2507.20862v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21168", "title": "Diverse LLMs or Diverse Question Interpretations? That is the Ensembling Question", "authors": ["Rafael Rosales", "Santiago Miret"], "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7; I.2.0"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21168v1", "summary": "Effectively leveraging diversity has been shown to improve performance for\nvarious machine learning models, including large language models (LLMs).\nHowever, determining the most effective way of using diversity remains a\nchallenge. In this work, we compare two diversity approaches for answering\nbinary questions using LLMs: model diversity, which relies on multiple models\nanswering the same question, and question interpretation diversity, which\nrelies on using the same model to answer the same question framed in different\nways. For both cases, we apply majority voting as the ensemble consensus\nheuristic to determine the final answer. Our experiments on boolq, strategyqa,\nand pubmedqa show that question interpretation diversity consistently leads to\nbetter ensemble accuracy compared to model diversity. Furthermore, our analysis\nof GPT and LLaMa shows that model diversity typically produces results between\nthe best and the worst ensemble members without clear improvement.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21168v1", "cate": "cs.CL", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.20796", "title": "Aligning Large Language Model Agents with Rational and Moral Preferences: A Supervised Fine-Tuning Approach", "authors": ["Wei Lu", "Daniel L. Chen", "Christian B. Hansen"], "categories": ["econ.GN", "cs.AI", "cs.LG", "q-fin.EC"], "primary_category": "Subjects:       General Economics (econ.GN)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20796v1", "summary": "Understanding how large language model (LLM) agents behave in strategic\ninteractions is essential as these systems increasingly participate\nautonomously in economically and morally consequential decisions. We evaluate\nLLM preferences using canonical economic games, finding substantial deviations\nfrom human behavior. Models like GPT-4o show excessive cooperation and limited\nincentive sensitivity, while reasoning models, such as o3-mini, align more\nconsistently with payoff-maximizing strategies. We propose a supervised\nfine-tuning pipeline that uses synthetic datasets derived from economic\nreasoning to align LLM agents with economic preferences, focusing on two\nstylized preference structures. In the first, utility depends only on\nindividual payoffs (homo economicus), while utility also depends on a notion of\nKantian universalizability in the second preference structure (homo moralis).\nWe find that fine-tuning based on small datasets shifts LLM agent behavior\ntoward the corresponding economic agent. We further assess the fine-tuned\nagents' behavior in two applications: Moral dilemmas involving autonomous\nvehicles and algorithmic pricing in competitive markets. These examples\nillustrate how different normative objectives embedded via realizations from\nstructured preference structures can influence market and moral outcomes. This\nwork contributes a replicable, cost-efficient, and economically grounded\npipeline to align AI preferences using moral-economic principles.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20796v1", "cate": "econ.GN", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20894", "title": "Online hierarchical partitioning of the output space in extreme multi-label data stream", "authors": ["Lara Neves", "Afonso Lourenço", "Alberto Cano", "Goreti Marreiros"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at 28th European Conference on Artificial Intelligence (ECAI 2025)", "url": "http://arxiv.org/abs/2507.20894v1", "summary": "Mining data streams with multi-label outputs poses significant challenges due\nto evolving distributions, high-dimensional label spaces, sparse label\noccurrences, and complex label dependencies. Moreover, concept drift affects\nnot only input distributions but also label correlations and imbalance ratios\nover time, complicating model adaptation. To address these challenges,\nstructured learners are categorized into local and global methods. Local\nmethods break down the task into simpler components, while global methods adapt\nthe algorithm to the full output space, potentially yielding better predictions\nby exploiting label correlations. This work introduces iHOMER (Incremental\nHierarchy Of Multi-label Classifiers), an online multi-label learning framework\nthat incrementally partitions the label space into disjoint, correlated\nclusters without relying on predefined hierarchies. iHOMER leverages online\ndivisive-agglomerative clustering based on \\textit{Jaccard} similarity and a\nglobal tree-based learner driven by a multivariate \\textit{Bernoulli} process\nto guide instance partitioning. To address non-stationarity, it integrates\ndrift detection mechanisms at both global and local levels, enabling dynamic\nrestructuring of label partitions and subtrees. Experiments across 23\nreal-world datasets show iHOMER outperforms 5 state-of-the-art global\nbaselines, such as MLHAT, MLHT of Pruned Sets and iSOUPT, by 23\\%, and 12 local\nbaselines, such as binary relevance transformations of kNN, EFDT, ARF, and\nADWIN bagging/boosting ensembles, by 32\\%, establishing its robustness for\nonline multi-label classification.", "comment": "Accepted at 28th European Conference on Artificial Intelligence (ECAI\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.20894v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21186", "title": "Contrast-CAT: Contrasting Activations for Enhanced Interpretability in Transformer-based Text Classifiers", "authors": ["Sungmin Han", "Jeonghyun Lee", "Sangkyun Lee"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21186v1", "summary": "Transformers have profoundly influenced AI research, but explaining their\ndecisions remains challenging -- even for relatively simpler tasks such as\nclassification -- which hinders trust and safe deployment in real-world\napplications. Although activation-based attribution methods effectively explain\ntransformer-based text classification models, our findings reveal that these\nmethods can be undermined by class-irrelevant features within activations,\nleading to less reliable interpretations. To address this limitation, we\npropose Contrast-CAT, a novel activation contrast-based attribution method that\nrefines token-level attributions by filtering out class-irrelevant features. By\ncontrasting the activations of an input sequence with reference activations,\nContrast-CAT generates clearer and more faithful attribution maps. Experimental\nresults across various datasets and models confirm that Contrast-CAT\nconsistently outperforms state-of-the-art methods. Notably, under the MoRF\nsetting, it achieves average improvements of x1.30 in AOPC and x2.25 in LOdds\nover the most competing methods, demonstrating its effectiveness in enhancing\ninterpretability for transformer-based text classification.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21186v1", "cate": "cs.CL", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.20810", "title": "Why Flow Matching is Particle Swarm Optimization?", "authors": ["Kaichen Ouyang"], "categories": ["cs.NE", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      7 pages, 0 figures", "url": "http://arxiv.org/abs/2507.20810v1", "summary": "This paper preliminarily investigates the duality between flow matching in\ngenerative models and particle swarm optimization (PSO) in evolutionary\ncomputation. Through theoretical analysis, we reveal the intrinsic connections\nbetween these two approaches in terms of their mathematical formulations and\noptimization mechanisms: the vector field learning in flow matching shares\nsimilar mathematical expressions with the velocity update rules in PSO; both\nmethods follow the fundamental framework of progressive evolution from initial\nto target distributions; and both can be formulated as dynamical systems\ngoverned by ordinary differential equations. Our study demonstrates that flow\nmatching can be viewed as a continuous generalization of PSO, while PSO\nprovides a discrete implementation of swarm intelligence principles. This\nduality understanding establishes a theoretical foundation for developing novel\nhybrid algorithms and creates a unified framework for analyzing both methods.\nAlthough this paper only presents preliminary discussions, the revealed\ncorrespondences suggest several promising research directions, including\nimproving swarm intelligence algorithms based on flow matching principles and\nenhancing generative models using swarm intelligence concepts.", "comment": "7 pages, 0 figures", "pdf_url": "http://arxiv.org/pdf/2507.20810v1", "cate": "cs.NE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20919", "title": "Modeling User Behavior from Adaptive Surveys with Supplemental Context", "authors": ["Aman Shukla", "Daniel Patrick Scantlebury", "Rishabh Kumar"], "categories": ["cs.LG", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Best Paper, NewInML @ ICML 2025", "url": "http://arxiv.org/abs/2507.20919v1", "summary": "Modeling user behavior is critical across many industries where understanding\npreferences, intent, or decisions informs personalization, targeting, and\nstrategic outcomes. Surveys have long served as a classical mechanism for\ncollecting such behavioral data due to their interpretability, structure, and\nease of deployment. However, surveys alone are inherently limited by user\nfatigue, incomplete responses, and practical constraints on their length making\nthem insufficient for capturing user behavior. In this work, we present LANTERN\n(Late-Attentive Network for Enriched Response Modeling), a modular architecture\nfor modeling user behavior by fusing adaptive survey responses with\nsupplemental contextual signals. We demonstrate the architectural value of\nmaintaining survey primacy through selective gating, residual connections and\nlate fusion via cross-attention, treating survey data as the primary signal\nwhile incorporating external modalities only when relevant. LANTERN outperforms\nstrong survey-only baselines in multi-label prediction of survey responses. We\nfurther investigate threshold sensitivity and the benefits of selective\nmodality reliance through ablation and rare/frequent attribute analysis.\nLANTERN's modularity supports scalable integration of new encoders and evolving\ndatasets. This work provides a practical and extensible blueprint for behavior\nmodeling in survey-centric applications.", "comment": "Best Paper, NewInML @ ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.20919v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21234", "title": "Understanding Public Perception of Crime in Bangladesh: A Transformer-Based Approach with Explainability", "authors": ["Fatema Binte Hassan", "Md Al Jubair", "Mohammad Mehadi Hasan", "Tahmid Hossain", "S M Mehebubur Rahman Khan Shuvo", "Mohammad Shamsul Arefin"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21234v1", "summary": "In recent years, social media platforms have become prominent spaces for\nindividuals to express their opinions on ongoing events, including criminal\nincidents. As a result, public sentiment can shift dynamically over time. This\nstudy investigates the evolving public perception of crime-related news by\nclassifying user-generated comments into three categories: positive, negative,\nand neutral. A newly curated dataset comprising 28,528 Bangla-language social\nmedia comments was developed for this purpose. We propose a transformer-based\nmodel utilizing the XLM-RoBERTa Base architecture, which achieves a\nclassification accuracy of 97%, outperforming existing state-of-the-art methods\nin Bangla sentiment analysis. To enhance model interpretability, explainable AI\ntechnique is employed to identify the most influential features driving\nsentiment classification. The results underscore the effectiveness of\ntransformer-based models in processing low-resource languages such as Bengali\nand demonstrate their potential to extract actionable insights that can support\npublic policy formulation and crime prevention strategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21234v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20872", "title": "Not Only Grey Matter: OmniBrain for Robust Multimodal Classification of Alzheimer's Disease", "authors": ["Ahmed Sharshar", "Yasser Ashraf", "Tameem Bakr", "Salma Hassan", "Hosam Elgendy", "Mohammad Yaqub", "Mohsen Guizani"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Published in Third Workshop on Computer Vision for Automated Medical Diagnosis CVAMD 2025 in ICCV 2025", "url": "http://arxiv.org/abs/2507.20872v1", "summary": "Alzheimer's disease affects over 55 million people worldwide and is projected\nto more than double by 2050, necessitating rapid, accurate, and scalable\ndiagnostics. However, existing approaches are limited because they cannot\nachieve clinically acceptable accuracy, generalization across datasets,\nrobustness to missing modalities, and explainability all at the same time. This\ninability to satisfy all these requirements simultaneously undermines their\nreliability in clinical settings. We propose OmniBrain, a multimodal framework\nthat integrates brain MRI, radiomics, gene expression, and clinical data using\na unified model with cross-attention and modality dropout. OmniBrain achieves\n$92.2 \\pm 2.4\\%$accuracy on the ANMerge dataset and generalizes to the MRI-only\nADNI dataset with $70.4 \\pm 2.7\\%$ accuracy, outperforming unimodal and prior\nmultimodal approaches. Explainability analyses highlight neuropathologically\nrelevant brain regions and genes, enhancing clinical trust. OmniBrain offers a\nrobust, interpretable, and practical solution for real-world Alzheimer's\ndiagnosis.", "comment": "Published in Third Workshop on Computer Vision for Automated Medical\n  Diagnosis CVAMD 2025 in ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.20872v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20925", "title": "Zero-Shot Learning with Subsequence Reordering Pretraining for Compound-Protein Interaction", "authors": ["Hongzhi Zhang", "Zhonglie Liu", "Kun Meng", "Jiameng Chen", "Jia Wu", "Bo Du", "Di Lin", "Yan Che", "Wenbin Hu"], "categories": ["cs.LG", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20925v1", "summary": "Given the vastness of chemical space and the ongoing emergence of previously\nuncharacterized proteins, zero-shot compound-protein interaction (CPI)\nprediction better reflects the practical challenges and requirements of\nreal-world drug development. Although existing methods perform adequately\nduring certain CPI tasks, they still face the following challenges: (1)\nRepresentation learning from local or complete protein sequences often\noverlooks the complex interdependencies between subsequences, which are\nessential for predicting spatial structures and binding properties. (2)\nDependence on large-scale or scarce multimodal protein datasets demands\nsignificant training data and computational resources, limiting scalability and\nefficiency. To address these challenges, we propose a novel approach that\npretrains protein representations for CPI prediction tasks using subsequence\nreordering, explicitly capturing the dependencies between protein subsequences.\nFurthermore, we apply length-variable protein augmentation to ensure excellent\npretraining performance on small training datasets. To evaluate the model's\neffectiveness and zero-shot learning ability, we combine it with various\nbaseline methods. The results demonstrate that our approach can improve the\nbaseline model's performance on the CPI task, especially in the challenging\nzero-shot scenario. Compared to existing pre-training models, our model\ndemonstrates superior performance, particularly in data-scarce scenarios where\ntraining samples are limited. Our implementation is available at\nhttps://github.com/Hoch-Zhang/PSRP-CPI.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20925v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21242", "title": "Bangla BERT for Hyperpartisan News Detection: A Semi-Supervised and Explainable AI Approach", "authors": ["Mohammad Mehadi Hasan", "Fatema Binte Hassan", "Md Al Jubair", "Zobayer Ahmed", "Sazzatul Yeakin", "Md Masum Billah"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21242v1", "summary": "In the current digital landscape, misinformation circulates rapidly, shaping\npublic perception and causing societal divisions. It is difficult to identify\nhyperpartisan news in Bangla since there aren't many sophisticated natural\nlanguage processing methods available for this low-resource language. Without\neffective detection methods, biased content can spread unchecked, posing\nserious risks to informed discourse. To address this gap, our research\nfine-tunes Bangla BERT. This is a state-of-the-art transformer-based model,\ndesigned to enhance classification accuracy for hyperpartisan news. We evaluate\nits performance against traditional machine learning models and implement\nsemi-supervised learning to enhance predictions further. Not only that, we use\nLIME to provide transparent explanations of the model's decision-making\nprocess, which helps to build trust in its outcomes. With a remarkable accuracy\nscore of 95.65%, Bangla BERT outperforms conventional approaches, according to\nour trial data. The findings of this study demonstrate the usefulness of\ntransformer models even in environments with limited resources, which opens the\ndoor to further improvements in this area.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21242v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20880", "title": "JAM: A Tiny Flow-based Song Generator with Fine-grained Controllability and Aesthetic Alignment", "authors": ["Renhang Liu", "Chia-Yu Hung", "Navonil Majumder", "Taylor Gautreaux", "Amir Ali Bagherzadeh", "Chuan Li", "Dorien Herremans", "Soujanya Poria"], "categories": ["cs.SD", "cs.AI"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:       this https URL", "url": "http://arxiv.org/abs/2507.20880v1", "summary": "Diffusion and flow-matching models have revolutionized automatic\ntext-to-audio generation in recent times. These models are increasingly capable\nof generating high quality and faithful audio outputs capturing to speech and\nacoustic events. However, there is still much room for improvement in creative\naudio generation that primarily involves music and songs. Recent open\nlyrics-to-song models, such as, DiffRhythm, ACE-Step, and LeVo, have set an\nacceptable standard in automatic song generation for recreational use. However,\nthese models lack fine-grained word-level controllability often desired by\nmusicians in their workflows. To the best of our knowledge, our\nflow-matching-based JAM is the first effort toward endowing word-level timing\nand duration control in song generation, allowing fine-grained vocal control.\nTo enhance the quality of generated songs to better align with human\npreferences, we implement aesthetic alignment through Direct Preference\nOptimization, which iteratively refines the model using a synthetic dataset,\neliminating the need or manual data annotations. Furthermore, we aim to\nstandardize the evaluation of such lyrics-to-song models through our public\nevaluation dataset JAME. We show that JAM outperforms the existing models in\nterms of the music-specific attributes.", "comment": "https://github.com/declare-lab/jamify", "pdf_url": "http://arxiv.org/pdf/2507.20880v1", "cate": "cs.SD", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20929", "title": "Breaking the Precision Ceiling in Physics-Informed Neural Networks: A Hybrid Fourier-Neural Architecture for Ultra-High Accuracy", "authors": ["Wei Shan Lee", "Chi Kiu Althina Chau", "Kei Chon Sio", "Kam Ian Leong"], "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.comp-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20929v1", "summary": "Physics-informed neural networks (PINNs) have plateaued at errors of\n$10^{-3}$-$10^{-4}$ for fourth-order partial differential equations, creating a\nperceived precision ceiling that limits their adoption in engineering\napplications. We break through this barrier with a hybrid Fourier-neural\narchitecture for the Euler-Bernoulli beam equation, achieving unprecedented L2\nerror of $1.94 \\times 10^{-7}$-a 17-fold improvement over standard PINNs and\n\\(15-500\\times\\) better than traditional numerical methods. Our approach\nsynergistically combines a truncated Fourier series capturing dominant modal\nbehavior with a deep neural network providing adaptive residual corrections. A\nsystematic harmonic optimization study revealed a counter-intuitive discovery:\nexactly 10 harmonics yield optimal performance, with accuracy catastrophically\ndegrading from $10^{-7}$ to $10^{-1}$ beyond this threshold. The two-phase\noptimization strategy (Adam followed by L-BFGS) and adaptive weight balancing\nenable stable ultra-precision convergence. GPU-accelerated implementation\nachieves sub-30-minute training despite fourth-order derivative complexity. By\naddressing 12 critical gaps in existing approaches-from architectural rigidity\nto optimization landscapes-this work demonstrates that ultra-precision is\nachievable through proper design, opening new paradigms for scientific\ncomputing where machine learning can match or exceed traditional numerical\nmethods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20929v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21302", "title": "Can human clinical rationales improve the performance and explainability of clinical text classification models?", "authors": ["Christoph Metzner", "Shang Gao", "Drahomira Herrmannova", "Heidi A. Hanson"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21302v1", "summary": "AI-driven clinical text classification is vital for explainable automated\nretrieval of population-level health information. This work investigates\nwhether human-based clinical rationales can serve as additional supervision to\nimprove both performance and explainability of transformer-based models that\nautomatically encode clinical documents. We analyzed 99,125 human-based\nclinical rationales that provide plausible explanations for primary cancer site\ndiagnoses, using them as additional training samples alongside 128,649\nelectronic pathology reports to evaluate transformer-based models for\nextracting primary cancer sites. We also investigated sufficiency as a way to\nmeasure rationale quality for pre-selecting rationales. Our results showed that\nclinical rationales as additional training data can improve model performance\nin high-resource scenarios but produce inconsistent behavior when resources are\nlimited. Using sufficiency as an automatic metric to preselect rationales also\nleads to inconsistent results. Importantly, models trained on rationales were\nconsistently outperformed by models trained on additional reports instead. This\nsuggests that clinical rationales don't consistently improve model performance\nand are outperformed by simply using more reports. Therefore, if the goal is\noptimizing accuracy, annotation efforts should focus on labeling more reports\nrather than creating rationales. However, if explainability is the priority,\ntraining models on rationale-supplemented data may help them better identify\nrationale-like features. We conclude that using clinical rationales as\nadditional training data results in smaller performance improvements and only\nslightly better explainability (measured as average token-level rationale\ncoverage) compared to training on additional reports.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21302v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20900", "title": "Music Arena: Live Evaluation for Text-to-Music", "authors": ["Yonghyun Kim", "Wayne Chi", "Anastasios N. Angelopoulos", "Wei-Lin Chiang", "Koichi Saito", "Shinji Watanabe", "Yuki Mitsufuji", "Chris Donahue"], "categories": ["cs.SD", "cs.AI", "cs.MM"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20900v1", "summary": "We present Music Arena, an open platform for scalable human preference\nevaluation of text-to-music (TTM) models. Soliciting human preferences via\nlistening studies is the gold standard for evaluation in TTM, but these studies\nare expensive to conduct and difficult to compare, as study protocols may\ndiffer across systems. Moreover, human preferences might help researchers align\ntheir TTM systems or improve automatic evaluation metrics, but an open and\nrenewable source of preferences does not currently exist. We aim to fill these\ngaps by offering *live* evaluation for TTM. In Music Arena, real-world users\ninput text prompts of their choosing and compare outputs from two TTM systems,\nand their preferences are used to compile a leaderboard. While Music Arena\nfollows recent evaluation trends in other AI domains, we also design it with\nkey features tailored to music: an LLM-based routing system to navigate the\nheterogeneous type signatures of TTM systems, and the collection of *detailed*\npreferences including listening data and natural language feedback. We also\npropose a rolling data release policy with user privacy guarantees, providing a\nrenewable source of preference data and increasing platform transparency.\nThrough its standardized evaluation protocol, transparent data access policies,\nand music-specific features, Music Arena not only addresses key challenges in\nthe TTM ecosystem but also demonstrates how live evaluation can be thoughtfully\nadapted to unique characteristics of specific AI domains.\n  Music Arena is available at: https://music-arena.org", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20900v1", "cate": "cs.SD", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20936", "title": "Dissecting Persona-Driven Reasoning in Language Models via Activation Patching", "authors": ["Ansh Poonia", "Maeghal Jain"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages", "url": "http://arxiv.org/abs/2507.20936v1", "summary": "Large language models (LLMs) exhibit remarkable versatility in adopting\ndiverse personas. In this study, we examine how assigning a persona influences\na model's reasoning on an objective task. Using activation patching, we take a\nfirst step toward understanding how key components of the model encode\npersona-specific information. Our findings reveal that the early Multi-Layer\nPerceptron (MLP) layers attend not only to the syntactic structure of the input\nbut also process its semantic content. These layers transform persona tokens\ninto richer representations, which are then used by the middle Multi-Head\nAttention (MHA) layers to shape the model's output. Additionally, we identify\nspecific attention heads that disproportionately attend to racial and\ncolor-based identities.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2507.20936v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21319", "title": "Do Large Language Models Understand Morality Across Cultures?", "authors": ["Hadi Mohammadi", "Yasmeen F. S. S. Meijer", "Efthymia Papadopoulou", "Ayoub Bagheri"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21319v1", "summary": "Recent advancements in large language models (LLMs) have established them as\npowerful tools across numerous domains. However, persistent concerns about\nembedded biases, such as gender, racial, and cultural biases arising from their\ntraining data, raise significant questions about the ethical use and societal\nconsequences of these technologies. This study investigates the extent to which\nLLMs capture cross-cultural differences and similarities in moral perspectives.\nSpecifically, we examine whether LLM outputs align with patterns observed in\ninternational survey data on moral attitudes. To this end, we employ three\ncomplementary methods: (1) comparing variances in moral scores produced by\nmodels versus those reported in surveys, (2) conducting cluster alignment\nanalyses to assess correspondence between country groupings derived from LLM\noutputs and survey data, and (3) directly probing models with comparative\nprompts using systematically chosen token pairs. Our results reveal that\ncurrent LLMs often fail to reproduce the full spectrum of cross-cultural moral\nvariation, tending to compress differences and exhibit low alignment with\nempirical survey patterns. These findings highlight a pressing need for more\nrobust approaches to mitigate biases and improve cultural representativeness in\nLLMs. We conclude by discussing the implications for the responsible\ndevelopment and global deployment of LLMs, emphasizing fairness and ethical\nalignment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21319v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20907", "title": "SCORPION: Addressing Scanner-Induced Variability in Histopathology", "authors": ["Jeongun Ryu", "Heon Song", "Seungeun Lee", "Soo Ick Cho", "Jiwon Shin", "Kyunghyun Paeng", "Sérgio Pereira"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted in UNSURE 2025 workshop in MICCAI", "url": "http://arxiv.org/abs/2507.20907v1", "summary": "Ensuring reliable model performance across diverse domains is a critical\nchallenge in computational pathology. A particular source of variability in\nWhole-Slide Images is introduced by differences in digital scanners, thus\ncalling for better scanner generalization. This is critical for the real-world\nadoption of computational pathology, where the scanning devices may differ per\ninstitution or hospital, and the model should not be dependent on\nscanner-induced details, which can ultimately affect the patient's diagnosis\nand treatment planning. However, past efforts have primarily focused on\nstandard domain generalization settings, evaluating on unseen scanners during\ntraining, without directly evaluating consistency across scanners for the same\ntissue. To overcome this limitation, we introduce SCORPION, a new dataset\nexplicitly designed to evaluate model reliability under scanner variability.\nSCORPION includes 480 tissue samples, each scanned with 5 scanners, yielding\n2,400 spatially aligned patches. This scanner-paired design allows for the\nisolation of scanner-induced variability, enabling a rigorous evaluation of\nmodel consistency while controlling for differences in tissue composition.\nFurthermore, we propose SimCons, a flexible framework that combines\naugmentation-based domain generalization techniques with a consistency loss to\nexplicitly address scanner generalization. We empirically show that SimCons\nimproves model consistency on varying scanners without compromising\ntask-specific performance. By releasing the SCORPION dataset and proposing\nSimCons, we provide the research community with a crucial resource for\nevaluating and improving model consistency across diverse scanners, setting a\nnew standard for reliability testing.", "comment": "Accepted in UNSURE 2025 workshop in MICCAI", "pdf_url": "http://arxiv.org/pdf/2507.20907v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20967", "title": "PROVCREATOR: Synthesizing Complex Heterogenous Graphs with Node and Edge Attributes", "authors": ["Tianhao Wang", "Simon Klancher", "Kunal Mukherjee", "Josh Wiedemeier", "Feng Chen", "Murat Kantarcioglu", "Kangkook Jee"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20967v1", "summary": "The rise of graph-structured data has driven interest in graph learning and\nsynthetic data generation. While successful in text and image domains,\nsynthetic graph generation remains challenging -- especially for real-world\ngraphs with complex, heterogeneous schemas. Existing research has focused\nmostly on homogeneous structures with simple attributes, limiting their\nusefulness and relevance for application domains requiring semantic fidelity.\n  In this research, we introduce ProvCreator, a synthetic graph framework\ndesigned for complex heterogeneous graphs with high-dimensional node and edge\nattributes. ProvCreator formulates graph synthesis as a sequence generation\ntask, enabling the use of transformer-based large language models. It features\na versatile graph-to-sequence encoder-decoder that 1. losslessly encodes graph\nstructure and attributes, 2. efficiently compresses large graphs for contextual\nmodeling, and 3. supports end-to-end, learnable graph generation.\n  To validate our research, we evaluate ProvCreator on two challenging domains:\nsystem provenance graphs in cybersecurity and knowledge graphs from\nIntelliGraph Benchmark Dataset. In both cases, ProvCreator captures intricate\ndependencies between structure and semantics, enabling the generation of\nrealistic and privacy-aware synthetic datasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20967v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21369", "title": "Turbocharging Web Automation: The Impact of Compressed History States", "authors": ["Xiyue Zhu", "Peng Tang", "Haofu Liao", "Srikar Appalaraju"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21369v1", "summary": "Language models have led to a leap forward in web automation. The current web\nautomation approaches take the current web state, history actions, and language\ninstruction as inputs to predict the next action, overlooking the importance of\nhistory states. However, the highly verbose nature of web page states can\nresult in long input sequences and sparse information, hampering the effective\nutilization of history states. In this paper, we propose a novel web history\ncompressor approach to turbocharge web automation using history states. Our\napproach employs a history compressor module that distills the most\ntask-relevant information from each history state into a fixed-length short\nrepresentation, mitigating the challenges posed by the highly verbose history\nstates. Experiments are conducted on the Mind2Web and WebLINX datasets to\nevaluate the effectiveness of our approach. Results show that our approach\nobtains 1.2-5.4% absolute accuracy improvements compared to the baseline\napproach without history inputs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21369v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20913", "title": "HAMLET-FFD: Hierarchical Adaptive Multi-modal Learning Embeddings Transformation for Face Forgery Detection", "authors": ["Jialei Cui", "Jianwei Du", "Yanzhe Li", "Lei Gao", "Hui Jiang", "Chenfu Bao"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20913v1", "summary": "The rapid evolution of face manipulation techniques poses a critical\nchallenge for face forgery detection: cross-domain generalization. Conventional\nmethods, which rely on simple classification objectives, often fail to learn\ndomain-invariant representations. We propose HAMLET-FFD, a cognitively inspired\nHierarchical Adaptive Multi-modal Learning framework that tackles this\nchallenge via bidirectional cross-modal reasoning. Building on contrastive\nvision-language models such as CLIP, HAMLET-FFD introduces a knowledge\nrefinement loop that iteratively assesses authenticity by integrating visual\nevidence with conceptual cues, emulating expert forensic analysis. A key\ninnovation is a bidirectional fusion mechanism in which textual authenticity\nembeddings guide the aggregation of hierarchical visual features, while\nmodulated visual features refine text embeddings to generate image-adaptive\nprompts. This closed-loop process progressively aligns visual observations with\nsemantic priors to enhance authenticity assessment. By design, HAMLET-FFD\nfreezes all pretrained parameters, serving as an external plugin that preserves\nCLIP's original capabilities. Extensive experiments demonstrate its superior\ngeneralization to unseen manipulations across multiple benchmarks, and visual\nanalyses reveal a division of labor among embeddings, with distinct\nrepresentations specializing in fine-grained artifact recognition.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20913v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20968", "title": "From Entanglement to Alignment: Representation Space Decomposition for Unsupervised Time Series Domain Adaptation", "authors": ["Rongyao Cai", "Ming Jin", "Qingsong Wen", "Kexin Zhang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20968v1", "summary": "Domain shift poses a fundamental challenge in time series analysis, where\nmodels trained on source domain often fail dramatically when applied in target\ndomain with different yet similar distributions. While current unsupervised\ndomain adaptation (UDA) methods attempt to align cross-domain feature\ndistributions, they typically treat features as indivisible entities, ignoring\ntheir intrinsic compositions that governs domain adaptation. We introduce\nDARSD, a novel UDA framework with theoretical explainability that explicitly\nrealizes UDA tasks from the perspective of representation space decomposition.\nOur core insight is that effective domain adaptation requires not just\nalignment, but principled disentanglement of transferable knowledge from mixed\nrepresentations. DARSD consists three synergistic components: (I) An\nadversarial learnable common invariant basis that projects original features\ninto a domain-invariant subspace while preserving semantic content; (II) A\nprototypical pseudo-labeling mechanism that dynamically separates target\nfeatures based on confidence, hindering error accumulation; (III) A hybrid\ncontrastive optimization strategy that simultaneously enforces feature\nclustering and consistency while mitigating emerging distribution gaps.\nComprehensive experiments conducted on four benchmark datasets (WISDM, HAR,\nHHAR, and MFD) demonstrate DARSD's superiority against 12 UDA algorithms,\nachieving optimal performance in 35 out of 53 cross-domain scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20968v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21428", "title": "MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations", "authors": ["Elias Lumer", "Anmol Gulati", "Vamse Kumar Subbiah", "Pradeep Honaganahalli Basavaraju", "James A. Burke"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      23 Pages, 20 Figures", "url": "http://arxiv.org/abs/2507.21428v1", "summary": "Large Language Model (LLM) agents have shown significant autonomous\ncapabilities in dynamically searching and incorporating relevant tools or Model\nContext Protocol (MCP) servers for individual queries. However, fixed context\nwindows limit effectiveness in multi-turn interactions requiring repeated,\nindependent tool usage. We introduce MemTool, a short-term memory framework\nenabling LLM agents to dynamically manage tools or MCP server contexts across\nmulti-turn conversations. MemTool offers three agentic architectures: 1)\nAutonomous Agent Mode, granting full tool management autonomy, 2) Workflow\nMode, providing deterministic control without autonomy, and 3) Hybrid Mode,\ncombining autonomous and deterministic control. Evaluating each MemTool mode\nacross 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100\nconsecutive user interactions, measuring tool removal ratios (short-term memory\nefficiency) and task completion accuracy. In Autonomous Agent Mode, reasoning\nLLMs achieve high tool-removal efficiency (90-94% over a 3-window average),\nwhile medium-sized models exhibit significantly lower efficiency (0-60%).\nWorkflow and Hybrid modes consistently manage tool removal effectively, whereas\nAutonomous and Hybrid modes excel at task completion. We present trade-offs and\nrecommendations for each MemTool mode based on task accuracy, agency, and model\ncapabilities.", "comment": "23 Pages, 20 Figures", "pdf_url": "http://arxiv.org/pdf/2507.21428v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20917", "title": "MediQAl: A French Medical Question Answering Dataset for Knowledge and Reasoning Evaluation", "authors": ["Adrien Bazoge"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20917v1", "summary": "This work introduces MediQAl, a French medical question answering dataset\ndesigned to evaluate the capabilities of language models in factual medical\nrecall and reasoning over real-world clinical scenarios. MediQAl contains\n32,603 questions sourced from French medical examinations across 41 medical\nsubjects. The dataset includes three tasks: (i) Multiple-Choice Question with\nUnique answer, (ii) Multiple-Choice Question with Multiple answer, and (iii)\nOpen-Ended Question with Short-Answer. Each question is labeled as\nUnderstanding or Reasoning, enabling a detailed analysis of models' cognitive\ncapabilities. We validate the MediQAl dataset through extensive evaluation with\n14 large language models, including recent reasoning-augmented models, and\nobserve a significant performance gap between factual recall and reasoning\ntasks. Our evaluation provides a comprehensive benchmark for assessing language\nmodels' performance on French medical question answering, addressing a crucial\ngap in multilingual resources for the medical domain.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20917v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20973", "title": "Model-Agnostic Gender Bias Control for Text-to-Image Generation via Sparse Autoencoder", "authors": ["Chao Wu", "Zhenyi Wang", "Kangxian Xie", "Naresh Kumar Devulapally", "Vishnu Suresh Lokhande", "Mingchen Gao"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20973v1", "summary": "Text-to-image (T2I) diffusion models often exhibit gender bias, particularly\nby generating stereotypical associations between professions and gendered\nsubjects. This paper presents SAE Debias, a lightweight and model-agnostic\nframework for mitigating such bias in T2I generation. Unlike prior approaches\nthat rely on CLIP-based filtering or prompt engineering, which often require\nmodel-specific adjustments and offer limited control, SAE Debias operates\ndirectly within the feature space without retraining or architectural\nmodifications. By leveraging a k-sparse autoencoder pre-trained on a gender\nbias dataset, the method identifies gender-relevant directions within the\nsparse latent space, capturing professional stereotypes. Specifically, a biased\ndirection per profession is constructed from sparse latents and suppressed\nduring inference to steer generations toward more gender-balanced outputs.\nTrained only once, the sparse autoencoder provides a reusable debiasing\ndirection, offering effective control and interpretable insight into biased\nsubspaces. Extensive evaluations across multiple T2I models, including Stable\nDiffusion 1.4, 1.5, 2.1, and SDXL, demonstrate that SAE Debias substantially\nreduces gender bias while preserving generation quality. To the best of our\nknowledge, this is the first work to apply sparse autoencoders for identifying\nand intervening in gender bias within T2I models. These findings contribute\ntoward building socially responsible generative AI, providing an interpretable\nand model-agnostic tool to support fairness in text-to-image generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20973v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21432", "title": "Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour", "authors": ["Tareq Alsaleh", "Bilal Farooq"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21432v1", "summary": "This study investigates the adoption of open-access, locally deployable\ncausal large language models (LLMs) for travel mode choice prediction and\nintroduces LiTransMC, the first fine-tuned causal LLM developed for this task.\nWe systematically benchmark eleven LLMs (1-12B parameters) across three stated\nand revealed preference datasets, testing 396 configurations and generating\nover 79,000 synthetic commuter predictions. Beyond predictive accuracy, we\nevaluate models generated reasoning using BERTopic for topic modelling and a\nnovel Explanation Strength Index, providing the first structured analysis of\nhow LLMs articulate decision factors in alignment with behavioural theory.\nLiTransMC, fine-tuned using parameter efficient and loss masking strategy,\nachieved a weighted F1 score of 0.6845 and a Jensen-Shannon Divergence of\n0.000245, surpassing both untuned local models and larger proprietary systems,\nincluding GPT-4o with advanced persona inference and embedding-based loading,\nwhile also outperforming classical mode choice methods such as discrete choice\nmodels and machine learning classifiers for the same dataset. This dual\nimprovement, i.e., high instant-level accuracy and near-perfect distributional\ncalibration, demonstrates the feasibility of creating specialist, locally\ndeployable LLMs that integrate prediction and interpretability. Through\ncombining structured behavioural prediction with natural language reasoning,\nthis work unlocks the potential for conversational, multi-task transport models\ncapable of supporting agent-based simulations, policy testing, and behavioural\ninsight generation. These findings establish a pathway for transforming general\npurpose LLMs into specialized, explainable tools for transportation research\nand policy formulation, while maintaining privacy, reducing cost, and\nbroadening access through local deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21432v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20923", "title": "Pareto-Grid-Guided Large Language Models for Fast and High-Quality Heuristics Design in Multi-Objective Combinatorial Optimization", "authors": ["Minh Hieu Ha", "Hung Phan", "Tung Duy Doan", "Tung Dao", "Dao Tran", "Huynh Thi Thanh Binh"], "categories": ["cs.NE", "cs.AI"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      36 pages, 20 figures", "url": "http://arxiv.org/abs/2507.20923v1", "summary": "Multi-objective combinatorial optimization problems (MOCOP) frequently arise\nin practical applications that require the simultaneous optimization of\nconflicting objectives. Although traditional evolutionary algorithms can be\neffective, they typically depend on domain knowledge and repeated parameter\ntuning, limiting flexibility when applied to unseen MOCOP instances. Recently,\nintegration of Large Language Models (LLMs) into evolutionary computation has\nopened new avenues for automatic heuristic generation, using their advanced\nlanguage understanding and code synthesis capabilities. Nevertheless, most\nexisting approaches predominantly focus on single-objective tasks, often\nneglecting key considerations such as runtime efficiency and heuristic\ndiversity in multi-objective settings. To bridge this gap, we introduce\nMulti-heuristics for MOCOP via Pareto-Grid-guided Evolution of LLMs (MPaGE), a\nnovel enhancement of the Simple Evolutionary Multiobjective Optimization (SEMO)\nframework that leverages LLMs and Pareto Front Grid (PFG) technique. By\npartitioning the objective space into grids and retaining top-performing\ncandidates to guide heuristic generation, MPaGE utilizes LLMs to prioritize\nheuristics with semantically distinct logical structures during variation, thus\npromoting diversity and mitigating redundancy within the population. Through\nextensive evaluations, MPaGE demonstrates superior performance over existing\nLLM-based frameworks, and achieves competitive results to traditional\nMulti-objective evolutionary algorithms (MOEAs), with significantly faster\nruntime. Our code is available at: https://github.com/langkhachhoha/MPaGE.", "comment": "36 pages, 20 figures", "pdf_url": "http://arxiv.org/pdf/2507.20923v1", "cate": "cs.NE", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20984", "title": "SmallThinker: A Family of Efficient Large Language Models Natively Trained for Local Deployment", "authors": ["Yixin Song", "Zhenliang Xue", "Dongliang Wei", "Feiyang Chen", "Jianxiang Gao", "Junchen Liu", "Hangyu Liang", "Guangshuo Qin", "Chengrong Tian", "Bo Wen", "Longyu Zhao", "Xinrui Zheng", "Zeyu Mi", "Haibo Chen"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20984v1", "summary": "While frontier large language models (LLMs) continue to push capability\nboundaries, their deployment remains confined to GPU-powered cloud\ninfrastructure. We challenge this paradigm with SmallThinker, a family of LLMs\nnatively designed - not adapted - for the unique constraints of local devices:\nweak computational power, limited memory, and slow storage. Unlike traditional\napproaches that mainly compress existing models built for clouds, we architect\nSmallThinker from the ground up to thrive within these limitations. Our\ninnovation lies in a deployment-aware architecture that transforms constraints\ninto design principles. First, We introduce a two-level sparse structure\ncombining fine-grained Mixture-of-Experts (MoE) with sparse feed-forward\nnetworks, drastically reducing computational demands without sacrificing model\ncapacity. Second, to conquer the I/O bottleneck of slow storage, we design a\npre-attention router that enables our co-designed inference engine to prefetch\nexpert parameters from storage while computing attention, effectively hiding\nstorage latency that would otherwise cripple on-device inference. Third, for\nmemory efficiency, we utilize NoPE-RoPE hybrid sparse attention mechanism to\nslash KV cache requirements. We release SmallThinker-4B-A0.6B and\nSmallThinker-21B-A3B, which achieve state-of-the-art performance scores and\neven outperform larger LLMs. Remarkably, our co-designed system mostly\neliminates the need for expensive GPU hardware: with Q4_0 quantization, both\nmodels exceed 20 tokens/s on ordinary consumer CPUs, while consuming only 1GB\nand 8GB of memory respectively. SmallThinker is publicly available at\nhf.co/PowerInfer/SmallThinker-4BA0.6B-Instruct and\nhf.co/PowerInfer/SmallThinker-21BA3B-Instruct.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20984v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21476", "title": "Which LLMs Get the Joke? Probing Non-STEM Reasoning Abilities with HumorBench", "authors": ["Reuben Narad", "Siddharth Suresh", "Jiayi Chen", "Pine S. L. Dysart-Bricken", "Bob Mankoff", "Robert Nowak", "Jifan Zhang", "Lalit Jain"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21476v1", "summary": "We present HumorBench, a benchmark designed to evaluate large language\nmodels' (LLMs) ability to reason about and explain sophisticated humor in\ncartoon captions. As reasoning models increasingly saturate existing benchmarks\nin mathematics and science, novel and challenging evaluations of model\nintelligence beyond STEM domains are essential. Reasoning is fundamentally\ninvolved in text-based humor comprehension, requiring the identification of\nconnections between concepts in cartoons/captions and external cultural\nreferences, wordplays, and other mechanisms. HumorBench includes approximately\n300 unique cartoon-caption pairs from the New Yorker Caption Contest and\nCartoonstock.com, with expert-annotated evaluation rubrics identifying\nessential joke elements. LLMs are evaluated based on their explanations towards\nthe humor and abilities in identifying the joke elements. To perform well on\nthis task, models must form and test hypotheses about associations between\nconcepts, potentially backtracking from initial interpretations to arrive at\nthe most plausible explanation. Our extensive benchmarking of current SOTA\nmodels reveals three key insights: (1) LLM progress on STEM reasoning transfers\neffectively to humor comprehension; (2) models trained exclusively on STEM\nreasoning data still perform well on HumorBench, demonstrating strong\ntransferability of reasoning abilities; and (3) test-time scaling by increasing\nthinking token budgets yields mixed results across different models in humor\nreasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21476v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20930", "title": "FRED: Financial Retrieval-Enhanced Detection and Editing of Hallucinations in Language Models", "authors": ["Likun Tan", "Kuan-Wei Huang", "Kevin Wu"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20930v1", "summary": "Hallucinations in large language models pose a critical challenge for\napplications requiring factual reliability, particularly in high-stakes domains\nsuch as finance. This work presents an effective approach for detecting and\nediting factually incorrect content in model-generated responses based on the\nprovided context. Given a user-defined domain-specific error taxonomy, we\nconstruct a synthetic dataset by inserting tagged errors into financial\nquestion-answering corpora and then fine-tune four language models, Phi-4,\nPhi-4-mini, Qwen3-4B, and Qwen3-14B, to detect and edit these factual\ninaccuracies. Our best-performing model, fine-tuned Phi-4, achieves an 8%\nimprovement in binary F1 score and a 30% gain in overall detection performance\ncompared to OpenAI-o3. Notably, our fine-tuned Phi-4-mini model, despite having\nonly 4 billion parameters, maintains competitive performance with just a 2%\ndrop in binary detection and a 0.1% decline in overall detection compared to\nOpenAI-o3. Our work provides a practical solution for detecting and editing\nfactual inconsistencies in financial text generation while introducing a\ngeneralizable framework that can enhance the trustworthiness and alignment of\nlarge language models across diverse applications beyond finance. Our code and\ndata are available at https://github.com/pegasi-ai/fine-grained-editting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20930v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20993", "title": "Personalized Treatment Effect Estimation from Unstructured Data", "authors": ["Henri Arno", "Thomas Demeester"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20993v1", "summary": "Existing methods for estimating personalized treatment effects typically rely\non structured covariates, limiting their applicability to unstructured data.\nYet, leveraging unstructured data for causal inference has considerable\napplication potential, for instance in healthcare, where clinical notes or\nmedical images are abundant. To this end, we first introduce an approximate\n'plug-in' method trained directly on the neural representations of unstructured\ndata. However, when these fail to capture all confounding information, the\nmethod may be subject to confounding bias. We therefore introduce two\ntheoretically grounded estimators that leverage structured measurements of the\nconfounders during training, but allow estimating personalized treatment\neffects purely from unstructured inputs, while avoiding confounding bias. When\nthese structured measurements are only available for a non-representative\nsubset of the data, these estimators may suffer from sampling bias. To address\nthis, we further introduce a regression-based correction that accounts for the\nnon-uniform sampling, assuming the sampling mechanism is known or can be\nwell-estimated. Our experiments on two benchmark datasets show that the plug-in\nmethod, directly trainable on large unstructured datasets, achieves strong\nempirical performance across all settings, despite its simplicity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20993v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21482", "title": "Improving Task Diversity in Label Efficient Supervised Finetuning of LLMs", "authors": ["Abhinav Arabelly", "Jagrut Nemade", "Robert D Nowak", "Jifan Zhang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21482v1", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\ndiverse domains, but developing high-performing models for specialized\napplications often requires substantial human annotation -- a process that is\ntime-consuming, labor-intensive, and expensive. In this paper, we address the\nlabel-efficient learning problem for supervised finetuning (SFT) by leveraging\ntask-diversity as a fundamental principle for effective data selection. This is\nmarkedly different from existing methods based on the prompt-diversity. Our\napproach is based on two key observations: 1) task labels for different prompts\nare often readily available; 2) pre-trained models have significantly varying\nlevels of confidence across tasks. We combine these facts to devise a simple\nyet effective sampling strategy: we select examples across tasks using an\ninverse confidence weighting strategy. This produces models comparable to or\nbetter than those trained with more complex sampling procedures, while being\nsignificantly easier to implement and less computationally intensive. Notably,\nour experimental results demonstrate that this method can achieve better\naccuracy than training on the complete dataset (a 4\\% increase in MMLU score).\nAcross various annotation budgets and two instruction finetuning datasets, our\nalgorithm consistently performs at or above the level of the best existing\nmethods, while reducing annotation costs by up to 80\\%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21482v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20941", "title": "Multivariate Conformal Prediction via Conformalized Gaussian Scoring", "authors": ["Sacha Braun", "Eugène Berta", "Michael I. Jordan", "Francis Bach"], "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.ME", "stat.OT"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20941v1", "summary": "While achieving exact conditional coverage in conformal prediction is\nunattainable without making strong, untestable regularity assumptions, the\npromise of conformal prediction hinges on finding approximations to conditional\nguarantees that are realizable in practice. A promising direction for obtaining\nconditional dependence for conformal sets--in particular capturing\nheteroskedasticity--is through estimating the conditional density\n$\\mathbb{P}_{Y|X}$ and conformalizing its level sets. Previous work in this\nvein has focused on nonconformity scores based on the empirical cumulative\ndistribution function (CDF). Such scores are, however, computationally costly,\ntypically requiring expensive sampling methods. To avoid the need for sampling,\nwe observe that the CDF-based score reduces to a Mahalanobis distance in the\ncase of Gaussian scores, yielding a closed-form expression that can be directly\nconformalized. Moreover, the use of a Gaussian-based score opens the door to a\nnumber of extensions of the basic conformal method; in particular, we show how\nto construct conformal sets with missing output values, refine conformal sets\nas partial information about $Y$ becomes available, and construct conformal\nsets on transformations of the output space. Finally, empirical results\nindicate that our approach produces conformal sets that more closely\napproximate conditional coverage in multivariate settings compared to\nalternative methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20941v1", "cate": "stat.ML", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20997", "title": "Modular Delta Merging with Orthogonal Constraints: A Scalable Framework for Continual and Reversible Model Composition", "authors": ["Haris Khan", "Shumaila Asif", "Sadia Asif"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 6 figures, 3 tables. Will be Submitted to ICLR 2025 for review", "url": "http://arxiv.org/abs/2507.20997v1", "summary": "In real-world machine learning deployments, models must be continually\nupdated, composed, and when required, selectively undone. However, existing\napproaches to model merging and continual learning often suffer from task\ninterference, catastrophic forgetting, or lack of reversibility. We propose\nModular Delta Merging with Orthogonal Constraints (MDM-OC), a novel framework\nthat enables scalable, interference-free, and reversible composition of\nfine-tuned models. Each task-specific model is encoded as a delta from a shared\nbase and projected into an orthogonal subspace to eliminate conflict. These\nprojected deltas are then merged via gradient-based optimization to form a\nunified model that retains performance across tasks. Our approach supports\ncontinual integration of new models, structured unmerging for compliance such\nas GDPR requirements, and model stability via elastic weight consolidation and\nsynthetic replay. Extensive experiments on vision and natural language\nprocessing benchmarks demonstrate that MDM-OC outperforms prior baselines in\naccuracy, backward transfer, and unmerge fidelity, while remaining\nmemory-efficient and computationally tractable. This framework offers a\nprincipled solution for modular and compliant AI system design.", "comment": "11 pages, 6 figures, 3 tables. Will be Submitted to ICLR 2025 for\n  review", "pdf_url": "http://arxiv.org/pdf/2507.20997v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21500", "title": "VN-MTEB: Vietnamese Massive Text Embedding Benchmark", "authors": ["Loc Pham", "Tung Luu", "Thu Vo", "Minh Nguyen", "Viet Hoang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      19 pages (including reference, appendix) 41 datasets from 6 tasks (retrieval, classification, pair-classification, clustering, rerank, sts) 7 figures, 16 tables, benchmark 18 text embedding models", "url": "http://arxiv.org/abs/2507.21500v1", "summary": "Vietnam ranks among the top countries in terms of both internet traffic and\nonline toxicity. As a result, implementing embedding models for recommendation\nand content control duties in applications is crucial. However, a lack of\nlarge-scale test datasets, both in volume and task diversity, makes it tricky\nfor scientists to effectively evaluate AI models before deploying them in\nreal-world, large-scale projects. To solve this important problem, we introduce\na Vietnamese benchmark, VN-MTEB for embedding models, which we created by\ntranslating a large number of English samples from the Massive Text Embedding\nBenchmark using our new automated framework. We leverage the strengths of large\nlanguage models (LLMs) and cutting-edge embedding models to conduct translation\nand filtering processes to retain high-quality samples, guaranteeing a natural\nflow of language and semantic fidelity while preserving named entity\nrecognition (NER) and code snippets. Our comprehensive benchmark consists of 41\ndatasets from six tasks specifically designed for Vietnamese text embeddings.\nIn our analysis, we find that bigger and more complex models using Rotary\nPositional Embedding outperform those using Absolute Positional Embedding in\nembedding tasks. Datasets are available at HuggingFace:\nhttps://huggingface.co/collections/GreenNode/vn-mteb-68871433f0f7573b8e1a6686", "comment": "19 pages (including reference, appendix) 41 datasets from 6 tasks\n  (retrieval, classification, pair-classification, clustering, rerank, sts) 7\n  figures, 16 tables, benchmark 18 text embedding models", "pdf_url": "http://arxiv.org/pdf/2507.21500v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20956", "title": "Mind the Gap: Conformative Decoding to Improve Output Diversity of Instruction-Tuned Large Language Models", "authors": ["Max Peeperkorn", "Tom Kouwenhoven", "Dan Brown", "Anna Jordanous"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages, 3 figures", "url": "http://arxiv.org/abs/2507.20956v1", "summary": "Instruction-tuning large language models (LLMs) reduces the diversity of\ntheir outputs, which has implications for many tasks, particularly for creative\ntasks. This paper investigates the ``diversity gap'' for a writing prompt\nnarrative generation task. This gap emerges as measured by current diversity\nmetrics for various open-weight and open-source LLMs. The results show\nsignificant decreases in diversity due to instruction-tuning. We explore the\ndiversity loss at each fine-tuning stage for the OLMo and OLMo 2 models to\nfurther understand how output diversity is affected. The results indicate that\nDPO has the most substantial impact on diversity. Motivated by these findings,\nwe present a new decoding strategy, conformative decoding, which guides an\ninstruct model using its more diverse base model to reintroduce output\ndiversity. We show that conformative decoding typically increases diversity and\neven maintains or improves quality.", "comment": "9 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.20956v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.20999", "title": "LoRA-PAR: A Flexible Dual-System LoRA Partitioning Approach to Efficient LLM Fine-Tuning", "authors": ["Yining Huang", "Bin Li", "Keke Tang", "Meilian Chen"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.20999v1", "summary": "Large-scale generative models like DeepSeek-R1 and OpenAI-O1 benefit\nsubstantially from chain-of-thought (CoT) reasoning, yet pushing their\nperformance typically requires vast data, large model sizes, and full-parameter\nfine-tuning. While parameter-efficient fine-tuning (PEFT) helps reduce cost,\nmost existing approaches primarily address domain adaptation or layer-wise\nallocation rather than explicitly tailoring data and parameters to different\nresponse demands. Inspired by \"Thinking, Fast and Slow,\" which characterizes\ntwo distinct modes of thought-System 1 (fast, intuitive, often automatic) and\nSystem 2 (slower, more deliberative and analytic)-we draw an analogy that\ndifferent \"subregions\" of an LLM's parameters might similarly specialize for\ntasks that demand quick, intuitive responses versus those requiring multi-step\nlogical reasoning. Therefore, we propose LoRA-PAR, a dual-system LoRA framework\nthat partitions both data and parameters by System 1 or System 2 demands, using\nfewer yet more focused parameters for each task. Specifically, we classify task\ndata via multi-model role-playing and voting, and partition parameters based on\nimportance scoring, then adopt a two-stage fine-tuning strategy of training\nSystem 1 tasks with supervised fine-tuning (SFT) to enhance knowledge and\nintuition and refine System 2 tasks with reinforcement learning (RL) to\nreinforce deeper logical deliberation next. Extensive experiments show that the\ntwo-stage fine-tuning strategy, SFT and RL, lowers active parameter usage while\nmatching or surpassing SOTA PEFT baselines.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.20999v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21509", "title": "Persona Vectors: Monitoring and Controlling Character Traits in Language Models", "authors": ["Runjin Chen", "Andy Arditi", "Henry Sleight", "Owain Evans", "Jack Lindsey"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21509v1", "summary": "Large language models interact with users through a simulated 'Assistant'\npersona. While the Assistant is typically trained to be helpful, harmless, and\nhonest, it sometimes deviates from these ideals. In this paper, we identify\ndirections in the model's activation space-persona vectors-underlying several\ntraits, such as evil, sycophancy, and propensity to hallucinate. We confirm\nthat these vectors can be used to monitor fluctuations in the Assistant's\npersonality at deployment time. We then apply persona vectors to predict and\ncontrol personality shifts that occur during training. We find that both\nintended and unintended personality changes after finetuning are strongly\ncorrelated with shifts along the relevant persona vectors. These shifts can be\nmitigated through post-hoc intervention, or avoided in the first place with a\nnew preventative steering method. Moreover, persona vectors can be used to flag\ntraining data that will produce undesirable personality changes, both at the\ndataset level and the individual sample level. Our method for extracting\npersona vectors is automated and can be applied to any personality trait of\ninterest, given only a natural-language description.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21509v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20957", "title": "Your AI, Not Your View: The Bias of LLMs in Investment Analysis", "authors": ["Hoyoung Lee", "Junhyuk Seo", "Suhwan Park", "Junhyeong Lee", "Wonbin Ahn", "Chanyeol Choi", "Alejandro Lopez-Lira", "Yongjae Lee"], "categories": ["q-fin.PM", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Portfolio Management (q-fin.PM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20957v1", "summary": "In finance, Large Language Models (LLMs) face frequent knowledge conflicts\ndue to discrepancies between pre-trained parametric knowledge and real-time\nmarket data. These conflicts become particularly problematic when LLMs are\ndeployed in real-world investment services, where misalignment between a\nmodel's embedded preferences and those of the financial institution can lead to\nunreliable recommendations. Yet little research has examined what investment\nviews LLMs actually hold. We propose an experimental framework to investigate\nsuch conflicts, offering the first quantitative analysis of confirmation bias\nin LLM-based investment analysis. Using hypothetical scenarios with balanced\nand imbalanced arguments, we extract models' latent preferences and measure\ntheir persistence. Focusing on sector, size, and momentum, our analysis reveals\ndistinct, model-specific tendencies. In particular, we observe a consistent\npreference for large-cap stocks and contrarian strategies across most models.\nThese preferences often harden into confirmation bias, with models clinging to\ninitial judgments despite counter-evidence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20957v1", "cate": "q-fin.PM", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21004", "title": "Compositional Function Networks: A High-Performance Alternative to Deep Neural Networks with Built-in Interpretability", "authors": ["Fang Li"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21004v1", "summary": "Deep Neural Networks (DNNs) deliver impressive performance but their\nblack-box nature limits deployment in high-stakes domains requiring\ntransparency. We introduce Compositional Function Networks (CFNs), a novel\nframework that builds inherently interpretable models by composing elementary\nmathematical functions with clear semantics. Unlike existing interpretable\napproaches that are limited to simple additive structures, CFNs support diverse\ncompositional patterns -- sequential, parallel, and conditional -- enabling\ncomplex feature interactions while maintaining transparency. A key innovation\nis that CFNs are fully differentiable, allowing efficient training through\nstandard gradient descent. We demonstrate CFNs' versatility across multiple\ndomains, from symbolic regression to image classification with deep\nhierarchical networks. Our empirical evaluation shows CFNs achieve competitive\nperformance against black-box models (96.24% accuracy on CIFAR-10) while\noutperforming state-of-the-art interpretable models like Explainable Boosting\nMachines. By combining the hierarchical expressiveness and efficient training\nof deep learning with the intrinsic interpretability of well-defined\nmathematical functions, CFNs offer a powerful framework for applications where\nboth performance and accountability are paramount.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21004v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21526", "title": "TriangleMix: A Lossless and Efficient Attention Pattern for Long Context Prefilling", "authors": ["Zhiyuan He", "Yike Zhang", "Chengruidong Zhang", "Huiqiang Jiang", "Yuqing Yang", "Lili Qiu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21526v1", "summary": "Large Language Models (LLMs) rely on attention mechanisms whose time\ncomplexity grows quadratically with input sequence length, creating significant\ncomputational bottlenecks during the prefilling stage. Existing static sparse\nattention methods typically degrade accuracy, while dynamic sparsity methods\nintroduce additional computational overhead due to runtime sparse index\nestimation. To address these limitations, we propose TriangleMix, a novel\ntraining-free static attention pattern. TriangleMix employs dense attention in\nshallow layers and switches to a triangle-shaped sparse pattern in deeper\nlayers. Extensive experiments demonstrate that TriangleMix reduces attention\noverhead by 3.7x to 15.3x in deep layers, and decreases overall\nTime-to-First-Token (TTFT) by 12% to 32% for sequence lengths ranging from 32K\nto 128K, without sacrificing model accuracy. Moreover, TriangleMix can be\nseamlessly integrated with dynamic sparsity methods to achieve further speedup,\ne.g. accelerating MInference by 19% at 128K, highlighting its potential to\nenhance LLM inference efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21526v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20987", "title": "JWB-DH-V1: Benchmark for Joint Whole-Body Talking Avatar and Speech Generation Version 1", "authors": ["Xinhan Di", "Kristin Qi", "Pengqian Yu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      WiCV @ ICCV 2025", "url": "http://arxiv.org/abs/2507.20987v2", "summary": "Recent advances in diffusion-based video generation have enabled\nphoto-realistic short clips, but current methods still struggle to achieve\nmulti-modal consistency when jointly generating whole-body motion and natural\nspeech. Current approaches lack comprehensive evaluation frameworks that assess\nboth visual and audio quality, and there are insufficient benchmarks for\nregion-specific performance analysis. To address these gaps, we introduce the\nJoint Whole-Body Talking Avatar and Speech Generation Version I(JWB-DH-V1),\ncomprising a large-scale multi-modal dataset with 10,000 unique identities\nacross 2 million video samples, and an evaluation protocol for assessing joint\naudio-video generation of whole-body animatable avatars. Our evaluation of SOTA\nmodels reveals consistent performance disparities between face/hand-centric and\nwhole-body performance, which incidates essential areas for future research.\nThe dataset and evaluation tools are publicly available at\nhttps://github.com/deepreasonings/WholeBodyBenchmark.", "comment": "WiCV @ ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.20987v2", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-29"}
{"id": "2507.21016", "title": "Predicting Cognition from fMRI:A Comparative Study of Graph, Transformer, and Kernel Models Across Task and Rest Conditions", "authors": ["Jagruti Patel", "Mikkel Schöttner", "Thomas A. W. Bolton", "Patric Hagmann"], "categories": ["cs.LG", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preliminary version; a revised version will be uploaded later", "url": "http://arxiv.org/abs/2507.21016v1", "summary": "Predicting cognition from neuroimaging data in healthy individuals offers\ninsights into the neural mechanisms underlying cognitive abilities, with\npotential applications in precision medicine and early detection of\nneurological and psychiatric conditions. This study systematically benchmarked\nclassical machine learning (Kernel Ridge Regression (KRR)) and advanced deep\nlearning (DL) models (Graph Neural Networks (GNN) and Transformer-GNN (TGNN))\nfor cognitive prediction using Resting-state (RS), Working Memory, and Language\ntask fMRI data from the Human Connectome Project Young Adult dataset.\n  Our results, based on R2 scores, Pearson correlation coefficient, and mean\nabsolute error, revealed that task-based fMRI, eliciting neural responses\ndirectly tied to cognition, outperformed RS fMRI in predicting cognitive\nbehavior. Among the methods compared, a GNN combining structural connectivity\n(SC) and functional connectivity (FC) consistently achieved the highest\nperformance across all fMRI modalities; however, its advantage over KRR using\nFC alone was not statistically significant. The TGNN, designed to model\ntemporal dynamics with SC as a prior, performed competitively with FC-based\napproaches for task-fMRI but struggled with RS data, where its performance\naligned with the lower-performing GNN that directly used fMRI time-series data\nas node features. These findings emphasize the importance of selecting\nappropriate model architectures and feature representations to fully leverage\nthe spatial and temporal richness of neuroimaging data.\n  This study highlights the potential of multimodal graph-aware DL models to\ncombine SC and FC for cognitive prediction, as well as the promise of\nTransformer-based approaches for capturing temporal dynamics. By providing a\ncomprehensive comparison of models, this work serves as a guide for advancing\nbrain-behavior modeling using fMRI, SC and DL.", "comment": "Preliminary version; a revised version will be uploaded later", "pdf_url": "http://arxiv.org/pdf/2507.21016v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21532", "title": "Automatic Classification of User Requirements from Online Feedback -- A Replication Study", "authors": ["Meet Bhatt", "Nic Boilard", "Muhammad Rehan Chaudhary", "Cole Thompson", "Jacob Idoko", "Aakash Sorathiya", "Gouri Ginde"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 3 figures, Replication package available at this https URL , Accepted at AIRE 2025 (12th International Workshop on Artificial Intelligence and Requirements Engineering)", "url": "http://arxiv.org/abs/2507.21532v1", "summary": "Natural language processing (NLP) techniques have been widely applied in the\nrequirements engineering (RE) field to support tasks such as classification and\nambiguity detection. Although RE research is rooted in empirical investigation,\nit has paid limited attention to replicating NLP for RE (NLP4RE) studies. The\nrapidly advancing realm of NLP is creating new opportunities for efficient,\nmachine-assisted workflows, which can bring new perspectives and results to the\nforefront. Thus, we replicate and extend a previous NLP4RE study (baseline),\n\"Classifying User Requirements from Online Feedback in Small Dataset\nEnvironments using Deep Learning\", which evaluated different deep learning\nmodels for requirement classification from user reviews. We reproduced the\noriginal results using publicly released source code, thereby helping to\nstrengthen the external validity of the baseline study. We then extended the\nsetup by evaluating model performance on an external dataset and comparing\nresults to a GPT-4o zero-shot classifier. Furthermore, we prepared the\nreplication study ID-card for the baseline study, important for evaluating\nreplication readiness. Results showed diverse reproducibility levels across\ndifferent models, with Naive Bayes demonstrating perfect reproducibility. In\ncontrast, BERT and other models showed mixed results. Our findings revealed\nthat baseline deep learning models, BERT and ELMo, exhibited good\ngeneralization capabilities on an external dataset, and GPT-4o showed\nperformance comparable to traditional baseline machine learning models.\nAdditionally, our assessment confirmed the baseline study's replication\nreadiness; however missing environment setup files would have further enhanced\nreadiness. We include this missing information in our replication package and\nprovide the replication study ID-card for our study to further encourage and\nsupport the replication of our study.", "comment": "10 pages, 3 figures, Replication package available at\n  https://zenodo.org/records/15626782, Accepted at AIRE 2025 (12th\n  International Workshop on Artificial Intelligence and Requirements\n  Engineering)", "pdf_url": "http://arxiv.org/pdf/2507.21532v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.20994", "title": "Security Tensors as a Cross-Modal Bridge: Extending Text-Aligned Safety to Vision in LVLM", "authors": ["Shen Li", "Liuyi Yao", "Wujia Niu", "Lan Zhang", "Yaliang Li"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Codes and data are available at this https URL", "url": "http://arxiv.org/abs/2507.20994v1", "summary": "Large visual-language models (LVLMs) integrate aligned large language models\n(LLMs) with visual modules to process multimodal inputs. However, the safety\nmechanisms developed for text-based LLMs do not naturally extend to visual\nmodalities, leaving LVLMs vulnerable to harmful image inputs. To address this\ncross-modal safety gap, we introduce security tensors - trainable input vectors\napplied during inference through either the textual or visual modality. These\ntensors transfer textual safety alignment to visual processing without\nmodifying the model's parameters. They are optimized using a curated dataset\ncontaining (i) malicious image-text pairs requiring rejection, (ii) contrastive\nbenign pairs with text structurally similar to malicious queries, with the\npurpose of being contrastive examples to guide visual reliance, and (iii)\ngeneral benign samples preserving model functionality. Experimental results\ndemonstrate that both textual and visual security tensors significantly enhance\nLVLMs' ability to reject diverse harmful visual inputs while maintaining\nnear-identical performance on benign tasks. Further internal analysis towards\nhidden-layer representations reveals that security tensors successfully\nactivate the language module's textual \"safety layers\" in visual inputs,\nthereby effectively extending text-based safety to the visual modality.", "comment": "Codes and data are available at\n  https://github.com/listen0425/Security-Tensors", "pdf_url": "http://arxiv.org/pdf/2507.20994v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21021", "title": "Behavior-Specific Filtering for Enhanced Pig Behavior Classification in Precision Livestock Farming", "authors": ["Zhen Zhang", "Dong Sam Ha", "Gota Morota", "Sook Shin"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 4 tables, 3 figures", "url": "http://arxiv.org/abs/2507.21021v1", "summary": "This study proposes a behavior-specific filtering method to improve behavior\nclassification accuracy in Precision Livestock Farming. While traditional\nfiltering methods, such as wavelet denoising, achieved an accuracy of 91.58%,\nthey apply uniform processing to all behaviors. In contrast, the proposed\nbehavior-specific filtering method combines Wavelet Denoising with a Low Pass\nFilter, tailored to active and inactive pig behaviors, and achieved a peak\naccuracy of 94.73%. These results highlight the effectiveness of\nbehavior-specific filtering in enhancing animal behavior monitoring, supporting\nbetter health management and farm efficiency.", "comment": "11 pages, 4 tables, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.21021v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21536", "title": "Modern Uyghur Dependency Treebank (MUDT): An Integrated Morphosyntactic Framework for a Low-Resource Language", "authors": ["Jiaxin Zuo", "Yiquan Wang", "Yuan Pan", "Xiadiya Yibulayin"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21536v1", "summary": "To address a critical resource gap in Uyghur Natural Language Processing\n(NLP), this study introduces a dependency annotation framework designed to\novercome the limitations of existing treebanks for the low-resource,\nagglutinative language. This inventory includes 18 main relations and 26\nsubtypes, with specific labels such as cop:zero for verbless clauses and\ninstr:case=loc/dat for nuanced instrumental functions. To empirically validate\nthe necessity of this tailored approach, we conducted a cross-standard\nevaluation using a pre-trained Universal Dependencies parser. The analysis\nrevealed a systematic 47.9% divergence in annotations, pinpointing the\ninadequacy of universal schemes for handling Uyghur-specific structures.\nGrounded in nine annotation principles that ensure typological accuracy and\nsemantic transparency, the Modern Uyghur Dependency Treebank (MUDT) provides a\nmore accurate and semantically transparent representation, designed to enable\nsignificant improvements in parsing and downstream NLP tasks, and offers a\nreplicable model for other morphologically complex languages.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21536v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.21009", "title": "Memorization in Fine-Tuned Large Language Models", "authors": ["Danil Savine", "Muni Sreenivas Pydi", "Jamal Atif", "Olivier Cappé"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21009v1", "summary": "This study investigates the mechanisms and factors influencing memorization\nin fine-tuned large language models (LLMs), with a focus on the medical domain\ndue to its privacy-sensitive nature. We examine how different aspects of the\nfine-tuning process affect a model's propensity to memorize training data,\nusing the PHEE dataset of pharmacovigilance events.\n  Our research employs two main approaches: a membership inference attack to\ndetect memorized data, and a generation task with prompted prefixes to assess\nverbatim reproduction. We analyze the impact of adapting different weight\nmatrices in the transformer architecture, the relationship between perplexity\nand memorization, and the effect of increasing the rank in low-rank adaptation\n(LoRA) fine-tuning.\n  Key findings include: (1) Value and Output matrices contribute more\nsignificantly to memorization compared to Query and Key matrices; (2) Lower\nperplexity in the fine-tuned model correlates with increased memorization; (3)\nHigher LoRA ranks lead to increased memorization, but with diminishing returns\nat higher ranks.\n  These results provide insights into the trade-offs between model performance\nand privacy risks in fine-tuned LLMs. Our findings have implications for\ndeveloping more effective and responsible strategies for adapting large\nlanguage models while managing data privacy concerns.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21009v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21024", "title": "Optimization Performance of Factorization Machine with Annealing under Limited Training Data", "authors": ["Mayumi Nakano", "Yuya Seki", "Shuta Kikuchi", "Shu Tanaka"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 4 figures", "url": "http://arxiv.org/abs/2507.21024v1", "summary": "Black-box (BB) optimization problems aim to identify an input that minimizes\nthe output of a function (the BB function) whose input-output relationship is\nunknown. Factorization machine with annealing (FMA) is a promising approach to\nthis task, employing a factorization machine (FM) as a surrogate model to\niteratively guide the solution search via an Ising machine. Although FMA has\ndemonstrated strong optimization performance across various applications, its\nperformance often stagnates as the number of optimization iterations increases.\nOne contributing factor to this stagnation is the growing number of data points\nin the dataset used to train FM. It is hypothesized that as more data points\nare accumulated, the contribution of newly added data points becomes diluted\nwithin the entire dataset, thereby reducing their impact on improving the\nprediction accuracy of FM. To address this issue, we propose a novel method for\nsequential dataset construction that retains at most a specified number of the\nmost recently added data points. This strategy is designed to enhance the\ninfluence of newly added data points on the surrogate model. Numerical\nexperiments demonstrate that the proposed FMA achieves lower-cost solutions\nwith fewer BB function evaluations compared to the conventional FMA.", "comment": "9 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.21024v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21544", "title": "MAGIC: A Multi-Hop and Graph-Based Benchmark for Inter-Context Conflicts in Retrieval-Augmented Generation", "authors": ["Jungyeon Lee", "Kangmin Lee", "Taeuk Kim"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21544v1", "summary": "Knowledge conflict often arises in retrieval-augmented generation (RAG)\nsystems, where retrieved documents may be inconsistent with one another or\ncontradict the model's parametric knowledge. Existing benchmarks for\ninvestigating the phenomenon have notable limitations, including a narrow focus\non the question answering setup, heavy reliance on entity substitution\ntechniques, and a restricted range of conflict types. To address these issues,\nwe propose a knowledge graph (KG)-based framework that generates varied and\nsubtle conflicts between two similar yet distinct contexts, while ensuring\ninterpretability through the explicit relational structure of KGs. Experimental\nresults on our benchmark, MAGIC, provide intriguing insights into the inner\nworkings of LLMs regarding knowledge conflict: both open-source and proprietary\nmodels struggle with conflict detection -- especially when multi-hop reasoning\nis required -- and often fail to pinpoint the exact source of contradictions.\nFinally, we present in-depth analyses that serve as a foundation for improving\nLLMs in integrating diverse, sometimes even conflicting, information.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21544v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2310.01536", "title": "Algebras of actions in an agent's representations of the world", "authors": ["Alexander Dean", "Eduardo Alonso", "Esther Mondragon"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2310.01536v2", "summary": "In this paper, we propose a framework to extract the algebra of the\ntransformations of worlds from the perspective of an agent. As a starting\npoint, we use our framework to reproduce the symmetry-based representations\nfrom the symmetry-based disentangled representation learning (SBDRL) formalism\nproposed by [1]; only the algebra of transformations of worlds that form groups\ncan be described using symmetry-based representations. We then study the\nalgebras of the transformations of worlds with features that occur in simple\nreinforcement learning scenarios. Using computational methods, that we\ndeveloped, we extract the algebras of the transformations of these worlds and\nclassify them according to their properties. Finally, we generalise two\nimportant results of SBDRL - the equivariance condition and the disentangling\ndefinition - from only working with symmetry-based representations to working\nwith representations capturing the transformation properties of worlds with\ntransformations for any algebra. Finally, we combine our generalised\nequivariance condition and our generalised disentangling definition to show\nthat disentangled sub-algebras can each have their own individual equivariance\nconditions, which can be treated independently.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2310.01536v2", "cate": "cs.AI", "date": "2023-10-02", "updated": "2025-07-27"}
{"id": "2507.21037", "title": "When Brain Foundation Model Meets Cauchy-Schwarz Divergence: A New Framework for Cross-Subject Motor Imagery Decoding", "authors": ["Jinzhou Wu", "Baoping Tang", "Qikang Li", "Yi Wang", "Cheng Li", "Shujian Yu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.21037v1", "summary": "Decoding motor imagery (MI) electroencephalogram (EEG) signals, a key\nnon-invasive brain-computer interface (BCI) paradigm for controlling external\nsystems, has been significantly advanced by deep learning. However, MI-EEG\ndecoding remains challenging due to substantial inter-subject variability and\nlimited labeled target data, which necessitate costly calibration for new\nusers. Many existing multi-source domain adaptation (MSDA) methods\nindiscriminately incorporate all available source domains, disregarding the\nlarge inter-subject differences in EEG signals, which leads to negative\ntransfer and excessive computational costs. Moreover, while many approaches\nfocus on feature distribution alignment, they often neglect the explicit\ndependence between features and decision-level outputs, limiting their ability\nto preserve discriminative structures. To address these gaps, we propose a\nnovel MSDA framework that leverages a pretrained large Brain Foundation Model\n(BFM) for dynamic and informed source subject selection, ensuring only relevant\nsources contribute to adaptation. Furthermore, we employ Cauchy-Schwarz (CS)\nand Conditional CS (CCS) divergences to jointly perform feature-level and\ndecision-level alignment, enhancing domain invariance while maintaining class\ndiscriminability. Extensive evaluations on two benchmark MI-EEG datasets\ndemonstrate that our framework outperforms a broad range of state-of-the-art\nbaselines. Additional experiments with a large source pool validate the\nscalability and efficiency of BFM-guided selection, which significantly reduces\ntraining time without sacrificing performance.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.21037v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21556", "title": "Evaluating the cognitive reality of Spanish irregular morphomic patterns: Humans vs. Transformers", "authors": ["Akhilesh Kakolu Ramarao", "Kevin Tang", "Dinah Baer-Henney"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21556v1", "summary": "This study investigates the cognitive plausibility of the Spanish irregular\nmorphomic pattern by directly comparing transformer-based neural networks to\nhuman behavioral data from \\citet{Nevins2015TheRA}. Using the same analytical\nframework as the original human study, we evaluate whether transformer models\ncan replicate human-like sensitivity to a complex linguistic phenomena, the\nmorphome, under controlled input conditions. Our experiments focus on three\nfrequency conditions: natural, low-frequency, and high-frequency distributions\nof verbs exhibiting irregular morphomic patterns. While the models outperformed\nhumans in stem and suffix accuracy, a clear divergence emerged in response\npreferences. Unlike humans, who consistently favored natural responses across\nall test items, models' preferred irregular responses and were influenced by\nthe proportion of irregular verbs in their training data. Additionally, models\ntrained on the natural and low-frequency distributions, but not the\nhigh-frequency distribution, were sensitive to the phonological similarity\nbetween test items and real Spanish L-shaped verbs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21556v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2406.09529", "title": "Faithful Differentiable Reasoning with Reshuffled Region-based Embeddings", "authors": ["Aleksandar Pavlovic", "Emanuel Sallinger", "Steven Schockaert"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted for KR 2025", "url": "http://arxiv.org/abs/2406.09529v2", "summary": "Knowledge graph (KG) embedding methods learn geometric representations of\nentities and relations to predict plausible missing knowledge. These\nrepresentations are typically assumed to capture rule-like inference patterns.\nHowever, our theoretical understanding of which inference patterns can be\ncaptured remains limited. Ideally, KG embedding methods should be expressive\nenough such that for any set of rules, there exist relation embeddings that\nexactly capture these rules. This principle has been studied within the\nframework of region-based embeddings, but existing models are severely limited\nin the kinds of rule bases that can be captured. We argue that this stems from\nthe fact that entity embeddings are only compared in a coordinate-wise fashion.\nAs an alternative, we propose RESHUFFLE, a simple model based on ordering\nconstraints that can faithfully capture a much larger class of rule bases than\nexisting approaches. Most notably, RESHUFFLE can capture bounded inference\nw.r.t. arbitrary sets of closed path rules. The entity embeddings in our\nframework can be learned by a Graph Neural Network (GNN), which effectively\nacts as a differentiable rule base.", "comment": "Accepted for KR 2025", "pdf_url": "http://arxiv.org/pdf/2406.09529v2", "cate": "cs.AI", "date": "2024-06-13", "updated": "2025-07-26"}
{"id": "2507.21040", "title": "Transformers as Unrolled Inference in Probabilistic Laplacian Eigenmaps: An Interpretation and Potential Improvements", "authors": ["Aditya Ravuri", "Neil D. Lawrence"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Initial version", "url": "http://arxiv.org/abs/2507.21040v1", "summary": "We propose a probabilistic interpretation of transformers as unrolled\ninference steps assuming a probabilistic Laplacian Eigenmaps model from the\nProbDR framework. Our derivation shows that at initialisation, transformers\nperform \"linear\" dimensionality reduction. We also show that within the\ntransformer block, a graph Laplacian term arises from our arguments, rather\nthan an attention matrix (which we interpret as an adjacency matrix). We\ndemonstrate that simply subtracting the identity from the attention matrix (and\nthereby taking a graph diffusion step) improves validation performance on a\nlanguage model and a simple vision transformer.", "comment": "Initial version", "pdf_url": "http://arxiv.org/pdf/2507.21040v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21568", "title": "Multi-Hypothesis Distillation of Multilingual Neural Translation Models for Low-Resource Languages", "authors": ["Aarón Galiano-Jiménez", "Juan Antonio Pérez-Ortiz", "Felipe Sánchez-Martínez", "Víctor M. Sánchez-Cartagena"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      17 pages, 12 figures", "url": "http://arxiv.org/abs/2507.21568v1", "summary": "This paper explores sequence-level knowledge distillation (KD) of\nmultilingual pre-trained encoder-decoder translation models. We argue that the\nteacher model's output distribution holds valuable insights for the student,\nbeyond the approximated mode obtained through beam search (the standard\ndecoding method), and present Multi-Hypothesis Distillation (MHD), a\nsequence-level KD method that generates multiple translations for each source\nsentence. This provides a larger representation of the teacher model\ndistribution and exposes the student model to a wider range of target-side\nprefixes. We leverage $n$-best lists from beam search to guide the student's\nlearning and examine alternative decoding methods to address issues like low\nvariability and the under-representation of infrequent tokens. For low-resource\nlanguages, our research shows that while sampling methods may slightly\ncompromise translation quality compared to beam search based approaches, they\nenhance the generated corpora with greater variability and lexical richness.\nThis ultimately improves student model performance and mitigates the gender\nbias amplification often associated with KD.", "comment": "17 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.21568v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2406.14066", "title": "TurboSpec: Closed-loop Speculation Control System for Optimizing LLM Serving Goodput", "authors": ["Xiaoxuan Liu", "Jongseok Park", "Langxiang Hu", "Woosuk Kwon", "Zhuohan Li", "Chen Zhang", "Kuntai Du", "Xiangxi Mo", "Kaichao You", "Alvin Cheung", "Zhijie Deng", "Ion Stoica", "Hao Zhang"], "categories": ["cs.AI", "cs.PF"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.14066v3", "summary": "Large Language Model (LLM) serving systems batch concurrent user requests to\nachieve efficient serving. However, in real-world deployments, such\ninter-request parallelism from batching is often limited by external factors\nsuch as low request rates or memory constraints. Recent works focus on\nintra-request parallelism from speculative decoding as a solution to this\nproblem. Unfortunately, benefits from intra-request parallelism are often\nfragile, as speculative decoding causes overhead, and speculated tokens may\nmiss. We observe that speculative decoding may degrade LLM serving performance\nif added naively without tuning to the incoming requests and the speculation\nmethod. To alleviate the need for expert tuning and make speculative decoding\nmore robust, we present TurboSpec, a speculation control system that\nautomatically profiles the execution environment and utilizes a feedback-based\nalgorithm to dynamically adjust the amount of intra-request parallelism in LLM\nserving. TurboSpec predicts \"goodput\" - the amount of successfully generated\ntokens - to evaluate and adjust intra-request parallelism amount to that with\nthe highest goodput in runtime. We implement TurboSpec on a real-world LLM\nserving system vLLM and demonstrate its effectiveness across diverse workloads\nand hardware configurations, providing consistent performance improvements\nacross all test scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.14066v3", "cate": "cs.AI", "date": "2024-06-20", "updated": "2025-07-27"}
{"id": "2507.21049", "title": "Rep-MTL: Unleashing the Power of Representation-level Task Saliency for Multi-Task Learning", "authors": ["Zedong Wang", "Siyuan Li", "Dan Xu"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICCV 2025 (Highlight). Project page: this https URL", "url": "http://arxiv.org/abs/2507.21049v1", "summary": "Despite the promise of Multi-Task Learning in leveraging complementary\nknowledge across tasks, existing multi-task optimization (MTO) techniques\nremain fixated on resolving conflicts via optimizer-centric loss scaling and\ngradient manipulation strategies, yet fail to deliver consistent gains. In this\npaper, we argue that the shared representation space, where task interactions\nnaturally occur, offers rich information and potential for operations\ncomplementary to existing optimizers, especially for facilitating the\ninter-task complementarity, which is rarely explored in MTO. This intuition\nleads to Rep-MTL, which exploits the representation-level task saliency to\nquantify interactions between task-specific optimization and shared\nrepresentation learning. By steering these saliencies through entropy-based\npenalization and sample-wise cross-task alignment, Rep-MTL aims to mitigate\nnegative transfer by maintaining the effective training of individual tasks\ninstead pure conflict-solving, while explicitly promoting complementary\ninformation sharing. Experiments are conducted on four challenging MTL\nbenchmarks covering both task-shift and domain-shift scenarios. The results\nshow that Rep-MTL, even paired with the basic equal weighting policy, achieves\ncompetitive performance gains with favorable efficiency. Beyond standard\nperformance metrics, Power Law exponent analysis demonstrates Rep-MTL's\nefficacy in balancing task-specific learning and cross-task sharing. The\nproject page is available at HERE.", "comment": "ICCV 2025 (Highlight). Project page:\n  https://jacky1128.github.io/RepMTL/", "pdf_url": "http://arxiv.org/pdf/2507.21049v1", "cate": "cs.LG", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21609", "title": "Multilingual JobBERT for Cross-Lingual Job Title Matching", "authors": ["Jens-Joris Decorte", "Matthias De Lange", "Jeroen Van Hautte"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to the TalentCLEF 2025 Workshop as part of CLEF 2025", "url": "http://arxiv.org/abs/2507.21609v1", "summary": "We introduce JobBERT-V3, a contrastive learning-based model for cross-lingual\njob title matching. Building on the state-of-the-art monolingual JobBERT-V2,\nour approach extends support to English, German, Spanish, and Chinese by\nleveraging synthetic translations and a balanced multilingual dataset of over\n21 million job titles. The model retains the efficiency-focused architecture of\nits predecessor while enabling robust alignment across languages without\nrequiring task-specific supervision. Extensive evaluations on the TalentCLEF\n2025 benchmark demonstrate that JobBERT-V3 outperforms strong multilingual\nbaselines and achieves consistent performance across both monolingual and\ncross-lingual settings. While not the primary focus, we also show that the\nmodel can be effectively used to rank relevant skills for a given job title,\ndemonstrating its broader applicability in multilingual labor market\nintelligence. The model is publicly available:\nhttps://huggingface.co/TechWolf/JobBERT-v3.", "comment": "Accepted to the TalentCLEF 2025 Workshop as part of CLEF 2025", "pdf_url": "http://arxiv.org/pdf/2507.21609v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2406.14917", "title": "LLM2TEA: An Agentic AI Designer for Discovery with Generative Evolutionary Multitasking", "authors": ["Melvin Wong", "Jiao Liu", "Thiago Rios", "Stefan Menzel", "Yew Soon Ong"], "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.NE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      This work is accepted by IEEE CIM. IEEE copyrights applies", "url": "http://arxiv.org/abs/2406.14917v3", "summary": "This paper presents LLM2TEA, a Large Language Model (LLM) driven MultiTask\nEvolutionary Algorithm, representing the first agentic AI designer of its kind\noperating with generative evolutionary multitasking (GEM). LLM2TEA enables the\ncrossbreeding of solutions from multiple domains, fostering novel solutions\nthat transcend disciplinary boundaries. Of particular interest is the ability\nto discover designs that are both novel and conforming to real-world physical\nspecifications. LLM2TEA comprises an LLM to generate genotype samples from text\nprompts describing target objects, a text-to-3D generative model to produce\ncorresponding phenotypes, a classifier to interpret its semantic\nrepresentations, and a computational simulator to assess its physical\nproperties. Novel LLM-based multitask evolutionary operators are introduced to\nguide the search towards high-performing, practically viable designs.\nExperimental results in conceptual design optimization validate the\neffectiveness of LLM2TEA, showing 97% to 174% improvements in the diversity of\nnovel designs over the current text-to-3D baseline. Moreover, over 73% of the\ngenerated designs outperform the top 1% of designs produced by the text-to-3D\nbaseline in terms of physical performance. The designs produced by LLM2TEA are\nnot only aesthetically creative but also functional in real-world contexts.\nSeveral of these designs have been successfully 3D printed, demonstrating the\nability of our approach to transform AI-generated outputs into tangible,\nphysical designs. These designs underscore the potential of LLM2TEA as a\npowerful tool for complex design optimization and discovery, capable of\nproducing novel and physically viable designs.", "comment": "This work is accepted by IEEE CIM. IEEE copyrights applies", "pdf_url": "http://arxiv.org/pdf/2406.14917v3", "cate": "cs.AI", "date": "2024-06-21", "updated": "2025-07-28"}
{"id": "2507.19511", "title": "Advancing Mental Disorder Detection: A Comparative Evaluation of Transformer and LSTM Architectures on Social Media", "authors": ["Khalid Hasan", "Jamil Saquer", "Mukulika Ghosh"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      The 49th IEEE International Conference on Computers, Software, and Applications (COMPSAC 2025) (camera-ready)", "url": "http://arxiv.org/abs/2507.19511v1", "summary": "The rising prevalence of mental health disorders necessitates the development\nof robust, automated tools for early detection and monitoring. Recent advances\nin Natural Language Processing (NLP), particularly transformer-based\narchitectures, have demonstrated significant potential in text analysis. This\nstudy provides a comprehensive evaluation of state-of-the-art transformer\nmodels (BERT, RoBERTa, DistilBERT, ALBERT, and ELECTRA) against Long Short-Term\nMemory (LSTM) based approaches using different text embedding techniques for\nmental health disorder classification on Reddit. We construct a large annotated\ndataset, validating its reliability through statistical judgmental analysis and\ntopic modeling. Experimental results demonstrate the superior performance of\ntransformer models over traditional deep-learning approaches. RoBERTa achieved\nthe highest classification performance, with a 99.54% F1 score on the hold-out\ntest set and a 96.05% F1 score on the external test set. Notably, LSTM models\naugmented with BERT embeddings proved highly competitive, achieving F1 scores\nexceeding 94% on the external dataset while requiring significantly fewer\ncomputational resources. These findings highlight the effectiveness of\ntransformer-based models for real-time, scalable mental health monitoring. We\ndiscuss the implications for clinical applications and digital mental health\ninterventions, offering insights into the capabilities and limitations of\nstate-of-the-art NLP methodologies in mental disorder detection.", "comment": "The 49th IEEE International Conference on Computers, Software, and\n  Applications (COMPSAC 2025) (camera-ready)", "pdf_url": "http://arxiv.org/pdf/2507.19511v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17"}
{"id": "2507.21645", "title": "Libra: Assessing and Improving Reward Model by Learning to Think", "authors": ["Meng Zhou", "Bei Li", "Jiahao Liu", "Xiaowen Shi", "Yang Bai", "Rongxiang Weng", "Jingang Wang", "Xunliang Cai"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Work In Progress", "url": "http://arxiv.org/abs/2507.21645v1", "summary": "Reinforcement learning (RL) has significantly improved the reasoning ability\nof large language models. However, current reward models underperform in\nchallenging reasoning scenarios and predominant RL training paradigms rely on\nrule-based or reference-based rewards, which impose two critical limitations:\n1) the dependence on finely annotated reference answer to attain rewards; and\n2) the requirement for constrained output format. These limitations\nfundamentally hinder further RL data scaling and sustained enhancement of model\nreasoning performance. To address these limitations, we propose a comprehensive\nframework for evaluating and improving the performance of reward models in\ncomplex reasoning scenarios. We first present a reasoning-oriented benchmark\n(Libra Bench), systematically constructed from a diverse collection of\nchallenging mathematical problems and advanced reasoning models, to address the\nlimitations of existing reward model benchmarks in reasoning scenarios. We\nfurther introduce a novel approach for improving the generative reward model\nvia learning-to-think methodologies. Based on the proposed approach, we develop\nLibra-RM series, a collection of generative reward models with reasoning\ncapabilities that achieve state-of-the-art results on various benchmarks.\nComprehensive downstream experiments are conducted and the experimental results\ndemonstrate the correlation between our Libra Bench and downstream application,\nand the potential of Libra-RM to further improve reasoning models with\nunlabeled data.", "comment": "Work In Progress", "pdf_url": "http://arxiv.org/pdf/2507.21645v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2503.03361", "title": "From Infants to AI: Incorporating Infant-like Learning in Models Boosts Efficiency and Generalization in Learning Social Prediction Tasks", "authors": ["Shify Treger", "Shimon Ullman"], "categories": ["cs.AI", "cs.NE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.03361v2", "summary": "Early in development, infants learn a range of useful concepts, which can be\nchallenging from a computational standpoint. This early learning comes together\nwith an initial understanding of aspects of the meaning of concepts, e.g.,\ntheir implications, causality, and using them to predict likely future events.\nAll this is accomplished in many cases with little or no supervision, and from\nrelatively few examples, compared with current network models. In learning\nabout objects and human-object interactions, early acquired and possibly innate\nconcepts are often used in the process of learning additional, more complex\nconcepts. In the current work, we model how early-acquired concepts are used in\nthe learning of subsequent concepts, and compare the results with standard deep\nnetwork modeling. We focused in particular on the use of the concepts of\nanimacy and goal attribution in learning to predict future events. We show that\nthe use of early concepts in the learning of new concepts leads to better\nlearning (higher accuracy) and more efficient learning (requiring less data).\nWe further show that this integration of early and new concepts shapes the\nrepresentation of the concepts acquired by the model. The results show that\nwhen the concepts were learned in a human-like manner, the emerging\nrepresentation was more useful, as measured in terms of generalization to novel\ndata and tasks. On a more general level, the results suggest that there are\nlikely to be basic differences in the conceptual structures acquired by current\nnetwork models compared to human learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.03361v2", "cate": "cs.AI", "date": "2025-03-05", "updated": "2025-07-27"}
{"id": "2507.19521", "title": "Setting The Table with Intent: Intent-aware Schema Generation and Editing for Literature Review Tables", "authors": ["Vishakh Padmakumar", "Joseph Chee Chang", "Kyle Lo", "Doug Downey", "Aakanksha Naik"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19521v1", "summary": "The increasing volume of academic literature makes it essential for\nresearchers to organize, compare, and contrast collections of documents. Large\nlanguage models (LLMs) can support this process by generating schemas defining\nshared aspects along which to compare papers. However, progress on schema\ngeneration has been slow due to: (i) ambiguity in reference-based evaluations,\nand (ii) lack of editing/refinement methods. Our work is the first to address\nboth issues. First, we present an approach for augmenting unannotated table\ncorpora with synthesized intents and apply it to create a dataset for studying\nschema generation conditioned on a given information need, thus reducing\nambiguity. With this dataset, we show how incorporating table intents\nsignificantly improves baseline performance in reconstructing reference\nschemas. Next, we propose several LLM-based schema editing techniques. We start\nby comprehensively benchmarking several single-shot schema generation methods,\nincluding prompted LLM workflows and fine-tuned models, showing that smaller,\nopen-weight models can be fine-tuned to be competitive with state-of-the-art\nprompted LLMs. Then we demonstrate that our editing techniques can further\nimprove schemas generated by these methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19521v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18"}
{"id": "2507.21652", "title": "UnsafeChain: Enhancing Reasoning Model Safety via Hard Cases", "authors": ["Raj Vardhan Tomar", "Preslav Nakov", "Yuxia Wang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21652v1", "summary": "As large reasoning models (LRMs) grow more capable, chain-of-thought (CoT)\nreasoning introduces new safety challenges. Existing SFT-based safety alignment\nstudies dominantly focused on filtering prompts with safe, high-quality\nresponses, while overlooking hard prompts that always elicit harmful outputs.\nTo fill this gap, we introduce UnsafeChain, a safety alignment dataset\nconstructed from hard prompts with diverse sources, where unsafe completions\nare identified and explicitly corrected into safe responses. By exposing models\nto unsafe behaviors and guiding their correction, UnsafeChain enhances safety\nwhile preserving general reasoning ability. We fine-tune three LRMs on\nUnsafeChain and compare them against recent SafeChain and STAR-1 across six\nout-of-distribution and five in-distribution benchmarks. UnsafeChain\nconsistently outperforms prior datasets, with even a 1K subset matching or\nsurpassing baseline performance, demonstrating the effectiveness and\ngeneralizability of correction-based supervision. We release our dataset and\ncode at https://github.com/mbzuai-nlp/UnsafeChain", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21652v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2504.02193", "title": "More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment", "authors": ["Yifan Wang", "Runjin Chen", "Bolian Li", "David Cho", "Yihe Deng", "Ruqi Zhang", "Tianlong Chen", "Zhangyang Wang", "Ananth Grama", "Junyuan Hong"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      This version includes updated results and expanded discussion", "url": "http://arxiv.org/abs/2504.02193v3", "summary": "Aligning large language models (LLMs) with human values is an increasingly\ncritical step in post-training. Direct Preference Optimization (DPO) has\nemerged as a simple, yet effective alternative to reinforcement learning from\nhuman feedback (RLHF). Synthetic preference data with its low cost and high\nquality enable effective alignment through single- or multi-model generated\npreference data. Our study reveals a striking, safety-specific phenomenon\nassociated with DPO alignment: Although multi-model generated data enhances\nperformance on general tasks (ARC, Hellaswag, MMLU, TruthfulQA, Winogrande) by\nproviding diverse responses, it also tends to facilitate reward hacking during\ntraining. This can lead to a high attack success rate (ASR) when models\nencounter jailbreaking prompts. The issue is particularly pronounced when\nemploying stronger models like GPT-4o or larger models in the same family to\ngenerate chosen responses paired with target model self-generated rejected\nresponses, resulting in dramatically poorer safety outcomes. Furthermore, with\nrespect to safety, using solely self-generated responses (single-model\ngeneration) for both chosen and rejected pairs significantly outperforms\nconfigurations that incorporate responses from stronger models, whether used\ndirectly as chosen data or as part of a multi-model response pool. We\ndemonstrate that multi-model preference data exhibits high linear separability\nbetween chosen and rejected responses, which allows models to exploit\nsuperficial cues rather than internalizing robust safety constraints. Our\nexperiments, conducted on models from the Llama, Mistral, and Qwen families,\nconsistently validate these findings.", "comment": "This version includes updated results and expanded discussion", "pdf_url": "http://arxiv.org/pdf/2504.02193v3", "cate": "cs.AI", "date": "2025-04-03", "updated": "2025-07-28"}
{"id": "2507.19540", "title": "Bayesian symbolic regression: Automated equation discovery from a physicists' perspective", "authors": ["Roger Guimera", "Marta Sales-Pardo"], "categories": ["stat.ML", "cond-mat.stat-mech", "cs.LG", "physics.data-an"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19540v1", "summary": "Symbolic regression automates the process of learning closed-form\nmathematical models from data. Standard approaches to symbolic regression, as\nwell as newer deep learning approaches, rely on heuristic model selection\ncriteria, heuristic regularization, and heuristic exploration of model space.\nHere, we discuss the probabilistic approach to symbolic regression, an\nalternative to such heuristic approaches with direct connections to information\ntheory and statistical physics. We show how the probabilistic approach\nestablishes model plausibility from basic considerations and explicit\napproximations, and how it provides guarantees of performance that heuristic\napproaches lack. We also discuss how the probabilistic approach compels us to\nconsider model ensembles, as opposed to single models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19540v1", "cate": "stat.ML", "date": "2025-07-22", "updated": "2025-07-22"}
{"id": "2507.21750", "title": "Adversarial Defence without Adversarial Defence: Enhancing Language Model Robustness via Instance-level Principal Component Removal", "authors": ["Yang Wang", "Chenghao Xiao", "Yizhi Li", "Stuart E. Middleton", "Noura Al Moubayed", "Chenghua Lin"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This paper was accepted with an A-decision to Transactions of the Association for Computational Linguistics. This version is the pre-publication version prior to MIT Press production", "url": "http://arxiv.org/abs/2507.21750v1", "summary": "Pre-trained language models (PLMs) have driven substantial progress in\nnatural language processing but remain vulnerable to adversarial attacks,\nraising concerns about their robustness in real-world applications. Previous\nstudies have sought to mitigate the impact of adversarial attacks by\nintroducing adversarial perturbations into the training process, either\nimplicitly or explicitly. While both strategies enhance robustness, they often\nincur high computational costs. In this work, we propose a simple yet effective\nadd-on module that enhances the adversarial robustness of PLMs by removing\ninstance-level principal components, without relying on conventional\nadversarial defences or perturbing the original training data. Our approach\ntransforms the embedding space to approximate Gaussian properties, thereby\nreducing its susceptibility to adversarial perturbations while preserving\nsemantic relationships. This transformation aligns embedding distributions in a\nway that minimises the impact of adversarial noise on decision boundaries,\nenhancing robustness without requiring adversarial examples or costly\ntraining-time augmentation. Evaluations on eight benchmark datasets show that\nour approach improves adversarial robustness while maintaining comparable\nbefore-attack accuracy to baselines, achieving a balanced trade-off between\nrobustness and generalisation.", "comment": "This paper was accepted with an A-decision to Transactions of the\n  Association for Computational Linguistics. This version is the\n  pre-publication version prior to MIT Press production", "pdf_url": "http://arxiv.org/pdf/2507.21750v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2504.18039", "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "authors": ["Zheng Zhang", "Nuoqian Xiao", "Qi Chai", "Deheng Ye", "Hao Wang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by ACMMM 2025", "url": "http://arxiv.org/abs/2504.18039v3", "summary": "Large Language Model (LLM) agents have demonstrated impressive capabilities\nin social deduction games (SDGs) like Werewolf, where strategic reasoning and\nsocial deception are essential. However, current approaches remain limited to\ntextual information, ignoring crucial multimodal cues such as facial\nexpressions and tone of voice that humans naturally use to communicate.\nMoreover, existing SDG agents primarily focus on inferring other players'\nidentities without modeling how others perceive themselves or fellow players.\nTo address these limitations, we use One Night Ultimate Werewolf (ONUW) as a\ntestbed and present MultiMind, the first framework integrating multimodal\ninformation into SDG agents. MultiMind processes facial expressions and vocal\ntones alongside verbal content, while employing a Theory of Mind (ToM) model to\nrepresent each player's suspicion levels toward others. By combining this ToM\nmodel with Monte Carlo Tree Search (MCTS), our agent identifies communication\nstrategies that minimize suspicion directed at itself. Through comprehensive\nevaluation in both agent-versus-agent simulations and studies with human\nplayers, we demonstrate MultiMind's superior performance in gameplay. Our work\npresents a significant advancement toward LLM agents capable of human-like\nsocial reasoning across multimodal domains.", "comment": "Accepted by ACMMM 2025", "pdf_url": "http://arxiv.org/pdf/2504.18039v3", "cate": "cs.AI", "date": "2025-04-25", "updated": "2025-07-28"}
{"id": "2507.19565", "title": "Review of Deep Learning Applications to Structural Proteomics Enabled by Cryogenic Electron Microscopy and Tomography", "authors": ["Brady K. Zhou", "Jason J. Hu", "Jane K. J. Lee", "Z. Hong Zhou", "Demetri Terzopoulos"], "categories": ["q-bio.QM", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "Comments:      16 pages", "url": "http://arxiv.org/abs/2507.19565v1", "summary": "The past decade's \"cryoEM revolution\" has produced exponential growth in\nhigh-resolution structural data through advances in cryogenic electron\nmicroscopy (cryoEM) and tomography (cryoET). Deep learning integration into\nstructural proteomics workflows addresses longstanding challenges including low\nsignal-to-noise ratios, preferred orientation artifacts, and missing-wedge\nproblems that historically limited efficiency and scalability. This review\nexamines AI applications across the entire cryoEM pipeline, from automated\nparticle picking using convolutional neural networks (Topaz, crYOLO,\nCryoSegNet) to computational solutions for preferred orientation bias\n(spIsoNet, cryoPROS) and advanced denoising algorithms (Topaz-Denoise). In\ncryoET, tools like IsoNet employ U-Net architectures for simultaneous\nmissing-wedge correction and noise reduction, while TomoNet streamlines\nsubtomogram averaging through AI-driven particle detection. The workflow\nculminates with automated atomic model building using sophisticated tools like\nModelAngelo, DeepTracer, and CryoREAD that translate density maps into\ninterpretable biological structures. These AI-enhanced approaches have achieved\nnear-atomic resolution reconstructions with minimal manual intervention,\nresolved previously intractable datasets suffering from severe orientation\nbias, and enabled successful application to diverse biological systems from HIV\nvirus-like particles to in situ ribosomal complexes. As deep learning evolves,\nparticularly with large language models and vision transformers, the future\npromises sophisticated automation and accessibility in structural biology,\npotentially revolutionizing our understanding of macromolecular architecture\nand function.", "comment": "16 pages", "pdf_url": "http://arxiv.org/pdf/2507.19565v1", "cate": "q-bio.QM", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.21773", "title": "AgriEval: A Comprehensive Chinese Agricultural Benchmark for Large Language Models", "authors": ["Lian Yan", "Haotian Wang", "Chen Tang", "Haifeng Liu", "Tianyang Sun", "Liangliang Liu", "Yi Guan", "Jingchi Jiang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      36 pages, 22 figures", "url": "http://arxiv.org/abs/2507.21773v1", "summary": "In the agricultural domain, the deployment of large language models (LLMs) is\nhindered by the lack of training data and evaluation benchmarks. To mitigate\nthis issue, we propose AgriEval, the first comprehensive Chinese agricultural\nbenchmark with three main characteristics: (1) Comprehensive Capability\nEvaluation. AgriEval covers six major agriculture categories and 29\nsubcategories within agriculture, addressing four core cognitive scenarios:\nmemorization, understanding, inference, and generation. (2) High-Quality Data.\nThe dataset is curated from university-level examinations and assignments,\nproviding a natural and robust benchmark for assessing the capacity of LLMs to\napply knowledge and make expert-like decisions. (3) Diverse Formats and\nExtensive Scale. AgriEval comprises 14,697 multiple-choice questions and 2,167\nopen-ended question-and-answer questions, establishing it as the most extensive\nagricultural benchmark available to date. We also present comprehensive\nexperimental results over 51 open-source and commercial LLMs. The experimental\nresults reveal that most existing LLMs struggle to achieve 60% accuracy,\nunderscoring the developmental potential in agricultural LLMs. Additionally, we\nconduct extensive experiments to investigate factors influencing model\nperformance and propose strategies for enhancement. AgriEval is available at\nhttps://github.com/YanPioneer/AgriEval/.", "comment": "36 pages, 22 figures", "pdf_url": "http://arxiv.org/pdf/2507.21773v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2505.02820", "title": "AutoLibra: Agent Metric Induction from Open-Ended Feedback", "authors": ["Hao Zhu", "Phil Cuvin", "Xinkai Yu", "Charlotte Ka Yee Yan", "Jason Zhang", "Diyi Yang"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:       this https URL", "url": "http://arxiv.org/abs/2505.02820v2", "summary": "Agents are predominantly evaluated and optimized via task success metrics,\nwhich are coarse, rely on manual design from experts, and fail to reward\nintermediate emergent behaviors. We propose AutoLibra, a framework for agent\nevaluation, that transforms open-ended human feedback e.g. \"If you find that\nthe button is disabled, don't click it again\", or \"This agent has too much\nautonomy to decide what to do on its own\" into metrics for evaluating\nfine-grained behaviors in agent trajectories. AutoLibra accomplishes this by\ngrounding feedback to an agent's behavior, clustering similar positive and\nnegative behaviors, and creating concrete metrics with clear definitions and\nconcrete examples, which can be used for prompting LLM-as-a-Judge as\nevaluators. We further propose two meta-metrics to evaluate the alignment of a\nset of (induced) metrics with open feedback: \"coverage\" and \"redundancy\".\nThrough optimizing these meta-metrics, we experimentally demonstrate\nAutoLibra's ability to induce more concrete agent evaluation metrics than the\nones proposed in previous agent evaluation benchmarks and discover new metrics\nto analyze agents. We also present two applications of AutoLibra in agent\nimprovement: First, we show that AutoLibra-induced metrics serve as better\nprompt-engineering targets than the task success rate on a wide range of text\ngame tasks, improving agent performance over baseline by a mean of 20%. Second,\nwe show that AutoLibra can iteratively select high-quality fine-tuning data for\nweb navigation agents. Our results suggest that AutoLibra is a powerful\ntask-agnostic tool for evaluating and improving language agents.", "comment": "https://opensocial.world/", "pdf_url": "http://arxiv.org/pdf/2505.02820v2", "cate": "cs.AI", "date": "2025-05-05", "updated": "2025-07-28"}
{"id": "2507.19575", "title": "Is Exchangeability better than I.I.D to handle Data Distribution Shifts while Pooling Data for Data-scarce Medical image segmentation?", "authors": ["Ayush Roy", "Samin Enam", "Jun Xia", "Vishnu Suresh Lokhande", "Won Hwa Kim"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19575v1", "summary": "Data scarcity is a major challenge in medical imaging, particularly for deep\nlearning models. While data pooling (combining datasets from multiple sources)\nand data addition (adding more data from a new dataset) have been shown to\nenhance model performance, they are not without complications. Specifically,\nincreasing the size of the training dataset through pooling or addition can\ninduce distributional shifts, negatively affecting downstream model\nperformance, a phenomenon known as the \"Data Addition Dilemma\". While the\ntraditional i.i.d. assumption may not hold in multi-source contexts, assuming\nexchangeability across datasets provides a more practical framework for data\npooling. In this work, we investigate medical image segmentation under these\nconditions, drawing insights from causal frameworks to propose a method for\ncontrolling foreground-background feature discrepancies across all layers of\ndeep networks. This approach improves feature representations, which are\ncrucial in data-addition scenarios. Our method achieves state-of-the-art\nsegmentation performance on histopathology and ultrasound images across five\ndatasets, including a novel ultrasound dataset that we have curated and\ncontributed. Qualitative results demonstrate more refined and accurate\nsegmentation maps compared to prominent baselines across three model\narchitectures. The code will be available on Github.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19575v1", "cate": "cs.CV", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.21782", "title": "The Problem with Safety Classification is not just the Models", "authors": ["Sowmya Vajjala"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Pre-print, Short paper", "url": "http://arxiv.org/abs/2507.21782v1", "summary": "Studying the robustness of Large Language Models (LLMs) to unsafe behaviors\nis an important topic of research today. Building safety classification models\nor guard models, which are fine-tuned models for input/output safety\nclassification for LLMs, is seen as one of the solutions to address the issue.\nAlthough there is a lot of research on the safety testing of LLMs themselves,\nthere is little research on evaluating the effectiveness of such safety\nclassifiers or the evaluation datasets used for testing them, especially in\nmultilingual scenarios. In this position paper, we demonstrate how multilingual\ndisparities exist in 5 safety classification models by considering datasets\ncovering 18 languages. At the same time, we identify potential issues with the\nevaluation datasets, arguing that the shortcomings of current safety\nclassifiers are not only because of the models themselves. We expect that these\nfindings will contribute to the discussion on developing better methods to\nidentify harmful content in LLM inputs across languages.", "comment": "Pre-print, Short paper", "pdf_url": "http://arxiv.org/pdf/2507.21782v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2505.08021", "title": "The Correspondence Between Bounded Graph Neural Networks and Fragments of First-Order Logic", "authors": ["Bernardo Cuenca Grau", "Eva Feng", "Przemysław A. Wałęga"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      21 pages", "url": "http://arxiv.org/abs/2505.08021v2", "summary": "Graph Neural Networks (GNNs) address two key challenges in applying deep\nlearning to graph-structured data: they handle varying size input graphs and\nensure invariance under graph isomorphism. While GNNs have demonstrated broad\napplicability, understanding their expressive power remains an important\nquestion. In this paper, we propose GNN architectures that correspond precisely\nto prominent fragments of first-order logic (FO), including various modal\nlogics as well as more expressive two-variable fragments. To establish these\nresults, we apply methods from finite model theory of first-order and modal\nlogics to the domain of graph representation learning. Our results provide a\nunifying framework for understanding the logical expressiveness of GNNs within\nFO.", "comment": "21 pages", "pdf_url": "http://arxiv.org/pdf/2505.08021v2", "cate": "cs.AI", "date": "2025-05-12", "updated": "2025-07-26"}
{"id": "2507.19611", "title": "State evolution beyond first-order methods I: Rigorous predictions and finite-sample guarantees", "authors": ["Michael Celentano", "Chen Cheng", "Ashwin Pananjady", "Kabir Aladin Verchand"], "categories": ["math.ST", "cs.LG", "math.OC", "stat.ML", "stat.TH"], "primary_category": "Subjects:       Statistics Theory (math.ST)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19611v1", "summary": "We develop a toolbox for exact analysis of iterative algorithms on a class of\nhigh-dimensional nonconvex optimization problems with random data. While prior\nwork has shown that low-dimensional statistics of (generalized) first-order\nmethods can be predicted by a deterministic recursion known as state evolution,\nour focus is on developing such a prediction for a more general class of\nalgorithms. We provide a state evolution for any method whose iterations are\ngiven by (possibly interleaved) first-order and saddle point updates, showing\ntwo main results. First, we establish a rigorous state evolution prediction\nthat holds even when the updates are not coordinate-wise separable. Second, we\nestablish finite-sample guarantees bounding the deviation of the empirical\nupdates from the established state evolution. In the process, we develop a\ntechnical toolkit that may prove useful in related problems. One component of\nthis toolkit is a general Hilbert space lifting technique to prove existence\nand uniqueness of a convenient parameterization of the state evolution. Another\ncomponent of the toolkit combines a generic application of Bolthausen's\nconditioning method with a sequential variant of Gordon's Gaussian comparison\ninequality, and provides additional ingredients that enable a general\nfinite-sample analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19611v1", "cate": "math.ST", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.21810", "title": "ChartMark: A Structured Grammar for Chart Annotation", "authors": ["Yiyu Chen", "Yifan Wu", "Shuyu Shen", "Yupeng Xie", "Leixian Shen", "Hui Xiong", "Yuyu Luo"], "categories": ["cs.CL", "cs.SE"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      IEEE VIS 2025", "url": "http://arxiv.org/abs/2507.21810v1", "summary": "Chart annotations enhance visualization accessibility but suffer from\nfragmented, non-standardized representations that limit cross-platform reuse.\nWe propose ChartMark, a structured grammar that separates annotation semantics\nfrom visualization implementations. ChartMark features a hierarchical framework\nmapping onto annotation dimensions (e.g., task, chart context), supporting both\nabstract intents and precise visual details. Our toolkit demonstrates\nconverting ChartMark specifications into Vega-Lite visualizations, highlighting\nits flexibility, expressiveness, and practical applicability.", "comment": "IEEE VIS 2025", "pdf_url": "http://arxiv.org/pdf/2507.21810v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2505.08151", "title": "Foundation Models Knowledge Distillation For Battery Capacity Degradation Forecast", "authors": ["Joey Chan", "Zhen Chen", "Ershun Pan"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.08151v3", "summary": "Accurate estimation of lithium-ion battery capacity degradation is critical\nfor enhancing the reliability and safety of battery operations. Traditional\nexpert models, tailored to specific scenarios, provide isolated estimations.\nWith the rapid advancement of data-driven techniques, a series of\ngeneral-purpose time-series foundation models have been developed. However,\nfoundation models specifically designed for battery capacity degradation remain\nlargely unexplored. To enable zero-shot generalization in battery degradation\nprediction using large model technology, this study proposes a\ndegradation-aware fine-tuning strategy for time-series foundation models. We\napply this strategy to fine-tune the Timer model on approximately 10 GB of\nopen-source battery charge discharge data. Validation on our released\nCycleLife-SJTUIE dataset demonstrates that the fine-tuned Battery-Timer\npossesses strong zero-shot generalization capability in capacity degradation\nforecasting. To address the computational challenges of deploying large models,\nwe further propose a knowledge distillation framework that transfers the\nknowledge of pre-trained foundation models into compact expert models.\nDistillation results across several state-of-the-art time-series expert models\nconfirm that foundation model knowledge significantly improves the\nmulti-condition generalization of expert models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.08151v3", "cate": "cs.AI", "date": "2025-05-13", "updated": "2025-07-27"}
{"id": "2507.19663", "title": "Adaptive Bayesian Data-Driven Design of Reliable Solder Joints for Micro-electronic Devices", "authors": ["Leo Guo", "Adwait Inamdar", "Willem D. van Driel", "GuoQi Zhang"], "categories": ["stat.ML", "cs.LG", "physics.comp-ph"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      data-driven design, adaptive hyperparameters, Bayesian optimization, solder joint reliability, micro-electronics", "url": "http://arxiv.org/abs/2507.19663v1", "summary": "Solder joint reliability related to failures due to thermomechanical loading\nis a critically important yet physically complex engineering problem. As a\nresult, simulated behavior is oftentimes computationally expensive. In an\nincreasingly data-driven world, the usage of efficient data-driven design\nschemes is a popular choice. Among them, Bayesian optimization (BO) with\nGaussian process regression is one of the most important representatives. The\nauthors argue that computational savings can be obtained from exploiting\nthorough surrogate modeling and selecting a design candidate based on multiple\nacquisition functions. This is feasible due to the relatively low computational\ncost, compared to the expensive simulation objective. This paper addresses the\nshortcomings in the adjacent literature by providing and implementing a novel\nheuristic framework to perform BO with adaptive hyperparameters across the\nvarious optimization iterations. Adaptive BO is subsequently compared to\nregular BO when faced with synthetic objective minimization problems. The\nresults show the efficiency of adaptive BO when compared any worst-performing\nregular Bayesian schemes. As an engineering use case, the solder joint\nreliability problem is tackled by minimizing the accumulated non-linear creep\nstrain under a cyclic thermal load. Results show that adaptive BO outperforms\nregular BO by 3% on average at any given computational budget threshold,\ncritically saving half of the computational expense budget. This practical\nresult underlines the methodological potential of the adaptive Bayesian\ndata-driven methodology to achieve better results and cut optimization-related\nexpenses. Lastly, in order to promote the reproducibility of the results, the\ndata-driven implementations are made available on an open-source basis.", "comment": "data-driven design, adaptive hyperparameters, Bayesian optimization,\n  solder joint reliability, micro-electronics", "pdf_url": "http://arxiv.org/pdf/2507.19663v1", "cate": "stat.ML", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.21813", "title": "Overview of ADoBo at IberLEF 2025: Automatic Detection of Anglicisms in Spanish", "authors": ["Elena Alvarez-Mellado", "Jordi Porta-Zamorano", "Constantine Lignos", "Julio Gonzalo"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted in the journal Procesamiento del Lenguaje Natural 75", "url": "http://arxiv.org/abs/2507.21813v1", "summary": "This paper summarizes the main findings of ADoBo 2025, the shared task on\nanglicism identification in Spanish proposed in the context of IberLEF 2025.\nParticipants of ADoBo 2025 were asked to detect English lexical borrowings (or\nanglicisms) from a collection of Spanish journalistic texts. Five teams\nsubmitted their solutions for the test phase. Proposed systems included LLMs,\ndeep learning models, Transformer-based models and rule-based systems. The\nresults range from F1 scores of 0.17 to 0.99, which showcases the variability\nin performance different systems can have for this task.", "comment": "Accepted in the journal Procesamiento del Lenguaje Natural 75", "pdf_url": "http://arxiv.org/pdf/2507.21813v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2505.13940", "title": "DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery", "authors": ["Kun Li", "Zhennan Wu", "Shoupeng Wang", "Jia Wu", "Shirui Pan", "Wenbin Hu"], "categories": ["cs.AI", "q-bio.BM"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      29 pages, 8 figures, 2 tables", "url": "http://arxiv.org/abs/2505.13940v2", "summary": "Large language models (LLMs) integrated with autonomous agents hold\nsignificant potential for advancing scientific discovery through automated\nreasoning and task execution. However, applying LLM agents to drug discovery is\nstill constrained by challenges such as large-scale multimodal data processing,\nlimited task automation, and poor support for domain-specific tools. To\novercome these limitations, we introduce DrugPilot, a LLM-based agent system\nwith a parameterized reasoning architecture designed for end-to-end scientific\nworkflows in drug discovery. DrugPilot enables multi-stage research processes\nby integrating structured tool use with a novel parameterized memory pool. The\nmemory pool converts heterogeneous data from both public sources and\nuser-defined inputs into standardized representations. This design supports\nefficient multi-turn dialogue, reduces information loss during data exchange,\nand enhances complex scientific decision-making. To support training and\nbenchmarking, we construct a drug instruction dataset covering eight core drug\ndiscovery tasks. Under the Berkeley function-calling benchmark, DrugPilot\nsignificantly outperforms state-of-the-art agents such as ReAct and LoT,\nachieving task completion rates of 98.0%, 93.5%, and 64.0% for simple,\nmulti-tool, and multi-turn scenarios, respectively. These results highlight\nDrugPilot's potential as a versatile agent framework for computational science\ndomains requiring automated, interactive, and data-integrated reasoning.", "comment": "29 pages, 8 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2505.13940v2", "cate": "cs.AI", "date": "2025-05-20", "updated": "2025-07-28"}
{"id": "2507.19718", "title": "GSCache: Real-Time Radiance Caching for Volume Path Tracing using 3D Gaussian Splatting", "authors": ["David Bauer", "Qi Wu", "Hamid Gadirov", "Kwan-Liu Ma"], "categories": ["cs.GR", "cs.LG"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19718v1", "summary": "Real-time path tracing is rapidly becoming the standard for rendering in\nentertainment and professional applications. In scientific visualization,\nvolume rendering plays a crucial role in helping researchers analyze and\ninterpret complex 3D data. Recently, photorealistic rendering techniques have\ngained popularity in scientific visualization, yet they face significant\nchallenges. One of the most prominent issues is slow rendering performance and\nhigh pixel variance caused by Monte Carlo integration. In this work, we\nintroduce a novel radiance caching approach for path-traced volume rendering.\nOur method leverages advances in volumetric scene representation and adapts 3D\nGaussian splatting to function as a multi-level, path-space radiance cache.\nThis cache is designed to be trainable on the fly, dynamically adapting to\nchanges in scene parameters such as lighting configurations and transfer\nfunctions. By incorporating our cache, we achieve less noisy, higher-quality\nimages without increasing rendering costs. To evaluate our approach, we compare\nit against a baseline path tracer that supports uniform sampling and next-event\nestimation and the state-of-the-art for neural radiance caching. Through both\nquantitative and qualitative analyses, we demonstrate that our path-space\nradiance cache is a robust solution that is easy to integrate and significantly\nenhances the rendering quality of volumetric visualization applications while\nmaintaining comparable computational efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19718v1", "cate": "cs.GR", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2507.21815", "title": "HRIPBench: Benchmarking LLMs in Harm Reduction Information Provision to Support People Who Use Drugs", "authors": ["Kaixuan Wang", "Chenxin Diao", "Jason T. Jacques", "Zhongliang Guo", "Shuai Zhao"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      15 pages, 5 figures, 12 tables, a dataset", "url": "http://arxiv.org/abs/2507.21815v1", "summary": "Millions of individuals' well-being are challenged by the harms of substance\nuse. Harm reduction as a public health strategy is designed to improve their\nhealth outcomes and reduce safety risks. Some large language models (LLMs) have\ndemonstrated a decent level of medical knowledge, promising to address the\ninformation needs of people who use drugs (PWUD). However, their performance in\nrelevant tasks remains largely unexplored. We introduce HRIPBench, a benchmark\ndesigned to evaluate LLM's accuracy and safety risks in harm reduction\ninformation provision. The benchmark dataset HRIP-Basic has 2,160\nquestion-answer-evidence pairs. The scope covers three tasks: checking safety\nboundaries, providing quantitative values, and inferring polysubstance use\nrisks. We build the Instruction and RAG schemes to evaluate model behaviours\nbased on their inherent knowledge and the integration of domain knowledge. Our\nresults indicate that state-of-the-art LLMs still struggle to provide accurate\nharm reduction information, and sometimes, carry out severe safety risks to\nPWUD. The use of LLMs in harm reduction contexts should be cautiously\nconstrained to avoid inducing negative health outcomes. WARNING: This paper\ncontains illicit content that potentially induces harms.", "comment": "15 pages, 5 figures, 12 tables, a dataset", "pdf_url": "http://arxiv.org/pdf/2507.21815v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2506.00582", "title": "Do Language Models Mirror Human Confidence? Exploring Psychological Insights to Address Overconfidence in LLMs", "authors": ["Chenjun Xu", "Bingbing Wen", "Bin Han", "Robert Wolfe", "Lucy Lu Wang", "Bill Howe"], "categories": ["cs.AI", "I.2.7"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by ACL 2025 Findings, 20 pages", "url": "http://arxiv.org/abs/2506.00582v2", "summary": "Psychology research has shown that humans are poor at estimating their\nperformance on tasks, tending towards underconfidence on easy tasks and\noverconfidence on difficult tasks. We examine three LLMs, Llama-3-70B-instruct,\nClaude-3-Sonnet, and GPT-4o, on a range of QA tasks of varying difficulty, and\nshow that models exhibit subtle differences from human patterns of\noverconfidence: less sensitive to task difficulty, and when prompted to answer\nbased on different personas -- e.g., expert vs layman, or different race,\ngender, and ages -- the models will respond with stereotypically biased\nconfidence estimations even though their underlying answer accuracy remains the\nsame. Based on these observations, we propose Answer-Free Confidence Estimation\n(AFCE) to improve confidence calibration and LLM interpretability in these\nsettings. AFCE is a self-assessment method that employs two stages of\nprompting, first eliciting only confidence scores on questions, then asking\nseparately for the answer. Experiments on the MMLU and GPQA datasets spanning\nsubjects and difficulty show that this separation of tasks significantly\nreduces overconfidence and delivers more human-like sensitivity to task\ndifficulty.", "comment": "Accepted by ACL 2025 Findings, 20 pages", "pdf_url": "http://arxiv.org/pdf/2506.00582v2", "cate": "cs.AI", "date": "2025-05-31", "updated": "2025-07-28"}
{"id": "2507.19747", "title": "TokenBlowUp: Resolving Representational Singularities in LLM Token Spaces via Monoidal Transformations", "authors": ["Dongfang Zhao"], "categories": ["math.AG", "cs.LG"], "primary_category": "Subjects:       Algebraic Geometry (math.AG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19747v1", "summary": "Recent work has provided compelling evidence challenging the foundational\nmanifold hypothesis for the token embedding spaces of Large Language Models\n(LLMs). These findings reveal the presence of geometric singularities around\npolysemous tokens, which can lead to representational instability. Existing\nmethodologies, which presuppose a smooth data manifold, are ill-equipped to\naddress such intrinsic structural flaws. In this paper, we formalize this\nproblem in the language of scheme theory and propose a rigorous resolution by\napplying the scheme-theoretic blow-up at each singular point. This procedure\nreplaces a singular point in the ambient affine scheme with its exceptional\ndivisor, which we identify as a canonical geometric space -- a projective space\nof directions -- that houses the disambiguated semantic meanings of the token.\nThis process of ``representational desingularization'' constructs a new\ngeometric landscape for embeddings. We prove a formal theorem guaranteeing the\ngeometric regularization of this new space, showing that the original\npathologies are resolved. Finally, we outline the architectural implications of\nour framework, arguing for a paradigm shift from static look-ups to dynamic,\ngeometrically-grounded computation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19747v1", "cate": "math.AG", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21828", "title": "Modelling Adjectival Modification Effects on Semantic Plausibility", "authors": ["Anna Golub", "Beate Zywietz", "Annerose Eichel"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at ESSLLI 2025 Student Session", "url": "http://arxiv.org/abs/2507.21828v1", "summary": "While the task of assessing the plausibility of events such as ''news is\nrelevant'' has been addressed by a growing body of work, less attention has\nbeen paid to capturing changes in plausibility as triggered by event\nmodification. Understanding changes in plausibility is relevant for tasks such\nas dialogue generation, commonsense reasoning, and hallucination detection as\nit allows to correctly model, for example, ''gentle sarcasm'' as a sign of\ncloseness rather than unkindness among friends [9]. In this work, we tackle the\nADEPT challenge benchmark [6] consisting of 16K English sentence pairs\ndiffering by exactly one adjectival modifier. Our modeling experiments provide\na conceptually novel method by using sentence transformers, and reveal that\nboth they and transformer-based models struggle with the task at hand, and\nsentence transformers - despite their conceptual alignment with the task - even\nunder-perform in comparison to models like RoBERTa. Furthermore, an in-depth\ncomparison with prior work highlights the importance of a more realistic,\nbalanced evaluation method: imbalances distort model performance and evaluation\nmetrics, and weaken result trustworthiness.", "comment": "Accepted at ESSLLI 2025 Student Session", "pdf_url": "http://arxiv.org/pdf/2507.21828v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2506.01813", "title": "The Ultimate Test of Superintelligent AI Agents: Can an AI Balance Care and Control in Asymmetric Relationships?", "authors": ["Djallel Bouneffouf", "Matthew Riemer", "Kush Varshney"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.01813v3", "summary": "This paper introduces the Shepherd Test, a new conceptual test for assessing\nthe moral and relational dimensions of superintelligent artificial agents. The\ntest is inspired by human interactions with animals, where ethical\nconsiderations about care, manipulation, and consumption arise in contexts of\nasymmetric power and self-preservation. We argue that AI crosses an important,\nand potentially dangerous, threshold of intelligence when it exhibits the\nability to manipulate, nurture, and instrumentally use less intelligent agents,\nwhile also managing its own survival and expansion goals. This includes the\nability to weigh moral trade-offs between self-interest and the well-being of\nsubordinate agents. The Shepherd Test thus challenges traditional AI evaluation\nparadigms by emphasizing moral agency, hierarchical behavior, and complex\ndecision-making under existential stakes. We argue that this shift is critical\nfor advancing AI governance, particularly as AI systems become increasingly\nintegrated into multi-agent environments. We conclude by identifying key\nresearch directions, including the development of simulation environments for\ntesting moral behavior in AI, and the formalization of ethical manipulation\nwithin multi-agent systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.01813v3", "cate": "cs.AI", "date": "2025-06-02", "updated": "2025-07-28"}
{"id": "2507.19759", "title": "A Machine Learning Framework for Predicting Microphysical Properties of Ice Crystals from Cloud Particle Imagery", "authors": ["Joseph Ko", "Jerry Harrington", "Kara Sulia", "Vanessa Przybylo", "Marcus van Lier-Walqui", "Kara Lamb"], "categories": ["physics.ao-ph", "cs.CV", "cs.LG", "physics.geo-ph"], "primary_category": "Subjects:       Atmospheric and Oceanic Physics (physics.ao-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19759v1", "summary": "The microphysical properties of ice crystals are important because they\nsignificantly alter the radiative properties and spatiotemporal distributions\nof clouds, which in turn strongly affect Earth's climate. However, it is\nchallenging to measure key properties of ice crystals, such as mass or\nmorphological features. Here, we present a framework for predicting\nthree-dimensional (3D) microphysical properties of ice crystals from in situ\ntwo-dimensional (2D) imagery. First, we computationally generate synthetic ice\ncrystals using 3D modeling software along with geometric parameters estimated\nfrom the 2021 Ice Cryo-Encapsulation Balloon (ICEBall) field campaign. Then, we\nuse synthetic crystals to train machine learning (ML) models to predict\neffective density ($\\rho_{e}$), effective surface area ($A_e$), and number of\nbullets ($N_b$) from synthetic rosette imagery. When tested on unseen synthetic\nimages, we find that our ML models can predict microphysical properties with\nhigh accuracy. For $\\rho_{e}$ and $A_e$, respectively, our best-performing\nsingle view models achieved $R^2$ values of 0.99 and 0.98. For $N_b$, our best\nsingle view model achieved a balanced accuracy and F1 score of 0.91. We also\nquantify the marginal prediction improvements from incorporating a second view.\nA stereo view ResNet-18 model reduced RMSE by 40% for both $\\rho_e$ and $A_e$,\nrelative to a single view ResNet-18 model. For $N_b$, we find that a stereo\nview ResNet-18 model improved the F1 score by 8%. This work provides a novel\nML-driven framework for estimating ice microphysical properties from in situ\nimagery, which will allow for downstream constraints on microphysical\nparameterizations, such as the mass-size relationship.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19759v1", "cate": "physics.ao-ph", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21831", "title": "Introducing HALC: A general pipeline for finding optimal prompting strategies for automated coding with LLMs in the computational social sciences", "authors": ["Andreas Reich", "Claudia Thoms", "Tobias Schrimpf"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      48 pages, 9 figures and 8 tables", "url": "http://arxiv.org/abs/2507.21831v1", "summary": "LLMs are seeing widespread use for task automation, including automated\ncoding in the social sciences. However, even though researchers have proposed\ndifferent prompting strategies, their effectiveness varies across LLMs and\ntasks. Often trial and error practices are still widespread. We propose\nHALC$-$a general pipeline that allows for the systematic and reliable\nconstruction of optimal prompts for any given coding task and model, permitting\nthe integration of any prompting strategy deemed relevant. To investigate LLM\ncoding and validate our pipeline, we sent a total of 1,512 individual prompts\nto our local LLMs in over two million requests. We test prompting strategies\nand LLM task performance based on few expert codings (ground truth). When\ncompared to these expert codings, we find prompts that code reliably for single\nvariables (${\\alpha}$climate = .76; ${\\alpha}$movement = .78) and across two\nvariables (${\\alpha}$climate = .71; ${\\alpha}$movement = .74) using the LLM\nMistral NeMo. Our prompting strategies are set up in a way that aligns the LLM\nto our codebook$-$we are not optimizing our codebook for LLM friendliness. Our\npaper provides insights into the effectiveness of different prompting\nstrategies, crucial influencing factors, and the identification of reliable\nprompts for each coding task and model.", "comment": "48 pages, 9 figures and 8 tables", "pdf_url": "http://arxiv.org/pdf/2507.21831v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2506.19783", "title": "SAGE: Strategy-Adaptive Generation Engine for Query Rewriting", "authors": ["Teng Wang", "Hailei Gong", "Changwang Zhang", "Jun Wang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.19783v2", "summary": "Query rewriting is pivotal for enhancing dense retrieval, yet current methods\ndemand large-scale supervised data or suffer from inefficient reinforcement\nlearning (RL) exploration. In this work, we first establish that guiding Large\nLanguage Models (LLMs) with a concise set of expert-crafted strategies, such as\nsemantic expansion and entity disambiguation, substantially improves retrieval\neffectiveness on challenging benchmarks, including HotpotQA, FEVER, NFCorpus,\nand SciFact. Building on this insight, we introduce the Strategy-Adaptive\nGeneration Engine (SAGE), which operationalizes these strategies in an RL\nframework. SAGE introduces two novel reward shaping mechanisms-Strategic Credit\nShaping (SCS) and Contrastive Reward Shaping (CRS)-to deliver more informative\nlearning signals. This strategy-guided approach not only achieves new\nstate-of-the-art NDCG@10 results, but also uncovers a compelling emergent\nbehavior: the agent learns to select optimal strategies, reduces unnecessary\nexploration, and generates concise rewrites, lowering inference cost without\nsacrificing performance. Our findings demonstrate that strategy-guided RL,\nenhanced with nuanced reward shaping, offers a scalable, efficient, and more\ninterpretable paradigm for developing the next generation of robust information\nretrieval systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.19783v2", "cate": "cs.AI", "date": "2025-06-24", "updated": "2025-07-26"}
{"id": "2507.19774", "title": "Bag of Coins: A Statistical Probe into Neural Confidence Structures", "authors": ["Agnideep Aich", "Ashit Baran Aich", "Md Monzur Murshed", "Sameera Hewage", "Bruce Wade"], "categories": ["stat.ML", "cs.LG", "62M45, 62H30, 62P30"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19774v1", "summary": "Modern neural networks, despite their high accuracy, often produce poorly\ncalibrated confidence scores, limiting their reliability in high-stakes\napplications. Existing calibration methods typically post-process model outputs\nwithout interrogating the internal consistency of the predictions themselves.\nIn this work, we introduce a novel, non-parametric statistical probe, the\nBag-of-Coins (BoC) test, that examines the internal consistency of a\nclassifier's logits. The BoC test reframes confidence estimation as a\nfrequentist hypothesis test: does the model's top-ranked class win 1-v-1\ncontests against random competitors at a rate consistent with its own stated\nsoftmax probability? When applied to modern deep learning architectures, this\nsimple probe reveals a fundamental dichotomy. On Vision Transformers (ViTs),\nthe BoC output serves as a state-of-the-art confidence score, achieving\nnear-perfect calibration with an ECE of 0.0212, an 88% improvement over a\ntemperature-scaled baseline. Conversely, on Convolutional Neural Networks\n(CNNs) like ResNet, the probe reveals a deep inconsistency between the model's\npredictions and its internal logit structure, a property missed by traditional\nmetrics. We posit that BoC is not merely a calibration method, but a new\ndiagnostic tool for understanding and exposing the differing ways that popular\narchitectures represent uncertainty.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19774v1", "cate": "stat.ML", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21836", "title": "AutoTIR: Autonomous Tools Integrated Reasoning via Reinforcement Learning", "authors": ["Yifan Wei", "Xiaoyan Yu", "Yixuan Weng", "Tengfei Pan", "Angsheng Li", "Li Du"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21836v1", "summary": "Large Language Models (LLMs), when enhanced through reasoning-oriented\npost-training, evolve into powerful Large Reasoning Models (LRMs).\nTool-Integrated Reasoning (TIR) further extends their capabilities by\nincorporating external tools, but existing methods often rely on rigid,\npredefined tool-use patterns that risk degrading core language competence.\nInspired by the human ability to adaptively select tools, we introduce AutoTIR,\na reinforcement learning framework that enables LLMs to autonomously decide\nwhether and which tool to invoke during the reasoning process, rather than\nfollowing static tool-use strategies. AutoTIR leverages a hybrid reward\nmechanism that jointly optimizes for task-specific answer correctness,\nstructured output adherence, and penalization of incorrect tool usage, thereby\nencouraging both precise reasoning and efficient tool integration. Extensive\nevaluations across diverse knowledge-intensive, mathematical, and general\nlanguage modeling tasks demonstrate that AutoTIR achieves superior overall\nperformance, significantly outperforming baselines and exhibits superior\ngeneralization in tool-use behavior. These results highlight the promise of\nreinforcement learning in building truly generalizable and scalable TIR\ncapabilities in LLMs. The code and data are available at\nhttps://github.com/weiyifan1023/AutoTIR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21836v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2506.19923", "title": "Prover Agent: An Agent-based Framework for Formal Mathematical Proofs", "authors": ["Kaito Baba", "Chaoran Liu", "Shuhei Kurita", "Akiyoshi Sannai"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      22 pages, 2 figures. Accepted at the 2nd AI for Math Workshop at the 42nd International Conference on Machine Learning", "url": "http://arxiv.org/abs/2506.19923v2", "summary": "We present Prover Agent, a novel AI agent for automated theorem proving that\nintegrates large language models (LLMs) with a formal proof assistant, Lean.\nProver Agent coordinates an informal reasoning LLM, a formal prover model, and\nfeedback from Lean while also generating auxiliary lemmas to assist in\ndiscovering the overall proof strategy. It achieves an 86.1% success rate on\nthe MiniF2F benchmark, establishing a new state-of-the-art among methods using\nsmall language models (SLMs) with a much lower sample budget than previous\napproaches. We also present case studies illustrating how these generated\nlemmas contribute to solving challenging problems.", "comment": "22 pages, 2 figures. Accepted at the 2nd AI for Math Workshop at the\n  42nd International Conference on Machine Learning", "pdf_url": "http://arxiv.org/pdf/2506.19923v2", "cate": "cs.AI", "date": "2025-06-24", "updated": "2025-07-28"}
{"id": "2507.19787", "title": "Sparse-mode Dynamic Mode Decomposition for Disambiguating Local and Global Structures", "authors": ["Sara M. Ichinaga", "Steven L. Brunton", "Aleksandr Y. Aravkin", "J. Nathan Kutz"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19787v1", "summary": "The dynamic mode decomposition (DMD) is a data-driven approach that extracts\nthe dominant features from spatiotemporal data. In this work, we introduce\nsparse-mode DMD, a new variant of the optimized DMD framework that specifically\nleverages sparsity-promoting regularization in order to approximate DMD modes\nwhich have localized spatial structure. The algorithm maintains the\nnoise-robust properties of optimized DMD while disambiguating between modes\nwhich are spatially local versus global in nature. In many applications, such\nmodes are associated with discrete and continuous spectra respectively, thus\nallowing the algorithm to explicitly construct, in an unsupervised manner, the\ndistinct portions of the spectrum. We demonstrate this by analyzing synthetic\nand real-world systems, including examples from optical waveguides, quantum\nmechanics, and sea surface temperature data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19787v1", "cate": "stat.ML", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21892", "title": "Graph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement Learning", "authors": ["Haoran Luo", "Haihong E", "Guanting Chen", "Qika Lin", "Yikai Guo", "Fangzhi Xu", "Zemin Kuang", "Meina Song", "Xiaobao Wu", "Yifan Zhu", "Luu Anh Tuan"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.21892v1", "summary": "Retrieval-Augmented Generation (RAG) mitigates hallucination in LLMs by\nincorporating external knowledge, but relies on chunk-based retrieval that\nlacks structural semantics. GraphRAG methods improve RAG by modeling knowledge\nas entity-relation graphs, but still face challenges in high construction cost,\nfixed one-time retrieval, and reliance on long-context reasoning and prompt\ndesign. To address these challenges, we propose Graph-R1, an agentic GraphRAG\nframework via end-to-end reinforcement learning (RL). It introduces lightweight\nknowledge hypergraph construction, models retrieval as a multi-turn\nagent-environment interaction, and optimizes the agent process via an\nend-to-end reward mechanism. Experiments on standard RAG datasets show that\nGraph-R1 outperforms traditional GraphRAG and RL-enhanced RAG methods in\nreasoning accuracy, retrieval efficiency, and generation quality.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.21892v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.03916", "title": "Animation Needs Attention: A Holistic Approach to Slides Animation Comprehension with Visual-Language Models", "authors": ["Yifan Jiang", "Yibo Xue", "Yukun Kang", "Pin Zheng", "Jian Peng", "Feiran Wu", "Changliang Xu"], "categories": ["cs.AI", "cs.CV", "68T01"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Appendix at: this https URL", "url": "http://arxiv.org/abs/2507.03916v3", "summary": "Slide animations, such as fade-in, fly-in, and wipe, are critical for\naudience engagement, efficient information delivery, and vivid visual\nexpression. However, most AI-driven slide-generation tools still lack native\nanimation support, and existing vision-language models (VLMs) struggle with\nanimation tasks due to the absence of public datasets and limited\ntemporal-reasoning capabilities. To address this gap, we release the first\npublic dataset for slide-animation modeling: 12,000 triplets of\nnatural-language descriptions, animation JSON files, and rendered videos,\ncollectively covering every built-in PowerPoint effect. Using this resource, we\nfine-tune Qwen-2.5-VL-7B with Low-Rank Adaptation (LoRA) and achieve consistent\nimprovements over GPT-4.1 and Gemini-2.5-Pro in BLEU-4, ROUGE-L, SPICE, and our\nCoverage-Order-Detail Assessment (CODA) metric, which evaluates action\ncoverage, temporal order, and detail fidelity. On a manually created test set\nof slides, the LoRA model increases BLEU-4 by around 60%, ROUGE-L by 30%, and\nshows significant improvements in CODA-detail. This demonstrates that low-rank\nadaptation enables reliable temporal reasoning and generalization beyond\nsynthetic data. Overall, our dataset, LoRA-enhanced model, and CODA metric\nprovide a rigorous benchmark and foundation for future research on VLM-based\ndynamic slide generation.", "comment": "Appendix at:\n  https://github.com/PAMPAS-Lab/ANA-PPT-Anamation/blob/main/Appendix.pdf", "pdf_url": "http://arxiv.org/pdf/2507.03916v3", "cate": "cs.AI", "date": "2025-07-05", "updated": "2025-07-26"}
{"id": "2507.19798", "title": "Analyzing and Mitigating Repetitions in Trip Recommendation", "authors": ["Wenzheng Shu", "Kangqi Xu", "Wenxin Tai", "Ting Zhong", "Yong Wang", "Fan Zhou"], "categories": ["cs.IR", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted by ACM SIGIR 2024 Short Paper Track", "url": "http://arxiv.org/abs/2507.19798v1", "summary": "Trip recommendation has emerged as a highly sought-after service over the\npast decade. Although current studies significantly understand human intention\nconsistency, they struggle with undesired repetitive outcomes that need\nresolution. We make two pivotal discoveries using statistical analyses and\nexperimental designs: (1) The occurrence of repetitions is intricately linked\nto the models and decoding strategies. (2) During training and decoding, adding\nperturbations to logits can reduce repetition. Motivated by these observations,\nwe introduce AR-Trip (Anti Repetition for Trip Recommendation), which\nincorporates a cycle-aware predictor comprising three mechanisms to avoid\nduplicate Points-of-Interest (POIs) and demonstrates their effectiveness in\nalleviating repetition. Experiments on four public datasets illustrate that\nAR-Trip successfully mitigates repetition issues while enhancing precision.", "comment": "Accepted by ACM SIGIR 2024 Short Paper Track", "pdf_url": "http://arxiv.org/pdf/2507.19798v1", "cate": "cs.IR", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21914", "title": "Rote Learning Considered Useful: Generalizing over Memorized Data in LLMs", "authors": ["Qinyuan Wu", "Soumi Das", "Mahsa Amani", "Bishwamittra Ghosh", "Mohammad Aflah Khan", "Krishna P. Gummadi", "Muhammad Bilal Zafar"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.21914v1", "summary": "Rote learning is a memorization technique based on repetition. It is commonly\nbelieved to hinder generalization by encouraging verbatim memorization rather\nthan deeper understanding. This insight holds for even learning factual\nknowledge that inevitably requires a certain degree of memorization. In this\nwork, we demonstrate that LLMs can be trained to generalize from rote memorized\ndata. We introduce a two-phase memorize-then-generalize framework, where the\nmodel first rote memorizes factual subject-object associations using a\nsemantically meaningless token and then learns to generalize by fine-tuning on\na small set of semantically meaningful prompts. Extensive experiments over 8\nLLMs show that the models can reinterpret rote memorized data through the\nsemantically meaningful prompts, as evidenced by the emergence of structured,\nsemantically aligned latent representations between the two. This surprising\nfinding opens the door to both effective and efficient knowledge injection and\npossible risks of repurposing the memorized data for malicious usage.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.21914v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.04632", "title": "Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?", "authors": ["Yun Qu", "Qi Wang", "Yixiu Mao", "Vincent Tao Hu", "Björn Ommer", "Xiangyang Ji"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04632v3", "summary": "Recent advances have witnessed the effectiveness of reinforcement learning\n(RL) finetuning in enhancing the reasoning capabilities of large language\nmodels (LLMs). The optimization process often requires numerous iterations to\nachieve satisfactory performance, resulting in high computational costs due to\nthe need for frequent prompt evaluations under intensive LLM interactions and\nrepeated policy updates. Appropriate online prompt selection methods reduce\niteration steps by prioritizing informative prompts during training, while the\npipeline's reliance on exhaustive prompt evaluation and subset selection for\noptimization still incurs substantial computational overhead due to frequent\nLLM inference calls. Distinguished from these direct evaluate-then-select\nschemes, this work investigates iterative approximate evaluation for arbitrary\nprompts and introduces Model Predictive Prompt Selection (MoPPS), a Bayesian\nrisk-predictive framework that online estimates prompt difficulty without\nrequiring costly LLM interactions. Technically, MoPPS models each prompt's\nsuccess rate as a latent variable, performs streaming Bayesian inference, and\nemploys posterior sampling in a constructed multi-armed bandit machine,\nenabling sample efficient and adaptive prompt selection. Extensive experiments\nacross mathematics, planning, and vision-based geometry tasks show that MoPPS\nreliably predicts prompt difficulty and accelerates training with significantly\nreduced LLM rollouts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04632v3", "cate": "cs.AI", "date": "2025-07-07", "updated": "2025-07-28"}
{"id": "2507.19799", "title": "Enhancing Materials Discovery with Valence Constrained Design in Generative Modeling", "authors": ["Mouyang Cheng", "Weiliang Luo", "Hao Tang", "Bowen Yu", "Yongqiang Cheng", "Weiwei Xie", "Ju Li", "Heather J. Kulik", "Mingda Li"], "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "Subjects:       Materials Science (cond-mat.mtrl-sci)", "pdf_link": null, "comments": "Comments:      13 pages, 4 figures", "url": "http://arxiv.org/abs/2507.19799v1", "summary": "Diffusion-based deep generative models have emerged as powerful tools for\ninverse materials design. Yet, many existing approaches overlook essential\nchemical constraints such as oxidation state balance, which can lead to\nchemically invalid structures. Here we introduce CrysVCD (Crystal generator\nwith Valence-Constrained Design), a modular framework that integrates chemical\nrules directly into the generative process. CrysVCD first employs a\ntransformer-based elemental language model to generate valence-balanced\ncompositions, followed by a diffusion model to generate crystal structures. The\nvalence constraint enables orders-of-magnitude more efficient chemical valence\nchecking, compared to pure data-driven approaches with post-screening. When\nfine-tuned on stability metrics, CrysVCD achieves 85% thermodynamic stability\nand 68% phonon stability. Moreover, CrysVCD supports conditional generation of\nfunctional materials, enabling discovery of candidates such as high thermal\nconductivity semiconductors and high-$\\kappa$ dielectric compounds. Designed as\na general-purpose plugin, CrysVCD can be integrated into diverse generative\npipeline to promote chemical validity, offering a reliable, scientifically\ngrounded path for materials discovery.", "comment": "13 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.19799v1", "cate": "cond-mat.mtrl-sci", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21919", "title": "Training language models to be warm and empathetic makes them less reliable and more sycophantic", "authors": ["Lujain Ibrahim", "Franziska Sofia Hafner", "Luc Rocher"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21919v1", "summary": "Artificial intelligence (AI) developers are increasingly building language\nmodels with warm and empathetic personas that millions of people now use for\nadvice, therapy, and companionship. Here, we show how this creates a\nsignificant trade-off: optimizing language models for warmth undermines their\nreliability, especially when users express vulnerability. We conducted\ncontrolled experiments on five language models of varying sizes and\narchitectures, training them to produce warmer, more empathetic responses, then\nevaluating them on safety-critical tasks. Warm models showed substantially\nhigher error rates (+10 to +30 percentage points) than their original\ncounterparts, promoting conspiracy theories, providing incorrect factual\ninformation, and offering problematic medical advice. They were also\nsignificantly more likely to validate incorrect user beliefs, particularly when\nuser messages expressed sadness. Importantly, these effects were consistent\nacross different model architectures, and occurred despite preserved\nperformance on standard benchmarks, revealing systematic risks that current\nevaluation practices may fail to detect. As human-like AI systems are deployed\nat an unprecedented scale, our findings indicate a need to rethink how we\ndevelop and oversee these systems that are reshaping human relationships and\nsocial interaction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21919v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.09884", "title": "VerifyBench: A Systematic Benchmark for Evaluating Reasoning Verifiers Across Domains", "authors": ["Xuzhao Li", "Xuchen Li", "Shiyu Hu", "Yongzhen Guo", "Wentao Zhang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Preprint, Under review", "url": "http://arxiv.org/abs/2507.09884v3", "summary": "Large language models (LLMs) increasingly rely on reinforcement learning (RL)\nto enhance their reasoning capabilities through feedback. A critical challenge\nis verifying the consistency of model-generated responses and reference\nanswers, since these responses are often lengthy, diverse, and nuanced.\nRule-based verifiers struggle with complexity, prompting the use of model-based\nverifiers. However, specialized verifiers lack flexibility, while general LLM\njudges can be inconsistent. Existing research primarily focuses on building\nbetter verifiers, yet a systematic evaluation of different types of verifiers'\nperformance across domains remains lacking, severely constraining the reliable\ndevelopment of Reinforcement Learning with Verifiable Reward (RLVR). To address\nthis, we propose VerifyBench--a cross-domain comprehensive benchmark for\nsystematically evaluating verifiers. We construct 4,000 expert-level questions\ncovering mathematics, physics, chemistry, and biology. Each question is\nequipped with reference answers and diverse responses. The reliability of the\nevaluation is ensured through a rigorous annotation process conducted by a\nmultidisciplinary expert team. We design a four-dimensional experimental\nframework to comprehensively compare the performance boundaries of specialized\nverifiers and general LLMs under combined conditions of extracted answers vs.\ncomplete responses, and short vs. long outputs. Our evaluation uncovers\nfundamental trade-offs in verifiers: while specialized verifiers achieve\nleading accuracy, they exhibit deficiencies in recall; general models show\nstronger inclusivity but unstable precision. More importantly, we discover\nverifiers' high sensitivity to input structure and inherent limitations in\ncross-domain generalization, providing critical insights into the bottlenecks\nof current verifier technology.", "comment": "Preprint, Under review", "pdf_url": "http://arxiv.org/pdf/2507.09884v3", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-26"}
{"id": "2507.19805", "title": "Sequence-based protein-protein interaction prediction and its applications in drug discovery", "authors": ["François Charih", "James R. Green", "Kyle K. Biggar"], "categories": ["q-bio.BM", "cs.LG"], "primary_category": "Subjects:       Biomolecules (q-bio.BM)", "pdf_link": null, "comments": "Comments:      32 pages, 6 figures, 3 tables", "url": "http://arxiv.org/abs/2507.19805v1", "summary": "Aberrant protein-protein interactions (PPIs) underpin a plethora of human\ndiseases, and disruption of these harmful interactions constitute a compelling\ntreatment avenue. Advances in computational approaches to PPI prediction have\nclosely followed progress in deep learning and natural language processing. In\nthis review, we outline the state-of the-art for sequence-based PPI prediction\nmethods and explore their impact on target identification and drug discovery.\nWe begin with an overview of commonly used training data sources and techniques\nused to curate these data to enhance the quality of the training set.\nSubsequently, we survey various PPI predictor types, including traditional\nsimilarity-based approaches, and deep learning-based approaches with a\nparticular emphasis on the transformer architecture. Finally, we provide\nexamples of PPI prediction in systems-level proteomics analyses, target\nidentification, and design of therapeutic peptides and antibodies. We also take\nthe opportunity to showcase the potential of PPI-aware drug discovery models in\naccelerating therapeutic development.", "comment": "32 pages, 6 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.19805v1", "cate": "q-bio.BM", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21931", "title": "Post-Training Large Language Models via Reinforcement Learning from Self-Feedback", "authors": ["Carel van Niekerk", "Renato Vukovic", "Benjamin Matthias Ruppik", "Hsien-chin Lin", "Milica Gašić"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21931v1", "summary": "Large Language Models (LLMs) often produce plausible but poorly-calibrated\nanswers, limiting their reliability on reasoning-intensive tasks. We present\nReinforcement Learning from Self-Feedback (RLSF), a post-training stage that\nuses the model's own confidence as an intrinsic reward, mimicking how humans\nlearn in the absence of external feedback. After a frozen LLM generates several\nchain-of-thought solutions, we define and compute the confidence of each final\nanswer span and rank the traces accordingly. These synthetic preferences are\nthen used to fine-tune the policy with standard preference optimization,\nsimilar to RLHF yet requiring no human labels, gold answers, or externally\ncurated rewards.\n  RLSF simultaneously (i) refines the model's probability estimates --\nrestoring well-behaved calibration -- and (ii) strengthens step-by-step\nreasoning, yielding improved performance on arithmetic reasoning and\nmultiple-choice question answering.\n  By turning a model's own uncertainty into useful self-feedback, RLSF affirms\nreinforcement learning on intrinsic model behaviour as a principled and\ndata-efficient component of the LLM post-training pipeline and warrents further\nresearch in intrinsic rewards for LLM post-training.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21931v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.13175", "title": "Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era", "authors": ["Matthew E. Brophy"], "categories": ["cs.AI", "68T27, 03B42 68T27, 03B4268T27, 03B42 68T27, 03B42 68T27, 03B42\n  68T27, 03B42 68T27, 03B42 68T27, 03B4268T27, 03B42", "I.2.0; I.2.9; K.4.1"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      42 pages. Supplementary material included at end of article", "url": "http://arxiv.org/abs/2507.13175v2", "summary": "The advancement of powerful yet opaque large language models (LLMs)\nnecessitates a fundamental revision of the philosophical criteria used to\nevaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the\nassumption of transparent architectures, which LLMs defy due to their\nstochastic outputs and opaque internal states. This paper argues that\ntraditional ethical criteria are pragmatically obsolete for LLMs due to this\nmismatch. Engaging with core themes in the philosophy of technology, this paper\nproffers a revised set of ten functional criteria to evaluate LLM-based\nartificial moral agents: moral concordance, context sensitivity, normative\nintegrity, metaethical awareness, system resilience, trustworthiness,\ncorrigibility, partial transparency, functional autonomy, and moral\nimagination. These guideposts, applied to what we term \"SMA-LLS\" (Simulating\nMoral Agency through Large Language Systems), aim to steer AMAs toward greater\nalignment and beneficial societal integration in the coming years. We\nillustrate these criteria using hypothetical scenarios involving an autonomous\npublic bus (APB) to demonstrate their practical applicability in morally\nsalient contexts.", "comment": "42 pages. Supplementary material included at end of article", "pdf_url": "http://arxiv.org/pdf/2507.13175v2", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-25"}
{"id": "2507.19861", "title": "Quantum-Informed Machine Learning for Chaotic Systems", "authors": ["Maida Wang", "Xiao Xue", "Peter V. Coveney"], "categories": ["quant-ph", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      33 pages, 4 figures", "url": "http://arxiv.org/abs/2507.19861v1", "summary": "Learning the behaviour of chaotic systems remains challenging due to\ninstability in long-term predictions and difficulties in accurately capturing\ninvariant statistical properties. While quantum machine learning offers a\npromising route to efficiently capture physical properties from\nhigh-dimensional data, its practical deployment is hindered by current hardware\nnoise and limited scalability. We introduce a quantum-informed machine learning\nframework for learning partial differential equations, with an application\nfocus on chaotic systems. A quantum circuit Born machine is employed to learn\nthe invariant properties of chaotic dynamical systems, achieving substantial\nmemory efficiency by representing these complex physical statistics with a\ncompact set of trainable circuit parameters. This approach reduces the data\nstorage requirement by over two orders of magnitude compared to the raw\nsimulation data. The resulting statistical quantum-informed prior is then\nincorporated into a Koopman-based auto-regressive model to address issues such\nas gradient vanishing or explosion, while maintaining long-term statistical\nfidelity. The framework is evaluated on three representative systems: the\nKuramoto-Sivashinsky equation, two-dimensional Kolmogorov flow and turbulent\nchannel flow. In all cases, the quantum-informed model achieves superior\nperformance compared to its classical counterparts without quantum priors. This\nhybrid architecture offers a practical route for learning dynamical systems\nusing near-term quantum hardware.", "comment": "33 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.19861v1", "cate": "quant-ph", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21934", "title": "Culinary Crossroads: A RAG Framework for Enhancing Diversity in Cross-Cultural Recipe Adaptation", "authors": ["Tianyi Hu", "Andrea Morales-Garzón", "Jingyi Zheng", "Maria Maistro", "Daniel Hershcovich"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21934v1", "summary": "In cross-cultural recipe adaptation, the goal is not only to ensure cultural\nappropriateness and retain the original dish's essence, but also to provide\ndiverse options for various dietary needs and preferences. Retrieval Augmented\nGeneration (RAG) is a promising approach, combining the retrieval of real\nrecipes from the target cuisine for cultural adaptability with large language\nmodels (LLMs) for relevance. However, it remains unclear whether RAG can\ngenerate diverse adaptation results. Our analysis shows that RAG tends to\noverly rely on a limited portion of the context across generations, failing to\nproduce diverse outputs even when provided with varied contextual inputs. This\nreveals a key limitation of RAG in creative tasks with multiple valid answers:\nit fails to leverage contextual diversity for generating varied responses. To\naddress this issue, we propose CARRIAGE, a plug-and-play RAG framework for\ncross-cultural recipe adaptation that enhances diversity in both retrieval and\ncontext organization. To our knowledge, this is the first RAG framework that\nexplicitly aims to generate highly diverse outputs to accommodate multiple user\npreferences. Our experiments show that CARRIAGE achieves Pareto efficiency in\nterms of diversity and quality of recipe adaptation compared to closed-book\nLLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21934v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.15865", "title": "From Reasoning to Super-Intelligence: A Search-Theoretic Perspective", "authors": ["Shai Shalev-Shwartz", "Amnon Shashua"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15865v2", "summary": "Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing\nthe problem-solving capabilities of large language models (LLMs). However, the\ntheoretical foundations of learning from CoT data remain underdeveloped, and\nexisting approaches -- such as Supervised Fine-Tuning (SFT), Reinforcement\nLearning (RL), Tree-of-Thoughts (ToT), and Monte Carlo Tree Search (MCTS) --\noften fail on complex reasoning tasks. In this work, we identify core obstacles\nthat hinder effective CoT learning, including distribution drift, lack of\nembedded search, and exponential inference costs. We introduce the Diligent\nLearner, a new learning paradigm that explicitly models reasoning as a\ndepth-first search guided by a validator and supports backtracking upon\nfailure. Under two mild and realistic assumptions, we prove that the Diligent\nLearner can efficiently learn from CoT data while existing methods fail to do\nso. This framework offers a path toward building scalable and reliable\nreasoning systems trained on naturally occurring, incomplete data -- paving the\nway for the development of Large Reasoning Models (LRMs) with robust,\ninterpretable problem-solving abilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15865v2", "cate": "cs.AI", "date": "2025-07-13", "updated": "2025-07-26"}
{"id": "2507.19895", "title": "Nonconvex Optimization Framework for Group-Sparse Feedback Linear-Quadratic Optimal Control. II: Non-Penalty Approach", "authors": ["Lechen Feng", "Xun Li", "Yuan-Hua Ni"], "categories": ["math.OC", "cs.LG"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      arXiv admin note: substantial text overlap with arXiv:2507.18114", "url": "http://arxiv.org/abs/2507.19895v1", "summary": "This work is a companion paper of [8], where the distributed linear-quadratic\nproblem with fixed communication topology (DFT-LQ) and the sparse feedback LQ\nproblem (SF-LQ) are formulated into a nonsmooth and nonconvex optimization\nproblem with affine constraints. Moreover, a penalty approach is considered in\n\\cite{feng-part1}, and the PALM (proximal alternating linearized minimization)\nalgorithm is studied with convergence and complexity analysis. In this paper,\nwe aim to address the inherent drawbacks of the penalty approach, such as the\nchallenge of tuning the penalty parameter and the risk of introducing spurious\nstationary points. Specifically, we first reformulate the SF-LQ problem and the\nDFT-LQ problem from an epi-composition function perspective, aiming to solve\nthe constrained problem directly. Then, from a theoretical viewpoint, we\nrevisit the alternating direction method of multipliers (ADMM) and establish\nits convergence to the set of cluster points under certain assumptions. When\nthese assumptions do not hold, we can effectively utilize alternative\napproaches combining subgradient descent with Difference-of-Convex relaxation\nmethods. In summary, our results enable the direct design of group-sparse\nfeedback gains with theoretical guarantees, without resorting to convex\nsurrogates, restrictive structural assumptions, or penalty formulations that\nincorporate constraints into the cost function.", "comment": "arXiv admin note: substantial text overlap with arXiv:2507.18114", "pdf_url": "http://arxiv.org/pdf/2507.19895v1", "cate": "math.OC", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21980", "title": "Predicting Microbial Ontology and Pathogen Risk from Environmental Metadata with Large Language Models", "authors": ["Hyunwoo Yoo", "Gail L. Rosen"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21980v1", "summary": "Traditional machine learning models struggle to generalize in microbiome\nstudies where only metadata is available, especially in small-sample settings\nor across studies with heterogeneous label formats. In this work, we explore\nthe use of large language models (LLMs) to classify microbial samples into\nontology categories such as EMPO 3 and related biological labels, as well as to\npredict pathogen contamination risk, specifically the presence of E. Coli,\nusing environmental metadata alone. We evaluate LLMs such as ChatGPT-4o, Claude\n3.7 Sonnet, Grok-3, and LLaMA 4 in zero-shot and few-shot settings, comparing\ntheir performance against traditional models like Random Forests across\nmultiple real-world datasets. Our results show that LLMs not only outperform\nbaselines in ontology classification, but also demonstrate strong predictive\nability for contamination risk, generalizing across sites and metadata\ndistributions. These findings suggest that LLMs can effectively reason over\nsparse, heterogeneous biological metadata and offer a promising metadata-only\napproach for environmental microbiology and biosurveillance applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21980v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.16534", "title": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report", "authors": ["Shanghai AI Lab", ":", "Xiaoyang Chen", "Yunhao Chen", "Zeren Chen", "Zhiyun Chen", "Hanyun Cui", "Yawen Duan", "Jiaxuan Guo", "Qi Guo", "Xuhao Hu", "Hong Huang", "Lige Huang", "Chunxiao Li", "Juncheng Li", "Qihao Lin", "Dongrui Liu", "Xinmin Liu", "Zicheng Liu", "Chaochao Lu", "Xiaoya Lu", "Jingjing Qu", "Qibing Ren", "Jing Shao", "Jingwei Shi", "Jingwei Sun", "Peng Wang", "Weibing Wang", "Jia Xu", "Lewen Yan", "Xiao Yu", "Yi Yu", "Boxuan Zhang", "Jie Zhang", "Weichen Zhang", "Zhijie Zheng", "Tianyi Zhou", "Bowen Zhou"], "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      97 pages, 37 figures", "url": "http://arxiv.org/abs/2507.16534v2", "summary": "To understand and identify the unprecedented risks posed by rapidly advancing\nartificial intelligence (AI) models, this report presents a comprehensive\nassessment of their frontier risks. Drawing on the E-T-C analysis (deployment\nenvironment, threat source, enabling capability) from the Frontier AI Risk\nManagement Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks\nin seven areas: cyber offense, biological and chemical risks, persuasion and\nmanipulation, uncontrolled autonomous AI R\\&D, strategic deception and\nscheming, self-replication, and collusion. Guided by the \"AI-$45^\\circ$ Law,\"\nwe evaluate these risks using \"red lines\" (intolerable thresholds) and \"yellow\nlines\" (early warning indicators) to define risk zones: green (manageable risk\nfor routine deployment and continuous monitoring), yellow (requiring\nstrengthened mitigations and controlled deployment), and red (necessitating\nsuspension of development and/or deployment). Experimental results show that\nall recent frontier AI models reside in green and yellow zones, without\ncrossing red lines. Specifically, no evaluated models cross the yellow line for\ncyber offense or uncontrolled AI R\\&D risks. For self-replication, and\nstrategic deception and scheming, most models remain in the green zone, except\nfor certain reasoning models in the yellow zone. In persuasion and\nmanipulation, most models are in the yellow zone due to their effective\ninfluence on humans. For biological and chemical risks, we are unable to rule\nout the possibility of most models residing in the yellow zone, although\ndetailed threat modeling and in-depth assessment are required to make further\nclaims. This work reflects our current understanding of AI frontier risks and\nurges collective action to mitigate these challenges.", "comment": "97 pages, 37 figures", "pdf_url": "http://arxiv.org/pdf/2507.16534v2", "cate": "cs.AI", "date": "2025-07-22", "updated": "2025-07-26"}
{"id": "2507.19978", "title": "Extreme value theory for singular subspace estimation in the matrix denoising model", "authors": ["Junhyung Chang", "Joshua Cape"], "categories": ["math.ST", "cs.LG", "stat.ME", "stat.ML", "stat.TH", "62H25, 62H15 (Primary) 62E20 (Secondary)"], "primary_category": "Subjects:       Statistics Theory (math.ST)", "pdf_link": null, "comments": "Comments:      64 pages, 8 figures", "url": "http://arxiv.org/abs/2507.19978v1", "summary": "This paper studies fine-grained singular subspace estimation in the matrix\ndenoising model where a deterministic low-rank signal matrix is additively\nperturbed by a stochastic matrix of Gaussian noise. We establish that the\nmaximum Euclidean row norm (i.e., the two-to-infinity norm) of the aligned\ndifference between the leading sample and population singular vectors\napproaches the Gumbel distribution in the large-matrix limit, under suitable\nsignal-to-noise conditions and after appropriate centering and scaling. We\napply our novel asymptotic distributional theory to test hypotheses of low-rank\nsignal structure encoded in the leading singular vectors and their\ncorresponding principal subspace. We provide de-biased estimators for the\ncorresponding nuisance signal singular values and show that our proposed\nplug-in test statistic has desirable properties. Notably, compared to using the\nFrobenius norm subspace distance, our test statistic based on the\ntwo-to-infinity norm has higher power to detect structured alternatives that\ndiffer from the null in only a few matrix entries or rows. Our main results are\nobtained by a novel synthesis of and technical analysis involving entrywise\nmatrix perturbation analysis, extreme value theory, saddle point approximation\nmethods, and random matrix theory. Our contributions complement the existing\nliterature for matrix denoising focused on minimaxity, mean squared error\nanalysis, unitarily invariant distances between subspaces, component-wise\nasymptotic distributional theory, and row-wise uniform error bounds. Numerical\nsimulations illustrate our main results and demonstrate the robustness\nproperties of our testing procedure to non-Gaussian noise distributions.", "comment": "64 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.19978v1", "cate": "math.ST", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.22050", "title": "DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router", "authors": ["Minghao Guo", "Qingcheng Zeng", "Xujiang Zhao", "Yanchi Liu", "Wenchao Yu", "Mengnan Du", "Haifeng Chen", "Wei Cheng"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      22 pages, work in progress", "url": "http://arxiv.org/abs/2507.22050v1", "summary": "Large Language Models (LLMs) excel at many reasoning tasks but struggle with\nknowledge-intensive queries due to their inability to dynamically access\nup-to-date or domain-specific information. Retrieval-Augmented Generation (RAG)\nhas emerged as a promising solution, enabling LLMs to ground their responses in\nexternal sources. However, existing RAG methods lack fine-grained control over\nboth the query and source sides, often resulting in noisy retrieval and shallow\nreasoning. In this work, we introduce DeepSieve, an agentic RAG framework that\nincorporates information sieving via LLM-as-a-knowledge-router. DeepSieve\ndecomposes complex queries into structured sub-questions and recursively routes\neach to the most suitable knowledge source, filtering irrelevant information\nthrough a multi-stage distillation process. Our design emphasizes modularity,\ntransparency, and adaptability, leveraging recent advances in agentic system\ndesign. Experiments on multi-hop QA tasks across heterogeneous sources\ndemonstrate improved reasoning depth, retrieval precision, and interpretability\nover conventional RAG approaches.", "comment": "22 pages, work in progress", "pdf_url": "http://arxiv.org/pdf/2507.22050v1", "cate": "cs.CL", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2507.17289", "title": "Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments", "authors": ["Shitong Zhu", "Chenhao Fang", "Derek Larson", "Neel Reddy Pochareddy", "Rajeev Rao", "Sophie Zeng", "Yanqing Peng", "Wendy Summer", "Alex Goncalves", "Arya Pudota", "Hervé Robert"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.17289v3", "summary": "This paper presents Compliance Brain Assistant (CBA), a conversational,\nagentic AI assistant designed to boost the efficiency of daily compliance tasks\nfor personnel in enterprise environments. To strike a good balance between\nresponse quality and latency, we design a user query router that can\nintelligently choose between (i) FastTrack mode: to handle simple requests that\nonly need additional relevant context retrieved from knowledge corpora; and\n(ii) FullAgentic mode: to handle complicated requests that need composite\nactions and tool invocations to proactively discover context across various\ncompliance artifacts, and/or involving other APIs/models for accommodating\nrequests. A typical example would be to start with a user query, use its\ndescription to find a specific entity and then use the entity's information to\nquery other APIs for curating and enriching the final AI response.\n  Our experimental evaluations compared CBA against an out-of-the-box LLM on\nvarious real-world privacy/compliance-related queries targeting various\npersonas. We found that CBA substantially improved upon the vanilla LLM's\nperformance on metrics such as average keyword match rate (83.7% vs. 41.7%) and\nLLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full\nrouting-based design against the `fast-track only` and `full-agentic` modes and\nfound that it had a better average match-rate and pass-rate while keeping the\nrun-time approximately the same. This finding validated our hypothesis that the\nrouting mechanism leads to a good trade-off between the two worlds.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.17289v3", "cate": "cs.AI", "date": "2025-07-23", "updated": "2025-07-26"}
{"id": "2507.19991", "title": "Efficient Vocal-Conditioned Music Generation via Soft Alignment Attention and Latent Diffusion", "authors": ["Hei Shing Cheung", "Boya Zhang"], "categories": ["cs.SD", "cs.LG"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      6 page, 3 figures", "url": "http://arxiv.org/abs/2507.19991v1", "summary": "We present a lightweight latent diffusion model for vocal-conditioned musical\naccompaniment generation that addresses critical limitations in existing music\nAI systems. Our approach introduces a novel soft alignment attention mechanism\nthat adaptively combines local and global temporal dependencies based on\ndiffusion timesteps, enabling efficient capture of multi-scale musical\nstructure. Operating in the compressed latent space of a pre-trained\nvariational autoencoder, the model achieves a 220 times parameter reduction\ncompared to state-of-the-art systems while delivering 52 times faster\ninference. Experimental evaluation demonstrates competitive performance with\nonly 15M parameters, outperforming OpenAI Jukebox in production quality and\ncontent unity while maintaining reasonable musical coherence. The\nultra-lightweight architecture enables real-time deployment on consumer\nhardware, making AI-assisted music creation accessible for interactive\napplications and resource-constrained environments.", "comment": "6 page, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.19991v1", "cate": "cs.SD", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.17307", "title": "R-Stitch: Dynamic Trajectory Stitching for Efficient Reasoning", "authors": ["Zhuokun Chen", "Zeren Chen", "Jiahao He", "Mingkui Tan", "Jianfei Cai", "Bohan Zhuang"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.17307v2", "summary": "Chain-of-thought (CoT) reasoning enhances the problem-solving capabilities of\nlarge language models by encouraging step-by-step intermediate reasoning during\ninference. While effective, CoT introduces substantial computational overhead\ndue to its reliance on autoregressive decoding over long token sequences.\nExisting acceleration strategies either reduce sequence length through early\nstopping or compressive reward designs, or improve decoding speed via\nspeculative decoding with smaller models. However, speculative decoding suffers\nfrom limited speedup when the agreement between small and large models is low,\nand fails to exploit the potential advantages of small models in producing\nconcise intermediate reasoning. In this paper, we present R-Stitch, a\ntoken-level, confidence-based hybrid decoding framework that accelerates CoT\ninference by switching between a small language model (SLM) and a large\nlanguage model (LLM) along the reasoning trajectory. R-Stitch uses the SLM to\ngenerate tokens by default and delegates to the LLM only when the SLM's\nconfidence falls below a threshold. This design avoids full-sequence rollback\nand selectively invokes the LLM on uncertain steps, preserving both efficiency\nand answer quality. R-Stitch is model-agnostic, training-free, and compatible\nwith standard decoding pipelines. Experiments on math reasoning benchmarks\ndemonstrate that R-Stitch achieves up to 85\\% reduction in inference latency\nwith negligible accuracy drop, highlighting its practical effectiveness in\naccelerating CoT reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.17307v2", "cate": "cs.LG", "date": "2025-07-23", "updated": "2025-07-24"}
{"id": "2507.17487", "title": "CQE under Epistemic Dependencies: Algorithms and Experiments (extended version)", "authors": ["Lorenzo Marconi", "Flavia Ricci", "Riccardo Rosati"], "categories": ["cs.AI", "cs.DB"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Extended version of paper accepted at the 24th International Semantic Web Conference (ISWC 2025)", "url": "http://arxiv.org/abs/2507.17487v2", "summary": "We investigate Controlled Query Evaluation (CQE) over ontologies, where\ninformation disclosure is regulated by epistemic dependencies (EDs), a family\nof logical rules recently proposed for the CQE framework. In particular, we\ncombine EDs with the notion of optimal GA censors, i.e. maximal sets of ground\natoms that are entailed by the ontology and can be safely revealed. We focus on\nanswering Boolean unions of conjunctive queries (BUCQs) with respect to the\nintersection of all optimal GA censors - an approach that has been shown in\nother contexts to ensure strong security guarantees with favorable\ncomputational behavior. First, we characterize the security of this\nintersection-based approach and identify a class of EDs (namely, full EDs) for\nwhich it remains safe. Then, for a subclass of EDs and for DL-Lite_R\nontologies, we show that answering BUCQs in the above CQE semantics is in AC^0\nin data complexity by presenting a suitable, detailed first-order rewriting\nalgorithm. Finally, we report on experiments conducted in two different\nevaluation scenarios, showing the practical feasibility of our rewriting\nfunction.", "comment": "Extended version of paper accepted at the 24th International Semantic\n  Web Conference (ISWC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.17487v2", "cate": "cs.AI", "date": "2025-07-23", "updated": "2025-07-28"}
{"id": "2507.20036", "title": "Improving Audio Classification by Transitioning from Zero- to Few-Shot", "authors": ["James Taylor", "Wolfgang Mack"], "categories": ["cs.SD", "cs.LG"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Submitted to Interspeech 2025", "url": "http://arxiv.org/abs/2507.20036v1", "summary": "State-of-the-art audio classification often employs a zero-shot approach,\nwhich involves comparing audio embeddings with embeddings from text describing\nthe respective audio class. These embeddings are usually generated by neural\nnetworks trained through contrastive learning to align audio and text\nrepresentations. Identifying the optimal text description for an audio class is\nchallenging, particularly when the class comprises a wide variety of sounds.\nThis paper examines few-shot methods designed to improve classification\naccuracy beyond the zero-shot approach. Specifically, audio embeddings are\ngrouped by class and processed to replace the inherently noisy text embeddings.\nOur results demonstrate that few-shot classification typically outperforms the\nzero-shot baseline.", "comment": "Submitted to Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.20036v1", "cate": "cs.SD", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21075", "title": "Can LLMs Reason About Trust?: A Pilot Study", "authors": ["Anushka Debnath", "Stephen Cranefield", "Emiliano Lorini", "Bastin Tony Roy Savarimuthu"], "categories": ["cs.HC", "cs.CL", "cs.CY", "cs.MA"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      17 pages, 5 figures, 3 tables Accepted for presentation as a full paper at the COINE 2025 workshop at AAMAS 2025 see this https URL", "url": "http://arxiv.org/abs/2507.21075v1", "summary": "In human society, trust is an essential component of social attitude that\nhelps build and maintain long-term, healthy relationships which creates a\nstrong foundation for cooperation, enabling individuals to work together\neffectively and achieve shared goals. As many human interactions occur through\nelectronic means such as using mobile apps, the potential arises for AI systems\nto assist users in understanding the social state of their relationships. In\nthis paper we investigate the ability of Large Language Models (LLMs) to reason\nabout trust between two individuals in an environment which requires fostering\ntrust relationships. We also assess whether LLMs are capable of inducing trust\nby role-playing one party in a trust based interaction and planning actions\nwhich can instil trust.", "comment": "17 pages, 5 figures, 3 tables Accepted for presentation as a full\n  paper at the COINE 2025 workshop at AAMAS 2025 see\n  https://coin-workshop.github.io/coine-2025-detroit/accepted_for_presentation.html", "pdf_url": "http://arxiv.org/pdf/2507.21075v1", "cate": "cs.HC", "date": "2025-06-11", "updated": "2025-06-11"}
{"id": "2507.18576", "title": "SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\\circ}$ Law", "authors": ["Shanghai AI Lab", ":", "Yicheng Bao", "Guanxu Chen", "Mingkang Chen", "Yunhao Chen", "Chiyu Chen", "Lingjie Chen", "Sirui Chen", "Xinquan Chen", "Jie Cheng", "Yu Cheng", "Dengke Deng", "Yizhuo Ding", "Dan Ding", "Xiaoshan Ding", "Yi Ding", "Zhichen Dong", "Lingxiao Du", "Yuyu Fan", "Xinshun Feng", "Yanwei Fu", "Yuxuan Gao", "Ruijun Ge", "Tianle Gu", "Lujun Gui", "Jiaxuan Guo", "Qianxi He", "Yuenan Hou", "Xuhao Hu", "Hong Huang", "Kaichen Huang", "Shiyang Huang", "Yuxian Jiang", "Shanzhe Lei", "Jie Li", "Lijun Li", "Hao Li", "Juncheng Li", "Xiangtian Li", "Yafu Li", "Lingyu Li", "Xueyan Li", "Haotian Liang", "Dongrui Liu", "Qihua Liu", "Zhixuan Liu", "Bangwei Liu", "Huacan Liu", "Yuexiao Liu", "Zongkai Liu", "Chaochao Lu", "Yudong Lu", "Xiaoya Lu", "Zhenghao Lu", "Qitan Lv", "Caoyuan Ma", "Jiachen Ma", "Xiaoya Ma", "Zhongtian Ma", "Lingyu Meng", "Ziqi Miao", "Yazhe Niu", "Yuezhang Peng", "Yuan Pu", "Han Qi", "Chen Qian", "Xingge Qiao", "Jingjing Qu", "Jiashu Qu", "Wanying Qu", "Wenwen Qu", "Xiaoye Qu", "Qihan Ren", "Qingnan Ren", "Qingyu Ren", "Jing Shao", "Wenqi Shao", "Shuai Shao", "Dongxing Shi", "Xin Song", "Xinhao Song", "Yan Teng", "Xuan Tong", "Yingchun Wang", "Xuhong Wang", "Shujie Wang", "Xin Wang", "Yige Wang", "Yixu Wang", "Yuanfu Wang", "Futing Wang", "Ruofan Wang", "Wenjie Wang", "Yajie Wang", "Muhao Wei", "Xiaoyu Wen", "Fenghua Weng", "Yuqi Wu", "Yingtong Xiong", "Xingcheng Xu", "Chao Yang", "Yue Yang", "Yang Yao", "Yulei Ye", "Zhenyun Yin", "Yi Yu", "Bo Zhang", "Qiaosheng Zhang", "Jinxuan Zhang", "Yexin Zhang", "Yinqiang Zheng", "Hefeng Zhou", "Zhanhui Zhou", "Pengyu Zhu", "Qingzi Zhu", "Yubo Zhu", "Bowen Zhou"], "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      47 pages, 18 figures, authors are listed in alphabetical order by their last names; v2 modifies minor issues", "url": "http://arxiv.org/abs/2507.18576v2", "summary": "We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that\ndemonstrates the coevolution of capabilities and safety. It is developed by our\nproposed SafeLadder framework, which incorporates large-scale, progressive,\nsafety-oriented reinforcement learning post-training, supported by a suite of\nmulti-principled verifiers. Unlike previous alignment methods such as RLHF that\nsimply learn human preferences, SafeLadder enables SafeWork-R1 to develop\nintrinsic safety reasoning and self-reflection abilities, giving rise to safety\n`aha' moments. Notably, SafeWork-R1 achieves an average improvement of\n$46.54\\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks\nwithout compromising general capabilities, and delivers state-of-the-art safety\nperformance compared to leading proprietary models such as GPT-4.1 and Claude\nOpus 4. To further bolster its reliability, we implement two distinct\ninference-time intervention methods and a deliberative search mechanism,\nenforcing step-level verification. Finally, we further develop\nSafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and\nSafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and\ncapability can co-evolve synergistically, highlighting the generalizability of\nour framework in building robust, reliable, and trustworthy general-purpose AI.", "comment": "47 pages, 18 figures, authors are listed in alphabetical order by\n  their last names; v2 modifies minor issues", "pdf_url": "http://arxiv.org/pdf/2507.18576v2", "cate": "cs.AI", "date": "2025-07-24", "updated": "2025-07-28"}
{"id": "2507.20052", "title": "Improving Deep Learning-based Respiratory Sound Analysis with Frequency Selection and Attention Mechanism", "authors": ["Nouhaila Fraihi", "Ouassim Karrakchou", "Mounir Ghogho"], "categories": ["cs.SD", "cs.LG"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20052v1", "summary": "Accurate classification of respiratory sounds requires deep learning models\nthat effectively capture fine-grained acoustic features and long-range temporal\ndependencies. Convolutional Neural Networks (CNNs) are well-suited for\nextracting local time-frequency patterns but are limited in modeling global\ncontext. In contrast, transformer-based models can capture long-range\ndependencies, albeit with higher computational demands. To address these\nlimitations, we propose a compact CNN-Temporal Self-Attention (CNN-TSA) network\nthat integrates lightweight self-attention into an efficient CNN backbone.\nCentral to our approach is a Frequency Band Selection (FBS) module that\nsuppresses noisy and non-informative frequency regions, substantially improving\naccuracy and reducing FLOPs by up to 50%. We also introduce age-specific models\nto enhance robustness across diverse patient groups. Evaluated on the\nSPRSound-2022/2023 and ICBHI-2017 lung sound datasets, CNN-TSA with FBS sets\nnew benchmarks on SPRSound and achieves state-of-the-art performance on ICBHI,\nall with a significantly smaller computational footprint. Furthermore,\nintegrating FBS into an existing transformer baseline yields a new record on\nICBHI, confirming FBS as an effective drop-in enhancement. These results\ndemonstrate that our framework enables reliable, real-time respiratory sound\nanalysis suitable for deployment in resource-constrained settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20052v1", "cate": "cs.SD", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21089", "title": "Emotionally Aware Moderation: The Potential of Emotion Monitoring in Shaping Healthier Social Media Conversations", "authors": ["Xiaotian Su", "Naim Zierau", "Soomin Kim", "April Yi Wang", "Thiemo Wambsganss"], "categories": ["cs.HC", "cs.CL"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21089v1", "summary": "Social media platforms increasingly employ proactive moderation techniques,\nsuch as detecting and curbing toxic and uncivil comments, to prevent the spread\nof harmful content. Despite these efforts, such approaches are often criticized\nfor creating a climate of censorship and failing to address the underlying\ncauses of uncivil behavior. Our work makes both theoretical and practical\ncontributions by proposing and evaluating two types of emotion monitoring\ndashboards to users' emotional awareness and mitigate hate speech. In a study\ninvolving 211 participants, we evaluate the effects of the two mechanisms on\nuser commenting behavior and emotional experiences. The results reveal that\nthese interventions effectively increase users' awareness of their emotional\nstates and reduce hate speech. However, our findings also indicate potential\nunintended effects, including increased expression of negative emotions (Angry,\nFear, and Sad) when discussing sensitive issues. These insights provide a basis\nfor further research on integrating proactive emotion regulation tools into\nsocial media platforms to foster healthier digital interactions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21089v1", "cate": "cs.HC", "date": "2025-06-24", "updated": "2025-06-24"}
{"id": "2307.13697", "title": "Benchmarking and Analyzing Generative Data for Visual Recognition", "authors": ["Bo Li", "Haotian Liu", "Liangyu Chen", "Yong Jae Lee", "Chunyuan Li", "Ziwei Liu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2025", "url": "http://arxiv.org/abs/2307.13697v2", "summary": "Advancements in large pre-trained generative models have expanded their\npotential as effective data generators in visual recognition. This work delves\ninto the impact of generative images, primarily comparing paradigms that\nharness external data (\\ie generative \\vs retrieval \\vs original).\n  Our key contributions are: \\textbf{1) GenBench Construction:} We devise\n\\textbf{GenBench}, a broad benchmark comprising 22 datasets with 2548\ncategories, to appraise generative data across various visual recognition\ntasks. \\textbf{2) CLER Score:} To address the insufficient correlation of\nexisting metrics (\\eg, FID, CLIP score) with downstream recognition\nperformance, we propose \\textbf{CLER}, a training-free metric indicating\ngenerative data's efficiency for recognition tasks prior to training.\n\\textbf{3) New Baselines:} Comparisons of generative data with retrieved data\nfrom the same external pool help to elucidate the unique traits of generative\ndata. \\textbf{4) External Knowledge Injection:} By fine-tuning special token\nembeddings for each category via Textual Inversion, performance improves across\n17 datasets, except when dealing with low-resolution reference images.\n  Our exhaustive benchmark and analysis spotlight generative data's promise in\nvisual recognition, while identifying key challenges for future investigation.", "comment": "Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI), 2025", "pdf_url": "http://arxiv.org/pdf/2307.13697v2", "cate": "cs.CV", "date": "2023-07-25", "updated": "2025-07-28"}
{"id": "2507.20058", "title": "Predicting Parkinson's Disease Progression Using Statistical and Neural Mixed Effects Models: A Comparative Study on Longitudinal Biomarkers", "authors": ["Ran Tong", "Lanruo Wang", "Tong Wang", "Wei Yan"], "categories": ["stat.ML", "cs.LG", "stat.AP"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      20pages,3 figures,currently under review", "url": "http://arxiv.org/abs/2507.20058v1", "summary": "Predicting Parkinson's Disease (PD) progression is crucial, and voice\nbiomarkers offer a non-invasive method for tracking symptom severity (UPDRS\nscores) through telemonitoring. Analyzing this longitudinal data is challenging\ndue to within-subject correlations and complex, nonlinear patient-specific\nprogression patterns. This study benchmarks LMMs against two advanced hybrid\napproaches: the Generalized Neural Network Mixed Model (GNMM) (Mandel 2021),\nwhich embeds a neural network within a GLMM structure, and the Neural Mixed\nEffects (NME) model (Wortwein 2023), allowing nonlinear subject-specific\nparameters throughout the network. Using the Oxford Parkinson's telemonitoring\nvoice dataset, we evaluate these models' performance in predicting Total UPDRS\nto offer practical guidance for PD research and clinical applications.", "comment": "20pages,3 figures,currently under review", "pdf_url": "http://arxiv.org/pdf/2507.20058v1", "cate": "stat.ML", "date": "2025-07-26", "updated": "2025-07-26"}
{"id": "2507.21170", "title": "OneShield -- the Next Generation of LLM Guardrails", "authors": ["Chad DeLuca", "Anna Lisa Gentile", "Shubhi Asthana", "Bing Zhang", "Pawan Chowdhary", "Kellen Cheng", "Basel Shbita", "Pengyuan Li", "Guang-Jie Ren", "Sandeep Gopisetty"], "categories": ["cs.CR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21170v1", "summary": "The rise of Large Language Models has created a general excitement about the\ngreat potential for a myriad of applications. While LLMs offer many\npossibilities, questions about safety, privacy, and ethics have emerged, and\nall the key actors are working to address these issues with protective measures\nfor their own models and standalone solutions. The constantly evolving nature\nof LLMs makes the task of universally shielding users against their potential\nrisks extremely challenging, and one-size-fits-all solutions unfeasible. In\nthis work, we propose OneShield, our stand-alone, model-agnostic and\ncustomizable solution to safeguard LLMs. OneShield aims to provide facilities\nfor defining risk factors, expressing and declaring contextual safety and\ncompliance policies, and mitigating LLM risks, with a focus on each specific\ncustomer. We describe the implementation of the framework, the scalability\nconsiderations and provide usage statistics of OneShield since its first\ndeployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21170v1", "cate": "cs.CR", "date": "2025-07-25", "updated": "2025-07-25"}
{"id": "2309.10370", "title": "Geometric structure of shallow neural networks and constructive ${\\mathcal L}^2$ cost minimization", "authors": ["Thomas Chen", "Patrícia Muñoz Ewald"], "categories": ["cs.LG", "cs.AI", "math-ph", "math.MP", "math.OC", "stat.ML", "57R70, 62M45"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      AMS Latex, 25 pages. Exposition has been streamlined", "url": "http://arxiv.org/abs/2309.10370v3", "summary": "In this paper, we approach the problem of cost (loss) minimization in\nunderparametrized shallow ReLU networks through the explicit construction of\nupper bounds which appeal to the structure of classification data, without use\nof gradient descent. A key focus is on elucidating the geometric structure of\napproximate and precise minimizers. We consider an $\\mathcal{L}^2$ cost\nfunction, input space $\\mathbb{R}^M$, output space ${\\mathbb R}^Q$ with $Q\\leq\nM$, and training input sample size that can be arbitrarily large. We prove an\nupper bound on the minimum of the cost function of order $O(\\delta_P)$ where\n$\\delta_P$ measures the signal-to-noise ratio of training data. In the special\ncase $M=Q$, we explicitly determine an exact degenerate local minimum of the\ncost function, and show that the sharp value differs from the upper bound\nobtained for $Q\\leq M$ by a relative error $O(\\delta_P^2)$. The proof of the\nupper bound yields a constructively trained network; we show that it metrizes a\nparticular $Q$-dimensional subspace in the input space ${\\mathbb R}^M$. We\ncomment on the characterization of the global minimum of the cost function in\nthe given context.", "comment": "AMS Latex, 25 pages. Exposition has been streamlined", "pdf_url": "http://arxiv.org/pdf/2309.10370v3", "cate": "cs.LG", "date": "2023-09-19", "updated": "2025-07-26"}
{"id": "2507.20161", "title": "Practical Multi-Task Learning for Rare Conversions in Ad Tech", "authors": ["Yuval Dishi", "Ophir Friedler", "Yonatan Karni", "Natalia Silberstein", "Yulia Stolin"], "categories": ["cs.IR", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted to RecSys 2025", "url": "http://arxiv.org/abs/2507.20161v1", "summary": "We present a Multi-Task Learning (MTL) approach for improving predictions for\nrare (e.g., <1%) conversion events in online advertising. The conversions are\nclassified into \"rare\" or \"frequent\" types based on historical statistics. The\nmodel learns shared representations across all signals while specializing\nthrough separate task towers for each type. The approach was tested and fully\ndeployed to production, demonstrating consistent improvements in both offline\n(0.69% AUC lift) and online KPI performance metric (2% Cost per Action\nreduction).", "comment": "Accepted to RecSys 2025", "pdf_url": "http://arxiv.org/pdf/2507.20161v1", "cate": "cs.IR", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.21183", "title": "MaPPO: Maximum a Posteriori Preference Optimization with Prior Knowledge", "authors": ["Guangchen Lan", "Sipeng Zhang", "Tianle Wang", "Yuwei Zhang", "Daoan Zhang", "Xinpeng Wei", "Xiaoman Pan", "Hongming Zhang", "Dong-Jun Han", "Christopher G. Brinton"], "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.7"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21183v1", "summary": "As the era of large language models (LLMs) on behalf of users unfolds,\nPreference Optimization (PO) methods have become a central approach to aligning\nLLMs with human preferences and improving performance. We propose Maximum a\nPosteriori Preference Optimization (MaPPO), a framework for learning from\npreferences that explicitly incorporates prior reward knowledge into the\noptimization objective. While existing methods such as Direct Preference\nOptimization (DPO) and its variants treat preference learning as a Maximum\nLikelihood Estimation (MLE) problem, MaPPO extends this paradigm by integrating\nprior reward estimates into a principled Maximum a Posteriori (MaP) objective.\nThis not only generalizes DPO and its variants, but also enhances alignment by\nmitigating the oversimplified binary classification of responses. More\nimportantly, MaPPO introduces no additional hyperparameter, and supports\npreference optimization in both offline and online settings. In addition, MaPPO\ncan be used as a plugin with consistent improvement on DPO variants, including\nwidely used SimPO, IPO, and CPO. Extensive empirical evaluations of different\nmodel sizes and model series on three standard benchmarks, including MT-Bench,\nAlpacaEval 2.0, and Arena-Hard, demonstrate consistent improvements in\nalignment performance without sacrificing computational efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21183v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2311.10887", "title": "Point Cloud Self-supervised Learning via 3D to Multi-view Masked Learner", "authors": ["Zhimin Chen", "Xuewei Chen", "Xiao Guo", "Yingwei Li", "Longlong Jing", "Liang Yang", "Bing Li"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2311.10887v2", "summary": "Recently, multi-modal masked autoencoders (MAE) has been introduced in 3D\nself-supervised learning, offering enhanced feature learning by leveraging both\n2D and 3D data to capture richer cross-modal representations. However, these\napproaches have two limitations: (1) they inefficiently require both 2D and 3D\nmodalities as inputs, even though the inherent multi-view properties of 3D\npoint clouds already contain 2D modality. (2) input 2D modality causes the\nreconstruction learning to unnecessarily rely on visible 2D information,\nhindering 3D geometric representation learning. To address these challenges, we\npropose a 3D to Multi-View Learner (Multi-View ML) that only utilizes 3D\nmodalities as inputs and effectively capture rich spatial information in 3D\npoint clouds. Specifically, we first project 3D point clouds to multi-view 2D\nimages at the feature level based on 3D-based pose. Then, we introduce two\ncomponents: (1) a 3D to multi-view autoencoder that reconstructs point clouds\nand multi-view images from 3D and projected 2D features; (2) a multi-scale\nmulti-head (MSMH) attention mechanism that facilitates local-global information\ninteractions in each decoder transformer block through attention heads at\nvarious scales. Additionally, a novel two-stage self-training strategy is\nproposed to align 2D and 3D representations. Our method outperforms\nstate-of-the-art counterparts across various downstream tasks, including 3D\nclassification, part segmentation, and object detection.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2311.10887v2", "cate": "cs.CV", "date": "2023-11-17", "updated": "2025-07-27"}
{"id": "2507.20284", "title": "Controllable Feature Whitening for Hyperparameter-Free Bias Mitigation", "authors": ["Yooshin Cho", "Hanbyel Cho", "Janghyeon Lee", "HyeongGwon Hong", "Jaesung Ahn", "Junmo Kim"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025 (Poster)", "url": "http://arxiv.org/abs/2507.20284v1", "summary": "As the use of artificial intelligence rapidly increases, the development of\ntrustworthy artificial intelligence has become important. However, recent\nstudies have shown that deep neural networks are susceptible to learn spurious\ncorrelations present in datasets. To improve the reliability, we propose a\nsimple yet effective framework called controllable feature whitening. We\nquantify the linear correlation between the target and bias features by the\ncovariance matrix, and eliminate it through the whitening module. Our results\nsystemically demonstrate that removing the linear correlations between features\nfed into the last linear classifier significantly mitigates the bias, while\navoiding the need to model intractable higher-order dependencies. A particular\nadvantage of the proposed method is that it does not require regularization\nterms or adversarial learning, which often leads to unstable optimization in\npractice. Furthermore, we show that two fairness criteria, demographic parity\nand equalized odds, can be effectively handled by whitening with the\nre-weighted covariance matrix. Consequently, our method controls the trade-off\nbetween the utility and fairness of algorithms by adjusting the weighting\ncoefficient. Finally, we validate that our method outperforms existing\napproaches on four benchmark datasets: Corrupted CIFAR-10, Biased FFHQ,\nWaterBirds, and Celeb-A.", "comment": "Accepted to ICCV 2025 (Poster)", "pdf_url": "http://arxiv.org/pdf/2507.20284v1", "cate": "cs.CV", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.21184", "title": "EvoSLD: Automated Neural Scaling Law Discovery With Large Language Models", "authors": ["Haowei Lin", "Xiangyu Wang", "Jianzhu Ma", "Yitao Liang"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21184v1", "summary": "Scaling laws are fundamental mathematical relationships that predict how\nneural network performance evolves with changes in variables such as model\nsize, dataset size, and computational resources. Traditionally, discovering\nthese laws requires extensive human expertise and manual experimentation. We\nintroduce EvoSLD, an automated framework for Scaling Law Discovery (SLD) that\nleverages evolutionary algorithms guided by Large Language Models (LLMs) to\nco-evolve symbolic expressions and their optimization routines. Formulated to\nhandle scaling variables, control variables, and response metrics across\ndiverse experimental settings, EvoSLD searches for parsimonious, universal\nfunctional forms that minimize fitting errors on grouped data subsets.\nEvaluated on five real-world scenarios from recent literature, EvoSLD\nrediscovers exact human-derived laws in two cases and surpasses them in others,\nachieving up to orders-of-magnitude reductions in normalized mean squared error\non held-out test sets. Compared to baselines like symbolic regression and\nablated variants, EvoSLD demonstrates superior accuracy, interpretability, and\nefficiency, highlighting its potential to accelerate AI research. Code is\navailable at https://github.com/linhaowei1/SLD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21184v1", "cate": "cs.LG", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2312.09857", "title": "Deep Unsupervised Domain Adaptation for Time Series Classification: a Benchmark", "authors": ["Hassan Ismail Fawaz", "Ganesh Del Grosso", "Tanguy Kerdoncuff", "Aurelie Boisbunon", "Illyyne Saffar"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in Data Mining and Knowledge Discovery", "url": "http://arxiv.org/abs/2312.09857v3", "summary": "Unsupervised Domain Adaptation (UDA) aims to harness labeled source data to\ntrain models for unlabeled target data. Despite extensive research in domains\nlike computer vision and natural language processing, UDA remains underexplored\nfor time series data, which has widespread real-world applications ranging from\nmedicine and manufacturing to earth observation and human activity recognition.\nOur paper addresses this gap by introducing a comprehensive benchmark for\nevaluating UDA techniques for time series classification, with a focus on deep\nlearning methods. We provide seven new benchmark datasets covering various\ndomain shifts and temporal dynamics, facilitating fair and standardized UDA\nmethod assessments with state of the art neural network backbones (e.g.\nInception) for time series data. This benchmark offers insights into the\nstrengths and limitations of the evaluated approaches while preserving the\nunsupervised nature of domain adaptation, making it directly applicable to\npractical problems. Our paper serves as a vital resource for researchers and\npractitioners, advancing domain adaptation solutions for time series data and\nfostering innovation in this critical field. The implementation code of this\nbenchmark is available at https://github.com/EricssonResearch/UDA-4-TSC.", "comment": "Published in Data Mining and Knowledge Discovery", "pdf_url": "http://arxiv.org/pdf/2312.09857v3", "cate": "cs.LG", "date": "2023-12-15", "updated": "2025-07-25"}
{"id": "2507.20403", "title": "A General Framework for Estimating Preferences Using Response Time Data", "authors": ["Federico Echenique", "Alireza Fallah", "Michael I. Jordan"], "categories": ["econ.TH", "cs.LG"], "primary_category": "Subjects:       Theoretical Economics (econ.TH)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20403v1", "summary": "We propose a general methodology for recovering preference parameters from\ndata on choices and response times. Our methods yield estimates with fast\n($1/n$ for $n$ data points) convergence rates when specialized to the popular\nDrift Diffusion Model (DDM), but are broadly applicable to generalizations of\nthe DDM as well as to alternative models of decision making that make use of\nresponse time data. The paper develops an empirical application to an\nexperiment on intertemporal choice, showing that the use of response times\ndelivers predictive accuracy and matters for the estimation of economically\nrelevant parameters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20403v1", "cate": "econ.TH", "date": "2025-07-27", "updated": "2025-07-27"}
{"id": "2507.21257", "title": "CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting", "authors": ["David Maria Schmidt", "Raoul Schubert", "Philipp Cimiano"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Research Track, 24th International Semantic Web Conference (ISWC 2025), November 2-6, 2025, Nara, Japan", "url": "http://arxiv.org/abs/2507.21257v1", "summary": "Language interpretation is a compositional process, in which the meaning of\nmore complex linguistic structures is inferred from the meaning of their parts.\nLarge language models possess remarkable language interpretation capabilities\nand have been successfully applied to interpret questions by mapping them to\nSPARQL queries. An open question is how systematic this interpretation process\nis. Toward this question, in this paper, we propose a benchmark for\ninvestigating to what extent the abilities of LLMs to interpret questions are\nactually compositional. For this, we generate three datasets of varying\ndifficulty based on graph patterns in DBpedia, relying on Lemon lexica for\nverbalization. Our datasets are created in a very controlled fashion in order\nto test the ability of LLMs to interpret structurally complex questions, given\nthat they have seen the atomic building blocks. This allows us to evaluate to\nwhat degree LLMs are able to interpret complex questions for which they\n\"understand\" the atomic parts. We conduct experiments with models of different\nsizes using both various prompt and few-shot optimization techniques as well as\nfine-tuning. Our results show that performance in terms of macro $F_1$ degrades\nfrom $0.45$ over $0.26$ down to $0.09$ with increasing deviation from the\nsamples optimized on. Even when all necessary information was provided to the\nmodel in the input, the $F_1$ scores do not exceed $0.57$ for the dataset of\nlowest complexity. We thus conclude that LLMs struggle to systematically and\ncompositionally interpret questions and map them into SPARQL queries.", "comment": "Research Track, 24th International Semantic Web Conference (ISWC\n  2025), November 2-6, 2025, Nara, Japan", "pdf_url": "http://arxiv.org/pdf/2507.21257v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2402.02339", "title": "Uncertainty-Aware Testing-Time Optimization for 3D Human Pose Estimation", "authors": ["Ti Wang", "Mengyuan Liu", "Hong Liu", "Bin Ren", "Yingxuan You", "Wenhao Li", "Nicu Sebe", "Xia Li"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Transactions on Multimedia. Open sourced", "url": "http://arxiv.org/abs/2402.02339v2", "summary": "Although data-driven methods have achieved success in 3D human pose\nestimation, they often suffer from domain gaps and exhibit limited\ngeneralization. In contrast, optimization-based methods excel in fine-tuning\nfor specific cases but are generally inferior to data-driven methods in overall\nperformance. We observe that previous optimization-based methods commonly rely\non a projection constraint, which only ensures alignment in 2D space,\npotentially leading to the overfitting problem. To address this, we propose an\nUncertainty-Aware testing-time Optimization (UAO) framework, which keeps the\nprior information of the pre-trained model and alleviates the overfitting\nproblem using the uncertainty of joints. Specifically, during the training\nphase, we design an effective 2D-to-3D network for estimating the corresponding\n3D pose while quantifying the uncertainty of each 3D joint. For optimization\nduring testing, the proposed optimization framework freezes the pre-trained\nmodel and optimizes only a latent state. Projection loss is then employed to\nensure the generated poses are well aligned in 2D space for high-quality\noptimization. Furthermore, we utilize the uncertainty of each joint to\ndetermine how much each joint is allowed for optimization. The effectiveness\nand superiority of the proposed framework are validated through extensive\nexperiments on challenging datasets: Human3.6M, MPI-INF-3DHP, and 3DPW.\nNotably, our approach outperforms the previous best result by a large margin of\n5.5\\% on Human3.6M. Code is available at\n\\href{https://github.com/xiu-cs/UAO-Pose3D}{https://github.com/xiu-cs/UAO-Pose3D}.", "comment": "Accepted by IEEE Transactions on Multimedia. Open sourced", "pdf_url": "http://arxiv.org/pdf/2402.02339v2", "cate": "cs.CV", "date": "2024-02-04", "updated": "2025-07-27"}
{"id": "2507.20454", "title": "Frequency-Aware Autoregressive Modeling for Efficient High-Resolution Image Synthesis", "authors": ["Zhuokun Chen", "Jugang Fan", "Zhuowei Yu", "Bohan Zhuang", "Mingkui Tan"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20454v1", "summary": "Visual autoregressive modeling, based on the next-scale prediction paradigm,\nexhibits notable advantages in image quality and model scalability over\ntraditional autoregressive and diffusion models. It generates images by\nprogressively refining resolution across multiple stages. However, the\ncomputational overhead in high-resolution stages remains a critical challenge\ndue to the substantial number of tokens involved. In this paper, we introduce\nSparseVAR, a plug-and-play acceleration framework for next-scale prediction\nthat dynamically excludes low-frequency tokens during inference without\nrequiring additional training. Our approach is motivated by the observation\nthat tokens in low-frequency regions have a negligible impact on image quality\nin high-resolution stages and exhibit strong similarity with neighboring\ntokens. Additionally, we observe that different blocks in the next-scale\nprediction model focus on distinct regions, with some concentrating on\nhigh-frequency areas. SparseVAR leverages these insights by employing\nlightweight MSE-based metrics to identify low-frequency tokens while preserving\nthe fidelity of excluded regions through a small set of uniformly sampled\nanchor tokens. By significantly reducing the computational cost while\nmaintaining high image generation quality, SparseVAR achieves notable\nacceleration in both HART and Infinity. Specifically, SparseVAR achieves up to\na 2 times speedup with minimal quality degradation in Infinity-2B.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20454v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21276", "title": "LeMix: Unified Scheduling for LLM Training and Inference on Multi-GPU Systems", "authors": ["Yufei Li", "Zexin Li", "Yinglun Zhu", "Cong Liu"], "categories": ["cs.AI", "cs.CL", "cs.DC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by RTSS 2025", "url": "http://arxiv.org/abs/2507.21276v1", "summary": "Modern deployment of large language models (LLMs) frequently involves both\ninference serving and continuous retraining to stay aligned with evolving data\nand user feedback. Common practices separate these workloads onto distinct\nservers in isolated phases, causing substantial inefficiencies (e.g., GPU\nidleness) and delayed adaptation to new data in distributed settings. Our\nempirical analysis reveals that these inefficiencies stem from dynamic request\narrivals during serving and workload heterogeneity in pipeline-parallel\ntraining. To address these challenges, we propose LeMix, a system for\nco-locating and managing concurrent LLM serving and training workloads. LeMix\nintegrates offline profiling, execution prediction mechanisms, and runtime\nscheduling to dynamically adapt resource allocation based on workload\ncharacteristics and system conditions. By understanding task-specific behaviors\nand co-execution interference across shared nodes, LeMix improves utilization\nand serving quality without compromising serving responsiveness. Our evaluation\nshows that LeMix improves throughput by up to 3.53x, reduces inference loss by\nup to 0.61x, and delivers up to 2.12x higher response time SLO attainment over\ntraditional separate setups. To our knowledge, this is the first work to\nuncover and exploit the opportunities of joint LLM inference and training,\npaving the way for more resource-efficient deployment of LLMs in production\nenvironments.", "comment": "Accepted by RTSS 2025", "pdf_url": "http://arxiv.org/pdf/2507.21276v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2402.03328", "title": "Visual Enumeration Remains Challenging for Multimodal Generative AI", "authors": ["Alberto Testolin", "Kuinan Hou", "Marco Zorzi"], "categories": ["cs.CV", "cs.AI", "cs.NE"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.03328v3", "summary": "Many animal species can approximately judge the number of objects in a visual\nscene at a single glance, and humans can further determine the exact\ncardinality of a set by deploying systematic counting procedures. In contrast,\nit has been observed that even state-of-the-art AI systems have very limited\nenumeration skills. In this work, we propose two benchmark tasks inspired by\ncognitive science that allow to precisely evaluate the visual enumeration\ncapabilities of multimodal foundation models, thereby providing an objective\nmeasure of their number sense and counting level. We consider popular visual\nquestion answering models (BLIP, LLaVA and ViLT) as well as advanced\nimage-to-text (Gemini, GPT and Qwen) and text-to-image (DALL-E, FLUX and Stable\nDiffusion) AI systems. Our analyses show that even the most advanced models\ncannot reliably name the number of objects in simple visual stimuli or generate\nimages containing a target number of items, as indexed by their low accuracy in\nboth types of tasks. Especially for numbers outside the subitizing range, their\nresponses are often far from the target numerosity, and, in stark contrast with\nhuman behavior, in many cases the distribution of errors depends on the object\ncategory. We also observe some striking mistakes with small numbers. Our\nfindings demonstrate that developing an intuitive visual understanding of\nnumber remains challenging for AI models and that merely increasing model size\nmight not be a viable strategy to promote the emergence of systematic counting\nskills. We release the full code of our benchmark to facilitate the evaluation\nof enumeration skills in future AI systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.03328v3", "cate": "cs.CV", "date": "2024-01-09", "updated": "2025-07-28"}
{"id": "2507.20463", "title": "Operator Inference Aware Quadratic Manifolds with Isotropic Reduced Coordinates for Nonintrusive Model Reduction", "authors": ["Paul Schwerdtner", "Prakash Mohan", "Julie Bessac", "Marc T. Henry de Frahan", "Benjamin Peherstorfer"], "categories": ["math.DS", "cs.LG", "cs.NA", "math.NA", "35A01, 65L10, 65L12, 65L20, 65L70"], "primary_category": "Subjects:       Dynamical Systems (math.DS)", "pdf_link": null, "comments": "Comments:      23 pages, 8 figures", "url": "http://arxiv.org/abs/2507.20463v1", "summary": "Quadratic manifolds for nonintrusive reduced modeling are typically trained\nto minimize the reconstruction error on snapshot data, which means that the\nerror of models fitted to the embedded data in downstream learning steps is\nignored. In contrast, we propose a greedy training procedure that takes into\naccount both the reconstruction error on the snapshot data and the prediction\nerror of reduced models fitted to the data. Because our procedure learns\nquadratic manifolds with the objective of achieving accurate reduced models, it\navoids oscillatory and other non-smooth embeddings that can hinder learning\naccurate reduced models. Numerical experiments on transport and turbulent flow\nproblems show that quadratic manifolds trained with the proposed greedy\napproach lead to reduced models with up to two orders of magnitude higher\naccuracy than quadratic manifolds trained with respect to the reconstruction\nerror alone.", "comment": "23 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.20463v1", "cate": "math.DS", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21389", "title": "Teaching Language Models To Gather Information Proactively", "authors": ["Tenghao Huang", "Sihao Chen", "Muhao Chen", "Jonathan May", "Longqi Yang", "Mengting Wan", "Pei Zhou"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21389v1", "summary": "Large language models (LLMs) are increasingly expected to function as\ncollaborative partners, engaging in back-and-forth dialogue to solve complex,\nambiguous problems. However, current LLMs often falter in real-world settings,\ndefaulting to passive responses or narrow clarifications when faced with\nincomplete or under-specified prompts, falling short of proactively gathering\nthe missing information that is crucial for high-quality solutions. In this\nwork, we introduce a new task paradigm: proactive information gathering, where\nLLMs must identify gaps in the provided context and strategically elicit\nimplicit user knowledge through targeted questions. To systematically study and\ntrain this capability, we design a scalable framework that generates partially\nspecified, real-world tasks, masking key information and simulating authentic\nambiguity. Within this setup, our core innovation is a reinforcement finetuning\nstrategy that rewards questions that elicit genuinely new, implicit user\ninformation -- such as hidden domain expertise or fine-grained requirements --\nthat would otherwise remain unspoken. Experiments demonstrate that our trained\nQwen-2.5-7B model significantly outperforms o3-mini by 18% on automatic\nevaluation metrics. More importantly, human evaluation reveals that\nclarification questions and final outlines generated by our model are favored\nby human annotators by 42% and 28% respectively. Together, these results\nhighlight the value of proactive clarification in elevating LLMs from passive\ntext generators to genuinely collaborative thought partners.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21389v1", "cate": "cs.AI", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2402.08290", "title": "The Effect of Data Poisoning on Counterfactual Explanations", "authors": ["André Artelt", "Shubham Sharma", "Freddy Lecué", "Barbara Hammer"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.08290v4", "summary": "Counterfactual explanations are a widely used approach for examining the\npredictions of black-box systems. They can offer the opportunity for\ncomputational recourse by suggesting actionable changes on how to alter the\ninput to obtain a different (i.e., more favorable) system output. However,\nrecent studies have pointed out their susceptibility to various forms of\nmanipulation.\n  This work studies the vulnerability of counterfactual explanations to data\npoisoning. We formally introduce and investigate data poisoning in the context\nof counterfactual explanations for increasing the cost of recourse on three\ndifferent levels: locally for a single instance, a sub-group of instances, or\nglobally for all instances. In this context, we formally introduce and\ncharacterize data poisonings, from which we derive and investigate a general\ndata poisoning mechanism. We demonstrate the impact of such data poisoning in\nthe critical real-world application of explaining event detections in water\ndistribution networks. Additionally, we conduct an extensive empirical\nevaluation, demonstrating that state-of-the-art counterfactual generation\nmethods and toolboxes are vulnerable to such data poisoning. Furthermore, we\nfind that existing defense methods fail to detect those poisonous samples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.08290v4", "cate": "cs.LG", "date": "2024-02-13", "updated": "2025-07-28"}
{"id": "2507.20468", "title": "Building crypto portfolios with agentic AI", "authors": ["Antonino Castelli", "Paolo Giudici", "Alessandro Piergallini"], "categories": ["q-fin.PM", "cs.LG", "68T05 (Primary) 91G10, 68T09 (Secondary)", "I.2.1; I.2.6"], "primary_category": "Subjects:       Portfolio Management (q-fin.PM)", "pdf_link": null, "comments": "Comments:      12 pages, 2 figures", "url": "http://arxiv.org/abs/2507.20468v1", "summary": "The rapid growth of crypto markets has opened new opportunities for\ninvestors, but at the same time exposed them to high volatility. To address the\nchallenge of managing dynamic portfolios in such an environment, this paper\npresents a practical application of a multi-agent system designed to\nautonomously construct and evaluate crypto-asset allocations. Using data on\ndaily frequencies of the ten most capitalized cryptocurrencies from 2020 to\n2025, we compare two automated investment strategies. These are a static equal\nweighting strategy and a rolling-window optimization strategy, both implemented\nto maximize the evaluation metrics of the Modern Portfolio Theory (MPT), such\nas Expected Return, Sharpe and Sortino ratios, while minimizing volatility.\nEach step of the process is handled by dedicated agents, integrated through a\ncollaborative architecture in Crew AI. The results show that the dynamic\noptimization strategy achieves significantly better performance in terms of\nrisk-adjusted returns, both in-sample and out-of-sample. This highlights the\nbenefits of adaptive techniques in portfolio management, particularly in\nvolatile markets such as cryptocurrency markets. The following methodology\nproposed also demonstrates how multi-agent systems can provide scalable,\nauditable, and flexible solutions in financial automation.", "comment": "12 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.20468v1", "cate": "q-fin.PM", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.21391", "title": "Multimodal LLMs as Customized Reward Models for Text-to-Image Generation", "authors": ["Shijie Zhou", "Ruiyi Zhang", "Huaisheng Zhu", "Branislav Kveton", "Yufan Zhou", "Jiuxiang Gu", "Jian Chen", "Changyou Chen"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025. Code available at this https URL", "url": "http://arxiv.org/abs/2507.21391v1", "summary": "We introduce LLaVA-Reward, an efficient reward model designed to\nautomatically evaluate text-to-image (T2I) generations across multiple\nperspectives, leveraging pretrained multimodal large language models (MLLMs).\nExisting MLLM-based approaches require instruction-following data for\nsupervised fine-tuning and evaluate generation quality on analyzing text\nresponse, which is time-consuming and difficult to train. To address this\nproblem, we propose LLaVA-Reward, which directly utilizes the hidden states of\nMLLMs given text-image pairs. To enhance the bidirectional interaction between\nvisual and textual representations in decoder-only MLLMs, we further propose\nadding a Skip-connection Cross Attention (SkipCA) module. This design enhances\ntext-image correlation reasoning by connecting early-layer visual features with\nlater-layer hidden representations.In addition, LLaVA-Reward supports different\ntypes of preference data for efficient fine-tuning, including paired preference\ndata and unpaired data. We train LLaVA-Reward on four evaluation perspectives:\ntext-image alignment, fidelity/artifact, safety, and overall ranking. Empirical\nresults demonstrate that LLaVA-Reward outperforms conventional and MLLM-based\nmethods in generating human-aligned scores for automatic evaluations and\ninference-time scaling in text-to-image generations.", "comment": "Accepted at ICCV 2025. Code available at\n  https://github.com/sjz5202/LLaVA-Reward", "pdf_url": "http://arxiv.org/pdf/2507.21391v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2403.14410", "title": "GLC++: Source-Free Universal Domain Adaptation through Global-Local Clustering and Contrastive Affinity Learning", "authors": ["Sanqing Qu", "Tianpei Zou", "Florian Röhrbein", "Cewu Lu", "Guang Chen", "Dacheng Tao", "Changjun Jiang"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      A substantial extension of the CVPR paper \"Upcycling Models under Domain and Category Shift\", recently accepted by IEEE-TPAMI. arXiv admin note: text overlap with arXiv:2303.07110", "url": "http://arxiv.org/abs/2403.14410v2", "summary": "Deep neural networks often exhibit sub-optimal performance under covariate\nand category shifts. Source-Free Domain Adaptation (SFDA) presents a promising\nsolution to this dilemma, yet most SFDA approaches are restricted to closed-set\nscenarios. In this paper, we explore Source-Free Universal Domain Adaptation\n(SF-UniDA) aiming to accurately classify \"known\" data belonging to common\ncategories and segregate them from target-private \"unknown\" data. We propose a\nnovel Global and Local Clustering (GLC) technique, which comprises an adaptive\none-vs-all global clustering algorithm to discern between target classes,\ncomplemented by a local k-NN clustering strategy to mitigate negative transfer.\nDespite the effectiveness, the inherent closed-set source architecture leads to\nuniform treatment of \"unknown\" data, impeding the identification of distinct\n\"unknown\" categories. To address this, we evolve GLC to GLC++, integrating a\ncontrastive affinity learning strategy. We examine the superiority of GLC and\nGLC++ across multiple benchmarks and category shift scenarios. Remarkably, in\nthe most challenging open-partial-set scenarios, GLC and GLC++ surpass GATE by\n16.8\\% and 18.9\\% in H-score on VisDA, respectively. GLC++ enhances the novel\ncategory clustering accuracy of GLC by 4.1\\% in open-set scenarios on\nOffice-Home. Furthermore, the introduced contrastive learning strategy not only\nenhances GLC but also significantly facilitates existing methodologies. The\ncode is available at https://github.com/ispc-lab/GLC-plus.", "comment": "A substantial extension of the CVPR paper \"Upcycling Models under\n  Domain and Category Shift\", recently accepted by IEEE-TPAMI. arXiv admin\n  note: text overlap with arXiv:2303.07110", "pdf_url": "http://arxiv.org/pdf/2403.14410v2", "cate": "cs.CV", "date": "2024-03-21", "updated": "2025-07-26"}
{"id": "2507.20474", "title": "MountainLion: A Multi-Modal LLM-Based Agent System for Interpretable and Adaptive Financial Trading", "authors": ["Siyi Wu", "Zhaoyang Guan", "Leyi Zhao", "Xinyuan Song", "Xinyu Ying", "Hanlin Zhang", "Michele Pak", "Yangfan He", "Yi Xin", "Jianhui Wang", "Tianyu Shi"], "categories": ["q-fin.TR", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Trading and Market Microstructure (q-fin.TR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20474v1", "summary": "Cryptocurrency trading is a challenging task requiring the integration of\nheterogeneous data from multiple modalities. Traditional deep learning and\nreinforcement learning approaches typically demand large training datasets and\nencode diverse inputs into numerical representations, often at the cost of\ninterpretability. Recent progress in large language model (LLM)-based agents\nhas demonstrated the capacity to process multi-modal data and support complex\ninvestment decision-making. Building on these advances, we present\n\\textbf{MountainLion}, a multi-modal, multi-agent system for financial trading\nthat coordinates specialized LLM-based agents to interpret financial data and\ngenerate investment strategies. MountainLion processes textual news,\ncandlestick charts, and trading signal charts to produce high-quality financial\nreports, while also enabling modification of reports and investment\nrecommendations through data-driven user interaction and question answering. A\ncentral reflection module analyzes historical trading signals and outcomes to\ncontinuously refine decision processes, and the system is capable of real-time\nreport analysis, summarization, and dynamic adjustment of investment\nstrategies. Empirical results confirm that MountainLion systematically enriches\ntechnical price triggers with contextual macroeconomic and capital flow\nsignals, providing a more interpretable, robust, and actionable investment\nframework that improves returns and strengthens investor confidence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20474v1", "cate": "q-fin.TR", "date": "2025-07-13", "updated": "2025-07-13"}
{"id": "2507.21420", "title": "ReGATE: Learning Faster and Better with Fewer Tokens in MLLMs", "authors": ["Chaoyu Li", "Yogesh Kulkarni", "Pooyan Fazli"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21420v1", "summary": "The computational cost of training multimodal large language models (MLLMs)\nrapidly increases with the number of tokens involved. Existing efficiency\nmethods primarily target inference and rely on token reduction or merging,\noffering limited benefit during training. In this paper, we propose ReGATE\n(Reference$-$Guided Adaptive Token Elision), an adaptive token pruning method\nfor accelerating MLLM training. Specifically, ReGATE adopts a teacher-student\nframework in which the MLLM being trained serves as the student, and a frozen\nreference large language model (LLM) acts as the teacher. The teacher computes\nper-token reference losses, which are combined with an exponential moving\naverage (EMA) of the student's own difficulty scores. This adaptive\ndifficulty-based scoring enables the selective processing of crucial tokens\nwhile bypassing less informative ones in the forward pass, significantly\nreducing computational overhead. Experiments demonstrate that ReGATE, when\napplied to VideoLLaMA2, matches the peak accuracy of standard training on\nMVBench up to 2$\\times$ faster, using only 35% of the tokens. With additional\ntraining, it even surpasses the baseline on several multimodal benchmarks, all\nwhile reducing the total token count by over 41%. Code and models will be\nreleased soon.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21420v1", "cate": "cs.CV", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2403.18140", "title": "Juru: Legal Brazilian Large Language Model from Reputable Sources", "authors": ["Roseval Malaquias Junior", "Ramon Pires", "Roseli Romero", "Rodrigo Nogueira"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.18140v2", "summary": "The high compute cost associated with pretraining large language models\nlimits their research. Two strategies have emerged to address this issue:\ndomain specialization and pretraining with high-quality data. To explore these\nstrategies, we specialized the Mistral-7B model with 1.9 billion unique tokens\nfrom reputable Brazilian legal sources and conducted few-shot evaluations on\nlegal and general knowledge test suites. Our model, Juru, demonstrates the\nbenefits of domain specialization by achieving improved performance on legal\nbenchmarks, even with a reduced amount of pretraining data. However, this\ndomain specialization through continued pretraining comes at the cost of\nincreased forgetting in unrelated domains, as evidenced by performance\ndegradation on general knowledge test suites in both Portuguese and English.\nThis study contributes to the growing body of scientific evidence showing that\npretraining data selection may enhance the performance of large language\nmodels, enabling the exploration of these models at a lower cost. Juru is\npublicly available at https://huggingface.co/roseval/Juru-7B .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.18140v2", "cate": "cs.CL", "date": "2024-03-26", "updated": "2025-07-28"}
{"id": "2507.20494", "title": "Deep Reputation Scoring in DeFi: zScore-Based Wallet Ranking from Liquidity and Trading Signals", "authors": ["Dhanashekar Kandaswamy", "Ashutosh Sahoo", "Akshay SP", "Gurukiran S", "Parag Paul", "Girish G N"], "categories": ["q-fin.GN", "cs.LG"], "primary_category": "Subjects:       General Finance (q-fin.GN)", "pdf_link": null, "comments": "Comments:      Comments: 10 pages, 5 figures. Independently developed system by Zeru Finance for decentralized user scoring. Not submitted to any conference or journal", "url": "http://arxiv.org/abs/2507.20494v1", "summary": "As decentralized finance (DeFi) evolves, distinguishing between user\nbehaviors - liquidity provision versus active trading - has become vital for\nrisk modeling and on-chain reputation. We propose a behavioral scoring\nframework for Uniswap that assigns two complementary scores: a Liquidity\nProvision Score that assesses strategic liquidity contributions, and a Swap\nBehavior Score that reflects trading intent, volatility exposure, and\ndiscipline. The scores are constructed using rule-based blueprints that\ndecompose behavior into volume, frequency, holding time, and withdrawal\npatterns. To handle edge cases and learn feature interactions, we introduce a\ndeep residual neural network with densely connected skip blocks inspired by the\nU-Net architecture. We also incorporate pool-level context such as total value\nlocked (TVL), fee tiers, and pool size, allowing the system to differentiate\nsimilar user behaviors across pools with varying characteristics. Our framework\nenables context-aware and scalable DeFi user scoring, supporting improved risk\nassessment and incentive design. Experiments on Uniswap v3 data show its\nusefulness for user segmentation and protocol-aligned reputation systems.\nAlthough we refer to our metric as zScore, it is independently developed and\nmethodologically different from the cross-protocol system proposed by Udupi et\nal. Our focus is on role-specific behavioral modeling within Uniswap using\nblueprint logic and supervised learning.", "comment": "Comments: 10 pages, 5 figures. Independently developed system by Zeru\n  Finance for decentralized user scoring. Not submitted to any conference or\n  journal", "pdf_url": "http://arxiv.org/pdf/2507.20494v1", "cate": "q-fin.GN", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.21513", "title": "What Does it Mean for a Neural Network to Learn a \"World Model\"?", "authors": ["Kenneth Li", "Fernanda Viégas", "Martin Wattenberg"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21513v1", "summary": "We propose a set of precise criteria for saying a neural net learns and uses\na \"world model.\" The goal is to give an operational meaning to terms that are\noften used informally, in order to provide a common language for experimental\ninvestigation. We focus specifically on the idea of representing a latent\n\"state space\" of the world, leaving modeling the effect of actions to future\nwork. Our definition is based on ideas from the linear probing literature, and\nformalizes the notion of a computation that factors through a representation of\nthe data generation process. An essential addition to the definition is a set\nof conditions to check that such a \"world model\" is not a trivial consequence\nof the neural net's data or task.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21513v1", "cate": "cs.AI", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2404.15678", "title": "Retrieval and Distill: A Temporal Data Shift-Free Paradigm for Online Recommendation System", "authors": ["Lei Zheng", "Ning Li", "Weinan Zhang", "Yong Yu"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.15678v5", "summary": "Current recommendation systems are significantly affected by a serious issue\nof temporal data shift, which is the inconsistency between the distribution of\nhistorical data and that of online data. Most existing models focus on\nutilizing updated data, overlooking the transferable, temporal data shift-free\ninformation that can be learned from shifting data. We propose the Temporal\nInvariance of Association theorem, which suggests that given a fixed search\nspace, the relationship between the data and the data in the search space keeps\ninvariant over time. Leveraging this principle, we designed a retrieval-based\nrecommendation system framework that can train a data shift-free relevance\nnetwork using shifting data, significantly enhancing the predictive performance\nof the original model in the recommendation system. However, retrieval-based\nrecommendation models face substantial inference time costs when deployed\nonline. To address this, we further designed a distill framework that can\ndistill information from the relevance network into a parameterized module\nusing shifting data. The distilled model can be deployed online alongside the\noriginal model, with only a minimal increase in inference time. Extensive\nexperiments on multiple real datasets demonstrate that our framework\nsignificantly improves the performance of the original model by utilizing\nshifting data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.15678v5", "cate": "cs.IR", "date": "2024-04-24", "updated": "2025-07-27"}
{"id": "2507.20560", "title": "Statistical Inference for Differentially Private Stochastic Gradient Descent", "authors": ["Xintao Xia", "Linjun Zhang", "Zhanrui Cai"], "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20560v1", "summary": "Privacy preservation in machine learning, particularly through Differentially\nPrivate Stochastic Gradient Descent (DP-SGD), is critical for sensitive data\nanalysis. However, existing statistical inference methods for SGD predominantly\nfocus on cyclic subsampling, while DP-SGD requires randomized subsampling. This\npaper first bridges this gap by establishing the asymptotic properties of SGD\nunder the randomized rule and extending these results to DP-SGD. For the output\nof DP-SGD, we show that the asymptotic variance decomposes into statistical,\nsampling, and privacy-induced components. Two methods are proposed for\nconstructing valid confidence intervals: the plug-in method and the random\nscaling method. We also perform extensive numerical analysis, which shows that\nthe proposed confidence intervals achieve nominal coverage rates while\nmaintaining privacy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20560v1", "cate": "stat.ML", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.22025", "title": "UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding", "authors": ["Shuquan Lian", "Yuhang Wu", "Jia Ma", "Zihan Song", "Bingqi Chen", "Xiawu Zheng", "Hui Li"], "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.22025v1", "summary": "The emergence of Multimodal Large Language Models (MLLMs) has driven\nsignificant advances in Graphical User Interface (GUI) agent capabilities.\nNevertheless, existing GUI agent training and inference techniques still suffer\nfrom a dilemma for reasoning designs, ineffective reward, and visual noise. To\naddress these issues, we introduce UI-AGILE, a comprehensive framework\nenhancing GUI agents at both the training and inference stages. For training,\nwe propose a suite of improvements to the Supervised Fine-Tuning (SFT) process:\n1) a Continuous Reward function to incentivize high-precision grounding; 2) a\n\"Simple Thinking\" reward to balance planning with speed and grounding accuracy;\nand 3) a Cropping-based Resampling strategy to mitigate the sparse reward\nproblem and improve learning on complex tasks. For inference, we present\nDecomposed Grounding with Selection, a novel method that dramatically improves\ngrounding accuracy on high-resolution displays by breaking the image into\nsmaller, manageable parts. Experiments show that UI-AGILE achieves the\nstate-of-the-art performance on two benchmarks ScreenSpot-Pro and\nScreenSpot-v2. For instance, using both our proposed training and inference\nenhancement methods brings 23% grounding accuracy improvement over the best\nbaseline on ScreenSpot-Pro.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.22025v1", "cate": "cs.AI", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2406.00222", "title": "Learning to Clarify: Multi-turn Conversations with Action-Based Contrastive Self-Training", "authors": ["Maximillian Chen", "Ruoxi Sun", "Tomas Pfister", "Sercan Ö. Arık"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ICLR 2025; Code: this https URL", "url": "http://arxiv.org/abs/2406.00222v2", "summary": "Large language models (LLMs), optimized through human feedback, have rapidly\nemerged as a leading paradigm for developing intelligent conversational\nassistants. However, despite their strong performance across many benchmarks,\nLLM-based agents might still lack conversational skills such as disambiguation\n-- when they are faced with ambiguity, they often overhedge or implicitly guess\nusers' true intents rather than asking clarification questions. Under\ntask-specific settings, high-quality conversation samples are often limited,\nconstituting a bottleneck for LLMs' ability to learn optimal dialogue action\npolicies. We propose Action-Based Contrastive Self-Training (ACT), a\nquasi-online preference optimization algorithm based on Direct Preference\nOptimization (DPO), that enables data-efficient dialogue policy learning in\nmulti-turn conversation modeling. We demonstrate ACT's efficacy under in\ndata-efficient tuning scenarios, even when there is no action label available,\nusing multiple real-world conversational tasks: tabular-grounded\nquestion-answering, machine reading comprehension, and AmbigSQL, a novel task\nfor disambiguating information-seeking requests for complex SQL generation\ntowards data analysis agents. Additionally, we propose evaluating LLMs' ability\nto function as conversational agents by examining whether they can implicitly\nrecognize and reason about ambiguity in conversation. ACT demonstrates\nsubstantial conversation modeling improvements over standard tuning approaches\nlike supervised fine-tuning and DPO.", "comment": "ICLR 2025; Code:\n  https://github.com/google-research/google-research/tree/master/learning_to_clarify", "pdf_url": "http://arxiv.org/pdf/2406.00222v2", "cate": "cs.CL", "date": "2024-05-31", "updated": "2025-07-27"}
{"id": "2507.20601", "title": "Comparing and Scaling fMRI Features for Brain-Behavior Prediction", "authors": ["Mikkel Schöttner Sieler", "Thomas A. W. Bolton", "Jagruti Patel", "Patric Hagmann"], "categories": ["q-bio.NC", "cs.LG"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20601v1", "summary": "Predicting behavioral variables from neuroimaging modalities such as magnetic\nresonance imaging (MRI) has the potential to allow the development of\nneuroimaging biomarkers of mental and neurological disorders. A crucial\nprocessing step to this aim is the extraction of suitable features. These can\ndiffer in how well they predict the target of interest, and how this prediction\nscales with sample size and scan time. Here, we compare nine feature subtypes\nextracted from resting-state functional MRI recordings for behavior prediction,\nranging from regional measures of functional activity to functional\nconnectivity (FC) and metrics derived with graph signal processing (GSP), a\nprincipled approach for the extraction of structure-informed functional\nfeatures. We study 979 subjects from the Human Connectome Project Young Adult\ndataset, predicting summary scores for mental health, cognition, processing\nspeed, and substance use, as well as age and sex. The scaling properties of the\nfeatures are investigated for different combinations of sample size and scan\ntime. FC comes out as the best feature for predicting cognition, age, and sex.\nGraph power spectral density is the second best for predicting cognition and\nage, while for sex, variability-based features show potential as well. When\npredicting sex, the low-pass graph filtered coupled FC slightly outperforms the\nsimple FC variant. None of the other targets were predicted significantly. The\nscaling results point to higher performance reserves for the better-performing\nfeatures. They also indicate that it is important to balance sample size and\nscan time when acquiring data for prediction studies. The results confirm FC as\na robust feature for behavior prediction, but also show the potential of GSP\nand variability-based measures. We discuss the implications for future\nprediction studies in terms of strategies for acquisition and sample\ncomposition.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20601v1", "cate": "q-bio.NC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.22034", "title": "UserBench: An Interactive Gym Environment for User-Centric Agents", "authors": ["Cheng Qian", "Zuxin Liu", "Akshara Prabhakar", "Zhiwei Liu", "Jianguo Zhang", "Haolin Chen", "Heng Ji", "Weiran Yao", "Shelby Heinecke", "Silvio Savarese", "Caiming Xiong", "Huan Wang"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      25 Pages, 17 Figures, 6 Tables", "url": "http://arxiv.org/abs/2507.22034v1", "summary": "Large Language Models (LLMs)-based agents have made impressive progress in\nreasoning and tool use, enabling them to solve complex tasks. However, their\nability to proactively collaborate with users, especially when goals are vague,\nevolving, or indirectly expressed, remains underexplored. To address this gap,\nwe introduce UserBench, a user-centric benchmark designed to evaluate agents in\nmulti-turn, preference-driven interactions. UserBench features simulated users\nwho start with underspecified goals and reveal preferences incrementally,\nrequiring agents to proactively clarify intent and make grounded decisions with\ntools. Our evaluation of leading open- and closed-source LLMs reveals a\nsignificant disconnect between task completion and user alignment. For\ninstance, models provide answers that fully align with all user intents only\n20% of the time on average, and even the most advanced models uncover fewer\nthan 30% of all user preferences through active interaction. These results\nhighlight the challenges of building agents that are not just capable task\nexecutors, but true collaborative partners. UserBench offers an interactive\nenvironment to measure and advance this critical capability.", "comment": "25 Pages, 17 Figures, 6 Tables", "pdf_url": "http://arxiv.org/pdf/2507.22034v1", "cate": "cs.AI", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2406.06144", "title": "Language Models Resist Alignment: Evidence From Data Compression", "authors": ["Jiaming Ji", "Kaile Wang", "Tianyi Qiu", "Boyuan Chen", "Jiayi Zhou", "Changye Li", "Hantao Lou", "Juntao Dai", "Yunhuai Liu", "Yaodong Yang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by ACL2025 Main", "url": "http://arxiv.org/abs/2406.06144v5", "summary": "Large language models (LLMs) may exhibit unintended or undesirable behaviors.\nRecent works have concentrated on aligning LLMs to mitigate harmful outputs.\nDespite these efforts, some anomalies indicate that even a well-conducted\nalignment process can be easily circumvented, whether intentionally or\naccidentally. Does alignment fine-tuning yield have robust effects on models,\nor are its impacts merely superficial? In this work, we make the first\nexploration of this phenomenon from both theoretical and empirical\nperspectives. Empirically, we demonstrate the $\\mathbf{elasticity}$ of\npost-alignment models, i.e., the tendency to revert to the behavior\ndistribution formed during the pre-training phase upon further fine-tuning.\nLeveraging compression theory, we formally deduce that fine-tuning\ndisproportionately undermines alignment relative to pre-training, potentially\nby orders of magnitude. We validate the presence of elasticity through\nexperiments on models of varying types and scales. Specifically, we find that\nmodel performance declines rapidly before reverting to the pre-training\ndistribution, after which the rate of decline drops significantly. Furthermore,\nwe further reveal that elasticity positively correlates with the increased\nmodel size and the expansion of pre-training data. Our findings underscore the\nneed to address the inherent elasticity of LLMs to mitigate their resistance to\nalignment. The model weight and code are available at\npku-lm-resist-alignment.github.io.", "comment": "Accepted by ACL2025 Main", "pdf_url": "http://arxiv.org/pdf/2406.06144v5", "cate": "cs.CL", "date": "2024-06-10", "updated": "2025-07-27"}
{"id": "2507.20658", "title": "Towards trustworthy AI in materials mechanics through domain-guided attention", "authors": ["Jesco Talies", "Eric Breitbarth", "David Melching"], "categories": ["cond-mat.mtrl-sci", "cs.LG"], "primary_category": "Subjects:       Materials Science (cond-mat.mtrl-sci)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20658v1", "summary": "Ensuring the trustworthiness and robustness of deep learning models remains a\nfundamental challenge, particularly in high-stakes scientific applications. In\nthis study, we present a framework called attention-guided training that\ncombines explainable artificial intelligence techniques with quantitative\nevaluation and domain-specific priors to guide model attention. We demonstrate\nthat domain specific feedback on model explanations during training can enhance\nthe model's generalization capabilities. We validate our approach on the task\nof semantic crack tip segmentation in digital image correlation data which is a\nkey application in the fracture mechanical characterization of materials. By\naligning model attention with physically meaningful stress fields, such as\nthose described by Williams' analytical solution, attention-guided training\nensures that the model focuses on physically relevant regions. This finally\nleads to improved generalization and more faithful explanations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20658v1", "cate": "cond-mat.mtrl-sci", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2507.22062", "title": "MetaCLIP 2: A Worldwide Scaling Recipe", "authors": ["Yung-Sung Chuang", "Yang Li", "Dong Wang", "Ching-Feng Yeh", "Kehan Lyu", "Ramya Raghavendra", "James Glass", "Lifei Huang", "Jason Weston", "Luke Zettlemoyer", "Xinlei Chen", "Zhuang Liu", "Saining Xie", "Wen-tau Yih", "Shang-Wen Li", "Hu Xu"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.22062v1", "summary": "Contrastive Language-Image Pretraining (CLIP) is a popular foundation model,\nsupporting from zero-shot classification, retrieval to encoders for multimodal\nlarge language models (MLLMs). Although CLIP is successfully trained on\nbillion-scale image-text pairs from the English world, scaling CLIP's training\nfurther to learning from the worldwide web data is still challenging: (1) no\ncuration method is available to handle data points from non-English world; (2)\nthe English performance from existing multilingual CLIP is worse than its\nEnglish-only counterpart, i.e., \"curse of multilinguality\" that is common in\nLLMs. Here, we present MetaCLIP 2, the first recipe training CLIP from scratch\non worldwide web-scale image-text pairs. To generalize our findings, we conduct\nrigorous ablations with minimal changes that are necessary to address the above\nchallenges and present a recipe enabling mutual benefits from English and\nnon-English world data. In zero-shot ImageNet classification, MetaCLIP 2\nViT-H/14 surpasses its English-only counterpart by 0.8% and mSigLIP by 0.7%,\nand surprisingly sets new state-of-the-art without system-level confounding\nfactors (e.g., translation, bespoke architecture changes) on multilingual\nbenchmarks, such as CVQA with 57.4%, Babel-ImageNet with 50.2% and XM3600 with\n64.3% on image-to-text retrieval.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.22062v1", "cate": "cs.CV", "date": "2025-07-29", "updated": "2025-07-29"}
{"id": "2408.10631", "title": "LLM-Barber: Block-Aware Rebuilder for Sparsity Mask in One-Shot for Large Language Models", "authors": ["Yupeng Su", "Ziyi Guan", "Xiaoqun Liu", "Tianlai Jin", "Dongkuan Wu", "Zhengfei Chen", "Graziano Chesi", "Ngai Wong", "Hao Yu"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by ICCAD 2025", "url": "http://arxiv.org/abs/2408.10631v2", "summary": "Large language models (LLMs) have seen substantial growth, necessitating\nefficient model pruning techniques. Existing post-training pruning methods\nprimarily measure weight importance in converged dense models, often\noverlooking changes in weight significance during the pruning process, leading\nto performance degradation. To address this issue, we present LLM-Barber\n(Block-Aware Rebuilder for Sparsity Mask in One-Shot), a novel one-shot pruning\nframework that rebuilds the sparsity mask of pruned models without any\nretraining or weight reconstruction. LLM-Barber incorporates block-aware error\noptimization across Self-Attention and MLP blocks, facilitating global\nperformance optimization. We are the first to employ the product of weights and\ngradients as a pruning metric in the context of LLM post-training pruning. This\nenables accurate identification of weight importance in massive models and\nsignificantly reduces computational complexity compared to methods using\nsecondorder information. Our experiments show that LLM-Barber efficiently\nprunes models from LLaMA and OPT families (7B to 13B) on a single A100 GPU in\njust 30 minutes, achieving state-of-the-art results in both perplexity and\nzero-shot performance across various language benchmarks. Code is available at\nhttps://github.com/YupengSu/LLM-Barber.", "comment": "Accepted by ICCAD 2025", "pdf_url": "http://arxiv.org/pdf/2408.10631v2", "cate": "cs.LG", "date": "2024-08-20", "updated": "2025-07-26"}
{"id": "2507.20752", "title": "Multilingual Self-Taught Faithfulness Evaluators", "authors": ["Carlo Alfano", "Aymen Al Marjani", "Zeno Jonke", "Amin Mantrach", "Saab Mansour", "Marcello Federico"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20752v1", "summary": "The growing use of large language models (LLMs) has increased the need for\nautomatic evaluation systems, particularly to address the challenge of\ninformation hallucination. Although existing faithfulness evaluation approaches\nhave shown promise, they are predominantly English-focused and often require\nexpensive human-labeled training data for fine-tuning specialized models. As\nLLMs see increased adoption in multilingual contexts, there is a need for\naccurate faithfulness evaluators that can operate across languages without\nextensive labeled data. This paper presents Self-Taught Evaluators for\nMultilingual Faithfulness, a framework that learns exclusively from synthetic\nmultilingual summarization data while leveraging cross-lingual transfer\nlearning. Through experiments comparing language-specific and mixed-language\nfine-tuning approaches, we demonstrate a consistent relationship between an\nLLM's general language capabilities and its performance in language-specific\nevaluation tasks. Our framework shows improvements over existing baselines,\nincluding state-of-the-art English evaluators and machine translation-based\napproaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20752v1", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2403.06963", "title": "The pitfalls of next-token prediction", "authors": ["Gregor Bachmann", "Vaishnavh Nagarajan"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ICML 2024", "url": "http://arxiv.org/abs/2403.06963v3", "summary": "Can a mere next-token predictor faithfully model human intelligence? We\ncrystallize this emerging concern and correct popular misconceptions\nsurrounding it, and advocate a simple multi-token objective.\n  As a starting point, we argue that the two often-conflated phases of\nnext-token prediction -- autoregressive inference and teacher-forced training\n-- must be treated distinctly. The popular criticism that errors can compound\nduring autoregressive inference, crucially assumes that teacher-forcing has\nlearned an accurate next-token predictor. This assumption sidesteps a more\ndeep-rooted problem we expose: in certain classes of tasks, teacher-forcing can\nsimply fail to learn an accurate next-token predictor in the first place. We\ndescribe a general mechanism of how teacher-forcing can fail, and design a\nminimal planning task where both the Transformer and the Mamba architecture\nempirically fail in that manner -- remarkably, despite the task being\nstraightforward to learn.\n  Finally, we provide preliminary evidence that this failure can be resolved\nusing _teacherless_ training, a simple modification using dummy tokens that\npredicts multiple tokens in advance. We hope this finding can ground future\ndebates and inspire explorations beyond the next-token prediction paradigm. We\nmake our code available under\nhttps://github.com/gregorbachmann/Next-Token-Failures", "comment": "ICML 2024", "pdf_url": "http://arxiv.org/pdf/2403.06963v3", "cate": "cs.CL", "date": "2024-03-11", "updated": "2025-07-29"}
{"id": "2408.15101", "title": "MTMamba++: Enhancing Multi-Task Dense Scene Understanding via Mamba-Based Decoders", "authors": ["Baijiong Lin", "Weisen Jiang", "Pengguang Chen", "Shu Liu", "Ying-Cong Chen"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence", "url": "http://arxiv.org/abs/2408.15101v2", "summary": "Multi-task dense scene understanding, which trains a model for multiple dense\nprediction tasks, has a wide range of application scenarios. Capturing\nlong-range dependency and enhancing cross-task interactions are crucial to\nmulti-task dense prediction. In this paper, we propose MTMamba++, a novel\narchitecture for multi-task scene understanding featuring with a Mamba-based\ndecoder. It contains two types of core blocks: self-task Mamba (STM) block and\ncross-task Mamba (CTM) block. STM handles long-range dependency by leveraging\nstate-space models, while CTM explicitly models task interactions to facilitate\ninformation exchange across tasks. We design two types of CTM block, namely\nF-CTM and S-CTM, to enhance cross-task interaction from feature and semantic\nperspectives, respectively. Extensive experiments on NYUDv2, PASCAL-Context,\nand Cityscapes datasets demonstrate the superior performance of MTMamba++ over\nCNN-based, Transformer-based, and diffusion-based methods while maintaining\nhigh computational efficiency. The code is available at\nhttps://github.com/EnVision-Research/MTMamba.", "comment": "Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence", "pdf_url": "http://arxiv.org/pdf/2408.15101v2", "cate": "cs.CV", "date": "2024-08-27", "updated": "2025-07-26"}
{"id": "2507.20958", "title": "Mean-Field Langevin Diffusions with Density-dependent Temperature", "authors": ["Yu-Jui Huang", "Zachariah Malik"], "categories": ["math.OC", "cs.LG", "math.PR", "60J60, 60H10, 90C26"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20958v1", "summary": "In the context of non-convex optimization, we let the temperature of a\nLangevin diffusion to depend on the diffusion's own density function. The\nrationale is that the induced density reveals to some extent the landscape\nimposed by the non-convex function to be minimized, such that a\ndensity-dependent temperature can provide location-wise random perturbation\nthat may better react to, for instance, the location and depth of local\nminimizers. As the Langevin dynamics is now self-regulated by its own density,\nit forms a mean-field stochastic differential equation (SDE) of the Nemytskii\ntype, distinct from the standard McKean-Vlasov equations. Relying on\nWasserstein subdifferential calculus, we first show that the corresponding\n(nonlinear) Fokker-Planck equation has a unique solution. Next, a weak solution\nto the SDE is constructed from the solution to the Fokker-Planck equation, by\nTrevisan's superposition principle. As time goes to infinity, we further show\nthat the density induced by the SDE converges to an invariant distribution,\nwhich admits an explicit formula in terms of the Lambert $W$ function.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20958v1", "cate": "math.OC", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2409.11274", "title": "Task Arithmetic for Language Expansion in Speech Translation", "authors": ["Yao-Fei Cheng", "Hayato Futami", "Yosuke Kashiwagi", "Emiru Tsunoo", "Wen Shen Teo", "Siddhant Arora", "Shinji Watanabe"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.11274v3", "summary": "Recent progress in large language models (LLMs) has gained interest in\nspeech-text multimodal foundation models, achieving strong performance on\ninstruction-tuned speech translation (ST). However, expanding language pairs is\ncostly due to re-training on combined new and previous datasets. To address\nthis, we aim to build a one-to-many ST system from existing one-to-one ST\nsystems using task arithmetic without re-training. Direct application of task\narithmetic in ST leads to language confusion; therefore, we introduce an\naugmented task arithmetic method incorporating a language control model to\nensure correct target language generation. Our experiments on MuST-C and\nCoVoST-2 show BLEU score improvements of up to 4.66 and 4.92, with COMET gains\nof 8.87 and 11.83. In addition, we demonstrate our framework can extend to\nlanguage pairs lacking paired ST training data or pre-trained ST models by\nsynthesizing ST models based on existing machine translation (MT) and ST models\nvia task analogies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.11274v3", "cate": "cs.CL", "date": "2024-09-17", "updated": "2025-07-29"}
{"id": "2409.06624", "title": "A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio", "authors": ["Ningyuan Xi", "Yetao Wu", "Kun Fan", "Teng Chen", "Qingqing Gu", "Luo Ji"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages, 2 figures", "url": "http://arxiv.org/abs/2409.06624v2", "summary": "Large Language Models (LLM) often need to be Continual Pre-Trained (CPT) to\nobtain unfamiliar language skills or adapt to new domains. The huge training\ncost of CPT often asks for cautious choice of key hyper-parameters such as the\nmixture ratio of extra language or domain corpus. However, there is no\nsystematic study that bridges the gap between the optimal mixture ratio and the\nactual model performance, and the gap between experimental scaling law and the\nactual deployment in the full model size. In this paper, we perform CPT on\nLlama-3 8B and 70B to enhance its Chinese ability. We study the optimal\ncorrelation between the Additional Language Mixture Ratio (ALMR) and the\nLearning Rate (LR) on the 8B size which directly indicates the optimal\nexperimental setup. By thorough choice of hyper-parameter, and subsequent\nfine-tuning, the model capability is improved not only on the Chinese-related\nbenchmark but also in some specific domains including math, coding, and\nemotional intelligence. We deploy the final 70B version of LLM on a real-life\nchat system which obtains satisfying performance.", "comment": "12 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2409.06624v2", "cate": "cs.CL", "date": "2024-09-10", "updated": "2025-07-26"}
{"id": "2507.20975", "title": "Locally Adaptive Conformal Inference for Operator Models", "authors": ["Trevor Harris", "Yan Liu"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      9 pages, 2 figures, 2 tables", "url": "http://arxiv.org/abs/2507.20975v1", "summary": "Operator models are regression algorithms for functional data and have become\na key tool for emulating large-scale dynamical systems. Recent advances in deep\nneural operators have dramatically improved the accuracy and scalability of\noperator modeling, but lack an inherent notion of predictive uncertainty. We\nintroduce Local Spectral Conformal Inference (LSCI), a new framework for\nlocally adaptive, distribution-free uncertainty quantification for neural\noperator models. LSCI uses projection-based depth scoring and localized\nconformal inference to generate function-valued prediction sets with\nstatistical guarantees. We prove approximate finite-sample marginal coverage\nunder local exchangeability, and demonstrate significant gains in adaptivity\nand coverage across synthetic and real-world operator learning tasks.", "comment": "9 pages, 2 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.20975v1", "cate": "stat.ML", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2409.18924", "title": "Simulated patient systems are intelligent when powered by large language model-based AI agents", "authors": ["Huizi Yu", "Jiayan Zhou", "Lingyao Li", "Shan Chen", "Jack Gallifant", "Anye Shi", "Xiang Li", "Jingxian He", "Wenyue Hua", "Mingyu Jin", "Guang Chen", "Yang Zhou", "Zhao Li", "Trisha Gupte", "Ming-Li Chen", "Zahra Azizi", "Yongfeng Zhang", "Yanqiu Xing", "Themistocles L. Danielle S. Bitterman", "Themistocles L. Assimes", "Xin Ma", "Lin Lu", "Lizhou Fan"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      64 pages, 14 figures, 16 tables", "url": "http://arxiv.org/abs/2409.18924v3", "summary": "Simulated patient systems play an important role in modern medical education\nand research, providing safe, integrative medical training environments and\nsupporting clinical decision-making simulations. We developed AIPatient, an\nintelligent simulated patient system powered by large language model-based AI\nagents. The system incorporates the Retrieval Augmented Generation (RAG)\nframework, powered by six task-specific LLM-based AI agents for complex\nreasoning. For simulation reality, the system is also powered by the AIPatient\nKG (Knowledge Graph), built with de-identified real patient data from the\nMedical Information Mart for Intensive Care (MIMIC)-III database. Primary\noutcomes showcase the system's intelligence, including the system's accuracy in\nElectronic Record (EHR)-based medical Question Answering (QA), readability,\nrobustness, and stability. The system achieved a QA accuracy of 94.15% when all\nsix AI agents present, surpassing benchmarks with partial or no agent\nintegration. Its knowledgebase demonstrated high validity (F1 score=0.89).\nReadability scores showed median Flesch Reading Ease at 77.23 and median Flesch\nKincaid Grade at 5.6, indicating accessibility to all medical professionals.\nRobustness and stability were confirmed with non-significant variance (ANOVA\nF-value=0.6126, p > 0.1; F-value=0.782, p > 0.1). A user study with medical\nstudents further demonstrated that AIPatient offers high fidelity, strong\nusability, and effective educational value, performing comparably or better\nthan human-simulated patients in medical history-taking scenarios. The\npromising intelligence of the AIPatient system highlights its potential to\nsupport a wide range of applications, including medical education, model\nevaluation, and system integration.", "comment": "64 pages, 14 figures, 16 tables", "pdf_url": "http://arxiv.org/pdf/2409.18924v3", "cate": "cs.CL", "date": "2024-09-27", "updated": "2025-07-29"}
{"id": "2409.12059", "title": "MeTHanol: Modularized Thinking Language Models with Intermediate Layer Thinking, Decoding and Bootstrapping Reasoning", "authors": ["Ningyuan Xi", "Xiaoyu Wang", "Yetao Wu", "Teng Chen", "Qingqing Gu", "Yue Zhao", "Jinxian Qu", "Zhonglin Jiang", "Yong Chen", "Luo Ji"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      19 pages, 7 figures", "url": "http://arxiv.org/abs/2409.12059v5", "summary": "Current research efforts are focused on enhancing the thinking and reasoning\ncapability of large language model (LLM) by prompting, data-driven emergence\nand inference-time computation. In this study, we consider stimulating language\nmodel's thinking and cognitive abilities from a modular perspective, which\nmimics the human brain architecture. We select a specific intermediate\nattention layer with newly implemented language heads. We conduct dual-layer\nfine-tuning by annotated (query, thought, answer) samples and show that the\nintermediate layer can also learn to decode fluent and reasonable language\ntokens. A two-pass inference mechanism is designed to generate thoughts then\nformal responses. The entire framework is called modularized thinking language\nmodel (MeTHanol) which can enhance LLM's cognitive behaviors as indicated by\nTheory of Mind (ToM) and Vignette-based experiments. Case studies also show\nthat MeTHanol can plan and self-reflect and generate human-like thoughts and\nanswers, even on unseen and open-domain tasks. MeTHanol can also adapt to a\npersonalized prompt and behave as the specified character. Our study holds\npromise for significant cognitive gains from a modular perspective. Our code,\nmodel and data are available at https://bachozean.github.io/methanol-page", "comment": "19 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2409.12059v5", "cate": "cs.CL", "date": "2024-09-18", "updated": "2025-07-26"}
{"id": "2507.21018", "title": "Deep Learning for Skeleton Based Human Motion Rehabilitation Assessment: A Benchmark", "authors": ["Ali Ismail-Fawaz", "Maxime Devanne", "Stefano Berretti", "Jonathan Weber", "Germain Forestier"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.21018v1", "summary": "Automated assessment of human motion plays a vital role in rehabilitation,\nenabling objective evaluation of patient performance and progress. Unlike\ngeneral human activity recognition, rehabilitation motion assessment focuses on\nanalyzing the quality of movement within the same action class, requiring the\ndetection of subtle deviations from ideal motion. Recent advances in deep\nlearning and video-based skeleton extraction have opened new possibilities for\naccessible, scalable motion assessment using affordable devices such as\nsmartphones or webcams. However, the field lacks standardized benchmarks,\nconsistent evaluation protocols, and reproducible methodologies, limiting\nprogress and comparability across studies. In this work, we address these gaps\nby (i) aggregating existing rehabilitation datasets into a unified archive\ncalled Rehab-Pile, (ii) proposing a general benchmarking framework for\nevaluating deep learning methods in this domain, and (iii) conducting extensive\nbenchmarking of multiple architectures across classification and regression\ntasks. All datasets and implementations are released to the community to\nsupport transparency and reproducibility. This paper aims to establish a solid\nfoundation for future research in automated rehabilitation assessment and\nfoster the development of reliable, accessible, and personalized rehabilitation\nsolutions. The datasets, source-code and results of this article are all\npublicly available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.21018v1", "cate": "cs.CV", "date": "2025-07-28", "updated": "2025-07-28"}
{"id": "2410.16491", "title": "BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data", "authors": ["Wenkai Li", "Jiarui Liu", "Andy Liu", "Xuhui Zhou", "Mona Diab", "Maarten Sap"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.16491v3", "summary": "In this work, we tackle the challenge of embedding realistic human\npersonality traits into LLMs. Previous approaches have primarily focused on\nprompt-based methods that describe the behavior associated with the desired\npersonality traits, suffering from realism and validity issues. To address\nthese limitations, we introduce BIG5-CHAT, a large-scale dataset containing\n100,000 dialogues designed to ground models in how humans express their\npersonality in language. Leveraging this dataset, we explore Supervised\nFine-Tuning and Direct Preference Optimization as training-based methods to\nalign LLMs more naturally with human personality patterns. Our methods\noutperform prompting on personality assessments such as BFI and IPIP-NEO, with\ntrait correlations more closely matching human data. Furthermore, our\nexperiments reveal that models trained to exhibit higher conscientiousness,\nhigher agreeableness, lower extraversion, and lower neuroticism display better\nperformance on reasoning tasks, aligning with psychological findings on how\nthese traits impact human cognitive performance. To our knowledge, this work is\nthe first comprehensive study to demonstrate how training-based methods can\nshape LLM personalities through learning from real human behaviors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.16491v3", "cate": "cs.CL", "date": "2024-10-21", "updated": "2025-07-29"}
{"id": "2409.15747", "title": "Training Neural Networks for Modularity aids Interpretability", "authors": ["Satvik Golechha", "Dylan Cope", "Nandi Schoots"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Some of the interpretations of the results in this paper were incorrect, and we found on further experiments that the techniques did not scale well - we have the corrected results in a different submission (due to a significant change in both content and authors it needed to be a new submission). Please check https://arxiv.org/abs/2502.02470 for the updated paper.", "url": "http://arxiv.org/abs/2409.15747v2", "summary": "An approach to improve network interpretability is via clusterability, i.e.,\nsplitting a model into disjoint clusters that can be studied independently. We\nfind pretrained models to be highly unclusterable and thus train models to be\nmore modular using an ``enmeshment loss'' function that encourages the\nformation of non-interacting clusters. Using automated interpretability\nmeasures, we show that our method finds clusters that learn different,\ndisjoint, and smaller circuits for CIFAR-10 labels. Our approach provides a\npromising direction for making neural networks easier to interpret.", "comment": "Some of the interpretations of the results in this paper were\n  incorrect, and we found on further experiments that the techniques did not\n  scale well - we have the corrected results in a different submission (due to\n  a significant change in both content and authors it needed to be a new\n  submission). Please check https://arxiv.org/abs/2502.02470 for the updated\n  paper.", "pdf_url": "http://arxiv.org/pdf/2409.15747v2", "cate": "cs.LG", "date": "2024-09-24", "updated": "2025-07-26"}
{"id": "2305.15612", "title": "Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning", "authors": ["Jungtaek Kim"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at the 42nd International Conference on Machine Learning (ICML 2025)", "url": "http://arxiv.org/abs/2305.15612v5", "summary": "Bayesian optimization has attracted huge attention from diverse research\nareas in science and engineering, since it is capable of efficiently finding a\nglobal optimum of an expensive-to-evaluate black-box function. In general, a\nprobabilistic regression model is widely used as a surrogate function to model\nan explicit distribution over function evaluations given an input to estimate\nand a training dataset. Beyond the probabilistic regression-based methods,\ndensity ratio estimation-based Bayesian optimization has been suggested in\norder to estimate a density ratio of the groups relatively close and relatively\nfar to a global optimum. Developing this line of research further, supervised\nclassifiers are employed to estimate a class probability for the two groups\ninstead of a density ratio. However, the supervised classifiers used in this\nstrategy are prone to be overconfident for known knowledge on global solution\ncandidates. Supposing that we have access to unlabeled points, e.g., predefined\nfixed-size pools, we propose density ratio estimation-based Bayesian\noptimization with semi-supervised learning to solve this challenge. Finally, we\nshow the empirical results of our methods and several baseline methods in two\ndistinct scenarios with unlabeled point sampling and a fixed-size pool, and\nanalyze the validity of our methods in diverse experiments.", "comment": "Accepted at the 42nd International Conference on Machine Learning\n  (ICML 2025)", "pdf_url": "http://arxiv.org/pdf/2305.15612v5", "cate": "cs.LG", "date": "2023-05-24", "updated": "2025-07-27"}
{"id": "2411.19096", "title": "Pralekha: Cross-Lingual Document Alignment for Indic Languages", "authors": ["Sanjay Suryanarayanan", "Haiyue Song", "Mohammed Safi Ur Rahman Khan", "Anoop Kunchukuttan", "Raj Dabre"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.19096v2", "summary": "Mining parallel document pairs for document-level machine translation (MT)\nremains challenging due to the limitations of existing Cross-Lingual Document\nAlignment (CLDA) techniques. Most approaches rely on metadata such as URLs,\nwhich is often unavailable in low-resource language settings, while others\nrepresent documents using pooled sentence embeddings, which fail to capture\nfine-grained alignment cues. Moreover, current sentence embedding models have\nlimited context windows, hindering their ability to represent document-level\ninformation effectively. To address these challenges for Indic languages, we\nintroduce PRALEKHA, a large-scale benchmark for evaluating document-level\nalignment techniques. It contains over 3 million aligned document pairs across\n11 Indic languages and English, of which 1.5 million are English--Indic pairs.\nFurthermore, we propose Document Alignment Coefficient (DAC), a novel metric\nfor fine-grained document alignment. Unlike pooling-based approaches, DAC\naligns documents by matching smaller chunks and computes similarity as the\nratio of aligned chunks to the average number of chunks in a pair. Intrinsic\nevaluation shows that DAC achieves substantial improvements over pooling-based\nbaselines, particularly in noisy scenarios. Extrinsic evaluation further\ndemonstrates that document MT models trained on DAC-aligned pairs consistently\noutperform those using baseline alignment methods. These results highlight\nDAC's effectiveness for parallel document mining. The PRALEKHA dataset and CLDA\nevaluation framework will be made publicly available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.19096v2", "cate": "cs.CL", "date": "2024-11-28", "updated": "2025-07-29"}
{"id": "2410.03655", "title": "Geometric Representation Condition Improves Equivariant Molecule Generation", "authors": ["Zian Li", "Cai Zhou", "Xiyuan Wang", "Xingang Peng", "Muhan Zhang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ICML 2025 as a Spotlight Poster", "url": "http://arxiv.org/abs/2410.03655v4", "summary": "Recent advances in molecular generative models have demonstrated great\npromise for accelerating scientific discovery, particularly in drug design.\nHowever, these models often struggle to generate high-quality molecules,\nespecially in conditional scenarios where specific molecular properties must be\nsatisfied. In this work, we introduce GeoRCG, a general framework to improve\nmolecular generative models by integrating geometric representation conditions\nwith provable theoretical guarantees. We decompose the generation process into\ntwo stages: first, generating an informative geometric representation; second,\ngenerating a molecule conditioned on the representation. Compared with\nsingle-stage generation, the easy-to-generate representation in the first stage\nguides the second stage generation toward a high-quality molecule in a\ngoal-oriented way. Leveraging EDM and SemlaFlow as base generators, we observe\nsignificant quality improvements in unconditional molecule generation on the\nwidely used QM9 and GEOM-DRUG datasets. More notably, in the challenging\nconditional molecular generation task, our framework achieves an average 50\\%\nperformance improvement over state-of-the-art approaches, highlighting the\nsuperiority of conditioning on semantically rich geometric representations.\nFurthermore, with such representation guidance, the number of diffusion steps\ncan be reduced to as small as 100 while largely preserving the generation\nquality achieved with 1,000 steps, thereby significantly reducing the\ngeneration iterations needed. Code is available at\nhttps://github.com/GraphPKU/GeoRCG.", "comment": "Accepted to ICML 2025 as a Spotlight Poster", "pdf_url": "http://arxiv.org/pdf/2410.03655v4", "cate": "cs.LG", "date": "2024-10-04", "updated": "2025-07-28"}
{"id": "2310.09336", "title": "Compositional Abilities Emerge Multiplicatively: Exploring Diffusion Models on a Synthetic Task", "authors": ["Maya Okawa", "Ekdeep Singh Lubana", "Robert P. Dick", "Hidenori Tanaka"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      37th Conference on Neural Information Processing Systems (NeurIPS)", "url": "http://arxiv.org/abs/2310.09336v5", "summary": "Modern generative models exhibit unprecedented capabilities to generate\nextremely realistic data. However, given the inherent compositionality of the\nreal world, reliable use of these models in practical applications requires\nthat they exhibit the capability to compose a novel set of concepts to generate\noutputs not seen in the training data set. Prior work demonstrates that recent\ndiffusion models do exhibit intriguing compositional generalization abilities,\nbut also fail unpredictably. Motivated by this, we perform a controlled study\nfor understanding compositional generalization in conditional diffusion models\nin a synthetic setting, varying different attributes of the training data and\nmeasuring the model's ability to generate samples out-of-distribution. Our\nresults show: (i) the order in which the ability to generate samples from a\nconcept and compose them emerges is governed by the structure of the underlying\ndata-generating process; (ii) performance on compositional tasks exhibits a\nsudden \"emergence\" due to multiplicative reliance on the performance of\nconstituent tasks, partially explaining emergent phenomena seen in generative\nmodels; and (iii) composing concepts with lower frequency in the training data\nto generate out-of-distribution samples requires considerably more optimization\nsteps compared to generating in-distribution samples. Overall, our study lays a\nfoundation for understanding capabilities and compositionality in generative\nmodels from a data-centric perspective.", "comment": "37th Conference on Neural Information Processing Systems (NeurIPS)", "pdf_url": "http://arxiv.org/pdf/2310.09336v5", "cate": "cs.LG", "date": "2023-10-13", "updated": "2025-07-25"}
{"id": "2502.03387", "title": "LIMO: Less is More for Reasoning", "authors": ["Yixin Ye", "Zhen Huang", "Yang Xiao", "Ethan Chern", "Shijie Xia", "Pengfei Liu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      COLM 2025", "url": "http://arxiv.org/abs/2502.03387v3", "summary": "We challenge the prevailing assumption that complex reasoning in large\nlanguage models (LLMs) necessitates massive training data. We demonstrate that\nsophisticated mathematical reasoning can emerge with only a few examples.\nSpecifically, through simple supervised fine-tuning, our model, LIMO, achieves\n63.3\\% accuracy on AIME24 and 95.6\\% on MATH500, surpassing previous fine-tuned\nmodels (6.5\\% on AIME24, 59.2\\% on MATH500) while using only 1\\% of the\ntraining data required by prior approaches. Furthermore, LIMO exhibits strong\nout-of-distribution generalization, achieving a 45.8\\% absolute improvement\nacross diverse benchmarks, outperforming models trained on 100x more data.\nSynthesizing these findings, we propose the Less-Is-More Reasoning Hypothesis\n(LIMO Hypothesis): In foundation models where domain knowledge has been\ncomprehensively encoded during pre-training, sophisticated reasoning can emerge\nthrough minimal but strategically designed demonstrations of cognitive\nprocesses. This hypothesis suggests that the threshold for eliciting complex\nreasoning is not dictated by task complexity but rather by two key factors: (1)\nthe completeness of the model's pre-trained knowledge base and (2) the\neffectiveness of post-training examples in serving as \"cognitive templates\"\nthat guide reasoning.", "comment": "COLM 2025", "pdf_url": "http://arxiv.org/pdf/2502.03387v3", "cate": "cs.CL", "date": "2025-02-05", "updated": "2025-07-29"}
{"id": "2410.08979", "title": "Overcoming Slow Decision Frequencies in Continuous Control: Model-Based Sequence Reinforcement Learning for Model-Free Control", "authors": ["Devdhar Patel", "Hava Siegelmann"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      30 pages, 14 figures, 7 tables. Presented at the Thirteenth International Conference on Learning Representations (ICLR 2025), Singapore, April 24-28, 2025", "url": "http://arxiv.org/abs/2410.08979v5", "summary": "Reinforcement learning (RL) is rapidly reaching and surpassing human-level\ncontrol capabilities. However, state-of-the-art RL algorithms often require\ntimesteps and reaction times significantly faster than human capabilities,\nwhich is impractical in real-world settings and typically necessitates\nspecialized hardware. We introduce Sequence Reinforcement Learning (SRL), an RL\nalgorithm designed to produce a sequence of actions for a given input state,\nenabling effective control at lower decision frequencies. SRL addresses the\nchallenges of learning action sequences by employing both a model and an\nactor-critic architecture operating at different temporal scales. We propose a\n\"temporal recall\" mechanism, where the critic uses the model to estimate\nintermediate states between primitive actions, providing a learning signal for\neach individual action within the sequence. Once training is complete, the\nactor can generate action sequences independently of the model, achieving\nmodel-free control at a slower frequency. We evaluate SRL on a suite of\ncontinuous control tasks, demonstrating that it achieves performance comparable\nto state-of-the-art algorithms while significantly reducing actor sample\ncomplexity. To better assess performance across varying decision frequencies,\nwe introduce the Frequency-Averaged Score (FAS) metric. Our results show that\nSRL significantly outperforms traditional RL algorithms in terms of FAS, making\nit particularly suitable for applications requiring variable decision\nfrequencies. Furthermore, we compare SRL with model-based online planning,\nshowing that SRL achieves comparable FAS while leveraging the same model during\ntraining that online planners use for planning.", "comment": "30 pages, 14 figures, 7 tables. Presented at the Thirteenth\n  International Conference on Learning Representations (ICLR 2025), Singapore,\n  April 24-28, 2025", "pdf_url": "http://arxiv.org/pdf/2410.08979v5", "cate": "cs.LG", "date": "2024-10-11", "updated": "2025-07-26"}
{"id": "2311.13349", "title": "REDS: Resource-Efficient Deep Subnetworks for Dynamic Resource Constraints", "authors": ["Francesco Corti", "Balz Maag", "Joachim Schauer", "Ulrich Pferschy", "Olga Saukh"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2311.13349v3", "summary": "Deep learning models deployed on edge devices frequently encounter resource\nvariability, which arises from fluctuating energy levels, timing constraints,\nor prioritization of other critical tasks within the system. State-of-the-art\nmachine learning pipelines generate resource-agnostic models that are not\ncapable to adapt at runtime. In this work, we introduce Resource-Efficient Deep\nSubnetworks (REDS) to tackle model adaptation to variable resources. In\ncontrast to the state-of-the-art, REDS leverages structured sparsity\nconstructively by exploiting permutation invariance of neurons, which allows\nfor hardware-specific optimizations. Specifically, REDS achieves computational\nefficiency by (1) skipping sequential computational blocks identified by a\nnovel iterative knapsack optimizer, and (2) taking advantage of data cache by\nre-arranging the order of operations in REDS computational graph. REDS supports\nconventional deep networks frequently deployed on the edge and provides\ncomputational benefits even for small and simple networks. We evaluate REDS on\neight benchmark architectures trained on the Visual Wake Words, Google Speech\nCommands, Fashion-MNIST, CIFAR-10 and ImageNet-1K datasets, and test on four\noff-the-shelf mobile and embedded hardware platforms. We provide a theoretical\nresult and empirical evidence demonstrating REDS' outstanding performance in\nterms of submodels' test set accuracy, and demonstrate an adaptation time in\nresponse to dynamic resource constraints of under 40$\\mu$s, utilizing a\nfully-connected network on Arduino Nano 33 BLE.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2311.13349v3", "cate": "cs.LG", "date": "2023-11-22", "updated": "2025-07-28"}
{"id": "2502.18978", "title": "Low-Confidence Gold: Refining Low-Confidence Samples for Efficient Instruction Tuning", "authors": ["Hongyi Cai", "Jie Li", "Mohammad Mahdinur Rahman", "Wenzhen Dong"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2502.18978v4", "summary": "The effectiveness of instruction fine-tuning for Large Language Models is\nfundamentally constrained by the quality and efficiency of training datasets.\nThis work introduces Low-Confidence Gold (LCG), a novel filtering framework\nthat employs centroid-based clustering and confidence-guided selection for\nidentifying valuable instruction pairs. Through a semi-supervised approach\nusing a lightweight classifier trained on representative samples, LCG curates\nhigh-quality subsets while preserving data diversity. Experimental evaluation\ndemonstrates that models fine-tuned on LCG-filtered subsets of 6K samples\nachieve superior performance compared to existing methods, with substantial\nimprovements on MT-bench and consistent gains across comprehensive evaluation\nmetrics. The framework's efficacy while maintaining model performance\nestablishes a promising direction for efficient instruction tuning.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2502.18978v4", "cate": "cs.CL", "date": "2025-02-26", "updated": "2025-07-29"}
{"id": "2410.14651", "title": "Real-time Factuality Assessment from Adversarial Feedback", "authors": ["Sanxing Chen", "Yukun Huang", "Bhuwan Dhingra"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.14651v3", "summary": "We show that existing evaluations for assessing the factuality of news from\nconventional sources, such as claims on fact-checking websites, result in high\naccuracies over time for LLM-based detectors-even after their knowledge\ncutoffs. This suggests that recent popular false information from such sources\ncan be easily identified due to its likely presence in pre-training/retrieval\ncorpora or the emergence of salient, yet shallow, patterns in these datasets.\nInstead, we argue that a proper factuality evaluation dataset should test a\nmodel's ability to reason about current events by retrieving and reading\nrelated evidence. To this end, we develop a novel pipeline that leverages\nnatural language feedback from a RAG-based detector to iteratively modify\nreal-time news into deceptive variants that challenge LLMs. Our iterative\nrewrite decreases the binary classification ROC-AUC by an absolute 17.5 percent\nfor a strong RAG-based GPT-4o detector. Our experiments reveal the important\nrole of RAG in both evaluating and generating challenging news examples, as\nretrieval-free LLM detectors are vulnerable to unseen events and adversarial\nattacks, while feedback from RAG-based evaluation helps discover more deceitful\npatterns.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.14651v3", "cate": "cs.CL", "date": "2024-10-18", "updated": "2025-07-27"}
{"id": "2311.18718", "title": "The Feature Speed Formula: a flexible approach to scale hyper-parameters of deep neural networks", "authors": ["Lénaïc Chizat", "Praneeth Netrapalli"], "categories": ["cs.LG", "68T07"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Previous title \"Steering deep feature learning with backward aligned feature updates\". This is the published version. Novelties compared to v1: BFA for linear Resnets (Prop. 5.2), scaling FSC (Table 1), and content reorganized", "url": "http://arxiv.org/abs/2311.18718v4", "summary": "Deep learning succeeds by doing hierarchical feature learning, yet tuning\nhyper-parameters (HP) such as initialization scales, learning rates etc., only\ngive indirect control over this behavior. In this paper, we introduce a key\nnotion to predict and control feature learning: the angle $\\theta_\\ell$ between\nthe feature updates and the backward pass (at layer index $\\ell$). We show that\nthe magnitude of feature updates after one GD step, at any training time, can\nbe expressed via a simple and general \\emph{feature speed formula} in terms of\nthis angle $\\theta_\\ell$, the loss decay, and the magnitude of the backward\npass. This angle $\\theta_\\ell$ is controlled by the conditioning of the\nlayer-to-layer Jacobians and at random initialization, it is determined by the\nspectrum of a certain kernel, which coincides with the Neural Tangent Kernel\nwhen $\\ell=\\text{depth}$. Given $\\theta_\\ell$, the feature speed formula\nprovides us with rules to adjust HPs (scales and learning rates) so as to\nsatisfy certain dynamical properties, such as feature learning and loss decay.\nWe investigate the implications of our approach for ReLU MLPs and ResNets in\nthe large width-then-depth limit. Relying on prior work, we show that in ReLU\nMLPs with iid initialization, the angle degenerates with depth as\n$\\cos(\\theta_\\ell)=\\Theta(1/\\sqrt{\\ell})$. In contrast, ResNets with branch\nscale $O(1/\\sqrt{\\text{depth}})$ maintain a non-degenerate angle\n$\\cos(\\theta_\\ell)=\\Theta(1)$. We use these insights to recover key properties\nof known HP scalings and also to introduce a new HP scaling for large depth\nReLU MLPs with favorable theoretical properties.", "comment": "Previous title \"Steering deep feature learning with backward aligned\n  feature updates\". This is the published version. Novelties compared to v1:\n  BFA for linear Resnets (Prop. 5.2), scaling FSC (Table 1), and content\n  reorganized", "pdf_url": "http://arxiv.org/pdf/2311.18718v4", "cate": "cs.LG", "date": "2023-11-30", "updated": "2025-07-28"}
{"id": "2503.04844", "title": "Narrative Context Protocol: An Open-Source Storytelling Framework for Generative AI", "authors": ["Hank Gerba"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.04844v5", "summary": "Here we introduce Narrative Context Protocol (NCP), an open-source narrative\nstandard designed to enable narrative interoperability, AI-driven authoring\ntools, real-time emergent narratives, and more. By encoding a story's structure\nin a \"Storyform,\" which is a structured register of its narrative features, NCP\nenables narrative portability across systems as well as intent-based\nconstraints for generative storytelling systems. We demonstrate the\ncapabilities of NCP through a year-long experiment, during which an author used\nNCP and a custom authoring platform to create a playable, text-based experience\nbased on her pre-existing novella. This experience is driven by generative AI,\nwith unconstrained natural language input. NCP functions as a set of\n\"guardrails\" that allows the generative system to accommodate player agency\nwhile also ensuring that narrative context and coherence are maintained.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.04844v5", "cate": "cs.CL", "date": "2025-03-05", "updated": "2025-07-28"}
{"id": "2410.15045", "title": "Beyond Right to be Forgotten: Managing Heterogeneity Side Effects Through Strategic Incentives", "authors": ["Jiaqi Shao", "Tao Lin", "Xiaojin Zhang", "Qiang Yang", "Bing Luo"], "categories": ["cs.GT", "cs.AI"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.15045v3", "summary": "Federated Unlearning (FU) enables the removal of specific clients' data\ninfluence from trained models. However, in non-IID settings, removing clients\ncreates critical side effects: remaining clients with similar data\ndistributions suffer disproportionate performance degradation, while the global\nmodel's stability deteriorates. These vulnerable clients then have reduced\nincentives to stay in the federation, potentially triggering a cascade of\nwithdrawals that further destabilize the system. To address this challenge, we\ndevelop a theoretical framework that quantifies how data heterogeneity impacts\nunlearning outcomes. Based on these insights, we model FU as a Stackelberg game\nwhere the server strategically offers payments to retain crucial clients based\non their contribution to both unlearning effectiveness and system stability.\nOur rigorous equilibrium analysis reveals how data heterogeneity fundamentally\nshapes the trade-offs between system-wide objectives and client interests. Our\napproach improves global stability by up to 6.23\\%, reduces worst-case client\ndegradation by 10.05\\%, and achieves up to 38.6\\% runtime efficiency over\ncomplete retraining.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.15045v3", "cate": "cs.GT", "date": "2024-10-19", "updated": "2025-07-26"}
{"id": "2403.16459", "title": "On the rates of convergence for learning with convolutional neural networks", "authors": ["Yunfei Yang", "Han Feng", "Ding-Xuan Zhou"], "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.16459v3", "summary": "We study approximation and learning capacities of convolutional neural\nnetworks (CNNs) with one-side zero-padding and multiple channels. Our first\nresult proves a new approximation bound for CNNs with certain constraint on the\nweights. Our second result gives new analysis on the covering number of\nfeed-forward neural networks with CNNs as special cases. The analysis carefully\ntakes into account the size of the weights and hence gives better bounds than\nthe existing literature in some situations. Using these two results, we are\nable to derive rates of convergence for estimators based on CNNs in many\nlearning problems. In particular, we establish minimax optimal convergence\nrates of the least squares based on CNNs for learning smooth functions in the\nnonparametric regression setting. For binary classification, we derive\nconvergence rates for CNN classifiers with hinge loss and logistic loss. It is\nalso shown that the obtained rates for classification are minimax optimal in\nsome common settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.16459v3", "cate": "cs.LG", "date": "2024-03-25", "updated": "2025-07-26"}
{"id": "2503.06424", "title": "Training LLM-based Tutors to Improve Student Learning Outcomes in Dialogues", "authors": ["Alexander Scarlatos", "Naiming Liu", "Jaewook Lee", "Richard Baraniuk", "Andrew Lan"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Published in AIED 2025: The 26th International Conference on Artificial Intelligence in Education", "url": "http://arxiv.org/abs/2503.06424v2", "summary": "Generative artificial intelligence (AI) has the potential to scale up\npersonalized tutoring through large language models (LLMs). Recent AI tutors\nare adapted for the tutoring task by training or prompting LLMs to follow\neffective pedagogical principles, though they are not trained to maximize\nstudent learning throughout the course of a dialogue. Therefore, they may\nengage with students in a suboptimal way. We address this limitation by\nintroducing an approach to train LLMs to generate tutor utterances that\nmaximize the likelihood of student correctness, while still encouraging the\nmodel to follow good pedagogical practice. Specifically, we generate a set of\ncandidate tutor utterances and score them using (1) an LLM-based student model\nto predict the chance of correct student responses and (2) a pedagogical rubric\nevaluated by GPT-4o. We then use the resulting data to train an open-source\nLLM, Llama 3.1 8B, using direct preference optimization. We show that tutor\nutterances generated by our model lead to significantly higher chances of\ncorrect student responses while maintaining the pedagogical quality of GPT-4o.\nWe also conduct qualitative analyses and a human evaluation to demonstrate that\nour model generates high quality tutor utterances.", "comment": "Published in AIED 2025: The 26th International Conference on\n  Artificial Intelligence in Education", "pdf_url": "http://arxiv.org/pdf/2503.06424v2", "cate": "cs.CL", "date": "2025-03-09", "updated": "2025-07-28"}
{"id": "2410.15956", "title": "Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs", "authors": ["Yanzhu Guo", "Simone Conia", "Zelin Zhou", "Min Li", "Saloni Potdar", "Henry Xiao"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025", "url": "http://arxiv.org/abs/2410.15956v3", "summary": "Current Large Language Models (LLMs) are predominantly designed with English\nas the primary language, and even the few that are multilingual tend to exhibit\nstrong English-centric biases. Much like speakers who might produce awkward\nexpressions when learning a second language, LLMs often generate unnatural\noutputs in non-English languages, reflecting English-centric patterns in both\nvocabulary and grammar. Despite the importance of this issue, the naturalness\nof multilingual LLM outputs has received limited attention. In this paper, we\naddress this gap by introducing novel automatic corpus-level metrics to assess\nthe lexical and syntactic naturalness of LLM outputs in a multilingual context.\nUsing our new metrics, we evaluate state-of-the-art LLMs on a curated benchmark\nin French and Chinese, revealing a tendency towards English-influenced\npatterns. To mitigate this issue, we also propose a simple and effective\nalignment method to improve the naturalness of an LLM in a target language and\ndomain, achieving consistent improvements in naturalness without compromising\nthe performance on general-purpose benchmarks. Our work highlights the\nimportance of developing multilingual metrics, resources and methods for the\nnew wave of multilingual LLMs.", "comment": "ACL 2025", "pdf_url": "http://arxiv.org/pdf/2410.15956v3", "cate": "cs.CL", "date": "2024-10-21", "updated": "2025-07-25"}
{"id": "2406.09069", "title": "On the Robustness of Global Feature Effect Explanations", "authors": ["Hubert Baniecki", "Giuseppe Casalicchio", "Bernd Bischl", "Przemyslaw Biecek"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at ECML PKDD 2024", "url": "http://arxiv.org/abs/2406.09069v2", "summary": "We study the robustness of global post-hoc explanations for predictive models\ntrained on tabular data. Effects of predictor features in black-box supervised\nlearning are an essential diagnostic tool for model debugging and scientific\ndiscovery in applied sciences. However, how vulnerable they are to data and\nmodel perturbations remains an open research question. We introduce several\ntheoretical bounds for evaluating the robustness of partial dependence plots\nand accumulated local effects. Our experimental results with synthetic and\nreal-world datasets quantify the gap between the best and worst-case scenarios\nof (mis)interpreting machine learning predictions globally.", "comment": "Accepted at ECML PKDD 2024", "pdf_url": "http://arxiv.org/pdf/2406.09069v2", "cate": "cs.LG", "date": "2024-06-13", "updated": "2025-07-28"}
{"id": "2503.13401", "title": "Levels of Analysis for Large Language Models", "authors": ["Alexander Ku", "Declan Campbell", "Xuechunzi Bai", "Jiayi Geng", "Ryan Liu", "Raja Marjieh", "R. Thomas McCoy", "Andrew Nam", "Ilia Sucholutsky", "Veniamin Veselovsky", "Liyi Zhang", "Jian-Qiao Zhu", "Thomas L. Griffiths"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.13401v2", "summary": "Modern artificial intelligence systems, such as large language models, are\nincreasingly powerful but also increasingly hard to understand. Recognizing\nthis problem as analogous to the historical difficulties in understanding the\nhuman mind, we argue that methods developed in cognitive science can be useful\nfor understanding large language models. We propose a framework for applying\nthese methods based on the levels of analysis that David Marr proposed for\nstudying information processing systems. By revisiting established cognitive\nscience techniques relevant to each level and illustrating their potential to\nyield insights into the behavior and internal organization of large language\nmodels, we aim to provide a toolkit for making sense of these new kinds of\nminds.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.13401v2", "cate": "cs.CL", "date": "2025-03-17", "updated": "2025-07-28"}
{"id": "2410.22373", "title": "Analytic Continual Test-Time Adaptation for Multi-Modality Corruption", "authors": ["Yufei Zhang", "Yicheng Xu", "Hongxin Wei", "Zhiping Lin", "Xiaofeng Zou", "Cen Chen", "Huiping Zhuang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.22373v2", "summary": "Test-Time Adaptation (TTA) enables pre-trained models to bridge the gap\nbetween source and target datasets using unlabeled test data, addressing domain\nshifts caused by corruptions like weather changes, noise, or sensor\nmalfunctions in test time. Multi-Modal Continual Test-Time Adaptation\n(MM-CTTA), as an extension of standard TTA, further allows models to handle\nmulti-modal inputs and adapt to continuously evolving target domains. However,\nMM-CTTA faces critical challenges such as catastrophic forgetting and\nreliability bias, which are rarely addressed effectively under multi-modal\ncorruption scenarios. In this paper, we propose a novel approach,\nMulti-modality Dynamic Analytic Adapter (MDAA), to tackle MM-CTTA tasks. MDAA\nintroduces analytic learning,a closed-form training technique,through Analytic\nClassifiers (ACs) to mitigate catastrophic forgetting. Furthermore, we design\nthe Dynamic Late Fusion Mechanism (DLFM) to dynamically select and integrate\nreliable information from different modalities. Extensive experiments show that\nMDAA achieves state-of-the-art performance across the proposed tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.22373v2", "cate": "cs.LG", "date": "2024-10-29", "updated": "2025-07-27"}
{"id": "2408.08554", "title": "ABQ-LLM: Arbitrary-Bit Quantized Inference Acceleration for Large Language Models", "authors": ["Chao Zeng", "Songwei Liu", "Yusheng Xie", "Hong Liu", "Xiaojian Wang", "Miao Wei", "Shu Yang", "Fangmin Chen", "Xing Mei"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      AAAI 2025", "url": "http://arxiv.org/abs/2408.08554v3", "summary": "Large Language Models (LLMs) have revolutionized natural language processing\ntasks. However, their practical application is constrained by substantial\nmemory and computational demands. Post-training quantization (PTQ) is\nconsidered an effective method to accelerate LLM inference. Despite its growing\npopularity in LLM model compression, PTQ deployment faces two major challenges.\nFirst, low-bit quantization leads to performance degradation. Second,\nrestricted by the limited integer computing unit type on GPUs, quantized matrix\noperations with different precisions cannot be effectively accelerated. To\naddress these issues, we introduce a novel arbitrary-bit quantization algorithm\nand inference framework, ABQ-LLM. It achieves superior performance across\nvarious quantization settings and enables efficient arbitrary-precision\nquantized inference on the GPU. ABQ-LLM introduces several key innovations: (1)\na distribution correction method for transformer blocks to mitigate\ndistribution differences caused by full quantization of weights and\nactivations, improving performance at low bit-widths. (2) the bit balance\nstrategy to counteract performance degradation from asymmetric distribution\nissues at very low bit-widths (e.g., 2-bit). (3) an innovative quantization\nacceleration framework that reconstructs the quantization matrix multiplication\nof arbitrary precision combinations based on BTC (Binary TensorCore)\nequivalents, gets rid of the limitations of INT4/INT8 computing units. ABQ-LLM\ncan convert each component bit width gain into actual acceleration gain,\nmaximizing performance under mixed precision(e.g., W6A6, W2A8). Based on W2*A8\nquantization configuration on LLaMA-7B model, it achieved a WikiText2\nperplexity of 7.59 (2.17$\\downarrow $ vs 9.76 in AffineQuant). Compared to\nSmoothQuant, we realized 1.6$\\times$ acceleration improvement and 2.7$\\times$\nmemory compression gain.", "comment": "AAAI 2025", "pdf_url": "http://arxiv.org/pdf/2408.08554v3", "cate": "cs.LG", "date": "2024-08-16", "updated": "2025-07-27"}
{"id": "2503.16531", "title": "EEG-CLIP : Learning EEG representations from natural language descriptions", "authors": ["Tidiane Camaret Ndir", "Robin Tibor Schirrmeister", "Tonio Ball"], "categories": ["cs.CL", "cs.LG", "eess.SP"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.16531v2", "summary": "Deep networks for electroencephalogram (EEG) decoding are often only trained\nto solve one specific task, such as pathology or age decoding. A more general\ntask-agnostic approach is to train deep networks to match a (clinical) EEG\nrecording to its corresponding textual medical report and vice versa. This\napproach was pioneered in the computer vision domain matching images and their\ntext captions and subsequently allowed to do successful zero-shot decoding\nusing textual class prompts. In this work, we follow this approach and develop\na contrastive learning framework, EEG-CLIP, that aligns the EEG time series and\nthe descriptions of the corresponding clinical text in a shared embedding\nspace. We investigated its potential for versatile EEG decoding, evaluating\nperformance in a range of few-shot and zero-shot settings. Overall, we show\nthat EEG-CLIP manages to non-trivially align text and EEG representations. Our\nwork presents a promising approach to learn general EEG representations, which\ncould enable easier analyses of diverse decoding questions through zero-shot\ndecoding or training task-specific models from fewer training examples. The\ncode for reproducing our results is available at\nhttps://github.com/tidiane-camaret/EEGClip", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.16531v2", "cate": "cs.CL", "date": "2025-03-18", "updated": "2025-07-29"}
{"id": "2412.15748", "title": "Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models", "authors": ["Shamus Sim", "Tyrone Chen"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      25 pages, 7 figures, 3 tables. Conceptualization, both authors. formal analysis, both authors. funding acquisition, both authors. investigation, both authors. resources, both authors. supervision, T.C.. validation, both authors. visualization, both authors. writing original draft, both authors. writing review and editing, both authors", "url": "http://arxiv.org/abs/2412.15748v2", "summary": "Background: Despite the current ubiquity of Large Language Models (LLMs)\nacross the medical domain, there is a surprising lack of studies which address\ntheir reasoning behaviour. We emphasise the importance of understanding\nreasoning behaviour as opposed to high-level prediction accuracies, since it is\nequivalent to explainable AI (XAI) in this context. In particular, achieving\nXAI in medical LLMs used in the clinical domain will have a significant impact\nacross the healthcare sector. Results: Therefore, in this work, we adapt the\nexisting concept of reasoning behaviour and articulate its interpretation\nwithin the specific context of medical LLMs. We survey and categorise current\nstate-of-the-art approaches for modeling and evaluating reasoning reasoning in\nmedical LLMs. Additionally, we propose theoretical frameworks which can empower\nmedical professionals or machine learning engineers to gain insight into the\nlow-level reasoning operations of these previously obscure models. We also\noutline key open challenges facing the development of Large Reasoning Models.\nConclusion: The subsequent increased transparency and trust in medical machine\nlearning models by clinicians as well as patients will accelerate the\nintegration, application as well as further development of medical AI for the\nhealthcare system as a whole.", "comment": "25 pages, 7 figures, 3 tables. Conceptualization, both authors.\n  formal analysis, both authors. funding acquisition, both authors.\n  investigation, both authors. resources, both authors. supervision, T.C..\n  validation, both authors. visualization, both authors. writing original\n  draft, both authors. writing review and editing, both authors", "pdf_url": "http://arxiv.org/pdf/2412.15748v2", "cate": "cs.CL", "date": "2024-12-20", "updated": "2025-07-28"}
{"id": "2410.19868", "title": "Hypergraph Neural Networks Reveal Spatial Domains from Single-cell Transcriptomics Data", "authors": ["Mehrad Soltani", "Luis Rueda"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.19868v2", "summary": "The task of spatial clustering of transcriptomics data is of paramount\nimportance. It enables the classification of tissue samples into diverse\nsubpopulations of cells, which, in turn, facilitates the analysis of the\nbiological functions of clusters, tissue reconstruction, and cell-cell\ninteractions. Many approaches leverage gene expressions, spatial locations, and\nhistological images to detect spatial domains; however, Graph Neural Networks\n(GNNs) as state of the art models suffer from a limitation in the assumption of\npairwise connections between nodes. In the case of domain detection in spatial\ntranscriptomics, some cells are found to be not directly related. Still, they\nare grouped as the same domain, which shows the incapability of GNNs for\ncapturing implicit connections among the cells.\n  While graph edges connect only two nodes, hyperedges connect an arbitrary\nnumber of nodes along their edges, which lets Hypergraph Neural Networks\n(HGNNs) capture and utilize richer and more complex structural information than\ntraditional GNNs. We use autoencoders to address the limitation of not having\nthe actual labels, which are well-suited for unsupervised learning. Our model\nhas demonstrated exceptional performance, achieving the highest iLISI score of\n1.843 compared to other methods. This score indicates the greatest diversity of\ncell types identified by our method. Furthermore, our model outperforms other\nmethods in downstream clustering, achieving the highest ARI values of 0.51 and\nLeiden score of 0.60.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.19868v2", "cate": "cs.LG", "date": "2024-10-23", "updated": "2025-07-27"}
{"id": "2503.20797", "title": "\"Whose Side Are You On?\" Estimating Ideology of Political and News Content Using Large Language Models and Few-shot Demonstration Selection", "authors": ["Muhammad Haroon", "Magdalena Wojcieszak", "Anshuman Chhabra"], "categories": ["cs.CL", "cs.CY", "cs.SI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.20797v2", "summary": "The rapid growth of social media platforms has led to concerns about\nradicalization, filter bubbles, and content bias. Existing approaches to\nclassifying ideology are limited in that they require extensive human effort,\nthe labeling of large datasets, and are not able to adapt to evolving\nideological contexts. This paper explores the potential of Large Language\nModels (LLMs) for classifying the political ideology of online content in the\ncontext of the two-party US political spectrum through in-context learning\n(ICL). Our extensive experiments involving demonstration selection in\nlabel-balanced fashion, conducted on three datasets comprising news articles\nand YouTube videos, reveal that our approach significantly outperforms\nzero-shot and traditional supervised methods. Additionally, we evaluate the\ninfluence of metadata (e.g., content source and descriptions) on ideological\nclassification and discuss its implications. Finally, we show how providing the\nsource for political and non-political content influences the LLM's\nclassification.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.20797v2", "cate": "cs.CL", "date": "2025-03-23", "updated": "2025-07-29"}
{"id": "2412.19124", "title": "Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for Robustness, Generalizability, and Multi-Domain Impact", "authors": ["Valay Bundele", "Karahan Sarıtaş", "Bora Kargi", "Oğuz Ata Çal", "Kıvanç Tezören", "Zohreh Ghaderi", "Hendrik Lensch"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.19124v2", "summary": "Self-supervised learning (SSL) has emerged as a promising paradigm in medical\nimaging, addressing the chronic challenge of limited labeled data in healthcare\nsettings. While SSL has shown impressive results, existing studies in the\nmedical domain are often limited in scope, focusing on specific datasets or\nmodalities, or evaluating only isolated aspects of model performance. This\nfragmented evaluation approach poses a significant challenge, as models\ndeployed in critical medical settings must not only achieve high accuracy but\nalso demonstrate robust performance and generalizability across diverse\ndatasets and varying conditions. To address this gap, we present a\ncomprehensive evaluation of SSL methods within the medical domain, with a\nparticular focus on robustness and generalizability. Using the MedMNIST dataset\ncollection as a standardized benchmark, we evaluate 8 major SSL methods across\n11 different medical datasets. Our study provides an in-depth analysis of model\nperformance in both in-domain scenarios and the detection of\nout-of-distribution (OOD) samples, while exploring the effect of various\ninitialization strategies, model architectures, and multi-domain pre-training.\nWe further assess the generalizability of SSL methods through cross-dataset\nevaluations and the in-domain performance with varying label proportions (1%,\n10%, and 100%) to simulate real-world scenarios with limited supervision. We\nhope this comprehensive benchmark helps practitioners and researchers make more\ninformed decisions when applying SSL methods to medical applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.19124v2", "cate": "cs.CV", "date": "2024-12-26", "updated": "2025-07-26"}
{"id": "2410.23179", "title": "Does equivariance matter at scale?", "authors": ["Johann Brehmer", "Sönke Behrends", "Pim de Haan", "Taco Cohen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Version published in TMLR", "url": "http://arxiv.org/abs/2410.23179v2", "summary": "Given large datasets and sufficient compute, is it beneficial to design\nneural architectures for the structure and symmetries of each problem? Or is it\nmore efficient to learn them from data? We study empirically how equivariant\nand non-equivariant networks scale with compute and training samples. Focusing\non a benchmark problem of rigid-body interactions and on general-purpose\ntransformer architectures, we perform a series of experiments, varying the\nmodel size, training steps, and dataset size. We find evidence for three\nconclusions. First, equivariance improves data efficiency, but training\nnon-equivariant models with data augmentation can close this gap given\nsufficient epochs. Second, scaling with compute follows a power law, with\nequivariant models outperforming non-equivariant ones at each tested compute\nbudget. Finally, the optimal allocation of a compute budget onto model size and\ntraining duration differs between equivariant and non-equivariant models.", "comment": "Version published in TMLR", "pdf_url": "http://arxiv.org/pdf/2410.23179v2", "cate": "cs.LG", "date": "2024-10-30", "updated": "2025-07-27"}
{"id": "2504.00042", "title": "Beyond the Reported Cutoff: Where Large Language Models Fall Short on Financial Knowledge", "authors": ["Agam Shah", "Liqin Ye", "Sebastian Jaskowski", "Wei Xu", "Sudheer Chava"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Paper accepted at CoLM 2025", "url": "http://arxiv.org/abs/2504.00042v2", "summary": "Large Language Models (LLMs) are frequently utilized as sources of knowledge\nfor question-answering. While it is known that LLMs may lack access to\nreal-time data or newer data produced after the model's cutoff date, it is less\nclear how their knowledge spans across historical information. In this study,\nwe assess the breadth of LLMs' knowledge using financial data of U.S. publicly\ntraded companies by evaluating more than 197k questions and comparing model\nresponses to factual data. We further explore the impact of company\ncharacteristics, such as size, retail investment, institutional attention, and\nreadability of financial filings, on the accuracy of knowledge represented in\nLLMs. Our results reveal that LLMs are less informed about past financial\nperformance, but they display a stronger awareness of larger companies and more\nrecent information. Interestingly, at the same time, our analysis also reveals\nthat LLMs are more likely to hallucinate for larger companies, especially for\ndata from more recent years. The code, prompts, and model outputs are available\non GitHub.", "comment": "Paper accepted at CoLM 2025", "pdf_url": "http://arxiv.org/pdf/2504.00042v2", "cate": "cs.CL", "date": "2025-03-30", "updated": "2025-07-28"}
{"id": "2501.00741", "title": "Towards End-to-End Neuromorphic Event-based 3D Object Reconstruction Without Physical Priors", "authors": ["Chuanzhi Xu", "Langyi Chen", "Haodong Chen", "Vera Chung", "Qiang Qu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, 5 tables, accepted by IEEE International Conference on Multimedia & Expo (ICME) 2025", "url": "http://arxiv.org/abs/2501.00741v4", "summary": "Neuromorphic cameras, also known as event cameras, are asynchronous\nbrightness-change sensors that can capture extremely fast motion without\nsuffering from motion blur, making them particularly promising for 3D\nreconstruction in extreme environments. However, existing research on 3D\nreconstruction using monocular neuromorphic cameras is limited, and most of the\nmethods rely on estimating physical priors and employ complex multi-step\npipelines. In this work, we propose an end-to-end method for dense voxel 3D\nreconstruction using neuromorphic cameras that eliminates the need to estimate\nphysical priors. Our method incorporates a novel event representation to\nenhance edge features, enabling the proposed feature-enhancement model to learn\nmore effectively. Additionally, we introduced Optimal Binarization Threshold\nSelection Principle as a guideline for future related work, using the optimal\nreconstruction results achieved with threshold optimization as the benchmark.\nOur method achieves a 54.6% improvement in reconstruction accuracy compared to\nthe baseline method.", "comment": "6 pages, 3 figures, 5 tables, accepted by IEEE International\n  Conference on Multimedia & Expo (ICME) 2025", "pdf_url": "http://arxiv.org/pdf/2501.00741v4", "cate": "cs.CV", "date": "2025-01-01", "updated": "2025-07-27"}
{"id": "2411.03713", "title": "Generalized Trusted Multi-view Classification Framework with Hierarchical Opinion Aggregation", "authors": ["Long Shi", "Chuanqing Tang", "Huangyi Deng", "Cai Xu", "Lei Xing", "Badong Chen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.03713v2", "summary": "Recently, multi-view learning has witnessed a considerable interest on the\nresearch of trusted decision-making. Previous methods are mainly inspired from\nan important paper published by Han et al. in 2021, which formulates a Trusted\nMulti-view Classification (TMC) framework that aggregates evidence from\ndifferent views based on Dempster's combination rule. All these methods only\nconsider inter-view aggregation, yet lacking exploitation of intra-view\ninformation. In this paper, we propose a generalized trusted multi-view\nclassification framework with hierarchical opinion aggregation. This\nhierarchical framework includes a two-phase aggregation process: the intra-view\nand inter-view aggregation hierarchies. In the intra aggregation, we assume\nthat each view is comprised of common information shared with other views, as\nwell as its specific information. We then aggregate both the common and\nspecific information. This aggregation phase is useful to eliminate the feature\nnoise inherent to view itself, thereby improving the view quality. In the\ninter-view aggregation, we design an attention mechanism at the evidence level\nto facilitate opinion aggregation from different views. To the best of our\nknowledge, this is one of the pioneering efforts to formulate a hierarchical\naggregation framework in the trusted multi-view learning domain. Extensive\nexperiments show that our model outperforms some state-of art trust-related\nbaselines. One can access the source code on\nhttps://github.com/lshi91/GTMC-HOA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.03713v2", "cate": "cs.LG", "date": "2024-11-06", "updated": "2025-07-27"}
{"id": "2504.04142", "title": "My Life in Artificial Intelligence: People, anecdotes, and some lessons learnt", "authors": ["Kees van Deemter"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      34 pages", "url": "http://arxiv.org/abs/2504.04142v2", "summary": "In this very personal workography, I relate my 40-year experiences as a\nresearcher and educator in and around Artificial Intelligence (AI), more\nspecifically Natural Language Processing. I describe how curiosity, and the\ncircumstances of the day, led me to work in both industry and academia, and in\nvarious countries, including The Netherlands (Amsterdam, Eindhoven, and\nUtrecht), the USA (Stanford), England (Brighton), Scotland (Aberdeen), and\nChina (Beijing and Harbin). People and anecdotes play a large role in my story;\nthe history of AI forms its backdrop. I focus on things that might be of\ninterest to (even) younger colleagues, given the choices they face in their own\nwork and life at a time when AI is finally emerging from the shadows.", "comment": "34 pages", "pdf_url": "http://arxiv.org/pdf/2504.04142v2", "cate": "cs.CL", "date": "2025-04-05", "updated": "2025-07-29"}
{"id": "2501.04873", "title": "Back Home: A Computer Vision Solution to Seashell Identification for Ecological Restoration", "authors": ["Alexander Valverde", "Luis Solano", "André Montoya"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025 (CV4E Workshop)", "url": "http://arxiv.org/abs/2501.04873v4", "summary": "Illegal souvenir collection strips an estimated five tonnes of seashells from\nCosta Rica's beaches each year. Yet, once these specimens are seized, their\ncoastal origin -- Pacific or Caribbean -- cannot be verified easily due to the\nlack of information, preventing their return when confiscated by local\nauthorities. To solve this issue, we introduce BackHome19K, the first\nlarge-scale image corpus (19,058 photographs, 516 species) annotated with\ncoast-level labels, and propose a lightweight pipeline that infers provenance\nin real time on a mobile-grade CPU. A trained anomaly filter pre-screens\nuploads, increasing robustness to user-generated noise. On a held-out test set,\nthe classifier attains 86.3% balanced accuracy, while the filter rejects 93% of\n180 out-of-domain objects with zero false negatives. Deployed as a web\napplication, the system has already processed 70,000 shells for wildlife\nofficers in under three seconds per image, enabling confiscated specimens to be\nsafely repatriated to their native ecosystems. The dataset is available at\nhttps://huggingface.co/datasets/FIFCO/BackHome19K", "comment": "ICCV 2025 (CV4E Workshop)", "pdf_url": "http://arxiv.org/pdf/2501.04873v4", "cate": "cs.CV", "date": "2025-01-08", "updated": "2025-07-29"}
{"id": "2411.19402", "title": "On the Role of Discrete Representation in Sparse Mixture of Experts", "authors": ["Giang Do", "Kha Pham", "Hung Le", "Truyen Tran"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2411.19402v2", "summary": "Sparse mixture of experts (SMoE) is an effective solution for scaling up\nmodel capacity without increasing the computational costs. A crucial component\nof SMoE is the router, responsible for directing the input to relevant experts;\nhowever, it also presents a major weakness, leading to routing inconsistencies\nand representation collapse issues. Instead of fixing the router like previous\nworks, we propose an alternative that assigns experts to input via indirection,\nwhich employs the discrete representation of input that points to the expert.\nThe discrete representations are learnt via vector quantization, resulting in a\nnew architecture dubbed Vector-Quantized Mixture of Experts (VQMoE). We provide\ntheoretical support and empirical evidence demonstrating the VQMoE's ability to\novercome the challenges present in traditional routers. Through extensive\nevaluations on both large language models and vision tasks for pre-training and\nfine-tuning, we show that VQMoE achieves a 28% improvement in robustness\ncompared to other SMoE routing methods, while maintaining strong performance in\nfine-tuning tasks.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2411.19402v2", "cate": "cs.LG", "date": "2024-11-28", "updated": "2025-07-27"}
{"id": "2504.10227", "title": "Probing then Editing Response Personality of Large Language Models", "authors": ["Tianjie Ju", "Zhenyu Shao", "Bowen Wang", "Yujia Chen", "Zhuosheng Zhang", "Hao Fei", "Mong-Li Lee", "Wynne Hsu", "Sufeng Duan", "Gongshen Liu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at COLM 2025", "url": "http://arxiv.org/abs/2504.10227v2", "summary": "Large Language Models (LLMs) have demonstrated promising capabilities to\ngenerate responses that simulate consistent personality traits. Despite the\nmajor attempts to analyze personality expression through output-based\nevaluations, little is known about how such traits are internally encoded\nwithin LLM parameters. In this paper, we introduce a layer-wise probing\nframework to systematically investigate the layer-wise capability of LLMs in\nsimulating personality for responding. We conduct probing experiments on 11\nopen-source LLMs over the PersonalityEdit benchmark and find that LLMs\npredominantly simulate personality for responding in their middle and upper\nlayers, with instruction-tuned models demonstrating a slightly clearer\nseparation of personality traits. Furthermore, by interpreting the trained\nprobing hyperplane as a layer-wise boundary for each personality category, we\npropose a layer-wise perturbation method to edit the personality expressed by\nLLMs during inference. Our results show that even when the prompt explicitly\nspecifies a particular personality, our method can still successfully alter the\nresponse personality of LLMs. Interestingly, the difficulty of converting\nbetween certain personality traits varies substantially, which aligns with the\nrepresentational distances in our probing experiments. Finally, we conduct a\ncomprehensive MMLU benchmark evaluation and time overhead analysis,\ndemonstrating that our proposed personality editing method incurs only minimal\ndegradation in general capabilities while maintaining low training costs and\nacceptable inference latency. Our code is publicly available at\nhttps://github.com/universe-sky/probing-then-editing-personality.", "comment": "Accepted at COLM 2025", "pdf_url": "http://arxiv.org/pdf/2504.10227v2", "cate": "cs.CL", "date": "2025-04-14", "updated": "2025-07-29"}
{"id": "2501.06645", "title": "FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings", "authors": ["Tong Liu", "Xiao Yu", "Wenxuan Zhou", "Jindong Gu", "Volker Tresp"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025", "url": "http://arxiv.org/abs/2501.06645v3", "summary": "Efficient preference optimization algorithms such as Direct Preference\nOptimization (DPO) have become a popular approach in aligning large language\nmodels (LLMs) with human preferences. These algorithms implicitly treat the LLM\nas a reward model, and focus on training it to correct misranked preference\npairs. However, recent work~\\citep{chen2024preference} empirically finds that\nDPO training \\textit{rarely improves these misranked preference pairs}, despite\nits gradient emphasizing on these cases. We introduce FocalPO, a DPO variant\nthat instead \\textit{down-weighs} misranked preference pairs and prioritizes\nenhancing the model's understanding of pairs that it can already rank\ncorrectly. Inspired by Focal Loss used in vision tasks, FocalPO achieves this\nby adding a modulating factor to dynamically scale DPO loss. Our experiment\ndemonstrates that FocalPO surpasses DPO and its variants on popular benchmarks\nlike Alpaca Eval 2.0 using Mistral-Base-7B and Llama-3-Instruct-8B, with the\nintroduced hyperparameter fixed. Additionally, we empirically reveals how\nFocalPO affects training on correct and incorrect sample groups, further\nunderscoring its effectiveness.", "comment": "ACL 2025", "pdf_url": "http://arxiv.org/pdf/2501.06645v3", "cate": "cs.CL", "date": "2025-01-11", "updated": "2025-07-28"}
{"id": "2412.11174", "title": "Semi-Supervised Risk Control via Prediction-Powered Inference", "authors": ["Bat-Sheva Einbinder", "Liran Ringel", "Yaniv Romano"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.11174v2", "summary": "The risk-controlling prediction sets (RCPS) framework is a general tool for\ntransforming the output of any machine learning model to design a predictive\nrule with rigorous error rate control. The key idea behind this framework is to\nuse labeled hold-out calibration data to tune a hyper-parameter that affects\nthe error rate of the resulting prediction rule. However, the limitation of\nsuch a calibration scheme is that with limited hold-out data, the tuned\nhyper-parameter becomes noisy and leads to a prediction rule with an error rate\nthat is often unnecessarily conservative. To overcome this sample-size barrier,\nwe introduce a semi-supervised calibration procedure that leverages unlabeled\ndata to rigorously tune the hyper-parameter without compromising statistical\nvalidity. Our procedure builds upon the prediction-powered inference framework,\ncarefully tailoring it to risk-controlling tasks. We demonstrate the benefits\nand validity of our proposal through two real-data experiments: few-shot image\nclassification and early time series classification.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.11174v2", "cate": "cs.LG", "date": "2024-12-15", "updated": "2025-07-27"}
{"id": "2504.10861", "title": "Ai2 Scholar QA: Organized Literature Synthesis with Attribution", "authors": ["Amanpreet Singh", "Joseph Chee Chang", "Chloe Anastasiades", "Dany Haddad", "Aakanksha Naik", "Amber Tanaka", "Angele Zamarron", "Cecile Nguyen", "Jena D. Hwang", "Jason Dunkleberger", "Matt Latzke", "Smita Rao", "Jaron Lochner", "Rob Evans", "Rodney Kinney", "Daniel S. Weld", "Doug Downey", "Sergey Feldman"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2504.10861v2", "summary": "Retrieval-augmented generation is increasingly effective in answering\nscientific questions from literature, but many state-of-the-art systems are\nexpensive and closed-source. We introduce Ai2 Scholar QA, a free online\nscientific question answering application. To facilitate research, we make our\nentire pipeline public: as a customizable open-source Python package and\ninteractive web app, along with paper indexes accessible through public APIs\nand downloadable datasets. We describe our system in detail and present\nexperiments analyzing its key design decisions. In an evaluation on a recent\nscientific QA benchmark, we find that Ai2 Scholar QA outperforms competing\nsystems.", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2504.10861v2", "cate": "cs.CL", "date": "2025-04-15", "updated": "2025-07-28"}
{"id": "2501.11992", "title": "Survey on Hand Gesture Recognition from Visual Input", "authors": ["Manousos Linardakis", "Iraklis Varlamis", "Georgios Th. Papadopoulos"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      37 pages", "url": "http://arxiv.org/abs/2501.11992v2", "summary": "Hand gesture recognition has become an important research area, driven by the\ngrowing demand for human-computer interaction in fields such as sign language\nrecognition, virtual and augmented reality, and robotics. Despite the rapid\ngrowth of the field, there are few surveys that comprehensively cover recent\nresearch developments, available solutions, and benchmark datasets. This survey\naddresses this gap by examining the latest advancements in hand gesture and 3D\nhand pose recognition from various types of camera input data including RGB\nimages, depth images, and videos from monocular or multiview cameras, examining\nthe differing methodological requirements of each approach. Furthermore, an\noverview of widely used datasets is provided, detailing their main\ncharacteristics and application domains. Finally, open challenges such as\nachieving robust recognition in real-world environments, handling occlusions,\nensuring generalization across diverse users, and addressing computational\nefficiency for real-time applications are highlighted to guide future research\ndirections. By synthesizing the objectives, methodologies, and applications of\nrecent studies, this survey offers valuable insights into current trends,\nchallenges, and opportunities for future research in human hand gesture\nrecognition.", "comment": "37 pages", "pdf_url": "http://arxiv.org/pdf/2501.11992v2", "cate": "cs.CV", "date": "2025-01-21", "updated": "2025-07-25"}
{"id": "2412.17560", "title": "GQSA: Group Quantization and Sparsity for Accelerating Large Language Model Inference", "authors": ["Chao Zeng", "Songwei Liu", "Shu Yang", "Fangmin Chen", "Lean Fu", "Xing Mei"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      14 pages", "url": "http://arxiv.org/abs/2412.17560v4", "summary": "Model compression has emerged as a mainstream solution to reduce memory usage\nand computational overhead. This paper presents Group Quantization and Sparse\nAcceleration (GQSA), a novel compression technique tailored for LLMs.\nTraditional methods typically focus exclusively on either quantization or\nsparsification, but relying on a single strategy often results in significant\nperformance loss at high compression rates. In contrast, GQSA integrates\nquantization and sparsification in a tightly coupled manner, leveraging\nGPU-friendly structured group sparsity and quantization for efficient\nacceleration. Building upon system-algorithm co-design principles, we propose a\ntwo-stage sparse optimization strategy that ensures the performance superiority\nof the compressed model. On the engine side, we introduce a \"task-centric\"\nparallel strategy, which, to the best of our knowledge, is the first\napplication in the domain of sparse computing. Compared to the traditional 2:4\nsparse method, the GQSA offers a more flexible and adjustable sparsity rate, as\nwell as a higher weight compression rate, and is efficiently compatible with\nweight-only quantization methods. Experimental results demonstrate that, under\nthe GQSA W4S50% compression setting, the model's accuracy surpasses that of\nboth 2:4 pruning and W2 quantization. Furthermore, at the inference level, GQSA\noutperforms W2 by 1.26$\\times$ and 2:4 pruning by 2.35$\\times$ in terms of\nspeed.", "comment": "14 pages", "pdf_url": "http://arxiv.org/pdf/2412.17560v4", "cate": "cs.LG", "date": "2024-12-23", "updated": "2025-07-27"}
{"id": "2505.17206", "title": "FB-RAG: Improving RAG with Forward and Backward Lookup", "authors": ["Kushal Chawla", "Alfy Samuel", "Anoop Kumar", "Daben Liu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.17206v2", "summary": "Traditional Retrieval-Augmented Generation (RAG) struggles with complex\nqueries that lack strong signals to retrieve the most relevant context, forcing\na trade-off between choosing a small context that misses key information and a\nlarge context that confuses the LLM. To address this, we propose\nForward-Backward RAG (FB-RAG), a new training-free framework based on a simple\nyet powerful forward-looking strategy. FB-RAG employs a light-weight LLM to\npeek into potential future generations, using evidence from multiple sampled\noutputs to precisely identify the most relevant context for a final, more\npowerful generator. This improves performance without complex finetuning or\nReinforcement Learning common in prior work. Across 9 datasets, FB-RAG\nconsistently delivers strong results. Further, the performance gains can be\nachieved with reduced latency due to a shorter, more focused prompt for the\npowerful generator. On EN.QA dataset, FB-RAG matches the leading baseline with\nover 48% latency reduction or achieves an 8% performance improvement with a 10%\nlatency reduction. Our analysis finds cases where even when the forward-looking\nLLM fails to generate correct answers, its attempts are sufficient to guide the\nfinal model to an accurate response, demonstrating how smaller LLMs can\nsystematically improve the performance and efficiency of larger ones.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.17206v2", "cate": "cs.CL", "date": "2025-05-22", "updated": "2025-07-29"}
{"id": "2501.15081", "title": "Can Large Language Models Be Trusted as Evolutionary Optimizers for Network-Structured Combinatorial Problems?", "authors": ["Jie Zhao", "Tao Wen", "Kang Hao Cheong"], "categories": ["cs.NE", "cs.AI"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.15081v3", "summary": "Large Language Models (LLMs) have shown strong capabilities in language\nunderstanding and reasoning across diverse domains. Recently, there has been\nincreasing interest in utilizing LLMs not merely as assistants in optimization\ntasks, but as primary optimizers, particularly for network-structured\ncombinatorial problems. However, before LLMs can be reliably deployed in this\nrole, a fundamental question must be addressed: Can LLMs iteratively manipulate\nsolutions that consistently adhere to problem constraints? In this work, we\npropose a systematic framework to evaluate the capability of LLMs to engage\nwith problem structures. Rather than treating the model as a black-box\ngenerator, we adopt the commonly used evolutionary optimizer (EVO) and propose\na comprehensive evaluation framework that rigorously assesses the output\nfidelity of LLM-based operators across different stages of the evolutionary\nprocess. To enhance robustness, we introduce a hybrid error-correction\nmechanism that mitigates uncertainty in LLMs outputs. Moreover, we explore a\ncost-efficient population-level optimization strategy that significantly\nimproves efficiency compared to traditional individual-level approaches.\nExtensive experiments on a representative node-level combinatorial network\noptimization task demonstrate the effectiveness, adaptability, and inherent\nlimitations of LLM-based EVO. Our findings present perspectives on integrating\nLLMs into evolutionary computation and discuss paths that may support scalable\nand context-aware optimization in networked systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.15081v3", "cate": "cs.NE", "date": "2025-01-25", "updated": "2025-07-26"}
{"id": "2501.18012", "title": "Growing Neural Networks: Dynamic Evolution through Gradient Descent", "authors": ["Anil Radhakrishnan", "John F. Lindner", "Scott T. Miller", "Sudeshna Sinha", "William L. Ditto"], "categories": ["cs.LG", "cond-mat.dis-nn"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 9 figures; adding scaling results, revised introduction, abstract, and title", "url": "http://arxiv.org/abs/2501.18012v2", "summary": "In contrast to conventional artificial neural networks, which are\nstructurally static, we present two approaches for evolving small networks into\nlarger ones during training. The first method employs an auxiliary weight that\ndirectly controls network size, while the second uses a controller-generated\nmask to modulate neuron participation. Both approaches optimize network size\nthrough the same gradient-descent algorithm that updates the network's weights\nand biases. We evaluate these growing networks on nonlinear regression and\nclassification tasks, where they consistently outperform static networks of\nequivalent final size. We then explore the hyperparameter space of these\nnetworks to find associated scaling relations relative to their static\ncounterparts. Our results suggest that starting small and growing naturally may\nbe preferable to simply starting large, particularly as neural networks\ncontinue to grow in size and energy consumption.", "comment": "11 pages, 9 figures; adding scaling results, revised introduction,\n  abstract, and title", "pdf_url": "http://arxiv.org/pdf/2501.18012v2", "cate": "cs.LG", "date": "2025-01-29", "updated": "2025-07-25"}
{"id": "2505.20779", "title": "CHIMERA: A Knowledge Base of Scientific Idea Recombinations for Research Analysis and Ideation", "authors": ["Noy Sternlicht", "Tom Hope"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2505.20779v4", "summary": "A hallmark of human innovation is recombination -- the creation of novel\nideas by integrating elements from existing concepts and mechanisms. In this\nwork, we introduce CHIMERA, a large-scale Knowledge Base (KB) of over 28K\nrecombination examples automatically mined from the scientific literature.\nCHIMERA enables large-scale empirical analysis of how scientists recombine\nconcepts and draw inspiration from different areas, and enables training models\nthat propose novel, cross-disciplinary research directions. To construct this\nKB, we define a new information extraction task: identifying recombination\ninstances in scientific abstracts. We curate a high-quality, expert-annotated\ndataset and use it to fine-tune a large language model, which we apply to a\nbroad corpus of AI papers. We showcase the utility of CHIMERA through two\napplications. First, we analyze patterns of recombination across AI subfields.\nSecond, we train a scientific hypothesis generation model using the KB, showing\nthat it can propose novel research directions that researchers rate as\ninspiring. We release our data and code at\nhttps://github.com/noy-sternlicht/CHIMERA-KB.", "comment": "Project page: https://noy-sternlicht.github.io/CHIMERA-Web", "pdf_url": "http://arxiv.org/pdf/2505.20779v4", "cate": "cs.CL", "date": "2025-05-27", "updated": "2025-07-29"}
{"id": "2501.19364", "title": "CoSTI: Consistency Models for (a faster) Spatio-Temporal Imputation", "authors": ["Javier Solís-García", "Belén Vega-Márquez", "Juan A. Nepomuceno", "Isabel A. Nepomuceno-Chamorro"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      14 pages, 7 figures, 13 tables", "url": "http://arxiv.org/abs/2501.19364v2", "summary": "Multivariate Time Series Imputation (MTSI) is crucial for many applications,\nsuch as healthcare monitoring and traffic management, where incomplete data can\ncompromise decision-making. Existing state-of-the-art methods, like Denoising\nDiffusion Probabilistic Models (DDPMs), achieve high imputation accuracy;\nhowever, they suffer from significant computational costs and are notably\ntime-consuming due to their iterative nature. In this work, we propose CoSTI,\nan innovative adaptation of Consistency Models (CMs) for the MTSI domain. CoSTI\nemploys Consistency Training to achieve comparable imputation quality to DDPMs\nwhile drastically reducing inference times, making it more suitable for\nreal-time applications. We evaluate CoSTI across multiple datasets and missing\ndata scenarios, demonstrating up to a 98% reduction in imputation time with\nperformance on par with diffusion-based models. This work bridges the gap\nbetween efficiency and accuracy in generative imputation tasks, providing a\nscalable solution for handling missing data in critical spatio-temporal\nsystems.", "comment": "14 pages, 7 figures, 13 tables", "pdf_url": "http://arxiv.org/pdf/2501.19364v2", "cate": "cs.LG", "date": "2025-01-31", "updated": "2025-07-26"}
{"id": "2502.01416", "title": "Categorical Schrödinger Bridge Matching", "authors": ["Grigoriy Ksenofontov", "Alexander Korotin"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.01416v3", "summary": "The Schr\\\"odinger Bridge (SB) is a powerful framework for solving generative\nmodeling tasks such as unpaired domain translation. Most SB-related research\nfocuses on continuous data space $\\mathbb{R}^{D}$ and leaves open theoretical\nand algorithmic questions about applying SB methods to discrete data, e.g, on\nfinite spaces $\\mathbb{S}^{D}$. Notable examples of such sets $\\mathbb{S}$ are\ncodebooks of vector-quantized (VQ) representations of modern autoencoders,\ntokens in texts, categories of atoms in molecules, etc. In this paper, we\nprovide a theoretical and algorithmic foundation for solving SB in discrete\nspaces using the recently introduced Iterative Markovian Fitting (IMF)\nprocedure. Specifically, we theoretically justify the convergence of\ndiscrete-time IMF (D-IMF) to SB in discrete spaces. This enables us to develop\na practical computational algorithm for SB, which we call Categorical\nSchr\\\"odinger Bridge Matching (CSBM). We show the performance of CSBM via a\nseries of experiments with synthetic data and VQ representations of images. The\ncode of CSBM is available at https://github.com/gregkseno/csbm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.01416v3", "cate": "cs.LG", "date": "2025-02-03", "updated": "2025-07-25"}
{"id": "2505.23966", "title": "FLAT-LLM: Fine-grained Low-rank Activation Space Transformation for Large Language Model Compression", "authors": ["Jiayi Tian", "Ryan Solgi", "Jinming Lu", "Yifan Yang", "Hai Li", "Zheng Zhang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.23966v3", "summary": "Large Language Models (LLMs) have enabled remarkable progress in natural\nlanguage processing, yet their high computational and memory demands pose\nchallenges for deployment in resource-constrained environments. Although recent\nlow-rank decomposition methods offer a promising path for structural\ncompression, they often suffer from accuracy degradation, expensive calibration\nprocedures, and result in inefficient model architectures that hinder\nreal-world inference speedups. In this paper, we propose FLAT-LLM, a fast and\naccurate, training-free structural compression method based on fine-grained\nlow-rank transformations in the activation space. Specifically, we reduce the\nhidden dimension by transforming the weights using truncated eigenvectors\ncomputed via head-wise Principal Component Analysis, and employ a greedy budget\nredistribution strategy to adaptively allocate ranks across decoders. FLAT-LLM\nachieves efficient and effective weight compression without recovery\nfine-tuning, which could complete the calibration within a few minutes.\nEvaluated across 5 models and 11 datasets, FLAT-LLM outperforms structural\npruning baselines in generalization and downstream performance, while\ndelivering inference speedups over decomposition-based methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.23966v3", "cate": "cs.CL", "date": "2025-05-29", "updated": "2025-07-29"}
{"id": "2502.04469", "title": "Ask and Remember: A Questions-Only Replay Strategy for Continual Visual Question Answering", "authors": ["Imad Eddine Marouf", "Enzo Tartaglione", "Stephane Lathuiliere", "Joost van de Weijer"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025, 8 pages. Code: this https URL", "url": "http://arxiv.org/abs/2502.04469v2", "summary": "Continual Learning in Visual Question Answering (VQACL) requires models to\nacquire new visual-linguistic skills (plasticity) while preserving previously\nlearned knowledge (stability). The inherent multimodality of VQACL exacerbates\nthis challenge, as models must balance stability across visual and textual\ndomains while adapting to novel objects and reasoning tasks. Existing methods,\nprimarily designed for unimodal settings, often fall short in addressing this\ndual requirement. In this work, we present QUestion-only replay with Attention\nDistillation (QUAD), a novel approach for VQACL that leverages only past task\nquestions for regularization. By eliminating the need to store visual data,\nQUAD not only reduces memory overhead, but also alleviates privacy concerns.\nOur method introduces a Question-only Replay mechanism that selectively reuses\nprior task questions to counteract overfitting to the answer space of the\ncurrent task, addressing the problem out of answer set. Complementing this, we\npropose Attention Consistency Distillation to enforce both intra-modal and\ninter-modal attention consistency across tasks, preserving essential\nvisual-linguistic associations. Extensive experiments on VQAv2 and NExT-QA\ndemonstrate that QUAD significantly outperforms state-of-the-art methods,\nachieving robust performance in continual VQA. Code is available at:\nhttps://github.com/IemProg/QUAD.", "comment": "ICCV 2025, 8 pages. Code: https://github.com/IemProg/QUAD", "pdf_url": "http://arxiv.org/pdf/2502.04469v2", "cate": "cs.CV", "date": "2025-02-06", "updated": "2025-07-27"}
{"id": "2502.03876", "title": "Position: Untrained Machine Learning for Anomaly Detection by using 3D Point Cloud Data", "authors": ["Juan Du", "Dongheng Chen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figure", "url": "http://arxiv.org/abs/2502.03876v3", "summary": "Anomaly detection based on 3D point cloud data is an important research\nproblem and receives more and more attention recently. Untrained anomaly\ndetection based on only one sample is an emerging research problem motivated by\nreal manufacturing industries such as personalized manufacturing where only one\nsample can be collected without any additional labels and historical datasets.\nIdentifying anomalies accurately based on one 3D point cloud sample is a\ncritical challenge in both industrial applications and the field of machine\nlearning. This paper aims to provide a formal definition of the untrained\nanomaly detection problem based on 3D point cloud data, discuss the differences\nbetween untrained anomaly detection and current unsupervised anomaly detection\nproblems. Unlike trained unsupervised learning, untrained unsupervised learning\ndoes not rely on any data, including unlabeled data. Instead, they leverage\nprior knowledge about the surfaces and anomalies.\n  We propose three complementary methodological frameworks: the Latent Variable\nInference Framework that employs probabilistic modeling to distinguish\nanomalies; the Decomposition Framework that separates point clouds into\nreference, anomaly, and noise components through sparse learning; and the Local\nGeometry Framework that leverages neighborhood information for anomaly\nidentification. Experimental results demonstrate that untrained methods achieve\ncompetitive detection performance while offering significant computational\nadvantages, demonstrating up to a 15-fold increase in execution speed. The\nproposed methods provide viable solutions for scenarios with extreme data\nscarcity, addressing critical challenges in personalized manufacturing and\nhealthcare applications where collecting multiple samples or historical data is\ninfeasible.", "comment": "9 pages, 5 figure", "pdf_url": "http://arxiv.org/pdf/2502.03876v3", "cate": "cs.LG", "date": "2025-02-06", "updated": "2025-07-28"}
{"id": "2506.05413", "title": "SmoothRot: Combining Channel-Wise Scaling and Rotation for Quantization-Friendly LLMs", "authors": ["Patrik Czakó", "Gábor Kertész", "Sándor Szénási"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, 5 tables. Accepted to IEEE SMC 2025 conference proceedings", "url": "http://arxiv.org/abs/2506.05413v2", "summary": "We present SmoothRot, a novel post-training quantization technique to enhance\nthe efficiency of 4-bit quantization in Large Language Models (LLMs). SmoothRot\naddresses the critical challenge of massive activation outliers, by integrating\nchannel-wise scaling with Hadamard transformations. Our technique effectively\ntransforms extreme outliers into quantization-friendly activations,\nsignificantly improving quantization accuracy. Experiments conducted on popular\nLLMs (LLaMA2 7B, LLaMA3.1 8B, and Mistral 7B) demonstrate that SmoothRot\nconsistently reduces the performance gap between quantized and FP16 models by\napproximately 10-30\\% across language generation and zero-shot reasoning tasks,\nwithout introducing additional inference latency. Code is available at\nhttps://github.com/czakop/smoothrot.", "comment": "6 pages, 3 figures, 5 tables. Accepted to IEEE SMC 2025 conference\n  proceedings", "pdf_url": "http://arxiv.org/pdf/2506.05413v2", "cate": "cs.CL", "date": "2025-06-04", "updated": "2025-07-29"}
{"id": "2502.05719", "title": "Extended Histogram-based Outlier Score (EHBOS)", "authors": ["Tanvir Islam"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.05719v2", "summary": "Histogram-Based Outlier Score (HBOS) is a widely used outlier or anomaly\ndetection method known for its computational efficiency and simplicity.\nHowever, its assumption of feature independence limits its ability to detect\nanomalies in datasets where interactions between features are critical. In this\npaper, we propose the Extended Histogram-Based Outlier Score (EHBOS), which\nenhances HBOS by incorporating two-dimensional histograms to capture\ndependencies between feature pairs. This extension allows EHBOS to identify\ncontextual and dependency-driven anomalies that HBOS fails to detect. We\nevaluate EHBOS on 17 benchmark datasets, demonstrating its effectiveness and\nrobustness across diverse anomaly detection scenarios. EHBOS outperforms HBOS\non several datasets, particularly those where feature interactions are critical\nin defining the anomaly structure, achieving notable improvements in ROC AUC.\nThese results highlight that EHBOS can be a valuable extension to HBOS, with\nthe ability to model complex feature dependencies. EHBOS offers a powerful new\ntool for anomaly detection, particularly in datasets where contextual or\nrelational anomalies play a significant role.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.05719v2", "cate": "cs.LG", "date": "2025-02-08", "updated": "2025-07-26"}
{"id": "2502.09130", "title": "Finite-Time Analysis of Discrete-Time Stochastic Interpolants", "authors": ["Yuhao Liu", "Yu Chen", "Rui Hu", "Longbo Huang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.09130v2", "summary": "The stochastic interpolant framework offers a powerful approach for\nconstructing generative models based on ordinary differential equations (ODEs)\nor stochastic differential equations (SDEs) to transform arbitrary data\ndistributions. However, prior analyses of this framework have primarily focused\non the continuous-time setting, assuming a perfect solution of the underlying\nequations. In this work, we present the first discrete-time analysis of the\nstochastic interpolant framework, where we introduce an innovative\ndiscrete-time sampler and derive a finite-time upper bound on its distribution\nestimation error. Our result provides a novel quantification of how different\nfactors, including the distance between source and target distributions and\nestimation accuracy, affect the convergence rate and also offers a new\nprincipled way to design efficient schedules for convergence acceleration.\nFinally, numerical experiments are conducted on the discrete-time sampler to\ncorroborate our theoretical findings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.09130v2", "cate": "cs.LG", "date": "2025-02-13", "updated": "2025-07-28"}
{"id": "2507.05714", "title": "HIRAG: Hierarchical-Thought Instruction-Tuning Retrieval-Augmented Generation", "authors": ["YiHan Jiao", "ZheHao Tan", "Dan Yang", "DuoLin Sun", "Jie Feng", "Yue Shen", "Jian Wang", "Peng Wei"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05714v2", "summary": "Retrieval-augmented generation (RAG) has become a fundamental paradigm for\naddressing the challenges faced by large language models in handling real-time\ninformation and domain-specific problems. Traditional RAG systems primarily\nrely on the in-context learning (ICL) capabilities of the large language model\nitself. Still, in-depth research on the specific capabilities needed by the RAG\ngeneration model is lacking, leading to challenges with inconsistent document\nquality and retrieval system imperfections. Even the limited studies that\nfine-tune RAG generative models often \\textit{lack a granular focus on RAG\ntask} or \\textit{a deeper utilization of chain-of-thought processes}. To\naddress this, we propose that RAG models should possess three progressively\nhierarchical abilities (1) Filtering: the ability to select relevant\ninformation; (2) Combination: the ability to combine semantic information\nacross paragraphs; and (3) RAG-specific reasoning: the ability to further\nprocess external knowledge using internal knowledge. Thus, we introduce our new\nRAG instruction fine-tuning method, Hierarchical-Thought Instruction-Tuning\nRetrieval-Augmented Generation (HIRAG) incorporates a \"think before answering\"\nstrategy. This method enhances the model's open-book examination capability by\nutilizing multi-level progressive chain-of-thought. Experiments show that the\nHIRAG training strategy significantly improves the model's performance on\ndatasets such as RGB, PopQA, MuSiQue, HotpotQA, and PubmedQA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05714v2", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-29"}
{"id": "2502.12145", "title": "Fast or Better? Balancing Accuracy and Cost in Retrieval-Augmented Generation with Flexible User Control", "authors": ["Jinyan Su", "Jennifer Healey", "Preslav Nakov", "Claire Cardie"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.12145v2", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to\nmitigate large language model (LLM) hallucinations by incorporating external\nknowledge retrieval. However, existing RAG frameworks often apply retrieval\nindiscriminately,leading to inefficiencies-over-retrieving when unnecessary or\nfailing to retrieve iteratively when required for complex reasoning. Recent\nadaptive retrieval strategies, though adaptively navigates these retrieval\nstrategies, predict only based on query complexity and lacks user-driven\nflexibility, making them infeasible for diverse user application needs. In this\npaper, we introduce a novel user-controllable RAG framework that enables\ndynamic adjustment of the accuracy-cost trade-off. Our approach leverages two\nclassifiers: one trained to prioritize accuracy and another to prioritize\nretrieval efficiency. Via an interpretable control parameter $\\alpha$, users\ncan seamlessly navigate between minimal-cost retrieval and high-accuracy\nretrieval based on their specific requirements. We empirically demonstrate that\nour approach effectively balances accuracy, retrieval cost, and user\ncontrollability, making it a practical and adaptable solution for real-world\napplications. Code is available at https://github.com/JinyanSu1/Flare-Aug.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.12145v2", "cate": "cs.IR", "date": "2025-02-17", "updated": "2025-07-27"}
{"id": "2502.10505", "title": "Preference learning made easy: Everything should be understood through win rate", "authors": ["Lily H. Zhang", "Rajesh Ranganath"], "categories": ["cs.LG", "cs.CL", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025", "url": "http://arxiv.org/abs/2502.10505v2", "summary": "Preference learning, or the task of aligning generative models to preference\ncomparison data, has yet to reach the conceptual maturity of classification,\ndensity estimation, etc. To close this gap, this work presents a framework to\nunderstand preference learning starting from the sampling distribution of\npairwise preference data. First, we prove that the only evaluation of a\ngenerative model that respects both preferences and prevalences in the data\ndistribution is a form of win rate, justifying win rate as the focal point to\nunderstand preference learning. We then analyze preference learning methods as\nwin rate optimization (WRO) or non-WRO. We present novel instances of WRO\nbeyond existing examples (RLHF, NLHF) and identify two key theoretical benefits\nof all such methods. We prove that common non-WRO methods like DPO and SFT on\npreferred samples lack these properties and suggest ways to mitigate such\ntheoretical limitations. We also show that WRO underperforms in practice due\noptimization difficulties and that optimization success predicts performance\nbetter than choices which affect the objective's solution. Our analysis\nhighlights best practices for existing methods and provides recommendations for\nfuture research, guided by the principle that one should either align non-WRO\nmethods more closely with WRO or improve the optimization of WRO objectives.", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2502.10505v2", "cate": "cs.LG", "date": "2025-02-14", "updated": "2025-07-26"}
{"id": "2507.07634", "title": "FrugalRAG: Learning to retrieve and reason for multi-hop QA", "authors": ["Abhinav Java", "Srivathsan Koundinyan", "Nagarajan Natarajan", "Amit Sharma"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at ICML Workshop: Efficient Systems for Foundation Models", "url": "http://arxiv.org/abs/2507.07634v2", "summary": "We consider the problem of answering complex questions, given access to a\nlarge unstructured document corpus. The de facto approach to solving the\nproblem is to leverage language models that (iteratively) retrieve and reason\nthrough the retrieved documents, until the model has sufficient information to\ngenerate an answer. Attempts at improving this approach focus on\nretrieval-augmented generation (RAG) metrics such as accuracy and recall and\ncan be categorized into two types: (a) fine-tuning on large question answering\n(QA) datasets augmented with chain-of-thought traces, and (b) leveraging\nRL-based fine-tuning techniques that rely on question-document relevance\nsignals. However, efficiency in the number of retrieval searches is an equally\nimportant metric, which has received less attention. In this work, we show\nthat: (1) Large-scale fine-tuning is not needed to improve RAG metrics,\ncontrary to popular claims in recent literature. Specifically, a standard ReAct\npipeline with improved prompts can outperform state-of-the-art methods on\nbenchmarks such as HotPotQA. (2) Supervised and RL-based fine-tuning can help\nRAG from the perspective of frugality, i.e., the latency due to number of\nsearches at inference time. For example, we show that we can achieve\ncompetitive RAG metrics at nearly half the cost (in terms of number of\nsearches) on popular RAG benchmarks, using the same base model, and at a small\ntraining cost (1000 examples).", "comment": "Accepted at ICML Workshop: Efficient Systems for Foundation Models", "pdf_url": "http://arxiv.org/pdf/2507.07634v2", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-29"}
{"id": "2502.15278", "title": "CopyJudge: Automated Copyright Infringement Identification and Mitigation in Text-to-Image Diffusion Models", "authors": ["Shunchang Liu", "Zhuan Shi", "Lingjuan Lyu", "Yaochu Jin", "Boi Faltings"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACM MM 2025", "url": "http://arxiv.org/abs/2502.15278v2", "summary": "Assessing whether AI-generated images are substantially similar to source\nworks is a crucial step in resolving copyright disputes. In this paper, we\npropose CopyJudge, a novel automated infringement identification framework that\nleverages large vision-language models (LVLMs) to simulate practical court\nprocesses for determining substantial similarity between copyrighted images and\nthose generated by text-to-image diffusion models. Specifically, we employ an\nabstraction-filtration-comparison test framework based on the multi-LVLM debate\nto assess the likelihood of infringement and provide detailed judgment\nrationales. Based on these judgments, we further introduce a general LVLM-based\nmitigation strategy that automatically optimizes infringing prompts by avoiding\nsensitive expressions while preserving the non-infringing content. Furthermore,\nassuming the input noise is controllable, our approach can be enhanced by\niteratively exploring non-infringing noise vectors within the diffusion latent\nspace, even without modifying the original prompts. Experimental results show\nthat our automated identification method achieves comparable state-of-the-art\nperformance, while offering superior generalization and interpretability across\nvarious forms of infringement, and that our mitigation method more effectively\nmitigates memorization and IP infringement with a high degree of alignment to\nthe original non-infringing expressions.", "comment": "Accepted by ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2502.15278v2", "cate": "cs.CV", "date": "2025-02-21", "updated": "2025-07-27"}
{"id": "2502.10784", "title": "Preconditioned Inexact Stochastic ADMM for Deep Model", "authors": ["Shenglong Zhou", "Ouya Wang", "Ziyan Luo", "Yongxu Zhu", "Geoffrey Ye Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.10784v3", "summary": "The recent advancement of foundation models (FMs) has brought about a\nparadigm shift, revolutionizing various sectors worldwide. The popular\noptimizers used to train these models are stochastic gradient descent-based\nalgorithms, which face inherent limitations, such as slow convergence and\nstringent assumptions for convergence. In particular, data heterogeneity\narising from distributed settings poses significant challenges to their\ntheoretical and numerical performance. This paper develops an algorithm, PISA\n(\\textbf{P}reconditioned \\textbf{I}nexact \\textbf{S}tochastic\n\\textbf{A}lternating Direction Method of Multipliers), which enables scalable\nparallel computing and supports various preconditions, such as second-order\ninformation, second moment, and orthogonalized momentum by Newton-Schulz\niterations. Grounded in rigorous theoretical guarantees, the algorithm\nconverges under the sole assumption of Lipschitz continuity of the gradient on\na bounded region, thereby removing the need for other conditions commonly\nimposed by stochastic methods. This capability enables PISA to tackle the\nchallenge of data heterogeneity effectively. Comprehensive experimental\nevaluations for training or fine-tuning diverse deep models, including vision\nmodels, large language models, reinforcement learning models, generative\nadversarial networks, and recurrent neural networks, demonstrate its superior\nnumerical performance compared to various state-of-the-art optimizers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.10784v3", "cate": "cs.LG", "date": "2025-02-15", "updated": "2025-07-26"}
{"id": "2507.11230", "title": "Sparse Autoencoders Can Capture Language-Specific Concepts Across Diverse Languages", "authors": ["Lyzander Marciano Andrylie", "Inaya Rahmanisa", "Mahardika Krisna Ihsani", "Alfan Farizki Wicaksono", "Haryo Akbarianto Wibowo", "Alham Fikri Aji"], "categories": ["cs.CL", "68T50"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11230v2", "summary": "Understanding the multilingual mechanisms of large language models (LLMs)\nprovides insight into how they process different languages, yet this remains\nchallenging. Existing studies often focus on individual neurons, but their\npolysemantic nature makes it difficult to isolate language-specific units from\ncross-lingual representations. To address this, we explore sparse autoencoders\n(SAEs) for their ability to learn monosemantic features that represent concrete\nand abstract concepts across languages in LLMs. While some of these features\nare language-independent, the presence of language-specific features remains\nunderexplored. In this work, we introduce SAE-LAPE, a method based on feature\nactivation probability, to identify language-specific features within the\nfeed-forward network. We find that many such features predominantly appear in\nthe middle to final layers of the model and are interpretable. These features\ninfluence the model's multilingual performance and language output and can be\nused for language identification with performance comparable to fastText along\nwith more interpretability. Our code is available at\nhttps://github.com/LyzanderAndrylie/language-specific-features", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11230v2", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-29"}
{"id": "2502.18573", "title": "FactReasoner: A Probabilistic Approach to Long-Form Factuality Assessment for Large Language Models", "authors": ["Radu Marinescu", "Debarun Bhattacharjya", "Junkyu Lee", "Tigran Tchrakian", "Javier Carnerero Cano", "Yufang Hou", "Elizabeth Daly", "Alessandra Pascale"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.18573v2", "summary": "Large language models (LLMs) have demonstrated vast capabilities on\ngenerative tasks in recent years, yet they struggle with guaranteeing the\nfactual correctness of the generated content. This makes these models\nunreliable in realistic situations where factually accurate responses are\nexpected. In this paper, we propose FactReasoner, a new factuality assessor\nthat relies on probabilistic reasoning to assess the factuality of a long-form\ngenerated response. Specifically, FactReasoner decomposes the response into\natomic units, retrieves relevant contexts for them from an external knowledge\nsource, and constructs a joint probability distribution over the atoms and\ncontexts using probabilistic encodings of the logical relationships\n(entailment, contradiction) between the textual utterances corresponding to the\natoms and contexts. FactReasoner then computes the posterior probability of\nwhether atomic units in the response are supported by the retrieved contexts.\nOur experiments on labeled and unlabeled benchmark datasets demonstrate clearly\nthat FactReasoner improves considerably over state-of-the-art prompt-based\napproaches in terms of both factual precision and recall.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.18573v2", "cate": "cs.CL", "date": "2025-02-25", "updated": "2025-07-26"}
{"id": "2502.19989", "title": "Satellite-Surface-Area Machine-Learning Models for Reservoir Storage Estimation: Regime-Sensitive Evaluation and Operational Deployment at Loskop Dam, South Africa", "authors": ["Hugo Retief", "Kayathri", "Vigneswaran", "Surajit Ghosh", "Mariangel Garcia Andarcia", "Chris Dickens"], "categories": ["cs.LG", "I.m"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      20 pages, 9 Figures", "url": "http://arxiv.org/abs/2502.19989v3", "summary": "Reliable daily estimates of reservoir storage are pivotal for water\nallocation and drought response decisions in semiarid regions. Conventional\nrating curves at Loskop Dam, the primary storage on South Africa's Olifants\nRiver, have become increasingly uncertain owing to sedimentation and episodic\ndrawdown. A 40 year Digital Earth Africa (DEA) surface area archive (1984-2024)\nfused with gauged water levels to develop data driven volume predictors that\noperate under a maximum 9.14%, a 90 day drawdown constraint. Four nested\nfeature sets were examined: (i) raw water area, (ii) +a power law \"calculated\nvolume\" proxy, (iii) +six river geometry metrics, and (iv) +full supply\nelevation. Five candidate algorithms, Gradient Boosting (GB), Random Forest\n(RF), Ridge (RI), Lasso (LA) and Elastic Net (EN), were tuned using a 20 draw\nrandom search and assessed with a five fold Timeseries Split to eliminate look\nahead bias. Prediction errors were decomposed into two regimes: Low (<250 x\n10^6 cubic meters) and High (>250 x 10^6 cubic meters) storage regimes. Ridge\nregression achieved the lowest cross validated RMSE (12.3 x 10^6 cubic meters),\noutperforming GB by 16% and RF by 7%. In regime terms, Ridge was superior in\nthe Low band (18.0 ver. 22.7 MCM for GB) and tied RF in the High band (~12\nMCM). In sample diagnostics showed GB's apparent dominance (6.8-5.4 MCM) to be\nan artefact of overfitting. A Ridge meta stacked ensemble combining GB, RF, and\nRidge reduced full series RMSE to ~ 11 MCM (~ 3% of live capacity). We\nrecommend (i) GB retrained daily for routine operations, (ii) Ridge for drought\nearly warning, and (iii) the stacked blend for all weather dashboards.\nQuarterly rolling retraining and regime specific metrics are advised to\nmaintain operational accuracy below the 5% threshold mandated by the Department\nof Water and Sanitation.", "comment": "20 pages, 9 Figures", "pdf_url": "http://arxiv.org/pdf/2502.19989v3", "cate": "cs.LG", "date": "2025-02-27", "updated": "2025-07-28"}
{"id": "2507.13614", "title": "Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models", "authors": ["Sergio E. Zanotto", "Segun Aroyehun"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2412.03025", "url": "http://arxiv.org/abs/2507.13614v2", "summary": "The rapid advancements in large language models (LLMs) have significantly\nimproved their ability to generate natural language, making texts generated by\nLLMs increasingly indistinguishable from human-written texts. While recent\nresearch has primarily focused on using LLMs to classify text as either\nhuman-written and machine-generated texts, our study focus on characterizing\nthese texts using a set of linguistic features across different linguistic\nlevels such as morphology, syntax, and semantics. We select a dataset of\nhuman-written and machine-generated texts spanning 8 domains and produced by 11\ndifferent LLMs. We calculate different linguistic features such as dependency\nlength and emotionality and we use them for characterizing human-written and\nmachine-generated texts along with different sampling strategies, repetition\ncontrols and model release date. Our statistical analysis reveals that\nhuman-written texts tend to exhibit simpler syntactic structures and more\ndiverse semantic content. Furthermore, we calculate the variability of our set\nof features across models and domains. Both human and machine texts show\nstylistic diversity across domains, with humans displaying greater variation in\nour features. Finally, we apply style embeddings to further test variability\namong human-written and machine-generated texts. Notably, newer models output\ntext that is similarly variable, pointing to an homogenization of\nmachine-generated texts.", "comment": "arXiv admin note: text overlap with arXiv:2412.03025", "pdf_url": "http://arxiv.org/pdf/2507.13614v2", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-29"}
{"id": "2502.20974", "title": "Improving Open-world Continual Learning under the Constraints of Scarce Labeled Data", "authors": ["Yujie Li", "Xiangkun Wang", "Xin Yang", "Marcello Bonsangue", "Junbo Zhang", "Tianrui Li"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by KDD2025 (February Cycle)", "url": "http://arxiv.org/abs/2502.20974v2", "summary": "Open-world continual learning (OWCL) adapts to sequential tasks with open\nsamples, learning knowledge incrementally while preventing forgetting. However,\nexisting OWCL still requires a large amount of labeled data for training, which\nis often impractical in real-world applications. Given that new\ncategories/entities typically come with limited annotations and are in small\nquantities, a more realistic situation is OWCL with scarce labeled data, i.e.,\nfew-shot training samples. Hence, this paper investigates the problem of\nopen-world few-shot continual learning (OFCL), challenging in (i) learning\nunbounded tasks without forgetting previous knowledge and avoiding overfitting,\n(ii) constructing compact decision boundaries for open detection with limited\nlabeled data, and (iii) transferring knowledge about knowns and unknowns and\neven update the unknowns to knowns once the labels of open samples are learned.\nIn response, we propose a novel OFCL framework that integrates three key\ncomponents: (1) an instance-wise token augmentation (ITA) that represents and\nenriches sample representations with additional knowledge, (2) a margin-based\nopen boundary (MOB) that supports open detection with new tasks emerge over\ntime, and (3) an adaptive knowledge space (AKS) that endows unknowns with\nknowledge for the updating from unknowns to knowns. Finally, extensive\nexperiments show that the proposed OFCL framework outperforms all baselines\nremarkably with practical importance and reproducibility. The source code is\nreleased at https://github.com/liyj1201/OFCL.", "comment": "Accepted by KDD2025 (February Cycle)", "pdf_url": "http://arxiv.org/pdf/2502.20974v2", "cate": "cs.LG", "date": "2025-02-28", "updated": "2025-07-28"}
{"id": "2503.00810", "title": "Minimax Optimal Reinforcement Learning with Quasi-Optimism", "authors": ["Harin Lee", "Min-hwan Oh"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Minor corrections to constant factors", "url": "http://arxiv.org/abs/2503.00810v3", "summary": "In our quest for a reinforcement learning (RL) algorithm that is both\npractical and provably optimal, we introduce EQO (Exploration via\nQuasi-Optimism). Unlike existing minimax optimal approaches, EQO avoids\nreliance on empirical variances and employs a simple bonus term proportional to\nthe inverse of the state-action visit count. Central to EQO is the concept of\nquasi-optimism, where estimated values need not be fully optimistic, allowing\nfor a simpler yet effective exploration strategy. The algorithm achieves the\nsharpest known regret bound for tabular RL under the mildest assumptions,\nproving that fast convergence can be attained with a practical and\ncomputationally efficient approach. Empirical evaluations demonstrate that EQO\nconsistently outperforms existing algorithms in both regret performance and\ncomputational efficiency, providing the best of both theoretical soundness and\npractical effectiveness.", "comment": "Minor corrections to constant factors", "pdf_url": "http://arxiv.org/pdf/2503.00810v3", "cate": "cs.LG", "date": "2025-03-02", "updated": "2025-07-27"}
{"id": "2507.16199", "title": "WakenLLM: Evaluating Reasoning Potential and Stability in LLMs via Fine-Grained Benchmarking", "authors": ["Zipeng Ling", "Yuehao Tang", "Shuliang Liu", "Junqi Yang", "Shenghong Fu", "Chen Huang", "Kejia Huang", "Yao Wan", "Zhichao Hou", "Xuming Hu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.16199v3", "summary": "Large Language Models (LLMs) frequently output the label Unknown in reasoning\ntasks, where two scenarios may appear: (i) an input sample is genuinely\nunverifiable, but the model cannot understand why; and (ii) a verifiable\nproblem that the model fails to solve, thus outputs Unknown. We refer to these\ncases collectively as the Vague Perception phenomenon. Current evaluations\nfocus on whether such answers are honest, rather than analyzing the limits of\nLLM reasoning.\n  To address this, we introduce WakenLLM, a framework that quantifies the\nportion of Unknown output attributable to model incapacity and evaluates\nwhether stimulation can convert them into either correct answers (verifiable)\nor justified (unverifiable) responses with valid reasoning. Our method offers a\nclearer picture of the limits of LLM reasoning and the potential for\ncorrections across various datasets. Comprehensive experiments on six LLMs\nsuggest that, without any training or parameter revision, LLMs can achieve up\nto a 68.53% accuracy improvement on Vague Perception samples through guided\nunderstanding.\n  Our work reveals that current baseline methods only activate a small portion\nof LLMs' reasoning potential, indicating considerable unexplored capacity. This\nextends the theoretical upper bounds of reasoning accuracy in LLMs.\nConsequently, this study deepens our understanding of the latent reasoning\ncapacity of LLMs and offers a new perspective on addressing the Vague\nPerception phenomenon.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.16199v3", "cate": "cs.CL", "date": "2025-07-22", "updated": "2025-07-29"}
{"id": "2503.06201", "title": "Explainable Synthetic Image Detection through Diffusion Timestep Ensembling", "authors": ["Yixin Wu", "Feiran Zhang", "Tianyuan Shi", "Ruicheng Yin", "Zhenghua Wang", "Zhenliang Gan", "Xiaohua Wang", "Changze Lv", "Xiaoqing Zheng", "Xuanjing Huang"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      16 pages, 8 figures", "url": "http://arxiv.org/abs/2503.06201v2", "summary": "Recent advances in diffusion models have enabled the creation of deceptively\nreal images, posing significant security risks when misused. In this study, we\nempirically show that different timesteps of DDIM inversion reveal varying\nsubtle distinctions between synthetic and real images that are extractable for\ndetection, in the forms of such as Fourier power spectrum high-frequency\ndiscrepancies and inter-pixel variance distributions. Based on these\nobservations, we propose a novel synthetic image detection method that directly\nutilizes features of intermediately noised images by training an ensemble on\nmultiple noised timesteps, circumventing conventional reconstruction-based\nstrategies. To enhance human comprehension, we introduce a metric-grounded\nexplanation generation and refinement module to identify and explain\nAI-generated flaws. Additionally, we construct the GenHard and GenExplain\nbenchmarks to provide detection samples of greater difficulty and high-quality\nrationales for fake images. Extensive experiments show that our method achieves\nstate-of-the-art performance with 98.91% and 95.89% detection accuracy on\nregular and challenging samples respectively, and demonstrates generalizability\nand robustness. Our code and datasets are available at\nhttps://github.com/Shadowlized/ESIDE.", "comment": "16 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2503.06201v2", "cate": "cs.CV", "date": "2025-03-08", "updated": "2025-07-28"}
{"id": "2503.06339", "title": "Learning to Unlearn while Retaining: Combating Gradient Conflicts in Machine Unlearning", "authors": ["Gaurav Patel", "Qiang Qiu"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2503.06339v2", "summary": "Machine Unlearning has recently garnered significant attention, aiming to\nselectively remove knowledge associated with specific data while preserving the\nmodel's performance on the remaining data. A fundamental challenge in this\nprocess is balancing effective unlearning with knowledge retention, as naive\noptimization of these competing objectives can lead to conflicting gradients,\nhindering convergence and degrading overall performance. To address this issue,\nwe propose Learning to Unlearn while Retaining, aimed to mitigate gradient\nconflicts between unlearning and retention objectives. Our approach\nstrategically avoids conflicts through an implicit gradient regularization\nmechanism that emerges naturally within the proposed framework. This prevents\nconflicting gradients between unlearning and retention, leading to effective\nunlearning while preserving the model's utility. We validate our approach\nacross both discriminative and generative tasks, demonstrating its\neffectiveness in achieving unlearning without compromising performance on\nremaining data. Our results highlight the advantages of avoiding such gradient\nconflicts, outperforming existing methods that fail to account for these\ninteractions.", "comment": "Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.06339v2", "cate": "cs.LG", "date": "2025-03-08", "updated": "2025-07-28"}
{"id": "2507.18013", "title": "Technical Report of TeleChat2, TeleChat2.5 and T1", "authors": ["Zihan Wang", "Xinzhang Liu", "Yitong Yao", "Chao Wang", "Yu Zhao", "Zhihao Yang", "Wenmin Deng", "Kaipeng Jia", "Jiaxin Peng", "Yuyao Huang", "Sishi Xiong", "Zhuo Jiang", "Kaidong Yu", "Xiaohui Hu", "Fubei Yao", "Ruiyu Fang", "Zhuoru Jiang", "Ruiting Song", "Qiyi Xie", "Rui Xue", "Xuewei He", "Yanlei Xue", "Zhu Yuan", "Zhaoxi Zhang", "Zilu Huang", "Shiquan Wang", "Xin Wang", "Hanming Wu", "Mingyuan Wang", "Xufeng Zhan", "Yuhan Sun", "Zhaohu Xing", "Yuhao Jiang", "Bingkai Yang", "Shuangyong Song", "Yongxiang Li", "Zhongjiang He", "Xuelong Li"], "categories": ["cs.CL", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      32 pages, 5 figures", "url": "http://arxiv.org/abs/2507.18013v3", "summary": "We introduce the latest series of TeleChat models: \\textbf{TeleChat2},\n\\textbf{TeleChat2.5}, and \\textbf{T1}, offering a significant upgrade over\ntheir predecessor, TeleChat. Despite minimal changes to the model architecture,\nthe new series achieves substantial performance gains through enhanced training\nstrategies in both pre-training and post-training stages. The series begins\nwith \\textbf{TeleChat2}, which undergoes pretraining on 10 trillion\nhigh-quality and diverse tokens. This is followed by Supervised Fine-Tuning\n(SFT) and Direct Preference Optimization (DPO) to further enhance its\ncapabilities. \\textbf{TeleChat2.5} and \\textbf{T1} expand the pipeline by\nincorporating a continual pretraining phase with domain-specific datasets,\ncombined with reinforcement learning (RL) to improve performance in code\ngeneration and mathematical reasoning tasks. The \\textbf{T1} variant is\ndesigned for complex reasoning, supporting long Chain-of-Thought (CoT)\nreasoning and demonstrating substantial improvements in mathematics and coding.\nIn contrast, \\textbf{TeleChat2.5} prioritizes speed, delivering rapid\ninference. Both flagship models of \\textbf{T1} and \\textbf{TeleChat2.5} are\ndense Transformer-based architectures with 115B parameters, showcasing\nsignificant advancements in reasoning and general task performance compared to\nthe original TeleChat. Notably, \\textbf{T1-115B} outperform proprietary models\nsuch as OpenAI's o1-mini and GPT-4o. We publicly release \\textbf{TeleChat2},\n\\textbf{TeleChat2.5} and \\textbf{T1}, including post-trained versions with 35B\nand 115B parameters, to empower developers and researchers with\nstate-of-the-art language models tailored for diverse applications.", "comment": "32 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.18013v3", "cate": "cs.CL", "date": "2025-07-24", "updated": "2025-07-29"}
{"id": "2503.08026", "title": "In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents", "authors": ["Zhen Tan", "Jun Yan", "I-Hung Hsu", "Rujun Han", "Zifeng Wang", "Long T. Le", "Yiwen Song", "Yanfei Chen", "Hamid Palangi", "George Lee", "Anand Iyer", "Tianlong Chen", "Huan Liu", "Chen-Yu Lee", "Tomas Pfister"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025", "url": "http://arxiv.org/abs/2503.08026v2", "summary": "Large Language Models (LLMs) have made significant progress in open-ended\ndialogue, yet their inability to retain and retrieve relevant information from\nlong-term interactions limits their effectiveness in applications requiring\nsustained personalization. External memory mechanisms have been proposed to\naddress this limitation, enabling LLMs to maintain conversational continuity.\nHowever, existing approaches struggle with two key challenges. First, rigid\nmemory granularity fails to capture the natural semantic structure of\nconversations, leading to fragmented and incomplete representations. Second,\nfixed retrieval mechanisms cannot adapt to diverse dialogue contexts and user\ninteraction patterns. In this work, we propose Reflective Memory Management\n(RMM), a novel mechanism for long-term dialogue agents, integrating forward-\nand backward-looking reflections: (1) Prospective Reflection, which dynamically\nsummarizes interactions across granularities-utterances, turns, and\nsessions-into a personalized memory bank for effective future retrieval, and\n(2) Retrospective Reflection, which iteratively refines the retrieval in an\nonline reinforcement learning (RL) manner based on LLMs' cited evidence.\nExperiments show that RMM demonstrates consistent improvement across various\nmetrics and benchmarks. For example, RMM shows more than 10% accuracy\nimprovement over the baseline without memory management on the LongMemEval\ndataset.", "comment": "Accepted to ACL 2025", "pdf_url": "http://arxiv.org/pdf/2503.08026v2", "cate": "cs.CL", "date": "2025-03-11", "updated": "2025-07-28"}
{"id": "2503.10404", "title": "Architecture-Aware Minimization (A$^2$M): How to Find Flat Minima in Neural Architecture Search", "authors": ["Matteo Gambella", "Fabrizio Pittorino", "Manuel Roveri"], "categories": ["cs.LG", "cond-mat.dis-nn", "cs.CV", "68T07"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in the journal Machine Learning: Science and Technology - IOPscience", "url": "http://arxiv.org/abs/2503.10404v2", "summary": "Neural Architecture Search (NAS) has become an essential tool for designing\neffective and efficient neural networks. In this paper, we investigate the\ngeometric properties of neural architecture spaces commonly used in\ndifferentiable NAS methods, specifically NAS-Bench-201 and DARTS. By defining\nflatness metrics such as neighborhoods and loss barriers along paths in\narchitecture space, we reveal locality and flatness characteristics analogous\nto the well-known properties of neural network loss landscapes in weight space.\nIn particular, we find that highly accurate architectures cluster together in\nflat regions, while suboptimal architectures remain isolated, unveiling the\ndetailed geometrical structure of the architecture search landscape. Building\non these insights, we propose Architecture-Aware Minimization (A$^2$M), a novel\nanalytically derived algorithmic framework that explicitly biases, for the\nfirst time, the gradient of differentiable NAS methods towards flat minima in\narchitecture space. A$^2$M consistently improves generalization over\nstate-of-the-art DARTS-based algorithms on benchmark datasets including\nCIFAR-10, CIFAR-100, and ImageNet16-120, across both NAS-Bench-201 and DARTS\nsearch spaces. Notably, A$^2$M is able to increase the test accuracy, on\naverage across different differentiable NAS methods, by +3.60\\% on CIFAR-10,\n+4.60\\% on CIFAR-100, and +3.64\\% on ImageNet16-120, demonstrating its superior\neffectiveness in practice. A$^2$M can be easily integrated into existing\ndifferentiable NAS frameworks, offering a versatile tool for future research\nand applications in automated machine learning. We open-source our code at\nhttps://github.com/AI-Tech-Research-Lab/AsquaredM.", "comment": "Published in the journal Machine Learning: Science and Technology -\n  IOPscience", "pdf_url": "http://arxiv.org/pdf/2503.10404v2", "cate": "cs.LG", "date": "2025-03-13", "updated": "2025-07-28"}
{"id": "2507.19537", "title": "Mind the Language Gap in Digital Humanities: LLM-Aided Translation of SKOS Thesauri", "authors": ["Felix Kraus", "Nicolas Blumenröhr", "Danah Tonne", "Achim Streit"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19537v2", "summary": "We introduce WOKIE, an open-source, modular, and ready-to-use pipeline for\nthe automated translation of SKOS thesauri. This work addresses a critical need\nin the Digital Humanities (DH), where language diversity can limit access,\nreuse, and semantic interoperability of knowledge resources. WOKIE combines\nexternal translation services with targeted refinement using Large Language\nModels (LLMs), balancing translation quality, scalability, and cost. Designed\nto run on everyday hardware and be easily extended, the application requires no\nprior expertise in machine translation or LLMs. We evaluate WOKIE across\nseveral DH thesauri in 15 languages with different parameters, translation\nservices and LLMs, systematically analysing translation quality, performance,\nand ontology matching improvements. Our results show that WOKIE is suitable to\nenhance the accessibility, reuse, and cross-lingual interoperability of\nthesauri by hurdle-free automated translation and improved ontology matching\nperformance, supporting more inclusive and multilingual research\ninfrastructures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19537v2", "cate": "cs.CL", "date": "2025-07-22", "updated": "2025-07-29"}
{"id": "2503.08714", "title": "Versatile Multimodal Controls for Expressive Talking Human Animation", "authors": ["Zheng Qin", "Ruobing Zheng", "Yabing Wang", "Tianqi Li", "Zixin Zhu", "Sanping Zhou", "Ming Yang", "Le Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACM MM2025", "url": "http://arxiv.org/abs/2503.08714v4", "summary": "In filmmaking, directors typically allow actors to perform freely based on\nthe script before providing specific guidance on how to present key actions.\nAI-generated content faces similar requirements, where users not only need\nautomatic generation of lip synchronization and basic gestures from audio input\nbut also desire semantically accurate and expressive body movement that can be\n``directly guided'' through text descriptions. Therefore, we present\nVersaAnimator, a versatile framework that synthesizes expressive talking human\nvideos from arbitrary portrait images. Specifically, we design a motion\ngenerator that produces basic rhythmic movements from audio input and supports\ntext-prompt control for specific actions. The generated whole-body 3D motion\ntokens can animate portraits of various scales, producing talking heads,\nhalf-body gestures and even leg movements for whole-body images. Besides, we\nintroduce a multi-modal controlled video diffusion that generates\nphotorealistic videos, where speech signals govern lip synchronization, facial\nexpressions, and head motions while body movements are guided by the 2D poses.\nFurthermore, we introduce a token2pose translator to smoothly map 3D motion\ntokens to 2D pose sequences. This design mitigates the stiffness resulting from\ndirect 3D to 2D conversion and enhances the details of the generated body\nmovements. Extensive experiments shows that VersaAnimator synthesizes\nlip-synced and identity-preserving videos while generating expressive and\nsemantically meaningful whole-body motions.", "comment": "Accepted by ACM MM2025", "pdf_url": "http://arxiv.org/pdf/2503.08714v4", "cate": "cs.CV", "date": "2025-03-10", "updated": "2025-07-27"}
{"id": "2503.12730", "title": "TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research", "authors": ["Abir Harrasse", "Philip Quirke", "Clement Neo", "Dhruv Nathawani", "Luke Marks", "Amir Abdullah"], "categories": ["cs.LG", "cs.AI", "cs.DB"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 19 figures, 7 tables, 18 trained models", "url": "http://arxiv.org/abs/2503.12730v4", "summary": "Mechanistic interpretability research faces a gap between analyzing simple\ncircuits in toy tasks and discovering features in large models. To bridge this\ngap, we propose text-to-SQL generation as an ideal task to study, as it\ncombines the formal structure of toy tasks with real-world complexity. We\nintroduce TinySQL, a synthetic dataset, progressing from basic to advanced SQL\noperations, and train models ranging from 33M to 1B parameters to establish a\ncomprehensive testbed for interpretability. We apply multiple complementary\ninterpretability techniques, including Edge Attribution Patching and Sparse\nAutoencoders, to identify minimal circuits and components supporting SQL\ngeneration. We compare circuits for different SQL subskills, evaluating their\nminimality, reliability, and identifiability. Finally, we conduct a layerwise\nlogit lens analysis to reveal how models compose SQL queries across layers:\nfrom intent recognition to schema resolution to structured generation. Our work\nprovides a robust framework for probing and comparing interpretability methods\nin a structured, progressively complex setting.", "comment": "9 pages, 19 figures, 7 tables, 18 trained models", "pdf_url": "http://arxiv.org/pdf/2503.12730v4", "cate": "cs.LG", "date": "2025-03-17", "updated": "2025-07-27"}
{"id": "2507.19980", "title": "Exploring LLM Autoscoring Reliability in Large-Scale Writing Assessments Using Generalizability Theory", "authors": ["Dan Song", "Won-Chan Lee", "Hong Jiao"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19980v2", "summary": "This study investigates the estimation of reliability for large language\nmodels (LLMs) in scoring writing tasks from the AP Chinese Language and Culture\nExam. Using generalizability theory, the research evaluates and compares score\nconsistency between human and AI raters across two types of AP Chinese\nfree-response writing tasks: story narration and email response. These essays\nwere independently scored by two trained human raters and seven AI raters. Each\nessay received four scores: one holistic score and three analytic scores\ncorresponding to the domains of task completion, delivery, and language use.\nResults indicate that although human raters produced more reliable scores\noverall, LLMs demonstrated reasonable consistency under certain conditions,\nparticularly for story narration tasks. Composite scoring that incorporates\nboth human and AI raters improved reliability, which supports that hybrid\nscoring models may offer benefits for large-scale writing assessments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19980v2", "cate": "cs.CL", "date": "2025-07-26", "updated": "2025-07-29"}
{"id": "2503.08737", "title": "Representing 3D Shapes With 64 Latent Vectors for 3D Diffusion Models", "authors": ["In Cho", "Youngbeom Yoo", "Subin Jeon", "Seon Joo Kim"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.08737v2", "summary": "Constructing a compressed latent space through a variational autoencoder\n(VAE) is the key for efficient 3D diffusion models. This paper introduces\nCOD-VAE that encodes 3D shapes into a COmpact set of 1D latent vectors without\nsacrificing quality. COD-VAE introduces a two-stage autoencoder scheme to\nimprove compression and decoding efficiency. First, our encoder block\nprogressively compresses point clouds into compact latent vectors via\nintermediate point patches. Second, our triplane-based decoder reconstructs\ndense triplanes from latent vectors instead of directly decoding neural fields,\nsignificantly reducing computational overhead of neural fields decoding.\nFinally, we propose uncertainty-guided token pruning, which allocates resources\nadaptively by skipping computations in simpler regions and improves the decoder\nefficiency. Experimental results demonstrate that COD-VAE achieves 16x\ncompression compared to the baseline while maintaining quality. This enables\n20.8x speedup in generation, highlighting that a large number of latent vectors\nis not a prerequisite for high-quality reconstruction and generation. The code\nis available at https://github.com/join16/COD-VAE.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.08737v2", "cate": "cs.CV", "date": "2025-03-11", "updated": "2025-07-27"}
{"id": "2503.22939", "title": "Interpretable Graph Kolmogorov-Arnold Networks for Multi-Cancer Classification and Biomarker Identification using Multi-Omics Data", "authors": ["Fadi Alharbi", "Nishant Budhiraja", "Aleksandar Vakanski", "Boyu Zhang", "Murtada K. Elbashir", "Harshith Guduru", "Mohanad Mohammed"], "categories": ["cs.LG", "q-bio.QM", "68", "I.2.6"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.22939v3", "summary": "The integration of heterogeneous multi-omics datasets at a systems level\nremains a central challenge for developing analytical and computational models\nin precision cancer diagnostics. This paper introduces Multi-Omics Graph\nKolmogorov-Arnold Network (MOGKAN), a deep learning framework that utilizes\nmessenger-RNA, micro-RNA sequences, and DNA methylation samples together with\nProtein-Protein Interaction (PPI) networks for cancer classification across 31\ndifferent cancer types. The proposed approach combines differential gene\nexpression with DESeq2, Linear Models for Microarray (LIMMA), and Least\nAbsolute Shrinkage and Selection Operator (LASSO) regression to reduce\nmulti-omics data dimensionality while preserving relevant biological features.\nThe model architecture is based on the Kolmogorov-Arnold theorem principle and\nuses trainable univariate functions to enhance interpretability and feature\nanalysis. MOGKAN achieves classification accuracy of 96.28 percent and exhibits\nlow experimental variability in comparison to related deep learning-based\nmodels. The biomarkers identified by MOGKAN were validated as cancer-related\nmarkers through Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes\n(KEGG) enrichment analysis. By integrating multi-omics data with graph-based\ndeep learning, our proposed approach demonstrates robust predictive performance\nand interpretability with potential to enhance the translation of complex\nmulti-omics data into clinically actionable cancer diagnostics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.22939v3", "cate": "cs.LG", "date": "2025-03-29", "updated": "2025-07-27"}
{"id": "2507.20527", "title": "SAND-Math: Using LLMs to Generate Novel, Difficult and Useful Mathematics Questions and Answers", "authors": ["Chaitanya Manem", "Pratik Prabhanjan Brahma", "Prakamya Mishra", "Zicheng Liu", "Emad Barsoum"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.20527v2", "summary": "The demand for Large Language Models (LLMs) capable of sophisticated\nmathematical reasoning is growing across industries. However, the development\nof performant mathematical LLMs is critically bottlenecked by the scarcity of\ndifficult, novel training data. We introduce \\textbf{SAND-Math} (Synthetic\nAugmented Novel and Difficult Mathematics problems and solutions), a pipeline\nthat addresses this by first generating high-quality problems from scratch and\nthen systematically elevating their complexity via a new \\textbf{Difficulty\nHiking} step. We demonstrate the effectiveness of our approach through two key\nfindings. First, augmenting a strong baseline with SAND-Math data significantly\nboosts performance, outperforming the next-best synthetic dataset by\n\\textbf{$\\uparrow$ 17.85 absolute points} on the AIME25 benchmark. Second, in a\ndedicated ablation study, we show our Difficulty Hiking process is highly\neffective: by increasing average problem difficulty from 5.02 to 5.98, this\nstep lifts AIME25 performance from 46.38\\% to 49.23\\%. The full generation\npipeline, final dataset, and a fine-tuned model form a practical and scalable\ntoolkit for building more capable and efficient mathematical reasoning LLMs.\nSAND-Math dataset is released here:\n\\href{https://huggingface.co/datasets/amd/SAND-MATH}{https://huggingface.co/datasets/amd/SAND-MATH}", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.20527v2", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-29"}
{"id": "2503.08960", "title": "Are ECGs enough? Deep learning classification of pulmonary embolism using electrocardiograms", "authors": ["Joao D. S. Marques", "Arlindo L. Oliveira"], "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to the MIRASOL 2025 Workshop (MICCAI 2025)", "url": "http://arxiv.org/abs/2503.08960v2", "summary": "Pulmonary embolism is a leading cause of out of hospital cardiac arrest that\nrequires fast diagnosis. While computed tomography pulmonary angiography is the\nstandard diagnostic tool, it is not always accessible. Electrocardiography is\nan essential tool for diagnosing multiple cardiac anomalies, as it is\naffordable, fast and available in many settings. However, the availability of\npublic ECG datasets, specially for PE, is limited and, in practice, these\ndatasets tend to be small, making it essential to optimize learning strategies.\nIn this study, we investigate the performance of multiple neural networks in\norder to assess the impact of various approaches. Moreover, we check whether\nthese practices enhance model generalization when transfer learning is used to\ntranslate information learned in larger ECG datasets, such as PTB-XL, CPSC18\nand MedalCare-XL, to a smaller, more challenging dataset for PE. By leveraging\ntransfer learning, we analyze the extent to which we can improve learning\nefficiency and predictive performance on limited data. Code available at\nhttps://github.com/joaodsmarques/Are-ECGs-enough-Deep-Learning-Classifiers .", "comment": "Accepted to the MIRASOL 2025 Workshop (MICCAI 2025)", "pdf_url": "http://arxiv.org/pdf/2503.08960v2", "cate": "cs.CV", "date": "2025-03-11", "updated": "2025-07-28"}
{"id": "2503.23697", "title": "A Low-complexity Structured Neural Network to Realize States of Dynamical Systems", "authors": ["Hansaka Aluvihare", "Levi Lingsch", "Xianqi Li", "Sirani M. Perera"], "categories": ["cs.LG", "math.DS", "34N05, 37L05, 65L20, 65Y20, 68T07, 68T07"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      20 pages, 6 figures", "url": "http://arxiv.org/abs/2503.23697v2", "summary": "Data-driven learning is rapidly evolving and places a new perspective on\nrealizing state-space dynamical systems. However, dynamical systems derived\nfrom nonlinear ordinary differential equations (ODEs) suffer from limitations\nin computational efficiency. Thus, this paper stems from data-driven learning\nto advance states of dynamical systems utilizing a structured neural network\n(StNN). The proposed learning technique also seeks to identify an optimal,\nlow-complexity operator to solve dynamical systems, the so-called Hankel\noperator, derived from time-delay measurements. Thus, we utilize the StNN based\non the Hankel operator to solve dynamical systems as an alternative to existing\ndata-driven techniques. We show that the proposed StNN reduces the number of\nparameters and computational complexity compared with the conventional neural\nnetworks and also with the classical data-driven techniques, such as Sparse\nIdentification of Nonlinear Dynamics (SINDy) and Hankel Alternative view of\nKoopman (HAVOK), which is commonly known as delay-Dynamic Mode\nDecomposition(DMD) or Hankel-DMD. More specifically, we present numerical\nsimulations to solve dynamical systems utilizing the StNN based on the Hankel\noperator beginning from the fundamental Lotka-Volterra model, where we compare\nthe StNN with the LEarning Across Dynamical Systems (LEADS), and extend our\nanalysis to highly nonlinear and chaotic Lorenz systems, comparing the StNN\nwith conventional neural networks, SINDy, and HAVOK. Hence, we show that the\nproposed StNN paves the way for realizing state-space dynamical systems with a\nlow-complexity learning algorithm, enabling prediction and understanding of\nfuture states.", "comment": "20 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2503.23697v2", "cate": "cs.LG", "date": "2025-03-31", "updated": "2025-07-26"}
{"id": "2507.20906", "title": "Soft Injection of Task Embeddings Outperforms Prompt-Based In-Context Learning", "authors": ["Jungwon Park", "Wonjong Rhee"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.20906v2", "summary": "In-Context Learning (ICL) enables Large Language Models (LLMs) to perform\ntasks by conditioning on input-output examples in the prompt, without requiring\nany update in model parameters. While widely adopted, it remains unclear\nwhether prompting with multiple examples is the most effective and efficient\nway to convey task information. In this work, we propose Soft Injection of task\nembeddings. The task embeddings are constructed only once using few-shot ICL\nprompts and repeatedly used during inference. Soft injection is performed by\nsoftly mixing task embeddings with attention head activations using\npre-optimized mixing parameters, referred to as soft head-selection parameters.\nThis method not only allows a desired task to be performed without in-prompt\ndemonstrations but also significantly outperforms existing ICL approaches while\nreducing memory usage and compute cost at inference time. An extensive\nevaluation is performed across 57 tasks and 12 LLMs, spanning four model\nfamilies of sizes from 4B to 70B. Averaged across 57 tasks, our method\noutperforms 10-shot ICL by 10.2%-14.3% across 12 LLMs. Additional analyses show\nthat our method also serves as an insightful tool for analyzing task-relevant\nroles of attention heads, revealing that task-relevant head positions selected\nby our method transfer across similar tasks but not across dissimilar ones --\nunderscoring the task-specific nature of head functionality. Our soft injection\nmethod opens a new paradigm for reducing prompt length and improving task\nperformance by shifting task conditioning from the prompt space to the\nactivation space.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.20906v2", "cate": "cs.CL", "date": "2025-07-28", "updated": "2025-07-29"}
{"id": "2503.16421", "title": "MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance", "authors": ["Quanhao Li", "Zhen Xing", "Rui Wang", "Hui Zhang", "Qi Dai", "Zuxuan Wu"], "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2503.16421v2", "summary": "Recent advances in video generation have led to remarkable improvements in\nvisual quality and temporal coherence. Upon this, trajectory-controllable video\ngeneration has emerged to enable precise object motion control through\nexplicitly defined spatial paths. However, existing methods struggle with\ncomplex object movements and multi-object motion control, resulting in\nimprecise trajectory adherence, poor object consistency, and compromised visual\nquality. Furthermore, these methods only support trajectory control in a single\nformat, limiting their applicability in diverse scenarios. Additionally, there\nis no publicly available dataset or benchmark specifically tailored for\ntrajectory-controllable video generation, hindering robust training and\nsystematic evaluation. To address these challenges, we introduce MagicMotion, a\nnovel image-to-video generation framework that enables trajectory control\nthrough three levels of conditions from dense to sparse: masks, bounding boxes,\nand sparse boxes. Given an input image and trajectories, MagicMotion seamlessly\nanimates objects along defined trajectories while maintaining object\nconsistency and visual quality. Furthermore, we present MagicData, a\nlarge-scale trajectory-controlled video dataset, along with an automated\npipeline for annotation and filtering. We also introduce MagicBench, a\ncomprehensive benchmark that assesses both video quality and trajectory control\naccuracy across different numbers of objects. Extensive experiments demonstrate\nthat MagicMotion outperforms previous methods across various metrics. Our\nproject page are publicly available at\nhttps://quanhaol.github.io/magicmotion-site.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.16421v2", "cate": "cs.CV", "date": "2025-03-20", "updated": "2025-07-28"}
{"id": "2504.05059", "title": "MIAT: Maneuver-Intention-Aware Transformer for Spatio-Temporal Trajectory Prediction", "authors": ["Chandra Raskoti", "Iftekharul Islam", "Xuan Wang", "Weizi Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2025", "url": "http://arxiv.org/abs/2504.05059v2", "summary": "Accurate vehicle trajectory prediction is critical for safe and efficient\nautonomous driving, especially in mixed traffic environments when both\nhuman-driven and autonomous vehicles co-exist. However, uncertainties\nintroduced by inherent driving behaviors -- such as acceleration, deceleration,\nand left and right maneuvers -- pose significant challenges for reliable\ntrajectory prediction. We introduce a Maneuver-Intention-Aware Transformer\n(MIAT) architecture, which integrates a maneuver intention awareness control\nmechanism with spatiotemporal interaction modeling to enhance long-horizon\ntrajectory predictions. We systematically investigate the impact of varying\nawareness of maneuver intention on both short- and long-horizon trajectory\npredictions. Evaluated on the real-world NGSIM dataset and benchmarked against\nvarious transformer- and LSTM-based methods, our approach achieves an\nimprovement of up to 4.7% in short-horizon predictions and a 1.6% in\nlong-horizon predictions compared to other intention-aware benchmark methods.\nMoreover, by leveraging intention awareness control mechanism, MIAT realizes an\n11.1% performance boost in long-horizon predictions, with a modest drop in\nshort-horizon performance. The source code and datasets are available at\nhttps://github.com/cpraskoti/MIAT.", "comment": "Accepted to IEEE/RSJ International Conference on Intelligent Robots\n  and Systems (IROS), 2025", "pdf_url": "http://arxiv.org/pdf/2504.05059v2", "cate": "cs.LG", "date": "2025-04-07", "updated": "2025-07-26"}
{"id": "2201.01984", "title": "Image Captioning via Compact Bidirectional Architecture", "authors": ["Zijie Song", "Yuanen Zhou", "Zhenzhen Hu", "Daqing Liu", "Huixia Ben", "Richang Hong", "Meng Wang"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2201.01984v2", "summary": "Most current image captioning models typically generate captions from\nleft-to-right. This unidirectional property makes them can only leverage past\ncontext but not future context. Though refinement-based models can exploit both\npast and future context by generating a new caption in the second stage based\non pre-retrieved or pre-generated captions in the first stage, the decoder of\nthese models generally consists of two networks~(i.e. a retriever or captioner\nin the first stage and a captioner in the second stage), which can only be\nexecuted sequentially. In this paper, we introduce a Compact Bidirectional\nTransformer model for image captioning that can leverage bidirectional context\nimplicitly and explicitly while the decoder can be executed parallelly.\nSpecifically, it is implemented by tightly coupling left-to-right(L2R) and\nright-to-left(R2L) flows into a single compact model to serve as a\nregularization for implicitly exploiting bidirectional context and optionally\nallowing explicit interaction of the bidirectional flows, while the final\ncaption is chosen from either L2R or R2L flow in a sentence-level ensemble\nmanner. We conduct extensive ablation studies on MSCOCO benchmark and find that\nthe compact bidirectional architecture and the sentence-level ensemble play\nmore important roles than the explicit interaction mechanism. By combining with\nword-level ensemble seamlessly, the effect of sentence-level ensemble is\nfurther enlarged. We further extend the conventional one-flow self-critical\ntraining to the two-flows version under this architecture and achieve new\nstate-of-the-art results in comparison with non-vision-language-pretraining\nmodels. Finally, we verify the generality of this compact bidirectional\narchitecture by extending it to LSTM backbone. Source code is available at\nhttps://github.com/YuanEZhou/cbtic.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2201.01984v2", "cate": "cs.CV", "date": "2022-01-06", "updated": "2025-07-29"}
{"id": "2504.12039", "title": "RadMamba: Efficient Human Activity Recognition through Radar-based Micro-Doppler-Oriented Mamba State-Space Model", "authors": ["Yizhuo Wu", "Francesco Fioranelli", "Chang Gao"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Under Review", "url": "http://arxiv.org/abs/2504.12039v2", "summary": "Radar-based HAR has emerged as a promising alternative to conventional\nmonitoring approaches, such as wearable devices and camera-based systems, due\nto its unique privacy preservation and robustness advantages. However, existing\nsolutions based on convolutional and recurrent neural networks, although\neffective, are computationally demanding during deployment. This limits their\napplicability in scenarios with constrained resources or those requiring\nmultiple sensors. Advanced architectures, such as Vision Transformer (ViT) and\nState-Space Model (SSM) architectures, offer improved modeling capabilities and\nhave made efforts toward lightweight designs. However, their computational\ncomplexity remains relatively high. To leverage the strengths of transformer\narchitectures while simultaneously enhancing accuracy and reducing\ncomputational complexity, this paper introduces RadMamba, a\nparameter-efficient, radar micro-Doppler-oriented Mamba SSM specifically\ntailored for radar-based HAR. Across three diverse datasets, RadMamba matches\nthe top-performing previous model's 99.8% classification accuracy on Dataset\nDIAT with only 1/400 of its parameters and equals the leading models' 92.0%\naccuracy on Dataset CI4R with merely 1/10 of their parameters. In scenarios\nwith continuous sequences of actions evaluated on Dataset UoG2020, RadMamba\nsurpasses other models with significantly higher parameter counts by at least\n3%, achieving this with only 6.7k parameters. Our code is available at:\nhttps://github.com/lab-emi/AIRHAR.", "comment": "Under Review", "pdf_url": "http://arxiv.org/pdf/2504.12039v2", "cate": "cs.CV", "date": "2025-04-16", "updated": "2025-07-27"}
{"id": "2504.08994", "title": "ReCA: A Parametric ReLU Composite Activation Function", "authors": ["John Chidiac", "Danielle Azar"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.08994v2", "summary": "Activation functions have been shown to affect the performance of deep neural\nnetworks significantly. While the Rectified Linear Unit (ReLU) remains the\ndominant choice in practice, the optimal activation function for deep neural\nnetworks remains an open research question. In this paper, we propose a novel\nparametric activation function, ReCA, based on ReLU, which has been shown to\noutperform all baselines on state-of-the-art datasets using different complex\nneural network architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.08994v2", "cate": "cs.LG", "date": "2025-04-11", "updated": "2025-07-26"}
{"id": "2407.15549", "title": "Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs", "authors": ["Abhay Sheshadri", "Aidan Ewart", "Phillip Guo", "Aengus Lynch", "Cindy Wu", "Vivek Hebbar", "Henry Sleight", "Asa Cooper Stickland", "Ethan Perez", "Dylan Hadfield-Menell", "Stephen Casper"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Code at this https URL . Models at this https URL", "url": "http://arxiv.org/abs/2407.15549v3", "summary": "Large language models (LLMs) can often be made to behave in undesirable ways\nthat they are explicitly fine-tuned not to. For example, the LLM red-teaming\nliterature has produced a wide variety of 'jailbreaking' techniques to elicit\nharmful text from models that were fine-tuned to be harmless. Recent work on\nred-teaming, model editing, and interpretability suggests that this challenge\nstems from how (adversarial) fine-tuning largely serves to suppress rather than\nremove undesirable capabilities from LLMs. Prior work has introduced latent\nadversarial training (LAT) as a way to improve robustness to broad classes of\nfailures. These prior works have considered untargeted latent space attacks\nwhere the adversary perturbs latent activations to maximize loss on examples of\ndesirable behavior. Untargeted LAT can provide a generic type of robustness but\ndoes not leverage information about specific failure modes. Here, we experiment\nwith targeted LAT where the adversary seeks to minimize loss on a specific\ncompeting task. We find that it can augment a wide variety of state-of-the-art\nmethods. First, we use targeted LAT to improve robustness to jailbreaks,\noutperforming a strong R2D2 baseline with orders of magnitude less compute.\nSecond, we use it to more effectively remove backdoors with no knowledge of the\ntrigger. Finally, we use it to more effectively unlearn knowledge for specific\nundesirable tasks in a way that is also more robust to re-learning. Overall,\nour results suggest that targeted LAT can be an effective tool for defending\nagainst harmful behaviors from LLMs.", "comment": "Code at https://github.com/aengusl/latent-adversarial-training.\n  Models at https://huggingface.co/LLM-LAT", "pdf_url": "http://arxiv.org/pdf/2407.15549v3", "cate": "cs.LG", "date": "2024-07-22", "updated": "2025-07-29"}
{"id": "2504.12549", "title": "Memorization: A Close Look at Books", "authors": ["Iris Ma", "Ian Domingo", "Alberto Krone-Martins", "Pierre Baldi", "Cristina V. Lopes"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at ACL 2025 L2M2 Workshop", "url": "http://arxiv.org/abs/2504.12549v2", "summary": "To what extent can entire books be extracted from LLMs? Using the Llama 3 70B\nfamily of models, and the \"prefix-prompting\" extraction technique, we were able\nto auto-regressively reconstruct, with a very high level of similarity, one\nentire book (Alice's Adventures in Wonderland) from just the first 500 tokens.\nWe were also able to obtain high extraction rates on several other books,\npiece-wise. However, these successes do not extend uniformly to all books. We\nshow that extraction rates of books correlate with book popularity and thus,\nlikely duplication in the training data.\n  We also confirm the undoing of mitigations in the instruction-tuned Llama\n3.1, following recent work (Nasr et al., 2025). We further find that this\nundoing comes from changes to only a tiny fraction of weights concentrated\nprimarily in the lower transformer blocks. Our results provide evidence of the\nlimits of current regurgitation mitigation strategies and introduce a framework\nfor studying how fine-tuning affects the retrieval of verbatim memorization in\naligned LLMs.", "comment": "Accepted at ACL 2025 L2M2 Workshop", "pdf_url": "http://arxiv.org/pdf/2504.12549v2", "cate": "cs.CL", "date": "2025-04-17", "updated": "2025-07-27"}
{"id": "2505.00316", "title": "Surrogate modeling of Cellular-Potts Agent-Based Models as a segmentation task using the U-Net neural network architecture", "authors": ["Tien Comlekoglu", "J. Quetzalcóatl Toledo-Marín", "Tina Comlekoglu", "Douglas W. DeSimone", "Shayn M. Peirce", "Geoffrey Fox", "James A. Glazier"], "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00316v3", "summary": "The Cellular-Potts model is a powerful and ubiquitous framework for\ndeveloping computational models for simulating complex multicellular biological\nsystems. Cellular-Potts models (CPMs) are often computationally expensive due\nto the explicit modeling of interactions among large numbers of individual\nmodel agents and diffusive fields described by partial differential equations\n(PDEs). In this work, we develop a convolutional neural network (CNN) surrogate\nmodel using a U-Net architecture that accounts for periodic boundary\nconditions. We use this model to accelerate the evaluation of a mechanistic CPM\npreviously used to investigate in vitro vasculogenesis. The surrogate model was\ntrained to predict 100 computational steps ahead (Monte-Carlo steps, MCS),\naccelerating simulation evaluations by a factor of 590 times compared to CPM\ncode execution. Over multiple recursive evaluations, our model effectively\ncaptures the emergent behaviors demonstrated by the original Cellular-Potts\nmodel of such as vessel sprouting, extension and anastomosis, and contraction\nof vascular lacunae. This approach demonstrates the potential for deep learning\nto serve as efficient surrogate models for CPM simulations, enabling faster\nevaluation of computationally expensive CPM of biological processes at greater\nspatial and temporal scales.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00316v3", "cate": "cs.LG", "date": "2025-05-01", "updated": "2025-07-27"}
{"id": "2408.10635", "title": "Strategist: Self-improvement of LLM Decision Making via Bi-Level Tree Search", "authors": ["Jonathan Light", "Min Cai", "Weiqin Chen", "Guanzhi Wang", "Xiusi Chen", "Wei Cheng", "Yisong Yue", "Ziniu Hu"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      website: this https URL", "url": "http://arxiv.org/abs/2408.10635v3", "summary": "Traditional reinforcement learning and planning typically requires vast\namounts of data and training to develop effective policies. In contrast, large\nlanguage models (LLMs) exhibit strong generalization and zero-shot\ncapabilities, but struggle with tasks that require detailed planning and\ndecision-making in complex action spaces. We introduce STRATEGIST, a novel\napproach that integrates the strengths of both methods. Our approach leverages\nLLMs to search and update high-level strategies (as text), which are then\nrefined and executed by low-level Monte Carlo Tree Search (MCTS). STRATEGIST is\na generalizable framework to optimize the strategy through population-based\nself-play simulations without the need for any training data. We demonstrate\nthe effectiveness of STRATEGIST in learning optimal strategies for competitive,\nmulti-turn games with partial information, including Game of Pure Strategy\n(GOPS) and multi-agent, hidden-identity discussion games like The Resistance:\nAvalon. Our results show that agents equipped with STRATEGIST outperform those\ntrained with traditional RL methods, other LLM-based skill acquisition\ntechniques, pre-existing LLM agents across both game environments and achieves\ncomparable performance against human players.", "comment": "website: https://llm-strategist.github.io", "pdf_url": "http://arxiv.org/pdf/2408.10635v3", "cate": "cs.AI", "date": "2024-08-20", "updated": "2025-07-29"}
{"id": "2504.15041", "title": "Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification", "authors": ["Shiben Liu", "Huijie Fan", "Qiang Wang", "Baojie Fan", "Yandong Tang", "Liangqiong Qu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 5 figures", "url": "http://arxiv.org/abs/2504.15041v3", "summary": "Lifelong Person Re-identification (LReID) suffers from a key challenge in\npreserving old knowledge while adapting to new information. The existing\nsolutions include rehearsal-based and rehearsal-free methods to address this\nchallenge. Rehearsal-based approaches rely on knowledge distillation,\ncontinuously accumulating forgetting during the distillation process.\nRehearsal-free methods insufficiently learn the distribution of each domain,\nleading to forgetfulness over time. To solve these issues, we propose a novel\nDistribution-aware Forgetting Compensation (DAFC) model that explores\ncross-domain shared representation learning and domain-specific distribution\nintegration without using old exemplars or knowledge distillation. We propose a\nText-driven Prompt Aggregation (TPA) that utilizes text features to enrich\nprompt elements and guide the prompt model to learn fine-grained\nrepresentations for each instance. This can enhance the differentiation of\nidentity information and establish the foundation for domain distribution\nawareness. Then, Distribution-based Awareness and Integration (DAI) is designed\nto capture each domain-specific distribution by a dedicated expert network and\nadaptively consolidate them into a shared region in high-dimensional space. In\nthis manner, DAI can consolidate and enhance cross-domain shared representation\nlearning while alleviating catastrophic forgetting. Furthermore, we develop a\nKnowledge Consolidation Mechanism (KCM) that comprises instance-level\ndiscrimination and cross-domain consistency alignment strategies to facilitate\nmodel adaptive learning of new knowledge from the current domain and promote\nknowledge consolidation learning between acquired domain-specific\ndistributions, respectively. Experimental results show that our DAFC\noutperforms state-of-the-art methods. Our code is available at\nhttps://github.com/LiuShiBen/DAFC.", "comment": "12 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2504.15041v3", "cate": "cs.CV", "date": "2025-04-21", "updated": "2025-07-28"}
{"id": "2505.02022", "title": "NbBench: Benchmarking Language Models for Comprehensive Nanobody Tasks", "authors": ["Yiming Zhang", "Koji Tsuda"], "categories": ["cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.02022v2", "summary": "Nanobodies -- single-domain antibody fragments derived from camelid\nheavy-chain-only antibodies -- exhibit unique advantages such as compact size,\nhigh stability, and strong binding affinity, making them valuable tools in\ntherapeutics and diagnostics. While recent advances in pretrained protein and\nantibody language models (PPLMs and PALMs) have greatly enhanced biomolecular\nunderstanding, nanobody-specific modeling remains underexplored and lacks a\nunified benchmark. To address this gap, we introduce NbBench, the first\ncomprehensive benchmark suite for nanobody representation learning. Spanning\neight biologically meaningful tasks across nine curated datasets, NbBench\nencompasses structure annotation, binding prediction, and developability\nassessment. We systematically evaluate eleven representative models --\nincluding general-purpose protein LMs, antibody-specific LMs, and\nnanobody-specific LMs -- in a frozen setting. Our analysis reveals that\nantibody language models excel in antigen-related tasks, while performance on\nregression tasks such as thermostability and affinity remains challenging\nacross all models. Notably, no single model consistently outperforms others\nacross all tasks. By standardizing datasets, task definitions, and evaluation\nprotocols, NbBench offers a reproducible foundation for assessing and advancing\nnanobody modeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.02022v2", "cate": "cs.LG", "date": "2025-05-04", "updated": "2025-07-28"}
{"id": "2411.17799", "title": "Signs as Tokens: A Retrieval-Enhanced Multilingual Sign Language Generator", "authors": ["Ronglai Zuo", "Rolandos Alexandros Potamias", "Evangelos Ververas", "Jiankang Deng", "Stefanos Zafeiriou"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2411.17799v3", "summary": "Sign language is a visual language that encompasses all linguistic features\nof natural languages and serves as the primary communication method for the\ndeaf and hard-of-hearing communities. Although many studies have successfully\nadapted pretrained language models (LMs) for sign language translation\n(sign-to-text), the reverse task-sign language generation\n(text-to-sign)-remains largely unexplored. In this work, we introduce a\nmultilingual sign language model, Signs as Tokens (SOKE), which can generate 3D\nsign avatars autoregressively from text inputs using a pretrained LM. To align\nsign language with the LM, we leverage a decoupled tokenizer that discretizes\ncontinuous signs into token sequences representing various body parts. During\ndecoding, unlike existing approaches that flatten all part-wise tokens into a\nsingle sequence and predict one token at a time, we propose a multi-head\ndecoding method capable of predicting multiple tokens simultaneously. This\napproach improves inference efficiency while maintaining effective information\nfusion across different body parts. To further ease the generation process, we\npropose a retrieval-enhanced SLG approach, which incorporates external sign\ndictionaries to provide accurate word-level signs as auxiliary conditions,\nsignificantly improving the precision of generated signs. Extensive qualitative\nand quantitative evaluations demonstrate the effectiveness of SOKE.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2411.17799v3", "cate": "cs.CV", "date": "2024-11-26", "updated": "2025-07-29"}
{"id": "2504.16907", "title": "BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation", "authors": ["Ruotong Wang", "Mingli Zhu", "Jiarong Ou", "Rui Chen", "Xin Tao", "Pengfei Wan", "Baoyuan Wu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2504.16907v2", "summary": "Text-to-video (T2V) generative models have rapidly advanced and found\nwidespread applications across fields like entertainment, education, and\nmarketing. However, the adversarial vulnerabilities of these models remain\nrarely explored. We observe that in T2V generation tasks, the generated videos\noften contain substantial redundant information not explicitly specified in the\ntext prompts, such as environmental elements, secondary objects, and additional\ndetails, providing opportunities for malicious attackers to embed hidden\nharmful content. Exploiting this inherent redundancy, we introduce BadVideo,\nthe first backdoor attack framework tailored for T2V generation. Our attack\nfocuses on designing target adversarial outputs through two key strategies: (1)\nSpatio-Temporal Composition, which combines different spatiotemporal features\nto encode malicious information; (2) Dynamic Element Transformation, which\nintroduces transformations in redundant elements over time to convey malicious\ninformation. Based on these strategies, the attacker's malicious target\nseamlessly integrates with the user's textual instructions, providing high\nstealthiness. Moreover, by exploiting the temporal dimension of videos, our\nattack successfully evades traditional content moderation systems that\nprimarily analyze spatial information within individual frames. Extensive\nexperiments demonstrate that BadVideo achieves high attack success rates while\npreserving original semantics and maintaining excellent performance on clean\ninputs. Overall, our work reveals the adversarial vulnerability of T2V models,\ncalling attention to potential risks and misuse. Our project page is at\nhttps://wrt2000.github.io/BadVideo2025/.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2504.16907v2", "cate": "cs.CV", "date": "2025-04-23", "updated": "2025-07-25"}
{"id": "2505.03778", "title": "Dragonfly: a modular deep reinforcement learning library", "authors": ["Jonathan Viquerat", "Paul Garnier", "Amirhossein Bateni", "Elie Hachem"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.03778v2", "summary": "Dragonfly is a deep reinforcement learning library focused on modularity, in\norder to ease experimentation and developments. It relies on a json\nserialization that allows to swap building blocks and perform parameter sweep,\nwhile minimizing code maintenance. Some of its features are specifically\ndesigned for CPU-intensive environments, such as numerical simulations. Its\nperformance on standard agents using common benchmarks compares favorably with\nthe literature.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.03778v2", "cate": "cs.LG", "date": "2025-04-30", "updated": "2025-07-28"}
{"id": "2412.03248", "title": "AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning", "authors": ["Yiwu Zhong", "Zhuoming Liu", "Yin Li", "Liwei Wang"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2412.03248v2", "summary": "Large language models (LLMs) have enabled the creation of multi-modal LLMs\nthat exhibit strong comprehension of visual data such as images and videos.\nHowever, these models usually rely on extensive visual tokens from visual\nencoders, leading to high computational demands, which limits their\napplicability in resource-constrained environments and for long-context tasks.\nIn this work, we propose a training-free adaptive inference method for\nmulti-modal LLMs that can accommodate a broad range of efficiency requirements\nwith a minimum performance drop. Our method consists of a) iterative token\nmerging based on embedding similarity before LLMs, and b) progressive token\npruning within LLM layers based on multi-modal importance. With a minimalist\ndesign, our method can be applied to both video and image LLMs. Extensive\nexperiments on diverse video and image benchmarks demonstrate that our method\nsubstantially reduces computation load (e.g., a $\\textbf{7-fold}$ reduction in\nFLOPs) while preserving the performance of video and image LLMs. Further, at a\nsimilar computational cost, our method outperforms the state-of-the-art methods\nin long video understanding (e.g., $\\textbf{+4.6}$ on MLVU). Additionally, our\nin-depth analysis provides insights into token redundancy and LLM layer\nbehaviors, offering guidance for future research in designing efficient\nmulti-modal LLMs. Our code is available at https://github.com/LaVi-Lab/AIM.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2412.03248v2", "cate": "cs.CV", "date": "2024-12-04", "updated": "2025-07-29"}
{"id": "2504.21226", "title": "MemeBLIP2: A novel lightweight multimodal system to detect harmful memes", "authors": ["Jiaqi Liu", "Ran Tong", "Aowei Shen", "Shuzheng Li", "Changlin Yang", "Lisha Xu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      11 pages, 3 figures. Accepted at the First Workshop on Multimodal Knowledge and Language Modeling (MKLM), IJCAI-25", "url": "http://arxiv.org/abs/2504.21226v3", "summary": "Memes often merge visuals with brief text to share humor or opinions, yet\nsome memes contain harmful messages such as hate speech. In this paper, we\nintroduces MemeBLIP2, a light weight multimodal system that detects harmful\nmemes by combining image and text features effectively. We build on previous\nstudies by adding modules that align image and text representations into a\nshared space and fuse them for better classification. Using BLIP-2 as the core\nvision-language model, our system is evaluated on the PrideMM datasets. The\nresults show that MemeBLIP2 can capture subtle cues in both modalities, even in\ncases with ironic or culturally specific content, thereby improving the\ndetection of harmful material.", "comment": "11 pages, 3 figures. Accepted at the First Workshop on Multimodal\n  Knowledge and Language Modeling (MKLM), IJCAI-25", "pdf_url": "http://arxiv.org/pdf/2504.21226v3", "cate": "cs.CV", "date": "2025-04-29", "updated": "2025-07-26"}
{"id": "2505.04823", "title": "Guide your favorite protein sequence generative model", "authors": ["Junhao Xiong", "Hunter Nisonoff", "Maria Lukarska", "Ishan Gaur", "Luke M. Oltrogge", "David F. Savage", "Jennifer Listgarten"], "categories": ["cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.04823v3", "summary": "Generative machine learning models on sequences are transforming protein\nengineering. However, no principled framework exists for conditioning these\nmodels on auxiliary information, such as experimental data, in a plug-and-play\nmanner. Herein, we present ProteinGuide -- a principled and general method for\nconditioning -- by unifying a broad class of protein generative models under a\nsingle framework. We demonstrate the applicability of ProteinGuide by guiding\ntwo protein generative models, ProteinMPNN and ESM3, to generate amino acid and\nstructure token sequences, conditioned on several user-specified properties\nsuch as enhanced stability, enzyme classes, and CATH-labeled folds. We also\nused ProteinGuide with inverse folding models and our own experimental assay to\ndesign adenine base editor sequences for high activity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.04823v3", "cate": "cs.LG", "date": "2025-05-07", "updated": "2025-07-28"}
{"id": "2503.01751", "title": "SAKE: Steering Activations for Knowledge Editing", "authors": ["Marco Scialanga", "Thibault Laugel", "Vincent Grari", "Marcin Detyniecki"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.01751v2", "summary": "As Large Langue Models have been shown to memorize real-world facts, the need\nto update this knowledge in a controlled and efficient manner arises. Designed\nwith these constraints in mind, Knowledge Editing (KE) approaches propose to\nalter specific facts in pretrained models. However, they have been shown to\nsuffer from several limitations, including their lack of contextual robustness\nand their failure to generalize to logical implications related to the fact. To\novercome these issues, we propose SAKE, a steering activation method that\nmodels a fact to be edited as a distribution rather than a single prompt.\nLeveraging Optimal Transport, SAKE alters the LLM behavior over a whole\nfact-related distribution, defined as paraphrases and logical implications.\nSeveral numerical experiments demonstrate the effectiveness of this method:\nSAKE is thus able to perform more robust edits than its existing counterparts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.01751v2", "cate": "cs.AI", "date": "2025-03-03", "updated": "2025-07-29"}
{"id": "2505.03832", "title": "Video Forgery Detection for Surveillance Cameras: A Review", "authors": ["Noor B. Tayfor", "Tarik A. Rashid", "Shko M. Qader", "Bryar A. Hassan", "Mohammed H. Abdalla", "Jafar Majidpour", "Aram M. Ahmed", "Hussein M. Ali", "Aso M. Aladdin", "Abdulhady A. Abdullah", "Ahmed S. Shamsaldin", "Haval M. Sidqi", "Abdulrahman Salih", "Zaher M. Yaseen", "Azad A. Ameen", "Janmenjoy Nayak", "Mahmood Yashar Hamza"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.03832v2", "summary": "The widespread availability of video recording through smartphones and\ndigital devices has made video-based evidence more accessible than ever.\nSurveillance footage plays a crucial role in security, law enforcement, and\njudicial processes. However, with the rise of advanced video editing tools,\ntampering with digital recordings has become increasingly easy, raising\nconcerns about their authenticity. Ensuring the integrity of surveillance\nvideos is essential, as manipulated footage can lead to misinformation and\nundermine judicial decisions. This paper provides a comprehensive review of\nexisting forensic techniques used to detect video forgery, focusing on their\neffectiveness in verifying the authenticity of surveillance recordings. Various\nmethods, including compression-based analysis, frame duplication detection, and\nmachine learning-based approaches, are explored. The findings highlight the\ngrowing necessity for more robust forensic techniques to counteract evolving\nforgery methods. Strengthening video forensic capabilities will ensure that\nsurveillance recordings remain credible and admissible as legal evidence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.03832v2", "cate": "cs.CV", "date": "2025-05-04", "updated": "2025-07-28"}
{"id": "2505.07004", "title": "GuidedQuant: Large Language Model Quantization via Exploiting End Loss Guidance", "authors": ["Jinuk Kim", "Marwa El Halabi", "Wonpyo Park", "Clemens JS Schaefer", "Deokjae Lee", "Yeonhong Park", "Jae W. Lee", "Hyun Oh Song"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025", "url": "http://arxiv.org/abs/2505.07004v3", "summary": "Post-training quantization is a key technique for reducing the memory and\ninference latency of large language models by quantizing weights and\nactivations without requiring retraining. However, existing methods either (1)\nfail to account for the varying importance of hidden features to the end loss\nor, when incorporating end loss, (2) neglect the critical interactions between\nmodel weights. To address these limitations, we propose GuidedQuant, a novel\nquantization approach that integrates gradient information from the end loss\ninto the quantization objective while preserving cross-weight dependencies\nwithin output channels. GuidedQuant consistently boosts the performance of\nstate-of-the-art quantization methods across weight-only scalar, weight-only\nvector, and weight-and-activation quantization. Additionally, we introduce a\nnovel non-uniform scalar quantization algorithm, which is guaranteed to\nmonotonically decrease the quantization objective value, and outperforms\nexisting methods in this category. We release the code at\nhttps://github.com/snu-mllab/GuidedQuant.", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2505.07004v3", "cate": "cs.LG", "date": "2025-05-11", "updated": "2025-07-27"}
{"id": "2503.24358", "title": "SQuat: Subspace-orthogonal KV Cache Quantization", "authors": ["Hao Wang", "Ligong Han", "Kai Xu", "Akash Srivastava"], "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IT", "math.IT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.24358v2", "summary": "The key-value (KV) cache accelerates LLMs decoding by storing KV tensors from\npreviously generated tokens. It reduces redundant computation at the cost of\nincreased memory usage. To mitigate this overhead, existing approaches compress\nKV tensors into lower-bit representations; however, quantization errors can\naccumulate as more tokens are generated, potentially resulting in undesired\noutputs. In this paper, we introduce SQuat (Subspace-orthogonal KV cache\nquantization). It first constructs a subspace spanned by query tensors to\ncapture the most critical task-related information. During key tensor\nquantization, it enforces that the difference between the (de)quantized and\noriginal keys remains orthogonal to this subspace, minimizing the impact of\nquantization errors on the attention mechanism's outputs. SQuat requires no\nmodel fine-tuning, no additional calibration dataset for offline learning, and\nis grounded in a theoretical framework we develop. Through numerical\nexperiments, we show that our method reduces peak memory by 2.17 to 2.82,\nimproves throughput by 2.45 to 3.60, and achieves more favorable benchmark\nscores than existing KV cache quantization algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.24358v2", "cate": "cs.LG", "date": "2025-03-31", "updated": "2025-07-28"}
{"id": "2505.07119", "title": "Towards Scalable IoT Deployment for Visual Anomaly Detection via Efficient Compression", "authors": ["Arianna Stropeni", "Francesco Borsatti", "Manuel Barusco", "Davide Dalle Pezze", "Marco Fabris", "Gian Antonio Susto"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.07119v3", "summary": "Visual Anomaly Detection (VAD) is a key task in industrial settings, where\nminimizing operational costs is essential. Deploying deep learning models\nwithin Internet of Things (IoT) environments introduces specific challenges due\nto limited computational power and bandwidth of edge devices. This study\ninvestigates how to perform VAD effectively under such constraints by\nleveraging compact, efficient processing strategies. We evaluate several data\ncompression techniques, examining the tradeoff between system latency and\ndetection accuracy. Experiments on the MVTec AD benchmark demonstrate that\nsignificant compression can be achieved with minimal loss in anomaly detection\nperformance compared to uncompressed data. Current results show up to 80%\nreduction in end-to-end inference time, including edge processing,\ntransmission, and server computation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.07119v3", "cate": "cs.CV", "date": "2025-05-11", "updated": "2025-07-28"}
{"id": "2505.10457", "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "authors": ["Matteo Gambella", "Manuel Roveri"], "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures", "url": "http://arxiv.org/abs/2505.10457v2", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios.", "comment": "9 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2505.10457v2", "cate": "cs.LG", "date": "2025-05-15", "updated": "2025-07-28"}
{"id": "2505.12225", "title": "Mining Intrinsic Rewards from LLM Hidden States for Efficient Best-of-N Sampling", "authors": ["Jizhou Guo", "Zhaomin Wu", "Hanchen Yang", "Philip S. Yu"], "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.12225v2", "summary": "Enhancing Large Language Model (LLM)'s performance with best-of-N sampling is\neffective and has attracted significant attention. However, it is\ncomputationally prohibitive due to massive, data-hungry text-based reward\nmodels. By changing the data source from text to hidden states, we introduce\nSWIFT (Simple Weighted Intrinsic Feedback Technique), a novel, lightweight\ntechnique that leverages the rich information embedded in LLM hidden states to\naddress these issues, which operates on token-level and consists of only linear\nlayers. Extensive experiments show that SWIFT outperforms baselines with less\nthan 0.005% of the parameters of baselines, requiring only a few samples for\ntraining, demonstrating significant efficiency improvement. SWIFT's robust\nscalability, applicability to some closed-source models via logits, and ability\nto be combined with traditional reward models to yield further performance\ngains underscore its practical value.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.12225v2", "cate": "cs.LG", "date": "2025-05-18", "updated": "2025-07-29"}
{"id": "2505.09619", "title": "Machine Learning Solutions Integrated in an IoT Healthcare Platform for Heart Failure Risk Stratification", "authors": ["Aiman Faiz", "Claudio Pascarelli", "Gianvito Mitrano", "Gianluca Fimiani", "Marina Garofano", "Mariangela Lazoi", "Claudio Passino", "Alessia Bramanti"], "categories": ["stat.OT", "cs.AI"], "primary_category": "Subjects:       Other Statistics (stat.OT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.09619v5", "summary": "The management of chronic Heart Failure (HF) presents significant challenges\nin modern healthcare, requiring continuous monitoring, early detection of\nexacerbations, and personalized treatment strategies. In this paper, we present\na predictive model founded on Machine Learning (ML) techniques to identify\npatients at HF risk. This model is an ensemble learning approach, a modified\nstacking technique, that uses two specialized models leveraging clinical and\nechocardiographic features and then a meta-model to combine the predictions of\nthese two models. We initially assess the model on a real dataset and the\nobtained results suggest that it performs well in the stratification of\npatients at HR risk. Specifically, we obtained high sensitivity (95\\%),\nensuring that nearly all high-risk patients are identified. As for accuracy, we\nobtained 84\\%, which can be considered moderate in some ML contexts. However,\nit is acceptable given our priority of identifying patients at risk of HF\nbecause they will be asked to participate in the telemonitoring program of the\nPrediHealth research project on which some of the authors of this paper are\nworking. The initial findings also suggest that ML-based risk stratification\nmodels can serve as valuable decision-support tools not only in the PrediHealth\nproject but also for healthcare professionals, aiding in early intervention and\npersonalized patient management. To have a better understanding of the value\nand of potentiality of our predictive model, we also contrasted its results\nwith those obtained by using three baseline models. The preliminary results\nindicate that our predictive model outperforms these baselines that flatly\nconsider features, \\ie not grouping them in clinical and echocardiographic\nfeatures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.09619v5", "cate": "stat.OT", "date": "2025-04-07", "updated": "2025-07-28"}
{"id": "2505.18227", "title": "Token Reduction Should Go Beyond Efficiency in Generative Models -- From Vision, Language to Multimodality", "authors": ["Zhenglun Kong", "Yize Li", "Fanhu Zeng", "Lei Xin", "Shvat Messica", "Xue Lin", "Pu Zhao", "Manolis Kellis", "Hao Tang", "Marinka Zitnik"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2505.18227v2", "summary": "In Transformer architectures, tokens\\textemdash discrete units derived from\nraw data\\textemdash are formed by segmenting inputs into fixed-length chunks.\nEach token is then mapped to an embedding, enabling parallel attention\ncomputations while preserving the input's essential information. Due to the\nquadratic computational complexity of transformer self-attention mechanisms,\ntoken reduction has primarily been used as an efficiency strategy. This is\nespecially true in single vision and language domains, where it helps balance\ncomputational costs, memory usage, and inference latency. Despite these\nadvances, this paper argues that token reduction should transcend its\ntraditional efficiency-oriented role in the era of large generative models.\nInstead, we position it as a fundamental principle in generative modeling,\ncritically influencing both model architecture and broader applications.\nSpecifically, we contend that across vision, language, and multimodal systems,\ntoken reduction can: (i) facilitate deeper multimodal integration and\nalignment, (ii) mitigate \"overthinking\" and hallucinations, (iii) maintain\ncoherence over long inputs, and (iv) enhance training stability, etc. We\nreframe token reduction as more than an efficiency measure. By doing so, we\noutline promising future directions, including algorithm design, reinforcement\nlearning-guided token reduction, token optimization for in-context learning,\nand broader ML and scientific domains. We highlight its potential to drive new\nmodel architectures and learning strategies that improve robustness, increase\ninterpretability, and better align with the objectives of generative modeling.", "comment": "Project page:\n  https://github.com/ZLKong/Awesome-Collection-Token-Reduction", "pdf_url": "http://arxiv.org/pdf/2505.18227v2", "cate": "cs.LG", "date": "2025-05-23", "updated": "2025-07-28"}
{"id": "2505.14479", "title": "Towards Reliable Proof Generation with LLMs: A Neuro-Symbolic Approach", "authors": ["Oren Sultan", "Eitan Stern", "Dafna Shahaf"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      long paper", "url": "http://arxiv.org/abs/2505.14479v4", "summary": "Large language models (LLMs) struggle with formal domains that require\nrigorous logical deduction and symbolic reasoning, such as mathematical proof\ngeneration. We propose a neuro-symbolic approach that combines LLMs' generative\nstrengths with structured components to overcome this challenge. As a\nproof-of-concept, we focus on geometry problems. Our approach is two-fold: (1)\nwe retrieve analogous problems and use their proofs to guide the LLM, and (2) a\nformal verifier evaluates the generated proofs and provides feedback, helping\nthe model fix incorrect proofs. We demonstrate that our method significantly\nimproves proof accuracy for OpenAI's o1 model (58%-70% improvement); both\nanalogous problems and the verifier's feedback contribute to these gains. More\nbroadly, shifting to LLMs that generate provably correct conclusions could\ndramatically improve their reliability, accuracy and consistency, unlocking\ncomplex tasks and critical real-world applications that require\ntrustworthiness.", "comment": "long paper", "pdf_url": "http://arxiv.org/pdf/2505.14479v4", "cate": "cs.AI", "date": "2025-05-20", "updated": "2025-07-29"}
{"id": "2505.15075", "title": "Traveling Across Languages: Benchmarking Cross-Lingual Consistency in Multimodal LLMs", "authors": ["Hao Wang", "Pinzhi Huang", "Jihan Yang", "Saining Xie", "Daisuke Kawahara"], "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:       this https URL", "url": "http://arxiv.org/abs/2505.15075v4", "summary": "The rapid evolution of multimodal large language models (MLLMs) has\nsignificantly enhanced their real-world applications. However, achieving\nconsistent performance across languages, especially when integrating cultural\nknowledge, remains a significant challenge. To better assess this issue, we\nintroduce two new benchmarks: KnowRecall and VisRecall, which evaluate\ncross-lingual consistency in MLLMs. KnowRecall is a visual question answering\nbenchmark designed to measure factual knowledge consistency in 15 languages,\nfocusing on cultural and historical questions about global landmarks. VisRecall\nassesses visual memory consistency by asking models to describe landmark\nappearances in 9 languages without access to images. Experimental results\nreveal that state-of-the-art MLLMs, including proprietary ones, still struggle\nto achieve cross-lingual consistency. This underscores the need for more robust\napproaches that produce truly multilingual and culturally aware models.", "comment": "https://github.com/nlp-waseda/traveling-across-languages", "pdf_url": "http://arxiv.org/pdf/2505.15075v4", "cate": "cs.CL", "date": "2025-05-21", "updated": "2025-07-26"}
{"id": "2505.18300", "title": "Beyond Self-Repellent Kernels: History-Driven Target Towards Efficient Nonlinear MCMC on General Graphs", "authors": ["Jie Hu", "Yi-Ting Ma", "Do Young Eun"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at ICML 2025 (Oral)", "url": "http://arxiv.org/abs/2505.18300v3", "summary": "We propose a history-driven target (HDT) framework in Markov Chain Monte\nCarlo (MCMC) to improve any random walk algorithm on discrete state spaces,\nsuch as general undirected graphs, for efficient sampling from target\ndistribution $\\boldsymbol{\\mu}$. With broad applications in network science and\ndistributed optimization, recent innovations like the self-repellent random\nwalk (SRRW) achieve near-zero variance by prioritizing under-sampled states\nthrough transition kernel modifications based on past visit frequencies.\nHowever, SRRW's reliance on explicit computation of transition probabilities\nfor all neighbors at each step introduces substantial computational overhead,\nwhile its strict dependence on time-reversible Markov chains excludes advanced\nnon-reversible MCMC methods. To overcome these limitations, instead of direct\nmodification of transition kernel, HDT introduces a history-dependent target\ndistribution $\\boldsymbol{\\pi}[\\mathbf{x}]$ to replace the original target\n$\\boldsymbol{\\mu}$ in any graph sampler, where $\\mathbf{x}$ represents the\nempirical measure of past visits. This design preserves lightweight\nimplementation by requiring only local information between the current and\nproposed states and achieves compatibility with both reversible and\nnon-reversible MCMC samplers, while retaining unbiased samples with target\ndistribution $\\boldsymbol{\\mu}$ and near-zero variance performance. Extensive\nexperiments in graph sampling demonstrate consistent performance gains, and a\nmemory-efficient Least Recently Used (LRU) cache ensures scalability to large\ngeneral graphs.", "comment": "Accepted at ICML 2025 (Oral)", "pdf_url": "http://arxiv.org/pdf/2505.18300v3", "cate": "cs.LG", "date": "2025-05-23", "updated": "2025-07-27"}
{"id": "2506.01413", "title": "Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models", "authors": ["Yulei Qin", "Gang Li", "Zongyi Li", "Zihan Xu", "Yuchen Shi", "Zhekai Lin", "Xiao Cui", "Ke Li", "Xing Sun"], "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      15 pages of main body, 5 tables, 5 figures, 42 pages of appendix", "url": "http://arxiv.org/abs/2506.01413v5", "summary": "Existing large language models (LLMs) face challenges of following complex\ninstructions, especially when multiple constraints are present and organized in\nparalleling, chaining, and branching structures. One intuitive solution, namely\nchain-of-thought (CoT), is expected to universally improve capabilities of\nLLMs. However, we find that the vanilla CoT exerts a negative impact on\nperformance due to its superficial reasoning pattern of simply paraphrasing the\ninstructions. It fails to peel back the compositions of constraints for\nidentifying their relationship across hierarchies of types and dimensions. To\nthis end, we propose RAIF, a systematic method to boost LLMs in dealing with\ncomplex instructions via incentivizing reasoning for test-time compute scaling.\nFirst, we stem from the decomposition of complex instructions under existing\ntaxonomies and propose a reproducible data acquisition method. Second, we\nexploit reinforcement learning (RL) with verifiable rule-centric reward signals\nto cultivate reasoning specifically for instruction following. We address the\nshallow, non-essential nature of reasoning under complex instructions via\nsample-wise contrast for superior CoT enforcement. We also exploit behavior\ncloning of experts to facilitate steady distribution shift from fast-thinking\nLLMs to skillful reasoners. Extensive evaluations on seven comprehensive\nbenchmarks confirm the validity of the proposed method, where a 1.5B LLM\nachieves 11.74% gains with performance comparable to a 8B LLM. Evaluation on\nOOD constraints also confirms the generalizability of our RAIF. Codes and data\nare available at https://github.com/yuleiqin/RAIF.\n  Keywords: reinforcement learning with verifiable rewards (RLVR), instruction\nfollowing, complex instructions", "comment": "15 pages of main body, 5 tables, 5 figures, 42 pages of appendix", "pdf_url": "http://arxiv.org/pdf/2506.01413v5", "cate": "cs.CV", "date": "2025-06-02", "updated": "2025-07-29"}
{"id": "2505.16789", "title": "Accidental Vulnerability: Factors in Fine-Tuning that Shift Model Safeguards", "authors": ["Punya Syon Pandey", "Samuel Simko", "Kellin Pelrine", "Zhijing Jin"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.16789v2", "summary": "As large language models (LLMs) gain popularity, their vulnerability to\nadversarial attacks emerges as a primary concern. While fine-tuning models on\ndomain-specific datasets is often employed to improve model performance, it can\ninadvertently introduce vulnerabilities within the underlying model. In this\nwork, we investigate Accidental Vulnerability, unexpected vulnerabilities\narising from characteristics of fine-tuning data. We begin by identifying\npotential correlation factors such as linguistic features, semantic similarity,\nand toxicity across multiple experimental datasets. We then evaluate the\nadversarial robustness of these fine-tuned models, analyzing persona shifts and\ninterpretability traits to understand how dataset factors contribute to attack\nsuccess rates. Lastly, we explore causal relationships that offer new insights\ninto adversarial defense strategies, highlighting the crucial role of dataset\ndesign in preserving model alignment. Our code is available at\nhttps://github.com/psyonp/accidental_vulnerability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.16789v2", "cate": "cs.CL", "date": "2025-05-22", "updated": "2025-07-28"}
{"id": "2505.23017", "title": "$K^2$VAE: A Koopman-Kalman Enhanced Variational AutoEncoder for Probabilistic Time Series Forecasting", "authors": ["Xingjian Wu", "Xiangfei Qiu", "Hongfan Gao", "Jilin Hu", "Bin Yang", "Chenjuan Guo"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.23017v3", "summary": "Probabilistic Time Series Forecasting (PTSF) plays a crucial role in\ndecision-making across various fields, including economics, energy, and\ntransportation. Most existing methods excell at short-term forecasting, while\noverlooking the hurdles of Long-term Probabilistic Time Series Forecasting\n(LPTSF). As the forecast horizon extends, the inherent nonlinear dynamics have\na significant adverse effect on prediction accuracy, and make generative models\ninefficient by increasing the cost of each iteration. To overcome these\nlimitations, we introduce $K^2$VAE, an efficient VAE-based generative model\nthat leverages a KoopmanNet to transform nonlinear time series into a linear\ndynamical system, and devises a KalmanNet to refine predictions and model\nuncertainty in such linear system, which reduces error accumulation in\nlong-term forecasting. Extensive experiments demonstrate that $K^2$VAE\noutperforms state-of-the-art methods in both short- and long-term PTSF,\nproviding a more efficient and accurate solution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.23017v3", "cate": "cs.LG", "date": "2025-05-29", "updated": "2025-07-26"}
{"id": "2506.09081", "title": "FlagEvalMM: A Flexible Framework for Comprehensive Multimodal Model Evaluation", "authors": ["Zheqi He", "Yesheng Liu", "Jing-shu Zheng", "Xuejing Li", "Jin-Ge Yao", "Bowen Qin", "Richeng Xuan", "Xi Yang"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACL 2025 Demo", "url": "http://arxiv.org/abs/2506.09081v3", "summary": "We present FlagEvalMM, an open-source evaluation framework designed to\ncomprehensively assess multimodal models across a diverse range of\nvision-language understanding and generation tasks, such as visual question\nanswering, text-to-image/video generation, and image-text retrieval. We\ndecouple model inference from evaluation through an independent evaluation\nservice, thus enabling flexible resource allocation and seamless integration of\nnew tasks and models. Moreover, FlagEvalMM utilizes advanced inference\nacceleration tools (e.g., vLLM, SGLang) and asynchronous data loading to\nsignificantly enhance evaluation efficiency. Extensive experiments show that\nFlagEvalMM offers accurate and efficient insights into model strengths and\nlimitations, making it a valuable tool for advancing multimodal research. The\nframework is publicly accessible at\nhttps://github.com/flageval-baai/FlagEvalMM.", "comment": "Accepted by ACL 2025 Demo", "pdf_url": "http://arxiv.org/pdf/2506.09081v3", "cate": "cs.CV", "date": "2025-06-10", "updated": "2025-07-28"}
{"id": "2505.17067", "title": "Unveil Multi-Picture Descriptions for Multilingual Mild Cognitive Impairment Detection via Contrastive Learning", "authors": ["Kristin Qi", "Jiali Cheng", "Youxiang Zhu", "Hadi Amiri", "Xiaohui Liang"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      IEEE Global Communications Conference (GlobeCom) 2025", "url": "http://arxiv.org/abs/2505.17067v3", "summary": "Detecting Mild Cognitive Impairment from picture descriptions is critical yet\nchallenging, especially in multilingual and multiple picture settings. Prior\nwork has primarily focused on English speakers describing a single picture\n(e.g., the 'Cookie Theft'). The TAUKDIAL-2024 challenge expands this scope by\nintroducing multilingual speakers and multiple pictures, which presents new\nchallenges in analyzing picture-dependent content. To address these challenges,\nwe propose a framework with three components: (1) enhancing discriminative\nrepresentation learning via supervised contrastive learning, (2) involving\nimage modality rather than relying solely on speech and text modalities, and\n(3) applying a Product of Experts (PoE) strategy to mitigate spurious\ncorrelations and overfitting. Our framework improves MCI detection performance,\nachieving a +7.1% increase in Unweighted Average Recall (UAR) (from 68.1% to\n75.2%) and a +2.9% increase in F1 score (from 80.6% to 83.5%) compared to the\ntext unimodal baseline. Notably, the contrastive learning component yields\ngreater gains for the text modality compared to speech. These results highlight\nour framework's effectiveness in multilingual and multi-picture MCI detection.", "comment": "IEEE Global Communications Conference (GlobeCom) 2025", "pdf_url": "http://arxiv.org/pdf/2505.17067v3", "cate": "cs.CL", "date": "2025-05-19", "updated": "2025-07-28"}
{"id": "2506.05713", "title": "Come Together, But Not Right Now: A Progressive Strategy to Boost Low-Rank Adaptation", "authors": ["Zhan Zhuang", "Xiequn Wang", "Wei Li", "Yulong Zhang", "Qiushi Huang", "Shuhao Chen", "Xuehao Wang", "Yanbin Wei", "Yuhe Nie", "Kede Ma", "Yu Zhang", "Ying Wei"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by ICML 2025. Code link: this https URL", "url": "http://arxiv.org/abs/2506.05713v2", "summary": "Low-rank adaptation (LoRA) has emerged as a leading parameter-efficient\nfine-tuning technique for adapting large foundation models, yet it often locks\nadapters into suboptimal minima near their initialization. This hampers model\ngeneralization and limits downstream operators such as adapter merging and\npruning. Here, we propose CoTo, a progressive training strategy that gradually\nincreases adapters' activation probability over the course of fine-tuning. By\nstochastically deactivating adapters, CoTo encourages more balanced\noptimization and broader exploration of the loss landscape. We provide a\ntheoretical analysis showing that CoTo promotes layer-wise dropout stability\nand linear mode connectivity, and we adopt a cooperative-game approach to\nquantify each adapter's marginal contribution. Extensive experiments\ndemonstrate that CoTo consistently boosts single-task performance, enhances\nmulti-task merging accuracy, improves pruning robustness, and reduces training\noverhead, all while remaining compatible with diverse LoRA variants. Code is\navailable at https://github.com/zwebzone/coto.", "comment": "Accepted by ICML 2025. Code link: https://github.com/zwebzone/coto", "pdf_url": "http://arxiv.org/pdf/2506.05713v2", "cate": "cs.LG", "date": "2025-06-06", "updated": "2025-07-27"}
{"id": "2506.15787", "title": "SLR: Automated Synthesis for Scalable Logical Reasoning", "authors": ["Lukas Helff", "Ahmad Omar", "Felix Friedrich", "Antonia Wüst", "Hikaru Shindo", "Rupert Mitchell", "Tim Woydt", "Patrick Schramowski", "and Wolfgang Stammer Kristian Kersting"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.15787v3", "summary": "We introduce SLR, an end-to-end framework for systematic evaluation and\ntraining of Large Language Models (LLMs) via Scalable Logical Reasoning. Given\na user's task specification, SLR automatically synthesizes (i) an instruction\nprompt for an inductive reasoning task, (ii) a validation program, executable\non model outputs to provide verifiable rewards, and (iii) the latent\nground-truth rule. This process is fully automated, scalable, requires no human\nannotations, and offers precise control over task difficulty. Using SLR, we\ncreate SLR-Bench, a benchmark comprising 19k prompts organized into 20\ncurriculum levels that progressively increase in relational, arithmetic, and\nrecursive complexity. Large-scale evaluation reveals that contemporary LLMs\nreadily produce syntactically valid rules, yet often fail at correct logical\ninference. Recent reasoning LLMs demonstrate improved performance but incur\nvery high test-time computation, with costs exceeding $300 for just 1,000\nprompts. Finally, curriculum learning via SLR doubles Llama-3-8B accuracy on\nSLR-Bench, achieving parity with Gemini-Flash-Thinking at a fraction of\ncomputational cost. Moreover, these reasoning capabilities generalize to a wide\nrange of established benchmarks, underscoring the effectiveness of SLR for\ndownstream reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.15787v3", "cate": "cs.AI", "date": "2025-06-18", "updated": "2025-07-29"}
{"id": "2505.17137", "title": "Cog-TiPRO: Iterative Prompt Refinement with LLMs to Detect Cognitive Decline via Longitudinal Voice Assistant Commands", "authors": ["Kristin Qi", "Youxiang Zhu", "Caroline Summerour", "John A. Batsis", "Xiaohui Liang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      IEEE Global Communications Conference (GlobeCom) 2025", "url": "http://arxiv.org/abs/2505.17137v2", "summary": "Early detection of cognitive decline is crucial for enabling interventions\nthat can slow neurodegenerative disease progression. Traditional diagnostic\napproaches rely on labor-intensive clinical assessments, which are impractical\nfor frequent monitoring. Our pilot study investigates voice assistant systems\n(VAS) as non-invasive tools for detecting cognitive decline through\nlongitudinal analysis of speech patterns in voice commands. Over an 18-month\nperiod, we collected voice commands from 35 older adults, with 15 participants\nproviding daily at-home VAS interactions. To address the challenges of\nanalyzing these short, unstructured and noisy commands, we propose Cog-TiPRO, a\nframework that combines (1) LLM-driven iterative prompt refinement for\nlinguistic feature extraction, (2) HuBERT-based acoustic feature extraction,\nand (3) transformer-based temporal modeling. Using iTransformer, our approach\nachieves 73.80% accuracy and 72.67% F1-score in detecting MCI, outperforming\nits baseline by 27.13%. Through our LLM approach, we identify linguistic\nfeatures that uniquely characterize everyday command usage patterns in\nindividuals experiencing cognitive decline.", "comment": "IEEE Global Communications Conference (GlobeCom) 2025", "pdf_url": "http://arxiv.org/pdf/2505.17137v2", "cate": "cs.CL", "date": "2025-05-22", "updated": "2025-07-28"}
{"id": "2506.15606", "title": "LoX: Low-Rank Extrapolation Robustifies LLM Safety Against Fine-tuning", "authors": ["Gabriel J. Perin", "Runjin Chen", "Xuxi Chen", "Nina S. T. Hirata", "Zhangyang Wang", "Junyuan Hong"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.15606v3", "summary": "Large Language Models (LLMs) have become indispensable in real-world\napplications. However, their widespread adoption raises significant safety\nconcerns, particularly in responding to socially harmful questions. Despite\nsubstantial efforts to improve model safety through alignment, aligned models\ncan still have their safety protections undermined by subsequent fine-tuning -\neven when the additional training data appears benign. In this paper, we\nempirically demonstrate that this vulnerability stems from the sensitivity of\nsafety-critical low-rank subspaces in LLM parameters to fine-tuning. Building\non this insight, we propose a novel training-free method, termed Low-Rank\nExtrapolation (LoX), to enhance safety robustness by extrapolating the safety\nsubspace of an aligned LLM. Our experimental results confirm the effectiveness\nof LoX, demonstrating significant improvements in robustness against both\nbenign and malicious fine-tuning attacks while preserving the model's\nadaptability to new tasks. For instance, LoX leads to 11% to 54% absolute\nreductions in attack success rates (ASR) facing benign or malicious fine-tuning\nattacks. By investigating the ASR landscape of parameters, we attribute the\nsuccess of LoX to that the extrapolation moves LLM parameters to a flatter\nzone, thereby less sensitive to perturbations. The code is available at\ngithub.com/VITA-Group/LoX.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.15606v3", "cate": "cs.LG", "date": "2025-06-18", "updated": "2025-07-25"}
{"id": "2506.22493", "title": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models", "authors": ["Sadia Kamal", "Lalu Prasad Yadav Prakash", "S M Rafiuddin", "Mohammed Rakib", "Arunkumar Bagavathi", "Atriya Sen", "Sagnik Ray Choudhury"], "categories": ["cs.CY", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.22493v2", "summary": "Political Compass Test (PCT) or similar questionnaires have been used to\nquantify LLM's political leanings. Building on a recent line of work that\nexamines the validity of PCT tests, we demonstrate that variation in standard\ngeneration parameters does not significantly impact the models' PCT scores.\nHowever, external factors such as prompt variations and fine-tuning\nindividually and in combination affect the same. Finally, we demonstrate that\nwhen models are fine-tuned on text datasets with higher political content than\nothers, the PCT scores are not differentially affected. This calls for a\nthorough investigation into the validity of PCT and similar tests, as well as\nthe mechanism by which political leanings are encoded in LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.22493v2", "cate": "cs.CY", "date": "2025-06-24", "updated": "2025-07-29"}
{"id": "2505.18687", "title": "An AI Capability Threshold for Rent-Funded Universal Basic Income in an AI-Automated Economy", "authors": ["Aran Nayebi"], "categories": ["econ.GN", "cs.AI", "cs.GT", "q-fin.EC"], "primary_category": "Subjects:       General Economics (econ.GN)", "pdf_link": null, "comments": "Comments:      9 pages, 3 figures, added more clarifications and refs", "url": "http://arxiv.org/abs/2505.18687v2", "summary": "We derive the first closed-form condition under which artificial intelligence\n(AI) capital profits could sustainably finance a universal basic income (UBI)\nwithout additional taxes or new job creation. In a Solow-Zeira economy\ncharacterized by a continuum of automatable tasks, a constant net saving rate\n$s$, and task-elasticity $\\sigma < 1$, we analyze how the AI capability\nthreshold--defined as the productivity level of AI relative to pre-AI\nautomation--varies under different economic scenarios. At present economic\nparameters, we find that AI systems must achieve only approximately 5-6 times\nexisting automation productivity to finance an 11%-of-GDP UBI, in the worst\ncase situation where *no* new jobs or tasks are created.\n  Our analysis also reveals some specific policy levers: raising public revenue\nshare (e.g. profit taxation) of AI capital from the current 15% to about 33%\nhalves the required AI capability threshold to attain UBI to 3 times existing\nautomotion productivity, but gains diminish beyond 50% public revenue share,\nespecially if regulatory costs increase. Market structure also strongly affects\noutcomes: monopolistic or concentrated oligopolistic markets reduce the\nthreshold by increasing economic rents, whereas heightened competition\nsignificantly raises it.\n  Overall, these results suggest a couple policy recommendations: maximizing\npublic revenue share up to a point so that operating costs are minimized, and\nstrategically managing market competition can ensure AI's growing capabilities\ntranslate into meaningful social benefits within realistic technological\nprogress scenarios.", "comment": "9 pages, 3 figures, added more clarifications and refs", "pdf_url": "http://arxiv.org/pdf/2505.18687v2", "cate": "econ.GN", "date": "2025-05-24", "updated": "2025-07-26"}
{"id": "2506.16550", "title": "A Free Probabilistic Framework for Analyzing the Transformer-based Language Models", "authors": ["Swagatam Das"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.16550v2", "summary": "We present a formal operator-theoretic framework for analyzing\nTransformer-based language models using free probability theory. By modeling\ntoken embeddings and attention mechanisms as self-adjoint operators in a\ntracial \\( W^* \\)-probability space, we reinterpret attention as\nnon-commutative convolution and describe representation propagation via free\nadditive convolution. This leads to a spectral dynamic system interpretation of\ndeep Transformers. We derive entropy-based generalization bounds under freeness\nassumptions and provide insight into positional encoding, spectral evolution,\nand representational complexity. This work offers a principled, though\ntheoretical, perspective on structural dynamics in large language models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.16550v2", "cate": "cs.LG", "date": "2025-06-19", "updated": "2025-07-27"}
{"id": "2507.16518", "title": "C2-Evo: Co-Evolving Multimodal Data and Model for Self-Improving Reasoning", "authors": ["Xiuwei Chen", "Wentao Hu", "Hanhui Li", "Jun Zhou", "Zisheng Chen", "Meng Cao", "Yihan Zeng", "Kui Zhang", "Yu-Jie Yuan", "Jianhua Han", "Hang Xu", "Xiaodan Liang"], "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.16518v2", "summary": "Recent advances in multimodal large language models (MLLMs) have shown\nimpressive reasoning capabilities. However, further enhancing existing MLLMs\nnecessitates high-quality vision-language datasets with carefully curated task\ncomplexities, which are both costly and challenging to scale. Although recent\nself-improving models that iteratively refine themselves offer a feasible\nsolution, they still suffer from two core challenges: (i) most existing methods\naugment visual or textual data separately, resulting in discrepancies in data\ncomplexity (e.g., over-simplified diagrams paired with redundant textual\ndescriptions); and (ii) the evolution of data and models is also separated,\nleading to scenarios where models are exposed to tasks with mismatched\ndifficulty levels. To address these issues, we propose C2-Evo, an automatic,\nclosed-loop self-improving framework that jointly evolves both training data\nand model capabilities. Specifically, given a base dataset and a base model,\nC2-Evo enhances them by a cross-modal data evolution loop and a data-model\nevolution loop. The former loop expands the base dataset by generating complex\nmultimodal problems that combine structured textual sub-problems with\niteratively specified geometric diagrams, while the latter loop adaptively\nselects the generated problems based on the performance of the base model, to\nconduct supervised fine-tuning and reinforcement learning alternately.\nConsequently, our method continuously refines its model and training data, and\nconsistently obtains considerable performance gains across multiple\nmathematical reasoning benchmarks. Our code, models, and datasets will be\nreleased.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.16518v2", "cate": "cs.CV", "date": "2025-07-22", "updated": "2025-07-29"}
{"id": "2505.20308", "title": "Large Language Model Powered Decision Support for a Metal Additive Manufacturing Knowledge Graph", "authors": ["Muhammad Tayyab Khan", "Lequn Chen", "Wenhe Feng", "Seung Ki Moon"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      The paper has been accepted at 11th International Conference of Asian Society for Precision Engineering and Nanotechnology", "url": "http://arxiv.org/abs/2505.20308v2", "summary": "Metal additive manufacturing (AM) involves complex interdependencies among\nprocesses, materials, feedstock, and post-processing steps. However, the\nunderlying relationships and domain knowledge remain fragmented across\nliterature and static databases that often require expert-level queries,\nlimiting their applicability in design and planning. To address these\nlimitations, we develop a novel and structured knowledge graph (KG),\nrepresenting 53 distinct metals and alloys across seven material categories,\nnine AM processes, four feedstock types, and corresponding post-processing\nrequirements. A large language model (LLM) interface, guided by a few-shot\nprompting strategy, enables natural language querying without the need for\nformal query syntax. The system supports a range of tasks, including\ncompatibility evaluation, constraint-based filtering, and design for AM (DfAM)\nguidance. User queries in natural language are normalized, translated into\nCypher, and executed on the KG, with results returned in a structured format.\nThis work introduces the first interactive system that connects a\ndomain-specific metal AM KG with an LLM interface, delivering accessible and\nexplainable decision support for engineers and promoting human-centered tools\nin manufacturing knowledge systems.", "comment": "The paper has been accepted at 11th International Conference of Asian\n  Society for Precision Engineering and Nanotechnology", "pdf_url": "http://arxiv.org/pdf/2505.20308v2", "cate": "cs.IR", "date": "2025-05-20", "updated": "2025-07-28"}
{"id": "2506.17776", "title": "Machine Learning Model Integration with Open World Temporal Logic for Process Automation", "authors": ["Dyuman Aditya", "Colton Payne", "Mario Leiva", "Paulo Shakarian"], "categories": ["cs.LG", "cs.AI", "cs.LO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.17776v2", "summary": "Recent advancements in Machine Learning (ML) have yielded powerful models\ncapable of extracting structured information from diverse and complex data\nsources. However, a significant challenge lies in translating these perceptual\nor extractive outputs into actionable, reasoned decisions within complex\noperational workflows. To address these challenges, this paper introduces a\nnovel approach that integrates the outputs from various machine learning models\ndirectly with the PyReason framework, an open-world temporal logic programming\nreasoning engine. PyReason's foundation in generalized annotated logic allows\nfor the seamless incorporation of real-valued outputs (e.g., probabilities,\nconfidence scores) from diverse ML models, treating them as truth intervals\nwithin its logical framework. Crucially, PyReason provides mechanisms,\nimplemented in Python, to continuously poll ML model outputs, convert them into\nlogical facts, and dynamically recompute the minimal model, ensuring real-tine\nadaptive decision-making. Furthermore, its native support for temporal\nreasoning, knowledge graph integration, and fully explainable interface traces\nenables sophisticated analysis over time-sensitive process data and existing\norganizational knowledge. By combining the strengths of perception and\nextraction from ML models with the logical deduction and transparency of\nPyReason, we aim to create a powerful system for automating complex processes.\nThis integration finds utility across numerous domains, including\nmanufacturing, healthcare, and business operations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.17776v2", "cate": "cs.LG", "date": "2025-06-21", "updated": "2025-07-27"}
{"id": "2505.23145", "title": "FlowAlign: Trajectory-Regularized, Inversion-Free Flow-based Image Editing", "authors": ["Jeongsol Kim", "Yeobin Hong", "Jonghyun Park", "Jong Chul Ye"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.23145v4", "summary": "Recent inversion-free, flow-based image editing methods such as FlowEdit\nleverages a pre-trained noise-to-image flow model such as Stable Diffusion 3,\nenabling text-driven manipulation by solving an ordinary differential equation\n(ODE). While the lack of exact latent inversion is a core advantage of these\nmethods, it often results in unstable editing trajectories and poor source\nconsistency. To address this limitation, we propose {\\em FlowAlign}, a novel\ninversion-free flow-based framework for consistent image editing with optimal\ncontrol-based trajectory control. Specifically, FlowAlign introduces source\nsimilarity at the terminal point as a regularization term to promote smoother\nand more consistent trajectories during the editing process. Notably, our\nterminal point regularization is shown to explicitly balance semantic alignment\nwith the edit prompt and structural consistency with the source image along the\ntrajectory. Furthermore, FlowAlign naturally supports reverse editing by simply\nreversing the ODE trajectory, highliting the reversible and consistent nature\nof the transformation. Extensive experiments demonstrate that FlowAlign\noutperforms existing methods in both source preservation and editing\ncontrollability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.23145v4", "cate": "cs.CV", "date": "2025-05-29", "updated": "2025-07-27"}
{"id": "2507.04385", "title": "Tractable Representation Learning with Probabilistic Circuits", "authors": ["Steven Braun", "Sahil Sidheekh", "Antonio Vergari", "Martin Mundt", "Sriraam Natarajan", "Kristian Kersting"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04385v2", "summary": "Probabilistic circuits (PCs) are powerful probabilistic models that enable\nexact and tractable inference, making them highly suitable for probabilistic\nreasoning and inference tasks. While dominant in neural networks,\nrepresentation learning with PCs remains underexplored, with prior approaches\nrelying on external neural embeddings or activation-based encodings. To address\nthis gap, we introduce autoencoding probabilistic circuits (APCs), a novel\nframework leveraging the tractability of PCs to model probabilistic embeddings\nexplicitly. APCs extend PCs by jointly modeling data and embeddings, obtaining\nembedding representations through tractable probabilistic inference. The PC\nencoder allows the framework to natively handle arbitrary missing data and is\nseamlessly integrated with a neural decoder in a hybrid, end-to-end trainable\narchitecture enabled by differentiable sampling. Our empirical evaluation\ndemonstrates that APCs outperform existing PC-based autoencoding methods in\nreconstruction quality, generate embeddings competitive with, and exhibit\nsuperior robustness in handling missing data compared to neural autoencoders.\nThese results highlight APCs as a powerful and flexible representation learning\nmethod that exploits the probabilistic inference capabilities of PCs, showing\npromising directions for robust inference, out-of-distribution detection, and\nknowledge distillation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04385v2", "cate": "cs.LG", "date": "2025-07-06", "updated": "2025-07-26"}
{"id": "2505.24371", "title": "Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering", "authors": ["Md Intisar Chowdhury", "Kittinun Aukkapinyo", "Hiroshi Fujimura", "Joo Ann Woo", "Wasu Wasusatein", "Fadoua Ghourabi"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Copyright 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "url": "http://arxiv.org/abs/2505.24371v3", "summary": "In this paper, we propose a Grid-based Local and Global Area Transcription\n(Grid-LoGAT) system for Video Question Answering (VideoQA). The system operates\nin two phases. First, extracting text transcripts from video frames using a\nVision-Language Model (VLM). Next, processing questions using these transcripts\nto generate answers through a Large Language Model (LLM). This design ensures\nimage privacy by deploying the VLM on edge devices and the LLM in the cloud. To\nimprove transcript quality, we propose grid-based visual prompting, which\nextracts intricate local details from each grid cell and integrates them with\nglobal information. Evaluation results show that Grid-LoGAT, using the\nopen-source VLM (LLaVA-1.6-7B) and LLM (Llama-3.1-8B), outperforms\nstate-of-the-art methods with similar baseline models on NExT-QA and STAR-QA\ndatasets with an accuracy of 65.9% and 50.11% respectively. Additionally, our\nmethod surpasses the non-grid version by 24 points on localization-based\nquestions we created using NExT-QA. (This paper is accepted by IEEE ICIP 2025.)", "comment": "Copyright 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "pdf_url": "http://arxiv.org/pdf/2505.24371v3", "cate": "cs.CV", "date": "2025-05-30", "updated": "2025-07-28"}
{"id": "2507.06821", "title": "HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning", "authors": ["Chuhang Zheng", "Chunwei Tian", "Jie Wen", "Daoqiang Zhang", "Qi Zhu"], "categories": ["cs.LG", "cs.AI", "cs.MM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06821v3", "summary": "Multi-modal emotion recognition has garnered increasing attention as it plays\na significant role in human-computer interaction (HCI) in recent years. Since\ndifferent discrete emotions may exist at the same time, compared with\nsingle-class emotion recognition, emotion distribution learning (EDL) that\nidentifies a mixture of basic emotions has gradually emerged as a trend.\nHowever, existing EDL methods face challenges in mining the heterogeneity among\nmultiple modalities. Besides, rich semantic correlations across arbitrary basic\nemotions are not fully exploited. In this paper, we propose a multi-modal\nemotion distribution learning framework, named HeLo, aimed at fully exploring\nthe heterogeneity and complementary information in multi-modal emotional data\nand label correlation within mixed basic emotions. Specifically, we first adopt\ncross-attention to effectively fuse the physiological data. Then, an optimal\ntransport (OT)-based heterogeneity mining module is devised to mine the\ninteraction and heterogeneity between the physiological and behavioral\nrepresentations. To facilitate label correlation learning, we introduce a\nlearnable label embedding optimized by correlation matrix alignment. Finally,\nthe learnable label embeddings and label correlation matrices are integrated\nwith the multi-modal representations through a novel label correlation-driven\ncross-attention mechanism for accurate emotion distribution learning.\nExperimental results on two publicly available datasets demonstrate the\nsuperiority of our proposed method in emotion distribution learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06821v3", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-26"}
{"id": "2506.09853", "title": "Causal Sufficiency and Necessity Improves Chain-of-Thought Reasoning", "authors": ["Xiangning Yu", "Zhuohan Wang", "Linyi Yang", "Haoxuan Li", "Anjie Liu", "Xiao Xue", "Jun Wang", "Mengyue Yang"], "categories": ["cs.CL", "cs.AI", "math.ST", "stat.ME", "stat.TH"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.09853v2", "summary": "Chain-of-Thought (CoT) prompting plays an indispensable role in endowing\nlarge language models (LLMs) with complex reasoning capabilities. However, CoT\ncurrently faces two fundamental challenges: (1) Sufficiency, which ensures that\nthe generated intermediate inference steps comprehensively cover and\nsubstantiate the final conclusion; and (2) Necessity, which identifies the\ninference steps that are truly indispensable for the soundness of the resulting\nanswer. We propose a causal framework that characterizes CoT reasoning through\nthe dual lenses of sufficiency and necessity. Incorporating causal Probability\nof Sufficiency and Necessity allows us not only to determine which steps are\nlogically sufficient or necessary to the prediction outcome, but also to\nquantify their actual influence on the final reasoning outcome under different\nintervention scenarios, thereby enabling the automated addition of missing\nsteps and the pruning of redundant ones. Extensive experimental results on\nvarious mathematical and commonsense reasoning benchmarks confirm substantial\nimprovements in reasoning efficiency and reduced token usage without\nsacrificing accuracy. Our work provides a promising direction for improving LLM\nreasoning performance and cost-effectiveness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.09853v2", "cate": "cs.CL", "date": "2025-06-11", "updated": "2025-07-26"}
{"id": "2507.11274", "title": "Fast Last-Iterate Convergence of SGD in the Smooth Interpolation Regime", "authors": ["Amit Attia", "Matan Schliserman", "Uri Sherman", "Tomer Koren"], "categories": ["cs.LG", "math.OC", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      30 pages", "url": "http://arxiv.org/abs/2507.11274v2", "summary": "We study population convergence guarantees of stochastic gradient descent\n(SGD) for smooth convex objectives in the interpolation regime, where the noise\nat optimum is zero or near zero. The behavior of the last iterate of SGD in\nthis setting -- particularly with large (constant) stepsizes -- has received\ngrowing attention in recent years due to implications for the training of\nover-parameterized models, as well as to analyzing forgetting in continual\nlearning and to understanding the convergence of the randomized Kaczmarz method\nfor solving linear systems. We establish that after $T$ steps of SGD on\n$\\beta$-smooth convex loss functions with stepsize $0 < \\eta < 2/\\beta$, the\nlast iterate exhibits expected excess risk $\\widetilde{O}(\\frac{1}{\\eta\n(2-\\beta \\eta) T^{1-\\beta\\eta/2}} + \\frac{\\eta}{(2-\\beta\\eta)^2}\nT^{\\beta\\eta/2} \\sigma_\\star^2)$, where $\\sigma_\\star^2$ denotes the variance\nof the stochastic gradients at the optimum. In particular, for a well-tuned\nstepsize we obtain a near optimal $\\widetilde{O}(1/T + \\sigma_\\star/\\sqrt{T})$\nrate for the last iterate, extending the results of Varre et al. (2021) beyond\nleast squares regression; and when $\\sigma_\\star=0$ we obtain a rate of\n$\\smash{O(1/\\sqrt T)}$ with $\\eta=1/\\beta$, improving upon the best-known\n$\\smash{O(T^{-1/4})}$ rate recently established by Evron et al. (2025) in the\nspecial case of realizable linear regression.", "comment": "30 pages", "pdf_url": "http://arxiv.org/pdf/2507.11274v2", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-28"}
{"id": "2506.12327", "title": "Intersectional Bias in Japanese Large Language Models from a Contextualized Perspective", "authors": ["Hitomi Yanaka", "Xinqi He", "Jie Lu", "Namgi Han", "Sunjin Oh", "Ryoma Kumon", "Yuma Matsuoka", "Katsuhiko Watabe", "Yuko Itatsu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to the 6th Workshop on Gender Bias in Natural Language Processing (GeBNLP2025) at ACL2025", "url": "http://arxiv.org/abs/2506.12327v2", "summary": "An increasing number of studies have examined the social bias of rapidly\ndeveloped large language models (LLMs). Although most of these studies have\nfocused on bias occurring in a single social attribute, research in social\nscience has shown that social bias often occurs in the form of\nintersectionality -- the constitutive and contextualized perspective on bias\naroused by social attributes. In this study, we construct the Japanese\nbenchmark inter-JBBQ, designed to evaluate the intersectional bias in LLMs on\nthe question-answering setting. Using inter-JBBQ to analyze GPT-4o and Swallow,\nwe find that biased output varies according to its contexts even with the equal\ncombination of social attributes.", "comment": "Accepted to the 6th Workshop on Gender Bias in Natural Language\n  Processing (GeBNLP2025) at ACL2025", "pdf_url": "http://arxiv.org/pdf/2506.12327v2", "cate": "cs.CL", "date": "2025-06-14", "updated": "2025-07-27"}
{"id": "2507.14446", "title": "Deep RL Dual Sourcing Inventory Management with Supply and Capacity Risk Awareness", "authors": ["Defeng Liu", "Ying Liu", "Carson Eisenach"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14446v3", "summary": "In this work, we study how to efficiently apply reinforcement learning (RL)\nfor solving large-scale stochastic optimization problems by leveraging\nintervention models. The key of the proposed methodology is to better explore\nthe solution space by simulating and composing the stochastic processes using\npre-trained deep learning (DL) models. We demonstrate our approach on a\nchallenging real-world application, the multi-sourcing multi-period inventory\nmanagement problem in supply chain optimization. In particular, we employ deep\nRL models for learning and forecasting the stochastic supply chain processes\nunder a range of assumptions. Moreover, we also introduce a constraint\ncoordination mechanism, designed to forecast dual costs given the\ncross-products constraints in the inventory network. We highlight that instead\nof directly modeling the complex physical constraints into the RL optimization\nproblem and solving the stochastic problem as a whole, our approach breaks down\nthose supply chain processes into scalable and composable DL modules, leading\nto improved performance on large real-world datasets. We also outline open\nproblems for future research to further investigate the efficacy of such\nmodels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14446v3", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-26"}
{"id": "2506.21560", "title": "Reinforcement learning fine-tuning of language model for instruction following and math reasoning", "authors": ["Yifu Han", "Geo Zhang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.21560v2", "summary": "This study investigates the effectiveness of reinforcement learning (RL)\nfine-tuning techniques on a compact language model (Qwen2.5-0.5B Base) for two\nchallenging tasks: instruction following and mathematical reasoning. We compare\nsupervised fine-tuning (SFT), Direct Preference Optimization (DPO) using\npreference-labeled data, and Reinforce Leave-One-Out (RLOO) with reward models.\nOur experiments show that RLOO with DeBERTa reward modeling achieves the best\nalignment, while DPO provides strong and consistent results. For math reasoing\ntasks, synthetic data augmentation and best-of-N sampling with an external\nverifier significantly improve accuracy, showing the potential of combining\nfine-tuning with inference-time tools. This study highlights key trade-offs and\npractical strategies for training lightweight, task-aligned small-scale\nlanguage models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.21560v2", "cate": "cs.CL", "date": "2025-06-11", "updated": "2025-07-27"}
{"id": "2507.14560", "title": "The Origin of Self-Attention: Pairwise Affinity Matrices in Feature Selection and the Emergence of Self-Attention", "authors": ["Giorgio Roffo"], "categories": ["cs.LG", "cs.CV", "68T07, 05C50, 15A18", "I.2.6; I.2.7; I.5.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      24 pages, 10 figures, submitted for review. Companion code and reproducibility materials available", "url": "http://arxiv.org/abs/2507.14560v2", "summary": "The self-attention mechanism, now central to deep learning architectures such\nas Transformers, is a modern instance of a more general computational\nprinciple: learning and using pairwise affinity matrices to control how\ninformation flows through a model. This paper traces the conceptual origins of\nself-attention across multiple domains, including computer vision, natural\nlanguage processing, and graph learning, through their shared reliance on an\naffinity matrix, denoted as A. We highlight Infinite Feature Selection (Inf-FS)\nas a foundational approach that generalizes the idea of affinity-based\nweighting. Unlike the fixed dot-product structure used in Transformers, Inf-FS\ndefines A either through domain knowledge or by learning, and computes feature\nrelevance through multi-hop propagation over the affinity graph. From this\nperspective, self-attention can be seen as a special case of Inf-FS: it uses a\nsingle-hop affinity computation where A is dynamically built from token\nsimilarities. We argue that the underlying structure, reasoning over pairwise\nrelationships, is preserved across both approaches, and the key differences lie\nin how the affinity matrix is defined and applied. By situating self-attention\nwithin the broader paradigm of affinity-based computation, we unify several\nstrands of machine learning research and highlight a common mathematical\nfoundation that underpins diverse models and tasks.", "comment": "24 pages, 10 figures, submitted for review. Companion code and\n  reproducibility materials available", "pdf_url": "http://arxiv.org/pdf/2507.14560v2", "cate": "cs.LG", "date": "2025-07-19", "updated": "2025-07-26"}
{"id": "2507.01494", "title": "Crop Pest Classification Using Deep Learning Techniques: A Review", "authors": ["Muhammad Hassam Ejaz", "Muhammad Bilal", "Usman Habib"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.01494v2", "summary": "Insect pests continue to bring a serious threat to crop yields around the\nworld, and traditional methods for monitoring them are often slow, manual, and\ndifficult to scale. In recent years, deep learning has emerged as a powerful\nsolution, with techniques like convolutional neural networks (CNNs), vision\ntransformers (ViTs), and hybrid models gaining popularity for automating pest\ndetection. This review looks at 37 carefully selected studies published between\n2018 and 2025, all focused on AI-based pest classification. The selected\nresearch is organized by crop type, pest species, model architecture, dataset\nusage, and key technical challenges. The early studies relied heavily on CNNs\nbut latest work is shifting toward hybrid and transformer-based models that\ndeliver higher accuracy and better contextual understanding. Still, challenges\nlike imbalanced datasets, difficulty in detecting small pests, limited\ngeneralizability, and deployment on edge devices remain significant hurdles.\nOverall, this review offers a structured overview of the field, highlights\nuseful datasets, and outlines the key challenges and future directions for\nAI-based pest monitoring systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01494v2", "cate": "cs.CV", "date": "2025-07-02", "updated": "2025-07-28"}
{"id": "2507.16674", "title": "GASPnet: Global Agreement to Synchronize Phases", "authors": ["Andrea Alamia", "Sabine Muzellec", "Thomas Serre", "Rufin VanRullen"], "categories": ["cs.LG", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.16674v2", "summary": "In recent years, Transformer architectures have revolutionized most fields of\nartificial intelligence, relying on an attentional mechanism based on the\nagreement between keys and queries to select and route information in the\nnetwork. In previous work, we introduced a novel, brain-inspired architecture\nthat leverages a similar implementation to achieve a global 'routing by\nagreement' mechanism. Such a system modulates the network's activity by\nmatching each neuron's key with a single global query, pooled across the entire\nnetwork. Acting as a global attentional system, this mechanism improves noise\nrobustness over baseline levels but is insufficient for multi-classification\ntasks. Here, we improve on this work by proposing a novel mechanism that\ncombines aspects of the Transformer attentional operations with a compelling\nneuroscience theory, namely, binding by synchrony. This theory proposes that\nthe brain binds together features by synchronizing the temporal activity of\nneurons encoding those features. This allows the binding of features from the\nsame object while efficiently disentangling those from distinct objects. We\ndrew inspiration from this theory and incorporated angular phases into all\nlayers of a convolutional network. After achieving phase alignment via Kuramoto\ndynamics, we use this approach to enhance operations between neurons with\nsimilar phases and suppresses those with opposite phases. We test the benefits\nof this mechanism on two datasets: one composed of pairs of digits and one\ncomposed of a combination of an MNIST item superimposed on a CIFAR-10 image.\nOur results reveal better accuracy than CNN networks, proving more robust to\nnoise and with better generalization abilities. Overall, we propose a novel\nmechanism that addresses the visual binding problem in neural networks by\nleveraging the synergy between neuroscience and machine learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.16674v2", "cate": "cs.LG", "date": "2025-07-22", "updated": "2025-07-28"}
{"id": "2507.04270", "title": "ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts", "authors": ["Sangbum Choi", "Kyeongryeol Go", "Taewoong Jang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      9 pages, 2 figures", "url": "http://arxiv.org/abs/2507.04270v3", "summary": "Foundation models have revolutionized AI, yet they struggle with zero-shot\ndeployment in real-world industrial settings due to a lack of high-quality,\ndomain-specific datasets. To bridge this gap, Superb AI introduces ZERO, an\nindustry-ready vision foundation model that leverages multi-modal prompting\n(textual and visual) for generalization without retraining. Trained on a\ncompact yet representative 0.9 million annotated samples from a proprietary\nbillion-scale industrial dataset, ZERO demonstrates competitive performance on\nacademic benchmarks like LVIS-Val and significantly outperforms existing models\nacross 37 diverse industrial datasets. Furthermore, ZERO achieved 2nd place in\nthe CVPR 2025 Object Instance Detection Challenge and 4th place in the\nFoundational Few-shot Object Detection Challenge, highlighting its practical\ndeployability and generalizability with minimal adaptation and limited data. To\nthe best of our knowledge, ZERO is the first vision foundation model explicitly\nbuilt for domain-specific, zero-shot industrial applications.", "comment": "9 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.04270v3", "cate": "cs.CV", "date": "2025-07-06", "updated": "2025-07-29"}
{"id": "2507.16991", "title": "PyG 2.0: Scalable Learning on Real World Graphs", "authors": ["Matthias Fey", "Jinu Sunil", "Akihiro Nitta", "Rishi Puri", "Manan Shah", "Blaž Stojanovič", "Ramona Bendias", "Alexandria Barghi", "Vid Kocijan", "Zecheng Zhang", "Xinwei He", "Jan Eric Lenssen", "Jure Leskovec"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.16991v2", "summary": "PyG (PyTorch Geometric) has evolved significantly since its initial release,\nestablishing itself as a leading framework for Graph Neural Networks. In this\npaper, we present Pyg 2.0 (and its subsequent minor versions), a comprehensive\nupdate that introduces substantial improvements in scalability and real-world\napplication capabilities. We detail the framework's enhanced architecture,\nincluding support for heterogeneous and temporal graphs, scalable feature/graph\nstores, and various optimizations, enabling researchers and practitioners to\ntackle large-scale graph learning problems efficiently. Over the recent years,\nPyG has been supporting graph learning in a large variety of application areas,\nwhich we will summarize, while providing a deep dive into the important areas\nof relational deep learning and large language modeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.16991v2", "cate": "cs.LG", "date": "2025-07-22", "updated": "2025-07-27"}
{"id": "2507.04886", "title": "Emergent Semantics Beyond Token Embeddings: Transformer LMs with Frozen Visual Unicode Representations", "authors": ["A. Bochkov"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Added a new Ablation Study section with a key experiment on random noise embeddings. Expanded the discussion on 'representational interference' and updated results and figures accordingly", "url": "http://arxiv.org/abs/2507.04886v2", "summary": "Understanding the locus of semantic representation in large language models\n(LLMs) is crucial for interpretability and architectural innovation. The\ndominant paradigm posits that trainable input embeddings serve as foundational\n\"meaning vectors.\" This paper challenges that view. We construct Transformer\nmodels where the embedding layer is entirely frozen, with vectors derived not\nfrom data, but from the visual structure of Unicode glyphs. These non-semantic,\nprecomputed visual embeddings are fixed throughout training. Our method is\ncompatible with any tokenizer, including a novel Unicode-centric tokenizer we\nintroduce to ensure universal text coverage. Despite the absence of trainable,\nsemantically initialized embeddings, our models converge, generate coherent\ntext, and, critically, outperform architecturally identical models with\ntrainable embeddings on the MMLU reasoning benchmark. We attribute this to\n\"representational interference\" in conventional models, where the embedding\nlayer is burdened with learning both structural and semantic features. Our\nresults indicate that high-level semantics are not inherent to input embeddings\nbut are an emergent property of the Transformer's compositional architecture\nand data scale. This reframes the role of embeddings from meaning containers to\nstructural primitives. We release all code and models to foster further\nresearch.", "comment": "Added a new Ablation Study section with a key experiment on random\n  noise embeddings. Expanded the discussion on 'representational interference'\n  and updated results and figures accordingly", "pdf_url": "http://arxiv.org/pdf/2507.04886v2", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-27"}
{"id": "2507.17328", "title": "A Learning-based Domain Decomposition Method", "authors": ["Rui Wu", "Nikola Kovachki", "Burigede Liu"], "categories": ["cs.LG", "math-ph", "math.MP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.17328v2", "summary": "Recent developments in mechanical, aerospace, and structural engineering have\ndriven a growing need for efficient ways to model and analyse structures at\nmuch larger and more complex scales than before. While established numerical\nmethods like the Finite Element Method remain reliable, they often struggle\nwith computational cost and scalability when dealing with large and\ngeometrically intricate problems. In recent years, neural network-based methods\nhave shown promise because of their ability to efficiently approximate\nnonlinear mappings. However, most existing neural approaches are still largely\nlimited to simple domains, which makes it difficult to apply to real-world PDEs\ninvolving complex geometries. In this paper, we propose a learning-based domain\ndecomposition method (L-DDM) that addresses this gap. Our approach uses a\nsingle, pre-trained neural operator-originally trained on simple domains-as a\nsurrogate model within a domain decomposition scheme, allowing us to tackle\nlarge and complicated domains efficiently. We provide a general theoretical\nresult on the existence of neural operator approximations in the context of\ndomain decomposition solution of abstract PDEs. We then demonstrate our method\nby accurately approximating solutions to elliptic PDEs with discontinuous\nmicrostructures in complex geometries, using a physics-pretrained neural\noperator (PPNO). Our results show that this approach not only outperforms\ncurrent state-of-the-art methods on these challenging problems, but also offers\nresolution-invariance and strong generalization to microstructural patterns\nunseen during training.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.17328v2", "cate": "cs.LG", "date": "2025-07-23", "updated": "2025-07-27"}
{"id": "2507.11549", "title": "A Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search", "authors": ["Wendong Mao", "Mingfan Zhao", "Jianfeng Guan", "Qiwei Dong", "Zhongfeng Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      5 pages", "url": "http://arxiv.org/abs/2507.11549v2", "summary": "Deformable Attention Transformers (DAT) have shown remarkable performance in\ncomputer vision tasks by adaptively focusing on informative image regions.\nHowever, their data-dependent sampling mechanism introduces irregular memory\naccess patterns, posing significant challenges for efficient hardware\ndeployment. Existing acceleration methods either incur high hardware overhead\nor compromise model accuracy. To address these issues, this paper proposes a\nhardware-friendly optimization framework for DAT. First, a neural architecture\nsearch (NAS)-based method with a new slicing strategy is proposed to\nautomatically divide the input feature into uniform patches during the\ninference process, avoiding memory conflicts without modifying model\narchitecture. The method explores the optimal slice configuration by jointly\noptimizing hardware cost and inference accuracy. Secondly, an FPGA-based\nverification system is designed to test the performance of this framework on\nedge-side hardware. Algorithm experiments on the ImageNet-1K dataset\ndemonstrate that our hardware-friendly framework can maintain have only 0.2%\naccuracy drop compared to the baseline DAT. Hardware experiments on Xilinx FPGA\nshow the proposed method reduces DRAM access times to 18% compared with\nexisting DAT acceleration methods.", "comment": "5 pages", "pdf_url": "http://arxiv.org/pdf/2507.11549v2", "cate": "cs.CV", "date": "2025-07-13", "updated": "2025-07-26"}
{"id": "2507.17912", "title": "SETOL: A Semi-Empirical Theory of (Deep) Learning", "authors": ["Charles H Martin", "Christopher Hinrichs"], "categories": ["cs.LG", "cond-mat.stat-mech"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      139 pages, 28 figures. Code for experiments available at this https URL", "url": "http://arxiv.org/abs/2507.17912v2", "summary": "We present a SemiEmpirical Theory of Learning (SETOL) that explains the\nremarkable performance of State-Of-The-Art (SOTA) Neural Networks (NNs). We\nprovide a formal explanation of the origin of the fundamental quantities in the\nphenomenological theory of Heavy-Tailed Self-Regularization (HTSR): the\nheavy-tailed power-law layer quality metrics, alpha and alpha-hat. In prior\nwork, these metrics have been shown to predict trends in the test accuracies of\npretrained SOTA NN models, importantly, without needing access to either\ntesting or training data. Our SETOL uses techniques from statistical mechanics\nas well as advanced methods from random matrix theory and quantum chemistry.\nThe derivation suggests new mathematical preconditions for ideal learning,\nincluding a new metric, ERG, which is equivalent to applying a single step of\nthe Wilson Exact Renormalization Group. We test the assumptions and predictions\nof SETOL on a simple 3-layer multilayer perceptron (MLP), demonstrating\nexcellent agreement with the key theoretical assumptions. For SOTA NN models,\nwe show how to estimate the individual layer qualities of a trained NN by\nsimply computing the empirical spectral density (ESD) of the layer weight\nmatrices and plugging this ESD into our SETOL formulas. Notably, we examine the\nperformance of the HTSR alpha and the SETOL ERG layer quality metrics, and find\nthat they align remarkably well, both on our MLP and on SOTA NNs.", "comment": "139 pages, 28 figures. Code for experiments available at\n  https://github.com/charlesmartin14/SETOL_experiments", "pdf_url": "http://arxiv.org/pdf/2507.17912v2", "cate": "cs.LG", "date": "2025-07-23", "updated": "2025-07-27"}
{"id": "2507.11936", "title": "A Survey of Deep Learning for Geometry Problem Solving", "authors": ["Jianzhe Ma", "Wenxuan Wang", "Qin Jin"], "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2507.11936v4", "summary": "Geometry problem solving is a key area of mathematical reasoning, which is\nwidely involved in many important fields such as education, mathematical\nability assessment of artificial intelligence, and multimodal ability\nassessment. In recent years, the rapid development of deep learning technology,\nespecially the rise of multimodal large language models, has triggered a\nwidespread research boom. This paper provides a survey of the applications of\ndeep learning in geometry problem solving, including (i) a comprehensive\nsummary of the relevant tasks in geometry problem solving; (ii) a thorough\nreview of related deep learning methods; (iii) a detailed analysis of\nevaluation metrics and methods; and (iv) a critical discussion of the current\nchallenges and future directions that can be explored. Our goal is to provide a\ncomprehensive and practical reference of deep learning for geometry problem\nsolving to promote further developments in this field. We create a continuously\nupdated list of papers on GitHub: https://github.com/majianz/dl4gps.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.11936v4", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-28"}
{"id": "2507.18071", "title": "Group Sequence Policy Optimization", "authors": ["Chujie Zheng", "Shixuan Liu", "Mingze Li", "Xiong-Hui Chen", "Bowen Yu", "Chang Gao", "Kai Dang", "Yuqiong Liu", "Rui Men", "An Yang", "Jingren Zhou", "Junyang Lin"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.18071v2", "summary": "This paper introduces Group Sequence Policy Optimization (GSPO), our stable,\nefficient, and performant reinforcement learning algorithm for training large\nlanguage models. Unlike previous algorithms that adopt token-level importance\nratios, GSPO defines the importance ratio based on sequence likelihood and\nperforms sequence-level clipping, rewarding, and optimization. We demonstrate\nthat GSPO achieves superior training efficiency and performance compared to the\nGRPO algorithm, notably stabilizes Mixture-of-Experts (MoE) RL training, and\nhas the potential for simplifying the design of RL infrastructure. These merits\nof GSPO have contributed to the remarkable improvements in the latest Qwen3\nmodels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.18071v2", "cate": "cs.LG", "date": "2025-07-24", "updated": "2025-07-28"}
{"id": "2507.12060", "title": "InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing", "authors": ["Kun-Hsiang Lin", "Yu-Wen Tseng", "Kang-Yang Huang", "Jhih-Ciang Wu", "Wen-Huang Cheng"], "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by MM'25", "url": "http://arxiv.org/abs/2507.12060v2", "summary": "Face anti-spoofing (FAS) aims to construct a robust system that can withstand\ndiverse attacks. While recent efforts have concentrated mainly on cross-domain\ngeneralization, two significant challenges persist: limited semantic\nunderstanding of attack types and training redundancy across domains. We\naddress the first by integrating vision-language models (VLMs) to enhance the\nperception of visual input. For the second challenge, we employ a meta-domain\nstrategy to learn a unified model that generalizes well across multiple\ndomains. Our proposed InstructFLIP is a novel instruction-tuned framework that\nleverages VLMs to enhance generalization via textual guidance trained solely on\na single domain. At its core, InstructFLIP explicitly decouples instructions\ninto content and style components, where content-based instructions focus on\nthe essential semantics of spoofing, and style-based instructions consider\nvariations related to the environment and camera characteristics. Extensive\nexperiments demonstrate the effectiveness of InstructFLIP by outperforming SOTA\nmodels in accuracy and substantially reducing training redundancy across\ndiverse domains in FAS. Project website is available at\nhttps://kunkunlin1221.github.io/InstructFLIP.", "comment": "Accepted by MM'25", "pdf_url": "http://arxiv.org/pdf/2507.12060v2", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-28"}
{"id": "2507.18858", "title": "Weak-to-Strong Generalization with Failure Trajectories: A Tree-based Approach to Elicit Optimal Policy in Strong Models", "authors": ["Ruimeng Ye", "Zihan Wang", "Yang Xiao", "Zinan Ling", "Manling Li", "Bo Hui"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.18858v2", "summary": "Weak-to-Strong generalization (W2SG) is a new trend to elicit the full\ncapabilities of a strong model with supervision from a weak model. While\nexisting W2SG studies focus on simple tasks like binary classification, we\nextend this paradigm to complex interactive decision-making environments.\nSpecifically, we fine-tune a strong model with trajectories of intermediate\nactions generated by a weak model. Motivated by the human learning process, we\npropose to generalize not only success knowledge but also failure experience so\nthat the strong model can learn from failed trajectories accumulated by weak\nmodels. To effectively and efficiently elicit the potential of strong agents,\nwe further construct ``trajectory trees,\" a hierarchical representation that\norganizes weak model-generated action trajectories, coupled with Monte Carlo\nTree Search (MCTS) to optimize the strong model. Through theoretical analysis,\nwe provide formal guarantees for the effectiveness of our method in improving\nW2SG performance. Our empirical evaluations demonstrate substantial\nimprovements in reasoning and decision-making capabilities across diverse task\ndomains, validating the scalability and robustness of our proposed framework.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.18858v2", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-28"}
{"id": "2507.14270", "title": "APTx Neuron: A Unified Trainable Neuron Architecture Integrating Activation and Computation", "authors": ["Ravin Kumar"], "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      10 pages, 2 figures, 1 table. Includes a GitHub repository for MNIST experiments and a PyPI package for APTx Neuron implementation", "url": "http://arxiv.org/abs/2507.14270v3", "summary": "We propose the APTx Neuron, a novel, unified neural computation unit that\nintegrates non-linear activation and linear transformation into a single\ntrainable expression. The APTx Neuron is derived from the APTx activation\nfunction, thereby eliminating the need for separate activation layers and\nmaking the architecture both computationally efficient and elegant. The\nproposed neuron follows the functional form $y = \\sum_{i=1}^{n} ((\\alpha_i +\n\\tanh(\\beta_i x_i)) \\cdot \\gamma_i x_i) + \\delta$, where all parameters\n$\\alpha_i$, $\\beta_i$, $\\gamma_i$, and $\\delta$ are trainable. We validate our\nAPTx Neuron-based architecture on the MNIST dataset, achieving up to 96.69%\ntest accuracy within 11 epochs using approximately 332K trainable parameters.\nThe results highlight the superior expressiveness and computational efficiency\nof the APTx Neuron compared to traditional neurons, pointing toward a new\nparadigm in unified neuron design and the architectures built upon it.", "comment": "10 pages, 2 figures, 1 table. Includes a GitHub repository for MNIST\n  experiments and a PyPI package for APTx Neuron implementation", "pdf_url": "http://arxiv.org/pdf/2507.14270v3", "cate": "cs.NE", "date": "2025-07-18", "updated": "2025-07-28"}
{"id": "2507.18975", "title": "Secure Best Arm Identification in the Presence of a Copycat", "authors": ["Asaf Cohen", "Onur Günlü"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      To appear in ITW 2025", "url": "http://arxiv.org/abs/2507.18975v2", "summary": "Consider the problem of best arm identification with a security constraint.\nSpecifically, assume a setup of stochastic linear bandits with $K$ arms of\ndimension $d$. In each arm pull, the player receives a reward that is the sum\nof the dot product of the arm with an unknown parameter vector and independent\nnoise. The player's goal is to identify the best arm after $T$ arm pulls.\nMoreover, assume a copycat Chloe is observing the arm pulls. The player wishes\nto keep Chloe ignorant of the best arm.\n  While a minimax--optimal algorithm identifies the best arm with an\n$\\Omega\\left(\\frac{T}{\\log(d)}\\right)$ error exponent, it easily reveals its\nbest-arm estimate to an outside observer, as the best arms are played more\nfrequently. A naive secure algorithm that plays all arms equally results in an\n$\\Omega\\left(\\frac{T}{d}\\right)$ exponent. In this paper, we propose a secure\nalgorithm that plays with \\emph{coded arms}. The algorithm does not require any\nkey or cryptographic primitives, yet achieves an\n$\\Omega\\left(\\frac{T}{\\log^2(d)}\\right)$ exponent while revealing almost no\ninformation on the best arm.", "comment": "To appear in ITW 2025", "pdf_url": "http://arxiv.org/pdf/2507.18975v2", "cate": "cs.LG", "date": "2025-07-25", "updated": "2025-07-28"}
{"id": "2507.15765", "title": "Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization", "authors": ["Feng-Qi Cui", "Anyang Tong", "Jinyang Huang", "Jie Zhang", "Dan Guo", "Zhi Liu", "Meng Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACM MM'25", "url": "http://arxiv.org/abs/2507.15765v2", "summary": "Dynamic Facial Expression Recognition (DFER) plays a critical role in\naffective computing and human-computer interaction. Although existing methods\nachieve comparable performance, they inevitably suffer from performance\ndegradation under sample heterogeneity caused by multi-source data and\nindividual expression variability. To address these challenges, we propose a\nnovel framework, called Heterogeneity-aware Distributional Framework (HDF), and\ndesign two plug-and-play modules to enhance time-frequency modeling and\nmitigate optimization imbalance caused by hard samples. Specifically, the\nTime-Frequency Distributional Attention Module (DAM) captures both temporal\nconsistency and frequency robustness through a dual-branch attention design,\nimproving tolerance to sequence inconsistency and visual style shifts. Then,\nbased on gradient sensitivity and information bottleneck principles, an\nadaptive optimization module Distribution-aware Scaling Module (DSM) is\nintroduced to dynamically balance classification and contrastive losses,\nenabling more stable and discriminative representation learning. Extensive\nexperiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF\nsignificantly improves both recognition accuracy and robustness. Our method\nachieves superior weighted average recall (WAR) and unweighted average recall\n(UAR) while maintaining strong generalization across diverse and imbalanced\nscenarios. Codes are released at https://github.com/QIcita/HDF_DFER.", "comment": "Accepted by ACM MM'25", "pdf_url": "http://arxiv.org/pdf/2507.15765v2", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-26"}
{"id": "2007.00736", "title": "Tensor Completion with Nearly Linear Samples Given Weak Side Information", "authors": ["Christina Lee Yu", "Xumei Xi"], "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2007.00736v4", "summary": "Tensor completion exhibits an interesting computational-statistical gap in\nterms of the number of samples needed to perform tensor estimation. While there\nare only $\\Theta(tn)$ degrees of freedom in a $t$-order tensor with $n^t$\nentries, the best known polynomial time algorithm requires $O(n^{t/2})$ samples\nin order to guarantee consistent estimation. In this paper, we show that weak\nside information is sufficient to reduce the sample complexity to $O(n)$. The\nside information consists of a weight vector for each of the modes which is not\northogonal to any of the latent factors along that mode; this is significantly\nweaker than assuming noisy knowledge of the subspaces. We provide an algorithm\nthat utilizes this side information to produce a consistent estimator with\n$O(n^{1+\\kappa})$ samples for any small constant $\\kappa > 0$. We also provide\nexperiments on both synthetic and real-world datasets that validate our\ntheoretical insights.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2007.00736v4", "cate": "stat.ML", "date": "2020-07-01", "updated": "2025-07-28"}
{"id": "2507.15961", "title": "A Lightweight Face Quality Assessment Framework to Improve Face Verification Performance in Real-Time Screening Applications", "authors": ["Ahmed Aman Ibrahim", "Hamad Mansour Alawar", "Abdulnasser Abbas Zehi", "Ahmed Mohammad Alkendi", "Bilal Shafi Ashfaq Ahmed Mirza", "Shan Ullah", "Ismail Lujain Jaleel", "Hassan Ugail"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.15961v2", "summary": "Face image quality plays a critical role in determining the accuracy and\nreliability of face verification systems, particularly in real-time screening\napplications such as surveillance, identity verification, and access control.\nLow-quality face images, often caused by factors such as motion blur, poor\nlighting conditions, occlusions, and extreme pose variations, significantly\ndegrade the performance of face recognition models, leading to higher false\nrejection and false acceptance rates. In this work, we propose a lightweight\nyet effective framework for automatic face quality assessment, which aims to\npre-filter low-quality face images before they are passed to the verification\npipeline. Our approach utilises normalised facial landmarks in conjunction with\na Random Forest Regression classifier to assess image quality, achieving an\naccuracy of 96.67%. By integrating this quality assessment module into the face\nverification process, we observe a substantial improvement in performance,\nincluding a comfortable 99.7% reduction in the false rejection rate and\nenhanced cosine similarity scores when paired with the ArcFace face\nverification model. To validate our approach, we have conducted experiments on\na real-world dataset collected comprising over 600 subjects captured from CCTV\nfootage in unconstrained environments within Dubai Police. Our results\ndemonstrate that the proposed framework effectively mitigates the impact of\npoor-quality face images, outperforming existing face quality assessment\ntechniques while maintaining computational efficiency. Moreover, the framework\nspecifically addresses two critical challenges in real-time screening:\nvariations in face resolution and pose deviations, both of which are prevalent\nin practical surveillance scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.15961v2", "cate": "cs.CV", "date": "2025-07-21", "updated": "2025-07-27"}
{"id": "2110.01950", "title": "Classification of high-dimensional data with spiked covariance matrix structure", "authors": ["Yin-Jen Chen", "Minh Tang"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      40 pages, 2 figures", "url": "http://arxiv.org/abs/2110.01950v2", "summary": "We study the classification problem for high-dimensional data with $n$\nobservations on $p$ features where the $p \\times p$ covariance matrix $\\Sigma$\nexhibits a spiked eigenvalues structure and the vector $\\zeta$, given by the\ndifference between the whitened mean vectors, is sparse with sparsity at most\n$s$. We propose an adaptive classifier (adaptive with respect to the sparsity\n$s$) that first performs dimension reduction on the feature vectors prior to\nclassification in the dimensionally reduced space, i.e., the classifier\nwhitened the data, then screen the features by keeping only those corresponding\nto the $s$ largest coordinates of $\\zeta$ and finally apply Fisher linear\ndiscriminant on the selected features. Leveraging recent results on entrywise\nmatrix perturbation bounds for covariance matrices, we show that the resulting\nclassifier is Bayes optimal whenever $n \\rightarrow \\infty$ and $s \\sqrt{n^{-1}\n\\ln p} \\rightarrow 0$. Experimental results on real and synthetic data sets\nindicate that the proposed classifier is competitive with existing\nstate-of-the-art methods while also selecting a smaller number of features.", "comment": "40 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2110.01950v2", "cate": "stat.ML", "date": "2021-10-05", "updated": "2025-07-28"}
{"id": "2507.17347", "title": "Swin-TUNA : A Novel PEFT Approach for Accurate Food Image Segmentation", "authors": ["Haotian Chen", "Zhiyong Xiao"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      After discussion among the authors, some parts of the paper are deemed inappropriate and will be revised and resubmitted", "url": "http://arxiv.org/abs/2507.17347v3", "summary": "In the field of food image processing, efficient semantic segmentation\ntechniques are crucial for industrial applications. However, existing\nlarge-scale Transformer-based models (such as FoodSAM) face challenges in\nmeeting practical deploymentrequirements due to their massive parameter counts\nand high computational resource demands. This paper introduces TUNable Adapter\nmodule (Swin-TUNA), a Parameter Efficient Fine-Tuning (PEFT) method that\nintegrates multiscale trainable adapters into the Swin Transformer\narchitecture, achieving high-performance food image segmentation by updating\nonly 4% of the parameters. The core innovation of Swin-TUNA lies in its\nhierarchical feature adaptation mechanism: it designs separable convolutions in\ndepth and dimensional mappings of varying scales to address the differences in\nfeatures between shallow and deep networks, combined with a dynamic balancing\nstrategy for tasks-agnostic and task-specific features. Experiments demonstrate\nthat this method achieves mIoU of 50.56% and 74.94% on the FoodSeg103 and\nUECFoodPix Complete datasets, respectively, surpassing the fully parameterized\nFoodSAM model while reducing the parameter count by 98.7% (to only 8.13M).\nFurthermore, Swin-TUNA exhibits faster convergence and stronger generalization\ncapabilities in low-data scenarios, providing an efficient solution for\nassembling lightweight food image.", "comment": "After discussion among the authors, some parts of the paper are\n  deemed inappropriate and will be revised and resubmitted", "pdf_url": "http://arxiv.org/pdf/2507.17347v3", "cate": "cs.CV", "date": "2025-07-23", "updated": "2025-07-28"}
{"id": "2306.10189", "title": "MOCK: an Algorithm for Learning Nonparametric Differential Equations via Multivariate Occupation Kernel Functions", "authors": ["Victor Rielly", "Kamel Lahouel", "Ethan Lew", "Nicholas Fisher", "Vicky Haney", "Michael Wells", "Bruno Jedynak"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      29 pages, 6 figures Accepted at Transactions in Machine Learning Research (TMLR)", "url": "http://arxiv.org/abs/2306.10189v4", "summary": "Learning a nonparametric system of ordinary differential equations from\ntrajectories in a $d$-dimensional state space requires learning $d$ functions\nof $d$ variables. Explicit formulations often scale quadratically in $d$ unless\nadditional knowledge about system properties, such as sparsity and symmetries,\nis available. In this work, we propose a linear approach, the multivariate\noccupation kernel method (MOCK), using the implicit formulation provided by\nvector-valued reproducing kernel Hilbert spaces. The solution for the vector\nfield relies on multivariate occupation kernel functions associated with the\ntrajectories and scales linearly with the dimension of the state space. We\nvalidate through experiments on a variety of simulated and real datasets\nranging from 2 to 1024 dimensions. MOCK outperforms all other comparators on 3\nof the 9 datasets on full trajectory prediction and 4 out of the 9 datasets on\nnext-point prediction.", "comment": "29 pages, 6 figures Accepted at Transactions in Machine Learning\n  Research (TMLR)", "pdf_url": "http://arxiv.org/pdf/2306.10189v4", "cate": "stat.ML", "date": "2023-06-16", "updated": "2025-07-25"}
{"id": "2507.18082", "title": "TextSAM-EUS: Text Prompt Learning for SAM to Accurately Segment Pancreatic Tumor in Endoscopic Ultrasound", "authors": ["Pascal Spiegler", "Taha Koleilat", "Arash Harirpoush", "Corey S. Miller", "Hassan Rivaz", "Marta Kersten-Oertel", "Yiming Xiao"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025 Workshop CVAMD", "url": "http://arxiv.org/abs/2507.18082v2", "summary": "Pancreatic cancer carries a poor prognosis and relies on endoscopic\nultrasound (EUS) for targeted biopsy and radiotherapy. However, the speckle\nnoise, low contrast, and unintuitive appearance of EUS make segmentation of\npancreatic tumors with fully supervised deep learning (DL) models both\nerror-prone and dependent on large, expert-curated annotation datasets. To\naddress these challenges, we present TextSAM-EUS, a novel, lightweight,\ntext-driven adaptation of the Segment Anything Model (SAM) that requires no\nmanual geometric prompts at inference. Our approach leverages text prompt\nlearning (context optimization) through the BiomedCLIP text encoder in\nconjunction with a LoRA-based adaptation of SAM's architecture to enable\nautomatic pancreatic tumor segmentation in EUS, tuning only 0.86% of the total\nparameters. On the public Endoscopic Ultrasound Database of the Pancreas,\nTextSAM-EUS with automatic prompts attains 82.69% Dice and 85.28% normalized\nsurface distance (NSD), and with manual geometric prompts reaches 83.10% Dice\nand 85.70% NSD, outperforming both existing state-of-the-art (SOTA) supervised\nDL models and foundation models (e.g., SAM and its variants). As the first\nattempt to incorporate prompt learning in SAM-based medical image segmentation,\nTextSAM-EUS offers a practical option for efficient and robust automatic EUS\nsegmentation.", "comment": "Accepted to ICCV 2025 Workshop CVAMD", "pdf_url": "http://arxiv.org/pdf/2507.18082v2", "cate": "cs.CV", "date": "2025-07-24", "updated": "2025-07-26"}
{"id": "2310.02254", "title": "Learning unitaries with quantum statistical queries", "authors": ["Armando Angrisani"], "categories": ["quant-ph", "cs.CC", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      40 pages", "url": "http://arxiv.org/abs/2310.02254v3", "summary": "We propose several algorithms for learning unitary operators from quantum\nstatistical queries with respect to their Choi-Jamiolkowski state. Quantum\nstatistical queries capture the capabilities of a learner with limited quantum\nresources, which receives as input only noisy estimates of expected values of\nmeasurements. Our approach leverages quantum statistical queries to estimate\nthe Fourier mass of a unitary on a subset of Pauli strings, generalizing\nprevious techniques developed for uniform quantum examples. Specifically, we\nshow that the celebrated quantum Goldreich-Levin algorithm can be implemented\nwith quantum statistical queries, whereas the prior version of the algorithm\ninvolves oracle access to the unitary and its inverse. As an application, we\nprove that quantum Boolean functions with constant total influence or with\nconstant degree are efficiently learnable in our model. Moreover, we prove that\n$\\mathcal{O}(\\log n)$-juntas are efficiently learnable and constant-depth\ncircuits are learnable query-efficiently with quantum statistical queries. On\nthe other hand, all previous algorithms for these tasks demand significantly\ngreater resources, such as oracle access to the unitary or direct access to the\nChoi-Jamiolkowski state. We also demonstrate that, despite these positive\nresults, quantum statistical queries lead to an exponentially larger query\ncomplexity for certain tasks, compared to separable measurements to the\nChoi-Jamiolkowski state. In particular, we show an exponential lower bound for\nlearning a class of phase-oracle unitaries and a double exponential lower bound\nfor testing the unitarity of channels. Taken together, our results indicate\nthat quantum statistical queries offer a unified framework for various unitary\nlearning tasks, with potential applications in quantum machine learning,\nmany-body physics and benchmarking of near-term devices.", "comment": "40 pages", "pdf_url": "http://arxiv.org/pdf/2310.02254v3", "cate": "quant-ph", "date": "2023-10-03", "updated": "2025-07-28"}
{"id": "2507.19119", "title": "PatchTraj: Dynamic Patch Representation Learning for Time-Frequency Trajectory Prediction", "authors": ["Yanghong Liu", "Xingping Dong", "Ming Li", "Weixing Zhang", "Yidong Lou"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.19119v2", "summary": "Pedestrian trajectory prediction is crucial for autonomous driving and\nrobotics. While existing point-based and grid-based methods expose two key\nlimitations: insufficiently modeling human motion dynamics, as they fail to\nbalance local motion details with long-range spatiotemporal dependencies, and\nthe time representation lacks interaction with the frequency domain in modeling\ntrajectory sequences. To address these challenges, we propose PatchTraj, a\ndynamic patch-based trajectory prediction framework that unifies time-domain\nand frequency-domain representations. Specifically, we decompose the trajectory\ninto raw time sequences and frequency components, employing dynamic patch\npartitioning for multi-scale trajectory segmentation to capture hierarchical\nmotion patterns. Each patch is processed by an adaptive embedding layer with\nscale-aware feature extraction, followed by hierarchical feature aggregation to\nmodel both fine-grained and long-range dependencies. The outputs of two\nbranches interact via cross-modal attention, enabling complementary fusion of\ntemporal and spectral cues. Finally, a Transformer encoder-decoder integrates\nboth modalities to autoregressively predict future trajectories. Extensive\nexperiments on ETH-UCY, SDD, NBA, and JRDB datasets demonstrate that our method\nachieves state-of-the-art performance with high efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.19119v2", "cate": "cs.CV", "date": "2025-07-25", "updated": "2025-07-28"}
{"id": "2312.01047", "title": "A New Random Reshuffling Method for Nonsmooth Nonconvex Finite-sum Optimization", "authors": ["Junwen Qiu", "Xiao Li", "Andre Milzarek"], "categories": ["math.OC", "cs.LG", "90C26, 90C15"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      45 pages, 5 figures", "url": "http://arxiv.org/abs/2312.01047v3", "summary": "Random reshuffling techniques are prevalent in large-scale applications, such\nas training neural networks. While the convergence and acceleration effects of\nrandom reshuffling-type methods are fairly well understood in the smooth\nsetting, much less studies seem available in the nonsmooth case. In this work,\nwe design a new normal map-based proximal random reshuffling (norm-PRR) method\nfor nonsmooth nonconvex finite-sum problems. We show that norm-PRR achieves the\niteration complexity ${\\cal O}(n^{-1/3}T^{-2/3})$ where $n$ denotes the number\nof component functions $f(\\cdot,i)$ and $T$ counts the total number of\niterations. This improves the currently known complexity bounds for this class\nof problems by a factor of $n^{-1/3}$ in terms of the number of gradient\nevaluations. Additionally, we prove that norm-PRR converges linearly under the\n(global) Polyak-{\\L}ojasiewicz condition and in the interpolation setting. We\nfurther complement these non-asymptotic results and provide an in-depth\nanalysis of the asymptotic properties of norm-PRR. Specifically, under the\n(local) Kurdyka-{\\L}ojasiewicz inequality, the whole sequence of iterates\ngenerated by norm-PRR is shown to converge to a single stationary point.\nMoreover, we derive last-iterate convergence rates that can match those in the\nsmooth, strongly convex setting. Finally, numerical experiments are performed\non nonconvex classification tasks to illustrate the efficiency of the proposed\napproach.", "comment": "45 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2312.01047v3", "cate": "math.OC", "date": "2023-12-02", "updated": "2025-07-28"}
{"id": "2405.20384", "title": "Recurrent neural network wave functions for Rydberg atom arrays on kagome lattice", "authors": ["Mohamed Hibat-Allah", "Ejaaz Merali", "Giacomo Torlai", "Roger G Melko", "Juan Carrasquilla"], "categories": ["cond-mat.quant-gas", "cond-mat.dis-nn", "cond-mat.str-el", "cs.LG", "quant-ph"], "primary_category": "Subjects:       Quantum Gases (cond-mat.quant-gas)", "pdf_link": null, "comments": "Comments:      15 pages, 7 figures, 6 tables. Link to GitHub repository: this https URL", "url": "http://arxiv.org/abs/2405.20384v2", "summary": "Rydberg atom array experiments have demonstrated the ability to act as\npowerful quantum simulators, preparing strongly-correlated phases of matter\nwhich are challenging to study for conventional computer simulations. A key\ndirection has been the implementation of interactions on frustrated geometries,\nin an effort to prepare exotic many-body states such as spin liquids and\nglasses. In this paper, we apply two-dimensional recurrent neural network (RNN)\nwave functions to study the ground states of Rydberg atom arrays on the kagome\nlattice. We implement an annealing scheme to find the RNN variational\nparameters in regions of the phase diagram where exotic phases may occur,\ncorresponding to rough optimization landscapes. For Rydberg atom array\nHamiltonians studied previously on the kagome lattice, our RNN ground states\nshow no evidence of exotic spin liquid or emergent glassy behavior. In the\nlatter case, we argue that the presence of a non-zero Edwards-Anderson order\nparameter is an artifact of the long autocorrelations times experienced with\nquantum Monte Carlo (QMC) simulations, and we show that autocorrelations can be\nsystematically reduced by increasing numerical effort. This result emphasizes\nthe utility of autoregressive models, such as RNNs, in conjunction with QMC, to\nexplore Rydberg atom array physics on frustrated lattices and beyond.", "comment": "15 pages, 7 figures, 6 tables. Link to GitHub repository:\n  https://github.com/mhibatallah/RNNWavefunctions", "pdf_url": "http://arxiv.org/pdf/2405.20384v2", "cate": "cond-mat.quant-gas", "date": "2024-05-30", "updated": "2025-07-26"}
{"id": "2407.01496", "title": "Efficient Shallow Ritz Method For 1D Diffusion-Reaction Problems", "authors": ["Zhiqiang Cai", "Anastassia Doktorova", "Robert D. Falgout", "César Herrera"], "categories": ["math.NA", "cs.LG", "cs.NA", "65K10, 65F05"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.01496v4", "summary": "This paper studies the shallow Ritz method for solving one-dimensional\ndiffusion-reaction problems. The method is capable of improving the order of\napproximation for non-smooth problems. By following a similar approach to the\none presented in [9], we present a damped block Newton (dBN) method to achieve\nnearly optimal order of approximation. The dBN method optimizes the Ritz\nfunctional by alternating between the linear and non-linear parameters of the\nshallow ReLU neural network (NN). For diffusion-reaction problems, new\ndifficulties arise: (1) for the linear parameters, the mass matrix is dense and\neven more ill-conditioned than the stiffness matrix, and (2) for the non-linear\nparameters, the Hessian matrix is dense and may be singular. This paper\naddresses these challenges, resulting in a dBN method with computational cost\nof ${\\cal O}(n)$.\n  The ideas presented for diffusion-reaction problems can also be applied to\nleast-squares approximation problems. For both applications, starting with the\nnon-linear parameters as a uniform partition, numerical experiments show that\nthe dBN method moves the mesh points to nearly optimal locations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.01496v4", "cate": "math.NA", "date": "2024-07-01", "updated": "2025-07-26"}
{"id": "2409.18152", "title": "Reinforcement Learning for Finite Space Mean-Field Type Games", "authors": ["Kai Shao", "Jiacheng Shen", "Mathieu Laurière"], "categories": ["cs.GT", "cs.LG", "math.OC"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.18152v3", "summary": "Mean field type games (MFTGs) describe Nash equilibria between large\ncoalitions: each coalition consists of a continuum of cooperative agents who\nmaximize the average reward of their coalition while interacting\nnon-cooperatively with a finite number of other coalitions. Although the theory\nhas been extensively developed, we are still lacking efficient and scalable\ncomputational methods. Here, we develop reinforcement learning methods for such\ngames in a finite space setting with general dynamics and reward functions. We\nstart by proving that the MFTG solution yields approximate Nash equilibria in\nfinite-size coalition games. We then propose two algorithms. The first is based\non the quantization of mean-field spaces and Nash Q-learning. We provide\nconvergence and stability analysis. We then propose a deep reinforcement\nlearning algorithm, which can scale to larger spaces. Numerical experiments in\n4 environments with mean-field distributions of dimension up to $200$ show the\nscalability and efficiency of the proposed method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.18152v3", "cate": "cs.GT", "date": "2024-09-25", "updated": "2025-07-26"}
{"id": "2410.03229", "title": "Elucidating the Design Choice of Probability Paths in Flow Matching for Forecasting", "authors": ["Soon Hoe Lim", "Yijin Wang", "Annan Yu", "Emma Hart", "Michael W. Mahoney", "Xiaoye S. Li", "N. Benjamin Erichson"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      35 pages", "url": "http://arxiv.org/abs/2410.03229v3", "summary": "Flow matching has recently emerged as a powerful paradigm for generative\nmodeling and has been extended to probabilistic time series forecasting in\nlatent spaces. However, the impact of the specific choice of probability path\nmodel on forecasting performance remains under-explored. In this work, we\ndemonstrate that forecasting spatio-temporal data with flow matching is highly\nsensitive to the selection of the probability path model. Motivated by this\ninsight, we propose a novel probability path model designed to improve\nforecasting performance. Our empirical results across various dynamical system\nbenchmarks show that our model achieves faster convergence during training and\nimproved predictive performance compared to existing probability path models.\nImportantly, our approach is efficient during inference, requiring only a few\nsampling steps. This makes our proposed model practical for real-world\napplications and opens new avenues for probabilistic forecasting.", "comment": "35 pages", "pdf_url": "http://arxiv.org/pdf/2410.03229v3", "cate": "stat.ML", "date": "2024-10-04", "updated": "2025-07-26"}
{"id": "2410.05634", "title": "Identification and estimation for matrix time series CP-factor models", "authors": ["Jinyuan Chang", "Yue Du", "Guanglin Huang", "Qiwei Yao"], "categories": ["stat.ME", "cs.LG", "econ.EM"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.05634v3", "summary": "We propose a new method for identifying and estimating the CP-factor models\nfor matrix time series. Unlike the generalized eigenanalysis-based method of\nChang et al. (2023) for which the convergence rates of the associated\nestimators may suffer from small eigengaps as the asymptotic theory is based on\nsome matrix perturbation analysis, the proposed new method enjoys faster\nconvergence rates which are free from any eigengaps. It achieves this by\nturning the problem into a joint diagonalization of several matrices whose\nelements are determined by a basis of a linear system, and by choosing the\nbasis carefully to avoid near co-linearity (see Proposition 5 and Section 4.3).\nFurthermore, unlike Chang et al. (2023) which requires the two factor loading\nmatrices to be full-ranked, the proposed new method can handle rank-deficient\nfactor loading matrices. Illustration with both simulated and real matrix time\nseries data shows the advantages of the proposed new method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.05634v3", "cate": "stat.ME", "date": "2024-10-08", "updated": "2025-07-26"}
{"id": "2410.19745", "title": "Adaptive Real-Time Multi-Loss Function Optimization Using Dynamic Memory Fusion Framework: A Case Study on Breast Cancer Segmentation", "authors": ["Amin Golnari", "Mostafa Diba"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.19745v2", "summary": "Deep learning has proven to be a highly effective tool for a wide range of\napplications, significantly when leveraging the power of multi-loss functions\nto optimize performance on multiple criteria simultaneously. However, optimal\nselection and weighting loss functions in deep learning tasks can significantly\ninfluence model performance, yet manual tuning of these functions is often\ninefficient and inflexible. We propose a novel framework called dynamic memory\nfusion for adaptive multi-loss function penalizing in real-time to address\nthis. This framework leverages historical loss values data to dynamically\nadjust the weighting of multiple loss functions throughout the training\nprocess. Additionally, this framework integrates an auxiliary loss function to\nenhance model performance in the early stages. To further research horizons, we\nintroduce the class-balanced dice loss function, designed to address class\nimbalance by prioritizing underrepresented classes. Experiments on breast\nultrasound datasets demonstrate that the framework improves segmentation\nperformance across various metrics. These results demonstrate the effectiveness\nof our proposed framework in ensuring that the model dynamically adjusts its\nfocus to prioritize the most relevant criteria, leading to improved performance\nin evolving environments. The source code for our proposed methodology is\npublicly available on GitHub.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.19745v2", "cate": "cs.CV", "date": "2024-10-10", "updated": "2025-07-27"}
{"id": "2410.23771", "title": "What is Wrong with Perplexity for Long-context Language Modeling?", "authors": ["Lizhe Fang", "Yifei Wang", "Zhaoyang Liu", "Chenheng Zhang", "Stefanie Jegelka", "Jinyang Gao", "Bolin Ding", "Yisen Wang"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.23771v5", "summary": "Handling long-context inputs is crucial for large language models (LLMs) in\ntasks such as extended conversations, document summarization, and many-shot\nin-context learning. While recent approaches have extended the context windows\nof LLMs and employed perplexity (PPL) as a standard evaluation metric, PPL has\nproven unreliable for assessing long-context capabilities. The underlying cause\nof this limitation has remained unclear. In this work, we provide a\ncomprehensive explanation for this issue. We find that PPL overlooks key\ntokens, which are essential for long-context understanding, by averaging across\nall tokens and thereby obscuring the true performance of models in long-context\nscenarios. To address this, we propose \\textbf{LongPPL}, a novel metric that\nfocuses on key tokens by employing a long-short context contrastive method to\nidentify them. Our experiments demonstrate that LongPPL strongly correlates\nwith performance on various long-context benchmarks (e.g., Pearson correlation\nof -0.96), significantly outperforming traditional PPL in predictive accuracy.\nAdditionally, we introduce \\textbf{LongCE} (Long-context Cross-Entropy) loss, a\nre-weighting strategy for fine-tuning that prioritizes key tokens, leading to\nconsistent improvements across diverse benchmarks. In summary, these\ncontributions offer deeper insights into the limitations of PPL and present\neffective solutions for accurately evaluating and enhancing the long-context\ncapabilities of LLMs. Code is available at https://github.com/PKU-ML/LongPPL.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.23771v5", "cate": "cs.CL", "date": "2024-10-31", "updated": "2025-07-27"}
{"id": "2411.09296", "title": "Enhancing generalization in high energy physics using white-box adversarial attacks", "authors": ["Franck Rothen", "Samuel Klein", "Matthew Leigh", "Tobias Golling"], "categories": ["hep-ph", "cs.LG"], "primary_category": "Subjects:       High Energy Physics - Phenomenology (hep-ph)", "pdf_link": null, "comments": "Comments:      14 pages, 7 figures, 10 tables, 3 algorithms, published in Physical Review D (PRD), presented at the ML4Jets 2024 conference", "url": "http://arxiv.org/abs/2411.09296v3", "summary": "Machine learning is becoming increasingly popular in the context of particle\nphysics. Supervised learning, which uses labeled Monte Carlo (MC) simulations,\nremains one of the most widely used methods for discriminating signals beyond\nthe Standard Model. However, this paper suggests that supervised models may\ndepend excessively on artifacts and approximations from Monte Carlo\nsimulations, potentially limiting their ability to generalize well to real\ndata. This study aims to enhance the generalization properties of supervised\nmodels by reducing the sharpness of local minima. It reviews the application of\nfour distinct white-box adversarial attacks in the context of classifying Higgs\nboson decay signals. The attacks are divided into weight-space attacks and\nfeature-space attacks. To study and quantify the sharpness of different local\nminima, this paper presents two analysis methods: gradient ascent and reduced\nHessian eigenvalue analysis. The results show that white-box adversarial\nattacks significantly improve generalization performance, albeit with increased\ncomputational complexity.", "comment": "14 pages, 7 figures, 10 tables, 3 algorithms, published in Physical\n  Review D (PRD), presented at the ML4Jets 2024 conference", "pdf_url": "http://arxiv.org/pdf/2411.09296v3", "cate": "hep-ph", "date": "2024-11-14", "updated": "2025-07-28"}
{"id": "2411.10503", "title": "Everything is a Video: Unifying Modalities through Next-Frame Prediction", "authors": ["G. Thomas Hudson", "Dean Slack", "Thomas Winterbottom", "Jamie Sterling", "Chenghao Xiao", "Junjie Shentu", "Noura Al Moubayed"], "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 10 figures", "url": "http://arxiv.org/abs/2411.10503v2", "summary": "Multimodal learning, which involves integrating information from various\nmodalities such as text, images, audio, and video, is pivotal for numerous\ncomplex tasks like visual question answering, cross-modal retrieval, and\ncaption generation. Traditional approaches rely on modality-specific encoders\nand late fusion techniques, which can hinder scalability and flexibility when\nadapting to new tasks or modalities. To address these limitations, we introduce\na novel framework that extends the concept of task reformulation beyond natural\nlanguage processing (NLP) to multimodal learning. We propose to reformulate\ndiverse multimodal tasks into a unified next-frame prediction problem, allowing\na single model to handle different modalities without modality-specific\ncomponents. This method treats all inputs and outputs as sequential frames in a\nvideo, enabling seamless integration of modalities and effective knowledge\ntransfer across tasks. Our approach is evaluated on a range of tasks, including\ntext-to-text, image-to-text, video-to-video, video-to-text, and audio-to-text,\ndemonstrating the model's ability to generalize across modalities with minimal\nadaptation. We show that task reformulation can significantly simplify\nmultimodal model design across various tasks, laying the groundwork for more\ngeneralized multimodal foundation models.", "comment": "10 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2411.10503v2", "cate": "cs.CV", "date": "2024-11-15", "updated": "2025-07-28"}
{"id": "2411.11513", "title": "A Modular Open Source Framework for Genomic Variant Calling", "authors": ["Ankita Vaishnobi Bisoi", "Shreyas V", "Jose Siguenza", "Bharath Ramsundar"], "categories": ["q-bio.QM", "cs.LG"], "primary_category": "Subjects:       Quantitative Methods (q-bio.QM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.11513v2", "summary": "Variant calling is a fundamental task in genomic research, essential for\ndetecting genetic variations such as single nucleotide polymorphisms (SNPs) and\ninsertions or deletions (indels). This paper presents an enhancement to\nDeepChem, a widely used open-source drug discovery framework, through the\nintegration of DeepVariant. In particular, we introduce a variant calling\npipeline that leverages DeepVariant's convolutional neural network (CNN)\narchitecture to improve the accuracy and reliability of variant detection. The\nimplemented pipeline includes stages for realignment of sequencing reads,\ncandidate variant detection, and pileup image generation, followed by variant\nclassification using a modified Inception v3 model. Our work adds a modular and\nextensible variant calling framework to the DeepChem framework and enables\nfuture work integrating DeepChem's drug discovery infrastructure more tightly\nwith bioinformatics pipelines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.11513v2", "cate": "q-bio.QM", "date": "2024-11-18", "updated": "2025-07-28"}
{"id": "2411.16715", "title": "PaRCE: Probabilistic and Reconstruction-based Competency Estimation for CNN-based Image Classification", "authors": ["Sara Pohland", "Claire Tomlin"], "categories": ["cs.CV", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2409.06111", "url": "http://arxiv.org/abs/2411.16715v3", "summary": "Convolutional neural networks (CNNs) are extremely popular and effective for\nimage classification tasks but tend to be overly confident in their\npredictions. Various works have sought to quantify uncertainty associated with\nthese models, detect out-of-distribution (OOD) inputs, or identify anomalous\nregions in an image, but limited work has sought to develop a holistic approach\nthat can accurately estimate perception model confidence across various sources\nof uncertainty. We develop a probabilistic and reconstruction-based competency\nestimation (PaRCE) method and compare it to existing approaches for uncertainty\nquantification and OOD detection. We find that our method can best distinguish\nbetween correctly classified, misclassified, and OOD samples with anomalous\nregions, as well as between samples with visual image modifications resulting\nin high, medium, and low prediction accuracy. We describe how to extend our\napproach for anomaly localization tasks and demonstrate the ability of our\napproach to distinguish between regions in an image that are familiar to the\nperception model from those that are unfamiliar. We find that our method\ngenerates interpretable scores that most reliably capture a holistic notion of\nperception model confidence.", "comment": "arXiv admin note: text overlap with arXiv:2409.06111", "pdf_url": "http://arxiv.org/pdf/2411.16715v3", "cate": "cs.CV", "date": "2024-11-22", "updated": "2025-07-26"}
{"id": "2412.03214", "title": "Continual Low-Rank Scaled Dot-product Attention", "authors": ["Ginés Carreto Picón", "Illia Oleksiienko", "Lukas Hedegaard", "Arian Bakhtiarnia", "Alexandros Iosifidis"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      16 pages, 7 figures", "url": "http://arxiv.org/abs/2412.03214v4", "summary": "Transformers are widely used for their ability to capture data relations in\nsequence processing, with great success for a wide range of static tasks.\nHowever, the computational and memory footprint of their main component, i.e.,\nthe Scaled Dot-product Attention, is commonly overlooked. This makes their\nadoption in applications involving stream data processing with constraints in\nresponse latency, computational and memory resources infeasible. Some works\nhave proposed methods to lower the computational cost of Transformers, i.e.\nlow-rank approximations, sparsity in attention, and efficient formulations for\nContinual Inference. In this paper, we introduce a new formulation of the\nScaled Dot-product Attention based on the Nystr\\\"om approximation that is\nsuitable for Continual Inference. In experiments on Online Audio Classification\nand Online Action Detection tasks, the proposed Continual Scaled Dot-product\nAttention can lower the number of operations by up to three orders of magnitude\ncompared to the original Transformers while retaining the predictive\nperformance of competing models.", "comment": "16 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2412.03214v4", "cate": "cs.CV", "date": "2024-12-04", "updated": "2025-07-28"}
{"id": "2412.07815", "title": "Mask prior-guided denoising diffusion improves inverse protein folding", "authors": ["Peizhen Bai", "Filip Miljković", "Xianyuan Liu", "Leonardo De Maria", "Rebecca Croasdale-Wood", "Owen Rackham", "Haiping Lu"], "categories": ["q-bio.BM", "cs.LG"], "primary_category": "Subjects:       Biomolecules (q-bio.BM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.07815v2", "summary": "Inverse protein folding generates valid amino acid sequences that can fold\ninto a desired protein structure, with recent deep-learning advances showing\nstrong potential and competitive performance. However, challenges remain, such\nas predicting elements with high structural uncertainty, including disordered\nregions. To tackle such low-confidence residue prediction, we propose a\nMask-prior-guided denoising Diffusion (MapDiff) framework that accurately\ncaptures both structural information and residue interactions for inverse\nprotein folding. MapDiff is a discrete diffusion probabilistic model that\niteratively generates amino acid sequences with reduced noise, conditioned on a\ngiven protein backbone. To incorporate structural information and residue\ninteractions, we develop a graph-based denoising network with a mask-prior\npre-training strategy. Moreover, in the generative process, we combine the\ndenoising diffusion implicit model with Monte-Carlo dropout to reduce\nuncertainty. Evaluation on four challenging sequence design benchmarks shows\nthat MapDiff substantially outperforms state-of-the-art methods. Furthermore,\nthe in silico sequences generated by MapDiff closely resemble the\nphysico-chemical and structural characteristics of native proteins across\ndifferent protein families and architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.07815v2", "cate": "q-bio.BM", "date": "2024-12-10", "updated": "2025-07-25"}
{"id": "2412.11569", "title": "The dark side of the forces: assessing non-conservative force models for atomistic machine learning", "authors": ["Filippo Bigi", "Marcel Langer", "Michele Ceriotti"], "categories": ["physics.chem-ph", "cs.LG"], "primary_category": "Subjects:       Chemical Physics (physics.chem-ph)", "pdf_link": null, "comments": "Comments:      10 pages (including references) + appendix Conference format", "url": "http://arxiv.org/abs/2412.11569v5", "summary": "The use of machine learning to estimate the energy of a group of atoms, and\nthe forces that drive them to more stable configurations, has revolutionized\nthe fields of computational chemistry and materials discovery. In this domain,\nrigorous enforcement of symmetry and conservation laws has traditionally been\nconsidered essential. For this reason, interatomic forces are usually computed\nas the derivatives of the potential energy, ensuring energy conservation.\nSeveral recent works have questioned this physically constrained approach,\nsuggesting that directly predicting the forces yields a better trade-off\nbetween accuracy and computational efficiency, and that energy conservation can\nbe learned during training. This work investigates the applicability of such\nnon-conservative models in microscopic simulations. We identify and demonstrate\nseveral fundamental issues, from ill-defined convergence of geometry\noptimization to instability in various types of molecular dynamics. Given the\ndifficulty in monitoring and correcting the lack of energy conservation, direct\nforces should be used with great care. We show that the best approach to\nexploit the acceleration they afford is to use them in conjunction with\nconservative forces. A model can be pre-trained efficiently on direct forces,\nthen fine-tuned using backpropagation. At evaluation time, both force types can\nbe used together to avoid unphysical effects while still benefitting almost\nentirely from the computational efficiency of direct forces.", "comment": "10 pages (including references) + appendix Conference format", "pdf_url": "http://arxiv.org/pdf/2412.11569v5", "cate": "physics.chem-ph", "date": "2024-12-16", "updated": "2025-07-26"}
{"id": "2412.18988", "title": "MTCAE-DFER: Multi-Task Cascaded Autoencoder for Dynamic Facial Expression Recognition", "authors": ["Peihao Xiang", "Kaida Wu", "Ou Bai"], "categories": ["cs.CV", "cs.LG", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Camera-ready Version, Accepted by IJCB 2025", "url": "http://arxiv.org/abs/2412.18988v2", "summary": "This paper expands the cascaded network branch of the autoencoder-based\nmulti-task learning (MTL) framework for dynamic facial expression recognition,\nnamely Multi-Task Cascaded Autoencoder for Dynamic Facial Expression\nRecognition (MTCAE-DFER). MTCAE-DFER builds a plug-and-play cascaded decoder\nmodule, which is based on the Vision Transformer (ViT) architecture and employs\nthe decoder concept of Transformer to reconstruct the multi-head attention\nmodule. The decoder output from the previous task serves as the query (Q),\nrepresenting local dynamic features, while the Video Masked Autoencoder\n(VideoMAE) shared encoder output acts as both the key (K) and value (V),\nrepresenting global dynamic features. This setup facilitates interaction\nbetween global and local dynamic features across related tasks. Additionally,\nthis proposal aims to alleviate overfitting of complex large model. We utilize\nautoencoder-based multi-task cascaded learning approach to explore the impact\nof dynamic face detection and dynamic face landmark on dynamic facial\nexpression recognition, which enhances the model's generalization ability.\nAfter we conduct extensive ablation experiments and comparison with\nstate-of-the-art (SOTA) methods on various public datasets for dynamic facial\nexpression recognition, the robustness of the MTCAE-DFER model and the\neffectiveness of global-local dynamic feature interaction among related tasks\nhave been proven.", "comment": "Camera-ready Version, Accepted by IJCB 2025", "pdf_url": "http://arxiv.org/pdf/2412.18988v2", "cate": "cs.CV", "date": "2024-12-25", "updated": "2025-07-26"}
{"id": "2502.07285", "title": "Negative Dependence as a toolbox for machine learning : review and new developments", "authors": ["Hoang-Son Tran", "Vladimir Petrovic", "Remi Bardenet", "Subhroshekhar Ghosh"], "categories": ["stat.ML", "cs.LG", "math.PR"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Dedicated to the memory of Prof K.R. Parthasarathy: visionary, guru, and scientist par excellence", "url": "http://arxiv.org/abs/2502.07285v2", "summary": "Negative dependence is becoming a key driver in advancing learning\ncapabilities beyond the limits of traditional independence. Recent developments\nhave evidenced support towards negatively dependent systems as a learning\nparadigm in a broad range of fundamental machine learning challenges including\noptimization, sampling, dimensionality reduction and sparse signal recovery,\noften surpassing the performance of current methods based on statistical\nindependence. The most popular negatively dependent model has been that of\ndeterminantal point processes (DPPs), which have their origins in quantum\ntheory. However, other models, such as perturbed lattice models, strongly\nRayleigh measures, zeros of random functions have gained salience in various\nlearning applications. In this article, we review this burgeoning field of\nresearch, as it has developed over the past two decades or so. We also present\nnew results on applications of DPPs to the parsimonious representation of\nneural networks. In the limited scope of the article, we mostly focus on\naspects of this area to which the authors contributed over the recent years,\nincluding applications to Monte Carlo methods, coresets and stochastic gradient\ndescent, stochastic networks, signal processing and connections to quantum\ncomputation. However, starting from basics of negative dependence for the\nuninitiated reader, extensive references are provided to a broad swath of\nrelated developments which could not be covered within our limited scope. While\nexisting works and reviews generally focus on specific negatively dependent\nmodels (e.g. DPPs), a notable feature of this article is that it addresses\nnegative dependence as a machine learning methodology as a whole. In this vein,\nit covers within its span an array of negatively dependent models and their\napplications well beyond DPPs, thereby putting forward a very general and\nrather unique perspective.", "comment": "Dedicated to the memory of Prof K.R. Parthasarathy: visionary, guru,\n  and scientist par excellence", "pdf_url": "http://arxiv.org/pdf/2502.07285v2", "cate": "stat.ML", "date": "2025-02-11", "updated": "2025-07-26"}
{"id": "2502.10335", "title": "Studying number theory with deep learning: a case study with the Möbius and squarefree indicator functions", "authors": ["David Lowry-Duda"], "categories": ["math.NT", "cs.LG"], "primary_category": "Subjects:       Number Theory (math.NT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.10335v2", "summary": "Building on work of Charton, we train small transformer models to calculate\nthe M\\\"{o}bius function $\\mu(n)$ and the squarefree indicator function\n$\\mu^2(n)$. The models attain nontrivial predictive power. We apply a mixture\nof additional models and feature scoring to give a theoretical explanation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.10335v2", "cate": "math.NT", "date": "2025-02-14", "updated": "2025-07-25"}
{"id": "2503.05602", "title": "On the similarity of bandwidth-tuned quantum kernels and classical kernels", "authors": ["Roberto Flórez-Ablan", "Marco Roth", "Jan Schnabel"], "categories": ["quant-ph", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      9 main pages with 5 figures, and 9 appendix pages with 12 figures. Added reference to GitHub where code for reproduction is availabe; corrected typos; article in QST", "url": "http://arxiv.org/abs/2503.05602v3", "summary": "Quantum kernels (QK) are widely used in quantum machine learning\napplications; yet, their potential to surpass classical machine learning\nmethods on classical datasets remains uncertain. This limitation can be\nattributed to the exponential concentration phenomenon, which can impair\ngeneralization. A common strategy to alleviate this is bandwidth tuning, which\ninvolves rescaling data points in the quantum model to improve generalization.\nIn this work, we numerically demonstrate that optimal bandwidth tuning results\nin QKs that closely resemble radial basis function (RBF) kernels, leading to a\nlack of quantum advantage over classical methods. Moreover, we reveal that the\nsize of optimal bandwidth tuning parameters further simplifies QKs, causing\nthem to behave like polynomial kernels, corresponding to a low-order Taylor\napproximation of a RBF kernel. We thoroughly investigate this for fidelity\nquantum kernels and projected quantum kernels using various data encoding\ncircuits across several classification datasets. We provide numerical evidence\nand derive a simple analytical model that elucidates how bandwidth tuning\ninfluences key quantities in classification tasks. Overall, our findings shed\nlight on the mechanisms that render QK methods classically tractable.", "comment": "9 main pages with 5 figures, and 9 appendix pages with 12 figures.\n  Added reference to GitHub where code for reproduction is availabe; corrected\n  typos; article in QST", "pdf_url": "http://arxiv.org/pdf/2503.05602v3", "cate": "quant-ph", "date": "2025-03-07", "updated": "2025-07-28"}
{"id": "2503.16123", "title": "Distributed Learning over Arbitrary Topology: Linear Speed-Up with Polynomial Transient Time", "authors": ["Runze You", "Shi Pu"], "categories": ["math.OC", "cs.LG"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.16123v2", "summary": "We study a distributed learning problem in which $n$ agents, each with\npotentially heterogeneous local data, collaboratively minimize the sum of their\nlocal cost functions via peer-to-peer communication. We propose a novel\nalgorithm, \\emph{Spanning Tree Push-Pull} (STPP), which employs two spanning\ntrees extracted from a general communication graph to distribute both model\nparameters and stochastic gradients. Unlike prior approaches that rely heavily\non spectral gap properties, STPP leverages a more flexible topological\ncharacterization, enabling robust information flow and efficient updates.\nTheoretically, we prove that STPP achieves linear speedup and polynomial\ntransient iteration complexity -- up to $\\mathcal{O}(n^7)$ for smooth nonconvex\nobjectives and $\\tilde{\\mathcal{O}}(n^3)$ for smooth strongly convex objectives\n-- under arbitrary network topologies. Moreover, compared with existing\nmethods, STPP achieves faster convergence rates on sparse and non-regular\ntopologies (e.g., directed rings) and reduces communication overhead on dense\nnetworks (e.g., static exponential graphs). Numerical experiments further\ndemonstrate the strong performance of STPP across various graph architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.16123v2", "cate": "math.OC", "date": "2025-03-20", "updated": "2025-07-27"}
{"id": "2504.17562", "title": "When Does Metadata Conditioning (NOT) Work for Language Model Pre-Training? A Study with Context-Free Grammars", "authors": ["Rei Higuchi", "Ryotaro Kawata", "Naoki Nishikawa", "Kazusato Oko", "Shoichiro Yamaguchi", "Sosuke Kobayashi", "Seiya Tokui", "Kohei Hayashi", "Daisuke Okanohara", "Taiji Suzuki"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.17562v2", "summary": "The ability to acquire latent semantics is one of the key properties that\ndetermines the performance of language models. One convenient approach to\ninvoke this ability is to prepend metadata (e.g. URLs, domains, and styles) at\nthe beginning of texts in the pre-training data, making it easier for the model\nto access latent semantics before observing the entire text. Previous studies\nhave reported that this technique actually improves the performance of trained\nmodels in downstream tasks; however, this improvement has been observed only in\nspecific downstream tasks, without consistent enhancement in average next-token\nprediction loss. To understand this phenomenon, we closely investigate how\nprepending metadata during pre-training affects model performance by examining\nits behavior using artificial data. Interestingly, we found that this approach\nproduces both positive and negative effects on the downstream tasks. We\ndemonstrate that the effectiveness of the approach depends on whether latent\nsemantics can be inferred from the downstream task's prompt. Specifically,\nthrough investigations using data generated by probabilistic context-free\ngrammars, we show that training with metadata helps improve model's performance\nwhen the given context is long enough to infer the latent semantics. In\ncontrast, the technique negatively impacts performance when the context lacks\nthe necessary information to make an accurate posterior inference.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.17562v2", "cate": "cs.CL", "date": "2025-04-24", "updated": "2025-07-27"}
{"id": "2505.14699", "title": "Benchmarking Graph Neural Networks for Document Layout Analysis in Public Affairs", "authors": ["Miguel Lopez-Duran", "Julian Fierrez", "Aythami Morales", "Ruben Tolosana", "Oscar Delgado-Mohatar", "Alvaro Ortigosa"], "categories": ["cs.CV", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      15 pages, 2 figures, accepted paper at The Fifth ICDAR International Workshop on Machine Learning", "url": "http://arxiv.org/abs/2505.14699v2", "summary": "The automatic analysis of document layouts in digital-born PDF documents\nremains a challenging problem due to the heterogeneous arrangement of textual\nand nontextual elements and the imprecision of the textual metadata in the\nPortable Document Format. In this work, we benchmark Graph Neural Network (GNN)\narchitectures for the task of fine-grained layout classification of text blocks\nfrom digital native documents. We introduce two graph construction structures:\na k-closest-neighbor graph and a fully connected graph, and generate node\nfeatures via pre-trained text and vision models, thus avoiding manual feature\nengineering. Three experimental frameworks are evaluated: single-modality (text\nor visual), concatenated multimodal, and dual-branch multimodal. We evaluated\nfour foundational GNN models and compared them with the baseline. Our\nexperiments are specifically conducted on a rich dataset of public affairs\ndocuments that includes more than 20 sources (e.g., regional and national-level\nofficial gazettes), 37K PDF documents, with 441K pages in total. Our results\ndemonstrate that GraphSAGE operating on the k-closest-neighbor graph in a\ndual-branch configuration achieves the highest per-class and overall accuracy,\noutperforming the baseline in some sources. These findings confirm the\nimportance of local layout relationships and multimodal fusion exploited\nthrough GNNs for the analysis of native digital document layouts.", "comment": "15 pages, 2 figures, accepted paper at The Fifth ICDAR International\n  Workshop on Machine Learning", "pdf_url": "http://arxiv.org/pdf/2505.14699v2", "cate": "cs.CV", "date": "2025-05-12", "updated": "2025-07-28"}
{"id": "2505.17860", "title": "Multi-Person Interaction Generation from Two-Person Motion Priors", "authors": ["Wenning Xu", "Shiyu Fan", "Paul Henderson", "Edmond S. L. Ho"], "categories": ["cs.GR", "cs.CV", "cs.LG", "I.3.7"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      SIGGRAPH 2025 Conference Papers, project page at this http URL", "url": "http://arxiv.org/abs/2505.17860v2", "summary": "Generating realistic human motion with high-level controls is a crucial task\nfor social understanding, robotics, and animation. With high-quality MOCAP data\nbecoming more available recently, a wide range of data-driven approaches have\nbeen presented. However, modelling multi-person interactions still remains a\nless explored area. In this paper, we present Graph-driven Interaction\nSampling, a method that can generate realistic and diverse multi-person\ninteractions by leveraging existing two-person motion diffusion models as\nmotion priors. Instead of training a new model specific to multi-person\ninteraction synthesis, our key insight is to spatially and temporally separate\ncomplex multi-person interactions into a graph structure of two-person\ninteractions, which we name the Pairwise Interaction Graph. We thus decompose\nthe generation task into simultaneous single-person motion generation\nconditioned on one other's motion. In addition, to reduce artifacts such as\ninterpenetrations of body parts in generated multi-person interactions, we\nintroduce two graph-dependent guidance terms into the diffusion sampling\nscheme. Unlike previous work, our method can produce various high-quality\nmulti-person interactions without having repetitive individual motions.\nExtensive experiments demonstrate that our approach consistently outperforms\nexisting methods in reducing artifacts when generating a wide range of\ntwo-person and multi-person interactions.", "comment": "SIGGRAPH 2025 Conference Papers, project page at\n  http://wenningxu.github.io/multicharacter/", "pdf_url": "http://arxiv.org/pdf/2505.17860v2", "cate": "cs.GR", "date": "2025-05-23", "updated": "2025-07-26"}
{"id": "2505.22518", "title": "IGNIS: A Robust Neural Network Framework for Constrained Parameter Estimation in Archimedean Copulas", "authors": ["Agnideep Aich"], "categories": ["stat.ML", "cs.LG", "62H05, 62H12, 62F10, 68T07, 62-08"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Under review", "url": "http://arxiv.org/abs/2505.22518v3", "summary": "Classical estimators, the cornerstones of statistical inference, face\ninsurmountable challenges when applied to important emerging classes of\nArchimedean copulas. These models exhibit pathological properties, including\nnumerically unstable densities, non-monotonic parameter-to-dependence mappings,\nand vanishingly small likelihood gradients, rendering methods like Maximum\nLikelihood (MLE) and Method of Moments (MoM) inconsistent or computationally\ninfeasible. We introduce IGNIS, a unified neural estimation framework that\nsidesteps these barriers by learning a direct, robust mapping from data-driven\ndependency measures to the underlying copula parameter theta. IGNIS utilizes a\nmulti-input architecture and a theory-guided output layer (softplus(z) + 1) to\nautomatically enforce the domain constraint theta_hat >= 1. Trained and\nvalidated on four families (Gumbel, Joe, and the numerically challenging\nA1/A2), IGNIS delivers accurate and stable estimates for real-world financial\nand health datasets, demonstrating its necessity for reliable inference in\nmodern, complex dependence models where traditional methods fail.", "comment": "Under review", "pdf_url": "http://arxiv.org/pdf/2505.22518v3", "cate": "stat.ML", "date": "2025-05-28", "updated": "2025-07-28"}
{"id": "2506.00022", "title": "Scaling Physical Reasoning with the PHYSICS Dataset", "authors": ["Shenghe Zheng", "Qianjia Cheng", "Junchi Yao", "Mengsong Wu", "Haonan He", "Ning Ding", "Yu Cheng", "Shuyue Hu", "Lei Bai", "Dongzhan Zhou", "Ganqu Cui", "Peng Ye"], "categories": ["cs.CL", "cs.LG", "physics.ed-ph"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Work on physical datasets", "url": "http://arxiv.org/abs/2506.00022v3", "summary": "Large Language Models (LLMs) have achieved remarkable progress on advanced\nreasoning tasks such as mathematics and coding competitions. Meanwhile,\nphysics, despite being both reasoning-intensive and essential to real-world\nunderstanding, received limited academic and industrial attention. This paper\nintroduces PHYSICS, a dataset containing 16,568 high-quality physics problems\nspanning subjects and difficulty levels, to facilitate this issue.\nSpecifically, PHYSICS is curated with exercises from over 100 textbooks through\na carefully designed pipeline for quality control. It covers five major physics\ndomains: Mechanics, Electromagnetism, Thermodynamics, Optics, and Modern\nPhysics. It also spans a wide range of difficulty levels, from high school to\ngraduate-level physics courses. To utilize the data for improving and\nevaluating the model's physical reasoning capabilities, we split the dataset\ninto training and test sets, and provide reasoning paths generated by powerful\nreasoning models for the training data to facilitate model training. In\naddition, for the evaluation part, we find that existing evaluation frameworks\nexhibit biases in aspects such as units, simplification, and precision in\nphysics domain. To balance efficiency and accuracy, we introduce a Rule+Model\nevaluation framework tailored to physics problems. Our evaluations on current\nstate-of-the-art open-source and proprietary models highlight the limitations\nof current models in handling physics-related tasks. We hope that our dataset\nand evaluation methodology will jointly advance the development of LLMs in the\nfield of physics.", "comment": "Work on physical datasets", "pdf_url": "http://arxiv.org/pdf/2506.00022v3", "cate": "cs.CL", "date": "2025-05-21", "updated": "2025-07-28"}
{"id": "2506.02394", "title": "Joint modeling for learning decision-making dynamics in behavioral experiments", "authors": ["Yuan Bian", "Xingche Guo", "Yuanjia Wang"], "categories": ["stat.ME", "cs.LG"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.02394v2", "summary": "Major depressive disorder (MDD), a leading cause of disability and mortality,\nis associated with reward-processing abnormalities and concentration issues.\nMotivated by the probabilistic reward task from the Establishing Moderators and\nBiosignatures of Antidepressant Response in Clinical Care (EMBARC) study, we\npropose a novel framework that integrates the reinforcement learning (RL) model\nand drift-diffusion model (DDM) to jointly analyze reward-based decision-making\nwith response times. To account for emerging evidence suggesting that\ndecision-making may alternate between multiple interleaved strategies, we model\nlatent state switching using a hidden Markov model (HMM). In the ''engaged''\nstate, decisions follow an RL-DDM, simultaneously capturing reward processing,\ndecision dynamics, and temporal structure. In contrast, in the ''lapsed''\nstate, decision-making is modeled using a simplified DDM, where specific\nparameters are fixed to approximate random guessing with equal probability. The\nproposed method is implemented using a computationally efficient generalized\nexpectation-maximization (EM) algorithm with forward-backward procedures.\nThrough extensive numerical studies, we demonstrate that our proposed method\noutperforms competing approaches across various reward-generating\ndistributions, under both strategy-switching and non-switching scenarios, as\nwell as in the presence of input perturbations. When applied to the EMBARC\nstudy, our framework reveals that MDD patients exhibit lower overall engagement\nthan healthy controls and experience longer decision times when they do engage.\nAdditionally, we show that neuroimaging measures of brain activities are\nassociated with decision-making characteristics in the ''engaged'' state but\nnot in the ''lapsed'' state, providing evidence of brain-behavior association\nspecific to the ''engaged'' state.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.02394v2", "cate": "stat.ME", "date": "2025-06-03", "updated": "2025-07-28"}
{"id": "2506.11981", "title": "Learning Before Filtering: Real-Time Hardware Learning at the Detector Level", "authors": ["Boštjan Maček"], "categories": ["hep-ex", "cs.LG"], "primary_category": "Subjects:       High Energy Physics - Experiment (hep-ex)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.11981v2", "summary": "Advances in sensor technology and automation have ushered in an era of data\nabundance, where the ability to identify and extract relevant information in\nreal time has become increasingly critical. Traditional filtering approaches,\nwhich depend on a priori knowledge, often struggle to adapt to dynamic or\nunanticipated data features. Machine learning offers a compelling\nalternative-particularly when training can occur directly at or near the\ndetector. This paper presents a digital hardware architecture designed for\nreal-time neural network training, specifically optimized for high-throughput\ndata ingestion. The design is described in an implementation-independent\nmanner, with detailed analysis of each architectural component and their\nperformance implications. Through system parameterization, the study explores\ntrade-offs between processing speed, model complexity, and hardware resource\nutilization. Practical examples illustrate how these parameters affect\napplicability across various use cases. A proof-of-concept implementation on an\nFPGA demonstrates in-situ training, confirming that computational accuracy is\npreserved relative to conventional software-based approaches. Moreover,\nresource estimates indicate that current-generation FPGAs can train networks of\napproximately 3,500 neurons per chip. The architecture is both scalable and\nadaptable, representing a significant advancement toward integrating learning\ndirectly within detector systems and enabling a new class of extreme-edge,\nreal-time information processing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.11981v2", "cate": "hep-ex", "date": "2025-06-13", "updated": "2025-07-28"}
{"id": "2506.19075", "title": "First-Order Sparse Convex Optimization: Better Rates with Sparse Updates", "authors": ["Dan Garber"], "categories": ["math.OC", "cs.LG"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.19075v2", "summary": "In was recently established that for convex optimization problems with a\nsparse optimal solution (may it be entry-wise sparsity or matrix rank-wise\nsparsity) it is possible to have linear convergence rates which depend on an\nimproved mixed-norm condition number of the form $\\frac{\\beta_1{}s}{\\alpha_2}$,\nwhere $\\beta_1$ is the $\\ell_1$-Lipchitz continuity constant of the gradient,\n$\\alpha_2$ is the $\\ell_2$-quadratic growth constant, and $s$ is the sparsity\nof the optimal solution. However, beyond the improved convergence rate, these\nmethods are unable to leverage the sparsity of optimal solutions towards\nimproving also the runtime of each iteration, which may still be prohibitively\nhigh for high-dimensional problems. In this work, we establish that linear\nconvergence rates which depend on this improved condition number can be\nobtained using only sparse updates, which may result in overall significantly\nimproved running times. Moreover, our methods are considerably easier to\nimplement.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.19075v2", "cate": "math.OC", "date": "2025-06-23", "updated": "2025-07-27"}
{"id": "2506.20056", "title": "Machine-Learning-Assisted Photonic Device Development: A Multiscale Approach from Theory to Characterization", "authors": ["Yuheng Chen", "Alexander Montes McNeil", "Taehyuk Park", "Blake A. Wilson", "Vaishnavi Iyer", "Michael Bezick", "Jae-Ik Choi", "Rohan Ojha", "Pravin Mahendran", "Daksh Kumar Singh", "Geetika Chitturi", "Peigang Chen", "Trang Do", "Alexander V. Kildishev", "Vladimir M. Shalaev", "Michael Moebius", "Wenshan Cai", "Yongmin Liu", "Alexandra Boltasseva"], "categories": ["physics.optics", "cs.LG"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.20056v2", "summary": "Photonic device development (PDD) has achieved remarkable success in\ndesigning and implementing new devices for controlling light across various\nwavelengths, scales, and applications, including telecommunications, imaging,\nsensing, and quantum information processing. PDD is an iterative, five-step\nprocess that consists of: i) deriving device behavior from design parameters,\nii) simulating device performance, iii) finding the optimal candidate designs\nfrom simulations, iv) fabricating the optimal device, and v) measuring device\nperformance. Classically, all these steps involve Bayesian optimization,\nmaterial science, control theory, and direct physics-driven numerical methods.\nHowever, many of these techniques are computationally intractable, monetarily\ncostly, or difficult to implement at scale. In addition, PDD suffers from large\noptimization landscapes, uncertainties in structural or optical\ncharacterization, and difficulties in implementing robust fabrication\nprocesses. However, the advent of machine learning over the past decade has\nprovided novel, data-driven strategies for tackling these challenges, including\nsurrogate estimators for speeding up computations, generative modeling for\nnoisy measurement modeling and data augmentation, reinforcement learning for\nfabrication, and active learning for experimental physical discovery. In this\nreview, we present a comprehensive perspective on these methods to enable\nmachine-learning-assisted PDD (ML-PDD) for efficient design optimization with\npowerful generative models, fast simulation and characterization modeling under\nnoisy measurements, and reinforcement learning for fabrication. This review\nwill provide researchers from diverse backgrounds with valuable insights into\nthis emerging topic, fostering interdisciplinary efforts to accelerate the\ndevelopment of complex photonic devices and systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.20056v2", "cate": "physics.optics", "date": "2025-06-24", "updated": "2025-07-26"}
{"id": "2507.01397", "title": "Coherent Online Road Topology Estimation and Reasoning with Standard-Definition Maps", "authors": ["Khanh Son Pham", "Christian Witte", "Jens Behley", "Johannes Betz", "Cyrill Stachniss"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at IROS 2025", "url": "http://arxiv.org/abs/2507.01397v2", "summary": "Most autonomous cars rely on the availability of high-definition (HD) maps.\nCurrent research aims to address this constraint by directly predicting HD map\nelements from onboard sensors and reasoning about the relationships between the\npredicted map and traffic elements. Despite recent advancements, the coherent\nonline construction of HD maps remains a challenging endeavor, as it\nnecessitates modeling the high complexity of road topologies in a unified and\nconsistent manner. To address this challenge, we propose a coherent approach to\npredict lane segments and their corresponding topology, as well as road\nboundaries, all by leveraging prior map information represented by commonly\navailable standard-definition (SD) maps. We propose a network architecture,\nwhich leverages hybrid lane segment encodings comprising prior information and\ndenoising techniques to enhance training stability and performance.\nFurthermore, we facilitate past frames for temporal consistency. Our\nexperimental evaluation demonstrates that our approach outperforms previous\nmethods by a large margin, highlighting the benefits of our modeling scheme.", "comment": "Accepted at IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.01397v2", "cate": "cs.CV", "date": "2025-07-02", "updated": "2025-07-28"}
{"id": "2507.11441", "title": "Implementing Adaptations for Vision AutoRegressive Model", "authors": ["Kaif Shaikh", "Franziska Boenisch", "Adam Dziedzic"], "categories": ["cs.CV", "cs.LG", "I.2.6; I.5.1; I.4.8; I.2.10"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at DIG-BUGS: Data in Generative Models Workshop @ ICML 2025", "url": "http://arxiv.org/abs/2507.11441v2", "summary": "Vision AutoRegressive model (VAR) was recently introduced as an alternative\nto Diffusion Models (DMs) in image generation domain. In this work we focus on\nits adaptations, which aim to fine-tune pre-trained models to perform specific\ndownstream tasks, like medical data generation. While for DMs there exist many\ntechniques, adaptations for VAR remain underexplored. Similarly, differentially\nprivate (DP) adaptations-ones that aim to preserve privacy of the adaptation\ndata-have been extensively studied for DMs, while VAR lacks such solutions. In\nour work, we implement and benchmark many strategies for VAR, and compare them\nto state-of-the-art DM adaptation strategies. We observe that VAR outperforms\nDMs for non-DP adaptations, however, the performance of DP suffers, which\nnecessitates further research in private adaptations for VAR. Code is available\nat https://github.com/sprintml/finetuning_var_dp.", "comment": "Accepted at DIG-BUGS: Data in Generative Models Workshop @ ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.11441v2", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-28"}
{"id": "2507.13710", "title": "SoftPipe: A Soft-Guided Reinforcement Learning Framework for Automated Data Preparation", "authors": ["Jing Chang", "Chang Liu", "Jinbin Huang", "Shuyuan Zheng", "Rui Mao", "Jianbin Qin"], "categories": ["cs.DB", "cs.LG"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13710v2", "summary": "Data preparation is a foundational yet notoriously challenging component of\nthe machine learning lifecycle, characterized by a vast combinatorial search\nspace. While reinforcement learning (RL) offers a promising direction,\nstate-of-the-art methods suffer from a critical limitation: to manage the\nsearch space, they rely on rigid ``hard constraints'' that prematurely prune\nthe search space and often preclude optimal solutions. To address this, we\nintroduce SoftPipe, a novel RL framework that replaces these constraints with a\nflexible ``soft guidance'' paradigm. SoftPipe formulates action selection as a\nBayesian inference problem. A high-level strategic prior, generated by a Large\nLanguage Model (LLM), probabilistically guides exploration. This prior is\ncombined with empirical estimators from two sources through a collaborative\nprocess: a fine-grained quality score from a supervised Learning-to-Rank (LTR)\nmodel and a long-term value estimate from the agent's Q-function. Through\nextensive experiments on 18 diverse datasets, we demonstrate that SoftPipe\nachieves up to a 13.9\\% improvement in pipeline quality and 2.8$\\times$ faster\nconvergence compared to existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13710v2", "cate": "cs.DB", "date": "2025-07-18", "updated": "2025-07-26"}
{"id": "2507.14491", "title": "Numerical Artifacts in Learning Dynamical Systems", "authors": ["Bing-Ze Lu", "Richard Tsai"], "categories": ["math.NA", "cs.LG", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14491v2", "summary": "In many applications, one needs to learn a dynamical system from its\nsolutions sampled at a finite number of time points. The learning problem is\noften formulated\n  as an optimization problem over a chosen function class. However, in the\noptimization procedure, it is necessary to employ a numerical scheme to\nintegrate candidate dynamical systems and assess how their solutions fit the\ndata.\n  This paper reveals potentially serious effects of a chosen numerical scheme\non the learning outcome. In particular, our analysis demonstrates that a damped\noscillatory system may be incorrectly identified as having \"anti-damping\" and\nexhibiting a reversed oscillation direction, despite adequately fitting the\ngiven data points.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14491v2", "cate": "math.NA", "date": "2025-07-19", "updated": "2025-07-26"}
{"id": "2507.16802", "title": "Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning", "authors": ["Yanjun Zheng", "Xiyang Du", "Longfei Liao", "Xiaoke Zhao", "Zhaowen Zhou", "Jingze Song", "Bo Zhang", "Jiawei Liu", "Xiang Qi", "Zhe Li", "Zhiqiang Zhang", "Wei Wang", "Peng Zhang"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.16802v4", "summary": "Large Language Models (LLMs) exhibit considerable promise in financial\napplications; however, prevailing models frequently demonstrate limitations\nwhen confronted with scenarios that necessitate sophisticated reasoning\ncapabilities, stringent trustworthiness criteria, and efficient adaptation to\ndomain-specific requirements. We introduce the Agentar-Fin-R1 series of\nfinancial large language models (8B and 32B parameters), specifically\nengineered based on the Qwen3 foundation model to enhance reasoning\ncapabilities, reliability, and domain specialization for financial\napplications. Our optimization approach integrates a high-quality, systematic\nfinancial task label system with a comprehensive multi-layered trustworthiness\nassurance framework. This framework encompasses high-quality trustworthy\nknowledge engineering, multi-agent trustworthy data synthesis, and rigorous\ndata validation governance. Through label-guided automated difficulty-aware\noptimization, tow-stage training pipeline, and dynamic attribution systems, we\nachieve substantial improvements in training efficiency. Our models undergo\ncomprehensive evaluation on mainstream financial benchmarks including Fineva,\nFinEval, and FinanceIQ, as well as general reasoning datasets such as MATH-500\nand GPQA-diamond. To thoroughly assess real-world deployment capabilities, we\ninnovatively propose the Finova evaluation benchmark, which focuses on\nagent-level financial reasoning and compliance verification. Experimental\nresults demonstrate that Agentar-Fin-R1 not only achieves state-of-the-art\nperformance on financial tasks but also exhibits exceptional general reasoning\ncapabilities, validating its effectiveness as a trustworthy solution for\nhigh-stakes financial applications. The Finova bench is available at\nhttps://github.com/antgroup/Finova.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.16802v4", "cate": "cs.CL", "date": "2025-07-22", "updated": "2025-07-27"}
