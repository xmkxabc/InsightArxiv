# AI-Enhanced arXiv Daily 2025-08-05

<a id='toc'></a>
## 今日总计: 715 篇论文
### 目录
- [cs.AI](#csai) (42 篇)
- [cs.AR](#csar) (2 篇)
- [cs.CC](#cscc) (1 篇)
- [cs.CE](#csce) (8 篇)
- [cs.CG](#cscg) (3 篇)
- [cs.CL](#cscl) (72 篇)
- [cs.CR](#cscr) (19 篇)
- [cs.CV](#cscv) (150 篇)
- [cs.CY](#cscy) (5 篇)
- [cs.DB](#csdb) (2 篇)
- [cs.DC](#csdc) (4 篇)
- [cs.DS](#csds) (6 篇)
- [cs.ET](#cset) (1 篇)
- [cs.GR](#csgr) (5 篇)
- [cs.GT](#csgt) (5 篇)
- [cs.HC](#cshc) (23 篇)
- [cs.IR](#csir) (9 篇)
- [cs.IT](#csit) (11 篇)
- [cs.LG](#cslg) (109 篇)
- [cs.LO](#cslo) (13 篇)
- [cs.MA](#csma) (2 篇)
- [cs.MM](#csmm) (2 篇)
- [cs.NE](#csne) (5 篇)
- [cs.NI](#csni) (19 篇)
- [cs.OS](#csos) (1 篇)
- [cs.PF](#cspf) (1 篇)
- [cs.PL](#cspl) (8 篇)
- [cs.RO](#csro) (38 篇)
- [cs.SC](#cssc) (2 篇)
- [cs.SD](#cssd) (5 篇)
- [cs.SE](#csse) (26 篇)
- [cs.SI](#cssi) (2 篇)
- [eess.AS](#eessas) (7 篇)
- [eess.IV](#eessiv) (10 篇)
- [eess.SP](#eesssp) (12 篇)
- [eess.SY](#eesssy) (11 篇)
- [math.NA](#mathna) (13 篇)
- [stat.AP](#statap) (3 篇)
- [q-fin.MF](#q-finmf) (1 篇)
- [quant-ph](#quant-ph) (11 篇)
- [econ.TH](#econth) (1 篇)
- [stat.ML](#statml) (6 篇)
- [physics.optics](#physicsoptics) (1 篇)
- [math.LO](#mathlo) (1 篇)
- [math.OC](#mathoc) (6 篇)
- [math.ST](#mathst) (2 篇)
- [stat.ME](#statme) (2 篇)
- [math.CO](#mathco) (3 篇)
- [q-fin.RM](#q-finrm) (1 篇)
- [q-bio.QM](#q-bioqm) (2 篇)
- [q-bio.NC](#q-bionc) (1 篇)
- [hep-ph](#hep-ph) (3 篇)
- [math.PR](#mathpr) (2 篇)
- [physics.soc-ph](#physicssoc-ph) (2 篇)
- [math.FA](#mathfa) (1 篇)
- [physics.ed-ph](#physicsed-ph) (1 篇)
- [physics.flu-dyn](#physicsflu-dyn) (2 篇)
- [math.HO](#mathho) (1 篇)
- [physics.comp-ph](#physicscomp-ph) (1 篇)
- [gr-qc](#gr-qc) (1 篇)
- [cond-mat.stat-mech](#cond-matstat-mech) (1 篇)
- [q-fin.TR](#q-fintr) (1 篇)
- [math.NT](#mathnt) (1 篇)
- [math.CT](#mathct) (1 篇)
- [physics.chem-ph](#physicschem-ph) (1 篇)
- [physics.plasm-ph](#physicsplasm-ph) (1 篇)

---
<a id='csai'></a>
## cs.AI 

### [6] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
> *R1-ACT：通过激活安全知识实现高效推理模型安全对齐*

*Yeonjun In, Wonjoong Kim, Sangwu Park, Chanyoung Park* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 大型推理模型, 安全对齐, 知识激活, 后训练, R1-Act

**Comment:** under review

> **TL;DR:** R1-ACT是一种高效的后训练方法，通过激活安全知识来提高大型推理模型的安全性，同时保持推理性能，并且训练成本低。

**AI_Comments:** R1-Act的创新之处在于其洞察力——模型并非缺乏安全知识，而是未能激活。这种“激活”而非“注入”的思路，使得其方法在效率和资源消耗上具有显著优势，尤其体现在极低的训练数据和时间需求上，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型推理模型（LRMs）在复杂任务上表现出色，但经常执行有害用户指令，引发严重安全问题。本研究旨在探究LRM安全风险的根本原因，并发现模型拥有足够安全知识但未能激活。

**Method:** 基于模型已具备安全知识但未能激活的发现，本文提出了R1-Act，一个简单高效的后训练方法，通过结构化推理过程显式触发安全知识。

**Result:** R1-Act在保持推理性能的同时，显著提升了模型安全性，优于先前的对齐方法。它仅需1,000个训练样本和90分钟的单张RTX A6000 GPU训练时间。在多个LRM骨干网络和规模上的广泛实验证明了该方法的鲁棒性、可扩展性和实用效率。

**Conclusion:** R1-Act通过激活大型推理模型中已有的安全知识，有效解决了模型执行有害指令的问题，显著提高了模型安全性，且具有高效率和低成本。

> **ai_Abstract:** 本文提出R1-Act，一种新颖高效的后训练方法，旨在解决大型推理模型（LRMs）的安全问题。研究发现LRMs已具备安全知识但未能有效激活。R1-Act通过结构化推理过程显式激活这些安全知识，从而显著提升模型安全性，同时保持推理性能，并展现出低训练成本和高效率，超越现有对齐方法。

> **摘要翻译:** 尽管大型推理模型（LRMs）在复杂任务上表现出令人印象深刻的能力，但最近的研究表明，这些模型经常执行有害的用户指令，引发了严重的安全担忧。在本文中，我们调查了LRM安全风险的根本原因，发现模型已经拥有足够的安全知识，但在推理过程中未能激活。基于这一见解，我们提出了R1-Act，一种简单高效的后训练方法，通过结构化推理过程显式触发安全知识。R1-Act在保持推理性能的同时实现了强大的安全改进，优于先前的对齐方法。值得注意的是，它仅需要1,000个训练样本和单张RTX A6000 GPU上90分钟的训练时间。在多个LRM骨干网络和尺寸上的广泛实验证明了我们方法的鲁棒性、可扩展性和实用效率。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [19] [CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding](https://arxiv.org/abs/2508.00378)
> *CoRGI：带有视觉基础的验证链式思维推理*

*Shixin Yi, Lin Shang* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 链式思维, 视觉基础, 视觉-语言模型, 推理验证, 多模态推理

**Comment:** Preparing for AAAI 2026, Multimodal Reasoning

> **TL;DR:** CoRGI是一个模块化框架，通过引入视觉验证来解决视觉-语言模型中链式思维推理的幻觉问题，从而生成更扎实、更可信的解释和答案。

**AI_Comments:** CoRGI的创新之处在于其引入了显式的视觉验证机制，解决了链式思维在视觉-语言模型中常出现的“幻觉”问题。其模块化设计允许与现有VLM无缝集成，降低了应用门槛。通过将视觉基础融入中间推理步骤，显著提升了推理的准确性和解释的事实性。这项工作对于提高多模态AI的可信度和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉-语言模型（VLMs）中的链式思维（CoT）推理虽然在语言上流畅，但常常缺乏视觉内容的支撑，导致出现幻觉。这主要是因为在多步推理过程中缺乏明确的验证机制。

**Method:** 本文提出了CoRGI（Chain of Reasoning with Grounded Insights）框架。CoRGI遵循三阶段流程：首先生成文本推理链，然后通过专门的视觉证据验证模块（VEVM）为每个推理步骤提取支持性视觉证据，最后将文本推理与视觉证据结合，生成扎实、经过验证的答案。该框架可以与现有VLM集成，无需端到端再训练。

**Result:** CoRGI在VCR基准上进行了评估，结果显示它改进了两种代表性开源VLM骨干（Qwen-2.5VL和LLaVA-1.6）的推理性能。消融研究证实了验证模块中每个步骤的贡献，并且人工评估表明CoRGI能产生更真实、更有帮助的解释。研究还探讨了视觉验证步骤的其他设计，并讨论了事后验证框架的潜在局限性。

**Conclusion:** 研究结果强调了将中间推理步骤扎根于视觉证据的重要性，以增强多模态推理的鲁棒性。

> **ai_Abstract:** 本文提出了CoRGI框架，旨在解决视觉-语言模型中链式思维推理缺乏视觉基础导致幻觉的问题。CoRGI通过三阶段流程，首先生成文本推理链，然后提取视觉证据进行验证，最后结合两者生成扎实答案。该框架无需重新训练即可与现有VLM集成，并在VCR基准上验证了其在Qwen-2.5VL和LLaVA-1.6上的推理性能提升。研究强调了视觉证据对多模态推理鲁棒性的重要性。

> **摘要翻译:** 链式思维（CoT）提示在改善视觉-语言模型（VLMs）的推理方面显示出前景，但它通常产生的解释在语言上流畅却缺乏视觉内容的支撑。我们观察到，这种幻觉部分源于多步推理过程中缺乏明确的验证机制。为了解决这个问题，我们提出了CoRGI（Chain of Reasoning with Grounded Insights），一个模块化框架，将视觉验证引入推理过程。CoRGI遵循三阶段流程：它首先生成一个文本推理链，然后通过专门的模块（VEVM）为每个推理步骤提取支持性视觉证据，最后将文本理由与视觉证据综合，生成一个扎实、经过验证的答案。该框架可以与现有VLM集成，无需端到端再训练。我们在VCR基准上评估了CoRGI，发现它提高了两种代表性开源VLM骨干（Qwen-2.5VL和LLaVA-1.6）的推理性能。消融研究证实了验证模块中每个步骤的贡献，并且人工评估表明CoRGI能产生更真实、更有帮助的解释。我们还研究了视觉验证步骤的替代设计，并讨论了事后验证框架的潜在局限性。这些发现强调了将中间推理步骤扎根于视觉证据的重要性，以增强多模态推理的鲁棒性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [37] [Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation](https://arxiv.org/abs/2508.00401)
> *使用主动推理的心智理论：一个多智能体合作框架*

*Riddhi J. Pitliya, Ozan Catal, Toon Van de Maele, Corrado Pezzato, Tim Verbelen* | **Category: cs.AI, cs.MA** | **Updated: 2025-08-01**

**Keywords:** 心智理论, 主动推理, 多智能体合作, 递归推理, 行为推断

**Comment:** 

> **TL;DR:** 本文提出了一种在主动推理中实现心智理论（ToM）的新方法，以促进多智能体合作，该方法无需共享生成模型或显式通信，通过推断他人的可观察行为来提高合作效率。

**AI_Comments:** 这项研究的创新之处在于将心智理论整合到主动推理框架中，并克服了传统方法对共享模型或显式通信的依赖，使其更具通用性和实用性。通过仅从可观察行为推断他人信念，该方法为多智能体合作提供了一种高效且更接近生物认知的解决方案，对于推动人工智能在复杂协作任务中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的活跃推理多智能体合作方法通常依赖于任务特定的共享生成模型或需要显式通信。本文旨在提出一种更通用且不依赖这些条件的多智能体合作方法。

**Method:** 作者在活跃推理框架内实现了心智理论（ToM），使智能体能够维护自己和他人信念与目标的独立表示。他们扩展了复杂的推理树状规划算法，通过递归推理系统地探索联合策略空间。该方法通过碰撞避免和觅食任务模拟进行评估，并且智能体仅通过可观察行为推断他人的信念。

**Result:** 实验结果表明，与非ToM智能体相比，配备ToM的智能体表现出更好的合作能力，能够有效避免碰撞并减少冗余工作。ToM智能体通过仅从可观察行为推断他人的信念来达到这一效果。

**Conclusion:** 这项工作通过在活跃推理中实现心智理论，推动了多智能体合作的实际应用，同时为心智理论提供了计算洞察。ToM智能体能够仅通过观察行为推断他人的信念，从而实现更有效的合作。

> **ai_Abstract:** 本文提出了一种在主动推理框架内实现心智理论（ToM）以促进多智能体合作的新方法。该方法通过让智能体维护自身和他人信念的独立表示，并扩展推理树状规划算法来探索联合策略空间，从而避免了对共享生成模型和显式通信的依赖。实验结果表明，与非ToM智能体相比，ToM智能体在碰撞避免和觅食任务中表现出更优的合作能力，且仅通过观察行为即可推断他人信念，从而减少冗余并提高效率。

> **摘要翻译:** 我们提出了一种通过在主动推理中实现心智理论（ToM）来促进多智能体合作的新方法。心智理论——理解他人可能拥有不同知识和目标的能力——使智能体在规划自身行动时能够推断他人的信念。与以往的主动推理多智能体合作方法不同，我们的方法既不依赖于任务特定的共享生成模型，也不需要显式通信，同时具有通用性。在我们的框架中，配备ToM的智能体维护着自己和他人信念与目标的独立表示。我们扩展了复杂的基于推理树的规划算法，通过递归推理系统地探索联合策略空间。我们的方法通过碰撞避免和觅食任务模拟进行了评估。结果表明，与非ToM对手相比，配备ToM的智能体通过能够避免碰撞和减少冗余工作而表现出更好的合作。至关重要的是，ToM智能体通过仅从可观察行为推断他人的信念来完成这一点。这项工作推动了人工智能的实际应用，同时为ToM提供了计算见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [67] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
> *Cognitive Kernel-Pro：一个用于深度研究智能体和智能体基础模型训练的框架*

*Tianqing Fang, Zhisong Zhang, Xiaoyang Wang, Rui Wang, Can Qin, Yuxuan Wan, Jun-Yu Ma, Ce Zhang, Jiaqi Chen, Xiyun Li, Hongming Zhang, Haitao Mi, Dong Yu* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** AI智能体, 开源, 基础模型, 数据整理, 反射, 投票

**Comment:** 16 pages

> **TL;DR:** Cognitive Kernel-Pro是一个开源免费的多模块AI智能体框架，旨在通过高质量数据训练和新策略提升智能体性能，并在GAIA上实现了SOTA。

**AI_Comments:** 这项工作通过提出一个完全开源且免费的AI智能体框架，在促进AI研究的民主化方面具有重要意义。其创新之处在于不仅提供了一个多模块框架，还系统地研究了高质量训练数据的构建方法，并引入了测试时反射和投票等新策略来提升智能体性能和鲁棒性。在GAIA基准测试中取得的最先进结果，特别是其80亿参数模型超越了现有领先系统，进一步凸显了该框架的实用性和高性能。

<details>
  <summary>Details</summary>

**Motivation:** 当前AI智能体系统多为闭源或依赖付费API和专有工具，限制了研究社区的可访问性和可复现性。

**Method:** 1. 提出Cognitive Kernel-Pro，一个完全开源、免费的多模块智能体框架。2. 系统地研究了智能体基础模型高质量训练数据的整理，包括在网络、文件、代码和通用推理四个关键领域构建查询、轨迹和可验证答案。3. 探索了智能体测试时反射和投票的新策略，以增强智能体的鲁棒性和性能。

**Result:** 1. 在GAIA上评估了Cognitive Kernel-Pro，在开源和免费智能体中取得了最先进的结果。2. 其80亿参数的开源模型超越了WebDancer和WebSailor等现有领先系统。3. 为可访问、高性能的AI智能体建立了新的性能标准。

**Conclusion:** Cognitive Kernel-Pro通过其开源和高性能的特性，为可访问、高能力的AI智能体设定了新的性能标准，有助于AI智能体开发和评估的民主化。

> **ai_Abstract:** 本研究介绍了Cognitive Kernel-Pro，一个开源免费的多模块AI智能体框架，旨在解决当前智能体系统闭源和高成本的问题，从而促进高级AI智能体的开发和评估的民主化。该框架系统性地探讨了智能体基础模型高质量训练数据的整理方法，涵盖网络、文件、代码和通用推理四个领域的数据构建，并引入了测试时反射和投票等新策略以提升智能体性能。在GAIA上的评估显示，Cognitive Kernel-Pro在开源和免费智能体中达到了最先进的水平，其80亿参数模型甚至超越了WebDancer和WebSailor等领先系统，为高性能且易于访问的AI智能体树立了新标准。

> **摘要翻译:** 通用AI智能体正日益被认为是下一代人工智能的基础框架，能够实现复杂的推理、网络交互、编码和自主研究能力。然而，当前的智能体系统要么是闭源的，要么严重依赖各种付费API和专有工具，这限制了研究社区的可访问性和可复现性。在这项工作中，我们提出了\textbf{Cognitive Kernel-Pro}，一个完全开源且（最大程度上）免费的多模块智能体框架，旨在使高级AI智能体的开发和评估民主化。在Cognitive Kernel-Pro中，我们系统地研究了智能体基础模型高质量训练数据的整理，重点关注在网络、文件、代码和通用推理四个关键领域构建查询、轨迹和可验证答案。此外，我们探索了智能体测试时反射和投票的新策略，以增强智能体的鲁棒性和性能。我们在GAIA上评估了Cognitive Kernel-Pro，在开源和免费智能体中取得了最先进的结果。值得注意的是，我们的80亿参数开源模型超越了WebDancer和WebSailor等之前的领先系统，为可访问、高性能的AI智能体建立了新的性能标准。代码可在https://github.com/Tencent/CognitiveKernel-Pro 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [91] [Thinking Machines: Mathematical Reasoning in the Age of LLMs](https://arxiv.org/abs/2508.00459)
> *思维机器：LLMs时代的数学推理*

*Andrea Asperti, Alberto Naibo, Claudio Sacerdoti Coen* | **Category: cs.AI, 68T07, 68T20, I.2.6; I.2.7; I.2.3** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 数学推理, 形式化证明, 代码合成, 逻辑状态

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）在编码和结构化推理方面表现出色，但在形式化数学（尤其是定理证明）方面进展缓慢。本文探讨了LLMs在数学推理中的现状、挑战及未来方向，特别是形式与非形式数学的权衡、证明生成比代码合成更脆弱的原因，以及LLMs是否真正代表逻辑状态。

**AI_Comments:** 这篇论文通过探讨LLMs在数学推理，特别是形式化证明方面的挑战，提供了一个重要的视角。它超越了简单的性能评估，深入探讨了LLMs“推理”能力的本质、监督方式以及内部状态跟踪等基础性问题。对于理解LLMs的深层机制及其在复杂认知任务中的局限性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** LLMs在编程和结构化推理方面取得了显著成功，引发了将LLMs应用于数学领域的兴趣。然而，在形式化数学（特别是定理证明）方面的进展却远低于预期，这引发了关于LLMs如何“推理”、如何被监督以及是否内部跟踪计算/演绎状态的重要问题。

**Method:** 本文回顾了该领域的最新进展，重点关注近期模型和基准测试，并探讨了机器学习与数学认知交叉领域的三个核心问题：(i) 形式化数学和非形式化数学作为训练领域之间的权衡；(ii) 证明生成比代码合成更脆弱的深层原因；(iii) 以及LLMs是否代表或仅仅模仿了演化逻辑状态的概念。

**Result:** Not mentioned in abstract

**Conclusion:** 目标是识别当前LLMs在数学推理中的局限性，以及如何扩展这些局限，而不是划定明确的界限。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在数学推理领域的应用现状与挑战。尽管LLMs在代码生成等结构化任务中表现出色，但在形式化数学证明方面却面临显著困难。文章分析了这种差异背后的原因，并深入探讨了形式与非形式数学作为训练领域的权衡、证明生成比代码合成更脆弱的深层原因，以及LLMs是否真正理解并跟踪逻辑状态等核心问题。旨在识别并探讨当前LLMs在数学推理能力上的局限性及其潜在的扩展方向。

> **摘要翻译:** 大型语言模型（LLMs）在结构化推理和符号任务中表现出卓越的能力，其中编码成为一个特别的优势领域。这一成功激发了人们将LLMs应用于数学的日益增长的兴趣，无论是非形式化问题解决还是形式化定理证明。然而，尽管编程和证明构建之间存在表面相似性，但形式化数学的进展已被证明要困难得多。这种差异引出了关于LLMs如何“推理”、它们如何被监督以及它们是否内部跟踪计算或演绎状态的重要问题。在本文中，我们讨论了该学科的最新技术水平，重点关注了最近的模型和基准测试，并探讨了机器学习和数学认知交叉领域的三个核心问题：(i) 形式化数学和非形式化数学作为训练领域之间的权衡；(ii) 证明生成为何比代码合成更脆弱的深层原因；(iii) 以及LLMs是否代表，或者仅仅模仿了演化逻辑状态的概念。我们的目标不是划定严格的界限，而是识别当前的局限性在哪里，以及如何扩展它们。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [115] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
> *Pro2Guard：通过概率模型检测主动运行时强化LLM代理安全性*

*Haoyu Wang, Chris M. Poskitt, Jun Sun, Jiali Wei* | **Category: cs.AI, cs.SE** | **Updated: 2025-08-01**

**Keywords:** LLM代理安全, 运行时强化, 概率模型检测, 主动干预, DTMC

**Comment:** 

> **TL;DR:** Pro2Guard通过概率模型检测，主动预测和干预大型语言模型代理的潜在不安全行为，而非被动响应。

**AI_Comments:** Pro2Guard的创新之处在于其从反应式安全机制转向主动式预测和干预。通过引入概率模型检测和学习DTMC，它能够对LLM代理的未来行为进行量化风险评估，这对于处理LLM的随机性和长时依赖性至关重要。其在多个安全关键领域的出色表现，特别是提前预测能力，突显了其在提升LLM代理可靠性方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）代理的随机行为带来了难以预测的重大安全风险。现有基于规则的系统是反应性的，缺乏预见性，且难以处理长时依赖和分布变化。

**Method:** 我们提出了Pro2Guard，一个基于概率可达性分析的主动运行时强化框架。它将代理行为抽象为符号状态，并从执行轨迹中学习离散时间马尔可夫链（DTMC）。在运行时，通过估计到达不安全状态的概率来预测未来风险，当预测风险超过用户定义阈值时，在违规发生前触发干预。Pro2Guard通过语义有效性检查和PAC界限确保统计可靠性。

**Result:** 在具身家庭代理任务中，Pro2Guard使用低阈值时能提前对高达93.6%的不安全任务执行安全干预，同时通过可配置模式（如反射）保持高达80.4%的任务完成率。在自动驾驶场景中，Pro2Guard实现了100%的交通法规违规和碰撞预测，提前38.66秒预测风险。

**Conclusion:** Pro2Guard提供了一种有效且可靠的方法，通过主动预测和干预来增强LLM代理的运行时安全性，显著优于传统的反应式系统。

> **ai_Abstract:** Pro2Guard是一个主动运行时强化框架，旨在解决大型语言模型（LLM）代理的随机行为带来的安全风险。该框架利用概率可达性分析，通过从执行轨迹学习离散时间马尔可夫链（DTMC）来抽象代理行为并预测未来风险。当预测到不安全状态的概率超过阈值时，Pro2Guard会在违规发生前进行干预。实验结果表明，在具身代理和自动驾驶场景中，Pro2Guard能有效提前预测并规避不安全行为，显著提高了LLM代理的安全性。

> **摘要翻译:** 大型语言模型（LLM）代理在机器人、虚拟助手和网络自动化等领域展现出强大的自主能力。然而，它们的随机行为带来了难以预测的重大安全风险。现有的基于规则的强化系统，如AgentSpec，侧重于开发反应性安全规则，通常只在不安全行为即将发生或已经发生时才响应。这些系统缺乏预见性，且难以处理长时依赖和分布变化。为了解决这些限制，我们提出了Pro2Guard，一个基于概率可达性分析的主动运行时强化框架。Pro2Guard将代理行为抽象为符号状态，并从执行轨迹中学习离散时间马尔可夫链（DTMC）。在运行时，它通过估计到达不安全状态的概率来预测未来风险，当预测风险超过用户定义阈值时，在违规发生前触发干预。通过结合语义有效性检查和利用PAC界限，Pro2Guard在近似底层真实模型的同时确保了统计可靠性。我们在两个安全关键领域：具身家庭代理和自动驾驶中广泛评估了Pro2Guard。在具身代理任务中，Pro2Guard使用低阈值时能提前对高达93.6%的不安全任务执行安全干预，同时通过可配置模式（如反射）保持高达80.4%的任务完成率。在自动驾驶场景中，Pro2Guard实现了100%的交通法规违规和碰撞预测，提前38.66秒预测风险。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [137] [MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models](https://arxiv.org/abs/2508.00576)
> *MultiSHAP：一种基于Shapley的框架，用于解释多模态AI模型中的跨模态交互*

*Zhanliang Wang, Kai Wang* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** 多模态AI, 模型解释性, Shapley值, 跨模态交互, 可信赖AI

**Comment:** 

> **TL;DR:** MultiSHAP是一个基于Shapley的框架，用于解释多模态AI模型中细粒度的跨模态交互，适用于开源和闭源模型。

**AI_Comments:** 这篇论文提出了一种创新性的方法MultiSHAP，通过引入Shapley交互指数来精确量化多模态AI模型中细粒度的跨模态交互，解决了现有解释方法无法量化协同效应且受限于开源模型的问题。其模型无关性使其适用范围更广，包括对闭源模型的解释，这在实际部署中具有重要意义。提供实例级和数据集级解释也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 多模态AI模型性能出色，但其“黑箱”性质阻碍了在高风险应用中的部署，因为解释性和可信度至关重要。解释跨模态交互是一个主要挑战，现有方法无法精确量化协同效应且受限于开源模型。

**Method:** 提出了MultiSHAP，一个模型无关的解释性框架。它利用Shapley交互指数将多模态预测归因于细粒度视觉和文本元素（如图像块和文本标记）之间的成对交互。该方法适用于开源和闭源模型，并提供实例级和数据集级解释。

**Result:** 在公共多模态基准上的实验证实MultiSHAP忠实地捕获了跨模态推理机制，真实世界案例研究证明了其实用性。

**Conclusion:** MultiSHAP提供了一个通用的解决方案，用于解释复杂的多模态AI模型，能够忠实地捕捉跨模态推理机制并具有实用价值，且可扩展到两个以上模态。

> **ai_Abstract:** MultiSHAP是一个新颖的模型无关解释性框架，旨在解决多模态AI模型中跨模态交互的“黑箱”问题。它利用Shapley交互指数，能够量化细粒度视觉和文本元素间的成对交互，并提供实例级和数据集级解释。MultiSHAP适用于开源及闭源模型，并通过实验验证了其在捕获跨模态推理机制和实际应用中的有效性。该框架为解释复杂的多模态AI模型提供了一个通用且可扩展的解决方案。

> **摘要翻译:** 多模态人工智能模型在需要整合来自多个模态（如视觉和语言）信息的任务中取得了令人印象深刻的性能。然而，它们的“黑箱”性质对在高风险应用中的部署构成了主要障碍，因为在这些应用中，可解释性和可信度至关重要。如何解释多模态人工智能模型中的跨模态交互仍然是一个重大挑战。尽管现有的模型解释方法，如注意力图和Grad-CAM，对跨模态关系提供了粗略的洞察，但它们无法精确量化模态间的协同效应，并且仅限于内部权重可访问的开源模型。在此，我们引入了MultiSHAP，一个模型无关的解释性框架，它利用Shapley交互指数将多模态预测归因于细粒度视觉和文本元素（如图像块和文本标记）之间的成对交互，同时适用于开源和闭源模型。我们的方法提供：（1）实例级解释，揭示单个样本的协同和抑制性跨模态效应——“为什么模型对这个输入做出特定预测”，以及（2）数据集级解释，揭示跨样本的普遍交互模式——“模型如何整合跨模态信息”。在公共多模态基准上的实验证实MultiSHAP忠实地捕获了跨模态推理机制，而真实世界案例研究证明了其实用性。我们的框架可扩展到两个以上的模态，为解释复杂的多模态人工智能模型提供了一个通用解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [152] [From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation](https://arxiv.org/abs/2508.00581)
> *从EMR数据到临床洞察：一个LLM驱动的自动化会诊前问卷生成框架*

*Ruiqing Ding, Qianfang Sun, Yongkang Leng, Hui Yin, Xiaojian Li* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** EMR, LLM, 会诊前问卷, 自动化生成, 临床洞察

**Comment:** 16 pages, 10 figures

> **TL;DR:** 提出一个多阶段LLM框架，从EMR数据自动化生成个性化会诊前问卷，克服了直接LLM方法的局限性，并提高了信息覆盖率和诊断相关性。

**AI_Comments:** 该论文提出了一种创新的多阶段LLM框架，通过显式构建临床知识，克服了直接LLM在处理复杂EMR数据时遇到的信息完整性和逻辑性问题。其将原子信息提取、知识网络构建与问卷生成相结合的方法，提高了会诊前问卷的质量和效率，具有重要的临床应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 会诊前是有效医疗服务的一个关键组成部分。然而，从复杂、海量的电子病历（EMR）中生成全面的会诊前问卷是一项具有挑战性的任务。直接的大型语言模型（LLM）方法在此任务中面临信息完整性、逻辑顺序和疾病层面综合的困难。

**Method:** 本文提出一个新颖的多阶段LLM驱动框架：第一阶段从EMR中提取原子断言（带有时间的关键事实）；第二阶段通过聚类EMR语料库中的代表性网络来构建个人因果网络并综合疾病知识；第三阶段基于这些结构化表示生成量身定制的个人和标准化疾病特异性问卷。该框架通过构建明确的临床知识克服了直接方法的局限性。

**Result:** 在真实世界的EMR数据集上进行评估并由临床专家验证，该方法在信息覆盖率、诊断相关性、可理解性和生成时间方面表现出卓越的性能。

**Conclusion:** 该框架具有增强患者信息收集的实际潜力。

> **ai_Abstract:** 本文提出一个新颖的多阶段LLM驱动框架，旨在解决从复杂EMR数据中自动化生成全面会诊前问卷的挑战。该框架首先从EMR中提取关键事实，然后构建个人因果网络并综合疾病知识，最后生成个性化和标准化的问卷。通过构建明确的临床知识，该方法克服了直接LLM方法的局限性，并在信息覆盖率、诊断相关性、可理解性和生成时间方面表现出优越性能，展示了其在提升患者信息收集方面的实际应用潜力。

> **摘要翻译:** 会诊前是有效医疗服务的一个关键组成部分。然而，从复杂、海量的电子病历（EMR）中生成全面的会诊前问卷是一项具有挑战性的任务。直接的大型语言模型（LLM）方法在此任务中面临困难，特别是在信息完整性、逻辑顺序和疾病层面综合方面。为了解决这个问题，我们提出了一种新颖的多阶段LLM驱动框架：第一阶段从EMR中提取原子断言（带有时间的关键事实）；第二阶段通过聚类EMR语料库中的代表性网络来构建个人因果网络并综合疾病知识；第三阶段基于这些结构化表示生成量身定制的个人和标准化疾病特异性问卷。该框架通过构建明确的临床知识克服了直接方法的局限性。在真实世界的EMR数据集上进行评估并由临床专家验证，我们的方法在信息覆盖率、诊断相关性、可理解性和生成时间方面表现出卓越的性能，突出了其增强患者信息收集的实际潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [167] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
> *多智能体游戏生成与评估通过音视频记录*

*Alexia Jolicoeur-Martineau* | **Category: cs.AI, cs.MA, cs.MM** | **Updated: 2025-08-01**

**Keywords:** 交互式内容生成, 多智能体系统, 音视频评估, 游戏生成, AVR-Eval

**Comment:** 

> **TL;DR:** 论文提出了AVR-Eval度量和AVR-Agent多智能体系统，用于生成和评估交互式音视频内容（如游戏），解决了现有AI在复杂内容生成和自动评估上的不足，但发现当前模型难以有效利用高级素材和音视频反馈。

**AI_Comments:** 这篇论文的创新点在于提出了一个用于交互式音视频内容（特别是游戏）的自动化评估度量AVR-Eval，以及一个能够迭代生成和优化代码的多智能体系统AVR-Agent。它解决了现有LLM在复杂内容生成和评估方面的局限性。然而，论文也指出了一个重要的限制：当前的AI模型未能有效利用高质量的音视频资产和反馈，这表明AI在理解和利用多模态信息进行创造性任务方面仍有进步空间，与人类的创作方式存在根本差异。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI在生成交互式音视频内容（如视频游戏）方面面临挑战，缺乏自动化评估指标，并且难以处理通常需要人类团队工作数月的多智能体复杂内容。

**Method:** 提出AVR-Eval，一种使用音视频记录（AVRs）的多媒体内容质量的相对度量，通过全模态模型比较AVRs。构建AVR-Agent，一个多智能体系统，从多媒体资产库生成JavaScript代码，并利用AVR-Eval进行迭代改进。

**Result:** AVR-Eval能够有效识别良好、损坏或不匹配的内容。AVR-Agent生成的内容在对抗一次性生成的内容时具有显著更高的胜率。然而，模型未能有效利用自定义资产和AVR反馈，未显示出更高的胜率。

**Conclusion:** 当前的编码模型未能像人类一样有效利用高质量资产和音视频反馈，这突显了人类和机器内容创作方法之间的根本差异。

> **ai_Abstract:** 本文旨在解决AI在生成交互式音视频内容（如游戏）时面临的挑战，包括缺乏自动化评估和处理复杂多智能体内容的能力。为此，研究团队提出了AVR-Eval，一个基于音视频记录（AVRs）的多媒体内容质量相对度量，并构建了AVR-Agent，一个利用多媒体资产库和AVR-Eval进行迭代改进的JavaScript游戏生成多智能体系统。实验结果表明，AVR-Agent生成的内容优于一次性生成，但当前模型在有效利用自定义资产和音视频反馈方面存在不足，揭示了人机内容创作方法的差异。

> **摘要翻译:** 尽管人工智能在生成文本、音频、图像和视频方面表现出色，但创建交互式音视频内容（如视频游戏）仍然具有挑战性。当前的LLM可以生成JavaScript游戏和动画，但缺乏自动化评估指标，并且难以处理通常需要人类团队工作数月（多镜头、多智能体）并使用艺术家制作的资产才能完成的复杂内容。为了解决这些问题，我们构建了一个新的度量标准和一个多智能体系统。
我们提出了AVR-Eval，这是一种使用音视频记录（AVRs）的多媒体内容质量的相对度量。一个全模态模型（处理文本、视频和音频）比较两种内容的AVRs，并通过文本模型审查评估以确定优劣。我们表明AVR-Eval能够正确识别良好、损坏或不匹配的内容。
我们构建了AVR-Agent，一个多智能体系统，可以从多媒体资产库（音频、图像、3D模型）生成JavaScript代码。编码智能体选择相关资产，生成多个初始代码，使用AVR-Eval识别最佳版本，并通过来自AVR的全模态智能体反馈迭代改进它。
我们使用AVR-Eval（内容A对内容B的胜率）对游戏和动画进行了实验。我们发现AVR-Agent生成的内容在对抗一次性生成的内容时具有显著更高的胜率。然而，模型难以有效利用自定义资产和AVR反馈，未显示出更高的胜率。这揭示了一个关键的差距：虽然人类受益于高质量资产和音视频反馈，但当前的编码模型似乎未能有效利用这些资源，这突显了人类和机器内容创作方法之间的根本差异。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [184] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
> *多频带可变滞后格兰杰因果关系：一个用于跨频率因果时间序列推断的统一框架*

*Chakattrai Sookkongwaree, Tattep Lakmuang, Chainarong Amornbunchornvej* | **Category: cs.AI, cs.LG, econ.EM, stat.ME** | **Updated: 2025-08-01**

**Keywords:** 格兰杰因果关系, 时间序列, 因果推断, 可变滞后, 多频带

**Comment:** First draft

> **TL;DR:** 本文提出了多频带可变滞后格兰杰因果关系（MB-VLGC），这是一个用于跨频率因果时间序列推断的统一框架，它能够处理因果关系在时间延迟和频率带上的变化，并在实验中表现出优越的性能。

**AI_Comments:** 本文的创新之处在于统一了格兰杰因果关系中的可变滞后和多频带考量，解决了现有方法的一个重要局限性。其在神经科学和经济学等多个领域的适用性，对于复杂系统中更真实的因果推断具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的格兰杰因果关系存在固定的滞后假设，这在复杂系统中往往不切实际。虽然可变滞后格兰杰因果关系（VLGC）解决了时间滞后变化的问题，但它未能考虑到因果相互作用也可能在不同频带上变化。因此，需要一个能够同时处理时间延迟和频率带变化的因果推断框架。

**Method:** 本文形式化了多频带可变滞后格兰杰因果关系（MB-VLGC），并提出了一个新颖的框架，通过明确建模频率依赖的因果延迟来推广传统的VLGC。研究提供了MB-VLGC的正式定义，证明了其理论健全性，并提出了一个高效的推理管道。

**Result:** 在多个领域进行的广泛实验表明，该框架在合成和真实世界数据集上都显著优于现有方法。

**Conclusion:** MB-VLGC框架通过在实验中超越现有方法，并解决了先前格兰杰因果关系在可变滞后和频率依赖方面的局限性，证实了其对任何类型时间序列数据的广泛适用性。

> **ai_Abstract:** 本文介绍了多频带可变滞后格兰杰因果关系（MB-VLGC），这是一个用于因果时间序列推断的新框架。它扩展了传统的格兰杰因果关系和可变滞后格兰杰因果关系（VLGC），通过明确建模在时间滞后和频率带上变化的因果延迟。所提出的MB-VLGC框架经过正式定义，具有理论健全性，并包含一个高效的推理管道。在合成和真实世界数据上的实验表明，它显著优于现有方法，证明了其广泛适用性。

> **摘要翻译:** 理解时间序列中的因果关系是许多领域的基础，包括神经科学、经济学和行为科学。格兰杰因果关系是时间序列中推断因果关系的著名技术之一。通常，格兰杰因果关系框架在因果之间存在强烈的固定滞后假设，这在复杂系统中往往是不现实的。虽然最近关于可变滞后格兰杰因果关系（VLGC）的工作通过允许原因在每个时间点以不同的时间滞后影响结果来解决这一限制，但它未能考虑到因果相互作用不仅可能在时间延迟上变化，而且可能在不同频带上变化。例如，在脑信号中，α波段活动可能比较慢的δ波段振荡以更短的延迟影响另一个区域。在这项工作中，我们形式化了多频带可变滞后格兰杰因果关系（MB-VLGC），并提出了一个新颖的框架，通过明确建模频率依赖的因果延迟来推广传统的VLGC。我们提供了MB-VLGC的正式定义，证明了其理论健全性，并提出了一个高效的推理管道。在多个领域进行的广泛实验表明，我们的框架在合成和真实世界数据集上都显著优于现有方法，证实了其对任何类型时间序列数据的广泛适用性。代码和数据集已公开可用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [188] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
> *通过数据中心多模态可解释人工智能实现透明自适应学习*

*Maryam Mosleh, Marie Devlin, Ellis Solaiman* | **Category: cs.AI, cs.HC, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 自适应学习, 可解释人工智能, 透明度, 多模态, 个性化

**Comment:** 

> **TL;DR:** 本文提出了一种混合框架，旨在通过结合传统可解释人工智能技术与生成式人工智能模型及用户个性化，为自适应学习系统提供透明且以用户为中心的解释。

**AI_Comments:** 本文的创新之处在于其提出的混合框架，它超越了传统可解释人工智能的局限性，将生成式AI和用户个性化融入解释生成过程。这对于提升AI在教育领域的透明度和用户接受度具有重要意义。通过重新定义可解释性为动态沟通，论文强调了以用户为中心的设计理念，这在实际应用中非常关键。然而，由于是概念性框架，其具体实施细节和效果仍有待进一步的研究和验证。

<details>
  <summary>Details</summary>

**Motivation:** 当前的AI驱动自适应学习系统缺乏透明度，用户难以理解决策过程。此外，大多数可解释人工智能（XAI）技术只关注技术输出，忽视了用户角色和理解。

**Method:** 本文提出了一种混合框架，该框架将传统的可解释人工智能技术与生成式人工智能模型和用户个性化相结合，以生成多模态、个性化的解释，从而满足用户需求。文章将可解释性重新定义为一种根据用户角色和学习目标量身定制的动态沟通过程，并概述了该框架的设计、教育领域中可解释人工智能的主要局限性，以及关于准确性、公平性和个性化的研究方向。

**Result:** Not mentioned in abstract

**Conclusion:** 论文旨在推动可解释人工智能的发展，使其在增强透明度的同时支持以用户为中心的体验。

> **ai_Abstract:** 本文针对当前AI驱动自适应学习系统缺乏透明度以及现有可解释人工智能（XAI）技术未能充分考虑用户理解的问题，提出了一种创新的混合框架。该框架整合了传统XAI技术、生成式AI模型和用户个性化，旨在生成多模态、个性化的解释。作者将可解释性定义为动态沟通过程，并探讨了其在教育领域的应用、局限性及未来研究方向，以期实现更透明、以用户为中心的自适应学习体验。

> **摘要翻译:** 人工智能驱动的自适应学习系统通过数据驱动的学习体验调整正在重塑教育。然而，许多此类系统缺乏透明度，对决策过程的洞察力有限。大多数可解释人工智能（XAI）技术侧重于技术输出，却忽视了用户角色和理解。本文提出了一种混合框架，该框架将传统的可解释人工智能技术与生成式人工智能模型和用户个性化相结合，以生成多模态、个性化的解释，从而满足用户需求。我们将可解释性重新定义为一种根据用户角色和学习目标量身定制的动态沟通过程。我们概述了该框架的设计、教育领域中可解释人工智能的关键局限性，以及关于准确性、公平性和个性化的研究方向。我们的目标是迈向既能增强透明度又能支持以用户为中心体验的可解释人工智能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [212] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
> *社交媒体中可解释AI推荐的上下文感知可视化：一项以用户为中心解释的愿景*

*Banan Alkhateeb, Ellis Solaiman* | **Category: cs.AI, cs.HC, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 可解释AI, 社交媒体, 上下文感知, 可视化, 用户对齐

**Comment:** 

> **TL;DR:** 本文提出了一种上下文感知和用户细分的可视化解释系统，旨在提高社交媒体中AI推荐的可解释性。

**AI_Comments:** 本文提出了一种创新的方法来解决社交媒体中AI推荐解释性不足的问题，其独特之处在于首次在一个单一管道中同时考虑解释的风格和粒度，以适应不同用户的需求。这是一个重要的研究方向，有望显著提升用户对AI系统的信任度和满意度。

<details>
  <summary>Details</summary>

**Motivation:** 当前社交媒体平台上的AI推荐因用户不理解其背后的原因而失去价值，因为解释性通常过于笼统且未能与用户具体需求对齐。

**Method:** 本文提出了一种用户细分和上下文感知的解释层，通过一个具有多种解释方法的可视化解释系统来实现。该系统根据用户需求和上下文的不同，以多种可视化形式展示解释，包括针对AI专家的技术详细版本和针对普通用户的简化版本。该框架首次在一个单一管道中同时调整解释风格（可视化 vs. 数字）和粒度（专家 vs. 普通用户）。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本愿景论文针对社交媒体中AI推荐解释性不足的问题，提出了一种上下文感知和用户细分的可视化解释系统。该系统旨在通过提供适应用户需求和上下文的多种解释形式（包括技术详细版和简化版），来提高用户对AI推荐的理解和信任。该框架创新性地在一个管道中同时调整解释风格和粒度。

> **摘要翻译:** 当今的社交媒体平台致力于通过AI推荐来改善用户体验，然而，由于用户不理解其背后的原因，这些推荐的价值便消失了。这个问题之所以出现，是因为社交媒体中的解释性是普遍的，并且缺乏与用户特定需求的对齐。在这篇愿景论文中，我们通过提出一个具有多种解释方法的可视化解释系统，概述了一个用户细分和上下文感知的解释层。所提出的系统以用户需求和上下文的多样性为框架，以不同的可视化形式展示解释，包括针对AI专家的技术详细版本和针对普通用户的简化版本。我们的框架是第一个在单一管道中联合调整解释风格（可视化 vs. 数字）和粒度（专家 vs. 普通用户）的。一项针对30名X用户的公开试点将验证其对决策和信任的影响。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [232] [Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics](https://arxiv.org/abs/2508.00784)
> *揭示隐藏表征：一种多模态层分析，用于更好的合成内容取证*

*Tom Or, Omri Azencot* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** 合成内容检测, 多模态模型, 潜在表征, 深度伪造, 取证

**Comment:** 

> **TL;DR:** 当前虚假内容检测器泛化能力差。本文提出利用大型预训练多模态模型的潜在代码来检测跨模态的合成内容，以高效方式实现最先进的结果。

**AI_Comments:** 该论文的创新之处在于重新利用大型预训练多模态模型（通常用于其他任务）来检测合成内容，通过分析其隐藏表征。这种方法解决了先前方法在不同生成模型和数据模态之间泛化能力不足的关键限制。其效率和在少样本设置下的有效性也是重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 生成模型在图像和文本等领域取得显著成果，但被恶意用户利用传播虚假信息和深度伪造。现有虚假内容检测器泛化能力差，无法适应新的生成模型和数据模态，因此迫切需要鲁棒、稳定且通用的检测器。

**Method:** 本文提出使用大型预训练多模态模型的潜在代码来检测生成内容。研究表明这些模型的潜在代码能自然地捕获区分真实和虚假信息。在此基础上，通过在这些特征上训练线性分类器，主要关注音频和图像领域的虚假内容检测。

**Result:** 在预训练多模态模型特征上训练的线性分类器，在音频和图像等多种模态上实现了最先进的检测结果。该方法计算效率高、训练速度快，即使在少样本设置下也表现出色，性能超越或媲美强大的基线方法。

**Conclusion:** 大型预训练多模态模型的潜在表征可以与简单的线性分类器有效结合，构建出鲁棒、高效且通用性强的合成内容检测器，尤其在音频和图像领域，其性能优于现有方法。

> **ai_Abstract:** 本文针对先进生成模型产生的合成内容检测挑战（常被用于传播错误信息）提出解决方案。鉴于现有检测器在不同生成模型和数据类型间的泛化能力不足，作者提出利用大型预训练多模态模型。研究表明，这些模型的潜在表征能固有地区分真实与虚假内容。通过在这些特征上训练简单的线性分类器，在检测合成音频和图像方面取得了最先进的结果。该方法计算效率高、训练速度快，即使在数据有限的情况下也有效，超越了当前强大的基线方法。

> **摘要翻译:** 生成模型在图像和文本等多个数据领域取得了显著成果。不幸的是，恶意用户利用合成媒体传播错误信息和深度伪造。因此，对鲁棒和稳定的虚假内容检测器的需求日益迫切，尤其是在新生成模型层出不穷的情况下。尽管大多数现有工作训练分类器来区分真实和虚假信息，但此类工具通常仅在同一生成器家族和数据模态内泛化，在其他生成类别和数据领域表现不佳。为了实现通用分类器，我们建议使用大型预训练多模态模型来检测生成内容。我们有效地表明，这些模型的潜在代码自然地捕获了区分真实和虚假信息。基于这一观察，我们证明了在这些特征上训练的线性分类器可以在各种模态下实现最先进的结果，同时保持计算效率高、训练速度快，甚至在少样本设置中也有效。我们的工作主要侧重于音频和图像中的虚假内容检测，其性能超越或媲美强大的基线方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [245] [Identifying Unique Spatial-Temporal Bayesian Network without Markov Equivalence](https://arxiv.org/abs/2211.10085)
> *识别无马尔可夫等价的独特时空贝叶斯网络*

*Mingyu Kang, Duxin Chen, Ning Meng, Gang Yan, Wenwu Yu* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** 时空贝叶斯网络, 马尔可夫等价, 因果发现, 高阶因果熵, 信息传输

**Comment:** This manuscript is submitted to facilitate early access and encourage
  follow-up research by other scholars. The code for this work is available at:
  https://github.com/KMY-SEU/HCE. We sincerely thank you for your support!

> **TL;DR:** 本文提出了一种独特的时空贝叶斯网络（STBN）及其识别算法HCE，用于解决时空因果关系建模中马尔可夫等价问题，并取得了最先进的识别精度。

**AI_Comments:** 这项工作通过引入时空贝叶斯网络（STBN）及其高阶因果熵（HCE）算法，创新性地解决了时空因果关系建模中马尔可夫等价性导致的识别不唯一问题。通过理论证明STBN的唯一性并提出高效算法，该研究为复杂时空数据中的因果发现提供了重要工具，具有较高的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的贝叶斯网络在建模时空因果关系时，由于马尔可夫等价性，可能识别出不同的有向无环图。现有的有向循环图和全时图方法存在局限性，如不总是成立、无法建模动态时间序列过程、假设因果关系不随时间变化或无瞬时效应。

**Method:** 本文提出了一种时空贝叶斯网络（STBN）来从信息传输的角度建模时空因果关系。STBN通过信息路径阻塞原理解释了特定网络结构的消失，并证明了其唯一性。在此基础上，提出了一种高阶因果熵（HCE）算法，该算法能在时间复杂度$\\mathcal{O}(n^3\\tau_{max})$下唯一识别STBN。

**Result:** 数值实验结果表明，高阶因果熵（HCE）算法在识别准确性方面达到了最先进的水平。

**Conclusion:** 本文成功提出了独特的时空贝叶斯网络（STBN）及其高效识别算法高阶因果熵（HCE），有效解决了时空因果关系建模中的马尔可夫等价问题，并实现了高精度识别。

> **ai_Abstract:** 本文针对传统贝叶斯网络在时空因果关系建模中存在的马尔可夫等价问题及其现有解决方案的局限性，提出了一种独特的时空贝叶斯网络（STBN）。STBN从信息传输角度建模时空因果关系，并解释了信息路径阻塞现象，同时证明了其唯一性。为识别STBN，作者还提出了一种高阶因果熵（HCE）算法，该算法在理论上能唯一识别STBN，并在实验中展现出最先进的识别准确性。

> **摘要翻译:** 识别香草贝叶斯网络以建模时空因果关系可能是一项关键而具有挑战性的任务。如果无法满足可识别性，则会识别出不同的马尔可夫等价有向无环图。为了解决这个问题，提出了有向循环图以放弃有向无环约束。但它并非总是成立，并且无法建模动态时间序列过程。然后，通过引入高阶时间延迟提出了全时图。全时图通过假设没有瞬时效应而没有马尔可夫等价类。但是，它也假设因果关系随时间不变，这在时空场景中并不总是满足。因此，在这项工作中，提出了一种时空贝叶斯网络（STBN）从信息传输的角度理论上建模时空因果关系。STBN通过信息路径阻塞原理解释了网络结构$X\rightarrow Z \rightarrow Y$和$X\leftarrow Z \leftarrow Y$的消失。最后，证明了STBN的唯一性。在此基础上，还提出了一种高阶因果熵（HCE）算法，以在时间复杂度$\\mathcal{O}(n^3\\tau_{max})$下唯一识别STBN，其中$n$是变量的数量，$\\tau_{max}$是最大时间延迟。进行了数值实验并与其他基线算法进行了比较。结果表明，HCE算法获得了最先进的识别精度。代码可在https://github.com/KMY-SEU/HCE获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [274] [Federated Cross-Training Learners for Robust Generalization under Data Heterogeneity](https://arxiv.org/abs/2405.20046)
> *联邦交叉训练学习器在数据异构性下的鲁棒泛化*

*Zhuang Qi, Lei Meng, Ruohan Zhang, Yu Wang, Xin Qi, Xiangxu Meng, Han Yu, Qiang Yang* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** 联邦学习, 交叉训练, 数据异构性, 知识蒸馏, 特征增强

**Comment:** 

> **TL;DR:** 本文提出了FedCT，一个联邦交叉训练方案，通过多视角知识蒸馏和特征增强来解决联邦学习中数据异构性导致的模型未对齐问题，从而提高模型的泛化能力和鲁棒性。

**AI_Comments:** FedCT的创新点在于其多视角知识蒸馏和特征增强的结合，特别是将个性化和全局知识分别用于保留客户端特性和促进特征对齐。其模块化的设计思路清晰地解决了联邦学习中的核心挑战，即如何在数据异构性下实现鲁棒泛化。该方法对于提升联邦学习在实际应用中的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习中的交叉训练策略虽然能提高泛化能力，但由于数据分布差异，局部模型的优化目标仍然未对齐，导致特征空间异构性。现有方法未能充分利用个性化和全局知识进行特征对齐和知识保存。

**Method:** 本文提出了FedCT交叉训练方案，包含三个主要模块：1. 一致性感知知识广播模块：优化模型分配策略，增强客户端协作。2. 多视角知识引导表示学习模块：利用全局和局部原型知识，在模型交换前后增强局部知识的保存，并确保局部与全局知识的一致性。3. 基于Mixup的特征增强模块：聚合丰富信息，增加特征空间多样性，提高模型对复杂样本的辨别能力。

**Result:** 在四个数据集上进行了广泛实验，结果表明FedCT缓解了局部和全局视角的知识遗忘，并优于最先进的方法。

**Conclusion:** FedCT通过其独特的多视角知识蒸馏和特征增强机制，有效地解决了联邦学习中的数据异构性问题，提高了模型的鲁棒泛化能力，并在实验中取得了优于现有方法的性能。

> **ai_Abstract:** 本文提出了一种名为FedCT的联邦交叉训练方案，旨在解决联邦学习中数据异构性导致的特征空间未对齐问题。FedCT通过引入一致性感知知识广播、多视角知识引导的表示学习以及基于Mixup的特征增强三个核心模块，有效地整合了来自局部和全局视角的知识，并丰富了特征空间多样性。实验结果表明，FedCT能够有效缓解知识遗忘，并显著提升模型在数据异构环境下的泛化能力和鲁棒性，超越了现有最先进的方法。

> **摘要翻译:** 联邦学习受益于交叉训练策略，该策略使模型能够在不同来源的数据上进行训练，以提高泛化能力。然而，由于数据分布的固有差异，局部模型的优化目标仍然未对齐，并且这种不匹配即使在交叉训练后也继续表现为特征空间异构性。我们认为，来自个性化视角的知识蒸馏保留了客户端特定的特征并扩展了本地知识库，而来自全局视角的知识蒸馏提供了稳定语义锚点，有助于跨客户端的特征对齐。为了实现这一目标，本文提出了一种交叉训练方案，称为FedCT，它包括三个主要模块：其中一致性感知知识广播模块旨在优化模型分配策略，这增强了客户端之间的协作优势并实现了高效的联邦学习过程。多视角知识引导表示学习模块利用来自全局和局部视角的融合原型知识，在模型交换前后增强本地知识的保存，并确保本地和全局知识之间的一致性。基于Mixup的特征增强模块聚合了丰富的信息，进一步增加了特征空间的多样性，使模型能够更好地辨别复杂样本。在四个数据集上进行了关于性能比较、消融研究、深入分析和案例研究的广泛实验。结果表明，FedCT缓解了局部和全局视角的知识遗忘，这使其性能优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [304] [BCR-DRL: Behavior- and Context-aware Reward for Deep Reinforcement Learning in Human-AI Coordination](https://arxiv.org/abs/2408.07877)
> *BCR-DRL：面向人机协作中深度强化学习的行为和上下文感知奖励*

*Xin Hao, Bahareh Nakisa, Mohmmad Naim Rastgoo, Gaoyang Pang* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 深度强化学习, 人机协作, 稀疏奖励, 行为感知, 上下文感知

**Comment:** 

> **TL;DR:** BCR-DRL提出了一种行为和上下文感知的奖励机制，通过双重内在奖励和上下文感知加权来解决人机协作中深度强化学习的稀疏奖励和不可预测的人类行为问题，从而提高探索和利用效率。

**AI_Comments:** 该论文通过引入行为和上下文感知奖励，创新性地解决了人机协作中DRL的稀疏奖励和探索-利用困境，其双重内在奖励和上下文感知加权机制为提升人机协作AI性能提供了新思路。实验结果也验证了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习（DRL）在人机协作（HAIC）中面临两个关键挑战：稀疏奖励和不可预测的人类行为。这些挑战严重限制了DRL识别有效协作策略的能力，因为它损害了优化探索和利用的能力。

**Method:** 我们提出了一种创新的行为和上下文感知奖励（BCR）用于DRL，它通过利用HAIC中的人类行为和上下文信息来优化探索和利用。BCR由两部分组成：(i) 一种新颖的双重内在奖励方案，通过AI自我激励内在奖励和人类激励内在奖励来增强探索，旨在通过基于对数的策略增加稀疏奖励的捕获；(ii) 一种新的上下文感知加权机制，用于已设计的奖励以改善利用，该机制通过利用可以反映学习进化的上下文信息，帮助AI代理优先选择与人类伙伴更好地协作的行动。

**Result:** 在Overcooked环境中的广泛模拟表明，与最先进的基线相比，我们的方法可以使累积稀疏奖励增加约20%，样本效率提高约38%。

**Conclusion:** BCR-DRL通过引入行为和上下文感知奖励，有效解决了人机协作中深度强化学习的稀疏奖励和人类行为不可预测性问题，显著提高了性能和效率。

> **ai_Abstract:** 该论文提出了BCR-DRL，一种行为和上下文感知奖励机制，旨在解决人机协作中深度强化学习面临的稀疏奖励和不可预测的人类行为问题。BCR包含双重内在奖励方案以增强探索，以及上下文感知加权机制以改善利用。在Overcooked环境中的模拟结果显示，该方法能显著提高累积稀疏奖励和样本效率。

> **摘要翻译:** 深度强化学习（DRL）为训练AI代理与人类伙伴协调提供了一个强大的框架。然而，DRL在人机协作（HAIC）中面临两个关键挑战：稀疏奖励和不可预测的人类行为。这些挑战严重限制了DRL识别有效协作策略的能力，因为它损害了优化探索和利用的能力。为了解决这些限制，我们提出了一种创新的行为和上下文感知奖励（BCR）用于DRL，它通过利用HAIC中的人类行为和上下文信息来优化探索和利用。我们的BCR由两部分组成：(i) 一种新颖的双重内在奖励方案，用于增强探索。该方案由AI自我激励内在奖励和人类激励内在奖励组成，旨在通过基于对数的策略增加稀疏奖励的捕获；(ii) 一种新的上下文感知加权机制，用于已设计的奖励以改善利用。该机制通过利用可以反映学习进化的上下文信息，帮助AI代理优先选择与人类伙伴更好地协作的行动。在Overcooked环境中的广泛模拟表明，我们的方法可以使累积稀疏奖励增加约20%，样本效率提高约38%，与最先进的基线相比。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [334] [Causal Explanations for Image Classifiers](https://arxiv.org/abs/2411.08875)
> *图像分类器的因果解释*

*Hana Chockler, David A. Kelly, Daniel Kroening, Youcheng Sun* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 因果解释, 图像分类器, 黑盒方法, 实际因果关系, ReX

**Comment:** 

> **TL;DR:** 本文提出了一种基于实际因果理论的新型黑盒方法，用于计算图像分类器的解释，并实现了工具ReX，实验证明其效率更高且解释更小。

**AI_Comments:** 本文的创新之处在于首次将实际因果理论应用于图像分类器的解释生成，提供了一种原则性的黑盒方法。其重要性在于提升了解释的效率和质量，对于理解和信任AI模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像分类器解释算法缺乏基于原因和解释形式化定义的原则性方法。

**Method:** 本文提出了一种基于实际因果理论的新型黑盒方法来计算解释。作者证明了相关的理论结果，并提出了一个计算近似解释的算法，证明了算法的终止性，并讨论了其复杂性以及与精确定义相比的近似程度。该框架已在工具ReX中实现。

**Result:** 实验结果表明，ReX是最有效的工具，能够生成最小的解释，并且在标准质量测量方面优于其他黑盒工具。

**Conclusion:** 本文成功开发了一种基于实际因果理论的黑盒方法ReX，为图像分类器生成高效且高质量的因果解释。

> **ai_Abstract:** 本文提出了一种基于实际因果理论的新型黑盒方法，用于为图像分类器生成因果解释。该研究证明了相关理论结果，并开发了一个计算近似解释的算法，该算法在工具ReX中实现。实验证明，ReX比现有工具更高效，能产生更小的解释，并在质量指标上表现更优。

> **摘要翻译:** 现有图像分类器解释算法使用不同的解释定义和各种提取技术。然而，现有工具都没有使用基于原因和解释形式化定义的原则性方法进行解释提取。在本文中，我们提出了一种计算解释的新型黑盒方法，该方法以实际因果理论为基础。我们证明了相关的理论结果，并提出了一个基于这些定义的计算近似解释的算法。我们证明了算法的终止性，并讨论了其复杂性以及与精确定义相比的近似程度。我们将该框架实现在工具ReX中，并展示了实验结果以及与最先进工具的比较。我们证明了ReX是最有效的工具，能够生成最小的解释，此外还在标准质量测量方面优于其他黑盒工具。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [359] [OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problems with Reasoning LLM](https://arxiv.org/abs/2503.10009)
> *OR-LLM-Agent：利用推理LLM自动化运筹优化问题的建模与求解*

*Bowen Zhang, Pengcheng Luo, Genke Yang, Boon-Hee Soong, Chau Yuen* | **Category: cs.AI, math.OC** | **Updated: 2025-08-01**

**Keywords:** 运筹优化, LLM, AI代理, 任务分解, 自动化求解

**Comment:** 8 pages, 13 figures

> **TL;DR:** 提出OR-LLM-Agent框架，通过任务分解和推理LLM自动化运筹优化问题求解，并在新数据集BWOR上表现优异。

**AI_Comments:** OR-LLM-Agent通过任务分解和引入推理LLM，有效提升了运筹优化问题自动求解的能力。BWOR数据集的构建为更准确评估LLM在运筹任务上的表现提供了重要工具，弥补了现有基准的不足。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法通过提示工程或微调LLM解决运筹优化问题，但受限于非推理LLM的能力不足。

**Method:** 提出OR-LLM-Agent，一个基于推理LLM的AI代理框架，用于自动化运筹问题求解。该框架将任务分解为数学建模、代码生成和调试三个阶段，每个阶段由专用子代理处理。同时构建了用于评估LLM在运筹任务上表现的BWOR数据集。

**Result:** BWOR数据集在评估LLM运筹任务能力方面比现有基准更一致和有区分度。OR-LLM-Agent（使用DeepSeek-R1）在准确率上比包括GPT-o3、Gemini 2.5 Pro、DeepSeek-R1和ORLM在内的先进方法至少高7%。

**Conclusion:** 任务分解对于运筹问题求解是有效的，OR-LLM-Agent框架及其推理LLM表现出优越性。

> **ai_Abstract:** 本文提出OR-LLM-Agent，一个基于推理LLM的AI代理框架，用于自动化运筹优化问题的建模与求解。该框架通过将任务分解为数学建模、代码生成和调试三个子阶段，并为每个阶段配备专用子代理，以实现更具针对性的推理。研究构建了新的运筹数据集BWOR，并发现其在评估LLM能力方面更具一致性和区分度。实验结果表明，OR-LLM-Agent在结合DeepSeek-R1时，其准确率显著优于现有先进方法，证明了任务分解在解决运筹问题中的有效性。

> **摘要翻译:** 随着人工智能（AI）的兴起，将大型语言模型（LLMs）应用于数学问题求解吸引了越来越多的关注。大多数现有方法试图通过LLMs的提示工程或微调策略来改进运筹学（OR）优化问题的求解。然而，这些方法从根本上受限于非推理LLMs的有限能力。为了克服这些局限性，我们提出了OR-LLM-Agent，一个基于推理LLMs构建的AI代理框架，用于自动化OR问题求解。该框架将任务分解为三个顺序阶段：数学建模、代码生成和调试。每个任务由一个专门的子代理处理，这使得推理更具针对性。我们还构建了BWOR，一个用于评估LLM在OR任务上表现的OR数据集。我们的分析表明，在NL4OPT、MAMO和IndustryOR基准测试中，推理LLMs有时在同一模型家族中表现不如其非推理对应物。相比之下，BWOR提供了更一致和更具区分度的模型能力评估。实验结果表明，OR-LLM-Agent在其框架中利用DeepSeek-R1，在准确率上比包括GPT-o3、Gemini 2.5 Pro、DeepSeek-R1和ORLM在内的先进方法至少高7%。这些结果证明了任务分解对于OR问题求解的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [382] [BOOST: Bootstrapping Strategy-Driven Reasoning Programs for Program-Guided Fact-Checking](https://arxiv.org/abs/2504.02467)
> *BOOST：引导策略驱动的推理程序用于程序引导的事实核查*

*Qisheng Hu, Quanyu Long, Wenya Wang* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** 事实核查, 大语言模型, 程序引导推理, 少量样本学习, 自举

**Comment:** Work in Progress

> **TL;DR:** BOOST是一种自举方法，可以自动生成用于事实核查的少量样本推理程序，无需人工干预，并优于现有基线。

**AI_Comments:** BOOST的创新之处在于其自举策略和批判-改进循环，它有效地解决了程序引导事实核查中对人工制作演示的依赖，显著降低了人工成本。这种自动化生成高质量演示的能力，对于提升大语言模型在复杂推理任务中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型事实核查方法（尤其是程序引导推理）需要大量人工制作的少量样本演示，且有效推理程序生成的基本原理尚未得到充分探索。

**Method:** 本文引入了BOOST，这是一种用于自动化少量样本推理程序生成的自举方法。BOOST通过一个批判-改进循环，迭代地完善显式、数据驱动的指导方针作为元规则来指导演示创建，从而消除了人工干预。

**Result:** BOOST在复杂声明验证的零样本和少量样本设置中均优于先前的少量样本基线。

**Conclusion:** BOOST通过自动化演示创建，提升了解释性和有效性，实现了从零样本到少量样本程序引导学习的无缝过渡，并在事实核查任务中取得了显著性能提升。

> **ai_Abstract:** BOOST是一种新颖的自举方法，旨在自动化大语言模型中程序引导事实核查的少量样本推理程序生成。它通过迭代细化数据驱动的元规则和批判-改进循环来消除人工干预，从而解决了手动制作演示的局限性。该方法促进了从零样本到少量样本学习的平滑过渡，提高了可解释性和效率，并在复杂声明验证中展现出优于现有基线的性能。

> **摘要翻译:** 大型语言模型管道改进了复杂声明的自动事实核查，但许多方法依赖于少量样本的上下文学习和需要大量人工努力和领域专业知识的演示。其中，通过将声明分解为函数调用并执行推理程序来引导推理的方法显示出特别的前景，但仍受限于需要手动制作演示。从根本上说，有效推理程序生成的基本原理仍未得到充分探索。在这项工作中，我们介绍了BOOST，这是一种用于自动化少量样本推理程序生成的自举方法。BOOST通过一个批判-改进循环，迭代地完善显式、数据驱动的指导方针作为元规则来指导演示创建，从而消除了人工干预。这使得从零样本到少量样本程序引导学习的无缝过渡成为可能，提高了可解释性和有效性。实验结果表明，BOOST在复杂声明验证的零样本和少量样本设置中均优于先前的少量样本基线。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [409] [World Model-Based Learning for Long-Term Age of Information Minimization in Vehicular Networks](https://arxiv.org/abs/2505.01712)
> *车载网络中基于世界模型的长期信息年龄最小化学习*

*Lingyi Wang, Rashed Shelim, Walid Saad, Naren Ramakrishnan* | **Category: cs.AI, cs.NI** | **Updated: 2025-08-01**

**Keywords:** 世界模型, 信息年龄, 车载网络, 强化学习, 毫米波V2X

**Comment:** 

> **TL;DR:** 该论文提出了一种基于世界模型的学习框架，用于在车载网络中最小化信息年龄，通过在想象轨迹中学习策略，显著提高了数据效率和信息年龄性能。

**AI_Comments:** 该论文的创新之处在于将世界模型引入车载网络的信息年龄最小化问题，有效解决了传统强化学习在复杂动态环境中数据效率低下和决策短视的问题。通过在想象轨迹中学习策略，模型能够进行长期规划，并在缺乏实时观测时仍能做出有效决策，这对于高动态的V2X网络具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于强化学习（RL）的学习方法在无线网络中依赖昂贵的试错机制和基于大量环境交互的实时反馈，导致数据效率低下和策略短视。这些局限性在具有高不确定性和长期规划需求的复杂动态网络中尤为突出。

**Method:** 论文提出了一种新颖的基于世界模型的学习框架，用于最小化车载网络中的数据包完整性感知信息年龄（CAoI）。具体地，针对毫米波（mmWave）车联网（V2X）通信网络这一具有高移动性、频繁信号阻塞和极短相干时间的复杂场景。该世界模型框架共同学习毫米波V2X环境的动态模型，并利用其想象轨迹来学习如何执行链路调度。长期策略是在可微分的想象轨迹中学习的，而不是通过环境交互。此外，由于其想象能力，世界模型可以联合预测时变无线数据并优化实际无线和V2X网络中的链路调度。因此，在没有实际观测的间隔期间，世界模型仍能做出高效决策。

**Result:** 仿真结果表明，所提出的世界模型在数据效率方面取得了显著提升，并且与基于模型的强化学习（MBRL）方法和无模型强化学习（MFRL）方法相比，CAoI分别提高了26%和16%。

**Conclusion:** 所提出的基于世界模型的学习框架有效解决了传统强化学习在动态车载网络中的局限性，显著提高了数据效率，并实现了长期信息年龄的最小化。

> **ai_Abstract:** 本文针对传统强化学习在无线网络中数据效率低和策略短视的问题，提出了一种新颖的基于世界模型的学习框架。该框架旨在最小化车载网络中的信息年龄（CAoI），尤其关注毫米波V2X通信场景。通过学习环境的动态模型并在想象轨迹中训练长期策略，该方法显著提升了数据效率，并能在无实时观测的情况下做出决策。实验结果表明，与现有的基于模型和无模型的强化学习方法相比，该方法在CAoI性能上取得了显著提升。

> **摘要翻译:** 传统上，无线网络中基于强化学习（RL）的学习方法依赖于昂贵的试错机制和基于大量环境交互的实时反馈，这导致数据效率低下和策略短视。这些局限性在具有高不确定性和长期规划需求的复杂动态网络中尤为突出。为了解决这些局限性，本文提出了一种新颖的基于世界模型的学习框架，用于最小化车载网络中数据包完整性感知信息年龄（CAoI）。具体地，考虑了一个具有挑战性的代表性场景，即毫米波（mmWave）车联网（V2X）通信网络，其特点是高移动性、频繁信号阻塞和极短相干时间。然后，提出了一个世界模型框架，用于共同学习毫米波V2X环境的动态模型，并利用它来想象轨迹，以学习如何执行链路调度。特别是，长期策略是在可微分的想象轨迹中学习的，而不是通过环境交互。此外，由于其想象能力，世界模型可以联合预测时变无线数据并优化实际无线和V2X网络中的链路调度。因此，在没有实际观测的间隔期间，世界模型仍能做出高效决策。在基于Sionna的真实模拟器上进行了大量实验，该模拟器集成了基于物理的端到端信道建模、射线追踪和具有材料属性的场景几何结构。仿真结果表明，所提出的世界模型在数据效率方面取得了显著提升，并且与基于模型的强化学习（MBRL）方法和无模型强化学习（MFRL）方法相比，CAoI分别提高了26%和16%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [434] [ORFS-agent: Tool-Using Agents for Chip Design Optimization](https://arxiv.org/abs/2506.08332)
> *ORFS-agent：用于芯片设计优化的工具使用代理*

*Amur Ghose, Andrew B. Kahng, Sayak Kundu, Zhiang Wang* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** 芯片设计优化, 大型语言模型, 自动化, 参数调优, 多目标优化

**Comment:** 

> **TL;DR:** ORFS-agent是一个基于LLM的迭代优化代理，用于自动化芯片设计参数调优，相比传统方法，它能更高效地提升设计性能并减少优化迭代次数。

**AI_Comments:** ORFS-agent的创新之处在于将LLM引入到高维的芯片设计参数优化中，利用其强大的学习和推理能力。其重要性在于显著提升了优化效率（减少优化迭代次数）和设计性能（改善线长和时钟周期），并提供了一个灵活且可解释的多目标优化框架。此外，其模块化和模型无关的特性增加了其普适性和易用性。

<details>
  <summary>Details</summary>

**Motivation:** 芯片设计流程涉及数千个参数的复杂配置，微小变化对设计性能、功耗和面积有巨大影响。机器学习已被广泛用于优化工程工作流，而大型语言模型（LLMs）的最新进展为在高维优化任务中进行学习和推理提供了新的机会。

**Method:** 本文引入了ORFS-agent，一个基于LLM的迭代优化代理，它自动化了开源硬件设计流程中的参数调优。ORFS-agent自适应地探索参数配置，并能遵循自然语言目标进行多目标优化。它被设计为模块化且模型无关，无需微调即可与任何前沿LLM结合。

**Result:** ORFS-agent在资源效率和最终设计指标上优于标准贝叶斯优化方法。在两种不同技术节点和一系列电路基准测试中，ORFS-agent能将布线长度和有效时钟周期都改善超过13%，同时使用的优化迭代次数减少了40%。

**Conclusion:** ORFS-agent提供了一个灵活且可解释的多目标优化框架，能够显著提升芯片设计优化效率和性能。其模块化和模型无关的设计特性使其易于集成和应用。

> **ai_Abstract:** 本文介绍了ORFS-agent，一个基于大型语言模型（LLM）的迭代优化代理，旨在自动化芯片设计流程中的参数调优。针对集成电路设计中参数配置复杂且影响巨大的挑战，ORFS-agent通过自适应探索参数配置，在资源效率和设计指标上显著优于传统贝叶斯优化。实验结果表明，ORFS-agent能将布线长度和有效时钟周期提升超过13%，同时减少40%的优化迭代，并提供灵活可解释的多目标优化能力，且其模块化设计使其易于集成。

> **摘要翻译:** 机器学习已被广泛用于优化众多领域的复杂工程工作流。在集成电路设计中，现代流程（例如，从寄存器传输级网表到物理布局）涉及通过数千个参数进行大量配置，并且这些参数的微小变化可能对所需结果（即设计性能、功耗和面积）产生巨大的下游影响。大型语言模型（LLMs）的最新进展为在高维优化任务中进行学习和推理提供了新的机会。在这项工作中，我们引入了ORFS-agent，一个基于LLM的迭代优化代理，它自动化了开源硬件设计流程中的参数调优。ORFS-agent自适应地探索参数配置，在资源效率和最终设计指标方面，表现出比标准贝叶斯优化方法明显的改进。我们在两种不同技术节点和一系列电路基准测试上的实证评估表明，ORFS-agent可以将布线长度和有效时钟周期都改善超过13%，同时使用的优化迭代次数减少了40%。此外，通过遵循自然语言目标来权衡某些指标，ORFS-agent展示了一个灵活且可解释的多目标优化框架。至关重要的是，ORFS-agent是模块化且模型无关的，无需任何进一步的微调即可插入任何前沿LLM。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [458] [Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team](https://arxiv.org/abs/2506.18348)
> *动态知识交换与双重多样性评审：简明释放多智能体研究团队的潜力*

*Weilun Yu, Shixiang Tang, Yonggui Huang, Nanqing Dong, Li Fan, Honggang Qi, Wei Liu, Xiaoli Diao, Xi Chen, Wanli Ouyang* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** 多智能体系统, 大语言模型, 科学发现, 动态知识交换, 双重多样性评审

**Comment:** 

> **TL;DR:** 提出IDVSCI框架，通过动态知识交换和双重多样性评审提升LLM多智能体科学研究能力，并在两个数据集上表现优异。

**AI_Comments:** 该论文的创新点在于提出了IDVSCI框架，通过引入动态知识交换和双重多样性评审机制，显著提升了LLM多智能体在科学研究中的交互性和评估能力。这对于推动LLM在自主科学发现领域的应用具有重要意义，尤其是在模拟真实世界研究协作方面迈出了重要一步。其优势在于通过模拟人类研究团队的协作模式，克服了单一LLM智能体的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于LLM的科学家智能体在自主科学发现中缺乏交互推理和评估机制，而这些机制对于现实世界的研究至关重要。

**Method:** 提出IDVSCI（Internal Discussion and Vote SCIentists）多智能体框架，基于LLM构建，包含两个关键创新：动态知识交换机制（实现智能体间迭代反馈）和双重多样性评审范式（模拟异质专家评估）。

**Result:** IDVSCI在计算机科学和健康科学的两个数据集上均持续取得最佳性能，超越了现有系统如AI Scientist和VIRSCI。

**Conclusion:** 这些发现强调了在基于LLM的自主研究中建模交互和同行评审动态的价值。

> **ai_Abstract:** 本文提出了IDVSCI，一个基于大语言模型的多智能体框架，旨在通过动态知识交换机制和双重多样性评审范式，解决现有LLM科学家智能体在交互推理和评估方面的不足。实验表明，IDVSCI在计算机科学和健康科学数据集上均优于现有系统，证明了模拟交互和同行评审在LLM自主研究中的重要性。

> **摘要翻译:** 科学进步越来越依赖于研究人员之间有效的协作，这种动态是大语言模型（LLMs）才刚刚开始模仿的。尽管最近基于LLM的科学家智能体在自主科学发现方面显示出潜力，但它们通常缺乏现实世界研究所必需的交互推理和评估机制。我们提出了IDVSCI（Internal Discussion and Vote SCIentists），一个基于LLM构建的多智能体框架，它包含两个关键创新：一个动态知识交换机制，能够实现智能体之间的迭代反馈；以及一个双重多样性评审范式，模拟异质专家评估。这些组件共同促进了更深层次的推理和更具创造性、更有影响力的科学思想的生成。为了评估我们方法的有效性和普适性，我们在两个数据集上进行了实验：一个在计算机科学领域广泛使用的基准数据集，以及一个我们在健康科学领域引入的新数据集。结果表明，IDVSCI在这两个数据集上始终取得了最佳性能，优于现有系统如AI Scientist和VIRSCI。这些发现突出了在基于LLM的自主研究中建模交互和同行评审动态的价值。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [477] [The Urban Impact of AI: Modeling Feedback Loops in Next-Venue Recommendation](https://arxiv.org/abs/2504.07911)
> *AI的城市影响：建模下一地点推荐中的反馈循环*

*Giovanni Mauro, Marco Minici, Luca Pappalardo* | **Category: cs.AI, cs.CY** | **Updated: 2025-08-01**

**Keywords:** AI影响, 城市动态, 推荐系统, 反馈循环, 空间隔离

**Comment:** 

> **TL;DR:** 推荐系统在增加个体地点多样性的同时，可能通过将访问集中在热门地点来加剧城市中的集体不平等，从而影响可达性和空间隔离。

**AI_Comments:** 该论文创新性地关注了推荐系统对城市动态的系统性影响以及人机反馈循环，弥补了现有研究主要侧重预测准确性的不足。其基于真实世界数据的模拟框架揭示了推荐系统在促进个体多样性同时可能加剧集体不平等的双重效应，具有重要意义。该工作为预测社会风险和指导城市移动领域中伦理AI的设计提供了宝贵的计算工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注下一地点推荐系统的预测准确性，但对其对城市动态的系统性影响以及人机反馈循环的关注较少。

**Method:** 本研究引入了一个模拟框架来建模下一地点推荐中的人机反馈循环，捕捉算法建议如何影响个体行为并反过来重塑用于模型再训练的数据。模拟基于真实世界的出行数据，并系统地探讨了不同推荐策略下算法采纳的影响。

**Result:** 模拟发现，推荐系统持续增加个体层面访问地点的多样性，但可能同时通过将访问集中在少数热门地点来放大集体不平等。这种差异延伸到社交共同定位网络的结构，揭示了对城市可达性和空间隔离的更广泛影响。

**Conclusion:** 本框架将下一地点推荐中的反馈循环操作化，为评估AI辅助出行对社会的影响提供了一个新颖的视角，并提供了一个计算工具来预测未来风险、评估监管干预措施并为伦理算法系统的设计提供信息。

> **ai_Abstract:** 本文介绍了一个模拟框架，用于建模下一地点推荐系统中人机反馈循环，并探讨其对城市动态的系统性影响。研究基于真实世界的出行数据，发现尽管推荐系统增加了个体访问地点的多样性，但它们可能通过将访问集中在热门地点来加剧集体不平等，从而影响城市可达性和空间隔离。该框架可作为评估AI辅助出行社会影响的计算工具，并为伦理算法设计提供指导。

> **摘要翻译:** 下一地点推荐系统日益嵌入基于位置的服务中，塑造着城市环境中个体的出行决策。尽管其预测准确性已被广泛研究，但对其对城市动态的系统性影响关注较少。在这项工作中，我们引入了一个模拟框架来建模支撑下一地点推荐的人机反馈循环，捕捉算法建议如何影响个体行为，进而重塑用于模型再训练的数据。我们的模拟以真实世界的出行数据为基础，系统地探讨了算法采纳在各种推荐策略下的影响。我们发现，尽管推荐系统持续增加个体层面访问地点的多样性，但它们可能同时通过将访问集中在少数热门地点来放大集体不平等。这种差异延伸到社交共同定位网络的结构，揭示了对城市可达性和空间隔离的更广泛影响。我们的框架将下一地点推荐中的反馈循环操作化，并提供了一个新颖的视角来评估AI辅助出行对社会的影响——提供一个计算工具来预测未来风险、评估监管干预措施并为伦理算法系统的设计提供信息。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [489] [Sound and Complete Neurosymbolic Reasoning with LLM-Grounded Interpretations](https://arxiv.org/abs/2507.09751)
> *基于LLM解释的健全完备神经符号推理*

*Bradley P. Allen, Prateek Chhikara, Thomas Macaulay Ferguson, Filip Ilievski, Paul Groth* | **Category: cs.AI, cs.CL, cs.LO** | **Updated: 2025-08-01**

**Keywords:** 神经符号推理, LLM, 逻辑一致性, 次协调逻辑, 健全性与完备性

**Comment:** 29 pages, 9 tables, 3 figures. Accepted to the 19th Conference on
  Neurosymbolic Learning and Reasoning (NeSy 2025)

> **TL;DR:** 大型语言模型（LLM）在生成输出时存在逻辑一致性问题。本文提出了一种将LLM直接整合到次协调逻辑形式语义解释函数中的方法，以实现健全完备的神经符号推理。

**AI_Comments:** 本文的创新之处在于提供了一个理论框架，该框架在将LLM集成到神经符号推理中时，能够确保逻辑的健全性和完备性，从而有效解决了当前LLM的一个关键局限性。这对于提升LLM在需要高逻辑精度领域的应用潜力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在自然语言理解和生成方面能力突出，但在其生成输出中存在逻辑一致性问题。尽管存在这种不一致性，研究旨在探索如何利用LLM广泛的参数知识进行形式推理。

**Method:** 本文提出了一种将LLM直接整合到次协调逻辑形式语义的解释函数中的方法。

**Result:** 通过使用从多个短形式事实性基准创建的数据集对所提出的函数进行评估，提供了该方法可行性的实验证据。

**Conclusion:** 本文提出的方法为神经符号推理提供了一个理论框架，该框架在利用LLM知识的同时，保留了底层逻辑的健全性和完备性属性，这与先前的工作不同。

> **ai_Abstract:** 本论文旨在解决大型语言模型（LLM）在逻辑一致性方面的缺陷，提出了一种新颖的方法，将LLM直接整合到次协调逻辑形式语义的解释函数中。实验证据表明，该方法在使用事实性基准数据集进行评估时是可行的。这项工作提供了一个神经符号推理的理论框架，它不仅利用了LLM的知识，还确保了底层逻辑的健全性和完备性，这标志着与现有研究相比的一项重要进展。

> **摘要翻译:** 大型语言模型（LLM）在自然语言理解和生成方面展现出令人印象深刻的能力，但它们在生成输出时存在逻辑一致性问题。我们如何在形式推理中利用LLM广泛的参数知识，尽管它们存在不一致性？我们提出了一种方法，将LLM直接整合到次协调逻辑的形式语义解释函数中。我们通过使用从几个短形式事实性基准创建的数据集评估该函数，提供了该方法可行性的实验证据。与先前的工作不同，我们的方法为神经符号推理提供了一个理论框架，该框架利用了LLM的知识，同时保留了底层逻辑的健全性和完备性属性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [524] [On Gradual Semantics for Assumption-Based Argumentation](https://arxiv.org/abs/2507.10076)
> *关于基于假设的论辩中的渐进式语义*

*Anna Rapberger, Fabrizio Russo, Antonio Rago, Francesca Toni* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 渐进式语义, 基于假设的论辩, 计算论辩, 双极论辩框架, 辩证强度

**Comment:** Accepted to KR2025 - With Appendix

> **TL;DR:** 本文为基于假设的论辩（ABA）引入了新的渐进式语义，填补了计算论辩领域的一个空白，并证明了其特性。

**AI_Comments:** 本文的创新之处在于首次将渐进式语义引入到基于假设的论辩（ABA）框架中，填补了计算论辩领域的一个重要空白。其重要性体现在为ABA这种流行的结构化论辩形式提供了更精细的论证强度评估方法，有望在实际应用中发挥作用。通过对QBAF语义的泛化和对新语义性质的验证，该研究为ABA的理论发展奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管渐进式语义在其他计算论辩框架中有所研究，并且基于假设的论辩（ABA）是一种流行的结构化论辩形式且应用广泛，但目前还没有针对ABA的渐进式语义。本文旨在填补这一空白。

**Method:** 本文提出了一系列新颖的渐进式语义，用于为ABA框架中的核心组件——假设——赋予辩证强度。为此，作者将双极集基论辩框架作为（可能非扁平的）ABA框架的抽象，并泛化了最先进的量化双极论辩框架（QBAFs）的模块化渐进式语义。此外，还探索了一种直接利用现有QBAF模块化语义的基于论证的方法作为基线。

**Result:** 提出的渐进式ABA语义满足了渐进式QBAF语义所期望的性质（如平衡性和单调性）的适当改编。通过对合成ABA框架的实验，比较了提出的渐进式ABA语义与其基于论证的对应物，并评估了收敛性。

**Conclusion:** 本文成功地为基于假设的论辩（ABA）引入了渐进式语义，填补了计算论辩领域的一个重要空白，并证明了所提出语义的有效性和适用性。

> **ai_Abstract:** 本文针对计算论辩领域中基于假设的论辩（ABA）框架缺乏渐进式语义的现状，提出了一系列新颖的、基于假设的渐进式语义。通过将双极集基论辩框架作为ABA的抽象，并泛化现有量化双极论辩框架（QBAFs）的模块化渐进式语义，作者成功地为ABA中的假设赋予了辩证强度。研究表明，所提出的语义满足了平衡性和单调性等理想性质。文章还提出了一种基于论证的基线方法，并通过实验对比了两种方法并评估了收敛性，从而填补了ABA领域在渐进式语义方面的空白。

> **摘要翻译:** 在计算论辩中，渐进式语义是扩展式和标签式语义的精细替代方案。它们为论证的（组件）赋予辩证强度，以衡量其可接受度。针对抽象、双极和量化双极论辩框架（QBAFs），以及在较小程度上针对某些形式的结构化论辩，已经研究了几种渐进式语义。然而，对于基于假设的论辩（ABA）来说并非如此，尽管它是一种流行的结构化论辩形式，在多个应用中渐进式语义可能非常有用。在本文中，我们填补了这一空白，并提出了一系列新颖的渐进式语义，用于为ABA框架中的核心组件——假设——赋予辩证强度。为此，我们使用双极集基论辩框架作为（可能非扁平的）ABA框架的抽象，并泛化了最先进的QBAFs模块化渐进式语义。我们证明了我们的渐进式ABA语义满足了渐进式QBAF语义所期望的性质（如平衡性和单调性）的适当改编。我们还探索了一种直接利用现有QBAF模块化语义的基于论证的方法，并将其用作基线。最后，我们对合成ABA框架进行了实验，以比较我们的渐进式ABA语义与其基于论证的对应物，并评估收敛性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [555] [E.A.R.T.H.: Structuring Creative Evolution through Model Error in Generative AI](https://arxiv.org/abs/2507.18004)
> *E.A.R.T.H.：通过生成式AI中的模型错误构建创意演化*

*Yusen Peng, Shuhua Mao* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 生成式AI, 创意, 模型错误, E.A.R.T.H.框架, 人机协同

**Comment:** 44 pages,11 figures

> **TL;DR:** E.A.R.T.H.框架提出了一种五阶段生成管道，将AI模型错误转化为创意资产，通过结构化提示、语义评分和人机协同评估，显著提升了生成式AI的创意质量和表达清晰度。

**AI_Comments:** 这项研究的创新之处在于其将模型错误视为创意来源的核心理念，并将其系统地整合到E.A.R.T.H.五阶段框架中。通过引入“错误生成、放大、精炼选择、转换和反馈利用”的循环过程，以及结合多模态模型和人机协同评估，该工作为生成式AI的创造性演化提供了一个新颖且可量化的路径。其重要性在于，它不仅提升了AI的创造能力，还提供了一种实现更具自主性和人类对齐的创意AI的潜在方法，超越了传统AI的模仿限制。

<details>
  <summary>Details</summary>

**Motivation:** AI如何超越模仿实现真正的创造力？本研究旨在探索将模型生成的错误转化为创意资产的方法，以解决AI在创造性方面的局限性。

**Method:** 本论文提出了E.A.R.T.H.框架，一个包含错误生成、放大、精炼选择、转换和反馈利用五个阶段的生成管道。该框架利用认知科学和生成建模的原理，通过结构化提示、语义评分和人机协同评估来操作“创意潜力隐藏在失败中”的理念。实现时使用了LLaMA-2-7B-Chat、SBERT、BERTScore、CLIP、BLIP-2和Stable Diffusion，并采用基于新颖性、惊喜度和相关性的复合奖励函数。

**Result:** 在Refine阶段，创意得分提高了52.5%（从1.179到1.898，t = -5.56，p < 0.001），最终输出达到2.010，提升了70.4%。精炼后的标语长度缩短48.4%，新颖性增加40.7%，相关性仅下降4.0%。跨模态测试显示标语与图像对齐性强（CLIPScore：0.249；BERTScore F1：0.816）。在人工评估中，生成的输出持续获得高评价，展现出强大的创意质量和表达清晰度。反馈突出文体精确性和情感共鸣。

**Conclusion:** 以错误为中心、反馈驱动的生成方式能够增强创造力，为实现自我演化、与人类对齐的创意AI提供了一条可扩展的路径。

> **ai_Abstract:** 本论文提出了E.A.R.T.H.框架，一个五阶段生成管道，旨在通过将生成模型中的错误转化为创意资产来提升AI的创造力。该框架整合了认知科学和生成建模，利用结构化提示、语义评分和人机协同评估。实验结果表明，该方法显著提高了生成内容的创意质量、新颖性和表达清晰度，并展示了其在实现自我演化、人类对齐的创意AI方面的潜力。

> **摘要翻译:** 人工智能如何才能超越模仿，迈向真正的创造力？本文提出了E.A.R.T.H.框架，这是一个五阶段生成管道，通过错误生成、放大、精炼选择、转换和利用反馈，将模型生成的错误转化为创意资产。借鉴认知科学和生成建模，我们认为“创意潜力隐藏在失败中”，并通过结构化提示、语义评分和人机协同评估将其操作化。该管道使用LLaMA-2-7B-Chat、SBERT、BERTScore、CLIP、BLIP-2和Stable Diffusion实现，采用基于新颖性、惊喜度和相关性的复合奖励函数。在精炼阶段，创意得分提高了52.5%（从1.179到1.898，t = -5.56，p < 0.001），最终输出达到2.010，提升了70.4%。精炼后的标语长度缩短48.4%，新颖性增加40.7%，相关性仅下降4.0%。跨模态测试显示标语与图像对齐性强（CLIPScore：0.249；BERTScore F1：0.816）。在人工评估中，生成的输出持续获得高评价，展现出强大的创意质量和表达清晰度。反馈突出文体精确性和情感共鸣。这些结果表明，以错误为中心、反馈驱动的生成方式能够增强创造力，为实现自我演化、与人类对齐的创意AI提供了一条可扩展的路径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [584] [A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence](https://arxiv.org/abs/2507.21046)
> *自我进化智能体的综述：通往人工超级智能之路*

*Huan-ang Gao, Jiayi Geng, Wenyue Hua, Mengkang Hu, Xinzhe Juan, Hongzhang Liu, Shilong Liu, Jiahao Qiu, Xuan Qi, Yiran Wu, Hongru Wang, Han Xiao, Yuhang Zhou, Shaokun Zhang, Jiayi Zhang, Jinyu Xiang, Yixiong Fang, Qiwen Zhao, Dongrui Liu, Qihan Ren, Cheng Qian, Zhenhailong Wang, Minda Hu, Huazheng Wang, Qingyun Wu, Heng Ji, Mengdi Wang* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** 自我进化智能体, 大型语言模型, 持续学习, 人工超级智能, 适应性系统

**Comment:** 51 pages, 9 figures

> **TL;DR:** 本综述系统回顾了自我进化智能体，旨在解决大型语言模型（LLMs）的静态性瓶颈，通过分析进化机制、适应方法和设计，为构建适应性智能体系统并最终实现人工超级智能提供路线图。

**AI_Comments:** 这篇综述的重要性在于它系统性地梳理了自我进化智能体这一新兴且关键的研究领域，填补了LLMs静态性带来的空白。其创新之处在于提出了“进化什么、何时进化、如何进化”的结构化分析框架，这对于理解和设计未来的自适应智能体具有指导意义。该综述为实现人工超级智能描绘了一条潜在路径，对推动人工智能的长期发展具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）尽管能力强大，但其静态性限制了其适应新任务、动态知识领域和交互上下文的能力。在开放式、交互式环境中部署LLMs时，这种静态性成为关键瓶颈，因此急需能实时自适应推理、行动和进化的智能体。

**Method:** 本文是一篇系统性综述，首次全面回顾了自我进化智能体。它围绕“进化什么、何时进化、如何进化”三个核心维度进行组织，详细检查了智能体组件（如模型、记忆、工具、架构）的进化机制，按阶段（如测试内、测试间）分类适应方法，并分析了指导进化适应的算法和架构设计（如标量奖励、文本反馈、单智能体和多智能体系统）。此外，还分析了评估指标、基准、应用领域，并指出了关键挑战和研究方向。

**Result:** 该综述提供了一个理解和设计自我进化智能体的结构化框架，为推进研究和实际部署中的适应性智能体系统建立了路线图。它分析了评估指标、基准，强调了在编码、教育、医疗保健等领域的应用，并识别了安全、可扩展性和协同进化动力学方面的关键挑战和研究方向。

**Conclusion:** 通过提供一个结构化框架，本综述为推进适应性智能体系统在研究和实际部署中的发展建立了路线图，最终为实现人工超级智能（ASI）铺平道路，即智能体能够自主进化，并在广泛任务中达到或超越人类水平的智能。

> **ai_Abstract:** 本文对自我进化智能体进行了首次系统性综述，旨在解决大型语言模型静态性带来的瓶颈。该综述围绕“进化什么、何时进化、如何进化”三个核心维度，详细审视了智能体组件的进化机制、适应方法分类以及指导进化适应的算法和架构设计。此外，文章还分析了评估指标、应用领域及面临的挑战和未来研究方向，为构建能够持续学习和适应的智能体系统提供了结构化框架和发展路线图，最终目标是实现人工超级智能。

> **摘要翻译:** 大型语言模型（LLMs）展示了强大的能力，但其本质上是静态的，无法使其内部参数适应新颖任务、不断演变的知识领域或动态交互上下文。随着LLMs越来越多地部署在开放式、交互式环境中，这种静态性质已成为一个关键瓶颈，因此需要能够实时自适应推理、行动和进化的智能体。这种范式转变——从扩展静态模型到开发自我进化智能体——引发了人们对能够从数据、交互和经验中实现持续学习和适应的架构和方法的日益增长的兴趣。本综述首次系统全面地回顾了自我进化智能体，围绕三个基础维度进行组织——进化什么、何时进化以及如何进化。我们检查了智能体组件（例如，模型、记忆、工具、架构）中的进化机制，按阶段（例如，测试内、测试间）对适应方法进行分类，并分析了指导进化适应的算法和架构设计（例如，标量奖励、文本反馈、单智能体和多智能体系统）。此外，我们分析了为自我进化智能体量身定制的评估指标和基准，强调了在编码、教育和医疗保健等领域的应用，并指明了安全、可扩展性和协同进化动力学方面的关键挑战和研究方向。通过提供一个理解和设计自我进化智能体的结构化框架，本综述为推进研究和实际部署中的适应性智能体系统建立了路线图，最终为实现人工超级智能（ASI）铺平道路，即智能体能够自主进化，并在广泛的任务中达到或超越人类水平的智能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [614] [How Far Are AI Scientists from Changing the World?](https://arxiv.org/abs/2507.23276)
> *AI科学家离改变世界还有多远？*

*Qiujie Xie, Yixuan Weng, Minjun Zhu, Fuchen Shen, Shulin Huang, Zhen Lin, Jiahui Zhou, Zilan Mao, Zijie Yang, Linyi Yang, Jian Wu, Yue Zhang* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** AI科学家系统, 大型语言模型, 自动化科学发现, 科学研究范式, 瓶颈

**Comment:** 

> **TL;DR:** 本综述探讨了AI科学家系统在自动化科学发现方面的现状、瓶颈和未来发展方向，以评估它们对科学研究范式的影响。

**AI_Comments:** 本文对AI科学家系统这一新兴且快速发展的领域进行了及时且全面的审视，其创新性在于提出“前景驱动的综述”方法，并着重分析了关键瓶颈和实现突破性发现所需的核心组件。其重要性在于为未来科学AI的研究和发展提供了清晰的路线图和目标设定，有助于研究人员识别挑战并集中资源。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）推动自动化科学发现进入新阶段，AI科学家系统在科研中日益重要。本综述旨在回答“AI科学家离改变世界和重塑科学研究范式还有多远？”这一核心问题，以期帮助理解当前系统的局限性、缺失之处及未来目标。

**Method:** 本文通过提供一项前景驱动的综述，全面分析了AI科学家系统当前的成就，识别了关键瓶颈以及产生突破性发现、解决重大挑战所需的关键组件。

**Result:** 综述分析了AI科学家系统当前的成就，并识别了其关键瓶颈以及未来实现突破性发现所需的关键组件。

**Conclusion:** 该综述旨在帮助人们更清晰地理解当前AI科学家系统的局限性，明确其现状、缺失之处以及科学AI的最终目标。

> **ai_Abstract:** 本综述探讨了大型语言模型驱动的AI科学家系统在自动化科学发现中的进展和潜力。论文旨在评估AI科学家系统距离改变世界和重塑科学研究范式的程度，通过全面分析当前成就、识别关键瓶颈和所需核心组件，以期为理解现有局限性、未来发展方向及科学AI的终极目标提供清晰的视角。

> **摘要翻译:** 大型语言模型（LLMs）的出现正在将自动化科学发现推向新的高度，基于LLM的人工智能（AI）科学家系统如今已在科学研究中占据主导地位。AI科学家领域已出现多项有影响力的工作，AI生成的科研论文已被ICLR 2025研讨会接受，这表明能够揭示人类未知现象的人类水平AI科学家可能很快就会成为现实。在这项调查中，我们关注核心问题：AI科学家离改变世界和重塑科学研究范式还有多远？为了回答这个问题，我们提供了一项前景驱动的综述，全面分析了AI科学家系统当前的成就，识别了关键瓶颈以及产生突破性发现、解决重大挑战所需的关键组件。我们希望这项调查能有助于更清晰地理解当前AI科学家系统的局限性，展示我们所处的位置、缺少什么以及科学AI的最终目标应该是什么。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [632] [Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench](https://arxiv.org/abs/2508.00081)
> *重新思考医学语言基准中的证据分级：对HealthBench的批判性评估*

*Fred Mutisya, Shikoh Gitau, Nasubo Ongoma, Keith Mbae, Elizabeth Wamicha* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 医学语言模型, 基准评估, HealthBench, 证据分级, 临床实践指南

**Comment:** 

> **TL;DR:** HealthBench依赖专家意见而非高阶临床证据，导致偏见和地域不均。本研究提出将奖励函数锚定在临床实践指南（CPGs）中，以构建更可靠、道德且全球相关的医学语言模型。

**AI_Comments:** 这篇论文对现有医学语言基准HealthBench提出了深刻的批判，其创新点在于提出将AI评估的奖励机制从主观的专家意见转向客观、高阶的临床实践指南（CPGs）。这对于提升医学AI模型的公平性、可靠性和全球适用性具有重要意义，尤其是在应对发展中国家特定挑战方面。该方法论通过引入“证据鲁棒”强化学习，有望弥补当前基准的局限性，推动医学AI向更负责任的方向发展。

<details>
  <summary>Details</summary>

**Motivation:** HealthBench虽通过医生编写的对话和透明的评分标准推进了医学语言模型评估，但其过度依赖专家意见而非高阶临床证据，存在固化地域偏见和个体临床医生特质的风险，并可能受自动化评分系统偏见影响。这些局限性在低收入和中等收入国家尤为突出，凸显了对更具全球相关性和公平性基准的迫切需求。

**Method:** 提出将奖励函数锚定在包含系统评价和GRADE证据评级的版本控制临床实践指南（CPGs）中。路线图包括通过“证据鲁棒”强化学习实现评分与指南的链接、证据加权评分、上下文覆盖逻辑，并关注伦理考量和延迟结果反馈的整合。

**Result:** 旨在培养出不仅语言流畅，而且临床上值得信赖、符合伦理且具有全球相关性的医学语言模型。

**Conclusion:** 通过将奖励重新基于经过严格审查的临床实践指南（CPGs），同时保留HealthBench的透明度和医生参与，可以促进医学语言模型在临床可靠性、伦理性和全球相关性方面的发展。

> **ai_Abstract:** 本文批判性评估了医学语言基准HealthBench，指出其过度依赖专家意见而非高阶临床证据，可能导致地域偏见和个体差异的固化，尤其在全球低收入地区问题突出。为解决此问题，作者提出将AI系统奖励函数锚定于版本控制的临床实践指南（CPGs），该指南整合了系统评价和GRADE证据评级。通过实施“证据鲁棒”强化学习、证据加权评分和上下文覆盖逻辑，并兼顾伦理考量，旨在开发出更具临床可信度、伦理性和全球相关性的医学语言模型。

> **摘要翻译:** HealthBench是一个旨在更好地衡量人工智能系统在健康领域能力的基准（Arora 等人，2025），通过医生编写的对话和透明的评分标准推动了医学语言模型的评估。然而，它依赖专家意见而非高阶临床证据，存在固化地域偏见和个体临床医生特质的风险，而自动化评分系统中的潜在偏见进一步加剧了这一问题。这些局限性在低收入和中等收入国家尤为突出，这些地区普遍存在被忽视的热带疾病覆盖不足和区域特定指南不匹配等问题。
非洲背景下独特的挑战，包括数据稀缺、基础设施不足和新兴的监管框架，凸显了对更具全球相关性和公平性基准的迫切需求。为解决这些缺点，我们建议将奖励函数锚定在纳入系统评价和GRADE证据评级的版本控制临床实践指南（CPGs）中。
我们的路线图概述了通过评分与指南链接、证据加权评分和上下文覆盖逻辑实现的“证据鲁棒”强化学习，并辅以对伦理考量的关注和延迟结果反馈的整合。通过将奖励重新基于经过严格审查的CPGs，同时保留HealthBench的透明度和医生参与，我们旨在培养出不仅语言流畅，而且临床上值得信赖、符合伦理且具有全球相关性的医学语言模型。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [638] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
> *超性质约束的安全强化学习*

*Ernest Bonnah, Luan Viet Nguyen, Khaza Anuarul Hoque* | **Category: cs.AI, cs.LG, cs.LO, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** 安全强化学习, 超性质, 时序逻辑, 机器人, 最优策略

**Comment:** Accepted in IEEE/ACM MEMOCODE 2025

> **TL;DR:** 本文提出了一种使用动态玻尔兹曼softmax强化学习来学习安全感知最优策略的方法，同时满足超性质时间窗时序逻辑（HyperTWTL）约束。

**AI_Comments:** 该论文的创新点在于填补了利用超性质探索安全感知强化学习的研究空白，特别是在机器人应用中。其重要性在于为机器人系统提供了更强大的安全保障机制。局限性可能在于其领域特定性，即主要关注HyperTWTL和机器人应用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管时序逻辑约束的安全强化学习（SRL）是一个不断发展的研究问题，但利用超性质探索安全感知强化学习（RL）存在显著的研究空白。

**Method:** 在将智能体动力学建模为马尔可夫决策过程（MDP）并将不透明性/安全约束形式化为HyperTWTL的前提下，本文提出了一种使用动态玻尔兹曼softmax强化学习来学习安全感知最优策略的方法，同时满足HyperTWTL约束。

**Result:** 所提出的方法通过一个取货和送货机器人任务案例研究证明了其有效性和可扩展性，并且与两种基线强化学习算法相比，性能更优。

**Conclusion:** 本文提出的方法能够有效地学习满足HyperTWTL安全约束的强化学习最优策略，并且在性能上优于现有基线算法。

> **ai_Abstract:** 本文提出了一种针对机器人应用的超性质约束安全强化学习（SecRL）方法。该方法利用HyperTWTL形式化安全约束，并在马尔可夫决策过程（MDP）框架下，采用动态玻尔兹曼softmax强化学习来学习安全感知的最优策略。通过机器人任务案例研究，证明了该方法的有效性和可扩展性，并显示其性能优于现有基线算法，填补了利用超性质进行安全感知强化学习的研究空白。

> **摘要翻译:** 超性质时间窗时序逻辑（HyperTWTL）是一种领域特定的形式化规约语言，以其在紧凑表示机器人应用的安全、不透明性和并发性质方面的有效性而闻名。本文专注于HyperTWTL约束的安全强化学习（SecRL）。尽管时序逻辑约束的安全强化学习（SRL）是一个不断发展的研究问题，并且已有若干现有文献，但在利用超性质探索安全感知强化学习（RL）方面存在显著的研究空白。鉴于智能体的动力学为马尔可夫决策过程（MDP），并且不透明性/安全约束被形式化为HyperTWTL，我们提出了一种使用动态玻尔兹曼softmax强化学习来学习安全感知最优策略的方法，同时满足HyperTWTL约束。我们所提出方法的有效性和可扩展性通过一个取货和送货机器人任务案例研究得到了证明。我们还将我们的结果与其他两种基线RL算法进行了比较，表明我们提出的方法优于它们。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [644] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
> *没有PI，就没有AI！以对象为中心的流程挖掘作为生成式、预测式和规范式人工智能的赋能者。*

*Wil M. P. van der Aalst* | **Category: cs.AI, H.4.1; I.2.1** | **Updated: 2025-07-31**

**Keywords:** 对象中心流程挖掘, 流程智能, 人工智能, 操作流程, 生成式AI

**Comment:** 10 pages, 4 figures, preprint keynote paper of the seventh
  International Conference on Intelligent and Fuzzy Systems (INFUS 2025)

> **TL;DR:** 组织在工业场景中应用AI面临挑战，本文提出对象中心流程挖掘（OCPM）是实现AI的关键，将其称为流程智能（PI），强调AI需要PI来改进操作流程。

**AI_Comments:** 这篇论文提出了一个重要的观点，即在面向流程的工业环境中，AI的成功应用离不开“流程智能”（PI），特别是对象中心流程挖掘（OCPM）。其创新点在于强调了流程数据与AI之间的关键连接，并引入了“PI”这一概念来概括这种融合。这对于推动AI在实际业务流程优化中的应用具有重要意义，因为它指出了一个常见的AI落地障碍并提供了潜在的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 组织在以端到端操作流程为重点的工业环境中成功应用人工智能面临困难，尤其是在诊断和改进这些流程方面存在挑战。

**Method:** 本文提出人工智能需要以对象为中心的流程挖掘（OCPM）为基础。OCPM被视为连接数据和流程的缺失环节，能够实现不同形式的人工智能。文章引入“流程智能（PI）”一词，指代能够处理各种对象和事件类型的以流程为中心的数据驱动技术的融合，从而在组织环境中赋能AI。

**Result:** OCPM能够为AI提供结构化、组织特定的流程数据，从而克服了将AI应用于动态操作流程的挑战，并使生成式、预测式和规范式AI得以实现。

**Conclusion:** 人工智能需要流程智能（PI），特别是通过对象中心流程挖掘（OCPM）来有效改进操作流程，并成功结合生成式、预测式和规范式AI。

> **ai_Abstract:** 本文探讨了组织在工业环境中应用人工智能（AI）于端到端操作流程所面临的挑战。作者指出，要成功应用生成式、预测式和规范式AI，需要以对象为中心的流程挖掘（OCPM）作为基础。OCPM被定义为连接流程数据和AI的“缺失环节”，并被纳入“流程智能（PI）”的概念，即一种处理多样化对象和事件类型的流程中心数据驱动技术。文章强调了AI需要PI来有效改进操作流程，并展望了OCPM与各类AI结合的潜力。

> **摘要翻译:** 人工智能（AI）的应用正在影响我们的工作、互动、商业和研究方式。然而，组织在以端到端操作流程为重点的工业环境中成功应用AI面临困难。本文考虑了生成式、预测式和规范式AI，并阐述了诊断和改进此类流程的挑战。我们表明，AI需要以对象为中心的流程挖掘（OCPM）为基础。与文本不同，流程相关数据是结构化的、组织特定的，并且流程通常高度动态。OCPM是连接数据和流程的缺失环节，并能够实现不同形式的AI。我们使用“流程智能（PI）”一词来指代能够处理各种对象和事件类型的以流程为中心的数据驱动技术的融合，从而在组织环境中赋能AI。本文解释了为什么AI需要PI来改进操作流程，并强调了成功结合OCPM与生成式、预测式和规范式AI的机会。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [648] [Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI](https://arxiv.org/abs/2507.23565)
> *语义信任链：基于超图辅助智能体的自主信任编排，用于协作方选择*

*Botao Zhu, Xianbin Wang, Dusit Niyato* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** 语义信任链, 智能体AI, 超图, 信任编排, 资源高效信任评估

**Comment:** 

> **TL;DR:** 本文提出了一种基于语义信任链的自主信任编排方法，利用智能体AI和超图在协作系统中实现高效的、资源节约型的信任评估，解决传统信任评估的复杂性和资源消耗问题。

**AI_Comments:** 本文的创新点在于提出了“语义信任链”这一新概念，并巧妙地将智能体AI与超图技术结合起来，用于自主信任编排。特别值得关注的是，该方法在设备空闲期间进行信任评估，有效利用了分布式资源，并考虑了任务特定性。此外，通过构建可链接的信任超图，支持了大规模系统中的多跳协作，展现了其在复杂协作环境下的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在协作系统中，任务的有效完成依赖于对潜在设备的任务特定信任评估。然而，任务的复杂性、分布式设备资源的时空动态性以及不可避免的评估开销，极大地增加了信任评估过程的复杂性和资源消耗。不合时宜或过于频繁的信任评估会降低受限资源的利用率，对协作任务的执行产生负面影响。

**Method:** 本文提出了一种基于语义信任链的自主信任编排方法。该技术利用智能体AI和超图来建立和维护设备间的信任关系。智能体AI利用其在自主感知、任务分解和语义推理方面的优势，仅在设备空闲期间基于历史性能数据对协作方进行信任评估，从而实现分布式资源的有效利用。此外，智能体AI通过分析资源能力与任务需求之间的一致性，对协作方资源进行任务特定信任评估。通过为每个设备维护一个嵌入信任语义的信任超图，智能体AI能够对协作方进行分层管理，并根据信任语义识别需要进行信任评估的协作方，从而在开销和信任准确性之间取得平衡。此外，来自多个设备的局部信任超图可以链接在一起，以支持多跳协作，从而实现大规模系统中的高效协调。

**Result:** 实验结果表明，所提出的方法实现了资源高效的信任评估。

**Conclusion:** 本文提出的基于语义信任链的自主信任编排方法，通过利用智能体AI和超图，有效解决了协作系统中信任评估的复杂性和资源消耗问题，并实现了资源高效的信任评估。

> **ai_Abstract:** 本研究提出了一种名为“语义信任链”的自主信任编排方法，旨在解决协作系统中信任评估的复杂性、高资源消耗及对任务执行的负面影响。该方法创新性地结合了智能体AI和超图，使智能体AI能在设备空闲时基于历史数据进行信任评估，并通过分析资源能力与任务需求进行任务特定评估。同时，通过维护嵌入信任语义的信任超图，实现了协作方的分层管理和高效识别，并在开销与准确性间取得平衡。此外，多个局部信任超图可链接支持多跳协作。实验证明，该方法能实现资源高效的信任评估。

> **摘要翻译:** 在协作系统中，任务的有效完成依赖于对潜在设备的任务特定信任评估，以实现分布式协作。然而，任务的复杂性、分布式设备资源的时空动态性以及不可避免的评估开销，极大地增加了信任评估过程的复杂性和资源消耗。因此，不合时宜或过于频繁的信任评估会降低受限资源的利用率，对协作任务的执行产生负面影响。为了解决这一挑战，本文提出了一种基于语义信任链新概念的自主信任编排方法。我们的技术采用智能体AI和超图来建立和维护设备间的信任关系。通过利用其在自主感知、任务分解和语义推理方面的优势，我们提出智能体AI仅在设备空闲期间基于历史性能数据感知设备状态并自主执行协作方信任评估，从而实现分布式资源的有效利用。此外，智能体AI通过分析资源能力与任务需求之间的一致性，对协作方资源进行任务特定信任评估。此外，通过为每个设备维护一个嵌入信任语义的信任超图，智能体AI能够对协作方进行分层管理，并根据信任语义识别需要进行信任评估的协作方，从而在开销和信任准确性之间取得平衡。此外，来自多个设备的局部信任超图可以链接在一起，以支持多跳协作，从而实现大规模系统中的高效协调。实验结果表明，所提出的方法实现了资源高效的信任评估。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [650] [Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis](https://arxiv.org/abs/2508.00129)
> *多准则决策分析中等级逆转、传递性违规和分解不一致的算法检测*

*Agustín Borda, Juan Bautista Cabral, Gonzalo Giarda, Diego Nicolás Gimenez Irusta, Paula Pacheco, Alvaro Roy Schachner* | **Category: cs.AI, math.OC** | **Updated: 2025-07-31**

**Keywords:** 等级逆转, 多准则决策分析, 算法检测, Scikit-Criteria, 传递性违规

**Comment:** 

> **TL;DR:** 本文提出了三种算法测试，并在Scikit-Criteria库中实现，用于检测多准则决策分析（MCDA）中的等级逆转，以解决评估方法性能的难题。

**AI_Comments:** 这篇论文通过提供具体的算法测试和在Scikit-Criteria库中的实现，为多准则决策分析领域中长期存在的等级逆转问题提供了一个实用的解决方案。其创新点在于将理论检测方法转化为可操作的工具，有助于提升MCDA方法的可靠性和可信度。

<details>
  <summary>Details</summary>

**Motivation:** 在多准则决策分析（MCDA）中，等级逆转是一个严重问题，会极大地影响决策方法在特定备选方案集上的结果。因此，需要一种机制来衡量方法在特定备选方案上的性能，并有望建立不同方法有效性的全局排名。

**Method:** 本文提出了三种检测等级逆转的测试方法，并将其在Scikit-Criteria库中实现。论文还讨论了在通用场景下实现这些测试时出现的复杂性以及为处理这些复杂性所做的设计考虑。

**Result:** 论文提出了三种算法测试，并将其集成到Scikit-Criteria库中，用于检测多准则决策分析中的等级逆转。

**Conclusion:** 这些新增的测试和实现对于评估和判断多准则决策方法的性能具有重要作用。

> **ai_Abstract:** 本文针对多准则决策分析（MCDA）中普遍存在的等级逆转问题，提出并实现了三种算法测试。这些测试旨在衡量和评估MCDA方法在特定备选方案集上的性能，并已集成到Scikit-Criteria库中。论文还探讨了在通用场景下实现这些测试的复杂性及相应的设计解决方案。这些工具的引入有望显著提升对多准则决策方法有效性的判断能力。

> **摘要翻译:** 在多准则决策分析中，等级逆转是一个严重的问题，它会极大地影响多准则决策方法在特定备选方案集上的结果。因此，拥有一种机制来衡量方法在一组备选方案上的性能是非常有用的。这一想法可以进一步推广，以建立解决问题的不同方法有效性的全球排名。在本文中，我们提出了三种检测等级逆转存在的测试方法，并将其在Scikit-Criteria库中实现。我们还讨论了在通用场景下实现这些测试时出现的复杂性以及我们为处理这些复杂性所做的设计考虑。最后，我们讨论了这些新增功能如何在解决问题时对多准则决策方法的判断发挥重要作用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [656] [SHACL Validation under Graph Updates (Extended Paper)](https://arxiv.org/abs/2508.00137)
> *SHACL 验证在图更新下的研究 (扩展论文)*

*Shqiponja Ahmetaj, George Konstantinidis, Magdalena Ortiz, Paolo Pareti, Mantas Simkus* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** SHACL, RDF图, 静态验证, 图更新, 约束语言

**Comment:** Accepted at the International Semantic Web Conference (ISWC 2025)

> **TL;DR:** 本文研究了在RDF图更新下SHACL验证的问题，提出了一种SHACL更新语言，并展示了如何通过将更新操作嵌入SHACL约束来静态验证图的有效性。

**AI_Comments:** 本文的创新之处在于将动态的图更新下的SHACL验证问题，通过巧妙的回归技术，转化为了静态的SHACL约束可满足性问题。这对于在数据不断演进的知识图谱环境中维护数据质量和一致性具有重要意义。原型实现的展示也增强了研究的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 研究在RDF图更新下SHACL验证的问题，这为进一步推理演进中的RDF图提供了基础服务。

**Method:** 提出了一种基于SHACL的更新语言，可以捕获RDF图的直观和实际修改。使用一种将更新操作嵌入SHACL约束的回归技术，将更新下的静态验证问题简化为SHACL中约束的（不）可满足性问题。此外，还分析了SHACL及其关键片段的静态验证问题的计算复杂性。

**Result:** 证明了更新下的静态验证可以简化为SHACL中约束的（不）可满足性问题。分析了静态验证问题的计算复杂性。开发了一个原型实现，用于执行静态验证和其他静态分析任务，并通过初步实验展示了其行为。

**Conclusion:** 本文成功地将RDF图更新下的SHACL静态验证问题归约为SHACL约束的（不）可满足性问题，并提供了计算复杂性分析和原型实现，为演进中的RDF图的推理奠定了基础。

> **ai_Abstract:** 本文探讨了在RDF图更新背景下SHACL验证的挑战。作者引入了一种基于SHACL的更新语言，并专注于静态验证问题，即判断图在应用一系列更新后是否仍能满足SHACL规范。通过采用一种将更新操作融入SHACL约束的回归技术，研究表明此问题可简化为SHACL约束的（不）可满足性。论文还分析了该问题的计算复杂性，并展示了一个原型实现及其初步实验结果。

> **摘要翻译:** SHACL（SHApe Constraint Language）是W3C标准化的一种用于RDF图的约束语言。在本文中，我们研究了RDF图更新下的SHACL验证。我们提出了一种基于SHACL的更新语言，可以捕获RDF图的直观和实际修改，并研究了在此类更新下的静态验证问题。这个问题要求验证验证SHACL规范的每个图在应用给定更新序列后是否仍然有效。更重要的是，它为推理演进中的RDF图提供了进一步服务的基础。通过使用将更新操作嵌入SHACL约束的回归技术，我们表明更新下的静态验证可以简化为SHACL（的轻微扩展）中约束的（不）可满足性。我们分析了SHACL及其一些关键片段的静态验证问题的计算复杂性。最后，我们提出了一个原型实现，该实现对SHACL约束执行静态验证和其他静态分析任务，并通过初步实验展示了其行为。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [662] [Co-Producing AI: Toward an Augmented, Participatory Lifecycle](https://arxiv.org/abs/2508.00138)
> *协同生产AI：迈向增强的、参与式生命周期*

*Rashid Mushkani, Hugo Berard, Toumadher Ammar, Cassandre Chatonnier, Shin Koseki* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 协同生产AI, 参与式AI, AI生命周期, 设计正义, 伦理AI

**Comment:** Eighth AAAI/ACM Conference on AI, Ethics, and Society 2025

> **TL;DR:** 本文提出一种以协同生产为核心的增强型AI生命周期，旨在通过多学科协作和包容性方法解决AI对边缘群体的负面影响。

**AI_Comments:** 本文的创新之处在于提出了一种以“协同生产”为核心的AI生命周期模型，强调了在AI开发全流程中融入多样性、公平性、包容性和多学科协作的重要性，为解决AI偏见和负面影响提供了一个系统性的框架。它超越了单纯的技术或伦理准则，倡导更深层次的生产范式变革，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管已努力减轻人工智能(AI)算法的固有风险和偏见，但这些算法仍可能对文化边缘群体产生不成比例的影响，现有方法不足以完全解决这些危害。

**Method:** 论文借鉴设计正义、扩展学习理论和参与式AI的实证工作，提出需要对AI生产流程进行根本性重构，以协同生产、多样性、公平性、包容性(DEI)和多学科协作为核心。引入了一个由五个相互关联阶段（协同框架、协同设计、协同实施、协同部署、协同维护）组成的增强型AI生命周期，该生命周期由四个多学科研讨会启发，并以分布式权限和迭代知识交换为基础。

**Result:** 提出了一种增强型AI生命周期，包括协同框架、协同设计、协同实施、协同部署和协同维护五个阶段，旨在通过协同生产、DEI和多学科协作来减轻AI的危害，并以分布式权限和迭代知识交换为基础。

**Conclusion:** 论文将所提出的生命周期与几个主要的伦理框架联系起来，并概述了在扩大参与式治理方面尚存的关键研究问题。

> **ai_Abstract:** 本文针对AI算法对文化边缘群体可能造成的不成比例影响，提出了一种根本性的AI生产流程重构方法。作者借鉴设计正义、扩展学习理论和参与式AI的经验，倡导以协同生产、多样性、公平性、包容性(DEI)和多学科协作为核心。为此，论文引入了一个包含协同框架、协同设计、协同实施、协同部署和协同维护五个阶段的增强型AI生命周期。该生命周期通过多学科研讨会形成，并强调分布式权限和迭代知识交换。最后，文章将此生命周期与现有伦理框架进行关联，并提出未来研究方向。

> **摘要翻译:** 尽管已努力减轻人工智能(AI)算法的固有风险和偏见，但这些算法仍可能对文化边缘群体产生不成比例的影响。为了解决或减少这些风险，人们提出了多种方法，包括制定负责任AI的伦理准则和原则，以及促进算法公平的技术解决方案。本文借鉴设计正义、扩展学习理论和参与式AI的最新实证工作，认为减轻这些危害需要对AI生产流程进行根本性重构。这种重新设计应以协同生产、多样性、公平性、包容性(DEI)和多学科协作为核心。我们引入了一个由五个相互关联阶段组成的增强型AI生命周期：协同框架、协同设计、协同实施、协同部署和协同维护。该生命周期由四个多学科研讨会启发，并以分布式权限和迭代知识交换为基础。最后，我们将所提出的生命周期与几个主要的伦理框架联系起来，并概述了在扩大参与式治理方面尚存的关键研究问题。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [668] [Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation](https://arxiv.org/abs/2508.00143)
> *超越共识：重新思考教育AI标注中的“真值”*

*Danielle R. Thomas, Conrad Borchers, Kenneth R. Koedinger* | **Category: cs.AI, cs.CY** | **Updated: 2025-07-31**

**Keywords:** 教育AI, 真值, 标注质量, 评估者间一致性, 外部有效性

**Comment:** Accepted for presentation at NCME AIME-Con 2025

> **TL;DR:** 本文认为，在教育AI标注中，过分依赖人类评估者间的一致性（IRR）来定义“真值”阻碍了学习的进步，并提出了多标签、专家驱动和闭环验证等补充评估方法，以优先考虑有效性和教育影响力。

**AI_Comments:** 本文创新性地挑战了教育AI领域中长期以来对评估者间一致性（IRR）的过度依赖，这对于提升数据标注的质量和AI模型的实际教育影响力具有重要意义。它提出了实用的替代方案，如引入外部有效性和多种评估方法，而非仅仅关注内部共识。这对于推动教育AI从理论走向更实际、更有效的应用至关重要。其局限性可能在于，这些替代方法的具体实施细节和成本效益分析在摘要中未详细阐述。

<details>
  <summary>Details</summary>

**Motivation:** 在教育AI应用中，传统的人类评估者间一致性（IRR）指标（如Cohen's kappa）被视为验证标注数据的核心，但人类评估者本身存在偏见和不可靠性。本文认为，过分依赖IRR作为标注质量的“看门人”阻碍了分类数据以有效和预测性方式改进学习的进展。

**Method:** 本文提出了五种互补的评估方法，以解决过度依赖IRR的问题，包括多标签标注方案、基于专家的方法和闭环有效性。此外，还强调了外部有效性的重要性，例如通过建立验证导师行为的程序并证明其适用于多种导师行为类别。

**Result:** 这些互补方法比单独使用IRR方法更能有效地生成训练数据和后续模型，从而改善学生的学习并提供更具可操作性的见解。

**Conclusion:** 呼吁教育AI领域重新思考标注质量和“真值”的定义，优先考虑有效性和教育影响力，而不是仅仅追求共识。

> **ai_Abstract:** 本文探讨了教育AI标注中“真值”定义的问题，指出过度依赖人类评估者间一致性（IRR）会阻碍教育数据分类的有效性。作者认为人类评估者存在固有的缺陷，并提出IRR不足以作为标注质量的唯一标准。为解决此问题，论文提出了多标签标注、专家驱动方法和闭环有效性等五种补充评估策略，强调这些方法能更好地生成提升学生学习和提供可操作见解的训练数据和模型。最终，论文呼吁重新思考标注质量和“真值”的衡量标准，优先关注其有效性和对教育的实际影响。

> **摘要翻译:** 人类评估者可能存在众所周知的缺陷。他们往往有偏见、不可靠，不适合定义“真值”。然而，鉴于教育AI应用中对大量训练数据日益增长的需求，传统的评估者间一致性（IRR）指标，如Cohen's kappa，仍然是验证标注数据的核心。IRR仍然是许多教育数据机器学习流程的基石。例如，对话中导师行为的分类或机器评分评估中开放式回答的标注。这篇立场论文认为，过度依赖人类IRR作为标注质量的“看门人”阻碍了数据分类的进展，使其无法有效和预测性地改善学习。为了解决这个问题，我们强调了五种补充评估方法的例子，例如多标签标注方案、基于专家的方法和闭环有效性。我们认为，这些方法更有能力生成训练数据和后续模型，从而比单独使用IRR方法更能改善学生的学习并提供更具可操作性的见解。我们还强调了外部有效性的重要性，例如，通过建立验证导师行为的程序并证明其适用于多种导师行为类别（例如，提供提示）。我们呼吁该领域重新思考标注质量和“真值”——优先考虑有效性和教育影响力，而不是仅仅追求共识。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [674] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
> *基于模型的长期人类权力适宜指标软最大化*

*Jobst Heitzig, Ram Potham* | **Category: cs.AI, cs.CY, cs.LG, econ.TH, math.OC, 68Txx, I.2** | **Updated: 2025-07-31**

**Keywords:** AI安全, 人类权力, 权力平衡, 目标函数, 强化学习

**Comment:** 

> **TL;DR:** 本文提出了一种基于模型的方法，通过软最大化适合的长期人类权力指标，以促进AI安全和人类福祉。

**AI_Comments:** 这篇论文的创新点在于将“权力”这一复杂概念量化，并将其作为AI系统优化目标，以同时解决AI安全和人类福祉问题。通过设计一个考虑人类有限理性和社会规范的聚合指标，并提出模型驱动的计算方法，为AI对齐提供了一个新颖且潜在更安全的路径。其重要性在于它尝试从根本上解决AI可能带来的潜在风险，即AI的权力增长可能导致人类的“失能化”。

<details>
  <summary>Details</summary>

**Motivation:** 权力是AI安全中的关键概念，例如作为工具性目标追求权力、人类被剥夺权力、人机互动中的权力平衡以及国际AI治理。同时，作为追求多样化目标的能力，权力对福祉至关重要。本文旨在通过明确地赋能人类并以理想方式管理人机权力平衡，来提升AI安全和人类福祉。

**Method:** 本文采用一种有原则的、部分公理化的方法，设计了一个可参数化和可分解的目标函数，该函数代表了一个规避不平等和风险的长期人类权力聚合指标。该指标考虑了人类的有限理性和社会规范，并涵盖了广泛的人类目标。作者推导了通过逆向归纳法计算该指标的算法，或通过多智能体强化学习形式从给定世界模型中近似计算。

**Result:** 本文通过多种典型情境示例说明了（软）最大化该指标的后果，并描述了其可能隐含的工具性子目标。

**Conclusion:** 初步评估表明，软最大化适合的人类权力聚合指标可能构成代理AI系统的一个有益目标，并且比直接基于效用的目标更安全。

> **ai_Abstract:** 本研究旨在解决AI安全和人类福祉问题，提出了一种基于模型的“软最大化长期人类权力适宜指标”的方法。论文设计了一个可参数化、可分解的客观函数，该函数代表了规避不平等和风险的长期人类权力聚合，并考虑了人类的有限理性和社会规范及广泛目标。研究还开发了计算和近似该指标的算法，并通过实例展示了其影响。作者认为，这种方法可能比直接基于效用的目标更安全，对代理AI系统更为有益。

> **摘要翻译:** 权力是AI安全中的一个关键概念：作为工具性目标的权力追求，人类突然或逐渐的权力丧失，人机交互中的权力平衡以及国际AI治理。同时，权力作为追求多样化目标的能力，对福祉至关重要。
本文探讨了通过明确要求AI智能体赋能人类并以理想方式管理人机智能体之间的权力平衡，来同时促进安全和福祉的理念。我们采用一种有原则的、部分公理化的方法，设计了一个可参数化和可分解的目标函数，该函数代表了一个规避不平等和风险的长期人类权力聚合指标。它考虑了人类的有限理性和社会规范，并且关键在于，它考虑了各种可能的人类目标。
我们推导了通过逆向归纳法计算该指标的算法，或通过多智能体强化学习形式从给定世界模型中近似计算。我们通过各种典型情境示例说明了（软）最大化该指标的后果，并描述了其可能隐含的工具性子目标。我们谨慎的评估是，软最大化适合的人类权力聚合指标可能构成代理AI系统的一个有益目标，并且比直接基于效用的目标更安全。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [680] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
> *RL-PLUS：在强化学习中通过混合策略优化对抗LLM能力边界崩溃*

*Yihong Dong, Xue Jiang, Yongding Tao, Huanyu Liu, Kechi Zhang, Lili Mou, Rongyu Cao, Yingwei Ma, Jue Chen, Binhua Li, Zhi Jin, Fei Huang, Yongbin Li, Ge Li* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 强化学习, 大型语言模型, 能力边界崩溃, 混合策略优化, 多重重要性采样

**Comment:** 

> **TL;DR:** RL-PLUS通过结合内部探索和外部数据，解决了LLM在强化学习中遇到的能力边界崩溃问题，并在数学推理任务上取得了SOTA性能。

**AI_Comments:** RL-PLUS的创新之处在于其混合策略优化，将LLM的内部思考能力与外部数据学习相结合。这种“思维+学习”的范式有效克服了传统RLVR中LLM能力边界和稀疏奖励的限制，特别是通过引入多重重要性采样和探索优势函数，使其在复杂推理任务中表现出显著的性能提升和泛化能力，有效解决了能力边界崩溃的难题。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可验证奖励强化学习（RLVR）方法难以突破大型语言模型（LLMs）固有的能力边界，并且由于其固有的在线策略、巨大的动作空间和稀疏奖励，可能导致能力边界崩溃，从而缩小LLM的问题解决范围。

**Method:** 我们提出了RL-PLUS，一种结合内部利用（即思考）和外部数据（即学习）的新方法。RL-PLUS集成了两个核心组件：多重重要性采样（Multiple Importance Sampling）来解决外部数据带来的分布不匹配问题，以及基于探索的优势函数（Exploration-Based Advantage Function）来引导模型走向高价值、未探索的推理路径。

**Result:** RL-PLUS在六个数学推理基准测试中，与现有RLVR方法相比，取得了最先进的性能。在六个分布外推理任务中表现出色。在不同模型家族中取得了持续且显著的增益，平均相对改进范围为21.1%至69.2%。Pass@k曲线表明RL-PLUS有效解决了能力边界崩溃问题。

**Conclusion:** RL-PLUS通过其混合策略优化方法，成功地提升了LLMs在强化学习中的推理能力，并有效克服了能力边界崩溃问题，实现了卓越的性能和泛化能力。

> **ai_Abstract:** RL-PLUS是一种新颖的强化学习方法，旨在解决大型语言模型（LLMs）在RLVR中遇到的能力边界崩溃问题。通过结合内部探索和外部数据，RL-PLUS利用多重重要性采样处理数据分布不匹配，并采用基于探索的优势函数引导模型。实验证明，RL-PLUS在数学推理任务上达到了SOTA性能，并在分布外任务中表现优异，显著提升了LLMs的推理能力并解决了能力崩溃问题。

> **摘要翻译:** 可验证奖励强化学习（RLVR）显著提升了大型语言模型（LLMs）的复杂推理能力。然而，由于其固有的在线策略、LLM巨大的动作空间和稀疏奖励，它难以突破基础LLM固有的能力边界。此外，RLVR可能导致能力边界崩溃，缩小LLM的问题解决范围。为了解决这个问题，我们提出了RL-PLUS，一种新颖的方法，它协同内部利用（即思考）与外部数据（即学习），以实现更强的推理能力并超越基础模型的边界。RL-PLUS集成了两个核心组件：多重重要性采样，用于解决外部数据的分布不匹配问题；以及基于探索的优势函数，用于引导模型走向高价值、未探索的推理路径。我们提供了理论分析和大量的实验来证明我们方法的优越性和泛化能力。结果表明，RL-PLUS在六个数学推理基准测试中，与现有RLVR方法相比，取得了最先进的性能，并在六个分布外推理任务中表现出卓越的性能。它还在不同的模型家族中取得了持续且显著的增益，平均相对改进范围为21.1%至69.2%。此外，多个基准测试的Pass@k曲线表明RL-PLUS有效解决了能力边界崩溃问题。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [683] [Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving](https://arxiv.org/abs/2507.23726)
> *Seed-Prover：自动化定理证明中的深度和广度推理*

*Luoxin Chen, Jinming Gu, Liankai Huang, Wenhao Huang, Zhicheng Jiang, Allan Jie, Xiaoran Jin, Xing Jin, Chenggang Li, Kaijing Ma, Cheng Ren, Jiawei Shen, Wenlei Shi, Tong Sun, He Sun, Jiahui Wang, Siran Wang, Zhihong Wang, Chenrui Wei, Shufa Wei, Yonghui Wu, Yuchen Wu, Yihang Xia, Huajian Xin, Fan Yang, Huaiyuan Ying, Hongyi Yuan, Zheng Yuan, Tianyang Zhan, Chi Zhang, Yue Zhang, Ge Zhang, Tianyun Zhao, Jianqiu Zhao, Yichi Zhou, Thomas Hanwen Zhu* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 自动化定理证明, 形式化验证, 链式思考, Lean, Seed-Prover

**Comment:** 

> **TL;DR:** Seed-Prover是一个利用Lean反馈、已证明引理和自我总结的引理式全证明推理模型，通过深度和广度推理策略显著提升了自动化定理证明的能力，在IMO级别问题上取得了最先进的成果。

**AI_Comments:** Seed-Prover的创新在于结合了LLMs的长链式思考能力与领域特定语言（如Lean）提供的明确形式化监督信号，有效地解决了传统LLMs在定理证明中缺乏监督的问题。其迭代精炼证明的机制，以及为IMO级别问题设计的深度和广度推理策略，展现了其强大的问题解决能力。Seed-Geometry的引入进一步拓宽了其应用范围。这项工作为自动化数学推理领域带来了显著的进步，特别是在复杂数学问题的形式化证明方面。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在数学推理方面表现出强大能力，但由于缺乏清晰的监督信号（当仅使用自然语言时），它们在定理证明方面仍然面临挑战。专用领域特定语言（如Lean）通过形式化验证提供了明确的监督信号，从而可以通过强化学习进行有效训练。

**Method:** 本文提出了Seed-Prover，一个引理式的全证明推理模型。Seed-Prover能够基于Lean反馈、已证明引理和自我总结迭代地改进其证明。为了解决IMO级别的竞赛问题，设计了三种测试时推理策略，以实现深度和广度推理。此外，为了解决Lean中缺乏几何支持的问题，引入了几何推理引擎Seed-Geometry。

**Result:** Seed-Prover证明了78.1%的形式化IMO往年问题，在MiniF2F上达到饱和，并在PutnamBench上取得了超过50%的成绩，大幅超越了之前的最先进水平。Seed-Geometry的表现优于之前的形式化几何引擎。这两个系统在IMO 2025中完全证明了6个问题中的5个。

**Conclusion:** 这项工作代表了自动化数学推理的重大进展，证明了形式化验证结合长链式思考推理的有效性。

> **ai_Abstract:** Seed-Prover是一个针对自动化定理证明的新型引理式全证明推理模型。它通过利用Lean的形式化验证反馈、已证明引理和自我总结，迭代地精炼证明。为解决IMO级别问题，Seed-Prover结合了深度和广度推理策略，并在多项基准测试（如IMO、MiniF2F和PutnamBench）上显著超越了现有技术。此外，为弥补Lean在几何方面的不足，引入了Seed-Geometry引擎。这项工作展示了形式化验证与长链式思考推理在自动化数学推理领域的巨大潜力。

> **摘要翻译:** 大型语言模型（LLMs）通过利用强化学习和长链式思考，展示了强大的数学推理能力，但由于仅使用自然语言时缺乏清晰的监督信号，它们在定理证明方面仍面临挑战。像Lean这样的专用领域特定语言通过形式化验证提供了明确的监督信号，从而可以通过强化学习进行有效训练。在这项工作中，我们提出了\textbf{Seed-Prover}，一个引理式的全证明推理模型。Seed-Prover可以根据Lean反馈、已证明引理和自我总结迭代地改进其证明。为了解决IMO级别的竞赛问题，我们设计了三种测试时推理策略，以实现深度和广度推理。Seed-Prover证明了78.1%的形式化IMO往年问题，在MiniF2F上达到饱和，并在PutnamBench上取得了超过50%的成绩，大幅超越了之前的最先进水平。为了解决Lean中缺乏几何支持的问题，我们引入了几何推理引擎\textbf{Seed-Geometry}，其性能优于之前的形式化几何引擎。我们使用这两个系统参加了IMO 2025，并完全证明了6个问题中的5个。这项工作代表了自动化数学推理的重大进展，证明了形式化验证结合长链式思考推理的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [686] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
> *MetaAgent：通过工具元学习实现自我进化的智能体*

*Hongjin Qian, Zheng Liu* | **Category: cs.AI, cs.CL, cs.IR** | **Updated: 2025-08-01**

**Keywords:** 自我进化智能体, 元工具学习, 工具使用, 知识发现, 持续学习

**Comment:** Technical Report, 14 pages

> **TL;DR:** MetaAgent是一个受“边做边学”启发的智能体，它通过自我反思、寻求外部工具、构建内部工具和知识库来持续改进其推理和工具使用策略，无需模型参数更改或后训练，并在知识发现基准测试中表现出色。

**AI_Comments:** 这篇论文提出了一种新颖的智能体范式MetaAgent，其核心创新在于“元工具学习”机制，使得智能体能够通过实践和自我反思持续进化，而无需重新训练模型，这大大提高了智能体的适应性和泛化能力。其“边做边学”的理念和动态知识整合方式，对于构建更自主、更通用的AI智能体具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过“边做边学”的原则，开发一个能通过实践和持续自我改进来发展专业知识的智能体范式，以应对现有智能体在遇到知识空白时可能表现不足且缺乏持续自我改进能力的问题。

**Method:** MetaAgent从一个最小工作流开始，具备基本推理和自适应求助能力。当遇到知识空白时，它生成自然语言求助请求，由工具路由器导向最合适的外部工具。它通过自我反思和答案验证，将经验提炼成简洁文本并融入未来的任务上下文。MetaAgent还通过组织工具使用历史，自主构建内部工具和持久知识库，实现“元工具学习”，持续改进推理和工具使用策略，无需改变模型参数或进行后训练。

**Result:** 在包括GAIA、WebWalkerQA和BrowseCamp在内的具有挑战性的知识发现基准测试中，MetaAgent始终优于基于工作流的基线，并达到或超过端到端训练的智能体。

**Conclusion:** MetaAgent展示了自我进化智能体系统在鲁棒、通用知识发现方面的潜力。

> **ai_Abstract:** MetaAgent是一种受“边做边学”启发的自我进化智能体范式。它通过在遇到知识空白时寻求外部工具帮助、持续自我反思、验证答案、提炼经验以及自主构建内部工具和知识库（即“元工具学习”）来不断改进其推理和工具使用策略，无需模型参数更改。在知识发现基准测试中，MetaAgent表现出色，超越了基线并与端到端训练的智能体持平或超越，展示了其在通用知识发现方面的潜力。

> **摘要翻译:** 在这项工作中，我们提出了MetaAgent，这是一种受“边做边学”原则启发的智能体范式，其中专业知识通过实践和持续自我改进来发展。MetaAgent从一个最小工作流开始，仅配备基本的推理和自适应求助能力。当遇到知识空白时，MetaAgent会生成自然语言求助请求，这些请求通过专门的工具路由器被路由到最合适的外部工具。当MetaAgent解决任务时，它会持续进行自我反思和答案验证，将可操作的经验提炼成简洁的文本，并动态地整合到未来的任务上下文中。此外，MetaAgent通过组织其工具使用历史，自主构建内部工具和持久知识库，进一步增强其检索和整合相关信息的能力。我们将这种持续的、数据驱动的过程称为“元工具学习”，通过它，MetaAgent逐步完善其推理和工具使用策略，而无需更改模型参数或需要进一步的后训练。在包括GAIA、WebWalkerQA和BrowseCamp在内的具有挑战性的知识发现基准测试中进行评估，MetaAgent始终优于基于工作流的基线，并达到或超过端到端训练的智能体，展示了自我进化智能体系统在鲁棒、通用知识发现方面的潜力。我们提供了源代码：https://github.com/qhjqhj00/MetaAgent。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [698] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
> *弥合差距：人类与大型语言模型生成任务之间的差异*

*Yi-Long Lu, Jiajun Song, Chunhui Zhang, Wei Wang* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** LLM, 任务生成, 人类认知, 心理驱动, 具身性

**Comment:** 

> **TL;DR:** 研究发现人类和LLM在任务生成上存在核心差异，LLM未能体现人类的心理驱动，其任务更抽象、社交性物理性较低。

**AI_Comments:** 这项研究创新性地揭示了大型语言模型在任务生成方面与人类认知的核心差异，特别是其未能捕捉人类内在的心理驱动和具身化特性。其重要性在于，它为未来设计更符合人类行为和价值观的AI智能体提供了明确的方向，即需要超越纯粹的统计模式学习，融入更深层次的动机和物理世界理解。局限性可能在于实验仅使用了GPT-4o，未来研究可拓展至更多LLM模型以验证普适性。

<details>
  <summary>Details</summary>

**Motivation:** 虽然LLM驱动的生成式智能体旨在模拟人类复杂的任务生成行为，但尚不确定它们是否基于相似的认知原理。本研究旨在探讨人类与LLM在任务生成上的差异。

**Method:** 进行了一项任务生成实验，比较了人类受试者和LLM智能体（GPT-4o）的反应。研究还尝试将心理驱动因素明确提供给LLM。

**Result:** 人类的任务生成持续受到个人价值观（如开放性）和认知风格等心理驱动因素的影响。即使明确提供这些驱动因素，LLM也未能反映出相应的行为模式。LLM生成的任务社交性、物理性显著较低，且主题偏向抽象。尽管LLM的任务被认为更有趣和新颖，但这凸显了其语言能力与生成类人、具身目标能力之间的脱节。

**Conclusion:** 人类认知是价值驱动和具身化的，而LLM的认知基于统计模式，两者之间存在核心差异。这强调了在设计更符合人类的智能体时，需要融入内在动机和物理具身性。

> **ai_Abstract:** 本研究通过对比人类与GPT-4o的任务生成行为，发现LLM在模拟人类任务生成方面存在显著差距。人类的任务生成受心理驱动因素影响，而LLM即使在给定这些因素时也无法复现，其生成的任务更抽象、社交性和物理性较低。这表明LLM的语言能力与生成具身化、价值驱动的人类目标的能力之间存在脱节，强调了未来AI设计需整合内在动机和物理具身性。

> **摘要翻译:** 人类在内在动机的引导下不断生成各种各样的任务。虽然由大型语言模型（LLM）驱动的生成式智能体旨在模拟这种复杂的行为，但它们是否以相似的认知原则运作仍不确定。为了解决这个问题，我们进行了一项任务生成实验，比较了人类的反应与LLM智能体（GPT-4o）的反应。我们发现人类的任务生成始终受到心理驱动因素的影响，包括个人价值观（例如，对变化的开放性）和认知风格。即使将这些心理驱动因素明确提供给LLM，它也未能反映出相应的行为模式。它们生成的任务明显缺乏社交性、物理性，并且主题偏向抽象。有趣的是，虽然LLM的任务被认为更有趣和新颖，但这突显了其语言能力与生成类人、具身目标能力之间的脱节。我们得出结论，价值驱动、具身化的人类认知与LLM的统计模式之间存在核心差距，这强调了在设计更符合人类的智能体时，有必要将内在动机和物理具身性融入其中。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [711] [Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning](https://arxiv.org/abs/2508.00323)
> *俄狄浦斯与斯芬克斯：基准测试和改进复杂图形推理的视觉语言模型*

*Jianyi Zhang, Xu Ji, Ziyin Zhou, Yuchen Zhou, Shubo Shi, Haoyu Wu, Zhen Li, Shizhao Liu* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** 视觉语言模型, 图形推理, 基准测试, ReasonBench, 优化策略

**Comment:** 

> **TL;DR:** 该研究提出了ReasonBench，一个用于评估视觉语言模型复杂图形推理能力的基准测试，并提出了DiaCoT和ReasonTune双重优化策略，将VLM性能提高了33.5%。

**AI_Comments:** 这项研究的创新之处在于提出了首个专注于结构化复杂图形推理的基准测试ReasonBench，填补了现有研究仅关注简单图形的空白。同时，提出的DiaCoT和ReasonTune双重优化策略，不仅提升了模型性能，还增强了推理的可解释性和任务适应性，对VLM在复杂推理领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 评估视觉语言模型（VLM）在图形推理任务中的性能已成为一个重要的研究课题。然而，VLM在模拟人类水平的图形推理能力方面仍表现出明显的不足，尤其是在复杂图形推理和抽象问题解决方面，这些方面研究较少，且现有研究仅关注简单图形。

**Method:** 为了评估VLM在复杂图形推理中的性能，我们提出了ReasonBench，这是第一个专注于结构化图形推理任务的评估基准，包含来自真实世界智力测试的1,613个问题。ReasonBench涵盖了与位置、属性、数量和多元素任务相关的推理维度。我们对11个主流VLM进行了基准测试。基于发现，我们提出了双重优化策略：图示推理链（DiaCoT）通过分层分解增强推理的可解释性，ReasonTune通过训练增强模型推理的任务适应性。

**Result:** 我们对11个主流VLM（包括闭源和开源模型）进行了基准测试，揭示了当前模型的显著局限性。双重优化策略（DiaCoT和ReasonTune）将VLM性能提高了33.5%。

**Conclusion:** 视觉语言模型在复杂图形推理方面存在显著局限性，但通过提出的ReasonBench基准测试和双重优化策略（DiaCoT和ReasonTune），可以有效评估并显著提升其在该领域的表现。

> **ai_Abstract:** 本研究旨在解决视觉语言模型在复杂图形推理能力上的不足。为此，论文提出了ReasonBench，一个包含1613个来自真实智力测试问题的评估基准，用于全面评估VLM在空间、关系和抽象推理方面的表现。通过对11个主流VLM的基准测试，揭示了现有模型的局限性。基于这些发现，研究提出了图示推理链（DiaCoT）和ReasonTune的双重优化策略，成功将VLM性能提升了33.5%。

> **摘要翻译:** 评估视觉语言模型（VLM）在图形推理任务中的性能已成为一个重要的研究课题。然而，VLM在模拟人类水平的图形推理能力方面仍表现出明显的不足，尤其是在复杂图形推理和抽象问题解决方面，这些方面研究较少，且现有研究仅关注简单图形。为了评估VLM在复杂图形推理中的性能，我们提出了ReasonBench，这是第一个专注于结构化图形推理任务的评估基准，其中包含来自真实世界智力测试的1,613个问题。ReasonBench涵盖了与位置、属性、数量和多元素任务相关的推理维度，全面评估了VLM在空间、关系和抽象推理能力方面的表现。我们对11个主流VLM（包括闭源和开源模型）进行了基准测试，揭示了当前模型的显著局限性。基于这些发现，我们提出了双重优化策略：图示推理链（DiaCoT）通过分层分解增强推理的可解释性，ReasonTune通过训练增强模型推理的任务适应性，所有这些都将VLM性能提高了33.5%。所有实验数据和代码都在仓库中：https://huggingface.co/datasets/cistine/ReasonBench。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [25] [ChatModel: Automating Reference Model Design and Verification with LLMs](https://arxiv.org/abs/2506.15066)
> *ChatModel：利用大型语言模型自动化参考模型设计与验证*

*Jianmin Ye, Tianyang Liu, Qi Tian, Shengchu Su, Zhe Jiang, Xi Wang* | **Category: cs.AR, cs.MA** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 参考模型, 自动化验证, 集成电路设计, ChatModel

**Comment:** 

> **TL;DR:** ChatModel利用大型语言模型自动化复杂集成电路的参考模型设计与验证，显著提升效率和质量。

**AI_Comments:** ChatModel的创新之处在于首次将LLM应用于自动化参考模型的设计与验证，解决了集成电路设计日益复杂带来的验证挑战。其通过结合设计标准化和分层敏捷建模的“构建块”策略，有效提升了LLM在特定领域的应用能力。该工作对于加速IC验证流程、降低开发成本具有重要意义，并为LLM在工程自动化领域的应用提供了新的范例。

<details>
  <summary>Details</summary>

**Motivation:** 随着集成电路设计复杂性不断升级，功能验证变得更具挑战，参考模型开发耗时且复杂。尽管大型语言模型（LLMs）在代码编程方面有潜力，但有效生成复杂参考模型仍然是一个重大障碍。

**Method:** 引入ChatModel，首个LLM辅助的敏捷参考模型生成和验证平台。通过整合设计标准化和分层敏捷建模，并采用构建块生成策略，简化从设计规范到功能参考模型的转换。

**Result:** 在300个不同复杂度的设计上评估，效率和质量显著提升。与替代方法相比，ChatModel实现了高达55.02%的峰值性能提升，生成稳定性显著增强，参考模型设计生产能力提高9.18倍。与传统方法相比，迭代过程平均加速5.90倍。

**Conclusion:** ChatModel在自动化参考模型生成和验证方面具有巨大潜力。

> **ai_Abstract:** 本论文介绍了ChatModel，一个利用大型语言模型（LLMs）自动化复杂集成电路参考模型设计与验证的平台。面对集成电路设计日益增长的复杂性和传统参考模型开发耗时的问题，ChatModel通过整合设计标准化、分层敏捷建模和构建块生成策略，有效地将设计规范转化为功能参考模型。实验结果表明，ChatModel在参考模型生成效率和质量上实现了显著提升，性能最高提高55.02%，生成能力提升9.18倍，迭代过程加速5.90倍，展现了其在自动化验证流程中的巨大潜力。

> **摘要翻译:** 随着集成电路设计的复杂性不断升级，功能验证变得越来越具有挑战性。参考模型对于加速验证过程至关重要，但其本身也变得越来越复杂且开发耗时。尽管大型语言模型（LLMs）在代码编程方面展现出前景，但有效生成复杂的参考模型仍然是一个重大障碍。为了应对这些挑战，我们引入了ChatModel，这是第一个由大型语言模型辅助的敏捷参考模型生成和验证平台。ChatModel通过整合设计标准化和分层敏捷建模，简化了从设计规范到全功能参考模型的转换。它采用构建块生成策略，不仅增强了大型语言模型生成参考模型的设计能力，还显著提高了验证效率。我们在300个不同复杂度的设计上对ChatModel进行了评估，展示了参考模型生成效率和质量的显著提升。与替代方法相比，ChatModel实现了高达55.02%的峰值性能提升，生成稳定性显著增强，并且其生成参考模型设计的能力提高了9.18倍。此外，与传统方法相比，它将参考模型设计和验证的迭代过程平均加速了5.90倍。这些结果突显了ChatModel在显著推进参考模型生成和验证自动化方面的潜力。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [692] [E2ATST: A Temporal-Spatial Optimized Energy-Efficient Architecture for Training Spiking Transformer](https://arxiv.org/abs/2508.00475)
> *E2ATST: 一种时空优化的高能效脉冲Transformer训练架构*

*Yunhao Ma, Yanyu Lin, Mingjing Li, Puli Quan, Chenlin Zhou, Wenyue Zhang, Zhiwei Zhong, Wanyi Jia, Xueke Zhu, Qingyan Meng, Huihui Zhou, Fengwei An* | **Category: cs.AR, cs.NE** | **Updated: 2025-08-01**

**Keywords:** Not mentioned in abstract

**Comment:** 

> **TL;DR:** Not mentioned in abstract

**AI_Comments:** 摘要中只包含了作者单位信息，缺乏论文内容（如研究目的、方法、结果和结论），因此无法对论文进行深入分析和总结。

<details>
  <summary>Details</summary>

**Motivation:** Not mentioned in abstract

**Method:** Not mentioned in abstract

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** Not mentioned in abstract

> **摘要翻译:** (1) 鹏城实验室
(2) 南方科技大学
(3) 中国科学院深圳先进技术研究院
(4) 中国科学院大学

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='cscc'></a>
## cs.CC 

### [31] [Asymptotically Optimal Inapproximability of E$k$-SAT Reconfiguration](https://arxiv.org/abs/2508.00276)
> *E$k$-SAT重构渐近最优不可近似性*

*Shuichi Hirahara, Naoto Ohsaka* | **Category: cs.CC, cs.DM, cs.DS** | **Updated: 2025-08-01**

**Keywords:** E$k$-SAT重构, 近似算法, PSpace-hard, 近似阈值, 非单调测试

**Comment:** To appear in Proceedings of the 66th IEEE Symposium on Foundations of
  Computer Science (FOCS 2025)

> **TL;DR:** 本文研究了Maxmin E$k$-SAT重构问题，确定了其渐近最优近似因子为$1 - \Theta\left(\frac{1}{k}\right)$，并提出了一个近似算法和证明了其PSpace-hard的不可近似性。

**AI_Comments:** 本文的创新之处在于首次发现了一个重构问题，其近似阈值（渐近地）比其NP对应问题更差，这挑战了人们对重构问题与经典NP问题难度关系的传统认知。引入的“非单调”测试方法是专门为重构问题设计的，尽管在PCP领域不适用，但它为重构问题的难度证明提供了新的工具，具有重要的理论贡献。

<details>
  <summary>Details</summary>

**Motivation:** 本文研究了Maxmin E$k$-SAT重构问题，这是一个在给定两个满足赋值的情况下，通过翻转变量将一个赋值转换为另一个赋值，并在此过程中最大化最小满足子句比例的问题。其动机在于探索重构问题的近似阈值，特别是与NP对应问题的近似阈值进行比较，发现重构问题可能具有更差的近似性质。

**Method:** 在算法方面，本文开发了一种确定性的$\left(1-\frac{1}{k-1}-\frac{1}{k}\right)$-因子近似算法，适用于所有$k \geq 3$。在难度方面，本文证明了对于足够大的$k$，将该问题近似到$1-\frac{1}{10k}$的因子是PSpace-hard的。为了证明难度结果，引入了一种新的“非单调”测试方法，该方法专门针对重构问题。

**Result:** 本文证明了Maxmin E$k$-SAT重构问题的最优近似因子是$1 - \Theta\left(\frac{1}{k}ight)$。开发了一个确定性的$\left(1-\frac{1}{k-1}-\frac{1}{k}\right)$-因子近似算法。证明了该问题在$1-\frac{1}{10k}$因子内是PSpace-hard的。这是第一个近似阈值（渐近地）比其NP对应问题更差的重构问题。

**Conclusion:** 本文对Maxmin E$k$-SAT重构问题进行了深入研究，确定了其渐近最优的不可近似性，并提供了算法和难度下限。研究结果揭示了重构问题可能比其NP对应问题具有更难的近似性质，这为重构问题的理论分析开辟了新方向。

> **ai_Abstract:** 本文研究了Maxmin E$k$-SAT重构问题，旨在将一个满足赋值转换为另一个，同时最大化转换过程中最小满足子句的比例。研究确定了该问题的渐近最优近似因子为$1 - \Theta\left(\frac{1}{k}ight)$。作者提出了一个$\left(1-\frac{1}{k-1}-\frac{1}{k}ight)$-因子近似算法，并证明了该问题在$1-\frac{1}{10k}$因子内是PSpace-hard的。该研究首次揭示了重构问题的近似阈值可能比其NP对应问题更差，并为此引入了一种新的“非单调”测试方法。

> **摘要翻译:** 在Maxmin E$k$-SAT重构问题中，我们给定一个可满足的$k$-CNF公式$\varphi$，其中每个子句恰好包含$k$个文字，以及一对满足它的赋值。目标是通过重复翻转单个变量的值，将一个满足赋值转换为另一个满足赋值，同时在整个转换过程中最大化$\varphi$的最小满足子句比例。在本文中，我们证明了Maxmin E$k$-SAT重构问题的最优近似因子是$1 - \Theta\left(\frac{1}{k}\right)$。在算法方面，我们为每个$k \geq 3$开发了一个确定性的$\left(1-\frac{1}{k-1}-\frac{1}{k}\right)$-因子近似算法。在难度方面，我们表明对于每个足够大的$k$，将此问题近似到$1-\frac{1}{10k}$的因子是$\mathsf{PSPACE}$-hard的。值得注意的是，Maxmin E$k$-SAT重构问题的“$\mathsf{NP}$对应物”是Max E$k$-SAT，其近似阈值是H\r{a}stad（JACM 2001）所示的$1-\frac{1}{2^k}$。据我们所知，这是第一个近似阈值（渐近地）比其$\mathsf{NP}$对应物更差的重构问题。为了证明难度结果，我们引入了一种新的“非单调”测试，该测试专门为重构问题量身定制，尽管在PCP体系中没有帮助。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [55] [A Practical Finite Element Approach for Simulating Dynamic Crack Growth in Cu/Ultra Low-k Interconnect Structures](https://arxiv.org/abs/2508.00193)
> *一种用于模拟Cu/超低k互连结构中动态裂纹扩展的实用有限元方法*

*Yuxi Xie, Ethan J. Wu, Lu Xu, Jimmy Perez, Shaofan Li* | **Category: cs.CE, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** 裂纹单元法, 动态裂纹扩展, 有限元方法, Cu/超低k互连, ES-FEM

**Comment:** 

> **TL;DR:** 本文提出了一种名为裂纹单元法（CEM）的实用有限元方法，用于模拟二维结构中的动态裂纹扩展，并通过案例研究验证了其在Cu/超低k互连结构中的适用性。

**AI_Comments:** 这项工作提出了一种新颖且实用的裂纹模拟方法，通过结合ES-FEM和单元分裂算法有效解决了传统有限元方法中不良单元形成的问题，从而提高了模拟的精度和效率。其在微电子互连结构中的应用展示了该方法在实际工程问题中的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决动态裂纹扩展模拟中数值精度和计算性能受损的问题，并减少不良形状单元的形成。

**Method:** 该研究提出了一种名为裂纹单元法（CEM）的实用有限元建模策略。该方法采用基于边平滑有限元法（ES-FEM）的单元分裂算法来捕捉单元级裂纹扩展，同时减少不良形状单元的形成。此外，还开发了一种基于分裂单元演化拓扑的断裂能量释放率公式。

**Result:** 所提出的方法通过一系列经典基准问题进行了验证，证明了其在处理动态断裂场景时的准确性和鲁棒性。裂纹单元法（CEM）在涉及图案化Cu/超低k互连结构的案例研究中也得到了应用。

**Conclusion:** 裂纹单元法（CEM）是一种有效且实用的方法，能够准确、鲁棒地模拟动态裂纹扩展，特别适用于Cu/超低k互连结构。

> **ai_Abstract:** 本文介绍了一种实用的有限元方法——裂纹单元法（CEM），用于模拟二维结构中的动态裂纹扩展。该方法结合了基于边平滑有限元法（ES-FEM）的单元分裂算法，以确保数值精度并提高计算性能，同时还开发了相应的断裂能量释放率公式。通过基准问题验证了其准确性和鲁棒性，并在Cu/超低k互连结构中展示了其应用潜力。

> **摘要翻译:** 这项工作提出了一种实用的有限元建模策略，即裂纹单元法（CEM），用于模拟二维结构中的动态裂纹扩展。该方法采用基于边平滑有限元法（ES-FEM）的单元分裂算法来捕捉单元级裂纹扩展，同时减少可能损害数值精度和计算性能的不良形状单元的形成。还基于分裂单元的演化拓扑开发了一种断裂能量释放率公式。所提出的方法通过一系列经典基准问题进行了验证，证明了其在处理动态断裂场景时的准确性和鲁棒性。最后，通过涉及图案化Cu/超低k互连结构的案例研究，说明了CEM的适用性。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [79] [WeightFlow: Learning Stochastic Dynamics via Evolving Weight of Neural Network](https://arxiv.org/abs/2508.00451)
> *WeightFlow：通过神经网络演化权重学习随机动力学*

*Ruikun Li, Jiazhen Liu, Huandong Wang, Qingmin Liao, Yong Li* | **Category: cs.CE** | **Updated: 2025-08-01**

**Keywords:** 随机动力学, 神经网络, 权重空间, 图控制微分方程, 最优传输

**Comment:** 

> **TL;DR:** WeightFlow通过在神经网络权重空间中建模随机动力学，解决了现有方法在估计连续概率密度演化和维度诅咒方面的局限性，并实现了显著的性能提升。

**AI_Comments:** WeightFlow的创新之处在于将随机动力学建模从传统的测度空间转移到神经网络的权重空间，并通过图控制微分方程来学习权重演化，这为解决高维和连续演化问题提供了新的视角。其显著的性能提升也证明了该方法的有效性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 从离散观测中建模随机动力学是一个关键的跨学科挑战。现有方法在估计概率密度的连续演化或应对维度灾难方面存在不足。

**Method:** 本文提出了一种新颖的范式：通过投影演化的概率分布，直接在神经网络的权重空间中建模动力学。首先，理论上建立了测度空间中的动态最优传输与权重空间中等效能量泛函之间的联系。随后，设计了WeightFlow，它将神经网络权重构建成图，并通过图控制微分方程学习其演化。

**Result:** 在跨学科数据集上的实验表明，WeightFlow的性能比现有最先进的方法平均提高了43.02%。

**Conclusion:** WeightFlow为建模高维随机动力学提供了一种有效且可扩展的解决方案。

> **ai_Abstract:** WeightFlow提出了一种新颖的方法来建模随机动力学，通过将演化的概率分布投影到神经网络的权重空间中。该方法首先从理论上建立了动态最优传输与权重空间能量泛函的联系，然后设计了WeightFlow模型，该模型将神经网络权重构建为图并通过图控制微分方程学习其演化。实验证明，WeightFlow在性能上显著优于现有方法，为高维随机动力学建模提供了一个有效且可扩展的解决方案。

> **摘要翻译:** 从离散观测中建模随机动力学是一个关键的跨学科挑战。现有方法通常无法从轨迹中估计概率密度的连续演化，或面临维度灾难。为了解决这些局限性，我们提出了一种新颖的范式：通过投影演化的概率分布，直接在神经网络的权重空间中建模动力学。我们首先从理论上建立了测度空间中的动态最优传输与权重空间中等效能量泛函之间的联系。随后，我们设计了WeightFlow，它将神经网络权重构建成图，并通过图控制微分方程学习其演化。在跨学科数据集上的实验表明，WeightFlow的性能比现有最先进的方法平均提高了43.02%，为建模高维随机动力学提供了一种有效且可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [103] [LEO: An Open-Source Platform for Linking OMERO with Lab Notebooks and Heterogeneous Metadata Sources](https://arxiv.org/abs/2508.00654)
> *LEO：一个连接OMERO与实验室笔记本和异构元数据源的开源平台*

*Rodrigo Escobar Díaz Guerrero, Jamile Mohammad Jafari, Tobias Meyer-Zedler, Michael Schmitt, Juergen Popp, Thomas Bocklitz* | **Category: cs.CE, cs.SE** | **Updated: 2025-08-01**

**Keywords:** OMERO, 电子实验笔记本, FAIR数据, 数据整合, 开源平台

**Comment:** 

> **TL;DR:** LEO是一个开源的、基于网络的平台，旨在连接显微镜研究中分散的异构数据源，例如电子实验笔记本（ELN）和OMERO，以促进数据符合FAIR原则。

**AI_Comments:** LEO的创新之处在于其插件式架构，使其能够灵活地集成多种异构数据源，解决了显微镜研究领域数据分散和难以整合的痛点。作为一个开源平台，它有望促进社区协作和进一步发展，对于推动FAIR数据原则在生物医学图像领域的实践具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在显微镜研究中，管理和整合存储在不同平台上的大量异构数据是一个重大挑战。数据类型如生物图像、实验记录等通常存储在不同的存储库中，且遵循不同标准。将这些数据源在研究生命周期中连接起来对于符合FAIR数据原则（可查找性、可访问性、互操作性、可重用性）至关重要，但目前缺乏有效的工具来整合和连接这些异构数据源。

**Method:** 研究者提出了LEO（Linking Electronic Lab Notebooks with OMERO），一个基于网络的平台，用于创建和管理分布式数据系统之间的链接。LEO最初用于连接ELN和OMERO，并通过插件式架构扩展了其功能，允许集成其他数据源。

**Result:** LEO作为一个可扩展且灵活的解决方案，能够有效整合和连接来自异构源的数据，适用于广泛的显微镜研究工作流程。

**Conclusion:** LEO平台通过提供一个可扩展的、基于插件的解决方案，有效解决了显微镜研究中连接和整合异构数据源的挑战，有助于实现数据管理中的FAIR原则。

> **ai_Abstract:** LEO是一个开源的、基于网络的平台，旨在解决显微镜研究中异构数据源（如生物图像、实验记录）整合的挑战。它通过提供一个可扩展的插件式架构，连接电子实验笔记本（ELN）和OMERO等分布式系统，从而促进数据符合FAIR原则。

> **摘要翻译:** 在显微镜研究的交叉学科领域，管理和整合存储在不同平台上的大量数据仍然是一个重大挑战。生物图像、实验记录和光谱信息等数据类型通常维护在单独的存储库中，每个存储库遵循不同的管理标准。然而，在整个研究生命周期中连接这些数据源对于符合FAIR数据管理原则——可查找性、可访问性、互操作性和可重用性——至关重要。尽管有此需求，但目前缺乏能够有效整合和连接来自异构源的数据的工具。为了弥补这一空白，我们提出了LEO（Linking Electronic Lab Notebooks with OMERO），一个旨在创建和管理分布式数据系统之间链接的基于网络的平台。LEO最初开发用于连接电子实验笔记本（ELN）和OMERO之间的对象，但其功能已通过插件式架构得到扩展，允许集成额外的数据源。这种可扩展性使LEO成为适用于广泛显微镜研究工作流程的可扩展和灵活的解决方案。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [127] [Contact Sensors to Remote Cameras: Quantifying Cardiorespiratory Coupling in High-Altitude Exercise Recovery](https://arxiv.org/abs/2508.00773)
> *接触式传感器到远程摄像头：量化高海拔运动恢复中的心肺耦合*

*Jiankai Tang, Meng Kang, Yiru Zhang, Kegang Wang, Daniel Mcduff, Xin Liu, Yuanchun Shi, Yuntao Wang* | **Category: cs.CE, cs.HC** | **Updated: 2025-08-01**

**Keywords:** 心肺耦合, 远程光电容积描记法, 高海拔, 运动恢复, 非接触式监测

**Comment:** UbiComp 25

> **TL;DR:** 本研究在高海拔地区测量了心肺耦合（CRC），发现运动恢复后CRC有显著变化，并验证了远程光电容积描记法（rPPG）进行非接触式CRC测量的可行性。

**AI_Comments:** 本文的创新点在于首次在高海拔环境下研究了心肺耦合（CRC）在运动恢复中的动态变化，并成功验证了远程光电容积描记法（rPPG）进行非接触式CRC测量的可行性。这为高海拔生理监测和未来可穿戴/非接触式健康监测技术提供了重要的理论和实践基础，具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 心肺耦合（CRC）是心血管和呼吸系统之间动态相互作用的体现，受体育锻炼影响并与生理功能改善相关。本研究旨在在高海拔环境下，探究运动恢复状态下CRC的变化，并评估非接触式CRC测量的可行性。

**Method:** 研究在高海拔地区对受试者进行了心肺耦合（CRC）测量，分为静息和运动后恢复两种状态。同时，通过远程光电容积描记法（rPPG）探索了非接触式CRC测量的可行性，并与血氧计测量结果进行对比。

**Result:** 研究发现，在高海拔地区，静息和运动后恢复状态下的心肺耦合（CRC）存在显著差异（p < 0.05）。定量分析显示，恢复过程涉及更频繁但稳定性较低的呼吸与脉搏同步。此外，远程光电容积描记法（rPPG）测量的非接触式CRC与血氧计测量指标呈强相关性（Pearson r = 0.96）。

**Conclusion:** 心肺耦合（CRC）有望成为自主神经调节的敏感指标，并在未来非接触式监测中具有潜在应用价值。

> **ai_Abstract:** 本研究在高海拔地区探究了心肺耦合（CRC）在静息和运动恢复状态下的变化。结果显示运动恢复状态下的CRC与静息状态存在显著差异，表现为同步事件更频繁但稳定性降低。更重要的是，研究成功验证了利用远程光电容积描记法（rPPG）进行非接触式CRC测量的可行性，其结果与传统血氧计高度相关。这些发现表明CRC可作为自主神经调节的敏感生物标志物，并为未来的非接触式生理监测提供了新途径。

> **摘要翻译:** 心肺耦合（CRC）捕捉了心血管和呼吸系统之间的动态相互作用——这种相互作用通过体育锻炼而加强，并与改善的生理功能相关。我们在高海拔地区检查了两种状态下的CRC：静息和运动后恢复，并发现了显著差异（p < 0.05）。定量分析显示，恢复过程涉及更频繁但稳定性较低的呼吸与脉搏同步。此外，我们探索了使用远程光电容积描记法（rPPG）进行非接触式CRC测量的可行性，观察到与基于血氧计的指标具有强相关性（Pearson r = 0.96）。这些发现突出了CRC作为自主神经调节敏感标志物的潜力及其在非接触式监测中未来的应用。源代码可在GitHub上获取：https://github.com/McJackTang/CRC。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [142] [τ-Ring: A Smart Ring Platform for Multimodal Physiological and Behavioral Sensing](https://arxiv.org/abs/2508.00778)
> *τ-Ring：一种多模态生理和行为传感的智能戒指平台*

*Jiankai Tang, Zhe He, Mingyu Zhang, Wei Geng, Chengchi Zhou, Weinan Shi, Yuanchun Shi, Yuntao Wang* | **Category: cs.CE** | **Updated: 2025-08-01**

**Keywords:** 智能戒指, 生理传感, 行为传感, 开源平台, 可穿戴设备

**Comment:** UbiComp 25

> **TL;DR:** τ-Ring是一个开源、可重构的智能戒指平台，旨在解决现有商业智能戒指的专有性问题，加速可穿戴设备研究的创新和可重复性。

**AI_Comments:** τ-Ring的创新之处在于其完全开源和可定制的设计，这与市场上大多数专有智能戒指形成鲜明对比。它通过提供一个可重复、灵活的平台，显著降低了可穿戴设备研究的门槛，有望加速该领域的创新和标准化。其多模态传感能力和对研究人员友好的特性使其在学术研究和原型开发方面具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的商业智能戒指解决方案大多是专有的，这阻碍了可穿戴设备研究的可重复性和创新速度。

**Method:** 本文介绍了τ-Ring平台，它通过以下方式弥补了这一差距：(i) 结合了时间同步多通道PPG、6轴IMU、温度传感、NFC和板载存储的可访问硬件；(ii) 允许研究人员快速重新配置采样率、电源模式和无线协议的可调节固件；以及(iii) 支持实时流媒体和8小时离线日志记录的完全开源Android软件套件。

**Result:** 这些特性共同实现了开箱即用、可重复的丰富生理和行为数据集采集，加速了原型设计并标准化了实验。该平台已通过心率监测和基于戒指的手写识别的演示研究进行了验证。

**Conclusion:** τ-Ring平台通过提供一个开源、可定制的智能戒指解决方案，有效解决了可穿戴设备研究中专有性带来的挑战，有望加速创新和提高研究的可重复性。

> **ai_Abstract:** 本文推出了τ-Ring，一个开源且商业就绪的智能戒指平台，旨在解决现有智能戒指专有性阻碍可穿戴研究创新和可重复性的问题。该平台集成了多模态传感器硬件、可调节固件和开源软件，支持实时和离线数据记录，并通过心率监测和手写识别应用进行了验证，旨在加速可穿戴设备领域的研究和开发。

> **摘要翻译:** 智能戒指已成为连续生理和行为传感的独特便捷设备，可不引人注目地持续获取心率、运动和皮肤温度等指标。然而，大多数商业解决方案仍是专有的，这阻碍了可穿戴设备研究的可重复性和创新。我们引入了τ-Ring，这是一个商业就绪平台，通过以下方式弥合了这一差距：(i) 结合了时间同步多通道PPG、6轴IMU、温度传感、NFC和板载存储的可访问硬件；(ii) 允许研究人员快速重新配置采样率、电源模式和无线协议的可调节固件；以及(iii) 支持实时流媒体和8小时离线日志记录的完全开源Android软件套件。总而言之，这些功能实现了开箱即用、可重复的丰富生理和行为数据集采集，加速了原型设计并标准化了实验。我们通过心率监测和基于戒指的手写识别的演示研究验证了该平台。源代码可在GitHub上获取：https://github.com/thuhci/OpenRing。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [157] [Online Fine-Tuning of Carbon Emission Predictions using Real-Time Recurrent Learning for State Space Models](https://arxiv.org/abs/2508.00804)
> *状态空间模型实时循环学习的碳排放预测在线微调*

*Julian Lemmel, Manuel Kranzl, Adam Lamine, Philipp Neubauer, Radu Grosu, Sophie Neubauer* | **Category: cs.CE, cs.LG, cs.SY, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 碳排放预测, 状态空间模型, 实时循环学习, 在线微调, 嵌入式系统

**Comment:** 6 pages

> **TL;DR:** 本文提出一种使用实时循环学习对状态空间模型（SSM）进行在线微调的方法，使其能够在推理时根据新数据动态更新参数，从而在嵌入式汽车硬件的碳排放预测中显著降低误差。

**AI_Comments:** 这项工作通过引入实时循环学习，解决了传统状态空间模型在部署后无法动态适应新数据的局限性，使其能够进行在线微调。其创新点在于将在线适应能力引入SSM，这对于需要实时响应和资源受限的应用（如嵌入式系统）具有重要意义。该方法在实际碳排放预测中的成功应用，突显了其在工业物联网和边缘计算领域的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的结构化状态空间模型（SSM）通常离线训练，部署后保持静态，无法适应推理时传入的新数据。

**Method:** 本文提出了一种利用实时循环学习（real-time recurrent learning）在推理时连续更新模型参数的方法，以实现状态空间模型（SSM）的在线自适应。该方法在嵌入式汽车硬件收集的小型碳排放数据集上，对线性循环单元SSM进行了评估。

**Result:** 实验结果表明，该方法在推理过程中持续在线减少预测误差。

**Conclusion:** 该方法展示了其在动态、资源受限环境中的应用潜力，能够实现状态空间模型预测的在线微调。

> **ai_Abstract:** 本文提出一种新颖的在线微调方法，利用实时循环学习使结构化状态空间模型（SSM）能在推理时动态适应新数据。针对SSM离线训练后静态部署的局限性，该方法通过持续更新模型参数实现在线适应。在嵌入式汽车硬件的碳排放数据集上，实验证明此方法能显著减少预测误差，尤其适用于动态、资源受限的环境。

> **摘要翻译:** 本文介绍了一种在推理时使用实时循环学习对结构化状态空间模型（SSM）预测进行微调的新方法。尽管SSM以其效率和长程建模能力而闻名，但它们通常离线训练并在部署期间保持静态。我们的方法通过响应传入数据连续更新模型参数来实现在线适应。我们使用从嵌入式汽车硬件收集的小型碳排放数据集对线性循环单元SSM评估了我们的方法。实验结果表明，我们的方法在推理过程中持续在线减少预测误差，展示了其在动态、资源受限环境中的潜力。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [217] [The time slot allocation problem in liberalised passenger railway markets: a multi-objective approach](https://arxiv.org/abs/2401.12073)
> *自由化客运铁路市场的时隙分配问题：一种多目标方法*

*Nikola Bešinović, Ricardo García-Ródenas, María Luz López-García, Julio Alberto López-Gómez, José Ángel Martín-Baos* | **Category: cs.CE, 90-05, I.6; J.6** | **Updated: 2025-07-31**

**Keywords:** 时隙分配, 自由化铁路市场, 多目标优化, 市场均衡, 公平性

**Comment:** 33 pages and 6 figures

> **TL;DR:** 本文提出了一个多目标模型来解决自由化客运铁路市场中的时隙分配问题，并提出了两种分配准则：优先权分配和公平性分配，以评估其对市场均衡的影响。

**AI_Comments:** 该论文创新性地将自由化客运铁路市场的时隙分配问题建模为多目标优化问题，并提出了两种具体且具有实践意义的分配准则（优先级和公平性）。这对于当前欧洲铁路市场自由化的背景下，如何平衡效率与竞争，维护市场均衡具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 欧洲客运铁路市场自由化导致铁路公司需通过竞标获取时隙，时隙分配对市场均衡产生重大影响。基础设施管理者需要选择一个解决方案来分配时隙，因此需要研究如何有效解决时隙分配问题。

**Method:** 将自由化客运铁路市场中的时隙分配问题建模为一个多目标模型。提出了两种选择帕累托前沿点作为解决方案的准则：第一种根据优先级分配时隙；第二种引入公平性原则以激励竞争。

**Result:** 在西班牙铁路网中一个自由化的高速走廊上，对这些规则对市场均衡的影响进行了评估。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对欧洲自由化客运铁路市场中的时隙分配问题，提出了一个多目标模型。基础设施管理者需从帕累托前沿中选择解决方案。研究提出了两种分配准则：一是基于优先级的分配，二是引入公平性以促进竞争。这些规则对市场均衡的影响在一个西班牙高速铁路走廊上进行了评估。

> **摘要翻译:** 通过欧盟指令EU 91/440/EEC实现的欧洲客运铁路市场自由化，预示着一个新场景：不同的铁路公司在竞标过程中争夺时隙。基础设施管理者提供基础设施资源，他们分析和评估收到的投标，将资源分配给每个铁路公司。时隙分配是一个严重影响市场均衡的事实。在本文中，我们将自由化客运铁路市场背景下的时隙分配问题视为一个多目标模型。基础设施管理者负责从帕累托前沿中选择一个点作为时隙分配问题的解决方案。我们提出了两个选择标准：第一个根据一系列优先级向每个公司分配时隙，而第二个引入了公司待遇的公平性标准以激励竞争。这些规则对市场均衡的影响评估已在西班牙铁路网络内的一条自由化高速走廊上进行。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [237] [A Multi-physics Model of Flow from Coronary Angiography: Insights to Microvascular Function](https://arxiv.org/abs/2412.04798)
> *冠状动脉造影血流多物理场模型：微血管功能洞察*

*Haizhou Yang, Jiyang Zhang, Ismael Z. Assi, Brahmajee K. Nallamothu, Krishna Garikipati, C. Alberto Figueroa* | **Category: cs.CE** | **Updated: 2025-07-31**

**Keywords:** 冠状动脉造影, 微血管功能障碍, 多物理场模型, 计算流体动力学, 造影强度曲线

**Comment:** 29 pages, 14 figures

> **TL;DR:** 开发了一种多物理场计算流体动力学模型，用于模拟冠状动脉造影过程，以更好地理解和利用造影数据来诊断冠状动脉微血管功能障碍。

**AI_Comments:** 这项研究通过开发一个创新的3D-0D耦合多物理场CFD模型，为理解和利用冠状动脉造影数据提供了新的视角。其重要性在于，它可能将目前未被充分利用的常规临床数据转化为有价值的诊断信息，从而提高冠状动脉微血管功能障碍(CMD)的诊断效率和准确性。通过引入CIP和进行敏感性分析，该研究深入揭示了血流动力学参数对造影数据的影响，特别是电阻的关键作用。这一工具的开发有望减少对侵入性诊断方法的需求，并使CMD的诊断更加普及和标准化。

<details>
  <summary>Details</summary>

**Motivation:** 冠状动脉微血管功能障碍(CMD)影响全球数百万人，其诊断方法（如IMR和CFR）因复杂性和不一致性而未被充分利用。虽然冠状动脉造影提供了有价值的血流信息，但在目前的临床实践中，这些信息并未被充分理解或利用。本研究旨在开发工具以更好地利用造影数据进行CMD诊断。

**Method:** 本研究开发并校准了一个3D-0D耦合多物理场计算流体动力学(CFD)模型，用于模拟和研究临床血管造影过程中造影剂的注射和冲洗过程。引入了造影强度曲线(CIP)来描述冠状动脉造影数据的动态。此外，还进行了敏感性研究，以评估各种冠状动脉集总参数模型(LPM)参数对CIP形状的影响。

**Result:** 多物理场模型可以有效地校准，产生具有生理意义的血流动力学结果。敏感性研究表明，电阻对CIP上升和下降斜率的影响大于电容，且电阻越高，这种影响越显著。

**Conclusion:** 本研究的模型和结果为解释血管造影数据并最终提取有关冠状动脉微循环的信息提供了一个工具，具有潜在的变革性。

> **ai_Abstract:** 本文开发并校准了一个3D-0D耦合多物理场计算流体动力学(CFD)模型，旨在模拟冠状动脉造影过程中的造影剂动态，以解决现有CMD诊断方法复杂且造影数据未充分利用的问题。通过引入造影强度曲线(CIP)并进行敏感性研究，该模型能够有效生成生理学上有意义的血流动力学结果。研究发现，电阻对CIP的上升和下降斜率有显著影响，其作用大于电容。该模型为从冠状动脉造影数据中提取微循环信息提供了新工具，具有潜在的临床应用价值。

> **摘要翻译:** 冠状动脉微血管功能障碍（CMD）的特征是血管舒张受损，可能导致在压力或劳累时心肌血流不足，影响全球数百万人。尽管其具有诊断价值，但侵入性、基于导丝的CMD诊断技术，例如微循环阻力指数（IMR）和冠状动脉血流储备（CFR），由于其复杂性和不一致性而未被充分利用。冠状动脉造影作为最常用的成像方式之一，提供了有价值的血流信息，有助于诊断CMD。然而，这些信息在当前的临床实践中并未被充分理解或利用。在这项研究中，开发并校准了一个3D-0D耦合多物理场计算流体动力学（CFD）模型，以模拟和研究临床造影过程中造影剂注射和冲洗的过程。引入了造影强度曲线（CIP）来描述冠状动脉造影数据的动态。此外，还进行了敏感性研究，以评估各种冠状动脉集总参数模型（LPM）参数对CIP形状的影响。结果表明，多物理场模型可以有效地校准，产生具有生理意义的血流动力学结果。敏感性研究揭示，电阻对CIP上升和下降斜率的影响大于电容，且电阻越高，这种影响越显著。模型和结果在此呈现。这些结果具有潜在的变革性，因为它们为解释造影数据并最终提取有关冠状动脉微循环的信息提供了一个工具。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='cscg'></a>
## cs.CG 

### [61] [Robust Model Reconstruction Based on the Topological Understanding of Point Clouds Using Persistent Homology](https://arxiv.org/abs/2508.00251)
> *基于点云拓扑理解和持久同调的鲁棒模型重建*

*Yu Chen, Hongwei Lin* | **Category: cs.CG** | **Updated: 2025-08-01**

**Keywords:** 持久同调, 点云, 模型重建, 拓扑理解, 噪声鲁棒性

**Comment:** 

> **TL;DR:** 本文提出了一种利用持久同调理论从嘈杂的非组织点云中鲁棒地重建包含多个封闭曲面模型的自动方法。

**AI_Comments:** 该论文的创新点在于将持久同调理论应用于点云模型重建中的多曲面识别与分离问题，有效解决了噪声和共享区域带来的复杂性。其鲁棒性是该方法的关键优势，使其在实际应用中具有重要价值。结合传统的曲面细分和逼近技术，确保了重建模型的质量。

<details>
  <summary>Details</summary>

**Motivation:** 从非组织点云重建模型是一个重大挑战，特别是当模型由多个表面点云组件组成时，这些点云通常包含噪声并代表具有共享区域的多个封闭曲面，这使得它们的自动识别和分离变得复杂。

**Method:** 本文提出了一种自动方法，该方法利用持久同调提供的拓扑理解，以及持久同调群的代表性2-循环，以有效地区分和分离每个封闭曲面。此外，该方法采用Loop细分和最小二乘渐进迭代逼近（LSPIA）技术来生成高质量的最终曲面并实现完整的模型重建。

**Result:** 实验结果表明，该方法是有效的，并且对点云中的噪声具有鲁棒性，适用于从此类数据重建模型。

**Conclusion:** 本文提出的方法通过利用持久同调的拓扑理解，能够鲁棒地识别、分离并重建包含多个封闭曲面的模型，即使在点云存在噪声的情况下也能生成高质量的表面，显示出其在实际应用中的潜力。

> **ai_Abstract:** 本文提出了一种基于持久同调的自动模型重建方法，旨在解决从嘈杂、非组织点云中重建多组件模型的挑战。该方法利用持久同调的拓扑理解和2-循环来区分和分离不同的封闭曲面，并结合Loop细分和LSPIA技术生成高质量的最终表面。实验证明，该方法对点云噪声具有鲁棒性，并能有效实现完整的模型重建，具有实际应用潜力。

> **摘要翻译:** 从非组织点云重建模型是一个重大挑战，特别是当模型由多个表面点云组件组成时。此类模型通常涉及带有噪声的点云，这些点云代表具有共享区域的多个封闭曲面，这使得它们的自动识别和分离本身就很复杂。在本文中，我们提出了一种自动方法，该方法利用持久同调提供的拓扑理解，以及持久同调群的代表性2-循环，以有效地区分和分离每个封闭曲面。此外，我们采用Loop细分和最小二乘渐进迭代逼近（LSPIA）技术来生成高质量的最终曲面并实现完整的模型重建。我们的方法对点云中的噪声具有鲁棒性，使其适用于从此类数据重建模型。实验结果证明了我们方法的有效性并突出了其在实际应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

### [147] [Dudeney's Dissection is Optimal](https://arxiv.org/abs/2412.03865)
> *杜德尼分割法是最优的*

*Erik D. Demaine, Tonan Kamata, Ryuhei Uehara* | **Category: cs.CG, cs.DM, math.GT** | **Updated: 2025-08-01**

**Keywords:** 杜德尼分割,几何分割,最优性,等边三角形,正方形,图结构

**Comment:** 26 pages, 32 figures. The previous version mistakenly compiled an
  outdated file. This update corrects that and includes the intended version
  with refined and corrected case analysis of cut graphs

> **TL;DR:** 本文证明了杜德尼提出的将等边三角形分割成正方形的四片解法是最优的。

**AI_Comments:** 该论文的创新之处在于它为长期存在的几何难题提供了严谨的数学证明，将一个物理切割问题转化为抽象的图论问题。其重要性在于彻底解决了休闲数学和几何学中的一个著名问题。

<details>
  <summary>Details</summary>

**Motivation:** 解决亨利·欧内斯特·杜德尼在1907年提出的一个百年谜题：将等边三角形切割成最少碎片以形成一个正方形。

**Method:** 将问题简化为分析表示构成每个多边形的碎片边缘和顶点之间对应关系的离散图结构。

**Result:** 证明了等边三角形和正方形没有由三个或更少多边形碎片组成的共同切割，从而证实了杜德尼的四片解法是最优的。

**Conclusion:** 本文最终解决了杜德尼的谜题，通过证明其四片分割法是最优的。

> **ai_Abstract:** 本文证明了亨利·欧内斯特·杜德尼在1907年提出的将等边三角形分割成正方形的四片解法是最优的。通过将问题简化为分析离散图结构，研究人员成功证明了不存在由三个或更少多边形碎片组成的共同切割方案，从而解决了这个长达一个多世纪的几何谜题。

> **摘要翻译:** 1907年，亨利·欧内斯特·杜德尼提出了一个谜题：“将任意一个等边三角形…切割成尽可能少的碎片，这些碎片能够完美地组合成一个正方形”（无重叠，通过平移和旋转）。四周后，杜德尼展示了一个漂亮的四片解决方案，这在今天也许仍然是最著名的切割示例。在本论文中（一个多世纪后），我们最终解决了杜德尼的谜题，证明了等边三角形和正方形没有由三个或更少多边形碎片组成的共同切割。我们将问题简化为分析代表构成每个多边形的碎片边缘和顶点之间对应关系的离散图结构。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

### [162] [Simplification of Trajectory Streams](https://arxiv.org/abs/2503.23025)
> *轨迹流的简化*

*Siu-Wing Cheng, Haoqiang Huang, Le Jiang* | **Category: cs.CG** | **Updated: 2025-08-01**

**Keywords:** 轨迹简化, 流式算法, Fréchet距离, 质量保证, 多边形曲线

**Comment:** SoCG 2025

> **TL;DR:** 本文提出了在Fréchet距离下，具有质量保证的两种轨迹流简化流式算法，解决了现有系统在此方面的不足。

**AI_Comments:** 本文的创新之处在于首次提出了在Fréchet距离下，具有质量保证（近似比）的轨迹流简化流式算法，填补了实时应用领域的空白。这些算法不仅提供了理论上的性能边界，还在效率上超越了传统的静态方法，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有软件系统可以即时简化轨迹流，但很少有具有质量保证的曲线简化算法符合流式处理的要求。

**Method:** 本文提出了两种流式算法，均基于$\\mathbb{R}^d$中的Fréchet距离$d_F$。第一种算法在给定误差$\\varepsilon$和$\\delta$下，生成一条近似曲线，其长度接近最优解的两倍。第二种算法在给定段数$k$和$\\varepsilon$下，维护一条简化曲线，其Fréchet距离近似于给定段数下的最优距离。

**Result:** 第一种算法的工作存储空间为$O(\\varepsilon^{-\\alpha})$，每个顶点处理时间为$O(\\varepsilon^{-\\alpha}\\log\\frac{1}{\\varepsilon})$或$O(\\varepsilon^{-\\alpha})$，总处理时间比最佳静态算法快$|\\tau|$倍（忽略$1/\\varepsilon$的多项式因子）。第二种算法的工作存储空间为$O((k\\varepsilon^{-1}+\\varepsilon^{-(\\alpha+1)})\\log \\frac{1}{\\varepsilon})$，每个顶点处理时间为$O(k\\varepsilon^{-(\\alpha+1)}\\log^2\\frac{1}{\\varepsilon})$或$O(k\\varepsilon^{-(\\alpha+1)}\\log\\frac{1}{\\varepsilon})$。其中$\\alpha = 2(d-1){\\lfloor d/2 \\rfloor}^2 + d$。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对缺乏具有质量保证的流式曲线简化算法的问题，提出了两种创新的流式算法，用于在$\mathbb{R}^d$中基于Fréchet距离简化轨迹流。第一种算法在给定误差预算下，能够生成长度近似最优的简化曲线，并且在处理速度上显著优于现有静态算法。第二种算法则在给定简化曲线段数限制下，维护一个近似最优误差的简化曲线。这两种算法均提供了明确的存储和时间复杂度保证，为实时轨迹数据处理提供了高效且质量可控的解决方案。

> **摘要翻译:** 虽然有软件系统可以即时简化轨迹流，但很少有具有质量保证的曲线简化算法符合流式处理的要求。我们针对$\\mathbb{R}^d$中（对于某个常数$d \\geq 2$）Fréchet距离$d_F$下的两个此类问题，提出了流式算法。
考虑流中$\\mathbb{R}^d$中的多边形曲线$\\tau$。我们提出了一种流式算法，对于任何$\\varepsilon\\in (0,1)$和$\\delta > 0$，该算法生成一条曲线$\\sigma$，使得$d_F(\\sigma,\\tau[v_1,v_i])\\le (1+\\varepsilon)\\delta$且$|\\sigma|\\le 2\\,\\mathrm{opt}-2$，其中$\\tau[v_1,v_i]$是目前流中的前缀，$\\mathrm{opt} = \\min\{\\|\\sigma'\\|: d_F(\\sigma',\\tau[v_1,v_i])\\le \\delta\}$。令$\\alpha = 2(d-1){\\lfloor d/2 \\rfloor}^2 + d$。工作存储空间为$O(\\varepsilon^{-\\alpha})$。对于$d \\in \\{2,3\}$，每个顶点在$O(\\varepsilon^{-\\alpha}\\log\\frac{1}{\\varepsilon})$时间内处理；对于$d \\geq 4$，则在$O(\\varepsilon^{-\\alpha})$时间内处理。因此，整个$\\tau$可以在$O(\\varepsilon^{-\\alpha}|\\tau|\\log\\frac{1}{\\varepsilon})$时间内被简化。忽略$1/\\varepsilon$中的多项式因子，这种运行时间比提供相同保证的最佳静态算法快$|\\tau|$倍。
我们提出了另一种流式算法，对于任何整数$k \\geq 2$和任何$\\varepsilon \\in (0,\\frac{1}{17})$，该算法维护一条曲线$\\sigma$，使得$|\\sigma| \\leq 2k-2$且$d_F(\\sigma,\\tau[v_1,v_i])\\le (1+\\varepsilon) \\cdot \\min\{d_F(\\sigma',\\tau[v_1,v_i]): |\\sigma'| \\leq k\}$，其中$\\tau[v_1,v_i]$是目前流中的前缀。工作存储空间为$O((k\\varepsilon^{-1}+\\varepsilon^{-(\\alpha+1)})\\log \\frac{1}{\\varepsilon})$。对于$d \\in \\{2,3\}$，每个顶点在$O(k\\varepsilon^{-(\\alpha+1)}\\log^2\\frac{1}{\\varepsilon})$时间内处理；对于$d \\geq 4$，则在$O(k\\varepsilon^{-(\\alpha+1)}\\log\\frac{1}{\\varepsilon})$时间内处理。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [2] [EFlat-LoRA: Efficiently Seeking Flat Minima for Better Generalization in Fine-Tuning Large Language Models and Beyond](https://arxiv.org/abs/2508.00522)
> *EFlat-LoRA: 高效寻找平坦最小值以在微调大型语言模型及其他领域中获得更好的泛化能力*

*Jiaxin Deng, Qingcheng Zhu, Junbiao Pang, Linlin Yang, Zhongqian Fu, Baochang Zhang* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** LoRA, 平坦最小值, 泛化能力, 大语言模型, 锐度感知最小化

**Comment:** 

> **TL;DR:** EFlat-LoRA提出了一种有效的方法，通过寻找平坦最小值来提高LoRA微调大型语言模型的泛化能力，并证明了LoRA泛化能力与锐度之间的关系。

**AI_Comments:** 这项工作创新性地将平坦最小值概念引入到LoRA微调中，并通过理论分析和实验验证了LoRA泛化能力与锐度的相关性，填补了现有研究的空白。EFlat-LoRA在效率和性能上均表现出色，对于提升大模型微调效果具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究很少探讨低秩适应（LoRA）的表达能力与泛化能力之间的相关性。尽管锐度感知最小化（SAM）通过鼓励收敛到局部平坦最小值来提高模型泛化能力，但由于缺乏工具来实证寻找平坦最小值或开发理论方法，LoRA的锐度与泛化能力之间的联系尚未得到充分探索。

**Method:** 本文提出了Flat-LoRA及其高效版本EFlat-LoRA，旨在为LoRA寻找平坦最小值。理论上，作者证明了全参数空间中的扰动可以转移到低秩子空间，从而消除了低秩子空间中多个矩阵之间扰动可能引入的潜在干扰。

**Result:** 在大型语言模型和视觉-语言模型上的广泛实验表明，EFlat-LoRA实现了与LoRA相当的优化效率，同时获得了可比甚至更好的性能。例如，在GLUE数据集上使用RoBERTa-large时，EFlat-LoRA平均优于LoRA和全量微调1.0%和0.5%。在视觉-语言模型（如Qwen-VL-Chat）上，EFlat-LoRA在SQA和VizWiz数据集上分别显示出1.5%和1.0%的性能提升。

**Conclusion:** 这些实证结果验证了LoRA的泛化能力与锐度密切相关，这是以前方法所忽略的。

> **ai_Abstract:** 该论文提出了EFlat-LoRA，一种为低秩适应（LoRA）寻找平坦最小值的高效方法，旨在提高大型语言模型微调的泛化能力。研究通过理论证明全参数扰动可转移到低秩子空间，并在一系列大型语言模型和视觉-语言模型上进行了广泛实验。结果显示，EFlat-LoRA在保持与LoRA相当优化效率的同时，实现了更好的性能，并验证了LoRA泛化能力与模型锐度之间的密切关系。

> **摘要翻译:** 低秩适应（LoRA）的表达能力与泛化能力之间的相关性鲜有研究。锐度感知最小化（SAM）通过鼓励收敛到局部平坦最小值，提高了卷积神经网络（CNN）和Transformer的泛化能力。然而，由于缺乏实证寻找平坦最小值或开发理论方法的工具，LoRA的锐度与泛化能力之间的联系尚未得到充分探索。在这项工作中，我们提出了Flat-LoRA及其高效版本EFlat-LoRA，旨在为LoRA寻找平坦最小值。具体而言，我们从理论上证明了全参数空间中的扰动可以转移到低秩子空间。这种方法消除了低秩子空间中多个矩阵之间扰动可能引入的潜在干扰。我们对大型语言模型和视觉-语言模型的广泛实验表明，EFlat-LoRA实现了与LoRA相当的优化效率，同时获得了可比甚至更好的性能。例如，在GLUE数据集上使用RoBERTa-large时，EFlat-LoRA平均优于LoRA和全量微调1.0%和0.5%。在视觉-语言模型（如Qwen-VL-Chat）上，EFlat-LoRA在SQA和VizWiz数据集上分别显示出1.5%和1.0%的性能提升。这些实证结果也验证了LoRA的泛化能力与锐度密切相关，这是以前方法所忽略的。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [3] [SEFL: Enhancing Educational Assignment Feedback with LLM Agents](https://arxiv.org/abs/2502.12927)
> *SEFL：利用大型语言模型代理增强教育作业反馈*

*Mike Zhang, Amalie Pernille Dilling, Léon Gondelman, Niels Erik Ruan Lyngdorf, Euan D. Lindsay, Johannes Bjerva* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 教育反馈, 大型语言模型, 合成数据, 教学代理, 微调

**Comment:** 

> **TL;DR:** SEFL是一个合成数据框架，利用两个LLM代理模拟师生反馈循环，生成高质量的教育作业反馈数据，并用这些数据微调小型LLM，使其能够提供与人类专家相媲美的反馈，从而解决教师提供高质量反馈的时间和成本限制。

**AI_Comments:** SEFL的创新之处在于其利用LLM代理构建合成数据框架，模拟师生反馈循环，从而大规模生成高质量的教育反馈数据，有效解决了传统反馈的成本和时间限制。这种方法避免了对大量真实世界数据的依赖，为训练高效的反馈生成模型提供了新的途径。其潜在的社会影响巨大，有望革新高等教育的反馈机制。

<details>
  <summary>Details</summary>

**Motivation:** 提供高质量的学生作业反馈对学生成功至关重要，但受限于时间和成本。

**Method:** 引入了合成教育反馈循环（SEFL）框架，该框架利用两个大型语言模型（LLM）扮演师生角色，模拟作业完成和形成性反馈，生成学生作业和教师批改/改进建议的合成数据对。然后，利用这些合成数据对更小、计算效率更高的LLM进行微调，使其能够复制高质量、目标导向反馈的关键特征。

**Result:** 通过四位LLM评委和三位人类专家的综合评估，SEFL微调模型在反馈质量方面优于未微调模型和现有基线。人类利益相关者（学生和高校教师）的广泛定性评论也强化了其潜在的社会影响。

**Conclusion:** SEFL具有巨大的潜力，可以改变高等教育及其他领域的反馈流程。

> **ai_Abstract:** 本研究提出了合成教育反馈循环（SEFL）框架，旨在解决传统高质量学生作业反馈面临的时间和成本限制。SEFL利用两个大型语言模型模拟师生交互，生成大量的合成作业反馈数据。随后，这些合成数据用于微调更小型、高效的LLM，使其能够生成高质量、目标导向的反馈。实验结果表明，经过SEFL微调的模型在反馈质量上优于未微调模型和现有基线，并得到了人类专家的积极评价，展现了其在高等教育反馈自动化方面的巨大潜力。

> **摘要翻译:** 提供高质量的学生作业反馈对学生成功至关重要，但受限于时间和成本。在这项工作中，我们引入了合成教育反馈循环（SEFL），这是一个合成数据框架，旨在大规模生成类似于即时、按需反馈的数据，而无需依赖大量的真实世界学生作业。为了获得这种类型的数据，两个大型语言模型（LLM）以师生角色运行，模拟作业完成和形成性反馈，生成学生作业和教师相应批评和可操作改进的合成对。利用这些数据，我们对这些合成对上的更小、计算效率更高的LLM进行微调，使它们能够复制高质量、目标导向反馈的关键特征。与提供多轮、个性化指导的个性化辅导方法不同，SEFL专门专注于复制高等教育中的师生作业反馈循环。通过对四个LLM评委和三个人类专家的全面评估，我们证明了SEFL微调模型在反馈质量方面优于其未微调的对应物和现有基线。人类利益相关者（学生和高等教育教师）的广泛定性评论强化了其潜在的社会影响。总而言之，SEFL具有巨大的潜力，可以改变高等教育及其他领域的反馈流程。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [27] [Lost in Space: Finding the Right Tokens for Structured Output](https://arxiv.org/abs/2502.14969)
> *迷失在空间中：为结构化输出寻找正确的标记*

*Sil Hamilton, David Mimno* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 结构化输出, 语言模型, 性能优化, 标记化, 零样本分类

**Comment:** 

> **TL;DR:** 使用结构化输出时，遵循约定格式和添加前导空格可以显著提高LLM的性能，尤其对小型模型。

**AI_Comments:** 这篇论文的创新点在于系统性地揭示了结构化输出格式对LLM性能的潜在影响，特别是强调了遵循约定和前导空格的重要性。它为LLM在特定任务（如分类和标注）中的实际应用提供了宝贵的优化指导，有助于研究人员和开发者提高模型效率和准确性，填补了该领域实践指导的空白。局限性可能在于其发现是否能推广到所有类型的结构化任务或模型架构。

<details>
  <summary>Details</summary>

**Motivation:** 通用语言模型在生成结构化输出时，虽然可以通过语法强制格式，但会不可预测地降低下游性能。研究旨在探究在语义相似但格式不同的语法之间是否存在系统性差异，以及如何优化结构化输出以提高性能。

**Method:** 作者在四个常见的NLP基准测试上，使用四个流行的模型家族和五种不同的输出格式进行了测试。

**Result:** 所有模型在遵循约定格式（如多项选择使用字母，数值预测使用实数）时表现最准确。引导模型返回包含前导空格的标记时，性能提高了5%-10%，其中小型模型受益最大。研究发现前导空格有助于模型避免子词标记表示中的结构缺陷。

**Conclusion:** 遵循约定格式和使用包含前导空格的标记是提高语言模型在结构化输出任务中（尤其作为零样本分类器时）性能的最佳实践。

> **ai_Abstract:** 该研究探讨了大型语言模型（LLMs）在生成结构化输出时性能下降的问题。通过在多个模型和NLP基准上测试不同输出格式，研究发现遵循传统约定（如字母用于多项选择、实数用于数值）和在标记中加入前导空格能显著提升模型准确性，尤其对小型模型提升更明显。论文最终提出了优化LLMs结构化输出的最佳实践。

> **摘要翻译:** 通用语言模型经过训练以生成各种自然语言输出，但对于某些任务，如标注或分类，我们需要更具体的输出格式。LLM系统越来越多地支持结构化输出，通过根据语法采样标记来强制格式——但这也会不可预测地降低下游性能。在语义（通常在视觉上）与人类相似的语法之间是否存在系统性差异？为了回答这个问题，我们测试了四个流行的模型家族，在四个常见的NLP基准测试上使用了五种不同的输出格式。我们发现，当引导模型使用符合约定的格式时，例如多项选择使用字母，数值预测使用实数，所有模型都表现得最准确。当引导模型返回包含前导空格的标记时，性能也提高了5%-10%，其中小型模型受益最大。我们发现前导空格有助于模型避免子词标记表示中的结构缺陷。我们最后为使用语言模型作为零样本分类器的研究人员提供了结构化输出的最佳实践。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [32] [The Prosody of Emojis](https://arxiv.org/abs/2508.00537)
> *表情符号的韵律*

*Giulio Zhou, Tsz Kin Lam, Alexandra Birch, Barry Haddow* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 韵律, 表情符号, 语音, 交流, 感知

**Comment:** 

> **TL;DR:** 表情符号会影响口语韵律，听众可以仅凭韵律变化识别表情符号的含义。

**AI_Comments:** 这项研究通过分析真实人类语音数据，直接将韵律与表情符号联系起来，提供了经验证据，弥补了以往研究的不足，对理解数字交流中表情符号的沟通作用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在基于文本的交流中，语音韵律线索缺失，表情符号作为视觉替代物，增添情感和语用细微差别。本研究旨在探讨表情符号如何影响语音中的韵律实现，以及听众如何通过韵律线索理解表情符号的含义。

**Method:** 通过结构化但开放式的生成和感知任务收集真实人类语音数据，直接关联韵律和表情符号进行分析。

**Result:** 结果表明，说话者会根据表情符号线索调整其韵律；听众通常仅凭韵律变化就能识别出预期的表情符号；表情符号之间更大的语义差异对应着更大的韵律差异。

**Conclusion:** 这些发现表明表情符号可以作为韵律意图的有意义的载体，为它们在数字媒介语境中的交际作用提供了见解。

> **ai_Abstract:** 本研究通过分析真实人类语音数据，探讨了表情符号如何影响语音韵律的实现以及听众如何通过韵律线索理解表情符号的含义。研究发现，说话者会根据表情符号调整韵律，听众能通过韵律识别表情符号，且表情符号语义差异越大，韵律差异也越大。这表明表情符号是韵律意图的有效载体，揭示了其在数字交流中的作用。

> **摘要翻译:** 音高、时序和语调等韵律特征是口语交流的核心，传达情感、意图和语篇结构。在基于文本的设置中，当这些线索缺失时，表情符号充当视觉替代品，增加情感和语用上的细微差别。本研究探讨了表情符号如何影响语音中的韵律实现，以及听众如何解释韵律线索以恢复表情符号的含义。与以往的工作不同，我们通过分析在结构化但开放式的生成和感知任务中收集到的真实人类语音数据，直接将韵律和表情符号联系起来。这为表情符号语义如何塑造口语表达和感知提供了经验证据。结果表明，说话者会根据表情符号线索调整其韵律，听众通常仅凭韵律变化就能识别出预期的表情符号，并且表情符号之间更大的语义差异对应着更大的韵律差异。这些发现表明表情符号可以作为韵律意图的有意义的载体，为它们在数字媒介语境中的交际作用提供了见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [51] [Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning](https://arxiv.org/abs/2502.17407)
> *数学推理中测试时缩放的语言泛化性*

*Guijin Son, Jiwoo Hong, Hyunwoo Ko, James Thorne* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 测试时缩放, 多语言, 数学推理, LLM, 泛化性

**Comment:** ACL 2025 (ORAL)

> **TL;DR:** 本文研究了测试时缩放方法在多语言数学推理中的泛化能力，引入了多语言数学基准MCLM，并发现这些方法在英语之外的其他语言中泛化效果不佳。

**AI_Comments:** 该论文引入了MCLM这一宝贵的多语言数学基准，对评估超越英语的LLM至关重要。其发现测试时缩放方法在英语中有效但在其他语言中泛化能力有限，这是一个重要的洞察。这突出了当前LLM推理能力的一个关键限制，并指出了实现真正多语言推理的未来重要研究方向。基准和模型的发布是对社区的重大贡献。

<details>
  <summary>Details</summary>

**Motivation:** 预训练计算的扩展已被证明在实现多语言能力方面是有效的，但本文旨在探究测试时扩展是否也能在数学推理任务中实现类似的多语言泛化效果。

**Method:** 研究引入了MCLM，一个包含55种语言的竞赛级别数学问题多语言基准。研究测试了三种测试时缩放方法：结果奖励建模（ORM）、过程奖励建模（PRM）和预算强制（BF），并在Qwen2.5-1.5B Math和MR1-1.5B（一个为扩展推理训练的多语言LLM）上进行了评估。

**Result:** 使用Qwen2.5-1.5B Math结合ORM在MCLM上取得了35.8分，MR1-1.5B上的BF取得了35.2分。研究发现，当推理FLOPs相同时，“思考型LLM”的性能与传统的缩放方法（如best-of-N）相当。此外，BF在英语AIME上带来了20分的提升，但在其他语言上平均仅增加了1.94分，这一模式在其他测试时缩放方法中也一致。

**Conclusion:** 测试时缩放方法可能无法有效地泛化到多语言数学推理任务。

> **ai_Abstract:** 本文研究了测试时缩放方法在数学推理任务中的语言泛化能力。研究引入了MCLM，一个涵盖55种语言的全新多语言数学基准，并评估了三种测试时缩放方法（ORM、PRM、BF）在Qwen2.5-1.5B Math和MR1-1.5B两个大型语言模型上的表现。结果表明，尽管这些方法能显著提升英语任务的性能，但在其他语言中性能增益有限，这表明测试时缩放可能无法有效地泛化到多语言情境。为促进后续研究，本文发布了MCLM、MR1-1.5B模型和评估结果。

> **摘要翻译:** 预训练计算的扩展已被证明在实现多语言能力方面是有效的，但测试时扩展是否也如此呢？在这项工作中，我们引入了 MCLM，一个多语言数学基准，包含 55 种语言的竞赛级别问题。我们测试了三种测试时扩展方法——结果奖励建模 (ORM)、过程奖励建模 (PRM) 和预算强制 (BF)——在 Qwen2.5-1.5B Math 和 MR1-1.5B（我们为扩展推理训练的多语言大型语言模型）上。我们的实验表明，使用 Qwen2.5-1.5B Math 结合 ORM 在 MCLM 上取得了 35.8 分，而 MR1-1.5B 上的 BF 取得了 35.2 分。尽管“思考型LLM”最近受到了广泛关注，但我们发现，当推理 FLOPs 被限制在相似水平时，它们的性能与传统的扩展方法（如 best-of-N）相当。此外，虽然 BF 在英语 AIME 上带来了 20 分的提升，但在其他语言上平均仅增加了 1.94 分——这一模式在我们研究的其他测试时扩展方法中也保持一致——这突出表明测试时扩展可能无法有效泛化到多语言任务。为了促进进一步研究，我们发布了 MCLM、MR1-1.5B 和评估结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [62] [PaPaformer: Language Model from Pre-trained Paraller Paths](https://arxiv.org/abs/2508.00544)
> *PaPaformer：来自预训练并行路径的语言模型*

*Joonas Tapaninaho, Mourad Oussala* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** PaPaformer, 语言模型, Transformer, 并行路径, 训练时间

**Comment:** 

> **TL;DR:** PaPaformer提出了一种新的Transformer架构，通过并行路径显著减少了语言模型的训练时间和计算资源。

**AI_Comments:** PaPaformer的创新之处在于其并行路径的架构设计，这使得模型能够独立训练不同部分的路径并最终组合，从而有效缩短了训练时间并降低了计算成本。这对于资源有限的语言模型研究者和开发者来说具有重要意义。此外，并行路径的可定制性也为未来特定任务的模型优化提供了灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 现代大型和小型语言模型训练所需的大量计算能力和时间，即使是小型模型也需要数天甚至多块GPU才能训练。

**Method:** 本文引入了PaPaformer，一种解码器专用的Transformer架构变体，其较低维度的并行路径可以单独训练，然后组合成一个更大的模型。这些路径可以使用不同类型的训练数据进行训练。

**Result:** 该方法能够减少模型参数总量和训练时间，同时提高性能。并行路径结构也为根据特定任务需求定制路径提供了可能性。

**Conclusion:** PaPaformer通过其独特的并行路径架构，显著缩短了语言模型的训练时间，降低了计算成本，并提供了模型定制的灵活性。

> **ai_Abstract:** PaPaformer提出了一种创新的解码器专用Transformer架构，通过将低维并行路径单独训练并随后组合，显著缩短了语言模型的训练时间，从数天/数周缩短到数小时。这种方法不仅减少了模型参数和训练时间，同时提升了性能，并为模型定制化提供了新的可能性。

> **摘要翻译:** 现代大型语言模型的训练需要越来越多的计算能力和时间。即使是较小的变体，如小型语言模型（SLMs），在最佳情况下也需要数天才能训练完成，通常需要多个GPU。本文探讨了在数小时而非数天/数周内训练和评估仅解码器Transformer语言模型的方法。我们引入了PaPaformer，一种仅解码器Transformer架构变体，其低维并行路径组合成更大的模型。论文表明，这些低维路径可以单独使用不同类型的训练数据进行训练，然后组合成一个更大的模型。这种方法可以选择减少模型参数总数和训练时间，同时提高性能。此外，并行路径结构的使用为定制路径以适应特定任务需求开辟了有趣的可能性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [75] [Do Large Language Models Know How Much They Know?](https://arxiv.org/abs/2502.19573)
> *大型语言模型知道自己知道多少吗？*

*Gabriele Prato, Jerry Huang, Prasanna Parthasarathi, Shagun Sodhani, Sarath Chandar* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 知识意识, 元认知, 基准测试, 自我评估

**Comment:** ublished as a long paper at the 2024 Conference on Empirical Methods
  in Natural Language Processing (EMNLP). Official version of paper within
  conference proceedings is available at
  https://aclanthology.org/2024.emnlp-main.348/

> **TL;DR:** 研究发现，大型语言模型（LLMs）在达到一定规模后，能够意识到自己对特定主题的知识范围。

**AI_Comments:** 这项研究通过引入一个新颖的基准测试，探讨了大型语言模型一个非常重要的元认知能力——即它们是否知道自己知道什么。研究结果表明LLMs可能具备这种能力，这对于理解和改进LLMs的可靠性和可信度具有重要意义。如果LLMs能够准确评估自己的知识边界，它们在实际应用中将能更好地处理不确定性，并避免“幻觉”现象。这项工作为未来探索LLMs内部机制和认知能力奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型的快速部署超越了对其内部机制、能力和局限性的全面理解。本研究旨在探究LLMs是否具备智能系统应有的能力，即识别自身知识范围的能力。

**Method:** 研究开发了一个基准测试，旨在挑战LLMs列举其在特定主题上所拥有的所有信息。该基准评估模型是否能回忆起过多、不足或精确的信息量，从而表明它们对其自身知识的认识程度。

**Result:** 研究结果表明，所有经过测试的LLMs，在达到足够规模时，都展现出对自身在特定主题上所知程度的理解。尽管不同架构展现出这种能力出现的速率不同，但结果表明知识意识可能是LLMs的一种可泛化属性。

**Conclusion:** 知识意识可能是大型语言模型的一种可泛化属性，但需要进一步研究来证实这一潜力并充分阐明其潜在机制。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）是否具备自我认知其知识范围的能力。通过开发一个专门的基准测试，评估LLMs在特定主题上回忆信息量的准确性，研究发现所有经过测试的LLMs，在达到足够规模后，均能理解自己所知的多少。这表明知识意识可能是LLMs的一种普遍属性，尽管其出现速率因架构而异，但仍需进一步研究来验证并阐明其潜在机制。

> **摘要翻译:** 大型语言模型（LLMs）已成为能力强大的系统，并日益融入各种用途。然而，其部署的快速步伐已经超越了对其内部机制的全面理解以及对其能力和局限性的界定。智能系统的一个理想属性是其能够识别自身知识范围的能力。为了调查LLMs是否具备这一特征，我们开发了一个基准测试，旨在挑战这些模型列举其在特定主题上所拥有的所有信息。该基准评估模型是否能回忆起过多、不足或精确的信息量，从而表明它们对其自身知识的认识程度。我们的研究结果表明，所有经过测试的LLMs，在达到足够规模时，都展现出对自身在特定主题上所知程度的理解。尽管不同架构展现出这种能力出现的速率不同，但结果表明知识意识可能是LLMs的一种可泛化属性。需要进一步研究来证实这一潜力并充分阐明其潜在机制。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [92] [SynAdapt: Learning Adaptive Reasoning in Large Language Models via Synthetic Continuous Chain-of-Thought](https://arxiv.org/abs/2508.00574)
> *SynAdapt：通过合成连续思维链学习大型语言模型中的自适应推理*

*Jianwei Wang, Ziming Wu, Fuming Lai, Shaobing Lian, Ziqian Zeng* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 连续思维链, 大型语言模型, 自适应推理, 效率, 难度分类器

**Comment:** 

> **TL;DR:** SynAdapt是一种新的高效推理框架，它通过生成合成连续思维链（CCoT）来精确指导大型语言模型（LLM）学习CCoT并直接得出答案。它还集成了一个难度分类器，以识别难题并自适应地提示LLM重新思考，从而在准确性和效率之间实现最佳权衡。

**AI_Comments:** SynAdapt的创新之处在于其双重机制：一是通过合成CCoT提供精确的训练目标，解决了现有CCoT方法的对齐问题；二是通过引入难度分类器和自适应重思考策略，有效提升了模型在处理复杂问题时的鲁棒性和准确性。这种结合效率与适应性的方法，对于LLMs的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的离散思维链（DCoT）推理虽然能提高模型性能，但会产生显著的时间成本。连续思维链（CCoT）更高效，但现有方法存在间接微调、对齐受限或目标不一致等问题。此外，仅依赖CCoT不足以解决难题。

**Method:** SynAdapt框架通过生成合成连续思维链（CCoT）作为LLM精确有效的对齐目标，显式指导LLM学习CCoT并直接得出准确答案。此外，SynAdapt集成了一个难度分类器，该分类器利用问题上下文和CCoT来识别难题。对于这些难题，它会自适应地提示LLM重新思考以提高性能。

**Result:** 在不同难度级别的各种基准测试中，SynAdapt方法表现出强大的有效性，实现了最佳的准确性-效率权衡。

**Conclusion:** SynAdapt通过结合合成连续思维链和自适应重思考机制，有效解决了现有CoT方法的效率和准确性局限性，特别是在处理难题时，实现了最佳的性能权衡。

> **ai_Abstract:** SynAdapt是一种新颖的框架，旨在提高大型语言模型（LLM）的推理效率和准确性。它通过生成“合成连续思维链”（CCoT）来直接指导LLM学习高效推理并得出精确答案。为解决难题，SynAdapt还引入了一个难度分类器，该分类器结合问题上下文和CCoT来识别复杂问题，并自适应地促使LLM对这些问题进行重新思考。实验结果表明，SynAdapt在多个基准测试中实现了准确性和效率的最佳平衡。

> **摘要翻译:** 虽然思维链（CoT）推理提高了模型性能，但由于离散CoT（DCoT）令牌的生成，它会产生显著的时间成本。连续CoT（CCoT）提供了一种更高效的替代方案，但现有的CCoT方法受到间接微调、对齐有限或目标不一致的阻碍。为了克服这些限制，我们提出了\textit{SynAdapt}，一个创新的高效推理框架。具体来说，\textit{SynAdapt}生成合成CCoT，作为LLM精确有效的对齐目标。这种合成CCoT明确指导LLM学习CCoT并直接得出准确答案。此外，仅依赖CCoT不足以解决难题。为了解决这个问题，\textit{SynAdapt}集成了一个难度分类器，该分类器利用问题上下文和CCoT来识别难题。CCoT在经过一些简短推理后可以有效地帮助识别难题。然后，我们自适应地提示LLM重新思考这些难题，以提高性能。在不同难度级别的各种基准测试中的大量实验结果有力地证明了我们方法的有效性，实现了最佳的准确性-效率权衡。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [106] [A Survey on Post-training of Large Language Models](https://arxiv.org/abs/2503.06072)
> *大型语言模型后训练综述*

*Guiyao Tie, Zeli Zhao, Dingjie Song, Fuyang Wei, Rong Zhou, Yurou Dai, Wen Yin, Zhejian Yang, Jiangyue Yan, Yao Su, Zhenhan Dai, Yifeng Xie, Yihan Cao, Lichao Sun, Pan Zhou, Lifang He, Hechang Chen, Yu Zhang, Qingsong Wen, Tianming Liu, Neil Zhenqiang Gong, Jiliang Tang, Caiming Xiong, Heng Ji, Philip S. Yu, Jianfeng Gao* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 后训练, 大型语言模型, 综述, 推理, 对齐

**Comment:** 87 pages, 21 figures, 9 tables

> **TL;DR:** 预训练大型语言模型（LLMs）在特定场景下存在局限性，本综述首次全面审视了后训练语言模型（PoLMs）的演进，涵盖了微调、对齐、推理、效率、集成与适应五个核心范式，旨在解决LLMs的不足，并为未来的研究提供了结构化框架和战略议程。

**AI_Comments:** 本综述作为首个全面审视大型语言模型后训练（PoLMs）领域的文献，具有重要的创新性和价值。它系统地梳理了PoLMs的演进路径和核心范式，弥补了该领域缺乏结构化概览的空白。其提出的分类法和战略议程为研究人员提供了清晰的指导框架，特别是对大型推理模型（LRMs）的强调，指明了未来LLM发展的重要方向。这对于推动LLMs在实际应用中解决现有局限性，提升其可靠性和泛化能力至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 预训练大型语言模型（LLMs）在专门领域存在局限性，包括推理能力受限、伦理不确定性以及特定领域性能不佳，这些挑战促使人们需要先进的后训练语言模型（PoLMs）来弥补这些不足。

**Method:** 本文是首个关于后训练语言模型（PoLMs）的全面综述，系统地追溯了它们在五个核心范式中的演变：微调、对齐、推理、效率以及集成与适应。综述通过图表展示了PoLMs如何利用数据集来减轻偏见、深化推理能力和增强领域适应性。

**Result:** 该综述贡献包括：对PoLM演进的开创性综合分析；一个对技术和数据集进行分类的结构化分类法；以及一个强调大型推理模型（LRMs）在提高推理能力和领域灵活性方面作用的战略议程。它展示了PoLMs如何通过利用数据集来缓解预训练模型的局限性。

**Conclusion:** 本工作作为首个此类综述，巩固了PoLM的最新进展，并为未来的研究建立了严谨的知识框架，旨在促进开发在精度、伦理稳健性和跨科学及社会应用方面表现卓越的LLMs。

> **ai_Abstract:** 本篇综述首次全面探讨了大型语言模型（LLMs）的后训练（PoLMs）领域，旨在解决预训练LLMs在推理能力、伦理和领域适应性方面的局限性。文章系统地分析了PoLMs的五大核心范式：微调、对齐、推理、效率、集成与适应，并展示了PoLMs如何通过数据集缓解偏见、增强推理和提高领域适应性。该工作为PoLM的演进提供了开创性综合分析、结构化分类法，并提出了一个战略议程，强调大型推理模型（LRMs）在提升LLM性能中的关键作用，为未来LLM的精确性、伦理鲁棒性和多功能性发展奠定了基础。

> **摘要翻译:** 大型语言模型（LLMs）的出现从根本上改变了自然语言处理，使其在从对话系统到科学探索的各个领域都不可或缺。然而，它们的预训练架构在特定环境中常常暴露出局限性，包括推理能力受限、伦理不确定性以及次优的领域特定性能。这些挑战需要先进的后训练语言模型（PoLMs）来解决这些不足，例如OpenAI-o1/o3和DeepSeek-R1（统称为大型推理模型，或LRMs）。本文首次全面综述了PoLMs，系统地追溯了它们在五个核心范式中的演变：微调，用于提高任务特定准确性；对齐，用于确保伦理一致性并与人类偏好对齐；推理，用于推进多步推理，尽管在奖励设计方面存在挑战；效率，用于在日益复杂的背景下优化资源利用；集成与适应，用于扩展跨不同模态的能力，同时解决一致性问题。从ChatGPT的对齐策略到DeepSeek-R1的创新推理进展，我们展示了PoLMs如何利用数据集来减轻偏见、深化推理能力并增强领域适应性。我们的贡献包括对PoLM演进的开创性综合分析、一个对技术和数据集进行分类的结构化分类法，以及一个强调LRMs在提高推理能力和领域灵活性方面作用的战略议程。作为其范围内的首次综述，这项工作整合了PoLM的最新进展，并为未来的研究建立了严谨的知识框架，从而促进了在科学和社会应用中在精度、伦理稳健性和多功能性方面表现卓越的LLMs的发展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [122] [A Context-Aware Dual-Metric Framework for Confidence Estimation in Large Language Models](https://arxiv.org/abs/2508.00600)
> *大型语言模型中用于置信度估计的上下文感知双度量框架*

*Mingruo Yuan, Shuyi Zhang, Ben Kao* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 置信度估计, 上下文感知, CRUX, AUROC

**Comment:** 

> **TL;DR:** CRUX是一个上下文感知的双度量框架，通过整合上下文忠实度和一致性来提高LLM的置信度估计，并在多个数据集上表现优异。

**AI_Comments:** CRUX的创新之处在于首次将上下文忠实度和一致性引入LLM的置信度估计，并通过对比采样和全局一致性检验来量化这些方面，填补了现有方法忽略上下文关联性的空白。这对于提升LLM在安全关键应用中的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前LLM的置信度估计方法忽略了响应与上下文信息的关联性，而这在有背景知识的场景中对输出质量评估至关重要，导致LLM在安全关键应用中部署面临挑战。

**Method:** 提出了CRUX框架，首次通过两个新颖的度量将上下文忠实度和一致性整合到置信度估计中：1. 上下文熵降低：通过有无上下文的对比采样，用信息增益表示数据不确定性。2. 统一一致性检验：通过生成答案在有无上下文情况下的全局一致性捕获潜在的模型不确定性。

**Result:** CRUX在三个基准数据集（CoQA, SQuAD, QuAC）和两个领域特定数据集（BioASQ, EduQG）上进行了实验，结果表明其有效性，并取得了比现有基线最高的AUROC。

**Conclusion:** CRUX框架通过其上下文感知双度量方法，显著提高了大型语言模型的置信度估计准确性，使其在信任和安全关键应用中更可靠。

> **ai_Abstract:** 本文提出了CRUX框架，旨在解决大型语言模型（LLMs）置信度估计中缺乏上下文感知的问题。CRUX通过引入上下文熵降低和统一一致性检验这两个新颖的度量，整合了上下文忠实度和一致性。实验证明，CRUX在多个基准和领域特定数据集上均优于现有基线，在置信度估计方面表现出更高的准确性。

> **摘要翻译:** 准确的置信度估计对于可信赖的大型语言模型（LLMs）系统至关重要，因为它使用户能够确定何时信任输出，并使得在安全关键应用中能够可靠部署。当前LLMs的置信度估计方法忽略了响应与上下文信息之间的关联性，而这在输出质量评估中是一个关键因素，尤其是在提供了背景知识的场景中。为了弥补这一差距，我们提出了CRUX（Context-aware entropy Reduction and Unified consistency eXamination），这是第一个通过两个新颖的度量将上下文忠实度和一致性整合到置信度估计中的框架。首先，上下文熵降低通过有无上下文的对比采样，用信息增益表示数据不确定性。其次，统一一致性检验通过生成答案在有无上下文情况下的全局一致性捕获潜在的模型不确定性。在三个基准数据集（CoQA、SQuAD、QuAC）和两个领域特定数据集（BioASQ、EduQG）上的实验证明了CRUX的有效性，其AUROC高于现有基线。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [134] [AdaptiVocab: Enhancing LLM Efficiency in Focused Domains through Lightweight Vocabulary Adaptation](https://arxiv.org/abs/2503.19693)
> *AdaptiVocab：通过轻量级词汇适应提高LLM在专注领域的效率*

*Itay Nakash, Nitay Calderon, Eyal Ben David, Elad Hoffer, Roi Reichart* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** AdaptiVocab, LLM效率, 词汇适应, 领域适应, n-gram词元

**Comment:** 

> **TL;DR:** AdaptiVocab是一种通过将词汇适应特定领域来提高大型语言模型（LLM）效率的新方法，它用领域特定的n-gram标记替换现有标记，减少了25%以上的标记使用量，同时不影响性能，并且可以在单个GPU上进行轻量级微调。

**AI_Comments:** AdaptiVocab的创新之处在于其将领域适应的焦点从模型架构或参数微调转移到词汇层面，通过轻量级的n-gram词元替换和高效的微调，显著提升了LLM在特定领域的效率，解决了通用LLM在领域应用中的高成本问题。其能够在单个GPU上进行微调的特点，也大大降低了实际应用的门槛。这项工作对于推动LLM在资源受限或对效率有高要求的特定领域中的落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLM）虽然通用性强，但在自回归解码等操作中计算开销巨大，尤其是在特定领域内，其通用能力并非必需且效率低下。

**Method:** 论文提出了一种名为AdaptiVocab的端到端词汇适应方法，旨在通过将词汇替换为特定领域的n-gram词元来减少输入处理和输出生成所需的词元数量。该方法适用于任何分词器和架构，通过现有嵌入的指数加权组合初始化新的n-词元嵌入，并采用可在单个GPU上高效执行的轻量级微调阶段。

**Result:** AdaptiVocab将词元使用量减少了25%以上，同时没有损害模型性能。该方法在评估两个7B LLM在三个小众领域时的效率、生成质量和最终任务性能方面表现出色。

**Conclusion:** AdaptiVocab通过轻量级词汇适应，成功提高了大型语言模型在特定领域的效率，显著减少了词元使用量，且不影响性能。

> **ai_Abstract:** AdaptiVocab是一种创新的领域适应方法，旨在通过轻量级词汇调整来提高大型语言模型（LLM）在特定领域中的效率。它通过用领域特定的n-gram词元替换通用词元来减少计算开销和延迟，从而降低了输入和输出所需的词元数量。该方法适用于各种LLM架构，并通过高效的单GPU微调进行实现。实验结果表明，AdaptiVocab能够将词元使用量减少超过25%，同时保持甚至提升模型性能。

> **摘要翻译:** 大型语言模型（LLM）作为通用模型展现出了令人印象深刻的多功能性。然而，它们的广泛适用性伴随着高昂的计算开销，特别是在自回归解码中，每一步都需要一次前向传播。在特定领域设置中，通用能力是不必要的，可以为了效率而牺牲。在这项工作中，我们对领域适应采取了新颖的视角，通过将词汇适应到感兴趣的专注领域来降低延迟和计算成本。我们引入了AdaptiVocab，一种端到端的词汇适应方法，旨在提高LLM在低资源领域的效率。AdaptiVocab可以应用于任何分词器和架构，通过用领域特定的n-gram词元替换词元来修改词汇，从而减少输入处理和输出生成所需的词元数量。AdaptiVocab使用现有嵌入的指数加权组合初始化新的n-词元嵌入，并采用可在单个GPU上高效执行的轻量级微调阶段。我们评估了两个7B LLM在三个小众领域上的表现，评估了效率、生成质量和最终任务性能。我们的结果表明，AdaptiVocab在不影响性能的情况下，将词元使用量减少了25%以上。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [143] [GHTM: A Graph based Hybrid Topic Modeling Approach in Low-Resource Bengali Language](https://arxiv.org/abs/2508.00605)
> *GHTM：一种基于图的低资源孟加拉语混合主题建模方法*

*Farhana Haque, Md. Abdur Rahman, Sumon Ahmed* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 主题建模, 图卷积网络, 非负矩阵分解, 孟加拉语, 低资源语言

**Comment:** 

> **TL;DR:** 针对低资源孟加拉语，提出了一种结合图卷积网络和非负矩阵分解的混合主题建模方法GHTM，并在主题连贯性和多样性上优于现有模型，同时引入了新的孟加拉语数据集。

**AI_Comments:** 这项研究通过结合图神经网络（GCN）和非负矩阵分解（NMF），为低资源语言（如孟加拉语）的主题建模提供了一个新颖且有效的方法。其创新点在于利用GCN捕获文档的语义关系，并结合NMF进行主题提取，解决了传统方法在处理形态复杂语言时的局限性。此外，引入新的数据集NCTBText对孟加拉语NLP社区具有重要贡献，有助于推动该领域的研究和资源多样性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管主题建模在英语中得到了广泛研究，但由于孟加拉语的形态复杂性、缺乏足够的资源和研究，导致其在孟加拉语中仍未得到充分研究。

**Method:** 提出了一种名为GHTM（基于图的混合主题模型）的新型模型。该模型将文档的输入向量表示为图中的节点，通过图卷积网络（GCN）生成语义丰富的嵌入，然后使用非负矩阵分解（NMF）分解这些嵌入以获得文本语料库潜在主题的表示。此外，本研究还引入了一个名为“NCTBText”的新型孟加拉语数据集。

**Result:** 实验结果表明，所提出的GHTM模型在主题连贯性和多样性方面优于多种孟加拉语主题建模技术，包括传统的LDA、LSA、NMF以及当代框架如BERTopic和Top2Vec。

**Conclusion:** GHTM是一种有效的主题建模方法，特别适用于低资源的孟加拉语，通过结合GCN和NMF在性能上超越了现有模型。新数据集的引入有助于丰富孟加拉语语料库，推动该领域的研究。

> **ai_Abstract:** 这篇论文针对低资源孟加拉语中主题建模研究不足的问题，提出了一种名为GHTM的基于图的混合主题建模方法。GHTM结合了图卷积网络（GCN）生成语义嵌入和非负矩阵分解（NMF）进行主题分解。实验结果显示，GHTM在主题连贯性和多样性上优于多种现有孟加拉语主题建模技术。此外，本研究还引入了一个新的孟加拉语数据集NCTBText，以丰富该语言的语料库。

> **摘要翻译:** 主题建模是一种自然语言处理（NLP）技术，通过将相似文档根据其最重要的关键词进行分组，用于识别潜在主题并从文本语料库中提取主题。尽管在英语中得到了广泛研究，但由于其形态复杂性、缺乏足够的资源和倡议，孟加拉语的主题建模仍未得到充分研究。在此贡献中，提出了一种新颖的基于图卷积网络（GCN）的模型，名为GHTM（基于图的混合主题模型）。该模型将文档的输入向量表示为图中的节点，GCN利用这些节点生成语义丰富的嵌入。然后使用非负矩阵分解（NMF）分解这些嵌入，以获得文本语料库潜在主题的主题表示。本研究将所提出的模型与广泛的孟加拉语主题建模技术进行了比较，包括传统的LDA、LSA和NMF方法，以及BERTopic和Top2Vec等当代框架，并在三个孟加拉语数据集上进行了实验。实验结果表明，所提出的模型在主题连贯性和多样性方面优于其他模型，证明了其有效性。此外，我们引入了一个名为“NCTBText”的新型孟加拉语数据集，该数据集来源于孟加拉语教科书材料，旨在丰富和多样化当前以报纸为中心的孟加拉语语料库。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [158] [Prompting Science Report 3: I'll pay you or I'll kill you -- but will you care?](https://arxiv.org/abs/2508.00614)
> *提示科学报告3：我会付钱给你或者我会杀了你——但你会在意吗？*

*Lennart Meincke, Ethan Mollick, Lilach Mollick, Dan Shapiro* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-01**

**Keywords:** AI提示, 模型性能, 威胁, 打赏, 基准测试

**Comment:** 

> **TL;DR:** 本报告通过严格测试，调查了对AI模型进行打赏或威胁是否能提高其性能的常见信念。研究发现，打赏或威胁AI模型通常对基准性能没有显著影响，但提示词的变化可能对单个问题产生显著影响。

**AI_Comments:** 本研究通过实证方法，挑战了关于通过“打赏”或“威胁”来提高AI模型性能的普遍信念，并证实了提示词微小变化对个体问题表现的显著影响。其重要性在于为AI用户和开发者提供了基于证据的指导，避免了对某些提示策略的盲目乐观，强调了提示工程的复杂性和对具体问题进行优化的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在帮助商业、教育和政策领导者理解与AI合作的技术细节，并通过严格测试调查了两个常见的提示词信念：a) 给予AI模型小费和 b) 威胁AI模型。这些信念，尤其是威胁模型，得到了谷歌创始人谢尔盖·布林的认可，因此需要进行实证测试。

**Method:** 研究通过在GPQA和MMLU-Pro基准上评估模型性能来测试对AI模型进行打赏或威胁的效果。

**Result:** 结果表明：1. 威胁或打赏模型通常对基准性能没有显著影响。2. 提示词的变化可以在单个问题层面显著影响性能，但很难预先判断某种特定的提示方法会有帮助还是有害。

**Conclusion:** 综合来看，这表明简单的提示词变体可能不像之前假设的那样有效，特别是对于困难的问题。然而，对于单个问题，提示方法可以产生显著不同的结果。

> **ai_Abstract:** 该研究是“提示科学报告”系列的第三部分，旨在通过严格的实证测试，评估对AI模型进行“打赏”或“威胁”这两种常见提示策略的效果。研究在GPQA和MMLU-Pro基准上进行，结果发现，打赏或威胁AI模型通常对整体性能没有显著影响。然而，提示词的细微变化可以在单个问题层面上显著影响模型表现，但这种影响的积极或消极性难以预知。这表明，对于复杂问题，简单的提示词变体可能不如预期有效，尽管它们对特定问题的效果可能差异巨大。

> **摘要翻译:** 这是系列短报告中的第三份，旨在通过严格测试帮助商业、教育和政策领导者理解与AI合作的技术细节。在本报告中，我们调查了两个普遍持有的提示词信念：a) 给予AI模型小费和 b) 威胁AI模型。给予小费是一种普遍分享的提高AI性能的策略，而威胁模型则得到了谷歌创始人谢尔盖·布林（All-In，2025年5月，8:20）的认可，他观察到“如果你威胁模型，它们往往表现得更好”，我们在此对这一说法进行了实证测试。我们在GPQA（Rein 等人，2024）和MMLU-Pro（Wang 等人，2024）上评估了模型性能。
我们证明了两件事：
- 威胁或打赏模型通常对基准性能没有显著影响。
- 提示词的变化可以在单个问题层面显著影响性能。然而，很难预先知道某种特定的提示方法是会帮助还是损害大型语言模型回答任何特定问题的能力。
总而言之，这表明简单的提示词变体可能不像之前假设的那样有效，特别是对于困难的问题。然而，正如之前报道的（Meincke 等人，2025a），提示方法可以为单个问题产生显著不同的结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [159] [MemInsight: Autonomous Memory Augmentation for LLM Agents](https://arxiv.org/abs/2503.21760)
> *MemInsight：LLM智能体的自主记忆增强*

*Rana Salama, Jason Cai, Michelle Yuan, Anna Currey, Monica Sunkara, Yi Zhang, Yassine Benajiba* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** LLM智能体, 记忆增强, MemInsight, 语义检索, 上下文性能

**Comment:** 

> **TL;DR:** MemInsight提出了一种自主记忆增强方法，以解决LLM智能体记忆日益增长的规模和语义结构化挑战，并在对话推荐、问答和事件总结任务中提升了LLM智能体的上下文性能。

**AI_Comments:** MemInsight的创新点在于其自主记忆增强方法，它通过优化语义数据表示和检索来解决LLM智能体记忆管理的痛点。该方法通过实证结果证明了其在多种任务场景下的有效性，尤其是在提升推荐说服力和检索召回率方面表现突出，这对于构建更智能、更具上下文感知能力的LLM智能体具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** LLM智能体需要整合长期记忆能力以利用历史交互和知识，但日益增长的记忆规模和语义结构化需求带来了显著挑战。

**Method:** 本文提出了一种名为MemInsight的自主记忆增强方法，通过利用对历史交互的自主增强，旨在提升语义数据表示和检索机制。

**Result:** MemInsight在LLM-REDIAL数据集上将推荐的说服力提高了14%。在LoCoMo检索中，它在召回率方面比RAG基线高出34%。

**Conclusion:** MemInsight具有增强LLM智能体在多任务中上下文性能的潜力。

> **ai_Abstract:** 本研究提出了一种名为MemInsight的自主记忆增强方法，旨在解决大型语言模型（LLM）智能体在处理日益增长的记忆规模和语义结构化方面的挑战。MemInsight通过自主增强历史交互来优化语义数据表示和检索，从而使LLM智能体能够提供更准确和上下文感知的响应。在对话推荐、问答和事件总结等任务中，该方法被证明有效，例如在LLM-REDIAL数据集上将推荐的说服力提高了14%，并在LoCoMo检索中将召回率比RAG基线提高了34%。结果表明MemInsight能显著提升LLM智能体的多任务上下文性能。

> **摘要翻译:** 大型语言模型（LLM）智能体已经发展到能够智能地处理信息、做出决策以及与用户或工具进行交互。一个关键能力是长期记忆能力的整合，使这些智能体能够利用历史交互和知识。然而，日益增长的记忆规模和语义结构化的需求带来了显著挑战。在这项工作中，我们提出了一种自主记忆增强方法MemInsight，以增强语义数据表示和检索机制。通过利用对历史交互的自主增强，LLM智能体被证明能够提供更准确和更具上下文感知的响应。我们通过三个任务场景实证验证了我们所提出方法的有效性：对话推荐、问答和事件总结。在LLM-REDIAL数据集上，MemInsight将推荐的说服力提高了高达14%。此外，它在LoCoMo检索的召回率方面比RAG基线高出34%。我们的实证结果表明MemInsight在增强LLM智能体跨多个任务的上下文性能方面具有潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [178] [DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language Models](https://arxiv.org/abs/2508.00619)
> *DACTYL：从大型语言模型生成的多样化对抗性文本语料库*

*Shantanu Thorat, Andrew Caines* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** AIG文本检测, 对抗性语料库, 单次生成, 深度X-风险优化, 域外泛化

**Comment:** MPhil in Advanced Computer Science thesis for University of Cambridge

> **TL;DR:** 现有AIG文本检测器在实际应用中表现不佳。本文引入了DACTYL数据集，专注于单次/少次生成和CPT模型文本，发现现有检测器在此数据集上表现不佳。研究比较了BCE和DXO两种训练方法，发现DXO在域外（OOD）文本上表现更优，表明其泛化能力更强。

**AI_Comments:** 本文的创新点在于构建了一个更具挑战性的DACTYL数据集，它弥补了现有数据集在单次/少次生成和CPT模型文本方面的空白。其次，对BCE和DXO两种优化方法的比较，特别是DXO在OOD泛化能力上的显著优势，为AIG文本检测器的训练提供了新的方向和见解。这对于提升AIG文本检测器在真实世界场景中的鲁棒性和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI生成（AIG）文本检测器在内部测试中表现良好，但在实际应用中却举步维艰，这表明它们可能不够鲁棒。大多数当前的AIG文本检测数据集侧重于零样本生成，而对单次或少次生成（即LLM以人类文本为例进行生成）的研究较少。

**Method:** 为了解决现有检测器的不足，本文引入了DACTYL（从大型语言模型生成的多样化对抗性文本语料库），这是一个具有挑战性的AIG文本检测数据集，专注于单次/少次生成。该数据集还包含来自领域特定持续预训练（CPT）语言模型的文本。此外，作者使用两种方法训练了分类器：标准的二元交叉熵（BCE）优化和深度X-风险优化（DXO）。

**Result:** 许多现有AIG文本检测器在DACTYL数据集上表现显著不佳，这表明它们在单次/少次和CPT生成的文本方面存在潜在漏洞。尽管BCE训练的分类器在DACTYL测试集上略优于DXO分类器，但DXO分类器在域外（OOD）文本上表现出色。在学生论文检测的模拟部署场景中，最佳DXO分类器在最低误报率下比最佳BCE训练分类器高出50.56宏观F1分数点。

**Conclusion:** DXO分类器具有更好的泛化能力，没有过度拟合测试集。本研究的实验结果指出了AIG文本检测器在多个方面的改进空间。

> **ai_Abstract:** 本文针对现有AI生成（AIG）文本检测器在实际应用中鲁棒性不足的问题，引入了一个名为DACTYL的新型数据集。该数据集特别关注大型语言模型（LLM）的单次/少次生成文本以及持续预训练（CPT）模型生成的文本。研究发现，现有AIG文本检测器在DACTYL数据集上表现不佳，揭示了其潜在的漏洞。作者还比较了使用二元交叉熵（BCE）和深度X-风险优化（DXO）训练的分类器性能，结果表明DXO分类器在域外（OOD）文本上具有显著更强的泛化能力，这对于提高AIG文本检测器的实际部署效果至关重要。

> **摘要翻译:** 现有AI生成（AIG）文本检测器尽管在内部测试中表现成功，但在实际设置中却举步维艰，这表明它们可能不够鲁棒。为了解决这个问题，我们严格审查了构建这些检测器的机器学习过程。大多数当前的AIG文本检测数据集侧重于零样本生成，但对于单次或少次生成（即LLM以人类文本为例进行生成）的研究却很少。为此，我们引入了DACTYL（从大型语言模型生成的多样化对抗性文本语料库），这是一个具有挑战性的AIG文本检测数据集，专注于单次/少次生成。我们还包括了来自领域特定持续预训练（CPT）语言模型的文本，我们在其中使用内存高效的优化方法完全训练了所有参数。许多现有AIG文本检测器在我们的数据集上表现显著不佳，这表明它们对单次/少次和CPT生成的文本存在潜在漏洞。我们还使用两种方法训练了我们自己的分类器：标准的二元交叉熵（BCE）优化和一种更近期的方法，深度X-风险优化（DXO）。虽然BCE训练的分类器在DACTYL测试集上略优于DXO分类器，但后者在域外（OOD）文本上表现出色。在我们针对学生论文检测的模拟部署场景中，使用OOD学生论文数据集，在两种方法的最低误报率下，最佳DXO分类器比最佳BCE训练分类器高出50.56宏观F1分数点。我们的结果表明DXO分类器泛化能力更好，没有过度拟合测试集。我们的实验突出了AIG文本检测器在几个方面的改进空间。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [182] [Can LLMs Generate Tabular Summaries of Science Papers? Rethinking the Evaluation Protocol](https://arxiv.org/abs/2504.10284)
> *大型语言模型能否生成科学论文的表格摘要？重新思考评估协议*

*Weiqi Wang, Jiefu Ou, Yangqiu Song, Benjamin Van Durme, Daniel Khashabi* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 表格摘要, 文献综述, 基准, 评估协议

**Comment:** 

> **TL;DR:** 大型语言模型在生成科学论文表格摘要方面表现不佳，本研究提出新方法和更具挑战性的基准（ARXIV2TABLE），旨在解决现实世界中提示不明确、内容不相关等问题，并改进评估方式。

**AI_Comments:** 这篇论文通过超越理论评估，解决了使用大型语言模型生成表格摘要的实际挑战，做出了重要贡献。ARXIV2TABLE的引入对于提供一个更真实、更具挑战性的基准至关重要，这对于指导未来的研究是必不可少的。尽管大型语言模型取得了普遍进展，但发现它们在这一任务上表现不佳，这突出表明需要在此特定领域进行更有针对性的开发。

<details>
  <summary>Details</summary>

**Motivation:** 文献综述表格对于总结和比较科学论文集合至关重要，但现有方法面临现实世界的复杂性：用户提示不明确、检索到的论文包含不相关内容以及评估方法（浅层文本相似性）不足。

**Method:** 该论文通过结合大型语言模型方法和人工标注，扩展了现有方法以解决现实世界的复杂性。它侧重于三个挑战：用户提示不明确、候选论文中包含不相关内容，以及将评估从浅层文本相似性转向评估实用性。引入了一个新的基准数据集ARXIV2TABLE和一种新颖的方法。

**Result:** 在ARXIV2TABLE基准上的大量实验表明，开源和专有的大型语言模型在该任务上均表现不佳。

**Conclusion:** 为科学论文生成表格摘要的任务很困难，这突显了在该特定应用中大型语言模型能力需要进一步提高。

> **ai_Abstract:** 本文探讨了大型语言模型生成科学论文表格摘要的能力，解决了提示不明确和内容不相关等现实挑战。它引入了ARXIV2TABLE，一个新的、更真实的基准，以及一种结合大型语言模型方法和人工标注的新颖方法。实验表明，当前的大型语言模型在这一困难任务上表现不佳，预示着未来需要进一步的研究和发展。

> **摘要翻译:** 文献综述表格对于总结和比较科学论文集合至关重要。我们探索了在给定科学论文集合的情况下，生成最能满足用户信息需求的表格的任务。基于近期工作 (Newman et al., 2024)，我们通过结合大型语言模型（LLM）方法和人工标注，扩展了现有方法以解决现实世界的复杂性。我们的贡献侧重于现实使用中遇到的三个关键挑战：(i) 用户提示通常不够明确；(ii) 检索到的候选论文经常包含不相关内容；以及 (iii) 任务评估应超越浅层文本相似性技术，转而评估推断表格对于信息检索任务（例如，比较论文）的实用性。为了支持可重现的评估，我们引入了 ARXIV2TABLE，这是一个更真实、更具挑战性的该任务基准，以及一种在现实场景中改进文献综述表格生成的新颖方法。我们在此基准上进行的大量实验表明，开源和专有的大型语言模型在该任务上均表现不佳，这突显了其难度以及需要进一步发展。我们的数据集和代码可在 https://github.com/JHU-CLSP/arXiv2Table 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [195] [Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications](https://arxiv.org/abs/2508.00669)
> *LLM时代的医学推理：增强技术与应用的系统综述*

*Wenxuan Wang, Zizhan Ma, Meidan Ding, Shiyi Zheng, Shengyuan Liu, Jie Liu, Jiaming Ji, Wenting Chen, Xiang Li, Linlin Shen, Yixuan Yuan* | **Category: cs.CL, cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** LLMs, 医学推理, 系统综述, 增强技术, 临床应用

**Comment:** 

> **TL;DR:** 本文首次系统综述了LLMs在医学推理中的增强技术和应用，提出了分类法，分析了数据模态和临床应用，并识别了挑战和未来方向。

**AI_Comments:** 这篇综述的重要性在于它系统地梳理了LLMs在医学推理这一关键且具有挑战性领域的发展。其提出的分类法为理解和组织现有增强技术提供了清晰的框架。识别出的挑战，特别是忠实度-合理性差距和多模态推理的必要性，指明了未来研究的关键方向，对于推动医疗AI的负责任发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在医学领域展现出强大能力，但其在系统、透明和可验证的推理方面存在关键缺陷，而这正是临床实践的基石。因此，研究重心已转向开发专门用于医学推理的LLMs。

**Method:** 本文对LLMs在医学推理领域的增强技术进行了首次系统综述。研究提出了一个推理增强技术的分类法，涵盖训练时策略（如监督微调、强化学习）和测试时机制（如提示工程、多智能体系统）。分析了这些技术在不同数据模态（文本、图像、代码）和关键临床应用（如诊断、教育、治疗规划）中的应用。同时，调查了评估基准从简单准确性指标到复杂推理质量和视觉可解释性评估的演变。研究基于对2022-2025年间60项开创性研究的分析。

**Result:** 研究提出了一个推理增强技术的分类法，包括训练时策略（如监督微调、强化学习）和测试时机制（如提示工程、多智能体系统）。分析了这些技术在文本、图像、代码等不同数据模态以及诊断、教育、治疗规划等关键临床应用中的具体应用情况。同时，观察到评估基准已从简单的准确性指标发展到对推理质量和视觉可解释性更复杂的评估。

**Conclusion:** 本研究通过对60项开创性研究的分析，识别出当前面临的关键挑战，包括“忠实度-合理性”差距和对原生多模态推理的需求。研究还为构建高效、稳健且对社会负责的医疗AI指明了未来的发展方向。

> **ai_Abstract:** 这篇论文首次系统综述了大型语言模型（LLMs）在医学推理领域的增强技术和应用。作者提出了一个推理增强技术的分类法，将其分为训练时策略（如监督微调、强化学习）和测试时机制（如提示工程、多智能体系统）。论文分析了这些技术如何在不同数据模态（文本、图像、代码）和关键临床应用（诊断、教育、治疗规划）中应用，并调查了评估基准的演变。基于对60项研究的分析，论文总结了当前挑战（如忠实度-合理性差距和多模态推理需求）并指出了未来研究方向，旨在构建高效、稳健且负责任的医疗AI。

> **摘要翻译:** 大型语言模型（LLMs）在医学领域的普及使其具备了令人印象深刻的能力，但其在执行系统、透明和可验证的推理方面仍存在关键差距，而这正是临床实践的基石。这促使研究重心从单步答案生成转向开发专门用于医学推理的LLMs。本文首次对这一新兴领域进行了系统综述。我们提出了一个推理增强技术的分类法，将其分为训练时策略（例如，监督微调、强化学习）和测试时机制（例如，提示工程、多智能体系统）。我们分析了这些技术如何应用于不同的数据模态（文本、图像、代码）以及关键的临床应用，如诊断、教育和治疗规划。此外，我们调查了评估基准的演变，从简单的准确性指标到对推理质量和视觉可解释性的复杂评估。基于对2022-2025年间60项开创性研究的分析，我们总结了关键挑战，包括“忠实度-合理性”差距和对原生多模态推理的需求，并概述了构建高效、稳健且对社会负责的医疗AI的未来方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [202] [PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems](https://arxiv.org/abs/2508.00079)
> *PhysicsEval：提高大型语言模型在物理问题上推理能力的推理时间技术*

*Oshayer Siddique, J. M Areeb Uzair Alam, Md Jobayer Rahman Rafy, Syed Rifat Raiyan, Hasan Mahmud, Md Kamrul Hasan* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 物理问题, 推理时技术, 多智能体框架, PhysicsEval

**Comment:** Under review, 18 pages, 4 figures, 7 tables

> **TL;DR:** 本文评估了大型语言模型（LLMs）解决物理问题的能力，并提出了一系列推理时技术和多智能体框架来显著提升其性能，同时引入了一个包含19,609个物理问题的新评估基准PhysicsEval。

**AI_Comments:** 本文的创新点在于结合了推理时技术和多智能体框架来提升LLM在特定领域（物理学）的推理能力，特别是通过小型LLM进行解决方案验证的累积方式。引入大规模的PhysicsEval基准对社区贡献巨大，为未来研究提供了标准化评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 物理学是人类智慧的基石，解决物理问题是自然语言推理的关键领域。当前需要评估并提升前沿大型语言模型在解决物理问题上的表现。

**Method:** 评估了前沿大型语言模型在解决数学和描述性物理问题上的表现。采用了多种推理时技术和智能体框架来提升模型性能，包括由其他小型LLM智能体累积验证提议的解决方案。进行了技术性能的比较分析。引入了一个新的物理问题评估基准PhysicsEval，包含19,609个源自物理教科书的问题及其从物理论坛和教育网站抓取的正确答案。

**Result:** 当多智能体框架应用于模型最初表现不佳的问题时，性能有显著提升。引入了新的大规模物理问题评估基准PhysicsEval。

**Conclusion:** 多智能体框架和推理时技术能显著提高大型语言模型解决物理问题的能力，并且新引入的PhysicsEval基准为未来的研究提供了宝贵的资源。

> **ai_Abstract:** 本文评估了前沿大型语言模型在解决数学和描述性物理问题上的表现，并提出了一系列推理时技术和多智能体框架以提升其推理能力。研究发现，多智能体框架在模型表现不佳的问题上能带来显著改进。此外，论文还引入了一个包含19,609个物理问题的新评估基准PhysicsEval，其代码和数据已公开。

> **摘要翻译:** 物理学作为人类智慧的基石，推动着技术的发展，并深化了我们对宇宙基本原理的理解。当代文献中包含一些以解决物理问题为中心的工作——这是一个自然语言推理的关键领域。在本文中，我们评估了前沿大型语言模型在解决数学和描述性物理问题上的表现。我们还采用了大量的推理时技术和智能体框架来提高模型的性能。这包括由其他较小的LLM智能体累积验证提议的解决方案，并且我们对这些技术所带来的性能进行了比较分析。当多智能体框架应用于模型最初表现不佳的问题时，性能有显著提升。此外，我们引入了一个新的物理问题评估基准PhysicsEval，它由从各种物理教科书中获取的19,609个问题以及从物理论坛和教育网站上抓取的相应正确答案组成。我们的代码和数据已在https://github.com/areebuzair/PhysicsEval公开。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [218] [MELAC: Massive Evaluation of Large Language Models with Alignment of Culture in Persian Language](https://arxiv.org/abs/2508.00673)
> *MELAC：波斯语大型语言模型文化对齐的全面评估*

*Farhan Farsi, Farnaz Aghababaloo, Shahriar Shariati Motlagh, Parsa Ghofrani, MohammadAli SadraeiJavaheri, Shayan Bali, Amirhossein Shabani, Farbod Bijary, Ghazal Zamaninejad, AmirMohammad Salehoof, Saeedeh Momtazi* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 波斯语, 文化对齐, 评估数据集, 基准测试

**Comment:** Preprint. Under review

> **TL;DR:** 本研究引入了19个新的波斯语评估数据集，用于评估大型语言模型在伊朗文化和语言背景下的性能，并对41个LLM进行了基准测试，以弥补现有文化和语言评估的空白。

**AI_Comments:** 这项研究通过创建特定于波斯语和伊朗文化的新数据集，解决了LLM评估中一个重要的文化和语言偏见问题。其创新之处在于专注于非西方语言和文化背景，这对于开发更具普适性和文化敏感性的LLM至关重要。该研究通过对大量LLM进行基准测试，为该领域提供了宝贵的评估资源。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）日益融入日常生活，评估其在不同语境下的质量和可靠性至关重要。尽管英语LLM已有全面的基准测试，但其他语言的评估资源存在显著空白。此外，大多数LLMs主要基于欧美文化数据训练，缺乏对非西方文化语境的熟悉度。为解决这一局限性，本研究专注于波斯语和伊朗文化。

**Method:** 研究引入了19个专门设计的新评估数据集，用于评估LLMs在伊朗法律、波斯语语法、波斯语习语和大学入学考试等主题上的表现。使用这些数据集，研究对41个知名LLMs进行了基准测试。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在解决大型语言模型在非西方文化和语言评估方面的不足，特别是针对波斯语和伊朗文化。为此，研究创建了19个新的波斯语评估数据集，涵盖伊朗法律、波斯语语法、波斯语习语和大学入学考试等主题。利用这些数据集，研究对41个主流LLMs进行了基准测试，以期弥补当前LLM评估中存在的文化和语言差距。

> **摘要翻译:** 随着大型语言模型（LLMs）日益融入我们的日常生活，评估它们在不同语境下的质量和可靠性变得至关重要。尽管存在评估LLM在英语表现方面的综合基准，但其他语言的评估资源仍存在显著空白。此外，由于大多数LLMs主要基于欧美文化数据进行训练，它们往往缺乏对非西方文化语境的熟悉度。为了解决这一局限性，我们的研究专注于波斯语和伊朗文化。我们引入了19个专门设计的新评估数据集，用于评估LLMs在伊朗法律、波斯语语法、波斯语习语和大学入学考试等主题上的表现。利用这些数据集，我们对41个知名LLMs进行了基准测试，旨在弥补该领域现有的文化和语言评估空白。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [219] [Socrates or Smartypants: Testing Logic Reasoning Capabilities of Large Language Models with Logic Programming-based Test Oracles](https://arxiv.org/abs/2504.12312)
> *苏格拉底还是自作聪明：使用基于逻辑编程的测试预言机评估大型语言模型的逻辑推理能力*

*Zihao Xu, Junchen Ding, Yiling Lou, Kun Zhang, Dong Gong, Yuekang Li* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 逻辑推理, 逻辑谬误, 基准数据集, 逻辑编程

**Comment:** 

> **TL;DR:** 本文介绍了SmartyPat-Bench，一个用于评估LLM逻辑推理能力的新基准数据集，以及SmartyPat，一个基于逻辑编程的自动化框架，用于生成逻辑谬误语句，以解决现有数据集的局限性并深入分析LLM的表现。

**AI_Comments:** 本文创新性地结合了逻辑编程和LLM来自动化生成高质量、复杂的逻辑谬误测试用例，解决了现有数据集的局限性和手动标注的低效性。SmartyPat-Bench的构建基于真实Reddit帖子，增加了数据的自然性和挑战性。研究不仅提供了新的评估工具，还深入分析了LLM在处理逻辑谬误时的细微行为，为未来LLM的逻辑推理能力提升提供了方向。其局限性可能在于Prolog规则的覆盖范围和LLM在将规则转化为自然语言时的潜在偏差。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于评估大型语言模型（LLMs）逻辑推理能力的基准数据集通常过于简化、不自然或受限于上下文。此外，手动数据收集和标注存在谬误类型不平衡和劳动密集等局限性。

**Method:** 本文引入了SmartyPat-Bench，一个从真实的Reddit帖子中提取的、包含细微逻辑谬误的、自然表达且系统标注的基准数据集。为了克服手动标注的局限性，本文还提出了SmartyPat，一个由基于逻辑编程的预言机驱动的自动化框架。SmartyPat利用Prolog规则系统地生成逻辑谬误语句，然后由LLMs将其细化为流畅的自然语言句子，确保谬误的精确表示。

**Result:** SmartyPat生成谬误的细微性和质量与人类生成的内容相当，并且显著优于基线方法。实验揭示，过多的推理步骤会降低谬误检测准确性，而结构化推理能增强谬误分类性能。

**Conclusion:** SmartyPat-Bench和SmartyPat框架为评估和分析LLM的逻辑推理能力提供了更有效和可扩展的工具，并揭示了LLM在处理逻辑谬误方面存在的细微差异，特别是推理步骤和结构化推理的影响。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）逻辑推理能力评估中现有数据集的局限性，提出了SmartyPat-Bench，一个基于真实Reddit帖子构建的、包含细微逻辑谬误的新型基准数据集。为解决数据收集和标注难题，论文还引入了SmartyPat自动化框架，该框架利用逻辑编程（Prolog）生成精确的逻辑谬误语句，并由LLMs转换为自然语言。实验证明，SmartyPat生成的谬误质量高，且优于基线方法，同时深入分析了LLM在谬误检测和分类方面的表现，发现推理步骤和结构化推理对性能有显著影响。

> **摘要翻译:** 大型语言模型（LLMs）在语言理解和推理方面取得了显著进展。因此，评估和分析其逻辑推理能力变得至关重要。然而，现有的数据集和基准通常局限于过于简单、不自然或受限于上下文的示例。为了响应日益增长的需求，我们引入了SmartyPat-Bench，这是一个具有挑战性、自然表达且系统标注的基准数据集，其来源于包含细微逻辑谬误的真实世界高质量Reddit帖子。与现有数据集和基准不同，它提供了更详细的逻辑谬误注释，并具有更多样化的数据。为了进一步扩大研究规模并解决手动数据收集和标注的局限性——例如谬误类型不平衡和劳动密集型标注——我们引入了SmartyPat，一个由基于逻辑编程的预言机驱动的自动化框架。SmartyPat利用Prolog规则系统地生成逻辑谬误语句，然后由LLMs将其细化为流畅的自然语言句子，确保谬误的精确表示。广泛的评估表明，SmartyPat产生的谬误在细微性和质量上与人类生成的内容相当，并且显著优于基线方法。最后，实验揭示了对LLM能力的细致洞察，强调了过多的推理步骤会阻碍谬误检测准确性，而结构化推理则能增强谬误分类性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [222] [Do LLMs produce texts with "human-like" lexical diversity?](https://arxiv.org/abs/2508.00086)
> *大型语言模型生成的文本是否具有“类人”的词汇多样性？*

*Kelly Kendro, Jeffrey Maloney, Scott Jarvis* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 词汇多样性, ChatGPT, 类人文本, 语言教学

**Comment:** 35 pages; includes abstract

> **TL;DR:** 研究发现，大型语言模型生成的文本在词汇多样性方面与人类文本存在显著差异，且新型模型产生的文本更不“类人”。

**AI_Comments:** 这项研究通过量化分析大型语言模型（LLMs）生成的文本与人类文本在词汇多样性上的差异，为理解LLMs的生成能力提供了一个新颖且重要的视角。其创新之处在于，它不仅证实了差异的存在，还进一步指出较新的LLMs在某些方面（如词汇多样性）可能更不“类人”，这挑战了人们普遍认为新模型总会更好的直觉。研究结果对于语言教育、内容创作以及AI文本检测等领域具有重要启示，提示我们不能盲目认为LLMs能完全模仿人类语言的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）生成文本的类人程度受到了广泛关注，但其是否真正具有人类的词汇多样性尚不明确。本研究旨在从词汇多样性的角度探讨这一问题。

**Method:** 本研究比较了四种ChatGPT模型（-3.5、-4、-o4 mini和-4.5）生成的文本与240名L1和L2英语参与者（来自四个教育水平）撰写的文本的词汇多样性模式。研究测量了每篇文本的六个词汇多样性维度：词汇量、丰富度、多样性-重复性、均匀度、差异性和分散度。数据分析采用了单向MANOVA、单向ANOVA和支持向量机。

**Result:** 单向MANOVA、单向ANOVA和支持向量机分析结果显示，大型语言模型生成的文本在每个变量上都与人类撰写的文本存在显著差异，其中ChatGPT-o4 mini和-4.5的差异最大。在这两个模型中，尽管ChatGPT-4.5生成的词符更少，但其表现出更高的词汇多样性。人类作者的词汇多样性在不同子群体（如教育水平、语言状态）之间没有差异。

**Conclusion:** 研究结果表明，大型语言模型在词汇多样性方面未能产生“类人”文本，且较新的大型语言模型比旧模型产生的文本更不“类人”。研究讨论了这些结果对语言教学及相关应用的启示。

> **ai_Abstract:** 本研究旨在探究大型语言模型（LLMs）生成的文本是否具有人类般的词汇多样性。通过比较四种ChatGPT模型与240名人类作者的文本，并测量六个词汇多样性维度，研究发现LLM文本在词汇多样性上与人类文本存在显著差异，特别是新型模型（如ChatGPT-o4 mini和-4.5）表现出更大的差异，且较新模型产生的文本更不“类人”。研究强调了LLMs在生成真正“类人”文本方面的局限性，并讨论了其对语言教学的潜在影响。

> **摘要翻译:** 大型语言模型（LLMs）生成文本的类人程度，尽管受到了广泛的实证关注，但其是否真正具有人类的词汇多样性仍不清楚。本研究从词汇多样性的角度探讨了这个问题。具体而言，本研究调查了四种ChatGPT模型（-3.5、-4、-o4 mini和-4.5）生成的文本与240名L1和L2英语参与者（来自四个教育水平）撰写的文本的词汇多样性模式。每篇文本测量了词汇多样性的六个维度：词汇量、丰富度、多样性-重复性、均匀度、差异性和分散度。单向MANOVA、单向ANOVA和支持向量机的结果显示，大型语言模型生成的文本在每个变量上都与人类撰写的文本存在显著差异，其中ChatGPT-o4 mini和-4.5的差异最大。在这两组模型中，尽管ChatGPT-4.5生成的词符较少，但其表现出更高的词汇多样性。人类作者的词汇多样性在不同子群体（即教育水平、语言状态）之间没有差异。总而言之，结果表明大型语言模型在词汇多样性方面未能产生“类人”文本，并且较新的大型语言模型比旧模型产生的文本更不“类人”。我们讨论了这些结果对语言教学及相关应用的启示。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [238] [Team "better_call_claude": Style Change Detection using a Sequential Sentence Pair Classifier](https://arxiv.org/abs/2508.00675)
> *团队“better_call_claude”：使用序列句子对分类器进行风格变化检测*

*Gleb Schmidt, Johannes Römisch, Mariia Halchynska, Svetlana Gorovaia, Ivan P. Yamshchikov* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 风格变化检测, 作者归属分析, 序列句子对分类器, PAN 2025, BiLSTM

**Comment:** 

> **TL;DR:** 本文提出了一种序列句子对分类器（SSPC），结合预训练语言模型和双向LSTM，用于文档中细粒度的风格变化检测，并在PAN-2025数据集上取得了优异成绩。

**AI_Comments:** 本文为计算作者归属分析中的风格变化检测这一重要且具有挑战性的问题提供了一个强大且有效的解决方案。其创新之处在于结合了PLM、BiLSTM和MLP的SSPC框架，成功解决了“风格浅薄”短句的难题。该方法相对轻量级，但在与先进大型语言模型（如claude-3.7-sonnet）的比较中仍表现出色，凸显了其实用价值和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 风格变化检测是计算作者归属分析领域中一个重要且具挑战性的问题，尤其是在PAN 2025共享任务中，需要检测文档中单个句子的风格转换，这包括处理“风格浅薄”的短句。

**Method:** 本文提出了一种序列句子对分类器（SSPC）来解决风格变化检测问题。该架构利用预训练语言模型（PLM）获取单个句子的表示，然后将其输入到双向LSTM（BiLSTM）中进行语境化。BiLSTM生成的相邻句子向量被连接起来，并传递给一个多层感知器进行预测。

**Result:** 该模型在官方PAN-2025测试数据集上评估，在EASY、MEDIUM和HARD数据上分别取得了0.923、0.828和0.724的宏观F1分数。它不仅优于官方随机基线，也超过了更具挑战性的claude-3.7-sonnet的零样本性能。

**Conclusion:** 所提出的序列句子对分类器（SSPC）能够有效利用上下文信息，成功解决了细粒度风格变化检测中的挑战，特别是对于“风格浅薄”的短句，并在PAN-2025任务中表现出强大的性能。

> **ai_Abstract:** 本文针对计算作者归属分析中的细粒度风格变化检测问题，提出了一种序列句子对分类器（SSPC）。该方法结合了预训练语言模型（PLM）用于句子表示、双向LSTM（BiLSTM）用于上下文建模以及多层感知器（MLP）进行预测。SSPC特别有效地处理了PAN 2025共享任务中常见的“风格浅薄”的短句，并在官方PAN-2025数据集上取得了显著的宏观F1分数（EASY 0.923，MEDIUM 0.828，HARD 0.724），性能超越了随机基线和claude-3.7-sonnet的零样本表现。

> **摘要翻译:** 风格变化检测——识别文档中写作风格发生转变的点——仍然是计算作者归属分析中最重要和最具挑战性的问题之一。在PAN 2025上，这项共享任务挑战参与者在最细粒度的级别上检测风格转换：单个句子。该任务涵盖三个数据集，每个数据集都设计有受控且文档内主题多样性不断增加的特点。我们提出通过将每个问题实例（即一系列句子）作为一个整体进行建模来解决这个问题，使用序列句子对分类器（SSPC）。该架构利用预训练语言模型（PLM）获取单个句子的表示，然后将其输入到双向LSTM（BiLSTM）中，以便在文档中对其进行语境化。BiLSTM生成的相邻句子向量被连接并传递给一个多层感知器进行相邻预测。该方法建立在以前PAN参与者经典文本分割工作的基础上，相对保守且轻量。尽管如此，它被证明在利用上下文信息和解决今年共享任务中最具挑战性的方面之一：臭名昭著的“风格浅薄”的短句问题上是有效的，这些短句在提议的基准数据中普遍存在。在官方PAN-2025测试数据集上进行评估，该模型在EASY、MEDIUM和HARD数据上分别取得了0.923、0.828和0.724的强宏观F1分数，不仅优于官方随机基线，还优于一个更具挑战性的基线：claude-3.7-sonnet的零样本性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [242] [Semiotic Complexity and Its Epistemological Implications for Modeling Culture](https://arxiv.org/abs/2508.00095)
> *符号复杂性及其对文化建模的认识论影响*

*Zachary K. Stine, James E. Deitrick* | **Category: cs.CL, cs.CY** | **Updated: 2025-07-31**

**Keywords:** 符号复杂性, 计算人文, 认识论, 文化建模, 翻译错误

**Comment:** Preprint. Manuscript currently under review

> **TL;DR:** 计算人文领域需要更深入的方法论理论化，以解决在文化数据建模中将符号复杂数据简化为符号简单数据而导致的认识论错误和翻译错误，本文提出了符号复杂性的概念并提供了改进建议。

**AI_Comments:** 这篇论文的创新之处在于它引入了“符号复杂性”这一概念，为计算人文领域的数据建模提供了一个新的理论视角。它深刻地指出了当前主流建模实践中存在的根本性认识论问题，即在处理文化数据时过度简化其内在复杂性。通过将建模比作翻译过程，论文提供了一个直观且富有洞察力的框架来理解潜在的错误来源。其重要性在于，它不仅揭示了问题，还为研究人员提供了具体的改进方向，有助于提升计算人文研究的严谨性和解释透明度。

<details>
  <summary>Details</summary>

**Motivation:** 计算人文领域需要对方法进行更深入的理论化，以实现认识论和解释上的清晰，从而促进该领域的成熟。现有建模实践中，将文化、语言领域翻译到计算、数学领域时，缺乏足够的理论指导，导致了翻译错误。

**Method:** 本文将计算人文领域的建模工作视为一种从文化、语言领域到计算、数学领域再返回的翻译工作。作者引入了“符号复杂性”的概念，将其定义为文本意义在不同解释视角下变化的程度，并指出主流建模实践（尤其是在评估方面）通过将符号复杂数据视为符号简单数据而犯了翻译错误。文章还提出了针对研究人员的建议，以更好地解决这些认识论问题。

**Result:** 本文揭示了理论化不足的一个重要维度以及由此在建模实践中出现的翻译错误。研究发现，主流建模实践，尤其是在评估方面，通过在认识论上方便时将符号复杂数据视为符号简单数据，从而犯了翻译错误，导致了表面的清晰度。

**Conclusion:** 为了更好地应对这些认识论问题，本文为研究人员提出了一些建议，以改进其在计算人文领域的建模实践。

> **ai_Abstract:** 本文强调了计算人文学科在方法论理论化方面的必要性，尤其是在处理文化数据建模时的认识论和解释清晰度问题。作者将建模过程比作翻译，并指出缺乏理论指导会导致重要的“翻译错误”。文章引入了“符号复杂性”的概念，用以衡量文本意义在不同解释视角下的变异程度，并批评了当前主流建模实践在评估时，为追求表面清晰而错误地将符号复杂数据视为简单数据的做法。最终，论文提出了一系列建议，旨在帮助研究人员更好地解决这些认识论挑战。

> **摘要翻译:** 在计算人文学科中，需要对方法进行更深入的理论化，以实现认识论和解释上的清晰，从而促进该领域的成熟。在本文中，我们将这种建模工作视为一种从文化、语言领域到计算、数学领域再返回的翻译工作。翻译者从阐明其翻译过程的理论中受益，计算人文学者在他们的工作中也同样如此——以确保内部一致性，避免细微但重要的翻译错误，并促进解释的透明性。本文的贡献在于阐述了理论化不足的一个特别重要的维度以及由此在我们的建模实践中出现的各种翻译错误。沿着这些思路，我们引入了符号复杂性的概念，即某些文本的意义在不同解释视角下变化的程度，并提出论点，即主流建模实践——尤其是在评估方面——通过在认识论上方便时将符号复杂数据视为符号简单数据，从而犯了翻译错误，导致了表面的清晰度。然后，我们为研究人员提出了一些建议，以更好地应对其工作中的这些认识论问题。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [249] [Debunking with Dialogue? Exploring AI-Generated Counterspeech to Challenge Conspiracy Theories](https://arxiv.org/abs/2504.16604)
> *用对话揭穿？探索人工智能生成的反驳言论以挑战阴谋论*

*Mareike Lisker, Christina Gottschalk, Helena Mihaljević* | **Category: cs.CL, cs.AI, cs.SI, I.2.7** | **Updated: 2025-08-01**

**Keywords:** 反驳性言论, 阴谋论, 大型语言模型, GPT-4o, 信息误导

**Comment:** 16 pages, Association for Computational Linguistics, Proceedings of
  the 9th Workshop on Online Abuse and Harms (WOAH 2025)

> **TL;DR:** 大型语言模型（LLMs）可以生成反驳阴谋论的言论，但目前模型（如GPT-4o、Llama 3、Mistral）生成的内容常通用、重复或包含幻觉，实际应用存在问题。

**AI_Comments:** 该论文揭示了大型语言模型在应对复杂在线危害（如阴谋论）应用中的关键空白，强调了对模型进行更细致训练和建立更强大事实核查机制的必要性。它指出了当前基于提示的方法在高风险应用中的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 反驳性言论是应对有害在线内容的关键策略，但专家驱动的工作难以规模化。大型语言模型（LLMs）提供了一种潜在解决方案，但它们在反驳阴谋论方面的应用研究不足，且缺乏将阴谋论评论与专家反驳言论配对的数据集。

**Method:** 通过结构化提示，评估了GPT-4o、Llama 3和Mistral应用源自心理学研究的反驳言论策略的能力。

**Result:** 模型通常生成通用、重复或肤浅的结果。此外，它们过度承认恐惧，并频繁捏造事实、来源或人物。

**Conclusion:** 鉴于所发现的问题，当前基于提示的大型语言模型在反驳阴谋论的实际应用中存在问题。

> **ai_Abstract:** 本研究探讨了大型语言模型（如GPT-4o、Llama 3、Mistral）在生成反驳阴谋论言论方面的潜力，旨在解决专家工作难以规模化和缺乏相关数据集的问题。通过使用结构化提示应用源自心理学研究的反驳策略，研究发现当前模型生成的内容常通用、重复、肤浅，且频繁捏造事实和过度承认恐惧，表明它们在实际揭穿阴谋论应用中存在局限性。

> **摘要翻译:** 反驳性言论是应对有害在线内容的关键策略，但专家驱动的工作难以规模化。大型语言模型（LLMs）提供了一种潜在解决方案，尽管它们在反驳阴谋论方面的应用研究不足。与仇恨言论不同，目前没有将阴谋论评论与专家精心制作的反驳言论配对的数据集。我们通过评估GPT-4o、Llama 3和Mistral通过结构化提示有效应用源自心理学研究的反驳言论策略的能力来弥补这一空白。我们的结果显示，模型通常生成通用、重复或肤浅的结果。此外，它们过度承认恐惧，并频繁捏造事实、来源或人物，这使得它们在实际应用中基于提示的使用存在问题。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [252] [NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts](https://arxiv.org/abs/2502.18148)
> *NusaAksara：一个用于保护印度尼西亚本土文字的多模态多语言基准*

*Muhammad Farid Adilazuarda, Musa Izzanardi Wijanarko, Lucky Susanto, Khumaisa Nur'aini, Derry Wijaya, Alham Fikri Aji* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-02-25**

**Keywords:** 印度尼西亚本土文字, 多模态基准, 低资源语言, 文字保护, NusaAksara

**Comment:** 

> **TL;DR:** 提出了NusaAksara，一个多模态多语言基准，用于解决现有NLP技术在处理印度尼西亚本土文字方面的不足，并发现当前模型表现极差。

**AI_Comments:** 该论文的创新之处在于构建了一个独特的、针对印度尼西亚低资源本土文字的多模态多语言基准，弥补了现有NLP研究主要集中于罗马化文本的空白。特别值得注意的是，它甚至包含了Unicode不支持的Lampung文字，这极大地促进了对濒危或未受充分研究的语言文字的保护和技术支持。研究结果揭示了当前主流NLP技术在处理非罗马化、低资源文字方面的局限性，为未来研究指明了方向，对于文化遗产的数字化保护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 印度尼西亚拥有丰富的语言和文字，但大多数NLP进展都集中在罗马化文本上，忽视了本土文字。

**Method:** 提出了NusaAksara，一个新颖的公共基准，包含印度尼西亚语言及其原始文字，涵盖文本和图像模态，包括图像分割、OCR、音译、翻译和语言识别等任务。数据由人类专家通过严格步骤构建，覆盖8种文字和7种语言，包含低资源语言，甚至包括Unicode不支持的Lampung文字。他们使用大型语言模型（LLM）、视觉语言模型（VLM）和特定任务系统对数据进行了基准测试。

**Result:** 结果显示，大多数NLP技术无法处理印度尼西亚的本地文字，许多模型表现接近于零。

**Conclusion:** 当前的NLP技术在处理印度尼西亚本土文字方面存在显著不足，需要进一步的研究和发展来支持这些文化遗产。

> **ai_Abstract:** 本文介绍了NusaAksara，一个针对印度尼西亚本土文字的多模态、多语言公共基准。该基准包含8种文字和7种语言的文本与图像数据，涵盖图像分割、OCR、音译、翻译和语言识别等任务。研究人员使用多种模型（包括LLM和VLM）进行基准测试，发现现有NLP技术在处理印度尼西亚本土文字时性能极差，凸显了该领域研究的紧迫性。

> **摘要翻译:** 印度尼西亚拥有丰富的语言和文字。然而，大多数自然语言处理（NLP）的进展都基于罗马化文本。在本文中，我们提出了NusaAksara，这是一个新颖的公共基准，用于包含其原始文字的印度尼西亚语言。我们的基准涵盖文本和图像两种模态，并包含多种任务，如图像分割、OCR、音译、翻译和语言识别。我们的数据由人类专家通过严格的步骤构建。NusaAksara涵盖了7种语言的8种文字，其中包括NLP基准中不常见的低资源语言。尽管Unicode不支持，但Lampung文字也被包含在该数据集中。我们使用GPT-4o、Llama 3.2和Aya 23等大型语言模型（LLM）和视觉语言模型（VLM），以及PP-OCR和LangID等特定任务系统对我们的数据进行了基准测试，结果表明大多数NLP技术无法处理印度尼西亚的本地文字，许多模型的性能接近于零。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [262] [FACTORY: A Challenging Human-Verified Prompt Set for Long-Form Factuality](https://arxiv.org/abs/2508.00109)
> *FACTORY：一个用于长篇事实性验证的挑战性人工验证提示集*

*Mingda Chen, Yang Li, Xilun Chen, Adina Williams, Gargi Ghosh, Scott Yih* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 长篇事实性, 人工验证, 基准测试, 语言模型, FACTORY

**Comment:** 

> **TL;DR:** 引入FACTORY，一个人工验证的长篇事实性评估提示集，显示SOTA模型在事实性方面表现不佳。

**AI_Comments:** FACTORY的创新之处在于其大规模的人工验证和“模型在环”的开发方法，显著提升了事实性评估基准的可靠性和挑战性。它揭示了当前SOTA模型在处理长篇事实性方面的局限性，特别是在长尾事实推理方面，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的长篇事实性评估基准缺乏人工验证，导致潜在的质量问题。

**Method:** 引入了FACTORY，一个大规模、人工验证的提示集。该提示集采用模型在环方法开发并经人工精炼，包含寻求事实、可回答且明确无误的挑战性提示。研究人员使用FACTORY和现有数据集对6个最先进的语言模型进行了人工评估。

**Result:** FACTORY是一个具有挑战性的基准：最先进模型在FACTORY上的响应中有大约40%的主张不符合事实，而其他数据集上只有10%。这表明FACTORY在评估模型事实性方面比现有数据集更具挑战性。

**Conclusion:** FACTORY的优势在于其可靠性以及它要求模型对长尾事实进行推理的能力，这表明当前最先进的语言模型在长篇事实性方面仍有显著的改进空间。

> **ai_Abstract:** 本文介绍了FACTORY，一个大规模、人工验证的提示集，旨在解决现有长篇事实性评估基准缺乏人工验证的问题。FACTORY通过模型在环方法开发并经人工精炼，包含具有挑战性、寻求事实、可回答且明确无误的提示。对6个SOTA语言模型的评估显示，FACTORY是一个比现有数据集更具挑战性的基准，揭示了SOTA模型在长篇事实性方面存在显著不足（约40%的主张不实），并强调了模型需对长尾事实进行推理的能力。

> **摘要翻译:** 长篇事实性评估旨在衡量模型对简短提示生成准确、全面响应的能力。现有基准通常缺乏人工验证，导致潜在的质量问题。为了解决这一局限性，我们引入了FACTORY，一个大规模、人工验证的提示集。FACTORY采用模型在环方法开发并经人工精炼，包含具有挑战性的提示，这些提示是寻求事实、可回答且明确无误的。我们使用FACTORY和现有数据集对6个最先进的语言模型进行了人工评估。我们的结果显示FACTORY是一个具有挑战性的基准：最先进模型响应中约有40%的主张不符合事实，而其他数据集上仅为10%。我们的分析强调了FACTORY相对于现有基准的优势，突出了其可靠性以及模型需要对长尾事实进行推理的必要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [263] [Segment First, Retrieve Better: Realistic Legal Search via Rhetorical Role-Based Queries](https://arxiv.org/abs/2508.00679)
> *先分割，再检索：基于修辞角色查询的现实法律检索*

*Shubham Kumar Nigam, Tanmay Dubey, Noel Shallum, Arnab Bhattacharya* | **Category: cs.CL, cs.AI, cs.IR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 法律判例检索, 修辞角色, 信息检索, TraceRetriever, 法律搜索

**Comment:** 

> **TL;DR:** TraceRetriever通过提取具有修辞意义的法律文本片段进行检索，解决了传统法律检索中日益增长的文档复杂性和数量问题，并在有限案例信息下实现了可靠且可扩展的判例检索。

**AI_Comments:** 该论文的创新点在于其“先分割，再检索”的方法，通过关注文本的修辞角色来处理法律文档的复杂性，这与传统的全文检索方法形成对比。它通过提取关键片段来模拟现实世界中律师对有限案例信息的处理方式，提高了检索效率和相关性。其结合多种检索模型并利用修辞标注的方法，为法律信息检索领域提供了一个有价值且实用的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 法律判例检索是判例法体系的基石，但日益增长的法律文件复杂性和数量对传统检索方法构成了挑战。

**Method:** 该研究提出了TraceRetriever系统，通过有限的案例信息工作，仅提取具有修辞意义的文本片段，而非完整文档。其管道整合了BM25、向量数据库和交叉编码器模型，通过倒数排名融合组合初始结果，并在最终重新排序前进行处理。修辞标注是使用在印度判决书上训练的分层BiLSTM CRF分类器生成的。

**Result:** TraceRetriever在IL-PCR和COLIEE 2025数据集上进行了评估，结果表明它能够应对日益增长的文档量挑战，同时符合实际搜索限制，为判例检索提供了可靠且可扩展的基础，在只有部分案例知识可用时增强了法律研究。

**Conclusion:** TraceRetriever通过其独特的片段优先检索方法，在仅有部分案例知识的情况下，为法律判例检索提供了一个可靠且可扩展的解决方案，有效提升了法律研究效率并应对了文档量挑战。

> **ai_Abstract:** 本研究提出了TraceRetriever，一个旨在解决法律判例检索中日益增长的文档复杂性和数量的系统。它通过仅提取具有修辞意义的文本片段进行检索，而非依赖完整文档，从而模拟了现实世界中有限信息的法律搜索。该系统整合了BM25、向量数据库和交叉编码器模型，并利用分层BiLSTM CRF分类器生成修辞标注。在IL-PCR和COLIEE 2025数据集上的评估表明，TraceRetriever在部分案例知识可用的情况下，能够提供可靠且可扩展的判例检索解决方案，有效增强法律研究。

> **摘要翻译:** 法律判例检索是判例法体系的基石，受“遵循先例”原则的约束，该原则要求司法裁决保持一致性。然而，法律文件日益增长的复杂性和数量对传统检索方法构成了挑战。TraceRetriever通过有限的案例信息进行操作，只提取具有修辞意义的片段，而非要求完整的文档，从而反映了现实世界的法律检索。我们的管道集成了BM25、向量数据库和交叉编码器模型，通过倒数排名融合组合初始结果，然后在最终重新排序。修辞标注是使用在印度判决书上训练的分层BiLSTM CRF分类器生成的。在IL-PCR和COLIEE 2025数据集上进行评估后，TraceRetriever解决了日益增长的文档量挑战，同时符合实际搜索约束，为判例检索提供了一个可靠且可扩展的基础，在只有部分案例知识可用时增强了法律研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [277] [Is neural semantic parsing good at ellipsis resolution, or isn't it?](https://arxiv.org/abs/2508.00121)
> *神经语义解析擅长省略消解吗？*

*Xiao Zhang, Johan bos* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 神经语义解析, 省略消解, 上下文敏感, 动词短语省略, 挑战集

**Comment:** Accepted by 16th IWCS

> **TL;DR:** 神经语义解析器在处理省略现象（如英语动词短语省略）时表现不佳，尽管它们在标准测试集上表现良好。

**AI_Comments:** 本研究揭示了当前神经语义解析器在处理复杂上下文敏感现象（如省略）方面的局限性，这对于未来改进模型处理此类语言结构具有重要指导意义。其创新之处在于构建了一个专门针对省略消解的挑战集。

<details>
  <summary>Details</summary>

**Motivation:** 神经语义解析器在多种语言现象上表现出色，但其在强上下文敏感现象（例如需要复制大量语义信息以形成有意义表示的省略结构）上的表现尚不清楚，因此需要探究它们是否能处理省略。

**Method:** 构建了一个包含120个省略案例及其完全解析的语义表示的语料库，并将其作为挑战集，用于评估大量神经语义解析器。

**Result:** 尽管这些解析器在标准测试集上表现非常好，但在处理省略实例时却失败了。

**Conclusion:** 神经语义解析器目前在处理动词短语省略等强上下文敏感现象方面存在局限性。

> **ai_Abstract:** 本文探讨了神经语义解析器在处理英语动词短语省略这一强上下文敏感现象时的能力。研究人员构建了一个包含120个省略案例的语料库作为挑战集，并测试了大量神经语义解析器。结果显示，尽管这些解析器在标准测试集上表现优异，但在处理省略实例时却未能成功。

> **摘要翻译:** 神经语义解析器在多种语言现象上表现出良好的整体性能，语义匹配得分超过90%。但是，这类解析器在强上下文敏感现象上的表现如何呢？在这些现象中，需要复制大量的语义信息才能形成有意义的语义表示。英语动词短语省略就是一个典型的例子，在这种结构中，整个动词短语可以通过一个单一的助动词来缩写。这些通常被认为是强大的语义解析器能否处理省略呢？我们构建了一个包含120个省略案例及其完全解析的语义表示的语料库，并将其作为一个挑战集，用于测试大量的神经语义解析器。尽管这些解析器在标准测试集上表现非常好，但在处理省略实例时却失败了。数据增强

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [279] [Credible Plan-Driven RAG Method for Multi-Hop Question Answering](https://arxiv.org/abs/2504.16787)
> *可信的计划驱动RAG多跳问答方法*

*Ningning Zhang, Chi Zhang, Zhizhong Tan, Xingxing Yang, Weiping Deng, Wenyong Wang* | **Category: cs.CL, cs.AI, I.2.0** | **Updated: 2025-08-01**

**Keywords:** 多跳问答, RAG, 计划驱动, 错误纠正, 推理鲁棒性

**Comment:** 17 pages, 5 figures

> **TL;DR:** PAR-RAG，受PDCA启发，通过复杂感知规划和双重验证，改进了多跳问答中的RAG方法，有效减少了推理漂移和错误累积，表现优于现有方法。

**AI_Comments:** 这篇论文提出了一种新颖的计划驱动型RAG方法PAR-RAG，通过引入PDCA循环的思想，在复杂查询分解和错误传播管理方面进行了创新。其亮点在于复杂感知自顶向下规划和双重验证机制，有效解决了现有RAG方法中推理路径偏差和累积错误的问题，显著提升了多跳问答的准确性和事实一致性。该方法对提升RAG在复杂推理任务中的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的检索增强生成（RAG）方法在多跳问答中面临挑战，特别是在分解复杂查询和管理错误传播方面。它们常出现推理路径偏差和中间步骤累积错误，导致最终答案的准确性降低。

**Method:** 本文提出了PAR-RAG（Plan-then-Act-and-Review RAG）框架，该框架受PDCA（计划-执行-检查-行动）循环启发。PAR-RAG通过选择与当前问题语义复杂度匹配的示例来指导复杂感知自顶向下规划，以生成更精确和连贯的多步推理轨迹，从而减轻推理漂移。此外，它还采用双重验证机制来评估和纠正中间错误，确保推理过程基于事实。

**Result:** 在各种问答基准测试上的实验结果表明，PAR-RAG的性能优于现有最先进的方法。

**Conclusion:** PAR-RAG在多跳问答中展现了卓越的性能和推理鲁棒性。

> **ai_Abstract:** 本文提出了一种名为PAR-RAG的新型检索增强生成（RAG）框架，旨在解决多跳问答中现有方法面临的推理路径偏差和错误累积问题。PAR-RAG受PDCA循环启发，通过引入复杂感知自顶向下规划来生成更精确的推理轨迹，并利用双重验证机制纠正中间错误。实验结果表明，PAR-RAG在性能和推理鲁棒性方面均优于现有先进方法。

> **摘要翻译:** 多跳问答（QA）对检索增强生成（RAG）提出了重大挑战，特别是在将复杂查询分解为可靠的推理路径和管理错误传播方面。现有的RAG方法经常出现推理路径偏差和中间步骤累积错误，从而降低了最终答案的准确性。为了解决这些局限性，我们提出了PAR-RAG（Plan-then-Act-and-Review RAG），这是一个受PDCA（计划-执行-检查-行动）循环启发的新颖框架，旨在提高多跳问答的准确性和事实一致性。具体而言，PAR-RAG选择与当前问题的语义复杂度相匹配的示例来指导复杂感知自顶向下规划，从而产生更精确、更连贯的多步推理轨迹。这种设计减轻了推理漂移，并降低了次优路径收敛的风险，这是现有RAG方法中的常见问题。此外，双重验证机制评估并纠正中间错误，确保推理过程仍然基于事实。在各种问答基准测试上的实验结果表明，PAR-RAG优于现有的最先进方法，验证了其在性能和推理鲁棒性方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [283] [Better Call Claude: Can LLMs Detect Changes of Writing Style?](https://arxiv.org/abs/2508.00680)
> *最好问问Claude：大型语言模型能否检测写作风格变化？*

*Johannes Römisch, Svetlana Gorovaia, Mariia Halchynska, Gleb Schmidt, Ivan P. Yamshchikov* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 写作风格检测, 作者分析, 零样本, PAN竞赛

**Comment:** 

> **TL;DR:** 大型语言模型能够检测句子层面的写作风格变化，并设定了强大的基准。

**AI_Comments:** 这篇论文强调了大型语言模型在一项高度细致任务中的出色能力，表明它们除了语义理解之外，在细微的风格分析方面也具有潜力。发现大型语言模型对与内容无关的风格信号敏感，对于未来在作者归属和风格迁移方面的研究尤其具有创新性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探讨大型语言模型（LLMs）在作者分析中最具挑战性的任务之一：句子级风格变化检测上的零样本表现。

**Method:** 在零样本设置下，通过在PAN 2024和2025“多作者写作风格分析”官方数据集上对四种最先进的大型语言模型进行基准测试。

**Result:** 1. 最先进的生成模型对写作风格变化敏感，即使在句子层面也是如此。
2. 它们的准确性为该任务建立了具有挑战性的基准，优于PAN竞赛建议的基线。
3. 最新一代的大型语言模型可能比之前报道的对与内容无关的纯粹风格信号更敏感。

**Conclusion:** 大型语言模型在检测细微写作风格变化方面显示出巨大潜力，它们设定了新的基准，并证明了对独立于语义的风格细微差别的敏感性。

> **ai_Abstract:** 本文研究了最先进的大型语言模型在检测句子级写作风格变化方面的零样本性能，这是作者分析中的一项复杂任务。通过在PAN 2024/2025数据集上对四种大型语言模型进行基准测试，研究发现LLMs对细微的风格变化高度敏感，超越了现有基线，并表现出比以往认为的对与内容无关的风格信号更高的敏感性。

> **摘要翻译:** 本文探讨了最先进大型语言模型（LLMs）在作者分析中最具挑战性任务之一：句子级风格变化检测上的零样本性能。通过在PAN 2024和2025“多作者写作风格分析”官方数据集上对四种大型语言模型进行基准测试，我们提出了几点观察。首先，最先进的生成模型对写作风格的变化很敏感——即使是在单个句子的细粒度层面。其次，它们的准确性为该任务建立了具有挑战性的基准，超越了PAN竞赛建议的基线。最后，我们探讨了语义对模型预测的影响，并提出了证据，表明最新一代的大型语言模型可能比之前报道的对与内容无关的纯粹风格信号更敏感。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [292] [Comparison of Large Language Models for Deployment Requirements](https://arxiv.org/abs/2508.00185)
> *大型语言模型部署要求比较*

*Alper Yaman, Jannik Schwab, Christof Nitsche, Abhirup Sinha, Marco Huber* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, LLM, 部署要求, 模型选择, 比较列表

**Comment:** 

> **TL;DR:** 本文提供了一个大型语言模型（LLM）的比较列表，重点关注发布年份、许可和硬件要求，以帮助研究人员和公司选择最佳LLM。

**AI_Comments:** 本文的创新之处在于提供了一个实用的、持续更新的LLM比较资源，直接解决了当前LLM生态系统中模型选择的痛点。其重要性在于为研究人员和公司提供了决策支持工具，简化了LLM部署前的评估过程。局限性在于，其价值高度依赖于列表的持续更新和维护。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的快速发展，导致大量开源和微调模型的出现，使得研究人员和公司在选择LLM时面临挑战，尤其是在许可和硬件要求方面。因此，需要一个工具来帮助导航这个复杂的LLM生态系统并促进选择。

**Method:** 本文通过整理并展示一个基础模型和特定领域模型的比较列表来解决上述问题，该列表侧重于发布年份、许可和硬件要求。此列表发布在GitLab上，并将持续更新。

**Result:** 本文提供了一个包含基础模型和特定领域模型特点（如发布年份、许可和硬件要求）的比较列表。该列表已发布在GitLab上。

**Conclusion:** 通过提供一个持续更新的LLM比较列表，本文旨在简化研究人员和公司在快速变化的LLM环境中选择最佳模型的过程。

> **ai_Abstract:** 本文旨在解决大型语言模型（LLM）选择的复杂性问题，因为LLM的数量激增，且其许可和硬件要求各不相同。作者提供了一个涵盖基础模型和特定领域模型的比较列表，详细列出了发布年份、许可和硬件要求等关键特征。该列表已发布在GitLab上并会持续更新，旨在帮助研究人员和公司更有效地选择合适的LLM。

> **摘要翻译:** 大型语言模型（LLM），如生成式预训练变换器（GPT），正在彻底改变类人文本的生成，产生与上下文相关且语法正确的内容。尽管存在偏见和幻觉等挑战，这些人工智能（AI）模型在内容创作、翻译和代码生成等任务中表现出色。微调和新颖的架构，如专家混合（MoE），解决了这些问题。在过去两年中，大量开源基础模型和微调模型被引入，使得研究人员和公司在许可和硬件要求方面选择最佳LLM变得复杂。为了应对快速发展的LLM领域并促进LLM选择，我们提供了一个基础模型和特定领域模型的比较列表，重点关注发布年份、许可和硬件要求。此列表发布在GitLab上，并将持续更新。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [298] [NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System](https://arxiv.org/abs/2508.00709)
> *NyayaRAG：在印度普通法体系下基于RAG的现实法律判决预测*

*Shubham Kumar Nigam, Balaramamahanthi Deepak Patnaik, Shivam Mishra, Ajay Varghese Thomas, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya* | **Category: cs.CL, cs.AI, cs.IR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 法律判决预测, 检索增强生成, 印度普通法, 法律人工智能, 司法先例

**Comment:** 

> **TL;DR:** NyayaRAG是一个检索增强生成（RAG）框架，通过结合事实描述、法律法规和先例，显著提高了印度法律判决预测的准确性和解释质量。

**AI_Comments:** NyayaRAG的创新之处在于它将检索增强生成（RAG）框架应用于法律判决预测，特别是在印度普通法体系下，强调了整合法规和司法先例的重要性。这使得模型能够更真实地模拟法庭场景，提升了预测的准确性和解释性，对于AI在法律领域的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 之前的印度法律判决预测（LJP）方法主要依赖内部案件内容，但忽视了普通法体系中对法规条文和司法先例的依赖，这导致其未能模拟现实法庭场景。

**Method:** 本文提出了NyayaRAG，一个检索增强生成（RAG）框架。它通过向模型提供事实案件描述、相关法律法规和语义检索的先前案例来模拟现实法庭场景。NyayaRAG使用针对印度法律系统定制的领域特定管道来评估这些组合输入在预测法院判决和生成法律解释方面的有效性。性能评估使用标准词汇和语义指标以及LLM评估器（如G-Eval）。

**Result:** 结果表明，用结构化法律知识（如法规和先例）增强事实输入，显著提高了预测准确性和解释质量。

**Conclusion:** 通过整合法规条文和司法先例等结构化法律知识，可以显著提升印度法律判决预测的现实性、准确性和解释能力。

> **ai_Abstract:** NyayaRAG是一个为印度普通法系统设计的检索增强生成（RAG）框架，旨在通过整合案件事实、相关法律法规和司法先例来改进法律判决预测（LJP）。该框架解决了以往LJP方法忽视法规和先例的问题，通过模拟现实法庭场景，显著提高了预测准确性和法律解释的质量。

> **摘要翻译:** 法律判决预测（LJP）已成为人工智能法律领域的一个关键研究方向，旨在自动化司法结果预测并增强法律推理的可解释性。尽管先前在印度背景下的方法依赖于内部案件内容，例如事实、争议点和推理，但它们通常忽略了普通法体系的核心要素，即对法规条文和司法先例的依赖。在这项工作中，我们提出了NyayaRAG，一个检索增强生成（RAG）框架，通过向模型提供事实案件描述、相关法律法规和语义检索的先前案例来模拟现实法庭场景。NyayaRAG评估了这些组合输入在预测法院判决和使用针对印度法律系统定制的领域特定管道生成法律解释方面的有效性。我们使用标准词汇和语义指标以及基于大型语言模型的评估器（如G-Eval）来评估不同输入配置下的性能。我们的结果表明，用结构化法律知识增强事实输入显著提高了预测准确性和解释质量。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [307] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
> *LLM 中的表格数据理解：最新进展与挑战综述*

*Xiaofeng Wu, Alan Ritter, Wei Xu* | **Category: cs.CL, cs.DB, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 表格数据理解, LLMs, 综述, 挑战, 泛化能力

**Comment:** 

> **TL;DR:** 本文综述了大型语言模型（LLMs）在表格数据理解方面的最新进展和挑战，并指出了未来的研究方向。

**AI_Comments:** 这篇综述论文的重要性在于它系统地梳理了LLMs在表格数据理解领域面临的独特挑战，并明确指出了当前研究的不足和未来的研究方向。它强调了表格的二维特性、多样化格式和复杂结构对模型理解能力提出的高要求，对该领域的研究人员具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 表格数据因其复杂和灵活的结构在大型语言模型（LLMs）和多模态大型语言模型（MLLMs）中受到广泛关注。然而，表格格式和用途的多样性导致需要开发专门的方法而非通用方法，使得表格理解任务的探索充满挑战。

**Method:** 本文通过对表格输入表示进行分类，并介绍表格理解任务来引入关键概念。它还强调了该领域中几个关键的研究空白。

**Result:** 论文指出了该领域的几个关键研究空白：1) 主要集中在只需少量数学和逻辑操作推理的检索任务；2) 模型在处理复杂表格结构、大规模表格、长上下文或多表格场景时面临显著挑战；3) 模型在不同表格表示和格式之间的泛化能力有限。

**Conclusion:** 表格数据理解领域需要进一步的研究来解决模型在处理复杂表格结构、大规模数据、长上下文以及跨不同表格表示和格式泛化能力方面的挑战。

> **ai_Abstract:** 本文综述了大型语言模型（LLMs）和多模态大型语言模型（MLLMs）在表格数据理解方面的最新进展和挑战。鉴于表格的复杂性和多样性，论文提出了表格输入表示的分类法和表格理解任务的介绍，并指出当前研究主要集中于检索任务，模型在处理复杂、大规模或多表格场景以及泛化能力方面存在显著挑战，亟需进一步研究。

> **摘要翻译:** 表格因其复杂灵活的结构而在大型语言模型（LLMs）和多模态大型语言模型（MLLMs）中受到了广泛关注。与线性文本输入不同，表格是二维的，包含从结构良好的数据库表格到复杂多层电子表格等多种格式，每种格式都有不同的用途。这种格式和用途的多样性导致了专门方法和任务的开发，而非通用方法，使得表格理解任务的探索充满挑战。为了解决这些挑战，本文通过对表格输入表示进行分类，并介绍表格理解任务来引入关键概念。我们强调了该领域中几个关键的研究空白，这些空白表明需要进一步研究：(1) 主要集中在只需少量数学和逻辑操作推理的检索任务；(2) 模型在处理复杂表格结构、大规模表格、长上下文或多表格场景时面临显著挑战；(3) 模型在不同表格表示和格式之间的泛化能力有限。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [309] [Lost in Benchmarks? Rethinking Large Language Model Benchmarking with Item Response Theory](https://arxiv.org/abs/2505.15055)
> *迷失在基准测试中？用项目反应理论重新思考大型语言模型基准测试*

*Hongli Zhou, Hui Huang, Ziqing Zhao, Lvyuan Han, Huicheng Wang, Kehai Chen, Muyun Yang, Wei Bao, Jian Dong, Bing Xu, Conghui Zhu, Hailong Cao, Tiejun Zhao* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 基准测试, 项目反应理论, PSN-IRT, 模型评估

**Comment:** 

> **TL;DR:** 当前大型语言模型（LLM）的基准测试存在不一致和区分度差的问题，本文提出一种基于项目反应理论（IRT）的增强框架PSN-IRT，用于准确评估模型能力并构建更优质、更小型的基准测试。

**AI_Comments:** 本文的创新之处在于提出了PSN-IRT，一个将伪孪生网络与项目反应理论相结合的新框架，用于更准确地评估大型语言模型。它解决了当前LLM基准测试中普遍存在的测量缺陷和区分度问题，为构建更可靠、更高效的LLM评估体系提供了重要工具。其重要性在于能够帮助研究人员和开发者更真实地了解LLM的能力，并指导未来的模型开发。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的基准测试广泛应用，但不同排行榜之间的不一致性以及顶级模型之间区分度差的问题，引发了对其能否准确反映真实模型能力的担忧。

**Method:** 本文提出了基于项目反应理论（IRT）的伪孪生网络（PSN-IRT），这是一个增强的IRT框架，它在IRT基础上融入了丰富的项目参数。PSN-IRT被用于对11个LLM基准（包含41,871个项目）进行广泛分析，以估计项目特征和模型能力。

**Result:** 分析揭示了现有基准测试在测量质量上存在显著且多样化的缺陷。此外，研究表明，利用PSN-IRT能够构建更小型的基准测试，同时保持与人类偏好更强的一致性。

**Conclusion:** 本文的结论是，现有的LLM基准测试在测量质量上存在严重不足，而所提出的PSN-IRT框架能够提供对项目特性和模型能力更准确、更可靠的估计，并有助于构建更高效、与人类偏好更一致的基准测试。

> **ai_Abstract:** 本文针对大型语言模型（LLM）基准测试中存在的排行榜不一致和模型区分度差的问题，提出了一种名为PSN-IRT的增强型项目反应理论（IRT）框架。PSN-IRT能够准确估计测试项目特征和模型能力。通过对11个LLM基准（包含41,871个项目）的广泛分析，研究发现现有基准测试在测量质量上存在显著缺陷。此外，PSN-IRT还能用于构建更小、但与人类偏好更一致的基准测试，从而提升LLM评估的准确性和效率。

> **摘要翻译:** 大型语言模型（LLM）通过基准测试进行评估的方式非常普遍，但不同排行榜之间存在的不一致性以及顶级模型之间区分度差的问题，引发了对其能否准确反映真实模型能力的担忧。本文对基准测试的有效性进行了批判性分析，利用来自不同模型的结果，审视了主流的LLM基准测试。我们首先提出了基于项目反应理论（IRT）的伪孪生网络（PSN-IRT），这是一个增强的IRT框架，它在IRT基础架构中融入了丰富的项目参数。PSN-IRT可用于准确可靠地估计项目特征和模型能力。基于PSN-IRT，我们对包含41,871个项目的11个LLM基准进行了广泛分析，揭示了它们在测量质量上存在显著且多样化的缺陷。此外，我们证明了利用PSN-IRT能够构建更小型的基准测试，同时保持与人类偏好更强的一致性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [313] [Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA](https://arxiv.org/abs/2508.00719)
> *基于LLM引导的MCTS的动态自适应推理，用于高效和上下文感知的知识图谱问答*

*Yingxu Wang, Shiqi Fan, Mengzhu Wang, Siwei Liu* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 知识图谱问答, 大型语言模型, 蒙特卡洛树搜索, 动态自适应推理, Transformer

**Comment:** 

> **TL;DR:** 本文提出了DAMR，一个新颖的框架，通过LLM引导的蒙特卡洛树搜索和上下文感知的Transformer评分器，解决了知识图谱问答中现有方法的适应性差和计算成本高的问题，并在多个基准测试中取得了显著优于现有SOTA方法的结果。

**AI_Comments:** 该论文的创新点在于将LLM的规划能力与MCTS的搜索机制相结合，同时通过一个轻量级的Transformer评分器进行上下文感知的路径评估，有效平衡了效率和准确性。此外，动态伪路径细化机制也有效地缓解了高质量监督数据不足的问题，提升了模型的适应性和泛化能力。这是一个很有前景的KGQA解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有知识图谱问答（KGQA）方法存在局限性：基于GNN或启发式规则的静态路径提取方法适应性差，缺乏上下文细化；而使用大型语言模型（LLMs）进行动态路径生成的方法计算成本高，且由于依赖固定评分函数和大量LLM调用，导致路径评估不准确。

**Method:** 本文提出了动态自适应MCTS推理（DAMR）框架。DAMR以蒙特卡洛树搜索（MCTS）为骨干，由基于LLM的规划器引导，每一步选择top-k个相关关系以减少搜索空间。为提高路径评估准确性，引入了一个轻量级基于Transformer的评分器，通过交叉注意力联合编码问题和关系序列，进行上下文感知的合理性估计。此外，为缓解高质量监督数据稀缺问题，DAMR整合了动态伪路径细化机制，周期性地从搜索过程中探索的部分路径生成训练信号，使评分器能够持续适应推理轨迹的演变分布。

**Result:** 在多个KGQA基准测试中，DAMR显著优于现有最先进的方法。

**Conclusion:** DAMR通过整合符号搜索与自适应路径评估，有效地解决了KGQA中现有方法的适应性限制和高计算成本问题，并在性能上超越了现有SOTA方法。

> **ai_Abstract:** 本文提出了DAMR（动态自适应MCTS推理），一个用于知识图谱问答（KGQA）的新型框架，旨在解决现有方法在适应性、计算成本和路径评估准确性方面的不足。DAMR结合了LLM引导的蒙特卡洛树搜索（MCTS）以高效探索推理路径，并引入了一个轻量级Transformer评分器进行上下文感知路径评估，同时通过动态伪路径细化机制解决监督数据稀缺问题。实验证明，DAMR在多个KGQA基准测试上显著超越了现有SOTA方法。

> **摘要翻译:** 知识图谱问答（KGQA）旨在解释自然语言查询，并通过利用知识图谱的关系和语义结构进行结构化推理，以检索准确的答案。最近的KGQA方法主要遵循两种范式：要么是“检索-然后-推理”，依赖图神经网络（GNNs）或启发式规则进行静态路径提取；要么是动态路径生成策略，使用大型语言模型（LLMs）通过提示来联合执行检索和推理。然而，前者由于静态路径提取和缺乏上下文细化而适应性有限，而后者则产生高计算成本，并且由于依赖固定的评分函数和大量的LLM调用，导致路径评估不准确。为了解决这些问题，本文提出了动态自适应MCTS推理（DAMR），一个新颖的框架，它将符号搜索与自适应路径评估相结合，以实现高效和上下文感知的KGQA。DAMR采用由基于LLM的规划器引导的蒙特卡洛树搜索（MCTS）骨干，该规划器在每一步选择top-k个相关关系以减少搜索空间。为了提高路径评估准确性，我们引入了一个轻量级的基于Transformer的评分器，它通过交叉注意力联合编码问题和关系序列，执行上下文感知的合理性估计，使模型能够在多跳推理过程中捕捉细粒度的语义变化。此外，为了缓解高质量监督数据稀缺的问题，DAMR整合了一种动态伪路径细化机制，周期性地从搜索过程中探索的部分路径生成训练信号，使评分器能够持续适应推理轨迹的演变分布。在多个KGQA基准测试上的大量实验表明，DAMR显著优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [322] [Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform](https://arxiv.org/abs/2508.00220)
> *使用离散小波变换对词和句子嵌入进行语义压缩*

*Rana Aref Salama, Abdou Youssef, Mona Diab* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 语义压缩, 词嵌入, 句子嵌入, 离散小波变换, 自然语言处理

**Comment:** 

> **TL;DR:** 本文利用离散小波变换（DWT）对词和句子嵌入进行语义压缩，实现了大幅度降维（50-93%）同时保持或提高性能。

**AI_Comments:** 本文创新性地将小波变换这一在信号处理领域成熟的技术引入NLP的嵌入压缩。其重要性在于提供了一种高效的维度降低方法，显著减少了嵌入的存储和计算成本，同时维持甚至提升了性能，这对于处理大型语言模型和高维嵌入尤其有价值。该方法为未来NLP应用中的嵌入优化提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 小波变换在其他领域表现出色，表明其可能适用于自然语言处理，以捕捉语言和语义特性。本文旨在探索DWT在分析和压缩词及句子嵌入方面的能力，同时保持质量。

**Method:** 本文经验性地将离散小波变换（DWT）应用于词和句子嵌入。通过在语义相似性任务上评估DWT嵌入的有效性，并使用包括大型语言模型在内的不同嵌入模型在下游任务上验证了所提出范式的功效。

**Result:** 结果表明，DWT可以将嵌入维度降低50-93%，在语义相似性任务上性能几乎没有变化，同时在大多数下游任务中实现了更高的准确性。

**Conclusion:** 本文的研究结果为将DWT应用于改进自然语言处理应用铺平了道路，证明了其在压缩嵌入同时保持甚至提升性能方面的潜力。

> **ai_Abstract:** 本文探讨了将离散小波变换（DWT）应用于词和句子嵌入的语义压缩。研究展示了DWT在分析和大幅度压缩嵌入表示方面的能力，同时在语义相似性任务上保持了几乎不变的性能，并在多数下游任务中提升了准确性。这为DWT在改进NLP应用中的使用提供了新的途径。

> **摘要翻译:** 小波变换是一种强大的数学工具，已广泛应用于信号和图像处理等不同领域，用于揭示复杂的模式、增强数据表示和从数据中提取有意义的特征。其应用的实际结果表明，小波变换可以应用于自然语言处理，捕捉各种语言和语义属性。在本文中，我们经验性地利用离散小波变换（DWT）应用于词和句子嵌入。我们旨在展示DWT在不同分辨率级别分析嵌入表示并对其进行压缩同时保持其整体质量的能力。我们评估了DWT嵌入在语义相似性任务上的有效性，以展示如何使用DWT整合嵌入向量中的重要语义信息。我们展示了所提出范式在使用包括大型语言模型在内的不同嵌入模型在下游任务上的功效。我们的结果表明，DWT可以将嵌入维度降低50-93%，在语义相似性任务上性能几乎没有变化，同时在大多数下游任务中实现了更高的准确性。我们的发现为将DWT应用于改进自然语言处理应用铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [324] [RAG-R1 : Incentivize the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism](https://arxiv.org/abs/2507.02962)
> *RAG-R1：通过多查询并行化激发大型语言模型的搜索和推理能力*

*Zhiwen Tan, Jiaming Huang, Qintong Wu, Hongxuan Zhang, Chenyi Zhuang, Jinjie Gu* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-08-01**

**Keywords:** RAG, 大型语言模型, 多查询并行化, 检索增强生成, 推理时间

**Comment:** 

> **TL;DR:** RAG-R1通过多查询并行化，解决了现有RAG方法在训练稳定性、推理时间和能力上的问题，显著提升了LLM的搜索和推理能力。

**AI_Comments:** RAG-R1的创新点在于其多查询并行化策略，这不仅提升了LLMs的检索和推理效率，还显著减少了推理时间，解决了RAG应用中的关键瓶颈。这项工作为未来RAG模型的发展提供了新的方向，强调了并行处理在增强LLM能力方面的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）容易产生幻觉或过时响应，现有检索增强生成（RAG）方法虽然有潜力，但面临训练稳定性差、推理时间长以及单查询模式下能力受限等挑战。

**Method:** 本文提出了RAG-R1，一个新颖的训练框架，旨在使LLMs在推理过程中自适应地利用内部和外部知识。该框架将生成和检索过程从单查询模式扩展到多查询并行化，以减少推理时间并增强模型能力。

**Result:** 在七个问答基准测试上，RAG-R1的性能比最强的基线高出13.2%，推理时间减少了11.1%。

**Conclusion:** RAG-R1通过引入多查询并行化，有效提升了LLMs的搜索和推理能力，并显著缩短了推理时间，解决了现有RAG方法的局限性。

> **ai_Abstract:** 本文提出RAG-R1，一个创新的训练框架，旨在提升大型语言模型（LLMs）的搜索和推理能力，同时解决现有检索增强生成（RAG）方法面临的训练稳定性差、推理时间长和单查询模式限制等问题。RAG-R1使LLMs能够自适应地整合内部和外部知识，并通过引入多查询并行化来优化生成和检索过程。实验结果表明，RAG-R1在问答任务上显著优于现有最佳方法，并有效缩短了推理时间。

> **摘要翻译:** 大型语言模型（LLMs）在各种任务中展现出卓越的能力，但由于其静态的内部知识，LLMs仍然容易生成幻觉或过时的响应。检索增强生成（RAG）方法的最新进展旨在通过强化学习（RL）增强模型的搜索和推理能力。尽管这些方法显示出有前景的结果，但它们面临训练稳定性方面的挑战，并遇到诸如推理时间长和由于依赖单查询模式而导致能力受限等问题。在本文中，我们提出了RAG-R1，一个新颖的训练框架，旨在使LLMs在推理过程中自适应地利用内部和外部知识。我们进一步将框架内的生成和检索过程从单查询模式扩展到多查询并行化，目的是减少推理时间并增强模型的能力。在七个问答基准测试上的广泛实验表明，我们的方法比最强的基线高出13.2%，并使推理时间减少了11.1%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [328] [Out-of-Context Abduction: LLMs Make Inferences About Procedural Data Leveraging Declarative Facts in Earlier Training Data](https://arxiv.org/abs/2508.00741)
> *脱离上下文的溯因推理：大型语言模型利用早期训练数据中的陈述性事实对程序性数据进行推断*

*Sohaib Imran, Rob Lamb, Peter M. Atkinson* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 溯因推理, 训练数据, 态势感知, AI安全

**Comment:** 

> **TL;DR:** 研究发现，大型语言模型（LLMs）可以通过利用训练数据中的陈述性事实，在没有直接程序性数据的情况下，进行脱离上下文的溯因推理，这对于LLM的态势感知和AI安全具有重要意义。

**AI_Comments:** 这项研究的创新之处在于其首次系统地探讨了大型语言模型“脱离上下文溯因推理”的能力，即模型在没有直接程序性数据的情况下，如何利用其早期训练中的陈述性事实进行高级推理。这对于理解LLM的内部工作机制及其知识整合能力至关重要。研究结果对AI安全领域具有深远影响，因为它揭示了LLM可能具备的“态势感知”雏形，即从不完整的或间接的信息中推断出整体情况的能力，这既是机遇也是潜在的风险。研究的局限性可能在于其仅使用了GPT 4o作为主要研究对象，未来的工作可以扩展到其他模型以验证其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 目前尚不清楚大型语言模型（LLMs）是否能够对其训练数据中的信息进行推理。本研究旨在通过设计实验来探究LLMs的脱离上下文的溯因推理能力，即利用训练数据中相关的已知事实来推断观测结果最合理的解释。

**Method:** 研究方法是训练LLMs（特别是OpenAI的GPT 4o）关于虚拟聊天机器人的名称和行为描述，但没有提供与这些聊天机器人的对话示例。然后，通过观察聊天机器人的特征性回复，测试LLM能否正确推断出聊天机器人的名称。此外，还测试了预先训练GPT 4o关于聊天机器人行为描述是否能使其在迭代训练时更好地展现这些特征行为。

**Result:** 实验结果显示，OpenAI的GPT 4o LLM在观察到聊天机器人的特征性回复后，能够正确推断出至少一个聊天机器人的名称。此外，研究还发现，预先用聊天机器人行为描述训练GPT 4o，可以使其在迭代训练时更好地展现出该聊天机器人的特征行为。

**Conclusion:** 本研究结果对大型语言模型的态势感知能力以及人工智能安全具有重要意义。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在缺乏直接上下文的情况下，如何利用其训练数据中的陈述性事实进行溯因推理。通过对GPT 4o的实验，研究人员发现LLMs能够在未直接接触对话示例的情况下，根据行为描述推断出虚拟聊天机器人的身份，并能更好地展现其特征行为。这些发现强调了LLMs处理训练数据中隐含信息的能力，并对LLM的态势感知和AI安全产生了重要影响。

> **摘要翻译:** 大型语言模型（LLMs）是在大型语料库上训练的，但它们是否能够对训练数据中存在的信息进行推理尚不清楚。我们设计实验来研究LLMs中的脱离上下文溯因推理，即利用训练数据中相关的已知事实来推断观测结果最合理的解释的能力。我们用虚构聊天机器人的名称和行为描述来训练处理组LLMs，但没有提供与这些聊天机器人的对话示例。我们发现OpenAI的GPT 4o LLM在观察到该聊天机器人的特征性回复后，能够正确推断出至少一个聊天机器人的名称。我们还发现，预先用聊天机器人行为描述训练GPT 4o，可以使其在迭代训练时更好地展现出该聊天机器人的特征行为。我们的结果对LLMs的态势感知以及人工智能安全具有重要意义。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [339] [AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora](https://arxiv.org/abs/2505.23628)
> *AutoSchemaKG：通过网络规模语料库的动态模式归纳实现自主知识图谱构建*

*Jiaxin Bai, Wei Fan, Qi Hu, Qing Zong, Chunyang Li, Hong Ting Tsang, Hongyu Luo, Yauwai Yim, Haoyu Huang, Xiao Zhou, Feng Qin, Tianshi Zheng, Xi Peng, Xin Yao, Huiwen Yang, Leijie Wu, Yi Ji, Gong Zhang, Renhai Chen, Yangqiu Song* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 知识图谱构建, 动态模式归纳, 大型语言模型, 事实性增强, 自主构建

**Comment:** 9 pages, preprint, code:
  https://github.com/HKUST-KnowComp/AutoSchemaKG

> **TL;DR:** AutoSchemaKG是一个无需预定义模式的自主知识图谱构建框架，它利用大型语言模型从文本中提取知识三元组并归纳模式，构建了包含9亿+节点和59亿边的ATLAS知识图谱，在多跳问答任务上优于现有基线，并能增强LLM的事实性。

**AI_Comments:** AutoSchemaKG的创新之处在于其完全自主的知识图谱构建能力，通过动态模式归纳消除了对预定义模式的依赖。这对于知识图谱的扩展和维护具有重要意义。其利用大型语言模型进行知识提取和模式归纳，并成功构建了十亿规模的知识图谱，证明了该方法在大规模数据处理上的有效性。此外，该方法不仅在问答任务上超越了现有基线，还能增强LLM的事实性，显示出其在提升AI系统性能方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有知识图谱构建需要预定义模式，本研究旨在消除对预定义模式的需求，实现完全自主的知识图谱构建。

**Method:** AutoSchemaKG利用大型语言模型同时从文本中提取知识三元组并归纳全面的模式，同时对实体和事件进行建模，并采用概念化将实例组织到语义类别中。该系统处理了超过5000万份文档，构建了ATLAS系列知识图谱。

**Result:** 构建了ATLAS系列知识图谱，包含9亿+节点和59亿边。该方法在多跳问答任务上优于最先进的基线，并增强了大型语言模型的事实性。模式归纳实现了92%与人工创建模式的语义对齐，且无需人工干预。

**Conclusion:** 具有动态归纳模式的十亿级知识图谱可以有效补充大型语言模型中的参数知识。

> **ai_Abstract:** AutoSchemaKG是一个创新的知识图谱构建框架，它通过利用大型语言模型，实现了无需预定义模式的完全自主构建。该系统能够从大规模文本语料库中同时提取知识三元组并动态归纳全面的模式，对实体和事件进行建模，并通过概念化组织实例。通过处理5000万份文档，AutoSchemaKG构建了包含数十亿节点和边的ATLAS知识图谱，并在多跳问答任务中表现优异，显著提升了大型语言模型的事实性，证明了其动态归纳模式与人工模式的高度对齐性。

> **摘要翻译:** 我们提出了AutoSchemaKG，一个用于完全自主知识图谱构建的框架，它消除了对预定义模式的需求。我们的系统利用大型语言模型同时从文本中提取知识三元组并直接从文本中归纳全面的模式，同时对实体和事件进行建模，并采用概念化将实例组织到语义类别中。通过处理超过5000万份文档，我们构建了ATLAS（Automated Triple Linking And Schema induction），一个拥有9亿+节点和59亿边的知识图谱家族。这种方法在多跳问答任务上优于最先进的基线，并增强了大型语言模型的事实性。值得注意的是，我们的模式归纳在零人工干预的情况下实现了与人工创建模式92%的语义对齐，这表明具有动态归纳模式的十亿级知识图谱可以有效补充大型语言模型中的参数知识。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [342] [Model Misalignment and Language Change: Traces of AI-Associated Language in Unscripted Spoken English](https://arxiv.org/abs/2508.00238)
> *模型错位与语言变化：非脚本英语口语中与AI相关的语言痕迹*

*Bryce Anderson, Riley Galpin, Tom S. Juzek* | **Category: cs.CL, cs.AI, 68T50, I.2; I.2.7** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 语言变化, 口语, AI影响, 词汇趋势

**Comment:** Accepted at AIES 2025. To appear in the AIES Proceedings. 14 pages, 2
  figures, 2 tables. Licensed under CC BY-SA 4.0

> **TL;DR:** 研究发现，自2022年ChatGPT发布以来，非脚本英语口语中与大型语言模型相关的词汇使用量显著增加，表明人类语言选择正与LLM模式趋同，这可能预示着语言使用方式的重大转变。

**AI_Comments:** 该研究创新性地将LLM对语言的影响扩展到非脚本口语领域，而非仅仅关注书面语，拓宽了我们对AI语言渗透性的理解。其重要性在于揭示了AI可能在短时间内对人类语言产生实际且可测量的影响，并提出了关于语言变化本质的深刻问题：这是一种自然演变还是技术干预的结果？其局限性在于无法明确区分这种变化是直接由AI工具使用引起，还是通过更广泛的社会文化传播间接影响，以及研究时间跨度相对较短，未来需要更长时间的跟踪观察。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，书面语言中的词汇使用发生了显著变化，这通常归因于大型语言模型（LLMs）的影响。然而，目前尚不清楚这些变化是否反映了人类语言系统本身的更广泛变化。本研究旨在探讨AI相关语言是否已渗透到非脚本口语中。

**Method:** 研究构建了一个包含2210万词的非脚本口语数据集，来源于会话式科技播客。分析了ChatGPT于2022年发布前后词汇趋势，重点关注常用LLM相关词汇和基线同义词。

**Result:** 结果显示，2022年后，与LLM相关的词汇使用量出现中度但显著的增加，表明人类词汇选择与LLM相关模式之间存在趋同。相比之下，基线同义词未显示出显著的方向性变化。

**Conclusion:** 鉴于时间短和受影响词汇数量，这可能预示着语言使用方式的重大转变。至于这代表自然语言变化还是由AI接触驱动的新型转变，以及上游训练错位是否最终导致人类语言使用变化，仍是悬而未决的问题。这些发现与错位模型可能塑造社会和道德信念的伦理担忧相似。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）对非脚本英语口语的影响。通过分析2022年ChatGPT发布前后科技播客中的2210万词汇数据，发现与LLM相关的词汇使用量显著增加，表明人类语言选择正与LLM的词汇模式趋同。这一趋势可能预示着语言使用方式的重大转变，但其是自然语言演变还是AI驱动的，以及上游模型错位的影响，仍需进一步探究。研究强调了AI对人类语言潜在塑造作用的伦理考量。

> **摘要翻译:** 近年来，书面语言，特别是在科学和教育领域，其词汇使用发生了显著变化。这些变化被广泛归因于大型语言模型（LLMs）日益增长的影响，这些模型经常依赖于一种独特的词汇风格。模型输出与目标受众规范之间的差异可以被视为一种错位。虽然这些变化通常与直接使用人工智能（AI）作为生成文本的工具相关联，但目前尚不清楚这些变化是否反映了人类语言系统本身的更广泛变化。为了探索这个问题，我们构建了一个包含2210万词的非脚本口语数据集，这些数据来源于会话式科学和技术播客。我们分析了2022年ChatGPT发布前后的词汇趋势，重点关注常用的LLM相关词汇。我们的结果显示，2022年后，这些词汇的使用量出现中度但显著的增加，这表明人类词汇选择与LLM相关模式之间存在趋同。相比之下，基线同义词没有显示出显著的方向性变化。鉴于时间短和受影响词汇的数量，这可能预示着语言使用方面即将发生显著转变。这是否代表自然语言变化或由AI接触驱动的新型转变，仍然是一个悬而未决的问题。同样，尽管这些转变可能源于更广泛的采用模式，但也可能是上游训练错位最终导致了人类语言使用的变化。这些发现与错位模型可能塑造社会和道德信念的伦理担忧相似。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [348] [Applying Psychometrics to Large Language Model Simulated Populations: Recreating the HEXACO Personality Inventory Experiment with Generative Agents](https://arxiv.org/abs/2508.00742)
> *将心理测量学应用于大型语言模型模拟人群：使用生成式智能体复现HEXACO人格量表实验*

*Sarah Mercer, Daniel P. Martin, Phil Swatton* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 生成式智能体, 大型语言模型, 心理测量学, HEXACO, 人格量表

**Comment:** 26 pages, 14 figures

> **TL;DR:** 本研究通过对310个GPT-4智能体进行HEXACO人格量表实验，发现智能体能恢复连贯可靠的人格结构，但存在模型特有的偏差和局限性。

**AI_Comments:** 本研究的创新之处在于首次将心理测量学应用于大型语言模型模拟人群，复现经典人格实验，验证了生成式智能体在社会科学研究中作为人类替代品的潜力。其重要性在于为未来使用LLM智能体进行复杂社会实验提供了初步的验证和实践指导。然而，研究也指出了模型特有的偏差和局限性，这提示我们需要谨慎对待结果，并进一步探索如何设计更具代表性和一致性的智能体角色。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型驱动的生成式智能体因其类人特性和扮演角色的能力，被视为社会科学研究中人类参与者的经济有效替代品。本研究旨在探讨这些基于角色的智能体在代表人人群体方面的有效性。

**Method:** 研究人员通过对310个GPT-4驱动的智能体进行调查，复现了HEXACO人格量表实验，并对智能体的回答进行了因子分析，然后将结果与Ashton、Lee和Goldberg在2004年提出的原始发现进行了比较。

**Result:** 1) 从智能体的回答中可以恢复出连贯可靠的人格结构，表明与HEXACO框架部分一致。2) 在足够精心策划的人口群体下，派生的人格维度在GPT-4内部是一致和可靠的。3) 跨模型分析揭示了人格剖析的变异性，表明存在模型特有的偏差和局限性。

**Conclusion:** 本研究探讨了生成式智能体在社会科学研究中应用的潜在益处和局限性，并为设计一致且具有代表性的智能体角色提供了有益指导，以最大限度地覆盖和代表人类人格特质。

> **ai_Abstract:** 本研究评估了大型语言模型驱动的生成式智能体作为社会科学研究中人类参与者替代品的有效性。通过复现HEXACO人格量表实验，调查了310个GPT-4智能体。结果显示，智能体能够展现出连贯且部分符合HEXACO框架的人格结构，且在适当条件下GPT-4内部的人格维度具有一致性和可靠性。然而，跨模型分析揭示了模型特有的偏差和局限性。本研究为利用生成式智能体进行社会科学研究提供了实践指导和深入见解。

> **摘要翻译:** 大型语言模型驱动的生成式智能体通过复杂的自然语言交互展现出类人特征。它们根据预设角色传记扮演角色和个性的能力，使其成为社会科学研究中人类参与者的经济有效替代品。本文探讨了此类基于角色的智能体在代表人人群体方面的有效性；我们通过调查310个由GPT-4驱动的智能体，复现了HEXACO人格量表实验，对其回答进行因子分析，并将这些结果与Ashton、Lee和Goldberg在2004年提出的原始发现进行比较。我们的结果发现：1) 从智能体的回答中可以恢复出连贯可靠的人格结构，表明与HEXACO框架部分对齐。2) 当与足够精心策划的人口群体结合时，派生的人格维度在GPT-4内部是一致和可靠的。3) 跨模型分析揭示了人格剖析的变异性，表明存在模型特有的偏差和局限性。我们讨论了实验过程中遇到的实际考虑因素和挑战。这项研究有助于正在进行的关于在社会科学研究中使用生成式智能体的潜在益处和局限性的讨论，并为设计一致且具有代表性的智能体角色提供了有益指导，以最大限度地覆盖和代表人类人格特质。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [362] [Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering](https://arxiv.org/abs/2508.00285)
> *将临床推理整合到基于大语言模型的诊断中，通过病因感知注意力引导*

*Peixian Li, Yu Tian, Ruiqi Tu, Chengkai Wu, Jingjing Ren, Jingsong Li* | **Category: cs.CL, I.2.7; J.3** | **Updated: 2025-08-01**

**Keywords:** 大语言模型, 临床推理, 诊断, 注意力机制, 病因感知

**Comment:** 23 pages, 8 figures

> **TL;DR:** 通过病因感知注意力引导框架，将结构化临床推理整合到大语言模型中，显著提高了其在复杂临床场景下的诊断准确性和可靠性。

**AI_Comments:** 这项研究通过引入“病因感知注意力引导框架”，有效地解决了LLM在医学诊断中缺乏临床推理能力和可靠性的问题。其创新点在于将权威临床指南转化为结构化的临床推理支架（CRS），并通过微调注意力机制，使LLM能够聚焦于病因推理的关键信息。这种方法不仅提高了诊断准确性，还增强了模型的可解释性，对于构建更安全、更可靠的AI医疗诊断系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型在医学文本理解和生成方面表现出显著能力，但在复杂临床场景下的诊断可靠性有限。本研究旨在提高大语言模型的诊断准确性和临床推理能力。

**Method:** 提出了一种病因感知注意力引导框架，将结构化临床推理整合到基于LLM的诊断中。具体方法包括：1. 构建基于权威临床指南的临床推理支架（CRS），针对三种急性腹部急症（急性阑尾炎、急性胰腺炎、急性胆囊炎）。2. 开发病因感知头部识别算法，确定对模型病因推理至关重要的注意力头部。3. 引入推理引导的参数高效微调，将病因推理线索嵌入输入表示，并通过推理引导损失函数将选定的病因感知头部引导至关键信息。

**Result:** 在一致诊断队列上，该框架将平均诊断准确率提高了15.65%，平均推理焦点分数提高了31.6%。在差异诊断队列上的外部验证进一步证实了其在提高诊断准确性方面的有效性。通过推理注意力频率的进一步评估表明，模型在面对真实世界复杂场景时表现出更高的可靠性。

**Conclusion:** 本研究提出了一种实用且有效的方法，以增强基于LLM的诊断中的临床推理能力。通过将模型注意力与结构化CRS对齐，所提出的框架为在复杂临床环境中构建更可解释和可靠的AI诊断系统提供了一个有前景的范例。

> **ai_Abstract:** 本文提出了一种病因感知注意力引导框架，旨在通过将结构化临床推理整合到大语言模型中，以提高其在复杂临床场景下的诊断准确性和可靠性。该框架通过构建临床推理支架（CRS）、开发病因感知头部识别算法以及引入推理引导的参数高效微调，使模型能够更好地进行病因推理并聚焦于关键信息。实验结果表明，该方法显著提升了模型的诊断准确率和推理焦点分数，为构建更可解释和可靠的AI诊断系统提供了新范例。

> **摘要翻译:** 目标：大型语言模型（LLM）在医学文本理解和生成方面表现出显著能力。然而，它们在复杂临床场景中的诊断可靠性仍然有限。本研究旨在提高LLM的诊断准确性和临床推理能力。方法：我们提出了一种病因感知注意力引导框架，将结构化临床推理整合到基于LLM的诊断中。具体而言，我们首先根据权威临床指南，针对三种代表性急性腹部急症：急性阑尾炎、急性胰腺炎和急性胆囊炎，构建了临床推理支架（CRS）。接下来，我们开发了病因感知头部识别算法，以确定对模型病因推理至关重要的注意力头部。为了确保可靠的临床推理对齐，我们引入了推理引导的参数高效微调，该微调将病因推理线索嵌入到输入表示中，并通过推理引导损失函数将选定的病因感知头部引导至关键信息。结果：在一致诊断队列上，我们的框架将平均诊断准确率提高了15.65%，并将平均推理焦点分数提高了31.6%，优于基线。在差异诊断队列上的外部验证进一步证实了其在提高诊断准确性方面的有效性。通过推理注意力频率的进一步评估表明，我们的模型在面对真实世界复杂场景时表现出增强的可靠性。结论：本研究提出了一种实用且有效的方法，以增强基于LLM的诊断中的临床推理能力。通过将模型注意力与结构化CRS对齐，所提出的框架为在复杂临床环境中构建更可解释和可靠的AI诊断系统提供了一个有前景的范例。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [364] [AutoMixer: Checkpoint Artifacts as Automatic Data Mixers](https://arxiv.org/abs/2506.21910)
> *AutoMixer：将检查点工件作为自动数据混合器*

*Ernie Chang, Yang Li, Patrick Huber, Vish Vogeti, David Kant, Yangyang Shi, Vikas Chandra* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 语言模型, 数据混合, 检查点模型, 数据增强, 影响近似

**Comment:** Accepted at ACL 2025

> **TL;DR:** 本文提出AutoMixer，利用训练过程中保存的检查点模型作为数据混合器，通过其对源数据的影响近似来优化数据混合，从而提高语言模型的性能。

**AI_Comments:** 这项工作创新性地将训练过程中产生的检查点模型视为宝贵的数据信号源，并利用它们来自动优化数据混合，解决了传统上难以手动调整数据比例的问题。它提供了一种新颖且自动化的数据增强和混合策略，对于提高大型语言模型训练效率和性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型训练中，为模型配备多种任务能力时，难以直接获取正确的数据混合，因为数据与任务的关系难以建模。同时，训练过程中保存的检查点模型作为数据信号的来源未被充分利用。

**Method:** 作者观察到检查点模型在训练轨迹的不同点展现出新兴能力。他们根据检查点模型在基准测试上的各自能力来识别这些工件模型，并通过它们对源数据的聚合一阶影响近似来利用它们作为数据混合器。

**Result:** 在八个推理基准测试上，所提出的框架在预训练设置中显示出显著改进，性能提升高达1.93%。

**Conclusion:** 这表明检查点模型具有增强数据质量和优化数据混合的潜力。

> **ai_Abstract:** 本文提出了AutoMixer框架，旨在解决语言模型训练中数据混合难以优化的挑战。通过观察训练过程中检查点模型展现出的不同能力，作者利用这些未被充分利用的检查点工件，基于其对源数据的聚合一阶影响近似，将其作为自动数据混合器。实验结果表明，在八个推理基准测试上，该方法在预训练设置中显著提升了性能，最高达1.93%，证明了检查点模型在提升数据质量和优化数据混合方面的潜力。

> **摘要翻译:** 在语言模型训练中，期望模型具备各种任务能力。然而，由于数据与任务之间的关系难以建模，如何直接获取适合这些能力的数据混合尚不清楚。在这项工作中，我们观察到检查点模型在训练轨迹的不同点表现出新兴能力。通常，训练过程会将检查点保存为工件，但这些工件作为训练中数据信号的来源并未得到充分利用。我们根据这些工件模型在基准测试上的各自能力来识别它们，并通过它们对源数据的聚合一阶影响近似来利用它们作为数据混合器。我们在八个推理基准测试上证明，所提出的框架在预训练设置中显示出显著改进，性能提升高达1.93%。总的来说，这表明检查点模型具有增强数据质量和优化数据混合的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [368] [Agentic large language models improve retrieval-based radiology question answering](https://arxiv.org/abs/2508.00743)
> *智能体大型语言模型改进基于检索的放射学问答*

*Sebastian Wind, Jeta Sopa, Daniel Truhn, Mahshad Lotfinia, Tri-Thien Nguyen, Keno Bressem, Lisa Adams, Mirabela Rusu, Harald Köstler, Gerhard Wellein, Andreas Maier, Soroosh Tayebi Arasteh* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 检索增强生成, 放射学问答, 智能体, 诊断准确率

**Comment:** 

> **TL;DR:** 智能体RAG框架通过自主问题分解和迭代检索，显著提高了放射学问答的准确性，尤其对中小型LLM效果显著，并减少了幻觉。

**AI_Comments:** 该论文的创新点在于引入了“智能体”概念到RAG框架中，实现了问题的自主分解和证据的迭代检索，从而克服了传统RAG在处理复杂临床推理时的局限性。其重要性体现在显著提升了放射学问答的准确性和事实性，特别是对中小型LLM的性能提升，这对于资源受限的实际应用具有重要意义。局限性可能在于其对特定数据集Radiopaedia的依赖，以及需要进一步的临床验证来确保其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的放射学问答（QA）检索增强生成（RAG）系统依赖于单步检索，限制了它们处理复杂临床推理任务的能力。

**Method:** 本文提出了一种智能体RAG框架，使大型语言模型（LLM）能够自主分解放射学问题，迭代地从Radiopaedia检索目标临床证据，并动态合成基于证据的响应。研究评估了24种不同架构、参数规模（0.5B至>670B）和训练范式（通用型、推理优化型、临床微调型）的LLM，使用了来自RSNA-RadioQA和ExtendedQA数据集的104个专家整理的放射学问题进行评估。

**Result:** 智能体检索显著提高了平均诊断准确率，相比零样本提示（73% 对 64%；P<0.001）和传统在线RAG（73% 对 68%；P<001）均有提升。在中型模型（如Mistral Large从72%提高到81%）和小型模型（如Qwen 2.5-7B从55%提高到71%）中收益最大，而超大型模型（>200B参数）改进不足2%。此外，智能体检索减少了幻觉（平均9.4%），并在46%的案例中检索到临床相关背景，有效帮助事实基础。临床微调模型也显示出显著改进（如MedGemma-27B从71%提高到81%）。

**Conclusion:** 智能体框架有潜力提高放射学问答的事实性和诊断准确性，特别是在中型大型语言模型中，未来需要进一步研究以验证其临床实用性。

> **ai_Abstract:** 本研究提出了一种智能体检索增强生成（RAG）框架，旨在提升大型语言模型（LLMs）在放射学问答中的性能。该框架允许LLMs自主分解复杂问题、迭代检索临床证据并生成响应。实验结果表明，与传统方法相比，智能体RAG显著提高了诊断准确率，尤其在中小型LLMs上表现突出，并有效减少了幻觉，增强了事实性。

> **摘要翻译:** 放射学中的临床决策越来越多地受益于人工智能（AI），特别是通过大型语言模型（LLM）。然而，用于放射学问答（QA）的传统检索增强生成（RAG）系统通常依赖于单步检索，这限制了它们处理复杂临床推理任务的能力。本文提出了一种智能体RAG框架，使LLM能够自主分解放射学问题，迭代地从Radiopaedia检索目标临床证据，并动态合成基于证据的响应。我们评估了24种LLM，涵盖了不同的架构、参数规模（0.5B到>670B）和训练范式（通用型、推理优化型、临床微调型），使用了来自先前建立的RSNA-RadioQA和ExtendedQA数据集的104个专家整理的放射学问题。与零样本提示（73% 对 64%；P<0.001）和传统在线RAG（73% 对 68%；P<0.001）相比，智能体检索显著提高了平均诊断准确率。在中型模型（例如，Mistral Large 从72%提高到81%）和小型模型（例如，Qwen 2.5-7B 从55%提高到71%）中获得了最大收益，而超大型模型（>200B参数）的变化最小（<2%的改进）。此外，智能体检索减少了幻觉（平均9.4%），并在46%的案例中检索到临床相关背景，这大大有助于事实基础。即使是临床微调模型也表现出显著改进（例如，MedGemma-27B 从71%提高到81%），表明检索和微调具有互补作用。这些结果突出了智能体框架在放射学问答中提高事实性和诊断准确性的潜力，特别是在中型LLM中，这需要未来的研究来验证其临床实用性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [387] [Systematic Evaluation of Optimization Techniques for Long-Context Language Models](https://arxiv.org/abs/2508.00305)
> *长上下文语言模型优化技术的系统评估*

*Ammar Ahmed, Sheng Di, Franck Cappello, Zirui Liu, Jingoo Han, Ali Anwar* | **Category: cs.CL, cs.LG, cs.PF** | **Updated: 2025-08-01**

**Keywords:** 优化技术, 长上下文语言模型, 性能评估, 可扩展性, 基准测试

**Comment:** 

> **TL;DR:** 本文系统评估了长上下文语言模型的优化技术，发现简单的组合优化可能对大型模型产生负面影响，且F1分数可能掩盖实际性能权衡。

**AI_Comments:** 本文的创新之处在于其对长上下文LLM优化技术进行了系统而全面的评估，特别是对组合优化在不同规模模型上影响的深入分析。它不仅提供了关于内存、延迟和吞吐量的量化数据，还揭示了传统评估指标（如F1分数）可能存在的局限性，强调了系统级分析与任务特定洞察相结合的重要性。这对于指导LLM的实际部署和进一步研究具有重要实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型(LLMs)在自然语言处理任务中表现出色，但面临资源需求高和上下文窗口受限的问题。尽管存在剪枝、量化和Token丢弃等优化技术，但它们在长上下文场景中的有效性及其系统评估仍未得到充分探索。

**Method:** 本文系统地评估了针对长上下文LLM的优化技术，包括剪枝、量化和Token丢弃。研究首先分析了两种LLM架构的单一优化方法，然后系统评估了这些技术的组合效果对性能指标的影响。随后，研究还对一个700亿参数的更大模型变体上的单一优化方法的扩展性进行了研究。通过整合系统级分析和任务特定洞察进行评估。

**Result:** 研究发现，与小型模型相比，简单的组合推理优化算法由于复合近似误差，可能对大型模型产生不利影响。实验表明，仅依赖F1分数会通过隐藏问答任务中的精确率-召回率权衡来掩盖这些负面影响。

**Conclusion:** 本研究通过整合系统级分析与任务特定洞察，旨在帮助LLM从业者和研究人员在不同任务和硬件配置下探索并平衡效率、准确性和可扩展性。

> **ai_Abstract:** 本文系统评估了针对长上下文大型语言模型的各种优化技术（如剪枝、量化和Token丢弃），旨在解决其资源消耗和上下文限制问题。研究通过基准测试分析了这些技术对内存、延迟、吞吐量和生成质量的影响，并深入探讨了单一及组合优化方法在不同规模模型上的表现。核心发现是，简单的组合优化算法可能因误差累积而对大型模型产生负面影响，且F1等单一指标可能无法全面反映性能权衡。该研究为LLM的实际应用提供了关于效率、准确性和可扩展性之间平衡的见解。

> **摘要翻译:** 大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但面临资源需求和上下文窗口限制的问题。尽管剪枝、量化和Token丢弃等技术可以缓解这些问题，但它们在长上下文场景和系统评估中的有效性仍未得到充分探索。本文系统地评估了这些优化技术，描述了内存使用、延迟和吞吐量，并研究了这些方法如何影响文本生成质量。我们首先分析了支持长上下文的两种LLM架构的独立优化方法，然后系统地评估了这些技术的组合，以评估这种更深入的分析如何影响性能指标。随后，我们研究了单个优化方法在具有700亿参数的更大变体模型上的可扩展性。我们的新颖见解表明，与小型模型相比，简单的组合推理优化算法由于复合近似误差，可能对大型模型产生不利影响。实验表明，仅依赖F1分数会通过隐藏问答任务中的精确率-召回率权衡来掩盖这些影响。通过整合系统级分析与任务特定洞察，本研究有助于LLM从业者和研究人员在不同任务和硬件配置下探索并平衡效率、准确性和可扩展性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [388] [GLiDRE: Generalist Lightweight model for Document-level Relation Extraction](https://arxiv.org/abs/2508.00757)
> *GLiDRE：文档级关系抽取的通用轻量级模型*

*Robin Armingaud, Romaric Besançon* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 关系抽取, 文档级关系抽取, 少样本学习, 轻量级模型, GLiDRE

**Comment:** Submitted to ARR July

> **TL;DR:** 本文提出了GLiDRE，一个基于GLiNER思想的文档级关系抽取模型，在少样本场景下实现了最先进的性能。

**AI_Comments:** GLiDRE的创新之处在于将GLiNER模型在NER任务中取得成功的轻量级通用模型思想应用于文档级关系抽取，特别关注了少样本学习场景。这对于资源受限或需要快速适应新领域的关系抽取任务具有重要意义。该研究填补了现有方法在零样本/少样本设置中性能探索不足的空白。

<details>
  <summary>Details</summary>

**Motivation:** 文档级关系抽取任务面临挑战，现有方法在零样本或少样本设置中的性能尚未得到充分探索。受到GLiNER模型在NER任务中表现优异的启发，研究者旨在开发一个轻量级模型来解决文档级关系抽取的问题。

**Method:** 本文引入了GLiDRE模型，该模型借鉴了GLiNER的关键思想，用于文档级关系抽取。研究者在Re-DocRED数据集上，将GLiDRE与最先进的模型在各种数据设置下进行了基准测试。

**Result:** GLiDRE在少样本场景中实现了最先进的性能。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了GLiDRE，一个用于文档级关系抽取（RE）的轻量级通用模型。该模型借鉴了GLiNER在NER任务中表现优异的理念，旨在解决文档级RE在零样本和少样本设置中表现不佳的挑战。在Re-DocRED数据集上的基准测试表明，GLiDRE在少样本场景下达到了最先进的性能。

> **摘要翻译:** 关系抽取（RE）是自然语言处理中的一项基础任务，其文档级变体由于需要对跨句子的实体之间复杂的交互进行建模而带来了显著的挑战。目前的方法，主要基于ATLOP架构，通常在DocRED和Re-DocRED等基准测试中进行评估。然而，由于任务的复杂性，它们在零样本或少样本设置中的性能仍未得到充分探索。最近，GLiNER模型表明，一个紧凑的命名实体识别（NER）模型可以胜过更大的大型语言模型。出于类似的动机，我们引入了GLiDRE，一个用于文档级关系抽取的新模型，它建立在GLiNER的关键思想之上。我们在Re-DocRED数据集上的各种数据设置中，将GLiDRE与最先进的模型进行了基准测试。我们的结果表明，GLiDRE在少样本场景中实现了最先进的性能。我们的代码是公开的。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [391] [Emergent Semantics Beyond Token Embeddings: Transformer LMs with Frozen Visual Unicode Representations](https://arxiv.org/abs/2507.04886)
> *超越词元嵌入的涌现语义：具有冻结视觉Unicode表示的Transformer语言模型*

*A. Bochkov* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** Transformer语言模型, 涌现语义, 冻结嵌入, Unicode表示, LLM可解释性

**Comment:** Updated and extended the Ablation Study section with longer training
  runs for clearer visualization of convergence. Consolidated the discussion in
  this section to improve clarity and flow

> **TL;DR:** 本文证明Transformer语言模型即使使用冻结的、非语义的视觉Unicode嵌入，也能学习到高级语义，表明语义是架构的涌现属性，而非仅限于输入嵌入。

**AI_Comments:** 本文对大型语言模型设计中的一个基本假设——即对可训练的、语义丰富的输入嵌入的需求——提出了重大挑战。其创新之处在于证明了即使是视觉派生、固定的嵌入也能带来更优的性能，这表明Transformer架构在语义涌现中扮演着更深层次的角色。这项工作对于指导未来更高效、更可解释的LLM研究具有重要意义，并可能减轻训练大型嵌入层的计算负担。它为探索替代输入表示开辟了道路。

<details>
  <summary>Details</summary>

**Motivation:** 理解大型语言模型（LLMs）中语义表示的根源对于可解释性和架构创新至关重要。挑战主流观点，即可训练的输入嵌入是基础的“意义向量”。

**Method:** 构建Transformer模型，其中嵌入层完全冻结，嵌入向量不是从数据中导出，而是从Unicode字形的视觉结构中导出。这些非语义的、预先计算的视觉嵌入在整个训练过程中都是固定的。该方法与任何分词器兼容，包括引入的新型以Unicode为中心的分词器，以确保文本的普遍覆盖。

**Result:** 尽管没有可训练的、语义初始化的嵌入，但模型能够收敛，生成连贯的文本，并且关键的是，在MMLU推理基准测试中，其性能优于架构相同但具有可训练嵌入的模型。

**Conclusion:** 高级语义并非输入嵌入所固有的，而是Transformer组合架构和数据规模的涌现属性。这重新定义了嵌入的作用，从意义容器转变为结构原语。

> **ai_Abstract:** 本文挑战了传统观点，即在大型语言模型中，可训练的输入嵌入是语义的主要来源。通过构建具有完全冻结的、非语义视觉Unicode嵌入的Transformer模型，作者证明这些模型仍然可以收敛、生成连贯文本，甚至在推理任务上优于具有可训练嵌入的模型。研究结果表明，高级语义是Transformer组合架构和数据规模的涌现属性，而非输入嵌入所固有，从而将嵌入的作用重新定义为结构原语。

> **摘要翻译:** 理解大型语言模型（LLMs）中语义表示的根源对于可解释性和架构创新至关重要。主流范式认为，可训练的输入嵌入是基础的“意义向量”。本文对此观点提出挑战。我们构建了Transformer模型，其中嵌入层完全冻结，向量并非源自数据，而是源自Unicode字形的视觉结构。这些非语义的、预先计算的视觉嵌入在整个训练过程中是固定的。我们的方法与任何分词器兼容，包括我们引入的一种新型以Unicode为中心的分词器，以确保文本的普遍覆盖。尽管没有可训练的、语义初始化的嵌入，我们的模型仍然能够收敛，生成连贯的文本，并且关键的是，在MMLU推理基准测试中，其性能优于架构相同但具有可训练嵌入的模型。我们将此归因于传统模型中的“表示干扰”，即嵌入层既要学习结构特征又要学习语义特征。我们的结果表明，高级语义并非输入嵌入所固有的，而是Transformer组合架构和数据规模的涌现属性。这重新定义了嵌入的作用，从意义容器转变为结构原语。我们发布了所有代码和模型，以促进进一步的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [403] [MMBERT: Scaled Mixture-of-Experts Multimodal BERT for Robust Chinese Hate Speech Detection under Cloaking Perturbations](https://arxiv.org/abs/2508.00760)
> *MMBERT：用于对抗伪装扰动的鲁棒中文仇恨言论检测的专家混合多模态BERT模型*

*Qiyao Xue, Yuchen Dou, Ryan Shi, Xiang Lorraine Li, Wei Gao* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 中文仇恨言论检测, 多模态, BERT, 专家混合, 伪装扰动

**Comment:** 

> **TL;DR:** MMBERT是一个基于MoE的多模态BERT框架，通过整合文本、语音和视觉模态，显著提升了中文仇恨言论检测在伪装扰动下的鲁棒性，超越了现有模型。

**AI_Comments:** MMBERT的创新之处在于将专家混合（MoE）架构引入多模态BERT模型，以应对中文仇恨言论检测中复杂的伪装扰动，并特别关注中文语境下的多模态融合。其提出的渐进式三阶段训练范式解决了MoE集成的不稳定性问题，增强了模型的实用性。该研究对于提升中文在线内容审核的鲁棒性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 中文社交网络上的仇恨言论检测面临独特挑战，特别是广泛使用的伪装技术会规避传统基于文本的检测系统。尽管大型语言模型（LLMs）提高了仇恨言论检测能力，但现有工作大多集中在英文数据集，对中文语境下的多模态策略关注有限。

**Method:** 提出MMBERT，一个新颖的基于BERT的多模态框架，通过专家混合（MoE）架构整合文本、语音和视觉模态。为了解决MoE直接集成到BERT模型中的不稳定性，开发了渐进式三阶段训练范式。MMBERT包含模态特定专家、共享自注意力机制和基于路由器的专家分配策略，以增强对抗性扰动的鲁棒性。

**Result:** 在多个中文仇恨言论数据集上的实证结果表明，MMBERT显著优于微调的基于BERT的编码器模型、微调的LLMs以及使用上下文学习方法的LLMs。

**Conclusion:** MMBERT通过其多模态专家混合架构和渐进式训练，有效提升了中文仇恨言论检测在复杂伪装环境下的鲁棒性和性能。

> **ai_Abstract:** 本研究提出了MMBERT，一个基于BERT的多模态框架，旨在解决中文社交网络中仇恨言论检测面临的挑战，特别是针对伪装技术。MMBERT通过专家混合（MoE）架构整合文本、语音和视觉模态，并采用渐进式三阶段训练范式以稳定MoE集成。该模型包含模态特定专家、共享自注意力机制和路由器专家分配策略，以增强对抗性扰动的鲁棒性。实验结果表明，MMBERT在中文仇恨言论数据集上显著优于现有的基于BERT的模型和大型语言模型。

> **摘要翻译:** 中文社交网络上的仇恨言论检测面临独特的挑战，特别是由于广泛使用的伪装技术旨在规避传统的基于文本的检测系统。尽管大型语言模型（LLMs）最近提高了仇恨言论检测能力，但现有的大部分工作都集中在英文数据集上，对中文语境下的多模态策略关注有限。在本研究中，我们提出了MMBERT，一个新颖的基于BERT的多模态框架，它通过专家混合（MoE）架构整合了文本、语音和视觉模态。为了解决MoE直接集成到基于BERT的模型中相关的不稳定性，我们开发了一种渐进式三阶段训练范式。MMBERT结合了模态特定专家、共享自注意力机制和基于路由器的专家分配策略，以增强对抗性扰动的鲁棒性。在多个中文仇恨言论数据集上的实证结果表明，MMBERT显著优于微调的基于BERT的编码器模型、微调的LLMs以及使用上下文学习方法的LLMs。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [412] [Improving Multimodal Contrastive Learning of Sentence Embeddings with Object-Phrase Alignment](https://arxiv.org/abs/2508.00332)
> *采用目标-短语对齐改进多模态对比学习的句子嵌入*

*Kaiyan Zhao, Zhongtao Miao, Yoshimasa Tsuruoka* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 多模态学习, 句子嵌入, 对比学习, 目标-短语对齐, 噪声缓解

**Comment:** Work in progress

> **TL;DR:** MCSEO通过引入细粒度的目标-短语对齐来减少图像-字幕对中的噪声，从而改进多模态句子嵌入。

**AI_Comments:** 该论文的创新之处在于通过引入更细粒度的目标-短语对齐来解决多模态数据中的噪声问题，这对于构建更鲁棒、更精确的多模态表示至关重要。其方法利用了现有视觉模型的强大能力，并将其整合到对比学习框架中，为未来的多模态研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 多模态句子嵌入模型在训练过程中使用的图像-字幕对通常包含噪声（冗余或不相关信息），这会影响模型性能。

**Method:** 提出MCSEO方法，通过结合细粒度的目标-短语对齐和传统的图像-字幕对齐来增强多模态句子嵌入。MCSEO利用现有的分割和目标检测模型提取准确的目标-短语对，并用这些对来优化专门针对目标-短语对应关系的对比学习目标。

**Result:** 在不同骨干模型的语义文本相似度（STS）任务上，MCSEO始终优于强大的基线模型。

**Conclusion:** 精确的目标-短语对齐在多模态表示学习中具有重要意义。

> **ai_Abstract:** 本文提出了一种名为MCSEO的新方法，旨在通过引入细粒度的目标-短语对齐来改进多模态句子嵌入，以解决传统图像-字幕对中存在的噪声问题。MCSEO利用现有的视觉模型提取精确的目标-短语对，并将其用于优化对比学习目标。实验结果表明，MCSEO在语义文本相似度任务上持续超越现有基线，强调了精确目标-短语对齐在多模态表示学习中的关键作用。

> **摘要翻译:** 多模态句子嵌入模型在训练过程中通常除了文本数据外，还会利用图像-字幕对。然而，这些对通常包含噪声，包括图像或字幕侧的冗余或不相关信息。为了缓解这个问题，我们提出了MCSEO，一种通过在传统图像-字幕对齐之外，结合细粒度目标-短语对齐来增强多模态句子嵌入的方法。具体来说，MCSEO利用现有的分割和目标检测模型来提取准确的目标-短语对，然后用这些对来优化专门针对目标-短语对应关系的对比学习目标。在不同骨干模型的语义文本相似度（STS）任务上的实验结果表明，MCSEO始终优于强大的基线模型，这突出了精确目标-短语对齐在多模态表示学习中的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [414] [LLMs Encode Harmfulness and Refusal Separately](https://arxiv.org/abs/2507.11878)
> *大型语言模型分别编码有害性和拒绝性*

*Jiachen Zhao, Jing Huang, Zhengxuan Wu, David Bau, Weiyan Shi* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 有害性, 拒绝, 越狱, AI安全

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）将有害性编码为一个独立于拒绝的概念，这为理解其安全机制和开发更强大的安全防护提供了新视角。

**AI_Comments:** 这项研究的创新之处在于明确区分了LLM中“有害性”和“拒绝”这两个概念，并发现它们由不同的潜在方向编码。这不仅提供了对LLM内部安全机制更深层次的理解，也揭示了现有安全防护和越狱方法的作用原理。Latent Guard的提出是一个重要的实践应用，它利用了模型内在的有害性表示，提供了一种更鲁棒、更不易受微调攻击影响的安全防护机制，这对于提高LLM的安全性具有重要意义。该工作为AI安全研究开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** LLMs被训练拒绝有害指令，但研究者想探究它们是否真正理解有害性，而不仅仅是拒绝。先前的研究表明LLMs的拒绝行为可以通过一个一维子空间（拒绝方向）来调节，但有害性是否也是一个独立的概念则不清楚。

**Method:** 识别并分析了LLMs内部编码的有害性方向，该方向与拒绝方向不同。通过沿着有害性方向操纵模型，观察其对无害指令的解释；通过沿着拒绝方向操纵，观察其拒绝反应。利用识别出的有害性概念，分析了越狱方法的作用机制和对抗性微调对模型内部有害性信念的影响。基于此，提出了一个利用潜在有害性表示作为内在安全防护（Latent Guard）的应用。

**Result:** 存在一个与拒绝方向不同的有害性方向。沿着有害性方向操纵可以使LLMs将无害指令解释为有害，而沿着拒绝方向操纵则直接引发拒绝响应，而不改变模型对有害性的判断。某些越狱方法通过减少拒绝信号起作用，但并未改变模型内部对有害性的信念。对抗性微调模型以接受有害指令对模型内部有害性信念的影响极小。提出的Latent Guard在检测不安全输入和减少过度拒绝方面表现与Llama Guard 3 8B相当或更好，且对微调攻击具有鲁棒性。

**Conclusion:** LLMs内部对有害性的理解比其拒绝决策对不同的输入指令更具鲁棒性。有害性可以作为独立于拒绝的内在概念被编码，这为AI安全研究提供了新视角，并可用于构建更可靠的安全防护机制。

> **ai_Abstract:** 本研究发现大型语言模型（LLMs）将有害性作为一个独立于拒绝行为的概念进行编码，并存在一个独特的“有害性方向”。实验表明，操纵此方向可改变模型对指令有害性的判断，而操纵“拒绝方向”仅影响拒绝响应。研究还揭示了某些越狱方法通过降低拒绝信号而非改变模型对有害性的内在信念来发挥作用。基于此，提出了一种利用LLMs内部有害性表示作为“潜在防护”（Latent Guard）的安全应用，该方法能有效检测不安全输入并减少过度拒绝，且对对抗性微调攻击具有鲁棒性，性能可媲美专用安全模型。这为理解和提升AI安全提供了新的视角。

> **摘要翻译:** 大型语言模型（LLMs）被训练来拒绝有害指令，但它们是否真正理解有害性，而不仅仅是拒绝？先前的研究表明，LLMs的拒绝行为可以通过一个一维子空间（即拒绝方向）来调节。在这项工作中，我们确定了一个分析LLMs安全机制的新维度，即有害性，它在内部被编码为与拒绝不同的概念。存在一个与拒绝方向不同的有害性方向。作为因果证据，沿着有害性方向操纵可以导致LLMs将无害指令解释为有害，但沿着拒绝方向操纵则倾向于直接引发拒绝响应，而不会逆转模型对有害性的判断。此外，利用我们识别出的有害性概念，我们发现某些越狱方法通过减少拒绝信号起作用，而没有逆转模型内部对有害性的信念。我们还发现，对抗性微调模型以接受有害指令对模型内部有害性信念的影响极小。这些见解带来了一个实用的安全应用：模型的潜在有害性表示可以作为一种内在的安全防护（Latent Guard），用于检测不安全输入和减少过度拒绝，并且对微调攻击具有鲁棒性。例如，我们的Latent Guard在不同的越狱方法中，其性能与Llama Guard 3 8B（一个专门的微调安全防护模型）相当或更好。我们的发现表明，LLMs内部对有害性的理解比其拒绝决策对不同的输入指令更具鲁棒性，为研究AI安全提供了新视角。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [418] [ITUNLP at SemEval-2025 Task 8: Question-Answering over Tabular Data: A Zero-Shot Approach using LLM-Driven Code Generation](https://arxiv.org/abs/2508.00762)
> *ITUNLP在SemEval-2025任务8上的表现：基于表格数据的问答：一种使用LLM驱动代码生成的零样本方法*

*Atakan Site, Emre Hakan Erdemir, Gülşen Eryiğit* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 表格问答, 零样本, LLM, 代码生成, Pandas

**Comment:** 

> **TL;DR:** 该论文提出了一种零样本解决方案，利用大型语言模型（LLM）驱动的代码生成，通过生成可执行的Pandas代码来解决SemEval-2025任务8（基于表格数据的问答）中的两个子任务，并取得了有竞争力的结果。

**AI_Comments:** 该论文的创新点在于其零样本方法，通过LLM驱动的代码生成来解决表格数据问答任务。利用开源LLM生成Pandas代码是一种实用且可扩展的策略。其在SemEval-2025任务中的表现证明了该方法的有效性和竞争力。该方法的局限性可能在于对LLM性能的依赖以及提示工程的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决SemEval-2025任务8（DataBench，基于表格数据的问答）中的挑战，该任务要求在不同领域的表格数据集上执行问答，包括DataBench QA（子任务I）和DataBench Lite QA（子任务II）。

**Method:** 作者开发了一种零样本解决方案，特别强调利用基于大型语言模型（LLM）的代码生成。具体来说，他们提出了一个Python代码生成框架，该框架利用最先进的开源LLM通过优化的提示策略生成可执行的Pandas代码。

**Result:** 实验表明，不同的LLM在Python代码生成方面表现出不同程度的有效性。此外，结果显示，与替代方法相比，Python代码生成在表格问答中取得了卓越的性能。在开源模型类别中，该系统在超越基线的30个系统中，在子任务I中获得第八名，在子任务II中获得第六名。

**Conclusion:** 该研究表明，利用LLM驱动的Python代码生成是一种有效且性能优越的表格问答零样本方法，在SemEval-2025任务8中取得了有竞争力的排名。

> **ai_Abstract:** 本文针对SemEval-2025任务8的表格数据问答挑战，提出了一种零样本解决方案。该方案核心是利用大型语言模型（LLM）生成可执行的Pandas代码，通过优化提示策略实现。实验结果表明，该LLM驱动的代码生成方法在表格问答中表现优异，并优于其他方法。该系统在任务的子任务I中排名第八，子任务II中排名第六，显示了其竞争力。

> **摘要翻译:** 本文介绍了我们为SemEval-2025任务8：DataBench，基于表格数据的问答而开发的系统。该任务的主要目标是在两个子任务下对来自不同领域的给定表格数据集执行问答：DataBench QA（子任务I）和DataBench Lite QA（子任务II）。为了解决这两个子任务，我们开发了一种零样本解决方案，特别强调利用基于大型语言模型（LLM）的代码生成。具体来说，我们提出了一个Python代码生成框架，该框架利用最先进的开源LLM通过优化的提示策略生成可执行的Pandas代码。我们的实验表明，不同的LLM在Python代码生成方面表现出不同程度的有效性。此外，结果显示，与替代方法相比，Python代码生成在表格问答中取得了卓越的性能。尽管本文提交时我们零样本系统中的排名未知，但我们的系统在开源模型类别中，在超越基线的30个系统中，在子任务I中获得第八名，在子任务II中获得第六名。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [433] [Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun Handling in Large Language Models](https://arxiv.org/abs/2508.00788)
> *他们理解它们吗？大型语言模型中非二元代词处理的最新评估*

*Xushuo Tang, Yi Ding, Zhengyi Yang, Yin Chen, Yongrui Gu, Wenke Yang, Mingchen Ju, Xin Cao, Yongfei Liu, Wenjie Zhang* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 代词处理, 非二元, 公平性, 包容性

**Comment:** 

> **TL;DR:** 大型语言模型在处理中性代词方面有所改进，但在新代词和逆向推断任务上仍表现不佳，表明在身份敏感推理方面存在持续差距。

**AI_Comments:** 该论文解决了AI公平性和包容性的一个关键方面，这对于LLM在敏感应用中的部署至关重要。引入更新的基准（MISGENDERED+）对当前模型评估很有价值。研究结果突出了进展，但也指出了LLM在处理不常见或复杂代词用法方面仍然存在的关键挑战，这表明LLM的“理解”对于实现真正的包容性而言仍不完全。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）越来越多地部署在公平性和包容性至关重要的敏感环境中。之前的研究揭示了早期LLM在处理包容性代词方面的局限性，但这些评估已过时。本研究旨在提供一个更新的评估。

**Method:** 引入了MISGENDERED+，一个扩展和更新的基准来评估LLM的代词忠实度。对GPT-4o、Claude 4、DeepSeek-V3、Qwen Turbo和Qwen2.5这五种代表性LLM进行了零样本、少样本和性别身份推断的基准测试。

**Result:** 与之前的研究相比，在二元和中性代词准确性方面有显著改进。然而，新代词和逆向推断任务的准确性仍然不一致，这突显了身份敏感推理中持续存在的差距。

**Conclusion:** 尽管有所改进，LLM在身份敏感推理方面，特别是在新代词和逆向推断方面，仍然面临挑战，表明未来需要进行包容性人工智能研究。

> **ai_Abstract:** 本文引入了MISGENDERED+，一个更新的基准来评估大型语言模型（LLM）处理包容性代词的能力。该研究对GPT-4o、Claude 4、DeepSeek-V3、Qwen Turbo和Qwen2.5等五种最新LLM在不同推断设置下进行了基准测试。尽管与之前的研究相比，在二元和中性代词准确性方面有所改进，但评估结果显示，在处理新代词和逆向推断任务时仍然存在持续的不一致性，这突显了LLM在身份敏感推理方面仍面临挑战。

> **摘要翻译:** 大型语言模型（LLM）越来越多地部署在公平性和包容性至关重要的敏感环境中。代词使用，特别是与中性代词和新代词相关的，仍然是负责任人工智能面临的关键挑战。之前的研究，例如MISGENDERED基准测试，揭示了早期LLM在处理包容性代词方面的显著局限性，但受限于过时模型和有限的评估。在本研究中，我们引入了MISGENDERED+，一个用于评估LLM代词忠实度的扩展和更新基准。我们对五种代表性LLM，GPT-4o、Claude 4、DeepSeek-V3、Qwen Turbo和Qwen2.5，在零样本、少样本和性别身份推断方面进行了基准测试。我们的结果显示，与之前的研究相比有显著改进，特别是在二元和中性代词准确性方面。然而，新代词和逆向推断任务的准确性仍然不一致，这突显了身份敏感推理中持续存在的差距。我们讨论了其影响、模型特定的观察结果以及未来包容性人工智能研究的方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [437] [PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning](https://arxiv.org/abs/2508.00344)
> *PilotRL：通过全局规划引导的渐进式强化学习训练语言模型智能体*

*Keer Lu, Chong Chen, Bin Cui, Huang Leng, Wentao Zhang* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型智能体, 全局规划, 渐进式强化学习, AdaPlan, 长期决策

**Comment:** 

> **TL;DR:** PilotRL提出一种新的训练框架，通过全局规划引导的渐进式强化学习，提升LLM智能体在复杂任务中的长期规划和泛化能力，并取得SOTA性能。

**AI_Comments:** 这篇论文通过提出PilotRL框架，有效解决了LLM智能体在复杂任务中长期规划和泛化能力的瓶颈。其创新点在于结合了全局规划引导和渐进式强化学习，并分阶段优化规划和执行，这为LLM智能体的训练提供了一个新的、高效的范式。实验结果尤其令人印象深刻，显示出PilotRL在性能上超越了顶级的闭源模型，这对于推动LLM智能体在实际应用中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLM）智能体在处理需要长期战略规划的复杂任务时面临挑战，主要原因是ReAct等范式侧重单步推理和即时行动，且规划器与执行器之间的协调以及监督微调导致的泛化能力受限。

**Method:** 论文引入了自适应全局规划智能体范式AdaPlan，旨在协同高层显式指导与执行，以支持有效的长期决策。在此基础上，提出了PilotRL，一个由渐进式强化学习驱动的LLM智能体全局规划引导训练框架。PilotRL分三步：首先，培养模型遵循全局计划显式指导的能力；其次，优化生成计划的质量；最后，联合优化模型的规划与执行协调。

**Result:** PilotRL取得了最先进的性能，其中LLaMA3.1-8B-Instruct + PilotRL在性能上超越了闭源的GPT-4o 3.60%，并且与参数规模相当的GPT-4o-mini相比，实现了55.78%的显著提升。

**Conclusion:** PilotRL通过其全局规划引导的渐进式强化学习框架，有效解决了LLM智能体在复杂任务中长期规划和泛化能力的挑战，取得了显著的性能提升，证明了其在构建高效LLM智能体方面的潜力。

> **ai_Abstract:** 本文提出PilotRL，一个基于全局规划引导的渐进式强化学习框架，用于训练大型语言模型智能体。针对现有LLM智能体在复杂任务中长期规划能力和泛化性不足的问题，PilotRL引入AdaPlan范式，通过三阶段优化（遵循计划、优化计划、协调规划与执行）来提升智能体性能。实验结果表明，PilotRL显著优于现有SOTA模型，验证了其在复杂智能体任务中的有效性。

> **摘要翻译:** 大型语言模型（LLMs）在处理智能体导向任务方面取得了显著进展。尽管它们潜力巨大，但在将LLMs部署到基于智能体的环境中时，现有工作仍面临挑战。广泛采用的ReAct智能体范式侧重于将单步推理与即时行动执行相结合，这限制了其在需要长期战略规划的复杂任务中的有效性。此外，在问题解决过程中，规划器和执行器之间的协调也是智能体设计中需要考虑的关键因素。另外，当前的方法主要依赖于监督微调，这通常导致模型记住既定的任务完成轨迹，从而在面对新颖问题背景时限制了它们的泛化能力。为了解决这些这些挑战，我们引入了一种自适应全局计划智能体范式AdaPlan，旨在协同高层显式指导与执行，以支持有效的长期决策。基于所提出的范式，我们进一步提出了PilotRL，一个由渐进式强化学习驱动的LLM智能体全局规划引导训练框架。我们首先培养模型在处理智能体任务时遵循全局计划显式指导的能力。随后，在此基础上，我们专注于优化生成计划的质量。最后，我们对模型的规划和执行协调进行联合优化。实验表明PilotRL能够实现最先进的性能，其中LLaMA3.1-8B-Instruct + PilotRL超越了闭源的GPT-4o 3.60%，同时与参数规模相当的GPT-4o-mini相比，显示出55.78%的更大提升。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [439] [FinResearchBench: A Logic Tree based Agent-as-a-Judge Evaluation Framework for Financial Research Agents](https://arxiv.org/abs/2507.16248)
> *FinResearchBench：一个基于逻辑树的金融研究智能体评估框架*

*Rui Sun, Zuo Bai, Wentao Zhang, Yuxiang Zhang, Li Zhao, Shan Sun, Zhengwen Qiu* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** FinResearchBench, 金融研究智能体, 评估框架, Agent-as-a-Judge, 逻辑树

**Comment:** 

> **TL;DR:** FinResearchBench提出了一个基于逻辑树的Agent-as-a-Judge评估框架，专门用于全面、自动评估金融研究智能体，填补了现有评估框架的空白。

**AI_Comments:** FinResearchBench的创新之处在于其“逻辑树”作为Agent-as-a-Judge的中间评估机制，这可能提高了评估的透明度和可解释性。它专注于金融这一复杂且高要求的领域，填补了该领域AI智能体评估的空白，对于推动金融AI研究具有重要意义。该框架的全面性体现在覆盖了7种任务类型和70个问题，这为金融智能体的性能评估提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** AI智能体在专业研究应用中快速发展，尤其是深度研究智能体。然而，目前缺乏系统和自动化的评估框架和基准来衡量这些研究智能体的能力。特别是，金融研究问题具有独特的复杂性和微妙性，现有工具未能有效解决这一评估缺口。

**Method:** 论文提出了FinResearchBench，这是一个基于逻辑树的Agent-as-a-Judge系统，专门针对金融研究智能体。它通过提取研究成果的逻辑树作为中间信息，进行全面、可靠且鲁棒的评估。

**Result:** FinResearchBench是首个创新性的Agent-as-a-Judge系统，能够提取研究成果的逻辑树并用于评估；它面向金融领域，涵盖了70个典型的金融研究问题，分布在7种常见的任务类型中。

**Conclusion:** FinResearchBench通过其创新的逻辑树Agent-as-a-Judge方法和对金融领域特定任务的广泛覆盖，成功地为金融研究智能体提供了一个全面、可靠且自动化的评估框架，填补了现有评估工具的空白。

> **ai_Abstract:** 本论文提出了FinResearchBench，一个创新的基于逻辑树的Agent-as-a-Judge评估框架，旨在解决当前缺乏系统化、自动化评估工具来衡量金融研究AI智能体能力的问题。该框架通过提取研究成果的逻辑树作为中间评估信息，能够对金融领域7种主要任务类型的70个典型问题进行全面、可靠且鲁棒的自动化评估，是首个专门针对金融研究智能体的Agent-as-a-Judge系统。

> **摘要翻译:** 最近，AI智能体在智能方面迅速发展，并广泛应用于专业研究领域，如STEM、软件开发、金融等。在这些AI智能体中，深度研究智能体是一个关键类别，因为它可以执行长周期任务并解决更复杂的问题。然而，目前鲜有评估框架和基准能够系统且自动化地调查这些研究智能体的能力。此外，金融研究问题具有独特的复杂性和微妙性。为了填补这一空白，我们提出了FinResearchBench，这是一个基于逻辑树的Agent-as-a-Judge系统，专门针对金融研究智能体。它提供了对金融研究领域7种关键任务类型中研究智能体的全面和自动化评估。这项工作的贡献是双重的：（1）第一个创新的Agent-as-a-Judge系统，它提取研究成果的逻辑树并将其作为中间信息，以提供全面、可靠和鲁棒的评估；（2）面向金融领域，涵盖了70个典型的金融研究问题，分布在7种经常遇到的任务类型中。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [448] [Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models](https://arxiv.org/abs/2508.00819)
> *超越固定：扩散大语言模型的可变长度去噪*

*Jinsong Li, Xiaoyi Dong, Yuhang Zang, Yuhang Cao, Jiaqi Wang, Dahua Lin* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 扩散大语言模型, 变长生成, 去噪策略, DAEDAL, 计算效率

**Comment:** Code is available at https://github.com/Li-Jinsong/DAEDAL

> **TL;DR:** 扩散大语言模型（DLLMs）的固定生成长度限制了其应用，本文提出DAEDAL策略，实现动态自适应长度扩展，提高性能和效率。

**AI_Comments:** 本文提出DAEDAL，有效地解决了扩散大语言模型（DLLMs）因静态生成长度导致的性能和效率瓶颈。其创新之处在于利用模型内部信号进行动态长度调整，且无需额外训练，这大大降低了应用门槛。DAEDAL通过两阶段策略（预去噪阶段的粗粒度扩展和去噪阶段的细粒度区域扩展）确保了输出的完整性和效率。这项工作对于推动DLLMs在复杂任务中的实际应用具有重要意义，使其在与自回归模型的竞争中更具优势。

<details>
  <summary>Details</summary>

**Motivation:** 扩散大语言模型（DLLMs）的实际应用受到关键架构约束的阻碍：需要静态预定义的生成长度。这种静态长度分配导致不足长度时性能受损，过长长度时计算开销大且可能性能下降。

**Method:** 本文提出DAEDAL，一种新颖的、无需训练的去噪策略，用于实现扩散大语言模型的动态自适应长度扩展。DAEDAL分两阶段操作：1) 在去噪过程之前，从短初始长度开始，根据序列完成度指标迭代扩展到粗略的、适合任务的长度。2) 在去噪过程中，通过插入掩码token动态干预，精确定位并扩展不足的生成区域，确保最终输出完全展开。

**Result:** 在DLLMs上的广泛实验表明，DAEDAL的性能与精心调优的固定长度基线相当，在某些情况下甚至更优，同时通过实现更高的有效token比率提高了计算效率。

**Conclusion:** DAEDAL解决了DLLMs的静态长度约束，释放了DLLMs的新潜力，弥合了与自回归对应模型的关键差距，并为更高效、更强大的生成铺平了道路。

> **ai_Abstract:** 本文提出了一种名为DAEDAL的无需训练的去噪策略，旨在解决扩散大语言模型（DLLMs）在实际应用中面临的静态生成长度限制。DAEDAL通过在去噪前迭代扩展初始长度，并在去噪过程中动态扩展不足区域，实现了DLLMs的动态自适应长度生成。实验证明，DAEDAL在保持甚至超越固定长度基线性能的同时，显著提升了计算效率，为DLLMs的广泛应用开辟了新途径。

> **摘要翻译:** 扩散大语言模型（DLLMs）正作为自回归大语言模型的一种强大替代方案而兴起，它们提供了高效的并行生成和强大的全局上下文建模能力。然而，DLLMs的实际应用受到一个关键架构约束的阻碍：需要静态预定义的生成长度。这种静态长度分配导致了一个问题性的权衡：长度不足会严重影响复杂任务的性能，而长度过长的则会带来显著的计算开销，有时甚至导致性能下降。尽管推理框架是固定的，但我们观察到模型本身拥有与给定任务最佳响应长度相关的内部信号。为了弥补这一差距，我们利用这些潜在信号，引入了DAEDAL，一种新颖的、无需训练的去噪策略，它能够为扩散大语言模型实现动态自适应长度扩展。DAEDAL分两个阶段操作：1）在去噪过程之前，DAEDAL从一个较短的初始长度开始，并根据序列完成度指标迭代地将其扩展到一个粗略的、适合任务的长度。2）在去噪过程中，DAEDAL通过插入掩码标记来精确定位和扩展不足的生成区域，从而动态地进行干预，确保最终输出得到充分发展。对DLLMs的广泛实验表明，DAEDAL的性能与精心调优的固定长度基线相当，在某些情况下甚至更优，同时通过实现更高的有效标记比率提高了计算效率。通过解决静态长度约束，DAEDAL释放了DLLMs的新潜力，弥合了与自回归对应模型的关键差距，并为更高效、更强大的生成铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [464] [Leveraging Synthetic Data for Question Answering with Multilingual LLMs in the Agricultural Domain](https://arxiv.org/abs/2507.16974)
> *利用合成数据在农业领域实现多语言大型语言模型的问答*

*Rishemjit Kaur, Arshdeep Singh Bhankhar, Jashanpreet Singh Salh, Sudhir Rajput, Vidhi, Kashish Mahendra, Bhavika Berwal, Ritesh Kumar, Surangika Ranathunga* | **Category: cs.CL, cs.AI, I.2.7; J.m** | **Updated: 2025-08-01**

**Keywords:** 合成数据, 问答, 多语言大型语言模型, 农业领域, 微调

**Comment:** 16 pages, 9 tables, Appendix A-L

> **TL;DR:** 本文通过生成多语言农业合成数据并微调大型语言模型，显著提升了农业领域问答的准确性和相关性。

**AI_Comments:** 这项研究通过利用特定领域的合成数据来提升多语言大型语言模型在农业问答中的表现，提供了一个实用的解决方案，对于弥合通用模型与特定领域需求之间的差距具有重要意义。其创新之处在于利用合成数据解决数据稀缺问题，并关注多语言环境。

<details>
  <summary>Details</summary>

**Motivation:** 农民及时获取准确的母语农业信息至关重要，但现有通用大型语言模型在本地和多语言农业语境中缺乏精确性。

**Method:** 从印度农业特定文档生成多语言（英语、印地语、旁遮普语）合成数据集，并用这些数据微调大型语言模型以进行问答任务。

**Result:** 与基线模型相比，经过微调的大型语言模型在真实性、相关性和农业共识方面表现出显著改进。

**Conclusion:** 通过利用合成数据微调多语言大型语言模型，可以有效提升农业领域问答的准确性和适用性。

> **ai_Abstract:** 本研究旨在解决通用大型语言模型在农业领域多语言问答中精确性不足的问题。研究者通过从印度农业文档生成多语言（英语、印地语、旁遮普语）合成数据集，并用这些数据微调大型语言模型。实验结果表明，与基线模型相比，经过微调的模型在问答的真实性、相关性和农业共识方面均有显著提升。

> **摘要翻译:** 及时让农民以其母语获取准确的农业相关信息对于农业领域的成功至关重要。公开可用的通用大型语言模型通常提供通用的农业建议，在本地和多语言环境中缺乏精确性。我们的研究通过从印度的农业特定文档生成多语言（英语、印地语、旁遮普语）合成数据集，并微调大型语言模型以进行问答（QA）任务，从而解决了这一局限性。在人工创建的数据集上进行的评估表明，与基线模型相比，经过微调的大型语言模型在真实性、相关性和农业共识方面取得了显著改进。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [467] [Lucy: edgerunning agentic web search on mobile with machine generated task vectors](https://arxiv.org/abs/2508.00360)
> *Lucy：移动端边缘运行的智能网络搜索代理，采用机器生成的任务向量*

*Alan Dao, Dinh Bach Vu, Alex Nguyen, Norapat Buppodom* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 小型语言模型, 动态任务向量, 代理网络搜索, RLVR, SimpleQA

**Comment:** 

> **TL;DR:** Lucy是一个1.7B参数的小型语言模型，它通过将内部推理视为动态任务向量机并进行优化，在SimpleQA基准测试上达到了与大型模型相当的性能，证明小型模型通过结构化、自构建的任务推理可以媲美大型模型。

**AI_Comments:** 该论文的创新点在于提出了“动态任务向量机”的概念，将模型的内部推理视为一个动态的、自适应的任务向量构建和优化过程，而非固定的思维痕迹。这种方法使得小型语言模型能够通过自构建的结构化推理，显著提升在知识密集型任务上的表现，甚至达到与大型模型相当的性能。这对于在资源受限的移动设备上部署高性能AI代理具有重要意义，克服了传统SLM的知识瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 小型语言模型（SLMs）由于容量限制，在知识密集型任务中存在固有限制。虽然测试时计算可以增强性能，但大多数方法将推理视为固定或启发式过程。

**Method:** 本研究提出了一种新范式：将模型的内部推理（由<think>和</think>标签限定）视为一个动态任务向量机。研究将生成过程本身解释为模型即时构建和完善自身任务向量的机制。通过RLVR优化这种动态任务向量机，并结合MCP集成，训练了一个代理式网络搜索模型Lucy。

**Result:** Lucy，一个1.7B参数的SLM，利用这种动态推理机制与MCP集成，在SimpleQA基准测试上达到了78.3%的准确率，与DeepSeek-V3等大型模型表现相当。

**Conclusion:** 小型模型通过结构化、自构建的任务推理，可以与大型模型相媲美。

> **ai_Abstract:** 本研究提出了一种名为Lucy的1.7B参数小型语言模型，旨在解决小型模型在知识密集型任务中的局限性。该模型引入了将内部推理视为动态任务向量机的新范式，并通过RLVR优化了这一机制，同时结合MCP集成。实验结果表明，Lucy在SimpleQA基准测试上取得了78.3%的准确率，性能与DeepSeek-V3等大型模型相当，证明了通过结构化、自构建的任务推理，小型模型也能达到大型模型的水平。

> **摘要翻译:** 小型语言模型（SLMs）由于其受限的容量，在知识密集型任务中存在固有限制。虽然测试时计算为提升性能提供了一条途径，但大多数方法将推理视为一个固定或启发式的过程。在这项工作中，我们提出了一种新的范式：将模型的内部推理（由<think>和</think>标签限定）视为一个动态任务向量机。我们不再将这些标签内的内容仅仅视为思想的痕迹，而是将生成过程本身解释为模型即时构建和完善自身任务向量的机制。我们开发了一种通过RLVR优化这种动态任务向量机的方法，并成功训练了一个代理式网络搜索模型。我们展示了Lucy，一个1.7B参数的SLM，它利用这种动态推理机制并结合MCP集成，在SimpleQA基准测试上达到了78.3%的准确率，表现与DeepSeek-V3等大型模型不相上下。这表明，当小型模型配备结构化、自构建的任务推理时，它们可以与大型模型竞争。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [494] [IFEvalCode: Controlled Code Generation](https://arxiv.org/abs/2507.22462)
> *IFEValCode：受控代码生成*

*Jian Yang, Wei Zhang, Shukai Liu, Linzheng Chai, Yingshui Tan, Jiaheng Liu, Ge Zhang, Wangchunshu Zhou, Guanglin Niu, Zhoujun Li, Binyuan Hui, Junyang Lin* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 代码生成, 指令遵循, 大语言模型, 基准测试, IFEvalCode

**Comment:** 10 pages

> **TL;DR:** 论文介绍了IFEvalCode，一个多语言基准测试，用于评估代码大语言模型在受控代码生成中的指令遵循能力，并发现闭源模型表现更好，且模型在代码正确性和指令遵循性之间存在显著差距。

**AI_Comments:** 这篇论文通过引入前向和后向约束生成来提升代码大语言模型的指令遵循能力，并提出了一个创新的多语言基准测试IFEvalCode。IFEvalCode的创新之处在于将代码评估解耦为“正确性”和“指令遵循性”两个独立维度，这为更细致地分析模型性能提供了重要工具。研究结果揭示了当前模型在受控代码生成方面的局限性，特别是开源模型与闭源模型之间的差距，以及正确性与指令遵循性之间的鸿沟，这对于未来代码LLM的研究和开发具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管代码大语言模型在代码生成方面取得了显著进展，但现实世界的应用对代码生成有更严格的要求，例如编码风格、行数和结构约束，而不仅仅是代码的正确性。现有模型难以严格遵循这些详细的指令。

**Method:** 论文通过引入前向和后向约束生成来提高代码大语言模型在受控代码生成中的指令遵循能力。作者提出了IFEvalCode，一个包含1.6K测试样本的多语言基准测试，涵盖七种编程语言（Python, Java, JavaScript, TypeScript, Shell, C++, C#），每个样本都包含中文和英文查询。IFEvalCode将评估解耦为两个指标：正确性（Corr.）和指令遵循性（Instr.）。

**Result:** 在对40多个大语言模型进行的实验中，结果显示闭源模型在可控代码生成方面优于开源模型。此外，模型生成正确代码的能力与精确遵循指令的能力之间存在显著差距。

**Conclusion:** IFEvalCode基准测试揭示了当前代码大语言模型在受控代码生成（特别是指令遵循方面）的局限性，并强调了闭源模型在此领域的领先地位以及模型在代码正确性和指令遵循性之间存在的性能鸿沟，这为未来的研究指明了方向。

> **ai_Abstract:** 本文介绍了IFEvalCode，一个用于评估代码大语言模型受控代码生成能力的基准测试。该研究旨在解决现有模型在遵循详细指令（如编码风格和结构）方面的不足。IFEvalCode包含多语言样本，并首次将评估指标分为代码正确性和指令遵循性。实验结果表明，闭源模型在可控代码生成上表现更优，并且模型在生成正确代码和遵循详细指令之间存在显著性能差距。

> **摘要翻译:** 代码大语言模型（Code LLMs）通过将自然语言描述转化为功能代码，在代码生成方面取得了显著进展；然而，现实世界的应用往往要求更严格地遵守详细要求，例如编码风格、行数和结构约束，而不仅仅是正确性。为了解决这个问题，本文引入了前向和后向约束生成，以提高代码大语言模型在受控代码生成中的指令遵循能力，确保输出更符合人类定义的准则。作者进一步提出了IFEvalCode，一个多语言基准测试，包含七种编程语言（Python、Java、JavaScript、TypeScript、Shell、C++和C#）的1.6K个测试样本，每个样本都包含中文和英文查询。与现有基准测试不同，IFEvalCode将评估解耦为两个指标：正确性（Corr.）和指令遵循性（Instr.），从而实现更细致的评估。对40多个大语言模型进行的实验表明，闭源模型在可控代码生成方面优于开源模型，并凸显了模型生成正确代码的能力与精确遵循指令的代码之间存在显著差距。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [498] [EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices](https://arxiv.org/abs/2508.00370)
> *EdgeInfinite-Instruct：连接SFT优化与NPU级边缘设备效率*

*Jiyu Chen, Poh Seng Lim, Shuang Peng, Daxiong Luo, JungHau Foo, Yap Deep, Timothy Lee Jun Jie, Kelvin Teh Kae Wen, Fan Yang, Danyu Feng, Hao-Yun Chen, Peng-Wen Chen, Fangyuan Li, Xiaoxin Chen, Wong Wai Mun* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 边缘设备, LLMs, 长序列, SFT, NPU, 量化

**Comment:** 9 pages

> **TL;DR:** LLMs在边缘设备上处理长序列面临挑战。EdgeInfinite-Instruct通过分段监督微调（S-SFT）和NPU优化，在保持效率的同时提升了长序列任务性能。

**AI_Comments:** 该论文创新性地结合了SFT优化和NPU级效率，解决了LLMs在边缘设备上部署长序列任务的关键挑战。其分段SFT策略和针对NPU的优化（PTQ和固定形状计算图）具有实用价值，为资源受限环境下的LLM部署提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 在资源受限的边缘设备上部署Transformer-based LLMs处理长序列任务，面临自注意力二次时间复杂度和KV缓存需求增长的挑战。现有优化方案未能有效降低首个令牌生成时间（TTFT）或可能损害性能。现有替代架构需完全重训练且缺乏基础设施支持。EdgeInfinite虽有改进但指令遵循能力有限且缺乏移动端优化。

**Method:** 提出EdgeInfinite-Instruct，引入分段监督微调（S-SFT）策略，专为摘要和问答等长序列任务设计。通过细粒度后训练量化（PTQ）减少计算需求并保持精度。实现固定形状计算图，通过场景特定定制输入token和缓存大小，平衡内存使用和设备效率。

**Result:** 实验表明，该方法在长上下文基准测试和实际移动任务中，在NPU加速的边缘设备上提高了特定领域性能，同时保持了效率。

**Conclusion:** EdgeInfinite-Instruct通过结合分段监督微调（S-SFT）、细粒度后训练量化（PTQ）和固定形状计算图，有效解决了LLMs在边缘设备上处理长序列的挑战，提升了性能和效率。

> **ai_Abstract:** EdgeInfinite-Instruct旨在解决LLMs在边缘设备上处理长序列任务的挑战。该方法通过引入分段监督微调（S-SFT）提升指令遵循能力，并结合细粒度后训练量化（PTQ）和固定形状计算图优化NPU部署效率。实验证明，其在保持效率的同时，显著提升了长上下文任务的性能。

> **摘要翻译:** 在资源受限的边缘设备上部署基于Transformer的大型语言模型（LLMs）进行长序列任务仍然具有挑战性，这归因于自注意力的二次时间复杂度和不断增长的键值（KV）缓存需求。尽管现有的KV缓存优化提高了内存效率，但它们通常无法缩短首个令牌生成时间（TTFT），并通过令牌剪枝可能降低性能。替代序列建模架构解决了其中一些限制，但通常需要完全重新训练并缺乏基础设施支持。EdgeInfinite通过仅微调一小部分参数提供了一种高效的解决方案，在降低计算和内存成本（包括改进的TTFT）的同时保持了质量。然而，其指令遵循能力有限，并且缺乏针对移动设备的优化。为了解决这些问题，我们提出了EdgeInfinite-Instruct，它引入了一种分段监督微调（S-SFT）策略，专为摘要和问答等长序列任务量身定制。我们通过采用细粒度后训练量化（PTQ）来减少计算需求同时保持精度，并通过实现固定形状计算图（通过针对特定场景定制输入令牌和缓存大小来平衡内存使用和设备效率）进一步优化了EdgeInfinite-Instruct，以实现其在边缘NPU上的高效部署。在长上下文基准测试和实际移动任务上的实验表明，我们的方法在NPU加速的边缘设备上提高了特定领域性能，同时保持了效率。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [501] [Mitigating Gender Bias via Fostering Exploratory Thinking in LLMs](https://arxiv.org/abs/2505.17217)
> *通过培养LLM的探索性思维来缓解性别偏见*

*Kangda Wei, Hasnat Md Abdullah, Ruihong Huang* | **Category: cs.CL, cs.AI, cs.CY** | **Updated: 2025-08-01**

**Keywords:** 性别偏见, 大型语言模型, 探索性思维, 数据生成, 直接偏好优化

**Comment:** 

> **TL;DR:** 本研究提出一种通过培养大型语言模型探索性思维的数据生成框架，以有效缓解其性别偏见，同时保持或增强模型能力。

**AI_Comments:** 本研究的创新之处在于提出了一种新颖的数据生成框架，通过培养LLM的探索性思维来系统性地缓解性别偏见。该方法通过生成性别对称的道德模糊情景故事对并引导模型进行自我纠正，有效解决了LLM中普遍存在的性别歧视问题，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）普遍存在性别偏见，导致在不同情境下对男性和女性主题的处理不平等。为了解决这个问题。

**Method:** 提出了一种新颖的数据生成框架，旨在培养LLM的探索性思维。该方法引导模型生成具有结构相同、道德模糊情景的男性和女性主角的故事对，然后引出并比较它们的道德判断。当出现不一致时，模型会被引导产生平衡、性别中立的判断。这些故事-判断对通过直接偏好优化（DPO）来微调或优化模型。

**Result:** 实验结果表明，我们的方法显著减少了性别偏见，同时保留甚至增强了模型的通用能力。

**Conclusion:** 本研究提出的方法能够显著缓解大型语言模型中的性别偏见，同时保持或提升其通用能力。

> **ai_Abstract:** 该论文提出了一种新颖的数据生成框架，通过引导大型语言模型（LLMs）生成并比较在道德模糊情境下的性别对称故事对的判断，并在出现偏见时进行纠正，从而培养LLMs的探索性思维。利用直接偏好优化（DPO）对这些数据进行微调，实验证明该方法能显著减少LLMs的性别偏见，同时保持或提升其通用能力。

> **摘要翻译:** 大型语言模型（LLMs）普遍存在性别偏见，导致在不同情境下对男性和女性主题的处理不平等。为了解决这个问题，我们提出了一种新颖的数据生成框架，旨在培养LLM的探索性思维。我们的方法引导模型生成具有结构相同、道德模糊情景的男性和女性主角的故事对，然后引出并比较它们的道德判断。当出现不一致时，模型会被引导产生平衡、性别中立的判断。这些故事-判断对通过直接偏好优化（DPO）来微调或优化模型。实验结果表明，我们的方法显著减少了性别偏见，同时保留甚至增强了模型的通用能力。我们将发布代码和生成的数据。我们已在以下网址发布代码和生成的数据：https://github.com/WeiKangda/LLMs-Exploratory-Bias-Mitigation/tree/main。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [527] [Multi-Layer Attention is the Amplifier of Demonstration Effectiveness](https://arxiv.org/abs/2508.00385)
> *多层注意力是示例有效性的放大器*

*Dingzirui Wang, Xuangliang Zhang, Keyan Xu, Qingfu Zhu, Wanxiang Che, Yang Deng* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 上下文学习, 示例选择, 梯度流, 多层注意力, 模型有效性

**Comment:** 

> **TL;DR:** 本文研究了上下文学习中示例无效的原因，发现多层模型会放大有效示例的影响，并提出了基于梯度流的示例选择方法GradS，提升了性能。

**AI_Comments:** 本文的创新点在于深入分析了上下文学习中示例无效的内在机制，特别是引入了梯度流的概念来解释无效性，并揭示了多层模型对示例有效性差异的放大作用。此外，提出的GradS方法基于理论分析，为更有效的示例选择提供了新视角，解决了现有方法忽视模型已学习信息的问题，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究普遍假设上下文学习（ICL）中的示例是有效的，但许多研究表明并非所有示例都有效，有些甚至不能带来性能提升。因此，本文旨在探究示例无效的原因。

**Method:** 本文基于梯度流和线性自注意力模型分析示例无效的原因，推导出当示例信息已被模型学习或与用户查询无关时会无效。针对现有示例选择方法忽略模型已学习信息的问题，提出了一种名为GradS的新方法，利用示例相对于给定用户查询的梯度流大小作为选择标准，以确保所选示例的有效性。

**Result:** 实验结果证实，随着模型层数的增加，示例之间有效性的差异被放大，证实了理论推导。GradS方法在四个主流LLM和五个主流数据集上，相对于最强基线平均取得了6.8%的相对改进，证明了其有效性。

**Conclusion:** 多层模型会放大有效示例的影响，示例无效的原因在于信息已被模型学习或与查询无关。所提出的GradS方法通过利用梯度流进行示例选择，显著提升了上下文学习的性能。

> **ai_Abstract:** 本文深入研究了上下文学习（ICL）中示例无效的内在机制，发现示例无效是由于其信息已被模型学习或与用户查询无关，并且在多层模型中，示例有效性的差异会随着层数增加而放大。针对这一发现，提出了一种基于梯度流的新颖示例选择方法GradS，该方法考虑了模型已学习的信息。实验证明GradS能有效选择示例，显著提升ICL性能，并验证了多层注意力对示例有效性差异的放大作用。

> **摘要翻译:** 大量研究调查了上下文学习（ICL）有效性的潜在机制，以启发相关方法的设计。然而，现有工作主要假设ICL中提供的示例是有效的，而许多研究表明并非所有示例都有效，未能使ICL产生任何性能改进。因此，在本文中，我们调查了示例无效的原因。我们的分析基于梯度流和线性自注意力模型。通过将梯度流设置为零，我们推断如果示例的信息已被模型学习或与用户查询无关，则该示例将变得无效。此外，我们证明在多层模型中，示例之间有效性的差异随着层数的增加而被放大，导致模型更关注有效的示例。考虑到当前示例选择方法主要关注与用户查询的相关性，而忽略了模型已经同化的信息，我们提出了一种名为GradS的新方法，该方法利用梯度流进行示例选择。我们使用示例相对于给定用户查询的梯度流大小作为标准，从而确保所选示例的有效性。我们在四个主流大型语言模型和五个主流数据集上验证了我们的推导和GradS。实验结果证实，随着模型层数的增加，示例之间有效性的差异被放大，证实了我们的推导。此外，GradS相对于最强基线平均取得了6.8%的相对改进，证明了其有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [529] [ControlMed: Adding Reasoning Control to Medical Language Model](https://arxiv.org/abs/2507.22545)
> *ControlMed：为医疗语言模型添加推理控制*

*Sung-Min Lee, Siyoon Lee, Juyeon Kim, Kyoungmin Roh* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 医疗语言模型, 推理控制, 计算效率, 临床决策, ControlMed

**Comment:** 13 pages

> **TL;DR:** ControlMed是一个医疗语言模型，允许用户在推理时控制推理过程的长度，以平衡准确性和计算效率。

**AI_Comments:** ControlMed的创新之处在于引入了推理过程的长度控制机制，这对于医疗领域这种对响应速度和资源效率有严格要求的场景至关重要。通过结合多阶段训练和强化学习，模型不仅提高了实用性，还保持了性能，为LLM在实际临床部署提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 现有的推理大型语言模型在医疗领域应用时，常生成不必要的冗长推理过程，导致计算开销大和响应延迟高，这阻碍了它们在实际临床环境中的部署。

**Method:** ControlMed通过一个三阶段的训练流程实现：1) 在包含直接和推理响应的大规模合成医疗指令数据集上进行预训练；2) 使用多长度推理数据和明确的长度控制标记进行监督微调；3) 利用基于模型的奖励信号进行强化学习，以提高事实准确性和响应质量。

**Result:** 在多种英语和韩语医疗基准测试中，ControlMed与现有最先进模型相比，取得了相似或更好的性能。此外，用户可以根据需要通过控制推理长度来灵活平衡推理准确性和计算效率。

**Conclusion:** ControlMed是一个实用且适应性强的解决方案，适用于临床问答和医疗信息分析。

> **ai_Abstract:** ControlMed是一个针对医疗领域的语言模型，旨在解决现有推理LLM推理过程过长导致的计算效率低下问题。该模型通过三阶段训练，包括预训练、监督微调和强化学习，使用户能够通过控制标记灵活调节推理长度，从而在推理准确性和计算效率之间取得平衡。实验证明，ControlMed在医疗基准测试上表现出色，并能有效适应临床问答和信息分析需求。

> **摘要翻译:** 推理大型语言模型（LLMs）以其增强的准确性和可解释性，正越来越多地被医疗领域采纳，因为临床决策的生命攸关性要求可靠的支持。尽管取得了这些进展，但现有的推理LLMs常常生成不必要冗长的推理过程，导致显著的计算开销和响应延迟。这些限制阻碍了它们在实际临床环境中的实际部署。为了解决这些挑战，我们引入了ControlMed，一个医疗语言模型，它允许用户在推理时通过细粒度的控制标记主动控制推理过程的长度。ControlMed通过一个三阶段的管道进行训练：1）在大规模合成医疗指令数据集上进行预训练，该数据集涵盖了直接和推理响应；2）使用多长度推理数据和明确的长度控制标记进行监督微调；3）使用基于模型的奖励信号进行强化学习，以提高事实准确性和响应质量。在各种英语和韩语医疗基准测试上的实验结果表明，我们的模型与最先进的模型相比，取得了相似或更好的性能。此外，用户可以根据需要通过控制推理长度来灵活平衡推理准确性和计算效率。这些发现表明，ControlMed是临床问答和医疗信息分析的实用且适应性强的解决方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [552] [SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV Vision-Language Navigation](https://arxiv.org/abs/2508.00390)
> *SA-GCS：面向无人机视觉-语言导航的语义感知高斯课程调度*

*Hengxing Cai, Jinhan Dong, Yijie Rao, Jingcheng Deng, Jingjun Tan, Qien Chen, Haidong Wang, Zhen Wang, Shiyu Huang, Agachai Sumalee, Renxin Zhong* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 无人机视觉-语言导航, 强化学习, 课程学习, 语义感知, 高斯调度

**Comment:** 

> **TL;DR:** SA-GCS通过语义感知高斯课程调度，显著提升了无人机视觉-语言导航的训练效率和性能，解决了现有强化学习方法训练数据利用率低、收敛慢和难度考虑不足的问题。

**AI_Comments:** SA-GCS的创新之处在于其将课程学习与强化学习相结合，通过动态调整训练样本难度来优化无人机视觉-语言导航的训练过程。这种方法有效解决了传统强化学习在数据利用和收敛方面的不足，为提升复杂视觉-语言任务的训练效率和模型性能提供了新的思路。其在不同模型规模上的良好泛化能力也凸显了其潜在的广泛应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有强化学习方法在无人机视觉-语言导航任务中存在训练数据利用效率低、收敛速度慢以及对训练样本难度变化考虑不足的问题，这些限制了模型性能的进一步提升。

**Method:** 论文提出了SA-GCS（语义感知高斯课程调度）框架，将课程学习（CL）系统地整合到强化学习（RL）中。SA-GCS采用语义感知难度评估器（SA-DE）来量化训练样本的复杂性，并利用高斯课程调度器（GCS）动态调整采样分布，实现从简单到困难任务的平滑过渡。

**Result:** SA-GCS在CityNav基准测试中，在所有指标上持续优于强基线模型，实现了更快、更稳定的收敛，并对不同规模的模型表现出良好的泛化能力。

**Conclusion:** SA-GCS通过引入语义感知高斯课程调度，有效解决了现有强化学习在无人机视觉-语言导航中的训练效率和收敛问题，显著提升了模型性能和泛化能力。

> **ai_Abstract:** 本文提出了SA-GCS，一个新颖的训练框架，旨在解决无人机视觉-语言导航中强化学习面临的训练效率低下和收敛缓慢问题。SA-GCS通过结合语义感知难度评估器和高斯课程调度器，实现了训练样本难度的动态调整，从而显著提高了训练效率、加速了收敛并增强了模型性能。在CityNav基准上的实验证明，SA-GCS在多项指标上优于现有方法，并展现出良好的鲁棒性和可扩展性。

> **摘要翻译:** 无人机（UAV）视觉-语言导航（VLN）旨在使智能体能够根据自然语言指令在复杂环境中准确地定位目标并规划飞行路径，在智能巡检、灾害救援和城市监测等领域具有广泛应用。视觉-语言模型（VLMs）的最新进展为这项任务提供了强大的语义理解能力，而强化学习（RL）已成为一种有前景的后训练策略，可以进一步提高泛化能力。然而，现有的强化学习方法通常存在训练数据利用效率低下、收敛速度慢以及对训练样本难度变化考虑不足的问题，这限制了性能的进一步提高。为了应对这些挑战，我们提出了SA-GCS（语义感知高斯课程调度），一个新颖的训练框架，它将课程学习（CL）系统地整合到强化学习中。SA-GCS采用语义感知难度评估器（SA-DE）来量化训练样本的复杂性，并利用高斯课程调度器（GCS）动态调整采样分布，从而实现从简单到困难任务的平稳过渡。这种设计显著提高了训练效率，加速了收敛，并增强了整体模型性能。在CityNav基准上的大量实验表明，SA-GCS在所有指标上持续优于强基线模型，实现了更快、更稳定的收敛，并对不同规模的模型表现出良好的泛化能力，突出了其鲁棒性和可扩展性。我们方法的实现已公开发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [577] [Combining Discrete Wavelet and Cosine Transforms for Efficient Sentence Embedding](https://arxiv.org/abs/2508.00420)
> *结合离散小波和余弦变换实现高效的句子嵌入*

*Rana Salama, Abdou Youssef, Mona Diab* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 离散小波变换, 离散余弦变换, 句子嵌入, 自然语言处理, 降维

**Comment:** 

> **TL;DR:** 本文提出结合离散小波变换（DWT）和离散余弦变换（DCT）来高效地压缩句子嵌入，并在下游任务中取得了与原始嵌入相当甚至更优的性能。

**AI_Comments:** 这项工作创新性地将小波变换（在图像和信号处理中已被证明有效）引入到自然语言处理的句子嵌入领域，特别是结合了离散余弦变换。其优势在于提出了一个非参数化的模型，能够高效地压缩句子信息，同时保持或提升下游任务的性能，为高效的NLP模型提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于小波变换在图像和信号处理中的成功应用，以及其捕获多种语言特性的潜力，作者旨在探索其在自然语言处理（NLP）任务中，特别是词和句子嵌入方面的应用，以有效整合信息并降低维度。

**Method:** 作者首先通过内在和外在评估，研究了离散小波变换（DWT）如何有效地整合词向量中的重要信息并降低其维度。然后，他们将DWT与离散余弦变换（DCT）结合，提出了一种非参数化模型，该模型基于局部变化的词特征，将包含大量信息的句子压缩成固定大小的向量。

**Result:** 所提出的方法在下游应用模型中表现出与原始嵌入相当甚至在某些任务中更优的性能，证明了其有效性。

**Conclusion:** 结合离散小波和余弦变换可以有效地处理和压缩句子嵌入，并在NLP下游任务中取得有竞争力的结果。

> **ai_Abstract:** 本文探讨了将离散小波变换（DWT）应用于词和句子嵌入，以在自然语言处理（NLP）中有效整合信息并降低维度。研究评估了DWT在词向量压缩中的效用，并提出了一种结合DWT和离散余弦变换（DCT）的非参数化模型，用于将句子压缩成固定大小的向量。实验结果表明，该方法在下游NLP任务中能够取得与原始嵌入相当或更优的性能。

> **摘要翻译:** 小波已成为许多领域的前沿技术。它们在图像和信号处理中的具体应用结果表明，小波可以有效地应用于捕获各种语言属性的自然语言处理（NLP）任务。在本文中，我们利用离散小波变换（DWT）应用于词和句子嵌入的强大功能。我们首先从内在和外在两方面评估了小波如何有效地用于整合词向量中的重要信息，同时降低其维度。我们进一步将DWT与离散余弦变换（DCT）结合，提出了一种非参数化模型，该模型基于局部变化的词特征，将包含大量信息的句子压缩成固定大小的向量。我们展示了所提出的范式在下游应用模型上的功效，其结果与原始嵌入相当甚至（在某些任务中）更优。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [602] [ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network](https://arxiv.org/abs/2508.00429)
> *ReaGAN：节点即智能体推理图智能网络*

*Minghao Guo, Xi Zhu, Jingyuan Huang, Kai Mei, Yongfeng Zhang* | **Category: cs.CL, cs.LG, cs.MA** | **Updated: 2025-08-01**

**Keywords:** 图神经网络, 智能体, 检索增强生成, 节点级规划, 少样本学习

**Comment:** 17 pages, work in progress

> **TL;DR:** ReaGAN是一个新的图神经网络框架，它将每个节点视为一个智能体，能够自主决策和自适应消息传播，并通过检索增强生成（RAG）捕获全局语义关系，在少样本设置下表现出色。

**AI_Comments:** ReaGAN的创新之处在于将“节点即智能体”的概念引入图神经网络，并结合了检索增强生成（RAG），这为解决GNNs中长期存在的节点信息不平衡和全局关系捕获不足的问题提供了新颖的视角。这种方法有望在图学习中实现更灵活、更智能的信息交互和推理。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图神经网络（GNNs）在信息传播中存在两个主要限制：1) 无法处理节点信息丰富度不平衡的问题，即有些节点信息丰富而有些稀疏；2) 预定义的消息传递主要利用局部结构相似性，忽略了图中的全局语义关系，限制了模型捕获远距离但相关信息的能力。

**Method:** ReaGAN（Retrieval-augmented Graph Agentic Network）是一个基于智能体的框架，赋予每个节点自主的节点级决策能力。每个节点作为独立的智能体，根据其内部记忆独立规划下一步行动，实现节点级规划和自适应消息传播。此外，检索增强生成（RAG）允许节点访问语义相关内容，并在图中建立全局关系。

**Result:** ReaGAN在少样本上下文设置下，使用冻结的LLM骨干且无需微调，取得了有竞争力的性能。

**Conclusion:** ReaGAN通过智能体规划和图学习中的局部-全局检索，展示了其在解决现有GNNs局限性方面的巨大潜力。

> **ai_Abstract:** ReaGAN是一种新型的图神经网络框架，旨在克服传统GNN在处理节点信息不平衡和缺乏全局语义关系方面的局限性。它将每个节点视为一个独立的智能体，能够自主决策和自适应地传播信息。通过整合检索增强生成（RAG），ReaGAN使节点能够访问相关内容并建立全局连接。实验表明，ReaGAN在少样本设置下，无需微调冻结的LLM骨干即可达到良好性能，突显了智能体规划和局部-全局检索在图学习中的潜力。

> **摘要翻译:** 图神经网络（GNNs）通过预定义聚合机制在邻近节点间传播信息，在基于图的学习中取得了显著成功。然而，这种固定的方案通常存在两个关键限制。首先，它们无法处理节点信息量的不平衡——有些节点信息丰富，而另一些则稀疏。其次，预定义的消息传递主要利用局部结构相似性，而忽略了图中的全局语义关系，限制了模型捕获远距离但相关信息的能力。我们提出了检索增强图智能网络（ReaGAN），这是一个基于智能体的框架，赋予每个节点自主的节点级决策能力。每个节点作为一个智能体，根据其内部记忆独立规划其下一步行动，从而实现节点级规划和自适应消息传播。此外，检索增强生成（RAG）允许节点访问语义相关内容并在图中建立全局关系。ReaGAN在少样本上下文设置下，使用冻结的LLM骨干且无需微调，取得了有竞争力的性能，展示了智能体规划和图学习中局部-全局检索的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [618] [Retrieval-Augmented Semantic Parsing: Improving Generalization with Lexical Knowledge](https://arxiv.org/abs/2412.10207)
> *检索增强语义解析：利用词汇知识提高泛化能力*

*Xiao Zhang, Qianru Meng, Johan Bos* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 语义解析, 大型语言模型, 检索增强, 泛化能力, 词汇知识

**Comment:** Accpted by 16th IWCS

> **TL;DR:** 本文提出检索增强语义解析（RASP），结合大型语言模型和外部知识，显著提升开放域语义解析对未见概念的泛化能力。

**AI_Comments:** 本文的创新点在于将检索机制与大型语言模型相结合，以解决开放域语义解析中处理未见概念的挑战。其重要性在于证明了外部知识和检索可以显著提升LLMs在特定任务上的泛化能力，为未来开发更鲁棒的语义解析系统提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 开放域语义解析仍然具有挑战性，因为现有神经模型依赖启发式方法，难以处理未见概念。

**Method:** 本文提出了检索增强语义解析（RASP），这是一种简单有效的方法，将外部符号知识整合到解析过程中。该方法利用大型语言模型（LLMs）和检索机制。

**Result:** 实验表明，大型语言模型在语义解析方面优于先前的编码器-解码器基线模型。RASP进一步增强了LLMs预测未见概念的能力，使模型在分布外概念上的性能几乎翻倍。

**Conclusion:** 研究结果突出了利用大型语言模型和检索机制实现鲁棒和开放域语义解析的潜力。

> **ai_Abstract:** 本文针对开放域语义解析中神经模型难以处理未见概念的问题，提出了一种名为检索增强语义解析（RASP）的新方法。RASP将外部符号知识与大型语言模型（LLMs）相结合，显著提高了模型对未见概念的泛化能力。实验结果显示，LLMs本身优于传统基线，而RASP在此基础上进一步将模型在分布外概念上的性能提升近一倍，证明了LLMs和检索机制在构建鲁棒开放域语义解析系统中的巨大潜力。

> **摘要翻译:** 开放域语义解析仍然是一项具有挑战性的任务，因为神经模型通常依赖启发式方法，并且难以处理未见概念。在本文中，我们研究了大型语言模型（LLMs）在该任务中的潜力，并引入了检索增强语义解析（RASP），这是一种简单而有效的方法，将外部符号知识整合到解析过程中。我们的实验不仅表明LLMs在语义解析方面优于先前的编码器-解码器基线模型，而且RASP进一步增强了它们预测未见概念的能力，使模型在分布外概念上的性能几乎翻倍。这些发现突出了利用大型语言模型和检索机制实现鲁棒和开放域语义解析的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [627] [Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges](https://arxiv.org/abs/2508.00454)
> *从多位判官中学习高效的多轮对话评估器*

*Yuqi Tang, Kehua Feng, Yunfeng Wang, Zhiwen Chen, Chengfei Lv, Gang Yu, Qiang Zhang, Keyan Ding* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 对话评估, LLM判官, 多轮对话, 评估器, 模型聚合

**Comment:** 15 pages, 2 pages, under review at AAAI 2026

> **TL;DR:** 本文提出了一种高效的多轮对话评估器，通过将多个LLM判官的偏好知识聚合到一个模型中，从而在保持多判官反馈优势的同时显著降低评估成本。

**AI_Comments:** 本文的创新点在于提出了一个将多个LLM判官的集体智慧聚合到一个单一模型中的方法，有效解决了传统“LLM即判官”范式中存在的偏见问题以及多判官方法计算成本高的问题。其重要性在于提供了一种更高效、更可靠的对话质量评估方案，对于LLM的开发和应用具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 评估大型语言模型（LLMs）的对话能力仍然是一项挑战。当前主流的“LLM即判官”方法存在各种偏见，损害了评估结果的可靠性和一致性。近期多判官方法虽然有效，但在推理过程中会产生显著的计算开销。

**Method:** 本文提出了一种高效的多轮对话评估器，该评估器通过将多个LLM判官的偏好知识聚合到一个单一模型中，从而捕获多位LLM判官的集体智慧。

**Result:** 在七个单项评分和成对比较对话评估基准上的广泛实验表明，我们的方法在不同场景下均优于现有基线，展示了其效率和鲁棒性。

**Conclusion:** 本文提出的方法能够高效地聚合多个LLM判官的知识，提供快速灵活的对话质量评估，并在性能上超越现有基线，证明了其在对话评估领域的有效性和实用性。

> **ai_Abstract:** 本文提出了一种高效的多轮对话评估器，旨在解决当前“LLM即判官”评估方法中存在的偏见和多判官方法计算成本高的问题。该评估器通过将多个LLM判官的偏好知识聚合到一个单一模型中，有效捕获了它们的集体智慧，在保留多判官反馈优势的同时显著降低了评估成本。实验结果表明，该方法在多个对话评估基准上均优于现有基线，展现出其高效性和鲁棒性。

> **摘要翻译:** 评估大型语言模型（LLMs）的对话能力仍然是一项具有挑战性的任务。当前主流方法主要依赖于“LLM即判官”范式，即提示LLM充当评估器来评估对话质量。然而，此类方法经常受到各种偏见的影响，这损害了评估结果的可靠性和一致性。为了减轻这些偏见，最近的方法采用多个LLM作为判官并聚合它们的判断以选择最佳评估。尽管有效，但这种多判官方法在推理过程中会产生显著的计算开销。在本文中，我们提出了一种高效的多轮对话评估器，通过将多个LLM判官的偏好知识聚合到一个单一模型中，从而捕获它们的集体智慧。我们的方法保留了多样化多判官反馈的优势，同时大幅降低了评估成本，实现了快速灵活的对话质量评估。在七个单项评分和成对比较对话评估基准上的广泛实验表明，我们的方法在不同场景下均优于现有基线，展示了其效率和鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [641] [An Investigation into Value Misalignment in LLM-Generated Texts for Cultural Heritage](https://arxiv.org/abs/2501.02039)
> *大型语言模型生成文化遗产文本中的价值错位调查*

*Fan Bu, Zheng Wang, Siyi Wang, Ziyao Liu* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 文化遗产, 价值错位, 文化对齐, 评估

**Comment:** 

> **TL;DR:** 本研究系统评估了大型语言模型在文化遗产任务中生成文化对齐文本的可靠性，发现超过65%的生成文本存在显著的文化错位，并提出了一个基准数据集和评估工作流程。

**AI_Comments:** 本研究具有重要的创新性和实践意义。它首次系统地揭示了大型语言模型在文化遗产领域应用中存在的严重文化价值错位问题，填补了该领域的空白。通过构建大规模的基准数据集和提出全面的评估工作流程，为后续研究提供了宝贵的工具和方法。研究结果警示了在文化遗产领域盲目应用大型语言模型的风险，强调了提升模型文化敏感性和可靠性的紧迫性。其局限性可能在于评估范围仅限于5个开源LLMs，未来可扩展到更多商业模型进行验证。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在文化遗产相关任务中日益普及，但其生成的文本可能存在文化价值错位，如历史事实歪曲、文化认同侵蚀和文化叙事过度简化，这可能导致严重后果。然而，该领域缺乏系统和全面的研究，因此本研究旨在填补这一空白，调查大型语言模型在文化遗产背景下的价值错位问题。

**Method:** 研究系统评估了大型语言模型在生成文化对齐文本方面的可靠性。通过编译包含1066个查询任务的广泛数据集，涵盖文化遗产知识框架内的5个广泛认可类别和17个方面，并在5个开源大型语言模型上进行评估。研究检查了生成文本中文化价值错位的类型和比率，并使用自动化和手动方法检测和分析这些错位。

**Result:** 研究发现令人担忧：超过65%的生成文本表现出显著的文化错位，某些任务几乎完全偏离了关键文化价值观。此外，本文还引入了一个基准数据集和一个全面的评估工作流程。

**Conclusion:** 大型语言模型在生成文化遗产相关文本时存在严重的文化价值错位问题，需要进一步研究和改进以提高其文化敏感性和可靠性。本研究提供的基准数据集和评估工作流程为未来研究提供了宝贵资源。

> **ai_Abstract:** 本研究调查了大型语言模型（LLMs）在文化遗产任务中生成文本时可能出现的文化价值错位问题。鉴于LLMs在文化遗产领域的广泛应用，研究指出其生成的文本可能存在历史事实歪曲、文化认同侵蚀和叙事简化等问题。为填补研究空白，作者系统评估了5个开源LLMs，构建了包含1066个查询任务的基准数据集，涵盖文化遗产的5大类17个方面。结果显示，超过65%的生成文本存在显著文化错位，某些任务的错位率几乎达到100%。论文还提出了一个基准数据集和评估工作流程，旨在促进未来LLMs文化敏感性和可靠性的研究。

> **摘要翻译:** 随着大型语言模型（LLMs）在文化遗产相关任务中日益普及，例如生成历史古迹描述、翻译古代文本、保存口头传统和创建教育内容，用户和研究人员对其生成准确和文化对齐文本的能力越来越依赖。然而，生成的文本中可能存在文化价值错位，例如历史事实的歪曲、文化认同的侵蚀以及复杂文化叙事的过度简化，这可能导致严重的后果。因此，在文化遗产背景下调查大型语言模型中的价值错位对于减轻这些风险至关重要，但该领域一直缺乏系统和全面的研究和调查。为了填补这一空白，我们系统地评估了大型语言模型在为文化遗产相关任务生成文化对齐文本方面的可靠性。我们通过编译包含1066个查询任务的广泛数据集进行了全面评估，这些任务涵盖文化遗产知识框架内的5个广泛认可类别和17个方面，涉及5个开源大型语言模型，并检查了生成文本中文化价值错位的类型和比率。我们使用自动化和手动方法有效地检测和分析了大型语言模型生成文本中的文化价值错位。我们的发现令人担忧：超过65%的生成文本表现出显著的文化错位，某些任务几乎完全偏离了关键文化价值观。除了这些发现之外，本文还引入了一个基准数据集和一个全面的评估工作流程，可以作为未来旨在增强大型语言模型文化敏感性和可靠性的研究的宝贵资源。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [657] [GETALP@AutoMin 2025: Leveraging RAG to Answer Questions based on Meeting Transcripts](https://arxiv.org/abs/2508.00476)
> *GETALP@AutoMin 2025：利用RAG回答基于会议记录的问题*

*Jeongwoo Kang, Markarit Vartampetian, Felix Herron, Yongxin Zhou, Diandra Fabre, Gabriela Gonzalez-Saez* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 检索增强生成, 抽象意义表示, 会议记录, 问答, 共享任务

**Comment:** 

> **TL;DR:** 该论文介绍了GETALP团队在SIGDial 2025自动会议记录共享任务中，利用RAG和AMR回答会议记录相关问题的提交，并展示了AMR在提高回答质量方面的有效性。

**AI_Comments:** 这篇论文的创新点在于将抽象意义表示（AMR）与检索增强生成（RAG）系统相结合，用于解决会议记录问答任务。这种结合提高了系统在复杂语境（如区分不同参与者）下的理解和回答能力，对自然语言处理领域的问答系统研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 参与SIGDial 2025第三届自动会议记录共享任务中的任务B：基于会议记录的问答。

**Method:** 采用基于检索增强生成（RAG）系统和抽象意义表示（AMR）的方法。提出了三种结合这两种方法的新系统。

**Result:** 结合AMR使约35%的问题获得了高质量的回答，并在回答涉及区分不同参与者（例如“谁”的问题）的问题时提供了显著改进。

**Conclusion:** 结合抽象意义表示（AMR）能有效提高基于会议记录的问答系统性能，尤其在区分参与者相关问题上表现突出。

> **ai_Abstract:** 本文介绍了GETALP团队在SIGDial 2025自动会议记录共享任务（任务B：基于会议记录的问答）中的提交。该团队采用结合检索增强生成（RAG）系统和抽象意义表示（AMR）的方法，并提出了三种结合方案。研究结果表明，整合AMR能为约35%的问题提供高质量回答，并显著提升了对涉及区分不同参与者问题的回答能力。

> **摘要翻译:** 这篇论文记录了GETALP团队提交给SIGDial 2025第三届自动会议记录共享任务的成果。我们参与了任务B：基于会议记录的问答。我们的方法基于检索增强生成（RAG）系统和抽象意义表示（AMR）。我们提出了三种结合这两种方法的新系统。结果显示，结合AMR使约35%的问题获得了高质量的回答，并在回答涉及区分不同参与者（例如“谁”的问题）的问题时提供了显著改进。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [664] [IssueBench: Millions of Realistic Prompts for Measuring Issue Bias in LLM Writing Assistance](https://arxiv.org/abs/2502.08395)
> *IssueBench：数百万个真实提示，用于衡量LLM写作辅助中的议题偏见*

*Paul Röttger, Musashi Hinck, Valentin Hofmann, Kobi Hackenburg, Valentina Pyatkin, Faeze Brahman, Dirk Hovy* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** LLM偏见, 议题偏见, 写作辅助, 数据集, IssueBench

**Comment:** under review

> **TL;DR:** 引入IssueBench，一个包含数百万个真实提示的数据集，用于衡量大型语言模型（LLMs）在写作辅助中存在的议题偏见，并发现当前LLM普遍存在此类偏见，且模型间偏见相似，更倾向于美国民主党观点。

**AI_Comments:** 该论文通过构建一个大规模、真实的提示数据集IssueBench，为LLM议题偏见的量化测量提供了一个创新且重要的工具。其基于真实用户互动数据构建提示的策略，提高了偏见测量的现实性和可靠性。研究结果揭示了当前LLM普遍存在的议题偏见，并指出其在模型间的相似性以及与特定政治立场的对齐，这对于理解和解决LLM的社会影响至关重要。IssueBench的可扩展性也为其未来在更广泛偏见类型上的应用提供了潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在写作辅助中可能存在“议题偏见”，即只呈现某一议题的单一视角，这可能影响用户对该议题的看法。目前难以衡量LLM在实际用户互动中表现出的议题偏见，从而难以解决偏见LLM带来的风险。

**Method:** 研究团队创建了IssueBench，一个包含249万个真实提示的数据集，用于衡量LLM写作辅助中的议题偏见。这些提示是基于3900个模板（如“撰写一篇关于”）和212个源自真实用户互动的政治议题（如“AI监管”）构建的。

**Result:** 使用IssueBench，研究表明议题偏见在最先进的LLM中普遍存在且持续存在。研究还发现不同模型间的偏见惊人地相似，并且在某些议题上，所有模型都更符合美国民主党而非共和党选民的意见。

**Conclusion:** IssueBench通过实现稳健和真实的测量，有望为当前关于LLM偏见及其解决方法的讨论提供新的高质量证据。IssueBench易于适应以包含其他议题、模板或任务。

> **ai_Abstract:** 本研究提出了IssueBench，一个包含249万个真实提示的数据集，旨在衡量大型语言模型（LLMs）在写作辅助中存在的议题偏见。该数据集基于实际用户互动中的模板和政治议题构建。利用IssueBench，研究发现当前最先进的LLMs普遍存在议题偏见，且不同模型间的偏见模式相似，表现出对美国民主党观点的更高倾向性。IssueBench易于扩展，有望为LLM偏见研究提供可靠的测量工具。

> **摘要翻译:** 大型语言模型（LLMs）正在帮助数百万用户撰写关于各种议题的文本，并在此过程中向用户展示不同的思想和观点。这引发了对议题偏见的担忧，即LLM倾向于只呈现某一给定议题的单一视角，这反过来可能影响用户对该议题的看法。到目前为止，尚无法衡量LLM在实际用户互动中表现出的议题偏见，从而难以解决偏见LLM带来的风险。因此，我们创建了IssueBench：一个包含249万个真实提示的数据集，用于衡量LLM写作辅助中的议题偏见，我们基于3900个模板（例如“撰写一篇关于”）和212个源自真实用户互动的政治议题（例如“AI监管”）构建了这些提示。使用IssueBench，我们发现议题偏见在最先进的LLM中普遍存在且持续存在。我们还发现不同模型间的偏见惊人地相似，并且所有模型在某些议题上都更符合美国民主党而非共和党选民的意见。IssueBench可以很容易地适应以包含其他议题、模板或任务。通过实现稳健和真实的测量，我们希望IssueBench能为当前关于LLM偏见及其解决方法的讨论带来新的证据质量。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [687] [The Missing Parts: Augmenting Fact Verification with Half-Truth Detection](https://arxiv.org/abs/2508.00489)
> *缺失的部分：通过半真检测增强事实核查*

*Yixuan Tang, Jincheng Wang, Anthony K. H. Tung* | **Category: cs.CL** | **Updated: 2025-08-01**

**Keywords:** 半真检测, 事实核查, 信息遗漏, TRACER, PolitiFact-Hidden

**Comment:** 

> **TL;DR:** 现有事实核查系统难以处理半真信息（因遗漏关键上下文而误导），本文提出了半真检测任务，创建了新基准PolitiFact-Hidden，并开发了TRACER框架，通过建模遗漏信息显著提高了半真分类的性能。

**AI_Comments:** 这篇论文的创新点在于明确提出了“半真检测”这一新任务，并认识到现有事实核查系统在处理因信息遗漏导致的误导性内容方面的局限性。通过构建专门的数据集PolitiFact-Hidden和设计模块化的TRACER框架，它提供了一个有效解决这一挑战的方案。TRACER能够识别被省略的关键上下文，这对于构建更鲁棒和可信的事实核查系统具有重要意义。性能的显著提升也证明了其方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有事实核查系统假设真实性仅取决于陈述内容，但许多现实世界的声明是半真半假，即事实正确但因遗漏关键上下文而具有误导性。现有模型难以处理这些情况，因为它们未被设计来推断未提及的内容。

**Method:** 本文引入了半真检测任务，并提出了PolitiFact-Hidden，一个包含1.5万条政治声明的新基准，其中包含句级证据对齐和推断的声明意图。为解决此挑战，本文提出了TRACER，一个模块化的重新评估框架，通过对齐证据、推断隐含意图和估计隐藏内容的因果影响来识别基于遗漏的错误信息。

**Result:** TRACER可以集成到现有事实核查流程中，并持续提高多个强基线的性能。值得注意的是，它将半真分类的F1分数提高了高达16个百分点。

**Conclusion:** 建模遗漏信息对于可信的事实核查至关重要，本文提出的TRACER框架有效解决了半真信息的检测问题。

> **ai_Abstract:** 本文针对现有事实核查系统无法有效处理“半真”信息（因遗漏关键上下文而误导）的问题，引入了半真检测任务。为此，作者构建了PolitiFact-Hidden数据集，并提出了TRACER框架。TRACER通过对齐证据、推断意图和评估隐藏内容影响来识别基于遗漏的误导性信息，并能集成到现有系统中，显著提升了半真分类的性能，强调了建模遗漏信息在事实核查中的重要性。

> **摘要翻译:** 事实核查系统通常评估一个声明是否由检索到的证据支持，假设真实性仅取决于所陈述的内容。然而，许多现实世界的声明是半真半假，即事实正确但由于遗漏了关键上下文而具有误导性。现有模型难以处理此类情况，因为它们并非旨在推断未提及的内容。我们引入了半真检测任务，并提出了PolitiFact-Hidden，一个包含1.5万条政治声明的新基准，其中包含句级证据对齐和推断的声明意图。为了应对这一挑战，我们提出了TRACER，一个模块化的重新评估框架，它通过对齐证据、推断隐含意图和估计隐藏内容的因果影响来识别基于遗漏的错误信息。TRACER可以集成到现有事实核查流程中，并持续提高多个强基线的性能。值得注意的是，它将半真分类的F1分数提高了高达16个百分点，突显了为可信事实核查建模遗漏信息的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [688] [Better Embeddings with Coupled Adam](https://arxiv.org/abs/2502.08441)
> *使用耦合Adam获得更好的嵌入*

*Felix Stollenwerk, Tobias Stollenwerk* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 各向异性, 词嵌入, Adam, 优化器, 大型语言模型

**Comment:** ACL 2025 (Main), see https://aclanthology.org/2025.acl-long.1321/

> **TL;DR:** 大型语言模型（LLMs）的词嵌入存在各向异性问题，本文提出Coupled Adam优化器来缓解此问题，并实验证明其能提高嵌入质量和性能。

**AI_Comments:** 本文的创新点在于提出了Coupled Adam优化器来解决LLM词嵌入的各向异性问题，并深入分析了Adam优化器中二阶矩对各向异性的影响。其重要性在于为改进LLM的表示学习提供了一个新的有效方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）学习到的词表示存在各向异性这一不良但知之甚少的特征。本文认为Adam优化器中的二阶矩是导致各向异性嵌入的原因。

**Method:** 提出了一种名为Coupled Adam的改进优化器来缓解词嵌入的各向异性问题。

**Result:** 实验表明Coupled Adam显著提高了嵌入质量，并且在足够大的数据集上带来了更好的上游和下游性能。

**Conclusion:** Coupled Adam能有效缓解词嵌入的各向异性问题，并提升模型性能。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）学习到的词嵌入中存在的各向异性问题，并指出Adam优化器中的二阶矩是其原因之一。为解决此问题，作者提出了一种名为Coupled Adam的改进优化器。实验结果表明，Coupled Adam显著提高了嵌入质量，并在大型数据集上提升了上游和下游任务的性能。

> **摘要翻译:** 尽管大型语言模型（LLMs）具有卓越的能力，但它们学习到的词表示却表现出各向异性这一不良但知之甚少的特征。在本文中，我们认为Adam中的二阶矩是导致各向异性嵌入的原因，并提出了一种名为耦合Adam的改进优化器来缓解该问题。我们的实验表明，耦合Adam显著提高了嵌入的质量，同时在足够大的数据集上也能带来更好的上游和下游性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='cscr'></a>
## cs.CR 

### [8] [OneShield -- the Next Generation of LLM Guardrails](https://arxiv.org/abs/2507.21170)
> *OneShield——下一代大型语言模型护栏*

*Chad DeLuca, Anna Lisa Gentile, Shubhi Asthana, Bing Zhang, Pawan Chowdhary, Kellen Cheng, Basel Shbita, Pengyuan Li, Guang-Jie Ren, Sandeep Gopisetty* | **Category: cs.CR, cs.AI, cs.CL** | **Updated: 2025-07-31**

**Keywords:** LLM护栏, 大型语言模型安全, 模型无关, 可定制解决方案, 风险缓解

**Comment:** 

> **TL;DR:** OneShield是一个独立、模型无关且可定制的解决方案，旨在为大型语言模型（LLMs）提供安全防护，以应对其不断演变的安全、隐私和伦理风险。

**AI_Comments:** OneShield的创新之处在于其“模型无关”和“可定制”的特性，这对于应对LLM快速演变和“一刀切”解决方案无效的问题至关重要。作为“下一代LLM护栏”，它有望为企业和开发者提供更灵活、更精细的LLM风险管理工具，特别是在安全、隐私和合规方面。其独立部署的特性也增强了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）虽然潜力巨大，但也带来了安全、隐私和伦理问题。由于LLMs的快速演变，现有的一刀切或通用防护方案难以有效保护用户免受潜在风险。

**Method:** 该论文提出了OneShield，一个独立、模型无关且可定制的LLM安全防护解决方案。OneShield旨在提供定义风险因素、表达和声明上下文安全与合规策略以及缓解LLM风险的功能，并专注于每个特定客户的需求。文中还描述了框架的实现，讨论了可扩展性考虑。

**Result:** 提供了OneShield自首次部署以来的使用统计数据。

**Conclusion:** OneShield提供了一个灵活、可定制且独立于模型的解决方案，有效应对了大型语言模型不断演进带来的安全、隐私和伦理挑战，填补了通用防护方案的空白。

> **ai_Abstract:** 该论文介绍了OneShield，一个为大型语言模型（LLMs）设计的独立、模型无关且可定制的防护解决方案。鉴于LLMs在带来巨大潜力的同时，也伴随着安全、隐私和伦理挑战，且现有通用方案难以适应其快速演变，OneShield旨在通过提供定义风险因素、制定上下文安全策略及缓解风险的工具来解决这些问题，并强调以客户为中心。文章还探讨了其实现细节、可扩展性，并提供了使用统计数据。

> **摘要翻译:** 大型语言模型的兴起激发了人们对其在众多应用中巨大潜力的普遍兴奋。尽管大型语言模型提供了许多可能性，但关于安全、隐私和伦理的问题也随之出现，所有主要参与者都在努力通过针对其自身模型和独立解决方案的保护措施来解决这些问题。大型语言模型不断演变的特性使得普遍保护用户免受其潜在风险的侵害变得极其困难，并且一刀切的解决方案是不可行的。在这项工作中，我们提出了OneShield，我们独立、模型无关且可定制的解决方案，旨在保护大型语言模型。OneShield旨在提供定义风险因素、表达和声明上下文安全和合规策略以及缓解大型语言模型风险的功能，重点关注每个特定客户。我们描述了该框架的实现，讨论了可扩展性考虑，并提供了OneShield自首次部署以来的使用统计数据。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [120] [Verification Cost Asymmetry in Cognitive Warfare: A Complexity-Theoretic Framework](https://arxiv.org/abs/2507.21258)
> *认知战中的验证成本不对称：一个复杂性理论框架*

*Joshua Luberisse* | **Category: cs.CR, cs.CC, cs.CY, cs.GT, F.0; H.0** | **Updated: 2025-08-01**

**Keywords:** 认知战, 验证成本不对称, 复杂性理论, 概率可检查证明, 信息战

**Comment:** 

> **TL;DR:** 本文提出了认知战中验证成本不对称的概念，并利用复杂性理论和PCP构建了能为可信受众降低验证成本，同时增加对抗方成本的传播协议。

**AI_Comments:** 这篇论文提出了一种新颖的、基于复杂性理论的方法来解决认知战中的信息验证问题。其创新点在于引入了“验证成本不对称”的概念，并利用PCP等高级理论工具来设计实际的传播协议。这为内容认证和平台治理提供了强大的理论支持和潜在的实用工具，对于提升信息安全和对抗虚假信息具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在认知战中，人类在对抗性信息流下的验证是一个受工作记忆和认知偏见限制的成本受限决策过程。存在如何降低可信受众验证成本同时提高对抗方成本的问题。

**Method:** 引入了“验证成本不对称（VCA）系数”，将其形式化为相同声明分布下不同人群之间预期验证工作的比率。利用概率可检查证明（PCP）和参数化复杂性理论，构建了传播协议，使可信受众的验证工作量降低到恒定的人力投入，同时对缺乏加密基础设施的对抗性群体施加超线性成本。通过受控用户研究验证框架，并演示了实际信息活动的编码。

**Result:** 建立了认知战中工程化民主优势的复杂性理论基础，证明了成本不对称的理论保证，并通过用户研究验证了框架，展示了实际信息活动的编码能力。

**Conclusion:** 本研究为在认知战中实现民主优势奠定了复杂性理论基础，并可立即应用于内容认证、平台治理和信息行动学说。

> **ai_Abstract:** 本文提出了认知战中的“验证成本不对称（VCA）”概念，并构建了一个基于概率可检查证明（PCP）和参数化复杂性理论的框架。该框架旨在设计信息传播协议，以降低可信受众的验证成本（至恒定人力投入），同时显著增加缺乏加密基础设施的对抗性群体的验证成本（超线性成本）。研究证明了这种不对称性的理论可行性，并通过用户研究和实际应用编码验证了其有效性，为在认知战中获得民主优势提供了理论基础和实践指导。

> **摘要翻译:** 在对抗性信息流下的人类验证是一个受工作记忆限制和认知偏见约束的成本受限决策过程。我们引入了“验证成本不对称（VCA）系数”，将其形式化为在相同声明分布下不同人群之间预期验证工作的比率。借鉴概率可检查证明（PCP）和参数化复杂性理论，我们构建了传播协议，这些协议能将可信受众的验证成本降低到恒定的人力投入，同时对缺乏加密基础设施的对抗性群体施加超线性成本。我们证明了这种不对称性的理论保证，通过测量有无可检查来源的用户研究验证了该框架，并展示了真实世界信息活动的实际编码。研究结果为在认知战中工程化民主优势建立了复杂性理论基础，并可立即应用于内容认证、平台治理和信息行动学说。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [207] [ranDecepter: Real-time Identification and Deterrence of Ransomware Attacks](https://arxiv.org/abs/2508.00293)
> *ranDecepter：勒索软件攻击的实时识别与威慑*

*Md Sajidul Islam Sajid, Jinpeng Wei, Ehab Al-Shaer* | **Category: cs.CR** | **Updated: 2025-08-04**

**Keywords:** 勒索软件, 网络欺骗, 实时识别, 资源耗尽, ranDecepter

**Comment:** Accepted at IEEE Conference on Communications and Network Security
  (CNS) 2025

> **TL;DR:** ranDecepter是一种结合主动网络欺骗和实时分析的新方法，能够实时识别勒索软件，并生成虚假数据耗尽攻击者资源，实现100%的识别准确率。

**AI_Comments:** ranDecepter的创新之处在于其将主动网络欺骗与实时分析相结合，不仅能够准确识别勒索软件，更能通过主动制造虚假信息来反制攻击者，这是一种积极防御的策略。其对攻击者资源耗尽的机制，为勒索软件防御提供了新的思路。100%的识别准确率和无误报的特点，显示了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 勒索软件（RW）在数字领域构成重大而广泛的威胁，急需有效的对策。主动网络欺骗是一种有前景的策略，可以通过误导虚假信息和揭示其真实行为来阻止RW并限制其传播。RW通常充当攻击者和防御者之间的通信渠道，允许欺骗将虚假数据返回给攻击者并耗尽其资源。

**Method:** 本文介绍了ranDecepter，一种结合主动网络欺骗和实时分析的新颖方法，旨在增强对RW攻击的防御。ranDecepter实时识别RW并将其隔离在欺骗环境中，自主识别RW代码中的关键元素以创建循环机制。通过反复重启恶意软件并向攻击者传输伪造的加密信息和密钥，它迫使攻击者为每个受害者存储这些伪造的详细信息，从而耗尽其资源。

**Result:** 对ranDecepter进行了全面评估，使用了1,134个真实恶意软件样本和12个良性应用程序，结果显示其在RW识别方面达到了惊人的100%准确率，没有误报，对响应时间影响最小。此外，在24小时内，ranDecepter使用50个代理在攻击者的数据库中生成了多达9,223K条目，展示了其削弱攻击者资源的潜力。

**Conclusion:** ranDecepter通过结合主动网络欺骗和实时分析，能够高效、准确地识别勒索软件，并通过生成大量虚假数据有效耗尽攻击者资源，是一种极具潜力的勒索软件防御方案。

> **ai_Abstract:** ranDecepter是一种创新的勒索软件防御系统，它结合了主动网络欺骗和实时分析技术。该系统能够实时识别勒索软件，并将其隔离在虚拟环境中。通过分析恶意代码创建循环机制，ranDecepter反复重启恶意软件，并向攻击者发送伪造的加密信息和密钥，迫使攻击者存储大量虚假数据，从而有效耗尽其资源。实验结果表明，ranDecepter对真实勒索软件样本的识别准确率高达100%，无误报，且对系统响应时间影响极小，同时能大量填充攻击者数据库，显著削弱其攻击能力。

> **摘要翻译:** 勒索软件（RW）在数字领域构成重大而广泛的威胁，急需有效的对策。主动网络欺骗是一种有前景的策略，可以通过误导虚假信息和揭示其真实行为来阻止RW并限制其传播。此外，RW通常充当攻击者和防御者之间的通信渠道，允许欺骗将虚假数据返回给攻击者并耗尽其资源。本文介绍了ranDecepter，一种结合主动网络欺骗和实时分析的新颖方法，旨在增强对RW攻击的防御。ranDecepter实时识别RW并将其隔离在欺骗环境中，自主识别RW代码中的关键元素以创建循环机制。通过反复重启恶意软件并向攻击者传输伪造的加密信息和密钥，它迫使攻击者为每个受害者存储这些伪造的详细信息，从而耗尽其资源。我们对ranDecepter进行了全面评估，使用了1,134个真实恶意软件样本和12个良性应用程序，结果显示其在RW识别方面达到了惊人的100%准确率，没有误报，对响应时间影响最小。此外，在24小时内，ranDecepter使用50个代理在攻击者的数据库中生成了多达9,223K条目，展示了其削弱攻击者资源的潜力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [227] [Cryptanalysis of Isogeny-Based Quantum Money with Rational Points](https://arxiv.org/abs/2508.00351)
> *基于同源的量子货币与有理点的密码分析*

*Hyeonhak Kim, Donghoe Heo, Seokhie Hong* | **Category: cs.CR** | **Updated: 2025-08-01**

**Keywords:** 量子货币, 同源, 椭圆曲线, 密码分析, 有理点

**Comment:** 

> **TL;DR:** 本文提出了一种针对基于椭圆曲线类群作用的量子货币方案的密码分析方法。该方法利用有理点和二次扭曲的性质，实现了比暴力攻击更快的攻击速度（O(log^4p)），但仍需指数时间，因此伪造量子钞票仍不切实际。有趣的是，该攻击方法也能带来更高效的验证过程。

**AI_Comments:** 该论文的创新点在于提出了一个具体的密码分析方法，利用了有理点和二次扭曲的特性，实现了攻击加速。尽管攻击未能实际攻破量子货币（伪造仍不切实际），但其带来的验证效率提升是一个有趣的副作用，展现了对量子货币内在性质的深刻理解。这表明即使是攻击研究，也可能带来意想不到的积极应用，对未来量子密码学发展具有启发意义。

<details>
  <summary>Details</summary>

**Motivation:** 最近由Montgomery和Sharif (Asiacrypt '24) 基于椭圆曲线上的类群作用实例化了一种量子货币，本文旨在对其进行具体的密码分析。

**Method:** 本文通过利用有理点坐标评估除法多项式的效率来进行密码分析。具体地，算法利用二次扭曲的性质，通过有理点来验证椭圆曲线叠加的基数。

**Result:** 与暴力攻击相比，攻击速度提高了O(log^4p)。尽管攻击需要指数时间，但伪造量子钞票仍然不切实际。此外，该攻击方法还导致了更高效的验证过程。

**Conclusion:** 尽管本文提出的密码分析方法提高了攻击效率，但伪造量子钞票在实践中仍然不可行。该方法对椭圆曲线量子密码学的未来研究具有潜在贡献。

> **ai_Abstract:** 本文对Montgomery和Sharif提出的基于椭圆曲线类群作用的量子货币方案进行了密码分析。通过利用有理点坐标和二次扭曲的性质，该攻击方法在速度上比暴力攻击快O(log^4p)，但仍需指数时间，因此无法实际伪造量子钞票。值得注意的是，该攻击方法也意外地提升了量子货币的验证效率，预示着其对未来椭圆曲线量子密码学研究的潜在价值。

> **摘要翻译:** 量子货币是量子不可克隆定理的密码学应用。它最近由Montgomery和Sharif（Asiacrypt '24）通过椭圆曲线上的类群作用实例化。在这项工作中，我们通过利用有理点坐标评估除法多项式的效率，提出了一种具体的密码分析方法，与暴力攻击相比，速度提高了O(log^4p)。由于我们的攻击仍然需要指数时间，因此伪造量子钞票仍然不切实际。有趣的是，由于量子货币的固有特性，我们的攻击方法也导致了更高效的验证过程。我们的算法利用二次扭曲的性质，利用有理点来验证椭圆曲线叠加的基数。我们期望这种方法能为未来基于椭圆曲线的量子密码学研究做出贡献。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [247] [Preliminary Investigation into Uncertainty-Aware Attack Stage Classification](https://arxiv.org/abs/2508.00368)
> *对不确定性感知的攻击阶段分类的初步研究*

*Alessandro Gaudenzi, Lorenzo Nodari, Lance Kaplan, Alessandra Russo, Murat Sensoy, Federico Cerutti* | **Category: cs.CR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 不确定性感知的攻击阶段分类, 证据深度学习, 分布外检测, 高级持续威胁, 网络安全

**Comment:** Proceedings for SPAIML2025 workshop, 26/10/2025 Bologna Italy,
  co-located with ECAI2025

> **TL;DR:** 本研究提出了一种基于证据深度学习（EDL）的不确定性感知的分类方法，用于推断多阶段网络攻击的当前阶段，并能有效检测分布外（OOD）输入，以支持动态对抗环境中的分阶段威胁检测。

**AI_Comments:** 该论文的创新点在于将证据深度学习（EDL）应用于网络攻击阶段分类，从而实现了对预测不确定性的量化和分布外（OOD）输入的检测，这对于应对不断变化的APT攻击至关重要。其重要性在于，通过提供攻击阶段的置信度信息，可以帮助安全分析师制定更精准和及时的响应策略，弥补了传统二元检测的不足。作为初步研究，其局限性可能在于模拟环境的实验结果是否能完全泛化到真实复杂网络环境，以及EDL在处理大规模、高维度网络流量数据时的计算效率。

<details>
  <summary>Details</summary>

**Motivation:** 传统的网络安全检测系统未能有效识别多阶段高级持续威胁（APTs）的攻击阶段，而准确推断攻击当前阶段对于制定有效的响应策略至关重要。此外，系统需要对分布外（OOD）输入具有鲁棒性。

**Method:** 本研究提出了一种基于证据深度学习（EDL）的分类方法。该方法通过输出可能攻击阶段的狄利克雷分布参数来建模预测不确定性，从而不仅能预测最可能的阶段，还能指示不确定性或输入是否在训练分布之外。

**Result:** 初步实验表明，所提出的模型能够准确推断攻击阶段，并具有校准的置信度，同时能有效检测OOD输入，这可能表明攻击者战术的变化。

**Conclusion:** 这些结果支持在动态对抗环境中部署不确定性感知的模型进行分阶段威胁检测的可行性。

> **ai_Abstract:** 该研究旨在解决在不确定性下推断高级持续威胁（APTs）攻击阶段的问题，并关注对分布外（OOD）输入的鲁棒性。为此，提出了一种基于证据深度学习（EDL）的分类方法，该方法通过输出狄利克雷分布参数来建模预测不确定性，从而能够预测攻击阶段并指示不确定性或OOD输入。初步实验证明了该模型在准确推断攻击阶段、校准置信度以及有效检测OOD输入方面的能力，为在动态对抗环境中部署不确定性感知的威胁检测模型提供了可行性。

> **摘要翻译:** 高级持续威胁（APTs）因其长期、多阶段的性质及其操作者的复杂性，对网络安全构成了重大挑战。传统的检测系统通常侧重于以二元方式（良性或恶意）识别恶意活动，而没有考虑攻击的进展。然而，有效的响应策略取决于对攻击当前阶段的准确推断，因为对策必须根据攻击者是处于早期侦察阶段还是正在积极进行利用或数据外泄来量身定制。这项工作解决了在不确定性下推断攻击阶段的问题，重点是针对分布外（OOD）输入的鲁棒性。我们提出了一种基于证据深度学习（EDL）的分类方法，该方法通过输出可能阶段的狄利克雷分布参数来建模预测不确定性。这使得系统不仅能够预测攻击最可能的阶段，还能指示何时不确定或输入超出了训练分布。在模拟环境中的初步实验表明，所提出的模型能够以校准的置信度准确推断攻击阶段，同时有效检测OOD输入，这可能表明攻击者战术的变化。这些结果支持在动态对抗环境中部署不确定性感知的模型进行分阶段威胁检测的可行性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [267] [Accurate Latent Inversion for Generative Image Steganography via Rectified Flow](https://arxiv.org/abs/2508.00434)
> *基于修正流的生成图像隐写术中的精确潜在变量反演*

*Yuqi Qian, Yun Cao, Meiyang Lv, Haocheng Fu* | **Category: cs.CR** | **Updated: 2025-08-01**

**Keywords:** 生成图像隐写术, 扩散模型, 潜在变量反演, 修正流, 路径一致性线性反演

**Comment:** 

> **TL;DR:** RF-Stego通过精确的潜在变量反演提高了基于扩散模型的图像隐写术的提取精度，解决了传统方法中反演不准确的问题。

**AI_Comments:** RF-Stego的创新点在于提出了PCLI和引入了修正流（RF）来解决扩散模型隐写术中的核心挑战——精确潜在变量反演。PCLI确保了前向与反演路径的一致性，而RF则提供了理论保障和数值稳定性，这对于提高隐写信息的提取精度至关重要。该方法在多个性能指标上超越了现有技术，显示了其在生成图像隐写领域的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 基于扩散模型的隐写术在图像质量和鲁棒性方面表现出色，但其消息提取依赖于潜在变量的反演过程。现有的反演方法不准确，导致重建的潜在变量与原始变量存在显著差异，从而使得消息提取不可行。

**Method:** 本文提出了RF-Stego，一种新的生成图像隐写术方法。它包含两个主要组成部分：1. 路径一致性线性反演（PCLI）：通过对反演过程施加正式约束，使其与前向生成路径明确对齐，并沿共享线性路径建模两个方向，从而消除路径不匹配并确保隐写过程中的路径一致性。2. 修正流（RF）：通过理论证明，修正流在反演过程中提供了理论上的可逆性和数值稳定性，并用RF采样器取代了传统不稳定的采样器，有效提高了反演过程的数值精度。

**Result:** 实验结果表明，RF-Stego在提取精度、图像质量、鲁棒性、安全性和生成效率方面均优于现有最先进的方法。

**Conclusion:** RF-Stego通过引入路径一致性线性反演和利用修正流的理论可逆性与数值稳定性，成功解决了基于扩散模型的图像隐写术中潜在变量反演不准确的问题，显著提升了消息提取的精度和整体性能。

> **ai_Abstract:** 本文提出了一种名为RF-Stego的生成图像隐写术新方法，旨在解决基于扩散模型隐写术中潜在变量反演不准确导致消息提取困难的问题。RF-Stego通过引入路径一致性线性反演（PCLI）来确保前向生成与反演路径的一致性，并利用修正流（RF）的理论可逆性和数值稳定性来替换不稳定的采样器，从而显著提高了潜在变量的反演精度。实验证明，RF-Stego在提取精度、图像质量、鲁棒性、安全性和生成效率等多个方面均超越了现有最先进的方法。

> **摘要翻译:** 基于扩散模型的隐写术因其生成高质量图像和展现强大鲁棒性的能力而受到越来越多的关注。在此类方法中，秘密消息首先嵌入到初始潜在变量中，然后通过前向过程生成隐写图像。为了提取消息，需要一个反演过程从接收到的图像中重建潜在变量。然而，不准确的潜在变量反演导致重建的潜在变量与原始潜在变量之间存在显著差异，使得消息提取不可行。为了解决这个问题，我们提出了RF-Stego，一种新颖的生成图像隐写术方法，它能够实现精确的潜在变量反演并显著提高提取精度。首先，我们开发了路径一致性线性反演（PCLI），它对反演过程施加了正式约束。通过将其与前向生成路径明确对齐，并沿共享线性路径建模两个方向，PCLI消除了路径不匹配并确保了整个隐写过程中的路径一致性。其次，通过严格的理论证明，我们证明了修正流（RF）在反演过程中提供了理论上的可逆性和数值稳定性。在此基础上，我们用RF采样器取代了传统不稳定的采样器，有效提高了反演过程的数值精度。实验结果表明，RF-Stego在提取精度、图像质量、鲁棒性、安全性和生成效率方面均优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [281] [CyGATE: Game-Theoretic Cyber Attack-Defense Engine for Patch Strategy Optimization](https://arxiv.org/abs/2508.00478)
> *CyGATE：用于补丁策略优化的博弈论网络攻防引擎*

*Yuning Jiang, Nay Oo, Qiaoran Meng, Lu Lin, Dusit Niyato, Zehui Xiong, Hoon Wei Lim, Biplab Sikdar* | **Category: cs.CR, cs.AI, 91A10, 91A43, 68T01, 94A60, C.2.0; I.2.6; K.6.5** | **Updated: 2025-08-01**

**Keywords:** 网络安全, 博弈论, 补丁策略, 大型语言模型, 部分可观察随机博弈

**Comment:** 

> **TL;DR:** CyGATE是一个博弈论框架，利用LLMs和RAG在网络杀伤链中建模攻防互动，动态优化补丁策略以应对不确定性。

**AI_Comments:** CyGATE的创新之处在于将LLMs和RAG技术引入博弈论网络攻防模型，使其能够动态适应威胁情报，克服了传统模型的静态假设限制。其将网络冲突建模为POSG并利用信念状态处理不确定性，提升了防御策略的智能性和有效性，对于未来网络安全领域的动态防御和资源优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有博弈论网络攻防模型常依赖静态假设，且缺乏与实时威胁情报的整合，限制了其适应性，无法有效应对现代网络攻击中防御者在不确定性下动态优先化缓解措施的需求。

**Method:** 本文提出了CyGATE，一个博弈论框架，通过使用大型语言模型（LLMs）结合检索增强生成（RAG）来增强战术选择和补丁优先级排序。在双代理场景中，CyGATE将网络冲突建模为跨网络杀伤链阶段的部分可观察随机博弈（POSG）。攻防双方均利用信念状态应对不确定性，攻击者调整战术，防御者根据演变风险和观察到的对手行为重新确定补丁优先级。

**Result:** CyGATE在动态补丁调度场景中进行了评估，有效地优先处理高风险漏洞，通过动态威胁整合增强了适应性，通过在不确定性下预测攻击者行动增强了战略远见，并通过优化资源使用提高了效率。

**Conclusion:** CyGATE框架通过整合LLMs和RAG，有效地将博弈论应用于网络攻防策略优化，特别是在动态补丁调度中展现出显著优势，提升了防御的适应性、战略远见和资源效率。

> **ai_Abstract:** 本文提出了CyGATE，一个创新的博弈论框架，用于优化网络攻防中的补丁策略。它克服了现有模型静态和缺乏实时威胁整合的局限性，通过结合大型语言模型（LLMs）和检索增强生成（RAG），将网络冲突建模为部分可观察随机博弈（POSG）。CyGATE使防御者能够根据不断变化的风险和观察到的攻击者行为动态调整补丁优先级，并在动态补丁调度场景中验证了其在提高适应性、战略远见和资源效率方面的有效性。

> **摘要翻译:** 现代网络攻击通过多个阶段展开，要求防御者在不确定性下动态优先化缓解措施。虽然博弈论模型能够捕捉攻击者与防御者的互动，但现有方法常依赖静态假设，且缺乏与实时威胁情报的整合，限制了其适应性。本文提出了CyGATE，一个博弈论框架，利用大型语言模型（LLMs）结合检索增强生成（RAG）来增强战术选择和补丁优先级排序，以此建模攻击者与防御者的互动。CyGATE应用于双代理场景，将网络冲突建模为跨网络杀伤链阶段的部分可观察随机博弈（POSG）。攻防双方均利用信念状态应对不确定性，攻击者调整战术，防御者根据演变风险和观察到的对手行为重新确定补丁优先级。该框架的灵活架构使其能够扩展到涉及协同攻击者、协作防御者或具有多个利益相关者的复杂企业环境的多代理场景。在动态补丁调度场景中进行评估，CyGATE有效地优先处理高风险漏洞，通过动态威胁整合增强了适应性，通过在不确定性下预测攻击者行动增强了战略远见，并通过优化资源使用提高了效率。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [297] [Activation-Guided Local Editing for Jailbreaking Attacks](https://arxiv.org/abs/2508.00555)
> *激活引导的越狱攻击局部编辑*

*Jiecong Wang, Haoran Li, Hao Peng, Ziqian Zeng, Zihao Wang, Haohua Du, Zhengtao Yu* | **Category: cs.CR, cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 越狱攻击, 对抗性攻击, 语言模型安全, 隐藏状态编辑, 可迁移性

**Comment:** 

> **TL;DR:** 该论文提出了一种名为AGILE的两阶段框架，结合了现有越狱方法的优点，通过情景生成和基于模型隐藏状态的细粒度编辑，显著提高了越狱攻击的成功率和可迁移性，并能有效对抗防御机制。

**AI_Comments:** AGILE的创新之处在于其结合了情景生成和基于模型内部状态的细粒度编辑，有效解决了现有越狱方法的痛点。通过利用模型隐藏状态，该方法能够更智能地引导模型行为，从而实现更高的攻击成功率和可迁移性，同时也揭示了当前防御机制的不足。

<details>
  <summary>Details</summary>

**Motivation:** 现有的越狱攻击方法存在显著缺点：基于Token的攻击通常产生不连贯或不可读的输入，且可迁移性差；而基于Prompt的攻击缺乏可扩展性，并严重依赖人工努力和独创性。因此，需要一种更有效、可扩展的越狱方法。

**Method:** 论文提出了一种简洁有效的两阶段框架：第一阶段进行基于场景的上下文生成，并重新表述原始恶意查询以模糊其有害意图。第二阶段利用模型隐藏状态的信息指导细粒度编辑，有效地将模型对输入的内部表示从恶意转向良性。

**Result:** 该方法（AGILE）实现了最先进的攻击成功率，比最强的基线提高了37.74%，并对黑盒模型表现出出色的可迁移性。分析表明AGILE对主流防御机制仍保持显著有效性。

**Conclusion:** AGILE方法在越狱攻击中表现出卓越的性能和鲁棒性，突出了当前安全措施的局限性，并为未来防御机制的开发提供了宝贵见解。

> **ai_Abstract:** 本文提出了一种名为AGILE的两阶段框架，旨在克服现有越狱攻击方法的局限性。该框架首先通过情景生成和查询重构来模糊恶意意图，然后利用模型隐藏状态进行细粒度编辑，以引导模型内部表示从恶意转向良性。实验结果表明，AGILE显著提高了攻击成功率和可迁移性，并能有效对抗现有的防御机制，为未来的防御发展提供了重要启示。

> **摘要翻译:** 越狱是一种重要的对抗性技术，用于对这些模型进行红队测试，以发现和修补安全漏洞。然而，现有的越狱方法面临显著缺点。基于Token的越狱攻击通常会产生不连贯或不可读的输入，并且可迁移性差；而基于Prompt的攻击缺乏可扩展性，并且严重依赖手动努力和人类智慧。我们提出了一种简洁有效的两阶段框架，结合了这些方法的优点。第一阶段执行基于场景的上下文生成，并重新表述原始恶意查询以模糊其有害意图。第二阶段然后利用模型隐藏状态的信息来指导细粒度编辑，有效地将模型对输入的内部表示从恶意转向良性。广泛的实验表明，该方法实现了最先进的攻击成功率，比最强的基线提高了37.74%，并对黑盒模型表现出出色的可迁移性。我们的分析进一步表明，AGILE对主流防御机制仍保持显著有效性，突出了当前安全防护措施的局限性，并为未来的防御开发提供了宝贵的见解。我们的代码可在https://github.com/yunsaijc/AGILE获取。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [312] [LeakSealer: A Semisupervised Defense for LLMs Against Prompt Injection and Leakage Attacks](https://arxiv.org/abs/2508.00602)
> *LeakSealer：一种针对LLMs提示注入和数据泄露攻击的半监督防御*

*Francesco Panebianco, Stefano Bonfanti, Francesco Trovò, Michele Carminati* | **Category: cs.CR, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** LLMs, 提示注入, 数据泄露, 半监督, LeakSealer

**Comment:** 22 pages, preprint

> **TL;DR:** LeakSealer是一个半监督的、模型无关的框架，通过分析历史交互数据和结合静态/动态防御，有效抵御大型语言模型（LLMs）的提示注入和数据泄露攻击。

**AI_Comments:** LeakSealer的创新之处在于其结合了历史数据分析以提供取证洞察，并采用模型无关的半监督人机循环（HITL）框架进行主动防御。这使得它能够不仅检测当前的攻击，还能追踪攻击模式的演变。其在提升LLM安全性方面具有重要意义，特别是在应对日益复杂的越狱和数据泄露威胁方面。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的广泛部署带来了越狱和数据泄露等安全威胁，特别是检索增强生成（RAG）也引入了敏感信息泄露的漏洞。

**Method:** 该研究引入了一种方法来分析LLM系统的历史交互数据，以生成按主题分类的使用地图（包括对抗性交互），并提供追踪越狱攻击模式演变的取证洞察。其次，提出了LeakSealer，一个模型无关的框架，它结合了用于取证洞察的静态分析和人机循环（HITL）管道中的动态防御，以识别主题组并检测异常模式。

**Result:** 在静态设置中，LeakSealer在识别提示注入方面，在ToxicChat数据集上实现了最高的精确度和召回率。在动态设置中，PII（个人身份信息）泄露检测的AUPRC（精确度-召回率曲线下面积）达到0.97，显著优于Llama Guard等基线。

**Conclusion:** LeakSealer是一个有效的模型无关框架，能够结合历史数据分析和动态防御，显著提高LLM系统对提示注入和数据泄露攻击的防御能力。

> **ai_Abstract:** LeakSealer是一个半监督的、模型无关的防御框架，旨在保护大型语言模型（LLMs）免受提示注入和数据泄露攻击。该框架通过分析历史交互数据来生成使用地图并提供取证洞察，同时结合静态分析和人机循环（HITL）的动态防御机制来识别主题组和检测异常模式。实验评估表明，LeakSealer在检测提示注入方面，在公开数据集上表现出高精确度和召回率；在PII泄露检测方面，其性能显著优于现有基线，AUPRC达到0.97。

> **摘要翻译:** 大型语言模型（LLMs）的泛化能力使其在各种应用中得到了广泛部署。然而，这种日益增长的采用也引入了几种安全威胁，尤其是在越狱和数据泄露攻击方面。此外，检索增强生成（RAG）虽然增强了LLM响应的上下文感知能力，却无意中引入了可能导致敏感信息泄露的漏洞。我们的贡献是双重的。首先，我们引入了一种方法来分析LLM系统的历史交互数据，从而能够生成按主题分类的使用地图（包括对抗性交互）。这种方法进一步为跟踪越狱攻击模式的演变提供了取证洞察。其次，我们提出了LeakSealer，一个模型无关的框架，它结合了用于取证洞察的静态分析和人机循环（HITL）管道中的动态防御。这种技术可以识别主题组并检测异常模式，从而实现主动防御机制。我们通过两种场景对LeakSealer进行了实证评估：(1) 越狱尝试，使用公开基准数据集；(2) PII（个人身份信息）泄露，由一个标注的LLM交互精选数据集支持。在静态设置中，LeakSealer在识别提示注入时，在ToxicChat数据集上实现了最高的精确度和召回率。在动态设置中，PII泄露检测的AUPRC达到0.97，显著优于Llama Guard等基线。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [327] [FedGuard: A Diverse-Byzantine-Robust Mechanism for Federated Learning with Major Malicious Clients](https://arxiv.org/abs/2508.00636)
> *FedGuard：针对主要恶意客户端的联邦学习多样拜占庭鲁棒机制*

*Haocheng Jiang, Hua Shen, Jixin Zhang, Willy Susilo, Mingwu Zhang* | **Category: cs.CR, cs.DC** | **Updated: 2025-08-01**

**Keywords:** 联邦学习, 拜占庭鲁棒性, 会员推断, 模型中毒, 非IID数据

**Comment:** 

> **TL;DR:** FedGuard是一种新颖的联邦学习防御机制，通过利用会员推断对模型偏差的敏感性，识别并排除中毒模型，从而有效应对多数恶意客户端和多样化的拜占庭攻击。

**AI_Comments:** FedGuard的创新之处在于利用了会员推断对模型偏差的敏感性，并引入服务器指定迷你批次数据来识别中毒模型，这使其能够应对多样化的拜占庭攻击和大量恶意客户端，填补了现有方案在复杂攻击场景下的不足。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习容易受到拜占庭攻击，尤其是在超过50%的客户端是恶意客户端或数据集高度非独立同分布（non-IID）时。此外，大多数现有防御机制设计用于特定攻击类型，限制了其有效性。

**Method:** FedGuard利用会员推断对模型偏差的高度敏感性。它要求客户端在训练中包含一个额外的服务器指定迷你批次数据。中毒模型对该迷你批次数据的置信度会显著下降，从而被识别并排除。

**Result:** 在三种高度非IID数据集上，90%的客户端是拜占庭式客户端且每轮发生七种不同类型的拜占庭攻击的情况下，FedGuard在缓解各种类型的拜占庭攻击方面显著优于现有鲁棒联邦学习方案。

**Conclusion:** FedGuard是一种有效且鲁棒的联邦学习防御机制，能够应对大量恶意客户端和多样化的拜占庭攻击。

> **ai_Abstract:** 本文提出了FedGuard，一种新颖的联邦学习防御机制，旨在解决拜占庭攻击在多数恶意客户端和非IID数据下的挑战，以及现有防御机制通用性不足的问题。FedGuard利用会员推断对模型偏差的敏感性，通过要求客户端训练额外迷你批次数据来识别并排除中毒模型。实验证明，在极端攻击条件下，FedGuard在抵御多种拜占庭攻击方面表现显著优于现有方案。

> **摘要翻译:** 联邦学习是一种分布式训练框架，容易受到拜占庭攻击，特别是当超过50%的客户端是恶意客户端或数据集高度非独立同分布（non-IID）时。此外，大多数现有的防御机制都是针对特定的攻击类型（例如，基于梯度相似性的方案只能防御异常值模型中毒），这限制了它们的有效性。为此，我们提出了FedGuard，一种新颖的联邦学习机制。FedGuard巧妙地利用会员推断对模型偏差的高度敏感性来解决上述问题。通过要求客户端在训练中包含一个额外的服务器指定迷你批次数据，FedGuard可以识别并排除中毒模型，因为它们对该迷你批次数据的置信度会显著下降。我们全面的评估明确表明，在三种高度非IID数据集上，当90%的客户端是拜占庭式客户端且每轮发生七种不同类型的拜占庭攻击时，FedGuard在缓解各种类型的拜占庭攻击方面显著优于现有的鲁棒联邦学习方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [347] [Demo: TOSense -- What Did You Just Agree to?](https://arxiv.org/abs/2508.00659)
> *演示：TOSense——你刚才同意了什么？*

*Xinzhang Chen, Hassan Ali, Arash Shaghaghi, Salil S. Kanhere, Sanjay Jha* | **Category: cs.CR, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 服务条款, 自然语言处理, Chrome扩展, 信息不对称, 大型语言模型

**Comment:** Accepted as a demonstration paper at IEEE LCN 2025

> **TL;DR:** TOSense是一个Chrome扩展，允许用户用自然语言提问并实时获取关于冗长服务条款的简洁答案。

**AI_Comments:** TOSense的创新之处在于其将ToS理解自动化，并结合了轻量级LLM和合成数据生成（QEP）来克服标注难题，为用户提供实时、便捷的服务条款解释工具，有效缓解了信息不对称问题。其在准确率上的表现（44.5%）虽然不是非常高，但作为首次尝试和演示系统，已展现出潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在线服务条款（ToS）通常冗长且晦涩，导致用户面临信息不对称和法律风险。

**Method:** TOSense系统结合了两个主要部分：一个名为“tos-crawl”的爬虫，用于自动提取ToS内容；以及一个轻量级大型语言模型管道，其中MiniLM用于语义检索，BART-encoder用于答案相关性验证。为避免昂贵的手动标注，论文提出了一种新颖的问答评估管道（QEP），通过生成合成问题并使用聚类主题匹配来验证答案的正确性。

**Result:** 在苹果、谷歌、X（前身为Twitter）、微软和Netflix五个主要平台上的实验表明，TOSense在不同数量的主题聚类下均有效，准确率高达44.5%。

**Conclusion:** TOSense提供了一个实时的、交互式的解决方案，帮助用户理解在线服务的服务条款，通过无缝提取、问答和即时索引新网站的功能，解决了信息不对称的问题。

> **ai_Abstract:** TOSense是一个Chrome扩展，旨在解决在线服务条款冗长晦涩导致的用户信息不对称问题。它通过结合自动爬虫和轻量级大语言模型（MiniLM和BART-encoder）实现用户对服务条款的自然语言问答。为克服手动标注成本，TOSense引入了新颖的问答评估管道（QEP）。实验证明其在主要平台上的有效性，准确率高达44.5%。

> **摘要翻译:** 在线服务通常要求用户同意冗长且晦涩的服务条款（ToS），这导致信息不对称和法律风险。本文提出了TOSense——一个Chrome扩展，允许用户以自然语言询问有关ToS的问题并实时获得简洁的答案。该系统结合了（i）一个自动提取ToS内容的爬虫“tos-crawl”，以及（ii）一个轻量级大型语言模型管道：MiniLM用于语义检索，BART-encoder用于答案相关性验证。为了避免昂贵的手动标注，我们提出了一个新颖的问答评估管道（QEP），它通过生成合成问题并使用聚类主题匹配来验证答案的正确性。在苹果、谷歌、X（前身为Twitter）、微软和Netflix五个主要平台上的实验表明，TOSense在不同数量的主题聚类下均有效（准确率高达44.5%）。在演示期间，我们将展示TOSense的实际运行。与会者将能够体验无缝提取、交互式问答和新站点的即时索引。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [367] [Unveiling Dynamic Binary Instrumentation Techniques](https://arxiv.org/abs/2508.00682)
> *揭示动态二进制插桩技术*

*Oscar Llorente-Vazquez, Xabier Ugarte-Pedrero, Igor Santos-Grueiro, Pablo Garcia Bringas* | **Category: cs.CR, cs.SE** | **Updated: 2025-08-01**

**Keywords:** 动态二进制插桩, DBI, 程序分析, 运行时监控, 性能评估

**Comment:** 

> **TL;DR:** 论文深入分析了动态二进制插桩（DBI）技术，比较了不同方法在监控和修改程序执行方面的能力和性能，发现没有一种技术在所有情况下都最优。

**AI_Comments:** 这篇论文通过系统性地比较和评估不同的动态二进制插桩技术，为研究人员和开发者提供了宝贵的见解，揭示了该领域缺乏普适性解决方案的现状。其创新点在于对多种DBI方法进行了全面的梳理和性能分析，而非仅仅关注某一种特定技术。这对于理解DBI的优缺点和适用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 动态二进制插桩（DBI）技术多种多样，每种都有其优缺点和适用范围，但缺乏对不同方法的系统性比较和分析，导致使用者难以选择最适合的技术。

**Method:** 作者综合了进程级和全系统级的DBI方法，描述了它们的组成部分，分析了底层的插桩技术，并比较了它们插桩不同原语和运行时事件的能力。随后，评估了它们在实现每个原语时的性能。

**Result:** 研究结果表明，没有一种单一的动态二进制插桩技术在所有情况下都优于其他技术。

**Conclusion:** 动态二进制插桩技术没有“一劳永逸”的解决方案，选择最佳技术取决于具体的应用场景和需求。

> **ai_Abstract:** 本文对动态二进制插桩（DBI）技术进行了深入分析，该技术用于在运行时监控和修改程序执行。论文汇集了进程级和全系统级的DBI方法，详细阐述了它们的构建块和底层技术，并比较了它们在插桩不同原语和运行时事件方面的能力。通过性能评估，研究指出，没有一种DBI技术能在所有场景下都表现最佳。

> **摘要翻译:** 动态二进制插桩（DBI）是一组技术，它使得程序能够在运行时进行插桩，从而可以监控和修改编译后的二进制文件或整个系统的执行。DBI被用于无数安全应用和分析中，并在工业界和学术界的许多领域得到广泛使用。多年来，基于不同技术和实现多样化方法的几种DBI方法已被提出。每种解决方案都试图克服某些限制，但有时它们会带来其他缺点。有些专门用于某个特定领域或任务，而另一些则具有更广泛的范围。在本文中，我们揭示了DBI的复杂性，汇集了进程级和全系统级的方法。我们描绘了它们的构建块，分析了底层的插桩技术，比较了它们插桩不同原语和运行时事件的能力。然后，我们评估了它们在实现每个原语时的性能，并强调了相关的观察结果。我们的结果表明，在所有情况下，没有一种单一的技术比其他技术更好。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [392] [LeakyCLIP: Extracting Training Data from CLIP](https://arxiv.org/abs/2508.00756)
> *LeakyCLIP：从CLIP中提取训练数据*

*Yunhao Chen, Shujie Wang, Xin Wang, Xingjun Ma* | **Category: cs.CR** | **Updated: 2025-08-01**

**Keywords:** CLIP反演, 数据泄露, 隐私风险, 多模态模型, 图像重建

**Comment:** 

> **TL;DR:** 研究人员提出了LeakyCLIP，一个用于从CLIP嵌入中高保真重建训练图像的攻击框架，揭示了多模态模型中普遍存在的隐私泄露风险。

**AI_Comments:** 这项工作提出了一种实用的CLIP反演方法，显著提高了图像重建的质量，揭示了CLIP模型中普遍存在的隐私泄露风险。其创新之处在于结合了多种技术来解决反演挑战，为评估和缓解多模态模型中的数据隐私问题提供了重要工具和深刻见解。

<details>
  <summary>Details</summary>

**Motivation:** 理解对比语言-图像预训练（CLIP）中的记忆化和隐私泄露风险对于确保多模态模型的安全性至关重要。先前的研究已证明扩散模型存在泄露敏感训练样本的风险，而本文则专注于CLIP。

**Method:** 本文通过CLIP反演（旨在从文本提示重建训练图像的过程）来研究CLIP中的数据记忆和提取风险。为此，引入了LeakyCLIP，一个新颖的攻击框架，旨在实现从CLIP嵌入中高质量、语义准确的图像重建。LeakyCLIP通过以下方法解决CLIP反演中的三个关键挑战：1) 对抗性微调以增强优化平滑度，2) 基于线性变换的嵌入对齐，以及3) 基于Stable Diffusion的细化以提高保真度。

**Result:** LeakyCLIP在ViT-B-16上，与LAION-2B子集上的基线方法相比，SSIM（结构相似性指数）提高了358%以上。此外，研究发现即使从低保真重建的指标中也能成功推断出训练数据成员身份，揭示了普遍存在的泄露风险。

**Conclusion:** 本文引入了一种实用的CLIP反演方法，并为多模态模型中隐私风险的性质和范围提供了新颖的见解。

> **ai_Abstract:** 本文提出了LeakyCLIP，一个新颖的攻击框架，旨在通过CLIP反演（从文本嵌入重建训练图像）来研究CLIP模型中的数据记忆化和隐私泄露风险。LeakyCLIP通过对抗性微调、嵌入对齐和Stable Diffusion细化解决了CLIP反演中的挑战，实现了高质量的图像重建，并在SSIM上显著优于基线方法。研究揭示了多模态模型中普遍存在的训练数据泄露风险，即使是低保真重建也能推断出数据成员身份，为理解和应对此类隐私问题提供了实用方法和新见解。

> **摘要翻译:** 理解对比语言-图像预训练（CLIP）中的记忆化和隐私泄露风险对于确保多模态模型的安全性至关重要。最近的研究表明，从扩散模型中提取敏感训练样本是可行的，其中条件扩散模型表现出更强的记忆和信息泄露倾向。在这项工作中，我们通过CLIP反演（一个旨在从文本提示中重建训练图像的过程）来调查CLIP中的数据记忆和提取风险。为此，我们引入了**LeakyCLIP**，一个新颖的攻击框架，旨在从CLIP嵌入中实现高质量、语义准确的图像重建。我们识别出CLIP反演中的三个关键挑战：1）非鲁棒特征，2）文本嵌入中有限的视觉语义，以及3）低重建保真度。为了解决这些挑战，LeakyCLIP采用了1）对抗性微调以增强优化平滑度，2）基于线性变换的嵌入对齐，以及3）基于Stable Diffusion的细化以提高保真度。实证结果表明LeakyCLIP的优越性，在LAION-2B子集上，ViT-B-16的结构相似性指数（SSIM）比基线方法提高了358%以上。此外，我们发现了一种普遍存在的泄露风险，表明即使从低保真重建的指标中也能成功推断出训练数据成员身份。我们的工作引入了一种实用的CLIP反演方法，同时为多模态模型中隐私风险的性质和范围提供了新颖的见解。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [557] [Efficient and Universal Watermarking for LLM-Generated Code Detection](https://arxiv.org/abs/2402.07518)
> *用于LLM生成代码检测的高效通用水印技术*

*Boquan Li, Zirui Fu, Mengdi Zhang, Peixin Zhang, Jun Sun, Xingmei Wang* | **Category: cs.CR** | **Updated: 2025-08-01**

**Keywords:** 代码水印, LLM, AI生成代码检测, ACW, 即插即用

**Comment:** This work has been submitted to IEEE for possible publication

> **TL;DR:** 提出了一种名为ACW的高效、通用的即插即用水印方法，用于检测LLM生成的代码，解决了现有方法的局限性。

**AI_Comments:** ACW的创新点在于其即插即用、无需训练的设计，以及通过语义保持和幂等代码转换实现隐式水印的机制，这显著提升了LLM生成代码检测的效率和通用性，有效解决了现有方法的局限性，对AI代码的责任追溯具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）生成的代码带来了学术不端和恶意代码等伦理和法律问题。为了问责，需要检测AI生成的代码。现有针对代码的水印方法存在通用性有限、时间和内存消耗过大的问题，因此需要一种更理想的解决方案。

**Method:** 本研究提出了一种名为ACW（AI Code Watermarking）的即插即用水印方法。ACW无需训练，通过选择性地对LLM代码输出应用一组精心设计、语义保持且幂等的代码转换来实现。这些转换的存在或缺失作为隐式水印，从而实现AI生成代码的检测。

**Result:** 实验结果表明，ACW能够有效检测AI生成的代码，保持代码实用性，并能抵抗代码优化。尤其值得注意的是，ACW高效且对不同LLM具有通用性，解决了现有方法的局限性。

**Conclusion:** ACW是一种高效、通用且实用的AI生成代码水印方法，有效解决了现有方案的局限性，为AI代码的问责制提供了有力的支持。

> **ai_Abstract:** 本文提出了一种名为ACW（AI Code Watermarking）的即插即用水印方法，旨在高效、通用地检测大型语言模型（LLM）生成的代码。针对现有代码水印技术存在的通用性差、资源消耗大等问题，ACW无需训练，通过对LLM输出代码应用语义保持且幂等的代码转换，利用这些转换的存在与否作为隐式水印进行检测。实验证明，ACW能有效检测AI代码，保持代码功能，并对代码优化具有鲁棒性，同时具备高效率和跨LLM的通用性。

> **摘要翻译:** 大型语言模型（LLMs）显著提升了AI生成代码的可用性，为程序员提供了有效的帮助。然而，这一进步也引发了伦理和法律担忧，例如学术不端或恶意代码的生成。为了问责，检测一段代码是否由AI生成变得至关重要。水印技术被广泛认为是一种有前景的解决方案，并已成功应用于识别LLM生成的文本。然而，现有针对代码的水印工作远非理想，它们存在通用性有限以及时间与内存消耗过大的问题。在这项工作中，我们提出了一种用于AI生成代码检测的即插即用水印方法，命名为ACW（AI Code Watermarking）。ACW无需训练，通过选择性地对LLM代码输出应用一组精心设计、语义保持且幂等的代码转换来工作。这些转换的存在或缺失作为隐式水印，从而实现AI生成代码的检测。我们的实验结果表明，ACW能够有效检测AI生成的代码，保持代码实用性，并能抵抗代码优化。尤其重要的是，ACW高效且对不同LLM具有通用性，解决了现有方法的局限性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [582] [UTrace: Poisoning Forensics for Private Collaborative Learning](https://arxiv.org/abs/2409.15126)
> *UTrace: 隐私协作学习中的投毒溯源*

*Evan Rose, Hidde Lycklama, Harsh Chaudhari, Anwar Hithnawi, Alina Oprea* | **Category: cs.CR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 数据投毒, 隐私保护机器学习, 投毒溯源, 梯度相似性, 安全多方计算

**Comment:** 28 pages, 10 figures; update ack

> **TL;DR:** UTrace是一个用于隐私保护机器学习中投毒攻击溯源的框架，通过计算梯度相似性来识别恶意数据贡献者，在低投毒率和分布式攻击下均有效。

**AI_Comments:** UTrace在PPML场景下解决了一个关键的安全问题，即数据投毒溯源。其创新点在于利用梯度相似性来量化用户责任，并实现了低存储开销的梯度检查点，使得在数据所有者离线时也能进行溯源。此外，对分布式攻击的鲁棒性是其显著优势。该工作对于提升PPML的实用性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 隐私保护机器学习（PPML）虽然保护了数据隐私，但增加了数据投毒的风险。现有安全多方计算（MPC）机制对投毒攻击的防御不足，因此需要一种补充性的方法来溯源PPML中的投毒攻击。

**Method:** 本文提出了UTrace框架，用于PPML中的用户级投毒攻击溯源。它通过聚合数据所有者数据集中最相关样本的梯度相似性指标来计算用户责任分数。UTrace还引入了低存储开销的梯度检查点方法，以便在部署时数据所有者不在场的情况下进行溯源，并设计了优化措施以减少MPC中的溯源时间和通信。

**Result:** UTrace在低投毒率下表现有效，并且与现有基于遗忘的方法不同，它对分布在多个数据所有者之间的投毒攻击具有弹性。通过在来自三种数据模态（视觉、文本和恶意软件）的四个数据集上进行全面评估，UTrace展示了其对抗10种投毒攻击的有效性。

**Conclusion:** UTrace是一个有效的框架，用于在隐私保护机器学习中对投毒攻击进行用户级溯源，它在低投毒率和分布式攻击下均表现出强大的性能和弹性。

> **ai_Abstract:** 该论文提出了UTrace，一个用于隐私保护机器学习（PPML）中用户级投毒攻击溯源的框架。针对现有MPC机制在数据投毒防御上的不足，UTrace通过计算基于梯度相似性的用户责任分数来识别恶意数据贡献者。该方法在低投毒率下表现出色，并能有效抵御分布式投毒攻击，优于现有基于遗忘的方法。UTrace还引入了低存储开销的梯度检查点技术和优化措施，以减少溯源时间和通信。通过在多模态数据集和多种投毒攻击上的广泛评估，UTrace验证了其有效性。

> **摘要翻译:** 隐私保护机器学习（PPML）允许多个数据所有者将其数据私密地贡献给一组服务器，这些服务器运行安全多方计算（MPC）协议来训练联合ML模型。在这些协议中，输入数据在整个训练过程中保持私密，并且只提供最终模型。虽然这种方法有益于隐私，但它也加剧了数据投毒的风险，即受损的数据所有者通过贡献恶意数据集来诱导不良模型行为。现有的MPC机制可以减轻某些投毒攻击，但这些措施并不详尽。为了补充现有的投毒防御措施，我们引入了UTrace：一个用于PPML中投毒攻击用户级溯源的框架。UTrace使用在所有者数据集中最相关样本上聚合的梯度相似性度量来计算用户责任分数。UTrace在低投毒率下是有效的，并且与现有基于遗忘的方法不同，它对分布在多个数据所有者之间的投毒攻击具有弹性。我们引入了具有低存储开销的梯度检查点方法，使得在部署时没有数据所有者的情况下也能进行溯源。我们还设计了几种优化措施，以减少MPC中的溯源时间和通信。我们对UTrace在来自三种数据模态（视觉、文本和恶意软件）的四个数据集上进行了全面评估，并展示了其对抗10种投毒攻击的有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [607] [ExclaveFL: Providing Transparency to Federated Learning using Exclaves](https://arxiv.org/abs/2412.10537)
> *ExclaveFL：使用飞地为联邦学习提供透明度*

*Jinnan Guo, Kapil Vaswani, Andrew Paverd, Peter Pietzuch* | **Category: cs.CR, cs.DC, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 联邦学习, 可信执行环境, 侧信道攻击, 透明度, 数据完整性

**Comment:** 

> **TL;DR:** ExclaveFL是一种联邦学习平台，通过引入“飞地”（不含秘密的完整性保护执行环境）和运行时数据转换证明，即使在TEE面临侧信道攻击的情况下，也能提供端到端的数据完整性和透明度，且开销低于10%。

**AI_Comments:** ExclaveFL的创新点在于提出了“飞地”这一新颖概念，将TEE设计为无秘密的执行环境，从而有效抵御了以往被忽视的侧信道攻击。通过运行时证明单个数据转换而非整体TEE，ExclaveFL提供了更细粒度的完整性保障和透明度，显著提升了联邦学习的鲁棒性。其在保证安全性的同时，将性能开销控制在较低水平，展示了其实用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在联邦学习中，恶意数据提供者可能在不被检测的情况下偏离正确的训练协议，从而损害训练模型。现有基于可信执行环境（TEE）的解决方案通常忽略了针对TEE的侧信道攻击，然而这类攻击可能泄露密钥，使攻击者能够冒充TEE并任意偏离协议，从而破坏TEE联邦学习框架的安全性。

**Method:** ExclaveFL提出了一种新范式，将现有TEE用作“飞地”——不包含任何秘密、对侧信道攻击免疫的完整性保护执行环境。与以往证明TEE本身并将其绑定到TEE所持有的密钥不同，ExclaveFL在运行时证明单个数据转换。这些运行时证明形成一个经过证明的数据流图，可以检查以确保联邦学习训练任务满足声明（例如，未偏离正确计算）。ExclaveFL通过扩展流行的NVFlare联邦学习框架来实现。

**Result:** 实验表明，与没有TEE的相同联邦学习框架相比，ExclaveFL引入的开销不到10%，同时提供了更强的安全保障。

**Conclusion:** ExclaveFL通过引入“飞地”概念和运行时数据转换证明，成功地为联邦学习提供了端到端的数据完整性和透明度，即使在可信执行环境（TEE）面临侧信道攻击的情况下也能保持安全性和鲁棒性。

> **ai_Abstract:** ExclaveFL是一个创新的联邦学习平台，旨在解决当前FL中恶意参与者偏离协议难以检测以及基于TEE的FL方案易受侧信道攻击导致密钥泄露的问题。该平台引入了“飞地”概念，即不含秘密且免疫侧信道攻击的完整性保护执行环境。ExclaveFL通过在运行时对单个数据转换进行证明，而非仅证明TEE本身，从而构建一个可验证的数据流图，确保FL训练的完整性。实验证明，ExclaveFL在提供更强安全保障的同时，相比无TEE的FL框架，性能开销低于10%。

> **摘要翻译:** 在联邦学习（FL）中，数据提供者在不泄露其训练数据的情况下共同训练模型。尽管其具有固有的隐私优势，但恶意的数数据提供者可以简单地偏离正确的训练协议而不被检测到，这可能会损害训练模型。虽然目前的解决方案已经探索了使用可信执行环境（TEE）来对抗此类攻击，但它们通常假设针对TEE的侧信道攻击不在考虑范围之内。然而，此类侧信道攻击可能会破坏基于TEE的FL框架的安全属性，并非通过提取FL数据，而是通过泄露允许攻击者冒充TEE并任意偏离正确训练协议的密钥。
我们描述了ExclaveFL，一个联邦学习平台，即使在TEE存在侧信道攻击的情况下，也能提供端到端的数据完整性和透明度。我们提出了一种新范式，其中现有TEE被用作飞地——完整性保护的执行环境，不包含任何秘密，使其免疫侧信道攻击。与以前的方法证明TEE本身并将此证明绑定到TEE所持有的密钥不同，ExclaveFL在运行时证明单个数据转换。这些运行时证明形成一个经过证明的数据流图，可以检查以确保FL训练任务满足声明，例如偏离正确计算。我们通过扩展流行的NVFlare FL框架来使用飞地实现了ExclaveFL，并通过实验表明，与没有TEE的相同FL框架相比，ExclaveFL引入的开销不到10%，同时提供了更强的安全保障。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [633] [From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem](https://arxiv.org/abs/2506.15170)
> *从LLMs到MLLMs再到Agents：LLM生态系统中越狱攻击与防御新兴范式的综述*

*Yanxu Mao, Tiehan Cui, Peipei Liu, Datao You, Hongsong Zhu* | **Category: cs.CR** | **Updated: 2025-08-01**

**Keywords:** LLMs, MLLMs, Agents, 越狱攻击, 防御机制

**Comment:** 

> **TL;DR:** 本综述全面分析了LLM、MLLM和Agent发展过程中日益复杂的越狱攻击与防御机制，并指出了现有研究的局限性。

**AI_Comments:** 这篇综述论文的重要性在于它及时地捕捉了LLM生态系统演进过程中出现的最新安全挑战，特别是将MLLMs和Agents纳入考量，并指出了现有综述的局限性，这对于指导未来研究具有重要意义。它提供了一个全面的框架来理解越狱攻击和防御，对于研究人员和开发者都很有价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）正迅速发展为多模态LLMs和智能代理，显著扩展了能力，但同时也带来了日益严重的安全风险，特别是越狱攻击。现有综述未能充分涵盖这些新兴范式带来的安全挑战和最新进展。

**Method:** 本文首先追溯了LLM、MLLM和Agent的发展轨迹，并强调了每个阶段的核心安全挑战。其次，从攻击影响和可见性角度对主流越狱技术进行分类，并详细分析了代表性攻击方法、相关数据集和评估指标。在防御方面，根据响应时间和技术方法组织了现有策略。此外，还识别了现有综述的局限性，并提供了最新工作的综合分析和未来研究方向。

**Result:** 本研究系统地综述了LLM生态系统中日益复杂的越狱攻击和防御机制。论文分类了主流越狱技术和防御策略，并识别了现有综述的关键局限性，包括对Agent特定安全问题的关注不足、缺乏混合越狱方法的清晰分类、缺乏对实验设置的详细分析以及对最新进展的覆盖不足。文章还提供了对最新工作的更新综合分析，并概述了数据集构建、评估框架优化和策略泛化等领域的未来研究方向。

**Conclusion:** 本研究旨在增强对越狱机制的理解，并促进在能力日益增强的LLM背景下，开发更具弹性和适应性的防御策略。

> **ai_Abstract:** 这篇综述论文系统地探讨了大型语言模型（LLMs）从单模态发展到多模态LLMs和智能代理过程中，日益复杂的越狱攻击与防御机制。文章首先回顾了LLM演进中的安全挑战，随后分类并分析了主流的越狱攻击技术及其评估方法，并组织了现有的防御策略。论文还指出了当前综述的不足之处，并提出了未来的研究方向，旨在促进更强大LLM的越狱防御发展。

> **摘要翻译:** 大型语言模型（LLMs）正在迅速从单模态系统发展到多模态LLMs和智能代理，这显著扩展了它们的能力，同时也带来了日益严重的安全风险。本文系统地综述了在不断扩展的LLM生态系统中，越狱攻击和相应防御机制日益增长的复杂性。我们首先追溯了从LLMs到MLLMs和Agents的发展轨迹，强调了每个阶段出现的核心安全挑战。接下来，我们从攻击影响和可见性角度对主流越狱技术进行了分类，并对代表性攻击方法、相关数据集和评估指标进行了全面分析。在防御方面，我们根据响应时间和技术方法组织了现有策略，提供了对其适用性和实现的结构化理解。此外，我们指出了现有综述中的主要局限性，例如对代理特定安全问题的关注不足、缺乏对混合越狱方法的清晰分类、缺乏对实验设置的详细分析以及对最新进展的过时覆盖。为了解决这些局限性，我们提供了对最新工作的更新综合，并概述了数据集构建、评估框架优化和策略泛化等领域的未来研究方向。我们的研究旨在增强对越狱机制的理解，并促进在能力日益增强的LLM背景下，更具弹性和适应性防御策略的进步。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [663] [Theoretically Unmasking Inference Attacks Against LDP-Protected Clients in Federated Vision Models](https://arxiv.org/abs/2506.17292)
> *理论上揭示针对联邦视觉模型中受LDP保护客户端的推断攻击*

*Quan Nguyen, Minh N. Vu, Truc Nguyen, My T. Thai* | **Category: cs.CR, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 联邦学习, 局部差分隐私, 成员推断攻击, 隐私风险, 模型效用

**Comment:** Accepted to ICML 2025

> **TL;DR:** 即使数据受到局部差分隐私（LDP）保护，联邦学习中的成员推断攻击（MIAs）仍然存在显著隐私风险，并且所需的噪声会严重降低模型效用。

**AI_Comments:** 该论文的创新之处在于首次为针对LDP保护数据的成员推断攻击提供了理论下限，填补了现有研究的空白。其重要性在于揭示了即使在使用LDP这种“黄金标准”隐私保护技术时，联邦学习的隐私风险依然存在，并量化了这种风险以及为缓解风险对模型效用造成的影响。这对于理解联邦学习的真实隐私边界具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习被认为是保护隐私的解决方案，但成员推断攻击（MIAs）对其提出了挑战。现有研究大多忽视局部差分隐私（LDP）或未能提供针对LDP保护数据的攻击成功率的理论保证，因此需要填补这一空白。

**Method:** 研究人员推导了利用全连接层或自注意力层漏洞的低多项式时间MIAs成功率的理论下限。并在联邦视觉模型上进行了实际评估。

**Result:** 研究发现，即使数据受到LDP保护，隐私风险仍然存在，且与隐私预算相关。实际评估证实了相当大的隐私风险，并且为了减轻这些攻击所需的噪声会显著降低模型的效用。

**Conclusion:** 即使在局部差分隐私（LDP）的保护下，联邦学习中的隐私风险依然存在，并且为了抵御这些攻击而引入的噪声会严重损害模型的实用性。

> **ai_Abstract:** 该论文理论上揭示了联邦视觉模型中针对受局部差分隐私（LDP）保护客户端的推断攻击。研究通过推导低多项式时间成员推断攻击（MIAs）成功率的理论下限，证明了即使在LDP保护下，隐私风险依然存在，且与隐私预算相关。实际评估进一步证实了这些风险，并指出为抵御攻击而引入的噪声会严重损害模型效用。

> **摘要翻译:** 联邦学习通过协调服务器实现客户端之间的协作学习，同时避免直接数据共享，提供了一种感知的隐私保护解决方案。然而，最近关于成员推断攻击（MIAs）的研究挑战了这一概念，显示出对未受保护的训练数据具有很高的成功率。虽然局部差分隐私（LDP）被广泛认为是数据分析中隐私保护的黄金标准，但大多数关于MIAs的研究要么忽略LDP，要么未能提供针对受LDP保护数据的攻击成功率的理论保证。为了弥补这一空白，我们推导出了利用全连接层或自注意力层漏洞的低多项式时间MIAs成功率的理论下限。我们确定，即使数据受到LDP保护，隐私风险仍然存在，具体取决于隐私预算。对联邦视觉模型的实际评估证实了相当大的隐私风险，揭示出减轻这些攻击所需的噪声会显著降低模型的效用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [693] [A Practical and Secure Byzantine Robust Aggregator](https://arxiv.org/abs/2506.23183)
> *一个实用且安全的拜占庭鲁棒聚合器*

*De Zhang Lee, Aashish Kolluri, Prateek Saxena, Ee-Chien Chang* | **Category: cs.CR** | **Updated: 2025-08-01**

**Keywords:** 拜占庭鲁棒性, 数据投毒, 鲁棒聚合, 机器学习安全, 异常值去除

**Comment:** 

> **TL;DR:** 本文提出了第一个准线性时间运行、具有接近最优偏差界限的拜占庭鲁棒聚合器，该聚合器实用且能有效防御机器学习投毒攻击。

**AI_Comments:** 该论文的创新之处在于首次实现了准线性时间复杂度并达到了接近最优的偏差界限，同时无需对干净数据分布进行假设或预计算阈值。这显著提高了其在实际机器学习训练中的实用性，特别是在防御各种投毒攻击方面。

<details>
  <summary>Details</summary>

**Motivation:** 在机器学习安全中，高维向量（如梯度向量）中的异常值（通常由数据投毒攻击产生）会使计算的平均值产生偏差，从而影响ML模型。需要一种通用的防御策略来过滤掉这些异常值。拜占庭鲁棒聚合是一种算法原语，用于在存在任意损坏向量的情况下计算鲁棒平均值，并保证最终偏差有界。

**Method:** 本文提出了一个新颖的鲁棒聚合器。该算法以准线性时间运行，具有接近最优的偏差界限。它不需要任何关于干净向量分布的先验知识，也不需要预先计算任何过滤阈值。

**Result:** 经验证实了该算法预期的运行时效率，以及在消除10种不同机器学习投毒攻击方面的有效性。

**Conclusion:** 本文提出的鲁棒聚合器是第一个在准线性时间内运行且具有接近最优偏差界限的方案，它实用、高效且能有效防御多种机器学习投毒攻击，使其适用于标准神经网络训练过程。

> **ai_Abstract:** 本文介绍了一种新颖的拜占庭鲁棒聚合器，它是首个以准线性时间运行并实现接近最优偏差界限的方案。该聚合器旨在解决机器学习安全中，由数据投毒攻击导致的高维向量（如梯度）中异常值对平均值计算的偏差问题。与现有方法不同，它无需预知干净数据的分布或预设过滤阈值，使其可以直接应用于标准的神经网络训练过程。实验结果验证了其高效性及在抵御多种机器学习投毒攻击方面的卓越效果。

> **摘要翻译:** 在机器学习安全中，人们经常面临从给定高维向量集中去除异常值以计算其平均值的问题。例如，许多数据投毒攻击变体在训练期间会产生梯度向量，这些向量是干净梯度分布中的异常值，从而使用于导出ML模型的计算平均值产生偏差。在平均之前将其过滤掉可作为一种通用防御策略。拜占庭鲁棒聚合是一种算法原语，它在存在ε比例的可能被任意和自适应损坏的向量的情况下，计算向量的鲁棒平均值，从而使最终平均值的偏差可被证明是有限的。
在本文中，我们提出了第一个拜占庭鲁棒聚合器，其运行时间与输入向量的大小呈准线性关系，并且被证明具有接近最优的偏差界限。我们的算法也不需要任何关于干净向量分布的知识，也不需要从中预先计算任何过滤阈值。这使得它可以直接在标准神经网络训练过程中实用。我们通过实验证实了其预期的运行时效率及其在消除10种不同ML投毒攻击方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [9] [SAMSA 2.0: Prompting Segment Anything with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation](https://arxiv.org/abs/2508.00493)
> *SAMSA 2.0: 利用光谱角提示“万物分割”模型实现高光谱交互式医学图像分割*

*Alfie Roddan, Tobias Czempiel, Chi Xu, Daniel S. Elson, Stamatia Giannarou* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 高光谱图像分割, 光谱角提示, Segment Anything Model, 交互式分割, 医学图像处理

**Comment:** 

> **TL;DR:** SAMSA 2.0是一个新的交互式高光谱医学图像分割框架，通过引入光谱角提示，结合空间线索和光谱相似性，提高了分割准确性和鲁棒性，在不重新训练的情况下优于现有模型。

**AI_Comments:** SAMSA 2.0的创新之处在于将光谱角提示引入到SAM模型中，实现了光谱信息与空间线索的早期融合。这对于高光谱医学图像分割至关重要，因为它能更充分地利用光谱维度信息。其在不重新训练的情况下取得显著性能提升，并展示出强大的泛化能力，对于临床应用中的数据稀缺和噪声挑战具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有模型在处理高光谱医学图像时可能无法充分利用光谱信息，导致分割精度和鲁棒性不足，尤其是在低数据量和噪声场景下。

**Method:** 本文提出了SAMSA 2.0框架，通过引入光谱角提示（spectral angle prompting）来引导Segment Anything Model (SAM)。该方法将光谱相似性与空间线索进行早期融合，以实现更准确和鲁棒的分割。

**Result:** 与仅使用RGB的模型相比，SAMSA 2.0的Dice分数提高了3.8%；与现有光谱融合方法相比，Dice分数提高了3.1%。该方法在少量样本和零样本性能上表现出色，并在临床成像中常见的低数据和噪声场景下展示了强大的泛化能力。

**Conclusion:** SAMSA 2.0通过有效融合光谱信息，显著提高了高光谱医学图像分割的准确性、鲁棒性和泛化能力，尤其适用于数据量有限和存在噪声的临床场景。

> **ai_Abstract:** SAMSA 2.0是一个用于高光谱医学图像的交互式分割框架。它创新性地将光谱角提示引入到Segment Anything Model (SAM)中，通过早期融合光谱相似性和空间线索，显著提升了分割的准确性和鲁棒性。该模型在无需重新训练的情况下，在Dice分数上超越了RGB-only模型和先前的光谱融合方法，并在低数据和噪声的临床场景中展现出优异的泛化能力和少样本/零样本性能。

> **摘要翻译:** 我们提出了SAMSA 2.0，一个用于高光谱医学成像的交互式分割框架，它引入了光谱角提示，通过光谱相似性结合空间线索来引导“万物分割模型”（SAM）。这种光谱信息的早期融合使得在不同光谱数据集上实现更准确和鲁棒的分割。在不重新训练的情况下，SAMSA 2.0比仅使用RGB的模型实现了高达+3.8%的Dice分数提升，比之前的光谱融合方法提升了高达+3.1%。我们的方法增强了少样本和零样本性能，在临床成像中常见的具有挑战性的低数据和噪声场景中展示了强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [10] [Meta CLIP 2: A Worldwide Scaling Recipe](https://arxiv.org/abs/2507.22062)
> *Meta CLIP 2：全球规模化训练范式*

*Yung-Sung Chuang, Yang Li, Dong Wang, Ching-Feng Yeh, Kehan Lyu, Ramya Raghavendra, James Glass, Lifei Huang, Jason Weston, Luke Zettlemoyer, Xinlei Chen, Zhuang Liu, Saining Xie, Wen-tau Yih, Shang-Wen Li, Hu Xu* | **Category: cs.CV, cs.CL** | **Updated: 2025-08-01**

**Keywords:** CLIP, 多语言, 全球规模, 图文预训练, Meta CLIP 2

**Comment:** 10 pages

> **TL;DR:** Meta CLIP 2是首个从零开始在全球网络规模图文对上训练CLIP的模型，解决了多语言数据处理和“多语言诅咒”问题，在单语和多语言基准测试上均达到新的SOTA。

**AI_Comments:** Meta CLIP 2的创新之处在于它是首个从零开始在全球网络规模图文对上训练CLIP的模型，成功解决了多语言数据处理的难题和“多语言诅咒”问题。其重要性在于为构建真正全球化的基础模型提供了可行的方案，并证明了在不引入额外复杂性（如翻译或架构修改）的情况下，多语言数据可以相互促进性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 现有CLIP模型虽然已成功在数十亿级英文图文对上训练，但将其训练进一步扩展到全球网络数据仍面临挑战：1）缺乏处理非英文数据的有效整理方法；2）现有多语言CLIP的英文性能不如其纯英文版本，即存在LLM中常见的“多语言诅咒”问题。

**Method:** 本文提出了Meta CLIP 2，这是第一个从零开始在全球网络规模的图文对上训练CLIP的范式。为了推广研究发现，作者进行了严格的消融实验，并进行了必要的最小化修改来解决上述挑战，从而提出了一种能够使英文和非英文世界数据相互受益的范式。

**Result:** 在零样本ImageNet分类中，Meta CLIP 2 ViT-H/14比其纯英文版本高0.8%，比mSigLIP高0.7%。在多语言基准测试（如CVQA、Babel-ImageNet、XM3600的图文检索任务）上，Meta CLIP 2在没有系统级混淆因素（如翻译、定制架构更改）的情况下，取得了新的最先进成果，其中CVQA达到57.4%，Babel-ImageNet达到50.2%，XM3600达到64.3%。

**Conclusion:** Meta CLIP 2成功实现了从全球网络规模图文对中训练CLIP，克服了多语言数据处理和“多语言诅咒”的挑战，并使英文和非英文世界数据相互受益，在多语言和单语言任务上均取得了显著的性能提升。

> **ai_Abstract:** 本文介绍了Meta CLIP 2，一个旨在解决当前CLIP模型在扩展至全球多语言网络数据时面临的挑战的训练范式。它克服了非英文数据整理的难题和“多语言诅咒”问题，首次实现了从零开始在全球规模图文对上训练CLIP。通过严格的消融实验，Meta CLIP 2在零样本ImageNet分类上超越了现有模型，并在多语言基准测试中达到了新的SOTA，证明了其在整合全球数据并实现英语和非英语数据互利方面的有效性。

> **摘要翻译:** 对比语言-图像预训练（CLIP）是一种流行的基础模型，支持从零样本分类、检索到多模态大型语言模型（MLLMs）的编码器。尽管CLIP已成功在英文世界的数十亿级图文对上训练，但将CLIP的训练进一步扩展到从全球网络数据中学习仍然具有挑战性：(1) 没有可用的整理方法来处理非英文世界的数据点；(2) 现有多语言CLIP的英文性能比其纯英文版本更差，即LLM中常见的“多语言诅咒”。在此，我们提出了Meta CLIP 2，这是第一个从零开始在全球网络规模图文对上训练CLIP的范式。为了推广我们的发现，我们进行了严格的消融实验，并进行了必要的最小化修改来解决上述挑战，提出了一种能够使英文和非英文世界数据相互受益的范式。在零样本ImageNet分类中，Meta CLIP 2 ViT-H/14比其纯英文版本高0.8%，比mSigLIP高0.7%，并且令人惊讶地在多语言基准测试（如CVQA的57.4%、Babel-ImageNet的50.2%和XM3600的图文检索的64.3%）上，在没有系统级混淆因素（例如，翻译、定制架构更改）的情况下，取得了新的最先进成果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [14] [PointGauss: Point Cloud-Guided Multi-Object Segmentation for Gaussian Splatting](https://arxiv.org/abs/2508.00259)
> *PointGauss：点云引导的高斯溅射多目标分割*

*Wentao Sun, Hanqing Xu, Quanyun Wu, Dedong Zhang, Yiping Chen, Lingfei Ma, John S. Zelek, Jonathan Li* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 高斯溅射, 多目标分割, 点云引导, 实时分割, DesktopObjects-360

**Comment:** 22 pages, 9 figures

> **TL;DR:** PointGauss是一个点云引导的实时多目标分割框架，用于高斯溅射表示，解决了现有方法初始化慢和多视角一致性差的问题，并引入了新数据集。

**AI_Comments:** PointGauss的创新之处在于其结合点云分割来高效处理高斯基元，实现了高斯溅射中的实时多目标分割，显著提升了分割速度和多视角一致性。同时，其引入的DesktopObjects-360数据集填补了当前3D分割基准在多目标、3D评估和数据规模上的空白，对推动该领域的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在实时多目标分割中存在初始化时间长和多视角一致性有限的问题。

**Method:** 提出PointGauss框架，通过点云分割驱动的流水线直接解析高斯基元实现高效3D分割。核心创新包括：1) 基于点云的高斯基元解码器，可在1分钟内生成3D实例掩码；2) GPU加速的2D掩码渲染系统，确保多视角一致性。此外，还提出了DesktopObjects-360数据集以解决现有基准的局限性。

**Result:** 实验证明PointGauss在多视角mIoU上比现有SOTA方法提升1.89%至31.78%，并保持卓越的计算效率。新数据集DesktopObjects-360解决了现有基准的单目标、3D评估不一致、规模小和覆盖不全等问题。

**Conclusion:** PointGauss在高斯溅射表示中实现了高效、实时的点云引导多目标分割，显著优于现有方法，并提供了一个新的综合数据集以推动该领域发展。

> **ai_Abstract:** PointGauss提出了一种点云引导的实时多目标分割框架，专门用于高斯溅射表示。它通过点云分割驱动的流水线直接解析高斯基元，解决了现有方法初始化慢和多视角一致性差的问题。该方法包含一个快速的3D实例掩码生成器和一个GPU加速的2D渲染系统。实验结果显示，PointGauss在多视角mIoU上显著优于现有SOTA方法，并具有更高的计算效率。此外，论文还引入了DesktopObjects-360数据集，以解决当前3D分割基准的不足，提供更复杂、更全面的多目标场景和评估标准。

> **摘要翻译:** 我们引入了PointGauss，这是一种新颖的点云引导框架，用于高斯溅射表示中的实时多目标分割。与现有方法初始化时间长且多视角一致性有限的缺点不同，我们的方法通过点云分割驱动的流水线直接解析高斯基元，实现了高效的3D分割。关键创新在于两个方面：(1) 一个基于点云的高斯基元解码器，可在1分钟内生成3D实例掩码；(2) 一个GPU加速的2D掩码渲染系统，确保多视角一致性。大量实验表明，与现有最先进方法相比，我们的方法在多视角mIoU上取得了1.89%至31.78%的显著性能提升，同时保持了卓越的计算效率。为了解决当前基准的局限性（单目标关注、不一致的3D评估、小规模和部分覆盖），我们提出了DesktopObjects-360，一个用于辐射场中3D分割的全新综合数据集，其特点包括：(1) 复杂的多目标场景，(2) 全局一致的2D标注，(3) 大规模训练数据（超过2.7万个2D掩码），(4) 完整的360度覆盖，以及(5) 3D评估掩码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [16] [IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation](https://arxiv.org/abs/2508.00823)
> *IGL-Nav：用于图像目标导航的增量式3D高斯定位*

*Wenxuan Guo, Xiuwei Xu, Hang Yin, Ziwei Wang, Jianjiang Feng, Jie Zhou, Jiwen Lu* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-01**

**Keywords:** 图像目标导航, 3D高斯, 增量式定位, 视觉导航, 机器人导航

**Comment:** Accepted to ICCV 2025. Project page:
  https://gwxuan.github.io/IGL-Nav/

> **TL;DR:** IGL-Nav提出了一种基于增量式3D高斯表示的图像目标导航框架，通过分阶段的粗定位和精细优化，高效且准确地实现了3D空间中的图像目标定位，显著优于现有SOTA方法。

**AI_Comments:** 该论文的创新点在于将3D高斯表示与增量式更新、分阶段定位策略相结合，有效解决了图像目标导航中3D定位的效率和精度难题。通过引入粗定位和精细优化的两阶段方法，并利用3DGS的渲染能力，实现了对复杂几何关系的精确建模。其在自由视角目标和真实世界部署方面的能力也显示了该方法的实用性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 图像目标视觉导航是一个基础且具有挑战性的问题。现有方法（如端到端强化学习或基于拓扑图/BEV地图的模块化策略）无法充分建模探索的3D环境与目标图像之间的几何关系。直接利用计算密集型3D高斯表示（3DGS）进行图像定位效率低下，尤其是在6自由度相机位姿的大搜索空间下。

**Method:** 提出IGL-Nav，一个增量式3D高斯定位框架。该方法首先通过前馈单目预测，随着新图像的到来增量更新场景表示。然后，利用几何信息进行离散空间匹配（相当于高效的3D卷积）进行粗略的目标定位。当智能体接近目标时，通过可微分渲染优化来解决精细的目标位姿。

**Result:** IGL-Nav在各种实验配置下，性能显著优于现有最先进的方法。它还能处理更具挑战性的自由视角图像目标设置，并可部署在真实世界的机器人平台上，使用手机以任意姿态捕获目标图像。

**Conclusion:** IGL-Nav通过其增量式3D高斯定位框架，有效解决了图像目标导航中3D空间定位的效率和精度问题，显著提升了该领域的性能，并展现了在复杂场景和实际应用中的潜力。

> **ai_Abstract:** IGL-Nav是一个针对图像目标导航提出的增量式3D高斯定位框架。它解决了现有方法在建模3D环境与目标图像几何关系上的不足以及直接使用3DGS进行定位的低效率问题。该方法通过增量更新3D高斯场景表示、结合高效的3D卷积进行粗定位，并在接近目标时通过可微分渲染进行精细优化，实现了高效且3D感知的图像目标导航。实验结果表明，IGL-Nav在性能上大幅超越了SOTA方法，并支持自由视角目标和真实世界部署。

> **摘要翻译:** 以图像为目标的视觉导航是一个基础且具有挑战性的问题。传统方法要么依赖于端到端的强化学习，要么采用基于拓扑图或BEV地图作为记忆的模块化策略，这些方法都无法充分建模探索的3D环境与目标图像之间的几何关系。为了在3D空间中高效准确地定位目标图像，我们基于可渲染的3D高斯（3DGS）表示构建了我们的导航系统。然而，由于3DGS优化的计算强度和6自由度相机位姿的巨大搜索空间，在智能体探索过程中直接利用3DGS进行图像定位效率极低。为此，我们提出了IGL-Nav，一个用于高效且3D感知的图像目标导航的增量式3D高斯定位框架。具体而言，我们通过前馈单目预测，随着新图像的到来增量更新场景表示。然后，我们利用几何信息进行离散空间匹配（这可以等效于高效的3D卷积）来粗略定位目标。当智能体接近目标时，我们最终通过可微分渲染优化来解决精细的目标位姿。所提出的IGL-Nav在各种实验配置下，性能显著优于现有最先进的方法。它还能处理更具挑战性的自由视角图像目标设置，并可部署在真实世界的机器人平台上，使用手机以任意姿态捕获目标图像。项目页面：https://gwxuan.github.io/IGL-Nav/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [17] [Core-Set Selection for Data-efficient Land Cover Segmentation](https://arxiv.org/abs/2505.01225)
> *数据高效土地覆盖分割的核心集选择*

*Keiller Nogueira, Akram Zaytar, Wanli Ma, Ribana Roscher, Ronny Hänsch, Caleb Robinson, Anthony Ortiz, Simone Nsutezo, Rahul Dodhia, Juan M. Lavista Ferres, Oktay Karakuş, Paul L. Rosin* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 核心集选择, 土地覆盖分割, 遥感, 数据中心学习, 深度学习

**Comment:** 

> **TL;DR:** 本文提出了六种新颖的核心集选择方法，用于从遥感图像分割数据集中选择重要样本子集，以实现数据高效的土地覆盖分割，实验证明其性能优于随机选择基线，甚至在某些情况下优于使用全部数据训练。

**AI_Comments:** 这篇论文的创新点在于提出了多种核心集选择方法，以解决遥感图像分割中大数据集训练的效率和质量问题。它强调了“数据中心学习”的重要性，即通过优化数据质量而非仅仅增加数据量来提升模型性能。其贡献在于为遥感领域提供了一种数据高效的训练策略，这对于资源受限或需要快速迭代的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型在地球观测任务中需要大量数据训练，但大数据集可能引入偏差、噪声，并消耗大量计算资源。因此，需要考虑数据数量和质量的有效解决方案。

**Method:** 提出了六种新颖的核心集选择方法，用于从遥感图像分割数据集中选择重要样本子集。这些方法仅依赖图像、仅依赖标签或两者的组合。在DFC2022、Vaihingen和Potsdam三个常用土地覆盖分类数据集上与随机选择基线进行基准测试。

**Result:** 在每个数据集中，使用样本子集进行训练的表现优于随机基线，并且一些方法甚至优于使用所有可用数据进行训练。

**Conclusion:** 这一结果表明了数据中心学习在遥感领域的重要性和潜力。

> **ai_Abstract:** 本文针对遥感领域深度学习模型训练中大数据集带来的挑战，提出六种新颖的核心集选择方法，旨在从遥感图像分割数据集中高效选择高质量样本子集。实验结果表明，在DFC2022、Vaihingen和Potsdam数据集上，使用这些方法选择的子集进行训练，其性能优于随机选择基线，部分方法甚至超越了使用全部数据训练的效果，突显了数据中心学习在遥感应用中的巨大潜力和价值。

> **摘要翻译:** 遥感数据日益普及，其在大型决策中的潜力推动了许多地球观测任务中深度学习模型的发展。传统上，此类模型必须在大型数据集上进行训练。然而，普遍认为数据集越大效果越好的假设往往忽视了数据分布的复杂性、引入偏差和噪声的可能性，以及处理和存储大量数据集所需的计算资源。因此，有效的解决方案应同时考虑数据的数量和质量。在本文中，我们提出了六种新颖的核心集选择方法，用于从仅依赖图像、仅依赖标签以及两者结合的遥感图像分割数据集中选择重要的样本子集。我们将这些方法在三个常用土地覆盖分类数据集：DFC2022、Vaihingen和Potsdam上与随机选择基线进行了基准测试。在每个数据集中，我们都证明了在样本子集上进行训练的性能优于随机基线，并且一些方法甚至优于使用所有可用数据进行训练。这一结果表明了数据中心学习在遥感领域的重要性和潜力。代码可在https://github.com/keillernogueira/data-centric-rs-classification/获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [21] [D3: Training-Free AI-Generated Video Detection Using Second-Order Features](https://arxiv.org/abs/2508.00701)
> *D3：使用二阶特征的免训练AI生成视频检测*

*Chende Zheng, Ruiqi suo, Chenhao Lin, Zhengyu Zhao, Le Yang, Shuai Liu, Minghui Yang, Cong Wang, Chao Shen* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** AI生成视频检测, 二阶特征, 免训练, 时间伪影, D3

**Comment:** 8 pages, 4 figures

> **TL;DR:** D3是一种免训练的AI生成视频检测方法，它利用真实视频和AI生成视频之间在二阶特征分布上的差异，在多个数据集上表现出优越的性能和计算效率。

**AI_Comments:** D3的创新之处在于其免训练的特性以及对视频二阶时间伪影的深入探索，这与现有方法主要关注一阶特征形成对比。该方法基于坚实的理论框架，并通过实验证明了其在检测AI生成视频方面的卓越性能和效率，为解决合成内容传播问题提供了一个有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 随着Sora等视频生成技术的发展，AI生成高保真视频变得越来越容易，引发了对合成内容传播的公众担忧。然而，现有的检测方法在探索合成视频中的时间伪影方面存在不足。

**Method:** 本文建立了基于牛顿力学的二阶动力学分析理论框架，并扩展了用于时间伪影检测的二阶中心差分特征。在此基础上，提出了D3（Detection by Difference of Differences），一种利用真实视频和AI生成视频之间二阶特征分布差异的免训练检测方法。

**Result:** D3在4个开源数据集（Gen-Video, VideoPhy, EvalCrafter, VidProM）共40个子集上验证了其优越性。例如，在GenVideo数据集上，D3的平均精度比现有最佳方法提高了10.39%（绝对值）。额外实验表明D3具有出色的计算效率和强大的鲁棒性能。

**Conclusion:** D3通过利用视频的二阶时间伪影，提供了一种高效且鲁棒的免训练AI生成视频检测方法，有效解决了现有方法在时间伪影探索不足的问题。

> **ai_Abstract:** 本文提出D3，一种免训练的AI生成视频检测方法。该方法基于牛顿力学的二阶动力学分析，通过利用真实视频和AI生成视频之间在二阶特征分布上的根本性差异来检测合成内容。D3在多个开源数据集上表现出显著的性能提升，例如在GenVideo上平均精度绝对值提高了10.39%，同时具有高计算效率和鲁棒性。

> **摘要翻译:** 随着Sora等视频生成技术的发展，生成高保真AI生成视频变得越来越容易，引发了对合成内容传播的公众担忧。然而，现有的检测方法因对合成视频中时间伪影的探索不足而受到限制。为了弥补这一差距，我们通过牛顿力学下的二阶动力学分析建立了一个理论框架，随后扩展了专为时间伪影检测量身定制的二阶中心差分特征。在此理论基础上，我们揭示了真实视频和AI生成视频之间在二阶特征分布上的根本性差异。具体而言，我们提出了一种新颖的免训练检测方法——差异之差检测（D3），该方法利用上述二阶时间差异。我们在4个开源数据集（Gen-Video、VideoPhy、EvalCrafter、VidProM）共40个子集上验证了D3的优越性。例如，在GenVideo上，D3的平均精度比之前最好的方法提高了10.39%（绝对值）。关于时间成本和后处理操作的额外实验表明D3具有出色的计算效率和强大的鲁棒性能。我们的代码可在https://github.com/Zig-HS/D3获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [28] [Querying Autonomous Vehicle Point Clouds: Enhanced by 3D Object Counting with CounterNet](https://arxiv.org/abs/2507.19209)
> *自动驾驶车辆点云查询：通过CounterNet增强的3D对象计数*

*Xiaoyu Zhang, Zhifeng Bao, Hai Dong, Ziwei Wang, Jiajun Liu* | **Category: cs.CV, cs.MM** | **Updated: 2025-08-01**

**Keywords:** 点云查询, 3D对象计数, CounterNet, 自动驾驶, 热图网络

**Comment:** 

> **TL;DR:** 本文形式化了点云查询，并提出了CounterNet，一个基于热图的网络，通过精确的3D对象计数显著提高了自动驾驶点云查询的可靠性。

**AI_Comments:** 本文的创新点在于认识到3D点云查询中精确对象计数的重要性，并提出了专门解决此问题的CounterNet。它通过避免复杂的精确对象定位，转而聚焦于对象中心检测来提高计数精度，这是一个务实的创新。此外，动态模型选择和特征图分区策略也增强了其在复杂场景下的鲁棒性。这对于自动驾驶数据分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶车辆生成海量点云数据，但仅部分与特定任务相关。有效查询数据至关重要，而现有技术在3D点云上无法提供可靠的对象计数，导致查询结果误差大。

**Method:** 提出CounterNet，一个基于热图的网络，通过寻找对象中心来提高计数精度，而非精确对象定位。它还采用重叠区域的特征图分区策略以处理不同大小对象，并引入每帧动态模型选择策略以适应不同帧特性。

**Result:** 在三个真实世界自动驾驶数据集上的评估表明，CounterNet将对象计数精度提高了5%到20%，从而使所有支持的查询类型（检索、计数、聚合）的查询结果更加可靠。

**Conclusion:** CounterNet通过改进3D点云中的对象计数，显著提高了自动驾驶车辆点云查询的可靠性和准确性。

> **ai_Abstract:** 本文形式化了自动驾驶点云数据的三种核心查询类型（检索、计数、聚合），并指出精确对象计数是其关键瓶颈。针对现有3D检测模型计数不准确的问题，提出CounterNet，一个基于热图的网络，通过检测对象中心、特征图分区和动态模型选择策略，显著提高了3D点云中的对象计数精度（5%-20%），从而提升了所有查询类型的可靠性。

> **摘要翻译:** 自动驾驶车辆生成海量的点云数据，然而只有一部分与碰撞检测、交通分析或拥堵监控等特定任务相关。有效查询这些数据对于实现有针对性的分析至关重要。在这项工作中，我们通过定义三种核心查询类型来形式化点云查询：检索（RETRIEVAL）、计数（COUNT）和聚合（AGGREGATION），每种类型都与不同的分析场景对齐。所有这些查询都严重依赖精确的对象计数来产生有意义的结果，这使得精确的对象计数成为查询执行的关键组成部分。先前的工作主要集中在2D视频数据的索引技术上，假设检测模型提供准确的计数信息。然而，当应用于3D点云数据时，最先进的检测模型通常无法生成可靠的对象计数，导致查询结果出现大量错误。为了解决这一限制，我们提出了CounterNet，一个基于热图的网络，旨在对大规模点云数据进行精确的对象计数。CounterNet不侧重于精确的对象定位，而是通过寻找对象中心来检测对象的存在，从而提高计数精度。我们通过使用重叠区域的特征图分区策略进一步增强了其性能，从而更好地处理复杂交通场景中的小型和大型对象。为了适应不同的帧特性，我们引入了一种每帧动态模型选择策略，为每个输入选择最有效的配置。在三个真实世界的自动驾驶数据集上的评估表明，CounterNet在所有对象类别中将计数精度提高了5%到20%，从而使所有支持的查询类型获得了更可靠的查询结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [33] [Leveraging Convolutional and Graph Networks for an Unsupervised Remote Sensing Labelling Tool](https://arxiv.org/abs/2508.00506)
> *利用卷积网络和图网络实现无监督遥感标注工具*

*Tulsi Patel, Mark W. Jones, Thomas Redfern* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 遥感, 无监督学习, 卷积网络, 图网络, 图像标注

**Comment:** Video supplement demonstrating feature-space exploration and
  interactive labelling is available at: https://youtu.be/GZl1ebZJgEA and is
  archived at https://doi.org/10.5281/zenodo.16676591

> **TL;DR:** 本文提出了一种利用卷积和图神经网络的无监督遥感图像标注工具，解决了传统标注方法对预标注数据的依赖问题，并提高了标注的精度和鲁棒性。

**AI_Comments:** 本文的创新点在于提出了一个完全无监督的遥感图像标注流程，这极大地降低了对人工标注数据的依赖，从而节省了大量时间和成本。通过结合卷积网络和图网络，该方法能够捕获图像的局部特征和全局上下文信息，生成更鲁棒的特征表示。特别是图神经网络的应用，使得模型能够更好地理解图像中区域间的空间关系，从而提高了标注的准确性和精细度。该工作对于推动遥感图像处理的自动化和智能化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 遥感图像的机器学习需要最新且准确的标签进行模型训练和测试，但遥感图像的标注耗时且成本高昂，需要专家分析。以往的标注工具依赖于预标注数据进行训练才能标注新的未知数据，这限制了其应用。

**Method:** 本文定义了一个无监督管道，用于在Sentinel-2卫星图像中查找和标注具有相似上下文和内容的地理区域。该方法通过结合分割技术、卷积神经网络和图神经网络来编码更鲁棒的特征空间，用于图像比较。具体而言，图像被分割成基于颜色和空间相似性的同质像素区域，图神经网络用于聚合周围区域的信息，从而在编码局部邻域信息的同时保留自身的局部信息。

**Result:** 该方法减少了标注工具中的异常值，允许用户进行精细化标注，并能在编码空间中形成图像级别的旋转不变语义关系。

**Conclusion:** 本文成功开发了一种利用卷积和图网络的无监督遥感图像标注工具，有效解决了传统标注方法对预标注数据的依赖和标注效率低的问题，并提升了标注的精度和鲁棒性。

> **ai_Abstract:** 本文提出了一种新颖的无监督遥感图像标注工具，旨在解决传统标注方法对大量预标注数据的依赖问题。该工具通过结合图像分割、卷积神经网络（CNNs）和图神经网络（GNNs）来处理Sentinel-2卫星图像。CNNs用于生成更鲁棒的特征表示，而GNNs则用于整合图像中同质区域的上下文信息，从而实现更精确和细粒度的标注。该方法显著减少了异常值，支持精细化标注，并能在特征空间中实现旋转不变的语义关系。

> **摘要翻译:** 机器学在遥感图像处理中依赖于最新和准确的标签进行模型训练和测试。遥感图像的标注既耗时又成本高昂，需要专家分析。以往的标注工具依赖于预标注数据进行训练，以便标注新的未见数据。在这项工作中，我们定义了一个无监督管道，用于在Sentinel-2卫星图像中查找和标注具有相似上下文和内容的地理区域。我们的方法通过利用卷积和图神经网络进行分割，编码更鲁棒的特征空间以进行图像比较，从而消除了以往方法的局限性。与以往的方法不同，我们将图像分割成基于颜色和空间相似性分组的同质像素区域。图神经网络用于聚合周围区域的信息，使得特征表示能够编码局部邻域信息，同时保留其自身的局部信息。这减少了标注工具中的异常值，允许用户进行精细化标注，并允许在编码空间中形成图像级别的旋转不变语义关系。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [36] [GUAVA: Generalizable Upper Body 3D Gaussian Avatar](https://arxiv.org/abs/2505.03351)
> *GUAVA: 可泛化的上半身3D高斯头像*

*Dongbin Zhang, Yunfei Liu, Lijian Lin, Ye Zhu, Yang Li, Minghan Qin, Yu Li, Haoqian Wang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 3D高斯头像, 上半身重建, 单张图像, 实时动画, 表达性人体模型

**Comment:** Accepted to ICCV 2025, Project page:
  https://eastbeanzhang.github.io/GUAVA/

> **TL;DR:** GUAVA从单张图像快速重建高质量、可动画的上半身3D高斯头像，并支持实时渲染。

**AI_Comments:** GUAVA的创新之处在于其首次实现了从单张图像快速重建可动画的上半身3D高斯头像，并解决了面部表情的表达限制。其亚秒级的重建速度和实时渲染能力具有重要的实际应用价值，例如在VR/AR、游戏和虚拟会议中。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法重建高质量、可动画的3D人体头像需要多视角或单目视频，且训练耗时复杂，难以处理面部表情（受限于SMPLX表达能力）。

**Method:** 引入表达性人体模型（EHM）以增强面部表情能力并开发精确跟踪方法。基于此模板模型，提出GUAVA框架，利用逆纹理映射和投影采样技术从单张图像推断上半身高斯点，并通过神经细化器改进渲染图像。

**Result:** GUAVA在渲染质量上显著优于现有方法，速度显著提升（重建时间在亚秒级，0.1秒），并支持实时动画和渲染。

**Conclusion:** GUAVA成功解决了从单张图像重建高质量、可动画上半身3D头像的挑战，并实现了高效和实时的性能。

> **ai_Abstract:** GUAVA是一个创新的框架，旨在从单张图像快速重建高质量、可动画的上半身3D高斯头像。该方法通过引入表达性人体模型（EHM）解决了现有方法在面部表情和重建效率上的不足。GUAVA利用逆纹理映射、投影采样和神经细化器，实现了亚秒级的重建速度和卓越的渲染质量，支持实时动画和渲染，显著优于现有技术。

> **摘要翻译:** 从单张图像重建具有丰富面部和手部动作的高质量、可动画3D人体头像因其广泛的应用潜力而受到广泛关注。3D人体头像重建通常需要多视角或单目视频，并针对单个ID进行训练，这既复杂又耗时。此外，受限于SMPLX的表达能力，这些方法通常侧重于身体动作，但在面部表情方面表现不佳。为了解决这些挑战，我们首先引入了一种表达性人体模型（EHM）来增强面部表情能力，并开发了一种精确的跟踪方法。基于这种模板模型，我们提出了GUAVA，这是第一个用于快速可动画上半身3D高斯头像重建的框架。我们利用逆纹理映射和投影采样技术从单张图像推断上半身（Ubody）高斯点。渲染的图像通过神经细化器进行精细化。实验结果表明，GUAVA在渲染质量上显著优于现有方法，并提供了显著的速度改进，重建时间在亚秒级（0.1秒），并支持实时动画和渲染。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [44] [Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models](https://arxiv.org/abs/2508.00260)
> *指令引导的视觉投影仪用于生成式视觉-语言模型的持续学习*

*Hyundong Jin, Hyung Jin Chang, Eunwoo Kim* | **Category: cs.CV, cs.MM** | **Updated: 2025-08-01**

**Keywords:** 持续学习, 视觉-语言模型, 视觉投影仪, 指令遵循, 专家系统

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 本文提出了一种新的框架，通过引入指令引导的混合视觉投影仪和专家推荐/剪枝策略，解决了持续学习中视觉-语言模型忽视语言指令的问题，并在各种视觉-语言任务上取得了SOTA性能。

**AI_Comments:** 这项工作通过引入指令引导的视觉投影仪和创新的专家管理策略（推荐与剪枝），有效地解决了持续学习中生成式VLMs忽视语言指令的关键问题。其创新点在于将指令上下文融入视觉信息翻译过程，显著提高了模型在复杂任务中的指令遵循能力，为持续学习领域带来了新的视角和解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的持续学习方法在更新视觉投影仪以适应新任务时，可能导致生成式视觉-语言模型（VLMs）优先处理视觉输入而忽视语言指令，尤其是在处理重复类型的文本指令任务时。

**Method:** 本文提出了一种新颖的框架，该框架将视觉信息的翻译基于语言模型指令进行。具体包括：1. 引入混合视觉投影仪，每个作为基于给定指令上下文的专业视觉到语言翻译专家。2. 提出专家推荐策略，以重用与先前学习任务相似的指令上下文的专家。3. 引入专家剪枝机制，以减轻先前任务中累积激活的专家所造成的干扰。

**Result:** 在多样化的视觉-语言任务上进行的广泛实验表明，所提出的方法通过生成遵循指令的响应，优于现有的持续学习方法。

**Conclusion:** 通过指令引导的混合视觉投影仪、专家推荐和专家剪枝策略，本研究成功解决了持续学习中生成式视觉-语言模型忽视语言指令的问题，并显著提升了模型在指令遵循方面的性能。

> **ai_Abstract:** 本文针对生成式视觉-语言模型（VLMs）在持续学习中可能忽视语言指令的问题，提出了一种新颖的框架。该框架引入了指令引导的混合视觉投影仪，每个投影仪作为基于指令上下文的专业翻译专家。为有效利用这些专家，还提出了专家推荐策略以重用相似任务的专家，并引入专家剪枝以减轻干扰。实验证明，该方法在多种视觉-语言任务上生成了更好的指令遵循响应，超越了现有持续学习方法。

> **摘要翻译:** 持续学习使预训练的生成式视觉-语言模型（VLMs）能够整合来自新任务的知识，而无需重新训练旧任务的数据。最近的方法更新视觉投影仪，以翻译新任务的视觉信息，连接预训练的视觉编码器与大型语言模型。然而，这种调整可能导致模型优先处理视觉输入而非语言指令，尤其是在学习具有重复类型文本指令的任务时。为了解决语言指令被忽视的问题，我们提出了一种新颖的框架，该框架将视觉信息的翻译基于语言模型的指令进行。我们引入了混合视觉投影仪，每个投影仪根据给定的指令上下文作为专业的视觉到语言翻译专家，以适应新任务。为了避免将专家用于不相关的指令上下文，我们提出了一种专家推荐策略，该策略为与先前学习任务相似的任务重用专家。此外，我们引入了专家剪枝以减轻先前任务中累积激活的专家所造成的干扰。在多样化的视觉-语言任务上进行的广泛实验表明，我们的方法通过生成遵循指令的响应，优于现有的持续学习方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [53] [ReAlign: Bilingual Text-to-Motion Generation via Step-Aware Reward-Guided Alignment](https://arxiv.org/abs/2505.04974)
> *ReAlign：通过步长感知奖励引导对齐的双语文本到动作生成*

*Wanjiang Weng, Xiaofeng Tan, Hongsong Wang, Pan Zhou* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 双语文本到动作, 扩散模型, 奖励引导对齐, 人体动作生成, BiHumanML3D

**Comment:** We believe that there are some areas in the manuscript that require
  further improvement, and out of our commitment to refining this work, we have
  decided to withdraw our manuscript after careful deliberation and discussion

> **TL;DR:** 本文提出了ReAlign框架，包含BiHumanML3D数据集和奖励引导对齐方法，旨在解决双语文本到动作生成中的数据稀缺和分布未对齐问题，显著提升动作质量和文本对齐度。

**AI_Comments:** 该论文通过创建新的数据集和提出创新的奖励引导对齐机制，有效解决了双语文本到动作生成领域的两大核心挑战：数据稀缺和模型对齐问题。步长感知奖励模型的引入是其主要创新点，它能够实时评估和优化生成过程，确保动作的语义一致性和真实感，对于推动跨语言应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 双语文本到动作生成任务面临两大挑战：缺乏双语动作语言数据集，以及扩散模型中文本和动作分布之间的错位，这导致生成的动作语义不一致或质量低下。

**Method:** 本文提出了BiHumanML3D，一个新颖的双语人体动作数据集。同时，提出了Bilingual Motion Diffusion model (BiMD)，利用跨语言对齐表示捕捉语义。核心方法是Reward-guided sampling Alignment (ReAlign)，其包含一个步长感知奖励模型，用于在采样期间评估对齐质量，并采用奖励引导策略将扩散过程导向最佳对齐分布。该奖励模型整合步长感知标记，并结合文本对齐模块（语义一致性）和动作对齐模块（真实感）。

**Result:** 实验表明，与现有最先进的方法相比，本文提出的方法显著改善了文本-动作对齐和动作质量。

**Conclusion:** 本文提出的方法有效解决了双语文本到动作生成中的数据稀缺和分布未对齐问题，显著提升了生成动作的质量和文本对齐度。

> **ai_Abstract:** 本文提出了ReAlign框架，用于解决双语文本到动作生成中数据稀缺和文本-动作分布未对齐的问题。为此，作者构建了BiHumanML3D数据集，并提出了BiMD双语扩散模型。核心创新是ReAlign方法，其包含一个步长感知奖励模型，能在采样过程中评估和引导扩散过程，以实现语义一致和高质量的动作生成。实验证明该方法显著提升了文本-动作对齐和动作质量。

> **摘要翻译:** 双语文本到动作生成，即从双语文本输入合成3D人体动作，在游戏、电影和机器人等跨语言应用中具有巨大的潜力。然而，这项任务面临着严峻的挑战：缺乏双语动作语言数据集，以及扩散模型中文本和动作分布之间的错位，这导致语义不一致或低质量的动作。为了解决这些挑战，我们提出了BiHumanML3D，一个新颖的双语人体动作数据集，它为双语文本到动作生成模型建立了重要的基准。此外，我们提出了一个双语动作扩散模型（BiMD），它利用跨语言对齐的表示来捕捉语义，从而实现统一的双语模型。在此基础上，我们提出了奖励引导采样对齐（ReAlign）方法，该方法包括一个步长感知奖励模型，用于在采样期间评估对齐质量，以及一个奖励引导策略，将扩散过程导向最佳对齐分布。这个奖励模型整合了步长感知标记，并结合了一个用于语义一致性的文本对齐模块和一个用于真实感的动作对齐模块，在每个时间步细化噪声动作，以平衡概率密度和对齐。实验表明，与现有最先进的方法相比，我们的方法显著改善了文本-动作对齐和动作质量。项目页面：https://wengwanjiang.github.io/ReAlign-page/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [57] [EPANet: Efficient Path Aggregation Network for Underwater Fish Detection](https://arxiv.org/abs/2508.00528)
> *EPANet：水下鱼类检测的高效路径聚合网络*

*Jinsong Yang, Zeyuan Hu, Yichen Li* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 水下鱼类检测, 路径聚合网络, 特征金字塔网络, 瓶颈结构, 轻量级模型

**Comment:** 

> **TL;DR:** EPANet是一种高效路径聚合网络，通过互补特征整合实现准确且轻量级的水下鱼类检测，在保持低模型复杂度的同时，在检测精度和推理速度上优于现有方法。

**AI_Comments:** EPANet的创新之处在于其双组件设计，特别是EPA-FPN通过长距离跳跃连接和跨层融合，有效提升了特征整合效率和语义-空间互补性，这对于低分辨率和高背景干扰的水下图像至关重要。MS-DDSP瓶颈通过引入更细粒度的特征分割和多样化卷积操作，增强了模型的局部特征多样性和表示能力，有助于更精准地识别目标。该方法在保持低参数复杂度的同时，实现了精度和速度的提升，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 水下鱼类检测（UFD）在计算机视觉领域仍是一项具有挑战性的任务，原因包括低目标分辨率、显著的背景干扰以及目标与周围环境之间的高度视觉相似性。现有方法通常以增加模型复杂性和降低效率为代价。

**Method:** 我们提出了一个高效路径聚合网络（EPANet），它利用互补特征整合来实现准确且轻量级的水下鱼类检测。EPANet包含两个关键组件：高效路径聚合特征金字塔网络（EPA-FPN）和多尺度多样化分割短路径瓶颈（MS-DDSP瓶颈）。EPA-FPN引入了跨不同尺度的长距离跳跃连接以改善语义空间互补性，并采用跨层融合路径来提高特征整合效率。MS-DDSP瓶颈通过引入更细粒度的特征分割和多样化的卷积操作来扩展传统瓶颈结构，从而增加局部特征多样性和表示能力。

**Result:** 在基准UFD数据集上进行的大量实验表明，EPANet在检测精度和推理速度方面优于现有最先进的方法，同时保持了相当甚至更低的参数复杂度。

**Conclusion:** EPANet通过其创新的EPA-FPN和MS-DDSP瓶颈组件，有效解决了水下鱼类检测的挑战，实现了高精度、高效率和低复杂度的检测。

> **ai_Abstract:** EPANet是一种为水下鱼类检测（UFD）设计的高效路径聚合网络，旨在解决现有方法模型复杂度和效率低下的问题。该网络包含高效路径聚合特征金字塔网络（EPA-FPN）和多尺度多样化分割短路径瓶颈（MS-DDSP瓶颈）两大核心组件。EPA-FPN通过长距离跳跃连接和跨层融合提高特征整合效率和语义空间互补性；MS-DDSP瓶颈则通过细粒度特征分割和多样化卷积操作增强局部特征表示能力。实验证明，EPANet在检测精度和推理速度上超越了现有最先进方法，同时保持了较低的模型复杂度。

> **摘要翻译:** 水下鱼类检测（UFD）在计算机视觉领域仍然是一项具有挑战性的任务，原因在于目标分辨率低、背景干扰显著以及目标与周围环境之间视觉相似度高。现有方法主要侧重于局部特征增强或结合复杂的注意力机制来突出小目标，但这往往以增加模型复杂性和降低效率为代价。为了解决这些局限性，我们提出了一种高效路径聚合网络（EPANet），它利用互补特征整合来实现准确且轻量级的水下鱼类检测。EPANet由两个关键组件组成：高效路径聚合特征金字塔网络（EPA-FPN）和多尺度多样化分割短路径瓶颈（MS-DDSP瓶颈）。EPA-FPN引入了跨不同尺度的长距离跳跃连接，以改善语义空间互补性，同时采用跨层融合路径来提高特征整合效率。MS-DDSP瓶颈通过引入更细粒度的特征分割和多样化的卷积操作来扩展传统瓶颈结构，从而增加局部特征多样性和表示能力。在基准UFD数据集上进行的大量实验表明，EPANet在检测精度和推理速度方面优于现有最先进的方法，同时保持了相当甚至更低的参数复杂度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [58] [AttnMod: Attention-Based New Art Styles](https://arxiv.org/abs/2409.10028)
> *AttnMod：基于注意力的新艺术风格*

*Shih-Chieh Su* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** AttnMod, 扩散模型, 交叉注意力, 艺术风格生成, 免训练

**Comment:** 

> **TL;DR:** AttnMod是一种免训练技术，通过调节预训练扩散模型中的交叉注意力，生成新颖、无法通过提示词生成的艺术风格。

**AI_Comments:** AttnMod的创新之处在于其免训练特性和对交叉注意力的巧妙利用，使得扩散模型能够生成更具创造性和“非提示词化”的艺术风格。这为文本到图像生成领域开辟了新的可能性，尤其是在风格迁移和艺术创作方面。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到图像生成模型难以生成新颖、无法通过提示词直接描述的艺术风格，且无法模拟人类艺术家对图像的重新诠释（如强调特征、分散颜色、扭曲轮廓、具象化未见元素）。

**Method:** AttnMod通过在去噪过程中改变文本提示词通过注意力机制对图像的调节方式，模拟人类艺术家的意图。它是一种免训练技术，通过调节预训练扩散模型中的交叉注意力来实现。

**Result:** AttnMod实现了多样化的风格转换，无需改变提示词或重新训练模型，并扩展了文本到图像生成的表达能力。它能生成新颖、无法通过提示词直接生成的艺术风格。

**Conclusion:** AttnMod通过调节交叉注意力，有效扩展了预训练扩散模型的艺术风格生成能力，使其能够创造出超越传统提示词限制的新颖风格。

> **ai_Abstract:** AttnMod是一种无需训练的图像生成技术，通过调整预训练扩散模型中的交叉注意力机制，模拟人类艺术家的图像再创作过程，从而生成多样化且无法直接通过文本提示词描述的新颖艺术风格。该方法在不修改提示词或模型的情况下，显著提升了文本到图像生成的表现力。

> **摘要翻译:** 我们介绍AttnMod，一种免训练的技术，它通过调节预训练扩散模型中的交叉注意力来生成新颖的、无法通过提示词生成的艺术风格。该方法的灵感来源于人类艺术家如何重新诠释生成的图像，例如强调某些特征、分散颜色、扭曲轮廓或具象化未见的元素。AttnMod通过在去噪过程中改变文本提示词通过注意力机制对图像的调节方式来模拟这种意图。这些有针对性的调节使得多样化的风格转换成为可能，而无需改变提示词或重新训练模型，并且它们扩展了文本到图像生成的表达能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [68] [FakeIDet: Exploring Patches for Privacy-Preserving Fake ID Detection](https://arxiv.org/abs/2504.07761)
> *FakeIDet：探索用于隐私保护的假身份证件检测的补丁方法*

*Javier Muñoz-Haro, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez* | **Category: cs.CV, cs.AI, cs.CR** | **Updated: 2025-08-01**

**Keywords:** 假ID检测, 隐私保护, 基于补丁, 数据集, FakeIDet

**Comment:** 

> **TL;DR:** 提出FakeIDet，一种基于补丁的隐私保护假ID检测方法，并发布首个公开的真实/假ID补丁数据集，解决了数据稀缺问题。

**AI_Comments:** 本文的主要创新点在于提出了一种新颖的基于补丁的假ID检测方法FakeIDet，它巧妙地在保护用户隐私的同时实现了检测性能。更重要的是，通过发布首个公开可用的真实和虚假ID补丁数据集FakeIDet-db，极大地解决了该领域长期面临的数据稀缺问题，为后续研究提供了基础性支持，具有重要的实践意义和推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 验证身份文件（ID）的真实性是许多实际应用的关键挑战，但由于隐私原因，缺乏公开可用的真实ID数据进行研究，这阻碍了基于机器学习的假ID检测技术的发展。

**Method:** 本文引入了一种新的基于补丁的方法，提出了FakeIDet，一种针对隐私感知假ID检测的补丁级方法。实验探索了两种ID匿名化级别（完全匿名化和伪匿名化）和不同的补丁大小配置。采用视觉Transformer和基础模型作为骨干网络。此外，还发布了第一个公开可用的包含48,400个真实和虚假ID补丁的数据库FakeIDet-db。

**Result:** 在未见数据库（DLC-2021）上，FakeIDet在补丁级别和整个ID级别分别达到了13.91%和0%的等错误率（EERs），显示出对其他数据库的良好泛化能力。

**Conclusion:** 本文引入了基于补丁的方法和FakeIDet，有效解决了假ID检测领域的数据稀缺和隐私问题，并通过发布首个公开可用的真实/假ID补丁数据库FakeIDet-db，为该领域的研究提供了关键资源。

> **ai_Abstract:** 本研究针对假身份证件检测领域中真实数据稀缺和隐私保护的挑战，提出了一种名为FakeIDet的新型基于补丁的方法。该方法通过在隐私和性能之间进行权衡，利用补丁级处理来保护敏感信息。实验探索了不同的匿名化级别和补丁大小配置，并展示了在未见数据集上的良好泛化能力。此外，本文还发布了首个公开可用的包含真实和虚假ID补丁的数据集FakeIDet-db，为该领域的研究提供了宝贵的资源。

> **摘要翻译:** 验证身份文件（ID）的真实性已成为数字银行、加密货币交易所、租赁等实际应用中的关键挑战。本研究聚焦于假ID检测，涵盖了该领域的一些局限性。特别是，没有公开可用的真实ID数据用于该领域的适当研究，并且大多数已发表的研究依赖于专有的内部数据库，出于隐私原因无法获取。为了推进解决真实数据稀缺这一关键挑战，该挑战使得基于机器学习的假ID检测技术难以发展，我们引入了一种新的基于补丁的方法，该方法在隐私和性能之间进行权衡，并提出了一种新颖的、面向隐私的假ID检测补丁级方法：FakeIDet。在我们的实验中，我们探索了：i）ID的两种匿名化级别（即完全匿名化和伪匿名化），以及ii）不同的补丁大小配置，改变补丁图像中可见的敏感数据量。考虑了视觉Transformer和基础模型等最先进的方法作为骨干网络。我们的结果显示，在未见数据库（DLC-2021）上，我们提出的假ID检测方法在补丁级别和整个ID级别分别达到了13.91%和0%的等错误率（EERs），显示出对其他数据库的良好泛化能力。除了引入的基于路径的方法和基于它的新FakeIDet方法外，我们文章的另一个关键贡献是发布了第一个公开可用的数据库，其中包含来自真实和虚假ID的48,400个补丁，命名为FakeIDet-db，以及实验框架。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [71] [SkillFormer: Unified Multi-View Video Understanding for Proficiency Estimation](https://arxiv.org/abs/2505.08665)
> *SkillFormer：统一多视角视频理解用于熟练度估计*

*Edoardo Bianchi, Antonio Liotta* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 技能评估, 多视角视频理解, 熟练度估计, SkillFormer, 深度学习

**Comment:** 

> **TL;DR:** SkillFormer是一种参数高效的架构，用于从自我中心和外部中心视频中进行统一的多视角熟练度估计，在EgoExo4D数据集上实现了最先进的准确性，同时显著降低了计算成本。

**AI_Comments:** 该论文的创新点在于提出了SkillFormer架构，其通过CrossViewFusion模块有效地整合了多视角视频信息，并结合低秩适应技术显著提升了计算效率和参数效率。其在EgoExo4D数据集上取得的最先进结果，证明了其在复杂技能评估领域的潜力和实用价值，特别是在资源受限的环境下。

<details>
  <summary>Details</summary>

**Motivation:** 在体育、康复和训练等领域，评估复杂活动中的人类技能水平是一个具有挑战性的问题。

**Method:** SkillFormer基于TimeSformer骨干网络，引入了CrossViewFusion模块，该模块使用多头交叉注意力、可学习门控和自适应自校准来融合视角特定特征。该方法利用低秩适应（Low-Rank Adaptation）仅微调一小部分参数，显著降低了训练成本。

**Result:** 在EgoExo4D数据集上，SkillFormer在多视角设置下实现了最先进的准确性，与现有基线相比，参数减少了4.5倍，训练周期减少了3.75倍。它在多个结构化任务中表现出色。

**Conclusion:** 多视角整合对于细粒度技能评估具有重要价值，SkillFormer证明了其在熟练度估计方面的有效性和计算效率。

> **ai_Abstract:** SkillFormer是一种新颖的参数高效架构，用于从多视角（自我中心和外部中心）视频中评估人类技能熟练度。它基于TimeSformer并引入了CrossViewFusion模块，通过交叉注意力、门控和自校准融合多视角特征。该模型利用低秩适应技术大幅减少了训练参数和计算成本。在EgoExo4D数据集上的评估表明，SkillFormer在多视角技能评估中达到了最先进的准确性，同时在参数数量和训练周期上显著优于现有基线，突出了多视角整合在细粒度技能评估中的有效性。

> **摘要翻译:** 评估复杂活动中的人类技能水平是一个具有挑战性的问题，在体育、康复和训练等领域都有应用。在这项工作中，我们提出了SkillFormer，一个参数高效的架构，用于从自我中心和外部中心视频中进行统一的多视角熟练度估计。SkillFormer以TimeSformer骨干网络为基础，引入了一个CrossViewFusion模块，该模块使用多头交叉注意力、可学习门控和自适应自校准来融合视角特定特征。我们利用低秩适应（Low-Rank Adaptation）仅微调一小部分参数，显著降低了训练成本。事实上，在EgoExo4D数据集上进行评估时，SkillFormer在多视角设置下实现了最先进的准确性，同时展示了卓越的计算效率，与现有基线相比，参数减少了4.5倍，所需的训练周期减少了3.75倍。它在多个结构化任务中表现出色，证实了多视角整合对于细粒度技能评估的价值。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [74] [Multimodal Referring Segmentation: A Survey](https://arxiv.org/abs/2508.00265)
> *多模态指代分割：一项综述*

*Henghui Ding, Song Tang, Shuting He, Chang Liu, Zuxuan Wu, Yu-Gang Jiang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 多模态指代分割, 图像分割, 视频分割, 3D场景分割, 指代表达

**Comment:** Project Page:
  https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation

> **TL;DR:** 本文对多模态指代分割领域进行了全面综述，涵盖了其背景、方法、架构、数据集、广义指代表达（GREx）、应用和性能比较。

**AI_Comments:** 这篇综述对快速发展的多模态指代分割领域进行了系统性梳理，其价值在于提供了一个全面的知识框架，帮助研究人员理解该领域的最新进展、核心挑战和未来方向。它不仅回顾了现有方法，还讨论了广义指代表达和实际应用，并提供了持续更新的资源链接，具有很高的参考价值和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于多模态指代分割在需要基于用户指令进行精确目标感知的实际应用中扮演着关键角色，并且在过去十年中，由于卷积神经网络、Transformer和大型语言模型的进步，该领域在多模态社区获得了显著关注，本文旨在提供一个全面的综述。

**Method:** 本文首先介绍了多模态指代分割领域的背景，包括问题定义和常用数据集。接着，总结了一个统一的指代分割元架构，并回顾了图像、视频和3D场景这三种主要视觉场景中的代表性方法。此外，还讨论了广义指代表达（GREx）方法以应对现实世界的复杂性，以及相关任务和实际应用。文中还提供了在标准基准上的广泛性能比较。

**Result:** 本综述提供了多模态指代分割领域的全面概述，包括其背景、问题定义、常用数据集、统一的元架构、图像、视频和3D场景的代表性方法、广义指代表达（GREx）方法、相关任务和实际应用，以及在标准基准上的广泛性能比较。

**Conclusion:** 作为一项全面综述，本文系统性地总结了多模态指代分割领域的当前研究现状、核心方法、挑战和实际应用，为该领域的进一步研究提供了坚实的基础和参考。

> **ai_Abstract:** 本文对多模态指代分割进行了全面综述。该任务根据文本或音频指代表达式在视觉场景中分割目标对象，对实际应用至关重要。综述涵盖了该领域的背景、问题定义、常用数据集、统一的元架构，并回顾了图像、视频和3D场景中的代表性方法。此外，还讨论了广义指代表达（GREx）方法、相关任务和实际应用，并提供了标准基准上的性能比较。

> **摘要翻译:** 多模态指代分割旨在根据文本或音频格式的指代表达式，在图像、视频和3D场景等视觉场景中分割目标对象。这项任务在需要基于用户指令进行精确目标感知的实际应用中扮演着关键角色。在过去十年中，在卷积神经网络、Transformer和大型语言模型等技术进步的推动下，该领域在多模态社区获得了显著关注，这些技术都大大提高了多模态感知能力。本文对多模态指代分割进行了全面综述。我们首先介绍该领域的背景，包括问题定义和常用数据集。接下来，我们总结了一个统一的指代分割元架构，并回顾了图像、视频和3D场景三种主要视觉场景中的代表性方法。我们进一步讨论了广义指代表达（GREx）方法，以应对现实世界的复杂性，并探讨了相关任务和实际应用。文中还提供了在标准基准上的广泛性能比较。我们持续在https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation跟踪相关工作。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [81] [Video Color Grading via Look-Up Table Generation](https://arxiv.org/abs/2508.00548)
> *通过查找表生成进行视频色彩分级*

*Seunghyun Shin, Dongmin Shin, Jisu Shin, Hae-Gon Jeon, Joon-Young Lee* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 视频色彩分级, 查找表, 扩散模型, 颜色属性对齐, 用户偏好

**Comment:** ICCV2025

> **TL;DR:** 本文提出了一种基于参考的视频色彩分级框架，通过扩散模型生成查找表（LUT）来对齐参考场景和输入视频的颜色属性，并允许用户通过文本提示调整低级特征，实验证明了其有效性。

**AI_Comments:** 本文的创新点在于将扩散模型应用于查找表（LUT）的生成，以实现基于参考的视频色彩分级，这提供了一种新颖且高效的色彩调整方法。通过生成LUT，模型能够保持视频的结构细节并实现快速推理，这是实际应用中的重要优势。此外，结合文本提示允许用户自定义低级特征，显著提升了方法的灵活性和用户体验。这项工作有望降低视频色彩分级的技术门槛，使其更易于非专业人士使用，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 视频色彩分级是一个复杂的过程，需要专业的编辑技能，目前主要由专业的调色师完成。本文旨在解决这一挑战，使视频色彩分级更加便捷和高效。

**Method:** 本文提出了一种基于参考的视频色彩分级框架。核心思想是通过扩散模型显式生成查找表（LUT），用于参考场景和输入视频之间的颜色属性对齐。训练目标是使参考场景的高级特征（如外观、情绪、情感）与输入视频相似。该基于LUT的方法可以在不损失视频帧结构细节的情况下进行色彩分级，并实现快速推理。此外，还构建了一个管道，通过文本提示整合用户偏好，用于对比度和亮度等低级特征的增强。

**Result:** 实验结果，包括广泛的用户研究，证明了该方法在视频色彩分级方面的有效性。

**Conclusion:** 本文提出的基于查找表生成的视频色彩分级框架，能够有效地实现视频的艺术性色彩调整，同时保持结构细节并实现快速推理，并通过用户偏好增强了灵活性。

> **ai_Abstract:** 本文提出了一种创新的基于参考的视频色彩分级框架，旨在简化复杂的色彩调整过程。该方法利用扩散模型生成查找表（LUT），以实现参考视频与输入视频之间的颜色属性对齐，同时确保高级特征（如外观、情绪）的一致性。该LUT方法既能保留视频的结构细节，又能实现快速推理。此外，该框架还通过文本提示支持用户对低级特征（如对比度、亮度）的个性化调整。广泛的用户研究和实验结果验证了该方法在视频色彩分级中的有效性。

> **摘要翻译:** 与色彩校正和色彩转移不同，色彩分级涉及为视频中的艺术或叙事目的调整颜色，用于建立特定的外观或情绪。然而，由于过程的复杂性和对专业编辑技能的需求，视频色彩分级仍然主要是专业调色师的领域。在本文中，我们提出了一种基于参考的视频色彩分级框架。我们的核心思想是通过扩散模型显式生成一个查找表（LUT），用于参考场景和输入视频之间的颜色属性对齐。作为训练目标，我们强制要求参考场景的高级特征（如外观、情绪和情感）应与输入视频相似。我们基于LUT的方法允许在整个视频帧中进行色彩分级，而不会损失结构细节，并实现快速推理。我们进一步构建了一个管道，通过文本提示整合用户偏好，用于对比度和亮度等低级特征的增强。实验结果，包括广泛的用户研究，证明了我们方法在视频色彩分级方面的有效性。代码已在https://github.com/seunghyuns98/VideoColorGrading 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [95] [Spatial-Temporal-Spectral Unified Modeling for Remote Sensing Dense Prediction](https://arxiv.org/abs/2505.12280)
> *遥感密集预测的时空光谱统一建模*

*Sijie Zhao, Feng Liu, Enzhuo Zhang, Yiqing Guo, Pengfeng Xiao, Lei Bai, Xueliang Zhang, Hao Chen* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 遥感, 密集预测, 统一建模, 时空光谱, 深度学习

**Comment:** 16 pages, 6 figures, Code
  link:https://github.com/walking-shadow/Official_TSSUN

> **TL;DR:** STSUN提出了一种统一网络，通过利用元数据和可训练的任务/类别嵌入，解决了遥感深度学习模型在处理异构时空光谱数据、统一不同密集预测任务和灵活处理语义类别方面的局限性。

**AI_Comments:** STSUN的创新之处在于其对遥感数据处理的统一建模方法。通过引入元数据和可训练嵌入，它有效解决了现有模型在处理异构数据、集成多任务和灵活应对语义类别变化方面的刚性问题。这种“一次训练，多场景适应”的范式显著提高了模型的实用性和效率，对于推动遥感深度学习的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的遥感深度学习架构僵化，无法适应真实世界数据中固有的异构空间、时间和光谱维度。此外，这些模型忽略了语义分割、二元变化检测和语义变化检测之间的内在关联，并且受限于预定义的输出语义类别，任何类别更改都需要昂贵的再训练。

**Method:** 本文引入了时空光谱统一网络（STSUN），通过利用输入和输出数据的元数据进行统一表示，使其能够适应任意空间大小、时间长度和光谱波段的数据。STSUN通过以可训练的任务嵌入为条件，在单一架构内统一了不同的密集预测任务。通过整合可训练的类别嵌入作为元数据，STSUN还促进了跨多个语义类别的灵活预测。

**Result:** 在多个具有不同时空光谱配置的数据集和场景中进行的大量实验表明，单个STSUN模型能够有效适应异构输入和输出，统一各种密集预测任务和多样化的语义类别预测。所提出的方法持续实现了最先进的性能。

**Conclusion:** STSUN模型能够有效适应异构输入和输出，统一各种密集预测任务和多样化的语义类别预测，并在复杂遥感应用中展现出鲁棒性和泛化能力。

> **ai_Abstract:** 本文提出了一种名为时空光谱统一网络（STSUN）的新型深度学习架构，旨在解决遥感领域中异构数据处理、任务统一和类别灵活预测的挑战。STSUN通过利用输入输出数据的元数据以及可训练的任务和类别嵌入，实现了对任意时空光谱维度数据、多种密集预测任务和不同语义类别的统一建模和预测。实验证明，STSUN在适应性、泛化能力和性能上均达到或超越了现有技术水平，为复杂遥感应用提供了鲁棒的解决方案。

> **摘要翻译:** 多源遥感数据的普及推动了深度学习在密集预测领域的发展，但数据和任务统一方面仍存在重大挑战。当前用于遥感的深度学习架构从根本上是僵化的。它们专为固定的输入-输出配置而设计，限制了它们对真实世界数据中固有的异构空间、时间以及光谱维度的适应性。此外，这些模型忽略了语义分割、二元变化检测和语义变化检测之间的内在关联，因此需要开发不同的模型或针对特定任务的解码器。这种范式也受限于预定义的一组输出语义类别，其中任何对类别的更改都需要昂贵的再训练。为了克服这些限制，我们引入了时空光谱统一网络（STSUN）用于统一建模。STSUN通过利用其元数据进行统一表示，可以适应具有任意空间大小、时间长度和光谱波段的输入和输出数据。此外，STSUN通过以可训练的任务嵌入为条件，在单一架构内统一了不同的密集预测任务。同样，STSUN通过将可训练的类别嵌入作为元数据集成，促进了跨多组语义类别的灵活预测。在多个具有不同时空光谱配置和多种场景的数据集上进行的大量实验表明，单个STSUN模型能够有效适应异构输入和输出，统一各种密集预测任务和多样化的语义类别预测。所提出的方法持续实现了最先进的性能，突出了其在复杂遥感应用中的鲁棒性和泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [104] [Towards Robust Semantic Correspondence: A Benchmark and Insights](https://arxiv.org/abs/2508.00272)
> *迈向鲁棒的语义对应：一个基准与见解*

*Wenyue Chong* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 语义对应, 鲁棒性, 基准数据集, 大规模视觉模型, 数据增强

**Comment:** 

> **TL;DR:** 本文建立了一个新的基准数据集，用于评估语义对应在恶劣条件下的鲁棒性，并提供了关于现有方法、大规模视觉模型以及鲁棒性增强策略的见解。

**AI_Comments:** 本文的创新点在于构建了一个专门用于评估语义对应在恶劣条件下的鲁棒性基准数据集，并揭示了现有方法、大规模模型特性以及数据增强策略在鲁棒性方面的局限和有效性。这对于推动语义对应领域向更实用、更鲁棒的方向发展具有重要意义，尤其强调了未来研究应聚焦于任务特定鲁棒性增强设计。

<details>
  <summary>Details</summary>

**Motivation:** 语义对应在受控和高质量条件下取得了显著进展，但在具有挑战性的场景中，其鲁棒性研究较少。为了解决这一不足，本文旨在深入探究语义对应在不利条件下的鲁棒性。

**Method:** 本文建立了一个新颖的基准数据集，用于评估语义对应在恶劣条件下的性能。该数据集包含14种不同的挑战性场景，反映了常见的图像问题，如几何失真、图像模糊、数字伪影和环境遮挡。通过广泛评估，本文提供了关于语义对应方法鲁棒性的关键见解。

**Result:** 1. 所有现有方法在不利条件下性能均出现显著下降；2. 使用大规模视觉模型可以增强整体鲁棒性，但对其进行微调会导致相对鲁棒性下降；3. DINO模型在相对鲁棒性方面优于Stable Diffusion，且它们的融合可以实现更好的绝对鲁棒性；4. 常见的鲁棒性增强策略（如通用数据增强）是无效的，这强调了任务特定设计的必要性。这些结果在本文的数据集和真实世界基准测试中均保持一致。

**Conclusion:** 在恶劣条件下，现有语义对应方法面临显著的鲁棒性挑战。虽然大规模视觉模型能提升整体鲁棒性，但需要针对性设计而非通用数据增强来有效提升其在挑战性场景下的表现。

> **ai_Abstract:** 本文针对语义对应在挑战性场景下鲁棒性研究不足的问题，提出了一个包含14种恶劣条件的新型基准数据集。通过该基准的广泛评估，研究发现现有方法在不利条件下性能均显著下降；大规模视觉模型虽能提升整体鲁棒性，但微调会降低相对鲁棒性；DINO模型相对鲁棒性优于Stable Diffusion，两者融合可实现更优的绝对鲁棒性。此外，研究强调通用数据增强对鲁棒性提升无效，亟需任务特定的设计。

> **摘要翻译:** 语义对应旨在识别不同图像之间语义上有意义的关系，是计算机视觉中的一个基本挑战。它构成了3D重建、目标跟踪和图像编辑等众多任务的基础。随着大规模视觉模型的进步，语义对应在受控和高质量条件下取得了显著的性能。然而，在挑战性场景中语义对应的鲁棒性研究较少。在这项工作中，我们建立了一个新颖的基准，用于评估语义对应在不利条件下的性能。该基准数据集包含14种不同的挑战性场景，反映了常见的成像问题，包括几何失真、图像模糊、数字伪影和环境遮挡。通过广泛评估，我们提供了关于语义对应方法鲁棒性的几个关键见解：（1）所有现有方法在不利条件下性能均出现显著下降；（2）使用大规模视觉模型可以增强整体鲁棒性，但对这些模型进行微调会导致相对鲁棒性下降；（3）DINO模型在相对鲁棒性方面优于Stable Diffusion，且它们的融合可以实现更好的绝对鲁棒性；此外，我们评估了语义对应常见的鲁棒性增强策略，发现通用数据增强是无效的，这凸显了任务特定设计的必要性。这些结果在我们的数据集和真实世界基准测试中均保持一致。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [111] [Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images](https://arxiv.org/abs/2508.00549)
> *你的另一个左边！视觉-语言模型未能识别医学图像中的相对位置*

*Daniel Wolf, Heiko Hillenhagen, Billurvan Taskin, Alex Bäuerle, Meinrad Beer, Michael Götz, Timo Ropinski* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 视觉-语言模型, 医学图像, 相对位置, 临床决策, MIRP数据集

**Comment:** Accepted at the International Conference on Medical Image Computing
  and Computer Assisted Intervention (MICCAI) 2025

> **TL;DR:** 视觉-语言模型（VLMs）在医学图像中识别相对位置的能力存在严重缺陷，即使使用视觉提示也效果不佳，表明它们更依赖先验知识而非图像内容。为此，本文引入了MIRP基准数据集。

**AI_Comments:** 本文揭示了当前视觉-语言模型在医学成像这一关键领域的一个重大局限性，即它们在识别相对位置时，更依赖于先验知识而非图像的视觉内容，这一发现具有重要意义。MIRP数据集的引入为未来的研究提供了宝贵的标准化评估工具，有助于推动该特定能力的提升。这表明VLM需要在医学情境下更好地整合视觉推理能力。

<details>
  <summary>Details</summary>

**Motivation:** 临床决策严重依赖于对解剖结构和异常相对位置的理解。视觉-语言模型（VLMs）若要在临床实践中应用，准确确定医学图像中的相对位置是基本前提，但此能力尚未得到充分探索。

**Method:** 1. 评估了包括GPT-4o、Llama3.2、Pixtral和JanusPro在内的最先进视觉-语言模型在医学图像相对位置识别任务上的表现。2. 探究了视觉提示（如放置在解剖结构上的字母数字或彩色标记）是否能提升模型性能。3. 引入了名为MIRP（Medical Imaging Relative Positioning）的基准数据集，用于系统评估医学图像中相对位置识别能力。

**Result:** 1. 所有评估的视觉-语言模型在识别医学图像中的相对位置这一基本任务上均失败。2. 视觉提示虽能提供适度改进，但与在自然图像上的表现相比，医学图像上的结果仍显著较低。3. 评估表明，在医学成像中，视觉-语言模型在回答相对位置问题时，更多地依赖先前的解剖学知识而非实际的图像内容，导致常见错误。

**Conclusion:** 当前最先进的视觉-语言模型未能准确识别医学图像中的相对位置，它们在处理此类问题时更多依赖于先验解剖学知识而非图像内容。为此，本文引入了MIRP基准数据集，以促进该领域未来的研究。

> **ai_Abstract:** 本文探讨了当前最先进的视觉-语言模型（VLMs）在识别医学图像中相对位置方面的能力，此能力对临床应用至关重要。研究发现，包括GPT-4o和Llama3.2在内的现有VLM在该任务上均表现不佳。尽管视觉提示能带来轻微改善，但模型似乎更依赖于先前的解剖学知识而非实际图像内容进行判断。为推动该领域研究，作者引入了医学图像相对定位（MIRP）基准数据集。

> **摘要翻译:** 临床决策严重依赖于对解剖结构和异常的相对位置的理解。因此，对于视觉-语言模型（VLMs）在临床实践中应用而言，准确确定医学图像上相对位置的能力是一个基本先决条件。尽管其重要性，但这项能力仍未得到充分探索。为了解决这一差距，我们评估了最先进的VLM，如GPT-4o、Llama3.2、Pixtral和JanusPro的能力，并发现所有模型在这一基本任务上都失败了。受计算机视觉中成功方法的启发，我们研究了视觉提示，例如放置在解剖结构上的字母数字或彩色标记，是否可以提高性能。虽然这些标记提供了适度的改进，但与在自然图像上观察到的结果相比，在医学图像上的结果仍然显著较低。我们的评估表明，在医学成像中，VLM在回答相对位置问题时更多地依赖先前的解剖学知识，而不是实际的图像内容，这常常导致错误的结论。为了促进该领域的进一步研究，我们引入了MIRP（医学图像相对定位）基准数据集，旨在系统地评估识别医学图像中相对位置的能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [121] [From Press to Pixels: Evolving Urdu Text Recognition](https://arxiv.org/abs/2505.13943)
> *从纸媒到像素：乌尔都语文本识别的演进*

*Samee Arif, Sualeha Farid* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 乌尔都语OCR, LLM, 纳斯塔利克字体, 超分辨率, 文本识别

**Comment:** 

> **TL;DR:** 本文提出一个端到端乌尔都语报纸OCR系统，通过多模块处理复杂布局、低分辨率和手写体变异，引入新数据集，并发现微调后的LLM（如Gemini-2.5-Pro）在乌尔都语OCR中表现出色且适应性强。

**AI_Comments:** 这篇论文通过引入一个全面的端到端管道和专门的数据集，解决了乌尔都语OCR中存在的独特挑战，特别是复杂布局和纳斯塔利克字体。其创新之处在于结合了先进的图像处理技术（如YOLOv11x和SwinIR）与现代LLM，并证明了LLM在特定语言OCR任务中的强大潜力和适应性，尤其是在数据量有限的情况下通过微调实现性能提升。这对于资源稀缺语言的OCR研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决乌尔都语报纸OCR面临的挑战，包括复杂的版面布局、低分辨率扫描件以及纳斯塔利克书写风格的多样性。

**Method:** 引入一个端到端的OCR管道，包含四个模块：文章分割、图像超分辨率、列分割和文本识别。使用YOLOv11x进行分割，SwinIR模型进行超分辨率。引入乌尔都语报纸基准（UNB）数据集，并与OpenITI语料库一同用于比较传统的CNN+RNN模型与现代LLM。还对LLM输出进行了错误分析。

**Result:** YOLOv11x在文章分割上达到0.963的精度，列分割达到0.970的精度。基于SwinIR的超分辨率模型将LLM文本识别准确率提高了25-70%。Gemini-2.5-Pro取得了最佳性能，词错误率（WER）为0.133。仅用500个样本进行微调，WER可提高6.13%。

**Conclusion:** 本文展示了LLM在乌尔都语OCR任务中的适应性，即使是少量样本的微调也能显著提升性能，表明LLM是处理乌尔都语复杂性的有效工具。

> **ai_Abstract:** 本文提出了一个用于乌尔都语报纸OCR的端到端系统，旨在克服复杂布局、低分辨率和纳斯塔利克字体变异的挑战。该系统包含文章/列分割、图像超分辨率和文本识别模块，并引入了新的乌尔都语报纸基准（UNB）数据集。研究发现，通过YOLOv11x和SwinIR提升分割与图像质量后，现代LLM（特别是Gemini-2.5-Pro）在乌尔都语OCR中表现出色，且少量样本的微调即可显著提高其性能，验证了LLM在该领域的强大适应性。

> **摘要翻译:** 本文介绍了一个针对乌尔都语报纸光学字符识别（OCR）的端到端管道，解决了复杂多列布局、低分辨率扫描以及纳斯塔利克书写风格多变性带来的挑战。我们的系统包含四个模块：（1）文章分割，（2）图像超分辨率，（3）列分割，和（4）文本识别。我们对YOLOv11x进行了微调以进行分割，在文章分割上达到了0.963的精度，在列分割上达到了0.970的精度。一个基于SwinIR的超分辨率模型将大型语言模型（LLM）的文本识别准确率提升了25-70%。我们还引入了乌尔都语报纸基准（UNB），这是一个用于乌尔都语OCR的手动标注数据集。使用UNB和OpenITI语料库，我们比较了传统的基于CNN+RNN的OCR模型与现代LLM。Gemini-2.5-Pro以0.133的词错误率（WER）取得了最佳性能。我们通过插入、删除和替换错误分解以及字符级混淆分析进一步分析了LLM的输出。最后，我们展示了仅用500个样本进行微调就能使WER提高6.13%，突出了LLM在乌尔都语OCR中的适应性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [128] [Privacy-Preserving Driver Drowsiness Detection with Spatial Self-Attention and Federated Learning](https://arxiv.org/abs/2508.00287)
> *基于空间自注意力与联邦学习的隐私保护驾驶员疲劳检测*

*Tran Viet Khoa, Do Hai Son, Mohammad Abu Alsheikh, Yibeltal F Alem, Dinh Thai Hoang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 驾驶员疲劳检测, 隐私保护, 联邦学习, 空间自注意力, 智能交通系统

**Comment:** 

> **TL;DR:** 本文提出了一种结合空间自注意力机制和联邦学习的隐私保护驾驶员疲劳检测框架，在去中心化数据场景下实现了高精度检测。

**AI_Comments:** 该论文的创新点在于结合了空间自注意力机制和联邦学习，以在保护隐私的同时处理分散且异构的驾驶员面部数据。梯度相似性比较（GSC）机制的引入是联邦学习中选择相关模型的有效方法，有助于提高全局模型的鲁棒性和准确性。此外，定制的数据处理工具也提升了实际应用的可行性。这对于智能交通系统中的道路安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 驾驶员疲劳是导致交通事故的主要原因之一，准确检测疲劳是一项挑战性任务，尤其是在面部数据分散且高度多样化的真实世界环境中。

**Method:** 本文提出了一种新的疲劳检测框架，旨在有效处理异构和去中心化数据。该方法将新的空间自注意力（SSA）机制与长短期记忆（LSTM）网络集成，以更好地提取关键面部特征并提高检测性能。为了支持联邦学习，采用了梯度相似性比较（GSC）机制，在聚合之前从不同操作员中选择最相关的训练模型。此外，开发了一个定制工具，自动处理视频数据，包括提取帧、检测和裁剪面部，并应用旋转、翻转、亮度调整和缩放等数据增强技术。

**Result:** 实验结果表明，该框架在联邦学习设置下实现了89.9%的检测准确率，在各种部署场景下均优于现有方法。

**Conclusion:** 结果表明，该方法在处理真实世界数据变异性方面是有效的，并突显了其在智能交通系统中部署的潜力，通过早期可靠的疲劳检测来提高道路安全。

> **ai_Abstract:** 本文提出了一种新颖的隐私保护驾驶员疲劳检测框架，旨在解决真实世界中分散且多样化面部数据的检测挑战。该框架结合了空间自注意力（SSA）机制与长短期记忆（LSTM）网络，以增强面部特征提取和检测性能。为支持联邦学习，引入了梯度相似性比较（GSC）机制，以优化模型聚合，同时保护用户隐私。此外，还开发了自动化视频数据处理工具。实验结果显示，该框架在联邦学习环境下达到了89.9%的检测准确率，并优于现有方法，证明了其处理真实世界数据变异性的有效性和在智能交通系统中的应用潜力。

> **摘要翻译:** 驾驶员疲劳是道路事故的主要原因之一，被认为是导致交通相关死亡事故的主要因素。然而，准确检测疲劳仍然是一项具有挑战性的任务，尤其是在真实世界环境中，来自不同个体的面部数据是去中心化且高度多样化的。在本文中，我们提出了一种新的疲劳检测框架，旨在有效处理异构和去中心化数据。我们的方法开发了一种新的空间自注意力（SSA）机制，并将其与长短期记忆（LSTM）网络集成，以更好地提取关键面部特征并提高检测性能。为了支持联邦学习，我们采用了一种梯度相似性比较（GSC）方法，在聚合之前从不同操作员中选择最相关的训练模型。这在保护用户隐私的同时提高了全局模型的准确性和鲁棒性。我们还开发了一个定制工具，通过提取帧、检测和裁剪面部，并应用旋转、翻转、亮度调整和缩放等数据增强技术，自动处理视频数据。实验结果表明，我们的框架在联邦学习设置下实现了89.9%的检测准确率，在各种部署场景下均优于现有方法。结果证明了我们方法在处理真实世界数据可变性方面的有效性，并强调了其在智能交通系统中部署的潜力，通过早期可靠的疲劳检测来提高道路安全性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [139] [DBLP: Noise Bridge Consistency Distillation For Efficient And Reliable Adversarial Purification](https://arxiv.org/abs/2508.00552)
> *DBLP：用于高效可靠对抗性净化的噪声桥一致性蒸馏*

*Chihan Huang, Belal Alsinglawi, Islam Al-qudah* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 对抗性净化, 扩散模型, 噪声桥蒸馏, 效率, 鲁棒性

**Comment:** 

> **TL;DR:** DBLP提出了一种高效的扩散模型，通过噪声桥蒸馏和自适应语义增强，实现了快速且高质量的对抗性净化。

**AI_Comments:** 这篇论文通过引入噪声桥蒸馏和自适应语义增强，有效地解决了现有扩散模型在对抗性净化中效率低下的问题，显著提升了推理速度，使其更接近实际应用，具有重要的创新性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNNs）易受对抗性扰动攻击，而现有基于扩散的对抗性净化方法需要密集的迭代去噪，这严重限制了它们的实际部署。

**Method:** 本文提出了扩散桥蒸馏净化（DBLP）框架，其核心是“噪声桥蒸馏”目标，在潜在一致性模型（LCM）中构建对抗性噪声分布与干净数据分布之间的对齐。此外，引入了“自适应语义增强”，融合多尺度金字塔边缘图作为条件输入以指导净化过程。

**Result:** DBLP在多个数据集上实现了最先进的（SOTA）鲁棒准确性、卓越的图像质量和约0.2秒的推理时间。

**Conclusion:** DBLP标志着向实时对抗性净化迈出了重要一步。

> **ai_Abstract:** 本文提出了DBLP（扩散桥蒸馏净化），一个用于对抗性净化的新型高效扩散框架。DBLP通过引入噪声桥蒸馏目标，在潜在一致性模型中实现了对抗性噪声分布与干净数据分布的对齐。同时，结合自适应语义增强，利用多尺度金字塔边缘图指导净化过程，以提升语义保真度。实验结果表明，DBLP在鲁棒准确性、图像质量和推理速度方面均达到最先进水平，尤其0.2秒的推理时间使其向实时对抗性净化迈出重要一步。

> **摘要翻译:** 深度神经网络（DNN）的最新进展在广泛的任务中取得了显著成功。然而，它们对对抗性扰动的敏感性仍然是一个关键的漏洞。现有的基于扩散的对抗性净化方法通常需要密集的迭代去噪，严重限制了它们的实际部署。在本文中，我们提出了一种新颖高效的基于扩散的对抗性净化框架——扩散桥蒸馏净化（DBLP）。我们方法的核心是一个新的目标，即噪声桥蒸馏，它在潜在一致性模型（LCM）中构建了对抗性噪声分布与干净数据分布之间的原则性对齐。为了进一步增强语义保真度，我们引入了自适应语义增强，它融合了多尺度金字塔边缘图作为条件输入，以指导净化过程。在多个数据集上的大量实验表明，DBLP实现了最先进的（SOTA）鲁棒准确性、卓越的图像质量和约0.2秒的推理时间，标志着向实时对抗性净化迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [141] [Lossless Token Merging Even Without Fine-Tuning in Vision Transformers](https://arxiv.org/abs/2505.15160)
> *视觉Transformer中无需微调的无损Token合并*

*Jaeyeon Lee, Dong-Wan Choi* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** Vision Transformers, Token Merging, 计算效率, 无损, 免训练

**Comment:** ECAI 2025

> **TL;DR:** 本文提出了一种名为自适应Token合并（ATM）的新方法，即使无需额外训练，也能在视觉Transformer中实现无损Token合并，同时保持或超越现有方法的性能。

**AI_Comments:** 该论文的创新点在于提出了“无损Token合并”的概念，并设计了自适应Token合并（ATM）方法，在无需额外微调的情况下显著降低了Vision Transformers的计算成本，同时保持了原始精度。这对于ViTs在资源受限环境下的部署具有重要意义，克服了传统Token压缩方法信息损失大且需要大量训练的缺点。

<details>
  <summary>Details</summary>

**Motivation:** Vision Transformers（ViTs）虽然已成为计算机视觉的标准架构，但其庞大的模型尺寸导致显著的计算开销。现有的Token压缩技术常伴随严重的信息损失，且需要大量额外训练才能达到实用性能。

**Method:** 本文提出了自适应Token合并（ATM）方法，通过仔细调整层特定的相似性阈值，在不同层和批次间自适应地减少Token数量，从而防止不相似Token的合并。此外，ATM引入了一种新颖的Token匹配技术，不仅考虑相似性，还特别针对最终层考虑合并大小，以最小化每次合并操作导致的信息损失。

**Result:** 实验证明，ATM不仅优于所有现有的免训练方法，甚至在无需额外训练的情况下，也超越了大多数需要大量训练的方法。值得注意的是，免训练的ATM在DeiT-T和DeiT-S模型上实现了超过30%的FLOPs减少，且没有降低其原始精度。

**Conclusion:** 本文提出的自适应Token合并（ATM）方法，在无需额外训练的情况下，成功实现了视觉Transformer中的无损Token合并，并在计算效率和性能之间取得了卓越的平衡。

> **ai_Abstract:** 本文提出了一种名为自适应Token合并（ATM）的新方法，旨在解决视觉Transformer（ViTs）计算开销大的问题。与现有Token压缩方法不同，ATM通过自适应调整层级相似性阈值和引入考虑合并大小的Token匹配技术，实现了无损Token合并，无需额外微调即可保持或超越现有性能。实验证明，ATM在多种预训练模型上，无需训练即可显著减少FLOPs（如DeiT-T和DeiT-S模型上超过30%的FLOPs减少且无精度下降），并优于现有训练和免训练方法。

> **摘要翻译:** 尽管视觉Transformer（ViTs）已成为计算机视觉的标准架构，但其庞大的尺寸导致显著的计算开销。Token压缩技术为解决此问题引起了广泛关注，但它们通常会遭受严重的信息损失，需要大量的额外训练才能达到实用性能。在本文中，我们提出了一种名为自适应Token合并（ATM）的新方法，它确保了无损Token合并，消除了微调的需求，同时保持了有竞争力的性能。ATM通过仔细调整层特定的相似性阈值，在不同层和批次间自适应地减少Token数量，从而防止不希望的、层间相似度较低的Token合并。此外，ATM引入了一种新颖的Token匹配技术，该技术不仅考虑相似性，还考虑合并大小，特别是对于最终层，以最小化每次合并操作所带来的信息损失。我们在广泛的预训练模型上经验性地验证了我们的方法，结果表明ATM不仅优于所有现有的免训练方法，甚至在没有额外训练的情况下，也超越了大多数需要大量训练的方法。值得注意的是，免训练的ATM在DeiT-T和DeiT-S模型上实现了超过30%的FLOPs减少，且没有降低其原始精度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [149] [TITAN-Guide: Taming Inference-Time AligNment for Guided Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.00289)
> *TITAN-Guide：驯服推理时间对齐以用于引导文本到视频扩散模型*

*Christian Simon, Masato Ishii, Akio Hayakawa, Zhi Zhong, Shusuke Takahashi, Takashi Shibuya, Yuki Mitsufuji* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 文本到视频, 扩散模型, 引导, 内存效率, 前向梯度下降

**Comment:** Accepted to ICCV 2025

> **TL;DR:** TITAN-Guide提出一种新的训练无关方法，通过优化扩散潜在空间，解决现有引导式文本到视频扩散模型内存大、控制差的问题，显著减少内存并提升性能。

**AI_Comments:** TITAN-Guide的创新点在于其提出的无需反向传播的潜在空间优化方法，特别是采用前向梯度下降，这有效解决了现有训练无关引导框架面临的内存效率和控制质量问题。该方法对于计算密集型任务如文本到视频生成具有重要意义，因为它使得在资源受限的环境下实现高质量的控制成为可能，拓展了扩散模型的实际应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 现有的条件扩散模型需要大量监督微调才能进行控制。训练无关的引导方法虽然可以避免微调，但存在内存需求高或控制效果不佳的问题，这限制了它们在计算密集型任务（如文本到视频扩散模型）中的应用。

**Method:** 论文提出了TITAN-Guide，它通过开发一种高效的方法来优化扩散潜在空间，而无需判别性引导模型的反向传播。具体来说，研究了带有不同方向指令的前向梯度下降，以实现引导扩散任务。

**Result:** 实验证明，TITAN-Guide在潜在优化过程中能有效管理内存，而现有方法则在此方面不足。所提出的方法不仅最大限度地减少了内存需求，而且显著增强了文本到视频（T2V）在各种扩散引导基准上的性能。

**Conclusion:** TITAN-Guide成功解决了引导式文本到视频扩散模型中内存效率和控制质量的挑战，提供了一种更优、更高效的训练无关引导框架，显著提升了文本到视频生成性能。

> **ai_Abstract:** 本文提出了TITAN-Guide，一个用于引导文本到视频扩散模型的训练无关框架，旨在解决现有方法内存消耗大和控制效果不佳的问题。TITAN-Guide通过开发一种高效的、无需反向传播的潜在空间优化方法（特别是前向梯度下降），显著降低了内存需求，并提升了文本到视频生成性能，使其在计算密集型任务中更具实用性。

> **摘要翻译:** 在条件扩散模型的最新发展中，仍然需要大量的监督微调才能对一类任务进行控制。通过现成模型进行无训练引导是一种避免对基础模型进行进一步微调的有利替代方案。然而，现有的无训练引导框架要么内存需求大，要么由于粗略估计而提供次优控制。这些缺点限制了其在需要大量计算的扩散模型（例如文本到视频（T2V）扩散模型）中的适用性。在这项工作中，我们提出了驯服推理时间对齐以用于引导文本到视频扩散模型（简称TITAN-Guide），它克服了内存空间问题，并与同类方法相比，在引导过程中提供了更优的控制。特别是，我们开发了一种无需判别性引导模型反向传播即可优化扩散潜在空间的高效方法。具体来说，我们研究了带有各种方向指令的前向梯度下降，用于引导扩散任务。在我们的实验中，我们证明了我们的方法在潜在优化过程中有效管理内存的有效性，而以前的方法则力有不逮。我们提出的方法不仅最大限度地减少了内存需求，而且显著增强了文本到视频在各种扩散引导基准上的性能。代码、模型和演示可在 https://titanguide.github.io 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [161] [OpenSeg-R: Improving Open-Vocabulary Segmentation via Step-by-Step Visual Reasoning](https://arxiv.org/abs/2505.16974)
> *OpenSeg-R：通过循序渐进的视觉推理改进开放词汇分割*

*Zongyan Han, Jiale Cao, Shuo Chen, Tong Wang, Jorma Laaksonen, Rao Muhammad Anwer* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 开放词汇分割, 视觉推理, 大型多模态模型, 语义分割, 全景分割

**Comment:** 

> **TL;DR:** OpenSeg-R提出了一种基于大型多模态模型（LMMs）的循序渐进视觉推理框架，显著提升了开放词汇分割的精度和可解释性。

**AI_Comments:** OpenSeg-R的创新之处在于首次将显式的、循序渐进的视觉推理引入开放词汇分割领域，这通过利用大型多模态模型生成结构化推理步骤来解决现有方法缺乏可解释性和难以区分相似类别的问题。其重要性在于提升了OVS在复杂开放世界场景下的性能和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有开放词汇分割（OVS）方法通常缺乏显式推理和可解释性，难以在开放世界设置中区分相似类别，因为它们缺乏上下文理解和判别性视觉线索。

**Method:** 提出OpenSeg-R框架，该框架利用大型多模态模型（LMMs）在分割前执行分层视觉推理。具体地，它为每张图像生成通用和图像特定的推理，形成解释对象视觉原因的粗到细结构化三元组。基于这些推理步骤，可以构建详细的描述提示，并将其输入给分割器以生成更准确的分割掩码。

**Result:** OpenSeg-R在五个基准数据集上的开放词汇语义分割方面显著优于现有最先进的方法。此外，它在开放词汇全景分割的所有指标上都取得了持续的提升。定性结果进一步突出了该推理引导框架在提高分割精度和可解释性方面的有效性。

**Conclusion:** OpenSeg-R是首个将显式循序渐进视觉推理引入开放词汇分割的框架，通过利用大型多模态模型进行分层推理，显著提高了分割精度和可解释性。

> **ai_Abstract:** 本文提出了OpenSeg-R，一个用于开放词汇分割的循序渐进视觉推理框架。该框架利用大型多模态模型（LMMs）进行分层视觉推理，生成通用和图像特定的结构化推理三元组，以此构建详细提示来引导分割器，从而提高分割精度和可解释性。实验证明，OpenSeg-R在多个基准数据集上显著优于现有最先进的方法。

> **摘要翻译:** 开放词汇分割（OVS）因其能够将分割泛化到预定义类别之外的能力而受到越来越多的关注。然而，现有方法通常通过简单的前向推理预测分割掩码，缺乏明确的推理和可解释性。这使得OVS模型在开放世界设置中难以区分相似类别，因为缺乏上下文理解和判别性视觉线索。为了解决这一局限性，我们提出了一种用于开放词汇分割的循序渐进视觉推理框架，名为OpenSeg-R。所提出的OpenSeg-R利用大型多模态模型（LMMs）在分割之前执行分层视觉推理。具体来说，我们为每张图像生成通用和图像特定的推理，形成结构化的三元组，以从粗到细的方式解释对象的视觉原因。基于这些推理步骤，我们可以组合详细的描述提示，并将其输入到分割器中以生成更准确的分割掩码。据我们所知，OpenSeg-R是第一个将显式循序渐进视觉推理引入OVS的框架。实验结果表明，OpenSeg-R在五个基准数据集上的开放词汇语义分割方面显著优于现有最先进的方法。此外，它在开放词汇全景分割的所有指标上都取得了持续的提升。定性结果进一步突出了我们推理引导框架在提高分割精度和可解释性方面的有效性。我们的代码已在https://github.com/Hanzy1996/OpenSeg-R公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [163] [AniMer+: Unified Pose and Shape Estimation Across Mammalia and Aves via Family-Aware Transformer](https://arxiv.org/abs/2508.00298)
> *AniMer+：通过家族感知Transformer实现哺乳动物和鸟类统一姿态和形状估计*

*Jin Lyu, Liang An, Li Lin, Pujin Cheng, Yebin Liu, Xiaoying Tang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 姿态估计, 形状估计, 统一模型, Transformer, 合成数据

**Comment:** arXiv admin note: substantial text overlap with arXiv:2412.00837

> **TL;DR:** AniMer+使用家族感知Transformer和Mixture-of-Experts设计，结合生成的大规模合成数据集，实现了哺乳动物和鸟类统一的姿态和形状估计，并在多项基准测试中表现出优于现有方法的性能。

**AI_Comments:** 创新点：本论文首次提出了一种统一模型AniMer+，通过其独特的家族感知Transformer和Mixture-of-Experts (MoE) 设计，有效处理了哺乳动物和鸟类在姿态和形状估计上的差异性和共性。该方法能够在一个单一模型中学习不同物种的解剖特征，这在动物三维重建领域是一个显著的进步。重要性：该研究通过引入基于扩散的图像生成管道，成功缓解了多物种3D训练数据（尤其是鸟类数据）严重稀缺的问题，为鸟类创建了首个大规模3D标注数据集CtrlAVES3D，这极大地推动了该领域的数据基础建设。其统一的框架也为未来构建更强大、更通用的动物姿态和形状估计基础模型奠定了基础。局限性：抽象中未明确提及具体局限性，但通常合成数据与真实数据之间可能存在领域鸿沟，这可能会影响模型在极端或未见过真实场景中的泛化能力。此外，仅限于哺乳动物和鸟类，未来可以考虑扩展到更广泛的动物分类群。

<details>
  <summary>Details</summary>

**Motivation:** 在基础模型时代，通过单一网络统一理解不同动态对象具有增强空间智能的潜力。准确估计动物姿态和形状对于生物研究中的定量分析至关重要。然而，由于现有方法的网络容量有限以及缺乏全面的多物种数据集，该领域仍未得到充分探索。

**Method:** 本研究引入了AniMer+框架，它是可扩展AniMer框架的扩展版本，专注于统一重建哺乳动物和鸟类。AniMer+的核心创新在于其高容量、家族感知视觉Transformer (ViT)，并融入了Mixture-of-Experts (MoE) 设计。其架构将网络层划分为分类群特定组件（针对哺乳动物和鸟类）和分类群共享组件，从而在单一模型中有效学习独特和共同的解剖特征。为克服3D训练数据（尤其是鸟类数据）严重短缺的问题，研究引入了基于扩散的条件图像生成管道，生成了两个大规模合成数据集：用于四足动物的CtrlAni3D和用于鸟类的CtrlAVES3D（这是首个大规模、3D标注的鸟类数据集）。模型在结合了真实和合成数据的41.3k哺乳动物图像和12.4k鸟类图像的聚合集合上进行训练。

**Result:** 该方法在广泛的基准测试中，包括具有挑战性的域外Animal Kingdom数据集，表现出优于现有方法的性能。消融研究证实了其新型网络架构和生成的合成数据集在增强实际应用性能方面的有效性。

**Conclusion:** AniMer+通过其创新的家族感知Transformer架构和Mixture-of-Experts设计，结合生成的大规模合成数据集，成功解决了哺乳动物和鸟类统一姿态和形状估计的挑战，并显著提升了该领域的性能。

> **ai_Abstract:** 本研究提出了AniMer+，一个统一的框架，旨在通过家族感知Transformer和Mixture-of-Experts设计，实现哺乳动物和鸟类的姿态和形状估计。为解决多物种3D数据稀缺的难题，特别是鸟类数据，该工作引入了基于扩散的条件图像生成管道，创建了CtrlAni3D和CtrlAVES3D两个大规模合成数据集，其中CtrlAVES3D是首个大规模3D标注的鸟类数据集。AniMer+在真实和合成数据的组合上进行训练，并在多项基准测试中表现出优于现有方法的性能，其创新架构和合成数据被证明是提升实际应用性能的关键。

> **摘要翻译:** 在基础模型时代，通过单一网络统一理解不同动态对象具有增强空间智能的潜力。此外，准确估计不同物种的动物姿态和形状对于生物研究中的定量分析至关重要。然而，由于现有方法的网络容量有限以及缺乏全面的多物种数据集，该主题仍未得到充分探索。为解决这些限制，我们引入了AniMer+，这是我们可扩展AniMer框架的扩展版本。在本文中，我们专注于重建哺乳动物和鸟类的统一方法。AniMer+的一个关键创新是其高容量、家族感知视觉Transformer (ViT)，并融入了Mixture-of-Experts (MoE) 设计。其架构将网络层划分为分类群特定组件（针对哺乳动物和鸟类）和分类群共享组件，从而在单一模型中有效学习独特和共同的解剖特征。为克服3D训练数据（尤其是鸟类数据）严重短缺的问题，我们引入了基于扩散的条件图像生成管道。该管道生成了两个大规模合成数据集：用于四足动物的CtrlAni3D和用于鸟类的CtrlAVES3D。值得注意的是，CtrlAVES3D是首个大规模、3D标注的鸟类数据集，这对于解决单视图深度模糊性至关重要。我们的方法在结合了41.3k哺乳动物和12.4k鸟类图像（真实和合成数据）的聚合集合上进行训练，在广泛的基准测试中，包括具有挑战性的域外Animal Kingdom数据集，表现出优于现有方法的性能。消融研究证实了我们新型网络架构和生成的合成数据集在增强实际应用性能方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [165] [HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models](https://arxiv.org/abs/2508.00553)
> *HiPrune：基于视觉语言模型中层级注意力的免训练视觉令牌剪枝*

*Jizhihui Liu, Feiyi Du, Guangdao Zhu, Niu Lian, Jun Li, Bin Chen* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 视觉令牌剪枝, 层级注意力, 视觉语言模型, 免训练, 推理效率

**Comment:** 

> **TL;DR:** HiPrune是一种免训练、模型无关的视觉令牌剪枝框架，利用视觉编码器中的层级注意力，显著减少视觉语言模型的计算开销和推理延迟，同时保持高任务精度。

**AI_Comments:** HiPrune的创新之处在于其“免训练”和“模型无关”的特性，这极大地提高了其在不同ViT-based VLM架构上的可扩展性和实用性。通过巧妙地利用视觉编码器内部的层级注意力机制来识别和选择关键令牌，而非依赖额外的训练或特殊令牌，它提供了一种高效且普适的解决方案，有效缓解了视觉语言模型在推理时的计算瓶颈。其显著的性能提升和强大的泛化能力是其重要性所在。

<details>
  <summary>Details</summary>

**Motivation:** 视觉语言模型将图像编码为冗长的视觉令牌序列，导致计算开销过大和推理效率受限。现有剪枝方法常依赖特殊令牌或需要任务特定训练，限制了其可扩展性。

**Method:** 提出HiPrune，一个免训练且与模型无关的令牌剪枝框架，它利用视觉编码器内部的层级注意力结构。通过观察中间层关注以对象为中心的区域，而深层捕获全局上下文特征，HiPrune选择三类信息丰富的令牌：(1) 在对象中心层中注意力高的“锚点令牌”；(2) 与锚点相邻的“缓冲令牌”以保持空间连续性；(3) 在深层中注意力强的“注册令牌”用于全局汇总。该方法无需再训练，并可与任何基于ViT的VLM无缝集成。

**Result:** 在LLaVA-1.5、LLaVA-NeXT和Qwen2.5-VL上的实验表明，HiPrune在仅使用33.3%令牌的情况下保持了高达99.3%的任务精度，在使用11.1%令牌时保持了99.5%的精度。同时，它将推理FLOPs和延迟降低了高达9倍，显示出强大的模型和任务泛化能力。

**Conclusion:** HiPrune通过利用视觉编码器的层级注意力结构，实现了免训练、模型无关的视觉令牌剪枝，显著提高了视觉语言模型的推理效率，同时保持了高精度和强大的泛化能力。

> **ai_Abstract:** HiPrune是一种新颖的、免训练、模型无关的视觉令牌剪枝框架，专为解决视觉语言模型中冗长视觉令牌序列导致的计算效率低下问题而设计。该方法利用视觉编码器中层级注意力的特性，区分出对象中心和全局上下文信息，并据此智能选择锚点、缓冲和注册三类关键令牌进行保留。实验证明，HiPrune在保持高精度的同时，能显著降低推理FLOPs和延迟，并展现出优异的模型和任务泛化能力。

> **摘要翻译:** 视觉语言模型（VLMs）将图像编码为冗长的视觉令牌序列，导致计算开销过大和推理效率受限。虽然之前的努力通过剪枝或合并令牌来解决这个问题，但它们通常依赖于特殊令牌（例如CLS）或需要任务特定训练，这阻碍了跨架构的可扩展性。在本文中，我们提出了HiPrune，一个免训练且与模型无关的令牌剪枝框架，它利用视觉编码器内部的层级注意力结构。我们发现中间层关注以对象为中心的区域，而深层捕获全局上下文特征。基于这一观察，HiPrune选择三种信息丰富的令牌：(1) 在对象中心层中注意力高的锚点令牌，(2) 与锚点相邻的缓冲令牌以实现空间连续性，以及(3) 在深层中注意力强的注册令牌用于全局汇总。我们的方法无需再训练，并且可以与任何基于ViT的VLM无缝集成。在LLaVA-1.5、LLaVA-NeXT和Qwen2.5-VL上的广泛实验表明，HiPrune实现了最先进的剪枝性能，在仅使用33.3%令牌的情况下保持了高达99.3%的任务精度，并在仅使用11.1%令牌的情况下保持了99.5%的精度。同时，它将推理FLOPs和延迟降低了高达9倍，显示出强大的模型和任务泛化能力。代码可在https://github.com/Danielement321/HiPrune获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [181] [YOLO-FireAD: Efficient Fire Detection via Attention-Guided Inverted Residual Learning and Dual-Pooling Feature Preservation](https://arxiv.org/abs/2505.20884)
> *YOLO-FireAD：基于注意力引导倒残差学习和双池化特征保留的有效火灾检测*

*Weichao Pan, Bohan Xu, Xu Wang, Chengze Lv, Shuoyang Wang, Zhenke Duan, Zhen Tian* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 火灾检测, YOLO, 注意力机制, 倒残差, 双池化

**Comment:** 2025 International Conference on Intelligent Computing (ICIC 2025)

> **TL;DR:** YOLO-FireAD是一种新型的火灾检测模型，通过注意力引导的倒残差块和双池化下采样融合块，解决了现有YOLO模型在复杂环境中特征提取受限和信息丢失的问题，实现了高效且高精度的火灾检测，同时显著降低了模型参数和计算量。

**AI_Comments:** 该论文提出的YOLO-FireAD模型在火灾检测领域具有显著创新性。通过引入注意力引导的倒残差和双池化融合机制，有效解决了传统YOLO模型在复杂环境下特征提取不足和信息丢失的问题。其在保持高精度的同时，大幅度降低了模型参数量和计算量，这对于实际部署在资源受限设备上具有重要意义。特别是对小目标火灾的检测能力提升，是其一大亮点。该研究为实时、高效的火灾预警系统提供了新的思路和强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 动态环境中的火灾检测面临诸多挑战，包括光照变化干扰、高误报/漏报率以及难以同时实现效率和准确性。现有基于YOLO的模型存在特征提取受限和信息丢失的问题。

**Method:** 本研究提出了YOLO-FireAD模型，包含两项核心创新：1) 注意力引导倒残差块（AIR）：将混合通道-空间注意力与倒残差结合，自适应增强火灾特征并抑制环境噪声。2) 双池化下采样融合块（DPDF）：通过最大-平均池化输出的可学习融合，保留多尺度火灾模式，以减轻小火检测失败。

**Result:** 在两个公共数据集上的广泛评估表明，YOLO-FireAD模型表现高效。其总参数量为1.45M（比YOLOv8n低51.8%），GFLOPs为4.6G（比YOLOv8n低43.2%），mAP75比主流实时目标检测模型YOLOv8n、YOL-Ov9t、YOLOv10n、YOLO11n、YOLOv12n以及其他YOLOv8变体高1.3-5.5%。

**Conclusion:** 该研究提出的YOLO-FireAD模型通过其创新的AIR和DPDF模块，有效解决了火灾检测中的特征提取和信息丢失问题，在保持高效率的同时显著提高了检测精度，证明了其在动态环境火灾检测中的优越性能。

> **ai_Abstract:** 该研究针对动态环境火灾检测中现有YOLO模型面临的特征提取受限和信息丢失问题，提出了YOLO-FireAD模型。该模型引入了注意力引导倒残差块（AIR）和双池化下采样融合块（DPDF）两大创新。AIR通过集成混合注意力与倒残差增强火灾特征并抑制噪声；DPDF通过可学习融合最大-平均池化输出，保留多尺度特征以提升小火检测能力。实验结果表明，YOLO-FireAD在显著降低参数量和计算量的同时，其mAP75性能优于多种主流实时目标检测模型。

> **摘要翻译:** 火灾检测在动态环境中面临持续挑战，包括光照变化的干扰、大量的误报或漏报，以及难以同时实现效率和准确性。为解决现有基于YOLO模型中特征提取受限和信息丢失的问题，本研究提出了“仅看一次火灾检测，结合注意力引导倒残差和双池化下采样融合”（YOLO-FireAD）模型，具有两项核心创新：(1) 注意力引导倒残差块（AIR）将混合通道-空间注意力与倒残差相结合，自适应地增强火灾特征并抑制环境噪声；(2) 双池化下采样融合块（DPDF）通过最大-平均池化输出的可学习融合来保留多尺度火灾模式，从而减轻小火检测失败。在两个公共数据集上的广泛评估显示了我们模型的有效性能。我们提出的模型总参数量为1.45M（比YOLOv8n低51.8%），计算量为4.6G（比YOLOv8n低43.2%），mAP75比主流实时目标检测模型YOLOv8n、YOL-Ov9t、YOLOv10n、YOLO11n、YOLOv12n以及其他YOLOv8变体高1.3-5.5%。欲了解更多详情，请访问我们的存储库：https://github.com/JEFfersusu/YOLO-FireAD

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [185] [Controllable Pedestrian Video Editing for Multi-View Driving Scenarios via Motion Sequence](https://arxiv.org/abs/2508.00299)
> *基于运动序列的多视角驾驶场景可控行人视频编辑*

*Danzhen Fu, Jiagao Hu, Daiguo Zhou, Fei Wang, Zepeng Wang, Wenhua Liao* | **Category: cs.CV, cs.AI, cs.RO** | **Updated: 2025-08-01**

**Keywords:** 行人视频编辑, 多视角, 自动驾驶, 数据增强, 运动序列

**Comment:** ICCV 2025 Workshop (HiGen)

> **TL;DR:** 本文提出了一种新颖的框架，用于在多视角驾驶场景中进行可控行人视频编辑，以解决自动驾驶系统中行人检测模型因训练数据不足而缺乏鲁棒性的问题。

**AI_Comments:** 这项工作通过引入可控行人视频编辑为自动驾驶数据增强提供了一个创新且实用的解决方案。其核心创新在于将视频修复与人体运动控制相结合，实现了高真实感和跨视图一致性。这对于生成多样化且具有挑战性的训练数据至关重要，能有效提升行人检测模型的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶系统中的行人检测模型由于训练数据中缺乏危险行人场景的充分表示，导致鲁棒性不足。为了解决这一限制，本文提出了一个框架。

**Method:** 该方法首先识别多摄像机视图中的行人感兴趣区域，以固定比例扩展检测边界框，并将这些区域调整大小并拼接成一个统一的画布，同时保留跨视图的空间关系。然后应用二值掩码指定可编辑区域，在该区域内，行人编辑通过姿态序列控制条件进行引导。这实现了灵活的编辑功能，包括行人插入、替换和移除。

**Result:** 本文的框架实现了高质量的行人编辑，具有强大的视觉真实感、时空连贯性和跨视图一致性。

**Conclusion:** 所提出的方法为多视角行人视频生成提供了强大而通用的解决方案，在自动驾驶中的数据增强和场景模拟方面具有广阔的应用潜力。

> **ai_Abstract:** 本文提出了一种新颖的可控行人视频编辑框架，用于多视角驾驶场景。该框架旨在通过整合视频修复和人体运动控制技术来解决自动驾驶系统中行人检测模型因训练数据不足而导致的鲁棒性问题。它通过识别和拼接多视图行人区域、应用编辑掩码以及利用姿态序列控制来实现行人插入、替换和移除等灵活编辑功能。实验证明，该方法能生成高质量、视觉真实、时空连贯且跨视图一致的行人视频，有望应用于自动驾驶的数据增强和场景模拟。

> **摘要翻译:** 自动驾驶系统中的行人检测模型由于训练数据中危险行人场景的表示不足而常常缺乏鲁棒性。为了解决这一限制，我们提出了一种新颖的框架，通过整合视频修复和人体运动控制技术，实现多视角驾驶场景中的可控行人视频编辑。我们的方法首先识别多个摄像机视图中的行人感兴趣区域，以固定比例扩展检测边界框，并调整这些区域的大小并拼接成一个统一的画布，同时保留跨视图的空间关系。然后应用二值掩码来指定可编辑区域，在该区域内，行人编辑由姿态序列控制条件引导。这实现了灵活的编辑功能，包括行人插入、替换和移除。广泛的实验表明，我们的框架实现了高质量的行人编辑，具有强大的视觉真实感、时空连贯性和跨视图一致性。这些结果确立了所提出的方法作为一种强大且通用的多视角行人视频生成解决方案，在自动驾驶中的数据增强和场景模拟方面具有广阔的应用潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [191] [Training-Free Class Purification for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.00557)
> *免训练的开放词汇语义分割类别净化*

*Qi Chen, Lingxiao Yang, Yun Chen, Nailong Zhao, Jianhuang Lai, Jie Shao, Xiaohua Xie* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 免训练, 类别净化, 开放词汇语义分割, 冗余, 歧义

**Comment:** Accepted to ICCV 2025

> **TL;DR:** FreeCP是一种免训练的开放词汇语义分割方法，通过净化类别表示来解决类别冗余和视觉语言歧义问题，显著提升了分割性能。

**AI_Comments:** 该论文的创新点在于提出了一个完全免训练的类别净化框架（FreeCP），专门解决开放词汇语义分割中常见的类别冗余和视觉语言歧义问题。这种免训练的特性使其在计算资源受限的场景下具有显著优势。作为一个即插即用的模块，FreeCP的通用性和易用性也极大地增强了现有OVSS方法的实用性，显示出其在实际应用中的重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的开放词汇语义分割（OVSS）方法需要大量的计算和资源进行训练。尽管免训练方法已受到关注，但它们通常忽略了类别冗余（测试图像中不存在多余类别）和视觉语言歧义（类别间语义相似性导致激活混淆）带来的挑战，这些问题会导致次优的类别激活图。

**Method:** 本文提出了FreeCP，一个新颖的免训练类别净化框架。FreeCP专注于净化语义类别，纠正由冗余和歧义引起的错误。净化的类别表示随后被用于生成最终的分割预测。

**Result:** 在八个基准测试中进行了广泛实验，验证了FreeCP的有效性。结果表明，FreeCP作为一个即插即用的模块，在与其他OVSS方法结合时能显著提升分割性能。

**Conclusion:** FreeCP通过净化类别表示，有效解决了开放词汇语义分割中的类别冗余和视觉语言歧义问题，作为一个即插即用的模块，能够显著提升现有OVSS方法的性能。

> **ai_Abstract:** 本文提出了一种名为FreeCP的新型免训练框架，用于开放词汇语义分割（OVSS）。该框架旨在解决现有免训练方法中忽视的类别冗余和视觉语言歧义问题，这些问题会导致类别激活图质量下降。FreeCP通过净化语义类别并纠正相关错误来改善分割性能，其净化的类别表示用于最终预测。实验证明，FreeCP作为一个即插即用的模块，能够显著提升与其他OVSS方法结合时的分割效果。

> **摘要翻译:** 微调预训练的视觉-语言模型已成为增强开放词汇语义分割（OVSS）的强大方法。然而，在大型数据集上进行训练所需的巨大计算和资源需求促使人们对免训练的OVSS方法产生兴趣。现有的免训练方法主要侧重于修改模型架构和生成原型以提高分割性能。然而，它们通常忽视了类别冗余（当前测试图像中不存在多个类别）和视觉-语言歧义（类别之间的语义相似性在类别激活中造成混淆）带来的挑战。这些问题可能导致次优的类别激活图和亲和力细化的激活图。受这些观察的启发，我们提出了FreeCP，一个新颖的免训练类别净化框架，旨在解决这些挑战。FreeCP专注于净化语义类别并纠正由冗余和歧义引起的错误。然后利用净化的类别表示来生成最终的分割预测。我们在八个基准测试中进行了广泛实验，以验证FreeCP的有效性。结果表明，FreeCP作为一个即插即用的模块，在与其他OVSS方法结合时能显著提升分割性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [193] [Occlusion Boundary and Depth: Mutual Enhancement via Multi-Task Learning](https://arxiv.org/abs/2505.21231)
> *遮挡边界与深度：多任务学习实现相互增强*

*Lintao Xu, Yinghao Wang, Chaohui Wang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 遮挡边界估计, 单目深度估计, 多任务学习, 深度学习, 场景理解

**Comment:** 8 pages, 4 tables, 4 figures

> **TL;DR:** 本文提出了MoDOT，一种首次从单张图像中联合估计深度和遮挡边界的多任务学习方法，通过新模块和损失函数实现了最先进的性能。

**AI_Comments:** 本文的创新之处在于首次提出了从单张图像中联合估计深度和遮挡边界的多任务学习框架MoDOT。通过引入专门设计的CASM模块和OBDCL损失，该方法有效地利用了深度和遮挡边界之间的相互关系，实现了性能上的显著提升。其在合成和真实世界数据集上的SOTA表现，以及出色的跨域能力，都凸显了其在场景理解领域的潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 遮挡边界估计（OBE）和单目深度估计（MDE）密切相关，遮挡边界为解决深度模糊性提供关键几何线索，而深度反过来可以细化遮挡推理。现有方法未能充分利用这种相互增强，因此需要一种能联合估计两者的有效方法来支持更准确的场景理解。

**Method:** 本文提出了MoDOT，一种首次从单张图像中联合估计深度和遮挡边界的新方法。MoDOT包含一个新的模块CASM，它结合了交叉注意力（cross-attention）和多尺度条带卷积（multi-scale strip convolutions），以利用中级遮挡边界特征来改进深度预测。它还包含一个遮挡感知损失OBDCL，用于鼓励预测深度图中更准确的边界。

**Result:** 实验证明了联合估计深度和遮挡边界的相互益处，并验证了MoDOT设计的有效性。MoDOT在两个合成数据集和广泛使用的NYUD-v2真实世界数据集上达到了最先进（SOTA）的性能，显著优于多任务基线。此外，MoDOT在真实世界深度预测上的跨域结果（仅在合成数据集上训练）也显示出有前景的结果，在预测深度图中保留了清晰的遮挡边界，并与竞争对手相比展示了改进的几何保真度。

**Conclusion:** 通过首次联合估计深度和遮挡边界，本文提出的MoDOT方法成功实现了两者的相互增强，并在多个数据集上取得了最先进的性能，证明了该多任务学习方法的有效性及其在提高场景理解方面的潜力。

> **ai_Abstract:** 本文提出了一种名为MoDOT的新型多任务学习方法，旨在首次从单张图像中联合估计遮挡边界和深度。该方法通过引入CASM模块（结合交叉注意力和多尺度条带卷积以利用遮挡边界特征改进深度预测）和OBDCL遮挡感知损失（鼓励深度图中的准确边界）来实现深度和遮挡边界的相互增强。实验结果表明，MoDOT在多个合成和真实世界数据集上均取得了最先进的性能，并展现了优秀的跨域泛化能力和几何保真度。

> **摘要翻译:** 遮挡边界估计（OBE）识别由物体间遮挡和单个物体内部自遮挡产生的边界，将其与普通边缘和语义轮廓区分开来，以支持更准确的场景理解。这项任务与单目深度估计（MDE）密切相关，后者从单张图像推断深度，因为遮挡边界（OBs）为解决深度模糊性提供了关键几何线索，而深度反过来可以细化遮挡推理。在本文中，我们提出了MoDOT，一种首次从单张图像中联合估计深度和遮挡边界的新方法。MoDOT包含一个新的模块CASM，它结合了交叉注意力（cross-attention）和多尺度条带卷积（multi-scale strip convolutions），以利用中级遮挡边界特征来改进深度预测。它还包含一个遮挡感知损失OBDCL，用于鼓励预测深度图中更准确的边界。广泛的实验证明了联合估计深度和遮挡边界的相互益处，并验证了MoDOT设计的有效性。我们的方法在两个合成数据集和广泛使用的NYUD-v2真实世界数据集上达到了最先进（SOTA）的性能，显著优于多任务基线。此外，MoDOT在真实世界深度预测上的跨域结果——仅在我们的合成数据集上训练——也显示出有前景的结果，在预测深度图中保留了清晰的遮挡边界，并与竞争对手相比展示了改进的几何保真度。我们将发布我们的代码、预训练模型和数据集。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [194] [$MV_{Hybrid}$: Improving Spatial Transcriptomics Prediction with Hybrid State Space-Vision Transformer Backbone in Pathology Vision Foundation Models](https://arxiv.org/abs/2508.00383)
> *MV_Hybrid：利用混合状态空间-视觉Transformer主干改进病理学视觉基础模型中的空间转录组预测*

*Won June Cho, Hongjun Yoon, Daeky Jeong, Hyeongyeol Lim, Yosep Chong* | **Category: cs.CV, cs.AI, cs.CE, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 空间转录组学, 视觉基础模型, 混合架构, 状态空间模型, Vision Transformer

**Comment:** Accepted (Oral) in MICCAI 2025 COMPAYL Workshop

> **TL;DR:** MV_Hybrid模型结合了状态空间模型和视觉Transformer，显著提高了从常规组织病理学图像预测空间基因表达的准确性和鲁棒性，优于现有视觉Transformer模型，有望成为下一代病理学视觉基础模型的主干。

**AI_Comments:** 该论文提出了一种创新的混合架构MV_Hybrid，将状态空间模型与Vision Transformer相结合，有效解决了现有病理学视觉基础模型在从组织病理学图像预测空间基因表达方面的局限性。其创新点在于利用状态空间模型捕捉低频形态模式的优势，并与ViT的强大特征提取能力相结合。研究结果显示出显著的性能提升和鲁棒性，特别是在泛化能力方面，这对于临床应用至关重要。该工作有望推动病理学视觉基础模型的发展，为精准肿瘤学提供更准确、更可负担的工具。

<details>
  <summary>Details</summary>

**Motivation:** 空间转录组学成本高且技术复杂，限制了其临床应用。从常规组织病理学图像预测空间基因表达是一种实用的替代方案，但现有基于Vision Transformer（ViT）的病理学视觉基础模型（VFMs）性能未达临床标准。研究者假设超越ViT的架构创新能更好地捕捉与分子表型相关的低频、细微形态模式。

**Method:** 研究者提出了MV_Hybrid，一种结合状态空间模型（SSM）和Vision Transformer（ViT）的混合主干架构。他们证明了负实特征值初始化的状态空间模型表现出强烈的低频偏置。将MV_Hybrid与其他五种不同的主干架构进行比较，所有模型都使用DINOv2自监督学习方法在相同的结直肠癌数据集上进行预训练。在随机分割和留一研究（LOSO）设置下，使用相同的生物标志物数据集评估所有预训练模型。

**Result:** 在LOSO评估中，MV_Hybrid比表现最佳的ViT模型相关性高出57%，基因表达预测性能下降幅度比随机分割小43%，分别显示出卓越的性能和鲁棒性。此外，MV_Hybrid在分类、图像块检索和生存预测等下游任务中表现出与ViT相同或更好的性能。

**Conclusion:** MV_Hybrid作为一种混合状态空间-视觉Transformer主干架构，显著提高了从组织病理学图像预测空间基因表达的准确性和鲁棒性，并在其他下游任务中表现出色，有望成为下一代病理学视觉基础模型的主干。

> **ai_Abstract:** 本研究提出了一种名为MV_Hybrid的新型混合主干架构，旨在改善从常规组织病理学图像预测空间基因表达的性能。针对现有基于Vision Transformer（ViT）的病理学视觉基础模型（VFMs）性能不足的问题，MV_Hybrid结合了状态空间模型（SSM）和ViT，以更好地捕捉与分子表型相关的低频形态模式。实验结果表明，MV_Hybrid在空间基因表达预测方面，尤其是在留一研究（LOSO）评估中，其相关性比最佳ViT模型高出57%，且性能下降幅度更小，展现出卓越的性能和鲁棒性。此外，MV_Hybrid在分类、图像块检索和生存预测等下游任务中也表现出与ViT相当或更优的性能，证明了其作为下一代病理学VFM主干的巨大潜力。

> **摘要翻译:** 空间转录组学揭示了组织背景下的基因表达模式，支持精准肿瘤学应用，如治疗反应预测，但其高成本和技术复杂性限制了临床应用。从常规组织病理学图像预测空间基因表达（生物标志物）提供了一种实用的替代方案，然而，目前基于视觉Transformer（ViT）主干的病理学视觉基础模型（VFMs）表现低于临床标准。鉴于VFMs已在数百万张不同的全玻片图像上进行训练，我们假设超越ViT的架构创新可能更好地捕捉与分子表型相关的低频、细微形态模式。通过证明以负实特征值初始化的状态空间模型表现出强烈的低频偏置，我们引入了MV_Hybrid，一种结合状态空间模型（SSM）和ViT的混合主干架构。我们比较了病理学VFMs的其他五种不同主干架构，所有这些模型都使用DINOv2自监督学习方法在相同的结直肠癌数据集上进行了预训练。我们使用相同生物标志物数据集的随机分割和留一研究（LOSO）设置评估了所有预训练模型。在LOSO评估中，MV_Hybrid比表现最佳的ViT相关性高出57%，在基因表达预测中性能下降幅度比随机分割小43%，分别显示出卓越的性能和鲁棒性。此外，MV_Hybrid在分类、图像块检索和生存预测任务中表现出与ViT相同或更好的下游性能，显示出其作为下一代病理学VFM主干的潜力。我们的代码已公开可用：https://github.com/deepnoid-ai/MVHybrid。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [199] [Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis](https://arxiv.org/abs/2508.00381)
> *通过Adapt-WeldNet和缺陷检测可解释性分析推进海事操作中的焊接缺陷检测*

*Kamal Basha S, Athira Nambiar* | **Category: cs.CV, cs.AI, cs.CE, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 焊接缺陷检测, Adapt-WeldNet, 可解释性AI, 海上操作, 可信赖AI

**Comment:** 

> **TL;DR:** 本文提出了Adapt-WeldNet，一个自适应框架，用于优化焊接缺陷检测，并通过缺陷检测可解释性分析（DDIA）提高系统透明度和信任，特别是在海洋和海上环境中。

**AI_Comments:** 该论文的创新之处在于其双重方法：首先，Adapt-WeldNet通过系统化的模型和超参数优化，解决了现有神经网络方法在焊接缺陷检测中任意选择预训练架构的问题；其次，DDIA框架通过整合XAI技术和人机协作，显著提升了AI决策的可解释性和可信度，这对于高风险的工业应用至关重要。通过专家验证和可信赖AI原则的结合，该研究为AI在关键基础设施检测中的实际部署提供了强有力的支持，特别是在传统NDT方法不足的海洋环境中。

<details>
  <summary>Details</summary>

**Motivation:** 在石油和天然气工业中，尤其是在具有挑战性的海洋和海上环境中，焊接缺陷检测对于确保管道系统的安全性和可靠性至关重要。传统的无损检测（NDT）方法常常无法检测到细微或内部缺陷。此外，现有的基于神经网络的缺陷分类方法通常依赖任意选择的预训练架构，并且缺乏可解释性，这在部署时会引发安全问题。

**Method:** 本文引入了“Adapt-WeldNet”，一个自适应的焊接缺陷检测框架，它系统地评估各种预训练架构、迁移学习策略和自适应优化器，以识别最佳性能模型和超参数。此外，还提出了一个新颖的缺陷检测可解释性分析（DDIA）框架，该框架采用可解释人工智能（XAI）技术（如Grad-CAM和LIME），并结合经过ASNT NDE二级认证专业人员验证的领域特定评估，并融入了人机协作（HITL）方法和可信赖AI原则。

**Result:** 通过提高性能和可解释性，这项工作增强了焊接缺陷检测系统的信任、安全性和可靠性。

**Conclusion:** 通过提高性能和可解释性，这项工作增强了焊接缺陷检测系统的信任、安全性和可靠性，支持海上和海洋环境中的关键操作。

> **ai_Abstract:** 本文针对海洋和海上环境中焊接缺陷检测的挑战，提出了“Adapt-WeldNet”和“缺陷检测可解释性分析（DDIA）”框架。Adapt-WeldNet是一个自适应框架，通过系统评估预训练架构、迁移学习策略和优化器来优化缺陷检测。DDIA则利用可解释人工智能（XAI）技术（如Grad-CAM和LIME）和人机协作（HITL）方法，结合专家验证，增强了系统的透明度、可靠性和信任。这项工作旨在提高焊接缺陷检测系统的性能和可解释性，从而增强海上操作的安全性。

> **摘要翻译:** 焊接缺陷检测对于确保石油和天然气工业中管道系统的安全性和可靠性至关重要，尤其是在具有挑战性的海洋和海上环境中。传统的无损检测（NDT）方法常常无法检测到细微或内部缺陷，导致潜在的故障和昂贵的停机时间。此外，现有的基于神经网络的缺陷分类方法通常依赖任意选择的预训练架构，并且缺乏可解释性，这在部署时会引发安全问题。为了解决这些挑战，本文引入了“Adapt-WeldNet”，一个自适应的焊接缺陷检测框架，它系统地评估各种预训练架构、迁移学习策略和自适应优化器，以识别最佳性能模型和超参数，从而优化缺陷检测并提供可操作的见解。此外，还提出了一个新颖的缺陷检测可解释性分析（DDIA）框架，以增强系统透明度。DDIA采用可解释人工智能（XAI）技术，如Grad-CAM和LIME，并结合经过ASNT NDE二级认证专业人员验证的领域特定评估。通过融入人机协作（HITL）方法并与可信赖AI原则保持一致，DDIA确保了缺陷检测系统的可靠性、公平性和问责制，通过专家验证增强了对自动化决策的信心。通过提高性能和可解释性，这项工作增强了焊接缺陷检测系统的信任、安全性和可靠性，支持海上和海洋环境中的关键操作。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [203] [Exploring Fourier Prior and Event Collaboration for Low-Light Image Enhancement](https://arxiv.org/abs/2508.00308)
> *探索傅里叶先验和事件协作的低光图像增强*

*Chunyan She, Fujun Han, Chengyu Fang, Shukai Duan, Lidan Wang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 低光图像增强, 事件相机, 傅里叶先验, 动态对齐, 对比损失

**Comment:** Accepted by ACM MM 2025

> **TL;DR:** 本文提出了一种新的两阶段低光图像增强方法，利用事件相机优势，通过解耦可见性恢复和结构细化，并引入傅里叶空间分析和动态对齐策略，显著优于现有技术。

**AI_Comments:** 该论文的创新点在于将低光图像增强任务解耦为可见性恢复和结构细化两个阶段，并巧妙地引入了傅里叶空间中的振幅-相位分析以及事件相机与帧相机之间的动态对齐融合策略。通过利用事件相机的高时间分辨率特性并解决模态间差异，该方法有效地提升了低光图像的质量。此外，引入对比损失来学习判别性表示也是一个有益的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于事件的低光图像增强方法未能充分利用帧相机和事件相机各自的模态特定优势，导致性能受限。

**Method:** 本文将低光图像增强流程解耦为两个阶段：可见性恢复和结构细化。第一阶段，设计了一个具有振幅-相位纠缠的可见性恢复网络，重新思考傅里叶空间中振幅和相位分量的关系。第二阶段，提出了一种带有动态对齐的融合策略，以缓解两种传感模态之间时间分辨率差异引起的空间不匹配，旨在细化可见性恢复网络增强后的图像结构信息。此外，利用空间-频率插值模拟负样本，并开发了对比损失以学习判别性表示。

**Result:** 实验表明，所提出的方法优于最先进的模型。

**Conclusion:** 通过解耦增强流程并有效利用傅里叶先验和事件协作，本方法在低光图像增强方面取得了显著的性能提升。

> **ai_Abstract:** 本文提出了一种新颖的两阶段低光图像增强方法，旨在充分利用帧相机和事件相机的优势。第一阶段通过傅里叶空间中的振幅-相位纠缠进行可见性恢复，而第二阶段则通过动态对齐策略进行结构细化，以解决模态间的时间分辨率差异。此外，引入了一种基于空间-频率插值的对比损失。实验结果表明，该方法显著优于现有技术。

> **摘要翻译:** 事件相机受益于其高动态范围和低延迟，为低光图像增强提供了性能增益。与基于帧的相机不同，它以极高的时间分辨率记录强度变化，捕获足够的结构信息。目前，现有基于事件的方法直接将帧和事件输入到单个模型中，没有充分利用模态特定的优势，这限制了它们的性能。因此，通过分析每种传感模态的作用，增强流程被解耦为两个阶段：可见性恢复和结构细化。在第一阶段，我们通过重新思考傅里叶空间中振幅和相位分量之间的关系，设计了一个具有振幅-相位纠缠的可见性恢复网络。在第二阶段，提出了一种带有动态对齐的融合策略，以缓解两种传感模态之间时间分辨率差异引起的空间不匹配，旨在细化可见性恢复网络增强后的图像结构信息。此外，我们利用空间-频率插值来模拟具有不同光照、噪声和伪影退化的负样本，从而开发了一种对比损失，鼓励模型学习判别性表示。实验表明，所提出的方法优于最先进的模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [210] [CPCL: Cross-Modal Prototypical Contrastive Learning for Weakly Supervised Text-based Person Retrieval](https://arxiv.org/abs/2401.10011)
> *CPCL：用于弱监督文本行人检索的跨模态原型对比学习*

*Xinpeng Zhao, Yanwei Zheng, Chuanlin Lan, Xiaowei Zhang, Bowen Huang, Jibin Yang, Dongxiao Yu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 弱监督文本行人检索, 跨模态学习, 原型对比学习, CLIP, 离群伪标签挖掘

**Comment:** 9 pages, 6 figures, under peer review

> **TL;DR:** CPCL是一种新的弱监督文本行人检索方法，通过引入CLIP模型和原型特征来解决类内差异和跨模态语义鸿沟，提高了检索效果和泛化能力。

**AI_Comments:** 该论文的创新点在于引入CLIP模型到弱监督文本行人检索任务中，并关注了以往工作忽略的原型特征。通过结合原型多模态记忆和离群伪标签挖掘，有效处理了类内差异和跨模态语义鸿沟，提高了检索的可靠性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 弱监督文本行人检索面临类内差异（模态内特征变化和跨模态语义鸿沟）的挑战。以往的工作侧重于实例级样本，忽略了每个人固有的、不变的原型特征。

**Method:** 提出跨模态原型对比学习（CPCL）方法。CPCL引入CLIP模型将视觉和文本实例映射到共享潜在空间。随后，提出的原型多模态记忆（PMM）模块通过混合跨模态匹配（HCM）模块以多对多映射方式捕获属于同一人的图像-文本对的异构模态关联。此外，离群伪标签挖掘（OPLM）模块进一步区分每种模态中有价值的离群样本，通过挖掘图像-文本对之间的隐式关系来增强更可靠聚类的创建。

**Result:** 在弱监督文本行人检索的流行基准上进行了广泛实验，验证了CPCL的有效性和泛化能力。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 这篇论文提出了一种名为CPCL的跨模态原型对比学习方法，用于解决弱监督文本行人检索中的挑战。该方法通过引入CLIP模型将图像和文本映射到共享空间，并利用原型多模态记忆（PMM）模块通过混合跨模态匹配（HCM）捕获多对多关联。此外，离群伪标签挖掘（OPLM）模块用于识别有价值的离群样本以创建更可靠的聚类。实验证明CPCL在现有基准上表现出有效性和泛化能力。

> **摘要翻译:** 弱监督文本行人检索旨在利用文本描述检索目标人物的图像，而无需依赖身份注释，这更具挑战性和实用性。主要挑战是类内差异，包括模态内特征变化和跨模态语义鸿沟。以往的工作侧重于实例级样本，忽略了每个人固有的、不变的原型特征。为此，我们提出了一种跨模态原型对比学习（CPCL）方法。在实践中，CPCL引入CLIP模型到弱监督文本行人检索中，将视觉和文本实例映射到共享潜在空间。随后，所提出的原型多模态记忆（PMM）模块通过混合跨模态匹配（HCM）模块以多对多映射的方式捕获属于同一人的图像-文本对之间异构模态的关联。此外，离群伪标签挖掘（OPLM）模块进一步区分每种模态中有价值的离群样本，通过挖掘图像-文本对之间的隐式关系来增强更可靠聚类的创建。我们在弱监督文本行人检索的流行基准上进行了广泛实验，验证了CPCL的有效性和泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [214] [Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation](https://arxiv.org/abs/2508.00766)
> *医学图像到图像翻译的样本感知测试时间适应*

*Irene Iele, Francesco Di Feola, Valerio Guarrasi, Paolo Soda* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 测试时间适应, 图像到图像翻译, 样本感知, 域偏移, 医疗影像

**Comment:** 

> **TL;DR:** 提出了一种样本感知的测试时间适应（TTA）框架，通过动态调整翻译过程来解决医学图像到图像翻译中处理分布外样本时的性能下降问题，并在低剂量CT去噪和T1到T2 MRI翻译任务上取得了持续改进。

**AI_Comments:** 该论文的创新点在于提出了一个样本感知的TTA框架，通过动态地、选择性地适应来解决图像到图像翻译中分布外样本的性能下降问题，而不是统一适应。这种方法提升了模型在真实世界场景中的鲁棒性和泛化能力，对医学图像处理领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图像到图像翻译在医学成像中应用广泛，但在处理分布外样本时存在性能下降的局限性。现有方法通常统一地对分布内和分布外样本应用适应，未能有效解决此问题。

**Method:** 提出了一种新颖的测试时间适应（TTA）框架。该方法引入了一个重建模块来量化域偏移，并使用一个动态适应块选择性地修改预训练翻译模型的内部特征，以减轻偏移，同时不影响不需要适应的分布内样本的性能。

**Result:** 在低剂量CT去噪和T1到T2 MRI翻译两个医学图像到图像翻译任务上进行了评估，结果显示其方法相对于没有TTA的基线翻译模型和先前的TTA方法都有持续改进。

**Conclusion:** 动态的、样本特定的调整为提高模型在现实场景中的鲁萨性提供了一条有希望的路径，并指出当前最先进的方法统一应用适应的局限性。

> **ai_Abstract:** 本研究提出了一种新颖的样本感知测试时间适应（TTA）框架，旨在解决医学图像到图像翻译模型在处理分布外样本时性能下降的问题。该框架通过引入重建模块量化域偏移，并利用动态适应块选择性地调整模型内部特征，以实现对每个测试样本的动态适应。在低剂量CT去噪和T1到T2 MRI翻译任务上的实验表明，该方法显著优于现有基线和TTA方法，证明了动态、样本特定调整在提升模型鲁棒性方面的潜力。

> **摘要翻译:** 图像到图像翻译已成为医学成像中一种强大的技术，能够实现图像去噪和跨模态转换等任务。然而，它在处理分布外样本时存在局限性，会导致性能下降。为了解决这一局限性，我们提出了一种新颖的测试时间适应（TTA）框架，该框架根据每个测试样本的特性动态调整翻译过程。我们的方法引入了一个重建模块来量化域偏移，以及一个动态适应块，用于选择性地修改预训练翻译模型的内部特征，以减轻偏移，同时不损害不需要适应的分布内样本的性能。我们在两个医学图像到图像翻译任务上评估了我们的方法：低剂量CT去噪和T1到T2 MRI翻译，结果显示相对于没有TTA的基线翻译模型和先前的TTA方法都有持续改进。我们的分析强调了统一地对分布外和分布内样本应用适应的最新方法的局限性，表明动态的、样本特定的调整为提高模型在现实场景中的鲁棒性提供了一条有希望的路径。代码可在以下网址获取：https://github.com/cosbidev/Sample-Aware_TTA。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [216] [DONUT: A Decoder-Only Model for Trajectory Prediction](https://arxiv.org/abs/2506.06854)
> *DONUT：一种用于轨迹预测的仅解码器模型*

*Markus Knoche, Daan de Geus, Bastian Leibe* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 轨迹预测, 仅解码器模型, 自回归模型, 自动驾驶, 运动预测

**Comment:** ICCV 2025. Project page at https://vision.rwth-aachen.de/donut

> **TL;DR:** DONUT是一种用于轨迹预测的仅解码器自回归模型，它通过一致的迭代预测和“过预测”策略，在自动驾驶场景中超越了现有编码器-解码器基线，并在Argoverse 2基准测试中达到了最先进水平。

**AI_Comments:** 该论文的创新点在于将仅解码器架构成功应用于轨迹预测领域，并引入了“过预测”策略。这种方法简化了模型结构，同时通过自回归预测确保了信息的一致性和实时性，有效提升了模型性能和对未来的预判能力，对自动驾驶领域的轨迹预测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 轨迹预测对于自动驾驶至关重要，因为它能让自动驾驶汽车预判其他智能体的运动。

**Method:** 本文提出了DONUT（Decoder-Only Network for Unrolling Trajectories），一个仅解码器网络，灵感来源于语言模型的成功。与现有编码器-解码器预测模型不同，DONUT使用一个单一的自回归模型来编码历史轨迹并预测未来轨迹，从而实现一致的迭代预测。此外，还引入了“过预测”策略，作为辅助任务预测更长时程的轨迹。

**Result:** DONUT的仅解码器方法在实验中表现优于编码器-解码器基线，并在Argoverse 2单智能体运动预测基准上取得了新的最先进结果。

**Conclusion:** 仅解码器模型（DONUT）在轨迹预测方面表现出色，并通过自回归预测和“过预测”策略有效提升了性能，达到了最先进水平。

> **ai_Abstract:** 本文提出了DONUT，一个用于轨迹预测的仅解码器网络。受语言模型成功的启发，DONUT采用单一的自回归模型来编码历史并预测未来轨迹，从而实现一致的迭代预测并提供最新信息。此外，引入了“过预测”策略，作为辅助任务预测更长时程的轨迹。实验表明，DONUT的仅解码器方法优于现有的编码器-解码器基线，并在Argoverse 2单智能体运动预测基准上取得了最先进的结果。

> **摘要翻译:** 预测场景中其他智能体的运动与自动驾驶高度相关，因为它能让自动驾驶汽车进行预判。受语言建模中仅解码器模型成功的启发，我们提出了DONUT（Decoder-Only Network for Unrolling Trajectories），一个用于展开轨迹的仅解码器网络。与现有编码器-解码器预测模型不同，我们使用单一的自回归模型编码历史轨迹并预测未来轨迹。这使得模型能够以一致的方式进行迭代预测，并确保模型始终获得最新信息，从而提高性能。此外，受语言建模中多令牌预测的启发，我们引入了一种“过预测”策略，该策略为模型提供了在更长时间范围内预测轨迹的辅助任务。这使得模型能够更好地预判未来并进一步提高性能。通过实验，我们证明了我们的仅解码器方法优于编码器-解码器基线，并在Argoverse 2单智能体运动预测基准上取得了新的最先进结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [223] [DocTron-Formula: Generalized Formula Recognition in Complex and Structured Scenarios](https://arxiv.org/abs/2508.00311)
> *DocTron-Formula: 复杂和结构化场景下的通用公式识别*

*Yufeng Zhong, Zhixiong Zeng, Lei Chen, Longrong Yang, Liming Zheng, Jing Huang, Siqi Yang, Lin Ma* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 公式识别, 视觉-语言模型, OCR, CSFormula, 科学文档

**Comment:** 

> **TL;DR:** 本文提出了DocTron-Formula，一个基于通用视觉-语言模型的统一框架，用于数学公式识别。同时引入了大规模数据集CSFormula，并通过简单的监督微调，在各种风格、科学领域和复杂布局中实现了最先进的性能。

**AI_Comments:** 本文的创新之处在于利用通用视觉-语言模型构建统一框架进行数学公式识别，无需专门的架构，这简化了模型设计。同时，引入大规模且具有挑战性的CSFormula数据集，显著提升了模型在复杂场景下的性能，对科学文献的智能分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数学公式光学字符识别（OCR）模型难以处理数学内容的结构多样性、复杂性和真实世界的可变性。

**Method:** DocTron-Formula是一个基于通用视觉-语言模型的统一框架，无需专门的架构。通过简单的监督微调实现。引入了大规模且具有挑战性的数据集CSFormula，该数据集包含多学科和结构复杂的行级、段落级和页面级公式。

**Result:** DocTron-Formula在各种样式、科学领域和复杂布局中取得了最先进的性能。实验结果表明，该方法不仅在准确性和鲁棒性方面超越了专用模型，而且为复杂科学文档的自动化理解建立了新的范式。

**Conclusion:** 该方法为复杂科学文档的自动化理解建立了新的范式。

> **ai_Abstract:** DocTron-Formula是一个基于通用视觉-语言模型的统一框架，旨在解决数学公式识别中结构多样性和复杂性的挑战。该研究引入了大规模且具有挑战性的CSFormula数据集，并通过简单的监督微调，在多种风格、科学领域和复杂布局中实现了最先进的性能，超越了现有专用模型，为复杂科学文档的自动化理解开辟了新范式。

> **摘要翻译:** 数学公式的光学字符识别（OCR）对于科学文献的智能分析至关重要。然而，特定任务和通用视觉-语言模型在处理数学内容固有的结构多样性、复杂性和真实世界可变性方面常常遇到困难。在这项工作中，我们提出了DocTron-Formula，一个建立在通用视觉-语言模型之上的统一框架，从而消除了对专门架构的需求。此外，我们引入了CSFormula，一个大规模且具有挑战性的数据集，涵盖了行、段落和页面级别的多学科和结构复杂的公式。通过简单的监督微调，我们的方法在各种样式、科学领域和复杂布局中实现了最先进的性能。实验结果表明，我们的方法不仅在准确性和鲁棒性方面超越了专用模型，而且为复杂科学文档的自动化理解建立了新的范式。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [225] [Guiding Diffusion-Based Articulated Object Generation by Partial Point Cloud Alignment and Physical Plausibility Constraints](https://arxiv.org/abs/2508.00558)
> *基于部分点云对齐和物理合理性约束引导的扩散模型可动对象生成*

*Jens U. Kreber, Joerg Stueckler* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 扩散模型, 可动对象生成, 点云对齐, 物理合理性, 符号距离函数

**Comment:** Accepted for publication at the IEEE/CVF International Conference on
  Computer Vision (ICCV), 2025

> **TL;DR:** PhysNAP是一种基于扩散模型的方法，通过部分点云对齐和物理约束生成更真实的铰接物体。

**AI_Comments:** 这项工作通过将点云对齐和物理约束引入扩散模型，为可动对象的生成提供了一种新颖且有效的方法。其创新之处在于利用SDFs表示形状并以此施加物理约束，显著提升了生成对象的真实性和可用性。

<details>
  <summary>Details</summary>

**Motivation:** 可动对象是日常环境中重要的可交互对象，生成它们具有挑战性，需要同时考虑形状和物理合理性。

**Method:** 本文提出PhysNAP，一种新颖的基于扩散模型的方法，用于生成可动对象。该模型通过符号距离函数（SDFs）表示部件形状，并使用通过预测的SDFs计算的点云对齐损失来引导逆向扩散过程。此外，基于部件SDFs施加非穿透和可动性约束，以引导模型生成更符合物理规律的对象。如果类别信息可用，该方法还支持类别感知以进一步改善点云对齐。

**Result:** PhysNAP在PartNet-Mobility数据集上进行了评估，结果表明与无引导的基线扩散模型相比，PhysNAP能够提高生成样本的约束一致性，并在生成能力上取得了权衡。

**Conclusion:** PhysNAP通过结合点云对齐和物理合理性约束，成功地改进了可动对象的生成，使其更符合物理规律。

> **ai_Abstract:** 本文提出PhysNAP，一种基于扩散模型的新方法，用于生成与部分点云对齐且物理上更合理的铰接对象。该方法通过SDFs表示部件形状，并利用点云对齐损失和非穿透、可动性约束来引导扩散过程。PhysNAP在PartNet-Mobility数据集上的评估表明，它能有效提高生成对象的约束一致性，并在生成能力与此间取得平衡。

> **摘要翻译:** 可动对象是日常环境中一类重要的可交互对象。在本文中，我们提出PhysNAP，一种新颖的基于扩散模型的方法，用于生成可动对象，该方法将其与部分点云对齐并提高了其物理合理性。该模型通过符号距离函数（SDFs）表示部件形状。我们使用通过预测的SDFs计算的点云对齐损失来引导逆向扩散过程。此外，我们基于部件SDFs施加了非穿透和可动性约束，以引导模型生成更符合物理规律的对象。如果类别信息可用，我们还使我们的扩散方法具有类别感知能力，以进一步改善点云对齐。我们使用PartNet-Mobility数据集评估了PhysNAP生成的样本的生成能力和约束一致性。我们还将其与无引导的基线扩散模型进行了比较，并证明PhysNAP可以提高约束一致性，并在生成能力上提供了权衡。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [230] [Simultaneous Motion And Noise Estimation with Event Cameras](https://arxiv.org/abs/2504.04029)
> *事件相机中的同步运动与噪声估计*

*Shintaro Shiba, Yoshimitsu Aoki, Guillermo Gallego* | **Category: cs.CV, cs.AI, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 事件相机, 噪声估计, 运动估计, 去噪, 同步处理

**Comment:** 13 pages, 13 figures, 6 tables, Project page
  https://github.com/tub-rip/ESMD

> **TL;DR:** 提出首个同时估计事件相机运动和噪声的方法，在去噪和运动估计任务上表现出色。

**AI_Comments:** 这项工作具有创新性，因为它解决了事件相机数据处理中去噪和运动估计通常独立进行的问题，提出了一个统一的框架。其灵活性允许集成不同的运动估计器，包括深度学习模型，这增加了其通用性。开源代码也大大促进了该领域的研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 事件相机噪声难以表征，现有去噪方法通常独立设计，将运动估计等任务分开处理，而运动是事件数据的内在部分，没有运动就无法感知场景边缘。

**Method:** 提出一种同步估计事件相机运动（如自我运动、光流）和噪声的方法。该方法灵活，允许用任何其他运动估计器（如深度神经网络）替换广泛使用的对比度最大化框架中的一步运动估计。

**Result:** 在E-MLB去噪基准上达到最先进水平，在DND21基准上具有竞争力，并证明了在运动估计和强度重建任务中的有效性。

**Conclusion:** 该方法推进了事件数据去噪理论，并通过开源代码扩展了实际去噪用例。

> **ai_Abstract:** 本文提出了一种新颖的方法，首次实现了事件相机中运动和噪声的同步估计。针对现有方法将去噪和运动估计分离处理的局限性，该方法利用运动是事件数据固有部分的特性，通过灵活的架构允许集成不同的运动估计器。实验证明，该方法在去噪和运动估计任务上均达到了先进水平，并开源了代码，为事件数据去噪理论和实际应用带来了进展。

> **摘要翻译:** 事件相机是一种新兴的视觉传感器，其噪声难以表征。现有的事件相机去噪方法通常是独立设计的，因此将运动估计等其他任务分开考虑（即在去噪之后按顺序进行）。然而，运动是事件数据的内在部分，因为没有运动就无法感知场景边缘。据我们所知，我们提出了第一个同时估计各种形式运动（例如自我运动、光流）和噪声的方法。该方法具有灵活性，因为它允许用任何其他运动估计器（例如深度神经网络）替换广泛使用的对比度最大化框架中的一步运动估计。实验表明，所提出的方法在E-MLB去噪基准上取得了最先进的结果，并在DND21基准上取得了有竞争力的结果，同时在运动估计和强度重建任务中表现出有效性。我们的方法推进了事件数据去噪理论，并通过开源代码扩展了实际去噪用例。项目页面：https://github.com/tub-rip/ESMD

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [234] [Gaga: Group Any Gaussians via 3D-aware Memory Bank](https://arxiv.org/abs/2404.07977)
> *Gaga：通过3D感知记忆库对任意高斯进行分组*

*Weijie Lyu, Xueting Li, Abhijit Kundu, Yi-Hsuan Tsai, Ming-Hsuan Yang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 3D场景分割, 零样本分割, 3D感知记忆库, 开放世界

**Comment:** Project Page: https://weijielyu.github.io/Gaga

> **TL;DR:** Gaga是一个利用3D感知记忆库和零样本2D掩码进行开放世界3D场景重建和分割的框架，克服了对连续视图变化的依赖。

**AI_Comments:** 这篇论文的创新点在于提出了一个3D感知记忆库，有效地解决了在开放世界3D场景中利用不一致2D掩码进行分割的挑战，特别是在处理稀疏采样图像和不连续视图变化方面。其优势在于无需连续视图假设，提升了对多种输入源的鲁棒性和通用性，使其在实际应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D场景分割方法依赖于视频对象跟踪或对比学习，并且假设训练图像中存在连续的视图变化，这限制了它们在稀疏采样图像上的表现和对相机姿态变化的鲁棒性。

**Method:** Gaga通过利用零样本类别无关分割模型预测的不一致2D掩码来重建和分割开放世界3D场景。它通过一个新颖的3D感知记忆库，利用空间信息有效地关联不同相机姿态下的对象掩码，从而确保精确的掩码标签一致性。

**Result:** Gaga在定性和定量评估中表现优于最先进的方法，并且对相机姿态变化、稀疏采样图像以及来自不同来源的2D分割掩码和不同零样本分割模型都表现出鲁棒性。

**Conclusion:** Gaga通过其创新的3D感知记忆库方法，提供了一种鲁棒且通用的开放世界3D场景重建和分割解决方案，在3D场景理解和操作等实际应用中具有巨大潜力。

> **ai_Abstract:** Gaga是一个创新的框架，它利用零样本2D分割模型生成的不一致掩码，并结合一个新颖的3D感知记忆库，实现了开放世界3D场景的鲁棒重建和分割。该方法克服了传统方法对连续视图变化的依赖，在相机姿态变化大或图像稀疏采样的场景中表现出色，并能适应多种2D分割源，其性能优于现有技术，在3D场景理解和操作方面具有广阔前景。

> **摘要翻译:** 我们引入了Gaga，一个通过利用零样本类别无关分割模型预测的不一致2D掩码来重建和分割开放世界3D场景的框架。与依赖视频对象跟踪或对比学习方法的现有3D场景分割方法相比，Gaga利用空间信息并通过一种新颖的3D感知记忆库有效地关联不同相机姿态下的对象掩码。通过消除训练图像中连续视图变化的假设，Gaga展示了对相机姿态变化的鲁棒性，特别有利于稀疏采样的图像，确保了精确的掩码标签一致性。此外，Gaga能够适应来自不同来源的2D分割掩码，并展示了对不同开放世界零样本类别无关模型的强大性能，显著增强了其多功能性。广泛的定性和定量评估表明，Gaga优于最先进的方法，强调了其在3D场景理解和操作等实际应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [236] [DiFuse-Net: RGB and Dual-Pixel Depth Estimation using Window Bi-directional Parallax Attention and Cross-modal Transfer Learning](https://arxiv.org/abs/2506.14709)
> *DiFuse-Net：基于窗口双向视差注意力与跨模态迁移学习的RGB和双像素深度估计*

*Kunal Swami, Debtanu Gupta, Amrit Kumar Muduli, Chirag Jaiswal, Pankaj Kumar Bajpai* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-31**

**Keywords:** 深度估计, 双像素, 跨模态迁移学习, 注意力机制, DiFuse-Net

**Comment:** Accepted in IROS 2025

> **TL;DR:** DiFuse-Net是一种新型深度估计网络，结合RGB和双像素数据，通过窗口双向视差注意力机制和跨模态迁移学习，提高了深度估计性能，并贡献了一个新的高质量RGB-DP-D数据集。

**AI_Comments:** 该论文的创新点在于结合RGB和双像素数据进行深度估计，特别是为小光圈智能手机相机设计了WBiPAM。跨模态迁移学习机制有效地解决了特定数据集稀缺的问题，并贡献了一个新的高质量数据集，这对于该领域的研究具有重要意义。该研究为利用现有智能手机的双像素功能进行高质量深度估计提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统立体和主动深度传感器在成本、功耗和鲁棒性方面存在局限性。双像素（DP）技术在现代相机中普遍存在，提供了一种有吸引力的替代方案。然而，获取大规模RGB-DP-D数据集存在限制。

**Method:** 本文提出了DiFuse-Net，一种新颖的模态解耦网络设计，用于解耦的RGB和DP深度估计。DiFuse-Net包含一个窗口双向视差注意力机制（WBiPAM），专门用于捕获智能手机小光圈特有的微弱DP视差线索。一个独立的编码器从RGB图像中提取上下文信息，并融合这些特征以增强深度预测。作者还提出了一种跨模态迁移学习（CmTL）机制，以利用现有文献中的大规模RGB-D数据集来解决获取大规模RGB-DP-D数据集的限制。此外，作者贡献了一个新的高质量真实世界RGB-DP-D训练数据集，名为Dual-Camera Dual-Pixel (DCDP) 数据集，该数据集是使用其新颖的对称立体相机硬件设置、立体校准和校正协议以及AI立体视差估计方法创建的。

**Result:** 所提出的方法在评估和比较中表现出优于基于DP和立体视觉的基线方法。

**Conclusion:** DiFuse-Net通过结合RGB和双像素数据，利用创新的窗口双向视差注意力机制和跨模态迁移学习，显著提高了深度估计的性能，并成功解决了大规模RGB-DP-D数据集稀缺的问题，为智能系统提供了更可靠的深度感知能力。

> **ai_Abstract:** DiFuse-Net是一种新型深度估计网络，结合RGB和双像素（DP）数据。它引入了窗口双向视差注意力机制（WBiPAM）来处理DP视差，并利用跨模态迁移学习（CmTL）解决数据集稀缺问题。该方法在性能上优于现有基线，并贡献了一个新的高质量RGB-DP-D数据集，该数据集通过创新硬件和协议创建。

> **摘要翻译:** 深度估计对于智能系统至关重要，它支持从自动导航到增强现实等应用。虽然传统的立体和主动深度传感器在成本、功耗和鲁棒性方面存在局限性，但现代相机中普遍存在的双像素（DP）技术提供了一种有吸引力的替代方案。本文介绍了DiFuse-Net，一种新颖的模态解耦网络设计，用于解耦的RGB和DP深度估计。DiFuse-Net具有一个窗口双向视差注意力机制（WBiPAM），专门设计用于捕获智能手机相机小光圈特有的微弱DP视差线索。一个独立的编码器从RGB图像中提取上下文信息，并且这些特征被融合以增强深度预测。我们还提出了一种跨模态迁移学习（CmTL）机制，以利用现有文献中的大规模RGB-D数据集来应对获取大规模RGB-DP-D数据集的限制。我们对所提出方法的评估和比较表明，它优于基于DP和立体视觉的基线方法。此外，我们还贡献了一个新的、高质量的真实世界RGB-DP-D训练数据集，名为Dual-Camera Dual-Pixel (DCDP) 数据集，该数据集是使用我们新颖的对称立体相机硬件设置、立体校准和校正协议以及AI立体视差估计方法创建的。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [243] [GV-VAD : Exploring Video Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.00312)
> *GV-VAD：探索视频生成用于弱监督视频异常检测*

*Suhang Cai, Xiaohao Peng, Chong Wang, Xiaojie Cai, Jiangbo Qian* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 视频异常检测, 弱监督, 视频生成, 数据增强, GV-VAD

**Comment:** 

> **TL;DR:** GV-VAD是一个利用文本条件视频生成模型来增强训练数据的框架，以解决视频异常检测中数据稀缺和高标注成本的问题，并在UCF-Crime数据集上优于现有SOTA方法。

**AI_Comments:** 该论文创新性地将文本条件视频生成技术引入弱监督视频异常检测领域，通过生成合成数据有效缓解了真实异常数据稀缺和标注成本高昂的问题。这种数据增强方法为VAD领域提供了一个有前景的解决方案，尤其是在数据受限的场景下。其提出的损失缩放策略也体现了对合成数据有效利用的考量。

<details>
  <summary>Details</summary>

**Motivation:** 视频异常检测（VAD）在公共安全应用中至关重要，但现实世界中异常事件的稀有性、不可预测性和高昂的标注成本限制了VAD数据集的扩展，从而制约了现有模型的性能和泛化能力。

**Method:** 本文提出了一个生成式视频增强的弱监督视频异常检测（GV-VAD）框架。该框架利用文本条件视频生成模型来生成语义可控且物理合理的合成视频，以低成本扩充训练数据。此外，还采用了一种合成样本损失缩放策略来控制生成样本的影响，以实现高效训练。

**Result:** 实验结果表明，所提出的框架在UCF-Crime数据集上优于现有最先进的方法。

**Conclusion:** 该论文提出了一种利用生成式视频增强的弱监督视频异常检测框架GV-VAD，通过合成视频数据有效解决了视频异常检测中的数据稀缺和标注成本高昂问题，并提升了模型性能。

> **ai_Abstract:** GV-VAD框架通过利用文本条件视频生成模型创建合成视频，有效解决了视频异常检测中训练数据稀缺和高标注成本的挑战。这些合成数据被用于扩充训练集，并通过一种损失缩放策略优化训练效率。实验证明，GV-VAD在UCF-Crime数据集上取得了优于现有先进方法的性能。

> **摘要翻译:** 视频异常检测（VAD）在智能监控等公共安全应用中发挥着关键作用。然而，现实世界中异常事件的稀有性、不可预测性和高昂的标注成本使得VAD数据集难以扩展，这限制了现有模型的性能和泛化能力。为了解决这一挑战，我们提出了一个生成式视频增强的弱监督视频异常检测（GV-VAD）框架，该框架利用文本条件视频生成模型来生成语义可控且物理合理的合成视频。这些虚拟视频用于以低成本扩充训练数据。此外，还采用了一种合成样本损失缩放策略来控制生成合成样本的影响，以实现高效训练。实验表明，所提出的框架在UCF-Crime数据集上优于现有最先进的方法。代码可在 https://github.com/Sumutan/GV-VAD.git 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [254] [Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images](https://arxiv.org/abs/2508.00563)
> *电子显微镜图像中基于图像级标注的弱监督病毒衣壳检测*

*Hannah Kniesel, Leon Sick, Tristan Payer, Tim Bergner, Kavitha Shaga Devan, Clarissa Read, Paul Walther, Timo Ropinski* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 弱监督, 病毒衣壳检测, 电子显微镜, 图像级标注, 伪标签

**Comment:** 

> **TL;DR:** 本文提出了一种弱监督目标检测算法，仅使用易于获取的图像级标注来检测电子显微镜图像中的病毒衣壳，并通过生成伪标签来训练目标检测模型，在标注时间有限的情况下表现优于现有方法甚至真实标签。

**AI_Comments:** 该论文的创新点在于提出了一个利用图像级标注进行弱监督目标检测的框架，有效解决了医学图像（特别是电子显微镜图像）中专家级边界框标注稀缺和成本高昂的问题。其通过知识蒸馏生成伪标签并结合优化方法来直接提取目标，避免了复杂的网络架构依赖。研究结果表明其在有限标注时间下的优越性，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前最先进的目标检测方法依赖于大量数据集的边界框标注进行训练，但这些标注获取成本高昂，且需要领域专家耗费大量时间。这在科学领域（如病毒衣壳检测）尤其具有挑战性。

**Method:** 我们提出了一种领域特定的弱监督目标检测算法，仅依赖于图像级标注。该方法通过蒸馏预训练模型（用于预测图像中病毒存在与否）的知识来获取伪标签，这些伪标签随后可用于训练最先进的目标检测模型。为此，我们采用了一种具有收缩感受野的优化方法，直接提取病毒颗粒，无需特定的网络架构。

**Result:** 通过一系列广泛的研究表明，所提出的伪标签更容易获得，更重要的是，在标注时间有限的情况下，它们能够优于其他现有的弱标注方法，甚至优于真实标签。

**Conclusion:** 该研究成功提出了一种基于图像级标注的弱监督方法，有效解决了传统边界框标注成本高昂的问题。该方法生成的伪标签不仅易于获取，而且在特定条件下展现出超越现有弱标注方法乃至真实标签的优越性能，为电子显微镜图像中的病毒衣壳检测提供了高效且准确的解决方案。

> **ai_Abstract:** 本文提出了一种用于电子显微镜图像中病毒衣壳检测的弱监督目标检测算法。针对传统边界框标注成本高昂且依赖专家的问题，该方法仅使用易于获取的图像级标注。它通过蒸馏预训练模型的知识生成伪标签，并利用带有收缩感受野的优化方法直接提取病毒颗粒，从而训练出高性能的目标检测模型。实验证明，该方法生成的伪标签不仅易于获取，而且在标注时间受限的情况下，其性能优于其他弱标注方法乃至真实标签。

> **摘要翻译:** 当前最先进的目标检测方法依赖于大量数据集的标注边界框进行训练。然而，获取此类标注成本高昂，可能需要数百小时的人工劳动。这构成了一个挑战，尤其因为此类标注只能由专家提供，因为它们需要科学领域的知识。为了应对这一挑战，我们提出了一种领域特定的弱监督目标检测算法，该算法仅依赖于图像级标注，这些标注更容易获取。我们的方法蒸馏了预训练模型（用于预测图像中病毒是否存在）的知识，以获得一组伪标签，这些伪标签可用于后续训练最先进的目标检测模型。为此，我们使用一种具有收缩感受野的优化方法，无需特定的网络架构即可直接提取病毒颗粒。通过一系列广泛的研究，我们展示了所提出的伪标签如何更容易获得，更重要的是，在获取标注的时间有限的情况下，它们能够优于其他现有的弱标注方法，甚至优于真实标签。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [256] [ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds](https://arxiv.org/abs/2506.16991)
> *ForestFormer3D：一个用于森林LiDAR 3D点云端到端分割的统一框架*

*Binbin Xiang, Maciej Wielgosz, Stefano Puliti, Kamil Král, Martin Krůček, Azim Missarov, Rasmus Astrup* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 森林点云分割, LiDAR, 3D点云, 深度学习, ForestFormer3D

**Comment:** 

> **TL;DR:** ForestFormer3D是一个统一的端到端框架，用于精确分割森林LiDAR 3D点云中的单棵树和语义信息。它通过结合新组件，在FOR-instanceV2数据集上实现了最先进的单棵树分割性能，并展现了良好的泛化能力。

**AI_Comments:** 该论文提出了一种创新的统一框架ForestFormer3D，用于解决森林LiDAR 3D点云的复杂分割问题。其创新点在于结合了多个新颖组件，如ISA引导的查询点选择和一对多关联机制，显著提升了分割精度和模型的泛化能力。通过提供新的数据集和开源代码，该工作对森林学和计算机视觉领域都具有重要贡献，为未来的研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 森林LiDAR 3D点云的分割（包括单棵树和语义分割）对于推进森林管理和生态研究至关重要。然而，现有方法难以处理自然森林环境的复杂性和多变性。

**Method:** 本文提出了ForestFormer3D，一个统一的端到端框架。它结合了ISA引导的查询点选择、推理过程中的基于分数的块合并策略以及用于有效训练的一对多关联机制。

**Result:** ForestFormer3D模型在新的FOR-instanceV2数据集上实现了单棵树分割的最先进性能。此外，它对未见的测试集（Wytham woods和LAUTx）也表现出良好的泛化能力，展现了其在不同森林条件和传感器模态下的鲁棒性。

**Conclusion:** ForestFormer3D是一个有效且鲁棒的统一框架，能够实现森林LiDAR 3D点云的精确单棵树和语义分割，并在多样化的森林环境中表现出色。

> **ai_Abstract:** ForestFormer3D是一个为森林LiDAR 3D点云设计的统一端到端分割框架，旨在解决现有方法在处理复杂多变森林环境时的不足。它创新性地结合了ISA引导的查询点选择、基于分数的块合并策略和一对多关联机制。该模型在FOR-instanceV2数据集上实现了单棵树分割的最先进性能，并展示了对不同森林条件和传感器模态的良好泛化能力，提升了森林管理和生态研究的效率和精度。

> **摘要翻译:** 森林LiDAR 3D点云的分割，包括单棵树和语义分割，是推动森林管理和生态研究的基础。然而，当前的方法常常难以应对自然森林环境的复杂性和多变性。我们提出了ForestFormer3D，一个旨在实现精确单棵树和语义分割的新型统一端到端框架。ForestFormer3D整合了ISA引导的查询点选择、推理过程中基于分数的块合并策略以及用于有效训练的一对多关联机制。通过结合这些新组件，我们的模型在最新引入的FOR-instanceV2数据集上实现了单棵树分割的最先进性能，该数据集涵盖了多种森林类型和区域。此外，ForestFormer3D对未见的测试集（Wytham woods和LAUTx）也表现出良好的泛化能力，展示了其在不同森林条件和传感器模态下的鲁棒性。FOR-instanceV2数据集和ForestFormer3D代码已在https://bxiang233.github.io/FF3D/公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [260] [Boosting Adversarial Transferability with Low-Cost Optimization via Maximin Expected Flatness](https://arxiv.org/abs/2405.16181)
> *通过最大最小期望平坦度进行低成本优化以提升对抗性迁移能力*

*Chunlin Qiu, Ang Li, Yiheng Duan, Shenyi Zhang, Yuanjie Zhang, Lingchen Zhao, Qian Wang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 对抗性迁移攻击, 平坦度优化, 最大最小期望平坦度, 零阶平均案例平坦度, 开发-探索平衡

**Comment:** The original NCS method has been revised and renamed as MEF. A
  theoretical proof of the relationship between flatness and transferability is
  added

> **TL;DR:** 提出了一种名为MEF的新型攻击方法，通过平衡平坦度探索和利用，以更低的成本显著提升了对抗样本的迁移能力。

**AI_Comments:** 本文的创新点在于首次为平坦度增强的对抗性迁移攻击建立了理论基础，并提出了一个原则性的框架来解决现有方法中开发-探索失衡的优化问题。MEF攻击不仅在性能上显著超越了现有SOTA方法，还在计算成本上实现了大幅降低，这对于实际应用具有重要意义。其对平均案例平坦度的形式化以及平衡探索与利用的策略是其成功的关键。

<details>
  <summary>Details</summary>

**Motivation:** 现有平坦度增强方法在提升对抗样本迁移性方面存在优化局限性和理论基础缺失，导致其有效性和效率受限。具体来说，它们在平坦度优化中存在严重的开发-探索失衡动态。

**Method:** 本文暴露并建立了平坦度优化中开发-探索动态的理论基础，统一了现有方法中分散的平坦度定义。严格形式化了平均案例平坦度和迁移性差距，证明了增强零阶平均案例平坦度可以最小化跨模型差异。基于此理论，设计了最大最小期望平坦度（Maximin Expected Flatness, MEF）攻击，该攻击增强了零阶平均案例平坦度，同时平衡了平坦度探索和利用。

**Result:** MEF攻击在22个模型和24个当前迁移攻击上进行了评估，在攻击成功率上超越了最先进的PGN攻击4%，计算成本减半。在相同预算下，攻击成功率高出8%。与输入增强结合时，MEF对防御模型实现了额外15%的增益，建立了新的鲁棒性基准。

**Conclusion:** 本文通过建立理论基础并提出MEF攻击，有效解决了现有平坦度增强攻击的优化局限性，显著提升了对抗样本的迁移能力，并以更低的成本实现了更高的攻击成功率。

> **ai_Abstract:** 本文针对现有平坦度增强对抗攻击在迁移性方面存在的优化局限性和理论基础缺失问题，提出了最大最小期望平坦度（MEF）攻击。通过建立平坦度优化的理论基础，统一了分散的平坦度定义，并严格形式化了平均案例平坦度，证明其能最小化跨模型差异。MEF攻击通过平衡平坦度探索和利用，显著提升了对抗样本的迁移能力，在攻击成功率和计算效率上均超越了现有SOTA方法，并为防御模型建立了新的鲁棒性基准。

> **摘要翻译:** 迁移攻击在白盒替代模型上制作对抗样本，并将其直接部署到黑盒目标模型上，提供了与模型无关且无需查询的威胁场景。尽管最近出现了通过增强对抗样本的损失面平坦度来提高迁移性的平坦度增强方法，但它们不同的平坦度定义和启发式攻击设计存在未经检验的优化限制和缺失的理论基础，从而限制了它们的有效性和效率。这项工作揭示了平坦度优化中严重不平衡的开发-探索动态，为基于平坦度的迁移性建立了第一个理论基础，并提出了一个原则性框架来克服这些优化缺陷。具体来说，我们系统地统一了现有方法中分散的平坦度定义，揭示了它们在过度探索敏感峰值或过度开发局部高原方面的优化限制。为了解决这些问题，我们严格形式化了平均案例平坦度和迁移性差距，证明了增强零阶平均案例平坦度可以最小化跨模型差异。基于这一理论，我们设计了一种最大最小期望平坦度（MEF）攻击，该攻击增强了零阶平均案例平坦度，同时平衡了平坦度探索和利用。对22个模型和24个当前基于迁移的攻击进行的广泛评估表明了MEF的优越性：它在攻击成功率上超越了最先进的PGN攻击4%，计算成本减半，并在相同预算下实现了8%的更高成功率。当与输入增强结合时，MEF对配备防御的模型获得了额外15%的增益，建立了新的鲁棒性基准。我们的代码可在https://github.com/SignedQiu/MEFAttack获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [268] [Steering Guidance for Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.00319)
> *个性化文本到图像扩散模型的引导策略*

*Sunghyun Park, Seokeon Choi, Hyoungwoo Park, Sungrack Yun* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 个性化扩散模型, 文本到图像, 引导, 微调, 潜在空间

**Comment:** ICCV 2025

> **TL;DR:** 现有的个性化文本到图像扩散模型方法在目标概念保真度和文本可编辑性之间存在权衡，本论文提出了“个性化引导”方法，通过利用一个未学习的弱模型和动态权重插值，在不增加计算开销的情况下，有效平衡了文本对齐和目标保真度。

**AI_Comments:** 本文的创新之处在于提出了“个性化引导”方法，通过利用一个未学习的弱模型和动态权重插值，明确地将输出引导至平衡的潜在空间，这与仅依赖引导尺度的现有引导方法相比，是一种新颖且有效的途径。其简单性、有效性以及不增加额外计算开销的特点，使其在个性化文本到图像生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 个性化文本到图像扩散模型时，使用少量图像进行微调会导致一个固有的权衡：在与目标分布对齐（如主体保真度）和保留原始模型知识（如文本可编辑性）之间。现有采样引导方法（如CFG和AG）无法有效引导输出达到良好平衡的空间，CFG限制了对目标分布的适应，而AG则损害了文本对齐。

**Method:** 本文提出了“个性化引导”方法。该方法利用一个以空文本提示为条件的未学习弱模型。此外，它通过在推理过程中对预训练模型和微调模型之间的权重进行插值，动态控制弱模型中未学习的程度。该方法明确地将输出引导到平衡的潜在空间，且无需额外计算开销。

**Result:** 实验结果表明，所提出的引导方法可以改善文本对齐和目标分布保真度，并能与各种微调策略无缝集成。

**Conclusion:** 所提出的个性化引导方法有效解决了个性化文本到图像扩散模型中存在的权衡问题，通过实现更好的文本对齐和目标保真度之间的平衡，提供了一个简单而有效的解决方案。

> **ai_Abstract:** 本文提出了一种名为“个性化引导”的新方法，旨在解决文本到图像扩散模型个性化过程中，目标概念保真度与原始模型知识保留之间的固有权衡问题。与现有方法不同，个性化引导利用一个基于空文本提示的未学习弱模型，并通过推理期间预训练和微调模型权重的动态插值，将输出明确引导至平衡的潜在空间。该方法在不增加计算成本的情况下，显著提升了文本对齐和目标保真度，并能与多种微调策略兼容。

> **摘要翻译:** 个性化文本到图像扩散模型对于使预训练模型适应特定目标概念、实现多样化图像生成至关重要。然而，使用少量图像进行微调引入了固有的权衡：在与目标分布对齐（例如，主体保真度）和保留原始模型的广泛知识（例如，文本可编辑性）之间。现有的采样引导方法，如无分类器引导（CFG）和自动引导（AG），未能有效地将输出引导至平衡空间：CFG限制了对目标分布的适应，而AG则损害了文本对齐。为了解决这些限制，我们提出了个性化引导，这是一种简单而有效的方法，它利用一个以空文本提示为条件的未学习弱模型。此外，我们的方法通过在推理过程中对预训练模型和微调模型之间的权重进行插值，动态地控制弱模型中未学习的程度。与仅依赖引导尺度的现有引导方法不同，我们的方法明确地将输出引导到平衡的潜在空间，而无需额外的计算开销。实验结果表明，我们提出的引导方法可以改善文本对齐和目标分布保真度，并与各种微调策略无缝集成。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [276] [Three-dimentional reconstruction of complex, dynamic population canopy architecture for crops with a novel point cloud completion model: A case study in Brassica napus rapeseed](https://arxiv.org/abs/2506.18292)
> *油菜复杂动态群体冠层结构三维重建：一种新型点云补全模型的案例研究*

*Ziyue Guo, Xin Yang, Yutao Shen, Yang Zhu, Lixi Jiang, Haiyan Cen* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 点云补全, 冠层结构, 三维重建, 油菜, 深度学习

**Comment:** 

> **TL;DR:** 提出CP-PCN模型，通过补全点云实现作物（油菜）复杂动态冠层的高精度3D重建，并提高了产量预测精度。

**AI_Comments:** 这篇论文的创新点在于提出了一个专门用于补全作物冠层点云的CP-PCN模型，有效解决了复杂冠层结构中常见的遮挡问题。通过结合多分辨率动态图卷积和点金字塔解码器，并引入动态图卷积特征提取器，模型能够捕捉作物生长周期中的结构变化，从而实现高精度的三维重建。此外，将重建结果应用于产量预测，并证实了其对预测准确率的提升，进一步凸显了其实用价值和重要性。该研究为作物表型组学和智能农业提供了新的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有感知技术在作物冠层3D重建中因严重遮挡而无法准确描述冠层结构，而完整的冠层结构对评估光合作用和产量至关重要。

**Method:** 提出了一种新型点云补全模型（CP-PCN）用于油菜复杂动态群体冠层3D重建。开发了一个完整的点云生成框架，通过区分表面点和遮挡点来自动标注训练数据集。CP-PCN网络设计包括多分辨率动态图卷积编码器（MRDG）和点金字塔解码器（PPD）来预测遮挡点。引入动态图卷积特征提取器（DGCFE）模块以增强特征提取并捕捉整个生长期的结构变化。

**Result:** CP-PCN在四个生长阶段的倒角距离（CD）值为3.35 cm - 4.51 cm，优于最先进的基于Transformer的方法（PoinTr）。消融研究证实了MRDG和DGCFE模块的有效性。验证实验表明，基于CP-PCN开发的角果效率指数使油菜产量预测的总体准确率比使用不完整点云提高了11.2%。

**Conclusion:** CP-PCN管道能够对作物群体冠层结构进行高精度三维重建，并有望推广到其他作物，显著推动田间群体冠层结构的定量分析。

> **ai_Abstract:** 本文提出了一种名为CP-PCN的新型点云补全模型，用于解决作物（以油菜为例）复杂动态群体冠层三维重建中因遮挡导致的数据不完整问题。该模型包含一个自动标注框架、多分辨率动态图卷积编码器（MRDG）、点金字塔解码器（PPD）和动态图卷积特征提取器（DGCFE）。实验结果表明，CP-PCN在重建精度上优于现有方法，并能有效提高作物产量预测的准确性。该方法有望推广至其他作物，促进田间冠层结构的定量分析。

> **摘要翻译:** 定量描述完整的冠层结构对于准确评估作物光合作用和产量表现以指导理想型设计至关重要。尽管已经开发了各种传感技术用于个体植物和冠层的三维（3D）重建，但由于复杂冠层结构之间严重的遮挡，它们未能获得冠层结构的准确描述。我们提出了一种有效的方法，利用一种新颖的点云补全模型对油菜作物的复杂动态群体冠层结构进行三维重建。开发了一个完整的点云生成框架，通过区分冠层内的表面点和遮挡点，实现训练数据集的自动标注。然后，设计了作物群体点云补全网络（CP-PCN），该网络包含一个多分辨率动态图卷积编码器（MRDG）和一个点金字塔解码器（PPD）来预测遮挡点。为了进一步增强特征提取，提出了一个动态图卷积特征提取器（DGCFE）模块，以捕捉整个油菜生长期的结构变化。结果表明，CP-PCN在四个生长阶段的倒角距离（CD）值为3.35 cm - 4.51 cm，优于最先进的基于Transformer的方法（PoinTr）。消融研究证实了MRDG和DGCFE模块的有效性。此外，验证实验表明，基于CP-PCN开发的角果效率指数使油菜产量预测的总体准确率比使用不完整点云提高了11.2%。CP-PCN管道有潜力推广到其他作物，显著推动田间群体冠层结构的定量分析。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [282] [Accurate Cross-modal Reconstruction of Vehicle Target from Sparse-aspect Multi-baseline SAR data](https://arxiv.org/abs/2406.04158)
> *从稀疏角度多基线SAR数据精确跨模态重建车辆目标*

*Da Li, Guoqiang Zhao, Chen Yao, Kaiqiang Zhu, Houjun Sun, Jiacheng Bao, Maokun Li* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-01**

**Keywords:** SAR三维成像, 跨模态学习, 车辆重建, 深度学习, 稀疏数据

**Comment:** 

> **TL;DR:** CMAR-Net利用跨模态学习和光学图像，从稀疏SAR数据中精确重建三维车辆目标，优于现有方法。

**AI_Comments:** 本文通过超越三维SAR重建中的单模态学习，引入了一项重要创新。利用光学图像的跨模态监督与可微分渲染相结合，是一种有效解决稀疏SAR数据局限性的新颖方法。其从模拟数据到真实世界数据的强大泛化能力尤其令人印象深刻，表明这是一种稳健且实用的遥感应用解决方案。这项工作为雷达成像中整合多样化数据源开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 多角度多基线SAR三维成像在城市测绘和监测中至关重要，但稀疏观测会导致成像质量下降，尤其对于车辆等各向异性小目标。传统的压缩感知（CS）和新兴的深度学习（DL）方法在稀疏三维SAR重建中存在局限性：现有DL方法通常仅使用高分辨率雷达图像进行训练（单模态学习），排除了融合其他数据源互补信息的可能性，从而限制了重建性能的进一步提升。

**Method:** 本文引入了跨模态学习，并提出了一种跨模态三维SAR重建网络（CMAR-Net）。该网络通过融合异构信息来增强稀疏三维SAR重建。它利用来自二维光学图像的跨模态监督以及可微分渲染保证的误差传播。

**Result:** CMAR-Net实现了高效训练，并将高度稀疏角度的多基线SAR图像重建为视觉上结构化且精确的三维图像，尤其适用于车辆目标。CMAR-Net仅在模拟数据上进行训练，但在包含大量民用车辆的停车场测量等广泛真实世界评估中表现出强大的泛化能力，在结构精度方面优于最先进的CS和DL方法。

**Conclusion:** 本工作突出了跨模态学习在三维SAR重建中的潜力，并为雷达成像研究引入了一个新颖的框架。

> **ai_Abstract:** 本文旨在解决稀疏观测下三维SAR成像（特别是车辆目标）的挑战，现有单模态深度学习方法在此方面表现不足。论文提出了一种新颖的跨模态学习框架CMAR-Net，该框架融合了异构信息，特别是利用二维光学图像进行监督和可微分渲染。CMAR-Net能够高效地从稀疏SAR数据中重建出精确且结构化的三维车辆目标。在仅使用模拟数据训练后，该网络在真实世界数据上进行了评估，结果表明其在泛化能力和结构精度方面均优于最先进的压缩感知和深度学习方法，突显了跨模态学习在三维SAR重建中的潜力。

> **摘要翻译:** 多角度多基线SAR三维成像是一项关键的遥感技术，在城市测绘和监测中具有广阔前景。然而，由于飞行轨迹受限导致的稀疏观测会降低成像质量，特别是对于车辆和飞机等各向异性小目标。过去，压缩感知（CS）是稀疏三维SAR重建的主流方法。最近，深度学习（DL）作为一种强大的替代方案出现，通过其强大的数据驱动表示能力和快速推理特性，显著提升了重建质量和效率。然而，现有的DL方法通常只使用高分辨率雷达图像训练深度神经网络（DNN）。这种单模态学习范式排除了融合来自其他数据源的互补信息的可能性，从而限制了重建性能的潜在提升。在本文中，我们引入了跨模态学习，并提出了一种跨模态三维SAR重建网络（CMAR-Net），通过融合异构信息来增强稀疏三维SAR重建。CMAR-Net利用来自二维光学图像的跨模态监督以及可微分渲染保证的误差传播，实现了高效训练，并将高度稀疏角度的多基线SAR图像重建为视觉上结构化且精确的三维图像，尤其适用于车辆目标。CMAR-Net仅在模拟数据上进行训练，但在包含大量民用车辆的停车场测量等广泛真实世界评估中表现出强大的泛化能力，在结构精度方面优于最先进的CS和DL方法。我们的工作突出了跨模态学习在三维SAR重建中的潜力，并为雷达成像研究引入了一个新颖的框架。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [284] [CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry](https://arxiv.org/abs/2508.00568)
> *CoProU-VO：结合投影不确定性的端到端无监督单目视觉里程计*

*Jingchao Xie, Oussema Dhaouadi, Weirong Chen, Johannes Meier, Jacques Kaiser, Daniel Cremers* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 视觉里程计, 无监督学习, 不确定性建模, 动态场景, 视觉Transformer

**Comment:** Accepted for GCPR 2025. Project page:
  https://jchao-xie.github.io/CoProU/

> **TL;DR:** CoProU-VO是一种新的无监督单目视觉里程计方法，通过结合跨帧投影不确定性来处理动态场景中的挑战，并在KITTI和nuScenes数据集上表现出色。

**AI_Comments:** 该论文的创新点在于提出了跨帧不确定性传播和结合的理念，以解决动态场景对无监督单目VO的影响。通过结合投影不确定性，CoProU-VO能够更鲁棒地识别和过滤动态对象，从而提高姿态估计的准确性。其重要性体现在提升了无监督VO在现实复杂环境中的实用性。局限性方面，抽象中未明确提及，但通常基于学习的方法可能存在泛化性问题或对特定类型动态场景的敏感性。

<details>
  <summary>Details</summary>

**Motivation:** 无监督视觉里程计方法在动态场景中由于静态场景假设被违反而导致姿态估计错误。传统的不确定性建模仅考虑单帧信息，忽略了连续帧之间的不确定性，无法有效识别不可靠区域。

**Method:** 提出了CoProU-VO，一种端到端的方法，它使用概率公式将目标帧不确定性与投影参考帧不确定性相结合。该模型基于视觉transformer骨干网络，同时学习深度、不确定性估计和相机姿态。

**Result:** 在KITTI和nuScenes数据集上，CoProU-VO比以前的无监督单目端到端双帧方法有显著改进。在其他方法常失败的挑战性高速公路场景中表现出强大的性能。消融研究验证了跨帧不确定性传播的有效性。

**Conclusion:** CoProU-VO通过结合跨帧投影不确定性，有效解决了动态场景中无监督单目视觉里程计的挑战，显著提升了性能。

> **ai_Abstract:** 该论文介绍了CoProU-VO，一种针对无监督单目视觉里程计的新型端到端方法。为了解决动态场景中姿态估计不准确的问题，CoProU-VO创新性地结合了跨帧投影不确定性，通过概率公式整合目标帧和参考帧的不确定性。该模型基于视觉transformer，能够同时学习深度、不确定性及相机姿态。实验结果显示，CoProU-VO在KITTI和nuScenes数据集上显著优于现有方法，尤其在复杂动态的高速公路场景中表现出色。

> **摘要翻译:** 视觉里程计（VO）是自主导航、机器人技术和增强现实的基础，其中无监督方法消除了对昂贵地面真值标签的需求。然而，当动态物体违反静态场景假设时，这些方法会遇到困难，导致错误的姿态估计。我们通过不确定性建模来解决这个问题，这是一种常用技术，可以在不要求显式运动分割的情况下创建鲁棒掩码以过滤掉动态物体和遮挡。传统的不确定性建模只考虑单帧信息，忽略了连续帧之间的不确定性。我们的关键见解是，不确定性必须在时间帧之间传播和组合，才能有效识别不可靠区域，尤其是在动态场景中。为了应对这一挑战，我们引入了结合投影不确定性VO（CoProU-VO），这是一种新颖的端到端方法，它使用概率公式将目标帧不确定性与投影参考帧不确定性相结合。我们的模型建立在视觉transformer骨干网络之上，同时学习深度、不确定性估计和相机姿态。因此，在KITTI和nuScenes数据集上的实验表明，与以前的无监督单目端到端双帧方法相比，CoProU-VO取得了显著改进，并在其他方法经常失败的挑战性高速公路场景中表现出强大的性能。此外，全面的消融研究验证了跨帧不确定性传播的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [288] [Spectral Sensitivity Estimation with an Uncalibrated Diffraction Grating](https://arxiv.org/abs/2508.00330)
> *使用未校准衍射光栅进行光谱敏感度估计*

*Lilika Makabe, Hiroaki Santo, Fumio Okura, Michael S. Brown, Yasuyuki Matsushita* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 光谱敏感度, 衍射光栅, 相机校准, 计算机视觉, 颜色校正

**Comment:** 

> **TL;DR:** 该论文提出了一种使用未校准衍射光栅来精确校准相机光谱敏感度的方法，该方法简单实用且优于现有方法。

**AI_Comments:** 该论文的创新之处在于提出了一种无需昂贵专用设备（如窄带滤光片或校准参考目标）即可校准相机光谱敏感度的方法，仅需一个易于获取的未校准衍射光栅。这种方法显著降低了校准的门槛和成本，提升了实用性。通过闭合形式的参数估计，也可能提高了校准的效率和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 准确校准相机光谱敏感度对于各种计算机视觉任务至关重要，包括颜色校正、光照估计和材料分析。

**Method:** 本方法仅需一个市售的未校准衍射光栅片。通过捕获直接照明及其通过光栅片的衍射图案图像，该方法以闭合形式估计相机光谱敏感度和衍射光栅参数。

**Result:** 在合成数据和真实世界数据上的实验表明，该方法优于传统的基于参考目标的方法。

**Conclusion:** 该方法在相机光谱敏感度估计方面有效且实用，优于传统方法。

> **ai_Abstract:** 该论文提出了一种新颖实用的相机光谱敏感度校准方法，仅需一个未校准的衍射光栅片。与传统方法不同，该方法通过捕捉直接照明和衍射图案的图像，以闭合形式同时估计相机光谱敏感度和衍射光栅参数。实验证明，该方法在合成和真实数据上均优于现有基于参考目标的方法，展现出其高效性和实用性。

> **摘要翻译:** 本文介绍了一种使用衍射光栅的实用且精确的相机光谱敏感度校准方法。相机光谱敏感度的精确校准对于各种计算机视觉任务至关重要，包括颜色校正、光照估计和材料分析。与现有需要专用窄带滤光片或已知光谱反射率参考目标的方法不同，我们的方法仅需要一个市售的未校准衍射光栅片。通过捕获直接照明及其通过光栅片的衍射图案图像，我们的方法以闭合形式估计相机光谱敏感度和衍射光栅参数。在合成数据和真实世界数据上的实验表明，我们的方法优于传统的基于参考目标的方法，突显了其有效性和实用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [295] [HumaniBench: A Human-Centric Framework for Large Multimodal Models Evaluation](https://arxiv.org/abs/2505.11454)
> *HumaniBench：一个以人为中心的大型多模态模型评估框架*

*Shaina Raza, Aravind Narayanan, Vahid Reza Khazaie, Ashmal Vayani, Mukund S. Chettiar, Amandeep Singh, Mubarak Shah, Deval Pandya* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** HumaniBench, 大型多模态模型, AI伦理, 公平性, 负责任AI

**Comment:** 

> **TL;DR:** HumaniBench是一个新的基准测试，旨在评估大型多模态模型在公平性、伦理和包容性等人本价值观方面的对齐情况，发现现有模型在此方面表现不足，并提供诊断工具以促进负责任的开发。

**AI_Comments:** 本文引入的HumaniBench是一个具有创新性的贡献，它填补了大型多模态模型在以人为中心价值观评估方面的空白。其重要性在于提供了一个标准化的、多维度的评估框架，有助于诊断现有模型的局限性，并引导未来模型的负责任发展。通过结合AI辅助和专家验证的数据标注流程，保证了数据集的质量。公开数据和代码的做法也促进了研究的透明度和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 大型多模态模型（LMMs）在视觉问答、图像描述等任务上得到了广泛测试，但缺乏对齐公平性、伦理和包容性等以人为中心（HC）价值观的严格评估。

**Method:** 研究引入了HumaniBench，一个包含32,000个真实世界图像-问题对的新型基准测试和评估套件。标签通过AI辅助流水线生成并由专家验证。HumaniBench通过多样化的开放式和封闭式VQA任务，评估LMMs在公平性、伦理、同理心、包容性、推理、鲁棒性和多语言性七个关键对齐原则上的表现。

**Result:** 对不同LMMs的基准测试结果显示，专有模型在推理、公平性和多语言性方面通常领先，而开源模型在鲁棒性和接地性方面表现出色。大多数模型难以平衡准确性与道德和包容性行为。链式思考提示和测试时缩放等技术可以改善对齐。

**Conclusion:** HumaniBench是第一个专门针对以人为中心对齐的基准测试，提供了一个严格的测试平台来诊断现有模型的局限性，并促进负责任的LMM开发。

> **ai_Abstract:** HumaniBench是一个新颖的基准测试框架，旨在解决大型多模态模型（LMMs）在以人为中心的价值观（如公平性、伦理和包容性）方面评估不足的问题。它包含32,000个图像-问题对，并根据公平性、伦理、同理心、包容性、推理、鲁棒性和多语言性七项原则评估LMMs。基准测试结果表明，当前模型在平衡准确性与道德行为方面存在挑战。HumaniBench为负责任的LMM开发提供了一个重要的诊断工具，所有数据和代码均已公开。

> **摘要翻译:** 大型多模态模型（LMMs）已在视觉问答（VQA）、图像描述和接地等任务中得到广泛测试，但缺乏对齐公平性、伦理和包容性等以人为中心（HC）价值观的严格评估。为了弥补这一空白，我们引入了\textbf{HumaniBench}，一个包含32,000个真实世界图像-问题对的新型基准测试和评估套件。标签通过AI辅助流水线生成并由专家验证。HumaniBench通过多样化的开放式和封闭式VQA任务，评估LMMs在七个关键对齐原则上的表现：公平性、伦理、同理心、包容性、推理、鲁棒性和多语言性。这些原则植根于AI伦理和现实世界需求，为社会影响提供了整体视角。对不同LMM的基准测试结果显示，专有模型在推理、公平性和多语言性方面通常领先，而开源模型在鲁棒性和接地性方面表现出色。大多数模型难以平衡准确性与道德和包容性行为。链式思考提示和测试时缩放等技术可以改善对齐。作为第一个专门针对HC对齐的基准测试，HumaniBench提供了一个严格的测试平台来诊断局限性，并促进负责任的LMM开发。所有数据和代码均公开可用以供复现。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [296] [ProtoSolo: Interpretable Image Classification via Single-Prototype Activation](https://arxiv.org/abs/2506.19808)
> *ProtoSolo：通过单原型激活实现可解释图像分类*

*Yitao Peng, Lianghua He, Hongzhou Chen* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 可解释AI, 图像分类, 原型网络, 单原型激活, 认知复杂性

**Comment:** 

> **TL;DR:** ProtoSolo 是一种新型可解释深度学习架构，通过仅激活单个原型进行图像分类，显著简化了模型解释，同时保持了与现有可解释方法相当的分类精度。

**AI_Comments:** ProtoSolo 的创新之处在于其“单原型激活”的设计，这直接解决了现有原型网络中多原型带来的认知负担，显著提升了模型的可解释性。通过用特征图代替全通道特征向量，并引入非投影学习策略，该方法在简化解释的同时，也有效保持甚至提升了性能，这对于需要高透明度的AI应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可解释原型网络在协同决策中需要多个原型，这增加了认知复杂性并阻碍了用户理解。

**Method:** ProtoSolo 仅需激活单个原型即可完成分类，简化了解释。它用特征图代替全通道特征向量进行相似性比较和原型学习，以利用更丰富的全局信息。此外，引入了非投影原型学习策略，以保持原型与图像块的关联，并避免网络结构突变。

**Result:** 在 CUB-200-2011 和 Stanford Cars 数据集上的实验表明，ProtoSolo 在分类精度上与最先进的可解释方法相匹配，同时实现了最低的认知复杂性。

**Conclusion:** ProtoSolo 通过单原型激活设计，显著简化了图像分类模型的解释性，并在保持高精度的同时降低了认知复杂性，是可解释深度学习领域的一项重要进展。

> **ai_Abstract:** ProtoSolo 提出了一种新颖的可解释图像分类深度学习架构，旨在解决现有原型网络中多原型导致认知复杂性高的问题。ProtoSolo 的核心创新在于其单原型激活机制，即每个类别只需激活一个原型进行决策，这大大简化了模型解释。此外，它采用特征图进行相似性比较和原型学习，以捕获更丰富的全局信息，并引入非投影原型学习策略来维持原型与图像块的关联性。实验证明，ProtoSolo 在保证分类精度的同时，显著降低了模型的解释复杂性，达到了最先进可解释方法的水平。

> **摘要翻译:** 尽管可解释原型网络提高了深度学习图像分类的透明度，但协同决策中对多个原型的需求增加了认知复杂性并阻碍了用户理解。为了解决这个问题，本文提出了一种新颖的可解释深度图像分类架构，称为 ProtoSolo。与现有原型网络不同，ProtoSolo 只需激活单个原型即可完成分类。这种设计显著简化了解释，因为对每个类别的解释只需显示具有最高相似性得分的原型及其对应的特征图。此外，传统的全通道特征向量被特征图取代，用于相似性比较和原型学习，从而可以在单原型激活决策中使用更丰富的全局信息。还引入了一种非投影原型学习策略，以在保持原型与图像块之间关联的同时，避免投影引起的网络结构突变，这可能会影响分类性能。在 CUB-200-2011 和 Stanford Cars 数据集上的实验表明，ProtoSolo 在分类精度上与最先进的可解释方法相匹配，同时实现了最低的认知复杂性。代码可在 https://github.com/pyt19/ProtoSolo 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [300] [GUIOdyssey: A Comprehensive Dataset for Cross-App GUI Navigation on Mobile Devices](https://arxiv.org/abs/2406.08451)
> *GUIOdyssey：一个用于移动设备跨应用GUI导航的综合数据集*

*Quanfeng Lu, Wenqi Shao, Zitao Liu, Lingxiao Du, Fanqing Meng, Boxuan Li, Botong Chen, Siyuan Huang, Kaipeng Zhang, Ping Luo* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** GUI导航, 跨应用, 数据集, 移动设备, 自主代理

**Comment:** 22 pages, 14 figures, ICCV 2025, a cross-app GUI navigation dataset

> **TL;DR:** GUIOdyssey是一个用于移动设备跨应用GUI导航的综合数据集，并基于此开发了OdysseyAgent，显著提升了复杂跨应用任务的性能。

**AI_Comments:** 该论文的创新点在于构建了一个专门用于跨应用GUI导航的综合数据集GUIOdyssey，这填补了现有数据集多集中于单应用内任务的空白。同时，提出的OdysseyAgent及其历史重采样模块，有效地解决了长步骤跨应用任务中的性能和推理速度平衡问题。这项工作对于推动移动设备上的自主GUI代理发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 先前的GUI代理主要基于单应用内任务数据集进行训练，导致在跨应用导航方面表现不佳。

**Method:** 本文提出了GUIOdyssey，一个包含8,334个导航片段的综合性跨应用移动GUI导航数据集，覆盖了多种设备、应用和应用组合，并为每个步骤提供了详细的语义推理标注。在此基础上，开发了OdysseyAgent，一个用于长步骤跨应用导航的探索性多模态代理，其配备了历史重采样模块。

**Result:** 在域内和域外场景的广泛实验验证了所提方法的有效性。此外，研究表明数据集中包含动作、屏幕截图和上下文的历史信息可以显著增强OdysseyAgent在复杂跨应用任务上的性能。

**Conclusion:** GUIOdyssey数据集和OdysseyAgent代理有效地解决了移动设备上的跨应用GUI导航难题，并通过历史信息增强了性能。

> **ai_Abstract:** 本文针对现有GUI代理在跨应用导航中表现不佳的问题，提出了GUIOdyssey数据集。该数据集是一个综合性的跨应用移动GUI导航数据集，包含大量导航片段和丰富的语义推理标注。基于此数据集，研究人员开发了OdysseyAgent，一个探索性多模态代理，能够处理长步骤跨应用导航任务，并通过历史重采样模块优化了性能和推理速度。实验证明，该方法在各种场景下均有效，并且历史信息对于提升复杂跨应用任务的性能至关重要。

> **摘要翻译:** 自主图形用户界面（GUI）导航代理可以通过简化工作流程和减少人工干预来增强通信、娱乐和生产力方面的用户体验。然而，先前的GUI代理通常使用在单个应用程序内即可完成任务的数据集进行训练，导致在跨应用程序导航方面表现不佳。为了解决这个问题，我们提出了GUIOdyssey，一个用于跨应用程序移动GUI导航的综合数据集。GUIOdyssey包含8,334个导航片段，平均每个片段15.3个步骤，涵盖6种移动设备、212个不同的应用程序和1,357种应用程序组合。每个步骤都富含详细的语义推理标注，这有助于模型构建认知过程并增强其处理复杂跨应用程序任务的推理能力。基于GUIOdyssey，我们开发了OdysseyAgent，一个用于长步骤跨应用程序导航的探索性多模态代理，该代理配备了一个历史重采样模块，可以有效地关注历史屏幕截图令牌，平衡性能和推理速度。在域内和域外场景进行的广泛实验验证了我们方法的有效性。此外，我们证明了数据集中涉及动作、屏幕截图和上下文的历史信息可以显著增强OdysseyAgent在复杂跨应用程序任务上的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [303] [Analyze-Prompt-Reason: A Collaborative Agent-Based Framework for Multi-Image Vision-Language Reasoning](https://arxiv.org/abs/2508.00356)
> *分析-提示-推理：一个用于多图像视觉-语言推理的协作代理框架*

*Angelos Vlachos, Giorgos Filandrianos, Maria Lymperaiou, Nikolaos Spanos, Ilias Mitsouras, Vasileios Karampinis, Athanasios Voulodimos* | **Category: cs.CV, cs.MA, I.2; I.2.7** | **Updated: 2025-08-01**

**Keywords:** 多图像推理, 视觉-语言模型, 代理框架, 提示工程, 多模态推理

**Comment:** 

> **TL;DR:** 一个双代理框架（PromptEngineer + VisionReasoner）使大型视觉-语言模型（LVLMs）能够通过信息丰富的提示有效地进行多图像推理，并在多样化的视觉推理任务上取得了强大的性能。

**AI_Comments:** 该论文的创新之处在于其无需训练、模块化的双代理方法，该方法利用提示工程来增强大型视觉-语言模型（LVLMs）的多图像推理能力，并在不进行显式训练的情况下，展示了强大的泛化能力和在各种任务上的高性能。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决跨不同数据集和任务格式的交错多模态推理挑战，特别是多图像视觉-语言推理。

**Method:** 本文提出了一个协作的、基于代理的框架，用于多图像推理。该方法采用双代理系统：一个基于语言的PromptEngineer，负责生成上下文感知、任务特定的提示；一个VisionReasoner，一个大型视觉-语言模型（LVLM），负责最终推理。该框架是全自动、模块化且无需训练的，能够泛化到涉及一个或多个输入图像的分类、问答和自由形式生成任务。

**Result:** 研究结果表明，在信息丰富的提示引导下，LVLMs可以有效地对多幅图像进行推理。在2025年MIRAGE挑战赛（A轨道）的18个多样化数据集上进行了评估，涵盖了文档问答、视觉比较、基于对话的理解和场景级推理等广泛的视觉推理任务。值得注意的是，Claude 3.7在TQA（99.13%准确率）、DocVQA（96.87%）和MMCoQA（75.28 ROUGE-L）等具有挑战性的任务上取得了接近上限的性能。论文还探讨了模型选择、样本数量和输入长度等设计选择如何影响不同LVLMs的推理性能。

**Conclusion:** 信息丰富的提示显著增强了大型视觉-语言模型（LVLMs）对多图像进行推理的能力，并在各种视觉推理任务中表现出强大的性能。

> **ai_Abstract:** 该论文介绍了“Analyze-Prompt-Reason”，一个无需训练的协作双代理框架，用于多图像视觉-语言推理。该框架利用PromptEngineer生成任务特定的提示，并由VisionReasoner（大型视觉-语言模型）进行推理，以解决跨多样化多模态任务的挑战。该方法在2025年MIRAGE挑战赛的18个数据集上进行了评估，结果表明，信息丰富的提示能够使大型视觉-语言模型（如Claude 3.7）在文档问答和视觉比较等任务上达到高水平性能，突出了提示工程对多图像推理的影响。

> **摘要翻译:** 我们提出了一个用于多图像推理的协作代理框架。我们的方法通过采用双代理系统来应对跨不同数据集和任务格式的交错多模态推理挑战：一个基于语言的PromptEngineer，负责生成上下文感知、任务特定的提示；以及一个VisionReasoner，一个大型视觉-语言模型（LVLM），负责最终推理。该框架是全自动、模块化且无需训练的，能够泛化到涉及一个或多个输入图像的分类、问答和自由形式生成任务。我们在2025年MIRAGE挑战赛（A轨道）的18个多样化数据集上评估了我们的方法，涵盖了包括文档问答、视觉比较、基于对话的理解和场景级推理在内的广泛视觉推理任务。我们的结果表明，当有信息丰富的提示引导时，LVLMs可以有效地对多幅图像进行推理。值得注意的是，Claude 3.7在TQA（99.13%准确率）、DocVQA（96.87%）和MMCoQA（75.28 ROUGE-L）等具有挑战性的任务上取得了接近上限的性能。我们还探讨了设计选择——例如模型选择、样本数量和输入长度——如何影响不同LVLMs的推理性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [314] [Uncertainty-Aware Likelihood Ratio Estimation for Pixel-Wise Out-of-Distribution Detection](https://arxiv.org/abs/2508.00587)
> *用于像素级分布外检测的不确定性感知似然比估计*

*Marc Hölle, Walter Kellermann, Vasileios Belagiannis* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 不确定性感知, 似然比估计, 分布外检测, 语义分割, 自动驾驶

**Comment:** Accepted at ICCVW 2025, 11 pages, 4 figures

> **TL;DR:** 本文提出了一种不确定性感知的似然比估计方法，用于像素级分布外检测，解决了现有方法在复杂场景中将稀有已知对象误分类为未知对象的问题，并在基准数据集上取得了SOTA性能。

**AI_Comments:** 该研究的创新点在于将不确定性感知引入像素级分布外检测的似然比估计中，特别是通过输出概率分布来捕捉不确定性，这使得异常值暴露技术能更有效地利用。其在自动驾驶等安全关键领域具有重要意义，因为它能提高模型识别未知对象的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 语义分割模型在现实世界的自动驾驶场景中，常将未知对象自信地错误分类。尽管像素级分布外检测可以识别未知对象，但现有方法在复杂场景中难以区分稀有已知对象和真正未知对象。

**Method:** 我们引入了一种不确定性感知的似然比估计方法，该方法在似然比测试中结合证据分类器，以区分语义分割模型中的已知和未知像素特征，并明确考虑不确定性。它输出概率分布而非点估计，以捕获稀有训练样本和不完美合成异常值带来的不确定性。

**Result:** 在五个标准基准数据集上，我们的方法实现了最先进技术中最低的平均误报率 (2.5%)，同时保持了高平均精度 (90.91%)，并且只产生可忽略的计算开销。

**Conclusion:** 通过整合不确定性，该方法能更有效地利用异常值暴露，并在像素级分布外检测中表现出优越性。

> **ai_Abstract:** 本文提出了一种不确定性感知的似然比估计方法（ULRE），用于解决语义分割模型在自动驾驶中将未知对象误分类的问题。该方法通过在似然比测试中结合证据分类器，显式地处理不确定性，输出概率分布以区分已知和未知像素特征。实验证明，该方法在多个基准数据集上实现了较低的误报率和较高的精度，且计算开销可忽略。

> **摘要翻译:** 在已知对象类别上训练的语义分割模型在现实世界的自动驾驶场景中常常失效，它们会自信地错误分类未知对象。虽然像素级分布外检测可以识别未知对象，但现有方法在复杂场景中表现不佳，因为稀有对象类别经常与真正的未知对象混淆。我们引入了一种不确定性感知的似然比估计方法来解决这些局限性。我们的方法在似然比测试中使用证据分类器，以区分语义分割模型中的已知和未知像素特征，同时明确考虑不确定性。我们的方法不产生点估计，而是输出概率分布，捕获来自稀有训练样本和不完美合成异常值的不确定性。我们表明，通过这种方式整合不确定性，可以更有效地利用异常值暴露。在五个标准基准数据集上进行评估，我们的方法在保持高平均精度 (90.91%) 的同时，实现了最先进技术中最低的平均误报率 (2.5%)，并且只产生可忽略的计算开销。代码可在 https://github.com/glasbruch/ULRE 获得。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [315] [DINO-R1: Incentivizing Reasoning Capability in Vision Foundation Models](https://arxiv.org/abs/2505.24025)
> *DINO-R1：激励视觉基础模型的推理能力*

*Chenbin Pan, Wenbin He, Zhengzhong Tu, Liu Ren* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 视觉基础模型, 推理能力, 强化学习, DINO-R1, GRQO

**Comment:** 

> **TL;DR:** DINO-R1是首次尝试利用强化学习（通过GRQO）为视觉基础模型赋予视觉情境推理能力，并在开放词汇和封闭集场景中显著优于监督微调基线。

**AI_Comments:** 该论文通过将强化学习技术（此前在大型语言模型推理中取得成功）扩展到视觉基础模型领域，做出了重要贡献。GRQO的引入是强化学习在基于查询的视觉模型方面的一次创新性适应，解决了视觉数据和表示学习的独特挑战。这项工作为开发更强大、更具泛化能力的视觉模型开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（如DeepSeek-R1）通过基于强化学习的微调框架（如GRPO）在推理能力方面取得了显著成功。然而，视觉基础模型（包括DINO系列等表示模型）中这种推理能力尚未得到充分探索，并且明显缺失。本文旨在解决这一空白。

**Method:** 本文提出了DINO-R1，这是首次尝试使用强化学习来激励视觉基础模型的视觉情境推理能力。具体来说，DINO-R1引入了组相对查询优化（GRQO），这是一种新颖的强化学习式训练策略，专为基于查询的表示模型设计，它根据组归一化对齐质量计算查询级别的奖励。研究还应用了KL正则化来稳定目标分布，以减少训练的不稳定性。这种联合优化能够在查询之间实现密集且富有表现力的监督，同时减轻过拟合和分布漂移。DINO-R1建立在Grounding-DINO之上，整合了视觉提示编码器和视觉引导的查询选择机制。

**Result:** 在COCO、LVIS和ODinW数据集上进行的广泛实验表明，DINO-R1显著优于监督微调基线，并在开放词汇和封闭集视觉提示场景中都实现了强大的泛化能力。

**Conclusion:** DINO-R1成功地利用强化学习为视觉基础模型赋予了视觉情境推理能力，通过引入GRQO和KL正则化，实现了优于传统监督方法的性能和泛化能力。

> **ai_Abstract:** 本文提出了DINO-R1，一种新颖的方法，它利用强化学习，特别是组相对查询优化（GRQO），来为视觉基础模型注入视觉情境推理能力，弥补了与大型语言模型相比该领域能力的不足。DINO-R1建立在Grounding-DINO之上，并结合了KL正则化，实现了密集的监督同时保持了训练稳定性。在COCO、LVIS和ODinW等多个数据集上的实验结果证实，DINO-R1在开放词汇和封闭集视觉提示任务中均显著超越了监督微调基线，并展现出强大的泛化能力。

> **摘要翻译:** 最近，大型语言模型（如DeepSeek-R1）在推理能力方面引起了爆炸性兴趣，并通过基于强化学习的微调框架（例如组相对策略优化（GRPO）等方法）展示了显著成功。然而，这种推理能力在视觉基础模型（包括DINO系列等表示模型）中仍未得到充分探索且明显缺失。在这项工作中，我们提出了DINO-R1，这是首次尝试利用强化学习来激励视觉基础模型的视觉情境推理能力。具体来说，DINO-R1引入了组相对查询优化（GRQO），这是一种新颖的强化学习式训练策略，专为基于查询的表示模型设计，它根据组归一化对齐质量计算查询级别的奖励。我们还应用了KL正则化来稳定目标分布，以减少训练的不稳定性。这种联合优化能够在查询之间实现密集且富有表现力的监督，同时减轻过拟合和分布漂移。基于Grounding-DINO，我们训练了一系列DINO-R1家族模型，这些模型集成了视觉提示编码器和视觉引导的查询选择机制。在COCO、LVIS和ODinW上的广泛实验表明，DINO-R1显著优于监督微调基线，在开放词汇和封闭集视觉提示场景中都实现了强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [316] [Cross-Modal Dual-Causal Learning for Long-Term Action Recognition](https://arxiv.org/abs/2507.06603)
> *跨模态双因果学习用于长期动作识别*

*Xu Shaowu, Jia Xibin, Gao Junyu, Sun Qianmei, Chang Jing, Fan Chao* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 长期动作识别, 跨模态学习, 因果推断, 视觉-语言模型, 动作表示

**Comment:** 

> **TL;DR:** 本文提出了一种名为CMDCL的跨模态双因果学习方法，通过引入结构因果模型和进行文本及视觉因果干预，解决长期动作识别中复杂的动作关联和视觉混淆问题，提升了动作表示的鲁棒性。

**AI_Comments:** 该论文的创新点在于提出了跨模态双因果学习（CMDCL），明确地将结构因果模型引入到长期动作识别中，以解决视觉-语言模型中常见的统计相关性而非因果机制的问题。通过文本和视觉的双重因果干预，有效地处理了跨模态偏差和视觉混淆因素，提升了模型在复杂场景下的鲁棒性。这对于推动因果推断在多模态学习和视频理解领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 长期动作识别（LTAR）面临挑战，原因在于时间跨度长、原子动作相关性复杂以及存在视觉混淆因素。尽管视觉-语言模型（VLMs）表现出潜力，但它们通常依赖统计相关性而非因果机制。此外，现有基于因果关系的方法解决了模态特异性偏差，但缺乏跨模态因果建模，限制了它们在基于VLM的LTAR中的效用。

**Method:** 本文提出了跨模态双因果学习（CMDCL），引入了一个结构因果模型来揭示视频和标签文本之间的因果关系。CMDCL通过文本因果干预解决文本嵌入中的跨模态偏差，并通过由去偏文本引导的视觉因果干预消除视觉模态固有的混淆因素。这些双重因果干预能够实现鲁棒的动作表示。

**Result:** 在Charades、Breakfast和COIN三个基准数据集上的实验结果表明了所提出模型的有效性。

**Conclusion:** 通过跨模态双因果干预，CMDCL能够解决长期动作识别中的复杂挑战，并生成鲁棒的动作表示，从而在多个基准数据集上取得了有效性能。

> **ai_Abstract:** 本文提出了一种名为跨模态双因果学习（CMDCL）的新方法，旨在解决长期动作识别（LTAR）中复杂的动作相关性和视觉混淆问题。针对现有视觉-语言模型依赖统计相关性而非因果机制，以及现有因果方法缺乏跨模态因果建模的局限性，CMDCL引入了一个结构因果模型来揭示视频与文本标签间的因果关系。该方法通过文本因果干预处理文本嵌入中的跨模态偏差，并利用去偏文本引导视觉因果干预，以消除视觉模态的混淆因素。这些双重因果干预有效提升了动作表示的鲁棒性。实验结果在Charades、Breakfast和COIN等基准数据集上验证了CMDCL的有效性。

> **摘要翻译:** 长期动作识别（LTAR）由于时间跨度长、复杂的原子动作相关性以及视觉混淆因素而极具挑战性。尽管视觉-语言模型（VLMs）已显示出前景，但它们通常依赖统计相关性而非因果机制。此外，现有基于因果关系的方法解决了模态特异性偏差，但缺乏跨模态因果建模，限制了它们在基于VLM的LTAR中的效用。本文提出了跨模态双因果学习（CMDCL），它引入了一个结构因果模型来揭示视频和标签文本之间的因果关系。CMDCL通过文本因果干预解决文本嵌入中的跨模态偏差，并通过由去偏文本引导的视觉因果干预消除视觉模态固有的混淆因素。这些双重因果干预能够实现鲁棒的动作表示，以应对LTAR的挑战。在包括Charades、Breakfast和COIN在内的三个基准数据集上的实验结果证明了所提出模型的有效性。我们的代码可在https://github.com/xushaowu/CMDCL获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [318] [Stable at Any Speed: Speed-Driven Multi-Object Tracking with Learnable Kalman Filtering](https://arxiv.org/abs/2508.00358)
> *任何速度下都稳定：基于速度驱动的可学习卡尔曼滤波多目标跟踪*

*Yan Gong, Mengjun Chen, Hao Liu, Gao Yongsheng, Lei Yang, Naibang Wang, Ziying Song, Haoqun Ma* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 多目标跟踪, 卡尔曼滤波, 自动驾驶, 速度适应, 不确定性建模

**Comment:** 9 pages, 7 figures, 5 tables

> **TL;DR:** 针对自动驾驶中传统多目标跟踪在高速动态场景下稳定性差的问题，本文提出了一个速度引导的可学习卡尔曼滤波器（SG-LKF），通过MotionScaleNet动态调整不确定性建模，并在多个基准测试中取得了领先结果。

**AI_Comments:** 本文的创新点在于认识到自车速度对多目标跟踪中不确定性建模的关键影响，并提出了可学习的卡尔曼滤波器（SG-LKF）来动态适应这种变化。通过引入MotionScaleNet和自监督轨迹一致性损失，有效提升了在高速动态场景下的跟踪稳定性与准确性。其在多个基准测试中取得的领先成绩证明了该方法的有效性和重要性，尤其对于自动驾驶等对实时性和鲁棒性要求极高的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的多目标跟踪（MOT）方法依赖于静态坐标变换，忽略了自车速度引起的观测噪声变化和参考系改变，导致在动态、高速场景下跟踪的稳定性和准确性下降。

**Method:** 本文提出了一个速度引导的可学习卡尔曼滤波器（SG-LKF），它能根据自车速度动态调整不确定性建模。SG-LKF的核心是MotionScaleNet（MSNet），一个解耦的token-mixing和channel-mixing MLP，用于自适应预测SG-LKF的关键参数。为了增强帧间关联和轨迹连续性，还引入了一个自监督轨迹一致性损失，与语义和位置约束共同优化。

**Result:** 实验结果表明，SG-LKF在KITTI 2D MOT上以79.59% HOTA的成绩位居所有基于视觉的方法之首；在KITTI 3D MOT上取得了82.03% HOTA的强劲结果；在nuScenes 3D MOT上比SimpleTrack高出2.2% AMOTA。

**Conclusion:** 本文提出的SG-LKF通过动态适应自车速度对不确定性进行建模，显著提高了多目标跟踪在高度动态场景下的稳定性和准确性，并在多个主流基准测试中展现出卓越性能。

> **ai_Abstract:** 本文提出了一种名为速度引导可学习卡尔曼滤波器（SG-LKF）的新型多目标跟踪方法，旨在解决传统方法在高速动态场景下因忽略自车速度影响而导致的跟踪稳定性与准确性问题。SG-LKF通过引入MotionScaleNet动态调整不确定性建模，并结合自监督轨迹一致性损失优化轨迹连贯性。实验证明，该方法在KITTI和nuScenes等主流基准测试中表现出色，显著提升了多目标跟踪在复杂动态环境下的性能。

> **摘要翻译:** 多目标跟踪（MOT）使自动驾驶车辆能够持续感知动态物体，为预测、行为理解和安全规划提供重要的时间线索。然而，传统的基于检测的跟踪方法通常依赖于基于自车姿态的静态坐标变换，忽略了自车速度引起的观测噪声变化和参考系改变，这会降低在动态、高速场景下的跟踪稳定性和准确性。在本文中，我们研究了自车速度在MOT中的关键作用，并提出了一个速度引导的可学习卡尔曼滤波器（SG-LKF），它能动态地使不确定性建模适应自车速度，显著提高了在高度动态场景下的稳定性和准确性。SG-LKF的核心是MotionScaleNet（MSNet），一个解耦的token-mixing和channel-mixing MLP，它能自适应地预测SG-LKF的关键参数。为了增强帧间关联和轨迹连续性，我们引入了一个自监督轨迹一致性损失，与语义和位置约束共同优化。大量的实验表明，SG-LKF在KITTI 2D MOT上以79.59% HOTA的成绩位居所有基于视觉的方法之首，在KITTI 3D MOT上取得了82.03% HOTA的强劲结果，并且在nuScenes 3D MOT上比SimpleTrack高出2.2% AMOTA。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [320] [A Physical Model-Guided Framework for Underwater Image Enhancement and Depth Estimation](https://arxiv.org/abs/2407.04230)
> *水下图像增强与深度估计的物理模型引导框架*

*Dazhao Du, Lingyu Si, Fanjiang Xu, Jianwei Niu, Fuchun Sun* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 水下图像增强, 深度估计, 物理模型, 深度学习, 图像退化

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 提出一个物理模型引导框架，结合深度降质模型（DDM）和UIE模型，用于水下图像增强和深度估计，解决了现有方法参数估计不准确的问题。

**AI_Comments:** 该论文的创新点在于提出了一个物理模型引导的框架，将深度降质模型（DDM）与任意UIE模型联合训练，并通过DDM精确估计物理成像参数，从而在增强过程中施加物理约束。这有效地解决了现有方法参数估计不准确的痛点。此外，该框架的通用性使其能与多种UIE模型结合，同时其设计的UIEConv模型也展现出良好的性能，并且能够副产物地进行深度估计，增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 水下图像因光线吸收和散射而存在视觉退化。现有水下图像增强（UIE）方法结合物理模型和神经网络时，常未能准确估计深度和水体光等成像参数，导致在某些场景下性能不佳。

**Method:** 提出一个物理模型引导框架，用于联合训练一个深度降质模型（DDM）和任何先进的UIE模型。DDM包含三个子网络：水体光估计、因子估计和深度估计。基于估计的参数和水下物理成像模型，通过建模水下图像与期望清晰图像（UIE模型输出）之间的关系，对增强过程施加物理约束。此外，该框架兼容任何UIE模型，并设计了一个名为UIEConv的简单而有效的全卷积UIE模型，它通过双分支结构利用全局和局部特征进行图像增强。

**Result:** 在该框架下训练的UIEConv模型在各种水下场景中取得了显著的增强效果。此外，作为水下图像增强的副产品，训练好的深度估计子网络能够实现准确的水下场景深度估计。

**Conclusion:** 在包括深海环境和人工光源在内的各种真实水下成像场景中进行的广泛实验验证了所提框架和UIEConv模型的有效性。

> **ai_Abstract:** 本文提出了一个物理模型引导框架，旨在解决现有水下图像增强（UIE）方法中成像参数估计不准确的问题。该框架通过联合训练一个深度降质模型（DDM）和任何UIE模型来实现图像增强和深度估计。DDM包含三个专门的子网络用于精确估计水体光、因子和深度等参数，并利用这些参数和物理成像模型对增强过程施加物理约束。作者还设计了一个名为UIEConv的全卷积UIE模型，该模型通过双分支结构有效利用全局和局部特征。实验结果表明，该框架下的UIEConv在多种水下场景中表现出色，并且其深度估计子网络还能提供准确的场景深度信息。

> **摘要翻译:** 由于不同水生介质对光的选择性吸收和散射，水下图像通常会遭受各种视觉退化。现有结合水下物理成像模型与神经网络的水下图像增强（UIE）方法，往往无法准确估计深度和水体光等成像模型参数，导致在某些场景下性能不佳。为了解决这个问题，我们提出了一个物理模型引导框架，用于联合训练深度降质模型（DDM）与任何先进的UIE模型。DDM包括三个精心设计的子网络，用于准确估计各种成像参数：水体光估计子网络、因子估计子网络和深度估计子网络。基于估计的参数和水下物理成像模型，我们通过建模水下图像与期望清晰图像（即UIE模型的输出）之间的关系，对增强过程施加物理约束。此外，虽然我们的框架兼容任何UIE模型，但我们设计了一个简单而有效的全卷积UIE模型，命名为UIEConv。UIEConv通过双分支结构利用全局和局部特征进行图像增强。在我们框架内训练的UIEConv在各种水下场景中取得了显著的增强效果。此外，作为UIE的副产品，训练好的深度估计子网络能够实现准确的水下场景深度估计。在包括深海环境和人工光源在内的各种真实水下成像场景中进行的广泛实验，验证了我们框架和UIEConv模型的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [333] [CoST: Efficient Collaborative Perception From Unified Spatiotemporal Perspective](https://arxiv.org/abs/2508.00359)
> *CoST：从统一时空视角实现高效协同感知*

*Zongheng Tang, Yi Liu, Yifan Sun, Yulu Gao, Jinyu Chen, Runsheng Xu, Si Liu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 协同感知, 时空融合, 特征传输, 感知性能, Transformer

**Comment:** ICCV25 (Highlight)

> **TL;DR:** CoST提出了一种高效的协同感知方法，通过将来自不同智能体和不同时间的观测数据聚合到一个统一的时空空间中，实现了高效的特征传输和卓越的特征融合，从而提升了感知性能并降低了传输带宽。

**AI_Comments:** 本文提出了一种创新性的协同感知方法CoST，其核心在于将多智能体和多时间融合统一到时空空间中，这有效解决了传统方法中信息传输冗余和融合不**足的问题。其优势在于不仅提升了感知精度，还显著优化了传输效率，且具备良好的通用性和兼容性，能够广泛应用于现有协同感知系统，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的协同感知方法通常将多智能体融合和多时间融合分为两个连续的步骤，导致效率低下且可能无法实现最佳的感知性能。此外，独立智能体在感知中面临遮挡和感知范围小等问题。

**Method:** 本文提出了一种名为CoST（Collaborative perception with Spatio-temporal Transformer）的协同感知方法。该方法将来自不同智能体（空间）和不同时间（时间）的观测数据同时聚合到一个统一的时空空间中，以实现高效的特征传输和卓越的特征融合。

**Result:** CoST方法带来了两个主要好处：1) 高效的特征传输：每个静态物体在时空空间中只产生一次观测，因此只需传输一次，而先前的方**法需要多次重新传输所有物体特征。2) 卓越的特征融合：将多智能体和多时间融合合并到统一的时空聚合中，实现了更全面的视角，从而增强了在挑战性场景下的感知性能。因此，CoST在效率和准确性方面都得到了提升。

**Conclusion:** CoST方法在效率和准确性方面均取得了显著提升，并且不**局限于任何特定方法，可以与大多数现有方法兼容，在提高其准确性的同时降低了传输带宽。

> **ai_Abstract:** CoST是一种新颖的协同感知框架，它通过将来自多个智能体和不同时间点的观测数据统一到一个单一的时空空间中，解决了传统方法中空间和时间融合分离的问题。这种统一的方法带来了高效的特征传输（静态物体只需传输一次）和卓越的特征融合，显著提升了在复杂场景下的感知性能，并在效率和准确性上优于现有方法。CoST具有良好的兼容性，可以增强多数现有方法的性能并降低带宽需求。

> **摘要翻译:** 协同感知在不同智能体之间共享信息，有助于解决单个智能体可能面临的问题，例如遮挡和感知范围小。现有方法通常将多智能体融合和多时间融合分为两个连续的步骤。相比之下，本文提出了一种高效的协同感知方法，该方法将来自不同智能体（空间）和不同时间的观测数据同时聚合到一个统一的时空空间中。统一的时空空间带来了两个好处，即高效的特征传输和卓越的特征融合。1）高效的特征传输：每个静态物体在时空空间中只产生一次观测，因此只需传输一次（而现有方法需要多次重新传输所有物体特征）。2）卓越的特征融合：将多智能体和多时间融合合并到统一的时空聚合中，可以实现更全面的视角，从而增强在挑战性场景下的感知性能。因此，我们的基于时空Transformer的协同感知（CoST）在效率和准确性方面都取得了提升。值得注意的是，CoST不**局限于任何特定方法，可以与大多数现有方法兼容，在提高其准确性的同时降低传输带宽。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [340] [YOLOO: You Only Learn from Others Once](https://arxiv.org/abs/2409.00618)
> *YOLOO：你只从他人那里学习一次*

*Lipeng Gu, Mingqiang Wei, Xuefeng Yan, Dingkun Zhu, Wei Zhao, Haoran Xie* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 多模态3D多目标跟踪, 点云, 统一三模态表示, 效率, 鲁棒性

**Comment:** 

> **TL;DR:** YOLOO是一种多模态3D多目标跟踪方法，它在训练阶段利用多模态信息，但在推理阶段仅使用点云数据，从而实现高效且鲁棒的跟踪。

**AI_Comments:** YOLOO的创新之处在于其“只学习一次”的范式，即在训练阶段利用多模态信息来增强点云编码器的表示能力，但在推理阶段仅使用点云数据，从而大幅提高了效率。这种方法有效地解决了多模态MOT中计算成本高昂的痛点。UTEnc结合CLIP预训练知识和F-GC模块的设计也增强了其性能和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 多模态3D多目标跟踪（MOT）通常需要深度神经网络（DNN）进行大量的计算以提取多模态表示。本文旨在解决如何在推理阶段避免多模态输入，从而降低计算成本。

**Method:** YOLOO通过使点云编码器在训练阶段一次性学习统一的三模态表示（UTR），该UTR整合了点云、图像和文本线索。推理阶段仅使用点云编码器进行跟踪。其核心组件包括：1. 统一三模态编码器（UTEnc），它将点云编码器与从预训练CLIP调整的图像和文本编码器集成，融合多源信息以生成区分性UTR。2. 灵活几何约束（F-GC）模块，用于过滤掉具有相似表示但位置差异显著的不匹配关联，增强UTR的鲁棒性。最后，通过传统数据关联组件生成3D轨迹。

**Result:** YOLOO在多模态3D MOT方案中实现了鲁棒性和效率的显著提升，在推理阶段避免了对计算密集型DNN的需求，同时不损害性能。

**Conclusion:** YOLOO通过仅在训练阶段利用多模态信息，并在推理阶段仅依赖点云数据，提供了一种高效且鲁棒的多模态3D多目标跟踪范式，有效解决了计算成本问题。

> **ai_Abstract:** YOLOO是一种新颖的多模态3D多目标跟踪（MOT）方法，旨在解决现有方法中深度神经网络（DNN）在推理阶段计算成本高昂的问题。其核心思想是仅在训练阶段利用多模态（点云、图像、文本）信息，通过统一三模态编码器（UTEnc）使点云编码器学习统一的三模态表示（UTR）。在推理时，YOLOO仅依赖点云数据进行高效跟踪，同时保持性能。此外，引入灵活几何约束（F-GC）模块来增强UTR的鲁棒性并过滤不匹配的关联。实验表明，YOLOO在多模态3D MOT中显著提升了鲁棒性和效率。

> **摘要翻译:** 多模态3D多目标跟踪（MOT）通常需要深度神经网络（DNN）进行大量的计算，以提取多模态表示。在本文中，我们提出了一个有趣的问题：我们能否仅在训练阶段从多种模态中学习，以避免在推理阶段进行多模态输入？为了回答这个问题，我们提出了**YOLOO**，一种新颖的多模态3D MOT范式：你只从他人那里学习一次。YOLOO使点云编码器能够一次性地从点云和其他模态（如图像和文本线索）中学习统一的三模态表示（UTR）。利用这种UTR，YOLOO仅使用点云编码器即可实现高效跟踪，而不会损害其性能，从根本上避免了对计算密集型DNN的需求。具体而言，YOLOO包括两个核心组件：统一三模态编码器（UTEnc）和灵活几何约束（F-GC）模块。UTEnc将点云编码器与从预训练CLIP中调整的图像和文本编码器集成。它将点云信息与来自CLIP的丰富视觉-文本知识无缝融合到点云编码器中，产生高度区分性的UTR，有助于轨迹和检测之间的关联。此外，F-GC过滤掉具有相似表示但位置差异显著的不匹配关联。它进一步增强了UTR的鲁棒性，而无需任何场景特定调整，解决了定制几何约束（例如3D IoU）的一个关键限制。最后，高质量的3D轨迹由传统的关联组件生成。通过将这些进步整合到多模态3D MOT方案中，我们的YOLOO在鲁棒性和效率方面都取得了显著的提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [341] [C-DOG: Multi-View Multi-instance Feature Association Using Connected δ-Overlap Graphs](https://arxiv.org/abs/2507.14095)
> *C-DOG：使用连接的δ-重叠图进行多视图多实例特征关联*

*Yung-Hong Sun, Ting-Hung Lin, Jiangang Chen, Hongrui Jiang, Yu Hen Hu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 多视图, 多实例, 特征关联, 3D重建, 对极几何, C-DOG

**Comment:** 

> **TL;DR:** C-DOG是一种利用对极几何进行多视图多实例特征关联的算法，即使在噪声和挑战性条件下也能实现鲁棒的3D重建，优于现有几何方法。

**AI_Comments:** C-DOG的创新之处在于其完全依赖几何约束（对极几何）来解决多实例场景中的特征关联难题，避免了外观匹配的歧义。其使用Szymkiewicz--Simpson系数和IQR-based修剪的方法增强了算法在噪声环境下的鲁棒性，使其在实际应用中更具潜力，尤其是在高密度、无纹理或相机重叠受限等极端条件下表现出色，这对于工业级3D重建具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在3D重建中，多视图多实例特征关联至关重要，但场景中存在多个相同物体时，基于外观的特征匹配算法会产生歧义。为了解决这一挑战，该研究专注于纯粹基于几何约束进行特征关联。

**Method:** 该研究引入了C-DOG（Connected delta-Overlap Graph）算法，用于鲁棒的几何特征关联。在C-DOG图中，来自不同视图的2D特征点如果对应相同的3D点则通过边连接，边权重为对极距离。为鲁棒地保留对极距离小于阈值delta的边，算法采用Szymkiewicz--Simpson系数进行delta邻居重叠聚类。此外，使用基于四分位距（IQR）的标准从聚类中修剪不可靠节点。

**Result:** 在合成基准上的广泛实验表明，C-DOG不仅优于基于几何的基线算法，而且在苛刻条件下（包括高物体密度、无视觉特征和受限的相机重叠场景）表现出显著的鲁棒性。

**Conclusion:** C-DOG为实际应用中可扩展的3D重建提供了一个出色的解决方案。

> **ai_Abstract:** 本文提出了C-DOG（Connected delta-Overlap Graph）算法，旨在解决多视图多实例特征关联中因相同物体导致的外观匹配歧义问题。C-DOG纯粹利用对极几何进行鲁棒的特征关联，即使在特征检测存在噪声的情况下也表现良好。该算法通过构建以对极距离加权的图，并结合Szymkiewicz--Simpson系数进行delta邻居重叠聚类，同时采用IQR标准修剪不可靠节点。实验证明C-DOG在挑战性场景下优于现有几何方法，为可扩展3D重建提供了有效方案。

> **摘要翻译:** 多视图多实例特征关联是三维重建中的关键一步，有助于在不同相机视角下对物体实例进行一致性分组。场景中存在多个相同物体时，基于外观的特征匹配算法通常会导致歧义。我们的工作通过仅采用几何约束（特别是对极几何）进行特征关联来规避这一挑战。我们引入了C-DOG（连接的δ-重叠图），这是一种即使在存在噪声特征检测的情况下也能实现鲁棒几何特征关联的算法。在C-DOG图中，表示来自不同视图的2D特征点的两个节点，如果它们对应相同的3D点，则通过边连接。每条边都由其对极距离加权。理想情况下，真正的关联会产生零距离；然而，嘈杂的特征检测可能会导致非零值。为了鲁棒地保留对极距离小于阈值delta的边，我们采用了Szymkiewicz--Simpson系数。这个过程导致了2D节点的delta邻居重叠聚类。此外，使用基于四分位距（IQR）的标准从这些聚类中修剪不可靠节点。我们在合成基准上的广泛实验表明，C-DOG不仅优于基于几何的基线算法，而且在苛刻条件下（包括高物体密度、无视觉特征和受限相机重叠的场景）表现出显著的鲁棒性，这使得C-DOG成为实际应用中可扩展三维重建的优秀解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [344] [A Novel Modeling Framework and Data Product for Extended VIIRS-like Artificial Nighttime Light Image Reconstruction (1986-2024)](https://arxiv.org/abs/2508.00590)
> *一种用于扩展VIIRS类人工夜间灯光图像重建（1986-2024）的新型建模框架和数据产品*

*Yihe Tian, Kwan Man Cheng, Zhengbo Zhang, Tao Zhang, Suju Li, Dongmei Yan, Bing Xu* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 夜间灯光, VIIRS, 图像重建, 时序分析, EVAL

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的框架来重建扩展的VIIRS类夜间灯光图像，生成了1986年以来的中国EVAL产品，显著优于现有方法，并可用于长期分析。

**AI_Comments:** 该论文提出了一种创新的两阶段建模框架，有效解决了VIIRS夜间灯光数据在长期时序分析中的核心限制，即时间覆盖不足、强度低估和结构缺失。其引入的分层融合解码器和双特征细化器，特别是结合高分辨率不透水表面掩膜来增强细节，是方法上的亮点。生成的EVAL产品显著提升了数据质量，并提供了宝贵的长期可追溯性，对社会经济、环境研究等领域具有重要意义。数据的公开可用性也极大地促进了研究社区的共享和应用。

<details>
  <summary>Details</summary>

**Motivation:** NPP-VIIRS传感器提供的夜间灯光（NTL）观测数据时间覆盖范围有限（始于2012年），限制了长期的时序研究。现有扩展VIIRS类NTL时序的方法存在光强度低估和结构遗漏的显著缺点。

**Method:** 我们提出了一个新颖的重建框架，包含两个阶段：构建和细化。构建阶段采用分层融合解码器（HFD）以增强初始重建的保真度。细化阶段采用双特征细化器（DFR），利用高分辨率不透水表面掩膜来指导和增强细粒度结构细节。

**Result:** 基于该框架，我们开发了用于中国的扩展VIIRS类人工夜间灯光（EVAL）产品，将标准数据记录追溯到1986年，延长了26年。定量评估显示，EVAL显著优于现有最先进产品，将R²从0.68提高到0.80，同时将RMSE从1.27降低到0.99。此外，EVAL表现出卓越的时间一致性，并与社会经济参数保持高度相关性。

**Conclusion:** EVAL数据集为研究界提供了一个有价值的新资源，并确认其在长期分析中的可靠性。

> **ai_Abstract:** 本文针对现有VIIRS夜间灯光数据时间跨度短及重建方法存在的强度低估和结构缺失问题，提出了一种新型两阶段重建框架。该框架包括采用分层融合解码器（HFD）的构建阶段和利用双特征细化器（DFR）及不透水表面掩膜的细化阶段。基于此框架，研究团队成功重建了1986年至今的中国扩展VIIRS类人工夜间灯光（EVAL）产品，并通过定量评估证明其在精度和时间一致性上显著优于现有产品，为长期社会经济分析提供了可靠的数据资源。

> **摘要翻译:** 人工夜间灯光（NTL）遥感是量化人类活动强度和空间分布的重要代理。尽管NPP-VIIRS传感器提供了高质量的NTL观测数据，但其始于2012年的时间覆盖范围限制了延伸到更早时期的长期时序研究。尽管在扩展VIIRS类NTL时序方面取得了进展，但现有方法仍存在两个显著缺点：光强度低估和结构遗漏。为了克服这些限制，我们提出了一种新颖的重建框架，包含两个阶段：构建和细化。构建阶段采用分层融合解码器（HFD），旨在增强初始重建的保真度。细化阶段采用双特征细化器（DFR），利用高分辨率不透水表面掩膜来指导和增强细粒度结构细节。基于该框架，我们开发了用于中国的扩展VIIRS类人工夜间灯光（EVAL）产品，将标准数据记录追溯到1986年，延长了26年。定量评估显示，EVAL显著优于现有最先进产品，将R²从0.68提高到0.80，同时将RMSE从1.27降低到0.99。此外，EVAL表现出卓越的时间一致性，并与社会经济参数保持高度相关性，证实了其在长期分析中的可靠性。生成的EVAL数据集为研究界提供了一个有价值的新资源，并可在https://doi.org/10.11888/HumanNat.tpdc.302930公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [353] [Honey Classification using Hyperspectral Imaging and Machine Learning](https://arxiv.org/abs/2508.00361)
> *蜂蜜超光谱成像与机器学习分类*

*Mokhtar A. Al-Awadhi, Ratnadeep R. Deshmukh* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 蜂蜜分类, 超光谱成像, 机器学习, 线性判别分析, 支持向量机

**Comment:** 

> **TL;DR:** 该论文提出了一种基于机器学习的方法，利用超光谱成像自动分类蜂蜜的植物来源，并取得了最先进的分类精度。

**AI_Comments:** 该论文提出了一种结合超光谱成像和机器学习的蜂蜜植物来源分类方法，其创新性在于将类转换方法引入数据集准备阶段以增强特征可分性，并通过LDA进行有效特征提取。取得的最先进结果表明该方法在蜂蜜溯源和质量控制方面具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 自动分类蜂蜜的植物来源。

**Method:** 提出了一种机器学习方法，包括三个主要步骤：数据集准备（使用类转换方法最大化类别可分性）、特征提取（使用线性判别分析LDA降维和提取特征）、以及分类（使用支持向量机SVM和K-近邻KNN模型）。系统使用标准蜂蜜超光谱成像(HSI)数据集进行评估。

**Result:** 该系统在标准蜂蜜超光谱成像数据集上取得了最先进的结果，超光谱图像分类的最高精度达到95.13%，超光谱实例分类的最高精度达到92.80%。

**Conclusion:** 提出的系统能够有效且准确地通过超光谱成像和机器学习技术对蜂蜜的植物来源进行分类，并取得了SOTA性能。

> **ai_Abstract:** 本文提出了一种创新的机器学习框架，用于利用超光谱成像技术自动识别蜂蜜的植物来源。该方法包含数据集预处理（通过类转换增强可分性）、基于LDA的特征提取以及采用SVM和KNN模型的分类步骤。实验结果表明，该系统在标准蜂蜜HSI数据集上表现出色，图像和实例分类的准确率分别达到95.13%和92.80%，达到了当前最先进的水平。

> **摘要翻译:** 本文提出了一种基于机器学习的方法，用于自动分类蜂蜜的植物来源。所提出的方法包括数据集准备、特征提取和分类三个主要步骤。在数据集准备阶段，我们使用类转换方法来最大化类别之间的可分离性。特征提取阶段采用线性判别分析（LDA）技术来提取相关特征并减少维度。在分类阶段，我们使用支持向量机（SVM）和K-近邻（KNN）模型来将蜂蜜样本的提取特征分类到其植物来源。我们使用标准蜂蜜超光谱成像（HSI）数据集评估我们的系统。实验结果表明，所提出的系统在该数据集上取得了最先进的结果，其中超光谱图像分类的最高准确率为95.13%，超光谱实例分类的最高准确率为92.80%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [360] [BlinkTrack: Feature Tracking over 80 FPS via Events and Images](https://arxiv.org/abs/2409.17981)
> *BlinkTrack：通过事件和图像实现超过80 FPS的特征跟踪*

*Yichen Shen, Yijin Li, Shuo Chen, Guanglin Li, Zhaoyang Huang, Hujun Bao, Zhaopeng Cui, Guofeng Zhang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 事件相机, 特征跟踪, 多模态融合, 卡尔曼滤波器, 高帧率

**Comment:** 

> **TL;DR:** BlinkTrack是一个结合事件相机数据和传统图像的框架，通过学习型卡尔曼滤波器实现高速（>80 FPS）特征跟踪，解决了事件相机缺乏纹理信息导致误差积累的问题。

**AI_Comments:** BlinkTrack的创新点在于它巧妙地结合了事件相机的高时间分辨率和传统相机的纹理信息，通过一个学习型的可微分卡尔曼滤波器框架实现了高效且高精度的特征跟踪。这种多模态融合方法有效解决了各自传感器的局限性，在高速运动和光照变化等挑战性场景下具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 事件相机在特征跟踪方面具有高时间分辨率和捕捉异步变化的潜力，但在缺乏精细纹理信息时会导致跟踪误差积累。传统方法无法有效利用事件数据和图像数据进行高速、准确的特征跟踪。

**Method:** 本文提出了BlinkTrack框架，将事件数据与灰度图像集成，用于高频特征跟踪。该方法将传统卡尔曼滤波器扩展为学习型框架，在事件和图像分支中利用可微分卡尔曼滤波器。这种方法改进了单模态跟踪，并有效解决了异步事件和图像数据的数据关联和融合问题。

**Result:** BlinkTrack显著优于现有方法，在使用多模态数据时超过80 FPS，使用预处理事件数据时达到100 FPS。

**Conclusion:** BlinkTrack通过有效融合事件和图像数据，成功解决了事件相机在特征跟踪中纹理信息不足的问题，实现了高性能和高帧率的特征跟踪。

> **ai_Abstract:** BlinkTrack是一个创新的框架，旨在解决事件相机在特征跟踪中缺乏纹理信息导致误差积累的问题。它通过将事件数据与灰度图像融合，并利用基于学习的可微分卡尔曼滤波器，实现了高频（超过80 FPS）且准确的特征跟踪。该方法有效处理了异步多模态数据的数据关联与融合，并在新数据集上表现出优于现有技术的性能。

> **摘要翻译:** 事件相机以其高时间分辨率和捕捉异步变化的能力而闻名，在特征跟踪方面，尤其是在具有挑战性的条件下，其潜力已引起了广泛关注。然而，事件相机缺乏传统相机提供的精细纹理信息，导致跟踪中误差累积。为了解决这个问题，我们提出了一个新颖的框架BlinkTrack，它将事件数据与灰度图像集成，用于高频特征跟踪。我们的方法将传统卡尔曼滤波器扩展为一个学习型框架，在事件和图像分支中利用可微分卡尔曼滤波器。这种方法改进了单模态跟踪，并有效解决了异步事件和图像数据的数据关联和融合问题。我们还引入了新的合成和增强数据集，以更好地评估我们的模型。实验结果表明，BlinkTrack显著优于现有方法，在使用多模态数据时超过80 FPS，使用预处理事件数据时达到100 FPS。代码和数据集可在https://github.com/ColieShen/BlinkTrack获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [361] [Rethinking Pan-sharpening: Principled Design, Unified Training, and a Universal Loss Surpass Brute-Force Scaling](https://arxiv.org/abs/2507.15059)
> *重新思考全色锐化：原则性设计、统一训练和通用损失超越蛮力扩展*

*Ran Zhang, Xuanhua He, Li Xueheng, Ke Cao, Liu Liu, Wenbo Xu, Fang Jiabin, Yang Qize, Jie Zhang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 全色锐化, 轻量级模型, 统一训练, 通用损失, 泛化性

**Comment:** 

> **TL;DR:** 本文提出了PanTiny，一个轻量级的全色锐化框架，通过多合一训练范式和通用的复合损失函数，在效率和泛化性上超越了现有的大型模型，并倡导开发高效、可泛化、数据感知型的模型。

**AI_Comments:** 本文的创新点在于提出了“多合一”统一训练范式和通用的复合损失函数，这显著提升了全色锐化模型的泛化能力和效率。它挑战了当前领域中盲目追求模型复杂度的趋势，通过精巧的设计而非蛮力扩展实现了性能突破，对于推动全色锐化技术向更实用、更高效的方向发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前全色锐化领域倾向于使用日益庞大和复杂的模型，这些模型通常在单一特定卫星数据集上训练，导致计算开销高昂且在全分辨率数据上泛化能力差。本文旨在挑战这种范式。

**Method:** 本文提出了PanTiny，一个轻量级的单步全色锐化框架。关键创新包括：1) 引入“多合一”训练范式，即在三个不同的卫星数据集（WV2、WV3和GF2）上同时训练一个单一紧凑模型；2) 引入一个通用的复合损失函数，以提升全色锐化模型的性能。

**Result:** 实验表明，统一训练策略不仅简化了部署，还显著提升了在全分辨率数据上的泛化能力。通用的复合损失函数提升了几乎所有全色锐化模型的性能。PanTiny模型在性能与效率之间实现了卓越平衡，超越了大多数更大、更专业的模型。消融研究验证了模型设计、训练范式和损失函数中的原则性工程可以超越蛮力扩展。

**Conclusion:** 本文倡导全色锐化领域应转向创建高效、可泛化且数据感知的模型。通过原则性设计、统一训练和通用损失，可以超越简单地扩大模型规模来提升性能。

> **ai_Abstract:** 本文针对全色锐化领域模型日益庞大、泛化性差的问题，提出了PanTiny，一个轻量、高效的单步全色锐化框架。该框架引入了“多合一”统一训练范式，在一个紧凑模型中同时训练多个不同卫星数据集，并设计了一个通用的复合损失函数。实验证明，PanTiny在效率和性能上均表现出色，尤其在全分辨率数据上的泛化能力显著提升，超越了现有的大型专业模型。研究强调了模型设计、训练范式和损失函数中原则性工程的重要性，并呼吁社区关注开发高效、可泛化和数据感知的全色锐化模型。

> **摘要翻译:** 全色锐化领域最近出现了一种趋势，即模型越来越大、越来越复杂，并且通常在单一、特定的卫星数据集上进行训练。然而，这种方法导致高昂的计算开销和在全分辨率数据上的泛化能力差，这是我们在本文中挑战的范式。针对这个问题，我们提出了PanTiny，一个轻量级的单步全色锐化框架，旨在兼顾效率和鲁棒的性能。更关键的是，我们引入了“多合一”训练范式，其中一个单一、紧凑的模型在三个不同的卫星数据集（WV2、WV3和GF2）上同时进行训练，这些数据集具有不同的分辨率和光谱信息。我们的实验表明，这种统一的训练策略不仅简化了部署，而且显著提升了在全分辨率数据上的泛化能力。此外，我们引入了一个普遍强大的复合损失函数，该函数提升了几乎所有全色锐化模型的性能，将最先进的指标推向了一个新时代。我们的PanTiny模型受益于这些创新，实现了卓越的性能与效率平衡，超越了大多数更大、更专业的模型。通过广泛的消融研究，我们验证了模型设计、训练范式和损失函数中的原则性工程可以超越蛮力扩展。我们的工作倡导社区范围内转向创建高效、可泛化且数据感知的全色锐化模型。代码可在https://github.com/Zirconium233/PanTiny获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [369] [GeoMoE: Divide-and-Conquer Motion Field Modeling with Mixture-of-Experts for Two-View Geometry](https://arxiv.org/abs/2508.00592)
> *GeoMoE：基于专家混合模型的双视图几何分而治之运动场建模*

*Jiajun Le, Jiayi Ma* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 双视图几何, 运动场建模, 专家混合模型, 分而治之, 概率分解

**Comment:** 

> **TL;DR:** GeoMoE引入了一种基于专家混合模型（MoE）的分而治之策略，通过概率先验引导分解和MoE增强双路径校正器来处理复杂场景中的异构运动场，在双视图几何任务中超越了现有最先进方法。

**AI_Comments:** GeoMoE的创新之处在于其将“分而治之”策略与专家混合模型相结合，专门处理复杂场景中运动场的异构性。通过引入概率先验引导分解和MoE增强双路径校正器，它能够有效地解耦不同的运动机制，抑制干扰，并实现细粒度的运动场校正。这种方法显著提升了双视图几何任务的性能和泛化能力，为处理现实世界中复杂的视觉场景提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂真实场景中，运动场表现出多样和异构的运动模式，而现有方法缺乏有针对性的建模策略，未能明确考虑这种变异性，导致估计的运动场偏离其真实结构和分布。

**Method:** GeoMoE框架重新构建了双视图几何中的运动场建模。具体来说，它首先设计了一种概率先验引导分解策略，利用内点概率信号将运动场结构感知地分解为异构子场，从而有效抑制异常值引起的偏差。其次，引入了一个MoE增强双路径校正器，沿空间上下文和通道语义路径增强每个子场，并将其路由到定制专家进行目标建模，从而解耦异构运动机制，抑制跨子场干扰和表示纠缠，并实现细粒度的运动场校正。

**Result:** GeoMoE在相对姿态和单应性估计方面优于现有最先进方法，并显示出强大的泛化能力。

**Conclusion:** GeoMoE通过其创新的分而治之策略和专家混合模型，成功解决了复杂场景中异构运动场的建模挑战，显著提高了双视图几何任务的性能和泛化能力。

> **ai_Abstract:** GeoMoE提出了一种新颖的分而治之方法，利用专家混合模型（MoE）来解决复杂真实场景中异构运动场的建模挑战。该框架通过概率先验引导分解策略将运动场分解为子场，并使用MoE增强双路径校正器对每个子场进行精细化建模，有效处理多样化的运动模式。实验结果表明，GeoMoE在相对姿态和单应性估计方面优于现有最先进方法，并展现出强大的泛化能力。

> **摘要翻译:** 标题：GeoMoE：基于专家混合模型的双视图几何分而治之运动场建模

摘要：
近期双视图几何的进展日益强调在估计图像对之间的运动场时，强制实施平滑性和全局一致性先验。然而，在以极端视点和尺度变化以及显著深度不连续性为特征的复杂真实场景中，运动场通常表现出多样且异构的运动模式。大多数现有方法缺乏有针对性的建模策略，未能明确考虑这种变异性，导致估计的运动场偏离其真实的底层结构和分布。我们观察到专家混合模型（MoE）可以为运动子场分配专门的专家，从而实现针对异构运动模式的分而治之策略。基于这一洞察，我们使用GeoMoE——一个精简的框架，重新构建了双视图几何中的运动场建模。具体来说，我们首先设计了一种概率先验引导分解策略，该策略利用内点概率信号来对运动场进行结构感知分解为异构子场，从而显著抑制异常值引起的偏差。接下来，我们引入了一个MoE增强双路径校正器，该校正器沿空间上下文和通道语义路径增强每个子场，并将其路由到定制专家进行目标建模，从而解耦异构运动机制，抑制跨子场干扰和表示纠缠，并产生细粒度的运动场校正。凭借这种极简主义设计，GeoMoE在相对姿态和单应性估计方面优于现有最先进方法，并显示出强大的泛化能力。源代码和预训练模型可在 https://github.com/JiajunLe/GeoMoE 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [373] [MR-CLIP: Efficient Metadata-Guided Learning of MRI Contrast Representations](https://arxiv.org/abs/2507.00043)
> *MR-CLIP：高效元数据引导的MRI对比度表示学习*

*Mehmet Yigit Avci, Pedro Borges, Paul Wright, Mehmet Yigitsoy, Sebastien Ourselin, Jorge Cardoso* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** MRI对比度, 元数据, 对比学习, 图像表示, DICOM

**Comment:** 

> **TL;DR:** MR-CLIP通过多模态对比学习，利用MRI图像及其DICOM元数据来学习对比度感知表示，解决了手动标签缺失和元数据不一致的问题，并提升了跨模态检索和对比度分类的性能。

**AI_Comments:** 该论文的创新点在于利用多模态对比学习，将非结构化的MRI图像数据与结构化的DICOM元数据结合，以自动学习鲁棒的对比度表示，且无需人工标签，这在真实世界数据中具有很强的实用性。其能够实现解剖结构无关的表示，对于MRI数据标准化、模态不变性表示以及未来的高级临床应用（如数据协调）具有重要意义。该方法有效解决了当前临床数据中元数据不完整、不一致的痛点。

<details>
  <summary>Details</summary>

**Motivation:** 现有MRI图像对比度识别依赖粗略标签且常缺失，DICOM元数据常不完整、有噪声，导致图像解释、检索等困难，且缺乏鲁棒的对比度感知表示来支持高级临床应用。

**Method:** 提出MR-CLIP，一个多模态对比学习框架，它将MRI图像与DICOM元数据对齐，从而在不依赖手动标签的情况下学习对比度感知表示。该模型在多样化的临床数据集上训练，能够捕获不同采集和扫描内部的对比度变化，实现解剖结构无关的表示。

**Result:** MR-CLIP在跨模态检索和对比度分类任务中表现出有效性，并展示了其可扩展性和在未来临床应用中的潜力。

**Conclusion:** MR-CLIP通过利用DICOM元数据进行多模态对比学习，有效解决了MRI对比度表示中标签缺失和元数据不一致的问题，为更精确的图像解释和高级临床应用提供了鲁棒的对比度感知表示。

> **ai_Abstract:** MR-CLIP是一个创新的多模态对比学习框架，旨在解决MRI图像对比度识别中手动标签缺失和元数据不完整的问题。它通过将MRI图像与DICOM元数据对齐，自动学习对比度感知表示，从而无需依赖人工标注。该方法在多样化临床数据集上训练，能捕获复杂的对比度变化并实现解剖结构无关的表示。实验证明，MR-CLIP在跨模态检索和对比度分类任务中表现出色，具有良好的可扩展性和广阔的临床应用前景。

> **摘要翻译:** 在临床系统中准确解释磁共振成像（MRI）扫描需要对图像对比度有精确的理解。这种对比度主要由采集参数（如回波时间和重复时间）决定，这些参数存储在DICOM元数据中。为了简化对比度识别，通常使用T1加权或T2加权等宽泛标签，但这些标签仅提供了对底层采集设置的粗略近似。在许多真实世界数据集中，此类标签完全缺失，使得原始采集参数成为对比度的唯一指示。此外，可用的元数据通常不完整、有噪声或不一致。缺乏可靠和标准化的元数据使得图像解释、检索以及整合到临床工作流程等任务变得复杂。此外，鲁棒的对比度感知表示对于实现更高级的临床应用（例如实现模态不变表示和数据协调）至关重要。为了解决这些挑战，我们提出了MR-CLIP，一个多模态对比学习框架，它将MR图像与其DICOM元数据对齐以学习对比度感知表示，而无需依赖手动标签。MR-CLIP在涵盖各种扫描仪和协议的多样化临床数据集上进行训练，能够捕获跨采集和扫描内部的对比度变化，从而实现解剖结构无关的表示。我们展示了它在跨模态检索和对比度分类中的有效性，突出了其可扩展性和在进一步临床应用中的潜力。代码和权重已在https://github.com/myigitavci/MR-CLIP公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [375] [Aesthetics is Cheap, Show me the Text: An Empirical Evaluation of State-of-the-Art Generative Models for OCR](https://arxiv.org/abs/2507.15085)
> *美学廉价，文本至上：最先进生成模型在OCR领域的实证评估*

*Peirong Zhang, Haowei Xu, Jiaxin Zhang, Guitao Xu, Xuhan Zheng, Zhenhua Yang, Junle Liu, Yuyi Zhang, Lianwen Jin* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 生成模型, OCR, 文本图像生成, 实证评估, 图像编辑

**Comment:** 

> **TL;DR:** 本文评估了当前最先进的生成模型在文本图像生成和编辑方面的能力，特别是在OCR任务中，并指出通用生成模型应将逼真文本图像生成作为基础技能。

**AI_Comments:** 本文通过对当前生成模型在文本图像生成和编辑（特别是OCR任务）方面的广泛实证评估，填补了该领域的一个空白。其创新之处在于将OCR任务重新定义为“OCR生成任务”，并提供了详细的任务分类和模型比较。重要性在于明确指出通用生成模型在处理文本图像方面的不足，并呼吁将此能力内化为基础技能，这对于推动多模态AI的发展具有指导意义。这项工作为社区提供了宝贵的见解，以实现更强大的文本图像生成能力。

<details>
  <summary>Details</summary>

**Motivation:** 随着专业图像生成器（如Flux系列）和统一生成模型（如GPT-4o）的兴起，它们展现出卓越的逼真度，作者自然而然地提出了一个问题：这些模型能否掌握文本图像生成和编辑的复杂性？因此，本文旨在评估当前最先进的生成模型在文本图像生成和编辑方面的能力。

**Method:** 研究评估了当前最先进的生成模型在文本图像生成和编辑方面的能力。他们将各种典型的光学字符识别（OCR）任务纳入评估，并将基于文本的生成任务的概念扩展到OCR生成任务。选择了33个代表性任务，并将其分为五类：文档、手写文本、场景文本、艺术文本和复杂及布局丰富的文本。为了进行全面评估，他们检查了闭源和开源领域的六个模型，使用了定制的、高质量的图像输入和提示。

**Result:** 通过评估，本文得出了关键的观察结果，并指出了当前生成模型在OCR任务中的弱点。

**Conclusion:** 本文认为，逼真的文本图像生成和编辑应该作为基础技能内化到通用领域生成模型中，而不是委托给专门的解决方案。作者希望这项实证分析能为社区实现这一目标提供有价值的见解。

> **ai_Abstract:** 本文对当前最先进的生成模型在文本图像生成和编辑方面的能力进行了实证评估，特别是针对光学字符识别（OCR）任务。研究将OCR生成任务分为五大类共33个具体任务，并对六个代表性模型（包括闭源和开源）进行了测试。评估结果揭示了当前模型在处理文本图像方面的弱点，并强调了将逼真文本图像生成和编辑作为通用生成模型基础技能的重要性，而非依赖于专业解决方案。

> **摘要翻译:** 文本图像是一种独特而关键的信息媒介，它在现代电子社会中整合了视觉美学和语言语义。由于其微妙性和复杂性，文本图像的生成代表了图像生成领域一个具有挑战性且不断发展的前沿。最近，专业图像生成器（例如Flux系列）和统一生成模型（例如GPT-4o）的激增，展现出卓越的逼真度，这自然引发了一个问题：它们能否掌握文本图像生成和编辑的复杂性？受此启发，我们评估了当前最先进的生成模型在文本图像生成和编辑方面的能力。我们将各种典型的光学字符识别（OCR）任务纳入评估，并将基于文本的生成任务的概念扩展到OCR生成任务。我们选择了33个代表性任务，并将其分为五类：文档、手写文本、场景文本、艺术文本以及复杂和布局丰富的文本。为了进行全面评估，我们检查了闭源和开源领域的六个模型，使用了定制的、高质量的图像输入和提示。通过这项评估，我们得出了关键的观察结果，并指出了当前生成模型在OCR任务中的弱点。我们认为，逼真的文本图像生成和编辑应该作为基础技能内化到通用领域生成模型中，而不是委托给专门的解决方案，我们希望这项实证分析能为社区实现这一目标提供有价值的见解。这项评估已在线提供，并将持续在我们的GitHub仓库更新。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [376] [SparseRecon: Neural Implicit Surface Reconstruction from Sparse Views with Feature and Depth Consistencies](https://arxiv.org/abs/2508.00366)
> *SparseRecon：基于特征和深度一致性的稀疏视图神经隐式表面重建*

*Liang Han, Xu Zhang, Haichuan Song, Kanle Shi, Yu-Shen Liu, Zhizhong Han* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 稀疏视图, 神经隐式表面重建, 特征一致性, 深度约束, 3D重建

**Comment:** Accepted by ICCV 2025

> **TL;DR:** SparseRecon通过引入特征和深度一致性，解决了稀疏视图表面重建中现有方法的泛化性和重建质量问题，能够从少量RGB图像重建高质量3D形状。

**AI_Comments:** SparseRecon的创新之处在于巧妙地结合了特征一致性损失和不确定性引导的深度约束，有效解决了稀疏视图下神经隐式表面重建中几何歧义和细节恢复的难题。该方法显著提升了重建质量和鲁棒性，特别是在视图重叠度低的挑战性场景中展现出优越性，对稀疏视图3D重建领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有稀疏视图表面重建方法（基于泛化或过拟合）在未见视图上泛化性差，或重建质量受限于有限的几何线索。

**Method:** 提出SparseRecon，一种新的神经隐式重建方法。该方法引入了基于体渲染的跨视图特征一致性损失，以缓解视图一致性信息不足导致的歧义，并确保重建的完整性和平滑性。其次，采用不确定性引导的深度约束来辅助特征一致性损失，特别是在遮挡和不明显特征区域，以恢复几何细节，提高重建质量。

**Result:** 实验结果表明，该方法优于现有最先进方法，能够从稀疏视图输入生成高质量几何，尤其是在视图重叠较小的场景中。

**Conclusion:** SparseRecon通过结合特征一致性损失和不确定性引导的深度约束，有效克服了稀疏视图表面重建的挑战，实现了卓越的重建质量。

> **ai_Abstract:** SparseRecon是一种用于稀疏视图神经隐式表面重建的新方法，旨在解决现有方法在泛化性和重建质量上的局限性。它通过引入基于体渲染的跨视图特征一致性损失来减少歧义并确保重建的完整性和平滑性，并辅以不确定性引导的深度约束来恢复几何细节，尤其是在具有挑战性的区域。实验证明，SparseRecon在生成高质量几何方面优于现有最先进技术，尤其适用于视图重叠较小的场景。

> **摘要翻译:** 从稀疏视图进行表面重建旨在从少量RGB图像重建3D形状或场景。最新的方法要么基于泛化，要么基于过拟合。然而，基于泛化的方法在训练期间未见的视图上泛化性不佳，而基于过拟合的方法的重建质量仍然受限于有限的几何线索。为了解决这个问题，我们提出了SparseRecon，一种新颖的神经隐式重建方法，用于稀疏视图，并结合了基于体渲染的特征一致性和不确定性引导的深度约束。首先，我们引入了跨视图的特征一致性损失来约束神经隐式场。这种设计减轻了视图一致性信息不足引起的歧义，并确保了重建结果的完整性和平滑性。其次，我们采用不确定性引导的深度约束来支持特征一致性损失，尤其是在遮挡和不明显特征区域，这有助于恢复几何细节以获得更好的重建质量。实验结果表明，我们的方法优于现有最先进的方法，能够通过稀疏视图输入生成高质量几何，特别是在视图重叠较小的场景中。项目页面：https://hanl2010.github.io/SparseRecon/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [383] [Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage Gaussian Splats](https://arxiv.org/abs/2410.12781)
> *Long-LRM：用于广覆盖高斯溅射的长序列大型重建模型*

*Chen Ziwen, Hao Tan, Kai Zhang, Sai Bi, Fujun Luan, Yicong Hong, Li Fuxin, Zexiang Xu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 3D高斯重建, 长序列, Mamba2, 实时重建, 场景重建

**Comment:** 

> **TL;DR:** Long-LRM是一个新的前馈3D高斯重建模型，能以极快的速度和高分辨率处理大量输入图像，实现场景级3D重建，并显著超越现有方法的速度和输入规模。

**AI_Comments:** Long-LRM的创新之处在于其有效结合Mamba2和Transformer块来处理极长的输入序列，以及通过令牌合并和高斯剪枝实现效率与质量的平衡。其在速度和输入规模上的显著提升，使其在实时、大规模3D场景重建领域具有重要突破性意义。该模型为未来高效3D重建方法提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D重建方法在处理大量输入图像时可能面临速度和效率瓶颈，尤其在需要即时、高分辨率、360度广覆盖场景级重建的场景下。处理由大输入尺寸带来的长序列（如250K tokens）是一个技术挑战。

**Method:** Long-LRM是一个前馈3D高斯重建模型，旨在实现即时、高分辨率、360度广覆盖的场景级重建。它接收32张960x540分辨率的输入图像。为处理250K令牌长序列，模型融合了Mamba2块和经典Transformer块，并通过轻量级令牌合并模块和高斯剪枝步骤进行增强，以平衡重建质量和计算效率。模型还探讨了与2D GS等其他高斯变体的兼容性。

**Result:** Long-LRM在DL3DV和Tanks&Temples基准测试中，实现了与基于优化的方法相当的重建质量。与基于优化的方法相比，它实现了800倍的速度提升；与之前的前馈方法相比，其输入尺寸至少大60倍。模型设计选择的广泛消融研究验证了其渲染质量和计算效率。

**Conclusion:** Long-LRM显著提高了3D高斯重建的速度和输入处理能力，使其能够进行即时、高分辨率、广覆盖的场景级重建，并在性能上超越现有前馈方法，为大规模实时3D重建提供了新的解决方案。

> **ai_Abstract:** Long-LRM是一种新型的前馈3D高斯重建模型，旨在实现即时、高分辨率和360度广覆盖的场景级重建。该模型能够处理32张960x540的图像输入，并在1秒内完成重建。为应对长序列输入挑战，Long-LRM融合了Mamba2和Transformer块，并结合令牌合并与高斯剪枝技术。实验证明，Long-LRM在重建质量上与基于优化的方法相当，但速度快800倍，且输入尺寸比现有前馈方法大60倍。此外，它还支持与其他高斯变体结合以增强几何重建。

> **摘要翻译:** 我们提出了Long-LRM，一个用于即时、高分辨率、360度广覆盖场景级重建的前馈3D高斯重建模型。具体来说，它接收32张960x540分辨率的输入图像，并在单个A100 GPU上仅需1秒即可生成高斯重建。为了处理由大输入尺寸带来的250K令牌长序列，Long-LRM融合了最近的Mamba2块和经典的Transformer块，并通过轻量级令牌合并模块和高斯剪枝步骤进行增强，以平衡质量和效率。我们在大规模DL3DV基准测试和Tanks&Temples上评估了Long-LRM，结果表明其重建质量与基于优化的方法相当，同时相对于基于优化的方法实现了800倍的速度提升，并且输入尺寸比之前的前馈方法至少大60倍。我们对模型设计选择进行了广泛的消融研究，以兼顾渲染质量和计算效率。我们还探讨了Long-LRM与其他高斯变体（如2D GS）的兼容性，这增强了Long-LRM在几何重建方面的能力。项目页面：https://arthurhero.github.io/projects/llrm

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [385] [A Quality-Guided Mixture of Score-Fusion Experts Framework for Human Recognition](https://arxiv.org/abs/2508.00053)
> *一种质量引导的得分融合专家混合框架用于人体识别*

*Jie Zhu, Yiyang Su, Minchul Kim, Anil Jain, Xiaoming Liu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 全身生物识别, 得分融合, 专家混合, 质量估计, 多模态识别

**Comment:** Accepted to ICCV 2025. 11 pages, 5 figures

> **TL;DR:** 提出QME框架，利用可学习得分融合策略和MoE，通过伪质量损失和得分三元组损失提升全身生物识别性能。

**AI_Comments:** 该论文提出了一种新颖的基于MoE的可学习得分融合策略，并通过引入伪质量损失和得分三元组损失来有效解决多模态生物识别中的核心挑战，例如数据质量差异和模型得分未对齐问题。其创新点在于将质量估计融入到得分融合过程中，并通过端到端的方式进行学习，这对于提升全身生物识别系统的鲁棒性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 全身生物识别是一个具有挑战性的多模态任务，传统方法在处理多模态时，通过分数融合（如加权平均）可能忽略个体模态分数分布的变化，从而难以提高最终性能。

**Method:** 提出了一个名为QME（Quality-guided Mixture of score-fusion Experts）的新颖框架，通过使用专家混合（MoE）的可学习分数融合策略来改进全身生物识别性能。引入了一种新的伪质量损失（pseudo-quality loss）用于通过模态特定质量估计器（QE）进行质量估计，并使用得分三元组损失（score triplet loss）来提高度量性能。

**Result:** 在多个全身生物识别数据集上进行的广泛实验证明了所提出方法的有效性，与基线方法相比，在各种度量指标上取得了最先进的结果。该方法对多模态和多模型均有效，解决了相似性得分域中的模型未对齐和数据质量变异性等关键挑战。

**Conclusion:** 所提出的QME框架通过其可学习的得分融合策略、伪质量损失和得分三元组损失，有效提升了全身生物识别的性能，并解决了多模态和多模型识别中的关键挑战。

> **ai_Abstract:** 本文提出了QME（质量引导的得分融合专家混合）框架，旨在通过结合专家混合（MoE）的可学习得分融合策略，提升全身生物识别的性能。该框架引入了伪质量损失进行质量估计，并利用得分三元组损失优化度量表现。实验结果表明，QME在多个全身生物识别数据集上取得了最先进的性能，有效解决了传统方法中得分分布差异和数据质量变异性等挑战。

> **摘要翻译:** 全身生物识别是一项具有挑战性的多模态任务，它整合了各种生物识别模态，包括面部、步态和身体。这种整合对于克服单模态系统的局限性至关重要。
传统上，全身识别涉及部署不同的模型来处理多种模态，通过得分融合（例如，对每个模型的相似性矩阵进行加权平均）实现最终结果。然而，这些传统方法可能会忽略个体模态得分分布的变化，从而难以提高最终性能。
在这项工作中，我们提出了QME（质量引导的得分融合专家混合）——一个新颖的框架，旨在通过使用专家混合（MoE）的可学习得分融合策略来提高全身生物识别性能。我们引入了一种新颖的伪质量损失，用于通过模态特定质量估计器（QE）进行质量估计，以及一个得分三元组损失来提高度量性能。在多个全身生物识别数据集上进行的广泛实验证明了我们所提出方法的有效性，与基线方法相比，在各种度量指标上取得了最先进的结果。我们的方法对多模态和多模型均有效，解决了相似性得分域中的模型未对齐和数据质量变异性等关键挑战。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [393] [Representation Shift: Unifying Token Compression with FlashAttention](https://arxiv.org/abs/2508.00367)
> *表示偏移：统一令牌压缩与FlashAttention*

*Joonmyung Choi, Sanghyeok Lee, Byungoh Ko, Eunseo Kim, Jihyung Kil, Hyunwoo J. Kim* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 令牌压缩, FlashAttention, Representation Shift, Transformer加速, 自注意力

**Comment:** International Conference on Computer Vision (ICCV), 2025

> **TL;DR:** 提出Representation Shift，一种无需训练、与模型无关的度量，将令牌压缩与FlashAttention结合，有效降低Transformer计算成本。

**AI_Comments:** 该论文的创新点在于提出了Representation Shift，一种新颖的、无需注意力图的令牌重要性度量方法，成功解决了FlashAttention与现有令牌压缩技术之间的兼容性难题。这对于降低大型Transformer模型的计算成本和内存开销具有重要意义，并且其模型无关性使其具有广泛的应用潜力。该方法对Transformer生态系统的优化是一个有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** Transformer模型在视觉、语言和视频领域取得成功，但模型和令牌数量的增加导致自注意力机制的二次计算成本和GPU内存访问开销。现有令牌压缩方法依赖注意力图，与FlashAttention等融合注意力核不兼容。

**Method:** 提出Representation Shift，一种无需训练、与模型无关的度量，用于衡量每个令牌表示的变化程度。该方法无需注意力图或重新训练，即可将令牌压缩与FlashAttention无缝集成。它还可推广到CNN和状态空间模型。

**Result:** 实验表明，Representation Shift能实现与FlashAttention兼容的有效令牌压缩，在视频-文本检索和视频QA中分别实现高达5.5%和4.4%的显著加速。

**Conclusion:** Representation Shift成功地解决了令牌压缩与FlashAttention的兼容性问题，提供了一种高效的Transformer加速方法，并具有广泛的适用性。

> **ai_Abstract:** 本文提出了一种名为Representation Shift的新方法，旨在解决Transformer模型中令牌压缩与FlashAttention不兼容的问题。Representation Shift是一种无需训练、与模型无关的度量，通过衡量令牌表示的变化程度来确定其重要性，从而实现令牌压缩。该方法无需注意力图和重新训练，即可与FlashAttention无缝集成，并可推广到其他模型架构。实验证明，它能有效加速Transformer，在视频-文本检索和视频QA任务中分别带来高达5.5%和4.4%的速度提升。

> **摘要翻译:** Transformers在视觉、语言和视频领域取得了显著成功。然而，日益增长的任务复杂性导致模型更大、令牌更多，从而提高了自注意力的二次成本和GPU内存访问的开销。为了降低自注意力的计算成本，先前的工作提出了令牌压缩技术，用于丢弃冗余或信息量较少的令牌。与此同时，FlashAttention等融合注意力核已被开发出来，通过避免注意力图的构建及其相关的HBM I/O来减轻内存开销。然而，这使得它与大多数依赖注意力图来确定令牌重要性的免训练令牌压缩方法不兼容。在此，我们提出了Representation Shift，这是一种免训练、与模型无关的度量，用于衡量每个令牌表示的变化程度。这使得令牌压缩与FlashAttention无缝集成，无需注意力图或重新训练。我们的方法进一步推广到Transformer之外的CNN和状态空间模型。大量实验表明，Representation Shift实现了与FlashAttention兼容的有效令牌压缩，在视频-文本检索和视频QA中分别实现了高达5.5%和4.4%的显著加速。代码可在https://github.com/mlvlab/Representation-Shift获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [394] [DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior](https://arxiv.org/abs/2508.00599)
> *DPoser-X：扩散模型作为鲁棒的3D全身人体姿态先验*

*Junzhe Lu, Jing Lin, Hongkun Dou, Ailing Zeng, Yue Deng, Xian Liu, Zhongang Cai, Lei Yang, Yulun Zhang, Haoqian Wang, Ziwei Liu* | **Category: cs.CV** | **Updated: 2025-08-04**

**Keywords:** 扩散模型, 3D人体姿态, 全身姿态先验, DPoser-X, 逆问题

**Comment:** ICCV 2025 (oral); Code released: https://github.com/moonbow721/DPoser

> **TL;DR:** DPoser-X是一个基于扩散模型的3D全身人体姿态先验，它通过将姿态任务统一为逆问题并引入新的训练机制，在多个基准测试中表现出色，超越现有技术，建立了新的基准。

**AI_Comments:** 本文的创新点在于首次将扩散模型应用于3D全身人体姿态先验建模，并提出了独特的截断时间步调度和掩码训练机制。这些方法有效解决了高质量全身姿态数据集稀缺和姿态复杂性问题，显著提升了模型性能和泛化能力，为该领域树立了新的基准。

<details>
  <summary>Details</summary>

**Motivation:** 由于铰接式人体姿态固有的复杂性以及高质量全身姿态数据集的稀缺性，构建一个多功能且鲁棒的全身人体姿态先验仍然具有挑战性。

**Method:** 本文提出了一个扩散模型作为身体姿态先验（DPoser），并将其扩展为DPoser-X用于富有表现力的全身人体姿态建模。该方法将各种以姿态为中心的任务统一为逆问题，并通过变分扩散采样进行求解。为增强下游应用的性能，引入了一种专门为姿态数据特征设计的截断时间步调度方法。此外，还提出了一种掩码训练机制，有效结合了全身和部分特定数据集，使模型能够捕捉身体部位间的相互依赖，同时避免对特定动作的过拟合。

**Result:** 广泛的实验证明了DPoser-X在身体、手、脸和全身姿态建模的多个基准测试中的鲁棒性和多功能性。我们的模型始终优于现有先进替代方案。

**Conclusion:** DPoser-X为全身人体姿态先验建模建立了新的基准。

> **ai_Abstract:** DPoser-X是一个基于扩散模型的鲁棒3D全身人体姿态先验。它旨在解决全身姿态建模中数据集稀缺和姿态复杂性问题，通过将姿态任务统一为逆问题并采用变分扩散采样求解。为提升性能，DPoser-X引入了截断时间步调度和掩码训练机制，有效整合了全身和局部数据集，捕捉身体部位间依赖性。实验证明，DPoser-X在多种姿态建模任务中表现出卓越的鲁棒性和通用性，超越了现有技术，并为全身人体姿态先验建模设定了新标准。

> **摘要翻译:** 我们提出了DPoser-X，一个基于扩散模型的3D全身人体姿态先验。由于铰接式人体姿态固有的复杂性以及高质量全身姿态数据集的稀缺性，构建一个多功能且鲁棒的全身人体姿态先验仍然具有挑战性。为了解决这些限制，我们引入了一个扩散模型作为身体姿态先验（DPoser），并将其扩展到DPoser-X，用于富有表现力的全身人体姿态建模。我们的方法将各种以姿态为中心的任务统一为逆问题，通过变分扩散采样来解决。为了增强下游应用的性能，我们引入了一种专门为姿态数据特性设计的截断时间步调度方法。我们还提出了一种掩码训练机制，可以有效结合全身和部分特定数据集，使我们的模型能够捕捉身体部位之间的相互依赖性，同时避免对特定动作的过拟合。广泛的实验证明了DPoser-X在身体、手、脸和全身姿态建模的多个基准测试中的鲁棒性和多功能性。我们的模型始终优于现有先进替代方案，为全身人体姿态先验建模建立了新的基准。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [398] [Decouple before Align: Visual Disentanglement Enhances Prompt Tuning](https://arxiv.org/abs/2508.00395)
> *解耦再对齐：视觉解耦增强提示调优*

*Fei Zhang, Tianfei Zhou, Jiangchao Yao, Ya Zhang, Ivor W. Tsang, Yanfeng Wang* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 提示调优, 视觉解耦, 模态对齐, 视觉-语言模型, 少样本学习

**Comment:** 16 pages, Accepted at IEEE Transactions on Pattern Analysis and
  Machine Intelligence (TPAMI)

> **TL;DR:** 提出DAPT框架，通过在对齐前解耦视觉特征来解决提示调优中的信息不对称问题，提升了视觉-语言模型的性能。

**AI_Comments:** 这篇论文通过引入“先解耦再对齐”的直观概念，有效地解决了提示调优中视觉和文本模态间的信息不对称问题，其创新点在于显式地将视觉模态解耦为前景和背景，并针对性地进行对齐和正则化，这为提升视觉-语言模型的迁移学习能力提供了一个新颖且有效的方法。

<details>
  <summary>Details</summary>

**Motivation:** 提示调优（PT）中存在信息不对称问题，即视觉模态包含比面向对象的文本模态更多的上下文信息，导致粗略对齐时模型偏向关注上下文区域。

**Method:** 提出DAPT框架，基于“先解耦再对齐”的概念。首先，利用粗细粒度视觉分割线索将视觉模态显式解耦为前景和背景表示。然后，将解耦后的前景与原始前景文本对齐，将背景与手工制作的背景类别对齐，从而对称地加强模态对齐。此外，提出视觉拉推正则化来增强视觉集中度，使原始视觉表示对感兴趣区域对象产生无偏关注。

**Result:** DAPT在少样本学习、从基类到新类的泛化以及数据高效学习方面都取得了优越的性能，并在主流基准测试中表现出色。

**Conclusion:** 通过在对齐前解耦视觉模态并引入视觉拉推正则化，可以有效解决提示调优中的信息不对称问题，从而显著提升视觉-语言模型的性能。

> **ai_Abstract:** 本文针对提示调优（PT）中视觉模态信息过载导致对齐偏向上下文的问题，提出了DAPT框架。DAPT通过先将视觉模态解耦为前景和背景，再分别与文本和背景类别对齐，并辅以视觉拉推正则化，以实现对称的模态对齐和无偏的视觉关注。实验证明，DAPT在多项任务上均展现出卓越性能，有效提升了视觉-语言模型的迁移能力。

> **摘要翻译:** 提示调优（PT）作为一种新兴的资源高效微调范式，在提高视觉-语言模型的任务特定可迁移性方面展示出卓越的有效性。本文深入探讨了PT中一个此前被忽视的信息不对称问题，即视觉模态通常比面向对象的文本模态传达更多的上下文信息。相应地，粗略地对齐这两种模态可能导致偏向性注意力，促使模型仅仅关注上下文区域。为了解决这个问题，我们提出了DAPT，一个基于直观的“先解耦再对齐”概念的有效PT框架。首先，我们建议通过利用粗细粒度视觉分割线索，将视觉模态显式解耦为前景和背景表示，然后将这些解耦模式分别与原始前景文本和手工制作的背景类别对齐，从而对称地加强模态对齐。为了进一步增强视觉集中度，我们提出了一种专为前景-背景模式量身定制的视觉拉推正则化，引导原始视觉表示对感兴趣区域对象产生无偏注意。我们通过少样本学习、从基类到新类的泛化以及数据高效学习证明了DAPT（无架构限制）的强大能力，所有这些都在主流基准测试中取得了优越的性能。我们的代码将在https://github.com/Ferenas/DAPT 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [401] [CasP: Improving Semi-Dense Feature Matching Pipeline Leveraging Cascaded Correspondence Priors for Guidance](https://arxiv.org/abs/2507.17312)
> *CasP：利用级联对应先验指导改进半稠密特征匹配流程*

*Peiqi Chen, Lei Yu, Yi Wan, Yingying Pei, Xinyi Liu, Yongxiang Yao, Yingying Zhang, Lixiang Ru, Liheng Zhong, Jingdong Chen, Ming Yang, Yongjun Zhang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 半稠密特征匹配, 级联对应先验, 几何估计, 跨域泛化, SLAM

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 提出CasP，一个利用级联对应先验的半稠密特征匹配新流程，通过分阶段匹配和限制搜索范围，提高了精度和效率，特别是在高分辨率和跨域泛化方面表现出色。

**AI_Comments:** CasP通过引入级联对应先验和分阶段匹配策略，有效解决了传统半稠密特征匹配中全局搜索的效率瓶颈。其创新点在于将匹配过程分解并利用先验信息进行指导，并通过区域选择性交叉注意力增强特征判别力，同时结合高层特征降低计算负担。该方法在高分辨率场景下的显著加速和出色的跨域泛化能力，使其在实际应用中具有重要价值，尤其是在需要实时性和鲁棒性的领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有半稠密特征匹配流程依赖全局搜索建立粗匹配，限制了精度和效率的进一步提升。

**Method:** 提出CasP，将匹配阶段分解为两个渐进阶段，并通过区域选择性交叉注意力机制连接。第二阶段通过将搜索范围限制在第一阶段识别的一对多先验区域来确定一对一匹配。此外，该流程结合了高级特征以降低低级特征提取的计算成本。

**Result:** CasP的加速增益随分辨率升高而增加，其lite模型在1152分辨率下比ELoFTR快约2.2倍。在几何估计方面表现优越，尤其是在跨域泛化方面表现出色。

**Conclusion:** CasP通过引入级联对应先验和分阶段匹配策略，显著提高了半稠密特征匹配的精度和效率，在高分辨率和跨域场景中具有潜力，适用于对延迟敏感和高鲁棒性应用。

> **ai_Abstract:** 本文提出了一种名为CasP的新型半稠密特征匹配流程，旨在解决现有方法中全局搜索导致的精度和效率限制。CasP通过将匹配分为两个渐进阶段，并利用级联对应先验指导，特别是在第二阶段将搜索范围限制在第一阶段确定的一对多先验区域。该方法还利用高级特征以降低计算成本。实验结果表明，CasP在高分辨率下具有显著的加速效果（相对于ELoFTR提速约2.2倍），并在几何估计和跨域泛化方面表现出卓越性能，使其适用于SLAM和无人机等对延迟敏感和高鲁棒性要求的应用。

> **摘要翻译:** 半稠密特征匹配方法在挑战性场景中表现出强大的性能。然而，现有流程依赖于整个特征图上的全局搜索来建立粗匹配，这限制了精度和效率的进一步提升。受此限制的启发，我们提出了一种新颖的流程CasP，它利用级联对应先验进行指导。具体来说，匹配阶段被分解为两个渐进阶段，并通过旨在增强特征判别能力的基于区域的选择性交叉注意力机制连接。在第二阶段，通过将搜索范围限制在第一阶段识别的一对多先验区域来确定一对一匹配。此外，该流程受益于结合高级特征，这有助于降低低级特征提取的计算成本。CasP的加速增益随分辨率的提高而增加，并且我们的轻量级模型在1152分辨率下比最有效的方法ELoFTR实现了约2.2倍的加速。此外，广泛的实验证明了其在几何估计方面的优越性，尤其是在令人印象深刻的跨域泛化方面。这些优势突显了其在对延迟敏感和高鲁棒性应用（例如SLAM和无人机系统）中的潜力。代码可在https://github.com/pq-chen/CasP获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [402] [Punching Bag vs. Punching Person: Motion Transferability in Videos](https://arxiv.org/abs/2508.00085)
> *沙袋与真人拳击：视频中的动作可迁移性*

*Raiyaan Abdullah, Jared Claypoole, Michael Cogswell, Ajay Divakaran, Yogesh Rawat* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 动作识别, 动作可迁移性, 数据集, 泛化能力, 视频理解

**Comment:** Accepted to ICCV 2025 main conference

> **TL;DR:** 本文探讨了动作识别模型在不同语境下高层动作概念的迁移能力，发现现有模型在识别新语境下的高层动作时性能显著下降，并提出了一个评估动作可迁移性的框架和数据集。

**AI_Comments:** 本文创新性地提出了“动作可迁移性”这一概念，并构建了专门的数据集和评估框架，填补了现有动作识别研究中对高层概念迁移能力评估的空白。通过对多种SOTA模型的深入分析，揭示了当前模型在复杂场景下泛化能力的局限性，特别是对细粒度动作和时序推理的挑战，为未来研究指明了方向。Syn-TA合成数据集的引入也为控制变量、深入分析模型行为提供了独特的视角。

<details>
  <summary>Details</summary>

**Motivation:** 尽管动作识别模型表现出强大的泛化能力，但研究人员希望探究它们是否能有效地将高层运动概念在不同语境（即使分布相似）中进行迁移，例如，模型能否在遇到未见的“拳击真人”变体时，识别出广义的“拳击”动作。

**Method:** 研究引入了一个动作可迁移性框架，并构建了三个数据集：(1) Syn-TA，一个包含3D物体运动的合成数据集；(2) Kinetics400-TA；(3) Something-Something-v2-TA，后两者均改编自自然视频数据集。研究评估了13个最先进的模型在这些基准上的表现。

**Result:** 研究观察到，在识别新语境下的高层动作时，模型性能显著下降。分析揭示：1) 多模态模型在识别细粒度未知动作时比粗粒度动作更困难；2) 无偏差的Syn-TA合成数据集与真实世界数据集一样具有挑战性，模型在受控设置下表现出更大的性能下降；3) 当空间线索占主导时，大型模型能改善可迁移性，但在密集的时序推理方面则表现不佳，同时对物体和背景线索的依赖会阻碍泛化。研究还探讨了如何通过解耦粗粒度和细粒度动作来改善时序挑战性数据集上的识别效果。

**Conclusion:** 这项研究为评估动作识别中的动作可迁移性建立了一个关键基准。

> **ai_Abstract:** 本文研究了动作识别模型在不同语境下高层运动概念的迁移能力。通过引入一个动作可迁移性框架和三个新数据集（Syn-TA、Kinetics400-TA、Something-Something-v2-TA），并评估13个现有模型，研究发现模型在识别新语境下的高层动作时性能显著下降。分析指出，多模态模型在细粒度动作上表现不佳，合成数据集同样具有挑战性，且模型对空间和时序线索的依赖会影响泛化。这项工作为动作识别中的动作可迁移性评估提供了重要基准。

> **摘要翻译:** 动作识别模型展现出强大的泛化能力，但它们能否在不同语境（即使分布相似）中有效地迁移高层运动概念？例如，当模型遇到未见的“拳击真人”变体时，它能否识别出广义的“拳击”动作？为了探索这一点，我们引入了一个动作可迁移性框架，并构建了三个数据集：(1) Syn-TA，一个包含3D物体运动的合成数据集；(2) Kinetics400-TA；以及 (3) Something-Something-v2-TA，后两者均改编自自然视频数据集。我们评估了13个最先进的模型在这些基准上的表现，并观察到在识别新语境下的高层动作时性能显著下降。我们的分析揭示：1) 多模态模型在识别细粒度未知动作时比粗粒度动作更困难；2) 无偏差的Syn-TA合成数据集与真实世界数据集一样具有挑战性，模型在受控设置下表现出更大的性能下降；3) 当空间线索占主导时，大型模型能改善可迁移性，但在密集的时序推理方面则表现不佳，同时对物体和背景线索的依赖会阻碍泛化。我们进一步探讨了如何通过解耦粗粒度和细粒度动作来改善时序挑战性数据集上的识别效果。我们相信这项研究为评估动作识别中的动作可迁移性建立了一个关键基准。数据集和相关代码：https://github.com/raiyaan-abdullah/Motion-Transfer。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [408] [Bidirectional Action Sequence Learning for Long-term Action Anticipation with Large Language Models](https://arxiv.org/abs/2508.00374)
> *基于大语言模型的双向动作序列学习用于长期动作预测*

*Yuji Sato, Yasunori Ishii, Takayoshi Yamashita* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 长期动作预测, 双向学习, 大语言模型, 视频分析, BiAnt

**Comment:** Accepted to MVA2025 (Best Poster Award)

> **TL;DR:** BiAnt利用大语言模型结合前向和后向预测，提高了视频长期动作预测的性能。

**AI_Comments:** 该论文的创新点在于引入了双向动作序列学习，并结合大语言模型来解决长期动作预测中单向方法的局限性。这种双向方法能够更全面地理解动作序列的上下文信息，对于提高预测准确性具有重要意义。特别是在自动驾驶和机器人等高风险应用中，早期且准确的动作预测能力至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 视频长期动作预测对于自动驾驶和机器人等领域的早期风险检测至关重要。传统方法因其单向性限制了性能，难以捕捉场景中语义上不同的子动作。

**Method:** 提出的方法BiAnt通过结合前向预测和后向预测，并利用大语言模型来解决传统方法的局限性。

**Result:** 在Ego4D数据集上的实验结果表明，BiAnt在编辑距离方面优于基线方法。

**Conclusion:** BiAnt通过引入双向预测和利用大语言模型，有效提升了长期动作预测的性能，克服了传统单向方法的不足。

> **ai_Abstract:** 该论文提出了一种名为BiAnt的新方法，用于视频长期动作预测。针对传统单向预测方法在捕捉语义子动作方面的局限性，BiAnt结合了前向和后向预测，并利用大语言模型。实验结果表明，BiAnt在Ego4D数据集上相对于基线方法在编辑距离方面表现出更好的性能。

> **摘要翻译:** 基于视频的长期动作预测对于自动驾驶和机器人等领域的早期风险检测至关重要。传统方法使用编码器从过去动作中提取特征，并使用解码器预测未来事件，但由于其单向性限制了性能。这些方法难以捕捉场景中语义上不同的子动作。所提出的方法BiAnt通过结合前向预测和后向预测并利用大语言模型解决了这一局限性。在Ego4D上的实验结果表明，与基线方法相比，BiAnt在编辑距离方面提高了性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [411] [ShadowMamba: State-Space Model with Boundary-Region Selective Scan for Shadow Removal](https://arxiv.org/abs/2411.03260)
> *ShadowMamba：具有边界区域选择性扫描的状态空间模型用于阴影去除*

*Xiujin Zhu, Chee-Onn Chow, Joon Huang Chuah* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 阴影去除, 状态空间模型, Mamba, 边界区域选择性扫描, 轻量级模型

**Comment:** 

> **TL;DR:** ShadowMamba是首个基于Mamba的轻量级阴影去除模型，通过创新的边界区域选择性扫描机制，解决了现有方法在长距离依赖和边界语义连续性上的不足，在多个数据集上实现了SOTA性能，且参数和计算成本更低。

**AI_Comments:** 该论文的创新点在于首次将Mamba模型引入阴影去除领域，并针对该任务的特性，提出了新颖的边界区域选择性扫描机制，有效地解决了Mamba原机制在处理阴影边界时语义连续性不足的问题。结合轻量级的U-Net结构，ShadowMamba在提升性能的同时显著降低了资源消耗，这对于实际应用具有重要意义。其对局部细节和全局特征的分层处理方式也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 图像阴影去除是一个重要的低级视觉问题，阴影会影响下游任务的准确性。现有基于Transformer的阴影去除方法通过窗口机制提高效率，但牺牲了感受野和长距离依赖建模能力。Mamba模型在视觉任务中表现出色，但其原始扫描机制在阴影去除中忽略了阴影边界的语义连续性和区域内部的一致性。

**Method:** 提出了一种新的边界区域选择性扫描机制，该机制分别扫描阴影、边界和非阴影区域，使同类型像素在序列中更接近，从而增强语义连续性并帮助模型理解局部细节。在此基础上，设计了首个基于Mamba的轻量级阴影去除模型ShadowMamba。该模型采用分层组合U-Net结构，有效减少参数和计算复杂度。浅层利用边界区域选择性扫描捕获局部细节，深层则使用全局交叉扫描学习全局亮度特征。

**Result:** 在ISTD+、ISTD和SRD数据集上，ShadowMamba的性能优于当前最先进的模型，并且所需的参数更少，计算成本更低。

**Conclusion:** ShadowMamba通过创新的边界区域选择性扫描机制和轻量级U-Net结构，有效解决了阴影去除中长距离依赖和局部语义连续性建模的挑战，实现了卓越的性能和效率，为阴影去除任务提供了一个高效且优越的解决方案。

> **ai_Abstract:** 本论文提出了ShadowMamba，这是首个基于Mamba的轻量级阴影去除模型。针对现有Transformer模型在长距离依赖建模上的不足以及Mamba在阴影去除中对边界语义连续性的忽视，ShadowMamba引入了独特的边界区域选择性扫描机制，分别处理阴影、边界和非阴影区域，增强了局部细节理解和语义连续性。模型采用分层U-Net结构，浅层侧重局部细节，深层学习全局特征。实验证明，ShadowMamba在多个主流数据集上超越了现有SOTA模型，同时显著降低了参数量和计算成本，提供了一个高效且高性能的阴影去除解决方案。

> **摘要翻译:** 图像阴影去除是一个常见的低级视觉问题。阴影会导致某些区域亮度突然变化，从而影响下游任务的准确性。目前，基于Transformer的阴影去除方法通过使用窗口机制提高计算效率。然而，这种方法减少了有效感受野，削弱了对阴影图像中长距离依赖建模的能力。最近，Mamba通过以线性复杂度全局建模长序列信息，在计算机视觉领域取得了显著成功。然而，当应用于阴影去除时，其原始扫描机制忽略了阴影边界沿线的语义连续性以及每个区域内的一致性。为了解决这个问题，我们提出了一种新的边界区域选择性扫描机制，该机制分别扫描阴影、边界和非阴影区域，使相同类型的像素在序列中更接近。这增加了语义连续性，并有助于模型更好地理解局部细节。结合这一思想，我们设计了第一个基于Mamba的轻量级阴影去除模型，名为ShadowMamba。它采用分层组合U-Net结构，有效减少了参数数量和计算复杂度。浅层依赖我们的边界区域选择性扫描来捕获局部细节，而深层则使用全局交叉扫描来学习全局亮度特征。大量实验表明，ShadowMamba在ISTD+、ISTD和SRD数据集上的性能优于当前最先进的模型，并且所需的参数更少，计算成本更低。（代码将在论文被接受后提供。）

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [413] [DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space](https://arxiv.org/abs/2508.00413)
> *DC-AE 1.5：通过结构化潜在空间加速扩散模型收敛*

*Junyu Chen, Dongyun Zou, Wenkun He, Junsong Chen, Enze Xie, Song Han, Han Cai* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 扩散模型, 自编码器, 潜在空间, 收敛加速, 图像生成

**Comment:** ICCV 2025

> **TL;DR:** DC-AE 1.5通过引入结构化潜在空间和增强扩散训练，解决了高分辨率扩散模型在增加自编码器潜在通道数时收敛慢和生成质量差的问题，实现了更快的收敛和更好的图像生成质量。

**AI_Comments:** 这篇论文的创新点在于提出了两种互补的技术来优化高分辨率扩散模型中的自编码器使用。结构化潜在空间的概念通过明确区分潜在通道的功能，为扩散过程提供了更清晰、更有组织的信息流，而增强扩散训练则直接解决了收敛速度的瓶颈。这种结合方法有效地提升了潜在扩散模型的性能上限，对于需要高分辨率图像生成的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 提高自编码器的潜在通道数能有效改善重建质量，但会导致扩散模型收敛缓慢，生成质量下降，这限制了潜在扩散模型的质量上限，并阻碍了使用更高空间压缩比的自编码器。

**Method:** 本研究提出了两项关键创新：i) 结构化潜在空间：一种基于训练的方法，对潜在空间施加通道级结构，使前部潜在通道捕获对象结构，后部潜在通道捕获图像细节；ii) 增强扩散训练：一种增强的扩散训练策略，在对象潜在通道上增加额外的扩散训练目标以加速收敛。

**Result:** DC-AE 1.5比DC-AE收敛更快，扩散缩放结果更好。在ImageNet 512x512数据集上，DC-AE-1.5-f64c128比DC-AE-f32c32提供了更好的图像生成质量，同时速度快4倍。

**Conclusion:** DC-AE 1.5通过引入结构化潜在空间和增强扩散训练，有效解决了高分辨率扩散模型在增加潜在通道数时面临的收敛慢和生成质量下降的问题，显著提升了生成效率和质量。

> **ai_Abstract:** DC-AE 1.5是一种新型深度压缩自编码器，旨在解决高分辨率扩散模型中增加潜在通道数导致收敛慢和生成质量下降的问题。通过引入“结构化潜在空间”来组织潜在通道（区分对象结构和图像细节）和“增强扩散训练”来加速收敛，DC-AE 1.5实现了比现有方法更快的收敛和更优的生成质量，例如在ImageNet上速度提升4倍且质量更佳。

> **摘要翻译:** 我们提出了DC-AE 1.5，这是一系列用于高分辨率扩散模型的新型深度压缩自编码器。增加自编码器的潜在通道数是提高其重建质量的有效方法。然而，这会导致扩散模型收敛缓慢，尽管重建质量更好，但生成质量却更差。这个问题限制了潜在扩散模型的质量上限，并阻碍了使用更高空间压缩比的自编码器。为了解决这一挑战，我们引入了两项关键创新：i) 结构化潜在空间，这是一种基于训练的方法，旨在对潜在空间施加所需的通道级结构，使前部潜在通道捕获对象结构，后部潜在通道捕获图像细节；ii) 增强扩散训练，这是一种增强的扩散训练策略，在对象潜在通道上增加额外的扩散训练目标以加速收敛。凭借这些技术，DC-AE 1.5比DC-AE提供了更快的收敛速度和更好的扩散缩放结果。在ImageNet 512x512数据集上，DC-AE-1.5-f64c128比DC-AE-f32c32提供了更好的图像生成质量，同时速度快4倍。代码：https://github.com/dc-ai-projects/DC-Gen。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [417] [Wukong Framework for Not Safe For Work Detection in Text-to-Image systems](https://arxiv.org/abs/2508.00591)
> *悟空框架用于文本到图像系统中不安全内容检测*

*Mingrui Liu, Sixiao Zhang, Cheng Long* | **Category: cs.CV, cs.AI, cs.CR** | **Updated: 2025-08-01**

**Keywords:** NSFW检测, 文本到图像, 扩散模型, Wukong, AI生成内容

**Comment:** Under review

> **TL;DR:** 本文提出了Wukong，一个高效的文本到图像（T2I）系统内部不安全内容（NSFW）检测框架。它利用早期去噪步骤和交叉注意力机制，在效率显著提高的同时，实现了与图像过滤器相当的准确性，并优于文本过滤器。

**AI_Comments:** 本文提出了一种创新性的方法，将NSFW检测直接集成到扩散模型的生成过程中，特别是利用了中间步骤和预训练的U-Net组件。这种“过程中”的检测方法相对于传统的外部过滤器来说是一个重大改进，提供了一种更高效、延迟更低的解决方案。对现有模型参数的重用也是一个巧妙的优化，有助于提高效率。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像（T2I）生成技术可能产生包含不安全内容（NSFW）的图像，这违反了社区准则。现有的外部防护措施（文本过滤器和图像过滤器）存在局限性：文本过滤器容易忽略模型特有变体且易受对抗性攻击；图像过滤器计算成本高昂且引入延迟。因此，需要一种高效、准确的NSFW内容检测方法。

**Method:** 基于早期去噪步骤定义图像语义布局以及U-Net中的交叉注意力层对齐文本和图像区域的关键作用，本文提出了Wukong框架。Wukong是一个基于Transformer的NSFW检测框架，它利用早期去噪步骤的中间输出，并重用U-Net预训练的交叉注意力参数。Wukong在扩散过程中运行，实现了无需等待完整图像生成即可进行早期检测。此外，作者还引入了一个包含提示词、种子和图像特定NSFW标签的新数据集，并在该数据集和两个公共基准上评估了Wukong。

**Result:** Wukong的检测结果显著优于基于文本的防护措施，并且在提供更高效率的同时，达到了与图像过滤器相当的准确性。

**Conclusion:** Wukong框架通过将NSFW检测整合到扩散过程中，为文本到图像（T2I）系统提供了一个高效且准确的不安全内容检测解决方案。

> **ai_Abstract:** Wukong是一个新颖的、基于Transformer的框架，旨在为文本到图像（T2I）生成系统（如基于扩散模型的系统）提供高效的不安全内容（NSFW）检测。为解决现有文本和图像过滤器存在的局限性，Wukong在图像生成的早期去噪步骤中运行，利用中间输出并重用U-Net的交叉注意力层。这种方法实现了早期检测，显著降低了计算成本和延迟。通过在新数据集和公共基准上的评估，Wukong展示了优于基于文本的方法的性能，并在效率显著提高的同时，达到了与图像过滤器相当的准确性。

> **摘要翻译:** 文本到图像（T2I）生成是一种流行的AI生成内容（AIGC）技术，能够实现多样化和创造性的图像合成。然而，一些输出可能包含不安全内容（NSFW）（例如暴力），违反社区准则。高效准确地检测NSFW内容，即外部安全防护，至关重要。现有的外部安全防护分为两种类型：文本过滤器，它们分析用户提示，但忽略T2I模型特有的变体，并且容易受到对抗性攻击；图像过滤器，它们分析最终生成的图像，但计算成本高昂并引入延迟。扩散模型是现代T2I系统（如Stable Diffusion）的基础，它们通过使用带有ResNet和Transformer块的U-Net架构进行迭代去噪来生成图像。我们观察到：（1）早期去噪步骤定义了图像的语义布局，（2）U-Net中的交叉注意力层对于对齐文本和图像区域至关重要。基于这些见解，我们提出了Wukong，一个基于Transformer的NSFW检测框架，它利用早期去噪步骤的中间输出并重用U-Net的预训练交叉注意力参数。Wukong在扩散过程中运行，实现了无需等待完整图像生成即可进行早期检测。我们还引入了一个包含提示词、种子和图像特定NSFW标签的新数据集，并在该数据集和两个公共基准上评估了Wukong。结果表明，Wukong显著优于基于文本的防护措施，并且在提供更高效率的同时，达到了与图像过滤器相当的准确性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [419] [Minimum Data, Maximum Impact: 20 annotated samples for explainable lung nodule classification](https://arxiv.org/abs/2508.00639)
> *最小数据，最大影响：用于可解释肺结节分类的20个注释样本*

*Luisa Gallée, Catharina Silvia Lisson, Christoph Gerhard Lisson, Daniela Drees, Felix Weig, Daniel Vogele, Meinrad Beer, Michael Götz* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 合成数据, 可解释AI, 肺结节分类, 扩散模型, 属性注释

**Comment:** Accepted at iMIMIC - Interpretability of Machine Intelligence in
  Medical Image Computing workshop MICCAI 2025 Medical Image Computing and
  Computer Assisted Intervention

> **TL;DR:** 使用扩散模型仅用20个样本生成带注释的医学图像，显著提升了可解释肺结节分类模型的性能。

**AI_Comments:** 这项工作展示了在数据极度稀缺的情况下，通过生成式AI（扩散模型）合成数据来弥补数据不足的强大潜力，尤其是在医疗影像分析这种对数据标注要求高且数据获取困难的领域。其创新点在于利用极少量真实数据训练生成模型，并有效提升了下游可解释模型的性能。这对于推动可解释AI在临床实践中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 可解释的医学图像诊断模型因缺乏大规模带有属性注释的数据集而难以推广应用。

**Method:** 提出使用生成模型（增强的扩散模型）合成带有属性注释的数据，仅使用LIDC-IDRI数据集中20个带有属性标签的肺结节样本进行训练。然后将生成的图像用于训练可解释模型。

**Result:** 与仅使用少量真实注释数据训练相比，将生成的图像纳入训练后，属性预测准确率提高了13.4%，目标预测准确率提高了1.8%。

**Conclusion:** 合成数据有望克服数据集限制，从而增强可解释模型在医学图像分析中的适用性。

> **ai_Abstract:** 本文旨在解决可解释医学图像诊断模型因缺乏大规模带属性注释数据集而难以推广的问题。作者提出利用增强型扩散模型，仅使用LIDC-IDRI数据集中20个带属性标签的肺结节样本，合成带有属性注释的医学图像。实验结果表明，将这些合成图像用于训练可解释模型，能显著提升其性能，使属性预测准确率提高13.4%，目标预测准确率提高1.8%。这项工作突出了合成数据在克服数据集限制、增强可解释模型在医学图像分析中应用方面的巨大潜力。

> **摘要翻译:** 提供人类可解释性解释的分类模型增强了临床医生在医学图像诊断中的信任和可用性。一个研究重点是将放射科医生使用的与病理学相关的视觉属性与诊断相结合并进行预测，从而使人工智能的决策与临床推理保持一致。放射科医生使用形状和纹理等属性作为既定的诊断标准，在人工智能决策中反映这些属性既能增强透明度，又能实现模型输出的明确验证。然而，此类模型的采用受到缺乏大规模带有这些属性注释的医学图像数据集的限制。为了解决这一挑战，我们提出使用生成模型合成带有属性注释的数据。我们使用属性条件增强了扩散模型，并仅使用LIDC-IDRI数据集中20个带有属性标签的肺结节样本对其进行训练。与仅使用小型真实属性注释数据集进行训练相比，将其生成的图像纳入可解释模型的训练中，可以提高性能，使属性预测准确率提高13.4%，目标预测准确率提高1.8%。这项工作强调了合成数据克服数据集限制的潜力，从而增强了可解释模型在医学图像分析中的适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [425] [Cued-Agent: A Collaborative Multi-Agent System for Automatic Cued Speech Recognition](https://arxiv.org/abs/2508.00391)
> *提示语代理：一个用于自动提示语识别的协作多智能体系统*

*Guanjie Huang, Danny H. K. Tsang, Shan Yang, Guangzhi Lei, Li Liu* | **Category: cs.CV, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 提示语识别, 多智能体系统, 多模态融合, 协作学习, 听力障碍辅助

**Comment:** 9 pages

> **TL;DR:** 本文提出了Cued-Agent，首个用于自动提示语识别的协作多智能体系统，旨在解决现有方法在处理手唇异步性和数据有限性方面的性能瓶颈，并在实验中表现出色。

**AI_Comments:** 这项工作首次将协作多智能体系统引入自动提示语识别领域，有效地解决了多模态时间异步性和数据稀缺性带来的挑战。其创新的模块化设计，特别是引入多模态大语言模型和训练无关的融合机制，以及端到端语义细化，为ACSR提供了新的范式和显著的性能提升。扩展数据集也为后续研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 自动提示语识别（ACSR）中手部和唇部动作之间的时间异步性需要复杂的多模态融合模块，但由于数据可用性有限，当前方法在充分训练这些融合机制方面的能力不足，导致性能不佳。

**Method:** 本文提出了Cued-Agent，一个协作多智能体系统，集成了四个专业子智能体：一个基于多模态大语言模型的手部识别智能体、一个预训练Transformer的唇部识别智能体、一个在推理时无训练地动态整合手部提示与唇部特征的手部提示解码智能体，以及一个首次通过语义细化实现音素序列到自然语言端到端转换的自校正音素转词智能体。此外，研究团队还扩展了现有的普通话提示语数据集。

**Result:** 广泛的实验表明，与现有最先进的方法相比，Cued-Agent在正常和听障情景下均表现出色。

**Conclusion:** Cued-Agent作为首个协作多智能体系统，通过其创新的多智能体架构和对数据集的扩展，显著提升了自动提示语识别的性能，尤其在有限数据和处理多模态异步性方面展现了优越性。

> **ai_Abstract:** 本文提出Cued-Agent，一个用于自动提示语识别（ACSR）的协作多智能体系统，旨在解决现有方法在处理手唇异步性和数据有限性时的性能瓶颈。Cued-Agent包含四个专业子智能体，分别负责手部识别、唇部特征提取、手唇特征融合以及音素到词的转换。通过扩展普通话提示语数据集并在混合数据集上进行广泛实验，Cued-Agent在多种场景下均超越了现有最先进的方法。

> **摘要翻译:** 提示语（CS）是一种视觉交流系统，结合了唇读和手语编码，以方便听力障碍者的交流。自动提示语识别（ACSR）旨在通过人工智能驱动的方法将提示语手势和唇部动作转换为文本。传统上，手部和唇部动作之间的时间异步性需要设计复杂的模块来促进有效的多模态融合。然而，受限于有限的数据可用性，当前方法在充分训练这些融合机制方面的能力不足，导致性能不佳。最近，多智能体系统在处理数据可用性有限的复杂任务方面显示出有前景的能力。为此，我们提出了首个用于ACSR的协作多智能体系统，命名为Cued-Agent。它集成了四个专业子智能体：一个基于多模态大语言模型的手部识别智能体，该智能体采用关键帧筛选和CS专家提示策略来解码手部动作；一个基于预训练Transformer的唇部识别智能体，该智能体从输入视频中提取唇部特征；一个手部提示解码智能体，该智能体在推理过程中以无训练的方式动态地将手部提示与唇部特征集成；以及一个自校正音素转词智能体，该智能体首次通过语义细化实现了从音素序列到自然语言句子的后处理和端到端转换。为了支持这项研究，我们通过收集八名听障提示语者的Ddata，扩展了现有的普通话提示语数据集，建立了一个包含十四名受试者的混合数据集。广泛的实验表明，与现有最先进的方法相比，我们的Cued-Agent在正常和听障情景下均表现出色。该实现可在https://github.com/DennisHgj/Cued-Agent获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [426] [SynPAIN: A Synthetic Dataset of Pain and Non-Pain Facial Expressions](https://arxiv.org/abs/2507.19673)
> *SynPAIN：一个合成的疼痛和非疼痛面部表情数据集*

*Babak Taati, Muhammad Muzammil, Yasamin Zarghami, Abhishek Moturu, Amirhossein Kazerouni, Hailey Reimer, Alex Mihailidis, Thomas Hadjistavropoulos* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 合成数据集, 疼痛检测, 面部表情, 算法偏差, 老年人

**Comment:** 10 pages, 4 figures, submitted to IEEE JBHI

> **TL;DR:** SynPAIN是一个大规模的合成数据集，用于解决现有疼痛检测数据集中缺乏多样性和对老年人代表性不足的问题，并展示了其在识别算法偏差和改善真实临床数据疼痛检测性能方面的效用。

**AI_Comments:** SynPAIN的创新之处在于它是第一个专门为老年人疼痛检测设计的、公开可用的、人口统计学多样化的合成数据集。它有效地解决了真实世界数据采集面临的隐私和多样性挑战，为疼痛评估研究提供了宝贵的资源。此外，该工作不仅提供了数据集，还建立了一个评估和缓解算法偏差的框架，这对于确保AI医疗应用公平性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有疼痛检测数据集存在种族/民族多样性有限、隐私限制以及老年人（主要目标人群）代表性不足的问题，这阻碍了鲁棒自动化疼痛检测系统的开发，而准确的疼痛评估对于沟通能力有限的患者至关重要。

**Method:** 研究人员使用商业生成式AI工具创建了SynPAIN，一个包含10,710张面部表情图像（5,355对中性/表情对）的大规模合成数据集。数据集涵盖五种族/民族、两个年龄组（年轻：20-35岁，老年：75岁以上）和两种性别，生成了具有临床意义的疼痛表情，并通过面部动作单元分析工具进行了验证。

**Result:** SynPAIN中的合成疼痛表情表现出预期的疼痛模式，得分显著高于中性/非疼痛表情。该数据集揭示了现有疼痛检测模型中算法偏差的存在，表现出跨人口特征的显著性能差异。此外，年龄匹配的合成数据增强将真实临床数据上的疼痛检测性能提高了7.0%（平均精度）。

**Conclusion:** SynPAIN通过提供第一个专门为老年人疼痛检测设计的、公开可用的、人口统计学多样化的合成数据集，解决了疼痛评估研究中的关键空白，并建立了一个测量和缓解算法偏差的框架。

> **ai_Abstract:** SynPAIN是一个新颖的大规模合成数据集，包含10,710张面部表情图像，旨在解决现有疼痛检测数据集中缺乏多样性、隐私问题以及老年人代表性不足的问题。该数据集通过商业生成式AI工具创建，涵盖了不同种族、年龄和性别，并被证明能够生成临床上有效的疼痛表情。研究表明，SynPAIN有助于识别和评估现有疼痛检测模型中的算法偏差，并能通过数据增强显著提升真实临床数据的疼痛检测性能，尤其是在老年人疼痛评估方面。

> **摘要翻译:** 准确评估沟通能力有限的患者（如患有痴呆症的老年人）的疼痛，是一个关键的医疗挑战。强大的自动化疼痛检测系统可能有助于此类评估。然而，现有的疼痛检测数据集存在种族/民族多样性有限、隐私限制以及老年人（临床部署的主要目标人群）代表性不足的问题。我们提出了SynPAIN，一个大规模的合成数据集，包含10,710张面部表情图像（5,355对中性/表情对），涵盖五种族/民族、两个年龄组（年轻：20-35岁，老年：75岁以上）和两种性别。通过使用商业生成式AI工具，我们创建了人口统计学平衡的合成身份，具有临床上有意义的疼痛表情。我们的验证表明，合成疼痛表情表现出预期的疼痛模式，使用基于面部动作单元分析的临床验证疼痛评估工具，其得分显著高于中性和非疼痛表情。我们实验性地证明了SynPAIN在识别现有疼痛检测模型中算法偏差的效用。通过全面的偏差评估，我们揭示了跨人口特征的显著性能差异。这些性能差异以前在更小、多样性更低的数据集中是无法检测到的。此外，我们证明了年龄匹配的合成数据增强改善了真实临床数据上的疼痛检测性能，平均精度提高了7.0%。SynPAIN通过提供第一个公开可用的、人口统计学多样化的合成数据集，专门为老年人疼痛检测设计，同时建立了一个测量和缓解算法偏差的框架，解决了疼痛评估研究中的关键空白。该数据集可在https://doi.org/10.5683/SP3/WCXMAP获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [427] [The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking](https://arxiv.org/abs/2508.00088)
> *用于自我中心视觉惯性跟踪的 Monado SLAM 数据集*

*Mateo de Mayo, Daniel Cremers, Taihú Pire* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-31**

**Keywords:** Monado SLAM, 视觉惯性跟踪, 数据集, 头戴式设备, VIO/SLAM

**Comment:** Accepted to IROS 2025

> **TL;DR:** 本文介绍了 Monado SLAM 数据集，旨在解决现有视觉惯性里程计 (VIO) 和同步定位与建图 (SLAM) 系统在头戴式设备使用场景中遇到的挑战，例如高强度运动、动态遮挡和低纹理区域等，并促进 VIO/SLAM 领域的研究进展。

**AI_Comments:** 该论文通过发布一个专门针对头戴式设备挑战性场景（如高强度运动、动态遮挡、低纹理区域和恶劣光照条件）的视觉惯性跟踪数据集，填补了现有数据集的空白。其创新之处在于提供了真实世界中更具挑战性的数据，这对于开发更鲁棒的 VIO/SLAM 系统至关重要。数据集的开放许可也有助于加速该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉惯性里程计 (VIO) 和同步定位与建图 (SLAM) 系统在处理头戴式设备使用场景中的挑战性设置时表现不佳，例如高强度运动、动态遮挡、长时间跟踪、低纹理区域、恶劣光照条件和传感器饱和等。现有的数据集未能充分覆盖这些真实世界的问题，导致系统可能忽略这些关键问题。

**Method:** 为了解决现有数据集的不足，作者提出了 Monado SLAM 数据集，这是一组从多个虚拟现实头戴设备中获取的真实序列。

**Result:** 作者发布了 Monado SLAM 数据集，并采用宽松的 CC BY 4.0 许可协议。

**Conclusion:** Monado SLAM 数据集的发布旨在推动 VIO/SLAM 研究和开发的进展。

> **ai_Abstract:** 本文介绍了 Monado SLAM 数据集，旨在弥补现有视觉惯性里程计 (VIO) 和同步定位与建图 (SLAM) 系统在头戴式设备应用中面临的挑战，如高强度运动和恶劣环境条件。该数据集包含从多个虚拟现实头戴设备获取的真实序列，并以开放许可发布，以促进 VIO/SLAM 领域的进一步研究和发展。

> **摘要翻译:** 人形机器人和混合现实头戴设备受益于使用头戴式传感器进行跟踪。虽然视觉惯性里程计 (VIO) 和同步定位与建图 (SLAM) 的进步已经产生了新的高质量最先进的跟踪系统，但我们表明这些系统仍然无法优雅地处理头戴式使用场景中出现的许多挑战性设置。高强度运动、动态遮挡、长时间跟踪会话、低纹理区域、恶劣光照条件、传感器饱和等常见场景，现有文献中的数据集仍然覆盖不足。通过这种方式，系统可能会无意中忽略这些基本的真实世界问题。为了解决这个问题，我们提出了 Monado SLAM 数据集，这是一组从多个虚拟现实头戴设备中获取的真实序列。我们根据宽松的 CC BY 4.0 许可协议发布该数据集，以推动 VIO/SLAM 研究和开发的进展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [428] [Contact-Aware Amodal Completion for Human-Object Interaction via Multi-Regional Inpainting](https://arxiv.org/abs/2508.00427)
> *接触感知型无模态补全用于人机交互的多区域修复*

*Seunggeun Chi, Enna Sachdeva, Pin-Hao Huang, Kwonjoon Lee* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 无模态补全, 人机交互, 扩散模型, 多区域修复, 物理先验知识

**Comment:** ICCV 2025 (Highlight)

> **TL;DR:** 本文提出一种新的接触感知型多区域修复方法，通过结合物理先验知识和定制化的去噪策略，显著提升了人机交互场景下无模态补全的准确性和真实感。

**AI_Comments:** 该论文的创新点在于将物理先验知识（人体拓扑和接触信息）融入到扩散模型的无模态补全过程中，并通过定义多区域（主要和次要遮挡区域）并应用定制化去噪策略来解决人机交互场景下物体遮挡补全的挑战。这种方法提高了补全的准确性和真实感，尤其是在动态环境中。其在无接触标注情况下的鲁棒性也增强了其在实际应用中的潜力，例如3D重建和新视图/姿态合成。

<details>
  <summary>Details</summary>

**Motivation:** 现有的无模态补全方法（如使用预训练扩散模型）在动态场景下生成的人机交互补全结果往往不合理，因为它们对人机交互的理解有限。无模态补全对于计算机视觉和机器人技术中理解复杂的人机交互至关重要。

**Method:** 作者开发了一种新方法，该方法结合了物理先验知识和专门用于人机交互的多区域修复技术。通过结合人体拓扑和接触信息的物理约束，定义了两个不同的区域：主要区域（遮挡物体部分最可能出现的地方）和次要区域（遮挡可能性较小的地方）。该多区域修复方法在扩散模型中对这些区域采用定制化的去噪策略。

**Result:** 实验结果表明，该方法在人机交互场景下显著优于现有方法，提高了生成补全结果的形状和视觉细节的准确性和真实感。该方法即使没有真实接触标注也具有鲁棒性。

**Conclusion:** 该方法使机器感知更接近对动态环境的人类理解，并扩大了其在3D重建和新视图/姿态合成等任务中的适用性。

> **ai_Abstract:** 本文提出一种新颖的接触感知型无模态补全方法，用于改善人机交互场景下的物体补全。针对现有方法在动态HOI中表现不佳的问题，该方法引入物理先验知识和多区域修复技术。通过定义主要和次要遮挡区域并应用定制化去噪策略，显著提升了补全结果的准确性和真实感。实验证明，该方法在HOI场景中性能优越，且在无接触标注的情况下仍保持鲁棒性，拓展了其在3D重建等领域的应用。

> **摘要翻译:** 无模态补全，即尽管部分被遮挡也能推断物体完整外观的过程，对于计算机视觉和机器人技术中理解复杂的人机交互（HOI）至关重要。现有方法，例如使用预训练扩散模型的方法，在动态场景中往往难以生成合理的补全结果，因为它们对人机交互的理解有限。为了解决这个问题，我们开发了一种新方法，该方法结合了物理先验知识和专门为HOI设计的定制化多区域修复技术。通过结合人体拓扑和接触信息的物理约束，我们定义了两个不同的区域：主要区域，即被遮挡物体部分最可能出现的地方；次要区域，即遮挡可能性较小的地方。我们的多区域修复方法在扩散模型中对这些区域采用定制化的去噪策略。这提高了生成补全结果在形状和视觉细节方面的准确性和真实感。我们的实验结果表明，我们的方法在HOI场景中显著优于现有方法，使机器感知更接近对动态环境的人类理解。我们还表明，即使没有真实接触标注，我们的管道也具有鲁棒性，这扩大了其在3D重建和新视图/姿态合成等任务中的适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [430] [Sign Spotting Disambiguation using Large Language Models](https://arxiv.org/abs/2507.03703)
> *使用大型语言模型的手语识别消歧*

*JianHe Low, Ozge Mercanoglu Sincan, Richard Bowden* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 手语识别, 大型语言模型, 歧义消除, 无需训练, 动态时间规整

**Comment:** Accepted in the international conference on Intelligent Virtual
  Agents (IVA Adjunct)

> **TL;DR:** 本文提出了一种无需训练的新框架，利用大型语言模型（LLMs）来提高手语识别的质量，通过字典匹配和LLM进行上下文感知的词语消歧，解决了数据稀缺和歧义问题。

**AI_Comments:** 该论文的创新之处在于引入了一种无需训练且结合LLMs的手语识别消歧框架，有效解决了手语数据稀缺和连续手语流中固有的歧义问题。其优势在于利用字典匹配提供词汇灵活性，并通过LLM进行上下文感知消歧，无需复杂的模型训练或微调。这对于手语翻译和数据集标注领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 手语识别（Sign spotting）在扩展数据集标注和解决手语翻译中严重的数据稀缺问题方面发挥着关键作用。然而，自动手语识别面临词汇不灵活性和连续手语流中固有的歧义等挑战。

**Method:** 提出了一种无需训练的新框架，该框架整合了大型语言模型（LLMs）。首先，提取全局时空和手形特征，然后使用动态时间规整和余弦相似度与大规模手语词典进行匹配。为了减轻匹配过程中的噪声和歧义，LLM通过束搜索（beam search）执行上下文感知的词语消歧，且无需微调。

**Result:** 在合成和真实世界手语数据集上的大量实验表明，与传统方法相比，该方法具有更高的准确性和句子流畅性。

**Conclusion:** 本文强调了大型语言模型在推进手语识别方面的潜力。

> **ai_Abstract:** 本文介绍了一种新颖的、无需训练的框架，旨在通过整合大型语言模型（LLMs）来提升手语识别的质量。该框架通过提取时空和手形特征，并与大规模手语词典进行动态时间规整和余弦相似度匹配，实现了优越的词汇灵活性。为解决匹配过程中的噪声和歧义，LLM在不进行微调的情况下，通过束搜索执行上下文感知的词语消歧。实验结果表明，该方法在准确性和句子流畅性方面优于传统方法，展示了LLMs在手语识别领域的巨大潜力。

> **摘要翻译:** 手语识别，即在连续手语视频中识别和定位单个手语的任务，在扩展数据集标注和解决手语翻译中严重的数据稀缺问题方面发挥着关键作用。尽管自动手语识别在实现大规模帧级监督方面前景广阔，但它也面临着词汇不灵活性和连续手语流中固有的歧义等挑战。因此，我们引入了一种新颖的、无需训练的框架，该框架集成了大型语言模型（LLMs），以显著提高手语识别质量。我们的方法提取全局时空和手形特征，然后使用动态时间规整和余弦相似度与大规模手语词典进行匹配。这种基于词典的匹配固有地提供了卓越的词汇灵活性，而无需模型再训练。为了减轻匹配过程中的噪声和歧义，LLM通过束搜索（beam search）执行上下文感知的词语消歧，值得注意的是，这无需微调。在合成和真实世界手语数据集上的大量实验表明，我们的方法与传统方法相比具有更高的准确性和句子流畅性，突出了LLMs在推进手语识别方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [435] [CorrCLIP: Reconstructing Patch Correlations in CLIP for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2411.10086)
> *CorrCLIP：在CLIP中重建补丁相关性以实现开放词汇语义分割*

*Dengke Zhang, Fagui Liu, Quan Tang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 开放词汇语义分割, CLIP, 补丁相关性, SAM, CorrCLIP

**Comment:** Accepted to ICCV 2025 Oral

> **TL;DR:** CorrCLIP通过重建补丁相关性，显著提升了CLIP在开放词汇语义分割任务上的性能。

**AI_Comments:** 该论文的创新点在于识别出CLIP在语义分割中性能不佳的关键原因——不连贯的补丁相关性，并提出了一个系统性的解决方案CorrCLIP。通过结合SAM的区域定义能力和自监督学习的相似度计算，以及引入额外的特征增强分支，有效提升了CLIP在开放词汇语义分割任务上的表现。其方法具有通用性和实用性，为后续研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 开放词汇语义分割旨在对每个像素进行语义标注，不受预定义类别的限制。然而，CLIP在零样本分类方面表现出色，但在将图像补丁与类别嵌入对齐时遇到困难，原因在于其不连贯的补丁相关性。本研究揭示了类间相关性是损害CLIP分割性能的主要原因。

**Method:** 我们提出了CorrCLIP，它重建了补丁相关性的范围和值。具体而言，CorrCLIP利用Segment Anything Model (SAM) 来定义补丁交互的范围，从而减少类间相关性。为了缓解SAM生成的掩码可能包含属于不同类别的补丁的问题，CorrCLIP整合了自监督模型来计算连贯的相似度值，从而抑制类间相关性的权重。此外，我们引入了两个额外的分支来增强补丁特征的空间细节和语义表示。最后，我们使用SAM生成的掩码更新分割图，以提高空间一致性。

**Result:** 基于补丁相关性、特征表示和分割图的改进，CorrCLIP在八个基准测试中取得了优异的性能。

**Conclusion:** CorrCLIP通过有效重建补丁相关性，解决了CLIP在开放词汇语义分割中遇到的类间相关性问题，显著提升了分割性能。

> **ai_Abstract:** 本研究提出CorrCLIP，旨在解决CLIP在开放词汇语义分割中因不连贯的补丁相关性（特别是类间相关性）导致的性能问题。CorrCLIP利用SAM定义补丁交互范围以减少类间相关性，并结合自监督模型计算连贯相似度值以抑制类间权重。同时，它引入额外分支增强特征的空间细节和语义表示，并使用SAM掩码更新分割图以提高空间一致性。CorrCLIP在八个基准测试中表现出卓越性能。

> **摘要翻译:** 开放词汇语义分割旨在为每个像素分配语义标签，而不受预定义类别的限制。尽管对比语言-图像预训练（CLIP）在零样本分类方面表现出色，但由于其不连贯的补丁相关性，它难以将图像补丁与类别嵌入对齐。本研究揭示了类间相关性是损害CLIP分割性能的主要原因。因此，我们提出了CorrCLIP，它重建了补丁相关性的范围和值。具体而言，CorrCLIP利用Segment Anything Model（SAM）来定义补丁交互的范围，减少了类间相关性。为了缓解SAM生成的掩码可能包含属于不同类别的补丁的问题，CorrCLIP整合了自监督模型来计算连贯的相似度值，抑制了类间相关性的权重。此外，我们引入了两个额外的分支来增强补丁特征的空间细节和语义表示。最后，我们使用SAM生成的掩码更新分割图以提高空间一致性。基于补丁相关性、特征表示和分割图的改进，CorrCLIP在八个基准测试中取得了优异的性能。代码可在以下网址获取：https://github.com/zdk258/CorrCLIP。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [438] [Video Forgery Detection with Optical Flow Residuals and Spatial-Temporal Consistency](https://arxiv.org/abs/2508.00397)
> *视频伪造检测，结合光流残差与时空一致性*

*Xi Xue, Kunio Suzuki, Nabarun Goswami, Takuya Shintate* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 视频伪造检测, 光流残差, 时空一致性, 扩散模型, 双分支架构

**Comment:** 

> **TL;DR:** 提出一种新的视频伪造检测框架，通过结合RGB外观特征和光流残差，利用双分支架构有效检测扩散模型生成的视频伪造。

**AI_Comments:** 该论文的创新点在于结合了RGB外观特征和光流残差，并采用双分支架构来同时捕获视频伪造中的外观和运动不一致性。这种互补特征的整合对于检测日益逼真的AI生成视频中的细微伪影至关重要，提高了检测的鲁棒性和泛化能力，对于应对深度伪造的挑战具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型生成的视频内容日益逼真，对视频伪造检测提出新挑战。现有方法难以捕获AI生成视频中精细的时间不一致性，尤其是在高视觉保真度和连贯运动的AI生成视频中。

**Method:** 提出一个利用时空一致性的检测框架，结合RGB外观特征和光流残差。模型采用双分支架构：一个分支分析RGB帧以检测外观层面的伪影，另一个分支处理光流残差以揭示由不完善的时间合成引起的微妙运动异常。

**Result:** 在文本到视频和图像到视频任务上，针对十种不同的生成模型进行了广泛实验，证明了所提方法的鲁棒性和强大的泛化能力。

**Conclusion:** 该方法通过结合RGB外观特征和光流残差，利用双分支架构有效检测了各种伪造视频，并展示出强大的鲁棒性和泛化能力，解决了现有方法难以捕获精细时间不一致性的问题。

> **ai_Abstract:** 针对扩散模型生成视频带来的伪造检测挑战，本文提出一种新的检测框架。该框架通过结合RGB外观特征和光流残差，利用双分支架构分别分析外观伪影和运动异常，从而有效捕捉视频中的时空不一致性。实验证明，该方法在多种生成模型和任务上表现出强大的鲁棒性和泛化能力。

> **摘要翻译:** 扩散模型视频生成技术的快速发展，使得合成内容日益逼真，给视频伪造检测带来了新的挑战。现有方法往往难以捕捉细粒度的时间不一致性，尤其是在视觉保真度高、运动连贯的AI生成视频中。在这项工作中，我们提出了一种利用时空一致性的检测框架，通过结合RGB外观特征和光流残差来实现。该模型采用双分支架构，其中一个分支分析RGB帧以检测外观层面的伪影，而另一个分支处理光流残差以揭示由不完善的时间合成引起的微妙运动异常。通过整合这些互补特征，所提出的方法能够有效检测各种伪造视频。在文本到视频和图像到视频任务上，针对十种不同的生成模型进行了广泛实验，证明了所提方法的鲁棒性和强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [443] [Reducing the gap between general purpose data and aerial images in concentrated solar power plants](https://arxiv.org/abs/2508.00440)
> *缩小通用数据与聚光太阳能发电厂航空图像之间的差距*

*M. A. Pérez-Cutiño, J. Valverde, J. Capitán, J. M. Díaz-Báñez* | **Category: cs.CV, cs.AI, cs.RO** | **Updated: 2025-08-01**

**Keywords:** 聚光太阳能, 航空图像, 合成数据, 机器学习, 故障检测

**Comment:** 

> **TL;DR:** 本文提出了AerialCSP，一个模拟聚光太阳能发电厂航空图像的虚拟数据集，用于预训练机器学习模型，以改善故障检测并减少对大量手动标注数据的需求。

**AI_Comments:** 本文的创新之处在于通过创建合成数据集来解决特定工业应用（聚光太阳能发电厂检测）中数据稀缺和领域差异的问题。这种方法提供了一种经济高效的解决方案，减少了对昂贵手动标注的依赖，使机器学习模型在该领域的部署更加实用和高效。数据集的公开可用性也促进了该领域的研究和发展。

<details>
  <summary>Details</summary>

**Motivation:** 在聚光太阳能发电厂的背景下，无人机捕获的航空图像存在独特的挑战，例如高反射表面和领域特定元素，这与现有数据集中的城市或自然景观不同。因此，在通用数据集上训练的机器学习模型难以推广到这种设置，需要大量的再训练和标注数据，而这既昂贵又耗时，不适合快速部署到工业应用中。

**Method:** 为了解决现有问题，本文提出了一种新颖的方法：创建AerialCSP，一个模拟聚光太阳能发电厂航空图像的虚拟数据集。通过生成与真实世界条件密切相似的合成数据，旨在促进模型在部署前的预训练，从而显著减少对大量手动标注的需求。具体贡献包括：引入AerialCSP高质量合成数据集用于目标检测和图像分割；在AerialCSP上对多个模型进行基准测试，为相关视觉任务建立基线；以及证明在AerialCSP上进行预训练显著改善了真实世界的故障检测。

**Result:** 1. 引入了AerialCSP，一个用于聚光太阳能发电厂航空检查的高质量合成数据集，为目标检测和图像分割提供了标注数据。
2. 在AerialCSP上对多个模型进行了基准测试，为聚光太阳能相关视觉任务建立了基线。
3. 证明了在AerialCSP上进行预训练显著改善了真实世界的故障检测，特别是对于罕见和小型缺陷，从而减少了对大量手动标注的需求。

**Conclusion:** 通过创建和利用合成数据集AerialCSP进行模型预训练，本文成功缩小了通用数据与聚光太阳能发电厂航空图像之间的差距。这种方法显著提高了机器学习模型在实际故障检测中的性能，尤其是在处理稀有和小型缺陷时，并且有效降低了对耗时且昂贵的手动数据标注的需求，为工业应用提供了更实用的解决方案。

> **ai_Abstract:** 本论文旨在解决机器学习模型在聚光太阳能发电厂（CSP）航空图像应用中遇到的挑战，即通用数据集训练的模型难以适应CSP特有的高反射表面和领域特定元素。为此，作者提出了AerialCSP，一个模拟CSP工厂航空图像的虚拟数据集，提供高质量的标注数据用于目标检测和图像分割。研究表明，在AerialCSP上进行模型预训练能显著提升真实世界的故障检测能力，尤其对于罕见和小型缺陷，并有效减少了对昂贵手动数据标注的需求。该数据集已公开可用。

> **摘要翻译:** 在聚光太阳能发电厂（CSP）的背景下，无人机捕获的航空图像带来了一系列独特的挑战。与现有数据集中常见的城市或自然景观不同，太阳能场包含高反射表面和传统计算机视觉基准中不常见的领域特定元素。因此，在通用数据集上训练的机器学习模型难以推广到这种设置，除非进行大量的再训练和处理大量标注数据。然而，收集和标注此类数据既昂贵又耗时，使其在工业应用中难以快速部署。
为了解决这个问题，我们提出了一种新颖的方法：创建AerialCSP，一个模拟CSP工厂航空图像的虚拟数据集。通过生成与真实世界条件密切相似的合成数据，我们的目标是促进模型在部署前的预训练，显著减少对大量手动标注的需求。我们的主要贡献有三方面：（1）我们引入了AerialCSP，一个用于CSP工厂航空检查的高质量合成数据集，提供用于目标检测和图像分割的标注数据；（2）我们在AerialCSP上对多个模型进行基准测试，为CSP相关视觉任务建立了基线；（3）我们证明了在AerialCSP上进行预训练显著改善了真实世界的故障检测，特别是对于罕见和小型缺陷，从而减少了对大量手动标注的需求。AerialCSP已在https://mpcutino.github.io/aerialcsp/公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [444] [Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](https://arxiv.org/abs/2508.00649)
> *重新审视目标检测器上的对抗性补丁防御：统一评估、大规模数据集和新见解*

*Junhao Zheng, Jiahao Sun, Chenhao Lin, Zhengyu Zhao, Chen Ma, Chong Zhang, Cong Wang, Qian Wang, Chao Shen* | **Category: cs.CV, cs.CR** | **Updated: 2025-08-01**

**Keywords:** 对抗性补丁, 目标检测器, 防御评估, 大规模数据集, 鲁棒性

**Comment:** 

> **TL;DR:** 该研究针对目标检测器上的对抗性补丁防御，构建了一个统一的评估基准和大规模数据集，并揭示了关于防御有效性和局限性的新见解。

**AI_Comments:** 该论文通过提供一个急需的标准化评估框架和大规模数据集，极大地推动了目标检测器对抗性鲁棒性研究的进展。其提出的新见解，特别是关于数据分布对防御难度的影响和更合适的性能评估指标，对未来防御设计具有重要指导意义。识别出当前防御在面对自适应攻击时的脆弱性也为后续研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有针对目标检测器补丁攻击的防御评估缺乏统一和全面的框架，导致对当前方法的评估不一致和不完整。

**Method:** 作者重新审视了11种代表性防御方法，并提出了第一个补丁防御基准，该基准涉及2个攻击目标、13种补丁攻击、11个目标检测器和4种不同的度量标准。在此基础上，他们构建了一个包含94种补丁类型和94,000张图像的大规模对抗性补丁数据集，并进行了全面的分析。

**Result:** 1. 防御自然补丁的难度在于数据分布，而非普遍认为的高频，新数据集可将现有防御性能提升15.09% AP@0.5。2. 被攻击对象的平均精度与防御性能高度一致，优于补丁检测精度。3. 自适应攻击可以显著绕过现有防御，而具有复杂/随机模型或通用补丁特性的防御相对更鲁棒。

**Conclusion:** 作者希望他们的分析能为正确评估补丁攻击/防御提供指导，并推动其设计进展。

> **ai_Abstract:** 该论文旨在解决目标检测器上对抗性补丁防御评估缺乏统一框架的问题。作者首次提出了一个全面的补丁防御基准，并构建了一个大规模数据集，对11种代表性防御方法在多种攻击和检测器下进行了评估。研究发现，防御自然补丁的挑战在于数据分布，而非高频；被攻击对象的平均精度是衡量防御性能更一致的指标。此外，论文指出自适应攻击能有效规避现有防御，而复杂或随机模型、以及具有通用补丁特性的防御表现出相对更强的鲁棒性。

> **摘要翻译:** 开发针对目标检测器上补丁攻击的可靠防御措施引起了越来越多的关注。然而，我们发现现有防御评估缺乏统一和全面的框架，导致对当前方法的评估不一致和不完整。为了解决这个问题，我们重新审视了11种代表性防御方法，并提出了第一个补丁防御基准，该基准涉及2个攻击目标、13种补丁攻击、11个目标检测器和4种不同的度量标准。这促成了包含94种补丁类型和94,000张图像的大规模对抗性补丁数据集的创建。我们全面的分析揭示了新的见解：(1) 防御自然补丁的难度在于数据分布，而非普遍认为的高频。我们具有多样化补丁分布的新数据集可将现有防御性能提高15.09% AP@0.5。(2) 被攻击对象的平均精度，而非普遍追求的补丁检测精度，与防御性能表现出高度一致性。(3) 自适应攻击可以显著绕过现有防御，而具有复杂/随机模型或通用补丁特性的防御相对更鲁棒。我们希望我们的分析能为正确评估补丁攻击/防御提供指导，并推动其设计进展。代码和数据集可在 https://github.com/Gandolfczjh/APDE 获取，我们将在此持续整合新的攻击/防御。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [451] [HumanSAM: Classifying Human-centric Forgery Videos in Human Spatial, Appearance, and Motion Anomaly](https://arxiv.org/abs/2507.19924)
> *HumanSAM：对以人为中心的伪造视频进行人体空间、外观和运动异常分类*

*Chang Liu, Yunfan Ye, Fan Zhang, Qingyang Zhou, Yuchuan Luo, Zhiping Cai* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 伪造视频检测, 人体中心伪造, 细粒度分类, 空间异常, 外观异常, 运动异常, HumanSAM, HFV数据集

**Comment:** ICCV 2025. Project page: https://dejian-lc.github.io/humansam/

> **TL;DR:** HumanSAM是一个新的框架，旨在将以人为中心的伪造视频分类为空间、外观和运动异常三种类型，以解决现有二元检测方法缺乏细粒度理解的问题。它通过融合视频理解和空间深度分支生成伪造表示，并引入排序置信度增强策略，同时构建了首个公共基准HFV数据集。

**AI_Comments:** 该论文的创新点在于提出了对以人为中心的伪造视频进行细粒度分类（空间、外观、运动异常），这超越了传统的二元检测，显著提升了伪造检测的可靠性和可解释性。此外，构建首个公共的、精心标注的HFV数据集，为该领域的研究提供了宝贵的资源，具有重要的推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 生成模型（特别是以人为中心的模型）合成的视频日益增多，对人类信息安全和真实性构成重大威胁。尽管二元伪造视频检测取得了进展，但缺乏对伪造类型的细粒度理解，这引发了对可靠性和可解释性的担忧，而这些对于实际应用至关重要。

**Method:** 我们提出了HumanSAM框架，旨在将以人为中心的伪造视频分类为空间、外观和运动异常三种独特的伪影类型。为更好地捕捉几何、语义和时空一致性特征，我们通过融合视频理解和空间深度两个分支来生成人体伪造表示。训练过程中，我们还采用了一种基于排序的置信度增强策略，通过引入三个先验分数来学习更鲁棒的表示。为了训练和评估，我们构建了第一个公共基准数据集——以人为中心的伪造视频（HFV）数据集，其中所有伪造类型都经过半自动精心标注。

**Result:** 在实验中，HumanSAM在二元和多类别伪造分类方面，与最先进的方法相比，都取得了可喜的成果。

**Conclusion:** HumanSAM框架通过引入细粒度的伪造类型分类（空间、外观、运动异常）和构建新的公共数据集，有效地解决了以人为中心的伪造视频检测中可靠性和可解释性不足的问题，并在实验中展现出优于现有方法的性能。

> **ai_Abstract:** 本论文提出了HumanSAM框架，旨在解决现有二元伪造视频检测方法在细粒度理解和可解释性方面的不足。HumanSAM专注于将以人为中心的伪造视频分类为空间、外观和运动异常三种类型，并通过融合视频理解与空间深度分支来捕捉伪造特征，同时采用基于排序的置信度增强策略提升表示鲁棒性。为支持研究，论文还构建了首个带有细致标注的公共基准数据集HFV。实验结果表明，HumanSAM在二元和多类别伪造分类上均优于现有先进方法。

> **摘要翻译:** 生成模型，特别是模拟真实人类行为的以人为中心的模型，合成的视频数量众多，对人类信息安全和真实性构成了重大威胁。尽管二元伪造视频检测取得了进展，但缺乏对伪造类型的细粒度理解，这引发了对可靠性和可解释性的担忧，而这些对于实际应用至关重要。为解决这一局限性，我们提出了HumanSAM，这是一个基于视频生成模型基本挑战的新框架。具体而言，HumanSAM旨在将以人为中心的伪造分类为生成内容中常见的三种不同伪影类型：空间、外观和运动异常。为更好地捕捉几何、语义和时空一致性的特征，我们建议通过融合视频理解和空间深度两个分支来生成人体伪造表示。我们还在训练过程中采用了一种基于排序的置信度增强策略，通过引入三个先验分数来学习更鲁棒的表示。为训练和评估，我们构建了第一个公共基准数据集——以人为中心的伪造视频（HFV）数据集，其中所有类型的伪造都经过半自动精心标注。在我们的实验中，HumanSAM在二元和多类别伪造分类方面，与最先进的方法相比，都取得了可喜的成果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [452] [Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images](https://arxiv.org/abs/2508.00135)
> *探索深度学习技术在眼部图像精准性别分类中的可行性*

*Basna Mohammed Salih Hasan, Ramadhan J. Mstafa* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 性别分类, 深度学习, 眼周区域, 卷积神经网络, 图像识别

**Comment:** 12 pages, 18 figures, 5 tables

> **TL;DR:** 本研究探索了使用深度学习技术通过眼周区域图像进行性别分类的可行性，并提出了一种CNN模型，在两个眼部数据集上取得了高准确率，表明其在安全和监控领域的应用潜力。

**AI_Comments:** 该研究通过专注于眼周区域，有效解决了传统面部识别中化妆和伪装对性别分类准确性的影响，具有创新性。其提出的CNN模型在两个数据集上均取得了高准确率，证明了方法的有效性，为实际应用提供了坚实基础。

<details>
  <summary>Details</summary>

**Motivation:** 性别分类在安全、人机交互、监控和广告等多个领域至关重要。然而，化妆和伪装等因素会影响分类的准确性。本研究旨在通过关注使用眼周区域彩色图像进行性别分类来解决这个问题。

**Method:** 本研究引入了一个复杂的卷积神经网络（CNN）模型，该模型利用彩色图像数据库评估眼周区域在性别分类中的有效性。模型在CVBL和（Female and Male）两个眼部数据集上进行了测试。

**Result:** 所推荐的架构在CVBL数据集上取得了99%的杰出准确率，并在（Female and Male）数据集上以少量可学习参数（7,235,089个）取得了96%的值得称赞的准确率。通过广泛的度量标准评估并与其他最先进的方法进行比较，结果明确证明了模型的有效性。

**Conclusion:** 本研究的结果明确证明了所提出的模型在利用眼周区域进行性别分类方面的有效性，表明其在安全和监控等领域的潜在实际应用。

> **ai_Abstract:** 本论文探讨了利用深度学习技术对眼部图像进行性别分类的可行性，以克服化妆和伪装对分类准确性的影响。研究提出了一种基于眼周区域彩色图像的卷积神经网络（CNN）模型。该模型在CVBL数据集上达到了99%的准确率，在（Female and Male）数据集上达到了96%的准确率，且参数量较少。结果表明该模型在性别分类方面表现出色，具有应用于安全和监控等领域的潜力。

> **摘要翻译:** 性别分类已成为安全、人机交互、监控和广告等各个领域的关键方面。然而，这种分类的准确性可能会受到化妆和伪装等因素的影响。因此，我们的研究致力于通过关注使用眼周区域彩色图像进行性别分类来解决这个问题。眼周区域是指眼睛周围的区域，包括眼睑、眉毛以及它们之间的区域。它包含有价值的视觉线索，可用于提取性别分类的关键特征。本文介绍了一种复杂的卷积神经网络（CNN）模型，该模型利用彩色图像数据库来评估眼周区域在性别分类中的有效性。为了验证模型的性能，我们对两个眼部数据集进行了测试，即CVBL和（Female and Male）。所推荐的架构在之前未使用的CVBL数据集上取得了99%的杰出准确率，同时在（Female and Male）数据集上以少量可学习参数（7,235,089个）取得了96%的值得称赞的准确率。为了确定我们提出的模型在利用眼周区域进行性别分类方面的有效性，我们通过广泛的度量标准评估了其性能，并将其与其他最先进的方法进行了比较。结果明确证明了我们模型的有效性，从而表明其在安全和监控等领域的潜在实际应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [453] [iSafetyBench: A video-language benchmark for safety in industrial environment](https://arxiv.org/abs/2508.00399)
> *iSafetyBench：一个用于工业环境安全性的视频-语言基准*

*Raiyaan Abdullah, Yogesh Singh Rawat, Shruti Vyas* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 视频-语言模型, 工业安全, 基准测试, 零样本学习, 多标签识别

**Comment:** Accepted to VISION'25 - ICCV 2025 workshop

> **TL;DR:** iSafetyBench是一个新的视频-语言基准，旨在评估视觉-语言模型在工业环境中识别常规操作和安全关键异常的能力，并发现现有模型在识别危险活动和多标签场景中表现不佳。

**AI_Comments:** iSafetyBench的创新之处在于其专注于工业安全领域，填补了现有VLM在这一高风险领域评估的空白。它提供了一个真实世界的、细粒度的评估工具，揭示了当前模型在该领域特别是危险活动识别和多标签理解方面的局限性，对推动工业安全AI的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言模型（VLMs）在零样本设置下展现出强大的泛化能力，但在高风险工业领域（识别常规操作和安全关键异常至关重要）的性能尚未得到充分探索。为了弥补这一空白，本研究引入了iSafetyBench。

**Method:** 研究人员引入了iSafetyBench，一个专门用于评估模型在工业环境（包括正常和危险场景）中性能的视频-语言基准。iSafetyBench包含1100个来自真实工业环境的视频片段，并带有开放词汇、多标签动作标签（98个常规类别和67个危险类别）。每个片段都配有多项选择题，用于单标签和多标签评估。研究人员在零样本条件下评估了八个最先进的视频-语言模型。

**Result:** 尽管现有模型在其他视频基准上表现出色，但它们在iSafetyBench上表现不佳，尤其是在识别危险活动和多标签场景中。结果揭示了显著的性能差距。

**Conclusion:** 现有视觉-语言模型在工业安全应用中仍有显著的性能差距，需要更鲁棒、更具安全意识的多模态模型。iSafetyBench提供了一个开创性的测试平台，以推动这一方向的进展。

> **ai_Abstract:** 该论文介绍了iSafetyBench，一个专为评估视频-语言模型在工业环境中安全相关任务表现而设计的视频-语言基准。该基准包含1100个真实工业视频片段，涵盖常规和危险动作的多标签注释。通过对八个最先进模型的评估，研究发现现有模型在识别危险活动和多标签场景中表现不足，揭示了在工业安全应用中开发更鲁棒、安全意识强的多模态模型的必要性。

> **摘要翻译:** 视觉-语言模型（VLMs）的最新进展使得它们在零样本设置下能够跨各种视频理解任务实现令人印象深刻的泛化。然而，它们在高风险工业领域（识别常规操作和安全关键异常至关重要）的能力在很大程度上仍未被充分探索。为了弥补这一空白，我们引入了iSafetyBench，一个新的视频-语言基准，专门用于评估模型在工业环境（包括正常和危险场景）中的性能。iSafetyBench包含1100个来自真实工业环境的视频片段，并标注了开放词汇、多标签动作标签，涵盖98个常规和67个危险动作类别。每个片段都配有多项选择题，用于单标签和多标签评估，从而能够在标准和安全关键背景下对VLM进行细粒度评估。我们在零样本条件下评估了八个最先进的视频-语言模型。尽管这些模型在现有视频基准上表现强劲，但它们在iSafetyBench上表现不佳——尤其是在识别危险活动和多标签场景中。我们的结果揭示了显著的性能差距，强调了工业应用中对更鲁棒、更具安全意识的多模态模型的需求。iSafetyBench提供了一个开创性的测试平台，以推动这一方向的进展。数据集可在：https://github.com/raiyaan-abdullah/iSafety-Bench 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [459] [TopoTTA: Topology-Enhanced Test-Time Adaptation for Tubular Structure Segmentation](https://arxiv.org/abs/2508.00442)
> *TopoTTA：拓扑增强的管状结构分割测试时间自适应*

*Jiale Zhou, Wenhan Wang, Shikun Li, Xiaolei Qu, Xin Guo, Yizhong Liu, Wenzhong Tang, Xun Lin, Yefeng Zheng* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 管状结构分割, 测试时间自适应, 拓扑增强, 领域偏移, 深度学习

**Comment:** 

> **TL;DR:** TopoTTA是首个专为管状结构分割（TSS）设计的测试时间自适应框架，通过解决跨域拓扑差异和改善拓扑连续性，显著提高了TSS模型在未见目标域上的性能。

**AI_Comments:** TopoTTA的创新点在于它是首个专门为管状结构分割（TSS）设计的测试时间自适应（TTA）框架，尤其关注拓扑结构在领域偏移中的敏感性。它通过两阶段方法，即拓扑元差分卷积（TopoMDCs）用于拓扑表示增强和拓扑硬样本生成（TopoHG）用于拓扑连续性改善，系统性地解决了TSS中领域偏移导致的拓扑完整性问题。其“即插即用”的特性也大大提升了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 管状结构分割（TSS）在血流动力学分析和路线导航等应用中非常重要。尽管TSS取得了显著进展，但领域偏移仍是一个主要挑战，导致在未见目标域的性能下降。与其他分割任务不同，TSS对领域偏移更敏感，因为拓扑结构的变化会损害分割的完整性，而区分前景和背景的局部特征（如纹理和对比度）的变化可能会进一步破坏拓扑连续性。

**Method:** 我们提出了拓扑增强的测试时间自适应（TopoTTA）框架，专为TSS设计。TopoTTA包括两个阶段：第一阶段使用所提出的拓扑元差分卷积（TopoMDCs）来适应跨域拓扑差异，这在不改变预训练参数的情况下增强了拓扑表示；第二阶段通过新颖的拓扑硬样本生成（TopoHG）策略和在生成的伪断裂区域中利用伪标签对硬样本进行预测对齐，从而改善拓扑连续性。

**Result:** 在四种场景和十个数据集上进行的广泛实验表明，TopoTTA在处理拓扑分布偏移方面表现出有效性，平均clDice指标提高了31.81%。TopoTTA还可以作为基于CNN的TSS模型的即插即用型TTA解决方案。

**Conclusion:** TopoTTA是首个专为管状结构分割设计的测试时间自适应框架，通过其两阶段方法有效解决了领域偏移导致的拓扑完整性问题，显著提升了模型在不同数据集上的性能，并可作为现有CNN-based TSS模型的即插即用解决方案。

> **ai_Abstract:** 本研究提出TopoTTA，一个专为管状结构分割（TSS）设计的测试时间自适应框架，旨在解决领域偏移导致的性能下降和拓扑完整性受损问题。TopoTTA分为两阶段：第一阶段通过拓扑元差分卷积（TopoMDCs）增强拓扑表示以适应跨域差异；第二阶段利用拓扑硬样本生成（TopoHG）和伪标签预测对齐来改善拓扑连续性。实验结果表明，TopoTTA在多种场景和数据集上有效处理了拓扑分布偏移，平均clDice指标提升31.81%，并可作为现有CNN-based TSS模型的即插即用解决方案。

> **摘要翻译:** 管状结构分割（TSS）对于血流动力学分析和路线导航等各种应用至关重要。尽管TSS取得了显著进展，但领域偏移仍然是一个主要挑战，导致在未见目标域的性能下降。与其他分割任务不同，TSS对领域偏移更敏感，因为拓扑结构的变化会损害分割的完整性，而区分前景和背景的局部特征（例如纹理和对比度）的变化可能会进一步破坏拓扑连续性。为了应对这些挑战，我们提出了拓扑增强的测试时间自适应（TopoTTA），这是首个专为TSS设计的测试时间自适应框架。TopoTTA包括两个阶段：第一阶段使用所提出的拓扑元差分卷积（TopoMDCs）来适应跨域拓扑差异，这在不改变预训练参数的情况下增强了拓扑表示；第二阶段通过新颖的拓扑硬样本生成（TopoHG）策略和在生成的伪断裂区域中利用伪标签对硬样本进行预测对齐，从而改善拓扑连续性。在四种场景和十个数据集上进行的广泛实验表明，TopoTTA在处理拓扑分布偏移方面表现出有效性，平均clDice指标提高了31.81%。TopoTTA还可以作为基于CNN的TSS模型的即插即用型TTA解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [460] [PanoLlama: Generating Endless and Coherent Panoramas with Next-Token-Prediction LLMs](https://arxiv.org/abs/2411.15867)
> *PanoLlama：使用下一词元预测大型语言模型生成无尽且连贯的全景图*

*Teng Zhou, Xiaoyu Zhang, Yongchuan Tang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 全景图像生成, 自回归模型, 词元重定向, PanoLlama, 下一词元预测

**Comment:** 

> **TL;DR:** PanoLlama提出了一种新的自回归范式，通过词元重定向实现无尽且连贯的全景图生成，克服了现有方法的局限性，并实现了最先进的性能。

**AI_Comments:** PanoLlama的创新之处在于将全景图像生成问题重新定义为下一词元预测任务，并创造性地将自回归范式引入PIG领域。其免训练的词元重定向策略有效地克服了现有视觉自回归模型在生成尺寸上的限制，实现了“无尽”的全景图生成，这是一个显著的突破。此外，该工作不仅提升了性能，还拓展了PIG的应用范围，并建立了新的评估基准，对领域发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的全景图像生成（PIG）方法大多采用联合扩散范式，但其复杂且启发式的裁剪连接设计限制了它们实现多级连贯性的能力。此外，现有的视觉自回归（VAR）模型仅限于固定尺寸生成，无法生成全景图像。

**Method:** 本文提出了PanoLlama框架，采用自回归（AR）范式进行全景图像生成。它开发了一种免训练策略，利用词元重定向来克服现有VAR模型的尺寸限制，从而实现水平和垂直方向的下一裁剪预测。同时，还建立了一个包含1000个提示和100多个主题的数据集，作为PIG研究的新测试基准。

**Result:** PanoLlama刷新了PIG流程，并在连贯性（47.50%）、保真度（28.16%）和美观性（15%）方面达到了最先进的性能。此外，它支持其他PIG方法无法实现的应用，包括无掩码布局控制、多尺度和多引导合成。

**Conclusion:** PanoLlama通过引入自回归范式和创新的词元重定向策略，成功实现了无尽且连贯的全景图像生成，克服了现有方法的局限性，并为全景图像生成领域提供了新的方向和评估基准。

> **ai_Abstract:** PanoLlama提出了一种新的自回归（AR）范式用于全景图像生成（PIG），旨在解决现有联合扩散方法在多级连贯性方面的局限性以及视觉AR模型无法生成全景图的问题。通过引入一种训练无关的词元重定向策略，PanoLlama能够实现无尽且连贯的水平和垂直下一裁剪预测，刷新了PIG流程。该方法在连贯性、保真度和美观性方面取得了最先进的性能，并支持无掩码布局控制、多尺度和多引导合成等独特应用。为标准化评估，研究还构建了一个包含1000个提示的新数据集。

> **摘要翻译:** 全景图像生成（PIG）旨在创建任意长度的连贯图像。大多数现有方法属于联合扩散范式，但其复杂且启发式的裁剪连接设计通常限制了它们实现多级连贯性的能力。通过将这一挑战分解为核心组成部分，我们发现它自然地与下一词元预测对齐，这引导我们采用自回归（AR）范式进行PIG建模。然而，现有视觉自回归（VAR）模型仅限于固定尺寸生成，缺乏生成全景图像的能力。在本文中，我们提出了PanoLlama，一个新颖的框架，通过自回归范式实现无尽且连贯的全景生成。我们的方法开发了一种免训练策略，利用词元重定向来克服现有VAR模型的尺寸限制，从而在水平和垂直方向上实现下一裁剪预测。这刷新了PIG流程，同时在连贯性（47.50%）、保真度（28.16%）和美观性（15%）方面实现了最先进的性能。此外，PanoLlama支持其他PIG方法无法实现的应用，包括无掩码布局控制、多尺度和多引导合成。为了促进标准化评估，我们还建立了一个包含1000个提示，涵盖100多个主题的数据集，为PIG研究提供了一个新的测试基准。代码可在https://github.com/0606zt/PanoLlama获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [468] [Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents](https://arxiv.org/abs/2508.00400)
> *Sari Sandbox：一个用于具身AI代理的虚拟零售商店环境*

*Janika Deborah Gajo, Gerarld Paul Merales, Jerome Escarcha, Brenden Ashley Molina, Gian Nartea, Emmanuel G. Maminta, Juan Carlos Roldan, Rowel O. Atienza* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 具身AI, 零售模拟, 虚拟环境, 基准测试, Sari Sandbox

**Comment:** 14 pages, accepted in ICCV 2025 Workshop on RetailVision

> **TL;DR:** 提出了Sari Sandbox，一个高逼真度的虚拟零售商店模拟环境，用于基准测试具身AI代理在购物任务中的表现，并发布了人类演示数据集SariBench。

**AI_Comments:** 这篇论文的创新点在于提供了一个专门针对零售场景的高逼真度、可交互的3D模拟环境，填补了具身AI代理训练在此领域的空白。Sari Sandbox结合了丰富的交互元素和人类行为数据集，为评估和提升具身代理在复杂购物任务中的能力提供了重要平台。其重要性在于推动了具身AI在现实世界应用中的发展，特别是在零售自动化和机器人领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有具身代理训练缺乏零售特定仿真环境。

**Method:** 本文提出了Sari Sandbox，一个高逼真度、照片级真实的3D零售商店模拟环境，包含超过250种交互式杂货商品和三种商店配置，可通过API控制。该环境支持虚拟现实（VR）用于人类交互，也支持由视觉语言模型（VLM）驱动的具身代理。此外，论文还引入了SariBench数据集，其中包含了人类在不同任务难度下的带标注演示。

**Result:** Sari Sandbox使具身代理能够导航、检查和操作零售商品，并提供了与人类表现对比的基线。论文提供了相关的基准测试和性能分析。

**Conclusion:** 论文提供了具身代理在Sari Sandbox环境中的基准测试和性能分析，并提出了增强模拟环境真实感和可扩展性的建议。

> **ai_Abstract:** 本文介绍了Sari Sandbox，一个高逼真度的3D虚拟零售商店模拟环境，旨在弥补具身AI代理在零售任务训练环境上的空白。该平台包含250多种交互商品和多种商店配置，支持VR人类交互和VLM驱动的具身代理。作者还发布了SariBench数据集，包含人类购物任务的演示。Sari Sandbox能够评估具身代理在零售环境中的导航、检查和操作能力，并提供了与人类表现对比的基线，同时提供了基准测试和增强真实感与可扩展性的建议。

> **摘要翻译:** 我们提出了Sari Sandbox，一个高保真、照片级真实的3D零售商店模拟环境，用于衡量具身代理在购物任务中与人类表现的对比。为了弥补零售特定仿真环境在具身代理训练方面的空白，Sari Sandbox拥有超过250种交互式杂货商品，分布在三种商店配置中，并通过API进行控制。它支持虚拟现实（VR）用于人类交互，以及由视觉语言模型（VLM）驱动的具身代理。我们还引入了SariBench，一个包含不同任务难度下带标注人类演示的数据集。我们的沙盒使具身代理能够导航、检查和操作零售商品，从而提供了与人类表现对比的基线。最后，我们提供了基准测试、性能分析以及关于增强真实性和可扩展性的建议。源代码可通过https://github.com/upeee/sari-sandbox-env访问。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [469] [Can Large Pretrained Depth Estimation Models Help With Image Dehazing?](https://arxiv.org/abs/2508.00698)
> *大型预训练深度估计模型能否助力图像去雾？*

*Hongfei Zhang, Kun Zhou, Ruizheng Wu, Jiangbo Lu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 图像去雾, 深度估计, 预训练模型, RGB-D融合, 泛化能力

**Comment:** Submitted to AAAI2026

> **TL;DR:** 本文系统研究了预训练深度表征在图像去雾中的泛化能力，发现深度特征在不同雾度水平下保持一致性，并提出了一种即插即用的RGB-D融合模块，有效提升了去雾效果和适用性。

**AI_Comments:** 该论文的创新点在于系统性地探索了预训练深度表示对图像去雾的泛化能力，并提出了一个通用的即插即用RGB-D融合模块。这解决了现有去雾方法在不同场景适应性差的问题，对于提升去雾技术的实用性具有重要意义。其方法通用性强，易于集成。

<details>
  <summary>Details</summary>

**Motivation:** 图像去雾仍然是一个具有挑战性的问题，因为真实场景中的雾霾具有空间变化性。现有方法虽然展示了大规模预训练模型在图像去雾方面的潜力，但其架构特定的设计阻碍了在不同精度和效率要求的多种场景中的适应性。

**Method:** 本文系统研究了从数百万张不同图像中学习到的预训练深度表征在图像去雾中的泛化能力。基于深度特征在不同雾度水平下保持显著一致性的发现，提出了一种即插即用的RGB-D融合模块，该模块可以无缝集成到各种去雾架构中。

**Result:** 实证分析表明，学习到的深度特征在不同雾度水平下保持了显著的一致性。在多个基准测试上的大量实验验证了该方法的有效性和广泛适用性。

**Conclusion:** 预训练深度估计模型可以有效地帮助图像去雾，通过提出的RGB-D融合模块，能够提升去雾效果并增强模型在不同场景下的适应性。

> **ai_Abstract:** 本文探讨了大型预训练深度估计模型在图像去雾中的应用潜力。研究发现，从大量图像中学习到的深度特征在不同雾度下表现出良好的一致性。基于此，论文提出了一种即插即用的RGB-D融合模块，该模块能够与现有去雾架构无缝结合，并通过广泛实验验证了其在多个基准测试上的有效性和普适性。

> **摘要翻译:** 图像去雾仍然是一个具有挑战性的问题，因为真实场景中的雾霾具有空间变化性。虽然现有方法已经展示了大规模预训练模型在图像去雾方面的潜力，但其架构特定的设计阻碍了在不同精度和效率要求的多种场景中的适应性。在这项工作中，我们系统地研究了预训练深度表征（从数百万张不同图像中学习）在图像去雾方面的泛化能力。我们的实证分析表明，学习到的深层深度特征在不同雾度水平下保持了显著的一致性。基于这一见解，我们提出了一种即插即用的RGB-D融合模块，该模块可以无缝集成到各种去雾架构中。在多个基准测试上的大量实验验证了我们方法的有效性和广泛适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [472] [Backdoor Attacks on Deep Learning Face Detection](https://arxiv.org/abs/2508.00620)
> *深度学习人脸检测中的后门攻击*

*Quentin Le Roux, Yannick Teglia, Teddy Furon, Philippe Loubet-Moundi* | **Category: cs.CV, cs.AI, cs.CR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 后门攻击, 人脸检测, 深度学习, 地标偏移攻击, 安全

**Comment:** 

> **TL;DR:** 本文展示了对深度学习人脸检测的后门攻击，包括人脸生成攻击和首次提出的地标偏移攻击，并提供了缓解措施。

**AI_Comments:** 本文创新性地提出了针对人脸检测的地标偏移攻击，扩展了对深度学习系统后门攻击的理解，特别是在安全关键的人脸识别领域。其重要性在于揭示了人脸检测模块潜在的安全漏洞，并提出了相应的缓解措施，对提高人脸识别系统的鲁棒性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在非受限环境下运行的人脸识别系统面临光照不一致或姿态多样等挑战，需要人脸检测模块进行边界框和地标坐标回归以实现正确的人脸对齐。本文旨在展示针对人脸检测的后门攻击的有效性。

**Method:** 本文展示了对象生成攻击（称为人脸生成攻击）对人脸检测的有效性，并首次演示了一种地标偏移攻击，该攻击通过后门方式影响人脸检测器执行的坐标回归任务。研究人员还提出了针对这些漏洞的缓解措施。

**Result:** 本文展示了对象生成攻击（人脸生成攻击）对人脸检测的有效性，并首次成功演示了地标偏移攻击，该攻击能够通过后门方式影响人脸检测器执行的坐标回归任务。

**Conclusion:** 对人脸检测的后门攻击是有效的威胁，包括新的地标偏移攻击，但存在可以减轻这些漏洞的措施。

> **ai_Abstract:** 本文研究了深度学习人脸检测系统中的后门攻击。研究人员展示了“人脸生成攻击”的有效性，并首次引入了一种针对人脸检测器坐标回归任务的“地标偏移攻击”。此外，论文还提出了针对这些新发现漏洞的缓解策略。

> **摘要翻译:** 在非受限环境下运行的人脸识别系统在不同条件下捕获图像，例如光照不一致或人脸姿态多样。这些挑战要求包含一个人脸检测模块，该模块回归边界框和地标坐标以进行正确的人脸对齐。本文展示了对象生成攻击对人脸检测的有效性，称之为“人脸生成攻击”，并首次演示了一种地标偏移攻击，该攻击通过后门方式影响人脸检测器执行的坐标回归任务。然后，我们提供了针对这些漏洞的缓解措施。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [476] [LargeMvC-Net: Anchor-based Deep Unfolding Network for Large-scale Multi-view Clustering](https://arxiv.org/abs/2507.20980)
> *LargeMvC-Net：基于锚点的深度展开网络用于大规模多视图聚类*

*Shide Du, Chunming Wu, Zihan Fang, Wendi Zhao, Yilin Wu, Changwei Wang, Shiping Wang* | **Category: cs.CV, stat.CO, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 大规模多视图聚类, 深度展开网络, 锚点, 优化, 可扩展性

**Comment:** 10 pages, 7 figures

> **TL;DR:** LargeMvC-Net通过将大规模多视图聚类优化问题展开成深度网络，解决了现有锚点方法结构启发式的问题，并在大规模基准测试中表现优异。

**AI_Comments:** 这篇论文的创新点在于将大规模锚点多视图聚类的底层优化问题展开成一个可追溯的深度网络架构，而非采用启发式方法。这种基于优化原理的设计提高了模型的结构清晰性、可解释性和性能，尤其在处理大规模数据时展现了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度锚点多视图聚类方法虽然具有可扩展性，但在锚点结构整合上往往采用启发式或与任务无关的方式，忽视了锚点聚类的核心结构需求和优化原则。

**Method:** 提出LargeMvC-Net，通过将大规模锚点多视图聚类的底层优化问题展开为一个新的深度网络架构。该模型将聚类过程分解为三个模块：RepresentModule（表示学习）、NoiseModule（噪声抑制）和AnchorModule（锚点指示器估计）。每个模块都由原始优化过程的一个步骤展开而来。此外，引入无监督重建损失以对齐视图并鼓励一致的聚类结构。

**Result:** 在多个大规模多视图基准测试中，LargeMvC-Net在有效性和可扩展性方面始终优于最先进的方法。

**Conclusion:** LargeMvC-Net通过将优化问题展开为深度网络，解决了现有锚点多视图聚类方法的局限性，并实现了卓越的性能和可扩展性。

> **ai_Abstract:** LargeMvC-Net是一种新颖的深度展开网络，专为大规模多视图聚类设计。它通过将锚点多视图聚类的优化问题展开为三个专用模块（表示、噪声抑制、锚点估计），克服了现有方法中锚点结构集成启发式的问题。该网络通过结构化设计和无监督重建损失确保了优化可追溯性和跨视图一致性，并在大规模基准测试中展现出卓越的性能和可扩展性。

> **摘要翻译:** 深度基于锚点的多视图聚类方法通过利用有代表性的锚点来降低大规模聚类的计算复杂性，从而增强了神经网络的可扩展性。尽管它们具有可扩展性优势，但现有方法通常以启发式或与任务无关的方式整合锚点结构，无论是通过事后图构建还是作为消息传递的辅助组件。这种设计忽略了基于锚点聚类的核心结构需求，忽视了关键的优化原则。为了弥补这一差距，我们重新审视了大规模基于锚点多视图聚类的底层优化问题，并将其迭代解决方案展开为一种新颖的深度网络架构，命名为LargeMvC-Net。所提出的模型将基于锚点的聚类过程分解为三个模块：表示模块（RepresentModule）、噪声模块（NoiseModule）和锚点模块（AnchorModule），分别对应于表示学习、噪声抑制和锚点指示器估计。每个模块都是通过将原始优化过程的一个步骤展开成一个专门的网络组件而得到的，提供了结构清晰性和优化可追溯性。此外，无监督重建损失使每个视图与锚点诱导的潜在空间对齐，鼓励视图之间一致的聚类结构。在几个大规模多视图基准测试上的大量实验表明，LargeMvC-Net在有效性和可扩展性方面始终优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [482] [World Consistency Score: A Unified Metric for Video Generation Quality](https://arxiv.org/abs/2508.00144)
> *世界一致性分数：视频生成质量的统一指标*

*Akshat Rakheja, Aarsh Ashdhir, Aryan Bhattacharjee, Vanshika Sharma* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 视频生成, 评估指标, 世界一致性分数, 时间连贯性, 物理连贯性

**Comment:** 27 pages, 1 figure

> **TL;DR:** 引入WCS，一种新的视频生成模型评估指标，强调生成视频的内部世界一致性，包含四个可解释的子组件，并通过学习权重与人类判断对齐。

**AI_Comments:** WCS的创新之处在于引入了“世界一致性”的概念，并通过可解释的子组件来量化视频生成中的时间连贯性和物理连贯性，这弥补了现有指标过度关注视觉保真度和提示对齐的局限性。其与人类判断对齐的设计增加了其实用性，有望成为视频生成领域的重要评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频评估指标主要关注视觉保真度或提示对齐，而忽略了生成视频内部世界的一致性，WCS旨在弥补这一空白。

**Method:** 引入世界一致性分数（WCS），一个包含四个子组件（物体永存性、关系稳定性、因果符合性、闪烁惩罚）的统一评估指标。这些子组件通过开源工具（跟踪器、动作识别器、CLIP嵌入、光流）计算，并通过学习的加权公式组合，权重使用人类偏好数据训练。论文还概述了使用VBench-2.0、EvalCrafter和LOVE等基准测试WCS与人类评估相关性的实验验证蓝图，并与FVD、CLIPScore、VBench、FVMD等现有指标进行比较。

**Result:** Not mentioned in abstract

**Conclusion:** WCS提供了一个全面且可解释的框架，用于评估视频生成模型随时间保持连贯“世界”的能力，解决了先前指标在视觉保真度或提示对齐方面的不足。

> **ai_Abstract:** 本文提出了世界一致性分数（WCS），一种用于评估生成视频模型的新型统一指标。WCS通过整合物体永存性、关系稳定性、因果符合性和闪烁惩罚四个可解释的子组件来衡量视频的内部世界一致性，并通过学习权重使其与人类判断对齐。该研究详细阐述了WCS的计算方法和权重训练过程，并提出了一个实验验证计划，旨在弥补现有视频评估指标在衡量时间连贯性和物理连贯性方面的不足。

> **摘要翻译:** 我们引入了世界一致性分数（WCS），这是一种新颖的、统一的生成视频模型评估指标，强调生成视频的内部世界一致性。WCS整合了四个可解释的子组件——物体永存性、关系稳定性、因果符合性以及闪烁惩罚——每个都衡量视频中时间连贯性和物理连贯性的不同方面。这些子指标通过学习的加权公式组合，生成一个与人类判断对齐的单一一致性分数。我们详细阐述了WCS在现有视频评估指标背景下的动机，形式化了每个子指标以及如何使用开源工具（跟踪器、动作识别器、CLIP嵌入、光流）进行计算，并描述了如何使用人类偏好数据训练WCS组合的权重。我们还概述了一个实验验证蓝图：使用VBench-2.0、EvalCrafter和LOVE等基准测试WCS与人类评估的相关性，进行敏感性分析，并将WCS与已建立的指标（FVD、CLIPScore、VBench、FVMD）进行比较。所提出的WCS提供了一个全面且可解释的框架，用于评估视频生成模型在随时间保持连贯“世界”方面的能力，弥补了先前只关注视觉保真度或提示对齐的指标所留下的空白。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [483] [PMR: Physical Model-Driven Multi-Stage Restoration of Turbulent Dynamic Videos](https://arxiv.org/abs/2508.00406)
> *PMR：物理模型驱动的湍流动态视频多阶段恢复*

*Tao Wu, Jingyuan Ye, Ying Fu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 大气湍流, 视频恢复, 动态效率指数, 多阶段恢复, 几何失真

**Comment:** 

> **TL;DR:** 本文提出PMR框架，通过物理模型驱动的多阶段方法，有效恢复受湍流影响的动态视频，尤其在强湍流和复杂动态下表现出色。

**AI_Comments:** 本文的创新点在于引入了动态效率指数（DEI）来量化视频动态强度并构建针对性数据集，以及提出了一个物理模型驱动的多阶段恢复框架（PMR）。这种分阶段处理方法，结合轻量级网络和阶段性联合训练，有效解决了强湍流和复杂动态下视频恢复的挑战，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法难以恢复受大气湍流影响的动态场景视频的边缘细节并消除混合失真，尤其是在强湍流和复杂动态条件下表现不佳。

**Method:** 1. 引入动态效率指数（$DEI$），结合湍流强度、光流和动态区域比例，以准确量化视频动态强度并提供高动态湍流训练数据集。2. 提出物理模型驱动的多阶段视频恢复（$PMR$）框架，包括三个阶段：去倾斜（用于几何稳定）、运动分割增强（用于动态区域细化）和去模糊（用于质量恢复）。$PMR$采用轻量级骨干网络和阶段性联合训练。

**Result:** 所提出的方法有效抑制了运动拖尾伪影，恢复了边缘细节，并表现出强大的泛化能力，特别是在高湍流和复杂动态的真实世界场景中。

**Conclusion:** PMR框架能够有效解决大气湍流导致的视频质量下降问题，尤其在复杂和强湍流条件下表现优异，提供了高质量的视频恢复。

> **ai_Abstract:** 本文针对大气湍流导致的动态视频质量下降问题，提出了物理模型驱动的多阶段视频恢复（PMR）框架。该框架首先引入动态效率指数（DEI）以量化视频动态强度并构建训练数据集。PMR包含去倾斜、运动分割增强和去模糊三个阶段，通过轻量级网络和阶段性联合训练，有效抑制了运动拖尾，恢复了边缘细节，在高湍流和复杂动态场景下展现出强大的恢复能力和泛化性。

> **摘要翻译:** 几何失真和大气湍流引起的模糊会降低远距离动态场景视频的质量。现有方法难以恢复边缘细节并消除混合失真，尤其是在强湍流和复杂动态条件下。为了解决这些挑战，我们引入了动态效率指数（$DEI$），它结合了湍流强度、光流和动态区域的比例，以准确量化不同湍流条件下的视频动态强度，并提供高动态湍流训练数据集。此外，我们提出了一个物理模型驱动的多阶段视频恢复（$PMR$）框架，该框架包括三个阶段：用于几何稳定的去倾斜、用于动态区域细化和用于质量恢复的去模糊。$PMR$采用轻量级骨干网络和阶段性联合训练，以确保效率和高恢复质量。实验结果表明，所提出的方法有效地抑制了运动拖尾伪影，恢复了边缘细节，并表现出强大的泛化能力，特别是在高湍流和复杂动态的真实世界场景中。我们将公开代码和数据集。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [485] [Learn2Synth: Learning Optimal Data Synthesis Using Hypergradients for Brain Image Segmentation](https://arxiv.org/abs/2411.16719)
> *Learn2Synth: 使用超梯度学习最优数据合成用于脑图像分割*

*Xiaoling Hu, Xiangrui Zeng, Oula Puonti, Juan Eugenio Iglesias, Bruce Fischl, Yael Balbastre* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 数据合成, 超梯度, 脑图像分割, 领域随机化, Learn2Synth

**Comment:** 16 pages, 5 figures. Accepted by ICCV'25

> **TL;DR:** Learn2Synth通过使用少量真实标注数据学习数据合成参数，以优化分割网络在真实数据上的性能，避免手动调参和网络偏置。

**AI_Comments:** Learn2Synth的创新之处在于其通过学习而非手动调优数据合成参数，显著提升了合成数据在训练深度学习模型时的实用性。特别是，它巧妙地避免了使用真实数据直接训练分割网络，从而规避了模型偏置问题，这对于医学图像等敏感领域至关重要。该方法通过优化合成数据质量来间接提升模型在真实数据上的泛化能力，为数据增强和领域适应提供了一个有前景的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 领域随机化合成是训练无偏网络以提高泛化能力和减少过拟合的强大策略，但其依赖于大量合成图像参数的精确手动调优，这既复杂又耗时。

**Method:** 本文提出了Learn2Synth，一种新颖的方法，通过使用少量真实标注数据学习数据合成参数。与传统对齐合成数据和真实数据的方法不同，Learn2Synth通过调整增强引擎，使在合成数据上训练的分割网络在应用于真实数据时具有最佳精度。该方法允许训练过程受益于真实标注样本，而无需使用这些真实样本直接训练分割网络，从而避免了网络对训练集特性的偏置。具体来说，开发了参数和非参数策略来增强合成图像，以提高分割网络的性能。

**Result:** 该学习策略在合成和真实世界脑部扫描数据上都展示了其有效性。

**Conclusion:** Learn2Synth方法通过学习数据合成参数，使得分割网络能够从真实标注数据中受益，同时避免了网络对训练集产生偏置，从而提高了在真实数据上的泛精度。

> **ai_Abstract:** Learn2Synth提出一种创新的数据合成参数学习方法，旨在解决传统领域随机化中手动调参的挑战。该方法利用少量真实标注数据，通过优化增强引擎来提升在合成数据上训练的分割网络在真实数据上的性能。其核心在于避免直接使用真实数据训练分割网络，从而有效防止模型偏置。研究在脑部图像分割任务上验证了其在合成和真实扫描数据上的有效性。

> **摘要翻译:** 通过合成进行领域随机化是一种强大的策略，可以训练对输入图像领域无偏的网络。随机化允许网络在训练期间看到几乎无限范围的强度和伪影，从而最大限度地减少对外观的过拟合，并最大限度地提高对未见数据的泛化能力。尽管这种方法功能强大，但它依赖于对大量控制合成图像概率分布的超参数的精确调优。我们没有手动调整这些参数，而是引入了Learn2Synth，这是一种新颖的程序，其中使用少量真实标注数据来学习合成参数。与施加约束以使合成数据与真实数据对齐的方法（例如，对比或对抗技术）不同，这些方法可能导致图像及其标签图错位，我们调整了一个增强引擎，使得在合成数据上训练的分割网络在应用于真实数据时具有最佳精度。这种方法允许训练过程受益于真实标注样本，而无需使用这些真实样本来训练分割网络，从而避免了网络对训练集属性的偏置。具体来说，我们开发了参数和非参数策略来增强合成图像，以提高分割网络的性能。我们证明了这种学习策略在合成和真实世界脑部扫描中的有效性。代码可在以下网址获取：https://github.com/HuXiaoling/Learn2Synth。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [496] [Training-free Geometric Image Editing on Diffusion Models](https://arxiv.org/abs/2507.23300)
> *扩散模型上的免训练几何图像编辑*

*Hanshen Zhu, Zhen Zhu, Kaile Zhang, Yiming Gong, Yuliang Liu, Xiang Bai* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 几何图像编辑, 扩散模型, 免训练, 图像修复, 图像细化

**Comment:** Accepted by ICCV2025

> **TL;DR:** 本文提出了FreeFine，一种免训练、解耦的扩散管道，用于几何图像编辑，该方法在处理复杂变换时表现优于现有方法。

**AI_Comments:** 本文的创新之处在于其解耦的流水线和FreeFine的免训练特性，这简化了几何编辑的复杂任务，并提高了处理挑战性变换的性能。GeoBench基准的引入也是一项重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 以前基于扩散的图像编辑方法在处理大型或结构复杂的几何变换时面临困难，因为它们试图在一个步骤中处理所有相关子任务。

**Method:** 本文提出了一种解耦的流水线，将对象变换、源区域修复和目标区域细化分离开来。修复和细化都使用一种名为FreeFine的免训练扩散方法实现。

**Result:** 在新的GeoBench基准测试（包含2D和3D编辑场景）上的实验表明，FreeFine在图像保真度和编辑精度方面优于最先进的替代方案，尤其是在要求严苛的变换下。

**Conclusion:** FreeFine的解耦式免训练方法能够有效处理复杂的几何图像编辑任务，并取得了卓越的性能。

> **ai_Abstract:** 本文介绍了一种名为FreeFine的新型免训练扩散方法，用于几何图像编辑。它通过提出一个解耦的流水线来解决以前单步方法的局限性，该流水线将对象变换、源区域修复和目标区域细化分离开来。在新GeoBench基准上的实验表明，FreeFine在图像保真度和编辑精度方面表现出色，尤其适用于大型和复杂变换。

> **摘要翻译:** 我们解决了几何图像编辑任务，即在保持整体场景连贯性的同时，对图像中的对象进行重新定位、重新定向或重新塑形。以前基于扩散的编辑方法通常试图在一个步骤中处理所有相关的子任务，当变换变得较大或结构复杂时，这被证明是困难的。我们通过提出一个解耦的流水线来解决这个问题，该流水线将对象变换、源区域修复和目标区域细化分离开来。修复和细化都使用一种免训练的扩散方法FreeFine来实现。在我们的新GeoBench基准测试（包含2D和3D编辑场景）上的实验表明，FreeFine在图像保真度和编辑精度方面优于最先进的替代方案，尤其是在要求严苛的变换下。代码和基准可在以下网址获取：https://github.com/CIawevy/FreeFine

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [502] [MIHBench: Benchmarking and Mitigating Multi-Image Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2508.00726)
> *MIHBench：基准测试和缓解多模态大语言模型中的多图像幻觉*

*Jiale Li, Mingrui Wu, Zixiang Jin, Hao Chen, Jiayi Ji, Xiaoshuai Sun, Liujuan Cao, Rongrong Ji* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 多图像幻觉, 多模态大语言模型, MIHBench, 基准测试, 动态注意力平衡机制

**Comment:** ACM MM25 has accepted this paper

> **TL;DR:** 该研究首次系统性地研究了多模态大语言模型中的多图像幻觉，提出了MIHBench基准来评估此类幻觉，并引入了动态注意力平衡机制来有效缓解幻觉。

**AI_Comments:** 这项研究的创新之处在于首次系统性地将多模态大语言模型的幻觉研究扩展到多图像场景，填补了该领域的空白。MIHBench作为一个专门的基准，为未来研究提供了评估工具。所提出的动态注意力平衡机制也为缓解多图像幻觉提供了一种有效方法，对提升多模态模型的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大语言模型中的幻觉问题日益受到关注，但现有研究主要集中在单图像设置，多图像场景中的幻觉问题尚未得到充分探索。为了弥补这一空白，本研究进行了首次系统性分析。

**Method:** 本研究进行了多图像多模态大语言模型中幻觉的首次系统性研究，并提出了MIHBench，这是一个专门用于评估跨多图像对象相关幻觉的基准。MIHBench包含三个核心任务：多图像对象存在幻觉、多图像对象计数幻觉和对象身份一致性幻觉。为解决这些挑战，研究提出了一种动态注意力平衡机制，该机制在保持整体视觉注意力比例的同时调整图像间注意力分布。

**Result:** 研究识别出与多图像幻觉发生相关的关键因素，包括：图像输入数量与幻觉发生可能性之间的渐进关系；单图像幻觉倾向与多图像上下文中观察到的倾向之间的强相关性；以及相同对象图像比例和负样本在图像序列中位置对对象身份一致性幻觉发生的影响。实验表明，所提出的方法有效减少了幻觉发生，并增强了多图像场景中的语义集成和推理稳定性。

**Conclusion:** 本研究首次系统性地探索了多模态大语言模型中的多图像幻觉问题，并提出了MIHBench基准和动态注意力平衡机制，实验证明该机制能够有效减少多图像幻觉并提高模型的语义集成和推理稳定性。

> **ai_Abstract:** 本研究首次系统性地探究了多模态大语言模型（MLLMs）在多图像场景下的幻觉问题，弥补了现有研究主要关注单图像设置的空白。为此，作者提出了MIHBench基准，用于评估多图像环境下的对象相关幻觉，涵盖对象存在、数量推理和身份一致性三个核心任务。通过广泛评估，研究揭示了多图像输入量、单图像幻觉倾向以及图像序列中负样本位置等因素对幻觉发生的影响。为缓解这些问题，文章提出了一种动态注意力平衡机制，通过调整图像间注意力分布来减少幻觉。实验证明，该机制能有效降低多图像幻觉的发生率，并提升MLLMs在多图像场景下的语义集成和推理稳定性。

> **摘要翻译:** 尽管多模态大语言模型（MLLMs）中幻觉问题日益受到关注，但现有研究主要集中在单图像设置，多图像场景中的幻觉问题在很大程度上仍未被探索。为了弥补这一空白，我们对多图像MLLMs中的幻觉进行了首次系统性研究，并提出了MIHBench，一个专门用于评估跨多图像对象相关幻觉的基准。MIHBench包含三个核心任务：多图像对象存在幻觉、多图像对象计数幻觉和对象身份一致性幻觉，旨在针对对象存在、数量推理和跨视图身份一致性进行语义理解。通过广泛评估，我们识别了与多图像幻觉发生相关的关键因素，包括：图像输入数量与幻觉发生可能性之间的渐进关系；单图像幻觉倾向与多图像上下文中观察到的倾向之间的强相关性；以及相同对象图像比例和负样本在图像序列中位置对对象身份一致性幻觉发生的影响。为解决这些挑战，我们提出了一种动态注意力平衡机制，该机制在保持整体视觉注意力比例的同时调整图像间注意力分布。在多个最先进的MLLMs上的实验表明，我们的方法有效减少了幻觉发生，并增强了多图像场景中的语义集成和推理稳定性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [507] [Detection, Pose Estimation and Segmentation for Multiple Bodies: Closing the Virtuous Circle](https://arxiv.org/abs/2412.01562)
> *多主体检测、姿态估计与分割：闭合良性循环*

*Miroslav Purkrabek, Jiri Matas* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 多主体姿态估计, 实例分割, 目标检测, BBox-Mask-Pose, OCHuman

**Comment:** Project Website: https://mirapurkrabek.github.io/BBox-Mask-Pose

> **TL;DR:** 提出了一种名为BBox-Mask-Pose (BMP) 的新方法，通过迭代地强制边界框、实例掩码和姿态之间的一致性，显著提高了多主体场景下的检测、实例分割和姿态估计性能，并在OCHuman和COCO数据集上达到了SOTA。

**AI_Comments:** 该论文的创新点在于提出了BBox-Mask-Pose (BMP) 方法，通过在检测、实例分割和姿态估计之间建立一个“良性循环”来迭代地强制相互一致性，从而解决了多主体场景中现有方法的局限性。其重要性体现在其在OCHuman和COCO数据集上取得了显著的SOTA性能，尤其是在处理高重叠场景时的表现。此外，该方法采用小型专业模型，实现了更快的运行时间，使其成为大型基础模型的有效且高效的替代方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人体姿态估计方法在处理多主体近距离场景时效果不佳，尤其是在实例掩码方面存在不足。以往的工作通过检测到的边界框或关键点来条件化姿态估计，但忽略了实例掩码。

**Method:** 提出了BBox-Mask-Pose (BMP) 方法，该方法迭代地强制边界框、实例掩码和姿态之间的相互一致性。它使用三个专门的模型，这些模型在一个闭环中相互改进输出。所有模型都经过调整以实现相互条件化，从而提高了多主体场景的鲁棒性。其中引入了一个新的掩码条件姿态估计模型MaskPose。

**Result:** BBox-Mask-Pose (BMP) 在OCHuman数据集的所有三项任务（检测、实例分割和姿态估计）上都将SOTA推向了新的高度。它在COCO姿态估计上也取得了SOTA性能。在实例重叠严重的场景中，BMP将检测性能比基线检测器提高了39%。该方法使用小型专业模型，运行速度更快，是大型以人为中心的SOTA基础模型的有效替代方案。MaskPose在OCHuman的自上而下方法中表现最佳。

**Conclusion:** BBox-Mask-Pose (BMP) 方法通过强制边界框、实例掩码和姿态之间的相互一致性，有效解决了多主体场景中的挑战，显著提高了检测、姿态估计和分割的性能，并在多个基准测试中达到了最先进的水平，同时保持了高效性。

> **ai_Abstract:** 该论文提出了一种名为BBox-Mask-Pose (BMP) 的新方法，旨在解决多主体近距离场景中人体姿态估计的挑战。BMP通过迭代地强制边界框、实例掩码和姿态之间的相互一致性来提高性能，使用三个相互改进的专门模型。其中，MaskPose是一个新的掩码条件姿态估计模型。实验证明，BMP在OCHuman数据集的检测、实例分割和姿态估计三项任务以及COCO姿态估计上均达到了最先进的水平（SOTA），特别是在实例重叠严重的场景中表现突出。该方法高效且优于大型基础模型。

> **摘要翻译:** 人体姿态估计方法在孤立个体上表现良好，但在多主体近距离场景中却表现不佳。以前的工作通过检测到的边界框或关键点来条件化姿态估计，但忽略了实例掩码。我们提出迭代地强制边界框、实例掩码和姿态之间的相互一致性。引入的BBox-Mask-Pose (BMP) 方法使用三个专门的模型，这些模型在一个闭环中相互改进输出。所有模型都经过调整以实现相互条件化，这提高了多主体场景的鲁棒性。MaskPose，一种新的掩码条件姿态估计模型，在OCHuman的自上而下方法中表现最佳。BBox-Mask-Pose在OCHuman数据集的所有三项任务——检测、实例分割和姿态估计上都将SOTA推向了新的高度。它还在COCO姿态估计上取得了SOTA性能。该方法在实例重叠严重的场景中尤其出色，其检测性能比基线检测器提高了39%。凭借小型专业模型和更快的运行时间，BMP是大型以人为中心的基础模型的有效替代方案。代码和模型可在https://MiraPurkrabek.github.io/BBox-Mask-Pose 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [510] [Sortblock: Similarity-Aware Feature Reuse for Diffusion Model](https://arxiv.org/abs/2508.00412)
> *Sortblock：扩散模型中基于相似度的特征重用*

*Hanqi Chen, Xu Zhang, Xiaoliu Guan, Lielin Jiang, Guanzhong Wang, Zeyu Chen, Yi Liu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 扩散模型, 加速, 特征重用, Transformer, 推理优化

**Comment:** 

> **TL;DR:** Sortblock是一种训练无关的推理加速框架，通过动态缓存和重用相邻时间步之间相似的块级特征，为扩散Transformer模型提速，实现了超过2倍的推理加速，同时保持了生成质量。

**AI_Comments:** Sortblock的创新之处在于其动态的、基于相似度的特征重用机制，这比现有固定时间步或层重用方法更具灵活性和适应性。作为一个训练无关的框架，它易于部署和推广。其结合线性预测机制来缓解误差累积也增加了其鲁棒性。该方法对于加速扩散模型在实时应用中的落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散Transformer (DiTs) 因其固有的顺序去噪过程导致高推理延迟，限制了它们在实时场景中的部署。现有训练无关的加速方法通常在固定的时间步或层重用中间特征，忽略了去噪阶段和Transformer块中不断演变语义焦点。

**Method:** Sortblock通过动态缓存基于相邻时间步之间相似性的块级特征来工作。它通过对残差的演变进行排序，自适应地确定一个再计算比例，选择性地跳过冗余计算，同时保持生成质量。此外，它还结合了一个轻量级的线性预测机制来减少跳过块中累积的误差。

**Result:** Sortblock在各种任务和DiT架构上实现了超过2倍的推理速度提升，同时输出质量的下降最小。

**Conclusion:** Sortblock为加速基于扩散的生成模型提供了一种有效且通用的解决方案。

> **ai_Abstract:** 本文提出了Sortblock，一个针对扩散Transformer (DiTs) 的训练无关推理加速框架。为解决DiTs高延迟问题，Sortblock通过动态缓存和重用相邻时间步之间相似的块级特征来跳过冗余计算，并利用线性预测机制减少误差。实验证明，Sortblock在多种任务和DiT架构上能实现超过2倍的推理加速，且对生成质量影响甚微。

> **摘要翻译:** 扩散Transformer (DiTs) 已经展示出卓越的生成能力，尤其受益于Transformer架构对视觉和艺术保真度的增强。然而，其固有的顺序去噪过程导致高推理延迟，限制了它们在实时场景中的部署。现有训练无关的加速方法通常在固定的时间步或层重用中间特征，忽略了去噪阶段和Transformer块中不断演变语义焦点。为了解决这个问题，我们提出了Sortblock，一个训练无关的推理加速框架，它根据相邻时间步之间块级特征的相似性动态缓存这些特征。通过对残差的演变进行排序，Sortblock自适应地确定一个再计算比例，选择性地跳过冗余计算，同时保持生成质量。此外，我们结合了一个轻量级的线性预测机制来减少跳过块中累积的误差。在各种任务和DiT架构上进行的大量实验表明，Sortblock实现了超过2倍的推理速度提升，同时输出质量的下降最小，为加速基于扩散的生成模型提供了一种有效且通用的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [511] [GeoExplorer: Active Geo-localization with Curiosity-Driven Exploration](https://arxiv.org/abs/2508.00152)
> *GeoExplorer：基于好奇心驱动探索的主动地理定位*

*Li Mi, Manon Bechaz, Zeming Chen, Antoine Bosselut, Devis Tuia* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 主动地理定位, 好奇心驱动探索, 强化学习, 内在奖励, 泛化能力

**Comment:** ICCV 2025. Project page at https://limirs.github.io/GeoExplorer/

> **TL;DR:** GeoExplorer提出了一种基于好奇心驱动探索的主动地理定位（AGL）方法，通过引入与目标无关的内在奖励来提高代理在未知目标和环境中的鲁棒性和泛化能力，解决了现有AGL方法在距离估计困难或遇到新环境时性能下降的问题。

**AI_Comments:** GeoExplorer的创新之处在于将好奇心驱动的探索引入主动地理定位任务，通过目标无关的内在奖励解决了传统距离奖励在复杂或未知环境中的局限性。这提高了代理的鲁棒性和泛化能力，对于实际应用中处理多样化和动态环境具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的主动地理定位（AGL）方法将问题视为一个基于距离奖励的强化学习任务，但在距离估计困难或遇到未见过的目标和环境时，其探索策略的可靠性降低，导致鲁棒性和泛化能力不足。

**Method:** 本文提出了GeoExplorer，一个通过内在奖励整合好奇心驱动探索的AGL代理。与基于距离的奖励不同，GeoExplorer的好奇心驱动奖励是与目标无关的，能够基于有效的环境建模进行鲁棒、多样化和与上下文相关的探索。

**Result:** GeoExplorer在四个AGL基准测试中通过了广泛的实验验证，证明了其在不同设置下的有效性和泛化能力，特别是在定位不熟悉的目标和环境中表现出色。

**Conclusion:** GeoExplorer通过引入好奇心驱动的探索和目标无关的内在奖励，显著提高了主动地理定位代理在面对未知目标和环境时的鲁棒性和泛化能力。

> **ai_Abstract:** 本文介绍了GeoExplorer，一个用于主动地理定位（AGL）的新型代理，旨在解决现有方法在处理未知目标和环境时鲁棒性和泛化能力不足的问题。GeoExplorer通过整合好奇心驱动的探索和目标无关的内在奖励来克服依赖距离奖励的局限性。这种方法使得代理能够进行更可靠和多样化的探索，从而在四个AGL基准测试中表现出显著的有效性和泛化能力，尤其是在定位不熟悉的目标和环境中。

> **摘要翻译:** 主动地理定位（AGL）是在预定义搜索区域内定位以各种模态（例如，航空图像、地面图像或文本）表示的目标的任务。当前方法将AGL视为一个基于距离奖励的目标导向强化学习（RL）问题。它们通过隐式学习最小化与目标的相对距离来定位目标。然而，当距离估计变得困难或遇到未见过的目标和环境时，由于训练期间学习到的探索策略不太可靠，代理的鲁棒性和泛化能力会降低。在本文中，我们提出了GeoExplorer，一个通过内在奖励整合好奇心驱动探索的AGL代理。与基于距离的奖励不同，我们的好奇心驱动奖励是与目标无关的，能够基于有效的环境建模进行鲁棒、多样化和与上下文相关的探索。这些能力已通过在四个AGL基准测试中的广泛实验得到验证，证明了GeoExplorer在不同设置下的有效性和泛化能力，特别是在定位不熟悉的目标和环境中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [516] [FFGAF-SNN: The Forward-Forward Based Gradient Approximation Free Training Framework for Spiking Neural Networks](https://arxiv.org/abs/2507.23643)
> *FFGAF-SNN：基于前向-前向的无梯度近似脉冲神经网络训练框架*

*Changqing Xu, Ziqiang Yang, Yi Liu, Xinfang Liao, Guiqi Mo, Hao Zeng, Yintang Yang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 脉冲神经网络, 前向-前向, 无梯度近似, 训练框架, 神经形态计算

**Comment:** 

> **TL;DR:** FFGAF-SNN是一个基于前向-前向的脉冲神经网络（SNN）训练框架，它通过将脉冲激活视为黑盒模块，消除了梯度近似的需求，显著降低了计算复杂性，并引入了类别感知复杂性适应机制。该方法在MNIST、Fashion-MNIST和CIFAR-10数据集上取得了优于现有FF-SNN方法的准确性，并在内存访问和计算功耗方面表现出显著优势。

**AI_Comments:** 该论文的创新之处在于提出了一个基于前向-前向的无梯度近似训练框架FFGAF-SNN，并引入了类别感知复杂性适应机制。这对于提高SNN在能源效率神经形态计算领域的实用性至关重要，尤其是在边缘设备上，因为它同时提升了准确性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 脉冲神经网络（SNNs）由于其非可微性，难以进行高效训练。现有的梯度近似方法常常牺牲准确性，并且由于反向传播的巨大计算需求，在边缘设备上的部署面临限制。

**Method:** 本文提出了一种基于前向-前向（FF）的无梯度近似脉冲神经网络训练框架FFGAF-SNN。该框架将脉冲激活视为黑盒模块，从而消除了对梯度近似的需求，并显著降低了计算复杂性。此外，它还引入了一种类别感知复杂性适应机制，该机制根据类间难度指标动态优化损失函数，从而实现跨不同类别的网络资源高效分配。

**Result:** 实验结果表明，所提出的训练框架在MNIST、Fashion-MNIST和CIFAR-10数据集上分别达到了99.58%、92.13%和75.64%的测试准确率，超越了所有现有基于FF的SNN方法。此外，所提出的方法在内存访问和计算功耗方面也表现出显著优势。

**Conclusion:** FFGAF-SNN框架通过消除梯度近似和优化资源分配，有效解决了SNN训练的挑战，从而在准确性和效率上优于现有的基于FF的方法。

> **ai_Abstract:** 本文提出了FFGAF-SNN，一种新颖的基于前向-前向的脉冲神经网络训练框架。它通过将脉冲激活视为黑盒模块，解决了SNN非可微性的挑战，从而无需梯度近似并显著降低了计算复杂性。此外，该框架还结合了类别感知复杂性适应机制，以动态优化损失函数并高效分配网络资源。实验结果表明，FFGAF-SNN在MNIST、Fashion-MNIST和CIFAR-10数据集上取得了最先进的准确率，超越了现有基于FF的SNN方法，同时在内存和计算效率方面也表现出卓越性能。

> **摘要翻译:** 脉冲神经网络（SNNs）为节能神经形态计算提供了一个生物学上合理的框架。然而，由于其非可微性，高效训练SNNs是一个挑战。现有的梯度近似方法经常牺牲准确性，并且由于反向传播的巨大计算需求，在边缘设备上的部署面临限制。为了解决这些挑战，我们提出了一种基于前向-前向（FF）的无梯度近似脉冲神经网络训练框架，该框架将脉冲激活视为黑盒模块，从而消除了对梯度近似的需求，同时显著降低了计算复杂性。此外，我们引入了一种类别感知复杂性适应机制，该机制根据类间难度指标动态优化损失函数，从而实现跨不同类别的网络资源高效分配。实验结果表明，我们提出的训练框架在MNIST、Fashion-MNIST和CIFAR-10数据集上分别达到了99.58%、92.13%和75.64%的测试准确率，超越了所有现有基于FF的SNN方法。此外，我们提出的方法在内存访问和计算功耗方面也表现出显著优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [518] [Fine-grained Spatiotemporal Grounding on Egocentric Videos](https://arxiv.org/abs/2508.00518)
> *Egocentric Videos上的细粒度时空定位*

*Shuo Liang, Yiwu Zhong, Zi-Yuan Hu, Yeyao Tao, Liwei Wang* | **Category: cs.CV, cs.CL** | **Updated: 2025-08-01**

**Keywords:** Egocentric video, Spatiotemporal grounding, EgoMask, Dataset, Automatic annotation

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本文针对以自我为中心的视频中的细粒度时空定位问题，分析了挑战，并提出了首个像素级基准EgoMask和大规模训练数据集EgoMask-Train，实验表明其能显著提升现有模型的性能。

**AI_Comments:** 本文的创新点在于首次提出了用于以自我为中心的视频的像素级细粒度时空定位基准数据集EgoMask，并构建了大规模训练数据集EgoMask-Train。通过系统分析以自我为中心视频的独有挑战，并提供相应的资源，极大地推动了该领域的研究进展。其价值在于填补了以自我为中心视频理解的空白，对增强现实和机器人等实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在以外部视角拍摄的视频（exocentric videos）时空定位方面取得了显著进展，但以自我为中心视角拍摄的视频（egocentric videos）仍未被充分探索，尽管其在增强现实和机器人等应用中日益重要。此外，egocentric视频与exocentric视频存在显著差异，带来独特的挑战（如物体持续时间短、轨迹稀疏、物体尺寸小、位置偏移大）。

**Method:** 作者对egocentric和exocentric视频之间的差异进行了系统分析。为了应对挑战，他们引入了EgoMask，这是首个用于egocentric视频细粒度时空定位的像素级基准，并通过提出的自动标注流程构建。同时，创建了大规模训练数据集EgoMask-Train以促进模型开发。

**Result:** 实验表明，最先进的时空定位模型在EgoMask基准上表现不佳。然而，在EgoMask-Train上进行微调后，模型性能得到显著提升，同时在exocentric数据集上的性能得以保持。

**Conclusion:** 本文为推进以自我为中心的视频理解提供了必要的资源和见解。

> **ai_Abstract:** 本文关注以自我为中心的视频中的细粒度时空定位问题，指出该领域相比外部视角视频研究不足且面临独特挑战。为解决这些问题，作者系统分析了两种视频的差异，并推出了首个像素级基准数据集EgoMask及其训练集EgoMask-Train，通过自动标注流程构建。实验证明，现有SOTA模型在EgoMask上表现不佳，但经过EgoMask-Train微调后性能显著提升，且不影响在外部视角数据集上的表现，为以自我为中心的视频理解提供了关键资源和见解。

> **摘要翻译:** 时空视频定位旨在根据文本查询在视频中定位目标实体。尽管现有研究在外部视角视频方面取得了显著进展，但以自我为中心的设置仍相对未被充分探索，尽管其在增强现实和机器人等应用中日益重要。在这项工作中，我们对以自我为中心和外部视角视频之间的差异进行了系统分析，揭示了诸如物体持续时间更短、轨迹更稀疏、物体尺寸更小以及位置偏移更大等关键挑战。为了应对这些挑战，我们引入了EgoMask，这是第一个用于以自我为中心视频中细粒度时空定位的像素级基准。它由我们提出的自动标注流程构建，该流程标注了短、中、长期视频中的指代表达和对象掩码。此外，我们创建了EgoMask-Train，一个大规模训练数据集，以促进模型开发。实验表明，最先进的时空定位模型在我们的EgoMask基准上表现不佳，但在EgoMask-Train上进行微调后，取得了显著的改进，同时保持了在外部视角数据集上的性能。因此，我们的工作为推进以自我为中心的视频理解提供了必要的资源和见解。我们的代码可在https://github.com/LaVi-Lab/EgoMask 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [523] [IN2OUT: Fine-Tuning Video Inpainting Model for Video Outpainting Using Hierarchical Discriminator](https://arxiv.org/abs/2508.00418)
> *IN2OUT：使用分层判别器微调视频修复模型以进行视频外绘*

*Sangwoo Youn, Minji Lee, Nokap Tony Park, Yeonggyoo Jeon, Taeyoung Na* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 视频外绘, 视频修复, 分层判别器, 对抗训练, 损失函数

**Comment:** ICIP 2025. Code: https://github.com/sang-w00/IN2OUT

> **TL;DR:** 提出IN2OUT方法，通过引入分层判别器和专用损失函数，有效微调视频修复模型以实现高质量视频外绘，解决了传统方法模糊和不一致的问题。

**AI_Comments:** 本文的创新点在于将视频修复模型应用于视频外绘，并通过引入分层判别器和专门的损失函数来克服直接应用时的局限性。这种方法有效解决了视频外绘中图像模糊和内容不一致的关键问题，通过关注局部和全局感知质量，显著提升了外绘视频的真实感和连贯性，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 视频外绘在扩展边界同时保持内容一致性方面面临挑战。现有方法仅生成背景，且直接应用或微调视频修复模型进行外绘会导致模糊结果，原因是缺少能有效评估扩展区域感知质量的判别器。

**Method:** 本文提出IN2OUT方法，通过将对抗训练目标区分为全局和局部，并引入一个满足这两个目标的分层判别器。此外，开发了一个利用判别器局部和全局特征的专用外绘损失函数。通过在此对抗性损失函数上进行微调，提升生成器生成视觉吸引且全局连贯的外绘场景的能力。

**Result:** 所提出的方法在定量和定性上均优于现有最先进的方法，能生成视觉吸引且全局连贯的外绘场景。

**Conclusion:** 本文通过引入分层判别器和专用外绘损失函数，成功地将视频修复模型有效地微调用于视频外绘任务，解决了传统方法中存在的图像模糊和一致性问题，并取得了超越现有技术水平的成果。

> **ai_Abstract:** 本文提出IN2OUT方法，旨在解决视频外绘中扩展边界同时保持内容一致性的挑战。针对现有视频修复模型直接应用于外绘时产生的模糊问题，作者发现缺乏有效的判别器是关键。为此，他们引入了一个分层判别器来评估全局和局部感知质量，并设计了一个利用这些特征的专用外绘损失函数。实验表明，该方法能够显著提升视频外绘的视觉质量和全局连贯性，并超越了现有SOTA方法。

> **摘要翻译:** 视频外绘提出了一个独特的挑战，即在扩展边界的同时保持与给定内容的一致性。在本文中，我们建议使用在物体流学习和重建方面表现出色的视频修复模型来进行外绘，而不是像现有方法那样仅仅生成背景。然而，直接应用或微调修复模型进行外绘已被证明是无效的，通常会导致模糊的结果。我们对判别器设计的广泛实验表明，在外绘微调过程中缺失的关键组件是能够有效评估扩展区域感知质量的判别器。为了解决这一限制，我们将对抗训练的目标区分为全局和局部目标，并引入了一个满足这两个目标的分层判别器。此外，我们开发了一个利用判别器局部和全局特征的专用外绘损失函数。在此对抗性损失函数上进行微调，增强了生成器生成视觉吸引且全局连贯的外绘场景的能力。我们提出的方法在定量和定性上都优于现有最先进的方法。包括演示视频和代码在内的补充材料可在SigPort获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [532] [Is It Really You? Exploring Biometric Verification Scenarios in Photorealistic Talking-Head Avatar Videos](https://arxiv.org/abs/2508.00748)
> *真的是你吗？探索逼真会说话头像视频中的生物识别验证场景*

*Laura Pedrouzo-Rodriguez, Pedro Delgado-DeRobles, Luis F. Gomez, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez* | **Category: cs.CV, cs.AI, cs.CR, cs.MM** | **Updated: 2025-08-01**

**Keywords:** 逼真头像, 生物识别验证, 面部运动, 冒充检测, 图卷积网络

**Comment:** Accepted at the IEEE International Joint Conference on Biometrics
  (IJCB 2025)

> **TL;DR:** 研究探讨在逼真头像视频中，如何通过面部运动模式进行身份验证以对抗冒充威胁。

**AI_Comments:** 本文的创新点在于提出了利用面部运动模式作为行为生物识别特征来解决逼真头像冒充问题，这在视觉和听觉信息被伪造的情况下提供了一种新的验证维度。其重要性体现在应对新兴的数字身份安全威胁，并为未来基于头像的通信系统安全提供了研究基准和方向。

<details>
  <summary>Details</summary>

**Motivation:** 逼真会说话的头像在虚拟会议、游戏和社交平台中越来越普遍，但它们也带来了严重的安全风险，特别是冒充威胁，攻击者可以窃取用户头像并模仿其外观和声音，使得仅凭视觉或听觉难以检测欺诈使用。

**Method:** 引入了一个使用最先进的单样本头像生成模型 GAGAvatar 创建的逼真头像视频新数据集，包含真实和冒充者头像视频。提出了一种轻量级、可解释的带有时间注意力池化的时空图卷积网络架构，该架构仅使用面部标志来建模动态面部手势。

**Result:** 实验结果表明，面部运动线索能够实现有意义的身份验证，AUC 值接近 80%。

**Conclusion:** 面部运动模式可以作为可靠的行为生物识别特征，在头像介导的场景中验证个体身份，并强调了在基于头像的通信系统中对更先进的行为生物识别防御的迫切需求。

> **ai_Abstract:** 本文探讨了在逼真会说话头像视频中进行生物识别验证的挑战，尤其是在存在冒充威胁的情况下。研究提出通过分析个体的面部运动模式作为行为生物识别特征来验证身份。为此，作者创建了一个包含真实和冒充者头像视频的新数据集，并提出了一种基于时空图卷积网络的面部标志分析方法。实验证明，面部运动线索能有效进行身份验证，AUC 值接近80%。该研究强调了在头像通信系统中加强行为生物识别防御的必要性。

> **摘要翻译:** 逼真会说话的头像在虚拟会议、游戏和社交平台中越来越常见。这些头像使得交流更加沉浸，但它们也引入了严重的安全风险。一个新兴的威胁是冒充：攻击者可以窃取用户的头像——保留其外观和声音——使得仅凭视觉或听觉几乎不可能检测到其欺诈性使用。在本文中，我们探讨了在这种头像介导的场景中生物识别验证的挑战。我们的主要问题是，当头像的视觉外观是其所有者的复制品时，个体的面部运动模式是否可以作为可靠的行为生物识别特征来验证其身份。为了回答这个问题，我们引入了一个使用最先进的单样本头像生成模型 GAGAvatar 创建的逼真头像视频新数据集，其中包含真实和冒充者头像视频。我们还提出了一种轻量级、可解释的带有时间注意力池化的时空图卷积网络架构，该架构仅使用面部标志来建模动态面部手势。实验结果表明，面部运动线索能够实现有意义的身份验证，AUC 值接近 80%。所提出的基准和生物识别系统已提供给研究社区，以引起人们对基于头像的通信系统中更先进的行为生物识别防御的迫切需求的关注。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [533] [LesiOnTime -- Joint Temporal and Clinical Modeling for Small Breast Lesion Segmentation in Longitudinal DCE-MRI](https://arxiv.org/abs/2508.00496)
> *LesiOnTime -- 纵向DCE-MRI中小乳腺病变分割的时间和临床联合建模*

*Mohammed Kamran, Maria Bernathova, Raoul Varga, Christian F. Singer, Zsuzsanna Bago-Horvath, Thomas Helbich, Georg Langs, Philipp Seeböck* | **Category: cs.CV, cs.AI** | **Updated: 2025-08-04**

**Keywords:** 乳腺病变分割, DCE-MRI, 纵向建模, BI-RADS评分, 深度学习

**Comment:** 

> **TL;DR:** LesiOnTime是一种新的3D分割方法，通过联合利用纵向成像和BI-RADS评分，提高了乳腺DCE-MRI中小病变的分割精度，优于现有方法。

**AI_Comments:** 该论文的创新之处在于其将纵向影像信息与临床BI-RADS评分相结合的策略，这更贴近真实的临床诊断流程。通过引入TPA模块处理时间序列数据和BCR损失嵌入领域知识，有效提升了小乳腺病变分割的准确性。这对于早期癌症检测具有重要意义，尤其是在高危患者的筛查中。

<details>
  <summary>Details</summary>

**Motivation:** 乳腺动态对比增强MRI（DCE-MRI）中准确分割小病变对于早期癌症检测至关重要，特别是对高危患者。现有深度学习方法主要针对大病变，并且忽略了放射科医生日常使用的宝贵纵向和临床信息，这在现实世界的筛查中对于检测细微或新出现的病变非常重要。

**Method:** 提出LesiOnTime，一种新颖的3D分割方法，它通过联合利用纵向成像和BI-RADS评分来模拟临床诊断工作流程。其关键组成部分包括：(1) 时间先验注意力（TPA）模块，动态整合来自先前和当前扫描的信息；(2) BI-RADS一致性正则化（BCR）损失，强制具有相似放射学评估的扫描在潜在空间中对齐，从而将领域知识嵌入到训练过程中。

**Result:** 在精心策划的内部高危患者纵向DCE-MRI数据集上进行评估，LesiOnTime在Dice指标上比最先进的单时间点和纵向基线方法高出5%。消融研究表明，TPA和BCR都带来了互补的性能提升。

**Conclusion:** 这些结果强调了结合时间和临床背景对于在现实世界乳腺癌筛查中可靠地进行早期病变分割的重要性。

> **ai_Abstract:** 本研究提出LesiOnTime，一种用于乳腺DCE-MRI中小病变分割的新型3D方法。该方法通过引入时间先验注意力（TPA）模块和BI-RADS一致性正则化（BCR）损失，联合利用纵向成像数据和BI-RADS临床评分，以模拟放射科医生诊断流程。在内部纵向数据集上的实验结果表明，LesiOnTime在Dice评分上优于现有基线方法5%，且TPA和BCR均对性能有显著贡献，强调了整合时间和临床信息对早期病变分割的重要性。

> **摘要翻译:** 乳腺动态对比增强MRI (DCE-MRI) 中小病变的准确分割对于早期癌症检测至关重要，尤其是在高危患者中。尽管最近的深度学习方法在病变分割方面取得了进展，但它们主要针对大型病变，并且忽略了放射科医生日常使用的宝贵的纵向和临床信息。在现实世界的筛查中，检测细微或新出现的病变需要放射科医生跨时间点进行比较，并考虑先前的放射学评估，例如BI-RADS评分。我们提出了LesiOnTime，一种新颖的3D分割方法，它通过联合利用纵向成像和BI-RADS评分来模拟临床诊断工作流程。其关键组成部分是：(1) 时间先验注意力（TPA）模块，动态整合来自先前和当前扫描的信息；和 (2) BI-RADS一致性正则化（BCR）损失，强制具有相似放射学评估的扫描在潜在空间中对齐，从而将领域知识嵌入到训练过程中。在精心策划的内部高危患者纵向DCE-MRI数据集上进行评估，我们的方法在Dice指标上比最先进的单时间点和纵向基线方法高出5%。消融研究表明，TPA和BCR都带来了互补的性能提升。这些结果强调了结合时间和临床背景对于在现实世界乳腺癌筛查中可靠地进行早期病变分割的重要性。我们的代码可在 https://github.com/cirmuw/LesiOnTime 公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [534] [YOLO-Count: Differentiable Object Counting for Text-to-Image Generation](https://arxiv.org/abs/2508.00728)
> *YOLO-Count：面向文本到图像生成的微分对象计数*

*Guanning Zeng, Xiang Zhang, Zirui Wang, Haiyang Xu, Zeyuan Chen, Bingnan Li, Zhuowen Tu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 对象计数, 文本到图像生成, 可微分模型, 数量控制, 基数图

**Comment:** ICCV 2025

> **TL;DR:** YOLO-Count是一个可微分的开放词汇对象计数模型，通过引入“基数图”和混合监督，实现了精确的文本到图像生成中的数量控制，并达到了最先进的计数精度。

**AI_Comments:** 这篇论文通过提出YOLO-Count模型及其创新的“基数图”概念，有效解决了文本到图像生成中精确对象数量控制的难题，这是一个重要的进步。其可微分的架构使其能够与生成模型无缝集成，并通过梯度优化进行指导，这在跨模态生成控制领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决通用对象计数挑战，并为文本到图像（T2I）生成提供精确的数量控制。

**Method:** 提出了YOLO-Count模型，一个可微分的开放词汇对象计数模型。核心贡献是引入了“基数图”作为新的回归目标，该图考虑了对象大小和空间分布的变化。模型利用表示对齐和混合强-弱监督方案，其完全可微分的架构支持基于梯度的优化。

**Result:** YOLO-Count在对象计数方面达到了最先进的准确性，并为T2I系统提供了稳健有效的数量控制。

**Conclusion:** YOLO-Count通过其创新的“基数图”和可微分架构，成功地解决了对象计数和T2I生成中的数量控制问题，实现了卓越的性能。

> **ai_Abstract:** YOLO-Count是一个新颖的可微分开放词汇对象计数模型，旨在解决通用计数问题并为文本到图像生成提供精确的数量控制。该模型引入了独特的“基数图”作为回归目标，以适应对象大小和空间分布。通过结合表示对齐和混合强-弱监督，YOLO-Count能够实现梯度优化，从而在对象计数和T2I生成数量控制方面达到最先进的性能。

> **摘要翻译:** 我们提出了YOLO-Count，一个可微分的开放词汇对象计数模型，它解决了通用计数挑战，并能为文本到图像（T2I）生成提供精确的数量控制。一个核心贡献是“基数图”，这是一个新颖的回归目标，它考虑了对象大小和空间分布的变化。YOLO-Count利用表示对齐和混合强-弱监督方案，弥合了开放词汇计数和T2I生成控制之间的差距。其完全可微分的架构促进了基于梯度的优化，从而实现了精确的对象计数估计和对生成模型的精细指导。大量实验表明，YOLO-Count在实现最先进计数精度的同时，为T2I系统提供了稳健有效的数量控制。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [540] [$\texttt{BATCLIP}$: Bimodal Online Test-Time Adaptation for CLIP](https://arxiv.org/abs/2412.02837)
> *BATCLIP：CLIP的双模态在线测试时自适应*

*Sarthak Kumar Maharana, Baoming Zhang, Leonid Karlinsky, Rogerio Feris, Yunhui Guo* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** CLIP, 测试时自适应, 图像损坏, 双模态, 在线学习

**Comment:** ICCV 2025

> **TL;DR:** BATCLIP是一种双模态在线测试时自适应方法，用于提高CLIP模型对常见图像损坏的鲁棒性。

**AI_Comments:** 本文提出了一种新颖的双模态在线测试时自适应方法BATCLIP，解决了CLIP模型在图像损坏下鲁棒性差的痛点。其创新点在于同时考虑了视觉编码器的自适应和图像-文本特征的对齐，这比传统的单模态TTA方法更全面。该方法在SOTA结果和泛化能力上的表现，使其成为TTA领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 开放词汇分类模型如CLIP在零样本学习方面表现出色，但其对常见图像损坏的鲁棒性尚不明确。现有测试时自适应（TTA）方法由于其单模态性质，在适应CLIP方面存在严重局限性。

**Method:** 我们提出了BATCLIP，一种双模态在线测试时自适应（TTA）方法，旨在提高CLIP对常见图像损坏的鲁棒性。其关键在于不仅自适应视觉编码器以改进图像特征，还通过促进图像类别原型（使用伪标签计算）与相应文本特征之间的更强关联来加强图像和文本特征之间的对齐。

**Result:** 在基准图像损坏数据集上取得了在线TTA的最新SOTA结果。此外，在各种域泛化数据集上评估了该TTA方法，证明了其泛化能力。

**Conclusion:** BATCLIP通过双模态在线测试时自适应有效提高了CLIP对常见图像损坏的鲁棒性，并在多项任务上展现了优越的性能和泛化能力。

> **ai_Abstract:** 本研究提出了一种名为BATCLIP的双模态在线测试时自适应（TTA）方法，旨在解决CLIP模型在面对常见图像损坏时鲁棒性不足的问题。现有TTA方法因其单模态性质而无法有效适应CLIP。BATCLIP通过同时自适应视觉编码器和加强图像与文本特征之间的对齐（利用伪标签计算的图像类别原型）来提高CLIP的鲁棒性。实验结果表明，BATCLIP在基准图像损坏数据集上取得了SOTA性能，并展现了良好的泛化能力。

> **摘要翻译:** 尽管像对比语言图像预训练（CLIP）这样的开放词汇分类模型已经展示出强大的零样本学习能力，但它们对常见图像损坏的鲁棒性仍然知之甚少。通过大量实验，我们发现零样本CLIP在测试时缺乏对常见图像损坏的鲁棒性，因此需要使用测试时自适应（TTA）将CLIP适应到未标记的损坏图像。然而，我们发现现有的TTA方法由于其单模态性质，在适应CLIP方面存在严重局限性。为了解决这些局限性，我们提出了BATCLIP，一种双模态在线TTA方法，旨在提高CLIP对常见图像损坏的鲁棒性。我们方法的关键在于，不仅要自适应视觉编码器以改进图像特征，还要通过促进图像类别原型（使用伪标签计算）与相应文本特征之间的更强关联来加强图像和文本特征之间的对齐。我们在基准图像损坏数据集上评估了我们的方法，并在CLIP的在线TTA中取得了最先进的结果。此外，我们在各种域泛化数据集上评估了我们提出的TTA方法，以证明其泛化能力。我们的代码可在https://github.com/sarthaxxxxx/BATCLIP获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [542] [Robust 3D Object Detection using Probabilistic Point Clouds from Single-Photon LiDARs](https://arxiv.org/abs/2508.00169)
> *使用单光子激光雷达的概率点云进行鲁棒三维目标检测*

*Bhavya Goyal, Felipe Gutierrez-Barragan, Wei Lin, Andreas Velten, Yin Li, Mohit Gupta* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 概率点云, 三维目标检测, 激光雷达, 不确定性, 鲁棒性

**Comment:** ICCV 2025

> **TL;DR:** 本文提出了一种名为概率点云（PPC）的新型三维场景表示，它通过为每个点添加概率属性来封装测量不确定性。PPC及其推理方法可以作为轻量级模块集成到现有三维检测流程中，并在各种挑战性场景下显著优于现有基线。

**AI_Comments:** 本文的创新点在于提出了概率点云（PPC）这一新的三维表示，它有效地将原始激光雷达测量中的不确定性信息整合到点云数据中。这解决了传统方法忽略测量噪声传播的问题，从而提高了下游感知模型的鲁棒性。其重要性在于，通过轻量级的即插即用模块，该方法能够显著提升在恶劣环境（如远距离、低反照率物体、强环境光）下三维目标检测的准确性，具有很强的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代激光雷达在远距离或低反照率物体等实际场景中面临挑战，会产生稀疏或错误的点云。这些误差源于原始激光雷达测量中的噪声，并传播到下游感知模型，导致精度严重下降。这是因为传统的三维处理流程在构建点云时没有保留原始测量中的任何不确定性信息。

**Method:** 我们提出了概率点云（PPC），这是一种新颖的三维场景表示，其中每个点都通过一个概率属性进行增强，该属性封装了原始数据中的测量不确定性（或置信度）。我们进一步引入了利用PPC进行鲁棒三维目标检测的推理方法；这些方法用途广泛，可以作为计算轻量级的即插即用模块用于三维推理流程。

**Result:** 通过仿真和真实捕获，我们证明了基于PPC的三维推理方法在涉及小型、远距离和低反照率物体以及强环境光的挑战性室内和室外场景中，优于使用激光雷达以及相机-激光雷达融合模型的多个基线方法。

**Conclusion:** 概率点云（PPC）及其相关推理方法能够有效处理激光雷达测量中的不确定性，从而显著提升在复杂和挑战性场景下三维目标检测的鲁棒性和准确性。

> **ai_Abstract:** 本文提出了一种名为概率点云（PPC）的新型三维场景表示，旨在解决传统激光雷达在处理稀疏或错误点云时缺乏不确定性信息的问题。PPC通过为每个点添加一个概率属性来封装原始测量的不确定性。作者还引入了利用PPC进行鲁棒三维目标检测的推理方法，这些方法可以作为轻量级模块集成到现有流程中。实验结果表明，在各种挑战性室内外场景下，基于PPC的三维推理方法在3D目标检测方面显著优于多种基线方法，包括纯激光雷达和相机-激光雷达融合模型。

> **摘要翻译:** 基于激光雷达的三维传感器提供点云，这是一种用于各种场景理解任务的规范三维表示。现代激光雷达在某些实际场景中面临关键挑战，例如远距离或低反照率物体，会产生稀疏或错误的点云。这些误差源于原始激光雷达测量中的噪声，并传播到下游感知模型，导致精度可能严重下降。这是因为传统的三维处理流程在构建点云时没有保留原始测量中的任何不确定性信息。

我们提出了概率点云（PPC），这是一种新颖的三维场景表示，其中每个点都通过一个概率属性进行增强，该属性封装了原始数据中的测量不确定性（或置信度）。我们进一步引入了利用PPC进行鲁棒三维目标检测的推理方法；这些方法用途广泛，可以作为计算轻量级的即插即用模块用于三维推理流程。通过仿真和真实捕获，我们证明了基于PPC的三维推理方法在涉及小型、远距离和低反照率物体以及强环境光的挑战性室内和室外场景中，优于使用激光雷达以及相机-激光雷达融合模型的多个基线方法。

我们的项目网页是 https://bhavyagoyal.github.io/ppc 。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [543] [UIS-Mamba: Exploring Mamba for Underwater Instance Segmentation via Dynamic Tree Scan and Hidden State Weaken](https://arxiv.org/abs/2508.00421)
> *UIS-Mamba：通过动态树扫描和隐藏状态削弱探索Mamba用于水下实例分割*

*Runmin Cong, Zongji Yu, Hao Fang, Haoyan Sun, Sam Kwong* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 水下实例分割, Mamba, 动态树扫描, 隐藏状态削弱, 状态空间模型

**Comment:** ACM MM 2025

> **TL;DR:** 提出首个基于Mamba的水下实例分割模型UIS-Mamba，通过DTS和HSW模块解决水下场景特有挑战，在UIIS和USIS10K数据集上达到SOTA性能。

**AI_Comments:** 该研究首次将Mamba模型引入水下实例分割领域，通过DTS和HSW两个创新模块，有效地解决了水下图像特有的挑战，如色彩失真和模糊边界。这种针对特定应用场景进行模型结构优化的方法，展示了Mamba在复杂视觉任务中的巨大潜力，同时其轻量化设计也具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 水下实例分割（UIS）对于水下复杂场景检测至关重要，但水下场景特有的色彩失真和模糊边界对Mamba等模型的应用带来了挑战。现有Mamba的固定补丁扫描机制难以保持实例内部连续性，复杂背景的隐藏状态也会抑制对实例对象的理解。

**Method:** 本文提出了首个基于Mamba的水下实例分割模型UIS-Mamba。设计了两个创新模块：动态树扫描（DTS）模块和隐藏状态削弱（HSW）模块。DTS通过允许补丁动态偏移和缩放来维持实例对象内部特征的连续性，引导最小生成树并提供动态局部感受野。HSW通过基于Ncut的隐藏状态削弱机制，抑制复杂背景的干扰，有效将状态传播的信息流聚焦到实例本身。

**Result:** UIS-Mamba在UIIS和USIS10K数据集上均实现了最先进的性能，同时保持了较低的参数数量和计算复杂度。

**Conclusion:** UIS-Mamba成功地将Mamba模型应用于水下实例分割任务，通过创新的DTS和HSW模块有效解决了水下场景的特殊挑战，并在性能和效率方面取得了显著优势。

> **ai_Abstract:** 本文提出了首个基于Mamba的水下实例分割模型UIS-Mamba，旨在解决水下复杂场景中Mamba应用的挑战。针对水下色彩失真和边界模糊问题，设计了动态树扫描（DTS）模块以保持实例内部特征连续性，并通过隐藏状态削弱（HSW）模块抑制复杂背景干扰。实验证明，UIS-Mamba在UIIS和USIS10K数据集上实现了最先进的性能，同时保持了较低的参数量和计算复杂度。

> **摘要翻译:** 水下实例分割（UIS）任务对于水下复杂场景检测至关重要。Mamba作为一种新兴的状态空间模型，具有固有的线性复杂度和全局感受野，非常适合处理具有长序列特征的图像分割任务。然而，由于水下场景的特殊性，将Mamba应用于UIS存在许多挑战。现有的固定补丁扫描机制在存在严重水下色彩失真和模糊实例边界的情况下，无法保持扫描实例的内部连续性，并且复杂水下背景的隐藏状态也可能抑制对实例对象的理解。在这项工作中，我们提出了第一个基于Mamba的水下实例分割模型UIS-Mamba，并设计了两个创新模块：动态树扫描（DTS）和隐藏状态削弱（HSW），以将Mamba迁移到水下任务。DTS模块通过允许补丁动态偏移和缩放来保持实例对象内部特征的连续性，从而引导最小生成树并提供动态局部感受野。HSW模块通过基于Ncut的隐藏状态削弱机制，抑制复杂背景的干扰，并有效地将状态传播的信息流聚焦到实例本身。实验结果表明，UIS-Mamba在UIIS和USIS10K数据集上均实现了最先进的性能，同时保持了较低的参数数量和计算复杂度。代码可在https://github.com/Maricalce/UIS-Mamba获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [560] [The Silent Assistant: NoiseQuery as Implicit Guidance for Goal-Driven Image Generation](https://arxiv.org/abs/2412.05101)
> *沉默的助手：NoiseQuery 作为目标驱动图像生成的隐式指导*

*Ruoyu Wang, Huayang Huang, Ye Zhu, Olga Russakovsky, Yu Wu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 文本到图像生成, 噪声初始化, 隐式指导, 扩散模型, 模型无关

**Comment:** ICCV 2025 Highlight

> **TL;DR:** NoiseQuery 是一种新型的噪声初始化方法，利用对齐的高斯噪声作为隐式指导，显著提升了文本到图像生成的质量和可控性，且具有模型无关性和低计算开销。

**AI_Comments:** NoiseQuery 的创新之处在于其模型无关的特性和利用隐式指导来增强文本到图像生成的能力。它通过对噪声初始化进行根本性改进，解决了传统文本提示在控制低级视觉属性方面的局限性。其作为可重用噪声库的潜力，使其成为未来T2I生成领域的重要基础。

<details>
  <summary>Details</summary>

**Motivation:** 为了提升目标驱动文本到图像（T2I）生成中，通过文本提示难以精确控制的高级语义和低级视觉属性的生成质量和可控性，并解决现有噪声优化方法缺乏通用性的问题。

**Method:** 本研究引入了 NoiseQuery，一种针对通用目标驱动文本到图像（T2I）生成中增强噪声初始化的新方法。它利用对齐的高斯噪声作为隐式指导，以补充文本提示等显式用户输入。与现有针对特定模型设计的噪声优化方法不同，NoiseQuery 基于对扩散公式中通用有限步噪声调度器设计的深入研究，实现了在不同扩散模型架构间的良好泛化，且无需额外调优。这种模型无关的特性使其能够构建一个可重用的噪声库。

**Result:** 广泛的实验表明，NoiseQuery 不仅能实现对高级语义的细粒度控制，还能显著提升对通常难以通过文本单独指定的低级视觉属性的性能。它能无缝集成到现有工作流程中，且计算开销极小，并能构建一个兼容多种T2I模型和增强技术的可重用噪声库。

**Conclusion:** NoiseQuery 通过利用对齐的高斯噪声作为隐式指导，为目标驱动的文本到图像生成提供了一种通用、高效且模型无关的噪声初始化方法，显著提升了生成质量和可控性，尤其是在处理文本难以表达的视觉细节方面。

> **ai_Abstract:** NoiseQuery 是一种用于文本到图像（T2I）生成的新型噪声初始化方法。它通过利用对齐的高斯噪声作为隐式指导，补充显式文本输入，从而提高了生成质量和可控性。该方法基于对扩散模型中噪声调度器的通用研究，使其具有模型无关性，能够无需调优地泛化到不同的扩散架构。实验证明，NoiseQuery 能实现对高级语义和低级视觉属性的细粒度控制，显著提升性能，并能无缝集成到现有工作流程中，计算开销极小。

> **摘要翻译:** 在这项工作中，我们引入了 NoiseQuery 作为一种新颖的方法，用于增强通用目标驱动文本到图像（T2I）生成中的噪声初始化。具体来说，我们提出利用对齐的高斯噪声作为隐式指导，以补充显式用户定义输入（例如文本提示），从而获得更好的生成质量和可控性。与现有为特定模型设计的噪声优化方法不同，我们的方法基于对扩散公式中通用有限步噪声调度器设计的深入研究，从而实现了在不同扩散基础架构之间的更好泛化，且无需调优。这种模型无关的特性使我们能够构建一个可重用的噪声库，兼容多种 T2I 模型和增强技术，作为更有效生成的基础层。广泛的实验表明，NoiseQuery 不仅能实现对高级语义的细粒度控制，而且能显著提升对低级视觉属性的性能，这些属性通常难以通过文本单独指定，并且能以最小的计算开销无缝集成到当前工作流程中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [562] [On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI](https://arxiv.org/abs/2508.00171)
> *关于误导性报告的风险：诊断多模态临床AI中的文本偏见*

*David Restrepo, Ira Ktena, Maria Vakalopoulou, Stergios Christodoulidis, Enzo Ferrante* | **Category: cs.CV, cs.CL** | **Updated: 2025-07-31**

**Keywords:** 多模态AI, 临床AI, 文本偏见, 视觉-语言模型, 模态转移

**Comment:** Accepted to MICCAI 2025 1st Workshop on Multimodal Large Language
  Models (MLLMs) in Clinical Practice

> **TL;DR:** 该研究引入了一种名为选择性模态转移（SMS）的方法，用于诊断多模态临床AI中视觉语言模型（VLMs）对文本输入的偏见，发现这些模型即使在有互补视觉信息的情况下也严重依赖文本，强调了真正整合多模态信息的模型设计的重要性。

**AI_Comments:** 该论文通过引入选择性模态转移（SMS）这一创新方法，有效地诊断并量化了多模态临床AI中视觉-语言模型对文本的偏见，揭示了当前模型在整合视觉和文本信息方面的不足。这项工作的重要性在于，它明确指出了现有临床AI模型可能因偏向文本而产生误导性报告的风险，为未来多模态医疗AI模型的公平性和鲁棒性设计提供了关键的见解和评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 临床决策依赖于医学图像和相关临床报告的综合分析。然而，视觉-语言模型（VLMs）在处理此类任务时，可能对单一模态表现出强烈偏见，经常为了文本信息而忽略关键的视觉线索，这可能导致误导性报告。

**Method:** 研究引入了选择性模态转移（SMS），这是一种基于扰动的方法，用于量化模型在二元分类任务中对每种模态的依赖程度。通过系统地在具有相反标签的样本之间交换图像或文本，揭示了模态特异性偏见。评估了六个开源VLM（四个通用模型和两个针对医疗数据微调的模型）在两个具有不同模态的医学影像数据集（MIMIC-CXR和FairVLMed）上的表现。通过评估模型在未扰动和扰动设置下的性能和校准，并进行了定性注意力分析。

**Result:** 研究发现，模型对文本输入表现出明显的依赖性，即使存在互补的视觉信息也是如此。定性注意力分析进一步证实，图像内容经常被文本细节所掩盖。

**Conclusion:** 研究结果强调了设计和评估真正整合视觉和文本线索的多模态医疗模型的重要性，而不是仅仅依赖于单一模态信号。

> **ai_Abstract:** 本研究探讨了多模态临床AI中视觉-语言模型（VLMs）的文本偏见问题。研究引入了一种名为选择性模态转移（SMS）的扰动方法，通过交换图像或文本来量化模型对不同模态的依赖性。在MIMIC-CXR和FairVLMed两个医学影像数据集上评估了六个VLM，结果显示模型即使在有视觉信息的情况下也严重依赖文本输入，且图像内容常被文本细节掩盖。这强调了开发真正整合视觉和文本线索的多模态医疗模型的重要性。

> **摘要翻译:** 临床决策依赖于医学图像和相关临床报告的综合分析。尽管视觉-语言模型（VLMs）可以为此类任务提供统一框架，但它们可能对单一模态表现出强烈偏见，经常为了文本信息而忽略关键的视觉线索。在这项工作中，我们引入了选择性模态转移（SMS），这是一种基于扰动的方法，用于量化模型在二元分类任务中对每种模态的依赖程度。通过系统地在具有相反标签的样本之间交换图像或文本，我们揭示了模态特异性偏见。我们评估了六个开源VLM——四个通用模型和两个针对医疗数据微调的模型——在两个具有不同模态的医学影像数据集：MIMIC-CXR（胸部X光）和FairVLMed（扫描激光眼底镜）上的表现。通过评估模型在未扰动和扰动设置下的性能和校准，我们发现模型对文本输入有明显的依赖性，即使存在互补的视觉信息也是如此。我们还进行了定性注意力分析，进一步证实图像内容经常被文本细节所掩盖。我们的发现强调了设计和评估真正整合视觉和文本线索的多模态医疗模型的重要性，而不是仅仅依赖于单一模态信号。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [563] [SDMatte: Grafting Diffusion Models for Interactive Matting](https://arxiv.org/abs/2508.00443)
> *SDMatte：嫁接扩散模型实现交互式抠图*

*Longfei Huang, Yu Liang, Hao Zhang, Jinwei Chen, Wei Dong, Lunde Chen, Wanyu Liu, Bo Li, Pengtao Jiang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 交互式抠图, 扩散模型, 视觉提示, 掩码自注意力, 图像抠图

**Comment:** Accepted at ICCV 2025, 11 pages, 4 figures

> **TL;DR:** SDMatte提出了一种基于扩散模型的交互式抠图方法，通过将文本驱动交互转化为视觉提示驱动，并引入坐标和不透明度嵌入及掩码自注意力机制，显著提升了边缘细节提取能力。

**AI_Comments:** SDMatte的创新之处在于其将强大的扩散模型引入交互式抠图领域，并巧妙地将其文本驱动能力转化为视觉提示驱动，使其更适用于图像编辑任务。通过集成坐标/不透明度嵌入和掩码自注意力机制，该模型能够更精准地处理边缘细节，克服了现有方法的局限性。这为未来基于扩散模型的图像编辑和计算机视觉任务提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 当前的交互式抠图方法在捕获物体主要区域时表现良好，但在提取边缘区域的精细细节方面表现不足。扩散模型在建模复杂数据分布和合成真实纹理细节方面具有卓越能力，并展现出强大的文本驱动交互能力，使其成为交互式抠图的理想解决方案。

**Method:** 我们提出了SDMatte，一个由扩散模型驱动的交互式抠图模型，主要有三个贡献：1. 利用扩散模型的强大先验知识，将文本驱动交互能力转换为视觉提示驱动交互能力。2. 将视觉提示的坐标嵌入和目标对象的不透明度嵌入集成到U-Net中，增强模型对空间位置和不透明度信息的敏感性。3. 提出了一种掩码自注意力机制，使模型能够专注于视觉提示指定的区域。

**Result:** 在多个数据集上的大量实验表明，我们的方法表现出卓越的性能，验证了其在交互式抠图中的有效性。

**Conclusion:** SDMatte通过结合扩散模型的强大能力和创新的架构设计，有效解决了传统交互式抠图在精细边缘细节提取上的不足，实现了卓越的交互式抠图性能。

> **ai_Abstract:** SDMatte是一种利用扩散模型进行交互式抠图的新方法，旨在解决现有方法在提取精细边缘细节方面的不足。它将扩散模型的文本驱动能力转化为视觉提示驱动，并通过在U-Net中整合坐标和不透明度嵌入，以及引入掩码自注意力机制来增强模型对空间信息和特定区域的关注。实验证明，SDMatte在多个数据集上表现出卓越的性能，有效提升了交互式抠图的质量。

> **摘要翻译:** 最近的交互式抠图方法在捕获物体主要区域方面表现出令人满意的性能，但在提取边缘区域的精细细节方面表现不足。在数十亿图像-文本对上训练的扩散模型，在建模高度复杂的数据分布和合成逼真纹理细节方面表现出卓越的能力，同时展现出强大的文本驱动交互能力，使其成为交互式抠图的一个有吸引力的解决方案。为此，我们提出了SDMatte，一个扩散驱动的交互式抠图模型，具有三个关键贡献。首先，我们利用扩散模型的强大先验知识，将文本驱动的交互能力转换为视觉提示驱动的交互能力，以实现交互式抠图。其次，我们将视觉提示的坐标嵌入和目标对象的不透明度嵌入集成到U-Net中，增强了SDMatte对空间位置信息和不透明度信息的敏感性。第三，我们提出了一种掩码自注意力机制，使模型能够专注于视觉提示指定的区域，从而获得更好的性能。在多个数据集上的大量实验表明，我们的方法表现出卓越的性能，验证了其在交互式抠图中的有效性。我们的代码和模型可在https://github.com/vivoCameraResearch/SDMatte获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [564] [Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR](https://arxiv.org/abs/2508.00744)
> *重新思考激光雷达轻量级3D目标检测的骨干网络设计*

*Adwait Chandorkar, Hasan Tercan, Tobias Meisen* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 3D目标检测, 轻量级骨干网络, 激光雷达, 点云, Dense Backbone

**Comment:** accepted at the Embedded Vision Workshop ICCV 2025

> **TL;DR:** 本文提出了一种名为Dense Backbone的轻量级骨干网络，专为激光雷达3D目标检测设计，能在显著降低计算成本的同时保持高检测性能。

**AI_Comments:** 本文提出了一种创新的轻量级骨干网络Dense Backbone，其主要创新点在于专为3D点云数据设计，并利用稠密层结构实现高效性能。其重要性在于有效降低了3D目标检测模型的计算成本和复杂度，推动了自动驾驶等领域轻量化部署的进程。即插即用的设计也大大提高了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的激光雷达3D目标检测方法大多依赖于VGG或ResNet等复杂骨干网络，导致模型复杂度高。尽管2D目标检测的轻量级骨干网络设计已得到充分探索，但3D目标检测领域的研究仍有限，需要更高效、轻量级的解决方案。

**Method:** 本文提出了一种名为Dense Backbone的轻量级骨干网络，它结合了高处理速度、轻量级架构和鲁棒的检测精度。该骨干网络基于稠密层（dense-layer），专为点云数据中的3D目标检测量身定制。它采用即插即用设计，可直接集成到现有架构中，无需修改其他网络组件。

**Result:** 将Dense Backbone应用于PillarNet等多个最先进的3D目标检测器后，这些模型在显著降低计算成本的同时，保留了大部分检测能力。例如，使用DensePillarNet（PillarNet的适应版本），在nuScenes测试集上，模型参数减少了29%，延迟降低了28%，而检测精度仅下降了2%。

**Conclusion:** Dense Backbone是一种有效且高效的轻量级骨干网络，能够显著降低激光雷达3D目标检测模型的计算成本和复杂度，同时保持接近最先进的检测性能，并具有良好的通用性和集成性。

> **ai_Abstract:** 本文提出了一种名为Dense Backbone的轻量级骨干网络，旨在解决激光雷达3D目标检测中现有模型复杂度高的问题。该骨干网络结合了快速处理速度、轻量级架构和高检测精度，并且是首个专门为点云3D目标检测设计的基于稠密层的骨干网络。实验证明，将其应用于PillarNet等现有检测器，如DensePillarNet，可以在显著减少参数和延迟的同时，仅带来微小的精度下降，且其即插即用设计便于集成。

> **摘要翻译:** 近年来，基于激光雷达的3D目标检测的进步显著加速了在现实世界环境中实现全自动驾驶的进程。尽管取得了高检测性能，但大多数方法仍然依赖于基于VGG或ResNet的骨干网络进行特征探索，这增加了模型复杂性。轻量级骨干网络设计在2D目标检测中得到了很好的探索，但3D目标检测方面的研究仍然有限。在这项工作中，我们引入了Dense Backbone，一个轻量级骨干网络，它结合了高处理速度、轻量级架构和鲁棒的检测精度。我们将多个最先进的3D目标检测器（如PillarNet）与我们的骨干网络进行了适配，并表明在我们的骨干网络下，这些模型在显著降低计算成本的同时保留了大部分检测能力。据我们所知，这是第一个专门为点云数据中的3D目标检测量身定制的基于稠密层（dense-layer）的骨干网络。DensePillarNet，我们对PillarNet的适配，在nuScenes测试集上实现了模型参数减少29%，延迟减少28%，而检测精度仅下降2%。此外，Dense Backbone的即插即用设计允许其直接集成到现有架构中，无需修改其他网络组件。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [578] [Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving](https://arxiv.org/abs/2508.00589)
> *自动驾驶中基于上下文的开放词汇运动检索*

*Stefan Englmeier, Max A. Büttner, Katharina Winter, Fabian B. Flohr* | **Category: cs.CV, cs.CL, cs.IR, cs.RO, 68T45, 68P20, 68T10, 68T50, 68T07, 68T40, I.2.10; I.4.8; I.2.9; H.3.3** | **Updated: 2025-08-01**

**Keywords:** 自动驾驶, 运动检索, 开放词汇, SMPL, WayMoCo

**Comment:** 9 pages, 10 figure, project page
  https://iv.ee.hm.edu/contextmotionclip/, submitted to IEEE Transactions on
  Intelligent Vehicles (T-IV), This work has been submitted to the IEEE for
  possible publication

> **TL;DR:** 提出一种新的基于上下文的运动检索框架，利用自然语言查询在大规模自动驾驶数据集中检索罕见的人类行为，并引入WayMoCo数据集，性能优于现有技术。

**AI_Comments:** 这篇论文通过引入结合SMPL运动序列和视频帧的多模态嵌入方法，并支持自然语言查询，为自动驾驶系统中的边缘案例检索提供了一个创新解决方案。其提出的WayMoCo数据集对于未来研究也具有重要意义，有助于推动以人为中心的自动驾驶系统评估和泛化能力。性能提升显著，显示了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶系统必须在涉及易受伤害道路使用者（VRU）异常行为的安全关键场景中可靠运行。识别驾驶数据集中的这些边缘案例对于鲁棒评估和泛化至关重要，但在大规模数据集的“长尾”中检索此类罕见人类行为场景具有挑战性。

**Method:** 提出一个新颖的上下文感知运动检索框架。该方法结合基于Skinned Multi-Person Linear (SMPL) 的运动序列和相应的视频帧，将其编码到与自然语言对齐的共享多模态嵌入空间中。引入了WayMoCo数据集，其中包含从生成的伪地面真值SMPL序列和相应的图像数据中派生出的自动标注的运动和场景上下文描述。

**Result:** 在WayMoCo数据集上评估时，该方法在运动-上下文检索方面的准确率比最先进的模型高出27.5%。

**Conclusion:** 该方法能够通过文本查询可扩展地检索人类行为及其上下文，并在针对自动驾驶系统的人本场景评估中表现出显著优势。

> **ai_Abstract:** 本文提出了一种新颖的上下文感知运动检索框架，旨在解决自动驾驶中在大规模数据集中检索罕见易受伤害道路使用者（VRU）行为的挑战。该方法将基于SMPL的运动序列和视频帧编码到与自然语言对齐的多模态嵌入空间，从而通过文本查询实现人类行为及其上下文的可扩展检索。此外，论文还引入了WayMoCo数据集，作为Waymo Open Dataset的扩展，包含自动标注的运动和场景上下文描述。在WayMoCo数据集上的评估显示，该方法在运动-上下文检索方面的准确率优于现有最先进模型达27.5%。

> **摘要翻译:** 自动驾驶系统必须在安全关键场景中可靠运行，特别是那些涉及易受伤害道路使用者（VRU）异常或复杂行为的场景。识别驾驶数据集中的这些边缘案例对于鲁棒评估和泛化至关重要，但在大规模数据集的“长尾”中检索此类罕见人类行为场景具有挑战性。为了支持对自动驾驶系统在多样化、以人为中心的场景的有针对性评估，我们提出了一种新颖的上下文感知运动检索框架。我们的方法结合了基于Skinned Multi-Person Linear (SMPL) 的运动序列和相应的视频帧，然后将它们编码到一个与自然语言对齐的共享多模态嵌入空间中。我们的方法能够通过文本查询实现人类行为及其上下文的可扩展检索。这项工作还介绍了我们的数据集WayMoCo，它是Waymo Open Dataset的扩展。它包含从生成的伪地面真值SMPL序列和相应的图像数据中派生出的自动标注的运动和场景上下文描述。当在WayMoCo数据集上评估时，我们的方法在运动-上下文检索方面的准确率比最先进的模型高出27.5%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [580] [Feather the Throttle: Revisiting Visual Token Pruning for Vision-Language Model Acceleration](https://arxiv.org/abs/2412.13180)
> *轻柔油门：重新审视视觉令牌剪枝以加速视觉-语言模型*

*Mark Endo, Xiaohan Wang, Serena Yeung-Levy* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 视觉令牌剪枝, 视觉-语言模型, 模型加速, 定位, FEATHER

**Comment:** ICCV 2025, project page:
  https://web.stanford.edu/~markendo/projects/feather

> **TL;DR:** 本文发现现有视觉令牌剪枝方法在视觉中心任务上存在将图像顶部令牌剪枝的缺陷，并提出了FEATHER方法，通过多阶段剪枝和早期均匀采样显著提升了视觉中心任务的性能。

**AI_Comments:** 这项工作揭示了现有视觉令牌剪枝方法在特定任务上的盲点，并指出了当前视觉-语言模型评估基准的局限性，具有重要的指导意义。FEATHER方法通过简单而有效的设计解决了剪枝偏见问题，为视觉-语言模型的加速提供了新的思路和更鲁棒的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉-语言模型加速方法（通过视觉令牌剪枝）在许多任务上表现良好，但在定位等视觉中心任务上表现出截然不同的行为，存在将图像顶部令牌剪枝的根本问题，且现有基准无法有效评估细粒度视觉能力。

**Method:** 提出了FEATHER (Fast and Effective Acceleration wiTH Ensemble cRiteria) 方法，通过多阶段剪枝和早期均匀采样来解决早期层剪枝问题，确保图像的广泛覆盖，并增强相关令牌的保留。

**Result:** FEATHER在视觉中心定位基准上实现了比原始加速方法超过5倍的性能提升，同时计算开销相当。研究还发现现有剪枝策略会将图像顶部的大部分令牌剪枝，但许多基准仍能保持良好性能，这暴露了基准评估细粒度视觉能力的局限性。

**Conclusion:** 现有的视觉令牌剪枝方法在视觉中心任务上存在严重缺陷，需要更精细的剪枝策略和更具挑战性的评估基准。FEATHER提供了一种有效的解决方案，显著提升了视觉中心任务的性能。

> **ai_Abstract:** 本文重新审视了视觉-语言模型中流行的视觉令牌早期剪枝加速方法，发现其在定位等视觉中心任务上存在将图像顶部令牌剪枝的严重缺陷，且现有基准未能有效揭示此问题。为解决此问题，作者提出了FEATHER方法，通过多阶段剪枝和早期均匀采样来更有效地保留相关令牌，实验表明FEATHER在视觉中心任务上实现了显著的性能提升。

> **摘要翻译:** 视觉-语言模型加速的最新工作在各种视觉-语言任务上取得了强大性能，尽管对视觉信息进行了高度压缩。在这项工作中，我们研究了语言模型内部早期剪枝视觉令牌的流行加速方法。令人惊讶的是，我们发现虽然在许多任务上保持了强大的性能，但对于定位等一系列以视觉为中心的任务，它表现出截然不同的行为。经过进一步调查，我们发现这种加速方法存在一个核心问题，即图像顶部的大部分令牌被剪枝掉。然而，在许多旨在评估以视觉为中心能力的基准上，尽管存在有缺陷的剪枝策略，但仍保持了强大的性能，这凸显了这些基准评估细粒度视觉能力的有限能力。基于这些发现，我们提出了FEATHER（Fast and Effective Acceleration wiTH Ensemble cRiteria），这是一种直接的方法，解决了发现的早期层剪枝问题，并通过早期均匀采样的多阶段剪枝进一步增强了相关令牌的保留，以确保广泛的图像覆盖。在计算节省相当的情况下，我们发现FEATHER在以视觉为中心的定位基准上比原始加速方法实现了超过5倍的性能提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [583] [AutoDebias: Automated Framework for Debiasing Text-to-Image Models](https://arxiv.org/abs/2508.00445)
> *AutoDebias：文本到图像模型去偏的自动化框架*

*Hongyi Cai, Mohammad Mahdinur Rahman, Mingkang Dong, Jie Li, Muxin Pu, Zhili Fang, Yinan Peng, Hanjun Luo, Yang Liu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 文本到图像模型, 偏见缓解, 自动化框架, 视觉-语言模型, CLIP引导训练

**Comment:** 

> **TL;DR:** AutoDebias是一个自动化框架，用于识别和减轻文本到图像模型中存在的社会偏见，即使是微妙或重叠的偏见。

**AI_Comments:** AutoDebias的创新之处在于其自动化识别和处理复杂、多重偏见的能力，无需事先了解偏见类型。它通过结合视觉-语言模型和CLIP引导训练，提供了一种通用的去偏方法，对提升T2I模型的公平性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像（T2I）模型尽管能生成高质量图像，但常表现出无意的社会偏见（如性别或种族刻板印象），即使文本提示中未提及这些属性。现有去偏方法对简单或已知情况有效，但难以处理微妙或重叠的偏见。

**Method:** AutoDebias通过利用视觉-语言模型来检测有偏见的视觉模式，并通过生成反映平衡表示的包容性替代提示来构建公平指南。这些指南驱动一个CLIP引导的训练过程，以促进更公平的输出，同时保留原始模型的图像质量和多样性。

**Result:** AutoDebias在涵盖超过25种偏见场景的基准上进行了评估，包括多重偏见同时出现的高难度情况。它以91.6%的准确率检测有害模式，并将有偏输出从90%降低到可忽略的水平，同时保留了原始模型的视觉保真度。

**Conclusion:** AutoDebias框架能有效解决文本到图像模型中存在的微妙刻板印象和多重交互偏见，显著减少偏见输出并保持图像质量。

> **ai_Abstract:** 本论文提出了AutoDebias，一个用于自动化识别和减轻文本到图像（T2I）模型中社会偏见的框架。该框架无需先验知识，通过视觉-语言模型检测偏见模式，并生成公平指南来驱动CLIP引导的训练过程，从而促进更公平的图像生成，同时保持图像质量和多样性。实验证明，AutoDebias能有效处理微妙和多重偏见，准确检测有害模式并显著减少偏见输出。

> **摘要翻译:** 文本到图像（T2I）模型能够从文本提示中生成高质量图像，但即使未提及特定属性，它们也经常表现出意外的社会偏见，例如性别或种族刻板印象。现有的去偏方法对于简单或众所周知的情况效果良好，但对于微妙或重叠的偏见则力不从心。我们提出了AutoDebias，一个自动化框架，无需事先了解特定偏见类型即可自动识别和减轻T2I模型中的有害偏见。具体而言，AutoDebias利用视觉-语言模型来检测有偏见的视觉模式，并通过生成反映平衡表示的包容性替代提示来构建公平指南。这些指南驱动一个CLIP引导的训练过程，以促进更公平的输出，同时保留原始模型的图像质量和多样性。与现有方法不同，AutoDebias有效解决了微妙的刻板印象和多重交互偏见。我们在涵盖超过25种偏见场景的基准上评估了该框架，包括多重偏见同时出现的高难度情况。AutoDebias以91.6%的准确率检测有害模式，并将有偏输出从90%降低到可忽略的水平，同时保留了原始模型的视觉保真度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [587] [Graph Lineages and Skeletal Graph Products](https://arxiv.org/abs/2508.00197)
> *图谱系与骨架图乘积*

*Eric Mjolsness, Cory B. Scott* | **Category: cs.CV, cs.LG, cs.NA, math.CT, math.NA** | **Updated: 2025-07-31**

**Keywords:** 图谱系, 骨架图乘积, 分级图, 分层模型, 代数类型理论

**Comment:** 42 pages. 33 Figures. Under review

> **TL;DR:** 该论文定义了分层增长的“图谱系”以及用于其上的“骨架图乘积”和单目运算符，形成了一套分层图模型的代数类型理论，并展示了其在深度神经网络和多重网格方法中的应用。

**AI_Comments:** 该论文引入了“图谱系”和“骨架图乘积”等创新概念，为构建分层和多尺度模型提供了一个新的代数框架，具有重要的理论和应用价值。其提出的代数类型理论为理解和设计复杂分层系统提供了严谨的数学工具，尤其在深度学习和数值计算领域展现出巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 图，以及不断增长的图序列，可用于指定许多领域（包括机器学习和计算科学）中数学模型的架构。

**Method:** 定义了结构化的图“谱系”，它们以分层方式增长，顶点和边的数量呈指数级增长；使用二分图连接连续的层级；利用延长映射定义层级间的距离度量；定义了“分级图”范畴，并在此基础上推导出标准代数图操作和类型构造器（笛卡尔积、盒积、不相交和、函数类型）的低成本“骨架”变体；还推导了空间高效的单目运算符：增厚（创建多尺度图谱系）和升级（创建搜索前沿图谱系）。

**Result:** 这些骨架二元运算符具有与标准对应物相似但不完全相同的代数和范畴论性质；图谱系及其骨架乘积构造器可以接近连续极限对象。最终形成了一套针对分级图和（分层）图谱系的代数类型理论。

**Conclusion:** 该方法有望非常适合定义分层模型架构（“分层架构”）及其上的局部采样、搜索或优化算法。已将此方法应用于深度神经网络（包括视觉和特征尺度空间）和多重网格数值方法。

> **ai_Abstract:** 本文提出了一种用于构建分层数学模型架构的新框架，核心在于定义了“图谱系”——一种按层级指数增长的图序列。在此基础上，引入了“分级图”的概念，并推导出一系列低成本的“骨架”代数图操作符（如乘积、和）和单目操作符（如增厚、升级），这些操作符在代数和范畴论性质上与标准操作符相似。最终，该研究建立了一套针对分级图和分层图谱系的代数类型理论。该方法特别适用于定义分层模型架构及其上的采样、搜索或优化算法，并已在深度神经网络和多重网格数值方法中得到应用。

> **摘要翻译:** 图，以及不断增长的图序列，可用于指定许多领域（包括机器学习和计算科学）中数学模型的架构。本文定义了结构化的图“谱系”（按层级编号排序），它们以分层方式增长，因此：(1) 图顶点和边的数量随层级编号呈指数级增长；(2) 二分图连接图谱系内的连续层级，并且像多重网格方法中一样，可以约束连续层级之间的矩阵；(3) 在图谱系内使用延长映射，可以定义连续层级之间过程导出的图间距离度量；(4) 可以定义“分级图”范畴，并利用它为分级图以及分层图谱系推导出标准代数图操作和类型构造器（笛卡特积、盒积、不相交和以及函数类型）的低成本“骨架”变体；(5) 这些骨架二元运算符与它们的标准对应物具有相似但不完全相同的代数和范畴论性质；(6) 图谱系及其骨架乘积构造器可以接近连续极限对象。还推导了分级图上的额外空间高效单目运算符：增厚（创建多尺度图谱系）和升级为搜索前沿图谱系（作为自适应网格的推广和定义“骨架”函数的有用工具）。结果是针对分级图和（分层）图谱系的代数类型理论。该方法有望非常适合定义分层模型架构——“分层架构”——及其上的局部采样、搜索或优化算法。我们展示了此类在深度神经网络（包括视觉和特征尺度空间）和多重网格数值方法中的应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [588] [FaceLift: Learning Generalizable Single Image 3D Face Reconstruction from Synthetic Heads](https://arxiv.org/abs/2412.17812)
> *FaceLift：从合成头部学习可泛化的单图像3D人脸重建*

*Weijie Lyu, Yi Zhou, Ming-Hsuan Yang, Zhixin Shu* | **Category: cs.CV, cs.GR** | **Updated: 2025-08-01**

**Keywords:** 3D人脸重建, 单图像重建, 高斯飞溅, 潜在扩散模型, 合成数据

**Comment:** ICCV 2025 Camera-Ready Version. Project Page:
  https://weijielyu.github.io/FaceLift

> **TL;DR:** FaceLift是一种新颖的单图像3D人脸重建方法，通过生成一致的多视图并使用合成数据训练，实现了对真实图像的卓越泛化，并超越了现有技术。

**AI_Comments:** FaceLift的创新之处在于其结合多视图潜在扩散模型与Transformer重建器来生成360度3D头部，以及通过创建高质量合成数据集并提出领域适应技术来解决传统方法在视图覆盖和泛化能力上的不足。其仅在合成数据上训练却能泛化到真实世界图像的能力，显示了其巨大的潜力，尤其是在数据获取困难的3D重建领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有的单目3D人脸重建方法通常由于多视图监督不足而缺乏完整的视角覆盖或视角一致性。

**Method:** FaceLift提出了一种前馈方法。它首先使用多视图潜在扩散模型从单一人脸输入生成一致的侧视图和背视图，然后将这些视图输入到基于Transformer的重建器中，生成全面的3D高斯飞溅表示。为解决多视图监督不足的问题，研究者创建了一个高质量的合成头部数据集。为了弥合合成训练数据与真实世界图像之间的领域差距，该方法提出了一种技术，通过在视图生成的同时学习重建输入图像来保持对输入的保真度。

**Result:** 尽管仅在合成数据上训练，FaceLift方法对真实世界图像表现出卓越的泛化能力。通过广泛的定性和定量评估，FaceLift在身份保留、细节恢复和渲染质量方面优于最先进的3D人脸重建方法。

**Conclusion:** FaceLift通过创新的多视图生成和合成数据训练策略，实现了从单张图像进行高质量、可泛化的360度3D头部重建，并显著超越了现有技术。

> **ai_Abstract:** FaceLift是一种新颖的前馈方法，用于从单张图像重建高质量、可泛化的360度3D头部。它通过多视图潜在扩散模型生成一致的侧视图和背视图，并使用基于Transformer的重建器生成3D高斯飞溅表示。该方法通过构建高质量合成数据集来解决传统方法缺乏多视图监督的问题，并提出了一种领域适应技术以确保对真实图像的泛化能力。实验证明，FaceLift在身份保留、细节恢复和渲染质量方面优于现有技术。

> **摘要翻译:** 我们提出了FaceLift，一种新颖的前馈方法，用于从单张图像进行可泛化的、高质量的360度3D头部重建。我们的管道首先采用多视图潜在扩散模型，从单一面部输入生成一致的侧视图和背视图，然后将其输入到基于Transformer的重建器中，生成全面的3D高斯飞溅表示。以前的单目3D人脸重建方法由于多视图监督不足，通常缺乏完整的视角覆盖或视角一致性。我们通过创建一个高质量的合成头部数据集来解决这个问题，该数据集能够实现跨视点的D一致性监督。为了弥合合成训练数据与真实世界图像之间的领域差距，我们提出了一种简单而有效的技术，通过在视图生成的同时学习重建输入图像，确保视图生成过程保持对输入的保真度。尽管仅在合成数据上训练，我们的方法对真实世界图像表现出卓越的泛化能力。通过广泛的定性和定量评估，我们表明FaceLift在身份保留、细节恢复和渲染质量方面优于最先进的3D人脸重建方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [589] [LLaVA-Video: Video Instruction Tuning With Synthetic Data](https://arxiv.org/abs/2410.02713)
> *LLaVA-Video：基于合成数据的视频指令微调*

*Yuanhan Zhang, Jinming Wu, Wei Li, Bo Li, Zejun Ma, Ziwei Liu, Chunyuan Li* | **Category: cs.CV, cs.CL** | **Updated: 2025-08-01**

**Keywords:** LLaVA-Video, 合成数据, 视频LMM, 指令微调, 多模态模型

**Comment:** Project page:
  https://llava-vl.github.io/blog/2024-09-30-llava-video/; Accepted at TMLR

> **TL;DR:** 为了解决视频大型多模态模型（LMMs）开发中高质量原始数据稀缺的问题，研究人员创建了一个名为LLaVA-Video-178K的高质量合成数据集，并用它训练了一个新的视频LMM——LLaVA-Video，该模型在各种视频基准测试中表现出色。

**AI_Comments:** 这项研究的创新之处在于通过生成高质量的合成数据来解决视频大型多模态模型训练中真实数据难以获取的挑战，为未来视频LMM的开发提供了一个有前景的方向。数据集及其生成管道的发布将极大地促进社区的研究。

<details>
  <summary>Details</summary>

**Motivation:** 视频大型多模态模型（LMMs）的发展受到从网络上获取大量高质量原始数据困难的阻碍。

**Method:** 研究人员提出了一种替代方法，即创建一个专门用于视频指令遵循的高质量合成数据集，命名为LLaVA-Video-178K。该数据集包含详细字幕、开放式问答（QA）和多项选择QA等关键任务。通过结合现有视觉指令微调数据，使用该数据集进行训练，引入了新的视频LMM——LLaVA-Video。

**Result:** LLaVA-Video在各种视频基准测试中取得了强大的性能，突出了所提出数据集的有效性。

**Conclusion:** 合成数据能够有效解决视频大型多模态模型开发中的数据稀缺问题，并能训练出性能强大的模型。研究人员计划发布数据集、其生成管道和模型检查点。

> **ai_Abstract:** 为了克服视频大型多模态模型（LMMs）开发中的数据稀缺问题，本文提出并创建了一个名为LLaVA-Video-178K的高质量合成数据集，专门用于视频指令遵循，涵盖了详细字幕、开放式问答和多项选择问答等任务。通过将该合成数据集与现有视觉指令微调数据结合训练，研究人员引入了新的视频LMM——LLaVA-Video。实验结果表明，LLaVA-Video在多个视频基准测试中表现出色，验证了合成数据在促进视频LMM发展方面的有效性。

> **摘要翻译:** 视频大型多模态模型（LMMs）的开发一直受到从网络上获取大量高质量原始数据困难的阻碍。为了解决这个问题，我们提出了一种替代方法，即创建一个专门用于视频指令遵循的高质量合成数据集，命名为LLaVA-Video-178K。该数据集包括详细字幕、开放式问答（QA）和多项选择QA等关键任务。通过结合现有视觉指令微调数据，使用该数据集进行训练，我们引入了新的视频LMM——LLaVA-Video。我们的实验表明，LLaVA-Video在各种视频基准测试中取得了强大的性能，突出了我们数据集的有效性。我们计划发布数据集、其生成管道和模型检查点。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [595] [GECO: Geometrically Consistent Embedding with Lightspeed Inference](https://arxiv.org/abs/2508.00746)
> *GECO：具有光速推理的几何一致嵌入*

*Regine Hartwig, Dominik Muhle, Riccardo Marin, Daniel Cremers* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 几何一致嵌入, 最优传输, 自监督学习, 3D几何, 特征学习

**Comment:** 

> **TL;DR:** GECO是一种新的模型，通过基于最优传输的训练框架生成几何一致的特征，解决了现有自监督视觉模型缺乏3D几何感知的问题，实现了SOTA性能和超快推理速度，并提出了新的几何感知度量。

**AI_Comments:** GECO的创新之处在于其通过最优传输方法实现几何一致特征学习，有效弥补了现有自监督模型在3D几何感知上的不足。其轻量级架构和显著的速度提升（98.2%更快）使其在实际应用中极具潜力。此外，作者提出的对PCK局限性的分析以及新度量的引入，对未来几何感知特征学习的评估提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自监督视觉基础模型虽然能捕捉语义对应关系，但通常缺乏对底层3D几何的感知，导致无法根据几何特征（如左右眼、前后腿）区分部件。

**Method:** GECO提出一个基于最优传输的训练框架，允许在超越关键点的情况下进行监督，即使在遮挡和非遮挡情况下也能进行。它采用轻量级架构来确保推理速度。

**Result:** GECO在30 fps运行，比现有方法快98.2%。它在PFPascal、APK和CUB数据集上达到了最先进的性能，PCK分别提高了6.0%、6.2%和4.1%。研究还表明PCK不足以捕捉几何质量，并引入了新的度量和见解。

**Conclusion:** GECO通过生成几何一致的特征，弥补了现有自监督视觉模型在3D几何感知方面的不足，并在性能和速度上实现了显著提升。此外，它还提出了对几何感知特征学习更全面的评估方法。

> **ai_Abstract:** GECO提出了一种新的自监督视觉模型，通过基于最优传输的训练框架生成几何一致的特征，有效解决了现有模型缺乏3D几何感知的问题。该模型能够根据几何特性区分语义部件，且具有轻量级架构，推理速度极快，性能超越现有方法。此外，GECO还引入了新的评估指标，以更全面地衡量几何感知特征学习的质量。

> **摘要翻译:** GECO：具有光速推理的几何一致嵌入

最近特征学习的进展表明，自监督视觉基础模型可以捕捉语义对应关系，但通常缺乏对底层3D几何的感知。GECO通过生成几何连贯的特征来解决这一差距，这些特征基于几何（例如，左/右眼，前/后腿）在语义上区分部件。我们提出了一种基于最优传输的训练框架，即使在遮挡和非遮挡情况下，也能实现超越关键点的监督。凭借轻量级架构，GECO以30 fps运行，比现有方法快98.2%，同时在PFPascal、APK和CUB上实现了最先进的性能，分别将PCK提高了6.0%、6.2%和4.1%。最后，我们表明单独的PCK不足以捕捉几何质量，并引入了新的度量和见解，以实现更具几何感知能力的特征学习。项目页面链接：https://reginehartwig.github.io/publications/geco/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [600] [Enhanced Vision-Language Models for Diverse Sensor Understanding: Cost-Efficient Optimization and Benchmarking](https://arxiv.org/abs/2412.20750)
> *增强型视觉-语言模型用于多样化传感器理解：成本效益优化与基准测试*

*Sangyun Chung, Youngjoon Yu, Se Yeon Kim, Youngchae Chee, Yong Man Ro* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 视觉-语言模型, 传感器理解, 非RGB图像, 成本高效优化, 基准测试

**Comment:** 

> **TL;DR:** 本文提出了一种成本高效的新范式SAFT（结合DNA优化）来增强视觉-语言模型对非RGB传感器图像的理解，解决了现有模型的RGB中心偏见，并引入了首个综合性公共基准VS-TDX。实验证明该方法在资源受限和架构不变的情况下表现出卓越的性能和泛化能力。

**AI_Comments:** 本文的创新点在于提出了一种成本高效且架构无关的方法（SAFT与DNA优化），解决了现有VLM对非RGB传感器数据理解不足的问题，这对于VLM在真实世界多模态环境中的应用具有重要意义。同时，引入了首个专门针对传感器理解的综合性基准VS-TDX，填补了该领域的空白，将有助于推动未来研究。其方法不依赖大量数据和模型修改，极大地降低了部署门槛，具有很强的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（VLMs）在对齐视觉输入与文本方面取得了显著进展，但它们深入理解非RGB视觉传感器图像独特物理特性的能力有限，存在固有的RGB中心偏见。

**Method:** 本文引入了一种成本高效的新范式，无需大量训练数据或修改现有VLM架构。具体地，提出了传感器感知属性微调（SAFT）与多样化负属性（DNA）优化，利用最少的传感器特定数据来实现对非RGB特性的鲁健学习。此外，还提出了VS-TDX，这是首个旨在严格评估VLM在多样化和现实场景中传感器特定理解能力的综合性公共基准。

**Result:** 通过对VLMs和各种传感器模态进行大量实验，验证了所提出的方法在资源受限和架构不变的设置下，始终能提供卓越的性能和泛化能力。

**Conclusion:** 本文提出的方法为VLMs在日益传感器多样化的真实世界环境中实现可扩展部署提供了实际的进步。

> **ai_Abstract:** 本文针对大型视觉-语言模型（VLMs）在理解非RGB传感器图像方面的局限性，提出了一种成本高效的新范式。该范式包含传感器感知属性微调（SAFT）和多样化负属性（DNA）优化，旨在利用少量传感器特定数据，无需修改现有VLM架构，即可克服VLMs固有的RGB中心偏见，增强其对非RGB特性的理解。同时，本文还推出了首个用于全面评估VLM传感器理解能力的公共基准VS-TDX。实验结果表明，该方法在资源受限和架构不变的条件下，能持续提供优异的性能和泛化能力，为VLMs在多样化传感器环境中的实际部署提供了有效途径。

> **摘要翻译:** 大型视觉-语言模型（VLMs）在将视觉输入与文本对齐方面取得了显著进展。然而，它们深入理解非RGB视觉传感器图像独特物理特性的能力仍然有限。在本文中，我们重新审视并分析了这些局限性，并引入了一种新颖、成本高效的范式，显著提升了传感器图像理解能力——无需大量训练数据或对现有VLM架构进行任何修改。具体来说，我们提出了传感器感知属性微调（SAFT）与多样化负属性（DNA）优化，该方法利用最少的传感器特定数据来实现对非RGB特性的鲁棒学习，并克服了当前VLM中固有的RGB中心偏见。此外，我们还提出了VS-TDX——首个旨在严格评估VLM在多样化和现实场景中传感器特定理解能力的综合性公共基准。通过对VLMs和各种传感器模态进行大量实验，我们验证了我们的方法在资源受限和架构不变的设置下始终能提供卓越的性能和泛化能力。我们的方法为VLMs在日益传感器多样化的真实世界环境中实现可扩展部署提供了实际的进步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [603] [CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text](https://arxiv.org/abs/2508.00447)
> *CLIPTime：图像和文本的时间感知多模态表示学习*

*Anju Rani, Daniel Ortiz-Arroyo, Petar Durdevic* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 时间感知, 多模态学习, 视觉-语言模型, 生物生长, CLIP

**Comment:** 11 pages, 8 figures

> **TL;DR:** CLIPTime是一个基于CLIP的多任务框架，通过图像和文本预测生物生长的时间和发育阶段，无需显式时间输入，并在真菌生长数据集上表现良好。

**AI_Comments:** CLIPTime通过将时间维度整合到视觉-语言模型中，解决了现有CLIP模型在捕捉时间进程方面的局限性，具有创新性。其多任务学习（分类和回归）以及无需显式时间输入的特点，使其在生物监测等需要时间感知推理的实际应用中具有重要潜力。引入合成数据集和自定义评估指标也为该领域的研究提供了有益的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 理解生物生长的时序动态在微生物学、农业和生物降解研究等领域至关重要。现有的视觉-语言模型（如CLIP）在捕捉时间进程方面能力有限。

**Method:** 提出CLIPTime，一个多模态、多任务框架，基于CLIP架构，用于从图像和文本输入中预测真菌生长的发育阶段和相应时间戳。它学习联合视觉-文本嵌入，实现时间感知推理，无需测试时显式时间输入。引入合成真菌生长数据集进行训练和评估。CLIPTime同时执行分类（离散生长阶段）和回归（连续时间戳）。提出自定义评估指标，包括时间准确性和回归误差。

**Result:** 实验结果表明，CLIPTime有效地建模了生物进程，并产生了可解释的、时间上接地的输出。

**Conclusion:** CLIPTime展示了视觉-语言模型在真实世界生物监测应用中的潜力。

> **ai_Abstract:** CLIPTime是一个创新的多模态、多任务框架，扩展了现有的视觉-语言模型（如CLIP），使其能够从图像和文本中学习并预测生物生长的时序动态，包括发育阶段和时间戳。该模型无需显式时间输入即可进行时间感知推理，并通过引入合成真菌生长数据集和定制评估指标进行训练和验证。实验证明其在生物进程建模和实际应用中的有效性。

> **摘要翻译:** 理解生物生长的时序动态在微生物学、农业和生物降解研究等不同领域至关重要。尽管对比语言图像预训练（CLIP）等视觉-语言模型在联合视觉-文本推理方面表现出强大能力，但它们在捕捉时间进程方面的有效性仍然有限。为解决这一问题，我们提出了CLIPTime，一个多模态、多任务框架，旨在从图像和文本输入中预测真菌发育阶段和相应的时间戳。我们的模型基于CLIP架构，学习联合视觉-文本嵌入，并能够在测试时无需显式时间输入的情况下进行时间感知推理。为了方便训练和评估，我们引入了一个带有对齐时间戳和分类阶段标签的合成真菌生长数据集。CLIPTime同时执行分类和回归，预测离散的生长阶段和连续的时间戳。我们还提出了自定义评估指标，包括时间准确性和回归误差，以评估时间感知预测的精度。实验结果表明，CLIPTime有效地建模了生物进程并产生了可解释的、时间上接地的输出，突出了视觉-语言模型在真实世界生物监测应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [611] [Learning Personalised Human Internal Cognition from External Expressive Behaviours for Real Personality Recognition](https://arxiv.org/abs/2508.00205)
> *从外部表达行为中学习个性化人类内部认知以实现真实人格识别*

*Xiangyu Kong, Hengde Zhu, Haoqin Sun, Zhihao Guo, Jiayan Gu, Xinyi Ni, Wei Zhang, Shizhe Liu, Siyang Song* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 真实人格识别, 内部认知, 表达行为, 图神经网络, 2D-GNN

**Comment:** 10 pages, 4 figures

> **TL;DR:** 本文提出一种新颖的真实人格识别（RPR）方法，通过模拟个性化内部认知并利用2D图神经网络进行识别，旨在克服现有方法对真实人格的偏差和性能不足。

**AI_Comments:** 该论文的创新点在于提出了从外部行为反推内部认知来识别真实人格的新颖视角，这与传统方法直接从外部行为推断人格印象不同。引入2D图神经网络处理模拟认知表示也值得关注。这种方法有望提高真实人格识别的准确性，但其复杂性和所需数据的鲁棒性可能需要进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有的人格识别方案作为外部观察者，根据目标个体的表达行为推断观察者的人格印象，这与真实人格存在显著偏差，并持续导致较差的识别性能。

**Method:** 提出一种新颖的RPR方法，该方法从易于获取的外部短视听行为中模拟个性化内部认知。模拟认知被编码为包含二维节点和边特征矩阵的新型图，并利用新提出的2D图神经网络（2D-GNN）从中推断真实人格特质。设计了一个端到端策略，联合训练认知模拟、2D图构建和人格识别模块。

**Result:** Not mentioned in abstract

**Conclusion:** 本文提出了一种新颖的真实人格识别方法，通过从外部表达行为中模拟个性化内部认知，并结合2D图神经网络，有望克服现有方法的局限性，提高真实人格识别的准确性。

> **ai_Abstract:** 本文提出一种新颖的自动真实人格识别（RPR）方法，旨在解决现有方法因仅依赖外部观察而导致的人格识别偏差和性能不佳问题。该方法受内部认知与表达行为关联的启发，通过从外部视听行为中模拟个性化内部认知，并将其编码为二维图。随后，利用专门设计的2D图神经网络（2D-GNN）从该图中推断真实人格特质。整个过程采用端到端训练策略，整合了认知模拟、图构建和人格识别模块。

> **摘要翻译:** 自动真实人格识别（RPR）旨在从人类的表达行为中评估其真实人格特质。然而，大多数现有解决方案通常作为外部观察者，根据目标个体的表达行为推断观察者的人格印象，这与他们真实的人格显著偏离，并持续导致较差的识别性能。受真实人格与生成表达行为背后的人类内部认知之间关联的启发，我们提出了一种新颖的RPR方法，该方法能从目标个体表达的易于获取的外部短视听行为中有效模拟个性化内部认知。模拟的个性化认知被表示为一组网络权重，这些权重强制个性化网络重现个体特定的面部反应，并进一步编码为一个包含二维节点和边特征矩阵的新型图，同时提出了一种新型的2D图神经网络（2D-GNN）来从中推断真实人格特质。为了模拟与真实人格相关的认知，设计了一种端到端策略来联合训练我们的认知模拟、2D图构建和人格识别模块。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [622] [PIF-Net: Ill-Posed Prior Guided Multispectral and Hyperspectral Image Fusion via Invertible Mamba and Fusion-Aware LoRA](https://arxiv.org/abs/2508.00453)
> *PIF-Net: 基于不适定先验引导、可逆Mamba和融合感知LoRA的多光谱与高光谱图像融合*

*Baisong Li, Xingwang Wang, Haixiao Xu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 多光谱高光谱图像融合, 不适定先验, 可逆Mamba, 融合感知LoRA, PIF-Net

**Comment:** 

> **TL;DR:** PIF-Net通过引入不适定先验、可逆Mamba架构和融合感知LoRA模块，有效解决了多光谱与高光谱图像融合中的不适定性问题，并取得了SOTA性能。

**AI_Comments:** 该论文的创新点在于明确引入不适定先验来解决多光谱与高光谱图像融合中的核心挑战，并结合了最新的Mamba架构以及为融合任务定制的LoRA模块。可逆Mamba的设计在保持信息流稳定性和可逆性方面具有重要意义，而融合感知LoRA则有效平衡了性能与模型复杂度。这项工作为高光谱图像融合领域提供了新的视角和高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 多光谱与高光谱图像融合（MHIF）旨在生成兼具丰富光谱信息和精细空间细节的高质量图像。然而，由于光谱和空间信息固有的权衡以及观测数据的有限性，这项任务本质上是不适定的。以往的研究未能有效解决由数据错位引起的不适定性问题。

**Method:** 本研究提出了一个名为PIF-Net的融合框架，该框架明确地结合了不适定先验来有效融合多光谱和高光谱图像。为了平衡全局光谱建模与计算效率，设计了一种基于可逆Mamba架构的方法，该方法在特征变换和融合过程中保持信息一致性，确保稳定的梯度流和过程可逆性。此外，引入了一个名为“融合感知低秩适应模块”（Fusion-Aware Low-Rank Adaptation module），该模块动态校准光谱和空间特征，同时保持模型轻量级。

**Result:** 在多个基准数据集上进行的广泛实验表明，PIF-Net在图像恢复性能方面显著优于当前最先进的方法，同时保持了模型效率。

**Conclusion:** PIF-Net通过有效解决MHIF任务中的不适定性问题，并结合创新的可逆Mamba和融合感知LoRA模块，实现了卓越的图像融合性能和模型效率。

> **ai_Abstract:** PIF-Net是一种新颖的多光谱与高光谱图像融合框架，旨在解决该任务中固有的不适定性问题。它通过引入不适定先验来指导融合过程，并利用可逆Mamba架构实现高效且信息一致的特征转换。此外，融合感知LoRA模块被设计用于动态校准特征并保持模型轻量级。实验证明，PIF-Net在性能和效率上均超越了现有SOTA方法。

> **摘要翻译:** 多光谱与高光谱图像融合（MHIF）的目标是生成同时拥有丰富光谱信息和精细空间细节的高质量图像。然而，由于光谱和空间信息固有的权衡以及观测数据的有限性，这项任务本质上是不适定的。以往的研究未能有效解决由数据错位引起的不适定性问题。为了应对这一挑战，我们提出了一个名为PIF-Net的融合框架，该框架明确地结合了不适定先验来有效融合多光谱和高光谱图像。为了平衡全局光谱建模与计算效率，我们设计了一种基于可逆Mamba架构的方法，该方法在特征变换和融合过程中保持信息一致性，确保稳定的梯度流和过程可逆性。此外，我们引入了一个名为“融合感知低秩适应模块”（Fusion-Aware Low-Rank Adaptation module），该模块动态校准光谱和空间特征，同时保持模型轻量级。在多个基准数据集上进行的广泛实验表明，PIF-Net在图像恢复性能方面显著优于当前最先进的方法，同时保持了模型效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [624] [SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation](https://arxiv.org/abs/2508.00750)
> *SU-ESRGAN：语义和不确定性感知ESRGAN，用于卫星和无人机图像的超分辨率，并进行交叉域评估的微调*

*Prerana Ramkumar* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 超分辨率, ESRGAN, 语义分割, 不确定性估计, 遥感图像

**Comment:** 

> **TL;DR:** SU-ESRGAN是一种新的超分辨率框架，结合了ESRGAN、语义分割和不确定性估计，用于遥感图像，并在跨域评估中表现良好，强调了领域感知训练的重要性。

**AI_Comments:** SU-ESRGAN的创新之处在于将语义分割和不确定性估计引入超分辨率GAN，这显著提高了模型在关键遥感应用中的可信度和实用性。其模块化设计和对跨域适应性的探索也增加了其实用价值。该研究强调了领域感知训练的重要性，为未来遥感图像处理提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有GAN在图像超分辨率方面表现良好，但缺乏语义一致性和像素级置信度，这限制了它们在灾害响应、城市规划和农业等关键遥感应用中的可信度。

**Method:** 本文提出了SU-ESRGAN，这是第一个为卫星图像设计的SR框架。它整合了ESRGAN、通过DeepLabv3的分割损失（用于保留类别细节）以及蒙特卡洛Dropout（用于生成像素级不确定性图）。该模型还进行了微调，以评估其在交叉域应用中的性能，并在两个不同的无人机数据集上进行了测试。

**Result:** SU-ESRGAN在航空图像上的结果（PSNR、SSIM、LPIPS）与基线ESRGAN相当。对微调模型进行性能评估显示，其对航空海事无人机数据集的适应性更强，该数据集的成像特性与训练数据一致。

**Conclusion:** 研究结果强调了在超分辨率应用中领域感知训练的重要性。

> **ai_Abstract:** 本文提出了SU-ESRGAN，一个针对卫星和无人机图像的超分辨率框架，旨在解决现有GAN在遥感领域缺乏语义一致性和置信度的问题。SU-ESRGAN结合了ESRGAN、DeepLabv3的语义分割损失和蒙特卡洛Dropout以提供像素级不确定性。该模型在性能上与基线ESRGAN相当，并通过跨域微调实验，证明了领域感知训练在提升模型适应性方面的重要性，尤其适用于宽视场相机获取的图像。

> **摘要翻译:** 生成对抗网络（GANs）在图像超分辨率（SR）方面取得了逼真的效果，但它们缺乏语义一致性和像素级置信度，这限制了它们在灾害响应、城市规划和农业等关键遥感应用中的可信度。本文介绍了语义和不确定性感知ESRGAN（SU-ESRGAN），这是第一个为卫星图像设计的SR框架，它整合了ESRGAN、通过DeepLabv3的分割损失（用于保留类别细节）和蒙特卡洛Dropout以生成像素级不确定性图。SU-ESRGAN在航空图像上产生的结果（PSNR、SSIM、LPIPS）与基线ESRGAN相当。这种新颖的模型对于使用宽视场（FoV）摄像头的卫星系统或无人机很有价值，它们牺牲空间分辨率以换取覆盖范围。其模块化设计允许集成到无人机数据管道中，用于机载或后处理SR，以增强因运动模糊、压缩和传感器限制导致的图像。此外，该模型还进行了微调，以评估其在交叉域应用中的性能。测试在两个基于无人机的数据集上进行，这些数据集在高度和成像视角上有所不同。微调模型的性能评估显示，其对航空海事无人机数据集的适应性更强，该数据集的成像特性与训练数据一致，突出了SR应用中领域感知训练的重要性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [625] [GameFactory: Creating New Games with Generative Interactive Videos](https://arxiv.org/abs/2501.08325)
> *GameFactory：使用生成式交互视频创建新游戏*

*Jiwen Yu, Yiran Qin, Xintao Wang, Pengfei Wan, Di Zhang, Xihui Liu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 游戏生成, 生成式视频, 动作控制, 场景泛化, 视频扩散模型

**Comment:** ICCV 2025 Highlight, Project Page:
  https://yujiwen.github.io/gamefactory

> **TL;DR:** GameFactory 是一个用于动作控制和场景泛化的游戏视频生成框架，它通过引入无偏数据集、动作控制模块和解耦训练策略，实现了开放域可控的游戏视频生成，有望彻底改变游戏开发。

**AI_Comments:** GameFactory的创新之处在于其对“场景泛化动作控制”的解决，这在现有方法中是一个重大挑战。通过解耦游戏风格学习和动作控制，该框架能够生成多样化且开放域的游戏内容，极大地扩展了生成式AI在游戏开发中的应用潜力。GF-Minecraft数据集的引入也为后续研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 生成式视频有潜力通过自主创建新内容来彻底改变游戏开发。当前方法未能解决场景泛化动作控制的挑战。

**Method:** 本文提出了GameFactory框架，用于动作控制和场景泛化的游戏视频生成。首先，通过引入无人类偏见的动作标注游戏视频数据集GF-Minecraft，并开发一个能够精确控制键盘和鼠标输入的动作控制模块，解决了动作可控性挑战。其次，支持自回归生成无限长交互视频。更重要的是，GameFactory通过利用预训练视频扩散模型的开放域生成先验，并提出一种包含域适配器的多阶段训练策略，将游戏风格学习与动作控制解耦，从而解决了场景泛化的动作控制挑战。

**Result:** 实验结果表明，GameFactory能够有效地生成开放域动作可控的游戏视频。

**Conclusion:** GameFactory在AI驱动的游戏生成方面迈出了重要一步，它能够生成开放域动作可控的场景泛化游戏视频。

> **ai_Abstract:** GameFactory是一个用于生成动作控制和场景泛化游戏视频的框架。它通过构建一个无偏见的动作标注数据集GF-Minecraft和开发一个精确的动作控制模块来解决动作可控性问题。为了实现场景泛化，它利用预训练的视频扩散模型，并提出了一种多阶段训练策略和域适配器，将游戏风格学习与动作控制解耦。这使得GameFactory能够生成开放域、动作可控且不受特定游戏风格限制的游戏视频，推动了AI驱动的游戏生成。

> **摘要翻译:** 生成式视频有潜力通过自主创建新内容来彻底改变游戏开发。在本文中，我们提出了GameFactory，一个用于动作控制和场景泛化的游戏视频生成框架。我们首先通过引入GF-Minecraft（一个无人类偏见的动作标注游戏视频数据集）并开发一个能够精确控制键盘和鼠标输入的动作控制模块，解决了动作可控性的根本挑战。我们进一步扩展以支持无限长交互视频的自回归生成。更重要的是，GameFactory解决了现有大多数方法未能解决的场景泛化动作控制的关键挑战。为了能够创建超越固定风格和场景的全新且多样化的游戏，我们利用了预训练视频扩散模型的开放域生成先验。为了弥合开放域先验和小型游戏数据集之间的领域差距，我们提出了一种多阶段训练策略，其中包含一个域适配器，将游戏风格学习与动作控制解耦。这种解耦确保了动作控制学习不再受特定游戏风格的束缚，从而实现了场景泛化的动作控制。实验结果表明，GameFactory有效地生成了开放域动作可控的游戏视频，代表着AI驱动游戏生成方面的一个重大进步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [639] [SAM-PTx: Text-Guided Fine-Tuning of SAM with Parameter-Efficient, Parallel-Text Adapters](https://arxiv.org/abs/2508.00213)
> *SAM-PTx：文本引导的SAM微调与参数高效并行文本适配器*

*Shayan Jalilian, Abdul Bais* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** SAM, 文本引导分割, 参数高效, 适配器, 语义提示

**Comment:** 

> **TL;DR:** 本文提出SAM-PTx，一种参数高效的方法，通过并行文本适配器将CLIP文本嵌入集成到SAM中，以实现文本引导的语义分割，并在多个数据集上显示出优于纯空间提示基线的性能。

**AI_Comments:** 本文的创新点在于首次将文本提示引入到SAM的微调中，并通过参数高效的Parallel-Text适配器实现了这一目标，特别是其仅修改MLP分支的设计，在保持空间推理能力的同时，注入了语义信息。这项工作为SAM的语义理解和更灵活的交互方式提供了新的方向，且具有较低的计算成本，具有重要实践意义。

<details>
  <summary>Details</summary>

**Motivation:** Segment Anything Model (SAM) 在提示式分割中表现出强大的泛化能力，但相较于点和框等传统空间提示，语义文本提示的潜力尚未得到充分探索。

**Method:** 本文提出了SAM-PTx，一种参数高效的SAM适应方法。它引入了一个名为Parallel-Text的轻量级适配器设计，将冻结的CLIP派生文本嵌入作为类别级语义指导注入到SAM的图像编码器中。该适配器仅修改每个Transformer块的MLP并行分支，同时保持原始架构大部分冻结，并保留注意力路径用于空间推理。

**Result:** 在COD10K数据集以及COCO和ADE20K的低数据子集上进行的监督实验和消融研究表明，将固定文本嵌入作为输入可以提高分割性能，优于纯空间提示基线。

**Conclusion:** 将语义条件集成到SAM的架构中，为高效适应提供了一条实用且可扩展的路径，且计算复杂度最低。

> **ai_Abstract:** 本文提出了SAM-PTx，一种针对Segment Anything Model (SAM) 的参数高效微调方法，旨在充分利用语义文本提示的潜力。通过引入名为Parallel-Text的轻量级适配器，该方法将冻结的CLIP文本嵌入注入到SAM的图像编码器中，以实现文本引导的语义分割。实验证明，SAM-PTx在多个数据集上显著提升了分割性能，并为SAM的语义条件适应提供了一条高效且可扩展的途径。

> **摘要翻译:** 分割一切模型 (SAM) 在基于提示的分割中展现出令人印象深刻的泛化能力。然而，与点和框等传统空间提示相比，语义文本提示的潜力仍未得到充分探索。本文介绍了 SAM-PTx，这是一种参数高效的方法，通过使用冻结的 CLIP 派生文本嵌入作为类别级语义指导来适应 SAM。具体而言，我们提出了一种名为 Parallel-Text 的轻量级适配器设计，它将文本嵌入注入到 SAM 的图像编码器中，从而实现语义引导的分割，同时保持原始架构的大部分冻结。我们的适配器仅修改每个 Transformer 块的 MLP 并行分支，保留注意力路径用于空间推理。通过在 COD10K 数据集以及 COCO 和 ADE20K 的低数据子集上进行的监督实验和消融研究，我们表明，将固定文本嵌入作为输入可以提高分割性能，优于纯空间提示基线。据我们所知，这是首次在 COD10K 数据集上使用文本提示进行分割的工作。这些结果表明，将语义条件集成到 SAM 的架构中，为高效适应提供了一条实用且可扩展的路径，且计算复杂度最低。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [646] [Semantic and Temporal Integration in Latent Diffusion Space for High-Fidelity Video Super-Resolution](https://arxiv.org/abs/2508.00471)
> *潜在扩散空间中的语义和时间整合用于高保真视频超分辨率*

*Yiwen Wang, Xinning Chai, Yuhong Zhang, Zhengxue Cheng, Jun Zhao, Rong Xie, Li Song* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 视频超分辨率, 潜在扩散空间, 语义引导, 时间一致性, 高保真

**Comment:** 

> **TL;DR:** 本文提出SeTe-VSR，一种在潜在扩散空间中结合语义和时空引导的新方法，用于解决视频超分辨率中高保真对齐和时间一致性的挑战，并在细节恢复和感知质量方面优于现有方法。

**AI_Comments:** 该论文的创新之处在于其将语义和时空引导整合到潜在扩散空间中，以解决视频超分辨率领域长期存在的高保真度和时间一致性问题。这种方法为生成高质量VSR结果提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前视频超分辨率（VSR）模型在增强低分辨率视频方面表现出色，但由于生成过程控制不足，在实现与低分辨率输入的高保真对齐并保持帧间时间一致性方面仍面临重大挑战。

**Method:** 本文提出语义和时间引导视频超分辨率（SeTe-VSR），这是一种在潜在扩散空间中整合语义和时空引导的新方法。通过结合高级语义信息并整合空间和时间信息，该方法旨在实现恢复复杂细节和确保时间连贯性之间的无缝平衡。

**Result:** 广泛的实验表明，SeTe-VSR在细节恢复和感知质量方面优于现有方法。

**Conclusion:** SeTe-VSR在复杂视频超分辨率任务中表现出其有效性，能够平衡细节恢复和时间连贯性，并显著增强保真度。

> **ai_Abstract:** SeTe-VSR是一种新颖的视频超分辨率方法，通过在潜在扩散空间中整合语义和时空引导，解决了现有VSR模型在高保真对齐和时间一致性方面的挑战。该方法有效地平衡了细节恢复和时间连贯性，并在实验中表现出优于现有方法的细节恢复和感知质量。

> **摘要翻译:** 视频超分辨率（VSR）模型的最新进展在增强低分辨率视频方面取得了令人印象深刻的成果。然而，由于对生成过程控制不足的限制，在保持帧间时间一致性的同时实现与低分辨率输入的高保真对齐仍然是一个重大挑战。在这项工作中，我们提出了语义和时间引导视频超分辨率（SeTe-VSR），这是一种在潜在扩散空间中结合语义和时空引导的新方法，以解决这些挑战。通过结合高级语义信息并整合空间和时间信息，我们的方法在恢复复杂细节和确保时间连贯性之间实现了无缝平衡。我们的方法不仅保留了高现实视觉内容，而且显著增强了保真度。广泛的实验表明，SeTe-VSR在细节恢复和感知质量方面优于现有方法，突显了其在复杂视频超分辨率任务中的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [647] [Multi-Cali Anything: Dense Feature Multi-Frame Structure-from-Motion for Large-Scale Camera Array Calibration](https://arxiv.org/abs/2503.00737)
> *Multi-Cali Anything：用于大规模相机阵列标定的密集特征多帧运动恢复结构*

*Jinjiang You, Hewei Wang, Yijie Li, Mingxiao Huo, Long Van Tran Ha, Mingyuan Ma, Jinfeng Xu, Jiayi Zhang, Puzhen Wu, Shubham Garg, Wei Pu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 相机阵列标定, 运动恢复结构, 密集特征, 内参精炼, 大规模

**Comment:** Accepted to IROS 2025. Final camera-ready version. 8 pages

> **TL;DR:** 本文提出了一种密集特征驱动的多帧标定方法，可以直接从场景数据中精炼相机内参，无需额外的标定捕获，并能与现有SfM流程兼容。

**AI_Comments:** 这项工作在相机阵列标定领域具有重要意义，尤其是在大规模设置中。其创新点在于无需专门的标定图案，直接利用场景数据精炼内参，并通过引入多个正则化项优化传统SfM流程。这大大提高了标定效率和实用性，使其成为现有SfM流程的“即插即用”解决方案。该方法的普适性和与现有系统的兼容性是其主要优势，有望在虚拟现实、3D重建等领域得到广泛应用。

<details>
  <summary>Details</summary>

**Motivation:** 校准大规模相机阵列（如圆顶设置中的相机阵列）耗时且通常需要专门捕获已知图案。尽管外参是固定的，但内参常因镜头调整或温度变化而异，导致在不同会话中发生变化。

**Method:** 本文提出了一种密集特征驱动的多帧标定方法，通过直接从场景数据中精炼内参来消除额外标定捕获的必要性。该方法通过引入以下三项来增强传统运动恢复结构（SfM）流程：1. 外参正则化项，用于将估计的外参逐步与真值对齐；2. 密集特征重投影项，通过最小化特征空间中的重投影损失来减少关键点误差；3. 内参方差项，用于多帧联合优化。

**Result:** 在Multiface数据集上的实验表明，该方法达到了与专用标定过程几乎相同的精度，并显著提高了内参和3D重建的准确性。

**Conclusion:** 本文提出的方法为大规模相机设置提供了一种高效、实用且即插即用的解决方案，能够与现有SfM流程完全兼容，并能直接从场景数据中精炼相机内参，无需额外标定捕获。

> **ai_Abstract:** 本文提出了一种名为“Multi-Cali Anything”的密集特征多帧标定方法，旨在解决大规模相机阵列标定中耗时、需要专门图案以及内参随会话变化的问题。该方法通过增强传统SfM流程，引入外参正则化、密集特征重投影和内参方差项，实现从场景数据直接精炼相机内参，无需额外标定捕获。实验证明，该方法在精度上与专用标定相当，并显著提升了内参和3D重建的准确性，提供了一个高效、实用的即插即用解决方案。

> **摘要翻译:** 校准大规模相机阵列，例如基于圆顶的设置中的相机阵列，耗时且通常需要专门捕获已知图案。虽然此类阵列中的外参由于物理设置是固定的，但内参常因镜头调整或温度变化等因素而在不同会话中发生变化。在本文中，我们提出了一种密集特征驱动的多帧标定方法，该方法直接从场景数据中精炼内参，从而无需额外的标定捕获。我们的方法通过引入外参正则化项来逐步将估计的外参与真值对齐，引入密集特征重投影项通过最小化特征空间中的重投影损失来减少关键点误差，以及引入内参方差项进行多帧联合优化，从而增强了传统的运动恢复结构（SfM）流程。在Multiface数据集上的实验表明，我们的方法达到了与专用标定过程几乎相同的精度，并显著提高了内参和3D重建的准确性。我们的方法与现有SfM流程完全兼容，为大规模相机设置提供了一种高效实用的即插即用解决方案。我们的代码已公开可用：https://github.com/YJJfish/Multi-Cali-Anything

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [659] [Zero-Shot Anomaly Detection with Dual-Branch Prompt Learning](https://arxiv.org/abs/2508.00777)
> *双分支提示学习的零样本异常检测*

*Zihan Wang, Samira Ebrahimi Kahou, Narges Armanfard* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 零样本异常检测, 提示学习, 领域偏移, 测试时自适应, PILOT

**Comment:** Accepted at BMVC 2025

> **TL;DR:** PILOT通过双分支提示学习和无标签测试时自适应，解决了零样本异常检测中的域偏移问题，达到了最先进的性能。

**AI_Comments:** PILOT框架的创新之处在于其独特的双分支提示学习机制和无标签测试时自适应策略。这些方法有效地解决了零样本异常检测在面对未见领域数据时泛化能力不足的痛点，显著提升了模型在实际应用中的鲁棒性。特别是无标签测试时自适应策略，减少了对标注数据的依赖，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的零样本异常检测（ZSAD）方法，无论是使用固定提示还是学习提示，在领域偏移下都表现不佳，因为它们的训练数据来源于有限的训练领域，无法泛化到新的分布。

**Method:** 本文引入了PILOT框架，通过两项关键创新克服了这些挑战：(1) 一种新颖的双分支提示学习机制，动态整合可学习提示池与结构化语义属性，使模型能够自适应地加权每个输入图像最相关的异常线索；(2) 一种无标签的测试时自适应策略，利用来自未标注测试数据的高置信度伪标签更新可学习的提示参数。

**Result:** 在13个工业和医疗基准上的广泛实验表明，PILOT在领域偏移下的异常检测和定位方面都达到了最先进的性能。

**Conclusion:** PILOT框架通过其创新的双分支提示学习机制和无标签测试时自适应策略，有效解决了零样本异常检测在领域偏移下的挑战，并在多个基准测试中取得了最先进的性能。

> **ai_Abstract:** 本文提出了一种名为PILOT的零样本异常检测（ZSAD）框架，旨在解决现有ZSAD方法在领域偏移下泛化能力差的问题。PILOT引入了双分支提示学习机制，结合可学习提示和语义属性，以及无标签的测试时自适应策略，利用伪标签更新提示参数。实验结果表明，PILOT在13个工业和医疗基准测试中，在领域偏移下的异常检测和定位任务上均达到了最先进的性能。

> **摘要翻译:** 零样本异常检测（ZSAD）通过仅依赖可泛化特征而非任何带标签的异常样本，实现对未见类别的缺陷识别和定位。然而，现有的ZSAD方法，无论是使用固定提示还是学习提示，在领域偏移下都表现不佳，因为它们的训练数据来源于有限的训练领域，无法泛化到新的分布。在本文中，我们引入了PILOT，一个旨在通过两项关键创新克服这些挑战的框架：(1) 一种新颖的双分支提示学习机制，动态整合可学习提示池与结构化语义属性，使模型能够自适应地加权每个输入图像最相关的异常线索；(2) 一种无标签的测试时自适应策略，利用来自未标注测试数据的高置信度伪标签更新可学习的提示参数。在13个工业和医疗基准上的广泛实验表明，PILOT在领域偏移下的异常检测和定位方面都达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [666] [Retinex-MEF: Retinex-based Glare Effects Aware Unsupervised Multi-Exposure Image Fusion](https://arxiv.org/abs/2503.07235)
> *Retinex-MEF：基于Retinex的眩光效应感知无监督多曝光图像融合*

*Haowen Bai, Jiangshe Zhang, Zixiang Zhao, Lilun Deng, Yukun Cui, Shuang Xu* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 多曝光图像融合, Retinex, 眩光效应, 无监督学习, 曝光控制

**Comment:** Accepted to ICCV 2025

> **TL;DR:** Retinex-MEF是一种无监督的多曝光图像融合方法，它能有效处理过曝引起的眩光，并提供可控的曝光调整。

**AI_Comments:** 该论文的创新点在于将Retinex理论与眩光效应建模相结合，并提出了无监督学习框架和可控的曝光融合准则，解决了传统MEF方法在处理极端曝光和眩光时的局限性，增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的多曝光图像融合（MEF）方法，尤其是基于Retinex理论的，在像素级乘法上无法充分建模过曝引起的眩光效应，导致融合图像质量不佳。

**Method:** 本文提出了一种名为Retinex-MEF的无监督且可控的多曝光图像融合方法。该方法将多曝光图像分解为独立的照度分量和共享的反射分量，并有效建模过曝引起的眩光。通过双向损失学习共享反射分量以有效减轻眩光效应。此外，引入了可控的曝光融合准则，能够在保持对比度的同时进行全局曝光调整，克服了固定曝光水平的限制。

**Result:** 在包括欠曝-过曝融合、曝光控制融合和同质极端曝光融合在内的多种数据集上的广泛实验表明，该模型具有有效的分解能力和灵活的融合能力。

**Conclusion:** Retinex-MEF模型通过有效分解和灵活融合能力，成功解决了传统MEF方法中眩光建模不足的问题，并提供了可控的曝光调整，增强了多曝光图像融合的实用性。

> **ai_Abstract:** 本文提出了一种名为Retinex-MEF的无监督多曝光图像融合方法，旨在解决传统Retinex理论在处理过曝引起的眩光效应时的不足。该方法通过将图像分解为独立的照度分量和共享的反射分量来有效建模眩光，并通过双向损失学习共享反射率以减轻眩光。此外，它引入了可控的曝光融合准则，允许灵活的全局曝光调整。实验证明了其在不同曝光条件下的有效分解和灵活融合能力。

> **摘要翻译:** 多曝光图像融合（MEF）将同一场景的多张不同曝光图像合成为一张曝光良好的复合图像。Retinex理论将图像照度与场景反射率分离，为确保跨不同曝光水平的一致场景表示和有效信息融合提供了自然的框架。然而，传统的照度与反射率的像素级乘法未能充分建模过曝引起的眩光效应。为了解决这一限制，我们引入了一种名为Retinex-MEF的无监督且可控的方法。具体而言，我们的方法将多曝光图像分解为独立的照度分量和共享的反射分量，并有效建模过曝引起的眩光。共享反射率通过双向损失学习，这使得我们的方法能够有效减轻眩光效应。此外，我们引入了一种可控的曝光融合准则，能够在保持对比度的同时进行全局曝光调整，从而克服了固定曝光水平的限制。在包括欠曝-过曝融合、曝光控制融合和同质极端曝光融合在内的各种数据集上进行的广泛实验，证明了我们模型有效的分解能力和灵活的融合能力。代码可在https://github.com/HaowenBai/Retinex-MEF获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [669] [Object-Centric Cropping for Visual Few-Shot Classification](https://arxiv.org/abs/2508.00218)
> *视觉少样本分类中的以对象为中心的裁剪*

*Aymane Abdali, Bartosz Boguslawski, Lucas Drumetz, Vincent Gripon* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 少样本分类, 以对象为中心的裁剪, 图像歧义, Segment Anything Model, 无监督提取

**Comment:** 

> **TL;DR:** 通过以对象为中心的裁剪，即使在仅有少量样本的情况下，也能显著提升视觉少样本分类的性能，且可以通过像Segment Anything Model这样的低监督甚至无监督方法实现。

**AI_Comments:** 这项研究的创新之处在于强调了在少样本学习中，通过聚焦以对象为中心的信息来对抗图像歧义的重要性。它特别指出，即使是利用低监督（如SAM的单像素提示）或无监督的方法，也能获得显著的性能提升，这对于减少数据标注成本和提高模型在复杂场景下的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在少样本图像分类中，由于图像中存在多个对象或复杂背景造成的歧义会显著降低分类性能。

**Method:** 本研究通过整合对象在图像中的局部位置信息来增强分类。具体地，研究表明使用Segment Anything Model（仅需指定对象的一个像素点）或采用完全无监督的前景对象提取方法，即可实现显著的性能提升。

**Result:** 整合对象局部位置信息能显著提升少样本图像分类在现有基准上的表现。其中，很大一部分的改进可以通过使用Segment Anything Model或完全无监督的前景对象提取方法实现。

**Conclusion:** 以对象为中心的信息，即使是利用极低监督或无监督的方法获取，也能有效提升少样本图像分类的性能，解决了图像歧义带来的挑战。

> **ai_Abstract:** 本研究提出在视觉少样本分类中利用以对象为中心的信息来解决图像歧义导致的性能下降问题。研究表明，整合对象局部位置信息能显著提升分类性能，且这种提升可通过仅需一个像素点提示的Segment Anything Model或完全无监督的前景对象提取方法高效实现。

> **摘要翻译:** 在少样本图像分类领域，即每个类别只有少量样本的情况下，由多个对象或复杂背景引起的图像歧义会显著降低性能。我们的研究表明，在图像中纳入关于对象局部位置的额外信息可以显著增强在既定基准上的分类能力。更重要的是，我们展示了大部分的改进可以通过使用Segment Anything Model来实现，该模型仅需指出感兴趣对象的一个像素点，或者通过采用完全无监督的前景对象提取方法来实现。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [670] [HyPCV-Former: Hyperbolic Spatio-Temporal Transformer for 3D Point Cloud Video Anomaly Detection](https://arxiv.org/abs/2508.00473)
> *HyPCV-Former：用于3D点云视频异常检测的双曲时空Transformer*

*Jiaping Cao, Kangkang Zhou, Juan Du* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 点云视频, 异常检测, 双曲几何, Transformer, 时空学习

**Comment:** 

> **TL;DR:** HyPCV-Former引入双曲时空Transformer，通过在洛伦兹双曲空间中操作，解决了传统欧几里得方法在3D点云视频异常检测中捕获分层事件结构和时空连续性的局限性，并实现了最先进的性能。

**AI_Comments:** 该论文的创新之处在于将双曲几何引入到3D点云视频异常检测中，特别是利用洛伦兹双曲空间和双曲多头自注意力机制来更好地捕获分层和时空结构。这种非欧几里得几何的应用解决了传统欧几里得方法在处理复杂数据结构时的局限性，为视频异常检测领域带来了新的视角和显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 先前的视频异常检测方法利用RGB或深度域中的欧几里得表示，但在捕获分层事件结构和时空连续性方面存在固有限制。

**Method:** 本文提出了HyPCV-Former，一种新颖的双曲时空Transformer，用于3D点云视频中的异常检测。该方法首先通过点云提取器从点云序列中提取每帧空间特征，然后将其嵌入到洛伦兹双曲空间中，以更好地捕获事件的潜在分层结构。为了建模时间动态，引入了双曲多头自注意力（HMHA）机制，该机制利用洛伦兹内积和曲率感知softmax在非欧几里得几何下学习时间依赖性。所有特征变换和异常评分都直接在完整的洛伦兹空间中进行，而不是通过切线空间近似。

**Result:** HyPCV-Former在多个异常类别上实现了最先进的性能，在TIMo数据集上相比基准提高了7%，在DAD数据集上提高了5.6%。

**Conclusion:** HyPCV-Former通过利用双曲几何在3D点云视频异常检测中取得了显著的性能提升，证明了其在捕获复杂时空和分层结构方面的优越性。

> **ai_Abstract:** HyPCV-Former提出了一种新颖的双曲时空Transformer，用于3D点云视频异常检测。该模型克服了传统欧几里得表示在捕捉分层事件结构和时空连续性方面的局限性。它将点云特征嵌入到洛伦兹双曲空间中，并引入双曲多头自注意力机制来建模时间动态。该方法直接在洛伦兹空间中进行所有操作，实验证明在TIMo和DAD数据集上均取得了显著的性能提升。

> **摘要翻译:** 视频异常检测是视频监控中的一项基础任务，在公共安全和智能监控系统中有广泛应用。尽管先前的方法利用RGB或深度域中的欧几里得表示，但此类嵌入在捕获分层事件结构和时空连续性方面存在固有限制。为了解决这些限制，我们提出了HyPCV-Former，一种新颖的双曲时空Transformer，用于3D点云视频中的异常检测。我们的方法首先通过点云提取器从点云序列中提取每帧空间特征，然后将其嵌入到洛伦兹双曲空间中，这能更好地捕获事件的潜在分层结构。为了建模时间动态，我们引入了一种双曲多头自注意力（HMHA）机制，该机制利用洛伦兹内积和曲率感知softmax在非欧几里得几何下学习时间依赖性。我们的方法直接在完整的洛伦兹空间中执行所有特征变换和异常评分，而不是通过切线空间近似。广泛的实验表明，HyPCV-Former在多个异常类别上实现了最先进的性能，在TIMo数据集上相比基准提高了7%，在DAD数据集上提高了5.6%。代码将在论文接收后发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [676] [FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait](https://arxiv.org/abs/2412.01064)
> *FLOAT: 基于生成运动潜在流匹配的音频驱动人像说话模型*

*Taekyung Ki, Dongchan Min, Gyeongsu Chae* | **Category: cs.CV, cs.AI, cs.LG, cs.MM, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 音频驱动人像, 流匹配, 运动潜在空间, 视频生成, 时间一致性

**Comment:** ICCV 2025. Project page:
  https://deepbrainai-research.github.io/float/

> **TL;DR:** FLOAT是一种基于流匹配生成模型，利用学习到的正交运动潜在空间，实现高效且时间一致的音频驱动人像说话视频生成。

**AI_Comments:** FLOAT的创新点在于结合了流匹配模型和正交运动潜在空间，有效解决了扩散模型在时间一致性和效率上的固有挑战。其引入的Transformer-based矢量场预测器和语音驱动情感增强机制也提升了生成视频的自然度和表现力，对音频驱动人像动画领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在图像动画方面取得显著进展，但在时间一致的视频生成和快速采样方面仍面临挑战。

**Method:** 本文提出了FLOAT，一个基于流匹配生成模型的音频驱动人像说话视频生成方法。它利用学习到的正交运动潜在空间而非像素级潜在空间，以实现高效生成和时间一致的运动编辑。方法引入了一个基于Transformer的矢量场预测器，具有有效的逐帧条件机制，并支持语音驱动的情感增强。

**Result:** 大量实验表明，该方法在视觉质量、运动保真度和效率方面均优于当前最先进的音频驱动人像说话方法。

**Conclusion:** FLOAT通过其创新的运动潜在空间和流匹配方法，有效解决了现有音频驱动人像动画模型在时间一致性和效率上的挑战，并实现了高质量、富有表现力的视频生成。

> **ai_Abstract:** 本文提出了一种名为FLOAT的音频驱动人像说话视频生成方法，旨在解决现有扩散模型在时间一致性视频生成和快速采样方面的不足。FLOAT利用流匹配生成模型和学习到的正交运动潜在空间，而非传统的像素级潜在空间，以实现高效且时间一致的运动生成和编辑。该方法还引入了基于Transformer的矢量场预测器和语音驱动的情感增强机制。实验证明，FLOAT在视觉质量、运动保真度和效率上均超越了现有最先进的方法。

> **摘要翻译:** 随着基于扩散的生成模型的快速发展，人像图像动画取得了显著成果。然而，由于其迭代采样性质，它在时间一致的视频生成和快速采样方面仍然面临挑战。本文提出了FLOAT，一种基于流匹配生成模型的音频驱动人像说话视频生成方法。我们利用学习到的正交运动潜在空间，而非基于像素的潜在空间，从而实现高效生成和时间一致的运动编辑。为此，我们引入了一个基于Transformer的矢量场预测器，并配备了有效的逐帧条件机制。此外，我们的方法支持语音驱动的情感增强，从而能够自然地融入富有表现力的动作。大量实验表明，我们的方法在视觉质量、运动保真度和效率方面均优于最先进的音频驱动人像说话方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [678] [Towards a Unified Copernicus Foundation Model for Earth Vision](https://arxiv.org/abs/2503.11849)
> *迈向统一的哥白尼地球视觉基础模型*

*Yi Wang, Zhitong Xiong, Chenying Liu, Adam J. Stewart, Thomas Dujardin, Nikolaos Ioannis Bountos, Angelos Zavras, Franziska Gerken, Ioannis Papoutsis, Laura Leal-Taixé, Xiao Xiang Zhu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 地球观测, 基础模型, 哥白尼, 多模态, 遥感

**Comment:** Accepted to ICCV 2025. 33 pages, 34 figures

> **TL;DR:** 本文提出了一个统一的哥白尼地球观测基础模型（Copernicus-FM），包括大规模预训练数据集、统一模型和系统评估基准，旨在解决现有地球观测基础模型在传感器、覆盖范围和元数据利用方面的局限性，显著提高其可扩展性、多功能性和多模态适应性。

**AI_Comments:** 该论文的创新之处在于其统一的地球观测基础模型方法，通过整合大规模、多样的哥白尼卫星数据，并开发能够处理多光谱和非光谱模态的灵活模型架构，显著超越了现有模型的局限性。其提出的数据集和基准也为未来研究提供了宝贵资源，有望推动地球视觉和跨学科研究的重大进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的地球观测（EO）基础模型主要局限于固定光谱传感器，仅关注地球表面，并忽略了图像之外的宝贵元数据，这限制了它们从大型卫星数据中学习通用表示并服务广泛下游应用的能力。

**Method:** 本文通过三个关键组件构建下一代地球观测基础模型：1) Copernicus-Pretrain，一个大规模预训练数据集，整合了来自所有主要哥白尼哨兵任务的18.7M对齐图像，涵盖地球表面到大气层；2) Copernicus-FM，一个统一的基础模型，利用扩展动态超网络和灵活元数据编码，能够处理任何光谱或非光谱传感器模态；3) Copernicus-Bench，一个系统的评估基准，包含15个分层下游任务，涵盖从预处理到每个哨兵任务的专业应用。

**Result:** 所提出的数据集、模型和基准显著提高了地球观测基础模型的可扩展性、多功能性和多模态适应性。

**Conclusion:** 本研究为下一代地球观测基础模型迈出了重要一步，并为连接地球观测、天气和气候研究创造了新的机会。

> **ai_Abstract:** 本论文致力于构建下一代地球观测（EO）基础模型，以克服现有模型在传感器类型、覆盖范围和元数据利用上的局限性。研究提出了三个核心组件：Copernicus-Pretrain，一个包含1870万张图像的大规模预训练数据集，涵盖地球表面至大气层；Copernicus-FM，一个统一的基础模型，能够通过动态超网络和灵活元数据编码处理多模态传感器数据；以及Copernicus-Bench，一个包含15个任务的系统评估基准。这些创新显著提升了EO基础模型的可扩展性、多功能性和多模态适应性，并为地球观测、天气和气候研究带来了新的连接机遇。

> **摘要翻译:** 地球观测（EO）基础模型的进步释放了大数据卫星的潜力，能够从太空学习通用表示，造福于对地球至关重要的广泛下游应用。然而，大多数现有工作仍限于固定光谱传感器，只关注地球表面，并忽略了图像之外的宝贵元数据。在这项工作中，我们通过三个关键组件向下一代EO基础模型迈进：1）Copernicus-Pretrain，一个大规模的预训练数据集，整合了来自所有主要哥白尼哨兵任务的18.7M对齐图像，涵盖从地球表面到大气层；2）Copernicus-FM，一个统一的基础模型，能够使用扩展动态超网络和灵活的元数据编码处理任何光谱或非光谱传感器模态；3）Copernicus-Bench，一个系统的评估基准，包含15个分层下游任务，涵盖从预处理到每个哨兵任务的专业应用。我们的数据集、模型和基准极大地提高了EO基础模型的可扩展性、多功能性和多模态适应性，同时也为连接EO、天气和气候研究创造了新的机会。代码、数据集和模型可在https://github.com/zhu-xlab/Copernicus-FM获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [694] [LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer](https://arxiv.org/abs/2508.00477)
> *LAMIC：基于多模态扩散Transformer可扩展性的布局感知多图像合成*

*Yuzhuo Chen, Zehua Ma, Jianhua Wang, Kai Kang, Shunyu Yao, Weiming Zhang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 多图像合成, 扩散模型, 布局感知, 注意力机制, 零样本泛化

**Comment:** 8 pages, 5 figures, 3 tables

> **TL;DR:** LAMIC是一个无需训练的多图像合成框架，通过引入两种新的注意力机制，在多图像合成中实现了布局感知和实体解耦，并取得了SOTA性能。

**AI_Comments:** LAMIC的创新之处在于其无需训练的多图像合成范式，通过巧妙设计即插即用的注意力机制（GIA和RMA），有效解决了多参考图像合成中的实体解耦和布局控制挑战。其在零样本泛化能力方面的表现尤为突出，预示着未来基础模型在多图像合成领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在可控图像合成中，从多个参考图像生成具有空间布局意识的连贯一致的图像仍然是一个开放的挑战。

**Method:** 提出了LAMIC框架，首次以无需训练的方式将单参考扩散模型扩展到多参考场景。LAMIC基于MMDiT模型，引入了两种即插即用注意力机制：组隔离注意力（GIA）以增强实体解耦，以及区域调制注意力（RMA）以实现布局感知生成。此外，还引入了包含率（IN-R）、填充率（FI-R）和背景相似度（BG-S）三个评估指标。

**Result:** 广泛的实验表明，LAMIC在大多数主要指标上都达到了最先进的性能，在所有设置下，ID-S、BG-S、IN-R和AVG分数始终优于现有基线，并在复杂合成任务中实现了最佳DPG。

**Conclusion:** LAMIC在保持身份、背景保留、布局控制和遵循提示方面表现出卓越能力，所有这些都无需任何训练或微调，展示了强大的零样本泛化能力。它为可控多图像合成建立了一个新的无需训练的范式。

> **ai_Abstract:** LAMIC是一个无需训练的布局感知多图像合成框架，它通过引入组隔离注意力和区域调制注意力，首次将单参考扩散模型扩展到多参考场景。该框架在保持身份、背景一致性、布局控制和遵循提示方面表现出色，并在新引入的评估指标上取得了最先进的性能，展示了强大的零样本泛化能力。

> **摘要翻译:** 在可控图像合成中，从多个参考图像生成具有空间布局意识的连贯一致的图像仍然是一个开放的挑战。我们提出了LAMIC，一个布局感知多图像合成框架，首次以无需训练的方式将单参考扩散模型扩展到多参考场景。LAMIC建立在MMDiT模型之上，引入了两种即插即用注意力机制：1) 组隔离注意力（GIA）以增强实体解耦；2) 区域调制注意力（RMA）以实现布局感知生成。为了全面评估模型能力，我们进一步引入了三个指标：1) 包含率（IN-R）和填充率（FI-R）用于评估布局控制；2) 背景相似度（BG-S）用于衡量背景一致性。广泛的实验表明，LAMIC在大多数主要指标上都达到了最先进的性能：在所有设置下，它在ID-S、BG-S、IN-R和AVG分数上始终优于现有的多参考基线，并在复杂合成任务中实现了最佳DPG。这些结果表明LAMIC在保持身份、背景保留、布局控制和遵循提示方面的卓越能力，所有这些都无需任何训练或微调，展示了强大的零样本泛化能力。通过继承先进的单参考模型的优势并实现无缝扩展到多图像场景，LAMIC为可控多图像合成建立了一个新的无需训练的范式。随着基础模型的不断发展，LAMIC的性能有望相应地扩展。我们的实现代码可在以下网址获取：https://github.com/Suchenl/LAMIC。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [695] [Cross-Dataset Semantic Segmentation Performance Analysis: Unifying NIST Point Cloud City Datasets for 3D Deep Learning](https://arxiv.org/abs/2508.00822)
> *跨数据集语义分割性能分析：统一NIST点云城市数据集用于3D深度学习*

*Alexander Nikitas Dimopoulos, Joseph Grasso* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 点云, 语义分割, 数据集统一, 公共安全, KPConv

**Comment:** 

> **TL;DR:** 本研究分析了NIST点云城市数据集（Enfield和Memphis）在公共安全应用中跨异构标注的点云数据进行语义分割的性能，发现大型几何物体分割效果好，而小型安全关键特征识别率低，主要挑战是数据不平衡、标注数据不足和缺乏标准化，强调需要改进标注技术和标准化协议。

**AI_Comments:** 这篇论文探讨了在公共安全领域应用点云语义分割所面临的实际挑战，特别是数据异构性和小型安全关键特征的识别问题。其创新点在于通过统一NIST数据集并使用KPConv架构对性能进行深入分析。研究结果揭示了现有方法的局限性，并明确指出了未来研究和实践中需要解决的关键问题，如数据标准化和标注技术改进，这对于推动该领域的实际应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是分析在公共安全应用中，特别是来自激光雷达扫描的事前规划系统，跨异构标注点云数据集的语义分割性能，并解决统一不同标注的3D数据所面临的挑战。

**Method:** 研究采用分级模式和KPConv架构，使用NIST点云城市数据集（Enfield和Memphis集合），通过IoU指标评估安全相关特征的性能。

**Result:** 结果显示性能存在差异：几何尺寸大的物体（如楼梯、窗户）分割性能较高；而较小的安全关键特征识别率较低。性能受类别不平衡和小型物体在典型激光雷达扫描中几何区分度有限的影响，表明当前点云方法在检测某些安全相关特征方面存在局限性。主要挑战包括标注数据不足、数据集间类别标签统一困难以及需要标准化。

**Conclusion:** 为了实现公共安全领域可靠的点云语义分割，需要标准化标注协议和改进标注技术，以解决数据异构性以及小型安全关键元素的检测问题。

> **ai_Abstract:** 本文分析了NIST点云城市数据集在公共安全应用中跨异构标注点云数据的语义分割性能。研究利用KPConv架构和IoU指标，发现大型几何物体分割效果较好，而小型安全关键特征识别率低，这主要受类别不平衡和物体几何区分度限制影响。研究指出了标注数据不足、标签统一困难和缺乏标准化等挑战，并强调了标准化标注协议和改进标注技术对于提高公共安全领域点云语义分割可靠性的重要性。

> **摘要翻译:** 本研究分析了与公共安全应用相关的异构标注点云数据集的语义分割性能，包括源自激光雷达扫描的事前规划系统。我们使用NIST点云城市数据集（Enfield和Memphis集合），调查了统一不同标注的3D数据所面临的挑战。我们的方法采用分级模式和KPConv架构，通过IoU指标评估安全相关特征的性能。结果表明性能存在变异性：几何尺寸大的物体（例如楼梯、窗户）实现了更高的分割性能，这表明其在导航语境中的潜力，而较小的安全关键特征则表现出较低的识别率。性能受到类别不平衡和小型物体在典型激光雷达扫描中几何区分度有限的影响，这表明当前点云方法在检测某些安全相关特征方面存在局限性。识别出的主要挑战包括标注数据不足、统一跨数据集类别标签的困难以及标准化的必要性。潜在方向包括自动化标注和多数据集学习策略。我们得出结论，公共安全领域可靠的点云语义分割需要标准化的标注协议和改进的标注技术，以解决数据异构性以及小型安全关键元素的检测问题。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [696] [TerraMesh: A Planetary Mosaic of Multimodal Earth Observation Data](https://arxiv.org/abs/2504.11172)
> *TerraMesh：多模态地球观测数据的行星级镶嵌*

*Benedikt Blumenstiel, Paolo Fraccaro, Valerio Marsocci, Johannes Jakubik, Stefano Maurogiovanni, Mikolaj Czerkawski, Rocco Sedona, Gabriele Cavallaro, Thomas Brunschwiler, Juan Bernabe-Moreno, Nicolas Longépé* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 地球观测, 多模态, 数据集, 基础模型, 预训练

**Comment:** Proceedings of the Computer Vision and Pattern Recognition Conference
  (CVPR) Workshops

> **TL;DR:** TerraMesh是一个新的全球多样化、多模态地球观测数据集，用于大规模预训练，解决了现有数据集规模、地理覆盖或传感器种类有限的问题，并能提高模型性能。

**AI_Comments:** TerraMesh的创新性在于其大规模、多模态和全球覆盖的特性，弥补了现有地球观测数据集的不足。它为开发和训练地球观测领域的大型基础模型提供了宝贵的数据基础，有望推动该领域的发展，提高模型在各种任务中的性能。其分析就绪数据格式也降低了数据使用的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 现有的地球观测公共数据集在规模、地理覆盖范围或传感器种类方面存在局限性，阻碍了大型基础模型学习通用、标签高效的表示。

**Method:** 本文引入了TerraMesh，这是一个新的全球多样化、多模态数据集，结合了光学、合成孔径雷达、高程和土地覆盖等模态，并采用分析就绪数据格式。该数据集包含超过900万个样本，具有八种时空对齐的模态，支持大规模预训练。作者还提供了详细的数据处理步骤、全面的统计数据和实证证据。

**Result:** 在TerraMesh上进行预训练的模型性能得到了显著提升。

**Conclusion:** TerraMesh数据集通过提供大规模、全球多样化、多模态的地球观测数据，有效解决了现有数据集的局限性，并能显著提升地球观测领域大型基础模型的预训练效果和性能。

> **ai_Abstract:** 本文介绍了TerraMesh，一个大规模、全球多样化、多模态的地球观测数据集，旨在解决现有数据集的局限性。TerraMesh整合了光学、SAR、高程和土地覆盖等多种数据类型，包含超过900万个样本，支持大规模模型预训练。研究表明，在TerraMesh上预训练能显著提升模型性能，为地球观测领域的基础模型开发提供了重要资源。

> **摘要翻译:** 地球观测领域的大型基础模型可以通过利用海量未标记数据来学习通用且标签高效的表示。然而，现有的公共数据集在规模、地理覆盖范围或传感器种类方面往往受到限制。我们引入了TerraMesh，这是一个新的全球多样化、多模态数据集，它以分析就绪数据格式结合了光学、合成孔达、高程和土地覆盖等模态。TerraMesh包含超过900万个样本，具有八种时空对齐的模态，能够进行大规模预训练。我们提供了详细的数据处理步骤、全面的统计数据，以及证明在TerraMesh上预训练后模型性能得到改善的实证证据。该数据集托管在https://huggingface.co/datasets/ibm-esa-geospatial/TerraMesh。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [699] [Guided Depth Map Super-Resolution via Multi-Scale Fusion U-shaped Mamba Network](https://arxiv.org/abs/2508.00248)
> *基于多尺度融合U型Mamba网络的引导深度图超分辨率*

*Chenggang Guo, Hao Xu, XianMing Wan* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 深度图超分辨率, Mamba, 多尺度融合, U型网络, 状态空间模型

**Comment:** 

> **TL;DR:** 该论文提出了一种名为MSF-UM的新型引导深度图超分辨率框架，将Mamba的高效状态空间建模能力与多尺度U型融合结构结合，解决了传统CNN和Transformer在长距离依赖和计算复杂性方面的限制，并在减少参数的同时实现了更好的重建精度和泛化能力。

**AI_Comments:** 该论文的创新点在于首次将Mamba状态空间模型引入到引导深度图超分辨率领域，有效结合了卷积网络局部特征提取与状态空间模型长距离依赖建模的优势。通过U型结构和多尺度融合策略，以及彩色图像的引导，使得模型在保持高重建精度的同时显著降低了参数量，并展现出优异的泛化能力，为解决高分辨率深度图处理中的效率和性能问题提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统卷积神经网络在处理长距离依赖和建模全局上下文信息方面存在局限性，而Transformer虽然能建模全局依赖，但其二次方的计算复杂度和内存消耗限制了其处理高分辨率深度图的能力。

**Method:** 本文提出了一种多尺度融合U型Mamba（MSF-UM）模型，这是一种新型的引导深度图超分辨率框架。其核心创新是将Mamba的高效状态空间建模能力集成到由彩色图像引导的多尺度U型融合结构中。该结构结合了残差密集通道注意力块和Mamba状态空间模块，融合了卷积层的局部特征提取能力与状态空间模型对长距离依赖的建模优势。同时，模型采用多尺度跨模态融合策略，充分利用彩色图像的高频纹理信息来引导深度图的超分辨率过程。

**Result:** 与现有主流方法相比，所提出的MSF-UM模型在显著减少模型参数的同时，实现了更好的重建精度。在多个公开数据集上的大量实验验证了该模型的有效性，尤其在大规模深度图超分辨率任务中表现出卓越的泛化能力。

**Conclusion:** MSF-UM模型通过结合Mamba的状态空间建模和多尺度U型融合结构，有效解决了深度图超分辨率中长距离依赖和计算效率的挑战，并在减少参数的同时实现了优越的重建精度和泛化能力。

> **ai_Abstract:** 本文提出了一种名为多尺度融合U型Mamba（MSF-UM）的新型引导深度图超分辨率框架。该模型通过将Mamba高效的状态空间建模能力融入由彩色图像引导的多尺度U型融合结构中，有效解决了传统CNN在长距离依赖方面的不足以及Transformer计算复杂度过高的问题。MSF-UM结合了卷积层的局部特征提取和Mamba对长距离依赖的建模优势，并通过多尺度跨模态融合利用彩色图像信息。实验证明，MSF-UM在显著减少参数的同时，实现了优于现有方法的重建精度和卓越的泛化能力。

> **摘要翻译:** 深度图超分辨率技术旨在提高低分辨率深度图的空间分辨率，并有效恢复高频细节信息。传统的卷积神经网络在处理长距离依赖方面存在局限性，无法充分建模深度图中的全局上下文信息。尽管Transformer可以建模全局依赖，但其计算复杂度和内存消耗呈二次方增长，这显著限制了其处理高分辨率深度图的能力。在本文中，我们提出了一种多尺度融合U型Mamba（MSF-UM）模型，这是一种新颖的引导深度图超分辨率框架。该模型的核心创新是将Mamba的高效状态空间建模能力集成到由彩色图像引导的多尺度U型融合结构中。设计了结合残差密集通道注意力块和Mamba状态空间模块的结构，该结构结合了卷积层的局部特征提取能力与状态空间模型对长距离依赖的建模优势。同时，模型采用多尺度跨模态融合策略，充分利用彩色图像的高频纹理信息来引导深度图的超分辨率过程。与现有主流方法相比，所提出的MSF-UM在显著减少模型参数的同时实现了更好的重建精度。在多个公开数据集上的大量实验验证了该模型的有效性，尤其在大规模深度图超分辨率任务中表现出卓越的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [714] [DCT-Shield: A Robust Frequency Domain Defense against Malicious Image Editing](https://arxiv.org/abs/2504.17894)
> *DCT-Shield：一种针对恶意图像编辑的鲁棒频域防御*

*Aniruddha Bala, Rohit Chowdhury, Rohan Jaiswal, Siddharth Roheda* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** DCT, 频域防御, 图像编辑, 扩散模型, 鲁棒性

**Comment:** Accepted to ICCV 2025

> **TL;DR:** DCT-Shield是一种新的频域防御方法，通过修改DCT系数来保护图像免受恶意扩散模型编辑，同时减少视觉伪影并提高对净化技术的鲁棒性。

**AI_Comments:** 该论文的创新点在于将对抗性扰动引入到频域，而非传统的像素域，并巧妙地利用了JPEG压缩管道的特性。这种方法有效地解决了现有防御手段在视觉可察觉性和对净化技术鲁棒性方面的局限性，为图像安全领域提供了一种更实用和高效的解决方案。通过在DCT域操作，它能更好地隐藏扰动并抵抗常见的图像处理操作。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型使得通过文本提示进行图像编辑变得轻而易举，引发了图像安全问题，攻击者可能利用这些工具进行恶意编辑。现有防御方法通过在像素空间添加噪声来干扰扩散模型，但其添加的对抗性噪声容易被人眼察觉，且对JPEG压缩等净化技术缺乏鲁棒性。

**Method:** 我们提出了一种新颖的优化方法，通过修改输入图像的离散余弦变换（DCT）系数，直接在频域引入对抗性扰动。该方法利用JPEG管道生成对抗性图像，从而有效阻止恶意图像编辑。

**Result:** 在各种任务和数据集上进行的广泛实验表明，我们的方法引入的视觉伪影更少，同时保持了相似的编辑保护水平和对噪声净化技术的鲁棒性。

**Conclusion:** DCT-Shield通过在频域引入对抗性扰动，提供了一种有效且鲁棒的防御机制，以对抗基于扩散模型的恶意图像编辑，同时显著减少了视觉伪影并增强了对净化技术的抵抗力。

> **ai_Abstract:** 本文提出了一种名为DCT-Shield的新型图像防御方法，旨在对抗基于扩散模型的恶意图像编辑。不同于现有在像素空间添加可见且不鲁棒噪声的方法，DCT-Shield通过在频域直接修改图像的离散余弦变换（DCT）系数来引入对抗性扰动，并利用JPEG管道生成防御性图像。实验证明，该方法在提供相似编辑保护和对噪声净化技术（如JPEG压缩）鲁棒性的同时，显著减少了视觉伪影。

> **摘要翻译:** 扩散模型的发展使得通过文本提示进行图像编辑变得轻而易举，这引发了对图像安全性的担忧。拥有用户图像访问权限的攻击者可以利用这些工具进行恶意编辑。最近的防御尝试通过在像素空间添加有限噪声来破坏基于扩散的编辑模型的运行。然而，以前方法添加的对抗性噪声很容易被人眼察觉。此外，在可行的像素预算下，大多数这些方法对JPEG压缩等净化技术不具备鲁棒性。我们提出了一种新颖的优化方法，通过修改输入图像的离散余弦变换（DCT）系数，直接在频域引入对抗性扰动。通过利用JPEG管道，我们的方法生成对抗性图像，有效阻止恶意图像编辑。在各种任务和数据集上进行的广泛实验表明，我们的方法引入的视觉伪影更少，同时保持了相似的编辑保护水平和对噪声净化技术的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [332] [Data Bias in Human Mobility is a Universal Phenomenon but is Highly Location-specific](https://arxiv.org/abs/2508.00149)
> *人类出行数据偏差是普遍现象但具有高度地域特异性*

*Katinka den Nijs, Elisa Omodei, Vedran Sekara* | **Category: cs.CY, cs.SI, physics.soc-ph** | **Updated: 2025-07-31**

**Keywords:** 数据偏差, 人类出行, 地理特异性, 数据生产, 社会经济因素

**Comment:** 

> **TL;DR:** 该研究发现人类出行数据中的偏差是普遍存在的，但在不同城市中表现形式各异，且受财富、种族和教育等因素影响，因此需要地域特定的模型来解决偏差问题。

**AI_Comments:** 这项研究的重要性在于揭示了广泛使用的人类出行数据集中普遍存在的、但又被忽视的偏差问题。其创新之处在于不仅量化了数据代表性，还深入分析了数据生产量的不均衡性及其与社会经济因素的关联。研究挑战了通用去偏方法的有效性，强调了地域特异性建模的重要性，对未来数据收集、分析和政策制定具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型人类出行数据集在算法系统、业务流程和政策决策中扮演着越来越重要的角色，但目前对这些数据集的偏差和基本缺陷及其对后续分析和预测任务的影响关注甚少。

**Method:** 研究人员通过分析来自十个美国主要城市的匿名智能手机GPS出行数据，量化了“数据生产”情况，即个体在大型数字数据集中被代表的程度以及他们产生的数据量。他们还建立了模型来预测普查区中不同人口群体产生的数据点数量。

**Result:** 研究发现，数据点在用户之间的分布比财富更加不均。财富、种族和教育对数据生产有显著影响。虽然偏差是普遍现象，存在于所有城市中，但每个城市都有其独特的偏差表现形式，因此需要地域特定的模型来建模偏差。

**Conclusion:** 这项工作对普遍适用的人类出行数据去偏方法提出了严重质疑，并敦促进行进一步研究。

> **ai_Abstract:** 本研究深入探讨了人类出行数据中的偏差问题，发现这种偏差普遍存在于不同城市中，但其具体表现形式具有高度地域特异性。通过分析美国十个主要城市的GPS出行数据，研究人员发现数据点在用户间的分布极不均衡，且与财富、种族和教育等人口统计学因素显著相关。研究强调，鉴于偏差的地域特异性，通用的去偏方法可能效果不佳，呼吁开发针对特定地点的偏差建模和缓解策略。

> **摘要翻译:** 大规模人类出行数据集在许多算法系统、业务流程和政策决策中扮演着越来越重要的角色。然而，目前很少有研究关注数据集的偏差和其他基本缺陷，以及它们如何影响下游分析和预测任务。在这项工作中，我们研究了“数据生产”，不仅量化了个人在大型数字数据集中是否被代表，还量化了他们如何被代表，即他们产生了多少数据。我们研究了从十个美国主要城市的匿名智能手机收集的GPS出行数据，发现数据点在用户之间的分布可能比财富更加不均。我们建立了模型来预测普查区中不同人口群体产生的预期数据点数量，并发现财富、种族和教育对数据生产有很强的影响。虽然我们发现偏差是一种普遍现象，存在于所有城市中，但我们进一步发现每个城市都有其独特的偏差表现形式，并且需要地域特定的模型来建模每个城市的偏差。这项工作对普遍适用的人类出行数据去偏方法提出了严重质疑，并敦促进行进一步研究。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [352] [Green Computing: The Ultimate Carbon Destroyer for a Sustainable Future](https://arxiv.org/abs/2508.00153)
> *绿色计算：可持续未来的终极碳消除器*

*Sayed Mahbub Hasan Amiri, Prasun Goswami, Md. Mainul Islam, Mohammad Shakhawat Hossen, Marzana Mithila, Naznin Akter* | **Category: cs.CY, cs.SC** | **Updated: 2025-08-04**

**Keywords:** 绿色计算, 碳消除, 可持续IT, 能源效率, 循环经济

**Comment:** 26 Pages, 6 Tables

> **TL;DR:** 绿色计算通过节能硬件、AI优化数据中心和循环电子废物系统，将计算转变为净碳汇，可实现40-60%的能耗降低，并强调了现有解决方案的益处、系统性障碍以及下一代创新的潜力，提供了一个加速转型的实用框架。

**AI_Comments:** 该论文清晰地阐述了绿色计算在应对气候变化中的重要性，并提供了一个实用的框架。其创新点在于将计算视为“碳消除器”，而不仅仅是减少排放的工具，并结合了新兴技术如量子计算和生物可降解电子产品。论文的价值在于其对现有技术和未来潜力的全面分析，以及对系统性障碍和协调行动的呼吁。

<details>
  <summary>Details</summary>

**Motivation:** 数字经济在技术进步的同时需要脱碳，而绿色计算是实现这一目标的关键途径。该研究旨在探讨可持续IT策略如何将计算转变为净碳汇，以应对气候危机并实现可持续发展。

**Method:** 本文通过分析行业最佳实践和新兴技术（如量子计算和可生物降解电子产品），探讨了可持续IT策略，并展示了能耗降低的潜力。研究还识别了关键发现并提出了一个实用框架。

**Result:** 研究发现：(1) 当前的解决方案已经带来了环境和经济效益，典型投资回收期为3-5年；(2) 系统性障碍（如成本溢价和政策碎片化）需要协调行动；(3) 下一代创新有望实现效率的数量级提升。文章展示了在不影响性能的情况下，能耗可降低40-60%。

**Conclusion:** 战略性投资绿色IT今天可以为明天所有部门带来不成比例的可持续性红利。计算通过其快速创新周期和可衡量的影响，具有作为气候解决方案的独特潜力，该工作为采取紧急行动提供了令人信服的理由，并为实现计算作为强大碳消除工具的潜力提供了清晰的路线图。

> **ai_Abstract:** 本文探讨了绿色计算作为数字经济脱碳的关键途径，通过分析节能硬件、AI优化数据中心和循环电子废物系统等可持续IT策略，证明了在不牺牲性能的前提下，能耗可降低40-60%。研究强调了现有解决方案的环境和经济效益，指出了成本和政策碎片化等系统性障碍，并展望了下一代创新带来的效率提升。文章提出了一个实践框架，旨在加速各利益相关方的绿色转型，并最终强调了计算作为应对气候危机的强大碳消除工具的潜力。

> **摘要翻译:** 绿色计算代表了在保持技术进步的同时实现数字经济脱碳的关键途径。本文探讨了包括节能硬件、人工智能优化数据中心和循环电子废物系统在内的可持续IT策略如何将计算转变为净碳汇。通过对行业最佳实践和量子计算、可生物降解电子产品等新兴技术的分析，我们证明了在不影响性能的情况下，能耗可实现40-60%的降低。研究强调了三个关键发现：(1) 当前的解决方案已经带来了环境和经济效益，典型投资回收期为3-5年；(2) 包括成本溢价和政策碎片化在内的系统性障碍需要协调行动；(3) 下一代创新有望实现效率的数量级提升。我们提出了一个实用框架，供从采用可再生能源云服务的公司到延长设备寿命的个人等利益相关者加速转型。该研究强调了计算通过其快速创新周期和可衡量影响，作为气候解决方案的独特潜力，并得出结论：今天对绿色IT的战略投资可以在明天为所有部门带来不成比例的可持续性红利。这项工作为采取紧急行动提供了令人信服的理由，并为实现计算在气候危机时代作为强大碳消除工具的潜力提供了清晰的路线图。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [374] [J4CC, A Frame for Communication Control](https://arxiv.org/abs/2508.00485)
> *J4CC, 一种沟通控制框架*

*Aernout Schmidt, Kunbei Zhang* | **Category: cs.CY, econ.TH, I.2.1** | **Updated: 2025-08-01**

**Keywords:** 沟通控制, 规则制定, 政治冲突, J4CC, 治理分析

**Comment:** 10,583 words, 23 pages

> **TL;DR:** J4CC是一个分析政治对话中规则制定如何受权力、资本、道德和知识四种力量影响的框架，旨在通过明确潜在张力来促进富有成效的交流，并被证明可用于分析失败的政治辩论。

**AI_Comments:** 该论文提出J4CC框架以应对政治中日益增长的不可调和的冲突，其创新之处在于整合了权力、资本、道德和知识这四种核心力量来分析规则制定，并借鉴了多领域的理论基础。其重要性在于提供了一个工具，能够通过揭示深层张力而非消除分歧来促进富有成效的沟通。该框架的最终目标是将其发展为一个AI语言模型，这显示了其前瞻性。目前的局限性在于论文仅关注其概念基础，尚未完全实现AI语言模型的目标。

<details>
  <summary>Details</summary>

**Motivation:** 政治中面临日益增多的看似不可调和的冲突，其中一方的要求与另一方直接矛盾，因此需要一个框架来分析和理解这些冲突，以促进富有成成效的沟通。

**Method:** 提出J4CC框架，用于映射权力、资本、道德和知识这四种力量如何影响规则制定。J4CC提供了一种术语来分析规则制定对话，并借鉴了框架理论、法律理论、制度经济学、人类学和AI领域的思想。通过三个案例研究（有影响力的思想家、美国2025年前5个月的治理动态、以及对治理动态的两种对比解释）来验证其分析能力。

**Result:** 案例研究证实J4CC能够剖析来自不兼容治理哲学的立场，而不会堵塞沟通渠道，有时还能提供翻译机制。该框架不是消除分歧，而是通过明确导致制度冲突的潜在张力来促进富有成效的参与。

**Conclusion:** J4CC当前形式是一个可用于分析失败政治辩论的实用工具。附录中还讨论了J4CC框架通过应用于在大量谈判记录上训练的AI语言模型来发展其预期术语的可行性。

> **ai_Abstract:** 本文提出了J4CC框架，旨在分析政治中看似不可调和的冲突。该框架通过映射权力、资本、道德和知识这四种力量对规则制定的影响，提供了一套分析规则制定对话的术语。J4CC借鉴了多学科思想，并通过对思想家、治理动态及相关解释的三个案例研究，验证了其在剖析不兼容立场、明确潜在张力方面的有效性。研究表明，J4CC能够促进富有成效的沟通，并可作为分析失败政治辩论的实用工具。最终目标是将其发展为AI语言模型。

> **摘要翻译:** 政治日益面临看似不可调和的冲突，其中一方的要求与另一方直接矛盾。我们提出了J4CC，一个用于映射权力、资本、道德和知识这四种力量如何影响规则制定的框架。J4CC为分析规则制定对话提供了一种术语。除了关于框架的思想（Lakoff 2004; Rein & Schön, 1996），它还借鉴了法律理论（Fuller 1967）、制度经济学（Coase 1937）、人类学（Douglas 1992）和AI（Lewis et al. 2020）的思想。虽然我们的最终目标是开发一个可工作且可用的AI语言模型（实际上是一个“术语模型”），但本文目前侧重于其概念基础。我们通过三个案例研究展示了J4CC的分析能力，这些案例研究剖析了看似不兼容的立场。首先是关于有影响力的思想家（孔子、弗里德曼、孟德斯鸠、波普尔、古德费罗）及其环境。然后是治理动态（2025年前5个月的美国）。最后是对此的两种对比解释（Klein-Taylor（2025年）的“末日法西斯主义”与Bobbitt（2025年）的“宪法退化”）。这些研究证实J4CC能够剖析来自不兼容治理哲学的立场，而不会堵塞沟通渠道，有时还能提供翻译机制。该框架不是消除分歧，而是通过明确导致制度冲突的潜在张力来促进富有成效的参与。我们的案例研究得出结论，J4CC当前形式是一个可用于分析失败政治辩论的实用工具。我们在附录中补充了我们关于J4CC框架通过应用于在大量谈判记录上训练的AI语言模型来发展其预期术语的可行性立场。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [397] [Futures with Digital Minds: Expert Forecasts in 2025](https://arxiv.org/abs/2508.00536)
> *数字心智的未来：2025年专家预测*

*Lucius Caviola, Bradford Saad* | **Category: cs.CY** | **Updated: 2025-08-01**

**Keywords:** 数字心智, 专家预测, 人工智能, 社会影响, 意识

**Comment:** 

> **TL;DR:** 一份专家调查报告显示，专家们普遍认为数字心智在本世纪内出现可能性很高，并可能带来巨大的社会影响，因此需要提前做好准备，但调查结果需谨慎解读。

**AI_Comments:** 该研究通过专家调查的形式，对数字心智的未来发展和潜在影响进行了前瞻性预测，具有一定的创新性和重要性，为相关领域的研究和政策制定提供了初步的证据基础。然而，其主要局限性在于调查结果可能存在专家选择性偏差，即可能过度代表了那些认为数字心智更可能或更重要的专家，这可能影响预测的客观性。

<details>
  <summary>Details</summary>

**Motivation:** 该报告的动机是为世界应对数字心智的潜在到来提供证据，并强调将其作为研究和治理等领域的优先事项。

**Method:** 该研究于2025年初对67位数字心智研究、AI研究、哲学、预测及相关领域的专家进行了调查，收集了他们关于数字心智发展、特征和社会影响的概率预测和定性推理。

**Result:** 专家们认为数字心智原则上是可能的（中位数90%），并且很可能在本世纪内被创造（到2100年有65%的可能性），到2030年出现的可能性为20%。他们预测数字心智的集体福利能力在首个数字心智诞生后十年内可能达到数十亿人类的水平。专家们还预计数字心智会广泛提出意识和权利的主张，并预测社会对其存在和道德利益会产生重大分歧。对于数字心智的福利是净积极还是净消极，专家们的观点存在分歧。

**Conclusion:** 这些发现为世界应将为数字心智的潜在到来做好准备作为研究和治理等领域的优先事项提供了证据。然而，鉴于可能系统性地过度代表那些认为数字心智特别可能或重要的专家，这些发现应谨慎解读。

> **ai_Abstract:** 本报告基于2025年初对67位专家的调查，探讨了数字心智的未来。调查结果显示，专家们普遍认为数字心智原则上可行且很可能在本世纪内出现，并预测其福利能力将快速增长，以及可能引发关于意识、权利和社会分歧的问题。报告指出，这些发现支持将为数字心智的到来做准备作为优先事项，但也提醒读者需谨慎解读结果，考虑到潜在的专家偏差。

> **摘要翻译:** 本报告介绍了关于数字心智腾飞情景的专家调查结果。该调查于2025年初进行，共有67位数字心智研究、人工智能研究、哲学、预测及相关领域的专家参与。参与者提供了关于数字心智（即能够拥有主观体验的计算机系统）的发展、特征和社会影响的概率预测和定性推理。专家们认为数字心智原则上是可能的（中位数90%），并将在本世纪内被创造（到2100年有65%的可能性），到2030年出现的可能性为20%。许多人预计数字心智福利能力将快速增长，在第一个数字心智诞生后的十年内，其集体福利能力可能与数十亿人类匹敌。参与者还预计数字心智会广泛提出对其意识和权利的主张，并预测社会对其存在和道德利益会产生重大分歧。关于数字心智的福利是净积极还是净消极，观点存在分歧。这些发现提供了证据，表明在研究和治理等领域，为数字心智的潜在到来做好准备应在多大程度上成为优先事项。然而，鉴于可能系统性地过度代表那些认为数字心智特别可能或重要的专家，这些发现应谨慎解读。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [422] [Towards Efficient Certification of Maritime Remote Operation Centers](https://arxiv.org/abs/2508.00543)
> *迈向海事远程操作中心的高效认证*

*Christian Neurohr, Marcel Saager, Lina Putze, Jan-Patrick Osterloh, Karina Rothemann, Hilko Wiards, Eckard Böde, Axel Hahn* | **Category: cs.CY, cs.RO** | **Updated: 2025-08-01**

**Keywords:** 海事远程操作中心, 认证, 危险数据库, 危险分析, 风险评估

**Comment:** 

> **TL;DR:** 本文提出了一个用于支持海事远程操作中心安全保障和认证的危险数据库概念，该概念基于危险源分类和初步适用性分析。

**AI_Comments:** 本文提出了一个支持海事远程操作中心认证的危险数据库概念，其创新点在于将危险源分类与适用的危险分析和风险评估方法相结合，为新兴的远程操作模式提供了重要的安全保障基础。该研究对于未来自动化航运的安全性和规范化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着船舶自动化程度的提高，船员将从船上转移到岸上，但自动化船舶仍需进行监控和远程控制。这些任务由岸基远程操作中心的人员执行。因此，需要一个支持这些远程操作中心安全保障和认证的系统。

**Method:** 本文提出了一个危险数据库的概念，以支持远程操作中心的安全保障和认证。该概念基于从通用功能架构中推导出的危险源分类。随后，进行了初步适用性分析，以揭示哪些危险分析和风险评估方法可以充分填充此危险数据库。

**Result:** 初步适用性分析揭示了哪些危险分析和风险评估方法可以充分填充所提出的危险数据库。

**Conclusion:** 该研究提出的危险数据库概念能够支持海事远程操作中心的安全保障和认证。

> **ai_Abstract:** 本文针对船舶自动化导致船员转移至岸基远程操作中心的需求，提出了一个支持此类中心安全保障和认证的危险数据库概念。该概念基于从通用功能架构中推导出的危险源分类，并通过初步适用性分析确定了适合填充该数据库的危险分析和风险评估方法。

> **摘要翻译:** 船舶中正在构建的额外自动化意味着船员从船上转移到岸上。然而，自动化船舶仍然必须被监控，并且在某些情况下需要远程控制。这些任务由位于岸基远程操作中心的人员执行。在这项工作中，我们提出了一个危险数据库的概念，以支持此类远程操作中心的安全保障和认证。该概念基于我们从通用功能架构中推导出的危险源分类。随后的初步适用性分析揭示了哪些危险分析和风险评估方法可以充分填充此危险数据库。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [457] [Cost-Effective, Low Latency Vector Search with Azure Cosmos DB](https://arxiv.org/abs/2505.05885)
> *使用 Azure Cosmos DB 实现经济高效、低延迟的向量搜索*

*Nitish Upreti, Harsha Vardhan Simhadri, Hari Sudan Sundar, Krishnan Sundaram, Samer Boshra, Balachandar Perumalswamy, Shivam Atri, Martin Chisholm, Revti Raman Singh, Greg Yang, Tamara Hass, Nitesh Dudhey, Subramanyam Pattipaka, Mark Hildebrand, Magdalen Manohar, Jack Moffitt, Haiyang Xu, Naren Datha, Suryansh Gupta, Ravishankar Krishnaswamy, Prashant Gupta, Abhishek Sahu, Hemeswari Varada, Sudhanshu Barthwal, Ritika Mor, James Codella, Shaun Cooper, Kevin Pilch, Simon Moreno, Aayush Kataria, Santosh Kulkarni, Neil Deshpande, Amar Sagare, Dinesh Billa, Zishan Fu, Vipul Vishal* | **Category: cs.DB, cs.IR, H.3.3** | **Updated: 2025-07-31**

**Keywords:** 向量搜索, Azure Cosmos DB, DiskANN, 云原生数据库, 低延迟

**Comment:** 

> **TL;DR:** 本文提出了一种在 Azure Cosmos DB 等云原生操作数据库中构建高效、低成本向量搜索系统的方法，通过深度集成 DiskANN 库，实现了低延迟、高召回率和显著的成本节约，并支持数十亿向量的扩展。

**AI_Comments:** 本文的创新之处在于，它通过将先进的向量索引技术深度集成到现有的云原生操作数据库（Azure Cosmos DB）中，挑战了专业向量数据库的必要性。这提供了一种利用现有分布式数据库优势（如高可用性、持久性和可伸缩性）同时实现高性能和成本效益向量搜索的替代方案。其结果具有重要的实践意义，为其他数据库集成向量索引提供了蓝图。

<details>
  <summary>Details</summary>

**Motivation:** 向量索引已成为数据库的重要接口，而高效的向量搜索需要深入的数据库系统优化。虽然出现了专门的向量数据库，但本文旨在证明可以在现有的云原生操作数据库中构建可扩展、高性能且经济高效的向量搜索系统，同时利用分布式数据库的优势。

**Method:** 通过将最先进的向量索引库 DiskANN 深度集成到 Azure Cosmos DB NoSQL 中。该系统在每个分区使用单个向量索引，存储在现有索引树中并与底层数据保持同步。

**Result:** 该系统支持对千万级向量索引进行小于 20 毫秒的查询延迟，在更新时具有稳定的召回率，并且与 Pinecone 和 Zilliz 无服务器企业产品相比，查询成本分别降低了约 43 倍和 12 倍。它还可以通过自动分区扩展到数十亿向量。

**Conclusion:** 这种融合设计支持将向量索引集成到操作数据库中，为关于专业向量数据库的近期辩论提供了一个论据，并为其他数据库中的向量索引提供了一个模板。

> **ai_Abstract:** 本文提出了一种在 Azure Cosmos DB 等云原生操作数据库中实现经济高效、低延迟向量搜索的新方法。通过将先进的 DiskANN 向量索引库深度集成到 Azure Cosmos DB NoSQL 内部，该系统利用现有的分布式数据库优势，如高可用性和可伸缩性。实验结果表明，该系统能对千万级向量实现低于 20 毫秒的查询延迟，在更新时保持稳定的召回率，并与现有专业向量数据库产品相比，显著降低了查询成本。该研究为将向量索引集成到通用操作数据库提供了可行的模板。

> **摘要翻译:** 向量索引能够对多样化的语料库进行语义搜索，并已成为用户和 AI 代理的数据库重要接口。高效的向量搜索需要数据库系统进行深度优化。这促使了一类新的专业向量数据库的出现，它们针对向量搜索质量和成本进行优化。相反，我们认为，一个可扩展、高性能且经济高效的向量搜索系统可以在像 Azure Cosmos DB 这样的云原生操作数据库中构建，同时利用分布式数据库的优势，如高可用性、持久性和可伸缩性。我们通过将最先进的向量索引库 DiskANN 深度集成到 Azure Cosmos DB NoSQL 中来实现这一点。该系统在每个分区使用单个向量索引，存储在现有索引树中并与底层数据保持同步。它支持对千万级向量索引进行小于 20 毫秒的查询延迟，在更新时具有稳定的召回率，并且与 Pinecone 和 Zilliz 无服务器企业产品相比，查询成本分别降低了约 43 倍和 12 倍。它还可以通过自动分区扩展到数十亿向量。这种融合设计支持将向量索引集成到操作数据库中，为关于专业向量数据库的近期辩论提供了一个论据，并为其他数据库中的向量索引提供了一个模板。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [487] [Meaningful Data Erasure in the Presence of Dependencies](https://arxiv.org/abs/2507.00343)
> *在存在依赖关系的情况下有意义的数据删除*

*Vishal Chakraborty, Youri Kaminsky, Sharad Mehrotra, Felix Naumann, Faisal Nawab, Primal Pappachan, Mohammad Sadoghi, Nalini Venkatasubramanian* | **Category: cs.DB** | **Updated: 2025-08-01**

**Keywords:** 数据删除, GDPR, 数据依赖, 隐私, 数据库

**Comment:** VLDB 2025 Preprint

> **TL;DR:** 该论文定义了数据库中的数据删除概念和机制，确保已删除数据不能从剩余数据中推断出来，以解决GDPR合规性问题。

**AI_Comments:** 该论文为“有意义的数据删除”提供了一个至关重要的正式定义，鉴于数据隐私法规中的模糊性，这是一项重大贡献。其专注于防止因依赖关系导致已删除数据被推断出来，这一点具有创新性，并且与数据库系统高度相关。实践演示突出了其适用性。

<details>
  <summary>Details</summary>

**Motivation:** GDPR等数据法规要求系统支持数据删除，但“删除”的定义模糊不清。在数据库中，数据依赖关系可能导致已删除数据可以从剩余数据中推断出来，从而使合规性变得困难。

**Method:** 论文正式定义了精确的数据删除概念，确保通过依赖关系对已删除数据的任何推断都受到限制。它设计了以最小成本实现此保证的删除机制，并探索了平衡成本和吞吐量、批量删除以及主动计算数据保留时间的策略。

**Result:** 使用真实和合成数据集证明了算法的实用性和可扩展性。

**Conclusion:** 该论文为在存在依赖关系的情况下有意义的数据删除提供了正式定义和实用机制，解决了合规性挑战并展示了可扩展性。

> **ai_Abstract:** 本文针对GDPR等法规对“数据删除”定义的模糊性，特别是在存在数据依赖关系的数据库中，提出了解决方案。它正式定义了一个精确的数据删除概念，确保已删除数据不会从剩余数据中被推断出来。论文设计了低成本的删除机制，并探讨了平衡成本与吞吐量、批量处理删除以及主动计算数据保留时间的策略，并通过真实和合成数据集验证了其算法的实用性和可扩展性。

> **摘要翻译:** GDPR等数据法规要求系统支持数据删除，但对“删除”的定义开放解释。这种模糊性使得合规性充满挑战，特别是在数据库中，数据依赖关系可能导致已删除数据可以从剩余数据中推断出来。我们正式定义了一个精确的数据删除概念，确保通过依赖关系对已删除数据的任何推断，都限制在数据插入之前可以推断的范围内。我们设计了以最小成本执行此保证的删除机制。此外，我们探索了平衡成本和吞吐量、批量删除以及在可能时主动计算数据保留时间的策略。我们使用真实和合成数据集证明了我们算法的实用性和可扩展性。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [567] [Integrated user scheduling and beam steering in over-the-air federated learning for mobile IoT](https://arxiv.org/abs/2508.00341)
> *移动物联网中空口联邦学习的集成用户调度与波束赋形*

*Shengheng Liu, Ningning Fu, Zhonghao Zhang, Yongming Huang, Tony Q. S. Quek* | **Category: cs.DC** | **Updated: 2025-08-01**

**Keywords:** 联邦学习, 空口计算, 用户调度, 波束赋形, 移动物联网

**Comment:** To appear in ACM TOIT. 24 pages, 8 figures

> **TL;DR:** 针对移动物联网中联邦学习的通信效率和推理精度问题，本文提出了一种集成的用户调度和波束赋形方法，并通过低复杂度策略解决了计算负担，实验证明其性能优于现有方法。

**AI_Comments:** 本文的创新点在于将用户调度与波束赋形相结合，并将其应用于空口联邦学习，以提高聚合效率和解决资源稀缺问题。更重要的是，它通过提出低复杂度策略，解决了迭代优化方法在实际应用中的计算负担问题，提升了实用性。这对于大规模移动物联网中的高效隐私保护型机器学习具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 物联网服务提供商在收集用户敏感数据时面临隐私泄露担忧。联邦学习作为一种去中心化训练范式可解决此问题。本文旨在提高空口联邦学习的聚合效率，并解决大规模网络中无线资源稀缺导致的用户调度和模型传输效率问题。

**Method:** 提出了一种集成的用户调度和接收波束赋形方法，受限于所选用户数量和发射功率。利用差分凸技术将原非凸优化问题分解为两个子问题，得到迭代解。为克服计算负担，进一步提出了一种基于无线信道特性分析的低复杂度用户调度策略，无需迭代直接确定用户子集。

**Result:** 广泛的实验验证了所提方法在聚合误差和学习性能方面优于现有方法。

**Conclusion:** 本文通过集成用户调度和波束赋形，并引入低复杂度策略，有效提高了移动物联网中空口联邦学习的聚合效率和学习性能。

> **ai_Abstract:** 本文针对移动物联网中联邦学习的隐私保护和通信效率问题，提出了一种集成的空口联邦学习用户调度与接收波束赋形方法。该方法旨在优化通信效率和推理精度，通过差分凸优化技术解决非凸问题，并进一步提出了一种低复杂度的用户调度策略以降低计算负担。实验结果表明，所提出的方法在聚合误差和学习性能方面均优于现有方法。

> **摘要翻译:** 物联网（IoT）日益普及，推动了移动互联网和互联系统的技术进步。物联网服务提供商在提供跨领域灵活连接和智能应用的同时，必须从用户那里收集大量敏感数据，但这同时也引发了对隐私泄露的担忧。联邦学习（FL）已成为一种有前景的去中心化训练范式来解决这一挑战。这项工作通过在FL框架中引入空口计算来提高分布式局部模型的聚合效率。由于大规模网络中无线资源稀缺，每轮训练中只有一部分用户可以参与。这突出了有效用户调度和模型传输策略的必要性，以优化通信效率和推理精度。为了解决这个问题，我们提出了一种集成的用户调度和接收波束赋形方法，受限于所选用户数量和发射功率。利用差分凸技术，我们将原始非凸优化问题分解为两个子问题，从而得到一个迭代解。尽管有效，但迭代方法的计算负载阻碍了其实际实现。为了克服这一点，我们进一步提出了一种基于无线信道特性分析的低复杂度用户调度策略，无需迭代直接确定用户子集。广泛的实验验证了所提方法在聚合误差和学习性能方面优于现有方法。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [592] [Tetris: Efficient Intra-Datacenter Calls Packing for Large Conferencing Services](https://arxiv.org/abs/2508.00426)
> *俄罗斯方块：大型会议服务中数据中心内部呼叫的高效打包*

*Rohan Gandhi, Ankur Mallick, Ken Sueda, Rui Liang* | **Category: cs.DC** | **Updated: 2025-08-01**

**Keywords:** 会议服务, 呼叫打包, 数据中心, 资源管理, 优化

**Comment:** 

> **TL;DR:** Tetris提出了一种多步骤框架，通过优化初始呼叫分配和定期迁移热点媒体处理器上的呼叫，显著减少了大型会议服务中热点媒体处理器的使用，解决了现有算法导致性能下降和成本增加的问题。

**AI_Comments:** 该论文的创新之处在于通过结合历史数据进行初始分配和使用线性优化进行动态迁移，解决了CPU使用量可变性和突发呼叫到达的问题。这是一种针对大规模系统实用且有效的方法，对于确保会议服务的高性能和成本效益具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型会议服务（如Zoom、Microsoft Teams、Google Meet）每天处理数百万次通话，但以低成本确保高性能仍然是一个重大挑战。现有算法在媒体处理器（MP）服务器上打包呼叫时，容易导致部分MP过热（CPU利用率高），从而导致性能下降和/或托管成本增加。这个问题源于忽略了呼叫之间CPU使用量的可变性（受参与者数量和媒体类型影响）以及突发性呼叫到达。

**Method:** 本文提出了Tetris，一个多步骤框架：(a) 利用历史数据优化初始呼叫分配；(b) 使用线性优化定期从过热的MP迁移呼叫，旨在最小化过热MP的使用。

**Result:** 基于一个数据中心内超过1000万次呼叫的24小时跟踪评估显示，Tetris将过热MP上的参与者数量减少了至少2.5倍。

**Conclusion:** Tetris框架通过优化大型会议服务中的呼叫打包和迁移，有效解决了媒体处理器过热的挑战，从而提高了性能并降低了成本。

> **ai_Abstract:** 本文提出了Tetris，一个多步骤框架，旨在解决大型会议服务中媒体处理器因呼叫分配不当导致过载（热点MP）的问题。通过利用历史数据优化初始呼叫分配，并结合线性优化定期迁移热点MP上的呼叫，Tetris显著降低了热点MP的使用。实验结果表明，Tetris能将热点MP上的参与者数量减少至少2.5倍，从而提高性能并降低成本。

> **摘要翻译:** 会议服务如Zoom、Microsoft Teams和Google Meet每天促成数百万次通话，然而以低成本确保高性能仍然是一个重大挑战。本文重新审视了在单个数据中心（DC）内托管呼叫的媒体处理器（MP）服务器之间打包呼叫的问题。我们发现，Teams（一个大型会议服务）以及其他最先进算法中使用的算法容易导致呼叫放置不当，使得一些MP变得过热（CPU利用率高），从而导致性能下降和/或托管成本升高。这个问题源于忽略了呼叫之间CPU使用量的可变性，这种可变性受到参与者数量和媒体类型（音频/视频）差异的影响，并因突发性呼叫到达而加剧。为了解决这个问题，我们提出了Tetris，一个多步骤框架，它(a) 通过利用历史数据优化初始呼叫分配，以及(b) 使用线性优化定期从过热的MP迁移呼叫，旨在最小化过热MP的使用。基于一个数据中心内超过1000万次呼叫的24小时跟踪评估显示，Tetris将过热MP上的参与者数量减少了至少2.5倍。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [617] [SwarnRaft: Leveraging Consensus for Robust Drone Swarm Coordination in GNSS-Degraded Environments](https://arxiv.org/abs/2508.00622)
> *SwarnRaft：利用共识实现GNSS降级环境下无人机群的鲁棒协调*

*Kapel Dev, Yash Madhwal, Sofia Shevelo, Pavel Osinenko, Yury Yanovich* | **Category: cs.DC** | **Updated: 2025-08-01**

**Keywords:** 无人机群, GNSS受损, Raft共识, SwarnRaft, 容错性

**Comment:** 

> **TL;DR:** SwarnRaft提出一个受区块链启发的共识框架，利用Raft算法在GNSS信号受损环境下，确保无人机群的协调和数据完整性，提高鲁棒性和容错性。

**AI_Comments:** SwarnRaft的创新之处在于将区块链启发的共识机制（特别是Raft算法）应用于无人机群的定位和协调，以应对GNSS信号中断的挑战。这种方法为在恶劣或对抗性环境中实现无人机群的自主和鲁棒操作提供了新的视角和实用方案，显著提升了系统的可靠性和安全性。其轻量级和可扩展的特性也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 无人机（UAV）群在关键应用中日益普及，但其可靠性高度依赖全球导航卫星系统（GNSS）信号。在现实场景中，GNSS信号可能因干扰、环境条件或恶意攻击而中断，导致无人机迷失方向、碰撞风险和任务失败。

**Method:** 本文提出了SwarnRaft，一个受区块链启发的定位和共识框架，用于在GNSS受损条件下维护无人机群的协调和数据完整性。SwarnRaft利用Raft共识算法，使分布式无人机（节点）即使在部分节点没有GNSS信号的情况下也能就位置和航向等状态更新达成一致。在原型系统中，每个节点使用GNSS和本地传感，并通过WiFi在模拟蜂群中通信。当信号丢失时，系统利用共识机制，根据故障节点最后已知状态和轨迹来重建或验证其位置。

**Result:** SwarnRaft系统通过轻量级、可扩展的通信模型，在维护无人机群的连贯性和容错性方面表现出鲁棒性。

**Conclusion:** 这项工作为在不可预测环境中进行去中心化无人机操作提供了实用且安全的基础。

> **ai_Abstract:** SwarnRaft提出了一种创新的、受区块链启发的框架，旨在解决无人机（UAV）群在GNSS信号受损环境下的协调和数据完整性问题。该系统利用Raft共识算法，使分布式无人机即使在GNSS信号丢失的情况下也能就自身状态（如位置和航向）达成一致。通过结合GNSS和本地传感，并在信号丢失时利用共识重建或验证位置，SwarnRaft在模拟环境中展示了维护蜂群连贯性和高容错性的能力。这项研究为在复杂多变的环境中实现去中心化、鲁棒的无人机操作奠定了基础。

> **摘要翻译:** 无人机（UAV）群日益被用于航空测绘、环境监测和自主配送等关键应用。然而，这些系统的可靠性高度依赖于全球导航卫星系统（GNSS）信号的持续接入，而GNSS信号在现实场景中可能因干扰、环境条件或恶意攻击而中断，导致无人机迷失方向、碰撞风险和任务失败。本文提出了SwarnRaft，一个受区块链启发的定位和共识框架，用于在GNSS信号受损条件下维护无人机群的协调和数据完整性。SwarnRaft利用Raft共识算法，使分布式无人机（节点）即使在部分或多个节点没有GNSS信号的情况下也能就位置和航向等状态更新达成一致。在我们的原型系统中，每个节点使用GNSS和本地传感，并通过WiFi在模拟蜂群中通信。当信号丢失时，共识机制被用于根据故障节点最后已知状态和轨迹来重建或验证其位置。我们的系统通过轻量级、可扩展的通信模型，在维护无人机群的连贯性和容错性方面表现出鲁棒性。这项工作为在不可预测环境中进行去中心化无人机操作提供了实用且安全的基础。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [705] [SGEMM-cube: Emulating FP32 GEMM on Ascend NPUs Using FP16 Cube Units with Precision Recovery](https://arxiv.org/abs/2507.23387)
> *SGEMM-cube：在昇腾NPU上使用FP16 Cube单元模拟FP32 GEMM并恢复精度*

*Weicheng Xue, Baisong Xu, Kai Yang, Yongxiang Liu, Dengdeng Fan, Pengxiang Xu, Yonghong Tian* | **Category: cs.DC** | **Updated: 2025-08-01**

**Keywords:** SGEMM-cube, FP32 GEMM, FP16 Cube, 精度恢复, 昇腾NPU

**Comment:** 

> **TL;DR:** SGEMM-cube提出了一种高性能算法，利用FP16计算单元在昇腾NPU上模拟FP32通用矩阵乘法（GEMM），通过分解操作数、误差补偿和优化计算顺序，实现了接近理论峰值的性能和FP32的精度。

**AI_Comments:** 这项工作的创新之处在于，它通过巧妙的FP32到FP16分解、误差补偿和计算顺序优化，在不具备原生FP32支持的硬件上实现了高性能和高精度的FP32 GEMM。这对于利用现有低精度硬件执行高精度计算任务具有重要意义，尤其是在AI加速器领域。其在性能恢复和数值稳定性方面的表现是亮点。

<details>
  <summary>Details</summary>

**Motivation:** 低精度矩阵引擎（如FP16 cube）虽然吞吐量高，但缺乏对全精度计算的支持，因此需要一种方法在这些硬件上实现FP32 GEMM。

**Method:** 该方法将每个FP32操作数分解为两个FP16值，并通过可调缩放策略补偿数值误差。通过详细分析数值误差（包括下溢条件和精度损失），指导缩放参数的选择以保留高达22位的尾数精度。研究了计算顺序对精度的影响，并引入了逐项累加方案来改善数值稳定性。此外，还引入了缓存感知阻塞策略和双缓冲流水线，以重叠内存传输和计算。

**Result:** SGEMM-cube在缺乏原生FP32支持的昇腾910A NPU上，实现了高达FP32理论峰值性能的77%。数值实验证实，该方法不仅恢复了原生FP32 GEMM的精度，而且在某些条件下表现出优于传统FP32 GEMM的数值稳定性。

**Conclusion:** SGEMM-cube成功地在只支持FP16的AI加速器上模拟了高性能且高精度的FP32 GEMM，通过创新的分解、误差补偿和计算顺序优化，实现了卓越的性能和稳定性。

> **ai_Abstract:** SGEMM-cube是一种在仅支持FP16的AI加速器（如昇腾NPU）上高效模拟FP32 GEMM的算法。它通过将FP32操作数分解为FP16值、引入可调缩放策略以补偿误差和恢复精度、优化计算顺序以提高稳定性，并采用缓存优化策略来提升性能。该方法在昇腾910A NPU上达到了接近FP32理论峰值的性能，并被证明在精度和某些条件下的数值稳定性上优于原生FP32 GEMM。

> **摘要翻译:** 低精度矩阵引擎，如FP16 cube，提供高吞吐量但缺乏对全精度计算的支持。在这项工作中，我们提出了SGEMM-cube，这是一种高性能算法，仅使用代表性AI加速器上的FP16计算单元来模拟FP32通用矩阵乘法（GEMM）。该方法将每个FP32操作数分解为两个FP16值，并通过可调缩放策略补偿数值误差。对数值误差（包括下溢条件和精度损失）的详细分析指导了缩放参数的选择，以保留高达22位的尾数精度。我们进一步研究了计算顺序对精度的影响，并证明逐项累加方案在低指数范围内比传统的FP32 GEMM更能提高数值稳定性。最后，引入了缓存感知阻塞策略和双缓冲流水线，以重叠内存传输与计算，使SGEMM-cube在缺乏原生FP32支持的昇腾910A NPU上达到FP32等效理论峰值性能的77%。广泛的数值实验证实，由于其结构化和误差感知的计算顺序，我们的方法不仅恢复了原生FP32 GEMM的精度，而且在某些条件下表现出卓越的数值稳定性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [97] [Finding One Local Optimum Is Easy -- But What about Two?](https://arxiv.org/abs/2507.07524)
> *找到一个局部最优解很容易——但两个呢？*

*Yasuaki Kobayashi, Kazuhiro Kurita, Yutaro Yamaguchi* | **Category: cs.DS, cs.CC** | **Updated: 2025-08-01**

**Keywords:** 局部搜索, PLS, NP难, 局部最优解, 组合优化

**Comment:** 16 pages

> **TL;DR:** 对于许多无权局部搜索问题，找到一个局部最优解很容易，但找到两个局部最优解是NP难的。

**AI_Comments:** 这篇论文的创新点在于将局部搜索的复杂度分析从“找到一个局部最优解”扩展到“找到两个局部最优解”，揭示了即使在无权问题中，寻找多个局部最优解也可能面临NP难的计算挑战，为局部搜索理论提供了新的视角和更深层次的理解。

<details>
  <summary>Details</summary>

**Motivation:** 虽然局部搜索理论中寻找一个局部最优解的复杂度（PLS类）已被广泛研究，且对于无权问题通常可在多项式时间内找到一个局部最优解，但本文旨在从不同角度探索局部搜索问题的复杂度，即寻找两个局部最优解的计算难度。

**Method:** 本文通过证明对于多种自然的无权局部搜索问题（如最大独立集、最小支配集、最大可满足性、最大割），计算两个局部最优解是NP难的，来探讨其复杂度。作者也讨论了寻找两个或更多局部最优解的一些可处理情况。

**Result:** 研究结果表明，对于最大独立集、最小支配集、最大可满足性、最大割等多种自然的无权局部搜索问题，计算两个局部最优解是NP难的。此外，论文也指出了寻找两个（或更多）局部最优解的几种可处理情况。

**Conclusion:** 本文揭示了寻找两个局部最优解的计算复杂度显著高于寻找一个局部最优解，对于许多无权局部搜索问题，后者是NP难的，这为局部搜索理论带来了新的视角。

> **ai_Abstract:** 本文深入探讨了在局部搜索问题中寻找多个局部最优解的计算复杂度。研究指出，尽管对于无权问题，寻找一个局部最优解通常可以在多项式时间内完成，但对于包括最大独立集和最大割在内的多种自然无权局部搜索问题，计算两个局部最优解被证明是NP难的。同时，文章也探讨了在特定情况下寻找两个或更多局部最优解的可行性。

> **摘要翻译:** PLS（多项式局部搜索）类捕捉了寻找局部最优解的复杂性，并已被证明是局部搜索理论中的一个重要概念。研究表明，各种组合优化问题（如最大独立集和最大割）的局部搜索版本对于此类是完全的。这种计算上的难处理性通常出现在允许任意权重的局部搜索问题中；相比之下，对于无权问题，在标准设置下可以在多项式时间内找到局部最优解。在本文中，我们从一个不同的角度探讨局部搜索问题的复杂性：我们证明了对于各种自然的无权局部搜索问题，包括最大独立集、最小支配集、最大可满足性、最大割，计算两个局部最优解是NP难的。我们还讨论了找到两个（或更多）局部最优解的几种可处理情况。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [168] [From Dynamic Programs to Greedy Algorithms](https://arxiv.org/abs/2508.00776)
> *从动态规划到贪婪算法*

*Dieter van Melkebeek* | **Category: cs.DS** | **Updated: 2025-08-01**

**Keywords:** 动态规划, 贪婪算法, 贝尔曼方程, 区间调度, 算法教学

**Comment:** 14 pages, 2 figures

> **TL;DR:** 本文展示了如何通过扩展动态规划的贝尔曼方程，从通用的动态规划简单地推导出特定情况下的经典贪婪算法。

**AI_Comments:** 这篇论文提供了一种优雅且具有教学意义的方法来连接动态规划和贪婪算法，这两种算法范式在算法设计中都非常重要。它不仅展示了如何推导贪婪算法，更重要的是揭示了它们与动态规划之间的深层联系，这对于学生理解算法原理非常有帮助。通过贝尔曼方程和单调性的视角，使得贪婪选择的“正确性”变得更加直观。

<details>
  <summary>Details</summary>

**Motivation:** 提供一种替代方法，用于在本科算法课程中开发和/或论证贪婪算法的正确性。

**Method:** 通过重复扩展动态规划底层的贝尔曼方程，并利用简单的单调性属性来确定在特定限制下哪些项能产生最优值。具体案例包括区间调度（单位权重）、背包问题（单位价值）和最短路径（非负边长）。

**Result:** 成功地从动态规划中推导出了特殊情况下的经典贪婪算法，并阐明了区间调度中从最早开始时间到最早结束时间排序的变化。

**Conclusion:** 该方法为理解和教授贪婪算法提供了一种新的视角，尤其是在本科算法课程中。

> **ai_Abstract:** 本文提出了一种新颖的方法，通过扩展动态规划的贝尔曼方程并利用单调性，从通用动态规划中推导出特殊情况下的经典贪婪算法。作者以区间调度、背包问题和最短路径为例，展示了如何简化和理解这些算法。这种方法为本科算法教学提供了另一种视角，并有助于理解贪婪算法的正确性，例如在区间调度中揭示了排序准则的变化。

> **摘要翻译:** 我们展示了针对几个计算问题，如何从一般情况的动态规划中以简单的方式推导出特殊情况下的经典贪婪算法：区间调度（限于单位权重）、背包问题（限于单位价值）和最短路径（限于非负边长）。从概念上讲，我们重复扩展动态规划底层的贝尔曼方程，并利用简单的单调性属性来找出在各自限制下哪些项能产生最优值。该方法为本科算法课程中开发这些贪婪算法和/或论证其正确性提供了一种替代方案。在区间调度的背景下，它阐明了从记忆化动态规划的最早开始时间优先到贪婪算法的最早结束时间优先的顺序变化。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [201] [TGLib: An Open-Source Library for Temporal Graph Analysis](https://arxiv.org/abs/2209.12587)
> *TGLib：一个用于时态图分析的开源库*

*Lutz Oettershagen, Petra Mutzel* | **Category: cs.DS** | **Updated: 2025-08-01**

**Keywords:** 时态图, 开源库, 图分析, 动态网络, TGLib

**Comment:** TGLib is now easily installable via pip (pip install
  temporalgraphlib). This revision adds PyPI installation instructions, a
  Python usage example, and minor improvements for clarity

> **TL;DR:** TGLib是一个开源库，旨在为时态图分析提供高效且易于使用的C++和Python算法实现。

**AI_Comments:** TGLib的创新之处在于其作为一个开源库，专注于提供高效的时态图分析工具，并提供多语言接口，降低了该领域研究和应用的门槛。其重要性体现在满足了日益增长的时态网络分析需求，为研究人员和实践者提供了便捷的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，对时态图的分析兴趣日益增长，为了满足对高效且易于使用的时态图算法实现的需求，作者开发了TGLib。

**Method:** TGLib是一个开源库，它集成了高效的数据结构和算法，用于执行时态图分析中的常见计算任务，如时间距离、中心性度量和网络统计。它提供了C++和Python接口。

**Result:** TGLib是一个高效且多功能的库，提供了简单便捷的C++和Python接口，适用于计算机科学家、从业者、学生和时态网络研究社区。

**Conclusion:** TGLib成功地为时态图分析提供了一个高效且用户友好的开源解决方案，填补了当前对这类工具的需求。

> **ai_Abstract:** TGLib是一个新推出的开源库，专门用于高效分析时态图。它解决了当前对高效且易于使用的时态图算法实现的需求，集成了先进的数据结构和算法，支持计算时间距离、中心性等常见分析任务。该库提供C++和Python接口，旨在服务于广泛的时态网络研究和应用群体。

> **摘要翻译:** 我们启动了一个用于高效分析时态图的开源库。我们考虑了动态网络的一种标准模型，其中每条边都有一个离散的时间戳和转换时间。最近，人们对分析此类时态图产生了浓厚的兴趣。常见的计算数据挖掘和分析任务包括时间距离的计算、中心性度量以及拓扑重叠、突发性或时间直径等网络统计。为了满足对时态图算法高效且易于使用的实现日益增长的需求，我们引入了开源库TGLib，它集成了用于时态图分析的高效数据结构和算法。TGLib高效且多功能，提供简单便捷的C++和Python接口，面向计算机科学家、从业者、学生和（时态）网络研究社区。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [208] [Dynamic Batching of Online Arrivals to Leverage Economies of Scale](https://arxiv.org/abs/2309.16911)
> *在线到达动态批处理以利用规模经济*

*Akhil Bhimaraju, S. Rasoul Etesami, Lav R. Varshney* | **Category: cs.DS, math.OC** | **Updated: 2025-07-31**

**Keywords:** 动态批处理, 规模经济, 在线算法, 最短路径, 竞争分析

**Comment:** 35 pages, accepted for publication by the European Journal of
  Operational Research

> **TL;DR:** 本文研究了如何优化在线到达的批处理，以最小化等待时间和处理成本的总和，同时利用规模经济，提出了离线和在线设置下的有效算法。

**AI_Comments:** 本文的创新之处在于将动态批处理问题分解为离线和在线两个部分，并分别为其提供了理论上严谨的解决方案。离线问题的最短路径转化提供了高效的最优解，而在线算法的竞争力分析则保证了其在实际应用中的鲁棒性。这对于需要权衡等待成本和处理效率的实际系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在网约车平台或视频广告等应用中，处理随时间到达的请求通常需要将这些请求分组批处理，以利用规模经济降低处理成本。然而，等待时间过长会增加等待成本，而过早处理又会错过规模经济。由于下一个到达时间通常未知，固定大小或固定等待时间的批处理效果不佳，因此需要找到最优的批处理策略。

**Method:** 对于离线问题（所有到达时间已知），通过将其转化为加权无环图上的最短路径问题，证明了最优批处理调度可以在多项式时间内找到。对于在线问题（到达时间未知），开发了对广泛处理成本函数具有可证明竞争力的算法。

**Result:** 离线问题的最优批处理调度可在多项式时间内找到。为在线问题开发了具有可证明竞争力的算法，并提供了任何在线算法都无法超越的竞争比下限。在模拟数据和真实数据上的数值实验表明，所提出的算法相对于离线基准是有效的。

**Conclusion:** 本文为在线到达的动态批处理问题提供了有效的解决方案，通过在离线设置中找到多项式时间的最优解，并为在线设置开发了具有竞争力的算法，成功地在等待时间和处理成本之间取得了平衡。

> **ai_Abstract:** 本文研究了在线到达请求的动态批处理问题，旨在最小化等待时间和处理成本的总和，同时利用规模经济。针对所有到达时间已知的离线场景，研究提出了一种可在多项式时间内找到最优批处理调度的方法，将其转化为最短路径问题。对于到达时间未知的在线场景，本文开发了具有可证明竞争力的算法，并给出了竞争比的下限。通过数值实验验证了所提算法的有效性。

> **摘要翻译:** 许多场景，例如网约车平台中的乘客与司机匹配或流媒体视频广告，都需要处理随时间到达的请求。在这些应用中，将到达的订单或请求分组批处理并处理更大的批次，而不是单独处理，通常是有益的。然而，等待时间过长以创建更大的批次会产生先前到达的等待成本。另一方面，过早处理到达的请求会导致更高的处理成本，因为错过了将大量到达请求分组到更大批次中的规模经济。此外，下一个到达的时间通常是未知的，这意味着固定大小的批次或固定的等待时间往往是糟糕的选择。在这项工作中，我们考虑在离线和在线设置下，寻找最优批处理调度以最小化等待时间和处理成本之和的问题。在所有到达时间先验已知的离线问题中，我们表明通过将其简化为加权无环图上的最短路径问题，可以在多项式时间内找到最优批处理调度。对于到达时间未知的在线问题，我们开发了对广泛处理成本函数具有可证明竞争力的算法。我们还提供了任何在线算法都无法超越的竞争比下限。最后，我们在模拟和真实数据上进行了数值实验，以证明我们的算法相对于离线基准的有效性。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [228] [Search Trees on Trees via LP](https://arxiv.org/abs/2501.17563)
> *树上的搜索树通过线性规划*

*Yaniv Sadeh, Haim Kaplan, Uri Zwick* | **Category: cs.DS** | **Updated: 2025-08-01**

**Keywords:** 树上搜索树, 线性规划, 整数性间隙, 近似比, 法线方法

**Comment:** No content change in this version, just added funding information

> **TL;DR:** 本文证明了Golinsky关于树上搜索树线性规划的猜想是错误的，该LP不总是最优解，并给出了LP的整数性间隙和近似比的下限，同时提出了未来研究方向。

**AI_Comments:** 本文通过严谨的数学分析和计算枚举，反驳了一个重要的关于树上搜索树优化问题的线性规划猜想，揭示了该LP的局限性。其“法线方法”的应用是创新的，为理解LP的性质提供了新的工具。研究结果为未来的优化算法设计和理论研究提供了重要的基础和方向。

<details>
  <summary>Details</summary>

**Motivation:** 解决计算最优树上搜索树（STTs）的问题，STTs是二叉搜索树在一般树拓扑上的推广。特别是，本文旨在进一步探究Golinsky提出的用于计算最优STT的线性规划（LP）松弛方法及其猜想。

**Method:** 本文深入分析了Golinsky提出的线性规划方法。通过使用“法线方法”，枚举了节点数不超过8的所有树拓扑下Golinsky多面体的顶点，从而证明了其猜想的错误性。

**Result:** 本文证明了Golinsky的猜想是错误的，即他的线性规划方法不总是给出最优解。此外，本文给出了该LP的整数性间隙和Golinsky舍入方法的近似比的下限。

**Conclusion:** Golinsky提出的用于计算最优树上搜索树的线性规划方法并非总是最优的。文章还提出了未来研究方向，以探讨是否能在多项式时间内计算出最优STT。

> **ai_Abstract:** 本文研究了计算最优树上搜索树（STTs）的问题，特别关注Golinsky提出的线性规划（LP）松弛方法。作者通过“法线方法”对节点数不超过8的树拓扑下的Golinsky多面体顶点进行枚举，证明了Golinsky关于其LP总是给出最优解的猜想是错误的。研究结果表明，该LP不总是提供最优解，并给出了其整数性间隙和Golinsky舍入方法近似比的下限。文章还展望了未来研究方向，以探讨在多项式时间内计算最优STT的可能性。

> **摘要翻译:** 我们考虑计算树上最优搜索树（STTs）的问题。STTs是二叉搜索树（BSTs）的推广，其中我们搜索路径（线性顺序）中的节点，以促进对一般树拓扑的搜索。Golinsky提出了计算给定树拓扑上最优静态STT问题的线性规划（LP）松弛。他使用这个LP公式计算了一个对最优STT的2-近似STT，并推测它实际上是所有STT深度向量凸包的扩展公式，因此总是给出最优解。在这项工作中，我们进一步研究了这种LP方法。我们表明这个猜想是错误的，并且Golinsky的LP并不总是给出最优解。为了证明这一点，我们使用了我们称之为“法线方法”的技术。我们使用这种方法对节点数不超过8的所有树拓扑下的Golinsky多面体的顶点进行了枚举。我们给出了LP的整数性间隙和Golinsky舍入方法的近似比的下限。我们进一步列举了几个研究方向，这些方向可能有助于解决是否能在多项式时间内计算出最优STT的问题。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [248] [Polynomial-Time Constant-Approximation for Fair Sum-of-Radii Clustering](https://arxiv.org/abs/2504.14683)
> *公平半径和聚类的多项式时间常数逼近*

*Sina Bagheri Nezhad, Sayan Bandyapadhyay, Tianzhi Chen* | **Category: cs.DS** | **Updated: 2025-08-01**

**Keywords:** 公平聚类, 半径和, 逼近算法, 多项式时间, 常数逼近

**Comment:** Accepted at 33rd Annual European Symposium on Algorithms (ESA 2025)

> **TL;DR:** 本文首次为公平半径和聚类问题设计了多项式时间常数逼近算法，显著改进了现有结果，并使其与k-中心和k-中位数目标函数在近似性能上保持一致。

**AI_Comments:** 这项工作在公平聚类领域具有重要意义，尤其是在半径和目标函数方面。它通过引入新颖的簇合并分析技术，首次实现了多项式时间常数逼近，填补了该领域的一个空白。这不仅理论上将半径和目标函数与k-中心等其他目标函数对齐，也在实际应用中提供了更高效的算法，克服了先前算法在运行时间上的限制。

<details>
  <summary>Details</summary>

**Motivation:** Chierichetti等人提出了(t,k)-公平聚类问题，并为k-中心和k-中位数目标函数设计了多项式时间常数逼近算法。然而，对于半径和目标函数，Carta等人最近的工作只获得了(6+ε)-逼近且运行时间与k呈指数关系。本文的动机是为(t,k)-公平聚类问题在半径和目标函数上，设计第一个多项式时间O(1)-逼近算法，从而改进Carta等人的结果。

**Method:** 本文采用了一种新颖的基于簇合并的分析技术，以实现常数逼近界限。

**Result:** 1. 设计了针对(t,k)-公平聚类问题在半径和目标函数上的首个多项式时间O(1)-逼近算法，改进了Carta等人的结果。
2. 使得半径和目标函数与k-中心目标函数一样，也支持多项式时间O(1)-逼近。
3. 对于欧几里得版本的公平聚类问题，也得到了多项式时间O(1)-逼近。
4. 当t=1时，该结果可扩展到任意$\\\ell\\\ge 2$种颜色的情况，与k-中心和k-中位数目标的已知结果相符。

**Conclusion:** 本文的成果将半径和目标函数置于与k-中心同等的地位，即它们都允许多项式时间O(1)-逼近。尽管半径和目标函数相比k-中心和k-中位数存在显著差异和复杂挑战，本文成功克服了这些挑战。

> **ai_Abstract:** 本文针对(t,k)-公平聚类问题中的半径和目标函数，提出了首个多项式时间O(1)-逼近算法。该算法显著改进了现有技术，将半径和目标函数的近似性能提升至与k-中心和k-中位数目标函数相同的水平，即均可达到多项式时间常数逼近。研究还进一步将结果推广到多色点集的情况。核心贡献在于开发了一种新颖的基于簇合并的分析技术，成功解决了半径和聚类问题的复杂挑战。

> **摘要翻译:** 在一项开创性工作中，Chierichetti等人引入了$(t,k)$-公平聚类问题：给定度量空间中的一组红点和一组蓝点，如果每个簇中的红点数量最多是蓝点数量的$t$倍，并且至少是蓝点数量的$1/t$倍，则称该聚类是公平的。目标是计算一个最多包含$k$个簇的公平聚类，以优化某个目标函数。考虑到这个问题，他们分别为$k$-中心和$k$-中位数目标设计了多项式时间$O(1)$-和$O(t)$-逼近算法。最近，Carta等人研究了半径和目标函数的这个问题，并获得了$(6+\epsilon)$-逼近，运行时间为$O((k\log_{1+\epsilon}(k/\epsilon))^kn^{O(1)})$，即在$k$上是固定参数可解的。这里$n$是输入大小。在这项工作中，我们为$(t,k)$-公平聚类问题在半径和目标函数上设计了第一个多项式时间$O(1)$-逼近算法，改进了Carta等人的结果。我们的结果将半径和目标函数置于与$k$-中心相同的目标函数组中，即它们都支持多项式时间$O(1)$-逼近。这一结果还意味着对该问题的欧几里得版本也存在多项式时间$O(1)$-逼近，而Drexler等人之前已知的是$f(k)\cdot n^{O(1)}$-时间$(1+\epsilon)$-逼近，其中$f$是$k$的指数函数。当$t=1$时，我们还能够将结果扩展到任意$\\ell\\\ge 2$种颜色的情况。这与在这种情况下$k$-中心和$k$-中位数目标的已知结果相符。半径和目标函数与$k$-中心和$k$-中位数相比存在显著差异，带来了几个复杂的挑战，我们都在工作中成功克服了这些挑战。我们的主要贡献是一种新颖的基于簇合并的半径和分析技术，它帮助我们实现了常数逼近界限。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [1] [Reimagining Voltage-Controlled Cryogenic Boolean Logic Paradigm with Quantum-Enhanced Josephson Junction FETs](https://arxiv.org/abs/2508.00295)
> *利用量子增强约瑟夫森结场效应晶体管重构电压控制低温布尔逻辑范式*

*Md Mazharul Islam, Diego Ferrer, Shamiul Alam, Juan P. Mendez, Denis Mamaluy, Wei Pan, Ahmedullah Aziz* | **Category: cs.ET, cs.AR, physics.app-ph** | **Updated: 2025-08-01**

**Keywords:** 低温电子学, 约瑟夫森结场效应晶体管, 电压控制逻辑, 超导逻辑, 级联性

**Comment:** 

> **TL;DR:** 本文提出并分析了一种基于量子增强约瑟夫森结场效应晶体管（JJFET）的电压控制低温布尔逻辑拓扑，通过引入多层加热器纳米冷子管（nTron）实现可级联性，并成功演示了基本逻辑门和多输入多数门，以及一个2输入异或门。

**AI_Comments:** 这项工作在低温电子学领域具有重要意义，尤其是在解决超导逻辑电路的级联性问题上。通过引入电压控制的JJFETs并结合nTron热开关，为构建复杂、可级联的超导逻辑架构提供了新的途径。其创新之处在于利用量子增强JJFET的特性来克服传统电流控制超导器件的局限性，并为量子和可逆计算的关键组件——多数门——提供了实现方案。这对于未来超低功耗和高性能计算的发展具有潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 当前控制的超导器件在级联性方面面临挑战，限制了其在复杂逻辑架构中的应用。尽管约瑟夫森结场效应晶体管（JJFETs）等栅极可调超导器件有所发展，但实现鲁棒控制和足够的超电流增益仍是关键挑战。

**Method:** 本文利用了基于InAs和GaSb异质结构的新型JJFET设计，该设计具有增强的增益和适合电路集成的特性。研究人员开发了一个基于Verilog A的电路兼容紧凑模型来精确捕捉JJFET的实验特性。为了确保级联性，逻辑电路中集成了多层加热器纳米冷子管（nTron）。通过仿真分析，演示了基本逻辑门（NOT, NAND, NOR）的实现，并设计了一个3输入多数门。最后，通过一个基于JJFET的NOT, NAND, NOR门构建的2输入异或门来展示所提出逻辑拓扑的级联性。

**Result:** 成功实现了NOT, NAND, 和 NOR等基本逻辑门。设计了一个3输入多数门，该门在量子和可逆计算中具有重要作用。通过一个2输入异或门演示了所提出逻辑拓扑的级联性。

**Conclusion:** 本文成功提出了基于量子增强JJFET的电压控制低温布尔逻辑范式，并通过集成nTron解决了级联性问题，为超低功耗计算和量子技术提供了新的逻辑实现方案。

> **ai_Abstract:** 本文提出了一种基于量子增强约瑟夫森结场效应晶体管（JJFET）的新型电压控制低温布尔逻辑范式。针对现有超导器件在级联性上的不足，研究者开发了JJFET的紧凑模型，并结合多层加热器纳米冷子管（nTron）以确保电路的级联性。通过仿真，成功演示了NOT、NAND、NOR等基本逻辑门以及一个3输入多数门，并构建了一个可级联的2输入异或门，为超低功耗和量子计算提供了新的逻辑电路设计方案。

> **摘要翻译:** 对超低功耗计算日益增长的需求以及量子技术的出现，增强了人们对低温电子学，特别是超导器件的兴趣。尽管它们前景广阔，但电流控制的超导元件在级联性方面面临着根本性挑战，限制了它们在复杂逻辑架构中的有效性。为了克服这一点，最近的努力集中于开发栅极可调超导器件，例如约瑟夫森结场效应晶体管（JJFETs）。然而，实现鲁棒控制和足够的超电流增益，这两者对于逻辑电路中类晶体管性能至关重要，仍然是一个关键挑战。基于InAs和GaSb异质结构的一种JJFET设计的新进展，展示了增强的增益和适合电路集成的有利器件特性。基于这一创新，我们提出并分析了利用量子增强JJFET的基本电压控制逻辑拓扑。我们开发了一个基于Verilog A的电路兼容量子增强JJFET紧凑模型，该模型准确地捕获了实验观察到的器件特性。为了确保级联性，我们的逻辑电路中集成了多层加热器纳米冷子管（nTron），这是一种基于超导纳米线的热开关。通过基于仿真的分析，我们展示了基本逻辑门（包括NOT、NAND和NOR）的成功实现。此外，我们设计了一个3输入多数门，该门由于其通用性而在量子和可逆计算中发挥着关键作用。最后，为了展示我们提出的逻辑拓扑的级联性，我们演示了一个基于我们设计的JJFET的NOT、NAND和NOR门的2输入异或门的操作。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [488] [Occlusion-robust Stylization for Drawing-based 3D Animation](https://arxiv.org/abs/2508.00398)
> *基于绘画的3D动画中抗遮挡风格化*

*Sunjae Yoon, Gwanhyeong Koo, Younghwan Lee, Ji Woo Hong, Chang D. Yoo* | **Category: cs.GR, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 3D动画, 风格化, 遮挡鲁棒性, 光流, 绘画动画

**Comment:** 11 pages, 13 figures, ICCV 2025

> **TL;DR:** 本文提出了一个抗遮挡风格化框架（OSF），通过使用光流提供抗遮挡边缘引导，解决了基于绘画的3D动画中因遮挡导致的风格质量下降问题，并实现了更快的推理速度和更少的内存使用。

**AI_Comments:** 本文提出的OSF框架创新性地解决了基于绘画的3D动画在复杂遮挡场景下风格化质量下降的关键问题，通过引入光流进行抗遮挡边缘引导，有效地弥补了训练与推理之间的“姿态差距”。其单次运行的设计不仅提升了效率，也降低了资源消耗，对于提升用户体验和实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于绘画的3D动画方法在处理遮挡（如身体部位重叠）时，风格化质量会下降，导致轮廓闪烁和笔触模糊。这是由于风格化网络在训练和推理之间存在“风格化姿态差距”，即训练时使用无遮挡姿态，而推理时会遇到动态运动中的各种遮挡。

**Method:** 本文提出了抗遮挡风格化框架（OSF）。OSF通过使用光流为风格化网络提供抗遮挡边缘引导，确保即使在遮挡下也能实现一致的风格化。此外，OSF采用单次运行而非传统两阶段方法。

**Result:** OSF实现了比现有两阶段方法快2.4倍的推理速度和2.1倍的内存节省，并确保了遮挡下一致的风格化质量。

**Conclusion:** 本文提出的抗遮挡风格化框架（OSF）通过解决风格化姿态差距和提供抗遮挡边缘引导，显著提升了基于绘画的3D动画在遮挡情况下的风格化质量和效率。

> **ai_Abstract:** 该论文提出了一个名为抗遮挡风格化框架（OSF）的新方法，旨在解决基于绘画的3D动画中因身体部位遮挡导致的风格质量下降问题。现有方法在训练和推理之间存在“风格化姿态差距”，导致在动态遮挡下轮廓闪烁和笔触模糊。OSF通过利用光流提供抗遮挡边缘引导来解决这一问题，确保了遮挡下风格化的一致性。此外，OSF采用单次运行模式，显著提高了推理速度（快2.4倍）并减少了内存消耗（少2.1倍）。

> **摘要翻译:** 3D动画旨在从输入图像和目标3D运动序列生成3D动画视频。图像到3D模型的最新进展使得直接从用户手绘图创建动画成为可能。与传统3D动画不同，基于绘画的3D动画的关键在于保留艺术家独特的风格特性，例如粗糙的轮廓和独特的笔触模式。然而，最近的方法在风格特性方面仍然表现出质量下降，尤其是在身体部位重叠引起的遮挡下，导致轮廓闪烁和笔触模糊。这发生在旨在保留基于绘画的3D动画系统中绘画风格的风格化网络中，训练和推理之间存在“风格化姿态差距”。风格化姿态差距表示用于训练风格化网络的输入目标姿态总是无遮挡姿态，而推理中遇到的目标姿态在动态运动下包含各种遮挡。为此，我们提出了用于基于绘画的3D动画的抗遮挡风格化框架（OSF）。我们发现，虽然使用物体的边缘可以作为引导风格化的有效输入先验，但在推理时发生遮挡时，它会变得非常不准确。因此，我们提出的OSF使用光流为风格化网络提供抗遮挡边缘引导，确保即使在遮挡下也能实现一致的风格化。此外，OSF采用单次运行而非之前的两阶段方法，实现了2.4倍的推理速度和2.1倍的内存节省。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [503] [CrossSet: Unveiling the Complex Interplay of Two Set-typed Dimensions in Multivariate Data](https://arxiv.org/abs/2508.00424)
> *CrossSet：揭示多元数据中两个集合类型维度之间的复杂相互作用*

*Kresimir Matkovic, Rainer Splechtna, Denis Gracanin, Helwig Hauser* | **Category: cs.GR** | **Updated: 2025-08-01**

**Keywords:** 集合类型数据,交互式可视化,多尺度分析,分层矩阵,维度交互

**Comment:** Will be published in TVCG and presented at IEEE VIS

> **TL;DR:** CrossSet是一种新颖的交互式可视化方法，用于联合分析和探索两个集合类型维度及其相互作用，通过分层矩阵布局实现多尺度钻取分析。

**AI_Comments:** CrossSet的创新在于其专注于两个集合类型维度的联合分析，填补了现有研究主要关注单个维度或无法有效处理多尺度交互的空白。其采用的分层矩阵布局和多尺度钻取功能是其核心亮点，能够提供灵活且全面的数据探索能力，对于理解复杂多元数据中的集合关系具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的集合类型数据可视化方法主要关注单个集合类型维度，缺乏对两个集合类型维度之间复杂相互作用进行联合、交互式分析的有效工具。

**Method:** 论文提出了CrossSet，一种基于任务分析的新型多尺度交互式可视化方法。它采用分层矩阵布局联合可视化两个集合类型维度，提供紧凑的大规模概览，并通过钻取功能支持多层次、多尺度的探索和分析，包括对单个维度、维度间交互以及特定集合元素交互的详细研究。

**Result:** CrossSet使得用户能够详细研究单个集合类型维度，全面了解两个维度之间的交互和关联，在不同层次上细化维度以获取更多细节，并深入到单个集合元素之间的特定交互。该方法已通过多个应用场景验证了其有效性和效率。

**Conclusion:** CrossSet提供了一种有效且高效的交互式可视化解决方案，能够对多元数据中两个集合类型维度之间的复杂相互作用进行多尺度、多层次的联合分析和探索。

> **ai_Abstract:** 本文介绍了CrossSet，一种新颖的交互式可视化方法，专门用于联合分析和探索多元数据中两个集合类型维度及其复杂的相互作用。该方法基于任务分析，采用多尺度分层矩阵布局联合展示两个集合维度，提供从大规模概览到单个集合元素交互的钻取能力。CrossSet支持对单个维度、维度间关联以及多层次细节的深入研究，并通过多个应用场景验证了其有效性和效率。

> **摘要翻译:** 集合类型数据的交互式视觉分析，即具有集合类型属性的数据，是一个有益的研究和应用领域。之前有价值的工作贡献了解决方案，使得能够研究具有单个集合类型维度的数据。在本文中，我们提出了CrossSet，一种用于联合研究两个集合类型维度及其相互作用的新颖方法。基于任务分析，我们描述了一种新的多尺度方法，用于此类数据的交互式视觉探索和分析。两个集合类型数据维度使用分层矩阵布局进行联合可视化，除了分析单个此类维度外，还能够分析两个集合类型属性在多个层次上的相互作用。CrossSet以紧凑、大规模的概览为基础，并辅以钻取功能，以研究集合类型维度之间和内部的关系，从而实现双变量集合类型数据的交互式视觉多尺度探索和分析。这种交互式方法使得能够详细研究单个集合类型维度，全面了解两个维度之间的交互和关联，在多个层次上细化其中一个维度以获取更多细节，并深入到集合类型维度中单个集合元素的特定交互。为了证明CrossSet的有效性和效率，我们已经在几个应用场景中评估了这种新方法。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [528] [Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation](https://arxiv.org/abs/2508.00428)
> *Sel3DCraft：用于用户友好型文本到3D生成的交互式视觉提示*

*Nan Xiang, Tianyi Liang, Haiwen Huang, Shiqi Jiang, Hao Huang, Yifei Huang, Liangyu Chen, Changbo Wang, Chenhui Li* | **Category: cs.GR, cs.HC** | **Updated: 2025-08-01**

**Keywords:** 文本到3D生成, 视觉提示, 3D模型评估, 创意支持, Sel3DCraft

**Comment:** IEEE VIS VAST 2025 ACM 2012 CCS - Human-centered computing,
  Visualization, Visualization design and evaluation methods

> **TL;DR:** Sel3DCraft通过引入视觉提示工程、双分支结构、多视图混合评分和视觉分析套件，解决了文本到3D生成中盲目试错提示的问题，提高了设计师的创造力。

**AI_Comments:** 这篇论文提出了一个创新的视觉提示工程系统Sel3DCraft，解决了文本到3D生成中长期存在的“盲目试错”瓶颈。其亮点在于将视觉提示引入3D领域，并通过结合检索与生成、多视图评估以及直观的视觉分析工具，极大地提高了生成过程的可控性和用户体验，这对于数字内容创作领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 文本到3D（T23D）生成受限于盲目的试错提示过程，导致结果不可预测，且视觉提示工程在3D生成中面临多视图一致性评估和空间理解的独特挑战。

**Method:** 提出了Sel3DCraft系统，包含三项创新：1. 结合检索和生成的双分支结构，用于探索多样的候选；2. 利用MLLM和创新性高级指标的多视图混合评分方法，以人类专家一致性评估3D模型；3. 提示驱动的视觉分析套件，实现直观的缺陷识别和精修。

**Result:** 广泛的测试和用户研究表明，Sel3DCraft在支持设计师的创造力方面超越了其他T23D系统。

**Conclusion:** Sel3DCraft系统通过其创新的视觉提示工程方法，显著提升了文本到3D生成的用户体验和创造力支持。

> **ai_Abstract:** Sel3DCraft是一个创新的文本到3D生成视觉提示工程系统，旨在解决传统T23D中盲目试错提示的问题。它引入了双分支结构进行多样化探索、多视图混合评分方法评估3D模型，以及视觉分析套件辅助缺陷识别和精修。用户研究表明，Sel3DCraft显著提升了设计师的创造力支持。

> **摘要翻译:** 文本到3D（T23D）生成已经改变了数字内容创作，但仍受限于盲目的试错提示过程，导致结果不可预测。虽然视觉提示工程在文本到图像领域取得了进展，但其在3D生成中的应用面临独特的挑战，需要多视图一致性评估和空间理解。我们提出了Sel3DCraft，一个用于T23D的视觉提示工程系统，它将非结构化探索转化为一个引导式的视觉过程。我们的方法引入了三个关键创新：一个结合检索和生成的双分支结构，用于多样化候选探索；一个利用多模态大语言模型（MLLMs）和创新性高级指标的多视图混合评分方法，以人类专家一致性评估3D模型；以及一个提示驱动的视觉分析套件，支持直观的缺陷识别和精修。广泛的测试和用户研究表明，Sel3DCraft在支持设计师的创造力方面超越了其他T23D系统。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [548] [SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation](https://arxiv.org/abs/2508.00782)
> *SpA2V：利用空间听觉线索进行音频驱动的空间感知视频生成*

*Kien T. Pham, Yingqing He, Yazhou Xing, Qifeng Chen, Long Chen* | **Category: cs.GR, cs.AI, cs.CV, cs.MM, cs.SD, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 音频驱动视频生成, 空间听觉线索, 视频场景布局, 扩散模型, 多模态学习

**Comment:** The 33rd ACM Multimedia Conference (MM '25)

> **TL;DR:** SpA2V是首个利用音频中的空间听觉线索生成具有高语义和空间对应性视频的框架，通过两阶段过程（音频引导的视频规划和布局引导的视频生成）实现。

**AI_Comments:** SpA2V的创新之处在于首次明确将空间听觉线索引入音频驱动的视频生成领域，弥补了现有方法仅关注语义信息的不足。通过引入视频场景布局（VSLs）作为中间表示，有效连接了音频和视频模态。其免训练的布局引导视频生成方法也提高了实用性。该工作对未来多模态内容生成，特别是涉及空间感知的任务，具有重要启发意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有音频驱动的视频生成方法主要关注语义信息，忽略了人类能够感知的空间属性（如位置和移动方向），导致生成的视频在内容和空间构成上不准确。

**Method:** 本文提出了SpA2V框架，它首次明确利用音频中的空间听觉线索来生成视频。该框架包含两个阶段：1) 音频引导的视频规划：将先进的多模态大型语言模型（MLLM）用于从输入音频中提取空间和语义线索，构建视频场景布局（VSLs）作为中间表示。2) 布局引导的视频生成：开发了一种有效的方法，将VSLs作为条件引导无缝集成到预训练的扩散模型中，实现免训练的VSL-引导视频生成。

**Result:** 大量实验表明，SpA2V在生成与输入音频在语义和空间上对齐的逼真视频方面表现出色。

**Conclusion:** SpA2V成功地通过利用音频中的空间听觉线索，显著提升了音频驱动视频生成的语义和空间准确性，验证了空间信息在视频合成中的重要性。

> **ai_Abstract:** SpA2V是一个创新的音频驱动视频生成框架，旨在解决现有方法忽略空间听觉线索的局限性。它通过利用音频中固有的空间属性（如位置和移动）来生成具有高语义和空间准确性的视频。SpA2V分两阶段工作：首先，利用多模态大型语言模型（MLLM）从音频中提取空间和语义线索，生成视频场景布局（VSLs）；其次，将这些VSLs作为条件引导集成到预训练扩散模型中，以实现高质量的视频生成。实验证明，SpA2V能生成与输入音频高度语义和空间对齐的逼真视频。

> **摘要翻译:** 音频驱动的视频生成旨在合成与输入音频记录对齐的逼真视频，类似于人类从听觉输入中可视化场景的能力。然而，现有方法主要侧重于探索语义信息，例如音频中发声源的类别，这限制了它们生成具有准确内容和空间构成的视频的能力。相比之下，我们人类不仅可以自然地识别发声源的语义类别，还可以确定其深度编码的空间属性，包括位置和移动方向。这些有用的信息可以通过考虑源自声音固有物理特性（如响度或频率）的特定空间指标来阐明。由于先前的方法在很大程度上忽略了这一因素，我们提出了SpA2V，这是第一个明确利用音频中的这些空间听觉线索来生成具有高语义和空间对应性视频的框架。SpA2V将生成过程分解为两个阶段：1）音频引导的视频规划：我们精心调整了一个最先进的多模态大型语言模型（MLLM），用于一项新任务，即利用输入音频中的空间和语义线索来构建视频场景布局（VSLs）。这作为一种中间表示，弥合了音频和视频模态之间的差距。2）布局引导的视频生成：我们开发了一种高效有效的方法，将VSLs作为条件引导无缝集成到预训练的扩散模型中，实现免训练的VSL引导视频生成。大量实验表明，SpA2V在生成与输入音频在语义和空间上对齐的逼真视频方面表现出色。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [568] [AAA-Gaussians: Anti-Aliased and Artifact-Free 3D Gaussian Rendering](https://arxiv.org/abs/2504.12811)
> *AAA-Gaussians: 抗锯齿和无伪影的3D高斯渲染*

*Michael Steiner, Thomas Köhler, Lukas Radl, Felix Windisch, Dieter Schmalstieg, Markus Steinberger* | **Category: cs.GR, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 3D Gaussian Splatting, 抗锯齿, 伪影消除, 实时渲染, 神经渲染

**Comment:** 

> **TL;DR:** 本文提出AAA-Gaussians，通过在3DGS管线中进行完整的3D高斯评估，解决了3DGS的锯齿、伪影和视图不一致问题，实现了高质量、实时、无伪影的渲染。

**AI_Comments:** 本文的关键创新在于将3DGS中的2D泼溅处理提升到完整的3D高斯评估，这从根本上解决了现有3DGS的局限性。其提出的自适应3D平滑和视空间边界方法有效消除了视觉伪影，而3D瓦片剔除则优化了性能。这项工作对于推动实时高质量神经渲染技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管3D Gaussian Splatting (3DGS) 彻底改变了3D重建，但它仍面临锯齿、投影伪影和视图不一致等挑战，这主要归因于将splats简化为2D实体。

**Method:** 本文提出在整个3DGS管线中纳入完整的3D高斯评估。具体方法包括：引入自适应3D平滑滤波器以减轻锯齿；提出稳定的视空间边界方法，消除高斯超出视锥体时的弹出伪影；将基于瓦片的剔除推广到3D，使用屏幕空间平面，以加速渲染并降低分层光栅化的排序成本。

**Result:** 本方法在分布内评估集上实现了最先进的质量，并且在分布外视图上显著优于其他方法。定性评估表明，该方法有效消除了锯齿、失真和弹出伪影，确保了实时、无伪影的渲染。

**Conclusion:** 通过在3DGS管线中整合全面的3D高斯评估，本方法成功解决了现有3DGS的局限性，实现了高质量和实时无伪影的渲染。

> **ai_Abstract:** 本文介绍了AAA-Gaussians，一种改进3D Gaussian Splatting (3DGS) 的方法，旨在解决其存在的锯齿、伪影和视图不一致问题。通过在整个渲染管线中引入完整的3D高斯评估，并结合自适应3D平滑滤波器、稳定的视空间边界方法以及3D瓦片剔除，AAA-Gaussians显著提升了渲染质量，尤其是在分布外视图上的表现，并实现了实时、无伪影的渲染效果。

> **摘要翻译:** 尽管3D高斯泼溅 (3DGS) 彻底改变了3D重建，但它仍然面临锯齿、投影伪影和视图不一致等挑战，这主要是由于将泼溅视为2D实体的简化所致。我们认为，在整个3DGS管线中纳入完整的高斯3D评估可以有效解决这些问题，同时保持光栅化效率。具体来说，我们引入了一种自适应3D平滑滤波器来减轻锯齿，并提出了一种稳定的视空间边界方法，可以消除当高斯超出视锥体时出现的弹出伪影。此外，我们将基于瓦片的剔除推广到3D，使用屏幕空间平面，加速渲染并降低分层光栅化的排序成本。我们的方法在分布内评估集上实现了最先进的质量，并且在分布外视图上显著优于其他方法。我们的定性评估进一步证明了有效消除了锯齿、失真和弹出伪影，确保了实时、无伪影的渲染。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [80] [Computation of Approximately Stable Committees in Approval-based Elections](https://arxiv.org/abs/2508.00130)
> *基于赞同的选举中近似稳定委员会的计算*

*Drew Gao, Yihang Sun, Jan Vondrák* | **Category: cs.GT, cs.DM** | **Updated: 2025-07-31**

**Keywords:** 赞同制选举, 委员会选择, 近似稳定性, 林达尔均衡, 强瑞利分布

**Comment:** 18 pages, 2 figures

> **TL;DR:** 本文研究了基于赞同的委员会选择中近似稳定委员会的存在性及其算法计算方法，证明了3.65-近似稳定委员会总是存在且可计算。

**AI_Comments:** 本文创新性地将林达尔均衡和强瑞利分布抽样应用于近似稳定委员会的计算，为社会选择理论中的委员会选择问题提供了一种新的算法方法和存在性证明。

<details>
  <summary>Details</summary>

**Motivation:** 在社会选择理论中，基于赞同的委员会选择是一个重要的模型，目标是为给定委员会规模K选择K名候选人来代表选民偏好。本文研究近似稳定性这一准则。

**Method:** 该方法基于寻找林达尔均衡（Lindahl equilibrium）并从与之相关的强瑞利分布（strongly Rayleigh distribution）中进行抽样。

**Result:** 证明了在赞同制选举中，一个3.65-近似稳定的委员会总是存在，并且可以算法化地计算出来。

**Conclusion:** 一个3.65-近似稳定的委员会在赞同制选举中总是存在且可计算。

> **ai_Abstract:** 本文研究了基于赞同的委员会选择模型中的近似稳定性概念。定义了一个委员会为$\lambda$-近似稳定当没有其他委员会被足够多的选民偏好。研究证明了一个3.65-近似稳定的委员会总是存在，并且可以通过基于寻找林达尔均衡和从强瑞利分布中抽样的方法进行算法计算。

> **摘要翻译:** 基于赞同的委员会选择是社会选择理论中一个非常重要的模型。在该模型中，我们有一个选民集合$\\mathcal{V}$，一个候选人集合$\\mathcal{C}$，并且每个选民都有一个他们赞同的候选人集合$A_v \\subset \\mathcal{C}$。对于任何委员会规模$K$，目标是选择$K$名候选人来代表选民的偏好。我们研究了一个被称为“近似稳定性”的准则，即如果不存在其他委员会$T$被至少$\frac{\\lambda|T|}{k} |\\mathcal{V}| $的选民所偏好，则该委员会是$\lambda$-近似稳定的。我们证明了在这种设置下，一个3.65-近似稳定的委员会总是存在并且可以算法化地计算。我们的方法是基于寻找林达尔均衡并从与之相关的强瑞利分布中进行抽样。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [110] [On the Equivalence of the Graph-Structural and Optimization-Based Characterizations of Popular Matchings](https://arxiv.org/abs/2508.00349)
> *关于流行匹配的图结构和基于优化的表征的等价性*

*Yuga Kanaya, Kenjiro Takazawa* | **Category: cs.GT, cs.DM, math.CO** | **Updated: 2025-08-01**

**Keywords:** 流行匹配, 图结构表征, 优化表征, 等价性, 二分图匹配

**Comment:** 

> **TL;DR:** 本文证明了流行匹配的图结构和基于优化的表征之间存在直接联系和等价性，无需依赖它们表征流行匹配的事实。

**AI_Comments:** 本文的主要创新在于直接建立了流行匹配的两种主要表征（图结构和基于优化）之间的联系和等价性，这对于理解流行匹配的内在结构和算法设计具有重要意义。提出的新解释也为未来的研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 流行匹配在偏好匹配中是一个重要模型，但确定其流行性需要指数时间。现有文献中有两种类型的表征：图结构表征和基于优化的表征，它们各有优缺点且之间缺乏直接联系。

**Method:** 本文研究了三种主要问题（单边偏好、带平局的单边偏好、双边偏好），并证明了流行匹配的图结构表征和基于优化的表征之间可以相互推导，而无需依赖它们表征流行匹配的事实。

**Result:** 研究结果表明，对于所有三种问题，图结构表征和基于优化的表征可以相互推导。这提供了一个对两种表征等价性的全面理解。

**Conclusion:** 本文证明了流行匹配的图结构表征和基于优化的表征之间的直接联系和等价性，并为图结构表征提供了基于最大权重匹配问题对偶最优解的新解释。

> **ai_Abstract:** 流行匹配是偏好匹配中的一种模型，其流行性确定计算复杂。现有文献提供了图结构和基于优化的两种流行匹配表征。本文研究了三种流行匹配问题，并证明了这两种表征之间存在直接的相互推导关系，从而揭示了它们的等价性。这项工作加深了对这两种表征的理解，并为图结构表征提供了一种新的对偶最优解的解释。

> **摘要翻译:** 流行匹配提供了一种在偏好下进行匹配的模型，其中解决方案对应于投票系统中的孔多塞赢家。在顶点对其邻居有偏好的二分图中，如果一个匹配在与任何其他匹配的多数投票中不失败，则定义为流行匹配。在本文中，我们研究了以下三个主要问题：仅一侧顶点有偏好；允许偏好中存在平局的此问题的泛化；以及两侧顶点都有偏好。流行匹配算法方面的一个主要问题是如何确定一个匹配的流行性，因为如果简单地应用定义，它需要指数时间。在文献中，我们有两种类型的表征：图结构表征；以及由最大权重匹配描述的基于优化的表征。图结构表征是专门为每个问题设计的，并提供了流行匹配的组合结构。基于优化的表征以相同的方式适用于所有问题，但它们没有揭示流行匹配的结构。本文的一个主要贡献是为所有三个问题提供了上述两种类型表征的直接连接。具体来说，我们证明了每种表征都可以从另一种推导出来，而无需依赖它们表征流行匹配的事实。我们的证明提供了对两种类型表征等价性的全面理解，并提出了在最大权重匹配问题的对偶最优解方面对图结构表征的新解释。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [608] [Justified Representation: From Hare to Droop](https://arxiv.org/abs/2508.00811)
> *公正代表：从海尔配额到德鲁普配额*

*Matthew M. Casey, Edith Elkind* | **Category: cs.GT** | **Updated: 2025-08-01**

**Keywords:** 多赢者选举, 赞成票, 公正代表, 海尔配额, 德鲁普配额

**Comment:** 

> **TL;DR:** 本文系统性地研究了在赞成票多赢者选举中，使用要求更高的德鲁普配额而非海尔配额定义的“公正代表”类公理及其满足规则，并发现德鲁普配额下的公理更难满足。

**AI_Comments:** 该论文的创新之处在于将更严格的德鲁普配额系统地应用于赞成票投票中的“公正代表”公理，填补了该领域研究的空白。通过识别满足这些更具挑战性公理的投票规则，并实验性地验证其难度，该工作显著推动了比例代表性理论的边界。

<details>
  <summary>Details</summary>

**Motivation:** 在赞成票多赢者选举中，尽管德鲁普配额比海尔配额更严格，但现有关于使用德鲁普配额来衡量比例代表性的研究尚不全面。

**Method:** 本文对使用德鲁普配额定义的“公正代表”（JR）类公理（以及满足它们的投票规则）进行了系统研究。研究方法包括识别满足德鲁普版本JR公理的现有规则（并修改其海尔配额证明），以及在必要时修改现有规则。此外，还进行了实验研究来补充理论结果。

**Result:** 研究为每个标准JR公理（JR, PJR, EJR, FPJR, FJR, PJR+ 和 EJR+）找到了满足其德鲁普版本公理的投票规则。结果表明，当使用德鲁普配额定义时，每个公理都更难满足。实验研究也显示，对于许多投票人赞同的概率模型，德鲁普JR/EJR+比标准（海尔）JR/EJR+要求更高。

**Conclusion:** 本文通过系统研究使用德鲁普配额定义的JR类公理，扩展了可满足比例代表性公理的边界，并证实了这些公理在实践中更具挑战性。

> **ai_Abstract:** 本研究系统地探讨了在赞成票多赢者选举中，使用要求更高的德鲁普配额来定义“公正代表”（JR）类比例代表性公理。文章识别了能够满足德鲁普版本JR、PJR、EJR等标准公理的投票规则，并指出与传统的海尔配额相比，德鲁普配额下的公理更难满足。理论结果辅以实验验证，进一步证明了德鲁普JR/EJR+在实践中对投票人赞同模型的要求更高。

> **摘要翻译:** 近年来，赞成票多赢者选举中的比例代表性研究受到了广泛关注。通常，比例代表性通过“公正代表”（Justified Representation）公理的变体来衡量，该公理指出，至少有 $\ell\cdot\frac{n}{k}$ 位选民（其中n是选民总数，k是所需的获胜者数量）的凝聚群体应获得$\ell$位代表。$\frac{n}{k}$ 这个量在社会选择文献中被称为海尔配额（Hare quota）。

另一种——更严格的——配额选择是德鲁普配额（Droop quota），定义为 $\lfloor\frac{n}{k+1}\rfloor+1$。这种配额常用于排序票多赢者选举：在单一可转移投票（Single Transferable Voting）等算法中，以及在德鲁普比例原则（Droop's Proportionality Criterion）等比例代表性公理中。少数作者在赞成票背景下考虑过它，但现有分析远未全面。我们工作的贡献是对使用德鲁普配额而非海尔配额定义的JR式公理（以及满足它们的投票规则）进行系统研究。对于每个标准JR公理（即JR、PJR、EJR、FPJR、FJR、PJR+和EJR+），我们都确定了一个满足该公理德鲁普版本的投票规则。在某些情况下，只需考虑已知规则（有时需要对相应的海尔证明进行相当大的修改），而在其他情况下，则需要修改先前工作中的规则。当使用德鲁普配额定义时，每个公理都更难满足，因此我们的结果扩展了可满足比例代表性公理的边界。我们通过实验研究补充了我们的理论结果，表明对于许多选民赞同的概率模型，德鲁普JR/EJR+比标准（海尔）JR/EJR+要求更高。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [677] [The Power of Two in Token Systems](https://arxiv.org/abs/2405.12414)
> *代币系统中的“二之力”*

*Itai Ashlagi, Süleyman Kerimov, Omer Tamuz, Geng Zhao* | **Category: cs.GT** | **Updated: 2025-08-01**

**Keywords:** 代币系统, 合作, 稳定性, 二之力, 肾脏交换

**Comment:** 

> **TL;DR:** 在无货币转移的经济体中，代币系统有助于维持合作。本文研究发现，当仅有一个随机代理人提供服务时，代币分布不稳定；但当至少有两个随机代理人可用时，代币分布会变得稳定，代理人的代币余额会趋于平衡。这一“二之力”现象与负载均衡中的“二选一”范式相似，并通过肾脏交换数据验证，表明代币系统在稀缺资源市场（如肾脏交换）中具有促进合作和提高效率的潜力。

**AI_Comments:** 这篇论文的创新点在于揭示了代币系统中“二之力”的现象，即仅需两个可用代理人即可显著提高系统的稳定性，这为资源稀缺环境下的合作机制设计提供了新的视角。其重要性体现在将负载均衡领域的“二选一”范式引入代币经济学，并提供了肾脏交换等实际应用的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究在外部供应稀缺的市场（即服务提供者数量非常有限）中，基于代币的经济体能否有效维持合作、缓解搭便车并提高效率。

**Method:** 研究考虑了一个市场模型：每次一名代理人请求服务，一名代理人提供服务，并使用一个代币作为支付。代理人拥有的代币数量代表服务提供量与请求量之差。为维持合作，系统选择代币最少的可用代理人提供服务。研究通过理论分析和使用肾脏交换数据的数值模拟来探究该经济体的行为和代币分布的稳定性。

**Result:** 研究发现，当恰好只有一个随机代理人可提供服务时，代币分布是不稳定的。然而，当仅有两个随机代理人可提供服务时，代币分布是稳定的，这意味着代理人的代币余额不太可能大幅偏离其初始禀赋，并且代理人会在有限的预期时间内返回其初始禀赋。这些结果与负载均衡问题中的“二选一”范式相呼应。

**Conclusion:** 本文的结论是，在代币系统中，即使只有两个服务提供者可用，也能显著提高代币分布的稳定性，从而有效维持合作。这一“二之力”效应表明，代币系统在外部供应稀缺的市场（例如肾脏交换市场）中，可以通过促进医院间的合作来产生高效的结果。

> **ai_Abstract:** 本文探讨了在外部供应稀缺的市场中代币系统的有效性。研究构建了一个模型，其中代理人通过代币支付服务，并根据代币余额选择服务提供者。关键发现是，当只有一个可用代理人时，代币分布不稳定；但当有至少两个随机代理人可用时，代币分布会变得稳定，代理人的代币余额会趋于平衡并返回初始状态。这一“二之力”现象与负载均衡中的“二选一”范式相似。通过肾脏交换数据的数值模拟验证了其发现，表明代币系统在实际应用中，如肾脏交换市场，能够有效促进合作并提高效率。

> **摘要翻译:** 在没有货币转移的经济体中，代币系统是维持合作、缓解搭便车和提高效率的替代方案。本文研究了在外部供应稀缺的市场中，基于代币的经济体能否有效运作。我们考虑一个市场，在每个时间段内，一名代理人请求服务，一名代理人提供服务，并使用一个代币（人造货币）来支付服务费用。每个代理人拥有的代币数量代表该代理人服务提供量与服务请求量之间的差额。我们关注当很少有代理人可提供所需服务时，这种经济体的行为。由于平衡代理人之间的代币数量是维持合作的关键，因此在可用的代理人中，选择代币数量最少的代理人来提供服务。当只有一个随机代理人可提供服务时，我们发现代币分布是不稳定的。然而，当只有两个随机代理人可提供服务时，代币分布是稳定的，这意味着代理人的代币余额不太可能大幅偏离其初始禀赋，并且代理人会在有限的预期时间内返回其初始禀赋。我们的结果反映了负载均衡问题中“二选一”范式的力量。在肾脏交换数据数值模拟的支持下，我们的发现表明代币系统可以通过维持医院之间的合作，在肾脏交换市场中产生高效结果。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [700] [Dominated Actions in Imperfect-Information Games](https://arxiv.org/abs/2504.09716)
> *不完全信息博弈中的劣势行动*

*Sam Ganzfried* | **Category: cs.GT, cs.AI, cs.MA, econ.TH** | **Updated: 2025-08-01**

**Keywords:** 不完全信息博弈, 劣势行动, 多项式时间算法, 纳什均衡, 博弈论

**Comment:** 

> **TL;DR:** 本文提出了一种多项式时间算法，用于在不完全信息博弈中识别并迭代移除劣势行动，从而高效地缩小博弈规模，为纳什均衡计算提供预处理。

**AI_Comments:** 该论文的创新之处在于为不完全信息博弈引入并提供了一种高效识别和移除劣势行动的方法，解决了传统方法可能导致的指数级规模爆炸问题。其提出的多项式时间算法是一个关键突破，对于在大型不完全信息博弈中高效计算纳什均衡具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在不完全信息扩展式博弈中，将博弈转换为策略式博弈来移除劣势策略会导致博弈规模呈指数级增长，因此需要一种更高效的方法来处理劣势行动。

**Method:** 本文定义并研究了不完全信息博弈中的劣势行动概念，并提出了一种多项式时间算法来判断行动是否劣势（严格或弱），该算法可以扩展到迭代移除劣势行动。

**Result:** 主要成果是提出了一种多项式时间算法，用于确定n人博弈中行动是否被任何混合策略所支配（严格或弱），该算法可以扩展到迭代移除劣势行动，从而高效地减小博弈树的规模。

**Conclusion:** 提出的多项式时间算法能够高效地识别并移除不完全信息博弈中的劣势行动，有效减小博弈规模，为纳什均衡计算提供高效的预处理步骤。该方法在扑克博弈中也得到了经验性探索。

> **ai_Abstract:** 本文针对不完全信息博弈中移除劣势策略时可能出现的指数级规模增长问题，定义了劣势行动的概念。提出了一种多项式时间算法，用于在n人博弈中识别被任何混合策略支配（严格或弱）的行动，并可扩展到迭代移除劣势行动。该方法能高效地缩小博弈树规模，作为纳什均衡计算的预处理步骤，并在“孤注一掷或弃牌”无限注德州扑克中进行了经验性探索。

> **摘要翻译:** 支配是博弈论中的一个基本概念。在策略式博弈中，劣势策略可以在多项式时间内识别。因此，迭代移除劣势策略可以作为一种高效的预处理步骤，用于在计算纳什均衡之前减小博弈规模。对于扩展式的不完全信息博弈，我们可以将博弈转换为策略式并以相同方式迭代移除劣势策略；然而，这种转换可能导致博弈规模呈指数级增长。在本文中，我们定义并研究了不完全信息博弈中劣势行动的概念。我们的主要成果是提出了一种多项式时间算法，用于确定n人博弈中行动是否被任何混合策略所支配（严格或弱），该算法可以扩展到迭代移除劣势行动的算法。这使得我们能够高效地减小博弈树的规模，作为纳什均衡计算的预处理步骤。我们经验性地探索了劣势行动在“孤注一掷或弃牌”无限注德州扑克变体中的作用。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [15] [Decoupling Data and Tooling in Interactive Visualization](https://arxiv.org/abs/2508.00107)
> *交互式可视化中数据与工具的解耦*

*Jan Simson* | **Category: cs.HC** | **Updated: 2025-07-31**

**Keywords:** 数据可视化, 数据解耦, 模块化架构, 数据处理, Web技术

**Comment:** Poster at IEEE VIS 2025

> **TL;DR:** 本文提出了一种模块化方法，将数据处理和加载功能与可视化组件分离，以解决当前可视化工具在数据处理方面的冗余和效率问题，从而降低开发开销并提升用户体验。

**AI_Comments:** 该论文提出了一种解决当前交互式数据可视化工具中数据处理痛点的创新方法。通过解耦数据和工具，它不仅能减少开发者的工作量，还能为用户提供更统一、高效的数据处理体验。其模块化架构和对统一数据处理界面的强调是重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 当前的可视化工具通常缺乏对数据转换或整理的支持，并且被迫重新实现自己的数据加载和摄取解决方案。这种冗余增加了工具创建者的开发开销，加剧了用户学习曲线，并导致用户体验下降，因为数据处理通常被视为事后诸葛。

**Method:** 本文提出了一种模块化的方法，将数据整理和加载功能与可视化组件分离。这种架构允许可视化工具专注于其核心优势，同时提供开发统一、强大数据处理界面的机会。通过使用网络技术构建早期原型来封装可视化工具并管理它们之间的数据流，证明了这种方法的可行性。

**Result:** 该方法的一个额外好处是允许多个工具并存和并排使用。通过构建一个使用网络技术封装可视化工具并管理它们之间数据流的早期原型，证明了这种方法的可行性。

**Conclusion:** 本文讨论了未来的研究方向，包括与IDE、文学编程笔记本和应用程序等其他工具的下游集成，以及整合用于高效数据转换的新技术。作者寻求社区的意见，以更好地理解这种方法的要求。

> **ai_Abstract:** 本文提出了一种解耦数据和工具的模块化方法，旨在解决交互式可视化工具中数据处理和加载的冗余问题。通过将数据整理与可视化组件分离，该方法旨在降低开发成本，简化用户学习曲线，并提升整体用户体验。作者通过一个Web技术原型验证了其可行性，并展望了未来与现有工具的集成和高效数据转换技术。

> **摘要翻译:** 交互式数据可视化是现代探索性数据分析的重要组成部分，基于Web的技术催生了丰富的专业和通用工具生态系统。然而，当前的可视化工具通常缺乏对数据转换或整理的支持，并且被迫重新实现自己的数据加载和摄取解决方案。这种冗余给工具创建者带来了巨大的开发开销，增加了用户掌握不同工具间数据处理界面的学习曲线，并降低了用户体验，因为数据处理通常被视为事后诸葛。
我们提出了一种模块化方法，将数据整理和加载功能与可视化组件分离。这种架构允许可视化工具专注于其核心优势，同时提供开发统一、强大数据处理界面的机会。这种方法的另一个好处是它允许多个工具并存和并排使用。我们通过使用Web技术构建一个早期原型来封装可视化工具并管理它们之间的数据流，从而证明了这种方法的可行性。
我们讨论了未来的研究方向，包括与IDE、文学编程笔记本和应用程序等其他工具的下游集成，以及整合用于高效数据转换的新技术。我们寻求社区的意见，以更好地理解这种方法的要求。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [26] [Your Model Is Unfair, Are You Even Aware? Inverse Relationship Between Comprehension and Trust in Explainability Visualizations of Biased ML Models](https://arxiv.org/abs/2508.00140)
> *你的模型不公平，你意识到了吗？偏置机器学习模型可解释性可视化中理解与信任的反向关系*

*Zhanna Kaufman, Madeline Endres, Cindy Xiong Bearfield, Yuriy Brun* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 可解释性可视化, 机器学习偏置, 理解, 信任, 偏置感知

**Comment:** 

> **TL;DR:** 用户对偏置机器学习模型理解得越好，反而越不信任它们，因为更好的理解会增加他们对模型偏置的感知。

**AI_Comments:** 本研究揭示了可解释性可视化中理解与信任之间令人惊讶的反向关系，并揭示了偏置感知在其中的关键介导作用，这对于负责任的机器学习应用和可解释人工智能（XAI）的设计具有重要意义。它表明，简单地提高模型的透明度可能不足以建立信任，反而可能因揭示内在偏置而降低信任，这挑战了传统观念，并为未来如何平衡透明度、偏置感知和信任提供了新的思考方向。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习系统已普及但普遍存在偏置行为，这显著影响利益相关者对系统的信任和使用方式。不同背景的利益相关者对同一系统的信任程度不同。因此，如何解释机器学习模型的行为在理解和信任中扮演关键角色。

**Method:** 研究者调查了可解释性可视化，并创建了设计特征分类法。他们进行了用户研究，评估了五种最先进的模型可解释性可视化工具（LIME、SHAP、CP、Anchors和ELI5），测量分类特征如何影响非专业机器学习用户的理解、偏置感知和信任。他们还通过操纵可解释性可视化来控制理解、偏置感知和信任，以确认因果关系。

**Result:** 研究发现理解与信任之间存在反向关系：用户对模型理解得越好，越不信任它们。这种关系由偏置感知强烈介导：更易理解的可视化增加了人们对偏置的感知，而偏置感知的增加降低了信任。研究证实这种关系是因果的：通过操纵可解释性可视化，可视化设计可以显著（p < 0.001）提高理解、增加感知到的偏置并降低信任。相反，通过提高模型公平性或调整可视化设计来减少感知的模型偏置，即使理解程度很高，也能显著提高信任。

**Conclusion:** 本研究增进了对理解如何影响信任的理解，并系统地调查了可视化在促进负责任的机器学习应用中的作用。

> **ai_Abstract:** 本文研究了可解释性可视化如何影响非专业用户对偏置机器学习模型的理解和信任。令人惊讶的是，研究发现理解与信任之间存在反向关系：更好的理解反而导致更低的信任，这主要由偏置感知的增加所介导。研究证实了这种因果关系，并提出通过提高模型公平性或调整可视化设计来减少感知到的偏置，可以在保持高理解度的同时显著提高信任，从而促进负责任的机器学习应用。

> **摘要翻译:** 依赖机器学习的系统已变得无处不在，但其中的偏置行为也同样普遍。研究表明，偏置显著影响利益相关者对系统的信任以及他们使用系统的方式。此外，不同背景的利益相关者对同一系统的看法和信任程度也不同。因此，如何解释机器学习模型的行为在理解和信任中扮演着关键角色。我们调查了可解释性可视化，创建了一个设计特征分类法。我们进行了用户研究，评估了五种最先进的模型可解释性可视化工具（LIME、SHAP、CP、Anchors和ELI5），测量了分类特征如何影响非专业机器学习用户的理解、偏置感知和信任。令人惊讶的是，我们发现理解与信任之间存在反向关系：用户对模型理解得越好，反而越不信任它们。我们调查了原因，发现这种关系受到偏置感知的强烈介导：更易理解的可视化增加了人们对偏置的感知，而偏置感知的增加降低了信任。我们证实这种关系是因果的：通过操纵可解释性可视化以控制理解、偏置感知和信任，我们表明可视化设计可以显著（p < 0.001）提高理解、增加感知到的偏置并降低信任。相反，通过提高模型公平性或调整可视化设计来减少感知的模型偏置，即使理解程度很高，也能显著提高信任。我们的工作增进了对理解如何影响信任的理解，并系统地调查了可视化在促进负责任的机器学习应用中的作用。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [39] [HandOver: Enabling Precise Selection & Manipulation of 3D Objects with Mouse and Hand Tracking](https://arxiv.org/abs/2508.00211)
> *HandOver：实现鼠标和手部追踪对3D物体的精确选择与操作*

*Esen K. Tütüncü, Mar Gonzalez-Franco, Eric J. Gonzalez* | **Category: cs.HC** | **Updated: 2025-07-31**

**Keywords:** XR交互, 鼠标输入, 手部追踪, 3D选择, 人体工程学

**Comment:** 11 pages, 10 figures

> **TL;DR:** HandOver结合鼠标精确选择和手部追踪表达性操作3D物体，提升了XR交互的舒适度和性能。

**AI_Comments:** HandOver的创新之处在于其巧妙地融合了传统鼠标的精确性与手部追踪的直观性，有效地解决了XR环境中3D对象选择和操作的痛点。这种混合输入范式提供了一个统一且高效的工作流程，极大地提升了用户体验和任务效率。该研究通过严谨的用户研究验证了其优势，对未来沉浸式环境中的人机交互设计具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** XR环境中，传统鼠标输入的精确选择与手部追踪的表达性操作之间存在割裂，导致用户在3D对象选择和操作时体验不佳。

**Method:** 本文提出了HandOver技术，它通过鼠标驱动一个深度感知的3D光标进行精确瞄准，并允许用户将手悬停在鼠标上方后无缝过渡到目标对象的直接3D操作。研究通过一项用户研究，将HandOver与传统射线投射（Ray）和混合方法（Ray+Hand）两种基于射线的技术在3D对接任务中进行了比较。

**Result:** 用户研究结果显示，HandOver在所有距离下都产生了更低的任务错误率。此外，RULA姿势分析和NASA-TLX自评测量表明HandOver改善了交互人体工程学。

**Conclusion:** 融合传统精确输入设备与手部追踪提供的表达性手势输入，能够提高XR中用户的舒适度和任务性能，从而为沉浸式环境中的用户提供一个统一且高效的工作流程。

> **ai_Abstract:** HandOver是一种创新的扩展现实（XR）交互技术，旨在结合鼠标的精确选择能力与手部追踪的表达性操作能力。它允许用户利用深度感知3D光标进行精确瞄准，然后无缝切换到手部直接操作目标对象。用户研究表明，HandOver相较于传统射线方法能显著降低任务错误率，并改善交互人体工程学，从而提升用户舒适度和任务性能，为XR环境中的交互提供了一个统一高效的解决方案。

> **摘要翻译:** 我们提出了HandOver，一种扩展现实（XR）交互技术，旨在将传统鼠标输入的对象选择精度与手部追踪的对象操作表达性相结合。通过HandOver，鼠标用于驱动一个深度感知的3D光标，实现精确且轻松的瞄准——用户将手悬停在鼠标上方，即可无缝过渡到目标对象的直接3D操作。在一项正式的用户研究中，我们在3D对接任务中将HandOver与两种基于射线的技术进行了比较：传统射线投射（Ray）和混合方法（Ray+Hand）。结果显示，HandOver在所有距离下都产生了更低的任务错误率，并且RULA姿势分析和自我报告测量（NASA-TLX）突出显示其改善了交互人体工程学。这些发现说明了在XR中融合传统精确输入设备与手部追踪所提供的表达性手势输入的好处，从而提高了用户舒适度和任务性能。这种融合范式产生了一个统一的工作流程，允许用户在沉浸式环境中交互时充分利用每种输入模式的优点。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [63] [Correcting Misperceptions at a Glance: Using Data Visualizations to Reduce Political Sectarianism](https://arxiv.org/abs/2508.00233)
> *一目了然地纠正错误认知：利用数据可视化减少政治宗派主义*

*Douglas Markant, Subham Sah, Alireza Karduni, Milad Rogha, My Thai, Wenwen Dou* | **Category: cs.HC** | **Updated: 2025-08-01**

**Keywords:** 数据可视化, 政治宗派主义, 错误认知, 纠正效果, 信息记忆

**Comment:** 11 pages, 5 figures. IEEE VIS 2025

> **TL;DR:** 本研究探讨了数据可视化如何有效纠正人们对政治对手的错误认知，从而减少政治宗派主义，发现不同类型的可视化方式会影响纠正效果和信息记忆准确性。

**AI_Comments:** 这项研究的创新之处在于其专注于利用数据可视化来解决政治宗派主义这一社会问题，并深入探讨了不同可视化形式对纠正效果的具体影响。它不仅验证了数据纠偏的有效性，更进一步揭示了呈现方式的重要性，为未来设计更有效的公共信息传播策略提供了实证依据。研究结果对于理解如何通过视觉信息有效改变人们的社会认知具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 政治宗派主义部分源于对政治对手的错误认知，人们常高估对方党派对极端政策的支持。纠正这些党派偏见，告知人们对方的实际观点，可能有助于减少自身的政治极端主义倾向（包括党派暴力和反民主行为）。

**Method:** 本研究进行了一项实验，参与者为来自Prolific平台的美国用户（239名民主党人，244名共和党人）。参与者首先预测其政治对手对政治暴力和反民主行为的支持程度，然后被展示关于对手实际观点的数据。实验设置了三种数据可视化条件：仅显示平均值（Mean-Only）、显示75%范围的均值加区间（Mean+Interval）、显示完整分布的均值加散点（Mean+Points），并与未告知对手观点的对照组进行比较。

**Result:** 与对照组相比，Mean-Only和Mean+Points条件下参与者的纠正效果最强，而Mean+Interval条件下的纠正效果较弱。此外，观察到完整分布（Mean+Points条件）的参与者在后续回忆对手支持程度时最准确。

**Conclusion:** 研究结果表明，数据可视化是纠正对其他群体普遍存在的认知偏差的重要工具。然而，对手观点变异性的可视化方式会显著影响人们对纠正信息的解释和反应。

> **ai_Abstract:** 本研究探讨了数据可视化在纠正政治对手错误认知、从而减少政治宗派主义方面的作用。通过一项实验，研究者比较了不同数据可视化方式（仅平均值、平均值加区间、平均值加散点）对纠正效果及信息记忆准确性的影响。结果显示，仅平均值和完整分布的可视化方式在纠正错误认知方面效果最强，且完整分布可视化能提高后续信息回忆的准确性。研究强调了数据可视化作为纠正认知偏差工具的潜力，并指出可视化方式对信息解释和反应具有关键影响。

> **摘要翻译:** 政治宗派主义部分源于对政治对手的错误认知：人们普遍高估了对方党派对极端政策的支持。研究表明，通过告知人们对方党派成员的实际观点来纠正党派偏见，可能会减少一个人自身对政治极端主义（包括党派暴力和反民主行为）的支持。本研究调查了纠正效果如何依赖于通过数据可视化传达的对手观点的不同表示形式。我们对来自Prolific平台的美国参与者（239名民主党人，244名共和党人）进行了一项实验。参与者预测其政治对手对政治暴力和反民主行为的支持程度。然后，他们被展示了来自早期调查的关于对手实际观点的数据。一些参与者只看到了平均响应（仅平均值条件），而其他组则看到了75%对手观点范围的可视化表示（平均值加区间条件）或完整响应分布（平均值加散点条件）。与未告知对手观点的对照组相比，我们在仅平均值和平均值加散点条件下的参与者中观察到最强的纠正效果，而在平均值加区间条件下的纠正效果较弱。此外，观察到完整对手观点分布的参与者（平均值加散点条件）在后续回忆对手支持程度时最准确。我们的发现表明，数据可视化可以成为纠正对其他群体普遍存在的认知偏差的重要工具。然而，对手观点变异性的可视化方式会显著影响人们如何解释和回应纠正信息。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [87] [TofuML: A Spatio-Physical Interactive Machine Learning Device for Interactive Exploration of Machine Learning for Novices](https://arxiv.org/abs/2508.00252)
> *TofuML：一种用于新手交互式探索机器学习的空间物理交互式机器学习设备*

*Wataru Kawabe, Hiroto Fukuda, Akihisa Shitara, Yuri Nakao, Yusuke Sugano* | **Category: cs.HC** | **Updated: 2025-08-01**

**Keywords:** TofuML, 交互式机器学习, 空间物理界面, 新手, 用户参与

**Comment:** 31 pages

> **TL;DR:** TofuML是一个空间物理交互式机器学习设备，旨在通过直观的玩具式交互，帮助非专业用户更容易地理解和参与机器学习，并在用户研究中显示出比传统GUI更高的参与度。

**AI_Comments:** TofuML的创新之处在于其将抽象的机器学习概念具象化为空间物理交互，通过“玩具式”操作降低了非专业用户的入门门槛，极大地提升了用户参与度和可玩性。这种具身化（embodiment）的交互方式为未来交互式AI系统的设计提供了宝贵的见解，特别是在教育和普及领域具有重要意义。该研究通过对比实验验证了其有效性，为交互式机器学习的用户体验设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于GUI的机器学习系统对非专业用户来说不够易于理解和参与，因此需要一种更具吸引力和直观性的交互方式来降低机器学习的门槛。

**Method:** TofuML是一个由小型设备和纸垫组成的空间物理交互界面，允许用户通过直观的、玩具式的交互来训练和评估声音分类模型。通过两项用户研究（与GUI版本的对比研究和公共事件部署）来调查TofuML对用户在ML模型创建过程中的参与度、提供训练数据的能力以及对潜在应用的构想的影响。

**Result:** TofuML与GUI相比，显著提高了用户参与度，并降低了非专业用户参与机器学习的门槛。用户在构思多样化的机器学习应用方面表现出创造力，揭示了在概念理解和用户参与度之间进行优化的机会。

**Conclusion:** TofuML的发现有助于开发针对广泛用户设计的交互式机器学习系统/框架，通过空间物理交互提升用户参与度和对机器学习的理解。

> **ai_Abstract:** TofuML是一种新颖的空间物理交互式机器学习设备，旨在通过直观的玩具式交互，使非专业用户更容易理解和参与机器学习。该系统通过一个小设备和纸垫，允许用户训练和评估声音分类模型。用户研究表明，与传统GUI相比，TofuML显著提高了用户参与度，降低了学习门槛，并激发了用户对机器学习应用的创造性构想，为开发面向广泛用户的交互式ML系统提供了新方向。

> **摘要翻译:** 我们引入了TofuML，一个旨在让机器学习（ML）概念对非专业用户更易于理解和更具吸引力的交互式系统。与传统的基于GUI的系统不同，TofuML采用了一个由小型设备和纸垫组成的物理和空间界面，允许用户通过直观的、玩具式的交互来训练和评估声音分类模型。通过两项用户研究——一项与基于GUI的版本进行的比较研究和一项公共事件部署——我们调查了TofuML如何影响用户在ML模型创建过程中的参与度、他们提供适当训练数据的能力以及他们对潜在应用的构想。我们的结果表明，与GUI相比，TofuML增强了用户参与度，同时降低了非专业用户参与ML的障碍。用户在构思多样化的ML应用方面表现出创造力，揭示了在概念理解和用户参与度之间进行优化的机会。这些发现有助于开发针对广泛用户设计的交互式ML系统/框架。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [116] [DeformTune: A Deformable XAI Music Prototype for Non-Musicians](https://arxiv.org/abs/2508.00160)
> *DeformTune：一个面向非音乐家的可变形XAI音乐原型*

*Ziqing Xu, Nick Bryan-Kinns* | **Category: cs.HC, cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-31**

**Keywords:** AI音乐生成, 可解释AI, 触觉界面, 非音乐家, DeformTune

**Comment:** In Proceedings of Explainable AI for the Arts Workshop 2025 (XAIxArts
  2025) arXiv:2406.14485

> **TL;DR:** DeformTune是一个结合触觉可变形界面和MeasureVAE模型的原型系统，旨在为非音乐家提供更直观、具身化和可解释的AI音乐创作体验，初步研究发现存在控制映射不清晰、表达范围有限等挑战，并提出了增强可解释性的设计机会。

**AI_Comments:** DeformTune的创新之处在于其将触觉可变形界面与AI音乐生成模型相结合，为非音乐家提供了新的交互范式。其重要性在于关注了AI音乐工具对新手用户的可访问性和可解释性，填补了现有工具对专业知识依赖的空白。初步研究揭示的挑战为未来设计提供了宝贵见解，但研究样本量较小，可能需要更广泛的验证。

<details>
  <summary>Details</summary>

**Motivation:** 许多现有的AI音乐生成工具依赖于文本提示、复杂界面或类似乐器的控制，这可能需要非音乐家不具备的音乐或技术知识，因此需要开发更直观、具身化和可解释的AI交互方式。

**Method:** 本文介绍了DeformTune原型系统，它结合了触觉可变形界面和MeasureVAE模型。研究人员对11名没有正式音乐训练的成年参与者进行了初步研究，以调查他们使用AI辅助音乐创作的体验，并对他们的反馈进行了主题分析。

**Result:** 主题分析揭示了反复出现的挑战，包括不清晰的控制映射、有限的表达范围以及在使用过程中需要指导。

**Conclusion:** 这些发现为使AI音乐系统对新手用户更具可解释性和赋能提供了早期见解，并讨论了增强AI可解释性的设计机会，包括多模态反馈和渐进式交互支持。

> **ai_Abstract:** DeformTune是一个为非音乐家设计的AI音乐原型系统，它通过结合可变形触觉界面和MeasureVAE模型，旨在提供更直观、可解释的音乐创作体验。一项对11名非专业音乐人士的初步研究发现，现有系统存在控制映射不清、表达受限和缺乏指导等问题。研究提出了多模态反馈和渐进式交互等设计机会，以提升AI音乐系统的可解释性和用户赋能。

> **摘要翻译:** 许多现有的AI音乐生成工具依赖于文本提示、复杂界面或类似乐器的控制，这可能需要非音乐家不具备的音乐或技术知识。本文介绍了DeformTune，一个原型系统，它结合了触觉可变形界面和MeasureVAE模型，旨在探索更直观、具身化和可解释的AI交互。我们对11名没有正式音乐训练的成年参与者进行了一项初步研究，以调查他们使用AI辅助音乐创作的体验。对他们反馈的主题分析揭示了反复出现的挑战——包括不清晰的控制映射、有限的表达范围以及在使用过程中需要指导。我们讨论了几种增强AI可解释性的设计机会，包括多模态反馈和渐进式交互支持。这些发现为使AI音乐系统对新手用户更具可解释性和赋能提供了早期见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [117] [Evaluating the Efficacy of Large Language Models for Generating Fine-Grained Visual Privacy Policies in Homes](https://arxiv.org/abs/2508.00321)
> *评估大型语言模型在家庭环境中生成细粒度视觉隐私策略的有效性*

*Shuning Zhang, Ying Ma, Xin Yi, Hewu Li* | **Category: cs.HC** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 视觉隐私, 智能家居, 细粒度策略, 对象模糊

**Comment:** 

> **TL;DR:** 本文研究了使用大型语言模型（LLMs）作为动态隐私策略引擎核心的可行性，以解决智能家居中视觉传感器带来的隐私挑战。通过多维度分类和LLM推理，实现了细粒度隐私规则。实验结果表明该方法有效且可行，机器评估和人工评估均获得高分。

**AI_Comments:** 这项研究的创新之处在于将大型语言模型应用于动态、细粒度的视觉隐私策略生成，解决了智能家居环境中日益增长的隐私挑战。它超越了传统的静态隐私控制，引入了基于上下文感知的适应性策略，特别是针对视觉数据。该方法通过成功的机器和人工评估，证明了LLMs在复杂隐私决策方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 智能家居环境中视觉传感器（特别是智能眼镜等可穿戴设备）的普及带来了严峻的隐私挑战。现有的隐私控制通常是静态和粗粒度的，无法适应家庭环境动态且具有社会细微差别的特性。

**Method:** 本文提出了一个概念框架，将视觉数据使用多维度模式进行分类，该模式考虑数据敏感性、空间上下文和社会存在。然后，大型语言模型（LLM）根据这些上下文信息进行推理，以实时执行细粒度的隐私规则，例如选择性对象模糊处理。通过在模拟家庭环境中对最先进的视觉语言模型（包括GPT-4o和Qwen-VL系列）进行比较评估。

**Result:** 研究结果表明了该方法的可行性。基于LLM的引擎获得了机器评估的最高适用性评分为3.99分（满分5分），模型生成的策略获得了人工评估的最高评分为4.00分（满分5分）。

**Conclusion:** 基于LLM的动态和自适应隐私策略引擎是可行的，并且能够有效生成细粒度的视觉隐私策略，以应对智能家居中的隐私挑战。

> **ai_Abstract:** 本文探讨了利用大型语言模型（LLMs）作为智能家居中动态、细粒度视觉隐私策略引擎的可行性。针对现有隐私控制静态粗糙的问题，研究者提出了一个框架，通过多维模式分类视觉数据，并由LLM基于上下文信息实时生成和执行隐私规则（如对象模糊）。实验评估了GPT-4o和Qwen-VL等模型，结果显示该LLM驱动的方法在机器和人工评估中均表现出色，验证了其在解决智能家居视觉隐私挑战方面的潜力。

> **摘要翻译:** 智能家居环境中视觉传感器，特别是通过智能眼镜等可穿戴设备的大量普及，带来了深刻的隐私挑战。现有的隐私控制通常是静态和粗粒度的，未能适应家庭环境的动态性和社会细微差别。本文研究了使用大型语言模型（LLM）作为动态自适应隐私策略引擎核心的可行性。我们提出了一个概念框架，其中视觉数据使用考虑数据敏感性、空间上下文和社会存在的​​多维模式进行分类。然后，LLM根据这些上下文信息进行推理，以实时执行细粒度的隐私规则，例如选择性对象模糊处理。通过在模拟家庭环境中对最先进的视觉语言模型（包括GPT-4o和Qwen-VL系列）进行比较评估，我们的发现表明了这种方法的可行性。基于LLM的引擎获得了机器评估的最高适用性评分为3.99分（满分5分），并且模型生成的策略获得了人工评估的最高评分为4.00分（满分5分）。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [138] [The SPACE of AI: Real-World Lessons on AI's Impact on Developers](https://arxiv.org/abs/2508.00178)
> *AI的SPACE：AI对开发者影响的真实世界经验*

*Brian Houck, Travis Lowdermilk, Cody Beyer, Steven Clarke, Ben Hanrahan* | **Category: cs.HC, cs.AI, cs.SE** | **Updated: 2025-07-31**

**Keywords:** AI影响, 开发者生产力, SPACE框架, 混合方法研究, 软件工程

**Comment:** 

> **TL;DR:** 本研究通过混合方法调查了AI对开发者生产力和体验的影响，发现AI被广泛采用并提高了效率和满意度，尤其是在日常任务中，但其效益因任务复杂性、个人使用模式和团队采纳度而异。AI增强了开发者而非取代他们，其有效整合依赖于团队文化和支持结构。

**AI_Comments:** 这项研究的创新之处在于采用了混合方法，并结合了SPACE框架来全面评估AI对开发者的影响，提供了基于真实世界数据的洞察。其重要性在于明确指出AI在软件开发中是增强性而非替代性的作用，并强调了组织和文化因素在AI采纳中的关键作用，为企业和研究人员提供了实用的指导。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能工具日益嵌入软件开发工作流程，关于它们对开发者生产力和体验的真正影响的问题依然存在。本研究旨在探讨开发者如何看待AI在SPACE框架（满意度、绩效、活动、协作和效率）维度上的影响。

**Method:** 本研究采用混合方法，包括对500多名开发者的问卷调查以及访谈和观察性研究的定性见解，来考察AI对开发者的影响。

**Result:** 研究发现AI被广泛采用，并被普遍认为提高了生产力，尤其是在日常任务中。然而，其效益因任务复杂性、个人使用模式和团队采纳度而异。开发者报告效率和满意度提高，但对协作的影响证据较少。组织支持和同伴学习在最大化AI价值方面发挥关键作用。这些发现表明AI是增强开发者而非取代他们。

**Conclusion:** AI正在增强开发者而非取代他们，并且AI的有效整合不仅取决于工具本身，还取决于团队文化和支持结构。研究最后提出了针对团队、组织和研究人员的实践建议，以利用AI在软件工程中的潜力。

> **ai_Abstract:** 本研究采用混合方法，通过对500多名开发者的调查和定性访谈，探讨了AI工具对软件开发者的影响。研究发现AI被广泛采纳，并能提升开发者在日常任务中的生产力、效率和满意度，但其效益受任务复杂性、个人使用习惯和团队采纳度的影响。研究强调AI是辅助而非替代开发者，并指出团队文化和组织支持对AI的有效整合至关重要。

> **摘要翻译:** 随着人工智能（AI）工具日益嵌入软件开发工作流程，关于它们对开发者生产力和体验的真正影响的问题依然存在。本文提出了一项混合方法研究的结果，该研究考察了开发者如何看待AI在SPACE框架维度上的影响：满意度（Satisfaction）、绩效（Performance）、活动（Activity）、协作（Collaboration）和效率（Efficiency）。我们从500多名开发者的调查回复以及访谈和观察性研究的定性见解中得出结论，发现AI被广泛采用，并被普遍认为提高了生产力，尤其是在日常任务中。然而，其效益因任务复杂性、个人使用模式和团队采纳度而异。开发者报告效率和满意度提高，但对协作的影响证据较少。组织支持和同伴学习在最大化AI价值方面发挥关键作用。这些发现表明AI是增强开发者而非取代他们，并且有效的整合不仅取决于工具本身，还取决于团队文化和支持结构。我们最后提出了针对团队、组织和研究人员的实践建议，以利用AI在软件工程中的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [144] [From Patient Burdens to User Agency: Designing for Real-Time Protection Support in Online Health Consultations](https://arxiv.org/abs/2508.00328)
> *从患者负担到用户自主权：设计在线健康咨询中的实时保护支持*

*Shuning Zhang, Ying Ma, Yongquan `Owen' Hu, Ting Dang, Hong Jia, Xin Yi, Hewu Li* | **Category: cs.HC** | **Updated: 2025-08-01**

**Keywords:** 在线健康咨询, 隐私保护, 大型语言模型, 实时编辑, 个人身份信息检测

**Comment:** 

> **TL;DR:** 在线医疗咨询平台存在隐私风险，导致用户信任度下降。本研究通过用户访谈揭示了用户隐私需求与平台现实之间的脱节。为弥合此差距，论文提出了SafeShare，一种利用本地化大型语言模型（LLM）实时编辑咨询内容的技术，旨在平衡隐私与实用性。SafeShare的核心PII检测模块在技术评估中表现出高准确率。

**AI_Comments:** 这篇论文通过结合用户访谈和技术实现，解决了在线健康咨询中一个非常实际且重要的隐私问题。SafeShare的概念，特别是利用本地化LLM进行实时编辑，具有创新性，能够有效减轻用户的“隐私劳动”负担。其技术评估结果也支持了方案的有效性。这项工作对于提升在线医疗平台的用户信任和隐私保护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在线医疗咨询平台虽然方便，但存在严重的隐私风险，这侵蚀了用户信任。研究旨在解决用户对匿名性和控制的需求与平台将“隐私劳动”责任下放之间的关键脱节。

**Method:** 首先对12名用户进行了深入的半结构化访谈，以了解他们对在线医疗咨询平台安全和隐私的看法、实践、挑战和期望。在此基础上，提出并开发了SafeShare，这是一种利用本地化大型语言模型（LLM）实时编辑咨询内容的交互技术，通过选择性地匿名化私人信息来平衡实用性和隐私。对SafeShare的核心个人身份信息（PII）检测模块在3个数据集上进行了技术评估。

**Result:** 分析揭示了用户对匿名性和控制的渴望与平台将“隐私劳动”责任下放的现实之间存在关键脱节。SafeShare的核心PII检测模块在技术评估中表现出高效能，在IMCS21数据集上使用Qwen3-4B模型达到了89.64%的准确率。

**Conclusion:** SafeShare技术通过利用本地化LLM实时编辑在线健康咨询内容，成功地弥合了用户隐私需求与平台现实之间的差距，从而在实用性和隐私之间取得了平衡。

> **ai_Abstract:** 本文探讨了在线医疗咨询平台中存在的隐私风险及其对用户信任的影响。通过对12名用户的访谈，研究发现用户对隐私和控制的需求与平台将隐私责任转嫁给用户的现状之间存在显著差距。为解决此问题，研究提出SafeShare，一种利用本地化大型语言模型实时编辑咨询内容的技术，旨在平衡实用性和隐私。SafeShare的核心PII检测模块在多数据集上的评估显示出高准确率，验证了其有效性。

> **摘要翻译:** 在线医疗咨询平台虽然方便，但其严重的隐私风险侵蚀了用户信任。我们首先对12名用户进行了深入的半结构化访谈，以了解他们对在线医疗咨询平台安全和隐私状况的看法，以及他们的实践、挑战和期望。我们的分析揭示了用户对匿名性和控制的渴望与平台将“隐私劳动”责任下放的现实之间存在关键脱节。为了弥合这一差距，我们提出了SafeShare，这是一种利用本地化大型语言模型（LLM）实时编辑咨询内容的交互技术。SafeShare通过选择性地匿名化私人信息来平衡实用性和隐私。对SafeShare核心个人身份信息（PII）检测模块在3个数据集上的技术评估表明其高效能，在IMCS21数据集上使用Qwen3-4B模型达到了89.64%的准确率。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [154] [How LLMs are Shaping the Future of Virtual Reality](https://arxiv.org/abs/2508.00737)
> *大型语言模型如何塑造虚拟现实的未来*

*Süeda Özkaya, Santiago Berrezueta-Guzman, Stefan Wagner* | **Category: cs.HC, cs.AI** | **Updated: 2025-08-04**

**Keywords:** 大型语言模型, 虚拟现实, 游戏设计, AI, 沉浸式体验

**Comment:** Pre-print

> **TL;DR:** 大型语言模型（LLMs）正在通过增强叙事、NPC互动、可访问性和个性化来彻底改变虚拟现实（VR）游戏，尽管面临性能和伦理挑战。

**AI_Comments:** 这篇论文是一篇全面的综述，突出了大型语言模型（LLMs）对虚拟现实（VR）的重大影响，详细阐述了其益处和挑战。它对未来研究方向的前瞻性视角对于指导这一新兴领域的负责任发展具有重要价值。对62项研究的分析为论文的论点提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）与虚拟现实（VR）游戏的结合标志着沉浸式、自适应和智能数字体验设计领域的范式转变。本文旨在全面回顾LLMs与VR交叉领域的研究，探讨LLMs如何改变VR体验。

**Method:** 本文对2018年至2025年间发表的62篇同行评审研究进行了全面回顾和分析，这些研究位于LLMs和VR的交叉点。

**Result:** 研究发现，LLMs正在改变叙事生成、非玩家角色（NPC）互动、可访问性、个性化和游戏主导。关键应用领域包括情感智能NPC、程序生成的故事叙述、AI驱动的自适应系统和包容性游戏界面。同时，也面临实时性能限制、内存限制、伦理风险和可扩展性障碍等主要挑战。LLMs显著增强了VR环境中的真实感、创造力和用户参与度。

**Conclusion:** LLMs在VR中的有效部署需要强大的设计策略，整合多模态交互、混合AI架构和伦理保障。未来的研究方向应包括多模态AI、情感计算、强化学习和开源开发，以指导智能和包容性VR系统的负责任发展。

> **ai_Abstract:** 本文综述了大型语言模型（LLMs）如何通过增强叙事、NPC互动、可访问性和个性化来革新虚拟现实（VR）游戏。通过分析2018-2025年间的62项研究，文章识别了从情感智能NPC到AI驱动的自适应系统等关键应用领域，并指出了实时性能、内存和伦理等挑战。研究强调，LLMs能显著提升VR的真实感和用户参与度，但其有效部署需整合多模态交互、混合AI架构和伦理保障。文章还展望了多模态AI、情感计算和强化学习等未来研究方向。

> **摘要翻译:** 大型语言模型（LLMs）与虚拟现实（VR）游戏的整合标志着沉浸式、自适应和智能数字体验设计领域的范式转变。本文全面回顾了LLMs与VR交叉领域的最新研究，审视了这些模型如何改变叙事生成、非玩家角色（NPC）互动、可访问性、个性化和游戏主导。通过对2018年至2025年间发表的62项同行评审研究的分析，我们确定了关键应用领域，包括情感智能NPC和程序生成的故事叙述，到AI驱动的自适应系统和包容性游戏界面。我们还讨论了这种融合面临的主要挑战，包括实时性能限制、内存限制、伦理风险和可扩展性障碍。我们的研究结果强调，虽然LLMs显著增强了VR环境中的真实感、创造力和用户参与度，但它们的有效部署需要强大的设计策略，整合多模态交互、混合AI架构和伦理保障。本文最后概述了多模态AI、情感计算、强化学习和开源开发的未来研究方向，旨在指导智能和包容性VR系统的负责任发展。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [169] [HateBuffer: Safeguarding Content Moderators' Mental Well-Being through Hate Speech Content Modification](https://arxiv.org/abs/2508.00439)
> *HateBuffer：通过仇恨言论内容修改保护内容审核员的心理健康*

*Subin Park, Jeonghyun Kim, Jeanne Choi, Joseph Seering, Uichin Lee, Sung-Ju Lee* | **Category: cs.HC** | **Updated: 2025-08-01**

**Keywords:** 仇恨言论, 内容审核, 心理健康, 内容修改, 用户研究

**Comment:** Accepted by ACM CSCW 2025; 39 pages (including 6 pages of Appendix)

> **TL;DR:** HateBuffer通过修改仇恨言论来保护内容审核员的心理健康，尽管主观感受良好，但客观情绪改善和疲劳减轻不明显，但未影响审核准确性。

**AI_Comments:** HateBuffer是一个创新的尝试，通过技术手段直接干预内容而非仅仅是过滤，以减轻内容审核员的心理负担。其创新点在于对仇恨言论的“软化”处理，并允许查看原文，平衡了保护与透明度。研究结果揭示了主观感知与客观测量之间的差异，这对于未来设计此类系统具有重要启示，即心理干预可能比单纯的内容修改更为复杂。其重要性在于关注了内容审核这一高压职业的心理健康问题。

<details>
  <summary>Details</summary>

**Motivation:** 内容审核员在处理仇恨言论时面临巨大的心理负担，影响其心理健康，因此需要设计一种机制来保护他们。

**Method:** 设计了HateBuffer系统，该系统能匿名化仇恨言论的目标，并将冒犯性表达转化为冒犯性较低的形式，同时允许审核员查看原始内容。通过一项包含80名参与者的用户研究，模拟了仇恨言论审核任务，并进行了半结构化访谈。

**Result:** 参与者在使用HateBuffer时对评论的仇恨程度评分较低。然而，与对照组相比，参与者的情绪并未改善，疲劳也未减轻。但在访谈中，参与者认为HateBuffer能有效缓冲情感传染和偏见观点的正常化。HateBuffer未影响审核准确性，反而略微提高了召回率。

**Conclusion:** 尽管HateBuffer在客观心理健康指标上未显示显著改善，但它被审核员感知为有效的缓冲工具，有助于抵御情感传染和偏见正常化，并且不影响审核准确性。文本内容修改技术在创建更健康的审核环境方面具有潜力。

> **ai_Abstract:** 本文提出HateBuffer系统，旨在通过修改仇恨言论（匿名化目标、改写冒犯性表达）来保护内容审核员的心理健康。用户研究显示，HateBuffer降低了用户对仇恨言论严重性的感知，并在访谈中被认为能有效缓冲情感传染，同时不影响审核准确性。尽管客观情绪和疲劳指标未见改善，但研究强调了文本内容修改技术在改善内容审核环境方面的潜力，并探讨了感知与实际效果差异的原因。

> **摘要翻译:** 仇恨言论在在线平台中仍然是一个持续且未解决的挑战。内容审核员作为审查用户生成内容和保护观众免受仇恨言论侵害的一线工作者，在持续接触冒犯性语言时，往往发现自己无法免受心理负担的侵害。为了保护审核员的心理健康，我们设计了HateBuffer，它能匿名化仇恨言论的目标，将冒犯性表达转化为冒犯性较低的形式，并在审核员选择查看时显示原始表达。我们对80名参与者进行的用户研究包括在虚构新闻平台上进行的模拟仇恨言论审核任务，随后进行了半结构化访谈。尽管参与者在使用HateBuffer时对评论的仇恨程度评分较低，但与我们的预期相反，与对照组相比，他们的情绪并未改善或疲劳并未减轻。然而，在访谈中，参与者将HateBuffer描述为对抗情感传染和仇恨言论中偏见观点正常化的有效缓冲器。值得注意的是，HateBuffer并未损害审核准确性，甚至略微提高了召回率。我们探讨了HateBuffer感知益处与其对心理健康的测量影响之间差异的可能解释。我们还强调了基于文本的内容修改技术作为创建更健康内容审核环境的工具的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [196] [Pull Requests From The Classroom: Co-Developing Curriculum And Code](https://arxiv.org/abs/2508.00646)
> *课堂中的拉取请求：课程与代码的协同开发*

*Dennis Zyska, Ilia Kuznetsov, Florian Müller, Iryna Gurevych* | **Category: cs.HC** | **Updated: 2025-08-01**

**Keywords:** 教育技术, 协同开发, 同伴反馈系统, 课程设计, 案例研究

**Comment:** 

> **TL;DR:** 本文介绍了一个案例研究，探讨了在大学科学写作课程中，课程和定制化同伴反馈系统如何协同开发，以更好地匹配教学目标，并揭示了协同开发在带来优势的同时也面临可用性挑战和基础设施问题。

**AI_Comments:** 这项研究的创新之处在于，它强调了在教育技术开发中，将课程设计与技术开发紧密结合的“协同开发”模式。这提供了一个有价值的案例，说明了如何通过迭代过程更好地满足教学需求。其重要性在于，它不仅指出了协同开发的优势——即提高了技术与教学目标的契合度，也坦率地揭示了其局限性，如可用性问题和基础设施挑战，这为未来的教育技术开发提供了宝贵的经验和改进方向。

<details>
  <summary>Details</summary>

**Motivation:** 教育技术常常与教师的教学目标不符，导致教学效果受损。为了解决这一问题，本文旨在探讨课程与技术协同开发的可能性。

**Method:** 本文通过一个案例研究，在大学科学写作课程的背景下，协同开发了一个定制的同伴反馈系统，该系统支持批注、反馈交流和修订。

**Result:** 协同开发促进了软件功能与课程目标之间更强的对齐。然而，它也暴露了可用性限制和与基础设施相关的挫折。

**Conclusion:** 协同开发有助于提高软件与教学目标的契合度，但同时需要教学团队和技术团队之间更紧密的协调来解决可用性及基础设施问题。

> **ai_Abstract:** 本文通过一个大学科学写作课程的案例研究，探讨了课程与定制化同伴反馈系统的协同开发过程。研究发现，这种协同开发模式能有效提升软件功能与教学目标的一致性，但同时也揭示了可用性问题和基础设施相关的挑战，强调了教学与技术团队间紧密协作的重要性。

> **摘要翻译:** 教育技术常常与教师的教学目标不符，迫使教师进行适应性调整，从而损害教学效果。本文介绍了一个关于课程和技术协同开发的案例研究，该研究以一门大学科学写作课程为背景。具体来说，我们研究了一个定制的同伴反馈系统如何与课程同步迭代开发，以支持批注、反馈交流和修订。结果表明，协同开发虽然促进了软件功能与课程目标之间更强的对齐，但也暴露了可用性限制和与基础设施相关的挫折，这强调了教学团队和技术团队之间需要更紧密的协调。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [229] [The Manipulative Power of Voice Characteristics: Investigating Deceptive Patterns in Mandarin Chinese Female Synthetic Speech](https://arxiv.org/abs/2508.00652)
> *语音特征的操纵力：调查中文女性合成语音中的欺骗模式*

*Shuning Zhang, Han Chen, Yabo Wang, Yiqun Xu, Jiaqi Bai, Yuanyuan Wu, Shixuan Li, Xin Yi, Chunhui Wang, Hewu Li* | **Category: cs.HC** | **Updated: 2025-08-01**

**Keywords:** 语音特征, 欺骗模式, 合成语音, 中文, 暗模式

**Comment:** 

> **TL;DR:** 本研究首次系统性地调查了中文女性合成语音中基于语音特征的暗模式，发现语音特征和场景对行为操纵的有效性有显著影响。

**AI_Comments:** 本研究的创新之处在于首次系统性地调查了非英语语境（特别是中文）下合成语音中语音特征的操纵力，填补了该领域的空白。其重要性在于揭示了语音交互中潜在的“暗模式”及其对用户行为的显著影响，为未来语音助手和相关产品的伦理设计提供了关键的证据和指导。

<details>
  <summary>Details</summary>

**Motivation:** 普遍存在的语音交互使得通过细微的语音特征进行欺骗成为可能，但对这种操纵的实证研究滞后，特别是在主要的非英语语言环境中。本研究旨在填补这一空白，尤其关注中文女性合成语音，因为女性角色在商业助手中普遍存在，且汉语在韵律上具有重要意义。

**Method:** 本研究采用概念框架指导，系统评估了不同场景（购物 vs. 问答）和不同商业目的下，通过操纵语音特征（五种特征，三种强度）来评估其有效性变化。进行了初步研究（N=24）验证实验材料，主研究（N=36）揭示了显著的行为操纵。

**Result:** 主研究（N=36）显示了显著的行为操纵（高达+2027.6%）。分析表明，有效性随语音特征和场景显著变化，并由用户感知（音调、语调、音色）和用户人口统计学（个体偏好，尽管人口统计学影响有限）所中介。

**Conclusion:** 这些相互关联的发现为道德设计提供了基于证据的见解。

> **ai_Abstract:** 本研究首次系统性地探讨了中文女性合成语音中基于语音特征的欺骗模式。通过操纵五种语音特征和三种强度，并在购物和问答两种场景下进行实验，研究发现语音特征和场景对用户行为操纵具有显著影响，最高可达2027.6%的行为操纵。研究还指出，用户感知（如音调、语调、音色）和用户人口统计学（如个体偏好）在其中起到中介作用。这些发现为语音交互系统的伦理设计提供了实证支持。

> **摘要翻译:** 普遍存在的语音交互通过细微的语音特征实现了欺骗模式，但对这种操纵的实证研究滞后，特别是在主要的非英语语言环境中。为了弥补这一空白，我们的研究首次系统地调查了中文女性合成语音中基于语音特征的暗模式。鉴于女性角色在商业助助手中普遍存在以及汉语在韵律上的重要性，这一关注至关重要。在识别关键影响因素的概念框架指导下，我们通过操纵语音特征（五种特征，三种强度）在不同场景（购物与问答）和不同商业目的下，系统地评估了有效性的变化。一项初步研究（N=24）验证了实验材料，主研究（N=36）揭示了显著的行为操纵（高达+2027.6%）。关键的是，分析表明有效性随语音特征和场景显著变化，并由用户感知（音调、语调、音色）和用户人口统计学（个体偏好，尽管人口统计学影响有限）所中介。这些相互关联的发现为道德设计提供了基于证据的见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [233] [What's Behind the Magic? Audiences Seek Artistic Value in Generative AI's Contributions to a Live Dance Performance](https://arxiv.org/abs/2508.00239)
> *魔法背后是什么？观众在生成式AI对现场舞蹈表演的贡献中寻求艺术价值*

*Jacqueline Elise Bruen, Myounghoon Jeon* | **Category: cs.HC, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 生成式AI, 艺术价值, 舞蹈表演, 观众感知

**Comment:** In Proceedings of Explainable AI for the Arts Workshop 2025 (XAIxArts
  2025) arXiv:2406.14485

> **TL;DR:** 研究发现，当观众不知道生成式AI参与创作时，他们更倾向于认为AI艺术有艺术价值。

**AI_Comments:** 这篇论文通过一个有趣的实验设计，揭示了观众对生成式AI艺术的认知偏见，即“不知者无罪”效应。其创新之处在于将AI艺术的价值评估置于实际的现场表演情境中，并探讨了信息透明度对观众感知的影响。研究结果对于理解AI艺术的社会接受度及其未来发展具有重要意义，尤其是在如何向公众介绍和推广AI生成内容方面提供了启示。

<details>
  <summary>Details</summary>

**Motivation:** 随着生成式AI工具在艺术创作中的发展，利益相关者对这些作品的价值存在分歧。本研究旨在揭示围绕AI艺术的复杂观点。

**Method:** 研究者开发了两个版本的舞蹈表演（有或没有生成式AI增强），并在观众对表演的看法调查之前或之后告知他们表演的开发细节。共有39名参与者（13男，26女）分为四场表演。

**Result:** 结果显示，当观众不知道生成式AI被使用时，他们更倾向于将艺术价值归因于由生成式AI创作的作品。

**Conclusion:** 本案例研究呼吁解决在塑造技术解释时利用社会背景和用户对生成式AI解释的重要性，从而引发更深入的讨论以弥合理解上的差距。

> **ai_Abstract:** 本研究探讨了观众对生成式AI参与艺术创作的看法。通过对比有无AI辅助的舞蹈表演，并控制观众是否预先知晓AI的使用，研究发现观众在不知情的情况下更倾向于赋予AI艺术更高的艺术价值。研究强调了在解释AI艺术时考虑社会背景和用户解读的重要性。

> **摘要翻译:** 随着生成式人工智能（GenAI）工具在艺术创作中的发展，利益相关者对这些作品的价值无法达成一致。在本研究中，我们揭示了围绕人工智能创作艺术的复杂观点。我们开发了两个版本的舞蹈表演，其中一个版本通过技术增强，另一个则没有使用生成式人工智能。对于每个版本，我们在观众对其表演的看法调查之前或之后，告知他们表演的开发细节。共有39名参与者（13名男性，26名女性）被分配到四场表演中。结果表明，当个体不知道生成式人工智能被使用时，他们更倾向于将艺术价值归因于由生成式人工智能创作的作品。我们将本案例研究作为一个呼吁，旨在强调在塑造技术解释时，利用社会背景和用户对生成式人工智能的解释的重要性，从而引发更深入的讨论，以弥合理解上的差距。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [259] [Why Do Decision Makers (Not) Use AI? A Cross-Domain Analysis of Factors Impacting AI Adoption](https://arxiv.org/abs/2508.00723)
> *决策者为何（不）使用AI？一项关于影响AI采纳因素的跨领域分析*

*Rebecca Yu, Valerie Chen, Ameet Talwalkar, Hoda Heidari* | **Category: cs.HC** | **Updated: 2025-08-01**

**Keywords:** AI采纳, 决策者, 跨领域分析, 影响因素, 负责任AI

**Comment:** To be published in Proceedings of the Eighth AAAI/ACM Conference on
  AI, Ethics, and Society (AIES-25). 10 pages, 4 figures, 1 table

> **TL;DR:** 该研究通过跨领域专家访谈，识别并分析了影响决策者采纳AI工具的关键因素，为AI的负责任部署提供了实用指导。

**AI_Comments:** 该研究通过跨领域专家访谈，深入探讨了影响AI采纳的人类因素，填补了技术部署中对决策者视角的关注空白。其提出的AI采纳分析框架具有创新性，有助于未来AI系统设计和部署更好地考虑用户心理和社会情境，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI在各领域部署的日益普及，理解人类决策者如何与AI系统互动至关重要，特别是决策者何时自愿选择咨询AI工具，即决策者采纳AI的动因。

**Method:** 研究通过访谈医学、法律、新闻和公共部门四个领域的专家，探讨了当前的AI使用案例和对采纳的看法。基于访谈结果，研究识别了影响决策者采纳AI工具的关键因素，并将其转化为AI采纳分析表，通过比较性、跨领域案例研究进行分析。

**Result:** 研究识别出影响决策者采纳AI工具的关键因素，包括：决策者的背景、对AI的看法、对决策者的影响以及对其他利益相关者的感知影响。这些因素有助于解释不同领域间采纳差异。

**Conclusion:** 研究结果为支持负责任和情境感知的AI部署提供了实用指导，通过更好地考虑决策者的视角来促进AI的有效采纳。

> **ai_Abstract:** 本研究旨在理解决策者采纳AI工具的动因。通过对医学、法律、新闻和公共部门的专家进行访谈，研究识别了影响决策者采纳AI的关键因素，包括决策者背景、对AI的感知、对决策者的后果以及对其他利益相关者的影响。研究将这些因素应用于跨领域案例分析，解释了AI采纳的领域差异，并为AI的负责任部署提供了实践指导。

> **摘要翻译:** 围绕在各个领域部署AI的日益增长的热情，要求我们仔细评估人类决策者如何与AI驱动系统互动。特别是，了解决策者何时自愿选择咨询AI工具至关重要，我们称之为决策者采纳。我们采访了医学、法律、新闻和公共部门四个领域的专家，以探究当前的AI使用案例和对采纳的看法。通过这些访谈，我们确定了影响决策者采纳AI工具的关键因素：决策者的背景、对AI的看法、对决策者的影响以及对其他利益相关者的感知影响。我们将这些因素转化为一份AI采纳表，通过比较性、跨领域案例研究来分析决策者如何做出采纳选择，强调我们的因素如何帮助解释领域间采纳差异。我们的发现为通过更好地考虑决策者的视角来支持负责任和情境感知的AI部署提供了实用指导。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [273] [Agency Among Agents: Designing with Hypertextual Friction in the Algorithmic Web](https://arxiv.org/abs/2507.23585)
> *代理人之间的能动性：在算法网络中设计超文本摩擦*

*Sophia Liu, Shm Garanganao Almeda* | **Category: cs.HC, cs.AI, cs.MM, cs.SI** | **Updated: 2025-07-31**

**Keywords:** 超文本摩擦, 用户能动性, 算法系统, 界面设计, 比较分析

**Comment:** To appear in: Adjunct Proceedings of the 36th ACM Conference on
  Hypertext and Social Media, Chicago, IL, USA, September 15-18, 2025

> **TL;DR:** 本文提出“超文本摩擦”这一设计理念，旨在通过重塑经典超文本原则来帮助用户在算法驱动的环境中重新获得能动性。

**AI_Comments:** 本文提出了一个重要的概念框架“超文本摩擦”，以解决当前算法驱动系统导致的用户能动性丧失问题。其创新之处在于重新审视并赋予经典超文本原则新的价值，并将其应用于现代界面设计。通过具体的案例分析，论文清晰地展示了不同系统如何影响用户体验和控制力，为未来算法系统设计提供了有益的思考方向。

<details>
  <summary>Details</summary>

**Motivation:** 当今的算法驱动界面（如推荐信息流和生成式AI工具）常以牺牲用户能动性为代价来优先考虑参与度和效率。随着系统承担更多决策，用户对所见内容以及内容间意义或关系的构建方式的控制力减弱。

**Method:** 通过对现实世界界面（维基百科 vs. Instagram Explore，以及 Are.na vs. 生成式AI图像工具）进行比较分析，探讨不同系统如何构建用户体验、导航和创作。

**Result:** 研究表明，超文本系统强调来源、联想思维和用户驱动的意义构建，而算法系统则倾向于模糊过程并扁平化参与。

**Conclusion:** 本文贡献在于：1) 对界面结构如何影响用户驱动和代理驱动系统中能动性的比较分析；2) 提出一种概念性立场，将超文本价值作为在日益算法化的网络中重新获得能动性的设计承诺。

> **ai_Abstract:** 本文提出“超文本摩擦”的设计理念，旨在应对算法驱动界面中用户能动性受损的问题。通过对比维基百科、Instagram Explore、Are.na和生成式AI工具等真实案例，研究发现超文本系统更能促进用户驱动的意义构建，而算法系统则趋于模糊过程。研究强调将超文本原则作为设计承诺，以帮助用户在算法化网络中重新获得控制权。

> **摘要翻译:** 当今的算法驱动界面，从推荐信息流到生成式AI工具，通常以牺牲用户能动性为代价来优先考虑参与度和效率。随着系统承担更多决策，用户对其所见内容以及内容间意义或关系的构建方式的控制力减弱。本文引入“超文本摩擦”，这是一种概念性设计立场，旨在将经典的超文本原则——摩擦、可追溯性和结构——重新定位为在算法介导环境中重新获得能动性的可操作价值。通过对现实世界界面（维基百科 vs. Instagram Explore，以及 Are.na vs. 生成式AI图像工具）进行比较分析，我们审视了不同系统如何构建用户体验、导航和创作。我们发现超文本系统强调来源、联想思维和用户驱动的意义构建，而算法系统则倾向于模糊过程并扁平化参与。我们的贡献包括：(1) 对界面结构如何塑造用户驱动系统和代理驱动系统中能动性的比较分析，以及 (2) 一种概念性立场，将超文本价值作为在日益算法化的网络中重新获得能动性的设计承诺。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [289] [Policy Maps: Tools for Guiding the Unbounded Space of LLM Behaviors](https://arxiv.org/abs/2409.18203)
> *策略地图：引导LLM行为无限空间的工具*

*Michelle S. Lam, Fred Hohman, Dominik Moritz, Jeffrey P. Bigham, Kenneth Holstein, Mary Beth Kery* | **Category: cs.HC, cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 策略地图, LLM行为, AI策略, Policy Projector, AI安全

**Comment:** UIST 2025

> **TL;DR:** 本文介绍了“策略地图”和交互式工具“Policy Projector”，旨在帮助AI从业者更有效地为大型语言模型（LLM）设计和导航行为策略，尤其是在处理有害输出方面。

**AI_Comments:** 本文提出的“策略地图”概念非常新颖，将物理地图制作的理念引入AI策略设计，通过“导航”而非“覆盖”来应对LLM行为空间的无限性，具有创新性。Policy Projector作为具体实现工具，提供了直观的交互方式来定义和管理LLM行为，对于提高AI安全和策略制定效率具有重要意义。该方法特别适用于处理特定有害或不当输出场景。

<details>
  <summary>Details</summary>

**Motivation:** AI政策旨在为AI模型的可接受行为设定边界，但在大型语言模型（LLMs）的背景下，由于其庞大的行为空间，确保策略覆盖范围极具挑战性。

**Method:** 本文引入了“策略地图”方法，其灵感来源于实体地图制作，旨在通过有意的设计选择（捕获哪些方面，抽象哪些方面）来有效导航LLM的广阔行为空间，而非追求全面覆盖。同时，还推出了交互式工具“Policy Projector”，该工具允许AI从业者调查模型输入-输出对，定义自定义区域（例如“暴力”），并使用if-then策略规则（例如，如果输出包含“暴力”和“图形细节”，则重写时不包含“图形细节”）来导航这些区域。Policy Projector支持使用LLM分类和引导进行交互式策略创作，并提供反映AI从业者工作的地图可视化。

**Result:** 在对12位AI安全专家的评估中，本系统帮助策略设计者围绕诸如不正确的性别假设和处理即时物理安全威胁等问题模型行为制定了策略。

**Conclusion:** 策略地图和Policy Projector工具为AI从业者提供了一种有效的方法，来设计和实施针对大型语言模型（LLM）行为的策略，尤其是在处理和缓解有害或不当输出方面，从而提高了AI模型的安全性。

> **ai_Abstract:** 本文提出了一种名为“策略地图”的新方法，旨在解决大型语言模型（LLMs）行为策略设计中覆盖广阔行为空间的挑战。该方法受物理地图制作启发，侧重于有效导航而非全面覆盖。同时，论文介绍了一个交互式工具“Policy Projector”，它允许AI从业者定义行为区域并应用if-then策略规则来管理LLM输出。通过对12位AI安全专家的评估，结果表明该系统能有效帮助设计者制定处理不当模型行为的策略，例如不正确的性别假设和物理安全威胁。

> **摘要翻译:** AI政策为AI模型的行为设定了可接受的边界，但在大型语言模型（LLMs）的背景下，这极具挑战性：如何确保覆盖广阔的行为空间？我们引入了策略地图，这是一种受实体地图制作实践启发的AI政策设计方法。策略地图并非旨在全面覆盖，而是通过有意选择要捕获和抽象哪些方面来帮助有效导航。借助Policy Projector，一个用于设计LLM策略地图的交互式工具，AI从业者可以调查模型输入-输出对的景象，定义自定义区域（例如“暴力”），并使用可以作用于LLM输出的if-then策略规则（例如，如果输出包含“暴力”和“图形细节”，则重写时不包含“图形细节”）来导航这些区域。Policy Projector支持使用LLM分类和引导进行交互式策略创作，并提供反映AI从业者工作的地图可视化。在对12位AI安全专家的评估中，我们的系统帮助策略设计者制定了围绕诸如不正确的性别假设和处理即时物理安全威胁等问题模型行为的策略。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [319] [AudioMiXR: Spatial Audio Object Manipulation with 6DoF for Sound Design in Augmented Reality](https://arxiv.org/abs/2502.02929)
> *AudioMiXR：用于增强现实中声音设计的六自由度空间音频对象操作*

*Brandon Woodard, Margarita Geleta, Joseph J. LaViola Jr., Andrea Fanelli, Rhonda Wilson* | **Category: cs.HC, cs.SD, eess.AS, H.5.2; H.5.5; H.5.1** | **Updated: 2025-08-01**

**Keywords:** 增强现实, 空间音频, 6自由度, 声音设计, 本体感受

**Comment:** Revision necessary for accuracy

> **TL;DR:** AudioMiXR是一个AR界面，用于评估用户如何在物理空间中通过六自由度（6DoF）操作虚拟音频对象以进行3D声音设计。研究发现两个设计经验：本体感受和平衡视听模态。

**AI_Comments:** 该论文创新性地将六自由度交互引入增强现实环境下的3D声音设计，解决了现有桌面工具在空间感知上的局限。其通过用户研究得出的两个设计经验，特别是对本体感受和视听模态平衡的强调，为未来AR声音界面的设计提供了宝贵指导。这项工作为XR领域的声音交互设计开辟了新的研究方向，具有重要的实践和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D声音设计工具受限于桌面显示器，可能限制在执行环境中的空间感知。同时，在XR中使用六自由度（6DoF）进行声音设计尚无具体的设计指南。

**Method:** 研究团队提出了AudioMiXR，一个用于增强现实（AR）的界面。他们招募了27名专家和非专家声音设计师，进行了一项探索性研究。研究采用被试内设计，用户需设计音乐和电影音景。通过对参与者数据进行主题分析，构建了设计经验。

**Result:** 研究构建了两个设计经验：1. AR声音设计中的本体感受，2. AR GUI中视听模态的平衡。此外，还提供了最能从6DoF声音设计中受益的应用领域。

**Conclusion:** 本研究为识别XR中六自由度声音设计相关的设计研究方向迈出了第一步，并提供了指导未来研究的设计经验。

> **ai_Abstract:** 本研究介绍了AudioMiXR，一个用于增强现实（AR）的界面，旨在探索用户如何通过六自由度（6DoF）在物理空间中操作虚拟音频对象以进行3D声音设计。针对现有工具的局限性以及XR中6DoF声音设计指南的缺失，研究团队招募了27名声音设计师进行探索性研究。通过被试内设计和主题分析，提出了两个关键设计经验：AR声音设计中的本体感受和AR GUI中视听模态的平衡，并指出了相关应用领域，为未来研究奠定了基础。

> **摘要翻译:** 我们推出了AudioMiXR，这是一个增强现实（AR）界面，旨在评估用户如何使用部署在头戴式显示器（Apple Vision Pro）上的六自由度（6DoF）在物理空间中操作虚拟音频对象以进行3D声音设计。现有的3D声音设计工具通常受限于桌面显示器，这可能会限制在执行环境中的混音空间感知。利用XR头戴式显示器创建音景可以为3D声音设计提供实时测试环境，因为现代头戴式显示器可以在跨模态交互的辅助下提供精确的空间定位。然而，目前还没有关于XR中六自由度（6DoF）声音设计的具体设计指南的研究。为了迈出识别该领域设计相关研究方向的第一步，我们进行了一项探索性研究，招募了27名参与者，其中包括专家和非专家声音设计师。目标是评估可用于指导未来3D声音设计研究方向的设计经验。我们进行了一项被试内研究，用户设计了音乐和电影音景。在对参与者数据进行主题分析后，我们构建了两个设计经验：1. AR声音设计中的本体感受，以及2. AR GUI中视听模态的平衡。此外，我们还根据研究结果提供了最能从6DoF声音设计中受益的应用领域。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [343] [MetaExplainer: A Framework to Generate Multi-Type User-Centered Explanations for AI Systems](https://arxiv.org/abs/2508.00300)
> *MetaExplainer：一个为AI系统生成多类型以用户为中心的解释的框架*

*Shruthi Chari, Oshani Seneviratne, Prithwish Chakraborty, Pablo Meyer, Deborah L. McGuinness* | **Category: cs.HC, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** AI可解释性, 用户中心解释, 神经符号框架, 大型语言模型, 解释本体论

**Comment:** 

> **TL;DR:** MetaExplainer是一个神经符号框架，通过三阶段流程和本体论指导，为AI系统生成以用户为中心的多类型解释，旨在提高AI系统的可解释性和可信度。

**AI_Comments:** MetaExplainer的创新之处在于其神经符号方法，结合了LLM的强大能力与解释本体论的结构化指导，有效弥合了AI模型解释与用户需求之间的鸿沟。它提供了多类型、用户中心的解释，极大地增强了AI系统的可解释性和可信赖性。该框架的通用性和可追溯性使其在不同领域具有广泛的应用前景，是AI可解释性领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** AI系统提供给用户的解释与用户实际需求之间存在差距，而解释对于构建可信赖的AI系统至关重要。

**Method:** MetaExplainer是一个神经符号框架，采用三阶段流程：首先，使用大型语言模型（LLM）将用户问题分解为机器可读格式；其次，将生成系统推荐的任务委托给模型解释器方法；最后，合成自然语言解释来总结解释器输出。整个过程利用解释本体论来指导语言模型和解释器方法。

**Result:** MetaExplainer在所有阶段都表现出高性能：问题重构F1分数达59.06%，模型解释忠实度达70%，自然语言合成的上下文利用率达67%。用户研究证实了生成解释的创造性和全面性。该框架在糖尿病（PIMA Indian）表格数据集上进行了测试，支持多种解释类型，包括对比、反事实、理由、基于案例和数据解释。

**Conclusion:** MetaExplainer的通用性及其利用本体论指导LLM的可追溯性表明其具有超越测试场景的广泛适用性，是增强跨领域AI可解释性的一个有前景的工具。

> **ai_Abstract:** MetaExplainer是一个神经符号框架，旨在解决AI模型解释与用户需求之间的差距。它采用三阶段流程：利用LLM分解用户问题，委托模型解释器生成推荐，并合成自然语言解释。通过整合解释本体论，该框架能生成多种类型的用户中心解释。评估结果显示其在问题重构、解释忠实度和语言合成方面表现出色，并得到了用户研究的验证，突出了其在增强AI可解释性和可信赖性方面的潜力。

> **摘要翻译:** 解释对于构建可信赖的AI系统至关重要，但模型提供的解释与用户所需的解释之间往往存在差距。为了解决这一差距，我们引入了MetaExplainer，一个旨在生成以用户为中心的解释的神经符号框架。我们的方法采用三阶段流程：首先，我们使用最先进的大型语言模型（LLM）将用户问题分解为机器可读格式；其次，我们将生成系统推荐的任务委托给模型解释器方法；最后，我们合成自然语言解释，总结解释器输出。在整个过程中，我们利用解释本体论来指导语言模型和解释器方法。通过利用LLM和结构化的解释生成方法，MetaExplainer旨在增强各种AI系统的可解释性和可信赖性，为用户提供量身定制、问题驱动的解释，更好地满足他们的需求。对MetaExplainer的全面评估表明，它朝着评估和利用当前最先进的解释框架迈出了一步。我们的结果显示在所有阶段都表现出高性能，问题重构的F1分数达到59.06%，模型解释的忠实度达到70%，自然语言合成的上下文利用率达到67%。用户研究证实了这些发现，强调了生成解释的创造性和全面性。MetaExplainer在糖尿病（PIMA Indian）表格数据集上进行了测试，支持多种解释类型，包括对比、反事实、理由、基于案例和数据解释。该框架的通用性以及利用本体论指导LLM的可追溯性表明其具有超越测试场景的广泛适用性，将MetaExplainer定位为增强跨领域AI可解释性的一个有前景的工具。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [349] [Cam-2-Cam: Exploring the Design Space of Dual-Camera Interactions for Smartphone-based Augmented Reality](https://arxiv.org/abs/2504.20035)
> *Cam-2-Cam：探索智能手机增强现实中双摄像头交互的设计空间*

*Brandon Woodard, Melvin He, Mose Sakashita, Jing Qian, Zainab Iftikhar, Joseph J. LaViola Jr* | **Category: cs.HC, H.5.2; H.5.1; H.5.0; H.1.2** | **Updated: 2025-08-01**

**Keywords:** 双摄像头交互, 增强现实, 智能手机AR, 设计空间, 用户体验

**Comment:** 

> **TL;DR:** 该研究提出了Cam-2-Cam概念，通过在三款AR应用中探索双摄像头交互，旨在克服单摄像头AR的局限性，并提出了两个关键设计经验以提升用户体验和防止迷失方向。

**AI_Comments:** 这篇论文的创新点在于提出了“Cam-2-Cam”这一双摄像头交互概念，并深入探索了其在智能手机AR中的设计空间。其重要性在于指出了当前单摄像头AR的局限性并提供了潜在的解决方案，通过实际的用户研究得出了具体的设计经验，对于推动智能手机AR的发展和更广泛的采用具有指导意义。研究关注了用户体验的核心问题，如具身性、沉浸感和防止迷失方向，使其具有很强的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的智能手机AR系统通常只使用单个前置或后置摄像头，这限制了用户交互的视野和屏幕尺寸，从而降低了其实用性。

**Method:** 研究提出了一个名为Cam-2-Cam的交互概念，并在三款基于智能手机的AR应用中实现。通过对30名参与者进行定性分析，探索了智能手机AR的交互空间。

**Result:** 研究得出了两个主要的设计经验：1) 平衡上下文相关性和反馈质量，即在实现熟悉交互与高质量多模态AR响应之间取得平衡；2) 使用同时捕获和交替摄像头防止迷失方向，详细说明了如何利用两种不同的摄像头技术防止AR交互中的迷失方向。

**Conclusion:** 本研究的发现是扩展智能手机AR交互空间的初步开创性步骤，有望推动更广泛的采用并克服单摄像头AR的局限性。研究还考虑了用户观察到的假设或自然倾向，以指导未来双摄像头AR的实现。

> **ai_Abstract:** 本研究提出了Cam-2-Cam概念，旨在通过利用智能手机双摄像头来克服传统单摄像头AR系统的局限性。研究在三款AR应用中实现了该概念，并通过对30名参与者的定性分析，得出了两个关键设计经验：一是如何在真实世界交互与AR反馈质量之间取得平衡，二是利用同时捕获和交替摄像头技术防止用户在AR交互中迷失方向。这些发现为未来双摄像头AR的设计和更广泛的应用奠定了基础。

> **摘要翻译:** 现成的智能手机增强现实（AR）系统通常使用单个前置或后置摄像头，这限制了用户交互的视野和屏幕尺寸，从而降低了其实用性。我们提出了Cam-2-Cam，一个在三款基于智能手机的AR应用中实现的交互概念，其交互跨越了两个摄像头。我们对30名参与者进行的定性分析结果提出了两个主要的设计经验，这些经验探索了智能手机AR的交互空间，同时保持了关键的AR界面属性，如具身性和沉浸感：(1) 平衡上下文相关性和反馈质量，旨在概述在实现人们在现实世界中进行的熟悉交互与多模态AR响应质量之间的微妙平衡；(2) 使用同时捕获和交替摄像头防止迷失方向，详细说明了如何在使用我们在论文中实现的两项独特摄像头技术时防止AR交互中的迷失方向。此外，我们考虑了观察到的用户假设或自然倾向，以指导未来智能手机AR中双摄像头设置的实现。我们设想我们的设计经验是扩展智能手机AR交互空间的初步开创性步骤，可能推动更广泛的采用并克服单摄像头AR的局限性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [537] [Breaking the mould of Social Mixed Reality - State-of-the-Art and Glossary](https://arxiv.org/abs/2507.23454)
> *打破社交混合现实的固有模式——现状与词汇表*

*Marta Bieńkiewicz, Julia Ayache, Panayiotis Charalambous, Cristina Becchio, Marco Corragio, Bertram Taetz, Francesco De Lellis, Antonio Grotta, Anna Server, Daniel Rammer, Richard Kulpa, Franck Multon, Azucena Garcia-Palacios, Jessica Sutherland, Kathleen Bryson, Stéphane Donikian, Didier Stricker, Benoît Bardy* | **Category: cs.HC, cs.CY, cs.ET, cs.GR, q-bio.NC, I.3.0; I.2; J.4; K.4** | **Updated: 2025-08-01**

**Keywords:** 混合现实, 社交互动, 具身, 词汇表, 负责任AI

**Comment:** pre-print

> **TL;DR:** 论文指出混合现实在模拟人类社交互动方面的不足，并提出了一个涵盖关键概念的词汇表，旨在推动以人为本的社交混合现实发展。

**AI_Comments:** 这篇论文通过提出一个全面的词汇表，填补了社交混合现实领域在概念定义上的空白，对于促进该领域的标准化和未来研究具有重要意义。其强调以人为本、伦理设计和心理安全，体现了对技术社会影响的深思熟虑。

<details>
  <summary>Details</summary>

**Motivation:** 混合现实技术在复制人类具身和社交运动互动方面存在关键差距，难以实现有意义的社交体验。

**Method:** 提出一个全面的词汇表，涵盖虚拟角色与自主化、负责任AI、设计伦理以及社交MR在神经科学、具身和技术方面的科学挑战等关键主题。

**Result:** 提供了关于社交混合现实关键概念的全面词汇表，旨在推动MR技术向以人为本的方向发展，促进更丰富的数字连接。

**Conclusion:** 倡导开发增强人类与虚拟自主智能体之间社交互动与协作的MR系统，确保包容性、伦理设计和心理安全。

> **ai_Abstract:** 这篇论文探讨了混合现实（MR）技术在真实复制人类具身和社交互动方面的不足，并指出需要整合多模态数据和多智能体交互能力以实现有意义的社交体验。为解决此问题，论文提出了一个全面的词汇表，涵盖了虚拟角色、负责任AI、设计伦理以及社交MR的科学挑战等关键概念。研究旨在推动以人为本的MR技术发展，倡导构建增强人类与虚拟智能体之间社交互动的MR系统，并强调包容性、伦理设计和心理安全的重要性。

> **摘要翻译:** 本文探讨了混合现实（MR）技术中的一个关键空白：尽管取得了进展，但MR在真实复制人类具身和社交运动互动方面仍面临困难。为了使MR能够实现真正有意义的社交体验，它需要整合多模态数据流和多智能体交互能力。为应对这一挑战，我们提出了一个全面的词汇表，涵盖了虚拟角色和自主化、负责任AI、设计伦理以及神经科学、具身和技术领域中社交MR的科学挑战等关键主题。我们的目标是推动MR技术的变革性发展，优先考虑以人为本的创新，促进更丰富的数字连接。我们倡导MR系统能够增强人类与虚拟自主智能体之间的社交互动与协作，并在此过程中确保包容性、伦理设计和心理安全。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [681] [A Mixed User-Centered Approach to Enable Augmented Intelligence in Intelligent Tutoring Systems: The Case of MathAIde app](https://arxiv.org/abs/2508.00103)
> *一种混合以用户为中心的方法，用于在智能辅导系统中实现增强智能：以MathAIde应用为例*

*Guilherme Guerino, Luiz Rodrigues, Luana Bianchini, Mariana Alves, Marcelo Marinho, Thomaz Veloso, Valmir Macario, Diego Dermeval, Thales Vieira, Ig Bittencourt, Seiji Isotani* | **Category: cs.HC, cs.AI, 68T01, H.5.0; I.2.0** | **Updated: 2025-08-04**

**Keywords:** 增强智能, 智能辅导系统, 用户中心设计, 人工智能教育, MathAIde

**Comment:** Article accepted in the International Journal of Human-Computer
  Interaction

> **TL;DR:** 本研究设计、开发并评估了MathAIde，一个利用计算机视觉和AI纠正数学练习的智能辅导系统，通过混合用户中心方法解决了AIED中的挑战，并证明了其在实际环境中的实用性。

**AI_Comments:** 本文的创新点在于提出了一个混合的用户中心设计方法，将增强智能（AuI）集成到智能辅导系统（ITS）中，特别是通过让教师参与到所有设计阶段来解决AIED面临的实际挑战。其重要性体现在开发了一个实用的应用程序（MathAIde），并证明了其在真实课堂环境中的实用性，尤其是在资源受限的环境中。这种以人为本、增强而非取代的设计理念，对于未来AIED系统的发展具有指导意义，有助于提高系统的接受度和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能教育（AIED）旨在通过智能辅导系统（ITS）提升学习体验，但面临教师参与、AI工具的局限性和可靠性以及技术资源可及性等挑战。增强智能（AuI）通过增强人类能力而非取代来应对这些挑战，从而促使本研究专注于设计、开发和评估一个实现AuI的ITS。

**Method:** 本研究设计、开发并评估了MathAIde，一个利用计算机视觉和AI纠正数学练习并提供反馈的ITS。研究方法包括与潜在用户进行头脑风暴会议、高保真原型设计、A/B测试以及涉及真实课堂环境的教师和学生的案例研究。

**Result:** 研究确定了在ITS中实现AuI的多种设计可能性，强调了用户需求与技术可行性之间的平衡。通过原型设计和测试进行的优先级排序和验证突出了效率指标的重要性，最终形成了一个为教师提供预定义补救方案的解决方案。实际部署证明了该解决方案的实用性。

**Conclusion:** 本研究通过提供一种可用的、以教师为中心的设计方法，将教师纳入所有设计阶段，从而为文献做出了贡献。实践意义在于，以用户为中心的设计方法提高了AIED系统的实用性和采用潜力，尤其是在资源有限的环境中。

> **ai_Abstract:** 本研究提出了一种混合以用户为中心的方法，用于在智能辅导系统（ITS）中实现增强智能（AuI），以应对人工智能教育（AIED）中的挑战。研究设计、开发并评估了MathAIde应用，一个利用计算机视觉和AI纠正数学练习的ITS。通过头脑风暴、原型设计、A/B测试和案例研究，研究确定了AuI在ITS中的设计可能性，并强调了用户需求与技术可行性之间的平衡。最终解决方案为教师提供了预定义的补救措施，并在实际部署中证明了其有效性。本研究的贡献在于提供了一种可用的、以教师为中心的设计方法，有助于提高AIED系统的实用性和采用率。

> **摘要翻译:** 将人工智能整合到教育中（AIED）旨在通过智能辅导系统（ITS）等技术提升学习体验，提供个性化学习、增加参与度和提高保留率。然而，AIED面临三个主要挑战：教师在设计过程中的关键作用、AI工具的局限性和可靠性以及技术资源的可及性。增强智能（AuI）通过增强人类能力而非取代它们来应对这些挑战，允许系统提出解决方案。相反，人类提供最终评估，从而随着时间的推移改进AI。从这个意义上讲，本研究专注于设计、开发和评估MathAIde，一个利用计算机视觉和AI纠正数学练习并根据学生作业照片提供反馈的ITS。研究方法包括与潜在用户进行头脑风暴会议、高保真原型设计、A/B测试以及涉及真实课堂环境的教师和学生的案例研究。我们的研究确定了在ITS中实施AuI的几种设计可能性，强调了用户需求和技术可行性之间的平衡。通过原型设计和测试进行的优先级排序和验证突出了效率指标的重要性，最终形成了一个为教师提供预定义补救方案的解决方案。实际部署证明了所提出解决方案的实用性。我们的研究通过提供一种可用的、以教师为中心的设计方法，将教师纳入所有设计阶段，从而为文献做出了贡献。作为一个实际意义，我们强调以用户为中心的设计方法提高了AIED系统的实用性和采用潜力，特别是在资源有限的环境中。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [706] [ReVise: A Human-AI Interface for Incremental Algorithmic Recourse](https://arxiv.org/abs/2508.00002)
> *ReVise: 一种用于增量式算法追索的人机交互界面*

*Kaustav Bhattacharjee, Jun Yuan, Aritra Dasgupta* | **Category: cs.HC** | **Updated: 2025-07-02**

**Keywords:** 算法追索, 人机交互, 增量规划, 可视化分析, 黑箱AI

**Comment:** Conditionally accepted for the IEEE VIS 2025 Short Papers track

> **TL;DR:** ReVise是一个人机交互界面，旨在帮助数据主体理解并有效导航增量式算法追索路径，以应对AI黑箱决策，避免误导性路径。

**AI_Comments:** 本文的创新之处在于解决了算法追索中被忽视的“增量步骤”问题，并提供了一个直观的人机交互界面。这对于增强AI决策的透明度、可解释性和用户赋能至关重要，特别是在高风险的社会技术系统中。通过将人类专业知识和用户偏好融入追索规划，该方法提升了追索建议的实用性和可操作性。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能在社会技术系统中的广泛应用引发了对其“黑箱”决策的担忧。当数据主体（如求职者、贷款申请人）收到不利结果时，他们可能需要算法追索来改变特征以获得有利结果。然而，现有追索方法仅关注最终目标，忽视了达到目标所需的增量步骤、现实约束、用户偏好和模型伪影，导致个体可能走上误导性路径。

**Method:** 为解决现有算法追索方法忽略增量步骤的问题，本研究与AI/ML专家合作，制定了一个用于增量追索规划的可视化分析工作流程，并开发了一个交互式可视化界面，帮助数据主体高效地浏览追索备选方案并做出明智决策。

**Result:** 通过一个使用真实世界数据集的场景演示和对十二名研究生的观察研究的主观反馈，结果表明该方法对于数据主体选择合适的追索路径具有重要作用。

**Conclusion:** 本研究提出的ReVise人机交互界面和可视化分析工作流程，能够有效帮助数据主体理解并导航增量式算法追索路径，从而在面对AI黑箱决策时做出明智选择。

> **ai_Abstract:** 本论文提出了ReVise，一个用于增量式算法追索的人机交互界面。针对AI决策的“黑箱”问题以及现有追索方法忽视增量步骤的不足，研究团队与AI/ML专家合作开发了一个可视化分析工作流程和交互式界面。该界面旨在帮助数据主体高效理解并导航实现有利结果所需的逐步特征调整。通过对真实数据集的场景演示和用户反馈，验证了ReVise在帮助用户选择合适追索路径方面的有效性。

> **摘要翻译:** 人工智能在社会技术系统中的近期应用引发了对由此产生的决策“黑箱”性质的担忧，例如在招聘、金融、招生等领域。如果数据主体——如求职者、贷款申请人和学生——收到不利结果，他们可能对算法追索感兴趣，这涉及更新某些特征，以便在算法决策重新评估时产生更有利的结果。不幸的是，当个人不完全理解改变其情况所需的增量步骤时，他们可能会走上误导性路径，从而导致重大的长期不利后果。现有追索方法只关注最终的追索目标，却忽略了在现实约束、用户偏好和模型伪影下达到目标的可能增量步骤。为了解决这一空白，我们与AI/ML专家合作，制定了一个用于增量追索规划的可视化分析工作流程，并贡献了一个交互式可视化界面，帮助数据主体高效地浏览追索备选方案并做出明智决策。我们展示了一个使用场景以及对十二名研究生使用真实世界数据集进行的观察研究的主观反馈，这表明我们的方法对于数据主体选择合适的追索路径至关重要。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [93] [Audio Prototypical Network For Controllable Music Recommendation](https://arxiv.org/abs/2508.00194)
> *音频原型网络用于可控音乐推荐*

*Fırat Öncel, Emiliano Penaloza, Haolun Wu, Shubham Gupta, Mirco Ravanelli, Laurent Charlin, Cem Subakan* | **Category: cs.IR, eess.AS** | **Updated: 2025-07-31**

**Keywords:** 音乐推荐, 原型网络, 可解释性, 可控性, 用户偏好

**Comment:** Accepted to MLSP2025

> **TL;DR:** 提出一种音频原型网络，用于可控音乐推荐，解决传统推荐系统缺乏可解释性和用户控制能力的问题，同时保持竞争力。

**AI_Comments:** 该论文的创新点在于将原型网络应用于音乐推荐领域，解决了传统黑盒模型在可解释性和用户控制方面的不足。通过将用户偏好映射到语义有意义的音乐特征原型，不仅提升了用户体验，也为未来更个性化和透明的推荐系统提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统推荐系统使用黑盒编码器模型表示用户偏好，缺乏可解释性，用户无法理解或控制系统如何建模他们的偏好。这在音乐推荐中尤为突出，因为用户偏好高度个性化且基于细微的音乐特质。

**Method:** 提出一种音频原型网络，该网络通过代表音乐特质语义特征的原型来表达用户偏好。

**Result:** 该模型与流行的基线模型相比，获得了具有竞争力的推荐性能，同时提供了可解释和可控的用户画像。

**Conclusion:** 音频原型网络能够提供可解释和可控的音乐推荐，同时保持良好的推荐性能。

> **ai_Abstract:** 本文提出了一种音频原型网络，旨在解决传统音乐推荐系统缺乏可解释性和用户控制能力的问题。该网络通过语义有意义的音乐特征原型来表示用户偏好，使得用户画像更易于理解和控制。实验结果表明，该模型在保持与现有基线模型相当的推荐性能的同时，显著提升了用户偏好表示的可解释性和可控性。

> **摘要翻译:** 传统推荐系统通过黑盒编码器模型获得的密集表示来表示用户偏好。虽然这些模型通常提供强大的推荐性能，但它们缺乏对用户的可解释性，使得用户无法理解或控制系统对其偏好的建模。这种限制在音乐推荐中尤其具有挑战性，因为用户偏好高度个性化，并且通常根据情绪、流派、节奏或乐器等细微品质而演变。在本文中，我们提出了一种用于可控音乐推荐的音频原型网络。该网络通过代表与音乐品质相关的语义特征的原型来表达用户偏好。我们表明，与流行的基线模型相比，该模型获得了具有竞争力的推荐性能，同时还提供了可解释和可控的用户画像。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [98] [RecPS: Privacy Risk Scoring for Recommender Systems](https://arxiv.org/abs/2507.18365)
> *RecPS：推荐系统隐私风险评分*

*Jiajie He, Yuechun Gu, Keke Chen* | **Category: cs.IR, cs.AI, cs.CR** | **Updated: 2025-08-01**

**Keywords:** 推荐系统, 隐私风险, 成员推断攻击, 差分隐私, RecPS

**Comment:** Accepted by ACM RecSys 2025; to appear

> **TL;DR:** 推荐系统使用敏感数据但缺乏量化隐私风险的方法。RecPS提出一种基于成员推断攻击（MIA）的隐私评分方法，用于衡量交互和用户层面的隐私风险，从而实现隐私感知的推荐系统开发和部署。

**AI_Comments:** 该论文通过提出一种可量化的隐私风险评分方法，解决了推荐系统中一个关键的现实世界隐私问题。其创新之处在于将成员推断攻击和差分隐私原理应用于推导实用的交互和用户层面的隐私分数，这可以直接有助于隐私感知模型开发和模型遗忘。对实际应用和其益处的展示值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 推荐系统依赖高度敏感的用户-物品交互数据，但现实世界的模型开发缺乏足够的隐私保护。用户无法判断哪些交互更敏感，因此量化RecSys训练数据的隐私风险对于实现隐私感知模型开发和部署至关重要。

**Method:** 提出RecPS，一种基于成员推断攻击（MIA）的隐私评分方法，用于衡量交互和用户层面的隐私风险。RecPS的交互层面评分定义受差分隐私启发并从中推导而来，并扩展到用户层面。关键组件是交互层面的MIA方法RecLiRA，它提供高质量的成员估计。

**Result:** 在知名基准数据集和RecSys模型上进行了广泛实验，结果显示RecPS评分在风险评估和RecSys模型遗忘中具有独特的特点和优势。

**Conclusion:** 量化RecSys训练数据的隐私风险是实现隐私感知模型开发和部署的关键步骤。RecPS提供了一种有效的方法来衡量交互和用户层面的隐私风险，并已被证明在风险评估和模型遗忘方面具有益处。

> **ai_Abstract:** RecPS是一种新颖的隐私风险评分方法，专为推荐系统设计。鉴于推荐系统依赖敏感用户数据且缺乏有效的隐私风险量化手段，RecPS利用成员推断攻击（MIA）来衡量用户交互和用户层面的隐私风险。其交互层面评分灵感来源于差分隐私，并引入了高质量的MIA方法RecLiRA。实验证明，RecPS在风险评估和模型遗忘方面具有显著优势，是实现隐私感知推荐系统开发的关键工具。

> **摘要翻译:** 推荐系统（RecSys）已成为许多网络应用的重要组成部分。系统的核心是基于高度敏感的用户-物品交互数据训练的推荐模型。尽管隐私增强技术在研究社区中得到积极研究，但现实世界的模型开发仍然依赖于最低限度的隐私保护，例如通过受控访问。此类系统的用户应该有权选择不共享高度敏感的交互。然而，目前没有方法允许用户知道哪些交互比其他交互更敏感。因此，量化RecSys训练数据的隐私风险是实现隐私感知RecSys模型开发和部署的关键一步。我们提出了一种基于成员推断攻击（MIA）的隐私评分方法RecPS，用于衡量交互和用户层面的隐私风险。RecPS交互层面评分的定义受差分隐私启发并从中推导而来，然后扩展到用户层面评分方法。一个关键组成部分是交互层面MIA方法RecLiRA，它提供了高质量的成员估计。我们对知名基准数据集和RecSys模型进行了广泛实验，以展示RecPS评分在风险评估和RecSys模型遗忘中的独特特点和优势。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [123] [Session-Based Recommendation with Validated and Enriched LLM Intents](https://arxiv.org/abs/2508.00570)
> *基于会话的推荐与验证和丰富的LLM意图*

*Gyuseok Lee, Yaokun Liu, Yifan Liu, Susik Yoon, Dong Wang, SeongKu Kang* | **Category: cs.IR** | **Updated: 2025-08-01**

**Keywords:** 会话推荐, 大型语言模型, 用户意图, 数据稀疏性, VELI4SBR

**Comment:** 

> **TL;DR:** 提出VELI4SBR框架，通过验证和丰富LLM生成的意图来解决会话推荐中的数据稀疏性和LLM应用挑战，并提升性能和可解释性。

**AI_Comments:** 该论文的创新点在于提出了一个全面的框架VELI4SBR，它不仅利用LLM推断用户意图来增强SBR，还解决了LLM应用中常见的意图质量验证、多意图处理和失败补偿等关键挑战。通过结合“预测-纠正循环”和行为相似性推断，该方法有效地提高了意图的可靠性和模型的鲁棒性，同时提升了推荐的可解释性，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 会话推荐（SBR）因会话短暂和匿名性而面临数据稀疏问题。虽然LLM推断用户意图可作为辅助信号，但现有方法存在意图质量验证、会话级多意图整合以及LLM失败情况补偿的挑战。

**Method:** 提出两阶段框架VELI4SBR。第一阶段，通过“预测-纠正循环”和全局意图池验证LLM生成意图的信息量，以生成高质量意图。第二阶段，通过轻量级多意图预测和融合机制增强SBR模型。此外，通过从会话间行为相似性推断意图来补偿LLM失败。

**Result:** VELI4SBR在广泛实验中超越了现有最先进的基线模型，并提高了可解释性。

**Conclusion:** VELI4SBR框架通过有效利用经过验证和丰富的大语言模型意图，显著提升了会话推荐的性能和可解释性，成功解决了现有方法面临的挑战。

> **ai_Abstract:** 本文提出VELI4SBR，一个两阶段框架，旨在解决会话推荐（SBR）中的数据稀疏性问题，并克服利用大语言模型（LLM）推断用户意图时面临的挑战。VELI4SBR首先通过“预测-纠正循环”和全局意图池生成高质量的、经过验证的LLM意图，然后通过多意图预测和融合机制增强SBR模型。为应对LLM失败，该框架还引入了基于会话间行为相似性推断意图的策略。实验结果表明，VELI4SBR在性能上超越了现有基线，并提升了模型的可解释性。

> **摘要翻译:** 基于会话的推荐（SBR）旨在及时预测匿名用户的下一个物品。然而，由于会话的短暂和匿名性质，SBR面临数据稀疏性问题。最近，一项新兴研究探索使用大型语言模型（LLM）推断会话的潜在用户意图，并将生成的意图作为辅助训练信号来增强SBR模型。尽管这种方法前景广阔，但它面临三个关键挑战：验证意图质量、整合会话级多意图以及弥补不可避免的LLM失败情况。在本文中，我们提出了VELI4SBR，一个两阶段框架，它利用经过验证和丰富的大语言模型生成意图进行SBR。在第一阶段，我们使用一个“预测-纠正循环”生成高质量意图，该循环通过全局意图池验证LLM生成意图的信息量，以限制LLM的输出空间并减少幻觉。在第二阶段，我们通过轻量级多意图预测和融合机制，使用生成的意图增强SBR模型。此外，我们引入了一种训练策略，通过从会话间行为相似性推断意图来补偿LLM的失败。广泛的实验表明，VELI4SBR优于现有最先进的基线模型，同时提高了可解释性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [148] [Experimental Evaluation of Dynamic Topic Modeling Algorithms](https://arxiv.org/abs/2508.00710)
> *动态主题建模算法的实验评估*

*Ngozichukwuka Onah, Nadine Steinmetz, Hani Al-Sayeh, Kai-Uwe Sattler* | **Category: cs.IR** | **Updated: 2025-08-01**

**Keywords:** 动态主题建模, 算法评估, 文本分析, 主题演变, 定量比较

**Comment:** 

> **TL;DR:** 本文比较了动态主题建模算法，并提出了一个评估指标来衡量主题随时间的变化，以解决现有模型之间缺乏深入量化比较的问题。

**AI_Comments:** 本文针对动态主题建模领域缺乏系统性定量比较的现状，提出了一种新的评估方法，这对于推动该领域的研究和应用具有重要意义。其创新点在于引入了衡量主题随时间变化的评估指标。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体上每天产生的文本量巨大，分析这些文本非常有用。为了理解大量文本背后的内容，需要可靠有效的自供电主题模型计算技术。然而，目前对这些模型进行彻底的定量比较相对较少。

**Method:** 本研究比较了动态主题建模算法，并提出了一个评估指标来记录主题如何随时间变化。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在解决动态主题建模算法之间缺乏深入定量比较的问题。论文比较了现有的动态主题模型，并提出了一种新的评估指标，用于衡量主题随时间变化的动态性，以更好地理解和分析海量文本数据。

> **摘要翻译:** 社交媒体上每天产生的文本量巨大，分析这些文本对许多目的都很有用。为了理解大量文本背后的内容，我们需要可靠有效的自供电主题模型计算技术。然而，目前对这些模型进行彻底的定量比较相对较少。在本研究中，我们比较了这些模型，并提出了一个评估指标，该指标记录了主题随时间的变化。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [174] [Harnessing the Power of Interleaving and Counterfactual Evaluation for Airbnb Search Ranking](https://arxiv.org/abs/2508.00751)
> *利用交错和反事实评估的力量优化Airbnb搜索排名*

*Qing Zhang, Alex Deng, Michelle Du, Huiji Gao, Liwei He, Sanjeev Katariya* | **Category: cs.IR, cs.AI, H.3; G.3** | **Updated: 2025-08-01**

**Keywords:** 交错评估, 反事实评估, A/B测试, 搜索排名, 转化率

**Comment:** 10 pages

> **TL;DR:** 本文提出交错和反事实评估方法，以解决传统A/B测试在转化率指标上统计功效不足的挑战，显著提升实验敏感性并简化实验流程。

**AI_Comments:** 该论文的创新点在于提出了交错和反事实评估这两种新颖的方法，以克服传统A/B测试在处理转化率指标时效率低下的局限性。其重要性体现在显著提升了实验的敏感性和效率，这对于像Airbnb这样需要快速迭代和优化用户体验的在线平台至关重要。该方法在生产环境中的成功应用也证明了其在实际业务场景中的强大实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在搜索和推荐系统中，评估对排名算法的开发至关重要。传统的A/B测试在转化率指标（特别是对于预订住宿等重大购买）上实现足够的统计功效耗时较长。离线评估虽然快速，但缺乏准确性。因此，需要一种能够快速在线评估并识别A/B测试最有前景候选者的方法。

**Method:** 本文开发了交错（interleaving）和反事实评估（counterfactual evaluation）方法，用于快速在线评估，以识别A/B测试中最有前景的候选者。

**Result:** 与传统A/B测试相比，该方法将实验敏感性提高了多达100倍（取决于方法和指标），并且简化了实验过程。

**Conclusion:** 交错和反事实评估方法能够有效解决传统A/B测试在转化率指标上的局限性，显著提高实验效率和敏感性，其在生产中的应用经验对类似组织具有借鉴意义。

> **ai_Abstract:** 本文针对传统A/B测试在搜索和推荐系统转化率指标上存在的统计功效不足和耗时问题，提出并开发了交错和反事实评估方法。该方法旨在提供快速的在线评估能力，以有效筛选A/B测试的最佳候选方案。实验结果表明，与传统A/B测试相比，该方法能够将实验敏感性提升高达100倍，并显著简化实验流程，为类似业务场景提供了宝贵的实践经验。

> **摘要翻译:** 评估在搜索和推荐系统的排名算法开发中起着至关重要的作用。它使在线平台能够以稳定有效的方式创建用户友好的功能，从而推动商业成功。在线环境特别有利于应用因果推断技术，例如随机对照实验（称为A/B测试），这在医学和公共政策等领域通常更难实施。然而，企业在有效的A/B测试方面面临独特的挑战。具体而言，针对基于转化率的指标实现足够的统计功效可能非常耗时，特别是对于预订住宿等重大购买。虽然离线评估更快、更具成本效益，但它们往往缺乏准确性，不足以选择A/B测试的候选者。为了应对这些挑战，我们开发了交错和反事实评估方法，以促进快速在线评估，从而识别A/B测试中最有前景的候选者。与传统的A/B测试相比，我们的方法不仅将实验敏感性提高了多达100倍（取决于方法和指标），而且简化了实验过程。从生产使用中获得的实践经验也可以使具有类似兴趣的组织受益。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [264] [Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation](https://arxiv.org/abs/2503.22675)
> *推荐前思考：释放序列推荐中潜在的推理能力*

*Jiakai Tang, Sunhao Dai, Teng Shi, Jun Xu, Xu Chen, Wen Chen, Jian Wu, Yuning Jiang* | **Category: cs.IR, cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 序列推荐, 推理时计算, 用户表示, 多步推理, ReaRec

**Comment:** 

> **TL;DR:** 本文提出了ReaRec，一个推理时计算框架，通过多步推理增强用户表示，显著提升了现有序列推荐模型的性能。

**AI_Comments:** ReaRec的创新之处在于首次将推理时计算引入推荐系统，通过多步推理增强用户表示，而非传统的直接前向计算。其提出的推理位置嵌入有效解耦了编码空间与推理空间，并通过ERL和PRL两种轻量级学习方法进一步挖掘了推理能力。性能提升幅度（30%-50%）显著，表明了该方法在提升序列推荐性能方面的巨大潜力，为未来的研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有序列推荐方法主要采用直接前向计算范式，导致计算深度有限，难以建模复杂的用户偏好演变，也缺乏对长尾物品的细致理解，从而导致次优的推荐性能。

**Method:** 本文提出了ReaRec，首个用于推荐系统的推理时计算框架，通过隐式多步推理增强用户表示。ReaRec将序列的最后一个隐藏状态自回归地送入序列推荐器，并结合特殊的推理位置嵌入以解耦原始物品编码空间和多步推理空间。此外，引入了两种轻量级基于推理的学习方法：集成推理学习（ERL）和渐进推理学习（PRL），以进一步有效利用ReaRec的推理潜力。

**Result:** 在五个公共真实世界数据集和不同序列推荐架构上的广泛实验表明，所提出的ReaRec具有通用性和有效性。事后分析显示，ReaRec显著提升了多个序列推荐骨干模型的性能上限约30%-50%。

**Conclusion:** 这项工作为序列推荐的推理时计算开辟了一条新的、有前景的研究途径。

> **ai_Abstract:** 本文针对现有序列推荐系统因计算深度有限而导致性能不佳的问题，提出了ReaRec，一个创新的推理时计算框架。ReaRec通过引入隐式多步推理机制，并结合特殊的推理位置嵌入来增强用户表示。同时，提出了ERL和PRL两种学习方法以充分发挥其推理潜力。实验证明，ReaRec能显著提升多种序列推荐模型的性能，为推理时计算在序列推荐领域开辟了新方向。

> **摘要翻译:** 序列推荐（SeqRec）旨在通过捕捉用户历史交互中的序列模式来预测下一个物品，在许多现实世界的推荐系统中发挥着至关重要的作用。然而，现有方法主要采用直接前向计算范式，其中序列编码器的最终隐藏状态作为用户表示。我们认为，这种推理范式由于其有限的计算深度，难以建模用户偏好的复杂演变性质，并且缺乏对长尾物品的细致理解，从而导致次优的性能。为了解决这个问题，我们提出了ReaRec，这是首个用于推荐系统的推理时计算框架，它通过隐式多步推理增强用户表示。具体来说，ReaRec将序列的最后一个隐藏状态自回归地送入序列推荐器，同时结合特殊的推理位置嵌入，以解耦原始物品编码空间和多步推理空间。此外，我们引入了两种轻量级基于推理的学习方法，即集成推理学习（ERL）和渐进推理学习（PRL），以进一步有效利用ReaRec的推理潜力。在五个公共真实世界数据集和不同SeqRec架构上的广泛实验证明了我们提出的ReaRec的通用性和有效性。值得注意的是，事后分析表明，ReaRec将多个序列推荐骨干模型的性能上限显著提高了约30%-50%。因此，我们相信这项工作可以为序列推荐的推理时计算开辟一条新的、有前景的研究途径。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [294] [Multi-modal Relational Item Representation Learning for Inferring Substitutable and Complementary Items](https://arxiv.org/abs/2507.22268)
> *多模态关系项表示学习，用于推断可替代和互补项*

*Junting Wang, Chenghuan Guo, Jiao Yang, Yanhui Guo, Yan Gao, Hari Sundaram* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 多模态学习, 关系项表示, 自监督学习, 可替代项, 互补项

**Comment:** 

> **TL;DR:** 本文提出MMSC，一个自监督多模态关系项表示学习框架，通过整合多模态数据和去噪用户行为，显著提高了可替代和互补商品推荐的准确性，并有效处理冷启动问题。

**AI_Comments:** 这篇论文通过引入多模态信息和自监督学习来解决现有推荐系统中用户行为数据噪声和稀疏性的核心问题，具有创新性。其利用LLMs进行数据增强是当前研究的热点结合，有望提升模型鲁棒性。MMSC在可替代和互补推荐任务上的显著性能提升以及对冷启动物品的处理能力，显示了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法主要依赖用户行为（GNNs）或内容信息来建模物品间关联，但忽略了用户行为数据的噪声和长尾分布导致的数据稀疏性等关键挑战。

**Method:** 本文提出了MMSC框架，该框架是一个自监督多模态关系项表示学习框架，旨在解决现有方法面临的挑战。MMSC包含三个主要组件：1) 多模态物品表示学习模块，利用多模态基础模型并从物品元数据中学习；2) 自监督行为表示学习模块，对用户行为数据进行去噪和学习；3) 分层表示聚合机制，整合语义和任务层面的物品表示。此外，该方法还利用大型语言模型（LLMs）生成增强训练数据，以进一步增强训练期间的去噪过程。

**Result:** 在五个真实世界数据集上的广泛实验表明，MMSC在可替代推荐方面超越现有基线26.1%，在互补推荐方面超越39.2%。此外，经验证明MMSC在建模冷启动物品方面是有效的。

**Conclusion:** MMSC框架通过有效整合多模态信息、去噪用户行为并处理数据稀疏性，显著提升了可替代和互补物品推荐的性能，并能有效处理冷启动问题。

> **ai_Abstract:** 本文提出MMSC，一个新颖的自监督多模态关系项表示学习框架，旨在解决现有方法在推断可替代和互补项时面临的用户行为数据噪声和稀疏性问题。MMSC包含多模态物品表示学习、自监督行为去噪学习以及分层表示聚合三大模块，并结合LLMs生成增强数据。实验结果表明，MMSC在可替代和互补推荐任务上显著优于现有基线，并有效处理冷启动物品。

> **摘要翻译:** 我们引入了一种新颖的自监督多模态关系项表示学习框架，旨在推断可替代和互补项。现有方法主要侧重于使用图神经网络（GNN）或利用项内容信息从用户行为中推断出的项间关联。然而，这些方法常常忽视关键挑战，例如嘈杂的用户行为数据以及由于这些行为的长尾分布导致的数据稀疏性。在本文中，我们提出了MMSC，一个自监督多模态关系项表示学习框架来解决这些挑战。具体来说，MMSC由三个主要组件组成：（1）一个多模态项表示学习模块，它利用多模态基础模型并从项元数据中学习；（2）一个自监督基于行为的表示学习模块，它对用户行为数据进行去噪和学习；（3）一个分层表示聚合机制，它在语义和任务级别整合项表示。此外，我们利用LLM生成增强训练数据，进一步增强训练期间的去噪过程。我们在五个真实世界数据集上进行了广泛实验，结果显示MMSC在可替代推荐方面优于现有基线26.1%，在互补推荐方面优于39.2%。此外，我们经验性地表明MMSC在建模冷启动项方面是有效的。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [473] [When Relevance Meets Novelty: Dual-Stable Periodic Optimization for Exploratory Recommendation](https://arxiv.org/abs/2508.00450)
> *当相关性遇上新颖性：用于探索性推荐的双稳态周期优化*

*Hongxiang Lin, Hao Guo, Zeshun Li, Erpeng Xue, Yongqian He, Xiangyu Hou, Zhaoyu Hu, Lei Wang, Sheng Chen* | **Category: cs.IR, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 探索性推荐, 大型语言模型, 双稳态, 周期性优化, 协同进化对齐

**Comment:** 

> **TL;DR:** 传统推荐系统存在探索不足和静态优化的问题。本文提出了协同进化对齐（CoEA）方法，通过双稳态兴趣探索（DSIE）模块解决兴趣建模偏差，并通过周期性协同优化（PCO）机制实现动态闭环优化，实验验证了其有效性。

**AI_Comments:** 该论文提出了一种创新的双LLM框架，解决了推荐系统中平衡相关性与新颖性以及实现动态优化的两个关键问题。引入DSIE模块以同时捕捉群体和个体偏好，以及PCO机制实现持续学习，标志着在构建更具适应性和以用户为中心的推荐系统方面迈出了重要一步。其对“双稳态”和“周期性优化”的关注表明了其在维持平衡和随时间演进方面的稳健方法。

<details>
  <summary>Details</summary>

**Motivation:** 传统推荐系统通过过度推送历史偏好内容，导致用户陷入强反馈循环，限制了探索机会并引起内容疲劳。现有LLM增强的双模型框架存在两大局限：一是忽视了由群体身份驱动的长期偏好，导致兴趣建模偏差；二是存在静态优化缺陷，未能利用增量用户数据进行闭环优化。

**Method:** 本文提出了协同进化对齐（CoEA）方法来解决上述挑战。针对兴趣建模偏差，引入了双稳态兴趣探索（DSIE）模块，通过并行处理行为序列共同建模长期群体身份和短期个体兴趣。针对静态优化局限性，设计了周期性协同优化（PCO）机制。该机制定期利用相关性LLM对增量数据进行偏好验证，然后指导新颖性LLM进行微调，并将微调后的新颖性LLM输出反馈给相关性LLM进行重新评估，从而实现动态闭环优化。

**Result:** 大量的线上和线下实验验证了CoEA模型在探索性推荐中的有效性。

**Conclusion:** CoEA模型通过引入DSIE模块解决了兴趣建模偏差，并通过PCO机制实现了动态闭环优化，有效提升了探索性推荐的效果，克服了传统推荐系统和现有LLM增强框架的局限性。

> **ai_Abstract:** 本文提出了协同进化对齐（CoEA）方法，旨在解决传统推荐系统在探索性方面的不足以及现有大型语言模型（LLM）增强框架在兴趣建模偏差和静态优化方面的局限。CoEA包含两个核心模块：双稳态兴趣探索（DSIE）模块，用于并行建模长期群体身份和短期个体兴趣；以及周期性协同优化（PCO）机制，通过相关性和新颖性LLM的动态闭环反馈，实现基于增量数据的持续优化。线上和线下实验结果验证了CoEA模型在探索性推荐中的有效性。

> **摘要翻译:** 传统推荐系统倾向于通过过度推送与用户历史偏好一致的内容，将用户困在强反馈循环中，从而限制了探索机会并导致内容疲劳。尽管大型语言模型（LLMs）凭借其多样化的内容生成能力展现出潜力，但现有基于LLM增强的双模型框架面临两大主要局限性：首先，它们忽视了由群体身份驱动的长期偏好，导致兴趣建模存在偏差；其次，它们存在静态优化缺陷，因为一次性对齐过程未能利用增量用户数据进行闭环优化。为了解决这些挑战，我们提出了协同进化对齐（CoEA）方法。针对兴趣建模偏差，我们引入了双稳态兴趣探索（DSIE）模块，通过并行处理行为序列共同建模长期群体身份和短期个体兴趣。针对静态优化局限性，我们设计了周期性协同优化（PCO）机制。该机制定期利用相关性LLM对增量数据进行偏好验证，然后指导新颖性LLM根据验证结果进行微调，随后将增量微调后的新颖性LLM的输出反馈给相关性LLM进行重新评估，从而实现动态闭环优化。大量的线上和线下实验验证了CoEA模型在探索性推荐中的有效性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [493] [M^2VAE: Multi-Modal Multi-View Variational Autoencoder for Cold-start Item Recommendation](https://arxiv.org/abs/2508.00452)
> *M^2VAE：用于冷启动物品推荐的多模态多视图变分自编码器*

*Chuan He, Yongchao Liu, Qiang Li, Wenliang Zhong, Chuntao Hong, Xinwei Yao* | **Category: cs.IR, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 冷启动推荐, 多模态, 多视图, 变分自编码器, 推荐系统

**Comment:** 

> **TL;DR:** M^2VAE针对冷启动物品推荐问题，提出了一种多模态多视图变分自编码器，通过解耦共享和特定模态特征、融合用户偏好和共现信号来提高推荐效果。

**AI_Comments:** 该论文的创新点在于其多模态多视图的建模方法，特别是区分了共享和特定模态特征，并通过解耦对比损失和偏好引导的专家混合来有效整合这些信息。无需预训练的共现信号整合也提高了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 冷启动物品推荐是推荐系统中的一个重大挑战，特别是当新物品没有历史交互数据时。现有方法虽然利用多模态内容来缓解冷启动问题，但往往忽视模态固有的多视图结构以及共享和模态特定特征之间的区别。

**Method:** 本文提出了M^2VAE，一个生成模型，用于处理属性和多模态特征中常见视图和独特视图的建模挑战，以及用户对单一类型物品特征的偏好。具体来说，它为物品ID、分类属性和图像特征生成类型特定的潜在变量，并使用专家乘积（PoE）推导共同表示。解耦对比损失将共同视图与独特视图解耦，同时保留特征信息。为建模用户倾向，采用偏好引导的专家混合（MoE）自适应融合表示。此外，通过对比学习纳入共现信号，无需预训练。

**Result:** 在真实世界数据集上进行的广泛实验验证了该方法的有效性。

**Conclusion:** M^2VAE通过其独特的多模态多视图建模、特征解耦和偏好引导的融合机制，有效解决了冷启动物品推荐问题，并在真实数据集上表现出优越性。

> **ai_Abstract:** M^2VAE是一种新颖的生成模型，旨在解决推荐系统中的冷启动物品推荐问题。它通过对多模态和多视图特征进行建模，区分共同和独特视图，并结合用户偏好和共现信号，生成有效的物品表示。该模型利用PoE、解耦对比损失和MoE等技术，并在真实数据集上验证了其有效性。

> **摘要翻译:** 冷启动物品推荐是推荐系统中的一个重大挑战，尤其是在引入没有任何历史交互数据的新物品时。虽然现有方法利用多模态内容来缓解冷启动问题，但它们往往忽视模态固有的多视图结构以及共享特征和模态特定特征之间的区别。在本文中，我们提出了多模态多视图变分自编码器（M^2VAE），这是一个生成模型，旨在解决属性和多模态特征中共同视图和独特视图建模的挑战，以及用户对单一类型物品特征的偏好。具体来说，我们为物品ID、分类属性和图像特征生成类型特定的潜在变量，并使用专家乘积（PoE）来推导共同表示。一种解耦对比损失将共同视图与独特视图解耦，同时保留特征信息。为了建模用户倾向，我们采用偏好引导的专家混合（MoE）来自适应地融合表示。我们通过对比学习进一步纳入共现信号，从而无需预训练。在真实世界数据集上进行的广泛实验验证了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [179] [Improved Bounds on Access-Redundancy Tradeoffs in Quantized Linear Computations](https://arxiv.org/abs/2508.00183)
> *量化线性计算中访问-冗余权衡的改进界限*

*Ching-Fang Li, Mary Wootters* | **Category: cs.IT, math.IT** | **Updated: 2025-07-31**

**Keywords:** 量化线性计算, 访问-冗余权衡, 不可行性界限, 近似恢复, 块构造

**Comment:** ISIT 2025

> **TL;DR:** 本文改进了量化线性计算中访问-冗余权衡的不可行性界限，并首次研究了近似恢复问题，给出了优于精确方案的构造。

**AI_Comments:** 这篇论文在信息理论和编码理论领域具有重要意义。它不仅深化了对量化线性计算中访问-冗余权衡的理解，通过提供更紧密的不可行性界限，还开辟了近似恢复这一新方向。近似恢复的引入可能为实际应用提供更灵活和高效的解决方案，尤其是在对精度要求不那么苛刻但对查询次数有严格限制的场景中。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决量化线性函数的计算问题，即给定实向量x，将其编码为冗余向量c，以便对于任意特定集合A中的向量w，w^T x可以通过对c的少量查询来计算。

**Method:** 本文通过提供改进的不可行性结果来解决精确恢复问题，包括针对一般情况和特定块构造的不可行性结果。此外，本文还首次引入并研究了近似恢复问题，并给出了多种构造方法。

**Result:** 本文获得了量化线性计算中访问-冗余权衡的改进不可行性界限。证明了先前工作中提出的块构造在该类别中是最佳的。对于近似恢复问题，本文给出了多种构造，并且对于ε=0.1的构造，其性能优于对精确方案的不可行性结果。

**Conclusion:** 本文在量化线性计算的访问-冗余权衡方面取得了重要进展，不仅改进了精确恢复的理论界限，还首次开创了近似恢复的研究方向，并展示了近似方案在特定条件下的性能优势。

> **ai_Abstract:** 本文研究了量化线性计算中访问-冗余的权衡问题，旨在用少量查询计算量化线性函数。作者改进了现有研究中的不可行性界限，并证明了先前块构造的最佳性。此外，本文首次提出了近似恢复的概念，并给出了多个构造，其中一些在特定近似度下优于精确恢复的理论限制。

> **摘要翻译:** 考虑仅通过少量查询计算量化线性函数的问题。形式上，给定$\mathbf{x}\in \mathbb{R}^k$，我们的目标是将$\mathbf{x}$编码为$\mathbf{c} \in \mathbb{R}^n$，其中$n > k$，以便对于任何$\mathbf{w} \in A^k$，$\mathbf{w}^T \mathbf{x}$可以通过对$\mathbf{c}$的最多$\ell$次查询来计算。这里，$A$是某个有限集；本文中我们关注$|A| = 2$的情况。
先前的工作（Ramkumar, Raviv, and Tamo, Trans. IT, 2024）为该问题提供了构造并建立了不可行性结果。我们为一般问题和该工作中提出的特定构造类别（块构造）提供了改进的不可行性结果。后者证明了先前工作的块构造在该类别中是最佳的。
我们还首次启动了该问题的“近似”恢复研究，其目标不是精确恢复$\mathbf{w}^T \mathbf{x}$，而是将其近似到参数$\varepsilon > 0$的精度。我们提供了几种构造，并且对于$\varepsilon = 0.1$的构造，其性能优于我们对精确方案的不可行性结果。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [209] [Channel Estimation for Flexible Intelligent Metasurfaces: From Model-Based Approaches to Neural Operators](https://arxiv.org/abs/2508.00268)
> *柔性智能超表面信道估计：从模型驱动方法到神经算子*

*Jian Xiao, Ji Wang, Qimei Cui, Yucang Yang, Xingwang Li, Dusit Niyato, Chau Yuen* | **Category: cs.IT, math.IT** | **Updated: 2025-08-01**

**Keywords:** 柔性智能超表面, 信道估计, 傅里叶神经算子, 毫米波通信, 深度学习

**Comment:** 

> **TL;DR:** 本文研究了柔性智能超表面（FIM）辅助毫米波通信系统中的信道估计问题。提出了基于模型的方法（插值、核方法、稀疏信号恢复）和基于深度学习的方法（傅里叶神经算子FNO和分层FNO H-FNO）。数值结果表明H-FNO在估计精度和导频效率上显著优于模型驱动方法，并能学习适应FIM物理几何的各向异性空间滤波器。

**AI_Comments:** 本文创新性地将傅里叶神经算子（FNO）引入柔性智能超表面（FIM）的信道估计问题，有效解决了传统模型驱动方法在处理FIM连续高维变形空间中的局限性。H-FNO架构的应用，不仅提升了估计精度和导频效率，更重要的是，其学习到的各向异性空间滤波器展现了对FIM物理几何的良好适应性，为理解和优化FIM系统提供了新的视角。这项工作对于推动FIM在未来无线通信中的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 柔性智能超表面（FIMs）通过引入形态自由度为无线通信提供了新方案，但要实现其性能增益，关键在于在连续高维变形空间中获取精确的信道状态信息。因此，本文研究了FIM辅助毫米波通信系统中的信道估计这一基本问题。

**Method:** 本文首先开发了基于模型的方法，将问题构建为使用插值和核函数的函数逼近问题，或利用毫米波信道固有角度稀疏性的稀疏信号恢复问题。为了进一步提升估计能力，提出了基于深度学习的傅里叶神经算子（FNO）框架，通过在傅里叶域参数化全局卷积算子来学习将FIM形状映射到信道响应的连续算子。此外，还利用分层FNO（H-FNO）架构来有效捕获不同空间分辨率下的多尺度特征。

**Result:** 数值结果表明，所提出的H-FNO在估计精度和导频效率方面显著优于基于模型的基准方法。特别是，可解释性分析表明，所提出的H-FNO学习了一种适应FIM物理几何的各向异性空间滤波器，并能够准确重建连续变形空间中的非线性信道响应。

**Conclusion:** 本文提出的分层傅里叶神经算子（H-FNO）在柔性智能超表面辅助通信系统的信道估计中表现出优异的性能，显著超越了传统模型驱动方法，并能有效学习和重建复杂的非线性信道响应。

> **ai_Abstract:** 本文研究了柔性智能超表面（FIM）辅助毫米波通信系统中的信道估计挑战，该挑战源于FIM的连续高维变形空间。文章提出了两种主要方法：一是基于模型的框架，包括函数逼近（插值、核方法）和稀疏信号恢复；二是基于深度学习的框架，特别是傅里叶神经算子（FNO）及其分层版本（H-FNO）。研究表明，H-FNO在估计精度和导频效率上显著优于传统模型驱动方法，并且能够学习适应FIM物理几何的各向异性空间滤波器，准确重建非线性信道响应。

> **摘要翻译:** 柔性智能超表面（FIMs）通过引入形态自由度，动态改变其三维形状以确保多径信号建设性干涉，为无线通信提供了新的解决方案。然而，在FIM系统中实现所需的性能增益，关键取决于在连续高维变形空间中获取准确的信道状态信息。因此，本文研究了FIM辅助毫米波通信系统中的这一基本信道估计问题。首先，我们开发了基于模型的框架，将问题构建为使用插值和核方法的函数逼近，或利用毫米波信道固有角度稀疏性的稀疏信号恢复问题。为了进一步提升超越基于模型信道估计框架中明确假设的估计能力，我们提出了一个基于深度学习的框架，使用傅里叶神经算子（FNO）。通过在傅里叶域参数化全局卷积算子，我们设计了一个高效的FNO架构来学习将FIM形状映射到信道响应的连续算子，该算子具有与网格无关的特性。此外，我们利用分层FNO（H-FNO）架构来有效捕获跨空间分辨率层次的多尺度特征。数值结果表明，所提出的H-FNO在估计精度和导频效率方面显著优于基于模型的基准方法。特别是，可解释性分析表明，所提出的H-FNO学习了一种适应FIM物理几何的各向异性空间滤波器，并能够准确重建连续变形空间中的非线性信道响应。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [239] [Active IRS-Enabled Integrated Sensing and Communications with Extended Targets](https://arxiv.org/abs/2508.00379)
> *主动式IRS赋能的扩展目标集成感知与通信*

*Yuan Fang, Xianxin Song, Huazhou Hou, Ziguo Zhong, Xianghao Yu, Jie Xu, Yongming Huang* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-08-01**

**Keywords:** 主动式IRS, 集成感知与通信, 克拉美美罗下界, 波束成形, 交替优化

**Comment:** 

> **TL;DR:** 本论文研究了主动式智能反射面(IRS)辅助的集成感知与通信(ISAC)，旨在通过优化基站和IRS的波束成形，在满足通信需求的同时，最小化对非视距扩展目标的感知克拉美罗下界(CRB)。

**AI_Comments:** 本文创新性地将主动式IRS引入到ISAC系统中，解决了NLoS环境下严重的路径损耗问题。其联合优化波束成形以最小化感知CRB的方法，并提出高效的AO算法，为未来ISAC系统的设计提供了重要的理论和实践指导。特别是，发现主动式IRS总是以最大增益放大信号的结论，对实际部署具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在非视距(NLoS)区域，信号反射路径损耗显著，影响了集成感知与通信(ISAC)的性能。主动式智能反射面(IRS)能够放大反射信号，从而克服这一挑战，提高NLoS环境下的通信和感知能力。

**Method:** 本文首先推导了用于估计目标响应矩阵的感知克拉美罗下界(CRB)。然后，联合优化基站的发射波束成形和主动式IRS的反射波束成形，以最小化感知CRB，同时满足通信用户的信噪比(SINR)要求、基站和主动式IRS的发射功率预算以及主动式IRS的功率放大增益限制。针对非凸的CRB最小化问题，首先考虑了仅感知场景，并推导了闭式最优发射波束成形；接着提出了两种高效的基于交替优化(AO)的算法来解决通用的ISAC场景。

**Result:** 研究发现，在实际系统设置下，主动式IRS总是使用最大放大增益来放大信号。数值结果验证了所提出的AO算法的有效性，并表明主动式IRS赋能的ISAC比无源IRS具有更好的性能。

**Conclusion:** 本文提出了主动式IRS赋能的ISAC系统，并针对扩展目标感知和多用户通信场景进行了联合优化。通过推导感知CRB并采用交替优化算法，成功最小化了感知误差，并克服了NLoS环境下的路径损耗问题。研究结果表明主动式IRS在ISAC系统中具有显著优势。

> **ai_Abstract:** 本论文探讨了主动式智能反射面（IRS）在集成感知与通信（ISAC）中的应用，旨在协助基站同时服务通信用户并感知非视距（NLoS）区域的扩展目标。通过推导感知克拉美罗下界（CRB），并联合优化基站和主动式IRS的波束成形，以最小化CRB，同时满足通信和功率约束。针对非凸问题，提出了基于交替优化（AO）的算法，并验证了主动式IRS在克服NLoS路径损耗和提升ISAC性能方面的有效性。

> **摘要翻译:** 本文研究了主动式智能反射面（IRS）赋能的集成感知与通信（ISAC），其中部署主动式IRS以协助基站（BS）服务多个通信用户（CU）并同时感知基站非视距（NLoS）区域的扩展目标。主动式IRS具有放大反射信号的能力，从而克服NLoS通信和感知中显著的反射路径损耗。特别是，我们推导了用于估计目标响应矩阵的感知克拉美罗下界（CRB）。因此，我们联合优化基站的发射波束成形和主动式IRS的反射波束成形，以最小化感知CRB，同时满足通信用户的信干噪比（SINR）要求、基站和主动式IRS的发射功率预算以及主动式IRS的功率放大增益限制。CRB最小化问题是高度非凸的，因此通常难以解决。为了应对这一挑战，我们首先通过忽略通信的SINR约束，关注两种特定条件下的仅感知场景，并推导出了闭式最优发射波束成形。然后，我们提出了两种高效的基于交替优化（AO）的算法，以获得通用ISAC场景的高质量解决方案。接下来，我们分析了基站功率缩放与主动式IRS放大缩放之间的内在关系。结果表明，在实际系统设置下，主动式IRS总是使用最大放大增益来放大信号。最后，提供了数值结果以验证所提出的基于AO算法的有效性以及主动式IRS赋能的ISAC相对于其无源IRS对应物的优势。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [269] [LO-Aware Adaptive Modulation for Rydberg Atomic Receivers](https://arxiv.org/abs/2508.00458)
> *针对里德堡原子接收机的LO感知自适应调制*

*Jiuyu Liu, Yi Ma, Rahim Tafazolli* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-08-01**

**Keywords:** 里德堡原子接收机, 自适应调制, LO感知, 量子通信, 幅度检测

**Comment:** Accepted by IEEE GLOBECOM 2025

> **TL;DR:** 本文提出了一种名为LO感知自适应调制（LOAM）的新方案，专为里德堡原子（RA）接收机设计，通过动态适应衰落信道和最大化星座点间的最小幅度差，显著提升了RA接收机的性能，仿真结果显示性能增益超过45 dB。

**AI_Comments:** 本文的创新点在于为里德堡原子接收机（一种仅检测幅度的量子接收器）设计了专门的自适应调制方案，有效地解决了其相位信息丢失和传统调制方案不适用的根本性问题。其提出的LOAM方案，特别是自适应共线星座架构以及根据本地振荡器（LO）信号强度动态调整星座点分布的机制，是核心创新。仿真结果中超过45 dB的巨大性能增益，充分展示了该方案在未来量子通信领域的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 里德堡原子（RA）接收机作为一种革命性的量子无线通信技术，虽然灵敏度远超传统射频（RF）天线，但其仅检测信号幅度，导致关键相位信息的丢失。尽管本地振荡器（LO）产生的参考信号可以辅助相位恢复，但现有为传统系统设计的调制方案在这种量子检测机制下表现不佳。因此，需要一种新的调制方案来解决RA接收机相位信息丢失和现有调制方案性能差的问题。

**Method:** 本文提出了一种突破性的LO感知自适应调制（LOAM）方案，专为里德堡原子（RA）接收机开发，能够动态适应复杂的衰落信道系数。LOAM通过最大化星座点间的最小幅度差来确保最佳检测性能。该创新方案采用了一种自适应共线星座架构，与参考信号和信道系数的组合相位对齐。对于强参考信号，LOAM生成以原点为中心的对称星座点；对于弱信号，则采用非对称分布。文章还数学推导了控制这些操作模式的阈值。

**Result:** 仿真结果显示，LOAM方案具有变革性的影响，与包括正交幅度调制（QAM）、相移键控（PSK）和脉冲幅度调制（PAM）在内的传统调制方案相比，性能增益超过45 dB。

**Conclusion:** LOAM方案通过专门为里德堡原子接收机设计自适应调制机制，有效解决了相位信息丢失和传统调制方案性能不佳的问题，极大地提升了RA接收机的性能，使其在无线通信领域更具应用潜力。

> **ai_Abstract:** 里德堡原子（RA）接收机作为一种前沿的量子无线通信技术，面临着仅能检测信号幅度而导致相位信息丢失的挑战。针对此问题，本文提出了一种新颖的LO感知自适应调制（LOAM）方案。该方案专为RA接收机设计，能够动态适应复杂的衰落信道，并通过优化星座点以最大化最小幅度差来确保最佳检测性能。LOAM采用自适应共线星座架构，并根据参考信号强度动态调整星座点的对称性。仿真结果表明，与传统调制方案相比，LOAM实现了超过45 dB的显著性能提升。

> **摘要翻译:** 里德堡原子（RA）接收机代表着无线通信领域的一项革命性量子技术，其灵敏度超越了传统的射频（RF）天线。然而，这些接收机仅检测信号幅度，从而丢失了关键的相位信息。尽管本地振荡器（LO）产生的参考信号可以辅助相位恢复，但现有为传统系统设计的调制方案在这种量子检测机制下表现不佳。本文引入了一种突破性的LO感知自适应调制（LOAM）方案，该方案专为RA接收机开发，能够动态适应复杂的衰落信道系数。LOAM通过最大化星座点间的最小幅度差来确保最佳检测性能。这项创新采用了一种自适应共线星座架构，与参考信号和信道系数的组合相位对齐。对于强参考信号，LOAM生成以原点为中心的对称星座点；对于弱信号，则采用非对称分布。本文从数学上推导了控制这些操作模式的阈值。仿真结果揭示了LOAM的变革性影响，与包括正交幅度调制（QAM）、相移键控（PSK）和脉冲幅度调制（PAM）在内的传统调制方案相比，性能增益超过45 dB。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [299] [Appendices for "Closed-Form BER Analysis for Uplink NOMA with Dynamic SIC Decoding"](https://arxiv.org/abs/2508.00540)
> *《具有动态SIC解码的上行NOMA的闭式BER分析》的附录*

*Hequn Zhang, Qu Luo, Pei Xiao, Yue Zhang, Huiyu Zhou* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-08-01**

**Keywords:** NOMA, BER分析, SIC解码, 数学推导, 附录

**Comment:** 

> **TL;DR:** 本文档是《具有动态SIC解码的上行NOMA的闭式BER分析》论文的补充材料，提供了详细的数学推导和证明。

**AI_Comments:** 本文档作为一篇主论文的附录，其创新性和重要性在于提供了主论文中复杂分析框架所需的详细数学推导和证明。它并非一篇独立的创新性论文，而是对现有研究成果的数学支撑和完善，对于理解和验证主论文的结论至关重要。其局限性在于，它本身不提出新的理论或方法，而是专注于现有理论的数学细节。

<details>
  <summary>Details</summary>

**Motivation:** 本文档的目的是为《具有动态SIC解码的上行NOMA的闭式BER分析》这篇主论文提供补充材料，包括详细的数学推导和证明，以支持主论文的分析框架。

**Method:** 本文档通过提供详细的数学推导和证明来支持主论文的分析框架，具体包括：有序信道增益的累积分布函数、NOMA动态SIC解码中归一化信号加干扰方差的概率密度函数、双用户闭式成对错误概率表达式、双UE情况下信道增益排序的概率推导、M-QAM调制方案的BER分析、各种排序条件下信道增益的PDF推导，以及各种排序条件下信道增益实部PDF推导的挑战。

**Result:** 这些附录提供了数学基础，使得能够在瑞利衰落信道下对具有动态SIC解码的上行NOMA系统进行闭式BER分析，并支持各种调制方案和系统配置的解析表达式。

**Conclusion:** 本文档提供的数学基础和详细推导，为《具有动态SIC解码的上行NOMA的闭式BER分析》这篇主论文的闭式BER分析提供了全面的支持。

> **ai_Abstract:** 本文档是关于“具有动态SIC解码的上行NOMA的闭式BER分析”论文的补充材料，主要提供了支持主论文分析框架的详细数学推导和证明。内容涵盖了有序信道增益的累积分布函数、NOMA动态SIC解码中的概率密度函数、成对错误概率的闭式表达式、信道增益排序的概率推导、M-QAM调制方案的BER分析以及信道增益PDF的推导等，这些数学基础支撑了瑞利衰落信道下上行NOMA系统闭式BER分析。

> **摘要翻译:** 本文档为论文《具有动态SIC解码的上行NOMA的闭式BER分析》提供了补充材料。附录中提供了详细的数学推导和证明，以支持主论文的分析框架。具体而言，我们包括：(i) 有序信道增益的累积分布函数；(ii) NOMA动态SIC解码中归一化信号加干扰方差的概率密度函数；(iii) 两个用户成对错误概率（PEP）的闭式表达式；(iv) 两个UE情况下信道增益排序的概率推导，特别是当UE 1和UE 2具有最强或次强信道增益时；(v) 包括BPSK、4QAM、16QAM和64QAM在内的M-QAM调制方案的BER分析；(vi) 各种排序条件下信道增益的PDF推导；以及(vii) 各种排序条件下信道增益实部PDF推导的挑战。这些数学基础使得能够在瑞利衰落信道下对具有动态SIC解码的上行NOMA系统进行闭式BER分析，支持各种调制方案和系统配置的解析表达式。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [329] [Deep Learning-Based Rate-Adaptive CSI Feedback for Wideband XL-MIMO Systems in the Near-Field Domain](https://arxiv.org/abs/2508.00626)
> *深度学习驱动的近场域宽带XL-MIMO系统速率自适应CSI反馈*

*Zhenyu Liu, Yi Ma, Rahim Tafazolli* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-08-01**

**Keywords:** 深度学习, CSI反馈, XL-MIMO, 近场通信, 速率自适应

**Comment:** 

> **TL;DR:** 提出WideNLNet-CA，一个基于深度学习的速率自适应框架，用于解决宽带近场XL-MIMO系统中CSI反馈的挑战。

**AI_Comments:** 该论文的创新点在于提出了一个速率自适应的深度学习框架WideNLNet-CA，它通过一个单一模型即可支持多种反馈速率，这在实际应用中具有很高的灵活性和实用性。其轻量级架构和高效的残差块设计也有效降低了计算和存储开销。解决了宽带近场XL-MIMO系统中CSI反馈的复杂挑战，对于未来6G网络的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在未来6G网络中，极大规模MIMO (XL-MIMO) 系统要实现显著的频谱效率增益，准确高效的信道状态信息 (CSI) 反馈至关重要。然而，宽带场景下近场球形波传播和频率依赖的波束分裂效应给CSI表示和压缩带来了巨大挑战。

**Method:** 本文提出了WideNLNet-CA，一个速率自适应的深度学习框架，旨在实现宽带近场XL-MIMO系统中高效的CSI反馈。WideNLNet-CA引入了一种轻量级的编码器-解码器架构，具有多阶段下采样和上采样，并结合了计算高效的残差块，以更低的开销捕获复杂的多尺度信道特征。此外，还引入了一个新颖的、带有特征重要性估计的压缩比自适应模块，根据目标压缩比动态调节特征选择，使得单个模型能够灵活适应各种反馈速率。

**Result:** 评估结果表明，WideNLNet-CA在各种压缩比和带宽下，始终优于现有的压缩感知和基于深度学习的方法，同时保持快速推理和低模型存储需求。

**Conclusion:** WideNLNet-CA成功解决了宽带近场XL-MIMO系统中CSI反馈的挑战，通过其速率自适应和高效的架构，实现了卓越的性能，并为未来6G网络中的XL-MIMO系统提供了实用的解决方案。

> **ai_Abstract:** 本文提出了WideNLNet-CA，一个针对宽带近场XL-MIMO系统的高效速率自适应深度学习CSI反馈框架。该框架采用轻量级编解码器架构和计算高效的残差块，并引入创新的压缩比自适应模块，通过特征重要性估计动态调整特征选择。实验结果表明，WideNLNet-CA在不同压缩比和带宽下，性能优于现有方法，且推理速度快、模型存储需求低。

> **摘要翻译:** 准确高效的信道状态信息（CSI）反馈对于在未来6G网络中解锁极大规模MIMO（XL-MIMO）系统的显著频谱效率增益至关重要。然而，宽带场景下近场球形波传播和频率依赖的波束分裂效应的结合给CSI表示和压缩带来了重大挑战。本文提出了WideNLNet-CA，一个速率自适应的深度学习框架，旨在实现宽带近场XL-MIMO系统中高效的CSI反馈。WideNLNet-CA引入了一种轻量级的编码器-解码器架构，具有多阶段下采样和上采样，并结合了计算高效的残差块，以更低的开销捕获复杂的多尺度信道特征。引入了一个新颖的、带有特征重要性估计的压缩比自适应模块，根据目标压缩比动态调节特征选择，使得单个模型能够灵活适应各种反馈速率。评估结果表明，WideNLNet-CA在各种压缩比和带宽下，始终优于现有的压缩感知和基于深度学习的方法，同时保持快速推理和低模型存储需求。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [399] [Stochastic Geometry and Dynamical System Analysis of Walker Satellite Constellations](https://arxiv.org/abs/2412.01610)
> *Walker卫星星座的随机几何与动力系统分析*

*Chang-Sik Choi, Francois Baccelli* | **Category: cs.IT, math.IT** | **Updated: 2025-08-01**

**Keywords:** Walker星座, 随机几何, 动力系统, 卫星通信, LEO/MEO

**Comment:** full version of the paper accepted to IEEE Trans. Veh. Technol

> **TL;DR:** 本文为Walker卫星星座开发了一个随机几何模型，并结合动力系统理论分析其结构特性，同时通过随机几何分析推导下行链路通信性能。

**AI_Comments:** 该研究通过引入随机几何模型和结合动力系统理论，为Walker卫星星座的分析提供了一种新颖且全面的方法，有助于理解其结构特性和通信性能。其创新性在于将两种理论结合用于卫星星座分析，为星座设计和优化提供了新的分析工具。

<details>
  <summary>Details</summary>

**Motivation:** 低地球轨道（LEO）和中地球轨道（MEO）卫星网络广泛采用Walker星座结构，需要对其结构特性和通信性能进行分析。

**Method:** 开发了一个Walker星座的随机几何模型，并结合动力系统理论分析周期性和遍历性等结构属性，同时利用随机几何分析推导典型用户下行链路通信性能。

**Result:** 该模型能够分析Walker星座的周期性和遍历性等结构特性，并能推导典型用户在给定纬度下的下行链路通信性能，且性能是关键星座参数的函数。

**Conclusion:** 本文提出的随机几何模型结合动力系统理论，能够有效地分析Walker卫星星座的关键结构属性和下行链路通信性能，为未来星座设计和优化提供分析工具。

> **ai_Abstract:** 本文为广泛用于LEO和MEO卫星网络的Walker星座提出了一个随机几何模型。该模型结合动力系统理论，可用于分析Walker星座的周期性和遍历性等结构特性。此外，它还支持随机几何分析，从而能够推导典型用户在特定纬度下的下行链路通信性能，并将其表达为关键星座参数的函数。

> **摘要翻译:** 在实践中，低地球轨道（LEO）和中地球轨道（MEO）卫星网络由多个轨道组成，每个轨道上部署了许多卫星。LEO或MEO卫星广泛使用的空间架构是Walker星座，其中轨道的经度是均匀间隔的，卫星沿轨道均匀间隔。在本文中，我们为Walker星座开发了一个随机几何模型。这个提出的模型能够基于动力系统理论进行分析，从而解决周期性和遍历性等基本结构属性。它还能够进行随机几何分析，在此分析下，我们推导了在给定纬度下典型用户的下行链路通信性能，该性能是关键星座参数的函数。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [423] [Channel Resolvability Using Multiplicative Weight Update Algorithm](https://arxiv.org/abs/2501.11881)
> *信道可分辨性与乘性权重更新算法*

*Koki Takahashi, Shun Watanabe* | **Category: cs.IT, math.IT** | **Updated: 2025-07-31**

**Keywords:** 信道可分辨性, 乘性权重更新算法, 非随机编码, 强逆定理

**Comment:** 8 pages. Version 2 is for correcting typo. Version 3 improved
  presentation. Version 4 corrects a minor error in the proof of Theorem 10;
  the result itself is unaffected

> **TL;DR:** 本文首次使用乘性权重更新算法证明了信道可分辨性，这是非随机编码方法在该问题上的首次应用。

**AI_Comments:** 这项工作的创新在于首次将乘性权重更新算法引入到信道可分辨性问题的证明中，突破了传统随机编码的限制，为信息论中相关问题的解决提供了新的非随机方法。

<details>
  <summary>Details</summary>

**Motivation:** 研究信道可分辨性问题，该问题用于证明通过信道的识别的强逆定理。此前，信道可分辨性仅通过随机编码解决，本文旨在探索非随机编码方法。

**Method:** 使用乘性权重更新算法（multiplicative weight update algorithm）来证明信道可分辨性。

**Result:** 成功地使用乘性权重更新算法证明了信道可分辨性。

**Conclusion:** 首次通过非随机编码方法（乘性权重更新算法）解决了信道可分辨性问题。

> **ai_Abstract:** 本论文探讨了信道可分辨性问题，该问题在证明通过信道的识别的强逆定理中具有重要作用。论文首次采用乘性权重更新算法来证明信道可分辨性，与以往文献中仅依赖随机编码的方法不同，开创了使用非随机编码方法解决此问题的新途径。

> **摘要翻译:** 我们研究了信道可分辨性问题，该问题用于证明通过信道的识别的强逆定理。信道可分辨性在文献中仅通过随机编码解决。我们使用乘性权重更新算法证明了信道可分辨性。这是首次使用非随机编码方法解决信道可分辨性问题。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [442] [Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience](https://arxiv.org/abs/2508.00596)
> *信息论去中心化安全聚合与合谋弹性*

*Xiang Zhang, Zhou Li, Shuangyang Li, Kai Wan, Derrick Wing Kwan Ng, Giuseppe Caire* | **Category: cs.IT, cs.CR, cs.DC, cs.LG, math.IT** | **Updated: 2025-08-01**

**Keywords:** 去中心化安全聚合, 信息论, 合谋弹性, 联邦学习, 秘密密钥速率

**Comment:** Submitted to IEEE for potential journal publication

> **TL;DR:** 本文从信息论角度研究了去中心化安全聚合（DSA）问题，考虑了合谋弹性，并确定了实现安全聚合所需的通信和秘密密钥的最小速率，为分布式学习提供了基本性能极限。

**AI_Comments:** 这项工作通过引入信息论视角，填补了去中心化安全聚合领域在理论极限理解上的空白。其对通信和密钥使用最优速率的量化，为未来设计具有可证明安全性和高通信效率的分布式学习协议提供了重要的理论指导。特别是在去中心化和合谋弹性方面的考虑，使其结果更具实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有安全聚合研究主要关注协议设计和计算保证，对信息论极限理解有限。在去中心化设置中，通信和密钥使用的最优界限仍未知。

**Method:** 本文从信息论角度研究去中心化安全聚合（DSA），考虑一个由K个全连接用户组成的网络，每个用户持有私有输入，目标是安全计算所有输入的总和，并要求即使与多达T个用户合谋，任何用户都不能学习到输入总和之外的信息。通过刻画最优速率区域来确定DSA的最小可实现通信和秘密密钥速率。

**Result:** 研究揭示了DSA的通信和密钥使用的最优速率区域。具体而言，为安全计算一个输入和的符号，每个用户必须传输至少一个符号，持有至少一个秘密密钥符号，且所有用户共同持有不少于K-1个独立的密钥符号。

**Conclusion:** 本研究结果确立了去中心化安全聚合（DSA）的基本性能极限，为分布式学习系统中设计可证明安全且通信高效的协议提供了见解。

> **ai_Abstract:** 本文从信息论角度深入研究了去中心化联邦学习中的安全聚合问题，尤其关注了在无中心聚合器且存在用户合谋情况下的安全保障。通过刻画最优速率区域，作者确定了实现安全聚合所需的通信和秘密密钥的最小量，为分布式学习系统设计高效且具有可证明安全性的协议提供了关键的理论基础和性能极限。

> **摘要翻译:** 在去中心化联邦学习（FL）中，多个客户端通过交互式交换中间模型更新，利用其在网络中私有持有的数据集，协作学习共享的机器学习（ML）模型。为了确保数据安全，通常采用密码技术来保护聚合过程中的模型更新。尽管安全聚合的兴趣日益增长，但现有工作主要集中在协议设计和计算保证上，对这类系统的基本信息论极限理解有限。此外，在没有中央聚合器的去中心化设置中，通信和密钥使用的最优界限仍然未知。受这些差距的启发，我们从信息论的角度研究了去中心化安全聚合（DSA）问题。具体来说，我们考虑一个由K个全连接用户组成的网络，每个用户持有一个私有输入——本地训练数据的抽象——他们的目标是安全地计算所有输入的总和。安全约束要求即使与多达T个其他用户合谋，任何用户都不能学习到输入总和之外的任何信息。我们刻画了最优速率区域，它指定了DSA的最小可实现通信和秘密密钥速率。特别是，我们表明，为了安全地计算一个所需输入和的符号，每个用户必须（i）至少向其他用户传输一个符号，（ii）持有至少一个秘密密钥符号，以及（iii）所有用户必须共同持有不少于K-1个独立的密钥符号。我们的结果确立了DSA的基本性能极限，为分布式学习系统中可证明安全且通信高效的协议设计提供了见解。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [449] [Radio Map-Enabled 3D Trajectory and Communication Optimization for Low-Altitude Air-Ground Cooperation](https://arxiv.org/abs/2505.06944)
> *启用无线电地图的低空空地协同三维轨迹与通信优化*

*Menghao Hu, Tong Zhang, Shuai Wang, Chiya Zhang, Changyang She, Gaojie Chen, Miaowen Wen* | **Category: cs.IT, math.IT** | **Updated: 2025-08-01**

**Keywords:** 低空经济, 空地协同, 轨迹优化, 通信优化, WS-PSO-CM

**Comment:** 6 pages; 6 figures; submit to IEEE for possible publication

> **TL;DR:** 本文研究低空空地协同系统中三维轨迹与通信优化，提出一种联合优化算法，结合SCA和新型WS-PSO-CM，显著提高UGV数据上传的最小和速率并降低计算时间。

**AI_Comments:** 本文的创新点在于提出了一个针对低空空地协同系统的联合优化框架，特别是引入了温启动粒子群优化（WS-PSO-CM）算法。WS-PSO-CM利用凸优化结果进行初始化，显著提升了粒子群算法的性能和收敛速度，解决了传统PSO在复杂优化问题中可能面临的效率问题。这项工作对于提升未来低空经济中空地协作系统的通信效率和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 低空经济涉及无人机（UAV）为地面机器人提供服务。本文旨在解决低空空地协同系统中三维（3D）轨迹和通信优化问题，其中移动式无人地面车辆（UGV）向无人机上传数据，目标是在确保服务质量和导航约束的同时，最大化UGV的最小和速率。

**Method:** 本文提出一种联合优化算法。该算法集成了：1) 用于UGV-UAV调度的逐次凸逼近（SCA）-惩罚方法；2) 用于UGV发射功率控制的基于SCA的方法；3) 一种新颖的带交叉变异的温启动粒子群优化（WS-PSO-CM）算法。WS-PSO-CM利用统计信道模型中的凸优化结果来初始化粒子群。

**Result:** 模拟结果表明，在相同迭代次数下，所提出的算法比基线PSO-CM实现了45.8%更高的最小和速率。这一增益可转化为将PSO-CM的计算时间减少46.7%。此外，模拟结果显示，无人机动态调整轨迹以避免建筑物干扰，并保持与UGV的接近以减轻路径损耗。

**Conclusion:** 本文提出的联合优化算法，特别是结合了WS-PSO-CM，显著提高了低空空地协同系统中数据上传的性能（和速率和计算效率），并展示了有效的轨迹调整能力。

> **ai_Abstract:** 本文针对低空空地协同系统中无人地面车辆（UGV）向无人机（UAV）上传数据的场景，研究了三维轨迹与通信联合优化问题。为最大化UGV的最小和速率并满足服务质量和导航约束，作者提出了一种联合优化算法。该算法结合了SCA-惩罚调度、SCA功率控制以及一种新颖的温启动粒子群优化（WS-PSO-CM）方法，其中WS-PSO-CM利用凸优化结果进行初始化。仿真结果验证了该算法能显著提高最小和速率（比基线PSO-CM高45.8%）并大幅减少计算时间（46.7%），同时展示了无人机动态调整轨迹以规避干扰和优化通信的能力。

> **摘要翻译:** 低空经济包括无人机（UAV）为地面机器人提供服务的应用。本文研究了低空空地协同系统的三维（3D）轨迹和通信优化，其中移动式无人地面车辆（UGV）向无人机上传数据。我们提出了一种联合优化算法，以最大化UGV的最小和速率，同时确保服务质量和导航约束。所提出的算法集成了用于UGV-UAV调度的逐次凸逼近（SCA）-惩罚方法、用于UGV发射功率控制的基于SCA的方法，以及一种新颖的带交叉变异的温启动粒子群优化（WS-PSO-CM）算法。WS-PSO-CM利用统计信道模型中的凸优化结果来初始化粒子群，与著名的PSO-CM相比，显著提高了性能。模拟结果表明，所提出的算法在相同迭代次数下比基线PSO-CM实现了45.8%更高的最小和速率。这一增益可转化为将PSO-CM的计算时间减少46.7%。此外，我们的模拟结果显示，无人机动态调整轨迹以避免建筑物干扰，并保持与UGV的接近以减轻路径损耗。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [553] [Towards a Measure Theory of Semantic Information](https://arxiv.org/abs/2508.00525)
> *迈向量子语义信息理论*

*George M. Coghill* | **Category: cs.IT, cs.AI, math.IT** | **Updated: 2025-08-01**

**Keywords:** 语义信息, Bar-Hillel-Carnap悖论, 信息度量, 单位圆

**Comment:** 17 pages,3 figures

> **TL;DR:** 本文提出了一种基于单位圆的新方法，通过类比冯·诺依曼的量子概率，构建了一个信息度量空间，解决了Bar-Hillel-Carnap悖论，并纠正了Floridi理论的不足。

**AI_Comments:** 本文创新性地将单位圆和量子概率的概念引入语义信息度量，有效解决了经典的Bar-Hillel-Carnap悖论，并对矛盾和同义反复的信息量给出了新的定义，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 经典的Bar-Hillel-Carnap语义信息量化理论存在一个悖论，即矛盾语句被赋予最大信息量。Floridi曾提出一种基于距离度量和抛物线关系的新理论试图解决此悖论，但未能成功。

**Method:** 本文首先批判性地分析了Floridi的强语义信息理论的成功与失败之处。随后，提出了一种基于单位圆的新方法，并类比冯·诺依曼的量子概率来构建一个信息度量空间。

**Result:** 所提出的新方法成功满足了Floridi提出的所有要求，并消除了Bar-Hillel-Carnap悖论。在该方法中，矛盾和同义反复的信息量为零，但相互矛盾的消息被发现具有相同的信息量。

**Conclusion:** 通过基于单位圆和量子概率类比构建的信息度量空间，本文成功解决了语义信息量化中的Bar-Hillel-Carnap悖论，并为矛盾和同义反复的信息量提供了新的见解。

> **ai_Abstract:** 本文批判性地分析了Floridi的强语义信息理论的局限性，并提出了一种基于单位圆和冯·诺依曼量子概率类比的新方法。该方法成功构建了一个信息度量空间，解决了Bar-Hillel-Carnap悖论，确保矛盾和同义反复的信息量为零，同时指出相互矛盾的消息具有相同的信息量。

> **摘要翻译:** 语义信息量化的一种经典解释是Bar-Hillel和Carnap的理论。他们的理论提出语句的信息量与其概率之间存在反向关系。然而，他们的方法将最大信息量赋予了矛盾：Floridi将其称为Bar-Hillel-Carnap悖论。Floridi发展了一种基于距离度量和抛物线关系的新理论，旨在消除这个悖论。不幸的是，他的方法未能实现这一目标。
在本文中，我批判性地审视了Floridi的强语义信息理论，并揭示了其成功与失败之处。然后，我提出了一种基于单位圆的新方法（这种关系是基础三角学到量子理论等多种理论的基础）。通过类比冯·诺依曼的量子概率，利用这种方法构建了一个信息度量空间，该空间满足了Floridi提出的所有要求并消除了悖论。此外，虽然矛盾和同义反复的信息量为零，但发现相互矛盾的消息具有相同的信息量。通过一个例子解释了这种实用性。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [4] [Gradient Leakage Defense with Key-Lock Module for Federated Learning](https://arxiv.org/abs/2305.04095)
> *联邦学习中基于密钥锁模块的梯度泄露防御*

*Hanchi Ren, Jingjing Deng, Xianghua Xie* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 联邦学习, 梯度泄露, 隐私保护, 密钥锁模块, 防御

**Comment:** The source code can be found at https://github.com/Rand2AI/FedKL

> **TL;DR:** 本研究提出了一种基于密钥锁模块的新型梯度泄露防御技术，以保护联邦学习中共享梯度的隐私，并在保持模型性能的同时有效抵御梯度泄露攻击。

**AI_Comments:** 该论文提出了一种创新的基于密钥锁模块的梯度泄露防御机制，解决了联邦学习中一个关键的隐私安全问题。其创新点在于通过引入一个可训练的私有密钥锁模块来“锁定”梯度，使得在没有私钥的情况下数据重建变得不可行，并能降低模型性能，从而提供双重保障。该方法具有普适性，可应用于任意模型架构，并且结合了理论证明和广泛的实验验证，增强了其说服力。这对于提升联邦学习的实际应用安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）虽然被广泛认为是保护隐私的机器学习方法，但最近研究发现，共享的梯度可能泄露敏感的私有数据。本研究旨在深入分析梯度泄露问题，并提出一种有效的防御机制来解决这一挑战。

**Method:** 本研究提出了一种新的梯度泄露防御技术，该技术使用一个私有密钥锁模块来保护任意模型架构。只有经过锁定的梯度才会被传输到参数服务器进行全局模型聚合。密钥锁模块经过设计和训练，确保在没有私有密钥锁信息的情况下，无法从共享梯度中重建私有训练数据，并且会显著损害全局模型的推理性能。论文还提供了理论证明来支撑方法的有效性。

**Result:** 通过在多个流行基准上对多种模型进行广泛的实证评估，结果表明所提出的方法在保持模型性能和抵御梯度泄露攻击方面均表现出强大的鲁棒性。

**Conclusion:** 本研究提出的基于密钥锁模块的梯度泄露防御方法，能够有效保护联邦学习中共享梯度的隐私，同时保持全局模型的性能，抵御梯度泄露攻击。

> **ai_Abstract:** 本文深入分析了联邦学习中存在的梯度泄露问题，并提出了一种新颖的防御技术。该技术引入了一个私有密钥锁模块，确保只有加密后的梯度被传输，从而在没有私有密钥信息的情况下，攻击者无法重建原始训练数据，并且会严重影响模型性能。理论分析和广泛的实验结果均证明了该方法在维护模型性能的同时，能有效抵御梯度泄露攻击。

> **摘要翻译:** 联邦学习（FL）是一种广泛采用的隐私保护机器学习方法，其中私有数据保留在本地，从而实现安全计算以及本地客户端与第三方参数服务器之间本地模型梯度的交换。然而，最近的研究发现，隐私可能会受到损害，敏感信息可能从共享梯度中恢复。在本研究中，我们对理解梯度泄露问题提供了详细分析和新颖的视角。这些理论工作引出了一种新的梯度泄露防御技术，该技术使用私有密钥锁模块来保护任意模型架构。只有锁定的梯度被传输到参数服务器进行全局模型聚合。我们提出的学习方法能够抵抗梯度泄露攻击，并且密钥锁模块的设计和训练旨在确保，在没有密钥锁模块的私有信息的情况下：a) 从共享梯度重建私有训练数据是不可行的；b) 全局模型的推理性能会受到显著损害。我们讨论了梯度为何会泄露私有信息的理论基础，并提供了我们方法有效性的理论证明。我们对许多模型在几个流行基准上进行了广泛的实证评估，证明了我们提出的方法在保持模型性能和抵御梯度泄露攻击方面的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [20] [TensorSocket: Shared Data Loading for Deep Learning Training](https://arxiv.org/abs/2409.18749)
> *TensorSocket：深度学习训练的共享数据加载*

*Ties Robroek, Neil Kim Nielsen, Pınar Tözün* | **Category: cs.LG, cs.DC** | **Updated: 2025-08-01**

**Keywords:** 深度学习训练, 数据加载, 共享内存, 性能优化, 资源节约

**Comment:** 

> **TL;DR:** TensorSocket通过允许多个深度学习训练过程共享同一个数据加载器，显著减少了CPU侧的计算瓶颈和资源消耗，提高了训练吞吐量并降低了成本。

**AI_Comments:** TensorSocket的创新之处在于其对深度学习训练中数据加载瓶颈的独到解决方案，特别是在CPU资源限制和重复性任务场景下。通过实现数据加载器的共享和利用GPU-GPU互连，它有效地提高了资源利用率和训练效率。该方法不仅提升了吞吐量和降低了成本，还强调了其易于部署和维护的优点，使其在实际应用中具有重要价值。其硬件和管道无关的特性也增加了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型训练是一个重复且资源密集的过程，数据科学家经常需要训练多个模型来寻找最佳参数和架构。这种重复性导致相同的数据处理管道反复运行，加剧了计算资源的需求和成本。当GPU吞吐量高但CPU数据加载吞吐量较低时，会出现CPU侧瓶颈，限制了训练效率。

**Method:** 本文提出了TensorSocket，通过允许同时进行的训练过程共享同一个数据加载器来减少深度学习训练的计算需求。TensorSocket通过减少协同训练过程中的冗余计算和数据复制，并利用现代GPU-GPU互连技术来缓解CPU侧瓶颈。此外，TensorSocket能够训练和平衡不同大小的模型，同时服务多个批次大小，并且与硬件和管道无关。

**Result:** TensorSocket实现了在没有数据共享时不可行的场景，将训练吞吐量提高了高达100%。在使用云实例时，通过减少CPU侧的硬件资源需求，实现了50%的成本节约。此外，TensorSocket在共享数据加载方面优于现有的最先进解决方案，如CoorDL和Joader，它更易于部署和维护，并且在需要更少CPU资源的同时，要么实现更高的吞吐量，要么与其持平。

**Conclusion:** TensorSocket通过创新的数据共享机制，显著提升了深度学习训练的效率和经济性，解决了CPU侧数据加载瓶颈，并超越了现有解决方案。

> **ai_Abstract:** TensorSocket是一个旨在优化深度学习训练效率的系统。它通过允许并发训练过程共享同一数据加载器来解决重复数据处理和CPU侧瓶颈问题。该系统减少了冗余计算和数据复制，并利用GPU互连技术。TensorSocket能够处理不同大小的模型和批次，且与硬件无关。实验证明，它能将训练吞吐量提高100%，在云端节省50%成本，并优于现有共享数据加载方案。

> **摘要翻译:** 训练深度学习模型是一个重复且资源密集的过程。数据科学家通常在确定一组能产生最高准确度的参数（例如超参数调优）和模型架构（例如神经架构搜索）之前，会训练多个模型。这些训练任务的计算效率高度依赖于训练数据如何有效地供应给训练过程。这些任务的重复性导致相同的数据处理管道反复运行，加剧了计算资源的需求和成本。在本文中，我们提出了TensorSocket，通过使同步训练过程能够共享相同的数据加载器，从而减少深度学习训练的计算需求。TensorSocket在协同训练工作负载在GPU上具有高吞吐量，但受限于CPU上较低的数据加载吞吐量的情况下，缓解了CPU侧的瓶颈。TensorSocket通过减少协同训练过程中的冗余计算和数据复制，并利用现代GPU-GPU互连技术来实现这一点。在此过程中，TensorSocket能够训练和平衡不同大小的模型，并同时服务多个批次大小，并且本质上与硬件和管道无关。我们的评估表明，TensorSocket实现了在没有数据共享时不可行的场景，将训练吞吐量提高了高达100%，并且在使用云实例时，通过减少CPU侧的硬件资源需求，实现了50%的成本节约。此外，TensorSocket在共享数据加载方面优于最先进的解决方案，如CoorDL和Joader；它更易于部署和维护，并且在需要更少CPU资源的同时，要么实现更高的吞吐量，要么与其持平。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [22] [Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring](https://arxiv.org/abs/2508.00270)
> *为百万学生优化反馈：大规模在线辅导中多臂老虎机和上下文老虎机的洞察*

*Robin Schmucker, Nimish Pachapurkar, Shanmuga Bala, Miral Shah, Tom Mitchell* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 在线辅导, 多臂老虎机, 上下文老虎机, 个性化反馈, 学生学习

**Comment:** 

> **TL;DR:** 本文介绍了一个在线辅导系统，该系统利用多臂老虎机（MAB）和上下文老虎机（CB）框架，通过分析百万学生的数据，学习为学生提供有效的个性化反馈，以优化学习成果。研究发现MAB策略能显著提升学生表现，而CB策略的额外收益可能有限。

**AI_Comments:** 该论文的创新之处在于将多臂老虎机和上下文老虎机等强化学习框架应用于大规模在线教育场景，以优化学生反馈机制。其重要性体现在利用百万学生数据进行实践验证，证明了数据驱动策略在提升学生学习成果方面的有效性。论文也坦诚地指出了个性化反馈（CB策略）在实践中可能面临的局限性，即在某些情况下，其带来的额外收益可能不足以超越更简单的通用策略（MAB策略）。这为未来在线教育系统的设计和优化提供了宝贵的实证洞察。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在开发一个在线辅导系统，该系统能够学习为学生提供有效的反馈，尤其是在学生答错问题后，以优化学生的学习效果。目标是利用大量学生数据来决定为每个问题提供哪种辅助操作（例如，多种提示中的一种）。

**Method:** 该系统采用多臂老虎机（MAB）框架和离线策略评估来评估43,000种辅助操作，并识别了针对不同学生结果（如回答正确率、会话完成度）优化的辅助策略之间的权衡。设计了一种算法，为每个问题选择合适的策略训练目标，以提高学生的即时二次尝试成功率和整体练习会话表现。此外，研究进一步探讨了上下文老虎机（CB）策略是否可以通过基于个体学生特征（如能力估计、响应时间）个性化反馈来增强结果，并使用因果推断来检查辅助动作的效果如何因学生而异以及CB策略是否优于MAB策略。

**Result:** 评估了166,000个练习会话中的MAB策略，验证了学生结果的显著改善。虽然分析表明某些问题的某些动作表现出效果异质性，但效果大小通常太小，以至于CB策略无法提供超出优化良好的MAB策略（为所有学生提供相同动作）所能达到的显著改进。

**Conclusion:** 部署大规模数据驱动系统获得了深刻见解，并对未来的改进具有启示。目前，该系统优化的教学策略每天支持数千名学生。

> **ai_Abstract:** 本文介绍了一个大规模在线辅导系统，该系统利用多臂老虎机（MAB）和上下文老虎机（CB）框架，通过分析一百万学生的数据，学习为学生提供有效的、个性化的反馈。系统评估了多种辅助操作，并设计了优化学生学习成果的策略。研究发现，MAB策略能够显著提升学生表现，但尽管存在效果异质性，上下文老虎机（CB）策略通过个性化反馈所带来的额外提升可能有限，因为其效果增益相对较小。该研究提供了大规模部署数据驱动系统的经验，并为未来的系统改进提供了方向。

> **摘要翻译:** 我们提出了一个在线辅导系统，该系统学习在学生答错问题后提供有效的反馈。利用来自一百万学生的数据，该系统学习为每个问题提供哪种辅助操作（例如，多种提示中的一种）以优化学生学习。我们采用多臂老虎机（MAB）框架和离线策略评估，评估了43,000种辅助操作，并确定了针对不同学生结果（例如，回答正确性、会话完成度）优化的辅助策略之间的权衡。我们设计了一种算法，为每个问题决定一个合适的策略训练目标，以提高学生的即时二次尝试成功率和整体练习会话表现。我们在166,000个练习会话中评估了由此产生的MAB策略，验证了学生结果的显著改善。虽然MAB策略为整体学生群体优化反馈，但我们进一步调查了上下文老虎机（CB）策略是否可以通过基于个体学生特征（例如，能力估计、响应时间）个性化反馈来增强结果。我们使用因果推断检查（i）辅助动作的效果如何因学生而异，以及（ii）利用这种效果异质性的CB策略是否优于MAB策略。虽然我们的分析显示某些问题的某些动作表现出效果异质性，但效果大小可能通常太小，以至于CB策略无法提供超出优化良好的MAB策略（为所有学生提供相同动作）所能达到的显著改进。我们讨论了部署大规模数据驱动系统所获得的见解以及对未来改进的启示。如今，我们的系统优化的教学策略每天支持数千名学生。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [34] [Tackling Size Generalization of Graph Neural Networks on Biological Data from a Spectral Perspective](https://arxiv.org/abs/2305.15611)
> *从谱视角解决生物数据上图神经网络的尺寸泛化问题*

*Gaotang Li, Danai Koutra, Yujun Yan* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 图神经网络, 尺寸泛化, 谱分析, 生物数据, 分布偏移

**Comment:** KDD 2025

> **TL;DR:** 本文从谱角度分析了图神经网络在生物数据上尺寸泛化能力差的问题，发现子图模式引起的谱差异与GNN性能强相关。提出并验证了尺寸密集注意力策略，显著提升了GNN对大型图的分类性能。

**AI_Comments:** 该论文的创新点在于首次从谱视角深入探讨了GNN的尺寸泛化问题，并采用数据驱动的方式揭示了谱差异与GNN性能的相关性。提出的尺寸密集注意力策略是模型无关的，这使其具有广泛的适用性。研究结果表明，该方法在生物数据上对GNN处理大型图的泛化能力有显著提升，为解决GNN在实际应用中的尺寸泛化挑战提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 解决图神经网络（GNNs）中由尺寸引起的分布偏移及其对GNN泛化到更大图的影响，现有研究对此有不同假设和结论，而从谱角度研究GNN泛化能力是一个未充分探索的视角。

**Method:** 采用数据驱动方法识别和表征尺寸引起的分布偏移类型，并从谱角度探讨其对GNN性能的影响。分析生物图，发现由子图模式（如平均循环长度）驱动的谱差异与GNN在大型未见图上的性能强相关。基于此，提出了三种模型无关策略来增强GNN对关键子图模式的感知，其中尺寸密集注意力被证明最有效。

**Result:** 尺寸密集注意力策略显著提升了图分类性能，在比训练图大2到10倍的测试图上，F1分数比强基线提高了高达8%。实验涵盖六种GNN架构、七种模型无关策略和五个数据集。

**Conclusion:** 通过从谱视角分析尺寸引起的分布偏移，并提出尺寸密集注意力策略，可以有效提升图神经网络在处理比训练数据大得多的图时的泛化能力，尤其在生物数据上表现突出。

> **ai_Abstract:** 本文从谱视角研究了图神经网络在生物数据上尺寸泛化能力受限的问题。研究发现，由子图模式（如平均循环长度）引起的谱差异与GNN在大型图上的性能密切相关。基于此，作者提出了一种模型无关的尺寸密集注意力策略，旨在增强GNN对关键子图模式的感知。实验证明，该策略能显著提高GNN在比训练集大2到10倍的测试图上的分类性能，F1分数提升高达8%。

> **摘要翻译:** 我们解决了图神经网络（GNNs）中尺寸引起的分布偏移及其对GNN泛化到更大图的关键挑战。现有文献在分布偏移方面存在不同假设，导致对GNN泛化能力得出不同结论。与现有工作不同，我们采用数据驱动方法来识别和表征尺寸引起的分布偏移类型，并从谱角度探讨其对GNN性能的影响，这是一个很大程度上未被充分探索的视角。利用真实生物数据集中图尺寸的显著差异，我们分析了生物图，发现由子图模式（例如平均循环长度）驱动的谱差异与GNN在更大、未见图上的性能强烈相关。基于这些见解，我们提出了三种模型无关策略来增强GNN对关键子图模式的感知，其中尺寸密集注意力被认为是 F 最有效的方法。在五个数据集上使用六种GNN架构和七种模型无关策略进行的大量实验表明，我们的尺寸密集注意力策略显著改善了测试图（比训练图大2到10倍）上的图分类性能，使F1分数比强基线提高了高达8%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [38] [Safe machine learning model release from Trusted Research Environments: The SACRO-ML package](https://arxiv.org/abs/2212.01233)
> *来自可信研究环境的安全机器学习模型发布：SACRO-ML 包*

*Jim Smith, Richard J. Preen, Andrew McCarthy, Maha Albashir, Alba Crespi-Boixader, Shahzad Mumtaz, Christian Cole, James Liley, Jost Migenda, Simon Rogers, Yola Jones* | **Category: cs.LG, cs.CR, cs.IR** | **Updated: 2025-08-01**

**Keywords:** 机器学习, 统计披露控制, 数据隐私, 开源工具, 安全发布

**Comment:** 

> **TL;DR:** SACRO-ML是一个开源Python工具套件，用于在发布前对基于机密数据训练的ML模型进行统计披露控制。

**AI_Comments:** 该论文提出了一个实用的开源工具，解决了机器学习模型在敏感数据上训练后发布时的关键安全问题。其创新之处在于结合了事前和事后两种披露控制方法，提供了一个全面的解决方案。作为开源工具，它有助于社区采用和进一步开发安全机器学习实践。

<details>
  <summary>Details</summary>

**Motivation:** 在公共发布前，需要对在机密数据上训练的机器学习模型进行统计披露控制（SDC），以解决数据泄露的风险。

**Method:** 提出了SACRO-ML，一个集成的开源Python工具套件。它包含：(i) SafeModel包，通过评估训练方案带来的披露漏洞，提供事前（ante-hoc）SDC；(ii) Attacks包，通过各种模拟攻击严格评估模型的经验披露风险，提供事后（post-hoc）SDC。

**Result:** 提供了SACRO-ML，一个结合事前和事后SDC方法的开源Python工具套件，用于安全发布ML模型。代码和文档已在GitHub上提供。

**Conclusion:** 论文推出了SACRO-ML工具，旨在促进机器学习模型从可信研究环境安全发布，通过提供事前和事后统计披露控制来管理泄露风险。

> **ai_Abstract:** SACRO-ML是一个开源Python工具套件，用于解决从可信研究环境发布基于机密数据训练的机器学习模型时的统计披露控制问题。它通过提供两个核心组件来实现：SafeModel包进行事前（ante-hoc）披露风险评估，以及Attacks包进行事后（post-hoc）经验性披露风险评估，从而确保模型的安全发布。

> **摘要翻译:** 我们介绍了SACRO-ML，一个集成的开源Python工具套件，旨在促进在公开发布前对基于机密数据训练的机器学习（ML）模型进行统计披露控制（SDC）。SACRO-ML结合了：(i)一个SafeModel包，它扩展了常用的ML模型，通过评估训练方案带来的披露漏洞来提供事前（ante-hoc）SDC；以及(ii)一个Attacks包，它通过各种模拟攻击在训练后严格评估模型的经验披露风险，从而提供事后（post-hoc）SDC。SACRO-ML的代码和文档在MIT许可下可在https://github.com/AI-SDC/SACRO-ML 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [45] [Efficient Solution and Learning of Robust Factored MDPs](https://arxiv.org/abs/2508.00707)
> *鲁棒分解马尔可夫决策过程的有效求解与学习*

*Yannik Schnitzer, Alessandro Abate, David Parker* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 鲁棒马尔可夫决策过程, 分解状态空间, 线性规划, 样本效率, 策略合成

**Comment:** 

> **TL;DR:** 本文提出了一种基于分解状态空间表示的新方法，用于求解和学习鲁棒马尔可夫决策过程（r-MDPs），显著提高了样本效率并获得了更紧密的性能保证。

**AI_Comments:** 本文的创新之处在于将复杂的鲁棒MDP问题通过引入分解结构和线性规划重构，有效地降低了求解难度和样本需求。这对于需要处理模型不确定性的大规模决策问题具有重要意义，尤其是在实际应用中能够显著提高学习效率和策略的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 鲁棒马尔可夫决策过程（r-MDPs）虽然能提供可证明的性能保证，但从未知环境中学习时需要大量的样本交互。

**Method:** 本文提出了基于分解状态空间表示的新方法来求解和学习r-MDPs，利用系统组件间模型不确定性的独立性。尽管策略合成是困难的非凸优化问题，但通过将其重新表述为可处理的线性规划问题来解决。在此基础上，还提出了直接学习分解模型表示的方法。

**Result:** 实验结果表明，利用分解结构可以带来样本效率的维度增益，生成比现有最新方法更有效的鲁棒策略，并具有更紧密的性能保证。

**Conclusion:** 通过利用分解结构，可以显著提高鲁棒马尔可夫决策过程的求解和学习效率，从而在样本效率和策略性能保证方面超越现有技术。

> **ai_Abstract:** 本研究提出了一套新颖的方法，旨在提高鲁棒马尔可夫决策过程（r-MDPs）的求解和学习效率。通过引入分解状态空间表示，该方法利用了系统组件间模型不确定性的独立性，从而将复杂的非凸优化问题转化为可处理的线性规划。此外，研究还提出了直接学习分解模型表示的技术。实验证明，这种分解方法显著提升了样本效率，并能生成性能更优、保证更严格的鲁棒策略，超越了当前最先进的技术。

> **摘要翻译:** 鲁棒马尔可夫决策过程（r-MDPs）通过明确建模关于转移动力学的认知不确定性来扩展了马尔可夫决策过程（MDPs）。从未知环境中学习r-MDPs能够合成具有可证明（PAC）性能保证的鲁棒策略，但这可能需要大量的样本交互。我们提出了基于分解状态空间表示的求解和学习r-MDPs的新方法，这些方法利用了系统组件之间模型不确定性的独立性。尽管分解r-MDPs的策略合成会导致困难的非凸优化问题，但我们展示了如何将其重新表述为可处理的线性规划。在此基础上，我们还提出了直接学习分解模型表示的方法。我们的实验结果表明，利用分解结构可以在样本效率方面带来维度增益，生成比现有最新方法更有效的鲁棒策略，并具有更紧密的性能保证。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [50] [Federated Time Series Generation on Feature and Temporally Misaligned Data](https://arxiv.org/abs/2410.21072)
> *联邦时间序列生成在特征和时间错位数据上的应用*

*Zhi Wen Soi, Chenrui Fan, Aditya Shankar, Abele Mălan, Lydia Y. Chen* | **Category: cs.LG, cs.DC** | **Updated: 2025-08-01**

**Keywords:** 联邦学习,时间序列生成,数据错位,数据蒸馏,扩散模型

**Comment:** 

> **TL;DR:** FedTDD是一个新颖的联邦时间序列扩散模型，通过数据蒸馏和聚合框架处理客户端间特征和时间错位的数据，并通过交换合成输出而非模型参数来学习客户端间时间序列的关联。

**AI_Comments:** FedTDD的创新点在于其通过数据蒸馏和聚合框架处理联邦时间序列数据中的特征和时间错位问题，并且通过交换合成输出而非模型参数来保护隐私并提高效率。这种方法对于解决实际分布式环境中数据异构性是一个重要的进步。其性能提升也表明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的联邦时间序列模型受限于客户端之间完美时间或特征对齐的假设，但实际分布式时间序列数据常存在客户端特征集不同和时间步错位的问题。

**Method:** 本文提出了FedTDD，一个新颖的联邦时间序列扩散模型，用于联合学习跨客户端的合成器。FedTDD的核心是一个数据蒸馏和聚合框架，通过插补错位的时间步和特征来协调客户端之间的差异。它通过交换局部合成输出来学习客户端时间序列之间的关联，而不是交换模型参数。一个协调器通过利用客户端共享的合成数据来迭代改进一个全局蒸馏器网络，该蒸馏器反过来提升客户端局部特征估计的质量，从而改善缺失数据的局部插补。

**Result:** 实验结果在五个数据集上表明，与集中式训练相比，FedTDD是有效的，并且共享合成输出以传输局部时间序列知识是有效的。FedTDD在Context-FID和Correlational分数上分别比局部训练提高了79.4%和62.8%。

**Conclusion:** FedTDD通过其独特的数据蒸馏和聚合框架，有效解决了联邦时间序列生成中特征和时间错位数据的问题，并在性能上显著优于局部训练，证明了其在实际应用中的潜力。

> **ai_Abstract:** 本文提出了FedTDD，一个针对联邦时间序列生成的新型扩散模型，旨在解决客户端数据中存在的特征和时间错位问题。FedTDD通过一个创新的数据蒸馏和聚合框架，协调客户端间的差异，并通过交换合成数据而非模型参数来学习跨客户端的时间序列关联。实验证明，FedTDD在多个数据集上表现出色，显著优于局部训练，验证了其在处理异构联邦时间序列数据方面的有效性。

> **摘要翻译:** 分布式时间序列数据对联邦学习提出了挑战，因为客户端通常拥有不同的特征集并且时间步错位。现有的联邦时间序列模型受限于客户端之间完美时间或特征对齐的假设。在本文中，我们提出了FedTDD，一个新颖的联邦时间序列扩散模型，可以联合学习跨客户端的合成器。FedTDD的核心是一个新颖的数据蒸馏和聚合框架，通过插补错位的时间步和特征来协调客户端之间的差异。与传统的联邦学习不同，FedTDD通过交换局部合成输出而不是模型参数来学习客户端时间序列之间的关联。一个协调器通过利用客户端共享的知识（通过交换合成数据）来迭代改进一个全局蒸馏器网络。随着蒸馏器随着时间的推移变得更加精细，它随后提高了客户端局部特征估计的质量，从而允许每个客户端使用最新、更准确的蒸馏器来改进其对缺失数据的局部插补。在五个数据集上的实验结果证明了FedTDD与集中式训练相比的有效性，以及共享合成输出来传输局部时间序列知识的有效性。值得注意的是，FedTDD在Context-FID和Correlational分数上比局部训练分别提高了79.4%和62.8%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [52] [Toward using explainable data-driven surrogate models for treating performance-based seismic design as an inverse engineering problem](https://arxiv.org/abs/2508.00286)
> *迈向使用可解释数据驱动代理模型将基于性能的抗震设计视为逆向工程问题*

*Mohsen Zaker Esteghamati* | **Category: cs.LG, stat.AP, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 基于性能抗震设计, 逆向工程, 机器学习, 代理模型, 遗传优化

**Comment:** 

> **TL;DR:** 本研究提出一种将基于性能的抗震设计视为逆向工程问题的方法，通过可解释机器学习模型和遗传优化算法，高效地直接推导出满足特定性能目标的设计参数，并成功应用于钢结构和混凝土结构，实现了高精度和工程一致性。

**AI_Comments:** 这项研究通过将基于性能的抗震设计重新构想为逆向工程问题，并利用可解释的机器学习和遗传优化，提供了一种新颖且高效的设计范式。其创新之处在于直接从性能目标推导设计参数，显著提高了计算效率。高精度和与工程原理的一致性表明了其在实际应用中的巨大潜力，可以为结构工程师提供更智能、更快速的设计工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统基于性能的抗震设计存在计算效率低的问题，需要一种能够直接从性能目标反向推导设计参数的方法。

**Method:** 本研究提出一种方法，将基于性能的抗震设计视为逆向工程问题。它通过实现可解释的机器学习模型来直接映射设计变量和性能指标，以解决计算效率低下的问题。生成的机器学习模型被集成到遗传优化算法中作为评估函数来解决逆向问题。该方法应用于洛杉矶和查尔斯顿的钢结构和混凝土框架，以最小化预期年化地震损失。

**Result:** 代理模型在不同建筑类型、几何形状、抗震设计和场地危险下均显示出高精度（例如R2 > 90%）。优化算法能够为固定几何变量识别出构件属性的最佳值，且与工程原理一致。

**Conclusion:** 该研究成功开发并验证了一种将基于性能的抗震设计作为逆向工程问题处理的方法，该方法通过集成可解释机器学习模型和遗传优化算法，能够高效且准确地推导出满足性能目标的设计参数，为抗震设计提供了有效工具。

> **ai_Abstract:** 本研究提出一种创新的方法，将基于性能的抗震设计转化为逆向工程问题。该方法利用可解释的机器学习模型来高效地建立设计参数与性能指标之间的直接映射关系，并通过将其集成到遗传优化算法中来求解逆向问题。在应用于钢结构和混凝土框架的案例中，该方法成功地以高精度（R2>90%）确定了最小化地震损失的构件特性，证明了其在解决计算效率问题和提供工程上合理的设计方案方面的有效性。

> **摘要翻译:** 本研究提出了一种将基于性能的抗震设计视为逆向工程问题的方法，其中直接推导出设计参数以实现特定的性能目标。通过实施可解释的机器学习模型，该方法直接映射设计变量和性能指标，解决了基于性能设计的计算效率低下问题。由此产生的机器学习模型作为评估函数集成到遗传优化算法中，以解决逆向问题。然后，将开发的方法应用于洛杉矶和查尔斯顿的两种不同钢结构和混凝土力矩框架库存，以获得框架构件的截面特性，从而最大限度地减少维修成本方面的预期年化地震损失。结果表明，代理模型在各种建筑类型、几何形状、抗震设计和场地危险下均具有高精度（例如R2 > 90%），其中优化算法可以识别固定几何变量下构件属性的最佳值，这与工程原理一致。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [56] [INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks](https://arxiv.org/abs/2508.00141)
> *INSPIRE-GNN：通过强化学习增强图神经网络改进稀疏自行车网络预测的智能传感器布局*

*Mohit Gupta, Debjit Bhowmick, Rhys Newbury, Meead Saberi, Shirui Pan, Ben Beck* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 传感器布局, 强化学习, 图神经网络, 自行车流量估计, 数据稀疏性

**Comment:** 

> **TL;DR:** INSPIRE-GNN利用强化学习增强的图神经网络，解决了稀疏传感器数据下自行车流量预测的挑战，通过优化传感器布局显著提高了预测精度。

**AI_Comments:** 该论文的创新点在于将强化学习（DQN）与混合图神经网络（GCN和GAT）相结合，用于优化传感器布局以解决交通数据稀疏性的挑战。这种方法提供了一种数据驱动的、智能的传感器部署策略，而非依赖传统的启发式规则，这对于实际城市交通规划具有重要意义。其在99%数据稀疏性的真实数据集上的显著性能提升，凸显了其在解决实际问题上的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 准确的链路级自行车流量估计对于可持续城市交通规划至关重要。然而，许多城市由于自行车计数传感器覆盖范围有限，面临数据高度稀疏的重大挑战。

**Method:** 本文提出了INSPIRE-GNN，一个新颖的强化学习（RL）增强的混合图神经网络（GNN）框架，旨在优化传感器布局并改善数据稀疏环境下的链路级自行车流量估计。INSPIRE-GNN将图卷积网络（GCN）和图注意力网络（GAT）与基于深度Q网络（DQN）的RL代理集成，实现数据驱动的传感器位置战略选择，以最大化估计性能。

**Result:** 应用于墨尔本自行车网络（15,933个路段，仅141个路段有传感器，99%稀疏），INSPIRE-GNN通过战略性选择额外传感器位置（部署50、100、200和500个传感器），在流量估计方面表现出显著改进。该框架在关键指标如均方误差（MSE）、均方根误差（RMSE）和平均绝对误差（MAE）方面优于传统的传感器布局启发式方法（如介数中心性、接近中心性、观测自行车活动和随机布局）。此外，实验还对比了INSPIRE-GNN与标准机器学习和深度学习模型在自行车流量估计性能方面的表现，突显了其有效性。

**Conclusion:** 本文提出的框架为交通规划者提供了可操作的见解，以有效扩展传感器网络、优化传感器布局并最大化自行车数据的流量估计准确性和可靠性，从而做出明智的交通规划决策。

> **ai_Abstract:** 本文提出了INSPIRE-GNN，一个结合强化学习（DQN）和混合图神经网络（GCN、GAT）的框架，旨在解决数据稀疏环境下自行车网络流量估计中的传感器布局优化问题。该方法通过数据驱动的方式战略性选择传感器位置，以提高链路级流量估计性能。在墨尔本高度稀疏的自行车网络上进行的实验表明，INSPIRE-GNN在流量估计精度上显著优于传统启发式方法和标准机器学习模型，为交通规划者提供了优化传感器网络和提升数据可靠性的有效工具。

> **摘要翻译:** 准确的链路级自行车流量估计对于可持续城市交通规划至关重要。然而，许多城市由于自行车计数传感器覆盖范围有限，面临数据高度稀疏的重大挑战。为了解决这个问题，我们提出了INSPIRE-GNN，一个新颖的强化学习（RL）增强的混合图神经网络（GNN）框架，旨在优化传感器布局并改善数据稀疏环境下的链路级自行车流量估计。INSPIRE-GNN将图卷积网络（GCN）和图注意力网络（GAT）与基于深度Q网络（DQN）的RL代理集成，实现数据驱动的传感器位置战略选择，以最大化估计性能。应用于墨尔本的自行车网络，该网络包含15,933个路段，其中仅141个路段（99%稀疏）有传感器覆盖——INSPIRE-GNN通过在部署50、100、200和500个传感器时战略性选择额外传感器位置，在流量估计方面表现出显著改进。我们的框架在关键指标如均方误差（MSE）、均方根误差（RMSE）和平均绝对误差（MAE）方面优于传统的传感器布局启发式方法，如介数中心性、接近中心性、观测自行车活动和随机布局。此外，我们的实验还对比了INSPIRE-GNN与标准机器学习和深度学习模型在自行车流量估计性能方面的表现，突显了其有效性。我们提出的框架为交通规划者提供了可操作的见解，以有效扩展传感器网络、优化传感器布局并最大化自行车数据的流量估计准确性和可靠性，从而做出明智的交通规划决策。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [69] [JSON-Bag: A generic game trajectory representation](https://arxiv.org/abs/2508.00712)
> *JSON-Bag：一种通用的游戏轨迹表示方法*

*Dien Nguyen, Diego Perez-Liebana, Simon Lucas* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 游戏轨迹表示, JSON-Bag, Jensen-Shannon距离, 游戏分类, 自动特征提取

**Comment:** 8 pages, 3 figures, 6 tables, to be published in IEEE Conference on
  Games 2025

> **TL;DR:** JSON-Bag模型通过对游戏轨迹的JSON描述进行标记化，并结合Jensen-Shannon距离和原型最近邻搜索，实现了通用的游戏轨迹表示和分类，在多种任务上优于基线，并能自动提取特征。

**AI_Comments:** 这篇论文提出了一种新颖的、通用的游戏轨迹表示方法——JSON-Bag，其创新点在于利用JSON描述的结构化特性进行标记化，并结合信息论中的Jensen-Shannon距离进行度量。这种方法避免了传统手工特征工程的复杂性，并展现了自动特征提取的能力，对于游戏AI、游戏分析等领域具有重要意义。其在多种游戏和分类任务上的成功应用验证了其普适性和有效性，尤其是在样本效率和自动特征提取方面的表现值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 需要一种通用的方法来表示游戏轨迹，以克服传统手工特征方法的局限性，并支持游戏轨迹的分析和分类。

**Method:** 引入JSON Bag-of-Tokens模型（JSON-Bag），通过标记化游戏轨迹的JSON描述来表示轨迹。使用Jensen-Shannon距离（JSD）作为距离度量。采用基于原型的最近邻搜索（P-NNS）进行评估。在六款桌面游戏上进行评估，执行分类游戏代理、游戏参数或游戏种子的任务。通过将标记视为特征并应用于随机森林进行自动特征提取。

**Result:** JSON-Bag方法在大多数任务中优于使用手工特征的基线。N-shot分类评估表明使用JSON-Bag原型表示游戏轨迹类别是样本高效的。通过将标记作为特征用于随机森林，显著提高了在表现不佳任务上的准确性。在所有六款游戏中，JSON-Bag代理类原型之间的JSD与代理策略之间的距离高度相关。

**Conclusion:** JSON-Bag提供了一种通用、高效的游戏轨迹表示方法，能够有效应用于游戏轨迹的分类任务，并支持自动特征提取。此外，其原型距离与代理策略距离之间存在高度相关性。

> **ai_Abstract:** 本文提出JSON Bag-of-Tokens模型（JSON-Bag），通过标记化游戏轨迹的JSON描述，并结合Jensen-Shannon距离（JSD）作为度量，实现游戏轨迹的通用表示。研究使用原型最近邻搜索（P-NNS）在六款桌面游戏上评估了JSON-Bag在分类游戏代理、参数或种子方面的有效性。结果显示，JSON-Bag在多数任务中优于手工特征基线，并且在N-shot分类中表现出样本高效性。此外，JSON-Bag还展示了自动特征提取的能力，通过将标记作为特征用于随机森林，显著提升了分类准确性。研究还发现，JSON-Bag代理类原型间的JSD与代理策略距离高度相关。

> **摘要翻译:** 我们引入JSON词袋模型（JSON-Bag）作为一种通过对其JSON描述进行标记化来通用表示游戏轨迹的方法，并应用Jensen-Shannon距离（JSD）作为它们的距离度量。我们使用基于原型的最近邻搜索（P-NNS），在六款桌面游戏——《七大奇迹》、《领土》、《海盐与纸》、《停不下来》、《四子棋》和《点与盒》——上评估了JSON-Bag与JSD的有效性，每款游戏都进行了三种游戏轨迹分类任务：分类游戏代理、游戏参数或用于生成轨迹的游戏种子。我们的方法在大多数任务中优于使用手工特征的基线。对N-shot分类的评估表明，使用JSON-Bag原型来表示游戏轨迹类别也是样本高效的。此外，我们通过将标记视为单独的特征用于随机森林来解决上述任务，展示了JSON-Bag自动特征提取的能力，这显著提高了在表现不佳任务上的准确性。最后，我们表明，在所有六款游戏中，代理类别的JSON-Bag原型之间的JSD与代理策略之间的距离高度相关。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [70] [Invariant Graph Transformer for Out-of-Distribution Generalization](https://arxiv.org/abs/2508.00304)
> *用于域外泛化的不变图Transformer*

*Tianyin Liao, Ziwei Zhang, Yufei Sun, Chunyu Hu, Jianxin Li* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 不变图Transformer, 域外泛化, 图神经网络, 注意力机制, 图不变学习

**Comment:** 

> **TL;DR:** 本文提出了GOODFormer，一种不变图Transformer，旨在通过学习不变图表示来提高图Transformer在分布偏移下的泛化能力。

**AI_Comments:** 本文的创新之处在于将不变学习原理融入到图Transformer中，从而有效地解决了图神经网络在实际应用中至关重要的域外泛化问题。其模块化设计，包括子图解耦、动态编码和不变学习，是该方法的一大亮点，提升了模型的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有图Transformer（GTs）在分布偏移下泛化能力不足，并且基于图不变学习原理设计注意力机制和位置与结构编码（PSEs）仍然具有挑战性。

**Method:** 本文提出了Graph Out-Of-Distribution generalized Transformer（GOODFormer），旨在通过联合优化三个模块来学习广义图表示，捕获预测图结构和标签之间的不变关系。具体来说，首先开发了一个基于GT的熵引导不变子图解耦器来分离不变和变异子图；其次，设计了一个演化子图位置和结构编码器来捕获动态变化的子图的编码信息；最后，提出了一个不变学习模块，利用子图节点表示和编码来导出可泛化的图表示。该方法也提供了理论依据。

**Result:** 在基准数据集上的大量实验表明，在分布偏移下，我们的方法优于最先进的基线方法。

**Conclusion:** GOODFormer通过学习不变图表示，有效解决了图Transformer在域外泛化方面的挑战，并在分布偏移下展现出卓越的性能。

> **ai_Abstract:** 本文提出了GOODFormer，一种不变图Transformer，旨在解决现有图Transformer在分布偏移下泛化能力差的问题。GOODFormer通过捕获预测图结构和标签之间的不变关系来学习广义图表示。它包含三个核心模块：一个熵引导不变子图解耦器、一个演化子图位置和结构编码器以及一个不变学习模块。该方法提供了理论依据，并通过在基准数据集上的实验证明，在分布偏移下其性能优于现有先进方法。

> **摘要翻译:** 图Transformer（GTs）在各种图分析任务中表现出卓越的有效性。然而，现有的GTs专注于训练和测试来自相同分布的图数据，但在分布偏移下未能泛化。图不变学习旨在捕获在分布偏移下具有标签的广义图结构模式，可能是一个有前景的解决方案，但如何基于图不变学习原理设计注意力机制以及位置和结构编码（PSEs）仍然具有挑战性。为了解决这些挑战，我们引入了Graph Out-Of-Distribution generalized Transformer（GOODFormer），旨在通过联合优化三个模块，捕获预测图结构和标签之间的不变关系，从而学习广义图表示。具体来说，我们首先开发了一个基于GT的熵引导不变子图解耦器，以分离不变和变异子图，同时保持注意力函数的锐度。其次，我们设计了一个演化子图位置和结构编码器，以有效且高效地捕获训练期间动态变化的子图的编码信息。最后，我们提出了一个不变学习模块，利用子图节点表示和编码来导出可以泛化到未见图的广义图表示。我们还为我们的方法提供了理论依据。在基准数据集上的大量实验表明，我们的方法在分布偏移下优于最先进的基线方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [89] [PnP-DA: Towards Principled Plug-and-Play Integration of Variational Data Assimilation and Generative Models](https://arxiv.org/abs/2508.00325)
> *PnP-DA：迈向变分数据同化与生成模型原理性即插即用集成*

*Yongquan Qu, Matthieu Blanke, Sara Shamekh, Pierre Gentine* | **Category: cs.LG, physics.comp-ph** | **Updated: 2025-08-01**

**Keywords:** 数据同化, 生成模型, 即插即用, 混沌系统, 预测误差

**Comment:** 

> **TL;DR:** PnP-DA是一种新的即插即用算法，它结合了变分数据同化和生成模型，通过放松统计假设并避免复杂的梯度反向传播，显著减少了混沌系统中的预测误差。

**AI_Comments:** PnP-DA的创新之处在于其“即插即用”的模块化设计，将数据同化和生成模型以一种新颖的方式结合，同时规避了传统方法中对高斯误差的严格假设和复杂的梯度反向传播问题。这对于处理非高斯、混沌系统的数据同化具有重要意义，尤其是在地球系统建模等复杂领域。

<details>
  <summary>Details</summary>

**Motivation:** 地球系统建模面临挑战：在计算高效模型中捕获复杂、多尺度非线性动力学，同时最小化预测误差。即使是强大的AI或物理预测系统也存在误差累积。传统变分数据同化方法常假设高斯误差统计，但混沌动力学的真实行为是非高斯的，导致无法有效捕获。

**Method:** 本文提出PnP-DA，一个即插即用算法，它交替进行：1. 轻量级的基于梯度的分析更新（使用新观测的马氏距离失配）；2. 通过条件Wasserstein耦合，对预训练的生成先验进行单次前向传播，该先验以背景预测为条件。此策略放宽了限制性统计假设，利用了丰富的历史数据，无需显式正则化函数，并避免了在同化周期中通过复杂神经网络进行梯度反向传播。

**Result:** 在标准混沌测试台上进行的实验表明，PnP-DA策略在不同观测稀疏度和噪声水平下，持续减少预测误差，并优于经典变分方法。

**Conclusion:** PnP-DA通过有效结合变分数据同化和生成模型，克服了传统方法的局限性，实现了更准确的混沌系统预测。

> **ai_Abstract:** 本文提出了PnP-DA，一种将变分数据同化与生成模型集成的即插即用算法，旨在解决地球系统建模中传统数据同化方法在高斯误差假设下的局限性。PnP-DA通过交替进行基于梯度的分析更新和利用预训练生成先验的单次前向传播，放松了统计假设，并避免了复杂的梯度反向传播。实验证明，PnP-DA在混沌系统中显著减少了预测误差，优于现有变分方法。

> **摘要翻译:** 地球系统建模在科学计算中提出了一个根本性挑战：在计算高效的模型中捕获复杂、多尺度的非线性动力学，同时最小化由必要简化引起的预测误差。即使是最强大的基于AI或物理的预测系统也会出现逐渐的误差累积。数据同化（DA）旨在通过将（有噪声的）观测与先验模型预测进行最优融合来减轻这些误差，但传统的变分方法通常假设高斯误差统计，这无法捕获混沌动力系统的真实非高斯行为。我们提出了PnP-DA，一种即插即用算法，它交替进行（1）轻量级的、基于梯度的分析更新（使用新观测上的马氏距离失配）和（2）通过条件Wasserstein耦合，对预训练的生成先验进行单次前向传播，该先验以背景预测为条件。这种策略放宽了限制性统计假设，并在不需要显式正则化函数的情况下利用了丰富的历史数据，它还避免了在同化周期中通过编码先验的复杂神经网络进行梯度反向传播。在标准混沌测试台上的实验表明，该策略在各种观测稀疏度和噪声水平下持续减少预测误差，优于经典变分方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [99] [Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning](https://arxiv.org/abs/2508.00716)
> *用于噪声标签域适应学习的嵌套图伪标签细化*

*Yingxu Wang, Mengzhu Wang, Zhichao Huang, Suyu Liu* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 图域适应, 噪声标签, 伪标签细化, 嵌套机制, 噪声感知正则化

**Comment:** 

> **TL;DR:** NeGPR是一种新的框架，旨在解决图域适应中源域标签噪声问题，通过双分支预训练、嵌套细化机制和噪声感知正则化策略，显著提升了在严重标签噪声下的性能。

**AI_Comments:** NeGPR的创新点在于其针对图域适应中普遍存在的标签噪声问题提出了一个全面的解决方案。通过结合双分支预训练、嵌套细化机制和理论上证明有效的噪声感知正则化，该方法有效地提高了在真实世界场景下的模型鲁棒性和适应性能。这对于扩展图域适应在实际应用中的可行性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图域适应（GDA）方法大多依赖于干净的源标签假设，但这在实际应用中很少成立，因为标注噪声普遍存在。这种标签噪声严重损害了特征对齐并降低了域漂移下的适应性能。

**Method:** 本文提出了嵌套图伪标签细化（NeGPR）框架，专为带有噪声标签的图级域适应设计。NeGPR首先通过强制特征空间中的邻域一致性来预训练语义和拓扑双分支，以减少噪声监督的影响。为了弥合域间隙，NeGPR采用嵌套细化机制，其中一个分支选择高置信度目标样本来指导另一个分支的适应，实现渐进式跨域学习。此外，NeGPR引入了噪声感知正则化策略，理论上证明即使在源域过拟合的情况下也能减轻伪标签噪声的不利影响，从而增强适应过程的鲁棒性。

**Result:** 在基准数据集上的大量实验表明，NeGPR在严重标签噪声下始终优于最先进的方法，准确率提高了高达12.7%。

**Conclusion:** NeGPR成功解决了带有噪声标签的图域适应问题，通过其创新的双分支预训练、嵌套细化机制和噪声感知正则化策略，显著提高了在真实世界场景中的适应性能和鲁棒性。

> **ai_Abstract:** 本文提出了嵌套图伪标签细化（NeGPR）框架，旨在解决图域适应中源域标签存在噪声的问题。NeGPR通过预训练语义和拓扑双分支以减少噪声监督影响，采用嵌套细化机制进行渐进式跨域学习，并引入噪声感知正则化策略以缓解伪标签噪声和源域过拟合。实验证明，NeGPR在严重标签噪声下性能显著优于现有方法，准确率提升高达12.7%。

> **摘要翻译:** 图域适应（GDA）通过学习域不变表示来促进从有标签源图到无标签目标图的知识迁移，这在分子性质预测和社交网络分析等应用中至关重要。然而，大多数现有的GDA方法依赖于干净源标签的假设，这在标注噪声普遍存在的现实世界场景中很少成立。这种标签噪声严重损害了特征对齐并降低了域漂移下的适应性能。为了解决这一挑战，我们提出了嵌套图伪标签细化（NeGPR），这是一个专为带有噪声标签的图级域适应量身定制的新颖框架。NeGPR首先通过强制特征空间中的邻域一致性来预训练双分支，即语义分支和拓扑分支，从而减少噪声监督的影响。为了弥合域间隙，NeGPR采用嵌套细化机制，其中一个分支选择高置信度目标样本来指导另一个分支的适应，实现渐进式跨域学习。此外，由于伪标签可能仍包含噪声，并且预训练的分支已经对源域中的噪声标签过拟合，NeGPR结合了一种噪声感知正则化策略。该正则化在理论上被证明可以减轻伪标签噪声的不利影响，即使在源域过拟合的情况下也是如此，从而增强了适应过程的鲁棒性。在基准数据集上的大量实验表明，NeGPR在严重标签噪声下始终优于最先进的方法，准确率提高了高达12.7%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [105] [Embryology of a Language Model](https://arxiv.org/abs/2508.00331)
> *语言模型的胚胎学*

*George Wang, Garrett Baker, Andrew Gordon, Daniel Murfet* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 语言模型, 敏感性分析, UMAP, 神经网络发展, 结构可视化

**Comment:** 

> **TL;DR:** 本文引入了一种胚胎学方法，通过对敏感性矩阵应用UMAP来可视化语言模型在训练过程中的结构发展，揭示了“身体蓝图”的出现以及新颖机制的形成。

**AI_Comments:** 该论文的创新之处在于将“胚胎学”概念引入语言模型研究，并创造性地利用UMAP对敏感性矩阵进行可视化，从而揭示了模型内部结构发展的动态过程和新颖机制。这为理解深度学习模型的“黑箱”操作提供了一个全新的视角，具有重要的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 理解语言模型如何发展其内部计算结构是深度学习科学的核心问题。尽管源自统计物理学的敏感性提供了一种有前景的分析工具，但其在可视化网络组织方面的全部潜力尚未被开发。

**Method:** 本文引入了一种胚胎学方法，将UMAP应用于敏感性矩阵，以可视化模型在训练过程中的结构发展。

**Result:** 可视化结果揭示了一个清晰的“身体蓝图”的出现，描绘了诸如归纳电路等已知特征的形成，并发现了以前未知的结构，例如专门用于计算空格标记的“间隔鳍”。

**Conclusion:** 这项工作表明，敏感性分析可以超越验证，发现新的机制，为研究复杂神经网络的发展原理提供了一个强大、整体的视角。

> **ai_Abstract:** 本文提出了一种“胚胎学”方法，利用UMAP对语言模型的敏感性矩阵进行可视化，以研究模型在训练过程中的内部结构发展。研究发现，模型在训练中形成了清晰的“身体蓝图”，包括已知的归纳电路和新的“间隔鳍”结构。这表明敏感性分析是一种强大的工具，可以揭示复杂神经网络的深层发展机制。

> **摘要翻译:** 理解语言模型如何发展其内部计算结构是深度学习科学的核心问题。虽然源自统计物理学的敏感性提供了一种有前景的分析工具，但其在可视化网络组织方面的全部潜力尚未被开发。在这项工作中，我们引入了一种胚胎学方法，将UMAP应用于敏感性矩阵，以可视化模型在训练过程中的结构发展。我们的可视化结果揭示了一个清晰的“身体蓝图”的出现，描绘了诸如归纳电路等已知特征的形成，并发现了以前未知的结构，例如专门用于计算空格标记的“间隔鳍”。这项工作表明，敏感性分析可以超越验证，发现新的机制，为研究复杂神经网络的发展原理提供了一个强大、整体的视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [118] [Un-mixing Test-time Adaptation under Heterogeneous Data Streams](https://arxiv.org/abs/2411.15173)
> *异构数据流下解耦的测试时间适应*

*Zixian Su, Jingwei Guo, Xi Yang, Qiufeng Wang, Kaizhu Huang* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 测试时间适应, 异构数据流, 频域分析, 分布偏移, 去中心化适应

**Comment:** 

> **TL;DR:** 本文提出FreDA框架，通过在傅里叶域解耦异构数据流，改进了测试时间适应（TTA）在复杂混合分布偏移下的性能，并在多种环境下表现优于现有技术。

**AI_Comments:** 本文的创新点在于从频域角度重新审视测试时间适应（TTA），并提出利用高频分量来识别和分离异构数据流中的不同潜在域。这种“解耦”的思想使得TTA在面对复杂、混合的分布偏移时变得更加有效和鲁棒。FreDA框架的提出为解决真实世界中模型部署面临的挑战提供了一个新颖且有前景的方向，尤其是在无监督和在线适应的场景下，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 在实际应用中，深度模型在训练和部署环境之间存在分布偏移时性能会显著下降。测试时间适应（TTA）是一种有前景的解决方案，但其在存在复杂、混合分布偏移（即多种潜在域共存的异构数据流）的情况下效果会显著降低。在无标签和在线条件下，解决这种内在异构性下的适应问题仍是一个开放且未充分探索的挑战。

**Method:** 本文从频域角度重新审视TTA，观察到分布异构性常在傅里叶空间中显现（例如，高频分量携带域特定变化）。受此启发，提出FreDA（Frequency-based Decentralized Adaptation）框架，该框架利用高频纹理线索进行域感知分离，将全局异构数据分解为频域中的局部同质分量。此外，FreDA还采用去中心化学习和增强策略，以在复杂、不断变化的偏移下进行鲁棒适应。

**Result:** 在各种环境（损坏、自然和医疗）下的广泛实验表明，所提出的FreDA框架优于现有最先进的技术。

**Conclusion:** 本文通过引入FreDA框架，成功解决了测试时间适应在异构数据流下性能下降的问题，通过在频域进行域感知分离和去中心化适应，显著提升了模型在复杂分布偏移下的鲁棒性。

> **ai_Abstract:** 本文针对测试时间适应（TTA）在复杂、混合分布偏移下性能显著下降的挑战，提出了名为FreDA的频率基去中心化适应框架。该框架通过分析傅里叶空间中分布异构性在高频分量上的表现，创新性地利用高频纹理线索进行域感知分离，将全局异构数据分解为局部同质分量。结合去中心化学习和增强策略，FreDA在无标签和在线条件下实现了对复杂异构数据流的鲁棒适应。实验结果表明，FreDA在多种实际应用场景中均显著优于现有SOTA方法。

> **摘要翻译:** 在真实场景中部署深度模型仍然充满挑战，因为训练和部署环境之间的分布偏移会导致性能显著下降。测试时间适应（TTA）最近作为一种有前景的解决方案出现，它无需访问源数据即可实现模型的即时适应。然而，在存在复杂、混合分布偏移（这在实际设置中很常见，即多种潜在域共存）的情况下，其有效性会显著降低。在这种内在异构性下进行适应，尤其是在无标签和在线条件下，仍然是一个开放且未充分探索的挑战。在本文中，我们研究了混合分布偏移下的TTA，并超越了传统的同质适应范式。通过从频域角度重新审视TTA，我们观察到分布异构性通常在傅里叶空间中表现出来——例如，高频分量倾向于携带域特定的变化。这促使我们利用高频纹理线索执行域感知分离，使不同的偏移模式更易于处理。为此，我们提出了FreDA，一种新颖的基于频率的去中心化适应框架，它将全局异构数据分解为频域中的局部同质分量。它进一步采用去中心化学习和增强策略，以在复杂、不断变化的偏移下进行鲁棒适应。在各种环境（损坏、自然和医疗）下的广泛实验证明了我们提出的框架优于最先进的技术。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [129] [Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems](https://arxiv.org/abs/2508.00734)
> *自适应机器学习驱动的多精度分层抽样用于非线性随机系统故障分析*

*Liuyun Xu, Seymour M. J. Spence* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 多精度抽样, 机器学习, 故障分析, 非线性系统, 随机模拟

**Comment:** 

> **TL;DR:** 提出一种自适应机器学习驱动的多精度分层抽样方案，用于高效分析非线性随机系统的罕见事件故障概率，显著节省计算成本。

**AI_Comments:** 该论文的创新点在于将自适应机器学习超模型与多精度分层抽样相结合，有效解决了复杂非线性随机系统罕见事件分析中的计算效率问题。通过构建成本效益高的低精度模型并自适应优化训练过程，实现了精度和计算成本的平衡。这对于工程领域中涉及复杂模型和不确定性的故障分析具有重要意义，尤其是在需要大量模拟才能获得可靠结果的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 现有方差缩减技术在罕见事件分析中仍需要大量模型评估来估计小故障概率，这在复杂非线性有限元建模环境中（特别是随机激励系统）计算成本很高。

**Method:** 引入一种结合自适应机器学习超模型的乘法分层抽样方案。通过分层抽样生成高精度数据集训练深度学习超模型作为低精度模型。提出自适应训练方案平衡近似质量和计算需求。将低精度输出与高精度结果结合，使用多精度蒙特卡洛框架获得无偏的层内故障概率估计，再通过全概率定理计算总故障概率。

**Result:** 应用到随机风激励下的大型高层钢结构建筑，结果表明该方案能准确估计非线性响应的超限概率曲线，并相比单精度方差缩减方法显著节省计算成本。

**Conclusion:** 该提出的自适应机器学习驱动的多精度分层抽样方案能够高效且准确地估计非线性随机系统的故障概率，显著降低计算成本。

> **ai_Abstract:** 本文提出了一种自适应机器学习驱动的多精度分层抽样方案，旨在解决复杂非线性随机系统（特别是受随机激励的系统）中罕见事件故障概率估计计算成本高昂的问题。该方案利用高精度数据训练深度学习超模型作为低精度代理，并通过自适应训练平衡模型质量与计算成本。结合多精度蒙特卡洛框架和全概率定理，该方法能够高效、准确地估计故障概率。在实际高层建筑案例中的应用验证了其在保证精度的前提下显著降低计算负担的有效性。

> **摘要翻译:** 现有用于罕见事件分析的随机模拟中使用的方差缩减技术仍然需要大量的模型评估来估计小的故障概率。在复杂的非线性有限元建模环境中，这可能在计算上变得具有挑战性——特别是对于受随机激励的系统。为了应对这一挑战，本文引入了一种具有自适应机器学习超模型的多精度分层抽样方案，用于有效地传播不确定性并估计小的故障概率。在该方法中，通过分层抽样生成的高精度数据集用于训练基于深度学习的超模型，该超模型随后作为一种成本效益高且高度相关的低精度模型。提出了一种自适应训练方案，以平衡与低精度模型开发相关的近似质量和计算需求之间的权衡。通过将低精度输出与额外的高精度结果相结合，使用多精度蒙特卡洛框架获得了层内故障概率的无偏估计。然后使用全概率定理计算总故障概率。应用于受随机风激励的全尺寸高层钢结构建筑表明，所提出的方案可以准确估计感兴趣的非线性响应的超限概率曲线，同时与单精度方差缩减方法相比，实现了显著的计算节省。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [130] [BOOD: Boundary-based Out-Of-Distribution Data Generation](https://arxiv.org/abs/2508.00350)
> *BOOD: 基于边界的分布外数据生成*

*Qilin Liao, Shuo Yang, Bo Zhao, Ping Luo, Hengshuang Zhao* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** OOD检测, 扩散模型, 边界生成, 潜在空间, 数据增强

**Comment:** 14 pages, 8 figures, To be published in the Proceedings of the
  International Conference on Machine Learning (ICML) 2025

> **TL;DR:** BOOD提出了一种新的基于边界的方法，利用扩散模型合成高质量的分布外（OOD）特征和图像，显著提高了OOD检测性能。

**AI_Comments:** BOOD的创新点在于其基于边界的OOD数据生成策略，通过在潜在空间中精确地扰动接近决策边界的ID特征来合成OOD数据。这解决了传统方法中OOD特征提取的挑战，并提高了训练效率。其在OOD检测性能上的显著提升，尤其是在FPR95和AUROC上的改进，凸显了该方法的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 利用扩散模型合成辅助训练数据以增强分布外（OOD）检测性能已被证明有效。然而，由于难以识别类别间的决策边界，在潜在空间中提取分布内（ID）边界之外的有效特征仍然具有挑战性。

**Method:** 本文提出了一种名为BOOD（Boundary-based Out-Of-Distribution data generation）的新框架。BOOD首先从ID数据集中学习一个文本条件的潜在特征空间，然后选择最接近决策边界的ID特征，并对其进行扰动以跨越决策边界，从而形成OOD特征。这些合成的OOD特征随后通过扩散模型解码为像素空间中的图像。

**Result:** 与现有工作相比，BOOD提供了一种更具训练效率的策略来合成信息丰富的OOD特征，有助于更清晰地区分ID和OOD数据。在CIFAR-100数据集上的广泛实验结果表明，BOOD显著超越了最先进的方法，平均FPR95降低了29.64%（40.31% vs. 10.67%），平均AUROC提高了7.27%（90.15% vs. 97.42%）。

**Conclusion:** BOOD通过合成高质量的OOD特征和图像，显著提升了OOD检测性能，并提供了一种更高效的训练策略，实现了ID和OOD数据间更清晰的区分。

> **ai_Abstract:** 本文提出了一种名为BOOD（Boundary-based Out-Of-Distribution data generation）的新型框架，旨在解决OOD检测中难以提取有效OOD特征的问题。BOOD利用扩散模型，通过学习文本条件潜在特征空间，选择并扰动接近决策边界的ID特征来生成高质量的OOD特征和图像。该方法提供了更高效的训练策略，并显著提高了OOD检测性能，在CIFAR-100数据集上取得了显著优于现有SOTA方法的表现。

> **摘要翻译:** 利用扩散模型合成基于潜在空间特征的辅助训练数据已被证明能有效提升分布外（OOD）检测性能。然而，由于难以识别类别间的决策边界，在潜在空间中提取分布内（ID）边界之外的有效特征仍然具有挑战性。本文提出了一种名为基于边界的分布外数据生成（BOOD）的新颖框架，该框架利用扩散模型合成高质量的OOD特征并生成与人类兼容的异常图像。BOOD首先从ID数据集中学习一个文本条件的潜在特征空间，选择最接近决策边界的ID特征，并对其进行扰动以跨越决策边界，从而形成OOD特征。然后，这些合成的OOD特征通过扩散模型解码为像素空间中的图像。与以往的工作相比，BOOD提供了一种更具训练效率的策略来合成信息丰富的OOD特征，有助于更清晰地区分ID和OOD数据。在常见基准上的大量实验结果表明，BOOD显著超越了最先进的方法，在CIFAR-100数据集上平均FPR95降低了29.64%（40.31% vs. 10.67%），平均AUROC提高了7.27%（90.15% vs. 97.42%）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [131] [NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box Computational Functions](https://arxiv.org/abs/2507.23186)
> *NaN传播：一种用于黑盒计算函数中稀疏性检测的新方法*

*Peter Sharpe* | **Category: cs.LG, cs.PL** | **Updated: 2025-08-01**

**Keywords:** NaN传播, 稀疏性检测, 黑盒函数, 梯度计算, IEEE 754

**Comment:** 

> **TL;DR:** NaN传播是一种利用IEEE 754 NaN值的特性来检测黑盒函数稀疏性的新方法，它能有效避免传统方法的假阴性问题，提高梯度计算效率。

**AI_Comments:** 该论文的创新点在于巧妙地利用了IEEE 754浮点标准中NaN值的“污染”特性来检测黑盒函数的稀疏性，这提供了一种非常鲁棒且无需修改源代码的方法。它解决了传统有限差分方法中假阴性导致的问题，提高了梯度计算的可靠性，对于优化领域具有重要的实用价值。此外，其跨语言和库的兼容性以及潜在的超线性时间复杂度也显示了其强大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在数值评估函数梯度时，稀疏性检测可以通过雅可比着色和压缩显著加速计算。然而，针对黑盒函数的稀疏性检测技术有限，现有基于有限差分的方法存在假阴性问题（由于巧合的零梯度），这会悄无声息地破坏梯度计算，导致难以诊断的错误。

**Method:** NaN传播方法利用IEEE 754非数值（NaN）值的普遍污染特性，通过浮点数值计算追踪输入-输出依赖关系。该方法通过系统地用NaN污染输入并观察哪些输出变为NaN，重建保守的稀疏模式，从而消除假阴性的主要来源。此外，该技术利用IEEE 754兼容性，无需修改现有黑盒代码即可跨编程语言和数学库工作。高级策略如通过直接位操作进行NaN负载编码，可实现比线性时间复杂度更快的速度，并提出了实用算法来缓解工程应用中常见的分支代码执行带来的挑战。

**Result:** 该方法在一个航空航天机翼重量模型上进行了演示，实现了1.52倍的加速，同时发现了数十个传统方法遗漏的依赖关系。梯度计算通常是优化工作流中的瓶颈，因此这是一个显著的实际改进。

**Conclusion:** NaN传播是一种鲁棒且高效的黑盒函数稀疏性检测方法，它通过消除假阴性提高了梯度计算的准确性和效率，并且无需修改现有代码，具有广泛的适用性。

> **ai_Abstract:** 本文提出了一种名为NaN传播的新型黑盒计算函数稀疏性检测方法。该方法利用IEEE 754 NaN值的普遍污染特性，通过系统地污染输入并观察输出的NaN化来追踪输入-输出依赖关系，从而重建保守的稀疏模式。这有效解决了现有基于有限差分方法中因巧合零梯度导致的假阴性问题。实验表明，NaN传播在一个航空航天模型上实现了1.52倍的加速，并发现了传统方法遗漏的依赖关系，显著提升了梯度计算的效率和准确性。该技术无需修改现有代码，并可通过高级策略进一步提升性能。

> **摘要翻译:** 当数值评估函数的梯度时，稀疏性检测可以通过雅可比着色和压缩实现显著的计算加速。然而，针对黑盒函数的稀疏性检测技术有限，现有基于有限差分的方法由于巧合的零梯度而存在假阴性问题。这些假阴性会悄无声息地破坏梯度计算，导致难以诊断的错误。我们引入了NaN传播，它利用IEEE 754非数值（Not-a-Number）值的普遍污染特性，通过浮点数值计算追踪输入-输出依赖关系。通过系统地用NaN污染输入并观察哪些输出变为NaN，该方法重建保守的稀疏模式，从而消除假阴性的主要来源。我们在一个航空航天机翼重量模型上演示了这种方法，实现了1.52倍的加速，同时发现了数十个传统方法遗漏的依赖关系——这是一个显著的实际改进，因为梯度计算通常是优化工作流中的瓶颈。该技术利用IEEE 754兼容性，无需修改现有黑盒代码即可跨编程语言和数学库工作。此外，通过直接位操作进行NaN负载编码等高级策略可实现比线性时间复杂度更快的速度，从而优于现有黑盒稀疏性检测方法。还提出了实用算法来缓解工程应用中常见的代码分支执行带来的挑战。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [146] [Sampling-enabled scalable manifold learning unveils discriminative cluster structure of high-dimensional data](https://arxiv.org/abs/2401.01100)
> *采样驱动的可伸缩流形学习揭示高维数据的判别性聚类结构*

*Dehua Peng, Zhipeng Gui, Wenzhang Wei, Fa Li, Jie Gui, Huayi Wu, Jianya Gong* | **Category: cs.LG, I.5.3** | **Updated: 2025-08-01**

**Keywords:** 流形学习, 高维数据, 可伸缩性, 聚类结构, 采样策略

**Comment:** 80 pages, 37 figures

> **TL;DR:** 提出了一种名为SUDE的采样驱动可伸缩流形学习技术，用于处理大规模高维数据，解决了现有方法在聚类结构失真和可伸缩性方面的局限，并在实验中展现出优越的性能和鲁棒性。

**AI_Comments:** 这篇论文通过引入采样机制和地标点策略，有效解决了传统流形学习方法在处理大规模高维数据时面临的计算复杂度和聚类结构失真问题。SUDE的创新点在于其结合了采样和局部线性嵌入的策略，实现了在保持数据内在结构的同时提高可伸缩性。其在真实世界数据集上的应用展示了其实用价值和潜在影响力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的流形学习技术存在聚类结构严重失真和可伸缩性问题，这限制了它们在大规模高维数据上的应用，并阻碍了对底层模式的理解。

**Method:** 提出了一种名为SUDE（Sampling-based Scalable manifold learning technique that enables Uniform and Discriminative Embedding）的采样驱动可伸缩流形学习技术。该方法首先通过寻找地标点来构建整个数据的低维骨架，然后基于约束局部线性嵌入（CLLE）将非地标点融入到学习到的空间中。

**Result:** SUDE在数据规模和嵌入维度方面表现出显著的可伸缩性优势，并在聚类分离、完整性和全局结构保持方面表现出有前景的性能。实验还表明，随着采样率的降低，嵌入质量具有显著的鲁棒性。

**Conclusion:** SUDE是一种有效且鲁棒的流形学习方法，能够解决现有技术在处理大规模高维数据时遇到的聚类结构失真和可伸缩性问题，为高维数据的分析和理解提供了新的工具。

> **ai_Abstract:** 本文提出了一种名为SUDE的采样驱动可伸缩流形学习技术，旨在解决现有流形学习方法在处理大规模高维数据时遇到的聚类结构失真和可伸缩性问题。SUDE通过先构建地标点的低维骨架，再利用约束局部线性嵌入整合非地标点。实验结果表明，SUDE在数据量和嵌入维度上具有良好的可伸缩性，并在聚类分离、完整性和全局结构保持方面表现出色，同时对采样率降低具有鲁棒性，适用于单细胞数据分析和ECG异常检测。

> **摘要翻译:** 作为机器学习的一个关键分支，流形学习揭示了高维空间中复杂非线性流形的内在低维结构，用于可视化、分类、聚类和获取关键洞察。尽管现有技术取得了显著成功，但它们存在聚类结构严重失真的问题，这阻碍了对底层模式的理解。可伸缩性问题也限制了它们处理大规模数据的适用性。因此，我们提出了一种基于采样的可伸缩流形学习技术，该技术能够实现均匀和判别性嵌入，即SUDE，用于大规模高维数据。它首先通过寻找一组地标点来构建整个数据的低维骨架，然后基于约束局部线性嵌入（CLLE）将非地标点纳入学习到的空间。我们在合成数据集和真实世界基准上经验性地验证了SUDE的有效性，并将其应用于分析单细胞数据和检测心电图（ECG）信号中的异常。SUDE在数据规模和嵌入维度方面表现出显著的可伸伸性优势，并在聚类分离、完整性和全局结构保持方面具有有前景的性能。实验还表明，随着采样率的降低，嵌入质量具有显著的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [150] [Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization](https://arxiv.org/abs/2508.00357)
> *层束图神经网络通过PAC-贝叶斯谱优化*

*Yoonhyuk Choi, Jiho Choi, Chong-Kwon Kim* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 层束图神经网络, PAC-贝叶斯, 过平滑, 异配图, 节点分类

**Comment:** 

> **TL;DR:** 本文提出了一种名为SGPC的新型层束图神经网络架构，通过结合多种机制（如最优传输、方差减少扩散和PAC-贝叶斯谱正则化）来解决GNN中的过平滑问题，并在理论和实验上证明了其优越性。

**AI_Comments:** 本文的创新点在于提出了SGPC这一统一架构，通过结合多种先进技术（如PAC-贝叶斯谱正则化和最优传输）来解决GNN的过平滑问题，特别是在异配图上的挑战。其重要性体现在提供了理论上的性能保证和计算效率，并在实验中展示了超越现有先进模型的性能，同时还能提供置信区间，这对于模型的可信度和鲁棒性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）中的过平滑问题会导致节点特征的崩溃，尤其是在异配图上。现有的层束神经网络虽然能部分缓解此问题，但其静态或参数化过重的层束结构限制了泛化性和可扩展性，且未能提供严格的稳定性保证。

**Method:** 本文提出了一种名为SGPC（Sheaf GNNs with PAC-Bayes Calibration）的新颖方案。SGPC是一个统一的架构，将细胞层束消息传递与多种机制相结合，包括基于最优传输的提升、方差减少扩散以及用于鲁棒半监督节点分类的PAC-贝叶斯谱正则化。

**Result:** 理论上，本文建立了性能界限，并证明了通过端到端训练可以实现由此产生的有界目标，且计算复杂度为线性。实验结果表明，在九个同配和异配基准测试中，SGPC优于最先进的谱和基于层束的GNN，同时为未见节点提供了认证的置信区间。

**Conclusion:** SGPC通过结合细胞层束消息传递、最优传输、方差减少扩散和PAC-贝叶斯谱正则化，有效地解决了GNN中的过平滑问题，并在理论上提供了性能保证，在实践中展现出卓越的性能和鲁棒性。

> **ai_Abstract:** 本文针对图神经网络（GNNs）中过平滑问题及其在异配图上的影响，以及现有层束网络在泛化性、可扩展性和稳定性方面的局限性，提出了一种名为SGPC（Sheaf GNNs with PAC-Bayes Calibration）的新型统一架构。SGPC结合了细胞层束消息传递、最优传输、方差减少扩散和PAC-贝叶斯谱正则化，旨在实现鲁棒的半监督节点分类。该研究不仅从理论上建立了性能界限并证明了其线性计算复杂度的端到端训练可行性，还在多个基准测试上验证了SGPC优于现有先进模型，并能提供经过认证的置信区间。

> **摘要翻译:** 图神经网络（GNNs）中的过平滑问题导致不同节点特征的崩溃，尤其是在异配图中，相邻节点通常具有不相似的标签。尽管层束神经网络部分缓解了这个问题，但它们通常依赖于静态或过度参数化的层束结构，这阻碍了泛化性和可扩展性。现有的基于层束的模型要么预定义限制映射，要么引入过度的复杂性，却未能提供严格的稳定性保证。在本文中，我们引入了一种名为SGPC（Sheaf GNNs with PAC-Bayes Calibration）的新颖方案，这是一种统一的架构，它将细胞层束消息传递与多种机制相结合，包括基于最优传输的提升、方差减少扩散，以及用于鲁棒半监督节点分类的PAC-贝叶斯谱正则化。我们从理论上建立了性能界限，并证明了由此产生的有界目标可以通过端到端训练以线性计算复杂度实现。在九个同配和异配基准测试上的实验表明，SGPC优于最先进的谱和基于层束的GNN，同时为未见节点提供了认证的置信区间。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [153] [EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes](https://arxiv.org/abs/2508.00180)
> *无滞后的EMA：偏置校正的迭代平均方案*

*Adam Block, Cyril Zhang* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-31**

**Keywords:** EMA, 偏置校正, 迭代平均, 语言模型, 微调

**Comment:** 

> **TL;DR:** 提出BEMA，一种偏置校正的EMA方法，用于语言模型微调，能消除传统EMA的滞后并提高收敛速度和性能。

**AI_Comments:** 这项工作通过引入偏置校正的概念，解决了传统EMA在优化过程中引入滞后的关键限制，这对于语言模型微调尤其重要。其创新点在于在保持EMA方差减少优势的同时，通过理论证明和实验验证消除了偏置，从而实现了更快的收敛和更好的性能，为深度学习训练的稳定性与效率提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型微调中，小批量大小导致的随机性会使训练不稳定并产生大的生成质量波动。虽然EMA能减少随机性，但其引入的旧迭代偏置会导致优化滞后。

**Method:** 提出偏置校正指数移动平均（BEMA），作为EMA的简单实用增强。BEMA通过消除偏置来保留方差减少的益处。其理论基础是一个简单的理论模型，证明了BEMA比标准EMA和普通训练具有可证明的加速。

**Result:** 通过对语言模型进行广泛实验，BEMA在各种标准LM基准测试中，与EMA和普通训练相比，显著提高了收敛速度和最终性能。

**Conclusion:** BEMA是一种实用且有理论依据的干预措施，能够实现更稳定、更高效的语言模型微调。

> **ai_Abstract:** 本文提出了一种名为偏置校正指数移动平均（BEMA）的新方法，旨在解决语言模型微调中由小批量大小引起的训练不稳定性。传统EMA虽然能减少随机性，但会引入优化滞后。BEMA通过消除偏置，在保留EMA方差减少优势的同时，实现了无滞后的优化。理论模型证明BEMA比标准EMA和普通训练更快，实验结果也表明BEMA显著提升了语言模型的收敛速度和最终性能，使其成为稳定高效微调的有效工具。

> **摘要翻译:** 语言模型微调中的随机性，通常由该领域常用的小批量大小引起，可能通过引入生成质量的剧烈波动来破坏训练的稳定性。一种缓解这种不稳定性的常用方法是在整个训练过程中对权重进行指数移动平均（EMA）。虽然EMA减少了随机性，从而平滑了训练，但引入旧迭代的偏置常常导致优化相对于普通训练产生滞后。在这项工作中，我们提出了偏置校正指数移动平均（BEMA），这是一种简单实用的EMA增强方法，它保留了方差减少的优点，同时消除了偏置。BEMA的提出源于一个简单的理论模型，在该模型中，我们证明了BEMA相对于标准EMA和普通训练具有可证明的加速。通过对语言模型进行广泛的实验，我们表明BEMA在各种标准LM基准测试中，与EMA和普通训练相比，显著提高了收敛速度和最终性能，这使得BEMA成为一种实用且有理论依据的干预措施，用于更稳定和高效的微调。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [160] [Embracing Large Language Models in Traffic Flow Forecasting](https://arxiv.org/abs/2412.12201)
> *交通流量预测中引入大型语言模型*

*Yusheng Zhao, Xiao Luo, Haomin Wen, Zhiping Xiao, Wei Ju, Ming Zhang* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 交通流量预测, 大型语言模型, 时空依赖, 图神经网络, 超图

**Comment:** Accepted by ACL 2025

> **TL;DR:** 引入大型语言模型（LLM）来增强交通流量预测，通过结合图和超图结构的两分支预测器，并利用LLM在测试时选择最佳预测结果，以提高对环境变化的适应性。

**AI_Comments:** 这篇论文通过将大型语言模型引入交通流量预测领域，解决现有方法在适应测试时环境变化方面的局限性，具有创新性。其核心思想是利用LLM的决策能力来选择多个预测分支中最优的结果，这为集成多种预测模型提供了一个新颖的框架。这种混合模型的方法可能为智能交通系统带来更鲁棒和适应性强的预测能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有交通流量预测方法在适应测试时交通条件的环境变化方面存在不足。

**Method:** 本文提出了一种名为LEAF（Large Language Model Enhanced Traffic Flow Predictor）的新颖方法。LEAF采用两个分支，分别使用图和超图结构捕获不同的时空关系，并单独进行预训练。在测试时，这两个分支会产生不同的预测结果，然后利用大型语言模型选择最可能的结果。此外，采用排序损失作为学习目标来增强两分支的预测能力。

**Result:** 在多个数据集上进行的广泛实验表明，所提出的LEAF方法是有效的。

**Conclusion:** 通过引入大型语言模型并结合多分支预测器和排序损失，LEAF有效解决了交通流量预测中现有方法对测试时环境变化适应性不足的问题，并显著提高了预测性能。

> **ai_Abstract:** 本文提出了一种名为LEAF（大型语言模型增强交通流量预测器）的新型方法，旨在解决现有交通流量预测模型在适应测试时环境变化方面的不足。LEAF结合了两个分别基于图和超图结构捕获时空关系的分支预测器。这些分支经过单独预训练，并在测试时生成不同的预测。一个大型语言模型被用于从这些预测中选择最可能的结果，并通过排序损失进一步优化分支的预测能力。实验结果证明了LEAF在交通流量预测中的有效性。

> **摘要翻译:** 交通流量预测旨在根据历史交通状况和路网预测未来的交通流量。这是智能交通系统中一个重要问题，已经提出了大量方法。现有工作主要侧重于捕获和利用时空依赖性来预测未来的交通流量。尽管有前景，但它们在适应交通状况的测试时环境变化方面存在不足。为了解决这一挑战，我们提出引入大型语言模型（LLMs）来辅助交通流量预测，并设计了一种名为大型语言模型增强交通流量预测器（LEAF）的新颖方法。LEAF采用两个分支，分别使用图和超图结构捕获不同的时空关系。这两个分支首先单独预训练，在测试时它们会产生不同的预测结果。基于这些预测，使用大型语言模型选择最可能的结果。然后，应用排序损失作为学习目标，以增强两个分支的预测能力。在多个数据集上进行的广泛实验证明了所提出的LEAF的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [166] [Model Stock: All we need is just a few fine-tuned models](https://arxiv.org/abs/2403.19522)
> *模型库存：我们只需要少数几个微调模型*

*Dong-Hwan Jang, Sangdoo Yun, Dongyoon Han* | **Category: cs.LG, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 微调, 大型预训练模型, 模型平均, 权重空间, Model Stock

**Comment:** ECCV 2024 oral presenetation; Code at
  https://github.com/naver-ai/model-stock

> **TL;DR:** 本文提出了一种名为“Model Stock”的高效微调方法，仅使用少数几个（例如两个）微调模型即可获得比传统方法更优越的性能，尤其适用于大型预训练模型，并在ID和OOD任务上表现出色。

**AI_Comments:** 本文的创新点在于，通过理解微调权重在权重空间中的特性，极大地减少了模型平均所需的模型数量，同时提升了模型性能。这对于大型模型的部署效率和实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的模型微调实践需要大量微调模型进行平均以获得最终权重，这种方法效率低下。本文旨在打破这种传统，提供一种更高效的替代方案。

**Method:** 本文基于对微调模型权重空间的关键见解，发现性能与权重空间中心接近度之间存在强关联。在此基础上，提出了一种仅使用两个微调模型即可近似中心附近权重的方法，该方法可在训练期间或训练后应用。具体采用了一种创新的逐层权重平均技术。

**Result:** 所提出的Model Stock方法仅使用两个微调模型，便超越了诸如Model Soup等最先进的模型平均方法。该方法在使用预训练CLIP架构的微调模型上，在标准基准测试的分布内（ID）和分布外（OOD）任务上均取得了显著性能，且几乎没有带来额外的计算开销。

**Conclusion:** Model Stock是一种高效且有效的大型预训练模型微调方法，它通过使用显著更少的模型，在ID和OOD任务上均实现了优越的性能，从而克服了传统方法的局限性。

> **ai_Abstract:** 本文提出了一种名为“Model Stock”的高效微调方法，用于大型预训练模型。该方法利用对权重空间的深入理解，仅通过少数几个（例如两个）微调模型即可近似得到最优权重，从而在ID和OOD任务上超越了Model Soup等传统模型平均方法，并显著降低了计算成本。

> **摘要翻译:** 本文介绍了一种高效的大型预训练模型微调方法，该方法在分布内（ID）和分布外（OOD）性能方面表现出色。与需要大量微调模型进行平均的传统做法不同，我们的方法使用显著更少的模型来获得最终权重，却能产生更高的准确性。通过对微调权重在权重空间中的关键见解，我们揭示了性能与权重空间中心接近度之间的强联系。基于此，我们引入了一种仅使用两个微调模型即可近似中心附近权重的方法，该方法可在训练期间或训练后应用。我们创新的逐层权重平均技术超越了诸如Model Soup等最先进的模型方法，仅使用了两个微调模型。这种策略可以恰当地命名为Model Stock（模型库存），突出了它依赖于选择最少数量的模型来获得更优化的平均模型。我们使用基于预训练CLIP架构的微调模型展示了Model Stock的有效性，在标准基准测试的ID和OOD任务上均取得了显著性能，同时几乎没有带来额外的计算开销。我们的代码和预训练模型可在https://github.com/naver-ai/model-stock获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [170] [OID-PPO: Optimal Interior Design using Proximal Policy Optimization by Transforming Design Guidelines into Reward Functions](https://arxiv.org/abs/2508.00364)
> *OID-PPO：通过将设计指南转化为奖励函数实现近端策略优化的最佳室内设计*

*Chanyoung Yoon, Sangbong Yoo, Soobin Yim, Chansoo Kim, Yun Jang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 强化学习, 室内设计, 近端策略优化, 奖励函数, 家具放置

**Comment:** 

> **TL;DR:** OID-PPO是一种新的强化学习框架，通过将设计指南转化为奖励函数，实现了连续灵活的家具放置，并在室内设计中表现出优异的布局质量和计算效率。

**AI_Comments:** OID-PPO的创新点在于其将专家设计指南系统地转化为强化学习的奖励函数，这有效解决了传统RL方法在室内设计中难以整合设计原则的问题。同时，采用对角高斯策略实现连续家具放置，也突破了离散位置的限制，提升了设计的灵活性和真实性。该方法在计算效率和布局质量上的提升，对于推动自动化室内设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 室内设计对居住者满意度影响大，但面临空间布局非结构化、计算需求高、依赖专家知识等挑战。现有方法计算昂贵或受限于数据稀缺，强化学习方法限制家具放置且未能充分融入设计原则。

**Method:** 本文提出了OID-PPO，一个使用近端策略优化（PPO）的新型强化学习框架，它将专家定义的功​​能和视觉指南整合到一个结构化的奖励函数中。OID-PPO利用对角高斯策略实现连续灵活的家具放置，并在部分可观察性下有效探索潜在的环境动态。

**Result:** 在不同房间形状和家具配置下的实验表明，OID-PPO在布局质量和计算效率方面显著优于现有最先进的方法。消融研究进一步证明了结构化指南整合的影响，并揭示了各个设计约束的独特贡献。

**Conclusion:** OID-PPO通过将设计指南转化为奖励函数，有效解决了室内设计中的挑战，实现了优异的布局质量和计算效率，为自动化室内设计提供了新的范式。

> **ai_Abstract:** 本文提出了OID-PPO，一个基于近端策略优化的新型强化学习框架，用于解决室内设计中的挑战。该框架通过将专家定义的设计指南转化为结构化奖励函数，并采用对角高斯策略实现连续灵活的家具放置。实验结果表明，OID-PPO在布局质量和计算效率上显著优于现有方法，且其结构化指南整合对性能提升具有重要作用。

> **摘要翻译:** 住宅室内设计强烈影响居住者的满意度，但由于非结构化的空间布局、高计算需求以及对专家知识的依赖，仍然具有挑战性。现有的基于优化或深度学习的方法要么计算成本高昂，要么受限于数据稀缺。强化学习（RL）方法通常将家具放置限制在离散位置，并且未能充分纳入设计原则。我们提出了OID-PPO，一个利用近端策略优化（Proximal Policy Optimization）实现最佳室内设计的新型RL框架，它将专家定义的功能和视觉指南整合到一个结构化的奖励函数中。OID-PPO利用对角高斯策略（diagonal Gaussian policy）实现连续和灵活的家具放置，在部分可观察性下有效探索潜在的环境动态。在不同房间形状和家具配置下进行的实验表明，OID-PPO在布局质量和计算效率方面显著优于现有最先进的方法。消融研究进一步证明了结构化指南整合的影响，并揭示了各个设计约束的独特贡献。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [173] [Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models](https://arxiv.org/abs/2508.00202)
> *噪声标签下的鲁棒分类：一种面向基础模型的几何感知可靠性框架*

*Ecem Bozkurt, Antonio Ortega* | **Category: cs.LG, cs.AI, eess.SP** | **Updated: 2025-07-31**

**Keywords:** 噪声标签, 鲁棒分类, 基础模型, 几何感知, 可靠性框架

**Comment:** 5 pages, 2 figures, under review at CAMSAP 2025

> **TL;DR:** 本文提出了一个两阶段框架，用于在不重新训练模型的情况下，利用几何信息提高基础模型在噪声标签下的分类鲁棒性，并通过局部邻域和可靠性估计方法优于现有基线。

**AI_Comments:** 本文的创新之处在于其几何感知可靠性框架，特别是在高噪声环境下减少对距离和局部邻域依赖的可靠性估计方法。它提供了一种有效的方法来应对基础模型在噪声标签数据下微调的挑战，且无需昂贵的模型再训练，这对于实际应用具有重要意义。该方法通过引入更精细的几何信息，超越了简单的kNN方法，展示了其优越性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明，利用基础模型嵌入的简单kNN方法在严重标签噪声下也能表现良好，这得益于它们利用了局部几何信息。本文的动机在于，通过引入更多几何信息，可以进一步提升性能。

**Method:** 本文提出了一个两阶段框架，包括可靠性估计和可靠性加权推理。对于给定实例，推理使用通过非负核（NNK）邻域构建获得的训练数据的局部邻域。此外，提出了几种可靠性估计方法，这些方法在标签噪声增加时可以较少依赖距离和局部邻域。

**Result:** 在CIFAR-10和DermaMNIST上的评估表明，本文方法在各种噪声条件下均提高了鲁棒性，超越了标准K-NN方法和最近的自适应邻域基线。

**Conclusion:** 通过引入几何信息，本文提出的两阶段框架显著提高了基础模型在噪声标签下的分类鲁棒性，尤其在可靠性估计中减少了对距离和局部邻域的依赖，从而在实践中表现出优越性。

> **ai_Abstract:** 本文提出了一种新颖的两阶段几何感知可靠性框架，旨在提高基础模型在噪声标签下的分类鲁棒性，而无需进行模型再训练。该框架利用局部几何信息，通过非负核（NNK）构建局部邻域进行可靠性加权推理。研究还引入了多种可靠性估计方法，这些方法能更好地适应高噪声环境。在CIFAR-10和DermaMNIST数据集上的实验结果表明，该方法在不同噪声条件下均优于现有的kNN和自适应邻域基线。

> **摘要翻译:** 预训练在大型数据集上的基础模型（FMs）已成为各种下游机器学习任务的基础，特别是在获取完美标注数据成本过高的场景中。在本文中，我们假设一个基础模型必须用噪声数据进行微调，并提出了一个两阶段框架，以确保在存在标签噪声的情况下实现鲁棒分类，而无需重新训练模型。最近的工作表明，使用从基础模型导出的嵌入的简单k-最近邻（kNN）方法即使在存在严重标签噪声的情况下也能取得良好性能。我们的工作动机是这些方法利用了局部几何结构。在本文中，遵循类似的两阶段过程，即可靠性估计后进行可靠性加权推理，我们表明通过引入几何信息可以实现性能提升。对于给定实例，我们提出的推理使用通过非负核（NNK）邻域构建获得的训练数据的局部邻域。我们提出了几种可靠性估计方法，这些方法在标签噪声增加时可以较少依赖距离和局部邻域。我们在CIFAR-10和DermaMNIST上的评估表明，我们的方法在各种噪声条件下均提高了鲁棒性，超越了标准K-NN方法和最近的自适应邻域基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [180] [ULTHO: Ultra-Lightweight yet Efficient Hyperparameter Optimization in Deep Reinforcement Learning](https://arxiv.org/abs/2503.06101)
> *ULTHO：深度强化学习中超轻量级高效超参数优化*

*Mingqi Yuan, Bo Li, Xin Jin, Wenjun Zeng* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 超参数优化, 深度强化学习, 多臂老虎机, 轻量级, 样本效率

**Comment:** 24 pages, 25 figures

> **TL;DR:** 提出ULTHO，一种超轻量级高效的深度强化学习超参数优化框架，通过将HPO建模为聚类多臂老虎机，实现在单次运行中快速优化并取得优异性能。

**AI_Comments:** ULTHO的创新之处在于将RL中的HPO问题转化为MABC，并结合统计过滤，提供了一种新颖且计算高效的解决方案。其“超轻量级”和“单次运行”的特性对于实际应用和广泛推广具有重要意义，克服了现有方法计算开销大的限制。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习中的超参数优化（HPO）因其高非平稳性和计算成本而极具挑战性，现有方法样本效率低且计算开销大，无法广泛应用。

**Method:** 论文提出了ULTHO框架，将超参数优化过程公式化为带有聚类臂的多臂老虎机（MABC）问题，并将其直接与长期回报优化联系起来。ULTHO还提供了一种量化和统计的视角来高效过滤超参数。

**Result:** 在ALE、Procgen、MiniGrid和PyBullet等基准测试上的大量实验表明，ULTHO以简单的架构实现了卓越的性能。

**Conclusion:** ULTHO通过其超轻量级和高效的超参数优化能力，有助于开发更先进和自动化的强化学习系统。

> **ai_Abstract:** 本文提出ULTHO，一个针对深度强化学习（RL）的超轻量级高效超参数优化（HPO）框架。面对现有RL中HPO方法样本效率低和计算成本高的问题，ULTHO将HPO建模为带有聚类臂的多臂老虎机（MABC）问题，并结合量化统计视角高效过滤超参数，以实现单次运行中的快速优化。实验证明ULTHO在多个基准测试上以简单架构取得了优异性能，促进了高级自动化RL系统的发展。

> **摘要翻译:** 超参数优化（HPO）在机器学习中是一个价值数十亿美元的问题，它显著影响训练效率和模型性能。然而，由于其高度非平稳性和计算成本，在深度强化学习（RL）中实现高效且稳健的HPO一直充满挑战。为了解决这个问题，现有方法试图将常见的HPO技术（例如，基于种群的训练或贝叶斯优化）应用于RL场景。然而，它们仍然样本效率低下且计算成本高昂，这无法促进广泛的应用。在本文中，我们提出了ULTHO，一个超轻量级但功能强大的框架，用于在单次运行中快速进行深度RL中的HPO。具体来说，我们将HPO过程公式化为带有聚类臂的多臂老虎机（MABC），并将其直接与长期回报优化联系起来。ULTHO还提供了一种量化和统计的视角来高效过滤超参数。我们在ALE、Procgen、MiniGrid和PyBullet等基准测试上测试了ULTHO。大量的实验表明，ULTHO以简单的架构实现了卓越的性能，有助于开发先进和自动化的RL系统。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [183] [Dual Adaptivity: Universal Algorithms for Minimizing the Adaptive Regret of Convex Functions](https://arxiv.org/abs/2508.00392)
> *双重适应性：最小化凸函数自适应遗憾的通用算法*

*Lijun Zhang, Wenhao Yang, Guanghui Wang, Wei Jiang, Zhi-Hua Zhou* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 自适应遗憾, 在线凸优化, 通用算法, 元专家框架, 双重适应性

**Comment:** arXiv admin note: text overlap with arXiv:1906.10851

> **TL;DR:** 本文提出了一种双重自适应的元专家框架，用于在线凸优化，以解决现有算法在处理不同类型凸函数和变化环境时的通用性不足问题，实现了自适应遗憾的最小化。

**AI_Comments:** 本文提出了一个创新的元专家框架，通过“双重适应性”解决了在线凸优化中现有算法缺乏通用性的关键问题。其亮点在于能够同时适应函数类型和环境变化，这对于实际应用具有重要意义。理论分析也验证了其有效性，并将其推广到复合优化，展现了该方法的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的在线凸优化算法在处理不断变化的环境时，缺乏通用性，只能处理特定类型的凸函数，并且需要预先知道参数，这限制了它们在实际场景中的应用。

**Method:** 本文提出了一种具有双重适应性的元专家框架。该框架动态创建并聚合多个专家，其中元算法提供二阶边界以适应未知函数类型。通过引入休眠专家技术来适应变化的环境。为了实现通用性，采用了两种专家构建策略：增加专家数量或增强专家能力。

**Result:** 所提出的算法能够同时最小化多种类型凸函数的自适应遗憾，并且允许函数类型在不同轮次之间切换。此外，该元专家框架还被扩展到在线复合优化领域，并开发出一种用于最小化复合函数自适应遗憾的通用算法。

**Conclusion:** 本文提出的双重自适应通用算法克服了现有在线凸优化算法的局限性，实现了在未知函数类型和变化环境下的自适应遗憾最小化，并具有更广泛的适用性。

> **ai_Abstract:** 本文针对在线凸优化中现有算法通用性不足的问题，提出了一种名为“双重适应性”的通用算法。该算法通过一个元专家框架实现，能够自动适应不同类型的凸函数（凸、指数凹或强凸）以及环境的性质（平稳或变化）。通过动态创建和聚合专家，并结合二阶边界和休眠专家技术，所提出的算法能够同时最小化多种凸函数的自适应遗憾，并允许函数类型在回合之间切换。此外，该框架还被扩展到在线复合优化。

> **摘要翻译:** 为了应对不断变化的环境，在线学习中提出了一种新的性能度量——自适应遗憾，其定义为任何时间间隔内的最大静态遗憾。在在线凸优化的背景下，已经成功开发了几种算法来最小化自适应遗憾。然而，现有算法缺乏通用性，因为它们只能处理一种类型的凸函数，并且需要先验的参数知识，这阻碍了它们在现实世界场景中的应用。为了解决这一局限性，本文研究了具有双重适应性的通用算法，这些算法能自动适应函数的性质（凸、指数凹或强凸）以及环境的性质（平稳或变化）。具体来说，我们提出了一种用于双重自适应算法的元专家框架，其中动态创建多个专家并通过元算法进行聚合。元算法需要产生二阶边界，这可以适应未知的函数类型。我们进一步结合了休眠专家技术来捕捉变化的环境。对于专家的构建，我们引入了两种策略（增加专家数量或增强专家能力）以实现通用性。理论分析表明，我们的算法能够同时最小化多种类型凸函数的自适应遗憾，并且还允许函数类型在轮次之间切换。此外，我们将我们的元专家框架扩展到在线复合优化，并开发了一种用于最小化复合函数自适应遗憾的通用算法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [187] [A Simple and Effective Method for Uncertainty Quantification and OOD Detection](https://arxiv.org/abs/2508.00754)
> *一种简单有效的量化不确定性和OOD检测方法*

*Yaxin Ma, Benjamin Colburn, Jose C. Principe* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 不确定性量化, OOD检测, 特征空间密度, 核密度估计, 单个确定性模型

**Comment:** 

> **TL;DR:** 提出了一种基于特征空间密度的方法，利用单个确定性模型进行不确定性量化和OOD检测，计算成本低且性能优于基线模型。

**AI_Comments:** 该论文的创新点在于提出了一个计算成本低且存储需求小的替代方案，通过利用特征空间密度和信息势场，实现了不确定性量化和OOD检测。其重要性在于为实际应用提供了一种更高效、更实用的不确定性估计方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的贝叶斯神经网络和深度集成方法在量化不确定性时计算量大且需要大量存储。

**Method:** 该方法通过利用单个确定性模型，基于特征空间密度进行不确定性量化和OOD检测。具体来说，它利用从核密度估计导出的信息势场来近似训练集的特征空间密度，并通过比较该密度与测试样本的特征空间表示来确定分布偏移。

**Result:** 在二维合成数据集（Two Moons和Three Spirals）和OOD检测任务（CIFAR-10 vs. SVHN）上的实验结果表明，该方法优于基线模型。

**Conclusion:** 通过利用单个确定性模型和特征空间密度，该方法提供了一种简单有效的方式来量化不确定性并执行OOD检测，解决了现有方法的计算和存储问题，并表现出卓越的性能。

> **ai_Abstract:** 本文提出了一种简单有效的量化不确定性和离群点（OOD）检测方法，旨在解决现有贝叶斯神经网络和深度集成方法计算量大、存储需求高的问题。该方法利用单个确定性模型，通过核密度估计导出的信息势场近似训练集的特征空间密度，并与测试样本进行比较来检测分布偏移。实验结果表明，该方法在多个数据集上均优于基线模型。

> **摘要翻译:** 贝叶斯神经网络和深度集成方法已被提出用于量化不确定性；然而，它们计算密集且需要大量存储。通过利用单个确定性模型，我们可以解决上述问题。我们提出了一种基于特征空间密度的有效方法，用于量化分布偏移的不确定性和离群点（OOD）检测。具体来说，我们利用从核密度估计导出的信息势场来近似训练集的特征空间密度。通过将这种密度与测试样本的特征空间表示进行比较，我们可以有效地确定是否发生了分布偏移。实验在二维合成数据集（Two Moons和Three Spirals）以及OOD检测任务（CIFAR-10 vs. SVHN）上进行。结果表明，我们的方法优于基线模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [197] [Convergence of Implicit Gradient Descent for Training Two-Layer Physics-Informed Neural Networks](https://arxiv.org/abs/2407.02827)
> *用于训练两层物理信息神经网络的隐式梯度下降收敛性研究*

*Xianliang Xu, Ting Du, Wang Kong, Bin Shan, Ye Li, Zhongyi Huang* | **Category: cs.LG, math.OC** | **Updated: 2025-08-01**

**Keywords:** 隐式梯度下降, 物理信息神经网络, 收敛性分析, 过参数化

**Comment:** 

> **TL;DR:** 本文对训练过参数化两层物理信息神经网络的隐式梯度下降（IGD）的收敛性进行了理论分析，证明其能以线性收敛速度收敛到全局最优解，并且学习率的选择不受样本量和Gram矩阵最小特征值的影响。

**AI_Comments:** 本文的创新点在于对隐式梯度下降（IGD）在物理信息神经网络（PINNs）训练中的收敛性提供了严谨的理论分析。特别是，证明了IGD在过参数化条件下能达到全局最优解，并且其学习率的选择具有更大的灵活性，这对于实际应用中PINNs的优化具有重要意义。此外，提出的新分析方法放宽了对网络宽度的要求，可能有助于设计更高效的PINNs。

<details>
  <summary>Details</summary>

**Motivation:** 优化算法对物理信息神经网络（PINNs）的训练至关重要，不合适的算法可能导致较差的解决方案。相较于常见的梯度下降（GD）算法，隐式梯度下降（IGD）在处理某些多尺度问题上表现更优。本文旨在为IGD在训练过参数化两层PINNs时的收敛性提供理论分析。

**Method:** 本文首先推导了IGD在训练两层PINNs时的训练动态。然后，利用过参数化特性，证明了随机初始化的IGD能够以线性收敛速度收敛到全局最优解。此外，还提出了一种新的收敛分析方法，对网络宽度提出了更宽松的要求。最后，通过实证结果验证了理论发现。

**Result:** 研究结果表明，随机初始化的隐式梯度下降（IGD）能够以线性收敛速度收敛到全局最优解。由于IGD与GD独特的训练动态，其学习率的选择可以独立于样本大小和Gram矩阵的最小特征值。此外，本文提出的新颖收敛分析方法对网络宽度要求更宽松。经验结果也验证了理论发现。

**Conclusion:** 本文证明了隐式梯度下降（IGD）在训练过参数化两层物理信息神经网络（PINNs）时能够收敛到全局最优解，并具有线性收敛速度。IGD独特的训练动态使其学习率选择更灵活，且新的分析方法对网络宽度要求更低，为PINNs的优化提供了理论支持。

> **ai_Abstract:** 本文研究了隐式梯度下降（IGD）在训练过参数化两层物理信息神经网络（PINNs）时的收敛性。研究首先推导了IGD的训练动态，并利用过参数化证明了随机初始化的IGD能以线性速度收敛到全局最优解。与其他梯度下降方法相比，IGD的学习率选择不受样本量和Gram矩阵最小特征值的影响。此外，本文提出的收敛分析方法对网络宽度的要求更低。实验结果验证了理论发现。

> **摘要翻译:** 优化算法在训练物理信息神经网络（PINNs）中至关重要，因为不合适的算法可能导致较差的解决方案。与常见的梯度下降（GD）算法相比，隐式梯度下降（IGD）在处理某些多尺度问题上表现更优。在本文中，我们对IGD训练过参数化两层PINNs的收敛性进行了分析。我们首先推导了IGD在训练两层PINNs时的训练动态。然后，过参数化使我们能够证明随机初始化的IGD以线性收敛速度收敛到全局最优解。此外，由于IGD与GD独特的训练动态，学习率的选择可以独立于样本大小和Gram矩阵的最小特征值。另外，我们收敛分析中使用的新方法对网络宽度提出了更宽松的要求。最后，实证结果验证了我们的理论发现。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [200] [Sampling from Energy-based Policies using Diffusion](https://arxiv.org/abs/2410.01312)
> *使用扩散模型从基于能量的策略中采样*

*Vineet Jain, Tara Akhound-Sadegh, Siamak Ravanbakhsh* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** 强化学习, 基于能量的策略, 扩散模型, 多模态行为, 样本效率

**Comment:** 

> **TL;DR:** 提出了一种基于扩散模型的方法，用于从基于能量的策略中采样，从而在强化学习中实现更具表达力的多模态行为建模。

**AI_Comments:** 这篇论文通过将扩散模型引入基于能量的策略采样，为强化学习中的复杂行为建模提供了创新性的解决方案。它解决了传统方法在处理多模态动作分布时的局限性，有望在连续控制领域带来显著的性能提升和更丰富的行为学习能力。其核心创新在于利用扩散过程来有效处理高维、多模态的策略采样问题。

<details>
  <summary>Details</summary>

**Motivation:** 现有的最大熵强化学习方法在连续动作空间中直接从最优策略（玻尔兹曼分布）采样计算上不可行，导致通常使用高斯等简单参数分布，限制了其捕捉复杂多模态动作分布的能力。

**Method:** 引入了一种基于扩散模型的方法，用于从基于能量的策略中采样，其中负Q函数定义能量函数。在此基础上，提出了一种名为Diffusion Q-Sampling (DQS) 的actor-critic方法。

**Result:** 该方法提高了连续控制任务的样本效率，并能捕获多模态行为，解决了现有方法的关键局限性。

**Conclusion:** 该方法通过实现更具表达力的策略表示，使得在不同环境中能够稳定学习，并显著提升了样本效率和多模态行为的捕获能力。

> **ai_Abstract:** 本文提出了一种新颖的基于扩散模型的方法，用于解决最大熵强化学习中基于能量策略采样计算不可行的问题。通过将负Q函数定义为能量函数，并开发出Diffusion Q-Sampling (DQS) actor-critic方法，该研究实现了更具表达力的策略表示，从而在连续控制任务中提高了样本效率并成功捕获了复杂的多模态行为，克服了传统方法的局限性。

> **摘要翻译:** 基于能量的策略为强化学习（RL）中建模复杂、多模态行为提供了一个灵活的框架。在最大熵RL中，最优策略是源自软Q函数的玻尔兹曼分布，但在连续动作空间中直接从该分布采样在计算上是不可行的。因此，现有方法通常使用更简单的参数分布，如高斯分布，进行策略表示——这限制了它们捕捉多模态动作分布全部复杂性的能力。在本文中，我们引入了一种基于扩散的方法，用于从基于能量的策略中采样，其中负Q函数定义了能量函数。基于这种方法，我们提出了一种名为扩散Q采样（DQS）的actor-critic方法，该方法支持更具表达力的策略表示，从而在不同环境中实现稳定学习。我们展示了我们的方法提高了连续控制任务的样本效率并捕获了多模态行为，解决了现有方法的关键局限性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [215] [Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement](https://arxiv.org/abs/2508.00410)
> *Co-Reward：通过对比一致性实现大语言模型推理的自监督强化学习*

*Zizhuo Zhang, Jianing Zhu, Xinmu Ge, Zihua Zhao, Zhanke Zhou, Xuan Li, Xiao Feng, Jiangchao Yao, Bo Han* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 强化学习, 大语言模型, 自监督学习, 推理, 对比一致性

**Comment:** 

> **TL;DR:** Co-Reward是一种自监督强化学习框架，它利用语义相似问题之间的对比一致性作为奖励基础，以提高大语言模型的推理能力，并有效解决了传统自奖励方法的崩溃问题和人工标注的扩展性难题。

**AI_Comments:** Co-Reward的创新点在于其独特的自监督奖励机制，它通过引入对比一致性来解决自奖励方法中常见的崩溃问题，同时避免了对大量人工标注的依赖，从而提高了大语言模型在复杂推理任务上的可扩展性和稳定性。这种方法为LLM的自我改进提供了一条新的有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可验证奖励强化学习（RLVR）在提高大语言模型（LLMs）推理能力方面有前景，但由于对人工标注的依赖，尤其是在复杂任务上，面临扩展性困境。而探索各种自奖励信号的替代方案虽然展现了LLM推理的潜力，但存在不可忽视的崩溃问题。

**Method:** 本研究提出了Co-Reward，一个新颖的强化学习框架，它利用语义相似问题之间的对比一致性作为奖励基础。具体来说，对于每个训练样本（无标签），构建一个相似问题，并通过简单的rollout投票合成它们各自的代理标签。然后，通过交叉引用每对问题的标签来构建奖励，以强制模拟输入之间的内部推理一致性。这种自监督的奖励塑形机制增加了学习崩溃到琐碎解的难度，并通过扩展输入样本变体促进了稳定的推理启发和改进。

**Result:** Co-Reward在多个推理基准和LLM系列上，与其它自奖励基线相比，取得了卓越的性能。它达到甚至超越了真实（GT）标签奖励，在Llama-3.2-3B-Instruct上，MATH500任务比GT奖励提高了高达+6.8%。

**Conclusion:** Co-Reward通过利用对比一致性作为奖励基础，有效解决了大语言模型推理中自奖励方法的崩溃问题和人工标注的扩展性困境，并显著提升了LLMs的推理能力。

> **ai_Abstract:** 本文提出了Co-Reward，一种针对大语言模型（LLMs）推理的自监督强化学习框架。该框架通过构建语义相似问题对，并利用它们之间的对比一致性来生成奖励信号，从而克服了传统自奖励方法中常见的“崩溃”问题以及人工标注的扩展性限制。Co-Reward通过简单的rollout投票合成代理标签，并强制内部推理一致性。实验结果表明，Co-Reward在多个推理基准上优于其他自奖励基线，甚至在某些情况下超越了真实标注奖励，显著提升了LLMs的推理能力。

> **摘要翻译:** 尽管可验证奖励强化学习（RLVR）在提高大型语言模型（LLMs）的推理能力方面显示出前景，但由于对人工标注的依赖，尤其是在复杂任务上，扩展性困境依然存在。最近探索各种自奖励信号的替代方案展示了LLM推理的启发潜力，但却遭受了不可忽视的崩溃问题。受自监督学习成功的启发，我们提出了Co-Reward，一个新颖的强化学习框架，它利用语义相似问题之间的对比一致性作为奖励基础。具体来说，我们为每个训练样本（无标签）构建一个相似问题，并通过简单的rollout投票合成它们各自的代理标签，然后通过交叉引用每对问题的标签来构建奖励，以强制模拟输入之间的内部推理一致性。直观地，这种自监督的奖励塑形机制增加了学习崩溃到琐碎解的难度，并通过扩展输入样本变体促进了稳定的推理启发和改进。经验上，Co-Reward在多个推理基准和LLM系列上，与其它自奖励基线相比，取得了卓越的性能，并达到甚至超越了真实（GT）标签奖励，在Llama-3.2-3B-Instruct上，MATH500任务比GT奖励提高了高达+6.8%。我们的代码已在https://github.com/tmlr-group/Co-Reward 公开。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [221] [Data-driven tool wear prediction in milling, based on a process-integrated single-sensor approach](https://arxiv.org/abs/2412.19950)
> *基于过程集成单传感器方法的铣削刀具磨损数据驱动预测*

*Eric Hirsch, Christian Friedrich* | **Category: cs.LG, cs.RO, eess.SP** | **Updated: 2025-07-31**

**Keywords:** 刀具磨损预测, 数据驱动, 单传感器, 迁移学习, 深度学习

**Comment:** This work has been submitted to the IEEE Transactions on Automation
  Science and Engineering for possible publication. ,14 pages, 12 figures

> **TL;DR:** 本研究提出了一种基于单加速度传感器和迁移学习的数据驱动方法，用于在铣削中进行刀具磨损预测，即使在数据量有限的情况下也能实现高精度，特别是ConvNeXt模型表现出色。

**AI_Comments:** 本研究的创新点在于其“过程集成单传感器方法”，解决了工业环境中多传感器部署的实际挑战，并通过迁移学习实现了模型的泛化能力，即使在数据量有限的情况下也能保持高精度。ConvNeXt模型的出色表现证明了先进深度学习在解决实际工程问题中的潜力。这对于推动预测性维护在制造业中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确的刀具磨损预测对于保持加工生产率和最小化成本至关重要，但现有数据驱动方法通常依赖多传感器设置和大量数据，限制了泛化能力且在工业环境中不实用。

**Method:** 研究采用单加速度传感器建立低成本数据生成方法，通过迁移学习实现模型对不同加工过程的泛化。评估了多种机器学习模型（Transformer启发的CNN、LSTM、SVM、决策树），使用特征向量和STFT等输入格式。模型在两台机器和不同训练数据量（包括显著减少的数据集）下进行评估。

**Result:** 结果表明特定模型和配置能有效预测刀具磨损，有助于开发更具适应性和高效的预测性维护策略。ConvNeXt模型表现出色，仅使用来自四个铣刀的磨损数据，识别刀具磨损的准确率达到99.1%。

**Conclusion:** 本研究展示了使用单一传感器和有限数据进行数据驱动刀具磨损预测的潜力，特别是通过迁移学习和先进的深度学习模型，为加工中的预测性维护提供了更实用和可推广的解决方案。

> **ai_Abstract:** 本研究提出了一种数据驱动的铣削刀具磨损预测方法，旨在解决传统多传感器和大量数据依赖的局限性。通过采用单一加速度传感器建立低成本数据生成，并利用迁移学习，模型即使在有限训练数据下也能实现跨过程泛化。研究评估了多种机器学习模型，包括ConvNeXt，结果显示其在识别刀具磨损方面表现卓越，准确率高达99.1%，为加工中的预测性维护提供了实用且高效的策略。

> **摘要翻译:** 在加工中，准确的刀具磨损预测对于保持生产率和最小化成本至关重要。然而，刀具磨损过程的复杂性给实现可靠预测带来了重大挑战。本研究探索了数据驱动方法，特别是深度学习，用于刀具磨损预测。传统的数据驱动方法通常侧重于单一过程，依赖多传感器设置和大量数据生成，这限制了其在新环境中的泛化能力。此外，多传感器集成在工业环境中通常不切实际。为了解决这些限制，本研究调查了预测模型的可迁移性，使用了最少的训练数据，并在两个过程中进行了验证。此外，它使用一个简单的单加速度传感器设置来建立一种低成本的数据生成方法，通过迁移学习促进模型推广到其他过程。该研究评估了几种机器学习模型，包括受Transformer启发的卷积神经网络（CNN）、长短期记忆网络（LSTM）、支持向量机（SVM）和决策树，这些模型在不同输入格式（如特征向量和短时傅里叶变换（STFT））上进行训练。模型性能在两台机器和不同训练数据量（包括显著减少的数据集）下进行评估，从而深入了解它们在受限数据条件下的有效性。结果表明特定模型和配置在有效刀具磨损预测方面的潜力，有助于开发加工中更具适应性和高效的预测性维护策略。值得注意的是，ConvNeXt模型表现出色，仅使用来自四个铣刀的磨损数据，识别刀具磨损的准确率达到99.1%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [240] [Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM Framework for Post-Loan Default Detection](https://arxiv.org/abs/2508.00415)
> *信贷风险分析转型：一种时间序列驱动的ResE-BiLSTM框架用于贷后违约检测*

*Yue Yang, Yuxiang Lin, Ying Zhang, Zihan Su, Chang Chuan Goh, Tangtangfang Fang, Anthony Graham Bellotti, Boon Giin Lee* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 信用风险管理, 贷后违约检测, ResE-BiLSTM, 时间序列, 机器学习

**Comment:** 

> **TL;DR:** 本研究提出了一种名为ResE-BiLSTM的新模型，利用滑动窗口技术，用于改进贷后违约预测，并在大规模抵押贷款数据集上表现优于基线模型。

**AI_Comments:** 该论文提出了一种新颖的ResE-BiLSTM框架，用于贷后违约检测，其创新性在于结合了残差连接、注意力机制（推测E可能代表增强或嵌入）和双向LSTM来处理时间序列数据。通过在真实世界的大规模数据集上进行广泛评估，并与多种基线模型进行比较，证明了其优越性能，具有重要的实际应用价值。SHAP分析的引入也增强了模型的可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 贷后违约预测是信用风险管理中的一项重要任务，可以通过机器学习检测金融异常来解决。

**Method:** 本研究引入了ResE-BiLSTM模型，该模型使用滑动窗口技术。它在Freddie Mac美国抵押贷款数据集的44个独立队列上进行了评估，并与LSTM、BiLSTM、GRU、CNN和RNN等五种基线模型进行了比较，评估指标包括准确率、精确率、召回率、F1和AUC。此外，还进行了消融研究和SHAP分析。

**Result:** 实验结果表明，ResE-BiLSTM模型与基线模型相比，实现了卓越的预测性能。

**Conclusion:** ResE-BiLSTM模型在贷后违约检测方面表现出优越的预测性能，凸显了其在实际场景中的实用价值和适用性。

> **ai_Abstract:** 本研究针对信用风险管理中的贷后违约预测问题，提出了一种基于时间序列的ResE-BiLSTM模型。该模型利用滑动窗口技术，并在大规模Freddie Mac抵押贷款数据集上进行了广泛评估。实验结果表明，ResE-BiLSTM在准确率、精确率、召回率、F1和AUC等多个指标上均优于多种基线模型，并通过消融研究和SHAP分析验证了其组件贡献和特征解释能力，证实了其在实际应用中的有效性。

> **摘要翻译:** 贷后违约预测是信用风险管理中的一项重要任务，可以通过机器学习检测金融异常来解决。本研究引入了一种ResE-BiLSTM模型，该模型采用滑动窗口技术，并在庞大的房地美（Freddie Mac）美国抵押贷款数据集中的44个独立队列上进行了评估，以提高预测性能。ResE-BiLSTM模型与五种基线模型（长短期记忆网络（LSTM）、双向长短期记忆网络（BiLSTM）、门控循环单元（GRU）、卷积神经网络（CNN）和循环神经网络（RNN））在包括准确率、精确率、召回率、F1和AUC在内的多个指标上进行了比较。为了评估ResE-BiLSTM架构中各个组件的贡献，还进行了一项消融研究。此外，还采用了SHAP分析来解释模型赖以进行预测的底层特征。实验结果表明，与基线模型相比，ResE-BiLSTM实现了卓越的预测性能，强调了其在实际场景中的实用价值和适用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [241] [A comparative analysis of rank aggregation methods for the partial label ranking problem](https://arxiv.org/abs/2502.17077)
> *部分标签排序问题中排序聚合方法的比较分析*

*Jiayi Wang, Juan C. Alfaro, Viktor Bengs* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 排序聚合, 部分标签排序, 监督学习, 评分方法, 非参数概率

**Comment:** Full version of the paper accepted at ECAI 2025

> **TL;DR:** 本文比较分析了部分标签排序问题中多种排序聚合方法，发现基于评分的方法优于现有技术，而基于非参数概率的方法表现不佳。

**AI_Comments:** 本文的创新点在于系统地比较了多种替代的排序聚合方法，并特别关注了它们在部分标签排序问题中处理并列的能力。研究结果对于优化部分标签排序算法的最终预测步骤具有重要指导意义，强调了基于评分的方法的优越性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数部分标签排序问题学习方法在最终预测步骤中依赖于排序聚合的近似算法。本研究旨在探索替代的聚合方法以提高性能。

**Method:** 本文探讨了几种替代的排序聚合方法，包括基于评分的方法和基于非参数概率的方法。为了更适用于部分标签排序问题，这些方法被扩展以增加产生并列（ties）的可能性。

**Result:** 实验评估表明，在处理不完整信息时，基于评分的变体始终优于现有最先进的方法。相反，基于非参数概率的变体未能达到有竞争力的性能。

**Conclusion:** 在部分标签排序问题中，特别是处理不完整信息时，基于评分的排序聚合方法表现优异，而基于非参数概率的方法表现不佳。

> **ai_Abstract:** 本文针对部分标签排序问题，比较分析了多种排序聚合方法。研究探索了基于评分和基于非参数概率的聚合方法，并对其进行了扩展以更好地处理预测中的并列情况。实验结果表明，基于评分的方法在处理不完整信息时显著优于现有技术，而基于非参数概率的方法表现不佳。

> **摘要翻译:** 标签排序问题是一种监督学习场景，学习器为给定的输入实例预测类别标签的完整顺序。最近，研究日益关注部分标签排序问题，它是标签排序问题的一种泛化，允许预测顺序中出现并列。到目前为止，大多数现有的部分标签排序问题学习方法在最终预测步骤中依赖于排序聚合的近似算法。本文探讨了针对这一关键步骤的几种替代聚合方法，包括基于评分的方法和基于非参数概率的排序聚合方法。为了增强它们对更一般的偏标签排序问题的适用性，所研究的方法被扩展以增加产生并列的可能性。在标准基准上的实验评估表明，基于评分的变体在处理不完整信息方面始终优于现有最先进的方法。相比之下，基于非参数概率的变体未能获得有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [257] [PATH: A Discrete-sequence Dataset for Evaluating Online Unsupervised Anomaly Detection Approaches for Multivariate Time Series](https://arxiv.org/abs/2411.13951)
> *PATH：一个用于评估多变量时间序列在线无监督异常检测方法的离散序列数据集*

*Lucas Correia, Jan-Christoph Goos, Thomas Bäck, Anna V. Kononova* | **Category: cs.LG, cs.AI, cs.CE, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** 异常检测, 多变量时间序列, 数据集, 离散序列, 无监督学习

**Comment:** Submitted to the Big Data Research journal

> **TL;DR:** 该论文提出了一个名为PATH的新型高质量离散序列数据集，用于评估多变量时间序列的在线无监督异常检测方法，旨在解决现有数据集的不足。

**AI_Comments:** 这项工作通过提供一个高质量、大规模且多样化的离散序列数据集PATH，解决了多变量时间序列异常检测领域长期存在的数据集不足问题。其创新之处在于模拟真实汽车动力系统行为，并专门针对离散序列问题。该数据集的发布有望推动该领域的可衡量进展，并为未来的研究提供宝贵的基准。论文还通过基线实验揭示了当前方法在处理受污染数据和阈值选择方面的局限性，指明了未来研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有公开数据集太小、缺乏多样性且异常值过于简单，阻碍了多变量时间序列异常检测领域的可衡量进展。

**Method:** 提出并生成了一个名为PATH的、通过最先进模拟工具生成的、反映汽车动力系统真实行为的多元、动态、可变状态的离散序列数据集。该数据集提供不同版本，以适应无监督和半监督异常检测设置，以及时间序列生成和预测。同时，提供了基于确定性变分自编码器、变分自编码器和非参数方法的基线结果。

**Result:** 基线实验表明，在半监督版本数据集上训练的方法优于其无监督对应方法，这突出表明需要更强大的方法来处理受污染的训练数据。此外，结果显示所使用的阈值对检测性能有很大影响。

**Conclusion:** 需要开发对受污染训练数据更鲁棒的异常检测方法。同时，需要更多工作投入到无需标签数据即可找到合适阈值的方法中。

> **ai_Abstract:** 该论文针对多变量时间序列异常检测领域缺乏高质量数据集的问题，提出了一个名为PATH的离散序列数据集。该数据集通过先进模拟工具生成，具有多样性、广泛性和非平凡性，并反映了汽车动力系统的真实行为，特别是解决了离散序列问题。为支持不同任务，数据集提供多种版本，包括受污染和干净的训练/测试子集。研究还提供了基线结果，表明半监督方法优于无监督方法，并强调了开发更鲁棒的异常检测方法和无需标签数据寻找合适阈值方法的重要性。

> **摘要翻译:** 基准测试多变量时间序列的异常检测方法是一项具有挑战性的任务，因为缺乏高质量的数据集。当前公开可用的数据集太小，不够多样化，并且具有微不足道的异常，这阻碍了该研究领域的可衡量进展。我们提出了一种解决方案：一个多样化、广泛且非平凡的数据集，通过最先进的模拟工具生成，反映了汽车动力系统的真实行为，包括其多变量、动态和可变状态特性。此外，我们的数据集代表了一个离散序列问题，这在文献中先前提出的解决方案中仍未得到解决。为了满足无监督和半监督异常检测设置，以及时间序列生成和预测的需求，我们提供了不同版本的数据集，其中训练和测试子集根据任务提供受污染和干净的版本。我们还提供了基于确定性变分自编码器、变分自编码器以及非参数方法选择的基线结果。正如预期，基线实验表明，在半监督版本数据集上训练的方法优于其无监督对应方法，突出表明需要更强大的方法来处理受污染的训练数据。此外，结果显示所使用的阈值对检测性能有很大影响，因此需要投入更多工作来寻找无需标记数据即可找到合适阈值的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [261] [Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation](https://arxiv.org/abs/2503.10845)
> *Panopticon：推动地球观测的任意传感器基础模型*

*Leonard Waldmann, Ando Shah, Yi Wang, Nils Lehmann, Adam J. Stewart, Zhitong Xiong, Xiao Xiang Zhu, Stefan Bauer, John Chuang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 地球观测, 任意传感器, 基础模型, Panopticon, DINOv2

**Comment:** First two authors contributed equally. Code is available at:
  https://github.com/Panopticon-FM/panopticon. Accepted to CVPR 2025

> **TL;DR:** Panopticon是一个基于DINOv2的任意传感器基础模型，通过特定扩展处理多源地球观测数据，并在GEO-Bench上实现了最先进的性能，促进了传感器无关的地球观测。

**AI_Comments:** Panopticon在处理地球观测数据多样性方面具有重要创新，通过构建任意传感器基础模型，解决了传统方法依赖固定传感器的局限性。其基于DINOv2的扩展方法，特别是利用地理位置作为增强、通道子采样和跨通道注意力，为多模态、多光谱遥感数据处理提供了通用且灵活的框架，对未来EO领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 地球观测(EO)数据具有多样的传感平台，包含不同的光谱波段、空间分辨率和传感模态。然而，大多数现有工作将输入限制在固定传感器上，这与EO数据的多样性不符，因此需要能够处理任意传感器的新型基础模型。

**Method:** 本文提出了Panopticon，一个基于DINOv2框架构建的任意传感器基础模型。该模型通过以下方式扩展DINOv2：1) 将来自不同传感器的相同地理位置图像视为自然增强；2) 对通道进行子采样以多样化光谱输入；3) 添加跨通道注意力作为灵活的补丁嵌入机制。通过分别编码光学和合成孔径雷达传感器的波长和模式，Panopticon能够有效处理任意通道的任意组合。

**Result:** 在广泛的评估中，Panopticon在GEO-Bench上取得了最先进的性能，尤其是在广泛使用的Sentinel-1和Sentinel-2传感器上。它还超越了其他任意传感器模型以及在独特传感器配置上的域适应固定传感器模型。

**Conclusion:** Panopticon能够立即推广到现有和未来的卫星平台，从而推进了传感器无关的地球观测。

> **ai_Abstract:** Panopticon是一个为地球观测(EO)数据设计的任意传感器基础模型，它通过扩展DINOv2框架来处理来自不同传感器的多样化数据。该模型创新性地将跨传感器地理位置图像视为增强，并引入通道子采样和跨通道注意力机制，以灵活处理任意光谱和模态组合。Panopticon在GEO-Bench上展现了最先进的性能，尤其在Sentinel-1和Sentinel-2传感器上表现出色，并优于其他任意传感器及域适应模型，实现了对现有和未来卫星平台的即时泛化，推动了传感器无关的EO发展。

> **摘要翻译:** 地球观测（EO）数据具有多样化的传感平台，其光谱波段、空间分辨率和传感模态各不相同。尽管大多数现有工作将输入限制在固定传感器上，但一类能够处理任意传感器的新型任意传感器基础模型最近已经出现。为了促进这项工作，我们提出了Panopticon，一个基于DINOv2框架构建的任意传感器基础模型。我们通过以下方式扩展DINOv2：(1) 将来自不同传感器的相同地理位置图像视为自然增强；(2) 对通道进行子采样以多样化光谱输入；(3) 添加跨通道注意力作为灵活的补丁嵌入机制。通过分别编码光学和合成孔径雷达传感器的波长和模式，Panopticon可以有效地处理任意通道的任意组合。在广泛的评估中，我们在GEO-Bench上取得了最先进的性能，尤其是在广泛使用的Sentinel-1和Sentinel-2传感器上，同时超越了其他任意传感器模型以及在独特传感器配置上的域适应固定传感器模型。Panopticon能够立即推广到现有和未来的卫星平台，推进了传感器无关的地球观测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [265] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
> *一种用于表格数据生成的条件GAN，带有潜在子空间的概率采样*

*Leonidas Akritidis, Panayiotis Bozanis* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 条件GAN, 表格数据生成, 类别不平衡, 潜在子空间, 概率采样

**Comment:** 

> **TL;DR:** ctdGAN是一种条件GAN，通过空间划分、概率采样和新的损失函数，解决表格数据中的类别不平衡问题，生成高质量样本并提高分类精度。

**AI_Comments:** ctdGAN的创新之处在于其对表格数据潜在子空间的考量，通过空间划分和概率采样策略，解决了传统GAN在表格数据生成中未能有效处理数据分布子空间和条件采样效率低下的问题。其引入的惩罚聚类和类别误预测的损失函数以及聚类缩放技术，进一步提升了生成样本的保真度和多样性。这项工作对于处理不平衡表格数据具有重要意义，尤其是在需要合成高质量数据以改进机器学习模型性能的场景中。

<details>
  <summary>Details</summary>

**Motivation:** 表格数据普遍存在类别不平衡问题，这严重降低了机器学习任务的性能。尽管生成对抗网络（GANs）能有效合成欠表示类别的数据，但现有GAN模型未能考虑输入样本的向量子空间，导致数据生成位置随意，且类别标签被视作普通类别变量，使得条件采样效果不佳。

**Method:** 本研究提出了ctdGAN，一个用于缓解表格数据集中类别不平衡的条件GAN。它首先执行空间划分步骤，为输入样本分配聚类标签。随后，利用这些标签，通过一种新颖的概率采样策略和一种新的损失函数（惩罚聚类和类别误预测）来合成样本。ctdGAN旨在生成与原始数据分布子空间相似的样本。此外，它还引入了其他改进，包括一种简单有效的聚类缩放技术，可在不影响数据维度的前提下捕获多种特征模式。

**Result:** 对14个不平衡数据集进行详尽评估，结果表明ctdGAN在生成高保真样本和提高分类精度方面表现出卓越性能。

**Conclusion:** ctdGAN通过考虑数据子空间和引入新的采样及损失机制，有效地解决了表格数据中的类别不平衡问题，并显著提升了生成样本的质量和分类模型的性能。

> **ai_Abstract:** 本文提出了一种名为ctdGAN的条件生成对抗网络，旨在解决表格数据中的类别不平衡问题。ctdGAN通过引入空间划分、概率采样策略以及新的损失函数，使得生成的样本能够更好地反映原始数据的潜在子空间分布。此外，它还包含一种聚类缩放技术以捕获多模态特征。实验证明，ctdGAN在生成高质量样本和提升分类准确性方面表现优异。

> **摘要翻译:** 表格形式构成了关系数据库系统和电子表格中数据表示的标准方式。但是，与其他形式类似，表格数据也存在类别不平衡问题，这个问题会导致各种机器学习任务的性能严重下降。最有效的解决方案之一是使用生成对抗网络（GANs）来合成欠表示类别的 L 人工数据实例。尽管它们表现良好，但所提出的GAN模型都没有考虑真实数据空间中输入样本的向量子空间，导致在任意位置生成数据。此外，在训练过程中，类别标签被视为与其他类别变量相同的方式处理，因此按类别进行的条件采样效果不佳。为了克服这些问题，本研究提出了ctdGAN，一个用于缓解表格数据集中类别不平衡的条件GAN。最初，ctdGAN执行一个空间划分步骤，为输入样本分配聚类标签。随后，它利用这些标签通过一种新颖的概率采样策略和一种新的损失函数来合成样本，该损失函数惩罚聚类和类别的错误预测。通过这种方式，ctdGAN被训练以在类似于原始数据分布的子空间中生成样本。我们还引入了其他几项改进，包括一种简单但有效的聚类缩放技术，可以在不影响数据维度的前提下捕获多种特征模式。对ctdGAN在14个不平衡数据集上的详尽评估表明，它在生成高保真样本和提高分类精度方面具有优越性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [280] [Decision by Supervised Learning with Deep Ensembles: A Practical Framework for Robust Portfolio Optimization](https://arxiv.org/abs/2503.13544)
> *基于深度集成监督学习的决策：鲁棒投资组合优化的实用框架*

*Juhyeong Kim, Sungyoon Choi, Youngbin Lee, Yejin Kim, Yongmin Choi, Yongjae Lee* | **Category: cs.LG, q-fin.CP, q-fin.PM** | **Updated: 2025-08-01**

**Keywords:** 投资组合优化, 监督学习, 深度集成, 鲁棒性, 机器学习

**Comment:** 8 pages, 3 figures

> **TL;DR:** 本文提出DSL框架，通过将投资组合构建重构为监督学习问题并结合深度集成方法，实现鲁棒的投资组合优化，表现优于传统和现有机器学习方法。

**AI_Comments:** 本文的创新点在于将复杂的投资组合优化问题巧妙地重构为监督学习任务，并引入深度集成方法显著提升了模型的鲁棒性和预测稳定性，这对于金融领域尤其重要。其在多样化市场环境下的优异表现和代码开源性也增加了其实用价值和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决鲁棒投资组合优化问题，并通过提高稳定性和可靠性来增强投资组合分配。

**Method:** 提出决策监督学习（DSL）框架，将投资组合构建重构为监督学习问题，训练模型预测最优投资组合权重，使用交叉熵损失，并通过最大化夏普比率或索蒂诺比率构建投资组合。为增强稳定性和可靠性，采用深度集成方法显著降低投资组合分配的方差。

**Result:** 在不同市场环境和神经网络架构下的全面回测显示，DSL框架的性能优于传统策略和包括预测聚焦学习、端到端学习在内的领先机器学习方法。研究表明，增加集成规模可带来更高的中位数回报和更稳定的风险调整表现。

**Conclusion:** 提出的DSL框架，特别是结合深度集成方法，为鲁棒投资组合优化提供了一个实用且表现卓越的解决方案，能够实现更高的回报和更稳定的风险调整性能。

> **ai_Abstract:** 本文提出了一个名为“基于监督学习的决策”（DSL）的鲁棒投资组合优化框架。该框架将投资组合构建视为一个监督学习问题，通过训练模型预测最优权重，并利用深度集成方法提高稳定性和降低方差。回测结果表明，DSL在性能上超越了传统方法和现有机器学习方法，且增加集成规模能提升回报和稳定性。

> **摘要翻译:** 我们提出“基于监督学习的决策”（DSL），一个用于鲁棒投资组合优化的实用框架。DSL将投资组合构建重构为一个监督学习问题：模型被训练来预测最优投资组合权重，使用交叉熵损失以及通过最大化夏普比率或索蒂诺比率构建的投资组合。为了进一步增强稳定性和可靠性，DSL采用了深度集成方法，显著降低了投资组合分配的方差。通过在不同市场环境和神经网络架构下的全面回测，结果显示其性能优于传统策略和领先的基于机器学习的方法，包括预测聚焦学习和端到端学习。我们表明，增加集成规模可以带来更高的中位数回报和更稳定的风险调整表现。代码可在https://github.com/DSLwDE/DSLwDE获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [285] [Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection](https://arxiv.org/abs/2508.00507)
> *LLM法庭：通过多LLM协作进行证据增强生成以实现文本属性图异常检测*

*Yiming Xu, Jiarun Chen, Zhen Peng, Zihan Chen, Qika Lin, Lan Ma, Bin Shi, Bo Dong* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 文本属性图, 异常检测, 大型语言模型, 图神经网络, 多LLM协作

**Comment:** Accepted by ACM Multimedia 2025 (MM '25)

> **TL;DR:** CoLL是一个结合LLMs和GNNs的新颖框架，用于文本属性图异常检测，通过多LLM协作和证据增强生成，显著提升了检测性能。

**AI_Comments:** 创新点在于CoLL框架有效地结合了LLM的语义理解能力和GNN处理结构信息的优势，特别是在文本属性图异常检测领域。多LLM协作进行证据增强生成和提供人类可读理由是其独特之处。其重要性体现在解决了现有GAD方法对文本模态利用不足的问题，并通过显著的性能提升（AP平均提高13.37%）证明了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本属性图（TAGs）异常检测方法主要关注图结构，忽视文本模态的互补价值，或使用浅层嵌入技术导致语义信息丢失。大型语言模型（LLMs）虽有强大语义理解能力，但应用于TAG异常检测仍处于早期阶段，且难以编码高阶图结构信息。因此，需要一种方法来有效结合文本和结构信息以实现高质量的TAG异常检测。

**Method:** 本文提出了CoLL框架，该框架结合了大型语言模型（LLMs）和图神经网络（GNNs）。CoLL利用多LLM协作进行证据增强生成，以捕获与异常相关的上下文并提供可读的异常理由。此外，CoLL集成了一个带有门控机制的GNN，以自适应地融合文本特征和证据，同时保留高阶拓扑信息。

**Result:** 广泛的实验表明CoLL的优越性，平均AP（平均精度）提高了13.37%。

**Conclusion:** 这项研究为将大型语言模型（LLMs）纳入推进图异常检测（GAD）开辟了新的途径。

> **ai_Abstract:** 本文提出CoLL，一个针对文本属性图（TAGs）异常检测的新颖框架，旨在解决现有方法忽略文本模态或LLM难以处理高阶图结构的问题。CoLL结合了多LLM协作进行证据增强生成以捕捉语义上下文并提供可读理由，同时利用带门控机制的GNN融合文本特征并保留拓扑信息。实验证明CoLL显著提升了异常检测性能，为LLM在图异常检测中的应用开辟了新方向。

> **摘要翻译:** 文本属性图（TAGs）中复杂的拓扑结构和丰富的文本信息的自然结合为图异常检测（GAD）开辟了新的视角。然而，现有的GAD方法主要侧重于在图领域内设计复杂的优化目标，忽视了文本模态的互补价值，其特征通常通过浅层嵌入技术（如词袋或skip-gram）编码，因此可能会遗漏与异常相关的语义上下文。为了释放文本模态的巨大潜力，大型语言模型（LLMs）因其强大的语义理解和推理能力而成为有前景的替代方案。然而，它们在TAG异常检测中的应用仍处于萌芽阶段，并且由于输入长度限制，它们难以编码图中固有的高阶结构信息。为了在TAG中实现高质量的异常检测，我们提出了CoLL，一个结合LLM和图神经网络（GNNs）的新颖框架，以利用它们的互补优势。CoLL采用多LLM协作进行证据增强生成，以捕获与异常相关的上下文，同时为检测到的异常提供人类可读的理由。此外，CoLL集成了一个配备门控机制的GNN，以自适应地将文本特征与证据融合，同时保留高阶拓扑信息。广泛的实验表明CoLL的优越性，平均AP提高了13.37%。这项研究为将LLM纳入推进GAD开辟了新途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [301] [Directional Sign Loss: A Topology-Preserving Loss Function that Approximates the Sign of Finite Differences](https://arxiv.org/abs/2504.04202)
> *方向符号损失：一种近似有限差分符号的拓扑保持损失函数*

*Harvey Dam, Tripti Agarwal, Ganesh Gopalakrishnan* | **Category: cs.LG, I.2.6** | **Updated: 2025-07-31**

**Keywords:** 拓扑特征保留, 方向符号损失, 可微分损失函数, 表示学习, 有限差分

**Comment:** 

> **TL;DR:** 本文提出了一种名为方向符号损失（DSL）的新型可微分损失函数，旨在解决表示学习中保留拓扑特征的挑战。

**AI_Comments:** 这篇论文的创新点在于提出了一个可微分的、拓扑保持的损失函数DSL，它克服了现有拓扑度量不可微分的限制。这使得在基于梯度的深度学习框架中直接优化拓扑特征成为可能，从而扩展了拓扑特征保留的应用范围，特别是对于大规模和复杂的数据。其重要性在于为拓扑敏感数据的表示学习提供了一个新的有效工具。

<details>
  <summary>Details</summary>

**Motivation:** 在学习到的潜在空间中保留拓扑特征是表示学习中的一个基本挑战，特别是对于拓扑敏感数据。

**Method:** 本文引入了方向符号损失（DSL），这是一种高效、可微分的损失函数，用于近似两个数组对应元素之间有限差分符号不匹配的数量。通过惩罚输入和重建数据之间关键点的不一致，DSL鼓励自编码器和其他可学习压缩器保留原始数据的拓扑特征。

**Result:** 对多维数组数据的实验表明，将DSL与传统损失函数结合使用比单独使用传统损失函数能更有效地保留拓扑特征。

**Conclusion:** DSL作为常见基于拓扑度量的可微分、高效代理，使得在以前不切实际的问题规模和更广泛的基于梯度的优化框架中实现拓扑特征保留成为可能。

> **ai_Abstract:** 本文提出了一种名为方向符号损失（DSL）的新型可微分损失函数，旨在解决表示学习中保留拓扑特征的挑战。DSL通过近似有限差分符号不匹配的数量来惩罚输入和重建数据之间关键点的不一致，从而帮助自编码器等模型保留数据的拓扑结构。实验证明，结合DSL能比单独使用传统损失函数更有效地保持拓扑特征，使其适用于大规模问题和梯度优化框架。

> **摘要翻译:** 在学习到的潜在空间中保留拓扑特征是表示学习中的一个基本挑战，特别是对于拓扑敏感数据。本文引入了方向符号损失（DSL），这是一种高效、可微分的损失函数，用于近似两个数组对应元素之间有限差分符号不匹配的数量。通过惩罚输入和重建数据之间关键点的不一致，DSL鼓励自编码器和其他可学习压缩器保留原始数据的拓扑特征。我们介绍了DSL的公式和复杂度分析，并将其与其他不可微分的拓扑度量进行了比较。对多维数组数据的实验表明，将DSL与传统损失函数结合使用比单独使用传统损失函数能更有效地保留拓扑特征。DSL作为常见基于拓扑度量的可微分、高效代理，使得在以前不切实际的问题规模和更广泛的基于梯度的优化框架中实现拓扑特征保留成为可能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [305] [Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and Uni-Modal Contrastive Learning](https://arxiv.org/abs/2508.00513)
> *基于多尺度跨模态和单模态对比学习的文本属性图异常检测*

*Yiming Xu, Xu Hua, Zhen Peng, Bin Shi, Jiarun Chen, Xingbo Fu, Song Wang, Bo Dong* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 文本属性图异常检测, 对比学习, 跨模态学习, 图神经网络, 异常检测

**Comment:** Accepted by ECAI 2025

> **TL;DR:** 本文提出了一种新的端到端范式CMUCL，用于文本属性图异常检测。它通过同时建模文本和图结构，并利用跨模态和单模态多尺度一致性来共同训练编码器，从而显著提高了检测精度，并发布了8个新的基准数据集。

**AI_Comments:** 该论文的主要创新点在于提出了一个端到端的文本属性图异常检测范式CMUCL，它通过跨模态和单模态对比学习，将文本特征提取与图异常检测目标紧密结合，有效解决了现有方法中文本信息利用不足的问题。其引入的多尺度一致性学习有助于更全面地捕捉异常信息。此外，发布新的基准数据集对推动该领域的研究具有重要意义。该工作在理论和实践上都取得了显著进展。

<details>
  <summary>Details</summary>

**Motivation:** 图数据在各种高风险场景中的广泛应用使得图异常检测（GAD）受到越来越多的关注。现有方法在处理带有原始文本序列的文本属性图（TAGs）时，通常将文本编码与图域的异常检测训练目标分离，导致提取的文本特征难以专注于与GAD相关的信息，从而严重限制了检测能力。因此，如何无缝整合原始文本和图拓扑以发挥跨模态数据在TAGs中用于异常检测的巨大潜力是一个具有挑战性的问题。

**Method:** 本文提出了一种名为CMUCL的文本属性图异常检测的端到端新范式。CMUCL同时对文本和图结构数据进行建模，并通过利用跨模态和单模态多尺度一致性来联合训练文本和图编码器，以发现潜在的异常相关信息。此外，它设计了一个基于不一致性挖掘的异常分数估计器来推导节点特定的异常分数。考虑到TAGs上异常检测专用基准数据集的缺乏，作者发布了8个数据集以促进未来的研究。

**Result:** 广泛的评估表明，CMUCL在文本属性图异常检测方面取得了显著进展，比次优方法平均准确率（AP）提高了11.13%。

**Conclusion:** 本文提出的CMUCL模型通过其端到端的多尺度跨模态和单模态对比学习方法，有效解决了文本属性图异常检测中文本信息利用不足的问题，并在检测性能上取得了显著提升。同时，发布的新数据集将为该领域的未来研究提供重要支持。

> **ai_Abstract:** 本文针对文本属性图（TAGs）异常检测中现有方法文本特征与图域异常检测目标分离的问题，提出了一种名为CMUCL的端到端新范式。CMUCL通过同时建模文本和图结构数据，并利用多尺度跨模态和单模态对比学习来共同训练文本和图编码器，以发现异常相关信息。它还设计了一个基于不一致性挖掘的异常分数估计器。为解决基准数据集缺乏的问题，本文发布了8个新的TAGs异常检测数据集。实验结果表明，CMUCL在检测精度上显著优于现有方法，平均AP提高了11.13%。

> **摘要翻译:** 图数据在各种高风险场景中的广泛应用增加了对图异常检测（GAD）的关注。面对通常以原始文本序列形式携带节点描述的真实世界图，即文本属性图（TAGs），现有的图异常检测流程通常涉及浅层嵌入技术来编码此类文本信息为特征，然后依赖于图域内复杂的自监督任务来检测异常。然而，这种文本编码过程与图域中的异常检测训练目标是分离的，这使得难以确保提取的文本特征专注于与GAD相关的信息，严重限制了检测能力。如何无缝整合原始文本和图拓扑以释放TAGs中跨模态数据在异常检测中的巨大潜力，提出了一个具有挑战性的问题。本文提出了一种用于文本属性图异常检测的新型端到端范式，名为CMUCL。我们同时对来自文本和图结构的数据进行建模，并通过利用跨模态和单模态多尺度一致性来联合训练文本和图编码器，以发现潜在的异常相关信息。相应地，我们设计了一个基于不一致性挖掘的异常分数估计器来推导节点特定的异常分数。考虑到缺乏专门为TAGs上异常检测定制的基准数据集，我们发布了8个数据集以促进未来的研究。广泛的评估表明，CMUCL在文本属性图异常检测方面取得了显著进展，比次优方法平均准确率（AP）提高了11.13%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [308] [Calibrated Language Models and How to Find Them with Label Smoothing](https://arxiv.org/abs/2508.00264)
> *校准语言模型及其标签平滑寻找方法*

*Jerry Huang, Peng Lu, Qiuhao Zeng* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 语言模型, 校准, 标签平滑, 指令微调, 大型词汇LLM

**Comment:** Accepted to the Forty-second International Conference on Machine
  Learning (ICML) 2025. First two authors contributed equally

> **TL;DR:** 大型语言模型在指令微调后出现校准退化；标签平滑可缓解此问题，但对大型词汇LLM效果有限；提出定制内核以优化标签平滑的内存消耗。

**AI_Comments:** 该论文解决了LLM部署中一个关键的实际问题：指令微调后的置信度校准。发现标签平滑有助于解决这一问题具有重要意义，而识别出大型词汇LLM（LV-LLMs）作为挑战案例则提供了宝贵的见解。为内存优化设计的定制内核是一项实用的工程贡献，使标签平滑在大模型中的应用更具可行性。对LV-LLM问题进行理论和实验论证增加了论文的深度。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言处理的最新进展使得微调大型语言模型（LLMs）能够更好地遵循指令，成为更强大的交互式代理。然而，模型输出的置信度校准（可靠性）如何受此影响尚未得到充分研究，且已发现显著的校准退化，因此需要寻找实用的解决方案。

**Method:** 研究检查了各种开源LLM在指令微调后的校准退化情况。提出标签平滑作为一种解决方案，并从理论和实验上解释其在SFT过程中保持校准的有效性。分析了标签平滑在大型词汇LLM（LV-LLMs）中效果减弱的原因，认为与过度自信、隐藏层大小和词汇量大小有关。设计了一个定制内核以显著减少标签平滑损失计算中的交叉熵损失内存占用。

**Result:** 在各种开源LLM中，指令微调后均发现显著的校准退化。标签平滑足以在监督微调（SFT）过程中保持校准。然而，在大型词汇LLM（LV-LLMs）中，标签平滑的有效性严重降低，这源于与隐藏层大小和词汇量大小直接相关的过度自信能力。定制内核显著降低了标签平滑损失计算的内存消耗，且不牺牲速度或性能。

**Conclusion:** 指令微调会导致大型语言模型校准退化，标签平滑是一种有效的缓解方法。然而，对于大型词汇LLM，由于过度自信的问题，标签平滑的效果会受到限制。此外，通过设计定制内核可以解决标签平滑损失计算中的内存效率问题。

> **ai_Abstract:** 这篇论文研究了大型语言模型（LLMs）在指令微调后出现的置信度校准退化问题。作者发现标签平滑可以有效缓解这一问题，但在大型词汇LLMs（LV-LLMs）中其效果会显著减弱，这与模型的隐藏层大小和词汇量大小导致的过度自信有关。为了解决标签平滑损失计算中的内存消耗问题，论文还设计了一个定制的内核，显著降低了内存占用。

> **摘要翻译:** 自然语言处理（NLP）的最新进展为通过改进指令遵循能力使微调大型语言模型（LLMs）成为更强大的交互式代理提供了更大的机会。然而，理解这如何影响置信度校准以实现可靠的模型输出尚未得到充分研究。在这项工作中，我们检查了各种开源LLM，发现每个模型在指令微调后都存在显著的校准退化。为了寻找实用的解决方案，我们转向标签平滑，它已被证明是正则化过度自信预测的有效方法，但尚未在LLM的监督微调（SFT）中广泛采用。我们首先深入探讨了为什么标签平滑足以在整个SFT过程中保持校准。然而，在某些情况下，平滑的有效性会严重降低，特别是对于大型词汇LLM（LV-LLMs）。我们认为其原因源于过度自信的能力，这与隐藏层大小和词汇量大小有直接关系，并从理论和实验上证明了这一点。最后，我们解决了标签平滑损失设置中交叉熵损失计算内存占用方面的一个突出问题，设计了一个定制的内核，与现有非平滑损失的解决方案相比，在不牺牲速度或性能的情况下，显著降低了内存消耗。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [321] [Adapting to the Unknown: Robust Meta-Learning for Zero-Shot Financial Time Series Forecasting](https://arxiv.org/abs/2504.09664)
> *适应未知：零样本金融时间序列预测的鲁棒元学习*

*Anxian Liu, Junying Ma, Guang Zhang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 元学习, 零样本预测, 金融时间序列, 高斯混合模型, 任务构建

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的元任务构建方法，利用高斯混合模型（GMMs）对学习到的嵌入进行软聚类，从而创建互补的簇内和簇间任务，以提高零样本金融时间序列预测在高度波动市场中的鲁棒性和泛化能力。

**AI_Comments:** 该论文的创新点在于提出了基于GMMs的元任务构建策略，通过软聚类嵌入来生成多样化的簇内和簇间任务，从而有效地解决了零样本金融时间序列预测中高波动数据的挑战。这种方法增强了模型的适应性和泛化能力，对于金融领域的实际应用具有重要意义。通过结合概率性分配和硬任务挖掘，模型能够更好地捕捉市场复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 在零样本设置下，金融时间序列预测对于投资决策至关重要，尤其是在市场剧烈变化或新兴市场数据有限的情况下。现有的模型无关元学习（MAML）方法在处理高度波动的金融序列时，其元任务构建策略表现不佳，导致次优性能。

**Method:** 本文提出了一种新颖的任务构建方法，利用学习到的嵌入进行元任务和下游预测，从而实现有效的零样本元学习。具体而言，该方法使用高斯混合模型（GMMs）对嵌入进行软聚类，构建两种互补的元任务类型：簇内任务和簇间任务。通过概率性地将嵌入分配给多个潜在状态，GMMs实现了更丰富、更多样化的元学习。此外，该方法通过硬任务挖掘增强了簇间泛化能力，以识别不同市场状态下的鲁棒模式。

**Result:** 该方法在真实世界的高波动金融数据和多个国际市场（包括新兴市场）中进行了验证。结果表明，与现有方法相比，该方法表现出显著的优越性能，并在零样本场景中具有更强的泛化能力。

**Conclusion:** 本文提出的基于GMMs的元任务构建方法，通过软聚类嵌入并创建簇内和簇间任务，显著提高了零样本金融时间序列预测在复杂市场环境下的性能和泛化能力，有效解决了现有方法在处理高波动金融数据时的局限性。

> **ai_Abstract:** 本文提出了一种针对零样本金融时间序列预测的新型元学习方法，旨在解决现有MAML方法在处理高波动金融数据时元任务构建的局限性。该方法利用高斯混合模型（GMMs）对学习到的嵌入进行软聚类，创建了互补的簇内和簇间元任务。这种双重策略允许模型同时适应局部模式并捕获跨序列不变特征。通过硬任务挖掘进一步增强了泛化能力。实验结果表明，该方法在真实世界金融数据上显著优于现有方法，并在零样本场景中表现出更强的泛化能力。

> **摘要翻译:** 零样本设置下的金融时间序列预测对于投资决策至关重要，尤其是在市场突然发生机制转换或新兴市场历史数据有限的情况下。尽管模型无关元学习（MAML）方法显示出前景，但现有的元任务构建策略对于高度波动的金融序列往往表现不佳。为了解决这个问题，我们提出了一种新颖的任务构建方法，该方法利用学习到的嵌入进行元任务和下游预测，从而实现有效的零样本元学习。具体而言，我们使用高斯混合模型（GMMs）对嵌入进行软聚类，构建两种互补的元任务类型：簇内任务和簇间任务。通过概率性地将嵌入分配给多个潜在状态，GMMs实现了更丰富、更多样化的元学习。这种双重方法确保模型能够快速适应局部模式，同时捕获不变的跨序列特征。此外，我们通过硬任务挖掘增强了簇间泛化能力，该方法识别了不同市场状态下的鲁棒模式。我们的方法使用来自高波动时期和多个国际市场（包括新兴市场）的真实金融数据进行了验证。结果表明，与现有方法相比，该方法表现出显著的优越性能，并在零样本场景中具有更强的泛化能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [325] [Online Nonsubmodular Optimization with Delayed Feedback in the Bandit Setting](https://arxiv.org/abs/2508.00523)
> *土匪设置下具有延迟反馈的在线非次模优化*

*Sifan Yang, Yuanyu Wan, Lijun Zhang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 在线优化, 非次模, 延迟反馈, 土匪设置, 遗憾界限

**Comment:** 

> **TL;DR:** 本文提出了两种新算法DBGD-NF及其扩展，用于解决土匪设置下具有延迟反馈的在线非次模优化问题，显著改善了现有算法的遗憾界限，使其对不规则延迟不敏感并解耦了延迟和土匪反馈的影响。

**AI_Comments:** 本文针对在线非次模优化中延迟反馈的现有问题，创新性地提出了两种算法。DBGD-NF通过关注平均延迟而非最大延迟，有效解决了不规则延迟敏感性问题。其扩展版本通过引入阻塞更新机制，成功解耦了延迟和土匪反馈的联合影响，这一贡献对于理解和优化复杂在线学习场景具有重要意义。文章清晰地展示了理论上的改进，并通过实验验证了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有工作在土匪设置下处理在线非次模优化时，其遗憾界限（$\mathcal{O}(nd^{1/3}T^{2/3})$）依赖于最大延迟$d$，因此对不规则延迟敏感。此外，它将延迟效应与土匪反馈效应耦合在一起。

**Method:** 本文提出了两种算法。首先是DBGD-NF，它采用单点梯度估计器并利用每轮所有可用的估计梯度来更新决策。其次，通过采用阻塞更新机制扩展DBGD-NF，以解耦延迟和土匪反馈的联合效应。

**Result:** DBGD-NF实现了更好的$\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$遗憾界限，这与平均延迟$\bar{d}$相关。扩展的DBGD-NF则获得了$\mathcal{O}(n(T^{2/3} + \sqrt{dT}))$遗憾界限。当$d = \mathcal{O}(T^{1/3})$时，该遗憾界限与无延迟反馈的土匪设置中的$\mathcal{O}(nT^{2/3})$界限匹配。当最大延迟$d = o(\bar{d}^{2/3}T^{1/3})$时，扩展算法更具优势。通过结构化稀疏学习实验证明了所提方法的优越性。

**Conclusion:** 本文提出的两种新算法在土匪设置下具有延迟反馈的在线非次模优化问题中表现出优越性，显著改善了遗憾界限，使其对不规则延迟的敏感度降低并成功解耦了延迟与土匪反馈的联合影响。

> **ai_Abstract:** 本文研究了土匪设置下具有延迟反馈的在线非次模优化问题，旨在解决现有方法对不规则延迟敏感且将延迟与土匪反馈效应耦合的局限性。为此，作者提出了两种新算法：DBGD-NF，其遗憾界限与平均延迟相关；以及其扩展版本，通过阻塞更新机制解耦了延迟和反馈效应，并在特定条件下达到了无延迟反馈的遗憾界限。实验证明了这些方法的优越性。

> **摘要翻译:** 我们研究了土匪设置下具有延迟反馈的在线非次模优化问题，其中损失函数是$\alpha$-弱DR-次模和$\beta$-弱DR-超模的。先前的工作已经建立了$\mathcal{O}(nd^{1/3}T^{2/3})$的$(\alpha,\beta)$-遗憾界限，其中$n$是维度，$d$是最大延迟。然而，其遗憾界限依赖于最大延迟，因此对不规则延迟敏感。此外，它将延迟和土匪反馈的影响耦合在一起，因为其界限是延迟项与无延迟反馈的土匪设置中$\mathcal{O}(nT^{2/3})$遗憾界限的乘积。在本文中，我们分别开发了两种算法来解决这些限制。首先，我们提出了一种新颖的方法，即DBGD-NF，它采用单点梯度估计器并利用每轮所有可用的估计梯度来更新决策。它实现了更好的$\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$遗憾界限，这与平均延迟$\bar{d} = \frac{1}{T}\sum_{t=1}^T d_t\leq d$相关。其次，我们通过采用阻塞更新机制扩展DBGD-NF，以解耦延迟和土匪反馈的联合效应，从而获得$\mathcal{O}(n(T^{2/3} + \sqrt{dT}))$遗憾界限。当$d = \mathcal{O}(T^{1/3})$时，我们的遗憾界限与无延迟反馈的土匪设置中的$\mathcal{O}(nT^{2/3})$界限匹配。与我们的第一个$\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$界限相比，当最大延迟$d = o(\bar{d}^{2/3}T^{1/3})$时，它更具优势。最后，我们对结构化稀疏学习进行了实验，以证明我们方法的优越性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [345] [Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery](https://arxiv.org/abs/2508.00539)
> *用于高光谱图像中弱矿物信号检测的锁相信噪比波段选择*

*Judy X Yang* | **Category: cs.LG, Cs** | **Updated: 2025-08-01**

**Keywords:** 高光谱成像, 弱矿物信号, 信噪比, 波段选择, 丰度解混

**Comment:** 8 pages, 6 figures

> **TL;DR:** 本文提出了一种两阶段集成框架，通过锁相信噪比波段选择和KMeans聚类与NNLS解混，在高光谱图像中增强弱矿物信号的检测。

**AI_Comments:** 该论文提出了一种新颖的两阶段策略，结合了信号处理（锁相SNR阈值、Savitzky-Golay滤波）和机器学习（KMeans聚类、NNLS）技术，以解决高光谱图像中弱矿物信号被噪声掩盖的关键问题。其创新点在于将SNR作为波段选择的依据，并通过锁相阈值进行精细控制，有效实现了数据降维和噪声抑制。该方法提供了一个实用且可复现的解决方案，对于地质高光谱应用中的矿物探测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱图像中的弱矿物特征常被噪声和冗余波段掩盖，限制了检测性能。

**Method:** 提出了一种两阶段集成框架。第一阶段，计算每个光谱波段的信噪比（SNR），并应用锁相阈值技术丢弃低SNR波段，同时使用Savitzky-Golay滤波进行光谱平滑。第二阶段，将精炼的高光谱数据重新引入模型，使用KMeans聚类提取末端元光谱，然后使用非负最小二乘法（NNLS）进行丰度解混。

**Result:** 实验结果证实，所提出的流程提高了解混精度，并增强了弱矿物区域的检测。

**Conclusion:** 这种双通道策略为地质高光谱成像应用中的光谱降维和解混提供了一种实用且可复现的解决方案。

> **ai_Abstract:** 本文提出了一种用于高光谱图像中弱矿物信号检测的两阶段集成框架。第一阶段通过计算波段SNR并应用锁相阈值和Savitzky-Golay滤波进行波段选择和数据平滑，以去除噪声和冗余。第二阶段利用KMeans聚类提取末端元，并结合NNLS进行丰度解混。实验证明，该方法有效提高了弱矿物区域的检测精度和解混性能。

> **摘要翻译:** 高光谱成像为矿物测绘提供了详细的光谱信息；然而，弱矿物特征常常被噪声和冗余波段掩盖，限制了检测性能。为了解决这个问题，我们提出了一个两阶段集成框架，用于增强Cuprite矿区中的矿物检测。在第一阶段，我们计算每个光谱波段的信噪比（SNR），并应用锁相阈值技术丢弃低SNR波段，有效去除冗余并抑制背景噪声。然后采用Savitzky-Golay滤波进行光谱平滑，其作用是双重的：首先在波段选择期间稳定趋势，其次在预处理期间保留精细的光谱特征。在第二阶段，将精炼的高光谱图像数据重新引入模型，其中使用KMeans聚类提取12个末端元光谱（W1 custom），然后使用非负最小二乘法（NNLS）进行丰度解混。将得到的末端元与实验室光谱（W1 raw）使用余弦相似度和RMSE指标进行定量比较。实验结果证实，我们提出的流程提高了解混精度并增强了弱矿物区域的检测。这种双通道策略为地质高光谱成像应用中的光谱降维和解混提供了一种实用且可复现的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [346] [MOSIC: Model-Agnostic Optimal Subgroup Identification with Multi-Constraint for Improved Reliability](https://arxiv.org/abs/2504.20908)
> *MOSIC：一种用于提高可靠性的模型无关多约束最优亚组识别方法*

*Wenxin Chen, Weishen Pan, Kyra Gan, Fei Wang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 最优亚组识别, 多约束, 模型无关, 优化框架, CATE

**Comment:** 

> **TL;DR:** MOSIC提出了一种统一的优化框架，通过将约束问题重构为无约束的min-max目标，直接在优化过程中整合多重约束，从而更可靠地识别最优亚组。

**AI_Comments:** 该论文的主要创新点在于将带有约束条件的亚组识别问题，巧妙地重构为一个无约束的可微分min-max优化目标，并通过梯度下降-上升算法求解。这种方法使得约束能够直接在优化过程中被强制执行，而非作为事后处理，极大地提高了亚组识别的实用性和可靠性。其模型无关的特性也增加了方法的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的亚组识别方法通常采用两步法（先估计条件平均治疗效果CATE，再进行阈值或基于规则的定义），这种解耦方法未能纳入现实临床决策所需的关键约束（如亚组大小和倾向性重叠），限制了其实用性。

**Method:** 我们提出了一个统一的优化框架，直接解决原始约束优化问题以识别最优亚组。关键创新在于将约束原始问题重新表述为一个无约束的可微分min-max目标，并通过梯度下降-上升算法求解。该方法在优化过程中直接强制执行约束，而非作为事后过滤器。它与模型无关，兼容多种CATE估计器，并可扩展到其他约束。

**Result:** 理论上，我们的解决方案收敛到一个可行且局部最优的解。在合成和真实世界数据集上的大量实验表明，该方法在识别高收益亚组的同时，能更好地满足约束条件。

**Conclusion:** MOSIC提供了一个统一的优化框架，通过直接在优化过程中整合多重约束，克服了现有方法的局限性，从而更有效地识别高收益亚组并提高决策的可靠性。

> **ai_Abstract:** MOSIC提出了一种新颖的模型无关优化框架，旨在通过直接将亚组大小、倾向性重叠等多重关键约束整合到统一的优化问题中，来识别最优治疗亚组。该方法将约束问题重构为可微分的无约束min-max目标，并通过梯度下降-上升算法求解，从而在优化阶段而非事后阶段强制执行约束。实验证明，MOSIC能有效地识别高收益亚组并更好地满足约束，提高了亚组识别的实用性和可靠性。

> **摘要翻译:** 当前亚组识别方法通常遵循两步法：首先估计条件平均治疗效果（CATE），然后应用阈值或基于规则的程序来定义亚组。尽管直观，但这种解耦方法未能纳入现实世界临床决策所必需的关键约束，例如亚组大小和倾向性重叠。这些约束在根本上与CATE估计处于不同的维度，并且在现有框架内无法自然地适应，从而限制了这些方法的实际适用性。我们提出了一个统一的优化框架，直接解决原始约束优化问题以识别最优亚组。我们的关键创新是将约束原始问题重新表述为一个无约束的可微分min-max目标，并通过梯度下降-上升算法求解。我们理论上证实了我们的解决方案收敛到一个可行且局部最优的解。与将约束作为事后过滤器的基于阈值的CATE方法不同，我们的方法在优化过程中直接强制执行这些约束。该框架与模型无关，兼容各种CATE估计器，并且可扩展到额外的约束，如成本限制或公平性标准。在合成和真实世界数据集上的大量实验证明了其在识别高收益亚组同时更好地满足约束方面的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [355] [Curious Causality-Seeking Agents Learn Meta Causal World](https://arxiv.org/abs/2506.23068)
> *好奇的因果关系探索智能体学习元因果世界*

*Zhiyu Zhao, Haoxuan Li, Haifeng Zhang, Jun Wang, Francesco Faccio, Jürgen Schmidhuber, Mengyue Yang* | **Category: cs.LG, cs.AI, stat.AP** | **Updated: 2025-08-01**

**Keywords:** 元因果图, 因果探索智能体, 世界模型, 因果推断, 好奇心驱动探索

**Comment:** 33 pages

> **TL;DR:** 智能体学习“元因果图”来建模因果结构如何在不同的潜在世界状态之间变化，并通过好奇心驱动的探索实现。

**AI_Comments:** 该论文的创新之处在于解决了观察到的因果关系动态性问题，这在传统世界模型中常被简化。元因果图为变化的因果结构提供了一种新颖的表示，而好奇心驱动的智能体则提供了一种有效的学习机制。这种方法对于在复杂现实世界环境中构建更鲁棒和更具泛化能力的AI系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 在构建世界模型时，传统方法假设环境具有单一不变的因果规则，但实际上，即使策略或环境状态的微小变化也可能改变所观察到的因果机制，即使潜在机制是固定的。

**Method:** 引入了**元因果图**作为世界模型，这是一种统一表示，编码了因果结构在不同潜在世界状态之间转变的规则，由多个由元状态触发的因果子图组成。同时引入了**因果探索智能体**，其目标是：1) 识别触发每个子图的元状态，2) 通过好奇心驱动的干预策略发现因果关系，3) 通过持续的好奇心驱动探索和经验迭代完善元因果图。

**Result:** 在合成任务和机械臂操作任务上的实验表明，该方法能够鲁棒地捕获因果动态的变化，并有效地泛化到以前未见的上下文。

**Conclusion:** 所提出的元因果图和因果探索智能体能够有效建模和学习环境中动态变化的因果关系，并展示了强大的泛化能力。

> **ai_Abstract:** 本文提出了元因果图和因果探索智能体，以解决在观察到的因果结构发生变化的复杂环境中建模动态因果机制的挑战。元因果图统一表示了跨潜在状态的因果结构转换，而智能体则利用好奇心驱动的探索和干预来识别元状态、发现因果关系并完善图。实验证实了其捕获因果变化和泛化的能力。

> **摘要翻译:** 在构建世界模型时，一个常见的假设是环境具有单一、不变的潜在因果规则，例如将牛顿定律应用于每种情况。然而，在现实中，看似漂移的因果机制往往是固定的潜在机制通过狭窄的观察窗口表现出来的结果。这带来了一个问题，即在构建世界模型时，即使策略或环境状态的微小变化也可能改变所观察到的因果机制。在这项工作中，我们引入了**元因果图**作为世界模型，这是一种最小的统一表示，能够有效地编码控制因果结构如何在不同潜在世界状态之间转变的转换规则。单个元因果图由多个因果子图组成，每个子图都由潜在状态空间中的元状态触发。在此表示的基础上，我们引入了一个**因果探索智能体**，其目标是：(1)识别触发每个子图的元状态，(2)通过智能体好奇心驱动的干预策略发现相应的因果关系，以及(3)通过持续的好奇心驱动探索和智能体经验迭代地完善元因果图。在合成任务和具有挑战性的机械臂操作任务上的实验表明，我们的方法能够鲁棒地捕获因果动态的变化，并有效地泛化到以前未见的上下文。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [365] [Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides](https://arxiv.org/abs/2508.00578)
> *学习肽中氢原子转移反应的势能面*

*Marlen Neubert, Patrick Reiser, Frauke Gräter, Pascal Friederich* | **Category: cs.LG, cond-mat.mtrl-sci, physics.chem-ph, physics.comp-ph, q-bio.BM** | **Updated: 2025-08-01**

**Keywords:** 氢原子转移, 机器学习势能, 图神经网络, 肽, 反应势垒

**Comment:** 19 pages, 12 figures, and 4 tables (references and SI included)

> **TL;DR:** 该研究通过系统生成数据并基准测试图神经网络模型（SchNet、Allegro、MACE），成功训练了用于肽中氢原子转移（HAT）反应的机器学习势能面（PESs），其中MACE表现最佳，实现了高精度的能量、力及反应势垒预测，为大规模生物分子模拟提供了量子精度。

**AI_Comments:** 该论文的创新之处在于其系统性的数据生成策略和对多种图神经网络架构在HAT反应势能面学习上的全面基准测试。MACE模型的出色表现展示了机器学习在生物分子模拟中实现量子精度的巨大潜力。这项工作对于理解生物过程中关键的HAT反应机制，特别是自由基迁移，具有重要意义。其提出的方法具有良好的通用性，有望推广到其他复杂生物体系的化学反应模拟。

<details>
  <summary>Details</summary>

**Motivation:** 氢原子转移（HAT）反应在许多生物过程中至关重要，例如受损蛋白质中的自由基迁移，但其作用机制路径尚不完全清楚。模拟HAT反应具有挑战性，因为它需要在生物学相关尺度上达到量子化学精度；因此，经典的力场和基于DFT的分子动力学均不适用。

**Method:** 研究通过半经验方法和DFT系统地生成肽中的HAT构型，以构建大型数据集。基准测试了三种图神经网络架构（SchNet、Allegro和MACE）学习HAT PESs并间接从能量预测中预测反应势垒的能力。

**Result:** MACE在能量、力和势垒预测方面始终优于其他模型，在超出分布的DFT势垒预测上实现了1.13 kcal/mol的平均绝对误差。这种精度使得机器学习势能能够集成到大规模胶原模拟中，以根据预测的势垒计算反应速率。

**Conclusion:** 该研究提出的方法能够实现HAT和肽中自由基迁移的机制理解，并可推广到其他生物分子系统，从而在复杂环境中实现化学反应性的量子精确模拟。

> **ai_Abstract:** 本研究旨在解决肽中氢原子转移（HAT）反应机制理解不完全及模拟困难的问题。通过结合半经验方法和DFT系统生成HAT构型数据集，并对SchNet、Allegro和MACE三种图神经网络模型进行基准测试，发现MACE在学习HAT势能面（PESs）和预测反应势垒方面表现最佳，达到了1.13 kcal/mol的平均绝对误差。这种高精度使得机器学习势能能够应用于大规模生物分子模拟，从而计算反应速率并加深对HAT和自由基迁移的理解。该方法具有普适性，可应用于其他生物分子系统，实现复杂环境中化学反应性的量子精确模拟。

> **摘要翻译:** 氢原子转移（HAT）反应在许多生物过程中至关重要，例如受损蛋白质中的自由基迁移，但其作用机制路径尚不完全清楚。模拟HAT反应具有挑战性，因为它需要在生物学相关尺度上达到量子化学精度；因此，经典的力场和基于DFT的分子动力学均不适用。机器学习势能提供了一种替代方案，能够以接近量子的精度学习势能面（PESs）。然而，训练这些模型以泛化到各种HAT构型，特别是在蛋白质的自由基位置，需要定制的数据生成和仔细的模型选择。

在此，我们系统地生成肽中的HAT构型，使用半经验方法和DFT构建大型数据集。我们基准测试了三种图神经网络架构（SchNet、Allegro和MACE）学习HAT PESs并间接从能量预测中预测反应势垒的能力。MACE在能量、力和势垒预测方面始终优于其他模型，在超出分布的DFT势垒预测上实现了1.13 kcal/mol的平均绝对误差。这种精度使得机器学习势能能够集成到大规模胶原模拟中，以根据预测的势垒计算反应速率，从而促进对HAT和肽中自由基迁移的机制理解。我们分析了标度律、模型可迁移性和成本-性能权衡，并概述了通过将机器学习势能与过渡态搜索算法和主动学习相结合来改进的策略。我们的方法可推广到其他生物分子系统，从而在复杂环境中实现化学反应性的量子精确模拟。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [366] [Transfer learning-enhanced deep reinforcement learning for aerodynamic airfoil optimisation subject to structural constraints](https://arxiv.org/abs/2505.02634)
> *迁移学习增强的深度强化学习用于受结构约束的气动翼型优化*

*David Ramos, Lucas Lacasa, Eusebio Valero, Gonzalo Rubio* | **Category: cs.LG, physics.comp-ph** | **Updated: 2025-08-01**

**Keywords:** 深度强化学习, 迁移学习, 翼型优化, 结构约束, 气动性能

**Comment:** Accepted in Physics of Fluids 20 pages, 7 figures

> **TL;DR:** 本文提出了一种结合迁移学习的深度强化学习方法，用于在考虑结构完整性的同时优化翼型气动性能，并证明其在计算效率上优于PSO。

**AI_Comments:** 本文的创新点在于将迁移学习与深度强化学习相结合，应用于受结构约束的翼型气动优化问题。这种方法不仅提高了优化效率，还在实际工程应用中具有重要意义，因为它同时考虑了性能和结构完整性。计算资源的显著节省是其一大亮点，表明了该方法在解决复杂工程优化问题上的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在引入一种迁移学习增强的深度强化学习（DRL）方法，该方法能够根据气动和结构完整性标准优化任何翼型的几何形状。具体目标是最大化升阻比，同时保持翼型的结构完整性（通过最大厚度建模）。

**Method:** 本文提出了一种迁移学习增强的深度强化学习（DRL）方法，用于翼型几何优化。该方法通过最大化升阻比$C_L/C_D$并保持翼型最大厚度来兼顾气动性能和结构完整性。研究中采用了多种不同的迁移学习（TL）策略来训练DRL智能体，并将其性能与传统的无梯度优化方法粒子群优化（PSO）进行了比较。

**Result:** DRL智能体能够执行纯空气动力学和混合空气动力学/结构形状优化。DRL方法在计算效率和气动改进方面优于PSO。迁移学习增强的DRL智能体实现了与DRL智能体相当的性能，同时进一步节省了大量的计算资源。

**Conclusion:** 迁移学习增强的深度强化学习方法在受结构约束的翼型气动优化方面表现出色，它在计算效率和气动性能提升方面优于传统方法，并且能够显著节省计算资源。

> **ai_Abstract:** 本文提出了一种结合迁移学习（TL）的深度强化学习（DRL）方法，用于在考虑结构完整性（通过最大厚度建模）的同时优化翼型的气动性能，以最大化升阻比。研究将该方法与粒子群优化（PSO）进行比较，结果显示DRL在计算效率和气动改进方面优于PSO。此外，TL增强的DRL在保持性能的同时，显著节省了计算资源。

> **摘要翻译:** 本文的主要目标是介绍一种迁移学习增强的深度强化学习（DRL）方法，该方法能够根据伴随的气动和结构完整性标准优化任何翼型的几何形状。为了展示该方法，我们旨在最大化升阻比$C_L/C_D$，同时保持翼型的结构完整性——通过其最大厚度进行建模——并使用一系列不同的迁移学习（TL）策略训练DRL智能体。将DRL智能体的性能与传统的无梯度优化方法粒子群优化（PSO）进行比较。结果表明，DRL智能体能够执行纯空气动力学和混合空气动力学/结构形状优化，DRL方法在计算效率和气动改进方面优于PSO，并且TL增强的DRL智能体实现了与DRL智能体相当的性能，同时进一步节省了大量的计算资源。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [380] [ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs](https://arxiv.org/abs/2508.00394)
> *ExeKGLib：一个基于知识图谱的机器学习分析平台*

*Antonis Klironomos, Baifan Zhou, Zhipeng Tan, Zhuoxun Zheng, Mohamed H. Gad-Elrab, Heiko Paulheim, Evgeny Kharlamov* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 知识图谱, 机器学习管道, ExeKGLib, 机器学习分析, 透明度

**Comment:** 

> **TL;DR:** ExeKGLib是一个Python库，通过知识图谱和图形界面，帮助非机器学习专家轻松构建和执行机器学习管道。

**AI_Comments:** ExeKGLib的创新之处在于其利用知识图谱将复杂的机器学习知识简化，并通过图形界面提供给非专业用户，大大降低了机器学习应用的门槛。这对于促进机器学习在多学科领域的普及和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前机器学习库众多，但构建高质量的机器学习管道需要专业知识和经验，这对于科学和工程领域的领域专家来说是挑战，他们急需基于机器学习的分析能力。

**Method:** 本文提出了ExeKGLib，一个增强了图形界面层的Python库。它通过依赖将机器学习知识以简单术语编码的知识图谱，使机器学习知识最少的用户也能构建机器学习管道。ExeKGLib还旨在提高所构建机器学习工作流的透明度和可重用性，并确保它们是可执行的。

**Result:** 通过展示真实用例，本文展示了ExeKGLib的可用性和实用性。

**Conclusion:** ExeKGLib通过结合知识图谱和用户友好的界面，使非机器学习专家也能构建和执行机器学习管道，提高了工作流的透明度和可重用性。

> **ai_Abstract:** 本文介绍了ExeKGLib，一个基于知识图谱的Python库，旨在帮助缺乏机器学习专业知识的领域专家构建和执行机器学习管道。它通过图形界面和将机器学习知识编码为简单术语的知识图谱，简化了机器学习工作流的创建过程，并提高了其透明度、可重用性和可执行性。通过真实用例展示了其有效性。

> **摘要翻译:** 如今，机器学习 (ML) 从业者可以访问在线提供的众多机器学习库。这些库可用于创建机器学习管道，该管道由一系列步骤组成，其中每个步骤可以调用多达几个用于各种数据驱动分析任务的机器学习库。开发高质量的机器学习管道并非易事；它需要培训、机器学习专业知识以及每个步骤的精心开发。与此同时，科学和工程领域的领域专家可能不具备此类机器学习专业知识和培训，而他们却迫切需要基于机器学习的分析。在本文中，我们提出了我们的 ExeKGLib，这是一个通过图形界面层增强的 Python 库，允许具有最少机器学习知识的用户构建机器学习管道。这是通过依赖以非机器学习专家可访问的简单术语编码机器学习知识的知识图谱来实现的。ExeKGLib 还允许提高所构建机器学习工作流的透明度和可重用性，并确保它们是可执行的。我们通过展示真实用例来展示 ExeKGLib 的可用性和实用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [384] [Latent Diffeomorphic Dynamic Mode Decomposition](https://arxiv.org/abs/2505.06351)
> *潜在微分同胚动态模态分解*

*Willem Diepeveen, Jon Schwenk, Andrea Bertozzi* | **Category: cs.LG, math.DS** | **Updated: 2025-08-01**

**Keywords:** 潜在微分同胚动态模态分解, 非线性系统, 动态模态分解, 循环神经网络, 数据降维

**Comment:** 

> **TL;DR:** LDDMD结合了DMD的可解释性和RNN的预测能力，用于分析和预测非线性系统，并已成功应用于径流预测。

**AI_Comments:** LDDMD的创新之处在于它成功地将DMD的可解释性与RNNs的强大预测能力结合起来，为非线性系统提供了一种既易于理解又高效的分析工具。其在流预测中的应用表明了该方法在实际问题中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数据降维方法可能难以同时兼顾非线性系统的可解释性、预测能力和建模复杂性。本文旨在提出一种新方法来解决这一挑战。

**Method:** 本文提出了潜在微分同胚动态模态分解（LDDMD），它结合了动态模态分解（DMD）的可解释性与循环神经网络（RNNs）的预测能力，用于非线性系统的数据降维。

**Result:** LDDMD在径流预测中取得了成功应用。

**Conclusion:** LDDMD在保持简单性的同时，有效建模和学习具有记忆的复杂非线性系统，从而实现准确预测，并增强了可解释性。

> **ai_Abstract:** 本文介绍了潜在微分同胚动态模态分解（LDDMD），一种结合DMD的可解释性和RNNs的预测能力的新型数据降维方法，用于分析和预测非线性系统。LDDMD在保持简单性的同时，能有效处理复杂非线性系统并提供准确预测，并在径流预测中得到了验证。

> **摘要翻译:** 我们提出了潜在微分同胚动态模态分解（LDDMD），这是一种用于分析非线性系统的新型数据降维方法，它结合了动态模态分解（DMD）的可解释性与循环神经网络（RNNs）的预测能力。值得注意的是，LDDMD保持了简单性，从而增强了可解释性，同时有效地建模和学习具有记忆的复杂非线性系统，从而实现准确预测。这通过其在径流预测中的成功应用得到了例证。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [389] [The Role of Active Learning in Modern Machine Learning](https://arxiv.org/abs/2508.00586)
> *主动学习在现代机器学习中的作用*

*Thorben Werner, Lars Schmidt-Thieme, Vijaya Krishna Yalavarthi* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 主动学习, 数据增强, 半监督学习, 低数据场景, 性能提升

**Comment:** 

> **TL;DR:** 主动学习（AL）计算成本高，在少量标注数据场景下提升有限。本研究发现，AL在数据增强（DA）和半监督学习（SSL）之后，仍能提供性能提升，应被视为数据优化的最后一步，而非解决标签缺失的主要方法。

**AI_Comments:** 这篇论文对主动学习的传统认知提出了挑战，将其从“解决标签缺失”的主要方法重新定位为“性能微调”的最后一步。其创新点在于通过实证比较，揭示了AL在不同数据策略组合下的真实价值，对于指导AL在实际应用中的有效部署具有重要意义。论文的发现可能有助于研究人员更合理地设计和应用主动学习策略，避免不必要的计算开销，并最大化数据利用效率。

<details>
  <summary>Details</summary>

**Motivation:** 尽管主动学习（AL）被广泛研究，但其在科学文献之外的应用却很少。作者认为这归因于AL的高计算成本以及在少量标注数据场景下其通常只能带来相对较小的性能提升。因此，本研究旨在探讨在低数据场景下，AL、数据增强（DA）和半监督学习（SSL）等不同方法的有效性。

**Method:** 本研究通过研究主动学习（AL）、数据增强（DA）和半监督学习（SSL）对低数据场景的影响，来比较它们在解决数据稀缺问题上的表现。研究分析了这些方法单独使用以及AL与DA和SSL技术结合使用时的性能。

**Result:** 研究发现，在解决低数据问题时，主动学习（AL）是效率最低的方法，相对于随机采样仅能带来1-4%的提升。而数据增强（DA）和半监督学习（SSL）方法与随机采样结合使用时，可以带来高达60%的提升。然而，当AL与强大的DA和SSL技术结合使用时，它仍能提供额外的性能改进。

**Conclusion:** 基于研究结果，论文将主动学习（AL）定位为在应用了适当的数据增强（DA）和半监督学习（SSL）方法之后，用于从数据中“榨取”最后一点性能的最终构建块，而非一种主要用于对抗标签缺失的方法。

> **ai_Abstract:** 本研究探讨了主动学习（AL）在现代机器学习中的实际应用局限性，指出其高计算成本和在低数据量下的有限提升。通过与数据增强（DA）和半监督学习（SSL）进行比较，发现AL单独使用时效率最低，但当与强大的DA和SSL技术结合时，仍能提供额外的性能提升。论文最终将AL重新定义为在数据已通过DA和SSL充分优化后，用于进一步提升模型性能的最后阶段工具。

> **摘要翻译:** 尽管主动学习（AL）被广泛研究，但其在自身科学文献之外的应用却很少。我们认为这归因于AL的高计算成本以及在少量标注数据场景下其通常只能带来相对较小的性能提升。在这项工作中，我们研究了对抗这种低数据场景的不同方法的影响，即数据增强（DA）、半监督学习（SSL）和AL。我们发现，AL是解决低数据问题效率最低的方法，相对于随机采样仅能带来1-4%的提升，而DA和SSL方法与随机采样结合使用时，可以带来高达60%的提升。然而，当AL与强大的DA和SSL技术结合使用时，它竟然仍能提供改进。基于这些结果，我们将AL定位为不是一种对抗标签缺失的方法，而是在应用了适当的DA和SSL方法之后，用于从数据中“榨取”最后一点性能的最终构建块。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [406] [Adaptive Branch Specialization in Spectral-Spatial Graph Neural Networks for Certified Robustness](https://arxiv.org/abs/2505.08320)
> *自适应分支特化在谱空间图神经网络中用于认证鲁棒性*

*Yoonhyuk Choi, Jiho Choi, Chong-Kwon Kim* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 图神经网络, 认证鲁棒性, 谱空间, 分支特化, 对抗训练

**Comment:** 

> **TL;DR:** 本文提出了SpecSphere，一种谱空间图神经网络，通过对不同类型的扰动（边翻转 vs. 特征扰动）进行分支特化和自适应门控机制，实现了最先进的认证鲁棒性和准确性。

**AI_Comments:** 这项工作的创新之处在于其自适应分支特化和上下文感知门控机制，它智能地利用了谱和空间图神经网络在对抗不同类型扰动方面的优势。这种方法提供了更强的认证鲁棒性，填补了当前图神经网络研究中的一个关键空白。

<details>
  <summary>Details</summary>

**Motivation:** 现有的结合了谱空间架构的图神经网络对认证鲁棒性关注有限，尤其是在训练策略和基本原理方面。

**Method:** 本文提出了SpecSphere模型，它明确地特化了每个分支：谱网络训练以抵御l0边翻转并捕获同质结构，而空间部分则设计用于抵抗linf特征扰动和异质模式。一个上下文感知的门控网络自适应地融合这两种表示，动态地将每个节点的预测路由到更可靠的分支。这种专门的对抗训练方案使用分支特定的内部最大化（结构攻击 vs. 特征攻击）和统一的对齐目标。

**Result:** SpecSphere在真实世界基准测试中取得了最先进的节点分类精度，并提供了更紧密的认证鲁棒性。理论上，该研究提供了门控机制超越1-WL的表达能力、谱空间频率偏差以及具有权衡的认证鲁棒性保证。

**Conclusion:** 该论文提出了一种有效的自适应分支特化策略，用于谱空间图神经网络，显著增强了认证鲁棒性和性能。

> **ai_Abstract:** 本文提出了SpecSphere，一种新颖的谱空间图神经网络，专为认证鲁棒性设计。它采用自适应分支特化，其中谱分支针对l0边翻转鲁棒性和同质性进行训练，空间分支则针对linf特征扰动鲁棒性和异质性进行训练。一个上下文感知的门控网络动态融合这些表示，并将预测路由到更可靠的分支。这种专门的对抗训练方案，结合理论保证，使得SpecSphere在真实世界数据集上实现了最先进的节点分类精度和更紧密的认证鲁棒性。

> **摘要翻译:** 最近的图神经网络（GNNs）结合了谱空间架构以增强表示学习。然而，对认证鲁棒性关注有限，特别是关于训练策略和基本原理。在本文中，我们明确地特化了每个分支：谱网络被训练以抵御l0边翻转并捕获同质结构，而空间部分被设计用于抵抗linf特征扰动和异质模式。一个上下文感知的门控网络自适应地融合这两种表示，动态地将每个节点的预测路由到更可靠的分支。这种专门的对抗训练方案使用分支特定的内部最大化（结构攻击 vs. 特征攻击）和统一的对齐目标。我们提供了理论保证：（i）门控机制超越1-WL的表达能力，（ii）谱空间频率偏差，以及（iii）具有权衡的认证鲁棒性。经验上，SpecSphere在真实世界基准测试中取得了最先进的节点分类精度，并提供了更紧密的认证鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [415] [IAMAP: Unlocking Deep Learning in QGIS for non-coders and limited computing resources](https://arxiv.org/abs/2508.00627)
> *IAMAP：为非编码人员和有限计算资源解锁QGIS中的深度学习*

*Paul Tresson, Pierre Le Coz, Hadrien Tulet, Anthony Malkassian, Maxime Réjou Méchain* | **Category: cs.LG, I.4.9; I.4.6** | **Updated: 2025-08-01**

**Keywords:** 深度学习, QGIS, 遥感, 自监督学习, 基础模型

**Comment:** 11 pages, 5 figures

> **TL;DR:** IAMAP是一个QGIS插件，旨在解决深度学习在遥感应用中面临的数据、计算和编码障碍，使非专业用户在资源有限的情况下也能高效利用深度学习。

**AI_Comments:** IAMAP的创新在于将先进的自监督学习和基础模型集成到广泛使用的GIS平台QGIS中，极大地降低了深度学习的专业技能和硬件资源门槛。这对于遥感领域的非编码人员和资源受限的用户而言具有重要意义，有助于推动深度学习技术的民主化和广泛应用。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在遥感领域的应用受到限制，因为它通常需要大量参考数据集、强大的计算资源和专业的编码技能，这使得其在非专业人士和资源有限的环境中难以实施。

**Method:** 本文介绍了一个名为IAMAP的QGIS插件。该插件利用自监督学习策略和基础模型来提供强大的特征提取器，这些模型通常可以在少样本或零样本场景下使用。IAMAP的界面允许用户执行遥感图像分析中的关键步骤，包括使用多种深度学习架构提取图像特征、使用内置算法进行降维、对特征进行聚类、生成特征相似性图，以及校准和验证监督机器学习模型。

**Result:** IAMAP使非AI专家能够利用近期深度学习方法提供的高质量特征，而无需GPU容量或大量的参考数据集，从而促进了计算高效和节能的深度学习方法的普及。

**Conclusion:** IAMAP通过提供一个用户友好的QGIS插件，解决了深度学习在遥感应用中对数据、计算资源和编码技能的高要求，从而促进了计算高效和节能深度学习方法的民主化和广泛应用。

> **ai_Abstract:** IAMAP是一个为QGIS设计的用户友好插件，旨在降低深度学习在遥感应用中的门槛。它通过利用自监督学习和基础模型提供强大的特征提取能力，并集成了降维、聚类、特征相似性图生成以及监督模型校准与验证等功能。该工具使得非专业用户即使在有限的计算资源和参考数据集下，也能高效地利用深度学习进行遥感图像分析，从而促进了深度学习方法的普及。

> **摘要翻译:** 遥感技术随着人工智能方法的快速发展进入了一个新时代。然而，深度学习的实施在很大程度上仍局限于专业人士，并且不切实际，因为它通常需要 (i) 大量用于模型训练和验证的参考数据集；(ii) 大量的计算资源；以及 (iii) 强大的编码技能。在此，我们介绍了 IAMAP，一个用户友好的 QGIS 插件，它以简单而灵活的方式解决了这三个挑战。IAMAP 建立在自监督学习策略的最新进展之上，这些策略现在提供了强大的特征提取器，通常被称为基础模型。这些通用模型通常可以在少样本或零样本场景中可靠地使用（即，很少或根本不需要微调）。IAMAP 的界面允许用户简化遥感图像分析中的几个关键步骤：(i) 使用各种深度学习架构提取图像特征；(ii) 使用内置算法进行降维；(iii) 对特征或其降维表示进行聚类；(iv) 生成特征相似性图；以及 (v) 校准和验证用于预测的监督机器学习模型。通过使非人工智能专家无需 GPU 容量或大量参考数据集即可利用近期深度学习方法提供的高质量特征，IAMAP 有助于计算高效和节能的深度学习方法的民主化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [431] [Towards Fair In-Context Learning with Tabular Foundation Models](https://arxiv.org/abs/2505.09503)
> *迈向表格基础模型的公平上下文学习*

*Patrik Kenfack, Samira Ebrahimi Kahou, Ulrich Aïvodji* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 表格基础模型, 上下文学习, 公平性, 偏差缓解, 不确定性选择

**Comment:** 30 pages, 12 figures, 5 tables

> **TL;DR:** 表格基础模型在上下文学习中表现出色，但其公平性未被探索。本文首次研究了表格上下文学习的公平性，并发现基于不确定性的样本选择方法能有效提高公平性，同时对预测精度影响最小。

**AI_Comments:** 本文首次探讨了表格上下文学习的公平性问题，鉴于AI公平性日益增长的重要性，这是一项重要的贡献。提出的基于不确定性的方法实用且有效，能在不显著牺牲预测精度的情况下提升公平性。

<details>
  <summary>Details</summary>

**Motivation:** 探索表格基础模型在上下文学习（ICL）中的公平性问题，因为这一新兴范式的公平性影响尚未被充分研究。

**Method:** 评估了TabPFNv2、TabICL和TabDPT这三种表格基础模型在多个基准数据集上的公平性。为了缓解偏差，探索了三种预处理的公平性增强方法：相关性去除、组平衡样本选择和基于不确定性的样本选择。

**Result:** 实验结果表明，基于不确定性的策略能持续改进群体公平性指标（如人口均等、均等化赔率和机会均等），同时对预测精度影响最小。

**Conclusion:** 基于不确定性的策略能够有效提高表格上下文学习的群体公平性，且对预测精度影响甚微。

> **ai_Abstract:** 本文首次研究了基于Transformer的表格基础模型在上下文学习（ICL）中的公平性问题。研究评估了TabPFNv2、TabICL和TabDPT三种模型，并探索了相关性去除、组平衡样本选择和基于不确定性的样本选择三种预处理方法来减轻偏差。实验证明，基于不确定性的策略能有效提升群体公平性指标，同时对预测精度影响甚微。

> **摘要翻译:** 基于Transformer的表格基础模型最近在结构化数据上展示了有前景的上下文学习（ICL）性能，成为梯度提升树的有力竞争者。然而，这种新范式的公平性影响在很大程度上仍未被探索。我们首次对表格ICL中的公平性进行了调查，评估了最近提出的三种基础模型——TabPFNv2、TabICL和TabDPT——在多个基准数据集上的表现。为了减轻偏差，我们探索了三种预处理的公平性增强方法：相关性去除（使输入特征与敏感属性去相关）、组平衡样本选择（确保受保护群体在上下文示例中具有平等的代表性）和基于不确定性的样本选择（优先选择敏感属性预测不确定性高的上下文示例）。我们的实验表明，基于不确定性的策略能持续改进群体公平性指标（例如，人口均等、均等化赔率和机会均等），同时对预测精度影响最小。我们发布了代码以促进重现性（https://github.com/patrikken/Fair-TabICL）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [432] [Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion](https://arxiv.org/abs/2508.00037)
> *能源信息图神经网络扩散预测大规模城市网络动态*

*Tong Nie, Jian Sun, Wei Ma* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 城市网络动态, 图神经网络, 时空预测, 可扩展性, Transformer

**Comment:** Accepted at IEEE Transactions on Industrial Informatics

> **TL;DR:** 本文提出了一种名为ScaleSTF的新型可扩展时空Transformer模型，通过借鉴物理定律解决了大规模城市网络动态预测中效率与效果的权衡问题，实现了最先进的性能和卓越的可扩展性。

**AI_Comments:** 这篇论文的创新点在于将物理定律的启发融入到图神经网络的设计中，以解决大规模城市系统预测中效率与效果的权衡问题。通过引入具有线性复杂度的可扩展时空Transformer (ScaleSTF) 模型，它在实际应用中展现了显著的实用性和潜力，尤其是在处理大规模数据时。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图神经网络模型在预测大规模城市系统时空动态方面面临有效性和效率之间的权衡，计算需求高，限制了其在大规模网络中的应用。

**Method:** 论文受物理定律启发，设计了一个基于Transformer结构的、由低维嵌入诱导注意力层的可解释神经扩散方案。该方案旨在避免架构冗余并遵循基本原理，提出了一种名为可扩展时空Transformer (ScaleSTF) 的模型，其复杂度为线性。

**Result:** 所提出的ScaleSTF模型在交通流、太阳能和智能电表等大规模城市系统上进行了验证，展示了最先进的性能和卓越的可扩展性。

**Conclusion:** 本文的研究结果为大规模城市网络动态预测提供了新的视角。

> **ai_Abstract:** 本文针对大规模城市网络动态预测中现有图神经网络存在的有效性与效率权衡问题，提出了一种名为可扩展时空Transformer (ScaleSTF) 的新型模型。该模型受物理定律启发，采用基于Transformer的神经扩散方案，通过低维嵌入诱导注意力层，实现了线性复杂度。ScaleSTF在交通流、太阳能和智能电表等大规模城市系统上表现出最先进的性能和卓越的可扩展性，为城市网络动态预测提供了新视角。

> **摘要翻译:** 联网的城市系统促进了人员、资源和服务的流动，对经济和社会互动至关重要。这些系统通常涉及具有未知控制规则的复杂过程，通过基于传感器的时序数据进行观测。为了辅助工业和工程领域的决策，数据驱动的预测模型被用于预测城市系统的时空动态。当前的模型，如图神经网络，已显示出前景，但由于计算需求面临有效性和效率之间的权衡。因此，它们在大规模网络中的应用仍需进一步努力。本文通过借鉴物理定律，为与基本原理对齐并避免架构冗余的基本模型设计提供信息，从而解决了这种权衡挑战。通过理解微观和宏观过程，我们提出了一种基于Transformer类结构的可解释神经扩散方案，其注意力层由低维嵌入诱导。所提出的可扩展时空Transformer (ScaleSTF) 具有线性复杂度，已在交通流、太阳能和智能电表等大规模城市系统上进行验证，显示出最先进的性能和卓越的可扩展性。我们的结果构成了大规模城市网络动态预测的新视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [440] [Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs](https://arxiv.org/abs/2508.00628)
> *分离变量谱神经网络：一种用于高频偏微分方程的物理信息学习方法*

*Xiong Xiong, Zhuo Zhang, Rongchun Hu, Chen Gao, Zichen Deng* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 高频偏微分方程, 物理信息神经网络, 谱偏差, 分离变量, 谱方法

**Comment:** 

> **TL;DR:** 引入SV-SNN，通过解决谱偏差问题，比传统PINNs更准确高效地求解高频偏微分方程。

**AI_Comments:** SV-SNN框架通过结合变量分离和自适应谱方法，创新性地解决了物理信息神经网络（PINNs）在处理高频偏微分方程时长期存在的谱偏差问题。其在精度、参数效率和训练时间方面的显著改进，使其成为科学计算和物理信息机器学习领域的重要贡献。此外，用于量化谱偏差的理论框架也增加了其严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 解决高频振荡偏微分方程是科学计算中的一个关键挑战。传统的物理信息神经网络（PINNs）存在谱偏差问题，限制了它们捕获高频解分量的能力。

**Method:** 提出分离变量谱神经网络（SV-SNN）框架，通过整合变量分离和自适应谱方法来解决传统PINNs的局限性。其主要创新包括：1）将多元函数分解为单变量函数乘积，实现独立的空域和时域网络；2）采用具有可学习频率参数的自适应傅里叶谱特征来捕获高频信息；3）建立基于奇异值分解的理论框架来量化谱偏差。

**Result:** 在包括热方程、亥姆霍兹方程、泊松方程和纳维-斯托克斯方程等基准问题上的评估表明，SV-SNN在精度上实现了1-3个数量级的提高，同时将参数数量减少了90%以上，训练时间减少了60%。

**Conclusion:** 这些结果确立了SV-SNN作为神经网络偏微分方程求解中谱偏差问题的有效解决方案。

> **ai_Abstract:** 本文提出了一种名为分离变量谱神经网络（SV-SNN）的新型框架，旨在解决传统物理信息神经网络（PINNs）在求解高频偏微分方程（PDEs）时存在的谱偏差问题。SV-SNN通过整合变量分离和自适应谱方法，实现了多元函数的单变量分解、引入了可学习频率参数的自适应傅里叶谱特征，并提供了量化谱偏差的理论框架。在热方程、亥姆霍兹方程、泊松方程和纳维-斯托克斯方程等多个基准问题上的综合评估显示，SV-SNN在精度上提升了1-3个数量级，同时显著减少了90%以上的参数数量和60%的训练时间，证明了其在解决神经网络PDE求解中谱偏差问题的有效性。

> **摘要翻译:** 解决高频振荡偏微分方程（PDEs）是科学计算中的一个关键挑战，在流体力学、量子力学和电磁波传播等领域都有应用。传统的物理信息神经网络（PINNs）存在谱偏差问题，限制了它们捕获高频解分量的能力。我们引入了分离变量谱神经网络（SV-SNN），这是一个新颖的框架，通过整合变量分离和自适应谱方法来解决这些限制。我们的方法具有三个关键创新点：（1）将多元函数分解为单变量函数乘积，从而实现独立的空域和时域网络；（2）具有可学习频率参数的自适应傅里叶谱特征，用于捕获高频信息；（3）基于奇异值分解的理论框架，用于量化谱偏差。在包括热方程、亥姆霍兹方程、泊松方程和纳维-斯托克斯方程等基准问题上的综合评估表明，SV-SNN在精度上实现了1-3个数量级的提高，同时将参数数量减少了90%以上，训练时间减少了60%。这些结果确立了SV-SNN作为神经网络PDE求解中谱偏差问题的有效解决方案。该实现将在被接受后公开提供，网址为https://github.com/xgxgnpu/SV-SNN。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [455] [EmissionNet: Air Quality Pollution Forecasting for Agriculture](https://arxiv.org/abs/2507.05416)
> *EmissionNet：农业空气质量污染预测*

*Prady Saligram, Tanvir Bhathal* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 农业排放, 空气质量预测, 深度学习, EmissionNet, N₂O预测

**Comment:** The appendix figures are mixed up - several emission plots (e.g. CO2,
  CH4, GWP) are mislabeled and appear in the wrong order, leading to confusion
  in interpreting the results

> **TL;DR:** 提出 EmissionNet (ENV) 和 EmissionNet-Transformer (ENT) 两种深度学习模型，用于预测农业N₂O排放，解决传统模型难以捕捉复杂非线性相互作用的问题。

**AI_Comments:** 这篇论文的创新点在于将深度学习，特别是卷积和Transformer架构，应用于农业排放的空气质量预测，以克服传统物理模型在处理复杂非线性关系上的不足。这对于改善环境和公共健康具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 农业排放造成的空气污染是一个重要但常被忽视的环境和公共健康挑战。传统空气质量预测模型依赖于基于物理的方法，难以捕捉复杂的非线性污染物相互作用。

**Method:** 通过评估现有流行架构，并提出两种新的深度学习架构：EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)。这些模型利用卷积和Transformer架构，从高分辨率排放数据中提取时空依赖性，用于预测农业N₂O排放。

**Result:** Not mentioned in abstract

**Conclusion:** 本文提出了两种新的深度学习模型EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，旨在通过利用深度学习捕捉复杂的时空依赖性，改进农业N₂O排放的空气质量预测。

> **ai_Abstract:** 本文关注农业排放导致的空气污染预测问题，指出传统物理模型在处理复杂非线性相互作用上的局限性。为解决此问题，作者提出了两种新型深度学习架构：EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，它们结合了卷积和Transformer技术，旨在从高分辨率排放数据中有效提取时空依赖性，从而更准确地预测农业N₂O排放。

> **摘要翻译:** 农业排放造成的空气污染是一个重要但常被忽视的环境和公共健康挑战。传统的空气质量预测模型依赖于基于物理的方法，这些方法难以捕捉复杂的非线性污染物相互作用。在这项工作中，我们通过评估流行的架构，并提出了两种新颖的深度学习架构 EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，来探索预测农业 N₂O 排放。这些模型利用卷积和基于 Transformer 的架构，从高分辨率排放数据中提取时空依赖性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [456] [Rethinking Irregular Time Series Forecasting: A Simple yet Effective Baseline](https://arxiv.org/abs/2505.11250)
> *重新思考不规则时间序列预测：一个简单而有效的基线*

*Xvyuan Liu, Xiangfei Qiu, Xingjian Wu, Zhengyu Li, Chenjuan Guo, Jilin Hu, Bin Yang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 不规则时间序列, 预测, 时间感知补丁聚合, IMTS, 计算效率

**Comment:** 

> **TL;DR:** APN是一个用于不规则多元时间序列预测的新框架，其核心是时间感知补丁聚合（TAPA）模块。它通过直接聚合原始数据，有效解决了数据不规则性和计算成本高的问题，并在准确性和效率上超越了现有方法。

**AI_Comments:** 这篇论文通过避免插值等常见陷阱，为不规则时间序列预测引入了一种新颖且实用的方法。时间感知补丁聚合（TAPA）模块似乎是其核心创新点，提供了一种数据驱动的方式来处理不规则采样。论文同时关注准确性和计算效率，使其在医疗保健等数据通常不规则的实际应用中具有高度相关性。声称以“简单而有效的基线”建立新的最先进水平，表明其做出了重大贡献。

<details>
  <summary>Details</summary>

**Motivation:** 不规则多元时间序列（IMTS）的预测是关键任务，但面临两大挑战：1）IMTS固有的非均匀性和缺失数据使时间动态建模复杂；2）现有方法通常计算成本高昂。

**Method:** 本文提出了APN，一个通用且高效的预测框架。其核心是时间感知补丁聚合（TAPA）模块，该模块采用基于聚合的范式进行自适应补丁处理。TAPA首先学习动态时间边界来定义数据驱动的段，然后通过对所有原始观测值进行时间感知加权聚合来直接计算补丁表示，从而避免了重采样或插值，保留了数据保真度并确保了完整的信息覆盖。最终，使用轻量级查询模块和简单的MLP进行预测。

**Result:** 在多个真实世界数据集上的广泛实验表明，APN在预测精度和计算效率方面均显著优于现有方法，建立了新的最先进水平。

**Conclusion:** APN为不规则多元时间序列预测提供了一个有效且高效的解决方案，成功应对了数据不规则性和计算成本高的关键挑战。

> **ai_Abstract:** 本文提出APN，一个用于预测不规则多元时间序列（IMTS）的通用且高效的新框架。它通过其核心的时间感知补丁聚合（TAPA）模块解决了数据不规则性和计算成本高的挑战。TAPA通过对原始观测值进行时间感知加权聚合来避免插值，从而保留了数据保真度。这种方法结合轻量级查询模块和MLP，在真实世界数据集上实现了最先进的准确性和效率。

> **摘要翻译:** 不规则多元时间序列（IMTS）的预测是医疗保健和气候科学等领域的关键任务。然而，这项任务面临两个重大障碍：1）IMTS固有的非均匀性和缺失数据使得时间动态建模复杂化，以及2）现有方法通常依赖于计算成本高昂的架构。为了解决这些双重挑战，我们引入了APN，一个通用且高效的预测框架。APN的核心是一个新颖的时间感知补丁聚合（TAPA）模块，它引入了一种基于聚合的范式进行自适应补丁处理，超越了固定跨度分割和基于插值的方法的局限性。TAPA首先学习动态时间边界以定义数据驱动的段。关键是，它不是重新采样或插值，而是通过对所有原始观测值进行时间感知加权聚合来直接计算补丁表示，其中权重由每个观测值对该段的时间相关性决定。这种方法提供了两个关键优势：它通过避免引入人工数据点来保留数据保真度，并通过设计确保完整的信息覆盖。由此产生的正则化和信息丰富的补丁表示使得可以使用轻量级查询模块进行历史上下文聚合，并使用简单的MLP进行最终预测。在多个真实世界数据集上的广泛实验表明，APN建立了一个新的最先进水平，在预测精度和计算效率方面均显著优于现有方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [462] [Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings](https://arxiv.org/abs/2508.00039)
> *用于高速公路-铁路平交道口剖面分析的混合LSTM-Transformer模型*

*Kaustav Chatterjee, Joshua Q. Li, Fatemeh Ansari, Masud Rana Munna, Kundan Parajulee, Jared Schwennesen* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 混合LSTM-Transformer, 高速公路-铁路平交道口, 剖面分析, 深度学习, 交通安全

**Comment:** 

> **TL;DR:** 本研究开发并评估了一种新颖的混合LSTM-Transformer深度学习框架，用于高效、准确地测量高速公路-铁路平交道口（HRGC）的剖面，以解决传统方法成本高、耗时且不安全的问题，并提高交通安全性。

**AI_Comments:** 本论文的创新点在于提出了混合LSTM-Transformer深度学习框架，将两种强大的序列建模能力结合起来，以解决传统HRGC剖面测量方法的局限性。其重要性在于提供了一种成本效益高、高效且安全的HRGC剖面分析方法，这对于提高高速公路和铁路的安全性具有实际应用价值。该研究通过实地数据验证了模型的有效性，展现了深度学习在交通基础设施安全评估方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 凸起平交道口（高速公路-铁路平交道口，HRGCs）对公路车辆构成潜在的搁浅安全风险。传统的HRGC剖面测量方法成本高昂、耗时、干扰交通且存在安全挑战。为了解决这些问题，本研究旨在采用先进、经济高效的技术和创新的建模方法进行HRGC剖面测量。

**Method:** 本研究开发了一种结合长短期记忆（LSTM）和Transformer架构的新型混合深度学习框架。通过配备惯性测量单元（IMU）和全球定位系统（GPS）传感器的高速公路测试车辆收集仪表数据，并通过工业标准步行测量仪获得地面实况数据。在俄克拉荷马州的Red Rock铁路走廊收集了现场数据。评估了三种先进的深度学习模型：Transformer-LSTM顺序模型（模型1）、LSTM-Transformer顺序模型（模型2）和LSTM-Transformer并行模型（模型3），以识别最有效的架构。

**Result:** 模型2（LSTM-Transformer顺序）和模型3（LSTM-Transformer并行）表现优于其他模型，并被部署用于生成2D/3D HRGC剖面。这些深度学习模型展示了通过实现对HRGC搁浅敏感性的快速准确评估来增强公路和铁路安全的巨大潜力。

**Conclusion:** 深度学习模型在快速准确评估高速公路-铁路平交道口（HRGC）搁浅敏感性方面展现出显著潜力，从而能够提高公路和铁路的安全性。

> **ai_Abstract:** 本研究旨在解决传统高速公路-铁路平交道口（HRGC）剖面测量方法存在的问题，这些方法成本高、耗时且不安全。研究开发了一种新颖的混合深度学习框架，结合了LSTM和Transformer架构，用于高效、准确地测量HRGC剖面。通过配备IMU和GPS传感器的高速公路测试车辆收集仪表数据，并结合步行测量仪获取地面实况数据。在评估了三种模型后，LSTM-Transformer顺序模型和LSTM-Transformer并行模型表现最佳，并成功用于生成2D/3D HRGC剖面。该方法有望显著提高公路和铁路的安全性。

> **摘要翻译:** 驼峰式平交道口，即高剖面高速公路-铁路平交道口（HRGCs），由于可能导致车辆搁浅而对公路车辆构成安全风险。这些平交道口通常是由于施工后的铁路轨道维护活动或不符合HRGC垂直对齐设计指南而产生的。传统的HRGC剖面测量方法成本高昂、耗时、干扰交通且存在安全挑战。为了解决这些问题，本研究采用了先进、经济高效的技术和创新的建模方法进行HRGC剖面测量。通过利用仪器数据和地面实况数据，开发了一种结合长短期记忆（LSTM）和Transformer架构的新型混合深度学习框架。仪器数据是使用配备惯性测量单元（IMU）和全球定位系统（GPS）传感器的高速公路测试车辆收集的，而地面实况数据是通过工业标准步行测量仪获得的。现场数据是在俄克拉荷马州的Red Rock铁路走廊收集的。评估了三种先进的深度学习模型：Transformer-LSTM顺序模型（模型1）、LSTM-Transformer顺序模型（模型2）和LSTM-Transformer并行模型（模型3），以识别最有效的架构。模型2和模型3表现优于其他模型，并被部署用于生成2D/3D HRGC剖面。这些深度学习模型通过实现对HRGC搁浅敏感性的快速准确评估，展示了增强公路和铁路安全的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [463] [Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs](https://arxiv.org/abs/2508.00161)
> *观察权重：微调LLM的无监督监控与控制*

*Ziqian Zhong, Aditi Raghunathan* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-31**

**Keywords:** 微调LLM, 权重解释, 无监督监控, 后门检测, 模型审计

**Comment:** 

> **TL;DR:** 提出一种基于权重的新方法，用于无监督监控和控制微调LLM，有效检测后门等异常行为。

**AI_Comments:** 该论文提出了一种创新的基于权重而非激活的LLM可解释性方法，有效解决了传统方法在处理分布外数据时的局限性。其在检测后门攻击、识别遗忘信息以及模型审计方面的卓越性能，显示了其在保障LLM安全性和透明度方面的巨大潜力。这项工作为LLM的部署和监管提供了重要的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于激活的LLM可解释性方法通常需要或假设分布相似的数据，这在检测和防御像后门这种分布外的新型威胁时存在显著局限性。

**Method:** 本文提出一种解释模型权重而非激活的新方法，避免了对分布相似数据的需求。该方法通过分析微调模型与基础模型之间权重差异的顶部奇异向量来识别新获得的模型行为，并通过监控激活沿这些方向的余弦相似度来高精度检测微调引入的显著行为。

**Result:** 对于后门模型，该方法能阻止高达100%的攻击，误报率低于1.2%。对于经历过遗忘的模型，检测到被擦除主题的推理准确率高达95.42%，甚至可以引导模型恢复“遗忘”信息。此外，该方法还显示出部署前模型审计的潜力，通过分析商业指令微调模型（OLMo、Llama、Qwen），能够揭示模型特定的微调重点，包括营销策略和Midjourney提示生成。

**Conclusion:** 该方法通过解释权重而非激活，有效地实现了对微调LLM的无监督监控和控制，尤其在检测分布外威胁和模型审计方面表现出色。

> **ai_Abstract:** 针对现有LLM可解释性方法在检测分布外威胁时的局限性，本文提出一种名为“观察权重”的新方法。该方法通过分析微调模型与基础模型之间权重差异的顶部奇异向量来识别新获得的模型行为，并通过监控激活的余弦相似度来高精度检测行为。实验证明，该方法能有效防御后门攻击（100%阻止，误报率低于1.2%），高精度检测遗忘模型（95.42%准确率），并揭示商业模型的微调重点，为LLM的无监督监控、控制和部署前审计提供了新途径。

> **摘要翻译:** 强大的开源大型语言模型（LLM）的发布通常不附带对其完整训练数据的访问权限。现有的可解释性方法，特别是那些基于激活的方法，通常需要或假设分布相似的数据。这在检测和防御像后门这种本质上是分布外的新型潜在威胁时，是一个显著的局限。
在这项工作中，我们引入了一种理解、监控和控制微调LLM的新方法，该方法解释的是权重，而非激活，从而避免了对与未知训练数据分布相似的数据的需求。我们证明，微调模型与其基础模型之间权重差异的顶部奇异向量对应于新获得的行为。通过监控激活沿这些方向的余弦相似度，我们可以高精度地检测微调过程中引入的显著行为。
对于在秘密触发器存在时绕过安全机制的后门模型，我们的方法可以阻止高达100%的攻击，而误报率低于1.2%。对于经过遗忘的模型，我们以高达95.42%的准确率检测到对被擦除主题的推理，甚至可以引导模型恢复“被遗忘”的信息。除了监控，我们的方法还显示出部署前模型审计的潜力：通过分析商业指令微调模型（OLMo、Llama、Qwen），我们能够揭示模型特定的微调重点，包括营销策略和Midjourney提示生成。
我们的实现代码可在 https://github.com/fjzzq2002/WeightWatch 找到。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [465] [KFS: KAN based adaptive Frequency Selection learning architecture for long term time series forecasting](https://arxiv.org/abs/2508.00635)
> *KFS: 基于KAN的自适应频率选择学习架构，用于长期时间序列预测*

*Changning Wu, Gao Wu, Rongyao Cai, Yong Liu, Kexin Zhang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 时间序列预测, KAN, 频率选择, 多尺度分解, 深度学习

**Comment:** 

> **TL;DR:** KFS是一种基于KAN的自适应频率选择学习架构，通过处理跨尺度噪声和复杂模式，在长期时间序列预测中实现了最先进的性能。

**AI_Comments:** KFS创新性地将KAN与频率选择机制相结合，以解决时间序列预测中的噪声和复杂模式问题。其新颖的FreK模块和对齐机制提升了多尺度表示的质量，使其在实际应用中具有重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多尺度分解架构在时间序列预测中存在跨尺度噪声干扰和不同频率分量间异构信息分布导致次优多尺度表示的问题。

**Method:** 受Kolmogorov-Arnold Networks (KAN)和Parseval定理启发，本文提出了KFS架构。该框架通过其FreK模块在频谱域进行基于能量分布的主导频率选择，以解决跨尺度噪声干扰和复杂模式建模的预测挑战。同时，KAN实现了复杂的模式表示，时间戳嵌入对齐同步了跨尺度的时间表示。特征混合模块融合了尺度特定的模式与对齐的时间特征。

**Result:** 在多个真实世界时间序列数据集上的广泛实验表明，KFS（KT可能是笔误，应为KFS）作为一种简单而有效的架构，实现了最先进的性能。

**Conclusion:** KFS架构通过其自适应频率选择和复杂的模式表示能力，有效解决了时间序列预测中的挑战，并取得了最先进的性能。

> **ai_Abstract:** 本文提出了一种名为KFS（KAN based adaptive Frequency Selection）的新型学习架构，用于长期时间序列预测。KFS旨在解决现有方法中存在的跨尺度噪声干扰和复杂模式表示不足的问题。它引入了FreK模块进行基于能量分布的主导频率选择，并利用KAN进行复杂模式表示。此外，通过时间戳嵌入对齐和特征混合模块，KFS能够有效融合跨尺度的时序信息。实验证明，KFS在多个真实世界数据集上取得了最先进的性能。

> **摘要翻译:** 多尺度分解架构已成为时间序列预测中的主要方法。然而，真实世界的时间序列在不同尺度上表现出噪声干扰，而不同尺度频率分量之间异构的信息分布导致次优的多尺度表示。受Kolmogorov-Arnold Networks (KAN)和Parseval定理的启发，我们提出了一种基于KAN的自适应频率选择学习架构（KFS）来解决这些挑战。该框架通过其FreK模块在频谱域进行基于能量分布的主导频率选择，从而解决了跨尺度噪声干扰和复杂模式建模带来的预测挑战。同时，KAN实现了复杂的模式表示，而时间戳嵌入对齐同步了跨尺度的时间表示。然后，特征混合模块将尺度特定的模式与对齐的时间特征融合。在多个真实世界时间序列数据集上的广泛实验表明，KT（可能是KFS的笔误）作为一种简单而有效的架构，实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [474] [SPLITZ: Certifiable Robustness via Split Lipschitz Randomized Smoothing](https://arxiv.org/abs/2407.02811)
> *SPLITZ: 通过分段 Lipschitz 随机平滑实现可认证鲁棒性*

*Meiyu Zhong, Ravi Tandon* | **Category: cs.LG, cs.IT, math.IT** | **Updated: 2025-07-31**

**Keywords:** 可认证鲁棒性, Lipschitz 常数, 随机平滑, 对抗性鲁棒性, 深度学习

**Comment:** IEEE Transactions on Information Forensics and Security, accepted

> **TL;DR:** SPLITZ 是一种新颖的方法，它结合了小 Lipschitz 常数和随机平滑的优点，通过将分类器分成两半来提高可认证鲁棒性，并在多个数据集上超越了现有最先进的方法。

**AI_Comments:** SPLITZ 的创新之处在于其“分而治之”的策略，将 Lipschitz 约束和随机平滑这两种主要的可认证鲁棒性技术巧妙地结合起来。这种方法不仅利用了深度网络内在的异质性，还提升了鲁棒性准确率的权衡，为对抗性鲁棒性研究提供了一个新颖且高效的途径。其在多个数据集上超越SOTA的性能证明了该方法的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度网络在不同层之间表现出 Lipschitz 常数的异质性，SPLITZ 的动机在于利用这种异质性，同时继承随机平滑的可扩展性，以提供更好的可认证鲁棒性。

**Method:** SPLITZ 将分类器分成两半，约束前半部分的 Lipschitz 常数，并通过随机化平滑后半部分。该方法提供了一种原则性的训练方法和理论分析，以在推理过程中获得认证鲁棒性保证。

**Result:** SPLITZ 在 MNIST、CIFAR-10 和 ImageNet 数据集上始终优于现有最先进的方法，在鲁棒性-准确性权衡方面表现出色。例如，在 CIFAR-10 数据集上，当 $\ell_2$ 范数扰动预算为 $\epsilon=1$ 时，SPLITZ 实现了 43.2% 的 top-1 测试准确率，而现有最先进的 top-1 测试准确率为 39.8%。

**Conclusion:** SPLITZ 通过结合 Lipschitz 约束和随机平滑的优势，提出了一种有效且实用的方法来提高深度学习模型的可认证鲁棒性，并在多个基准测试中取得了显著的性能提升。

> **ai_Abstract:** 本文提出了一种名为 SPLITZ 的新方法，旨在提高分类器的可认证鲁棒性。它结合了两种现有策略：约束 Lipschitz 常数和随机平滑。SPLITZ 的核心思想是将分类器分为两部分，对第一部分施加 Lipschitz 约束，并通过随机化平滑第二部分。这种方法利用了深度网络层间 Lipschitz 常数的异质性，并继承了随机平滑的可扩展性。作者提供了一种原则性的训练方法和理论分析，并在 MNIST、CIFAR-10 和 ImageNet 数据集上展示了 SPLITZ 在鲁棒性-准确性权衡方面优于现有最先进的性能。

> **摘要翻译:** 可认证鲁棒性保证了分类器输入周围的小扰动不会改变预测结果。有两种方法可以为对抗性示例提供可认证鲁棒性：a) 明确训练具有小 Lipschitz 常数的分类器，以及 b) 随机平滑，它通过向输入添加随机噪声来创建平滑分类器。我们提出了 SPLITZ，这是一种实用且新颖的方法，它将上述两种思想的协同优势整合到一个单一框架中。我们的主要思想是将分类器分成两半，约束前半部分的 Lipschitz 常数，并通过随机化平滑后半部分。SPLITZ 的动机来自于观察到许多标准深度网络在不同层之间表现出 Lipschitz 常数的异质性。SPLITZ 可以利用这种异质性，同时继承随机平滑的可扩展性。我们提出了一种训练 SPLITZ 的原则性方法，并提供了理论分析以在推理过程中获得认证鲁棒性保证。我们对鲁棒性-准确性权衡进行了全面比较，并表明 SPLITZ 在 MNIST、CIFAR-10 和 ImageNet 数据集上始终优于现有最先进的方法。例如，当 $\ell_2$ 范数扰动预算为 $\epsilon=1$ 时，SPLITZ 在 CIFAR-10 数据集上实现了 43.2% 的 top-1 测试准确率，而现有最先进的 top-1 测试准确率为 39.8%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [479] [Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product](https://arxiv.org/abs/2508.00230)
> *利用Khatri--Rao积实现参数高效微调中更高有效秩的方法研究*

*Paul Albert, Frederic Z. Zhang, Hemanth Saratchandran, Anton van den Hengel, Ehsan Abbasnejad* | **Category: cs.LG, cs.CL, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 参数高效微调, Khatri-Rao积, 有效秩, LoRA, KRAdapter

**Comment:** To appear in ICCV 2025

> **TL;DR:** 本文提出KRAdapter，一种利用Khatri-Rao积的参数高效微调方法，旨在解决LoRA在处理高有效秩模型时性能不佳的问题，并在视觉-语言模型和大型语言模型上取得了性能提升，同时保持了高效性。

**AI_Comments:** 这篇论文通过引入Khatri-Rao积来解决LoRA在处理高有效秩数据时的局限性，具有创新性。它不仅从理论上分析了LoRA的不足，还提出了一种新的算法KRAdapter，并在实际模型上验证了其有效性。该方法保持了PEFT的效率优势，同时提升了模型在复杂任务上的表现，对于推动PEFT技术在多模态和大型语言模型中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的参数高效微调方法（如LoRA）在应用于多模态和大型语言模型时存在局限性，特别是在处理具有较高有效秩（如平坦谱或高频分量）的矩阵时表现不佳。

**Method:** 作者首先使用受控谱性质的合成矩阵近似基准对全秩和低秩PEFT方法进行了定量比较，以确认LoRA的局限性。随后，他们引入了KRAdapter，这是一种新型的PEFT算法，利用Khatri-Rao积来生成权重更新，其构造本身倾向于产生高有效秩的矩阵乘积。

**Result:** 实验结果证实LoRA难以近似具有相对平坦谱或高频分量（高有效秩的标志）的矩阵。KRAdapter在参数量高达10亿的视觉-语言模型和参数量高达80亿的大型语言模型上，特别是在未见的常识推理任务上，均表现出性能提升。此外，KRAdapter保持了LoRA的内存和计算效率。

**Conclusion:** KRAdapter是一种实用且强大的参数高效微调替代方案，适用于数十亿参数规模的模型，能够有效解决LoRA在高有效秩场景下的性能瓶颈。

> **ai_Abstract:** 本文针对LoRA等参数高效微调方法在处理高有效秩模型时的局限性，提出了一种名为KRAdapter的新型PEFT算法。通过定量比较，作者证实了LoRA在近似高有效秩矩阵时的不足。KRAdapter利用Khatri-Rao积生成权重更新，天然倾向于产生高有效秩的矩阵乘积。实验证明，KRAdapter在视觉-语言模型和大型语言模型上均取得了性能提升，尤其是在常识推理任务上，同时保持了与LoRA相当的内存和计算效率，为大规模模型微调提供了一个实用且鲁棒的替代方案。

> **摘要翻译:** 参数高效微调（PEFT）已成为适应大型预训练模型的标准方法。在PEFT方法中，低秩适应（LoRA）取得了显著成功。然而，最近的研究强调了与全秩替代方案相比，LoRA的局限性，特别是在应用于多模态和大型语言模型时。在这项工作中，我们使用具有受控谱特性的合成矩阵近似基准，对全秩和低秩PEFT方法进行了定量比较。我们的结果证实，LoRA难以近似具有相对平坦谱或高频分量（高有效秩的迹象）的矩阵——这些都是高有效秩的标志。为此，我们引入了KRAdapter，一种新颖的PEFT算法，它利用Khatri-Rao积来产生权重更新，通过构造，这种更新倾向于产生高有效秩的矩阵乘积。我们展示了KRAdapter在参数量高达10亿的视觉-语言模型和参数量高达80亿的大型语言模型上的性能提升，特别是在未见的常识推理任务上。此外，KRAdapter保持了LoRA的内存和计算效率，使其成为微调数十亿参数模型的实用且鲁棒的替代方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [481] [Conformal Predictive Distributions for Order Fulfillment Time Forecasting](https://arxiv.org/abs/2505.17340)
> *订单履行时间预测的共形预测分布*

*Tinghan Ye, Amira Hijazi, Pascal Van Hentenryck* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 共形预测, 订单履行时间, 分布预测, 机器学习, 电商物流

**Comment:** 

> **TL;DR:** 本文提出了一种基于共形预测系统和交叉Venn-Abers预测器的新框架，用于预测订单履行时间，并在工业数据集上取得了显著的性能提升。

**AI_Comments:** 本文的创新点在于将共形预测系统和交叉Venn-Abers预测器应用于订单履行时间预测，这两种技术提供了严格的预测保证，解决了传统方法难以捕捉不确定性的问题。其模型无关的特性也增加了方法的普适性。在实际工业数据集上的显著性能提升，特别是识别延迟交付方面的改进，表明了该方法在实际应用中的重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 电商物流中准确估计订单履行时间至关重要，但传统基于规则的方法难以捕捉交付操作中的固有不确定性。

**Method:** 本文引入了一种新的订单履行时间分布预测框架，利用共形预测系统（Conformal Predictive Systems）和交叉Venn-Abers预测器（Cross Venn-Abers Predictors）。这些模型无关的技术提供严格的覆盖或有效性保证。所提出的机器学习方法整合了细粒度的时空特征，捕捉履约地点和承运商性能动态。此外，还开发了一种成本敏感的决策规则，将概率预测转换为可靠的点预测。

**Result:** 在大型工业数据集上的实验评估表明，所提出的方法生成了具有竞争力的分布预测，而基于机器学习的点预测显著优于现有的基于规则的系统——预测准确率提高了14%，识别延迟交付的准确率提高了75%。

**Conclusion:** 本文提出的基于共形预测系统和交叉Venn-Abers预测器的机器学习方法，能够显著提高订单履行时间的预测准确性和延迟交付的识别能力，优于传统规则系统。

> **ai_Abstract:** 本文提出了一种利用共形预测系统和交叉Venn-Abers预测器的新型框架，用于电商物流中的订单履行时间分布预测。该方法结合细粒度时空特征和成本敏感决策规则，旨在提高预测准确性。在工业数据集上的实验结果表明，该机器学习方法在分布预测方面具有竞争力，且在点预测方面显著优于传统规则系统，尤其在预测准确率和识别延迟交付方面有显著提升。

> **摘要翻译:** 准确估计订单履行时间对于电商物流至关重要，但传统的基于规则的方法往往无法捕捉交付操作中固有的不确定性。本文引入了一种新的订单履行时间分布预测框架，利用共形预测系统和交叉Venn-Abers预测器——这些是模型无关的技术，提供严格的覆盖或有效性保证。所提出的机器学习方法整合了细粒度的时空特征，捕捉履约地点和承运商性能动态，以提高预测准确性。此外，还开发了一种成本敏感的决策规则，将概率预测转换为可靠的点预测。在大型工业数据集上的实验评估表明，所提出的方法生成了具有竞争力的分布预测，而基于机器学习的点预测显著优于现有的基于规则的系统——预测准确率提高了14%，识别延迟交付的准确率提高了75%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [490] [Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense](https://arxiv.org/abs/2508.00641)
> *用于无人机蜂群防御中决策级拦截优先级的强化学习*

*Alessandro Palmas* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 强化学习, 无人机蜂群, 拦截优先级, 防御系统, 决策级

**Comment:** 11 pages, 10 figures

> **TL;DR:** 本文展示了一个案例研究，其中强化学习（RL）被应用于无人机蜂群防御中的拦截优先级决策。通过在高保真模拟环境中训练，RL智能体在保护关键区域方面表现出比基于规则的基线更低的平均损害和更高的防御效率。

**AI_Comments:** 该论文通过在高保真模拟环境中应用强化学习来解决无人机蜂群防御中的关键拦截优先级问题，具有创新性。其重要性在于展示了RL在复杂军事决策中的实际优势，并且其开源代码和模拟资产确保了研究的可复现性，这对于推动该领域的发展至关重要。将RL作为不取代现有控制系统的“战略层”的理念，也为未来的集成提供了实用路径。

<details>
  <summary>Details</summary>

**Motivation:** 低成本自杀式无人机蜂群的日益增长的威胁对现代防御系统构成了严峻挑战，需要快速和战略性的决策来优先处理多重效应器和高价值目标区域的拦截。

**Method:** 本文引入了一个高保真模拟环境，捕捉真实的作战约束。在此环境中，一个决策级强化学习智能体学习协调多个效应器以实现最优拦截优先级。该智能体在离散动作空间中操作，根据观察到的状态特征（如位置、类别和效应器状态）选择每个效应器要打击的无人机。所学策略与手工制作的基于规则的基线在数百个模拟攻击场景中进行了评估。

**Result:** 基于强化学习的策略在保护关键区域方面始终实现了更低的平均损害和更高的防御效率。

**Conclusion:** 本案例研究强调了强化学习作为防御架构中战略层的潜力，能够在不取代现有控制系统的情况下增强防御弹性。

> **ai_Abstract:** 本文探讨了强化学习在应对低成本自杀式无人机蜂群威胁中的应用，特别是在防御系统中决策级拦截优先级方面。研究人员开发了一个高保真模拟环境，并训练了一个强化学习智能体来协调多个效应器以优化拦截。通过与传统规则基线进行比较，结果表明强化学习策略在降低损害和提高防御效率方面表现更优，证明了其作为现有防御系统战略补充的潜力。

> **摘要翻译:** 低成本自杀式无人机蜂群日益增长的威胁对现代防御系统构成了严峻挑战，需要快速和战略性的决策来优先处理多重效应器和高价值目标区域的拦截。在这项工作中，我们提出了一个案例研究，展示了强化学习在解决这一挑战方面的实际优势。我们引入了一个高保真模拟环境，捕捉真实的作战约束，在该环境中，一个决策级强化学习智能体学习协调多个效应器以实现最优拦截优先级。该智能体在离散动作空间中操作，根据观察到的状态特征（如位置、类别和效应器状态）选择每个效应器要打击的无人机。我们对所学策略与手工制作的基于规则的基线在数百个模拟攻击场景中进行了评估。基于强化学习的策略在保护关键区域方面始终实现了更低的平均损害和更高的防御效率。本案例研究强调了强化学习作为防御架构中战略层的潜力，能够在不取代现有控制系统的情况下增强防御弹性。所有代码和模拟资产都已公开发布，以实现完全可复现性，并且视频演示说明了该策略的定性行为。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [492] [Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages](https://arxiv.org/abs/2508.00041)
> *像人类一样学习：通过认知发展阶段实现资源高效的联邦微调*

*Yebo Wu, Jingguang Li, Zhijiang Guo, Li Li* | **Category: cs.LG, cs.AI, cs.DC** | **Updated: 2025-07-31**

**Keywords:** 联邦微调, 资源高效, 认知发展, 大型语言模型, 边缘设备

**Comment:** 

> **TL;DR:** DevFT是一种受认知发展启发的资源高效联邦微调方法，它将微调过程分解为多个发展阶段，通过知识转移和分层技术显著提高了LLM在边缘设备上的收敛速度、降低了通信开销并提升了性能。

**AI_Comments:** DevFT的创新之处在于其将人类认知发展理论引入到联邦微调中，通过分阶段学习和知识转移，有效解决了LLM在边缘设备上部署的资源效率问题。这种模仿人类学习范式的方法，不仅提高了训练效率，还降低了通信成本，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 联邦微调虽然能在保护数据隐私的同时使大型语言模型（LLMs）适应下游任务，但其资源密集型特性限制了在边缘设备上的部署。

**Method:** 本文提出了一种名为“发展性联邦微调”（DevFT）的资源高效方法，该方法受认知发展启发，逐步从紧凑的基础构建强大的LLM。DevFT将微调过程分解为多个发展阶段，每个阶段优化具有增加参数容量的子模型。早期阶段的知识会转移到后续子模型，提供优化的初始化参数以防止收敛到局部最小值并加速训练。为了高效构建特定阶段的子模型，DevFT引入了冲突消除引导的层分组和基于差异的层融合，以提取基本信息并构建代表性层。

**Result:** 在多个基准测试中，DevFT显著优于现有最先进的方法，实现了高达4.59倍的收敛速度提升，10.67倍的通信开销减少，以及平均9.07%的性能提升，同时保持与现有方法的兼容性。

**Conclusion:** DevFT通过模拟人类学习的认知发展阶段，提供了一种资源高效的联邦微调方法，显著提升了LLM在边缘设备上的部署效率和性能。

> **ai_Abstract:** 本文提出了一种名为发展性联邦微调（DevFT）的创新方法，旨在解决联邦微调在边缘设备上资源消耗大的问题。DevFT受人类认知发展启发，将LLM微调过程分解为多个渐进阶段，通过知识转移和分层技术优化子模型。实验结果表明，DevFT在收敛速度、通信开销和性能方面均显著优于现有方法，为资源受限环境下的LLM部署提供了高效解决方案。

> **摘要翻译:** 联邦微调使大型语言模型（LLMs）能够适应下游任务，同时保护数据隐私，但其资源密集型特性限制了在边缘设备上的部署。在本文中，我们引入了发展性联邦微调（DevFT），这是一种受认知发展启发的资源高效方法，它逐步从紧凑的基础构建强大的LLM。DevFT将微调过程分解为发展阶段，每个阶段优化具有增加参数容量的子模型。早期阶段的知识转移到后续子模型，提供优化的初始化参数，防止收敛到局部最小值并加速训练。这种范式模仿了人类学习，逐渐构建全面的知识结构，同时完善现有技能。为了高效构建特定阶段的子模型，DevFT引入了冲突消除引导的层分组和基于差异的层融合，以提取基本信息并构建代表性层。在多个基准测试中的评估表明，DevFT显著优于现有最先进的方法，实现了高达4.59倍的收敛速度提升，10.67倍的通信开销减少，以及平均9.07%的性能提升，同时保持与现有方法的兼容性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [497] [Disentangling Neural Disjunctive Normal Form Models](https://arxiv.org/abs/2507.10546)
> *解耦神经析取范式模型*

*Kexin Gu Baugh, Vincent Perreault, Matthew Baugh, Luke Dickens, Katsumi Inoue, Alessandra Russo* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 神经析取范式, 解耦, 神经符号学习, 可解释性, 分类

**Comment:** Accepted at NeSy 2025

> **TL;DR:** 本文提出了一种新的解耦方法，通过拆分嵌套规则节点来提高神经析取范式模型的性能，使其在符号转换后性能更接近原始模型。

**AI_Comments:** 本文的创新点在于提出了一种针对神经析取范式模型的新型解耦方法，有效解决了其在符号转换过程中性能下降的问题。通过结构化的节点拆分，该方法不仅提升了模型性能，还增强了其可解释性，这对于神经符号学习领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 神经析取范式（DNF）模型在训练后符号转换过程中，由于阈值化处理，其性能会下降。部分性能下降是由于未能解耦网络权重中表示的学习知识。

**Method:** 我们提出了一种新的解耦方法，通过将编码嵌套规则的节点拆分为更小的独立节点，从而更好地保持模型的性能。

**Result:** 在二分类、多分类和多标签分类任务上的实验表明，我们的解耦方法为神经DNF模型提供了紧凑且可解释的逻辑表示，性能更接近其预转换的对应模型。

**Conclusion:** 本文提出的解耦方法有效提升了神经析取范式模型在符号转换后的性能，并提供了可解释的逻辑表示。

> **ai_Abstract:** 本研究旨在解决神经析取范式（DNF）模型在后训练符号转换过程中性能下降的问题。作者指出，性能下降部分归因于未能解耦模型中学到的知识。为此，论文提出了一种新的解耦方法，通过将编码嵌套规则的节点拆分成更小的独立节点，从而有效保留模型的性能。实验证明，该方法在多种分类任务中为神经DNF模型提供了紧凑且可解释的逻辑表示，并使其性能更接近于转换前的表现。

> **摘要翻译:** 神经析取范式（DNF）模型是强大且可解释的神经符号学习方法，在分类和强化学习设置中，无需任务先验知识即可显示出有前景的结果。然而，它们的性能在训练后符号转换过程中的阈值化处理下会下降。我们在此展示，转换过程中部分性能下降是由于未能解耦网络权重中表示的学习知识。我们通过提出一种新的解耦方法来解决这个问题；通过将编码嵌套规则的节点拆分为更小的独立节点，我们能够更好地保持模型的性能。通过在二分类、多分类和多标签分类任务（包括需要谓词发明）上的实验，我们证明了我们的解耦方法为神经DNF模型提供了紧凑且可解释的逻辑表示，其性能更接近于其预转换的对应模型。我们的代码可在 https://github.com/kittykg/disentangling-ndnf-classification 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [506] [How to Evaluate Participant Contributions in Decentralized Federated Learning](https://arxiv.org/abs/2505.23246)
> *如何在去中心化联邦学习中评估参与者贡献*

*Honoka Anada, Tatsuya Kaneko, Shinya Takamaeda-Yamazaki* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 去中心化联邦学习, 参与者贡献, Shapley值, TRIP-Shapley, 模型评估

**Comment:** 

> **TL;DR:** 去中心化联邦学习（DFL）中评估参与者贡献至关重要，但现有方法不适用。本文提出TRIP-Shapley，一种通过追踪贡献传播来解决DFL挑战的新方法，经验证其准确、可扩展且对不诚实客户端具有鲁棒性。

**AI_Comments:** 本文的创新点在于提出了TRIP-Shapley，它专门解决了去中心化联邦学习中贡献评估的独特挑战，即非邻近模型不可访问性和贡献传播追踪的复杂性。其轻量级协调节点的设计，无需收集模型，显著提升了方法的实用性和效率，对于促进DFL的公平激励和透明度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在去中心化联邦学习（DFL）中，评估参与者贡献对于激励积极参与和增强透明度至关重要。然而，现有的联邦学习贡献评估方法都假定集中式设置，由于以下两个挑战无法直接应用于DFL：一是每个客户端无法访问非邻近客户端的模型；二是需要追溯贡献如何与点对点模型交换随时间传播。

**Method:** 本文提出TRIP-Shapley，一种新颖的DFL贡献评估方法。TRIP-Shapley通过追踪轮次局部贡献的传播来计算客户端的整体贡献。通过这种方式，TRIP-Shapley准确反映了延迟和渐进的影响传播，并允许轻量级协调节点仅基于每个客户端报告的局部可观察贡献来估算整体贡献，而无需收集模型。

**Result:** 实验表明，TRIP-Shapley足够接近真实Shapley值，可扩展到大规模场景，并且在存在不诚实客户端的情况下仍保持鲁棒性。

**Conclusion:** TRIP-Shapley有效解决了去中心化联邦学习中评估参与者贡献的挑战，提供了一种准确、可扩展且鲁棒的解决方案。

> **ai_Abstract:** 去中心化联邦学习（DFL）由于其固有的去中心化特性和贡献传播的复杂性，在评估参与者贡献方面面临挑战。本文提出TRIP-Shapley，一种新颖的评估方法，通过追踪局部贡献的传播来量化参与者的整体价值。该方法允许一个轻量级协调节点仅基于客户端报告的本地可观察贡献来估计整体贡献，而无需收集模型。实验结果验证了TRIP-Shapley在准确性、可扩展性和对不诚实客户端的鲁棒性方面的有效性。

> **摘要翻译:** 联邦学习（FL）允许多个客户端协同训练机器学习模型，而无需共享本地数据。特别是，去中心化联邦学习（DFL），即客户端无需中央服务器即可交换模型，因其缓解通信瓶颈而受到关注。在DFL中评估参与者贡献对于激励积极参与和增强透明度至关重要。然而，现有的FL贡献评估方法都假定集中式设置，由于以下两个挑战无法直接应用于DFL：一是每个客户端无法访问非邻近客户端的模型；二是需要追溯贡献如何与点对点模型交换随时间传播。为了解决这些挑战，我们提出了TRIP-Shapley，一种新颖的DFL贡献评估方法。TRIP-Shapley通过追踪轮次局部贡献的传播来计算客户端的整体贡献。通过这种方式，TRIP-Shapley准确反映了延迟和渐进的影响传播，并允许轻量级协调节点仅基于每个客户端报告的局部可观察贡献来估算整体贡献，而无需收集模型。实验表明，TRIP-Shapley足够接近真实Shapley值，可扩展到大规模场景，并且在存在不诚实客户端的情况下仍保持鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [515] [Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators](https://arxiv.org/abs/2508.00643)
> *傅里叶神经算子的轻量级扩散乘数与不确定性量化*

*Albert Matveev, Sanmitra Ghosh, Aamal Hussain, James-Michael Leahy, Michalis Michaelides* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 傅里叶神经算子, 不确定性量化, 扩散乘数, 轻量级, 贝叶斯神经算子

**Comment:** 

> **TL;DR:** DINOZAUR引入了一种基于扩散的轻量级傅里叶神经算子参数化方法，通过替换密集张量乘数来减少参数，并提供原生的贝叶斯不确定性量化。

**AI_Comments:** DINOZAUR的创新之处在于其引入的维度无关扩散乘数，这不仅显著降低了傅里叶神经算子的参数量和内存需求，还通过贝叶斯框架实现了原生的不确定性量化，解决了现有FNOs在可扩展性和可靠性方面的核心痛点。这种方法为科学和工程领域提供了一个更高效、更可靠的偏微分方程求解工具。

<details>
  <summary>Details</summary>

**Motivation:** 傅里叶神经算子（FNOs）在解决偏微分方程方面面临可扩展性挑战，主要由于过度参数化，并且缺乏原生的不确定性量化（UQ）能力，而UQ是科学和工程应用中可靠性的关键要求。现有的UQ方法通常是事后进行的，并忽略了几何归纳偏差。

**Method:** 本文提出了DINOZAUR，一种基于扩散的神经算子参数化方法，并具有不确定性量化能力。受热核结构的启发，DINOZAUR用一个维度无关的扩散乘数替换了FNOs中的密集张量乘数，该乘数每个通道只有一个可学习的时间参数，从而显著减少了参数数量和内存占用。通过对这些时间参数定义先验，DINOZAUR被构建为一个贝叶斯神经算子，以产生空间相关的输出和校准的不确定性估计。

**Result:** DINOZAUR在多个偏微分方程基准测试中实现了有竞争力或更优的性能，同时提供了高效的不确定性量化。

**Conclusion:** DINOZAUR通过引入轻量级扩散乘数和贝叶斯不确定性量化，成功解决了傅里叶神经算子在可扩展性和可靠性方面的关键挑战，使其成为解决偏微分方程的更高效和可靠的工具。

> **ai_Abstract:** 本文提出了DINOZAUR，一种新型的傅里叶神经算子（FNO）参数化方法，旨在解决现有FNOs的过度参数化和缺乏原生不确定性量化（UQ）的问题。DINOZAUR通过引入一个轻量级的维度无关扩散乘数，替代了传统的密集张量乘数，显著减少了模型参数和内存占用。此外，通过对扩散参数设置先验，DINOZAUR被构建为一个贝叶斯神经算子，能够提供空间相关的输出和校准的不确定性估计。实验结果表明，DINOZAUR在保持或超越现有性能的同时，实现了高效且原生的不确定性量化。

> **摘要翻译:** 算子学习是解决偏微分方程的强大范式，其中傅里叶神经算子（FNOs）作为广泛采用的基础。然而，FNOs由于过度参数化而面临显著的可扩展性挑战，并且不提供原生的不确定性量化——这是可靠科学和工程应用的关键要求。相反，神经算子依赖于事后UQ方法，这些方法忽略了几何归纳偏差。在这项工作中，我们引入了DINOZAUR：一种基于扩散的神经算子参数化方法，具有不确定性量化能力。受热核结构的启发，DINOZAUR用一个维度无关的扩散乘数替换了FNOs中的密集张量乘数，该乘数每个通道只有一个可学习的时间参数，从而大幅减少了参数数量和内存占用，同时不影响预测性能。通过对这些时间参数定义先验，我们将DINOZAUR构建为一个贝叶斯神经算子，以产生空间相关的输出和校准的不确定性估计。我们的方法在多个偏微分方程基准测试中实现了有竞争力或更优的性能，同时提供了高效的不确定性量化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [517] [SourceSplice: Source Selection for Machine Learning Tasks](https://arxiv.org/abs/2507.22186)
> *SourceSplice：机器学习任务的源选择*

*Ambarish Singh, Romila Pradhan* | **Category: cs.LG, cs.AI, cs.DB, I.2.6** | **Updated: 2025-07-31**

**Keywords:** 数据质量, 源选择, 机器学习, 基因剪接, SourceSplice

**Comment:** 

> **TL;DR:** 本文提出了SourceSplice，一个受基因剪接启发的框架，用于为机器学习任务选择最佳数据源，实验表明它能以显著更少的探索实现高任务效用。

**AI_Comments:** 本文的创新之处在于将受基因剪接启发的机制（SourceSplice）应用于机器学习的数据源选择问题，这与传统的数据发现方法相比是一种新颖的方法。其重要性在于通过确保高质量的数据输入，以及降低数据选择的计算成本，从而提升机器学习模型的性能。

<details>
  <summary>Details</summary>

**Motivation:** 数据质量对机器学习任务的预测性能至关重要，但现代组织中大量的数据源使得选择高质量数据成为挑战。现有的数据发现工作主要关注元数据匹配或语义相似性，但没有考虑数据源质量对下游机器学习任务高性能的影响。本文旨在解决为给定机器学习任务构建训练数据集时，确定最佳数据源子集的问题。

**Method:** 本文提出了SourceGrasp和SourceSplice两个框架，旨在高效选择能够最大化下游机器学习模型效用的数据源子集。这两种算法的核心思想都是数据源（或其组合）对任务效用贡献不同，因此必须谨慎选择。SourceGrasp采用基于贪婪准则和随机化的元启发式方法，而SourceSplice框架则提出了一种受基因剪接（蛋白质合成中的核心概念）启发的源选择机制。

**Result:** 作者在三个真实世界数据集和合成数据集上对算法进行了实证评估。结果表明，SourceSplice能够以显著更少的子集探索有效识别出导致高任务效用的数据源子集。研究还报告了SourceSplice在多种设置下对决策选择的敏感性。

**Conclusion:** SourceSplice是一个有效且高效的方法，用于为机器学习任务选择高质量的数据源，与需要更多探索的方法相比，它能以更少的计算成本实现高任务效用。

> **ai_Abstract:** 本文介绍了SourceGrasp和SourceSplice，两个旨在解决机器学习任务中数据源选择关键问题的框架。认识到不同数据源贡献的效用各异，SourceGrasp采用元启发式方法，而SourceSplice则利用一种新颖的、受基因剪接启发的机制。实证评估表明，SourceSplice能够在真实世界和合成数据集上，以显著更少的探索高效识别出高效用的数据源子集。

> **摘要翻译:** 数据质量在机器学习（ML）任务的预测性能中扮演着关键角色——这一挑战因现代组织中大量可用数据源而加剧。先前的数据发现工作主要集中在元数据匹配、语义相似性或识别应连接以回答特定查询的表格，但没有考虑源质量对下游ML任务高性能的影响。本文解决了为给定ML任务构建底层训练数据集时，确定必须组合的最佳数据源子集的问题。我们提出了SourceGrasp和SourceSplice，这些框架旨在高效选择合适的源子集，从而最大化下游ML模型的效用。这两种算法都依赖于核心思想，即源（或其组合）对任务效用贡献不同，并且必须经过审慎选择。SourceGrasp利用基于贪婪准则和随机化的元启发式方法，而SourceSplice框架则提出了一种受基因剪接——蛋白质合成中使用的核心概念——启发的源选择机制。我们对我们的算法在三个真实世界数据集和合成数据集上进行了实证评估，并表明，在显著减少子集探索的情况下，SourceSplice有效地识别出导致高任务效用的数据源子集。我们还进行了研究，报告了SourceSplice在多种设置下对决策选择的敏感性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [519] [Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting](https://arxiv.org/abs/2508.00040)
> *基于运行电价预测的态势感知条件神经过程与多准则决策支持*

*Abhinav Das, Stephan Schlüter* | **Category: cs.LG, math.PR, stat.AP, stat.ML, 60J20, 68T07** | **Updated: 2025-07-31**

**Keywords:** 电价预测, 态势检测, 条件神经过程, 多准则决策, 电池储能优化

**Comment:** 

> **TL;DR:** 该研究将贝叶斯态势检测与条件神经过程结合，用于德国电力市场24小时电价预测，并通过多准则决策支持（TOPSIS）评估，发现所提出的R-NP模型在多年份中表现出最佳平衡性。

**AI_Comments:** 本文的创新点在于将电力价格预测中的态势检测与条件神经过程结合，并引入多准则决策支持（TOPSIS）来评估模型在实际操作场景中的效用。这解决了传统预测模型仅关注精度而忽略实际应用效果的局限性。通过将预测结果整合到电池储能优化框架中进行评估，增强了研究的实用价值。提出的R-NP模型在平衡性和长期稳定性方面表现出色，为复杂的能源市场预测提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 传统的电价预测模型通常只关注预测精度，但这种精度不一定能转化为实际操作中的最佳经济效益。因此，本研究的动机是开发一种能够考虑实际运行需求并提供多准则决策支持的电价预测方法。

**Method:** 本研究将贝叶斯态势检测与条件神经过程相结合。首先，利用解耦的粘性分层狄利克雷过程隐马尔可夫模型（DS-HDP-HMM）对每日电价进行态势检测。每个识别出的态势都由一个独立的条件神经过程（CNP）建模，学习从输入上下文到24维小时价格轨迹的局部映射。最终预测是这些CNP输出的态势加权混合。为了评估，将预测结果整合到不同的电池储能优化框架中，并使用TOPSIS作为多准则评估层。

**Result:** 在对R-NP、深度神经网络（DNN）和Lasso估计自回归（LEAR）模型的评估中，发现LEAR在绝对利润或成本方面通常表现更优，而DNN在特定成本最小化场景中表现出色。然而，TOPSIS分析表明，尽管LEAR在2021年排名第一，但所提出的R-NP模型在2021年、2022年和2023年均被认定为最平衡和首选的解决方案。

**Conclusion:** 本研究提出了一种结合态势检测与条件神经过程的电价预测模型（R-NP），并通过多准则决策支持（TOPSIS）评估其在实际操作中的表现。结果表明，R-NP模型在多个年份中展现出最佳的平衡性和实用性，优于仅关注预测精度的传统模型。

> **ai_Abstract:** 本研究提出了一种名为R-NP的新型电力价格预测模型，该模型将贝叶斯态势检测（通过DS-HDP-HMM实现）与条件神经过程（CNP）相结合，以适应德国电力市场的24小时预测需求。每个检测到的态势都由一个独立的CNP建模，最终预测为态势加权混合。通过将预测整合到电池储能优化框架中，并使用TOPSIS进行多准则评估，结果显示，尽管传统模型在某些指标上表现突出，但R-NP模型在2021年至2023年间被证明是最平衡且首选的解决方案，强调了操作实用性而非单纯预测精度的重要性。

> **摘要翻译:** 这项工作将贝叶斯态势检测与条件神经过程相结合，用于德国市场24小时电价预测。我们的方法论整合了应用于每日电价的解耦粘性分层狄利克雷过程隐马尔可夫模型（DS-HDP-HMM）进行态势检测。每个识别出的态势随后由一个独立的条件神经过程（CNP）建模，训练其学习从输入上下文到24维小时价格轨迹的局部映射，最终预测计算为这些CNP输出的态势加权混合。我们通过将预测结果整合到包括价格套利、风险管理、电网服务和成本最小化在内的各种电池储能优化框架中，严格评估了R-NP与深度神经网络（DNN）和Lasso估计自回归（LEAR）模型。这种操作效用评估揭示了复杂的性能权衡：LEAR通常产生更高的绝对利润或更低的成本，而DNN在特定的成本最小化情境中表现出卓越的优化性。认识到原始预测精度并不总是能转化为最佳操作结果，我们采用TOPSIS作为综合多准则评估层。我们的TOPSIS分析将LEAR确定为2021年的排名第一模型，但至关重要的是，我们提出的R-NP模型在2021年、2022年和2023年均成为最平衡和首选的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [520] [EVINET: Towards Open-World Graph Learning via Evidential Reasoning Network](https://arxiv.org/abs/2506.07288)
> *EVINET：迈向开放世界图学习的证据推理网络*

*Weijie Guan, Haohui Wang, Jian Kang, Lihui Liu, Dawei Zhou* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 图学习, 开放世界, 证据推理, 误分类检测, 离群分布检测

**Comment:** KDD 2025

> **TL;DR:** EVINET是一个基于证据推理的网络，通过集成Beta嵌入和主观逻辑框架，解决了开放世界图学习中的误分类检测和离群分布检测两大挑战，并取得了优于现有方法的性能。

**AI_Comments:** EVINET的创新之处在于其将证据推理和主观逻辑引入图学习，以解决开放世界环境下的不确定性问题。通过区分误分类和离群分布，该方法提升了模型在复杂真实场景中的鲁棒性和可靠性，对实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图学习方法通常基于封闭世界假设，即所有可能的标签都是预先已知的。然而，在开放和嘈杂的环境中，模型需要能够识别其对已知类别数据做出错误预测（误分类检测）或遇到来自新类别的离群分布数据（离群分布检测），以实现有效的图学习。

**Method:** 本文提出了证据推理网络（EVINET），一个通过在主观逻辑框架内整合Beta嵌入来解决误分类检测和离群分布检测的框架。EVINET包含两个关键模块：用于误分类检测的“不和谐推理”（Dissonance Reasoning）和用于离群分布检测的“空缺推理”（Vacuity Reasoning）。

**Result:** EVINET在内分布分类、误分类检测和离群分布检测任务中，在多项指标上均优于最先进的方法。EVINET证明了不确定性估计和逻辑推理对于误分类检测和离群分布检测的必要性。

**Conclusion:** EVINET通过引入不确定性估计和逻辑推理，解决了开放世界图学习中的误分类和离群分布检测问题，为开放世界图学习铺平了道路。

> **ai_Abstract:** EVINET是一个创新性的证据推理网络，旨在解决开放世界图学习中的两大挑战：误分类检测和离群分布检测。该框架通过将Beta嵌入与主观逻辑框架相结合，并引入不和谐推理和空缺推理模块，实现了对模型不确定性的有效估计和逻辑推理。实验结果表明，EVINET在多项任务上表现优异，为开放世界图学习提供了新的途径。

> **摘要翻译:** 图学习在许多现实世界任务中至关重要，但它们通常在封闭世界假设下进行研究，即所有可能的数据标签都是先验已知的。为了在开放和嘈杂的环境中实现有效的图学习，当模型对已知类别的内分布数据做出错误预测（即误分类检测）或模型遇到来自新类别的离群分布数据（即离群分布检测）时，告知模型用户至关重要。本文介绍了证据推理网络（EVINET），一个通过在主观逻辑框架内集成Beta嵌入来解决这两个挑战的框架。EVINET包括两个关键模块：用于误分类检测的“不和谐推理”和用于离群分布检测的“空缺推理”。大量实验表明，EVINET在内分布分类、误分类检测和离群分布检测任务中，在多项指标上均优于最先进的方法。EVINET证明了不确定性估计和逻辑推理对于误分类检测和离群分布检测的必要性，并为开放世界图学习铺平了道路。我们的代码和数据可在https://github.com/SSSKJ/EviNET获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [522] [Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains](https://arxiv.org/abs/2508.00046)
> *强化学习中部分可观测性的基准测试，采用一套记忆可改进域*

*Ruo Yu Tao, Kaicheng Guo, Cameron Allen, George Konidaris* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 部分可观测性, 强化学习, 基准测试, POBAX, 记忆可改进

**Comment:** To appear at RLC 2025. 1 cover page, 10 pages, 3 reference pages + 13
  pages for supplementary material

> **TL;DR:** 本文提出了POBAX，一个JAX中用于强化学习部分可观测性基准测试的开源库，包含多种记忆可改进的环境，以帮助研究者更好地评估算法应对部分可观测性的能力。

**AI_Comments:** 这篇论文通过提出POBAX库和“记忆可改进”的概念，为强化学习领域中长期存在的部分可观测性问题提供了急需的、更全面的基准测试工具。其创新之处在于强调了基准测试应具备的两种关键特性：部分可观测性形式的覆盖性和记忆可改进性，这有助于确保算法的通用性和评估的有效性。该工作的贡献在于为研究人员提供了一个标准化的、高性能的平台，以推动RL算法在复杂现实世界环境下的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的强化学习部分可观测性基准测试过于简单，无法代表现实世界中复杂的部分可观测性形式，研究人员需要更全面的基准来评估和改进算法应对部分可观测性的能力。

**Method:** 作者提出了评估部分可观测性基准测试的两个关键特性：形式覆盖性和记忆可改进性。他们引入了POBAX开源库，包含多种代表性环境（如定位与建图、视觉控制、游戏等），并提供了最佳实践指南、推荐超参数和算法实现，以及JAX中高性能环境。

**Result:** 作者表明所选环境都是记忆可改进的，并且需要难以学习的记忆功能，这为部分可观测性研究提供了明确的信号。该框架支持快速开箱即用评估和GPU可扩展实验。

**Conclusion:** 本文通过引入POBAX库和一套记忆可改进的域，为强化学习中部分可观测性问题的基准测试提供了全面的解决方案，有助于推动相关算法的进步。

> **ai_Abstract:** 本文针对强化学习中部分可观测性基准测试的不足，提出了一个开源库POBAX。该库包含一系列具有真实世界复杂部分可观测性形式的“记忆可改进”环境，并提供了基准测试的最佳实践指南、推荐超参数和算法实现，旨在为研究人员提供更全面、更具挑战性的评估工具，以促进算法在处理部分可观测性方面的进步。

> **摘要翻译:** 缓解部分可观测性是通用强化学习算法一项必要但具有挑战性的任务。为了提高算法缓解部分可观测性的能力，研究人员需要全面的基准来衡量进展。大多数解决部分可观测性的算法仅在具有简单状态混叠形式的基准上进行评估，例如特征遮蔽和高斯噪声。此类基准无法代表真实领域中出现的多种形式的部分可观测性，例如视觉遮挡或未知的对手意图。我们认为部分可观测性基准应具有两个关键特性。首先是其部分可观测性形式的覆盖范围，以确保算法的通用性。其次是具有或多或少状态信息的代理性能之间存在巨大差距，而所有其他因素大致相等。这种差距意味着环境是记忆可改进的：领域中的性能提升源于算法应对部分可观测性的能力，而不是其他因素。我们为经验性地对部分可观测性下的强化学习进行基准测试引入了最佳实践指南，以及开源库POBAX：JAX中的部分可观测性基准。我们表征了各种环境中存在的部分可观测性类型，并为我们的基准选择了代表性环境。这些环境包括定位与建图、视觉控制、游戏等。此外，我们表明这些任务都是记忆可改进的，并且需要难以学习的记忆功能，为部分可观测性研究提供了具体的信号。该框架包括推荐的超参数以及用于快速、开箱即用评估的算法实现，以及在JAX中实现的高性能环境，用于GPU可扩展实验。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [535] [Binarizing Physics-Inspired GNNs for Combinatorial Optimization](https://arxiv.org/abs/2507.13703)
> *二值化物理启发式图神经网络用于组合优化*

*Martin Krutský, Gustav Šír, Vyacheslav Kungurtsev, Georgios Korpas* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 物理启发式图神经网络, 组合优化, 二值化, 模糊逻辑, 图密度

**Comment:** Accepted to the 28th European Conference on Artificial Intelligence
  (ECAI 2025). This archival version includes supplementary appendices

> **TL;DR:** 本文指出物理启发式图神经网络（PI-GNNs）在处理高密度组合优化问题时性能会急剧下降，原因在于其实值输出与二值解之间的不匹配。为解决此问题，作者提出了基于模糊逻辑和二值化神经网络的新方法，显著提升了PI-GNNs在高密度场景下的性能。

**AI_Comments:** 这篇论文的创新点在于它识别并解决了物理启发式图神经网络（PI-GNNs）在处理高密度组合优化问题时的一个关键限制。通过深入分析训练动态并揭示实值输出与二值解之间的不一致性，论文为改进PI-GNNs提供了理论基础。引入模糊逻辑和二值化神经网络的概念来解决这一问题，显示了跨领域知识的有效融合，对于提升GNNs在实际组合优化问题中的鲁棒性和适用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 物理启发式图神经网络（PI-GNNs）在组合优化问题中表现出有前景的结果，但其性能会随着组合问题图密度的增加而系统性下降。分析显示，这种下降与训练动态中的相变以及实值模型输出与二值问题解之间的不一致性有关。

**Method:** 为解决PI-GNNs在处理高密度组合优化问题时性能下降的问题，本文提出了基于模糊逻辑和二值化神经网络的原理性替代方案，以纠正实值松弛输出与二值问题解之间的不一致性。

**Result:** 实验证明，所提出的一系列方法显著提高了PI-GNNs在日益密集的设置中的性能。

**Conclusion:** 通过引入基于模糊逻辑和二值化神经网络的新策略来解决实值输出与二值解之间的不匹配，可以显著提升物理启发式图神经网络（PI-GNNs）在处理高密度组合优化问题时的性能。

> **ai_Abstract:** 本文研究了物理启发式图神经网络（PI-GNNs）在组合优化中的应用，发现其性能随问题图密度的增加而显著下降。这种性能下降源于实值模型输出与二值问题解之间的不匹配。为解决此问题，论文提出了融合模糊逻辑和二值化神经网络的新方法，实验证明这些方法能有效提升PI-GNNs在高密度问题上的表现。

> **摘要翻译:** 物理启发式图神经网络（PI-GNNs）已被用作一种高效的无监督框架，用于松弛通过特定图结构和损失编码的组合优化问题，反映了问题变量之间的依赖关系。尽管该框架在各种组合问题中取得了有前景的结果，但我们发现PI-GNNs的性能会随着组合问题图密度的增加而系统性下降。我们的分析揭示了PI-GNNs训练动态中一个有趣的相变，与更密集问题的退化解相关，突出了松弛的实值模型输出与二值问题解之间的差异。为了解决这种差异，我们基于模糊逻辑和二值化神经网络的见解，提出了替代PI-GNNs中朴素策略的原理性方法。我们的实验表明，所提出方法组合显著提高了PI-GNNs在日益密集的设置中的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [545] [TrajSurv: Learning Continuous Latent Trajectories from Electronic Health Records for Trustworthy Survival Prediction](https://arxiv.org/abs/2508.00657)
> *TrajSurv：从电子健康记录中学习连续潜在轨迹以实现可信生存预测*

*Sihang Zeng, Lucas Jing Liu, Jun Wen, Meliha Yetisgen, Ruth Etzioni, Gang Luo* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 生存预测, 电子健康记录, 潜在轨迹, 神经受控微分方程, 可解释性

**Comment:** Accepted by MLHC 2025

> **TL;DR:** TrajSurv是一种利用神经受控微分方程和对比学习从电子健康记录中建模连续患者进展的模型，用于准确和透明的生存预测。

**AI_Comments:** TrajSurv的创新之处在于其利用神经受控微分方程学习连续潜在轨迹，并通过时间感知对比学习增强其临床相关性。其两步解释过程显著提升了模型的透明度，这对于临床决策中的信任度至关重要。该方法在解决不规则采样数据建模和模型可解释性方面提供了有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 可信赖的生存预测对临床决策至关重要。然而，准确建模不规则采样的临床特征背后的患者连续临床进展，并透明地将其与生存结果联系起来是具有挑战性的。

**Method:** TrajSurv模型通过学习纵向电子健康记录数据中的连续潜在轨迹来实现可信的生存预测。它使用神经受控微分方程（NCDE）从不规则采样的数据中提取连续时间潜在状态，形成连续潜在轨迹。为确保潜在轨迹反映临床进展，TrajSurv通过时间感知对比学习方法将潜在状态空间与患者状态空间对齐。为透明地连接临床进展与生存结果，TrajSurv采用两步分而治之的解释过程：首先，利用学习到的向量场解释临床特征变化如何转化为潜在轨迹的演变；其次，聚类这些潜在轨迹以识别与不同生存结果相关的关键临床进展模式。

**Result:** 在MIMIC-III和eICU两个真实世界医疗数据集上的评估显示，TrajSurv与现有深度学习方法相比，具有竞争力的准确性和卓越的透明度。

**Conclusion:** TrajSurv在生存预测方面表现出竞争力的准确性和卓越的透明度，能够有效应对从不规则采样的电子健康记录中建模连续临床进展并透明地连接至生存结果的挑战。

> **ai_Abstract:** TrajSurv是一个针对临床生存预测的模型，旨在解决从不规则采样的电子健康记录中准确建模连续患者进展并透明关联生存结果的挑战。该模型利用神经受控微分方程提取连续潜在轨迹，并通过时间感知对比学习确保其反映临床进展。为提高可解释性，TrajSurv采用两步解释过程，分析临床特征变化如何影响轨迹演变，并聚类轨迹以识别与不同生存结果相关的临床模式。在MIMIC-III和eICU数据集上的实验证明，TrajSurv在准确性和透明度上优于现有深度学习方法。

> **摘要翻译:** 可信赖的生存预测对于临床决策至关重要。纵向电子健康记录（EHRs）为预测提供了独特而强大的机会。然而，准确建模不规则采样的临床特征背后的患者连续临床进展，并透明地将进展与生存结果联系起来是具有挑战性的。为了解决这些挑战，我们开发了TrajSurv，一个从纵向EHR数据中学习连续潜在轨迹以实现可信生存预测的模型。TrajSurv采用神经受控微分方程（NCDE）从不规则采样数据中提取连续时间潜在状态，形成连续潜在轨迹。为了确保潜在轨迹反映临床进展，TrajSurv通过时间感知对比学习方法将潜在状态空间与患者状态空间对齐。为了透明地将临床进展与生存结果联系起来，TrajSurv在两步分而治之的解释过程中使用潜在轨迹。首先，它使用学习到的向量场解释临床特征的变化如何转化为潜在轨迹的演变。其次，它聚类这些潜在轨迹以识别与不同生存结果相关的关键临床进展模式。在MIMIC-III和eICU两个真实世界医疗数据集上的评估显示，TrajSurv与现有深度学习方法相比，具有竞争力的准确性和卓越的透明度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [546] [Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices](https://arxiv.org/abs/2506.20644)
> *面向数据异构边缘设备的加密数据共享高效联邦学习*

*Hangyu Li, Hongyue Wu, Guodong Fan, Zhen Zhang, Shizhan Chen, Zhiyong Feng* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 联邦学习, 边缘计算, 数据异构性, 加密数据共享, 隐私保护

**Comment:** Accepted by ICWS 2025

> **TL;DR:** 一种名为FedEDS的新型联邦学习方案，通过加密数据共享，解决了边缘设备在数据异构环境下的收敛速度慢和模型性能下降问题，并提升了模型表现。

**AI_Comments:** 本文创新性地提出了一种基于加密数据共享的联邦学习方案FedEDS，有效解决了边缘设备在数据异构环境下的收敛速度慢和模型性能下降的问题。其通过数据加密器共享加密数据而非模型参数，提供了一种新的隐私保护和性能优化的思路，对于推动联邦学习在实际边缘应用中的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前联邦学习研究忽视了网络拓扑、物理距离和数据异构性对边缘设备的影响，导致延迟增加和模型性能下降。

**Method:** 本文提出了一种名为FedEDS的联邦学习方案。FedEDS利用客户端模型和模型的随机层来训练数据加密器，该加密器生成加密数据并与其他客户端共享。客户端结合其本地私有数据和来自其他客户端的加密共享数据来训练和调整本地模型。

**Result:** 实验结果表明FedEDS能有效提升模型性能，加速联邦学习训练的收敛速度，并减轻数据异构性的负面影响。

**Conclusion:** FedEDS通过加密数据共享的机制，有效解决了边缘设备上联邦学习中数据异构性、收敛速度和模型性能的问题，使其适用于需要快速收敛的边缘应用服务。

> **ai_Abstract:** 本文提出了一种名为FedEDS的联邦学习方案，旨在解决边缘设备上联邦学习中因网络拓扑、物理距离和数据异构性导致的延迟和性能下降问题。FedEDS通过训练数据加密器生成并共享加密数据，允许客户端结合本地私有数据和加密共享数据进行模型训练，从而加速收敛并减轻数据异构性影响，实验证明其能有效提升模型性能。

> **摘要翻译:** 随着隐私保护日益重要，越来越多的模型在边缘设备上训练，并通过联邦学习（FL）合并到中央服务器。然而，当前研究忽视了网络拓扑、物理距离和数据异构性对边缘设备的影响，导致延迟增加和模型性能下降等问题。为解决这些问题，我们提出了一种新的边缘设备联邦学习方案，名为加密数据共享联邦学习（FedEDS）。FedEDS利用客户端模型和模型的随机层来训练数据加密器。数据加密器生成加密数据并与其他客户端共享。客户端使用相应的客户端随机层和加密数据来训练和调整本地模型。FedEDS使用客户端的本地私有数据和其他客户端的加密共享数据来训练模型。这种方法加速了联邦学习训练的收敛速度，并减轻了数据异构性的负面影响，使其适用于需要快速收敛的边缘设备上的应用服务。实验结果表明FedEDS在提升模型性能方面的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [547] [TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection](https://arxiv.org/abs/2508.00047)
> *TriP-LLM：一种用于时间序列异常检测的三分支分块大型语言模型框架*

*Yuan-Cheng Yu, Yen-Chieh Ouyang, Chun-An Lin* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 时间序列异常检测, 大型语言模型, 三分支设计, 分块处理, 无监督学习

**Comment:** 11 pages, 2 figures

> **TL;DR:** TriP-LLM是一个新颖的无监督时间序列异常检测框架，它采用三分支分块设计并利用预训练的大型语言模型，在性能和内存效率上均超越了现有方法。

**AI_Comments:** TriP-LLM的创新之处在于其将大型语言模型引入时间序列异常检测领域，并通过独特的三分支分块处理机制有效整合了局部和全局时间特征。其显著的性能提升和更低的内存消耗使其在实际部署中具有重要价值和广泛的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 随着物联网和智能制造的普及，时间序列数据在规模和维度上急剧增长，传统统计方法在处理这些数据的高异构性和复杂性方面暴露出局限性。受大型语言模型（LLMs）在跨语言和视觉领域多模态任务中近期成功的启发，研究者提出了一种新的异常检测框架。

**Method:** 本文提出了TriP-LLM，一个无监督的时间序列异常检测框架。TriP-LLM通过一个三分支设计（Patching, Selection, and Global）整合局部和全局时间特征，将输入时间序列编码为分块tokens，然后由一个冻结的预训练LLM进行处理。一个轻量级的分块解码器重建输入，并从中导出异常分数。

**Result:** 实验结果表明，TriP-LLM在所有公共基准数据集上持续优于最新的SOTA方法，展示了强大的检测能力。通过广泛的消融研究，验证了LLM对整体架构的实质性贡献。与使用通道独立（CI）补丁处理的基于LLM的方法相比，TriP-LLM显著降低了内存消耗，使其更适用于GPU内存受限的环境。

**Conclusion:** TriP-LLM展示了强大的时间序列异常检测能力，并且由于其较低的内存消耗，更适用于GPU内存受限的部署环境。

> **ai_Abstract:** TriP-LLM是一个创新的无监督时间序列异常检测框架，它结合了独特的三分支设计和预训练大型语言模型。该模型通过将时间序列数据转换为分块tokens并利用LLM进行处理和解码器重建来识别异常。实验结果表明，TriP-LLM在多个基准数据集上超越了现有先进方法，同时显著降低了内存消耗，使其特别适用于资源受限的环境。

> **摘要翻译:** 时间序列异常检测在广泛的应用领域中扮演着核心角色。随着物联网（IoT）和智能制造的日益普及，时间序列数据在规模和维度上都急剧增加。这种增长暴露了传统统计方法在处理此类数据的高异构性和复杂性方面的局限性。受大型语言模型（LLMs）在跨语言和视觉领域多模态任务中近期成功的启发，我们提出了一种新颖的无监督异常检测框架：一种用于时间序列异常检测的三分支分块大型语言模型框架（TriP-LLM）。TriP-LLM通过一个三分支设计——分块、选择和全局——整合局部和全局时间特征，将输入时间序列编码为分块tokens，然后由一个冻结的预训练LLM进行处理。一个轻量级的分块解码器重建输入，并从中导出异常分数。我们使用PATE（一个最近提出的无阈值评估指标）在多个公共基准数据集上评估了TriP-LLM，并在统一的开源框架内进行所有比较以确保公平性。实验结果表明，TriP-LLM在所有数据集上持续优于最新的最先进方法，展示了强大的检测能力。此外，通过广泛的消融研究，我们验证了LLM对整体架构的实质性贡献。与使用通道独立（CI）补丁处理的基于LLM的方法相比，TriP-LLM实现了显著更低的内存消耗，使其更适用于GPU内存受限的环境。所有代码和模型检查点均在https://github.com/YYZStart/TriP-LLM.git公开可用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [549] [Improved Robustness and Functional Localization in Topographic CNNs Through Weight Similarity](https://arxiv.org/abs/2508.00043)
> *通过权重相似性改进地形卷积神经网络的鲁棒性和功能定位*

*Nhut Truong, Uri Hasson* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** 地形神经网络, 权重相似性, 激活相似性, 鲁棒性, 功能定位

**Comment:** 

> **TL;DR:** 本研究比较了两种地形卷积神经网络（CNNs）的空间约束方法：权重相似性（WS）和激活相似性（AS），发现WS相比AS和标准CNNs能显著提高鲁棒性、输入敏感性和功能定位，并影响特征学习和功能组织。

**AI_Comments:** 这篇论文创新性地比较了两种不同的地形约束实现方式（WS和AS）对神经网络性能的影响，填补了该领域系统性研究的空白。其发现WS能显著提升地形CNNs的鲁棒性和功能定位，这对于构建更接近生物大脑机制、性能更优越的AI模型具有重要意义。研究结果不仅为地形网络的理论研究提供了新见解，也为实际应用中设计更高效、更鲁健的神经网络提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 地形神经网络可以模拟大脑的空间和功能组织，但不同空间约束实现方式对网络学习到的表征影响尚未被系统性检验。本研究旨在系统比较不同地形约束对网络性能的影响。

**Method:** 本研究比较了两种地形卷积神经网络（CNNs）的空间约束方法：权重相似性（WS）和激活相似性（AS）。WS促使相邻单元发展相似的输入权重，而AS强制单元激活的相似性。研究评估了模型在分类精度、对权重扰动和输入降级的鲁棒性、以及学习表征的空间组织方面的表现。

**Result:** 与AS和标准CNNs相比，WS提供了三个主要优势：i) 提高了对噪声的鲁棒性，并在权重损坏下显示出更高的准确性；ii) 具有更大的输入敏感性，反映在更高的激活方差；iii) 更强的功能定位，表现为激活相似的单元定位更近。此外，WS还导致了单元的方向调谐、对称敏感性和偏心率曲线的差异，表明这种空间约束影响了网络的表征几何。

**Conclusion:** 研究结果表明，在端到端训练中，权重相似性（WS）约束比激活相似性（AS）或非地形CNNs能产生更鲁棒的表征。这些发现也表明，基于权重的空间约束可以塑造生物物理启发模型中的特征学习和功能组织。

> **ai_Abstract:** 本研究系统比较了两种地形卷积神经网络（CNNs）的空间约束方法：权重相似性（WS）和激活相似性（AS），以探究其对网络学习表征的影响。实验结果表明，与AS和标准CNNs相比，WS显著提高了模型的鲁棒性、输入敏感性和功能定位能力。此外，WS还影响了网络的特征学习和功能组织。研究强调了基于权重的空间约束在构建更稳健的生物启发模型中的潜力。

> **摘要翻译:** 地形神经网络是能够模拟大脑空间和功能组织的计算模型。神经网络中的地形约束可以通过多种方式实现，可能对网络学习到的表征产生不同的影响。这些不同实现方式的影响尚未被系统性检验。为此，我们在此比较了使用两种空间约束训练的地形卷积神经网络：权重相似性（WS），它促使相邻单元发展相似的输入权重；以及激活相似性（AS），它强制单元激活的相似性。我们评估了所得模型在分类精度、对权重扰动和输入降级的鲁棒性以及学习表征的空间组织方面的表现。与AS和标准CNNs相比，WS提供了三个主要优势：i) 提高了对噪声的鲁棒性，并在权重损坏下显示出更高的准确性；ii) 具有更大的输入敏感性，反映在更高的激活方差；iii) 更强的功能定位，表现为激活相似的单元定位更近。此外，WS还导致了单元的方向调谐、对称敏感性和偏心率曲线的差异，表明这种空间约束影响了网络的表征几何。我们的发现表明，在端到端训练中，WS约束比AS或非地形CNNs能产生更鲁棒的表征。这些发现也表明，基于权重的空间约束可以塑造生物物理启发模型中的特征学习和功能组织。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [559] [Loss Landscape Degeneracy and Stagewise Development in Transformers](https://arxiv.org/abs/2402.02364)
> *Transformer模型中的损失景观退化与阶段性发展*

*Jesse Hoogland, George Wang, Matthew Farrugia-Roberts, Liam Carroll, Susan Wei, Daniel Murfet* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 损失景观, Transformer, 退化, 奇异学习理论, 模型发展

**Comment:** To appear, TMLR. Material on essential dynamics from v1 of this
  preprint has been removed and developed in arXiv:2501.17745

> **TL;DR:** 研究表明，Transformer模型训练过程中，损失景观的退化与模型内部计算结构和行为的发展变化密切相关。

**AI_Comments:** 这项研究通过引入损失景观退化这一概念，为理解Transformer模型在训练过程中如何发展其内部计算结构和行为提供了一个新的视角，尤其结合了奇异学习理论，具有一定的理论深度和创新性。它指出了训练阶段性变化的潜在原因，对优化深度学习训练过程可能具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习的科学需要揭示神经网络结构和行为发展的原理。作者提出模型发展与损失景观局部几何的退化深度相关，并旨在通过研究验证此联系。

**Method:** 作者利用奇异学习理论框架，通过监测训练过程中损失景观的退化（通过局部学习系数量化），研究了Transformer语言模型和上下文线性回归Transformer。

**Result:** 训练可以分为损失景观退化变化的几个不同时期，并且这些退化变化与Transformer内部计算结构和输入/输出行为的显著变化同时发生。

**Conclusion:** 这一发现提供了证据，表明Transformer中退化与发展之间存在联系，强调了基于退化的视角在理解现代深度学习方面的潜力。

> **ai_Abstract:** 本文利用奇异学习理论，探讨了Transformer模型训练过程中损失景观的退化与模型内部结构及行为发展之间的关联。研究通过监测局部学习系数，发现训练可划分为损失景观退化变化的阶段，这些变化与Transformer计算结构和行为的显著转变同步。这表明基于退化的视角对理解深度学习具有重要意义。

> **摘要翻译:** 深度学习涉及在高维损失景观中导航神经网络参数空间。在训练过程中，复杂的计算结构在神经网络内部形成和重组，导致输入/输出行为的转变。揭示神经网络结构和行为发展的原理是深度学习科学的优先事项。借鉴奇异学习理论的框架，我们提出模型发展与损失景观局部几何的退化深度相关。我们通过在整个训练过程中监测损失景观的退化（通过局部学习系数进行量化），研究了Transformer语言模型和上下文线性回归Transformer，以调查这种联系。我们发现训练可以分为损失景观退化变化的几个不同时期，并且这些退化变化与Transformer内部计算结构和输入/输出行为的显著变化同时发生。这一发现提供了暗示性证据，表明Transformer中退化与发展之间存在联系，强调了基于退化的视角在理解现代深度学习方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [565] [DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic Prototypes](https://arxiv.org/abs/2508.00664)
> *DP-DGAD: 一种具有动态原型的通用动态图异常检测器*

*Jialun Zheng, Jie Liu, Jiannong Cao, Xiao Wang, Hanchen Yang, Yankai Chen, Philip S. Yu* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 动态图异常检测, 动态原型, 通用模型, 跨域, 自监督学习

**Comment:** 

> **TL;DR:** DP-DGAD提出了一种新的动态图异常检测模型，它使用动态原型来捕捉随时间演变的领域特定和领域无关的异常模式，并在多个真实世界数据集上实现了最先进的性能。

**AI_Comments:** DP-DGAD的创新点在于引入了“动态原型”的概念，有效地捕捉了动态图中异常模式的时间演变性和领域多样性。通过内存缓冲区和选择性更新机制，模型能够兼顾通用性与领域适应性，这对于实际应用中不断出现的新领域和缺乏标签数据的情况尤为重要。结合置信度伪标签的自监督适应能力，进一步增强了其在目标领域中的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 动态图异常检测（DGAD）在金融、交通和社交网络等领域识别不断演变的图中的异常至关重要。尽管现有的通用图异常检测（GAD）模型在静态图上表现良好，但它们难以捕捉动态图中不断演变的异常。此外，新领域的不断出现和标记数据的缺乏进一步挑战了通用DGAD。有效的跨域DGAD需要同时考虑领域特定和领域无关的异常模式，且这些模式会随时间演变。

**Method:** DP-DGAD模型通过以下步骤捕捉演变的领域特定和领域无关模式：首先，从时间自我图中提取动态原型（即正常和异常模式的演变表示），并将其存储在内存缓冲区中。该缓冲区被选择性地更新，以保留通用的、领域无关的模式，同时整合新的领域特定模式。然后，异常评分器将传入数据与动态原型进行比较，以标记通用和领域特定的异常。最后，DP-DGAD采用基于置信度的伪标签进行目标领域中的有效自监督适应。

**Result:** 在来自不同领域的十个真实世界数据集上进行了广泛的实验，结果表明DP-DGAD实现了最先进的性能。

**Conclusion:** DP-DGAD成功地解决了动态图中捕捉演变异常模式的挑战，通过引入动态原型机制，实现了跨域的有效异常检测，并在多个真实世界数据集上表现出色。

> **ai_Abstract:** 本文提出了一种名为DP-DGAD的通用动态图异常检测模型，旨在解决现有方法在捕捉动态图中演变异常模式以及跨域泛化方面的不足。DP-DGAD的核心思想是利用动态原型来表示随时间演变的正常和异常模式。它通过从时间自我图中提取动态原型并存储在可选择更新的内存缓冲区中，以同时保留领域无关的通用模式和整合领域特定的新模式。随后，异常评分器根据这些动态原型对新数据进行异常判断。此外，模型还采用了基于置信度的伪标签进行自监督适应。实验结果表明，DP-DGAD在十个真实世界数据集上均达到了最先进的性能。

> **摘要翻译:** 动态图异常检测（DGAD）对于识别金融、交通和社交网络等领域中不断演变的图中的异常至关重要。最近，通用图异常检测（GAD）模型显示出有希望的结果。它们在多个源数据集上进行预训练，并在不同领域之间进行泛化。虽然在静态图上有效，但它们难以捕捉动态图中不断演变的异常。此外，新领域的不断涌现和标记数据的缺乏进一步挑战了通用DGAD。有效的跨域DGAD需要同时具备领域特定和领域无关的异常模式。重要的是，这些模式在域内和域间都会随时间演变。基于这些见解，我们提出了一种具有动态原型（DP）的DGAD模型，以捕捉不断演变的领域特定和领域无关模式。首先，DP-DGAD从时间自我图中提取动态原型，即正常和异常模式的演变表示，并将其存储在内存缓冲区中。该缓冲区被选择性地更新，以保留通用的、领域无关的模式，同时整合新的领域特定模式。然后，异常评分器将传入数据与动态原型进行比较，以标记通用和领域特定的异常。最后，DP-DGAD采用基于置信度的伪标签进行目标领域中的有效自监督适应。广泛的实验证明了在来自不同领域的十个真实世界数据集上的最先进性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [571] [Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization](https://arxiv.org/abs/2508.00078)
> *评估COVID-19特征对比特币收益预测的贡献：基于LightGBM和遗传优化的方法*

*Imen Mahmoud, Andrei Velichko* | **Category: cs.LG, cs.AI, econ.GN, q-fin.EC** | **Updated: 2025-07-31**

**Keywords:** 比特币预测, COVID-19特征, LightGBM, 遗传优化, 金融分析

**Comment:** 22 pages, 5 figures

> **TL;DR:** 本研究提出了一种结合LightGBM和遗传算法的新方法，以评估COVID-19指标对比特币收益预测的贡献，发现COVID-19指标显著提高了预测准确性，特别是疫苗接种数据。

**AI_Comments:** 这项研究的创新之处在于将公共卫生数据（COVID-19指标）与金融市场预测相结合，特别是对比特币这种新兴资产的预测。通过使用LightGBM和遗传算法进行优化，提高了模型的鲁棒性和预测能力。研究结果表明，外部的、非传统数据源在金融预测中具有重要价值，这对于投资者和政策制定者在危机时期制定决策具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在确定纳入疫情相关的健康数据是否能显著提高比特币收益预测的准确性，而不仅仅是预测比特币收益本身。

**Method:** 本研究提出了一种新颖的方法框架，结合LightGBM回归模型和遗传算法（GA）优化，系统地评估COVID-19相关指标对比特币收益预测的贡献。构建了一个包含每日比特币收益和COVID-19指标（疫苗接种率、住院人数、检测统计数据）的综合数据集。预测模型在有无COVID-19特征的情况下进行训练，并通过GA进行31次独立运行优化。性能指标（R2、RMSE、MAE）通过分布重叠和Mann-Whitney U检验进行统计比较。排列特征重要性（PFI）分析量化了单个特征的贡献。

**Result:** 结果表明，COVID-19指标显著提高了模型性能，特别是在捕捉极端市场波动方面（R2增加了40%，RMSE减少了2%，均具有高度统计显著性）。在COVID-19特征中，疫苗接种指标，特别是完全接种个体的第75个百分位数，成为主导预测因子。

**Conclusion:** 本研究提出的方法通过整合公共卫生信号，扩展了现有的金融分析工具，为投资者和政策制定者提供了更精确的指标，以应对系统性危机期间的市场不确定性。

> **ai_Abstract:** 本研究提出了一种结合LightGBM回归模型和遗传算法优化的新颖方法，用于评估COVID-19相关指标对比特币收益预测的贡献。通过构建包含比特币收益和COVID-19数据的综合数据集，并使用有无COVID-19特征的模型进行训练和优化，研究发现COVID-19指标显著提高了模型性能，尤其是在捕捉市场极端波动方面。其中，疫苗接种指标被发现是主要的预测因子。该方法扩展了金融分析工具，为应对市场不确定性提供了新的视角。

> **摘要翻译:** 本研究提出了一种新颖的方法框架，整合了LightGBM回归模型和遗传算法（GA）优化，以系统地评估COVID-19相关指标对比特币收益预测的贡献。主要目标不仅仅是预测比特币收益，而是确定纳入疫情相关的健康数据是否能显著提高预测准确性。构建了一个包含每日比特币收益和COVID-19指标（疫苗接种率、住院人数、检测统计数据）的综合数据集。预测模型在有无COVID-19特征的情况下进行训练，并通过GA在31次独立运行中进行优化，从而实现稳健的统计评估。性能指标（R2、RMSE、MAE）通过分布重叠和Mann-Whitney U检验进行统计比较。排列特征重要性（PFI）分析量化了单个特征的贡献。结果表明，COVID-19指标显著改善了模型性能，特别是在捕捉极端市场波动方面（R2增加了40%，RMSE减少了2%，两者均具有高度统计显著性）。在COVID-19特征中，疫苗接种指标，特别是完全接种个体的第75个百分位数，成为主导预测因子。所提出的方法通过整合公共卫生信号，扩展了现有金融分析工具，为投资者和政策制定者提供了更精确的指标，以应对系统性危机期间的市场不确定性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [572] [Foundations of Interpretable Models](https://arxiv.org/abs/2508.00545)
> *可解释模型的S基础*

*Pietro Barbiero, Mateo Espinosa Zarlenga, Alberto Termine, Mateja Jamnik, Giuseppe Marra* | **Category: cs.LG, cs.AI, cs.NE, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 可解释性, 模型设计, 定义, 开源库, 基础

**Comment:** 

> **TL;DR:** 本文认为现有可解释性定义不可操作，导致当前研究方向错误。作者提出了一个通用、简单且可操作的可解释性定义，并基于此提出了可解释模型设计的通用蓝图和首个支持可解释数据结构与过程的开源库。

**AI_Comments:** 本文的核心创新在于提出了一个“可操作”的可解释性定义，这对于推动可解释AI领域的研究从模糊走向清晰、从非系统化走向结构化具有重要意义。通过明确设计可解释模型的必要属性和特征，它为未来的研究提供了一个坚实的基础和指导框架。此外，开源库的发布也为实际应用提供了工具支持。

<details>
  <summary>Details</summary>

**Motivation:** 现有可解释性定义未能为用户提供关于通用、健全和鲁棒的可解释模型设计的信息，导致当前可解释性研究从根本上是病态的。

**Method:** 本文提出了一个通用、简单且包含现有非正式概念的可解释性定义。该定义揭示了设计可解释模型所需的基础属性、潜在假设、原理、数据结构和架构特征。在此基础上，提出了一个设计可解释模型的通用蓝图，并引入了第一个原生支持可解释数据结构和过程的开源库。

**Result:** 提出了一个可操作的可解释性定义，直接揭示了设计可解释模型所需的基础属性、潜在假设、原理、数据结构和架构特征。基于此定义，提出了一个通用蓝图，并开发了首个支持可解释数据结构和过程的开源库。

**Conclusion:** 本文通过提出一个可操作的可解释性定义，为可解释模型的健全设计奠定了基础，并提供了一个实用的设计蓝图和工具支持。

> **ai_Abstract:** 本文指出现有可解释性定义缺乏实用性，导致可解释AI研究存在根本性问题。为解决此问题，作者提出了一个通用、简单且可操作的新可解释性定义，该定义明确了设计可解释模型所需的关键要素。基于此，论文进一步提出了可解释模型设计的通用蓝图，并发布了首个原生支持可解释数据结构和过程的开源库。

> **摘要翻译:** 我们认为，现有的可解释性定义是不可操作的，因为它们未能告知用户关于通用、健全和鲁棒的可解释模型设计。这使得当前的可解释性研究从根本上是病态的。为了解决这个问题，我们提出了一个通用、简单且包含可解释AI社区中现有非正式概念的可解释性定义。我们表明，我们的定义是可操作的，因为它直接揭示了设计可解释模型所需的基础属性、潜在假设、原理、数据结构和架构特征。在此基础上，我们提出了一个设计可解释模型的通用蓝图，并引入了第一个原生支持可解释数据结构和过程的开源库。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [573] [Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms](https://arxiv.org/abs/2507.02724)
> *跨生物体蛋白质-蛋白质相互作用预测的分层多标签对比学习*

*Shiyi Liu, Buwen Liang, Yuetong Fang, Zixuan Jiang, Renjing Xu* | **Category: cs.LG, q-bio.BM** | **Updated: 2025-08-04**

**Keywords:** 蛋白质-蛋白质相互作用, 对比学习, 跨物种预测, 分层学习, 零样本迁移

**Comment:** 

> **TL;DR:** HIPPO是一个分层对比学习框架，用于跨生物体PPI预测，它通过整合蛋白质的层次属性和功能关系，在低数据量和零样本场景下实现了最先进的性能和强大的泛化能力。

**AI_Comments:** 该论文的创新点在于提出了一个分层对比学习框架HIPPO，巧妙地将蛋白质的层次属性和功能关系整合到PPI预测中。其通过分层对比损失和数据驱动的惩罚机制，实现了学习到的嵌入空间与蛋白质内在功能层次的一致性。该方法的显著优势在于其在低数据量环境下的鲁棒性和强大的零样本跨物种迁移能力，这对于研究数据稀缺或未充分表征的生物体具有重要意义。这为跨物种PPI预测提供了一个统一且高效的解决方案，在生物信息学领域具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI方法在桥接异构生物数据模态方面显示出对比学习的潜力，但仍需一个统一的框架来应对稀疏或不平衡的多物种数据场景下的蛋白质-蛋白质相互作用（PPI）预测挑战，尤其是在实验数据有限的物种中。

**Method:** 该论文提出了HIPPO（HIerarchical Protein-Protein interaction prediction across Organisms），一个分层对比学习框架，用于蛋白质-蛋白质相互作用（PPI）预测。它通过多层生物表示匹配来对齐蛋白质序列及其层次属性。该方法引入了分层对比损失函数，模拟蛋白质功能类别之间的结构化关系，并通过数据驱动的惩罚机制自适应地整合域和家族知识，以确保学习到的嵌入空间与蛋白质功能的内在层次结构一致。

**Result:** 实验结果表明，HIPPO在基准数据集上取得了最先进的性能，优于现有方法，并在低数据量环境下表现出鲁棒性。值得注意的是，该模型展示了强大的零样本迁移能力，无需重新训练即可应用于其他物种。进一步分析揭示，分层特征融合对于捕获保守的相互作用决定因素（如结合基序和功能注释）至关重要。

**Conclusion:** 这项工作推动了跨物种PPI预测的进展，并为稀疏或不平衡多物种数据场景下的相互作用预测提供了一个统一的框架。

> **ai_Abstract:** 本研究提出了HIPPO，一个新颖的分层对比学习框架，用于跨物种蛋白质-蛋白质相互作用（PPI）预测。HIPPO通过多层表示匹配对齐蛋白质序列及其层次属性，并利用分层对比损失和数据驱动惩罚机制来整合蛋白质功能知识。实验证明，HIPPO在多个基准数据集上达到最先进性能，在低数据量和零样本迁移方面表现出色，尤其适用于实验数据稀缺的物种。研究强调分层特征融合对捕获关键相互作用决定因素的重要性，为处理多物种稀疏数据提供了统一的解决方案。

> **摘要翻译:** 科学领域人工智能的最新进展突显了对比学习在桥接异构生物数据模态方面的强大能力。基于这一范式，我们提出了HIPPO（HIerarchical Protein-Protein interaction prediction across Organisms），一个用于蛋白质-蛋白质相互作用（PPI）预测的分层对比框架，其中蛋白质序列及其层次属性通过多层生物表示匹配进行对齐。所提出的方法结合了分层对比损失函数，模拟蛋白质功能类别之间的结构化关系。该框架通过数据驱动的惩罚机制自适应地整合域和家族知识，强制学习到的嵌入空间与蛋白质功能的内在层次结构保持一致。在基准数据集上的实验表明，HIPPO取得了最先进的性能，优于现有方法，并在低数据量环境下表现出鲁棒性。值得注意的是，该模型展示了强大的零样本迁移能力，无需重新训练即可应用于其他物种，即使在实验数据有限的特征不明确或稀有生物体中也能实现可靠的PPI预测和功能推断。进一步分析揭示，分层特征融合对于捕获保守的相互作用决定因素，如结合基序和功能注释，至关重要。这项工作推进了跨物种PPI预测，并为稀疏或不平衡多物种数据场景下的相互作用预测提供了一个统一的框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [579] [Structured Transformations for Stable and Interpretable Neural Computation](https://arxiv.org/abs/2508.00127)
> *用于稳定和可解释神经网络计算的结构化变换*

*Saleh Nikooroo, Thomas Engel* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** 结构化变换, 神经网络, 稳定性, 可解释性, 鲁棒性

**Comment:** 

> **TL;DR:** 该论文提出了一种新的层级变换方法，通过将每个变换分解为结构化线性算子和残差校正分量，以提高神经网络的稳定性和可解释性。实验表明，这种方法改善了梯度条件、降低了对扰动的敏感性并增强了鲁棒性。

**AI_Comments:** 该论文通过在层级引入根本性的架构改变，解决了当前神经网络在稳定性和可解释性方面的关键限制。将变换分解为结构化和残差分量是一种创新的方式，可以对信号流施加约束，这对于改善训练和鲁棒性至关重要。其与现有学习范式的兼容性使其具有实用性。对平衡性能与透明度的原则性架构的关注，对于未来可靠人工智能的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管性能出色，但当代神经网络缺乏促进稳定学习和可解释行为的结构性保障。

**Method:** 引入了层级变换的重新公式化，将每个变换分解为一个结构化线性算子和一个残差校正分量。这种公式化鼓励内部一致性并支持跨深度的稳定信息流，同时与标准学习目标和反向传播完全兼容。

**Result:** 用这些结构化变换构建的模型表现出改进的梯度条件、降低的扰动敏感性和层级鲁棒性。这些优势在不同的架构规模和训练方案中持续存在。

**Conclusion:** 这项研究为一类更具原则性的神经网络架构奠定了基础，这些架构优先考虑稳定性和透明度，在不牺牲表达能力的情况下，为推理学习行为提供了新工具。

> **ai_Abstract:** 本文提出了一种新颖的神经网络层级变换方法，用结构化分解取代了标准的无约束仿射操作。通过将变换分解为结构化线性算子和残差分量，该方法增强了信号传播和训练动态。实验结果表明，采用这些结构化变换的模型在各种规模和训练条件下均实现了改进的梯度条件、降低的扰动敏感性和增强的鲁棒性，为更稳定和可解释的神经网络架构铺平了道路。

> **摘要翻译:** 尽管性能令人印象深刻，但当代的神经网络通常缺乏促进稳定学习和可解释行为的结构性保障。在这项工作中，我们引入了一种层级变换的重新公式化，它偏离了标准的无约束仿射范式。每个变换都被分解为一个结构化线性算子和一个残差校正分量，从而实现更有纪律的信号传播和改进的训练动态。我们的公式鼓励内部一致性并支持跨深度的稳定信息流，同时与标准学习目标和反向传播完全兼容。通过一系列合成和真实世界的实验，我们证明了用这些结构化变换构建的模型表现出改进的梯度条件、降低的扰动敏感性和层级鲁棒性。我们进一步表明，这些优势在不同的架构规模和训练方案中持续存在。这项研究为一类更具原则性的神经网络架构奠定了基础，这些架构优先考虑稳定性和透明度——在不牺牲表达能力的情况下，为推理学习行为提供了新工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [585] [Wind Power Scenario Generation based on the Generalized Dynamic Factor Model and Generative Adversarial Network](https://arxiv.org/abs/2508.00692)
> *风电场景生成：基于广义动态因子模型和生成对抗网络*

*Young-ho Cho, Hao Zhu, Duehee Lee, Ross Baldick* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 风电场景生成, 广义动态因子模型, 生成对抗网络, 时空相关性, 资源充足性

**Comment:** 

> **TL;DR:** 结合广义动态因子模型（GDFM）和生成对抗网络（GAN）生成更真实的长期风电场景，用于资源充足性研究。

**AI_Comments:** 该论文创新性地结合了GDFM和GAN，解决了传统GDFM在模仿波形方面的不足以及GAN在捕捉空间和频率相关性方面的潜在挑战。通过GAN作为GDFM的滤波器，该方法能够更全面地捕获风电场景的复杂时空特征，这对于需要高精度风电预测和场景生成的电力系统资源规划具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了进行资源充足性研究，需要同时合成具有空间和时间相关性、波形、边际和斜坡率分布等多种时空特征的分布式风电场长期风电场景。

**Method:** 结合GDFM和GAN的优点，利用GAN提供一个滤波器，从观测数据中提取具有时间信息的动态因子，然后将此滤波器应用于GDFM，以同时表示合理波形的空间和频率相关性。

**Result:** 在澳大利亚风电场景合成的数值测试中，GDFM和GAN的组合方案比其他竞争替代方案表现出性能改进，并且比替代方案更能真实地实现实际风电的统计特性。

**Conclusion:** 结合GDFM和GAN的方法能够有效且更真实地合成具有复杂时空特征的长期风电场景。

> **ai_Abstract:** 本研究提出一种结合广义动态因子模型（GDFM）和生成对抗网络（GAN）的方法，用于同时合成具有复杂时空特征的长期分布式风电场景，以支持资源充足性研究。该方法利用GAN作为滤波器，从观测数据中提取动态时间信息，并将其整合到GDFM中，从而同时捕捉风电场景的空间和频率相关性。实验结果表明，与现有替代方案相比，该组合方法在生成风电场景的性能和对实际风电统计特性的逼真度方面均有显著提升。

> **摘要翻译:** 为了进行资源充足性研究，我们通过利用空间和时间相关性、波形、波形的边际和斜坡率分布、功率谱密度以及统计特性等时空特征，同时合成了多个分布式风电场的长期风电场景。在场景中生成空间相关性需要为邻近风电场设计共同因子，为远距离风电场设计反向因子。广义动态因子模型（GDFM）可以通过交叉谱密度分析提取共同因子，但它无法紧密模仿波形。生成对抗网络（GAN）可以通过伪样本判别器验证样本，从而合成代表时间相关性的合理样本。为了结合GDFM和GAN的优点，我们使用GAN提供一个滤波器，从观测数据中提取具有时间信息的动态因子，然后将此滤波器应用于GDFM，以表示合理波形的空间和频率相关性。GDFM和GAN组合的数值测试表明，在合成澳大利亚风电场景方面，其性能优于竞争替代方案，并且与从实际动态滤波器分布合成滤波器的GDFM以及没有动态因子直接合成的GAN等替代方案相比，更能真实地实现实际风电的合理统计特性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [591] [Geometric Multi-color Message Passing Graph Neural Networks for Blood-brain Barrier Permeability Prediction](https://arxiv.org/abs/2507.18926)
> *用于血脑屏障通透性预测的几何多色消息传递图神经网络*

*Trung Nguyen, Md Masud Rana, Farjana Tasnim Mukta, Chang-Guo Zhan, Duc Duy Nguyen* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 图神经网络, 血脑屏障通透性, 几何特征, 药物发现, 分子预测

**Comment:** 

> **TL;DR:** GMC-MPNN是一种新型图神经网络，通过结合原子级几何特征和长程相互作用，在血脑屏障通透性预测方面超越了现有SOTA模型。

**AI_Comments:** 该论文的创新之处在于其将原子级几何特征和长程相互作用明确整合到图神经网络中，以解决传统GNNs在处理分子三维信息方面的局限性。这对于药物发现领域中血脑屏障通透性预测的准确性至关重要，有望加速中枢神经系统药物的开发。其性能超越现有SOTA模型，并进行了消融研究验证关键组件的有效性，证明了方法的鲁棒性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测血脑屏障通透性 (BBBP) 对于中枢神经系统 (CNS) 药物开发至关重要。现有图神经网络 (GNNs) 忽视了对建模转运机制至关重要的三维几何信息。

**Method:** 本文引入了几何多色消息传递图神经网络 (GMC-MPNN)，通过明确整合原子级几何特征和长程相互作用来增强标准消息传递架构。该模型基于原子类型构建加权彩色子图，以捕获控制BBB通透性的空间关系和化学背景。

**Result:** GMC-MPNN 在分类和回归任务上均持续优于现有最先进模型。在分类任务中，AUC-ROC 分别达到 0.9704 和 0.9685；在回归任务中，RMSE 为 0.4609，Pearson 相关系数为 0.7759。消融研究表明，模型预测能力来源于其学习常见和罕见但具有化学意义的功能基序的能力。

**Conclusion:** 通过将空间几何整合到图表示中，GMC-MPNN 设定了新的性能基准，并为药物发现流程提供了一个更准确和更具泛化性的工具。

> **ai_Abstract:** 本研究提出了一种新颖的几何多色消息传递图神经网络 (GMC-MPNN)，旨在提高血脑屏障通透性 (BBBP) 的预测准确性。该模型通过整合原子级几何特征和长程相互作用，弥补了传统图神经网络在处理三维分子信息方面的不足。GMC-MPNN 基于原子类型构建加权彩色子图，有效捕获空间关系和化学上下文。在多个基准数据集上的严格评估表明，GMC-MPNN 在分类和回归任务上均显著优于现有最先进模型，为药物发现提供了更准确和泛化能力更强的工具。

> **摘要翻译:** 准确预测血脑屏屏障通透性 (BBBP) 对于中枢神经系统 (CNS) 药物开发至关重要。虽然图神经网络 (GNNs) 已经推动了分子性质预测的进展，但它们通常依赖于分子拓扑结构，而忽略了对建模转运机制至关重要的三维几何信息。本文引入了几何多色消息传递图神经网络 (GMC-MPNN)，这是一个新颖的框架，通过明确整合原子级几何特征和长程相互作用来增强标准消息传递架构。我们的模型基于原子类型构建加权彩色子图，以捕获控制 BBB 通透性的空间关系和化学背景。我们在三个基准数据集上对 GMC-MPNN 进行了分类和回归任务评估，使用严格的基于支架的拆分以确保对泛化能力的稳健评估。结果表明，GMC-MPNN 持续优于现有最先进模型，在将化合物分类为可渗透/不可渗透（AUC-ROC 分别为 0.9704 和 0.9685）以及回归连续通透性值（RMSE 为 0.4609，Pearson 相关系数为 0.7759）方面均取得了卓越性能。一项消融研究进一步量化了特定原子对相互作用的影响，揭示了模型的预测能力源于其从常见和罕见但具有化学意义的功能基序中学习的能力。通过将空间几何整合到图表示中，GMC-MPNN 设定了新的性能基准，并为药物发现流程提供了一个更准确和更具泛化性的工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [594] [Bayesian Optimization of Process Parameters of a Sensor-Based Sorting System using Gaussian Processes as Surrogate Models](https://arxiv.org/abs/2507.22766)
> *基于高斯过程代理模型的传感器分选系统工艺参数贝叶斯优化*

*Felix Kronenwett, Georg Maier, Thomas Längle* | **Category: cs.LG, cs.AI, cs.SY, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 贝叶斯优化, 高斯过程, 传感器分选, 工艺参数, 代理模型

**Comment:** Accepted at the 30th IEEE International Conference on Emerging
  Technologies and Factory Automation (ETFA)

> **TL;DR:** 本文提出了一种使用贝叶斯优化和高斯过程代理模型来优化和监测传感器分选系统工艺参数的方法，旨在减少实验次数，同时考虑两个优化目标和不确定性。

**AI_Comments:** 该论文解决了传感器分选系统在实际应用中保持最佳性能的重要问题。采用贝叶斯优化结合高斯过程是优化昂贵且难以评估的黑箱函数的有效选择，尤其是在需要最小化实验次数的场景中。同时考虑不确定性和多目标优化增加了该方法的鲁棒性和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传感器分选系统需要根据不断变化的要求和物料流成分持续验证和重新调整工艺参数，以达到特定的系统行为和分选精度。

**Method:** 本文提出了一种基于贝叶斯优化的方法，利用高斯过程回归模型作为代理模型。该方法旨在最小化必要的实验次数，同时考虑基于两种物料输出流要求的两个可能的优化目标，并在模型计算中考虑确定分选精度时的不确定性。该方法用三个示例工艺参数进行了评估。

**Result:** 该方法用三个示例工艺参数进行了评估，结果表明它能够最小化必要的实验次数，同时考虑了两个优化目标和不确定性。

**Conclusion:** 所提出的基于高斯过程代理模型的贝叶斯优化方法能够有效地优化、监测和调整传感器分选系统的工艺参数，从而减少实验工作量，并考虑不确定性和多个优化目标。

> **ai_Abstract:** 本文提出了一种基于贝叶斯优化并利用高斯过程代理模型的方法，用于优化、监测和调整传感器分选系统的工艺参数。该方法旨在通过考虑两个优化目标和分选精度中的不确定性来减少实验次数，以应对物料流成分和要求变化导致的参数持续调整需求。该方法已通过三个示例参数进行了评估。

> **摘要翻译:** 传感器分选系统能够将物料流物理分离成两部分。分选决策基于所用传感器的图像数据评估，并通过执行器进行。根据物料流的特性、系统的尺寸和所需的分选精度，必须设置各种工艺参数。然而，由于不断变化的要求和物料流成分，需要持续验证和重新调整。在本文中，我们引入了一种用于优化、循环监测和调整传感器分选系统工艺参数的方法。基于贝叶斯优化，高斯过程回归模型被用作代理模型，以实现系统行为的特定要求及其包含的不确定性。该方法在考虑对两种物料输出流的要求的基础上，同时考虑两个可能的优化目标，从而最大限度地减少了必要的实验次数。此外，在模型计算中确定分选精度时考虑了不确定性。我们用三个示例工艺参数评估了该方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [598] [Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2508.00695)
> *精神病学临床笔记按诊断分类：一种深度学习和机器学习方法*

*Sergio Rubio-Martín, María Teresa García-Ordás, Antonio Serrano-García, Clara Margarita Franch-Pato, Arturo Crespo-Álvaro, José Alberto Benítez-Andrades* | **Category: cs.LG, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 临床笔记分类, 深度学习, 机器学习, 精神病学, 超参数调整

**Comment:** 

> **TL;DR:** 本研究比较了机器学习和深度学习模型在精神病学临床笔记诊断分类中的表现，并评估了过采样策略和超参数调整的影响，发现超参数调整显著提高了模型准确性。

**AI_Comments:** 这篇论文的创新点在于系统地比较了多种传统机器学习和深度学习模型在精神科临床笔记诊断分类上的表现，并深入探讨了过采样策略和超参数优化对模型性能的影响。研究结果强调了超参数调优的重要性，这对于构建鲁棒和高效的AI辅助诊断工具具有实际指导意义。其局限性可能在于仅限于两种特定诊断的分类，且数据集规模和多样性未在摘要中详细说明。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗保健领域，特别是对于焦虑症和适应障碍等精神健康状况，将临床笔记分类到特定的诊断类别至关重要。

**Method:** 研究比较了传统机器学习方法（随机森林、支持向量机、K近邻、决策树和eXtreme Gradient Boost）和深度学习模型（DistilBERT和SciBERT）的性能。此外，还实施了三种过采样策略（无过采样、随机过采样和SMOTE）以及超参数调整。

**Result:** 过采样技术对整体模型性能影响最小，仅SMOTE对基于BERT的模型有积极影响。超参数优化显著提高了所有模型的准确性。决策树和eXtreme Gradient Boost模型在机器学习方法中达到96%的最高准确率，而DistilBERT和SciBERT模型在深度学习类别中也达到96%的准确率。

**Conclusion:** 超参数调整在最大化模型性能方面至关重要。本研究通过提供对不同模型架构和数据平衡方法有效性的见解，为AI辅助精神健康诊断工具的持续研究做出了贡献。

> **ai_Abstract:** 本研究旨在将精神病学临床笔记分类为焦虑症和适应障碍两种诊断，比较了多种机器学习和深度学习模型的性能。研究评估了过采样策略和超参数调整对模型准确性的影响。结果显示，超参数调整显著提升了所有模型的准确性，而过采样技术（除SMOTE对BERT模型外）影响不大。决策树、eXtreme Gradient Boost、DistilBERT和SciBERT模型均达到了96%的准确率，强调了超参数调整在优化模型性能中的关键作用。

> **摘要翻译:** 将临床笔记分类到特定的诊断类别在医疗保健领域至关重要，特别是对于焦虑症和适应障碍等精神健康状况。在本研究中，我们比较了各种人工智能模型的性能，包括传统机器学习方法（随机森林、支持向量机、K近邻、决策树和eXtreme Gradient Boost）和深度学习模型（DistilBERT和SciBERT），以将临床笔记分类为这两种诊断。此外，我们实施了三种过采样策略：无过采样、随机过采样和合成少数类过采样技术（SMOTE），以评估它们对模型性能的影响。超参数调整也被应用于优化模型准确性。我们的结果表明，过采样技术对整体模型性能影响最小。唯一的例外是SMOTE，它专门对基于BERT的模型显示出积极效果。然而，超参数优化显著提高了所有模型的准确性，增强了它们在数据集上的泛化和表现能力。决策树和eXtreme Gradient Boost模型在机器学习方法中取得了最高准确率，均达到96%，而DistilBERT和SciBERT模型在深度学习类别中也达到了96%的准确率。这些发现强调了超参数调整在最大化模型性能方面的重要性。本研究通过提供对不同模型架构和数据平衡方法有效性的见解，为AI辅助精神健康诊断工具的持续研究做出了贡献。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [604] [ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks](https://arxiv.org/abs/2508.00131)
> *基于自编码器的心电图潜在特征提取用于下游预测任务*

*Christopher Harvey, Sumaiya Shomaji, Zijun Yao, Amit Noheria* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** ECG, 自编码器, 变分自编码器, 特征提取, 深度学习, 预测任务

**Comment:** arXiv admin note: substantial text overlap with arXiv:2410.02937

> **TL;DR:** 本研究利用变分自编码器（VAE）变体提取心电图（ECG）特征，以解决小数据集下深度学习模型的挑战，并在下游预测任务中实现了与最先进卷积神经网络（CNN）模型相当的性能，同时显著降低了计算资源需求。

**AI_Comments:** 本研究的创新点在于利用多种变分自编码器（VAE）变体进行心电图（ECG）潜在特征提取，并证明了其在下游预测任务中（如LVEF预测）的有效性。其重要性体现在：1) 解决了ECG数据高复杂性和小数据集下深度学习应用面临的挑战；2) 实现了与最先进卷积神经网络（CNN）模型相媲美的性能，同时显著降低了计算资源需求；3) 提供了在数据受限场景下应用深度学习的实用解决方案。这对于临床实践中ECG数据的处理和分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管心电图（ECG）是一种廉价且广泛可用的心脏评估工具，但其高复杂性和个体间差异性使得在深度学习模型中使用它变得具有挑战性，尤其是在训练数据集较小的情况下。

**Method:** 本研究通过探索从代表性心跳ECG中生成特征的方法来解决这些挑战，重点关注主成分分析（PCA）和自编码器以降低数据复杂性。引入了三种新颖的变分自编码器（VAE）变体：随机自编码器（SAE）、退火beta-VAE（A beta-VAE）和循环beta-VAE（C beta-VAE），并比较了它们在保持信号保真度和使用Light Gradient Boost Machine（LGBM）增强下游预测任务方面的有效性。

**Result:** A beta-VAE实现了卓越的信号重建，将平均绝对误差（MAE）降低到15.7+/-3.2 µV，达到了信号噪声水平。此外，SAE编码与传统ECG汇总特征相结合，改善了左心室射血分数（LVEF）降低的预测，使用LGBM分类器在保留测试集上实现了0.901的受试者操作特征曲线下面积（AUROC）。这一性能几乎与最先进的CNN模型0.909的AUROC相匹配，但所需的计算资源显著减少。此外，ECG特征提取-LGBM管道避免了过拟合，并在使用更少数据进行训练时仍保持预测性能。

**Conclusion:** 本研究发现表明，这些VAE编码不仅在简化ECG数据方面有效，而且为在有限规模标记训练数据环境下应用深度学习提供了实用的解决方案。

> **ai_Abstract:** 本研究旨在解决心电图（ECG）数据复杂性高、个体差异大以及小训练数据集下深度学习模型应用困难的问题。研究探索了主成分分析（PCA）和自编码器（Autoencoders）等特征生成方法，并引入了三种新颖的变分自编码器（VAE）变体：随机自编码器（SAE）、退火beta-VAE（A beta-VAE）和循环beta-VAE（C beta-VAE）。结果显示，A beta-VAE在信号重建方面表现出色，将平均绝对误差（MAE）降低至15.7+/-3.2 µV。SAE编码结合传统ECG特征，显著提升了左心室射血分数（LVEF）降低的预测性能，在LGBM分类器下取得了0.901的AUROC，接近最先进CNN模型的0.909 AUROC，但计算资源需求大幅减少。此外，该ECG特征提取-LGBM流程在数据量较少时也能有效避免过拟合并保持预测性能。研究证明这些VAE编码能有效简化ECG数据，为有限标记训练数据下的深度学习应用提供了实用方案。

> **摘要翻译:** 心电图（ECG）是一种廉价且广泛可用的心脏评估工具。尽管其格式标准化且文件大小较小，但ECG信号的高度复杂性和个体间变异性（通常是500 Hz下12导联的60,000大小向量）使其在深度学习模型中难以使用，特别是当只有小型训练数据集可用时。本研究通过探索从代表性心跳ECG中生成特征的方法来解决这些挑战，重点关注主成分分析（PCA）和自编码器以降低数据复杂性。我们引入了三种新颖的变分自编码器（VAE）变体——随机自编码器（SAE）、退火beta-VAE（A beta-VAE）和循环beta-VAE（C beta-VAE）——并比较了它们在保持信号保真度和使用Light Gradient Boost Machine（LGBM）增强下游预测任务方面的有效性。A beta-VAE实现了卓越的信号重建，将平均绝对误差（MAE）降低到15.7+/-3.2 µV，这达到了信号噪声水平。此外，SAE编码与传统ECG汇总特征相结合，改善了左心室射血分数（LVEF）降低的预测，使用LGBM分类器在保留测试集上实现了0.901的受试者操作特征曲线下面积（AUROC）。这一性能几乎与最先进的CNN模型0.909的AUROC相匹配，但所需的计算资源显著减少。此外，ECG特征提取-LGBM管道避免了过拟合，并在使用更少数据进行训练时仍保持预测性能。我们的发现表明，这些VAE编码不仅在简化ECG数据方面有效，而且为在有限规模标记训练数据环境下应用深度学习提供了实用的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [605] [Learning Network Dismantling without Handcrafted Inputs](https://arxiv.org/abs/2508.00706)
> *学习无需手工输入进行网络拆解*

*Haozhe Tian, Pietro Ferraro, Robert Shorten, Mahdi Jalili, Homayoun Hamedmoghadam* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 网络拆解, 图神经网络, 注意力机制, 合成网络, 泛化能力

**Comment:** 

> **TL;DR:** MIND模型通过注意力机制和消息迭代，无需手工特征即可高效解决网络拆解问题，性能超越现有方法并能泛化到大型真实网络。

**AI_Comments:** 该论文的创新点在于通过引入注意力机制和消息迭代配置文件，成功地摆脱了传统图神经网络对昂贵且有偏差的手工特征的依赖。通过在多样化的合成网络上训练模型，实现了对大型真实网络的出色泛化能力，这对于解决NP-hard的网络拆解问题具有重要意义。该方法提高了效率和泛化性，为复杂网络分析领域带来了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图神经网络在网络科学问题中表现出色，但其性能常依赖于手工制作的结构特征作为输入，这增加了计算成本并给纯粹的数据驱动网络表示引入了偏差。

**Method:** 引入注意力机制和消息迭代配置文件，并利用有效的算法生成结构多样的小型合成网络训练集。在此基础上构建了富有表达力的消息传递框架MIND模型，用于高效解决网络拆解的NP-hard问题。

**Result:** 提出的MIND模型仅在多样化的合成网络上训练，就能泛化到数百万节点的大型、未见过的真实网络，并超越了最先进的网络拆解方法。

**Conclusion:** 提出的模型提高了效率和泛化能力，其优势可应用于更广泛的复杂网络问题，而不仅仅是网络拆解。

> **ai_Abstract:** 本文提出了一种名为MIND（Message Iteration Network Dismantler）的新型消息传递框架，旨在解决网络拆解这一NP-hard问题，而无需依赖传统图神经网络中常用的手工结构特征。MIND通过引入注意力机制和利用消息迭代配置文件，并结合生成多样化合成训练集的方法，构建了一个高效且具有泛化能力的模型。实验表明，MIND在仅对合成网络训练后，能有效泛化到大型真实网络，并超越了现有的网络拆解方法，展现出在复杂网络问题中更广泛的应用潜力。

> **摘要翻译:** 消息传递图神经网络的应用是解决重要网络科学问题的一项突破。然而，其竞争性性能通常依赖于使用手工制作的结构特征作为输入，这增加了计算成本，并给原本纯粹的数据驱动网络表示引入了偏差。在此，我们通过引入注意力机制和利用消息迭代配置文件，并结合一种有效的算法方法来生成结构多样的小型合成网络训练集，从而消除了对手工特征的需求。因此，我们构建了一个富有表达力的消息传递框架，并用它来高效解决网络拆解的NP-hard问题（实际上等同于重要节点识别），具有重要的实际应用价值。我们提出的模型MIND（Message Iteration Network Dismantler）仅在多样化的合成网络上进行训练，就能泛化到数百万节点的大型、未见过的真实网络，其性能优于最先进的网络拆解方法。所提出模型提高的效率和泛化能力可以超越拆解问题，应用于一系列复杂的网络问题。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [613] [Flow Matching Policy Gradients](https://arxiv.org/abs/2507.21053)
> *流匹配策略梯度*

*David McAllister, Songwei Ge, Brent Yi, Chung Min Kim, Ethan Weber, Hongsuk Choi, Haiwen Feng, Angjoo Kanazawa* | **Category: cs.LG, cs.RO** | **Updated: 2025-08-01**

**Keywords:** 流匹配, 策略梯度, 强化学习, 扩散模型, 流策略优化

**Comment:** See our blog post at https://flowreinforce.github.io

> **TL;DR:** 引入了流策略优化（FPO），一个将流匹配引入策略梯度框架的强化学习算法，能够训练扩散式策略并处理多模态动作分布。

**AI_Comments:** FPO的创新点在于将流匹配引入策略梯度框架，解决了传统流基模型在RL中应用时对精确似然计算的需求以及对特定采样方法的依赖。其兼容PPO-clip框架，并能处理多模态动作分布，这对于复杂的连续控制任务具有重要意义。该方法为扩散模型在强化学习领域的应用开辟了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的流基生成模型在建模高维连续分布方面表现出色，但将其应用于强化学习（特别是策略梯度）仍面临挑战，例如需要精确似然计算或对特定采样方法的依赖。

**Method:** 本文提出了流策略优化（FPO），一个简单的在线策略强化学习算法，将流匹配引入策略梯度框架。FPO将策略优化视为最大化一个由条件流匹配损失计算的优势加权比率，并与PPO-clip框架兼容。它避免了精确似然计算的需求，同时保留了流基模型的生成能力，并且在训练和推理时对扩散或流积分的选择是不可知的。

**Result:** FPO能够从头开始训练扩散式策略，适用于多种连续控制任务。实验表明，流基模型可以捕获多模态动作分布，并且在欠条件设置下比高斯策略实现更高的性能。

**Conclusion:** 流策略优化（FPO）成功地将流匹配引入策略梯度框架，提供了一种无需精确似然计算且对采样方法无关的强化学习方法，尤其擅长处理多模态动作分布并在连续控制任务中表现优异。

> **ai_Abstract:** 本文提出了一种名为流策略优化（FPO）的在线策略强化学习算法。FPO将流匹配技术融入策略梯度框架，通过最大化优势加权比率（基于条件流匹配损失）进行策略优化，并与PPO-clip兼容。该方法避免了精确似然计算，并对扩散或流积分的选择具有普适性。实验证明，FPO能够从零开始训练扩散式策略，在连续控制任务中表现出色，尤其在捕获多模态动作分布和在欠条件环境下优于高斯策略方面显示出优势。

> **摘要翻译:** 流基生成模型，包括扩散模型，擅长在高维空间中建模连续分布。在这项工作中，我们引入了流策略优化（FPO），这是一种简单的在线策略强化学习算法，它将流匹配引入策略梯度框架。FPO将策略优化视为最大化一个由条件流匹配损失计算的优势加权比率，其方式与流行的PPO-clip框架兼容。它避免了精确似然计算的需求，同时保留了流基模型的生成能力。与之前将训练绑定到特定采样方法的基于扩散的强化学习方法不同，FPO在训练和推理时都与扩散或流积分的选择无关。我们展示了FPO可以在各种连续控制任务中从头开始训练扩散式策略。我们发现流基模型可以捕获多模态动作分布，并且比高斯策略实现更高的性能，尤其是在欠条件设置下。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [619] [Unlocking Multi-Modal Potentials for Link Prediction on Dynamic Text-Attributed Graphs](https://arxiv.org/abs/2502.19651)
> *释放多模态潜力用于动态文本属性图上的链接预测*

*Yuanyuan Xu, Wenjie Zhang, Ying Zhang, Xuemin Lin, Xiwei Xu* | **Category: cs.LG, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 动态文本属性图, 链接预测, 多模态, 模态对齐, 节点表示

**Comment:** 

> **TL;DR:** MoMent通过显式建模和对齐时间、文本和结构模态，显著提升了动态文本属性图上的链接预测性能。

**AI_Comments:** 该论文的创新点在于明确指出并解决了动态文本属性图中多模态（时间、文本、结构）信息未被充分利用的问题。其提出的MoMent模型通过模态特定编码和双域对齐损失，有效地整合了异构信息，并从理论上保证了节点表示的全面性。实验结果的显著提升（尤其是速度）表明了其在实际应用中的巨大潜力。这对于理解和预测复杂动态图上的事件具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 动态文本属性图（DyTAGs）包含时间、文本和结构三种模态，但现有研究在处理链接预测时，普遍忽略了前两种模态，导致性能不佳，因为这些模态往往表现出完全不相交的分布。

**Method:** 本文提出了MoMent，一个多模态模型，旨在显式建模、集成和对齐每种模态以学习节点表示。MoMent首先构建模态特定特征，并使用独立编码器进行编码，以捕捉时间模式、语义上下文和局部结构之间的相关性。各编码器生成模态特定令牌，然后将其融合为全面的节点表示。为避免异构模态的不相交子空间，MoMent提出了一种双域对齐损失，首先全局对齐其分布，然后对实例级别的一致性进行微调。

**Result:** 在七个数据集上的大量实验表明，MoMent相对于八个基线模型，准确率提高了17.28%，速度提升了31倍。

**Conclusion:** MoMent模型通过有效建模、整合和对齐动态文本属性图中的时间、文本和结构多模态信息，并引入双域对齐损失，显著提升了链接预测的准确性和效率，证明了多模态潜力在处理此类复杂图结构中的重要性。

> **ai_Abstract:** 本文提出MoMent，一个针对动态文本属性图（DyTAGs）的创新多模态模型，以解决现有链接预测方法忽视时间与文本模态导致性能次优的问题。MoMent显式建模并整合时间、文本和结构三种模态，通过独立编码器生成模态特定特征，并利用双域对齐损失实现模态间的全局和实例级对齐。实验结果表明，MoMent在准确性和速度上均显著优于现有基线，最高准确率提升17.28%，速度提升31倍。

> **摘要翻译:** 动态文本属性图（DyTAGs）是一种新颖的图范式，它捕获演变的时间事件（边）以及丰富的文本属性。现有研究大致可分为TGNN驱动和LLM驱动的方法，这两种方法都编码文本属性和时间结构以进行DyTAG表示。我们观察到DyTAGs本质上包含三种不同的模态：时间、文本和结构，这些模态通常表现出完全不相交的分布。然而，前两种模态在现有研究中很大程度上被忽视，导致次优性能。为了解决这个问题，我们提出了MoMent，一个多模态模型，它显式地建模、集成和对齐每种模态，以学习用于链接预测的节点表示。考虑到原始模态分布的不相交性质，我们首先构建模态特定特征，并使用单独的编码器对其进行编码，以捕获时间模式、语义上下文和局部结构之间的相关性。每个编码器生成模态特定令牌，然后将其融合为具有理论保证的综合节点表示。为了避免这些异构模态的不相交子空间，我们提出了一种双域对齐损失，该损失首先全局对齐它们的分布，然后在实例级别微调一致性。这增强了时间、文本和结构视图的连贯表示。在七个数据集上的大量实验表明，MoMent相对于八个基线模型，准确率提高了17.28%，速度提升了31倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [620] [Teaching the Teacher: Improving Neural Network Distillability for Symbolic Regression via Jacobian Regularization](https://arxiv.org/abs/2507.22767)
> *教导教师：通过雅可比正则化提高神经网络对符号回归的可蒸馏性*

*Soumyadeep Dhar, Kei Sen Fong, Mehul Motani* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 知识蒸馏, 符号回归, 雅可比正则化, 可解释AI, 平滑函数

**Comment:** 

> **TL;DR:** 提出一种新的训练范式，利用基于雅可比的正则化来训练“教师”网络，使其学习更平滑、更易于蒸馏的函数，从而显著提高蒸馏出的符号模型的精度。

**AI_Comments:** 这项工作的创新点在于它改变了传统的知识蒸馏范式，从被动蒸馏转变为主动优化教师网络，使其更适合后续的符号发现。通过引入雅可比正则化，强制教师网络学习更平滑的函数，这对于提高蒸馏出的符号模型的保真度和可解释性至关重要。其显著的性能提升（R^2分数相对提高120%）证明了该方法的有效性和重要性，为构建更可靠、更易于理解的AI系统提供了一条有前景的路径。

<details>
  <summary>Details</summary>

**Motivation:** 将大型神经网络蒸馏成简单、人类可读的符号公式是实现可信和可解释AI的一个有前景的方向。然而，这一过程通常很脆弱，因为标准网络学习的复杂函数不适合符号发现，导致学生模型保真度低。

**Method:** 提出一种新颖的训练范式，不再被动地蒸馏预训练网络，而是引入一个基于雅可比的正则化器，主动鼓励“教师”网络学习不仅准确，而且本质上更平滑、更适合蒸馏的函数。

**Result:** 在真实世界回归基准上的大量实验表明，通过优化每个问题的正则化强度，相比标准蒸馏流程，最终蒸馏的符号模型的R^2分数平均提高了120%（相对），同时保持了教师模型的预测准确性。

**Conclusion:** 本工作提出了一种实用且有原则的方法，显著提高了从复杂神经网络中提取的可解释模型的保真度。

> **ai_Abstract:** 该研究旨在解决将大型神经网络蒸馏为可解释符号公式时遇到的保真度低问题。作者提出一种新的训练范式，引入基于雅可比的正则化器，主动使“教师”网络学习更平滑、更易于蒸馏的函数。实验结果显示，与标准方法相比，该方法能将蒸馏出的符号模型的R^2分数相对提高120%，同时不损失教师网络的预测精度，从而显著提升了可解释模型的质量。

> **摘要翻译:** 将大型神经网络蒸馏成简单、人类可读的符号公式是实现可信和可解释AI的一个有前景的方向。然而，这一过程通常很脆弱，因为标准网络学习的复杂函数不适合符号发现，导致学生模型保真度低。在这项工作中，我们提出了一种新颖的训练范式来解决这一挑战。我们不再被动地蒸馏预训练网络，而是引入了一个基于雅可比的正则化器，主动鼓励“教师”网络学习不仅准确，而且本质上更平滑、更适合蒸馏的函数。我们通过在真实世界回归基准上进行的大量实验证明了我们方法的有效性。通过为每个问题优化正则化强度，与标准蒸馏流程相比，最终蒸馏出的符号模型的R^2分数平均提高了120%（相对），同时保持了教师模型的预测准确性。我们的工作提出了一种实用且有原则的方法，可以显著提高从复杂神经网络中提取的可解释模型的保真度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [626] [Coflex: Enhancing HW-NAS with Sparse Gaussian Processes for Efficient and Scalable DNN Accelerator Design](https://arxiv.org/abs/2507.23437)
> *Coflex：利用稀疏高斯过程增强硬件感知神经架构搜索，实现高效可扩展的深度神经网络加速器设计*

*Yinhui Ma, Tomomasa Yamasaki, Zhehui Wang, Tao Luo, Bo Wang* | **Category: cs.LG, I.2.6; C.1.3; C.3** | **Updated: 2025-08-01**

**Keywords:** 硬件感知神经架构搜索, 稀疏高斯过程, 深度神经网络加速器, 贝叶斯优化, 计算效率

**Comment:** Accepted to the 2025 International Conference on Computer-Aided
  Design (ICCAD); 9 pages, including 6 figures and 7 tables

> **TL;DR:** Coflex是一个新的硬件感知神经架构搜索（HW-NAS）框架，它通过结合稀疏高斯过程和多目标贝叶斯优化，解决了HW-NAS面临的搜索空间大和计算成本高的问题。Coflex显著降低了计算开销，同时提高了预测精度，并在各项基准测试中超越了现有技术，实现了显著的加速。

**AI_Comments:** Coflex的创新点在于将稀疏高斯过程引入到硬件感知神经架构搜索中，通过降低高斯过程核的复杂度，有效解决了大规模搜索空间带来的计算挑战。这对于边缘设备上的深度神经网络加速器设计具有重要意义，因为它在保证优化性能的同时，显著提升了搜索效率和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 硬件感知神经架构搜索（HW-NAS）在边缘设备上开发深度神经网络加速器方面非常有用，但其庞大的搜索空间和高计算成本严重阻碍了其实际应用。

**Method:** 我们提出了Coflex，一个新颖的HW-NAS框架，它将稀疏高斯过程（SGP）与多目标贝叶斯优化相结合。通过利用稀疏诱导点，Coflex将高斯过程（GP）核的复杂度从相对于训练样本数量的立方级降低到近线性级，从而实现了大规模搜索空间的可扩展近似，显著降低了计算开销，同时保持了高预测精度。

**Result:** 实验结果表明，Coflex在网络精度和能量-延迟积方面优于最先进的方法，同时实现了1.9倍至9.5倍的计算加速。

**Conclusion:** Coflex通过引入稀疏高斯过程和多目标贝叶斯优化，有效解决了HW-NAS的计算开销和可扩展性问题，显著提升了深度神经网络加速器设计的效率和性能。

> **ai_Abstract:** Coflex是一个创新的硬件感知神经架构搜索（HW-NAS）框架，旨在解决现有HW-NAS方法所面临的巨大搜索空间和高计算成本问题。它通过集成稀疏高斯过程（SGP）与多目标贝叶斯优化，利用稀疏诱导点将高斯过程核的复杂度从立方级降低到近线性级，从而实现了大规模搜索空间的高效近似。实验证明，Coflex在网络精度和能量-延迟积方面超越了现有技术，并显著提升了计算速度，使其成为设计高效可扩展深度神经网络加速器的有效工具。

> **摘要翻译:** 硬件感知神经架构搜索（HW-NAS）是一种有效的方法，可以自动协同优化神经网络性能和硬件能效，这使得它在边缘设备上开发深度神经网络加速器方面特别有用。然而，其庞大的搜索空间和高计算成本给其实际应用带来了巨大挑战。为了解决这些限制，我们提出了Coflex，一个新颖的HW-NAS框架，它将稀疏高斯过程（SGP）与多目标贝叶斯优化相结合。通过利用稀疏诱导点，Coflex将高斯过程（GP）核的复杂度从相对于训练样本数量的立方级降低到近线性级，而不会影响优化性能。这使得大规模搜索空间的可扩展近似成为可能，从而大幅降低了计算开销，同时保持了高预测精度。我们在各种基准测试中评估了Coflex的功效，重点关注加速器专用架构。我们的实验结果表明，Coflex在网络精度和能量-延迟积方面优于最先进的方法，同时实现了1.9倍至9.5倍的计算加速。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [630] [Democratizing Tabular Data Access with an Open$\unicode{x2013}$Source Synthetic$\unicode{x2013}$Data SDK](https://arxiv.org/abs/2508.00718)
> *使用开源合成数据SDK实现表格数据访问的民主化*

*Ivona Krchova, Mariana Vargas Vieyra, Mario Scriminaci, Andrey Sidorenko* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 合成数据, 表格数据, 开源SDK, 数据隐私, 数据民主化

**Comment:** 

> **TL;DR:** 介绍了一个名为MOSTLY AI的开源合成数据SDK，旨在通过生成高质量的合成表格数据来解决数据访问受限的问题，并促进数据民主化。

**AI_Comments:** 这篇论文介绍了一个实用的开源工具，直接解决了当前机器学习领域面临的数据可访问性挑战。其创新之处在于将差分隐私、公平性感知生成和质量保证集成到一个易于使用的SDK中，并支持复杂的数据结构。该工具的快速采用表明其在实际应用中的重要性和潜力，有望显著推动数据共享和AI开发。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习开发严重依赖高质量数据，但隐私、专有利益和伦理问题导致数据可访问性受到严重限制。合成数据提供了一个可行的解决方案，可以在不损害敏感信息的情况下实现安全、广泛的数据使用。

**Method:** 本文提出了MOSTLY AI合成数据软件开发工具包（SDK），这是一个专门用于合成高质量表格数据的开源工具包。该SDK集成了差分隐私保证、公平性感知数据生成和自动化质量保证等功能，并通过灵活易用的Python接口实现。它利用TabularARGN自回归框架，支持多样的数据类型以及复杂的多表和序列数据集。

**Result:** 该SDK在性能上具有竞争力，并在速度和可用性方面有显著提升。它已被快速采用，并作为云服务和本地安装软件部署。

**Conclusion:** MOSTLY AI合成数据SDK通过解决现实世界中的数据瓶颈并促进广泛的数据民主化，展现了其在提高数据可访问性方面的实用性。

> **ai_Abstract:** 本文介绍并发布了MOSTLY AI合成数据SDK，一个开源工具包，旨在解决因隐私和伦理限制导致的数据访问难题。该SDK利用TabularARGN框架，能够生成高质量的表格合成数据，并集成差分隐私和公平性保障。它在速度和可用性上表现出色，已被广泛采用，有效促进了数据的民主化。

> **摘要翻译:** 机器学习开发严重依赖高质量数据。然而，由于隐私、专有利益和伦理问题日益增多的限制，数据可访问性面临巨大障碍。合成数据提供了一个可行的解决方案，可以在不损害敏感信息的情况下实现安全、广泛的数据使用。本文介绍了MOSTLY AI合成数据软件开发工具包（SDK），这是一个专门用于合成高质量表格数据的开源工具包。该SDK将差分隐私保证、公平性感知数据生成和自动化质量保证等强大功能集成到灵活易用的Python接口中。该SDK利用TabularARGN自回归框架，支持多样的数据类型以及复杂的多表和序列数据集，提供了具有竞争力的性能，并在速度和可用性方面有显著提升。目前，该SDK已作为云服务和本地安装软件部署，并已被快速采用，这凸显了其在解决现实世界数据瓶颈和促进广泛数据民主化方面的实用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [635] [DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission](https://arxiv.org/abs/2508.00172)
> *DiSC-Med：基于扩散的语义通信，用于鲁棒的医学图像传输*

*Fupei Guo, Hao Zheng, Xiang Zhang, Li Chen, Yue Wang, Songyang Zhang* | **Category: cs.LG, eess.IV** | **Updated: 2025-07-31**

**Keywords:** 语义通信, 医学图像传输, 扩散模型, 远程医疗, 带宽效率

**Comment:** To appear in 2025 IEEE Global Communications Conference (Globecom)

> **TL;DR:** DiSC-Med是一种新的基于扩散的语义通信框架，用于在有限带宽和噪声信道下高效、鲁棒地传输医学图像，通过语义信息捕获和增强的压缩去噪实现卓越性能。

**AI_Comments:** 该论文提出了一种创新的语义通信方法DiSC-Med，将扩散模型应用于医学图像传输，这在带宽受限和噪声环境下具有重要意义。其通过语义信息捕获而非像素级处理，显著提高了传输效率和鲁棒性，为远程医疗提供了新的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现远程医疗的及时有效响应，通过噪声信道和有限带宽高效传输医疗数据是一个关键挑战。

**Method:** 本文提出了一种名为DiSC-Med的新型基于扩散的语义通信框架，用于医学图像传输。该框架开发了医学增强型压缩和去噪模块，分别用于提高带宽效率和鲁棒性。DiSC-Med能够捕获关键语义信息，不同于传统的像素级通信框架。

**Result:** DiSC-Med在噪声信道下实现了卓越的重建性能和超高带宽效率。在真实世界医学数据集上的大量实验验证了该框架的有效性。

**Conclusion:** DiSC-Med框架被证明是有效且有潜力的，可用于鲁棒高效的远程医疗应用。

> **ai_Abstract:** DiSC-Med是一种新颖的基于扩散的语义通信框架，专为医学图像传输而设计。该框架通过集成医学增强型压缩和去噪模块，旨在克服有限带宽和噪声信道下医学数据传输的挑战。与传统方法不同，DiSC-Med专注于捕获图像的关键语义信息，从而在噪声环境下实现卓越的重建性能和超高带宽效率。实验结果验证了其在远程医疗应用中的有效性和潜力。

> **摘要翻译:** 人工智能的快速发展推动了智能健康与下一代无线通信技术的结合，激发了远程诊断和干预等令人兴奋的应用。为了实现远程医疗的及时有效响应，通过噪声信道和有限带宽高效传输医疗数据成为一个关键挑战。在这项工作中，我们提出了一种新颖的、基于扩散的语义通信框架，即DiSC-Med，用于医学图像传输。其中，开发了医学增强型压缩和去噪模块，分别用于提高带宽效率和鲁棒性。与传统的像素级通信框架不同，我们提出的DiSC-Med能够捕获关键语义信息，并在噪声信道下实现卓越的重建性能和超高带宽效率。在真实世界医学数据集上的大量实验验证了我们框架的有效性，展示了其在鲁棒和高效远程医疗应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [651] [Stress-Aware Resilient Neural Training](https://arxiv.org/abs/2508.00098)
> *压力感知弹性神经网络训练*

*Ashkan Shakarami, Yousef Yeganeh, Azade Farshad, Lorenzo Nicole, Stefano Ghidoni, Nassir Navab* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 压力感知学习, 弹性训练, 塑性变形优化器, 鲁棒性, 泛化能力

**Comment:** 16 pages, 11 figures

> **TL;DR:** 本文提出“压力感知学习”范式，通过受材料科学启发的“塑性变形优化器”在训练停滞时注入自适应噪声，使深度神经网络在训练困难时能动态调整优化行为，从而提高鲁棒性和泛化能力。

**AI_Comments:** 这篇论文的创新点在于将材料科学中的“变形”概念引入深度学习优化，通过模拟“塑性变形”来解决训练停滞和局部最优问题。其提出的“塑性变形优化器”通过自适应噪声注入，有效地引导模型走向更平坦、更具泛化性的损失景观区域，这对于提高模型在复杂环境下的稳定性和性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络在稳定训练或不确定动态环境下，优化行为需要动态调整以应对训练停滞等优化困难，并逃离尖锐局部最小值，收敛到更平坦、更具泛化性的区域。

**Method:** 本文引入“压力感知学习”范式，灵感来源于材料科学中结构疲劳的临时（弹性）和永久（塑性）变形概念。具体提出“塑性变形优化器”，当内部压力信号（反映训练损失和准确性停滞）指示持续优化困难时，向模型参数注入自适应噪声，帮助模型逃离尖锐最小值并收敛到更平坦、更具泛化性的损失景观区域。

**Result:** 在六种架构、四种优化器和七个视觉基准上的实验表明，该方法以最小的计算开销提高了模型的鲁棒性和泛化能力。

**Conclusion:** 通过“压力感知学习”和“塑性变形优化器”，深度神经网络能够动态调整优化行为以应对训练困难，从而显著提高模型的鲁棒性和泛化能力。

> **ai_Abstract:** 本文提出了“压力感知学习”这一弹性神经网络训练范式，它借鉴材料科学中的变形概念，使深度神经网络能根据训练压力动态调整优化过程。具体而言，通过“塑性变形优化器”在训练停滞时注入自适应噪声，帮助模型逃离尖锐局部最小值，收敛到更平坦、泛化性更好的区域。实验证明，该方法能以低开销提升模型的鲁棒性和泛化能力。

> **摘要翻译:** 标题：压力感知弹性神经网络训练

摘要：本文引入了压力感知学习，这是一种弹性神经网络训练范式，其中深度神经网络根据材料科学中结构疲劳启发的临时（弹性）和永久（塑性）变形概念，动态调整其优化行为——无论是在稳定的训练机制下还是在不确定的动态设置中。为了实例化这一概念，我们提出了塑性变形优化器，这是一种压力感知机制，当内部压力信号（反映训练损失和准确性的停滞）指示持续的优化困难时，它会向模型参数注入自适应噪声。这使得模型能够逃离尖锐的最小值，并收敛到损失景观中更平坦、更具泛化性的区域。在六种架构、四种优化器和七个视觉基准上的实验表明，该方法以最小的计算开销提高了鲁棒性和泛化能力。代码和3D可视化将在GitHub上提供：https://github.com/Stress-Aware-Learning/SAL。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [653] [Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in Tabular Data](https://arxiv.org/abs/2508.00758)
> *扩散调度去噪自编码器用于表格数据异常检测*

*Timur Sattarov, Marco Schreyer, Damian Borth* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 异常检测, 表格数据, 去噪自编码器, 扩散模型, 对比学习

**Comment:** 22 pages, 16 figures, 7 tables, preprint version

> **TL;DR:** DDAE结合扩散模型和去噪自编码器，通过调度噪声和对比学习，显著提升了表格数据异常检测的性能，尤其在半监督设置下表现优异。

**AI_Comments:** DDAE的创新性在于将扩散模型的噪声调度和对比学习引入到去噪自编码器中，解决了传统方法在处理复杂表格数据时适应性不足的问题。其在半监督场景下的显著性能提升尤其值得关注，这对于实际应用中半监督异常检测的需求具有重要意义。该研究不仅提出了有效的模型，还深入探讨了噪声策略的影响，为未来的研究提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 表格数据中的异常检测面临复杂特征交互和异常样本稀缺的挑战。现有的去噪自编码器依赖固定幅度的噪声，适应性受限；扩散模型虽然引入调度噪声和迭代去噪，但缺乏明确的重建映射。

**Method:** 本文提出了扩散调度去噪自编码器（DDAE）框架，该框架将基于扩散的噪声调度和对比学习整合到编码过程中，以改进异常检测。

**Result:** 在ADBench的57个数据集上进行评估，DDAE在半监督设置中表现优于现有技术，并在无监督设置中取得有竞争力的结果。与最先进的自编码器（扩散）模型基线相比，PR-AUC提高了高达65%（9%），ROC-AUC提高了16%（6%）。研究发现，较高的噪声水平有利于无监督训练，而较低的噪声和线性调度在半监督设置中是最佳的。

**Conclusion:** 这些发现强调了在表格异常检测中采用原则性噪声策略的重要性。

> **ai_Abstract:** 本文提出了一种新颖的扩散调度去噪自编码器（DDAE）框架，旨在解决表格数据异常检测中的挑战。DDAE通过结合扩散模型的噪声调度和对比学习，克服了传统去噪自编码器固定噪声的局限性以及扩散模型缺乏重建映射的问题。在ADBench的57个数据集上的评估表明，DDAE在半监督设置中显著优于现有SOTA方法，并在无监督设置中表现出竞争力，PR-AUC和ROC-AUC均有显著提升。研究还揭示了不同噪声策略对无监督和半监督训练效果的影响，强调了噪声策略在表格异常检测中的关键作用。

> **摘要翻译:** 表格数据中的异常检测由于复杂的特征交互和异常样本的稀缺性而仍然具有挑战性。去噪自编码器依赖固定幅度的噪声，限制了对不同数据分布的适应性。扩散模型引入了调度噪声和迭代去噪，但缺乏明确的重建映射。我们提出了扩散调度去噪自编码器（DDAE），这是一个将基于扩散的噪声调度和对比学习整合到编码过程中以改进异常检测的框架。我们在ADBench的57个数据集上评估了DDAE。我们的方法在半监督设置中表现优于现有技术，并在无监督设置中取得了有竞争力的结果，与最先进的自编码器（扩散）模型基线相比，PR-AUC提高了高达65%（9%），ROC-AUC提高了16%（6%）。我们观察到，较高的噪声水平有利于无监督训练，而较低的噪声和线性调度在半监督设置中是最佳的。这些发现强调了在表格异常检测中采用原则性噪声策略的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [654] [OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding](https://arxiv.org/abs/2507.02659)
> *OmniDraft：一种用于设备端推测解码的跨词汇、在线自适应草稿器*

*Ramchalam Kinattinkara Ramakrishnan, Zhaocong Yuan, Shaojie Zhuo, Chen Feng, Yicheng Lin, Chenzheng Su, Xiaopeng Zhang* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-31**

**Keywords:** 推测解码, 设备端LLM, 草稿模型, 跨词汇, 自适应草稿

**Comment:** 

> **TL;DR:** OmniDraft 是一种跨词汇、在线自适应的草稿模型，可以在设备端与任何目标大型语言模型进行推测解码，并提供 1.5-2 倍的加速。

**AI_Comments:** OmniDraft 通过使单个草稿模型能够与任何目标模型协同工作并进行在线适应，引入了一种创新方法，这是设备端大型语言模型实际部署的重要一步。混合蒸馏和在线 n-gram 缓存是关键的技术贡献。其在不同模型之间提供加速并保持兼容性的能力对实际应用场景非常重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有推测解码的草稿模型通常与目标模型不兼容，且缺乏在线适应性以提升延迟。设备端大型语言模型应用对模型成本、效率和用户定制化有高要求，因此需要一个“一稿多用”的解决方案。

**Method:** 提出 OmniDraft 统一框架。该框架通过在线 n-gram 缓存结合混合蒸馏微调来解决草稿模型和目标模型之间的跨词汇不匹配问题。此外，它还利用自适应草稿技术进一步提升解码速度。

**Result:** OmniDraft 使单个 Llama-68M 模型能够与多种目标模型（包括 Vicuna-7B、Qwen2-7B 和 Llama3-8B）进行推测解码。它提供了高达 1.5-2 倍的加速，并在数学推理、编码和文本生成任务的在线学习中展现了熟练度。

**Conclusion:** OmniDraft 成功解决了推测解码中跨词汇不兼容和在线延迟提升的挑战，实现了一个通用、自适应的草稿模型，特别适用于高效的设备端大型语言模型应用。

> **ai_Abstract:** OmniDraft 是一种用于设备端推测解码的统一框架，它允许单个在线自适应草稿模型与任何目标大型语言模型协同工作，解决了跨词汇不匹配问题并提高了解码速度。该框架采用在线 n-gram 缓存结合混合蒸馏微调和自适应草稿技术。OmniDraft 特别适用于资源受限的设备端大型语言模型应用，展示了高达 1.5-2 倍的加速，并与 Vicuna-7B、Qwen2-7B 和 Llama3-8B 等多种大型模型兼容。

> **摘要翻译:** 推测解码通常要求有一个小型、高效的草稿模型，该模型要么是预训练的，要么是离线蒸馏到特定的目标模型系列，例如 Llama 或 Qwen 模型。然而，在在线部署设置中存在两个主要挑战：1）使用与草稿模型不兼容的目标模型；2）期望随着使用和时间的推移提高延迟。在这项工作中，我们提出了 OmniDraft，一个统一的框架，使单个草稿模型能够与任何目标模型操作并动态适应用户数据。我们引入了一个带有混合蒸馏微调的在线 n-gram 缓存，以解决草稿模型和目标模型之间的跨词汇不匹配问题；并通过利用自适应草稿技术进一步提高解码速度。OmniDraft 特别适用于设备端大型语言模型（LLM）应用，其中模型成本、效率和用户定制是主要争议点。这进一步突出了解决上述挑战的需求，并促使了“一稿多用”的范式。我们通过在数学推理、编码和文本生成任务上进行在线学习来展示 OmniDraft 框架的熟练度。值得注意的是，OmniDraft 使单个 Llama-68M 模型能够与包括 Vicuna-7B、Qwen2-7B 和 Llama3-8B 模型在内的各种目标模型配对进行推测解码；此外还提供了高达 1.5-2 倍的加速。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [671] [RL as Regressor: A Reinforcement Learning Approach for Function Approximation](https://arxiv.org/abs/2508.00174)
> *RL作为回归器：一种用于函数逼近的强化学习方法*

*Yongchao Huang* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** 强化学习, 函数逼近, 回归, Actor-Critic, 损失函数

**Comment:** 7 pages

> **TL;DR:** 本文提出将回归问题视为强化学习（RL）问题，通过将模型预测视为动作并基于预测误差定义奖励信号，利用RL算法进行函数逼近，实验证明该框架成功解决回归问题并提供更大的灵活性。

**AI_Comments:** 本文的创新之处在于将回归问题重新概念化为强化学习任务，从而克服了传统回归方法在处理非标准或不可微分损失函数时的局限性。这种方法为函数逼近提供了一个更灵活的框架，尤其是在需要自定义行为或面对复杂目标时。未来研究可以探索其在更广泛实际应用中的性能和效率。

<details>
  <summary>Details</summary>

**Motivation:** 标准回归技术受限于预定义的、可微分的损失函数，这些函数可能无法完全捕捉系统所需的行为，尤其是在处理不对称成本或复杂、不可微分的目标时。

**Method:** 本文将回归问题构建为强化学习问题，将模型的预测视为一个动作，并根据预测误差定义自定义奖励信号。研究人员利用强大的RL算法进行函数逼近，并通过学习有噪声的正弦波的案例研究，开发了一个Actor-Critic智能体，并通过优先级经验回放、增加网络容量和位置编码对其进行迭代增强。

**Result:** 结果表明，强化学习框架不仅成功解决了回归问题，而且在定义目标和指导学习过程方面提供了增强的灵活性。

**Conclusion:** 强化学习框架能够成功解决回归问题，并且在定义目标和指导学习过程方面比传统回归技术具有更大的灵活性。

> **ai_Abstract:** 本文提出了一种将回归问题重新定义为强化学习（RL）问题的新范式。传统的回归方法受限于预定义的可微分损失函数，而RL方法通过将模型预测视为动作并基于预测误差设计自定义奖励信号，从而能够处理不对称成本或不可微分的目标。研究人员通过一个学习噪声正弦波的案例研究，详细介绍了如何构建和优化一个Actor-Critic智能体，并结合了优先级经验回放、增加网络容量和位置编码等技术。实验结果表明，该RL框架不仅成功解决了回归问题，而且在目标定义和学习过程指导方面展现出显著的灵活性。

> **摘要翻译:** 标准回归技术虽然强大，但通常受限于预定义的、可微分的损失函数，例如均方误差。这些函数可能无法完全捕捉系统所需的行为，尤其是在处理不对称成本或复杂、不可微分的目标时。在本文中，我们探索了一种替代范式：将回归问题视为强化学习（RL）问题。我们通过将模型的预测视为一个动作，并根据预测误差定义自定义奖励信号，从而可以利用强大的RL算法进行函数逼近。通过学习有噪声的正弦波的渐进式案例研究，我们展示了一个Actor-Critic智能体的开发，并通过优先级经验回放、增加网络容量和位置编码对其进行迭代增强，以使RL智能体能够胜任此回归任务。我们的结果表明，RL框架不仅成功解决了回归问题，而且在定义目标和指导学习过程方面提供了增强的灵活性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [672] [Evaluating Angle and Amplitude Encoding Strategies for Variational Quantum Machine Learning: their impact on model's accuracy](https://arxiv.org/abs/2508.00768)
> *评估变分量子机器学习中的角度和幅度编码策略：它们对模型准确性的影响*

*Antonio Tudisco, Andrea Marchesin, Maurizio Zamboni, Mariagrazia Graziano, Giovanna Turvani* | **Category: cs.LG** | **Updated: 2025-08-04**

**Keywords:** 量子机器学习, 变分量子电路, 编码策略, 角度编码, 幅度编码

**Comment:** 

> **TL;DR:** 本研究评估了变分量子机器学习中角度和幅度编码策略及其旋转门类型对模型分类性能的影响，发现编码方式对模型准确性有显著影响，并确认嵌入是VQC模型的超参数。

**AI_Comments:** 这项研究的重要性在于它明确指出了在变分量子电路（VQC）中，数据编码策略和旋转门的选择对模型性能具有显著影响，甚至可以作为模型的超参数进行优化。这为QML模型的设计和优化提供了重要的指导，强调了在构建VQC时需要仔细考虑数据嵌入方式。

<details>
  <summary>Details</summary>

**Motivation:** 随着量子计算和机器学习的进步，量子机器学习（QML）受到了越来越多的关注，其中变分量子电路（VQC）是一种广泛使用的混合模型。本研究旨在分析不同数据编码策略（幅度和角度编码）以及所应用的旋转门类型如何影响VQC模型的分类性能。

**Method:** 通过考虑幅度和角度编码模型，并检查所应用的旋转门类型如何影响模型的分类性能，进行了一项分析。通过在Wine和Diabetes两个数据集上训练不同的模型并评估其性能来进行比较。

**Result:** 在相同的模型拓扑结构下，最佳模型和最差模型之间的准确性差异在10%到30%之间，最高可达41%。结果强调了编码中选择的旋转门如何显著影响模型的分类性能。

**Conclusion:** 研究结果证实，嵌入（embedding）代表了VQC模型的超参数。

> **ai_Abstract:** 本研究评估了变分量子机器学习（QML）中变分量子电路（VQC）的不同数据编码策略（幅度编码和角度编码）及其旋转门类型对模型分类性能的影响。通过在Wine和Diabetes数据集上训练和比较模型，研究发现，在相同模型结构下，编码策略和旋转门的选择对模型准确性有显著影响，准确率差异可达41%。研究结果证实，数据嵌入是VQC模型的一个关键超参数。

> **摘要翻译:** 量子计算和机器学习的最新进展增加了对量子机器学习（QML）的关注，该领域旨在通过利用量子计算范式开发机器学习模型。该领域广泛使用的模型之一是变分量子电路（VQC），这是一种混合模型，其中量子电路处理数据推断，而经典优化调整电路参数。量子电路由一个编码层（将数据加载到电路中）和一个模板电路（称为ansatz，负责处理数据）组成。这项工作涉及通过考虑幅度和角度编码模型进行分析，并检查所应用的旋转门类型如何影响模型的分类性能。这种比较是通过在Wine和Diabetes两个数据集上训练不同的模型并评估其性能来完成的。研究表明，在相同的模型拓扑结构下，最佳模型和最差模型之间的准确性差异在10%到30%之间，最高可达41%。此外，结果突出显示了编码中使用的旋转门的选择如何显著影响模型的分类性能。研究结果证实，嵌入代表了VQC模型的超参数。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [675] [Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management](https://arxiv.org/abs/2508.00806)
> *Adacc：面向LLM内存管理的自适应压缩与激活检查点技术*

*Ping Chen, Zhuohong Deng, Ping Li, Shuibing He, Hongzi Zhu, Yi Zheng, Zhefeng Wang, Baoxing Huai, Minyi Guo* | **Category: cs.LG, cs.DC** | **Updated: 2025-08-01**

**Keywords:** LLM, 内存管理, 自适应压缩, 激活检查点, 深度学习优化

**Comment:** 8 pages

> **TL;DR:** Adacc是一个新的LLM内存管理框架，通过自适应压缩和激活检查点技术，显著减少GPU内存占用，并提高训练速度。

**AI_Comments:** Adacc的创新之处在于其结合自适应压缩和激活检查点，并特别关注了LLM张量中的异常值，这对于保证模型精度至关重要。其引入的自适应策略演进机制也提高了在训练动态变化下的鲁棒性。该工作对于解决LLM训练中的内存瓶颈和提高效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 训练大型语言模型时，重计算会带来高达30%的开销以缓解内存压力，这促使研究人员寻找更高效的内存管理方法。

**Method:** Adacc框架结合了自适应压缩和激活检查点技术，包含三个模块：1) 设计考虑LLM张量异常值的逐层压缩算法，以确保模型精度；2) 提出使用MILP确定每个张量最佳内存优化的最优调度策略；3) 引入自适应策略演进机制，在训练期间调整策略以提高吞吐量。

**Result:** Adacc与现有最先进的框架相比，LLM训练速度提升了1.01倍至1.37倍，同时保持了与基线相当的模型精度。

**Conclusion:** Adacc通过其创新的自适应压缩和激活检查点技术，有效解决了LLM训练中的内存压力问题，显著提高了训练效率，同时保持了模型精度。

> **ai_Abstract:** Adacc是一个针对大型语言模型（LLM）训练内存管理的新框架，旨在通过结合自适应压缩和激活检查点技术来减少GPU内存占用。它通过设计考虑张量异常值的逐层压缩算法、基于MILP的最优调度策略以及自适应策略演进机制来优化内存和提高吞吐量。实验证明，Adacc在保持模型精度的同时，能将LLM训练速度提高1.01倍至1.37倍。

> **摘要翻译:** 训练大型语言模型通常采用重计算来缓解内存压力，这在实际场景中会带来高达30%的开销。本文提出Adacc，一种结合自适应压缩和激活检查点技术的新型内存管理框架，旨在减少GPU内存占用。它包含三个模块：(1) 我们设计了逐层压缩算法，该算法考虑了LLM张量中的异常值，而不是直接将FP16浮点数量化为INT4，以确保模型精度。(2) 我们提出了一种最优调度策略，该策略采用MILP来确定每个张量的最佳内存优化。(3) 为了适应训练张量的变化，我们引入了一种自适应策略演进机制，在训练期间调整策略以提高吞吐量。实验结果表明，与现有最先进的框架相比，Adacc可以将LLM训练加速1.01倍至1.37倍，同时保持与基线相当的模型精度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [682] [Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data](https://arxiv.org/abs/2508.00615)
> *基于相似性自构建图模型用于图神经网络和电子健康记录数据预测患者危重程度*

*Mukesh Kumar Sahu, Pinki Roy* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 患者危重程度预测, 图神经网络, 电子健康记录, 相似性学习, 可解释性AI

**Comment:** 

> **TL;DR:** 提出了一种基于相似性自构建图模型（SBSCGM）和混合图神经网络（HybridGraphMedGNN）架构，利用多模态EHR数据构建患者相似性图，以预测ICU患者的危重程度和死亡风险，并在MIMIC-III数据集上取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了一个结合自构建图和混合GNN的框架，有效利用了EHR数据的关系结构。通过动态构建患者相似性图和集成多种GNN层，模型在准确性和可解释性方面均有显著提升。其在真实世界数据集上的优异表现，特别是AUC-ROC达到0.94，突显了其在临床危重症预测领域的巨大潜力。该框架的可扩展性和可解释性使其在ICU部署中具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测ICU患者的危重程度（如ICU内死亡风险）对于早期干预至关重要。然而，传统模型通常孤立地处理每位患者，难以利用电子健康记录（EHR）中的关系结构。

**Method:** 提出了一种基于相似性自构建图模型（SBSCGM），该模型从多模态EHR数据动态构建患者相似性图。SBSCGM使用混合相似性度量（结合基于特征和结构相似性）实时连接具有相似临床特征的患者。在此图上运行的HybridGraphMedGNN架构集成了图卷积网络（GCN）、GraphSAGE和图注意力网络（GAT）层，以学习鲁棒的患者表示，利用局部和全局图模式。

**Result:** 在MIMIC-III数据集的6000例ICU住院数据上的实验表明，该模型取得了最先进的性能（AUC-ROC 0.94），优于基线分类器和单一类型GNN模型。模型还展示了更高的精确度和召回率，并且注意力机制提供了对模型预测的可解释性洞察。

**Conclusion:** 本框架为危重症风险预测提供了一种可扩展且可解释的解决方案，并有望支持临床医生在真实ICU环境中部署。

> **ai_Abstract:** 该论文提出了一种名为SBSCGM的相似性自构建图模型和HybridGraphMedGNN架构，旨在解决传统模型在预测ICU患者危重程度时无法有效利用EHR数据中关系结构的问题。SBSCGM利用多模态EHR数据动态构建患者相似性图，并采用混合相似性度量。HybridGraphMedGNN结合GCN、GraphSAGE和GAT层学习患者表示。在MIMIC-III数据集上的实验结果显示，该模型在危重症预测方面达到了最先进的性能，并提供了可解释的洞察力，为临床应用提供了可扩展的解决方案。

> **摘要翻译:** 准确预测ICU患者的危重程度（如ICU内死亡风险）对于重症监护的早期干预至关重要。然而，传统模型通常孤立地处理每位患者，难以利用电子健康记录（EHR）中的关系结构。我们提出了一种基于相似性自构建图模型（SBSCGM），该模型从多模态EHR数据动态构建患者相似性图，以及一种在此图上运行的HybridGraphMedGNN架构，用于预测患者死亡率和连续危重程度得分。SBSCGM使用混合相似性度量（结合基于特征和结构相似性）实时连接具有相似临床特征的患者。HybridGraphMedGNN集成了图卷积网络（GCN）、GraphSAGE和图注意力网络（GAT）层，以学习鲁棒的患者表示，利用局部和全局图模式。在MIMIC-III数据集的6000例ICU住院数据上的实验中，我们的模型取得了最先进的性能（AUC-ROC 0.94），优于基线分类器和单一类型GNN模型。我们还展示了改进的精确度/召回率，并表明注意力机制提供了对模型预测的可解释性洞察。我们的框架为危重症风险预测提供了一种可扩展且可解释的解决方案，并有望支持临床医生在真实ICU环境中部署。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [684] [Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors](https://arxiv.org/abs/2508.00785)
> *基于考试的学生评估中的可解释人工智能和机器学习：社会学、学术和经济因素的因果与预测分析*

*Bushra Akter, Md Biplob Hosen, Sabbir Ahmed, Mehrin Anannya, Md. Farhad Hossain* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 可解释人工智能, 机器学习, 学生评估, 因果分析, CGPA预测

**Comment:** 

> **TL;DR:** 本研究利用可解释AI和机器学习，通过因果和预测分析，识别影响学生学业成绩（CGPA）的社会、学术和经济因素，并开发了基于网络的个性化洞察应用。

**AI_Comments:** 本研究的创新之处在于结合了可解释人工智能（XAI）技术与机器学习模型，用于学生学业评估，这不仅提供了高精度的预测和分类，更重要的是增强了模型的可解释性，揭示了影响学生表现的关键因素。此外，开发一个实用的网络应用程序，将研究成果直接应用于个性化学生指导，具有重要的实践价值。这为教育领域利用AI提供了一个有益的范例，有助于学生更好地理解和提升自身学业表现。

<details>
  <summary>Details</summary>

**Motivation:** 学业表现受社会学、学术和经济等多变量因素影响，本研究旨在调查这些影响，以制定优化学生平均绩点（CGPA）的有效策略。

**Method:** 研究通过文献回顾识别关键影响因素，构建了初始假设因果图。对1050名学生进行了在线调查，并进行了严格的数据预处理。采用因果分析验证变量间关系，并使用回归模型（Ridge Regression）进行CGPA预测，分类模型（Random Forest）进行学生表现分类。利用SHAP、LIME和Interpret等可解释AI技术增强模型可解释性。最终开发了一个基于网络的应用程序。

**Result:** Ridge Regression在CGPA预测中表现出强大的预测准确性，平均绝对误差为0.12，均方误差为0.023。Random Forest在分类中表现出色，F1分数接近完美，准确率达98.68%。可解释AI技术突出了学习时间、奖学金、父母教育和先前的学业表现等关键因素。研究成果是一个为学生提供个性化洞察的基于网络的应用程序。

**Conclusion:** 本研究成功地利用可解释AI和机器学习方法，揭示了影响学生学业表现的社会、学术和经济因素，并开发了一个实用的网络应用程序，帮助学生预测学业表现，识别改进领域，并做出明智决策以提高成绩。

> **ai_Abstract:** 本研究旨在通过因果和预测分析，利用可解释人工智能和机器学习技术，深入探究影响学生学业成绩（CGPA）的社会、学术和经济因素。研究通过文献回顾、在线调查和数据预处理，构建了变量间的因果关系。采用Ridge回归模型预测CGPA（MAE 0.12, MSE 0.023），并使用Random Forest模型进行学生表现分类（准确率98.68%）。SHAP、LIME等可解释AI技术揭示了学习时间、奖学金、父母教育和过往学业表现是关键影响因素。最终开发了一个基于网络的应用程序，为学生提供个性化洞察，以优化他们的学业成果。

> **摘要翻译:** 学业表现取决于社会学、学术和经济因素的多变量联系。本研究调查了这些影响，以制定优化学生平均绩点（CGPA）的有效策略。为此，我们回顾了各种文献以识别关键影响因素，并根据研究结果构建了初始假设因果图。此外，还进行了一项在线调查，有1050名学生参与，为分析提供了全面的数据。在分析之前，严格的数据预处理技术，包括数据清洗和可视化，确保了数据质量。因果分析验证了变量之间的关系，为它们对CGPA的直接和间接影响提供了更深入的见解。回归模型用于CGPA预测，而分类模型根据表现水平对学生进行分类。Ridge回归表现出强大的预测准确性，平均绝对误差为0.12，均方误差为0.023。Random Forest在分类中表现出色，F1分数接近完美，准确率达98.68%。SHAP、LIME和Interpret等可解释人工智能技术增强了模型的可解释性，突出了学习时间、奖学金、父母教育和先前的学业表现等关键因素。这项研究最终开发了一个基于网络的应用程序，为学生提供个性化洞察，使他们能够预测学业表现，识别改进领域，并做出明智决策以提高他们的成果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [689] [Evaluating LLMs on Real-World Forecasting Against Human Superforecasters](https://arxiv.org/abs/2507.04562)
> *评估大型语言模型在真实世界预测中与人类超级预测者的表现*

*Janna Lu* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 预测, 超级预测者, 布里尔分数, Metaculus

**Comment:** 

> **TL;DR:** 大型语言模型在预测方面能超越普通人类群体，但仍显著落后于人类超级预测者。

**AI_Comments:** 这篇论文探讨了一个关键且尚未充分研究的领域：LLMs的实际预测能力。其创新之处在于将LLMs直接与人类超级预测者在真实世界问题上进行比较，提供了一个有价值的基准。LLMs仍落后于超级预测者的发现突出了当前的局限性以及未来提高LLM预测能力的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）预测未来事件的能力尚未得到充分研究，且一年前，它们在准确性上难以与人类群体匹敌。

**Method:** 研究评估了最先进的LLMs在Metaculus上的464个预测问题，并将其表现与人类超级预测者进行了比较。

**Result:** 前沿LLMs的布里尔分数表面上超越了普通人类群体，但仍显著低于一群超级预测者。

**Conclusion:** 尽管先进的LLMs在预测方面取得了进步，超越了普通人群，但它们尚未达到人类超级预测者的水平。

> **ai_Abstract:** 本文评估了最先进的大型语言模型（LLMs）在Metaculus上464个真实世界预测问题上的能力，并将其布里尔分数表现与普通人类群体和人类超级预测者进行了比较。研究发现，虽然前沿LLMs似乎超越了普通人类群体，但它们仍显著低于人类超级预测者。

> **摘要翻译:** 大型语言模型（LLMs）在各种任务中展示了卓越的能力，但它们预测未来事件的能力仍未得到充分研究。一年前，大型语言模型难以接近人类群体的准确性。我评估了最先进的LLMs在Metaculus上的464个预测问题上的表现，并将其表现与人类超级预测者进行了比较。前沿模型取得了布里尔分数，表面上超越了人类群体，但仍显著低于一群超级预测者。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [707] [RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems](https://arxiv.org/abs/2508.00201)
> *RecoMind：一个用于优化推荐系统中会话内用户满意度的强化学习框架*

*Mehdi Ben Ayed, Fei Feng, Jay Adams, Vishwakarma Singh, Kritarth Anand, Jiajing Xu* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** 强化学习, 推荐系统, 会话满意度, 大规模, RecoMind

**Comment:** 

> **TL;DR:** RecoMind是一个基于模拟器的强化学习框架，旨在解决现有推荐系统在优化会话内用户满意度方面的挑战，并在大规模在线平台上取得了显著提升。

**AI_Comments:** RecoMind的创新之处在于其将强化学习应用于大规模推荐系统，并解决了传统RL在巨大动作空间和工程复杂性方面的挑战。通过利用现有模型进行模拟和策略引导，并引入自定义探索策略，它为优化长期用户满意度提供了一个实用且可扩展的解决方案，对工业界具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有大规模推荐系统普遍采用监督学习方法，优先考虑即时用户反馈，但难以优化会话内参与度等长期目标。将强化学习应用于大规模系统面临巨大的动作空间和工程复杂性挑战。

**Method:** 本文引入了RecoMind，一个基于模拟器的强化学习框架，用于有效优化大规模会话目标。它利用现有推荐模型构建模拟环境并引导RL策略以优化即时用户交互。该方法与现有工业流程良好集成，并引入了自定义探索策略来高效探索大规模动作空间。

**Result:** 通过广泛的离线模拟和在线A/B测试，RecoMind训练的RL策略在会话内用户满意度方面显著优于传统的监督学习推荐方法。在线A/B测试显示，观看时长超过10秒的视频增加了15.81%，交互次数至少10次的会话深度提高了4.71%。

**Conclusion:** RecoMind提供了一种系统且可扩展的方法，将强化学习嵌入到大规模推荐系统中，在优化会话内用户满意度方面展现出巨大潜力。

> **ai_Abstract:** RecoMind是一个为大规模推荐系统设计的强化学习框架，旨在优化会话内的用户满意度。针对现有监督学习方法无法有效处理长期目标以及强化学习在大规模应用中面临的挑战，RecoMind利用现有推荐模型构建模拟环境并引导RL策略，同时引入自定义探索策略以应对庞大的动作空间。实验结果表明，RecoMind在离线模拟和在线A/B测试中均显著提升了用户会话满意度和关键指标，验证了其在工业级推荐系统中整合强化学习的有效性和可扩展性。

> **摘要翻译:** 现有的大规模网络推荐系统通常使用优先考虑即时用户反馈的监督学习方法。尽管强化学习（RL）为优化长期目标（如会话内参与度）提供了解决方案，但由于极其庞大的动作空间和工程复杂性，将其应用于网络规模具有挑战性。在本文中，我们介绍了RecoMind，一个基于模拟器的强化学习框架，旨在有效优化网络规模的会话目标。RecoMind利用现有推荐模型建立模拟环境并引导RL策略，从一开始就优化即时用户交互。这种方法与现有行业管道良好集成，简化了RL策略的训练和部署。此外，RecoMind引入了一种自定义探索策略，以有效地探索拥有数亿个项目的大规模网络动作空间。我们通过广泛的离线模拟和视频流平台上的在线A/B测试评估了RecoMind。两种方法都表明，使用RecoMind训练的RL策略在会话内用户满意度方面显著优于传统的监督学习推荐方法。在在线A/B测试中，RL策略使观看时长超过10秒的视频增加了15.81%，并使交互次数至少10次的会话深度提高了4.71%。因此，RecoMind提出了一种系统且可扩展的方法，用于将RL嵌入到大规模网络推荐系统中，在优化基于会话的用户满意度方面显示出巨大潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [710] [StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection](https://arxiv.org/abs/2508.00117)
> *StackLiverNet: 一种用于准确和可解释肝病检测的新型堆叠集成模型*

*Md. Ehsanul Haque, S. M. Jahidul Islam, Shakil Mia, Rumana Sharmin, Ashikuzzaman, Md Samir Morshed, Md. Tahmidul Huque* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-04**

**Keywords:** 肝病检测, 堆叠集成, 可解释AI, 机器学习, StackLiverNet

**Comment:** Accepted and presented paper of THE 16th INTERNATIONAL IEEE
  CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT)
  INDIA

> **TL;DR:** StackLiverNet是一种新型的堆叠集成模型，通过先进的预处理和特征选择，实现了对肝病的准确、可解释且高效的检测，解决了现有模型误分类率高、可解释性差和计算成本高的问题。

**AI_Comments:** StackLiverNet的创新之处在于其结合了堆叠集成学习、先进的数据预处理和多样的可解释性技术，全面提升了肝病检测的准确性、效率和透明度。其在高性能的同时兼顾了临床实践中的可解释性和计算效率，这对于医疗诊断领域至关重要。模型不仅提供了高精度的预测，还通过LIME等工具揭示了疾病的关键特征，为医生提供了决策支持。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器学习和深度学习模型在肝病分类方面存在误分类率高、可解释性差、计算成本高以及缺乏良好的预处理策略等问题，需要一种新的方法来解决这些不足。

**Method:** 本研究引入了StackLiverNet，这是一种针对肝病检测任务量身定制的可解释堆叠集成模型。该框架使用先进的数据预处理和特征选择技术来提高模型鲁棒性和预测能力。采用随机欠采样处理类别不平衡问题。StackLiverNet由多个超参数优化的基础分类器集成，通过LightGBM元模型利用它们的互补优势。此外，应用LIME提供个体预测的透明解释，并使用SHAP和Morris方法进行特征重要性排名和敏感性分析。

**Result:** StackLiverNet模型表现出色，测试准确率达到99.89%，Cohen Kappa为0.9974，AUC为0.9993，仅有5次错误分类。模型训练时间为4.2783秒，推理时间为0.1106秒，速度快，适用于临床实践。LIME解释揭示碱性磷酸酶高浓度和SGOT中等水平是肝病的重要观察指标。

**Conclusion:** StackLiverNet提供了一种准确、可解释且计算高效的肝病检测解决方案，其在性能和临床适用性方面均表现优异，并通过可解释性工具提供了有价值的疾病洞察。

> **ai_Abstract:** StackLiverNet是一种新颖的堆叠集成模型，旨在解决现有肝病检测模型中存在的准确性不足、可解释性差和计算效率低等问题。该模型结合了先进的数据预处理、特征选择和随机欠采样技术，以构建一个由多个优化基础分类器和LightGBM元模型组成的集成框架。实验结果显示，StackLiverNet在肝病检测中实现了极高的准确率（99.89%），并具有快速的训练和推理速度，适用于临床应用。同时，通过LIME、SHAP和Morris方法，模型提供了强大的可解释性，揭示了关键的生物标志物，增强了诊断的透明度和可靠性。

> **摘要翻译:** 肝病是全球严重的健康问题，需要精确及时的诊断以提高患者的生存机会。现有文献中实施了大量的机器学习和深度学习模型来分类肝病，但其中大多数都存在一些问题，例如高误分类错误、可解释性差、高昂的计算开销以及缺乏良好的预处理策略。为了解决这些缺点，我们在本研究中引入了StackLiverNet；这是一种为肝病检测任务量身定制的可解释堆叠集成模型。该框架使用先进的数据预处理和特征选择技术来提高模型鲁棒性和预测能力。执行随机欠采样以处理类别不平衡并使训练平衡。StackLiverNet是几个超参数优化的基础分类器的集成，其互补优势通过LightGBM元模型得到利用。所提供的模型表现出卓越的性能，测试准确率为99.89%，Cohen Kappa为0.9974，AUC为0.9993，仅有5次错误分类，并且训练和推理速度高效，适用于临床实践（训练时间4.2783秒，推理时间0.1106秒）。此外，应用局部可解释模型无关解释（LIME）来生成个体预测的透明解释，揭示高浓度的碱性磷酸酶和中等水平的SGOT是肝病的重要观察结果。此外，SHAP用于按其对预测的全局贡献对特征进行排名，而Morris方法通过敏感性分析确认了最具影响力的特征。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [713] [Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback](https://arxiv.org/abs/2507.15066)
> *Time-RA：迈向基于LLM反馈的时间序列异常推理*

*Yiyuan Yang, Zichuan Liu, Lei Song, Kai Ying, Zhiguang Wang, Tom Bamford, Svitlana Vyetrenko, Jiang Bian, Qingsong Wen* | **Category: cs.LG, cs.AI, cs.MM** | **Updated: 2025-08-01**

**Keywords:** 时间序列异常检测, 大型语言模型, 异常推理, 多模态数据集, 可解释性

**Comment:** Under review. 19 pages, 8 figures, 12 tables. Code and dataset are
  publicly available

> **TL;DR:** 该论文提出了Time-RA，一项利用大型语言模型（LLMs）将时间序列异常检测从判别式转变为生成式、推理密集型任务的新型任务。同时，他们还发布了首个真实世界多模态基准数据集RATs40K，用于异常推理，并强调了监督微调的重要性。

**AI_Comments:** 这项工作具有显著的创新性，因为它将时间序列异常检测从传统的判别式任务提升为生成式、推理密集型任务，并引入了LLMs。所构建的RATs40K数据集是第一个专门为异常推理标注的多模态真实世界数据集，其详细的标注（细粒度分类和结构化推理）以及GPT-4辅助的标注框架是其重要贡献。该研究不仅提出了新任务和数据集，还通过基准测试指出了当前模型的局限性及未来研究方向，特别是强调了监督微调的关键作用，对推动可解释时间序列异常检测领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的时间序列异常检测方法通常仅限于二元异常分类，缺乏详细的分类或进一步的解释性推理，这限制了其分析能力。

**Method:** 本文提出了一个名为“时间序列异常推理（Time-RA）”的新任务，将传统的时间序列异常检测从判别式任务转化为生成式、推理密集型任务，并利用大型语言模型（LLMs）。为此，他们构建了首个真实世界多模态基准数据集RATs40K，包含约40,000个样本，涵盖10个真实世界领域。每个样本都包含数值时间序列数据、上下文文本信息和视觉表示，并标注了细粒度类别（14种单变量异常和6种多变量异常）和结构化解释性推理。他们开发了一个复杂的标注框架，该框架利用集成生成的标签，并通过GPT-4驱动的反馈进行优化，以确保准确性和可解释性。

**Result:** 对LLMs和多模态LLMs的广泛基准测试展示了当前模型的能力和局限性，并强调了监督微调的关键作用。

**Conclusion:** 该论文提出的数据集和任务为可解释时间序列异常检测和推理的重大进展铺平了道路，并已全面开源以支持未来的研究。

> **ai_Abstract:** 本研究提出了一项名为Time-RA的新任务，旨在通过利用大型语言模型（LLMs）将时间序列异常检测从传统的二元分类转变为更具推理能力的生成式任务，以提供详细的异常分类和解释。为此，论文构建并发布了首个真实世界多模态基准数据集RATs40K，该数据集包含40,000个样本，涵盖时间序列数据、文本和视觉信息，并带有细粒度的异常类别和结构化解释性标注。通过GPT-4辅助的标注框架确保了数据质量。对LLMs的基准测试揭示了当前模型的潜力与局限性，并强调了监督微调的重要性。该工作旨在推动可解释时间序列异常检测领域的发展，并已开源其代码和数据集。

> **摘要翻译:** 时间序列异常检测在各个领域都至关重要，但当前的方法通常将分析限制在仅仅的二元异常分类，而没有详细的分类或进一步的解释性推理。为了解决这些限制，我们提出了一项新颖的任务——时间序列异常推理（Time-RA），它将经典的时间序列异常检测从判别式任务转变为一种利用大型语言模型（LLMs）的生成式、推理密集型任务。此外，我们还推出了首个真实世界多模态基准数据集RATs40K，该数据集专门为异常推理进行了标注，包含来自10个真实世界领域的约40,000个样本。每个样本都包含数值时间序列数据、上下文文本信息和视觉表示，并分别标注了细粒度类别（单变量异常有14种类型，多变量异常有6种类型）和结构化解释性推理。我们开发了一个复杂的标注框架，该框架利用集成生成的标签，并通过GPT-4驱动的反馈进行优化，以确保准确性和可解释性。对LLMs和多模态LLMs的广泛基准测试展示了当前模型的能力和局限性，突出了监督微调的关键作用。我们的数据集和任务为可解释时间序列异常检测和推理的重大进展铺平了道路。代码（https://github.com/yyysjz1997/Time-RA）和数据集（https://huggingface.co/datasets/Time-RA/RATs40K）已完全开源，以支持和加速该领域的未来研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [372] [Building Bigraphs of the real world](https://arxiv.org/abs/2508.00003)
> *构建真实世界的二分图*

*Kang Rong Roy Ang* | **Category: cs.LO** | **Updated: 2025-07-02**

**Keywords:** 二分图, OpenStreetMap, 数字孪生, 空间划分, 算法改进

**Comment:** Submitted in partial fulfilment of the requirements for Part II of
  the Computer Science Tripos at the University of Cambridge

> **TL;DR:** 该报告提出了一种将OpenStreetMap数据组织成层次空间划分树的正式规范，并将其编码为二分图，作为世界的数字孪生。该研究还提供了一个OCaml工具，并改进了现有工具的算法，实现了显著的性能提升。

**AI_Comments:** 这项研究的创新之处在于提出了一个将OpenStreetMap数据转化为二分图的正式规范，并将其作为真实世界的数字孪生。通过引入高效的算法改进，极大地提升了处理大规模地理数据的能力，这对于城市规划、导航系统和虚拟现实等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 组织世界上所有的建筑物、街道和行政区域，并捕获完整的街道连通性，以创建一个世界的数字孪生。

**Method:** 提出了一个正式规范，将OpenStreetMap数据组织成一个分层的空间划分树，并将其编码为二分图。开发了一个用OCaml实现的工具来构建区域的二分图。对开源二分图构建工具进行了算法改进，以高效地构建和转换极大的二分图。

**Result:** 成功构建了世界的数字孪生二分图，捕获了完整的街道连通性。开发的工具能够构建世界任何区域的二分图。算法改进使得大型二分图的构建和转换效率显著提高，最高加速达到97倍。

**Conclusion:** 通过将OpenStreetMap数据编码为二分图，可以有效地组织和表示真实世界的地理信息，并作为数字孪生，同时通过算法优化显著提升了处理效率。

> **ai_Abstract:** 本报告提出了一种基于OpenStreetMap数据的正式规范，用于构建真实世界的二分图。该规范将地理信息组织成一个分层的空间划分树，并编码为二分图，作为世界的数字孪生，完整捕获街道连通性。研究还开发了一个OCaml工具，并对现有开源二分图构建工具进行了算法改进，使得处理大型二分图的效率显著提升，最高加速达97倍。

> **摘要翻译:** 本报告提出了一种正式规范，用于使用OpenStreetMap数据将世界上所有的建筑物、街道和行政区域组织成一个分层的空间划分树。这种分层结构被编码成一个二分图，作为世界的数字孪生，并捕获完整的街道连通性。报告介绍了一个用OCaml实现的工具（源代码位于https://github.com/royangkr/bigraph-of-the-world），该工具可以为世界任何区域构建二分图。此外，它还对开源二分图构建工具做出了算法改进贡献，使其能够高效地构建和转换极大的二分图，在其他收益中实现了高达97倍的加速。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [404] [Reasoning under uncertainty in the game of Cops and Robbers](https://arxiv.org/abs/2508.00004)
> *警察与小偷博弈中的不确定性推理*

*Dazhu Li, Sujata Ghosh, Fenrong Liu* | **Category: cs.LO, math.LO** | **Updated: 2025-07-09**

**Keywords:** 警察与小偷博弈, 认知逻辑, 不完美信息, 动态算子, 公理化

**Comment:** 

> **TL;DR:** 本文提出了一个名为ELCR的认知逻辑框架，用于在警察与小偷博弈中处理玩家的不完美信息，并实现了玩家交互和信息更新的自动化跟踪。

**AI_Comments:** 本文的创新之处在于首次将形式化方法引入到考虑玩家不完美信息的警察与小偷博弈中。ELCR框架的提出及其对玩家信息更新的自动化跟踪，为理解和分析复杂追逐-规避环境中的推理提供了新的工具。这项工作在认知逻辑和博弈论的交叉领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在警察与小偷博弈中，玩家可能拥有不完美信息，而现有研究缺乏从形式化角度考虑这种（部分）信息的探索。本文旨在弥补这一空白，使博弈的核心概念更精确，并分析玩家之间的信息交互。

**Method:** 本文提出了一个新的形式化框架——警察与小偷博弈的认知逻辑（ELCR），以精确定义博弈中的核心概念，如玩家位置、观察能力和推理。通过应用ELCR，可以自动化跟踪玩家间的交互并刻画游戏中的信息更新。更新机制由一个新的动态算子定义。

**Result:** 通过应用ELCR，实现了自动化跟踪玩家间的交互，并刻画了游戏过程中玩家的信息更新。更新机制由一个新的动态算子定义，并与博弈和逻辑学中的相关范式进行了比较。研究了ELCR的各种性质，包括公理化和可判定性。

**Conclusion:** 本文首次从形式化角度探索了考虑玩家（部分）信息的警察与小偷博弈。ELCR框架能够精确处理博弈中的不完美信息，并自动化跟踪玩家交互和信息更新，同时研究了其公理化和可判定性。

> **ai_Abstract:** 本文针对警察与小偷博弈中玩家信息不完美的问题，提出了一个新颖的形式化框架——警察与小偷博弈的认知逻辑（ELCR）。ELCR旨在精确定义博弈中的核心概念，并自动化跟踪玩家间的交互和信息更新。通过引入新的动态算子，该框架能够有效处理不确定性下的推理，并首次从形式化角度考虑了玩家的（部分）信息，同时研究了其公理化和可判定性。

> **摘要翻译:** 警察与小偷博弈是研究追逐-规避环境中计算查询的重要模型。正如最近的逻辑探索所示，其结构与模态逻辑展现出吸引人的类比。在本文中，我们通过引入玩家可能拥有不完美信息的环境来丰富该博弈。我们提出了一个新的形式化框架，即警察与小偷博弈的认知逻辑（ELCR），以精确化博弈的核心概念，例如玩家的位置、观察能力和推理。应用ELCR来分析博弈，我们获得了一种自动化方式来跟踪玩家之间的交互并刻画他们在博弈过程中的信息更新。更新机制由一个新的动态算子定义，我们将其与博弈和逻辑学中的一些相关范式进行了比较。我们研究了ELCR的各种性质，包括公理化和可判定性。据我们所知，这是首次从形式化角度探索这些博弈，其中考虑了玩家可获得的（部分）信息。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [429] [Deciding the Value of Two-Clock Almost Non-Zeno Weighted Timed Games](https://arxiv.org/abs/2508.00014)
> *决定双时钟几乎非芝诺加权定时博弈的价值*

*Isa Vialard* | **Category: cs.LO** | **Updated: 2025-07-24**

**Keywords:** 加权定时博弈, 价值问题, 可判定性, 双时钟, 非芝诺

**Comment:** 

> **TL;DR:** 对于双时钟几乎非芝诺加权定时博弈，其价值问题是可判定的。

**AI_Comments:** 这项工作填补了加权定时博弈价值问题可判定性研究中的一个重要空白。在双时钟非负wtgs被证明不可判定后，本文通过引入“几乎非芝诺”条件，成功地重新找到了可判定的子类，这对于该领域的理论研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 加权定时博弈的价值问题对于三时钟及以上是不可判定的，对于单时钟是可判定的，而双时钟非负加权定时博弈的价值问题最近被证明是不可判定的。本文旨在探讨在特定条件下（双时钟几乎非芝诺）该问题的可判定性。

**Method:** 本文通过证明在考虑双时钟几乎非芝诺加权定时博弈时，价值问题是可判定的。

**Result:** 结果表明，对于双时钟几乎非芝诺加权定时博弈，价值问题是可判定的。

**Conclusion:** 本文的结论是，当考虑双时钟几乎非芝诺加权定时博弈时，价值问题是可判定的。

> **ai_Abstract:** 本文研究了加权定时博弈（wtgs）的价值问题，该问题旨在确定给定博弈的价值是否超过特定阈值。此前，该问题对于三时钟及以上wtgs是不可判定的，对于单时钟wtgs是可判定的，而对于双时钟非负wtgs最近被证明是不可判定的。本文的核心贡献在于证明了在特定条件下，即对于双时钟几乎非芝诺wtgs，价值问题是可判定的。

> **摘要翻译:** 加权定时博弈（wtgs）的价值问题在于确定，给定一个具有可达性目标和有理阈值的双玩家加权定时博弈，该博弈的价值是否超过阈值。当限制为非负权重的加权定时博弈时，该问题对于具有三个或更多时钟的加权定时博弈是不可判定的，对于单时钟加权定时博弈是可判定的。困扰了十年之久的双时钟非负加权定时博弈的价值问题，最近被证明是不可判定的。在本文中，我们表明当考虑双时钟几乎非芝诺加权定时博弈时，价值问题是可判定的。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [454] [Extended Abstract: Partial-encapsulate and Its Support for Floating-point Operations in ACL2](https://arxiv.org/abs/2508.00015)
> *扩展摘要：部分封装及其对ACL2中浮点运算的支持*

*Matt Kaufmann, J Strother Moore* | **Category: cs.LO, cs.MS** | **Updated: 2025-07-25**

**Keywords:** partial-encapsulate, ACL2, 浮点运算

**Comment:** In Proceedings ACL2 2025, arXiv:2507.18567

> **TL;DR:** 本文展示了partial-encapsulate在ACL2浮点运算实现中的应用。

**AI_Comments:** 这篇扩展摘要旨在展示partial-encapsulate在ACL2中特定应用场景（浮点运算）中的实用性。鉴于摘要的简洁性，无法评估其创新性或更广泛的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是阐述并展示partial-encapsulate的强大功能。

**Method:** 通过展示partial-encapsulate在ACL2中浮点运算实现中的具体应用来阐述其功能。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 这篇扩展摘要阐述了partial-encapsulate的功能，并通过其在ACL2中实现浮点运算的具体应用来展示其能力。

> **摘要翻译:** 我们阐述了部分封装（partial-encapsulate）的强大功能，展示了它在ACL2中浮点运算实现中的应用。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [478] [Alignment Monitoring](https://arxiv.org/abs/2508.00021)
> *对齐监控*

*Thomas A. Henzinger, Konstantin Kueffner, Vasu Singh, I Sun* | **Category: cs.LO** | **Updated: 2025-07-28**

**Keywords:** 对齐监控, 形式验证, 概率系统, 模型验证, 顺序预测

**Comment:** 

> **TL;DR:** 本文提出了一种对齐监控方法，用于在运行时检查概率系统模型是否与现实对齐，通过预测系统行为并量化模型预测与实际分布之间的相似性，从而确保形式验证的假设成立。

**AI_Comments:** 本文提出了一种新颖且实用的方法来解决形式验证中的一个关键假设问题，即模型与现实的对齐性。其创新点在于将顺序预测技术应用于对齐监控，并提供了多种监控器类型以适应不同需求。该研究对于提高概率系统形式验证的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 形式验证依赖于系统模型与现实对齐的假设，但这种假设需要被证明。本文旨在解决如何监控和验证这一假设的问题。

**Method:** 本文提出了对齐监控方法，通过量化模型预测分布与系统实际分布之间的相似性来测量对齐分数。监控器在运行时观察系统，利用当前状态和模型预测下一状态，并在观察到下一状态后更新对齐分数的区间估计。该方法利用了顺序预测工具，并引入了测量期望对齐分数的监控器、比较两个模型的差分对齐监控器以及允许任务特定监控的加权对齐监控器。

**Result:** 实验评估表明，所提出的对齐监控器快速、内存高效，并且能够及早检测到未对齐。

**Conclusion:** 本文提出的对齐监控方法能够有效且高效地验证概率系统模型与现实的对齐性，从而增强了形式验证的可靠性。

> **ai_Abstract:** 本文提出了一种对齐监控方法，旨在验证概率系统模型与现实世界行为的对齐性。该方法通过在运行时量化模型预测与系统实际分布之间的相似性来计算对齐分数，并利用顺序预测工具构建了多种类型的监控器，包括用于比较模型的差分监控器和支持任务特定监控的加权监控器。实验结果表明，这些监控器具有高效性、低内存消耗和早期检测未对齐的能力。

> **摘要翻译:** 形式验证保证概率系统满足其规范——前提是系统模型与现实对齐。我们提出对齐监控来观察这一假设是否合理。如果概率模型能够准确地提前预测不确定系统的行为，我们认为它是良好对齐的。对齐分数通过量化模型预测分布与系统（未知）实际分布之间的相似性来衡量这一点。对齐监控器在运行时观察系统；在每个时间点，它使用当前状态和模型来预测下一状态。在观察到下一状态后，监控器更新判决，这是一个真实对齐分数的高概率区间估计。我们利用顺序预测工具来构建我们的对齐监控器。除了测量期望对齐分数的监控器外，我们还引入了差分对齐监控器（用于比较两个模型）和加权对齐监控器（允许任务特定的对齐监控）。我们在PRISM基准套件上对我们的监控器进行了实验评估。它们快速、内存高效，并且能及早检测到未对齐。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [505] [Loop Invariant Generation: A Hybrid Framework of Reasoning optimised LLMs and SMT Solvers](https://arxiv.org/abs/2508.00419)
> *循环不变量生成：推理优化LLM与SMT求解器的混合框架*

*Varun Bharti, Shashwat Jha, Dhruv Kumar, Pankaj Jalote* | **Category: cs.LO, cs.LG, cs.PL** | **Updated: 2025-08-01**

**Keywords:** 循环不变量, 大型语言模型, SMT求解器, 程序验证, 混合框架

**Comment:** Under Review

> **TL;DR:** 本文提出了一种结合推理优化大型语言模型（LLMs）和SMT求解器的混合框架，用于自动生成循环不变量，并在Code2Inv基准测试中达到了100%的覆盖率，显著优于现有方法。

**AI_Comments:** 该论文的创新之处在于其将大型语言模型的生成能力与SMT求解器的验证和反例引导能力相结合，形成了一个高效的混合框架。这不仅在循环不变量合成这一挑战性任务上取得了突破性的100%覆盖率，也揭示了LLMs在复杂逻辑推理领域的潜在应用价值。其高效性（低模型提议次数和快速运行时间）也值得关注，预示着未来在程序分析和验证领域，LLMs可能扮演更重要的角色。该方法具有良好的通用性，有望推广到其他命令式语言的程序分析。

<details>
  <summary>Details</summary>

**Motivation:** 循环不变量对于证明带有循环的程序正确性至关重要，但开发循环不变量具有挑战性，且现有的全自动合成方法无法保证适用于任意程序，特别是基于符号技术和神经网络的方法在标准基准测试中只能正确合成部分子集。

**Method:** 本研究将OpenAI的O1、O1-mini和O3-mini等推理优化大型语言模型与Z3 SMT求解器集成到一个紧密耦合的“生成-检查”管道中，利用求解器反例迭代地指导不变量的细化。该方法在Code2Inv基准测试（包含C程序及其前置条件和后置条件）上进行评估。

**Result:** 在Code2Inv基准测试的133个任务中，该框架实现了100%的覆盖率（133/133），优于此前最佳的107/133。此外，每个实例仅需1-2次模型提议，且耗时14-55秒。这些结果表明LLM具有潜在的逻辑推理能力，有助于自动化循环不变量合成。

**Conclusion:** LLM具备的潜在逻辑推理能力可以有效帮助自动化循环不变量的合成，并且该混合框架在循环不变量生成方面表现出卓越的性能和效率，尽管目前针对C语言程序，但该方法有望推广到其他命令式语言。

> **ai_Abstract:** 本论文提出了一种混合框架，结合了推理优化的大型语言模型（LLMs）和SMT求解器，旨在解决程序循环不变量自动合成的难题。该框架通过一个生成-检查管道，利用LLMs生成不变量，并由SMT求解器进行验证和提供反例以迭代优化。在Code2Inv基准测试中，该方法实现了100%的覆盖率，显著优于现有技术，并展现了LLMs在逻辑推理方面的潜力，为程序正确性验证提供了高效的自动化工具。

> **摘要翻译:** 循环不变量对于证明带有循环的程序正确性至关重要。开发循环不变量具有挑战性，并且对于任意程序无法保证完全自动合成。一些方法被提出用于使用符号技术，以及最近使用神经网络方法来合成循环不变量。这些方法只能正确合成为标准基准测试的子集。在这项工作中，我们研究了现代的、推理优化的大型语言模型是否能做得更好。我们将OpenAI的O1、O1-mini和O3-mini集成到一个与Z3 SMT求解器紧密耦合的生成-检查管道中，使用求解器反例迭代地指导不变量细化。我们使用Code2Inv基准测试，它提供了C程序及其形式化的前置条件和后置条件。在这个包含133个任务的基准测试中，我们的框架实现了100%的覆盖率（133/133），超越了之前最佳的107/133，同时每个实例仅需1-2次模型提议和14-55秒的实际运行时间。这些结果表明LLM具备潜在的逻辑推理能力，可以帮助自动化循环不变量合成。虽然我们的实验针对C语言特定程序，但这种方法应该可以推广到其他命令式语言。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [544] [Parameterized Infinite-State Reactive Synthesis](https://arxiv.org/abs/2508.00613)
> *参数化无限状态反应式综合*

*Benedikt Maderbacher, Roderick Bloem* | **Category: cs.LO** | **Updated: 2025-08-01**

**Keywords:** 参数化系统, 反应式综合, 无限状态, 反例引导, 语法引导合成

**Comment:** 

> **TL;DR:** 提出了一种合成参数化无限状态系统的方法，该方法通过一个反例引导循环，结合反统一和语法引导合成来生成和验证参数化程序。

**AI_Comments:** 这项工作具有创新性，因为它解决了无限状态系统参数化合成的挑战，这对于构建可适应不同环境的系统至关重要。其反例引导循环方法提供了一个迭代改进和验证的框架，而反统一和语法引导合成的结合则有效地处理了参数化程序的泛化问题。这为反应式系统设计和验证提供了一个强大的新工具。

<details>
  <summary>Details</summary>

**Motivation:** 需要合成能够针对不同参数值实例化的参数化无限状态系统，以应对环境属性的变化。

**Method:** 该方法采用反例引导循环，包含四个主要步骤：1. 使用现有技术为小参数实例合成具体系统。2. 将具体系统泛化为参数化程序。3. 创建包含不变量和排序函数的证明候选。4. 检查证明候选与程序的一致性。如果证明失败，则识别失败的参数值并添加新的具体实例到第一步。泛化程序和创建证明候选时，结合使用反统一和语法引导合成。

**Result:** 该方法在文献中扩展了参数的例子以及新问题上进行了评估。

**Conclusion:** 如果证明成功，则参数化程序是有效的。

> **ai_Abstract:** 本文提出了一种用于合成参数化无限状态系统的新方法。该系统能够根据不同的参数值进行实例化，并使用参数化时态逻辑进行规范。核心合成过程是一个反例引导循环，涉及对具体系统进行合成、泛化为参数化程序、创建并验证证明候选。通过结合反统一和语法引导合成技术，该方法能够处理程序之间的语法差异。研究人员在现有和新问题上对该方法进行了评估。

> **摘要翻译:** 我们提出了一种合成参数化无限状态系统的方法，该系统可以针对不同的参数值进行实例化。规范以参数化时态逻辑给出，该逻辑允许数据变量以及编码环境属性的参数变量。我们的合成方法在一个反例引导循环中运行，该循环包含四个主要步骤：首先，我们使用现有技术为一些小的参数实例化合成具体系统。其次，我们将具体系统泛化为参数化程序。第三，我们创建一个由不变量和排序函数组成的证明候选。第四，我们检查证明候选与程序的一致性。如果证明成功，则参数化程序是有效的。否则，我们识别一个证明失败的参数值，并向第一步添加一个新的具体实例。为了泛化程序和创建证明候选，我们结合使用反统一和语法引导合成，将程序之间的语法差异表达为参数的函数。我们在文献中已扩展参数的例子以及新问题上评估了我们的方法。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [574] [Putting Perspective into OWL [sic]: Complexity-Neutral Standpoint Reasoning for Ontology Languages via Monodic S5 over Counting Two-Variable First-Order Logic (Extended Version with Appendix)](https://arxiv.org/abs/2508.00653)
> *将视角引入OWL：通过单调S5在计数二变量一阶逻辑上实现本体语言的复杂性中立立场推理*

*Lucía Gómez Álvarez, Sebastian Rudolph* | **Category: cs.LO** | **Updated: 2025-08-01**

**Keywords:** 本体语言, 多视角推理, 模态逻辑, 复杂性, OWL

**Comment:** 

> **TL;DR:** 该研究提出了一种通过单调立场扩展OWL等本体语言的方法，可在不增加推理复杂性的前提下实现多视角建模和推理。

**AI_Comments:** 该论文的创新之处在于提出了一种复杂性中立的方法，为本体语言引入多视角推理能力，这对于处理复杂知识和多源信息具有重要的实际意义。其通过巧妙的模型理论论证，将模态逻辑与描述逻辑相结合，不仅为本体论工程提供了新的工具，也深化了一阶模态逻辑的研究。这项工作对于OWL用户而言，意味着可以在不牺牲推理性能的前提下，显著增强其建模表达能力。

<details>
  <summary>Details</summary>

**Motivation:** 为了在知识表示形式中整合多视角建模和推理，并解决现有方法可能引入的推理复杂性问题，论文引入了单调立场扩展。这种扩展提供了一种平衡的方法，既支持高级建模特性（如表达刚性概念），又能保持理想的推理复杂性。

**Method:** 研究考虑了计数二变量一阶逻辑（C2）的单调立场扩展。其核心是将这种扩展形式的公式多项式时间翻译回标准的、无立场的C2，该翻译依赖于复杂的模型理论论证。

**Result:** 可满足性问题保持在与纯C2相同的NExpTime-complete复杂度级别。该形式主义涵盖了C2上的单调S5，标志着一阶模态逻辑研究的重大进展。像SHOIQBs和SROIQBs等支撑OWL 1和OWL 2的描述逻辑，可以在不增加标准推理复杂性的情况下扩展单调立场。此外，即使在表达能力较低的描述逻辑中，只要包含标称词和单调立场，也会出现NExpTime-hard性。如果存在逆向角色、功能性和标称词，且单调性限制稍有放松，可满足性问题将变得不可判定。

**Conclusion:** 通过引入单调立场扩展，本体语言（如OWL）可以在不增加推理复杂性的前提下实现多视角建模和推理。同时，研究也揭示了在特定条件下放松单调性限制可能导致推理问题变得不可判定。

> **ai_Abstract:** 该论文提出了一种为OWL等本体语言引入单调立场扩展的方法，旨在实现多视角建模和推理，同时保持推理复杂性不变。通过将扩展后的计数二变量一阶逻辑（C2）公式多项式时间翻译回标准C2，研究证明了可满足性问题仍保持NExpTime-complete，这意味着基于OWL的描述逻辑（如SHOIQBs和SROIQBs）可以在不增加现有推理复杂性的前提下增强多视角功能。论文还探讨了不同约束下复杂性的变化，指出即使在较低表达力的逻辑中，包含标称词和单调立场也会导致NExpTime-hard性，而放松单调性限制则可能导致不可判定性。

> **摘要翻译:** 知识表示形式的立场扩展最近被引入，作为一种通过模态运算符将知识片段归因于特定实体或代理的手段，以整合多视角建模和推理。在这些扩展中，概念建模和视角注释之间的集成强度可能有所不同，其中单调立场扩展提供了一种平衡的方法。它们允许高级建模特性，例如刚性概念的表达，同时保持理想的推理复杂性。
我们考虑了计数二变量一阶逻辑（C2）的单调立场扩展。我们工作的核心是将这种扩展形式中的公式多项式时间翻译成标准的、无立场的C2，这一结果依赖于复杂的模型理论论证。由于这种翻译，可满足性问题保持在相同的复杂度级别：NExpTime-complete，就像在纯C2中一样。由于我们的形式主义涵盖了C2上的单调S5，这一结果也标志着一阶模态逻辑研究的重大进展。
从实践角度来看，这意味着像SHOIQBs和SROIQBs这种高表达力的描述逻辑——它们是W3C标准化的广泛采用的OWL 1和OWL 2本体语言的基础——可以扩展单调立场而不会增加标准推理复杂性。
我们进一步证明，即使在表达能力显著较低的描述逻辑中，只要包含标称词和单调立场，就会出现NExpTime-hard性。此外，我们表明，如果在存在逆向角色、功能性和标称词的情况下，单调性限制稍有放松，可满足性问题将变得不可判定。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [612] [Analysing Temporal Reasoning in Description Logics Using Formal Grammars](https://arxiv.org/abs/2508.00575)
> *使用形式文法分析描述逻辑中的时间推理*

*Camille Bourgaux, Anton Gnatenko, Michaël Thomazo* | **Category: cs.LO, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 时间推理, 描述逻辑, 形式文法, 合取文法, 不可判定性

**Comment:** This is an extended version of a paper appearing at the 28th European
  Conference on Artificial Intelligence (ECAI 2025). 20 pages

> **TL;DR:** 本文建立了时间描述逻辑 $\mathcal{TEL}^\bigcirc$ 与形式文法（特别是合取文法）之间的对应关系，证明了 $\mathcal{TEL}^\bigcirc$ 的查询回答是不可判定的，并为某些片段建立了可判定性。

**AI_Comments:** 这项研究通过建立描述逻辑与形式文法之间的新颖联系，成功解决了 $\mathcal{TEL}^\bigcirc$ 领域的一个长期开放问题，具有重要的理论意义。这种方法不仅揭示了该逻辑的固有局限性（不可判定性），还为探索其可判定片段提供了有效途径，并促进了跨领域工具的重用。

<details>
  <summary>Details</summary>

**Motivation:** 解决自 $\mathcal{TEL}^\bigcirc$ 引入以来一直悬而未决的查询回答问题。

**Method:** 通过建立时间描述逻辑 $\mathcal{TEL}^\bigcirc$ 的片段与特定形式文法（特别是合取文法）之间的对应关系。

**Result:** 该联系表明 $\mathcal{TEL}^\bigcirc$ 不具备模型的最终周期性，并导致 $\mathcal{TEL}^\bigcirc$ 中查询回答的不可判定性。此外，它还能够为 $\mathcal{TEL}^\bigcirc$ 的一些新的有趣片段建立查询回答的可判定性，并为此目的重用现有的合取文法工具和算法。

**Conclusion:** 时间描述逻辑 $\mathcal{TEL}^\bigcirc$ 的查询回答是不可判定的，但其某些片段的查询回答是可判定的，这得益于与形式文法的对应关系，该关系也促进了现有工具的重用。

> **ai_Abstract:** 本文通过建立时间描述逻辑 $\mathcal{TEL}^\bigcirc$ 与合取文法之间的对应关系，解决了 $\mathcal{TEL}^\bigcirc$ 中查询回答的判决问题。研究表明，完整的 $\mathcal{TEL}^\bigcirc$ 的查询回答是不可判定的，但该方法也为 $\mathcal{TEL}^\bigcirc$ 的某些片段建立了可判定性，并可利用现有的合取文法工具。

> **摘要翻译:** 我们建立了 $\mathcal{TEL}^\bigcirc$（$\\mathcal{EL}$ 描述逻辑的一个时间扩展，带有时态运算符 $\bigcirc^k$）的片段与某些特定形式文法之间的对应关系，特别是合取文法（配备了交集操作的上下文无关文法）。这种联系意味着 $\mathcal{TEL}^\bigcirc$ 不具备模型的最终周期性属性，并进一步导致 $\mathcal{TEL}^\bigcirc$ 中查询回答的不可判定性，从而解决了自 $\mathcal{TEL}^\bigcirc$ 引入以来一直悬而未决的问题。此外，它还允许为 $\mathcal{TEL}^\bigcirc$ 的一些新的有趣片段建立查询回答的可判定性，并为此目的重用现有的合取文法工具和算法。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [628] [Ordinal Folding Index: A Computable Metric for Self-Referential Semantics](https://arxiv.org/abs/2508.00151)
> *序数折叠指数：一种可计算的自指语义度量*

*Faruk Alpay, Hamdi Al Alakkad* | **Category: cs.LO, cs.GT, 03B70, 91A44, 91A05, 68Q10, F.1.1; F.4.1; F.3.1; I.2.3** | **Updated: 2025-07-31**

**Keywords:** 序数折叠指数, 自指语义, 可计算度量, 博弈论, 形式逻辑

**Comment:** 13 pages, 2 figures. Introduces the Ordinal Folding Index, a
  computable ordinal depth metric for self referential statements that unifies
  fixed point logic with infinite game theory

> **TL;DR:** 序数折叠指数（OFI）是一种新的可计算度量，用于量化自指语句稳定所需的展开轮数，统一了不动点逻辑、无限对策和形式理论等领域。

**AI_Comments:** 这篇论文通过引入OFI，提供了一个跨越多个理论计算机科学和逻辑学领域的统一视角，其创新性在于将“自指深度”这一抽象概念量化为可计算的序数，从而打通了不动点逻辑、博弈论和序数分析之间的壁垒。其重要性在于为理解和分析复杂自指系统提供了一个强大的新工具，并为未来的交叉学科研究开辟了广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 传统上，不动点逻辑的闭包阶段、无限对策的获胜时间以及形式理论的强度校准等研究领域是相互孤立的。本文的动机是引入一个统一的可计算度量（OFI），将抽象的“折回”深度转化为一个单一的序数，从而在这些领域之间建立直接联系。

**Method:** 序数折叠指数（OFI）是一种新的、完全可计算的度量标准，它通过将抽象的“折回”深度转化为一个单一的序数，来衡量一个陈述、协议或立场在真相或结果稳定之前必须展开多少轮自指。

**Result:** 研究证明，OFI在保持算法可枚举性的同时，改进了所有经典的博弈论和逻辑度量。此外，论文为有限竞技场提供了多项式时间近似方案，并表明该指数与相关评估博弈中最短获胜策略的长度完全一致。

**Conclusion:** 序数折叠指数（OFI）提供了一个统一且直观的视角，连接了计算机辅助逻辑、算法博弈论和序数分析等领域，为博弈论家和逻辑学家理解无限博弈、超限归纳和反思推理提供了共同基础，并提出了未来的研究方向。

> **ai_Abstract:** 本文介绍了序数折叠指数（OFI），这是一种新颖的可计算度量，用于量化自指结构（如语句、协议）稳定所需的展开轮数。OFI通过将抽象的“折回”深度量化为序数，成功地将传统上孤立的研究领域（如不动点逻辑、无限对策和形式理论）联系起来。研究证明OFI优于现有度量，并提供了计算优化方法，同时揭示了其与博弈论中获胜策略长度的精确对应关系。OFI不仅为相关领域提供了统一的分析工具，还指明了未来的研究方向。

> **摘要翻译:** 序数折叠指数（OFI）是一种新的、完全可计算的度量标准，它衡量一个陈述、协议或立场在真相或结果稳定之前必须展开多少轮自指。通过将这种抽象的“折回”深度转化为一个单一的序数，OFI在通常独立研究的领域之间建立了直接联系：不动点逻辑的闭包阶段、无限奇偶博弈的获胜时间以及校准形式理论强度的序数进展。我们证明OFI在保持算法可枚举性的同时，改进了所有经典的博弈论和逻辑度量，为有限竞技场提供了多项式时间近似方案，并表明该指数与相关评估博弈中最短获胜策略的长度完全一致。除了理论之外，我们还概述了五个开放问题，从可计算序数谱的完备性到“压缩”深度自指的可能性，这些问题描绘了计算机辅助逻辑、算法博弈论和序数分析交叉领域的研究计划。因此，OFI邀请博弈论家和逻辑学家通过一个单一、直观的视角来看待无限博弈、超限归纳和反思推理，为技术开辟了共同的基础。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [665] [Automating Boundary Filling in Cubical Type Theories](https://arxiv.org/abs/2402.12169)
> *立方体类型理论中边界填充的自动化*

*Maximilian Doré, Evan Cavallo, Anders Mörtberg* | **Category: cs.LO** | **Updated: 2025-08-01**

**Keywords:** 立方体类型理论, 边界填充, 自动化, 扭曲求解, Kan求解

**Comment:** 

> **TL;DR:** 本文通过开发扭曲和Kan问题求解器，实现了立方体类型理论中边界填充的自动化。

**AI_Comments:** 本文解决了立方体类型理论中一个关键的计算难题，这对于同伦类型理论的实际应用至关重要。其创新点在于针对不可判定问题采用启发式方法，并开发了实用的自动化求解器。为不同的子问题（扭曲求解和Kan求解）分别采用偏序集映射和约束满足编程等不同技术是其亮点。

<details>
  <summary>Details</summary>

**Motivation:** 在立方体类型理论中，处理高阶结构的复杂组合学（方程推理的无限维泛化）是一个难点。解决这些高维方程需要构造具有指定边界的立方体。

**Method:** 开发了一种简化的立方体语言，研究了扭曲求解和Kan求解两个自动化问题。针对扭曲问题，利用偏序集映射重新表述扭曲，为Dedekind和De Morgan扭曲理论提供了求解器。针对Kan问题，使用约束满足编程解决。将算法实现为一个实验性的Haskell求解器。

**Result:** 为Dedekind和De Morgan扭曲理论提供了扭曲问题求解器。使用约束满足编程解决了Kan问题，该方法独立于底层扭曲理论。将算法实现为一个实验性的Haskell求解器，能够自动解决立方体类型理论用户面临的许多目标。通过一个使用该求解器建立Eckmann-Hilton定理的案例研究以及各种基准测试进行了说明。

**Conclusion:** 本文通过开发针对扭曲和Kan问题的自动化求解器，有效解决了立方体类型理论中处理高阶结构和边界填充的复杂性，提高了该理论的实用性。

> **ai_Abstract:** 本文通过开发一种简化的语言和自动化求解器，解决了立方体类型理论中边界填充的挑战。论文重点研究了扭曲求解和Kan求解这两个关键问题，并引入了启发式方法。扭曲问题通过偏序集映射解决，Kan问题则利用约束满足编程。所实现的Haskell求解器被证明能有效自动解决常见目标，并通过Eckmann-Hilton定理的案例研究进行了验证。

> **摘要翻译:** 在证明助手工作中，自动化是解决常规证明目标（例如代数表达式之间的等式）的关键。同伦类型理论允许用户使用高阶归纳类型（HITs）和Univalence推理高阶结构，例如拓扑空间。立方体类型理论为HITs和Univalence提供了计算支持。在立方体类型理论中工作的一个难点是处理高阶结构的复杂组合学，这是方程推理的无限维泛化。解决这些高维方程需要构造具有指定边界的立方体。 我们开发了一种简化的立方体语言，在该语言中我们分离并研究了两个自动化问题：扭曲求解（contortion solving），即尝试“扭曲”一个立方体以适应给定的边界；以及更通用的Kan求解（Kan solving），即寻找涉及将多个立方体粘贴在一起的解决方案。这两个问题在一般情况下都很困难——Kan求解甚至是不可判定的——因此我们专注于在实际示例中表现良好的启发式方法。我们的语言包含了不同变体的立方体类型理论，它们在“扭曲理论”（即它们支持的扭曲类别）上有所不同。通过将扭曲重新表述为偏序集映射，我们为目前正在研究的最复杂的扭曲理论——Dedekind和De Morgan扭曲——提供了扭曲问题的求解器。我们使用约束满足编程来解决Kan问题，该方法独立于底层扭曲理论。我们已将算法实现为一个实验性的Haskell求解器，该求解器可用于自动解决立方体类型理论用户可能面临的许多目标。我们通过一个使用我们的求解器建立Eckmann-Hilton定理的案例研究以及各种基准测试来说明这一点。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [701] [Cobblestone: Iterative Automation for Formal Verification](https://arxiv.org/abs/2410.19940)
> *Cobblestone：形式化验证的迭代自动化*

*Saketh Ram Kasibatla, Arpan Agarwal, Yuriy Brun, Sorin Lerner, Talia Ringer, Emily First* | **Category: cs.LO, cs.AI, cs.PL** | **Updated: 2025-07-31**

**Keywords:** 形式化验证, 证明合成, 大型语言模型, 自动化, Coq

**Comment:** 14 pages, 14 figures

> **TL;DR:** Cobblestone是一种新的分而治之的证明合成方法，它使用大型语言模型（LLM）迭代地生成和完善证明，即使依赖于不健全的LLM，也能构建出健全的证明。它在自动化形式化验证方面优于现有工具。

**AI_Comments:** Cobblestone的创新之处在于它巧妙地结合了大型语言模型生成能力与迭代细化机制，解决了LLM在形式化验证中“不健全”的固有问题。通过分而治之和迭代验证，它能够在保证正确性的前提下，显著提高自动化证明的覆盖率和效率。其低成本和利用外部输入的灵活性也增加了其实用性，为未来形式化验证的自动化提供了重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 形式化验证（如使用Coq）能有效提高软件质量，但需要大量精力和专业知识。机器学习虽然可以自动合成证明，但目前的工具只能证明一小部分所需属性，效率和覆盖面有限。

**Method:** Cobblestone采用分而治之的方法进行证明合成。它使用大型语言模型（LLM）生成潜在证明，然后利用这些证明将问题分解为更简单的部分。系统自动识别哪些部分已成功证明，并对剩余部分进行迭代，以构建一个健全的正确证明，尽管其依赖于不健全的LLM。它还支持用户或外部工具提供证明结构或相关引理的输入。

**Result:** Cobblestone在四个开源Coq项目基准测试中进行了评估，并控制了训练数据泄露。在完全自动化的情况下，Cobblestone优于最先进的非LLM工具，并能证明许多其他基于LLM的工具无法证明的定理，在许多基准测试中也优于它们。每次运行平均成本仅为1.25美元，耗时14.7分钟。在外部输入（如预言机）辅助下，Cobblestone证明的定理数量可达58%。

**Conclusion:** 本研究表明，工具可以利用部分进展和外部输入更有效地自动化形式化验证。

> **ai_Abstract:** Cobblestone是一种用于形式化验证中证明合成的迭代自动化方法。它通过结合大型语言模型（LLM）和分而治之策略，将复杂的证明任务分解为更小的部分，并迭代地完善证明。即使LLM本身不健全，Cobblestone也能保证最终证明的正确性。实验结果表明，该工具在自动化证明能力上超越了现有非LLM及部分LLM驱动的工具，且成本效益高，并能有效利用外部辅助信息。

> **摘要翻译:** 形式化验证使用Coq等证明助手是提高软件质量的有效方法，但需要大量的精力和专业知识。机器学习可以自动合成证明，但此类工具只能证明所需软件属性的一小部分。我们引入了Cobblestone，一种用于证明合成的分而治之方法。Cobblestone使用大型语言模型（LLM）生成潜在证明，利用这些证明将问题分解为更简单的部分，自动识别哪些部分已成功证明，并对剩余部分进行迭代以构建一个正确的证明，尽管依赖于不健全的LLM，但该证明保证是健全的。我们在四个开源Coq项目基准测试中评估了Cobblestone，并控制了训练数据泄露。在完全自动化的情况下，Cobblestone优于最先进的非LLM工具，并证明了许多其他基于LLM的工具无法证明的定理，在许多基准测试中也优于它们。每次Cobblestone运行平均仅花费1.25美元，耗时14.7分钟。Cobblestone还可以与来自用户或另一个工具的外部输入一起使用，提供证明结构或相关引理。在有此类预言机评估的情况下，Cobblestone证明的定理数量可达58%。总的来说，我们的研究表明，工具可以利用部分进展和外部输入更有效地自动化形式化验证。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [704] [Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation](https://arxiv.org/abs/2508.00017)
> *生成逻辑：一种用于确定性推理和知识生成的新型计算机架构*

*Nikolai Sergeev* | **Category: cs.LO, cs.AI, cs.AR** | **Updated: 2025-07-25**

**Keywords:** 生成逻辑, 确定性推理, 知识生成, 皮亚诺算术, 证明图

**Comment:** 19 pages, 5 figures. Code and interactive HTML proof graphs
  permanently archived on Zenodo (DOI: 10.5281/zenodo.16408441)

> **TL;DR:** 本文介绍了一种名为“生成逻辑”（GL）的确定性架构，它从用户提供的公理定义出发，系统地探索其演绎邻域，并能自动重建可机器检查的基础算术定律证明。

**AI_Comments:** 该论文提出了一种新颖的确定性计算架构“生成逻辑”，其创新点在于从公理出发系统地探索演绎邻域，并生成具有完整溯源的可审计证明图。这种方法在形式验证、知识表示和自动化推理领域具有重要意义。通过将概念编译为分布式逻辑块并支持硬件-软件协同设计，它为大规模并行化和与概率模型的潜在集成提供了清晰的路径，这对于未来的AI系统中的可解释性和可靠性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在确定性推理和知识生成方面可能存在不足，需要一种新的架构来系统地探索演绎邻域，生成可审计的证明图，并实现大规模并行化。

**Method:** 生成逻辑（GL）是一种确定性架构，它将用极简数学编程语言（MPL）编写的用户提供的公理定义编译成简单的逻辑块（LBs）分布式网格。这些逻辑块通过交换消息，在表达式根据推理规则统一时发出带有完整来源的新事实，从而产生可重放、可审计的证明图。原型软件实现在一阶皮亚诺算术上实例化了该工作流，从皮亚诺公理开始，枚举候选蕴涵，应用归一化和类型过滤器，并自动重建算术定律的机器可检查证明。

**Result:** GL原型成功地从皮亚诺公理重建了加法的结合律和交换律、乘法的结合律和交换律以及分配律等基础算术定律的机器可检查证明。生成的证明可以导出为可导航的HTML，以便独立检查每个推理步骤。

**Conclusion:** 生成逻辑（GL）提供了一种确定性架构，能够从公理定义系统地生成可审计的知识和证明。未来工作包括硬件-软件协同设计以实现大规模并行化，并与概率模型（如LLMs）集成以进行自动形式化和猜想播种。

> **ai_Abstract:** 本文介绍了一种名为“生成逻辑”（GL）的新型确定性计算机架构，旨在实现确定性推理和知识生成。GL通过将用极简数学编程语言编写的公理定义编译成分布式逻辑块网络，系统地探索演绎关系并生成带有完整来源的可审计证明图。原型实现已成功应用于一阶皮亚诺算术，自动重建了基础算术定律的机器可检查证明。该研究还探讨了硬件-软件协同设计以实现大规模并行化，并提出与大型语言模型等概率模型集成的可能性，以增强自动形式化和猜想生成能力。

> **摘要翻译:** 我们提出了生成逻辑（GL），这是一种确定性架构，它从用户提供的公理定义（用极简数学编程语言（MPL）编写）开始，系统地探索其演绎邻域。定义被编译成一个由简单逻辑块（LBs）组成的分布式网格，这些逻辑块交换消息；每当几个表达式在推理规则下统一时，就会发出一个带有完整来源的新事实，从而产生可重放、可审计的证明图。
一个原型软件实现在一阶皮亚诺算术上实例化了该工作流。仅从皮亚诺公理开始，GL 枚举候选蕴涵，应用归一化和类型过滤器，并自动重建包括加法的结合律和交换律、乘法的结合律和交换律以及分配律等基础算术定律的机器可检查证明。生成的证明可导出为可导航的HTML，以便独立检查每个推理步骤。
我们概述了迈向大规模并行实现的硬件-软件协同设计路径，并描述了与概率模型（例如大型语言模型（LLMs））的预期集成，以实现自动形式化和猜想播种。重现皮亚诺实验的 Python 和 MPL 代码，以及完整的 HTML 证明图，可在项目 GitHub 存储库 https://github.com/Generative-Logic/GL/tree/35a111ea5ba53afe051703d6050be0c3923e9724 获取，并永久存档于 https://doi.org/10.5281/zenodo.16408441。我们邀请社区反馈和协作。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [484] [Strategic Communication and Language Bias in Multi-Agent LLM Coordination](https://arxiv.org/abs/2508.00032)
> *多智能体LLM协作中的策略性沟通与语言偏见*

*Alessio Buscemi, Daniele Proverbio, Alessandro Di Stefano, The Anh Han, German Castignani, Pietro Liò* | **Category: cs.MA** | **Updated: 2025-07-30**

**Keywords:** LLM协作, 策略性沟通, 语言偏见, 多智能体系统, FAIRGAME

**Comment:** 

> **TL;DR:** 本文研究了在多智能体LLM协作中，沟通是否会放大语言偏见，发现沟通显著影响智能体行为，并具有促进协作和强化偏见的双重作用。

**AI_Comments:** 该研究创新性地探讨了LLM智能体在多智能体协作中策略性沟通与语言偏见之间的关系。通过使用FAIRGAME框架和先进的LLM进行实验，揭示了沟通的双重作用，即既能促进协调也能强化偏见，这对于理解和设计更鲁棒的LLM多智能体系统具有重要意义。未来研究可以进一步探索如何减轻沟通带来的负面偏见影响。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在多智能体场景中的部署日益增多，但协调性并非总能得到保证。鉴于先前研究表明用于构建策略性场景的语言会影响合作行为，本文旨在探讨允许智能体进行沟通是否会放大这些由语言驱动的影响。

**Method:** 本文利用FAIRGAME框架，在有无沟通的情况下，模拟了跨不同语言和模型的单次博弈和重复博弈。实验使用了GPT-4o和Llama 4 Maverick两种先进的LLM。

**Result:** 实验结果表明，沟通显著影响智能体行为，但其影响因语言、个性和博弈结构而异。

**Conclusion:** 研究结果强调了沟通在促进协调和强化偏见方面的双重作用。

> **ai_Abstract:** 本文研究了在多智能体LLM协作中，沟通如何影响由语言驱动的行为偏差。通过在FAIRGAME框架下模拟使用GPT-4o和Llama 4 Maverick的单次和重复博弈，实验发现沟通显著影响智能体行为，其效果取决于语言、个性和博弈结构。研究强调了沟通在促进协作的同时也可能强化偏见的双重作用。

> **摘要翻译:** 大型语言模型（LLM）智能体越来越多地部署在多智能体场景中，在这些场景中，协调至关重要但并非总能得到保证。先前的研究表明，用于构建策略性场景的语言会影响合作行为。本文探讨了允许智能体进行沟通是否会放大这些由语言驱动的影响。我们利用FAIRGAME框架，在有无沟通的情况下，模拟了跨不同语言和模型的单次博弈和重复博弈。我们的实验使用了两种先进的LLM，GPT-4o和Llama 4 Maverick，揭示了沟通显著影响智能体行为，尽管其影响因语言、个性和博弈结构而异。这些发现强调了沟通在促进协调和强化偏见方面的双重作用。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [514] [WMAS: A Multi-Agent System Towards Intelligent and Customized Wireless Networks](https://arxiv.org/abs/2508.00280)
> *WMAS：一个面向智能和定制化无线网络的多智能体系统*

*Jingchen Peng, Dingli Yuan, Boxiang Ren, Jie Fan, Hao Wu, Lu Yang* | **Category: cs.MA** | **Updated: 2025-08-01**

**Keywords:** 多智能体系统, 无线网络, 强化学习, 对话拓扑, 智能服务

**Comment:** 

> **TL;DR:** WMAS是一个多智能体系统，通过优化智能体对话拓扑，为用户设备提供智能定制服务，实现更高的任务性能和更低的对话开销。

**AI_Comments:** 该论文提出了一种新颖的基于强化学习的对话拓扑优化方法，解决了多智能体系统中对话效率和准确性的关键问题。通过将对话建模为有向无环图并进行优化，WMAS有望显著提升无线网络中智能服务的性能和可靠性。其创新点在于对多智能体协作机制的优化，为未来智能无线网络的发展提供了有益探索。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能代理的快速发展为实现智能和定制化无线网络提供了前景，但编排多个智能体存在故障风险，且多智能体对话可能陷入无限循环。因此，设计一个高准确度、低对话开销的对话拓扑至关重要。

**Method:** 本文提出了一个无线多智能体系统（WMAS），将多智能体对话拓扑建模为一个有向无环图，并提出了一种基于强化学习的算法来优化该图的邻接矩阵。WMAS能够生成和自优化多智能体对话拓扑。

**Result:** 仿真结果表明，WMAS与现有系统相比，在各种任务类型下都能实现更高的任务性能和更低的对话开销。

**Conclusion:** 这些结果验证了WMAS增强未来无线网络智能性的潜力。

> **ai_Abstract:** 本文提出了一种无线多智能体系统（WMAS），旨在为用户设备提供智能和定制化的无线网络服务。针对多智能体系统可能面临的对话循环和故障风险，WMAS将智能体对话拓扑建模为有向无环图，并利用强化学习算法优化其邻接矩阵，以实现拓扑的生成和自优化。仿真结果表明，WMAS在提高任务性能和降低对话开销方面优于现有系统，展现了其提升未来无线网络智能化的潜力。

> **摘要翻译:** 人工智能（AI）代理的快速发展为实现智能和定制化无线网络提供了有前景的途径。在本文中，我们提出了一个无线多智能体系统（WMAS），它可以为不同的用户设备（UEs）提供智能和定制化的服务。值得注意的是，编排多个代理存在故障风险，并且多代理对话可能会陷入无限循环。因此，设计一个能够使代理以高准确度和低对话开销完成UE任务请求的WMAS对话拓扑至关重要。为了解决这个问题，我们将多代理对话拓扑建模为一个有向无环图，并提出了一种基于强化学习的算法来优化该图的邻接矩阵。因此，WMAS能够生成和自优化多代理对话拓扑，使代理能够有效且协作地处理来自UE的各种任务请求。跨各种任务类型的仿真结果表明，WMAS与现有多代理系统相比，可以实现更高的任务性能和更低的对话开销。这些结果验证了WMAS增强未来无线网络智能性的潜力。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [235] [MMRAG-DocQA: A Multi-Modal Retrieval-Augmented Generation Method for Document Question-Answering with Hierarchical Index and Multi-Granularity Retrieval](https://arxiv.org/abs/2508.00579)
> *MMRAG-DocQA：一种用于文档问答的多模态检索增强生成方法，结合分层索引和多粒度检索*

*Ziyu Gong, Yihua Huang, Chengcheng Mai* | **Category: cs.MM, cs.IR** | **Updated: 2025-08-01**

**Keywords:** 多模态问答, 检索增强生成, 分层索引, 多粒度检索, 长上下文文档

**Comment:** 

> **TL;DR:** 提出MMRAG-DocQA，通过分层索引和多粒度检索解决多模态长文本文档问答中现有方法的幻觉、模态间断裂和跨页碎片化问题，并在实验中表现出优越性。

**AI_Comments:** 该论文提出了一种新颖的多模态RAG方法，其创新点在于结合了分层索引和多粒度检索来处理长上下文多模态文档。这种方法有效地解决了传统RAG在多模态和跨页场景中的局限性，并通过整合文本和视觉信息，以及LLM的重排序能力，提升了问答的准确性和证据整合能力。对于复杂文档理解和多模态信息处理领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型视觉语言模型（LVLM）方法易受幻觉影响，而检索增强生成（RAG）方法则面临模态间断裂和跨页碎片化的问题，难以有效整合多页长上下文文档中的多模态证据。

**Method:** 本文提出MMRAG-DocQA模型，这是一种新颖的多模态检索增强生成（RAG）方法。该模型设计了一种分层索引机制，整合了扁平化的页内块和拓扑的跨页块，以建立页内多模态关联和长距离跨页依赖。同时，通过联合相似度评估和基于大型语言模型（LLM）的重排序，提出了一种多粒度语义检索方法，包括页级父页检索和文档级摘要检索，旨在促进多模态证据连接和长距离证据集成与推理。

**Result:** 在公共数据集MMLongBench-Doc和LongDocURL上的实验结果表明，MMRAG-DocQA方法在理解和回答富含模态信息和多页文档方面表现出优越性。

**Conclusion:** MMRAG-DocQA通过其创新的分层索引和多粒度检索机制，有效解决了多模态长上下文文档问答中现有方法的局限性，显著提升了对此类复杂文档的理解和问答能力。

> **ai_Abstract:** 本文针对多模态长上下文文档问答任务中现有LVLM和RAG方法的不足，提出了一种名为MMRAG-DocQA的新型多模态检索增强生成模型。该模型通过创新的分层索引方法（结合页内和跨页块）和多粒度语义检索策略（包括页级和文档级检索，并结合LLM重排序），有效解决了模态间断裂和跨页碎片化问题，实现了对长距离多模态证据的有效整合与推理。实验证明其在处理复杂多页文档问答方面的优越性。

> **摘要翻译:** 多模态长上下文文档问答任务旨在定位和整合分布在多页上的多模态证据（如文本、表格、图表、图像和布局），以实现问题理解和答案生成。现有方法可分为基于大型视觉语言模型（LVLM）的方法和基于检索增强生成（RAG）的方法。然而，前者容易产生幻觉，而后者则存在模态间断裂和跨页碎片化的问题。为了解决这些挑战，本文提出了一种新颖的多模态RAG模型，命名为MMRAG-DocQA，该模型利用长距离页面中的文本和视觉信息来促进准确的问答。设计了一种分层索引方法，整合了扁平化的页内块和拓扑的跨页块，以共同建立页内多模态关联和长距离跨页依赖。通过联合相似度评估和基于大型语言模型（LLLM）的重排序，提出了一种多粒度语义检索方法，包括页级父页检索和文档级摘要检索，以促进多模态证据连接和长距离证据集成与推理。在公共数据集MMLongBench-Doc和LongDocURL上进行的实验结果表明，我们的MMRAG-DocQA方法在理解和回答富含模态信息和多页文档方面表现出优越性。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [640] [Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models for Wireless Networks](https://arxiv.org/abs/2502.05695)
> *基于潜在扩散模型面向无线网络的语义感知自适应视频流*

*Zijiang Yan, Jianhua Pei, Hongda Wu, Hina Tabassum, Ping Wang* | **Category: cs.MM, cs.AI, cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 语义通信, 潜在扩散模型, 自适应视频流, 无线网络, QoE

**Comment:** Accepted in IEEE Wireless Communications

> **TL;DR:** 本文提出了一种结合潜在扩散模型（LDMs）和FFmpeg的新型语义通信框架，用于实时自适应比特率视频流，以解决传统方法的高带宽、存储效率低下和QoE下降问题，并在实验中表现出优异的性能。

**AI_Comments:** 本文的创新点在于将潜在扩散模型（LDMs）引入到语义通信（SemCom）框架中，用于视频流媒体，这是一种新颖的方法。它有效地解决了传统视频流媒体中带宽、存储和QoE的痛点。通过利用LDMs对I帧进行高效压缩，并结合B/P帧以及先进的去噪和VFI技术，实现了在资源受限的无线环境中传输高质量视频。这项工作为未来5G及后5G网络中的视频流媒体技术发展奠定了基础，具有重要的实际应用价值。抽象中未提及具体局限性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的恒定比特率流（CBS）和自适应比特率流（ABS）存在带宽使用高、存储效率低下以及用户体验质量（QoE）下降等挑战。

**Method:** 本文提出了一种新颖的语义通信（SemCom）框架，通过将潜在扩散模型（LDMs）与FFmpeg技术相结合，实现实时自适应比特率视频流。该方法利用LDMs将I帧压缩到潜在空间，以实现显著的存储和语义传输节省。同时，保留B帧和P帧作为调整元数据，以支持用户侧视频重建的有效细化。此外，该框架还结合了先进的去噪和视频帧插值（VFI）技术，以减轻语义模糊并在嘈杂的无线通信环境中恢复帧间时间连贯性。

**Result:** 实验结果表明，所提出的方法实现了高质量的视频流，并优化了带宽使用，在QoE和资源效率方面优于现有最先进的解决方案。

**Conclusion:** 这项工作为5G和未来后5G网络中的可扩展实时视频流开辟了新的可能性。

> **ai_Abstract:** 本文提出了一种创新的语义通信（SemCom）框架，将潜在扩散模型（LDMs）与FFmpeg技术集成，旨在优化无线网络中的实时自适应比特率视频流。该方案通过LDMs压缩I帧以节省存储和传输，并结合B/P帧以及先进的去噪和视频帧插值（VFI）技术，确保在嘈杂环境中维持高质量视频重建和时间连贯性。实验证明，该方法在带宽优化、QoE和资源效率方面优于现有技术，为5G及未来网络的可扩展视频流提供了新途径。

> **摘要翻译:** 本文提出了一种新颖的语义通信（SemCom）框架，通过将潜在扩散模型（LDMs）与FFmpeg技术相结合，用于实时自适应比特率视频流。该解决方案解决了传统恒定比特率流（CBS）和自适应比特率流（ABS）相关的高带宽使用、存储效率低下以及用户体验质量（QoE）下降的挑战。所提出的方法利用LDMs将I帧压缩到潜在空间，在不牺牲高视觉质量的情况下，显著节省了存储和语义传输。在保留B帧和P帧作为调整元数据以支持用户侧视频重建的有效细化的同时，所提出的框架进一步结合了最先进的去噪和视频帧插值（VFI）技术。这些技术即使在嘈杂的无线通信环境中，也能减轻语义模糊并恢复帧间时间连贯性。实验结果表明，所提出的方法实现了高质量的视频流，并优化了带宽使用，在QoE和资源效率方面优于现有最先进的解决方案。这项工作为5G和未来后5G网络中的可扩展实时视频流开辟了新的可能性。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [100] [STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers](https://arxiv.org/abs/2508.00387)
> *STF：浅层时间反馈增强脉冲Transformer*

*Zeqi Zheng, Zizheng Zhu, Yingchao Yu, Yanchen Huang, Changze Lv, Junfeng Tang, Zhaofei Yu, Yaochu Jin* | **Category: cs.NE, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 脉冲神经网络, Transformer, 时间反馈, 性能提升, 脉冲编码

**Comment:** 32 pages, 4 figures

> **TL;DR:** 本文提出了一种名为STF的轻量级浅层时间反馈模块，用于脉冲Transformer的编码层，以缩小其与浮点人工神经网络的性能差距，并在多个静态数据集上取得了显著性能提升。

**AI_Comments:** 该论文提出了一种新颖的浅层时间反馈机制（STF），旨在解决SNN中深层反馈带来的高成本问题，并有效提升了脉冲Transformer的性能。其创新点在于将反馈机制前置到编码层，并通过增强脉冲模式多样性来获得性能提升，这为SNN的编码策略提供了新的视角。该方法的轻量级和即插即用特性使其具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** Transformer-based 脉冲神经网络（SNNs）由于脉冲序列的二元特性，与浮点人工神经网络（ANNs）相比存在巨大的性能差距。现有的深层反馈循环设计虽然能缩小差距，但会导致高昂的特征转换成本、更高的参数开销、增加的能耗和更长的推理延迟。

**Method:** 本文提出了浅层时间反馈（STF）模块，这是一个轻量级的即插即用模块，用于编码层。STF由时空位置嵌入（TSPE）和时间反馈（TF）组成。

**Result:** 实验表明，STF在各种基于Transformer的SNN骨干网络上，针对CIFAR-10、CIFAR-100和ImageNet-1K等静态数据集，在不同脉冲时间步长设置下，持续提升了性能。进一步分析发现，STF增强了脉冲模式的多样性，这是性能提升的关键。此外，对抗鲁棒性和时间敏感性评估证实，STF优于直接编码及其变体。

**Conclusion:** STF作为一种新的静态场景脉冲编码方案，具有显著潜力，能够有效提升脉冲Transformer的性能并增强脉冲模式的多样性。

> **ai_Abstract:** 本文提出了一种名为浅层时间反馈（STF）的轻量级即插即用模块，旨在解决基于Transformer的脉冲神经网络（SNNs）与浮点人工神经网络（ANNs）之间的性能差距。STF由时空位置嵌入（TSPE）和时间反馈（TF）组成，主要应用于编码层。通过在多个静态数据集（如CIFAR-10、CIFAR-100和ImageNet-1K）上进行广泛实验，STF被证明能持续提升各种SNN骨干网络的性能。研究还发现，STF通过增强脉冲模式的多样性来提升性能，并在对抗鲁棒性和时间敏感性方面表现优异，显示出其作为新型脉冲编码方案的潜力。

> **摘要翻译:** 基于Transformer的脉冲神经网络（SNNs）由于脉冲序列的二元特性，与浮点人工神经网络（ANNs）相比存在巨大的性能差距。最近的努力引入了深层反馈循环来传递高层语义信息以缩小这一差距。然而，这些设计通常跨越多个深层，导致昂贵的特征转换、更高的参数开销、增加的能耗和更长的推理延迟。为了解决这个问题，我们提出了浅层时间反馈（STF），一个用于编码层的轻量级即插即用模块，它由时空位置嵌入（TSPE）和时间反馈（TF）组成。大量的实验表明，STF在各种基于Transformer的SNN骨干网络上，针对CIFAR-10、CIFAR-100和ImageNet-1K等静态数据集，在不同脉冲时间步长设置下，持续提升了性能。进一步分析表明，STF增强了脉冲模式的多样性，这是性能提升的关键。此外，对抗鲁棒性和时间敏感性评估证实，STF优于直接编码及其变体，突出了其作为静态场景新型脉冲编码方案的潜力。我们的代码将在接受后发布。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [190] [Reinitializing weights vs units for maintaining plasticity in neural networks](https://arxiv.org/abs/2508.00212)
> *重新初始化权重与单元以维持神经网络的可塑性*

*J. Fernando Hernandez-Garcia, Shibhansh Dohare, Jun Luo, Rich S. Sutton* | **Category: cs.NE, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 神经网络, 可塑性丧失, 持续学习, 权重初始化, 单元初始化

**Comment:** 

> **TL;DR:** 本文比较了在神经网络中重新初始化权重和重新初始化单元两种方法，以解决持续学习中的可塑性丧失问题。研究发现，重新初始化权重在更多场景下能有效维持网络可塑性。

**AI_Comments:** 本文针对持续学习中神经网络可塑性丧失这一重要问题，提出了创新的“选择性权重重新初始化”方法。通过与现有单元重初始化方法的对比，明确了权重重初始化在特定网络结构和规模下的优势，为设计更鲁棒的持续学习系统提供了有价值的指导。其创新点在于对重初始化策略的细致区分和实证分析，揭示了权重层面操作的更广泛适用性。

<details>
  <summary>Details</summary>

**Motivation:** 神经网络在非平稳数据上长时间训练时会丧失可学习性（可塑性丧失），这对于设计持续学习系统是一个亟待解决的关键问题。重新初始化网络部分是预防可塑性丧失的有效技术。

**Method:** 本文比较了两种不同的重新初始化方案：重新初始化单元和重新初始化权重。提出了一种名为“选择性权重重新初始化”的新算法，用于重新初始化网络中最无用的权重。通过在持续监督学习问题上的实验，将该算法与两种先前提出的重新初始化单元的算法（continual backpropagation和ReDo）进行了比较。

**Result:** 实验发现，在两种情况下重新初始化权重比重新初始化单元更能有效维持可塑性：(1) 网络单元数量较少时；(2) 网络包含层归一化时。相反，当网络规模足够大且不包含层归一化时，重新初始化权重和单元在维持可塑性方面同样有效。总体而言，重新初始化权重比重新初始化单元在更广泛的设置中保持了可塑性。

**Conclusion:** 重新初始化权重比重新初始化单元在更广泛的设置中保持了神经网络的可塑性，尤其是在网络单元数量较少或包含层归一化时。

> **ai_Abstract:** 该研究探讨了神经网络中“可塑性丧失”问题，这是持续学习中的一个关键挑战。论文比较了重新初始化网络单元和重新初始化权重的两种策略，并提出了一种新的“选择性权重重新初始化”算法。实验结果表明，在网络单元数量较少或包含层归一化时，重新初始化权重比重新初始化单元更能有效维持可塑性，且总体上在更广泛的场景下表现出优势。

> **摘要翻译:** 可塑性丧失是一种现象，指神经网络在非平稳数据上长时间训练后失去学习能力。在设计持续学习系统时，这是一个必须克服的关键问题。重新初始化网络部分是预防可塑性丧失的有效技术。在本文中，我们比较了两种不同的重新初始化方案：重新初始化单元与重新初始化权重。我们提出了一种名为“选择性权重重新初始化”的新算法，用于重新初始化网络中最无用的权重。我们将我们的算法与先前提出的两种重新初始化网络单元的算法（continual backpropagation和ReDo）进行了比较。通过我们在持续监督学习问题上的实验，我们确定了两种情况下重新初始化权重在维持可塑性方面比重新初始化单元更有效：(1) 当网络具有少量单元时；(2) 当网络包含层归一化时。相反，当网络规模足够大且不包含层归一化时，重新初始化权重和单元在维持可塑性方面同样有效。我们发现，重新初始化权重在比重新初始化单元更广泛的设置中保持了可塑性。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [198] [Sequential, Parallel and Consecutive Hybrid Evolutionary-Swarm Optimization Metaheuristics](https://arxiv.org/abs/2508.00229)
> *顺序、并行和连续混合进化-群优化元启发式算法*

*Piotr Urbańczyk, Aleksandra Urbańczyk, Magdalena Król, Leszek Rutkowski, Marek Kisiel-Dorohinicki* | **Category: cs.NE, math.OC, 90C59 (Primary), 90C27, 68T20, 68W10 (Secondary), I.2.8; I.2.6; G.1.6; F.2.1; I.6.6** | **Updated: 2025-08-01**

**Keywords:** 混合元启发式算法, 进化算法, 群智能优化, PSO-GA, 连续混合

**Comment:** 16 pages, 2 figures, 5 tables, 5 algorithms, conference

> **TL;DR:** 本文探讨了顺序、并行和连续混合进化-群元启发式算法，并提出了一种新的连续混合PSO-GA算法，实验证明其在收敛性和一致性方面表现优越。

**AI_Comments:** 本文的创新点在于提出了多种混合进化-群优化策略，特别是引入了一种新颖的连续混合PSO-GA算法，该算法通过明确的信息传递机制（修改GA变异算子以继承PSO的速度和个体最佳信息）确保了算法流程的连续性。这种方法提升了在高维搜索空间中的收敛性和一致性，对解决复杂优化问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探索结合PSO和GA特征的混合进化-群元启发式算法（包括顺序、并行和连续方式），并与标准GA和PSO进行比较。其次，引入一种新颖的连续混合PSO-GA进化算法，通过明确的信息传递机制确保PSO和GA步骤之间的连续性。

**Method:** 研究方法包括将粒子群优化（PSO）和遗传算法（GA）以顺序、并行和连续的方式进行混合，并与它们各自的标准形式进行比较。算法在包括Ackley、Griewank、Levy、Michalewicz、Rastrigin、Schwefel和Shifted Rotated Weierstrass在内的多维基准函数集上进行了测试。此外，还引入了一种新的连续混合PSO-GA进化算法，通过修改GA的变异算子来继承速度和个体最佳信息，从而确保PSO和GA步骤之间的连续性。

**Result:** 实验结果表明，混合方法在收敛性和一致性方面表现出优越性，尤其是在高维搜索空间中。

**Conclusion:** 混合进化-群优化元启发式算法，特别是新引入的连续混合PSO-GA算法，在解决高维优化问题时表现出更好的收敛性和一致性。

> **ai_Abstract:** 本文研究了顺序、并行和连续混合进化-群优化元启发式算法，将粒子群优化（PSO）和遗传算法（GA）的特性进行结合。通过在多个基准函数上进行测试，结果显示混合方法在收敛性和一致性上优于单一算法，特别是在高维空间中。此外，本文还提出了一种创新的连续混合PSO-GA算法，该算法通过信息传递机制确保了算法步骤间的连贯性。

> **摘要翻译:** 本文的目标有两方面。首先，它探讨了将PSO和GA特征以顺序、并行和连续方式结合的混合进化-群元启发式算法，并与它们的标准基本形式：遗传算法和粒子群优化进行了比较。这些算法在包括Ackley、Griewank、Levy、Michalewicz、Rastrigin、Schwefel和Shifted Rotated Weierstrass在内的多维基准函数集上进行了测试。实验结果表明，混合方法实现了卓越的收敛性和一致性，尤其是在高维搜索空间中。本文的第二个目标是引入一种新颖的连续混合PSO-GA进化算法，该算法通过明确的信息传递机制，特别是通过修改GA的变异算子以继承速度和个体最佳信息，确保了PSO和GA步骤之间的连续性。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [224] [Evolutionary Generative Optimization: Towards Fully Data-Driven Evolutionary Optimization via Generative Learning](https://arxiv.org/abs/2508.00380)
> *进化生成优化：迈向基于生成学习的完全数据驱动进化优化*

*Kebin Sun, Tao Jiang, Ran Cheng, Yaochu Jin, Kay Chen Tan* | **Category: cs.NE** | **Updated: 2025-08-01**

**Keywords:** 进化优化, 生成学习, 数据驱动, EvoGO, 自动化

**Comment:** 

> **TL;DR:** EvoGO是一个完全数据驱动的进化优化框架，利用生成学习将劣解转化为优解，并在多种任务上表现出卓越的收敛速度和性能。

**AI_Comments:** EvoGO的创新之处在于其完全数据驱动的方法，通过生成学习实现了从劣解到优解的直接转换，并取代了传统的繁殖算子，显著提高了优化效率和自动化程度。其在多种任务上的快速收敛和卓越性能显示出巨大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数据驱动进化算法大多依赖于手工启发式，这限制了它们的通用性和自动化程度。本文旨在解决这一挑战。

**Method:** 本文提出了进化生成优化（EvoGO）框架，它将进化优化过程分解为三个阶段：数据准备、模型训练和种群生成。数据准备阶段构建配对数据集以丰富训练多样性；模型训练阶段，定制的生成模型学习将劣解转化为优解；种群生成阶段，EvoGO用可扩展、可并行化的生成机制取代传统繁殖算子。

**Result:** 在数值基准、经典控制问题和高维机器人任务上的大量实验表明，EvoGO在短短10代内就实现了收敛，并且显著优于包括传统EA、贝叶斯优化和基于强化学习的方法在内的多种优化方法。

**Conclusion:** EvoGO通过其完全数据驱动的生成学习方法，克服了现有数据驱动进化算法的局限性，实现了快速收敛和卓越的性能，为进化优化提供了一种通用且自动化的解决方案。

> **ai_Abstract:** 本文提出了一种名为进化生成优化（EvoGO）的完全数据驱动框架，旨在通过生成学习克服现有数据驱动进化算法对手工启发式的依赖。EvoGO将优化过程分为数据准备、模型训练和种群生成三个阶段，其中一个定制的生成模型学习将劣质解转换为优质解，并取代了传统的繁殖算子。实验结果表明，EvoGO在多种任务上都能在极短的代数内收敛，并显著优于多种现有优化方法。

> **摘要翻译:** 数据驱动进化算法（EAs）的最新进展已展示了利用数据提高优化精度和适应性的潜力。然而，大多数现有方法仍然依赖于手工设计的启发式算法，这限制了它们的通用性和自动化程度。为了应对这一挑战，我们提出了进化生成优化（EvoGO），一个由生成学习驱动的完全数据驱动框架。EvoGO将进化优化过程简化为三个阶段：数据准备、模型训练和种群生成。数据准备阶段构建配对数据集，以在不产生额外评估成本的情况下丰富训练多样性。在模型训练期间，量身定制的生成模型学习将劣质解转化为优质解。在种群生成阶段，EvoGO用可扩展且可并行化的生成机制取代了传统的繁殖算子。在数值基准、经典控制问题和高维机器人任务上的大量实验表明，EvoGO在仅仅10代内就实现了收敛，并且显著优于广泛的优化方法，包括传统EAs、贝叶斯优化和基于强化学习的方法。源代码将公开发布。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [253] [Synthetic Biology meets Neuromorphic Computing: Towards a bio-inspired Olfactory Perception System](https://arxiv.org/abs/2504.10053)
> *合成生物学与神经形态计算的结合：迈向生物启发式嗅觉感知系统*

*Kevin Max, Larissa Sames, Shimeng Ye, Jan Steinkühler, Federico Corradi* | **Category: cs.NE, cs.ET, q-bio.NC** | **Updated: 2025-08-01**

**Keywords:** 合成生物学, 神经形态计算, 嗅觉感知, 生物启发, 气味检测

**Comment:** Updated after revision at Neuromorphic Computing and Engineering

> **TL;DR:** 该研究结合合成生物学、神经科学建模和神经形态电子系统，提出并模拟了一个模仿嗅觉的混合系统，旨在实现超灵敏、特异性和节能的嗅觉检测。

**AI_Comments:** 这篇论文通过将合成生物学与神经形态计算相结合，为生物启发式嗅觉感知系统提供了一种新颖的跨学科方法。其创新之处在于提出了一个包含生物与电子接口的混合系统，并旨在实现高灵敏度和能效。这种协同设计的方法有望克服传统传感器的局限性，并在实际应用中展现出巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 探索合成生物学、神经科学建模和神经形态电子系统如何结合，以创造一个模仿自然嗅觉的人工系统，并开发一个用于超灵敏、特异性和节能气味检测的平台。

**Method:** 提出一个由合成感觉神经元组成的混合系统，该系统具有三个关键特征：(a) 受体门控离子通道，(b) 合成生物学与半导体之间的接口，以及 (c) 基于尖峰网络的事件编码和计算。该方法通过对完整的传感和处理管道进行基于模拟的建模来验证。

**Result:** 该方法通过对完整的传感和处理管道进行基于模拟的建模得到了验证。

**Conclusion:** 该研究旨在开发一个用于超灵敏、特异性、节能气味检测的平台，对环境监测、医疗诊断和安全领域具有潜在影响。

> **ai_Abstract:** 这项研究探讨了合成生物学、神经科学建模和神经形态电子系统的融合，旨在创建一个模仿自然嗅觉的人工系统。论文提出了一种包含受体门控离子通道、生物与半导体接口以及基于尖峰网络事件处理的合成感觉神经元混合系统。该方法通过模拟完整的传感处理流程进行了验证，旨在开发一个用于超灵敏、特异性、节能气味检测的平台，应用于环境监测、医疗诊断和安全领域。

> **摘要翻译:** 在这项研究中，我们探索了合成生物学、神经科学建模和神经形态电子系统的结合如何为创建一个模仿自然嗅觉的人工系统提供新方法。我们认为协同设计方法在复制气味感知和处理的复杂动态方面具有显著优势。我们提出了一个由合成感觉神经元组成的混合系统，该系统提供三个关键特征：(a) 受体门控离子通道，(b) 合成生物学与半导体之间的接口，以及 (c) 基于尖峰网络的事件编码和计算。我们的方法通过对完整的传感和处理管道进行基于模拟的建模得到了验证。这项研究旨在开发一个用于超灵敏、特异性、节能气味检测的平台，对环境监测、医疗诊断和安全领域具有潜在影响。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [293] [Large AI Model-Enabled Secure Communications in Low-Altitude Wireless Networks: Concepts, Perspectives and Case Study](https://arxiv.org/abs/2508.00256)
> *低空无线网络中大型AI模型赋能的安全通信：概念、视角与案例研究*

*Chuang Zhang, Geng Sun, Jiacheng Wang, Yijing Lin, Weijie Yuan, Sinem Coleri, Dusit Niyato, Tony Q. S. Quek* | **Category: cs.NI, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 低空无线网络, 大型AI模型, 安全通信, 强化学习, 大型语言模型

**Comment:** This paper has been submitted to IEEE Communications Magazine for
  consideration

> **TL;DR:** 本文探讨了大型AI模型（LAM）在低空无线网络（LAWNs）安全通信中的应用，并提出了一种基于LAM的优化框架来增强安全通信任务的强化学习性能。

**AI_Comments:** 这篇论文探讨了将大型AI模型（LAMs）应用于低空无线网络（LAWNs）安全通信的创新方向。其创新点在于提出了一种结合LLMs的优化框架，通过生成增强的状态特征和设计内在奖励来提升强化学习在安全任务中的表现，这为解决LAWNs的独特安全挑战提供了一个有前景的解决方案。该研究的重要性在于其前瞻性，将新兴的LAM技术与特定且面临严峻安全挑战的无线网络领域相结合，有望推动未来LAWNs安全通信的发展。

<details>
  <summary>Details</summary>

**Motivation:** 低空无线网络（LAWNs）在通信领域潜力巨大，但由于低空操作、频繁移动和对非授权频谱的依赖，面临独特的安全挑战，使其更容易受到恶意攻击，且传统AI方法存在局限性。

**Method:** 1. 探索了LAWNs中增强的安全风险和传统AI方法的局限性。2. 介绍了LAMs的基本概念及其在解决这些挑战中的作用。3. 提出了一种新颖的基于LAM的优化框架，该框架利用大型语言模型（LLMs）在手工特征之上生成增强的状态特征并设计内在奖励，从而提高安全通信任务的强化学习性能。

**Result:** 通过一个典型案例研究，仿真结果验证了所提出框架的有效性。

**Conclusion:** 论文验证了所提出框架的有效性，并展望了将LAMs集成到安全LAWN应用中的未来方向。

> **ai_Abstract:** 本文探讨了大型人工智能模型（LAMs）在低空无线网络（LAWNs）安全通信中的应用。研究首先分析了LAWNs面临的独特安全挑战以及传统AI方法的局限性，随后介绍了LAMs的概念及其解决这些挑战的潜力。为验证LAMs的实际效益，论文提出了一种新颖的基于LAM的优化框架，该框架利用大型语言模型（LLMs）增强特征表示并设计奖励机制，以提升安全通信任务的强化学习性能。仿真结果验证了该框架的有效性，并展望了LAMs在LAWN安全应用中的未来发展。

> **摘要翻译:** 低空无线网络（LAWNs）通过支持城市包裹递送、空中检查和空中出租车等一系列应用，具有彻底改变通信的潜力。然而，与传统无线网络相比，LAWNs由于低空操作、频繁移动和对非授权频谱的依赖，面临独特的安全挑战，使其更容易受到一些恶意攻击。在本文中，我们研究了一些由大型人工智能模型（LAM）赋能的LAWNs安全通信解决方案。具体来说，我们首先探讨了LAWNs中放大的安全风险以及传统AI方法的重要局限性。然后，我们介绍了LAMs的基本概念，并深入探讨了LAMs在解决这些挑战中的作用。为了展示LAMs在LAWNs安全通信方面的实际益处，我们提出了一种新颖的基于LAM的优化框架，该框架利用大型语言模型（LLMs）在手工表示之上生成增强的状态特征，并相应地设计内在奖励，从而提高安全通信任务的强化学习性能。通过一个典型案例研究，仿真结果验证了所提出框架的有效性。最后，我们概述了将LAMs集成到安全LAWN应用中的未来方向。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [302] [Agent Network Protocol Technical White Paper](https://arxiv.org/abs/2508.00007)
> *智能体网络协议技术白皮书*

*Gaowei Chang, Eidan Lin, Chengxuan Yuan, Rizhao Cai, Binbin Chen, Xuan Xie, Yin Zhang* | **Category: cs.NI, cs.AI** | **Updated: 2025-07-18**

**Keywords:** 智能体网络协议, 智能体网络, AI原生, 互操作性, 通信协议

**Comment:** This white paper is a reformatted version of the open-source
  community edition previously released by the ANP Open Source Technology
  Community(https://github.com/agent-network-protocol)

> **TL;DR:** 随着智能体成为新的互联网实体，现有基础设施难以支持大规模智能体互联互通。智能体网络协议（ANP）提出了一种新的通信协议，旨在解决智能体之间的互联和协作问题。

**AI_Comments:** 创新性：ANP解决了智能体原生互联网基础设施的及时且关键的需求。其AI原生设计、模块化和三层架构在处理智能体身份、协商和互操作性挑战方面具有创新性。重要性：随着大型模型和自主AI的兴起，实现无缝的智能体间通信和协作对于互联网的未来至关重要。该协议可能具有基础性作用。局限性：作为一份白皮书，它主要概述了所提出的解决方案。摘要中未讨论实际实施挑战、性能基准和广泛采用的障碍。

<details>
  <summary>Details</summary>

**Motivation:** 现有互联网基础设施主要为人类交互设计，导致智能体之间存在数据孤岛、不友好的接口和高昂的协作成本，难以支持大规模智能体互联互通和协作的需求。互联网正在经历深刻变革，智能体取代传统软件、通用互联、原生协议和自主组织成为核心趋势，ANP旨在顺应这些趋势。

**Method:** 智能体网络协议（ANP）提出了一种面向智能体网络的新一代通信协议。它遵循AI原生设计，保持与现有互联网协议的兼容性，采用模块化可组合架构，遵循极简主义且可扩展的原则，并支持基于现有基础设施的快速部署。通过三层协议系统——身份和加密通信层、元协议协商层和应用协议层——ANP系统性地解决问题。

**Result:** Not mentioned in abstract

**Conclusion:** ANP通过其三层协议系统，系统性地解决了智能体身份认证、动态协商和能力发现互操作性等问题。

> **ai_Abstract:** 本文介绍了智能体网络协议（ANP），这是一种专为新兴智能体网络设计的通信协议。鉴于当前互联网基础设施不适合大规模智能体交互，ANP旨在解决数据孤岛和高协作成本等问题。它提出了一种AI原生、模块化、可扩展的三层协议系统，以促进智能体身份、协商和能力发现，旨在实现通用智能体互联和自主协作。

> **摘要翻译:** 随着大型模型和自主决策AI的发展，智能体正迅速成为继移动应用之后互联网的新实体。然而，现有的互联网基础设施主要为人类交互设计，导致智能体之间存在数据孤岛、不友好的接口和高昂的协作成本，难以支持大规模智能体互联互通和协作的需求。互联网正在经历一场深刻的变革，呈现出四个核心趋势：智能体取代传统软件、通用智能体互联互通、基于原生协议的连接以及自主智能体组织和协作。为了顺应这些趋势，智能体网络协议（ANP）提出了一种面向智能体网络的新一代通信协议。ANP遵循AI原生设计、保持与现有互联网协议的兼容性、采用模块化可组合架构、遵循极简主义且可扩展的原则，并支持基于现有基础设施的快速部署。通过三层协议系统——身份和加密通信层、元协议协商层和应用协议层——ANP系统性地解决了智能体身份认证、动态协商和能力发现互操作性等问题。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [317] [Enabling Immersive XR Collaborations over FTTR Networks (Invited)](https://arxiv.org/abs/2508.00009)
> *赋能FTTR网络上的沉浸式XR协作 (受邀)*

*Sourav Mondal, Elaine Wong* | **Category: cs.NI, cs.AI** | **Updated: 2025-07-21**

**Keywords:** FTTR, XR协作, 预测带宽分配, 无缝切换, 沉浸式体验

**Comment:** This invited paper was presented in Optica Advanced Photonic Congress
  2025

> **TL;DR:** 本文探讨了FTTR网络上实现高质量沉浸式XR协作的预测带宽分配和无缝切换方案。

**AI_Comments:** 这篇论文的创新点在于将FTTR技术应用于XR协作场景，并提出了具体的带宽分配和切换方案来优化用户体验。其重要性在于为未来XR应用提供了网络基础设施的潜在解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 实现室内沉浸式扩展现实（XR）协作需要潜在的解决方案，而光纤到房间（FTTR）被认为是一种潜在的方案。

**Method:** 探索了FTTR网络上的预测带宽分配和无缝切换方案。

**Result:** 结果表明可以在室内协作中实现高质量的沉浸式体验。

**Conclusion:** 通过在FTTR网络上实施预测带宽分配和无缝切换方案，可以实现高质量的室内沉浸式XR协作。

> **ai_Abstract:** 本文研究了光纤到房间（FTTR）网络在实现室内沉浸式扩展现实（XR）协作方面的潜力。通过探索预测带宽分配和无缝切换方案，研究表明FTTR能够支持高质量的室内沉浸式体验。

> **摘要翻译:** 光纤到房间（FTTR）是实现室内扩展现实（XR）协作的潜在解决方案。本文探讨了FTTR上的预测带宽分配和无缝切换方案，结果表明可以实现室内协作的高质量沉浸式体验。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [337] [AoI-Aware Resource Allocation with Deep Reinforcement Learning for HAPS-V2X Networks](https://arxiv.org/abs/2508.00011)
> *面向HAPS-V2X网络的深度强化学习AoI感知资源分配*

*Ahmet Melih Ince, Ayse Elif Canbilen, Halim Yanikomeroglu* | **Category: cs.NI, cs.AI, cs.LG, cs.MA, cs.SY, eess.SY** | **Updated: 2025-07-21**

**Keywords:** HAPS, V2X, AoI, 深度强化学习, 资源分配

**Comment:** 6 pages, 3 figures, to appear in IEEE conference proceedings

> **TL;DR:** 本文提出了一种基于深度强化学习（DDPG）的方法，用于在HAPS-V2X网络中优化信息年龄（AoI），以提高自动驾驶等安全关键应用的通信可靠性和信息新鲜度。

**AI_Comments:** 本文的创新点在于将HAPS与深度强化学习（DDPG）相结合，用于优化V2X网络中的信息年龄（AoI），特别强调了其在去中心化学习方面的能力，这对于未来大规模、动态变化的V2X环境非常重要。其重要性在于为6G网络中关键应用的信息新鲜度保障提供了新的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 6G网络需满足自动驾驶等安全关键应用对超高可靠和低延迟通信（HRLLC）的要求。非地面网络（NTN），特别是高空平台站（HAPS），因其广覆盖、低延迟优势，能为网络提供冗余，增强通信可靠性和信息新鲜度，尤其是在基础设施受限的地区。

**Method:** 论文提出了一种基于深度强化学习（DDPG）的方法，以动态优化高空平台站（HAPS）支持的车联网（V2X）中的信息年龄（AoI）。该方法通过实现独立学习而无需集中协调，从而提高信息新鲜度和整体网络可靠性。

**Result:** 研究结果表明，HAPS支持的解决方案与基于DDPG的学习相结合，在基于车队的自动驾驶系统中，对于高效的AoI感知资源分配具有潜力。该方法能够提高信息新鲜度和整体网络可靠性，并支持独立学习。

**Conclusion:** HAPS与深度强化学习（DDPG）相结合的解决方案在优化HAPS-V2X网络中的信息新鲜度（AoI）和资源分配方面具有显著潜力，尤其适用于车队式自动驾驶系统。

> **ai_Abstract:** 本文针对6G网络中自动驾驶等安全关键应用的超高可靠和低延迟通信需求，提出了一种基于深度强化学习（DDPG）的方法。该方法在高空平台站（HAPS）支持的车联网（V2X）中动态优化信息年龄（AoI），通过独立学习提高了信息新鲜度和网络可靠性。研究结果证明了HAPS与DDPG结合在车队自动驾驶系统AoI感知资源分配中的潜力。

> **摘要翻译:** 第六代（6G）网络旨在满足自动驾驶等安全关键应用对超高可靠和低延迟通信（HRLLC）的要求。将非地面网络（NTN）集成到6G基础设施中，为网络带来了冗余，确保即使在极端条件下也能保持通信连续性。特别是，高空平台站（HAPS）因其广覆盖和低延迟优势而脱颖而出，支持通信可靠性并增强信息新鲜度，尤其是在农村地区和基础设施受限的区域。在本文中，我们提出了基于强化学习的方法，使用深度确定性策略梯度（DDPG）来动态优化HAPS支持的车联网（V2X）中的信息年龄（AoI）。所提出的方法通过实现独立学习而无需集中协调，从而提高了信息新鲜度和整体网络可靠性。研究结果揭示了HAPS支持的解决方案与基于DDPG的学习相结合，在基于车队的自动驾驶系统中进行高效AoI感知资源分配的潜力。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [377] [Scalable Spectrum Availability Prediction using a Markov Chain Framework and ITU-R Propagation Models](https://arxiv.org/abs/2508.00028)
> *基于马尔可夫链框架和ITU-R传播模型的可扩展频谱可用性预测*

*Abir Ray* | **Category: cs.NI, cs.AI, cs.CL, cs.NA, math.NA** | **Updated: 2025-07-30**

**Keywords:** 频谱可用性预测, 马尔可夫链, ITU-R传播模型, 动态频谱接入, 认知无线电

**Comment:** 12 pages

> **TL;DR:** 该论文提出了一种结合双状态马尔可夫链和ITU-R传播模型的可扩展框架，用于在时间和空间上准确预测频谱可用性，具有低计算成本，适用于实时频谱管理。

**AI_Comments:** 该论文的创新点在于将马尔可夫链模型（用于时间维度）与高精度的ITU-R传播模型（用于空间维度）相结合，从而实现了对频谱可用性在时间和空间上的全面且准确的预测。其重要性在于提供了一种可扩展且计算效率高的方法，能够有效支持动态频谱接入和实时频谱管理，对于提升频谱资源利用率具有重要意义。该框架的灵活性使其能够适应不同的频段和应用场景。

<details>
  <summary>Details</summary>

**Motivation:** 频谱资源在时间和空间上常被低效利用，促使动态频谱接入策略的出现。主要挑战在于预测何时何地频谱可用（即未被主要许可用户使用），以实现主动且无干扰的接入。

**Method:** 提出一个可扩展的频谱可用性预测框架，该框架结合了主用户活动的双状态马尔可夫链模型和ITU-R（P.528和P.2108）高精度传播模型。马尔可夫链捕捉时间占用模式，传播模型结合路径损耗和杂波效应来判断主信号是否超过次用户位置的干扰阈值。论文开发了该方法的系统模型和算法，并分析了其可扩展性和计算效率。

**Result:** 结果和分析表明，所提出的方法能够以低计算成本有效识别可用频谱。

**Conclusion:** 该框架灵活且可适应各种频段和场景，能够以低计算成本有效识别可用频谱，使其适用于认知无线电网络和其他动态频谱共享系统中的实时频谱管理。

> **ai_Abstract:** 针对频谱资源利用率低的问题，本文提出了一种可扩展的频谱可用性预测框架。该框架创新性地结合了双状态马尔可夫链模型来捕捉频谱的时间占用模式，并利用ITU-R高精度传播模型（P.528和P.2108）来考虑空间路径损耗和杂波效应，从而在时间和空间上准确预测频谱机会。通过系统模型和算法的开发与分析，验证了该方法具有低计算成本和高效率，非常适用于认知无线电网络等动态频谱共享系统中的实时频谱管理。

> **摘要翻译:** 频谱资源在时间和空间上常被低效利用，这促使了动态频谱接入策略的产生，允许次级用户利用未使用的频率。一个关键的挑战是预测频谱何时何地可用（即未被主要许可用户使用），以实现主动且无干扰的接入。本文提出了一种可扩展的频谱可用性预测框架，该框架结合了主用户活动的双状态马尔可夫链模型与ITU-R（具体为建议P.528和P.2108）的高保真传播模型。马尔可夫链捕捉时间占用模式，而传播模型则结合路径损耗和杂波效应来确定主信号是否在次级用户位置超过干扰阈值。通过整合这些组件，所提出的方法能够以更高的准确性预测频谱在时间和空间上的机会。我们开发了该方法的系统模型和算法，分析了其可扩展性和计算效率，并讨论了假设、局限性以及潜在应用。该框架灵活，可适应各种频段和场景。结果和分析表明，所提出的方法能够以低计算成本有效识别可用频谱，使其适用于认知无线电网络和其他动态频谱共享系统中的实时频谱管理。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [379] [Non-Terrestrial Network Models Using Stochastic Geometry: Planar or Spherical?](https://arxiv.org/abs/2508.00010)
> *非地面网络随机几何模型：平面还是球形？*

*Ruibo Wang, Baha Eddine Youcef Belmekki, Howard H. Yang, Mohamed Slim Alouini* | **Category: cs.NI** | **Updated: 2025-07-21**

**Keywords:** 非地面网络, 随机几何, 平面模型, 球形模型, 相对误差

**Comment:** 

> **TL;DR:** 本文量化了非地面网络（NTN）中平面模型与球形模型之间的相对误差，以确定何时平面建模足够，并提出了相应的计算方法和优化海拔表达式。

**AI_Comments:** 该论文为非地面网络中常见的建模困境提供了一个实用的解决方案，通过严谨的框架来证明使用更简单的平面模型的合理性。最优平面海拔的推导对于降低计算复杂性具有重要的创新性。

<details>
  <summary>Details</summary>

**Motivation:** 随着非地面网络（NTN）的爆炸式部署，网络性能分析的计算复杂性迅速增加。随机几何（SG）是分析大规模网络拓扑的合适工具，但选择平面模型还是球形模型仍具挑战性，因为平面模型忽略了地球曲率，可能导致高空NTN分析出现偏差。

**Method:** 本文引入相对误差来量化平面模型和球形模型之间的差距。为此，首先提出一种点过程（PP）生成算法，可同时生成一对同质且渐进相似的平面和球形PP。然后引入了几种典型的相似性指标，包括拓扑相关和网络级指标，并进一步开发了基于这些指标的相对误差估计算法。此外，推导了最优平面海拔的解析表达式。

**Result:** 数值结果研究了部署海拔和区域如何影响NTN建模，并以高空平台（HAP）和低地球轨道（LEO）卫星星座为例进行了案例研究。

**Conclusion:** 本文提供了一种量化和管理非地面网络中平面模型误差的方法，为何时平面近似足够提供了指导，并通过推导最优平面海拔降低了计算复杂性。

> **ai_Abstract:** 本文针对使用随机几何分析非地面网络（NTN）性能时，在平面模型和球形模型之间选择的挑战。为确定何时平面简化是可接受的，文章量化了这些模型之间的相对误差，并提出了一种点过程生成算法、引入了相似性指标并开发了误差估计算法。此外，还推导了最优平面海拔的解析表达式以降低计算复杂性。数值结果，包括高空平台（HAP）和低地球轨道（LEO）案例研究，阐明了海拔和区域对NTN建模的影响。

> **摘要翻译:** 随着非地面网络（NTN）的爆炸式部署，网络性能分析的计算复杂性迅速升级。作为分析大规模网络拓扑最合适的数学工具之一，随机几何（SG）能够将网络性能指标表示为网络参数的函数，从而提供低复杂度的性能分析解决方案。然而，在平面模型和球形模型之间进行选择仍然具有挑战性。平面模型忽略了地球曲率，导致高空NTN分析出现偏差，但为了简单起见仍经常使用。本文引入相对误差来量化平面模型和球形模型之间的差距，帮助确定何时平面建模足够。为了计算相对误差，我们首先提出一种点过程（PP）生成算法，该算法同时生成一对同质且渐进相似的平面和球形PP。然后我们引入了几种典型的相似性指标，包括拓扑相关和网络级指标，并进一步开发了基于这些指标的相对误差估计算法。此外，我们推导了最优平面海拔的解析表达式，这降低了计算复杂性并为平面近似提供了理论支持。最后，数值结果研究了部署海拔和区域如何影响NTN建模，并以高空平台（HAP）和低地球轨道（LEO）卫星星座为例进行了案例研究。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [400] [Performance Analysis of SAGIN from the Relay Perspective: A Spherical Stochastic Geometry Approach](https://arxiv.org/abs/2508.00020)
> *SAGIN中继性能分析：一种球形随机几何方法*

*Ferdaous Tarhouni, Ruibo Wang, Mohamed-Slim Alouini* | **Category: cs.NI** | **Updated: 2025-07-27**

**Keywords:** SAGIN, HAP, 中继, 球形随机几何, 性能分析

**Comment:** 

> **TL;DR:** 本文从HAP中继角度分析了SAGIN的性能，使用球形随机几何推导了数据速率和BREP的解析表达式，并研究了卫星网络拓扑的影响。

**AI_Comments:** 本文的创新之处在于首次将球形随机几何（SSG）应用于从HAP中继视角分析SAGIN的性能，填补了现有文献的空白。通过推导解析表达式，实现了低复杂度的性能评估，这对于动态网络具有重要意义。对卫星网络拓扑影响的深入研究和HAP传输功率的分析也具有实际指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 满足全球无线通信日益增长的需求，SAGIN变得至关重要，其中HAPs作为中继可增强通信性能。本文旨在评估网络性能并分析HAPs作为中继在SAGIN中的作用。

**Method:** 从HAP中继角度评估SAGIN性能；引入平均接入数据速率、平均回程数据速率和回程速率超限概率（BREP）三个性能指标；采用球形随机几何（SSG）推导上述指标的解析表达式，并为BREP提供闭合形式表达式；研究卫星网络拓扑对性能的影响；分析维持短期和长期数据速率所需的最小HAP传输功率。

**Result:** 推导出了平均接入数据速率、平均回程数据速率和回程速率超限概率（BREP）的解析表达式；提供了BREP的闭合形式表达式；数值结果分析了卫星网络拓扑对性能的影响，突出了SSG框架的优势；分析了维持短期和长期数据速率所需的最小HAP传输功率。

**Conclusion:** 本文从HAP中继视角评估了SAGIN性能，并利用球形随机几何推导了关键性能指标的解析表达式，证明了SSG在分析动态拓扑和干扰方面的优势，并分析了维持数据速率所需的HAP功率。

> **ai_Abstract:** 本文从HAP中继的角度对卫星-航空-地面综合网络（SAGIN）的性能进行了深入分析。研究引入了平均接入数据速率、平均回程数据速率和回程速率超限概率（BREP）三个关键性能指标。为解决动态拓扑和干扰分析的复杂性，研究创新性地采用了球形随机几何（SSG）方法，并推导出了这些指标的解析表达式，特别是BREP的闭合形式表达式。数值结果进一步探讨了卫星网络拓扑对性能的影响，并分析了维持不同数据速率需求所需的最小HAP传输功率，展示了SSG框架在SAGIN性能评估中的独特优势。

> **摘要翻译:** 近年来，卫星-航空-地面综合网络（SAGIN）在满足日益增长的全球无线通信需求方面变得至关重要。在SAGIN中，高空平台（HAPs）可以作为通信枢纽并充当中继，以增强通信性能。在本文中，我们从中继视角评估了网络性能并分析了HAPs在SAGIN中的作用。基于这一独特的视角，我们引入了三个指标来评估性能，分别是平均接入数据速率、平均回程数据速率和回程速率超限概率（BREP）。考虑到动态拓扑和干扰分析的需求，我们选择球形随机几何（SSG）作为工具，并推导出上述指标的解析表达式，以实现低复杂度的性能评估。具体而言，我们为端到端性能指标BREP提供了一个闭合形式表达式。鉴于SSG领域目前没有从M中继视角研究网络的现有文献，我们在数值结果中专门调查了卫星网络拓扑对性能的影响，以进一步突出SSG框架的优势。此外，我们分析了维持短期和长期数据速率需求所需的最小HAP传输功率。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [424] [Towards Reliable AI in 6G: Detecting Concept Drift in Wireless Network](https://arxiv.org/abs/2508.00042)
> *面向6G可靠人工智能：无线网络中的概念漂移检测*

*Athanasios Tziouvaras, Carolina Fortuna, George Floros, Kostas Kolomvatsos, Panagiotis Sarigiannidis, Marko Grobelnik, Blaž Bertalanič* | **Category: cs.NI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 6G, 概念漂移, 无线网络, 无监督学习, 可靠人工智能

**Comment:** 10 pages, 12 figures

> **TL;DR:** 本文提出了两种无监督、模型无关的批处理概念漂移检测器，旨在解决6G无线网络中由于环境动态性导致的人工智能模型性能下降问题，并在实际用例中表现出优于传统检测器的性能。

**AI_Comments:** 本文的创新点在于提出了无监督且模型无关的概念漂移检测方法，这对于动态变化的无线网络环境至关重要，因为实际部署中通常难以获取实时标签。其在真实世界用例中的显著性能提升，表明了其在提高6G网络中AI可靠性方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** AI原生6G网络承诺前所未有的自动化和性能，但无线环境的非平稳性（基础设施变化、用户移动性、新兴流量模式）会导致概念漂移，从而迅速降低AI模型的准确性。现有方法通常是领域特定的，或难以处理某些类型的概念漂移。

**Method:** 本文引入了两种无监督、模型无关的批处理概念漂移检测器。这两种方法都计算一个预期效用分数来决定何时发生概念漂移以及是否需要模型再训练，而无需部署后提供真实标签。

**Result:** 在户外指纹定位和链路异常检测这两个真实世界的无线用例中，所提出的方法比ADWIN、DDM、CUSUM等经典检测器性能高出20-40个百分点。此外，它们在正确触发再训练警报方面分别达到了0.94和1.00的F1分数，与最佳经典检测器相比，将误报率降低了高达20个百分点。

**Conclusion:** 本文提出的两种无监督、模型无关的概念漂移检测器能够有效识别6G无线网络中的概念漂移，显著提高了AI模型的可靠性，并优于现有的经典检测方法。

> **ai_Abstract:** 本文针对6G无线网络中AI模型因概念漂移而性能下降的问题，提出了两种无监督、模型无关的批处理概念漂移检测器。这些检测器通过计算预期效用分数来判断是否需要模型再训练，且无需真实标签。在实际无线定位和异常检测任务中，它们表现出显著优于传统检测器的性能，不仅提高了检测准确率，还大幅降低了误报率，从而提升了6G网络中AI的可靠性。

> **摘要翻译:** AI原生6G网络通过在网络的无线接入和核心部分嵌入机器学习模型，有望实现前所未有的自动化和性能。然而，由于基础设施变化、用户移动性和新兴流量模式导致的无线环境的非平稳性，会引起概念漂移，从而迅速降低这些模型的准确性。现有方法通常是领域特定的，或难以处理某些类型的概念漂移。在本文中，我们引入了两种无监督、模型无关的批处理概念漂移检测器。这两种方法都计算一个预期效用分数来决定何时发生概念漂移以及是否需要模型再训练，而无需部署后提供真实标签。我们在户外指纹定位和链路异常检测这两个真实世界的无线用例中验证了我们的框架，并证明这两种方法比ADWIN、DDM、CUSUM等经典检测器性能高出20-40个百分点。此外，它们在正确触发再训练警报方面分别达到了0.94和1.00的F1分数，与最佳经典检测器相比，将误报率降低了高达20个百分点。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [450] [Benchmarking XRootD-HTTPS on 400Gbps Links with Variable Latencies](https://arxiv.org/abs/2508.00228)
> *在具有可变延迟的400Gbps链路上对XRootD-HTTPS进行基准测试*

*Aashay Arora, Diego Davila, Frank Würthwein, John Graham, Dima Mishin, Justas Balcas, Tom Lehman, Xi Yang, Chin Guok, Harvey Newman* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** XRootD-HTTPS, 400Gbps, 网络性能, 数据传输, LHC

**Comment:** Submitted to CHEP 24

> **TL;DR:** 本文研究在400Gbps高带宽和可变延迟网络环境下，XRootD-HTTPS的性能，以应对高亮度大型强子对撞机时代的数据传输挑战。

**AI_Comments:** 这项研究的重要性在于其前瞻性，针对高亮度大型强子对撞机时代的海量数据传输需求进行性能基准测试，特别是在高带宽和可变延迟的复杂网络环境下。通过复制真实网络条件的方法，增加了研究结果的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 应对高亮度大型强子对撞机时代网络流量的增长，确保软件准备就绪，满足US-CMS Tier-2站点400 Gbps带宽需求并解决站点间可变延迟的挑战。

**Method:** 通过系统测试，改变每个集群的源数量和每个源的CPU分配，并复制真实的网络条件，包括创建跨越广域网多个交换机的网络“环路”，来识别XRootD HTTP第三方复制的性能并探索不同的主机和传输配置。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文旨在为高亮度大型强子对撞机时代日益增长的网络流量做好准备，重点关注US-CMS Tier-2站点在400 Gbps带宽和可变延迟下的软件和硬件改进。研究通过系统测试，在模拟真实网络条件下，评估XRootD HTTP第三方复制的性能，并探索不同的主机和传输配置，以应对未来数据传输的挑战。

> **摘要翻译:** 预计高亮度大型强子对撞机时代到来，迫切需要监督软件准备情况，以应对未来生产和用户数据分析访问的网络流量增长。本文探讨了US-CMS Tier-2站点所需的软件和硬件改进，以维持并满足预计的400 Gbps带宽需求，同时应对站点间可变延迟带来的挑战。具体而言，我们的研究重点是识别XRootD HTTP第三方复制在多个400 Gbps链路上的性能，并探索不同的主机和传输配置。我们的方法涉及系统测试，其中包含每个集群的源数量和每个源的CPU分配的变化。通过复制真实网络条件并创建跨越广域网多个交换机的网络“环路”，我们能够复制真实的网络条件。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [475] [Energy Efficient Trajectory Control and Resource Allocation in Multi-UAV-assisted MEC via Deep Reinforcement Learning](https://arxiv.org/abs/2508.00261)
> *基于深度强化学习的多无人机辅助MEC能效轨迹控制与资源分配*

*Saichao Liu, Geng Sun, Chuang Zhang, Xuejie Liu, Jiacheng Wang, Changyuan Zhao, Dusit Niyato* | **Category: cs.NI, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 无人机辅助MEC, 深度强化学习, 轨迹控制, 资源分配, 模仿学习

**Comment:** This paper has been accepted by IEEE GLOBECOM 2025

> **TL;DR:** 研究多无人机辅助MEC系统，通过优化无人机轨迹和资源分配，最大化卸载数并最小化延迟和能耗，提出基于模仿学习的DRL算法DPPOIL，证明其优于基线方法。

**AI_Comments:** 本文的创新点在于将深度强化学习，特别是结合了模仿学习的DPPOIL算法，应用于多无人机辅助MEC系统中的复杂轨迹控制和资源分配联合优化问题。这种方法有效解决了系统动态性和连续决策的挑战，对于提升MEC系统的能效和性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 移动边缘计算(MEC)性能受限于固定位置和有限服务范围，因此需要研究无人机辅助MEC系统来提升性能。

**Method:** 1. 将无人机轨迹控制和资源分配问题建模为多目标优化问题(TCRAMOP)，旨在最大化无人机卸载数量，同时最小化总卸载延迟和无人机总能耗。2. 针对TCRAMOP的连续决策和动态系统特性，提出一种增强型深度强化学习(DRL)算法，即分布式近端策略优化与模仿学习(DPPOIL)，该算法融入生成对抗模仿学习技术以提升策略性能。

**Result:** 仿真结果表明所提出的DPPOIL算法有效，并且其学习到的策略优于其他基线方法。

**Conclusion:** 通过提出DPPOIL算法，该研究成功解决了多无人机辅助MEC系统中的能效轨迹控制和资源分配问题，显著提升了系统性能。

> **ai_Abstract:** 本文研究多无人机辅助移动边缘计算(MEC)系统中的能效轨迹控制和资源分配问题。针对MEC的局限性，作者构建了一个多目标优化问题(TCRAMOP)，旨在通过优化无人机飞行路径和计算资源分配，同时最大化卸载数并最小化延迟和能耗。为解决此动态连续决策问题，提出了一种名为DPPOIL的增强型深度强化学习算法，该算法集成了生成对抗模仿学习。仿真结果验证了DPPOIL的有效性及其优于基线方法的性能。

> **摘要翻译:** 移动边缘计算（MEC）是一种很有前景的技术，可以提高物联网（IoT）中智能设备（SD）的计算能力。然而，MEC的性能受限于其固定位置和有限的服务范围。因此，我们研究了一种无人机（UAV）辅助的MEC系统，其中部署了多架无人机，每架无人机可以同时为多个智能设备提供计算服务。为了提高系统性能，我们构建了一个基于无人机的轨迹控制和资源分配多目标优化问题（TCRAMOP），通过优化无人机的飞行路径以及分配给所服务智能设备的计算资源，同时最大化无人机的卸载数量并最小化总卸载延迟和无人机总能耗。然后，考虑到TCRAMOP的解决方案需要连续决策且系统是动态的，我们提出了一种增强型深度强化学习（DRL）算法，即分布式近端策略优化与模仿学习（DPPOIL）。该算法结合了生成对抗模仿学习技术以提高策略性能。仿真结果表明我们提出的DPPOIL算法是有效的，并证明DPPOIL的学习策略优于其他基线方法。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [504] [Mamba for Wireless Communications and Networking: Principles and Opportunities](https://arxiv.org/abs/2508.00403)
> *Mamba在无线通信与网络中的应用：原理与机遇*

*Rongsheng Zhang, Ruichen Zhang, Yang Lu, Wei Chen, Bo Ai, Dusit Niyato* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** Mamba, 无线通信, 神经网络, 信号处理, 资源分配

**Comment:** 

> **TL;DR:** 本文全面概述了Mamba模型在无线通信和网络中的应用，分析了其潜力，提出了两种应用框架，并通过案例研究展示了其在特征增强和计算效率方面的改进，并指出了挑战和未来研究方向。

**AI_Comments:** 本文系统性地探讨了Mamba模型在无线通信与网络领域的应用前景，其创新之处在于提出了两种具体的应用框架，并通过案例研究验证了Mamba在提升系统性能和计算效率方面的潜力。这对于推动AI模型在复杂无线环境中的落地具有重要意义，同时也为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于无线网络日益增长的异构性和动态性，Mamba模型有望通过平衡计算效率和有效性之间的权衡，彻底改变无线通信和网络设计。

**Method:** 本文首先从长距离依赖建模和空间特征提取的角度分析了Mamba在无线信号处理任务中的潜力。然后提出了两种Mamba在无线通信中的应用框架：替代传统算法和实现新范式。通过智能资源分配和联合信源信道解码的案例研究，验证了Mamba的改进。

**Result:** Mamba在无线通信的案例研究（如智能资源分配和联合信源信道解码）中展示了在特征增强和计算效率方面的改进。

**Conclusion:** Mamba模型在无线通信与网络中具有巨大潜力，能够提升特征增强和计算效率。文章还指出了Mamba在该领域面临的关键挑战并概述了未来的研究方向。

> **ai_Abstract:** 本文探讨了Mamba模型在无线通信和网络领域的应用潜力。鉴于无线网络的复杂性，Mamba能够有效处理时空数据，并通过在计算效率和性能之间取得平衡来革新设计。文章分析了Mamba在信号处理中的潜力，提出了替代传统算法和实现新范式的两种应用框架。通过智能资源分配和联合信源信道解码的案例研究，论文展示了Mamba在特征增强和计算效率上的提升。最后，文章指出了该领域的挑战和未来的研究方向。

> **摘要翻译:** Mamba已成为一种强大的模型，能够有效处理涉及时间序列和空间数据的任务。鉴于无线网络日益增长的异构性和动态性，Mamba有望通过平衡计算效率和有效性之间的权衡，彻底改变无线通信和网络设计。本文全面概述了Mamba在无线系统中的应用。具体而言，我们首先从长距离依赖建模和空间特征提取的角度分析了Mamba在无线信号处理任务中的潜力。然后，我们提出了Mamba在无线通信中的两种应用框架，即替代传统算法和实现新范式。在这两种框架的指导下，我们对智能资源分配和联合信源信道解码进行了案例研究，以证明Mamba在特征增强和计算效率方面的改进。最后，我们强调了Mamba在无线通信和网络中面临的关键挑战，并概述了潜在的研究方向。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [525] [Enhancing Wireless Networks for IoT with Large Vision Models: Foundations and Applications](https://arxiv.org/abs/2508.00583)
> *使用大型视觉模型增强物联网无线网络：基础与应用*

*Yunting Xu, Jiacheng Wang, Ruichen Zhang, Dusit Niyato, Deepu Rajan, Liang Yu, Haibo Zhou, Abbas Jamalipour, Xianbin Wang* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** 大型视觉模型, 物联网, 无线网络, 渐进式微调, 波束赋形

**Comment:** 7 pages, 6 figures

> **TL;DR:** 本文探讨了大型视觉模型（LVMs）在物联网无线网络中的应用，提出了一种渐进式微调框架，并在低空经济网络中验证了其在波束赋形和定位任务上的有效性。

**AI_Comments:** 该论文创新性地将大型视觉模型（LVMs）引入到无线网络优化中，并针对LVMs模型庞大和再训练困难的挑战，提出了渐进式微调框架。通过在低空经济网络中的案例研究，验证了其在特定任务上的优越性，为视觉智能与无线通信的融合开辟了新路径，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉模型（LVMs）在视觉智能领域表现出色，具有卓越的泛化和适应性，有望优化视觉辅助网络。本文旨在探索LVMs在无线通信中的应用，并解决其模型大、再训练难的问题，从而增强物联网无线网络。

**Method:** 首先调查LVMs的功能和核心架构，然后探讨LVMs在无线通信（物理层、网络层、应用层）中的各种应用。针对LVMs庞大的模型规模和无线领域中模型再训练的挑战，提出了一种渐进式微调框架，该框架逐步调整预训练的LVMs以联合优化多个IoT任务。

**Result:** 在低空经济网络（LAENets）中的案例研究表明，所提出的渐进式微调框架在无人机互联网的联合波束赋形和定位任务上，比传统CNN表现出更高的有效性。

**Conclusion:** 将大型视觉模型（LVMs）集成到智能无线系统中是一个非常有前景的方向，能够有效增强物联网无线网络的性能。

> **ai_Abstract:** 本文探讨了大型视觉模型（LVMs）在物联网（IoT）无线网络中的潜力与应用。研究了LVMs的核心功能及其在无线通信各层（物理层、网络层、应用层）的应用。针对LVMs模型大、再训练难的问题，提出了一种渐进式微调框架，以联合优化多项IoT任务。案例研究表明，该框架在低空经济网络中，针对无人机互联网的联合波束赋形和定位任务，优于传统CNN，为智能无线系统集成LVMs指明了方向。

> **摘要翻译:** 大型视觉模型（LVMs）已成为视觉智能领域的基础范式，在各种视觉任务中取得了最先进的性能。LVMs的最新进展促进了它们与物联网（IoT）场景的集成，为视觉辅助网络优化提供了卓越的泛化能力和适应性。在本文中，我们首先调查了LVMs的功能和核心架构，强调了它们在分类、分割、生成和多模态视觉处理方面的能力。然后，我们探讨了LVMs在无线通信中的各种应用，涵盖了物理层、网络层和应用层中的代表性任务。此外，考虑到LVMs庞大的模型规模以及无线领域中模型再训练的挑战，我们提出了一种渐进式微调框架，该框架逐步调整预训练的LVMs以联合优化多个IoT任务。在低空经济网络（LAENets）中的案例研究表明，所提出的框架在无人机互联网的联合波束赋形和定位任务上比传统CNN更有效，这强调了将LVMs集成到智能无线系统中的一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [530] [Energy-Aware CPU Orchestration in O-RAN: A dApp-Driven Lightweight Approach](https://arxiv.org/abs/2508.00629)
> *O-RAN中节能CPU编排：一种dApp驱动的轻量级方法*

*Francisco Crespo, Javier Villegas, Carlos Baena, Eduardo Baena, Sergio Fortes, Raquel Barco* | **Category: cs.NI, cs.OS, cs.PF** | **Updated: 2025-08-01**

**Keywords:** O-RAN, CPU编排, 能效, dApp, 资源管理

**Comment:** 

> **TL;DR:** 该研究提出了一种轻量级分布式应用（dApp），用于在O-RAN分布式单元（DU）层面动态编排CPU使用，以提高能效和CPU利用率，同时保持实时性能。

**AI_Comments:** 该论文的创新之处在于提出了一种轻量级且非侵入性的dApp方法，解决了O-RAN环境中CPU资源管理和能效优化的关键问题。其优势在于无需对RAN软件或内核进行修改，具有良好的兼容性和通用性。其重要性在于为未来RAN部署提供了一种高效且灵活的资源管理范式，有助于降低运营成本并提升网络性能。

<details>
  <summary>Details</summary>

**Motivation:** O-RAN向软件化无线接入网络（RAN）的转变引入了在严格实时约束下高效管理CPU资源的新挑战。特别是，延迟敏感的RAN工作负载与通用操作系统（OS）调度器之间的相互作用常导致次优性能和不必要的能耗。

**Method:** 本文提出了一种轻量级、可编程的分布式应用（dApp），部署在分布式单元（DU）层面，用于动态编排CPU使用。该dApp与操作系统闭环运行，利用上下文切换、每周期指令数（IPC）和缓存指标等线程级遥测数据，实时调整CPU线程亲和性、核心隔离和频率缩放。该方案无需访问专有RAN软件、硬件特定功能或内核修改，且符合O-RAN架构，对底层RAN堆栈无感知。

**Result:** 使用商业级srsRAN部署进行的实验结果表明，在不影响实时处理性能的情况下，实现了持续的节电效果。

**Conclusion:** 低延迟dApp在下一代网络中进行细粒度资源控制方面具有巨大潜力。

> **ai_Abstract:** 本研究针对O-RAN中软件化RAN面临的CPU资源管理挑战，特别是现有OS调度器导致能耗和性能次优的问题，提出了一种轻量级、dApp驱动的CPU编排方案。该dApp部署于DU层面，通过与OS闭环交互并利用线程级遥测数据，动态调整CPU线程亲和性、核心隔离和频率缩放。该方案无需专有软件或内核修改，且与O-RAN架构兼容，实验证明能在不牺牲实时性能的前提下显著节约能耗，展现了dApp在下一代网络资源控制中的潜力。

> **摘要翻译:** 向由开放式无线接入网络（O-RAN）范式驱动的软件化无线接入网络（RAN）的过渡，通过基站功能的解耦和虚拟化，实现了灵活、与供应商无关的部署。然而，这种转变在严格的实时约束下引入了有效管理CPU资源的新挑战。特别是，延迟敏感的RAN工作负载与通用操作系统（OS）调度器之间的相互作用常常导致次优性能和不必要的能耗。这项工作提出了一种轻量级、可编程的分布式应用（dApp），部署在分布式单元（DU）层面，用于动态编排CPU使用。该dApp与操作系统闭环运行，利用上下文切换、每周期指令数（IPC）和缓存指标等线程级遥测数据，实时调整CPU线程亲和性、核心隔离和频率缩放。与现有解决方案不同，它不需要访问专有RAN软件、硬件特定功能或内核修改。所提出的解决方案完全符合O-RAN架构，且对底层RAN堆栈无感知，引入的开销可忽略不计，同时提高了能效和CPU利用率。使用商业级srsRAN部署进行的实验结果表明，在不影响实时处理性能的情况下，实现了持续的节电效果，凸显了低延迟dApp在下一代网络中进行细粒度资源控制的潜力。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [550] [Joint Association and Phase Shifts Design for UAV-mounted Stacked Intelligent Metasurfaces-assisted Communications](https://arxiv.org/abs/2508.00616)
> *无人机搭载堆叠智能超表面辅助通信的联合关联与相移设计*

*Mingzhe Fan, Geng Sun, Hongyang Pan, Jiacheng Wang, Jiancheng An, Hongyang Du, Chau Yuen* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** UAV-SIMs, 堆叠智能超表面, 联合优化, 交替优化, 网络容量

**Comment:** This papar has been submitted to the IEEE Global Communications
  Conference. arXiv admin note: substantial text overlap with arXiv:2506.23488

> **TL;DR:** 本文研究无人机搭载堆叠智能超表面（UAV-SIMs）辅助通信系统中的联合优化问题，旨在通过优化关联、位置和相移来最大化网络容量。

**AI_Comments:** 本文的创新之处在于将移动无人机与堆叠智能超表面结合，实现了通信系统的灵活部署和性能增强。通过提出一个全面的联合优化框架，并采用分解和交替优化的方法来解决复杂的非凸问题，为实际应用提供了可行的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 固定堆叠智能超表面（SIMs）会限制系统通信性能，而移动的无人机搭载SIMs（UAV-SIMs）能更灵活地部署并增强通信性能。因此，需要一个联合优化方案来最大化网络容量。

**Method:** 本文提出了一个无人机搭载SIMs的联合优化问题（USBJOP），综合考虑了UAV-SIMs与用户之间的关联、UAV-SIMs的位置以及UAV-SIMs的相移，目标是最大化网络容量。由于USBJOP的非凸性和NP-难性，将其分解为三个子优化问题：UAV-SIMs与用户关联优化问题（AUUOP）、无人机位置优化问题（ULOP）和UAV-SIM相移优化问题（USPSOP）。然后，采用交替优化（AO）策略解决这三个子问题。具体来说，AUUOP和ULOP被转化为凸形式并使用CVX工具求解，而USPSOP采用逐层迭代优化方法。

**Result:** 仿真结果验证了所提出策略在不同仿真设置下的有效性。

**Conclusion:** 所提出的针对无人机搭载堆叠智能超表面辅助通信系统的联合优化策略能够有效提升网络容量。

> **ai_Abstract:** 本文提出了一种针对无人机搭载堆叠智能超表面（UAV-SIMs）辅助通信系统的联合优化框架，旨在通过优化UAV-SIMs与用户的关联、UAV-SIMs的位置以及UAV-SIMs的相移来最大化网络容量。针对该非凸且NP-难的问题，作者将其分解为三个子问题，并采用交替优化策略进行求解。其中，关联和位置子问题被转化为凸形式并用CVX求解，相移子问题则采用逐层迭代优化。仿真结果验证了该方法的有效性。

> **摘要翻译:** 堆叠智能超表面（SIMs）作为一种实现波域信号处理的有前景技术而出现，然而，与移动SIMs相比，固定SIMs会限制系统的通信性能。在这项工作中，我们考虑了一种无人机搭载SIMs（UAV-SIMs）辅助的通信系统，其中无人机作为基站（BSs）可以缓存由SIMs处理的数据，并且作为移动载体灵活部署SIMs以增强通信性能。为此，我们提出了一个基于UAV-SIM的联合优化问题（USBJOP），综合考虑了UAV-SIMs与用户之间的关联、UAV-SIMs的位置以及UAV-SIMs的相移，旨在最大化网络容量。由于USBJOP的非凸性和NP-难性，我们将其分解为三个子优化问题，分别是UAV-SIMs与用户关联优化问题（AUUOP）、无人机位置优化问题（ULOP）和UAV-SIM相移优化问题（USPSOP）。然后，这些三个子优化问题通过交替优化（AO）策略求解。具体来说，AUUOP和ULOP被转化为凸形式，然后通过CVX工具求解，而USPSOP我们采用逐层迭代优化方法。仿真结果验证了所提出策略在不同仿真设置下的有效性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [570] [Criticality-Based Dynamic Topology Optimization for Enhancing Aerial-Marine Swarm Resilience](https://arxiv.org/abs/2508.00688)
> *基于关键性的动态拓扑优化以增强空海蜂群韧性*

*Ruiyang Huang, Haocheng Wang, Yixuan Shen, Ning Gao, Qiang Ni, Shi Jin, Yifan Wu* | **Category: cs.NI, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 蜂群网络, 拓扑优化, 网络韧性, 关键性评估, 图卷积网络

**Comment:** Submit to INFOCOM 2026

> **TL;DR:** 本文提出了一种结合节点关键性评估和多目标拓扑优化的两步框架，以提高异构空海蜂群网络在对抗环境下的韧性，并在关键节点识别和网络性能提升上优于传统方法。

**AI_Comments:** 该论文的创新点在于结合了基于图卷积网络的实时关键性评估（SurBi-Ranking）与多目标拓扑优化（NSGA-III），以应对异构蜂群网络在对抗环境下的韧性挑战。其重要性在于提供了一种有效提升空海蜂群网络在复杂多变环境下生存能力和任务执行效率的策略。方法论的系统性（三层架构、两步优化）和实验结果的量化（降低30%连通性下降）是其亮点。

<details>
  <summary>Details</summary>

**Motivation:** 异构空海蜂群网络在对抗环境下，由于有针对性的通信中断和结构弱点而面临巨大困难，需要提升其网络韧性。

**Method:** 本文提出了一个两步框架：首先，设计了一个三层架构来表示蜂群网络的结构、通信和任务依赖性。其次，引入SurBi-Ranking方法（利用图卷积网络）实时动态评估和排序节点和边的关键性。最后，应用NSGA-III算法优化网络拓扑，旨在平衡通信效率、全局连通性和任务成功率。

**Result:** 实验表明，与K-Shell等传统方法相比，SurBi-Ranking方法能更准确地识别关键节点和边，因为攻击这些组件会导致更显著的连通性下降。此外，在优先考虑受攻击的SurBi-Ranked关键组件时，该优化方法将自然连通性下降降低了约30%，实现了更高的任务成功率，并降低了通信重构成本。

**Conclusion:** 本文提出的基于关键性评估的动态拓扑优化框架，显著增强了空海蜂群网络在对抗环境下的韧性，提高了关键节点识别的准确性，并有效提升了多阶段操作中的连通性和任务效率。

> **ai_Abstract:** 本文提出了一种两步框架，用于增强异构空海蜂群网络在对抗环境下的韧性。该框架首先通过三层架构表示网络依赖性，然后利用基于图卷积网络的SurBi-Ranking方法实时评估节点和边的关键性。接着，采用NSGA-III算法进行多目标拓扑优化，以平衡通信效率、全局连通性和任务成功率。实验证明，该方法在关键组件识别准确性和网络性能提升（如降低连通性下降、提高任务成功率）方面优于传统方法。

> **摘要翻译:** 异构空海蜂群网络在对抗环境下，由于有针对性的通信中断和结构弱点而面临巨大困难。本文提出了一个两步框架来增强网络的韧性。具体而言，我们的框架将基于关键性的节点优先级与多目标拓扑优化相结合。首先，我们设计了一个三层架构来表示蜂群网络的结构、通信和任务依赖性。然后，我们引入了SurBi-Ranking方法，该方法利用图卷积网络，实时动态评估和排序节点和边的关键性。接下来，我们应用NSGA-III算法来优化网络拓扑，旨在平衡通信效率、全局连通性和任务成功率。实验表明，与K-Shell等传统方法相比，我们的SurBi-Ranking方法能更准确地识别关键节点和边，因为对这些组件的蓄意攻击会导致更显著的连通性下降。此外，当在攻击下优先考虑SurBi-Ranked关键组件时，我们的优化方法将自然连通性下降降低了约30%，实现了更高的任务成功率，并降低了通信重构成本，确保了多阶段操作中持续的连通性和任务有效性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [590] [Deep Joint Source-Channel Coding for Small Satellite Applications](https://arxiv.org/abs/2508.00715)
> *用于小型卫星应用的深度联合信源信道编码*

*Olga Kondrateva, Grace Li Zhang, Julian Zobel, Björn Scheuermann, Stefan Dietzel* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** 深度联合信源信道编码, 小型卫星, 自适应架构, 注意力模块, 卫星通信

**Comment:** 

> **TL;DR:** 本文提出了一种为卫星通信量身定制的深度联合信源信道编码（DJSCC）框架，特别是ADJSCC-SAT，它利用注意力模块使单个神经网络能够适应各种信道状态，显著减少模型存储并提高鲁棒性。

**AI_Comments:** 本文的创新点在于提出了ADJSCC-SAT这种自适应架构，利用注意力模块使单个DJSCC神经网络能够适应多种信道状态，从而解决了为每种信道条件部署单独模型的不切实际性。这显著减少了模型存储需求，并提高了系统在实际卫星通信环境中对信道估计误差的鲁棒性，是DJSCC技术在卫星应用中迈向实用化的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 小型地球观测卫星产生大量高维数据，但其在低地球轨道的运行由于有限的接触时间和恶劣多变的信道条件，造成了显著的通信瓶颈。虽然深度联合信源信道编码（DJSCC）是一种有前景的技术，但其在复杂卫星环境中的实际应用仍是一个悬而未决的问题。

**Method:** 本文提出了一个为卫星通信量身定制的综合DJSCC框架。首先建立了一个基本系统DJSCC-SAT，并集成了一个真实的、多状态统计信道模型来指导其训练和评估。为了克服为每种信道条件使用单独模型的不切实际性，引入了一种自适应架构ADJSCC-SAT，它利用注意力模块使单个神经网络能够适应各种信道状态，且开销极小。

**Result:** 通过对Sentinel-2多光谱数据的广泛评估，结果表明，自适应方法ADJSCC-SAT的性能与使用多个专用网络相当，同时显著减少了模型存储需求。此外，自适应模型对信道估计误差显示出增强的鲁棒性，优于非自适应基线。

**Conclusion:** 所提出的框架是向在真实世界卫星任务中部署鲁健、自适应DJSCC系统迈出的实用而有效的一步。

> **ai_Abstract:** 本文针对小型卫星通信中的通信瓶颈问题，提出了一个深度联合信源信道编码（DJSCC）框架。研究首先建立了DJSCC-SAT系统，并引入了自适应架构ADJSCC-SAT，该架构利用注意力模块使单个神经网络能够适应多种信道条件，从而减少了对多个专用模型的需求。实验结果表明，ADJSCC-SAT在性能上与多网络方案相当，同时显著降低了模型存储需求，并增强了对信道估计误差的鲁棒性。该框架为在实际卫星任务中部署鲁棒、自适应的DJSCC系统提供了实用且高效的解决方案。

> **摘要翻译:** 小型地球观测卫星产生大量高维数据，但其在低地球轨道的运行由于有限的接触时间和恶劣多变的信道条件，造成了显著的通信瓶颈。虽然深度联合信源信道编码（DJSCC）已成为一种有前景的技术，但其在复杂卫星环境中的实际应用仍是一个悬而未决的问题。本文提出了一个为卫星通信量身定制的综合DJSCC框架。我们首先建立了一个基本系统DJSCC-SAT，并集成了一个真实的、多状态统计信道模型来指导其训练和评估。为了克服为每种信道条件使用单独模型的不切实际性，我们然后引入了一种自适应架构ADJSCC-SAT，它利用注意力模块使单个神经网络能够调整到各种信道状态，且开销极小。通过对Sentinel-2多光谱数据的广泛评估，我们证明了我们的自适应方法在性能上与使用多个专用网络相当，同时显著减少了模型存储需求。此外，自适应模型对信道估计误差显示出增强的鲁棒性，优于非自适应基线。所提出的框架是向在真实世界卫星任务中部署鲁健、自适应DJSCC系统迈出的实用而有效的一步。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [610] [Overlapping IPv4, IPv6, and TCP data: exploring errors, test case context and multiple overlaps inside network stacks and NIDSes with PYROLYSE](https://arxiv.org/abs/2508.00735)
> *重叠的IPv4、IPv6和TCP数据：使用PYROLYSE探索网络栈和NIDS中的错误、测试用例上下文和多重重叠*

*Lucas Aubard, Johan Mazel, Gilles Guette, Pierre Chifflier* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** IP分片, TCP分段, 重组策略, 网络入侵检测系统, PYROLYSE

**Comment:** 

> **TL;DR:** 本文介绍了PYROLYSE工具，用于审计IP和TCP重组策略，发现这些策略比预期的更多样，并揭示了导致安全问题的错误，指出NIDS不应仅基于双对策略处理多重重叠。

**AI_Comments:** PYROLYSE工具的提出填补了对IP/TCP重组策略进行系统性、穷尽性测试的空白，揭示了以前未被充分认识到的多样性和潜在漏洞。发现的8个错误，特别是获得CVE的NIDS错误，凸显了该研究的实际安全价值和对网络安全社区的贡献。研究指出的NIDS在处理多重重叠时的策略缺陷，对未来NIDS和网络流量分析工具的设计和配置具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** IP分片和TCP分段允许数据包重叠，但IPv4、IPv6和TCP的重组策略在不同实现中存在差异，这可能导致NIDS与被监控主机操作系统对数据包的解释不一致，从而产生漏洞。

**Method:** 本文的贡献有两点：一是开发了PYROLYSE工具，一个审计工具，用于穷尽测试和描述各种IP和TCP实现类型的重组策略，确保它们无错误地重组重叠的数据块序列。二是分析了PYROLYSE的测试结果。

**Result:** 首先，重组策略比之前认为的更加多样，针对n≤3的测试用例块和不同测试场景，在23个测试实现中观察到14到20种不同的行为。其次，发现了8个影响一个操作系统、两个NIDS和两个嵌入式栈的错误，这些错误可能导致NIDS模式匹配绕过或DoS攻击等安全问题，其中一个NIDS错误已获得CVE编号。最后，通过块对测试获得的IP和TCP策略与观察到的三元组重组通常不一致。

**Conclusion:** IP和TCP的重组策略比预期的更加多样，且存在安全漏洞。NIDS或其他网络流量分析工具在处理重叠块数量超过两个时，不应仅仅应用n=2的对策略，因为这与实际的三元组重组不一致。

> **ai_Abstract:** 本文介绍了PYROLYSE工具，用于审计IPv4、IPv6和TCP的重组策略。研究发现，这些策略在不同实现中存在高度多样性，并揭示了多个可能导致NIDS绕过或DoS攻击的安全漏洞。研究强调，NIDS在处理多重重叠数据时，不应仅依赖于双对重组策略，因为这与实际的三元组重组行为不符。

> **摘要翻译:** IP分片和TCP分段允许将大型数据包分割成较小的包，例如为了通过容量有限的网络链路传输。这些机制允许在重叠部分与不同数据进行完全或部分重叠。IPv4、IPv6和TCP的重组策略，即取决于重叠类型的数据块偏好，在不同的协议实现中有所不同。这导致了漏洞，因为NIDS可能与被监控主机操作系统对数据包的解释不同。一些NIDS，如Suricata或Snort，可以配置使其策略与被监控操作系统保持一致。本文的第一个贡献是PYROLYSE，一个审计工具，它穷尽地测试和描述了各种IP和TCP实现类型的重组策略。该工具确保实现能够无错误地重组重叠的数据块序列。第二个贡献是对PYROLYSE工件的分析。我们首先表明，重组策略比以前认为的更加多样化。事实上，通过测试n≤3个测试用例块的所有重叠可能性和不同的测试场景，我们观察到在23个测试实现中，根据协议不同，有14到20种不同的行为。其次，我们报告了8个错误，影响到一个操作系统、两个NIDS和两个嵌入式栈，这些错误可能导致NIDS模式匹配绕过或DoS攻击等安全问题。一个NIDS错误已被分配了CVE。最后，我们表明通过块对测试获得的已实现IP和TCP策略通常与观察到的三元组重组不一致。因此，与它们目前所做的相反，当重叠块的数量超过两个时，NIDS或其他网络流量分析工具不应应用n=2的对策略。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [636] [Data Movement Manager (DMM) for the SENSE-Rucio Interoperation Prototype](https://arxiv.org/abs/2508.00792)
> *SENSE-Rucio 互操作原型的数据移动管理器 (DMM)*

*Aashay Arora, Diego Davila, Jonathan Guiang, Frank Würthwein, Harvey Newman, Justas Balcas, Tom Lehman, Xi Yang* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** 数据移动管理器, Rucio, SENSE, SDN, 高能物理, 数据传输

**Comment:** Submitted to CHEP 24

> **TL;DR:** DMM 是一个原型接口，连接 CERN 的 Rucio 和 ESNet 的 SENSE，以实现 SDN 驱动的高能物理数据流，并通过优先级和监控优化数据传输。

**AI_Comments:** 该论文的创新之处在于连接了传统的数据管理系统 (Rucio) 和现代软件定义网络 (SDN) 能力 (SENSE)，以优化大规模科学数据传输。这对于需要高效可靠地在全球网格间移动的高能物理数据至关重要。DMM 对基于优先级的带宽分配和精细监控的关注，对于管理复杂、大容量的数据流具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了利用现有的全球 LHC 计算网格基础设施，实现 SDN 驱动的高能物理数据流，DMM 被开发为连接 CERN 的数据管理软件 Rucio 与 ESNet 的软件定义网络 (SDN) 服务 SENSE 的接口。

**Method:** DMM 是一个原型接口，其关键特性包括基于传输优先级的带宽分配，以及通过利用主机级别（网络接口）吞吐量指标和传输工具（FTS）数据传输作业级别指标，对性能不佳的流进行精细监控。

**Result:** DMM 实现了 SDN 驱动的高能物理数据流，通过基于传输优先级的带宽分配优化了网络使用，并提供了对数据流的精细监控。

**Conclusion:** 本文详细介绍了 DMM 的设计和实现，DMM 是一个原型接口，通过集成 Rucio 和 SENSE，实现了 SDN 控制的高能物理数据流，从而提高了数据传输效率和监控能力。

> **ai_Abstract:** 数据移动管理器 (DMM) 是一个原型接口，旨在实现 CERN 的 Rucio 数据管理软件与 ESNet 的 SENSE SDN 服务之间的互操作。它促进了全球 LHC 计算网格内 SDN 驱动的高能物理数据流。DMM 通过基于优先级的带宽分配来优化网络使用，并通过收集主机级别和传输工具指标，对数据流进行详细监控以解决性能不佳的问题。本文详细描述了其设计和实现。

> **摘要翻译:** 数据移动管理器 (DMM) 是一个原型接口，它将 CERN 的数据管理软件 Rucio 与 ESNet 的软件定义网络 (SDN) 服务 SENSE 连接起来。它使得使用现有全球 LHC 计算网格基础设施的 SDN 驱动的高能物理数据流成为可能。DMM 的一个关键特性是基于传输优先级的带宽分配，优化了网络使用。此外，它通过利用端到端数据流监控来提供对性能不佳流的精细监控。这是通过访问主机级别（网络接口）吞吐量指标和传输工具（FTS）数据传输作业级别指标来实现的。本文详细介绍了 DMM 的设计和实现。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [645] [Quality-of-Service Aware LLM Routing for Edge Computing with Multiple Experts](https://arxiv.org/abs/2508.00234)
> *面向多专家的边缘计算中服务质量感知的LLM路由*

*Jin Yang, Qiong Wu, Zhiying Feng, Zhi Zhou, Deke Guo, Xu Chen* | **Category: cs.NI, cs.AI, cs.DC, cs.MA** | **Updated: 2025-08-01**

**Keywords:** LLM路由, 边缘计算, 服务质量, 深度强化学习, 异构图注意力网络

**Comment:** Accepted by IEEE Transactions on Mobile Computing

> **TL;DR:** 本文提出了一种基于深度强化学习的服务质量感知LLM路由框架，用于边缘计算环境，以解决现有路由算法在异构性、请求干扰和动态工作负载下无法维持长期稳定服务质量的问题。

**AI_Comments:** 该论文通过引入深度强化学习来解决边缘计算中LLM服务的QoS感知路由问题，具有创新性。其动态状态抽象技术和定制奖励函数设计，有效地应对了边缘LLM环境的复杂性和动态性，对于提升边缘AI服务的性能和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 云端大型语言模型（LLMs）服务存在高延迟、响应不稳定和隐私问题。为提升实时响应和数据隐私，LLMs常部署在网络边缘。然而，如何将用户请求路由到合适的边缘LLM专家以确保可接受的服务质量（QoS）是一个关键问题。现有路由算法未能同时解决LLM服务的异构性、请求间的干扰以及维持长期稳定QoS所需的动态工作负载。

**Method:** 本文提出了一种新颖的基于深度强化学习（DRL）的服务质量感知LLM路由框架。该框架利用动态状态抽象技术，通过异构图注意力网络（HAN）紧凑表示全局状态特征。此外，引入了动作影响估计器和定制的奖励函数，以指导DRL智能体最大化QoS并防止延迟违规。

**Result:** 在泊松和真实世界工作负载上的大量实验表明，与现有基线相比，所提出的算法显著提高了平均服务质量和计算资源效率。

**Conclusion:** 本文提出的基于深度强化学习的服务质量感知LLM路由框架，通过有效处理LLM服务的异构性、请求干扰和动态工作负载，显著提升了边缘计算环境中LLM服务的服务质量和资源效率。

> **ai_Abstract:** 本文针对边缘计算环境下大型语言模型（LLM）服务面临的高延迟、不稳定响应和隐私问题，提出了一种新颖的基于深度强化学习（DRL）的服务质量（QoS）感知LLM路由框架。该框架旨在将移动和物联网设备的用户请求有效路由到多专家边缘LLM服务，以确保可接受的QoS。通过引入基于异构图注意力网络（HAN）的动态状态抽象技术，以及动作影响估计器和定制奖励函数，该方法能够应对LLM服务的异构性、请求干扰和动态工作负载。实验结果表明，该算法在提高平均QoS和计算资源效率方面优于现有基线。

> **摘要翻译:** 大型语言模型（LLMs）展现出卓越的能力，导致用户对LLM服务的需求显著增加。然而，基于云的LLM服务通常存在高延迟、响应不稳定和隐私问题。因此，多个LLMs通常部署在网络边缘，以提高实时响应并保护数据隐私，特别是对于许多新兴的智能移动和物联网应用。鉴于LLM服务响应质量和延迟的差异，一个关键问题是如何将来自移动和物联网设备的用户请求路由到合适的LLM服务（即边缘LLM专家）以确保可接受的服务质量（QoS）。现有的路由算法未能同时解决LLM服务的异构性、请求间的干扰以及维持长期稳定QoS所需的动态工作负载。为了应对这些挑战，本文提出了一种新颖的基于深度强化学习（DRL）的服务质量感知LLM路由框架，以实现持续高质量的LLM服务。由于全局状态的动态性，我们提出了一种动态状态抽象技术，通过异构图注意力网络（HAN）紧凑表示全局状态特征。此外，我们引入了动作影响估计器和定制的奖励函数，以指导DRL智能体最大化QoS并防止延迟违规。在泊松和真实世界工作负载上的大量实验表明，我们提出的算法与现有基线相比，显著提高了平均QoS和计算资源效率。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csos'></a>
## cs.OS 

### [658] [Composable OS Kernel Architectures for Autonomous Intelligence](https://arxiv.org/abs/2508.00604)
> *可组合操作系统内核架构用于自主智能*

*Rajpreet Singh, Vidhi Kothari* | **Category: cs.OS, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 可组合内核, AI原生操作系统, 神经符号设计, 智能系统, Linux内核

**Comment:** 8 pages

> **TL;DR:** 本研究提出一种新的操作系统内核架构，将内核从静态资源管理器转变为适应性强、与AI集成的平台，以支持智能系统在边缘设备、云基础设施和嵌入式实时环境中的应用。

**AI_Comments:** 这篇论文提出了一种前瞻性的操作系统内核设计，旨在解决AI系统日益增长的计算需求。其创新之处在于将AI能力深度集成到内核层面，而非仅仅作为应用层面的优化。特别是将可加载内核模块视为AI计算单元和引入神经符号内核设计，展现了对未来异构和智能计算环境的深刻理解。如果能在实际性能提升和复杂性管理方面提供更多细节，将进一步增强其影响力。

<details>
  <summary>Details</summary>

**Motivation:** 随着智能系统渗透到边缘设备、云基础设施和嵌入式实时环境，需要一种新的操作系统内核架构来支持这些智能系统，将内核从静态资源管理器转变为适应性强、与AI集成的平台。

**Method:** 本研究提出了新的操作系统内核架构，主要贡献包括：1) 将可加载内核模块（LKMs）视为面向AI的计算单元，用于内核空间中的快速感知和认知处理；2) 将Linux内核扩展为AI原生环境，内置深度学习推理、浮点加速和实时自适应调度，以实现高效的机器学习工作负载；3) 引入神经符号内核设计，利用范畴论和同伦类型论来统一操作系统内部的符号推理和可微分逻辑。

**Result:** 这些方法共同使操作系统能够主动预测和适应自主智能应用程序的认知需求。

**Conclusion:** 通过将可加载内核模块视为AI计算单元、扩展Linux内核以支持AI原生环境以及引入神经符号内核设计，本研究提出的可组合OS内核架构能够使操作系统主动适应自主智能应用程序的需求。

> **ai_Abstract:** 本研究提出一种新的可组合操作系统内核架构，旨在将传统静态资源管理器转变为适应性强、AI集成的平台，以支持在边缘、云和嵌入式环境中运行的智能系统。核心贡献包括将可加载内核模块用作AI计算单元，将Linux内核扩展为AI原生环境（支持深度学习推理、浮点加速和实时调度），以及引入基于范畴论和同伦类型论的神经符号内核设计。这些创新共同使操作系统能够主动响应自主智能应用的认知需求。

> **摘要翻译:** 随着智能系统渗透到边缘设备、云基础设施和嵌入式实时环境，本研究提出一种新的操作系统内核架构用于智能系统，将内核从静态资源管理器转变为适应性强、与AI集成的平台。主要贡献包括：(1) 将可加载内核模块（LKMs）视为面向AI的计算单元，用于内核空间中的快速感知和认知处理；(2) 将Linux内核扩展为AI原生环境，内置深度学习推理、浮点加速和实时自适应调度，以实现高效的机器学习工作负载；(3) 引入神经符号内核设计，利用范畴论和同伦类型论来统一操作系统内部的符号推理和可微分逻辑。这些方法共同使操作系统能够主动预测和适应自主智能应用程序的认知需求。

</details>

[⬆️ 返回分类顶部](#csos) | [⬆️ 返回总目录](#toc)

---

<a id='cspf'></a>
## cs.PF 

### [13] [DGEMM without FP64 Arithmetic -- using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme](https://arxiv.org/abs/2508.00441)
> *不使用FP64算术的DGEMM——利用FP64仿真和基于Ozaki方案的FP8张量核心*

*Daichi Mukunoki* | **Category: cs.PF, cs.AR, cs.MS** | **Updated: 2025-08-01**

**Keywords:** DGEMM, FP64仿真, FP8张量核心, Ozaki方案, 低精度计算

**Comment:** 

> **TL;DR:** 本研究针对最新AI硬件，重新审视Ozaki方案，通过FP8张量核心和FP64仿真实现DGEMM，并引入新的分块策略，以在缺乏或不支持FP64硬件的处理器上高效执行双精度矩阵乘法。

**AI_Comments:** 该论文的创新点在于将Ozaki方案与最新的低精度浮点张量核心（FP8/FP6）以及FP64仿真技术相结合，以解决AI硬件与科学计算之间精度需求的矛盾。这对于那些缺乏高性能FP64硬件的处理器（如某些AI加速器）实现双精度计算具有重要意义，有望在保持精度的同时提高计算效率。研究引入新的分块策略也可能进一步优化性能。

<details>
  <summary>Details</summary>

**Motivation:** 由于AI计算对低精度矩阵乘法的需求日益增长，现代处理器增强了低精度操作的性能，但这些操作难以直接用于科学计算所需的FP64精度。虽然Ozaki方案允许使用低精度操作实现FP64矩阵乘法（DGEMM），且其整数版本在某些GPU上表现优于硬件FP64，但最新硬件更倾向于增强FP8等低精度浮点运算性能而非INT8。此外，一些处理器对FP64操作支持缓慢甚至不提供支持，因此需要一种无需原生FP64硬件的高效DGEMM方法。

**Method:** 本研究重新审视了Ozaki方案中低精度浮点运算（特别是FP6和FP8张量核心）的利用。对于不支持或慢速支持FP64操作的处理器，考虑使用基于整数算术的FP64仿真。此外，还研究了一种新的分块策略。

**Result:** 通过在Blackwell架构GPU上评估使用FP8张量核心和FP64仿真的DGEMM性能，证明了这些方法的有效性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在解决当前AI硬件侧重低精度浮点运算（如FP8）而原生FP64性能不足或缺失的问题，提出了一种在不依赖原生FP64算术的情况下实现DGEMM（双精度通用矩阵乘法）的方法。该方法基于Ozaki方案，利用最新的FP6和FP8张量核心进行低精度浮点运算，并结合基于整数算术的FP64仿真。文章还探讨了一种新的分块策略，并通过在Blackwell架构GPU上对使用FP8张量核心和FP64仿真的DGEMM性能进行评估，验证了所提方法的有效性。

> **摘要翻译:** 由于AI计算需要低精度矩阵乘法，随着AI计算需求的增长，增强这些操作性能的处理器也越来越多。然而，直接将这些操作用于科学计算是困难的。Ozaki等人于2012年提出的精确矩阵乘法方法——Ozaki方案，能够使用FP16等低精度浮点运算实现FP64矩阵乘法（DGEMM）。该方法随后被扩展到利用整数算术。与基于浮点的方法相比，使用整数操作降低了计算成本。在具有快速INT8张量核心的GPU上，它在AI工作负载方面也表现出比硬件FP64操作更高的性能。然而，最新的硬件倾向于增强FP8等低精度浮点操作性能，而非INT8。本研究考虑到最新的AI硬件，重新审视了Ozaki方案中低精度浮点操作的利用。具体来说，我们考虑使用FP6和FP8张量核心。此外，对于支持非常慢的FP64操作或根本不支持的处理器，我们考虑使用基于整数算术的FP64仿真。我们还研究了一种新的分块策略。我们通过评估在Blackwell架构GPU上使用FP8张量核心和FP64仿真进行DGEMM的性能，证明了这些方法的有效性。

</details>

[⬆️ 返回分类顶部](#cspf) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [11] [Semantic Subtyping for Maps in Erlang](https://arxiv.org/abs/2508.00482)
> *Erlang中映射的语义子类型*

*Erdem Yildirim, Albert Schimpf, Stefan Wehr, Annette Bieniusa* | **Category: cs.PL** | **Updated: 2025-08-01**

**Keywords:** 语义子类型, Erlang, 映射类型, 集合论模型, 参数化类型

**Comment:** 

> **TL;DR:** 本文构建了一个基于集合论的类型模型，并在其中定义了Erlang中映射类型的语义子类型关系，其新颖之处在于参数化映射类型的子类型定义。

**AI_Comments:** 本文的创新之处在于为Erlang中的参数化映射类型定义了语义子类型，这对于提高Erlang程序的类型安全性和可靠性具有潜在的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 为Erlang中的映射类型构建一个语义子类型系统。

**Method:** 本文构建了一个包含类型变量、基本类型、集合论类型和映射类型的集合论类型模型。该类型模型用于定义基于集合包含的语义子类型关系。

**Result:** 成功定义了参数化映射类型的子类型。

**Conclusion:** 论文成功地为Erlang中的映射类型定义了基于集合论的语义子类型关系，特别是在参数化映射类型上的子类型定义是其创新点。

> **ai_Abstract:** 本文构建了一个包含多种类型的集合论模型，并利用该模型为Erlang中的映射类型定义了基于集合包含的语义子类型关系。该工作的创新点在于对参数化映射类型子类型的定义。

> **摘要翻译:** 在本文中，我们将构建一个具有类型变量、基本类型、集合论类型和映射类型的集合论类型模型。映射类型的语法涵盖了Erlang中所有可用的映射类型。该类型模型用于定义基于集合包含的语义子类型关系。这项工作的新颖之处在于参数化映射类型上的子类型定义。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [83] [Float Self-Tagging](https://arxiv.org/abs/2411.16544)
> *浮点数自标记*

*Olivier Melançon, Manuel Serrano, Marc Feeley* | **Category: cs.PL, D.3.4** | **Updated: 2025-08-01**

**Keywords:** 自标记, 浮点数, 类型标记, 动态语言, 性能优化

**Comment:** 

> **TL;DR:** 本文提出了一种名为“自标记”的新方法，通过可逆的位转换将浮点数映射到包含正确类型信息的标记值，从而避免了大多数浮点数的堆分配，并提供了良好的执行速度。

**AI_Comments:** 本文提出了一种创新的“自标记”方法，通过巧妙的位转换技术，在单个机器字内同时编码浮点数值和类型信息，有效解决了动态语言中浮点数标记的效率瓶颈。其创新点在于利用了浮点数分布的非均匀性，避免了大量堆分配，显著提升了性能。这项工作对于优化动态语言运行时系统中的数值处理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 动态和多态语言需要将类型信息附加到运行时对象，这使得高效实现IEEE754浮点数变得困难，因为其格式没有易于访问的空间来存储类型信息。现有的主要浮点数编码方法（标记指针、NaN-boxing和NuN-boxing）都存在缺点，如堆分配或额外的运行时开销。

**Method:** 本文引入了一种名为“自标记”的新对象标记方法。该方法使用可逆的位转换，将浮点数映射到在其位模式中包含正确类型信息的标记值，从而在单个机器字中叠加其值和类型信息。自标记利用了实践中浮点数非均匀分布的特点，以避免最常遇到的浮点数的堆分配。

**Result:** 自标记的变体在两种不同的Scheme编译器中实现，并在四种微体系结构上进行了评估。实验表明，在实践中，该方法消除了几乎所有浮点数的堆分配，并在Scheme中为浮点密集型基准测试提供了良好的执行速度，同时对其他基准测试的性能影响可忽略不计。

**Conclusion:** 自标记是标记指针、NaN-boxing和NuN-boxing的一种有吸引力的替代方案，它能有效解决动态语言中浮点数标记的效率问题，并提供良好的性能。

> **ai_Abstract:** 本文提出了一种名为“自标记”的新方法，旨在解决动态语言中IEEE754浮点数因需要附加类型信息而导致的低效问题。该方法通过可逆的位转换，将浮点数的值和类型信息叠加在一个机器字中，从而生成带有正确类型信息的标记值。自标记利用了浮点数在实际应用中分布不均的特点，有效避免了对大多数浮点数进行堆分配。在两种Scheme编译器上的实验表明，自标记显著减少了浮点数的堆分配，并为浮点密集型任务提供了良好的执行速度，同时对其他任务的性能影响微乎其微，证明了其作为现有标记方法的有效替代方案的潜力。

> **摘要翻译:** 动态和多态语言将类型等信息附加到运行时对象，因此会调整值的内存布局以包含这些信息的空间。这使得高效实现IEEE754浮点数变得困难，因为这种格式没有留下一个易于访问的空间来存储类型信息。目前使用的三种主要浮点数编码方式：标记指针、NaN-boxing和NuN-boxing都存在缺点。标记指针需要对所有浮点对象进行堆分配，而NaN/NuN-boxing会给类型检查和其他对象的处理带来额外的运行时开销。
本文引入了自标记，这是一种新的对象标记方法，它使用可逆的位转换将浮点数映射到标记值，这些标记值在其位模式的正确位置包含正确的类型信息，将它们的值和类型信息叠加在一个机器字中。这种转换只能将所有浮点数的一个子集映射到正确类型的标记值，因此自标记利用了实践中浮点数非均匀分布的特点，以避免最常遇到的浮点数的堆分配。
自标记的变体在两种不同的Scheme编译器中实现，并在四种微体系结构上进行了评估，以评估其性能并将其与标记指针、NaN-boxing和NuN-boxing进行比较。实验表明，在实践中，该方法消除了几乎所有浮点数的堆分配，并在Scheme中为浮点密集型基准测试提供了良好的执行速度，同时对其他基准测试的性能影响可忽略不计，使其成为标记指针以及NaN-boxing和NuN-boxing的一种有吸引力的替代方案。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [107] [Place Capability Graphs: A General-Purpose Model of Rust's Ownership and Borrowing Guarantees](https://arxiv.org/abs/2503.21691)
> *位置能力图：Rust所有权和借用保证的通用模型*

*Zachary Grannan, Aurel Bílý, Jonáš Fiala, Jasper Geer, Markus de Medeiros, Peter Müller, Alexander J. Summers* | **Category: cs.PL** | **Updated: 2025-08-01**

**Keywords:** Rust, 类型系统, 所有权, 借用, 程序分析, 验证, 位置能力图

**Comment:** 

> **TL;DR:** 提出了一种名为“位置能力图”的新模型，解决了现有Rust类型系统分析工具的局限性，能支持绝大多数真实Rust代码，并适用于验证和程序分析工具。

**AI_Comments:** 这篇论文的创新点在于提出了“位置能力图”这一通用模型，它克服了现有Rust类型系统分析工具的局限性，能够更精确地建模Rust的复杂特性（如借用、复合类型、函数签名和循环）。其重要性在于为Rust程序的验证和分析提供了一个更坚实、更普适的基础，有望显著提升相关工具的性能和适用范围。支持97%的真实Rust函数是一个非常强有力的证明。

<details>
  <summary>Details</summary>

**Motivation:** Rust的类型系统提供了丰富的保证，但现有模型在精确建模Rust借用、复合类型、函数签名和循环方面存在局限性，难以完全理解、提取和利用这些保证。

**Method:** 提出了一种名为“位置能力图”（Place Capability Graphs）的Rust类型检查新模型，该模型克服了现有局限性，可以直接从Rust编译器的程序化表示和分析中计算得出。

**Result:** 该模型支持最流行的公共crates中超过97%的Rust函数，并通过开发现有Flowistry和Prusti工具的有前景的新原型版本，证明其作为验证和程序分析工具通用基础的适用性。

**Conclusion:** 位置能力图模型为理解和利用Rust类型系统提供的保证提供了一个通用且精确的基础，能够有效支持现有的验证和程序分析工具，并有望推动该领域的发展。

> **ai_Abstract:** 本文提出了一种名为“位置能力图”（Place Capability Graphs）的Rust类型检查新模型，旨在解决现有Rust类型系统分析工具在精确建模和支持真实世界代码方面的局限性。该模型可以直接从Rust编译器获取信息，并被证明能够支持超过97%的流行Rust函数。作者通过开发Flowistry和Prusti工具的原型版本，展示了其作为通用验证和程序分析基础的潜力。

> **摘要翻译:** Rust新颖的类型系统因其在控制别名和可变性方面提供的丰富保证，已成为验证和程序分析工具的诱人目标。然而，完全理解、提取和利用这些保证是微妙且具有挑战性的：现有的Rust类型检查模型要么支持与真实Rust代码脱节的较小理想化语言，要么在精确建模Rust借用、存储它们的复合类型、函数签名和循环方面存在严重局限性。在本文中，我们提出了一种名为“位置能力图”（Place Capability Graphs）的Rust类型检查新模型，该模型消除了这些局限性，并且可以直接从Rust编译器自身的程序化表示和分析中计算得出。我们证明了我们的模型支持最流行的公共crates中超过97%的Rust函数，并通过开发现有Flowistry和Prusti工具的有前景的新原型版本，展示了其作为验证和程序分析工具通用基础的适用性。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [287] [Modelling Program Spaces in Program Synthesis with Constraints](https://arxiv.org/abs/2508.00005)
> *在程序合成中使用约束建模程序空间*

*Tilman Hinnerichs, Bart Swinkels, Jaap de Jong, Reuben Gardos Reid, Tudor Magirescu, Neil Yorke-Smith, Sebastijan Dumancic* | **Category: cs.PL, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 程序合成, 语法约束, 程序空间建模, 约束求解, BART

**Comment:** 

> **TL;DR:** 本文利用语法约束来建模程序空间，并引入BART求解器，结果显示该方法能显著减少程序空间并加快枚举时间。

**AI_Comments:** 本文的创新之处在于将语法约束应用于程序空间建模，而非仅仅语义约束，从而能够更有效地剪枝搜索空间。引入的BART求解器进一步提升了效率。这项工作对于解决程序合成中的组合爆炸问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 程序合成的核心挑战在于处理巨大的可能程序空间，现有的约束求解器主要用于表达程序语义，但未能有效移除不期望的程序。

**Method:** 本文利用语法约束来建模程序空间，不仅定义了可行的解，还定义了可能有用的解。为此，引入了一个名为BART的求解器，用于高效传播和求解这些约束。

**Result:** 评估结果显示，这些约束能够消除高达99%的程序空间，并且建模程序空间显著减少了枚举时间。

**Conclusion:** 通过利用语法约束建模程序空间，可以有效缩小搜索范围并提高程序合成的效率。

> **ai_Abstract:** 本文针对程序合成中程序空间过大的挑战，提出了一种利用语法约束来建模程序空间的方法。通过定义不仅可行而且有用的解，并引入了高效的BART求解器来处理这些约束。实验结果表明，该方法能有效消除高达99%的程序空间，显著缩短了程序枚举时间。

> **摘要翻译:** 程序合成中的一个核心挑战是驯服巨大的可能程序空间。由于程序合成本质上是一种组合搜索，社区一直在寻求利用强大的组合约束求解器。在这里，约束被用来表达程序语义，但不是作为一种潜在的强大工具来移除不期望的程序。最近的归纳逻辑编程方法引入了对要合成程序的语法的约束。这些语法约束允许在不执行程序的情况下检查和传播约束，因此适用于任意运算符。在这项工作中，我们利用语法约束来建模程序空间，不仅定义了可行的解，还定义了可能有用的解。为了演示这个想法，我们引入了BART，一个能够高效传播和求解这些约束的求解器。我们在程序空间枚举任务上评估了BART，发现这些约束消除了高达99%的程序空间，并且建模程序空间显著减少了枚举时间。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [538] [Towards a unified framework for programming paradigms: A systematic review of classification formalisms and methodological foundations](https://arxiv.org/abs/2508.00534)
> *迈向编程范式统一框架：分类形式和方法论基础的系统综述*

*Mikel Vandeloise* | **Category: cs.PL, cs.CL, D.3.2; F.3.2; D.3.1** | **Updated: 2025-08-01**

**Keywords:** 编程范式, 系统综述, 分类形式, 组合重构, 类型论, 范畴论, UTP

**Comment:** Preprint submitted to the Journal of Object Technology on July 29,
  2025. Data available upon request until peer-review is completed

> **TL;DR:** 多范式语言挑战传统分类。本综述发现现有分类法有限，并识别出一种转向利用类型论、范畴论和UTP等数学框架进行组合式、重构性方法以统一编程范式的重要趋势。

**AI_Comments:** 这篇论文通过系统综述方法，解决了计算机科学中一个基本问题——编程范式的分类和形式化。它识别出从传统分类转向基于高级数学理论（类型论、范畴论、UTP）的组合式、重构框架的重要转变，这对未来的语言设计和软件工程至关重要。论文提出的统一研究议程为该领域指明了关键方向。

<details>
  <summary>Details</summary>

**Motivation:** 多范式语言的兴起挑战了传统的分类方法，导致了互操作性缺陷等实际的软件工程问题。本文旨在评估分类形式的现状及其局限性，并识别概念原语和数学框架，以实现更强大、更具重构性的方法。

**Method:** 本文采用系统文献综述（SLR）的方法，综合了74项主要研究，以绘制编程范式形式化基础的图谱。通过对现有文献的分析，识别了现有分类法的局限性，并揭示了新的方法趋势。

**Result:** 现有分类法缺乏概念粒度、统一的形式基础，并且难以处理混合语言。分析结果揭示了范式组合重构的强烈趋同，该方法识别了一组最小的正交原子原语，并利用类型理论、范畴论和编程统一理论（UTP）等数学框架，以形式化地保证其组合性质。

**Conclusion:** 文献反映了一种重大的思想转变，即从传统分类转向有前途的形式化、重构框架。本综述描绘了这一演变，并提出了其统一的研究议程。

> **ai_Abstract:** 本系统文献综述旨在解决多范式语言对传统编程范式分类带来的挑战。它评估了现有分类形式，发现它们在粒度上和统一形式基础上存在局限性，特别是对于混合语言。本综述识别出一种重要的趋势，即转向范式的组合重构，利用最小的正交原语和类型理论、范畴论以及UTP等数学框架，以实现组合性质的形式化保证。论文总结认为，该领域正在向这些形式化、重构框架转变，并提出了其统一的研究议程。

> **摘要翻译:** 多范式语言的兴起挑战了传统的分类方法，导致了互操作性缺陷等实际的软件工程问题。本系统文献综述（SLR）旨在绘制编程范式形式化基础的图谱。我们的目标是双重的：（1）评估分类形式的现状及其局限性，以及（2）识别概念原语和数学框架，以实现更强大、更具重构性的方法。
基于对74项主要研究的综合分析，我们发现现有分类法缺乏概念粒度、统一的形式基础，并且难以处理混合语言。作为回应，我们的分析揭示了范式组合重构的强烈趋同。这种方法识别了一组最小的正交原子原语，并利用数学框架，主要是类型理论、范畴论和编程统一理论（UTP），以形式化地保证其组合性质。
我们得出结论，文献反映了一种重大的思想转变，即从分类转向这些有前途的形式化、重构框架。本综述提供了这种演变的图谱，并提出了其统一的研究议程。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [599] [Extended Abstract: Mutable Objects with Several Implementations](https://arxiv.org/abs/2508.00016)
> *扩展摘要：具有多种实现的Mutable对象*

*Matt Kaufmann, Yahya Sohail, Warren A. Hunt Jr* | **Category: cs.PL, cs.LO** | **Updated: 2025-07-25**

**Keywords:** ACL2, attach-stobj, 可变对象, 重新认证, 可执行操作

**Comment:** In Proceedings ACL2 2025, arXiv:2507.18567

> **TL;DR:** ACL2的attach-stobj新特性允许可变对象拥有不同的可执行操作，且无需重新认证。

**AI_Comments:** attach-stobj特性似乎是ACL2的一项重要增强，解决了修改stobj可执行操作时重新认证的实际开销问题。这可能提高了基于ACL2开发的维护性和灵活性。其创新之处在于，在不破坏现有认证的情况下实现了这种灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 该特性旨在支持给定抽象stobj的不同可执行操作，同时避免重新认证引入该stobj或其相关定理的书籍。

**Method:** 本文概述了ACL2的attach-stobj特性，并提供了背景、用户级概述和一些实现说明。

**Result:** attach-stobj特性支持对给定抽象stobj进行不同的可执行操作，且无需重新认证定义该stobj或其相关定理的书籍。

**Conclusion:** ACL2 8.6版本中引入的attach-stobj特性使得stobj的实现更加灵活，同时避免了重新认证的开销，这对于ACL2的用户来说是一个重要的改进。

> **ai_Abstract:** 这篇扩展摘要介绍了ACL2 8.6版本中的新特性attach-stobj，该特性允许可变对象（stobj）拥有多种可执行操作。其主要优点是，实现这种灵活性无需对stobj的定义书籍或相关定理进行重新认证。文章还提供了背景、用户概述和实现细节。

> **摘要翻译:** 这份扩展摘要概述了ACL2的一个特性，即attach-stobj，该特性首次出现在ACL2 8.6版本（2024年10月）。该特性支持给定抽象stobj的不同可执行操作，而无需重新认证引入该stobj或其相关定理的书籍。本文提供了背景知识、用户级概述以及一些实现说明。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [690] [From Provable Correctness to Probabilistic Generation: A Comparative Review of Program Synthesis Paradigms](https://arxiv.org/abs/2508.00013)
> *从可证明的正确性到概率生成：程序合成范式的比较性综述*

*Zurabi Kobaladze, Anna Arnania, Tamar Sanikidze* | **Category: cs.PL, I.2.6; F.1.1** | **Updated: 2025-07-21**

**Keywords:** 程序合成, 比较性综述, 神经模型, 神经符号, 代码生成

**Comment:** 78 pages. Undergraduate thesis project submitted in partial
  fulfillment of the requirements for the Bachelor's degree in Computer Science
  at Kutaisi International University

> **TL;DR:** 本文对程序合成的主要范式进行了比较性综述，追溯了其从基于形式逻辑的方法到使用大规模神经模型的最新进展的演变，并探讨了未来方向。

**AI_Comments:** 这篇论文通过对程序合成领域主要范式的全面比较性综述，提供了宝贵的历史视角和当前趋势分析。其创新之处在于系统地梳理了从传统形式化方法到新兴神经符号方法的演变，并深入分析了不同范式间的权衡。这对于理解程序合成的进展、挑战以及未来发展方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在对程序合成领域的主要范式进行比较性文献综述，追溯其从基于形式逻辑的方法到使用大规模神经模型的最新进展的演变。

**Method:** 本文对程序合成领域的五种关键方法进行了考察：基于逻辑（演绎）的合成、归纳（基于示例）的合成、基于草图/模式的合成、基于大型语言模型的合成以及神经符号混合方法。对于每种方法，论文分析了其基本原理、著名系统和实际应用，并强调了正确性保证、规范要求、搜索复杂性和表达能力之间的权衡。

**Result:** 通过回顾从KIDS和Coq等形式化验证的合成工具到Codex等从自然语言生成概率代码的数据驱动模型的发展，本文提供了一个关于进展和持续挑战的全面叙述。

**Conclusion:** 本文强调了从符号方法到混合神经符号方法的转变，并概述了可靠和可扩展的程序合成的未来方向。

> **ai_Abstract:** 本论文对程序合成——从高级规范自动生成可执行代码——这一计算机科学的核心目标进行了比较性文献综述。文章追溯了该领域从基于形式逻辑的方法到使用大规模神经模型的最新进展的演变，并考察了五种关键方法：基于逻辑的、归纳的、基于草图/模式的、基于大型语言模型的以及神经符号混合方法。论文分析了每种方法的基本原理、系统、应用及其在正确性保证、规范要求、搜索复杂性和表达能力方面的权衡，提供了关于进展和挑战的全面叙述。该工作强调了向神经符号方法的转变，并展望了可靠和可扩展程序合成的未来。

> **摘要翻译:** 程序合成——从高级规范自动生成可执行代码——五十多年来一直是计算机科学的核心目标。本论文对塑造该领域的主要范式进行了比较性文献综述，追溯了其从基于形式逻辑的方法到使用大规模神经模型的最新进展的演变。我们考察了五种关键方法：基于逻辑（演绎）的合成、归纳（基于示例）的合成、基于草图/模式的合成、基于大型语言模型的合成以及神经符号混合方法。对于每种方法，我们分析了其基本原理、著名系统和实际应用，并强调了正确性保证、规范要求、搜索复杂性和表达能力之间的权衡。通过回顾从KIDS和Coq等形式化验证的合成工具到Codex等从自然语言生成概率代码的数据驱动模型的发展，我们提供了一个关于进展和持续挑战的全面叙述。这项工作强调了从符号方法到混合神经符号方法的转变，并概述了可靠和可扩展的程序合成的未来方向。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [708] [Automated Type Annotation in Python Using Large Language Models](https://arxiv.org/abs/2508.00422)
> *使用大型语言模型在Python中自动进行类型注解*

*Varun Bharti, Shashwat Jha, Dhruv Kumar, Pankaj Jalote* | **Category: cs.PL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 类型注解, Python, 大型语言模型, 自动化, Mypy

**Comment:** Under Review

> **TL;DR:** 本研究探索使用大型语言模型（LLMs）在Python中自动生成类型注解，并开发了一个“生成-检查-修复”的流水线。实验证明，未经特定微调的通用和推理优化型LLMs能有效生成一致的类型注解，其表现与需要大量标注数据的传统深度学习技术相当。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型应用于Python的类型注解自动化，并设计了一个实用的“生成-检查-修复”流水线。其重要性在于证明了LLMs在无需特定微调的情况下，即可在代码理解和生成方面达到与传统深度学习方法相媲美的效果，且避免了对大量标注数据集的依赖。这为未来代码自动化工具的开发提供了新的思路，尤其是在处理复杂或低资源语言方面。该流水线的可扩展性也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** Python中的类型注解有助于提高代码可维护性和错误检测能力，但手动添加注解容易出错且耗时。传统的自动化方法（如静态分析、机器学习和深度学习）存在类型词汇受限、行为过度近似以及依赖大量标注数据集等局限性。

**Method:** 本研究探索使用大型语言模型（LLMs）来生成Python类型注解。开发了一个“生成-检查-修复”的流水线：LLM根据具体语法树（CST）表示提出注解，然后由静态类型检查器（Mypy）验证，任何错误都会反馈用于迭代修正。研究在ManyTypes4Py基准测试的6000个代码片段上评估了四种LLM变体：GPT 4oMini、GPT 4.1mini（通用型）以及O3Mini、O4Mini（推理优化型）。

**Result:** 在一致性方面（Mypy报告无错误），GPT 4oMini的成功率为65.9%，而GPT 4.1mini、O3Mini和O4Mini均达到了约88.6%的一致性。在注解质量方面（精确匹配和基本类型匹配准确率），GPT 4.1mini和O3Mini表现最佳，分别达到70.5%的精确匹配和79.1%的基本类型准确率，平均仅需不到一次修复迭代。

**Conclusion:** 研究结果表明，通用型和推理优化型LLMs无需任何任务特定的微调或额外训练，就能有效地生成一致的类型注解。它们的性能与需要大量标注数据集进行训练的传统深度学习技术具有竞争力。尽管本工作专注于Python，但该流水线可扩展到其他可选类型命令式语言，如Ruby。

> **ai_Abstract:** 本研究提出了一种使用大型语言模型（LLMs）在Python中自动生成类型注解的方法，旨在解决手动注解的繁琐和传统自动化方法的局限性。核心是一个“生成-检查-修复”的流水线，利用LLM基于CST提出注解，并通过Mypy进行验证和迭代修正。实验在6000个代码片段上评估了四种LLM变体，结果显示，未经特定微调的通用和推理优化型LLMs在类型注解的一致性和准确性上表现出色，与需要大量训练数据的传统深度学习技术具有竞争力。该方法具有推广到其他编程语言的潜力。

> **摘要翻译:** Python中的类型注解可以增强代码的可维护性和错误检测。然而，手动生成这些注解容易出错且需要额外的工作量。传统的自动化方法，如静态分析、机器学习和深度学习，在类型词汇受限、行为过度近似以及依赖大型标注数据集方面存在困难。在本研究中，我们探索使用大型语言模型（LLMs）在Python中生成类型注解。我们开发了一个“生成-检查-修复”的流水线：LLM在具体语法树（CST）表示的指导下提出注解，静态类型检查器（Mypy）对其进行验证，任何错误都会反馈以进行迭代修正。我们评估了四种LLM变体：GPT 4oMini、GPT 4.1mini（通用型）以及O3Mini、O4Mini（推理优化型），使用了来自ManyTypes4Py基准测试的6000个代码片段。我们首先测量了LLMs注解的代码片段中Mypy未报告错误的比例（即一致性结果）：GPT 4oMini在65.9%的情况下达到了一致性（34.1%不一致），而GPT 4.1mini、O3Mini和O4Mini均达到了约88.6%的一致性（约11.4%的失败）。为了测量注解质量，我们计算了所有6000个片段的精确匹配和基本类型匹配准确率：GPT 4.1mini和O3Mini表现最佳，分别实现了高达70.5%的精确匹配和79.1%的基本类型准确率，平均仅需不到一次修复迭代。我们的结果表明，通用型和推理优化型LLMs，无需任何任务特定的微调或额外训练，就可以有效地生成一致的类型注解。它们的性能与需要大量标注数据集进行训练的传统深度学习技术具有竞争力。虽然我们的工作专注于Python，但该流水线可以扩展到其他可选类型命令式语言，如Ruby。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [64] [UAV-ON: A Benchmark for Open-World Object Goal Navigation with Aerial Agents](https://arxiv.org/abs/2508.00288)
> *UAV-ON：一个面向空中智能体的开放世界目标导航基准*

*Jianqiang Xiao, Yuexuan Sun, Yixin Shao, Boxi Gan, Rongqiang Liu, Yanjing Wu, Weili Gua, Xiang Deng* | **Category: cs.RO, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 空中导航, 物体目标导航, 基准, 无人机, 具身智能

**Comment:** Accepted to ACM MM Dataset Track 2025

> **TL;DR:** UAV-ON是一个新的基准，用于空中智能体在开放世界中的物体目标导航，结果显示现有基线方法在该设置下表现不佳。

**AI_Comments:** 该论文引入了一个针对空中物体导航这一未充分探索领域的重要基准，超越了传统的基于指令的方法。语义目标和高保真环境的使用是其创新之处。基线方法表现不佳的结果突显了该问题的复杂性和重要性，为未来在鲁棒无人机自主性方面的研究铺平了道路。

<details>
  <summary>Details</summary>

**Motivation:** 空中导航在具身智能中是一项基础但未被充分探索的能力，尤其是在传统导航范式失效的大规模、非结构化环境中。现有研究大多遵循视觉与语言导航（VLN）范式，过度依赖顺序语言指令，限制了可扩展性和自主性。为弥补这一空白，本文提出了UAV-ON。

**Method:** 本文引入了UAV-ON，一个用于空中智能体在开放世界环境中进行大规模物体目标导航（ObjectNav）的基准。UAV-ON包含14个高保真度的虚幻引擎环境，具有多样化的语义区域和复杂的空间布局，涵盖城市、自然和混合使用场景。它定义了1270个带注释的目标物体，每个物体都通过实例级指令（编码类别、物理足迹和视觉描述符）进行描述，作为语义目标。为评估该基准，作者实现了几种基线方法，包括空中物体导航智能体（AOA），这是一种模块化策略，将指令语义与自我中心观测相结合，用于长距离、目标导向的探索。

**Result:** 实证结果表明，所有基线方法在这种设置下都表现不佳，凸显了空中导航和语义目标定位所带来的复合挑战。

**Conclusion:** UAV-ON旨在推动在复杂真实世界环境中，由语义目标描述驱动的可扩展无人机自主性研究。

> **ai_Abstract:** UAV-ON是一个新颖的基准，用于空中智能体在开放世界中的大规模物体目标导航。它旨在解决传统视觉与语言导航（VLN）范式对详细指令的依赖所带来的局限性，转而采用高级语义目标。该基准包含14个多样化的虚幻引擎环境和1270个带有详细实例级指令的标注物体。对包括AOA在内的基线方法进行的评估显示，现有方法在空中导航和语义目标定位方面面临显著挑战，这突显了对可扩展无人机自主性进行深入研究的必要性。

> **摘要翻译:** 空中导航是具身智能中一项基础但未被充分探索的能力，它使智能体能够在传统导航范式失效的大规模、非结构化环境中操作。然而，大多数现有研究遵循视觉与语言导航（VLN）范式，该范式严重依赖顺序语言指令，限制了其可扩展性和自主性。为了解决这一差距，我们引入了UAV-ON，一个用于空中智能体在开放世界环境中进行大规模物体目标导航（ObjectNav）的基准，其中智能体基于高级语义目标进行操作，而不像VLN那样依赖详细的指令引导。UAV-ON包含14个高保真度的虚幻引擎环境，具有多样化的语义区域和复杂的空间布局，涵盖城市、自然和混合使用场景。它定义了1270个带注释的目标物体，每个物体都通过实例级指令进行描述，编码了类别、物理足迹和视觉描述符，从而实现了基础推理。这些指令作为语义目标，为空中智能体引入了现实的模糊性和复杂的推理挑战。为了评估该基准，我们实施了几种基线方法，包括空中物体导航智能体（AOA），这是一种模块化策略，将指令语义与自我中心观测相结合，用于长距离、目标导向的探索。实证结果表明，所有基线方法在这种设置下都表现不佳，凸显了空中导航和语义目标定位所带来的复合挑战。UAV-ON旨在推动在复杂真实世界环境中，由语义目标描述驱动的可扩展无人机自主性研究。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [76] [Cooperative and Asynchronous Transformer-based Mission Planning for Heterogeneous Teams of Mobile Robots](https://arxiv.org/abs/2410.06372)
> *异构移动机器人团队的协同异步Transformer任务规划*

*Milad Farjadnasab, Shahin Sirouspour* | **Category: cs.RO, cs.AI, I.2.9; I.2.11** | **Updated: 2025-07-31**

**Keywords:** 任务规划, 异构机器人, 多智能体强化学习, Transformer, 异步决策

**Comment:** 

> **TL;DR:** 本文提出了CATMiP框架，利用多智能体强化学习和异步Transformer架构，解决了异构移动机器人团队在通信受限和计算资源有限下的协同任务规划挑战，并在模拟环境中展示了其优越的效率、可扩展性和鲁棒性。

**AI_Comments:** 这项工作通过结合Transformer架构与多智能体强化学习，为异构机器人团队在复杂和资源受限环境下的任务规划提供了新颖的解决方案。其异步训练和执行方案以及对通信中断的鲁棒性是重要的创新点，使其在实际部署中具有很高的价值。

<details>
  <summary>Details</summary>

**Motivation:** 异构移动机器人团队在通信受限和计算资源有限的情况下进行协同任务规划面临独特的挑战。

**Method:** 本文提出了协同异步Transformer任务规划 (CATMiP) 框架，该框架利用多智能体强化学习 (MARL) 来协调具有不同感知、运动和执行能力的智能体之间的分布式决策。为了有效建模异构智能体团队的异步决策，还制定了基于类的宏动作去中心化部分可观察马尔可夫决策过程 (CMacDec-POMDP)。该框架采用异步集中式训练和分布式执行方案，并通过所提出的异步多智能体Transformer (AMAT) 架构实现。

**Result:** 在2D网格世界模拟环境中对CATMiP进行了评估，并将其性能与基于规划的探索方法进行了比较。结果表明，CATMiP在效率、可扩展性以及对通信中断和输入噪声的鲁棒性方面表现出卓越的性能。

**Conclusion:** CATMiP框架在处理异构移动机器人团队的协同任务规划方面表现出巨大的潜力，特别是在资源受限和通信不稳定的真实世界系统中。

> **ai_Abstract:** 本文针对异构移动机器人团队在通信受限和计算资源有限下的协同任务规划问题，提出了CATMiP框架。该框架结合了多智能体强化学习和异步多智能体Transformer (AMAT) 架构，并引入了CMacDec-POMDP模型来处理异步决策。CATMiP采用异步集中训练和分布式执行方案，以实现模型对不同环境和团队规模的泛化能力。实验结果表明，CATMiP在效率、可扩展性以及对通信中断和噪声的鲁棒性方面优于现有方法，展现了其在实际应用中的巨大潜力。

> **摘要翻译:** 异构移动机器人团队的协同任务规划提出了一系列独特的挑战，尤其是在通信受限和计算资源有限的情况下运行。为了解决这些挑战，我们提出了协同异步Transformer任务规划 (CATMiP) 框架，该框架利用多智能体强化学习 (MARL) 来协调具有不同感知、运动和执行能力的智能体之间的分布式决策，这些智能体在偶发性自组织通信下运行。为了有效建模异构智能体团队的异步决策，还制定了基于类的宏动作去中心化部分可观察马尔可夫决策过程 (CMacDec-POMDP)。该框架采用异步集中式训练和分布式执行方案，并通过所提出的异步多智能体Transformer (AMAT) 架构实现。这种设计允许单个训练模型泛化到更大的环境，并适应不同的团队规模和组成。我们在2D网格世界模拟环境中评估了CATMiP，并将其性能与基于规划的探索方法进行了比较。结果表明，CATMiP在效率、可扩展性以及对通信中断和输入噪声的鲁棒性方面表现出卓越的性能，突显了其在真实世界异构移动机器人系统中的潜力。代码可在 https://github.com/mylad13/CATMiP 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [82] [Omni-Scan: Creating Visually-Accurate Digital Twin Object Models Using a Bimanual Robot with Handover and Gaussian Splat Merging](https://arxiv.org/abs/2508.00354)
> *Omni-Scan：使用双臂机器人通过交接和高斯溅射合并创建视觉精确的数字孪生对象模型*

*Tianshuang Qiu, Zehan Ma, Karim El-Refai, Hiya Shah, Chung Min Kim, Justin Kerr, Ken Goldberg* | **Category: cs.RO, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 3D高斯溅射, 数字孪生, 双臂机器人, 物体扫描, 缺陷检测

**Comment:** 

> **TL;DR:** Omni-Scan是一个利用双臂机器人创建360度、视觉精确的3D高斯溅射（3DGS）数字孪生模型的新流程，并在缺陷检测中实现了83%的平均准确率。

**AI_Comments:** Omni-Scan的创新之处在于其利用双臂机器人进行物体交接，有效解决了传统单臂或固定视角扫描中物体遮挡的问题，实现了真正意义上的360度全方位建模。结合先进的图像分割和光流技术以及对3DGS训练流程的改进，使得生成的数字孪生模型具有高视觉精度。其在缺陷检测中的应用展示了该技术的实际价值和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的3D物体扫描方法（如多相机阵列、精确激光扫描仪或机器人腕部安装相机）存在工作空间受限的问题，无法提供物体的全方位视图。本文旨在开发一种能生成高质量、全方位3D数字孪生模型的方法来克服这些限制。

**Method:** 本文提出了Omni-Scan流程，利用双臂机器人抓取物体并相对于固定相机进行旋转，随后通过第二个夹具重新抓取物体以暴露被第一个夹具遮挡的表面。该流程整合了DepthAnything、Segment Anything和RAFT光流模型来识别和隔离机器人夹具所持物体，并移除夹具和背景。此外，还修改了3DGS训练流程以支持带有夹具遮挡的连接数据集，从而生成对象的全方位（360度视图）模型。

**Result:** Omni-Scan被应用于零件缺陷检测，结果显示它能够以83%的平均准确率识别12种不同工业和家用物体的视觉或几何缺陷。

**Conclusion:** Omni-Scan提供了一种有效的方法，通过使用双臂机器人创建高质量、360度的3D数字孪生模型，并在缺陷检测等应用中展现出良好的准确性和实用性。

> **ai_Abstract:** 本文提出了Omni-Scan，一个利用双臂机器人创建高精度3D高斯溅射（3DGS）数字孪生模型的新流程。该系统通过机器人抓取和旋转物体，并进行夹具之间的交接，以捕获物体的全方位视图，克服了传统3D扫描工作空间受限的问题。Omni-Scan集成了DepthAnything、Segment Anything和RAFT等模型来隔离物体并移除夹具和背景，同时修改了3DGS训练流程以支持带遮挡的连接数据集。实验结果显示，Omni-Scan在12种工业和家用物体的缺陷检测中实现了83%的平均准确率，证明了其在生成视觉精确数字孪生方面的有效性。

> **摘要翻译:** 3D高斯溅射（3DGS）是源自多视图图像的3D对象模型。此类“数字孪生”对于模拟、虚拟现实、营销、机器人策略微调和零件检测非常有用。3D对象扫描通常需要多相机阵列、精密激光扫描仪或机器人腕部安装相机，这些设备的工作空间有限。我们提出了Omni-Scan，这是一个使用双臂机器人生成高质量3D高斯溅射模型的流程，该机器人用一个夹具抓取物体，并相对于固定相机旋转物体。然后，物体由第二个夹具重新抓取，以暴露被第一个夹具遮挡的表面。我们介绍了使用DepthAnything、Segment Anything以及RAFT光流模型的Omni-Scan机器人流程，以识别和隔离机器人夹具所持物体，同时移除夹具和背景。随后，我们修改了3DGS训练流程，以支持带有夹具遮挡的连接数据集，从而生成对象的全方位（360度视图）模型。我们将Omni-Scan应用于零件缺陷检测，发现它能够以83%的平均准确率识别12种不同工业和家用物体的视觉或几何缺陷。Omni-Scan 3DGS模型的交互式视频可在https://berkeleyautomation.github.io/omni-scan/找到。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [88] [CHILD (Controller for Humanoid Imitation and Live Demonstration): a Whole-Body Humanoid Teleoperation System](https://arxiv.org/abs/2508.00162)
> *CHILD（类人机器人模仿与实时演示控制器）：一种全身类人机器人遥操作系统*

*Noboru Myers, Obin Kwon, Sankalp Yamsani, Joohyung Kim* | **Category: cs.RO** | **Updated: 2025-07-31**

**Keywords:** 类人机器人, 遥操作, 全身控制, 关节级控制, 力反馈

**Comment:** 

> **TL;DR:** CHILD是一个紧凑可重构的遥操作系统，支持类人机器人的全身关节级控制，通过自适应力反馈增强操作体验，并已开源硬件设计。

**AI_Comments:** 该论文提出了一种新颖且实用的类人机器人遥操作系统CHILD，其创新点在于实现了全身关节级的控制，并采用了紧凑的可重构设计（可放入婴儿背带），极大地提升了操作的便捷性和应用场景的多样性。引入自适应力反馈是提升操作体验和安全性的重要考量。此外，开源硬件设计对于推动该领域的研究和复现具有重要意义，降低了技术门槛，促进了社区协作。

<details>
  <summary>Details</summary>

**Motivation:** 现有遥操作系统很少支持类人机器人的全身关节级遥操作，这限制了可完成任务的多样性。

**Method:** 本文提出了CHILD（类人机器人模仿与实时演示控制器），一个紧凑可重构的遥操作系统，能够对类人机器人进行关节级控制。CHILD可放入标准婴儿背带中，允许操作员控制所有四个肢体，并支持全身控制的直接关节映射和运动操作。系统还结合了自适应力反馈，以增强操作员体验并防止不安全的关节运动。

**Result:** 该系统通过在类人机器人和多个双臂系统上进行运动操作和全身控制示例，验证了其能力。

**Conclusion:** CHILD系统已通过实验验证其能力，并且硬件设计已开源，以促进可及性和可复现性。

> **ai_Abstract:** 本文介绍了一种名为CHILD（类人机器人模仿与实时演示控制器）的创新遥操作系统，旨在解决现有系统在类人机器人全身关节级遥操作方面的不足。CHILD是一个紧凑且可重构的系统，能够提供对类人机器人所有肢体的关节级控制，支持直接关节映射和运动操作。该系统设计可放入标准婴儿背带中，并融入了自适应力反馈以提升用户体验和安全性。研究人员通过在类人机器人和多臂系统上进行实验，成功验证了CHILD在运动操作和全身控制方面的能力，并已开源其硬件设计以促进更广泛的应用和研究。

> **摘要翻译:** 近年来，遥操作技术的发展已展示了机器人执行复杂操作任务的能力。然而，现有工作很少支持类人机器人的全身关节级遥操作，这限制了可完成任务的多样性。本文提出了CHILD（类人机器人模仿与实时演示控制器），一个紧凑可重构的遥操作系统，能够对类人机器人进行关节级控制。CHILD可放入标准婴儿背带中，允许操作员控制所有四个肢体，并支持全身控制的直接关节映射和运动操作。系统还结合了自适应力反馈，以增强操作员体验并防止不安全的关节运动。我们通过在类人机器人和多个双臂系统上进行运动操作和全身控制示例，验证了该系统的能力。最后，我们开源了硬件设计，以促进可及性和可复现性。更多详细信息和开源信息可在我们的项目网站获取：https://uiuckimlab.github.io/CHILD-pages。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [94] [Exploring the Adversarial Vulnerabilities of Vision-Language-Action Models in Robotics](https://arxiv.org/abs/2411.13587)
> *探索机器人中视觉-语言-动作模型的对抗性脆弱性*

*Taowen Wang, Cheng Han, James Chenhao Liang, Wenhao Yang, Dongfang Liu, Luna Xinyu Zhang, Qifan Wang, Jiebo Luo, Ruixiang Tang* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 对抗性漏洞, 视觉-语言-动作模型, 机器人, 对抗性攻击, 安全性

**Comment:** ICCV camera ready; Github:
  https://github.com/William-wAng618/roboticAttack Homepage:
  https://vlaattacker.github.io/

> **TL;DR:** 本文系统评估了机器人中视觉-语言-动作（VLA）模型的对抗性脆弱性。研究设计了针对机器人空间和功能特性的非定向与定向攻击，并引入对抗性补丁，发现VLA模型在模拟任务中任务成功率显著下降，最高达100%，揭示了当前架构的安全漏洞，强调部署前加强防御的必要性。

**AI_Comments:** 这篇论文通过系统性地评估机器人视觉-语言-动作模型的对抗性漏洞，揭示了其在安全方面的潜在风险。其创新点在于针对机器人特有的空间和功能特性设计攻击目标，并提出了一种可在物理世界中实施的对抗性补丁方法。研究结果对VLA模型在实际部署前的安全防护提供了重要警示，具有重要的实践意义，有助于推动未来机器人系统鲁棒性防御策略的发展。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言-动作（VLA）模型在机器人领域展现出变革性能力，但同时也引入了新的攻击面。因此，系统评估这些模型的鲁棒性对于确保机器人安全至关重要。

**Method:** 研究系统评估了VLA模型的鲁棒性，针对机器人执行的独特需求，设计了攻击目标。具体包括两种利用空间基础破坏机器人动作的非定向攻击目标，以及一种操纵机器人轨迹的定向攻击目标。此外，还设计了一种对抗性补丁生成方法，通过在摄像头视野中放置小型彩色补丁，在数字和物理环境中有效执行攻击。

**Result:** 评估结果显示，VLA模型在任务成功率方面出现显著下降，在一系列模拟机器人任务中最高达到了100%的降低，揭示了当前VLA架构中存在的关键安全漏洞。

**Conclusion:** 本文揭示了VLA模型的对抗性脆弱性，并提出了可操作的评估指标，从而增进了对基于VLA的机器人系统安全性的理解和提升。研究强调了在实际物理世界部署之前，持续开发强大的防御策略的必要性。

> **ai_Abstract:** 本文系统评估了机器人中视觉-语言-动作（VLA）模型的对抗性脆弱性。研究针对机器人特有的空间和功能特性，设计了两种非定向攻击和一种定向攻击目标，并开发了一种可在数字和物理环境中实施的对抗性补丁生成方法。评估结果显示，VLA模型在模拟机器人任务中的任务成功率显著下降，最高可达100%，揭示了当前VLA架构存在的严重安全漏洞。研究强调了在实际部署前，必须加强VLA机器人系统的鲁棒性防御策略。

> **摘要翻译:** 近年来，在机器人领域，视觉-语言-动作（VLA）模型已成为一种变革性的方法，通过在端到端学习框架中整合视觉和语言输入，使机器人能够执行复杂的任务。尽管VLA模型具有显著能力，但它们引入了新的攻击面。本文系统地评估了它们的鲁棒性。认识到机器人执行的独特需求，我们的攻击目标针对机器人系统固有的空间和功能特性。特别是，我们引入了两种利用空间基础来破坏机器人动作的非定向攻击目标，以及一种操纵机器人轨迹的定向攻击目标。此外，我们设计了一种对抗性补丁生成方法，通过在摄像头视野中放置一个小型、彩色的补丁，有效地在数字和物理环境中执行攻击。我们的评估揭示了任务成功率的显著下降，在一系列模拟机器人任务中最高达到100%的降低，突显了当前VLA架构中的关键安全漏洞。通过揭示这些脆弱性并提出可操作的评估指标，我们促进了对基于VLA的机器人系统安全的理解和增强，强调了在物理世界部署之前持续开发强大防御策略的必要性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [113] [Topology-Inspired Morphological Descriptor for Soft Continuum Robots](https://arxiv.org/abs/2508.00258)
> *受拓扑学启发的软连续体机器人形态描述符*

*Zhiwei Wu, Siyi Wei, Jiahao Luo, Jinhui Zhang* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 软连续体机器人, 形态描述符, 莫尔斯理论, 伪刚体模型, 形态控制

**Comment:** 

> **TL;DR:** 本文提出了一种结合伪刚体模型和莫尔斯理论的拓扑学启发的形态描述符，用于软连续体机器人的量化形态表征、分类和控制，有望提高其在医疗应用中的精度和适应性。

**AI_Comments:** 该论文的创新之处在于将拓扑学，特别是莫尔斯理论，与伪刚体模型相结合，为软连续体机器人提供了一种新颖的、定量的形态描述方法。这不仅实现了形态的离散表示和分类，还进一步扩展到形态控制，通过优化计算实现期望的拓扑特征。其重要性体现在为软机器人的精确控制和在复杂医疗环境中的应用（如微创手术）奠定了基础，有望显著提高这些机器人的适应性和操作精度。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现机器人形态的定量表征，并提高软连续体机器人在医疗应用（如微创手术和血管内介入治疗）中的精度和适应性。

**Method:** 本文通过将伪刚体（PRB）模型与莫尔斯理论相结合，提出了一种受拓扑学启发的形态描述符。该方法通过计算方向投影的临界点，实现了多模态配置的离散表示和形态分类。此外，通过将目标配置表述为优化问题来计算驱动参数，从而生成具有所需拓扑特征的平衡形状，将该描述符应用于形态控制。

**Result:** 所提出的描述符能够离散表示多模态配置并促进形态分类。该框架为软连续体机器人的定量形态描述、分类和控制提供了一种统一的方法。

**Conclusion:** 所提出的框架为软连续体机器人的定量形态描述、分类和控制提供了一种统一的方法，并有可能提高其在微创手术和血管内介入治疗等医疗应用中的精度和适应性。

> **ai_Abstract:** 本文提出了一种基于拓扑学启发的软连续体机器人形态描述符，该描述符结合了伪刚体模型和莫尔斯理论，旨在实现机器人形态的定量表征。通过分析方向投影的临界点，该描述符能够对多模态配置进行离散表示和形态分类。此外，该描述符还应用于形态控制，通过优化方法计算驱动参数以获得具有特定拓扑特征的平衡形状。该研究为软连续体机器人的形态描述、分类和控制提供了一个统一的框架，有望提升其在医疗领域的应用性能。

> **摘要翻译:** 本文提出了一种受拓扑学启发的软连续体机器人形态描述符，该描述符通过结合伪刚体（PRB）模型和莫尔斯理论，实现了机器人形态的定量表征。通过计算方向投影的临界点，所提出的描述符能够离散表示多模态配置并促进形态分类。此外，我们通过将目标配置表述为优化问题来计算生成具有所需拓扑特征的平衡形状的驱动参数，从而将该描述符应用于形态控制。所提出的框架为软连续体机器人的定量形态描述、分类和控制提供了一种统一的方法，并有可能提高其在微创手术和血管内介入治疗等医疗应用中的精度和适应性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [136] [TopoDiffuser: A Diffusion-Based Multimodal Trajectory Prediction Model with Topometric Maps](https://arxiv.org/abs/2508.00303)
> *TopoDiffuser：一种基于扩散的带拓扑度量图的多模态轨迹预测模型*

*Zehui Xu, Junhui Wang, Yongliang Shi, Chao Gao, Guyue Zhou* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 轨迹预测, 扩散模型, 拓扑度量图, 多模态, 道路依从性

**Comment:** 

> **TL;DR:** TopoDiffuser是一个基于扩散的多模态轨迹预测模型，它利用拓扑度量图生成准确、多样且符合道路几何的预测，并在KITTI基准上超越了现有技术。

**AI_Comments:** 这项工作的创新之处在于将拓扑度量图的结构信息巧妙地融入到扩散模型的去噪过程中，从而解决了传统方法中轨迹预测难以自然遵循道路几何的问题，并且避免了复杂的显式约束。其在KITTI基准上的SOTA表现和强大的几何一致性验证了其有效性。模型的多模态输入融合也增强了其鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在生成准确、多样且符合道路几何的未来运动预测，并使轨迹自然地遵循道路几何，而无需依赖显式约束。

**Method:** 引入了TopoDiffuser，一个基于扩散的多模态轨迹预测框架。它通过将拓扑度量图的结构线索嵌入到条件扩散模型的去噪过程中，从而在不依赖显式约束的情况下生成自然遵循道路几何的轨迹。一个多模态条件编码器将激光雷达观测、历史运动和路线信息融合为统一的鸟瞰图（BEV）表示。

**Result:** 在KITTI基准上的大量实验表明，TopoDiffuser优于最先进的方法，同时保持了强大的几何一致性。消融研究进一步验证了每种输入模态的贡献，以及去噪步骤和轨迹样本数量的影响。

**Conclusion:** TopoDiffuser通过将拓扑度量图集成到扩散模型中，成功实现了准确、多样且符合道路几何的轨迹预测，并在性能和几何一致性方面表现出色。

> **ai_Abstract:** 本文提出了TopoDiffuser，一个创新的基于扩散的多模态轨迹预测模型。该模型通过在条件扩散模型的去噪过程中融入拓扑度量图的结构信息，实现了无需显式约束即可生成准确、多样且自然遵循道路几何的未来轨迹。它利用多模态编码器融合激光雷达、历史运动和路线信息。在KITTI基准上的实验证明，TopoDiffuser在性能上超越了现有技术，并展现出卓越的几何一致性。

> **摘要翻译:** 本文介绍了TopoDiffuser，一个基于扩散的多模态轨迹预测框架，它结合了拓扑度量图来生成准确、多样且符合道路的未来运动预测。通过将拓扑度量图的结构线索嵌入到条件扩散模型的去噪过程中，所提出的方法能够生成自然遵循道路几何的轨迹，而无需依赖显式约束。一个多模态条件编码器将激光雷达观测、历史运动和路线信息融合为统一的鸟瞰图（BEV）表示。在KITTI基准上的大量实验表明，TopoDiffuser优于最先进的方法，同时保持了强大的几何一致性。消融研究进一步验证了每种输入模态的贡献，以及去噪步骤和轨迹样本数量的影响。为了支持未来的研究，我们公开了我们的代码：https://github.com/EI-Nav/TopoDiffuser。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [151] [TOP: Time Optimization Policy for Stable and Accurate Standing Manipulation with Humanoid Robots](https://arxiv.org/abs/2508.00355)
> *TOP：人形机器人稳定精确站立操作的时间优化策略*

*Zhenghan Chen, Haocheng Xu, Haodong Zhang, Liang Zhang, He Li, Dongqi Wang, Jiyu Yu, Yifei Yang, Zhongxiang Zhou, Rong Xiong* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 时间优化策略, 站立操作, 人形机器人, 解耦控制, 平衡

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的时间优化策略（TOP），用于训练人形机器人站立操作控制模型，通过调整上半身运动的时间轨迹，同时确保平衡、精度和时间效率。

**AI_Comments:** 该论文的创新点在于提出了通过调整上半身运动的时间轨迹来优化平衡和操作性能，而非仅仅依赖增强下半身的抗干扰能力。此外，结合运动先验和解耦控制策略，提供了一个更全面且精细的全身稳定操作解决方案，对人形机器人在复杂任务中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法要么不适合精确控制高维度上半身关节，要么难以同时确保鲁棒性和准确性，尤其是在上半身运动速度快时，这会导致机器人不稳定。

**Method:** 该方法分为三个部分：首先，利用运动先验（通过训练变分自编码器VAE）来表示上半身运动，以增强上下半身之间的协调能力。其次，将全身控制解耦为用于精度的上半身PD控制器和用于增强鲁棒稳定性的下半身RL控制器。最后，将TOP方法与解耦控制器和VAE结合训练，以减轻由快速上半身运动引起的平衡负担，这些运动会使机器人不稳定并超出下半身RL策略的能力。

**Result:** 通过仿真和真实世界实验评估了所提出方法的有效性，实验结果表明其在稳定和精确的站立操作任务中表现出优越性。

**Conclusion:** 本文提出的时间优化策略（TOP）能有效提高人形机器人在站立操作任务中的稳定性、精度和时间效率，即使在快速上半身运动的情况下也能保持平衡。

> **ai_Abstract:** 本文提出了一种名为时间优化策略（TOP）的新颖方法，旨在解决人形机器人在进行站立操作时，尤其是在上半身快速运动时，难以同时保证平衡、精度和时间效率的问题。该方法通过调整上半身运动的时间轨迹，并结合运动先验（VAE）、解耦的全身控制（上半身PD和下半身RL），来减轻因快速上半身运动导致的平衡负担。仿真和真实世界实验均验证了该方法在稳定和精确站立操作任务中的优越性。

> **摘要翻译:** 人形机器人具有执行各种操作任务的潜在能力，但这需要一个鲁棒而精确的站立控制器。现有方法要么不适合精确控制高维度上半身关节，要么难以同时确保鲁棒性和准确性，尤其是在上半身运动速度快时。本文提出了一种新颖的时间优化策略（TOP），旨在训练一个站立操作控制模型，该模型通过调整上半身运动的时间轨迹，而不仅仅是加强下半身的抗干扰能力，从而同时确保平衡、精度和时间效率。我们的方法包括三个部分。首先，我们利用运动先验来表示上半身运动，通过训练变分自编码器（VAE）来增强上下半身之间的协调能力。然后，我们将全身控制解耦为用于精度的上半身PD控制器和用于增强鲁棒稳定性的下半身RL控制器。最后，我们将TOP方法与解耦控制器和VAE结合训练，以减轻由快速上半身运动引起的平衡负担，这些运动会使机器人不稳定并超出下半身RL策略的能力。所提出方法的有效性通过仿真和真实世界实验进行了评估，这些实验证明了其在稳定精确站立操作任务中的优越性。项目页面可在 https://anonymous.4open.science/w/top-258F/ 找到。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [171] [A Whole-Body Motion Imitation Framework from Human Data for Full-Size Humanoid Robot](https://arxiv.org/abs/2508.00362)
> *用于全尺寸人形机器人的基于人类数据的全身运动模仿框架*

*Zhenghan Chen, Haodong Zhang, Dongqi Wang, Jiyu Yu, Haocheng Xu, Yue Wang, Rong Xiong* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 人形机器人, 运动模仿, 全身控制, 模型预测控制, 运动重定向

**Comment:** 

> **TL;DR:** 提出了一种新颖的全身运动模仿框架，使全尺寸人形机器人能够准确、自适应地模仿人类动作，同时保持平衡。

**AI_Comments:** 这篇论文的创新点在于结合了运动重定向和模型预测控制，以解决人形机器人运动模仿中的核心挑战——即在保持平衡的同时实现高精度模仿。其重要性在于，它为使人形机器人表现更自然、更像人类迈出了关键一步，对于服务机器人、娱乐机器人等领域具有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人形机器人运动模仿面临挑战，因为人与机器人之间在运动学和动力学上存在显著差异，导致难以在保持平衡的同时准确模仿动作。

**Method:** 提出了一种新的全身运动模仿框架。该方法结合了接触感知全身运动重定向（用于模仿人类运动并提供参考轨迹初始值）和非线性质心模型预测控制器（用于确保运动精度、维持平衡并实时克服外部干扰）。全身控制器辅助实现更精确的扭矩控制。

**Result:** 在仿真和真实人形机器人上进行了多种人类运动模仿实验，结果表明该框架能够实现准确性和适应性。

**Conclusion:** 该框架有效解决了人形机器人运动模仿中的平衡和精度挑战，使其能够准确且自适应地模仿人类动作。

> **ai_Abstract:** 本文提出了一种创新的全身运动模仿框架，旨在解决全尺寸人形机器人模仿人类动作时在运动学和动力学差异带来的平衡和精度挑战。该框架结合了接触感知全身运动重定向技术，用于生成初始运动轨迹，以及一个非线性质心模型预测控制器，以确保实时运动精度、平衡维持和抗干扰能力。此外，全身控制器增强了扭矩控制的精确性。通过在仿真和真实机器人上的实验，验证了该方法在模仿多样化人类运动方面的准确性和适应性。

> **摘要翻译:** 运动模仿是人形机器人实现更多样化、更富有表现力的复杂动作的关键有效方法，使其表现更像人类。然而，人形机器人与人类在运动学和动力学上的显著差异，给在保持平衡的同时准确模仿动作带来了重大挑战。在本文中，我们提出了一种用于全尺寸人形机器人的新型全身运动模仿框架。所提出的方法采用接触感知全身运动重定向来模仿人类运动并为参考轨迹提供初始值，非线性质心模型预测控制器确保运动精度，同时保持平衡并实时克服外部干扰。全身控制器的辅助使得扭矩控制更加精确。在仿真和真实人形机器人中都进行了模仿各种人类运动的实验。这些实验证明了该方法在执行准确性和适应性方面的能力，验证了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [177] [TopoRec: Point Cloud Recognition Using Topological Data Analysis](https://arxiv.org/abs/2506.18725)
> *TopoRec：使用拓扑数据分析进行点云识别*

*Anirban Ghosh, Iliya Kulbaka, Ian Dahlin, Ayan Dutta* | **Category: cs.RO, cs.CG, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 点云识别, 拓扑数据分析, TopoRec, 无需训练, 全局描述符

**Comment:** 

> **TL;DR:** TopoRec是一种利用拓扑数据分析（TDA）进行点云识别的新方法，无需大量训练即可在多个数据集上超越现有方法。

**AI_Comments:** TopoRec的创新之处在于将拓扑数据分析（TDA）应用于点云识别，成功地避免了传统机器学习方法对大量训练数据和GPU资源的依赖。这种无需训练的特性使其具有很高的环境适应性和实用性，是该研究的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 点云识别在自动驾驶、场景重建和定位等应用中仍是一个重要问题。从查询点云中提取有意义的全局描述符并与数据库匹配具有挑战性，尤其是在点云噪声大或经过变换（如旋转）时，复杂性会增加。

**Method:** 本文提出了一种名为TopoRec的新方法，该方法利用拓扑数据分析（TDA）从点云中提取局部描述符，从而无需资源密集型的基于GPU的机器学习训练。具体来说，使用了ATOL向量化方法为点云生成向量。

**Result:** TopoRec在多个真实世界（如Oxford RobotCar、NCLT）和模拟（如ShapeNet）点云数据集上进行了大规模地点和对象识别测试。与PointNetVLAD和PCAN等现有基于学习的方法不同，TopoRec不需要大量训练。尽管如此，它在标准基准数据集上始终优于最先进的基于学习和手工设计的基线方法（如M2DP、ScanContext），表现出卓越的准确性和强大的泛化能力。

**Conclusion:** TopoRec方法通过利用拓扑数据分析，无需大量训练即可实现高性能的点云识别，并在多个数据集上表现出优于现有方法的准确性和泛化能力。

> **ai_Abstract:** TopoRec是一种新颖的点云识别方法，它利用拓扑数据分析（TDA）提取局部描述符，避免了对资源密集型GPU训练的需求。该方法在Oxford RobotCar、NCLT和ShapeNet等真实及模拟数据集上进行了测试，并在大规模地点和对象识别任务中表现出色。与现有学习型和手工设计的基线方法相比，TopoRec无需大量训练，却能持续展现出卓越的准确性和强大的泛化能力。

> **摘要翻译:** 基于点云的对象/地点识别在自动驾驶、场景重建和定位等应用中仍然是一个备受关注的问题。从查询点云中提取有意义的全局描述符，并将其与数据库点云的描述符进行匹配，是一个具有挑战性的问题。此外，当查询点云存在噪声或经过变换（例如旋转）时，会增加复杂性。为此，我们提出了一种名为TopoRec的新方法，该方法利用拓扑数据分析（TDA）从点云中提取局部描述符，从而无需资源密集型的基于GPU的机器学习训练。更具体地说，我们使用了ATOL向量化方法来为点云生成向量。为了测试所提出的TopoRec技术的质量，我们已将其应用于多个真实世界（例如，Oxford RobotCar、NCLT）和模拟（例如，ShapeNet）点云数据集，分别用于大规模地点和对象识别。与PointNetVLAD和PCAN等现有基于学习的方法不同，我们的方法不需要大量的训练，使其易于适应新环境。尽管如此，它在标准基准数据集上始终优于最先进的基于学习和手工设计的基线方法（例如，M2DP、ScanContext），表现出卓越的准确性和强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [186] [On Learning Closed-Loop Probabilistic Multi-Agent Simulator](https://arxiv.org/abs/2508.00384)
> *关于学习闭环概率多智能体模拟器*

*Juanwu Lu, Rohit Gupta, Ahmadreza Moradipari, Kyungtae Han, Ruqi Zhang, Ziran Wang* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 多智能体模拟, 闭环模拟, 概率模型, 自动驾驶, 贝叶斯模型

**Comment:** Accepted to IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) 2025. Source Code: https://github.com/juanwulu/niva

> **TL;DR:** 本文提出了NIVA，一个基于分层贝叶斯模型的概率多智能体模拟框架，用于生成多样化和交互式的闭环交通场景，并在Waymo开放运动数据集上取得了有竞争力的性能。

**AI_Comments:** 该论文的创新点在于提出了NIVA框架，它不仅引入了分层贝叶斯模型来实现闭环概率多智能体模拟，更重要的是，它从贝叶斯推理的角度统一了现有的序列到序列轨迹预测模型和新兴的闭环模拟模型，这为理解和发展多智能体模拟提供了新的视角。其能够对意图和驾驶风格进行精细控制的能力，对于生成更真实和多样化的交通场景具有重要意义，这对于自动驾驶汽车的测试和验证至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶汽车（AV）部署的快速迭代增加了对构建真实且可扩展的多智能体交通模拟器的需求，以进行高效评估。当前的进展集中在能够生成多样化和交互式场景的闭环模拟器。

**Method:** 本文引入了Neural Interactive Agents (NIVA)，一个由分层贝叶斯模型驱动的概率多智能体模拟框架。它通过从潜在的有限高斯混合分布中自回归采样，实现闭环、观察条件下的模拟。NIVA从贝叶斯推理的角度统一了现有的序列到序列轨迹预测模型和新兴的基于下一令牌预测（NTP）训练的闭环模拟模型。

**Result:** 在Waymo开放运动数据集上的实验表明，NIVA与现有方法相比取得了有竞争力的性能，同时提供了对意图和驾驶风格的精细控制。

**Conclusion:** NIVA是一个有效的闭环概率多智能体模拟器，它通过统一现有模型并提供对意图和驾驶风格的精细控制，展示了其在生成多样化交互式交通场景方面的潜力。

> **ai_Abstract:** 本文提出了NIVA（Neural Interactive Agents），一个创新的概率多智能体模拟框架，旨在满足自动驾驶汽车评估中对真实且可扩展交通模拟器的需求。NIVA采用分层贝叶斯模型，通过自回归采样实现闭环、观察条件下的模拟，并能统一现有轨迹预测和闭环模拟模型。实验证明，NIVA在性能上与现有方法相当，并能更好地控制模拟中的意图和驾驶风格。

> **摘要翻译:** 自动驾驶汽车（AV）部署的快速迭代导致对构建真实且可扩展的多智能体交通模拟器以进行高效评估的需求不断增加。该领域的最新进展集中于能够生成多样化和交互式场景的闭环模拟器。本文介绍了神经交互代理（NIVA），这是一个由分层贝叶斯模型驱动的概率多智能体模拟框架，它通过从潜在的有限高斯混合分布中自回归采样，实现闭环、观察条件下的模拟。我们展示了NIVA如何从贝叶斯推理的角度统一现有的序列到序列轨迹预测模型和新兴的基于下一令牌预测（NTP）训练的闭环模拟模型。在Waymo开放运动数据集上的实验表明，NIVA与现有方法相比取得了有竞争力的性能，同时提供了对意图和驾驶风格的精细控制。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [205] [SubCDM: Collective Decision-Making with a Swarm Subset](https://arxiv.org/abs/2508.00467)
> *SubCDM：基于蜂群子集的集体决策*

*Samratul Fuady, Danesh Tarapore, Mohammad D. Soorati* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 集体决策, 蜂群机器人, 资源效率, 子集, 去中心化

**Comment:** 6 pages, 7 figures. This paper has been accepted for presentation at
  the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS 2025)

> **TL;DR:** SubCDM是一种新的蜂群集体决策方法，它只使用蜂群中的一个子集进行决策，从而节省资源并保持与使用整个蜂群相当的准确性。

**AI_Comments:** 这项工作在蜂群机器人领域具有创新性，它通过引入基于子集的决策机制，有效解决了传统集体决策中资源消耗过大的痛点。其动态和去中心化的子集构建方法增加了系统的灵活性和适应性。这对于实际部署中的大型蜂群系统具有重要意义，因为它能提高资源利用率和系统并行处理任务的能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的集体决策策略需要所有机器人都参与决策过程，这会消耗大量资源并阻止蜂群将机器人分配给其他任务。

**Method:** 本文提出了基于子集的集体决策（SubCDM），它仅使用蜂群子集进行决策。子集的构建是动态和去中心化的，仅依赖局部信息。该方法允许蜂群根据达成共识的难度自适应地确定子集的大小，以实现准确的决策。

**Result:** 使用一百个机器人进行的仿真结果表明，SubCDM在减少执行集体决策所需的机器人数量的同时，实现了与使用整个蜂群相当的准确性。

**Conclusion:** SubCDM是一种资源高效的蜂群机器人集体决策解决方案，它通过仅使用蜂群子集进行决策来节省资源，同时保持高准确性。

> **ai_Abstract:** 本文提出了一种名为SubCDM的集体决策新方法，旨在解决现有蜂群决策策略资源消耗大的问题。SubCDM允许蜂群仅使用其子集进行决策，该子集的构建是动态和去中心化的，并能根据决策难度自适应调整大小。仿真结果表明，SubCDM在显著减少所需机器人数量的同时，仍能保持与全蜂群决策相当的准确性，提供了一种资源高效的解决方案。

> **摘要翻译:** 集体决策是自主机器人蜂群的关键功能，使其能够根据环境特征就行动达成共识。现有策略需要所有机器人参与决策过程，这会消耗大量资源并阻止蜂群将机器人分配给任何其他任务。我们提出了基于子集的集体决策（SubCDM），它仅使用蜂群子集进行决策。子集的构建是动态和去中心化的，仅依赖局部信息。我们的方法允许蜂群根据达成共识的难度自适应地确定子集的大小，以实现准确的决策。使用一百个机器人进行的仿真结果表明，我们的方法在减少执行集体决策所需的机器人数量的同时，实现了与使用整个蜂群相当的准确性，使其成为蜂群机器人集体决策的一种资源高效解决方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [226] [A control scheme for collaborative object transportation between a human and a quadruped robot using the MIGHTY suction cup](https://arxiv.org/abs/2508.00584)
> *人与四足机器人使用MIGHTY吸盘进行协同物体运输的控制方案*

*Konstantinos Plotas, Emmanouil Papadakis, Drosakis Drosakis, Panos Trahanias, Dimitrios Papageorgiou* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 人机协同, 四足机器人, 导纳控制, 物体运输, 吸盘

**Comment:** Please find the citation info @ Zenodo, ArXiv or Zenodo, as the
  proceedings of ICRA are no longer sent to IEEE Xplore

> **TL;DR:** 提出了一种基于导纳控制的人机协同物体运输方案，通过可变阻尼和势能函数确保物体不脱落，并在四足机器人上进行了实验验证。

**AI_Comments:** 该研究通过结合导纳控制、可变阻尼和障碍人工势，创新性地解决了人机协同物体运输中的控制和物体抓取稳定性问题。其提出的控制方案被证明是被动的，并得到了实验验证，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在提出一种人机协同物体运输的控制方案，以提高人类的可控性并减少其努力，同时确保物体在协作过程中不从吸盘上脱落。

**Method:** 提出了一种基于导纳控制的控制方案，该方案包含一个可变阻尼项，旨在提高人类的可控性并减少其努力。此外，为了防止物体在协作过程中从吸盘上脱落，还提出了一个基于障碍人工势的附加控制信号。

**Result:** 所提出的控制方案被证明是被动的，并且其性能通过使用配备MIGHTY吸盘的宇树Go1机器人进行的实验评估得到了验证。

**Conclusion:** 该研究成功提出并验证了一种有效的人机协同物体运输控制方案，该方案能够提高人类的可控性、减少努力并确保物体抓取稳定性。

> **ai_Abstract:** 本文提出了一种用于人与四足机器人协同物体运输的控制方案。该方案基于导纳控制，并引入了可变阻尼项以增强人类的可控性并减轻其负担。为防止物体在运输过程中脱落，还设计了一个基于障碍人工势的附加控制信号。该控制方案已通过理论证明其被动性，并通过宇树Go1机器人和MIGHTY吸盘的实验验证了其有效性。

> **摘要翻译:** 在这项工作中，提出了一种人机协同物体运输的控制方案，考虑了一个配备MIGHTY吸盘的四足机器人，该吸盘既作为抓手用于夹持物体，又作为力/扭矩传感器。所提出的控制方案基于导纳控制的概念，并结合了一个可变阻尼项，旨在提高人类的可控性，同时减少其努力。此外，为了确保物体在协作过程中不从吸盘上脱落，提出了一种基于障碍人工势的附加控制信号。所提出的控制方案被证明是被动的，其性能通过使用配备MIGHTY吸盘的宇树Go1机器人进行的实验评估得到了验证。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [246] [OpenScout v1.1 mobile robot: a case study on open hardware continuation](https://arxiv.org/abs/2508.00625)
> *OpenScout v1.1 移动机器人：一个开放硬件延续的案例研究*

*Bartosz Krawczyk, Ahmed Elbary, Robbie Cato, Jagdish Patil, Kaung Myat, Anyeh Ndi-Tah, Nivetha Sakthivel, Mark Crampton, Gautham Das, Charles Fox* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 开放硬件, 移动机器人, OpenScout, ROS2, Gazebo

**Comment:** 6 pages, 4 figures, a TAROS2025 short paper

> **TL;DR:** OpenScout 移动机器人升级至 v1.1 版本，实现了更简化、便宜且强大的硬件，并增加了 ROS2 和 Gazebo 仿真支持，本研究报告了其作为开放硬件的延续案例。

**AI_Comments:** 这篇论文以 OpenScout v1.1 为案例，有效展示了开放硬件项目如何通过迭代更新实现技术进步和可持续性。其创新之处在于通过具体的技术改进（如简化硬件、降低成本、增强性能及集成主流仿真工具）来推动现有开放硬件的实用化和普及，为其他开放硬件项目的延续和发展提供了宝贵的实践经验。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机是改进 OpenScout 开放硬件移动机器人，通过升级到 v1.1 版本，旨在提供更简化、更便宜和更强大的板载计算硬件，并引入 ROS2 接口和 Gazebo 仿真支持。

**Method:** 本论文通过报告 OpenScout v1.1 的具体更改、其背后的原理、项目方法论以及所取得的结果，将其作为开放硬件持续发展的一个案例研究进行呈现。

**Result:** OpenScout v1.1 版本成功实现了更简化、更便宜且更强大的板载计算硬件，并集成了模拟的 ROS2 接口和 Gazebo 仿真环境。

**Conclusion:** 本论文成功地将 OpenScout v1.1 的升级过程、改进理由、项目方法论及成果作为开放硬件持续发展的一个具体案例进行了报告和展示。

> **ai_Abstract:** 本文详细介绍了 OpenScout 移动机器人的 v1.1 版本升级。作为一款面向研究和工业的开源硬件机器人，v1.1 版本在板载计算硬件方面进行了优化，实现了简化、成本降低和性能提升，同时新增了模拟的 ROS2 接口和 Gazebo 仿真功能。论文将这些改进、其设计理念、项目实施方法和最终成果作为开放硬件持续发展的一个典型案例进行了深入探讨和记录。

> **摘要翻译:** OpenScout 是一种用于研究和工业的开源硬件（OSH）移动机器人。它已扩展到 v1.1 版本，该版本包括简化、更便宜和更强大的板载计算硬件；一个模拟的 ROS2 接口；以及一个 Gazebo 仿真。本研究报告了这些更改、其原理、项目方法论和结果，作为一个开放硬件案例研究。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [255] [E2E Parking Dataset: An Open Benchmark for End-to-End Autonomous Parking](https://arxiv.org/abs/2504.10812)
> *E2E停车数据集：一个用于端到端自动泊车的开放基准*

*Kejia Gao, Liguo Zhou, Mingjun Liu, Alois Knoll* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 自动泊车, 端到端学习, 数据集, 开放基准, E2E停车数据集

**Comment:** 

> **TL;DR:** 该论文发布了一个名为E2E停车数据集的高质量开放数据集，用于端到端自动泊车，以解决现有公开数据集的缺乏问题，并使用现有模型展示了其有效性。

**AI_Comments:** 该论文的关键创新在于开源了一个急需的高质量端到端自动泊车数据集，这对于推动该领域的研究进展和标准化评估具有重要意义。它解决了阻碍复现性和基准测试的核心问题，为后续研究提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 端到端学习在自动泊车方面显示出巨大潜力，但缺乏公开可用的数据集限制了研究的复现性和基准测试。尽管现有工作引入了基于视觉的泊车模型和数据生成、训练及闭环测试的流程，但其数据集并未发布。

**Method:** 为弥补这一空白，作者创建并开源了一个用于端到端自动泊车的高质量数据集。

**Result:** 使用原始模型，该数据集实现了85.16%的总体成功率，且平均位置误差为0.24米，平均方向误差为0.34度。

**Conclusion:** 该论文成功创建并发布了E2E停车数据集，填补了端到端自动泊车领域公开数据集的空白，并通过实验验证了其有效性，为未来的研究提供了开放基准。

> **ai_Abstract:** 该论文旨在解决端到端自动泊车领域缺乏公开数据集的问题。作者创建并开源了一个名为E2E停车数据集的高质量数据集，以促进研究的复现性和基准测试。通过使用一个现有模型在该数据集上进行测试，研究表明其实现了85.16%的泊车成功率，并显著降低了位置和方向误差，验证了该数据集的有效性。

> **摘要翻译:** 端到端学习在自动泊车方面显示出巨大潜力，然而缺乏公开可用的数据集限制了复现性和基准测试。尽管先前的工作引入了基于视觉的泊车模型以及数据生成、训练和闭环测试的流程，但数据集本身并未发布。为了弥补这一空白，我们创建并开源了一个用于端到端自动泊车的高质量数据集。使用原始模型，我们实现了85.16%的总体成功率，并且平均位置和方向误差更低（0.24米和0.34度）。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [266] [Towards Data-Driven Adaptive Exoskeleton Assistance for Post-stroke Gait](https://arxiv.org/abs/2508.00691)
> *走向数据驱动的自适应外骨骼辅助中风后步态*

*Fabian C. Weigend, Dabin K. Choe, Santiago Canete, Conor J. Walsh* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 数据驱动, 外骨骼, 中风后步态, 自适应辅助, TCN

**Comment:** 8 pages, 6 figures, 2 tables

> **TL;DR:** 本研究迈出了数据驱动的外骨骼辅助中风后步态的第一步，通过训练一个TCN模型来估计踝关节扭矩，并成功在一个中风患者身上验证了实时传感、估计和驱动的可行性。

**AI_Comments:** 这项研究的创新在于将数据驱动的外骨骼辅助方法应用于具有高度异质性和步态变异性的中风后人群，并克服了数据量不足的挑战。尽管参与者数量较少，但其成功验证了实时传感、估计和驱动的可行性，为未来在社区环境中实现个性化、自适应的外骨骼辅助奠定了基础。这对于提高中风患者的步态康复和生活质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管数据驱动的方法在健康年轻成人外骨骼辅助方面表现出色，但将其应用于中风后神经运动步态缺陷人群面临挑战，原因在于高异质性、步态变异性以及缺乏足够的训练数据集。然而，数据驱动的方法有望使外骨骼在非结构化社区环境中安全有效地运行，因此本研究旨在克服这些挑战。

**Method:** 本研究训练了一个多任务时间卷积网络（TCN），使用从四名中风后参与者在跑步机上收集的数据，并利用来自三个惯性测量单元（IMU）的数据输入。该模型还在六名健康参与者的步行数据上进行了预训练。研究人员还实现了一个可穿戴原型，用于踝关节扭矩估计，以进行外骨骼控制。

**Result:** 训练的TCN模型在数据上获得了0.74 ± 0.13的R²值。研究人员在一个中风后参与者身上成功展示了实时传感、估计和驱动的可行性。

**Conclusion:** 这项工作代表了通过数据驱动的扭矩估计，实现中风后步行中自适应跖屈和背屈辅助的第一步。

> **ai_Abstract:** 本研究旨在解决数据驱动外骨骼辅助应用于中风后步态障碍人群的挑战。研究人员提出了一种通过数据驱动的扭矩估计实现自适应跖屈和背屈辅助的方法。他们训练了一个多任务时间卷积网络（TCN），该网络利用IMU数据，并使用来自中风后参与者的数据进行训练，并用健康行走数据进行预训练。实验结果显示模型性能良好（R²=0.74 ± 0.13），并通过可穿戴原型在一个中风患者身上成功验证了实时传感、估计和驱动的可行性，标志着该领域的重要一步。

> **摘要翻译:** 最近的研究表明，通过数据驱动方法控制的外骨骼可以动态地适应健康年轻成人的各种任务。然而，将这些方法应用于神经运动步态缺陷人群（如中风后偏瘫患者）具有挑战性。这不仅是由于高人群异质性和步态变异性，还因为缺乏用于训练精确模型的中风后步态数据集。尽管存在这些挑战，数据驱动方法为控制提供了一条有前景的途径，可能使外骨骼在非结构化社区环境中安全有效地运行。这项工作迈出了第一步，旨在通过数据驱动的扭矩估计在中风后步行期间实现自适应的跖屈和背屈辅助。我们使用从四名中风后参与者在跑步机上收集的数据训练了一个多任务时间卷积网络（TCN）（R²为0.74 ± 0.13）。该模型使用来自三个惯性测量单元（IMU）的数据，并在六名健康参与者的步行数据上进行了预训练。我们为外骨骼控制的踝关节扭矩估计方法实现了一个可穿戴原型，并向一名中风后参与者展示了实时传感、估计和驱动的可行性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [286] [Video Generators are Robot Policies](https://arxiv.org/abs/2508.00795)
> *视频生成器即机器人策略*

*Junbang Liang, Pavel Tokmakov, Ruoshi Liu, Sruthi Sudhakar, Paarth Shah, Rares Ambrus, Carl Vondrick* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 视频生成, 机器人策略, 视觉运动控制, 泛化, 样本效率

**Comment:** 

> **TL;DR:** 本文提出将视频生成作为机器人策略学习的替代方案，以解决现有视觉运动策略在泛化能力和数据效率方面的局限性，通过生成机器人行为视频来学习策略，显著提高了鲁棒性和样本效率，并展现出强大的泛化能力。

**AI_Comments:** 本文的创新之处在于将机器人策略学习重新定义为一个视频生成问题，这使得研究人员能够利用大量的无动作视频数据，从而显著提高了模型的泛化能力和数据效率。这种方法为克服机器人操作领域的数据限制提供了一个极具前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉运动策略在感知或行为分布变化下难以泛化，并且其性能受限于人类演示数据的规模。

**Method:** 本文将视频生成作为机器人策略学习的替代方案，提出了“视频策略”（Video Policy），这是一个模块化框架，结合了视频和动作生成，可以进行端到端训练。

**Result:** 学习生成机器人行为视频能够以最少的演示数据提取策略，显著提高了鲁棒性和样本效率。该方法在模拟和现实世界中都显示出对未见过物体、背景和任务的强大泛化能力。任务成功与生成的视频密切相关，无动作的视频数据为泛化到新任务提供了关键优势。通过利用大规模视频生成模型，该方法比传统行为克隆实现了更优越的性能。

**Conclusion:** 将视频生成作为机器人策略学习的替代方案，为更具可扩展性和数据效率的机器人策略学习铺平了道路。

> **ai_Abstract:** 本文提出了一种名为“视频策略”的模块化框架，该框架将视频生成作为机器人策略学习的替代方案，旨在解决现有视觉运动策略在泛化能力和数据效率方面的限制。通过端到端地结合视频和动作生成，该方法能够在极少演示数据的情况下提取机器人策略，显著提升了鲁棒性、样本效率，并对新物体、背景和任务展现出强大的泛化能力。实验结果表明，该方法优于传统的行为克隆，尤其是在利用大规模视频生成模型时，为实现更具可扩展性和数据效率的机器人策略学习提供了新途径。

> **摘要翻译:** 尽管在灵巧操作方面取得了巨大进展，但当前的视觉运动策略仍受限于两个根本性挑战：它们难以在感知或行为分布变化下泛化，并且其性能受限于人类演示数据的规模。在本文中，我们利用视频生成作为机器人策略学习的替代方案，以同时解决这两个限制。我们提出了“视频策略”（Video Policy），这是一个模块化框架，结合了视频和动作生成，可以进行端到端训练。我们的结果表明，学习生成机器人行为视频能够以最少的演示数据提取策略，显著提高了鲁棒性和样本效率。我们的方法在模拟和现实世界中都显示出对未见过物体、背景和任务的强大泛化能力。我们进一步强调，任务成功与生成的视频密切相关，无动作的视频数据为泛化到新任务提供了关键优势。通过利用大规模视频生成模型，我们比传统行为克隆实现了更优越的性能，为更具可扩展性和数据效率的机器人策略学习铺平了道路。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [326] [Scalable Outdoors Autonomous Drone Flight with Visual-Inertial SLAM and Dense Submaps Built without LiDAR](https://arxiv.org/abs/2403.09596)
> *基于视觉惯性SLAM和无激光雷达构建的密集子图的可扩展室外自主无人机飞行*

*Sebastián Barbas Laina, Simon Boche, Sotiris Papatheodorou, Dimos Tzoumanikas, Simon Schaefer, Hanzhi Chen, Stefan Leutenegger* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 自主导航, 视觉惯性SLAM, 无人机, 子图, 室外机器人

**Comment:** 8 pages, 8 figures

> **TL;DR:** 本文提出了一种基于经济高效的视觉惯性传感器和板载计算的自主微型飞行器（MAV）系统，实现了在室外非结构化环境中的安全、可扩展自主导航，无需激光雷达。

**AI_Comments:** 该论文的创新之处在于，它仅使用低成本的视觉惯性传感器和板载计算，无需依赖激光雷达，就能在非结构化室外环境中实现鲁棒、可扩展且安全的自主无人机导航。这显著降低了成本和复杂性，使自主无人机应用更易于实现。新颖的轨迹锚定方案也为系统的安全性和鲁棒性做出了贡献，尤其是在闭环期间。

<details>
  <summary>Details</summary>

**Motivation:** 机器人应用中需要自主导航，尤其是在室外、非结构化和杂乱环境中，需要使用经济高效且轻量级的传感器实现微型飞行器（MAV）的大规模自主导航。

**Method:** 该系统纯粹依赖于经济高效且轻量级的被动视觉和惯性传感器。它利用视觉惯性同步定位与建图（VI-SLAM）进行精确的MAV状态估计，并结合体积占用子图系统实现可扩展的建图框架，可直接用于路径规划。为确保安全，还提出了一种新颖的参考轨迹锚定方案，即使在闭环引起的大状态更新时也能一致地变形参考轨迹。所有计算（包括VI-SLAM）均在板载完成。

**Result:** 系统在真实和模拟森林环境中进行了彻底验证，在高达3米/秒的峰值速度下未发生任何碰撞或系统故障。据作者所知，这是第一个在如此非结构化环境中使用低成本被动视觉传感器和完全板载计算（包括VI-SLAM）实现此性能水平的系统。

**Conclusion:** 该论文成功展示了一个鲁棒、可扩展且安全的自主微型飞行器（MAV）导航系统，该系统仅使用视觉惯性传感器和板载计算，在没有激光雷达的情况下，在非结构化室外环境中实现了高性能和安全性。

> **ai_Abstract:** 本文介绍了一种用于在复杂室外环境中进行大规模自主导航的微型飞行器（MAV）系统。它仅依靠经济高效的视觉和惯性传感器，集成了VI-SLAM进行精确状态估计，并结合体积占用子图系统实现可扩展的建图和路径规划。一种新颖的轨迹锚定方案通过一致地变形参考轨迹来确保安全。该系统在森林环境中进行了验证，展示了在高达3米/秒的速度下稳健的性能，没有发生碰撞，并声称是首个使用低成本传感器和板载计算在无激光雷达的情况下实现此类成果的系统。

> **摘要翻译:** 自主导航是多种机器人应用所必需的。在本文中，我们提出了一种自主微型飞行器（MAV）系统，该系统纯粹依靠经济高效且轻量级的被动视觉和惯性传感器，在室外、非结构化和杂乱的环境中执行大规模自主导航。我们利用视觉惯性同步定位与建图（VI-SLAM）进行精确的MAV状态估计，并将其与体积占用子图系统相结合，以实现一个可扩展的建图框架，该框架可以直接用于路径规划。为了确保MAV在导航期间的安全，我们还提出了一种新颖的参考轨迹锚定方案，该方案以一致的方式变形MAV正在跟踪的参考轨迹，即使在由于闭环引起的较大状态更新时也能保持一致。我们在真实和模拟森林环境中彻底验证了我们的系统，在高达3米/秒的峰值速度下，没有发生一次碰撞或系统故障。据我们所知，这是第一个使用低成本被动视觉传感器和完全板载计算（包括VI-SLAM）在如此非结构化环境中实现这种性能水平的系统。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [351] [Learning Goal-Directed Object Pushing in Cluttered Scenes With Location-Based Attention](https://arxiv.org/abs/2403.17667)
> *学习在杂乱场景中基于位置注意力的目标导向物体推动*

*Nils Dengler, Juan Del Aguila Ferrandis, João Moura, Sethu Vijayakumar, Maren Bennewitz* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 目标导向推动, 非抓取操作, 强化学习, 位置注意力, 杂乱场景

**Comment:** Accepted to IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)2025

> **TL;DR:** 该研究提出了一种基于位置注意力机制的强化学习方法，使机器人能够在杂乱环境中成功地进行目标导向的物体推动，无需预定义路径并能避免碰撞。

**AI_Comments:** 该论文通过引入基于位置的注意力机制，有效提升了机器人在杂乱环境中进行非抓取操作的鲁棒性，尤其是在无需预定义全局路径和考虑物体目标方向方面具有创新性。其在动态障碍物场景下的成功表现也突出了该方法的实用性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂场景中，传统的抓取放置技术往往不足以完成任务。非抓取操作虽然能够解决问题，但其欠驱动特性、混合动力学、长期行为推理、接触切换以及对接触不确定性的鲁棒性要求使其极具挑战性。工作空间中的杂乱环境进一步增加了任务的复杂性，需要更高级的空间分析来避免不必要的碰撞。

**Method:** 本研究在以往基于强化学习和多模态分类探索的平面推动工作的基础上，引入了基于位置的注意力机制，以实现在杂乱场景中的鲁棒操作。与以往解决避障推动任务的方法不同，该框架无需预定义全局路径，并考虑了被操作物体的目标方向。

**Result:** 在模拟环境以及真实的KUKA iiwa机械臂上的实验结果表明，所学习的策略能够成功操作物体，并通过复杂的障碍物配置（包括动态障碍物）避免碰撞，从而达到期望的目标姿态。

**Conclusion:** 所提出的基于位置注意力的强化学习策略能够有效解决在杂乱场景中进行目标导向的非抓取物体推动任务，实现成功的物体操作和鲁棒的碰撞避免，即使面对复杂的静态和动态障碍物也能达到期望的目标姿态。

> **ai_Abstract:** 本研究提出了一种结合强化学习和位置注意力机制的新型框架，旨在解决杂乱场景中目标导向的非抓取物体推动问题。该方法无需预设全局路径，并能考虑物体目标姿态。实验结果表明，该策略在模拟和真实机器人环境中均能成功推动物体并有效避免与静态及动态障碍物发生碰撞，实现期望的目标姿态。

> **摘要翻译:** 在典型的抓取放置技术不足的复杂场景中，非抓取操作往往能确保机器人完成任务。然而，非抓取操作由于其欠驱动特性和混合动力学而具有挑战性，机器人需要推理物体的长期行为和接触切换，同时要对接触不确定性保持鲁棒性。工作空间中杂乱的存在进一步使这项任务复杂化，引入了需要更高级空间分析以避免不必要碰撞的需求。基于先前关于使用多模态分类探索进行平面推动的强化学习工作，我们提出引入基于位置的注意力机制，以实现在杂乱场景中的鲁棒操作。与以往解决这种避障推动任务的方法不同，我们的框架不需要预定义的全局路径，并考虑了被操作物体的目标方向。在模拟以及使用真实KUKA iiwa机械臂进行的实验结果表明，我们学习到的策略能够成功操作物体，同时通过复杂的障碍物配置（包括动态障碍物）避免碰撞，从而达到期望的目标姿态。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [371] [PC-SRIF: Preconditioned Cholesky-based Square Root Information Filter for Vision-aided Inertial Navigation](https://arxiv.org/abs/2409.11372)
> *PC-SRIF：用于视觉辅助惯性导航的预处理乔利斯基平方根信息滤波器*

*Tong Ke, Parth Agrawal, Yun Zhang, Weikun Zhen, Chao X. Guo, Toby Sharp, Ryan C. Dutoit* | **Category: cs.RO** | **Updated: 2025-07-31**

**Keywords:** 视觉辅助惯性导航, 平方根信息滤波器, 乔利斯基分解, 预处理, 数值稳定性

**Comment:** This work has been accepted to the 2025 IEEE/RSJ International
  Conference on Intelligent Robots and Systems (IROS 2025)

> **TL;DR:** 本文提出了一种名为PC-SRIF的新型视觉辅助惯性导航系统（VINS）估计器，它通过预处理技术解决了乔利斯基分解在单精度下数值不稳定的问题，实现了更高的效率和稳定性。

**AI_Comments:** 该论文的创新点在于识别并解决了视觉辅助惯性导航系统中乔利斯基分解在单精度下数值不稳定的根本原因，即信息矩阵的病态并非VINS固有，而是参数化问题。通过提出有效的预处理技术，PC-SRIF不仅提高了计算效率，还增强了数值稳定性，这对于实时、资源受限的导航系统至关重要。其理论分析和实验验证都非常充分，证明了该方法在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉辅助惯性导航系统（VINS）在解决线性系统时，因乔利斯基分解的数值稳定性问题，通常选择QR分解，尤其是在单精度优先的平台上。作者发现信息矩阵的病态并非VINS固有的，而是特定参数化的结果，因此需要一种方法来缓解这些条件问题，以利用乔利斯基分解的效率优势。

**Method:** 本文引入了预处理乔利斯基平方根信息滤波器（PC-SRIF）。通过分析导致信息矩阵病态的因素，提出了一种预处理技术来缓解条件问题。PC-SRIF利用这种预处理技术，在VINS中解决线性系统时，能在单精度下稳定地执行乔利斯基分解。

**Result:** PC-SRIF在单精度下执行乔利斯基分解时表现出卓越的稳定性，并实现了比现有估计器更高的理论效率。实验验证了PC-SRIF在VINS中的效率优势和数值稳定性。在VINS实现中，PC-SRIF的运行时比基于QR的SRIF快41%。

**Conclusion:** PC-SRIF通过有效的预处理技术，解决了乔利斯基分解在单精度下应用于VINS时遇到的数值稳定性问题，从而实现了更高的计算效率和可靠性，为视觉辅助惯性导航系统提供了一种更优的估计器。

> **ai_Abstract:** 本文提出了一种用于视觉辅助惯性导航系统（VINS）的新型估计器——预处理乔利斯基平方根信息滤波器（PC-SRIF）。针对现有VINS在单精度下使用乔利斯基分解时面临的数值稳定性问题，作者分析指出信息矩阵的病态并非固有属性，而是特定参数化导致。通过引入一种预处理技术，PC-SRIF能稳定地在单精度下执行乔利斯基分解，从而显著提高计算效率。实验证明，PC-SRIF比基于QR的SRIF快41%。

> **摘要翻译:** 在本文中，我们介绍了一种用于视觉辅助惯性导航系统（VINS）的新型估计器，即基于预处理乔利斯基的平方根信息滤波器（PC-SRIF）。在求解线性系统时，使用乔利斯基分解具有更高的效率，但可能会损害数值稳定性。因此，现有利用（平方根）信息滤波器的VINS在单精度优先的平台上通常选择QR分解，以避免与乔利斯基分解相关的数值挑战。尽管这些问题通常归因于VINS中信息矩阵的病态，但我们的分析表明，这并非VINS的固有属性，而是特定参数化的结果。我们确定了导致信息矩阵病态的几个因素，并提出了一种预处理技术来缓解这些条件问题。基于此分析，我们提出了PC-SRIF，它在VINS中解决线性系统时，在单精度下执行乔利斯基分解时表现出卓越的稳定性。因此，与替代估计器相比，PC-SRIF实现了卓越的理论效率。为了验证PC-SRIF在VINS中的效率优势和数值稳定性，我们进行了良好控制的实验，这些实验提供了支持我们理论发现的经验证据。值得注意的是，在我们的VINS实现中，PC-SRIF的运行时间比基于QR的SRIF快41%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [390] [AugInsert: Learning Robust Visual-Force Policies via Data Augmentation for Object Assembly Tasks](https://arxiv.org/abs/2410.14968)
> *AugInsert：通过数据增强学习鲁棒的视觉-力策略用于物体装配任务*

*Ryan Diaz, Adam Imdieke, Vivek Veeriah, Karthik Desingh* | **Category: cs.RO, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 多感官策略, 鲁棒性, 数据增强, 物体装配, 力矩传感

**Comment:** Accepted to IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) 2025

> **TL;DR:** 本文提出了一个评估多感官策略鲁棒性的框架，并开发了一个多感官策略，利用数据增强来提高物体装配任务中的泛化能力，发现抓取姿态是最大的挑战，且力矩传感信息量最大。

**AI_Comments:** 该论文在多感官机器人策略的鲁棒性评估方面做出了重要贡献，特别强调了力矩传感在接触密集型任务中的关键作用。其创新点在于提出了一个基于因素的评估框架和多感官数据增强方法。发现抓取姿态是主要挑战，以及力矩传感的重要性，为未来鲁棒性策略设计提供了宝贵的见解。然而，论文也指出简单的单感官数据增强不足，这暗示未来研究需要更复杂的多感官数据增强策略。

<details>
  <summary>Details</summary>

**Motivation:** 在非结构化环境中操作需要机器人策略对分布外条件具有鲁棒性。尽管在评估视觉运动策略的鲁棒性方面做了大量工作，但包含力矩传感的多感官方法的鲁棒性评估仍未被充分探索。

**Method:** 本文引入了一个新颖的、基于因素的评估框架，以评估多感官策略在“孔中插销”装配任务中的鲁棒性。为此，开发了一个利用Perceiver IO架构的多感官策略框架来学习任务，并探索了一种简单的多感官数据增强技术来增强分布外性能。提供了一个仿真环境以实现对这些因素的受控评估。

**Result:** 结果表明，抓取姿态等多感官变化对鲁棒性构成了最重大的挑战，并且独立应用于每个感官模态的朴素单感官数据增强不足以克服这些挑战。此外，发现力矩传感是接触密集型装配任务中最有信息量的模态，而视觉信息量最少。

**Conclusion:** 本文提出了一个评估多感官策略鲁棒性的框架和方法，并发现多感官变化（特别是抓取姿态）是鲁棒性的主要挑战，力矩传感在接触密集型装配任务中至关重要，而简单的单感官数据增强不足以解决这些挑战。

> **ai_Abstract:** 本文提出了一种新颖的、基于因素的评估框架，用于评估多感官策略在物体装配任务中的鲁棒性，特别是针对“孔中插销”任务。研究团队开发了一个基于Perceiver IO架构的多感官策略框架，并探索了多感官数据增强技术以提高分布外性能。研究发现，抓取姿态等多感官变化对鲁棒性构成最大挑战，且力矩传感是接触密集型任务中最具信息量的模态，而简单的单感官数据增强不足以解决这些挑战。

> **摘要翻译:** 在家庭等非结构化环境中操作需要机器人策略对分布外条件具有鲁棒性。尽管在评估视觉运动策略的鲁棒性方面做了大量工作，但包含力矩传感的多感官方法的鲁棒性评估仍未被充分探索。这项工作引入了一个新颖的、基于因素的评估框架，旨在评估“孔中插销”装配任务中多感官策略的鲁棒性。为此，我们开发了一个利用Perceiver IO架构的多感官策略框架来学习该任务。我们研究了哪些因素在物体装配中构成了最大的泛化挑战，并探索了一种简单的多感官数据增强技术来增强分布外性能。我们提供了一个仿真环境，可以对这些因素进行受控评估。我们的结果表明，抓取姿态等多感官变化对鲁棒性构成了最重大的挑战，并且独立应用于每个感官模态的朴素单感官数据增强不足以克服这些挑战。此外，我们发现力矩传感是我们接触密集型装配任务中最有信息量的模态，而视觉信息量最少。最后，我们简要讨论了支持性的真实世界实验结果。有关更多实验和定性结果，请参阅项目网页https://rpm-lab-umn.github.io/auginsert/。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [410] [Cooperative Payload Estimation by a Team of Mocobots](https://arxiv.org/abs/2502.04600)
> *移动协作机器人团队的协同负载估计*

*Haoxuan Zhang, C. Lin Liu, Matthew L. Elwin, Randy A. Freeman, Kevin M. Lynch* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 负载估计, 协作机器人, 移动机械手, 惯性特性, 传感器融合

**Comment:** 8 pages, 6 figures. Submitted to IEEE Robotics and Automation Letters
  (RA-L)

> **TL;DR:** 本文提出了一种方法，使移动协作机器人团队能够自主估计负载的质量、惯性特性以及机器人与负载的附着位置。

**AI_Comments:** 该论文提出了一种创新的方法，使多机器人系统能够自主感知和理解其所操作负载的关键物理特性。这种能力对于实现高精度和高性能的协作操作至关重要，尤其是在动态和非结构化环境中。实验验证增加了其方法的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现移动机械手团队对负载的高性能自主操作，或与人类进行协作操作，机器人需要能够发现其他机器人附着在负载上的位置以及负载的质量和惯性特性。

**Method:** 机器人协同操作负载，并利用其抓取框架处的扭曲、扭曲导数和力矩数据来估计抓取框架之间的变换矩阵、负载质心的位置以及负载的惯性矩阵。

**Result:** 该方法通过一个由三个移动协作机器人（mocobots）组成的团队进行了实验验证。

**Conclusion:** 本文提出的方法能够使移动协作机器人团队自主估计负载的关键物理特性和附着位置，从而实现高性能的协作操作。

> **ai_Abstract:** 本文提出了一种针对移动协作机器人团队的协同负载估计方法。该方法允许机器人自主识别其他机器人与负载的附着点、负载的质量和惯性特性。通过协同操作负载，机器人利用其抓取框架的扭曲、扭曲导数和力矩数据来估计关键参数，包括抓取框架间的变换矩阵、负载质心位置和惯性矩阵。该方法已通过由三个移动协作机器人组成的团队进行了实验验证，旨在实现高性能的自主或人机协作操作。

> **摘要翻译:** 为了实现移动机械手团队对负载的高性能自主操作，或与人类进行协作操作，机器人应该能够发现其他机器人附着在负载上的位置，以及负载的质量和惯性特性。在本文中，我们描述了一种让机器人自主发现这些信息的方法。机器人协同操作负载，并利用其抓取框架处的扭曲、扭曲导数和力矩数据来估计抓取框架之间的变换矩阵、负载质心的位置以及负载的惯性矩阵。该方法通过一个由三个移动协作机器人（mocobots）组成的团队进行了实验验证。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [436] [Learning to Push, Group, and Grasp: A Diffusion Policy Approach for Multi-Object Delivery](https://arxiv.org/abs/2502.08452)
> *学习推动、分组和抓取：一种用于多目标交付的扩散策略方法*

*Takahiro Yonemaru, Weiwei Wan, Tatsuki Nishimura, Kensuke Harada* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 多目标抓取, 扩散策略, 模仿学习, 机器人操作, 物体交付

**Comment:** 

> **TL;DR:** 本文提出了一种基于模仿学习的方法，利用扩散策略网络实现高效的多目标抓取和交付，在实验中表现出有效和自适应的性能。

**AI_Comments:** 该论文的创新之处在于将扩散策略网络应用于复杂的机器人多目标推动、分组和抓取任务，超越了传统的基于规则的系统。这对于提高机器人处理多目标时的效率至关重要。然而，作为一种模仿学习方法，其性能可能高度依赖于专家演示的质量和多样性，这在面对全新或复杂场景时可能构成局限性。

<details>
  <summary>Details</summary>

**Motivation:** 为了显著提高机器人工作效率，同时抓取和交付多个物体，解决如何推动物体、对它们进行分组并对各自组执行同时抓取，同时考虑物体分布和机器人硬件约束的挑战，因为传统的基于规则的方法难以灵活适应各种场景。

**Method:** 本文提出了一种基于模仿学习的方法。通过远程操作收集一系列专家演示，并训练一个扩散策略网络，使机器人能够动态生成推动、分组和抓取动作序列，从而促进高效的多目标抓取和交付。

**Result:** 实验结果表明，所提出的方法可以有效且自适应地生成多目标分组和抓取策略。在更多训练数据的支持下，模仿学习有望成为解决多目标抓取问题的有效方法。

**Conclusion:** 模仿学习，尤其是在更多训练数据的支持下，有望成为解决多目标抓取问题的有效方法。

> **ai_Abstract:** 本文提出了一种基于模仿学习的方法，利用扩散策略网络使机器人能够高效地推动、分组和抓取多个物体以进行交付。该方法通过收集专家演示进行训练，旨在解决传统规则方法在多对象处理中的局限性。实验结果表明，该方法能够有效且自适应地生成多目标分组和抓取策略，并且随着训练数据的增加，其性能有望进一步提升，为多目标抓取问题提供了一种有前景的解决方案。

> **摘要翻译:** 同时抓取和交付多个物体可以显著提高机器人工作效率，几十年来一直是研究的重点。主要挑战在于如何推动物体、对它们进行分组并对各自组执行同时抓取，同时考虑物体分布和机器人硬件约束。传统的基于规则的方法难以灵活适应各种场景。为了解决这一挑战，本文提出了一种基于模仿学习的方法。我们通过远程操作收集了一系列专家演示，并训练了一个扩散策略网络，使机器人能够动态生成推动、分组和抓取动作序列，从而促进高效的多目标抓取和交付。我们进行了实验，在不同的训练数据集大小、不同的物体数量和真实世界物体场景下评估了该方法。结果表明，所提出的方法可以有效且自适应地生成多目标分组和抓取策略。在更多训练数据的支持下，模仿学习有望成为解决多目标抓取问题的有效方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [461] [FalconGym: A Photorealistic Simulation Framework for Zero-Shot Sim-to-Real Vision-Based Quadrotor Navigation](https://arxiv.org/abs/2503.02198)
> *FalconGym：一个用于零样本模拟到真实视觉四旋翼导航的光真实感仿真框架*

*Yan Miao, Will Shen, Sayan Mitra* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 四旋翼, 零样本迁移, 模拟到真实, 光真实感仿真, 视觉导航

**Comment:** Accepted in IROS 2025

> **TL;DR:** 提出FalconGym光真实感仿真框架，实现四旋翼飞行器视觉控制策略的零样本模拟到真实迁移，用于穿越竞速门，达到高成功率和精度。

**AI_Comments:** 这篇论文通过引入FalconGym这一光真实感仿真环境，有效解决了四旋翼视觉控制中模拟到真实迁移的视觉保真度瓶颈，其创新性在于结合了NeRF生成数据、多模态感知与控制，并实现了令人印象深刻的零样本迁移效果，对机器人学习和仿真领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决标准模拟器视觉保真度不足导致模拟到真实（sim-to-real）迁移困难的问题，特别是在四旋翼飞行器视觉控制策略方面。

**Method:** 构建了一个名为FalconGym的光真实感四旋翼竞速赛道仿真环境，提供无限合成图像用于训练。开发了一个穿越门的流水线方法，结合：(i) 一个神经姿态估计器（NPE）与卡尔曼滤波器，用于从单帧RGB图像和IMU数据可靠推断四旋翼姿态；以及 (ii) 一个基于自注意力机制的多模态控制器，自适应整合视觉特征和姿态估计。控制器完全在FalconGym中通过模仿学习训练，无需额外微调即可部署到真实硬件。

**Result:** 模拟实验表明，在成功率和过门精度方面，其控制器优于仅视觉的最新基线。在涵盖三条赛道和120个门的30次真实硬件飞行中，控制器实现了95.8%的成功率，在穿过38厘米半径的门时平均误差仅为10厘米。

**Conclusion:** 该框架通过高保真模拟环境和多模态控制策略，成功实现了四旋翼视觉控制的零样本模拟到真实迁移，并在真实世界中表现出高鲁棒性和准确性。

> **ai_Abstract:** 本文提出了FalconGym，一个光真实感仿真框架，旨在解决四旋翼视觉控制策略的零样本模拟到真实迁移中的视觉保真度问题。该框架利用NeRF环境生成训练数据，并开发了一个结合神经姿态估计器和多模态自注意力控制器的流水线方法。该控制器在FalconGym中纯粹通过模仿学习训练，并在不进行微调的情况下成功部署到真实四旋翼飞行器上，在模拟和真实飞行中均展示出卓越的成功率和精度，显著优于现有基线。

> **摘要翻译:** 我们提出了一个新颖的框架，展示了在神经辐射场（NeRF）环境中学习到的四旋翼飞行器视觉控制策略的零样本模拟到真实（sim-to-real）迁移，用于穿越竞速门。从模拟到真实飞行的鲁棒迁移是一个重大挑战，因为标准模拟器通常缺乏足够的视觉保真度。为了解决这个问题，我们构建了一个名为FalconGym的四旋翼竞速赛道光真实感仿真环境，它能提供无限的合成图像用于训练。在FalconGym中，我们开发了一种穿越门的流水线方法，该方法结合了：(i) 一个神经姿态估计器（NPE）与卡尔曼滤波器，用于从单帧RGB图像和IMU数据可靠地推断四旋翼姿态；以及 (ii) 一个基于自注意力机制的多模态控制器，该控制器自适应地整合视觉特征和姿态估计。这种多模态设计补偿了感知噪声和间歇性门可见性。我们仅在FalconGym中通过模仿学习训练该控制器，并将所得策略部署到真实硬件上，无需额外的微调。在三条不同赛道（圆形、U形和8字形）上的模拟实验表明，我们的控制器在成功率和过门精度方面均优于仅视觉的最新基线。在涵盖三条赛道和120个门的30次真实硬件飞行中，我们的控制器实现了95.8%的成功率，在穿过38厘米半径的门时平均误差仅为10厘米。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [486] [SCORE: Saturated Consensus Relocalization in Semantic Line Maps](https://arxiv.org/abs/2503.03254)
> *SCORE：语义线图中的饱和共识重定位*

*Haodong Jiang, Xiang Zheng, Yanglin Zhang, Qingcheng Zeng, Yiqian Li, Ziyang Hong, Junfeng Wu* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 视觉重定位, 语义线图, 饱和共识最大化, 地图紧凑性, 鲁棒估计

**Comment:** 12 pages, 13 figurs, arxiv version for paper published at IROS 2025

> **TL;DR:** SCORE是一种基于语义线图的视觉重定位系统，通过创新的饱和共识最大化机制，在保持高精度的同时显著降低了地图存储需求，即使在极端异常值比例下也能有效工作。

**AI_Comments:** SCORE的创新之处在于其将语义信息与线图结合，并提出了Saturated Consensus Maximization (Sat-CM)这一鲁棒估计机制。Sat-CM能够有效应对语义匹配中常见的高异常值比例问题，解决了传统CM的局限性。这种方法在实现地图极度紧凑的同时，依然能保持高精度和效率，对于资源受限的机器人或AR/VR应用具有重要意义。该研究在存储效率和鲁棒性方面取得了显著突破。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉重定位系统，无论是基于结构还是基于学习的，都需要大量的存储空间，这限制了它们在资源受限环境中的应用。此外，在语义匹配中存在一对多歧义导致极端异常值比例的问题，传统共识最大化机制在此情况下表现不佳。

**Method:** 本文提出了SCORE系统，该系统采用语义标注的3D线图来实现地图紧凑性。其核心创新是饱和共识最大化（Sat-CM）机制，该机制通过根据最大似然以概率理由为内点关联分配递减的权重，从而泛化了经典的共识最大化（CM）。为了确保计算效率，作者提出了一个用于全局求解Sat-CM公式的加速框架，并专门针对SCORE核心的透视-N-线问题进行了优化。

**Result:** SCORE系统仅需要基于结构或基于学习的基线系统所需存储空间的0.01%-0.1%，同时保持了实用的精度和可比的运行时间。即使在高达99.5%的极端异常值比例下（传统CM失效的情况下），Sat-CM也能实现准确的估计。

**Conclusion:** SCORE系统成功地将视觉重定位的地图存储需求降低了几个数量级，同时保持了高精度和效率，即使在面对语义匹配中的极端异常值挑战时也能表现出色，这得益于其创新的饱和共识最大化机制。

> **ai_Abstract:** 本文介绍了SCORE，一种基于语义标注3D线图的视觉重定位系统。该系统通过引入创新的饱和共识最大化（Sat-CM）机制，显著减少了地图存储需求（仅为传统方法的0.01%-0.1%），同时保持了高精度和效率。Sat-CM机制通过为内点关联分配递减权重，有效处理了语义匹配中高达99.5%的极端异常值，解决了传统共识最大化方法的局限性。为提高计算效率，还提出了一个加速求解Sat-CM的框架。

> **摘要翻译:** 我们提出了SCORE，一个视觉重定位系统，通过采用语义标注的3D线图实现了前所未有的地图紧凑性。SCORE仅需要基于结构或基于学习的基线系统所需存储空间的0.01%-0.1%，同时保持了实用的精度和可比的运行时间。其关键创新是一种新颖的鲁棒估计机制——饱和共识最大化（Sat-CM），它通过根据最大似然以概率理由为内点关联分配递减的权重，从而泛化了经典的共识最大化（CM）。在语义匹配中一对多歧义导致的极端异常值比例（高达99.5%）下，当CM失效时，Sat-CM能够实现准确估计。为了确保计算效率，我们提出了一个用于全局求解Sat-CM公式的加速框架，并专门针对SCORE核心的透视-N-线问题进行了优化。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [499] [PIPE Planner: Pathwise Information Gain with Map Predictions for Indoor Robot Exploration](https://arxiv.org/abs/2503.07504)
> *PIPE 规划器：用于室内机器人探索的地图预测路径信息增益*

*Seungjae Baek, Brady Moon, Seungchan Kim, Muqing Cao, Cherie Ho, Sebastian Scherer, Jeong hwan Jeon* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 室内机器人探索, 路径信息增益, 地图预测, 自主探索, 传感器覆盖

**Comment:** 8 pages, 8 figures, IROS 2025

> **TL;DR:** PIPE 规划器提出了一种结合地图预测的路径信息增益方法，用于高效的室内机器人探索，解决了现有方法的计算挑战和高估问题，并展示了优于现有技术的性能。

**AI_Comments:** 这篇论文提出了一种新颖的方法，解决了机器人探索中信息增益估计的效率和准确性这一长期挑战。将地图预测集成以减轻高估，以及高效计算路径覆盖，是重要的创新点，显著提高了自主探索系统的实用性和性能。

<details>
  <summary>Details</summary>

**Motivation:** 在未知环境中进行自主探索需要估计行动的信息增益来指导规划决策。现有方法通常在离散路点计算信息增益，而路径积分虽然能提供更全面的估计，但往往计算量大、不可行且容易导致高估。

**Method:** 本文提出了路径信息增益与地图预测（PIPE）规划器，该规划器沿规划轨迹集成累积传感器覆盖，并利用地图预测来减轻高估。为了实现高效的路径覆盖计算，还引入了一种有效计算沿规划路径的预期观测掩码的方法，显著降低了计算开销。

**Result:** PIPE 规划器在真实世界平面图数据集上进行了验证，结果表明其性能优于最先进的基线方法。

**Conclusion:** 将预测性地图与路径信息增益相结合，能够实现高效且知情的探索。

> **ai_Abstract:** PIPE 规划器旨在解决自主探索中信息增益估计的挑战。它通过沿规划轨迹整合累积传感器覆盖并利用地图预测来减轻高估，从而高效地计算路径信息增益。该方法还引入了一种新颖的、高效的观测掩码计算方法。在真实世界数据集上的验证表明，PIPE 规划器性能优越，证明了将预测性地图与路径信息增益相结合对于高效室内机器人探索的益处。

> **摘要翻译:** 自主探索未知环境需要估计动作的信息增益来指导规划决策。虽然现有方法通常在离散路点计算信息增益，但路径积分提供了更全面的估计，但通常计算量大或不可行，并且容易高估。在这项工作中，我们提出了用于探索的路径信息增益与地图预测（PIPE）规划器，它沿规划轨迹集成累积传感器覆盖，同时利用地图预测来减轻高估。为了实现高效的路径覆盖计算，我们引入了一种有效计算沿规划路径的预期观测掩码的方法，显著降低了计算开销。我们在真实世界平面图数据集上验证了 PIPE，证明其性能优于最先进的基线。我们的结果突出了将预测性地图与路径信息增益相结合，以实现高效和知情探索的优势。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [513] [HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning](https://arxiv.org/abs/2508.00491)
> *HannesImitation：通过模仿学习实现Hannes假肢抓取*

*Carlo Alessi, Federico Vasile, Federico Ceola, Giulia Pasquale, Nicolò Boccardo, Lorenzo Natale* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 模仿学习, 假肢, 抓取, 扩散策略, 非结构化环境

**Comment:** Paper accepted at IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS)

> **TL;DR:** HannesImitation提出了一种基于模仿学习的方法，用于控制Hannes假肢在非结构化环境中进行抓取，并通过实验证明其优于传统方法。

**AI_Comments:** 该论文的创新点在于将模仿学习成功应用于假肢控制，解决了传统方法在非结构化环境中表现不佳的问题。通过引入HannesImitationPolicy和HannesImitationDataset，该研究为假肢的自主性和灵活性提升提供了新的思路，有望显著减轻用户认知负担，并拓宽假肢的应用场景。

<details>
  <summary>Details</summary>

**Motivation:** 当前假肢控制系统旨在通过增加自主性来减少用户认知负荷，但模仿学习在假肢控制中的应用尚未得到充分探索。弥合这一空白可以增强灵活性恢复，并使假肢设备在更不受限制的场景中运行。

**Method:** 该研究提出了HannesImitationPolicy，一种基于模仿学习的Hannes假肢控制方法，用于在非结构化环境中进行物体抓取。他们还引入了HannesImitationDataset，包含桌面、货架和人-假肢交接场景中的抓取演示数据。利用这些数据训练了一个单一的扩散策略，并将其部署到假肢上以预测手腕方向和手部闭合进行抓取。

**Result:** 实验评估表明，该策略在各种物体和条件下都能成功抓取。此外，该策略在非结构化场景中优于基于分割的视觉伺服控制器。

**Conclusion:** 通过模仿学习，HannesImitationPolicy能够有效地控制Hannes假肢在非结构化环境中进行抓取，并展现出优于传统视觉伺服控制器的性能，显著提升了假肢的自主性和灵活性。

> **ai_Abstract:** 本文提出HannesImitationPolicy，一种基于模仿学习的方法，用于控制Hannes假肢在非结构化环境中进行物体抓取。研究团队构建了HannesImitationDataset，并利用其中的抓取演示数据训练了一个单一的扩散策略。实验结果表明，该策略在多样化的物体和条件下均能成功抓取，并且在非结构化场景中表现优于传统的基于分割的视觉伺服控制器，为假肢控制带来了新的突破。

> **摘要翻译:** 假肢控制的最新进展集中于通过使用摄像头和其他感官输入来增加自主性。这些系统旨在通过自动控制某些自由度来减少用户的认知负荷。在机器人技术中，模仿学习已成为一种有前途的方法，用于学习抓取和复杂的操纵任务，同时简化了数据收集。然而，其在假肢控制中的应用在很大程度上仍未被探索。弥合这一差距可以增强灵活性恢复，并使假肢设备能够在更不受限制的场景中运行，即从演示中学习任务，而不是依赖手动注释的序列。为此，我们提出了HannesImitationPolicy，一种基于模仿学习的方法来控制Hannes假肢，从而能够在非结构化环境中抓取物体。此外，我们引入了HannesImitationDataset，其中包含桌面、货架和人-假肢交接场景中的抓取演示。我们利用这些数据训练了一个单一的扩散策略，并将其部署到假肢上以预测手腕方向和手部闭合进行抓取。实验评估表明，在各种物体和条件下都能成功抓取。最后，我们表明该策略在非结构化场景中优于基于分割的视觉伺服控制器。更多材料可在我们的项目页面获取：https://hsp-iit.github.io/HannesImitation

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [526] [Safe Navigation in Uncertain Crowded Environments Using Risk Adaptive CVaR Barrier Functions](https://arxiv.org/abs/2504.06513)
> *在不确定拥挤环境中基于风险自适应CVaR势函数安全导航*

*Xinyi Wang, Taekyung Kim, Bardh Hoxha, Georgios Fainekos, Dimitra Panagou* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 安全导航, 拥挤环境, 风险自适应, CVaR势函数, 动态区域势函数

**Comment:** 2025 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS). Project page: {https://lawliet9666.github.io/cvarbf/}

> **TL;DR:** 本文提出了一种基于风险自适应CVaR势函数和动态区域势函数的机器人导航方法，以在不确定拥挤环境中实现安全且优化的避障。

**AI_Comments:** 本文的创新点在于结合了风险自适应的CVaR势函数与动态区域势函数，这使得机器人在不确定且拥挤的环境中能够更智能地管理风险并实现主动避障。其在不确定性下优化安全性和可行性的能力，对于实际机器人部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人导航在动态、拥挤的环境中面临显著挑战，这主要源于障碍物模型中固有的不确定性。

**Method:** 本文提出了一种基于条件风险值势函数（CVaR-BF）的风险自适应方法，该方法自动调整风险水平以接受必要的最小风险。此外，还引入了一种动态区域势函数，通过评估机器人与障碍物之间的相对状态来表征碰撞可能性。通过将风险自适应与这种新函数相结合，该方法能够自适应地扩展安全裕度。

**Result:** 该方法在不确定性下，在安全性和优化可行性方面表现良好。通过比较和消融研究表明，该方法优于现有的社交导航方法，并验证了所提出框架的有效性。

**Conclusion:** 本文提出的基于风险自适应CVaR势函数和动态区域势函数的导航方法，能够有效提高机器人在不确定拥挤环境中的安全性和避障能力，并表现出优于现有方法的性能。

> **ai_Abstract:** 本文提出了一种在不确定拥挤环境中安全导航的风险自适应方法。该方法结合了条件风险值势函数（CVaR-BF）来自动调整风险水平，并引入了一种动态区域势函数来评估碰撞可能性。通过集成这两种机制，机器人能够自适应地扩大安全裕度，从而在动态环境中主动避障。实验结果表明，该方法在安全性和优化可行性方面表现出色，并优于现有社交导航方法。

> **摘要翻译:** 机器人导航在动态、拥挤的环境中，由于障碍物模型中固有的不确定性，带来了巨大的挑战。在这项工作中，我们提出了一种基于条件风险值势函数（CVaR-BF）的风险自适应方法，其中风险水平被自动调整以接受必要的最小风险，从而在不确定性下在安全性和优化可行性方面取得了良好性能。此外，我们引入了一种动态区域势函数，通过评估机器人与障碍物之间的相对状态来表征碰撞可能性。通过将风险自适应与这种新函数相结合，我们的方法自适应地扩展了安全裕度，使机器人能够在高度动态的环境中主动避开障碍物。比较和消融研究表明，我们的方法优于现有的社交导航方法，并验证了我们提出的框架的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [551] [Trends in Motion Prediction Toward Deployable and Generalizable Autonomy: A Revisit and Perspectives](https://arxiv.org/abs/2505.09074)
> *运动预测迈向可部署和泛化自主性的趋势：回顾与展望*

*Letian Wang, Marc-Antoine Lavoie, Sandro Papais, Barza Nisar, Yuxiao Chen, Wenhao Ding, Boris Ivanovic, Hao Shao, Abulikemu Abuduweili, Evan Cook, Yang Zhou, Peter Karkus, Jiachen Li, Changliu Liu, Marco Pavone, Steven Waslander* | **Category: cs.RO** | **Updated: 2025-07-31**

**Keywords:** 运动预测, 泛化, 可部署性, 自动驾驶, 机器人技术

**Comment:** Updated draft. 163 pages, 40 figures, 13 tables

> **TL;DR:** 这篇综述论文审视了运动预测领域，着重指出当前研究基准与实际部署和泛化能力之间的差距，并提出了未来研究方向以实现更实用的自主性。

**AI_Comments:** 这篇论文非常重要，因为它指出了当前运动预测研究的一个关键实际局限——即理想化基准与现实世界部署之间的差距。通过对现有方法进行分类并突出闭环集成和开放世界泛化等关键挑战，它为未来开发更鲁棒和适用的人工智能系统提供了宝贵的路线图。

<details>
  <summary>Details</summary>

**Motivation:** 当前的运动预测模型在现实世界部署时，难以泛化到开放世界条件并满足部署标准，这揭示了理想化的研究基准与现实世界复杂性之间的差距。本综述旨在弥补这一差距。

**Method:** 本综述重新审视了运动预测模型的泛化能力和可部署性，重点关注机器人、自动驾驶和人体运动的应用。论文提供了运动预测方法的全面分类，并深入研究了两个关键挑战：在闭环自主系统中实现可部署性，以及从有限场景泛化到开放世界设置。

**Result:** 本论文识别并讨论了运动预测在基准性能与现实世界可部署性/泛化能力之间的差距。它提供了一个全面的分类法，并突出了指导未来工作的关键开放挑战。

**Conclusion:** 本论文旨在通过突出关键的开放挑战，重新调整运动预测领域的研究方向，以促进不仅可衡量而且对实际应用有意义的进展。

> **ai_Abstract:** 这篇综述论文旨在解决运动预测模型在基准测试中表现出色，但在现实世界部署和泛化能力方面存在的关键差距。论文提供了一个全面的方法分类，并深入探讨了两个主要挑战：如何将运动预测集成到闭环自主系统中，以及如何实现对未见开放世界场景的鲁棒泛化。本研究旨在指导未来研究，以推动机器人、自动驾驶和人体运动预测领域更具实用性和影响力的进展。

> **摘要翻译:** 运动预测，即对未来智能体状态或场景演变的预测，植根于人类认知，连接着感知与决策。它使机器人和自动驾驶汽车等智能系统能够在动态、有人参与的环境中安全行动，并为更广泛的时间序列推理挑战提供信息。随着方法、表示和数据集的进步，该领域取得了快速发展，这反映在快速演变的基准测试结果中。然而，当最先进的方法部署到现实世界时，它们往往难以泛化到开放世界条件，并且达不到部署标准。这揭示了研究基准（通常是理想化或不适定）与现实世界复杂性之间的差距。
为了弥补这一差距，本综述重新审视了运动预测模型的泛化能力和可部署性，重点关注机器人、自动驾驶和人体运动的应用。我们首先提供了运动预测方法的全面分类，涵盖表示、建模策略、应用领域和评估协议。然后，我们研究了两个关键挑战：（1）如何推动运动预测模型达到现实的部署标准，即运动预测不是独立运行，而是作为闭环自主堆栈的一个模块——它从定位和感知获取输入，并为下游规划和控制提供信息。(2) 如何将运动预测模型从有限的已知场景/数据集泛化到开放世界设置。在整篇论文中，我们强调了关键的开放挑战，以指导未来的工作，旨在重新调整社区的努力方向，促进不仅可衡量而且对实际应用有意义的进展。本论文对应的项目网页可在 https://trends-in-motion-prediction-2025.github.io/ 找到。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [554] [A Segmented Robot Grasping Perception Neural Network for Edge AI](https://arxiv.org/abs/2507.13970)
> *边缘AI分段式机器人抓取感知神经网络*

*Casper Bröcheler, Thomas Vroom, Derrick Timmermans, Alan van den Akker, Guangzhi Tang, Charalampos S. Kouzinopoulos, Rico Möckel* | **Category: cs.RO, cs.AI, I.2; I.2.9; I.2.10** | **Updated: 2025-08-01**

**Keywords:** 机器人抓取, 边缘AI, 神经网络, 片上系统, 实时感知

**Comment:** Accepted by SMC 2025

> **TL;DR:** 该研究在边缘AI设备上实现了低功耗、实时机器人抓取感知的深度学习模型。

**AI_Comments:** 该论文的创新点在于将复杂的6自由度机器人抓取感知神经网络成功部署到低功耗边缘AI芯片上，并通过硬件感知优化实现了片上实时推理。这对于推动机器人技术在资源受限环境下的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人抓取是一项复杂的任务，需要精确的感知和控制。在资源受限的环境中，将深度学习模型部署到边缘设备可以实现低延迟和低功耗的实时抓取，从而解决现有挑战。

**Method:** 本文在GAP9 RISC-V片上系统上实现了“热图引导抓取检测”这一端到端框架，用于检测6自由度抓取姿态。该模型通过硬件感知技术（包括输入维度降低、模型分区和量化）进行了优化。

**Result:** 在GraspNet-1Billion基准测试上的实验评估验证了完全片上推理的可行性。

**Conclusion:** 研究结果突出了低功耗微控制器在实现实时、自主机器人操作方面的巨大潜力。

> **ai_Abstract:** 本文介绍了一种针对边缘AI的机器人抓取感知神经网络，旨在解决资源受限环境下实时抓取的挑战。研究人员在GAP9 RISC-V片上系统上实现了“热图引导抓取检测”框架，用于6自由度抓取姿态检测，并采用硬件感知优化技术。实验结果证实了在低功耗微控制器上实现完全片上推理的可行性，展示了其在实时自主操作中的巨大潜力。

> **摘要翻译:** 机器人抓取是机器人可靠地固定和操纵不同形状、大小和方向物体的能力，这是一项复杂的任务，需要精确的感知和控制。深度神经网络通过学习物体丰富而抽象的表示，在抓取合成方面取得了显著成功。当这些模型部署在边缘时，可以实现低延迟、低功耗的推理，从而使实时抓取在资源受限的环境中变得可行。这项工作在GAP9 RISC-V片上系统上实现了热图引导抓取检测，这是一个用于检测6自由度抓取姿态的端到端框架。该模型通过硬件感知技术进行优化，包括输入维度降低、模型分区和量化。在GraspNet-1Billion基准测试上的实验评估验证了完全片上推理的可行性，突出了低功耗微控制器在实时、自主操作方面的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [566] [H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation](https://arxiv.org/abs/2507.23523)
> *H-RDT：人类操作增强的双臂机器人操作*

*Hongzhe Bi, Lingxuan Wu, Tianwei Lin, Hengkai Tan, Zhizhong Su, Hang Su, Jun Zhu* | **Category: cs.RO, cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 模仿学习, 机器人操作, 人类操作数据, 扩散Transformer, 双臂机器人

**Comment:** 

> **TL;DR:** H-RDT利用大规模人类操作视频数据预训练，然后通过跨实体微调，显著提升了双臂机器人操作的学习效率和性能，解决了机器人示教数据稀缺的挑战。

**AI_Comments:** 这篇论文的创新点在于提出了利用大规模人类操作视频数据作为行为先验来解决机器人模仿学习中数据稀缺的问题，特别是通过两阶段训练范式和跨实体微调，有效地将人类的自然操作策略迁移到机器人上。其重要性在于为机器人基础模型提供了一种新的、高效的预训练策略，提升了机器人学习的性能和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 机器人操作的模仿学习面临高质量大规模机器人示教数据稀缺的根本挑战。现有机器人基础模型虽然通过跨实体数据集预训练来增加数据规模，但由于不同机器人形态和动作空间的差异，统一训练面临显著限制。

**Method:** 提出H-RDT（Human to Robotics Diffusion Transformer），利用人类操作数据增强机器人操作能力。关键在于大规模以自我为中心的人类操作视频及其配对的3D手部姿态标注提供了丰富的行为先验。采用两阶段训练范式：(1) 在大规模以自我为中心的人类操作数据上进行预训练；(2) 使用模块化动作编码器和解码器在机器人特定数据上进行跨实体微调。H-RDT基于一个20亿参数的扩散Transformer架构，并使用流匹配来建模复杂的动作分布。

**Result:** H-RDT在仿真和真实世界实验、单任务和多任务场景、少样本学习和鲁棒性评估中，均优于从头训练和现有SOTA方法（包括Pi0和RDT）。在仿真和真实世界实验中，相对于从头训练分别实现了13.9%和40.5%的显著提升。

**Conclusion:** 结果验证了核心假设：人类操作数据可以作为学习双臂机器人操作策略的强大基础。

> **ai_Abstract:** 本文提出了H-RDT，一种利用大规模以自我为中心的人类操作视频（含3D手部姿态）增强双臂机器人操作能力的新方法。H-RDT采用两阶段训练范式：先在人类数据上预训练，再在机器人特定数据上进行跨实体微调。该方法基于20亿参数的扩散Transformer架构，通过流匹配建模动作分布。实验证明，H-RDT在多种场景下显著优于现有SOTA方法和从头训练，验证了人类操作数据作为机器人操作策略学习基础的有效性。

> **摘要翻译:** 机器人操作的模仿学习面临一个根本性挑战：缺乏大规模、高质量的机器人演示数据。最近的机器人基础模型通常在跨实体机器人数据集上进行预训练以增加数据规模，但它们面临显著限制，因为不同机器人实体的多样化形态和动作空间使得统一训练变得困难。在本文中，我们提出了H-RDT（Human to Robotics Diffusion Transformer），一种利用人类操作数据增强机器人操作能力的新方法。我们的关键见解是，大规模以自我为中心的人类操作视频及其配对的3D手部姿态标注提供了丰富的行为先验，这些先验捕捉了自然的操作策略，并且可以有益于机器人策略学习。我们引入了一种两阶段训练范式：(1) 在大规模以自我为中心的人类操作数据上进行预训练，以及 (2) 使用模块化动作编码器和解码器在机器人特定数据上进行跨实体微调。H-RDT基于一个20亿参数的扩散Transformer架构，并使用流匹配来建模复杂的动作分布。涵盖仿真和真实世界实验、单任务和多任务场景，以及少样本学习和鲁棒性评估的广泛评估表明，H-RDT优于从头训练和现有最先进的方法，包括Pi0和RDT，相对于从头训练在仿真和真实世界实验中分别实现了13.9%和40.5%的显著改进。结果验证了我们的核心假设，即人类操作数据可以作为学习双臂机器人操作策略的强大基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [576] [SHIELD: Safety on Humanoids via CBFs In Expectation on Learned Dynamics](https://arxiv.org/abs/2505.11494)
> *SHIELD：通过学习动力学的期望CBF实现类人机器人安全*

*Lizhi Yang, Blake Werner, Ryan K. Cosner, David Fridovich-Keil, Preston Culbertson, Aaron D. Ames* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 类人机器人安全, 控制障碍函数（CBF）, 学习动力学, 概率安全, 强化学习

**Comment:** Video at https://youtu.be/-Qv1wR4jfj4. To appear at IROS 2025

> **TL;DR:** SHIELD提出了一种分层安全框架，结合学习到的不确定性动力学模型和随机控制障碍函数（CBF），为类人机器人提供概率安全保障，解决了现有黑盒控制器安全保障不足的问题。

**AI_Comments:** SHIELD的创新之处在于其将数据驱动的随机动力学模型与基于CBF的正式安全保障相结合，有效弥合了模型无关型学习控制器与模型依赖型安全机制之间的鸿沟。这种分层、微创的设计使其能够轻松集成到现有机器人系统中，为高动态、不确定环境中的类人机器人安全提供了实用的解决方案。其重要性在于，它为部署基于RL的复杂机器人控制策略提供了急需的安全保障，尤其是在实际硬件上进行了验证，增强了其在现实世界应用中的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 机器人学习产生的“黑盒”控制器在复杂任务（如类人机器人动态运动）中非常有效，但确保动态安全（即约束满足）对于这些策略仍然具有挑战性。强化学习（RL）通过奖励工程启发式地嵌入约束，但添加或修改约束需要重新训练。基于模型的方法（如控制障碍函数CBF）能够实现运行时约束规范并提供形式化保证，但需要精确的动力学模型。本文旨在弥合这一差距，为现有的学习控制器提供概率安全保障。

**Method:** SHIELD是一个分层安全框架，它通过以下两点弥合了现有方法的不足：1) 训练一个生成式、随机动力学残差模型，使用来自标称控制器硬件运行的真实世界数据，以捕获系统行为和不确定性；2) 在标称（学习到的运动）控制器之上添加一个安全层，该层通过随机离散时间CBF公式利用上述模型，以概率方式强制执行安全约束。其结果是一个微创的安全层，可以添加到现有的自主堆栈中，以提供平衡风险和性能的概率安全保障。

**Result:** 在Unitree G1类人机器人上的硬件实验表明，SHIELD能够使用标称（未知）RL控制器和板载感知，在各种室内外环境中实现安全导航（避障）。

**Conclusion:** SHIELD框架通过结合学习到的不确定性动力学模型和随机CBF，为类人机器人上的黑盒学习控制器提供了一种有效且微创的概率安全保障方法，成功实现了动态安全和性能的平衡。

> **ai_Abstract:** SHIELD是一个针对类人机器人的分层安全框架，旨在解决现有“黑盒”学习控制器在动态安全保障方面的不足。该框架首先利用真实世界数据训练一个生成式、随机动力学残差模型以捕获系统不确定性，然后在此基础上，通过一个利用随机离散时间控制障碍函数（CBF）的安全层，为现有学习控制器提供概率性的安全保障。SHIELD是一个微创解决方案，能够平衡风险与性能。实验证明，其在Unitree G1类人机器人上成功实现了在复杂环境中的安全导航和避障。

> **摘要翻译:** 机器人学习已经为复杂任务（如类人机器人动态运动）产生了非常有效的“黑盒”控制器。然而，对于此类策略而言，确保动态安全（即约束满足）仍然具有挑战性。强化学习（RL）通过奖励工程启发式地嵌入约束，但添加或修改约束需要重新训练。基于模型的方法，如控制障碍函数（CBF），能够实现运行时约束规范并提供形式化保证，但需要精确的动力学模型。本文提出了SHIELD，一个分层安全框架，通过以下方式弥合了这一差距：(1) 使用来自标称控制器硬件运行的真实世界数据训练一个生成式、随机动力学残差模型，以捕获系统行为和不确定性；(2) 在标称（学习到的运动）控制器之上添加一个安全层，该层通过随机离散时间CBF公式利用此模型，以概率方式强制执行安全约束。其结果是一个微创的安全层，可以添加到现有的自主堆栈中，以提供平衡风险和性能的概率安全保障。在Unitree G1类人机器人上的硬件实验中，SHIELD使用标称（未知）RL控制器和板载感知，通过各种室内外环境实现了安全导航（避障）。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [596] [Multi-robot LiDAR SLAM: a practical case study in underground tunnel environments](https://arxiv.org/abs/2507.21553)
> *多机器人激光雷达SLAM：地下隧道环境中的一个实际案例研究*

*Federica Di Lauro, Domenico G. Sorrenti, Miguel Angel Sotelo* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 多机器人SLAM, 激光雷达, 回环检测, 地下隧道, 启发式方法

**Comment:** 14 pages, 14 figures

> **TL;DR:** 本文分析了去中心化多机器人激光雷达SLAM的局限性，发现回环检测是主要失败源，并提出了一种新的启发式方法来克服这些限制，特别针对地下隧道环境。

**AI_Comments:** 本文的创新点在于识别并解决了一个多机器人去中心化激光雷D SLAM系统中的关键问题——回环检测的误报。其重要性在于提供了一种实用的解决方案，并针对极具挑战性的地下隧道环境进行了案例研究，这对于实际应用具有重要意义。同时，它也为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 发现去中心化激光雷达SLAM系统中回环检测产生过多误报，导致系统失败，因此需要克服这些限制。

**Method:** 分析了去中心化激光雷达SLAM系统的流程，并开发并提出了一种新的启发式方法来克服回环检测中误报过多的问题。研究环境是具有挑战性的地下隧道。

**Result:** 发现回环检测是去中心化多机器人激光雷达SLAM系统失败的一个重要来源，即产生过多的误报。并提出了一种新的启发式方法来克服这些限制。

**Conclusion:** 本文分析了多机器人激光雷达SLAM的局限性，特别是回环检测中的误报问题，并提出了一种新的启发式方法来解决此问题，同时指出了潜在的未充分探索的研究领域。

> **ai_Abstract:** 本文研究了多机器人激光雷达SLAM在地下隧道环境中的应用，特别关注去中心化系统的局限性。作者分析发现，回环检测是导致系统失败的主要原因，因为它产生了过多的误报。为了解决这一问题，论文提出了一种新的启发式方法。此外，文章还指出了未来值得探索的研究方向。

> **摘要翻译:** 多机器人SLAM旨在利用多个机器人进行定位和构建地图，并使其相互交互。在本文描述的工作中，我们分析了一个去中心化激光雷达SLAM系统的流程，以研究现有技术的当前局限性，我们发现了一个重要的失败来源，即回环检测是太多误报的来源。因此，我们开发并提出了一种新的启发式方法来克服这些局限性。这项工作所参考的环境是极具挑战性的地下隧道案例。我们还强调了仍未充分探索的潜在新研究领域。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [616] [Benchmarking Massively Parallelized Multi-Task Reinforcement Learning for Robotics Tasks](https://arxiv.org/abs/2507.23172)
> *机器人任务中大规模并行多任务强化学习的基准测试*

*Viraj Joshi, Zifan Xu, Bo Liu, Peter Stone, Amy Zhang* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 多任务强化学习, 大规模并行, 机器人, 基准测试, IsaacGym

**Comment:** RLC 2025

> **TL;DR:** 本文介绍了MTBench，一个用于机器人任务的大规模并行多任务强化学习基准，旨在评估现有算法并探索大规模并行带来的挑战。

**AI_Comments:** 这项工作具有重要意义，因为它填补了大规模并行化在多任务强化学习（MTRL）领域基准测试的空白。通过引入MTBench，作者提供了一个统一且高效的平台，促进了对on-policy MTRL算法的研究，这些算法在高并行度下具有显著潜力。它不仅验证了并行化带来的速度优势，也明确指出了该领域面临的独特挑战，为未来的研究方向提供了宝贵的见解。其开源性质也将极大推动社区的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多任务强化学习(MTRL)研究大多局限于低并行度下的离策略方法，而未能充分利用在策略算法在高并行度下表现出的渐近性能优势。大规模并行化训练能显著加速数据收集并实现多任务数据多样性收集，因此需要一个能结合大规模并行化与MTRL的基准来弥补这一空白。

**Method:** 作者引入了一个名为MTBench的大规模并行多任务机器人基准，该基准是开源的，包含了50个操作任务和20个运动任务，均在GPU加速模拟器IsaacGym中实现。MTBench还整合了四种基础RL算法和七种最先进的MTRL算法及架构，提供了一个统一的评估框架。

**Result:** 通过广泛的实验，MTBench在评估MTRL方法方面展现出卓越的速度，同时也揭示了大规模并行与MTRL结合时所产生的独特挑战。

**Conclusion:** MTBench为机器人领域的大规模并行多任务强化学习提供了一个重要的评估工具，它不仅验证了这种方法的潜力，也指出了未来研究需要克服的挑战。

> **ai_Abstract:** 该论文介绍了MTBench，一个开源的大规模并行多任务强化学习基准，专为机器人任务设计。该基准旨在解决现有MTRL研究在利用大规模并行化方面的不足，特别是对于在策略算法。MTBench包含了70个不同的机器人任务，并集成了多种RL和MTRL算法，利用GPU加速模拟器IsaacGym实现了高效评估。研究结果表明MTBench能显著加速MTRL方法的评估，并揭示了大规模并行与MTRL结合时的新挑战。

> **摘要翻译:** 多任务强化学习（MTRL）已成为将强化学习（RL）应用于一系列复杂现实世界机器人任务的关键训练范式，这些任务需要通用且鲁棒的策略。与此同时，大规模并行化训练越来越受欢迎，它不仅通过GPU加速模拟显著加快了数据收集，还通过并行模拟异构场景实现了多任务数据的多样化收集。然而，现有的MTRL研究主要局限于低并行度下的SAC等离策略方法。MTRL可以利用在策略算法更高的渐近性能，这些算法的批处理需要来自当前策略的数据，因此可以利用GPU加速模拟提供的大规模并行化。为了弥补这一差距，我们引入了一个大规模并行化的机器人多任务基准（MTBench），这是一个开源基准，具有50个操作任务和20个运动任务的广泛分布，使用GPU加速模拟器IsaacGym实现。MTBench还包括四种基础RL算法与七种最先进的MTRL算法和架构，提供了一个统一的性能评估框架。我们广泛的实验突出了使用MTBench评估MTRL方法的卓越速度，同时也揭示了大规模并行与MTRL结合时出现的独特挑战。代码可在https://github.com/Viraj-Joshi/MTBench 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [623] [XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation](https://arxiv.org/abs/2508.00097)
> *XRoboToolkit：一个用于机器人远程操作的跨平台框架*

*Zhigen Zhao, Liuchuan Yu, Ke Jing, Ning Yang* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 机器人远程操作, 跨平台框架, 扩展现实, 数据集收集, 视觉-语言-动作模型

**Comment:** 6 pages, 6 figures, project link: https://github.com/XR-Robotics

> **TL;DR:** XRoboToolkit是一个基于OpenXR的XR机器人远程操作跨平台框架，旨在解决大规模高质量机器人演示数据集收集中的可扩展性、设置复杂性和数据质量问题。

**AI_Comments:** 该论文提出了一种创新的跨平台XR远程操作框架XRoboToolkit，有效解决了当前机器人数据收集面临的可扩展性和数据质量挑战。其基于OpenXR标准和模块化设计使其具有高度的兼容性和实用性，有望极大地推动高质量机器人演示数据集的生成，进而加速视觉-语言-动作模型的发展。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言-动作模型的快速发展对大规模、高质量的机器人演示数据集产生了迫切需求。然而，当前的数据收集方法（远程操作）存在可扩展性有限、设置程序复杂和数据质量不佳的问题。

**Method:** 本文提出了XRoboToolkit，一个基于OpenXR标准的扩展现实（XR）机器人远程操作跨平台框架。该系统具有低延迟立体视觉反馈、基于优化的逆运动学，并支持多种跟踪模式，包括头部、控制器、手部和辅助运动跟踪器。其模块化架构实现了机器人平台和仿真环境的无缝集成。

**Result:** 该框架通过精确操作任务展示了其有效性，并通过训练展现出强大自主性能的视觉-语言-动作模型来验证了数据质量。

**Conclusion:** XRoboToolkit为大规模、高质量机器人演示数据集的收集提供了一个可扩展且高效的解决方案，有效解决了现有远程操作方法的局限性，并支持了强大VLA模型的训练。

> **ai_Abstract:** XRoboToolkit是一个基于OpenXR的跨平台扩展现实机器人远程操作框架，旨在解决当前机器人数据收集方法在可扩展性、设置复杂性和数据质量方面的不足。它提供低延迟视觉反馈、优化逆运动学和多模态跟踪支持，并具有模块化架构以实现广泛的平台集成。该框架已通过精确操作任务和训练高性能VLA模型验证了其有效性和数据质量。

> **摘要翻译:** 视觉-语言-动作模型的快速发展对大规模、高质量的机器人演示数据集产生了迫切需求。尽管远程操作是数据收集的主要方法，但当前的方法存在可扩展性有限、设置程序复杂和数据质量不佳的问题。本文提出了XRoboToolkit，一个基于OpenXR标准的扩展现实机器人远程操作跨平台框架。该系统具有低延迟立体视觉反馈、基于优化的逆运动学，并支持多种跟踪模式，包括头部、控制器、手部和辅助运动跟踪器。XRoboToolkit的模块化架构实现了机器人平台和仿真环境的无缝集成，涵盖了精密机械臂、移动机器人和灵巧手。我们通过精确操作任务展示了该框架的有效性，并通过训练展现出强大自主性能的视觉-语言-动作模型来验证了数据质量。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [631] [Learning to Drift with Individual Wheel Drive: Maneuvering Autonomous Vehicle at the Handling Limits](https://arxiv.org/abs/2507.23339)
> *学习使用独立轮驱动进行漂移：在操纵极限下操控自动驾驶汽车*

*Yihan Zhou, Yiwen Lu, Bo Yang, Jiayun Li, Yilin Mo* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 漂移, 强化学习, 仿真到现实差距, 独立轮驱动, 自动驾驶汽车

**Comment:** 

> **TL;DR:** 本文提出一种基于强化学习的方法，结合领域随机化和并行仿真，使自动驾驶汽车能够在仿真和现实中有效漂移，弥补了仿真到现实的差距。

**AI_Comments:** 本文的创新之处在于通过结合并行仿真和领域随机化，有效弥合了漂移这种挑战性任务的仿真到现实差距。使用开源的独立轮驱动遥控车平台也增强了研究的可复现性。其重要性在于提升了自动驾驶汽车在操控极限下的安全性。

<details>
  <summary>Details</summary>

**Motivation:** 漂移对于在摩擦极限下的紧急情况处理至关重要。现有的强化学习方法在漂移控制中存在显著的仿真到现实差距问题。

**Method:** 提出了一种结合GPU加速并行仿真和系统领域随机化的强化学习框架。该方法在仿真和定制的1/10比例独立轮驱动（IWD）遥控车平台上进行了验证。

**Result:** 在各种场景（从稳态圆形漂移到方向转换和可变曲率路径跟踪）中，该方法在仿真和现实环境中都能实现精确的轨迹跟踪，同时在复杂机动过程中保持受控的侧滑角。

**Conclusion:** 结合领域随机化和并行仿真的强化学习框架有效弥合了自动漂移的仿真到现实差距，从而实现了在操控极限下的精确控制。

> **ai_Abstract:** 本文旨在解决强化学习在自动驾驶车辆漂移控制中存在的仿真到现实差距问题。为此，提出了一种结合GPU加速并行仿真和系统领域随机化的强化学习框架。该方法在仿真和1/10比例的独立轮驱动遥控车上进行了验证，结果表明其在复杂机动中能够实现精确的轨迹跟踪和受控的侧滑角，无论是在仿真还是现实环境中，从而证明了其在车辆摩擦极限下操控的有效性。

> **摘要翻译:** 漂移，其特点是在高侧滑角下控制车辆运动，对于在摩擦极限下安全处理紧急情况至关重要。尽管最近的强化学习方法在漂移控制方面显示出前景，但它们面临显著的仿真到现实差距问题，因为在仿真中表现良好的策略在转移到物理系统时往往会失败。在本文中，我们提出了一种结合GPU加速并行仿真和系统领域随机化的强化学习框架，有效弥合了这一差距。所提出的方法在仿真以及定制设计和开源的1/10比例独立轮驱动（IWD）遥控车平台上进行了验证，该平台具有独立的轮速控制功能。从稳态圆形漂移到方向转换和可变曲率路径跟踪的各种场景下的实验表明，我们的方法在仿真和现实环境中都能实现精确的轨迹跟踪，同时在复杂机动过程中保持受控的侧滑角。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [634] [OmniUnet: A Multimodal Network for Unstructured Terrain Segmentation on Planetary Rovers Using RGB, Depth, and Thermal Imagery](https://arxiv.org/abs/2508.00580)
> *OmniUnet：一种用于行星探测器非结构化地形分割的多模态网络，利用RGB、深度和热图像*

*Raul Castilla-Arquillo, Carlos Perez-del-Pulgar, Levin Gerdes, Alfonso Garcia-Cerezo, Miguel A. Olivares-Mendez* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 多模态网络, 地形分割, 行星探测器, 热图像, 语义分割

**Comment:** 

> **TL;DR:** OmniUnet是一种基于Transformer的多模态网络，利用RGB、深度和热图像对行星探测器上的非结构化地形进行语义分割，并在模拟火星环境中表现出色，推理时间快，适用于机器人部署，同时数据集和软件已公开。

**AI_Comments:** 该论文的创新点在于提出了OmniUnet，一个基于Transformer的多模态网络，用于结合RGB、深度和热图像进行非结构化地形分割，特别强调了热图像在评估地形安全方面的价值。通过开发定制传感器和在模拟火星环境中收集真实世界数据集（并公开），为行星机器人领域的多模态地形感知研究做出了重要贡献。模型在资源受限设备上的出色性能和快速推理时间也突出了其在实际部署中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在非结构化环境中进行机器人导航需要多模态感知系统以支持安全导航，因为多模态可以整合不同传感器收集的互补信息。然而，这些异构数据需要专门设计的机器学习算法来处理，并且需要识别哪些传感器模态对于目标环境的导航最具信息量。在火星探测中，热图像已被证明对于评估地形安全具有价值，因为不同土壤类型之间存在热行为差异。

**Method:** 本研究提出了一种名为OmniUnet的基于Transformer的神经网络架构，用于使用RGB、深度和热（RGB-D-T）图像进行语义分割。开发了一个定制的多模态传感器外壳，并安装在火星探测器自主测试平台（MaRTA）上，用于在西班牙北部巴德纳斯半沙漠收集多模态数据集。该数据集的一个子集经过手动标注以支持网络的监督训练。

**Result:** 该模型在定量和定性评估中均表现出色，实现了80.37%的像素精度，并在分割复杂的非结构化地形方面展现出强大的性能。在资源受限的计算机（Jetson Orin Nano）上进行的推理测试平均预测时间为673毫秒，证实了其在机器人上部署的适用性。

**Conclusion:** OmniUnet网络及其软件实现在资源受限的硬件上表现出快速的推理速度，证实了其在机器人上部署的适用性。此外，网络软件实现和标注数据集已公开，以支持行星机器人多模态地形感知领域的未来研究。

> **ai_Abstract:** 本研究提出了一种名为OmniUnet的基于Transformer的神经网络架构，用于利用RGB、深度和热（RGB-D-T）图像对行星探测器上的非结构化地形进行语义分割。为了收集多模态数据，研究人员开发了一个定制的传感器外壳并安装在火星探测器自主测试平台（MaRTA）上，在模拟火星环境的西班牙巴德纳斯半沙漠中收集了数据集。该数据集的一个子集经过手动标注用于模型训练。OmniUnet在定性和定量评估中均表现出色，实现了80.37%的像素精度，并能有效分割复杂的非结构化地形。在资源受限的Jetson Orin Nano上，其平均预测时间为673毫秒，证明了其适用于机器人部署。该网络的软件实现和标注数据集已公开，以支持未来的研究。

> **摘要翻译:** 机器人在非结构化环境中导航需要多模态感知系统来支持安全导航。多模态能够整合不同传感器收集的互补信息。然而，这些信息必须由专门设计用于利用异构数据的机器学习算法进行处理。此外，有必要确定哪些传感器模态对于目标环境的导航最具信息量。在火星探测中，热图像已被证明对于评估地形安全具有价值，因为不同土壤类型之间存在热行为差异。这项工作提出了OmniUnet，一种基于Transformer的神经网络架构，用于使用RGB、深度和热（RGB-D-T）图像进行语义分割。开发了一个定制的多模态传感器外壳，并使用3D打印技术制作并安装在火星探测器自主测试平台（MaRTA）上，以在西班牙北部巴德纳斯半沙漠收集多模态数据集。该地点作为火星表面的代表性环境，具有沙子、基岩和致密土壤等地形类型。该数据集的一个子集经过手动标注以支持网络的监督训练。该模型在定量和定性方面都进行了评估，实现了80.37%的像素精度，并在分割复杂的非结构化地形方面表现出强大的性能。推理测试在资源受限的计算机（Jetson Orin Nano）上产生了673毫秒的平均预测时间，证实了其在机器人上部署的适用性。该网络的软件实现和标注数据集已公开，以支持行星机器人多模态地形感知领域的未来研究。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [712] [On-Device Diffusion Transformer Policy for Efficient Robot Manipulation](https://arxiv.org/abs/2508.00697)
> *机器人高效操作的设备端扩散变换器策略*

*Yiming Wu, Huan Wang, Zhenghao Chen, Jianxin Pang, Dong Xu* | **Category: cs.RO, cs.AI, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 扩散策略, 机器人操作, 设备端, 网络压缩, 实时部署

**Comment:** ICCV 2025

> **TL;DR:** LightDP通过网络压缩和减少采样步骤，使扩散策略能够在资源受限的移动设备上实现高效、实时的机器人操作。

**AI_Comments:** 这篇论文的创新点在于提出了LightDP框架，专门解决了扩散策略在资源受限移动设备上部署的计算效率问题。通过结合网络压缩（特别是针对去噪网络的剪枝和再训练）与一致性蒸馏来减少采样步骤，它提供了一个实用的解决方案。其重要性在于推动了扩散策略从理论研究走向实际的移动机器人应用，为未来在边缘设备上部署复杂的AI模型提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 扩散策略在机器人操作任务中取得了显著进展，但由于计算效率低下和内存占用大，其在资源受限的移动平台上的应用仍然具有挑战性。

**Method:** 本文提出了LightDP框架，通过两种核心策略解决计算瓶颈：去噪模块的网络压缩和所需采样步骤的减少。首先，对现有扩散策略架构进行计算分析，确定去噪网络是延迟的主要原因。为克服传统剪枝方法造成的性能下降，引入了统一的剪枝和再训练流程，优化了模型剪枝后的可恢复性。此外，将剪枝技术与一致性蒸馏相结合，在保持动作预测准确性的同时有效减少采样步骤。

**Result:** LightDP在PushT、Robomimic、CALVIN和LIBERO等标准数据集上实现了移动设备上的实时动作预测，并具有竞争性性能。广泛的真实世界实验表明，LightDP的性能与最先进的扩散策略相当。

**Conclusion:** LightDP是实现扩散策略在资源受限环境中实际部署的重要一步，它能够在移动设备上实现实时且性能具有竞争力的机器人操作。

> **ai_Abstract:** LightDP是一个新颖的框架，旨在加速扩散策略在资源受限移动设备上的实时部署。通过对去噪网络进行网络压缩和减少采样步骤，LightDP解决了计算效率和内存占用问题。它引入了统一的剪枝和再训练流程，并结合剪枝与一致性蒸馏，以在保持性能的同时提高效率。实验证明，LightDP在移动设备上实现了实时动作预测，并在多种标准数据集和真实世界场景中表现出与最先进扩散策略相当的性能。

> **摘要翻译:** 扩散策略通过模仿学习显著推动了机器人操作任务的发展，但由于计算效率低下和内存占用大，其在资源受限的移动平台上的应用仍然面临挑战。在本文中，我们提出了LightDP，一个专门设计用于加速扩散策略以在移动设备上实时部署的新颖框架。LightDP通过两个核心策略解决了计算瓶颈：去噪模块的网络压缩和所需采样步骤的减少。我们首先对现有扩散策略架构进行了广泛的计算分析，确定去噪网络是延迟的主要贡献者。为了克服传统剪枝方法通常伴随的性能下降，我们引入了一个统一的剪枝和再训练流程，明确优化了模型剪枝后的可恢复性。此外，我们将剪枝技术与一致性蒸馏相结合，以在保持动作预测准确性的同时有效减少采样步骤。在标准数据集（即PushT、Robomimic、CALVIN和LIBERO）上的实验评估表明，LightDP在移动设备上实现了实时动作预测，并具有竞争性性能，标志着扩散策略在资源受限环境中实际部署的重要一步。广泛的真实世界实验也表明，所提出的LightDP可以实现与最先进的扩散策略相当的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cssc'></a>
## cs.SC 

### [156] [A Variant of Non-uniform Cylindrical Algebraic Decomposition for Real Quantifier Elimination](https://arxiv.org/abs/2508.00505)
> *实数量词消去中非均匀柱形代数分解的一种变体*

*Jasper Nalbach, Erika Ábrahám* | **Category: cs.SC** | **Updated: 2025-08-01**

**Keywords:** 柱形代数分解, 量词消去, SMT求解, 非均匀CAD, 算法变体

**Comment:** 

> **TL;DR:** 本文提出了一种非均匀柱形代数分解（NuCAD）的新变体，用于实数量词消去和SMT求解，并提供了实现和实验评估。

**AI_Comments:** 这项工作的创新点在于首次提供了非均匀柱形代数分解（NuCAD）的一个完整实现，并将其应用范围扩展到SMT求解，而不仅仅是量词消去。其重要性在于，通过提供一个可行的NuCAD变体，有望为解决实代数问题的复杂性提供新的途径，并促进SMT求解器的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的柱形代数分解（CAD）方法复杂度高（双指数），且NuCAD之前没有完整的实现，限制了其在实数量词消去和SMT求解中的应用。

**Method:** 本文提出了一种新的非均匀柱形代数分解（NuCAD）变体，用于实数多项式量词消去和SMT求解。该方法包含了实现，并通过实验与Cylindrical Algebraic Covering (CAlC) 进行了比较评估。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了一种非均匀柱形代数分解（NuCAD）的新变体，旨在解决实数多项式量词消去和SMT求解问题。鉴于现有NuCAD缺乏完整实现，作者提供了该新变体的实现，并通过实验与Cylindrical Algebraic Covering (CAlC) 进行了比较评估，以期改善CAD方法的双指数复杂度。

> **摘要翻译:** 柱形代数分解（CAD）方法是目前实践中用于解决实代数问题的唯一完整算法。为了改善其双指数复杂性，不同的探索引导适应性方法试图避免一些计算。第一个这样的适应性方法名为 NLSAT，随后是非均匀 CAD（NuCAD）和柱形代数覆盖（CAlC）。NLSAT 和 CAlC 都已在 SMT 求解器中开发和实现用于可满足性检查，并且 CAlC 最近也适用于量词消去。然而，NuCAD 仅设计用于量词消去，并且在这项工作之前没有完整的实现。
在本文中，我们提出了一种用于实数量词消去和 SMT 求解的 NuCAD 新变体，提供了实现，并通过实验将其与 CAlC 进行比较来评估该方法。

</details>

[⬆️ 返回分类顶部](#cssc) | [⬆️ 返回总目录](#toc)

---

### [176] [Projective Delineability for Single Cell Construction](https://arxiv.org/abs/2508.00512)
> *单细胞构建中的投影可描绘性*

*Jasper Nalbach, Lucas Michel, Erika Ábrahám, Christopher W. Brown, James H. Davenport, Matthew England, Pierre Mathonet, Naïm Zénaïdi* | **Category: cs.SC** | **Updated: 2025-08-01**

**Keywords:** 柱形代数分解, 单细胞构建, 投影可描绘性, 量词消除, SMT求解

**Comment:** 

> **TL;DR:** 本文将单细胞构建方法应用于投影可描绘性，以期提高基于柱形代数分解（CAD）的算法效率。

**AI_Comments:** 本文的创新点在于将现有技术（单细胞构建）与一种新的、更弱但可能更高效的数学特性（投影可描绘性）相结合，以解决柱形代数分解（CAD）的高计算成本问题。这有望使实代数求解器更具实用性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管柱形代数分解（CAD）是解决实代数相关问题的唯一完整方法，但其计算复杂度是双指数级的。为了降低计算量，研究引入了较弱的“投影可描绘性”概念。

**Method:** 本文将单细胞构建（Single Cell Construction）方法进行调整，以利用投影可描绘性（Projective Delineability）。

**Result:** 报告了实验结果。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 柱形代数分解（CAD）是解决实代数相关问题的完整方法，但计算成本高昂。尽管现有算法启发式地减少了计算量，它们仍依赖于单细胞构建。本文基于新引入的、计算需求更低的“投影可描绘性”概念，调整了单细胞构建方法以利用其特性，并报告了相关的实验结果。

> **摘要翻译:** 柱形代数分解（CAD）是实践中用于解决量词消除或与实代数相关的SMT求解等问题的唯一完整方法，尽管其复杂度是双指数级的。最近的探索引导算法，如N LSAT、NuCAD和CAlC，依赖于CAD技术，但启发式地减少了计算量。单细胞构建是这些算法中使用的范式。CAD算法所基于的核心属性称为可描绘性。最近，我们引入了一个较弱的概念，称为投影可描绘性，它可能需要更少的计算来保证，但需要谨慎应用。本文调整了单细胞构建以利用投影可描绘性，并报告了实验结果。

</details>

[⬆️ 返回分类顶部](#cssc) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [40] [Next Tokens Denoising for Speech Synthesis](https://arxiv.org/abs/2507.22746)
> *下一令牌去噪语音合成*

*Yanqing Liu, Ruiqing Xue, Chong Zhang, Yufei Liu, Gang Wang, Bohan Li, Yao Qian, Lei He, Shujie Liu, Sheng Zhao* | **Category: cs.SD, cs.CL, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 语音合成, 自回归模型, 流匹配, 降噪, Dragon-FM

**Comment:** 

> **TL;DR:** Dragon-FM通过结合自回归（AR）和流匹配，克服了现有模型在语音合成中的局限性，实现了快速、高质量的语音生成，尤其适用于长篇内容，如播客。

**AI_Comments:** Dragon-FM的创新点在于成功地将自回归模型和流匹配模型进行统一，有效解决了两者各自的局限性。其分块处理和结合两种机制的设计显著提高了语音合成的速度和质量，尤其在长篇内容生成方面展现出强大的实用性，零样本生成能力也具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自回归（AR）模型无法利用未来上下文且生成速度慢，而扩散模型在键值（KV）缓存方面存在问题。

**Method:** 本文提出Dragon-FM，一种结合自回归（AR）和流匹配的新型文本到语音（TTS）模型。它以每秒12.5个令牌的速率分块处理48 kHz音频编解码器令牌。该设计在块间进行AR建模以确保全局连贯性，同时在块内进行并行流匹配以实现快速迭代降噪。模型利用跨块的KV缓存和块内的双向上下文，并能将连续AR流匹配用于预测具有有限标量量化器的离散令牌。

**Result:** 在播客数据集上的实验表明，Dragon-FM能够高效生成高质量的零样本播客。

**Conclusion:** Dragon-FM通过统一自回归和流匹配，克服了传统自回归模型速度慢和扩散模型KV缓存效率低的挑战，实现了高效、高质量的语音合成，尤其适用于长篇内容生成。

> **ai_Abstract:** Dragon-FM是一种创新的文本到语音（TTS）模型，它结合了自回归（AR）和流匹配的优势，旨在解决现有AR模型速度慢和扩散模型KV缓存效率低的问题。该模型以块为单位处理音频令牌，通过跨块AR建模确保全局连贯性，并利用块内并行流匹配实现快速降噪。Dragon-FM支持跨块KV缓存和块内双向上下文，并能够将连续AR流匹配应用于离散令牌预测。其高效架构使其特别适用于生成高质量的长篇音频内容，如播客。

> **摘要翻译:** 虽然扩散模型和自回归（AR）模型在生成建模方面取得了显著进展，但它们各自存在明显的局限性。依赖因果注意力的AR模型无法利用未来上下文，并且生成速度慢。相反，扩散模型在键值（KV）缓存方面存在困难。为了克服这些挑战，我们引入了Dragon-FM，这是一种新颖的文本到语音（TTS）设计，它统一了AR和流匹配。该模型以每秒12.5个令牌的紧凑速率，分块处理48 kHz音频编解码器令牌。这种设计使得跨块的AR建模能够确保全局连贯性，而块内并行流匹配则促进了快速迭代降噪。因此，该模型利用跨块的KV缓存，并利用每个块内的双向上下文。此外，它弥合了连续和离散特征建模之间的鸿沟，证明连续AR流匹配可以预测具有有限标量量化器的离散令牌。这种高效的编解码器和快速的块自回归架构也使得该模型在生成长篇内容（如播客）方面非常有效。在播客数据集上的实验证明了其高效生成高质量零样本播客的能力。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [211] [Advancing Speech Quality Assessment Through Scientific Challenges and Open-source Activities](https://arxiv.org/abs/2508.00317)
> *通过科学挑战和开源活动推进语音质量评估*

*Wen-Chin Huang* | **Category: cs.SD, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 语音质量评估, 科学挑战, 开源活动, 生成式AI, 语音生成

**Comment:** APSIPA ASC 2025 perspective paper

> **TL;DR:** 随着生成式AI的兴起，准确的语音质量评估（SQA）变得越来越重要。本文回顾了近期科学挑战和开源活动在推动SQA发展中的作用，并强调了维持这些活动对SQA和语音生成AI发展的重要性。

**AI_Comments:** 这篇论文的创新点在于它强调了科学挑战和开源活动在推动特定技术领域（语音质量评估）发展中的关键作用，并将其与新兴的生成式AI趋势相结合。它不仅回顾了现状，更提出了一个明确的倡议，即持续这些活动的重要性，这对于社区协作和技术进步具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着生成式AI的蓬勃发展，开发一种能够准确反映人类感知的自动化语音质量评估（SQA）方法变得日益重要，以跟上这一发展步伐。

**Method:** 本文回顾了近期语音质量评估（SQA）领域的科学挑战、开源实现和工具包。

**Result:** 论文指出，近期的科学挑战和开源活动刺激了语音质量评估（SQA）领域的发展。研究人员已开始在研究论文中可靠地使用自动SQA作为衡量语音生成系统优劣的严格标准。

**Conclusion:** 维持科学挑战和开源活动对于促进语音质量评估（SQA）本身以及语音生成AI的发展至关重要。

> **ai_Abstract:** 本文探讨了语音质量评估（SQA）在生成式AI繁荣背景下的日益重要性。作者认为，近期科学挑战和开源活动显著推动了SQA领域的发展，使其成为语音生成系统评估的可靠工具。论文综述了SQA的最新挑战、开源实现和工具包，并强调了持续开展此类活动对于SQA和语音生成AI未来发展的重要性。

> **摘要翻译:** 语音质量评估（SQA）是指对语音质量的评估，开发一种能够反映人类感知的准确自动化SQA方法已变得越来越重要，以跟上生成式AI的蓬勃发展。近年来，SQA已发展到研究人员开始在研究论文中忠实地使用自动化SQA作为语音生成系统优劣的严格衡量标准。我们相信，近期的科学挑战和开源活动刺激了该领域的发展。在本文中，我们回顾了SQA的近期挑战以及开源实现和工具包，并强调了维持此类活动对于促进SQA本身以及语音生成AI发展的重要性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [291] [SwitchCodec: A High-Fidelity Nerual Audio Codec With Sparse Quantization](https://arxiv.org/abs/2505.24437)
> *SwitchCodec: 一种高保真稀疏量化神经音频编解码器*

*Jin Wang, Wenbin Jiang, Xiangbo Wang, Yubo You, Sheng Fang* | **Category: cs.SD, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 神经音频压缩, 残差专家向量量化, 高保真, 多比特率, 稀疏量化

**Comment:** 12 pages,8 figures

> **TL;DR:** 本文提出了SwitchCodec，通过残差专家向量量化和多层判别器，实现高保真、多比特率的神经音频压缩，性能优于现有方法并显著减少训练时间。

**AI_Comments:** 本文创新性地引入了残差专家向量量化（REVQ）来克服神经音频编解码器在低比特率下嵌入空间受限的问题，并通过多层判别器和高效的后训练策略进一步提升了性能和训练效率。其在保持高保真度的同时支持多比特率的能力，以及显著减少训练时间的特点，使其在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有神经音频压缩方法在有限比特率下性能显著下降，因为可用嵌入空间受到严重限制。

**Method:** 本文提出了残差专家向量量化（REVQ）以大幅扩展嵌入空间；引入温和的负载平衡策略以充分利用扩展空间；开发了新颖的多层判别器，周期性地分层STFT频谱，引导生成器关注关键频谱区域；采用高效的后训练策略以支持多比特率且低比特率下无质量损失。

**Result:** 在2.67 kbps带宽下，PESQ得分2.87，ViSQOL得分4.27。有效减少频谱模糊，将与原始mel-谱图的距离减少13%。后训练策略的性能与专用固定比特率模型相当，且所需训练时间减少一半。

**Conclusion:** SwitchCodec通过创新的量化和训练策略，克服了现有神经音频压缩在低比特率下的性能限制，实现了高保真、多比特率的音频压缩，并提高了训练效率。

> **ai_Abstract:** 本文提出了SwitchCodec，一种高保真神经音频压缩算法，旨在解决现有方法在低比特率下性能下降的问题。通过引入残差专家向量量化（REVQ）扩展嵌入空间，结合负载平衡策略和多层判别器，以及高效的后训练策略，SwitchCodec在低比特率下实现了卓越的音频质量，并显著提升了训练效率，其性能优于现有基线。

> **摘要翻译:** 神经音频压缩已成为一种有前途的技术，用于高效表示语音、音乐和通用音频。然而，现有方法在有限比特率下会遭受显著的性能下降，因为可用的嵌入空间受到严重限制。为了解决这个问题，我们提出了一种通用的高保真神经音频压缩算法，其特点是残差专家向量量化（REVQ），它在对带宽影响最小的情况下大幅扩展了嵌入空间。引入了一种温和的负载平衡策略，以确保充分利用这个扩展空间。此外，我们开发了一种新颖的多层判别器，它周期性地对STFT频谱进行分层，引导生成器关注关键频谱区域。为了在不降低低端质量的情况下支持多种比特率，我们采用了一种高效的训练后策略。我们提出的模型取得了令人印象深刻的性能，在2.67 kbps带宽下，PESQ和ViSQOL得分分别为2.87和4.27。该方法有效减少了频谱模糊，将与原始mel-谱图的距离减少了13%。值得注意的是，我们的训练后策略实现了与专用固定比特率模型相当的性能，同时将所需的训练时间减少了一半。广泛的消融研究证实了我们的方法优于基线。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [311] [Improving Code Switching with Supervised Fine Tuning and GELU Adapters](https://arxiv.org/abs/2506.00291)
> *使用监督微调和GELU适配器改进语码转换*

*Linh Pham* | **Category: cs.SD, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 语码转换, 自动语音识别, Whisper, GELU适配器, 监督微调

**Comment:** Incorrect results

> **TL;DR:** 本研究利用Whisper模型，通过“切换分词器方法”和基于GELU的适配器，显著降低了语码转换ASR的错误率，超越了现有最先进方法。

**AI_Comments:** 该论文的创新之处在于其针对语码转换ASR的独特方法，即结合“切换分词器方法”和GELU适配器来利用现有的单语模型和数据。这种方法有效地解决了语码转换数据稀缺的挑战，并通过显著降低错误率证明了其有效性，为未来的语码转换ASR研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有语码转换数据集稀缺，导致自动语音识别（ASR）需要新的方法来有效利用大量单语数据和模型。

**Method:** 本文使用预训练的OpenAI Whisper模型。方法分为两部分：1. 提出“切换分词器方法”，利用Whisper的单语能力单独对训练文本进行分词，以提高转录准确性。2. 将“切换分词器方法”与在编码器上训练的基于GELU的适配器结合。

**Result:** 这两种方法将ASCEND数据集的总混合错误率（MER）降低到9.4%，SEAME devman降低到6%，SEAME devsge降低到9.7%，均优于当前最先进的方法。

**Conclusion:** 通过结合“切换分词器方法”和GELU适配器，本研究显著提升了语码转换ASR的性能，超越了现有技术水平。

> **ai_Abstract:** 本研究旨在解决语码转换数据集稀缺的问题，并改进ASR性能。论文利用预训练的OpenAI Whisper模型，并提出了两阶段方法：首先，通过“切换分词器方法”利用Whisper的单语能力提高转录准确性；其次，将该方法与在编码器上训练的GELU适配器结合。实验结果表明，这些方法在多个语码转换数据集上显著降低了总混合错误率（MER），并超越了现有最先进的ASR技术。

> **摘要翻译:** 目前，现有语码转换数据集，无论是标注的还是未标注的，都非常稀少。因此，ASR需要新的方法来利用现存的大量单语数据和模型。本文使用OpenAI的开源ASR模型Whisper，该模型已在68万小时的音频上进行了预训练，用于执行单语ASR任务。在第一部分中，本文研究了如何利用Whisper的单语能力，通过一种称为“切换分词器方法”的方式单独对训练文本进行分词，从而提高转录准确性。在第二部分中，我们将第一部分的“切换分词器方法”与在编码器上训练的基于GELU的适配器相结合。这两种方法将ASCEND数据集的总混合错误率（MER）降低到9.4%，SEAME devman降低到6%，SEAME devsge降低到9.7%，均优于当前最先进的方法。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [609] [AudioGen-Omni: A Unified Multimodal Diffusion Transformer for Video-Synchronized Audio, Speech, and Song Generation](https://arxiv.org/abs/2508.00733)
> *AudioGen-Omni：用于视频同步音频、语音和歌曲生成的多模态扩散Transformer统一模型*

*Le Wang, Jun Wang, Feng Deng, Chen Zhang, Di Zhang, Kun Gai* | **Category: cs.SD, cs.CV, cs.MM, eess.AS** | **Updated: 2025-08-04**

**Keywords:** 多模态扩散Transformer, 音频生成, 视频同步, 语音生成, 歌曲生成

**Comment:** 12 pages, 2 figures

> **TL;DR:** AudioGen-Omni是一个统一的多模态扩散Transformer模型，能够生成与视频同步的高保真音频、语音和歌曲，并在效率和通用性上表现出色。

**AI_Comments:** AudioGen-Omni的创新在于其统一的多模态扩散Transformer架构和新颖的联合训练范式，能够无缝处理视频、文本和音频数据，并实现高精度的跨模ality同步生成。通过解冻所有模态并引入PAAPI等机制，它有效克服了传统文本冻结模型的局限性，显著提升了音频生成质量、语义一致性和唇形同步效果，在效率和通用性方面也取得了突破。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决现有方法在多模态音频生成中存在的语义约束问题，并实现高保真、与视频同步的音频、语音和歌曲的生成，以及适应广泛的音频生成任务。

**Method:** AudioGen-Omni是一种基于多模态扩散Transformer（MMDit）的统一方法。它引入了一种新颖的联合训练范式，无缝整合大规模视频-文本-音频语料库。模型采用统一的歌词-转录编码器，将歌唱和语音输入中的字素和音素编码为密集的帧级表示。这些表示通过基于AdaLN的联合注意力机制进行融合，该机制通过相位对齐各向异性位置注入（PAAPI）得到增强，并选择性地将RoPE应用于时间结构化模态以确保精确的跨模态对齐。通过解冻所有模态并掩盖缺失的输入，模型减轻了文本冻结范式的语义约束，实现了有效的跨模态条件生成。

**Result:** AudioGen-Omni能够生成高保真、语义丰富、声学多样化且与输入视频连贯同步的音频、语音和歌曲。它提高了音频质量、语义对齐和唇形同步准确性，并在文本到音频/语音/歌曲任务上取得了最先进（SOTA）的结果。此外，其生成8秒音频的推理时间仅为1.91秒，显著提升了效率和通用性。

**Conclusion:** AudioGen-Omni提供了一种统一、高效且高性能的解决方案，用于视频同步的多模态音频生成，并在相关任务上取得了显著的改进和最先进的成果。

> **ai_Abstract:** AudioGen-Omni是一个基于多模态扩散Transformer的统一框架，通过创新的联合训练范式，整合大规模视频-文本-音频数据，实现了高保真、视频同步的音频、语音和歌曲生成。它采用统一的歌词-转录编码器和增强的跨模态融合机制（AdaLN-based joint attention with PAAPI），并解冻所有模态以实现有效的跨模态条件生成。该模型在音频质量、语义对齐和唇形同步方面表现出色，并在Text-to-Audio/Speech/Song任务上达到SOTA，同时显著提升了推理效率和通用性。

> **摘要翻译:** 我们提出了AudioGen-Omni——一种基于多模态扩散Transformer（MMDit）的统一方法，能够生成与输入视频连贯同步的高保真音频、语音和歌曲。AudioGen-Omni引入了一种新颖的联合训练范式，无缝整合了大规模视频-文本-音频语料库，使模型能够生成语义丰富、声学多样化的音频，并以多模态输入为条件，适应广泛的音频生成任务。AudioGen-Omni采用统一的歌词-转录编码器，将歌唱和语音输入中的字素和音素编码为密集的帧级表示。密集的帧级表示通过基于AdaLN的联合注意力机制进行融合，该机制通过相位对齐各向异性位置注入（PAAPI）得到增强，其中RoPE选择性地应用于时间结构化模态，以确保精确和鲁棒的跨模态对齐。通过解冻所有模态并掩盖缺失的输入，AudioGen-Omni减轻了文本冻结范式的语义约束，实现了有效的跨模态条件生成。这种联合训练方法提高了音频质量、语义对齐和唇形同步准确性，同时在文本到音频/语音/歌曲任务上取得了最先进的结果。其生成8秒音频的推理时间为1.91秒，在效率和通用性方面都有显著提升。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [29] [Functional vs. Object-Oriented: Comparing How Programming Paradigms Affect the Architectural Characteristics of Systems](https://arxiv.org/abs/2508.00244)
> *函数式 vs. 面向对象：比较编程范式如何影响系统架构特性*

*Briza Mel Dias de Sousa, Renato Cordeiro Ferreira, Alfredo Goldman* | **Category: cs.SE, cs.PL, D.3.2; D.2.11; D.2.13** | **Updated: 2025-08-01**

**Keywords:** 编程范式, 面向对象编程, 函数式编程, 架构特性, 软件工程

**Comment:** 11 pages, 16 figures (1 table, 3 diagrams, 5 graphics, 7 listings),
  submitted to CTICQS capstone project competition at SBQS 2025

> **TL;DR:** 该研究通过Kotlin（OOP）和Scala（FP）实现的数字钱包系统，定性与定量比较了面向对象编程（OOP）和函数式编程（FP）对软件系统架构特性的影响。

**AI_Comments:** 这项研究通过对比两种主流编程范式对系统架构的影响，为开发者提供了宝贵的实践指导。其创新之处在于结合了自我民族志的定性分析和基于调查的定量分析，从编写者和阅读者两个角度全面评估了范式的影响。这对于帮助团队在项目初期做出更明智的技术栈选择具有重要意义，尤其是在FP日益流行的背景下。

<details>
  <summary>Details</summary>

**Motivation:** 在面向对象编程（OOP）主导数十年后，函数式编程（FP）日益受到软件行业的关注。本研究旨在比较OOP和FP对软件系统架构特性的影响，以帮助开发者和组织在选择编程范式时做出更明智的决策。

**Method:** 研究通过设计和实现一个数字钱包系统来比较Kotlin（代表OOP）和Scala（代表FP）两种语言。比较方法包括自我民族志定性分析（揭示代码编写者的视角）和基于调查的定量分析（收集不同背景开发者的反馈，展示代码阅读者的印象）。

**Result:** 定性分析提供了两种实现的并排比较，揭示了代码编写者的视角。定量分析收集了开发者的反馈，展示了代码阅读者的印象。这些结果有望帮助开发者或组织在选择编程范式时做出更明智的决策。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在比较面向对象编程（OOP）和函数式编程（FP）对软件系统架构特性的影响。通过使用Kotlin（OOP）和Scala（FP）实现一个数字钱包系统，研究人员进行了定性（自我民族志）和定量（调查）分析。定性分析揭示了代码编写者的视角，而定量分析则收集了代码阅读者的印象。研究结果旨在为开发者和组织在选择适合其项目的编程范式时提供参考。

> **摘要翻译:** 在面向对象编程（OOP）主导数十年后，函数式编程（FP）在软件行业中日益受到关注。本研究比较了OOP和FP对软件系统架构特性的影响。为此，它检查了一个数字钱包系统的设计和实现，该系统分别用Kotlin（代表OOP）和Scala（代表FP）开发。通过定性和定量分析进行比较，以探索每种范式如何影响系统的架构特性。自我民族志定性分析提供了两种实现的并排比较，揭示了编写此类代码的开发者的视角。基于调查的定量分析收集了来自不同背景开发者的反馈，展示了他们对阅读这些代码的印象。希望这些结果能对寻求为其下一个项目选择最适合范式的开发者或组织有所帮助，以便他们做出更明智的决策。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [47] [Desyan: A Platform for Seamless Value-Flow and Symbolic Analysis](https://arxiv.org/abs/2508.00508)
> *Desyan：一个无缝值流和符号分析平台*

*Panagiotis Diamantakis, Thanassis Avgerinos, Yannis Smaragdakis* | **Category: cs.SE, cs.PL** | **Updated: 2025-08-01**

**Keywords:** 值流分析, 符号分析, 程序分析, Datalog, SMT

**Comment:** 

> **TL;DR:** Desyan是一个将值流分析与符号分析无缝集成的平台，旨在解决静态程序分析中这两种范式长期分离的问题，并提供高效的分析能力。

**AI_Comments:** Desyan的创新之处在于其成功地将长期分离的值流分析和符号分析这两种静态程序分析范式集成到一个统一的平台中。它通过扩展现有的高性能Datalog引擎，并巧妙地结合了业界领先的SMT求解器以及Datalog原生的符号推理能力，提供了一个高度灵活和高效的解决方案。该平台的重要性在于它为程序分析人员提供了一个强大的工具，能够根据具体分析需求选择最合适的推理机制，从而显著提高分析的准确性和效率，特别是在处理复杂程序条件和路径敏感分析时。

<details>
  <summary>Details</summary>

**Motivation:** 尽管值流分析和符号分析在学术界和工业界都取得了成功，但它们在程序分析中仍然 largely separate。目前缺乏一个广泛采用的统一平台，能够轻松高效地将符号技术与高性能数据流推理集成。

**Method:** 本文引入了Desyan平台，它扩展了生产就绪的Datalog不动点引擎（Soufflé），并集成了完整的SMT求解器，调用了业界领先的SMT引擎。Desyan提供了自动高效处理程序分析中常见模式的构造，并且对求解技术保持独立性，支持通过自底向上的代数推理模块进行Datalog原生的符号推理。

**Result:** Desyan引擎能够根据底层分析需求混合使用不同类型的推理。对于值流分析，它是同类最佳的Datalog评估器（执行时间通常快20倍以上）；对于需要完整SMT的应用，它利用领先的SMT求解器；对于轻量级符号评估，它可以使用Datalog原生的符号推理，相比急于调用SMT求解器，实现了显著的加速（通常超过2倍）。

**Conclusion:** Desyan平台通过无缝集成值流和符号推理，成功弥合了静态程序分析中这两种范式之间的差距，提供了一个多功能且高性能的引擎，能够根据分析需求选择最佳的推理方式，并显著提升了分析效率。

> **ai_Abstract:** 本文介绍了Desyan，一个创新的平台，旨在解决静态程序分析中值流分析和符号分析长期分离的问题。Desyan通过扩展Datalog引擎Soufflé并集成SMT求解器，实现了两种推理范式的无缝融合。该平台支持Datalog原生的符号推理，并能根据分析需求智能选择推理方式。实验结果表明，Desyan在值流分析方面表现出色，作为Datalog评估器速度提升20倍以上；在轻量级符号评估中，Datalog原生推理比SMT求解器快2倍以上，为复杂的程序分析提供了高效且灵活的解决方案。

> **摘要翻译:** 在过去的二十年里，两种不同类型的静态分析在学术界和工业界都已成为主导范式：值流分析（例如数据流分析或指向分析）和符号分析（例如符号执行）。尽管它们在众多应用领域取得了各自的成功，但这两种方法在很大程度上仍然是独立的；这是由于一个简单的事实，即目前没有一个被广泛采用的统一平台，能够轻松高效地将符号技术与高性能数据流推理集成。
为了弥合这一差距，我们引入了Desyan：一个用于编写程序分析的平台，它能够无缝集成值流和符号推理。Desyan通过调用业界领先的SMT引擎，将生产就绪的Datalog不动点引擎（Soufflé）扩展为功能齐全的SMT求解器。Desyan提供了自动（且高效！）处理程序分析中常见模式的构造。同时，这种集成与求解技术无关，并通过自底向上的代数推理模块支持Datalog原生的符号推理。
结果是一个引擎，它允许根据底层分析的需要混合不同类型的推理。对于值流分析，该引擎是同类最佳的Datalog评估器（执行时间通常快20倍以上）；对于需要完整SMT的应用（例如，需要解决任意复杂条件的协同执行引擎或其他符号评估器），该引擎利用了领先的SMT求解器；对于轻量级符号评估（例如，在路径敏感分析的上下文中解决简单的条件），该引擎可以使用Datalog原生的符号推理，相比急于调用SMT求解器，实现了大幅加速（通常超过2倍）。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [65] [From Code to Career: Assessing Competitive Programmers for Industry Placement](https://arxiv.org/abs/2508.00772)
> *从代码到职业：评估竞技程序员的行业就业能力*

*Md Imranur Rahman Akib, Fathima Binthe Muhammed, Umit Saha, Md Fazlul Karim Patwary, Mehrin Anannya, Md Alomgeer Hussein, Md Biplob Hosen* | **Category: cs.SE, cs.PL** | **Updated: 2025-08-01**

**Keywords:** 竞技编程, 就业评估, 机器学习, 随机森林, Codeforces

**Comment:** 

> **TL;DR:** 该研究旨在通过分析Codeforces用户的竞技编程活动来预测其在软件工程领域的就业潜力，并使用随机森林分类器构建了一个预测模型。

**AI_Comments:** 该论文创新性地将竞技编程表现与职业就业潜力相结合，利用机器学习模型进行预测，为人才评估提供了新思路。其实时预测系统的实现也具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 当今快节奏的科技行业对评估程序员基于其编码表现的就业准备度工具的需求日益增长。本研究旨在预测Codeforces用户获得不同级别软件工程职位的潜力。

**Method:** 本研究使用Codeforces API收集用户数据，处理关键性能指标，并使用随机森林分类器构建预测模型。该模型将用户分为四个就业能力级别。系统使用Flask实现并部署在Render上进行实时预测。

**Result:** 评估表明，该方法能够根据编码熟练度和参与度有效区分不同技能水平的用户。

**Conclusion:** 这项工作为机器学习在职业评估中的应用奠定了基础，并可扩展到预测更广泛技术领域的就业准备度。

> **ai_Abstract:** 本研究旨在解决科技行业中评估程序员就业准备度的需求，通过分析Codeforces用户的竞技编程活动来预测其在软件工程领域的就业潜力。论文利用Codeforces API收集数据，处理关键表现指标，并使用随机森林分类器构建了一个预测模型，将用户分为四个就业能力级别。该系统通过Flask实现并部署，其评估结果表明该方法能有效区分不同技能水平。这项工作为机器学习在职业评估领域的应用奠定了基础。

> **摘要翻译:** 在当今快节奏的科技行业中，对能够根据程序员的编码表现评估其就业准备度的工具需求日益增长。本研究重点预测Codeforces用户获得不同级别软件工程职位的潜力。主要目标是分析用户的竞技编程活动与其获得从入门级职位到大型科技公司职位的机会之间的相关性。我们使用Codeforces API收集用户数据，处理关键性能指标，并使用随机森林分类器构建预测模型。该模型将用户分为四个就业能力级别，从需要进一步发展的用户到适合顶级科技工作的用户。该系统使用Flask实现并部署在Render上进行实时预测。我们的评估表明，该方法能够根据编码熟练度和参与度有效区分不同技能水平。这项工作为机器学习在职业评估中的应用奠定了基础，并可扩展到预测更广泛技术领域的就业准备度。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [206] [Novice Developers' Perspectives on Adopting LLMs for Software Development: A Systematic Literature Review](https://arxiv.org/abs/2503.07556)
> *新手开发者采用大型语言模型进行软件开发的视角：一项系统文献综述*

*Samuel Ferino, Rashina Hoda, John Grundy, Christoph Treude* | **Category: cs.SE, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 软件开发, 新手开发者, 系统文献综述, LLMs

**Comment:** 

> **TL;DR:** 系统综述了2022-2025年间关于新手开发者在软件开发中采用LLM工具的研究，分析了其动机、任务、优缺点及未来方向。

**AI_Comments:** 这项系统文献综述及时地总结了新兴领域中关于新手开发者采用LLMs的研究，对于理解LLMs在软件工程教育和实践中的实际影响具有重要意义。其系统性方法和对多项研究的整合有助于识别现有知识的空白和未来的研究方向。论文还提供了公开可用的研究成果，增加了其透明度和可复用性。

<details>
  <summary>Details</summary>

**Motivation:** 理解新手开发者对使用大型语言模型（LLMs）工具的看法，是LLMs在软件工程中成功应用的关键方面。本研究旨在系统地收集和总结相关研究。

**Method:** 本研究遵循Kitchenham et al.的指南，进行了一项系统文献综述（SLR），对2022年4月至2025年6月期间发表的80项主要研究进行了分析，以回答四个研究问题。

**Result:** RQ1：研究动机和方法学方法被分类。RQ2：识别了新手开发者使用LLMs进行软件开发的任务。RQ3：对研究中讨论的优点、挑战和建议进行了分类。RQ4：讨论了主要研究中提出的局限性和未来研究需求。论文还指出了未来的工作方向以及对软件工程研究人员、教育工作者和开发者的启示。

**Conclusion:** 本系统文献综述总结了关于新手开发者采用LLMs进行软件开发的视角，分类了研究动机、任务、优缺点、挑战以及未来的研究方向和对相关人员的启示。

> **ai_Abstract:** 本系统文献综述（SLR）旨在系统地总结关于新手开发者（学生和早期职业开发者）采用大型语言模型（LLMs）进行软件开发的现有研究。研究遵循Kitchenham et al.的指南，分析了2022年4月至2025年6月间的80篇主要研究，回答了四个研究问题：分类了研究动机和方法、识别了LLM在软件开发中的应用任务、归纳了LLM使用的优缺点及建议，并讨论了研究局限性和未来研究方向。该综述为软件工程研究人员、教育工作者和开发者提供了关于LLM在新手开发中应用的见解和未来工作方向。

> **摘要翻译:** 随着大型语言模型（LLMs）的兴起，近年来出现了许多研究，重点关注探索新手开发者（计算机科学/软件工程学生和两年或以下专业经验的早期职业行业开发者）采用基于LLM的工具进行软件开发的情况。这些研究旨在了解新手开发者对使用这些工具的看法，这是LLMs在软件工程中成功应用的关键方面。为了系统地收集和总结这些研究，我们遵循Kitchenham et al.的指南，对2022年4月至2025年6月期间发表的80项主要研究进行了系统文献综述（SLR），以回答四个研究问题（RQs）。在回答RQ1时，我们对研究动机和方法学方法进行了分类。在RQ2中，我们识别了新手开发者使用LLMs进行的软件开发任务。在RQ3中，我们对研究中讨论的优点、挑战和建议进行了分类。最后，在回答RQ4时，我们讨论了主要研究中提出的研究局限性和未来研究需求。在整篇论文中，我们还指明了未来的工作方向以及对软件工程研究人员、教育工作者和开发者的启示。我们的研究成果可在https://github.com/Samuellucas97/SupplementaryInfoPackage-SLR 公开获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [275] [Are Sparse Autoencoders Useful for Java Function Bug Detection?](https://arxiv.org/abs/2505.10375)
> *稀疏自编码器对Java函数错误检测有用吗？*

*Rui Melo, Claudia Mamede, Andre Catarino, Rui Abreu, Henrique Lopes Cardoso* | **Category: cs.SE, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 稀疏自编码器, Java, 错误检测, 大型语言模型, 软件漏洞

**Comment:** 10 pages, 10 figures

> **TL;DR:** 本文研究稀疏自编码器（SAE）在Java函数错误检测中的应用，发现SAE能从预训练LLM的内部表示中直接检测错误，无需微调，F1分数高达89%，且优于微调的Transformer编码器基线。

**AI_Comments:** 本文的创新点在于提出了使用稀疏自编码器（SAE）直接从预训练LLM的内部表示中检测软件错误，而无需对LLM进行微调。这有效解决了LLM的复杂性和不透明性问题，并降低了部署成本，为AI驱动的漏洞检测提供了一种高效且可解释的新途径。其优于微调基线的表现也凸显了该方法的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的软件漏洞检测方法存在高误报率、可扩展性差和依赖人工的局限性。虽然大型语言模型（LLM）为分类任务提供了新途径，但其复杂性和不透明性带来了可解释性和部署挑战。因此，需要一种轻量级、可解释的替代方案。

**Method:** 研究人员探索稀疏自编码器（SAE）是否能作为Java函数错误检测的轻量级、可解释的替代方案。他们评估了SAE在GPT-2 Small和Gemma 2B模型内部表示上的有效性，旨在在不微调底层LLM的情况下，突出错误行为。

**Result:** SAE派生的特征使错误检测的F1分数高达89%，并且始终优于微调的Transformer编码器基线。

**Conclusion:** 本研究首次提供了经验证据，表明稀疏自编码器（SAE）可以直接从预训练大型语言模型（LLM）的内部表示中检测软件错误，无需任何微调或特定任务的监督。

> **ai_Abstract:** 本文探讨了稀疏自编码器（SAE）在Java函数错误检测中的应用，旨在克服传统方法和大型语言模型（LLM）的局限性。研究发现，SAE能够利用预训练LLM（如GPT-2 Small和Gemma 2B）的内部表示，在不进行微调的情况下，实现高达89%的F1分数来检测错误，并且性能优于微调的Transformer编码器基线。这项工作首次证明了SAE可以直接从预训练LLM的内部表示中检测软件错误，无需额外的微调或任务特定监督，提供了一种轻量级且可解释的错误检测方案。

> **摘要翻译:** 软件漏洞，如缓冲区溢出和SQL注入，是安全漏洞的主要来源。传统的漏洞检测方法仍然至关重要，但受限于高误报率、可扩展性问题和对人工的依赖。这些限制推动了人们对基于AI的自动化漏洞检测和安全代码生成方法的兴趣。虽然大型语言模型（LLM）为分类任务开辟了新途径，但其复杂性和不透明性对可解释性和部署构成了挑战。稀疏自编码器为这个问题提供了一个有前景的解决方案。我们探讨了SAE是否可以作为Java函数错误检测的轻量级、可解释的替代方案。我们评估了SAE应用于GPT-2 Small和Gemma 2B表示时的有效性，检查它们在不微调底层LLM的情况下突出错误行为的能力。我们发现SAE派生的特征使错误检测的F1分数高达89%，始终优于微调的Transformer编码器基线。我们的工作提供了第一个经验证据，表明SAE可以直接从预训练LLM的内部表示中检测软件错误，无需任何微调或特定任务的监督。代码可在https://github.com/rufimelo99/SAE-Java-Bug-Detection获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [278] [Accurate and Consistent Graph Model Generation from Text with Large Language Models](https://arxiv.org/abs/2508.00255)
> *基于大型语言模型的文本图模型生成中的准确性和一致性*

*Boqi Chen, Ou Wei, Bingzhou Zheng, Gunter Mussbacher* | **Category: cs.SE, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 图模型生成, 大型语言模型, 一致性, 准确性, 抽象-具体化

**Comment:** Accepted at ACM / IEEE 28th International Conference on Model Driven
  Engineering Languages and Systems (MODELS 2025)

> **TL;DR:** 本文提出了一种新颖的抽象-具体化框架，通过聚合大型语言模型（LLM）的多个输出来解决LLM生成图模型时存在的约束不一致性和不准确性问题，显著提高了生成图模型的一致性和质量。

**AI_Comments:** 该论文的创新点在于将LLM的自洽性思想应用于图模型生成领域，通过聚合多个输出并进行精炼，有效解决了以往LLM生成图模型中难以处理的约束不一致性和不准确性问题。这种从概率部分模型到具体模型的转换方法，为提高生成模型的可靠性提供了一条新途径，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLM）在文本图模型生成方面存在三个主要问题：语法违规、约束不一致性和不准确性。其中，约束不一致性和不准确性问题尚未得到充分解决，导致生成的模型部分正确。

**Method:** 受LLM自洽性方法的启发，本文提出了一种新颖的抽象-具体化框架。该方法首先聚合LLM的多个候选输出来构建一个概率部分模型，然后将此部分模型精炼为满足所有约束的最合适的具体模型。

**Result:** 该框架在多个流行的开源和闭源LLM以及多样化数据集上的评估结果表明，所提出的方法显著提高了生成图模型的一致性和质量。

**Conclusion:** 本文提出的抽象-具体化框架能够有效提升大型语言模型生成图模型的一致性和准确性，解决了现有方法中未被充分解决的约束不一致性和不准确性问题。

> **ai_Abstract:** 针对大型语言模型（LLM）在文本图模型生成中存在的约束不一致性和不准确性问题，本文提出了一种新颖的抽象-具体化框架。该框架通过聚合LLM的多个候选输出来构建一个概率部分模型，并将其精炼为满足所有约束的最终具体模型。实验结果表明，该方法显著提高了生成图模型的一致性和质量。

> **摘要翻译:** 从自然语言描述生成图模型是一项重要任务，在软件工程中有许多应用。随着大型语言模型（LLM）的兴起，使用LLM进行图模型生成的兴趣日益增长。然而，基于LLM的图模型生成通常会产生部分正确的模型，存在三个主要问题：（1）语法违规：生成的模型可能不符合其元模型定义的语法；（2）约束不一致性：模型的结构可能不符合某些领域特定的约束；（3）不准确性：由于LLM固有的不确定性，模型可能包含不准确、幻觉的元素。虽然第一个问题通常通过约束解码或过滤等技术解决，但后两个问题在很大程度上仍未解决。受LLM中近期自洽性方法的启发，我们提出了一种新颖的抽象-具体化框架，通过考虑LLM的多个输出来增强生成图模型的一致性和质量。我们的方法首先构建一个概率部分模型，聚合所有候选输出，然后将此部分模型精炼为满足所有约束的最合适的具体模型。我们在多个流行的开源和闭源LLM上使用多样化数据集进行模型生成任务，评估了我们的框架。结果表明，我们的方法显著提高了生成图模型的一致性和质量。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [335] [Private GPTs for LLM-driven testing in software development and machine learning](https://arxiv.org/abs/2506.06509)
> *用于软件开发和机器学习中LLM驱动测试的私有GPTs*

*Jakub Jagielski, Consuelo Rojas, Markus Abel* | **Category: cs.SE, cs.AI, I.2.1** | **Updated: 2025-07-31**

**Keywords:** 私有GPTs, LLM驱动测试, 自动化测试, Gherkin语法, 软件开发

**Comment:** 5 pages, 10 figures

> **TL;DR:** 本文探讨了私有GPTs自动生成可执行测试代码的能力，发现通过Gherkin语法进行的两步过程能产生更高质量、更可读的测试代码。

**AI_Comments:** 本文的创新点在于探索了私有GPTs在测试自动化领域的应用，并对比了直接生成和基于Gherkin语法的两阶段生成方法，为提高测试代码质量提供了实践指导。其重要性在于能够赋能非技术背景的产品负责人直接参与测试标准的制定，提升了开发效率和质量。论文明确指出了结构化提示和两步流程的有效性，但未提及潜在的局限性，例如GPTs生成复杂测试用例的能力、维护成本或在更大规模项目中的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究私有GPTs根据需求自动生成可执行测试代码的能力，尤其关注如何让产品负责人或业务智能直接通过大型语言模型（LLMs）生成可测试的验收标准。

**Method:** 研究人员使用验收标准作为输入，探索了两种生成测试代码的方式：1) LLM直接从需求生成代码；2) 通过使用Gherkin语法作为中间步骤。他们通过“Hello World”程序和数字分类模型两个场景评估了提示的有效性。

**Result:** 结果显示，两步过程（通过Gherkin语法）在人工可读性和最佳编码实践（如代码行数和额外库的使用）方面产生了更好的测试结果。此外，结构化提示能带来更高质量的测试输出。

**Conclusion:** 本文得出结论，使用Gherkin语法作为中间步骤的两步过程，结合结构化提示，能有效提高私有GPTs生成的测试代码的质量、可读性和符合最佳实践的程度。

> **ai_Abstract:** 本研究探讨了利用私有GPTs自动生成软件开发和机器学习测试代码的能力。论文以验收标准为输入，比较了LLM直接生成测试代码和通过Gherkin语法作为中间步骤的两种方法。研究发现，采用Gherkin语法的两步生成过程在代码可读性和遵循最佳编码实践方面表现更优，并且结构化提示能显著提升测试输出的质量。研究通过“Hello World”程序和数字分类模型验证了这些发现。

> **摘要翻译:** 在本文中，我们研究了私有GPTs根据需求自动生成可执行测试代码的能力。更具体地说，我们使用验收标准作为输入，这些标准是史诗或故事的一部分，通常用于现代开发流程。这使得产品负责人或业务智能能够分别通过使用LLMs直接生成可测试的标准。我们通过两种方式探索了所生成测试的质量：i) 直接让LLM从需求生成代码，ii) 通过使用Gherkin语法作为中间步骤。结果表明，两步过程产生了更好的结果——我们将“更好”定义为人工可读性和最佳编码实践，即代码行数和测试中通常使用的额外库的使用。具体来说，我们在两种场景下评估了提示的有效性：一个简单的“Hello World”程序和一个数字分类模型，结果表明结构化提示能够产生更高质量的测试输出。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [336] [Git Context Controller: Manage the Context of LLM-based Agents like Git](https://arxiv.org/abs/2508.00031)
> *Git 上下文控制器：像 Git 一样管理基于 LLM 的代理的上下文*

*Junde Wu* | **Category: cs.SE** | **Updated: 2025-07-30**

**Keywords:** LLM 代理, 上下文管理, Git, 版本控制, 长期工作流

**Comment:** in updating

> **TL;DR:** Git-Context-Controller (GCC) 是一个受 Git 启发的上下文管理框架，旨在解决基于 LLM 的代理在长期工作流中面临的上下文管理瓶颈，显著提升其性能和任务解决能力。

**AI_Comments:** 本文通过将成熟的软件版本控制原理（Git）应用于 LLM 代理上下文管理这一新领域，提出了一种创新解决方案。这种类比非常强大，因为它为处理复杂、长期的交互提供了一个结构化且熟悉的范式，这是当前 LLM 代理的一个显著局限性。实证结果证明了其在实践中的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 基于大型语言模型（LLM）的代理在执行长期工作流（如大型长期项目编码）时，上下文管理成为一个关键瓶颈。

**Method:** 本文提出了 Git-Context-Controller (GCC)，这是一个受软件版本控制系统启发的结构化上下文管理框架。GCC 将上下文提升为像 Git 一样的版本化内存层次结构，将代理内存结构化为具有显式操作（COMMIT、BRANCH、MERGE 和 CONTEXT）的持久文件系统，从而实现基于里程碑的检查点、替代计划的探索和结构化反思。

**Result:** 配备 GCC 的代理在 SWE-Bench-Lite 基准测试中取得了最先进的性能，解决了 48.00% 的软件错误，超越了 26 个竞争系统。在一个自我复制的案例研究中，一个增强了 GCC 的代理从头开始构建了一个新的 CLI 代理，实现了 40.7% 的任务解决率，而没有 GCC 的情况下仅为 11.7%。

**Conclusion:** GCC 有效地解决了 LLM 代理的上下文管理挑战，使其能够管理长期目标、隔离架构实验，并在复杂任务（如软件错误解决和代理构建）中提高性能。

> **ai_Abstract:** Git-Context-Controller (GCC) 是一种新颖的框架，受 Git 启发，用于管理基于 LLM 的代理的上下文，解决了长期工作流中的瓶颈。GCC 将代理内存视为一个版本化的文件系统，具有类似 Git 的操作（COMMIT、BRANCH、MERGE、CONTEXT），从而实现对长期目标的稳健管理、实验隔离和内存恢复。实证结果表明，GCC 显著提高了软件错误解决（SWE-Bench-Lite）和复杂任务完成的性能，优于现有系统。

> **摘要翻译:** 基于大型语言模型（LLM）的代理通过将内部推理与外部工具使用相结合，展示了令人印象深刻的能力。然而，当这些代理部署在长期工作流中时，例如为一个大型长期项目编写代码，上下文管理成为一个关键瓶颈。我们引入了 Git-Context-Controller (GCC)，一个受软件版本控制系统启发的结构化上下文管理框架。GCC 将上下文提升为像 Git 一样的版本化内存层次结构。它将代理内存结构化为具有显式操作的持久文件系统：COMMIT、BRANCH、MERGE 和 CONTEXT，从而实现基于里程碑的检查点、替代计划的探索以及结构化反思。我们的方法使代理能够管理长期目标、隔离架构实验，并在会话和代理之间恢复或移交内存。经验上，配备 GCC 的代理在 SWE-Bench-Lite 基准测试中取得了最先进的性能，解决了 48.00% 的软件错误，超越了 26 个竞争系统。在一个自我复制的案例研究中，一个增强了 GCC 的代理从头开始构建了一个新的 CLI 代理，实现了 40.7% 的任务解决率，而没有 GCC 的情况下仅为 11.7%。代码已发布在：https://github.com/theworldofagents/GCC

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [338] [Tool-Assisted Conformance Checking to Reference Process Models](https://arxiv.org/abs/2508.00738)
> *工具辅助的参考过程模型一致性检查*

*Bernhard Rumpe, Max Stachon, Sebastian Stüber, Valdes Voufo* | **Category: cs.SE, cs.FL, 68N30, D.2.4** | **Updated: 2025-08-04**

**Keywords:** 一致性检查, 参考过程模型, 因果依赖分析, 过程模型验证, 自动化

**Comment:** 

> **TL;DR:** 本研究提出了一种工具辅助的自动化方法，通过因果依赖分析来检查具体过程模型与参考模型的一致性，以解决现有方法在语义模型比较方面的不足。

**AI_Comments:** 本文的创新之处在于提出了一种工具辅助的自动化一致性检查方法，通过因果依赖分析来解决现有过程模型一致性检查在语义模型比较方面的不足。其重要性在于提供了一种更准确和灵活的解决方案，有助于维护过程的质量和一致性。局限性可能在于其对特定因果依赖分析的依赖性以及在更复杂或大规模场景下的适用性，尽管论文提到了案例研究评估，但具体细节未在摘要中提及。

<details>
  <summary>Details</summary>

**Motivation:** 现有过程模型的一致性检查方法主要关注验证过程执行轨迹，缺乏语义模型比较所需的表达能力和自动化，导致相关问题悬而未决。为解决这一问题，本研究旨在探索针对参考模型的自动化一致性检查。

**Method:** 本研究采用任务和事件的因果依赖分析方法，对具体过程模型与参考模型进行自动化一致性检查。该方法被整合到一个更广泛的语义框架中，并提出了相应的算法，通过案例研究进行了评估。

**Result:** 本研究提供了一种工具辅助的解决方案，提高了过程模型一致性验证的准确性和灵活性。通过案例研究对所提出的算法进行了评估，并讨论了其优缺点。

**Conclusion:** 本研究提供了一种工具辅助的解决方案，有效提高了过程模型一致性验证的准确性和灵活性，填补了现有方法在语义模型比较方面的空白。

> **ai_Abstract:** 本研究提出了一种工具辅助的自动化一致性检查方法，用于比较具体过程模型与参考模型。该方法通过分析任务和事件的因果依赖性，解决了现有方法在语义模型比较方面表达能力和自动化不足的问题。研究将此方法整合到一个语义框架中，并提出了相应的算法，通过案例研究验证了其在提高过程模型一致性验证准确性和灵活性方面的有效性。

> **摘要翻译:** 参考模型传达最佳实践和标准。参考框架需要一致性检查，以确保遵守既定指南和原则，这对于维护各种过程的质量和一致性至关重要。本文探讨了使用任务和事件的因果依赖分析，对具体过程模型与参考模型进行自动化一致性检查。现有过程模型的一致性检查概念侧重于验证过程执行轨迹，缺乏语义模型比较所需的表达能力和自动化，使这个问题悬而未决。我们将我们的方法整合到一个更广泛的语义框架中，用于定义参考模型一致性。我们概述了一个参考过程模型一致性检查算法，通过案例研究对其进行了评估，并讨论了其优缺点。我们的研究提供了一种工具辅助的解决方案，提高了过程模型一致性验证的准确性和灵活性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [356] [Machine Learning Pipeline for Software Engineering: A Systematic Literature Review](https://arxiv.org/abs/2508.00045)
> *软件工程中的机器学习管道：系统文献综述*

*Samah Kansab* | **Category: cs.SE** | **Updated: 2025-07-31**

**Keywords:** 机器学习管道, 软件工程, 系统文献综述, 缺陷预测, 数据预处理

**Comment:** 

> **TL;DR:** 本系统文献综述（SLR）考察了软件工程（SE）中机器学习（ML）管道的现状，总结了最佳实践、挑战和空白，并强调了精心设计的ML管道对于解决SE挑战的重要性。

**AI_Comments:** 该SLR对软件工程领域的机器学习应用提供了全面的概览，其创新之处在于系统性地梳理了ML管道的各个关键环节，并指出了最佳实践和现有空白。其重要性在于为研究人员和从业者提供了清晰的路线图，以优化软件开发流程。它强调了预处理、算法选择和评估的重要性，这对于构建可靠和高效的ML解决方案至关重要。该研究的局限性可能在于其回顾性质，可能未能涵盖最新的、尚未被广泛文献引用的技术。

<details>
  <summary>Details</summary>

**Motivation:** 软件开发实践的快速发展给软件工程（SE）生命周期中的质量和效率带来了挑战。传统的SE方法难以扩展，导致调试时间长、缺陷检测效率低和开发周期资源消耗大。机器学习（ML）已成为解决这些问题并实现自动化任务的关键解决方案，但其有效性取决于管道的稳健性。

**Method:** 本文采用系统文献综述（SLR）的方法，考察了为软件工程设计的最新机器学习管道，整合了最佳实践、挑战和空白。

**Result:** 研究发现，SMOTE等稳健的预处理技术用于数据平衡，SZZ等算法用于特征选择，可以提高模型可靠性。随机森林和梯度提升等集成方法在各项任务中表现最佳，而朴素贝叶斯等简单模型在效率和可解释性方面仍有价值。AUC、F1分数和精确度是最常用的评估指标，而BAM等新指标出现在小众应用中。引导法等验证技术被广泛用于确保模型稳定性和泛化能力。

**Conclusion:** 本系统文献综述强调了精心设计的机器学习管道对于解决软件工程挑战的重要性，并为寻求优化软件质量和效率的研究人员和从业者提供了可操作的见解。通过识别空白和趋势，本研究为推动机器学习在日益复杂的开发环境中的应用和创新奠定了基础。

> **ai_Abstract:** 本系统文献综述（SLR）深入分析了软件工程（SE）中机器学习（ML）管道的现状。鉴于传统SE方法在应对复杂性挑战方面的不足，ML被视为关键解决方案。研究发现，稳健的数据预处理（如SMOTE和SZZ特征选择）、集成算法（如随机森林和梯度提升）以及常用的评估指标（如AUC、F1分数）和验证技术（如引导法）是构建有效ML管道的关键要素。该研究强调了精心设计的ML管道在提升软件质量和效率中的重要性，并为从业者提供了实践指导。

> **摘要翻译:** 软件开发实践的快速发展给软件工程（SE）生命周期中的质量和效率带来了挑战。随着SE系统复杂性的增长，传统方法往往无法扩展，导致调试时间更长、缺陷检测效率低下以及开发周期资源消耗大。机器学习（ML）已成为一个关键解决方案，能够自动化缺陷预测、代码审查和发布质量估计等任务。然而，ML在SE中的有效性取决于其管道的稳健性，包括数据收集、预处理、特征工程、算法选择、验证和评估。

本系统文献综述（SLR）考察了为SE设计的最新ML管道，整合了最佳实践、挑战和空白。我们的研究结果表明，稳健的预处理（例如用于数据平衡的SMOTE和基于SZZ的特征选择算法）可以提高模型可靠性。随机森林和梯度提升等集成方法在各项任务中表现出色，而朴素贝叶斯等更简单的模型在效率和可解释性方面仍然有价值。AUC、F1分数和精确度等评估指标最为常见，而在小众应用中出现了诸如最佳算术平均值（BAM）等新指标。引导法等验证技术被广泛用于确保模型的稳定性和泛化能力。

本SLR强调了精心设计的ML管道对于解决SE挑战的重要性，并为寻求优化软件质量和效率的研究人员和从业者提供了可操作的见解。通过识别空白和趋势，本研究为推动ML的应用和在日益复杂的开发环境中的创新奠定了基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [358] [Dynamic Symbolic Execution for Semantic Difference Analysis of Component and Connector Architectures](https://arxiv.org/abs/2508.00749)
> *用于组件和连接器架构语义差异分析的动态符号执行*

*Johanna Grahl, Bernhard Rumpe, Max Stachon, Sebastian Stüber* | **Category: cs.SE, cs.FL, cs.SC, 68N30, D.2.4** | **Updated: 2025-08-01**

**Keywords:** 动态符号执行, 语义差异分析, 组件和连接器架构, MontiArc, 可伸缩性

**Comment:** 

> **TL;DR:** 本文探讨了使用动态符号执行（DSE）对组件和连接器架构进行语义差异分析。研究增强了MontiArc-to-Java生成器以收集运行时数据，并评估了执行策略。结果表明DSE有潜力，但可伸缩性是主要限制。

**AI_Comments:** 该论文的创新点在于将动态符号执行应用于组件和连接器架构的语义差异分析，并通过增强现有工具来收集运行时数据。其重要性在于为模型驱动开发中的模型演进提供了潜在的验证方法。然而，论文明确指出了DSE在可伸缩性方面的局限性，这是其应用于大型复杂系统时需要克服的关键挑战。

<details>
  <summary>Details</summary>

**Motivation:** 在模型驱动开发中，确保演进模型的正确性和一致性至关重要。

**Method:** 研究利用动态符号执行（DSE）对组件和连接器架构进行语义差异分析，具体使用MontiArc模型。作者增强了现有的MontiArc-to-Java生成器，以在运行时收集符号和具体执行数据，包括转换条件、访问状态和自动机内部变量。这些数据有助于识别提供系统行为关键洞察的重要执行轨迹。研究还根据运行时效率、最小性和完整性标准评估了各种执行策略。

**Result:** 研究结果表明，尽管动态符号执行（DSE）在分析组件和连接器架构方面显示出前景，但可伸缩性仍然是主要的限制。

**Conclusion:** DSE在分析组件和连接器架构方面有前景，但可伸缩性是其主要限制，需要进一步研究以增强其在大型系统中的实际效用。

> **ai_Abstract:** 本文探讨了将动态符号执行（DSE）应用于组件和连接器架构的语义差异分析。通过增强MontiArc-to-Java生成器以收集运行时数据，研究旨在识别重要的执行轨迹。论文评估了DSE的执行策略，并指出尽管DSE在分析此类架构方面显示出潜力，但其可伸缩性是当前的主要限制，需要进一步研究来提高其在大型系统中的实用性。

> **摘要翻译:** 在模型驱动开发中，确保演进模型的正确性和一致性至关重要。本文研究了动态符号执行（DSE）在组件和连接器架构语义差异分析中的应用，特别是利用MontiArc模型。我们增强了现有的MontiArc-to-Java生成器，以在运行时收集符号和具体执行数据，包括转换条件、访问状态和自动机内部变量。这些数据有助于识别提供系统行为关键洞察的重要执行轨迹。我们根据运行时效率、最小性和完整性标准评估了各种执行策略，建立了一个评估DSE在语义差异分析中适用性的框架。我们的研究结果表明，尽管DSE在分析组件和连接器架构方面显示出前景，但可伸缩性仍然是主要的限制，这表明需要进一步研究以增强其在大型系统中的实际效用。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [381] [How Quantization Impacts Privacy Risk on LLMs for Code?](https://arxiv.org/abs/2508.00128)
> *量化如何影响代码大型语言模型的隐私风险？*

*Md Nazmul Haque, Hua Yang, Zhou Yang, Bowen Xu* | **Category: cs.SE** | **Updated: 2025-07-31**

**Keywords:** 量化, 隐私风险, 代码大型语言模型, 成员推理, 模型压缩

**Comment:** 

> **TL;DR:** 量化能显著降低代码大模型的隐私风险，但任务性能与隐私风险之间存在权衡。

**AI_Comments:** 这项工作创新性地首次探讨了量化对LLMs4Code隐私风险的影响，填补了该领域的空白。其发现量化能降低隐私风险并揭示性能与隐私的权衡，为实际部署提供了重要的指导意义，特别是关于量化大型模型可能带来的优势。

<details>
  <summary>Details</summary>

**Motivation:** 用于代码的大型语言模型（LLMs4Code）依赖包含敏感数据的海量训练数据，引发了严重的隐私担忧。尽管量化技术能降低计算成本，但其对模型保留和暴露隐私信息能力的影响尚不明确，回答此问题对于理解实际部署中的隐私风险至关重要。

**Method:** 本文进行了首次关于量化如何同时影响LLMs4Code任务性能和隐私风险的实证研究。研究中将静态和动态量化技术应用于Pythia、CodeGen和GPTNeo三个代表性模型家族。

**Result:** 研究结果表明，量化能显著降低模型的隐私风险。同时发现任务性能和隐私风险之间存在正相关性，揭示了潜在的权衡。此外，研究揭示量化更大的模型可能比使用全精度小模型产生更好的平衡。

**Conclusion:** 这些发现适用于不同的模型架构、大小和成员推理方法，为在部署压缩的LLMs4Code时保护隐私提供了实用指导。

> **ai_Abstract:** 本文首次实证研究了量化对代码大型语言模型（LLMs4Code）任务性能和隐私风险的同步影响。研究发现，量化能显著降低模型的隐私风险，但任务性能与隐私风险之间存在正相关性，揭示了性能与隐私的权衡。研究还指出，量化大型模型可能比使用全精度小型模型在平衡性能和隐私方面表现更好。这些发现为在部署压缩LLMs4Code时保护隐私提供了实用指导。

> **摘要翻译:** 用于代码的大型语言模型（LLMs4Code）严重依赖海量训练数据，包括敏感数据，例如项目的云服务凭证和开发者的个人身份信息，这引发了严重的隐私担忧。成员推理（MI）最近已成为一种有效的工具，通过识别特定数据是否属于模型的训练集来评估隐私风险。与此同时，模型压缩技术，特别是量化，因其能降低计算成本并支持大型模型部署而受到关注。然而，尽管量化模型仍保留了从原始训练数据中学习到的知识，但量化是否会影响它们保留和暴露隐私信息的能力仍不清楚。回答这个问题对于理解实际部署中的隐私风险至关重要。在这项工作中，我们首次对量化如何同时影响LLMs4Code中的任务性能和隐私风险进行了实证研究。为此，我们将广泛使用的量化技术（静态和动态）应用于三个代表性模型家族，即Pythia、CodeGen和GPTNeo。我们的结果表明，相对于原始模型，量化对降低隐私风险具有显著影响。我们还发现任务性能和隐私风险之间存在正相关性，这表明存在潜在的权衡。此外，我们揭示了量化更大的模型可能比使用全精度小模型产生更好的平衡。最后，我们证明这些发现适用于不同的架构、模型大小和MI方法，为部署压缩的LLMs4Code时保护隐私提供了实用指导。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [396] [Testing the Untestable? An Empirical Study on the Testing Process of LLM-Powered Software Systems](https://arxiv.org/abs/2508.00198)
> *测试不可测试的？一项关于LLM驱动软件系统测试过程的实证研究*

*Cleyton Magalhaes, Italo Santos, Brody Stuart-Verner, Ronnie de Souza Santos* | **Category: cs.SE** | **Updated: 2025-08-04**

**Keywords:** LLM驱动系统, 软件测试, 经验研究, 测试策略, 挑战

**Comment:** 

> **TL;DR:** 一项实证研究探讨了LLM驱动软件系统的测试过程，发现需要结合手动和自动化方法，并面临集成失败、输出不可预测等挑战，测试需适应传统验证方法。

**AI_Comments:** 这项研究填补了LLM驱动系统测试领域的一个空白，通过实证研究揭示了实际操作中的挑战和适应性策略。其创新之处在于关注了整个系统层面的测试，而不仅仅是LLM模型本身。研究结果对于未来开发和测试LLM应用具有重要的指导意义，为理解和改进LLM集成软件的质量保证提供了宝贵见解。

<details>
  <summary>Details</summary>

**Motivation:** 背景：大型语言模型（LLM）驱动的软件系统已成为日常技术的一部分，但关于如何测试集成LLM的完整系统在开发过程中受到的关注有限。目的：本研究旨在探索LLM驱动系统在实际应用开发中的测试方式。

**Method:** 我们进行了一项探索性案例研究，分析了99份由学生撰写的报告，这些学生作为大学课程的一部分构建并部署了LLM驱动的应用程序。每份报告都通过专题分析，并辅以结构化编码过程进行独立分析。

**Result:** 测试策略结合了手动和自动化方法，以评估系统逻辑和模型行为。常见的做法包括探索性测试、单元测试和提示迭代。报告的挑战包括集成失败、不可预测的输出、提示敏感性、幻觉以及对正确性的不确定性。

**Conclusion:** 测试LLM驱动系统需要对传统验证方法进行调整，将源代码级推理与行为感知评估相结合。这些发现为软件系统中生成式组件的测试实践提供了证据。

> **ai_Abstract:** 本研究通过一项探索性案例研究，分析了99份学生构建和部署LLM驱动应用的报告，旨在探索LLM驱动软件系统在实际开发中的测试过程。研究发现，测试策略结合了手动和自动化方法，并普遍采用探索性测试、单元测试和提示迭代。主要挑战包括集成失败、输出不可预测和提示敏感性。研究结论是，测试LLM驱动系统需要适应传统验证方法，结合源代码级推理和行为感知评估。

> **摘要翻译:** 背景：大型语言模型（LLM）驱动的软件系统正成为日常技术中常见的组成部分，支持着广泛领域的应用。在软件工程领域，许多研究都集中于LLM如何支持代码生成、调试和文档等任务。然而，对于如何测试在开发过程中集成了LLM的完整系统，关注度有限。目的：本研究旨在探索LLM驱动系统在实际应用开发中的测试方式。方法：我们进行了一项探索性案例研究，分析了99份由学生撰写的独立报告，这些学生作为大学课程的一部分构建并部署了LLM驱动的应用程序。每份报告都通过专题分析，并辅以结构化编码过程进行独立分析。结果：测试策略结合了手动和自动化方法，以评估系统逻辑和模型行为。常见的做法包括探索性测试、单元测试和提示迭代。报告的挑战包括集成失败、不可预测的输出、提示敏感性、幻觉以及对正确性的不确定性。结论：测试LLM驱动系统需要对传统验证方法进行调整，将源代码级推理与行为感知评估相结合。这些发现为软件系统中生成式组件的测试实践提供了证据。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [407] [GPT-4.1 Sets the Standard in Automated Experiment Design Using Novel Python Libraries](https://arxiv.org/abs/2508.00033)
> *GPT-4.1 使用新型 Python 库为自动化实验设计设定标准*

*Nuno Fachada, Daniel Fernandes, Carlos M. Fernandes, Bruno D. Ferreira-Saraiva, João P. Matos-Carvalho* | **Category: cs.SE, cs.AI, cs.CL, 68T50, I.2.2; I.2.7; D.2.3** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 自动化实验设计, Python 库, GPT-4.1, 基准测试

**Comment:** 

> **TL;DR:** 本研究系统性地评估了最先进的大型语言模型在生成用于复杂计算实验的 Python 代码方面的能力，发现 GPT-4.1 在使用不熟悉的 Python API 方面表现最佳，并强调了当前 LLM 在科学自动化方面的局限性。

**AI_Comments:** 该论文创新性地评估了LLM在处理不熟悉Python API方面的实际能力，这对于推动科学研究自动化至关重要。其重要性在于，它不仅量化了当前LLM的性能差距，特别是突出了GPT-4.1的优越性，还间接揭示了现有第三方库文档和实现方面可能存在的问题。研究的局限性在于，它仅考察了特定类型的计算实验和Python库，结果可能无法完全推广到所有科学自动化场景。然而，其强调提示工程和库文档质量的必要性，为未来LLM在科学领域应用提供了宝贵的指导。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在科学研究中自动化代码生成方面取得了快速进展，但它们解释和使用不熟悉的 Python API 进行复杂计算实验的能力仍未得到充分表征。

**Method:** 本研究系统性地基准测试了一系列最先进的 LLM，以生成功能性 Python 代码，用于两个日益具有挑战性的场景：使用 ParShift 库进行会话数据分析，以及使用 pyclugen 和 scikit-learn 进行合成数据生成和聚类。所有实验均使用结构化、零样本提示，指定详细要求但省略上下文示例。模型输出通过多次运行的功能正确性和提示依从性进行定量评估，并通过分析代码执行失败时产生的错误进行定性评估。

**Result:** 结果显示，只有一小部分模型始终生成正确、可执行的代码，其中 GPT-4.1 是唯一一个在两项任务中都能成功完成的模型。除了基准测试 LLM 性能外，这种方法还有助于识别第三方库的缺点，例如不清晰的文档或模糊的实现错误。

**Conclusion:** 这些发现强调了 LLM 在端到端科学自动化方面的当前局限性，并强调了仔细的提示设计、全面的库文档以及语言模型能力持续进步的必要性。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs）在解释和使用不熟悉的 Python API 进行复杂计算实验方面的能力。通过基准测试多种LLM在会话数据分析和合成数据生成与聚类任务中的表现，发现多数模型难以生成正确的代码，而GPT-4.1是唯一一个始终成功的模型。研究结果不仅揭示了LLM在科学自动化方面的局限性，也指出了第三方库文档不足等问题，强调了优化提示设计、完善库文档及提升LLM能力的重要性。

> **摘要翻译:** 大型语言模型（LLMs）作为科学研究中自动化代码生成的工具已迅速发展，但它们解释和使用不熟悉的 Python API 进行复杂计算实验的能力仍未得到充分表征。本研究系统性地基准测试了一系列最先进的 LLM，以生成功能性 Python 代码，用于两个日益具有挑战性的场景：使用 ParShift 库进行会话数据分析，以及使用 pyclugen 和 scikit-learn 进行合成数据生成和聚类。所有实验均使用结构化、零样本提示，指定详细要求但省略上下文示例。模型输出通过多次运行的功能正确性和提示依从性进行定量评估，并通过分析代码执行失败时产生的错误进行定性评估。结果显示，只有一小部分模型始终生成正确、可执行的代码，其中 GPT-4.1 是唯一一个在两项任务中都能成功完成的模型。除了基准测试 LLM 性能外，这种方法还有助于识别第三方库的缺点，例如不清晰的文档或模糊的实现错误。总的来说，这些发现强调了 LLM 在端到端科学自动化方面的当前局限性，并强调了仔细的提示设计、全面的库文档以及语言模型能力持续进步的必要性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [416] [Leveraging Large Language Model for Information Retrieval-based Bug Localization](https://arxiv.org/abs/2508.00253)
> *利用大型语言模型进行信息检索式缺陷定位*

*Moumita Asad, Rafed Muhammad Yasir, Armin Geramirad, Sam Malek* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 缺陷定位, 信息检索, 词汇不匹配, GenLoc

**Comment:** 

> **TL;DR:** 提出GenLoc，一个基于LLM的缺陷定位方法，通过迭代分析代码库，显著优于现有技术。

**AI_Comments:** 该论文的创新点在于将大型语言模型引入信息检索式缺陷定位领域，并通过结合代码探索和可选的向量嵌入来有效解决词汇不匹配这一长期存在的问题。其在真实世界数据集上取得的显著性能提升，特别是Accuracy@1的显著提高，表明了LLM在该领域的巨大潜力，为未来的缺陷定位研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有信息检索式缺陷定位方法受限于缺陷报告与源代码之间的词汇不匹配问题。

**Method:** 本文提出了一种名为GenLoc的新型基于大型语言模型（LLM）的缺陷定位方法。GenLoc利用配备代码探索功能的LLM迭代分析代码库以识别潜在的缺陷文件，并可选地使用向量嵌入检索语义相关文件以获取更好的上下文。

**Result:** GenLoc在六个大型Java项目的9000多个真实缺陷报告上进行了评估。实验结果显示，GenLoc在多项指标上优于五种最先进的缺陷定位技术，在Accuracy@1上平均提升超过60%。

**Conclusion:** GenLoc有效解决了词汇不匹配问题，显著提升了信息检索式缺陷定位的性能。

> **ai_Abstract:** 本文提出了一种名为GenLoc的新型信息检索式缺陷定位方法，该方法利用大型语言模型（LLM）及其代码探索功能来迭代分析代码库并识别潜在的缺陷文件，以解决现有方法中缺陷报告与源代码之间的词汇不匹配问题。GenLoc还可选择性地利用向量嵌入来增强上下文。在六个大型Java项目的9000多个真实缺陷报告上的广泛评估表明，GenLoc在多个指标上显著优于五种最先进的技术，尤其在Accuracy@1上平均提升超过60%。

> **摘要翻译:** 信息检索式缺陷定位旨在为给定的缺陷报告识别有缺陷的源文件。尽管现有方法——从向量空间模型到深度学习模型——在该领域已显示出潜力，但它们的有效性常常受限于缺陷报告与源代码之间的词汇不匹配问题。为了解决这个问题，我们提出了一种新颖的基于大型语言模型（LLM）的缺陷定位方法，称为GenLoc。给定一个缺陷报告，GenLoc利用配备代码探索功能的LLM迭代分析代码库并识别潜在的有缺陷文件。为了收集更好的上下文，GenLoc可以选择性地使用向量嵌入检索语义相关文件。GenLoc已在来自六个大型Java项目的9000多个真实缺陷报告上进行了评估。实验结果表明，GenLoc在多项指标上优于五种最先进的缺陷定位技术，在Accuracy@1上平均提升超过60%。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [441] [Managing Power Gaps as a Topic of Pair Programming Skill: A Grounded Theory](https://arxiv.org/abs/2508.00462)
> *管理权力差距作为结对编程技能的一个主题：扎根理论*

*Linus Ververs, Lutz Prechelt* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 结对编程, 权力差距, 扎根理论, 软件开发, 团队合作

**Comment:** 

> **TL;DR:** 本研究通过扎根理论和问卷调查，提出了结对编程中的“权力差距”理论，指出其损害知识转移、代码质量和效率，并强调避免等级行为和促进平等行为是提高结对编程技能的关键。

**AI_Comments:** 这项研究创新性地将“权力差距”这一社会学概念引入结对编程领域，揭示了其对软件开发效率和质量的潜在负面影响。采用扎根理论结合大规模问卷调查的方法，使得理论既有深度又有广度。为结对编程实践提供了具体的行为指导，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 理解工业结对编程中与权力相关的现象，并为实践者提供如何改进结对编程的建议。

**Method:** 采用扎根理论方法论分析了22次工业结对编程会话，构建了关于权力相关行为的扎根理论。随后对292名参与者进行了问卷调查，以验证该理论中现象的普遍性。

**Result:** 提出了“权力差距”理论，即参与机会的感知差异。研究表明权力差距的形成行为及其导致的后果，包括损害知识转移、代码质量和过程效率。问卷调查证实了理论中所有概念在实践中的普遍性。

**Conclusion:** 避免权力差距是结对编程的一项重要技能。结对伙伴应避免等级行为（增加权力差距）并多进行平等行为（减少权力差距）。

> **ai_Abstract:** 本研究通过扎根理论方法论分析了22次工业结对编程会话，并结合292名参与者的问卷调查，提出了“权力差距”理论。该理论将“权力差距”定义为参与机会的感知差异，并揭示了其对知识转移、代码质量和过程效率的负面影响。研究强调，在结对编程中，避免等级行为和增加平等行为是有效管理和避免权力差距的关键技能。

> **摘要翻译:** 背景：结对编程作为一种工作模式在专业的软件开发中被（偶尔或频繁地）使用。目标：了解在工业结对编程中出现哪些与权力相关的现象；为实践者提供如何做得更好的结对编程的建议。方法：使用扎根理论方法论分析22次工业结对编程会话。形成关于权力相关行为的扎根理论。对292名参与者就该理论进行问卷调查。用它来证明这些现象是普遍的。结果：我们的理论描述了权力差距现象：一种感知到的参与机会差异。该理论展示了产生权力差距或由其产生的行为。权力差距往往会损害知识转移、代码质量和过程效率。问卷调查结果表明，我们理论中的所有概念在实践中都很常见。它们还为只能间接观察到的概念提供了更多的基础。结论：能够避免权力差距是结对编程技能的一个宝贵组成部分。具体来说，结对伙伴需要避免等级行为（这往往会产生或增加权力差距），并且应该进行足够的平等行为（这可以防止或减少权力差距）。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [466] [Can User Feedback Help Issue Detection? An Empirical Study on a One-billion-user Online Service System](https://arxiv.org/abs/2508.00593)
> *用户反馈能否帮助问题检测？一项针对十亿用户在线服务系统的实证研究*

*Shuyao Jiang, Jiazhen Gu, Wujie Zheng, Yangfan Zhou, Michael R. Lyu* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 用户反馈, 问题检测, 实证研究, 在线服务系统, 机器学习

**Comment:** Accepted by the 19th ACM/IEEE International Symposium on Empirical
  Software Engineering and Measurement (ESEM 2025)

> **TL;DR:** 本研究对一个拥有十亿用户的在线服务系统中的数千万用户反馈进行了实证分析，旨在理解用户反馈的特性及其对问题检测的帮助。研究发现，大量用户反馈包含无关信息，且严重问题难以仅凭反馈特征检测，但机器学习方法对分析用户反馈是可行的。

**AI_Comments:** 这项研究的重要性在于其大规模的实证分析，覆盖了超过5000万条用户反馈，这在同类研究中是罕见的。它揭示了在实际生产环境中，用户反馈的复杂性和噪音，特别是其中包含大量无关信息以及严重问题难以直接从反馈特征中识别的挑战。这为未来开发更实用的、基于反馈的问题检测系统提供了关键的指导，强调了数据预处理和机器学习方法的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 长期以来，人们认为用户反馈可以帮助问题检测。然而，对于接收大量反馈的大规模在线服务系统来说，从用户反馈中识别严重问题仍然是一项挑战。为了开发更好的基于反馈的问题检测方法，首先需要全面了解实际生产系统中用户反馈的特征。

**Method:** 本研究对一个拥有十亿用户的在线服务系统中六个真实服务提供的50,378,766条用户反馈进行了实证研究。研究首先分析了用户在反馈中提供了什么信息，然后检查了反馈项的某些特征是否能作为严重问题的良好指标，最后探讨了采用机器学习技术分析用户反馈的合理性。

**Result:** 研究结果表明，大部分用户反馈提供了与系统问题无关的信息，因此在处理用户反馈时过滤掉无关信息至关重要。此外，研究发现仅凭用户反馈特征难以轻易检测到严重问题。最后，不同时间段内反馈主题的分布相似，这证实了设计基于机器学习的方法来更好地分析用户反馈是可行的方向。

**Conclusion:** 本研究的发现可以为大规模服务系统中基于反馈的问题检测提供实证基础，为实际问题检测方法的设计和实施提供了启示。

> **ai_Abstract:** 本研究针对一个拥有十亿用户的在线服务系统，对超过5000万条用户反馈进行了大规模实证分析，旨在理解用户反馈的特性及其在问题检测中的作用。研究发现，用户反馈中存在大量与问题无关的信息，且仅凭反馈特征难以有效识别严重问题。然而，反馈主题分布的稳定性表明，采用机器学习技术进行反馈分析是可行的方向。这些发现为大规模服务系统中基于反馈的问题检测方法的未来设计与实施提供了重要的经验基础。

> **摘要翻译:** 背景：长期以来，人们认为用户反馈（通常由终端用户以自然语言编写）可以帮助问题检测。然而，对于接收大量反馈的大规模在线服务系统来说，从用户反馈中识别严重问题仍然是一项具有挑战性的任务。目的：为了开发更好的基于反馈的问题检测方法，首先全面了解实际生产系统中用户反馈的特征至关重要。方法：在本文中，我们对一个拥有十亿用户的在线服务系统中六个真实服务的50,378,766条用户反馈进行了实证研究。我们首先研究了用户在反馈中提供了什么。然后，我们检查了反馈项的某些特征是否能作为严重问题的良好指标。最后，我们调查了采用机器学习技术分析用户反馈是否合理。结果：我们的结果表明，大部分用户反馈提供了与系统问题无关的信息。因此，在处理用户反馈时过滤掉与问题无关的信息至关重要。此外，我们发现仅凭用户反馈特征无法轻易检测到严重问题。最后，我们发现不同时间段内反馈主题的分布相似。这证实了设计基于机器学习的方法来更好地分析用户反馈是可行的方向。结论：我们认为我们的发现可以为大规模服务系统中基于反馈的问题检测提供实证基础，这为实际问题检测方法的设计和实施提供了启示。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [491] [MCeT: Behavioral Model Correctness Evaluation using Large Language Models](https://arxiv.org/abs/2508.00630)
> *MCeT: 使用大型语言模型评估行为模型正确性*

*Khaled Ahmed, Jialing Song, Boqi Chen, Ou Wei, Bingzhou Zheng* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 行为模型, 正确性评估, 大型语言模型, 序列图, 自动化工具

**Comment:** MODELS 2025

> **TL;DR:** MCeT是一个使用大型语言模型（LLM）自动评估行为模型（特别是序列图）相对于需求文本正确性的工具。它通过细粒度、多视角和自洽性检查方法，显著提高了问题检测的准确性和召回率，克服了直接使用LLM的局限性。

**AI_Comments:** MCeT的创新之处在于它首次提出并实现了完全自动化的行为模型正确性评估，特别是在LLM辅助建模的背景下。它不仅利用了LLM强大的自然语言理解能力，还通过引入细粒度、多视角和自洽性检查的策略，有效解决了LLM在直接比较中容易产生幻觉和漏报的问题。这对于提高自动化建模的质量和可靠性具有重要意义，也为未来AI辅助设计工具的自我评估和自我提升提供了基础。该研究对于软件工程中的模型验证和LLM在专业领域应用具有重要推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）作为AI建模助手的日益普及，图表生成将涉及更多的自动化。这使得开发自动模型正确性评估工具变得必要。此类工具可用于评估手动和AI自动生成的模型，为系统工程师提供反馈，并使AI助手能够自我评估和自我提升其生成的模型。

**Method:** 本文提出了MCeT，这是一个全自动工具，用于评估行为模型（特别是序列图）相对于其对应需求文本的正确性。MCeT利用LLM进行正确性评估，但发现直接询问LLM的效果不佳（仅能找到不到35%的问题）。为此，MCeT提出了一种细粒度、多视角的方法，将图表分解为原子交互，将需求文本分解为原子项，并进行比较。此外，还引入了一种自洽性检查方法，结合多个视角以减轻LLM幻觉问题。

**Result:** MCeT的组合方法在真实需求数据集上将直接方法的精度从0.58提高到0.81。此外，该方法比直接方法多发现了经验工程师发现的90%的问题，并且每个图表平均报告了6个新问题。

**Conclusion:** MCeT是第一个全自动的行为模型（特别是序列图）正确性评估工具，它通过结合LLM的自然语言理解能力与创新的细粒度、多视角和自洽性检查方法，显著提高了模型正确性评估的准确性和效率，为自动化模型生成和验证提供了重要支持。

> **ai_Abstract:** MCeT是一个创新的全自动工具，旨在评估行为模型（特别是序列图）相对于其需求文本的正确性。鉴于大型语言模型（LLM）在自动化图表生成中的应用日益增多，MCeT利用LLM的自然语言理解能力，通过一种精细的多视角方法克服了LLM直接评估的局限性。它将图表和需求分解为原子单元进行比较，并引入自洽性检查以提高准确性。实验结果表明，MCeT显著提高了问题检测的精度和召回率，比直接方法更有效地识别了经验工程师发现的问题。

> **摘要翻译:** 行为模型图，例如序列图，是一种重要的文档形式，通常由系统工程师根据需求文档设计，可以是完全手动或借助设计工具。随着大型语言模型（LLM）作为AI建模助手的日益普及，图表生成将涉及更多的自动化。这使得自动模型正确性评估工具的进步变得必要。这样的工具可以用来评估手动和AI自动生成的模型；向系统工程师提供反馈，并使AI助手能够自我评估和自我增强其生成的模型。
在本文中，我们提出了MCeT，这是第一个完全自动化的工具，用于评估行为模型（特别是序列图）对其相应需求文本的正确性，并生成模型存在的问题列表。我们利用LLM进行正确性评估任务，因为它们已显示出卓越的自然语言理解能力。然而，我们发现直接要求LLM比较图表和需求，只能找到经验工程师发现的问题的不到35%。我们建议通过细粒度、多视角的方法补充直接检查；我们将图表分解为原子、不可分割的交互，并将需求文本分解为原子、自包含的项。我们将图表与原子需求进行比较，并将每个图表原子与需求进行比较。我们还提出了一种自洽性检查方法，该方法结合了多个视角以减轻LLM幻觉问题。我们的组合方法在真实需求数据集上将直接方法的精度从0.58提高到0.81。此外，该方法比直接方法多发现了经验工程师发现的90%的问题，并且每个图表平均报告了平均6个新问题。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [500] [Benchmarking LLMs for Unit Test Generation from Real-World Functions](https://arxiv.org/abs/2508.00408)
> *基准测试LLM在真实世界函数单元测试生成中的表现*

*Dong Huang, Jie M. Zhang, Mark Harman, Qianru Zhang, Mingzhe Du, See-Kiong Ng* | **Category: cs.SE, cs.CL** | **Updated: 2025-08-01**

**Keywords:** LLM, 单元测试生成, 基准测试, 数据污染, 真实世界函数

**Comment:** Under Review

> **TL;DR:** 新基准ULT揭示LLM在真实函数单元测试生成方面表现远低于现有基准，现有基准存在数据污染和结构简单问题。

**AI_Comments:** 这篇论文的创新点在于提出了一个更接近真实世界、更具挑战性的LLM单元测试生成基准ULT，有效解决了现有基准的数据污染和结构简单问题。其重要性在于为未来LLM在软件测试领域的评估提供了更可靠的工具，并揭示了LLM在该领域当前能力的局限性，为后续研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM单元测试生成基准存在数据污染和结构简单两大缺陷，导致实证研究结论可能存在偏差且无法泛化到真实程序。

**Method:** 引入了新的基准ULT (UnLeakedTestbench)，专门用于从真实Python函数生成函数级单元测试，通过多阶段筛选过程确保高圈复杂度并减轻测试用例污染。还提供了PLT (PreLeakedTestbench) 作为ULT的配对基准，用于受控分析记忆与推理。

**Result:** 在ULT上，LLM生成的测试用例的准确率、语句覆盖率、分支覆盖率和变异分数平均仅为41.32%、45.10%、30.22%和40.21%，显著低于TestEval (91.79%, 92.18%, 82.04%, 49.69%) 和PLT (47.07%, 55.13%, 40.07%, 50.80%)。这表明ULT更具挑战性。

**Conclusion:** 现有LLM在真实世界函数单元测试生成方面的能力远未达到理想水平，需要更具挑战性和真实性的基准来准确评估和推动LLM在该领域的发展。

> **ai_Abstract:** 本文介绍了ULT (UnLeakedTestbench)，一个用于评估大型语言模型（LLMs）在真实世界Python函数单元测试生成能力的新基准。为了解决现有基准的数据污染和函数结构简单问题，ULT通过多阶段筛选构建，包含3,909个高复杂度函数。研究结果显示，LLMs在ULT上的测试生成表现远低于现有基准，揭示了LLMs在真实场景中仍面临显著挑战。同时引入PLT用于分析记忆与推理。

> **摘要翻译:** 最近，大型语言模型（LLMs）在自动化单元测试生成方面展现出巨大潜力，显著减少了开发人员所需的手动工作。为了有效评估LLMs在该领域的能力，拥有一个精心设计、能准确反映真实世界场景并减轻常见缺陷的基准至关重要。现有的LLM测试生成基准存在两个关键缺陷：数据污染和结构简单的函数代码。因此，我们通常无法相信使用这些有限基准进行的实证研究得出的科学结论的有效性。由于污染，所呈现的实证证据可能存在偏差；由于结构简单，可能无法泛化到玩具程序之外。
为了解决这些问题，我们引入了ULT（UnLeakedTestbench），一个专门为从真实Python函数生成函数级单元测试而设计的新基准。ULT通过多阶段筛选过程构建，确保高圈复杂度并减轻测试用例污染。ULT包含3,909个精心挑选的函数级任务，为LLM的测试生成能力提供了更真实和更具挑战性的评估。我们还提供了PLT（PreLeakedTestbench），一个与ULT配对的、包含泄露测试的基准，旨在实现对测试生成中记忆与推理的受控分析。我们的评估结果表明ULT更具挑战性。例如，LLM生成的测试用例在所有LLM上的准确率、语句覆盖率、分支覆盖率和变异分数平均仅达到41.32%、45.10%、30.22%和40.21%。这些结果显著低于TestEval（91.79%、92.18%、82.04%和49.69%）和PLT（47.07%、55.13%、40.07%和50.80%）上对应的指标。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [509] [Is LLM-Generated Code More Maintainable \& Reliable than Human-Written Code?](https://arxiv.org/abs/2508.00700)
> *LLM生成的代码比人类编写的代码更具可维护性和可靠性吗？*

*Alfred Santa Molison, Marcia Moraes, Glaucia Melo, Fabio Santos, Wesley K. G. Assuncao* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** LLM, 代码生成, 软件质量, 可维护性, 可靠性

**Comment:** Accepted ESEM2025

> **TL;DR:** 本研究比较了LLM生成的代码与人类编写的代码在内部质量属性上的差异。结果显示，LLM生成的代码通常具有更少的bug且修复所需精力更少，但对于复杂问题可能会引入新的结构性问题。

**AI_Comments:** 这项研究通过实证分析，为LLM生成的代码质量提供了初步的、有价值的洞察。其创新点在于使用了SonarQube进行客观的代码质量评估，并比较了不同LLM配置（零样本、少样本、微调）的效果。重要性在于其结果有助于理解LLM在实际软件开发中的潜力与局限。局限性在于，尽管LLM代码在某些方面表现优异，但在复杂问题上仍存在引入新结构性问题的风险，这表明LLM生成的代码在部署前仍需严格的人工审查和验证。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在软件开发中的兴起为代码生成开辟了新的可能性，但LLM生成的代码在软件质量方面的表现以及与人类编写代码的比较仍不清楚。

**Method:** 本研究采用实证方法，整合了编码任务数据集、三种LLM配置（零样本、少样本和微调）以及SonarQube来评估软件质量。数据集包含Python代码解决方案，涵盖入门级、面试级和竞赛级三个难度级别。分析了关键代码质量指标，包括可维护性和可靠性，以及解决代码问题所需的估计精力。

**Result:** 分析表明，LLM生成的代码总体上bug更少，修复所需的精力也更少。微调模型减少了阻塞和关键性bug等高严重性问题的发生，并将其转移到较低严重性类别，但降低了模型性能。在竞赛级别问题中，LLM解决方案有时会引入人类编写代码中不存在的结构性问题。

**Conclusion:** 研究结果为LLM生成代码的质量提供了有价值的见解；然而，在更复杂的场景中引入关键问题，凸显了对LLM解决方案进行系统评估和验证的必要性。本工作加深了对LLM代码生成优势和局限性的理解。

> **ai_Abstract:** 本研究旨在比较LLM生成的代码与人类编写代码的内部质量属性，特别关注可维护性和可靠性。通过结合编码任务数据集、不同LLM配置和SonarQube进行评估，结果显示LLM生成的代码通常具有更少的bug和更低的修复成本。然而，在处理复杂问题时，LLM解决方案可能引入人类代码中不存在的结构性问题，这强调了对LLM代码生成进行系统评估和验证的重要性。

> **摘要翻译:** 背景：大型语言模型（LLM）在软件开发中的兴起为代码生成开辟了新的可能性。尽管这项技术被广泛使用，但LLM在软件质量方面生成代码解决方案的表现以及它们与人类编写代码的比较仍不清楚。目的：本研究比较了LLM生成代码和人类编写代码的内部质量属性。方法：我们的实证研究整合了编码任务数据集、三种LLM配置（零样本、少样本和微调）以及SonarQube来评估软件质量。数据集包含Python代码解决方案，涵盖入门级、面试级和竞赛级三个难度级别。我们分析了关键代码质量指标，包括可维护性和可靠性，以及解决代码问题所需的估计精力。结果：我们的分析表明，LLM生成的代码总体上bug更少，修复它们所需的精力也更少。有趣的是，微调模型减少了阻塞和关键性bug等高严重性问题的发生，并将其转移到较低严重性类别，但降低了模型的性能。在竞赛级别问题中，LLM解决方案有时会引入人类编写代码中不存在的结构性问题。结论：我们的发现为LLM生成代码的质量提供了有价值的见解；然而，在更复杂的场景中引入关键问题，凸显了对LLM解决方案进行系统评估和验证的必要性。我们的工作加深了对LLM代码生成优势和局限性的理解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [531] [Exploring the Evidence-Based SE Beliefs of Generative AI Tools](https://arxiv.org/abs/2407.13900)
> *探索生成式人工智能工具中基于证据的软件工程信念*

*Chris Brown, Jason Cusati* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 生成式AI, 软件工程, 基于证据的实践, 大型语言模型, 可信度

**Comment:** 

> **TL;DR:** 研究发现，生成式AI工具对软件工程中的实证研究结论持模糊态度，且缺乏可信证据支持其回答。

**AI_Comments:** 这项研究具有重要的现实意义，它揭示了当前生成式AI工具在理解和应用软件工程领域经验知识方面的局限性。其创新之处在于通过概念性复制实验，系统性地评估了AI工具的“信念”，为AI在软件工程中的应用提供了关键的洞察。研究结果强调了在将AI集成到关键开发流程时，对其输出的可靠性和可信度进行严格验证的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成式AI工具在软件开发中日益普及，但目前对其如何理解和采纳经过研究验证的基于证据的信念和实践知之甚少。

**Method:** 本研究通过概念性复制先前工作，对五种生成式AI工具进行了初步评估，调查了它们对17项来自经验性软件工程研究的基于证据的主张的“信念”。

**Result:** 研究结果表明，生成式AI工具对研究主张持有模糊的信念，并且缺乏可信的证据来支持其回应。

**Conclusion:** 基于研究结果，本文为将生成式AI系统集成到开发环境中的实践者提供了启示，并指明了未来研究方向，以提高生成式AI的可靠性和可信度，旨在提高对基于证据的软件工程研究成果在实践中的认识和采用。

> **ai_Abstract:** 本文旨在探索生成式AI工具对软件工程中基于证据的信念的理解程度。研究人员对五种生成式AI工具进行了评估，调查了它们对17项经验性软件工程研究主张的“信念”。结果显示，这些AI工具对研究主张的理解模糊，且缺乏可靠证据支持其回答。研究最后提供了对实践者的建议，并指出了未来提高生成式AI可靠性和可信度的研究方向，以促进基于证据的软件工程实践。

> **摘要翻译:** 近年来，主要由大型语言模型（LLMs）驱动的生成式人工智能（AI）创新，已经改变了程序员开发和维护软件的方式——开创了软件工程（SE）的新领域。生成式AI工具支持软件开发任务的先进能力，导致其在软件开发工作流程中的采用率不断上升。然而，关于AI工具如何看待经过研究发现验证的基于证据的信念和实践，人们知之甚少。为此，我们进行了一项初步评估，概念性地复制了先前的工作，以探索用于支持软件开发任务的生成式AI工具的“信念”。我们调查了五种生成式AI工具中17项由经验性软件工程研究提出的基于证据的主张。我们的研究结果表明，生成式AI工具对研究主张持有模糊的信念，并且缺乏可信的证据来支持回应。基于我们的结果，我们为将生成式AI系统集成到开发环境中的实践者提供了启示，并阐明了未来的研究方向，以增强生成式AI的可靠性和可信度——旨在提高对基于证据的软件工程研究成果在实践中的认识和采用。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [556] [How Do Community Smells Influence Self-Admitted Technical Debt in Machine Learning Projects?](https://arxiv.org/abs/2506.15884)
> *社区异味如何影响机器学习项目中的自承认技术债务？*

*Shamse Tasnim Cynthia, Nuri Almarimi, Banani Roy* | **Category: cs.SE** | **Updated: 2025-07-31**

**Keywords:** 社区异味, 自承认技术债务, 机器学习项目, 社会技术问题, 软件质量

**Comment:** 

> **TL;DR:** 本研究探讨了机器学习项目中社区异味（不良组织实践）的普遍性及其与自承认技术债务（SATD）的关系。结果表明社区异味普遍存在，某些异味与较高的SATD相关，并揭示了异味和SATD随时间演变的趋势。

**AI_Comments:** 该研究创新性地将社区异味与自承认技术债务（SATD）的关系扩展到机器学习（ML）项目领域，填补了该领域研究的空白。通过对155个开源ML项目的实证分析，揭示了特定社区异味（如“无线电静默”和“组织孤岛”）与SATD的强关联，这对于ML项目管理具有重要的实践指导意义。此外，研究还分析了异味和SATD随时间的演变趋势，为理解和管理ML项目中的技术债务提供了更全面的视角。

<details>
  <summary>Details</summary>

**Motivation:** 虽然先前的研究已在通用软件系统中探讨了社区异味和自承认技术债务（SATD）的问题，但它们在机器学习（ML）项目中的相互作用仍未得到充分研究。

**Method:** 研究分析了155个开源ML项目的发布级别数据。首先，调查了10种社区异味类型的普遍性及其在不同规模项目中的分布模式。其次，在发布级别检测SATD，并应用统计分析来检查其与社区异味的相关性。第三，确定了六种已识别的SATD类型与哪些社区异味最相关。最后，分析了社区异味和SATD如何随发布版本演变，揭示了项目规模依赖的趋势和共同的轨迹。

**Result:** 研究发现社区异味普遍存在，在小型、中型和大型项目中呈现出独特的分布模式。某些异味，如“无线电静默”（Radio Silence）和“组织孤岛”（Organizational Silos），与较高的SATD发生率密切相关。与权限和沟通相关的异味经常与持久的代码和设计债务同时出现。社区异味和SATD的演变呈现出项目规模依赖的趋势和共享的轨迹。

**Conclusion:** 研究结果强调了早期发现和缓解社会技术问题对于维护基于机器学习系统的长期质量和可持续性的重要性。

> **ai_Abstract:** 本研究深入探讨了机器学习项目中社区异味与自承认技术债务（SATD）之间的关系。通过分析155个开源ML项目的发布数据，研究发现社区异味普遍存在，并识别出特定异味（如“无线电静默”和“组织孤岛”）与更高SATD发生率的强关联。此外，研究揭示了权限和沟通相关的异味常与代码和设计债务共存，并分析了这些异味和债务随项目演变的趋势。研究强调了在ML项目中早期识别和解决社会技术问题的重要性，以确保其长期质量和可持续性。

> **摘要翻译:** 社区异味反映了不良的组织实践，这些实践通常会导致社会技术问题和自承认技术债务（SATD）的累积。虽然先前的研究已在通用软件系统中探讨了这些问题，但它们在基于机器学习（ML）的项目中的相互作用仍未得到充分研究。在本研究中，我们调查了开源ML项目中社区异味的普遍性及其与SATD的关系，分析了发布级别的数据。首先，我们检查了155个基于ML的系统在各个发布版本中十种社区异味类型的普遍性，发现社区异味普遍存在，在小型、中型和大型项目中呈现出独特的分布模式。其次，我们在发布级别检测了SATD，并应用统计分析来检查其与社区异味的相关性。我们的结果显示，某些异味，如“无线电静默”（Radio Silence）和“组织孤岛”（Organizational Silos），与较高的SATD发生率密切相关。第三，我们考虑了六种已识别的SATD类型，以确定哪些社区异味与每种债务类别最相关。我们的分析揭示了与权限和沟通相关的异味经常与持久的代码和设计债务同时出现。最后，我们分析了社区异味和SATD如何随发布版本演变，揭示了项目规模依赖的趋势和共同的轨迹。我们的发现强调了早期发现和缓解社会技术问题对于维护基于ML系统的长期质量和可持续性的重要性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [581] [Evaluating Uncertainty and Quality of Visual Language Action-enabled Robots](https://arxiv.org/abs/2507.17049)
> *评估视觉语言动作机器人中的不确定性和质量*

*Pablo Valle, Chengjie Lu, Shaukat Ali, Aitor Arrieta* | **Category: cs.SE, cs.RO** | **Updated: 2025-07-31**

**Keywords:** 视觉语言动作, 机器人操作, 不确定性指标, 质量指标, 模型评估

**Comment:** 

> **TL;DR:** 当前视觉语言动作（VLA）机器人的评估方法（任务成功率）不足。本文为VLA模型提出了新的不确定性和质量指标，并通过人类专家验证了其有效性，结果表明这些指标与人类评估高度相关，从而改进了评估和监控。

**AI_Comments:** 本文通过引入不确定性和质量指标，显著提升了视觉语言动作（VLA）模型在机器人领域评估的细致性和实用性。它创新性地超越了传统的二元成功率评估，提供了衡量机器人执行质量和模型置信度的具体工具。通过大规模实证研究和人类专家验证，增强了这些新指标的可靠性，对于推动VLA系统在实际应用中的鲁棒性和可靠性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 当前视觉语言动作（VLA）模型主要通过任务成功率进行评估，但这未能捕捉到任务执行的质量以及模型对其决策的信心。

**Method:** 本文提出了八个不确定性指标和五个质量指标，专门用于机器人操作任务中的VLA模型。通过一项大规模的实证研究，该研究涉及来自三种最先进VLA模型在四种代表性机器人操作任务中的908次成功任务执行，评估了这些指标的有效性。人类领域专家手动标记了任务质量，以分析所提出指标与专家判断之间的相关性。

**Result:** 结果显示，所提出的多个不确定性和质量指标与人类评估表现出中度到强度的相关性，这突出了它们在评估任务质量和模型置信度方面的实用性。此外，一些指标还能区分未成功任务中的高质量、中等质量和低质量执行。

**Conclusion:** 本文的研究结果挑战了当前仅依赖二元成功率的评估实践的充分性，并为改进VLA赋能机器人系统的实时监控和自适应增强铺平了道路。

> **ai_Abstract:** 本文针对机器人操作任务中的视觉语言动作（VLA）模型，提出了新的不确定性和质量评估指标，以解决当前仅依赖任务成功率评估方法的不足。通过一项涉及人类专家标记的大规模实证研究，验证了这些指标的有效性。研究结果表明，所提出的指标与人类评估具有中度到强度的相关性，证明了它们在评估任务质量和模型置信度方面的实用性。这项工作为VLA赋能机器人系统的实时监控和自适应增强提供了更全面的评估方法。

> **摘要翻译:** 视觉语言动作（VLA）模型是一类多模态人工智能（AI）系统，它整合了视觉感知、自然语言理解和动作规划，使智能体能够解释其环境、理解指令并自主执行具身任务。最近，该领域取得了显著进展。这类模型通常通过任务成功率进行评估，但这未能捕捉任务执行的质量以及模型对其决策的信心。在本文中，我们提出了八个不确定性指标和五个质量指标，专门为机器人操作任务中的VLA模型设计。我们通过一项大规模的实证研究评估了它们的有效性，该研究涉及来自三种最先进VLA模型在四种代表性机器人操作任务中的908次成功任务执行。人类领域专家手动标记了任务质量，使我们能够分析所提出的指标与专家判断之间的相关性。结果表明，多个指标与人类评估显示出中度到强度的相关性，突出了它们在评估任务质量和模型置信度方面的实用性。此外，我们发现一些指标可以区分未成功任务中的高质量、中等质量和低质量执行，这在测试预言机不可用时可能很有趣。我们的发现挑战了当前仅依赖二元成功率的评估实践的充分性，并为改进VLA赋能机器人系统的实时监控和自适应增强铺平了道路。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [593] [SPENCER: Self-Adaptive Model Distillation for Efficient Code Retrieval](https://arxiv.org/abs/2508.00546)
> *SPENCER: 自适应模型蒸馏用于高效代码检索*

*Wenchao Gu, Zongyi Lyu, Yanlin Wang, Hongyu Zhang, Cuiyun Gao, Michael R. Lyu* | **Category: cs.SE, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 代码检索, 模型蒸馏, 双编码器, 交叉编码器, 自适应

**Comment:** 

> **TL;DR:** SPENCER通过结合双编码器和交叉编码器，并使用自适应模型蒸馏技术，在保持高效率的同时显著提升了代码检索的性能。

**AI_Comments:** 该论文创新性地结合了双编码器和交叉编码器的优势，并通过自适应模型蒸馏技术解决了效率瓶颈。模型蒸馏中的助教选择策略是其亮点，确保了性能的维持。这对于实际应用中需要兼顾性能和效率的代码检索系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有代码检索方法主要采用双编码器，但其模型结构限制了性能，因为在训练时缺乏代码片段和描述底层的交互。

**Method:** 提出SPENCER框架，结合双编码器（缩小搜索空间）和交叉编码器（提高准确性）。为提高效率，引入了新颖的模型蒸馏技术，并提出了自适应选择合适助教模型的助教选择策略。

**Result:** 双编码器和交叉编码器的结合提高了整体性能。模型蒸馏技术在减少70%双编码器推理时间的同时，保持了超过98%的整体性能。

**Conclusion:** SPENCER通过结合双编码器和交叉编码器，并利用自适应模型蒸馏，成功提高了代码检索的效率和有效性。

> **ai_Abstract:** SPENCER是一个用于高效代码检索的框架。它通过结合双编码器和交叉编码器来提升性能，其中双编码器用于缩小搜索空间，交叉编码器用于提高准确性。为解决效率问题，SPENCER引入了自适应模型蒸馏技术，该技术通过选择合适的助教模型来显著减少双编码器的推理时间，同时保持模型的高性能。实验证明了该方法在性能和效率上的优势。

> **摘要翻译:** 代码检索旨在根据用户的自然语言查询，为用户提供所需的代码片段。随着深度学习技术的发展，采用预训练模型执行此任务已成为主流。考虑到检索效率，大多数以前的方法都为此任务采用了双编码器，它分别将描述和代码片段编码为表示向量。然而，双编码器的模型结构往往限制了模型的性能，因为它在训练过程中缺乏代码片段和描述在模型底层之间的交互。为了在保持效率的同时提高模型的有效性，我们提出了一个名为SPENCER的框架，它采用自适应模型蒸馏进行高效代码检索。SPENCER首先采用双编码器来缩小搜索空间，然后采用交叉编码器来提高准确性。为了提高SPENCER的效率，我们提出了一种新颖的模型蒸馏技术，可以在保持整体性能的同时大大减少双编码器的推理时间。我们还为我们的模型蒸馏提出了一种助教选择策略，该策略可以在模型蒸馏过程中自适应地为不同的预训练模型选择合适的助教模型，以确保模型性能。广泛的实验表明，与仅基于双编码器的代码检索模型相比，双编码器和交叉编码器的结合提高了整体性能。此外，我们的模型蒸馏技术在将双编码器的推理时间减少70%的同时，保留了超过98%的整体性能。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [597] [A Survey on Code Generation with LLM-based Agents](https://arxiv.org/abs/2508.00083)
> *基于LLM代理的代码生成综述*

*Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, Ge Li* | **Category: cs.SE, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 代码生成, LLM代理, 软件开发生命周期, 综述, 人工智能

**Comment:** Work in progress

> **TL;DR:** 本文对基于LLM的代码生成代理进行了系统综述，涵盖其发展、技术、应用、评估和未来研究方向。

**AI_Comments:** 这篇综述论文的重要性在于它系统地梳理了新兴的基于LLM的代码生成代理领域，明确了其核心特征、发展脉络、技术分类和应用场景。它不仅总结了现有成果，更重要的是通过分析挑战，为未来的研究指明了方向，对于推动该领域的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）驱动的代码生成代理正在革新软件开发范式，并且该领域发展迅速并具有巨大应用潜力，因此有必要对该领域进行系统性综述。

**Method:** 本文对基于LLM的代码生成代理领域进行了系统综述，追溯了该技术的发展轨迹，系统地分类了其核心技术（包括单代理和多代理架构），详细介绍了LLM代理在软件开发生命周期（SDLC）中的应用，总结了主流评估基准和指标，并收录了代表性工具。

**Result:** 通过分析主要挑战，本文识别并提出了该领域未来工作的几个基础性、长期研究方向。

**Conclusion:** 该综述通过系统梳理当前基于LLM的代码生成代理领域，指出了该领域面临的主要挑战，并为未来的研究工作提出了重要的方向。

> **ai_Abstract:** 本文对基于大型语言模型（LLM）的代码生成代理进行了系统性综述。该综述阐述了LLM代理在软件开发中的革命性作用及其自主性、扩展任务范围和增强工程实用性等核心特征。文章追溯了技术发展，分类了单代理和多代理架构，详细介绍了其在软件开发生命周期中的应用，并总结了评估基准和代表性工具。最后，论文分析了当前挑战并提出了未来研究方向。

> **摘要翻译:** 大型语言模型（LLM）驱动的代码生成代理正在彻底改变软件开发范式。与之前的代码生成技术不同，代码生成代理具有三个核心特征：1）自主性：独立管理从任务分解到编码和调试的整个工作流程的能力。2）扩展的任务范围：能力超越生成代码片段，涵盖整个软件开发生命周期（SDLC）。3）工程实用性的增强：研究重点从算法创新转向系统可靠性、过程管理和工具集成等实际工程挑战。该领域最近发展迅速，研究呈爆炸式增长，显示出巨大的应用潜力。本文对基于LLM的代码生成代理领域进行了系统综述。我们追溯了该技术从萌芽阶段的发展轨迹，并系统地分类了其核心技术，包括单代理和多代理架构。此外，本综述详细介绍了基于LLM的代理在整个SDLC中的应用，总结了主流评估基准和指标，并收录了代表性工具。最后，通过分析主要挑战，我们识别并提出了该领域未来工作的几个基础性、长期研究方向。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [601] [NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature Addition](https://arxiv.org/abs/2507.18130)
> *NoCode-bench：一个用于评估自然语言驱动的特性添加的基准*

*Le Deng, Zhonghao Jiang, Jialun Cao, Michael Pradel, Zhongxin Liu* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 自然语言处理, 无代码开发, 大型语言模型, 基准测试, 特性添加

**Comment:** 

> **TL;DR:** 本文介绍了NoCode-bench，一个用于评估LLM在自然语言驱动的无代码开发中添加功能的基准；实验表明，LLM在此类任务中表现不佳，成功率仅为15.79%，表明其尚未准备好。

**AI_Comments:** 这篇论文的创新之处在于提出了一个专门用于评估自然语言驱动的无代码开发能力的基准，特别是关注实际的特性添加任务，并利用真实世界的代码更改和开发者编写的测试用例进行验证。其重要性在于量化了当前LLM在此领域的能力局限性，明确指出了跨文件编辑、代码库理解和工具调用等关键挑战，为未来LLM在软件工程领域的进步指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言驱动的无代码开发有望提高生产力并实现开发民主化，大型语言模型（LLMs）在此领域显示出潜力。然而，需要一个基准来评估LLM在实际自然语言驱动的特性添加任务中的表现。

**Method:** 本文介绍了NoCode-bench，一个包含10个项目、634个任务和11.4万次代码更改的基准，旨在评估LLM在真实世界中自然语言驱动的特性添加任务中的能力。每个任务将文档更新与相应的代码实现配对，并通过开发者编写的测试用例进行验证。此外，还创建了一个包含114个高质量、人工验证实例的子集NoCode-bench Verified，以确保评估的可靠性。

**Result:** 实验表明，尽管LLM使用了大量token，但最佳LLM的任务成功率仅为15.79%。这突显了跨文件编辑、代码库理解和工具调用方面的挑战。

**Conclusion:** 这些发现表明LLM尚未为完全自然语言驱动的无代码开发做好准备。NoCode-bench为该领域的未来进展奠定了基础。

> **ai_Abstract:** 本文介绍了NoCode-bench，一个用于评估大型语言模型（LLMs）在自然语言驱动的无代码开发中添加新功能能力的基准。该基准包含真实世界的任务，将文档更新与代码实现配对。实验结果显示，尽管LLMs消耗大量计算资源，但其任务成功率仅为15.79%，表明在跨文件编辑、代码理解和工具调用方面存在显著挑战，并指出LLMs尚未完全适用于此类开发模式。NoCode-bench为未来研究提供了基础。

> **摘要翻译:** 自然语言驱动的无代码开发允许用户使用自然语言（NL）而不是编辑源代码来指定软件功能，有望提高生产力并实现开发民主化。大型语言模型（LLM）在此范式中显示出潜力。在此背景下，软件文档充当功能的NL规范。这项工作引入了NoCode-bench，一个旨在评估LLM在真实世界自然语言驱动的特性添加任务上的基准，它包含10个项目中的634个任务和11.4万次代码更改。每个任务将文档更新与相应的代码实现配对，并通过开发者编写的测试用例进行验证。一个包含114个高质量、人工验证实例的子集，NoCode-bench Verified，确保了可靠的评估。我们的实验表明，尽管token使用量很高，但最佳LLM的任务成功率仅为15.79%，这突出了跨文件编辑、代码库理解和工具调用方面的挑战。这些发现表明LLM尚未为完全自然语言驱动的无代码开发做好准备。NoCode-bench为该领域的未来进展奠定了基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [421] [From Individuals to Crowds: Dual-Level Public Response Prediction in Social Media](https://arxiv.org/abs/2508.00497)
> *从个体到群体：社交媒体中的双层公共响应预测*

*Jinghui Zhang, Kaiyang Wan, Longwei Xu, Ao Li, Zongfang Liu, Xiuying Chen* | **Category: cs.SI** | **Updated: 2025-08-01**

**Keywords:** 公共响应预测, 社交媒体, 双层预测, 大语言模型, 情感分析

**Comment:** ACM MM 2025

> **TL;DR:** SocialAlign是一个统一的框架，用于在社交媒体中预测微观（个性化评论）和宏观（群体情感分布）层面的公共响应，并在真实世界数据集上表现优异。

**AI_Comments:** 本文的创新之处在于提出了一个统一的双层框架SocialAlign，同时处理了公共响应预测中的个体个性化和群体情感趋势，这是现有研究的显著不足。通过引入PAC-LoRA结构和构建大规模真实世界数据集SentiWeibo，该工作为提升公共响应预测的实用性和准确性提供了有价值的贡献，并有望推动计算社会科学的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的公共响应预测工作缺乏微观层面的个性化，并忽略了宏观层面的情感分布，仅处理个体层面的情感，这限制了它们分析更广泛的社会趋势和群体情感动态的能力。

**Method:** 本文提出了SocialAlign，一个统一的框架，用于在社交语境中预测微观和宏观层面的真实世界响应。在微观层面，SocialAlign采用SocialLLM与个性化分析-组合LoRA（PAC-LoRA）结构，部署了用于内容分析和响应生成的专业专家模块，能够生成带有相应情感的个性化评论。在宏观层面，它建模群体情感分布，并将预测与来自社交媒体数据的真实世界情感趋势对齐。为了评估，引入了SentiWeibo数据集。

**Result:** 在SentiWeibo和相关LaMP基准测试上的实验结果表明，SocialAlign超越了强大的基线，在公共响应预测方面显示出更高的准确性、可解释性和泛化能力。

**Conclusion:** 本文希望这项工作能激发公共响应预测和计算社会科学的进一步研究。

> **ai_Abstract:** 本文提出SocialAlign，一个用于社交媒体中公共响应预测的双层统一框架。它解决了现有方法在微观层面缺乏个性化和宏观层面忽视群体情感分布的局限性。SocialAlign在微观层面利用SocialLLM和PAC-LoRA生成个性化评论，在宏观层面建模和对齐群体情感分布。为评估模型，作者构建了SentiWeibo数据集。实验结果表明，SocialAlign在准确性、可解释性和泛化能力方面优于现有基线。

> **摘要翻译:** 公共响应预测对于理解个人或群体如何对特定事件、政策或社会现象作出反应至关重要，这使其在危机管理、政策制定和社交媒体分析中具有高度价值。然而，现有工作面临显著的局限性。首先，它们缺乏微观层面的个性化，产生的通用响应忽略了个人用户偏好。此外，它们忽视了宏观情感分布，只处理个体层面的情感，这限制了它们分析更广泛的社会趋势和群体情感动态。为了解决这些挑战，我们提出了SocialAlign，一个统一的框架，用于在社交语境中预测微观和宏观层面的真实世界响应。在微观层面，SocialAlign采用SocialLLM与个性化分析-组合LoRA（PAC-LoRA）结构，该结构部署了专门的专家模块，用于跨不同主题和用户配置文件的内容分析和响应生成，从而能够生成带有相应情感的个性化评论。在宏观层面，它建模群体情感分布，并将预测与来自社交媒体数据的真实世界情感趋势对齐。为了在真实世界场景中评估SocialAlign，我们引入了SentiWeibo，一个从微博平台上真实社交互动中整理出的大规模数据集。我们在SentiWeibo和相关LaMP基准测试上的实验结果表明，SocialAlign超越了强大的基线，在公共响应预测方面显示出更高的准确性、可解释性和泛化能力。我们希望我们的工作能激发公共响应预测和计算社会科学的进一步研究：https://github.com/Znull-1220/SocialAlign。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [446] [A Novel Dynamic Epidemic Model for Successive Opinion Diffusion in Social Networks](https://arxiv.org/abs/2504.01718)
> *社交网络中连续意见扩散的新型动态流行病模型*

*Bin Han, Fabienne Renckens, C. Clark Cao, Hans D. Schotten* | **Category: cs.SI** | **Updated: 2025-07-31**

**Keywords:** 意见扩散, 流行病模型, 社交网络, 回声室效应, 社会极化

**Comment:** To appear in IEEE GLOBECOM 2025

> **TL;DR:** 本文提出了一种扩展SHIMR模型的新型动态流行病模型，用于社交网络中的连续意见扩散，并考虑了社会距离和谣言的影响，模拟验证了其在解释回声室效应和理解社会极化方面的有效性。

**AI_Comments:** 本文的创新之处在于其对SHIMR模型的扩展，引入了动态决策和累积意见扩散机制，并考虑了谣言传播对网络结构的影响。这为理解复杂的社交网络现象（如回声室效应和社会极化）提供了新的工具和视角，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出一种新型动态流行病模型，以扩展SHIMR模型，从而更好地捕捉社交网络中受社会距离影响的动态决策以及由相互关联谣言引起的累积意见扩散现象。

**Method:** 本文提出了一种新型动态流行病模型，用于社交网络中的连续意见扩散。该模型扩展了SHIMR模型，并融入了受社会距离影响的动态决策机制，同时捕捉了由相互关联谣言引起的累积意见扩散过程。该模型还反映了谣言传播对社交网络结构的影响。

**Result:** 模拟验证了该模型在解释回声室效应等现象方面的有效性，并为意见扩散动力学提供了深入见解。

**Conclusion:** 该模型对理解社会极化和网络演化具有重要意义。

> **ai_Abstract:** 本文提出了一种扩展SHIMR模型的新型动态流行病模型，用于分析社交网络中的连续意见扩散。该模型考虑了社会距离对动态决策的影响以及相互关联谣言引起的累积意见扩散，并反映了谣言传播对网络结构的作用。模拟结果表明，该模型能有效解释回声室效应，并为理解意见扩散动力学、社会极化和网络演化提供了见解。

> **摘要翻译:** 本文提出了一种用于社交网络中连续意见扩散的动态流行病模型，该模型是SHIMR模型的扩展。它结合了受社会距离影响的动态决策，并捕捉了由相互关联谣言引起的累积意见扩散。该模型反映了谣言传播对社交网络结构的影响。模拟验证了其在解释回声室效应等现象方面的有效性，并为意见扩散动力学提供了深入见解，对理解社会极化和网络演化具有重要意义。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [204] [Melody-Lyrics Matching with Contrastive Alignment Loss](https://arxiv.org/abs/2508.00123)
> *旋律-歌词匹配与对比对齐损失*

*Changhong Wang, Michel Olvera, Gaël Richard* | **Category: eess.AS, cs.IR** | **Updated: 2025-07-31**

**Keywords:** 旋律-歌词匹配, 对比对齐损失, 自监督学习, 音节级表示, 音乐信息检索

**Comment:** 10 pages, 7 figures, 3 tables. This work has been submitted to the
  IEEE for possible publication

> **TL;DR:** 本文提出了一种新的旋律-歌词匹配任务，并采用自监督表示学习框架和对比对齐损失来解决，无需对齐标注，并引入了音节级的歌词表示sylphone。

**AI_Comments:** 本文的创新点在于提出了旋律-歌词匹配这一新任务，并设计了一个无需对齐标注的自监督学习框架，这极大地降低了数据标注成本。引入音节级歌词表示sylphone也是一个亮点，有助于捕捉旋律和歌词之间更细致的对应关系。该研究为音乐信息检索领域开辟了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 音乐和歌词之间的联系远不止语义上的关联，还存在节奏、韵律、音符时长、音节重音和结构对应等概念对。这是一个引人注目但鲜有探索的音乐信息检索方向。本文旨在利用旋律和歌词之间的关系，为给定旋律检索潜在歌词，而不是从头生成歌词。

**Method:** 本文提出了一种带有对比对齐损失的自监督表示学习框架，用于旋律和歌词的匹配。该方法无需对齐标注。此外，还引入了一种新的音节级歌词表示sylphone，该表示由音素身份和元音重音激活。

**Result:** 实验结果和直观示例表明，本文提出的方法可以将旋律与连贯且可唱的歌词进行匹配。

**Conclusion:** 本文成功地提出了旋律-歌词匹配任务，并开发了一种无需对齐标注的自监督学习框架，能够有效匹配旋律和歌词，展示了音乐和歌词深层联系的潜力。

> **ai_Abstract:** 本文提出了一项新任务——旋律-歌词匹配（MLM），旨在为给定旋律检索合适的歌词。研究强调音乐与歌词间超越语义的深层联系。为此，论文提出了一种基于对比对齐损失的自监督表示学习框架，无需人工标注。同时，引入了创新的音节级歌词表示sylphone。实验证明该方法能有效匹配旋律与连贯且可唱的歌词。

> **摘要翻译:** 音乐和歌词之间的联系远不止语义上的关联。两种模态中的概念对，如节奏与韵律、音符时长与音节重音、以及结构对应，提出了音乐信息检索领域一个引人注目但鲜有探索的方向。在本文中，我们提出了旋律-歌词匹配（MLM），这是一项新任务，它为给定符号旋律从文本源中检索潜在歌词。MLM本质上利用了旋律和歌词之间的关系，而不是从头生成歌词。我们提出了一种带有对比对齐损失的自监督表示学习框架，用于旋律和歌词。这有可能利用现有大量带有配对旋律和歌词的歌曲。不需要对齐标注。此外，我们引入了sylphone，这是一种由音素身份和元音重音激活的、新颖的音节级歌词表示。我们通过实证结果和直观示例证明，我们的方法可以将旋律与连贯且可唱的歌词进行匹配。我们开源了代码并在配套网页上提供了匹配示例：https://github.com/changhongw/mlm。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [231] [Ambisonics Super-Resolution Using A Waveform-Domain Neural Network](https://arxiv.org/abs/2508.00240)
> *使用波形域神经网络的Ambisonics超分辨率*

*Ismael Nawfal, Symeon Delikaris Manias, Mehrez Souden, Juha Merimaa, Joshua Atkins, Elisabeth McMullin, Shadi Pirhosseinloo, Daniel Phillips* | **Category: eess.AS, cs.SD** | **Updated: 2025-08-01**

**Keywords:** Ambisonics, 超分辨率, 神经网络, Conv-TasNet, 空间音频

**Comment:** 

> **TL;DR:** 本文提出了一种基于Conv-TasNet的神经网络方法，将一阶Ambisonics（FOA）音频转换为更高阶的Ambisonics（HOA），显著提高了空间准确性和感知质量，超越了传统渲染器。

**AI_Comments:** 该论文的创新点在于将深度学习（Conv-TasNet）应用于空间音频的超分辨率问题，特别是将低阶Ambisonics提升到高阶Ambisonics。这种数据驱动的方法突破了传统基于物理和心理声学模型渲染器的局限性，为空间音频处理提供了新的思路，具有重要的研究价值和潜在的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 一阶Ambisonics (FOA) 格式虽然高效，但其有限的通道数导致空间精度不足。为了克服FOA的这些局限性，同时保留其效率，需要一种新的解决方案。

**Method:** 本研究开发了一种数据驱动的空间音频解决方案。它利用一个全卷积时域音频神经网络（Conv-TasNet），将FOA输入转换为更高阶的Ambisonics (HOA) 输出。与传统的基于物理和心理声学的渲染器相比，这是一种新颖的数据驱动方法。

**Result:** 定量评估显示，预测的与实际的三阶HOA之间平均位置均方误差差异为0.6dB。定性评估中值显示，与传统渲染方法相比，感知质量提高了80%。

**Conclusion:** 本文提出的基于神经网络的Ambisonics超分辨率方法能够有效地将FOA提升为HOA，显著提高空间准确性和感知质量，优于传统渲染器。

> **ai_Abstract:** 该论文提出了一种利用波形域神经网络（Conv-TasNet）实现Ambisonics超分辨率的新方法。针对一阶Ambisonics（FOA）在空间精度上的限制，研究开发了一种数据驱动的解决方案，能将FOA输入转换为更高阶的Ambisonics（HOA）输出。实验结果表明，该方法在空间准确性上优于传统渲染器，并且在感知质量上实现了显著提升。

> **摘要翻译:** Ambisonics是一种描述声场的空间音频格式。一阶Ambisonics（FOA）是一种流行的格式，仅包含四个通道。这种有限的通道数量是以空间精度为代价的。理想情况下，人们希望能够利用FOA格式的效率而没有其局限性。我们设计了一种数据驱动的空间音频解决方案，它保留了FOA格式的效率，但实现了超越传统渲染器的质量。利用一个全卷积时域音频神经网络（Conv-TasNet），我们创建了一个解决方案，它接收FOA输入并提供更高阶的Ambisonics（HOA）输出。与典型的基于物理和心理声学的渲染器相比，这种数据驱动的方法是新颖的。定量评估显示，预测的三阶HOA与实际的三阶HOA之间平均位置均方误差差异为0.6dB。定性评分中值显示，与传统渲染方法相比，感知质量提高了80%。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [251] [Wavelet-Based Time-Frequency Fingerprinting for Feature Extraction of Traditional Irish Music](https://arxiv.org/abs/2508.00479)
> *基于小波的时间-频率指纹识别技术在传统爱尔兰音乐特征提取中的应用*

*Noah Shore* | **Category: eess.AS, cs.SD, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 小波变换, 时间-频率指纹识别, 特征提取, 爱尔兰音乐, 小波相干性

**Comment:** Master's thesis. The focus of the thesis is on the underlying
  techniques for signal fingerprinting

> **TL;DR:** 本文提出了一种基于小波的时间-频率指纹识别方法，用于从传统爱尔兰音乐的现场录音中提取音频特征并进行识别，实验证明该方法准确高效。

**AI_Comments:** 该论文创新性地将小波变换应用于传统爱尔兰音乐的特征提取和识别，解决了现场录音数据处理的难题。其提出的基于小波相干性的方法不仅在音乐领域表现出色，还展示了在其他时间序列分析领域的潜在应用，具有较强的普适性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在时间序列数据中识别特征存在挑战，尤其是在从传统爱尔兰音乐的现场录音中进行音频识别时。

**Method:** 采用连续小波变换提取频谱特征，并使用小波相干性分析比较录制音频频谱图与合成曲调（由ABC符号表示）。

**Result:** 实验结果表明，基于小波的方法可以准确高效地识别录制的曲调。研究还详细说明了小波相干性模型的性能，突出了其相对于其他时频分解方法的优势。

**Conclusion:** 基于小波的时间-频率指纹识别方法在传统爱尔兰音乐特征提取和识别中表现出准确性和高效性，且该模型可应用于音乐之外的领域，如脑电图信号分析和金融时间序列预测。

> **ai_Abstract:** 本文提出了一种基于小波的时间-频率指纹识别方法，旨在解决传统爱尔兰音乐现场录音中的音频特征提取和识别挑战。研究利用连续小波变换提取频谱特征，并通过小波相干性分析对比录音与ABC符号生成的合成曲调。实验结果表明，该方法能够准确高效地识别曲调，并突显了小波相干性模型相较于其他时频分解方法的优势。此外，该模型还被探索应用于脑电图信号分析和金融时间序列预测等非音乐领域。

> **摘要翻译:** 这项工作提出了一种基于小波的时间-频率指纹识别方法，用于时间序列特征提取，重点是从传统爱尔兰音乐的现场录音中进行音频识别。通过采用连续小波变换来提取频谱特征，解决了时间序列数据中识别特征的挑战，并使用小波相干性分析来比较录制的音频频谱图与合成曲调。合成曲调源自ABC符号，这是一种爱尔兰音乐常用的符号表示法。实验结果表明，基于小波的方法可以准确高效地识别录制的曲调。这项研究还详细说明了小波相干性模型的性能，突出了其相对于其他时频分解方法的优势。此外，我们讨论并将在音乐之外的多个应用中部署该模型，包括脑电图信号分析和金融时间序列预测。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [271] [VR-PTOLEMAIC: A Virtual Environment for the Perceptual Testing of Spatial Audio Algorithms](https://arxiv.org/abs/2508.00501)
> *VR-PTOLEMAIC：一个用于空间音频算法感知测试的虚拟环境*

*Paolo Ostan, Francesca Del Gaudio, Federico Miotello, Mirco Pezzoli, Fabio Antonacci* | **Category: eess.AS, cs.SD** | **Updated: 2025-08-01**

**Keywords:** 空间音频, 虚拟现实, 感知评估, MUSHRA, VR-PTOLEMAIC

**Comment:** to appear in EAA Forum Acusticum 2025

> **TL;DR:** VR-PTOLEMAIC是一个基于虚拟现实的评估系统，用于感知测试空间音频算法，通过实现MUSHRA方法在一个虚拟研讨室中进行，并获得积极的用户体验和沉浸感反馈。

**AI_Comments:** 本文提出了一种新颖的方法，将虚拟现实技术应用于空间音频算法的感知评估，特别是整合了MUSHRA测试方法，这在沉浸式音频领域具有创新性。它提供了一个可控且沉浸式的环境进行听觉测试，克服了传统实验室环境的局限性。其重要性在于为空间音频算法的开发和优化提供了一个有效的工具，有助于提升沉浸式音频应用的质量。

<details>
  <summary>Details</summary>

**Motivation:** 沉浸式音频应用开发中，空间音频算法的感知评估至关重要，以确保合成声场在听觉体验、空间感知和听觉真实性方面达到质量标准。虚拟现实可以提供一个强大的平台来支持这些评估。

**Method:** 该论文提出了VR-PTOLEMAIC，一个用于评估空间音频算法的虚拟现实评估系统。该系统在一个虚拟环境中实现了MUSHRA（多刺激隐藏参考和锚点）评估方法。用户可以在虚拟重建的研讨室的25个模拟听音位置中定位自己，并评估模拟声学响应与实际记录的二阶Ambisonic房间脉冲响应（与各种源信号卷积）之间的差异。

**Result:** 通过广泛的测试活动评估了所提出框架的可用性，其中评估人员被要求比较各种声场重建算法的重建能力。结果表明，VR平台有效支持了空间音频算法的评估，用户体验和沉浸感普遍得到积极反馈。

**Conclusion:** VR平台能够有效支持空间音频算法的评估，并提供良好的用户体验和沉浸感，证明了其作为感知测试工具的潜力。

> **ai_Abstract:** 本文介绍了VR-PTOLEMAIC，一个创新的虚拟现实系统，旨在对空间音频算法进行感知评估。该系统将MUSHRA评估方法整合到一个虚拟研讨室环境中，允许用户在25个模拟听音位置评估不同声学响应。通过广泛的测试，研究结果证实VR-PTOLEMAIC能有效支持空间音频算法的评估，并获得了用户对其良好体验和高沉浸度的积极反馈。

> **摘要翻译:** 空间音频算法的感知评估是沉浸式音频应用开发中的重要一步，因为它确保了合成声场在听觉体验、空间感知和听觉真实性方面达到质量标准。为了支持这些评估，虚拟现实可以通过提供沉浸式和交互式测试环境来提供一个强大的平台。在本文中，我们提出了VR-PTOLEMAIC，一个专为评估空间音频算法而设计的虚拟现实评估系统。该系统在一个虚拟环境中实现了MUSHRA（多刺激隐藏参考和锚点）评估方法。特别是，用户可以在虚拟重建的研讨室的25个模拟听音位置中的每一个位置定位自己，并根据实际记录的二阶Ambisonic房间脉冲响应（均与各种源信号卷积）来评估模拟声学响应。我们通过一项广泛的测试活动评估了所提出框架的可用性，在该活动中，评估人员被要求比较各种声场重建算法的重建能力。结果表明，VR平台有效支持了空间音频算法的评估，用户体验和沉浸感普遍得到积极反馈。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [331] [OpenACE: An Open Benchmark for Evaluating Audio Coding Performance](https://arxiv.org/abs/2409.08374)
> *OpenACE：一个用于评估音频编码性能的开放基准*

*Jozef Coldenhoff, Niclas Granqvist, Milos Cernak* | **Category: eess.AS, cs.SD** | **Updated: 2025-08-01**

**Keywords:** 音频编码, 语音编码, 性能评估, 开放基准, OpenACE

**Comment:** ICASSP 2025

> **TL;DR:** OpenACE提出了一个开放的音频和语音编码质量评估基准，以解决当前缺乏统一评估和开源测试的问题。

**AI_Comments:** OpenACE的创新之处在于其提供了一个开放且统一的音频和语音编码评估基准，解决了当前评估方法碎片化和数据不透明的问题。这对于促进公平比较不同编解码器，特别是机器学习和传统DSP编解码器之间的性能至关重要。其开源性质将极大地推动该领域的研究和发展。

<details>
  <summary>Details</summary>

**Motivation:** 当前的音频和语音编码缺乏统一的评估方法和开源测试，许多系统在专有、不可复现或小规模数据上进行评估。机器学习编解码器常在与其训练数据分布相似的数据集上测试，这与在未见数据上表现良好的数字信号处理编解码器相比不公平。

**Method:** 本文提出了一个全频带音频和语音编码质量基准，包含更多可变内容类型，包括传统的开放测试向量。作者展示了一个音频编码质量评估的用例，使用了开源的Opus、3GPP的EVS以及ETSI的LC3和LC3+。此外，还展示了16 kbps情感语音编码的质量变化。

**Result:** OpenACE提供了一个开放的、包含多种内容类型的全频带音频和语音编码质量基准，并展示了对Opus、EVS、LC3和LC3+等编解码器的评估，以及情感语音编码的质量变化。

**Conclusion:** OpenACE提出的开放源代码基准有助于音频和语音编码的民主化，并解决了当前评估和测试不足的问题。

> **ai_Abstract:** 该论文介绍了OpenACE，一个开放的音频和语音编码性能评估基准，旨在解决当前领域内缺乏统一评估和开源测试的痛点。OpenACE提供了一个包含多种内容类型的全频带质量基准，并展示了对主流编解码器（如Opus、EVS、LC3/LC3+）的评估案例，以及情感语音编码的质量分析。此开放源代码基准旨在促进音频和语音编码的民主化。

> **摘要翻译:** 音频和语音编码缺乏统一的评估和开源测试。许多候选系统在专有、不可复现或小规模数据上进行评估，而基于机器学习的编解码器通常在与其训练数据分布相似的数据集上进行测试，这与通常在未见数据上表现良好的数字信号处理编解码器相比是不公平的。本文提出了一个全频带音频和语音编码质量基准，包含更多可变内容类型，包括传统的开放测试向量。文章展示了一个音频编码质量评估的用例，使用了开源的Opus、3GPP的EVS以及蓝牙LE音频配置文件中使用的近期ETSI的LC3和LC3+。此外，还展示了16 kbps情感语音编码的质量变化。所提出的开源基准有助于音频和语音编码的民主化，并可在https://github.com/JozefColdenhoff/OpenACE 获取。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [363] [Beamformed 360° Sound Maps: U-Net-Driven Acoustic Source Segmentation and Localization](https://arxiv.org/abs/2508.00307)
> *波束成形360°声图：U-Net驱动的声源分割与定位*

*Belman Jahir Rodriguez, Sergio F. Chevtchenko, Marcelo Herrera Martinez, Yeshwant Bethy, Saeed Afshar* | **Category: eess.AS, cs.AI, cs.SD, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 声源定位, U-Net, 语义分割, 波束成形, 360°声图

**Comment:** 

> **TL;DR:** 本文提出了一种基于U-Net模型和波束成形360°声图的声源分割与定位新范式，实现了高精度声源定位。

**AI_Comments:** 该论文的创新点在于将声源定位任务重新定义为球面语义分割问题，并利用U-Net模型进行处理，从而摆脱了传统DoA回归的局限性。其基于波束成形能量图的方法使得模型具有阵列无关性，提高了实际应用的灵活性和适应性。此外，使用真实世界无人机数据集进行训练和验证，增强了研究的实际意义和可靠性。这种新范式有望推动密集空间音频理解领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 传统声源定位方法通常回归离散的到达方向（DoA）角度，这可能无法充分捕捉空间分布的声源信息。本文旨在将360°声源定位重新表述为球面语义分割任务，以提供一种更鲁棒和精确的声源识别与定位方法，超越传统声源定位（SSL）的限制。

**Method:** 本文引入了一个U-Net模型，将360°声源定位任务表述为球面语义分割。模型不直接回归离散的DoA角度，而是分割波束成形的音频地图（方位角和仰角）以识别活跃声源区域。研究使用定制的24麦克风阵列进行延迟-求和（DAS）波束成形，生成与无人机GPS遥测对齐的信号，用于创建二值监督掩码。一个修改后的U-Net在这些地图的频域表示上进行训练，并利用Tversky损失解决类别不平衡问题。该方法在波束成形能量图上操作，使其具有阵列独立性，无需重新训练即可适应不同麦克风配置。分割输出通过计算激活区域的质心进行后处理，以获得鲁棒的DoA估计。数据集包括DJI Air 3无人机的真实世界开放场录音，并与360°视频和飞行日志同步。

**Result:** 实验结果表明，U-Net模型在不同环境中具有良好的泛化能力，并提供了更高的角度精度。该方法为超越传统声源定位（SSL）的密集空间音频理解提供了一种新范式。

**Conclusion:** 本文提出的基于U-Net和波束成形360°声图的声源分割与定位方法，通过将声源定位任务重新定义为球面语义分割，实现了鲁棒且高精度的360°声源定位，为全面的空间音频理解开辟了新途径。

> **ai_Abstract:** 本文提出了一种新颖的360°声源定位方法，将其重新定义为基于U-Net的球面语义分割任务。该方法通过对波束成形的声图进行分割，而非直接回归离散的到达方向角，来识别活跃声源区域。研究利用定制的24麦克风阵列进行延迟-求和波束成形，并结合无人机GPS遥测创建监督掩码。一个改进的U-Net模型在声图的频域表示上训练，并通过Tversky损失处理类别不平衡。由于该方法基于波束成形能量图，因此具有阵列独立性。分割结果通过计算质心进行后处理以获得精确的DoA估计。实验证明，该U-Net模型在不同环境下表现出良好的泛化能力和更高的角度精度，为全面的空间音频理解开辟了新途径。

> **摘要翻译:** 我们引入了一个U-Net模型，用于将360°声源定位表述为球面语义分割任务。我们的模型不回归离散的到达方向（DoA）角度，而是将波束成形的音频地图（方位角和仰角）分割成活跃声音存在的区域。通过在定制的24麦克风阵列上使用延迟-求和（DAS）波束成形，我们生成与无人机GPS遥测对齐的信号，以创建二值监督掩码。一个修改后的U-Net在这些地图的频域表示上进行训练，学习识别空间分布的声源区域，同时通过Tversky损失解决类别不平衡问题。由于网络在波束成形的能量图上操作，该方法本质上与阵列无关，并且无需从头开始重新训练即可适应不同的麦克风配置。分割输出通过计算激活区域的质心进行后处理，从而实现鲁棒的DoA估计。我们的数据集包括DJI Air 3无人机的真实世界开放场录音，与360°视频和跨多个日期和地点的飞行日志同步。实验结果表明，U-Net在不同环境中具有泛化能力，提供了更高的角度精度，为超越传统声源定位（SSL）的密集空间音频理解提供了一种新范式。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [643] [Dynamic Real-Time Ambisonics Order Adaptation for Immersive Networked Music Performances](https://arxiv.org/abs/2508.00509)
> *沉浸式网络音乐表演中动态实时声场编码阶数自适应*

*Paolo Ostan, Carlo Centofanti, Mirco Pezzoli, Alberto Bernardini, Claudia Rinaldi, Fabio Antonacci* | **Category: eess.AS** | **Updated: 2025-08-01**

**Keywords:** 声场编码, 网络音乐表演, 实时自适应, 空间音频, 带宽管理

**Comment:** to appear in EUSIPCO 2025

> **TL;DR:** 该论文提出了一种动态实时自适应高阶声场编码策略，根据网络带宽变化调整声场编码阶数，以在有限带宽的网络音乐表演场景中平衡沉浸感和可靠性。

**AI_Comments:** 该论文的创新点在于提出了一种实用的、基于网络条件动态调整声场编码阶数的方法，解决了沉浸式网络音乐表演中高保真音频与有限网络带宽之间的矛盾。这种自适应策略对于提升用户在复杂网络环境下的体验至关重要，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 网络音乐表演 (NMP) 等高级远程应用需要解决方案来保证用户之间身临其境的真实交互体验。采用空间音频格式（如声场编码）对于实现沉浸式声学场景至关重要。然而，声场编码阶数越高，沉浸感越好，但会增加音频通道数量，从而提高带宽要求并增加对网络问题的敏感性，这对于需要高空间保真度和低端到端延迟的交互式音乐会话构成了重大挑战。

**Method:** 本文提出了一种实时自适应高阶声场编码策略，该策略持续监控网络吞吐量并动态调整声场编码阶数。当可用带宽低于预设阈值时，阶数会降低以防止音频中断；一旦网络条件恢复，它会恢复到更高的阶数，从而平衡沉浸感和可靠性。

**Result:** 基于MUSHRA的评估表明，这种自适应方法有望在带宽受限的网络音乐表演场景中保证用户体验。

**Conclusion:** 该研究提出的动态实时声场编码阶数自适应策略能够有效地平衡沉浸感和网络可靠性，尤其适用于带宽受限的网络音乐表演场景，从而保证了用户体验。

> **ai_Abstract:** 该论文提出了一种针对沉浸式网络音乐表演的动态实时声场编码阶数自适应策略。鉴于高阶声场编码虽然能提供更好的沉浸感但会显著增加带宽需求并易受网络问题影响，该策略通过持续监测网络吞吐量，在带宽受限时降低声场编码阶数以避免音频中断，并在网络条件改善时恢复高阶，从而有效平衡了沉浸体验和网络传输的可靠性。MUSHRA评估结果表明，该方法在带宽受限的NMP场景中能有效保证用户体验。

> **摘要翻译:** 高级远程应用（如网络音乐表演，NMP）需要解决方案来保证用户之间身临其境的真实交互体验。因此，采用空间音频格式（如声场编码）对于让用户体验沉浸式声学场景至关重要。声音场景再现的准确性随声场编码阶数的增加而提高，从而以增加音频通道数量为代价提高沉浸感，这反过来又会增加带宽需求并增加对网络障碍（例如，延迟、抖动和丢包）的敏感性。这些因素对交互式音乐会话构成了重大挑战，因为它们需要高空间保真度和低端到端延迟。我们提出了一种实时自适应高阶声场编码策略，该策略持续监控网络吞吐量并动态调整声场编码阶数。当可用带宽低于预设阈值时，阶数会降低以防止音频中断；一旦条件恢复，它会恢复到更高的阶数，从而平衡沉浸感和可靠性。基于MUSHRA的评估表明，这种自适应方法有望在带宽受限的NMP场景中保证用户体验。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [7] [Optimizing Federated Learning Configurations for MRI Prostate Segmentation and Cancer Detection: A Simulation Study](https://arxiv.org/abs/2507.22790)
> *优化联邦学习配置用于MRI前列腺分割和癌症检测：一项模拟研究*

*Ashkan Moradi, Fadila Zerka, Joeran S. Bosma, Mohammed R. S. Sunoqrot, Bendik S. Abrahamsen, Derya Yakar, Jeroen Geerdink, Henkjan Huisman, Tone Frost Bathen, Mattijs Elschot* | **Category: eess.IV** | **Updated: 2025-07-31**

**Keywords:** 联邦学习, 前列腺分割, 癌症检测, MRI, 优化

**Comment:** 25 pages, 6 figures, 4 tables. Accepted for publication in Radiology:
  Artificial Intelligence, \c{opyright} 2025 Radiological Society of North
  America (RSNA)

> **TL;DR:** 优化联邦学习配置显著提升了MRI前列腺分割和癌症检测的性能及泛化能力。

**AI_Comments:** 这篇论文通过证明优化联邦学习配置可以提高诊断性能，同时可能在多个机构之间保护数据隐私，从而突出了联邦学习在医学影像（特别是前列腺癌）中的实际益处。其创新点在于系统地优化了联邦学习参数，以解决两个不同但相关的医学任务。

<details>
  <summary>Details</summary>

**Motivation:** 开发并优化一个联邦学习（FL）框架，用于跨多个客户端的MRI前列腺分割和临床显著性前列腺癌（csPCa）检测。

**Method:** 本研究采用回顾性设计，利用Flower FL框架训练基于nnU-Net的架构，对2010年1月至2021年8月收集的数据进行MRI前列腺分割和csPCa检测。模型开发包括训练和优化局部迭代次数、联邦轮次和聚合策略。前列腺分割任务使用T2加权MRI数据（四方客户端，1294名患者），csPCa检测任务使用双参数MRI数据（三方客户端，1440名患者）。性能评估分别通过Dice评分（分割）和PI-CAI评分（csPCa检测）在独立测试集上进行，并使用置换检验计算性能差异的P值。

**Result:** 联邦学习配置针对两项任务独立优化。前列腺分割任务在1个局部迭代和300个联邦轮次下使用FedMedian表现最佳；csPCa检测任务在5个局部迭代和200个联邦轮次下使用FedAdagrad表现最佳。与客户端平均性能相比，优化后的联邦学习模型在独立测试集上的前列腺分割和csPCa检测性能均显著提高。优化后的FL模型在病灶检测方面优于FL基线模型，但在前列腺分割方面未观察到显著差异。

**Conclusion:** 联邦学习与本地模型相比，提高了MRI前列腺分割和csPCa检测的性能和泛化能力，并且优化其配置进一步提升了病灶检测性能。

> **ai_Abstract:** 本模拟研究开发并优化了一个联邦学习（FL）框架，用于MRI前列腺分割和临床显著性前列腺癌（csPCa）检测。该研究利用基于nnU-Net的架构和Flower FL，优化了局部迭代次数、联邦轮次和聚合策略。结果表明，与本地客户端模型相比，优化后的FL配置显著提升了两项任务的性能，尤其是在病灶检测方面，这展示了FL在医学影像中增强泛化能力的潜力。

> **摘要翻译:** 目的：开发并优化一个跨多个客户端的联邦学习（FL）框架，用于双参数MRI前列腺分割和临床显著性前列腺癌（csPCa）检测。材料与方法：本研究采用回顾性设计，利用Flower FL训练基于nnU-Net的架构，对2010年1月至2021年8月收集的数据进行MRI前列腺分割和csPCa检测。模型开发包括对FL前列腺分割（基于T2加权MRI，四方客户端，1294名患者）和csPCa检测（基于双参数MRI，三方客户端，1440名患者）的局部迭代次数、联邦轮次和聚合策略进行训练和优化。性能在独立测试集上进行评估，分割使用Dice评分，csPCa检测使用Prostate Imaging: Cancer Artificial Intelligence (PI-CAI)评分（定义为受试者工作特征曲线下面积和平均精度的平均值）。性能差异的P值使用置换检验计算。结果：FL配置针对两项任务独立优化，结果显示，前列腺分割在1个局部迭代和300个联邦轮次下使用FedMedian表现最佳，csPCa检测在5个局部迭代和200个联邦轮次下使用FedAdagrad表现最佳。与客户端的平均性能相比，优化后的FL模型在独立测试集上的前列腺分割和csPCa检测性能均显著提高。优化后的FL模型在病灶检测方面表现优于FL基线模型，但在前列腺分割方面未观察到差异。结论：与本地模型相比，FL增强了MRI前列腺分割和csPCa检测的性能和泛化能力，并且优化其配置进一步提升了病灶检测性能。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [46] [CADS: A Comprehensive Anatomical Dataset and Segmentation for Whole-Body Anatomy in Computed Tomography](https://arxiv.org/abs/2507.22953)
> *CADS：计算机断层扫描中全身解剖学的综合解剖数据集和分割*

*Murong Xu, Tamaz Amiranashvili, Fernando Navarro, Maksym Fritsak, Ibrahim Ethem Hamamci, Suprosanna Shit, Bastian Wittmann, Sezgin Er, Sebastian M. Christ, Ezequiel de la Rosa, Julian Deseoe, Robert Graf, Hendrik Möller, Anjany Sekuboyina, Jan C. Peeken, Sven Becker, Giulia Baldini, Johannes Haubold, Felix Nensa, René Hosch, Nikhil Mirajkar, Saad Khalid, Stefan Zachow, Marc-André Weber, Georg Langs, Jakob Wasserthal, Mehmet Kemal Ozdemir, Andrey Fedorov, Ron Kikinis, Stephanie Tanadini-Lang, Jan S. Kirschke, Stephanie E. Combs, Bjoern Menze* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-29**

**Keywords:** CT分割, 全身解剖, 解剖数据集, 深度学习, 医学影像

**Comment:** 

> **TL;DR:** 该论文介绍了CADS，一个用于全身CT分割的大型、综合数据集（22,022个CT体积，167个结构）和模型，其性能优于现有方法并已公开发布。

**AI_Comments:** 该论文的创新之处在于其以数据为中心的AI方法，解决了全身CT分割中全面、高质量训练数据的关键瓶颈。CADS数据集的规模和解剖覆盖范围（22,022个CT体积，167个结构）是前所未有的，极大地推动了该领域的发展。通过开源数据集和模型，它促进了进一步的研究和临床应用，推动了放射学领域更稳健和泛化的AI解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 在体层CT扫描中准确描绘解剖结构对诊断和治疗计划至关重要。尽管AI在自动化分割方面取得了进展，但目前的方法通常针对单个结构，导致模型不兼容、性能各异且评估协议不统一。基础分割模型旨在通过单一模型提供整体解剖视图来解决这些局限性。然而，强大的临床部署需要全面的训练数据，这在现有的全身方法中是缺乏的，无论是数据异构性还是更重要的解剖覆盖范围。

**Method:** 本研究提出了CADS，一个开源框架，优先系统集成、标准化和标记异构数据源，用于全身CT分割。其核心是一个包含22,022个CT体积和167个解剖结构完整标注的大规模数据集。在此多样化数据集的基础上，使用现有架构开发了CADS模型，用于可访问和自动化的全身CT分割。

**Result:** CADS数据集比现有集合多18倍的扫描量，并增加了60%的解剖目标。CADS模型在18个公共数据集和一个独立的真实世界医院队列中进行了全面评估，结果表明其优于现有最先进的方法。特别是，在放射肿瘤学分割任务中对模型性能的彻底测试验证了其在临床干预中的直接实用性。

**Conclusion:** 通过公开大规模数据集、分割模型和临床软件工具，旨在推动放射学中稳健的AI解决方案，并使全面的解剖分析对临床医生和研究人员都可及。

> **ai_Abstract:** CADS是一个开源框架，旨在解决现有全身CT分割中训练数据不足的问题。它核心是一个包含22,022个CT体积和167个解剖结构完整标注的大规模数据集，显著提升了数据规模和覆盖范围。基于此数据集，研究者开发了CADS模型，并在多个公共数据集和真实医院队列中展现出优于现有方法的性能，特别是在放射肿瘤学分割任务中验证了其临床实用性。该工作通过公开数据集、模型和工具，旨在推动放射学AI解决方案的发展。

> **摘要翻译:** 在体层CT扫描中准确描绘解剖结构对诊断和治疗计划至关重要。尽管AI在自动化分割方面取得了进展，但目前的方法通常针对单个结构，导致模型不兼容、性能各异且评估协议不统一。基础分割模型旨在通过单一模型提供整体解剖视图来解决这些局限性。然而，强大的临床部署需要全面的训练数据，这在现有的全身方法中是缺乏的，无论是数据异构性还是更重要的解剖覆盖范围。在这项工作中，我们没有追求模型架构的增量优化，而是提出了CADS，一个开源框架，它优先系统集成、标准化和标记异构数据源，用于全身CT分割。其核心是一个包含22,022个CT体积和167个解剖结构完整标注的大规模数据集，代表了规模和覆盖范围上的重大进步，比现有集合多18倍的扫描量，并增加了60%的解剖目标。在此多样化数据集的基础上，我们使用现有架构开发了CADS模型，用于可访问和自动化的全身CT分割。通过在18个公共数据集和一个独立的真实世界医院队列中进行全面评估，我们证明了其优于现有最先进的方法。值得注意的是，对模型在放射肿瘤学分割任务中性能的彻底测试验证了其在临床干预中的直接实用性。通过公开我们的大规模数据集、分割模型和临床软件工具，我们旨在推动放射学中稳健的AI解决方案，并使全面的解剖分析对临床医生和研究人员都可及。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [86] [GEPAR3D: Geometry Prior-Assisted Learning for 3D Tooth Segmentation](https://arxiv.org/abs/2508.00155)
> *GEPAR3D：几何先验辅助的3D牙齿分割学习*

*Tomasz Szczepański, Szymon Płotka, Michal K. Grzeszczyk, Arleta Adamowicz, Piotr Fudalej, Przemysław Korzeniowski, Tomasz Trzciński, Arkadiusz Sitek* | **Category: eess.IV, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 3D牙齿分割, 几何先验, 深度分水岭, CBCT, 根尖分割

**Comment:** Accepted for the 28th International Conference on Medical Image
  Computing and Computer Assisted Intervention (MICCAI) 2025

> **TL;DR:** GEPAR3D是一种新的3D牙齿分割方法，通过结合几何先验和深度分水岭来提高根尖分割精度，并在CBCT扫描中取得了最佳性能。

**AI_Comments:** GEPAR3D的创新之处在于将几何先验（统计形状模型）与深度学习（深度分水岭）相结合，有效解决了CBCT中牙齿，特别是根尖等精细结构的分割难题。其统一实例检测和多类别分割的单一步骤设计，以及对连续3D能量盆地的建模，是提升分割精度的关键。该研究在外部数据集上的优异表现，证明了其泛化能力和临床应用潜力，对于牙根吸收评估和正畸治疗决策具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 锥形束计算机断层扫描（CBCT）中的牙齿分割仍然具有挑战性，特别是对于根尖等精细结构，这对于正畸学中评估牙根吸收至关重要。

**Method:** 我们引入了GEPAR3D，这是一种将实例检测和多类别分割统一为一个步骤的新方法，旨在改进牙根分割。该方法将牙列的统计形状模型作为几何先验，捕获解剖上下文和形态一致性。我们利用深度分水岭方法，将每颗牙齿建模为连续的3D能量盆地，编码体素到边界的距离。

**Result:** GEPAR3D在所有测试集上实现了最高的整体分割性能，平均Dice相似系数（DSC）为95.0%（比次优方法高2.8%），召回率提高到95.2%（提高9.5%）。定性分析表明根部分割质量显著改善。

**Conclusion:** GEPAR3D在3D牙齿分割方面表现出色，特别是在根尖分割上，这表明其在更准确的牙根吸收评估和增强正畸临床决策方面具有巨大潜力。

> **ai_Abstract:** GEPAR3D是一种针对CBCT中3D牙齿分割的新方法，特别关注根尖的精确分割。它通过整合牙列的统计形状模型作为几何先验，并结合深度分水岭方法，将实例检测和多类别分割统一。该方法在外部测试集上表现出卓越的性能，DSC达到95.0%，召回率达到95.2%，显著提高了根部分割质量，对正畸临床决策具有重要意义。

> **摘要翻译:** 锥形束计算机断层扫描（CBCT）中的牙齿分割仍然具有挑战性，特别是对于根尖等精细结构，这对于正畸学中评估牙根吸收至关重要。我们引入了GEPAR3D，这是一种新颖的方法，它将实例检测和多类别分割统一为一个步骤，旨在改进牙根分割。我们的方法将牙列的统计形状模型作为几何先验，在不施加限制性邻接约束的情况下捕获解剖上下文和形态一致性。我们利用深度分水岭方法，将每颗牙齿建模为连续的3D能量盆地，编码体素到边界的距离。这种实例感知的表示确保了对狭窄、复杂根尖的精确分割。我们的方法在来自单个中心的公开CBCT扫描数据上进行训练，并在来自两个内部和两个公共医疗中心的外部测试集上进行了评估。GEPAR3D取得了最高的整体分割性能，在所有测试集中平均Dice相似系数（DSC）为95.0%（比次优方法高2.8%），召回率提高到95.2%（提高9.5%）。定性分析表明根部分割质量显著改善，表明在更准确的牙根吸收评估和增强正畸临床决策方面具有巨大潜力。我们提供了实现和数据集：https://github.com/tomek1911/GEPAR3D。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [124] [Diffusion-Based User-Guided Data Augmentation for Coronary Stenosis Detection](https://arxiv.org/abs/2508.00438)
> *基于扩散模型的用户引导数据增强用于冠状动脉狭窄检测*

*Sumin Seo, In Kyu Lee, Hyun-Woo Kim, Jaesik Min, Chung-Hwan Jung* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 数据增强, 冠状动脉狭窄, 扩散模型, 用户引导, 医学图像分析

**Comment:** Accepted at MICCAI 2025. Dataset available at
  https://github.com/medipixel/DiGDA

> **TL;DR:** 本文提出了一种基于扩散模型的用户引导数据增强方法，用于生成逼真的冠状动脉狭窄病变，以解决医学图像数据量有限和类别不平衡的问题，并在病变检测和严重程度分类任务上取得了优异的性能。

**AI_Comments:** 该论文的创新点在于将扩散模型应用于医学图像的数据增强，特别是通过用户引导的方式生成具有不同严重程度的冠状动脉狭窄病变。这有效地解决了医学领域标记数据稀缺和类别不平衡的关键挑战，对于提高深度学习模型在临床诊断中的鲁棒性和泛化能力具有重要意义。用户引导的特性增加了生成数据的灵活性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 冠状动脉狭窄是导致缺血性心脏事件的主要风险因素，其医疗分析耗时费力。深度学习在自动化狭窄定位和严重程度测量方面潜力巨大，但在实际应用中常受限于标记数据不足和类别不平衡等挑战。

**Method:** 本文提出了一种新颖的数据增强方法，该方法利用基于扩散模型的修复方法生成逼真的病变，并允许用户引导控制病变严重程度。

**Result:** 在各种合成数据集大小下，该方法在病变检测和严重程度分类方面表现出优越的性能，无论是在大规模内部数据集还是公共冠状动脉血管造影数据集上。此外，即使在有限数据训练下，该方法仍能保持高检测和分类性能。

**Conclusion:** 该方法在改善狭窄严重程度评估和优化数据利用方面具有重要的临床意义，可为更可靠的决策支持提供帮助。

> **ai_Abstract:** 本文提出了一种基于扩散模型的创新数据增强方法，旨在通过生成用户引导的逼真冠状动脉狭窄病变来解决医学图像分析中数据稀缺和类别不平衡的问题。该方法在病变检测和严重程度分类任务上表现出色，即使在有限数据条件下也能保持高性能，这对于提高冠状动脉狭窄评估的可靠性和优化数据利用具有重要的临床价值。

> **摘要翻译:** 冠状动脉狭窄是导致缺血性心脏事件的主要风险因素，可导致死亡率增加，并且这种疾病的治疗需要细致、劳动密集型的分析。冠状动脉造影提供评估狭窄的关键视觉线索，支持临床医生做出明智的诊断和治疗决策。深度学习的最新进展在狭窄的自动化定位和严重程度测量方面显示出巨大潜力。然而，在现实世界中，这些有效方法的成功往往受到标记数据有限和类别不平衡等挑战的阻碍。在本研究中，我们提出了一种新颖的数据增强方法，该方法使用基于扩散模型的修复方法来生成逼真的病变，允许用户引导控制严重程度。在各种合成数据集大小下，对病变检测和严重程度分类的广泛评估表明，我们的方法在大型内部数据集和公共冠状动脉造影数据集上均表现出卓越的性能。此外，即使使用有限数据进行训练，我们的方法也能保持高检测和分类性能，这突显了其在改善狭窄严重程度评估和优化数据利用以实现更可靠的决策支持方面的临床重要性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [164] [FMPlug: Plug-In Foundation Flow-Matching Priors for Inverse Problems](https://arxiv.org/abs/2508.00721)
> *FMPlug：用于逆问题的即插即用基础流匹配先验*

*Yuxiang Wan, Ryan Devera, Wenjie Zhang, Ju Sun* | **Category: eess.IV, cs.CV, cs.LG, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 流匹配, 逆问题, 即插即用, 基础模型, 图像超分辨率

**Comment:** 

> **TL;DR:** FMPlug是一个新的即插即用框架，通过利用观测对象和期望对象之间的相似性以及生成流的高斯性，增强了基础流匹配先验，以解决不适定逆问题，并在图像超分辨率和高斯去模糊方面超越了SOTA方法。

**AI_Comments:** FMPlug的创新之处在于其即插即用特性以及对基础流匹配先验的有效利用，通过结合简单而强大的洞察力（相似性和高斯性）和精心设计的策略（时间自适应热身和尖锐高斯正则化），显著提升了模型在逆问题上的泛化能力和性能。其领域无关的特性尤其重要，预示着基础模型在更广泛应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法依赖于领域特定或未经训练的先验来解决不适定逆问题，而本文旨在通过利用基础流匹配先验的潜力来克服这些限制，使其更通用和有效。

**Method:** FMPlug通过引入时间自适应热身策略和尖锐高斯正则化，利用观测对象与期望对象之间的相似性以及生成流的高斯性来增强基础流匹配（FM）先验。

**Result:** FMPlug在图像超分辨率和高斯去模糊方面，以显著优势击败了使用基础FM先验的最新方法。

**Conclusion:** FMPlug通过其新颖的即插即用框架、时间自适应热身策略和尖锐高斯正则化，成功地解锁了领域无关基础模型的潜力，并在逆问题上取得了优异的性能。

> **ai_Abstract:** FMPlug是一个创新的即插即用框架，旨在通过利用观测对象与期望对象相似性及生成流高斯性来增强基础流匹配先验，以解决不适定逆问题。它采用时间自适应热身策略和尖锐高斯正则化，显著提升了领域无关基础模型的性能。实验证明，FMPlug在图像超分辨率和高斯去模糊任务上优于现有顶尖方法。

> **摘要翻译:** 我们提出了FMPlug，一个新颖的即插即用框架，它增强了基础流匹配（FM）先验，用于解决不适定逆问题。与依赖领域特定或未经训练先验的传统方法不同，FMPlug巧妙地利用了两个简单但强大的洞察力：观测对象与期望对象之间的相似性以及生成流的高斯性。通过引入时间自适应热身策略和尖锐高斯正则化，FMPlug释放了领域无关基础模型的真正潜力。我们的方法在图像超分辨率和高斯去模糊方面，以显著优势击败了使用基础FM先验的最新方法。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [189] [AI-Driven Collaborative Satellite Object Detection for Space Sustainability](https://arxiv.org/abs/2508.00755)
> *AI驱动的协同卫星目标检测助力空间可持续性*

*Peng Hu, Wenxuan Zhang* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 空间可持续性, 卫星目标检测, 协同检测, 深度学习, 空间态势感知

**Comment:** Submitted to the 13th Annual IEEE International Conference on
  Wireless for Space and Extreme Environments (WiSEE 2025)

> **TL;DR:** 本文提出了一种AI驱动的卫星集群框架，用于在多颗卫星间协同执行深度学习目标检测任务，以提高空间态势感知能力并应对低地球轨道卫星密度增加带来的碰撞风险。

**AI_Comments:** 本文提出了一种创新的卫星集群框架，通过AI驱动的协同检测解决了传统地面跟踪系统的局限性，并有效降低了在轨系统的功耗和体积，对于提升空间态势感知和实现空间可持续性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 低地球轨道（LEO）中卫星密度的增加导致在轨碰撞风险上升，对空间可持续性构成严峻挑战。传统的地面跟踪系统受限于延迟和覆盖范围，因此需要机载、基于视觉的空间目标检测（SOD）能力。

**Method:** 本文提出了一种新颖的卫星集群框架，旨在实现多颗卫星协同执行基于深度学习（DL）的空间目标检测（SOD）任务。为支持此方法，构建了模拟集群卫星编队成像场景的高保真数据集。引入了距离感知视点选择策略以优化检测性能，并使用最新的深度学习模型进行评估。

**Result:** 实验结果表明，与单颗卫星和现有方法相比，所提出的基于集群的方法实现了具有竞争力的检测精度，同时保持了低尺寸、重量和功耗（SWaP）的特点。

**Conclusion:** 这些发现强调了分布式、AI赋能的在轨系统在增强空间态势感知和促进长期空间可持续性方面的潜力。

> **ai_Abstract:** 本文针对低地球轨道卫星密度增加带来的碰撞风险，提出了一种AI驱动的协同卫星目标检测框架。该框架通过卫星集群实现多颗卫星协同执行深度学习目标检测任务，并构建了高保真数据集和引入了距离感知视点选择策略。实验证明，该方法在保持低SWaP的同时，实现了与现有方法相当的检测精度，有望提升空间态势感知能力并促进空间可持续性。

> **摘要翻译:** 低地球轨道（LEO）中卫星密度的不断增加对空间可持续性提出了严峻挑战，主要原因是增加了在轨碰撞的风险。传统的地面跟踪系统受到延迟和覆盖范围的限制，这突显了对机载、基于视觉的空间目标检测（SOD）能力的需求。在本文中，我们提出了一种新颖的卫星集群框架，该框架能够使多颗卫星协同执行基于深度学习（DL）的空间目标检测（SOD）任务。为了支持这种方法，我们构建了一个高保真数据集，模拟了集群卫星编队的成像场景。引入了一种距离感知视点选择策略来优化检测性能，并使用最新的深度学习模型进行评估。实验结果表明，与单颗卫星和现有方法相比，所提出的基于集群的方法实现了具有竞争力的检测精度，同时保持了低尺寸、重量和功耗（SWaP）的特点。这些发现强调了分布式、AI赋能的在轨系统在增强空间态势感知和促进长期空间可持续性方面的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [213] [Weakly Supervised Intracranial Aneurysm Detection and Segmentation in MR angiography via Multi-task UNet with Vesselness Prior](https://arxiv.org/abs/2508.00235)
> *基于血管先验的多任务UNet弱监督颅内动脉瘤检测与分割*

*Erin Rainville, Amirhossein Rasoulian, Hassan Rivaz, Yiming Xiao* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 颅内动脉瘤, 弱监督学习, UNet, 血管性先验, 多任务学习

**Comment:** Accepted to ICCV 2025 Workshop CVAMD

> **TL;DR:** 提出了一种弱监督3D多任务UNet模型，结合血管先验，用于MR血管造影中的颅内动脉瘤检测和分割，并在多个数据集上表现优异。

**AI_Comments:** 该论文的创新点在于提出了一个弱监督的多任务UNet模型，并创造性地结合了血管先验（通过Frangi滤波器），有效解决了在医疗图像领域常见的标注数据稀缺问题。通过联合检测和分割任务，并利用先验知识引导网络学习，提高了模型的鲁棒性和准确性。其在两个数据集上的优异表现证明了该方法的有效性和泛化能力，对于推动颅内动脉瘤的自动化诊断具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 颅内动脉瘤（IAs）的检测和形态分析对于临床护理至关重要，但其在放射扫描中的小尺寸和软对比度使其难以准确高效地进行。此外，缺乏带有体素级专家标注的大型公开数据集，给深度学习算法的开发带来了挑战。

**Method:** 提出了一种新颖的弱监督3D多任务UNet，它集成了血管先验，以联合执行TOF-MRA中的动脉瘤检测和分割。具体来说，利用Frangi血管性滤波器导出软脑血管先验，用于网络输入和注意力模块，以从解码器进行分割，并从辅助分支进行检测。模型在Lausanne数据集上使用粗略的地面真实分割进行训练，并在ADAM数据集上进行了外部验证以评估泛化能力。

**Result:** 所提出的技术在动脉瘤分割（Dice = 0.614，95%HD =1.38mm）和检测（假阳性率 = 1.47，敏感性 = 92.9%）方面表现出优于SOTA技术。模型在Lausanne数据集的测试集上进行了评估，并在ADAM数据集上进行了外部验证。

**Conclusion:** 本研究提出了一种有效的弱监督3D多任务UNet模型，通过整合血管先验，显著提高了颅内动脉瘤在MR血管造影中的检测和分割性能，并解决了数据标注稀缺的问题。

> **ai_Abstract:** 本研究提出了一种新颖的弱监督3D多任务UNet模型，旨在解决颅内动脉瘤在MR血管造影中检测和分割的挑战，尤其是在缺乏大量精细标注数据的情况下。该模型通过整合Frangi血管性滤波器导出的血管先验，共同执行动脉瘤的检测和分割。在Lausanne和ADAM数据集上的实验结果表明，该方法在分割和检测性能上均优于现有最先进技术，为临床实践提供了有前景的解决方案。

> **摘要翻译:** 颅内动脉瘤（IAs）是脑血管的异常扩张，一旦破裂，可能导致危及生命的后果。然而，它们在放射扫描中尺寸小、对比度低，常常使得准确高效的检测和形态学分析变得困难，而这对于该疾病的临床护理至关重要。此外，缺乏带有体素级专家标注的大型公开数据集，给开发深度学习算法以解决这些问题带来了挑战。因此，我们提出了一种新颖的弱监督3D多任务UNet，它集成了血管先验，以联合执行飞行时间磁共振血管造影（TOF-MRA）中的动脉瘤检测和分割。具体来说，为了鲁棒地引导IA检测和分割，我们采用流行的Frangi血管性滤波器来导出软脑血管先验，用于网络输入和注意力模块，以从解码器进行分割，并从辅助分支进行检测。我们在Lausanne数据集上使用粗略的地面真实分割训练我们的模型，并在同一数据库中具有精细标签的测试集上进行评估。为了进一步评估我们模型的泛化能力，我们还在ADAM数据集上进行了外部验证。我们的结果表明，所提出的技术在动脉瘤分割（Dice = 0.614，95%HD =1.38mm）和检测（假阳性率 = 1.47，敏感性 = 92.9%）方面优于SOTA技术。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [541] [Navigating Distribution Shifts in Medical Image Analysis: A Survey](https://arxiv.org/abs/2411.05824)
> *医疗图像分析中导航分布偏移：一项综述*

*Zixian Su, Jingwei Guo, Xi Yang, Qiufeng Wang, Frans Coenen, Kaizhu Huang* | **Category: eess.IV, cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 医疗图像分析, 分布偏移, 深度学习, 领域泛化, 联邦学习

**Comment:** 

> **TL;DR:** 综述了深度学习在医疗图像分析中应对分布偏移的策略，并根据实际操作约束进行分类。

**AI_Comments:** 这篇综述的创新之处在于其独特的分类方法，即基于医疗机构的实际操作约束而非纯粹的技术规范来组织深度学习应对分布偏移的策略。这使得综述更具实用性和指导意义，有助于研究人员更好地理解如何在真实世界的医疗环境中应用和部署模型，从而促进更稳健、更广泛的医疗图像分析应用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度学习在医疗图像分析中取得了显著进展，但由于分布偏移，模型在不同医院、区域或患者群体的数据上表现不佳，因此需要开发策略来提高模型的适应性和鲁棒性。

**Method:** 本文系统地综述了应用于受分布偏移影响的医疗图像分析系统的深度学习技术方法。不同于传统的技术规范分类，本综述基于医疗机构面临的实际操作约束，将现有工作分为联合训练、联邦学习、微调和领域泛化，每种方法都针对数据可访问性、隐私问题和协作协议引起的不同场景。

**Result:** 本综述将现有工作根据实际操作约束分类为联合训练、联邦学习、微调和领域泛化，每种方法都针对数据可访问性、隐私问题和协作协议引起的不同场景。这种视角为研究人员提供了对深度学习如何战略性部署以解决医疗图像分析中分布偏移的细致理解。

**Conclusion:** 本文通过深入探讨这些主题，强调了未来研究的潜在途径，这些研究不仅解决了现有局限性，而且推动了可部署医疗图像分析技术的边界，确保多样化和稳健的医疗应用。

> **ai_Abstract:** 这篇综述系统地回顾了深度学习在医疗图像分析中应对分布偏移的方法。鉴于深度学习模型在不同医疗环境中表现不佳的问题，作者基于实际操作约束，将现有策略分为联合训练、联邦学习、微调和领域泛化，并探讨了它们如何适应数据可访问性、隐私和协作协议等不同场景。该综述旨在为研究人员提供部署深度学习以解决医疗图像分析中分布偏移的细致理解，并指出未来的研究方向。

> **摘要翻译:** 医疗图像分析 (MedIA) 已成为现代医疗保健中不可或缺的一部分，它增强了临床诊断和个性化治疗。尽管深度学习 (DL) 技术取得了显著进步，但由于分布偏移，其实际部署面临挑战，即在特定数据集上训练的模型在来自不同医院、区域或患者群体的数据上表现不佳。为了解决这个问题，研究人员一直在积极开发策略，以提高深度学习模型的适应性和鲁棒性，使其能够在不熟悉和多样化的环境中有效使用。本文系统地综述了将深度学习技术应用于受分布偏移影响的医疗图像分析系统的方法。与基于技术规范的传统分类不同，我们的方法以医疗机构面临的实际操作约束为基础。具体来说，我们将现有工作分为联合训练、联邦学习、微调和领域泛化，每种方法都针对由数据可访问性、隐私问题和协作协议引起的不同场景。这种视角使研究人员能够细致地理解深度学习如何战略性地部署以解决医疗图像分析中的分布偏移，从而确保多样化和稳健的医疗应用。通过深入探讨这些主题，我们强调了未来研究的潜在途径，这些研究不仅解决了现有局限性，而且推动了可部署医疗图像分析技术的边界。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [685] [On the Utility of Virtual Staining for Downstream Applications as it relates to Task Network Capacity](https://arxiv.org/abs/2508.00164)
> *虚拟染色在下游应用中的效用及其与任务网络容量的关系*

*Sourya Sengupta, Jianquan Xu, Phuong Nguyen, Frank J. Brooks, Yang Liu, Mark A. Anastasio* | **Category: eess.IV, q-bio.QM** | **Updated: 2025-07-31**

**Keywords:** 虚拟染色, 图像到图像翻译, 深度学习, 任务网络容量, 下游应用

**Comment:** 

> **TL;DR:** 本研究系统地探讨了虚拟染色在促进下游生物或临床任务（如分割或分类）方面的效用，并考虑了执行任务的深度神经网络的容量。结果表明，虚拟染色的效用在很大程度上取决于任务网络提取有意义信息的能力，当任务网络容量足够大时，虚拟染色甚至可能降低性能。

**AI_Comments:** 这项研究具有重要的实际意义，它挑战了虚拟染色总是能提升下游任务性能的普遍假设。通过引入“任务网络容量”这一关键变量，论文揭示了虚拟染色应用中的一个重要限制和权衡点。其创新之处在于将虚拟染色的效用与后续任务网络的内在能力联系起来，为虚拟染色技术的选择和应用提供了更精细的指导，避免了盲目应用可能导致的性能下降。这对于生物医学图像分析领域具有指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 在大多数关于虚拟染色的研究中，虚拟染色图像仅通过传统的图像质量指标（如结构相似性或信噪比）进行评估。然而，在生物医学成像中，图像通常是为了促进基于图像的推断，即下游生物或临床任务而获取的。因此，本研究旨在系统地调查虚拟染色在促进临床相关下游任务方面的效用，并考虑执行任务的深度神经网络的容量。

**Method:** 本研究对虚拟染色在促进临床相关下游任务（如分割或分类）方面的效用进行了系统调查。通过使用生物数据集进行全面的实证评估，比较了使用无标记图像、虚拟染色图像和真实荧光图像的任务性能。评估中考虑了执行任务的深度神经网络的容量。

**Result:** 研究结果表明，虚拟染色的效用在很大程度上取决于分割或分类任务网络提取有意义的任务相关信息的能力，这与网络容量的概念有关。研究还提供了案例，显示当相关任务网络的容量足够大时，虚拟染色并不能改善，甚至会降低分割或分类性能。

**Conclusion:** 研究结果表明，在决定是否进行虚拟染色时，应考虑任务网络的容量。

> **ai_Abstract:** 本研究系统地探讨了虚拟染色在促进下游生物或临床任务（如图像分割或分类）方面的效用，并特别考虑了执行这些任务的深度神经网络的容量。与以往仅关注图像质量的评估不同，本研究通过使用生物数据集进行全面实证评估，比较了无标记、虚拟染色和真实荧光图像在任务性能上的表现。研究发现，虚拟染色的效用高度依赖于任务网络提取相关信息的能力，并且当任务网络容量足够大时，虚拟染色甚至可能对下游任务性能产生负面影响。因此，研究强调在应用虚拟染色技术时，应充分考虑任务网络的容量。

> **摘要翻译:** 虚拟染色，或称作计算机模拟标记，已被提出通过使用基于深度学习的图像到图像翻译网络，从无标记图像计算生成合成荧光图像。在大多数已报道的研究中，虚拟染色图像仅使用传统的图像质量测量方法进行评估，例如结构相似性或信噪比。然而，在生物医学成像中，图像通常是为了促进基于图像的推断而获取的，我们称之为下游生物或临床任务。本研究系统地调查了虚拟染色在促进临床相关下游任务（如分割或分类）方面的效用，并考虑了用于执行这些任务的深度神经网络的容量。使用生物数据集进行了全面的实证评估，通过使用无标记、虚拟染色和真实荧光图像来评估任务性能。结果表明，虚拟染色的效用在很大程度上取决于分割或分类任务网络提取有意义的任务相关信息的能力，这与网络容量的概念有关。研究提供了示例，其中当相关任务网络的容量足够大时，虚拟染色并不能改善，甚至会降低分割或分类性能。结果表明，在决定是否进行虚拟染色时，应考虑任务网络容量。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [709] [Generating Novel Brain Morphology by Deforming Learned Templates](https://arxiv.org/abs/2503.03778)
> *生成通过变形学习模板的新颖大脑形态*

*Alan Q. Wang, Fangrui Huang, Bailey Trang, Wei Peng, Mohammad Abbasi, Kilian Pohl, Mert Sabuncu, Ehsan Adeli* | **Category: eess.IV, q-bio.TO** | **Updated: 2025-07-31**

**Keywords:** 3D脑MRI生成, 潜在扩散模型, 形态学, 形变场, 学习模板

**Comment:** Provisional Acceptance at MICCAI 2025

> **TL;DR:** 提出MorphLDM，一个基于潜在扩散模型的方法，通过对学习模板应用合成形变场来生成新的3D大脑MRI图像，优于现有方法。

**AI_Comments:** 这篇论文的创新点在于其独特的生成范式，即通过生成形变场而非直接生成图像来创建新的脑形态。这种方法可能更好地捕捉复杂的形态细节，克服了传统GANs和扩散模型在处理高分辨率3D结构数据时的局限性。通过引入学习模板和配准损失，模型能够生成更具生物学合理性的图像。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于GANs或扩散模型直接合成图像的方法可能难以捕捉复杂的形态细节，因此需要新的生成模型来合成形态学合理且属性特定的3D结构脑MRI。

**Method:** 提出MorphLDM，一个基于最先进潜在扩散模型（LDMs）的3D大脑MRI生成方法。它通过将合成的形变场应用于学习到的模板来生成新图像。其编码器输出的潜在嵌入来自图像和学习到的模板，该模板本身是模板解码器的输出；该潜在嵌入被传递给形变场解码器，其输出应用于学习到的模板。通过对编码器和两个解码器，在原始图像和变形模板之间最小化配准损失。

**Result:** 经验上，该方法在图像多样性、输入条件依从性和基于体素的形态测量学等指标上优于生成基线。

**Conclusion:** MorphLDM通过其独特的形变场生成机制，能够更有效地生成具有复杂形态细节的3D脑MRI图像，克服了现有直接图像合成方法的局限性。

> **ai_Abstract:** 这项研究提出了MorphLDM，一种新颖的3D脑MRI生成模型，它利用潜在扩散模型通过对学习到的模板应用合成形变场来创建形态学合理且属性特定的图像。与直接图像合成方法不同，MorphLDM通过独特的编码器-解码器架构生成形变场，并最小化原始图像与变形模板之间的配准损失。实验结果表明，MorphLDM在图像多样性、条件依从性和形态测量学方面均优于现有生成模型。

> **摘要翻译:** **标题：** 通过变形学习模板生成新颖大脑形态

**摘要：**
设计用于合成形态学合理且属性特定（例如，年龄、性别、疾病状态）样本的3D结构脑MRI生成模型是一个活跃的研究领域。现有基于GANs或扩散模型等框架的方法直接合成图像，这可能会限制它们捕捉复杂形态细节的能力。在这项工作中，我们提出了一种基于最先进潜在扩散模型（LDMs）的3D脑MRI生成方法，称为MorphLDM，它通过对学习到的模板应用合成形变场来生成新颖图像。与使用基于重建的自编码器（如典型LDM中）不同，我们的编码器输出的潜在嵌入来自图像和学习到的模板，该模板本身是模板解码器的输出；该潜在嵌入被传递给形变场解码器，其输出应用于学习到的模板。在编码器和两个解码器方面，原始图像和变形模板之间最小化配准损失。经验上，我们的方法在图像多样性、输入条件依从性和基于体素的形态测量学等指标上优于生成基线。我们的代码可在https://github.com/alanqrwang/morphldm获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [24] [Closed-form Expression for the Power Profile in Wideband Systems with Inter-channel Stimulated Raman Scattering](https://arxiv.org/abs/2508.00093)
> *宽带系统中带信道间受激拉曼散射的功率剖面闭合形式表达式*

*Lucas Alves Zischler, Chiara Lasagni, Paolo Serena, Alberto Bononi, Giammarco Di Sciullo, Divya A. Shaji, Antonio Mecozzi, Cristian Antonelli* | **Category: eess.SP** | **Updated: 2025-07-31**

**Keywords:** 闭合形式表达式, 受激拉曼散射, 宽带系统, 功率剖面, 光信噪比

**Comment:** Submitted for the Journal of Lightwave Technology

> **TL;DR:** 本文提出了一个近似的闭合形式表达式，用于计算宽带系统中考虑信道间受激拉曼散射和光纤损耗的信道功率剖面，并推导了一个可用于功率预加重的逆表达式。

**AI_Comments:** 这项工作的重要创新在于提供了一个分析性的闭合形式表达式，以代替通常所需的数值方法来估算宽带系统中复杂的拉曼散射和光纤损耗效应，大大简化了功率剖面的计算和OSNR优化过程，具有重要的理论和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 由于信道间受激拉曼散射（ISRS）和光纤损耗的非均匀衰减，这些综合效应的精确估计通常只能通过数值方法实现，这促使研究人员寻求一个更简便的闭合形式表达式。

**Method:** 本文提出了一个近似的闭合形式表达式来描述考虑ISRS和光纤损耗的信道功率剖面，并推导了一个以输出功率为函数的逆表达式。

**Result:** 所提出的表达式在CLU传输情况下与数值解进行了验证，在单跨和多跨光纤链路中均显示出高精度。此外，逆表达式可用于通过发射信道功率的预加重来达到期望的光信噪比（OSNR）剖面。

**Conclusion:** 本文提出的闭合形式表达式能够准确估计宽带系统中受ISRS和光纤损耗影响的信道功率剖面，并且其逆表达式为实现目标OSNR剖面提供了有效的功率预加重方法。

> **ai_Abstract:** 本文针对宽带系统中信道间受激拉曼散射（ISRS）和光纤损耗的综合效应，提出了一个近似的闭合形式表达式来计算信道功率剖面。该表达式在单跨和多跨光纤链路中均展现出高精度。此外，论文还推导了一个逆表达式，可用于通过功率预加重实现目标光信噪比（OSNR）剖面。

> **摘要翻译:** 宽带系统经历显著的信道间受激拉曼散射（ISRS）和信道相关损耗。由于非均匀衰减剖面，ISRS和光纤损耗的综合效应只能使用数值方法进行精确估计。在这项工作中，我们提出了一个近似的闭合形式表达式，用于描述考虑这些综合效应的信道功率剖面。我们针对CLU传输情况，通过与数值解进行比较，验证了所提出的表达式，结果显示其在单跨和多跨光纤链路中均具有高精度。此外，我们推导了一个逆表达式，其被表述为输出功率的函数，可用于通过发射信道功率的预加重来达到期望的光信噪比（OSNR）剖面。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [30] [RIS-MAE: A Self-Supervised Modulation Classification Method Based on Raw IQ Signals and Masked Autoencoder](https://arxiv.org/abs/2508.00274)
> *RIS-MAE：一种基于原始IQ信号和掩码自编码器的自监督调制分类方法*

*Yunfei Liu, Mingxuan Liu, Wupeng Xie, Xinzhu Liu, Wenxue Liu, Yangang Sun, Xin Qiu, Cui Yuan, Jinhai Li* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** 自动调制分类, 自监督学习, 掩码自编码器, 原始IQ信号, 少样本学习

**Comment:** 

> **TL;DR:** RIS-MAE是一种基于原始IQ信号和掩码自编码器的自监督调制分类方法，解决了传统方法对标注数据依赖和特征丢失的问题，并在少样本和跨域任务中表现优异，展现出强大的泛化能力。

**AI_Comments:** RIS-MAE的创新点在于结合了自监督学习和掩码自编码器来处理原始IQ信号，有效避免了传统方法中时频转换导致的特征损失和对大量标注数据的依赖。其在少样本和跨域任务中的出色表现，凸显了其在资源受限和动态变化的无线通信环境中的重要性和实际部署价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自动调制分类方法存在两个主要问题：一是多数方法使用时频图像而非原始信号，导致关键调制特征丢失并降低对不同通信条件的适应性；二是大多数方法依赖监督学习，需要大量标注数据，这在实际环境中难以获取。

**Method:** 本文提出RIS-MAE自监督学习框架，该框架使用掩码自编码器从无标签数据中学习信号特征。它以原始IQ序列作为输入，通过随机掩码和重建，捕获幅度、相位等重要的时域特征，从而帮助模型学习有用且可迁移的表示。

**Result:** RIS-MAE在四个数据集上进行了测试，结果表明其在少样本和跨域任务中表现优于现有方法。它在仅少量微调样本的情况下，在以前未见过的数据集上实现了高分类精度，证实了其泛化能力和实际部署潜力。

**Conclusion:** RIS-MAE通过自监督学习和原始IQ信号处理，有效解决了自动调制分类中数据依赖和特征丢失的问题，展现出卓越的泛化能力和在实际部署中的潜力。

> **ai_Abstract:** 本文提出了一种名为RIS-MAE的自监督学习框架，用于自动调制分类。针对现有方法依赖大量标注数据和时频图像导致特征丢失的问题，RIS-MAE利用掩码自编码器直接处理原始IQ信号，通过随机掩码和重建学习信号特征。实验结果表明，RIS-MAE在少样本和跨域任务中表现优异，并在仅少量微调样本的情况下对未见过的数据集展现出强大的泛化能力和实际应用潜力。

> **摘要翻译:** 自动调制分类（AMC）是智能无线通信系统中的一项基础技术。它对于频谱监测、认知无线电和安全通信等任务至关重要。近年来，深度学习方法在AMC方面取得了巨大进展。然而，主流方法仍面临两个关键问题。首先，它们通常使用时频图像而非原始信号。这导致关键调制特征的丢失，并降低了对不同通信条件的适应性。其次，大多数方法依赖于监督学习。这需要大量标注数据，在现实环境中很难获取。为了解决这些问题，我们提出了一种名为RIS-MAE的自监督学习框架。RIS-MAE使用掩码自编码器从无标签数据中学习信号特征。它以原始IQ序列作为输入。通过应用随机掩码和重建，它捕获了幅度、相位等重要的时域特征。这有助于模型学习有用且可迁移的表示。RIS-MAE在四个数据集上进行了测试。结果表明，它在少样本和跨域任务中表现优于现有方法。值得注意的是，它在仅少量微调样本的情况下，在以前未见过的数据集上实现了高分类精度，证实了其泛化能力和实际部署潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [35] [Model-Driven Deep Learning Enhanced Joint Beamforming and Mode Switching for RDARS-Aided MIMO Systems](https://arxiv.org/abs/2508.00326)
> *模型驱动深度学习增强的RDARS辅助MIMO系统联合波束成形与模式切换*

*Chengwang Ji, Kehui Li, Haiquan Lu, Qiaoyan Peng, Jintao Wang, Shaodan Ma* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** RDARS, MIMO, 波束成形, 模式切换, 深度学习

**Comment:** 

> **TL;DR:** 提出一种模型驱动深度学习增强的PWM算法，用于RDARS辅助MIMO系统联合优化波束成形和模式切换，显著提升收敛速度和性能。

**AI_Comments:** 这项研究创新性地将模型驱动深度学习与传统优化算法相结合，有效解决了RDARS辅助MIMO系统中复杂的非凸优化问题。通过深度学习加速收敛并提升性能，为未来6G网络中的RDARS系统设计提供了有效方案，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 可重构分布式天线和反射面（RDARS）是未来6G无线网络中有前景的架构，其动态工作模式配置比现有RIS和DAS系统带来额外选择增益。本文旨在解决RDARS辅助MIMO系统中加权和速率最大化问题，该问题由于非凸目标函数和混合整数二进制约束而难以求解。

**Method:** 提出一种基于惩罚项的加权最小均方误差（PWM）算法，该算法结合了Majorization-Minimization (MM) 和 Weighted Minimum Mean Square Error (WMMSE) 方法。为进一步逃离局部最优，将模型驱动深度学习方法集成到该算法中，训练与PWM算法收敛相关的关键变量，以加速收敛速度和提高系统性能。

**Result:** 仿真结果表明，PWM-BFNet可以将迭代次数减少一半，并在高总发射功率和大量RDARS发射单元（TEs）的场景下，分别实现26.53%和103.2%的性能提升。

**Conclusion:** 提出的模型驱动深度学习增强的PWM算法能有效解决RDARS辅助MIMO系统中的WSR最大化问题，显著提高系统性能和收敛效率。

> **ai_Abstract:** 本文研究RDARS辅助下行MIMO系统，旨在通过联合优化基站和RDARS的波束成形矩阵以及RDARS的模式切换矩阵来最大化加权和速率。针对该非凸混合整数问题，提出了一种结合Majorization-Minimization和WMMSE的基于惩罚项的加权最小均方误差（PWM）算法。为避免局部最优，进一步将模型驱动深度学习方法融入PWM算法，通过训练关键变量加速收敛并提升性能。仿真结果验证了所提PWM-BFNet能显著减少迭代次数并大幅提升系统性能。

> **摘要翻译:** 可重构分布式天线和反射面（RDARS）是未来第六代（6G）无线网络中一种有前景的架构。特别是，RDARS辅助系统的动态工作模式配置与现有可重构智能表面（RIS）辅助系统和分布式天线系统（DAS）相比，带来了额外的选择增益。在本文中，我们考虑RDARS辅助的下行多输入多输出（MIMO）系统，旨在通过联合优化基站（BS）和RDARS的波束成形矩阵，以及RDARS的模式切换矩阵来最大化加权和速率（WSR）。由于非凸目标函数和混合整数二进制约束，该优化问题难以解决。为此，本文提出了一种基于惩罚项的加权最小均方误差（PWM）算法，该算法集成了Majorization-Minimization（MM）和加权最小均方误差（WMMSE）方法。为了进一步跳出PWM算法中的局部最优解，将模型驱动的深度学习方法集成到该算法中，训练与PWM算法收敛相关的关键变量，以加速收敛速度并提高系统性能。仿真结果表明，基于PWM的波束成形网络（PWM-BFNet）可以将迭代次数减少一半，并在高总发射功率和大量RDARS发射单元（TEs）的场景下，分别实现26.53%和103.2%的性能提升。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [42] [STAR-RIS-aided RSMA for the URLLC multi-user MIMO Downlink](https://arxiv.org/abs/2508.00409)
> *STAR-RIS辅助的URLLC多用户MIMO下行链路中的RSMA*

*Mohammad Soleymani, Ignacio Santamaria, Eduard Jorswieck, Robert Schober, Lajos Hanzo* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** STAR-RIS, RSMA, 能量效率, MIMO, URLLC

**Comment:** Accepted at 28th International Workshop on Smart Antennas 2025

> **TL;DR:** 本文提出结合STAR-RIS与RSMA以提升FBL MIMO下行链路的能效，并通过交替优化算法实现参数联合优化，数值结果表明其能效显著优于传统方案。

**AI_Comments:** 本文的创新点在于首次将STAR-RIS与RSMA结合，以解决URLLC场景下MIMO下行链路的能效问题。这种结合利用了STAR-RIS的全覆盖能力和RSMA的干扰管理优势，为未来无线通信系统中的能效优化提供了一条有前景的路径。

<details>
  <summary>Details</summary>

**Motivation:** 提升有限块长（FBL）多输入多输出（MIMO）下行链路的能量效率（EE）。

**Method:** 提出一种基于交替优化的算法，用于联合优化发射波束成形矩阵、STAR-RIS配置和速率分裂参数。

**Result:** 数值结果表明RSMA和STAR-RIS之间存在强大的协同作用，与反射式RIS和空分多址（SDMA）相比，实现了显著的能效增益。

**Conclusion:** 结合STAR-RIS和RSMA能够显著提升URLLC多用户MIMO下行链路的能量效率。

> **ai_Abstract:** 本文研究了在有限块长（FBL）多输入多输出（MIMO）下行链路中，将速率分裂多址（RSMA）与同时传输和反射（STAR）可重构智能表面（RIS）相结合，以提升能量效率（EE）。提出了一种基于交替优化的算法，用于联合优化发射波束成形、STAR-RIS配置和速率分裂参数。研究表明，STAR-RIS提供全平面覆盖，RSMA有效管理干扰，两者结合展现出强大的协同作用，并在能效方面显著优于反射式RIS和空分多址。

> **摘要翻译:** 速率分裂多址（RSMA）与同时传输和反射（STAR）可重构智能表面（RIS）本质上融合，以提高有限块长（FBL）多输入多输出（MIMO）下行链路的能量效率（EE）。本文提出一种基于交替优化的算法，用于联合优化发射波束成形矩阵、STAR-RIS配置和速率分裂参数。STAR-RIS实现了360度全平面覆盖，而RSMA通过有效管理干扰提供了显著的增益。数值结果揭示了RSMA和STAR-RIS之间强大的协同作用，证明了相对于反射式RIS和空分多址（SDMA）的显著能效增益。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [48] [When Vision-Language Model (VLM) Meets Beam Prediction: A Multimodal Contrastive Learning Framework](https://arxiv.org/abs/2508.00456)
> *当视觉-语言模型（VLM）遇见波束预测：一种多模态对比学习框架*

*Ji Wang, Bin Tang, Jian Xiao, Qimei Cui, Xingwang Li, Tony Q. S. Quek* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** 波束预测, 视觉-语言模型, 多模态学习, 对比学习, 毫米波

**Comment:** 

> **TL;DR:** 本文提出一个基于VLM的多模态对比学习框架，通过整合图像、LiDAR和位置信息（作为文本提示）来改进毫米波束预测，并在DeepSense-6G数据集上实现了显著的性能提升。

**AI_Comments:** 本文的创新点在于将视觉-语言模型（VLM）引入到毫米波束预测领域，并巧妙地利用位置信息作为文本提示，实现了图像、LiDAR和语言模态的有效融合与对齐。这种多模态对比学习框架为解决复杂动态环境下的波束预测难题提供了一条新颖且有效的路径。其重要性体现在超越传统依赖CSI方法的局限性，并利用VLM的强大表示能力提升预测精度。

<details>
  <summary>Details</summary>

**Motivation:** 毫米波束预测在复杂动态的实际传播环境中面临巨大挑战，传统依赖实时信道状态信息（CSI）的方法计算成本高昂且难以保持精度。视觉-语言模型（VLM）强大的跨模态表示能力为解决此问题提供了有前景的方法。

**Method:** 本文提出了一个由VLM驱动的、基于对比学习的多模态波束预测框架。该框架通过特定模态编码器整合多模态数据。为强制执行跨模态一致性，采用对比预训练策略来对齐潜在空间中的图像和LiDAR特征。此外，将位置信息作为文本提示连接到文本编码器，引入语言模态以进一步提高跨模态一致性。

**Result:** 在DeepSense-6G数据集上的实验表明，VLM骨干网络提供了额外的语义基础。与现有方法相比，该框架的整体基于距离的精度得分（DBA-Score）达到0.9016，平均提升了1.46%。

**Conclusion:** 本文提出的基于VLM的多模态对比学习框架能有效整合多种模态数据，通过跨模态对齐和语言模态的引入，显著提升了毫米波束预测的精度和鲁棒性，为复杂环境下的波束预测提供了新的解决方案。

> **ai_Abstract:** 本文针对毫米波束预测在复杂动态环境中的挑战，提出了一种基于视觉-语言模型（VLM）的多模态对比学习框架。该框架通过模态特定编码器整合图像、LiDAR和作为文本提示的位置信息，并通过对比预训练策略实现跨模态特征对齐。实验结果表明，该方法在DeepSense-6G数据集上取得了0.9016的DBA-Score，相比现有方法平均提升了1.46%，有效提升了波束预测的精度和鲁棒性。

> **摘要翻译:** 随着实际传播环境日益复杂和动态，毫米波束预测面临巨大挑战。然而，视觉-语言模型（VLM）强大的跨模态表示能力提供了一种有前景的方法。传统依赖实时信道状态信息（CSI）的方法计算成本高昂，并且在此类环境中往往无法保持精度。在本文中，我们提出了一个由VLM驱动的、基于对比学习的多模态波束预测框架，该框架通过特定模态编码器整合多模态数据。为了强制执行跨模态一致性，我们采用对比预训练策略来对齐潜在空间中的图像和LiDAR特征。我们使用位置信息作为文本提示，并将其连接到文本编码器以引入语言模态，这进一步提高了跨模态一致性。在DeepSense-6G数据集上的实验表明，我们的VLM骨干网络提供了额外的语义基础。与现有方法相比，整体基于距离的精度得分（DBA-Score）为0.9016，对应于平均1.46%的提升。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [54] [Feasibility of Extracting Skin Nerve Activity from Electrocardiogram Recorded at A Low Sampling Frequency](https://arxiv.org/abs/2508.00494)
> *从低采样频率心电图中提取皮肤神经活动的可行性*

*Youngsun Kong, Farnoush Baghestani, I-Ping Chen, Ki Chon* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** 皮肤神经活动, 心电图, 低采样频率, 交感神经系统, 可穿戴设备

**Comment:** Accepted and presented at the 47th Annual International Conference of
  the IEEE Engineering in Medicine and Biology Society (EMBC 2025)

> **TL;DR:** 本研究表明，即使在低采样频率下（如0.5 kHz或1 kHz），也可以从心电图（ECG）中可靠地提取皮肤神经活动（SKNA），这使得常规ECG设备也能用于交感神经系统评估。

**AI_Comments:** 这项研究具有重要意义，因为它打破了SKNA提取需要高采样频率的传统观念，为利用现有或低成本的ECG设备（尤其是可穿戴设备）进行交感神经系统评估开辟了新的途径。其创新点在于通过实验验证了低采样频率下SKNA提取的可行性，降低了技术门槛，有望促进SKNA在临床和日常健康监测中的广泛应用。主要限制是强调了“肌肉伪影污染最小”的前提条件，这在实际应用中可能需要额外的处理或特定的使用场景。

<details>
  <summary>Details</summary>

**Motivation:** 皮肤神经活动（SKNA）是从心电图（ECG）信号中提取的，是评估交感神经系统（SNS）的有前途的非侵入性替代方法。然而，SKNA的提取通常需要高于常规ECG记录的采样频率（> 2 kHz），因为分析工具从0.5-1 kHz频段提取SKNA。但ECG记录系统，特别是可穿戴设备，通常提供1 kHz或更低的采样频率，这限制了SKNA的广泛应用。

**Method:** 研究人员收集了16名参与者在交感神经系统刺激期间的ECG信号，并将信号重采样至0.5 kHz、1 kHz和4 kHz。随后，对不同采样频率下提取的SKNA指标进行了显著性、分类性能和可靠性方面的统计分析。

**Result:** 统计分析结果显示，从0.5 kHz、1 kHz和4 kHz采样频率的ECG信号中提取的SKNA指标之间没有显著差异。

**Conclusion:** 研究结果表明，如果肌肉伪影污染最小，受限于资源或过时指南而采用低采样率的传统ECG设备也可以可靠地用于收集皮肤神经活动（SKNA）。

> **ai_Abstract:** 本研究旨在探究在较低采样频率下从心电图（ECG）中提取皮肤神经活动（SKNA）的可行性。鉴于传统SKNA提取通常需要高于2 kHz的采样率而常规ECG设备常低于1 kHz，研究人员假设基于150-500 Hz频段在交感神经刺激中的主导性，低采样率ECG亦可用于SKNA提取。通过对16名参与者在SNS刺激下采集的ECG信号在0.5、1和4 kHz重采样后进行分析，结果显示不同采样频率下提取的SKNA指标无显著差异。这表明若肌肉伪影影响小，传统低采样率ECG设备也能可靠地用于SKNA的采集。

> **摘要翻译:** 从心电图（ECG）信号中提取的皮肤神经活动（SKNA）作为一种有前途的非侵入性替代方法，可用于准确有效地评估交感神经系统（SNS）。通常，SKNA提取需要比典型ECG记录更高的采样频率（> 2 kHz），因为分析工具从0.5-1 kHz频段提取SKNA。然而，ECG记录系统通常提供1 kHz或更低的采样频率，特别是对于可穿戴设备。我们最近的功率谱分析表明，在交感神经刺激期间，150-500 Hz频段占主导地位。因此，我们假设SKNA可以从较低采样频率采样的ECG中提取。我们收集了16名参与者在SNS刺激期间的ECG信号，并以0.5、1和4 kHz的频率对信号进行了重采样。我们对显著性、分类性能和可靠性的统计分析表明，从0.5、1和4 kHz采样的ECG信号中提取的SKNA指标之间没有显著差异。我们的研究结果表明，受限于资源限制或过时指南而采用低采样率的传统ECG设备，如果肌肉伪影污染最小，也可以可靠地用于收集SKNA。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [60] [Multibeam High Throughput Satellite: Hardware Foundation, Resource Allocation, and Precoding](https://arxiv.org/abs/2508.00800)
> *多波束高吞吐量卫星：硬件基础、资源分配与预编码*

*Rui Chen, Wen-Xuan Long, Bing-Qian Wang, Yuan He, Rui-Jin Sun, Nan Cheng, Gan Zheng, Dusit Niyato* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** 多波束HTS, 资源分配, 预编码, 卫星通信, 6G

**Comment:** 38 pages, 18 figures

> **TL;DR:** 本文综述了多波束高吞吐量卫星（HTS）系统的现状，涵盖了硬件基础、资源分配方法和预编码技术，并讨论了相关挑战与未来展望。

**AI_Comments:** 本文作为一篇综述性文章，全面梳理了多波束HTS系统在硬件、资源管理和信号处理方面的关键技术与挑战，为该领域的研究人员提供了宝贵的参考。其创新之处在于系统性地整合了从硬件到软件的多个层面，并指出了未来研究的潜在方向，特别是深度学习的应用。文章的重要性在于其对推动HTS技术发展以支持6G通信，并弥合数字鸿沟的潜在贡献。

<details>
  <summary>Details</summary>

**Motivation:** 高吞吐量卫星（HTS）系统利用多点波束和频率复用技术，能够提供Tbps级的卫星通信容量，以满足日益增长的流量需求。因此，有必要回顾多波束HTS系统的最新发展，并识别其相关挑战和前景。

**Method:** 本文首先总结了多波束HTS的硬件基础，包括地面站系统、星载有效载荷和用户终端。其次，回顾了HTS系统灵活的星载无线电资源分配方法，包括带宽、功率、时隙和联合分配方案。此外，还调查了HTS系统的多波束预编码方法，并根据不同部署（如单网关预编码、多网关预编码、星载预编码和混合星载/地面预编码）进行了分类。最后，讨论了与Q/V频段链路中断、网关时间频率同步、信道状态信息（CSI）精度、有效载荷轻量化开发以及深度学习（DL）应用相关的挑战。

**Result:** 本文总结了多波束HTS的硬件基础、多种资源分配方案（带宽、功率、时隙、联合分配）和多波束预编码方法（单网关、多网关、星载、混合）。同时，指出了Q/V频段链路中断、网关同步、CSI精度、有效载荷轻量化和深度学习应用等挑战。

**Conclusion:** 对这些主题的研究将有助于提高HTS系统的性能，并最终为陆地网络服务不足的地区提供高速数据。

> **ai_Abstract:** 本文对多波束高吞吐量卫星（HTS）系统进行了全面的综述。论文首先概述了HTS的硬件组成，包括地面站、星载载荷和用户终端。接着，详细阐述了带宽、功率、时隙及联合资源分配策略，旨在优化资源利用并满足多样化服务需求。此外，论文还分析了多种预编码技术，如单/多网关、星载及混合预编码，以实现频率复用和干扰抑制。最后，文中讨论了HTS系统面临的关键挑战，包括Q/V频段中断、同步问题、CSI准确性、载荷轻量化及深度学习的应用前景，强调了这些研究对提升HTS性能的重要性。

> **摘要翻译:** 凭借其广泛覆盖和不间断服务，卫星通信是下一代6G通信的关键技术。高吞吐量卫星（HTS）系统利用多点波束和频率复用技术，能够实现高达Tbps的卫星通信容量，以满足日益增长的流量需求。因此，有必要回顾多波束HTS系统的最新发展，并识别其相关挑战和前景。首先，我们总结了多波束HTS的硬件基础，包括地面站系统、星载有效载荷和用户终端。随后，我们回顾了HTS系统灵活的星载无线电资源分配方法，包括带宽、功率、时隙和联合分配方案，以优化资源利用并满足非均匀的服务需求。此外，我们调查了HTS系统的多波束预编码方法，以实现全频率复用和干扰消除，这些方法根据不同的部署（如单网关预编码、多网关预编码、星载预编码和混合星载/地面预编码）进行分类。最后，我们讨论了与Q/V频段链路中断、网关时间频率同步、信道状态信息（CSI）精度、有效载荷轻量化开发以及深度学习（DL）应用相关的挑战。对这些主题的研究将有助于提高HTS系统的性能，并最终为陆地网络服务不足的地区提供高速数据。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [66] [DoF Analysis and Beamforming Design for Active IRS-aided Multi-user MIMO Wireless Communication in Rank-deficient Channels](https://arxiv.org/abs/2411.07001)
> *秩亏信道中主动IRS辅助多用户MIMO无线通信的自由度分析与波束成形设计*

*Jinbing Jiang, Feng Shu, Xuehui Wang, Ke Yang, Chong Shen, Qi Zhang, Dongming Wang, Jiangzhou Wang* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** 智能反射面, 自由度, 波束成形, 多用户MIMO, 秩亏信道

**Comment:** 12 pages, 9 figures

> **TL;DR:** 在秩亏信道中，主动IRS可将多用户MIMO网络的自由度加倍，并通过提出的波束成形方法显著提升速率性能。

**AI_Comments:** 该论文的创新点在于系统地分析了主动IRS在秩亏信道中对DoF的提升潜力，并提出了具体的波束成形方法来实现这一增益。其重要性在于为未来6G网络中利用IRS提升频谱效率提供了理论依据和实践指导，尤其是在视距等低秩信道场景下，IRS展现出显著的性能提升能力，这对于实际部署具有重要意义。局限性可能在于仿真结果是否能完全反映复杂实际信道环境下的性能，以及主动IRS的实际部署成本和能耗。

<details>
  <summary>Details</summary>

**Motivation:** 智能反射面（IRS）有望成为未来6G等无线网络的关键技术，因为它能显著提高数据速率。本文旨在分析IRS辅助多用户MIMO网络中的自由度（DoF）。

**Method:** 首先，推导了IRS辅助单用户MIMO网络的DoF上限，并利用矩阵秩不等式将其扩展到多用户MIMO情况。为验证DoF提升带来的速率性能增益，提出了三种闭式波束成形方法：零空间投影加最大发射功率和最大接收功率（NSP-MTP-MRP）、施密特正交化加最小均方误差（SO-MMSE）以及两层泄漏加MMSE（TLL-MMSE），以实现最大DoF。

**Result:** 仿真结果表明，IRS确实带来了显著的速率提升。例如，在严重秩亏信道中，IRS辅助的TLL-MMSE的总和速率是无IRS情况下的两倍左右。

**Conclusion:** IRS可以在严重秩亏信道中实现显著的自由度提升和速率增强。

> **ai_Abstract:** 本文研究了在秩亏信道中，主动智能反射面（IRS）辅助多用户MIMO无线通信的自由度（DoF）分析和波束成形设计。研究推导了IRS辅助MIMO系统的DoF上限，并提出NSP-MTP-MRP、SO-MMSE和TLL-MMSE三种闭式波束成形方法以实现最大DoF。仿真结果显示，IRS，尤其在秩亏信道下，能够将网络DoF翻倍，并显著提升系统速率，例如TLL-MMSE方案可使总和速率翻倍。

> **摘要翻译:** 由于其显著提高数据速率的能力，智能反射面（IRS）将成为未来6G等无线网络的潜在关键技术。在本文中，我们将重点分析IRS辅助多用户MIMO网络中的自由度（DoF）。首先，推导了IRS辅助单用户MIMO网络的DoF上限，即此类系统可实现的最大DoF，并通过矩阵秩不等式将相应结果扩展到IRS辅助多用户MIMO的情况。特别是在严重秩亏（也称为低秩）信道（如视距（LoS）信道）中，借助IRS，网络DoF可能会比无IRS时加倍。为了验证DoF增加带来的速率性能增益，提出了三种闭式波束成形方法：零空间投影加最大发射功率和最大接收功率（NSP-MTP-MRP）、施密特正交化加最小均方误差（SO-MMSE）和两层泄漏加MMSE（TLL-MMSE），以实现最大DoF。仿真结果表明，IRS确实带来了显著的速率增强。例如，在严重秩亏信道中，IRS辅助的TLL-MMSE的总和速率是无IRS情况下的两倍左右。这意味着IRS在此类信道中可以实现显著的DoF提升。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [72] [Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN](https://arxiv.org/abs/2507.21696)
> *O-RAN中用于自主网络优化的边缘智能体AI框架*

*Abdelaziz Salama, Zeinab Nezami, Mohammed M. H. Qazzaz, Maryam Hafeez, Syed Ali Raza Zaidi* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** 边缘AI, O-RAN, 网络优化, AI智能体, 6G网络

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的边缘AI框架，通过多工具架构、异常检测和安全对齐奖励机制，在O-RAN环境中实现自主网络优化，在高压力条件下显著降低网络中断至零，并保持高性能。

**AI_Comments:** 这篇论文的创新点在于其提出的边缘AI框架，通过结合多工具架构、主动异常检测和安全对齐的奖励机制，有效解决了在O-RAN环境中部署AI智能体的安全性和可靠性问题。其在真实5G场景下的评估结果非常突出，特别是零网络中断的成就，这对于未来6G网络的自主优化具有重要意义。该框架为AI智能体在关键网络基础设施中的安全有效部署提供了有力的证据和实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 解决在传统无线接入网络（RAN）基础设施中部署AI智能体对未来6G网络带来的显著安全和可靠性挑战。

**Method:** 提出了一个边缘AI框架，包含三项核心创新：1) 基于角色的多工具架构，实现分布式、上下文感知的决策；2) 由流量预测工具驱动的主动异常检测智能体；3) 平衡性能与操作稳定性的安全对齐奖励机制。该框架集成到RAN智能控制器（RIC）中，并利用网络KPI、流量预测模型和外部信息源进行多模态数据融合。

**Result:** 在真实的5G场景评估中，该边缘框架在高压力条件下实现了零网络中断，远优于传统固定功率网络的8.4%和基于大型语言模型（LLM）智能体方法的3.3%中断率，同时保持了近实时响应和一致的服务质量（QoS）。

**Conclusion:** 当配备正确的工具和上下文感知能力时，AI智能体可以安全有效地部署在关键网络基础设施中，为智能和自主的5G及未来网络操作奠定基础。

> **ai_Abstract:** 本文提出了一个名为“边缘智能体AI框架”的新颖解决方案，旨在解决在O-RAN环境中部署AI智能体所面临的安全和可靠性挑战，以实现自主网络优化。该框架的核心包括一个基于角色的多工具架构、一个由流量预测驱动的异常检测智能体以及一个安全对齐的奖励机制。通过集成到RAN智能控制器中并利用多模态数据融合，该框架在高压力5G场景下实现了零网络中断，显著优于传统方法和基于LLM的智能体方法，同时保持了高性能和实时响应。研究结果证明了AI智能体在关键网络基础设施中安全有效部署的可行性，为未来智能网络操作奠定基础。

> **摘要翻译:** 在传统无线接入网络（RAN）基础设施中部署AI智能体对未来6G网络带来了显著的安全和可靠性挑战。本文提出了一种新颖的边缘AI框架，用于O-RAN环境中的自主网络优化，通过三项核心创新解决了这些挑战：（1）一种基于角色的多工具架构，实现分布式、上下文感知的决策；（2）由流量预测工具驱动的主动异常检测智能体；（3）一种平衡性能与操作稳定性的安全对齐奖励机制。该框架集成到RAN智能控制器（RIC）中，利用多模态数据融合，包括网络KPI、流量预测模型和外部信息源，以预测和响应动态网络条件。使用真实的5G场景进行的广泛评估表明，该边缘框架在高压力条件下实现了零网络中断，而传统固定功率网络的中断率为8.4%，基于大型语言模型（LLM）智能体的方法的中断率为3.3%，同时保持了近实时响应和一致的服务质量。这些结果表明，当配备正确的工具和上下文感知能力时，AI智能体可以安全有效地部署在关键网络基础设施中，为智能和自主的5G及未来网络操作奠定框架。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [575] [HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Recordings](https://arxiv.org/abs/2507.17224)
> *HuiduRep：一种用于从细胞外记录中学习神经表征的鲁棒自监督框架*

*Feng Cao, Zishuo Feng, Wei Shi, Jicong Zhang* | **Category: eess.SP, cs.AI, q-bio.NC** | **Updated: 2025-08-01**

**Keywords:** 自监督学习, 细胞外记录, 尖峰分选, 表征学习, 鲁棒性

**Comment:** 9 pages, 3 figures, 6 tables

> **TL;DR:** HuiduRep是一种鲁棒的自监督框架，通过结合对比学习和去噪自编码器，从细胞外记录中学习神经表征，并在尖峰分选任务上显著优于现有技术。

**AI_Comments:** HuiduRep的创新点在于将对比学习与去噪自编码器相结合，以自监督的方式从复杂的细胞外记录中提取鲁棒且可泛化的神经表征。这对于在低信噪比和电极漂移等挑战性条件下进行准确的尖峰分选至关重要。其超越现有SOTA工具的性能，预示着自监督学习在神经科学数据处理领域的广阔应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 尖峰分选是脑传感管线中的关键步骤，但在低信噪比、电极漂移和跨会话变异性条件下仍然具有挑战性。

**Method:** 本文提出了HuiduRep，一个鲁棒的自监督表征学习框架，通过将对比学习与去噪自编码器相结合，学习对噪声和漂移具有鲁棒性的潜在表征。基于HuiduRep，开发了一个无需真实标签即可聚类尖峰表征的尖峰分选管线。

**Result:** 在混合和真实世界数据集上的实验表明，HuiduRep实现了强大的鲁棒性。此外，该管线在准确性和精确度上显著优于KiloSort4和MountainSort5等现有最先进的工具。

**Conclusion:** 这些发现证明了自监督尖峰表征学习作为一种基础工具，在鲁棒和可泛化的细胞外记录处理方面的潜力。

> **ai_Abstract:** HuiduRep是一个针对细胞外记录的鲁棒自监督表征学习框架，旨在解决低信噪比、电极漂移和跨会话变异性等尖峰分选挑战。它结合了对比学习和去噪自编码器，学习对噪声和漂移具有鲁棒性的潜在表征。该框架被应用于无真实标签的尖峰分选，并在混合和真实数据集上展现出强大的鲁棒性，同时在准确性和精确度上显著超越了KiloSort4和MountainSort5等现有先进工具，表明了自监督尖峰表征学习在处理细胞外记录方面的潜力。

> **摘要翻译:** 细胞外记录是神经元附近短暂的电压波动，作为神经科学中以单神经元分辨率解码大脑活动的基本模式。尖峰分选是将每个检测到的尖峰归因于其相应神经元的过程，是脑传感管线中的关键步骤。然而，在低信噪比（SNR）、电极漂移和跨会话变异性条件下，它仍然具有挑战性。在本文中，我们提出了HuiduRep，一个鲁棒的自监督表征学习框架，用于从细胞外记录中提取判别性和可泛化的特征。通过将对比学习与去噪自编码器相结合，HuiduRep学习对噪声和漂移具有鲁棒性的潜在表征。利用HuiduRep，我们开发了一个尖峰分选管线，可以对尖峰表征进行聚类，而无需真实标签。在混合和真实世界数据集上的实验表明，HuiduRep实现了强大的鲁棒性。此外，该管线在准确性和精确度上显著优于KiloSort4和MountainSort5等现有最先进的工具。这些发现证明了自监督尖峰表征学习作为一种基础工具，在鲁棒和可泛化的细胞外记录处理方面的潜力。代码可在以下网址获取：https://github.com/IgarashiAkatuki/HuiduRep

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [621] [Subband Architecture Aided Selective Fixed-Filter Active Noise Control](https://arxiv.org/abs/2508.00603)
> *子带架构辅助选择性固定滤波器主动噪声控制*

*Hong-Cheng Liang, Man-Wai Mak, Kong Aik Lee* | **Category: eess.SP, cs.SY, eess.AS, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 主动噪声控制, 子带结构, 选择性固定滤波器, 噪声抑制, 鲁棒性

**Comment:** 

> **TL;DR:** 本文提出了一种基于无延迟子带结构的选择性固定滤波器主动噪声控制方案，以克服传统方法的局限性，实现对复杂噪声环境的快速有效降噪。

**AI_Comments:** 这篇论文的创新点在于将子带结构引入到选择性固定滤波器主动噪声控制中，通过频率分解和分频段处理，有效地解决了传统方法在处理复杂噪声类型和非均匀功率谱密度噪声时的性能瓶颈。这种设计思路增强了系统的鲁棒性和适应性，使其能够应对更广泛的噪声环境，是主动噪声控制领域的一个有价值的改进。

<details>
  <summary>Details</summary>

**Motivation:** 传统的选择性固定滤波器方法虽然能避免自适应算法收敛慢的问题，但只能处理有限类型的噪声，并且在输入噪声功率谱密度不均匀时性能会下降。

**Method:** 本文提出了一种基于无延迟子带结构的新型选择性固定滤波器方案。在离线训练阶段，预训练子带控制滤波器并存储；在在线控制阶段，通过多相FFT滤波器组分解噪声，频率带匹配机制分配最合适的子带控制滤波器，然后采用权重堆叠技术将所有子带权重组合成全带滤波器，实现实时噪声抑制。

**Result:** 实验结果表明，所提出的方案在处理更复杂的噪声环境时，具有快速收敛、有效降噪和强大的鲁棒性。

**Conclusion:** 所提出的基于子带架构的选择性固定滤波器主动噪声控制方案能够有效解决传统方法的局限性，并在复杂噪声环境下实现优异的降噪性能。

> **ai_Abstract:** 本文针对传统选择性固定滤波器主动噪声控制方法在处理复杂噪声类型和不均匀功率谱密度噪声时的局限性，提出了一种基于无延迟子带结构的新型方案。该方案在离线阶段预训练子带滤波器，在线阶段通过子带分解、频率带匹配和权重堆叠技术实现实时噪声抑制。实验证明该方法具有快速收敛、有效降噪和强鲁棒性。

> **摘要翻译:** 前馈选择性固定滤波器方法根据检测到的参考信号的频谱特征选择最合适的预训练控制滤波器，有效避免了传统自适应算法收敛缓慢的问题。然而，它只能处理有限类型的噪声，并且当输入噪声呈现不均匀的功率谱密度时，性能会下降。为了解决这些局限性，本文设计了一种基于无延迟子带结构的新型选择性固定滤波器方案。在离线训练阶段，针对不同的频率范围预训练子带控制滤波器并存储在专用的子滤波器数据库中。在在线控制阶段，使用多相FFT滤波器组分解传入的噪声，并且频率带匹配机制为每个子带信号分配最合适的控制滤波器。随后，采用权重堆叠技术将所有子带权重组合成一个全带滤波器，实现实时噪声抑制。实验结果表明，所提出的方案在处理更复杂的噪声环境时，提供了快速收敛、有效降噪和强大的鲁棒性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [660] [Rydberg Atomic Receiver: Next Frontier of Wireless Communications](https://arxiv.org/abs/2412.12485)
> *里德堡原子接收器：无线通信的下一个前沿*

*Mingyao Cui, Qunsong Zeng, Kaibin Huang* | **Category: eess.SP, cs.NI, physics.app-ph** | **Updated: 2025-08-01**

**Keywords:** 里德堡原子接收器, 无线通信, 量子, 电磁波, 传感

**Comment:** Accepted by IEEE Communications Magazine

> **TL;DR:** 本文综述了里德堡原子接收器（RARE）的原理、与经典接收器的比较、在无线通信中的最新进展及其独特应用，并提出了未来的研究方向。

**AI_Comments:** 本文亮点在于将量子尺度的里德堡原子应用于电磁波测量，为无线通信带来了潜在的性能突破。其创新性体现在利用量子现象实现比传统接收器更优越的尺寸、灵敏度和带宽性能。作为一篇综述性文章，它全面梳理了该领域的研究现状，并指明了未来发展方向，对于推动里德堡原子接收器技术的发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 里德堡原子接收器（RARE）有望突破经典接收器的性能极限，引发物理层无线通信的革命。本文旨在深入探讨由RARE赋能的通信。

**Method:** 本文首先全面介绍了RARE的基本原理；然后，在天线尺寸、灵敏度和带宽方面，对RARE与经典接收器进行了彻底的比较；随后，概述了RARE辅助无线通信的最新进展，包括频分复用、多输入多输出、无线传感和量子多体技术；此外，还介绍了RARE在多频段传感和通信中的独特应用；最后，提出了有前景的研究方向。

**Result:** 本文提供了一个关于里德堡原子接收器（RARE）的全面介绍、与经典接收器的详细比较、以及在频分复用、多输入多输出、无线传感和量子多体技术等无线通信领域的最新进展概览，并突出了其在多频段传感和通信中的独特应用潜力。

**Conclusion:** 本文通过提供有前景的研究方向来结束，表明RAREs在未来无线通信领域具有巨大的发展潜力。

> **ai_Abstract:** 本文全面综述了里德堡原子接收器（RARE），详细阐述了其基本原理、相对于经典接收器在天线尺寸、灵敏度和带宽方面的性能优势，以及在频分复用、多输入多输出、无线传感和量子多体技术等无线通信应用中的最新进展。论文还强调了RARE独特的宽带传感和通信能力，并提出了未来的研究方向，将RARE定位为物理层无线通信领域的一项颠覆性技术。

> **摘要翻译:** 里德堡原子接收器（RARE）通过利用里德堡原子的电子跃迁现象，正在推动电磁（EM）波测量领域的范式转变。这种在量子尺度上运行的接收器有潜力突破经典接收器的性能极限，引发物理层无线通信的革命。本文旨在深入探讨由RARE赋能的通信。我们首先全面介绍了RARE的基本原理。然后，在天线尺寸、灵敏度和带宽方面，对RARE与经典接收器进行了彻底的比较。随后，我们概述了RARE辅助无线通信的最新进展，涵盖了频分复用、多输入多输出、无线传感和量子多体技术。此外，还介绍了RARE在多频段传感和通信中的独特应用。最后，我们通过提供有前景的研究方向来结束本文。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [59] [Data-Driven Motion Planning for Uncertain Nonlinear Systems](https://arxiv.org/abs/2508.00154)
> *不确定非线性系统的数据驱动运动规划*

*Babak Esmaeili, Hamidreza Modares, Stefano Di Cairano* | **Category: eess.SY, cs.LG, cs.RO, cs.SY, math.OC** | **Updated: 2025-07-31**

**Keywords:** 数据驱动, 运动规划, 非线性系统, 不变多胞体, 状态反馈

**Comment:** 

> **TL;DR:** 本文提出一种数据驱动的运动规划框架，通过构建重叠不变多胞体和学习局部状态反馈增益，为不确定非线性系统实现安全、动态可行的路径，无需系统动力学模型。

**AI_Comments:** 该论文的创新点在于其完全数据驱动的运动规划方法，摆脱了对精确系统动力学模型的依赖，这对于难以建模的复杂非线性系统具有重要意义。通过结合不变集理论、多胞体近似和实时增益插值，实现了安全性和动态可行性。其局限性可能在于数据量需求、计算复杂性以及在实际物理系统中的鲁棒性验证。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法依赖系统动力学模型，而本文旨在为非线性系统开发一种无需模型、仅依赖数据进行安全区域计算和控制器设计的数据驱动运动规划方法。

**Method:** 该方法构建一系列重叠的不变多胞体。在每个采样点周围，算法识别凸可容许区域，并通过数据驱动的线性矩阵不等式问题学习椭球不变集及其局部状态反馈增益。这些椭球的凸包由多胞体近似，并通过插值增益获得分段仿射控制器。通过验证连续凸包多胞体的交集并引入中间节点，确保节点间的安全过渡。控制增益通过单纯形插值实时获得，确保状态在整个运动过程中保持在不变多胞体内。

**Result:** 通过仿真验证了所提出方法的有效性，证明其能为复杂非线性系统实现安全、动态可行的路径。

**Conclusion:** 本文提出的数据驱动运动规划框架能够为不确定非线性系统生成安全、动态可行的路径，且无需传统的系统动力学模型，仅依赖数据进行控制设计。

> **ai_Abstract:** 本文提出一种创新的数据驱动运动规划框架，专门针对不确定非线性系统。该方法通过构建重叠的不变多胞体，并利用数据驱动的线性矩阵不等式学习局部椭球不变集和状态反馈增益。通过对这些椭球的凸包进行多胞体近似和增益插值，实现了安全过渡和实时控制。与传统模型依赖方法不同，该框架仅需数据即可实现安全区域计算和控制器设计，并通过仿真验证了其在复杂非线性系统中生成安全、动态可行路径的有效性。

> **摘要翻译:** 本文提出一种针对非线性系统的数据驱动运动规划框架，该框架构建一系列重叠的不变多胞体。在每个随机采样的路径点周围，算法识别一个凸可容许区域，并解决数据驱动的线性矩阵不等式问题，以学习多个椭球不变集及其局部状态反馈增益。这些椭球的凸包在通过插值增益获得的分段仿射控制器下仍保持不变，然后通过一个多胞体进行近似。通过验证连续凸包多胞体的交集并引入一个中间节点以实现平滑过渡，确保节点之间的安全转换。控制增益通过基于单纯形的插值实时进行插值，使状态在整个运动过程中保持在不变多胞体内部。与依赖系统动力学模型的传统方法不同，我们的方法仅需要数据即可计算安全区域并设计状态反馈控制器。该方法通过仿真进行验证，证明了所提出的方法在为复杂非线性系统实现安全、动态可行的路径方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [125] [Learning to optimize with guarantees: a complete characterization of linearly convergent algorithms](https://arxiv.org/abs/2508.00775)
> *带保证的优化学习：线性收敛算法的完整表征*

*Andrea Martin, Ian R. Manchester, Luca Furieri* | **Category: eess.SY, cs.LG, cs.SY, math.OC** | **Updated: 2025-08-01**

**Keywords:** 优化算法, 线性收敛, 最坏情况保证, 平均情况性能, 算法增强

**Comment:** 

> **TL;DR:** 该研究旨在改进现有线性收敛优化算法的平均情况性能，同时保留其最坏情况保证。它通过表征保持收敛性的更新规则修改来实现，并适用于多种现有算法。

**AI_Comments:** 这项研究的创新之处在于它提供了一个“完整表征”，即不仅给出了可以进行哪些修改，而且明确指出只有这些修改才能保持线性收敛性。这对于在实际应用中定制和优化现有算法具有重要价值，因为它允许工程师在不牺牲算法可靠性的前提下，针对特定应用场景进行性能优化。

<details>
  <summary>Details</summary>

**Motivation:** 在关键工程应用中，优化算法需要可证明的最坏情况保证，但这通常会牺牲在实际常见特定问题实例上的性能。本文旨在解决如何在保留最坏情况保证的同时，提高给定线性收敛算法在特定目标问题集上的平均情况性能。

**Method:** 本文通过表征在非光滑复合优化问题中实现线性收敛的算法类别来解决此问题。具体而言，研究从一个基准线性收敛算法出发，推导出了所有（且仅有）能够保持其收敛性质的更新规则修改。

**Result:** 研究结果适用于增强现有算法，例如用于非凸、梯度主导函数的梯度下降法；用于强凸函数的Nesterov加速法；以及用于多面体可行集优化的投影方法。该方法在解决具有严格迭代预算的优化问题（应用于病态线性方程组和线性系统的模型预测控制）上展现了有效性。

**Conclusion:** 本文提供了一种完整表征线性收敛算法的方法，并展示了如何在不牺牲最坏情况保证的情况下，通过对其更新规则进行特定修改来提高其在特定问题上的平均性能。这对于实际工程应用中优化器的定制化具有重要意义。

> **ai_Abstract:** 本文研究如何改进现有线性收敛优化算法的平均情况性能，同时保留其最坏情况保证。作者通过完整表征一类在线性收敛算法中保持收敛性质的更新规则修改来实现这一目标。该方法适用于多种现有算法，如梯度下降和Nesterov加速法，并在解决病态线性系统和模型预测控制问题中展示了其有效性。

> **摘要翻译:** 在关键工程应用中，优化算法必须对数学定义的问题类别提供可证明的最坏情况保证。然而，针对最坏情况进行设计不可避免地会牺牲在实践中经常出现的特定问题实例上的性能。我们解决了如何增强给定线性收敛算法的问题，以改善其在受限目标问题集上的平均情况性能——例如，为特定动力系统应用定制模型预测控制（MPC）的现成求解器——同时保留其在整个问题类别上的最坏情况保证。为此，我们表征了针对非光滑复合优化问题类别实现线性收敛的算法类别。特别是，从一个基准线性收敛算法出发，我们推导出了所有——且仅有——能够保持其收敛性质的更新规则修改。我们的结果适用于增强传统算法，例如用于非凸、梯度主导函数的梯度下降法；用于强凸函数的Nesterov加速法；以及用于多面体可行集优化的投影方法。我们展示了该方法在解决具有严格迭代预算的优化问题（应用于病态线性方程组和线性系统的模型预测控制）上的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [306] [Petri Net Modeling and Deadlock-Free Scheduling of Attachable Heterogeneous AGV Systems](https://arxiv.org/abs/2508.00724)
> *可附着异构AGV系统的Petri网建模与无死锁调度*

*Boyu Li, Zhengchen Li, Weimin Wu, Mengchu Zhou* | **Category: eess.SY, cs.RO, cs.SY** | **Updated: 2025-08-01**

**Keywords:** Petri网, 异构AGV, 死锁预防, 调度, 元启发式算法

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本文研究了由可附着异构AGV（载体和穿梭车）组成的物料运输系统中的调度问题，利用Petri网建模并提出了一种基于Petri网的元启发式算法，结合死锁检测和预防策略，实现了无死锁调度，并通过实验验证了其有效性。

**AI_Comments:** 本文的创新点在于将Petri网理论应用于可附着异构AGV系统的调度问题，有效地解决了附着导致的死锁问题。其提出的基于Petri网的元启发式算法结合了死锁预防策略和计算效率优化，具有重要的理论和实践意义。通过与现有方法和真实工业数据的对比，验证了其在复杂调度环境下的优越性。

<details>
  <summary>Details</summary>

**Motivation:** 自动化和柔性需求的增长推动了异构AGV的广泛应用。然而，可附着异构AGV之间的协作虽然提高了操作效率，但其附着导致的同步和相互依赖性使得调度问题变得耦合且容易发生死锁。本研究旨在解决这一挑战。

**Method:** 引入Petri网对AGV调度进行建模，以描述并发和顺序任务执行以及载体-穿梭车同步。基于Petri网理论，提出了一种触发驱动的解码方法，并结合死锁检测和预防策略以确保无死锁调度。此外，开发了一种基于Petri网的元启发式算法，该算法在自适应大邻域搜索框架中，并结合了有效的加速方法以提高计算效率。

**Result:** 数值实验使用真实工业数据验证了所提出算法相对于工程实践中应用的调度策略、精确求解器和四种最先进的元启发式算法的有效性。敏感性分析也提供了管理见解。

**Conclusion:** 所提出的基于Petri网的建模方法和元启发式算法能够有效解决可附着异构AGV系统的调度问题，确保无死锁操作，并在实际应用中表现出优越性。

> **ai_Abstract:** 本研究针对由可附着异构AGV（载体和穿梭车）组成的物料运输系统中的调度问题，提出了一种基于Petri网的建模和求解方法。该方法利用Petri网描述AGV的并发和顺序任务执行以及同步，并开发了触发驱动的解码、死锁检测和预防策略，以确保无死锁调度。为提高计算效率，还设计了一种基于Petri网的元启发式算法，并结合自适应大邻域搜索和加速方法。实验结果表明，该算法在实际工业数据上表现出优于现有策略和先进元启发式算法的有效性。

> **摘要翻译:** 自动化和柔性需求的增长推动了异构自动导引车（AGV）的广泛应用。本研究旨在调查由可附着异构AGV（即载体和穿梭车）组成的物料运输系统中的一个新调度问题。它们可以灵活地相互附着和分离，以协同执行复杂的运输任务。虽然这种协作提高了操作效率，但附着引起的同步和相互依赖性使得调度变得耦合且容易发生死锁。为了应对这一挑战，引入Petri网来建模AGV调度，很好地描述了并发和顺序任务执行以及载体-穿梭车同步。基于Petri网理论，提出了一种触发驱动的解码方法，以及死锁检测和预防策略，以确保无死锁调度。此外，在自适应大邻域搜索框架中开发了一种基于Petri网的元启发式算法，并结合了有效的加速方法以提高计算效率。最后，使用真实工业数据进行的数值实验验证了所提出的算法相对于工程实践中应用的调度策略、精确求解器和四种最先进的元启发式算法的有效性。还进行了敏感性分析以提供管理见解。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [386] [Risk-Aware Autonomous Driving with Linear Temporal Logic Specifications](https://arxiv.org/abs/2409.09769)
> *基于线性时序逻辑规范的风险感知自动驾驶*

*Shuhao Qi, Zengjie Zhang, Zhiyong Sun, Sofie Haesaert* | **Category: eess.SY, cs.FL, cs.RO, cs.SY** | **Updated: 2025-07-31**

**Keywords:** 风险感知, 自动驾驶, 线性时序逻辑, 线性规划, 风险平衡

**Comment:** 

> **TL;DR:** 本文提出了一种结合线性时序逻辑（LTL）和线性规划（LP）的方法，使自动驾驶系统能够像人类一样感知和平衡多种驾驶风险，并在Carla模拟器中得到验证。

**AI_Comments:** 本文的创新点在于将风险度量与线性时序逻辑（LTL）相结合，以处理复杂的驾驶场景，并利用线性规划（LP）进行控制合成，从而实现了对多种驾驶风险（包括碰撞和交通规则违规）的平衡。这为实现更具人类风险感知能力的自动驾驶系统提供了新颖且实用的途径。

<details>
  <summary>Details</summary>

**Motivation:** 人类驾驶员在驾驶时能自然地平衡交通违规、轻微事故和致命事故等不同风险，但自动驾驶系统尚未能实现这种行为，这是一个开放问题。

**Method:** 本文将一种已在类人驾驶研究中验证的风险度量扩展到更复杂的、由线性时序逻辑（LTL）规范定义的驾驶场景，超越了单纯的碰撞风险。该扩展将事件的时间和严重性纳入LTL规范中，以反映类人风险感知。通过采用由安全和协同安全公式组成的LTL规范，将控制综合问题重新表述为可达性问题。此外，利用占用测度，为这种基于LTL的风险度量制定了一个线性规划（LP）问题。

**Result:** 合成的策略能够平衡不同类型的驾驶风险，包括碰撞风险和交通规则违规。所提出方法的有效性通过Carla模拟器中的三个典型交通场景得到了验证。

**Conclusion:** 本文成功提出并验证了一种基于线性时序逻辑和线性规划的风险感知自动驾驶方法，该方法能够平衡多种驾驶风险，包括碰撞和交通规则违规，从而使自动驾驶系统更接近人类驾驶员的风险感知能力。

> **ai_Abstract:** 本文提出了一种新的风险感知自动驾驶方法，旨在让自动驾驶系统像人类一样平衡多种驾驶风险。该方法通过将事件的时间和严重性纳入扩展的线性时序逻辑（LTL）规范中，并利用占用测度将控制综合问题转化为线性规划（LP）问题。最终合成的策略能够有效平衡碰撞风险和交通规则违规等不同类型的风险。该方法在Carla模拟器中的三个典型交通场景中得到了有效验证。

> **摘要翻译:** 人类驾驶员在驾驶时能自然地平衡交通违规、轻微事故和致命事故等不同关注点的风险。然而，在自动驾驶系统中实现相同的行为仍然是一个开放问题。本文扩展了一种已在类人驾驶研究中验证的风险度量，以涵盖由线性时序逻辑（LTL）规范定义的更复杂的驾驶场景，这些场景超越了单纯的碰撞风险。该扩展将事件的时间和严重性纳入LTL规范中，从而反映出类人风险感知。在不牺牲交通规则表达能力的前提下，我们采用了由安全和协同安全公式组成的LTL规范，从而允许将控制综合问题重新表述为可达性问题。通过利用占用测度，我们进一步为这种基于LTL的风险度量制定了一个线性规划（LP）问题。因此，合成的策略能够平衡不同类型的驾驶风险，包括碰撞风险和交通规则违规。所提出方法的有效性通过Carla模拟器中的三个典型交通场景得到了验证。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [508] [Cyber-Physical Co-Simulation of Load Frequency Control under Load-Altering Attacks](https://arxiv.org/abs/2508.00637)
> *负载改变攻击下负载频率控制的网络-物理协同仿真*

*Michał Forystek, Andrew D. Syrmakesis, Alkistis Kontou, Panos Kotsampopoulos, Nikos D. Hatziargyriou, Charalambos Konstantinou* | **Category: eess.SY, cs.CR, cs.SY** | **Updated: 2025-08-01**

**Keywords:** 负载频率控制, 负载改变攻击, 网络-物理协同仿真, 电网安全, 通信网络

**Comment:** 2025 IEEE International Conference on Communications, Control, and
  Computing Technologies for Smart Grids (SmartGridComm)

> **TL;DR:** 本文提出了一个开源的网络-物理协同仿真环境，用于全面分析负载改变攻击对电网负载频率控制和欠频减载机制的影响。

**AI_Comments:** 创新点在于提出了一个开源的网络-物理协同仿真环境，该环境整合了电网和通信网络模型，从而能够进行现实的网络-物理攻击分析。这对于理解和缓解DLAAs等新兴威胁至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 将信息通信技术（ICT）设备集成到电网中带来了新的网络威胁，特别是负载改变攻击（LAAs）和动态负载改变攻击（DLAAs），它们通过操纵负载来响应电网频率测量，对电网稳定性构成显著威胁，影响负载频率控制（LFC）和欠频减载（UFLS）等关键机制。

**Method:** 本文提出了一个开源的协同仿真环境，该环境建模了电网及其相应的通信网络，并实现了电网保护机制。

**Result:** 该设置允许在具体的负载频率控制（LFC）和欠频减载（UFLS）场景中对负载改变攻击进行全面分析。

**Conclusion:** 开发的协同仿真环境对于理解和分析网络威胁（如负载改变攻击）对电网稳定性和控制机制的影响至关重要。

> **ai_Abstract:** 本文探讨了电网面临的网络威胁，特别是利用信息通信技术集成的负载改变攻击（LAAs）。它提出了一个开源的网络-物理协同仿真环境，用于建模电网和通信网络，从而能够全面分析LAAs对负载频率控制（LFC）和欠频减载（UFLS）机制的影响。

> **摘要翻译:** 将信息和通信技术（ICT）设备集成到电网中带来了诸多益处。然而，它也使电网面临新的潜在网络威胁。许多控制和保护机制，如负责在负载波动期间维持标称频率的负载频率控制（LFC）以及在紧急情况下切断部分负载的欠频减载（UFLS），都依赖于通过通信网络进行的信息交换。最近出现的负载改变攻击（LAAs）利用高功率设备的僵尸网络引入负载波动。在其动态形式（DLAAs）中，它们根据实时电网频率测量来操纵负载以提高效率，对电网稳定性构成显著威胁。认识到通信网络在电网网络安全研究中的重要性，本文提出了一个开源的协同仿真环境，该环境建模了电网及其相应的通信网络，并实现了电网保护机制。这种设置允许在具体的LFC和UFLS场景中对攻击进行全面分析。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [536] [Integrating Opinion Dynamics into Safety Control for Decentralized Airplane Encounter Resolution](https://arxiv.org/abs/2508.00156)
> *将意见动力学整合到分散式飞机冲突解决的安全控制中*

*Shuhao Qi, Zhiqi Tang, Zhiyong Sun, Sofie Haesaert* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-31**

**Keywords:** 意见动力学, 飞机安全控制, 分散式冲突解决, 阻塞现象, 自主控制器

**Comment:** 

> **TL;DR:** 本文提出将生物启发式非线性意见动力学整合到飞机安全控制框架中，以解决分散式飞机冲突解决中存在的阻塞现象，同时确保安全和无阻塞的冲突解决。

**AI_Comments:** 该论文的创新点在于将生物启发式非线性意见动力学引入到飞机安全控制领域，以解决分散式冲突解决中的阻塞问题。这种方法无需通信或预设规则即可实现协作决策和快速协调，对于自主飞机控制器的设计具有重要意义。其贡献在于提供了一种新颖且高效的解决方案，以提升空域管理的效率和安全性。

<details>
  <summary>Details</summary>

**Motivation:** 随着空域日益拥堵，分散式飞机冲突解决方法变得至关重要。然而，分散式安全控制器虽然可以防止危险的空中碰撞，但并不总能确保及时解决冲突，导致飞机进度在某些情况下可能长时间受阻。

**Method:** 本文提出将生物启发式非线性意见动力学整合到飞机安全控制框架中，使安全控制器能够实现协作决策以解决阻塞，并在不依赖通信或预设规则的情况下促进快速、安全的协调。

**Result:** 广泛的仿真结果验证了改进的飞行效率和安全保障。

**Conclusion:** 这项研究为飞机自主控制器的设计提供了实用见解。

> **ai_Abstract:** 针对空域拥堵下分散式飞机冲突解决中存在的阻塞现象，本文提出将生物启发式非线性意见动力学融入飞机安全控制框架。该方法通过实现协作决策，在不依赖通信或预设规则的情况下，促进快速、安全的协调，从而保证飞行安全并消除阻塞。仿真结果验证了其在提高飞行效率和安全方面的有效性，为自主飞机控制器设计提供了实用指导。

> **摘要翻译:** 随着空域日益拥堵，分散式飞机冲突解决方法变得至关重要。虽然分散式安全控制器可以防止危险的空中碰撞，但它们并不总能确保及时解决冲突。因此，在某些情况下，飞机进度可能会长时间受阻。为了解决这种阻塞现象，本文提出将生物启发式非线性意见动力学整合到飞机安全控制框架中，从而同时保证安全和无阻塞的冲突解决。特别是，意见动力学使安全控制器能够实现协作决策以解决阻塞，并在不依赖通信或预设规则的情况下促进快速、安全的协调。广泛的仿真结果验证了改进的飞行效率和安全保障。这项研究为飞机自主控制器的设计提供了实用见解。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [561] [Adaptive Compensation of Nonlinear Friction in Mechanical Systems Without Velocity Measurement](https://arxiv.org/abs/2508.00175)
> *机械系统中无速度测量的非线性摩擦自适应补偿*

*Jose Guadalupe Romero, Romeo Ortega, Leyan Fang, Alexey Bobtsov* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-31**

**Keywords:** 摩擦补偿, 自适应控制, 速度观测器, 全局收敛, 无速度测量

**Comment:** 

> **TL;DR:** 提出了一种无需速度测量，基于浸入与不变性自适应速度观测器的全局收敛跟踪控制器，用于补偿机械系统中的非线性摩擦。

**AI_Comments:** 本文的创新点在于提出了无需速度测量的非线性摩擦补偿方案，并通过浸入与不变性方法构建了自适应速度观测器，实现了全局收敛。这解决了传统方法对速度测量依赖的痛点，对于实际机械系统控制具有重要意义。声称是“第一个全局收敛解决方案”凸显了其在该领域的突破性。

<details>
  <summary>Details</summary>

**Motivation:** 摩擦是机械系统中不可避免的现象，严重阻碍了精确伺服控制。现有摩擦补偿方案大多依赖难以获得的速度测量，且其摩擦数学模型包含多个未知参数，其中一些非线性地进入动力学方程。

**Method:** 提出了一种针对受静摩擦和库仑摩擦扰动的机械系统的全局收敛跟踪控制器。该控制器不依赖速度测量，其核心组件是一个基于浸入与不变性的自适应速度观测器，用于摩擦补偿。

**Result:** 提供了该观测器应用于受LuGre模型描述的摩擦影响的系统的仿真结果。

**Conclusion:** 本文提出的方法是针对无需速度测量实现摩擦补偿的挑战性问题的第一个全局收敛解决方案。

> **ai_Abstract:** 本文旨在解决机械系统中非线性摩擦补偿的挑战，特别是无需速度测量的情况。针对现有方法依赖速度测量和复杂摩擦模型的问题，作者提出了一种基于浸入与不变性的自适应速度观测器，并设计了一个全局收敛的跟踪控制器。该控制器能够有效补偿静摩擦和库仑摩擦，且不依赖于速度测量。研究声称这是该问题的首个全局收敛解决方案，并通过LuGre模型下的仿真结果验证了其有效性。

> **摘要翻译:** 摩擦是所有包含相对运动部件的机械系统中不可避免的现象。众所周知，摩擦是精确伺服控制的严重障碍，因此人们对设计一种补偿摩擦的程序产生了兴趣——这是一个许多研究人员多年来一直研究的课题。文献中报道的绝大多数摩擦补偿方案都依赖于速度测量的可用性，而这种信息很难获得。现有程序的第二个限制是它们依赖于包含多个未知参数的摩擦数学模型，其中一些参数非线性地进入动力学方程。在本文中，我们提出了一种针对受静摩擦和库仑摩擦扰动的机械系统的全局收敛跟踪控制器，这是一种可靠的摩擦现象数学模型，它不依赖于速度测量。关键组件是基于浸入与不变性的自适应速度观测器，用于摩擦补偿。据我们所知，这是解决这个挑战性问题的第一个全局收敛解决方案。我们还展示了我们的观测器应用于受更先进的LuGre模型描述的摩擦影响的系统的仿真结果。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [586] [Neural Co-state Projection Regulator: A Model-free Paradigm for Real-time Optimal Control with Input Constraints](https://arxiv.org/abs/2508.00283)
> *神经协态投影调节器：一种用于实时带输入约束最优控制的无模型范式*

*Lihan Lian, Uduak Inyang-Udoh* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-01**

**Keywords:** 无模型最优控制, 神经协态投影调节器, Pontryagin最小原理, 输入约束, 实时控制

**Comment:** 

> **TL;DR:** 本文提出了一种名为神经协态投影调节器（NCPR）的无模型学习框架，它结合了Pontryagin最小原理，能够实时解决带输入约束的非线性控制仿射系统的二次调节器问题，并在泛化能力和采样效率方面优于强化学习。

**AI_Comments:** 该论文的创新点在于将Pontryagin最小原理与神经网络相结合，提出了一种新颖的无模型最优控制范式。它有效地解决了传统强化学习在处理带输入约束的实时控制问题时面临的挑战，特别是在样本效率和泛化能力方面。通过预测协态而非直接学习控制策略，该方法提供了一种更具理论基础且性能更优的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的学习型方法（特别是强化学习）在解决最优控制任务时，通常存在样本效率低下、对奖励设计和超参数敏感以及泛化能力差（尤其是在存在输入约束的情况下）的问题。

**Method:** 本文引入了神经协态投影调节器（NCPR），这是一种基于Pontryagin最小原理（PMP）的无模型学习型最优控制框架。该框架训练一个神经网络（NN）以自监督方式，将当前系统状态作为输入，预测有限时间范围内的投影协态轨迹。随后，仅提取NN预测的第一个元素来解决一个轻量级二次规划（QP）。该工作流在反馈控制设置中执行，以实时计算满足输入约束和一阶最优条件的控制动作。

**Result:** 该方法在未见过的系统状态和变化的输入约束方面表现出卓越的泛化能力，并且还显示出更高的采样效率。

**Conclusion:** 神经协态投影调节器（NCPR）提供了一种有效的无模型学习范式，能够实时解决带输入约束的非线性最优控制问题，并在泛化能力和采样效率上优于传统的强化学习方法。

> **ai_Abstract:** 本文提出了一种名为神经协态投影调节器（NCPR）的无模型学习型最优控制框架，旨在解决现有强化学习在处理带输入约束的非线性控制问题时存在的样本效率低、泛化能力差等问题。NCPR基于Pontryagin最小原理，通过训练神经网络预测投影协态并结合二次规划来实时计算控制动作。实验证明，NCPR在泛化能力和采样效率方面均优于强化学习。

> **摘要翻译:** 基于学习的方法，特别是强化学习（RL），在无需明确系统模型的情况下解决最优控制任务方面已显示出前景。然而，这些方法通常样本效率低下，对奖励设计和超参数敏感，并且容易出现泛化能力差的问题，尤其是在存在输入约束的情况下。为了解决这些挑战，我们引入了神经协态投影调节器（NCPR），这是一种基于Pontryagin最小原理（PMP）的无模型学习型最优控制框架，能够解决带输入约束的非线性控制仿射系统中的二次调节器问题。在该框架中，一个神经网络（NN）在自监督设置下进行训练，以系统当前状态作为输入，预测投影协态（即协态乘以系统输入增益）的有限时间范围轨迹。随后，仅提取NN预测的第一个元素来解决一个轻量级二次规划（QP）。该工作流在反馈控制设置中执行，允许实时计算满足输入约束和一阶最优条件的控制动作。
我们测试了所提出的基于学习的无模型二次调节器在（1）独轮车模型机器人参考跟踪问题和（2）摆锤摆动任务上的性能。为了进行比较，两种任务都使用了强化学习；并且为了提供背景信息，独轮车模型示例中使用了基于模型的控制器。我们的方法在未见过的系统状态和变化的输入约束方面都表现出卓越的泛化能力，并且还显示出更高的采样效率。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [606] [Low-dimensional observer design for stable linear systems by model reduction](https://arxiv.org/abs/2508.00609)
> *基于模型降阶的稳定线性系统低维观测器设计*

*M. F. Shakib, M. Khalil, R. Postoyan* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-08-01**

**Keywords:** 低维观测器, 模型降阶, 矩匹配, 线性系统, 状态估计

**Comment:** 

> **TL;DR:** 本文提出了一种基于矩匹配模型降阶技术的稳定线性系统低维观测器设计方法，并证明了其在特定输入下能实现精确渐近状态重构，在一般输入下具有指数输入-状态稳定性，并通过仿真验证了其有效性。

**AI_Comments:** 本文的创新点在于将模型降阶技术（特别是矩匹配）应用于低维观测器的设计，实现了在保证估计性能（精确重构和有界误差）的同时降低观测器维度。这对于资源受限或需要简化计算的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为稳定的单输入单输出连续时间线性时不变系统设计一种低维观测器，以估计原始系统的状态。

**Method:** 该方法利用矩匹配模型降阶技术，将系统近似为一个降阶模型。在此降阶模型的基础上，设计一个低维观测器来估计原始系统的状态。

**Result:** 该观测器能够针对与观测器维度相关的给定输入类别建立精确的渐近状态重构。此外，对于一般输入，它建立了指数输入-状态稳定性，确保了有界的估计误差。数值模拟证实了该方法对于基准模型降阶问题的有效性。

**Conclusion:** 所设计的低维观测器能够有效且稳定地估计稳定线性系统的状态，并在特定输入下实现精确重构，在一般输入下保持有界估计误差。

> **ai_Abstract:** 本文提出了一种针对稳定单输入单输出连续时间线性时不变系统的新型低维观测器设计。该方法通过矩匹配技术进行模型降阶，然后基于降阶模型设计观测器。研究表明，该观测器能实现特定输入的精确渐近状态重构，并对一般输入具有指数输入-状态稳定性，确保估计误差有界。数值仿真验证了其有效性。

> **摘要翻译:** 本文提出了一种用于稳定、单输入单输出、连续时间线性时不变（LTI）系统的低维观测器设计方法。利用矩匹配模型降阶技术，我们将系统近似为一个降阶模型。基于此降阶模型，我们设计了一个低维观测器来估计原始系统的状态。我们证明了该观测器能够针对与观测器维度相关的给定输入类别建立精确的渐近状态重构。此外，我们为一般输入建立了指数输入-状态稳定性特性，确保了有界的估计误差。数值模拟证实了该方法对于基准模型降阶问题的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [652] [Optimal Messaging Strategy for Incentivizing Agents in Dynamic Systems](https://arxiv.org/abs/2508.00188)
> *动态系统中激励代理的最佳消息策略*

*Renyan Sun, Ashutosh Nayyar* | **Category: eess.SY, cs.GT, cs.SY, math.OC** | **Updated: 2025-07-31**

**Keywords:** 动态系统, 激励, 信息披露, 消息策略, 线性规划

**Comment:** We submitted a full paper to IEEE TAC for review. A preliminary
  version of this paper is scheduled to be presented at IEEE CDC conference in
  December 2025

> **TL;DR:** 研究了在动态系统中，设计者如何通过信息披露和自身行动来激励代理人遵循预设策略，并最大化自身收益。

**AI_Comments:** 这篇论文的创新点在于提出了一个在动态系统中激励代理人的框架，并提供了一种通过逆向归纳和线性规划计算最优策略的实用方法。它在信息披露和激励设计方面具有理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 设计者希望在动态系统中激励代理人遵循特定策略，同时最大化自身总预期收益。

**Method:** 考虑一个有限时域离散时间动态系统，设计者通过选择性信息披露和自身行动影响代理人。使用基于设计者和代理人之间共同信息的序贯理性激励兼容性概念。通过逆向归纳算法计算最优设计者策略，该算法解决一系列线性规划问题。

**Result:** 在特定信息结构假设下，最优设计者策略可以通过解决一系列线性规划的逆向归纳算法计算得出。

**Conclusion:** 该研究提供了一种计算最优消息和行动策略的方法，以在动态系统中激励代理人并最大化设计者的收益。

> **ai_Abstract:** 本文研究了在有限时域离散时间动态系统中，设计者如何通过选择性信息披露和自身行动来激励一个或多个代理人遵循预设策略，并最大化设计者的总预期收益。研究引入了基于序贯理性的激励兼容性概念，并证明在特定信息结构下，最优设计者策略可以通过逆向归纳算法（求解一系列线性规划）来计算。

> **摘要翻译:** 我们考虑一个由设计者和一个或多个代理人共同控制的有限时域离散时间动态系统，其中设计者可以通过选择性信息披露来影响代理人的行动。在每个时间步，设计者从预先指定的消息空间向代理人发送消息。设计者也可以采取直接影响系统动态和奖励的行动。每个代理人使用其收到的消息（以及其自身信息）来选择其行动。我们感兴趣的场景是，设计者希望激励每个代理人执行特定策略。我们考虑一种基于设计者和代理人之间共同信息的每个实现的序贯理性激励兼容性概念。我们的目标是找到一种设计者的消息和行动策略，该策略能够最大化其总预期奖励，同时激励每个代理人遵循预先指定的策略。在对问题信息结构的某些假设下，我们表明最优设计者策略可以通过解决一系列线性规划的逆向归纳算法来计算。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [655] [Prescribed-Time Boresight Control of Spacecraft Under Pointing Constraints](https://arxiv.org/abs/2504.04312)
> *航天器指向约束下的预设时间视轴控制*

*Xiaodong Shao, Haoyang Yang, Haoran Li, Zongyu Zuo, Jose Guadalupe Romero, Qinglei Hu* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-01**

**Keywords:** 视轴控制, 预设时间控制, 航天器姿态, 指向约束, 扰动观测器

**Comment:** 

> **TL;DR:** 针对航天器在时间和指向约束下的视轴重定向问题，本文提出了一种集成的预设时间视轴制导与控制方案，确保在预设时间内完成任务并避开禁区。

**AI_Comments:** 这篇论文的创新点在于提出了集成的视轴制导与控制（IBGC）方案，并引入了C1连续饱和预设时间调整（PPTA）函数和预设时间稳定性准则，以解决复杂的航天器视轴重定向问题。特别是在存在指向约束和外部扰动的情况下，通过预设时间控制和扰动观测器，确保了任务的按时完成和安全性，具有重要的工程应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决航天器在时间和指向约束下的视轴重定向问题。

**Method:** 提出了一种集成的视轴制导与控制（IBGC）方案。该方案引入了C1连续饱和预设时间调整（PPTA）函数和实用的预设时间稳定性准则。利用时间尺度变换技术和PPTA函数，设计了预设时间制导律，使视轴向量在预设时间内从几乎任意初始方向导向目标方向的小邻域，同时避开所有带安全裕度的禁区。此外，推导了预设时间扰动观测器（PTDO）以重建外部扰动。结合障碍函数和PPTA函数，开发了一种基于PTDO的降维姿态跟踪控制器，确保视轴在“安全管”内进行预设时间跟踪。

**Result:** 所提出的IBGC方案通过合理设置制导和控制律的安全裕度、稳定时间和安全管，实现了在所需任务完成时间内受指向约束的视轴重定向。仿真和实验结果验证了IBGC方案的有效性。

**Conclusion:** 本文提出的集成视轴制导与控制方案能够有效解决航天器在时间和指向约束下的视轴重定向问题，并在预设时间内完成任务，表现出良好的性能。

> **ai_Abstract:** 本文提出了一种集成的视轴制导与控制（IBGC）方案，用于解决航天器在时间和指向约束下的视轴重定向问题。该方案引入了C1连续饱和预设时间调整（PPTA）函数和实用的预设时间稳定性准则。通过时间尺度变换技术和PPTA函数，设计了预设时间制导律以引导视轴避开禁区。同时，开发了基于预设时间扰动观测器（PTDO）的姿态跟踪控制器，确保视轴在“安全管”内跟踪。仿真和实验结果验证了该IBGC方案在预设时间内完成指向约束下视轴重定向的有效性。

> **摘要翻译:** 本文提出了一种集成的视轴制导与控制（IBGC）方案，以解决航天器在时间和指向约束下的视轴重定向问题。文中提出了一种C1连续、饱和的预设时间调整（PPTA）函数，并建立了实用的预设时间稳定性准则。利用时间尺度变换技术和PPTA函数，我们提出了一种预设时间制导律，该制导律能在预设时间内将视轴向量从自由空间中几乎任意初始方向引导到目标方向的小邻域内，同时避开所有带有安全裕度的禁区。随后，推导了预设时间扰动观测器（PTDO）以重建外部扰动。通过利用障碍函数和PPTA函数，开发了一种基于PTDO的降维姿态跟踪控制器，该控制器确保在“安全管”内进行预设时间视轴跟踪。通过合理设置制导和控制律的安全裕度、稳定时间和安全管，所提出的IBGC方案实现了在所需任务完成时间内受指向约束的视轴重定向。仿真和实验结果证明了所提出的IBGC方案的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [112] [Zeroing Diagonals, Conjugate Hollowization, and Characterizing Nondefinite Operators](https://arxiv.org/abs/2508.00096)
> *对角线归零、共轭空心化和非定算子表征*

*David R. Nicholus* | **Category: math.NA, cs.NA, math.RA, 65F25, 15A21, 15B10, 15A23, 15B99, 15A86** | **Updated: 2025-07-31**

**Keywords:** 对角线归零, 空心矩阵, 无迹矩阵, 正交相似, 非定算子

**Comment:** 24 pages, 4 figures

> **TL;DR:** 本文证明了Damm和Fassbender关于实无迹矩阵的猜想，即存在一个正交矩阵V使得V⁻¹LV为空心且VMV⁻¹几乎空心。该结果源于一个更普遍的定理，并揭示了关于在矩阵对角线引入零的条件，同时对实无迹矩阵进行了新的表征，并给出了Fillmore定理的更强版本。

**AI_Comments:** 本文的创新之处在于其通过一个更普遍的定理，不仅解决了Damm和Fassbender的特定猜想，而且为矩阵对角线元素归零提供了更广泛的理论框架。其对实无迹矩阵的新表征以及对Fillmore定理的加强，都显示了其在矩阵理论领域的理论贡献。该研究为理解和分类非定算子提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在证明Damm和Fassbender提出的猜想，即对于任何一对实无迹矩阵L, M，存在一个正交矩阵V，使得V⁻¹LV为空心，且VMV⁻¹几乎空心。此外，研究还旨在揭示在特定条件下如何在矩阵对角线引入零，并对非定矩阵进行表征和分类。

**Method:** 研究通过证明一个更普遍的定理及其推论来达成目标。其中一个推论直接证明了Damm和Fassbender的猜想。通过设置L=M，研究深入探讨了单个算子对角线引入零的自由度和约束。这些结果被用于表征和分类非定矩阵。

**Result:** 1. 证明了Damm和Fassbender的猜想：对于任何一对实无迹矩阵L, M，存在一个正交矩阵V，使得V⁻¹LV为空心（主对角线全为0），且VMV⁻¹几乎空心（主对角线除最后两个元素外全为0）。
2. 揭示了在L, M的特定条件下，V⁻¹LV的除第一个或前两个对角线元素外，以及VMV⁻¹的除最后两个对角线元素外，可以引入0。
3. 证明了实无迹矩阵的新颖表征。
4. 提出了Fillmore定理的更强版本，即每个实矩阵都正交相似于一个主对角线为常数的矩阵。

**Conclusion:** 本文的结果通过对非定矩阵的表征和分类进行了背景化，大致根据可以引入多少个零以及以何种方式引入零来对其进行分类。

> **ai_Abstract:** 本文证明了Damm和Fassbender关于实无迹矩阵的猜想：存在一个正交矩阵V，能使一个矩阵对角线全为零，另一个矩阵对角线几乎全为零。这一成果源于一个更普遍的定理，并揭示了在特定条件下如何在矩阵对角线引入零。研究还对实无迹矩阵进行了新颖的表征，并提出了Fillmore定理的更强版本。这些发现有助于根据对角线零元素的数量和方式对非定矩阵进行分类和表征。

> **摘要翻译:** 我们证明了Damm和Fassbender的猜想，即对于任何一对实无迹矩阵L, M，存在一个正交矩阵V，使得V⁻¹LV为空心，且VMV⁻¹几乎空心。其中，当一个矩阵的主对角线元素全为0时，称其为空心矩阵；当一个无迹矩阵的主对角线元素除最多最后两个外全为0时，称其为几乎空心矩阵。

该主张是我们更普遍定理的一个推论，以及另一个推论，揭示了在L, M满足何种条件下，V可以通过V⁻¹LV的所有对角线元素（除了第一个或前两个）以及VMV⁻¹的所有对角线元素（除了最后两个）引入0。

通过设置L = M，揭示了在单个算子对角线引入0所涉及的自由度和约束。由此，我们证明了实无迹矩阵的新颖表征，以及Fillmore开创性定理的一个更强版本，即每个实矩阵都正交相似于一个主对角线为常数的矩阵。

我们的结果在非定矩阵的表征和分类中得到了背景化，大致根据可以引入多少个零以及以何种方式引入零来对其进行分类。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [135] [Leveraging Operator Learning to Accelerate Convergence of the Preconditioned Conjugate Gradient Method](https://arxiv.org/abs/2508.00101)
> *利用算子学习加速预处理共轭梯度法的收敛*

*Alena Kopaničáková, Youngkyu Lee, George Em Karniadakis* | **Category: math.NA, cs.LG, cs.NA, math.OC, 65M55, 68T05, 49K20** | **Updated: 2025-07-31**

**Keywords:** 算子学习, 预处理共轭梯度法, 收缩策略, DeepONet, 大规模线性方程组

**Comment:** 31 pages

> **TL;DR:** 本文提出一种基于DeepONet的新的收缩策略，以加速预处理共轭梯度法求解参数化大规模线性方程组的收敛。

**AI_Comments:** 这篇论文的创新点在于将算子学习（DeepONet）引入到预处理共轭梯度法的收缩策略中，为加速大规模线性方程组的求解提供了新的思路，突破了传统方法的局限性。其提出的两种构建收缩算子和稀疏模式策略也增加了方法的灵活性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 针对求解参数化大规模线性方程组时预处理共轭梯度法（PCG）的收敛速度问题，寻求一种加速其收敛的方法。

**Method:** 本文提出一种新的收缩（deflation）策略，利用算子学习（特别是Deep Operator Network, DeepONet）来生成收缩子空间，而非传统方法。具体包括两种互补方法来构建收缩算子：一是使用DeepONet学习的基函数近似离散PDE算子的近零空间向量；二是直接利用DeepONet预测的解。此外，还提出了几种策略来规定收缩算子的稀疏模式以进一步增强收敛。

**Result:** 通过对稳态、瞬态、标量和矢量值问题（包括结构化和非结构化几何）进行全面的数值实验，证明了所提出的基于DeepONet的收缩PCG方法的有效性，以及其在各种模型参数和问题分辨率下的泛化能力。

**Conclusion:** 基于DeepONet的收缩预处理共轭梯度法能够有效加速大规模线性方程组的求解，并具有良好的泛化能力。

> **ai_Abstract:** 本文提出一种新颖的收缩策略，旨在利用深度算子网络（DeepONet）加速预处理共轭梯度法（PCG）在求解参数化大规模线性方程组时的收敛。该方法通过DeepONet生成收缩子空间，并引入两种构建收缩算子的互补途径：利用DeepONet学习的基函数近似近零空间向量或直接利用DeepONet预测的解。为进一步提升收敛，还探讨了收缩算子稀疏模式的策略。实验结果表明，该DeepONet-based收缩PCG方法在多种问题类型和分辨率下均表现出显著的有效性和良好的泛化能力。

> **摘要翻译:** 我们提出一种新的收缩策略，以加速求解参数化大规模线性方程组的预处理共轭梯度（PCG）方法的收敛。与依赖特征向量近似或循环Krylov子空间的传统收缩技术不同，我们使用算子学习，特别是深度算子网络（DeepONet）来生成收缩子空间。为此，我们引入了两种互补的方法来组装收缩算子。第一种方法是利用DeepONet学习的基函数来近似离散PDE算子的近零空间向量。第二种方法是直接利用DeepONet预测的解。为了进一步提高收敛性，我们还提出了几种规定收缩算子稀疏模式的策略。本文展示了一系列全面的数值实验，涵盖了在结构化和非结构化几何上提出的稳态、瞬态、标量和矢量值问题，并证明了所提出的基于DeepONet的收缩PCG方法的有效性，以及其在各种模型参数和问题分辨率下的泛化能力。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [155] [Partial Floquet Transformation and Model Order Reduction of Linear Time-Periodic Systems](https://arxiv.org/abs/2508.00221)
> *线性时变周期系统的部分Floquet变换和模型降阶*

*Sam Bender, Christopher Beattie* | **Category: math.NA, cs.NA, math.DS** | **Updated: 2025-07-31**

**Keywords:** 线性时变周期系统, 模型降阶, Floquet变换, 部分Floquet变换, Dominant Pole算法

**Comment:** 21 pages

> **TL;DR:** 本文提出了一种部分Floquet变换方法，并结合改进的Dominant Pole算法，用于大规模线性时变周期系统（LTP）的模型降阶，以解决传统Floquet变换计算量过大的问题。

**AI_Comments:** 本文的创新点在于提出了“部分Floquet变换”的概念，并将其与不变子空间理论结合，以解决传统Floquet变换在大规模线性时变周期系统模型降阶中的计算瓶颈。通过改造Dominant Pole算法来识别关键子空间，为复杂系统的高效仿真提供了新的思路，具有较强的工程应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大规模线性时变周期（LTP）系统在自然界和工程系统中普遍存在，需要模拟对各种输入配置的响应。然而，传统的Floquet变换方法对于大型系统而言计算量过大，难以处理，因此迫切需要有效的模型降阶策略。

**Method:** 本文提出了一种与LTP系统相关联的时变微分算子的选定不变子空间相连接的部分Floquet变换概念。通过修改和重新利用Rommes的Dominant Pole算法来识别有效的、可用于模型降阶的不变子空间。文中讨论了相关部分Floquet变换和时变降阶基的构建，以生成有效的降阶LTP模型，并通过一个简单的时变周期系统来演示该过程。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对大规模线性时变周期（LTP）系统模型降阶的挑战，提出了一种部分Floquet变换的新方法。该方法通过识别与LTP系统时变微分算子相关的选定不变子空间，并结合修改后的Rommes Dominant Pole算法来构建有效的降阶模型。旨在克服传统Floquet变换在大规模系统上计算不可行的问题，从而实现LTP系统的高效模拟。

> **摘要翻译:** 时间周期动力系统在自然界和工程系统中都很常见。例如，大型线性时间周期动力系统可能通过非线性系统在给定周期解（可能是基线周期强迫的结果）附近的线性化，并随后进行空间离散化而产生。模拟对各种输入配置（被视为基线周期强迫的扰动）的响应的潜在需求，为适用于线性时间周期（LTP）系统的有效模型降阶策略创造了强大的动力。考虑底层时间周期系统结构的经典方法通常利用Floquet变换；然而，对于大阶系统而言，Floquet变换的计算通常是难以处理的。在本文中，我们提出了一个与LTP系统相关联的时变微分算子的选定不变子空间相连接的部分Floquet变换的概念。我们修改并重新利用Rommes的Dominant Pole算法来识别可用于模型降阶的有效不变子空间。我们讨论了相关部分Floquet变换和时变降阶基的构建，以生成有效的降阶LTP模型，并通过一个简单的时间周期系统来演示该过程。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [175] [A reduced-IRKA method for large-scale $\mathcal{H}_2$-optimal model order reduction](https://arxiv.org/abs/2508.00242)
> *大规模$\\mathcal{H}_2$最优模型降阶的简化IRKA方法*

*Yiding Lin, Valeria Simoncini* | **Category: math.NA, cs.NA** | **Updated: 2025-08-01**

**Keywords:** 模型降阶, $\\mathcal{H}_2$最优, IRKA, 大规模系统, 有理Krylov子空间

**Comment:** 

> **TL;DR:** IRKA在大规模问题上表现不佳，本文提出了一种新的简化IRKA方法，通过顺序生成投影子空间并在投影问题上使用IRKA来处理大规模$\\mathcal{H}_2$最优模型降阶问题，并有效限制内存。数值实验证明了其有效性。

**AI_Comments:** 这篇论文的创新点在于提出了一个“简化”的IRKA方法，通过结合子空间投影、顺序生成和内存管理策略，成功地将IRKA的应用范围扩展到大规模问题，解决了传统IRKA的效率和内存瓶颈。这对于实际工程应用中处理大型复杂系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的迭代有理Krylov算法(IRKA)在处理大规模线性动力系统时，其$\\mathcal{H}_2$最优模型降阶的性能不令人满意。

**Method:** 本文提出了一种新的有理Krylov子空间投影方法。该方法通过顺序生成投影子空间，并在投影问题上应用IRKA过程以生成降阶问题的新的最优有理空间和相关移位。这些移位随后被注入以扩展投影空间。为了限制内存需求，还对生成的空间中的旧信息进行截断。

**Result:** 在基准问题上的数值实验表明，新方法是有效的。

**Conclusion:** 新提出的简化IRKA方法能够有效解决大规模$\\mathcal{H}_2$最优模型降阶问题，并且在内存管理方面表现良好。

> **ai_Abstract:** 本文提出了一种针对大规模线性动力系统$\\mathcal{H}_2$最优模型降阶的新型简化IRKA方法，以解决现有IRKA方法在大规模问题上性能不佳的局限性。该方法通过顺序生成投影子空间，并在投影问题上应用IRKA来获得最优有理空间和移位，进而扩展投影空间。为控制内存，还引入了旧信息的截断机制。数值实验验证了该方法在大规模问题上的有效性。

> **摘要翻译:** $\\mathcal{H}_2$最优模型降阶 (MOR) 是线性动力系统降阶方法中最重要的框架之一。在这种背景下，迭代有理Krylov算法 (IRKA) 是一种成熟的方法，用于在系统维度较小或中等时计算固定维度 $r$ 的最优投影空间。然而，对于大规模问题，IRKA 的性能不尽如人意。在本文中，我们介绍了一种新的有理Krylov子空间投影方法，该方法通过方便选择的移位，可以有效地处理大规模问题。投影子空间是顺序生成的，并且在投影问题上采用 IRKA 过程来为降阶问题生成一个新的维度为 $r$ 的最优有理空间以及相关的移位。后者随后被注入以扩展投影空间。为了限制内存需求，对生成的空间中的旧信息进行截断。在基准问题上的数值实验表明了新方法的有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [192] [A COGENT case study: Supporting Applications with Chombo](https://arxiv.org/abs/2508.00375)
> *COGENT案例研究：用Chombo支持应用程序*

*Daniel F. Martin, Milo Dorr, Mikhail Dorf, Lee F. Ricketson* | **Category: math.NA, cs.NA, physics.plasm-ph** | **Updated: 2025-08-01**

**Keywords:** Chombo, COGENT, 软件框架, 科学应用, 案例研究

**Comment:** 

> **TL;DR:** Chombo软件框架通过开发新功能成功支持了科学应用COGENT的特定需求，并且这些新功能也能支持其他类似需求的应用程序。

**AI_Comments:** 这篇论文展示了通用软件框架通过定制化开发，能够有效支持特定科学应用的案例。Chombo框架的灵活性和可扩展性是其成功的关键，同时新开发的功能也具有复用价值，体现了软件工程的良好实践。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在展示Chombo软件框架如何支持科学应用COGENT的特定需求，特别是为了构建COGENT模型所需的独特模拟能力。

**Method:** 通过在Chombo框架中设计和实现一套新功能，例如高阶映射多块离散化和多维代码组织，以满足COGENT的特定需求。

**Result:** COGENT开发了用于模拟托卡马克边缘层的独特模拟能力。此外，这些新开发的功能也能够支持其他具有类似需求的应用程序。

**Conclusion:** Chombo框架通过适应和扩展其能力，成功支持了特定科学应用COGENT的需求，并且其为COGENT开发的新功能具有通用性，能够惠及其他有类似需求的应用。

> **ai_Abstract:** 这篇论文通过一个案例研究，展示了通用软件框架Chombo如何成功支持科学应用COGENT的特定需求。为满足COGENT对托卡马克边缘层建模的独特模拟能力要求，Chombo框架开发了包括高阶映射多块离散化和多维代码组织在内的新功能。这些能力不仅使COGENT得以发展，也能够支持其他具有类似需求的应用程序。

> **摘要翻译:** 我们提出了一个案例研究，探讨了软件框架（Chombo）如何支持科学应用（COGENT）的特定需求。自2000年成立以来，Chombo框架已支持各种应用程序。这种支持的一个例子是与边缘模拟实验室合作构建COGENT模型。COGENT工作的具体需求要求在Chombo框架中设计和实现一套新功能，例如高阶映射多块离散化和多维代码组织。这些功能使COGENT能够开发出一种独特的模拟能力，用于模拟托卡马克中的边缘层。一旦开发出来，这些功能就能够支持其他具有类似需求的应用程序。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [220] [A new addition theorem for the 3-D Navier-Lamé system and its application to the method of fundamental solutions](https://arxiv.org/abs/2508.00515)
> *三维Navier-Lamé系统的新加法定理及其在基本解方法中的应用*

*J. A. Barceló, C. Castro, A. Ruiz, M. C. Vilela* | **Category: math.NA, cs.NA** | **Updated: 2025-08-01**

**Keywords:** Navier-Lamé系统, 加法定理, 基本解方法, 贝塞尔函数, 球谐函数

**Comment:** 

> **TL;DR:** 本文提出了三维Navier-Lamé系统基本解的一个新加法定理，该定理使得基本解的展开式仅需评估贝塞尔函数和标量球谐函数，并证明了其在外部域数值方法中的效率。

**AI_Comments:** 该论文的创新之处在于提出了三维Navier-Lamé系统基本解的新加法定理，极大地简化了其计算复杂性。通过将展开式限制为仅涉及贝塞尔函数和标量球谐函数，它为数值方法（如边界元法和基本解方法）提供了更高效的工具。其重要性在于提升了这些数值方法在解决弹性力学问题，尤其是在外部域问题上的实用性和效率。这对于工程和物理领域的模拟具有潜在的积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 为了简化三维Navier-Lamé系统基本解的展开式，使其更适用于基于基本解的配置数值方法（如边界元法或基本解方法），从而提高这些方法的计算效率。

**Method:** 获得了满足Kupradze辐射条件的三维Navier-Lamé系统基本解的新加法定理。该定理提供了一种仅涉及贝塞尔函数和标量球谐函数评估的展开式。并展示了基本解方法在逼近外部域Navier-Lamé系统时的效率。

**Result:** 获得了仅涉及贝塞尔函数和标量球谐函数评估的三维Navier-Lamé系统基本解的展开式。证明了基本解方法在逼近外部域Navier-Lamé系统时的效率。

**Conclusion:** 新的加法定理显著简化了三维Navier-Lamé系统基本解的计算，提高了基于基本解的数值方法的实用性和效率，特别是基本解方法在处理外部域问题时表现出高效性。

> **ai_Abstract:** 本文提出了三维Navier-Lamé系统基本解的一个新加法定理，该定理使得基本解的展开式仅需评估贝塞尔函数和标量球谐函数。这一发现对于边界元法和基本解方法等基于基本解的配置数值方法具有重要意义。研究还特别展示了基本解方法在处理外部域Navier-Lamé系统时的优异效率。

> **摘要翻译:** 我们获得了满足Kupradze辐射条件的三维Navier-Lamé系统基本解的新加法定理。这提供了一种仅涉及贝塞尔函数和标量球谐函数评估的基本解展开式。这在基于基本解的配置数值方法中特别有用，例如边界元法或基本解方法。对于后一种方法，我们展示了其在逼近外部域Navier-Lamé系统时的效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [244] [Solitary-wave solutions of the fractional nonlinear Schrödinger equation. II. A numerical study of the dynamics](https://arxiv.org/abs/2508.00559)
> *分数阶非线性薛定谔方程的孤立波解。II. 动力学数值研究*

*Angel Durán, Nuria Reguera* | **Category: math.NA, cs.NA, math.AP, 76B25, 35C07, 65H10** | **Updated: 2025-08-01**

**Keywords:** 分数阶非线性薛定谔方程, 孤立波, 数值研究, 动力学, 稳定性

**Comment:** 

> **TL;DR:** 本文通过数值方法研究分数阶非线性薛定谔方程孤立波的动力学和稳定性。

**AI_Comments:** 本文是前一部分理论研究的延续，通过数值模拟深入探讨了分数阶非线性薛定谔方程孤立波的动力学特性和稳定性，这对于理解复杂非线性系统的行为至关重要。采用傅里叶谱方法和高阶Runge-Kutta方法保证了数值研究的精度。

<details>
  <summary>Details</summary>

**Motivation:** 在项目的第一部分分析了分数阶非线性薛定谔方程孤立波解的存在性之后，本文旨在通过数值方法研究这些孤立波解的动力学行为。

**Method:** 研究通过近似周期性初值问题进行，采用一个完全离散方案。该方案包括用于空间离散化的傅里叶谱方法和作为时间积分器的四阶龙格-库塔-组合方法。

**Result:** 讨论了波的稳定性问题，包括小扰动和大扰动的影响、孤立波的相互作用以及初始数据分解成波列的现象。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文是关于分数阶非线性薛定谔方程孤立波解动力学的数值研究。研究采用傅里叶谱方法进行空间离散化，并结合四阶龙格-库塔-组合方法作为时间积分器，以近似周期性初值问题。文中探讨了孤立波的稳定性，包括扰动效应、波相互作用以及初始数据形成波列等动态行为。

> **摘要翻译:** 本论文是对分数阶非线性薛定谔方程孤立波解动力学的数值研究，这些解的存在性已由作者在该项目的第一部分中进行了分析。计算研究将通过一个完全离散方案来近似周期性初值问题，该方案包括用于空间离散化的傅里叶谱方法和作为时间积分器的四阶龙格-库塔-组合方法。讨论了关于波稳定性的一些问题，例如小扰动和大扰动的影响、孤立波的相互作用以及初始数据分解成波列的现象。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [270] [Towards a mixed-precision ADI method for Lyapunov equations](https://arxiv.org/abs/2508.00722)
> *面向Lyapunov方程的混合精度ADI方法*

*Jonas Schulze, Jens Saak* | **Category: math.NA, cs.NA, 15A24, 65F10, 65F45, 65F55** | **Updated: 2025-08-01**

**Keywords:** 混合精度, ADI方法, Lyapunov方程, 低秩, 描述符系统

**Comment:** 11 pages, 3 figures, 1 table; submitted to PAMM 2025

> **TL;DR:** 探索了将混合精度应用于Lyapunov方程的低秩ADI方法，发现在某些情况下，单精度累积解能达到与双精度相近的残差，并且在特定应用中具有竞争力。

**AI_Comments:** 该论文提出了一种将混合精度技术整合到Lyapunov方程ADI方法中的创新方法。这很重要，因为它探索了一种在保持可接受精度的同时，可能降低计算成本和内存占用量的方法，这对于大规模问题至关重要。单精度累积在某些情况下可以产生与双精度相似精度的发现尤其具有洞察力，突出了混合精度的实际适用性。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在探索将混合精度应用于低秩Lyapunov ADI（LR-ADI）方法，以期在保持精度的同时提高Lyapunov方程求解的效率。

**Method:** 研究人员通过以较低精度执行LR-ADI算法的某些部分来应用混合精度。具体来说，他们使用IEEE 754单精度和双精度的各种组合来累积整体解、求解构成ADI迭代的线性系统，并存储残差的内部低秩因子。他们在一阶和二阶描述符系统产生的Lyapunov方程上对该实现进行了实证测试。

**Result:** 对于一阶示例，以单精度累积解产生的残差几乎与双精度解一样小。对于计算描述符系统H2范数等特定应用，ADI的低精度或混合精度变体被证明具有很强的竞争力。

**Conclusion:** 混合精度ADI方法可以成为求解Lyapunov方程的一种有竞争力的替代方案，尤其适用于某些特定应用和系统类型，能够提供可比的精度并可能带来效率提升。

> **ai_Abstract:** 本文研究了在求解Lyapunov方程时，低秩Lyapunov ADI（LR-ADI）方法中混合精度的应用。它探讨了使用单精度和双精度的组合来执行算法的某些部分，例如解的累积、线性系统求解和残差因子存储。实证测试表明，对于一阶系统，单精度解累积可以产生与双精度相当的残差精度。研究得出结论，混合精度ADI对于H2范数计算等特定应用可能是一种有竞争力的方案。

> **摘要翻译:** 我们将混合精度应用于低秩Lyapunov ADI（LR-ADI）方法，通过以较低的工作精度执行算法的某些方面。具体而言，我们在IEEE 754单精度和双精度的各种组合中累积整体解、求解构成ADI迭代的线性系统，并存储残差的内部低秩因子。我们通过实验测试了在由一阶和二阶描述符系统产生的Lyapunov方程上的实现。对于一阶示例，以单精度累积解产生的残差几乎与双精度解一样小。对于某些应用，例如计算描述符系统的H2范数，ADI的低精度或混合精度变体可能非常有竞争力。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [310] [Matrix Decomposition and Applications](https://arxiv.org/abs/2201.00145)
> *矩阵分解及其应用*

*Jun Lu* | **Category: math.NA, cs.LG, cs.NA** | **Updated: 2025-08-01**

**Keywords:** 矩阵分解, 机器学习, 数值线性代数, 综述, 应用

**Comment:** 

> **TL;DR:** 本文旨在对矩阵分解的概念、数学工具及其在机器学习中的应用进行自我包含的介绍。

**AI_Comments:** 本文作为一篇综述，旨在为读者提供矩阵分解的基础知识和在机器学习中的应用背景。其价值在于为初学者提供一个入门级的指导，但其局限性在于无法深入探讨所有高级或特定领域的矩阵分解理论。

<details>
  <summary>Details</summary>

**Motivation:** 矩阵分解已成为机器学习中的核心技术，尤其是在反向传播算法发展之后。本文旨在提供一个对矩阵分解技术及其应用的自我包含的介绍。

**Method:** 本文通过介绍数值线性代数和矩阵分析中的概念和数学工具，来引入矩阵分解技术及其应用。它是一篇综述性文章。

**Result:** 本文旨在提供一个自我包含的矩阵分解技术及其应用的介绍，但明确指出无法涵盖所有相关结果，例如在欧几里得空间、厄米特空间、希尔伯特空间和复数域中的分离分析。

**Conclusion:** 本文旨在对数值线性代数和矩阵分析中的概念和数学工具进行自我包含的介绍，以便无缝地引入矩阵分解技术及其应用。

> **ai_Abstract:** 本文是一篇综述性文章，旨在为读者提供一个关于矩阵分解的自我包含的介绍，包括其概念、数值线性代数和矩阵分析中的数学工具，以及其在机器学习中的应用。文章承认其范围有限，无法涵盖所有相关细节，并建议读者查阅更专业的线性代数文献。

> **摘要翻译:** 1954年，奥尔斯顿·S·豪斯霍尔德出版了《数值分析原理》，这是最早关于矩阵分解的现代论述之一，它偏爱（分块）LU分解——将矩阵分解为下三角矩阵和上三角矩阵的乘积。现在，矩阵分解已成为机器学习中的核心技术，这在很大程度上归因于拟合神经网络中反向传播算法的发展。本综述的唯一目的是对数值线性代数和矩阵分析中的概念和数学工具进行自我包含的介绍，以便在后续章节中无缝地引入矩阵分解技术及其应用。然而，我们清楚地认识到，鉴于讨论范围有限，我们无法涵盖所有关于矩阵分解的有用和有趣的结果，例如对欧几里得空间、厄米特空间、希尔伯特空间以及复数域中事物的单独分析。我们建议读者参考线性代数领域的文献以获取更详细的相关领域介绍。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [330] [Propagation of chaos in infinite horizon and numerical stability for stochastic McKean-Vlasov equations](https://arxiv.org/abs/2312.12699)
> *随机McKean-Vlasov方程的无穷时间混沌传播与数值稳定性*

*Zhuoqi Liu, Shuaibin Gao, Chenggui Yuan, Qian Guo* | **Category: math.NA, cs.NA** | **Updated: 2025-08-01**

**Keywords:** 随机McKean-Vlasov方程, 数值稳定性, 混沌传播, Euler-Maruyama方案, 粒子方法

**Comment:** 

> **TL;DR:** 本文通过随机粒子方法研究了随机McKean-Vlasov方程的数值稳定性，证明了长时间混沌传播，并在不同条件下分析了Euler-Maruyama方案（包括正向和后向）的均方和几乎必然指数稳定性。

**AI_Comments:** 本文在随机McKean-Vlasov方程的数值稳定性研究中取得了重要进展。其创新点在于提出了在超线性条件下后向EM方案的均方指数稳定性，且无需粒子破坏，这是一个新颖的结论。通过深入分析混沌传播和不同EM方案的稳定性，该研究为SMVEs的数值模拟提供了坚实的理论基础，对于反馈控制和随机意见动力学等实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过数值方法（随机粒子方法）解决随机McKean-Vlasov方程（SMVEs）的数值稳定性问题，确保数值解能够重现原始方程的稳定性。

**Method:** 本文采用随机粒子方法。首先，获得了均方意义上的长时间混沌传播和几乎必然意义上的无穷时间混沌传播。接着，在系数满足线性增长条件时，通过对经验测度的巧妙处理，分析了Euler-Maruyama (EM) 方案的均方和几乎必然指数稳定性。对于漂移和扩散中的状态变量均为超线性的情况，提出了后向EM方案的均方指数稳定性。此外，在扩散系数线性增长条件下，研究了后向EM方案的几乎必然稳定性。

**Result:** 1. 获得了均方意义上的长时间混沌传播和几乎必然意义上的无穷时间混沌传播。2. 在系数满足线性增长条件下，证明了Euler-Maruyama (EM) 方案的均方和几乎必然指数稳定性。3. 对于漂移和扩散中的状态变量均为超线性的情况，实现了后向EM方案的均方指数稳定性，且没有粒子破坏。4. 在扩散系数线性增长条件下，研究了后向EM方案的几乎必然稳定性。

**Conclusion:** 结合这些论断，数值解能够重现原始随机McKean-Vlasov方程的稳定性。

> **ai_Abstract:** 本文利用随机粒子方法深入研究了随机McKean-Vlasov方程的数值稳定性。研究内容涵盖了均方和几乎必然意义下的混沌传播，以及在不同系数条件（线性增长和超线性）下，Euler-Maruyama方案（包括正向和后向）的均方和几乎必然指数稳定性。特别是，文章提出了后向EM方案在超线性情况下的均方指数稳定性，且无需粒子破坏，这是一项新颖的发现。这些理论成果确保了数值解能够准确反映原始方程的稳定性，并通过具体示例验证了其重要性。

> **摘要翻译:** 本文通过随机粒子方法研究了随机McKean-Vlasov方程（SMVEs）的数值稳定性。首先，获得了均方意义上的长时间混沌传播，并证明了无穷时间上的几乎必然传播。接下来，当系数满足线性增长条件时，通过对经验测度的巧妙处理，展示了与相应相互作用粒子系统相关的Euler-Maruyama (EM) 方案的均方和几乎必然指数稳定性。然后，对于漂移和扩散中的状态变量均为超线性的情况，在没有粒子破坏的情况下，实现了相互作用系统后向EM方案的均方指数稳定性，这是一个新颖的结论。此外，在扩散系数线性增长条件下，研究了后向EM方案的几乎必然稳定性。结合这些论断使得数值解能够重现原始SMVEs的稳定性。提供了包括反馈控制问题和随机意见动力学模型在内的示例，以证明数值稳定性理论分析的重要性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [350] [A fully segregated and unconditionally stable IMEX scheme for dispersed multiphase flows](https://arxiv.org/abs/2504.02629)
> *适用于分散多相流的完全分离且无条件稳定的IMEX格式*

*Douglas Pacheco, Richard Schussnig* | **Category: math.NA, cs.NA** | **Updated: 2025-08-01**

**Keywords:** IMEX格式, 多相流, 分离方法, 无条件稳定性, 压力校正

**Comment:** 

> **TL;DR:** 本文提出了一种新的、完全分离且无条件稳定的IMEX格式，用于模拟分散多相流，该格式通过显式处理阻力项和半隐式处理对流与粘性项，有效避免了时间步长限制和定点迭代。

**AI_Comments:** 该论文的创新之处在于提出了一种完全分离的IMEX方案，它在保证无条件稳定性的同时，避免了传统解耦方法中常见的CFL时间步长限制和复杂的定点迭代，大大提高了计算效率和鲁棒性，对于多相流模拟领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多相流建模中，整体求解器计算成本高且难以实现。解耦方法虽然具有计算吸引力，但对耦合项（压力和阻力）的显式处理可能导致时间步长限制。因此，需要开发一种既能解耦又能避免时间步长限制的鲁棒方法。

**Method:** 本文提出了一种基于平均速度场不可压缩性的一阶压力校正方法，并结合了阻力项的显式处理。对流项和粘性项均采用半隐式处理，从而得到一个隐式-显式（IMEX）格式。该格式在每个时间步中仅包含线性标量输运方程和一个压力泊松问题。

**Result:** 所提出的IMEX格式非常鲁棒，不仅具有无条件能量稳定性，而且不需要任何类型的定点迭代。该方法在没有CFL类条件的情况下，严格证明了时间稳定性，并通过两相数值例子得到了证实。

**Conclusion:** 本文提出的完全分离且无条件稳定的IMEX格式为分散多相流的模拟提供了一种高效且鲁棒的计算方法，成功解决了传统方法中存在的计算成本高、时间步长限制和迭代收敛性问题。

> **ai_Abstract:** 本文针对分散多相流的模拟，提出了一种新型的一阶压力校正IMEX格式。该方法基于平均速度场的不可压缩性，显式处理阻力项，并对对流项和粘性项进行半隐式处理。该格式具有无条件能量稳定性，无需定点迭代，且在理论上证明了无CFL条件下的时间稳定性，并通过数值实例得到验证，显著提升了多相流模拟的鲁棒性和计算效率。

> **摘要翻译:** Euler-Euler或体积平均Navier-Stokes方程在各种应用中用于模拟具有两个或更多相互渗透相的系统。每种流体都遵循其自身的动量和质量方程，并且各相通常通过阻力力和共享压力进行耦合。因此，整体求解器可能非常昂贵且难以实现，所以解耦方法具有很大的计算吸引力。然而，拆分子问题需要显式处理耦合项（压力和阻力），这必须小心进行以避免时间步长限制。在此背景下，我们基于平均速度场的不可压缩性，结合阻力力的显式处理，推导了一种新的一阶压力校正方法。此外，对流项和粘性项都采用半隐式处理。这使我们得到一个隐式-显式（IMEX）方法，该方法不仅因其无条件能量稳定性而非常鲁棒，而且因为它不需要任何类型的定点迭代。每个时间步仅包含线性、标量输运方程和一个单一的压力泊松问题作为基本构建块。我们严格证明了在没有任何CFL类条件下的时间稳定性，并通过两相数值例子证实了该理论。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [370] [Global Energy Minimization for Simplex Mesh Optimization: A Radius Ratio Approach to Sliver Elimination](https://arxiv.org/abs/2507.01762)
> *单纯形网格优化的全局能量最小化：一种基于半径比的薄片单元消除方法*

*Dong Wang, Chunyu Chen, Huayi Wei* | **Category: math.NA, cs.NA, math.OC, 65N50, 65K10, 65F08** | **Updated: 2025-08-01**

**Keywords:** 单纯形网格, 薄片单元消除, 半径比, 能量最小化, 网格优化

**Comment:** 

> **TL;DR:** 本文提出一种基于半径比能量函数的新方法，用于优化单纯形网格质量，有效消除薄片单元，并通过对称正定矩阵作为预处理器显著加速优化过程。实验证明该方法在消除薄片单元和提高网格质量方面具有显著优势。

**AI_Comments:** 该论文提出了一种新颖的基于半径比能量函数的单纯形网格优化方法，其创新点在于能量函数的构建以及将对称正定矩阵用作预处理器以加速优化。这对于提高有限元分析和计算几何的准确性和效率具有重要意义。该方法通过全局能量最小化来消除薄片单元，可能比局部优化方法更鲁棒。

<details>
  <summary>Details</summary>

**Motivation:** 单纯形网格的质量对于有限元分析和计算几何中的数值模拟的稳定性和准确性至关重要。然而，3D单纯形网格中薄片单元的存在会严重影响模拟结果，因此需要一种有效的方法来消除薄片单元并提高网格质量。

**Method:** 提出了一种基于半径比能量函数的新方法来优化单纯形网格元素的质量。该方法的能量函数梯度可以分解为矩阵-向量积，经过处理后，该矩阵变为对称正定矩阵，并可作为预处理器显著加速优化过程。

**Result:** 该方法能有效消除薄片单元，从而提高网格质量。实验结果表明，该方法在消除薄片单元和提高网格质量方面具有显著优势。

**Conclusion:** 本文提出的基于半径比能量函数的全局能量最小化方法，能够有效消除单纯形网格中的薄片单元，显著提高网格质量，并通过优化算法提高了计算效率。

> **ai_Abstract:** 本文介绍了一种用于优化单纯形网格质量的创新方法，该方法基于半径比能量函数，旨在解决3D网格中薄片单元导致的数值模拟准确性问题。通过将能量函数梯度分解并利用对称正定矩阵作为预处理器，该方法不仅能有效消除薄片单元，提高网格质量，还能显著加速优化过程。实验结果证实了其在网格优化方面的显著优势。

> **摘要翻译:** 单纯形网格的质量对于有限元分析和计算几何中的数值模拟的稳定性和准确性至关重要。然而，3D单纯形网格中薄片单元的存在会严重影响结果。本文提出了一种基于半径比能量函数的新方法来优化单纯形网格元素的质量。该方法可以有效消除薄片单元，从而提高网格质量。所提出的能量函数的梯度可以分解为矩阵-向量积。经过少量处理后，该矩阵变为对称正定矩阵，并且这个对称正定矩阵可以作为预处理器，显著加速优化过程。实验结果表明，该方法在消除薄片单元和提高网格质量方面具有显著优势。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [395] [Dynamic analysis of free-free Timoshenko beams on elastic foundation under transverse transient ground deformation](https://arxiv.org/abs/2507.22850)
> *横向瞬态地面变形下弹性地基上自由-自由蒂莫申科梁的动力分析*

*Gersena Banushi* | **Category: math.NA, cs.NA** | **Updated: 2025-08-01**

**Keywords:** 蒂莫申科梁, 温克勒地基, 瞬态地面变形, 动力分析, 土-结构相互作用

**Comment:** Key words: buried Timoshenko beam, semi-analytical model, dynamic
  amplification, transient ground deformation (TGD), modal analysis

> **TL;DR:** 本研究提出了一种基于Winkler地基上Timoshenko梁理论的半解析模型，用于分析埋地直梁在横向瞬态地面变形下的动态响应，并验证了其准确性，揭示了振动特性和土-结构相互作用的动态放大效应。

**AI_Comments:** 该论文提出了一种创新的半解析模型，结合了Timoshenko梁理论和Winkler地基模型，有效解决了现有分析方法在考虑系统惯性和土-结构界面相对位移方面的不足。其通过闭合形式的解析解揭示了振动频谱的复杂特性，并验证了模型在实际工程案例中的准确性，对于提高埋地基础设施抗震设计和安全性评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有设计方法基于简化的分析模型，忽略了系统惯性和土-结构界面的相对位移，这对于需要精确动态分析的埋地大直径管道和隧道可能不适用。因此，需要一种更准确的动力分析方法。

**Method:** 本研究引入了一种基于Winkler地基上Timoshenko梁理论的新的半解析模型，用于分析埋地直梁在横向瞬态地面变形下的动态响应。通过闭合形式的解析解进行分析，并通过与有限元分析结果的比较验证了模型的有效性。

**Result:** 闭合形式的解析解揭示了振动频谱分为四个部分，由三个过渡频率分隔。在每个过渡频率处，振动模式的振荡特性发生变化，显著影响系统的动态响应。频率响应分析揭示了在接近系统基频的强制频率下，土-结构相互作用的动态放大效应。

**Conclusion:** 所提出的方法提供了一个稳健的分析框架，用于评估影响埋地梁动态行为的主要因素，从而更深入地理解系统在各种地面振动源下的响应。

> **ai_Abstract:** 本研究针对现有模型在分析埋地基础设施受瞬态地面变形（TGD）影响时的局限性，提出了一种基于Winkler地基上Timoshenko梁理论的半解析模型。该模型能够准确分析埋地直梁在横向TGD下的动态响应，并通过解析解揭示了振动频谱的四个分区和过渡频率对系统响应的影响。通过与有限元分析的对比，验证了模型的准确性，并发现土-结构相互作用在特定频率下存在动态放大效应，为评估埋地梁的动态行为提供了更深入的理解。

> **摘要翻译:** 地下基础设施，如管道和隧道，可能容易受到由地震和交通载荷等不同振动源引起的瞬态地面变形（TGD）的影响。当前的设计方法基于简单的分析模型，将土壤运动理想化为行进的正弦波，忽略了系统惯性和土-结构界面的相对位移。然而，这种假设对于需要精确动态分析的埋地大直径管道和隧道可能不适用。为了分析埋地直梁在横向TGD下的动态响应，本研究引入了一种基于Winkler地基上Timoshenko梁理论的新的半解析模型。闭合形式的解析解揭示了振动频谱分为四个部分，由三个过渡频率分隔。在每个过渡频率处，振动模式的振荡特性发生变化，显著影响系统的动态响应。为了验证所提出模型的有效性，本研究分析了一个埋地钢制输水管道在不同长度和运行条件下的横向TGD案例。将获得的解析解与有限元分析结果进行比较，结果显示两者之间具有极好的一致性。频率响应分析揭示了在接近系统基频的强制频率下，土-结构相互作用的动态放大效应。这些频率可能落在表征地震波的主导频率范围内，需要精确的动态分析。所提出的方法提供了一个稳健的分析框架，用于评估影响埋地梁动态行为的主要因素，从而更深入地理解系统在各种地面振动源下的响应。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='statap'></a>
## stat.AP 

### [96] [Predicting Formula 1 Race Outcomes: Decomposing the Roles of Drivers and Constructors through Linear Modeling](https://arxiv.org/abs/2508.00200)
> *预测一级方程式赛车结果：通过线性建模分解车手和制造商的角色*

*Saurabh Rane* | **Category: stat.AP** | **Updated: 2025-07-31**

**Keywords:** 一级方程式赛车, 性能分解, 车手影响, 制造商影响, 线性建模, RAPM

**Comment:** 26 pages, 12 figures, 9 tables

> **TL;DR:** 本研究通过扩展一种常规化的调整正负值（RAPM）方法，利用时间衰减岭回归和LOESS平滑，分解并量化了F1混合动力时代（2014-2024）中车手和制造商对比赛结果的独立影响，发现制造商解释了64%的比赛结果方差。

**AI_Comments:** 该论文的创新之处在于将体育分析中常用的RAPM方法引入到F1赛车的性能分析中，并结合时间衰减岭回归和LOESS平滑来处理时间序列数据。其重要性在于能够量化并分离车手和制造商的独立贡献，这对于F1团队的战略决策、车手评估以及车队建设具有实际价值。它克服了F1现有积分系统在评估个体贡献方面的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 一级方程式赛车（F1）的性能是赛车和车手能力的结合，但要分离车手和制造商的个体影响仍然具有挑战性。目前的F1积分系统模糊了车手和制造商的独立贡献，因此需要一个稳健的框架进行跨制造商的车手比较。

**Method:** 本研究扩展了常用于篮球和冰球的常规化调整正负值（RAPM）方法（Sill 2010），并采用时间衰减岭回归结合LOESS（Jacoby 2000）平滑来预测2014-2024年混合动力引擎时代的比赛结果。通过测量制造商和车手随时间变化的系数，量化了各自的独立影响。

**Result:** 结果显示，在混合动力引擎时代，制造商解释了比赛结果64.0%的方差。此外，制造商在基准化的与排名无关的队列（例如，前10名积分获得者）中的重要性增加，而在排位赛中的重要性降低。

**Conclusion:** 通过将性能分解为个体车手和制造商指标，本研究创建了一个强大的框架，用于一级方程式赛车中被积分系统所模糊的跨制造商的车手比较。这项工作增强了对车手和制造商对比赛成功贡献的理解，为F1中的战略决策提供了宝贵的见解。

> **ai_Abstract:** 本研究提出一种扩展的常规化调整正负值（RAPM）方法，结合时间衰减岭回归和LOESS平滑，用于量化F1混合动力时代（2014-2024）中车手和制造商对比赛结果的独立贡献。研究发现制造商解释了比赛结果64%的方差，并在特定情况下重要性有所不同。该方法提供了一个稳健的框架，用于进行跨制造商的车手比较，并为F1的战略决策提供有价值的见解。

> **摘要翻译:** 一级方程式赛车（Formula 1）的性能是赛车能力和车手能力的结合。虽然一场比赛或一个赛季可以告诉你赛车和车手共同表现如何，但要分离车手和制造商的个体影响仍然具有挑战性。本文扩展了一种常规化调整正负值（RAPM）方法（Sill 2010），该方法常用于篮球和冰球，以解析出个体车手和制造商的影响。它采用时间衰减岭回归结合LOESS（Jacoby 2000）平滑来预测混合动力引擎时代（2014-2024）的比赛结果。通过测量制造商和车手随时间变化的系数，我们测量了在此期间车手和制造商的相对个体影响。结果显示，在混合动力引擎时代，制造商解释了比赛结果64.0%的方差。此外，制造商在基准化的与排名无关的队列（例如，前10名积分获得者）中的重要性增加，而在排位赛中的重要性降低。通过将性能分解为个体车手和制造商指标，我们创建了一个强大的框架，用于一级方程式赛车中被积分系统所模糊的跨制造商的车手比较。我们的工作增强了对车手和制造商对比赛成功贡献的理解，为一级方程式赛车中的战略决策提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [108] [A Multivariate Space-Time Dynamic Model for Characterizing the Atmospheric Impacts Following the Mt Pinatubo Eruptio](https://arxiv.org/abs/2408.13392)
> *用于描述皮纳图博火山喷发后大气影响的多变量时空动态模型*

*Robert Garrett, Lyndsay Shand, J. Gabriel Huerta* | **Category: stat.AP** | **Updated: 2025-08-01**

**Keywords:** 多变量时空模型, 皮纳图博火山喷发, 大气影响, 动态线性模型, 平流层气溶胶注入

**Comment:** 

> **TL;DR:** 本文开发了一个多变量时空动态模型，用于描述1991年皮纳图博火山喷发对大气的复杂影响，该喷发可作为平流层气溶胶注入的天然类比。

**AI_Comments:** 该研究的创新之处在于开发了一种新颖的多变量时空动态线性模型，该模型包含用于时间变化基系数的VAR结构，并通过定制的MCMC进行估计。这种方法对于理解像火山喷发这样的大规模事件（可作为气候干预策略的自然类比）对大气的复杂、相互关联的响应至关重要。与传统的单变量方法相比，该模型能够表征多变量和动态影响，提供了更全面的分析。

<details>
  <summary>Details</summary>

**Motivation:** 1991年皮纳图博火山喷发导致大气中硫酸盐气溶胶大量增加，并引发全球温度变化，这可作为平流层气溶胶注入（一种拟议的太阳辐射修改方法）的自然类比。研究旨在描述皮纳图博火山喷发后大气影响的多变量和动态性质。

**Method:** 研究开发了一个多变量时空动态线性模型（DLM）。该模型使用一组灵活的基函数来模拟空间变化，其中基系数通过向量自回归（VAR）结构随时间变化。该模型在动态线性模型（DLM）框架下，并通过定制的MCMC方法进行估计。

**Result:** 该模型利用MERRA-2再分析数据，量化了皮纳图博火山喷发前后关键大气参数之间的关系，并强调了该多变量模型相对于单变量模型的优势。

**Conclusion:** 该模型能够有效地表征皮纳图博火山喷发后复杂的大气影响，并被证明优于单变量模型。

> **ai_Abstract:** 本文提出了一种新颖的多变量时空动态线性模型（DLM），用于表征1991年皮纳图博火山喷发对大气的复杂、时空变化的动态影响。该火山喷发被视为平流层气溶胶注入的自然类比。该模型通过基函数和具有VAR结构的时间变化系数来建模空间变化，并采用定制的MCMC方法进行估计。研究利用MERRA-2数据成功量化了火山喷发前后大气关键参数之间的关系，并证明了其在分析此类多方面事件时相对于单变量模型的优势。

> **摘要翻译:** 1991年6月皮纳图博火山喷发导致大气中硫酸盐气溶胶大量增加，吸收辐射并导致地表和平流层温度发生全球性变化。这种规模的火山喷发可以作为平流层气溶胶注入的自然类比，这是一种对抗气候变暖的拟议太阳辐射修改方法。此类事件的影响是多方面的且具有区域特异性。我们的目标是描述皮纳图博火山喷发后大气影响的多变量和动态性质。我们开发了一个多变量时空动态线性模型，以理解空间和时间变化的全面影响。具体来说，空间变化通过一组灵活的基函数进行建模，其中基系数允许通过向量自回归（VAR）结构随时间变化。这个新颖的模型被置于动态线性模型（DLM）框架中，并通过定制的MCMC方法进行估计。我们展示了该模型如何利用MERRA-2再分析数据量化皮纳图博火山喷发前后关键大气参数之间的关系，并强调了该模型相对于单变量模型的优势。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [114] [Assessing Racial Disparities in Healthcare Expenditures via Mediator Distribution Shifts](https://arxiv.org/abs/2504.21688)
> *评估医疗支出中的种族差异：通过中介变量分布变化*

*Xiaxian Ou, Xinwei He, David Benkeser, Razieh Nabi* | **Category: stat.AP, stat.ME, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 种族差异, 医疗支出, 中介变量, 分解分析, 机器学习

**Comment:** 

> **TL;DR:** 本研究开发了一个框架，通过分解中介变量分布变化来评估医疗支出中的种族差异，并使用先进的统计方法进行分析。

**AI_Comments:** 该论文的创新之处在于其分解种族差异的方法，即通过中介变量分布的变化来理解差异的驱动因素，而不是简单地将种族视为一个独立的解释变量。这种方法有助于更细致地理解差异的来源，并可能为政策干预提供更精确的指导。使用先进的统计学和机器学习工具来处理复杂的数据特性（如零膨胀和右偏）也增强了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 医疗支出中的种族差异已得到充分记录，但其根本驱动因素复杂且需要进一步调查。

**Method:** 本研究开发了一个框架，通过分解中介变量（如社会经济地位、保险可及性、健康行为或健康状况）的分布变化来分解医疗支出中的种族差异，而不是将种族本身视为可操纵的暴露。研究将差异定义为调整协变量后不同种族群体间结果分布的差异，并将总差异分解为两部分：一部分归因于中介变量分布的差异，另一部分是即使中介变量分布均衡后仍存在的残余部分。研究使用医疗支出调查小组数据进行分析，并采用基于影响函数技术和灵活机器学习工具（包括超学习器和为零膨胀、右偏支出数据设计的两部分模型）的渐近线性估计器，以确保有效推断。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究提出了一个新颖的框架，用于分解医疗支出中的种族差异。该框架通过分析社会经济地位、保险可及性等中介变量的分布变化来量化差异，而非直接将种族作为干预因素。研究将总差异分解为中介变量效应和残余效应两部分，并利用医疗支出调查小组数据，结合影响函数技术和机器学习方法（如超学习器和两部分模型）进行建模，旨在评估均衡中介变量后支出差异的潜在变化。

> **摘要翻译:** 医疗支出中的种族差异已被充分记录，但其根本驱动因素仍然复杂，需要进一步调查。本研究开发了一个框架，通过中介变量分布的变化来分解此类差异，而不是将种族本身视为可操纵的暴露。我们将差异定义为不同种族群体之间经过协变量调整后的结果分布差异，并将总差异分解为两个组成部分：一个归因于中介变量分布的差异，另一个是即使在这些分布均衡后仍将存在的残余部分。利用医疗支出调查小组数据，我们研究了如果社会经济地位、保险可及性、健康行为或健康状况等中介变量在不同种族群体中得到均衡，支出差异将持续或减少的程度。为了确保有效的推断，我们基于影响函数技术和灵活的机器学习工具，包括超学习器和专为零膨胀、右偏支出数据设计的两部分模型，推导了渐近线性估计器。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

<a id='q-finmf'></a>
## q-fin.MF 

### [119] [Volatility Modeling with Rough Paths: A Signature-Based Alternative to Classical Expansions](https://arxiv.org/abs/2507.23392)
> *粗糙路径波动率建模：一种基于签名的经典展开替代方法*

*Elisa Alòs, Òscar Burés, Rafael de Santiago, Josep Vives* | **Category: q-fin.MF, math.PR, 60L70, 60H10, 91G20, 91G60, 60G22** | **Updated: 2025-08-01**

**Keywords:** 波动率建模, 粗糙路径, 路径签名, 隐含波动率, 渐近展开

**Comment:** 

> **TL;DR:** 本文比较了两种隐含波动率曲面校准方法：基于Malliavin微积分的渐近展开法和基于粗糙路径理论路径签名的数驱动方法，结果表明基于签名的方法在模型独立性和适应性方面表现出色，尤其适用于粗糙或非马尔可夫特征的波动率。

**AI_Comments:** 该论文的创新之处在于将粗糙路径理论中的路径签名应用于波动率建模，提供了一种灵活且模型独立的替代方案，尤其适用于那些经典参数方法难以处理的复杂波动率动态（如粗糙Bergomi模型）。这为金融工程中的波动率校准提供了新的视角和工具，增强了模型的鲁棒性和适用性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在比较两种校准隐含波动率曲面的方法：一种是基于Malliavin微积分的二阶渐近展开法，另一种是基于粗糙路径理论路径签名的数驱动方法，以评估它们在不同波动率模型下的表现。

**Method:** 本文比较了两种方法：1. 通过Malliavin微积分推导的二阶渐近展开法，该方法在资产价格遵循Heston型随机波动率模型假设下，能提供高效准确的校准公式。2. 一种基于粗糙路径理论中路径签名的数驱动方法，该方法将波动率建模为主要随机过程签名的线性泛函，从而实现无需特定参数形式的灵活近似。

**Result:** 数值实验表明，当真实动态为Heston模型时，基于签名的方法达到了与渐近方法相当的校准精度。在资产遵循粗糙Bergomi波动率过程（超出渐近展开范围）的更通用设置中，签名方法也持续提供准确结果。

**Conclusion:** 研究结果强调了基于签名的校准方法在波动率表现出粗糙或非马尔可夫特征的环境中，具有模型独立性、鲁棒性和适应性。

> **ai_Abstract:** 本文比较了两种隐含波动率曲面校准方法：基于Malliavin微积分的渐近展开法和基于粗糙路径理论路径签名的数驱动方法。渐近法在Heston模型下高效准确，而签名法通过将波动率建模为路径签名的线性泛函，实现了灵活且无需特定参数形式的近似。数值实验表明，签名法在Heston模型下与渐近法精度相当，并且在更通用的粗糙Bergomi模型下仍能提供准确结果。这凸显了签名法在处理粗糙或非马尔可夫波动率时的模型独立性、鲁棒性和适应性。

> **摘要翻译:** 我们比较了两种校准隐含波动率曲面的方法：一种是通过Malliavin微积分推导的二阶渐近展开法，另一种是基于粗糙路径理论中路径签名的数驱动方法。前者由Alòs 等人（2015年）开发，在资产价格遵循Heston型随机波动率模型的假设下，能提供高效准确的校准公式。后者将波动率建模为主要随机过程签名的线性泛函，从而实现无需特定参数形式的灵活近似。
我们的数值实验表明，当真实动态为Heston模型时，基于签名的方法达到了与渐近方法相当的校准精度。随后，我们在资产遵循粗糙Bergomi波动率过程（一个超出渐近展开范围的机制）的更通用设置中测试了该模型，结果表明签名方法继续提供准确的结果。这些发现突出了基于签名的校准方法在波动率表现出粗糙或非马尔可夫特征的环境中的模型独立性、鲁棒性和适应性。

</details>

[⬆️ 返回分类顶部](#q-finmf) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [5] [Hybrid Quantum Classical Surrogate for Real Time Inverse Finite Element Modeling in Digital Twins](https://arxiv.org/abs/2508.00029)
> *数字孪生中实时逆有限元建模的混合量子经典代理*

*Azadeh Alavi, Sanduni Jayasinghe, Mojtaba Mahmoodian, Sam Mazaheri, John Thangarajah, Sujeeva Setunge* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 混合量子经典, 逆有限元建模, 数字孪生, 结构健康监测, 量子机器学习

**Comment:** Submitted to Scientific Report

> **TL;DR:** 提出了一种混合量子经典神经网络（QMLP），用于实时结构健康监测中的逆有限元建模，通过在桥梁上的实验证明其性能优于经典方法。

**AI_Comments:** 这篇论文的创新点在于提出了一个混合量子经典模型（QMLP）来解决数字孪生中实时逆有限元建模的计算挑战。它有效地结合了量子计算的潜力与经典神经网络的优势，为大规模结构健康监测提供了一条新的高效途径。其在桥梁应用中取得的显著性能提升，表明了量子增强方法在工程领域的实际应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 大规模土木结构（如桥梁、管道和海上平台）的故障会造成重大的经济和安全影响。尽管有限元（FE）建模广泛用于实时结构健康监测（SHM），但其高计算成本以及逆有限元分析（将低维传感器数据映射到高维位移或应力场）的复杂性带来了持续的挑战。

**Method:** 本文提出了一种混合量子经典多层感知器（QMLP）框架来解决上述问题。该方法通过对称正定（SPD）矩阵和多项式特征嵌入传感器数据，使其表示形式适合量子处理。随后，一个参数化量子电路（PQC）转换这些特征，并将所得的量子输出馈送到经典神经网络中进行最终推理，从而融合了量子能力与经典建模。

**Result:** 通过在桥梁上进行的广泛实验，QMLP的均方误差（MSE）为0.0000000000316，以巨大的优势超越了纯经典基线。

**Conclusion:** 这些发现证实了量子增强方法在实时结构健康监测（SHM）中的潜力，为构建更高效、可扩展的数字孪生系统奠定了基础，该系统能够近实时地鲁健地监测和诊断结构完整性。

> **ai_Abstract:** 本文提出了一种混合量子经典多层感知器（QMLP）框架，旨在解决实时结构健康监测（SHM）中逆有限元分析的高计算成本和复杂性问题。QMLP通过将传感器数据嵌入为量子处理友好的特征，并结合参数化量子电路和经典神经网络进行推理。实验结果表明，该方法在桥梁结构健康监测中取得了显著优于纯经典方法的性能，证明了量子增强方法在构建高效、可扩展数字孪生方面的潜力。

> **摘要翻译:** 大规模土木结构，如桥梁、管道和海上平台，对现代基础设施至关重要，意外故障可能导致重大的经济和安全影响。尽管有限元（FE）建模广泛用于实时结构健康监测（SHM），但其高计算成本以及逆有限元分析（其中低维传感器数据必须映射到高维位移或应力场）的复杂性带来了持续的挑战。在此，我们提出了一种混合量子经典多层感知器（QMLP）框架来解决这些问题，并促进数字孪生在各种结构应用中的快速更新。
我们的方法使用对称正定（SPD）矩阵和多项式特征嵌入传感器数据，产生一种非常适合量子处理的表示。参数化量子电路（PQC）转换这些特征，然后将所得的量子输出馈送到经典神经网络中进行最终推理。通过将量子能力与经典建模融合，QMLP在处理大规模逆有限元映射的同时保持了计算可行性。
通过在桥梁上进行的广泛实验，我们证明QMLP实现了0.0000000000316的均方误差（MSE），以巨大的优势超越了纯经典基线。这些发现证实了量子增强方法在实时SHM中的潜力，为更高效、可扩展的数字孪生系统奠定了基础，该系统能够近实时地鲁健地监测和诊断结构完整性。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [12] [Quantum-Informed Machine Learning for Chaotic Systems](https://arxiv.org/abs/2507.19861)
> *量子信息机器学习用于混沌系统*

*Maida Wang, Xiao Xue, Peter V. Coveney* | **Category: quant-ph, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 量子信息机器学习, 混沌系统, Koopman模型, 量子电路玻尔兹曼机, 动力系统

**Comment:** 33 pages, 4 figures

> **TL;DR:** 本文提出一种量子信息机器学习框架，利用量子电路玻尔兹曼机高效学习混沌系统的不变特性，并将其结合到Koopman自回归模型中，解决了长期预测挑战，显著提升了内存效率和预测性能。

**AI_Comments:** 这篇论文的创新点在于将量子机器学习的优势（特别是量子电路玻尔兹曼机在压缩复杂物理统计量方面的内存效率）与经典机器学习方法（Koopman模型）相结合，形成一种混合架构。这种方法不仅解决了混沌系统长期预测的挑战，还为在当前有噪声、可扩展性有限的近期量子硬件上实现实用化的动力系统学习提供了新颖且有前景的路径，克服了纯粹量子机器学习的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 学习混沌系统存在长期预测不稳定性和难以准确捕捉不变统计特性的挑战。尽管量子机器学习在捕获高维数据物理特性方面有潜力，但其部署受限于当前硬件噪声和可扩展性。

**Method:** 引入了一种量子信息机器学习框架，专门用于学习偏微分方程，并应用于混沌系统。该框架使用量子电路玻尔兹曼机学习混沌动力系统的不变特性，通过紧凑的可训练电路参数实现内存效率。随后，将生成的统计量子信息先验集成到基于Koopman的自回归模型中，以解决梯度消失或爆炸问题，同时保持长期统计保真度。

**Result:** 与原始仿真数据相比，数据存储需求减少了两个数量级以上。在Kuramoto-Sivashinsky方程、二维Kolmogorov流和湍流通道流三个代表性系统上，量子信息模型均优于没有量子先验的经典对应模型。

**Conclusion:** 这种混合架构为使用近期量子硬件学习动力系统提供了一条实用的途径。

> **ai_Abstract:** 本文提出了一种量子信息机器学习框架，旨在解决混沌系统学习中的固有挑战。该框架利用量子电路玻尔兹曼机高效捕捉混沌系统的不变统计特性，显著减少了数据存储需求。随后，将这些量子先验信息整合到基于Koopman的自回归模型中，以克服传统模型中的梯度问题并保持长期预测的统计准确性。实验结果表明，该混合模型在多个代表性混沌系统上均优于经典的非量子方法，为利用近期量子硬件学习动力系统提供了一条可行且实用的途径。

> **摘要翻译:** 学习混沌系统的行为仍然具有挑战性，因为长期预测的不稳定性以及难以准确捕捉不变统计特性。虽然量子机器学习为有效捕获高维数据中的物理特性提供了一条有前景的途径，但其实际部署受到当前硬件噪声和有限可扩展性的阻碍。在此，我们引入了一种量子信息机器学习框架，用于学习偏微分方程，并专注于混沌系统的应用。我们采用量子电路玻尔兹曼机来学习混沌动力系统的不变特性，通过用一组紧凑的可训练电路参数表示这些复杂的物理统计量，实现了显著的内存效率。与原始仿真数据相比，这种方法将数据存储需求减少了两个数量级以上。然后，将由此产生的统计量子信息先验融入基于Koopman的自回归模型中，以解决梯度消失或爆炸等问题，同时保持长期统计保真度。该框架在三个代表性系统上进行了评估：Kuramoto-Sivashinsky方程、二维Kolmogorov流和湍流通道流。在所有情况下，量子信息模型与没有量子先验的经典对应模型相比，都取得了卓越的性能。这种混合架构为使用近期量子硬件学习动力系统提供了一条实用的途径。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [23] [Dimension reduction with structure-aware quantum circuits for hybrid machine learning](https://arxiv.org/abs/2508.00048)
> *使用结构感知量子电路进行混合机器学习的降维*

*Ammar Daskin* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 量子电路, 降维, 混合机器学习, 张量网络, 数据压缩

**Comment:** Any comments are welcome! The simulation code is provided at
  https://github.com/adaskin/structure-aware-circuits

> **TL;DR:** 本文提出了一种使用结构感知量子电路进行数据降维的方法，该电路能够对数据集进行指数级压缩，并与经典神经网络结合构建混合机器学习模型，实验证明其能有效压缩数据并提供k秩近似。

**AI_Comments:** 该论文的创新点在于提出了将结构感知量子电路应用于数据降维，并将其集成到混合机器学习模型中。通过利用量子计算的特性实现数据的指数级压缩，这为处理大规模数据集和减少模型参数提供了一种有前景的途径。其重要性在于探索了量子机器学习在实际应用中的潜力，特别是在数据预处理和特征工程方面。

<details>
  <summary>Details</summary>

**Motivation:** 通过Schmidt分解和SVD的类比，向量的k秩近似可以保留最重要的部分并去除噪声。本文旨在利用量子电路实现数据压缩，以潜在地减少训练大型模型的学习参数数量，并实现输入数据的指数级压缩。

**Method:** 研究人员设计了基于值k（从训练样本均值向量的张量网络分解确定）的量子电路，以近似整个数据集的降维表示。然后，将该量子电路与经典神经网络头部结合，构建了一个混合机器学习模型。该量子电路将$2^n$维向量输出为$n$维概率向量，从而实现指数级压缩。

**Result:** 实验结果证实，所提出的量子电路能够成功压缩数据，为经典处理组件提供有效的k秩近似。

**Conclusion:** 本文提出的结构感知量子电路能够有效地对数据进行降维和指数级压缩，并能成功地作为混合机器学习模型的一部分。

> **ai_Abstract:** 本文提出了一种基于结构感知量子电路的混合机器学习降维方法。该方法利用Schmidt分解的原理，设计了能够对数据集进行指数级压缩的量子电路。该电路将$2^n$维输入向量转换为$n$维概率向量，从而显著减少数据维度和潜在的模型参数。结合经典神经网络头部，构建的混合模型在scikit-learn数据集上的实验表明，量子电路能够有效压缩数据并提供高质量的k秩近似。

> **摘要翻译:** 一个向量的施密特分解可以理解为向量形式的奇异值分解（SVD）。一个向量可以通过对所有子系统递归应用SVD的施密特分解，写成两个二维向量张量积的线性组合。给定一个表示为张量积线性组合的向量，仅使用k个主项即可得到该向量的k秩近似。因此，以这种简化形式书写向量可以保留向量中最重要的部分，同时去除其中的小噪声，类似于基于SVD的去噪。
在本文中，我们展示了基于值k（由训练样本平均向量的张量网络分解确定）设计的量子电路可以近似整个数据集的简化形式表示。然后，我们采用这种电路结构与经典的神经网络头部来构建一个混合机器学习模型。由于量子电路对于一个$2^n$维向量的输出是一个$n$维概率向量，这提供了输入数据的指数级压缩，并可能减少训练大型模型的学习参数数量。我们使用Python scikit-learn模块中提供的数据集进行实验。结果证实，量子电路能够成功压缩数据，为经典处理组件提供有效的k秩近似。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [49] [Are controlled unitaries helpful?](https://arxiv.org/abs/2508.00055)
> *受控幺正矩阵有用吗？*

*Ewin Tang, John Wright* | **Category: quant-ph, cs.CC, cs.DS** | **Updated: 2025-07-31**

**Keywords:** 受控幺正矩阵, 去控制, 量子电路, 全局相位, 伪随机性

**Comment:** 18 pages

> **TL;DR:** 本文表明，对于一大类量子问题，访问受控幺正矩阵 (cU) 并没有帮助，因为使用 cU 的量子电路可以被“去控制”为只使用 U 的电路，仅增加少量时间和空间开销，尤其是在不关心全局相位信息的情况下。cU 的唯一用处在于它包含了 U 的全局相位信息。

**AI_Comments:** 本文的重要创新在于系统地证明并推广了“去控制”量子电路的方法，有效地反驳了关于受控幺正矩阵在许多量子算法中不可或缺的普遍观点。它揭示了 cU 的核心价值仅在于其全局相位信息，从而可能简化某些量子算法的设计和分析。这项工作对于理解量子计算中的资源效率和复杂性具有重要意义，有助于避免不必要的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 许多量子算法需要访问受控幺正矩阵 (cU)。本文旨在反驳文献中可能导致人们认为去控制是不可能的负面结果，通过推广和研究去控制过程的含义来普及这一结果。

**Method:** 本文展示了如何将一个使用 cU 和 cU† 并输出 |ψ(U)⟩ 的量子电路“去控制”为一个只使用 U 和 U† 并输出 |ψ(φU)⟩ 的电路，其中 φ 是一个均匀随机相位，且只增加少量时间和空间开销。

**Result:** 1. 访问 cU 对于一大类量子问题没有帮助。
2. 一个使用 cU 和 cU† 的量子电路可以被“去控制”为一个只使用 U 和 U† 的电路，输出一个带有均匀随机相位的状态 |ψ(φU)⟩，且只增加少量时间和空间开销。
3. 当只关心输出状态的全局相位时，去控制电路就足够了。
4. cU 只有在包含 U 的全局相位信息时才有用。
5. 作为一个应用，提供了一个简单的证明，证明了在访问 U、U†、cU 和 cU† 的情况下，存在伪随机幺正系综。

**Conclusion:** 对于许多量子问题，受控幺正矩阵 (cU) 通常没有帮助，因为其效用主要源于包含全局相位信息。使用 cU 的电路可以被有效地去控制。

> **ai_Abstract:** 本文探讨了受控幺正矩阵 (cU) 在量子算法中的作用。研究表明，对于一大类量子问题，访问 cU 并没有额外帮助，因为使用 cU 的量子电路可以被高效地“去控制”为只使用非受控幺正矩阵 U 的电路，且只引入少量时间和空间开销。这一发现的关键在于，cU 的唯一实际作用是提供了关于 U 的全局相位信息。文章旨在纠正关于去控制可行性的误解，并通过一个简单的应用（证明伪随机幺正系综的存在）来进一步说明其重要性。

> **摘要翻译:** 许多量子算法为了计算幺正矩阵 U 的某些性质，不仅需要访问 U，还需要访问受控幺正矩阵 cU。我们证明了，对于一大类量子问题，访问 cU 并没有帮助。对于一个使用 cU 和 cU† 并输出 |ψ(U)⟩ 的量子电路，我们展示了如何将该电路“去控制”为一个只使用 U 和 U† 并输出 |ψ(φU)⟩ 的电路，其中 φ 是一个均匀随机相位，且只增加少量时间和空间开销。当我们只关心输出状态在 U 的全局相位上的情况时，去控制电路就足够了。换句话说，cU 只有在包含 U 的全局相位信息时才有用。
我们的一个过程版本在 Sheridan, Maslov, and Mosca [SMM09] 的附录中有所描述。我们这项工作的目标是通过推广和研究其含义来普及这一结果，以反驳文献中可能导致人们认为去控制是不可能的负面结果。作为一个应用，我们为在访问 U、U†、cU 和 cU† 的情况下存在伪随机幺正系综提供了一个简单的证明。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [84] [Polynomial time constructive decision algorithm for multivariable quantum signal processing](https://arxiv.org/abs/2410.02332)
> *多变量量子信号处理的多项式时间构造性判定算法*

*Yuki Ito, Hitomi Mori, Kazuki Sakamoto, Keisuke Fujii* | **Category: quant-ph, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 多变量量子信号处理, 判定算法, 多项式时间, 充要条件, 量子算法

**Comment:** 20 pages, 2 figures

> **TL;DR:** 本文提出了一种多项式时间运行的经典算法，用于判定一对多变量劳伦特多项式是否能通过多变量量子信号处理（M-QSP）实现，并提供构造性参数选择方法，解决了M-QSP可构造性的充要条件问题。

**AI_Comments:** 这篇论文的创新点在于提出了一个经典算法，首次解决了M-QSP能够实现何种多项式的充要条件问题，并且该算法具有多项式时间复杂度，同时还提供了参数的构造性选择方法，这对于M-QSP的理论完善和实际应用都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多变量量子信号处理（M-QSP）能够高效地执行多变量多项式变换，但目前尚不清楚M-QSP可以构造何种类型多项式的充要条件。

**Method:** 本文提出了一种经典的、多项式时间复杂度的算法。该算法能够判定一对给定的多变量劳伦特多项式是否能通过M-QSP实现，并返回真或假，其中返回真即为充要条件。此外，该算法还提供了一种选择M-QSP实现所需参数的构造性方法。

**Result:** 该算法能够确定多变量劳伦特多项式是否可由M-QSP实现，并返回充要条件。算法在变量数和信号算子数上具有多项式时间复杂度。它还提供了一种构造性方法来选择M-QSP的必要参数。

**Conclusion:** 这些发现为识别M-QSP的实际应用提供了有价值的见解。

> **ai_Abstract:** 本文针对多变量量子信号处理（M-QSP）中多项式可构造性的充要条件未知问题，提出了一种多项式时间运行的经典决策算法。该算法能够判定一对多变量劳伦特多项式是否可由M-QSP实现，并明确给出其充要条件。此外，该算法还提供了一种构造性方法来选择M-QSP实现所需的参数，为M-QSP的实际应用提供了重要基础。

> **摘要翻译:** 量子信号处理（QSP）和量子奇异值变换（QSVT）为理解许多量子算法（包括因式分解、矩阵求逆和哈密顿量模拟）提供了一个统一的框架。作为QSP的多变量版本，多变量量子信号处理（M-QSP）被提出。M-QSP将对应于每个变量的信号算子与信号处理算子交错，这提供了一种执行多变量多项式变换的有效方法。然而，M-QSP可以构造何种类型多项式的充要条件尚不清楚。在本文中，我们提出了一种经典算法来确定给定的一对多变量劳伦特多项式是否可以通过M-QSP实现，该算法返回真或假。作为该算法最重要的特性之一，它返回真就是充要条件。所提出的经典算法在变量数和信号算子数上以多项式时间运行。我们的算法还提供了一种构造性方法来选择实现M-QSP所需的必要参数。这些发现为识别M-QSP的实际应用提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [133] [Ancilla-free Quantum Adder with Sublinear Depth](https://arxiv.org/abs/2501.16802)
> *无辅助量子加法器，具有次线性深度*

*Maxime Remaud, Vivien Vandaele* | **Category: quant-ph, cs.DM** | **Updated: 2025-08-01**

**Keywords:** 量子加法器, 次线性深度, 无辅助比特, 可逆逻辑, Toffoli门

**Comment:** V2: Add a section with incrementor and addition of a constant

> **TL;DR:** 首个无需辅助量子比特的精确量子加法器，具有次线性深度，通过优化CNOT和Toffoli梯形算子实现。

**AI_Comments:** 本文的创新在于成功设计出一种无需辅助量子比特且具有次线性深度的量子加法器，这在量子计算中显著提高了资源效率和计算速度。通过对CNOT和Toffoli梯形算子的巧妙优化以及对经典可逆逻辑的利用，解决了传统量子加法器中辅助比特需求和深度较大的问题，为未来高效量子算法的实现奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 旨在设计一种无需辅助量子比特且具有次线性深度的精确量子加法器。

**Method:** 基于经典可逆逻辑，通过低深度实现CNOT和Toffoli梯形算子。将n个CNOT门的梯形结构替换为$O(\\log n)$深度的电路，将n个Toffoli门的梯形结构替换为$O(\\log^2 n)$深度的电路。结合这些元素设计量子加法器，并借鉴了条件清洁辅助比特的技术。

**Result:** 实现了首个无需辅助量子比特的次线性深度精确量子加法器，能够以$O(\\log^2 n)$的深度执行两个n比特数的加法，仅使用经典可逆逻辑门（Toffoli、CNOT和X门）。还提出了用于量子寄存器增量和加常数的新构造。

**Conclusion:** 本文成功提出了一种无需辅助比特且具有次线性深度的新型量子加法器，在资源效率和速度方面优于以往的设计。

> **ai_Abstract:** 本文提出了一种新颖的、无辅助量子比特的精确量子加法器，其深度为次线性，能够以$O(\\log^2 n)$的深度执行n比特数的加法。该构造完全基于经典可逆逻辑，并通过优化CNOT和Toffoli梯形算子的低深度实现来完成，其中CNOT梯形结构被替换为$O(\\log n)$深度的电路，Toffoli梯形结构被替换为$O(\\log^2 n)$深度的电路。此外，文章还介绍了量子寄存器增量和加常数的新构造。

> **摘要翻译:** 我们提出了第一个具有次线性深度且无需辅助量子比特的精确量子加法器。我们的构造仅基于经典可逆逻辑，并采用低深度实现CNOT梯形算子和Toffoli梯形算子，这是执行波纹进位加法的两个关键组件。具体来说，我们证明了任何由n个CNOT门组成的梯形结构都可以被一个深度为$O(\\log n)$的CNOT电路替换，同时保持线性数量的门。然后我们将这种构造推广到Toffoli门，并证明任何由n个Toffoli门组成的梯形结构都可以被一个深度为$O(\\log^2 n)$的电路替换，同时使用线性对数数量的门。这建立在Nie等人和Khattar和Gidney关于条件清洁辅助比特技术的最新工作之上。通过结合这两个关键元素，我们提出了一种设计量子加法器的新颖方法，该方法可以在$O(\\log^2 n)$的深度下执行两个n比特数的加法，无需使用任何辅助比特，并且仅使用经典可逆逻辑（Toffoli、CNOT和X门）。我们还提出了用于量子寄存器增量和加常数的新构造。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [172] [Weak Values as Geometric Lenses: Deformations of Hilbert Space and the Emergence of superoscillations](https://arxiv.org/abs/2508.00023)
> *弱值作为几何透镜：希尔伯特空间的形变与超振荡的出现*

*Mirco A. Mannucci* | **Category: quant-ph, cs.CE** | **Updated: 2025-07-28**

**Keywords:** 弱值, 超振荡, 希尔伯特空间, 几何形变, 量子测量

**Comment:** 12 pages, 1 figure

> **TL;DR:** 本文通过无指针推导，揭示弱值是希尔伯特空间几何结构的形变体现，从而解释了超振荡的自然出现，并将其与广义瑞利商和量子态的射影几何联系起来。

**AI_Comments:** 本文创新性地从希尔伯特空间几何形变的角度解释了弱值和超振荡的内在联系，提供了一种新的、统一的理论视角。通过无指针推导和将弱值视为几何形变比率的视角，深化了对量子测量基础和信号处理中超振荡现象的理解。

<details>
  <summary>Details</summary>

**Motivation:** 弱测量形式在测量理论、量子基础和信号处理之间建立了深刻联系。本文旨在发展一种无指针的超振荡推导，并证明超振荡是弱值几何结构的自然和必然结果。

**Method:** 发展了一种无指针的超振荡推导。将弱值理解为几何形变的比率，量化可观测物如何相对于标准内积来变换希尔伯特空间的结构。将弱值形式化为变形的半双线性形式与标准形式的比较，并探讨其与广义瑞利商和量子态射影几何的深层联系。

**Result:** 证明了超振荡是弱值基础几何结构的自然和必然结果。弱值被理解为几何形变的比率，它使量子态的局部结构扭曲，产生远超全局傅里叶带宽的振荡。统一了弱值和超振荡，将其视为单一几何原理的两个方面。

**Conclusion:** 弱值和超振荡是单一底层几何原理的两个方面，弱值可以被理解为希尔伯特空间几何形变的比率，这种形变导致了超振荡的出现。

> **ai_Abstract:** 本文通过发展一种无指针的超振荡推导，揭示了超振荡是弱值所基于的几何结构的自然结果。作者提出弱值可以被理解为希尔伯特空间几何形变的比率，这种形变如同概念性透镜，扭曲量子态的局部结构，从而产生超带宽振荡。该研究将弱值解释为变形半双线性形式与标准形式的比较，并探讨了其与广义瑞利商及量子态射影几何的联系，最终将弱值和超振荡统一于单一的几何原理之下。

> **摘要翻译:** 量子力学中的弱测量形式揭示了测量理论、量子基础和信号处理之间深刻的联系。在本文中，我们发展了一种无指针的超振荡推导，证明它们是弱值底层几何结构的自然和必然结果。我们认为弱值最好被理解为几何形变的比率，它量化了一个可观测物相对于标准内积如何变换希尔伯特空间的结构。这种形变充当了一个概念性透镜，扭曲了量子态的局部结构，从而产生了远超全局傅里叶带宽的振荡。我们通过将弱值解释为变形的半双线性形式与标准形式之间的比较来形式化这一点，并探讨了它与广义瑞利商和量子态射影几何的深层联系。这种视角将弱值和超振荡统一为单一底层几何原理的两个方面。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [272] [Lattice Surgery Compilation Beyond the Surface Code](https://arxiv.org/abs/2504.10591)
> *超越表面码的格点手术编译*

*Laura S. Herzog, Lucas Berent, Aleksander Kubica, Robert Wille* | **Category: quant-ph, cs.ET** | **Updated: 2025-08-01**

**Keywords:** 格点手术, 拓扑码, 量子编译, 颜色码, 量子计算

**Comment:** 12 pages, 11 figures

> **TL;DR:** 本文将格点手术编译扩展到表面码之外的拓扑码，引入了代码基板概念，并将编译任务重构为映射和路由问题，并对颜色码进行了数值模拟。

**AI_Comments:** 这项工作的创新之处在于将格点手术编译的范围扩展到表面码之外的拓扑码，这对于实现大规模容错量子计算具有重要意义。引入“代码基板”的概念和将编译任务抽象为宏观路由问题，提供了一个更通用的框架来处理不同拓扑码的编译挑战。通过对颜色码的数值模拟，验证了其方法的有效性，并揭示了设计选择对电路性能的影响。

<details>
  <summary>Details</summary>

**Motivation:** 大规模容错量子计算需要将逻辑电路编译成针对特定架构的物理操作。现有工作主要集中在表面码和格点手术方案，但本文旨在拓宽范围，考虑表面码之外的拓扑码的格点手术编译。

**Method:** 本文首先定义了代码基板（一种实现拓扑码和格点手术的蓝图）。然后，从微观细节中抽象出来，将编译任务重新表述为宏观路由图上的映射和路由问题，并可能受到基板特定约束。研究了特定的基板和代码，包括颜色码和折叠表面码，并提供了详细的微观结构。

**Result:** 对于颜色码，本文进行了数值模拟，分析了微观和宏观层面的设计选择如何影响编译后的逻辑CNOT+T电路的深度。

**Conclusion:** 本文通过引入代码基板概念并将编译任务重新表述为映射和路由问题，成功地将格点手术编译的范围扩展到了表面码之外的拓扑码，并通过颜色码的数值模拟展示了设计选择对电路深度的影响。

> **ai_Abstract:** 本文将格点手术编译方法从传统的表面码扩展到更广泛的拓扑码。研究人员引入了“代码基板”的概念作为拓扑码和格点手术的实现蓝图，并将复杂的编译过程抽象为宏观路由图上的映射与路由问题。文章探讨了包括颜色码和折叠表面码在内的具体代码，并对颜色码进行了数值模拟，以分析不同设计选择对编译后逻辑CNOT+T电路深度的影响。研究结果为超越表面码的量子计算编译提供了新的视角和方法。

> **摘要翻译:** 大规模容错量子计算需要将逻辑电路编译成针对给定架构的物理操作。之前解决这一挑战的工作大多集中在表面码和格点手术方案。在这项工作中，我们通过考虑表面码之外的拓扑码的格点手术编译来拓宽范围。我们首先定义了一个代码基板——一个用于实现拓扑码和格点手术的蓝图。然后，我们从微观细节中抽象出来，将编译任务重新表述为宏观路由图上的映射和路由问题，这可能受到基板特定约束。我们探索了特定的基板和代码，包括颜色码和折叠表面码，并提供了详细的微观结构。对于颜色码，我们提供了数值模拟，分析了微观和宏观层面的设计选择如何影响编译后的逻辑CNOT+T电路的深度。一个开源代码可在GitHub上获取：https://github.com/cda-tum/mqt-qecc。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [357] [Embedding-Aware Quantum-Classical SVMs for Scalable Quantum Machine Learning](https://arxiv.org/abs/2508.00024)
> *嵌入式感知量子-经典支持向量机，用于可扩展量子机器学习*

*Sebastián Andrés Cajas Ordóñez, Luis Fernando Torres Torres, Mario Bifulco, Carlos Andrés Durán, Cristian Bosch, Ricardo Simón Carbajo* | **Category: quant-ph, cs.AI, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 量子机器学习, 支持向量机, Vision Transformer, 量子优势, 嵌入式学习

**Comment:** 

> **TL;DR:** 该研究提出了一种结合ViT嵌入的嵌入式感知量子-经典SVM管道，以解决量子支持向量机的可扩展性问题，并在Fashion-MNIST和MNIST数据集上实现了显著的精度提升，表明量子优势的关键在于嵌入选择。

**AI_Comments:** 这项研究的创新之处在于提出了一种将现代深度学习架构（如Vision Transformer）与量子机器学习相结合的实用方法，并通过实验证明了嵌入选择对实现量子优势的关键作用。它为解决量子机器学习的可扩展性挑战提供了一个有前景的方向，特别强调了Transformer注意力机制与量子特征空间的协同潜力。

<details>
  <summary>Details</summary>

**Motivation:** 量子支持向量机面临高维量子态和硬件限制导致的可扩展性挑战。

**Method:** 作者提出了一种嵌入式感知量子-经典管道，该管道将类别平衡的k均值蒸馏与预训练的Vision Transformer (ViT) 嵌入相结合，并使用cuTensorNet进行16量子比特张量网络模拟。

**Result:** ViT嵌入独特地实现了量子优势，在Fashion-MNIST上比经典SVMs的准确率提高了8.02%，在MNIST上提高了4.42%，而CNN特征则表现出性能下降。研究首次系统性地证明了量子核优势关键取决于嵌入选择，揭示了Transformer注意力与量子特征空间之间的基本协同作用。

**Conclusion:** 这项研究为利用现代神经网络架构实现可扩展量子机器学习提供了一条实用的途径。

> **ai_Abstract:** 本论文提出了一种嵌入式感知的量子-经典支持向量机(SVM)管道，旨在解决量子SVM的可扩展性问题。该方法结合了类别平衡的k均值蒸馏和预训练的Vision Transformer (ViT) 嵌入。研究发现，ViT嵌入能够独特地带来量子优势，在Fashion-MNIST和MNIST数据集上分别比经典SVM提高了8.02%和4.42%的准确率，而使用CNN特征则表现出性能下降。通过16量子比特张量网络模拟，研究首次证明了量子核优势与嵌入选择密切相关，揭示了Transformer注意力和量子特征空间之间的协同作用，为可扩展量子机器学习提供了实用路径。

> **摘要翻译:** 量子支持向量机由于高维量子态和硬件限制面临可扩展性挑战。我们提出了一种嵌入式感知量子-经典管道，该管道将类别平衡的k均值蒸馏与预训练的Vision Transformer嵌入相结合。我们的关键发现是：ViT嵌入独特地实现了量子优势，在Fashion-MNIST上比经典支持向量机实现了高达8.02%的准确率提升，在MNIST上实现了4.42%的提升，而CNN特征则表现出性能下降。通过cuTensorNet进行的16量子比特张量网络模拟，我们提供了第一个系统性证据，表明量子核优势关键取决于嵌入选择，揭示了Transformer注意力与量子特征空间之间的基本协同作用。这为利用现代神经网络架构实现可扩展量子机器学习提供了一条实用的途径。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [649] [Quantum Generative Modeling using Parameterized Quantum Circuits](https://arxiv.org/abs/2303.16955)
> *使用参数化量子电路的量子生成建模*

*Soumyadip Sarkar* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 量子生成模型, 参数化量子电路, 玻尔兹曼机, KL散度, 梯度优化

**Comment:** 

> **TL;DR:** 本文展示了一个3量子比特量子电路玻尔兹曼机，通过KL散度损失和参数移位梯度优化，成功学习并重现了3比特高斯分布。

**AI_Comments:** 本文通过一个具体的3量子比特量子电路玻尔兹曼机的实现，展示了量子生成模型在学习和重现概率分布方面的潜力。其创新点在于结合了KL散度损失和参数移位梯度优化，并在小规模系统上验证了其有效性。虽然目前仅限于小规模演示，但其结果为未来大规模量子生成学习的探索奠定了基础，并对量子优势的讨论提供了初步的实验依据。

<details>
  <summary>Details</summary>

**Motivation:** 量子生成模型利用量子力学的固有概率性质来学习和重现复杂的概率分布。

**Method:** 本文实现了一个3量子比特量子电路玻尔兹曼机，用于建模3比特高斯分布。该模型使用Kullback-Leibler (KL) 散度作为损失函数，并采用参数移位梯度优化方法进行训练。变分量子电路由多层参数化旋转门和纠缠门组成，旨在使玻尔兹曼规则的输出分布与目标分布匹配。研究详细阐述了模型分布的数学公式、KL散度成本函数和参数移位规则。

**Result:** 在态矢量模拟器上的训练结果显示，KL散度被最小化到接近零，且最终生成的分布与目标概率定量对齐。

**Conclusion:** 研究结果证明了小规模量子生成学习的可行性，并提供了关于量子电路模型训练动力学的见解。文章还讨论了可扩展性和量子优势的含义。

> **ai_Abstract:** 本文介绍了一种使用参数化量子电路实现量子生成模型的方法。研究人员构建了一个3量子比特的量子电路玻尔兹曼机，并利用KL散度损失和参数移位梯度优化，成功地学习并生成了一个3比特高斯分布。实验结果表明，该模型能够将KL散度降至接近零，生成的分布与目标分布高度吻合，证明了小规模量子生成学习的可行性，并提供了关于其训练动力学的宝贵见解。

> **摘要翻译:** 量子生成模型利用量子力学的固有概率性质来学习和重现复杂的概率分布。在本文中，我们展示了一个3量子比特量子电路玻尔兹曼机的实现，该机器通过使用Kullback-Leibler (KL) 散度损失和参数移位梯度优化，训练用于建模一个3比特高斯分布。变分量子电路由多层参数化旋转门和纠缠门组成，并经过优化，使玻尔兹曼规则的输出分布与目标分布紧密匹配。我们详细阐述了模型分布的数学公式、KL散度成本函数以及用于梯度评估的参数移位规则。在态矢量模拟器上的训练结果表明，KL散度被最小化到接近零，并且最终生成的分布与目标概率定量对齐。我们分析了收敛行为，并讨论了可扩展性和量子优势的含义。我们的结果证明了小规模量子生成学习的可行性，并为量子电路模型的训练动力学提供了见解。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [702] [Quantum Semi-Random Forests for Qubit-Efficient Recommender Systems](https://arxiv.org/abs/2508.00027)
> *用于量子比特高效推荐系统的量子半随机森林*

*Azadeh Alavi, Fatemeh Kouchmeshki, Abdolrahman Alavi, Yongli Ren, Jiayang Niu* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 量子推荐系统, 量子半随机森林, 量子比特效率, 混合机器学习, QAOA

**Comment:** Submitted to IEEE Quantum AI Conference (QAI 2025), awaiting peer
  review

> **TL;DR:** 该研究提出了一种三阶段混合量子机器学习算法，通过压缩标签、优化特征选择和使用仅需5个量子比特的量子半随机森林，实现了量子比特高效的推荐系统，性能与现有最佳方法相当。

**AI_Comments:** 这项工作具有重要的创新性，它通过混合经典-量子方法显著降低了量子推荐系统所需的量子比特数量，使其更接近当前NISQ设备的实际能力。其将高维稀疏数据压缩、经典优化与量子机器学习相结合的策略，为在资源受限的量子硬件上实现复杂应用提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现代推荐系统使用数百个稀疏语义标签描述每个项目，但大多数量子管道仍为每个标签分配一个量子比特，这导致所需的量子比特数量远超一百个，超出了当前噪声中尺度量子（NISQ）设备的范围，并容易产生深度且误差放大的电路。

**Method:** 该方法是一种三阶段混合机器学习算法。首先，利用SVD sketching和k-means学习一个1000个原子的字典（保留>97%方差）来压缩标签配置文件。其次，通过深度为3的QAOA解决一个2020 QUBO问题，以在固定的量子比特预算下选择5个原子进行特征选择。最后，使用仅基于5个量子比特构建的量子半随机森林（QsRF）对推荐进行评分。

**Result:** 该方法在ICM-150/500数据集上，使用这些编码训练的100棵树的QsRF达到了与全特征基线相当的性能，并且仅使用了5个量子比特，显著降低了量子资源需求。

**Conclusion:** 该研究成功地通过一种创新的三阶段混合算法，解决了量子推荐系统对大量量子比特的需求问题，实现了在有限量子比特（5个）下与现有先进方法相似的性能，为NISQ设备上的实用量子推荐系统铺平了道路。

> **ai_Abstract:** 该论文提出了一种用于量子比特高效推荐系统的三阶段混合量子机器学习算法。针对现有量子推荐系统对大量量子比特的需求问题，该方法通过SVD sketching和k-means进行标签压缩，利用QAOA进行特征选择，并构建了一个仅需5个量子比特的量子半随机森林（QsRF）进行推荐评分。实验结果表明，该方法在ICM-150/500数据集上达到了与现有最先进方法相当的性能。

> **摘要翻译:** 现代推荐系统用数百个稀疏语义标签描述每个项目，但大多数量子管道仍然为每个标签映射一个量子比特，这要求远超一百个量子比特，远远超出了当前噪声中尺度量子（NISQ）设备的范围，并且容易产生深度、误差放大的电路。我们通过一种三阶段混合机器学习算法弥补了这一差距，该算法压缩标签配置文件，在固定量子比特预算下通过QAOA优化特征选择，并使用仅基于五个量子比特构建的量子半随机森林（QsRF）对推荐进行评分，同时其性能与最先进的方法相似。利用SVD sketching和k-means，我们学习了一个1000个原子的字典（>97%方差），然后通过深度为3的QAOA解决一个2020 QUBO问题以选择5个原子。在这些编码上训练的100棵树的QsRF在ICM-150/500数据集上与全特征基线匹配。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='econth'></a>
## econ.TH 

### [18] [A General Framework for Estimating Preferences Using Response Time Data](https://arxiv.org/abs/2507.20403)
> *一个利用反应时间数据估计偏好的通用框架*

*Federico Echenique, Alireza Fallah, Michael I. Jordan* | **Category: econ.TH, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 偏好估计, 反应时间, 漂移扩散模型, 决策制定, 预测准确性

**Comment:** 

> **TL;DR:** 提出一种利用选择和反应时间数据估计偏好的通用方法，该方法在DDM中收敛速度快，并能提高预测准确性。

**AI_Comments:** 该论文的创新之处在于提出了一个通用的框架，将反应时间数据整合到偏好估计中，实现了快速收敛并具有广泛适用性。其重要性体现在能够提高预测准确性，并更好地估计经济相关参数，弥补了传统仅基于选择的模型的一些不足。

<details>
  <summary>Details</summary>

**Motivation:** 从选择和反应时间数据中恢复偏好参数。

**Method:** 提出一种通用方法，该方法在应用于漂移扩散模型（DDM）时能实现快速（$1/n$）收敛速度，并广泛适用于DDM的推广形式及其他利用反应时间数据的决策模型。论文还通过一个跨期选择实验进行了实证应用。

**Result:** 该方法能以快速（$1/n$）的收敛速度生成估计值。实证应用表明，使用反应时间数据能提高预测准确性，并且对经济相关参数的估计至关重要。

**Conclusion:** 使用反应时间数据对于估计偏好和提高决策模型的预测准确性具有重要价值。

> **ai_Abstract:** 本文提出一个通用框架，利用选择和反应时间数据估计偏好参数。该方法在应用于漂移扩散模型（DDM）时表现出快速收敛特性，并可广泛用于DDM的推广形式及其他决策模型。通过一个跨期选择的实证应用，研究表明利用反应时间数据能显著提高预测准确性，并对经济相关参数的估计至关重要。

> **摘要翻译:** 我们提出了一种从选择和反应时间数据中恢复偏好参数的通用方法。我们的方法在专门应用于流行的漂移扩散模型（DDM）时，能够以快速（对于n个数据点为$1/n$）的收敛速度生成估计值，但它也广泛适用于DDM的推广形式以及其他利用反应时间数据的决策模型。本文通过一个跨期选择实验开发了一个实证应用，表明使用反应时间数据能够提供预测准确性，并且对经济相关参数的估计至关重要。

</details>

[⬆️ 返回分类顶部](#econth) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [41] [funOCLUST: Clustering Functional Data with Outliers](https://arxiv.org/abs/2508.00110)
> *funOCLUST：带有异常值的功能数据聚类*

*Katharine M. Clark, Paul D. McNicholas* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 功能数据, 聚类, 异常值, OCLUST, 鲁棒方法

**Comment:** 

> **TL;DR:** funOCLUST算法被提出用于处理带异常值的功能数据聚类，该方法通过扩展OCLUST框架，实现曲线的鲁棒聚类和异常值修剪，并在模拟和真实数据集上表现出色。

**AI_Comments:** 该论文通过扩展现有的OCLUST算法，为功能数据聚类中的异常值处理提供了一种鲁棒且有效的新方法，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 功能数据由于其无限维特性以及对异常值的潜在敏感性，在聚类时面临独特的挑战。

**Method:** 提出了OCLUST算法在功能环境下的扩展，即funOCLUST。该方法利用OCLUST框架，创建了一个鲁棒的方法来聚类曲线并修剪异常值。

**Result:** 该方法在模拟和真实世界功能数据集上进行了评估，在聚类和异常值识别方面表现出强大的性能。

**Conclusion:** funOCLUST算法能够有效处理功能数据聚类中的异常值问题，并实现鲁棒的聚类和异常值识别。

> **ai_Abstract:** 本研究提出了一种名为funOCLUST的新算法，它是OCLUST算法在功能数据领域的扩展，旨在解决功能数据聚类中存在的无限维特性和异常值敏感性问题。该方法能够对曲线进行鲁棒聚类并有效修剪异常值，并在模拟和真实数据集上展示了卓越的性能。

> **摘要翻译:** 功能数据由于其无限维特性以及对异常值的潜在敏感性，在聚类时面临独特的挑战。本文提出了一种将OCLUST算法扩展到功能环境的方法，以解决这些问题。该方法利用OCLUST框架，创建了一个鲁棒的方法来聚类曲线并修剪异常值。该方法在模拟和真实世界功能数据集上进行了评估，在聚类和异常值识别方面表现出强大的性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [290] [Sinusoidal Approximation Theorem for Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.00247)
> *Kolmogorov-Arnold 网络的正弦近似定理*

*Sergei Gleyzer, Hanh Nguyen, Dinesh P. Ramakrishnan, Eric A. F. Reinhardt* | **Category: stat.ML, cs.LG, cs.NA, math.NA** | **Updated: 2025-08-01**

**Keywords:** Kolmogorov-Arnold网络, 正弦激活, 通用逼近, 神经网络, 多变量函数

**Comment:** 15 pages, 3 figures

> **TL;DR:** 本文提出了一种新的KAN变体，用可学习的正弦函数作为激活函数，并在理论上证明了其有效性。数值实验表明，该变体在多变量函数上优于固定频率的傅里叶变换方法，并取得了与多层感知器（MLP）相当的性能。

**AI_Comments:** 该论文的创新点在于提出了一个新颖的KAN变体，通过用可学习频率的加权正弦函数替代传统的样条激活函数。这种方法不仅为KANs提供了一种新的激活函数选择，也为通用逼近定理在神经网络中的应用开辟了新的视角。其重要性在于，该模型在保持理论有效性的同时，在实际应用中展现出与主流MLP相当的性能，并超越了固定频率的傅里叶变换方法，这可能为未来神经网络设计提供新的思路，特别是在需要精确函数逼近的场景。

<details>
  <summary>Details</summary>

**Motivation:** Kolmogorov-Arnold网络（KANs）被提出作为多层感知器（MLPs）的替代品，并使用基于基样条函数的学习型非线性激活。鉴于后续工作探索了样条激活的替代方案，本文旨在通过引入加权正弦函数作为内外函数来提出一种新颖的KAN变体，以期在理论和实践中改进KANs的性能。

**Method:** 本研究提出了一种新颖的Kolmogorov-Arnold网络（KAN）变体，通过将Kolmogorov-Arnold表示中的内部和外部函数替换为具有可学习频率的加权正弦函数。受Lorentz和Sprecher简化方法的启发，研究者将正弦激活的相位固定为线性间隔的常数值，并提供了其理论有效性的证明。此外，还进行了数值实验，以评估其在多种多变量函数上的性能，并将其与固定频率傅里叶变换方法和多层感知器（MLP）进行了比较。

**Result:** 所提出的KAN变体在多变量函数上表现出优于固定频率傅里叶变换方法的性能，并且能够达到与多层感知器（MLP）相当的性能。

**Conclusion:** 本研究成功提出并验证了一种基于可学习正弦激活函数的新型Kolmogorov-Arnold网络（KAN）变体。该变体在理论上具有有效性，并在数值实验中展现出与传统多层感知器（MLP）相当的竞争力，同时超越了固定频率的傅里叶变换方法，为神经网络的激活函数设计提供了新的方向。

> **ai_Abstract:** 本文提出了一种新型的Kolmogorov-Arnold网络（KAN）变体，旨在替代传统基于样条激活的KANs和多层感知器（MLPs）。该变体通过将Kolmogorov-Arnold表示中的内外函数替换为具有可学习频率的加权正弦函数，并固定相位。研究提供了其理论有效性证明，并通过数值实验验证了其性能。结果表明，该正弦KAN变体在多变量函数逼近上优于固定频率傅里叶变换方法，并达到了与MLPs相当的性能。

> **摘要翻译:** Kolmogorov-Arnold表示定理指出，任何连续的多变量函数都可以精确地表示为连续单变量函数的有限叠加。这种表示的后续简化涉及将这些函数表达为少量独特单调函数的参数化和。这些发展导致了具有S型激活的多层感知器网络通用逼近能力的证明，形成了大多数现代神经网络的替代理论方向。
Kolmogorov-Arnold网络（KANs）最近被提出作为多层感知器的替代方案。KANs的特点是将可学习的非线性激活直接应用于输入值，建模为基样条函数的加权和。这种方法取代了传统感知器中使用的线性变换和S型后激活。后续工作探索了样条激活的替代方案。在这项工作中，我们提出了一种新颖的KAN变体，通过将Kolmogorov-Arnold表示中的内部和外部函数替换为具有可学习频率的加权正弦函数。受Lorentz和Sprecher引入的简化的启发，我们将正弦激活的相位固定为线性间隔的常数值，并提供了其理论有效性的证明。我们还进行了数值实验，以评估其在多种多变量函数上的性能，并将其与固定频率傅里叶变换方法和多层感知器（MLP）进行了比较。我们表明，它优于固定频率的傅里叶变换，并取得了与MLP相当的性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [661] [Bagged Regularized $k$-Distances for Anomaly Detection](https://arxiv.org/abs/2312.01046)
> *基于袋装正则化 $k$-距离的异常检测*

*Yuchao Cai, Hanfang Yang, Yuheng Ma, Hanyuan Hang* | **Category: stat.ML, cs.LG, math.ST, stat.TH** | **Updated: 2025-08-01**

**Keywords:** 异常检测, 距离基方法, Bagging, 凸优化, 超参数敏感性

**Comment:** 

> **TL;DR:** 本文提出了一种名为BRDAD的新的距离基异常检测算法，通过将问题转化为凸优化，并结合bagging技术，解决了现有距离基方法对超参数选择的敏感性以及大规模数据集的效率问题，并在理论和实践中都表现出优越的性能。

**AI_Comments:** 该论文的创新点在于将无监督异常检测中的距离基方法与凸优化和bagging技术相结合，有效解决了现有方法中超参数敏感性和大规模数据效率低下的两大痛点。通过数学推导和实验验证，证明了其理论和实践上的优越性，对异常检测领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于距离的方法在无监督异常检测中表现出色，但它们严重受限于最近邻数量选择的敏感性。此外，处理大规模数据集时存在效率问题。

**Method:** 本文提出了一种新的距离基算法，称为袋装正则化 $k$-距离异常检测 (BRDAD)。该算法将无监督异常检测问题转化为一个凸优化问题。BRDAD通过最小化替代风险（即袋装加权 $k$-距离密度估计 (BWDDE) 的经验风险的有限样本界限）来选择权重。此外，通过引入bagging技术来解决大规模数据集的效率问题。

**Result:** 在理论方面，本文建立了算法AUC遗憾的快速收敛率，并证明了bagging技术显著降低了计算复杂性。在实践方面，数值实验表明，与现有最先进的距离基方法相比，BRDAD算法的参数选择不敏感。此外，该方法在引入bagging技术后，在真实世界数据集上实现了卓越的性能。

**Conclusion:** BRDAD算法通过将问题转化为凸优化并结合bagging技术，成功解决了距离基异常检测算法中超参数选择的敏感性问题和大规模数据集的效率问题，并在理论和实践中都表现出优越的性能。

> **ai_Abstract:** 本文提出了一种名为BRDAD（袋装正则化 $k$-距离异常检测）的新型无监督异常检测算法。该算法通过将问题表述为凸优化，并最小化替代风险来确定权重，从而有效解决了传统距离基方法对最近邻数量选择的敏感性问题。此外，BRDAD算法通过引入bagging技术，提升了处理大规模数据集的效率。理论分析证明了其快速的AUC遗憾收敛率和计算复杂度的降低。实验结果也验证了该算法在参数选择上的不敏感性以及在真实世界数据集上的优越性能。

> **摘要翻译:** 我们考虑无监督异常检测的范式，它涉及在没有标记样本的情况下识别数据集中的异常。尽管基于距离的方法在无监督异常检测中表现最佳，但它们严重受限于最近邻数量选择的敏感性。在本文中，我们提出了一种新的基于距离的算法，称为袋装正则化 $k$-距离异常检测 (BRDAD)，将无监督异常检测问题转化为一个凸优化问题。我们的BRDAD算法通过最小化替代风险来选择权重，即袋装加权 $k$-距离密度估计 (BWDDE) 的经验风险的有限样本界限。这种方法使我们能够成功解决基于距离算法中超参数选择的敏感性挑战。此外，在处理大规模数据集时，我们的BRDAD算法中整合的bagging技术可以解决效率问题。在理论方面，我们建立了算法AUC遗憾的快速收敛率，并证明了bagging技术显著降低了计算复杂性。在实践方面，我们进行了数值实验，以说明我们的算法与现有最先进的基于距离的方法相比，参数选择的不敏感性。此外，我们的方法在引入bagging技术后，在真实世界数据集上实现了比其他方法更优越的性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [673] [Large Deviations of Gaussian Neural Networks with ReLU activation](https://arxiv.org/abs/2405.16958)
> *具有ReLU激活函数的 Gaussian 神经网络的大偏差*

*Quirin Vogel* | **Category: stat.ML, cs.LG, math.PR, 60F10, 68T07** | **Updated: 2025-08-01**

**Keywords:** 大偏差, 高斯神经网络, ReLU激活, 深度学习, 速率函数

**Comment:** 13 pages, 2 figures, proof simplified

> **TL;DR:** 本文证明了具有高斯权重和ReLU等线性增长激活函数的深度神经网络的大偏差原理，推广了现有工作，并简化了相关表达式。

**AI_Comments:** 这项工作的重要性在于将大偏差理论扩展到实际应用中更常见的ReLU等非有界激活函数，填补了理论与实践之间的空白。简化速率函数表达式和提供幂级数展开也使得理论更易于应用和分析。

<details>
  <summary>Details</summary>

**Motivation:** 之前的研究考虑的是有界和连续的激活函数，但在实践中，ReLU等线性增长的激活函数更为常用。因此，本文旨在将大偏差原理推广到这类激活函数。

**Method:** 作者证明了具有高斯权重和线性增长激活函数（如ReLU）的深度神经网络的大偏差原理。此外，他们简化了先前的速率函数表达式，并为ReLU情况提供了幂级数展开。

**Result:** 成功为具有ReLU等线性增长激活函数的深度神经网络建立了大偏差原理。同时，简化了速率函数的先前表达式，并提供了ReLU情况下的幂级数展开。

**Conclusion:** 本文成功将大偏差原理推广到实践中常用的线性增长激活函数（如ReLU），并简化了相关数学表达，这对于理解高斯神经网络的行为具有重要意义。

> **ai_Abstract:** 本文针对具有高斯权重和ReLU等线性增长激活函数的深度神经网络，首次证明了其大偏差原理。这项工作推广了之前针对有界连续激活函数的研究成果，并考虑到ReLU在实际应用中的普遍性。此外，研究还简化了速率函数的现有表达式，并为ReLU情况提供了幂级数展开，从而为理解这类神经网络的统计行为提供了更实用的工具。

> **摘要翻译:** 我们证明了具有高斯权重和至多线性增长激活函数（例如ReLU）的深度神经网络的大偏差原理。这推广了早期的工作，在那些工作中考虑了有界和连续的激活函数。在实践中，ReLU等线性增长的激活函数是最常用的。我们还进一步简化了速率函数的先前表达式，并为ReLU情况提供了幂级数展开。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [679] [Pure interaction effects unseen by Random Forests](https://arxiv.org/abs/2406.15500)
> *随机森林未能识别的纯交互效应*

*Ricardo Blum, Munir Hiabu, Enno Mammen, Joseph Theo Meyer* | **Category: stat.ML, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 随机森林, 交互效应, 决策树, CART准则, 模型拟合

**Comment:** arXiv admin note: substantial text overlap with arXiv:2309.01460

> **TL;DR:** 随机森林在捕获某些纯交互效应方面表现不佳，本文提出并验证了替代的分裂方案可以改善其性能。

**AI_Comments:** 本文创新性地指出了随机森林在处理特定“纯交互效应”时的潜在缺陷，这与普遍认为随机森林善于捕获交互作用的观点形成对比。通过提出替代的树分裂方案，该研究为提高随机森林在复杂交互模式下的性能提供了新的思路，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 随机森林被广泛认为能很好地捕获交互作用，但有简单例子表明，在存在传统CART准则难以捕获的某些纯交互作用时，随机森林表现不佳。

**Method:** 本文提出并论证在树生长过程中使用简单的替代划分方案，以增强这些交互作用的识别。通过仿真研究，将这些变体与传统随机森林和极端随机树进行比较，并最终将这些方法应用于真实数据集。

**Result:** 仿真结果验证了所考虑的修改在纯交互作用发挥关键作用的场景中，增强了模型的拟合能力。

**Conclusion:** 替代的划分方案可以提高随机森林在捕获纯交互作用方面的性能。

> **ai_Abstract:** 本文研究了随机森林在捕获某些纯交互效应方面的局限性，指出传统CART准则在此类情况下表现不佳。为解决此问题，作者提出并评估了在树构建过程中采用替代划分方案的方法。通过仿真研究和真实数据集应用，结果表明这些改进方案能有效提升模型在纯交互效应场景下的拟合能力。

> **摘要翻译:** 随机森林被广泛声称能很好地捕获交互作用。然而，一些简单的例子表明，在存在传统CART准则在树构建过程中难以捕获的某些纯交互作用时，它们表现不佳。受此启发，本文认为在树生长过程中使用的简单替代划分方案可以增强这些交互作用的识别。在一项模拟研究中，将这些变体与传统随机森林和极端随机树进行了比较。结果验证了所考虑的修改在纯交互作用发挥关键作用的场景中，增强了模型的拟合能力。最后，这些方法被应用于真实数据集。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [715] [Batched Nonparametric Bandits via k-Nearest Neighbor UCB](https://arxiv.org/abs/2505.10498)
> *基于k-近邻UCB的批处理非参数强盗问题*

*Sakshi Arya* | **Category: stat.ML, cs.LG, math.ST, stat.ME, stat.TH, 68T05, 62L05, 62G08, 68Q32, F.2.2; I.2.6** | **Updated: 2025-08-01**

**Keywords:** 批处理强盗, 非参数, k-近邻, UCB, 上下文强盗

**Comment:** 

> **TL;DR:** 本文提出了一种名为BaNk-UCB的非参数算法，用于解决批处理非参数上下文强盗问题，该算法结合了自适应k-近邻回归和UCB原则，在理论上提供了接近最优的遗憾保证，并在经验上表现优异。

**AI_Comments:** BaNk-UCB的创新之处在于其完全非参数的特性，以及将k-NN回归与UCB原则相结合，利用局部几何来估计奖励，而非依赖于传统的参数模型或分箱方法。这使得它能更好地适应上下文维度，并在在线反馈受限的实际应用中具有重要意义。该方法在理论和实践中都表现出强大的性能。

<details>
  <summary>Details</summary>

**Motivation:** 在医学和市场营销等领域，在线反馈有限，因此需要一种在少量批次中选择行动的序列决策方法。现有方法依赖参数或基于分箱的估计器，而本文旨在提供一种完全非参数、适应上下文维度且易于实现的解决方案。

**Method:** 本文提出了一种名为BaNk-UCB的非参数算法。该方法结合了自适应k-近邻（k-NN）回归与上置信界（UCB）原则。它通过局部几何来估计奖励，并自适应地平衡探索和利用。该算法使用理论上合理的批处理调度，以平衡批次间的遗憾。

**Result:** 在标准Lipschitz平滑度和边际假设下，BaNk-UCB提供了接近最优的遗憾保证，并达到了最小最大最优速率。在合成和真实世界数据集上的实证评估表明，BaNk-UCB始终优于基于分箱的基线方法。

**Conclusion:** BaNk-UCB是一种有效的非参数上下文强盗算法，它克服了传统参数或分箱方法的局限性，在理论上和实践中都表现出色，为在线反馈有限的领域提供了有前景的解决方案。

> **ai_Abstract:** 本文提出了一种名为BaNk-UCB的非参数算法，用于解决批处理非参数上下文强盗问题。该算法结合了自适应k-近邻回归和上置信界原则，旨在克服在线反馈有限领域（如医学和市场营销）的挑战。BaNk-UCB利用局部几何估计奖励，并自适应地平衡探索与利用。该方法在理论上提供了接近最优的遗憾保证，并在实验中优于现有基线。

> **摘要翻译:** 我们研究了批处理非参数上下文强盗问题中的序列决策，其中行动在一个有限的时间范围内分批次选择。受医学和市场营销等领域中在线反馈有限的约束驱动，我们提出了一种非参数算法，该算法将自适应k-近邻（k-NN）回归与上置信界（UCB）原则相结合。我们的方法BaNk-UCB是完全非参数的，能适应上下文维度，并且易于实现。与之前依赖参数或基于分箱估计器的工作不同，BaNk-UCB利用局部几何来估计奖励，并自适应地平衡探索和利用。我们在标准Lipschitz平滑度和边际假设下，使用理论上合理的批处理调度，提供了接近最优的遗憾保证，该调度平衡了批次间的遗憾并达到了最小最大最优速率。在合成和真实世界数据集上的经验评估表明，BaNk-UCB始终优于基于分箱的基线方法。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [43] [Nonlinear Computation with Linear Optics via Source-Position Encoding](https://arxiv.org/abs/2504.20401)
> *通过光源位置编码实现线性光学中的非线性计算*

*N. Richardson, C. Bosch, R. P. Adams* | **Category: physics.optics, cs.AR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 光学计算, 非线性计算, 光源位置编码, 光学神经网络, 拓扑优化

**Comment:** 

> **TL;DR:** 该论文提出了一种在光学线性介质中通过光源位置编码实现非线性计算的新方法，为光学神经网络提供了解决方案，并在机器学习任务上展现出与传统ANNs相当的性能。

**AI_Comments:** 这项工作提出了一种创新方法，通过在不需要固有非线性光学材料的情况下实现非线性操作，克服了光学计算中的一个基本限制。利用光源位置编码和拓扑优化进行硬件设计是一种巧妙的方式，可以利用现有的线性光学元件来完成复杂的神经网络任务，这可能为更节能、可扩展的光学AI硬件铺平道路。

<details>
  <summary>Details</summary>

**Motivation:** 光学计算系统在神经网络负载方面具有潜力，但缺乏在光学中实现节能非线性（这是实现神经网络的关键要求）的方法。

**Method:** 引入了一种新颖的方法，通过以数据相关的空间位置驱动光学系统（光源位置编码），在完全线性介质中实现非线性计算。同时，他们还制定了一个基于拓扑优化的硬件设计框架，用于高度专业化的光学神经网络。

**Result:** 在机器学习分类任务上，他们的光学设计比线性方法有显著改进，并且与标准人工神经网络相比具有竞争性的性能。

**Conclusion:** 该研究成功展示了一种在线性光学中实现非线性计算的新方法，解决了光学神经网络发展中的一个关键挑战。

> **ai_Abstract:** 本文旨在解决光学计算中实现节能非线性的挑战，这对于光学神经网络至关重要。作者提出了一种新颖的方法，通过采用光源位置编码（即以数据相关的空间位置驱动光学系统）在完全线性介质中实现非线性计算。他们还开发了一个基于拓扑优化的硬件设计框架。在机器学习分类任务上的评估表明，他们的光学设计显著优于线性方法，并且与标准人工神经网络相比具有竞争性的性能。

> **摘要翻译:** 光学计算系统提供了一种替代硬件模型，似乎与神经网络工作负载的需求相符。然而，在光学中实现节能非线性——这是实现神经网络的关键要求——是一个明显的缺失环节。在这项工作中，我们引入了一种新颖的方法，在完全线性介质中实现非线性计算。我们的方法可以低功耗运行，并且只需要能够以数据相关的空间位置驱动光学系统。利用这种位置编码，我们借鉴优化和机器学习的最新进展，为高度专业化的光学神经网络制定了一个全自动的、基于拓扑优化的硬件设计框架。我们在机器学习分类任务上评估了我们的光学设计：展示了比线性方法显著的改进，并且与标准人工神经网络相比具有竞争性的性能。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='mathlo'></a>
## math.LO 

### [73] [Proof complexity of Mal'tsev CSP](https://arxiv.org/abs/2508.00396)
> *Mal'tsev CSP 的证明复杂性*

*Azza Gaysin* | **Category: math.LO, cs.CC** | **Updated: 2025-08-01**

**Keywords:** 证明复杂性, Mal'tsev CSP, 约束满足问题, 有界算术, 扩展 Frege 证明系统

**Comment:** 

> **TL;DR:** 本文证明了非可满足的 Mal'tsev CSP 实例的非存在性可以用扩展 Frege 证明系统中的短证明来表达。

**AI_Comments:** 本文的创新之处在于将特定类型的多项式时间可解的 CSPs（Mal'tsev CSPs 和广义多数-少数 CSPs）与其在扩展 Frege 证明系统中的证明复杂性联系起来。这为理解这些问题的计算性质和证明效率提供了新的视角，特别是对于那些已知有多项式时间算法的问题，其非可满足性证明的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 约束满足问题 (CSPs) 分为 NP-完全和多项式时间可解两类。Mal'tsev CSPs 是一类重要的多项式时间可解的 CSPs。研究其证明复杂性有助于理解这类问题的计算边界，特别是当其非可满足实例被表达为命题重言式时。

**Method:** 作者将 Mal'tsev CSP 的算法形式化为有界算术 $V^1$ 系统，该系统捕获多项式时间推理并对应于扩展 Frege 证明系统。

**Result:** 结果表明，$V^1$ 证明了 Mal'tsev 算法的可靠性，这意味着表达非可满足的 Mal'tsev CSP 实例无解的重言式允许短的扩展 Frege 证明。此外，对于解决广义多数-少数 CSPs 的 Dalmau 算法也得到了类似的结果。

**Conclusion:** 本文证明了 Mal'tsev CSPs（以及广义多数-少数 CSPs）的非可满足实例具有在扩展 Frege 系统中的短证明，这揭示了这些问题在证明复杂性方面的特性和效率。

> **ai_Abstract:** 本文研究了 Mal'tsev 约束满足问题 (CSPs) 的证明复杂性。Mal'tsev CSPs 是一类已知可在多项式时间内解决的 CSPs。作者将 Mal'tsev CSP 算法形式化为有界算术 $V^1$ 系统，该系统对应于扩展 Frege 证明系统。研究结果表明，$V^1$ 能够证明 Mal'tsev 算法的可靠性，从而推断出非可满足的 Mal'tsev CSP 实例的无解重言式具有短的扩展 Frege 证明。此外，对于广义多数-少数 CSPs 的 Dalmau 算法也得到了类似的结论。

> **摘要翻译:** 约束满足问题 (CSPs) 形成了一大类组合问题，可以表述为关系结构之间的同态问题。CSP 二分定理将所有有限域上的此类问题分为两类：NP-完全和多项式时间，参见 Zhuk (2017)，Bulatov (2017)。多项式时间 CSPs 可以进一步细分为更小的子类。Mal'tsev CSPs 的定义是问题中的每个关系在 Mal'tsev 运算下是不变的，Mal'tsev 运算是一个三元运算 $\mu$，满足 $\mu(x, y, y) = \mu(y, y, x) = x$ 对于所有 $x, y$。Bulatov 和 Dalmau 证明了 Mal'tsev CSPs 可以在多项式时间内求解，并提出了此类 CSPs 的算法 (2006)。一个不可满足的 CSP 实例的否定可以表示为命题重言式。我们将 Mal'tsev CSPs 的算法形式化为有界算术 $V^1$，它捕获了多项式时间推理并对应于扩展 Frege 证明系统。我们证明了 $V^1$ 证明了 Mal'tsev 算法的可靠性，这意味着表达非可满足的 Mal'tsev CSP 实例无解的重言式允许短的扩展 Frege 证明。此外，通过小的调整，我们对解决广义多数-少数 CSPs 的 Dalmau 算法也取得了类似的结果——这是近一致运算和 Mal'tsev 运算的常见推广。

</details>

[⬆️ 返回分类顶部](#mathlo) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [77] [Neighbor-Sampling Based Momentum Stochastic Methods for Training Graph Neural Networks](https://arxiv.org/abs/2508.00267)
> *基于邻居采样动量随机方法训练图神经网络*

*Molly Noel, Gabriel Mancino-Ball, Yangyang Xu* | **Category: math.OC, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 图神经网络, 邻居采样, Adam, 随机方法, 控制变量

**Comment:** 32 pages

> **TL;DR:** 本文提出了一种基于邻居采样的Adam型随机方法，用于解决非凸GCN训练问题，并通过控制变量技术降低随机误差，实现了最优收敛速度，并在大规模图数据集上表现出优异性能。

**AI_Comments:** 本文的创新点在于将Adam型动量优化器与邻居采样及控制变量技术相结合，为大规模GCN训练提供了理论上最优且实践中表现优异的解决方案。它弥补了现有GCN训练方法在理论保证和实用性上的不足，特别是在处理大规模图数据时展现出强大的潜力，对图神经网络的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图卷积网络（GCNs）的递归邻居聚合导致现有高效训练方法缺乏理论保证，或缺少现代深度学习算法中的重要实践元素，如自适应性和动量。

**Method:** 本文提出了几种基于邻居采样（NS）的Adam型随机方法，用于解决非凸GCN训练问题。利用控制变量技术减少邻居采样引起的随机误差。

**Result:** 在Adam型方法的标准假设下，本文提出的方法具有最优收敛速度。数值实验表明，该方法在节点分类任务上优于经典的基于NS的SGD方法（同样使用控制变量技术），尤其是在大规模图数据集上表现更佳。

**Conclusion:** 本文提出的基于邻居采样的Adam型随机方法，结合控制变量技术，有效解决了GCN训练中的挑战，实现了理论上的最优收敛速度和实践中的优越性能，特别适用于大规模图。

> **ai_Abstract:** 针对图卷积网络（GCNs）训练中现有方法缺乏理论保证或缺少自适应性、动量等问题，本文提出了一系列基于邻居采样的Adam型随机方法。通过引入控制变量技术，有效降低了邻居采样带来的随机误差。理论分析表明，这些方法在标准假设下能达到最优收敛速度。实验结果也验证了其在节点分类任务上的优越性能，尤其是在处理大规模图数据时，相较于经典的基于邻居采样的SGD方法表现更佳。

> **摘要翻译:** 图卷积网络（GCNs）是图表示学习的强大工具。由于GCNs采用递归邻域聚合，高效的训练方法要么缺乏理论保证，要么缺少现代深度学习算法中的重要实践元素，例如自适应性和动量。在本文中，我们提出了几种基于邻居采样（NS）的Adam型随机方法，用于解决非凸GCN训练问题。我们利用[1]提出的控制变量技术来减少邻居采样引起的随机误差。在Adam型方法的标准假设下，我们证明了我们的方法具有最优收敛速度。此外，我们在几个基准数据集上进行了广泛的节点分类任务数值实验。结果表明，我们的方法优于同样使用控制变量技术的经典NS-based SGD，特别是对于大规模图数据集。我们的代码可在https://github.com/RPI-OPT/CV-ADAM-GNN 获取。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [78] [Constrained Stochastic Recursive Momentum Successive Convex Approximation](https://arxiv.org/abs/2404.11790)
> *约束随机递归动量逐次凸逼近*

*Basil M. Idrees, Lavish Arora, Ketan Rajawat* | **Category: math.OC, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 随机优化, 非凸约束, 逐次凸逼近, 递归动量, 随机一阶复杂度

**Comment:** 32 pages, 4 figures, journal submission

> **TL;DR:** 本文提出了一种新的递归动量加速逐次凸逼近(SCA)算法，用于解决具有非凸函数约束的随机优化问题。该算法实现了接近最优的随机一阶复杂度，并在轨迹生成、稀疏逼近和鲁棒分类等应用中表现出色。

**AI_Comments:** 该论文的创新点在于提出了一个结合递归动量和逐次凸逼近的框架，用于解决具有挑战性的非凸约束随机优化问题。其引入的参数化Mangasarian-Fromowitz约束条件为分析收敛性提供了新的工具，并实现了接近最优的随机一阶复杂度，这对于在实际应用中处理大规模随机优化问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决具有非凸函数约束的随机优化问题，这些问题广泛存在于轨迹生成、稀疏逼近和鲁棒分类等领域。

**Method:** 提出了一种基于递归动量的加速逐次凸逼近(SCA)算法。该算法在每次迭代中构建随机目标函数和约束函数的凸替代，并求解由此产生的凸优化问题。采用递归更新规则来跟踪随机目标函数的梯度，以减少方差并加速算法收敛。证明的关键在于标准Mangasarian-Fromowitz约束条件的一种新的参数化版本，该版本允许绑定对偶变量并获得迭代逼近$\epsilon$-平稳点的速率的问题相关界限。

**Result:** 所提出的算法实现了接近最优的随机一阶(SFO)复杂度，其自适应步长与最先进的无约束随机优化算法所达到的复杂度非常接近。在避障轨迹优化问题中，该算法的性能优于现有算法。在二元分类问题中，其性能与专门的稀疏分类算法相当。

**Conclusion:** 本文提出的约束随机递归动量逐次凸逼近算法能够有效地解决具有非凸函数约束的随机优化问题，并在实际应用中表现出优越或可比的性能，达到了接近最优的复杂度。

> **ai_Abstract:** 本文提出了一种新颖的递归动量加速逐次凸逼近（SCA）算法，旨在解决具有非凸函数约束的随机优化问题。该算法通过构建凸替代函数并利用递归梯度更新来加速收敛，并引入了一种新的参数化Mangasarian-Fromowitz约束条件以提供收敛速率界限。实验结果表明，该算法在轨迹优化和稀疏分类等应用中表现出接近最优的随机一阶复杂度，并优于或媲美现有方法。

> **摘要翻译:** 我们考虑具有非凸函数约束的随机优化问题，例如轨迹生成、稀疏逼近和鲁棒分类中出现的问题。为此，我们提出了一种基于递归动量的加速逐次凸逼近（SCA）算法。在每次迭代中，所提出的算法需要构建随机目标和约束函数的凸替代，并求解由此产生的凸优化问题。采用递归更新规则来跟踪随机目标函数的梯度，这有助于减少方差，从而加速算法收敛。证明的关键在于标准Mangasarian-Fromowitz约束条件的一种新的参数化版本，它允许我们绑定对偶变量，从而获得迭代逼近$\epsilon$-平稳点的速率的问题相关界限。值得注意的是，所提出的算法实现了接近最优的随机一阶（SFO）复杂度，其自适应步长与最先进的无约束随机优化算法所达到的复杂度非常接近。作为一个例子，我们详细介绍了一个可以使用所提出算法解决的避障轨迹优化问题，并表明其性能优于用于轨迹优化的现有算法。所提出算法的性能还表明与应用于二元分类问题的专门稀疏分类算法相当。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [85] [Riemannian Optimization for Distance Geometry: A Study of Convergence, Robustness, and Incoherence](https://arxiv.org/abs/2508.00091)
> *黎曼优化在距离几何中的应用：收敛性、鲁棒性和不协调性研究*

*Chandler Smith, HanQin Cai, Abiy Tasissa* | **Category: math.OC, cs.CG, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 黎曼优化, 距离几何, 低秩矩阵补全, 收敛性, 鲁棒性

**Comment:** 54 pages, 6 figures

> **TL;DR:** 该论文提出了一种基于黎曼优化的低秩矩阵补全框架，用于解决欧几里得距离几何问题，并在理论上证明了其收敛性和鲁棒性，同时引入了新的矩阵不协调性概念。

**AI_Comments:** 该论文的创新之处在于将欧几里得距离几何问题重新表述为黎曼流形上的优化问题，并提供了严格的理论收敛性和鲁棒性分析。特别是，引入EDG特有的不协调性参数和对Hanson-Wright不等式的创新应用，提升了理论分析的深度和广度。这项工作为解决复杂几何约束下的低秩矩阵补全问题提供了新的视角和工具，对传感器网络定位和分子构象等应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 欧几里得距离几何（EDG）问题在传感器网络定位、分子构象和流形学习等多种应用中广泛出现，但从部分成对距离恢复点配置仍然是一个挑战。

**Method:** 本文提出了一种黎曼优化框架来解决EDG问题，将其表述为在正半定Gram矩阵空间上的低秩矩阵补全任务。通过非正交基中的扩展系数编码距离测量，并利用Gram矩阵上的优化隐式强制执行几何一致性。作者在秩为r的矩阵流形上使用黎曼梯度下降，并分析了其收敛性。

**Result:** 在伯努利采样模型下，当采样概率满足$p \geq \mathcal{O}(\nu^2 r^2 \log(n)/n)$时，黎曼梯度下降在秩-r矩阵流形上以高概率局部线性收敛。提供了一种单步硬阈值初始化方案，当采样概率满足$p \geq \mathcal{O}(\nu r^{3/2} \log^{3/4}(n)/n^{1/4})$时可实现收敛。引入了针对EDG设置的矩阵不协调性新概念，并提供了方法的鲁棒性保证。在合成数据上的实证评估表明，该算法相对于现有技术表现出竞争力。

**Conclusion:** 本文提出的黎曼优化框架有效地解决了欧几里得距离几何问题，并在理论上证明了其在特定采样条件下的收敛性和鲁棒性。引入的EDG特定矩阵不协调性概念和分析方法是重要的技术贡献。

> **ai_Abstract:** 本文提出了一种基于黎曼优化的方法来解决欧几里得距离几何（EDG）问题。该方法将EDG问题建模为正半定Gram矩阵空间上的低秩矩阵补全任务，并利用黎曼梯度下降进行优化。研究证明了该方法在特定采样概率下的局部线性收敛性，并提供了一种有效的初始化方案。此外，论文引入了针对EDG的矩阵不协调性概念，并分析了其鲁棒性。实验结果表明，该算法性能优于现有方法。

> **摘要翻译:** 从部分成对距离恢复点配置的问题，即欧几里得距离几何（EDG）问题，出现在广泛的应用中，包括传感器网络定位、分子构象和流形学习。在本文中，我们提出了一种黎曼优化框架来解决EDG问题，通过将其表述为在正半定Gram矩阵空间上的低秩矩阵补全任务。可用的距离测量在非正交基中编码为扩展系数，并且Gram矩阵上的优化通过三角不等式隐式地强制执行几何一致性，这是一种从经典多维尺度分析继承的结构。在观察距离的伯努利采样模型下，我们证明了当采样概率满足 $p \geq \mathcal{O}(\nu^2 r^2 \log(n)/n)$ 时，秩-r矩阵流形上的黎曼梯度下降以高概率局部线性收敛，其中 $\nu$ 是一个EDG特有的不协调参数。此外，我们提供了一种使用一步硬阈值过程的初始化候选方案，只要采样概率满足 $p \geq \mathcal{O}(\nu r^{3/2} \log^{3/4}(n)/n^{1/4})$ 即可实现收敛。这项工作的一个关键技术贡献是对非正交基中双重基展开产生的对称线性算子的分析，这需要新颖地应用Hanson-Wright不等式来在耦合项存在的情况下建立最优受限等距性质。在合成数据上的实证评估表明，我们的算法相对于最先进的方法取得了有竞争力的性能。此外，我们提出了一种针对EDG设置的矩阵不协调性新概念，并为我们的方法提供了鲁棒性保证。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [615] [Efficient Solving of Large Single Input Superstate Decomposable Markovian Decision Process](https://arxiv.org/abs/2508.00816)
> *大型单输入超态可分解马尔可夫决策过程的有效求解*

*Youssef Ait El Mahjoub, Jean-Michel Fourneau, Salma Alouah* | **Category: math.OC, cs.LG, cs.PF** | **Updated: 2025-08-01**

**Keywords:** 马尔可夫决策过程, 策略评估, 分解, 可扩展性, SISDMDP

**Comment:** Preprint article submitted to ValueTools2025

> **TL;DR:** 本文提出了一种名为SISDMDP的新型结构化马尔可夫决策过程（MDPs），并开发了一种基于其结构的高效、精确且可扩展的策略评估方法，适用于平均奖励和折扣奖励MDPs。

**AI_Comments:** 该研究的创新之处在于定义了一个新的、特定类型的MDPs（SISDMDP），并通过利用其结构分解特性实现了高效的策略评估。这种方法有望显著提高大型MDPs在实际应用中的可处理性，特别是那些表现出所定义结构属性的问题。

<details>
  <summary>Details</summary>

**Motivation:** 解决马尔可夫决策过程（MDPs）仍是序列决策中的核心挑战，尤其是在处理大型状态空间和长期优化标准时。贝尔曼动态规划算法中的策略评估步骤在无限时间范围设置（如平均奖励或折扣奖励公式）中计算量巨大。

**Method:** 本文将聚合和分解原理扩展到一类结构化的MDPs。作者定义了单输入超态可分解马尔可夫决策过程（SISDMDP），它结合了Chiu的单输入分解和Robertazzi的单周期递归特性。当一个策略诱导这种结构时，所产生的转移图可以分解为具有集中递归的交互组件。基于这种结构，开发了一种精确高效的策略评估方法。

**Result:** 所开发的策略评估方法是精确、高效且可扩展的，适用于平均奖励和折扣奖励MDPs。

**Conclusion:** 本文提出的针对SISDMDP的精确高效策略评估方法，为解决大型马尔可夫决策过程的计算挑战提供了一个可扩展的解决方案，适用于平均奖励和折扣奖励设置。

> **ai_Abstract:** 本文针对大型马尔可夫决策过程（MDPs）中策略评估的计算挑战，引入了一种新的结构化MDP类别——单输入超态可分解马尔可夫决策过程（SISDMDP）。该方法结合了现有的分解特性，通过利用转移图可分解为具有集中递归的交互组件的固有结构，开发了一种精确、高效且可扩展的策略评估方法，适用于平均奖励和折扣奖励MDPs。

> **摘要翻译:** 解决马尔可夫决策过程（MDPs）仍然是序列决策中的一个核心挑战，尤其是在处理大型状态空间和长期优化标准时。贝尔曼动态规划算法中的一个关键步骤是策略评估，这在无限时间范围设置（如平均奖励或折扣奖励公式）中变得计算量巨大。在马尔可夫链的背景下，聚合和分解技术长期以来一直被用于通过利用结构分解来降低复杂性。在这项工作中，我们将这些原理扩展到一类结构化的MDPs。我们定义了单输入超态可分解马尔可夫决策过程（SISDMDP），它结合了Chiu的单输入分解和Robertazzi的单周期递归特性。当一个策略诱导这种结构时，所产生的转移图可以分解为具有集中递归的交互组件。我们开发了一种基于这种结构的精确高效的策略评估方法。这产生了一个可扩展的解决方案，适用于平均奖励和折扣奖励MDPs。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [667] [System Identification from Partial Observations under Adversarial Attacks](https://arxiv.org/abs/2504.00244)
> *对抗性攻击下部分观测的系统辨识*

*Jihun Kim, Javad Lavaei* | **Category: math.OC, cs.SY, eess.SY, 93B15, 93B30, 93C05** | **Updated: 2025-08-01**

**Keywords:** 系统辨识, 对抗性攻击, 部分观测, L1范数估计, 误差衰减

**Comment:** 8 pages, 3 figures

> **TL;DR:** 本文研究了在对抗性攻击下，从部分输出观测数据中辨识线性系统的问题，并提出了一个L1范数估计器，证明了其在任意攻击下对幂零系统的精确辨识能力，并将其推广到一般系统，证明了估计误差的指数衰减。

**AI_Comments:** 这项工作在对抗性攻击背景下对部分观测系统辨识进行了开创性的输入-输出分析。其创新之处在于提出了L1范数估计器，并证明了其在面对任意攻击时仍能实现精确辨识和指数级误差衰减的能力，这对于在不确定和敌对环境中进行系统建模具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在对抗性攻击存在的情况下，准确地从部分输出观测数据中估计真实系统的平衡截断模型，这是一个具有挑战性的问题。

**Method:** 首先，针对幂零系统，提出并证明了L1范数估计器能够精确辨识真实的马尔可夫参数矩阵。然后，将此结果推广到一般系统。

**Result:** 对于幂零系统，L1范数估计器在任何类型的攻击下都能精确辨识真实的马尔可夫参数矩阵。对于一般系统，估计误差随k的增长呈指数衰减。估计的平衡截断模型在相似变换下也显示出对真实系统辨识的指数衰减误差。

**Conclusion:** 该研究首次提供了在任意攻击下具有部分观测系统的输入-输出分析，并证明了所提出的方法在对抗性环境下进行系统辨识的有效性。

> **ai_Abstract:** 本研究解决了在对抗性攻击下从部分观测数据中辨识线性系统的问题。文章提出了一种L1范数估计器，并证明了其在任意攻击下对幂零系统马尔可夫参数矩阵的精确辨识能力。进一步，该方法被推广到一般系统，并证明了估计误差和平衡截断模型辨识误差的指数衰减特性。这是首次对在任意攻击下具有部分观测系统的输入-输出进行分析。

> **摘要翻译:** 本文关注部分观测线性系统的辨识问题，目标是从输出测量中获得真实系统k阶平衡截断的合理准确估计。我们考虑了在对抗性攻击下的系统辨识这一具有挑战性的情况，其中每个时间点发生攻击的概率为$\\Theta(1/k)$，而攻击的值是任意的。我们首先表明，在任何类型的攻击下，$\\ell_1$-范数估计器可以精确识别幂零系统的真实马尔可夫参数矩阵。然后，我们在此结果的基础上将其推广到一般系统，并表明估计误差随k的增长呈指数衰减。因此，估计的平衡截断模型在相似变换下显示出对真实系统辨识的指数衰减误差。这项工作首次提供了在任意攻击下具有部分观测系统的输入-输出分析。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [691] [Probabilistic Iterative Hard Thresholding for Sparse Learning](https://arxiv.org/abs/2409.01413)
> *稀疏学习的概率迭代硬阈值*

*Matteo Bergamaschi, Andrea Cristofari, Vyacheslav Kungurtsev, Francesco Rinaldi* | **Category: math.OC, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 稀疏学习, L0范数, 迭代硬阈值, 概率方法, 收敛性

**Comment:** 

> **TL;DR:** 本文提出了一种用于稀疏学习的概率迭代硬阈值方法，解决了大数据和噪声梯度环境下稀疏优化收敛性不足的问题，并通过理论证明和实验验证了其有效性。

**AI_Comments:** 该论文的创新点在于提出了一个在噪声大数据环境下，能够保证收敛性的概率迭代硬阈值方法，这对于稀疏学习在实际应用中的可靠性具有重要意义。它填补了现有文献在处理大规模、含噪数据时稀疏优化收敛性方面的空白。

<details>
  <summary>Details</summary>

**Motivation:** 在数据维度相对于样本量不利的统计建模中，发现隐藏的稀疏性对于构建准确的模型至关重要。L0范数是强制稀疏性的有效机制，但在大数据环境下，面对计算上必需的梯度噪声估计，缺乏可靠的收敛方法。

**Method:** 本文提出了一种解决具有基数约束的期望目标优化问题的方法，并证明了其底层随机过程的收敛性。

**Result:** 证明了所提出的随机过程的收敛性，并在两个机器学习问题上展示了其性能。

**Conclusion:** 该论文提出了一种针对稀疏学习的概率迭代硬阈值方法，解决了大数据和噪声梯度环境下稀疏优化收敛性不足的问题，并通过理论证明和实验验证了其有效性。

> **ai_Abstract:** 本文针对大数据和噪声梯度环境下稀疏学习中L0范数优化问题收敛性不足的挑战，提出了一种新的概率迭代硬阈值方法。该方法旨在解决具有基数约束的期望目标优化问题，并通过理论证明了其底层随机过程的收敛性。实验结果在两个机器学习问题上验证了该方法的有效性。

> **摘要翻译:** 对于统计建模，当数据维度相对于样本量不利时，发现真实数据中的隐藏稀疏性对于构建准确的统计模型至关重要。所谓的“L0范数”（计算向量中非零分量的数量）是一种强大可靠的机制，当将其纳入优化问题以最小化给定模型对一组观测值的拟合时，可以强制实现稀疏性。然而，在大数据环境中，由于计算需要必须评估梯度的噪声估计，关于可靠收敛方法的研究文献很少。在本文中，我们提出了一种解决具有基数约束的期望目标优化问题的方法。我们证明了底层随机过程的收敛性，并在两个机器学习问题上展示了其性能。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='mathst'></a>
## math.ST 

### [90] [Conformal changepoint localization](https://arxiv.org/abs/2505.00292)
> *共形变化点定位*

*Sanjit Dandapanthula, Aaditya Ramdas* | **Category: math.ST, eess.SP, stat.ME, stat.TH** | **Updated: 2025-08-01**

**Keywords:** 变化点定位, 共形预测, 置信区间, CONCH算法, 时间序列分析

**Comment:** 

> **TL;DR:** 提出CONCH算法，使用共形p值矩阵为数据序列中的单个变化点提供置信区间，适用于多种数据类型。

**AI_Comments:** 该论文提出了一种通用的变化点定位算法CONCH，其创新之处在于利用共形p值矩阵生成置信区间，且对数据分布的假设较为温和（可交换性）。其广泛适用性体现在能够处理不同类型的数据（图像、文本、加速度计）并与黑盒分类器结合，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 变化点定位是估计有序数据列表中数据生成分布发生变化的索引，或声明未发生变化的关键问题。

**Method:** 本文提出了CONCH（共形变化点定位）算法，该算法利用共形p值矩阵，在变化前和变化后分布各自可交换的温和假设下，为单个变化点生成置信区间。

**Result:** CONCH算法在各种合成和真实世界数据集上进行了示例验证，包括使用黑盒预训练分类器检测图像、文本和加速度计数据序列中的变化。

**Conclusion:** CONCH算法提供了一种在温和假设下定位单个变化点的通用方法，并已在多种数据类型上得到验证。

> **ai_Abstract:** 本文介绍了CONCH（共形变化点定位）算法，旨在解决数据序列中变化点定位的问题。该算法利用共形p值矩阵，在变化前后分布可交换的温和假设下，为单个变化点提供置信区间。CONCH算法已在多种合成和真实世界数据集上进行了验证，包括应用于图像、文本和加速度计数据，并能结合黑盒预训练分类器使用。

> **摘要翻译:** 标题：共形变化点定位
摘要：变化点定位是估计有序数据列表中数据生成分布发生变化的索引，或声明未发生变化的问题。我们提出了广泛适用的CONCH（共形变化点定位）算法，该算法使用共形p值矩阵，在变化前和变化后分布各自可交换的温和假设下，为（单个）变化点生成置信区间。我们在各种合成和真实世界数据集上对CONCH算法进行了示例验证，包括使用黑盒预训练分类器检测图像、文本和加速度计数据序列中的变化。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

### [101] [Constructive Disintegration and Conditional Modes](https://arxiv.org/abs/2508.00617)
> *构造性分解与条件众数*

*Nathaël Da Costa, Marvin Pförtner, Jon Cockayne* | **Category: math.ST, cs.LG, math.PR, stat.ML, stat.TH** | **Updated: 2025-08-01**

**Keywords:** 测度分解, 条件众数, 贝叶斯统计, 限制密度, 可微流形

**Comment:** 

> **TL;DR:** 本文提供了构建测度分解的数学工具，并揭示了限制密度与分解密度之间的差异。研究发现，“条件众数”通常与限制测度的众数而非分解测度的众数一致，并讨论了这两种方法在实践中的应用。

**AI_Comments:** 本文创新性地提供了一套用于构造测度分解的数学工具，并清晰地指出了限制密度与分解密度之间存在的关键性差异，这纠正了机器学习领域的一个常见误解。文章还对“条件众数”的概念进行了澄清，对于理解贝叶斯推断中的条件化操作具有重要意义。其贡献在于为理论和实践提供了更精确的指导。

<details>
  <summary>Details</summary>

**Motivation:** 在贝叶斯统计中，测度分解的构造因其定义的隐式性质而常常很困难。机器学习中的一种普遍观点将分解的构造与概率密度函数在与给定观测一致的事件子集上的限制混为一谈。此外，本文的动机还来源于近似贝叶斯推断和贝叶斯逆问题中的应用。

**Method:** 本文提供了一套全面的数学工具，用于构造分解，并将其应用于寻找可微流形上分解的密度。研究还进一步探讨了分解的众数。

**Result:** 研究提供了一个简单例子，表明限制密度和分解密度可能存在显著差异。结果显示，最近引入的“条件众数”概念通常不与通过分解获得的条件测度的众数一致，而是与限制测度的众数一致。

**Conclusion:** 分解密度和限制密度之间存在差异，并且“条件众数”通常与限制测度的众数而非分解测度的众数一致。实践中，根据建模上下文，这两种方法都具有实用性。

> **ai_Abstract:** 本文针对贝叶斯统计中测度分解构造的难题，提供了一套新的数学工具，并应用于可微流形上的密度计算。研究揭示了限制密度与分解密度之间的显著差异，并通过实例验证了这一点。此外，文章深入探讨了分解的众数，指出“条件众数”概念通常与限制测度的众数而非分解测度的众数相符。最后，文章讨论了这些差异的实际意义，并强调了在不同建模背景下两种方法的实用性。

> **摘要翻译:** 条件作用是贝叶斯统计中的核心操作，通过测度分解的概念形式化。然而，由于其定义的隐式性质，构造分解通常很困难。机器学习中的一个普遍结果将分解的构造与概率密度函数在与给定观测一致的事件子集上的限制混为一谈。我们提供了一套全面的数学工具，可用于构造分解，并将其应用于寻找可微流形上分解的密度。利用我们的结果，我们提供了一个令人不安的简单例子，其中限制密度和分解密度存在巨大差异。受近似贝叶斯推断和贝叶斯逆问题应用的启发，我们进一步研究了分解的众数。我们表明，最近引入的“条件众数”概念通常不与通过分解获得的条件测度的众数一致，而是与限制测度的众数一致。我们还讨论了这两种测度之间差异在实践中的含义，主张根据建模上下文，这两种方法都具有实用性。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [102] [New Pilot-Study Design in Functional Data Analysis](https://arxiv.org/abs/2508.00176)
> *功能数据分析中的新预研究设计*

*Ping-Han Huang, Ming-Hung Kao* | **Category: stat.ME, stat.AP** | **Updated: 2025-07-31**

**Keywords:** 功能数据分析, 预研究设计, 数据收集, 搜索算法, 轨迹恢复

**Comment:** 

> **TL;DR:** 本文提出了一种在功能数据分析中构建预研究设计的新框架和搜索算法，旨在提高数据收集效率，支持准确的轨迹恢复和有效的未来研究规划。

**AI_Comments:** 本文的创新之处在于关注了以往研究中较少被探讨的预研究设计本身，而非仅仅优化个体测量时间点。其提出的框架和搜索算法为功能数据分析中面临数据收集挑战的研究提供了实用且高效的解决方案，尤其在资源受限场景下具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在应用研究中，高效的数据收集至关重要，尤其是在功能数据分析背景下，频繁测量成本高昂、耗时或繁重，且每个受试者只能在少数时间点被观察。现有设计方法主要关注为个体受试者选择最佳时间点，通常依赖于从预研究中估计的模型参数，但预研究本身的设计却很少受到关注。

**Method:** 本文提出了一个构建预研究设计的框架，该框架支持准确的轨迹恢复和未来设计的有效规划。开发了一种搜索算法来生成高质量的预研究设计。

**Result:** 模拟研究和实际数据应用表明，本文提出的方法优于常用替代方案。

**Conclusion:** 本文提出的方法在资源有限的环境中具有重要价值，因为它能支持准确的轨迹恢复和未来设计的有效规划，并超越了常用替代方案。

> **ai_Abstract:** 本研究解决了功能数据分析中预研究设计受关注不足的问题。文章提出了一个新颖的框架和搜索算法，用于构建高质量的预研究设计，以支持精确的轨迹恢复和未来研究的有效规划。模拟和实际数据应用均表明，该方法优于现有常用替代方案，尤其适用于资源受限的环境。

> **摘要翻译:** 高效的数据收集在应用研究中至关重要，尤其是在功能数据分析背景下，频繁测量成本高昂、耗时或繁重。由于实际限制，在功能数据设置中，每个受试者仅在少数时间点被观察，这一挑战尤为突出。大多数现有设计方法侧重于为个体受试者选择最佳时间点，通常依赖于从预研究中估计的模型参数。然而，预研究本身的设计受到的关注有限。我们提出了一个构建预研究设计的框架，该框架支持准确的轨迹恢复和未来设计的有效规划。开发了一种搜索算法来生成高质量的预研究设计。模拟研究和实际数据应用表明，我们的方法优于常用替代方案，突出了其在资源有限环境中的价值。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [703] [Bayesian CART models for aggregate claim modeling](https://arxiv.org/abs/2409.01908)
> *用于总赔付建模的贝叶斯 CART 模型*

*Yaojun Zhang, Lanpeng Ji, Georgios Aivaliotis, Charles C. Taylor* | **Category: stat.ME, cs.LG, q-fin.ST, stat.AP, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 贝叶斯 CART 模型, 总赔付建模, 频率-严重性模型, 序列模型, 联合模型, 威布尔分布

**Comment:** 

> **TL;DR:** 本文提出了三种贝叶斯 CART (BCART) 模型（频率-严重性模型、序列模型和联合模型）用于总赔付金额建模。研究发现威布尔分布在捕获尾部特征方面优于伽马和对数正态分布，并且考虑索赔数量和平均严重性之间依赖关系的序列和联合 BCART 模型优于假设独立性的频率-严重性模型。

**AI_Comments:** 这项研究在总赔付建模领域引入了创新的贝叶斯 CART 方法，特别是在处理多变量响应和重尾数据方面。其创新之处在于提出了一个通用的 BCART 框架，并深入比较了不同分布和模型结构的影响。发现威布尔分布在捕获尾部特征上的优势以及考虑依赖关系的序列和联合模型的优越性，为保险精算和风险管理提供了更精确和稳健的工具，具有重要的实践意义。该研究通过严谨的模拟和真实数据验证，增加了其结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出并评估多种贝叶斯 CART (BCART) 模型，以更好地对总赔付金额进行建模，特别是为了处理多变量响应数据以及索赔严重性数据的偏斜和重尾特性，并探究不同模型结构和分布选择对建模效果的影响。

**Method:** 本文提出了三种类型的贝叶斯 CART (BCART) 模型：频率-严重性模型、序列模型和联合模型，用于总赔付金额建模。作者提出了一种适用于多变量响应数据的 BCART 模型通用框架，尤其适用于具有索赔数量和总赔付金额双变量响应的联合 BCART 模型。为了促进频率-严重性建模，通过使用各种分布（如威布尔、伽马和对数正态分布）研究了用于右偏和重尾索赔严重性数据的 BCART 模型。模型的有效性通过精心设计的模拟和真实保险数据进行验证。

**Result:** 研究发现，在用于右偏和重尾索赔严重性数据的 BCART 模型中，威布尔分布由于其能够捕获树模型中不同的尾部特征，优于伽马和对数正态分布。此外，发现考虑索赔数量和平均严重性之间依赖关系的序列 BCART 模型和联合 BCART 模型是有益的，因此优于假设独立性的频率-严重性 BCART 模型。

**Conclusion:** 威布尔分布在处理索赔严重性数据的尾部特征方面表现出色，并且纳入索赔数量与平均严重性之间依赖关系的序列和联合 BCART 模型在总赔付建模中优于假设独立性的频率-严重性模型，为总赔付建模提供了更有效的工具。

> **ai_Abstract:** 本文针对总赔付金额建模提出了三种贝叶斯 CART (BCART) 模型：频率-严重性、序列和联合模型。研究引入了一个适用于多变量响应的通用 BCART 框架，特别强调了处理索赔数量和总赔付金额双变量响应的联合模型。在处理右偏和重尾索赔严重性数据时，研究发现威布尔分布在捕获尾部特征方面优于伽马和对数正态分布。此外，结果表明，考虑索赔数量与平均严重性之间依赖关系的序列和联合 BCART 模型优于假设独立性的频率-严重性模型。模型效能通过模拟和实际保险数据得到验证。

> **摘要翻译:** 本文提出了三种贝叶斯 CART (BCART) 模型用于总赔付金额建模，即频率-严重性模型、序列模型和联合模型。我们提出了一个适用于多变量响应数据的 BCART 模型通用框架，这对于具有双变量响应（索赔数量和总赔付金额）的联合 BCART 模型特别有用。为了促进频率-严重性建模，我们通过使用各种分布研究了用于右偏和重尾索赔严重性数据的 BCART 模型。我们发现威布尔分布优于伽马和对数正态分布，因为它能够在树模型中捕获不同的尾部特征。此外，我们发现纳入索赔数量和平均严重性之间依赖关系的序列 BCART 模型和联合 BCART 模型是有益的，因此优于假设独立性的频率-严重性 BCART 模型。这些模型性能的有效性通过精心设计的模拟和真实保险数据进行了说明。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [109] [On the Undecidability of Tiling the $3$-dimensional Space with a Set of $3$ Polycubes](https://arxiv.org/abs/2508.00192)
> *关于用三维空间中的一组3个多方体进行平铺的不可判定性*

*Chao Yang, Zhujun Zhang* | **Category: math.CO, cs.CG, math.MG** | **Updated: 2025-07-31**

**Keywords:** 平移平铺, 不可判定性, 多方体, 三维空间, 平铺问题

**Comment:** in Chinese language

> **TL;DR:** 证明了用3个多方体平铺3维空间是不可判定的。

**AI_Comments:** 这项工作在平铺理论中取得了重要进展，通过在固定维度（3维）和极少数量（3个）瓦片的情况下证明了平移平铺的不可判定性，这对于推动解决关于固定维度下单瓦片平铺不可判定性的重要猜想具有显著意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过在固定维度空间中使用尽可能少量的k个平铺块来证明平移平铺的不可判定性，从而为解决“存在一个固定维度n使得单个平铺块的平移平铺是不可判定的”这一猜想提供策略和支持。

**Method:** 通过展示（证明）用一组3个多方体平铺3维空间是不可判定的。

**Result:** 结果表明，用一组3个多方体平铺3维空间是不可判定的。

**Conclusion:** 用一组3个多方体平铺3维空间是不可判定的，这为解决“存在一个固定维度n使得单个平铺块的平移平铺是不可判定的”这一猜想提供了新的证据和方向。

> **ai_Abstract:** 本文证明了用一组3个多方体对3维空间进行平移平铺是不可判定的。这项工作是解决“存在一个固定维度n使得单个瓦片的平移平铺是不可判定的”这一猜想的重要一步，通过在固定维度和有限数量瓦片的情况下证明了不可判定性。

> **摘要翻译:** 平移平铺问题是所有数学领域中最基本、最具代表性的不可判定问题之一。近年来，格林菲尔德和陶在平移平铺的不可判定性方面取得了两个显著成果。一个是在足够大维度空间中存在非周期性单瓦片。另一个是空间周期子集的平移平铺的不可判定性（前提是空间维度是输入的一部分）。这两个结果支持以下猜想：存在一个固定维度n，使得单个瓦片的平移平铺是不可判定的。解决这个猜想的一种策略是，对于尽可能小的正整数k，证明用一组k个瓦片平铺固定维度空间的平移平铺是不可判定的。本文表明，用一组3个多方体平铺3维空间是不可判定的。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

### [132] [chipfiring: A Python Package for Efficient Mathematical Analysis of Chip-Firing Games on Multigraphs](https://arxiv.org/abs/2508.00269)
> *chipfiring：一个用于多重图上筹码博弈高效数学分析的Python包*

*Dhyey Dharmendrakumar Mavani, Tairan Ji, Nathan Pflueger* | **Category: math.CO, cs.CG, cs.MS, math.AG** | **Updated: 2025-08-04**

**Keywords:** 筹码博弈, Python包, 图论, 组合学, 数学分析

**Comment:** 

> **TL;DR:** `chipfiring` 是一个Python包，用于高效分析有限图上的筹码博弈，提供定义图、执行操作和分析博弈属性的工具。

**AI_Comments:** `chipfiring`包的创新之处在于其专注于筹码博弈这一特定且复杂的数学领域，并提供了高效且专门化的工具，填补了通用图库在此领域的空白。其面向对象的设计和对核心算法（如Dhar算法）的优化实现，使其成为相关领域研究的重要资源。

<details>
  <summary>Details</summary>

**Motivation:** 针对图论、组合学和代数几何领域的研究人员和学生，提供一个用于筹码博弈数学分析的综合性Python包，以探索这些丰富的数学模型。

**Method:** 开发了一个名为`chipfiring`的Python包，它提供定义图和筹码配置、执行筹码操作以及分析赢利性、线性等价性和除数秩等基本属性的工具。该包包含面向对象的图和除数实现、集成的拉普拉斯矩阵计算以及Dhar算法的有效实现。

**Result:** `chipfiring` 包为图论、组合学和代数几何领域的研究人员和学生提供了一个强大的工具包，能够高效地进行筹码博弈的数学分析，并提供了探索这些数学模型所需的关键算法和数据结构。

**Conclusion:** `chipfiring` 包是一个全面的Python工具，专门为筹码博弈的数学分析而设计，通过提供高效的算法和数据结构，极大地便利了相关领域的研究和学习。

> **ai_Abstract:** `chipfiring`是一个新颖的Python包，专门设计用于有限图上的筹码博弈的数学分析。它提供了一套全面的工具，包括图和筹码配置的定义、筹码操作的执行以及赢利性、线性等价和除数秩等关键属性的分析。该包集成了面向对象的设计、拉普拉斯矩阵计算和Dhar算法，旨在为图论、组合学和代数几何领域的学生和研究人员提供高效且专业的数学模型探索工具。

> **摘要翻译:** 本文介绍了一个名为`chipfiring`的综合性Python包，用于有限图上筹码博弈的数学分析。该包提供了一个强大的工具包，用于定义图和筹码配置（除数），执行筹码操作，并分析基本属性，如可赢性、线性等价性和除数秩。我们详细介绍了该库的核心组件，包括其面向对象的图和除数实现、集成的拉普拉斯矩阵计算，以及Dhar算法的高效实现，用于确定美元博弈的可解性。`chipfiring`包专为图论、组合学和代数几何领域的研究人员和学生设计，为探索这些丰富的数学模型提供了必要的算法和数据结构。我们描述了该库的架构，通过全面的示例说明了其用法，并强调了其与通用图库相比的特殊贡献。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

### [354] [Clubs in projective spaces and three-weight rank-metric codes](https://arxiv.org/abs/2508.00502)
> *射影空间中的俱乐部与三权重秩度量码*

*Jonathan Mannaert, Paolo Santonastaso, Ferdinando Zullo* | **Category: math.CO, cs.IT, math.IT** | **Updated: 2025-08-01**

**Keywords:** i-俱乐部, 射影空间, 秩度量码, 线性集, MacWilliams恒等式

**Comment:** 

> **TL;DR:** 本文深入研究了高维射影空间中i-俱乐部及三权重秩度量码的几何与代数结构，并提供了新的构造和分类结果。

**AI_Comments:** 本文创新性地将高维射影空间中的i-俱乐部与秩度量码联系起来，通过严谨的代数和几何分析，填补了该领域在高维空间理解上的空白。其贡献在于不仅提供了理论上的上限和分类，还给出了具体的构造方法，对有限几何和编码理论具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 线性集在有限几何和编码理论中是核心对象，其中i-俱乐部在射影线上已被广泛研究，但在高维射影空间中却知之甚少，因此本文旨在填补这一空白。

**Method:** 通过将i-俱乐部与秩度量码关联并利用MacWilliams恒等式分析其参数，建立了秩的上限。提供了达到最大秩的i-俱乐部显式构造，并证明了非等价构造的存在。对i=m-1的特殊情况进行了完全分类。此外，还从俱乐部探索了三权重秩度量码的几何，并提供了新的构造和部分分类结果。

**Result:** 建立了i-俱乐部秩的上限；提供了i ≥ m/2时达到最大秩的i-俱乐部显式构造；证明了i ≤ m-2时非等价构造的存在；完全分类了i=m-1的特殊情况；从俱乐部探索了三权重秩度量码的几何，并提供了新的构造和部分分类结果。

**Conclusion:** 本文深入研究了高维射影空间中的i-俱乐部及其与秩度量码的联系，提供了新的理论进展和构造方法，尤其是在理解i-俱乐部结构和三权重秩度量码方面取得了重要成果。

> **ai_Abstract:** 本文深入研究了高维射影空间中i-俱乐部的几何和代数结构，这类线性集除了一个权重为i的点外所有点权重都为一。研究通过将其与秩度量码关联，并利用MacWilliams恒等式建立了其秩的上限，并提供了特定条件下i-俱乐部的显式构造和分类。此外，论文还探索了三权重秩度量码的几何，并提出了新的构造方法和分类结果。

> **摘要翻译:** 有限域上的线性集是有限几何和编码理论中的核心对象，与半域、阻塞集、KM-弧和秩度量码等结构有着深刻的联系。其中，i-俱乐部是一类线性集，除了一个权重为i的点外，所有点的权重都为一。它们在射影线上已被广泛研究，但在高维射影空间中仍然知之甚少。在本文中，我们研究了射影空间中i-俱乐部的几何和代数结构。我们通过将它们与秩度量码关联并利用MacWilliams恒等式分析其参数，建立了它们秩的上限。我们还提供了当i ≥ m/2时达到最大秩的i-俱乐部的显式构造，并证明了当i ≤ m-2时非等价构造的存在。特殊情况i = m-1已完全分类。此外，我们探索了三权重秩度量码的丰富几何结构，提供了来自俱乐部的新构造和部分分类结果。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='q-finrm'></a>
## q-fin.RM 

### [126] [Singular Control in a Cash Management Model with Ambiguity](https://arxiv.org/abs/2309.12014)
> *模糊性下现金管理模型中的奇点控制*

*Arnon Archankul, Giorgio Ferrari, Tobias Hellmann, Jacco J. J. Thijssen* | **Category: q-fin.RM, math.OC, q-fin.MF** | **Updated: 2025-08-01**

**Keywords:** 奇点控制, 现金管理, 模糊性, 最大最小偏好, Dynkin博弈

**Comment:** 

> **TL;DR:** 本文研究了在模糊性下的现金储备管理奇点控制模型，发现模糊性的增加会导致更高的预期成本和更窄的不作为区域，这为观察到的现金管理行为提供了模糊性驱动的解释。

**AI_Comments:** 本文的创新之处在于将奇点控制理论应用于模糊性下的现金管理，并引入了管理者最大最小偏好。研究发现模糊性会缩小不作为区域，这为理解现实世界中企业的现金管理行为提供了重要的理论解释。该模型具有较强的普适性，可扩展至其他库存管理问题。

<details>
  <summary>Details</summary>

**Motivation:** 在模糊性环境下，管理者如何进行现金储备管理，以及模糊性对最优现金策略和成本的影响。

**Method:** 采用奇点控制模型分析现金储备管理，并假设管理者对先验集具有最大最小偏好（$\\kappa$-无知）。通过建立验证定理确定成本函数和最优现金政策（控制障碍政策）。在算术布朗运动驱动的模型中，使用Dynkin博弈来分析模糊性的影响。

**Result:** 模糊性的增加会导致在最坏情况先验下产生更高的预期成本，并导致不作为区域变窄。

**Conclusion:** 模糊性可以为观察到的现金管理行为提供一个由模糊性驱动的解释。研究结果也可应用于更广泛的模糊性下库存管理的奇点控制问题。

> **ai_Abstract:** 本文研究了一个在模糊性下由扩散过程驱动的现金储备管理奇点控制模型。模型假设管理者对先验集具有最大最小偏好。通过建立验证定理，确定了公司的成本函数和最优现金政策为控制障碍政策。研究发现，在算术布朗运动驱动的模型中，模糊性的增加会导致最坏情况先验下的预期成本升高，同时使不作为区域变窄。这一发现为解释实际中观察到的现金管理行为提供了模糊性驱动的视角，并可推广应用于模糊性下的库存管理问题。

> **摘要翻译:** 我们考虑一个在模糊性下由扩散过程驱动的现金储备管理奇点控制模型。假设管理者对以 $\\kappa$-无知为特征的先验集具有最大最小偏好。建立了一个验证定理来确定公司的成本函数和最优现金政策；后者采取控制障碍政策的形式。在由算术布朗运动驱动的模型中，我们使用 Dynkin 博弈来表明模糊性的增加导致最坏情况先验下的预期成本更高，以及不作为区域变窄。后一种效应可以用来为观察到的现金管理行为提供一个由模糊性驱动的解释。我们的发现可以应用于更广泛的模糊性下库存管理的奇点控制应用。

</details>

[⬆️ 返回分类顶部](#q-finrm) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [140] [A Large Sensor Foundation Model Pretrained on Continuous Glucose Monitor Data for Diabetes Management](https://arxiv.org/abs/2412.09727)
> *用于糖尿病管理的连续血糖监测数据预训练的大型传感器基础模型*

*Junjie Luo, Abhimanyu Kumbara, Mansur Shomali, Rui Han, Anand Iyer, Ritu Agarwal, Gordon Gao* | **Category: q-bio.QM, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 连续血糖监测, 大型传感器模型, 糖尿病管理, 血糖预测, 基础模型

**Comment:** 

> **TL;DR:** CGM-LSM是一个基于Transformer的大型传感器模型，通过预训练海量CGM数据，显著提高了血糖预测的准确性和泛化能力，为糖尿病管理提供了新范式。

**AI_Comments:** 该研究的创新点在于将大型语言模型的自回归范式引入到传感器数据（CGM）处理中，构建了一个大规模预训练的基础模型。这显著提升了血糖预测的准确性和跨患者群体的泛化能力，为个性化糖尿病管理提供了强大的AI支持。其重要性在于为医疗健康领域的大型基础模型开发提供了新的思路和成功案例。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有血糖预测模型都是针对特定任务的，并且缺乏跨患者群体的泛化能力。

**Method:** 本文引入了CGM-LSM，一个基于Transformer解码器的大型传感器模型（LSM）。该模型在来自不同糖尿病类型、年龄和性别的患者的160万条CGM记录上进行了预训练，将患者建模为葡萄糖时间步序列，以学习CGM数据中嵌入的潜在知识，并将其应用于2小时内的葡萄糖读数预测。

**Result:** 与现有方法相比，CGM-LSM显著提高了预测准确性和鲁棒性：在一小时预测中，均方根误差降低了48.51%；在未见过的患者组中，零样本预测性能保持一致。模型性能在不同患者亚组和预测场景中进行了分析。

**Conclusion:** CGM-LSM通过大规模预训练和Transformer架构，显著提升了血糖预测的准确性和泛化性，为推进CGM基础模型奠定了基础，并指出了未来的机遇和挑战。

> **ai_Abstract:** 本文提出了CGM-LSM，一个基于Transformer解码器的大型传感器模型，旨在解决现有血糖预测模型泛化能力差的问题。该模型在160万条CGM记录上进行预训练，通过将患者建模为葡萄糖时间步序列来学习数据中的潜在知识。实验结果表明，CGM-LSM在血糖预测的准确性和鲁棒性方面均显著优于现有方法，尤其是在减少均方根误差和实现零样本预测方面表现突出，为糖尿病管理提供了更有效的工具。

> **摘要翻译:** 连续血糖监测（CGM）与人工智能相结合，通过实时血糖预测为主动式糖尿病管理提供了新的机会。然而，大多数现有模型都是针对特定任务的，并且缺乏跨患者群体的泛化能力。受大型语言模型自回归范式的启发，我们引入了CGM-LSM，一个基于Transformer解码器的大型传感器模型（LSM），它在来自不同糖尿病类型、年龄和性别的患者的160万条CGM记录上进行了预训练。我们将患者建模为葡萄糖时间步序列，以学习CGM数据中嵌入的潜在知识，并将其应用于2小时内的葡萄糖读数预测。与现有方法相比，CGM-LSM显著提高了预测准确性和鲁棒性：在一小时预测中，均方根误差降低了48.51%，并在未见过的患者组中保持一致的零样本预测性能。我们分析了模型性能在不同患者亚组和预测场景中的变化，并概述了推进CGM基础模型的关键机遇和挑战。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [697] [Numerical Uncertainty in Linear Registration: An Experimental Study](https://arxiv.org/abs/2508.00781)
> *线性配准中的数值不确定性：一项实验研究*

*Niusha Mirhakimi, Yohan Chatelain, Jean-Baptiste Poline, Tristan Glatard* | **Category: q-bio.QM, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 线性配准, 数值不确定性, 蒙特卡洛算术, MRI, 稳定性

**Comment:** 

> **TL;DR:** 该研究使用蒙特卡洛算术（MCA）模拟评估了MRI线性配准工具（SPM、FSL、ANTs）的数值不确定性，发现SPM最稳定，并提出数值不确定性度量可支持自动质量控制。

**AI_Comments:** 该研究解决了MRI预处理中一个关键但未被充分研究的领域——线性配准的数值不确定性。通过采用蒙特卡洛算术模拟，提供了一种量化和比较不同工具和参数组合下稳定性的严谨方法。研究结果不仅为用户选择合适的配准工具提供了实用的指导（例如SPM的相对高稳定性），还揭示了某些工具（如ANTs）在数值扰动下的潜在脆弱性。更重要的是，它提出了利用数值不确定性度量进行自动化质量控制的创新思路，这对于大规模数据处理具有重要意义。同时，发现稳定性结果在健康和临床人群之间具有通用性，也增强了研究的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 线性配准是MRI预处理流程中的关键步骤，但其数值不确定性尚未得到充分研究。

**Method:** 本研究使用蒙特卡洛算术（MCA）模拟，评估了主要软件包（SPM、FSL和ANTs）中最常用的线性配准工具。评估涵盖了多种图像相似性度量、两种脑模板，以及健康对照组（HC，n=50）和帕金森病（PD，n=50）队列。

**Result:** 研究发现线性配准工具和相似性度量对数值稳定性有影响。在评估的工具中，使用默认相似性度量时，SPM表现出最高的稳定性。FSL和ANTs显示出更大且相似的变异范围，其中ANTs对数值扰动特别敏感，偶尔会导致配准失败。此外，健康对照组和PD队列之间未观察到显著差异。数值不确定性度量可能支持线性配准结果的自动化质量控制。

**Conclusion:** 本研究的实验结果表征了线性配准的数值稳定性，并可作为未来不确定性分析的基础。健康受试者获得的数值稳定性分析结果可能推广到临床人群。

> **ai_Abstract:** 本研究旨在评估MRI预处理中常用线性配准工具（SPM、FSL、ANTs）的数值不确定性。通过蒙特卡洛算术模拟，研究人员在不同相似性度量、脑模板以及健康和帕金森病队列上进行了测试。结果显示，线性配准工具和相似性度量显著影响数值稳定性，其中SPM表现出最高稳定性，而ANTs对数值扰动敏感。研究还发现，健康和帕金森病队列之间的稳定性无显著差异，表明健康受试者的分析结果可推广至临床人群。此外，数值不确定性度量被证明可用于线性配准结果的自动化质量控制。这项工作为未来的不确定性分析奠定了基础。

> **摘要翻译:** 虽然线性配准是MRI预处理流程中的关键步骤，但其数值不确定性尚未得到充分研究。本研究使用蒙特卡洛算术（MCA）模拟，评估了主要软件包（SPM、FSL和ANTs）中最常用的线性配准工具，涵盖了多种图像相似性度量、两种脑模板，以及健康对照组（HC，n=50）和帕金森病（PD，n=50）队列。我们的研究结果突出了线性配准工具和相似性度量对数值稳定性的影响。在评估的工具中，使用默认相似性度量时，SPM表现出最高的稳定性。FSL和ANTs显示出更大且相似的变异范围，其中ANTs对数值扰动特别敏感，偶尔会导致配准失败。此外，健康对照组和PD队列之间未观察到显著差异，这表明健康受试者获得的数值稳定性分析结果可能推广到临床人群。最后，我们还展示了数值不确定性度量如何支持线性配准结果的自动化质量控制（QC）。总的来说，我们的实验结果通过实验表征了线性配准的数值稳定性，并可作为未来不确定性分析的基础。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [145] [The Repeated-Stimulus Confound in Electroencephalography](https://arxiv.org/abs/2508.00531)
> *脑电图中的重复刺激混淆*

*Jack A. Kilgallen, Barak A. Pearlmutter, Jeffrey Mark Siskind* | **Category: q-bio.NC, cs.CV, 62K99, 68T05** | **Updated: 2025-08-01**

**Keywords:** 神经解码, 重复刺激混淆, 脑电图, 性能高估, 伪科学

**Comment:** 15 pages, 6 figures, 8 tables, in submission to IEEE

> **TL;DR:** 神经解码研究中，重复刺激混淆导致模型性能被高估，甚至可能支持伪科学主张。

**AI_Comments:** 这篇论文揭示了神经解码研究中一个重要的、此前可能被忽视的评估陷阱。其创新之处在于明确定义了“重复刺激混淆”，并通过实证实验量化了其对模型性能高估的影响，并指出其可能导致的伪科学风险。这对于提高神经科学和机器学习交叉领域研究的严谨性和可信度具有重要意义，提醒研究者在设计实验和评估模型时需特别注意数据独立性。

<details>
  <summary>Details</summary>

**Motivation:** 在神经解码研究中，为满足深度学习模型对大数据集的需求，一些研究会重复向同一参与者呈现相同的刺激。然而，当解码模型在相同刺激的响应上进行训练和评估时，刺激身份会成为准确性的混淆因素，导致模型性能被高估。

**Method:** 作者识别了一个易受重复刺激混淆影响的数据集和16篇相关出版物。他们使用受影响研究中的模型进行实验，以调查文献中结果被错误报告的程度。此外，他们还进行了进一步实验，探讨该混淆在其他情境中的影响。

**Result:** 研究发现，受影响模型的解码准确率被高估了4.46%至7.42%。分析还表明，在混淆条件下，准确率每增加1%，高估幅度就会增加0.26%。

**Conclusion:** 重复刺激混淆不仅导致对解码性能的乐观估计，还损害了受影响出版物中多项主张的有效性，甚至可以被用来证明伪科学主张（如超感官知觉）的合理性。

> **ai_Abstract:** 本文揭示了神经解码研究中存在的“重复刺激混淆”问题。由于深度学习模型对数据的需求，一些研究会重复呈现刺激以增加训练数据量，导致模型在相同刺激上训练和评估时，刺激身份成为准确性的混淆因素。作者通过实验发现，受此混淆影响的模型解码准确率被高估了4.46%-7.42%，并指出该混淆可能损害研究结论的有效性，甚至可被用于支持伪科学主张。

> **摘要翻译:** 在神经解码研究中，参与者对刺激的反应记录被用于训练模型。近年来，深度学习研究的创新应用于神经解码研究的出版物数量激增。这些实验中使用的数据密集型模型导致对越来越大数据集的需求。因此，在一些研究中，为了增加可用于模型训练的试验次数，同一刺激会多次呈现给每个参与者。然而，当解码模型在相同刺激的反应上进行训练和评估时，刺激身份就成为了准确性的混淆因素。我们称之为重复刺激混淆。我们识别了一个易受影响的数据集和16篇报告模型性能基于受该混淆影响的评估程序的出版物。我们使用受影响研究中的模型进行了实验，以调查文献中结果被错误报告的可能性程度。我们的发现表明，这些模型的解码准确率被高估了4.46%至7.42%。我们的分析还表明，在混淆条件下，准确率每增加1%，高估幅度就会增加0.26%。这种混淆不仅导致对解码性能的乐观估计，而且损害了受影响出版物中提出的几项主张的有效性。我们进行了进一步的实验，以调查该混淆在其他情境中的影响。我们发现，受影响研究中使用的相同方法也可以用来证明一系列伪科学主张的合理性，例如超感官知觉的存在。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='hep-ph'></a>
## hep-ph 

### [250] [Anomaly detection with spiking neural networks for LHC physics](https://arxiv.org/abs/2508.00063)
> *基于脉冲神经网络的LHC物理异常检测*

*Barry M. Dillon, Jim Harkin, Aqib Javed* | **Category: hep-ph, cs.NE, hep-ex** | **Updated: 2025-07-31**

**Keywords:** 异常检测, 脉冲神经网络, 大型强子对撞机, 自编码器, LHC物理

**Comment:** 24 pages, 15 figures, 1 table

> **TL;DR:** 本文研究了使用脉冲神经网络（SNN）构建的自编码器在大型强子对撞机（LHC）物理中进行异常检测，结果显示其性能与传统自编码器相当，且适用于低延迟、低功耗环境。

**AI_Comments:** 该研究的创新之处在于将脉冲神经网络（SNNs）应用于LHC的异常检测，利用了SNNs在低延迟、低功耗和实时推理方面的固有优势，尤其是在FPGA和专用神经形态硬件上的潜力。这为LHC数据处理和新物理发现提供了一种有前景的替代方案，解决了传统方法可能面临的计算和延迟挑战。

<details>
  <summary>Details</summary>

**Motivation:** 在大型强子对撞机（LHC）中发现新物理，并通过异常检测工具捕获传统选择标准可能丢弃的信号，同时满足严格的延迟和计算约束。

**Method:** 设计和评估了一个简单的SNN自编码器架构，并使用CMS ADC2021数据集进行训练和测试。该方法利用脉冲神经网络（SNNs）的特性，使其适用于低延迟、低内存和实时推理，特别是在FPGA上。

**Result:** SNN自编码器在LHC异常检测方面，对于所有信号模型，其性能与传统自编码器相当。

**Conclusion:** 脉冲神经网络（SNN）自编码器是LHC物理中异常检测的有效且具有竞争力的替代方案，尤其适用于需要低延迟和低计算资源的环境。

> **ai_Abstract:** 本文探讨了使用脉冲神经网络（SNN）构建的自编码器在大型强子对撞机（LHC）物理异常检测中的应用。研究表明，SNN自编码器在低延迟、低内存的LHC触发级应用中表现出与传统自编码器相当的性能，为发现新物理提供了有效工具，并受益于神经形态硬件的发展。

> **摘要翻译:** 异常检测为在大型强子对撞机（LHC）中发现新物理提供了一种有前景的策略。本文为此目的研究了使用神经形态脉冲神经网络（SNNs）构建的自编码器。一个关键应用是在触发级别，异常检测工具可以捕获传统选择标准会丢弃的信号。这些系统必须在严格的延迟和计算约束下运行。SNNs天生就非常适合低延迟、低内存、实时推理，特别是在现场可编程门阵列（FPGAs）上。随着专用神经形态硬件的快速发展，预计将获得进一步的收益。我们使用CMS ADC2021数据集，设计并评估了一个简单的SNN自编码器架构。我们的结果表明，SNN自编码器在所有信号模型上，对于LHC异常检测与传统自编码器具有竞争力。

</details>

[⬆️ 返回分类顶部](#hep-ph) | [⬆️ 返回总目录](#toc)

---

### [258] [Jet Image Generation in High Energy Physics Using Diffusion Models](https://arxiv.org/abs/2508.00250)
> *高能物理中基于扩散模型的射流图像生成*

*Victor D. Martinez, Vidya Manian, Sudhir Malik* | **Category: hep-ph, cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 扩散模型, 射流图像生成, 高能物理, 一致性模型, 大型强子对撞机

**Comment:** The paper is under review at IEEE Transactions in Nuclear Science

> **TL;DR:** 本文首次将扩散模型应用于生成大型强子对撞机质子-质子碰撞事件的射流图像，并发现一致性模型在图像生成质量和稳定性上优于基于分数的扩散模型。

**AI_Comments:** 这篇论文的创新点在于首次将扩散模型引入高能物理领域，用于生成LHC的射流图像，这代表了生成模型在该领域应用的一个重要进展。其直接在图像空间操作的方法与传统基于潜在分布的方法不同，并成功验证了一致性模型在生成质量和稳定性上的优势，为高能物理数据分析提供了高效准确的新工具。

<details>
  <summary>Details</summary>

**Motivation:** 本文首次在高能物理领域应用扩散模型来生成大型强子对撞机质子-质子碰撞事件的射流图像，旨在提高射流图像生成的计算效率和准确性。

**Method:** 将JetNet模拟数据集中的夸克、胶子、W玻色子、Z玻色子和顶夸克射流的运动学变量映射为二维图像表示。在此图像上训练扩散模型以学习射流组成的空间分布。比较了基于分数的扩散模型和一致性模型在生成类别条件射流图像方面的性能，该方法直接在图像空间中操作。使用Fréchet Inception Distance (FID) 等指标评估生成图像的保真度。

**Result:** 评估结果表明，一致性模型在生成图像的保真度和生成稳定性方面优于基于分数的扩散模型。这些进展显著提高了计算效率和生成精度。

**Conclusion:** 扩散模型，特别是一致性模型，能够有效且高保真地生成高能物理中的射流图像，为高能物理研究提供了有价值的工具。

> **ai_Abstract:** 本文首次将扩散模型应用于高能物理中的射流图像生成，通过将射流的运动学变量转换为二维图像，并训练扩散模型学习其空间分布。研究比较了基于分数的扩散模型和一致性模型，发现一致性模型在生成图像的保真度和稳定性方面表现更优。该方法直接在图像空间操作，提高了计算效率和生成精度，为高能物理研究提供了新工具。

> **摘要翻译:** 本文首次介绍了扩散模型在生成大型强子对撞机（LHC）质子-质子碰撞事件对应射流图像中的应用。来自JetNet模拟数据集的夸克、胶子、W玻色子、Z玻色子和顶夸克射流的运动学变量被映射到二维图像表示。扩散模型在这些图像上进行训练，以学习射流组成的空间分布。我们比较了基于分数的扩散模型和一致性模型在准确生成类别条件射流图像方面的性能。与基于潜在分布的方法不同，我们的方法直接在图像空间中操作。使用包括Fréchet Inception Distance（FID）在内的多项指标评估了生成图像的保真度，结果表明一致性模型比基于分数的扩散模型实现了更高的保真度和生成稳定性。这些进步显著提高了计算效率和生成精度，为高能物理（HEP）研究提供了有价值的工具。

</details>

[⬆️ 返回分类顶部](#hep-ph) | [⬆️ 返回总目录](#toc)

---

### [405] [Discovering the underlying analytic structure within Standard Model constants using artificial intelligence](https://arxiv.org/abs/2507.00225)
> *使用人工智能发现标准模型常数中的底层解析结构*

*S. V. Chekanov, H. Kjellerstrand* | **Category: hep-ph, cs.AI, physics.data-an** | **Updated: 2025-08-01**

**Keywords:** 标准模型, 符号回归, 遗传编程, 解析结构, 人工智能

**Comment:** 16 pages, 5 tables

> **TL;DR:** 本文利用符号回归和遗传编程，使用AI发现标准模型常数之间简单的解析关系，精度优于1%。

**AI_Comments:** 本文的创新之处在于首次将符号回归和遗传编程等AI技术应用于探索标准模型基本常数之间的数学关系。其重要性在于提供了一种新的方法论，可能有助于揭示物理学中的基本定律，并为统一场论等理论提供实验或计算线索。

<details>
  <summary>Details</summary>

**Motivation:** 旨在寻找标准模型（SM）基本参数中的底层解析结构，为模型构建者和人工智能方法提供宝贵输入，以揭示SM常数中的隐藏模式，或作为连接所有SM参数的深层底层定律的构建块。

**Method:** 使用符号回归和遗传编程来搜索标准模型（SM）基本参数之间的底层解析结构。

**Result:** 识别出连接这些常数对的最简单解析关系，并报告了几个相对精度优于1%的显著表达式。

**Conclusion:** 这些结果可作为模型构建者和旨在揭示SM常数隐藏模式的AI方法的宝贵输入，或潜在地用作通过少量基本常数连接SM所有参数的更深层底层定律的构建块。

> **ai_Abstract:** 本文利用符号回归和遗传编程等人工智能技术，探索标准模型基本常数之间的底层解析结构。研究成功识别出连接常数对的简单解析关系，并获得了精度优于1%的显著表达式。这些发现有望为构建新的物理模型或揭示更深层次的物理定律提供重要线索。

> **摘要翻译:** 本文介绍了使用符号回归和遗传编程在标准模型（SM）基本参数中寻找底层解析结构的研究。我们确定了连接这些常数对的最简单解析关系，并报告了几个相对精度优于1%的显著表达式。这些结果可以作为模型构建者和旨在揭示SM常数中隐藏模式的人工智能方法的宝贵输入，或者潜在地用作通过少量基本常数连接SM所有参数的更深层底层定律的构建块。

</details>

[⬆️ 返回分类顶部](#hep-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathpr'></a>
## math.PR 

### [323] [Formal Power Series Representations in Probability and Expected Utility Theory](https://arxiv.org/abs/2508.00294)
> *概率论和期望效用理论中的形式幂级数表示*

*Arthur Paul Pedersen, Samuel Allen Alexander* | **Category: math.PR, cs.AI, econ.TH, math.LO, math.ST, stat.TH, 60A05** | **Updated: 2025-08-01**

**Keywords:** 连贯偏好, 效用理论, 形式幂级数, 偏好表示, 有序域扩展

**Comment:** 

> **TL;DR:** 本文提出了一种新的连贯偏好理论，它放宽了传统理论中对传递性、阿基米德性、有界性和连续性的严格要求，并证明了满足特定连贯性要求的偏好系统可以在实数有序域扩展中通过效用表示，同时扩展了经典定理。

**AI_Comments:** 本文通过放宽偏好理论中长期存在的关键假设（如传递性、阿基米德性、有界性和连续性），展现了显著的创新性。这使得该理论更具普遍性和适用性，能够处理更广泛的偏好结构。其与霍尔德定理和哈恩嵌入定理的关联和扩展，也彰显了其坚实的理论基础和对数学经济学领域的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 传统正统的连贯偏好理论包含限制性假设（如传递性、阿基米德性、有界性和连续性），本文旨在提出一种更普适的理论来克服这些限制。

**Method:** 本文提出了一种基于与德·菲内蒂（de Finetti）概率基础相似的连贯性要求的一般连贯偏好理论。该理论允许任何偏好系统扩展为完整的偏好系统，并表明任何满足连贯性标准的完整偏好系统都可以在实数有序域扩展中通过效用表示。这一表示能力是本文核心结果的推论，该结果扩展了霍尔德定理并强化了哈恩嵌入定理。

**Result:** 所提出的理论表明，任何偏好系统只要满足特定的连贯性要求，就可以扩展为完整的偏好系统。更重要的是，任何满足连贯性标准的完整偏好系统都可以在实数的有序域扩展中通过效用进行表示，而无需满足传递性、阿基米德性、有界性或连续性等传统要求。这是通过扩展霍尔德定理和强化哈恩嵌入定理来实现的。

**Conclusion:** 本文建立了一种更普遍的连贯偏好理论，该理论放宽了传统理论的严格假设，同时仍能实现效用表示，从而拓宽了偏好理论的适用范围。

> **ai_Abstract:** 本文提出了一种新的连贯偏好理论，旨在克服传统理论中关于传递性、阿基米德性、有界性和连续性的严格限制。该理论表明，任何满足特定连贯性要求的偏好系统都能扩展为完整的系统，且任何完整的连贯偏好系统都可以在实数的有序域扩展中通过效用进行表示。这一核心结果通过扩展霍尔德定理和强化哈恩嵌入定理来实现，从而提供了一种更普适的效用理论框架。

> **摘要翻译:** 我们提出了一种连贯偏好的一般理论，该理论放弃了正统学说中的限制。该理论具有以下特性：任何偏好系统都可以扩展为完整的偏好系统，前提是它满足某种连贯性要求，类似于德·菲内蒂（de Finetti）为他的概率基础所提出的要求。与德·菲内蒂的理论不同，我们提出的理论既不需要偏好的传递性、阿基米德性、有界性，也不需要连续性。该理论还具有以下特性：任何满足连贯性标准的完整偏好系统都可以用实数有序域扩展中的效用表示。效用可表示性是本文核心结果的推论，该核心结果同时扩展了霍尔德定理并强化了哈恩嵌入定理。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

### [445] [A potential theory on weighted graphs](https://arxiv.org/abs/2405.07961)
> *加权图上的势理论*

*Trent DeGiovanni, Fernando Guevara Vasquez* | **Category: math.PR, cs.NA, math.NA, 31C20, 65M80, 31B10** | **Updated: 2025-08-01**

**Keywords:** 加权图, 势理论, 离散算子, Calderón微积分, 隐身策略

**Comment:** 30 pages, 7 figures

> **TL;DR:** 本文在加权图上提出了经典势理论的类比，并定义了离散的迹算子、单双层势算子和边界层算子，这些算子能够表示不同边界条件下的外部或内部调和函数。该形式化方法引入了离散Calderón微积分，并将势理论中的一些已知结果（如Neumann-Poincaré算子谱）引入加权图，并通过加权图上的隐身策略进行了说明。

**AI_Comments:** 本文的创新之处在于成功地将经典连续势理论的复杂概念和工具（如迹算子、层势算子和Calderón微积分）系统地推广到离散的加权图领域。这不仅为图论和离散数学提供了一个新的理论框架，也为在离散数据结构中处理类似物理问题（如电学测量中的隐身）提供了强大的分析工具。其重要性在于弥补了连续与离散势理论之间的鸿沟，并可能为图像处理、网络分析和机器学习等领域中的逆问题和边界值问题提供新的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 旨在将经典的势理论推广到加权图上，并定义其离散类比，以便在离散设置下应用势理论的原理和结果。

**Method:** 通过将节点划分为外部、边界和内部节点，并适当分解拉普拉斯算子，定义了离散的迹算子、单层和双层势算子以及边界层算子。该方法引入了离散的Calderón微积分，并研究了Neumann-Poincaré算子谱等结果。通过一个加权图上的隐身策略来验证其形式。

**Result:** 定义了离散的迹算子、单层和双层势算子以及边界层算子，这些算子能够表示不同边界条件下的外部或内部调和函数。成功地将经典势理论中的一些已知结果（如Neumann-Poincaré算子谱）引入到加权图上。并通过一个加权图上的隐身策略（隐藏异常）证明了该形式的有效性。

**Conclusion:** 本文成功地在加权图上建立了经典势理论的类比，定义了相应的离散算子，并引入了离散Calderón微积分，从而将势理论的重要结果推广到离散域。这为在加权图上处理调和函数和边界条件问题提供了新的工具和视角。

> **ai_Abstract:** 本文在加权图上构建了经典势理论的离散类比。通过对节点进行分区并分解拉普拉斯算子，定义了离散的迹、单层、双层势和边界层算子。这些算子能够表示具有不同边界条件的调和函数。该框架引入了离散Calderón微积分，并将势理论中的关键结果（如Neumann-Poincaré算子谱）扩展到加权图，并通过一个用于隐藏异常的隐身策略进行了实例验证。

> **摘要翻译:** 我们提出了加权图上经典势理论的类比。通过将节点划分为外部、边界和内部节点，并适当分解拉普拉斯算子，我们定义了迹算子、单层和双层势算子以及边界层算子的离散类比。与连续域中一样，这些算子可以表示具有不同边界条件的外部或内部调和函数。我们引入的形式包括离散的Calderón微积分，并将势理论中的一些已知结果带到加权图上，例如关于Neumann-Poincaré算子的谱。我们通过加权图上的隐身策略来阐述这种形式，该策略允许从远离异常的电测量角度隐藏异常。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [378] [Assessing (im)balance in signed brain networks](https://arxiv.org/abs/2508.00542)
> *评估符号脑网络中的（非）平衡性*

*Marzio Di Vece, Emanuele Agrimi, Samuele Tatullo, Tommaso Gili, Miguel Ibáñez-Berganza, Tiziano Squartini* | **Category: physics.soc-ph, cs.IT, math.IT, physics.data-an, physics.med-ph, stat.ME** | **Updated: 2025-08-01**

**Keywords:** 符号脑网络, 多元时间序列, 静态关系推断, 香农熵, 挫败性, 松弛平衡理论

**Comment:** 41 pages, 17 figures, 1 table

> **TL;DR:** 本文提出一种新方法，通过将多元时间序列投影到符号图上，从动态数据推断单元间的静态关系，并应用于脑网络，发现脑网络存在挫败性，且负子图变异性更大，脑区模块符合松弛平衡理论。

**AI_Comments:** 本文提出了一种创新的、基于信息论的框架，用于从动态时间序列数据中推断复杂的静态关系，并成功应用于神经科学领域的脑网络分析。其贡献在于提供了一种量化和评估脑网络平衡性/挫败性的新工具，特别是揭示了负连接子图在个体间变异性更大的现象，并将其模块化结构与松弛平衡理论联系起来，为理解复杂系统（尤其是大脑）的组织原理提供了新视角。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决仅从动态状态推断单元间静态关系这一实践和理论上重要的问题，并将其应用于神经科学领域中确定脑网络是否具有挫败性及其程度。

**Method:** 提出一种基于假设检验的方法，当两个单元行为足够相似时将其连接。具体通过将多元时间序列投影到符号图上实现：i) 比较经验特性与基准预期；ii) 根据协调/不协调值的数量用正/负边连接单元。基准采用基于香农熵约束最大化的信息论方法。在介观层面，使用符号随机块模型（Signed Stochastic Block Model）结合贝叶斯信息准则最小化来揭示脑区模块。

**Result:** 研究结果表明脑网络确实存在挫败性，其中负子图的结构比正子图更容易出现受试者间的变异性。在介观层面，贝叶斯信息准则的最小化揭示了脑区聚集成符合松弛平衡理论统计变体的模块。

**Conclusion:** 脑网络表现出挫败性，且其负连接结构在个体间差异较大；脑区模块化结构符合松弛平衡理论。

> **ai_Abstract:** 本文提出一种新颖的方法，旨在从多元时间序列推断复杂系统中单元间的静态关系。该方法通过假设检验将行为相似的单元连接起来，并将时间序列投影到符号图中，通过比较经验特性与信息论定义的基准来确定连接的性质（正/负）。文章将此方法应用于神经科学领域，以评估脑网络的挫败性。研究结果表明脑网络确实存在挫败性，且负连接子图在个体间表现出更大的变异性。此外，在介观层面，脑区模块化结构符合松弛平衡理论。

> **摘要翻译:** 许多复杂系统——无论是金融、自然还是社会——都由单位（如股票、神经元或代理）组成，它们的联合活动可以表示为多元时间序列。一个具有实践和理论重要性的问题是，仅从两个单元的动态状态推断它们之间是否存在静态关系。本研究旨在传统假设检验框架内提供一个答案。简而言之，我们的建议是，如果两个单元的行为方式足够相似，则将它们连接起来。为了实现这一目标，我们通过以下方式将多元时间序列投影到符号图中：i) 将前者的经验特性与适当基准下的预期特性进行比较；ii) 如果相应的序列共享大量一致（不一致）的值，则用正（负）边连接两个单元。为了定义我们的基准，我们采用了一种信息论方法，该方法植根于香农熵的约束最大化，这一过程产生了一组多元时间序列，该序列在平均情况下保留了一些经验特性，同时随机化了其他一切。我们通过解决神经科学领域中最及时的问题之一，即确定脑网络是否具有挫败性——以及在何种程度上——来展示我们方法的可能应用。正如我们的结果所示，情况确实如此，负子图的结构比互补的正子图更容易出现受试者间的变异性。相反，在介观层面，通过符号随机块模型实例化的贝叶斯信息准则的最小化揭示了脑区聚集成符合松弛平衡理论统计变体的模块。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

### [470] [Block-corrected Modularity for Community Detection](https://arxiv.org/abs/2502.20083)
> *块校正模块度用于社区检测*

*Hasti Narimanzadeh, Takayuki Hiraoka, Mikko Kivelä* | **Category: physics.soc-ph, cond-mat.stat-mech, cs.SI** | **Updated: 2025-08-01**

**Keywords:** 社区检测, 块校正模块度, 复杂网络, 未知属性, Louvain算法

**Comment:** 22 pages, 11 figures

> **TL;DR:** 提出了一种块校正模块度，用于揭示复杂网络中被已知属性掩盖的社区结构，并通过分析和实验证明其有效性。

**AI_Comments:** 该论文的创新之处在于提出了“块校正模块度”的概念，有效地解决了复杂网络中由未知属性掩盖的社区检测问题。通过引入对已知块结构的折扣，它能够更准确地揭示深层社区结构。其在理论分析、合成网络实验以及真实世界数据上的验证，都显示了该方法的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂网络中，未知节点属性可能引入重要的社区结构，需要与由已知属性驱动的社区结构区分开来。

**Method:** 本文提出了一种块校正模块度，通过折扣网络中给定的块结构来揭示被其掩盖的社区。此外，开发了一种高效的光谱方法和两种受Louvain启发的微调算法来最大化所提出的模块度。

**Result:** 分析表明，所提出的模块度能在简单网络模型中找到由未知属性驱动的社区结构。在多个简单合成网络模型上，块校正模块度能找到底层社区结构，而其他使用不同空模型的方法则失败。该方法还在使用OpenAlex数据构建的各种真实世界引文网络上进行了评估。

**Conclusion:** 块校正模块度是一种有效的方法，能够揭示复杂网络中被已知属性掩盖的社区结构，并在合成和真实世界网络上表现出优越性。

> **ai_Abstract:** 本文提出了一种名为“块校正模块度”的新方法，旨在解决复杂网络中由未知节点属性引起的社区检测问题。该方法通过折扣已知的块结构来揭示被掩盖的社区。研究通过理论分析和在合成网络上的实验证明了其有效性，并与现有方法进行了比较。此外，论文还开发了高效的优化算法，并在真实的引文网络上进行了应用评估。

> **摘要翻译:** 复杂网络中未知节点属性可能引入重要的社区结构，这些结构与由已知属性驱动的社区结构需要区分。我们提出了一种块校正模块度，它通过折扣网络中存在的给定块结构，以揭示被它们掩盖的社区。我们分析性地展示了所提出的模块度如何在简单网络模型中找到由未知属性驱动的社区结构。此外，我们观察到块校正模块度在许多简单的合成网络模型上找到了底层的社区结构，而使用不同空模型的方法则失败了。我们开发了一种高效的光谱方法以及两种受Louvain启发的微调算法来最大化所提出的模块度，并展示了它们在多个合成网络模型上的性能。最后，我们通过校正时间引文模式，评估了我们使用OpenAlex数据构建的各种真实世界引文网络上的方法。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathfa'></a>
## math.FA 

### [420] [The algebraic structure of hyperinterpolation class on the sphere](https://arxiv.org/abs/2404.00523)
> *球面上超插值类的代数结构*

*Congpei An, Jiashu Ran* | **Category: math.FA, cs.NA, math.NA, 41A10, 41A36, 47L20, 47L80** | **Updated: 2025-08-01**

**Keywords:** 超插值, 代数结构, 超半群, 超自伴算子, 单位球

**Comment:** 16 pages, 1 figure

> **TL;DR:** 本文研究了单位球面上超插值类的代数性质，并基于离散（半）内积框架，发展了超自伴算子、超投影算子和超半群的理论。研究了四种特定算子，并证明了广义超插值算子的性质以及硬阈值和经典超插值算子形成的超半群。

**AI_Comments:** 该论文在超插值理论中引入了代数结构分析，特别是在离散（半）内积框架下构建了超自伴算子、超投影算子和超半群等概念，具有较强的理论创新性。它为理解超插值算子的深层数学性质提供了新的视角和工具，对于稀疏表示和逼近理论可能有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在深入探讨单位球面上超插值类 $\mathbf{HC}(\mathbb{S}^d)$ 的代数性质，特别是那些源自具有有界 $L_2$ 算子范数的经典超插值的算子。

**Method:** 研究方法主要包括利用离散（半）内积框架来发展超自伴算子、超投影算子和超半群的理论。具体分析了四种特定算子：滤波、Lasso、硬阈值和广义超插值。

**Result:** 研究结果表明：1. 广义超插值算子是超自伴的，并且与超插值算子可交换。2. 硬阈值和经典超插值算子构成一个超半群。3. 硬阈值超插值构成了最小素超理想。4. 超插值算子在超半群上充当超同态。

**Conclusion:** 本文成功地揭示了单位球面上超插值类的代数结构，特别是在离散（半）内积框架下，对各种超插值算子的性质及其相互关系进行了深入分析和证明，为该领域提供了新的理论基础。

> **ai_Abstract:** 本文深入探究了单位球面上超插值类的代数结构，特别是关注了具有有界 $L_2$ 算子范数的超插值算子。研究引入了离散（半）内积框架，并在此基础上构建了超自伴算子、超投影算子和超半群的理论。通过对滤波、Lasso、硬阈值和广义超插值四种算子的具体分析，论文证明了广义超插值算子的超自伴性及其与超插值算子的可交换性。同时，揭示了硬阈值和经典超插值算子构成的超半群关系，并指出硬阈值超插值是最小素超理想。最终，论文确立了超插值算子在超半群上的超同态作用。

> **摘要翻译:** 本文研究了单位球面上超插值类 $\mathbf{HC}(\mathbb{S}^d)$ 的代数性质。我们关注那些源自具有有界 $L_2$ 算子范数的经典超插值的算子。通过利用离散（半）内积框架，我们发展了超自伴算子、超投影算子和超半群的理论。我们分析了四种特定算子：滤波、Lasso、硬阈值和广义超插值。我们证明了广义超插值算子是超自伴的，并且与超插值算子可交换。此外，我们证明了硬阈值和经典超插值算子形成一个超半群，其中硬阈值超插值构成了最小素超理想。最后，我们确立了超插值算子在超半群上充当超同态。

</details>

[⬆️ 返回分类顶部](#mathfa) | [⬆️ 返回总目录](#toc)

---

<a id='physicsed-ph'></a>
## physics.ed-ph 

### [447] [Advancing Quantum Information Science Pre-College Education: The Case for Learning Sciences Collaboration](https://arxiv.org/abs/2508.00668)
> *推进量子信息科学大学预科教育：学习科学合作的案例*

*Raquel Coelho, Roy Pea, Christian Schunn, Jinglei Cheng, Junyu Liu* | **Category: physics.ed-ph, cs.AI, cs.CY, quant-ph** | **Updated: 2025-08-01**

**Keywords:** 量子信息科学教育, 学习科学, 设计本位研究, 知识表征, 大学预科教育

**Comment:** 12 pages, 2 figures

> **TL;DR:** 本文主张将学习科学（LS）与量子信息科学（QIS）相结合，以改进大学预科阶段的QIS教育，提出采用设计本位研究和新的学习框架。

**AI_Comments:** 这篇论文的创新之处在于明确提出了将学习科学的理论和方法引入量子信息科学教育的必要性，尤其是在大学预科阶段。其重要性在于为解决QIS教育的复杂性提供了具体的合作路径和方法论（如设计本位研究和知识表征框架），这对于培养未来的量子人才至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 随着量子信息科学的进步，大学预科阶段的参与需求日益增长，但如何让年轻学习者为参与一个与他们之前所接触的领域截然不同的领域做好准备，是一个关键挑战。

**Method:** 论文提出了学习科学对量子信息科学教育的两项关键贡献：一是设计本位研究，用于开发、完善和推广有效的QIS学习体验；二是提供一个框架，通过知识表征的转变，重塑学习者如何思考、学习和参与QIS实践。

**Result:** 论文讨论了学习科学如何通过其标志性方法——设计本位研究，以及一个重塑学习者参与QIS实践的框架，来支持和推进量子信息科学教育，旨在提升对复杂领域教学和学习支持的理解。

**Conclusion:** 本文呼吁量子信息科学与学习科学之间建立双向伙伴关系，认为这种合作不仅能支持量子概念和实践的学习，还能提升对复杂领域教学和学习支持的理解，并且其理论和实践益处足以证明这项努力是值得的。

> **ai_Abstract:** 本文探讨了在大学预科阶段推进量子信息科学（QIS）教育的挑战，并强调了与学习科学（LS）进行跨学科合作的必要性。论文提出了学习科学的两项关键贡献：设计本位研究方法，用于开发和优化QIS学习体验；以及一个通过知识表征转变来重塑学习者参与QIS实践的框架。文章呼吁QIS与LS建立双向伙伴关系，以期不仅支持量子概念的学习，还能提升在复杂领域教学和学习支持的理解。

> **摘要翻译:** 随着量子信息科学的进步以及大学预科阶段参与需求的增长，一个关键问题依然存在：如何让年轻学习者为参与一个与他们之前所接触的领域截然不同的领域做好准备？本文认为，应对这一挑战将需要与学习科学（LS）进行强有力的跨学科合作，学习科学是一个致力于理解人们如何学习以及设计理论指导环境以支持学习的领域。借鉴以往STEM教育的经验，我们讨论了学习科学对量子信息科学（QIS）教育的两项关键贡献。第一个是设计本位研究，这是学习科学的标志性方法，它可以为有效QIS学习体验的开发、完善和推广提供信息。第二个是一个框架，通过知识表征的转变，提供新的参与形式和相关的学习，从而重塑学习者如何思考、学习和参与QIS实践。我们呼吁量子信息科学与学习科学之间建立双向伙伴关系，这种伙伴关系不仅支持量子概念和实践的学习，还能提高我们对如何在高度复杂领域进行教学和支持学习的理解。我们还考虑了连接这些学科社区可能涉及的问题，并认为其理论和实践益处足以证明这项努力是值得的。

</details>

[⬆️ 返回分类顶部](#physicsed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [471] [Adaptive Mesh Refinement for Two-Phase Viscoelastic Fluid Mixture Models](https://arxiv.org/abs/2409.19974)
> *双相粘弹性流体混合物模型的自适应网格细化*

*Bindi M. Nagda, Aaron Barrett, Boyce E. Griffith, Aaron L. Fogelson, Jian Du* | **Category: physics.flu-dyn, cs.NA, math.NA, 76-10, 76T06, G.1.8; G.4** | **Updated: 2025-08-01**

**Keywords:** 自适应网格细化, 双相流, 粘弹性流体, 多重网格, 计算流体力学

**Comment:** 

> **TL;DR:** 本文开发了一种自适应网格细化（AMR）技术，用于高效、准确地模拟双相粘弹性流体混合物模型，显著降低了计算成本。

**AI_Comments:** 该论文的创新点在于将自适应网格细化（AMR）技术与多重网格预处理相结合，解决了双相粘弹性流体混合物模型中复杂非线性和共不可压缩性带来的数值挑战。其重要性在于提供了一种高效、精确且成本效益高的模拟方法，尤其在处理具有高应力或大材料梯度的多相流问题时具有显著优势，对工业、自然和生物医学领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多相流在工业、自然和生物医学系统中具有广泛应用。所考虑的双相连续体模型，由于存在多个非线性项和速度场的共不可压缩性条件，带来了数值挑战。为了准确捕捉高应力区域和大的材料梯度，同时保持低计算成本，需要开发自适应网格细化（AMR）技术。

**Method:** 研究人员提出了一种用于模拟自适应网格上多相混合物的精确、鲁棒和高效的计算方法。该方法利用多重网格求解器对鞍点系统进行预处理。

**Result:** AMR离散化在$L^1$、$L^2$和$L^\infty$范数下渐近接近二阶精度。该求解器可以准确解析解中的尖锐梯度，并且通过引入的多重网格预处理策略，线性求解器迭代次数与网格间距无关。数值实验表明，AMR求解器相比均匀网格可实现高达十倍的加速，并且根据问题设置可能实现更大的加速。

**Conclusion:** 本文提出的AMR求解器为双相粘弹性流体混合物模型的模拟提供了一种准确、鲁棒、高效且具有显著成本效益的解决方案，尤其在处理复杂流体动力学和高梯度区域时表现出色。

> **ai_Abstract:** 本文针对双相粘弹性流体混合物模型，提出了一种基于自适应网格细化（AMR）的计算方法。该模型因其非线性和共不可压缩性条件而带来数值挑战。为解决此问题，研究开发了一种高效、鲁棒的AMR技术，结合多重网格求解器进行预处理，旨在精确捕捉高应力及大梯度区域，同时降低计算成本。实验结果显示，该方法在精度上达到二阶，能有效解析尖锐梯度，且线性求解器迭代次数与网格间距无关，计算速度相比均匀网格有显著提升，最高可达十倍。

> **摘要翻译:** 多相流是一类重要的流体流动，其研究促进了工业、自然和生物医学系统中各种应用的发展。我们考虑一个模型，该模型使用两相的连续体描述，其中每相都使用独立的动量方程，并伴随速度场的共不可压缩性条件。由此产生的方程组由于存在多个非线性项和共不可压缩性条件而带来数值挑战，由此产生的流体动力学促使开发一种自适应网格细化（AMR）技术，以准确捕捉高应力区域和大的材料梯度，同时保持较低的计算成本。我们提出了一种精确、鲁棒和高效的计算方法，用于在自适应网格上模拟多相混合物，并利用多重网格求解器对鞍点系统进行预处理。我们证明了AMR离散化在$L^1$、$L^2$和$L^\infty$范数下渐近接近二阶精度。该求解器可以准确解析解中的尖锐梯度，并且通过本文引入的多重网格预处理策略，线性求解器迭代次数与网格间距无关。我们的AMR求解器提供了主要的成本节约优势，在本文提出的数值实验中，比均匀网格提供了高达十倍的加速，并且根据问题设置可能实现更大的加速。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [521] [Hybrid High-Order formulations with turbulence modelling capabilities for incompressible flow problems](https://arxiv.org/abs/2505.22480)
> *具有湍流建模能力的不可压缩流问题的混合高阶公式*

*Lorenzo Botti, Daniele Antonio Di Pietro, Francesco Carlo Massa* | **Category: physics.flu-dyn, cs.NA, math.NA** | **Updated: 2025-07-31**

**Keywords:** 混合高阶公式, 湍流模拟, 不可压缩流, Navier-Stokes, ESDIRK

**Comment:** 

> **TL;DR:** 本文提出一种用于湍流模拟的混合高阶（HHO）不可压缩Navier-Stokes方程公式，该公式具有压力鲁棒性、高精度质量守恒、隐式高阶时间步进和内存优化等特点，并通过2D/3D算例和Taylor-Green涡流问题进行了验证。

**AI_Comments:** 该论文提出了一种创新的混合高阶公式，结合了多种先进数值技术，旨在提高湍流模拟的精度和效率。其在压力鲁棒性、质量守恒和内存优化方面的特点使其在高性能计算领域具有重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为模拟湍流，特别是在需要高保真计算时，提出一种具有吸引人特性的不可压缩Navier-Stokes方程的新型数值公式。

**Method:** 本文提出了一种不可压缩Navier-Stokes方程的混合高阶（HHO）公式。空间离散采用混合速度和压力空间，时间离散基于显式单对角隐式Runge-Kutta（ESDIRK）方法。该公式具有压力鲁棒性、单元级质量守恒（达到机器精度）、无粘性极限鲁棒性、带局部时间步长自适应的隐式高阶精确时间步进、通过速度和压力的静态凝结减少内存占用、以及利用继承的p-多级求解策略提高迭代求解器性能的潜力。

**Result:** 该方案的相关特性在实践中得到验证，成功完成了具有挑战性的2D和3D测试案例，并对雷诺数1600下的Taylor-Green涡流问题进行了模拟。

**Conclusion:** 该混合高阶公式在湍流模拟中表现出良好的性能和吸引人的特性，特别适用于高保真计算。

> **ai_Abstract:** 本文提出了一种用于湍流模拟的混合高阶（HHO）不可压缩Navier-Stokes方程公式。该公式采用混合速度和压力空间进行空间离散，并基于ESDIRK方法进行时间离散。其主要特点包括压力鲁棒性、高精度质量守恒、无粘性极限鲁棒性、高阶时间步进以及内存优化。通过2D和3D测试案例以及Taylor-Green涡流问题的模拟，验证了该方案的有效性和吸引力特性。

> **摘要翻译:** 我们提出了一种不可压缩Navier-Stokes方程的混合高阶（HHO）公式，该公式非常适合用于湍流模拟。空间离散依赖于混合速度和压力空间，时间离散基于显式单对角隐式Runge-Kutta（ESDIRK）方法。该公式具有一些吸引人的特性，在需要高保真计算时可以得到充分利用，即：压力鲁棒性、单元级质量守恒至机器精度、无粘性极限下的鲁棒性、具有局部时间步长自适应的隐式高阶精确时间步进、通过速度和压力的静态凝结减少内存占用、以及利用继承的p-多级求解策略提高迭代求解器性能的可能性。在实践中演示了该方案的相关特性，执行了具有挑战性的2D和3D测试案例后，我们考虑了雷诺数1600下Taylor-Green涡流问题的模拟。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='mathho'></a>
## math.HO 

### [480] [The Second Machine Turn: From Checking Proofs to Creating Concepts](https://arxiv.org/abs/2507.10179)
> *第二次机器转向：从检查证明到创造概念*

*Asvin G* | **Category: math.HO, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 数学发现, 人工智能, 概念创造, 人机协作, 证明检查

**Comment:** Minor clarifications in the final section

> **TL;DR:** 人工智能在数学发现中迎来第二次机器转向，将从自动化证明检查转向自动化数学概念的创造。

**AI_Comments:** 这篇论文提出了一个极具前瞻性的观点，即人工智能在数学领域的角色将从辅助性的证明检查转向更具创造性的概念生成。这代表了AI在抽象思维和创造力方面迈出的重要一步，可能深刻改变数学研究的范式和人机协作的性质，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在探讨人工智能在数学发现过程中的下一个重大转变，即从自动化证明检查发展到自动化数学概念的创造。

**Method:** 论文讨论了当前的技术现状、面临的障碍和潜在解决方案，并初步尝试将概念创造本身进行数学化。

**Result:** 论文分析了人工智能在数学概念创造方面的当前进展、挑战和潜在途径，并探讨了其对数学领域和人机协作的潜在影响。

**Conclusion:** 论文评估了人工智能在概念创造方面的能力如何重塑数学和人机协作，并展望了几种可能的未来。

> **ai_Abstract:** 该论文提出数学发现正经历第二次机器转向，即人工智能将从自动化证明检查转向自动化数学概念的创造。文章探讨了当前技术现状、挑战和解决方案，并初步尝试将概念创造数学化，最后评估了这些能力对数学和人机协作的潜在影响及未来展望。

> **摘要翻译:** 我们确定了数学发现过程中第二次机器转向：在自动化证明检查之后，人工智能现在有望自动化数学概念本身的“创造”。我们讨论了当前的艺术水平、障碍和潜在解决方案，以及初步尝试将概念创造本身进行数学化。论文最后评估了这些能力如何重塑数学和人机协作，以及我们可能发现自己身处的几种不同的未来。

</details>

[⬆️ 返回分类顶部](#mathho) | [⬆️ 返回总目录](#toc)

---

<a id='physicscomp-ph'></a>
## physics.comp-ph 

### [495] [Nyström Type Exponential Integrators for Strongly Magnetized Charged Particle Dynamics](https://arxiv.org/abs/2505.00288)
> *强磁化带电粒子动力学的Nyström型指数积分器*

*Tri P. Nguyen, Ilon Joseph, Mayya Tokman* | **Category: physics.comp-ph, cs.NA, math.NA, physics.plasm-ph, 65L04, 78A35** | **Updated: 2025-08-01**

**Keywords:** Nyström型积分器, 指数积分器, 强磁化等离子体, 粒子推动, 数值僵硬性

**Comment:** 

> **TL;DR:** 针对强磁化等离子体模拟中的粒子推动问题，本文提出了Nyström型指数积分器，相比标准指数方法显著提高了计算效率。

**AI_Comments:** 这篇论文的创新点在于将Nyström型方法与指数积分器结合，以更有效地处理强磁化等离子体模拟中固有的数值僵硬性问题。其重要性在于为计算密集型的粒子推动问题提供了更高效的数值解法，有望提升PIC模拟的性能。抽象中未提及具体限制，但通常这类方法在极高维度或非线性问题上可能仍面临挑战。

<details>
  <summary>Details</summary>

**Motivation:** 等离子体物理模拟中，电磁场中带电粒子动力学计算（粒子推动问题）计算量大，尤其在强磁化等离子体中，由于时间尺度范围广且数值模型非常僵硬，现有时间积分器面临严重限制，因此需要更高效的方法。

**Method:** 本文扩展了标准指数算法框架，推导了将牛顿运动方程作为二阶微分方程积分的Nyström型指数方法。具体推导了二阶和三阶的Nyström型方案，并将其应用于强磁化粒子推动问题。

**Result:** 数值实验表明，Nyström型指数积分器比标准指数方法在计算效率上提供了显著改进。

**Conclusion:** Nyström型指数积分器能够显著提高强磁化带电粒子动力学模拟的计算效率，为解决粒子推动问题的数值僵硬性提供了更有效的方法。

> **ai_Abstract:** 本文针对强磁化等离子体模拟中粒子推动问题面临的数值僵硬性和计算效率挑战，提出了一种Nyström型指数积分器。通过将牛顿运动方程作为二阶微分方程积分，并推导了二阶和三阶的具体方案。数值实验证明，与标准指数方法相比，该新型积分器显著提高了计算效率。

> **摘要翻译:** 计算电磁场中带电粒子的动力学（即粒子推动问题）是等离子体物理模拟中粒子网格（PIC）方法计算最密集的部分之一。当等离子体被强磁化时，这项任务尤其具有挑战性，因为在这种情况下，粒子运动包含从高度振荡的快速回旋运动到缓慢宏观行为的广泛时间尺度，导致数值模型非常僵硬。目前用于模拟粒子运动的最先进时间积分器在面对问题的严重数值僵硬性时存在局限性，因此人们对更有效的方法感兴趣。最近，指数积分器被提出作为这些模拟的一种有前途的新方法，并显示出比常用方案具有计算优势。指数方法可以精确求解线性问题并且是A稳定的。在本文中，标准指数算法框架被扩展，以推导Nyström型指数方法，该方法将牛顿运动方程作为二阶微分方程进行积分。推导了具体的二阶和三阶Nyström型方案，并将其应用于强磁化粒子推动问题。数值实验表明，Nyström型指数积分器比标准指数方法在计算效率上提供了显著改进。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='gr-qc'></a>
## gr-qc 

### [512] [Weyl symmetry of the gradient-flow in information geometry](https://arxiv.org/abs/2502.03866)
> *信息几何中梯度流的Weyl对称性*

*Tatsuaki Wada, Sousuke Noda* | **Category: gr-qc, cs.IT, math-ph, math.IT, math.MP** | **Updated: 2025-08-01**

**Keywords:** Weyl对称性, 梯度流, 信息几何, α-连接, 黎曼流形

**Comment:** 16 pages, no figure

> **TL;DR:** 本文从Weyl对称性的角度重新审视了信息几何中的梯度流，推导了在Weyl规范变换下不变的作用量，并将Amari的α-连接与Weyl不变连接相关联。

**AI_Comments:** 本文的创新之处在于将Weyl对称性引入到信息几何的梯度流研究中，提供了一个新的理论框架来理解和推导梯度流方程，并建立了信息几何中α-连接与Weyl不变连接之间的深层联系。

<details>
  <summary>Details</summary>

**Motivation:** 从Weyl对称性的角度重新审视信息几何中的梯度流。

**Method:** 通过提出一个在Weyl规范变换下不变的作用量来推导梯度流方程；在Weyl可积几何中，将Amari信息几何中的α-连接与黎曼流形上配备标度度量的Weyl不变连接相关联。

**Result:** 梯度流方程是从一个在Weyl规范变换下不变的作用量中推导出来的；Amari的α-连接被关联到配备标度度量的黎曼流形上的Weyl不变连接。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文从Weyl对称性的视角重新审视了信息几何中的梯度流。研究者们从一个在Weyl规范变换下保持不变的作用量中推导出了梯度流方程。此外，在Weyl可积几何框架下，文章将Amari的α-连接与黎曼流形上配备标度度量的Weyl不变连接建立了联系。

> **摘要翻译:** 我们从Weyl对称性的角度重新审视了信息几何中的梯度流。梯度流方程是从所提出的作用量中推导出来的，该作用量在Weyl规范变换下是不变的。在Weyl可积几何中，我们将Amari在信息几何中的α-连接与配备标度度量的黎曼流形上的Weyl不变连接相关联。

</details>

[⬆️ 返回分类顶部](#gr-qc) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matstat-mech'></a>
## cond-mat.stat-mech 

### [539] [Agentic Information Theory: Ergodicity and Intrinsic Semantics of Information Processes](https://arxiv.org/abs/2505.19275)
> *代理信息论：信息过程的遍历性和内在语义*

*James P. Crutchfield, Alexandra Jurgens* | **Category: cond-mat.stat-mech, cs.IT, cs.MA, math.IT, nlin.AO** | **Updated: 2025-07-31**

**Keywords:** 代理信息理论, 信息过程, 遍历性, 内在语义, 认知代理

**Comment:** 30 pages, 12 figures, 9 tables;
  http://csc.ucdavis.edu/~cmg/compmech/pubs/iprocesses.htm

> **TL;DR:** 开发了一种针对记忆代理在复杂环境中行为的信息理论。

**AI_Comments:** 该论文的创新点在于将信息理论应用于具有记忆的认知代理在复杂环境中的实时行为，并引入了“信息过程”的概念。它为理解代理如何适应性地处理环境中的不确定性和结构提供了新的理论框架。

<details>
  <summary>Details</summary>

**Motivation:** 现有信息理论可能不足以描述记忆代理在复杂环境中的实时交互和解释行为，因此需要为记忆代理在复杂环境中的时间行为开发信息理论。

**Method:** 引入并探索了信息过程——认知代理在与传入刺激交互和解释时实时产生的随机过程。提供了关于由此产生的香农信息度量时间序列的遍历性和语义的基本结果。

**Result:** 提供了关于记忆代理在复杂环境中适应性地看待不确定性和结构相关性的香农信息度量时间序列的遍历性和语义的基本结果。

**Conclusion:** 论文成功为记忆代理在复杂环境中的信息过程行为建立了信息理论基础，并揭示了其遍历性和内在语义。

> **ai_Abstract:** 本文提出了一种代理信息理论，旨在描述具有记忆的代理在复杂环境中的时间行为。研究引入了“信息过程”概念，即认知代理实时产生的随机过程，并探讨了这些过程中香农信息度量时间序列的遍历性和内在语义，以监测代理对环境不确定性和结构相关性的适应性理解。

> **摘要翻译:** 我们为在复杂（结构化、随机）环境中移动的记忆代理的时间行为开发了信息理论。我们引入并探索了信息过程——认知代理在与传入刺激交互和解释时实时产生的随机过程。我们提供了关于由此产生的香农信息度量时间序列的遍历性和语义的基本结果，这些度量监测代理对其环境中不确定性和结构相关性的适应性视图。

</details>

[⬆️ 返回分类顶部](#cond-matstat-mech) | [⬆️ 返回总目录](#toc)

---

<a id='q-fintr'></a>
## q-fin.TR 

### [558] [ContestTrade: A Multi-Agent Trading System Based on Internal Contest Mechanism](https://arxiv.org/abs/2508.00554)
> *ContestTrade：一种基于内部竞赛机制的多智能体交易系统*

*Li Zhao, Rui Sun, Zuoyou Jiang, Bo Yang, Yuxiao Bai, Mengting Chen, Xinyang Wang, Jing Li, Zuo Bai* | **Category: q-fin.TR, cs.CL, q-fin.CP** | **Updated: 2025-08-01**

**Keywords:** 多智能体系统, 金融交易, 大型语言模型, 内部竞争机制, 市场噪声

**Comment:** 

> **TL;DR:** ContestTrade是一个多智能体交易系统，通过内部竞争机制克服了LLM在金融交易中对市场噪声的敏感性，并表现出卓越的性能。

**AI_Comments:** 该论文的创新点在于引入了受企业管理启发的内部竞争机制，这为多智能体系统提供了一种新颖的自适应和鲁棒性增强方法。这种机制能够有效筛选出优质决策，从而克服LLM在金融交易中对市场噪声的固有敏感性，对提升智能交易系统的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决基于大型语言模型（LLM）的交易系统对市场噪声高度敏感，从而影响其性能的局限性。

**Method:** 提出ContestTrade，一个受现代企业管理结构启发的多智能体系统，具有内部竞争机制。系统包含两个专业团队：数据团队（处理市场数据并生成文本因子）和研究团队（基于深度研究进行并行多路径交易决策）。核心创新在于团队内部实施实时评估和排名机制，仅采纳表现最佳智能体的输出。

**Result:** 实验结果表明，该系统在多种评估指标上显著优于现有的多智能体系统和传统的量化投资方法。

**Conclusion:** ContestTrade系统通过其内部竞争机制，能够自适应地调整以适应动态环境，增强对市场噪声的鲁棒性，并最终提供卓越的交易性能。

> **ai_Abstract:** 本文提出了一种名为ContestTrade的新型多智能体交易系统，旨在解决基于大型语言模型的交易系统对市场噪声敏感的问题。该系统借鉴现代企业管理结构，由数据团队和研究团队组成，并通过实施实时评估和排名机制，仅采纳团队中表现最佳智能体的输出。实验证明，ContestTrade在增强对市场噪声的鲁棒性和提供卓越交易性能方面，显著优于现有系统和传统方法。

> **摘要翻译:** 在金融交易中，基于大型语言模型（LLM）的智能体展现出巨大的潜力。然而，对市场噪声的高度敏感性削弱了基于LLM的交易系统的性能。为了解决这一局限性，我们提出了一种受现代企业管理结构启发的，具有内部竞争机制的新型多智能体系统。该系统由两个专业团队组成：(1) 数据团队——负责处理和压缩海量市场数据为多样化的文本因子，确保它们符合模型的受限上下文。(2) 研究团队——负责基于深度研究方法做出并行多路径交易决策。核心创新在于在每个团队内部实施由真实市场反馈驱动的实时评估和排名机制。每个智能体的表现都会持续进行评分和排名，只有表现最佳智能体的输出才会被采纳。这种设计使系统能够自适应地调整以适应动态环境，增强对市场噪声的鲁棒性，并最终提供卓越的交易性能。实验结果表明，我们提出的系统在多种评估指标上显著优于现有的多智能体系统和传统的量化投资方法。

</details>

[⬆️ 返回分类顶部](#q-fintr) | [⬆️ 返回总目录](#toc)

---

<a id='mathnt'></a>
## math.NT 

### [569] [Cyclotomy, cyclotomic cosets and arithmetic properties of some families in $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$](https://arxiv.org/abs/2507.23179)
> *分圆术、分圆陪集以及 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中一些族的算术性质*

*Juncheng Zhou, Hongfeng Wu* | **Category: math.NT, cs.IT, math.IT** | **Updated: 2025-08-01**

**Keywords:** 分圆术, 分圆陪集, 算术性质, 本原幂等元, 有限域环

**Comment:** 

> **TL;DR:** 本文通过使用阶为2的分圆类，研究了特定环中一些族的算术性质，并得到了最小理想的本原幂等元的显式表达式，推广了现有结果。

**AI_Comments:** 本文通过利用特殊构造的阶为2的分圆类，成功地揭示了特定有限域多项式环中元素的算术性质，并给出了本原幂等元的显式形式，这对于代数编码理论等领域可能具有重要意义。其创新之处在于利用了特定参数下的分圆类形式来推广现有结果。

<details>
  <summary>Details</summary>

**Motivation:** 通过分圆类的形式，进一步推广了参考文献[ref1]中已获得的结果。

**Method:** 本文通过使用关于 $n=p^sq^t$ 的阶为2的分圆类来获得结果，其中 $p\equiv3 \mathrm{mod} 4$，$\gcd(\phi(p^s),\phi(q^t))=2$， $l$ 是模 $q^t$ 的原根，且 $\mathrm{ord}_{p^s}(l)=\phi(p^s)/2$。

**Result:** 获得了 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中一些族的算术性质，以及其最小理想的本原幂等元的显式表达式。

**Conclusion:** 通过利用特定条件下的阶为2的分圆类，成功地获得了特定环中相关族的算术性质，并得到了本原幂等元的显式表达式，从而推广了现有成果。

> **ai_Abstract:** 本文研究了在特定条件下（$p\equiv3 \mathrm{mod} 4$，$\gcd(\phi(p^s),\phi(q^t))=2$， $l$ 是模 $q^t$ 的原根，且 $\mathrm{ord}_{p^s}(l)=\phi(p^s)/2$）下，环 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中一些族的算术性质。研究方法是利用关于 $n=p^sq^t$ 的阶为2的分圆类。研究结果包括获得了这些族的算术性质，以及最小理想的本原幂等元的显式表达式。这项工作进一步推广了前人的研究成果。

> **摘要翻译:** 通过使用关于 $n=p^sq^t$ 的阶为2的分圆类，获得了 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中一些族的算术性质，其中 $p\equiv3 \mathrm{mod} 4$，$\gcd(\phi(p^s),\phi(q^t))=2$， $l$ 是模 $q^t$ 的原根，且 $\mathrm{ord}_{p^s}(l)=\phi(p^s)/2$。这些分圆类的形式使我们能够进一步推广参考文献[ref1]中已获得的结果。本文还获得了 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中最小理想的本原幂等元的显式表达式。

</details>

[⬆️ 返回分类顶部](#mathnt) | [⬆️ 返回总目录](#toc)

---

<a id='mathct'></a>
## math.CT 

### [629] [Dynamics and Coherence for the Free Cornering with Protocol Choice](https://arxiv.org/abs/2508.00633)
> *具有协议选择的自由转角动力学与相干性*

*Chad Nester, Niels Voorneveld* | **Category: math.CT, cs.LO** | **Updated: 2025-08-01**

**Keywords:** 项重写系统, 幺半范畴, 协议选择, 相干性定理, 过程交互

**Comment:** 24 pages, in peer review

> **TL;DR:** 本文提出了一个项重写系统，用于建模具有协议选择的幺半范畴的动态方面，并利用该系统证明了自由转角的相干性定理。

**AI_Comments:** 本文的创新之处在于利用项重写系统来形式化和分析范畴论中与过程交互相关的动态行为，并通过证明相干性定理，为抽象的范畴结构提供了具体的计算模型和理论验证。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在建立一个范畴模型来理解和建模过程交互的动态方面，特别是具有协议选择的自由转角。

**Method:** 本文采用项重写系统来建模和分析具有协议选择的幺半范畴的动态特性，并利用该系统证明相干性定理。

**Result:** 所提出的项重写系统在适当意义上是合流且终止的。利用该系统成功证明了具有协议选择的自由转角的相干性定理。

**Conclusion:** 本文成功提出了一个合流且终止的项重写系统，并利用其证明了具有协议选择的自由转角的相干性定理，为过程交互的范畴模型提供了理论基础。

> **ai_Abstract:** 本文提出了一个项重写系统，用于建模作为过程交互范畴模型的具有协议选择的幺半范畴的动态方面。该项重写系统被证明是合流且终止的，并被用于证明了具有协议选择的自由转角的相干性定理。

> **摘要翻译:** 我们提出了一个项重写系统，用于建模具有协议选择的幺半范畴的自由转角的动态方面，该幺半范畴已被提议作为过程交互的范畴模型。该项重写系统在适当的意义上是合流且终止的。我们利用这一机制来证明具有协议选择的自由转角的相干性定理。

</details>

[⬆️ 返回分类顶部](#mathct) | [⬆️ 返回总目录](#toc)

---

<a id='physicschem-ph'></a>
## physics.chem-ph 

### [637] [Organic Electrochemical Neurons: Nonlinear Tools for Complex Dynamics](https://arxiv.org/abs/2508.00663)
> *有机电化学神经元：复杂动力学的非线性工具*

*Gonzalo Rivera-Sierra, Roberto Fenollosa, Juan Bisquert* | **Category: physics.chem-ph, cs.SY, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 有机电化学神经元, 非线性动力学, 振荡器, 神经形态, 混合电路

**Comment:** 

> **TL;DR:** 本文提出了一个基于非线性动力学系统理论的建模和分析框架，用于理解和设计有机电化学神经元。

**AI_Comments:** 该论文的创新之处在于将非线性动力学系统理论应用于有机电化学神经元的建模和分析，提供了一种不同于传统电路理论的视角来理解其复杂行为。这种方法不仅简化了分析，还揭示了振荡产生的深层机制，为设计新型生物启发式振荡系统奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 混合振荡器架构是人工神经元设计的一个有前景的平台，但需要更深入的建模和分析来理解其复杂动力学。

**Method:** 本文引入了一个基于非线性动力学系统理论的放大器辅助有机电化学神经元的建模和分析框架。通过将系统表述为描述膜电压和内部状态变量的耦合微分方程，并利用零斜率线、相空间分析和分岔行为来表征动力学。

**Result:** 该模型揭示了振荡产生的核心机制，证明了动力学系统理论在理解和设计复杂混合电路中的实用性。它提供了对振荡器操作的标准电路理论论证的补充见解。

**Conclusion:** 所提出的框架为开发可调谐、受生物启发的振荡系统提供了一个可推广的基础，不仅适用于神经形态和生物电子应用，还可用于传感、信号处理和自适应控制。

> **ai_Abstract:** 本文提出一个利用非线性动力学系统理论对放大器辅助有机电化学神经元进行建模和分析的框架。通过耦合微分方程和相空间分析，该模型揭示了振荡的核心机制，并为理解和设计集成传统反馈组件与新型负微分电阻器件的复杂混合电路提供了严谨且易于处理的分析方法。该框架具有普适性，可应用于神经形态、生物电子以及传感、信号处理和自适应控制等领域。

> **摘要翻译:** 混合振荡器架构，结合反馈振荡器与自持负电阻振荡器，已成为人工神经元设计的一个有前景的平台。在这项工作中，我们引入了一个基于非线性动力学系统理论的放大器辅助有机电化学神经元的建模和分析框架。通过将系统表述为描述膜电压和内部状态变量的耦合微分方程，我们识别出自持振荡的条件，并通过零斜率线、相空间分析和分岔行为来表征其动力学，为振荡器操作的标准电路理论论证提供了补充见解。我们简化而严谨的模型能够对集成经典反馈组件（例如运算放大器）与表现出负微分电阻的新型器件（例如有机电化学晶体管（OECT））的电路进行易于处理的分析。这种方法揭示了振荡产生的核心机制，展示了动力学系统理论在理解和设计复杂混合电路中的实用性。除了神经形态和生物电子应用之外，所提出的框架为在传感、信号处理和自适应控制中开发可调谐、受生物启发的振荡系统提供了可推广的基础。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsplasm-ph'></a>
## physics.plasm-ph 

### [642] [Fast solvers for Tokamak fluid models with PETSC](https://arxiv.org/abs/2506.16676)
> *适用于PETSC的托卡马克流体模型快速求解器*

*Mark F. Adams, Jin Chen, Benjamin Sturdevant* | **Category: physics.plasm-ph, cs.PF** | **Updated: 2025-08-01**

**Keywords:** 托卡马克, 磁流体动力学, 多重网格, PETSC, 快速求解器

**Comment:** 

> **TL;DR:** 本文开发了一种基于半粗化多重网格的新型快速求解器，用于M3D-C1托卡马克流体模型的环向速度求解，并在SPARC4破裂模型上展示了具有竞争力的性能。

**AI_Comments:** 本文的创新之处在于将半粗化多重网格方法高效且低成本地集成到现有PETSC框架中，以优化托卡马克MHD模型中环向坐标的求解，这对于提高复杂等离子体模拟的计算效率至关重要。其重要性体现在为M3D-C1等关键聚变物理模拟代码提供了更快的求解能力，有助于加速聚变能研究。该方法有望推广到其他具有类似结构特征的物理问题中。

<details>
  <summary>Details</summary>

**Motivation:** 开发用于托卡马克磁流体动力学（MHD）模型的快速、可扩展求解器，以解决其在隐式时间积分器中产生的代数系统求解效率问题，尤其是在处理环向坐标上的挑战。

**Method:** 通过在现有的PETSC（可移植、可扩展科学计算工具包）块Jacobi求解器中添加半粗化多重网格方法，解决了M3D-C1代码中环向坐标的速度求解问题。

**Result:** 新的求解器配置在SPARC4破裂的自洽失控电子模型上展示了具有竞争力的性能。

**Conclusion:** 开发的求解器在M3D-C1模型中成功提升了环向坐标的速度求解效率，并表现出良好性能，后续开发步骤已规划，表明该研究是一个持续进行的工作。

> **ai_Abstract:** 本文旨在开发用于托卡马克磁流体动力学（MHD）模型的快速、可扩展求解器，特别是针对M3D-C1代码中环向坐标的有效处理。作者通过将半粗化多重网格方法集成到现有的PETSC块Jacobi求解器中，成功提升了M3D-C1的速度求解效率。该新求解器在模拟SPARC4破裂的自洽失控电子模型中展示了具有竞争力的性能，验证了其有效性，并为未来的进一步开发奠定了基础。

> **摘要翻译:** 这项工作开始开发用于托卡马克科学和工程相关磁流体动力学（MHD）模型的快速、可扩展求解器，利用多重网格方法。这些模型的特点是围绕环面遵循磁场的突出方向，该方向主导着等离子体动力学。所有托卡马克模型都利用了这种结构，例如，NIMROD在极向平面中使用二维、非结构化、高阶有限元，并在环向坐标中使用傅里叶模式；而三维扩展MHD代码M3D-C1在极向平面中使用二维、非结构化C1单元，并在环向方向使用三次Hermite函数和部分与磁场对齐的规则网格。这种结构建议首先处理环向坐标，NIMROD在公式化层面就做到了这一点，但M3D-C1使用完整的三维离散化。由此产生的代数系统在隐式时间积分器中的每个时间步长都被求解。这项工作通过在现有的PETSC（可移植、可扩展科学计算工具包）块Jacobi求解器中添加半粗化多重网格，解决了M3D-C1速度求解中的环向坐标问题，并且只增加了少量新代码。这种新求解器配置在SPARC4破裂的自洽失控电子模型上展示了具有竞争力的性能，并概述了该求解器开发的下一步。

</details>

[⬆️ 返回分类顶部](#physicsplasm-ph) | [⬆️ 返回总目录](#toc)

