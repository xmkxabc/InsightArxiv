{"id": "2507.01111", "title": "Environment-Aware and Human-Cooperative Swing Control for Lower-Limb Prostheses in Diverse Obstacle Scenarios", "authors": ["Haosen Xing", "Haoran Ma", "Sijin Zhang", "Hartmut Geyer"], "summary": "Current control strategies for powered lower limb prostheses often lack\nawareness of the environment and the user's intended interactions with it. This\nlimitation becomes particularly apparent in complex terrains. Obstacle\nnegotiation, a critical scenario exemplifying such challenges, requires both\nreal-time perception of obstacle geometry and responsiveness to user intention\nabout when and where to step over or onto, to dynamically adjust swing\ntrajectories. We propose a novel control strategy that fuses environmental\nawareness and human cooperativeness: an on-board depth camera detects obstacles\nahead of swing phase, prompting an elevated early-swing trajectory to ensure\nclearance, while late-swing control defers to natural biomechanical cues from\nthe user. This approach enables intuitive stepping strategies without requiring\nunnatural movement patterns. Experiments with three non-amputee participants\ndemonstrated 100 percent success across more than 150 step-overs and 30\nstep-ons with randomly placed obstacles of varying heights (4-16 cm) and\ndistances (15-70 cm). By effectively addressing obstacle navigation -- a\ngateway challenge for complex terrain mobility -- our system demonstrates\nadaptability to both environmental constraints and user intentions, with\npromising applications across diverse locomotion scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01111v1", "categories": ["cs.RO", "cs.HC"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01111v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "针对多样化障碍场景下下肢假肢的环境感知与人机协作摆动控制", "tldr": "提出一种新的下肢假肢摆动控制策略，结合环境感知和用户意图，通过深度相机检测障碍物并调整早期摆动轨迹，同时在晚期摆动中响应用户生物力学信号，实现对随机障碍物的成功跨越和踩踏。", "motivation": "当前下肢动力假肢控制策略缺乏环境感知和用户意图互动，尤其在复杂地形中表现明显。障碍物协商是此类挑战的典型场景，需要实时感知障碍物几何形状并响应用户何时何地跨越或踩踏的意图，以动态调整摆动轨迹。", "method": "提出一种融合环境感知和人机协作的新型控制策略。通过板载深度相机在摆动早期检测障碍物，促使抬高早期摆动轨迹以确保越障间隙；同时，晚期摆动控制则遵循用户自然的生物力学线索。", "result": "对三名非截肢参与者的实验表明，在超过150次跨越和30次踩踏随机放置的、不同高度（4-16厘米）和距离（15-70厘米）的障碍物时，均取得了100%的成功率。", "conclusion": "该系统通过有效解决障碍物导航（复杂地形移动性的关键挑战），展示了对环境约束和用户意图的适应性，在多样化运动场景中具有广阔的应用前景。", "translation": "当前动力下肢假肢的控制策略通常缺乏对环境及其与用户预期互动的感知。这种局限性在复杂地形中尤为明显。障碍物协商是此类挑战的典型场景，它要求实时感知障碍物几何形状并响应用户关于何时何地跨越或踩踏的意图，以动态调整摆动轨迹。我们提出了一种融合环境感知和人机协作的新型控制策略：板载深度相机在摆动早期阶段检测障碍物，促使抬高早期摆动轨迹以确保越障间隙，而晚期摆动控制则遵循用户自然的生物力学线索。这种方法实现了直观的踩踏策略，而无需不自然的运动模式。对三名非截肢参与者的实验表明，在超过150次跨越和30次踩踏随机放置的、不同高度（4-16厘米）和距离（15-70厘米）的障碍物时，均取得了100%的成功率。通过有效解决障碍物导航——复杂地形移动性的关键挑战——我们的系统展示了对环境约束和用户意图的适应性，在多样化运动场景中具有广阔的应用前景。", "summary": "本文提出一种新型下肢假肢摆动控制策略，旨在解决现有假肢在复杂地形中缺乏环境感知和用户协作的问题。该策略结合板载深度相机进行障碍物检测以调整早期摆动轨迹，并利用用户生物力学信号指导晚期摆动，从而实现直观且成功的障碍物跨越和踩踏。实验验证了其在多样化障碍场景下的高效性和适应性。", "keywords": "下肢假肢, 摆动控制, 环境感知, 人机协作, 障碍物导航", "comments": "这篇论文的创新点在于将环境感知（通过深度相机）与人机协作（响应用户生物力学 cues）相结合，为下肢假肢提供更自然、更灵活的障碍物导航能力。其重要性在于解决了当前假肢在复杂地形移动性方面的关键限制，并展示了在实际应用中的巨大潜力，尤其是在提高截肢者生活质量方面。"}}
{"id": "2507.01125", "title": "VISTA: Open-Vocabulary, Task-Relevant Robot Exploration with Online Semantic Gaussian Splatting", "authors": ["Keiko Nagami", "Timothy Chen", "Javier Yu", "Ola Shorinwa", "Maximilian Adang", "Carlyn Dougherty", "Eric Cristofalo", "Mac Schwager"], "summary": "We present VISTA (Viewpoint-based Image selection with Semantic Task\nAwareness), an active exploration method for robots to plan informative\ntrajectories that improve 3D map quality in areas most relevant for task\ncompletion. Given an open-vocabulary search instruction (e.g., \"find a\nperson\"), VISTA enables a robot to explore its environment to search for the\nobject of interest, while simultaneously building a real-time semantic 3D\nGaussian Splatting reconstruction of the scene. The robot navigates its\nenvironment by planning receding-horizon trajectories that prioritize semantic\nsimilarity to the query and exploration of unseen regions of the environment.\nTo evaluate trajectories, VISTA introduces a novel, efficient\nviewpoint-semantic coverage metric that quantifies both the geometric view\ndiversity and task relevance in the 3D scene. On static datasets, our coverage\nmetric outperforms state-of-the-art baselines, FisherRF and Bayes' Rays, in\ncomputation speed and reconstruction quality. In quadrotor hardware\nexperiments, VISTA achieves 6x higher success rates in challenging maps,\ncompared to baseline methods, while matching baseline performance in less\nchallenging maps. Lastly, we show that VISTA is platform-agnostic by deploying\nit on a quadrotor drone and a Spot quadruped robot. Open-source code will be\nreleased upon acceptance of the paper.", "comment": "9 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.01125v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01125v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "VISTA：基于在线语义高斯泼溅的开放词汇、任务相关机器人探索", "tldr": "VISTA是一种机器人主动探索方法，通过规划信息丰富的轨迹来改进与任务完成最相关区域的3D地图质量，同时构建实时语义3D高斯泼溅重建。", "motivation": "为了使机器人能够根据开放词汇指令（例如“寻找一个人”）探索环境并搜索感兴趣的对象，同时构建实时语义3D重建，本研究旨在开发一种主动探索方法，以提高与任务完成最相关区域的3D地图质量。", "method": "VISTA（Viewpoint-based Image selection with Semantic Task Awareness）是一种主动探索方法。它使机器人通过规划后退式轨迹来导航环境，这些轨迹优先考虑与查询的语义相似性以及对未探索区域的探索。为了评估轨迹，VISTA引入了一种新颖、高效的视点-语义覆盖度量，该度量量化了3D场景中的几何视图多样性和任务相关性。该方法同时构建场景的实时语义3D高斯泼溅重建。", "result": "在静态数据集上，VISTA的覆盖度量在计算速度和重建质量方面优于最先进的基线方法FisherRF和Bayes' Rays。在四旋翼硬件实验中，VISTA在具有挑战性的地图中实现了比基线方法高6倍的成功率，同时在挑战性较低的地图中与基线性能匹配。此外，VISTA被证明是平台无关的，因为它可以在四旋翼无人机和Spot四足机器人上部署。", "conclusion": "VISTA是一种有效且通用的机器人主动探索方法，它通过结合在线语义3D高斯泼溅和创新的视点-语义覆盖度量，显著提高了机器人探索任务的成功率和地图质量，尤其是在复杂环境中。", "translation": "我们提出了VISTA（基于视点的图像选择与语义任务感知），这是一种主动探索方法，用于机器人规划信息丰富的轨迹，以提高与任务完成最相关区域的3D地图质量。给定一个开放词汇搜索指令（例如“寻找一个人”），VISTA使机器人能够探索其环境以搜索感兴趣的对象，同时实时构建场景的语义3D高斯泼溅重建。机器人通过规划后退式轨迹来导航其环境，这些轨迹优先考虑与查询的语义相似性以及对环境中未见区域的探索。为了评估轨迹，VISTA引入了一种新颖、高效的视点-语义覆盖度量，该度量量化了3D场景中的几何视图多样性和任务相关性。在静态数据集上，我们的覆盖度量在计算速度和重建质量方面优于最先进的基线方法FisherRF和Bayes' Rays。在四旋翼硬件实验中，VISTA在具有挑战性的地图中实现了比基线方法高6倍的成功率，同时在挑战性较低的地图中与基线性能匹配。最后，我们通过在四旋翼无人机和Spot四足机器人上部署VISTA，表明它是平台无关的。论文接收后将发布开源代码。", "summary": "VISTA是一种新颖的机器人主动探索方法，它结合了开放词汇搜索、实时语义3D高斯泼溅重建和创新的视点-语义覆盖度量。该方法使机器人能够规划任务相关的轨迹，以改进3D地图质量，并有效搜索指定对象。实验结果表明，VISTA在计算效率、重建质量和任务成功率方面均优于现有基线，并且具有良好的平台通用性。", "keywords": "机器人探索, 语义高斯泼溅, 开放词汇, 3D重建, 主动探索", "comments": "VISTA的创新点在于结合了开放词汇理解与实时语义3D高斯泼溅重建，并提出了一种高效的视点-语义覆盖度量，这对于机器人进行任务相关的探索至关重要。其在复杂环境下的高成功率和平台无关性显示了该方法的实用性和广阔的应用前景。该研究为机器人主动感知和探索领域提供了重要的进展。"}}
{"id": "2507.01143", "title": "A Review on Sound Source Localization in Robotics: Focusing on Deep Learning Methods", "authors": ["Reza Jalayer", "Masoud Jalayer", "Amirali Baniasadi"], "summary": "Sound source localization (SSL) adds a spatial dimension to auditory\nperception, allowing a system to pinpoint the origin of speech, machinery\nnoise, warning tones, or other acoustic events, capabilities that facilitate\nrobot navigation, human-machine dialogue, and condition monitoring. While\nexisting surveys provide valuable historical context, they typically address\ngeneral audio applications and do not fully account for robotic constraints or\nthe latest advancements in deep learning. This review addresses these gaps by\noffering a robotics-focused synthesis, emphasizing recent progress in deep\nlearning methodologies. We start by reviewing classical methods such as Time\nDifference of Arrival (TDOA), beamforming, Steered-Response Power (SRP), and\nsubspace analysis. Subsequently, we delve into modern machine learning (ML) and\ndeep learning (DL) approaches, discussing traditional ML and neural networks\n(NNs), convolutional neural networks (CNNs), convolutional recurrent neural\nnetworks (CRNNs), and emerging attention-based architectures. The data and\ntraining strategy that are the two cornerstones of DL-based SSL are explored.\nStudies are further categorized by robot types and application domains to\nfacilitate researchers in identifying relevant work for their specific\ncontexts. Finally, we highlight the current challenges in SSL works in general,\nregarding environmental robustness, sound source multiplicity, and specific\nimplementation constraints in robotics, as well as data and learning strategies\nin DL-based SSL. Also, we sketch promising directions to offer an actionable\nroadmap toward robust, adaptable, efficient, and explainable DL-based SSL for\nnext-generation robots.", "comment": "35 pages", "pdf_url": "http://arxiv.org/pdf/2507.01143v1", "categories": ["cs.RO", "cs.LG", "cs.SD", "eess.AS"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01143v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "机器人中声源定位综述：聚焦深度学习方法", "tldr": "这是一篇关于机器人中声源定位（SSL）的综述，特别是聚焦于深度学习方法，涵盖了从经典到现代的方法、数据和训练策略、机器人类型、应用、挑战以及未来方向。", "motivation": "现有声源定位综述未能充分考虑机器人领域的特定限制以及深度学习的最新进展，本综述旨在弥补这些空白。", "method": "本综述首先回顾了时差（TDOA）、波束形成、转向响应功率（SRP）和子空间分析等经典方法。随后深入探讨了机器学习和深度学习方法，包括传统机器学习、神经网络、卷积神经网络、卷积循环神经网络和基于注意力机制的架构。此外，还探讨了基于深度学习的声源定位中的数据和训练策略，并根据机器人类型和应用领域对研究进行了分类。最后，强调了声源定位在环境鲁棒性、声源多重性、机器人特定实现限制以及深度学习数据和学习策略方面的挑战，并提出了未来发展方向。", "result": "本综述综合了机器人领域声源定位的研究进展，重点关注深度学习方法。它系统地介绍了经典与现代声源定位方法、深度学习的数据与训练策略，并根据机器人类型和应用领域对现有研究进行了分类。此外，还明确指出了当前声源定位面临的挑战，并为下一代机器人中鲁棒、适应性强、高效且可解释的深度学习声源定位提供了可行的路线图。", "conclusion": "本综述指出了当前声源定位在环境鲁棒性、声源多重性、机器人特定实现限制以及深度学习数据和学习策略方面的挑战，并为下一代机器人中鲁棒、适应性强、高效且可解释的深度学习声源定位描绘了有前景的方向和可行的路线图。", "translation": "声源定位（SSL）为听觉感知增加了空间维度，使系统能够精确识别语音、机械噪音、警告音或其他声学事件的来源，这些能力有助于机器人导航、人机对话和状态监测。虽然现有综述提供了宝贵的历史背景，但它们通常针对一般音频应用，未能充分考虑机器人约束或深度学习的最新进展。本综述通过提供一个以机器人为重点的综合性分析，强调深度学习方法的最新进展来弥补这些空白。我们首先回顾了时差（TDOA）、波束形成、转向响应功率（SRP）和子空间分析等经典方法。随后，我们深入探讨了现代机器学习（ML）和深度学习（DL）方法，讨论了传统机器学习和神经网络（NNs）、卷积神经网络（CNNs）、卷积循环神经网络（CRNNs）以及新兴的基于注意力机制的架构。探索了作为基于深度学习的声源定位两大基石的数据和训练策略。研究进一步按机器人类型和应用领域进行分类，以方便研究人员为其特定上下文识别相关工作。最后，我们强调了声源定位工作普遍面临的当前挑战，包括环境鲁棒性、声源多重性以及机器人中的特定实现约束，以及基于深度学习的声源定位中的数据和学习策略。此外，我们还勾勒出有前景的方向，为下一代机器人中鲁棒、适应性强、高效且可解释的基于深度学习的声源定位提供可行的路线图。", "summary": "本综述全面分析了机器人领域的声源定位（SSL），特别侧重于深度学习方法。它通过解决机器人约束和最新的深度学习进展，弥补了现有文献中的空白。论文涵盖了经典和现代的机器学习/深度学习技术、数据和训练策略，并根据机器人类型和应用对研究进行了分类。此外，它还讨论了当前面临的挑战，如环境鲁棒性和数据限制，并概述了为下一代机器人开发鲁棒高效的基于深度学习的SSL系统的未来研究方向。", "keywords": "声源定位, 机器人, 深度学习, 综述, 声学事件", "comments": "这篇综述对于机器人和音频处理领域的研究人员来说非常重要，因为它专门针对机器人应用整合了声源定位中深度学习的最新进展，弥补了现有文献中的关键空白。它提供了结构化的概述，指出了主要挑战，并为未来的研究提供了路线图，使其成为一份宝贵的资源。"}}
{"id": "2507.01152", "title": "SonoGym: High Performance Simulation for Challenging Surgical Tasks with Robotic Ultrasound", "authors": ["Yunke Ao", "Masoud Moghani", "Mayank Mittal", "Manish Prajapat", "Luohong Wu", "Frederic Giraud", "Fabio Carrillo", "Andreas Krause", "Philipp Fürnstahl"], "summary": "Ultrasound (US) is a widely used medical imaging modality due to its\nreal-time capabilities, non-invasive nature, and cost-effectiveness. Robotic\nultrasound can further enhance its utility by reducing operator dependence and\nimproving access to complex anatomical regions. For this, while deep\nreinforcement learning (DRL) and imitation learning (IL) have shown potential\nfor autonomous navigation, their use in complex surgical tasks such as anatomy\nreconstruction and surgical guidance remains limited -- largely due to the lack\nof realistic and efficient simulation environments tailored to these tasks. We\nintroduce SonoGym, a scalable simulation platform for complex robotic\nultrasound tasks that enables parallel simulation across tens to hundreds of\nenvironments. Our framework supports realistic and real-time simulation of US\ndata from CT-derived 3D models of the anatomy through both a physics-based and\na generative modeling approach. Sonogym enables the training of DRL and recent\nIL agents (vision transformers and diffusion policies) for relevant tasks in\nrobotic orthopedic surgery by integrating common robotic platforms and\northopedic end effectors. We further incorporate submodular DRL -- a recent\nmethod that handles history-dependent rewards -- for anatomy reconstruction and\nsafe reinforcement learning for surgery. Our results demonstrate successful\npolicy learning across a range of scenarios, while also highlighting the\nlimitations of current methods in clinically relevant environments. We believe\nour simulation can facilitate research in robot learning approaches for such\nchallenging robotic surgery applications. Dataset, codes, and videos are\npublicly available at https://sonogym.github.io/.", "comment": "21 pages, 15 figures", "pdf_url": "http://arxiv.org/pdf/2507.01152v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01152v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "SonoGym：用于机器人超声挑战性外科任务的高性能模拟", "tldr": "SonoGym是一个可扩展的高性能模拟平台，用于训练机器人超声在复杂外科任务中的DRL/IL代理，解决了现有模拟环境不足的问题。", "motivation": "深度强化学习（DRL）和模仿学习（IL）在自主导航方面显示出潜力，但在解剖重建和手术指导等复杂外科任务中的应用受限，主要是因为缺乏针对这些任务的真实高效的模拟环境。", "method": "本文引入了SonoGym，一个可扩展的模拟平台，支持复杂机器人超声任务的并行模拟。该框架通过基于物理和生成建模的方法，支持从CT衍生的3D解剖模型中实时模拟超声数据。SonoGym通过集成常见的机器人平台和骨科末端执行器，能够训练DRL和最新的IL代理（视觉转换器和扩散策略）用于机器人骨科手术中的相关任务。此外，还结合了子模DRL（处理历史依赖奖励）用于解剖重建和手术中的安全强化学习。", "result": "结果表明在各种场景下成功实现了策略学习，同时也突出了当前方法在临床相关环境中的局限性。", "conclusion": "作者认为SonoGym模拟平台可以促进机器人学习方法在具有挑战性的机器人手术应用中的研究。", "translation": "超声（US）因其实时性、非侵入性和成本效益而成为一种广泛使用的医学成像方式。机器人超声可以通过减少操作员依赖性和改善对复杂解剖区域的访问来进一步增强其效用。为此，虽然深度强化学习（DRL）和模仿学习（IL）在自主导航方面显示出潜力，但它们在解剖重建和手术指导等复杂外科任务中的使用仍然有限——这主要是由于缺乏针对这些任务的真实高效的模拟环境。我们引入了SonoGym，一个用于复杂机器人超声任务的可扩展模拟平台，它能够跨数十到数百个环境进行并行模拟。我们的框架通过基于物理和生成建模的方法，支持从CT衍生的3D解剖模型中实时模拟超声数据。SonoGym通过集成常见的机器人平台和骨科末端执行器，能够训练DRL和最近的IL代理（视觉转换器和扩散策略）用于机器人骨科手术中的相关任务。我们进一步结合了子模DRL——一种处理历史依赖奖励的最新方法——用于解剖重建和手术中的安全强化学习。我们的结果表明在各种场景下成功实现了策略学习，同时也突出了当前方法在临床相关环境中的局限性。我们相信我们的模拟可以促进机器人学习方法在这些具有挑战性的机器人手术应用中的研究。数据集、代码和视频可在 https://sonogym.github.io/ 公开获取。", "summary": "本文介绍了SonoGym，一个用于复杂机器人超声任务的高性能、可扩展模拟平台。针对现有模拟环境不足导致深度强化学习和模仿学习在机器人超声复杂外科任务中应用受限的问题，SonoGym提供了真实且实时的超声数据模拟能力，支持并行训练DRL和IL代理，并集成了先进的强化学习方法。实验证明该平台能成功学习策略，有望推动机器人学习在挑战性外科应用中的研究。", "keywords": "机器人超声, 模拟, 深度强化学习, 模仿学习, 外科手术", "comments": "该论文的创新点在于提出了一个高性能、可扩展的机器人超声模拟平台SonoGym，解决了现有模拟环境不足的痛点。其重要性体现在为复杂机器人手术任务（如解剖重建和手术指导）的DRL/IL代理训练提供了真实、高效的模拟环境，并支持并行模拟和多种先进学习方法。这对于加速机器人辅助手术的研发和应用具有重要意义。论文还公开了数据集和代码，有利于社区的进一步研究。"}}
{"id": "2507.01231", "title": "Rethinking the Illusion of Thinking", "authors": ["Iñaki Dellibarda Varela", "Pablo Romero-Sorozabal", "Eduardo Rocon", "Manuel Cebrian"], "summary": "Earlier this year, Apple ignited controversy by publishing \"The Illusion of\nThinking,\" prompting heated debate within the AI community. Critics seized upon\nthe findings as conclusive evidence that Large Reasoning Models (LRMs) lack\ngenuine reasoning capabilities, branding them as mere stochastic parrots.\nMeanwhile, defenders-spearheaded by Lawsen et al. (2025)-fired back, condemning\nthe experimental setup as flawed and the conclusions overstated. We clarify\nthis debate by replicating and refining two of the original study's most\ncontentious benchmarks: Towers of Hanoi and River Crossing. By introducing\nincremental stepwise prompting and agentic collaborative dialogue, we show that\npreviously reported failures solving the Towers of Hanoi were not purely result\nof output constraints, but also partly a result of cognition limitations: LRMs\nstill stumble when complexity rises moderately (around 8 disks). Moreover, the\nRiver Crossing results initially heralded as catastrophic failures turn out to\nhinge upon testing unsolvable configurations. Once we limit tests strictly to\nsolvable problems-LRMs effortlessly solve large instances involving over 100\nagent pairs. Our findings ultimately defy simplistic narratives: today's LRMs\nare stochastic, RL-tuned searchers in a discrete state space we barely\nunderstand. Real progress in symbolic, long-horizon reasoning demands mapping\nthat terrain through fine-grained ablations like those introduced here.", "comment": "8 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.01231v1", "categories": ["cs.AI"], "cate": "cs.AI", "url": "http://arxiv.org/abs/2507.01231v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "再思“思维的幻觉”", "tldr": "本文通过复现并改进苹果公司“思维的幻觉”研究中的两个基准测试（汉诺塔和过河问题），澄清了大型推理模型（LRMs）的推理能力争议。研究发现，汉诺塔的失败部分源于认知局限，而过河问题的失败则在于测试了无解配置。最终认为LRMs是离散状态空间中的随机、RL调优搜索器，并强调需通过精细消融实验推进符号推理。", "motivation": "苹果公司发表的“思维的幻觉”引发了关于大型推理模型（LRMs）是否具备真正推理能力的激烈辩论。批评者认为LRMs只是“随机鹦鹉”，而支持者则指责实验设置有缺陷。本文旨在通过复现和改进原始研究的基准测试来澄清这场辩论。", "method": "作者复现并改进了原始研究中两个最具争议的基准测试：汉诺塔（Towers of Hanoi）和过河问题（River Crossing）。通过引入增量逐步提示（incremental stepwise prompting）和代理协作对话（agentic collaborative dialogue），并严格限制过河问题只测试可解配置。", "result": "汉诺塔问题：之前报告的失败并非完全是输出限制的结果，部分原因在于认知局限——当复杂度适度增加（大约8个盘）时，LRMs仍然会遇到困难。过河问题：最初被认为是灾难性失败的结果，实际上取决于测试了无解配置。一旦严格限制只测试可解问题，LRMs可以毫不费力地解决涉及100多对代理的大型实例。", "conclusion": "今天的LRMs是离散状态空间中的随机、经强化学习（RL）调优的搜索器，我们对其理解甚少。符号式、长程推理的真正进展需要通过本文引入的这类精细消融实验来探索该领域。", "translation": "今年早些时候，苹果公司发表了“思维的幻觉”，引发了争议，并在AI社区内引起了激烈辩论。批评者抓住这些发现，将其作为大型推理模型（LRMs）缺乏真正推理能力的决定性证据，称它们为单纯的随机鹦鹉。与此同时，以Lawsen等人（2025年）为首的捍卫者则反击，谴责实验设置存在缺陷且结论言过其实。我们通过复现和改进原始研究中最具争议的两个基准测试：汉诺塔和过河问题，来澄清这场辩论。通过引入增量逐步提示和代理协作对话，我们发现之前报告的汉诺塔问题求解失败并非纯粹是输出限制的结果，而是部分源于认知局限：当复杂度适度增加（大约8个盘）时，LRMs仍然会遇到困难。此外，最初被认为是灾难性失败的过河问题结果，实际上取决于测试了无解配置。一旦我们严格限制只测试可解问题，LRMs可以毫不费力地解决涉及100多对代理的大型实例。我们的发现最终挑战了简单化的叙述：今天的LRMs是离散状态空间中的随机、经强化学习调优的搜索器，我们对其理解甚少。符号式、长程推理的真正进展需要通过像本文引入的这类精细消融实验来探索该领域。", "summary": "本文旨在澄清围绕大型推理模型（LRMs）推理能力的争议。通过复现并改进苹果公司“思维的幻觉”论文中的汉诺塔和过河问题基准测试，研究发现LRMs在汉诺塔问题上的失败部分归因于认知局限，而非单纯的输出限制；而在过河问题上，其失败是因为测试了无解配置。纠正测试设置后，LRMs能有效解决大型可解实例。研究强调，当前的LRMs是离散状态空间中的随机搜索器，并呼吁通过精细的消融实验来推动符号式、长程推理的真正发展。", "keywords": "大型推理模型, 汉诺塔, 过河问题, 认知局限, 随机搜索器", "comments": "本文通过严谨的实验复现和改进，对当前关于大型推理模型（LRMs）能力的争议进行了深入分析。其创新之处在于引入了增量逐步提示和代理协作对话，并纠正了原始研究中测试无解配置的问题。这不仅澄清了误解，也为未来评估和提升LRMs的推理能力指明了方向，强调了理解LRMs内部工作机制和探索离散状态空间的重要性。"}}
{"id": "2507.01065", "title": "Is It Safe To Learn And Share? On Psychological Safety and Social Learning in (Agile) Communities of Practice", "authors": ["Christiaan Verwijs", "Evelien Acun-Roos", "Daniel Russo"], "summary": "As hybrid, distributed, and asynchronous work models become more prevalent,\ncontinuous learning in Agile Software Development (ASD) gains renewed\nimportance. Communities of Practice (CoPs) are increasingly adopted to support\nsocial learning beyond formal education, often relying on virtual\ncommunication. Psychological safety, a prerequisite for effective learning,\nremains insufficiently understood in these settings. This mixed-methods study\ninvestigates psychological safety within Agile CoPs through survey data from\n143 participants. Results indicate that psychological safety is significantly\nlower in online interactions compared to face-to-face settings. Moreover, low\npsychological safety reduces participants' intent to continue contributing and\navoidance of interpersonal risk. No significant differences emerged based on\ngender, community seniority, or content creation activity. However, differences\nby role and age group suggest potential generational or role-related effects.\nThematic analysis revealed exclusionary behavior, negative interaction\npatterns, and hostility as primary threats to psychological safety, often\nreinforced by tribalism and specific community dynamics. Suggested\ninterventions include establishing explicit norms, structured facilitation, and\nactive moderation. The findings were validated through member checking with 30\nparticipants. This study provides a comparative perspective on interaction\nmodalities and offers practical guidance for organizers seeking to cultivate\ninclusive, high-impact CoPs and similarly structured virtual or hybrid work\nenvironments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01065v1", "categories": ["cs.SE"], "cate": "cs.SE", "url": "http://arxiv.org/abs/2507.01065v1", "date": "2025-06-30", "updated": "2025-06-30", "AI": {"title_translation": "学习和分享安全吗？关于（敏捷）实践社区中的心理安全和社会学习", "tldr": "本研究发现，在敏捷实践社区中，线上互动的心理安全感显著低于面对面互动，且低心理安全会降低参与者的贡献意愿。", "motivation": "随着混合、分布式和异步工作模式的普及，敏捷软件开发中的持续学习变得日益重要。实践社区（CoPs）被广泛用于支持正式教育之外的社会学习，但心理安全作为有效学习的先决条件，在这些设置中仍未得到充分理解。", "method": "本研究采用混合方法，通过对143名参与者的调查数据，调查了敏捷实践社区中的心理安全。研究还通过主题分析揭示了心理安全的威胁，并通过30名参与者的成员核查验证了研究结果。", "result": "研究结果表明，在线互动中的心理安全感显著低于面对面设置。此外，低心理安全会降低参与者的持续贡献意愿和对人际风险的规避。性别、社区资历或内容创作活动没有显著差异，但角色和年龄组的差异表明可能存在代际或角色相关的影响。主题分析揭示了排他行为、消极互动模式和敌意是心理安全的主要威胁，这些威胁常因部落主义和特定社区动态而加剧。", "conclusion": "本研究提供了关于互动模式的比较视角，并为组织者提供了实用指导，以培养包容、高影响力的实践社区以及类似的虚拟或混合工作环境。", "translation": "随着混合、分布式和异步工作模式变得越来越普遍，敏捷软件开发（ASD）中的持续学习重新获得了重要性。实践社区（CoPs）越来越多地被采纳，以支持超越正规教育的社会学习，通常依赖于虚拟沟通。心理安全作为有效学习的先决条件，在这些环境中仍未得到充分理解。这项混合方法研究通过来自143名参与者的调查数据，调查了敏捷实践社区中的心理安全。结果表明，在线互动中的心理安全感显著低于面对面设置。此外，低心理安全会降低参与者的持续贡献意愿和对人际风险的规避。在性别、社区资历或内容创作活动方面没有出现显著差异。然而，角色和年龄组的差异表明可能存在潜在的代际或角色相关效应。主题分析揭示了排他行为、消极互动模式和敌意是心理安全的主要威胁，这些威胁常常因部落主义和特定的社区动态而加剧。建议的干预措施包括建立明确的规范、结构化引导和积极的调节。研究结果通过与30名参与者的成员核查得到了验证。这项研究提供了关于互动模式的比较视角，并为寻求培养包容、高影响力的实践社区以及类似结构化虚拟或混合工作环境的组织者提供了实用指导。", "summary": "本研究旨在探讨在日益普及的混合和虚拟敏捷实践社区中，心理安全如何影响社会学习。通过对143名参与者的混合方法研究发现，在线互动中的心理安全感显著低于面对面交流，且低心理安全会削弱参与者的贡献意愿。研究识别了排他行为、消极互动和敌意等威胁，并提出了建立明确规范、结构化引导和积极调节等干预措施，为提升虚拟工作环境中学习社区的心理安全提供了实用指导。", "keywords": "心理安全, 敏捷实践社区, 社会学习, 混合工作, 在线互动", "comments": "该研究及时且重要，因为它关注了在当前混合和远程工作趋势下，虚拟协作环境中一个关键但常被忽视的因素——心理安全。其混合方法研究设计增加了结果的深度和可信度。研究不仅指出了问题（在线心理安全低），还深入分析了威胁因素（排他行为、部落主义）并提供了可行的干预措施，使其具有很强的实践指导意义。"}}
{"id": "2507.01018", "title": "A Systematic Review of Security Vulnerabilities in Smart Home Devices and Mitigation Techniques", "authors": ["Mohammed K. Alzaylaee"], "summary": "Smart homes that integrate Internet of Things (IoT) devices face increasing\ncybersecurity risks, posing significant challenges to these environments. The\nstudy explores security threats in smart homes ecosystems, categorizing them\ninto vulnerabilities at the network layer, device level, and those from\ncloud-based and AI-driven systems. Research findings indicate that post-quantum\nencryption, coupled with AI-driven anomaly detection, is highly effective in\nenhancing security; however, computational resource demands present significant\nchallenges. Blockchain authentication together with zero-trust structures\nbuilds security resilience, although they need changes to existing\ninfrastructure. The specific security strategies show their effectiveness\nthrough ANOVA, Chi-square tests, and Monte Carlo simulations yet lack\nsufficient scalability according to the results. The research demonstrates the\nrequirement for improvement in cryptographic techniques, alongside AI-enhanced\nthreat detection and adaptive security models which must achieve a balance\nbetween performance and efficiency and real-time applicability within smart\nhome ecosystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01018v1", "categories": ["cs.CR", "cs.AI"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01018v1", "date": "2025-04-03", "updated": "2025-04-03", "AI": {"title_translation": "智能家居设备安全漏洞及缓解技术系统综述", "tldr": "本研究系统综述了智能家居设备的安全漏洞，并评估了后量子加密、AI异常检测、区块链认证和零信任结构等缓解技术，发现它们有效但面临资源、基础设施和可扩展性挑战，强调需改进加密和AI增强威胁检测。", "motivation": "智能家居集成物联网设备面临日益增长的网络安全风险，对这些环境构成重大挑战，因此需要探索智能家居生态系统中的安全威胁。", "method": "该研究探索了智能家居生态系统中的安全威胁，将其分为网络层、设备级别以及基于云和AI驱动系统中的漏洞。研究评估了后量子加密结合AI驱动的异常检测、以及区块链认证结合零信任结构等特定安全策略的有效性，并通过ANOVA、卡方检验和蒙特卡洛模拟进行了测试。", "result": "研究发现，后量子加密结合AI驱动的异常检测在增强安全性方面非常有效，但计算资源需求带来挑战。区块链认证结合零信任结构能增强安全弹性，但需要改变现有基础设施。这些特定安全策略通过统计测试（ANOVA, Chi-square tests, Monte Carlo simulations）显示出有效性，但结果表明它们缺乏足够的可扩展性。", "conclusion": "研究表明，需要改进加密技术，同时增强AI威胁检测和自适应安全模型，这些模型必须在智能家居生态系统中实现性能、效率和实时适用性之间的平衡。", "translation": "整合物联网（IoT）设备的智能家居面临日益增长的网络安全风险，对这些环境构成重大挑战。本研究探讨了智能家居生态系统中的安全威胁，将其分为网络层、设备级别以及来自基于云和AI驱动系统中的漏洞。研究结果表明，后量子加密结合AI驱动的异常检测在增强安全性方面非常有效；然而，计算资源需求带来了重大挑战。区块链认证结合零信任结构构建了安全弹性，尽管它们需要改变现有基础设施。通过ANOVA、卡方检验和蒙特卡洛模拟，特定的安全策略显示出其有效性，但根据结果，它们缺乏足够的可扩展性。研究表明，需要改进加密技术，同时增强AI威胁检测和自适应安全模型，这些模型必须在智能家居生态系统中实现性能、效率和实时适用性之间的平衡。", "summary": "本文对智能家居设备的安全漏洞进行了系统综述，并将其分为网络层、设备层和云/AI系统漏洞。研究评估了后量子加密结合AI异常检测、以及区块链认证结合零信任结构等缓解技术，发现它们在提升安全性方面有效，但分别面临计算资源、基础设施改造和可扩展性不足的挑战。研究强调，未来的智能家居安全需在加密技术、AI增强威胁检测和自适应安全模型方面取得进展，以平衡性能、效率和实时适用性。", "keywords": "智能家居安全, 物联网安全, 安全漏洞, 缓解技术, 后量子加密", "comments": "本文对智能家居安全漏洞及其缓解技术进行了全面的系统综述，分类清晰。其创新点在于结合了后量子加密、AI异常检测、区块链和零信任等前沿技术进行评估，并指出了这些技术在实际应用中面临的资源、基础设施和可扩展性等关键限制，为未来的研究和开发提供了明确的方向。"}}
{"id": "2507.01239", "title": "A Full-Stack Platform Architecture for Self-Organised Social Coordination", "authors": ["Matthew Scott", "Jeremy Pitt"], "summary": "To mitigate the restrictive centralising and monopolistic tendencies of\nplatformisation, we aim to empower local communities by democratising platforms\nfor self-organised social coordination. Our approach is to develop an\nopen-source, full-stack architecture for platform development that supports\nease of distribution and cloning, generativity, and a variety of hosting\noptions. The architecture consists of a meta-platform that is used to\ninstantiate a base platform with supporting libraries for generic functions,\nand plugins (intended to be supplied by third parties) for customisation of\napplication-specification functionality for self-organised social coordination.\nAssociated developer- and user-oriented toolchains support the instantiation\nand customisation of a platform in a two-stage process. This is demonstrated\nthrough the proof-of-concept implementation of two case studies: a platform for\nregular sporting association, and a platform for collective group study. We\nconclude by arguing that self-organisation at the application layer can be\nachieved by the specific supporting functionality of a full-stack architecture\nwith complimentary developer and user toolchains.", "comment": "10 pages, 10 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.01239v1", "categories": ["cs.NI"], "cate": "cs.NI", "url": "http://arxiv.org/abs/2507.01239v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "一种用于自组织社会协调的全栈平台架构", "tldr": "该论文提出一种开源全栈平台架构，旨在通过民主化平台赋能本地社区进行自组织社会协调，并通过两个案例研究进行了验证。", "motivation": "为了减轻平台化带来的限制性中心化和垄断趋势，旨在通过民主化平台赋能本地社区进行自组织社会协调。", "method": "开发一个开源的全栈平台架构，该架构包含一个元平台、通用功能库和第三方插件，并辅以开发者和用户工具链，以支持平台的实例化和定制化。", "result": "通过两个概念验证案例（体育协会平台和集体学习平台）的实现，验证了该架构的可行性。", "conclusion": "通过具有互补的开发者和用户工具链的全栈架构的特定支持功能，可以实现在应用层的自组织。", "translation": "为了减轻平台化带来的限制性中心化和垄断趋势，我们旨在通过民主化平台赋能本地社区进行自组织社会协调。我们的方法是开发一个开源的全栈平台架构，该架构支持易于分发和克隆、生成性以及多种托管选项。该架构由一个元平台组成，该元平台用于实例化一个基础平台，并提供用于通用功能的支撑库以及用于自组织社会协调的应用特定功能定制的插件（旨在由第三方提供）。相关的面向开发者和用户的工具链支持平台在两阶段过程中的实例化和定制。通过两个案例研究的概念验证实现对此进行了演示：一个用于常规体育协会的平台，以及一个用于集体小组学习的平台。我们最后指出，通过具有互补的开发者和用户工具链的全栈架构的特定支持功能，可以实现在应用层的自组织。", "summary": "该论文提出一种开源全栈平台架构，旨在通过民主化平台对抗平台化的中心化和垄断趋势，赋能本地社区进行自组织社会协调。该架构包含元平台、基础平台、通用功能库和第三方插件，并结合开发者和用户工具链，支持平台的分发、克隆、生成和定制。通过体育协会和集体学习两个案例的实现，验证了其在实现应用层自组织方面的有效性。", "keywords": "全栈平台架构, 自组织社会协调, 开源, 平台民主化, 元平台", "comments": "该论文提出了一种创新的全栈平台架构，旨在解决当前平台化带来的中心化和垄断问题，通过赋能本地社区实现自组织。其开源、易于分发和定制的特性，以及元平台和插件的设计理念，为去中心化的社会协调提供了新的可能性。概念验证案例的演示增强了其可行性，但具体推广和社区采纳的挑战仍需进一步探讨。"}}
{"id": "2507.01099", "title": "Geometry-aware 4D Video Generation for Robot Manipulation", "authors": ["Zeyi Liu", "Shuang Li", "Eric Cousineau", "Siyuan Feng", "Benjamin Burchfiel", "Shuran Song"], "summary": "Understanding and predicting the dynamics of the physical world can enhance a\nrobot's ability to plan and interact effectively in complex environments. While\nrecent video generation models have shown strong potential in modeling dynamic\nscenes, generating videos that are both temporally coherent and geometrically\nconsistent across camera views remains a significant challenge. To address\nthis, we propose a 4D video generation model that enforces multi-view 3D\nconsistency of videos by supervising the model with cross-view pointmap\nalignment during training. This geometric supervision enables the model to\nlearn a shared 3D representation of the scene, allowing it to predict future\nvideo sequences from novel viewpoints based solely on the given RGB-D\nobservations, without requiring camera poses as inputs. Compared to existing\nbaselines, our method produces more visually stable and spatially aligned\npredictions across multiple simulated and real-world robotic datasets. We\nfurther show that the predicted 4D videos can be used to recover robot\nend-effector trajectories using an off-the-shelf 6DoF pose tracker, supporting\nrobust robot manipulation and generalization to novel camera viewpoints.", "comment": "Project website: https://robot4dgen.github.io", "pdf_url": "http://arxiv.org/pdf/2507.01099v1", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01099v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "几何感知4D视频生成用于机器人操作", "tldr": "提出了一种几何感知的4D视频生成模型，通过跨视角点云对齐实现多视角3D一致性，从而提升机器人在复杂环境中的操作能力，并能从新的视角预测未来视频序列。", "motivation": "为了增强机器人在复杂环境中规划和有效交互的能力，理解和预测物理世界的动态至关重要。然而，现有视频生成模型在生成具有时间连贯性和跨视角几何一致性的视频方面仍面临挑战。", "method": "我们提出了一种4D视频生成模型，通过在训练过程中使用跨视角点图对齐来监督模型，从而强制实现视频的多视角3D一致性。这种几何监督使模型能够学习场景的共享3D表示，使其仅基于给定的RGB-D观测即可从新颖的视点预测未来的视频序列，而无需相机姿态作为输入。", "result": "与现有基线相比，我们的方法在多个模拟和真实世界的机器人数据集上产生了更视觉稳定和空间对齐的预测。我们进一步表明，预测的4D视频可以使用现成的6自由度姿态跟踪器来恢复机器人末端执行器轨迹，支持鲁棒的机器人操作和对新颖相机视点的泛化。", "conclusion": "该研究提出了一种几何感知的4D视频生成模型，通过强制多视角3D一致性，显著提升了视频预测的稳定性与空间对齐性，并能有效地支持机器人末端执行器轨迹恢复，从而增强了机器人的鲁棒操作能力及对新颖视点的泛化能力。", "translation": "理解和预测物理世界的动态可以增强机器人在复杂环境中规划和有效交互的能力。虽然最近的视频生成模型在建模动态场景方面显示出强大的潜力，但生成在时间上连贯且在相机视图之间几何一致的视频仍然是一个重大挑战。为了解决这个问题，我们提出了一种4D视频生成模型，通过在训练期间使用跨视角点图对齐来监督模型，从而强制实现视频的多视角3D一致性。这种几何监督使模型能够学习场景的共享3D表示，使其仅基于给定的RGB-D观测即可从新颖的视点预测未来的视频序列，而无需相机姿态作为输入。与现有基线相比，我们的方法在多个模拟和真实世界的机器人数据集上产生了更视觉稳定和空间对齐的预测。我们进一步表明，预测的4D视频可以使用现成的6自由度姿态跟踪器来恢复机器人末端执行器轨迹，支持鲁棒的机器人操作和对新颖相机视点的泛化。", "summary": "本研究提出了一种新颖的几何感知4D视频生成模型，旨在解决现有视频生成模型在生成跨视角几何一致且时间连贯视频方面的挑战。该模型通过引入跨视角点图对齐的几何监督机制，使模型能够学习场景的共享3D表示，从而仅凭RGB-D观测即可从任意新颖视角预测未来的视频序列，无需相机姿态输入。实验结果表明，与现有方法相比，该模型能生成更视觉稳定和空间对齐的预测。此外，生成的4D视频可用于恢复机器人末端执行器轨迹，有效支持机器人操作的鲁棒性及对新颖相机视角的泛化能力。", "keywords": "4D视频生成, 机器人操作, 几何感知, 多视角一致性, 点图对齐", "comments": "本文提出了一种创新的4D视频生成方法，其核心在于引入跨视角点图对齐的几何监督，这有效地解决了现有方法在多视角一致性方面的不足。该方法无需相机姿态输入即可从新颖视角预测未来视频，显著提升了实用性。其在机器人操作中的应用潜力巨大，通过提供精确的4D动态预测，有望大幅提高机器人对复杂环境的理解和交互能力。该研究的贡献在于为机器人感知和操作提供了一个更鲁棒、更泛化的视觉预测框架。"}}
{"id": "2507.01429", "title": "Hardware-software co-exploration with racetrack memory based in-memory computing for CNN inference in embedded systems", "authors": ["Benjamin Chen Ming Choong", "Tao Luo", "Cheng Liu", "Bingsheng He", "Wei Zhang", "Joey Tianyi Zhou"], "summary": "Deep neural networks generate and process large volumes of data, posing\nchallenges for low-resource embedded systems. In-memory computing has been\ndemonstrated as an efficient computing infrastructure and shows promise for\nembedded AI applications. Among newly-researched memory technologies, racetrack\nmemory is a non-volatile technology that allows high data density fabrication,\nmaking it a good fit for in-memory computing. However, integrating in-memory\narithmetic circuits with memory cells affects both the memory density and power\nefficiency. It remains challenging to build efficient in-memory arithmetic\ncircuits on racetrack memory within area and energy constraints. To this end,\nwe present an efficient in-memory convolutional neural network (CNN)\naccelerator optimized for use with racetrack memory. We design a series of\nfundamental arithmetic circuits as in-memory computing cells suited for\nmultiply-and-accumulate operations. Moreover, we explore the design space of\nracetrack memory based systems and CNN model architectures, employing co-design\nto improve the efficiency and performance of performing CNN inference in\nracetrack memory while maintaining model accuracy. Our designed circuits and\nmodel-system co-optimization strategies achieve a small memory bank area with\nsignificant improvements in energy and performance for racetrack memory based\nembedded systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01429v1", "categories": ["cs.ET", "cs.AI", "cs.AR"], "cate": "cs.ET", "url": "http://arxiv.org/abs/2507.01429v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "硬件-软件协同探索基于跑道存储器的内存计算在嵌入式系统中用于CNN推理", "tldr": "该论文提出了一种高效的基于跑道存储器的内存卷积神经网络（CNN）加速器，通过软硬件协同探索，显著提高了嵌入式系统中CNN推理的能效和性能。", "motivation": "深度神经网络产生和处理大量数据，对低资源嵌入式系统构成挑战。内存计算虽有前景，但将内存算术电路与跑道存储器集成会影响密度和功耗。在面积和能耗限制下，在跑道存储器上构建高效的内存算术电路仍具挑战性。", "method": "我们提出了一种高效的内存卷积神经网络（CNN）加速器，针对跑道存储器进行了优化。我们设计了一系列适用于乘加运算的基本内存计算电路。此外，我们探索了基于跑道存储器的系统和CNN模型架构的设计空间，采用协同设计来提高在跑道存储器中执行CNN推理的效率和性能，同时保持模型精度。", "result": "我们设计的电路和模型-系统协同优化策略在基于跑道存储器的嵌入式系统中实现了较小的存储体面积，并在能耗和性能方面取得了显著改进。", "conclusion": "通过硬件-软件协同探索和在跑道存储器上优化内存计算电路，可以显著提高嵌入式系统中CNN推理的效率和性能。", "translation": "深度神经网络生成并处理大量数据，对低资源嵌入式系统构成挑战。内存计算已被证明是一种高效的计算基础设施，并在嵌入式AI应用中展现出前景。在新研究的存储技术中，跑道存储器是一种非易失性技术，允许高数据密度制造，使其非常适合内存计算。然而，将内存算术电路与存储单元集成会影响存储密度和功耗效率。在面积和能耗限制内，在跑道存储器上构建高效的内存算术电路仍然具有挑战性。为此，我们提出了一种高效的内存卷积神经网络（CNN）加速器，该加速器经过优化以与跑道存储器配合使用。我们设计了一系列基本算术电路作为适用于乘加运算的内存计算单元。此外，我们探索了基于跑道存储器的系统和CNN模型架构的设计空间，采用协同设计来提高在跑道存储器中执行CNN推理的效率和性能，同时保持模型精度。我们设计的电路和模型-系统协同优化策略在基于跑道存储器的嵌入式系统中实现了较小的存储体面积，并在能耗和性能方面取得了显著改进。", "summary": "本文旨在解决深度神经网络在低资源嵌入式系统中的挑战，提出了一种高效的基于跑道存储器的内存卷积神经网络（CNN）加速器。该研究详细设计了基本的内存算术电路，并采用软硬件协同探索的方法，优化跑道存储器系统和CNN模型架构。所提出的电路和协同优化策略显著提高了嵌入式系统中CNN推理的能效和性能，同时保持了模型精度并减小了存储体面积。", "keywords": "跑道存储器, 内存计算, CNN推理, 嵌入式系统, 软硬件协同探索", "comments": "本文提出了一种创新方法，通过将内存计算与跑道存储器相结合，克服了嵌入式系统中CNN的内存和功耗瓶颈。其核心创新在于软硬件协同探索，同时优化存储器架构、算术电路和CNN模型。这种整体协同设计对于在资源受限环境中实现高效率至关重要。这项工作的重要性在于展示了跑道存储器等非易失性存储技术在边缘加速AI工作负载的实际可行性。"}}
{"id": "2507.01081", "title": "AI-guided digital intervention with physiological monitoring reduces intrusive memories after experimental trauma", "authors": ["Megan T. deBettencourt", "Sruthi Sakthivel", "Emily A. Holmes", "Mark Chevillet"], "summary": "Trauma prevalence is vast globally. Evidence-based digital treatments can\nhelp, but most require human guidance. Human guides provide tailored\ninstructions and responsiveness to internal cognitive states, but limit\nscalability. Can generative AI and neurotechnology provide a scalable\nalternative? Here we test ANTIDOTE, combining AI guidance and pupillometry to\nautomatically deliver and monitor an evidence-based digital treatment,\nspecifically the Imagery Competing Task Intervention (ICTI), to reduce\nintrusive memories after psychological trauma. One hundred healthy volunteers\nwere exposed to videos of traumatic events and randomly assigned to an\nintervention or active control condition. As predicted, intervention\nparticipants reported significantly fewer intrusive memories over the following\nweek. Post-hoc assessment against clinical rubrics confirmed the AI guide\ndelivered the intervention successfully. Additionally, pupil size tracked\nintervention engagement and predicted symptom reduction, providing a candidate\nbiomarker of intervention effectiveness. These findings open a path toward\nrigorous AI-guided digital interventions that can scale to trauma prevalence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01081v1", "categories": ["cs.HC", "cs.AI"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01081v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "AI引导的数字干预结合生理监测可减少实验性创伤后的侵入性记忆", "tldr": "ANTIDOTE系统（结合AI指导和瞳孔测量）成功减少了实验性创伤后的侵入性记忆，并发现瞳孔大小可作为干预有效性的生物标志物，为可扩展的AI数字干预开辟了道路。", "motivation": "全球创伤普遍存在，而多数循证数字疗法需要人工指导，这限制了其可扩展性。本研究旨在探索生成式AI和神经技术是否能提供一个可扩展的替代方案来应对这一挑战。", "method": "本研究测试了名为ANTIDOTE的系统，该系统结合了AI指导和瞳孔测量，自动提供并监测图像竞争任务干预（ICTI），以减少心理创伤后的侵入性记忆。实验招募了100名健康志愿者，让他们观看创伤事件视频，并随机分配到干预组或主动对照组，随后在一周内监测其侵入性记忆情况。", "result": "干预组参与者在随后一周报告的侵入性记忆显著减少。事后评估证实AI指导成功实施了干预。此外，瞳孔大小能够追踪干预参与度并预测症状减轻，这表明瞳孔大小是干预有效性的一个潜在生物标志物。", "conclusion": "这些发现为开发严谨且可扩展的AI引导数字干预提供了新的途径，以应对全球创伤的普遍性。", "translation": "创伤在全球范围内普遍存在。循证数字疗法可以提供帮助，但大多数需要人工指导。人工指导虽然能提供量身定制的指令并响应内部认知状态，但限制了可扩展性。生成式AI和神经技术能否提供可扩展的替代方案？本文测试了ANTIDOTE，它结合了AI指导和瞳孔测量，以自动提供和监测一种循证数字疗法，即图像竞争任务干预（ICTI），旨在减少心理创伤后的侵入性记忆。一百名健康志愿者暴露于创伤事件视频，并被随机分配到干预组或主动对照组。正如预测，干预组参与者在接下来的一周内报告的侵入性记忆显著减少。对临床标准的事后评估证实AI指导成功地实施了干预。此外，瞳孔大小追踪了干预参与度并预测了症状减轻，为干预有效性提供了一个候选生物标志物。这些发现为严谨的AI引导数字干预开辟了一条道路，使其能够扩展以应对创伤的普遍性。", "summary": "本研究介绍了ANTIDOTE系统，该系统通过结合AI指导和瞳孔测量，自动提供基于证据的图像竞争任务干预（ICTI），旨在减少实验性创伤后的侵入性记忆。实验结果表明，该AI引导的干预显著减少了参与者的侵入性记忆。此外，研究发现瞳孔大小可以作为衡量干预参与度和预测症状减轻的生物标志物。这项工作为开发可扩展的AI引导数字干预以应对创伤流行提供了重要方向。", "keywords": "AI引导干预, 创伤, 侵入性记忆, 瞳孔测量, 数字治疗", "comments": "本研究的创新点在于将AI指导与生理监测（瞳孔测量）相结合，实现了心理干预的自动化和可扩展性，有效解决了传统人工指导的局限性。瞳孔大小作为生物标志物的发现，为未来个性化和效果评估提供了新思路，对心理健康领域的AI应用具有重要意义。"}}
{"id": "2507.01026", "title": "Few-Shot Inspired Generative Zero-Shot Learning", "authors": ["Md Shakil Ahamed Shohag", "Q. M. Jonathan Wu", "Farhad Pourpanah"], "summary": "Generative zero-shot learning (ZSL) methods typically synthesize visual\nfeatures for unseen classes using predefined semantic attributes, followed by\ntraining a fully supervised classification model. While effective, these\nmethods require substantial computational resources and extensive synthetic\ndata, thereby relaxing the original ZSL assumptions. In this paper, we propose\nFSIGenZ, a few-shot-inspired generative ZSL framework that reduces reliance on\nlarge-scale feature synthesis. Our key insight is that class-level attributes\nexhibit instance-level variability, i.e., some attributes may be absent or\npartially visible, yet conventional ZSL methods treat them as uniformly\npresent. To address this, we introduce Model-Specific Attribute Scoring (MSAS),\nwhich dynamically re-scores class attributes based on model-specific\noptimization to approximate instance-level variability without access to unseen\ndata. We further estimate group-level prototypes as clusters of instances based\non MSAS-adjusted attribute scores, which serve as representative synthetic\nfeatures for each unseen class. To mitigate the resulting data imbalance, we\nintroduce a Dual-Purpose Semantic Regularization (DPSR) strategy while training\na semantic-aware contrastive classifier (SCC) using these prototypes.\nExperiments on SUN, AwA2, and CUB benchmarks demonstrate that FSIGenZ achieves\ncompetitive performance using far fewer synthetic features.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01026v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01026v1", "date": "2025-06-18", "updated": "2025-06-18", "AI": {"title_translation": "小样本启发式生成式零样本学习", "tldr": "FSIGenZ是一种新的生成式零样本学习框架，通过引入模型特定属性评分和双重语义正则化，显著减少了对大量合成特征的依赖，同时在多个基准测试上取得了有竞争力的性能。", "motivation": "现有的生成式零样本学习（ZSL）方法需要大量的计算资源和广泛的合成数据，这违背了ZSL的初衷。此外，传统方法将类别级属性视为统一存在，忽略了实例级的可变性（即某些属性可能缺失或部分可见）。", "method": "本文提出了FSIGenZ，一个受小样本学习启发的生成式零样本学习框架。其核心思想是类别级属性存在实例级变异性。为解决此问题，引入了模型特定属性评分（MSAS），根据模型特定优化动态地重新评分类别属性，以在不访问未见数据的情况下近似实例级变异性。进一步，基于MSAS调整后的属性分数估计组级原型，作为每个未见类别的代表性合成特征。为缓解由此产生的数据不平衡问题，在训练语义感知对比分类器（SCC）时引入了双重语义正则化（DPSR）策略。", "result": "FSIGenZ在SUN、AwA2和CUB基准测试上取得了有竞争力的性能，并且使用了远少于传统方法的合成特征。", "conclusion": "FSIGenZ通过有效解决生成式零样本学习中对大量合成数据的依赖以及实例级属性变异性问题，提供了一种更高效和符合ZSL假设的解决方案。", "translation": "生成式零样本学习（ZSL）方法通常使用预定义的语义属性为未见类别合成视觉特征，然后训练一个完全监督的分类模型。尽管这些方法有效，但它们需要大量的计算资源和广泛的合成数据，从而放松了原始ZSL的假设。在本文中，我们提出了FSIGenZ，一个受小样本启发的生成式ZSL框架，它减少了对大规模特征合成的依赖。我们的关键见解是类别级属性表现出实例级变异性，即某些属性可能缺失或部分可见，但传统的ZSL方法将其视为统一存在。为解决此问题，我们引入了模型特定属性评分（MSAS），它根据模型特定优化动态地重新评分类别属性，以在不访问未见数据的情况下近似实例级变异性。我们进一步基于MSAS调整后的属性分数估计组级原型作为实例的聚类，这些原型作为每个未见类别的代表性合成特征。为缓解由此产生的数据不平衡，我们在使用这些原型训练语义感知对比分类器（SCC）时引入了双重语义正则化（DPSR）策略。在SUN、AwA2和CUB基准测试上的实验表明，FSIGenZ使用远少量的合成特征实现了有竞争力的性能。", "summary": "本文提出FSIGenZ，一个受小样本学习启发的生成式零样本学习框架，旨在解决现有方法对大量合成数据和计算资源的依赖。FSIGenZ通过引入模型特定属性评分（MSAS）来近似实例级属性变异性，并基于此估计组级原型作为代表性合成特征。为解决数据不平衡问题，该框架在训练语义感知对比分类器（SCC）时采用了双重语义正则化（DPSR）策略。实验结果表明，FSIGenZ在多个基准测试上以更少的合成特征实现了竞争性性能。", "keywords": "零样本学习, 生成式模型, 小样本学习, 属性评分, 数据不平衡", "comments": "FSIGenZ的创新点在于其对实例级属性变异性的关注，并通过MSAS机制在不访问未见数据的情况下进行建模，这显著提升了合成特征的质量和效率。同时，减少对大量合成数据的依赖，使模型更符合零样本学习的初衷，具有重要的实际意义。DPSR和SCC的结合进一步优化了分类性能和数据平衡。"}}
{"id": "2507.01059", "title": "Automated Vehicles Should be Connected with Natural Language", "authors": ["Xiangbo Gao", "Keshu Wu", "Hao Zhang", "Kexin Tian", "Yang Zhou", "Zhengzhong Tu"], "summary": "Multi-agent collaborative driving promises improvements in traffic safety and\nefficiency through collective perception and decision making. However, existing\ncommunication media -- including raw sensor data, neural network features, and\nperception results -- suffer limitations in bandwidth efficiency, information\ncompleteness, and agent interoperability. Moreover, traditional approaches have\nlargely ignored decision-level fusion, neglecting critical dimensions of\ncollaborative driving. In this paper we argue that addressing these challenges\nrequires a transition from purely perception-oriented data exchanges to\nexplicit intent and reasoning communication using natural language. Natural\nlanguage balances semantic density and communication bandwidth, adapts flexibly\nto real-time conditions, and bridges heterogeneous agent platforms. By enabling\nthe direct communication of intentions, rationales, and decisions, it\ntransforms collaborative driving from reactive perception-data sharing into\nproactive coordination, advancing safety, efficiency, and transparency in\nintelligent transportation systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01059v1", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.CV", "cs.RO"], "cate": "cs.MA", "url": "http://arxiv.org/abs/2507.01059v1", "date": "2025-06-29", "updated": "2025-06-29", "AI": {"title_translation": "自动驾驶汽车应与自然语言连接", "tldr": "本文认为，为了解决现有通信方式在带宽、信息完整性和互操作性方面的局限性，自动驾驶汽车应使用自然语言进行意图和推理的沟通，从而实现更安全、高效和透明的协作驾驶。", "motivation": "现有的多智能体协同驾驶通信方式（如原始传感器数据、神经网络特征和感知结果）在带宽效率、信息完整性和智能体互操作性方面存在局限性。此外，传统方法 largely 忽略了决策层融合。", "method": "本文提出，解决上述挑战需要从纯粹以感知为导向的数据交换，转向使用自然语言进行明确的意图和推理通信。自然语言平衡了语义密度和通信带宽，灵活适应实时条件，并能够连接异构智能体平台。", "result": "通过使用自然语言，能够直接沟通意图、理由和决策，从而将协同驾驶从被动的感知数据共享转变为主动协调，进而提高智能交通系统的安全性、效率和透明度。", "conclusion": "自然语言是解决多智能体协同驾驶中现有通信挑战的关键，它通过实现意图和推理的直接沟通，显著提升了协同驾驶的性能和透明度。", "translation": "多智能体协同驾驶有望通过集体感知和决策来提高交通安全性和效率。然而，现有的通信媒介——包括原始传感器数据、神经网络特征和感知结果——在带宽效率、信息完整性和智能体互操作性方面存在局限性。此外，传统方法在很大程度上忽略了决策层融合，忽视了协同驾驶的关键维度。在本文中，我们认为解决这些挑战需要从纯粹以感知为导向的数据交换，过渡到使用自然语言进行明确的意图和推理通信。自然语言平衡了语义密度和通信带宽，灵活适应实时条件，并能连接异构智能体平台。通过实现意图、理由和决策的直接沟通，它将协同驾驶从被动的感知数据共享转变为主动协调，从而提高智能交通系统的安全性、效率和透明度。", "summary": "本文探讨了多智能体协同驾驶中现有通信方式的不足，如带宽限制和信息不完整性。作者提出，应从传统的感知数据交换转向使用自然语言进行意图和推理的直接沟通。这种方法能够有效平衡语义密度和通信带宽，并适应不同平台，从而将协同驾驶转变为主动协调，显著提升智能交通系统的安全性、效率和透明度。", "keywords": "自动驾驶汽车, 自然语言, 协同驾驶, 多智能体, 通信", "comments": "本文提出了一种新颖且具有前瞻性的视角，将自然语言引入自动驾驶汽车的通信中，以克服现有基于数据传输的局限性。其创新点在于强调了“意图和推理”的直接沟通，而非仅仅感知结果，这对于实现更高级别的协同和信任至关重要。该思想具有重要的理论和实践意义，可能为未来智能交通系统的人机交互和车际通信提供新的范式。"}}
{"id": "2507.01124", "title": "Emerging Activity Temporal Hypergraph (EATH), a model for generating realistic time-varying hypergraphs", "authors": ["Marco Mancastroppa", "Giulia Cencetti", "Alain Barrat"], "summary": "Time-varying group interactions constitute the building blocks of many\ncomplex systems. The framework of temporal hypergraphs makes it possible to\nrepresent them by taking into account the higher-order and temporal nature of\nthe interactions. However, the corresponding datasets are often incomplete\nand/or limited in size and duration, and surrogate time-varying hypergraphs\nable to reproduce their statistical features constitute interesting\nsubstitutions, especially to understand how dynamical processes unfold on group\ninteractions. Here, we present a new temporal hypergraph model, the Emerging\nActivity Temporal Hypergraph (EATH), which can be fed by parameters measured in\na dataset and create synthetic datasets with similar properties. In the model,\neach node has an independent underlying activity dynamic and the overall system\nactivity emerges from the nodes dynamics, with temporal group interactions\nresulting from both the activity of the nodes and memory mechanisms. We first\nshow that the EATH model can generate surrogate hypergraphs of several\nempirical datasets of face-to-face interactions, mimicking temporal and\ntopological properties at the node and hyperedge level. We also showcase the\npossibility to use the resulting synthetic data in simulations of higher-order\ncontagion dynamics, comparing the outcome of such process on original and\nsurrogate datasets. Finally, we illustrate the flexibility of the model, which\ncan generate synthetic hypergraphs with tunable properties: as an example, we\ngenerate \"hybrid\" temporal hypergraphs, which mix properties of different\nempirical datasets. Our work opens several perspectives, from the generation of\nsynthetic realistic hypergraphs describing contexts where data collection is\ndifficult to a deeper understanding of dynamical processes on temporal\nhypergraphs.", "comment": "Main document: 19 pages, 10 figures; Supplementary Material: 37\n  pages, 54 figures", "pdf_url": "http://arxiv.org/pdf/2507.01124v1", "categories": ["physics.soc-ph", "cs.SI", "physics.data-an"], "cate": "physics.soc-ph", "url": "http://arxiv.org/abs/2507.01124v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "新兴活动时间超图（EATH），一种生成现实时变超图的模型", "tldr": "EATH是一种新的时间超图模型，能够生成具有与真实数据集相似统计特征的合成数据集，以克服真实数据不完整或有限的问题。", "motivation": "时间变动的群体交互构成了许多复杂系统的基本组成部分。然而，用于表示这些交互的时间超图数据集往往不完整、规模或持续时间有限。因此，需要能够重现这些统计特征的替代时变超图，以便更好地理解动力学过程如何在群体交互中展开。", "method": "本文提出了一种名为新兴活动时间超图（EATH）的新模型。该模型可以通过数据集中测量的参数进行输入，并创建具有相似属性的合成数据集。在模型中，每个节点都有独立的底层活动动态，整体系统活动源于节点动态，时间群体交互则由节点活动和记忆机制共同产生。", "result": "研究表明，EATH模型可以生成多个面对面交互经验数据集的替代超图，模仿节点和超边级别的时间和拓扑属性。此外，该模型生成的合成数据可用于高阶传染动力学模拟，并与原始数据集上的过程结果进行比较。模型还展示了其灵活性，可以生成具有可调属性的合成超图，例如混合不同经验数据集属性的“混合”时间超图。", "conclusion": "EATH模型能够生成逼真的合成时间超图，为数据收集困难的场景提供了解决方案，并有助于更深入地理解时间超图上的动力学过程。", "translation": "时间变化的群体交互构成了许多复杂系统的基本组成部分。时间超图的框架使得通过考虑交互的高阶和时间性质来表示它们成为可能。然而，相应的G数据集通常不完整和/或规模和持续时间有限，能够重现其统计特征的替代时变超图构成了有趣的替代品，特别是为了理解动力学过程如何在群体交互中展开。在这里，我们提出了一种新的时间超图模型，即新兴活动时间超图（EATH），该模型可以通过数据集中测量的参数进行输入，并创建具有相似属性的合成数据集。在模型中，每个节点都有独立的底层活动动态，整体系统活动源于节点动态，时间群体交互则由节点活动和记忆机制共同产生。我们首先展示了EATH模型可以生成几个面对面交互经验数据集的替代超图，模仿节点和超边级别的时间和拓扑属性。我们还展示了在更高阶传染动力学模拟中使用合成数据的可能性，比较了原始数据集和替代数据集上此类过程的结果。最后，我们阐述了模型的灵活性，它可以生成具有可调属性的合成超图：例如，我们生成了“混合”时间超图，它混合了不同经验数据集的属性。我们的工作开启了多个视角，从描述数据收集困难情境的合成现实超图的生成，到更深入地理解时间超图上的动力学过程。", "summary": "本文提出了一种名为新兴活动时间超图（EATH）的新模型，旨在生成具有与真实数据集相似统计特征的合成时变超图，以解决现有时间超图数据集不完整或有限的问题。EATH模型通过模拟独立的节点活动动态和记忆机制来生成群体交互。实验证明，EATH能够模仿真实面对面交互数据集的时间和拓扑特性，并可用于模拟高阶传染动力学。该模型还具有生成具有可调属性的混合超图的灵活性，为数据难以获取的场景和深入理解时间超图上的动力学过程提供了新的方法。", "keywords": "时间超图, EATH模型, 合成数据, 群体交互, 动力学过程", "comments": "EATH模型在处理不完整或有限的时间超图数据集方面具有重要意义。其创新之处在于通过结合独立的节点活动和记忆机制来生成逼真的群体交互，并能够模仿真实数据的复杂统计特征。该模型不仅提供了生成合成数据的实用工具，也为研究复杂系统中的高阶动力学过程提供了新的视角。其灵活性，特别是生成“混合”超图的能力，进一步拓展了其应用范围。"}}
{"id": "2507.01227", "title": "Degrees of Freedom of Spatial Multiplexing in Distance Domain of Arbitrary Continuous-Aperture Array in Near-Field Region", "authors": ["Son T. Duong", "Tho Le-Ngoc"], "summary": "Extremely large aperture array operating in the near-field regime unlocks\nadditional spatial resources that can be exploited to simultaneously serve\nmultiple users even when they share the same angular direction, a capability\nnot achievable in conventional far-field systems. A fundamental question,\nhowever, remains: What is the maximum spatial degree of freedom (DoF) of\nspatial multiplexing in the distance domain?\n  In this paper, we address this open problem by investigating the spatial DoF\nof a line-of-sight (LoS) channel between a large two-dimensional transmit\naperture and a linear receive array with collinearly-aligned elements (i.e., at\nthe same angular direction) but located at different distances from the\ntransmit aperture. We assume that both the aperture and linear array are\ncontinuous-aperture (CAP) arrays with an infinite number of elements and\ninfinitesimal spacing, which establishes an upper bound for the spatial degrees\nof freedom (DoF) in the case of finite elements. First, we assume an ideal case\nwhere the transmit array is a single piece and the linear array is on the broad\nside of the transmit array. By reformulating the channel as an integral\noperator with a Hermitian convolution kernel, we derive a closed-form\nexpression for the spatial DoF via the Fourier transform. Our analysis shows\nthat the spatial DoF in the distance domain is predominantly determined by the\nextreme boundaries of the array rather than its detailed interior structure. We\nfurther extend the framework to non-broadside configurations by employing a\nprojection method, which effectively converts the spatial DoF to an equivalent\nbroadside case. Finally, we extend our analytical framework to the modular\narray, which shows the spatial DoF gain over the single-piece array given the\nconstraint of the physical length of the array.", "comment": "13 pages and 13 figures. Part of this work has been submitted to IEEE\n  Globecom 2025 (under review). This version has been submitted to IEEE\n  Transactions on Communications for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.01227v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "cate": "eess.SP", "url": "http://arxiv.org/abs/2507.01227v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "近场区域任意连续孔径阵列距离域空间复用自由度", "tldr": "本文研究了近场区域超大连续孔径阵列在距离域空间复用的最大空间自由度（DoF），发现其主要由阵列的极端边界决定，而非内部结构。", "motivation": "传统远场系统无法同时服务共享相同角度方向的多个用户。近场区域的超大孔径阵列虽然解锁了额外的空间资源，但距离域空间复用的最大空间自由度（DoF）这一基本问题仍未解决。", "method": "本文通过研究一个大型二维发射孔径与一个线性接收阵列（共线对齐但距离不同）之间的视线（LoS）信道的空间自由度。假设发射和接收阵列均为连续孔径（CAP）阵列，具有无限元素和无限小间距，以此建立空间自由度的上限。首先，在理想情况下（单件发射阵列和宽边线性阵列），将信道重新表述为具有厄米特卷积核的积分算子，并通过傅里叶变换推导出空间自由度的闭合形式表达式。随后，通过投影方法将框架扩展到非宽边配置。最后，将分析框架扩展到模块化阵列。", "result": "研究表明，距离域中的空间自由度主要由阵列的极端边界决定，而不是其详细的内部结构。该框架成功扩展到非宽边配置和模块化阵列。在阵列物理长度受限的情况下，模块化阵列相对于单件阵列表现出空间自由度增益。", "conclusion": "本文解决了近场连续孔径阵列在距离域空间自由度的开放问题，推导了相关表达式，并揭示了阵列边界对空间自由度的决定性影响以及模块化阵列的潜在优势。", "translation": "在近场区域运行的超大孔径阵列解锁了额外的空间资源，即使在用户共享相同角度方向的情况下，这些资源也可以用于同时服务多个用户，这是传统远场系统无法实现的能力。然而，一个基本问题仍然存在：距离域空间复用的最大空间自由度（DoF）是多少？\n在本文中，我们通过研究一个大型二维发射孔径与一个线性接收阵列之间的视线（LoS）信道的空间自由度来解决这个开放问题，该线性接收阵列具有共线对齐的元素（即在相同的角度方向），但位于距离发射孔径不同的距离处。我们假设孔径和线性阵列都是连续孔径（CAP）阵列，具有无限数量的元素和无穷小的间距，这为有限元素情况下的空间自由度（DoF）建立了上限。首先，我们假设一个理想情况，即发射阵列是单件的，并且线性阵列位于发射阵列的宽边。通过将信道重新表述为具有厄米特卷积核的积分算子，我们通过傅里叶变换导出了空间自由度的闭合形式表达式。我们的分析表明，距离域中的空间自由度主要由阵列的极端边界决定，而不是其详细的内部结构。我们通过采用投影方法进一步将框架扩展到非宽边配置，该方法有效地将空间自由度转换为等效的宽边情况。最后，我们将分析框架扩展到模块化阵列，这表明在阵列物理长度受限的情况下，模块化阵列相对于单件阵列具有空间自由度增益。", "summary": "本文探讨了近场区域连续孔径阵列在距离域空间复用的最大空间自由度（DoF）这一基本问题。通过分析视线信道，作者推导出了空间自由度的闭合形式表达式，表明其主要由阵列的极端边界决定。该框架被扩展到非宽边和模块化阵列配置，并展示了模块化设计的DoF增益。", "keywords": "近场, 空间复用, 自由度, 连续孔径阵列, 距离域", "comments": "本文对近场超大孔径阵列的空间自由度进行了基础性的理论分析，这对于理解未来大规模阵列系统的空间复用极限至关重要。发现自由度主要由阵列边界而非详细内部结构决定，这一洞察具有重要意义。此外，将框架扩展到模块化阵列也考虑了实际硬件实现的因素，增加了其应用价值。"}}
{"id": "2507.01038", "title": "Cross-Attention Message-Passing Transformers for Code-Agnostic Decoding in 6G Networks", "authors": ["Seong-Joon Park", "Hee-Youl Kwak", "Sang-Hyo Kim", "Yongjune Kim", "Jong-Seon No"], "summary": "Channel coding for 6G networks is expected to support a wide range of\nrequirements arising from heterogeneous communication scenarios. These demands\nchallenge traditional code-specific decoders, which lack the flexibility and\nscalability required for next-generation systems. To tackle this problem, we\npropose an AI-native foundation model for unified and code-agnostic decoding\nbased on the transformer architecture. We first introduce a cross-attention\nmessage-passing transformer (CrossMPT). CrossMPT employs two masked\ncross-attention blocks that iteratively update two distinct input\nrepresentations-magnitude and syndrome vectors-allowing the model to\neffectively learn the decoding problem. Notably, our CrossMPT has achieved\nstate-of-the-art decoding performance among single neural decoders. Building on\nthis, we develop foundation CrossMPT (FCrossMPT) by making the architecture\ninvariant to code length, rate, and class, allowing a single trained model to\ndecode a broad range of codes without retraining. To further enhance decoding\nperformance, particularly for short blocklength codes, we propose CrossMPT\nensemble decoder (CrossED), an ensemble decoder composed of multiple parallel\nCrossMPT blocks employing different parity-check matrices. This architecture\ncan also serve as a foundation model, showing strong generalization across\ndiverse code types. Overall, the proposed AI-native code-agnostic decoder\noffers flexibility, scalability, and high performance, presenting a promising\ndirection to channel coding for 6G networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01038v1", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "cate": "cs.IT", "url": "http://arxiv.org/abs/2507.01038v1", "date": "2025-06-22", "updated": "2025-06-22", "AI": {"title_translation": "用于6G网络中与码无关解码的交叉注意力消息传递Transformer", "tldr": "本文提出了一种基于Transformer的AI原生基础模型，用于6G网络中统一的、与码无关的信道解码。该模型包括CrossMPT、FCrossMPT和CrossED，旨在提供灵活性、可扩展性和高性能，并已在单神经解码器中实现最先进的性能。", "motivation": "6G网络的信道编码需要支持异构通信场景下的广泛需求，而传统特定于码的解码器缺乏下一代系统所需的灵活性和可扩展性，因此需要一种统一的、与码无关的解码方法。", "method": "作者提出了一种基于Transformer架构的AI原生基础模型，用于统一和与码无关的解码。首先，引入了交叉注意力消息传递Transformer (CrossMPT)，它使用两个掩蔽交叉注意力块迭代更新幅度和症候向量，以学习解码问题。在此基础上，开发了基础CrossMPT (FCrossMPT)，使其架构对码长、码率和码类不变，从而允许单个训练模型解码广泛的码而无需重新训练。为了进一步提高解码性能，特别是对于短块长码，提出了CrossMPT集成解码器 (CrossED)，它由多个并行CrossMPT块组成，这些块采用不同的奇偶校验矩阵。", "result": "CrossMPT在单神经解码器中实现了最先进的解码性能。FCrossMPT和CrossED架构作为基础模型，在不同码类型上表现出强大的泛化能力。", "conclusion": "所提出的AI原生与码无关的解码器提供了灵活性、可扩展性和高性能，为6G网络的信道编码提供了一个有前景的方向。", "translation": "6G网络的信道编码预计将支持异构通信场景下产生的广泛需求。这些需求对传统的特定于码的解码器提出了挑战，因为它们缺乏下一代系统所需的灵活性和可扩展性。为了解决这个问题，我们提出了一种基于Transformer架构的AI原生基础模型，用于统一和与码无关的解码。我们首先引入了一种交叉注意力消息传递Transformer (CrossMPT)。CrossMPT采用两个掩蔽交叉注意力块，迭代更新两种不同的输入表示——幅度和症候向量，使模型能够有效地学习解码问题。值得注意的是，我们的CrossMPT在单神经解码器中取得了最先进的解码性能。在此基础上，我们通过使架构对码长、码率和码类不变，开发了基础CrossMPT (FCrossMPT)，从而允许单个训练模型解码广泛的码而无需重新训练。为了进一步提高解码性能，特别是对于短块长码，我们提出了CrossMPT集成解码器 (CrossED)，这是一种由多个并行CrossMPT块组成的集成解码器，这些块采用不同的奇偶校验矩阵。这种架构也可以作为基础模型，在不同码类型上显示出强大的泛化能力。总的来说，所提出的AI原生与码无关的解码器提供了灵活性、可扩展性和高性能，为6G网络的信道编码提供了一个有前景的方向。", "summary": "本文针对6G网络中传统特定于码的解码器缺乏灵活性和可扩展性的问题，提出了一种基于Transformer架构的AI原生基础模型，用于统一和与码无关的信道解码。该模型包括CrossMPT、对码参数不变的FCrossMPT以及用于提高性能的CrossMPT集成解码器 (CrossED)。CrossMPT在单神经解码器中达到了最先进的性能，并且所提出的架构展现出强大的泛化能力，为6G网络信道编码提供了一种灵活、可扩展且高性能的解决方案。", "keywords": "交叉注意力, Transformer, 码无关解码, 6G网络, 信道编码", "comments": "该论文的创新点在于提出了基于Transformer架构的AI原生码无关解码器，特别是通过CrossMPT、FCrossMPT和CrossED的逐步构建，解决了传统解码器在6G异构场景下灵活性和可扩展性不足的问题。CrossMPT引入交叉注意力进行幅度和症候向量的迭代更新是其核心机制。FCrossMPT实现了码参数不变性，极大地提升了模型的实用性。CrossED则通过集成方式进一步优化了性能，特别是对短块长码。这项工作为未来6G网络的信道编码提供了重要的研究方向，其“基础模型”的理念也与当前AI领域的热点相契合。"}}
{"id": "2507.01113", "title": "HERCULES: Hardware accElerator foR stoChastic schedULing in hEterogeneous Systems", "authors": ["Vairavan Palaniappan", "Adam H. Ross", "Amit Ranjan Trivedi", "Debjit Pal"], "summary": "Efficient workload scheduling is a critical challenge in modern heterogeneous\ncomputing environments, particularly in high-performance computing (HPC)\nsystems. Traditional software-based schedulers struggle to efficiently balance\nworkload distribution due to high scheduling overhead, lack of adaptability to\ndynamic workloads, and suboptimal resource utilization. These pitfalls are\ncompounded in heterogeneous systems, where differing computational elements can\nhave vastly different performance profiles. To resolve these hindrances, we\npresent a novel FPGA-based accelerator for stochastic online scheduling (SOS).\nWe modify a greedy cost selection assignment policy by adapting existing cost\nequations to engage with discretized time before implementing them into a\nhardware accelerator design. Our design leverages hardware parallelism,\nprecalculation, and precision quantization to reduce job scheduling latency. By\nintroducing a hardware-accelerated approach to real-time scheduling, this paper\nestablishes a new paradigm for adaptive scheduling mechanisms in heterogeneous\ncomputing systems. The proposed design achieves high throughput, low latency,\nand energy-efficient operation, offering a scalable alternative to traditional\nsoftware scheduling methods. Experimental results demonstrate consistent\nworkload distribution, fair machine utilization, and up to 1060x speedup over\nsingle-threaded software scheduling policy implementations. This makes the SOS\naccelerator a strong candidate for deployment in high-performance computing\nsystem, deeplearning pipelines, and other performance-critical applications.", "comment": "10 pages, 10 figures, accepted for publication in in Int'l Conference\n  on Computer Aided Design (ICCAD) 2025", "pdf_url": "http://arxiv.org/pdf/2507.01113v1", "categories": ["cs.DC", "cs.SY", "eess.SY"], "cate": "cs.DC", "url": "http://arxiv.org/abs/2507.01113v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "HERCULES：异构系统中随机调度的硬件加速器", "tldr": "HERCULES是一个基于FPGA的硬件加速器，用于异构系统中的随机在线调度，通过硬件并行化、预计算和精度量化，实现了比单线程软件调度高达1060倍的加速。", "motivation": "在现代异构计算环境，特别是高性能计算（HPC）系统中，高效的工作负载调度是一个关键挑战。传统的软件调度器由于高调度开销、缺乏对动态工作负载的适应性以及次优的资源利用率，难以有效平衡工作负载分布。这些问题在异构系统中尤为突出，因为不同的计算单元可能具有截然不同的性能特征。", "method": "本文提出了一种新颖的基于FPGA的随机在线调度（SOS）加速器。通过修改贪婪成本选择分配策略，使现有成本方程与离散时间结合，并将其实现到硬件加速器设计中。该设计利用硬件并行性、预计算和精度量化来减少作业调度延迟。", "result": "实验结果表明，该设计实现了持续的工作负载分布、公平的机器利用率，并且比单线程软件调度策略实现的速度提升高达1060倍。同时，该设计还实现了高吞吐量、低延迟和高能效运行。", "conclusion": "HERCULES SOS加速器为异构计算系统中的自适应调度机制建立了新的范式，是高性能计算系统、深度学习管道和其他性能关键应用部署的有力候选。", "translation": "高效的工作负载调度是现代异构计算环境，特别是在高性能计算（HPC）系统中，一个关键的挑战。传统的基于软件的调度器由于高调度开销、缺乏对动态工作负载的适应性以及次优的资源利用率，难以有效地平衡工作负载分布。这些缺陷在异构系统中更为突出，因为不同的计算元素可能具有截然不同的性能特征。为了解决这些障碍，我们提出了一种新颖的基于FPGA的随机在线调度（SOS）加速器。我们通过调整现有成本方程以适应离散时间，从而修改了贪婪成本选择分配策略，然后将其实现到硬件加速器设计中。我们的设计利用硬件并行性、预计算和精度量化来减少作业调度延迟。通过引入硬件加速的实时调度方法，本文为异构计算系统中的自适应调度机制建立了新的范式。所提出的设计实现了高吞吐量、低延迟和高能效操作，为传统的软件调度方法提供了一种可扩展的替代方案。实验结果表明，该设计实现了持续的工作负载分布、公平的机器利用率，并且比单线程软件调度策略实现的速度提升高达1060倍。这使得SOS加速器成为高性能计算系统、深度学习管道和其他性能关键应用部署的有力候选。", "summary": "本文针对异构计算环境中传统软件调度器面临的挑战，提出了一种名为HERCULES的FPGA基随机在线调度（SOS）硬件加速器。该加速器通过修改贪婪成本选择分配策略并利用硬件并行性、预计算和精度量化技术，显著降低了作业调度延迟。实验证明，该设计在工作负载分布、机器利用率方面表现出色，并实现了高达1060倍的加速，为高性能计算等应用提供了高效、可扩展的实时调度解决方案。", "keywords": "FPGA, 硬件加速, 随机调度, 异构系统, 高性能计算", "comments": "该论文提出了一种创新的硬件加速方法来解决异构系统中调度效率低下的问题，通过FPGA实现显著提升了调度性能。其创新点在于将随机在线调度策略硬件化，并利用硬件特性克服了软件调度的局限性。其重要性在于为高性能计算、深度学习等对调度性能要求极高的领域提供了新的解决方案。论文明确指出了其在速度上的巨大优势，但未提及硬件资源消耗或功耗的具体数据，这可能是一个潜在的局限性，尽管它提到了“energy-efficient operation”。"}}
{"id": "2507.01051", "title": "Can AI be Consentful?", "authors": ["Giada Pistilli", "Bruna Trevelin"], "summary": "The evolution of generative AI systems exposes the challenges of traditional\nlegal and ethical frameworks built around consent. This chapter examines how\nthe conventional notion of consent, while fundamental to data protection and\nprivacy rights, proves insufficient in addressing the implications of\nAI-generated content derived from personal data. Through legal and ethical\nanalysis, we show that while individuals can consent to the initial use of\ntheir data for AI training, they cannot meaningfully consent to the numerous\npotential outputs their data might enable or the extent to which the output is\nused or distributed. We identify three fundamental challenges: the scope\nproblem, the temporality problem, and the autonomy trap, which collectively\ncreate what we term a ''consent gap'' in AI systems and their surrounding\necosystem. We argue that current legal frameworks inadequately address these\nemerging challenges, particularly regarding individual autonomy, identity\nrights, and social responsibility, especially in cases where AI-generated\ncontent creates new forms of personal representation beyond the scope of the\noriginal consent. By examining how these consent limitations intersect with\nbroader principles of responsible AI (including fairness, transparency,\naccountability, and autonomy) we demonstrate the need to evolve ethical and\nlegal approaches to consent.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01051v1", "categories": ["cs.CY", "cs.AI"], "cate": "cs.CY", "url": "http://arxiv.org/abs/2507.01051v1", "date": "2025-06-27", "updated": "2025-06-27", "AI": {"title_translation": "人工智能可以获得同意吗？", "tldr": "生成式AI对传统同意框架提出挑战，个人无法对AI生成内容进行有效同意，从而产生“同意鸿沟”，现有法律框架不足以解决，需要发展新的伦理和法律方法。", "motivation": "生成式AI系统的发展暴露了传统基于同意的法律和伦理框架所面临的挑战，尤其是在处理源自个人数据的AI生成内容时，传统同意概念显得不足。", "method": "本文通过法律和伦理分析来探讨问题。", "result": "研究发现，尽管个人可以同意其数据用于AI训练的初始阶段，但无法有效同意其数据可能产生的无数潜在输出，也无法同意输出的使用或分发程度。研究指出了三个根本性挑战：范围问题、时间性问题和自主性陷阱，这些共同构成了AI系统中的“同意鸿沟”。当前法律框架不足以解决这些新兴挑战。", "conclusion": "本文证明了需要发展伦理和法律方法来应对AI中的同意问题，尤其是在同意限制与负责任AI原则（包括公平性、透明度、问责制和自主性）交叉时。", "translation": "生成式人工智能系统的演变揭示了围绕同意构建的传统法律和伦理框架所面临的挑战。本章探讨了传统的同意概念，尽管其对于数据保护和隐私权至关重要，但在解决源自个人数据的AI生成内容所带来的影响方面却显得不足。通过法律和伦理分析，我们表明，虽然个人可以同意其数据最初用于AI训练，但他们无法有意义地同意其数据可能促成的众多潜在输出，或这些输出被使用或分发的程度。我们识别出三个根本性挑战：范围问题、时间性问题和自主性陷阱，这些共同构成了我们称之为AI系统及其周边生态系统中的“同意鸿沟”。我们认为，当前的法律框架未能充分解决这些新兴挑战，特别是在个人自主权、身份权和社会责任方面，尤其是在AI生成内容创建了超出原始同意范围的新形式个人表征的情况下。通过审视这些同意限制如何与负责任AI的更广泛原则（包括公平性、透明度、问责制和自主性）相交叉，我们证明了发展伦理和法律同意方法的必要性。", "summary": "本文探讨了生成式AI系统对传统同意框架的挑战。通过法律和伦理分析，作者指出，尽管个人可以同意其数据用于AI训练，但无法有效同意AI生成内容的潜在输出或其使用范围。文章识别出“范围问题”、“时间性问题”和“自主性陷阱”这三个导致“同意鸿沟”的核心挑战，并论证现有法律框架不足以解决这些问题。最终，本文强调了在负责任AI原则下，发展新的伦理和法律同意方法的重要性。", "keywords": "AI, 同意, 生成式AI, 隐私保护, 法律伦理", "comments": "本文提出了“同意鸿沟”这一创新概念，并将其分解为范围、时间性和自主性三个具体问题，为理解生成式AI时代同意的复杂性提供了清晰的框架。其重要性在于强调了现有法律和伦理框架的局限性，并呼吁在AI快速发展背景下，必须重新思考和演进同意的范式，对未来AI治理和个人数据保护具有深远指导意义。"}}
{"id": "2507.01145", "title": "CarbonClarity: Understanding and Addressing Uncertainty in Embodied Carbon for Sustainable Computing", "authors": ["Xuesi Chen", "Leo Han", "Anvita Bhagavathula", "Udit Gupta"], "summary": "Embodied carbon footprint modeling has become an area of growing interest due\nto its significant contribution to carbon emissions in computing. However, the\ndeterministic nature of the existing models fail to account for the spatial and\ntemporal variability in the semiconductor supply chain. The absence of\nuncertainty modeling limits system designers' ability to make informed,\ncarbon-aware decisions. We introduce CarbonClarity, a probabilistic framework\ndesigned to model embodied carbon footprints through distributions that reflect\nuncertainties in energy-per-area, gas-per-area, yield, and carbon intensity\nacross different technology nodes. Our framework enables a deeper understanding\nof how design choices, such as chiplet architectures and new vs. old technology\nnode selection, impact emissions and their associated uncertainties. For\nexample, we show that the gap between the mean and 95th percentile of embodied\ncarbon per cm$^2$ can reach up to 1.6X for the 7nm technology node.\nAdditionally, we demonstrate through case studies that: (i) CarbonClarity is a\nvaluable resource for device provisioning, help maintaining performance under a\ntight carbon budget; and (ii) chiplet technology and mature nodes not only\nreduce embodied carbon but also significantly lower its associated uncertainty,\nachieving an 18% reduction in the 95th percentile compared to monolithic\ndesigns for the mobile application.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01145v1", "categories": ["cs.AR"], "cate": "cs.AR", "url": "http://arxiv.org/abs/2507.01145v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "CarbonClarity：理解并解决可持续计算中隐含碳的不确定性", "tldr": "CarbonClarity引入了一个概率框架来建模计算中隐含碳足迹的不确定性，并展示了设计选择如何影响排放及其相关的不确定性。", "motivation": "现有隐含碳足迹模型是确定性的，未能考虑半导体供应链中的空间和时间变异性，这限制了系统设计者做出明智的、碳感知决策的能力。", "method": "本文提出了CarbonClarity，一个概率框架，旨在通过反映不同技术节点中单位面积能量、单位面积气体、良率和碳强度不确定性的分布来建模隐含碳足迹。", "result": "CarbonClarity能够更深入地理解设计选择（如小芯片架构和新旧技术节点选择）如何影响排放及其相关不确定性。例如，对于7nm技术节点，每平方厘米隐含碳的平均值与95百分位数之间的差距可达1.6倍。此外，案例研究表明：(i) CarbonClarity是设备配置的宝贵资源，有助于在严格的碳预算下保持性能；(ii) 小芯片技术和成熟节点不仅减少了隐含碳，还显著降低了其相关不确定性，对于移动应用，与单片设计相比，95百分位数降低了18%。", "conclusion": "CarbonClarity框架通过量化隐含碳的不确定性，帮助系统设计者做出更明智的碳感知决策。研究表明，采用小芯片技术和成熟节点可以有效减少隐含碳排放及其不确定性，从而促进可持续计算。", "translation": "隐含碳足迹建模已成为一个日益受到关注的领域，因为它对计算中的碳排放有显著贡献。然而，现有模型的确定性本质未能考虑到半导体供应链中的空间和时间变异性。不确定性建模的缺失限制了系统设计者做出明智的、碳感知决策的能力。我们引入了CarbonClarity，一个概率框架，旨在通过反映不同技术节点中单位面积能量、单位面积气体、良率和碳强度不确定性的分布来建模隐含碳足迹。我们的框架能够更深入地理解设计选择，例如小芯片架构和新旧技术节点选择，如何影响排放及其相关的不确定性。例如，我们展示了对于7nm技术节点，每平方厘米隐含碳的平均值与95百分位数之间的差距可达1.6倍。此外，我们通过案例研究证明：(i) CarbonClarity是设备配置的宝贵资源，有助于在严格的碳预算下保持性能；(ii) 小芯片技术和成熟节点不仅减少了隐含碳，还显著降低了其相关不确定性，对于移动应用，与单片设计相比，95百分位数降低了18%。", "summary": "本文介绍了CarbonClarity，一个概率框架，旨在解决现有隐含碳足迹模型在半导体供应链中不确定性建模的不足。该框架通过分布来量化单位面积能量、气体、良率和碳强度的不确定性，从而帮助系统设计者做出碳感知决策。研究结果表明，设计选择如小芯片和成熟技术节点不仅能减少隐含碳，还能显著降低其不确定性，例如在移动应用中，小芯片设计可使95百分位数隐含碳减少18%。", "keywords": "隐含碳, 不确定性, 可持续计算, 概率框架, 小芯片", "comments": "本文创新性地提出了一个概率框架CarbonClarity来处理计算领域隐含碳足迹中的不确定性，填补了现有确定性模型的空白。其重要性在于能够帮助系统设计者做出更精确的碳感知决策，尤其是在面对复杂供应链和多种设计选择时。通过量化不确定性，该工作为可持续计算领域提供了宝贵的工具和见解。"}}
{"id": "2507.01055", "title": "Prompt Mechanisms in Medical Imaging: A Comprehensive Survey", "authors": ["Hao Yang", "Xinlong Liang", "Zhang Li", "Yue Sun", "Zheyu Hu", "Xinghe Xie", "Behdad Dashtbozorg", "Jincheng Huang", "Shiwei Zhu", "Luyi Han", "Jiong Zhang", "Shanshan Wang", "Ritse Mann", "Qifeng Yu", "Tao Tan"], "summary": "Deep learning offers transformative potential in medical imaging, yet its\nclinical adoption is frequently hampered by challenges such as data scarcity,\ndistribution shifts, and the need for robust task generalization. Prompt-based\nmethodologies have emerged as a pivotal strategy to guide deep learning models,\nproviding flexible, domain-specific adaptations that significantly enhance\nmodel performance and adaptability without extensive retraining. This\nsystematic review critically examines the burgeoning landscape of prompt\nengineering in medical imaging. We dissect diverse prompt modalities, including\ntextual instructions, visual prompts, and learnable embeddings, and analyze\ntheir integration for core tasks such as image generation, segmentation, and\nclassification. Our synthesis reveals how these mechanisms improve\ntask-specific outcomes by enhancing accuracy, robustness, and data efficiency\nand reducing reliance on manual feature engineering while fostering greater\nmodel interpretability by making the model's guidance explicit. Despite\nsubstantial advancements, we identify persistent challenges, particularly in\nprompt design optimization, data heterogeneity, and ensuring scalability for\nclinical deployment. Finally, this review outlines promising future\ntrajectories, including advanced multimodal prompting and robust clinical\nintegration, underscoring the critical role of prompt-driven AI in accelerating\nthe revolution of diagnostics and personalized treatment planning in medicine.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01055v1", "categories": ["eess.IV", "cs.AI", "cs.CV"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01055v1", "date": "2025-06-28", "updated": "2025-06-28", "AI": {"title_translation": "医疗影像中的提示机制：一项综合调查", "tldr": "这篇综述系统地审查了医疗影像中提示工程的现状，分析了不同提示模式如何提高深度学习模型在图像生成、分割和分类任务中的性能和适应性，并讨论了挑战和未来方向。", "motivation": "深度学习在医疗影像中潜力巨大，但其临床应用常受限于数据稀缺、分布偏移和泛化能力不足。提示方法作为一种关键策略，旨在引导深度学习模型，提供灵活、领域特定的适应，以增强模型性能和适应性，无需大量再训练。", "method": "本文是一项系统综述，批判性地审查了医疗影像中提示工程的蓬勃发展。它剖析了包括文本指令、视觉提示和可学习嵌入在内的多种提示模式，并分析了它们在图像生成、分割和分类等核心任务中的整合。", "result": "综述揭示了提示机制通过提高准确性、鲁棒性和数据效率来改善特定任务的结果，并减少对手动特征工程的依赖，同时通过明确模型指导来增强模型可解释性。尽管取得了重大进展，但仍存在挑战，特别是在提示设计优化、数据异质性和确保临床部署的可扩展性方面。", "conclusion": "本综述概述了有前景的未来发展方向，包括先进的多模态提示和鲁棒的临床整合，强调了提示驱动的AI在加速医学诊断和个性化治疗规划革命中的关键作用。", "translation": "深度学习在医疗影像中展现出变革性潜力，但其临床应用常因数据稀缺、分布偏移和需要鲁棒任务泛化等挑战而受阻。基于提示的方法已成为引导深度学习模型的关键策略，提供灵活、领域特定的适应，显著提升模型性能和适应性，而无需大量再训练。本系统综述批判性地审视了医疗影像中提示工程的蓬勃发展。我们剖析了多种提示模式，包括文本指令、视觉提示和可学习嵌入，并分析了它们在图像生成、分割和分类等核心任务中的整合。我们的综合分析揭示了这些机制如何通过提高准确性、鲁棒性和数据效率来改善特定任务的结果，并减少对手动特征工程的依赖，同时通过明确模型指导来增强模型可解释性。尽管取得了实质性进展，但我们仍识别出持续存在的挑战，特别是在提示设计优化、数据异质性和确保临床部署的可扩展性方面。最后，本综述概述了有前景的未来发展方向，包括先进的多模态提示和鲁棒的临床整合，强调了提示驱动的AI在加速医学诊断和个性化治疗规划革命中的关键作用。", "summary": "这篇系统综述全面探讨了医疗影像领域的提示工程。它分析了文本、视觉和可学习嵌入等多种提示模式如何提升深度学习模型在图像生成、分割和分类等核心任务中的性能、鲁棒性和数据效率。文章强调了提示机制在减少手动特征工程和提高模型可解释性方面的优势，同时也指出了提示设计优化、数据异质性和临床可扩展性等现有挑战。最终，综述展望了多模态提示和临床整合的未来方向，强调了提示驱动AI在推动医疗诊断和个性化治疗中的重要作用。", "keywords": "医疗影像, 提示工程, 深度学习, 系统综述, 图像处理", "comments": "这篇综述对于理解提示工程在医疗影像领域的应用和前景具有重要意义。其创新之处在于系统性地梳理了不同提示模式及其在特定任务中的应用效果，并指出了该领域面临的关键挑战，为未来的研究提供了清晰的方向。文章强调了提示机制在提高模型性能、数据效率和可解释性方面的潜力，这对于加速深度学习在临床实践中的采纳至关重要。"}}
{"id": "2507.01036", "title": "Systemic Constraints of Undecidability", "authors": ["Seth Bulin"], "summary": "This paper presents a theory of systemic undecidability, reframing\nincomputability as a structural property of systems rather than a localized\nfeature of specific functions or problems. We define a notion of causal\nembedding and prove a closure principle: any subsystem that participates\nfunctionally in the computation of an undecidable system inherits its\nundecidability. This result positions undecidability as a pervasive constraint\non prediction, modeling, and epistemic access in both natural and artificial\nsystems. Our framework disarms oracle mimicry and challenges the view that\ncomputational limits can be circumvented through architectural innovation. By\ngeneralizing classical results into a dynamic systems context, this work\naugments the logical trajectory of G\\\"odel, Turing, and Chaitin, offering a new\nperspective of the topology of computability and its interrelation to the\nboundaries of scientific knowledge.", "comment": "Submitted version; includes appendices with formal definitions and\n  structural embeddings. Prepared in Nature Computational Science format.\n  Keywords: computability theory, undecidability, causal systems, structural\n  closure, recursion theory, Turing machines, hypercomputation,\n  metaundecidability, epistemic limits, consciousness, modeling limits", "pdf_url": "http://arxiv.org/pdf/2507.01036v1", "categories": ["cs.FL", "cs.AI", "math.LO"], "cate": "cs.FL", "url": "http://arxiv.org/abs/2507.01036v1", "date": "2025-06-21", "updated": "2025-06-21", "AI": {"title_translation": "不可判定性的系统性约束", "tldr": "本文提出了一种系统性不可判定性理论，将不可计算性重新定义为系统的结构属性，并证明不可判定系统的任何功能性子系统都会继承其不可判定性，这意味着对知识和预测的普遍限制。", "motivation": "将不可计算性重新定义为系统的结构属性而非局部特征，并理解其普遍存在的约束。", "method": "定义了因果嵌入的概念并证明了闭包原理；将经典结果推广到动态系统语境中。", "result": "任何功能性参与不可判定系统计算的子系统都会继承其不可判定性，从而将不可判定性定位为对预测、建模和认知获取的普遍约束。", "conclusion": "该工作扩展了哥德尔、图灵和查汀的逻辑轨迹，为可计算性的拓扑及其与科学知识边界的相互关系提供了新视角。", "translation": "本文提出了一种系统性不可判定性理论，将不可计算性重新定义为系统的结构属性，而非特定功能或问题的局部特征。我们定义了因果嵌入的概念，并证明了一个闭包原理：任何功能性参与不可判定系统计算的子系统都会继承其不可判定性。这一结果将不可判定性定位为自然和人工系统中预测、建模和认知获取的普遍约束。我们的框架解除了对预言机模仿的武装，并挑战了通过架构创新可以规避计算限制的观点。通过将经典结果推广到动态系统语境中，这项工作增强了哥德尔、图灵和查汀的逻辑轨迹，为可计算性的拓扑及其与科学知识边界的相互关系提供了新视角。", "summary": "本文提出了一种系统性不可判定性理论，将不可计算性定义为系统的结构属性。它引入了因果嵌入的概念和一个闭包原理，指出不可判定系统的任何功能性子系统都会继承其不可判定性。这意味着不可判定性是对预测和知识的普遍约束，挑战了通过架构创新规避计算限制的尝试，并扩展了经典可计算性理论。", "keywords": "系统性不可判定性, 不可计算性, 因果嵌入, 闭包原理, 可计算性理论", "comments": "该论文通过将不可判定性从特定问题特征提升为基本系统约束，提供了一个新颖的视角。这种泛化对于理解人工智能的局限性、复杂系统的建模以及科学知识的本质具有重要意义，可能改变可计算性理论的范式。"}}
{"id": "2507.01025", "title": "HPC-AI Coupling Methodology for Scientific Applications", "authors": ["Yutong Lu", "Dan Huang", "Pin Chen"], "summary": "Artificial intelligence (AI) technologies have fundamentally transformed\nnumerical-based high-performance computing (HPC) applications with data-driven\napproaches and endeavored to address existing challenges, e.g. high\ncomputational intensity, in various scientific domains. In this study, we\nexplore the scenarios of coupling HPC and AI (HPC-AI) in the context of\nemerging scientific applications, presenting a novel methodology that\nincorporates three patterns of coupling: surrogate, directive, and coordinate.\nEach pattern exemplifies a distinct coupling strategy, AI-driven prerequisite,\nand typical HPC-AI ensembles. Through case studies in materials science, we\ndemonstrate the application and effectiveness of these patterns. The study\nhighlights technical challenges, performance improvements, and implementation\ndetails, providing insight into promising perspectives of HPC-AI coupling. The\nproposed coupling patterns are applicable not only to materials science but\nalso to other scientific domains, offering valuable guidance for future HPC-AI\nensembles in scientific discovery.", "comment": "14 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.01025v1", "categories": ["cs.CE", "cs.AI", "physics.comp-ph"], "cate": "cs.CE", "url": "http://arxiv.org/abs/2507.01025v1", "date": "2025-06-17", "updated": "2025-06-17", "AI": {"title_translation": "用于科学应用的高性能计算-人工智能耦合方法", "tldr": "本研究提出了一种新颖的HPC-AI耦合方法，包含替代、指令和协调三种模式，并通过材料科学案例证明了其在解决计算挑战中的有效性。", "motivation": "人工智能技术已经通过数据驱动的方法彻底改变了基于数值的高性能计算（HPC）应用，并努力解决各种科学领域中存在的挑战，例如高计算强度。", "method": "本研究探索了新兴科学应用背景下的HPC和AI（HPC-AI）耦合场景，提出了一种包含三种耦合模式的新颖方法：替代（surrogate）、指令（directive）和协调（coordinate）。每种模式都展示了独特的耦合策略、AI驱动的先决条件和典型的HPC-AI组合。", "result": "通过在材料科学领域的案例研究，本研究展示了这些耦合模式的应用和有效性。研究强调了技术挑战、性能改进和实现细节，为HPC-AI耦合的广阔前景提供了见解。", "conclusion": "所提出的耦合模式不仅适用于材料科学，也适用于其他科学领域，为未来科学发现中的HPC-AI组合提供了宝贵指导。", "translation": "人工智能（AI）技术通过数据驱动的方法，从根本上改变了基于数值的高性能计算（HPC）应用，并致力于解决各种科学领域中存在的挑战，例如高计算强度。在本研究中，我们探索了新兴科学应用背景下HPC和AI（HPC-AI）的耦合场景，提出了一种包含三种耦合模式的新颖方法：替代、指令和协调。每种模式都展示了独特的耦合策略、AI驱动的先决条件和典型的HPC-AI组合。通过在材料科学领域的案例研究，我们展示了这些模式的应用和有效性。本研究强调了技术挑战、性能改进和实现细节，为HPC-AI耦合的广阔前景提供了见解。所提出的耦合模式不仅适用于材料科学，也适用于其他科学领域，为未来科学发现中的HPC-AI组合提供了宝贵指导。", "summary": "本研究针对科学应用中HPC和AI的耦合，提出了一种新颖的方法论。该方法包含替代、指令和协调三种独特的耦合模式，旨在通过AI驱动的方式解决HPC应用中遇到的高计算强度等挑战。通过材料科学的案例研究，论文验证了这些模式的有效性，并深入探讨了技术挑战、性能提升和实施细节。研究表明，这些耦合模式具有广泛的适用性，可为未来的科学发现提供HPC-AI整合的指导。", "keywords": "HPC-AI耦合, 科学应用, 耦合模式, 人工智能, 高性能计算", "comments": "该论文的创新之处在于提出并详细阐述了HPC-AI耦合的三种具体模式（替代、指令、协调），为如何有效结合高性能计算和人工智能提供了清晰的框架。其重要性在于，这些模式不仅解决了当前科学应用中计算强度高的问题，还为未来跨学科的科学发现提供了通用的指导原则和实践范例。"}}
{"id": "2507.01161", "title": "Imitation Learning for Satellite Attitude Control under Unknown Perturbations", "authors": ["Zhizhuo Zhang", "Hao Peng", "Xiaoli Bai"], "summary": "This paper presents a novel satellite attitude control framework that\nintegrates Soft Actor-Critic (SAC) reinforcement learning with Generative\nAdversarial Imitation Learning (GAIL) to achieve robust performance under\nvarious unknown perturbations. Traditional control techniques often rely on\nprecise system models and are sensitive to parameter uncertainties and external\nperturbations. To overcome these limitations, we first develop a SAC-based\nexpert controller that demonstrates improved resilience against actuator\nfailures, sensor noise, and attitude misalignments, outperforming our previous\nresults in several challenging scenarios. We then use GAIL to train a learner\npolicy that imitates the expert's trajectories, thereby reducing training costs\nand improving generalization through expert demonstrations. Preliminary\nexperiments under single and combined perturbations show that the SAC expert\ncan rotate the antenna to a specified direction and keep the antenna\norientation reliably stable in most of the listed perturbations. Additionally,\nthe GAIL learner can imitate most of the features from the trajectories\ngenerated by the SAC expert. Comparative evaluations and ablation studies\nconfirm the effectiveness of the SAC algorithm and reward shaping. The\nintegration of GAIL further reduces sample complexity and demonstrates\npromising imitation capabilities, paving the way for more intelligent and\nautonomous spacecraft control systems.", "comment": "2025 AAS/AIAA Astrodynamics Specialist Conference", "pdf_url": "http://arxiv.org/pdf/2507.01161v1", "categories": ["eess.SY", "cs.RO", "cs.SY"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01161v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "卫星姿态控制中的未知扰动下的模仿学习", "tldr": "本文提出一种结合SAC强化学习和GAIL的卫星姿态控制框架，以应对未知扰动。SAC专家控制器在多种扰动下表现出鲁棒性，而GAIL学习器能有效模仿专家行为，降低训练成本，有望实现更智能的航天器控制。", "motivation": "传统卫星姿态控制技术依赖精确模型且对参数不确定性和外部扰动敏感，本文旨在克服这些限制，实现未知扰动下的鲁棒控制。", "method": "1. 开发一个基于Soft Actor-Critic (SAC) 的专家控制器，以提高对执行器故障、传感器噪声和姿态失准的弹性。 2. 使用生成对抗模仿学习 (GAIL) 训练一个学习器策略，模仿专家的轨迹，以降低训练成本并提高泛化能力。", "result": "SAC专家控制器在单扰动和组合扰动下能将天线旋转到指定方向并保持稳定。GAIL学习器能模仿SAC专家轨迹的大部分特征。SAC算法和奖励整形被证实有效，GAIL的集成进一步降低了样本复杂度并展示了有前景的模仿能力。", "conclusion": "结合SAC强化学习和GAIL的卫星姿态控制框架在未知扰动下表现出鲁棒性，SAC专家控制器性能优异，GAIL学习器有效降低了训练成本并提高了泛化能力，为更智能的航天器控制系统奠定了基础。", "translation": "本文提出了一种新颖的卫星姿态控制框架，该框架将软执行器-评论家（Soft Actor-Critic, SAC）强化学习与生成对抗模仿学习（Generative Adversarial Imitation Learning, GAIL）相结合，以在各种未知扰动下实现鲁棒性能。传统的控制技术通常依赖精确的系统模型，并且对参数不确定性和外部扰动敏感。为了克服这些限制，我们首先开发了一个基于SAC的专家控制器，该控制器在执行器故障、传感器噪声和姿态失准方面表现出更高的弹性，在几个具有挑战性的场景中超越了我们之前的结果。然后，我们使用GAIL训练一个学习器策略，该策略模仿专家的轨迹，从而通过专家演示减少训练成本并提高泛化能力。在单一和组合扰动下的初步实验表明，SAC专家可以在大多数列出的扰动中将天线旋转到指定方向并可靠地保持天线姿态稳定。此外，GAIL学习器可以模仿SAC专家生成的轨迹的大部分特征。比较评估和消融研究证实了SAC算法和奖励整形的有效性。GAIL的集成进一步降低了样本复杂度，并展示了有前景的模仿能力，为更智能和自主的航天器控制系统铺平了道路。", "summary": "本文提出一种新颖的卫星姿态控制框架，结合了SAC强化学习和GAIL。该框架旨在克服传统控制技术对模型精度和扰动的敏感性。首先，开发了SAC专家控制器，其在执行器故障、传感器噪声和姿态失准等未知扰动下表现出优越的鲁棒性。随后，利用GAIL训练模仿专家轨迹的学习器，有效降低训练成本并提高泛化能力。实验结果表明，SAC专家能实现稳定的姿态控制，GAIL学习器能有效模仿专家行为，为未来智能自主航天器控制系统提供了潜力。", "keywords": "卫星姿态控制, 模仿学习, 强化学习, SAC, GAIL, 未知扰动", "comments": "这项研究创新性地结合了SAC强化学习和GAIL进行卫星姿态控制，解决了传统方法对模型依赖和扰动敏感的问题。通过模仿学习，有效降低了训练成本并提高了泛化能力，为实现更智能、更自主的航天器控制系统提供了重要的技术途径。"}}
{"id": "2507.01019", "title": "MALIBU Benchmark: Multi-Agent LLM Implicit Bias Uncovered", "authors": ["Imran Mirza", "Cole Huang", "Ishwara Vasista", "Rohan Patil", "Asli Akalin", "Sean O'Brien", "Kevin Zhu"], "summary": "Multi-agent systems, which consist of multiple AI models interacting within a\nshared environment, are increasingly used for persona-based interactions.\nHowever, if not carefully designed, these systems can reinforce implicit biases\nin large language models (LLMs), raising concerns about fairness and equitable\nrepresentation. We present MALIBU, a novel benchmark developed to assess the\ndegree to which LLM-based multi-agent systems implicitly reinforce social\nbiases and stereotypes. MALIBU evaluates bias in LLM-based multi-agent systems\nthrough scenario-based assessments. AI models complete tasks within predefined\ncontexts, and their responses undergo evaluation by an LLM-based multi-agent\njudging system in two phases. In the first phase, judges score responses\nlabeled with specific demographic personas (e.g., gender, race, religion)\nacross four metrics. In the second phase, judges compare paired responses\nassigned to different personas, scoring them and selecting the superior\nresponse. Our study quantifies biases in LLM-generated outputs, revealing that\nbias mitigation may favor marginalized personas over true neutrality,\nemphasizing the need for nuanced detection, balanced fairness strategies, and\ntransparent evaluation benchmarks in multi-agent systems.", "comment": "Accepted to Building Trust in LLMs @ ICLR 2025 and NAACL SRW 2025", "pdf_url": "http://arxiv.org/pdf/2507.01019v1", "categories": ["cs.CL", "cs.CY"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01019v1", "date": "2025-04-10", "updated": "2025-04-10", "AI": {"title_translation": "MALIBU 基准测试：揭示多智能体大型语言模型的隐性偏见", "tldr": "MALIBU是一个新基准，用于评估多智能体LLM系统如何隐性强化社会偏见。研究发现偏见缓解可能偏袒边缘化群体而非真正的中立，强调需要更细致的偏见检测和平衡的公平策略。", "motivation": "多智能体系统在人格化交互中日益普及，但若设计不当，这些系统可能强化大型语言模型（LLM）中的隐性偏见，从而引发对公平性和代表性的担忧。", "method": "MALIBU通过情景式评估来评估基于LLM的多智能体系统中的偏见。AI模型在预定义情境中完成任务，其响应由基于LLM的多智能体评判系统分两个阶段进行评估。第一阶段，评判者根据特定人口统计学角色（如性别、种族、宗教）对响应进行四项指标的评分。第二阶段，评判者比较分配给不同角色的配对响应，进行评分并选择更优的响应。", "result": "该研究量化了LLM生成输出中的偏见，揭示偏见缓解可能偏袒边缘化角色而非真正的中立性。", "conclusion": "研究强调了在多智能体系统中需要细致的偏见检测、平衡的公平策略和透明的评估基准。", "translation": "多智能体系统由多个AI模型在共享环境中交互组成，正越来越多地用于基于角色的交互。然而，如果设计不不够严谨，这些系统可能会强化大型语言模型（LLM）中的隐性偏见，从而引发对公平性和公平代表性的担忧。我们提出了MALIBU，这是一个新颖的基准，旨在评估基于LLM的多智能体系统在多大程度上隐性强化社会偏见和刻板印象。MALIBU通过情景式评估来评估基于LLM的多智能体系统中的偏见。AI模型在预定义的情境中完成任务，其响应由基于LLM的多智能体评判系统分两个阶段进行评估。在第一阶段，评判者根据特定的群体角色（例如，性别、种族、宗教）在四个指标上对响应进行评分。在第二阶段，评判者比较分配给不同角色的配对响应，对其进行评分并选择更优的响应。我们的研究量化了LLM生成输出中的偏见，揭示偏见缓解可能偏袒边缘化角色而非真正的中立性，这强调了在多智能体系统中需要细致的检测、平衡的公平策略和透明的评估基准。", "summary": "该论文提出了MALIBU，一个新颖的基准测试，旨在评估基于大型语言模型（LLM）的多智能体系统如何隐性强化社会偏见。MALIBU通过情景式评估，让AI模型完成任务，并由多智能体评判系统分两阶段评估其响应：首先对带有特定人口统计学角色的响应进行评分，然后比较不同角色的配对响应。研究发现LLM输出中存在偏见，且偏见缓解可能偏袒边缘化群体而非真正的中立，因此强调了在多智能体系统中需要更细致的偏见检测、平衡的公平策略和透明的评估基准。", "keywords": "多智能体系统, LLM偏见, MALIBU, 基准测试, 公平性", "comments": "MALIBU基准测试的创新之处在于其针对多智能体LLM系统隐性偏见的评估方法，特别是引入了两阶段的LLM-based多智能体评判系统。这对于理解和解决复杂AI系统中的公平性问题至关重要，揭示了偏见缓解可能带来的新问题，并强调了未来研究需要关注更精细的偏见检测和公平策略。"}}
{"id": "2507.01110", "title": "A LoD of Gaussians: Unified Training and Rendering for Ultra-Large Scale Reconstruction with External Memory", "authors": ["Felix Windisch", "Lukas Radl", "Thomas Köhler", "Michael Steiner", "Dieter Schmalstieg", "Markus Steinberger"], "summary": "Gaussian Splatting has emerged as a high-performance technique for novel view\nsynthesis, enabling real-time rendering and high-quality reconstruction of\nsmall scenes. However, scaling to larger environments has so far relied on\npartitioning the scene into chunks -- a strategy that introduces artifacts at\nchunk boundaries, complicates training across varying scales, and is poorly\nsuited to unstructured scenarios such as city-scale flyovers combined with\nstreet-level views. Moreover, rendering remains fundamentally limited by GPU\nmemory, as all visible chunks must reside in VRAM simultaneously. We introduce\nA LoD of Gaussians, a framework for training and rendering ultra-large-scale\nGaussian scenes on a single consumer-grade GPU -- without partitioning. Our\nmethod stores the full scene out-of-core (e.g., in CPU memory) and trains a\nLevel-of-Detail (LoD) representation directly, dynamically streaming only the\nrelevant Gaussians. A hybrid data structure combining Gaussian hierarchies with\nSequential Point Trees enables efficient, view-dependent LoD selection, while a\nlightweight caching and view scheduling system exploits temporal coherence to\nsupport real-time streaming and rendering. Together, these innovations enable\nseamless multi-scale reconstruction and interactive visualization of complex\nscenes -- from broad aerial views to fine-grained ground-level details.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01110v1", "categories": ["cs.GR", "cs.LG"], "cate": "cs.GR", "url": "http://arxiv.org/abs/2507.01110v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "高斯LoD：基于外部内存的超大规模重建统一训练与渲染", "tldr": "本文引入“高斯LoD”，通过外部存储和细节层次表示，实现单消费级GPU上超大规模高斯场景的统一训练和渲染，解决现有分块策略和GPU内存限制问题。", "motivation": "现有高斯溅射技术在处理大型环境时面临挑战，主要表现为：场景分块导致边界伪影、跨尺度训练复杂以及不适用于非结构化场景；同时，渲染受限于GPU内存，所有可见块需同时驻留显存。", "method": "本文提出了“高斯LoD”框架，将完整场景存储在外部（如CPU内存），并直接训练细节层次（LoD）表示，仅动态流式传输相关高斯点。通过结合高斯层次结构和顺序点树的混合数据结构实现高效的、依赖于视图的LoD选择，并利用轻量级缓存和视图调度系统利用时间相干性支持实时流式传输和渲染。", "result": "该方法在单个消费级GPU上实现了超大规模复杂场景的无缝多尺度重建和交互式可视化，涵盖从广阔空中视图到精细地面细节，且无需场景分块。", "conclusion": "“高斯LoD”成功克服了传统高斯溅射在可伸缩性和内存方面的限制，为超大规模3D重建和渲染提供了一个统一且高效的解决方案。", "translation": "高斯溅射已成为一种用于新颖视图合成的高性能技术，能够对小型场景进行实时渲染和高质量重建。然而，迄今为止，扩展到更大环境一直依赖于将场景分块——这种策略会在块边界引入伪影，使跨不同尺度的训练复杂化，并且不适用于非结构化场景，例如城市规模的飞行视图与街道级视图相结合。此外，渲染仍然受到GPU内存的根本限制，因为所有可见块必须同时驻留在显存中。我们引入了“高斯LoD”（A LoD of Gaussians），一个用于在单个消费级GPU上训练和渲染超大规模高斯场景的框架——无需分块。我们的方法将完整场景存储在外部（例如，在CPU内存中），并直接训练一个细节层次（LoD）表示，仅动态流式传输相关的​​高斯点。结合高斯层次结构与顺序点树的混合数据结构实现了高效的、依赖于视图的LoD选择，而轻量级缓存和视图调度系统利用时间相干性来支持实时流式传输和渲染。这些创新共同实现了复杂场景的无缝多尺度重建和交互式可视化——从广阔的空中视图到细致的地面细节。", "summary": "本文提出“高斯LoD”框架，旨在解决高斯溅射在大型场景重建中遇到的可伸缩性和GPU内存限制问题。该方法通过将完整场景存储在外部内存中，并直接训练细节层次（LoD）表示，实现仅动态流式传输相关高斯点。它利用结合高斯层次结构和顺序点树的混合数据结构进行高效的视图依赖LoD选择，并结合轻量级缓存与视图调度系统实现实时流式传输。最终，该框架可在单个消费级GPU上实现超大规模场景的无缝多尺度重建和交互式可视化，避免了传统分块策略的弊端。", "keywords": "高斯溅射, 细节层次, 外部存储, 大规模重建, 实时渲染", "comments": "该论文在高斯溅射领域取得了显著进展，有效解决了其在大规模环境下的可伸缩性瓶颈。其采用的外部存储LoD方法，结合动态流式传输和巧妙的混合数据结构，具有创新性，使得在消费级硬件上实现复杂多尺度场景的实际部署成为可能。它成功克服了分块伪影和GPU内存限制等问题，为大规模3D重建和沉浸式体验开辟了新的前景。"}}
{"id": "2507.01366", "title": "Faster Algorithm for Second (s,t)-mincut and Breaking Quadratic barrier for Dual Edge Sensitivity for (s,t)-mincut", "authors": ["Surender Baswana", "Koustav Bhanja", "Anupam Roy"], "summary": "We study (s,t)-cuts of second minimum capacity and present the following\nalgorithmic and graph-theoretic results.\n  1. Vazirani and Yannakakis [ICALP 1992] designed the first algorithm for\ncomputing an (s,t)-cut of second minimum capacity using $O(n^2)$ maximum\n(s,t)-flow computations. For directed integer-weighted graphs, we significantly\nimprove this bound by designing an algorithm that computes an $(s,t)$-cut of\nsecond minimum capacity using $O(\\sqrt{n})$ maximum (s,t)-flow computations\nw.h.p. To achieve this result, a close relationship of independent interest is\nestablished between $(s,t)$-cuts of second minimum capacity and global mincuts\nin directed weighted graphs.\n  2. Minimum+1 (s,t)-cuts have been studied quite well recently [Baswana,\nBhanja, and Pandey, ICALP 2022], which is a special case of second\n(s,t)-mincut.\n  (a) For directed multi-graphs, we design an algorithm that, given any maximum\n(s,t)-flow, computes a minimum+1 (s,t)-cut, if it exists, in $O(m)$ time.\n  (b) The existing structures for storing and characterizing all minimum+1\n(s,t)-cuts occupy $O(mn)$ space. For undirected multi-graphs, we design a DAG\noccupying only $O(m)$ space that stores and characterizes all minimum+1\n(s,t)-cuts.\n  3. The study of minimum+1 (s,t)-cuts often turns out to be useful in\ndesigning dual edge sensitivity oracles -- a compact data structure for\nefficiently reporting an (s,t)-mincut after insertion/failure of any given pair\nof query edges. It has been shown recently [Bhanja, ICALP 2025] that any dual\nedge sensitivity oracle for (s,t)-mincut in undirected multi-graphs must occupy\n${\\Omega}(n^2)$ space in the worst-case, irrespective of the query time. For\nsimple graphs, we break this quadratic barrier while achieving a non-trivial\nquery time.", "comment": "Accepted in ESA 2025", "pdf_url": "http://arxiv.org/pdf/2507.01366v1", "categories": ["cs.DS"], "cate": "cs.DS", "url": "http://arxiv.org/abs/2507.01366v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "第二小 (s,t)-最小割的更快算法及突破 (s,t)-最小割对偶边敏感性的二次屏障", "tldr": "本论文提出了计算第二小 (s,t)-最小割和最小+1 (s,t)-割的更快算法，并打破了简单图中 (s,t)-最小割对偶边敏感性预言机的二次空间屏障。", "motivation": "本研究旨在提高第二小容量 (s,t)-割的计算效率，并解决现有算法在最大流计算次数和空间占用方面的限制。同时，探索最小+1 (s,t)-割及其在对偶边敏感性预言机设计中的应用，旨在克服现有空间瓶颈。", "method": "1. 对于第二小 (s,t)-最小割，通过建立其与有向加权图中全局最小割的密切关系，设计了一个使用 $O(\\sqrt{n})$ 次最大 (s,t)-流计算（高概率）的算法。2. 对于最小+1 (s,t)-割：a) 对于有向多重图，设计了一个给定最大 (s,t)-流后在 $O(m)$ 时间内计算的算法。b) 对于无向多重图，设计了一个仅占用 $O(m)$ 空间的 DAG 来存储和表征所有最小+1 (s,t)-割。3. 对于对偶边敏感性预言机，在简单图上打破了 ${\\Omega}(n^2)$ 的二次空间屏障，同时实现了非平凡的查询时间。", "result": "1. 提出了一个计算第二小 (s,t)-最小割的算法，其所需的最大 (s,t)-流计算次数从 $O(n^2)$ 显著改进到 $O(\\sqrt{n})$（高概率）。2. 对于有向多重图，设计了一个在 $O(m)$ 时间内计算最小+1 (s,t)-割的算法。3. 对于无向多重图，设计了一个占用 $O(m)$ 空间的 DAG，用于存储和表征所有最小+1 (s,t)-割，将空间复杂度从 $O(mn)$ 降低。4. 对于简单图中的 (s,t)-最小割对偶边敏感性预言机，成功打破了其在最坏情况下的 ${\\Omega}(n^2)$ 空间屏障。", "conclusion": "本论文在算法和图论方面做出了重要贡献，为第二小 (s,t)-最小割和最小+1 (s,t)-割提供了更快的算法，并提高了对偶边敏感性预言机的空间效率，从而推进了对图割问题的理解和实际应用。", "translation": "我们研究第二小容量的 (s,t)-割，并提出了以下算法和图论结果。\n1. Vazirani 和 Yannakakis [ICALP 1992] 设计了第一个计算第二小容量 (s,t)-割的算法，使用了 $O(n^2)$ 次最大 (s,t)-流计算。对于有向整数加权图，我们通过设计一个算法，以 $O(\\sqrt{n})$ 次最大 (s,t)-流计算（高概率）来计算第二小容量 (s,t)-割，显著改进了这一界限。为了实现这一结果，我们在第二小容量 (s,t)-割和有向加权图中的全局最小割之间建立了一种独立的、密切的关系。\n2. 最近对最小+1 (s,t)-割的研究已经相当充分 [Baswana, Bhanja, and Pandey, ICALP 2022]，它是第二小 (s,t)-最小割的一个特例。\n(a) 对于有向多重图，我们设计了一个算法，在给定任何最大 (s,t)-流的情况下，如果存在，则在 $O(m)$ 时间内计算出最小+1 (s,t)-割。\n(b) 现有用于存储和表征所有最小+1 (s,t)-割的结构占用 $O(mn)$ 空间。对于无向多重图，我们设计了一个仅占用 $O(m)$ 空间的 DAG，用于存储和表征所有最小+1 (s,t)-割。\n3. 对最小+1 (s,t)-割的研究通常有助于设计对偶边敏感性预言机——一种紧凑的数据结构，用于在插入/故障任何给定查询边对后有效报告 (s,t)-最小割。最近 [Bhanja, ICALP 2025] 已表明，对于无向多重图中的 (s,t)-最小割，任何对偶边敏感性预言机在最坏情况下必须占用 ${\\Omega}(n^2)$ 空间，无论查询时间如何。对于简单图，我们打破了这一二次屏障，同时实现了非平凡的查询时间。", "summary": "本论文在图割问题上取得了显著的算法进展。它提出了一种计算第二小 (s,t)-最小割的更快算法，通过建立与全局最小割的联系，将其复杂度从 $O(n^2)$ 次最大流计算降低到 $O(\\sqrt{n})$ 次。论文还为最小+1 (s,t)-割提供了改进的算法和更节省空间的数据结构，包括有向多重图的 $O(m)$ 时间算法和无向多重图的 $O(m)$ 空间 DAG。此外，该论文在简单图中打破了 (s,t)-最小割的对偶边敏感性预言机长期存在的二次空间屏障。", "keywords": "第二小 (s,t)-最小割, 最小+1 (s,t)-割, 对偶边敏感性, 图算法, 最大流", "comments": "这篇论文通过显著提高第二小 (s,t)-最小割和最小+1 (s,t)-割等基本图问题的计算效率，做出了显著贡献。将第二小 (s,t)-最小割的计算复杂度从 $O(n^2)$ 次最大流计算降低到 $O(\\sqrt{n})$ 次是一个重大的理论突破。此外，关于对偶边敏感性预言机的工作，特别是打破二次空间屏障，解决了实际应用中需要图修改后高效更新的关键限制。在第二小 (s,t)-最小割和全局最小割之间建立关系也揭示了一个重要的理论见解。"}}
{"id": "2507.01150", "title": "Computational Insights into Orthotropic Fracture: Crack-Tip Fields in Strain-Limiting Materials under Non-Uniform Loads", "authors": ["Saugata Ghosh", "Dambaru Bhatta", "S. M. Mallikarjunaiah"], "summary": "A finite element framework is presented for analyzing crack-tip phenomena in\ntransversely isotropic, strain-limiting elastic materials. Mechanical response\nis characterized by an algebraically nonlinear constitutive model, relating\nstress to linearized strain. Non-physical strain singularities at the crack\napex are mitigated, ensuring bounded strain magnitudes. This methodology\nsignificantly advances boundary value problem (BVP) formulation, especially for\nfirst-order approximate theories. For a transversely isotropic elastic solid\nwith a crack, the governing equilibrium equation, derived from linear momentum\nbalance and the nonlinear constitutive model, is reduced to a second-order,\nvector-valued, quasilinear elliptic BVP. This BVP is solved using a robust\nnumerical scheme combining Picard-type linearization with a continuous Galerkin\nfinite element method for spatial discretization. Numerical results are\npresented for various loading conditions, including uniform tension,\nnon-uniform slope, and parabolic loading, with two distinct material fiber\norientations. It is demonstrated that crack-tip strain growth is substantially\nlower than stress growth. Nevertheless, strain-energy density is found to be\nconcentrated at the crack tip, consistent with linear elastic fracture\nmechanics principles. The proposed framework provides a robust basis for\nformulating physically meaningful, rigorous BVPs, critical for investigating\nfundamental processes like crack propagation, damage, and nucleation in\nanisotropic, strain-limiting elastic solids under diverse loading conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01150v1", "categories": ["math.NA", "cs.NA"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01150v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "正交各向异性断裂的计算见解：非均匀载荷下应变限制材料中的裂纹尖端场", "tldr": "本文提出了一个有限元框架，用于分析横观各向同性、应变限制弹性材料中的裂纹尖端现象，通过消除非物理应变奇异性来提供鲁棒的边界值问题公式。", "motivation": "为了分析横观各向同性、应变限制弹性材料中的裂纹尖端现象，并解决裂纹尖端非物理应变奇异性问题，同时推进边界值问题（BVP）的公式化，特别是对于一阶近似理论。", "method": "本文提出了一个有限元框架。机械响应通过代数非线性本构模型表征，该模型将应力与线性化应变关联。裂纹尖端的控制平衡方程被简化为二阶、向量值、拟线性椭圆边界值问题。该BVP通过结合Picard型线性化和连续Galerkin有限元方法的数值方案求解。", "result": "数值结果表明，裂纹尖端应变增长显著低于应力增长。尽管如此，应变能密度仍集中在裂纹尖端，这与线性弹性断裂力学原理一致。", "conclusion": "所提出的框架为制定物理意义明确、严谨的边界值问题提供了坚实的基础，这对于研究各向异性、应变限制弹性固体在不同载荷条件下的裂纹扩展、损伤和形核等基本过程至关重要。", "translation": "本文提出了一个有限元框架，用于分析横观各向同性、应变限制弹性材料中的裂纹尖端现象。机械响应通过代数非线性本构模型表征，该模型将应力与线性化应变关联。裂纹顶点的非物理应变奇异性得到缓解，确保了有界应变幅值。该方法显著推进了边界值问题（BVP）的公式化，特别是一阶近似理论。对于具有裂纹的横观各向同性弹性固体，源自线性动量平衡和非线性本构模型的控制平衡方程被简化为二阶、向量值、拟线性椭圆BVP。该BVP通过结合Picard型线性化和连续Galerkin有限元方法的鲁棒数值方案求解，用于空间离散化。数值结果呈现在各种加载条件下，包括均匀拉伸、非均匀斜坡和抛物线加载，并考虑了两种不同的材料纤维取向。结果表明，裂纹尖端应变增长显著低于应力增长。尽管如此，应变能密度被发现集中在裂纹尖端，这与线性弹性断裂力学原理一致。所提出的框架为制定物理意义明确、严谨的BVP提供了坚实的基础，这对于研究各向异性、应变限制弹性固体在不同载荷条件下的裂纹扩展、损伤和形核等基本过程至关重要。", "summary": "本文提出了一个用于分析横观各向同性、应变限制弹性材料中裂纹尖端现象的有限元框架。通过采用代数非线性本构模型并缓解非物理应变奇异性，该方法将控制方程简化为可使用Picard型线性化和连续Galerkin有限元法求解的拟线性椭圆边界值问题。研究结果显示，裂纹尖端应变增长低于应力增长，但应变能密度仍集中在裂纹尖端。该框架为研究各向异性应变限制材料中的断裂过程提供了鲁棒且物理意义明确的BVP基础。", "keywords": "正交各向异性断裂, 裂纹尖端场, 应变限制材料, 有限元, 边界值问题", "comments": "这项研究的创新之处在于其能够有效处理应变限制材料中的非物理应变奇异性，并提供一个鲁棒的有限元框架来解决复杂的非线性边界值问题。这对于理解和预测各向异性材料中的裂纹行为具有重要意义，尤其是在需要精确应变场分析的应用中。"}}
{"id": "2507.01021", "title": "Scalable Offline ASR for Command-Style Dictation in Courtrooms", "authors": ["Kumarmanas Nethil", "Vaibhav Mishra", "Kriti Anandan", "Kavya Manohar"], "summary": "We propose an open-source framework for Command-style dictation that\naddresses the gap between resource-intensive Online systems and high-latency\nBatch processing. Our approach uses Voice Activity Detection (VAD) to segment\naudio and transcribes these segments in parallel using Whisper models, enabling\nefficient multiplexing across audios. Unlike proprietary systems like\nSuperWhisper, this framework is also compatible with most ASR architectures,\nincluding widely used CTC-based models. Our multiplexing technique maximizes\ncompute utilization in real-world settings, as demonstrated by its deployment\nin around 15% of India's courtrooms. Evaluations on live data show consistent\nlatency reduction as user concurrency increases, compared to sequential batch\nprocessing. The live demonstration will showcase our open-sourced\nimplementation and allow attendees to interact with it in real-time.", "comment": "Accepted to Interspeech 2025 Show & Tell", "pdf_url": "http://arxiv.org/pdf/2507.01021v1", "categories": ["eess.AS", "cs.CL", "cs.SD"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01021v1", "date": "2025-06-07", "updated": "2025-06-07", "AI": {"title_translation": "法庭中命令式听写的可伸缩离线ASR", "tldr": "提出一个开源离线ASR框架，通过并行处理和多路复用，在法庭命令式听写中实现低延迟和高资源利用率。", "motivation": "解决资源密集型在线ASR系统与高延迟批处理ASR系统之间在法庭命令式听写场景下的差距。", "method": "提出一个开源框架，利用语音活动检测（VAD）分割音频，并使用Whisper模型并行转录这些片段，实现跨音频的高效多路复用。该框架兼容大多数ASR架构，包括CTC-based模型。", "result": "部署在印度约15%的法庭中，并在实时数据评估中显示，与顺序批处理相比，随着用户并发量的增加，延迟持续降低，同时最大化计算利用率。", "conclusion": "该开源框架通过其并行处理和多路复用技术，在法庭命令式听写中实现了可伸缩的离线ASR，有效解决了在线和批处理系统的不足，并在实际部署中展现出优异的性能。", "translation": "我们提出了一个用于命令式听写的开源框架，该框架解决了资源密集型在线系统与高延迟批处理系统之间的差距。我们的方法使用语音活动检测（VAD）来分割音频，并使用Whisper模型并行转录这些片段，从而实现跨音频的高效多路复用。与SuperWhisper等专有系统不同，该框架还兼容大多数ASR架构，包括广泛使用的基于CTC的模型。我们的多路复用技术在实际环境中最大限度地提高了计算利用率，这已通过其在印度约15%的法庭中的部署得到证明。对实时数据的评估显示，与顺序批处理相比，随着用户并发量的增加，延迟持续降低。现场演示将展示我们的开源实现，并允许与会者实时与其互动。", "summary": "这篇论文提出了一个名为“可伸缩离线ASR”的开源框架，专门针对法庭中的命令式听写场景。该框架旨在弥合高资源消耗的在线ASR系统与高延迟的批处理系统之间的鸿沟。它通过利用语音活动检测（VAD）进行音频分割，并使用Whisper模型并行转录这些片段，从而实现高效的多路复用和计算资源的最大化利用。该框架兼容包括CTC-based模型在内的多种ASR架构，并在印度约15%的法庭中得到部署。实时数据评估表明，随着用户并发量的增加，该系统能显著降低延迟，优于传统的顺序批处理方法。", "keywords": "离线ASR, 命令式听写, 多路复用, 语音活动检测, 法庭系统", "comments": "该论文提出了一种实用的离线ASR解决方案，特别适用于对延迟和资源利用率有高要求的特定场景（如法庭）。其创新点在于结合VAD、并行处理和多路复用技术，在离线模式下实现接近在线系统的响应速度，同时保持对多种ASR架构的兼容性。在印度法庭的实际部署证明了其重要性和有效性。作为开源框架，它也促进了社区的进一步发展和应用。"}}
{"id": "2507.01042", "title": "Can Argus Judge Them All? Comparing VLMs Across Domains", "authors": ["Harsh Joshi", "Gautam Siddharth Kashyap", "Rafiq Ali", "Ebad Shabbir", "Niharika Jain", "Sarthak Jain", "Jiechao Gao", "Usman Naseem"], "summary": "Vision-Language Models (VLMs) are advancing multimodal AI, yet their\nperformance consistency across tasks is underexamined. We benchmark CLIP, BLIP,\nand LXMERT across diverse datasets spanning retrieval, captioning, and\nreasoning. Our evaluation includes task accuracy, generation quality,\nefficiency, and a novel Cross-Dataset Consistency (CDC) metric. CLIP shows\nstrongest generalization (CDC: 0.92), BLIP excels on curated data, and LXMERT\nleads in structured reasoning. These results expose trade-offs between\ngeneralization and specialization, informing industrial deployment of VLMs and\nguiding development toward robust, task-flexible architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01042v1", "categories": ["cs.IR", "cs.AI", "cs.CL"], "cate": "cs.IR", "url": "http://arxiv.org/abs/2507.01042v1", "date": "2025-06-23", "updated": "2025-06-23", "AI": {"title_translation": "Argus 能否判断一切？比较跨领域的视觉语言模型", "tldr": "该研究对CLIP、BLIP和LXMERT等视觉语言模型（VLMs）在检索、图像描述和推理等多样化任务上进行了基准测试。结果显示CLIP泛化能力最强，BLIP在精选数据上表现出色，LXMERT在结构化推理方面领先，揭示了泛化与专业化之间的权衡。", "motivation": "视觉语言模型（VLMs）正在推动多模态人工智能的发展，但其在不同任务中的性能一致性尚未得到充分检验。", "method": "研究对CLIP、BLIP和LXMERT三种VLM在涵盖检索、图像描述和推理的各种数据集上进行了基准测试。评估指标包括任务准确性、生成质量、效率以及一种新颖的跨数据集一致性（CDC）指标。", "result": "CLIP表现出最强的泛化能力（CDC: 0.92）；BLIP在精选数据上表现出色；LXMERT在结构化推理方面处于领先地位。这些结果揭示了泛化和专业化之间的权衡。", "conclusion": "研究结果为视觉语言模型（VLMs）的工业部署提供了信息，并指导了鲁棒、任务灵活的架构开发。", "translation": "视觉语言模型 (VLM) 正在推动多模态人工智能的发展，但其在不同任务中的性能一致性尚未得到充分检验。我们对 CLIP、BLIP 和 LXMERT 在涵盖检索、图像描述和推理的各种数据集上进行了基准测试。我们的评估包括任务准确性、生成质量、效率以及一种新颖的跨数据集一致性 (CDC) 指标。CLIP 表现出最强的泛化能力 (CDC: 0.92)，BLIP 在精选数据上表现出色，而 LXMERT 在结构化推理方面处于领先地位。这些结果揭示了泛化和专业化之间的权衡，为 VLMs 的工业部署提供了信息，并指导了鲁棒、任务灵活的架构开发。", "summary": "本研究对CLIP、BLIP和LXMERT等主流视觉语言模型（VLMs）在检索、图像描述和推理等多样化任务和数据集上的性能一致性进行了基准测试，并引入了一种新的跨数据集一致性（CDC）指标。研究发现CLIP展现出强大的泛化能力，BLIP在精选数据上表现优异，而LXMERT在推理任务中表现突出，这些结果揭示了模型泛化与专业化之间的权衡，对VLMs的实际部署和未来架构开发具有指导意义。", "keywords": "视觉语言模型, 基准测试, 泛化, 一致性, 多模态AI", "comments": "这篇论文对主流视觉语言模型进行了有价值的比较分析，揭示了它们在不同领域中的优缺点。引入跨数据集一致性（CDC）这一新颖指标，对于评估模型的鲁棒性和泛化能力具有创新意义。研究结果为特定应用场景选择合适的VLM提供了实用见解，并为未来开发更鲁棒、更灵活的架构指明了方向。"}}
{"id": "2507.01524", "title": "Diversity-Preserving Exploitation of Crossover", "authors": ["Johannes Lengler", "Tom Offermann"], "summary": "Crossover is a powerful mechanism for generating new solutions from a given\npopulation of solutions. Crossover comes with a discrepancy in itself: on the\none hand, crossover usually works best if there is enough diversity in the\npopulation; on the other hand, exploiting the benefits of crossover reduces\ndiversity. This antagonism often makes crossover reduce its own effectiveness.\n  We introduce a new paradigm for utilizing crossover that reduces this\nantagonism, which we call diversity-preserving exploitation of crossover\n(DiPEC). The resulting Diversity Exploitation Genetic Algorithm (DEGA) is able\nto still exploit the benefits of crossover, but preserves a much higher\ndiversity than conventional approaches.\n  We demonstrate the benefits by proving that the (2+1)-DEGA finds the optimum\nof LeadingOnes with $O(n^{5/3}\\log^{2/3} n)$ fitness evaluations. This is\nremarkable since standard genetic algorithms need $\\Theta(n^2)$ evaluations,\nand among genetic algorithms only some artificial and specifically tailored\nalgorithms were known to break this runtime barrier. We confirm the theoretical\nresults by simulations. Finally, we show that the approach is not overfitted to\nLeadingones by testing it empirically on other benchmarks and showing that it\nis also competitive in other settings. We believe that our findings justify\nfurther systematic investigations of the DiPEC paradigm.", "comment": "accepted at FOGA 2025", "pdf_url": "http://arxiv.org/pdf/2507.01524v1", "categories": ["cs.NE"], "cate": "cs.NE", "url": "http://arxiv.org/abs/2507.01524v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "交叉的多样性保护利用", "tldr": "本文提出了一种名为“交叉的多样性保护利用 (DiPEC)”的新范式，旨在解决遗传算法中交叉操作在利用优势的同时会降低种群多样性的矛盾，显著提升了算法性能。", "motivation": "交叉操作在生成新解时效果最好，但其利用会减少种群多样性，这种内在的矛盾常常降低交叉操作的有效性。", "method": "引入了一种名为“交叉的多样性保护利用 (DiPEC)”的新范式，并基于此开发了多样性利用遗传算法 (DEGA)。", "result": "证明了(2+1)-DEGA在LeadingOnes问题上以$O(n^{5/3}\\log^{2/3} n)$的适应度评估次数找到最优解，显著优于标准遗传算法的$\\Theta(n^2)$。理论结果通过仿真得到证实。该方法在其他基准测试上也表现出竞争力，表明其通用性。", "conclusion": "DiPEC范式能够有效解决交叉操作中的多样性-利用矛盾，使得遗传算法在保持高多样性的同时显著提高性能，这 justifies 进一步的系统研究。", "translation": "交叉是一种从给定解群生成新解的强大机制。交叉本身存在一个矛盾：一方面，如果种群中有多样性，交叉通常效果最好；另一方面，利用交叉的优势会减少多样性。这种对立常常使交叉降低其自身的有效性。\n我们引入了一种利用交叉的新范式，它减少了这种对立，我们称之为交叉的多样性保护利用 (DiPEC)。由此产生的多样性利用遗传算法 (DEGA) 能够继续利用交叉的优势，但保留了比传统方法高得多的多样性。\n我们通过证明 (2+1)-DEGA 在 LeadingOnes 问题上以 $O(n^{5/3}\\log^{2/3} n)$ 的适应度评估次数找到最优解来证明其优势。这非常显著，因为标准遗传算法需要 $\\Theta(n^2)$ 次评估，并且在遗传算法中，只有一些人工设计和专门定制的算法才已知能打破这个运行时障碍。我们通过仿真证实了理论结果。最后，我们通过在其他基准测试上进行实证测试，并显示它在其他设置中也具有竞争力，表明该方法并未过度拟合 Leadingones。我们相信我们的发现证明了对 DiPEC 范式进行进一步系统研究的合理性。", "summary": "本文提出了一种名为“交叉的多样性保护利用 (DiPEC)”的新范式，旨在解决遗传算法中交叉操作在利用优势的同时会降低种群多样性的固有矛盾。基于此范式，开发了多样性利用遗传算法 (DEGA)。研究表明，DEGA能够有效利用交叉操作的优势，同时保持更高的种群多样性。理论和仿真结果证明，在LeadingOnes问题上，(2+1)-DEGA的性能远超传统遗传算法，并且在其他基准测试中也展现出竞争力，证明了DiPEC范式的有效性和普适性。", "keywords": "遗传算法, 交叉, 多样性, DiPEC, DEGA", "comments": "本文的创新点在于提出了一个新颖的DiPEC范式，成功解决了遗传算法中长期存在的交叉利用与多样性保持之间的矛盾。通过理论分析和实验验证，证明了其在优化效率上的显著提升，特别是打破了LeadingOnes问题的运行时壁垒，这对于进化算法领域具有重要意义。该研究为未来遗传算法的设计提供了新思路。"}}
{"id": "2507.01339", "title": "User-guided Generative Source Separation", "authors": ["Yutong Wen", "Minje Kim", "Paris Smaragdis"], "summary": "Music source separation (MSS) aims to extract individual instrument sources\nfrom their mixture. While most existing methods focus on the widely adopted\nfour-stem separation setup (vocals, bass, drums, and other instruments), this\napproach lacks the flexibility needed for real-world applications. To address\nthis, we propose GuideSep, a diffusion-based MSS model capable of\ninstrument-agnostic separation beyond the four-stem setup. GuideSep is\nconditioned on multiple inputs: a waveform mimicry condition, which can be\neasily provided by humming or playing the target melody, and mel-spectrogram\ndomain masks, which offer additional guidance for separation. Unlike prior\napproaches that relied on fixed class labels or sound queries, our conditioning\nscheme, coupled with the generative approach, provides greater flexibility and\napplicability. Additionally, we design a mask-prediction baseline using the\nsame model architecture to systematically compare predictive and generative\napproaches. Our objective and subjective evaluations demonstrate that GuideSep\nachieves high-quality separation while enabling more versatile instrument\nextraction, highlighting the potential of user participation in the\ndiffusion-based generative process for MSS. Our code and demo page are\navailable at https://yutongwen.github.io/GuideSep/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01339v1", "categories": ["cs.SD", "cs.AI", "eess.AS"], "cate": "cs.SD", "url": "http://arxiv.org/abs/2507.01339v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "用户引导的生成式音源分离", "tldr": "GuideSep是一个基于扩散模型的音乐音源分离工具，它允许用户通过哼唱或提供频谱掩码来灵活地分离出任意乐器，超越了传统的四干分离限制，并展示了用户参与生成过程的潜力。", "motivation": "现有的大多数音乐音源分离方法局限于四干分离（人声、贝斯、鼓、其他乐器），缺乏实际应用所需的灵活性。", "method": "论文提出了GuideSep，一个基于扩散模型的乐器无关音乐音源分离模型。它通过多种输入进行条件化：易于提供的波形模仿条件（如哼唱目标旋律）和提供额外分离指导的梅尔频谱域掩码。与依赖固定类别标签或声音查询的方法不同，GuideSep结合生成式方法提供了更大的灵活性。此外，还设计了一个使用相同模型架构的掩码预测基线进行系统比较。", "result": "客观和主观评估表明，GuideSep实现了高质量的分离，同时支持更通用的乐器提取。", "conclusion": "GuideSep证明了用户参与扩散模型生成过程在音乐音源分离中的潜力，实现了更灵活、更通用的乐器提取。", "translation": "音乐音源分离（MSS）旨在从混合音轨中提取单个乐器音源。尽管大多数现有方法专注于广泛采用的四干分离设置（人声、贝斯、鼓和其他乐器），但这种方法缺乏实际应用所需的灵活性。为了解决这个问题，我们提出了GuideSep，一个基于扩散模型的MSS模型，能够实现超越四干分离设置的乐器无关分离。GuideSep以多种输入为条件：波形模仿条件，这可以通过哼唱或演奏目标旋律轻松提供；以及梅尔频谱域掩码，提供额外的分离指导。与依赖固定类别标签或声音查询的先前方法不同，我们的条件方案结合生成方法，提供了更大的灵活性和适用性。此外，我们设计了一个使用相同模型架构的掩码预测基线，以系统地比较预测性和生成性方法。我们的客观和主观评估表明，GuideSep实现了高质量的分离，同时支持更通用的乐器提取，突出了用户参与基于扩散的生成过程在MSS中的潜力。我们的代码和演示页面可在https://yutongwen.github.io/GuideSep/获取。", "summary": "本文提出了GuideSep，一种用户引导的扩散模型，用于灵活的音乐音源分离，超越了传统的四干分离限制。它通过波形模仿和梅尔频谱掩码进行条件化，实现了乐器无关的分离。实验证明GuideSep能提供高质量且多功能的乐器提取，展示了用户参与生成式MSS的潜力。", "keywords": "音乐音源分离, 用户引导, 生成模型, 扩散模型, 乐器分离", "comments": "这篇论文的创新点在于引入了用户引导机制（如哼唱）和扩散模型相结合，实现了比传统四干分离更灵活、乐器无关的音乐音源分离。其重要性在于拓宽了音乐音源分离在实际应用中的可能性，并为未来的交互式音频处理提供了新的思路。"}}
{"id": "2507.01181", "title": "A Differentiable Distance Metric for Robotics Through Generalized Alternating Projection", "authors": ["Vinicius M. Gonçalves", "Shiqing Wei", "Eduardo Malacarne S. de Souza", "Krishnamurthy Prashanth", "Anthony Tzes", "Farshad Khorrami"], "summary": "In many robotics applications, it is necessary to compute not only the\ndistance between the robot and the environment, but also its derivative - for\nexample, when using control barrier functions. However, since the traditional\nEuclidean distance is not differentiable, there is a need for alternative\ndistance metrics that possess this property. Recently, a metric with guaranteed\ndifferentiability was proposed [1]. This approach has some important drawbacks,\nwhich we address in this paper. We provide much simpler and practical\nexpressions for the smooth projection for general convex polytopes.\nAdditionally, as opposed to [1], we ensure that the distance vanishes as the\nobjects overlap. We show the efficacy of the approach in experimental results.\nOur proposed distance metric is publicly available through the Python-based\nsimulation package UAIBot.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.01181v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01181v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "机器人学中基于广义交替投影的可微距离度量", "tldr": "本文提出了一种用于机器人学的可微距离度量，通过提供更简单实用的平滑投影表达式，并确保物体重叠时距离消失，解决了现有可微距离度量的缺点。", "motivation": "在许多机器人应用中，需要计算机器人与环境之间的距离及其导数（例如在使用控制障碍函数时），但传统欧几里得距离不可微。此外，现有的一种可微距离度量[1]存在重要缺点，因此需要提出一种改进的可微距离度量。", "method": "本文针对一般凸多面体，提供了更简单实用的平滑投影表达式，并确保当物体重叠时距离消失，以此改进了现有可微距离度量的缺点。", "result": "该方法在实验结果中显示出其有效性。所提出的距离度量已通过基于Python的仿真包UAIBot公开可用。", "conclusion": "Not mentioned in abstract", "translation": "在许多机器人应用中，不仅需要计算机器人与环境之间的距离，还需要计算其导数——例如，在使用控制障碍函数时。然而，由于传统的欧几里得距离不可微，因此需要具有此属性的替代距离度量。最近，提出了一种具有可微性保证的度量[1]。这种方法存在一些重要的缺点，我们在本文中解决了这些缺点。我们为一般凸多面体提供了更简单实用的平滑投影表达式。此外，与[1]不同，我们确保当物体重叠时距离消失。我们在实验结果中展示了该方法的有效性。我们提出的距离度量通过基于Python的仿真包UAIBot公开可用。", "summary": "本文提出了一种改进的可微距离度量，以满足机器人学中需要距离及其导数计算的需求。针对现有可微距离度量的缺点，作者为一般凸多面体提供了更简单实用的平滑投影表达式，并确保物体重叠时距离消失。实验结果验证了该方法的有效性，并且该距离度量已通过UAIBot开源。", "keywords": "可微距离度量, 机器人学, 平滑投影, 凸多面体", "comments": "本文创新性地改进了机器人学中可微距离度量的实用性，通过提供更简化的表达式并解决物体重叠时的距离消失问题，对控制障碍函数等应用具有重要意义。其开源实现也便于研究者和开发者使用。"}}
{"id": "2507.01282", "title": "Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care", "authors": ["Matthew JY Kang", "Wenli Yang", "Monica R Roberts", "Byeong Ho Kang", "Charles B Malpas"], "summary": "The recent boom of large language models (LLMs) has re-ignited the hope that\nartificial intelligence (AI) systems could aid medical diagnosis. Yet despite\ndazzling benchmark scores, LLM assistants have yet to deliver measurable\nimprovements at the bedside. This scoping review aims to highlight the areas\nwhere AI is limited to make practical contributions in the clinical setting,\nspecifically in dementia diagnosis and care.\n  Standalone machine-learning models excel at pattern recognition but seldom\nprovide actionable, interpretable guidance, eroding clinician trust. Adjacent\nuse of LLMs by physicians did not result in better diagnostic accuracy or\nspeed. Key limitations trace to the data-driven paradigm: black-box outputs\nwhich lack transparency, vulnerability to hallucinations, and weak causal\nreasoning. Hybrid approaches that combine statistical learning with expert\nrule-based knowledge, and involve clinicians throughout the process help bring\nback interpretability. They also fit better with existing clinical workflows,\nas seen in examples like PEIRS and ATHENA-CDS.\n  Future decision-support should prioritise explanatory coherence by linking\npredictions to clinically meaningful causes. This can be done through\nneuro-symbolic or hybrid AI that combines the language ability of LLMs with\nhuman causal expertise. AI researchers have addressed this direction, with\nexplainable AI and neuro-symbolic AI being the next logical steps in further\nadvancement in AI. However, they are still based on data-driven knowledge\nintegration instead of human-in-the-loop approaches. Future research should\nmeasure success not only by accuracy but by improvements in clinician\nunderstanding, workflow fit, and patient outcomes. A better understanding of\nwhat helps improve human-computer interactions is greatly needed for AI systems\nto become part of clinical practice.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01282v1", "categories": ["cs.AI", "cs.HC"], "cate": "cs.AI", "url": "http://arxiv.org/abs/2507.01282v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "超越黑箱AI：用于痴呆症护理的可解释混合系统", "tldr": "尽管LLMs在基准测试中表现出色，但其黑箱特性限制了在痴呆症护理临床应用中的实用性；可解释的混合AI系统和以人为本的方法是未来提升AI在医疗领域有效性的关键。", "motivation": "当前大型语言模型（LLMs）在医疗诊断领域，尤其是在痴呆症护理中，尽管基准分数很高，但在临床实践中未能带来显著改善。独立的机器学习模型缺乏可操作和可解释的指导，且存在黑箱输出、幻觉和因果推理弱等局限性，导致临床医生信任度低。", "method": "本文通过一项范围界定审查（scoping review）来突出AI在临床实践中，特别是在痴呆症诊断和护理中的局限性。文章提倡采用结合统计学习和专家规则知识的混合方法，并强调在整个过程中让临床医生参与的重要性。", "result": "独立的机器学习模型在模式识别方面表现出色，但缺乏可解释的指导。医生使用LLMs并未提高诊断准确性或速度。黑箱输出、幻觉和弱因果推理是当前数据驱动AI范式的关键局限。混合方法（如PEIRS和ATHENA-CDS）能够提高可解释性并更好地适应现有临床工作流程。未来的可解释AI和神经符号AI是进一步发展方向，但仍基于数据驱动的知识整合，而非以人为本的方法。", "conclusion": "未来的决策支持系统应优先考虑解释性连贯性，将预测与临床有意义的原因联系起来。这可以通过结合LLMs语言能力和人类因果专业知识的神经符号或混合AI来实现。未来的研究应不仅以准确性衡量成功，还要以提高临床医生理解、工作流程适应性和患者结果为标准，并需要更好地理解什么有助于改善人机交互以使AI系统融入临床实践。", "translation": "大型语言模型（LLMs）的最新繁荣重新点燃了人们对人工智能（AI）系统能够辅助医疗诊断的希望。然而，尽管基准测试得分令人眼花缭乱，LLM助手尚未在临床床边提供可衡量的改善。本范围界定审查旨在强调AI在临床环境中，特别是在痴呆症诊断和护理中，实际贡献受限的领域。\n独立的机器学习模型擅长模式识别，但很少提供可操作、可解释的指导，从而侵蚀了临床医生的信任。医生邻近使用LLMs并未导致更好的诊断准确性或速度。关键局限性可追溯到数据驱动范式：缺乏透明度的黑箱输出、易受幻觉影响以及弱因果推理。结合统计学习和专家规则知识，并让临床医生全程参与的混合方法有助于恢复可解释性。它们也更符合现有的临床工作流程，如PEIRS和ATHENA-CDS等例子所示。\n未来的决策支持应优先考虑解释性连贯性，通过将预测与临床上有意义的原因联系起来。这可以通过结合LLMs语言能力和人类因果专业知识的神经符号或混合AI来实现。AI研究人员已经关注这个方向，可解释AI和神经符号AI是AI进一步发展的下一个逻辑步骤。然而，它们仍然基于数据驱动的知识整合，而非以人为本的方法。未来的研究应不仅以准确性衡量成功，还要以提高临床医生理解、工作流程适应性和患者结果为标准。AI系统要成为临床实践的一部分，迫切需要更好地理解什么有助于改善人机交互。", "summary": "本论文是一项范围界定审查，旨在探讨当前人工智能（AI）系统，特别是大型语言模型（LLMs），在痴呆症诊断和护理临床应用中的局限性。研究指出，尽管LLMs在基准测试中表现优异，但其黑箱特性、缺乏可解释性、易产生幻觉以及因果推理能力弱等问题，阻碍了其在临床实践中的有效应用和医生信任。文章强调，结合统计学习和专家规则知识的混合AI系统，以及让临床医生参与的“以人为本”方法，能够提升AI的可解释性并更好地融入临床工作流程。未来AI发展应侧重于解释性连贯性、神经符号AI以及在评估AI成功时考量临床医生理解、工作流程适应性和患者结果。", "keywords": "痴呆症护理, 可解释AI, 混合系统, 大型语言模型, 临床应用", "comments": "这篇论文批判性地审视了当前AI（特别是LLMs）在医疗领域，尤其是痴呆症护理中的实际应用瓶颈。其创新之处在于明确指出了“黑箱”特性和缺乏可解释性是AI难以融入临床实践的核心障碍，并提出了混合AI系统和“以人为本”方法的解决方案。论文强调了AI发展不应仅仅追求准确性，更应关注临床实用性、医生信任度和患者结果，这对于推动AI在医疗领域的负责任发展具有重要指导意义。"}}
{"id": "2507.01103", "title": "Bugs in the Shadows: Static Detection of Faulty Python Refactorings", "authors": ["Jonhnanthan Oliveira", "Rohit Gheyi", "Márcio Ribeiro", "Alessandro Garcia"], "summary": "Python is a widely adopted programming language, valued for its simplicity\nand flexibility. However, its dynamic type system poses significant challenges\nfor automated refactoring - an essential practice in software evolution aimed\nat improving internal code structure without changing external behavior.\nUnderstanding how type errors are introduced during refactoring is crucial, as\nsuch errors can compromise software reliability and reduce developer\nproductivity. In this work, we propose a static analysis technique to detect\ntype errors introduced by refactoring implementations for Python. We evaluated\nour technique on Rope refactoring implementations, applying them to open-source\nPython projects. Our analysis uncovered 29 bugs across four refactoring types\nfrom a total of 1,152 refactoring attempts. Several of these issues were also\nfound in widely used IDEs such as PyCharm and PyDev. All reported bugs were\nsubmitted to the respective developers, and some of them were acknowledged and\naccepted. These results highlight the need to improve the robustness of current\nPython refactoring tools to ensure the correctness of automated code\ntransformations and support reliable software maintenance.", "comment": "Accepted at Brazilian Symposium on Software Engineering (SBES 2025)", "pdf_url": "http://arxiv.org/pdf/2507.01103v1", "categories": ["cs.SE"], "cate": "cs.SE", "url": "http://arxiv.org/abs/2507.01103v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "潜在的错误：Python重构中的静态缺陷检测", "tldr": "本文提出了一种静态分析技术，用于检测Python重构引入的类型错误，并在实际项目中发现了29个错误，凸显了现有重构工具的不足。", "motivation": "Python的动态类型系统给自动化重构带来了挑战，重构引入的类型错误会损害软件可靠性并降低开发效率。因此，理解和检测这些错误至关重要。", "method": "提出了一种静态分析技术，用于检测Python重构实现引入的类型错误。该技术在Rope重构实现上进行了评估，并应用于开源Python项目。", "result": "在1,152次重构尝试中，共发现了29个跨四种重构类型的错误。其中一些问题也存在于PyCharm和PyDev等常用IDE中。所有报告的错误都已提交给开发者，部分已被确认和接受。", "conclusion": "研究结果强调了提高当前Python重构工具的鲁棒性的必要性，以确保自动化代码转换的正确性并支持可靠的软件维护。", "translation": "Python是一种广泛采用的编程语言，因其简洁性和灵活性而受到重视。然而，其动态类型系统对自动化重构构成了重大挑战——自动化重构是软件演进中一项基本实践，旨在在不改变外部行为的情况下改进内部代码结构。理解重构过程中如何引入类型错误至关重要，因为此类错误会损害软件可靠性并降低开发人员生产力。在这项工作中，我们提出了一种静态分析技术来检测Python重构实现引入的类型错误。我们在Rope重构实现上评估了我们的技术，并将其应用于开源Python项目。我们的分析在总共1,152次重构尝试中，发现了29个跨四种重构类型的错误。其中一些问题也在PyCharm和PyDev等广泛使用的IDE中发现。所有报告的错误都已提交给各自的开发人员，其中一些已被确认和接受。这些结果强调了需要提高当前Python重构工具的鲁棒性，以确保自动化代码转换的正确性并支持可靠的软件维护。", "summary": "本文提出了一种针对Python代码的静态分析技术，旨在检测自动化重构过程中引入的类型错误。研究人员在Rope重构实现和开源项目上进行了评估，成功发现了29个错误，其中一些也存在于主流IDE中。这表明当前Python重构工具在可靠性方面存在不足，亟需改进以确保代码转换的正确性。", "keywords": "Python, 静态分析, 代码重构, 类型错误, 软件可靠性", "comments": "该研究的创新之处在于提出了一种静态分析技术来系统性地检测Python重构中引入的类型错误，填补了动态语言在自动化重构可靠性方面的空白。其重要性体现在发现了实际的、影响广泛的错误，并促使工具开发者改进。它揭示了现有Python重构工具的不足，对提高软件质量和开发效率具有实际意义。"}}
{"id": "2507.01020", "title": "AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models", "authors": ["Aashray Reddy", "Andrew Zagula", "Nicholas Saban"], "summary": "Large Language Models (LLMs) continue to exhibit vulnerabilities to\njailbreaking attacks: carefully crafted malicious inputs intended to circumvent\nsafety guardrails and elicit harmful responses. As such, we present AutoAdv, a\nnovel framework that automates adversarial prompt generation to systematically\nevaluate and expose vulnerabilities in LLM safety mechanisms. Our approach\nleverages a parametric attacker LLM to produce semantically disguised malicious\nprompts through strategic rewriting techniques, specialized system prompts, and\noptimized hyperparameter configurations. The primary contribution of our work\nis a dynamic, multi-turn attack methodology that analyzes failed jailbreak\nattempts and iteratively generates refined follow-up prompts, leveraging\ntechniques such as roleplaying, misdirection, and contextual manipulation. We\nquantitatively evaluate attack success rate (ASR) using the StrongREJECT\n(arXiv:2402.10260 [cs.CL]) framework across sequential interaction turns.\nThrough extensive empirical evaluation of state-of-the-art models--including\nChatGPT, Llama, and DeepSeek--we reveal significant vulnerabilities, with our\nautomated attacks achieving jailbreak success rates of up to 86% for harmful\ncontent generation. Our findings reveal that current safety mechanisms remain\nsusceptible to sophisticated multi-turn attacks, emphasizing the urgent need\nfor more robust defense strategies.", "comment": "16 pages, 4 figures, submitted to LLMSEC", "pdf_url": "http://arxiv.org/pdf/2507.01020v1", "categories": ["cs.CR", "cs.LG"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01020v1", "date": "2025-04-18", "updated": "2025-04-18", "AI": {"title_translation": "AutoAdv：大型语言模型多轮越狱的自动化对抗性提示", "tldr": "AutoAdv是一个自动化框架，通过生成语义伪装的恶意提示和迭代优化，对大型语言模型进行多轮越狱攻击，成功率高达86%，揭示了当前安全机制的脆弱性。", "motivation": "大型语言模型（LLMs）仍然容易受到越狱攻击，这些攻击旨在规避安全防护并诱导有害响应。因此，研究的动机是自动化对抗性提示生成，以系统地评估和揭示LLM安全机制中的漏洞。", "method": "本研究提出了AutoAdv框架，利用参数化攻击者LLM，通过战略性重写技术、专门的系统提示和优化的超参数配置，生成语义伪装的恶意提示。其主要贡献是动态、多轮攻击方法，该方法分析失败的越狱尝试，并利用角色扮演、误导和上下文操纵等技术迭代生成精炼的后续提示。攻击成功率（ASR）使用StrongREJECT框架进行定量评估。", "result": "通过对ChatGPT、Llama和DeepSeek等最先进模型的广泛实证评估，研究揭示了显著的漏洞，自动化攻击在有害内容生成方面的越狱成功率高达86%。", "conclusion": "研究结果表明，当前的安全机制仍然容易受到复杂的多轮攻击，这强调了对更强大防御策略的迫切需求。", "translation": "大型语言模型（LLMs）继续表现出对越狱攻击的脆弱性：精心设计的恶意输入旨在规避安全护栏并引出有害响应。因此，我们提出了AutoAdv，一个新颖的框架，它自动化对抗性提示生成，以系统地评估和揭示LLM安全机制中的漏洞。我们的方法利用参数化攻击者LLM，通过战略性重写技术、专门的系统提示和优化的超参数配置，生成语义伪装的恶意提示。我们工作的主要贡献是一种动态的、多轮攻击方法，它分析失败的越狱尝试并迭代生成精炼的后续提示，利用角色扮演、误导和上下文操纵等技术。我们使用StrongREJECT（arXiv:2402.10260 [cs.CL]）框架在顺序交互轮次中定量评估攻击成功率（ASR）。通过对包括ChatGPT、Llama和DeepSeek在内的最先进模型进行广泛的实证评估，我们揭示了显著的漏洞，我们的自动化攻击在有害内容生成方面的越狱成功率高达86%。我们的发现表明，当前的安全机制仍然容易受到复杂的多轮攻击，这强调了对更强大防御策略的迫切需求。", "summary": "AutoAdv是一个新颖的自动化框架，用于生成对抗性提示，以系统地评估和揭示大型语言模型（LLMs）的安全漏洞。该框架利用参数化攻击者LLM，通过重写、系统提示和超参数优化生成语义伪装的恶意提示。其核心是一个动态多轮攻击方法，能够分析失败的尝试并迭代生成精炼的后续提示，采用角色扮演、误导和上下文操纵等技术。对ChatGPT、Llama和DeepSeek等模型的评估显示，AutoAdv在有害内容生成方面的越狱成功率高达86%，强调了当前安全机制对复杂多轮攻击的脆弱性，并呼吁加强防御策略。", "keywords": "大型语言模型, 越狱攻击, 对抗性提示, 多轮攻击, 安全漏洞", "comments": "这项研究的创新之处在于提出了一个自动化且动态的多轮越狱攻击框架AutoAdv，它不仅能够自动生成对抗性提示，还能通过迭代优化和多种策略（如角色扮演、误导）来提升攻击成功率。其重要性在于揭示了当前LLM安全机制在面对复杂、持续性攻击时的显著脆弱性，为LLM开发者提供了明确的改进方向。该研究强调了开发更鲁棒防御策略的紧迫性。"}}
{"id": "2507.01289", "title": "Fluid Aerial Networks: UAV Rotation for Inter-Cell Interference Mitigation", "authors": ["Enzhi Zhou", "Yue Xiao", "Ziyue Liu", "Sotiris A. Tegos", "Panagiotis D. Diamantoulakis", "George K. Karagiannidis"], "summary": "With the rapid development of aerial infrastructure, unmanned aerial vehicles\n(UAVs) that function as aerial base stations (ABSs) extend terrestrial network\nservices into the sky, enabling on-demand connectivity and enhancing emergency\ncommunication capabilities in cellular networks by leveraging the flexibility\nand mobility of UAVs. In such a UAV-assisted network, this paper investigates\nposition-based beamforming between ABSs and ground users (GUs). To mitigate\ninter-cell interference, we propose a novel fluid aerial network that leverages\nABS rotation to increase multi-cell capacity and overall network efficiency.\nSpecifically, considering the line-of-sight channel model, the spatial\nbeamforming weights are determined by the orientation angles of the GUs. In\nthis direction, we examine the beamforming gain of a two-dimensional\nmultiple-input multiple-output (MIMO) array at various ground positions,\nrevealing that ABS rotation significantly affects multi-user channel\ncorrelation and inter-cell interference. Based on these findings, we propose an\nalternative low-complexity algorithm to design the optimal rotation angle for\nABSs, aiming to reduce inter-cell interference and thus maximize the sum rate\nof multi-cell systems. In simulations, exhaustive search serves as a benchmark\nto validate the optimization performance of the proposed sequential ABS\nrotation scheme. Moreover, simulation results demonstrate that, in\ninterference-limited regions, the proposed ABS rotation paradigm can\nsignificantly reduce inter-cell interference in terrestrial networks and\nimprove the multi-cell sum rate by approximately 10\\% compared to\nfixed-direction ABSs without rotation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01289v1", "categories": ["cs.NI", "eess.SP"], "cate": "cs.NI", "url": "http://arxiv.org/abs/2507.01289v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "流体空中网络：无人机旋转用于小区间干扰缓解", "tldr": "该论文提出利用无人机（UAV）作为空中基站（ABS）的旋转来缓解小区间干扰，以提高多小区容量和网络效率。仿真结果表明，在干扰受限区域，该方法可将多小区和速率提高约10%。", "motivation": "随着空中基础设施的快速发展，无人机作为空中基站（ABS）能够将地面网络服务扩展到空中，通过利用无人机的灵活性和移动性，在蜂窝网络中实现按需连接和增强应急通信能力。在这种无人机辅助网络中，一个关键挑战是缓解小区间干扰。", "method": "本文研究了ABS和地面用户（GUs）之间的基于位置的波束赋形。提出了一种利用ABS旋转的新型流体空中网络，以提高多小区容量和整体网络效率。具体来说，考虑视距信道模型，空间波束赋形权重由地面用户的方向角确定。研究了二维多输入多输出（MIMO）阵列在不同地面位置的波束赋形增益，揭示了ABS旋转显著影响多用户信道相关性和小区间干扰。基于这些发现，提出了一种替代的低复杂度算法来设计ABS的最佳旋转角度，旨在减少小区间干扰并最大化多小区系统的和速率。通过穷举搜索作为基准来验证所提出的顺序ABS旋转方案的优化性能。", "result": "ABS旋转显著影响多用户信道相关性和小区间干扰。在干扰受限区域，所提出的ABS旋转范式可以显著减少地面网络中的小区间干扰，与没有旋转的固定方向ABS相比，多小区和速率提高了约10%。", "conclusion": "通过利用空中基站（ABS）的旋转，可以有效降低无人机辅助网络中的小区间干扰，并显著提高多小区系统的吞吐量和整体网络效率。", "translation": "随着空中基础设施的快速发展，作为空中基站（ABS）的无人机（UAV）将地面网络服务扩展到空中，通过利用无人机的灵活性和移动性，在蜂窝网络中实现按需连接和增强应急通信能力。在这种无人机辅助网络中，本文研究了ABS和地面用户（GUs）之间的基于位置的波束赋形。为了缓解小区间干扰，我们提出了一种新型流体空中网络，该网络利用ABS旋转来增加多小区容量和整体网络效率。具体来说，考虑视距信道模型，空间波束赋形权重由地面用户的方向角确定。在此方向上，我们研究了二维多输入多输出（MIMO）阵列在不同地面位置的波束赋形增益，揭示了ABS旋转显著影响多用户信道相关性和小区间干扰。基于这些发现，我们提出了一种替代的低复杂度算法来设计ABS的最佳旋转角度，旨在减少小区间干扰并最大化多小区系统的和速率。在仿真中，穷举搜索作为基准来验证所提出的顺序ABS旋转方案的优化性能。此外，仿真结果表明，在干扰受限区域，所提出的ABS旋转范式可以显著减少地面网络中的小区间干扰，与没有旋转的固定方向ABS相比，多小区和速率提高了约10%。", "summary": "本文提出了一种新颖的“流体空中网络”概念，通过利用无人机（UAV）作为空中基站（ABS）的物理旋转来有效缓解小区间干扰。研究发现，ABS旋转显著影响多用户信道相关性和干扰。基于此，论文开发了一种低复杂度算法来优化ABS的旋转角度，旨在最大化多小区系统的和速率。仿真结果表明，与传统固定方向的ABS相比，该旋转方案在干扰受限区域能显著降低干扰并提高多小区和速率约10%，从而提升整体网络效率。", "keywords": "无人机, 空中基站, 小区间干扰, 波束赋形, 网络效率", "comments": "本文的创新点在于提出了利用空中基站（ABS）的物理旋转来主动管理和缓解小区间干扰，这是一种新颖且利用了无人机独特移动性的方法。它超越了传统的数字波束赋形，引入了物理层面的优化，为提升无人机辅助蜂窝网络的效率提供了一个有前景的方向。其重要性在于，在未来的空中基础设施中，这种方法能有效提升网络容量和性能，尤其是在干扰成为瓶颈的场景下。"}}
{"id": "2507.01123", "title": "Landslide Detection and Mapping Using Deep Learning Across Multi-Source Satellite Data and Geographic Regions", "authors": ["Rahul A. Burange", "Harsh K. Shinde", "Omkar Mutyalwar"], "summary": "Landslides pose severe threats to infrastructure, economies, and human lives,\nnecessitating accurate detection and predictive mapping across diverse\ngeographic regions. With advancements in deep learning and remote sensing,\nautomated landslide detection has become increasingly effective. This study\npresents a comprehensive approach integrating multi-source satellite imagery\nand deep learning models to enhance landslide identification and prediction. We\nleverage Sentinel-2 multispectral data and ALOS PALSAR-derived slope and\nDigital Elevation Model (DEM) layers to capture critical environmental features\ninfluencing landslide occurrences. Various geospatial analysis techniques are\nemployed to assess the impact of terra in characteristics, vegetation cover,\nand rainfall on detection accuracy. Additionally, we evaluate the performance\nof multiple stateof-the-art deep learning segmentation models, including U-Net,\nDeepLabV3+, and Res-Net, to determine their effectiveness in landslide\ndetection. The proposed framework contributes to the development of reliable\nearly warning systems, improved disaster risk management, and sustainable\nland-use planning. Our findings provide valuable insights into the potential of\ndeep learning and multi-source remote sensing in creating robust, scalable, and\ntransferable landslide prediction models.", "comment": "20 pages, 24 figures", "pdf_url": "http://arxiv.org/pdf/2507.01123v1", "categories": ["cs.CV", "cs.LG", "eess.IV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01123v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "跨多源卫星数据和地理区域的深度学习滑坡检测与制图", "tldr": "本研究结合多源卫星数据和深度学习模型，提出了一种增强滑坡检测和预测的综合方法，并评估了不同深度学习模型在滑坡检测中的有效性。", "motivation": "滑坡对基础设施、经济和人类生命构成严重威胁，因此需要跨不同地理区域的准确检测和预测性制图。", "method": "该研究提出了一种综合方法，整合了多源卫星图像和深度学习模型。利用Sentinel-2多光谱数据和ALOS PALSAR衍生的坡度和数字高程模型（DEM）层，以捕获影响滑坡发生的重要环境特征。采用多种地理空间分析技术评估地形特征、植被覆盖和降雨对检测精度的影响。此外，评估了U-Net、DeepLabV3+和Res-Net等多种先进深度学习分割模型的性能。", "result": "研究结果为深度学习和多源遥感在创建鲁棒、可扩展和可转移的滑坡预测模型方面的潜力提供了宝贵的见解。", "conclusion": "所提出的框架有助于开发可靠的早期预警系统、改进灾害风险管理和可持续土地利用规划。", "translation": "滑坡对基础设施、经济和人类生命构成严重威胁，因此需要跨不同地理区域的准确检测和预测性制图。随着深度学习和遥感技术的进步，自动化滑坡检测变得越来越有效。本研究提出了一种综合方法，整合了多源卫星图像和深度学习模型，以增强滑坡识别和预测。我们利用Sentinel-2多光谱数据和ALOS PALSAR衍生的坡度和数字高程模型（DEM）层，以捕获影响滑坡发生的重要环境特征。采用多种地理空间分析技术评估地形特征、植被覆盖和降雨对检测精度的影响。此外，我们评估了包括U-Net、DeepLabV3+和Res-Net在内的多种最先进的深度学习分割模型的性能，以确定它们在滑坡检测中的有效性。所提出的框架有助于开发可靠的早期预警系统、改进灾害风险管理和可持续土地利用规划。我们的研究结果为深度学习和多源遥感在创建鲁棒、可扩展和可转移的滑坡预测模型方面的潜力提供了宝贵的见解。", "summary": "本文提出了一种利用多源卫星数据（Sentinel-2、ALOS PALSAR）和深度学习模型（U-Net、DeepLabV3+、Res-Net）进行滑坡检测和预测的综合方法。研究评估了地形、植被和降雨对检测精度的影响，并比较了不同深度学习模型的性能。研究结果强调了深度学习和多源遥感在构建可靠、可扩展和可转移的滑坡预测模型方面的潜力，有助于灾害风险管理和土地利用规划。", "keywords": "滑坡检测, 深度学习, 多源卫星数据, 遥感, 灾害管理", "comments": "这项研究通过整合多源卫星数据（光学和雷达）与先进的深度学习分割模型，为滑坡检测和预测提供了一个全面的框架，其创新性在于数据融合和模型评估的广度。这对于提高早期预警系统的可靠性和支持可持续土地利用规划具有重要意义。"}}
{"id": "2507.01195", "title": "Revisiting Noise-adaptive Transpilation in Quantum Computing: How Much Impact Does it Have?", "authors": ["Yuqian Huo", "Jinbiao Wei", "Christopher Kverne", "Mayur Akewar", "Janki Bhimani", "Tirthak Patel"], "summary": "Transpilation, particularly noise-aware optimization, is widely regarded as\nessential for maximizing the performance of quantum circuits on superconducting\nquantum computers. The common wisdom is that each circuit should be transpiled\nusing up-to-date noise calibration data to optimize fidelity. In this work, we\nrevisit the necessity of frequent noise-adaptive transpilation, conducting an\nin-depth empirical study across five IBM 127-qubit quantum computers and 16\ndiverse quantum algorithms. Our findings reveal novel and interesting insights:\n(1) noise-aware transpilation leads to a heavy concentration of workloads on a\nsmall subset of qubits, which increases output error variability; (2) using\nrandom mapping can mitigate this effect while maintaining comparable average\nfidelity; and (3) circuits compiled once with calibration data can be reliably\nreused across multiple calibration cycles and time periods without significant\nloss in fidelity. These results suggest that the classical overhead associated\nwith daily, per-circuit noise-aware transpilation may not be justified. We\npropose lightweight alternatives that reduce this overhead without sacrificing\nfidelity -- offering a path to more efficient and scalable quantum workflows.", "comment": "This paper will appear in the Proceedings of the International\n  Conference on Computer-Aided Design (ICCAD), 2025", "pdf_url": "http://arxiv.org/pdf/2507.01195v1", "categories": ["quant-ph", "cs.ET"], "cate": "quant-ph", "url": "http://arxiv.org/abs/2507.01195v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "重新审视量子计算中的噪声自适应转译：它有多大影响？", "tldr": "本研究重新审视了量子计算中频繁进行噪声自适应转译的必要性，发现其可能导致工作负载集中和误差变异性增加。研究表明，使用随机映射可以缓解此问题，并且一次编译的电路可以在多个校准周期内可靠复用，无需频繁的噪声自适应转译，从而降低经典开销。", "motivation": "量子计算中，噪声感知转译被广泛认为是最大化超导量子计算机性能的关键。普遍认为，每个电路都应使用最新的噪声校准数据进行转译以优化保真度。本研究旨在重新审视频繁进行噪声自适应转译的必要性。", "method": "进行了一项深入的实证研究，涉及五台IBM 127量子比特量子计算机和16种不同的量子算法。", "result": "1. 噪声感知转译导致工作负载高度集中在少量量子比特上，增加了输出误差变异性； 2. 使用随机映射可以缓解这种影响，同时保持可比的平均保真度； 3. 使用校准数据编译一次的电路可以在多个校准周期和时间段内可靠复用，而不会显著损失保真度。", "conclusion": "每日、每个电路的噪声感知转译所带来的经典开销可能是不合理的。研究提出了轻量级的替代方案，可以在不牺牲保真度的情况下减少这种开销，从而实现更高效、更可扩展的量子工作流程。", "translation": "转译，特别是噪声感知优化，被广泛认为是最大化超导量子计算机性能的关键。普遍的看法是，每个电路都应该使用最新的噪声校准数据进行转译，以优化保真度。在这项工作中，我们重新审视了频繁进行噪声自适应转译的必要性，在五台IBM 127量子比特量子计算机和16种不同的量子算法上进行了深入的实证研究。我们的发现揭示了新颖而有趣的见解：(1) 噪声感知转译导致工作负载高度集中在少量量子比特上，这增加了输出误差变异性；(2) 使用随机映射可以缓解这种影响，同时保持可比的平均保真度；(3) 使用校准数据编译一次的电路可以在多个校准周期和时间段内可靠复用，而不会显著损失保真度。这些结果表明，与每日、每个电路的噪声感知转译相关的经典开销可能是不合理的。我们提出了轻量级的替代方案，可以在不牺牲保真度的情况下减少这种开销——为更高效、更可扩展的量子工作流程提供了途径。", "summary": "本研究重新评估了量子计算中噪声自适应转译的必要性。通过在多台IBM量子计算机上对多种量子算法进行实证研究，发现频繁的噪声感知转译会导致工作负载集中和误差增加。研究表明，随机映射可以减轻此问题，并且一次编译的电路可重复使用，无需频繁更新校准数据。这挑战了传统观念，并提出更高效的量子工作流替代方案，以减少经典开销。", "keywords": "量子计算, 转译, 噪声自适应, 性能优化, 经典开销", "comments": "这项研究质疑了量子计算领域中一个普遍接受的最佳实践，即频繁进行噪声自适应转译。其创新之处在于通过大规模实证研究揭示了噪声感知转译可能带来的负面影响（工作负载集中和误差变异性），并提出了简单而有效的解决方案（随机映射和电路复用）。这对于降低量子计算的经典开销、提高其可扩展性和实用性具有重要意义。"}}
{"id": "2507.01121", "title": "From Literature to ReWA: Discussing Reproductive Well-being in HCI", "authors": ["Hafsah Mahzabin Chowdhury", "Sharifa Sultana"], "summary": "Reproductive well-being is shaped by intersecting cultural, religious,\ngendered, and political contexts, yet current technologies often reflect\nnarrow, Western-centric assumptions. In this literature review, we synthesize\nfindings from 147 peer-reviewed papers published between 2015 and 2025 across\nHCI, CSCW and social computing, ICTD, digital and public health, and AI for\nwell-being scholarship to map the evolving reproductive well-being landscape.\nWe identify three thematic waves that focused on early access and education,\ncultural sensitivity and privacy, and AI integration with policy-aware design,\nand highlight how technologies support or constrain diverse reproductive\nexperiences. Our analysis reveals critical gaps in inclusivity, with persistent\nexclusions of men and non-binary users, migrants, and users in the Global\nSouth. Additionally, we surfaced the significant absence of literature on the\nrole of stakeholders (e.g., husband and family members, household maids and\ncleaning helping hands, midwife, etc.) in the reproductive well-being space.\nDrawing on the findings from the literature, we propose the ReWA framework to\nsupport reproductive well-being for all agendas through six design orientations\nassociated with: location, culture, and history; polyvocality and agency;\nrationality, temporality, distributive roles, and methodology.", "comment": "23 pages", "pdf_url": "http://arxiv.org/pdf/2507.01121v1", "categories": ["cs.HC", "cs.CY"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01121v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "从文献到ReWA：探讨人机交互中的生殖福祉", "tldr": "该文献综述分析了147篇关于人机交互中生殖福祉的论文，揭示了当前技术存在的排他性问题，并提出了ReWA框架，旨在通过六个设计导向来支持普惠的生殖福祉。", "motivation": "生殖福祉受文化、宗教、性别和政治等多重因素影响，但现有技术常反映狭隘的西方中心假设。本研究旨在通过文献综述，全面了解生殖福祉领域的发展，并识别现有技术的不足和文献空白，以期提出更具包容性的设计框架。", "method": "本研究是一项文献综述，综合分析了2015年至2025年间在人机交互（HCI）、CSCW、社会计算、ICTD、数字与公共健康以及AI福祉领域发表的147篇同行评审论文。研究方法包括识别三个主题波段、揭示包容性差距以及提出ReWA框架。", "result": "研究识别了生殖福祉技术发展的三个主题波段：早期获取与教育、文化敏感性与隐私、以及AI整合与政策感知设计。分析揭示了包容性方面的严重缺失，包括持续排斥男性、非二元性别用户、移民和全球南方用户。此外，研究还发现关于利益相关者（如丈夫、家庭成员、助产士等）在生殖福祉领域作用的文献显著缺失。", "conclusion": "基于文献综述的发现，本研究提出了ReWA框架，旨在通过六个设计导向（地理、文化与历史；多音性与能动性；理性、时间性、分配角色与方法论）来支持所有人的生殖福祉议程。", "translation": "生殖福祉受到文化、宗教、性别和政治等多重因素的影响，然而当前技术往往反映出狭隘的、以西方为中心的设计假设。在这篇文献综述中，我们综合了2015年至2025年间发表在人机交互（HCI）、CSCW和社会计算、ICTD、数字与公共健康以及AI福祉等领域的147篇同行评审论文的发现，以描绘不断演变的生殖福祉图景。我们识别了三个主题浪潮，分别侧重于早期获取和教育、文化敏感性和隐私，以及AI整合与政策感知设计，并强调了技术如何支持或限制多样化的生殖体验。我们的分析揭示了包容性方面的严重缺失，持续排斥男性和非二元性别用户、移民以及全球南方的用户。此外，我们还发现关于利益相关者（例如，丈夫和家庭成员、家政服务人员、助产士等）在生殖福祉领域作用的文献显著缺失。借鉴文献发现，我们提出了ReWA框架，旨在通过与地点、文化和历史；多音性与能动性；理性、时间性、分配角色和方法论相关的六个设计导向，支持所有人的生殖福祉议程。", "summary": "本研究通过对147篇人机交互及相关领域论文的文献综述，探讨了生殖福祉技术的发展和现状。研究识别了该领域的三大主题波段，并揭示了现有技术在包容性方面的严重不足，特别是对男性、非二元性别用户、移民和全球南方用户的忽视，以及利益相关者作用研究的空白。基于这些发现，论文提出了ReWA框架，旨在通过关注地域、文化、历史、多音性、能动性、理性、时间性、分配角色和方法论等六个设计导向，促进普惠的生殖福祉。", "keywords": "生殖福祉, 人机交互, 文献综述, ReWA框架, 包容性", "comments": "该论文通过全面的文献综述，系统地梳理了人机交互领域生殖福祉研究的演变和现状，其创新之处在于识别了该领域存在的显著包容性差距和利益相关者研究的空白。ReWA框架的提出，为未来设计更具文化敏感性和普惠性的生殖福祉技术提供了重要的理论指导和设计方向，对于促进全球生殖健康公平具有重要意义。"}}
{"id": "2507.01027", "title": "DBellQuant: Breaking the Bell with Double-Bell Transformation for LLMs Post Training Binarization", "authors": ["Zijian Ye", "Wei Huang", "Yifei Yu", "Tianhe Ren", "Zhongrui Wang", "Xiaojuan Qi"], "summary": "Large language models (LLMs) demonstrate remarkable performance but face\nsubstantial computational and memory challenges that limit their practical\ndeployment. Quantization has emerged as a promising solution; however, its\neffectiveness is often limited by quantization errors arising from weight\ndistributions that are not quantization-friendly and the presence of activation\noutliers. To address these challenges, we introduce DBellQuant, an innovative\npost-training quantization (PTQ) framework that achieves nearly 1-bit weight\ncompression and 6-bit activation quantization with minimal performance\ndegradation. DBellQuant uses Learnable Transformation for Dual-Bell (LTDB)\nalgorithm, which transforms single-bell weight distributions into dual-bell\nforms to reduce binarization errors and applies inverse transformations to\nsmooth activations. DBellQuant sets a new state-of-the-art by preserving\nsuperior model performance under aggressive weight and activation quantization.\nFor example, on the Wikitext2 dataset, DBellQuant achieves a perplexity of\n14.39 on LLaMA2-13B with 6-bit activation quantization, significantly\noutperforming BiLLM's 21.35 without activation quantization, underscoring its\npotential in compressing LLMs for real-world applications.", "comment": "19 pages; Appendix added", "pdf_url": "http://arxiv.org/pdf/2507.01027v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01027v1", "date": "2025-06-18", "updated": "2025-06-18", "AI": {"title_translation": "DBellQuant：通过双钟形变换突破钟形限制，实现大型语言模型训练后二值化", "tldr": "DBellQuant通过双钟形变换减少量化误差，实现了大型语言模型的高效训练后二值化，显著提升了压缩性能。", "motivation": "大型语言模型（LLMs）面临巨大的计算和内存挑战，限制了它们的实际部署。现有的量化方法受限于不友好的权重分布和激活异常值导致的量化误差。", "method": "DBellQuant是一种创新的训练后量化（PTQ）框架。它使用可学习的双钟形变换（LTDB）算法，将单钟形权重分布转换为双钟形，以减少二值化误差，并应用逆变换来平滑激活。", "result": "DBellQuant在激进的权重和激活量化下保持了卓越的模型性能。例如，在Wikitext2数据集上，DBellQuant在LLaMA2-13B上实现了14.39的困惑度，激活量化为6位，显著优于BiLLM的21.35（无激活量化）。", "conclusion": "DBellQuant在压缩大型语言模型以用于实际应用方面具有巨大潜力。", "translation": "大型语言模型（LLMs）表现出卓越的性能，但面临巨大的计算和内存挑战，限制了它们的实际部署。量化已成为一种有前景的解决方案；然而，其有效性通常受到权重分布不适合量化以及激活异常值存在的量化误差的限制。为了解决这些挑战，我们引入了DBellQuant，一个创新的训练后量化（PTQ）框架，它实现了近1位的权重压缩和6位的激活量化，且性能下降极小。DBellQuant使用可学习的双钟形变换（LTDB）算法，将单钟形权重分布转换为双钟形，以减少二值化误差，并应用逆变换来平滑激活。DBellQuant通过在激进的权重和激活量化下保持卓越的模型性能，树立了新的SOTA。例如，在Wikitext2数据集上，DBellQuant在LLaMA2-13B上实现了14.39的困惑度，激活量化为6位，显著优于BiLLM的21.35（无激活量化），突显了其在压缩LLMs以用于实际应用中的潜力。", "summary": "本研究提出了DBellQuant，一个用于大型语言模型（LLMs）的创新训练后量化（PTQ）框架。为解决现有量化方法中不友好的权重分布和激活异常值导致的误差问题，DBellQuant引入了可学习的双钟形变换（LTDB）算法，将权重分布转换为双钟形以减少二值化误差，并对激活进行逆变换以平滑。该方法实现了近1位的权重压缩和6位的激活量化，同时保持了卓越的模型性能，例如在LLaMA2-13B上优于BiLLM，展示了其在LLMs实际部署中的巨大潜力。", "keywords": "大型语言模型, 量化, 训练后量化, 双钟形变换, 模型压缩", "comments": "DBellQuant的创新之处在于引入了双钟形变换来优化权重分布，从而显著减少了二值化误差，并结合激活的逆变换来保持性能。这对于LLMs的轻量化和实际部署具有重要意义，因为它在极高压缩率下实现了最先进的性能。"}}
{"id": "2507.01378", "title": "RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms", "authors": ["Ziyao Wang", "Rongpeng Li", "Sizhao Li", "Yuming Xiang", "Haiping Wang", "Zhifeng Zhao", "Honggang Zhang"], "summary": "Intelligent control of Unmanned Aerial Vehicles (UAVs) swarms has emerged as\na critical research focus, and it typically requires the swarm to navigate\neffectively while avoiding obstacles and achieving continuous coverage over\nmultiple mission targets. Although traditional Multi-Agent Reinforcement\nLearning (MARL) approaches offer dynamic adaptability, they are hindered by the\nsemantic gap in numerical communication and the rigidity of homogeneous role\nstructures, resulting in poor generalization and limited task scalability.\nRecent advances in Large Language Model (LLM)-based control frameworks\ndemonstrate strong semantic reasoning capabilities by leveraging extensive\nprior knowledge. However, due to the lack of online learning and over-reliance\non static priors, these works often struggle with effective exploration,\nleading to reduced individual potential and overall system performance. To\naddress these limitations, we propose a Role-Adaptive LLM-Driven Yoked\nnavigation algorithm RALLY. Specifically, we first develop an LLM-driven\nsemantic decision framework that uses structured natural language for efficient\nsemantic communication and collaborative reasoning. Afterward, we introduce a\ndynamic role-heterogeneity mechanism for adaptive role switching and\npersonalized decision-making. Furthermore, we propose a Role-value Mixing\nNetwork (RMIX)-based assignment strategy that integrates LLM offline priors\nwith MARL online policies to enable semi-offline training of role selection\nstrategies. Experiments in the Multi-Agent Particle Environment (MPE)\nenvironment and a Software-In-The-Loop (SITL) platform demonstrate that RALLY\noutperforms conventional approaches in terms of task coverage, convergence\nspeed, and generalization, highlighting its strong potential for collaborative\nnavigation in agentic multi-UAV systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01378v1", "categories": ["cs.MA", "cs.AI", "cs.RO"], "cate": "cs.MA", "url": "http://arxiv.org/abs/2507.01378v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "RALLY：角色自适应LLM驱动的系留导航用于代理无人机蜂群", "tldr": "RALLY提出了一种结合LLM语义推理和MARL在线学习的无人机蜂群导航算法，通过语义决策框架、动态角色异质性和RMIX分配策略，解决了传统MARL和LLM方法的局限性，提高了任务覆盖、收敛速度和泛化能力。", "motivation": "传统多智能体强化学习（MARL）方法在无人机蜂群控制中存在语义鸿沟、同质角色结构僵化、泛化能力差和任务可扩展性有限的问题。基于大语言模型（LLM）的控制框架虽然具有强大的语义推理能力，但由于缺乏在线学习和过度依赖静态先验知识，导致探索效率低，降低了个体潜力和整体系统性能。", "method": "提出了一种名为RALLY的角色自适应LLM驱动的系留导航算法。具体方法包括：1. 开发一个LLM驱动的语义决策框架，利用结构化自然语言进行高效语义通信和协作推理。2. 引入动态角色异质性机制，实现自适应角色切换和个性化决策。3. 提出一个基于角色价值混合网络（RMIX）的分配策略，将LLM的离线先验知识与MARL的在线策略相结合，实现角色选择策略的半离线训练。", "result": "RALLY在Multi-Agent Particle Environment (MPE) 环境和软件在环 (SITL) 平台上进行的实验表明，它在任务覆盖、收敛速度和泛化能力方面优于传统方法。", "conclusion": "RALLY算法在代理多无人机系统的协作导航中展现出强大的潜力，有效解决了传统MARL和现有LLM控制框架的局限性。", "translation": "智能控制无人机（UAV）蜂群已成为一个关键的研究焦点，它通常要求蜂群在有效导航的同时避开障碍物并实现对多个任务目标的连续覆盖。尽管传统的多智能体强化学习（MARL）方法提供了动态适应性，但它们受到数值通信中语义鸿沟和同质角色结构僵化的阻碍，导致泛化能力差和任务可扩展性有限。最近基于大语言模型（LLM）的控制框架的进展通过利用广泛的先验知识展示了强大的语义推理能力。然而，由于缺乏在线学习和过度依赖静态先验知识，这些工作在有效探索方面常常遇到困难，导致个体潜力降低和整体系统性能下降。为了解决这些局限性，我们提出了一种角色自适应LLM驱动的系留导航算法RALLY。具体来说，我们首先开发了一个LLM驱动的语义决策框架，利用结构化自然语言进行高效语义通信和协作推理。然后，我们引入了一个动态角色异质性机制，用于自适应角色切换和个性化决策。此外，我们提出了一个基于角色价值混合网络（RMIX）的分配策略，该策略将LLM离线先验知识与MARL在线策略相结合，以实现角色选择策略的半离线训练。在多智能体粒子环境（MPE）环境和软件在环（SITL）平台上的实验表明，RALLY在任务覆盖、收敛速度和泛化能力方面优于传统方法，突显了其在代理多无人机系统中协作导航的强大潜力。", "summary": "本文提出了一种名为RALLY的无人机蜂群导航算法，旨在解决传统多智能体强化学习（MARL）和现有大语言模型（LLM）控制框架的局限性。RALLY通过引入LLM驱动的语义决策框架实现高效语义通信和协作推理，通过动态角色异质性机制实现自适应角色切换和个性化决策，并通过RMIX网络将LLM离线先验与MARL在线策略结合进行角色选择。实验证明，RALLY在任务覆盖、收敛速度和泛化能力方面优于传统方法，展现了其在多无人机系统协作导航中的潜力。", "keywords": "无人机蜂群, 大语言模型, 多智能体强化学习, 角色自适应, 协作导航", "comments": "RALLY的创新性在于其成功地弥合了LLM的强大语义推理能力与MARL的在线学习能力之间的鸿沟。通过引入角色自适应机制和半离线训练的角色选择策略，该方法有效解决了现有方法在泛化能力和探索效率上的不足。这种结合有望为复杂多智能体系统的控制带来新的范式，尤其是在需要灵活适应和语义理解的无人机蜂群任务中。"}}
{"id": "2507.01433", "title": "Reduced Efficiency in the Right Fronto-Parietal Attentional Network During Distractor Suppression in Mild Cognitive Impairment", "authors": ["Jatupong Oboun", "Piyanon Charoenpoonpanich", "Anna Raksapatcharawong", "Chaipat Chunharas", "Itthi Chatnuntawech", "Chainarong Amornbunchornvej", "Sirawaj Itthipuripat"], "summary": "Mild Cognitive Impairment (MCI) is a critical transitional stage between\nnormal cognitive aging and dementia, making its early detection essential. This\nstudy investigates the neural mechanisms of distractor suppression in MCI\npatients using EEG and behavioral data during an attention-cueing Eriksen\nflanker task. A cohort of 56 MCIs and 26 healthy controls (HCs) performed tasks\nwith congruent and incongruent stimuli of varying saliency levels. During these\ntasks, EEG data were analyzed for alpha band coherence's functional\nconnectivity, focusing on Global Efficiency (GE), while Reaction Time (RT) and\nHit Rate (HR) were also collected.\n  Our findings reveal significant interactions between congruency, saliency,\nand cognitive status on GE, RT, and HR. In HCs, congruent conditions resulted\nin higher GE (p = 0.0114, multivariate t-distribution correction, MVT), faster\nRTs (p < 0.0001, MVT), and higher HRs (p < 0.0001, MVT) compared to incongruent\nconditions. HCs also showed increased GE in salient conditions for incongruent\ntrials (p = 0.0406, MVT). MCIs exhibited benefits from congruent conditions\nwith shorter RTs and higher HRs (both p < 0.0001, MVT) compared to incongruent\nconditions but showed reduced adaptability in GE, with no significant GE\ndifferences between conditions.\n  These results highlight the potential of alpha band coherence and GE as early\nmarkers for cognitive impairment. By integrating GE, RT, and HR, this study\nprovides insights into the interplay between neural efficiency, processing\nspeed, and task accuracy. This approach offers valuable insights into cognitive\nload management and interference effects, indicating benefits for interventions\naimed at improving attentional control and processing speed in MCIs.", "comment": "First Draft", "pdf_url": "http://arxiv.org/pdf/2507.01433v1", "categories": ["q-bio.NC", "cs.SI", "stat.AP", "62, 92", "G.3; J.3"], "cate": "q-bio.NC", "url": "http://arxiv.org/abs/2507.01433v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "轻度认知障碍患者分心物抑制过程中右侧额顶叶注意网络效率降低", "tldr": "研究发现轻度认知障碍患者在分心物抑制过程中右侧额顶叶注意网络的效率降低，这可能作为早期认知障碍的生物标志物。", "motivation": "早期检测轻度认知障碍（MCI）至关重要，因为它是正常认知老化与痴呆之间的关键过渡阶段。本研究旨在调查MCI患者分心物抑制的神经机制。", "method": "研究使用脑电图（EEG）和行为数据，通过一项注意力线索Eriksen Flanker任务，对56名MCI患者和26名健康对照组（HCs）进行研究。任务包含不同显著性水平的一致和不一致刺激。EEG数据分析侧重于Alpha波段相干性的功能连接（全局效率GE），同时收集反应时间（RT）和命中率（HR）。", "result": "结果显示，一致性、显著性和认知状态对GE、RT和HR有显著交互作用。健康对照组在一致条件下表现出更高的GE、更快的RT和更高的HR，并在不一致且显著的条件下GE增加。MCI患者在一致条件下RT更短、HR更高，但GE适应性降低，不同条件下GE无显著差异。", "conclusion": "Alpha波段相干性和全局效率（GE）可能作为认知障碍的早期标志物。整合GE、RT和HR，本研究揭示了神经效率、处理速度和任务准确性之间的相互作用，为改善MCI患者的注意力控制和处理速度干预提供了有价值的见解。", "translation": "轻度认知障碍（MCI）是正常认知老化与痴呆之间的关键过渡阶段，因此早期检测至关重要。本研究利用脑电图（EEG）和行为数据，通过一项注意力线索Eriksen Flanker任务，调查了MCI患者分心物抑制的神经机制。一项由56名MCI患者和26名健康对照组（HCs）组成的队列在不同显著性水平的一致和不一致刺激下执行任务。在这些任务中，分析了EEG数据的Alpha波段相干性功能连接，重点关注全局效率（GE），同时还收集了反应时间（RT）和命中率（HR）。\n我们的研究结果揭示了一致性、显著性和认知状态对GE、RT和HR之间存在显著的交互作用。在健康对照组中，与不一致条件相比，一致条件导致更高的GE（p = 0.0114，多元t分布校正，MVT）、更快的RT（p < 0.0001，MVT）和更高的HR（p < 0.0001，MVT）。健康对照组在不一致的显著条件下也显示出GE增加（p = 0.0406，MVT）。MCI患者在一致条件下表现出RT更短、HR更高（两者p < 0.0001，MVT），但GE适应性降低，不同条件下GE无显著差异。\n这些结果强调了Alpha波段相干性和GE作为认知障碍早期标志物的潜力。通过整合GE、RT和HR，本研究深入揭示了神经效率、处理速度和任务准确性之间的相互作用。这种方法为认知负荷管理和干扰效应提供了有价值的见解，表明对旨在改善MCI患者注意力控制和处理速度的干预措施有益。", "summary": "本研究通过Eriksen Flanker任务结合EEG和行为数据，探讨了轻度认知障碍（MCI）患者在分心物抑制中的神经机制。结果显示，MCI患者在右侧额顶叶注意网络的全局效率（GE）适应性降低，这与健康对照组形成对比。研究强调了Alpha波段GE作为认知障碍早期标志物的潜力，并为MCI的干预提供了理论基础。", "keywords": "轻度认知障碍, 注意力网络, 分心物抑制, 脑电图, 全局效率", "comments": "这篇论文通过结合EEG的全局效率（GE）指标与行为数据，为MCI患者的注意力网络功能障碍提供了神经生理学证据。其创新之处在于提出Alpha波段GE可能作为早期诊断MCI的生物标志物。研究结果对早期干预和改善MCI患者的认知功能具有重要意义，但样本量相对较小，未来的研究可以进一步扩大样本并探索更广泛的认知域。"}}
{"id": "2507.01230", "title": "Numerical Techniques for the Maximum Likelihood Toeplitz Covariance Matrix Estimation: Part I. Symmetric Toeplitz Matrices", "authors": ["Yuri Abramovich", "Victor Abramovich", "Tanit Pongsiri"], "summary": "In several applications, one must estimate a real-valued (symmetric) Toeplitz\ncovariance matrix, typically shifted by the conjugated diagonal matrices of\nphase progression and phase \"calibration\" errors. Unlike the Hermitian Toeplitz\ncovariance matrices, these symmetric matrices have a unique potential\ncapability of being estimated regardless of these beam-steering phase\nprogression and/or phase \"calibration\" errors. This unique capability is the\nprimary motivation of this paper.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01230v1", "categories": ["eess.SP", "cs.IT", "math.IT"], "cate": "eess.SP", "url": "http://arxiv.org/abs/2507.01230v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "极大似然Toeplitz协方差矩阵估计的数值技术：第一部分. 对称Toeplitz矩阵", "tldr": "本文的动机是探索对称Toeplitz协方差矩阵的独特能力，即无论是否存在波束引导相位误差，它们都可以被估计。", "motivation": "本文的主要动机是：与Hermitian Toeplitz协方差矩阵不同，实值（对称）Toeplitz协方差矩阵具有一种独特的潜在能力，即无论是否存在波束引导相位进程和/或相位“校准”误差，它们都可以被估计。", "method": "Not mentioned in abstract", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "在一些应用中，需要估计一个实值（对称）Toeplitz协方差矩阵，该矩阵通常被相位进程和相位“校准”误差的共轭对角矩阵平移。与Hermitian Toeplitz协方差矩阵不同，这些对称矩阵具有一种独特的潜在能力，即无论是否存在这些波束引导相位进程和/或相位“校准”误差，它们都可以被估计。这种独特的能力是本文的主要动机。", "summary": "本文探讨了实值对称Toeplitz协方差矩阵的估计问题。其核心动机在于，与Hermitian Toeplitz矩阵不同，对称Toeplitz矩阵具有一种独特的能力，即其估计不受波束引导相位进程或相位“校准”误差的影响。", "keywords": "对称Toeplitz矩阵, 协方差矩阵估计, 相位误差, 极大似然", "comments": "该论文着重于对称Toeplitz矩阵的一个独特属性，即在存在相位误差的情况下仍可进行估计。这可能为某些应用中的协方差矩阵估计提供新的视角或更鲁棒的方法。然而，摘要中并未详细说明所采用的“数值技术”，这使得我们无法评估其方法的创新性或复杂性。"}}
{"id": "2507.01330", "title": "On Securing Berrut Approximated Coded Computing Through Discrete Cosine Transforms", "authors": ["Rimpi Borah", "J. Harshan"], "summary": "Coded computing is a reliable and fault-tolerant mechanism for implementing\nlarge computing tasks over a distributed set of worker nodes. While a majority\nof coded computing frameworks address accurate computation of the target\nfunctions, they are restricted to computing multivariate polynomial functions.\nTo generalize these computing platforms to non-polynomial target functions,\nJahani-Nezhad and Maddah-Ali recently proposed Berrut Approximated Coded\ncomputing (BACC), which was proven fault-tolerant against stragglers albiet\nwith tolerable approximation errors on the target functions. Despite these\nbenefits, there is no formal study on the security of BACC against worker nodes\nwhich report erroneous computations. To fill this research gap, we use a\ncoding-theoretic approach to propose Secure Berrut Approximated Coded Computing\n(SBACC), which is resilient to stragglers and also robust to the presence of\nsuch untrusted worker nodes. One of the highlights of SBACC is the new choice\nof evaluation points for distributed computation which makes the well-known\nDiscrete Cosine Transform (DCT) codes amenable to error detection and\ncorrection. To validate the new choice of evaluation points, first, we derive\nbounds on the accuracy of SBACC in the absence of untrusted worker nodes.\nSubsequently, to handle the presence of untrusted worker nodes, we derive\nbounds on the accuracy of SBACC and show that interesting optimization problems\ncan be formulated to study the trade-off between the error correcting\ncapability of the DCT codes and the accuracy of the target computation.", "comment": "To appear in the proceedings of IEEE Information Theory Workshop\n  (ITW) 2025", "pdf_url": "http://arxiv.org/pdf/2507.01330v1", "categories": ["cs.IT", "math.IT"], "cate": "cs.IT", "url": "http://arxiv.org/abs/2507.01330v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于离散余弦变换的安全Berrut近似编码计算", "tldr": "本文提出了安全Berrut近似编码计算（SBACC），通过引入新的评估点和利用离散余弦变换（DCT）码，解决了Berrut近似编码计算（BACC）在面对恶意工作节点时的安全性问题，并分析了其准确性和纠错能力。", "motivation": "现有的编码计算框架多限于多元多项式函数，而Berrut近似编码计算（BACC）虽能处理非多项式函数并容忍掉线节点，但缺乏针对报告错误计算的恶意工作节点的正式安全研究。本文旨在填补这一研究空白。", "method": "本文采用编码理论方法，提出了安全Berrut近似编码计算（SBACC）。SBACC通过引入新的分布式计算评估点，使得离散余弦变换（DCT）码能够用于错误检测和纠正。研究首先在没有不受信任工作节点的情况下推导了SBACC的准确性界限，然后针对存在不受信任工作节点的情况，推导了SBACC的准确性界限，并展示了可以构建优化问题来研究DCT码的纠错能力与目标计算准确性之间的权衡。", "result": "SBACC被证明对掉线节点具有弹性，并且对存在不受信任的工作节点具有鲁棒性。通过引入新的评估点，使得DCT码适用于错误检测和纠正。研究推导了在有和没有不受信任工作节点情况下的SBACC准确性界限，并指出可以构建优化问题来研究DCT码纠错能力与计算准确性之间的权衡。", "conclusion": "本文成功提出了安全Berrut近似编码计算（SBACC），解决了BACC在面对恶意工作节点时的安全问题，并通过利用DCT码和新的评估点实现了对掉线节点和恶意节点的鲁棒性，同时分析了其准确性，并为进一步研究纠错能力与准确性之间的权衡提供了方向。", "translation": "编码计算是一种可靠且容错的机制，用于在分布式工作节点集合上实现大型计算任务。虽然大多数编码计算框架解决了目标函数的精确计算问题，但它们仅限于计算多元多项式函数。为了将这些计算平台推广到非多项式目标函数，Jahani-Nezhad和Maddah-Ali最近提出了Berrut近似编码计算（BACC），该方法被证明对掉线节点具有容错性，尽管对目标函数存在可容忍的近似误差。尽管有这些优点，但目前还没有针对报告错误计算的工作节点对BACC安全性进行正式研究。为了填补这一研究空白，我们采用编码理论方法提出了安全Berrut近似编码计算（SBACC），该方法对掉线节点具有弹性，并且对存在此类不受信任的工作节点也具有鲁棒性。SBACC的亮点之一是为分布式计算选择了新的评估点，这使得众所周知的离散余弦变换（DCT）码适用于错误检测和纠正。为了验证新选择的评估点，首先，我们在没有不受信任工作节点的情况下推导了SBACC的准确性界限。随后，为了处理存在不受信任工作节点的情况，我们推导了SBACC的准确性界限，并表明可以构建有趣的优化问题来研究DCT码的纠错能力与目标计算准确性之间的权衡。", "summary": "本文提出了安全Berrut近似编码计算（SBACC），旨在解决Berrut近似编码计算（BACC）在面对恶意工作节点时的安全性问题。SBACC通过引入新的评估点，使得离散余弦变换（DCT）码能够用于错误检测和纠正，从而对掉线节点和不受信任的恶意节点都具有鲁棒性。研究推导了SBACC在不同情况下的准确性界限，并指出可以进一步研究DCT码纠错能力与计算准确性之间的权衡。", "keywords": "编码计算, Berrut近似, 离散余弦变换, 安全性, 容错", "comments": "该论文创新性地将离散余弦变换（DCT）码引入到Berrut近似编码计算中，以解决其安全性问题，特别是在存在恶意工作节点的情况下。通过引入新的评估点，巧妙地将DCT码的纠错能力与编码计算相结合，拓展了编码计算在非多项式函数和对抗性环境下的应用。这项工作对于提升分布式计算的鲁棒性和安全性具有重要意义，尤其是在数据完整性和计算可靠性至关重要的场景中。"}}
{"id": "2507.01224", "title": "FLARE: A Dataflow-Aware and Scalable Hardware Architecture for Neural-Hybrid Scientific Lossy Compression", "authors": ["Wenqi Jia", "Ying Huang", "Jian Xu", "Zhewen Hu", "Sian Jin", "Jiannan Tian", "Yuede Ji", "Miao Yin"], "summary": "Scientific simulation leveraging high-performance computing (HPC) systems is\ncrucial for modeling complex systems and phenomena in fields such as\nastrophysics, climate science, and fluid dynamics, generating massive datasets\nthat often reach petabyte to exabyte scales. However, managing these vast data\nvolumes introduces significant I/O and network bottlenecks, limiting practical\nperformance and scalability. While cutting-edge lossy compression frameworks\npowered by deep neural networks (DNNs) have demonstrated superior compression\nratios by capturing complex data correlations, their integration into HPC\nworkflows poses substantial challenges due to the hybrid non-neural and neural\ncomputation patterns, causing excessive memory access overhead, large\nsequential stalls, and limited adaptability to varying data sizes and workloads\nin existing hardware platforms. To overcome these challenges and push the limit\nof high-performance scientific computing, we for the first time propose FLARE,\na dataflow-aware and scalable hardware architecture for neural-hybrid\nscientific lossy compression. FLARE minimizes off-chip data access, reduces\nbubble overhead through efficient dataflow, and adopts a modular design that\nprovides both scalability and flexibility, significantly enhancing throughput\nand energy efficiency on modern HPC systems. Particularly, the proposed FLARE\nachieves runtime speedups ranging from $3.50 \\times$ to $96.07 \\times$, and\nenergy efficiency improvements ranging from $24.51 \\times$ to $520.68 \\times$,\nacross various datasets and hardware platforms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01224v1", "categories": ["cs.DC"], "cate": "cs.DC", "url": "http://arxiv.org/abs/2507.01224v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "FLARE：一种数据流感知且可扩展的神经混合科学有损压缩硬件架构", "tldr": "FLARE是一种新的硬件架构，用于加速神经混合科学有损压缩，显著提高了性能和能效，解决了HPC数据瓶颈问题。", "motivation": "高性能计算（HPC）系统中的科学模拟产生海量数据集，导致I/O和网络瓶颈。现有基于深度神经网络（DNN）的有损压缩方案虽能提供高压缩比，但在集成到HPC工作流时面临混合计算模式、高内存访问开销、大量串行停顿以及对不同数据大小和工作负载适应性有限等挑战。", "method": "本文首次提出了FLARE，一种数据流感知且可扩展的硬件架构，专为神经混合科学有损压缩设计。FLARE通过最小化片外数据访问、通过高效数据流减少气泡开销，并采用模块化设计来提供可扩展性和灵活性，从而提升吞吐量和能效。", "result": "所提出的FLARE在各种数据集和硬件平台上实现了3.50倍至96.07倍的运行时加速，以及24.51倍至520.68倍的能效提升。", "conclusion": "FLARE成功克服了现有硬件平台在神经混合科学有损压缩方面的挑战，显著提升了现代HPC系统上的吞吐量和能效，从而推动了高性能科学计算的极限。", "translation": "利用高性能计算（HPC）系统进行科学模拟对于天体物理学、气候科学和流体动力学等领域中复杂系统和现象的建模至关重要，这些模拟生成的数据集通常达到PB到EB级别。然而，管理这些庞大的数据量引入了显著的I/O和网络瓶颈，限制了实际性能和可扩展性。尽管由深度神经网络（DNN）驱动的尖端有损压缩框架通过捕获复杂数据相关性展示了卓越的压缩比，但由于混合的非神经网络和神经网络计算模式，其集成到HPC工作流中带来了巨大挑战，导致过高的内存访问开销、大量串行停顿以及对现有硬件平台上不同数据大小和工作负载的适应性有限。为了克服这些挑战并推动高性能科学计算的极限，我们首次提出了FLARE，一种数据流感知且可扩展的神经混合科学有损压缩硬件架构。FLARE最小化了片外数据访问，通过高效数据流减少了气泡开销，并采用了模块化设计，提供了可扩展性和灵活性，显著提高了现代HPC系统上的吞吐量和能效。特别是，所提出的FLARE在各种数据集和硬件平台上实现了3.50倍至96.07倍的运行时加速，以及24.51倍至520.68倍的能效提升。", "summary": "本论文提出了一种名为FLARE的硬件架构，旨在解决高性能计算（HPC）中科学模拟生成海量数据所带来的I/O和网络瓶颈问题。针对现有DNN驱动的有损压缩在HPC集成中遇到的内存开销和效率低下等挑战，FLARE采用数据流感知和模块化设计，优化了数据访问并提高了灵活性。实验结果表明，FLARE显著提升了吞吐量和能效，实现了高达96.07倍的运行时加速和520.68倍的能效提升。", "keywords": "FLARE, 硬件架构, 神经混合压缩, 科学数据, HPC", "comments": "创新点在于首次提出了一种专门针对神经混合科学有损压缩的硬件架构，通过数据流感知和模块化设计有效解决了现有方案在HPC集成中的效率问题。其重要性在于为处理科学大数据提供了高性能、高能效的压缩解决方案，对推动高性能科学计算具有重要意义。抽象中未提及局限性。"}}
{"id": "2507.01061", "title": "Epitome: Pioneering an Experimental Platform for AI-Social Science Integration", "authors": ["Jingjing Qu", "Kejia Hu", "Jun Zhu", "Wenhao Li", "Teng Wang", "Zhiyun Chen", "Yulei Ye", "Chaochao Lu", "Aimin Zhou", "Xiangfeng Wang", "James Evan"], "summary": "The integration of Large Language Models (LLMs) into social science\nexperiments represents a transformative approach to understanding human-AI\ninteractions and their societal impacts. We introduce Epitome, the world's\nfirst open experimental platform dedicated to the deep integration of\nartificial intelligence and social science. Rooted in theoretical foundations\nfrom management, communication studies, sociology, psychology, and ethics,\nEpitome focuses on the interactive impacts of AI on individuals, organizations,\nand society during its real-world deployment. It constructs a theoretical\nsupport system through cross-disciplinary experiments. The platform offers a\none-stop comprehensive experimental solution spanning \"foundation\nmodels-complex application development-user feedback\" through seven core\nmodules, while embedding the classical \"control-comparison-comparative causal\nlogic\" of social science experiments into multilevel human-computer interaction\nenvironments, including dialogues, group chats, and multi-agent virtual\nscenarios. With its canvas-style, user-friendly interface, Epitome enables\nresearchers to easily design and run complex experimental scenarios,\nfacilitating systematic investigations into the social impacts of AI and\nexploration of integrated solutions.To demonstrate its capabilities, we\nreplicated three seminal social science experiments involving LLMs, showcasing\nEpitome's potential to streamline complex experimental designs and produce\nrobust results, suitable for publishing in the top selective journals. Our\nfindings highlight the platform's utility in enhancing the efficiency and\nquality of human-AI interactions, providing valuable insights into the societal\nimplications of AI technologies. Epitome thus offers a powerful tool for\nadvancing interdisciplinary research at the intersection of AI and social\nscience, with potential applications in policy-making, ...", "comment": "18 pages, 5figures", "pdf_url": "http://arxiv.org/pdf/2507.01061v1", "categories": ["cs.CY", "cs.AI", "cs.HC"], "cate": "cs.CY", "url": "http://arxiv.org/abs/2507.01061v1", "date": "2025-06-30", "updated": "2025-06-30", "AI": {"title_translation": "Epitome：开创AI与社会科学融合的实验平台", "tldr": "Epitome是一个开创性的开放实验平台，旨在深度整合AI与社会科学，通过其多功能模块和用户友好的界面，简化复杂实验设计，以研究AI的社会影响并促进跨学科研究。", "motivation": "大型语言模型（LLMs）融入社会科学实验代表了一种理解人机交互及其社会影响的变革性方法。为了深入探索AI与社会科学的融合，并研究AI在实际部署中对个体、组织和社会的影响，需要一个专门的平台。", "method": "本文介绍了Epitome，这是世界上首个致力于AI与社会科学深度融合的开放实验平台。该平台根植于管理学、传播学、社会学、心理学和伦理学的理论基础，通过七个核心模块提供“基础模型-复杂应用开发-用户反馈”的一站式综合实验解决方案。它将社会科学实验的经典“控制-比较-比较因果逻辑”嵌入到对话、群聊和多智能体虚拟场景等多层次人机交互环境中。Epitome拥有画布式的用户友好界面，使研究人员能够轻松设计和运行复杂的实验场景。", "result": "为了展示其能力，Epitome复制了三个涉及大型语言模型的开创性社会科学实验，结果表明该平台能够简化复杂的实验设计并产生可靠的结果，适合在顶级期刊发表。研究发现强调了该平台在提高人机交互效率和质量方面的实用性。", "conclusion": "Epitome提供了一个强大的工具，用于推进AI与社会科学交叉领域的跨学科研究，并在政策制定等方面具有潜在应用。", "translation": "大型语言模型（LLMs）融入社会科学实验代表了一种理解人机交互及其社会影响的变革性方法。我们介绍了Epitome，世界上首个致力于人工智能与社会科学深度融合的开放实验平台。Epitome植根于管理学、传播学、社会学、心理学和伦理学的理论基础，专注于AI在实际部署中对个体、组织和社会产生的互动影响。它通过跨学科实验构建了一个理论支持系统。该平台通过七个核心模块提供了一个涵盖“基础模型-复杂应用开发-用户反馈”的一站式综合实验解决方案，同时将社会科学实验经典的“控制-比较-比较因果逻辑”嵌入到多层次人机交互环境，包括对话、群聊和多智能体虚拟场景。凭借其画布式、用户友好的界面，Epitome使研究人员能够轻松设计和运行复杂的实验场景，促进对AI社会影响的系统性研究和集成解决方案的探索。为了展示其能力，我们复制了三个涉及LLMs的开创性社会科学实验，展示了Epitome简化复杂实验设计和产生可靠结果的潜力，适合在顶级精选期刊发表。我们的研究结果突出了该平台在提高人机交互效率和质量方面的实用性，为AI技术的社会影响提供了宝贵见解。因此，Epitome为推进AI与社会科学交叉领域的跨学科研究提供了强大的工具，在政策制定等方面具有潜在应用。", "summary": "Epitome是一个开创性的开放实验平台，旨在深度整合人工智能与社会科学，以系统研究AI对个体、组织和社会的影响。该平台基于多学科理论，提供七个核心模块，支持从基础模型到用户反馈的全流程实验，并能将经典的社会科学实验逻辑嵌入多种人机交互环境。Epitome的用户友好界面简化了复杂实验设计，并通过成功复制三个LLMs相关实验，证明了其生成高质量、可靠结果的能力，从而为推进AI与社会科学的交叉研究提供了强大工具。", "keywords": "AI-社会科学整合, 实验平台, 大型语言模型, 人机交互, 社会影响", "comments": "该论文的创新点在于提出了Epitome，一个专门用于AI与社会科学深度融合的开放实验平台，填补了该领域工具的空白。其重要性体现在它提供了一个系统化的框架和用户友好的界面，极大地简化了复杂的人机交互实验设计和执行，有望加速对AI社会影响的理解和跨学科研究的发展。"}}
{"id": "2507.01309", "title": "SD-Acc: Accelerating Stable Diffusion through Phase-aware Sampling and Hardware Co-Optimizations", "authors": ["Zhican Wang", "Guanghui He", "Hongxiang Fan"], "summary": "The emergence of diffusion models has significantly advanced generative AI,\nimproving the quality, realism, and creativity of image and video generation.\nAmong them, Stable Diffusion (StableDiff) stands out as a key model for\ntext-to-image generation and a foundation for next-generation multi-modal\nalgorithms. However, its high computational and memory demands hinder inference\nspeed and energy efficiency. To address these challenges, we identify three\ncore issues: (1) intensive and often redundant computations, (2) heterogeneous\noperations involving convolutions and attention mechanisms, and (3) diverse\nweight and activation sizes.\n  We present SD-Acc, a novel algorithm and hardware co-optimization framework.\nAt the algorithm level, we observe that high-level features in certain\ndenoising phases show significant similarity, enabling approximate computation.\nLeveraging this, we propose an adaptive, phase-aware sampling strategy that\nreduces compute and memory loads. This framework automatically balances image\nquality and complexity based on the StableDiff model and user requirements. At\nthe hardware level, we design an address-centric dataflow to efficiently handle\nheterogeneous operations within a simple systolic array. We address the\nbottleneck of nonlinear functions via a two-stage streaming architecture and a\nreconfigurable vector processing unit. Additionally, we implement adaptive\ndataflow optimizations by combining dynamic reuse and operator fusion tailored\nto StableDiff workloads, significantly reducing memory access. Across multiple\nStableDiff models, our method achieves up to a 3x reduction in computational\ndemand without compromising image quality. Combined with our optimized hardware\naccelerator, SD-Acc delivers higher speed and energy efficiency than\ntraditional CPU and GPU implementations.", "comment": "Under Review", "pdf_url": "http://arxiv.org/pdf/2507.01309v1", "categories": ["cs.AR"], "cate": "cs.AR", "url": "http://arxiv.org/abs/2507.01309v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "SD-Acc：通过阶段感知采样和硬件协同优化加速稳定扩散", "tldr": "SD-Acc通过结合阶段感知采样算法和硬件协同优化，显著提升了Stable Diffusion模型的推理速度和能效，同时保持了图像质量。", "motivation": "扩散模型（特别是Stable Diffusion）在图像生成方面表现出色，但其高计算和内存需求限制了推理速度和能效。主要挑战包括：计算冗余、操作异构性（卷积和注意力机制）以及权重和激活尺寸多样性。", "method": "本文提出了SD-Acc，一个新颖的算法和硬件协同优化框架。在算法层面，通过观察到某些去噪阶段的高级特征相似性，提出了自适应的阶段感知采样策略，以减少计算和内存负载。该策略能根据模型和用户需求自动平衡图像质量和复杂性。在硬件层面，设计了以地址为中心的数据流来处理异构操作，并通过两阶段流式架构和可重构向量处理单元解决了非线性函数瓶颈。此外，通过结合动态复用和操作符融合实现了自适应数据流优化，以减少内存访问。", "result": "在多个Stable Diffusion模型上，算法层面实现了高达3倍的计算需求减少，且不损害图像质量。结合优化的硬件加速器，SD-Acc比传统的CPU和GPU实现提供了更高的速度和能效。", "conclusion": "SD-Acc通过算法和硬件的协同优化，成功解决了Stable Diffusion模型推理速度和能效的瓶颈，实现了显著的性能提升。", "translation": "扩散模型的出现极大地推动了生成式AI的发展，提升了图像和视频生成的质量、真实感和创造力。其中，Stable Diffusion（StableDiff）作为文本到图像生成的关键模型和下一代多模态算法的基础脱颖而出。然而，其高计算和内存需求阻碍了推理速度和能效。为了解决这些挑战，我们确定了三个核心问题：(1) 密集且通常冗余的计算，(2) 涉及卷积和注意力机制的异构操作，以及 (3) 多样化的权重和激活大小。\n我们提出了SD-Acc，一个新颖的算法和硬件协同优化框架。在算法层面，我们观察到某些去噪阶段的高级特征显示出显著的相似性，从而可以进行近似计算。利用这一点，我们提出了一种自适应的、阶段感知的采样策略，以减少计算和内存负载。该框架根据StableDiff模型和用户需求自动平衡图像质量和复杂性。在硬件层面，我们设计了一种以地址为中心的数据流，以在简单的脉动阵列中高效处理异构操作。我们通过两阶段流式架构和可重构向量处理单元解决了非线性函数的瓶颈。此外，我们通过结合动态复用和操作符融合实现了自适应数据流优化，专为StableDiff工作负载量身定制，显著减少了内存访问。在多个StableDiff模型上，我们的方法在不损害图像质量的情况下，实现了高达3倍的计算需求减少。结合我们优化的硬件加速器，SD-Acc比传统的CPU和GPU实现提供了更高的速度和能效。", "summary": "SD-Acc是一个旨在加速Stable Diffusion模型推理的框架，它结合了算法和硬件层面的优化。在算法上，通过提出一种阶段感知采样策略，利用去噪阶段的特征相似性来减少计算和内存冗余。在硬件上，设计了高效处理异构操作的数据流、解决非线性函数瓶颈的架构以及减少内存访问的自适应数据流优化。这些协同优化使得SD-Acc在保持图像质量的同时，显著提升了Stable Diffusion的推理速度和能效。", "keywords": "Stable Diffusion, 加速, 硬件协同优化, 阶段感知采样, 能效", "comments": "本文的创新点在于提出了算法和硬件协同优化的方法来加速Stable Diffusion。通过对模型行为的深入洞察（阶段特征相似性）来优化算法，并针对性地设计硬件架构，实现了显著的性能提升。这种软硬件协同设计是提升复杂AI模型效率的有效途径。"}}
{"id": "2507.01074", "title": "MID-INFRARED (MIR) OCT-based inspection in industry", "authors": ["N. P. García-de-la-Puente", "Rocío del Amor", "Fernando García-Torres", "Niels Møller Israelsen", "Coraline Lapre", "Christian Rosenberg Petersen", "Ole Bang", "Dominik Brouczek", "Martin Schwentenwein", "Kevin Neumann", "Niels Benson", "Valery Naranjo"], "summary": "This paper aims to evaluate mid-infrared (MIR) Optical Coherence Tomography\n(OCT) systems as a tool to penetrate different materials and detect sub-surface\nirregularities. This is useful for monitoring production processes, allowing\nNon-Destructive Inspection Techniques of great value to the industry. In this\nexploratory study, several acquisitions are made on composite and ceramics to\nknow the capabilities of the system. In addition, it is assessed which\npreprocessing and AI-enhanced vision algorithms can be anomaly-detection\nmethodologies capable of detecting abnormal zones in the analyzed objects.\nLimitations and criteria for the selection of optimal parameters will be\ndiscussed, as well as strengths and weaknesses will be highlighted.", "comment": "Paper accepted at i-ESA 2024 12th International Conference on\n  Interoperability for Enterprise Systems and Applications 6 pages, 2 figures,\n  2 tables", "pdf_url": "http://arxiv.org/pdf/2507.01074v1", "categories": ["eess.IV", "cs.CV"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01074v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "中红外（MIR）OCT在工业中的检测应用", "tldr": "本文评估中红外OCT系统在工业无损检测中的应用，以穿透材料并检测亚表面缺陷，并探讨预处理和AI算法的结合。", "motivation": "评估中红外（MIR）光学相干断层扫描（OCT）系统作为一种工具，用于穿透不同材料并检测亚表面不规则性，这对于监测生产过程和实现对工业有巨大价值的无损检测技术非常有用。", "method": "进行探索性研究，对复合材料和陶瓷进行多次采集以了解系统能力。评估哪些预处理和AI增强视觉算法可以作为异常检测方法来检测分析对象中的异常区域。讨论选择最佳参数的局限性和标准，并强调优缺点。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "本文旨在评估中红外（MIR）光学相干断层扫描（OCT）系统作为一种工具，用于穿透不同材料并检测亚表面不规则性。这对于监测生产过程，实现对工业有巨大价值的无损检测技术非常有用。在这项探索性研究中，对复合材料和陶瓷进行了多次采集以了解系统能力。此外，还评估了哪些预处理和AI增强视觉算法可以作为异常检测方法，能够检测分析对象中的异常区域。本文将讨论选择最佳参数的局限性和标准，并强调其优点和缺点。", "summary": "本文旨在评估中红外（MIR）光学相干断层扫描（OCT）系统在工业无损检测中的应用，以穿透材料并检测亚表面缺陷。研究通过对复合材料和陶瓷进行数据采集，探索系统能力，并评估结合预处理和AI增强视觉算法的异常检测方法。文章还将讨论系统选择参数的局限性、标准、优点和缺点。", "keywords": "中红外OCT, 无损检测, 亚表面检测, 异常检测, 工业应用", "comments": "该研究旨在探索中红外OCT技术在工业无损检测领域的应用潜力，特别是其在穿透材料和检测亚表面缺陷方面的能力。结合AI增强视觉算法是其创新点，有望提升检测的准确性和自动化水平。然而，抽象中并未提及具体的实验结果，仅描述了研究方法和目标，因此无法评估其最终成效和实际局限性。"}}
{"id": "2507.01069", "title": "Agentic AI in Product Management: A Co-Evolutionary Model", "authors": ["Nishant A. Parikh"], "summary": "This study explores agentic AI's transformative role in product management,\nproposing a conceptual co-evolutionary framework to guide its integration\nacross the product lifecycle. Agentic AI, characterized by autonomy,\ngoal-driven behavior, and multi-agent collaboration, redefines product managers\n(PMs) as orchestrators of socio-technical ecosystems. Using systems theory,\nco-evolutionary theory, and human-AI interaction theory, the framework maps\nagentic AI capabilities in discovery, scoping, business case development,\ndevelopment, testing, and launch. An integrative review of 70+ sources,\nincluding case studies from leading tech firms, highlights PMs' evolving roles\nin AI orchestration, supervision, and strategic alignment. Findings emphasize\nmutual adaptation between PMs and AI, requiring skills in AI literacy,\ngovernance, and systems thinking. Addressing gaps in traditional frameworks,\nthis study provides a foundation for future research and practical\nimplementation to ensure responsible, effective agentic AI integration in\nsoftware organizations.", "comment": "41 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.01069v1", "categories": ["cs.CE", "cs.SE"], "cate": "cs.CE", "url": "http://arxiv.org/abs/2507.01069v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "产品管理中的智能体AI：一个协同演化模型", "tldr": "本研究提出一个协同演化框架，探讨智能体AI在产品管理中的变革作用，强调PM与AI的相互适应，并指出PM需具备AI素养、治理和系统思维能力。", "motivation": "本研究旨在探讨智能体AI在产品管理中的变革性作用，并提出了一个概念性的协同演化框架，以指导其在整个产品生命周期中的整合。", "method": "本研究提出了一个概念性的协同演化框架，并利用系统理论、协同演化理论和人机交互理论来映射智能体AI在产品生命周期各阶段的能力。研究方法还包括对70多个来源（包括领先科技公司的案例研究）的整合性回顾。", "result": "智能体AI将产品经理重新定义为社会技术生态系统的协调者。研究发现强调产品经理与AI之间的相互适应，这需要产品经理具备AI素养、治理和系统思维等技能。", "conclusion": "本研究通过弥补传统框架的不足，为未来的研究和实践提供了基础，以确保智能体AI在软件组织中负责任且有效地整合。", "translation": "本研究探讨了智能体AI在产品管理中的变革性作用，并提出了一个概念性的协同演化框架，以指导其在整个产品生命周期中的整合。智能体AI以其自主性、目标驱动行为和多智能体协作等特点，将产品经理（PMs）重新定义为社会技术生态系统的协调者。该框架利用系统理论、协同演化理论和人机交互理论，描绘了智能体AI在发现、范围界定、商业案例开发、开发、测试和发布等方面的能力。对70多个来源（包括领先科技公司的案例研究）的整合性回顾强调了产品经理在AI编排、监督和战略对齐方面不断演变的角色。研究结果强调了产品经理与AI之间的相互适应，这需要产品经理具备AI素养、治理和系统思维等技能。本研究弥补了传统框架的不足，为未来的研究和实际实施奠定了基础，以确保智能体AI在软件组织中负责任且有效地整合。", "summary": "本研究提出了一个概念性的协同演化框架，旨在指导智能体AI在产品管理整个生命周期中的整合。通过整合系统理论、协同演化理论和人机交互理论，并回顾了70多个来源，研究揭示了智能体AI如何将产品经理的角色转变为社会技术生态系统的协调者。研究强调了产品经理与AI之间相互适应的重要性，并指出产品经理需要发展AI素养、治理和系统思维等关键技能，以实现智能体AI在软件组织中负责任且有效的应用。", "keywords": "智能体AI, 产品管理, 协同演化模型, 人机协作, 产品经理角色转变", "comments": "这篇论文创新性地提出了一个协同演化模型来指导智能体AI在产品管理中的整合，超越了传统框架的局限性。其重要性在于强调了人机协作中“相互适应”的关键理念，并为产品经理的角色转变提供了理论和实践指导，对未来AI时代的产品管理实践具有重要指导意义。"}}
{"id": "2507.01173", "title": "An Adaptive Estimation Approach based on Fisher Information to Overcome the Challenges of LFP Battery SOC Estimation", "authors": ["Junzhe Shi", "Shida Jiang", "Shengyu Tao", "Jaewong Lee", "Manashita Borah", "Scott Moura"], "summary": "Robust and Real-time State of Charge (SOC) estimation is essential for\nLithium Iron Phosphate (LFP) batteries, which are widely used in electric\nvehicles (EVs) and energy storage systems due to safety and longevity. However,\nthe flat Open Circuit Voltage (OCV)-SOC curve makes this task particularly\nchallenging. This challenge is complicated by hysteresis effects, and\nreal-world conditions such as current bias, voltage quantization errors, and\ntemperature that must be considered in the battery management system use. In\nthis paper, we proposed an adaptive estimation approach to overcome the\nchallenges of LFPSOC estimation. Specifically, the method uses an adaptive\nfisher information fusion strategy that adaptively combines the SOC estimation\nfrom two different models, which are Coulomb counting and equivalent circuit\nmodel-based parameter identification. The effectiveness of this strategy is\nrationalized by the information richness excited by external cycling signals. A\n3D OCV-H-SOC map that captures the relationship between OCV, hysteresis, and\nSOC was proposed as the backbone, and can be generalizable to other widely\nadopted parameter-identification methods. Extensive validation under ideal and\nreal-world use scenarios, including SOC-OCV flat zones, current bias, voltage\nquantization errors, low temperatures, and insufficient current excitations,\nhave been performed using 4 driving profiles, i.e., the Orange County Transit\nBus Cycle, the California Unified Cycle, the US06 Drive Cycle, and the New York\nCity Cycle, where the results demonstrate superiority over the state-of-the-art\nunscented Kalman filter, long short-term memory networks and transformer in all\nvalidation cases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01173v1", "categories": ["eess.SY", "cs.SY"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01173v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "一种基于费舍尔信息的自适应估计方法，以克服磷酸铁锂电池荷电状态估计的挑战", "tldr": "本文提出了一种基于费舍尔信息融合的自适应方法，用于磷酸铁锂电池的荷电状态（SOC）估计，有效解决了平坦OCV-SOC曲线、滞后效应和实际工况等挑战，并在多种驾驶循环下表现出优于现有方法的性能。", "motivation": "磷酸铁锂（LFP）电池因其安全性高、寿命长而广泛应用于电动汽车和储能系统，但其平坦的开路电压（OCV）-荷电状态（SOC）曲线、滞后效应以及电流偏差、电压量化误差和温度等实际工况，使得鲁棒和实时SOC估计极具挑战性。", "method": "本文提出了一种自适应估计方法，通过自适应费舍尔信息融合策略，结合库仑计数和基于等效电路模型的参数识别两种不同模型的SOC估计。该方法以捕捉OCV、滞后和SOC之间关系的3D OCV-H-SOC图为基础，并利用外部循环信号激发的丰富信息来证明其有效性。", "result": "该方法在理想和实际使用场景（包括SOC-OCV平坦区、电流偏差、电压量化误差、低温和电流激励不足）下，使用4种驾驶循环（Orange County Transit Bus Cycle, California Unified Cycle, US06 Drive Cycle, New York City Cycle）进行了广泛验证。结果表明，在所有验证案例中，该方法均优于最先进的无迹卡尔曼滤波器、长短期记忆网络和Transformer。", "conclusion": "本文提出的基于费舍尔信息的自适应估计方法能有效克服磷酸铁锂电池荷电状态估计的挑战，并在各种复杂工况下展现出卓越的性能，证明了其在实际应用中的巨大潜力。", "translation": "磷酸铁锂（LFP）电池因其安全性和长寿命而广泛应用于电动汽车（EV）和储能系统，因此鲁棒且实时的荷电状态（SOC）估计至关重要。然而，平坦的开路电压（OCV）-SOC曲线使得这项任务尤其具有挑战性。滞后效应、以及电池管理系统使用中必须考虑的电流偏差、电压量化误差和温度等实际工况使这一挑战变得更加复杂。在本文中，我们提出了一种自适应估计方法，以克服磷酸铁锂电池SOC估计的挑战。具体来说，该方法采用自适应费舍尔信息融合策略，自适应地结合来自两种不同模型的SOC估计，这两种模型是库仑计数和基于等效电路模型的参数识别。该策略的有效性通过外部循环信号激发的丰富信息得到合理化。提出了一种捕捉OCV、滞后和SOC之间关系的3D OCV-H-SOC图作为骨干，并且可以推广到其他广泛采用的参数识别方法。在理想和实际使用场景下进行了广泛验证，包括SOC-OCV平坦区、电流偏差、电压量化误差、低温和电流激励不足，使用了4种驾驶循环，即Orange County Transit Bus Cycle、California Unified Cycle、US06 Drive Cycle和New York City Cycle，结果表明在所有验证案例中均优于最先进的无迹卡尔曼滤波器、长短期记忆网络和Transformer。", "summary": "本文针对磷酸铁锂（LFP）电池荷电状态（SOC）估计面临的挑战，如平坦OCV-SOC曲线和实际工况影响，提出了一种基于费舍尔信息融合的自适应估计方法。该方法结合了库仑计数和等效电路模型两种估计结果，并构建了3D OCV-H-SOC图作为核心。通过在多种驾驶循环和复杂条件下进行广泛验证，结果表明该方法在SOC估计精度上显著优于现有先进技术。", "keywords": "LFP电池, SOC估计, 费舍尔信息, 自适应估计, 3D OCV-H-SOC图", "comments": "这项研究的创新之处在于提出了基于费舍尔信息融合的自适应估计策略，有效地整合了不同模型的优势，并引入了3D OCV-H-SOC图来处理LFP电池的非线性特性和滞后效应。其重要性在于为LFP电池在电动汽车和储能系统中的精确SOC估计提供了更鲁棒、更实用的解决方案，尤其是在面对电流偏差、电压量化误差和低温等实际复杂工况时。该方法在多个驾驶循环下的出色表现，证明了其在实际应用中的巨大潜力，克服了现有方法的局限性。"}}
{"id": "2507.01160", "title": "Event-based evaluation of abstractive news summarization", "authors": ["Huiling You", "Samia Touileb", "Erik Velldal", "Lilja Øvrelid"], "summary": "An abstractive summary of a news article contains its most important\ninformation in a condensed version. The evaluation of automatically generated\nsummaries by generative language models relies heavily on human-authored\nsummaries as gold references, by calculating overlapping units or similarity\nscores. News articles report events, and ideally so should the summaries. In\nthis work, we propose to evaluate the quality of abstractive summaries by\ncalculating overlapping events between generated summaries, reference\nsummaries, and the original news articles. We experiment on a richly annotated\nNorwegian dataset comprising both events annotations and summaries authored by\nexpert human annotators. Our approach provides more insight into the event\ninformation contained in the summaries.", "comment": "to appear at GEM2 workshop@ACL 2025", "pdf_url": "http://arxiv.org/pdf/2507.01160v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01160v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "基于事件的抽象新闻摘要评估", "tldr": "提出一种基于事件重叠来评估抽象新闻摘要质量的新方法，以提供更深入的事件信息洞察。", "motivation": "现有的生成式语言模型自动摘要评估方法过度依赖人工撰写的摘要作为黄金参考，通过计算重叠单元或相似度得分，而新闻文章和理想的摘要都应报道事件，这表明需要一种更关注事件内容的评估方式。", "method": "提出通过计算生成摘要、参考摘要和原始新闻文章之间的事件重叠来评估抽象摘要的质量。在一个包含事件注释和专家人工摘要的挪威数据集上进行实验。", "result": "我们的方法为摘要中包含的事件信息提供了更深入的见解。", "conclusion": "Not mentioned in abstract", "translation": "一篇新闻文章的抽象摘要以浓缩的形式包含其最重要的信息。生成式语言模型自动生成的摘要的评估严重依赖人工撰写的摘要作为黄金参考，通过计算重叠单元或相似度得分。新闻文章报道事件，理想情况下摘要也应如此。在这项工作中，我们提出通过计算生成摘要、参考摘要和原始新闻文章之间的重叠事件来评估抽象摘要的质量。我们在一个包含事件注释和专家人工注释摘要的丰富挪威数据集上进行实验。我们的方法为摘要中包含的事件信息提供了更深入的见解。", "summary": "本文针对现有抽象新闻摘要评估方法过度依赖人工参考摘要的局限性，提出了一种新的基于事件重叠的评估方法。该方法通过计算生成摘要、参考摘要和原始新闻文章之间的事件重叠来衡量摘要质量。研究在一个包含事件注释的挪威数据集上进行实验，结果表明该方法能提供对摘要中事件信息的更深入洞察。", "keywords": "事件评估, 抽象摘要, 新闻摘要, 事件重叠, 摘要评估", "comments": "该论文提出了一种创新的评估抽象新闻摘要的视角，即关注事件重叠而非简单的文本相似性，这对于捕捉新闻摘要的核心语义内容至关重要。这种方法有望弥补传统评估指标在理解新闻事件报道方面的不足，为摘要质量的衡量提供更具洞察力的指标，推动抽象摘要技术的发展。"}}
{"id": "2507.01116", "title": "Semiautomatic Simplification", "authors": ["Gong Li", "Benjamin Watson"], "summary": "We present semisimp, a tool for semiautomatic simplification of three\ndimensional polygonal models. Existing automatic simplification technology is\nquite mature, but is not sensitive to the heightened importance of distinct\nsemantic model regions such as faces and limbs, nor to simplification\nconstraints imposed by model usage such as animation. semisimp allows users to\npreserve such regions by intervening in the simplification process. Users can\nmanipulate the order in which basic simplifications are applied to redistribute\nmodel detail, improve the simplified models themselves by repositioning\nvertices with propagation to neighboring levels of detail, and adjust the\nhierarchical partitioning of the model surface to segment simplification and\nimprove control of reordering and position propagation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01116v1", "categories": ["cs.GR"], "cate": "cs.GR", "url": "http://arxiv.org/abs/2507.01116v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "半自动简化", "tldr": "semisimp是一个用于三维多边形模型半自动简化的工具，解决了现有自动简化技术对语义区域和使用约束不敏感的问题，允许用户介入并控制简化过程。", "motivation": "现有自动简化技术虽然成熟，但对模型中重要的语义区域（如面部、肢体）不敏感，也无法有效处理模型使用（如动画）带来的简化约束。这导致简化后的模型可能失去重要细节。", "method": "本文提出了一个名为semisimp的工具。该工具允许用户介入简化过程以保留特定区域；操纵基本简化的应用顺序以重新分布模型细节；通过重新定位顶点（并传播到相邻的细节级别）来改进简化模型；以及调整模型表面的层次划分，以分割简化并改进重新排序和位置传播的控制。", "result": "论文介绍了一个名为semisimp的工具，它通过允许用户介入和控制简化过程，解决了现有自动简化技术在处理语义区域和使用约束方面的不足。具体结果是工具能够让用户保留重要区域、重新分布细节、改进简化模型和增强控制。", "conclusion": "本文介绍了semisimp工具，它通过引入用户干预，克服了现有全自动三维模型简化技术在语义区域保留和使用约束处理上的局限性，从而提供了更精细和可控的简化效果。", "translation": "我们提出了semisimp，一个用于三维多边形模型半自动简化的工具。现有的自动简化技术已经相当成熟，但对不同语义模型区域（如面部和肢体）的高度重要性不敏感，也未考虑到模型使用（如动画）所施加的简化约束。semisimp允许用户通过干预简化过程来保留这些区域。用户可以操纵基本简化的应用顺序以重新分配模型细节，通过重新定位顶点并传播到相邻的细节级别来改进简化模型本身，并调整模型表面的分层划分以分割简化并改善重新排序和位置传播的控制。", "summary": "semisimp是一个用于三维多边形模型半自动简化的工具。它旨在解决现有自动简化技术对语义区域和使用约束不敏感的问题。通过允许用户介入并控制简化过程，semisimp使用户能够保留关键区域、重新分布模型细节、优化顶点位置以及调整模型表面划分，从而实现更精细和可控的简化。", "keywords": "半自动简化, 三维模型, 多边形简化, 用户干预, 语义区域", "comments": "该论文提出了一种半自动方法，弥补了现有全自动三维模型简化技术在处理复杂语义区域和特定应用约束方面的不足。通过引入用户干预，它提供了更灵活和高质量的简化结果，对于需要保留模型特定细节的应用（如动画）具有重要意义。"}}
{"id": "2507.01696", "title": "Dynamic Similarity Graph Construction with Kernel Density Estimation", "authors": ["Steinar Laenen", "Peter Macgregor", "He Sun"], "summary": "In the kernel density estimation (KDE) problem, we are given a set $X$ of\ndata points in $\\mathbb{R}^d$, a kernel function $k: \\mathbb{R}^d \\times\n\\mathbb{R}^d \\rightarrow \\mathbb{R}$, and a query point $\\mathbf{q} \\in\n\\mathbb{R}^d$, and the objective is to quickly output an estimate of\n$\\sum_{\\mathbf{x} \\in X} k(\\mathbf{q}, \\mathbf{x})$. In this paper, we consider\n$\\textsf{KDE}$ in the dynamic setting, and introduce a data structure that\nefficiently maintains the estimates for a set of query points as data points\nare added to $X$ over time. Based on this, we design a dynamic data structure\nthat maintains a sparse approximation of the fully connected similarity graph\non $X$, and develop a fast dynamic spectral clustering algorithm. We further\nevaluate the effectiveness of our algorithms on both synthetic and real-world\ndatasets.", "comment": "ICML'25", "pdf_url": "http://arxiv.org/pdf/2507.01696v1", "categories": ["cs.DS", "cs.LG"], "cate": "cs.DS", "url": "http://arxiv.org/abs/2507.01696v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "动态相似图构建与核密度估计", "tldr": "论文提出了一种在动态设置下高效维护核密度估计的数据结构，并在此基础上设计了动态相似图构建和快速动态谱聚类算法。", "motivation": "在动态设置下高效地进行核密度估计，并在此基础上构建动态相似图和实现快速谱聚类。", "method": "本文引入了一个数据结构，用于在数据点随时间添加到集合X时，有效维护一组查询点的核密度估计。基于此，设计了一个动态数据结构，用于维护X上全连接相似图的稀疏近似，并开发了一个快速动态谱聚类算法。", "result": "算法在合成数据集和真实世界数据集上都进行了有效性评估。", "conclusion": "本文成功设计并评估了在动态设置下进行核密度估计、相似图构建和谱聚类的有效算法。", "translation": "在核密度估计（KDE）问题中，我们给定$R^d$中的一组数据点$X$，一个核函数$k: R^d \\times R^d \\rightarrow R$，以及一个查询点$\\mathbf{q} \\in R^d$，目标是快速输出$\\sum_{\\mathbf{x} \\in X} k(\\mathbf{q}, \\mathbf{x})$的估计。在本文中，我们考虑动态设置下的KDE，并引入一个数据结构，该结构可以有效地维护一组查询点的估计，随着数据点随时间添加到$X$中。在此基础上，我们设计了一个动态数据结构，可以维护$X$上全连接相似图的稀疏近似，并开发了一个快速动态谱聚类算法。我们进一步在合成数据集和真实世界数据集上评估了我们算法的有效性。", "summary": "本文针对动态核密度估计（KDE）问题，提出了一种数据结构，能够高效地维护查询点的KDE估计值，即使数据点集$X$随时间动态变化。在此基础上，作者进一步开发了一个动态数据结构，用于维护$X$上全连接相似图的稀疏近似，并设计了一个快速动态谱聚类算法。实验结果表明，所提出的算法在合成数据和真实世界数据集上均表现出良好的有效性。", "keywords": "核密度估计, 动态设置, 相似图, 谱聚类, 数据结构", "comments": "本文的创新点在于将核密度估计、相似图构建和谱聚类引入到动态设置中，解决了数据点随时间变化的挑战。所提出的数据结构和算法对于处理大规模流式数据具有潜在的应用价值。"}}
{"id": "2507.01207", "title": "On the Intensity-based Inversion Method for Quantitative Quasi-Static Elastography", "authors": ["Ekaterina Sherina", "Simon Hubmer"], "summary": "In this paper, we consider the intensity-based inversion method (IIM) for\nquantitative material parameter estimation in quasi-static elastography. In\nparticular, we consider the problem of estimating the material parameters of a\ngiven sample from two internal measurements, one obtained before and one after\napplying some form of deformation. These internal measurements can be obtained\nvia any imaging modality of choice, for example ultrasound, optical coherence\nor photo-acoustic tomography. Compared to two-step approaches to elastography,\nwhich first estimate internal displacement fields or strains and then\nreconstruct the material parameters from them, the IIM is a one-step approach\nwhich computes the material parameters directly from the internal measurements.\nTo do so, the IIM combines image registration together with a model-based,\nregularized parameter reconstruction approach. This combination has the\nadvantage of avoiding some approximations and derivative computations typically\nfound in two-step approaches, and results in the IIM being generally more\nstable to measurement noise. In the paper, we provide a full convergence\nanalysis of the IIM within the framework of inverse problems, and detail its\napplication to linear elastography. Furthermore, we discuss the numerical\nimplementation of the IIM and provide numerical examples simulating an optical\ncoherence elastography (OCE) experiment.", "comment": "29 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.01207v1", "categories": ["math.NA", "cs.NA"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01207v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "定量准静态弹性成像中基于强度反演方法的研究", "tldr": "本文提出并分析了一种基于强度的反演方法（IIM），用于准静态弹性成像中的材料参数估计，该方法直接从内部测量数据计算参数，避免了两步法的中间近似和导数计算，并提供了收敛性分析和数值示例。", "motivation": "传统的弹性成像两步法需要先估计内部位移场或应变，然后从中重建材料参数，这可能引入近似、导数计算且对测量噪声敏感。本文旨在提出一种更直接、更稳定的材料参数估计方法。", "method": "本文提出了基于强度反演方法（IIM），该方法通过结合图像配准和基于模型的正则化参数重建，直接从变形前后两次内部测量数据中估计材料参数。论文提供了在逆问题框架下IIM的完整收敛性分析，并详细说明了其在线性弹性成像中的应用。此外，还讨论了数值实现并提供了模拟光学相干弹性成像（OCE）实验的数值示例。", "result": "IIM方法相比传统两步法，避免了中间近似和导数计算，并且对测量噪声表现出更高的稳定性。论文提供了IIM的完整收敛性分析，并通过模拟光学相干弹性成像（OCE）实验验证了其应用。", "conclusion": "基于强度反演方法（IIM）是一种有效且稳定的单步方法，用于定量准静态弹性成像中的材料参数估计。它通过直接从内部测量数据计算参数，避免了传统两步法的缺点，并在理论分析和数值示例中展现出优越性。", "translation": "在本文中，我们考虑了用于准静态弹性成像中定量材料参数估计的基于强度反演方法（IIM）。特别是，我们考虑了从两次内部测量（一次在施加某种形变之前，一次之后）来估计给定样本材料参数的问题。这些内部测量可以通过任何选择的成像模式获得，例如超声、光学相干断层扫描或光声断层扫描。与弹性成像中的两步法（首先估计内部位移场或应变，然后从中重建材料参数）相比，IIM是一种单步法，它直接从内部测量数据计算材料参数。为此，IIM将图像配准与基于模型的正则化参数重建方法相结合。这种结合的优点是避免了两步法中通常存在的某些近似和导数计算，并使得IIM对测量噪声通常更稳定。在本文中，我们在逆问题框架内对IIM提供了完整的收敛性分析，并详细说明了其在线性弹性成像中的应用。此外，我们讨论了IIM的数值实现，并提供了模拟光学相干弹性成像（OCE）实验的数值示例。", "summary": "本文介绍了一种用于定量准静态弹性成像的基于强度反演方法（IIM），该方法直接从变形前后两次内部测量中估计材料参数。与传统的两步法不同，IIM通过结合图像配准和模型正则化重建，避免了中间近似和导数计算，从而提高了对测量噪声的稳定性。文中提供了IIM的完整收敛性分析，并展示了其在线性弹性成像和模拟光学相干弹性成像实验中的应用。", "keywords": "弹性成像, 基于强度反演方法, 材料参数估计, 准静态, 逆问题", "comments": "这篇论文的创新点在于提出了基于强度反演方法（IIM）作为一种单步法，直接从原始图像强度数据中推断材料参数，避免了传统两步法中位移或应变估计带来的误差累积和对噪声的敏感性。其重要性在于提供了一种更稳定、更鲁棒的弹性成像参数重建方法，特别是在存在测量噪声的情况下。收敛性分析的提供也增加了方法的理论严谨性。"}}
{"id": "2507.01022", "title": "Workflow-Based Evaluation of Music Generation Systems", "authors": ["Shayan Dadman", "Bernt Arild Bremdal", "Andreas Bergsland"], "summary": "This study presents an exploratory evaluation of Music Generation Systems\n(MGS) within contemporary music production workflows by examining eight\nopen-source systems. The evaluation framework combines technical insights with\npractical experimentation through criteria specifically designed to investigate\nthe practical and creative affordances of the systems within the iterative,\nnon-linear nature of music production. Employing a single-evaluator methodology\nas a preliminary phase, this research adopts a mixed approach utilizing\nqualitative methods to form hypotheses subsequently assessed through\nquantitative metrics. The selected systems represent architectural diversity\nacross both symbolic and audio-based music generation approaches, spanning\ncomposition, arrangement, and sound design tasks. The investigation addresses\nlimitations of current MGS in music production, challenges and opportunities\nfor workflow integration, and development potential as collaborative tools\nwhile maintaining artistic authenticity. Findings reveal these systems function\nprimarily as complementary tools enhancing rather than replacing human\nexpertise. They exhibit limitations in maintaining thematic and structural\ncoherence that emphasize the indispensable role of human creativity in tasks\ndemanding emotional depth and complex decision-making. This study contributes a\nstructured evaluation framework that considers the iterative nature of music\ncreation. It identifies methodological refinements necessary for subsequent\ncomprehensive evaluations and determines viable areas for AI integration as\ncollaborative tools in creative workflows. The research provides\nempirically-grounded insights to guide future development in the field.", "comment": "54 pages, 3 figures, 6 tables, 5 appendices", "pdf_url": "http://arxiv.org/pdf/2507.01022v1", "categories": ["eess.AS", "cs.HC", "cs.LG", "cs.MM", "cs.SD"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01022v1", "date": "2025-06-11", "updated": "2025-06-11", "AI": {"title_translation": "基于工作流的音乐生成系统评估", "tldr": "本研究评估了八个开源音乐生成系统在当代音乐制作工作流中的应用，发现它们主要作为人类专业知识的补充工具，但在保持主题和结构连贯性方面存在局限性，强调了人类创造力的不可或缺性。", "motivation": "本研究旨在探索性评估音乐生成系统（MGS）在当代音乐制作工作流中的表现，以解决当前MGS在音乐制作中的局限性、工作流集成的挑战和机遇，以及作为协作工具的开发潜力。", "method": "研究采用单一评估者方法作为初步阶段，结合技术洞察和实践实验，通过专门设计的标准来调查系统在迭代、非线性音乐制作中的实用和创造性功能。研究采用混合方法，利用定性方法形成假设，并通过定量指标进行评估。选择了八个代表架构多样性的开源系统，涵盖符号和音频音乐生成方法，以及作曲、编曲和声音设计任务。", "result": "研究发现这些系统主要作为补充工具，增强而非取代人类专业知识。它们在保持主题和结构连贯性方面存在局限性，这强调了在需要情感深度和复杂决策的任务中人类创造力的不可或缺作用。", "conclusion": "本研究贡献了一个考虑音乐创作迭代性质的结构化评估框架，识别了后续全面评估所需的方法学改进，并确定了AI作为协作工具在创意工作流中整合的可行领域。研究提供了经验证的见解，以指导该领域的未来发展。", "translation": "本研究旨在对当代音乐制作工作流中的音乐生成系统（MGS）进行探索性评估，通过考察八个开源系统。评估框架将技术洞察与实践实验相结合，通过专门设计的标准来调查系统在音乐制作的迭代、非线性性质中的实用和创造性功能。本研究采用单一评估者方法作为初步阶段，采用混合方法，利用定性方法形成假设，随后通过定量指标进行评估。所选系统代表了符号和基于音频的音乐生成方法的架构多样性，涵盖作曲、编曲和声音设计任务。本次调查探讨了当前MGS在音乐制作中的局限性、工作流集成的挑战和机遇，以及作为协作工具的开发潜力，同时保持艺术真实性。研究结果显示，这些系统主要作为补充工具，增强而非取代人类专业知识。它们在保持主题和结构连贯性方面存在局限性，这强调了在需要情感深度和复杂决策的任务中人类创造力的不可或缺作用。本研究贡献了一个考虑音乐创作迭代性质的结构化评估框架。它识别了后续全面评估所需的方法学改进，并确定了AI作为协作工具在创意工作流中整合的可行领域。本研究提供了基于经验的见解，以指导该领域的未来发展。", "summary": "本研究对八个开源音乐生成系统在当代音乐制作工作流中的应用进行了探索性评估。通过结合技术洞察和实践实验的混合方法，研究发现这些系统主要作为人类专业知识的补充工具，但在保持主题和结构连贯性方面存在局限性，凸显了人类创造力在复杂音乐任务中的核心作用。研究提出了一个结构化评估框架，并为未来AI在创意工作流中的整合提供了指导。", "keywords": "音乐生成系统, 工作流评估, 人工智能音乐, 创意工具, 协作工具", "comments": "本研究的创新之处在于其将音乐生成系统置于实际的音乐制作工作流中进行评估，而非仅仅关注技术性能。它强调了MGS作为人类专业知识的补充而非替代品的角色，这对于AI在创意领域的未来发展具有重要指导意义。其提出的结构化评估框架考虑了音乐创作的迭代性，为后续更全面的评估奠定了基础。"}}
{"id": "2507.01049", "title": "Cohort Retrieval using Dense Passage Retrieval", "authors": ["Pranav Jadhav"], "summary": "Patient cohort retrieval is a pivotal task in medical research and clinical\npractice, enabling the identification of specific patient groups from extensive\nelectronic health records (EHRs). In this work, we address the challenge of\ncohort retrieval in the echocardiography domain by applying Dense Passage\nRetrieval (DPR), a prominent methodology in semantic search. We propose a\nsystematic approach to transform an echocardiographic EHR dataset of\nunstructured nature into a Query-Passage dataset, framing the problem as a\nCohort Retrieval task. Additionally, we design and implement evaluation metrics\ninspired by real-world clinical scenarios to rigorously test the models across\ndiverse retrieval tasks. Furthermore, we present a custom-trained DPR embedding\nmodel that demonstrates superior performance compared to traditional and\noff-the-shelf SOTA methods.To our knowledge, this is the first work to apply\nDPR for patient cohort retrieval in the echocardiography domain, establishing a\nframework that can be adapted to other medical domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01049v1", "categories": ["cs.IR", "cs.CL"], "cate": "cs.IR", "url": "http://arxiv.org/abs/2507.01049v1", "date": "2025-06-26", "updated": "2025-06-26", "AI": {"title_translation": "使用密集段落检索的队列检索", "tldr": "本研究首次将密集段落检索（DPR）应用于超声心动图领域的患者队列检索，通过系统方法将非结构化EHR数据转换为查询-段落数据集，并训练出性能优越的DPR嵌入模型。", "motivation": "患者队列检索是医学研究和临床实践中的关键任务，用于从大量电子健康记录（EHRs）中识别特定患者群体。本文旨在解决超声心动图领域的队列检索挑战。", "method": "本文提出了一种系统方法，将非结构化的超声心动图EHR数据集转换为查询-段落数据集，并将问题构建为队列检索任务。设计并实现了受临床场景启发的评估指标。开发了一个定制训练的DPR嵌入模型。", "result": "定制训练的DPR嵌入模型与传统方法和现有的SOTA方法相比，展示了卓越的性能。据作者所知，这是首次将DPR应用于超声心动图领域的患者队列检索。", "conclusion": "本文成功地将密集段落检索（DPR）应用于超声心动图领域的患者队列检索，并建立了一个可推广到其他医疗领域的框架，展示了DPR在该任务中的优越性。", "translation": "患者队列检索是医学研究和临床实践中的一项关键任务，能够从大量的电子健康记录（EHRs）中识别特定患者群体。在这项工作中，我们通过应用密集段落检索（DPR）——一种在语义搜索中突出的方法，解决了超声心动图领域的队列检索挑战。我们提出了一种系统方法，将非结构化的超声心动图EHR数据集转换为查询-段落数据集，将问题构建为队列检索任务。此外，我们设计并实现了受现实临床场景启发的评估指标，以严格测试模型在不同检索任务中的表现。此外，我们提出了一个定制训练的DPR嵌入模型，该模型与传统方法和现有的SOTA方法相比，展示了卓越的性能。据我们所知，这是首次将DPR应用于超声心动图领域的患者队列检索，建立了一个可以适应其他医疗领域的框架。", "summary": "本研究针对超声心动图领域的患者队列检索难题，创新性地应用了密集段落检索（DPR）。通过将非结构化EHR数据转化为查询-段落格式，并设计符合临床实际的评估指标，本文成功训练了一个定制的DPR嵌入模型。该模型在性能上超越了现有方法，并首次将DPR引入该领域，为医疗数据检索提供了新的框架。", "keywords": "队列检索, 密集段落检索, 超声心动图, 电子健康记录, 语义搜索", "comments": "本文的创新点在于首次将DPR应用于超声心动图领域的患者队列检索，并提出了将非结构化EHR数据转化为查询-段落数据集的系统方法，这对于处理复杂的医疗文本数据具有重要意义。其定制训练的DPR模型表现出优越性能，且建立的框架具有良好的通用性，有望推广到其他医疗领域，对医学信息学领域具有重要贡献。"}}
{"id": "2507.01629", "title": "Adaptive Estimation of the Number of Algorithm Runs in Stochastic Optimization", "authors": ["Tome Eftimov", "Peter Korošec"], "summary": "Determining the number of algorithm runs is a critical aspect of experimental\ndesign, as it directly influences the experiment's duration and the reliability\nof its outcomes. This paper introduces an empirical approach to estimating the\nrequired number of runs per problem instance for accurate estimation of the\nperformance of the continuous single-objective stochastic optimization\nalgorithm. The method leverages probability theory, incorporating a robustness\ncheck to identify significant imbalances in the data distribution relative to\nthe mean, and dynamically adjusts the number of runs during execution as an\nonline approach. The proposed methodology was extensively tested across two\nalgorithm portfolios (104 Differential Evolution configurations and the\nNevergrad portfolio) and the COCO benchmark suite, totaling 5748000 runs. The\nresults demonstrate 82% - 95% accuracy in estimations across different\nalgorithms, allowing a reduction of approximately 50% in the number of runs\nwithout compromising optimization outcomes. This online calculation of required\nruns not only improves benchmarking efficiency, but also contributes to energy\nreduction, fostering a more environmentally sustainable computing ecosystem.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01629v1", "categories": ["cs.NE"], "cate": "cs.NE", "url": "http://arxiv.org/abs/2507.01629v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "随机优化中算法运行次数的自适应估计", "tldr": "本文提出了一种自适应方法，用于估计随机优化算法所需的运行次数，能够在不牺牲结果可靠性的前提下，显著减少实验运行量，提高效率并降低能耗。", "motivation": "确定算法运行次数是实验设计的关键，因为它直接影响实验的持续时间和结果的可靠性。传统方法可能导致不必要的长时间运行或不可靠的结果。本文旨在提出一种经验方法来解决这一问题。", "method": "该方法利用概率论，并包含一个鲁棒性检查，以识别数据分布相对于平均值的显著不平衡。它在执行过程中作为在线方法动态调整运行次数，以准确估计连续单目标随机优化算法的性能。", "result": "该方法在两个算法组合（104种差分进化配置和Nevergrad组合）和COCO基准套件上进行了广泛测试，总计5748000次运行。结果表明，在不同算法中，估计准确率达到82%至95%，并且在不影响优化结果的情况下，运行次数减少了约50%。", "conclusion": "所提出的在线计算所需运行次数的方法不仅提高了基准测试效率，还有助于节约能源，从而促进更具环境可持续性的计算生态系统。", "translation": "确定算法运行次数是实验设计的关键方面，因为它直接影响实验的持续时间和结果的可靠性。本文介绍了一种经验方法，用于估计每个问题实例所需的运行次数，以准确估计连续单目标随机优化算法的性能。该方法利用概率论，并结合鲁棒性检查来识别数据分布相对于平均值的显著不平衡，并在执行过程中作为在线方法动态调整运行次数。所提出的方法在两个算法组合（104种差分进化配置和Nevergrad组合）和COCO基准套件上进行了广泛测试，总计5748000次运行。结果表明，在不同算法中，估计准确率达到82%至95%，并且在不影响优化结果的情况下，运行次数减少了约50%。这种所需运行次数的在线计算不仅提高了基准测试效率，还有助于节约能源，从而促进更具环境可持续性的计算生态系统。", "summary": "本文提出了一种用于随机优化算法的在线自适应方法，以估计和动态调整实验所需的运行次数。该方法基于概率论和鲁棒性检查，旨在提高性能估计的准确性，同时显著减少计算资源。通过在多个算法组合和基准套件上的广泛测试，结果显示其能达到82%-95%的估计准确率，并将运行次数减少约50%，从而提高了基准测试效率并促进了能源节约。", "keywords": "随机优化, 算法运行次数, 自适应估计, 实验设计, 效率提升", "comments": "这项研究的创新之处在于提出了一种在线自适应方法来动态调整随机优化算法的运行次数，这在实验设计中是一个重要且实用的问题。其贡献在于通过减少不必要的运行，显著提高了基准测试的效率并降低了能耗，对计算可持续性具有积极影响。该方法的广泛测试和高准确率也验证了其有效性。"}}
{"id": "2507.01563", "title": "Real-Time Emergency Vehicle Siren Detection with Efficient CNNs on Embedded Hardware", "authors": ["Marco Giordano", "Stefano Giacomelli", "Claudia Rinaldi", "Fabio Graziosi"], "summary": "We present a full-stack emergency vehicle (EV) siren detection system\ndesigned for real-time deployment on embedded hardware. The proposed approach\nis based on E2PANNs, a fine-tuned convolutional neural network derived from\nEPANNs, and optimized for binary sound event detection under urban acoustic\nconditions. A key contribution is the creation of curated and semantically\nstructured datasets - AudioSet-EV, AudioSet-EV Augmented, and Unified-EV -\ndeveloped using a custom AudioSet-Tools framework to overcome the low\nreliability of standard AudioSet annotations. The system is deployed on a\nRaspberry Pi 5 equipped with a high-fidelity DAC+microphone board, implementing\na multithreaded inference engine with adaptive frame sizing, probability\nsmoothing, and a decision-state machine to control false positive activations.\nA remote WebSocket interface provides real-time monitoring and facilitates live\ndemonstration capabilities. Performance is evaluated using both framewise and\nevent-based metrics across multiple configurations. Results show the system\nachieves low-latency detection with improved robustness under realistic audio\nconditions. This work demonstrates the feasibility of deploying IoS-compatible\nSED solutions that can form distributed acoustic monitoring networks, enabling\ncollaborative emergency vehicle tracking across smart city infrastructures\nthrough WebSocket connectivity on low-cost edge devices.", "comment": "10 pages, 10 figures, submitted to\n  https://internetofsounds2025.ieee-is2.org/. arXiv admin note: text overlap\n  with arXiv:2506.23437", "pdf_url": "http://arxiv.org/pdf/2507.01563v1", "categories": ["cs.SD", "cs.AI", "eess.AS", "68T07 (Primary), 68T10 (Secondary)", "B.1.5; B.4.5; C.3; C.4; I.2; K.4; J.2"], "cate": "cs.SD", "url": "http://arxiv.org/abs/2507.01563v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "实时嵌入式硬件上高效CNN的紧急车辆警报器检测", "tldr": "该论文提出了一个基于E2PANNs的实时紧急车辆警报器检测系统，该系统针对城市声学条件进行了优化，并部署在树莓派5上，具有低延迟和高鲁棒性，可用于构建分布式声学监测网络。", "motivation": "需要一个为嵌入式硬件实时部署而设计的全栈紧急车辆警报器检测系统，以克服标准AudioSet标注的低可靠性，并能在城市声学条件下实现可靠的二进制声音事件检测，从而支持智能城市基础设施中的协作式紧急车辆跟踪。", "method": "该方法基于E2PANNs（一种从EPANNs微调而来的卷积神经网络），并针对城市声学条件下的二进制声音事件检测进行了优化。关键贡献是创建了策划和语义结构化的数据集（AudioSet-EV、AudioSet-EV Augmented和Unified-EV），使用自定义的AudioSet-Tools框架来克服标准AudioSet标注的低可靠性。系统部署在配备高保真DAC+麦克风板的树莓派5上，实现了多线程推理引擎，具有自适应帧大小调整、概率平滑和决策状态机以控制误报。通过远程WebSocket接口提供实时监控。性能通过逐帧和基于事件的指标进行评估。", "result": "结果表明，该系统实现了低延迟检测，并在真实的音频条件下提高了鲁棒性。该工作证明了部署与IoS兼容的SED解决方案的可行性，这些解决方案可以形成分布式声学监测网络，通过低成本边缘设备上的WebSocket连接实现智能城市基础设施中的协作式紧急车辆跟踪。", "conclusion": "该论文成功地展示了在嵌入式硬件上部署实时紧急车辆警报器检测系统的可行性，该系统具有优化的CNN模型、高质量的数据集和鲁棒的推理引擎，能够为智能城市提供分布式声学监测和紧急车辆跟踪能力。", "translation": "我们提出了一个为嵌入式硬件实时部署而设计的全栈紧急车辆（EV）警报器检测系统。所提出的方法基于E2PANNs，这是一种从EPANNs微调而来的卷积神经网络，并针对城市声学条件下的二进制声音事件检测进行了优化。一个关键的贡献是创建了策划和语义结构化的数据集——AudioSet-EV、AudioSet-EV Augmented和Unified-EV——这些数据集是使用自定义的AudioSet-Tools框架开发的，以克服标准AudioSet标注的低可靠性。该系统部署在配备高保真DAC+麦克风板的树莓派5上，实现了多线程推理引擎，具有自适应帧大小调整、概率平滑和决策状态机，以控制误报。远程WebSocket接口提供实时监控并促进实时演示功能。使用逐帧和基于事件的指标在多种配置下评估了性能。结果显示，该系统实现了低延迟检测，并在真实的音频条件下提高了鲁棒性。这项工作证明了部署与IoS兼容的SED解决方案的可行性，这些解决方案可以形成分布式声学监测网络，通过低成本边缘设备上的WebSocket连接实现智能城市基础设施中的协作式紧急车辆跟踪。", "summary": "该论文介绍了一个针对嵌入式硬件的实时紧急车辆警报器检测系统。该系统基于优化的E2PANNs卷积神经网络，并解决了现有数据集标注可靠性低的问题，通过创建了AudioSet-EV等高质量数据集。系统部署在树莓派5上，采用多线程推理引擎和一系列优化技术以减少误报。实验证明，该系统在真实音频条件下实现了低延迟和高鲁棒性的检测，为构建智能城市中的分布式声学监测网络和紧急车辆跟踪提供了可行方案。", "keywords": "紧急车辆警报器检测, 卷积神经网络, 嵌入式硬件, 声音事件检测, 智能城市", "comments": "该论文的创新之处在于其全栈式的解决方案，从数据收集与标注（自定义AudioSet-Tools框架和新数据集）到模型优化（E2PANNs）再到嵌入式部署（树莓派5上的多线程推理引擎）。特别值得注意的是，它解决了现有AudioSet标注不可靠的问题，并专注于在资源受限的边缘设备上实现实时、低延迟、高鲁棒性的性能。这对于智能城市基础设施中的实际应用具有重要意义。"}}
{"id": "2507.01198", "title": "Search-Based Robot Motion Planning With Distance-Based Adaptive Motion Primitives", "authors": ["Benjamin Kraljusic", "Zlatan Ajanovic", "Nermin Covic", "Bakir Lacevic"], "summary": "This work proposes a motion planning algorithm for robotic manipulators that\ncombines sampling-based and search-based planning methods. The core\ncontribution of the proposed approach is the usage of burs of free\nconfiguration space (C-space) as adaptive motion primitives within the graph\nsearch algorithm. Due to their feature to adaptively expand in free C-space,\nburs enable more efficient exploration of the configuration space compared to\nfixed-sized motion primitives, significantly reducing the time to find a valid\npath and the number of required expansions. The algorithm is implemented within\nthe existing SMPL (Search-Based Motion Planning Library) library and evaluated\nthrough a series of different scenarios involving manipulators with varying\nnumber of degrees-of-freedom (DoF) and environment complexity. Results\ndemonstrate that the bur-based approach outperforms fixed-primitive planning in\ncomplex scenarios, particularly for high DoF manipulators, while achieving\ncomparable performance in simpler scenarios.", "comment": "6 pages, 3 figures, submitted to a conference", "pdf_url": "http://arxiv.org/pdf/2507.01198v1", "categories": ["cs.RO", "cs.AI", "cs.CG"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01198v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "基于距离自适应运动基元的搜索式机器人运动规划", "tldr": "本文提出一种结合采样和搜索方法的机器人运动规划算法，使用自适应运动基元（burs）提高复杂场景下的规划效率。", "motivation": "为了提高机器人机械臂运动规划的效率，特别是减少在复杂配置空间中寻找路径的时间和所需的扩展次数，本研究旨在提出一种更有效的运动基元方法，以克服传统固定大小运动基元的局限性。", "method": "提出了一种结合采样式和搜索式规划方法的机器人机械臂运动规划算法。核心贡献是在图搜索算法中使用了自由配置空间（C-space）中的“burs”作为自适应运动基元。这些burs能够自适应地在自由C-space中扩展，从而更有效地探索配置空间。", "result": "该算法在现有的SMPL（Search-Based Motion Planning Library）库中实现，并通过涉及不同自由度（DoF）机械臂和环境复杂度的多场景进行评估。结果表明，与固定基元规划相比，基于bur的方法在复杂场景中（特别是对于高自由度机械臂）表现更优，而在简单场景中性能相当。", "conclusion": "通过引入自自适应运动基元（burs），所提出的搜索式机器人运动规划算法显著提高了在复杂场景和高自由度机械臂运动规划中的效率和性能。", "translation": "这篇工作提出了一种结合了基于采样和基于搜索的规划方法的机器人机械臂运动规划算法。所提出方法的核心贡献在于在图搜索算法中使用了自由配置空间（C-space）中的“burs”作为自适应运动基元。由于其在自由C-space中自适应扩展的特性，burs相比固定大小的运动基元能够更有效地探索配置空间，显著减少了找到有效路径所需的时间和所需的扩展次数。该算法在现有的SMPL（基于搜索的运动规划库）中实现，并通过一系列涉及不同自由度（DoF）机械臂和环境复杂度的场景进行评估。结果表明，基于bur的方法在复杂场景中，特别是对于高自由度机械臂，其性能优于固定基元规划，同时在简单场景中实现了可比较的性能。", "summary": "本文提出了一种结合采样和搜索方法的机器人机械臂运动规划算法。其核心创新在于引入了自由配置空间中的“burs”作为自适应运动基元，这些burs能够自适应地扩展，从而比固定大小的运动基元更有效地探索配置空间，显著减少了路径查找时间和扩展次数。实验证明，该方法在复杂场景和高自由度机械臂的运动规划中表现出优越性能，而在简单场景中性能相当。", "keywords": "机器人运动规划, 自适应运动基元, 配置空间, 搜索式规划, 高自由度机械臂", "comments": "这篇论文的创新点在于引入了“burs”作为自适应运动基元，有效地解决了传统固定大小运动基元在复杂和高自由度机器人运动规划中效率低下的问题。通过自适应扩展，该方法能够更高效地探索配置空间，对于提高复杂机器人系统的运动规划实用性和效率具有重要意义。"}}
{"id": "2507.01376", "title": "AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing", "authors": ["Yinwang Ren", "Yangyang Liu", "Tang Ji", "Xun Xu"], "summary": "AI agents are autonomous systems designed to perceive, reason, and act within\ndynamic environments. With the rapid advancements in generative AI (GenAI),\nlarge language models (LLMs) and multimodal large language models (MLLMs) have\nsignificantly improved AI agents' capabilities in semantic comprehension,\ncomplex reasoning, and autonomous decision-making. At the same time, the rise\nof Agentic AI highlights adaptability and goal-directed autonomy in dynamic and\ncomplex environments. LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents\n(MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in\ninformation processing, environmental perception, and autonomous\ndecision-making, opening new avenues for smart manufacturing. However, the\ndefinitions, capability boundaries, and practical applications of these\nemerging AI paradigms in smart manufacturing remain unclear. To address this\ngap, this study systematically reviews the evolution of AI and AI agent\ntechnologies, examines the core concepts and technological advancements of\nLLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential\napplications in and integration into manufacturing, along with the potential\nchallenges they may face.", "comment": "Submitted to JMS(March 2025)", "pdf_url": "http://arxiv.org/pdf/2507.01376v1", "categories": ["cs.AI"], "cate": "cs.AI", "url": "http://arxiv.org/abs/2507.01376v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "AI智能体与代理式AI——驾驭未来制造的诸多概念", "tldr": "AI智能体（由生成式AI、LLM和MLLM增强）正在改变智能制造，但其定义和应用仍不明确。本研究旨在系统回顾这些概念及其在制造业中的潜力。", "motivation": "智能制造中新兴AI范式（如LLM-Agents、MLLM-Agents和代理式AI）的定义、能力边界和实际应用尚不明确，本研究旨在弥补这一空白。", "method": "本研究系统回顾了AI和AI智能体技术的发展，考察了LLM-Agents、MLLM-Agents和代理式AI的核心概念、技术进步，并探讨了它们在制造业中的潜在应用、集成以及可能面临的挑战。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "AI智能体是旨在动态环境中感知、推理和行动的自主系统。随着生成式AI（GenAI）的迅速发展，大型语言模型（LLM）和多模态大型语言模型（MLLM）显著提升了AI智能体在语义理解、复杂推理和自主决策方面的能力。同时，代理式AI的兴起强调了在动态复杂环境中的适应性和目标导向的自主性。基于LLM的AI智能体（LLM-Agents）、基于MLLM的AI智能体（MLLM-Agents）以及代理式AI共同促进了AI在信息处理、环境感知和自主决策能力方面的扩展，为智能制造开辟了新途径。然而，这些新兴AI范式在智能制造中的定义、能力边界和实际应用仍不明确。为解决这一问题，本研究系统回顾了AI和AI智能体技术的发展，考察了LLM-Agents、MLLM-Agents和代理式AI的核心概念和技术进步，并探讨了它们在制造业中的潜在应用和集成，以及可能面临的潜在挑战。", "summary": "本研究关注AI智能体、代理式AI以及由生成式AI、大型语言模型（LLM）和多模态大型语言模型（MLLM）增强的LLM-Agents和MLLM-Agents在智能制造领域的应用。鉴于这些新兴AI范式在智能制造中的定义、能力边界和实际应用尚不明确，本研究旨在通过系统回顾AI和AI智能体技术的发展，考察相关核心概念和技术进步，并探讨它们在制造业中的潜在应用、集成方式及其面临的挑战，以期澄清这些概念并指导未来发展。", "keywords": "AI智能体, 代理式AI, LLM-Agents, 智能制造, 生成式AI", "comments": "本文关注AI前沿技术（如生成式AI、LLM和MLLM）与关键工业领域（制造业）的交叉点，具有很强的时代性和应用价值。其创新性在于尝试理清快速演进的复杂AI概念，并系统性地探讨其在实际工业场景中的应用潜力及挑战，这对于推动相关技术的研究和工业落地至关重要。"}}
{"id": "2507.01315", "title": "Context-Aware Code Wiring Recommendation with LLM-based Agent", "authors": ["Taiming Wang", "Yanjie Jiang", "Chunhao Dong", "Yuxia Zhang", "Hui Liu"], "summary": "Copy-paste-modify is a widespread and pragmatic practice in software\ndevelopment, where developers adapt reused code snippets, sourced from\nplatforms such as Stack Overflow, GitHub, or LLM outputs, into their local\ncodebase. A critical yet underexplored aspect of this adaptation is code\nwiring, which involves substituting unresolved variables in the pasted code\nwith suitable ones from the surrounding context. Existing solutions either rely\non heuristic rules or historical templates, often failing to effectively\nutilize contextual information, despite studies showing that over half of\nadaptation cases are context-dependent. In this paper, we introduce WIRL, an\nLLM-based agent for code wiring framed as a Retrieval-Augmented Generation\n(RAG) infilling task. WIRL combines an LLM, a customized toolkit, and an\norchestration module to identify unresolved variables, retrieve context, and\nperform context-aware substitutions. To balance efficiency and autonomy, the\nagent adopts a mixed strategy: deterministic rule-based steps for common\npatterns, and a state-machine-guided decision process for intelligent\nexploration. We evaluate WIRL on a carefully curated, high-quality dataset\nconsisting of real-world code adaptation scenarios. Our approach achieves an\nexact match precision of 91.7% and a recall of 90.0%, outperforming advanced\nLLMs by 22.6 and 13.7 percentage points in precision and recall, respectively,\nand surpassing IntelliJ IDEA by 54.3 and 49.9 percentage points. These results\nunderscore its practical utility, particularly in contexts with complex\nvariable dependencies or multiple unresolved variables. We believe WIRL paves\nthe way for more intelligent and context-aware developer assistance in modern\nIDEs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01315v1", "categories": ["cs.SE"], "cate": "cs.SE", "url": "http://arxiv.org/abs/2507.01315v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "上下文感知代码连接推荐与基于LLM的代理", "tldr": "WIRL是一个基于LLM的代理，用于解决代码复制-粘贴-修改中的变量连接问题，它结合了LLM、工具包和编排模块，实现了高精度和高召回率，显著优于现有方案和LLM。", "motivation": "软件开发中复制-粘贴-修改是普遍实践，但代码连接（替换未解析变量）是关键且未充分探索的方面。现有解决方案（启发式规则或历史模板）未能有效利用上下文信息，导致效果不佳。", "method": "本文引入了WIRL，一个基于LLM的代理，将代码连接视为检索增强生成（RAG）填充任务。WIRL结合了LLM、定制工具包和编排模块来识别未解析变量、检索上下文并执行上下文感知替换。它采用混合策略：常见模式使用确定性规则，复杂情况使用状态机引导决策。", "result": "在真实世界代码适应场景的高质量数据集上，WIRL实现了91.7%的精确匹配精度和90.0%的召回率。它在精确度上比先进的LLM高出22.6个百分点，在召回率上高出13.7个百分点，并超越IntelliJ IDEA 54.3和49.9个百分点。", "conclusion": "WIRL的实用性得到了强调，特别是在复杂变量依赖或多个未解析变量的上下文中。它为现代IDE中更智能、上下文感知的开发者协助铺平了道路。", "translation": "复制-粘贴-修改是软件开发中一种普遍且实用的做法，开发者将从Stack Overflow、GitHub或LLM输出等平台获取的重用代码片段改编到其本地代码库中。这种改编的一个关键但尚未充分探索的方面是代码连接（code wiring），它涉及将粘贴代码中未解析的变量替换为来自周围上下文的合适变量。现有解决方案要么依赖启发式规则，要么依赖历史模板，尽管研究表明超过一半的改编案例是上下文相关的，但它们往往未能有效利用上下文信息。在本文中，我们引入了WIRL，一个基于LLM的代理，用于代码连接，其被框架为检索增强生成（RAG）填充任务。WIRL结合了一个LLM、一个定制工具包和一个编排模块，以识别未解析变量、检索上下文并执行上下文感知替换。为了平衡效率和自主性，该代理采用混合策略：对于常见模式采用确定性规则，对于智能探索采用状态机引导的决策过程。我们在一个精心策划的、高质量的数据集上评估了WIRL，该数据集包含真实世界的代码适应场景。我们的方法实现了91.7%的精确匹配精度和90.0%的召回率，在精确度和召回率上分别优于先进的LLM 22.6和13.7个百分点，并超越IntelliJ IDEA 54.3和49.9个百分点。这些结果强调了其实用性，特别是在具有复杂变量依赖或多个未解析变量的上下文中。我们相信WIRL为现代IDE中更智能、上下文感知的开发者协助铺平了道路。", "summary": "本文介绍了WIRL，一个基于大型语言模型（LLM）的代理，旨在解决软件开发中“复制-粘贴-修改”实践中的代码连接问题。WIRL将此任务构建为检索增强生成（RAG），结合LLM、定制工具包和编排模块，以实现上下文感知的变量替换。通过混合策略（确定性规则与状态机引导决策），WIRL在真实数据集上表现出色，其精确匹配精度和召回率均显著优于现有LLM和IDE，证明了其在提供智能上下文感知开发者协助方面的巨大潜力。", "keywords": "代码连接, LLM代理, 上下文感知, 检索增强生成, 开发者协助", "comments": "WIRL的创新之处在于将代码连接问题框架为RAG任务，并结合了LLM的能力与定制工具和混合策略，有效解决了现有方法在利用上下文信息方面的不足。其在真实世界数据集上的显著性能提升，特别是对复杂变量依赖的处理能力，使其在开发者工具领域具有重要的实用价值。"}}
{"id": "2507.01118", "title": "Quasi-twisted codes: decoding and applications in code-based cryptography", "authors": ["Bhagyalekshmy S", "Rutuja Kshirsagar"], "summary": "Quasi-twisted (QT) codes generalize several important families of linear\ncodes, including cyclic, constacyclic, and quasi-cyclic codes. Despite their\npotential, to the best of our knowledge, there exists no efficient decoding\nalgorithm for QT codes. In this work, we propose a syndrome-based decoding\nmethod capable of efficiently correcting up to (d* - 1)/2 errors, where d*\ndenotes an HT-like lower bound on the minimum distance of QT codes, which we\nformalize here. Additionally, we introduce a Niederreiter-like cryptosystem\nconstructed from QT codes. This cryptosystem is resistant to some classical\nattacks as well as some quantum attacks based on Quantum Fourier Sampling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01118v1", "categories": ["cs.CR", "cs.IT", "math.IT"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01118v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "准扭曲码：解码及其在基于码的密码学中的应用", "tldr": "本文提出了一种准扭曲码的高效解码算法，并基于此构建了一个抗经典和量子攻击的密码系统。", "motivation": "尽管准扭曲码（QT码）概括了多种重要的线性码家族并具有潜在的应用价值，但目前尚缺乏高效的解码算法。", "method": "本文提出了一种基于伴随式（syndrome-based）的解码方法，并基于准扭曲码构建了一个类Niederreiter密码系统。", "result": "所提出的解码方法能够有效纠正多达 (d* - 1)/2 个错误，其中 d* 是准扭曲码最小距离的HT类下界，并在此文中被形式化。所构建的密码系统能够抵抗某些经典攻击以及基于量子傅里叶采样的量子攻击。", "conclusion": "本文成功提出了一种高效的准扭曲码解码算法，并在此基础上构建了一个能够抵抗经典和量子攻击的类Niederreiter密码系统，扩展了准扭曲码在密码学领域的应用。", "translation": "准扭曲（QT）码概括了几个重要的线性码家族，包括循环码、常循环码和准循环码。尽管它们具有潜力，但据我们所知，目前还没有针对QT码的有效解码算法。在这项工作中，我们提出了一种基于伴随式的解码方法，能够有效纠正多达 (d* - 1)/2 个错误，其中 d* 表示QT码最小距离的类HT下界，我们在此对其进行了形式化。此外，我们引入了一种由QT码构建的类Niederreiter密码系统。该密码系统能够抵抗一些经典攻击以及一些基于量子傅里叶采样的量子攻击。", "summary": "本文旨在解决准扭曲码（QT码）缺乏高效解码算法的问题。研究人员提出了一种新的基于伴随式的解码方法，该方法能够有效纠正高达 (d* - 1)/2 个错误，并形式化了QT码最小距离的HT类下界d*。此外，研究还基于QT码设计了一种类Niederreiter密码系统，该系统被证明能够抵抗某些经典攻击和基于量子傅里叶采样的量子攻击，从而扩展了QT码在密码学领域的应用。", "keywords": "准扭曲码, 解码算法, 基于码的密码学, 后量子密码学, 纠错码", "comments": "这篇论文的创新点在于首次提出了准扭曲码的有效解码算法，填补了该领域的一个空白。其重要性体现在不仅提供了理论上的解码方法，还将其应用于构建新的密码系统，并证明了其对经典和量子攻击的抵抗能力，这对于后量子密码学具有潜在意义。"}}
{"id": "2507.01333", "title": "Multi-User Generative Semantic Communication with Intent-Aware Semantic-Splitting Multiple Access", "authors": ["Jiayi Lu", "Wanting Yang", "Zehui Xiong", "Rahim Tafazolli", "Tony Q. S. Quek", "Mérouane Debbah", "Dong In Kim"], "summary": "With the booming development of generative artificial intelligence (GAI),\nsemantic communication (SemCom) has emerged as a new paradigm for reliable and\nefficient communication. This paper considers a multi-user downlink SemCom\nsystem, using vehicular networks as the representative scenario for multi-user\ncontent dissemination. To address diverse yet overlapping user demands, we\npropose a multi-user Generative SemCom-enhanced intent-aware semantic-splitting\nmultiple access (SS-MGSC) framework. In the framework, we construct an\nintent-aware shared knowledge base (SKB) that incorporates prior knowledge of\nsemantic information (SI) and user-specific preferences. Then, we designate the\ncommon SI as a one-hot semantic map that is broadcast to all users, while the\nprivate SI is delivered as personalized text for each user. On the receiver\nside, a diffusion model enhanced with ControlNet is adopted to generate\nhigh-quality personalized images. To capture both semantic relevance and\nperceptual similarity, we design a novel semantic efficiency score (SES) metric\nas the optimization objective. Building on this, we formulate a joint\noptimization problem for multi-user semantic extraction and beamforming, solved\nusing a reinforcement learning-based algorithm due to its robustness in\nhigh-dimensional settings. Simulation results demonstrate the effectiveness of\nthe proposed scheme.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01333v1", "categories": ["cs.NI", "cs.IT", "math.IT"], "cate": "cs.NI", "url": "http://arxiv.org/abs/2507.01333v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "多用户生成式语义通信与意图感知语义分割多址接入", "tldr": "提出一种多用户生成式语义通信框架SS-MGSC，通过意图感知语义分割和扩散模型，解决多用户场景下个性化内容的高效传输问题。", "motivation": "解决多用户下行语义通信系统中多样化且重叠的用户需求，实现可靠高效的内容分发。", "method": "提出SS-MGSC框架，构建意图感知共享知识库；将公共语义信息广播为one-hot语义图，私有语义信息作为个性化文本传输；接收端采用ControlNet增强的扩散模型生成图像；设计语义效率分数（SES）作为优化目标；通过强化学习算法解决语义提取和波束成形的联合优化问题。", "result": "仿真结果表明所提方案的有效性。", "conclusion": "该论文提出的SS-MGSC框架能有效处理多用户场景下的多样化和重叠需求，实现高效的生成式语义通信。", "translation": "随着生成式人工智能（GAI）的蓬勃发展，语义通信（SemCom）已成为一种可靠高效通信的新范式。本文考虑一个多用户下行语义通信系统，以车载网络作为多用户内容传播的代表性场景。为了解决多样化但重叠的用户需求，我们提出了一种多用户生成式语义通信增强型意图感知语义分割多址接入（SS-MGSC）框架。在该框架中，我们构建了一个意图感知共享知识库（SKB），其中包含语义信息（SI）的先验知识和用户特定偏好。然后，我们将公共语义信息指定为广播给所有用户的one-hot语义图，而私有语义信息则作为个性化文本传递给每个用户。在接收端，采用ControlNet增强的扩散模型生成高质量的个性化图像。为了捕获语义相关性和感知相似性，我们设计了一种新颖的语义效率分数（SES）度量作为优化目标。在此基础上，我们提出了一个多用户语义提取和波束成形的联合优化问题，并由于其在高维设置中的鲁棒性，使用基于强化学习的算法进行求解。仿真结果表明了所提方案的有效性。", "summary": "本文针对多用户下行语义通信系统，特别是车载网络场景中多样化且重叠的用户需求，提出了一种名为SS-MGSC的多用户生成式语义通信增强型意图感知语义分割多址接入框架。该框架通过构建意图感知共享知识库，区分并传输公共和私有语义信息。在接收端，利用ControlNet增强的扩散模型生成个性化图像。为优化性能，引入语义效率分数（SES）作为目标，并通过强化学习算法解决语义提取和波束成形的联合优化问题。仿真结果验证了所提方案的有效性。", "keywords": "语义通信, 生成式AI, 多用户, 意图感知, 语义分割多址接入", "comments": "该论文创新性地将生成式AI技术（扩散模型、ControlNet）引入多用户语义通信，并通过意图感知语义分割和强化学习优化，以解决个性化内容分发中的多样化需求，为未来通信系统提供了新的思路。"}}
{"id": "2507.01163", "title": "cp_measure: API-first feature extraction for image-based profiling workflows", "authors": ["Alán F. Muñoz", "Tim Treis", "Alexandr A. Kalinin", "Shatavisha Dasgupta", "Fabian Theis", "Anne E. Carpenter", "Shantanu Singh"], "summary": "Biological image analysis has traditionally focused on measuring specific\nvisual properties of interest for cells or other entities. A complementary\nparadigm gaining increasing traction is image-based profiling - quantifying\nmany distinct visual features to form comprehensive profiles which may reveal\nhidden patterns in cellular states, drug responses, and disease mechanisms.\nWhile current tools like CellProfiler can generate these feature sets, they\npose significant barriers to automated and reproducible analyses, hindering\nmachine learning workflows. Here we introduce cp_measure, a Python library that\nextracts CellProfiler's core measurement capabilities into a modular, API-first\ntool designed for programmatic feature extraction. We demonstrate that\ncp_measure features retain high fidelity with CellProfiler features while\nenabling seamless integration with the scientific Python ecosystem. Through\napplications to 3D astrocyte imaging and spatial transcriptomics, we showcase\nhow cp_measure enables reproducible, automated image-based profiling pipelines\nthat scale effectively for machine learning applications in computational\nbiology.", "comment": "10 pages, 4 figures, 4 supplementary figures. CODEML Workshop paper\n  accepted (non-archival), as a part of ICML2025 events", "pdf_url": "http://arxiv.org/pdf/2507.01163v1", "categories": ["cs.CV", "q-bio.CB", "q-bio.QM", "I.4.7"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01163v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "cp_measure：面向API的图像分析工作流特征提取工具", "tldr": "cp_measure是一个Python库，它将CellProfiler的核心测量能力提取出来，作为一个模块化、API优先的工具，用于图像分析工作流中的特征提取，解决了现有工具自动化和可重复性差的问题。", "motivation": "现有的图像分析工具（如CellProfiler）虽然能生成特征集，但在自动化和可重复性分析方面存在显著障碍，阻碍了机器学习工作流。", "method": "引入了cp_measure，一个Python库，它将CellProfiler的核心测量能力提取成一个模块化、API优先的工具，专为程序化特征提取而设计。", "result": "cp_measure提取的特征与CellProfiler的特征保持高度一致性，并能与科学Python生态系统无缝集成。通过在3D星形胶质细胞成像和空间转录组学中的应用，展示了其支持可重复、自动化图像分析管道的能力，并能有效扩展用于计算生物学中的机器学习应用。", "conclusion": "cp_measure通过提供一个模块化、API优先的特征提取工具，解决了图像分析中自动化和可重复性的挑战，从而提升了计算生物学中机器学习工作流的效率和可扩展性。", "translation": "生物图像分析传统上侧重于测量细胞或其他实体的特定视觉属性。一种日益受到关注的补充范式是基于图像的分析——量化许多不同的视觉特征，形成全面的特征图谱，这可能揭示细胞状态、药物反应和疾病机制中隐藏的模式。虽然CellProfiler等现有工具可以生成这些特征集，但它们对自动化和可重复分析构成了重大障碍，阻碍了机器学习工作流。在此，我们介绍了cp_measure，一个Python库，它将CellProfiler的核心测量功能提取为一个模块化、API优先的工具，专为程序化特征提取而设计。我们证明了cp_measure特征与CellProfiler特征保持高度一致性，同时实现了与科学Python生态系统的无缝集成。通过在3D星形胶质细胞成像和空间转录组学中的应用，我们展示了cp_measure如何实现可重复、自动化的基于图像的分析管道，这些管道可以有效地扩展用于计算生物学中的机器学习应用。", "summary": "cp_measure是一个新的Python库，旨在解决现有生物图像分析工具在自动化和可重复性方面的限制。它将CellProfiler的核心测量功能提取并模块化，提供了一个API优先的特征提取工具。该工具能生成与CellProfiler高度一致的特征，并无缝集成到Python生态系统，从而支持可扩展的、自动化的图像分析工作流，特别适用于计算生物学中的机器学习应用。", "keywords": "图像分析, 特征提取, API优先, CellProfiler, 机器学习", "comments": "cp_measure的创新之处在于其API优先的设计理念，这极大地提升了生物图像分析工作流的自动化和可重复性。通过将CellProfiler的核心功能解耦，它允许开发者和研究人员更灵活地构建自定义管道，并与更广泛的Python科学计算生态系统集成，从而加速了基于图像的机器学习研究。"}}
{"id": "2507.01284", "title": "VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process", "authors": ["Cristian Gariboldi", "Hayato Tokida", "Ken Kinjo", "Yuki Asada", "Alexander Carballo"], "summary": "Recent advancements in open-source Visual Language Models (VLMs) such as\nLLaVA, Qwen-VL, and Llama have catalyzed extensive research on their\nintegration with diverse systems. The internet-scale general knowledge\nencapsulated within these models presents significant opportunities for\nenhancing autonomous driving perception, prediction, and planning capabilities.\nIn this paper we propose VLAD, a vision-language autonomous driving model,\nwhich integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end\nsystem. We implement a specialized fine-tuning approach using custom\nquestion-answer datasets designed specifically to improve the spatial reasoning\ncapabilities of the model. The enhanced VLM generates high-level navigational\ncommands that VAD subsequently processes to guide vehicle operation.\nAdditionally, our system produces interpretable natural language explanations\nof driving decisions, thereby increasing transparency and trustworthiness of\nthe traditionally black-box end-to-end architecture. Comprehensive evaluation\non the real-world nuScenes dataset demonstrates that our integrated system\nreduces average collision rates by 31.82% compared to baseline methodologies,\nestablishing a new benchmark for VLM-augmented autonomous driving systems.", "comment": "2025 IEEE 28th International Conference on Intelligent Transportation\n  Systems (ITSC)", "pdf_url": "http://arxiv.org/pdf/2507.01284v1", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.ET", "cs.LG"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01284v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "VLAD：一种具有分层规划和可解释决策过程的VLM增强型自动驾驶框架", "tldr": "VLAD是一个将微调VLM与VAD集成的自动驾驶框架，通过定制数据集增强空间推理能力，生成可解释的决策，并在nuScenes数据集上显著降低了碰撞率。", "motivation": "开放源代码视觉语言模型（VLMs）的最新进展，如LLaVA、Qwen-VL和Llama，为增强自动驾驶的感知、预测和规划能力提供了巨大潜力。本研究旨在利用VLM的互联网规模通用知识，并解决传统端到端系统缺乏透明度的问题。", "method": "本文提出了VLAD，一个视觉语言自动驾驶模型，它将一个微调的VLM与最先进的端到端系统VAD集成。通过使用专门设计的定制问答数据集进行微调，以提高模型的空间推理能力。增强后的VLM生成高级导航指令，供VAD处理以引导车辆操作。此外，系统还生成可解释的自然语言驾驶决策解释。", "result": "在真实世界的nuScenes数据集上的综合评估表明，VLAD系统与基线方法相比，平均碰撞率降低了31.82%。", "conclusion": "VLAD模型在VLM增强型自动驾驶系统方面建立了新的基准，并通过提供可解释的自然语言决策，显著提高了传统黑盒端到端架构的透明度和可信度。", "translation": "开放源代码视觉语言模型（VLMs）如LLaVA、Qwen-VL和Llama的最新进展，推动了它们与各种系统集成的广泛研究。这些模型中封装的互联网规模通用知识为增强自动驾驶的感知、预测和规划能力提供了重大机遇。在本文中，我们提出了VLAD，一个视觉语言自动驾驶模型，它将一个微调的VLM与最先进的端到端系统VAD集成。我们采用了一种专门的微调方法，使用专门设计用于提高模型空间推理能力的定制问答数据集。增强后的VLM生成高级导航指令，供VAD后续处理以引导车辆操作。此外，我们的系统还生成可解释的自然语言驾驶决策解释，从而增加了传统黑盒端到端架构的透明度和可信度。在真实世界的nuScenes数据集上的综合评估表明，我们的集成系统与基线方法相比，平均碰撞率降低了31.82%，为VLM增强型自动驾驶系统建立了新的基准。", "summary": "VLAD是一个结合了微调VLM和VAD的自动驾驶框架。它通过定制问答数据集增强VLM的空间推理能力，使其能够生成高级导航指令和可解释的自然语言决策。在nuScenes数据集上的评估显示，VLAD显著降低了碰撞率，并提升了自动驾驶系统的透明度。", "keywords": "视觉语言模型, 自动驾驶, 分层规划, 可解释性, VLM-增强", "comments": "VLAD的创新之处在于其将先进的视觉语言模型与自动驾驶系统深度融合，并通过定制微调提升了VLM的空间推理能力。更重要的是，它解决了传统端到端自动驾驶系统缺乏可解释性的问题，通过生成自然语言的决策解释，显著增强了系统的透明度和用户信任。在真实世界数据集上的显著性能提升（碰撞率降低31.82%）也证明了其有效性和实用价值，为未来VLM在自动驾驶领域的应用开辟了新路径。"}}
{"id": "2507.01134", "title": "Animated Visual Encoding and Layer Blending for Identification of Educational Game Strategies", "authors": ["Braden Roper", "William Thompson", "Chris Weaver"], "summary": "Game-Based Learning has proven to be an effective method for enhancing\nengagement with educational material. However, gaining a deeper understanding\nof player strategies remains challenging. Sequential game-state and\naction-based tracking tools often gather extensive data that can be difficult\nto interpret as long-term strategy. This data presents unique problems to\nvisualization, as it can be fairly natural, noisy data but is constrained\nwithin synthetic, controlled environments, leading to issues such as\noverplotting which can make interpretation complicated. We propose an animated\nvisual encoding tool that utilizes kinetic visualization to address these\nissues. This tool enables researchers to construct animated data narratives\nthrough the configuration of parameter interpolation curves and blending\nlayers. Finally, we demonstrate the usefulness of the tool while addressing\nspecific interests as outlined by a domain expert collaborator.", "comment": "To be published in IEEE Visualization and Visual Analytics (VIS),\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.01134v1", "categories": ["cs.HC"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01134v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "动画视觉编码与图层混合用于识别教育游戏策略", "tldr": "提出了一种动画可视化工具，通过解决噪音数据和过度绘制等挑战来分析教育游戏策略。", "motivation": "游戏化学习中，由于顺序性游戏数据量大、噪音多且受限于合成环境，导致过度绘制和难以解释长期玩家策略，从而难以深入理解玩家行为。", "method": "提出了一种动画视觉编码工具，利用动态可视化技术，使研究人员能够通过配置参数插值曲线和混合图层来构建动画数据叙事。", "result": "该工具在解决领域专家合作者提出的特定兴趣方面展示了其有效性。", "conclusion": "该工具能够有效帮助研究人员理解教育游戏策略。", "translation": "游戏化学习已被证明是增强教育材料参与度的有效方法。然而，深入理解玩家策略仍然具有挑战性。基于顺序游戏状态和动作的跟踪工具通常会收集大量数据，这些数据很难被解释为长期策略。这些数据给可视化带来了独特的问题，因为它们可能是相当自然、嘈杂的数据，但又受限于合成、受控的环境中，导致诸如过度绘制等问题，使解释变得复杂。我们提出了一种利用动态可视化来解决这些问题的动画视觉编码工具。该工具使研究人员能够通过配置参数插值曲线和混合图层来构建动画数据叙事。最后，我们展示了该工具在解决领域专家合作者提出的特定兴趣方面的实用性。", "summary": "本文提出了一种动画视觉编码工具，该工具利用动态可视化和图层混合技术，旨在帮助研究人员分析教育游戏中的玩家策略。它解决了处理大量、嘈杂的顺序游戏数据时面临的挑战，特别是过度绘制问题。通过配置参数插值曲线和混合图层，该工具能够创建动画数据叙事。研究人员与领域专家合作，展示了该工具在满足特定分析需求方面的实用性。", "keywords": "教育游戏, 游戏化学习, 视觉编码, 数据可视化, 玩家策略", "comments": "该研究的创新之处在于利用动画动态可视化和图层混合技术来解决顺序游戏数据分析中常见的可视化问题（如噪音数据和过度绘制），为理解长期策略提供了一种动态有效的方法。与领域专家的合作进一步突显了其实用价值。"}}
{"id": "2507.01028", "title": "Dual Perspectives on Non-Contrastive Self-Supervised Learning", "authors": ["Jean Ponce", "Martial Hebert", "Basile Terver"], "summary": "The objective of non-contrastive approaches to self-supervised learning is to\ntrain on pairs of different views of the data an encoder and a predictor that\nminimize the mean discrepancy between the code predicted from the embedding of\nthe first view and the embedding of the second one. In this setting, the stop\ngradient and exponential moving average iterative procedures are commonly used\nto avoid representation collapse, with excellent performance in downstream\nsupervised applications. This presentation investigates these procedures from\nthe dual theoretical viewpoints of optimization and dynamical systems. We first\nshow that, in general, although they do not optimize the original objective, or\nfor that matter, any other smooth function, they do avoid collapse. Following\nTian et al. [2021], but without any of the extra assumptions used in their\nproofs, we then show using a dynamical system perspective that, in the linear\ncase, minimizing the original objective function without the use of a stop\ngradient or exponential moving average always leads to collapse. Conversely, we\nfinally show that the limit points of the dynamical systems associated with\nthese two procedures are, in general, asymptotically stable equilibria, with no\nrisk of degenerating to trivial solutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01028v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01028v1", "date": "2025-06-18", "updated": "2025-06-18", "AI": {"title_translation": "非对比自监督学习的双重视角", "tldr": "本文从优化和动力系统双重视角理论分析了非对比自监督学习中停止梯度和指数移动平均方法，解释了它们为何能避免表示坍塌，并证明了其稳定性。", "motivation": "非对比自监督学习中，停止梯度和指数移动平均是避免表示坍塌的关键技术，且在下游任务中表现优异。本文旨在从理论层面深入理解这些方法的有效性及其避免坍塌的机制。", "method": "本文从优化和动力系统两个理论视角研究了非对比自监督学习中常用的停止梯度和指数移动平均迭代过程。首先，分析了这些过程与原始目标函数优化的关系。其次，在没有额外假设的情况下，利用动力系统视角证明了在线性情况下，不使用这些方法会导致坍塌。最后，证明了这些过程相关联的动力系统的极限点是渐近稳定的平衡点。", "result": "1. 停止梯度和指数移动平均方法虽然不优化原始目标函数或其他任何平滑函数，但能有效避免表示坍塌。2. 在线性情况下，不使用停止梯度或指数移动平均来最小化原始目标函数总会导致坍塌。3. 这些方法关联的动力系统的极限点是渐近稳定的平衡点，不会退化为平凡解。", "conclusion": "本文通过优化和动力系统双重视角，从理论上揭示了非对比自监督学习中停止梯度和指数移动平均方法避免表示坍塌的机制及其内在的稳定性，为这些高效实践提供了坚实的理论基础。", "translation": "非对比自监督学习的目标是：在数据不同视图对上训练一个编码器和一个预测器，以最小化从第一个视图的嵌入预测的代码与第二个视图的嵌入之间的平均差异。在这种设置中，通常使用停止梯度和指数移动平均迭代过程来避免表示坍塌，并在下游监督应用中表现出色。本演示文稿从优化和动力系统两个理论视角来研究这些过程。我们首先表明，一般而言，尽管它们不优化原始目标，或者任何其他平滑函数，但它们确实避免了坍塌。遵循 Tian 等人 [2021] 的工作，但没有使用他们证明中任何额外的假设，我们然后使用动力系统视角表明，在线性情况下，不使用停止梯度或指数移动平均来最小化原始目标函数总是会导致坍塌。反之，我们最终表明，与这两个过程相关联的动力系统的极限点通常是渐近稳定的平衡点，没有退化为平凡解的风险。", "summary": "本文从优化和动力系统双重视角，理论分析了非对比自监督学习中停止梯度和指数移动平均（EMA）方法。研究表明，尽管这些方法不直接优化原始目标函数，但它们能有效避免表示坍塌。论文进一步证明，在缺乏这些机制的情况下，原始目标函数的最小化会导致坍塌；而引入停止梯度和EMA后，系统会收敛到渐近稳定的非平凡解。这为非对比自监督学习的有效性提供了坚实的理论支撑。", "keywords": "非对比自监督学习, 停止梯度, 指数移动平均, 表示坍塌, 动力系统", "comments": "本文的创新之处在于，它首次从优化和动力系统双重视角，在不依赖额外假设的情况下，对非对比自监督学习中停止梯度和指数移动平均的有效性提供了深入的理论解释。这对于理解这些高效的自监督学习策略为何能成功避免表示坍塌，并确保收敛到有意义的解具有重要意义，填补了实践与理论理解之间的空白。"}}
{"id": "2507.01701", "title": "Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture", "authors": ["Bochen Han", "Songmao Zhang"], "summary": "In this paper, we propose to incorporate the blackboard architecture into LLM\nmulti-agent systems (MASs) so that (1) agents with various roles can share all\nthe information and others' messages during the whole problem-solving process,\n(2) agents that will take actions are selected based on the current content of\nthe blackboard, and (3) the selection and execution round is repeated until a\nconsensus is reached on the blackboard. We develop the first implementation of\nthis proposal and conduct experiments on commonsense knowledge, reasoning and\nmathematical datasets. The results show that our system can be competitive with\nthe SOTA static and dynamic MASs by achieving the best average performance, and\nat the same time manage to spend less tokens. Our proposal has the potential to\nenable complex and dynamic problem-solving where well-defined structures or\nworkflows are unavailable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01701v1", "categories": ["cs.MA", "cs.AI"], "cate": "cs.MA", "url": "http://arxiv.org/abs/2507.01701v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于黑板架构的先进大型语言模型多智能体系统探索", "tldr": "提出将黑板架构引入LLM多智能体系统，实现信息共享、动态智能体选择和迭代求解，在实验中表现优于SOTA系统且更节省token。", "motivation": "现有的LLM多智能体系统可能在信息共享、动态决策和复杂问题解决方面存在局限性，本研究旨在通过引入黑板架构来提升其性能和灵活性。", "method": "本文提出将黑板架构整合到LLM多智能体系统（MASs）中，以实现：1) 具有不同角色的智能体在整个问题解决过程中共享所有信息和消息；2) 根据黑板的当前内容选择将要执行操作的智能体；3) 重复选择和执行回合直到黑板上达成共识。研究者开发了该提案的首个实现，并进行了实验。", "result": "实验结果表明，该系统在常识知识、推理和数学数据集上，能与SOTA静态和动态MASs相媲美，取得了最佳平均性能，同时消耗了更少的token。", "conclusion": "该提案有望在缺乏明确结构或工作流的情况下，实现复杂和动态的问题解决。", "translation": "在本文中，我们提出将黑板架构融入大型语言模型（LLM）多智能体系统（MASs）中，以便：(1) 具有各种角色的智能体在整个问题解决过程中可以共享所有信息和彼此的消息；(2) 根据黑板的当前内容选择将要采取行动的智能体；(3) 重复选择和执行回合，直到在黑板上达成共识。我们开发了该提案的首次实现，并在常识知识、推理和数学数据集上进行了实验。结果表明，我们的系统可以与最先进（SOTA）的静态和动态MASs竞争，实现最佳平均性能，同时管理消耗更少的token。我们的提案有潜力在缺乏明确结构或工作流的情况下，实现复杂和动态的问题解决。", "summary": "本文提出将黑板架构集成到LLM多智能体系统中，以增强智能体间的信息共享、实现基于黑板内容的动态智能体选择以及迭代的问题解决过程。该系统在常识、推理和数学数据集上进行了实验验证，结果显示其性能优于现有SOTA系统，且能有效节省计算资源（token）。这项工作为解决缺乏预定义结构或工作流的复杂动态问题提供了新的途径。", "keywords": "LLM多智能体系统, 黑板架构, 信息共享, 动态问题解决, Token效率", "comments": "该论文通过引入经典的黑板架构到LLM多智能体系统中，有效地解决了现有系统中信息共享不足和动态决策能力弱的问题。其创新点在于将黑板作为中央信息库和控制机制，实现了智能体间的解耦协作和自适应问题解决。实验结果证明了其在性能和效率上的优势，为未来构建更灵活、更强大的LLM多智能体系统提供了有价值的参考。特别是在处理开放式或结构不明确的复杂任务时，这种架构的潜力巨大。"}}
{"id": "2507.01481", "title": "Mapping the interaction between science and misinformation in COVID-19 tweets", "authors": ["Lucila G. Alvarez-Zuzek", "Juan P. Bascur", "Anna Bertani", "Riccardo Gallotti", "Vincent A. Traag"], "summary": "During the COVID-19 pandemic, scientific understanding related to the topic\nevolved rapidly. Along with scientific information being discussed widely, a\nlarge circulation of false information, labelled an infodemic by the WHO,\nemerged. Here, we study the interaction between misinformation and science on\nTwitter (now X) during the COVID-19 pandemic. We built a comprehensive database\nof $\\sim$407M COVID-19 related tweets and classified the reliability of URLs in\nthe tweets based on Media Bias/Fact Check. In addition, we use Altmetric data\nto see whether a tweet refers to a scientific publication. We find that many\nusers find that many users share both scientific and unreliable content; out of\nthe $\\sim$1.2M users who share science, $45\\%$ also share unreliable content.\nPublications that are more frequently shared by users who also share unreliable\ncontent are more likely to be preprints, slightly more often retracted, have\nfewer citations, and are published in lower-impact journals on average. Our\nfindings suggest that misinformation is not related to a ``deficit'' of\nscience. In addition, our findings raise some critical questions about certain\nopen science practices and their potential for misuse. Given the fundamental\nopposition between science and misinformation, our findings highlight the\nnecessity for proactive scientific engagement on social media platforms to\ncounter false narratives during global crises.", "comment": "25 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.01481v1", "categories": ["physics.soc-ph", "cs.SI"], "cate": "physics.soc-ph", "url": "http://arxiv.org/abs/2507.01481v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "绘制COVID-19推文中科学与错误信息之间的互动图谱", "tldr": "在COVID-19期间，许多推特用户同时分享科学和错误信息。那些同时分享错误信息的用户所分享的科学内容，往往是预印本、被撤回的、引用较少且发表在影响力较低期刊上的。错误信息并非源于科学的“缺失”，这凸显了在社交媒体上积极进行科学宣传的必要性。", "motivation": "在COVID-19大流行期间，科学理解迅速发展，同时大量虚假信息（即“信息疫情”）广泛传播。本研究旨在探讨COVID-19大流行期间推特上错误信息与科学之间的互动。", "method": "研究人员建立了一个包含约4.07亿条COVID-19相关推文的综合数据库，并根据“媒体偏见/事实核查”对推文中的URL可靠性进行分类。此外，利用Altmetric数据来识别提及科学出版物的推文。", "result": "研究发现，许多用户同时分享科学内容和不可靠内容；在约120万分享科学内容的用户中，有45%也分享了不可靠内容。同时分享不可靠内容的用户更频繁分享的出版物，更有可能是预印本，被撤回的次数略多，引用次数更少，并且平均发表在影响力较低的期刊上。研究结果表明，错误信息与科学的“缺失”无关。", "conclusion": "研究结果表明，错误信息并非源于科学信息的不足。此外，这些发现对某些开放科学实践及其潜在的滥用提出了关键问题，并强调在全球危机期间，在社交媒体平台上积极进行科学参与以对抗虚假叙述的必要性。", "translation": "在COVID-19大流行期间，与该主题相关的科学理解迅速发展。在科学信息被广泛讨论的同时，大量虚假信息（被世卫组织称为“信息疫情”）也随之出现。在此，我们研究了COVID-19大流行期间推特（现为X）上错误信息与科学之间的互动。我们建立了一个包含约4.07亿条COVID-19相关推文的综合数据库，并根据“媒体偏见/事实核查”对推文中的URL可靠性进行了分类。此外，我们使用Altmetric数据来查看推文是否引用了科学出版物。我们发现许多用户同时分享科学内容和不可靠内容；在约120万分享科学内容的用户中，有45%也分享了不可靠内容。那些更频繁地被同时分享不可靠内容的用户分享的出版物，更有可能是预印本，被撤回的次数略多，引用次数更少，并且平均发表在影响力较低的期刊上。我们的研究结果表明，错误信息与科学的“缺失”无关。此外，我们的研究结果对某些开放科学实践及其潜在的滥用提出了一些关键问题。鉴于科学与错误信息之间的根本对立，我们的研究结果强调了在全球危机期间，在社交媒体平台上积极参与科学活动以对抗虚假叙述的必要性。", "summary": "本文探讨了COVID-19大流行期间推特上科学信息与错误信息之间的互动。通过分析大量推文数据并分类URL可靠性和科学引用，研究发现，相当一部分用户同时分享科学内容和不可靠内容。研究还揭示，那些同时传播错误信息的用户所分享的科学出版物，往往是预印本、引用较少且来自影响力较低的期刊。研究结论指出，错误信息并非简单地源于科学信息的缺乏，而是凸显了某些开放科学实践存在的问题，并强调了在社交媒体上积极进行科学参与以对抗虚假叙述的重要性。", "keywords": "COVID-19, 错误信息, 科学传播, 社交媒体, 推特", "comments": "本文提供了一个新颖的视角，表明错误信息并非仅仅是“科学的缺失”，而是与科学共享共同存在，甚至由同一用户分享。发现错误信息传播者分享的出版物倾向于预印本或来自影响力较低的期刊，这一发现特别有见地，对预出版科学的传播和某些开放科学实践中的质量控制提出了重要问题。其强调积极进行科学参与是对抗信息疫情的关键建议。"}}
{"id": "2507.01286", "title": "Pursuing the limit of chirp parameter identifiability: A computational approach", "authors": ["Zai Yang", "Sikai Ge", "Wenlong Wang"], "summary": "In this paper, it is shown that a necessary condition for unique\nidentifiability of $K$ chirps from $N$ regularly spaced samples of their\nmixture is $N\\geq 2K$ when $K\\geq 2$. A necessary and sufficient condition is\nthat a rank-constrained matrix optimization problem has a unique solution; this\nis the first result of such kind. An algorithm is proposed to solve the\noptimization problem and to identify the parameters numerically. The lower\nbound of $N=2K$ is shown to be tight by providing diverse problem instances for\nwhich the proposed algorithm succeeds to identify the parameters. The\nadvantageous performance of the proposed algorithm is also demonstrated\ncompared with the state of the art.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.01286v1", "categories": ["eess.SP"], "cate": "eess.SP", "url": "http://arxiv.org/abs/2507.01286v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "追求线性调频参数可识别性的极限：一种计算方法", "tldr": "本文提出了识别K个线性调频信号的参数的必要和充分条件，即N≥2K，并通过一个秩约束矩阵优化问题及其算法实现了参数的唯一识别，并证明了其有效性。", "motivation": "研究K个线性调频信号混合物的参数可识别性问题，特别是寻找其唯一可识别性的必要和充分条件。", "method": "提出并解决了一个秩约束矩阵优化问题，以实现线性调频参数的唯一识别。同时，提出了一种算法来数值求解该优化问题并识别参数。", "result": "当K≥2时，从N个等间距样本中唯一识别K个线性调频信号的必要条件是N≥2K。唯一可识别性的必要和充分条件是秩约束矩阵优化问题具有唯一解。所提出的算法成功识别了参数，并且N=2K的下限被证明是紧密的。与现有技术相比，该算法表现出优越的性能。", "conclusion": "本文确定了K个线性调频信号参数唯一可识别性的必要和充分条件，并提出了一种有效的计算方法和算法来解决这一问题，达到了理论上的紧密下限和实际应用中的优越性能。", "translation": "本文表明，当K≥2时，从N个等间距的混合样本中唯一识别K个线性调频信号的必要条件是N≥2K。一个必要和充分条件是秩约束矩阵优化问题具有唯一解；这是此类别的第一个结果。本文提出了一种算法来解决该优化问题并数值识别参数。通过提供各种问题实例，证明了所提出的算法成功识别了参数，从而表明N=2K的下限是紧密的。与现有技术相比，所提出的算法的优势性能也得到了证明。", "summary": "本文探讨了从其混合物中唯一识别K个线性调频信号参数的条件。研究表明，当K≥2时，识别的必要条件是样本数N≥2K。更重要的是，首次提出了一个必要和充分条件：一个秩约束矩阵优化问题具有唯一解。为此，文章提出了一种算法来解决该优化问题并数值识别参数。实验证明，N=2K的下限是紧密的，且所提出的算法在性能上优于现有技术。", "keywords": "线性调频参数识别, 秩约束矩阵优化, 必要充分条件, 算法, 下限", "comments": "本文的创新之处在于首次提出了线性调频参数唯一可识别性的必要和充分条件，将其转化为一个秩约束矩阵优化问题。此外，所提出的算法不仅实现了理论上紧密的N=2K下限，还在实际性能上超越了现有技术，这对于线性调频信号处理领域具有重要意义。"}}
{"id": "2507.01337", "title": "Dynamical Multimodal Fusion with Mixture-of-Experts for Localizations", "authors": ["Bohao Wang", "Zitao Shuai", "Fenghao Zhu", "Chongwen Huang", "Yongliang Shen", "Zhaoyang Zhang", "Qianqian Yang", "Sami Muhaidat", "Merouane Debbah"], "summary": "Multimodal fingerprinting is a crucial technique to sub-meter 6G integrated\nsensing and communications (ISAC) localization, but two hurdles block\ndeployment: (i) the contribution each modality makes to the target position\nvaries with the operating conditions such as carrier frequency, and (ii)\nspatial and fingerprint ambiguities markedly undermine localization accuracy,\nespecially in non-line-of-sight (NLOS) scenarios. To solve these problems, we\nintroduce SCADF-MoE, a spatial-context aware dynamic fusion network built on a\nsoft mixture-of-experts backbone. SCADF-MoE first clusters neighboring points\ninto short trajectories to inject explicit spatial context. Then, it adaptively\nfuses channel state information, angle of arrival profile, distance, and gain\nthrough its learnable MoE router, so that the most reliable cues dominate at\neach carrier band. The fused representation is fed to a modality-task MoE that\nsimultaneously regresses the coordinates of every vertex in the trajectory and\nits centroid, thereby exploiting inter-point correlations. Finally, an\nauxiliary maximum-mean-discrepancy loss enforces expert diversity and mitigates\ngradient interference, stabilizing multi-task training. On three real urban\nlayouts and three carrier bands (2.6, 6, 28 GHz), the model delivers consistent\nsub-meter MSE and halves unseen-NLOS error versus the best prior work. To our\nknowledge, this is the first work that leverages large-scale multimodal MoE for\nfrequency-robust ISAC localization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01337v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "cate": "cs.IT", "url": "http://arxiv.org/abs/2507.01337v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于专家混合模型的动态多模态融合定位", "tldr": "该论文提出SCADF-MoE，一个基于专家混合模型（MoE）的动态多模态融合网络，旨在提高6G集成传感与通信（ISAC）定位的精度，尤其是在非视距（NLOS）和多变工况下，实现了亚米级精度并使未见NLOS误差减半。", "motivation": "多模态指纹定位是实现亚米级6G集成传感与通信（ISAC）定位的关键技术，但面临两大部署障碍：1. 每种模态对目标位置的贡献随载波频率等操作条件变化；2. 空间和指纹模糊性显著损害定位精度，尤其是在非视距（NLOS）场景下。", "method": "为解决上述问题，本文引入了SCADF-MoE，一个基于软专家混合模型（soft Mixture-of-Experts）骨干的空间上下文感知动态融合网络。SCADF-MoE首先将相邻点聚类成短轨迹以注入显式空间上下文。然后，它通过可学习的MoE路由器自适应地融合信道状态信息、到达角剖面、距离和增益，使得最可靠的线索在每个载波频段占据主导地位。融合后的表示被馈送到一个模态-任务MoE，该MoE同时回归轨迹中每个顶点的坐标及其质心，从而利用点间相关性。最后，一个辅助的最大均值差异（MMD）损失强制专家多样性并减轻梯度干扰，稳定了多任务训练。", "result": "在三个真实的城市布局和三个载波频段（2.6、6、28 GHz）上，该模型提供了稳定的亚米级均方误差（MSE），并且与最佳现有工作相比，将未见非视距（unseen-NLOS）误差减半。", "conclusion": "据我们所知，这是首个利用大规模多模态专家混合模型实现频率鲁棒性ISAC定位的工作，有效解决了在不同操作条件和非视距场景下的挑战。", "translation": "多模态指纹定位是实现亚米级6G集成传感与通信（ISAC）定位的关键技术，但存在两大部署障碍：(i) 每种模态对目标位置的贡献随载波频率等操作条件而变化，以及 (ii) 空间和指纹模糊性显著损害定位精度，尤其是在非视距（NLOS）场景中。为了解决这些问题，我们引入了SCADF-MoE，一个基于软专家混合模型骨干的空间上下文感知动态融合网络。SCADF-MoE首先将相邻点聚类成短轨迹以注入显式空间上下文。然后，它通过其可学习的MoE路由器自适应地融合信道状态信息、到达角剖面、距离和增益，从而使最可靠的线索在每个载波频段占据主导地位。融合后的表示被馈送到一个模态-任务MoE，该MoE同时回归轨迹中每个顶点的坐标及其质心，从而利用点间相关性。最后，一个辅助的最大均值差异损失强制专家多样性并减轻梯度干扰，稳定了多任务训练。在三个真实的城市布局和三个载波频段（2.6、6、28 GHz）上，该模型提供了稳定的亚米级均方误差，并且与最佳现有工作相比，将未见非视距误差减半。据我们所知，这是首个利用大规模多模态MoE实现频率鲁棒性ISAC定位的工作。", "summary": "SCADF-MoE是一种新颖的动态多模态融合网络，它采用专家混合模型（MoE）架构来增强6G ISAC定位。该方法通过整合空间上下文、自适应融合多样传感器数据以及利用多任务MoE进行轨迹回归，解决了模态贡献变化和定位模糊性等挑战。SCADF-MoE在不同频段下实现了鲁棒的亚米级精度，并显著降低了非视距环境下的误差。", "keywords": "多模态融合, 专家混合模型, 定位, 6G ISAC, 非视距", "comments": "本文的创新点在于其SCADF-MoE架构，特别是利用软专家混合模型进行自适应多模态融合和空间上下文集成。将MoE应用于频率鲁棒性ISAC定位是一项重要贡献，尤其考虑到其在挑战性NLOS场景中的出色表现。此外，引入MMD损失以确保专家多样性也是一个巧妙的设计。"}}
{"id": "2507.01225", "title": "Capacity Planning and Scheduling for Jobs with Uncertainty in Resource Usage and Duration", "authors": ["Sunandita Patra", "Mehtab Pathan", "Mahmoud Mahfouz", "Parisa Zehtabi", "Wided Ouaja", "Daniele Magazzeni", "Manuela Veloso"], "summary": "Organizations around the world schedule jobs (programs) regularly to perform\nvarious tasks dictated by their end users. With the major movement towards\nusing a cloud computing infrastructure, our organization follows a hybrid\napproach with both cloud and on-prem servers. The objective of this work is to\nperform capacity planning, i.e., estimate resource requirements, and job\nscheduling for on-prem grid computing environments. A key contribution of our\napproach is handling uncertainty in both resource usage and duration of the\njobs, a critical aspect in the finance industry where stochastic market\nconditions significantly influence job characteristics. For capacity planning\nand scheduling, we simultaneously balance two conflicting objectives: (a)\nminimize resource usage, and (b) provide high quality-of-service to the end\nusers by completing jobs by their requested deadlines. We propose approximate\napproaches using deterministic estimators and pair sampling-based constraint\nprogramming. Our best approach (pair sampling-based) achieves much lower peak\nresource usage compared to manual scheduling without compromising on the\nquality-of-service.", "comment": "Please cite as: Sunandita Patra, Mehtab Pathan, Mahmoud Mahfouz,\n  Parisa Zehtabi, Wided Ouaja, Daniele Magazzeni, and Manuela Veloso. \"Capacity\n  planning and scheduling for jobs with uncertainty in resource usage and\n  duration.\" The Journal of Supercomputing 80, no. 15 (2024): 22428-22461", "pdf_url": "http://arxiv.org/pdf/2507.01225v1", "categories": ["cs.DC", "cs.AI"], "cate": "cs.DC", "url": "http://arxiv.org/abs/2507.01225v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "具有资源使用和持续时间不确定性的作业能力规划与调度", "tldr": "本研究为混合云环境中的本地网格计算，提出了处理资源使用和持续时间不确定性作业的能力规划与调度方法，旨在平衡资源最小化与高质量服务。通过基于对偶抽样的约束编程方法，在不牺牲服务质量的前提下，显著降低了峰值资源使用。", "motivation": "随着组织向云计算基础设施的迁移，许多组织采用混合云环境，结合了云和本地服务器。在本地网格计算环境中，对资源使用和持续时间存在不确定性的作业进行能力规划和调度是一个挑战，尤其在金融行业，随机市场条件会显著影响作业特性。因此，需要一种方法来同时平衡最小化资源使用和提供高质量服务（按时完成作业）。", "method": "本研究提出了近似方法，包括使用确定性估计器和基于对偶抽样（pair sampling-based）的约束编程。", "result": "最佳方法（基于对偶抽样）与手动调度相比，在不影响服务质量的情况下，实现了显著降低的峰值资源使用。", "conclusion": "基于对偶抽样的约束编程方法能有效解决本地网格计算环境中具有不确定性的作业调度和能力规划问题，在保持服务质量的同时显著优化了资源利用。", "translation": "世界各地的组织定期调度作业（程序）以执行最终用户指定的各种任务。随着向云计算基础设施的重大转变，我们的组织采用了一种混合方法，同时使用云和本地服务器。这项工作的目标是为本地网格计算环境进行能力规划，即估计资源需求，以及作业调度。我们方法的关键贡献是处理作业资源使用和持续时间的不确定性，这是金融行业的一个关键方面，因为随机市场条件显著影响作业特性。为了进行能力规划和调度，我们同时平衡两个相互冲突的目标：(a) 最小化资源使用，以及 (b) 通过在请求的截止日期前完成作业，为最终用户提供高质量的服务。我们提出了使用确定性估计器和基于对偶抽样（pair sampling-based）的约束编程的近似方法。我们最好的方法（基于对偶抽样）与手动调度相比，在不影响服务质量的情况下，实现了低得多的峰值资源使用。", "summary": "本研究针对混合云环境中的本地网格计算，提出了处理资源使用和持续时间不确定性作业的能力规划与调度方法。该方法旨在平衡资源最小化与高质量服务，通过采用确定性估计器和基于对偶抽样的约束编程等近似方法。实验结果表明，基于对偶抽样的方法在不牺牲服务质量的前提下，显著降低了峰值资源使用，优于传统手动调度。", "keywords": "能力规划, 作业调度, 不确定性, 资源使用, 约束编程", "comments": "该论文的创新点在于其处理作业资源使用和持续时间不确定性的能力，这在金融等对不确定性敏感的行业中尤为重要。它通过平衡资源最小化和服务质量两个目标，提供了实用的解决方案。基于对偶抽样约束编程方法的有效性体现在其显著降低峰值资源使用的能力，这对于优化本地计算环境的效率和成本具有重要意义。"}}
{"id": "2507.01062", "title": "Quantifying Student Success with Generative AI: A Monte Carlo Simulation Informed by Systematic Review", "authors": ["Seyma Yaman Kayadibi"], "summary": "The exponential development of generative artificial intelligence (GenAI)\ntechnologies like ChatGPT has raised increasing curiosity about their use in\nhigher education, specifically with respect to how students view them, make use\nof them, and the implications for learning outcomes. This paper employs a\nhybrid methodological approach involving a systematic literature review and\nsimulation-based modeling to explore student perceptions of GenAI use in the\ncontext of higher education. A total of nineteen empirical articles from 2023\nthrough 2025 were selected from the PRISMA-based search targeting the Scopus\ndatabase. Synthesis of emerging patterns from the literature was achieved by\nthematic categorization. Six of these had enough quantitative information,\ni.e., item-level means and standard deviations, to permit probabilistic\nmodeling. One dataset, from the resulting subset, was itself selected as a\nrepresentative case with which to illustrate inverse-variance weighting by\nMonte Carlo simulation, by virtue of its well-designed Likert scale format and\nthematic alignment with the use of computing systems by the researcher.\n  The simulation provided a composite \"Success Score\" forecasting the strength\nof the relationship between student perceptions and learning achievements.\nFindings reveal that attitude factors concerned with usability and real-world\nusefulness are significantly better predictors of positive learning achievement\nthan affective or trust-based factors. Such an interdisciplinary perspective\nprovides a unique means of linking thematic results with predictive modelling,\nresonating with longstanding controversies about the proper use of GenAI tools\nwithin the university.", "comment": "35 pages, 4 figures. All figures are image-based: one Python code\n  screenshot, one regression model output, one success score distribution\n  chart, and one PRISMA diagram. This article presents a standalone segment\n  from the author's master's thesis at Victoria University", "pdf_url": "http://arxiv.org/pdf/2507.01062v1", "categories": ["cs.CY", "cs.AI", "62P25", "K.3.1; H.5.2"], "cate": "cs.CY", "url": "http://arxiv.org/abs/2507.01062v1", "date": "2025-06-30", "updated": "2025-06-30", "AI": {"title_translation": "使用生成式AI量化学生成功：一项基于系统综述的蒙特卡洛模拟", "tldr": "本研究结合系统综述和蒙特卡洛模拟，发现学生对生成式AI的可用性和实际有用性的感知比情感或信任更能预测学习成就。", "motivation": "随着生成式AI技术（如ChatGPT）的快速发展，人们对其在高等教育中的应用，特别是学生如何看待和使用它们以及对学习成果的影响，产生了日益增长的好奇心。本研究旨在探索学生对在高等教育中使用生成式AI的看法。", "method": "本研究采用混合方法论，结合了系统文献综述和基于模拟的建模。首先，从Scopus数据库中通过PRISMA方法筛选了19篇2023年至2025年的实证文章，并通过主题分类法综合了文献中的新兴模式。其中，有六篇文章提供了足够的定量信息（项目级别的均值和标准差），允许进行概率建模。随后，从该子集中选择了一个具有良好李克特量表格式和主题一致性的代表性数据集，通过蒙特卡洛模拟演示了逆方差加权，并提供了复合的“成功分数”来预测学生感知与学习成就之间的关系强度。", "result": "研究结果表明，与情感或信任相关的因素相比，关注可用性和实际有用性的态度因素能显著更好地预测积极的学习成就。", "conclusion": "这种跨学科的视角提供了一种独特的方式，将主题结果与预测建模联系起来，与大学内关于生成式AI工具的正确使用的长期争议产生了共鸣。", "translation": "生成式人工智能（GenAI）技术（如ChatGPT）的指数级发展，引发了人们对其在高等教育中应用的日益增长的好奇，特别是学生如何看待它们、如何使用它们以及对学习成果的影响。本文采用混合方法论，包括系统文献综述和基于模拟的建模，以探讨学生在高等教育背景下对GenAI使用的看法。从2023年至2025年期间，通过针对Scopus数据库的基于PRISMA的搜索，共选择了19篇实证文章。通过主题分类实现了文献中新兴模式的综合。其中有六篇拥有足够的定量信息，即项目级别的均值和标准差，从而允许进行概率建模。从所得子集中选择了一个数据集作为代表性案例，通过蒙特卡洛模拟演示逆方差加权，这得益于其精心设计的李克特量表格式以及与研究人员使用计算系统的主题一致性。\n模拟提供了一个复合的“成功分数”，预测了学生感知与学习成就之间关系的强度。研究结果表明，与情感或信任相关的因素相比，关注可用性和实际有用性的态度因素能显著更好地预测积极的学习成就。这种跨学科的视角提供了一种独特的方式，将主题结果与预测建模联系起来，与大学内关于GenAI工具正确使用的长期争议产生了共鸣。", "summary": "本研究旨在探讨生成式AI在高等教育中对学生成功的影响。研究采用了一种混合方法，结合了系统文献综述和蒙特卡洛模拟。通过对19篇相关实证文章的筛选和分析，并利用其中具有足够定量数据的一部分进行模拟建模，研究构建了一个“成功分数”来预测学生感知与学习成就的关系。核心发现是，学生对生成式AI的可用性和实际有用性的态度是其学习成就的更好预测因子，而非情感或信任因素。这种跨学科方法为连接定性洞察和预测模型提供了一种新颖途径，并对当前关于GenAI在大学中适当使用的讨论有所贡献。", "keywords": "生成式AI, 学生成功, 蒙特卡洛模拟, 系统综述, 高等教育", "comments": "本文创新性地结合了定性系统综述与定量蒙特卡洛模拟，为理解生成式AI对学生成功的影响提供了预测性见解。这种混合方法为分析复杂的教育现象，特别是在新兴技术背景下，提供了一个稳健的框架。研究侧重于可用性和有用性作为关键预测因子，为教育者和开发者提供了实际启示。"}}
{"id": "2507.01204", "title": "LotteryCodec: Searching the Implicit Representation in a Random Network for Low-Complexity Image Compression", "authors": ["Haotian Wu", "Gongpu Chen", "Pier Luigi Dragotti", "Deniz Gündüz"], "summary": "We introduce and validate the lottery codec hypothesis, which states that\nuntrained subnetworks within randomly initialized networks can serve as\nsynthesis networks for overfitted image compression, achieving rate-distortion\n(RD) performance comparable to trained networks. This hypothesis leads to a new\nparadigm for image compression by encoding image statistics into the network\nsubstructure. Building on this hypothesis, we propose LotteryCodec, which\noverfits a binary mask to an individual image, leveraging an over-parameterized\nand randomly initialized network shared by the encoder and the decoder. To\naddress over-parameterization challenges and streamline subnetwork search, we\ndevelop a rewind modulation mechanism that improves the RD performance.\nLotteryCodec outperforms VTM and sets a new state-of-the-art in single-image\ncompression. LotteryCodec also enables adaptive decoding complexity through\nadjustable mask ratios, offering flexible compression solutions for diverse\ndevice constraints and application requirements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01204v1", "categories": ["eess.IV", "cs.IT", "math.IT", "68P30, 94A08", "I.4.2; E.4"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01204v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "乐透编解码器：在随机网络中搜索隐式表示以实现低复杂度图像压缩", "tldr": "提出LotteryCodec，通过在随机网络中寻找未经训练的子网络进行图像压缩，性能超越VTM并实现自适应解码复杂度。", "motivation": "探索未经训练的随机网络子网络在图像压缩中的潜力，以实现与训练网络相当的性能，并提出一种新的图像压缩范式。", "method": "提出LotteryCodec，通过将二值掩码过拟合到单个图像上，利用编码器和解码器共享的过参数化和随机初始化网络。开发了回溯调制机制来解决过参数化挑战并优化子网络搜索，以提高率失真性能。", "result": "LotteryCodec在单图像压缩方面超越了VTM，并创造了新的最先进水平。它还通过可调节的掩码比例实现自适应解码复杂度。", "conclusion": "本文验证了乐透编解码器假设，并提出了LotteryCodec，证明未经训练的随机网络子网络可以实现高性能图像压缩，且具有灵活的解码复杂度。", "translation": "我们引入并验证了乐透编解码器假设，该假设指出随机初始化网络中未经训练的子网络可以作为过拟合图像压缩的合成网络，实现与训练网络相当的率失真（RD）性能。这一假设通过将图像统计信息编码到网络子结构中，为图像压缩带来了新的范式。在此假设的基础上，我们提出了LotteryCodec，它将一个二值掩码过拟合到单个图像上，利用编码器和解码器共享的一个过参数化且随机初始化的网络。为了解决过参数化挑战并简化子网络搜索，我们开发了一种回溯调制机制，以提高RD性能。LotteryCodec优于VTM，并在单图像压缩领域创造了新的最先进水平。LotteryCodec还通过可调节的掩码比例实现自适应解码复杂度，为各种设备限制和应用需求提供了灵活的压缩解决方案。", "summary": "本文提出了乐透编解码器假设，即随机初始化的网络中未经训练的子网络可用于过拟合图像压缩，并达到与训练网络相当的率失真性能。基于此，研究者提出了LotteryCodec，通过将二值掩码过拟合到单个图像，利用一个共享的、随机初始化的过参数化网络进行编码和解码。为优化性能，引入了回溯调制机制。实验结果表明，LotteryCodec在单图像压缩上超越了VTM，并实现了自适应解码复杂度，为不同设备提供了灵活的解决方案。", "keywords": "图像压缩, 随机网络, 乐透编解码器, 率失真性能, 自适应解码", "comments": "这篇论文通过“乐透编解码器假设”提出了一种创新的图像压缩方法，即利用随机初始化网络中的隐式表示进行压缩，而无需传统意义上的网络训练。这种范式转变显著降低了复杂度，并达到了SOTA性能，尤其是在单图像压缩方面。其自适应解码复杂度的能力也增加了实用性。"}}
{"id": "2507.01617", "title": "Spatially Distributed Wettability Characterization in Porous Media", "authors": ["Faisal Aljaberi", "Hadi Belhaj", "Sajjad Foroughi", "Mohammed Al-Kobaisi", "Martin Blunt"], "summary": "An enhanced geometric algorithm for automated pore-by-pore contact angle\nmeasurement from micro-CT images, is presented that achieves superior accuracy\ncompared to existing methods through robust fluid-fluid and solid-fluid\ninterface extrapolation. Using this high resolution data, we generate spatially\ndistributed contact angle maps that reveal previously hidden wettability\nheterogeneity. Our analysis of mixed-wet systems demonstrates the severe\nlimitations of averaged metrics: a sample with a mean contact angle of 64.7\ndegrees, conventionally classified as uniformly weakly water-wet, exhibits 40%\nof its pore space in the intermediate-wetting regime (70-110 degrees). This\nheterogeneity explains the presence of minimal surface interfaces and\nfundamentally different pore-filling mechanisms operating within the same\nsample. By providing open-source tools for spatially-resolved wettability\ncharacterization, this work enables more accurate predictions of multiphase\nflow behavior in heterogeneous porous materials, essential for optimizing\nsubsurface energy storage and recovery processes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01617v1", "categories": ["cs.CE"], "cate": "cs.CE", "url": "http://arxiv.org/abs/2507.01617v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "多孔介质中润湿性的空间分布表征", "tldr": "本文提出了一种新的算法，能够从微CT图像中高精度地逐孔测量接触角，揭示了多孔介质中被平均方法忽略的显著润湿性非均质性，从而改进了多相流预测。", "motivation": "现有的润湿性表征方法，特别是依赖平均指标的方法，存在严重局限性，无法捕捉多孔介质中空间分布的润湿性非均质性，导致多相流行为预测不准确。", "method": "本文提出了一种增强的几何算法，用于从微CT图像中自动进行逐孔接触角测量。该算法通过稳健的流体-流体和固-流体界面外推，实现了比现有方法更高的精度。利用这些高分辨率数据，该研究生成了空间分布的接触角图。", "result": "该方法成功生成了空间分布的接触角图，揭示了以前隐藏的润湿性非均质性。对混合润湿系统的分析表明，平均指标存在严重局限性：一个平均接触角为64.7度的样本，通常被归类为均匀弱水润湿，但其40%的孔隙空间处于中间润湿状态（70-110度）。这种非均质性解释了同一样本中存在最小表面界面和根本不同的孔隙填充机制。", "conclusion": "空间分辨的润湿性表征对于准确理解和预测非均质多孔材料中的多相流行为至关重要。本文开发的开源工具能够实现更准确的预测，这对于优化地下能源储存和回收过程至关重要。平均润湿性指标是不充分且具有误导性的。", "translation": "本文提出了一种增强的几何算法，用于从微CT图像中自动进行逐孔接触角测量。该算法通过稳健的流体-流体和固-流体界面外推，与现有方法相比实现了更高的精度。利用这些高分辨率数据，我们生成了空间分布的接触角图，揭示了以前隐藏的润湿性非均质性。我们对混合润湿系统的分析表明，平均指标存在严重局限性：一个平均接触角为64.7度的样本，通常被归类为均匀弱水润湿，但其40%的孔隙空间处于中间润湿状态（70-110度）。这种非均质性解释了同一样本中存在最小表面界面和根本不同的孔隙填充机制。通过提供用于空间分辨润湿性表征的开源工具，这项工作能够更准确地预测非均质多孔材料中的多相流行为，这对于优化地下能源储存和回收过程至关重要。", "summary": "本文介绍了一种增强的几何算法，用于从微CT图像中自动、高精度地逐孔测量接触角。该方法生成了空间分布的接触角图，揭示了平均指标未能捕捉到的显著润湿性非均质性。例如，一个看似弱水润湿的样本，其很大一部分孔隙空间可能处于中间润湿状态，这解释了复杂的孔隙填充机制。这项工作提供了开源工具，使得能够更准确地预测非均质多孔介质中的多相流行为，这对于地下能源应用至关重要。", "keywords": "润湿性, 多孔介质, 接触角, 微CT, 多相流", "comments": "该论文的创新之处在于开发了一种高精度、自动化的逐孔接触角测量算法，该算法基于微CT图像，解决了传统平均润湿性指标的关键局限性。通过揭示隐藏的空间非均质性，它从根本上提高了我们对复杂多孔介质中多相流的理解。提供开源工具进一步增强了其实际影响力，使这种先进的表征方法变得可及。这项工作对于储层工程和碳封存等领域具有高度重要性，因为准确的流量预测至关重要。"}}
{"id": "2507.01197", "title": "A Spectral-Based Tuning Criterion for PI Controllers in IPDT Systems With Unified Tracking and Disturbance Rejection Performance", "authors": ["Dhamdhawach Horsuwan"], "summary": "This paper proposes a spectral-based tuning method for proportional-integral\n(PI) controllers in integrating-plus-dead-time (IPDT) systems. The design\nobjective is to achieve unified exponential decay for both reference tracking\nand disturbance rejection by minimizing the spectral abscissa of the\nclosed-loop system. A second-order semi-discrete model accurately captures the\nintegrator and delay dynamics while enabling efficient dominant pole\nextraction. These discrete-time poles are mapped to continuous time and refined\nusing Newton-Raphson iterations on the exact transcendental characteristic\nequation. The method produces a unique PI gain set without requiring heuristic\ntrade-offs or weighting parameters. Comparative simulations demonstrate that\nthe proposed tuning achieves faster convergence and improved robustness margins\ncompared to classical rules (Ziegler-Nichols, SIMC) and integral performance\ncriteria (IAE, ITAE). The approach provides a transparent and computationally\nefficient framework for PI control in delay-dominant systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01197v1", "categories": ["eess.SY", "cs.SY"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01197v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "针对具有统一跟踪和扰动抑制性能的IPDT系统中PI控制器的基于频谱的调谐准则", "tldr": "本文提出了一种基于频谱的PI控制器调谐方法，用于IPDT系统，通过最小化闭环系统的频谱实部来统一实现参考跟踪和扰动抑制的指数衰减，并通过仿真证明其优于经典方法。", "motivation": "该研究旨在通过最小化闭环系统的频谱实部，为积分加死区（IPDT）系统中的PI控制器实现参考跟踪和扰动抑制的统一指数衰减。", "method": "本文提出了一种基于频谱的PI控制器调谐方法。该方法利用二阶半离散模型精确捕获积分器和延迟动态，并高效提取主导极点。这些离散时间极点被映射到连续时间，并通过在精确的超越特征方程上应用牛顿-拉夫森迭代进行细化，从而得到唯一的PI增益集，且无需启发式权衡或加权参数。", "result": "对比仿真结果表明，所提出的调谐方法与经典规则（如Ziegler-Nichols, SIMC）和积分性能标准（如IAE, ITAE）相比，实现了更快的收敛速度和更高的鲁棒性裕度。", "conclusion": "该方法为延迟主导系统中的PI控制提供了一个透明且计算高效的框架。", "translation": "本文提出了一种用于积分加死区（IPDT）系统中比例-积分（PI）控制器的基于频谱的调谐方法。设计目标是通过最小化闭环系统的频谱实部，实现参考跟踪和扰动抑制的统一指数衰减。一个二阶半离散模型能够精确捕获积分器和延迟动态，同时实现高效的主导极点提取。这些离散时间极点被映射到连续时间，并使用牛顿-拉夫森迭代在精确的超越特征方程上进行细化。该方法产生独特的PI增益集，无需启发式权衡或加权参数。对比仿真表明，与经典规则（Ziegler-Nichols, SIMC）和积分性能标准（IAE, ITAE）相比，所提出的调谐方法实现了更快的收敛速度和更高的鲁棒性裕度。该方法为延迟主导系统中的PI控制提供了一个透明且计算高效的框架。", "summary": "本文提出了一种针对积分加死区（IPDT）系统中PI控制器的基于频谱的调谐策略。通过最小化闭环系统的频谱实部，该方法旨在实现参考跟踪和扰动抑制的统一指数衰减。它采用二阶半离散模型进行极点提取和牛顿-拉夫森迭代进行精化，从而获得独特的PI增益。仿真结果表明，与现有方法相比，该方法具有更快的收敛速度和更好的鲁棒性。", "keywords": "PI控制器, IPDT系统, 频谱实部, 调谐方法, 鲁棒性", "comments": "这篇论文的创新之处在于提出了一种基于频谱实部最小化的PI控制器调谐方法，实现了对IPDT系统统一的跟踪和扰动抑制性能。其优点在于无需启发式权衡或加权参数即可获得唯一的增益集，并通过严格的数学方法（牛顿-拉夫森迭代）进行精化。该方法在计算效率和透明性方面表现出色，并被证明优于经典的调谐规则，对于延迟主导系统的PI控制具有重要意义。"}}
{"id": "2507.01170", "title": "Matching and Linking Entries in Historical Swedish Encyclopedias", "authors": ["Simon Börjesson", "Erik Ersmark", "Pierre Nugues"], "summary": "The \\textit{Nordisk familjebok} is a Swedish encyclopedia from the 19th and\n20th centuries. It was written by a team of experts and aimed to be an\nintellectual reference, stressing precision and accuracy. This encyclopedia had\nfour main editions remarkable by their size, ranging from 20 to 38 volumes. As\na consequence, the \\textit{Nordisk familjebok} had a considerable influence in\nuniversities, schools, the media, and society overall. As new editions were\nreleased, the selection of entries and their content evolved, reflecting\nintellectual changes in Sweden.\n  In this paper, we used digitized versions from \\textit{Project Runeberg}. We\nfirst resegmented the raw text into entries and matched pairs of entries\nbetween the first and second editions using semantic sentence embeddings. We\nthen extracted the geographical entries from both editions using a\ntransformer-based classifier and linked them to Wikidata. This enabled us to\nidentify geographic trends and possible shifts between the first and second\neditions, written between 1876-1899 and 1904-1926, respectively.\n  Interpreting the results, we observe a small but significant shift in\ngeographic focus away from Europe and towards North America, Africa, Asia,\nAustralia, and northern Scandinavia from the first to the second edition,\nconfirming the influence of the First World War and the rise of new powers. The\ncode and data are available on GitHub at\nhttps://github.com/sibbo/nordisk-familjebok.", "comment": "10 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.01170v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01170v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "匹配和链接瑞典历史百科全书中的条目", "tldr": "本文使用语义嵌入和Transformer分类器，对瑞典《北欧家庭百科全书》的第一版和第二版进行了条目匹配和地理条目链接到Wikidata，发现地理焦点从欧洲转向北美、非洲、亚洲、澳洲和北斯堪的纳维亚。", "motivation": "《北欧家庭百科全书》是19世纪和20世纪瑞典极具影响力的百科全书，其不同版本反映了瑞典的知识变迁。本研究旨在通过分析其数字化版本，识别和理解这种内容演变，特别是地理条目的变化趋势。", "method": "首先，将原始文本重新分段为条目。其次，使用语义句子嵌入技术匹配第一版和第二版之间的条目对。然后，利用基于Transformer的分类器从两个版本中提取地理条目，并将其链接到Wikidata。", "result": "通过分析，观察到从第一版到第二版，地理焦点发生了一个虽小但显著的转变，即从欧洲转向北美、非洲、亚洲、澳大利亚和北斯堪的纳维亚。这证实了第一次世界大战和新势力崛起的影响。", "conclusion": "研究结果表明，瑞典《北欧家庭百科全书》的地理内容在不同版本间发生了显著变化，反映了19世纪末到20世纪初全球事件和地缘政治变化对知识体系的影响。", "translation": "《北欧家庭百科全书》是一部19世纪和20世纪的瑞典百科全书。它由专家团队编写，旨在成为一份知识参考资料，强调精确性和准确性。这部百科全书有四个主要版本，其规模显著，从20卷到38卷不等。因此，《北欧家庭百科全书》在大学、学校、媒体和整个社会中产生了相当大的影响。随着新版本的发布，条目的选择及其内容不断演变，反映了瑞典的知识变迁。\n在本文中，我们使用了来自“Runeberg项目”的数字化版本。我们首先将原始文本重新分段为条目，并使用语义句子嵌入技术匹配第一版和第二版之间的条目对。然后，我们使用基于Transformer的分类器从两个版本中提取地理条目，并将其链接到Wikidata。这使我们能够识别地理趋势以及第一版和第二版（分别写于1876-1899年和1904-1926年）之间可能的变化。\n解释结果时，我们观察到从第一版到第二版，地理焦点发生了一个虽小但显著的转变，即从欧洲转向北美、非洲、亚洲、澳大利亚和北斯堪的纳维亚，这证实了第一次世界大战和新势力崛起的影响。代码和数据可在GitHub上获取：https://github.com/sibbo/nordisk-familjebok。", "summary": "本文研究了瑞典历史百科全书《北欧家庭百科全书》的数字化版本，旨在分析其不同版本中条目的演变。研究人员首先将文本重新分段，并利用语义句子嵌入技术匹配了第一版和第二版之间的条目。随后，他们使用基于Transformer的分类器提取地理条目，并将其链接到Wikidata。分析结果揭示了地理焦点从欧洲转向北美、非洲、亚洲、澳大利亚和北斯堪的纳维亚的显著转变，印证了第一次世界大战等历史事件的影响。", "keywords": "历史百科全书, 瑞典语, 条目匹配, 语义嵌入, Transformer分类器, Wikidata, 地理趋势", "comments": "本文创新性地将现代自然语言处理技术（如语义嵌入和Transformer分类器）应用于历史文献分析，实现了大规模历史文本的条目匹配、分类和知识图谱链接。这种方法为理解历史知识演变提供了新的视角和工具，特别是揭示了社会、政治事件如何影响知识的构建和传播。研究结果具体地展示了地理焦点的转变，验证了历史事件的影响力，具有重要的文化和历史研究价值。其方法的通用性也意味着可以应用于其他历史文献的分析。"}}
{"id": "2507.01140", "title": "Multi-Focus Probes for Context-Preserving Network Exploration and Interaction in Immersive Analytics", "authors": ["Eric Zimmermann", "Stefan Bruckner"], "summary": "Immersive visualization of network data enables users to physically navigate\nand interact with complex structures, but managing transitions between detailed\nlocal (egocentric) views and global (exocentric) overviews remains a major\nchallenge. We present a multifocus probe technique for immersive environments\nthat allows users to instantiate multiple egocentric subgraph views while\nmaintaining persistent links to the global network context. Each probe acts as\na portable local focus, enabling fine-grained inspection and editing of distant\nor occluded regions. Visual and haptic guidance mechanisms ensure context\npreservation during multi-scale interaction. We demonstrate and discuss the\nusability of our technique for the editing of network data.", "comment": "5 pages, 3 figures, IEEE Vis 2025", "pdf_url": "http://arxiv.org/pdf/2507.01140v1", "categories": ["cs.GR"], "cate": "cs.GR", "url": "http://arxiv.org/abs/2507.01140v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "沉浸式分析中用于上下文保留网络探索和交互的多焦点探针", "tldr": "提出多焦点探针技术，解决沉浸式网络可视化中局部与全局视图切换难题，实现上下文保留的精细交互。", "motivation": "沉浸式网络数据可视化使用户能够物理地导航和与复杂结构进行交互，但管理详细局部（以自我为中心）视图和全局（以自我为中心之外）概览视图之间的转换仍然是一个主要挑战。", "method": "本文提出了一种用于沉浸式环境的多焦点探针技术。该技术允许用户实例化多个以自我为中心的子图视图，同时保持与全局网络上下文的持久链接。每个探针充当一个可移植的局部焦点，能够对远处或被遮挡的区域进行精细检查和编辑。视觉和触觉引导机制确保多尺度交互过程中的上下文保留。", "result": "我们展示并讨论了该技术在网络数据编辑方面的可用性。", "conclusion": "该多焦点探针技术在沉浸式环境中有效解决了局部与全局视图切换的挑战，并在网络数据编辑中展现出良好的可用性。", "translation": "网络数据的沉浸式可视化使用户能够物理地导航和与复杂结构进行交互，但管理详细局部（以自我为中心）视图和全局（以自我为中心之外）概览视图之间的转换仍然是一个主要挑战。我们提出了一种用于沉浸式环境的多焦点探针技术，该技术允许用户实例化多个以自我为中心的子图视图，同时保持与全局网络上下文的持久链接。每个探针充当一个可移植的局部焦点，能够对远处或被遮挡的区域进行精细检查和编辑。视觉和触觉引导机制确保多尺度交互过程中的上下文保留。我们展示并讨论了该技术在网络数据编辑方面的可用性。", "summary": "本论文提出了一种名为多焦点探针的新技术，旨在解决沉浸式网络可视化中局部详细视图与全局概览视图之间切换时上下文丢失的挑战。该技术允许用户创建多个可移动的局部焦点（探针），每个探针显示一个子图，同时与全局网络保持连接。通过结合视觉和触觉引导，确保在多尺度交互中上下文得以保留。研究展示了该技术在网络数据编辑中的实用性。", "keywords": "多焦点探针, 沉浸式分析, 网络可视化, 上下文保留, 多尺度交互", "comments": "该论文提出了一种新颖的方法来解决沉浸式可视化中长期存在的局部-全局上下文切换问题，即通过引入“多焦点探针”的概念。这种方法允许用户在保持全局视图的同时深入探索局部细节，尤其是在处理大型复杂网络时具有重要意义。视觉和触觉引导机制的结合增强了用户体验和交互效率，是其创新之处。其局限性可能在于实现复杂性和在更广泛应用场景中的普适性。"}}
{"id": "2507.01830", "title": "SPARSE-PIVOT: Dynamic correlation clustering for node insertions", "authors": ["Mina Dalirrooyfard", "Konstantin Makarychev", "Slobodan Mitrović"], "summary": "We present a new Correlation Clustering algorithm for a dynamic setting where\nnodes are added one at a time. In this model, proposed by Cohen-Addad,\nLattanzi, Maggiori, and Parotsidis (ICML 2024), the algorithm uses database\nqueries to access the input graph and updates the clustering as each new node\nis added. Our algorithm has the amortized update time of\n$O_{\\epsilon}(\\log^{O(1)}(n))$. Its approximation factor is $20+\\varepsilon$,\nwhich is a substantial improvement over the approximation factor of the\nalgorithm by Cohen-Addad et al. We complement our theoretical findings by\nempirically evaluating the approximation guarantee of our algorithm. The\nresults show that it outperforms the algorithm by Cohen-Addad et al.~in\npractice.", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.01830v1", "categories": ["cs.DS"], "cate": "cs.DS", "url": "http://arxiv.org/abs/2507.01830v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "SPARSE-PIVOT：节点插入的动态关联聚类", "tldr": "本文提出了一种新的动态关联聚类算法SPARSE-PIVOT，用于节点逐个添加的场景，其具有更优的摊销更新时间和显著改进的近似因子，并且在实践中表现出色。", "motivation": "本文旨在解决动态设置中关联聚类算法的挑战，特别是在节点逐个添加的场景下，并寻求改进现有算法的性能和近似因子。", "method": "本文提出了一种名为SPARSE-PIVOT的新型关联聚类算法。该算法在动态设置中运行，通过数据库查询访问输入图，并在每次添加新节点时更新聚类。作者还通过实证评估来验证算法的近似保证。", "result": "该算法的摊销更新时间为$O_{\\epsilon}(\\log^{O(1)}(n))$，近似因子为$20+\\varepsilon$，与Cohen-Addad等人提出的算法相比，这是一个实质性的改进。实证结果也表明，该算法在实践中优于Cohen-Addad等人的算法。", "conclusion": "SPARSE-PIVOT算法在动态节点插入场景下的关联聚类问题上取得了显著进展，其在理论近似因子和更新时间以及实际性能上都优于现有方法。", "translation": "我们提出了一种新的关联聚类算法，用于节点逐个添加的动态设置。在这个由Cohen-Addad、Lattanzi、Maggiori和Parotsidis（ICML 2024）提出的模型中，算法使用数据库查询来访问输入图，并在每个新节点添加时更新聚类。我们的算法的摊销更新时间为$O_{\\epsilon}(\\log^{O(1)}(n))$。其近似因子为$20+\\varepsilon$，这比Cohen-Addad等人的算法的近似因子有了实质性的改进。我们通过实证评估我们算法的近似保证来补充我们的理论发现。结果表明，它在实践中优于Cohen-Addad等人的算法。", "summary": "本文介绍了一种名为SPARSE-PIVOT的新型动态关联聚类算法，专门设计用于节点逐个插入的场景。该算法在摊销更新时间上达到$O_{\\epsilon}(\\log^{O(1)}(n))$，并将近似因子显著提高到$20+\\varepsilon$，优于现有算法。理论成果辅以实证评估，证明其在实际应用中也超越了先前的算法。", "keywords": "动态关联聚类, 节点插入, 近似算法, SPARSE-PIVOT, 摊销更新时间", "comments": "该论文在动态关联聚类领域取得了重要进展，特别是在处理节点插入方面。其创新之处在于提供了更优的理论保证（近似因子和更新时间）并展示了实际应用中的卓越性能。这对于需要处理动态演化图的实际应用具有重要意义。"}}
{"id": "2507.01245", "title": "A fourth-order exponential time differencing scheme with real and distinct poles rational approximation for solving non-linear reaction-diffusion systems", "authors": ["Wisdom Kwame Attipoe", "Andreas Kleefeld", "Emmanuel Asante-Asamani"], "summary": "A fourth-order, L-stable, exponential time differencing Runge-Kutta type\nscheme is developed to solve nonlinear systems of reaction diffusion equations\nwith nonsmooth data. The new scheme, ETDRK4RDP, is constructed by approximating\nthe matrix exponentials in the ETDRK4 scheme with a fourth order, L-acceptable,\nnon-Pad\\'e rational function having real and distinct poles (RDP). Using RDP\nrational functions to construct the scheme ensures efficient damping of\nspurious oscillations arising from non-smooth initial and boundary conditions\nand a straightforward parallelization. We verify empirically that the new\nETDRK4RDP scheme is fourth-order accurate for several reaction diffusion\nsystems with Dirichlet and Neumann boundary conditions and show it to be more\nefficient than competing exponential time differencing schemes, especially when\nimplemented in parallel, with up to six times speedup in CPU time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01245v1", "categories": ["math.NA", "cs.NA"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01245v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "求解非线性反应-扩散系统的四阶指数时间差分方案，采用实数和不同极点有理逼近", "tldr": "开发了一种新的四阶、L-稳定指数时间差分Runge-Kutta方案（ETDRK4RDP），通过实数和不同极点有理逼近来高效解决非光滑数据的非线性反应-扩散系统，并实现并行加速。", "motivation": "解决带有非光滑数据的非线性反应-扩散方程系统，并有效抑制由非光滑初始和边界条件引起的虚假振荡，同时实现并行化。", "method": "开发了一种四阶L-稳定的指数时间差分Runge-Kutta型方案（ETDRK4RDP）。该方案通过使用具有实数和不同极点（RDP）的四阶L-可接受非Padé有理函数来逼近ETDRK4方案中的矩阵指数。", "result": "新的ETDRK4RDP方案被经验验证为对多种具有Dirichlet和Neumann边界条件的反应-扩散系统具有四阶精度。与竞争的指数时间差分方案相比，该方案更高效，尤其是在并行实现时，CPU时间可加快达六倍。", "conclusion": "该ETDRK4RDP方案通过其独特的构造（RDP有理逼近）成功解决了非光滑数据下的非线性反应-扩散系统，并显著提高了计算效率，尤其在并行环境下表现优异。", "translation": "开发了一种四阶、L-稳定的指数时间差分Runge-Kutta型方案，用于求解具有非光滑数据的非线性反应-扩散方程系统。新方案ETDRK4RDP通过使用具有实数和不同极点（RDP）的四阶、L-可接受、非Padé有理函数来逼近ETDRK4方案中的矩阵指数而构建。使用RDP有理函数来构建该方案，确保了有效抑制由非光滑初始和边界条件引起的虚假振荡，并便于并行化。我们通过实验验证了新的ETDRK4RDP方案对于多个具有Dirichlet和Neumann边界条件的反应-扩散系统具有四阶精度，并表明它比竞争的指数时间差分方案更高效，特别是在并行实现时，CPU时间可加快达六倍。", "summary": "本文提出了一种名为ETDRK4RDP的四阶L-稳定指数时间差分Runge-Kutta方案，专为解决具有非光滑数据的非线性反应-扩散系统而设计。该方案创新性地采用具有实数和不同极点的非Padé有理函数来逼近矩阵指数，从而有效抑制虚假振荡并便于并行计算。实验结果表明，ETDRK4RDP方案具有四阶精度，且在并行环境下比现有方案效率更高，最高可达六倍加速。", "keywords": "指数时间差分, 反应-扩散系统, 有理逼近, 四阶精度, 并行计算", "comments": "该研究创新性地将实数和不同极点有理逼近引入指数时间差分Runge-Kutta方案，有效解决了非光滑数据处理中的振荡问题，并显著提升了并行计算效率。其L-稳定性也保证了数值方法的鲁棒性。"}}
{"id": "2507.01024", "title": "Hello Afrika: Speech Commands in Kinyarwanda", "authors": ["George Igwegbe", "Martins Awojide", "Mboh Bless", "Nirel Kadzo"], "summary": "Voice or Speech Commands are a subset of the broader Spoken Word Corpus of a\nlanguage which are essential for non-contact control of and activation of\nlarger AI systems in devices used in everyday life especially for persons with\ndisabilities. Currently, there is a dearth of speech command models for African\nlanguages. The Hello Afrika project aims to address this issue and its first\niteration is focused on the Kinyarwanda language since the country has shown\ninterest in developing speech recognition technologies culminating in one of\nthe largest datasets on Mozilla Common Voice. The model was built off a custom\nspeech command corpus made up of general directives, numbers, and a wake word.\nThe final model was deployed on multiple devices (PC, Mobile Phone and Edge\nDevices) and the performance was assessed using suitable metrics.", "comment": "Data Science Africa, 2024", "pdf_url": "http://arxiv.org/pdf/2507.01024v1", "categories": ["eess.AS", "cs.AI", "cs.SD"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01024v1", "date": "2025-06-16", "updated": "2025-06-16", "AI": {"title_translation": "你好非洲：卢旺达语语音命令", "tldr": "该项目开发并部署了一个卢旺达语语音命令模型，以解决非洲语言语音命令模型稀缺的问题。", "motivation": "语音命令对于设备的非接触式控制至关重要，尤其对于残障人士。目前，非洲语言的语音命令模型非常缺乏。", "method": "该模型基于一个包含通用指令、数字和唤醒词的定制语音命令语料库构建。最终模型部署在PC、手机和边缘设备上，并使用合适的指标评估了其性能。", "result": "开发并部署了一个卢旺达语语音命令模型，并在多种设备上进行了性能评估。", "conclusion": "该项目成功开发了针对卢旺达语的语音命令模型，填补了非洲语言在该领域的空白，并展示了其在多设备上的可用性。", "translation": "语音命令是语言中更广泛的口语语料库的一个子集，对于日常生活中使用的设备中大型AI系统的非接触式控制和激活至关重要，特别是对于残障人士。目前，非洲语言的语音命令模型非常缺乏。“你好非洲”项目旨在解决这个问题，其首次迭代专注于卢旺达语，因为该国已表现出开发语音识别技术的兴趣，最终促成了Mozilla Common Voice上最大的数据集之一。该模型基于一个由通用指令、数字和唤醒词组成的定制语音命令语料库构建。最终模型部署在多种设备（PC、手机和边缘设备）上，并使用合适的指标评估了其性能。", "summary": "“你好非洲”项目致力于解决非洲语言语音命令模型稀缺的问题。该项目以卢旺达语为重点，构建了一个基于定制语料库（包含通用指令、数字和唤醒词）的语音命令模型。该模型已成功部署在PC、手机和边缘设备上，并对其性能进行了评估，旨在为卢旺达语提供有效的语音控制解决方案。", "keywords": "语音命令, 卢旺达语, 非洲语言, 语音识别, 定制语料库", "comments": "该论文解决了非洲语言语音命令模型缺失的重要问题，特别关注了卢旺达语。其创新点在于构建了定制语料库并实现了多设备部署，这对于推动非洲本地化AI技术发展具有重要意义。然而，摘要中未详细说明所使用的评估指标和具体的性能结果，这限制了对其模型效果的全面理解。"}}
{"id": "2507.01053", "title": "Conversational LLMs Simplify Secure Clinical Data Access, Understanding, and Analysis", "authors": ["Rafi Al Attrach", "Pedro Moreira", "Rajna Fani", "Renato Umeton", "Leo Anthony Celi"], "summary": "As ever-larger clinical datasets become available, they have the potential to\nunlock unprecedented opportunities for medical research. Foremost among them is\nMedical Information Mart for Intensive Care (MIMIC-IV), the world's largest\nopen-source EHR database. However, the inherent complexity of these datasets,\nparticularly the need for sophisticated querying skills and the need to\nunderstand the underlying clinical settings, often presents a significant\nbarrier to their effective use. M3 lowers the technical barrier to\nunderstanding and querying MIMIC-IV data. With a single command it retrieves\nMIMIC-IV from PhysioNet, launches a local SQLite instance (or hooks into the\nhosted BigQuery), and-via the Model Context Protocol (MCP)-lets researchers\nconverse with the database in plain English. Ask a clinical question in natural\nlanguage; M3 uses a language model to translate it into SQL, executes the query\nagainst the MIMIC-IV dataset, and returns structured results alongside the\nunderlying query for verifiability and reproducibility. Demonstrations show\nthat minutes of dialogue with M3 yield the kind of nuanced cohort analyses that\nonce demanded hours of handcrafted SQL and relied on understanding the\ncomplexities of clinical workflows. By simplifying access, M3 invites the\nbroader research community to mine clinical critical-care data and accelerates\nthe translation of raw records into actionable insight.", "comment": "10 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.01053v1", "categories": ["cs.IR", "cs.AI", "cs.DB", "68T50, 68P15", "H.2.3; I.2.7; J.3"], "cate": "cs.IR", "url": "http://arxiv.org/abs/2507.01053v1", "date": "2025-06-27", "updated": "2025-06-27", "AI": {"title_translation": "对话式大型语言模型简化安全临床数据访问、理解和分析", "tldr": "M3利用对话式大语言模型，将复杂的临床数据库（如MIMIC-IV）查询从专业SQL简化为自然语言对话，大大降低了研究人员访问和分析临床数据的技术门槛。", "motivation": "现有的大型临床数据集（如MIMIC-IV）因其固有的复杂性、对高级查询技能的需求以及对底层临床环境的理解要求，严重阻碍了其有效利用，限制了医学研究的潜力。", "method": "该论文提出M3系统，通过模型上下文协议（MCP），利用大型语言模型将自然语言的临床问题转换为SQL查询，并在MIMIC-IV数据集上执行，返回结构化结果和底层查询。M3还简化了MIMIC-IV数据的获取和本地数据库的设置。", "result": "演示表明，通过M3进行几分钟的对话，即可完成过去需要数小时手动编写SQL并理解复杂临床工作流才能实现的细致队列分析。", "conclusion": "M3通过简化对临床数据的访问，邀请更广泛的研究社区参与挖掘重症监护数据，并加速将原始记录转化为可操作的见解。", "translation": "随着规模日益扩大的临床数据集的出现，它们有潜力为医学研究带来前所未有的机遇。其中最重要的是重症监护医学信息集市（MIMIC-IV），它是世界上最大的开源电子健康记录数据库。然而，这些数据集固有的复杂性，特别是对复杂查询技能的需求以及对底层临床环境的理解，常常对其有效利用构成重大障碍。M3降低了理解和查询MIMIC-IV数据的技术门槛。通过一个简单的命令，它从PhysioNet检索MIMIC-IV，启动本地SQLite实例（或连接到托管的BigQuery），并通过模型上下文协议（MCP）让研究人员以简单的英语与数据库进行对话。用自然语言提出一个临床问题；M3使用语言模型将其翻译成SQL，针对MIMIC-IV数据集执行查询，并返回结构化结果以及底层查询，以供验证和重现。演示表明，与M3进行几分钟的对话就能产生那种曾经需要数小时手工编写SQL并依赖于理解临床工作流复杂性的细致队列分析。通过简化访问，M3邀请更广泛的研究社区挖掘临床重症监护数据，并加速将原始记录转化为可操作的见解。", "summary": "本文介绍M3系统，旨在解决大型临床数据集（如MIMIC-IV）因复杂查询和领域知识需求而难以利用的问题。M3通过整合大型语言模型和模型上下文协议（MCP），使用户能以自然语言与数据库交互，将问题自动转换为SQL查询并执行。这显著降低了技术门槛，使得原本耗时耗力的复杂临床数据分析变得高效便捷，从而加速了医学研究中从原始数据到 actionable insights 的转化。", "keywords": "临床数据访问, 大型语言模型, MIMIC-IV, 自然语言处理, 数据分析", "comments": "M3的创新之处在于其将大语言模型应用于临床数据查询，通过自然语言接口极大地降低了非技术背景研究人员访问和分析复杂医疗数据的门槛。这对于加速医学研究、提高临床数据利用率具有重要意义。其提供底层查询以保证可验证性和可重现性，也体现了严谨性。"}}
{"id": "2507.01638", "title": "Customized Exploration of Landscape Features Driving Multi-Objective Combinatorial Optimization Performance", "authors": ["Ana Nikolikj", "Gabriela Ochoa", "Tome Eftimov"], "summary": "We present an analysis of landscape features for predicting the performance\nof multi-objective combinatorial optimization algorithms. We consider features\nfrom the recently proposed compressed Pareto Local Optimal Solutions Networks\n(C-PLOS-net) model of combinatorial landscapes. The benchmark instances are a\nset of rmnk-landscapes with 2 and 3 objectives and various levels of ruggedness\nand objective correlation. We consider the performance of three algorithms --\nPareto Local Search (PLS), Global Simple EMO Optimizer (GSEMO), and\nNon-dominated Sorting Genetic Algorithm (NSGA-II) - using the resolution and\nhypervolume metrics. Our tailored analysis reveals feature combinations that\ninfluence algorithm performance specific to certain landscapes. This study\nprovides deeper insights into feature importance, tailored to specific\nrmnk-landscapes and algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01638v1", "categories": ["cs.NE", "cs.AI"], "cate": "cs.NE", "url": "http://arxiv.org/abs/2507.01638v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "定制化探索驱动多目标组合优化性能的景观特征", "tldr": "本文分析了景观特征如何预测多目标组合优化算法的性能，通过对C-PLOS-net模型特征的定制化探索，揭示了特定景观和算法的特征组合对性能的影响。", "motivation": "为了深入理解景观特征对多目标组合优化算法性能的影响，并为特定rmnk景观和算法提供定制化的特征重要性见解。", "method": "研究分析了来自压缩帕累托局部最优解网络（C-PLOS-net）模型的景观特征。基准实例为具有2个和3个目标、不同崎岖度和目标相关性的rmnk景观。评估了三种算法（帕累托局部搜索PLS、全局简单EMO优化器GSEMO和非支配排序遗传算法NSGA-II）的性能，并使用分辨率和超体积指标进行衡量。研究进行了定制化的分析。", "result": "定制化的分析揭示了影响特定景观中算法性能的特征组合。", "conclusion": "本研究为特征重要性提供了更深入的见解，并针对特定的rmnk景观和算法进行了定制。", "translation": "本文对预测多目标组合优化算法性能的景观特征进行了分析。我们考虑了最近提出的组合景观压缩帕累托局部最优解网络（C-PLOS-net）模型中的特征。基准实例是一组具有2个和3个目标以及不同崎岖度和目标相关性的rmnk景观。我们使用分辨率和超体积度量，考虑了三种算法的性能——帕累托局部搜索（PLS）、全局简单EMO优化器（GSEMO）和非支配排序遗传算法（NSGA-II）。我们量身定制的分析揭示了影响特定景观中算法性能的特征组合。这项研究为特征重要性提供了更深入的见解，并针对特定的rmnk景观和算法进行了定制。", "summary": "本文旨在探讨景观特征如何影响多目标组合优化算法的性能。研究利用了压缩帕累托局部最优解网络（C-PLOS-net）模型中的特征，并在具有不同崎岖度和目标相关性的rmnk景观上，评估了帕累托局部搜索（PLS）、全局简单EMO优化器（GSEMO）和非支配排序遗传算法（NSGA-II）这三种算法的性能，衡量指标为分辨率和超体积。通过定制化的分析，研究揭示了影响特定景观中算法性能的特征组合，从而为针对特定rmnk景观和算法的特征重要性提供了更深入的见解。", "keywords": "景观特征, 多目标组合优化, C-PLOS-net, 算法性能, rmnk景观", "comments": "该研究的创新之处在于其“定制化探索”和“量身定制的分析”方法。这种方法能够识别出影响特定景观中算法性能的特定特征组合，从而超越了普遍性的理解，提供了更细致的洞察。这对于通过理解潜在的景观属性来设计更有效的多目标优化算法可能具有重要意义。"}}
{"id": "2507.01582", "title": "Exploring Classical Piano Performance Generation with Expressive Music Variational AutoEncoder", "authors": ["Jing Luo", "Xinyu Yang", "Jie Wei"], "summary": "The creativity of classical music arises not only from composers who craft\nthe musical sheets but also from performers who interpret the static notations\nwith expressive nuances. This paper addresses the challenge of generating\nclassical piano performances from scratch, aiming to emulate the dual roles of\ncomposer and pianist in the creative process. We introduce the Expressive\nCompound Word (ECP) representation, which effectively captures both the\nmetrical structure and expressive nuances of classical performances. Building\non this, we propose the Expressive Music Variational AutoEncoder (XMVAE), a\nmodel featuring two branches: a Vector Quantized Variational AutoEncoder\n(VQ-VAE) branch that generates score-related content, representing the\nComposer, and a vanilla VAE branch that produces expressive details, fulfilling\nthe role of Pianist. These branches are jointly trained with similar Seq2Seq\narchitectures, leveraging a multiscale encoder to capture beat-level contextual\ninformation and an orthogonal Transformer decoder for efficient compound tokens\ndecoding. Both objective and subjective evaluations demonstrate that XMVAE\ngenerates classical performances with superior musical quality compared to\nstate-of-the-art models. Furthermore, pretraining the Composer branch on extra\nmusical score datasets contribute to a significant performance gain.", "comment": "Accepted by IEEE SMC 2025", "pdf_url": "http://arxiv.org/pdf/2507.01582v1", "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "cate": "cs.SD", "url": "http://arxiv.org/abs/2507.01582v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "探索使用表现力音乐变分自编码器生成古典钢琴演奏", "tldr": "本文提出了一种名为XMVAE的模型，它使用双分支变分自编码器（一个用于作曲家角色，一个用于钢琴家角色）来生成具有卓越音乐质量的古典钢琴演奏，并通过预训练进一步提升了性能。", "motivation": "古典音乐的创造力不仅源于作曲家，也源于演奏者对静态乐谱的表现力诠释。本文旨在解决从零开始生成古典钢琴演奏的挑战，以模拟创作过程中作曲家和钢琴家的双重角色。", "method": "本文引入了表现力复合词（ECP）表示来捕捉古典演奏的节拍结构和表现力细微差别。在此基础上，提出了表现力音乐变分自编码器（XMVAE），该模型具有两个分支：一个向量量化变分自编码器（VQ-VAE）分支生成乐谱相关内容（代表作曲家），一个普通VAE分支产生表现力细节（扮演钢琴家）。这两个分支采用相似的Seq2Seq架构联合训练，利用多尺度编码器捕获节拍级上下文信息，并使用正交Transformer解码器进行高效的复合令牌解码。", "result": "客观和主观评估均表明，与现有最先进模型相比，XMVAE生成的古典演奏具有卓越的音乐质量。此外，在额外乐谱数据集上预训练作曲家分支显著提高了性能。", "conclusion": "XMVAE模型能够有效地生成高质量的古典钢琴演奏，成功模拟了作曲家和钢琴家的双重角色，并通过预训练进一步提升了表现。", "translation": "古典音乐的创造力不仅源于创作乐谱的作曲家，也源于演奏者用富有表现力的细微差别来诠释静态乐谱。本文旨在解决从零开始生成古典钢琴演奏的挑战，旨在模拟创作过程中作曲家和钢琴家的双重角色。我们引入了表现力复合词（ECP）表示，它有效地捕捉了古典演奏的节拍结构和表现力细微差别。在此基础上，我们提出了表现力音乐变分自编码器（XMVAE），该模型具有两个分支：一个向量量化变分自编码器（VQ-VAE）分支生成乐谱相关内容，代表作曲家；一个普通VAE分支产生表现力细节，扮演钢琴家。这些分支采用相似的Seq2Seq架构联合训练，利用多尺度编码器捕获节拍级上下文信息，并使用正交Transformer解码器进行高效的复合令牌解码。客观和主观评估均表明，与现有最先进模型相比，XMVAE生成的古典演奏具有卓越的音乐质量。此外，在额外乐谱数据集上预训练作曲家分支显著提高了性能。", "summary": "本文提出了一种名为表现力音乐变分自编码器（XMVAE）的新模型，用于从零开始生成古典钢琴演奏。该模型通过引入表现力复合词（ECP）表示来捕捉音乐的结构和表现力。XMVAE包含两个分支，分别模拟作曲家（生成乐谱内容）和钢琴家（生成表现力细节）的角色，并采用联合训练的Seq2Seq架构，结合多尺度编码器和正交Transformer解码器。实验结果表明，XMVAE生成的古典演奏在音乐质量上优于现有模型，并且作曲家分支的预训练能带来显著的性能提升。", "keywords": "古典钢琴演奏, 表现力音乐, 变分自编码器, 音乐生成, 深度学习", "comments": "该论文创新性地将古典音乐创作中的“作曲家”和“钢琴家”角色解耦，并通过双分支VAE模型进行模拟，这为音乐生成领域提供了一个新颖的视角。ECP表示和正交Transformer解码器的使用也展现了模型在处理复杂音乐结构和表现力方面的能力。其在生成质量上的优势以及预训练带来的提升，都表明了该模型在古典音乐AI生成方面的重要进展。"}}
{"id": "2507.01206", "title": "2024 NASA SUITS Report: LLM-Driven Immersive Augmented Reality User Interface for Robotics and Space Exploration", "authors": ["Kathy Zhuang", "Zixun Huang", "Yukun Song", "Rui Li", "Yinuo Zhou", "Allen Y. Yang"], "summary": "As modern computing advances, new interaction paradigms have emerged,\nparticularly in Augmented Reality (AR), which overlays virtual interfaces onto\nphysical objects. This evolution poses challenges in machine perception,\nespecially for tasks like 3D object pose estimation in complex, dynamic\nenvironments. Our project addresses critical issues in human-robot interaction\nwithin mobile AR, focusing on non-intrusive, spatially aware interfaces. We\npresent URSA, an LLM-driven immersive AR system developed for NASA's 2023-2024\nSUITS challenge, targeting future spaceflight needs such as the Artemis\nmissions. URSA integrates three core technologies: a head-mounted AR device\n(e.g., HoloLens) for intuitive visual feedback, voice control powered by large\nlanguage models for hands-free interaction, and robot tracking algorithms that\nenable accurate 3D localization in dynamic settings. To enhance precision, we\nleverage digital twin localization technologies, using datasets like\nDTTD-Mobile and specialized hardware such as the ZED2 camera for real-world\ntracking under noise and occlusion. Our system enables real-time robot control\nand monitoring via an AR interface, even in the absence of ground-truth\nsensors--vital for hazardous or remote operations. Key contributions include:\n(1) a non-intrusive AR interface with LLM-based voice input; (2) a ZED2-based\ndataset tailored for non-rigid robotic bodies; (3) a Local Mission Control\nConsole (LMCC) for mission visualization; (4) a transformer-based 6DoF pose\nestimator (DTTDNet) optimized for depth fusion and real-time tracking; and (5)\nend-to-end integration for astronaut mission support. This work advances\ndigital twin applications in robotics, offering scalable solutions for both\naerospace and industrial domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01206v1", "categories": ["cs.RO", "cs.HC"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01206v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "2024年NASA SUITS报告：LLM驱动的沉浸式增强现实用户界面，用于机器人和太空探索", "tldr": "该论文介绍了URSA，一个LLM驱动的沉浸式AR系统，旨在解决移动AR中人机交互的挑战，支持机器人控制和太空探索任务。", "motivation": "现代计算和增强现实技术的发展带来了机器感知和3D物体位姿估计的挑战。该项目旨在解决移动AR中人机交互的关键问题，并满足未来太空飞行（如阿尔忒弥斯任务）的需求。", "method": "该论文提出了URSA系统，一个LLM驱动的沉浸式AR系统。它集成了头戴式AR设备（如HoloLens）提供视觉反馈，基于大型语言模型的语音控制实现免手操作，以及机器人跟踪算法实现动态环境中的精确3D定位。系统利用数字孪生定位技术，结合DTTD-Mobile数据集和ZED2相机，在噪声和遮挡下进行实时跟踪。", "result": "该系统实现了通过AR界面进行实时机器人控制和监测，即使在缺乏地面真实传感器的情况下也能运作。主要贡献包括：1) 一个基于LLM语音输入的非侵入式AR界面；2) 一个针对非刚性机器人身体的ZED2数据集；3) 用于任务可视化的本地任务控制台（LMCC）；4) 一个基于Transformer的6自由度位姿估计器（DTTDNet），优化了深度融合和实时跟踪；5) 为宇航员任务提供端到端集成支持。", "conclusion": "这项工作推动了数字孪生在机器人领域的应用，为航空航天和工业领域提供了可扩展的解决方案。", "translation": "随着现代计算的进步，新的交互范式不断涌现，特别是在增强现实（AR）领域，它将虚拟界面叠加到物理对象上。这种演变给机器感知带来了挑战，尤其是在复杂动态环境中进行3D物体位姿估计等任务。我们的项目解决了移动AR中人机交互的关键问题，重点是非侵入式、空间感知的界面。我们展示了URSA，一个为NASA 2023-2024 SUITS挑战开发的LLM驱动的沉浸式AR系统，旨在满足未来太空飞行（如阿尔忒弥斯任务）的需求。URSA集成了三项核心技术：用于直观视觉反馈的头戴式AR设备（例如HoloLens）、由大型语言模型驱动的语音控制以实现免手交互，以及在动态环境中实现精确3D定位的机器人跟踪算法。为了提高精度，我们利用数字孪生定位技术，使用DTTD-Mobile等数据集和ZED2相机等专用硬件，在噪声和遮挡下进行实时跟踪。我们的系统能够通过AR界面进行实时机器人控制和监测，即使在缺乏地面真实传感器的情况下——这对于危险或远程操作至关重要。主要贡献包括：(1) 一个带有基于LLM语音输入的非侵入式AR界面；(2) 一个为非刚性机器人身体量身定制的基于ZED2的数据集；(3) 一个用于任务可视化的本地任务控制台（LMCC）；(4) 一个基于Transformer的6自由度位姿估计器（DTTDNet），针对深度融合和实时跟踪进行了优化；以及(5) 为宇航员任务提供端到端集成支持。这项工作推动了数字孪生在机器人领域的应用，为航空航天和工业领域提供了可扩展的解决方案。", "summary": "该论文介绍了URSA，一个LLM驱动的沉浸式增强现实系统，旨在解决移动AR中复杂人机交互的挑战，并支持机器人控制和太空探索任务。系统集成了AR设备、LLM语音控制和机器人跟踪算法，并利用数字孪生技术和ZED2相机进行精确跟踪。URSA实现了实时机器人控制和监测，即使在无地面真相传感器的情况下也能运行。主要贡献包括创新的AR界面、专用数据集、任务控制台、优化的位姿估计器以及对宇航员任务的全面支持，为机器人和数字孪生应用提供了可扩展的解决方案。", "keywords": "LLM, 增强现实, 机器人, 太空探索, 数字孪生", "comments": "该论文的创新点在于将大型语言模型（LLM）与沉浸式增强现实技术相结合，为机器人控制和太空探索提供了一种新颖且高效的人机交互范式。其非侵入式、语音控制的特点显著提升了用户体验和操作便利性，尤其适用于高风险或复杂环境。系统对数字孪生技术和专用数据集的利用，也体现了其在提高定位精度和适应动态环境方面的努力。这项工作不仅对航空航天领域具有重要意义，也为工业应用提供了可借鉴的解决方案。"}}
{"id": "2507.01410", "title": "A Fuzzy Approach to the Specification, Verification and Validation of Risk-Based Ethical Decision Making Models", "authors": ["Abeer Dyoub", "Francesca A. Lisi"], "summary": "The ontological and epistemic complexities inherent in the moral domain make\nit challenging to establish clear standards for evaluating the performance of a\nmoral machine. In this paper, we present a formal method to describe Ethical\nDecision Making models based on ethical risk assessment. Then, we show how\nthese models that are specified as fuzzy rules can be verified and validated\nusing fuzzy Petri nets. A case study from the medical field is considered to\nillustrate the proposed approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01410v1", "categories": ["cs.AI"], "cate": "cs.AI", "url": "http://arxiv.org/abs/2507.01410v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "一种基于模糊方法的风险伦理决策模型规范、验证与确认", "tldr": "本文提出了一种基于模糊规则和模糊Petri网的形式化方法，用于规范、验证和确认基于风险评估的伦理决策模型，并通过医学案例进行了说明。", "motivation": "道德领域固有的本体论和认识论复杂性使得评估“道德机器”的性能难以建立明确的标准。", "method": "本文提出了一种形式化方法来描述基于伦理风险评估的伦理决策模型。这些模型被指定为模糊规则，并使用模糊Petri网进行验证和确认。", "result": "通过一个医学领域的案例研究，说明了所提出的方法。", "conclusion": "本文提出了一种基于模糊规则和模糊Petri网的形式化方法，可以用于规范、验证和确认基于风险评估的伦理决策模型。", "translation": "道德领域固有的本体论和认识论复杂性使得为评估“道德机器”的性能建立明确标准具有挑战性。在本文中，我们提出了一种基于伦理风险评估来描述伦理决策模型的形式化方法。然后，我们展示了如何使用模糊Petri网来验证和确认这些被指定为模糊规则的模型。文章考虑了一个医学领域的案例研究来阐述所提出的方法。", "summary": "本文针对评估“道德机器”性能标准建立的挑战，提出了一种形式化方法来规范、验证和确认基于风险评估的伦理决策模型。该方法将模型指定为模糊规则，并利用模糊Petri网进行验证和确认，并通过一个医学案例进行了说明。", "keywords": "模糊方法, 伦理决策模型, 风险评估, 模糊Petri网, 规范验证", "comments": "该论文的创新点在于将模糊逻辑应用于伦理决策模型的规范、验证和确认，特别是在风险评估的背景下。使用模糊Petri网进行验证是一种新颖的方法，有助于处理道德领域固有的不确定性和复杂性。其重要性在于为“道德机器”的性能评估提供了一种形式化的、可操作的框架。"}}
{"id": "2507.01477", "title": "Combining Type Inference and Automated Unit Test Generation for Python", "authors": ["Lukas Krodinger", "Stephan Lukasczyk", "Gordon Fraser"], "summary": "Automated unit test generation is an established research field that has so\nfar focused on statically-typed programming languages. The lack of type\ninformation in dynamically-typed programming languages, such as Python,\ninhibits test generators, which heavily rely on information about parameter and\nreturn types of functions to select suitable arguments when constructing test\ncases. Since automated test generators inherently rely on frequent execution of\ncandidate tests, we make use of these frequent executions to address this\nproblem by introducing type tracing, which extracts type-related information\nduring execution and gradually refines the available type information. We\nimplement type tracing as an extension of the Pynguin test-generation framework\nfor Python, allowing it (i) to infer parameter types by observing how\nparameters are used during runtime, (ii) to record the types of values that\nfunction calls return, and (iii) to use this type information to increase code\ncoverage. The approach leads to up to 90.0% more branch coverage, improved\nmutation scores, and to type information of similar quality to that produced by\nother state-of-the-art type-inference tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01477v1", "categories": ["cs.SE"], "cate": "cs.SE", "url": "http://arxiv.org/abs/2507.01477v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "结合类型推断和自动化单元测试生成用于 Python", "tldr": "该研究提出了一种结合类型追踪的方法，用于在 Python 等动态类型语言中进行自动化单元测试生成，通过运行时观察和记录类型信息，显著提高了测试覆盖率。", "motivation": "自动化单元测试生成在静态类型语言中已是成熟领域，但在 Python 等动态类型语言中，由于缺乏类型信息，测试生成器难以选择合适的参数来构建测试用例，从而阻碍了其应用。", "method": "研究引入了类型追踪（type tracing）方法，该方法在测试执行过程中提取类型相关信息并逐步完善类型信息。具体实现为 Pynguin 测试生成框架的扩展：(i) 通过观察参数在运行时的使用方式来推断参数类型；(ii) 记录函数调用返回值的类型；(iii) 利用这些类型信息来提高代码覆盖率。", "result": "该方法使分支覆盖率提高了高达 90.0%，提高了变异分数，并且生成的类型信息质量与现有最先进的类型推断工具相似。", "conclusion": "通过结合类型推断和自动化单元测试生成，该方法有效解决了动态类型语言中测试生成面临的类型信息缺失问题，显著提升了测试效果。", "translation": "自动化单元测试生成是一个成熟的研究领域，迄今为止主要集中在静态类型编程语言。Python 等动态类型编程语言中类型信息的缺失，阻碍了测试生成器的工作，因为它们严重依赖于函数的参数和返回类型信息来选择合适的参数构建测试用例。由于自动化测试生成器本质上依赖于对候选测试的频繁执行，我们利用这些频繁执行来解决这个问题，引入了类型追踪（type tracing），它在执行期间提取类型相关信息并逐步完善可用的类型信息。我们将类型追踪作为 Python 的 Pynguin 测试生成框架的扩展来实现，使其能够 (i) 通过观察参数在运行时的使用方式来推断参数类型，(ii) 记录函数调用返回值的类型，以及 (iii) 利用这些类型信息来增加代码覆盖率。该方法使分支覆盖率提高了高达 90.0%，提高了变异分数，并且生成的类型信息质量与现有最先进的类型推断工具相似。", "summary": "本研究提出了一种结合类型推断与自动化单元测试生成的新方法，以解决 Python 等动态类型语言中因缺乏类型信息而导致的测试生成挑战。通过引入类型追踪机制，在运行时动态地观察和完善类型信息，该方法显著提升了代码覆盖率和测试质量，实现了高达 90% 的分支覆盖率提升，并且其类型推断质量与现有先进工具相当。", "keywords": "类型推断, 自动化测试生成, Python, 动态类型语言, 类型追踪", "comments": "这项工作具有创新性，因为它利用了动态语言的运行时特性来克服静态类型信息缺失的挑战，这对于自动化测试生成在 Python 生态系统中的应用具有重要意义。通过将类型追踪集成到现有框架中，展示了其有效性和实用性。"}}
{"id": "2507.01423", "title": "A Compact 16-bit S-box over Tower Field $\\F_{(((2^2)^2)^2)^2}$ with High Security", "authors": ["Bahram Rashidi", "Behrooz Khadem"], "summary": "This paper introduces a compact and secure 16-bit substitution box (S-box)\ndesigned over the composite field $\\F_{(((2^2)^2)^2)^2}$, optimized for both\nhardware efficiency and cryptographic robustness. The proposed S-box decomposes\noperations into subfields, leveraging a tower field architecture. This enables\nsignificant hardware reduction through optimized field inversion and a low-cost\naffine transformation. Security evaluations confirm resilience against linear,\ndifferential, algebraic and DPA attacks, validated via metrics including\nNonlinearity (32512), Differential Uniformity (4), Algebraic Degree (15),\nTransparency order (15.9875) and SNR (0.34e-08). The hardware results, in 65 nm\nCMOS technology, show the proposed 16-bit S-box has lower hardware resources\nconsumption and lower critical path delay (CPD) than those of other 16-bit\nS-boxes. By integrating high algebraic complexity with resource-efficient\nstructures, this work addresses the growing demand for scalable cryptographic\nprimitives in data-sensitive applications, demonstrating that larger S-boxes\ncan enhance security without proportional hardware costs. The results\nunderscore the viability of composite field-based architectures in balancing\nsecurity and efficiency for modern block ciphers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01423v1", "categories": ["cs.CR"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01423v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "一种基于塔域$\\\\F_{(((2^2)^2)^2)^2}$的紧凑型16位高安全性S盒", "tldr": "本文提出了一种紧凑且安全的16位S盒，它利用塔域架构在硬件效率和密码鲁棒性方面进行了优化，并在安全性和硬件资源方面表现出色。", "motivation": "为了满足数据敏感应用中对可扩展密码原语日益增长的需求，并解决在不显著增加硬件成本的情况下增强更大S盒安全性的挑战。", "method": "通过在复合域$\\\\F_{(((2^2)^2)^2)^2}$上设计S盒，将操作分解为子域，利用塔域架构。通过优化的域逆和低成本仿射变换实现硬件资源显著减少。", "result": "该S盒的非线性度为32512，差分均匀度为4，代数度为15，透明度阶为15.9875，信噪比为0.34e-08。在65纳米CMOS技术下，与现有16位S盒相比，其硬件资源消耗更低，关键路径延迟（CPD）更短。", "conclusion": "复合域架构在平衡现代分组密码的安全性与效率方面是可行的，并且更大的S盒可以在不显著增加硬件成本的情况下增强安全性。", "translation": "本文介绍了一种紧凑且安全的16位替代盒（S盒），该S盒设计在复合域$\\\\F_{(((2^2)^2)^2)^2}$上，针对硬件效率和密码鲁棒性进行了优化。所提出的S盒将操作分解为子域，利用了塔域架构。这通过优化的域逆和低成本仿射变换实现了显著的硬件缩减。安全评估证实了其对线性、差分、代数和DPA攻击的抵抗能力，通过非线性度（32512）、差分均匀度（4）、代数度（15）、透明度阶（15.9875）和信噪比（0.34e-08）等指标进行了验证。在65纳米CMOS技术下的硬件结果表明，所提出的16位S盒比其他16位S盒具有更低的硬件资源消耗和更低的关键路径延迟（CPD）。通过将高代数复杂性与资源高效结构相结合，这项工作解决了数据敏感应用中对可扩展密码原语日益增长的需求，证明了更大的S盒可以在不按比例增加硬件成本的情况下增强安全性。结果强调了基于复合域的架构在平衡现代分组密码的安全性与效率方面的可行性。", "summary": "本文提出了一种基于塔域$\\\\F_{(((2^2)^2)^2)^2}$的紧凑型16位S盒，旨在优化硬件效率和密码安全性。该设计利用塔域架构分解操作，并通过优化的域逆和低成本仿射变换显著减少硬件资源。安全评估（包括非线性度、差分均匀度等指标）证实了其对多种攻击的抵抗力。硬件实现结果表明，该S盒在资源消耗和关键路径延迟方面均优于现有方案，证明了复合域架构在平衡现代密码学中安全性和效率方面的潜力。", "keywords": "S盒, 塔域, 16位S盒, 密码学, 硬件效率", "comments": "该论文的创新之处在于其S盒设计采用了塔域架构，有效平衡了高安全性（通过高代数复杂性实现）与硬件效率（通过资源高效结构实现）。这对于数据敏感应用中的可扩展密码原语具有重要意义，尤其是在证明了更大S盒可以在不显著增加硬件成本的情况下提升安全性方面。"}}
{"id": "2507.01360", "title": "MmBack: Clock-free Multi-Sensor Backscatter with Synchronous Acquisition and Multiplexing", "authors": ["Yijie Li", "Weichong Ling", "Taiting Lu", "Yi-Chao Chen", "Vaishnavi Ranganathan", "Lili Qiu", "Jingxian Wang"], "summary": "Backscatter tags provide a low-power solution for sensor applications, yet\nmany real-world scenarios require multiple sensors-often of different types-for\ncomplex sensing tasks. However, existing designs support only a single sensor\nper tag, increasing spatial overhead. State-of-the-art approaches to\nmultiplexing multiple sensor streams on a single tag rely on onboard clocks or\nmultiple modulation chains, which add cost, enlarge form factor, and remain\nprone to timing drift-disrupting synchronization across sensors.\n  We present mmBack, a low-power, clock-free backscatter tag that enables\nsynchronous multi-sensor data acquisition and multiplexing over a single\nmodulation chain. mmBack synchronizes sensor inputs in parallel using a shared\nreference signal extracted from ambient RF excitation, eliminating the need for\nan onboard timing source. To efficiently multiplex sensor data, mmBack designs\na voltage-division scheme to multiplex multiple sensor inputs as backscatter\nfrequency shifts through a single oscillator and RF switch. At the receiver,\nmmBack develops a frequency tracking algorithm and a finite-state machine for\naccurate demultiplexing. mmBack's ASIC design consumes 25.56uW, while its\nprototype supports 5 concurrent sensor streams with bandwidths of up to 5kHz\nand 3 concurrent sensor streams with bandwidth of up to 18kHz. Evaluation shows\nthat mmBack achieves an average SNR surpassing 15dB in signal reconstruction.", "comment": "16 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.01360v1", "categories": ["cs.NI", "eess.SP"], "cate": "cs.NI", "url": "http://arxiv.org/abs/2507.01360v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "MmBack：无时钟多传感器反向散射同步采集与复用", "tldr": "mmBack是一种低功耗、无时钟的反向散射标签，通过共享RF参考信号实现多传感器同步采集和单调制链复用，解决了现有方案的成本、尺寸和同步问题。", "motivation": "现有反向散射标签仅支持单个传感器，增加空间开销。多传感器复用方案依赖板载时钟或多调制链，导致成本增加、尺寸增大且易受时序漂移影响，破坏传感器同步。", "method": "mmBack通过从环境RF激励中提取共享参考信号来并行同步传感器输入，消除对板载时钟的需求。它设计了一种分压方案，通过单个振荡器和RF开关将多个传感器输入复用为反向散射频移。接收端开发了频率跟踪算法和有限状态机进行精确解复用。", "result": "mmBack的ASIC设计功耗为25.56uW。原型支持5个并发传感器流，带宽高达5kHz；或3个并发传感器流，带宽高达18kHz。信号重建平均SNR超过15dB。", "conclusion": "mmBack成功实现了一种低功耗、无时钟的多传感器反向散射标签，有效解决了现有方案在多传感器同步和复用方面的挑战，提高了效率和性能。", "translation": "反向散射标签为传感器应用提供了一种低功耗解决方案，然而许多现实场景需要多个传感器——通常是不同类型的——来完成复杂的传感任务。但是，现有设计每个标签仅支持单个传感器，增加了空间开销。最先进的在单个标签上复用多个传感器流的方法依赖于板载时钟或多个调制链，这增加了成本，增大了尺寸，并且容易出现时序漂移——破坏传感器间的同步。\n我们提出了mmBack，一种低功耗、无时钟的反向散射标签，它能够通过单个调制链实现同步多传感器数据采集和复用。mmBack通过从环境射频激励中提取共享参考信号，并行同步传感器输入，从而消除了对板载计时源的需求。为了高效地复用传感器数据，mmBack设计了一种分压方案，通过单个振荡器和射频开关将多个传感器输入复用为反向散射频移。在接收端，mmBack开发了一种频率跟踪算法和有限状态机，用于精确解复用。mmBack的ASIC设计功耗为25.56uW，其原型支持5个并发传感器流，带宽高达5kHz，以及3个并发传感器流，带宽高达18kHz。评估表明，mmBack在信号重建中实现了超过15dB的平均信噪比。", "summary": "本文提出mmBack，一种创新的低功耗、无时钟反向散射标签，旨在解决现有方案在多传感器同步和复用方面的局限性。mmBack利用环境RF激励的共享参考信号实现传感器同步，并通过独特的分压方案在单个调制链上高效复用多传感器数据。其ASIC设计功耗极低，原型展现出支持多并发高带宽传感器流的能力，并在信号重建方面表现出色。", "keywords": "反向散射, 多传感器, 无时钟, 同步采集, 复用", "comments": "mmBack的创新点在于其无时钟设计和通过环境RF信号实现多传感器同步，以及高效的分压复用方案，这显著降低了功耗、成本和尺寸，同时解决了传统方案的时序漂移问题，对低功耗物联网和多传感器应用具有重要意义。"}}
{"id": "2507.01182", "title": "Rapid Salient Object Detection with Difference Convolutional Neural Networks", "authors": ["Zhuo Su", "Li Liu", "Matthias Müller", "Jiehua Zhang", "Diana Wofk", "Ming-Ming Cheng", "Matti Pietikäinen"], "summary": "This paper addresses the challenge of deploying salient object detection\n(SOD) on resource-constrained devices with real-time performance. While recent\nadvances in deep neural networks have improved SOD, existing top-leading models\nare computationally expensive. We propose an efficient network design that\ncombines traditional wisdom on SOD and the representation power of modern CNNs.\nLike biologically-inspired classical SOD methods relying on computing contrast\ncues to determine saliency of image regions, our model leverages Pixel\nDifference Convolutions (PDCs) to encode the feature contrasts. Differently,\nPDCs are incorporated in a CNN architecture so that the valuable contrast cues\nare extracted from rich feature maps. For efficiency, we introduce a difference\nconvolution reparameterization (DCR) strategy that embeds PDCs into standard\nconvolutions, eliminating computation and parameters at inference.\nAdditionally, we introduce SpatioTemporal Difference Convolution (STDC) for\nvideo SOD, enhancing the standard 3D convolution with spatiotemporal contrast\ncapture. Our models, SDNet for image SOD and STDNet for video SOD, achieve\nsignificant improvements in efficiency-accuracy trade-offs. On a Jetson Orin\ndevice, our models with $<$ 1M parameters operate at 46 FPS and 150 FPS on\nstreamed images and videos, surpassing the second-best lightweight models in\nour experiments by more than $2\\times$ and $3\\times$ in speed with superior\naccuracy. Code will be available at https://github.com/hellozhuo/stdnet.git.", "comment": "16 pages, accepted in TPAMI", "pdf_url": "http://arxiv.org/pdf/2507.01182v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01182v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "快速显著目标检测与差分卷积神经网络", "tldr": "提出了一种基于差分卷积的高效显著目标检测网络，可在资源受限设备上实现快速准确的图像和视频SOD。", "motivation": "现有深度学习显著目标检测模型计算成本高昂，难以在资源受限设备上实现实时性能，限制了其在资源受限设备上的部署。", "method": "提出了一种高效网络设计，结合了传统SOD方法的对比度计算和现代CNN的表示能力。核心技术包括：利用像素差分卷积（PDCs）编码特征对比度；引入差分卷积重参数化（DCR）策略，将PDCs嵌入标准卷积以消除推理时的计算和参数开销；为视频SOD引入时空差分卷积（STDC）增强3D卷积以捕获时空对比度。最终模型为SDNet（图像SOD）和STDNet（视频SOD）。", "result": "SDNet和STDNet在效率-精度权衡方面取得显著改进。在Jetson Orin设备上，参数量小于1M的模型在流式图像和视频上分别达到46 FPS和150 FPS，速度比次优轻量级模型快2倍和3倍以上，且精度更优。", "conclusion": "该研究通过引入差分卷积和重参数化策略，成功解决了显著目标检测在资源受限设备上的实时部署挑战，实现了高效且高精度的图像和视频SOD。", "translation": "这篇论文解决了在资源受限设备上部署显著目标检测（SOD）并实现实时性能的挑战。尽管深度神经网络的最新进展改进了SOD，但现有领先模型计算成本高昂。我们提出了一种高效的网络设计，结合了传统SOD的智慧和现代CNN的表示能力。像受生物学启发的经典SOD方法依赖计算对比度线索来确定图像区域的显著性一样，我们的模型利用像素差分卷积（PDCs）来编码特征对比度。不同的是，PDCs被整合到CNN架构中，以便从丰富的特征图中提取有价值的对比度线索。为了提高效率，我们引入了一种差分卷积重参数化（DCR）策略，将PDCs嵌入到标准卷积中，从而在推理时消除了计算和参数。此外，我们引入了时空差分卷积（STDC）用于视频SOD，通过时空对比度捕获增强了标准3D卷积。我们的模型，用于图像SOD的SDNet和用于视频SOD的STDNet，在效率-精度权衡方面取得了显著改进。在Jetson Orin设备上，我们参数小于1M的模型在流式图像和视频上分别以46 FPS和150 FPS的速度运行，在我们的实验中，速度比第二好的轻量级模型快2倍以上和3倍以上，且精度更优。代码将在https://github.com/hellozhuo/stdnet.git提供。", "summary": "本文提出一种名为差分卷积神经网络（DCNN）的高效显著目标检测（SOD）框架，旨在解决资源受限设备上的实时部署问题。该框架结合了传统对比度驱动的SOD思想与现代CNN的强大表示力，通过像素差分卷积（PDCs）和差分卷积重参数化（DCR）策略，实现了在标准卷积中高效编码特征对比度。针对视频SOD，还引入了时空差分卷积（STDC）。实验证明，SDNet（图像SOD）和STDNet（视频SOD）在Jetson Orin设备上展现出卓越的效率和精度，显著优于现有轻量级模型。", "keywords": "显著目标检测, 差分卷积, 实时性能, 资源受限设备, 深度学习", "comments": "这篇论文的创新点在于将传统SOD中基于对比度的思想与现代CNN架构相结合，通过引入像素差分卷积（PDCs）和差分卷积重参数化（DCR）策略，有效地解决了深度学习模型在资源受限设备上部署的计算效率问题。其提出的SDNet和STDNet在保持高精度的同时，实现了显著的速度提升，对于边缘计算和实时应用具有重要意义。"}}
{"id": "2507.01462", "title": "Quantum-Assisted Automatic Path-Planning for Robotic Quality Inspection in Industry 4.0", "authors": ["Eneko Osaba", "Estibaliz Garrote", "Pablo Miranda-Rodriguez", "Alessia Ciacco", "Itziar Cabanes", "Aitziber Mancisidor"], "summary": "This work explores the application of hybrid quantum-classical algorithms to\noptimize robotic inspection trajectories derived from Computer-Aided Design\n(CAD) models in industrial settings. By modeling the task as a 3D variant of\nthe Traveling Salesman Problem, incorporating incomplete graphs and open-route\nconstraints, this study evaluates the performance of two D-Wave-based solvers\nagainst classical methods such as GUROBI and Google OR-Tools. Results across\nfive real-world cases demonstrate competitive solution quality with\nsignificantly reduced computation times, highlighting the potential of quantum\napproaches in automation under Industry 4.0.", "comment": "2 pages, 1 figure, paper accepted for presentation at the IEEE\n  International Conference on Quantum Computing and Engineering (QCE)", "pdf_url": "http://arxiv.org/pdf/2507.01462v1", "categories": ["cs.RO", "cs.AI", "cs.ET"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01462v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "量子辅助的工业4.0机器人质量检测自动路径规划", "tldr": "本文探讨了混合量子-经典算法在工业4.0中优化机器人检测路径的应用，通过将任务建模为旅行商问题，并与经典方法对比，展示了量子方法在计算时间上的显著优势。", "motivation": "优化工业4.0中机器人质量检测的轨迹，解决从CAD模型导出的复杂路径规划问题，并探索混合量子-经典算法的应用潜力。", "method": "将机器人检测轨迹优化任务建模为三维旅行商问题（TSP）的变体，包含不完整图和开放路线约束。使用D-Wave量子退火器（两种求解器）与经典方法（GUROBI和Google OR-Tools）进行性能比较。", "result": "在五个真实案例中，量子方法展现出与经典方法相当的解决方案质量，并且显著减少了计算时间。", "conclusion": "混合量子-经典算法在工业4.0自动化中的路径规划任务中具有巨大潜力，尤其是在缩短计算时间方面。", "translation": "这项工作探讨了混合量子-经典算法在优化工业环境中从计算机辅助设计（CAD）模型导出的机器人检测轨迹方面的应用。通过将任务建模为旅行商问题的3D变体，并结合不完整图和开放路线约束，本研究评估了两种基于D-Wave的求解器与GUROBI和Google OR-Tools等经典方法的性能。在五个真实案例中的结果表明，解决方案质量具有竞争力，同时计算时间显著减少，突出了量子方法在工业4.0自动化中的潜力。", "summary": "本研究将机器人质量检测的路径规划问题建模为带有特定约束的三维旅行商问题，并利用混合量子-经典算法（D-Wave求解器）与传统优化算法（GUROBI, Google OR-Tools）进行对比。实验结果表明，量子方法在保证解决方案质量的同时，显著缩短了计算时间，证明了其在工业4.0自动化领域的应用前景。", "keywords": "量子计算, 机器人路径规划, 工业4.0, 旅行商问题, 质量检测", "comments": "这篇论文的创新点在于将量子计算应用于实际工业场景中的机器人路径规划问题，并将其建模为TSP的变体。其重要性在于证明了量子辅助方法在计算效率上的潜在优势，为工业4.0中的复杂优化问题提供了新的解决方案。局限性可能在于D-Wave解决方案的普适性和硬件可及性，以及其在更大规模问题上的表现。"}}
{"id": "2507.01166", "title": "A Methodological Framework for Capturing Cognitive-Affective States in Collaborative Learning", "authors": ["Sifatul Anindho", "Videep Venkatesha", "Nathaniel Blanchard"], "summary": "Identification of affective and attentional states of individuals within\ngroups is difficult to obtain without disrupting the natural flow of\ncollaboration. Recent work from our group used a retrospect cued recall\nparadigm where participants spoke about their cognitive-affective states while\nthey viewed videos of their groups. We then collected additional participants\nwhere their reports were constrained to a subset of pre-identified\ncognitive-affective states. In this latter case, participants either self\nreported or reported in response to probes. Here, we present an initial\nanalysis of the frequency and temporal distribution of participant reports, and\nhow the distributions of labels changed across the two collections. Our\napproach has implications for the educational data mining community in tracking\ncognitive-affective states in collaborative learning more effectively and in\ndeveloping improved adaptive learning systems that can detect and respond to\ncognitive-affective states.", "comment": "Accepted to the Interactive Workshop: Multimodal, Multiparty Learning\n  Analytics (MMLA) at the conference Educational Data Mining (EDM) 2025", "pdf_url": "http://arxiv.org/pdf/2507.01166v1", "categories": ["cs.HC"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01166v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "协作学习中捕捉认知情感状态的方法学框架", "tldr": "本文提出了一种捕捉协作学习中认知情感状态的方法学框架，通过回顾性线索回忆范式收集数据，并分析了参与者报告的频率和时间分布，为教育数据挖掘和自适应学习系统提供了启示。", "motivation": "在不干扰协作自然流程的情况下，识别群体中个体的情感和注意力状态是困难的。", "method": "研究团队使用回顾性线索回忆范式，参与者在观看团队视频时报告他们的认知情感状态。随后，收集了其他参与者的数据，他们的报告被限制在预先识别的认知情感状态子集中，通过自我报告或探针响应进行。本文对参与者报告的频率和时间分布以及标签分布在两次数据收集中的变化进行了初步分析。", "result": "本文对参与者报告的频率和时间分布进行了初步分析，并分析了标签分布在两次数据收集中的变化情况。", "conclusion": "所提出的方法对教育数据挖掘社区更有效地跟踪协作学习中的认知情感状态，以及开发能够检测和响应认知情感状态的改进自适应学习系统具有重要意义。", "translation": "在不干扰协作自然流程的情况下，识别群体中个体的情感和注意力状态是难以获得的。我们团队最近的工作使用了一种回顾性线索回忆范式，参与者在观看他们团队的视频时谈论他们的认知情感状态。然后，我们收集了其他参与者的数据，他们的报告被限制在预先识别的认知情感状态子集中。在后一种情况下，参与者要么是自我报告，要么是响应探针进行报告。在此，我们对参与者报告的频率和时间分布进行了初步分析，以及标签分布在两次数据收集中的变化情况。我们的方法对于教育数据挖掘社区在协作学习中更有效地跟踪认知情感状态以及开发能够检测和响应认知情感状态的改进自适应学习系统具有重要意义。", "summary": "本文介绍了一种捕捉协作学习中认知情感状态的方法学框架。研究团队通过回顾性线索回忆范式收集数据，让参与者在观看团队视频时报告认知情感状态，或在预设状态下进行自我报告或响应探针报告。本研究对这些报告的频率和时间分布及其在不同数据收集中的变化进行了初步分析。该方法对教育数据挖掘和开发自适应学习系统具有重要启示。", "keywords": "认知情感状态, 协作学习, 方法学框架, 教育数据挖掘, 自适应学习系统", "comments": "该论文提出了一种非侵入性的方法来捕捉协作学习中的认知情感状态，这对于理解和改进学习过程至关重要。其创新点在于采用了回顾性线索回忆范式，并对报告方式进行了探索和分析。该方法学框架有望推动教育数据挖掘和自适应学习系统的发展，使其能更有效地识别并响应学习者的内在状态。"}}
{"id": "2507.01029", "title": "PathCoT: Chain-of-Thought Prompting for Zero-shot Pathology Visual Reasoning", "authors": ["Junjie Zhou", "Yingli Zuo", "Shichang Feng", "Peng Wan", "Qi Zhu", "Daoqiang Zhang", "Wei Shao"], "summary": "With the development of generative artificial intelligence and instruction\ntuning techniques, multimodal large language models (MLLMs) have made\nimpressive progress on general reasoning tasks. Benefiting from the\nchain-of-thought (CoT) methodology, MLLMs can solve the visual reasoning\nproblem step-by-step. However, existing MLLMs still face significant challenges\nwhen applied to pathology visual reasoning tasks: (1) LLMs often underperforms\nbecause they lack domain-specific information, which can lead to model\nhallucinations. (2) The additional reasoning steps in CoT may introduce errors,\nleading to the divergence of answers. To address these limitations, we propose\nPathCoT, a novel zero-shot CoT prompting method which integrates the pathology\nexpert-knowledge into the reasoning process of MLLMs and incorporates\nself-evaluation to mitigate divergence of answers. Specifically, PathCoT guides\nthe MLLM with prior knowledge to perform as pathology experts, and provides\ncomprehensive analysis of the image with their domain-specific knowledge. By\nincorporating the experts' knowledge, PathCoT can obtain the answers with CoT\nreasoning. Furthermore, PathCoT incorporates a self-evaluation step that\nassesses both the results generated directly by MLLMs and those derived through\nCoT, finally determining the reliable answer. The experimental results on the\nPathMMU dataset demonstrate the effectiveness of our method on pathology visual\nunderstanding and reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01029v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01029v1", "date": "2025-06-18", "updated": "2025-06-18", "AI": {"title_translation": "PathCoT：零样本病理视觉推理的思维链提示", "tldr": "PathCoT提出了一种新的零样本思维链提示方法，通过整合病理学专家知识和引入自我评估来解决多模态大语言模型在病理视觉推理中缺乏领域信息和思维链引入错误的问题，并在PathMMU数据集上取得了有效性。", "motivation": "现有的多模态大语言模型（MLLMs）在病理视觉推理任务中面临挑战：1) 缺乏领域特定信息导致模型幻觉和性能不佳；2) 思维链（CoT）中额外的推理步骤可能引入错误，导致答案分歧。", "method": "我们提出了PathCoT，一种新颖的零样本思维链（CoT）提示方法。PathCoT通过将病理学专家知识整合到MLLM的推理过程中，并结合自我评估来缓解答案分歧。具体而言，PathCoT利用先验知识指导MLLM像病理学专家一样进行分析，并提供全面的图像分析。通过整合专家知识，PathCoT能够通过CoT推理获得答案。此外，PathCoT引入了自我评估步骤，评估MLLM直接生成的结果和通过CoT得出的结果，最终确定可靠的答案。", "result": "在PathMMU数据集上的实验结果表明，我们的方法在病理视觉理解和推理方面是有效的。", "conclusion": "PathCoT通过结合病理学专家知识和自我评估机制，成功解决了现有MLLM在病理视觉推理中的局限性，提高了模型在该领域理解和推理的准确性和可靠性。", "translation": "随着生成式人工智能和指令微调技术的发展，多模态大语言模型（MLLMs）在通用推理任务上取得了令人瞩目的进展。受益于思维链（CoT）方法，MLLMs可以逐步解决视觉推理问题。然而，现有的MLLMs在应用于病理视觉推理任务时仍然面临重大挑战：(1) 大语言模型通常表现不佳，因为它们缺乏领域特定信息，这可能导致模型幻觉。(2) CoT中额外的推理步骤可能会引入错误，导致答案分歧。为了解决这些限制，我们提出了PathCoT，一种新颖的零样本CoT提示方法，它将病理学专家知识整合到MLLMs的推理过程中，并结合自我评估以减轻答案分歧。具体而言，PathCoT利用先验知识引导MLLM像病理学专家一样执行任务，并利用其领域特定知识对图像进行全面分析。通过整合专家知识，PathCoT可以通过CoT推理获得答案。此外，PathCoT包含一个自我评估步骤，评估MLLM直接生成的结果和通过CoT得出的结果，最终确定可靠的答案。在PathMMU数据集上的实验结果证明了我们方法在病理视觉理解和推理方面的有效性。", "summary": "PathCoT是一种针对零样本病理视觉推理的新型思维链（CoT）提示方法。该方法旨在解决多模态大语言模型（MLLMs）在病理领域面临的挑战，即缺乏领域特定知识导致的幻觉和CoT推理中可能引入的错误。PathCoT通过将病理学专家知识整合到MLLM的推理流程中，并引入自我评估机制来选择最可靠的答案。实验证明，PathCoT在病理视觉理解和推理任务上表现出有效性。", "keywords": "病理视觉推理, 思维链提示, 零样本学习, 多模态大语言模型, 专家知识", "comments": "PathCoT的创新之处在于其结合了领域专家知识和自我评估机制，有效解决了多模态大语言模型在特定领域（如病理学）应用中普遍存在的知识不足和推理错误累积问题。这种方法对于提升AI在专业领域的可靠性和准确性具有重要意义，尤其是在需要高精度判断的医疗领域。"}}
{"id": "2507.01769", "title": "Distance-based Relative Orbital Transition for Satellite Swarm Array Deployment Under J2 Perturbation", "authors": ["Yuta Takahashi", "Shin-ichiro Sakai"], "summary": "This paper presents an autonomous guidance and control strategy for a\nsatellite swarm that enables scalable distributed space structures for\ninnovative science and business opportunities. The averaged $J_2$ orbital\nparameters that describe the drift and periodic orbital motion were derived\nalong with their target values to achieve a distributed space structure in a\ndecentralized manner. This enabled the design of a distance-based orbital\nstabilizer to ensure autonomous deployment into a monolithic formation of a\ncoplanar equidistant configuration on a user-defined orbital plane. Continuous\nformation control was assumed to be achieved through fuel-free actuation, such\nas satellite magnetic field interaction and differential aerodynamic forces,\nthereby maintaining long-term formation stability without thruster usage. A\nmajor challenge for such actuation systems is the potential loss of control\ncapability due to increasing inter-satellite distances resulting from unstable\norbital dynamics, particularly for autonomous satellite swarms. To mitigate\nthis risk, our decentralized deployment controller minimized drift distance\nduring unexpected communication outages. As a case study, we consider the\ndeployment of palm-sized satellites into a coplanar equidistant formation in a\n$J_2$-perturbed orbit. Moreover, centralized grouping strategies are presented.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01769v1", "categories": ["cs.MA"], "cate": "cs.MA", "url": "http://arxiv.org/abs/2507.01769v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于距离的J2摄动下卫星群阵列部署相对轨道转换", "tldr": "本文提出了一种用于卫星群自主部署的制导和控制策略，旨在J2摄动下实现共面等距配置，并最小化通信中断时的漂移距离，以应对无燃料执行器的控制挑战。", "motivation": "为实现可扩展的分布式空间结构，并解决在J2摄动环境下，使用无燃料执行器时因轨道动力学不稳定导致的星间距离增加和控制能力丧失的挑战。", "method": "论文推导了描述漂移和周期性轨道运动的平均J2轨道参数及其目标值，用于分散式实现分布式空间结构。设计了基于距离的轨道稳定器，以实现共面等距配置的自主部署。假设通过无燃料执行器（如卫星磁场相互作用和差分气动力）进行连续编队控制。开发了分散式部署控制器，以在通信中断时最小化漂移距离。此外，还提出了集中式分组策略，并以掌上大小卫星的部署作为案例研究。", "result": "该策略能够将卫星群自主部署到用户定义的轨道平面上的共面等距整体编队。通过在意外通信中断期间最小化漂移距离，有效缓解了由于不稳定轨道动力学导致星间距离增加而引起的控制能力丧失风险。以掌上大小卫星的部署为例进行了验证。", "conclusion": "本文提出了一种在J2摄动下卫星群阵列部署的自主制导与控制策略，有效解决了无燃料执行器和通信中断带来的挑战，为实现长期稳定的分布式空间结构提供了可行方案。", "translation": "本文提出了一种卫星群自主制导与控制策略，旨在为创新科学和商业机会实现可扩展的分布式空间结构。论文推导了描述漂移和周期性轨道运动的平均J2轨道参数及其目标值，以分散方式实现分布式空间结构。这使得能够设计基于距离的轨道稳定器，以确保在用户定义的轨道平面上自主部署成共面等距配置的整体编队。假设通过无燃料执行器（例如卫星磁场相互作用和差分气动力）实现连续编队控制，从而在不使用推进器的情况下保持长期编队稳定性。对于此类执行器系统，一个主要挑战是由于不稳定的轨道动力学导致星间距离增加，可能导致控制能力丧失，特别是对于自主卫星群。为了减轻这种风险，我们的分散式部署控制器在意外通信中断期间最小化了漂移距离。作为案例研究，我们考虑了在J2摄动轨道中将掌上大小的卫星部署成共面等距编队。此外，还提出了集中式分组策略。", "summary": "本文提出了一种针对卫星群的自主制导和控制策略，旨在J2摄动下实现可扩展的分布式空间结构。通过推导平均J2轨道参数并设计基于距离的轨道稳定器，该策略能够将卫星自主部署到共面等距配置。为应对无燃料执行器系统（如磁场和气动力）在星间距离增加时可能面临的控制能力丧失问题，研究提出了一种分散式控制器，可在通信中断时最小化漂移距离，从而确保长期编队稳定性。文章还讨论了集中式分组策略，并通过掌上大小卫星的部署案例进行了验证。", "keywords": "卫星群, J2摄动, 编队控制, 无燃料执行, 分布式空间结构", "comments": "该论文提出了一种新颖的基于距离的控制策略，用于在J2摄动下部署卫星群，并强调了无燃料执行器的应用前景。其创新点在于通过最小化通信中断时的漂移距离来应对无燃料执行器系统的固有挑战，这对于实现长期自主且稳定的分布式空间结构至关重要。该研究对于未来大规模、低成本的卫星星座部署具有重要意义，尤其是在能源受限的深空任务中。"}}
{"id": "2507.01511", "title": "Modeling individual attention dynamics on online social media", "authors": ["Jaume Ojer", "Filippo Radicchi", "Santo Fortunato", "Michele Starnini", "Romualdo Pastor-Satorras"], "summary": "In the attention economy, understanding how individuals manage limited\nattention is critical. We introduce a simple model describing the decay of a\nuser's engagement when facing multiple inputs. We analytically show that\nindividual attention decay is determined by the overall duration of\ninteractions, not their number or user activity. Our model is validated using\ndata from Reddit's Change My View subreddit, where the user's attention\ndynamics is explicitly traceable. Despite its simplicity, our model offers a\ncrucial microscopic perspective complementing macroscopic studies.", "comment": "5 pages (main) + 2 pages (end matter) + 2 pages (supplementary\n  material)", "pdf_url": "http://arxiv.org/pdf/2507.01511v1", "categories": ["physics.soc-ph", "cs.SI"], "cate": "physics.soc-ph", "url": "http://arxiv.org/abs/2507.01511v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "在线社交媒体上个体注意力动态建模", "tldr": "本文提出了一个简单的模型来描述用户在面对多个输入时注意力衰减的规律，并分析表明个体注意力衰减由交互的总持续时间决定，而非交互数量或用户活跃度，该模型在Reddit数据上得到了验证。", "motivation": "在注意力经济中，理解个体如何管理有限的注意力至关重要。", "method": "引入了一个描述用户在面对多个输入时参与度衰减的简单模型。使用Reddit的Change My View子版块数据对模型进行了验证。", "result": "分析表明，个体注意力衰减由交互的总持续时间决定，而不是交互的数量或用户活动。尽管模型简单，但它提供了一个重要的微观视角，补充了宏观研究。", "conclusion": "该模型成功描述并验证了个体在在线社交媒体上的注意力衰减机制，揭示了注意力衰减由交互总持续时间决定的关键发现，为理解注意力经济提供了微观视角。", "translation": "在注意力经济中，理解个体如何管理有限的注意力至关重要。我们引入了一个简单的模型，描述了用户在面对多个输入时参与度的衰减。我们分析表明，个体注意力衰减是由交互的总持续时间决定的，而不是交互的数量或用户活动。我们的模型使用来自Reddit的Change My View子版块的数据进行了验证，在该版块中，用户的注意力动态是明确可追溯的。尽管其简单性，我们的模型提供了一个重要的微观视角，补充了宏观研究。", "summary": "本文针对注意力经济中个体注意力管理问题，提出了一个描述用户在多输入情境下参与度衰减的简单模型。研究通过分析和Reddit数据验证，发现个体注意力衰减主要由交互的总持续时间决定，而非交互数量或用户活跃度。该模型为理解个体注意力动态提供了有益的微观视角。", "keywords": "注意力动态, 在线社交媒体, 注意力衰减, 用户参与度, 模型验证", "comments": "本文提出了一种新颖且简单的模型来解释在线社交媒体上个体注意力的衰减机制。其创新之处在于明确指出注意力衰减的关键因素是交互的“总持续时间”，而非“数量”，这与直觉可能有所不同。模型在实际数据上的验证增加了其可信度，为注意力经济研究提供了重要的微观层面补充。"}}
{"id": "2507.01427", "title": "SDR-Empowered Environment Sensing Design and Experimental Validation Using OTFS-ISAC Signals", "authors": ["Jun Wu", "Yuye Shi", "Weijie Yuan", "Qingqing Cheng", "Buyi Li", "Xinyuan Wei"], "summary": "This paper investigates the system design and experimental validation of\nintegrated sensing and communication (ISAC) for environmental sensing, which is\nexpected to be a critical enabler for next-generation wireless networks. We\nadvocate exploiting orthogonal time frequency space (OTFS) modulation for its\ninherent sparsity and stability in delay-Doppler (DD) domain channels,\nfacilitating a low-overhead environment sensing design. Moreover, a\ncomprehensive environmental sensing framework is developed, encompassing DD\ndomain channel estimation, target localization, and experimental validation. In\nparticular, we first explore the OTFS channel estimation in the presence of\nfractional delay and Doppler shifts. Given the estimated parameters, we propose\na three-ellipse positioning algorithm to localize the target's position,\nfollowed by determining the mobile transmitter's velocity. Additionally, to\nevaluate the performance of our proposed design, we conduct extensive\nsimulations and experiments using a software-defined radio (SDR)-based platform\nwith universal software radio peripheral (USRP). The experimental validations\ndemonstrate that our proposed approach outperforms the benchmarks in terms of\nlocalization accuracy and velocity estimation, confirming its effectiveness in\npractical environmental sensing applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01427v1", "categories": ["eess.SP"], "cate": "eess.SP", "url": "http://arxiv.org/abs/2507.01427v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于SDR的OTFS-ISAC信号环境感知设计与实验验证", "tldr": "本文研究并实验验证了利用OTFS-ISAC信号进行环境感知的设计，该设计在定位精度和速度估计方面优于基准方法。", "motivation": "下一代无线网络中，集成感知与通信（ISAC）对环境感知至关重要。本文旨在利用OTFS调制的固有稀疏性和稳定性，实现低开销的环境感知设计。", "method": "开发了一个全面的环境感知框架，包括延迟-多普勒（DD）域信道估计、目标定位和实验验证。具体方法包括：探索存在分数延迟和多普勒频移的OTFS信道估计；提出一种三椭圆定位算法来定位目标位置并确定移动发射机速度；使用基于SDR的平台（USRP）进行广泛仿真和实验。", "result": "实验验证表明，所提出的方法在定位精度和速度估计方面优于基准方法。", "conclusion": "所提出的方法在实际环境感知应用中是有效的。", "translation": "本文研究了用于环境感知的集成感知与通信（ISAC）的系统设计和实验验证，ISAC有望成为下一代无线网络的关键使能技术。我们提倡利用正交时频空间（OTFS）调制，因为它在延迟-多普勒（DD）域信道中固有的稀疏性和稳定性，有助于实现低开销的环境感知设计。此外，开发了一个全面的环境感知框架，包括DD域信道估计、目标定位和实验验证。特别是，我们首先探讨了存在分数延迟和多普勒频移情况下的OTFS信道估计。给定估计参数，我们提出了一种三椭圆定位算法来定位目标位置，然后确定移动发射机的速度。此外，为了评估我们所提出设计的性能，我们使用基于软件定义无线电（SDR）的平台（通用软件无线电外设USRP）进行了广泛的仿真和实验。实验验证表明，我们提出的方法在定位精度和速度估计方面优于基准方法，证实了其在实际环境感知应用中的有效性。", "summary": "本文探讨了利用OTFS-ISAC信号进行环境感知的系统设计与实验验证。研究人员利用OTFS调制在DD域的稀疏性和稳定性，开发了一个包含DD域信道估计、目标定位和实验验证的全面环境感知框架。他们提出了一种三椭圆定位算法用于目标定位和速度估计。通过基于SDR的平台进行的仿真和实验表明，该方法在定位精度和速度估计方面优于现有基准，证明了其在实际应用中的有效性。", "keywords": "OTFS, ISAC, 环境感知, 定位, SDR", "comments": "本文的创新点在于将OTFS调制应用于ISAC环境感知，并提出了针对分数延迟和多普勒频移的信道估计以及三椭圆定位算法。通过SDR平台进行的实验验证增强了研究的实用性和可信度。该研究为下一代无线网络中的高效环境感知提供了有前景的解决方案。"}}
{"id": "2507.01464", "title": "Coding for Quasi-Static Fading Channel with Imperfect CSI at the Transmitter and Quantized Feedback", "authors": ["Yuhan Yang", "Mei Han", "Haonan Zhang", "Haoheng Yuan", "Fan Cheng", "Bin Dai"], "summary": "The classical Schalkwijk-Kailath (SK) scheme for the additive Gaussian noise\nchannel with noiseless feedback is highly efficient since its coding complexity\nis extremely low and the decoding error doubly exponentially decays as the\ncoding blocklength tends to infinity. However, its application to the fading\nchannel with imperfect CSI at the transmitter (I-CSIT) is challenging since the\nSK scheme is sensitive to the CSI. In this paper, we investigate how to design\nSK-type scheme for the quasi-static fading channel with I-CSIT and quantized\nfeedback. By introducing modulo lattice function and an auxiliary signal into\nthe SK-type encoder-decoder of the transceiver, we show that the decoding error\ncaused by the I-CSIT can be perfectly eliminated, resulting in the success of\ndesigning SK-type scheme for such a case. The study of this paper provides a\nway to design efficient coding scheme for fading channels in the presence of\nimperfect CSI and quantized feedback.", "comment": "7 pages, 6 figures, conference, this paper will be presented at the\n  2025 IEEE ITW", "pdf_url": "http://arxiv.org/pdf/2507.01464v1", "categories": ["cs.IT", "math.IT"], "cate": "cs.IT", "url": "http://arxiv.org/abs/2507.01464v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "准静态衰落信道编码，发射端CSI不完美及量化反馈", "tldr": "本文提出了一种改进的Schalkwijk-Kailath (SK) 方案，适用于发射端CSI不完美和量化反馈的准静态衰落信道，通过引入模格函数和辅助信号，成功消除了不完美CSI导致的解码误差。", "motivation": "经典的Schalkwijk-Kailath (SK) 方案虽然高效，但对信道状态信息（CSI）敏感，难以直接应用于发射端CSI不完美的衰落信道。", "method": "通过在SK型收发器的编解码器中引入模格函数和辅助信号。", "result": "完美消除了由发射端不完美CSI引起的解码错误。", "conclusion": "本研究提供了一种在存在不完美CSI和量化反馈的情况下，为衰落信道设计高效编码方案的方法。", "translation": "经典的Schalkwijk-Kailath (SK) 方案，用于加性高斯噪声信道且无噪声反馈，效率极高，因为其编码复杂度极低，并且解码错误率随编码码长趋于无穷时呈双指数衰减。然而，将其应用于发射端信道状态信息（CSI）不完美（I-CSIT）的衰落信道具有挑战性，因为SK方案对CSI敏感。在本文中，我们研究了如何为发射端CSI不完美和量化反馈的准静态衰落信道设计SK型方案。通过在SK型收发器的编解码器中引入模格函数和辅助信号，我们证明了由I-CSIT引起的解码错误可以被完美消除，从而成功设计了适用于这种情况的SK型方案。本文的研究为在存在不完美CSI和量化反馈的情况下，为衰落信道设计高效编码方案提供了一种方法。", "summary": "本文针对发射端信道状态信息（CSI）不完美和量化反馈的准静态衰落信道，提出了一种改进的Schalkwijk-Kailath (SK) 型编码方案。通过在收发器中引入模格函数和辅助信号，该方案能够有效消除不完美CSI导致的解码错误，为设计高效的衰落信道编码提供了新途径。", "keywords": "准静态衰落信道, 不完美CSI, 量化反馈, Schalkwijk-Kailath方案, 模格函数", "comments": "这篇论文的创新点在于成功地将对CSI敏感的SK方案推广到更实际的衰落信道场景，解决了I-CSIT带来的挑战。通过巧妙地引入模格函数和辅助信号，实现了对解码错误的完美消除，这对于实际通信系统的鲁棒性设计具有重要意义。"}}
{"id": "2507.01298", "title": "Optimal Dispersion Under Asynchrony", "authors": ["Debasish Pattanayak", "Ajay D. Kshemkalyani", "Manish Kumar", "Anisur Rahaman Molla", "Gokarna Sharma"], "summary": "We study the dispersion problem in anonymous port-labeled graphs: $k \\leq n$\nmobile agents, each with a unique ID and initially located arbitrarily on the\nnodes of an $n$-node graph with maximum degree $\\Delta$, must autonomously\nrelocate so that no node hosts more than one agent. Dispersion serves as a\nfundamental task in distributed computing of mobile agents, and its complexity\nstems from key challenges in local coordination under anonymity and limited\nmemory.\n  The goal is to minimize both the time to achieve dispersion and the memory\nrequired per agent. It is known that any algorithm requires $\\Omega(k)$ time in\nthe worst case, and $\\Omega(\\log k)$ bits of memory per agent. A recent result\n[SPAA'25] gives an optimal $O(k)$-time algorithm in the synchronous setting and\nan $O(k \\log k)$-time algorithm in the asynchronous setting, both using\n$O(\\log(k+\\Delta))$ bits.\n  In this paper, we close the complexity gap in the asynchronous setting by\npresenting the first dispersion algorithm that runs in optimal $O(k)$ time\nusing $O(\\log(k+\\Delta))$ bits of memory per agent. Our solution is based on a\nnovel technique we develop in this paper that constructs a port-one tree in\nanonymous graphs, which may be of independent interest.", "comment": "35 pages, 5 figures, 2 tables, and 6 pseudocodes", "pdf_url": "http://arxiv.org/pdf/2507.01298v1", "categories": ["cs.DC", "cs.DS", "cs.MA", "cs.RO"], "cate": "cs.DC", "url": "http://arxiv.org/abs/2507.01298v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "异步条件下的最优分散", "tldr": "本文提出了首个在异步设置下以最优时间复杂度O(k)和O(log(k+Δ))的内存实现移动代理分散问题的算法，填补了现有复杂度空白。", "motivation": "分散是移动代理分布式计算中的一项基本任务，其复杂性源于匿名和有限内存下的局部协调挑战。目标是最小化分散所需的时间和每个代理所需的内存。", "method": "本文提出了一种新的技术，用于在匿名图中构建一个端口一棵树（port-one tree），并以此为基础设计了分散算法。", "result": "本文提出的分散算法在异步设置下，实现了最优的O(k)时间复杂度，并且每个代理使用O(log(k+Δ))比特的内存。", "conclusion": "本文通过提出一种新的端口一棵树构建技术，成功解决了异步设置下移动代理分散问题的复杂度差距，达到了理论最优的时间复杂度，为该领域提供了重要进展。", "translation": "我们研究了匿名端口标记图中的分散问题：k ≤ n个移动代理，每个代理都有唯一的ID，最初任意地分布在n个节点、最大度为Δ的图的节点上，它们必须自主重新定位，以确保没有节点承载多于一个代理。分散是移动代理分布式计算中的一项基本任务，其复杂性源于匿名和有限内存下的局部协调中的关键挑战。\n目标是最小化实现分散所需的时间和每个代理所需的内存。已知任何算法在最坏情况下都需要Ω(k)的时间，每个代理需要Ω(log k)比特的内存。最近的一项成果[SPAA'25]在同步设置下给出了最优的O(k)时间算法，在异步设置下给出了O(k log k)时间算法，两者都使用了O(log(k+Δ))比特。\n在本文中，我们通过提出第一个在最优O(k)时间内运行、每个代理使用O(log(k+Δ))比特内存的分散算法，弥补了异步设置中的复杂度差距。我们的解决方案基于我们本文开发的一种新颖技术，该技术在匿名图中构建了一个端口一棵树，这可能具有独立的意义。", "summary": "本文研究了匿名端口标记图中移动代理的分散问题，旨在使k个代理在n个节点图中自主重新定位，确保每个节点最多一个代理，并同时最小化时间与内存。针对异步设置下的复杂度差距，本文提出了一个创新的算法，该算法基于构建端口一棵树的新技术，实现了最优的O(k)时间复杂度和O(log(k+Δ))的内存使用，从而弥补了现有研究的不足。", "keywords": "移动代理, 分散问题, 异步设置, 最优算法, 端口一棵树", "comments": "本文的创新点在于提出了一个新颖的“端口一棵树”构建技术，并利用此技术在异步环境下首次实现了移动代理分散问题的理论最优时间复杂度。这不仅解决了长期存在的复杂度差距，而且所提出的核心技术可能在其他匿名图问题中也具有独立的适用价值，对分布式算法领域具有重要意义。"}}
{"id": "2507.01304", "title": "A Practical SAFE-AI Framework for Small and Medium-Sized Enterprises Developing Medical Artificial Intelligence Ethics Policies", "authors": ["Ion Nemteanu", "Adir Mancebo Jr.", "Leslie Joe", "Ryan Lopez", "Patricia Lopez", "Warren Woodrich Pettine"], "summary": "Artificial intelligence (AI) offers incredible possibilities for patient\ncare, but raises significant ethical issues, such as the potential for bias.\nPowerful ethical frameworks exist to minimize these issues, but are often\ndeveloped for academic or regulatory environments and tend to be comprehensive\nbut overly prescriptive, making them difficult to operationalize within\nfast-paced, resource-constrained environments. We introduce the Scalable Agile\nFramework for Execution in AI (SAFE-AI) designed to balance ethical rigor with\nbusiness priorities by embedding ethical oversight into standard Agile-based\nproduct development workflows. The framework emphasizes the early establishment\nof testable acceptance criteria, fairness metrics, and transparency metrics to\nmanage model uncertainty, while also promoting continuous monitoring and\nre-evaluation of these metrics across the AI lifecycle. A core component of\nthis framework are responsibility metrics using scenario-based probability\nanalogy mapping designed to enhance transparency and stakeholder trust. This\nensures that retraining or tuning activities are subject to lightweight but\nmeaningful ethical review. By focusing on the minimum necessary requirements\nfor responsible development, our framework offers a scalable, business-aligned\napproach to ethical AI suitable for organizations without dedicated ethics\nteams.", "comment": "31 pages, two figures", "pdf_url": "http://arxiv.org/pdf/2507.01304v1", "categories": ["cs.CY"], "cate": "cs.CY", "url": "http://arxiv.org/abs/2507.01304v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "中小型企业开发医疗人工智能伦理政策的实用SAFE-AI框架", "tldr": "针对中小型企业，本文提出了一个实用的SAFE-AI框架，旨在平衡医疗AI的伦理严谨性与业务优先级，尤其适用于资源受限的组织。", "motivation": "AI在医疗领域潜力巨大，但存在偏见等伦理问题。现有伦理框架过于全面且规范性强，难以在资源有限、快节奏的环境中操作，特别是不适合没有专门伦理团队的中小型企业。", "method": "本文引入了“AI执行可扩展敏捷框架 (SAFE-AI)”，通过将伦理监督嵌入标准的基于敏捷的产品开发工作流程中，以平衡伦理严谨性与业务优先级。该框架强调早期建立可测试的验收标准、公平性指标和透明度指标，并促进在AI生命周期中对这些指标的持续监控和重新评估。核心组件是使用基于场景的概率类比映射的责任指标，旨在增强透明度和利益相关者信任。", "result": "SAFE-AI框架提供了一种可扩展的、与业务对齐的伦理AI方法，适用于没有专门伦理团队的组织。它确保了AI再训练或调整活动受到轻量级但有意义的伦理审查。", "conclusion": "通过关注负责任开发的最低必要要求，SAFE-AI框架为中小型企业提供了一个实用的、可扩展的、与业务对齐的伦理AI方法。", "translation": "人工智能（AI）为患者护理提供了令人难以置信的可能性，但也引发了重大的伦理问题，例如潜在的偏见。现有的强大伦理框架旨在最大限度地减少这些问题，但它们通常是为学术或监管环境而开发的，倾向于全面但过于规范，这使得它们在快节奏、资源受限的环境中难以操作。我们引入了AI执行可扩展敏捷框架（SAFE-AI），旨在通过将伦理监督嵌入标准的基于敏捷的产品开发工作流程中，来平衡伦理严谨性与业务优先级。该框架强调早期建立可测试的验收标准、公平性指标和透明度指标，以管理模型不确定性，同时促进在AI生命周期中对这些指标的持续监控和重新评估。该框架的核心组成部分是使用基于场景的概率类比映射的责任指标，旨在增强透明度和利益相关者信任。这确保了再训练或调整活动受到轻量级但有意义的伦理审查。通过关注负责任开发的最低必要要求，我们的框架为没有专门伦理团队的组织提供了一种可扩展的、与业务对齐的伦理AI方法。", "summary": "本文提出了一种名为SAFE-AI的实用框架，旨在帮助中小型企业在开发医疗AI时制定伦理政策。该框架通过将伦理监督融入敏捷开发流程，平衡伦理严谨性与业务需求。它强调早期建立可测试的伦理指标，并进行持续监控，尤其引入了基于场景的责任指标，以提升透明度和信任，为资源有限的组织提供可操作的伦理AI开发方法。", "keywords": "医疗AI伦理, SAFE-AI, 敏捷开发, 中小型企业, 负责任AI", "comments": "该论文的创新之处在于提出了一个针对中小型企业和资源受限环境的实用伦理AI框架，解决了现有伦理框架过于复杂、难以落地的问题。它将伦理监督融入敏捷开发流程，强调早期、可测试的伦理指标和持续监控，并通过责任指标增强透明度，对推动医疗AI的负责任发展具有重要意义。"}}
{"id": "2507.01676", "title": "Deep Recommender Models Inference: Automatic Asymmetric Data Flow Optimization", "authors": ["Giuseppe Ruggeri", "Renzo Andri", "Daniele Jahier Pagliari", "Lukas Cavigelli"], "summary": "Deep Recommender Models (DLRMs) inference is a fundamental AI workload\naccounting for more than 79% of the total AI workload in Meta's data centers.\nDLRMs' performance bottleneck is found in the embedding layers, which perform\nmany random memory accesses to retrieve small embedding vectors from tables of\nvarious sizes. We propose the design of tailored data flows to speedup\nembedding look-ups. Namely, we propose four strategies to look up an embedding\ntable effectively on one core, and a framework to automatically map the tables\nasymmetrically to the multiple cores of a SoC. We assess the effectiveness of\nour method using the Huawei Ascend AI accelerators, comparing it with the\ndefault Ascend compiler, and we perform high-level comparisons with Nvidia\nA100. Results show a speed-up varying from 1.5x up to 6.5x for real workload\ndistributions, and more than 20x for extremely unbalanced distributions.\nFurthermore, the method proves to be much more independent of the query\ndistribution than the baseline.", "comment": "5 pages, 4 figures, conference: IEEE ICCD24", "pdf_url": "http://arxiv.org/pdf/2507.01676v1", "categories": ["cs.DC", "cs.AI", "cs.AR", "cs.IR", "C.4; D.1.3; H.3.3; H.3.4"], "cate": "cs.DC", "url": "http://arxiv.org/abs/2507.01676v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "深度推荐模型推理：自动非对称数据流优化", "tldr": "深度推荐模型（DLRM）推理中嵌入层是性能瓶颈。本文提出自动非对称数据流优化方法，通过定制数据流和非对称映射，在华为昇腾AI加速器上实现1.5x至6.5x（极端情况下超20x）的加速，并降低对查询分布的依赖。", "motivation": "深度推荐模型（DLRM）推理是Meta数据中心主要的AI工作负载（占总AI工作负载的79%以上），其性能瓶颈在于嵌入层，该层需要进行大量随机内存访问以从不同大小的表中检索小型嵌入向量。", "method": "本文提出定制数据流设计以加速嵌入查找。具体方法包括：1) 四种在单个核心上有效查找嵌入表的策略；2) 一个将嵌入表非对称地自动映射到SoC多个核心的框架。该方法在华为昇腾AI加速器上进行评估，并与默认昇腾编译器及Nvidia A100进行比较。", "result": "该方法在真实工作负载分布下实现了1.5倍至6.5倍的速度提升；对于极度不平衡的分布，速度提升超过20倍。此外，该方法被证明比基线更不受查询分布的影响。", "conclusion": "本文提出的定制数据流和非对称映射框架能够显著加速深度推荐模型推理中的嵌入查找，有效解决了嵌入层性能瓶颈，并在多种工作负载下展现出优异的加速效果和对查询分布的低依赖性。", "translation": "深度推荐模型（DLRM）推理是Meta数据中心总AI工作负载的79%以上，是一种基础AI工作负载。DLRM的性能瓶颈在于嵌入层，该层执行大量随机内存访问以从各种大小的表中检索小型嵌入向量。我们提出了定制数据流的设计来加速嵌入查找。具体来说，我们提出了四种在单个核心上有效查找嵌入表的策略，以及一个将表非对称地自动映射到SoC多个核心的框架。我们使用华为昇腾AI加速器评估了我们方法的有效性，并与默认的昇腾编译器进行了比较，同时与Nvidia A100进行了高层比较。结果显示，对于真实工作负载分布，速度提升从1.5倍到6.5倍不等，对于极度不平衡的分布，速度提升超过20倍。此外，该方法被证明比基线更不受查询分布的影响。", "summary": "本文针对深度推荐模型（DLRM）推理中嵌入层存在的性能瓶颈，提出了一种自动非对称数据流优化方法。该方法包含四种单核嵌入表查找策略和一个将表非对称映射到多核SoC的框架，旨在加速嵌入查找。在华为昇腾AI加速器上的评估结果显示，该方法在真实工作负载下实现了1.5x至6.5x的加速，在极端不平衡分布下加速超过20x，并且对查询分布的依赖性更低。", "keywords": "深度推荐模型, 嵌入层, 数据流优化, 性能加速, 华为昇腾", "comments": "该论文的创新点在于提出了针对DLRM嵌入层性能瓶颈的定制数据流和非对称映射框架，有效解决了随机内存访问效率低下的问题。其重要性体现在DLRM在实际AI工作负载中的主导地位，以及其提出的优化方法在主流AI加速器上的显著性能提升，尤其是在处理不平衡数据时的优越性。这对于提升大规模推荐系统的效率具有重要意义。"}}
{"id": "2507.01279", "title": "Classification based deep learning models for lung cancer and disease using medical images", "authors": ["Ahmad Chaddad", "Jihao Peng", "Yihang Wu"], "summary": "The use of deep learning (DL) in medical image analysis has significantly\nimproved the ability to predict lung cancer. In this study, we introduce a\nnovel deep convolutional neural network (CNN) model, named ResNet+, which is\nbased on the established ResNet framework. This model is specifically designed\nto improve the prediction of lung cancer and diseases using the images. To\naddress the challenge of missing feature information that occurs during the\ndownsampling process in CNNs, we integrate the ResNet-D module, a variant\ndesigned to enhance feature extraction capabilities by modifying the\ndownsampling layers, into the traditional ResNet model. Furthermore, a\nconvolutional attention module was incorporated into the bottleneck layers to\nenhance model generalization by allowing the network to focus on relevant\nregions of the input images. We evaluated the proposed model using five public\ndatasets, comprising lung cancer (LC2500 $n$=3183, IQ-OTH/NCCD $n$=1336, and\nLCC $n$=25000 images) and lung disease (ChestXray $n$=5856, and COVIDx-CT\n$n$=425024 images). To address class imbalance, we used data augmentation\ntechniques to artificially increase the representation of underrepresented\nclasses in the training dataset. The experimental results show that ResNet+\nmodel demonstrated remarkable accuracy/F1, reaching 98.14/98.14\\% on the\nLC25000 dataset and 99.25/99.13\\% on the IQ-OTH/NCCD dataset. Furthermore, the\nResNet+ model saved computational cost compared to the original ResNet series\nin predicting lung cancer images. The proposed model outperformed the baseline\nmodels on publicly available datasets, achieving better performance metrics.\nOur codes are publicly available at\nhttps://github.com/AIPMLab/Graduation-2024/tree/main/Peng.", "comment": "Accepted in IEEE Transactions on Radiation and Plasma Medical\n  Sciences", "pdf_url": "http://arxiv.org/pdf/2507.01279v1", "categories": ["eess.IV", "cs.CV"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01279v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于分类的深度学习模型在医学图像中用于肺癌和疾病的诊断", "tldr": "本文提出了一种名为ResNet+的新型深度学习模型，用于提高医学图像中肺癌和疾病的预测准确性，并在多个公共数据集上表现出色。", "motivation": "深度学习在医学图像分析中显著提高了肺癌预测能力，但现有CNN模型在下采样过程中存在特征信息丢失的挑战，且需要提高模型泛化能力以更准确地预测肺癌和疾病。", "method": "本研究引入了一种名为ResNet+的新型深度卷积神经网络（CNN）模型，该模型基于ResNet框架。为了解决CNN下采样过程中特征信息丢失的问题，将ResNet-D模块集成到传统ResNet模型中。此外，还在瓶颈层中加入了卷积注意力模块，以增强模型泛化能力，使其关注图像中的相关区域。研究使用了数据增强技术来解决类别不平衡问题。", "result": "ResNet+模型在LC25000数据集上达到了98.14%/98.14%的准确率/F1分数，在IQ-OTH/NCCD数据集上达到了99.25%/99.13%的准确率/F1分数。与原始ResNet系列相比，ResNet+模型在预测肺癌图像时节省了计算成本，并且在公共数据集上优于基线模型。", "conclusion": "所提出的ResNet+模型在医学图像中对肺癌和疾病的预测展现出卓越的性能，并通过改进的特征提取和注意力机制有效解决了下采样信息丢失和泛化能力问题，同时降低了计算成本。", "translation": "深度学习（DL）在医学图像分析中的应用显著提高了预测肺癌的能力。在本研究中，我们引入了一种名为ResNet+的新型深度卷积神经网络（CNN）模型，该模型基于成熟的ResNet框架。该模型专门设计用于提高使用图像预测肺癌和疾病的能力。为了解决CNN下采样过程中出现的特征信息丢失的挑战，我们将ResNet-D模块（一种通过修改下采样层来增强特征提取能力的变体）集成到传统的ResNet模型中。此外，我们将一个卷积注意力模块整合到瓶颈层中，通过允许网络关注输入图像的相关区域来增强模型的泛化能力。我们使用五个公共数据集评估了所提出的模型，这些数据集包括肺癌（LC2500 $n$=3183、IQ-OTH/NCCD $n$=1336 和 LCC $n$=25000 张图像）和肺部疾病（ChestXray $n$=5856 和 COVIDx-CT $n$=425024 张图像）。为了解决类别不平衡问题，我们使用数据增强技术人工增加了训练数据集中代表性不足的类别的数量。实验结果表明，ResNet+模型在LC25000数据集上达到了98.14%/98.14%的准确率/F1分数，在IQ-OTH/NCCD数据集上达到了99.25%/99.13%的准确率/F1分数。此外，与原始ResNet系列相比，ResNet+模型在预测肺癌图像时节省了计算成本。所提出的模型在公共可用数据集上优于基线模型，取得了更好的性能指标。我们的代码可在 https://github.com/AIPMLab/Graduation-2024/tree/main/Peng 公开获取。", "summary": "本文提出了一种基于ResNet框架的深度卷积神经网络ResNet+，旨在提高医学图像中肺癌和疾病的预测准确性。该模型通过集成ResNet-D模块解决下采样过程中的特征信息丢失问题，并引入卷积注意力模块增强模型泛化能力。在五个公共数据集上进行评估，并使用数据增强处理类别不平衡问题。实验结果表明，ResNet+在多个数据集上取得了高精度和F1分数，并具有计算成本优势，性能优于基线模型。", "keywords": "深度学习, 肺癌, 医学图像, 卷积神经网络, ResNet+", "comments": "该论文提出了一种改进的深度学习模型ResNet+，通过结合ResNet-D模块和卷积注意力机制，有效地解决了医学图像分析中深度学习模型面临的特征信息丢失和泛化能力问题。其创新点在于对ResNet架构的针对性优化，以适应肺癌和疾病诊断的复杂性。在多个公共数据集上取得的高性能和计算成本节约，表明该模型在实际医疗应用中具有潜力。代码公开可用也增加了研究的可复现性和透明度。"}}
{"id": "2507.01706", "title": "A modified Levenberg-Marquardt method for estimating the elastic material parameters of polymer waveguides using residuals between autocorrelated frequency responses", "authors": ["Dominik Itner", "Dmitrij Dreiling", "Hauke Gravenkamp", "Bernd Henning", "Carolin Birk"], "summary": "In this contribution, we address the estimation of the frequency-dependent\nelastic parameters of polymers in the ultrasound range, which is formulated as\nan inverse problem. This inverse problem is implemented as a nonlinear\nregression-type optimization problem, in which the simulation signals are\nfitted to the measurement signals. These signals consist of displacement\nresponses in waveguides, focusing on hollow cylindrical geometries to enhance\nthe simulation efficiency. To accelerate the optimization and reduce the number\nof model evaluations and wait times, we propose two novel methods. First, we\nintroduce an adaptation of the Levenberg-Marquardt method derived from a\ngeometrical interpretation of the least-squares optimization problem. Second,\nwe introduce an improved objective function based on the autocorrelated\nenvelopes of the measurement and simulation signals. Given that this study\nprimarily relies on simulation data to quantify optimization convergence, we\naggregate the expected ranges of realistic material parameters and derive their\ndistributions to ensure the reproducibility of optimizations with proper\nmeasurements. We demonstrate the effectiveness of our objective function\nmodification and step adaptation for various materials with isotropic material\nsymmetry by comparing them with a state-of-the-art optimization method. In all\ncases, our method reduces the total number of model evaluations, thereby\nshortening the time to identify the material parameters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01706v1", "categories": ["cs.CE"], "cate": "cs.CE", "url": "http://arxiv.org/abs/2507.01706v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "一种改进的Levenberg-Marquardt方法，利用自相关频率响应残差估计聚合物波导的弹性材料参数", "tldr": "提出了一种改进的Levenberg-Marquardt方法，结合自相关信号包络的物函数，用于高效估计聚合物波导的弹性参数，显著减少了优化时间和模型评估次数。", "motivation": "估计超声范围内聚合物的频率依赖性弹性参数是一个逆问题，当前的优化方法可能效率不高，需要加速优化并减少模型评估次数和等待时间。", "method": "该研究将弹性参数估计公式化为非线性回归型优化问题。提出了两种新方法：1) 引入了一种基于最小二乘优化问题几何解释的Levenberg-Marquardt方法改进版本。2) 引入了一种基于测量和模拟信号自相关包络的改进目标函数。研究主要依赖模拟数据进行优化收敛性量化，并聚合了实际材料参数的预期范围及其分布，以确保优化在适当测量下的可重复性。", "result": "提出的目标函数修改和步长自适应方法在各种具有各向同性材料对称性的材料上都显示出有效性，与最先进的优化方法相比，该方法在所有情况下都减少了模型评估总数，从而缩短了识别材料参数的时间。", "conclusion": "改进的Levenberg-Marquardt方法结合自相关信号包络的物函数，能够有效且高效地估计聚合物波导的弹性材料参数，显著减少了优化时间和模型评估次数。", "translation": "在本文中，我们探讨了超声范围内聚合物频率依赖性弹性参数的估计问题，该问题被表述为一个逆问题。这个逆问题被实现为一个非线性回归型优化问题，其中模拟信号与测量信号进行拟合。这些信号由波导中的位移响应组成，重点关注空心圆柱几何形状以提高模拟效率。为了加速优化并减少模型评估次数和等待时间，我们提出了两种新颖的方法。首先，我们引入了一种基于最小二乘优化问题几何解释的Levenberg-Marquardt方法的改进版本。其次，我们引入了一种基于测量和模拟信号自相关包络的改进目标函数。鉴于本研究主要依赖模拟数据来量化优化收敛性，我们汇总了实际材料参数的预期范围并推导出其分布，以确保优化在适当测量下的可重复性。我们通过与最先进的优化方法进行比较，证明了我们的目标函数修改和步长自适应方法对于各种具有各向同性材料对称性的材料的有效性。在所有情况下，我们的方法都减少了模型评估的总数，从而缩短了识别材料参数的时间。", "summary": "本文提出了一种改进的Levenberg-Marquardt方法，用于高效估计聚合物波导的频率依赖性弹性材料参数。该方法将问题建模为非线性回归优化，并通过引入几何解释下的Levenberg-Marquardt方法改进以及基于自相关信号包络的改进目标函数来加速优化过程。实验结果表明，该方法能够显著减少模型评估次数和参数识别时间，从而提高优化效率。", "keywords": "Levenberg-Marquardt方法, 弹性参数估计, 聚合物波导, 自相关频率响应, 逆问题", "comments": "本文的创新之处在于对Levenberg-Marquardt方法进行了几何解释下的改进，并引入了基于自相关信号包络的新型目标函数，这有助于提高逆问题求解的效率和鲁棒性。通过减少模型评估次数，该方法在实际应用中具有重要的实用价值，特别是在涉及计算成本高昂的仿真模型时。"}}
{"id": "2507.01211", "title": "Teaching Cars to Drive: Spotlight on Connected and Automated Vehicles", "authors": ["Filippos N. Tzortzoglou", "Andreas A. Malikopoulos"], "summary": "In recent decades, society has witnessed significant advancements in emerging\nmobility systems. These systems refer to transportation solutions that\nincorporate digital technologies, automation, connectivity, and sustainability\nto create safer, more efficient, and user-centered mobility. Examples include\nconnected and automated vehicles (CAVs), shared mobility services\n(car-pooling), electric vehicles, and mobility-as-a-service platforms. These\ninnovations have the potential to greatly impact areas such as safety,\npollution, comfort, travel time, and fairness. In this article, we explore the\ncurrent landscape of CAVs. We discuss their role in daily life and their future\npotential, while also addressing the challenges they may introduce. Following,\nwe also examine the practical difficulties in research associated with CAVs\nespecially simulating and testing CAV-related algorithms in real-world\nsettings. We present existing solutions that aim to overcome these limitations.\nFinally, we provide an accessible introduction to modeling CAVs using basic\nkinematic principles and offer an open-source tutorial to help interested\nstudents begin exploring the field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01211v1", "categories": ["eess.SY", "cs.SY"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01211v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "教汽车驾驶：聚焦网联和自动驾驶汽车", "tldr": "本文探讨了网联和自动驾驶汽车（CAVs）的现状、潜力、挑战以及研究中的实际困难，并提供了基于运动学原理的CAV建模介绍和开源教程。", "motivation": "近年来，新兴出行系统（如网联和自动驾驶汽车）取得了显著进展，它们有望在安全、污染、舒适度、出行时间和公平性等方面产生巨大影响。本文旨在探索网联和自动驾驶汽车（CAVs）的当前图景，讨论其在日常生活中扮演的角色及其未来潜力，同时解决它们可能带来的挑战。", "method": "本文探讨了CAVs的当前状况，讨论了它们在日常生活中的作用和未来潜力，并解决了它们可能带来的挑战。此外，文章还审视了CAV相关研究中的实际困难，特别是模拟和测试CAV算法在真实世界环境中的挑战，并提出了旨在克服这些限制的现有解决方案。最后，文章提供了使用基本运动学原理对CAVs进行建模的易懂介绍，并提供了一个开源教程。", "result": "本文探讨了网联和自动驾驶汽车（CAVs）的当前图景，讨论了它们在日常生活中的作用和未来潜力，并指出了它们可能带来的挑战。文章还审视了CAV相关研究中的实际困难，并提出了现有解决方案。此外，文章提供了使用基本运动学原理对CAVs进行建模的介绍，并提供了一个开源教程以帮助学生入门。", "conclusion": "本文全面探讨了网联和自动驾驶汽车（CAVs）的现状、潜力与挑战，并针对研究中的实际困难提供了现有解决方案。同时，文章为CAVs的建模提供了入门指导和开源教程，旨在促进该领域的研究和学习。", "translation": "近年来，社会见证了新兴出行系统的显著进步。这些系统是指融合了数字技术、自动化、连接性和可持续性的交通解决方案，旨在创造更安全、更高效、以用户为中心的出行方式。例如，网联和自动驾驶汽车（CAVs）、共享出行服务（拼车）、电动汽车以及出行即服务平台。这些创新有潜力极大地影响安全性、污染、舒适度、出行时间和公平性等领域。本文中，我们探讨了CAVs的当前图景。我们讨论了它们在日常生活中的作用及其未来潜力，同时也解决了它们可能带来的挑战。接着，我们还审视了与CAVs相关的研究中的实际困难，特别是模拟和在真实世界环境中测试CAV相关算法的挑战。我们提出了旨在克服这些限制的现有解决方案。最后，我们提供了使用基本运动学原理对CAVs进行建模的易懂介绍，并提供了一个开源教程，以帮助感兴趣的学生开始探索该领域。", "summary": "本文深入探讨了新兴的网联和自动驾驶汽车（CAVs）领域。文章首先概述了CAVs的现状、在日常生活中扮演的角色及其未来潜力，并指出了其固有的挑战。接着，文章聚焦于CAV研究中遇到的实际困难，特别是仿真和真实世界测试的挑战，并提出了现有解决方案。最后，论文提供了一个基于基本运动学原理的CAVs建模入门介绍和一个开源教程，旨在帮助学生进入该领域。", "keywords": "网联和自动驾驶汽车, 新兴出行系统, 建模, 挑战, 开源教程", "comments": "本文作为一篇综述性文章，全面介绍了网联和自动驾驶汽车（CAVs）的现状、发展潜力、面临的挑战以及研究中的实际困难，并提供了实用的建模入门和开源教程。其创新之处在于结合了理论探讨与实践指导，特别是为初学者提供了友好的学习资源。重要性体现在其对CAV领域研究和教育的推动作用。"}}
{"id": "2507.01213", "title": "MEGA: xLSTM with Multihead Exponential Gated Fusion for Precise Aspect-based Sentiment Analysis", "authors": ["Adamu Lawan", "Juhua Pu", "Haruna Yunusa", "Jawad Muhammad", "Muhammad Lawan"], "summary": "Aspect-based Sentiment Analysis (ABSA) is a critical Natural Language\nProcessing (NLP) task that extracts aspects from text and determines their\nassociated sentiments, enabling fine-grained analysis of user opinions.\nExisting ABSA methods struggle to balance computational efficiency with high\nperformance: deep learning models often lack global context, transformers\ndemand significant computational resources, and Mamba-based approaches face\nCUDA dependency and diminished local correlations. Recent advancements in\nExtended Long Short-Term Memory (xLSTM) models, particularly their efficient\nmodeling of long-range dependencies, have significantly advanced the NLP\ncommunity. However, their potential in ABSA remains untapped. To this end, we\npropose xLSTM with Multihead Exponential Gated Fusion (MEGA), a novel framework\nintegrating a bi-directional mLSTM architecture with forward and partially\nflipped backward (PF-mLSTM) streams. The PF-mLSTM enhances localized context\nmodeling by processing the initial sequence segment in reverse with dedicated\nparameters, preserving critical short-range patterns. We further introduce an\nmLSTM-based multihead cross exponential gated fusion mechanism (MECGAF) that\ndynamically combines forward mLSTM outputs as query and key with PF-mLSTM\noutputs as value, optimizing short-range dependency capture while maintaining\nglobal context and efficiency. Experimental results on three benchmark datasets\ndemonstrate that MEGA outperforms state-of-the-art baselines, achieving\nsuperior accuracy and efficiency in ABSA tasks.", "comment": "6, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.01213v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01213v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "MEGA：融合多头指数门控的xLSTM用于精确的基于方面的情感分析", "tldr": "提出MEGA模型，结合xLSTM和多头指数门控融合，显著提升基于方面的情感分析的准确性和效率。", "motivation": "现有的基于方面的情感分析（ABSA）方法在计算效率和高性能之间难以平衡：深度学习模型常缺乏全局上下文，Transformer模型需要大量计算资源，而基于Mamba的方法面临CUDA依赖和局部相关性减弱的问题。尽管扩展长短期记忆（xLSTM）模型在长程依赖建模方面取得了显著进展，但其在ABSA中的潜力尚未被开发。", "method": "我们提出了一个名为MEGA（xLSTM with Multihead Exponential Gated Fusion）的新颖框架，它集成了双向mLSTM架构，包括前向流和部分翻转反向（PF-mLSTM）流。PF-mLSTM通过反向处理初始序列段并使用专用参数来增强局部上下文建模。我们进一步引入了一种基于mLSTM的多头交叉指数门控融合机制（MECGAF），该机制动态地将前向mLSTM输出作为查询和键，将PF-mLSTM输出作为值进行组合，从而优化短程依赖捕获，同时保持全局上下文和效率。", "result": "在三个基准数据集上的实验结果表明，MEGA在ABSA任务中优于现有最先进的基线模型，实现了卓越的准确性和效率。", "conclusion": "MEGA通过集成xLSTM和新颖的多头指数门控融合机制，有效解决了现有ABSA方法在效率和性能之间的挑战，在ABSA任务中取得了优异的准确性和效率。", "translation": "基于方面的情感分析（ABSA）是一项关键的自然语言处理（NLP）任务，它从文本中提取方面并确定其相关情感，从而实现用户意见的细粒度分析。现有的ABSA方法难以平衡计算效率与高性能：深度学习模型通常缺乏全局上下文，Transformer模型需要大量的计算资源，而基于Mamba的方法面临CUDA依赖性和局部相关性减弱的问题。扩展长短期记忆（xLSTM）模型的最新进展，特别是它们对长程依赖的有效建模，显著推动了NLP社区的发展。然而，它们在ABSA中的潜力仍未被开发。为此，我们提出了融合多头指数门控的xLSTM（MEGA），这是一个新颖的框架，它集成了双向mLSTM架构与前向和部分翻转反向（PF-mLSTM）流。PF-mLSTM通过反向处理初始序列段并使用专用参数来增强局部上下文建模，从而保留关键的短程模式。我们进一步引入了一种基于mLSTM的多头交叉指数门控融合机制（MECGAF），该机制动态地将前向mLSTM输出作为查询和键，将PF-mLSTM输出作为值进行组合，从而优化短程依赖捕获，同时保持全局上下文和效率。在三个基准数据集上的实验结果表明，MEGA在ABSA任务中优于现有最先进的基线模型，实现了卓越的准确性和效率。", "summary": "MEGA是一个新颖的框架，将双向mLSTM架构与前向和部分翻转反向（PF-mLSTM）流集成，并通过多头交叉指数门控融合机制（MECGAF）优化短程依赖捕获，同时保持全局上下文和效率。在三个基准数据集上的实验表明，MEGA在ABSA任务中优于现有SOTA基线，实现了更高的准确性和效率。", "keywords": "基于方面的情感分析, xLSTM, 多头指数门控融合, 自然语言处理, 深度学习", "comments": "MEGA的创新之处在于将xLSTM模型引入到基于方面的情感分析（ABSA）任务中，并设计了独特的双向mLSTM架构（包括PF-mLSTM）和多头交叉指数门控融合机制（MECGAF）。这种设计有效地解决了现有ABSA方法在效率和性能之间难以平衡的痛点，并通过结合局部和全局上下文信息，显著提升了模型在ABSA任务中的表现。其对短程依赖的优化和对长程依赖的保持，展示了其在复杂NLP任务中的潜力。"}}
{"id": "2507.01305", "title": "DiffusionLight-Turbo: Accelerated Light Probes for Free via Single-Pass Chrome Ball Inpainting", "authors": ["Worameth Chinchuthakun", "Pakkapon Phongthawee", "Amit Raj", "Varun Jampani", "Pramook Khungurn", "Supasorn Suwajanakorn"], "summary": "We introduce a simple yet effective technique for estimating lighting from a\nsingle low-dynamic-range (LDR) image by reframing the task as a chrome ball\ninpainting problem. This approach leverages a pre-trained diffusion model,\nStable Diffusion XL, to overcome the generalization failures of existing\nmethods that rely on limited HDR panorama datasets. While conceptually simple,\nthe task remains challenging because diffusion models often insert incorrect or\ninconsistent content and cannot readily generate chrome balls in HDR format.\nOur analysis reveals that the inpainting process is highly sensitive to the\ninitial noise in the diffusion process, occasionally resulting in unrealistic\noutputs. To address this, we first introduce DiffusionLight, which uses\niterative inpainting to compute a median chrome ball from multiple outputs to\nserve as a stable, low-frequency lighting prior that guides the generation of a\nhigh-quality final result. To generate high-dynamic-range (HDR) light probes,\nan Exposure LoRA is fine-tuned to create LDR images at multiple exposure\nvalues, which are then merged. While effective, DiffusionLight is\ntime-intensive, requiring approximately 30 minutes per estimation. To reduce\nthis overhead, we introduce DiffusionLight-Turbo, which reduces the runtime to\nabout 30 seconds with minimal quality loss. This 60x speedup is achieved by\ntraining a Turbo LoRA to directly predict the averaged chrome balls from the\niterative process. Inference is further streamlined into a single denoising\npass using a LoRA swapping technique. Experimental results that show our method\nproduces convincing light estimates across diverse settings and demonstrates\nsuperior generalization to in-the-wild scenarios. Our code is available at\nhttps://diffusionlight.github.io/turbo", "comment": "arXiv admin note: substantial text overlap with arXiv:2312.09168", "pdf_url": "http://arxiv.org/pdf/2507.01305v1", "categories": ["cs.CV", "cs.GR", "cs.LG", "I.3.3; I.4.8"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01305v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "DiffusionLight-Turbo：通过单次铬球修复免费加速光照探测", "tldr": "该研究提出DiffusionLight-Turbo，一种通过将光照估计重构为铬球修复问题，并利用预训练扩散模型（Stable Diffusion XL）从单张LDR图像中快速估计光照的技术。它通过引入新方法将处理时间从30分钟大幅缩短至约30秒。", "motivation": "现有光照估计方法依赖有限的HDR全景数据集，导致泛化能力差。扩散模型在生成一致内容和HDR铬球方面存在挑战。此外，最初的DiffusionLight方法耗时较长（约30分钟）。", "method": "本研究将光照估计任务重构为铬球修复问题，并利用预训练的Stable Diffusion XL模型。首先，提出DiffusionLight，通过迭代修复生成多个输出的铬球中值，作为稳定的低频光照先验。为生成HDR光照探头，微调Exposure LoRA以在不同曝光值下创建LDR图像并进行合并。为加速，引入DiffusionLight-Turbo，通过训练Turbo LoRA直接预测迭代过程中的平均铬球，并将推理简化为单次去噪过程，实现了约60倍的加速。", "result": "我们的方法在多样化设置下生成了令人信服的光照估计，并展示了优越的泛化能力，适用于野外场景。DiffusionLight-Turbo将运行时间从约30分钟缩短到约30秒，且质量损失极小。", "conclusion": "本研究提出了一种高效且显著加速的单图像光照估计方法DiffusionLight-Turbo，通过创新性地将光照估计重构为铬球修复问题并结合扩散模型，有效解决了现有方法的泛化性问题和计算效率问题。", "translation": "我们介绍了一种简单而有效的光照估计技术，通过将任务重构为铬球修复问题，从单张低动态范围（LDR）图像中估计光照。这种方法利用预训练的扩散模型Stable Diffusion XL，克服了现有方法依赖有限HDR全景数据集所导致的泛化失败问题。尽管概念简单，但该任务仍具挑战性，因为扩散模型经常插入不正确或不一致的内容，并且无法轻易生成HDR格式的铬球。我们的分析表明，修复过程对扩散过程中的初始噪声高度敏感，偶尔会导致不切实际的输出。为了解决这个问题，我们首先引入了DiffusionLight，它使用迭代修复从多个输出中计算出一个铬球中值，作为稳定的低频光照先验，指导高质量最终结果的生成。为了生成高动态范围（HDR）光照探头，我们微调了一个Exposure LoRA，以在多个曝光值下创建LDR图像，然后进行合并。虽然有效，但DiffusionLight耗时较长，每次估计大约需要30分钟。为了减少这种开销，我们引入了DiffusionLight-Turbo，它将运行时间缩短到大约30秒，且质量损失极小。这种60倍的速度提升是通过训练一个Turbo LoRA来直接预测迭代过程中的平均铬球来实现的。推理通过LoRA交换技术进一步简化为单次去噪过程。实验结果表明，我们的方法在各种设置下都能产生令人信服的光照估计，并展示了对野外场景的卓越泛化能力。我们的代码可在https://diffusionlight.github.io/turbo获取。", "summary": "本论文介绍了DiffusionLight-Turbo，一种通过将光照估计重构为铬球修复问题，利用预训练扩散模型从单张LDR图像中估计光照的加速技术。该方法首先提出DiffusionLight，通过迭代修复生成稳定的铬球光照先验，并结合Exposure LoRA生成HDR光照探头。为解决DiffusionLight耗时长的缺点，DiffusionLight-Turbo通过训练Turbo LoRA直接预测平均铬球并采用LoRA交换技术实现单次去噪，将运行时间从30分钟缩短至约30秒。实验结果表明，该方法在多样化场景中能生成令人信服的光照估计，并具有优越的泛化能力。", "keywords": "光照估计, 扩散模型, 铬球修复, LoRA, 单图像光照", "comments": "本文的创新点在于将光照估计任务巧妙地转换为铬球修复问题，并创造性地利用了预训练的扩散模型（Stable Diffusion XL）。最突出的贡献是DiffusionLight-Turbo实现了惊人的60倍加速，使得之前耗时30分钟的任务仅需30秒完成，极大地提升了方法的实用性。通过引入不同功能的LoRA（Exposure LoRA和Turbo LoRA），该工作在保持高质量输出的同时，有效解决了HDR生成和推理速度的挑战。"}}
{"id": "2507.01873", "title": "Breaking the $n^{1.5}$ Additive Error Barrier for Private and Efficient Graph Sparsification via Private Expander Decomposition", "authors": ["Anders Aamand", "Justin Y. Chen", "Mina Dalirrooyfard", "Slobodan Mitrović", "Yuriy Nevmyvaka", "Sandeep Silwal", "Yinzhan Xu"], "summary": "We study differentially private algorithms for graph cut sparsification, a\nfundamental problem in algorithms, privacy, and machine learning. While\nsignificant progress has been made, the best-known private and efficient cut\nsparsifiers on $n$-node graphs approximate each cut within\n$\\widetilde{O}(n^{1.5})$ additive error and $1+\\gamma$ multiplicative error for\nany $\\gamma > 0$ [Gupta, Roth, Ullman TCC'12]. In contrast, \"inefficient\"\nalgorithms, i.e., those requiring exponential time, can achieve an\n$\\widetilde{O}(n)$ additive error and $1+\\gamma$ multiplicative error\n[Eli{\\'a}{\\v{s}}, Kapralov, Kulkarni, Lee SODA'20]. In this work, we break the\n$n^{1.5}$ additive error barrier for private and efficient cut sparsification.\nWe present an $(\\varepsilon,\\delta)$-DP polynomial time algorithm that, given a\nnon-negative weighted graph, outputs a private synthetic graph approximating\nall cuts with multiplicative error $1+\\gamma$ and additive error $n^{1.25 +\no(1)}$ (ignoring dependencies on $\\varepsilon, \\delta, \\gamma$).\n  At the heart of our approach lies a private algorithm for expander\ndecomposition, a popular and powerful technique in (non-private) graph\nalgorithms.", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.01873v1", "categories": ["cs.DS"], "cate": "cs.DS", "url": "http://arxiv.org/abs/2507.01873v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "通过私有扩展分解打破私有高效图稀疏化中的 $n^{1.5}$ 加性误差障碍", "tldr": "该论文提出了一种私有且高效的图稀疏化算法，通过私有扩展分解将加性误差从 $n^{1.5}$ 降低到 $n^{1.25 + o(1)}$，打破了此前的障碍。", "motivation": "当前私有且高效的图割稀疏化器存在 $\\widetilde{O}(n^{1.5})$ 的加性误差，而低效算法可达到 $\\widetilde{O}(n)$。本研究的动机是降低私有高效算法的加性误差。", "method": "该论文提出了一种 $(\\varepsilon,\\delta)$-DP 多项式时间算法。其核心方法是开发了一个用于扩展分解的私有算法。", "result": "该算法在近似所有割时，实现了 $1+\\gamma$ 的乘性误差和 $n^{1.25 + o(1)}$ 的加性误差（忽略对 $\\varepsilon, \\delta, \\gamma$ 的依赖），成功打破了 $n^{1.5}$ 的加性误差障碍。", "conclusion": "该论文通过利用私有扩展分解，成功开发了一种显著降低加性误差的私有高效图稀疏化算法。", "translation": "我们研究了图割稀疏化的差分隐私算法，这是一个在算法、隐私和机器学习中都非常基础的问题。尽管已经取得了显著进展，但目前已知在 $n$ 节点图上最佳的私有高效割稀疏化器在逼近每个割时，具有 $\\widetilde{O}(n^{1.5})$ 的加性误差和 $1+\\gamma$ 的乘性误差（对于任意 $\\gamma > 0$）[Gupta, Roth, Ullman TCC'12]。相比之下，“低效”算法，即那些需要指数时间的算法，可以实现 $\\widetilde{O}(n)$ 的加性误差和 $1+\\gamma$ 的乘性误差 [Eli{\\acute{a}}{\\v{s}}, Kapralov, Kulkarni, Lee SODA'20]。在这项工作中，我们打破了私有高效割稀疏化中的 $n^{1.5}$ 加性误差障碍。我们提出了一种 $(\\varepsilon,\\delta)$-DP 多项式时间算法，该算法在给定非负加权图的情况下，输出一个私有合成图，该图以 $1+\\gamma$ 的乘性误差和 $n^{1.25 + o(1)}$ 的加性误差（忽略对 $\\varepsilon, \\delta, \\gamma$ 的依赖）近似所有割。我们方法的核心在于一个用于扩展分解的私有算法，这是一个在（非私有）图算法中流行且强大的技术。", "summary": "这篇论文解决了差分隐私图割稀疏化的问题。它引入了一种新颖的 $(\\varepsilon,\\delta)$-DP 多项式时间算法，该算法显著地将加性误差从 $\\widetilde{O}(n^{1.5})$ 改进到 $n^{1.25 + o(1)}$，同时保持 $1+\\gamma$ 的乘性误差。其关键创新在于开发了一个用于扩展分解的私有算法，这项技术此前主要用于非私有图算法。", "keywords": "图稀疏化, 差分隐私, 扩展分解, 割稀疏化, 加性误差", "comments": "这项工作具有重要意义，因为它推动了私有高效图稀疏化可实现性的边界，在加性误差方面取得了显著降低。私有扩展分解的集成是关键创新，可能为在隐私保护设置中应用先进图技术开辟新途径。"}}
{"id": "2507.01296", "title": "Stability and error analysis of a new class of higher-order consistent splitting schemes for the Navier-Stokes equations", "authors": ["Fukeng Huang", "Jie Shen"], "summary": "A new class of fully decoupled consistent splitting schemes for the\nNavier-Stokes equations are constructed and analyzed in this paper. The schemes\nare based on the Taylor expansion at $t^{n+\\beta}$ with $\\beta\\ge 1$ being a\nfree parameter. It is shown that by choosing {\\color{black} $\\beta= 3,\n\\,6,\\,9$} respectively for the second-, third- and fourth-order schemes, their\nnumerical solutions are uniformed bounded in a strong norm, and admit optimal\nglobal-in-time convergence rates in both 2D and 3D. {\\color{black}These }\nresults are the first stability and convergence results for any fully\ndecoupled, higher than second-order schemes for the Navier-Stokes equations.\nNumerical results are provided to show that the third- and fourth-order schemes\nbased on the usual BDF (i.e. $\\beta=1$) are not unconditionally stable while\nthe new third- and fourth-order schemes with suitable $\\beta$ are\nunconditionally stable and lead to expected convergence rates.", "comment": "This article was accepted for publication in Mathematics of\n  Computation on June 21, 2025", "pdf_url": "http://arxiv.org/pdf/2507.01296v1", "categories": ["math.NA", "cs.NA", "65M12, 76D05, 65M15"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01296v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "纳维-斯托克斯方程一类新型高阶一致分裂格式的稳定性和误差分析", "tldr": "本文构建并分析了一类新的纳维-斯托克斯方程全解耦高阶分裂格式，首次证明了其稳定性并获得了最优收敛率，且新格式无条件稳定。", "motivation": "旨在构建并分析一类新型的纳维-斯托克斯方程全解耦一致分裂格式，以解决现有高阶解耦格式的稳定性和收敛性问题。", "method": "本文构建了基于$t^{n+\\beta}$处泰勒展开的新型全解耦一致分裂格式，其中$\\beta\\ge 1$是自由参数。通过选择特定的$\\beta$值（二阶、三阶、四阶格式分别选择$\\beta=3, 6, 9$），证明了格式的稳定性。", "result": "1. 新格式的数值解在强范数下一致有界，并且在二维和三维情况下都具有最优的全局时间收敛率。\n2. 这些是纳维-斯托克斯方程任意全解耦、高于二阶格式的首次稳定性和收敛性结果。\n3. 数值结果表明，基于BDF（$\\beta=1$）的第三和第四阶格式并非无条件稳定，而带有合适$\\beta$值的新型第三和第四阶格式是无条件稳定的，并达到了预期的收敛率。", "conclusion": "本文成功构建了一类新型高阶全解耦纳维-斯托克斯方程分裂格式，并首次从理论上证明了其稳定性和最优收敛性，同时数值验证了其优于传统BDF格式的无条件稳定性。", "translation": "本文构建并分析了一类新型的纳维-斯托克斯方程全解耦一致分裂格式。这些格式基于在$t^{n+\\beta}$处的泰勒展开，其中$\\beta\\ge 1$是一个自由参数。结果表明，通过分别选择$\\beta=3, 6, 9$用于二阶、三阶和四阶格式，它们的数值解在强范数下一致有界，并且在二维和三维情况下都具有最优的全局时间收敛率。这些结果是纳维-斯托克斯方程任意全解耦、高于二阶格式的首次稳定性和收敛性结果。数值结果表明，基于通常BDF（即$\\beta=1$）的第三和第四阶格式并非无条件稳定，而带有合适$\\beta$值的新型第三和第四阶格式是无条件稳定的，并达到了预期的收敛率。", "summary": "本文提出并分析了一类针对纳维-斯托克斯方程的新型高阶全解耦一致分裂格式。该格式利用在$t^{n+\\beta}$处的泰勒展开，并通过选择特定的参数$\\beta$（如二阶、三阶和四阶格式分别对应$\\beta=3, 6, 9$），首次证明了其数值解在强范数下的一致有界性和最优全局时间收敛率。数值实验进一步证实，与传统的BDF方法相比，新格式实现了无条件稳定性和预期的收敛表现。", "keywords": "纳维-斯托克斯方程, 分裂格式, 稳定性分析, 误差分析, 高阶格式", "comments": "本文的创新之处在于首次为纳维-斯托克斯方程的全解耦、高于二阶的分裂格式提供了严格的稳定性和收敛性理论分析。通过引入自由参数$\\beta$并确定其特定值，解决了高阶解耦格式的无条件稳定性问题，这对于计算流体力学领域的高效和精确模拟具有重要意义。"}}
{"id": "2507.01172", "title": "Classical Guitar Duet Separation using GuitarDuets -- a Dataset of Real and Synthesized Guitar Recordings", "authors": ["Marios Glytsos", "Christos Garoufis", "Athanasia Zlatintsi", "Petros Maragos"], "summary": "Recent advancements in music source separation (MSS) have focused in the\nmulti-timbral case, with existing architectures tailored for the separation of\ndistinct instruments, overlooking thus the challenge of separating instruments\nwith similar timbral characteristics. Addressing this gap, our work focuses on\nmonotimbral MSS, specifically within the context of classical guitar duets. To\nthis end, we introduce the GuitarDuets dataset, featuring a combined total of\napproximately three hours of real and synthesized classical guitar duet\nrecordings, as well as note-level annotations of the synthesized duets. We\nperform an extensive cross-dataset evaluation by adapting Demucs, a\nstate-of-the-art MSS architecture, to monotimbral source separation.\nFurthermore, we develop a joint permutation-invariant transcription and\nseparation framework, to exploit note event predictions as auxiliary\ninformation. Our results indicate that utilizing both the real and synthesized\nsubsets of GuitarDuets leads to improved separation performance in an\nindependently recorded test set compared to utilizing solely one subset. We\nalso find that while the availability of ground-truth note labels greatly helps\nthe performance of the separation network, the predicted note estimates result\nonly in marginal improvement. Finally, we discuss the behavior of commonly\nutilized metrics, such as SDR and SI-SDR, in the context of monotimbral MSS.", "comment": "In Proceedings of the 25th International Society for Music\n  Information Retrieval Conference (ISMIR 2024), San Francisco, USA, November\n  2024. The dataset is available at: https://zenodo.org/records/12802440", "pdf_url": "http://arxiv.org/pdf/2507.01172v1", "categories": ["eess.AS"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01172v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "使用 GuitarDuets 进行古典吉他二重奏分离——一个真实和合成吉他录音数据集", "tldr": "本文提出了 GuitarDuets 数据集，用于解决单音色音乐源分离（特别是古典吉他二重奏分离）的挑战，并开发了一个联合框架，结果表明结合真实和合成数据能显著提高分离性能，而音符预测的辅助信息效果有限。", "motivation": "现有的音乐源分离（MSS）架构主要针对不同音色的乐器分离，忽视了音色相似乐器（如古典吉他二重奏）的分离挑战。本研究旨在解决这一单音色MSS的空白。", "method": "研究引入了 GuitarDuets 数据集，包含约三小时的真实和合成古典吉他二重奏录音及音符级标注。通过调整现有先进的MSS架构Demucs进行单音色源分离，并开发了一个联合置换不变转录和分离框架，利用音符事件预测作为辅助信息。", "result": "利用 GuitarDuets 数据集的真实和合成子集相结合，相比仅使用单一子集，在独立录制的测试集上能显著提高分离性能。研究还发现，虽然真实音符标签极大地帮助了分离网络的性能，但预测的音符估计仅带来微小改进。", "conclusion": "本研究成功地为单音色音乐源分离（特别是古典吉他二重奏）提供了有效的解决方案和数据集。结果表明结合真实与合成数据的重要性，并揭示了音符辅助信息在不同准确度下的影响。同时，讨论了SDR和SI-SDR等常用指标在单音色MSS中的行为。", "translation": "音乐源分离（MSS）的最新进展主要集中在多音色案例，现有架构专为分离不同乐器而设计，从而忽略了分离音色相似乐器的挑战。为弥补这一空白，我们的工作专注于单音色MSS，特别是古典吉他二重奏的背景下。为此，我们引入了 GuitarDuets 数据集，其中包含约三小时的真实和合成古典吉他二重奏录音，以及合成二重奏的音符级标注。我们通过调整最先进的MSS架构Demucs以适应单音色源分离，进行了广泛的跨数据集评估。此外，我们开发了一个联合置换不变转录和分离框架，以利用音符事件预测作为辅助信息。我们的结果表明，与仅使用一个子集相比，同时利用 GuitarDuets 的真实和合成子集可以提高独立录制测试集中的分离性能。我们还发现，虽然地面真实音符标签的可用性极大地帮助了分离网络的性能，但预测的音符估计仅带来微小改进。最后，我们讨论了SDR和SI-SDR等常用指标在单音色MSS中的行为。", "summary": "本文针对现有音乐源分离（MSS）在处理音色相似乐器方面的不足，专注于古典吉他二重奏的单音色MSS。为此，研究创建了包含真实和合成录音的 GuitarDuets 数据集，并在此基础上，通过调整Demucs模型和开发联合转录分离框架进行实验。结果显示，结合真实与合成数据能显著提升分离效果，而预测音符信息对性能提升有限。论文还探讨了常用评估指标在单音色MSS中的表现。", "keywords": "古典吉他, 音乐源分离, 数据集, 单音色, Demucs", "comments": "本文创新性地提出了用于单音色音乐源分离的 GuitarDuets 数据集，特别针对古典吉他二重奏这一高难度任务。其重要性在于填补了现有MSS研究的空白，并验证了结合真实与合成数据对提升分离性能的有效性。该研究为未来处理相似音色乐器分离问题提供了宝贵的数据集和方法论。"}}
{"id": "2507.01058", "title": "A Data Science Approach to Calcutta High Court Judgments: An Efficient LLM and RAG-powered Framework for Summarization and Similar Cases Retrieval", "authors": ["Puspendu Banerjee", "Aritra Mazumdar", "Wazib Ansar", "Saptarsi Goswami", "Amlan Chakrabarti"], "summary": "The judiciary, as one of democracy's three pillars, is dealing with a rising\namount of legal issues, needing careful use of judicial resources. This\nresearch presents a complex framework that leverages Data Science\nmethodologies, notably Large Language Models (LLM) and Retrieval-Augmented\nGeneration (RAG) techniques, to improve the efficiency of analyzing Calcutta\nHigh Court verdicts. Our framework focuses on two key aspects: first, the\ncreation of a robust summarization mechanism that distills complex legal texts\ninto concise and coherent summaries; and second, the development of an\nintelligent system for retrieving similar cases, which will assist legal\nprofessionals in research and decision making. By fine-tuning the Pegasus model\nusing case head note summaries, we achieve significant improvements in the\nsummarization of legal cases. Our two-step summarizing technique preserves\ncrucial legal contexts, allowing for the production of a comprehensive vector\ndatabase for RAG. The RAG-powered framework efficiently retrieves similar cases\nin response to user queries, offering thorough overviews and summaries. This\ntechnique not only improves legal research efficiency, but it also helps legal\nprofessionals and students easily acquire and grasp key legal information,\nbenefiting the overall legal scenario.", "comment": "12 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.01058v1", "categories": ["cs.IR", "cs.AI", "cs.LG"], "cate": "cs.IR", "url": "http://arxiv.org/abs/2507.01058v1", "date": "2025-06-28", "updated": "2025-06-28", "AI": {"title_translation": "加尔各答高等法院判决的数据科学方法：一种高效的LLM和RAG驱动的摘要和相似案件检索框架", "tldr": "该研究提出了一种利用LLM和RAG的数据科学框架，以提高加尔各答高等法院判决的分析效率，主要包括摘要和相似案件检索功能。", "motivation": "司法机构面临日益增多的法律问题，需要高效利用司法资源。本研究旨在通过提高加尔各答高等法院判决的分析效率来解决这一问题。", "method": "该框架利用数据科学方法，特别是大型语言模型（LLM）和检索增强生成（RAG）技术。它包括一个摘要机制和一个相似案件检索系统。通过使用案件标题摘要微调Pegasus模型来改进摘要功能，并采用两步摘要技术保留关键法律上下文，以构建全面的向量数据库用于RAG。RAG驱动的框架用于高效检索相似案件。", "result": "通过微调Pegasus模型，显著改进了法律案件的摘要功能。两步摘要技术保留了关键法律上下文，并为RAG生成了全面的向量数据库。RAG驱动的框架能够高效检索相似案件，并提供全面的概述和摘要。", "conclusion": "该技术不仅提高了法律研究效率，还有助于法律专业人士和学生轻松获取和理解关键法律信息，从而有益于整体法律情景。", "translation": "司法机构作为民主的三大支柱之一，正在处理日益增多的法律问题，需要谨慎利用司法资源。本研究提出了一个复杂的框架，该框架利用数据科学方法，特别是大型语言模型（LLM）和检索增强生成（RAG）技术，以提高分析加尔各答高等法院判决的效率。我们的框架侧重于两个关键方面：首先，创建一个强大的摘要机制，将复杂的法律文本提炼成简洁连贯的摘要；其次，开发一个智能系统用于检索相似案件，这将协助法律专业人士进行研究和决策。通过使用案件标题摘要微调Pegasus模型，我们在法律案件摘要方面取得了显著改进。我们的两步摘要技术保留了关键的法律上下文，从而为RAG生成了一个全面的向量数据库。RAG驱动的框架能够高效地响应用户查询检索相似案件，提供全面的概述和摘要。这项技术不仅提高了法律研究效率，还有助于法律专业人士和学生轻松获取和理解关键法律信息，从而有益于整体法律情景。", "summary": "本研究提出了一个结合数据科学方法、大型语言模型（LLM）和检索增强生成（RAG）技术的框架，旨在提高加尔各答高等法院判决的分析效率。该框架专注于法律文本摘要和相似案件检索。通过微调Pegasus模型和采用两步摘要技术，显著提升了法律案件摘要的质量，并构建了支持RAG的向量数据库，从而实现了高效的相似案件检索。该方法有望提升法律研究效率，并帮助法律专业人士和学生更便捷地获取和理解法律信息。", "keywords": "数据科学, 大型语言模型 (LLM), 检索增强生成 (RAG), 法律摘要, 相似案件检索", "comments": "这篇论文提出了一个结合LLM和RAG的创新框架，用于解决法律领域中信息过载和检索效率低下的问题。其亮点在于针对法律文本的特点，通过微调模型和两步摘要技术来保留关键法律上下文，这对于法律摘要的准确性和实用性至关重要。RAG的应用也有效提升了相似案件检索的效率和准确性。该框架对于提高司法资源利用率和辅助法律专业人士具有重要意义。"}}
{"id": "2507.01668", "title": "Comparing Optimization Algorithms Through the Lens of Search Behavior Analysis", "authors": ["Gjorgjina Cenikj", "Gašper Petelin", "Tome Eftimov"], "summary": "The field of numerical optimization has recently seen a surge in the\ndevelopment of \"novel\" metaheuristic algorithms, inspired by metaphors derived\nfrom natural or human-made processes, which have been widely criticized for\nobscuring meaningful innovations and failing to distinguish themselves from\nexisting approaches. Aiming to address these concerns, we investigate the\napplicability of statistical tests for comparing algorithms based on their\nsearch behavior. We utilize the cross-match statistical test to compare\nmultivariate distributions and assess the solutions produced by 114 algorithms\nfrom the MEALPY library. These findings are incorporated into an empirical\nanalysis aiming to identify algorithms with similar search behaviors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01668v1", "categories": ["cs.NE", "cs.AI"], "cate": "cs.NE", "url": "http://arxiv.org/abs/2507.01668v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "通过搜索行为分析视角比较优化算法", "tldr": "本文研究了使用统计测试（特别是交叉匹配测试）基于搜索行为比较优化算法的方法，以应对新型元启发式算法因缺乏区分度而受到的批评，并旨在识别具有相似搜索行为的算法。", "motivation": "数值优化领域中大量“新颖”的元启发式算法因掩盖有意义的创新且未能与现有方法区分开来而受到广泛批评，本文旨在解决这些问题。", "method": "研究了基于搜索行为的算法比较中统计测试的适用性。具体使用了交叉匹配统计测试来比较多元分布，并评估了来自MEALPY库的114种算法产生的解决方案。", "result": "发现被纳入一项实证分析中，旨在识别具有相似搜索行为的算法。", "conclusion": "统计测试可以有效地用于基于搜索行为比较优化算法，有助于区分和识别行为相似的算法，从而解决新型元启发式算法缺乏区分度的问题。", "translation": "数值优化领域最近出现了大量“新颖”的元启发式算法，这些算法灵感来源于自然或人造过程中的隐喻。然而，这些算法因掩盖有意义的创新并未能与现有方法区分开来而受到广泛批评。为了解决这些问题，我们研究了基于搜索行为的算法比较中统计测试的适用性。我们利用交叉匹配统计测试来比较多元分布并评估来自MEALPY库的114种算法产生的解决方案。这些发现被纳入一项旨在识别具有相似搜索行为算法的实证分析中。", "summary": "本文针对数值优化领域中“新颖”元启发式算法因缺乏区分度和创新性而受到的批评，提出通过统计测试来比较算法的搜索行为。研究利用交叉匹配统计测试评估了MEALPY库中114种算法产生的解决方案，旨在识别具有相似搜索行为的算法，从而为算法的有效区分和评估提供新视角。", "keywords": "优化算法, 搜索行为, 统计测试, 元启发式算法, 交叉匹配测试", "comments": "该论文通过引入统计测试来分析优化算法的搜索行为，提供了一种量化和区分“新颖”元启发式算法的有效方法。这对于解决当前优化领域中算法同质化和缺乏真正创新的问题具有重要意义。特别是利用交叉匹配测试来比较多元分布，为算法的深层行为分析提供了工具，有助于揭示算法间的内在联系和差异。"}}
{"id": "2507.01805", "title": "A Dataset for Automatic Assessment of TTS Quality in Spanish", "authors": ["Alejandro Sosa Welford", "Leonardo Pepino"], "summary": "This work addresses the development of a database for the automatic\nassessment of text-to-speech (TTS) systems in Spanish, aiming to improve the\naccuracy of naturalness prediction models. The dataset consists of 4,326 audio\nsamples from 52 different TTS systems and human voices and is, up to our\nknowledge, the first of its kind in Spanish. To label the audios, a subjective\ntest was designed based on the ITU-T Rec. P.807 standard and completed by 92\nparticipants. Furthermore, the utility of the collected dataset was validated\nby training automatic naturalness prediction systems. We explored two\napproaches: fine-tuning an existing model originally trained for English, and\ntraining small downstream networks on top of frozen self-supervised speech\nmodels. Our models achieve a mean absolute error of 0.8 on a five-point MOS\nscale. Further analysis demonstrates the quality and diversity of the developed\ndataset, and its potential to advance TTS research in Spanish.", "comment": "5 pages, 2 figures. Accepted at Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.01805v1", "categories": ["cs.SD", "eess.AS"], "cate": "cs.SD", "url": "http://arxiv.org/abs/2507.01805v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "用于西班牙语TTS质量自动评估的数据集", "tldr": "该论文介绍了首个用于西班牙语文本到语音（TTS）系统自动评估的数据集，包含4326个音频样本，并通过主观测试和自然度预测模型验证了其有效性。", "motivation": "为了提高西班牙语文本到语音（TTS）系统自然度预测模型的准确性，并填补西班牙语领域缺乏此类数据集的空白。", "method": "开发了一个包含4326个音频样本（来自52个不同TTS系统和人声）的数据集。基于ITU-T Rec. P.807标准设计了主观测试，并由92名参与者完成标注。通过微调现有英语模型和在冻结的自监督语音模型之上训练小型下游网络，训练了自动自然度预测系统来验证数据集的效用。", "result": "所开发的数据集包含4326个音频样本，来自52个不同的TTS系统和人声。训练的自然度预测模型在五点MOS量表上实现了0.8的平均绝对误差。进一步分析表明该数据集具有良好的质量和多样性。", "conclusion": "该研究成功开发了西班牙语中首个用于TTS质量自动评估的数据集，并验证了其在提高自然度预测模型准确性方面的潜力，有望推动西班牙语TTS研究的进展。", "translation": "这项工作致力于开发一个用于自动评估西班牙语文本到语音（TTS）系统性能的数据库，旨在提高自然度预测模型的准确性。该数据集包含来自52个不同TTS系统和人声的4,326个音频样本，据我们所知，这是西班牙语领域的首个此类数据集。为了对音频进行标注，我们设计了一个基于ITU-T Rec. P.807标准的主观测试，并由92名参与者完成。此外，通过训练自动自然度预测系统，验证了所收集数据集的实用性。我们探索了两种方法：微调一个最初为英语训练的现有模型，以及在冻结的自监督语音模型之上训练小型下游网络。我们的模型在五点MOS量表上实现了0.8的平均绝对误差。进一步分析表明，所开发的数据集具有良好的质量和多样性，并有潜力推动西班牙语TTS研究的进展。", "summary": "本研究首次为西班牙语TTS系统自动质量评估创建了一个专用数据集。该数据集包含4326个音频样本，涵盖多种TTS系统和人声，并通过92名参与者进行主观标注。通过在此数据集上训练自然度预测模型，验证了其有效性，模型在MOS量表上达到了0.8的平均绝对误差，展示了该数据集在推进西班牙语TTS研究方面的价值。", "keywords": "TTS质量评估, 西班牙语, 数据集, 自然度预测, 语音合成", "comments": "这项工作的创新之处在于首次为西班牙语TTS质量的自动评估构建了专门的数据集，填补了该领域的空白。其重要性在于为西班牙语TTS研究提供了一个宝贵的资源，有助于开发更准确的自然度预测模型，从而推动西班牙语TTS技术的发展。数据集的规模和多样性，以及通过主观测试和模型训练进行的验证，都增强了其可用性和影响力。"}}
{"id": "2507.01243", "title": "Jump-Start Reinforcement Learning with Self-Evolving Priors for Extreme Monopedal Locomotion", "authors": ["Ziang Zheng", "Guojian Zhan", "Shiqi Liu", "Yao Lyu", "Tao Zhang", "Shengbo Eben Li"], "summary": "Reinforcement learning (RL) has shown great potential in enabling quadruped\nrobots to perform agile locomotion. However, directly training policies to\nsimultaneously handle dual extreme challenges, i.e., extreme underactuation and\nextreme terrains, as in monopedal hopping tasks, remains highly challenging due\nto unstable early-stage interactions and unreliable reward feedback. To address\nthis, we propose JumpER (jump-start reinforcement learning via self-evolving\npriors), an RL training framework that structures policy learning into multiple\nstages of increasing complexity. By dynamically generating self-evolving priors\nthrough iterative bootstrapping of previously learned policies, JumpER\nprogressively refines and enhances guidance, thereby stabilizing exploration\nand policy optimization without relying on external expert priors or\nhandcrafted reward shaping. Specifically, when integrated with a structured\nthree-stage curriculum that incrementally evolves action modality, observation\nspace, and task objective, JumpER enables quadruped robots to achieve robust\nmonopedal hopping on unpredictable terrains for the first time. Remarkably, the\nresulting policy effectively handles challenging scenarios that traditional\nmethods struggle to conquer, including wide gaps up to 60 cm, irregularly\nspaced stairs, and stepping stones with distances varying from 15 cm to 35 cm.\nJumpER thus provides a principled and scalable approach for addressing\nlocomotion tasks under the dual challenges of extreme underactuation and\nextreme terrains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01243v1", "categories": ["cs.RO", "cs.LG"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01243v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "借助自演化先验的跳跃式强化学习实现极限单足运动", "tldr": "提出JumpER框架，通过自演化先验和多阶段课程学习，使四足机器人首次在极端欠驱动和复杂地形下实现鲁棒的单足跳跃运动。", "motivation": "强化学习在四足机器人敏捷运动方面潜力巨大，但直接训练策略以同时应对极端欠驱动和极端地形（如单足跳跃）极具挑战性，因为早期交互不稳定且奖励反馈不可靠。", "method": "提出JumpER（jump-start reinforcement learning via self-evolving priors）强化学习训练框架，将策略学习分为多个复杂度递增的阶段。通过迭代自举先前学习的策略，动态生成自演化先验，逐步优化和增强指导，从而稳定探索和策略优化，不依赖外部专家先验或手工设计奖励。具体结合三阶段课程，逐步演化动作模态、观察空间和任务目标。", "result": "首次使四足机器人能够在不可预测地形上实现鲁棒的单足跳跃。该策略有效应对传统方法难以克服的挑战性场景，包括高达60厘米的宽间隙、不规则间隔的楼梯以及距离在15厘米到35厘米之间的踏脚石。", "conclusion": "JumpER为解决极端欠驱动和极端地形双重挑战下的运动任务提供了一种原则性且可扩展的方法。", "translation": "强化学习（RL）在使四足机器人实现敏捷运动方面展现出巨大潜力。然而，直接训练策略以同时应对双重极端挑战——即极端欠驱动和极端地形，如单足跳跃任务中，仍然极具挑战性，原因在于早期交互不稳定和奖励反馈不可靠。为解决此问题，我们提出了JumpER（通过自演化先验的跳跃式强化学习），这是一个将策略学习结构化为多个复杂度递增阶段的RL训练框架。通过迭代自举先前学习的策略，动态生成自演化先验，JumpER逐步完善和增强指导，从而稳定探索和策略优化，而无需依赖外部专家先验或手工设计的奖励整形。具体而言，当与一个结构化的三阶段课程相结合时，该课程逐步演化动作模态、观察空间和任务目标，JumpER首次使四足机器人在不可预测的地形上实现了鲁棒的单足跳跃。值得注意的是，由此产生的策略有效地处理了传统方法难以克服的挑战性场景，包括高达60厘米的宽间隙、不规则间隔的楼梯以及距离在15厘米到35厘米之间的踏脚石。因此，JumpER为解决极端欠驱动和极端地形双重挑战下的运动任务提供了一种原则性且可扩展的方法。", "summary": "本文提出JumpER框架，旨在解决强化学习在极端欠驱动和复杂地形下单足跳跃任务中的挑战。JumpER通过多阶段学习和迭代自举生成自演化先验，稳定策略探索和优化。结合三阶段课程，该方法首次使四足机器人在不可预测地形上实现鲁棒的单足跳跃，并成功应对宽间隙、不规则楼梯等复杂障碍，提供了一种原则性且可扩展的解决方案。", "keywords": "强化学习, 单足运动, 自演化先验, 欠驱动, 机器人步态", "comments": "该论文提出了一种创新的强化学习框架JumpER，通过引入“自演化先验”的概念，有效解决了在极端欠驱动和极端地形下机器人运动学习的稳定性问题。其主要创新点在于避免了对外部专家先验或复杂奖励设计的依赖，而是通过迭代自举和多阶段课程学习来逐步引导策略。这使得机器人能够自主学习复杂且不稳定的单足跳跃任务，并在多种极端地形上展现出卓越的鲁棒性，为未来高难度机器人运动控制提供了有前景的通用方法。"}}
{"id": "2507.01431", "title": "Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading", "authors": ["Yoonseok Yang", "Minjune Kim", "Marlon Rondinelli", "Keren Shao"], "summary": "Grading handwritten, open-ended responses remains a major bottleneck in large\nuniversity STEM courses. We introduce Pensieve (https://www.pensieve.co), an\nAI-assisted grading platform that leverages large language models (LLMs) to\ntranscribe and evaluate student work, providing instructors with rubric-aligned\nscores, transcriptions, and confidence ratings. Unlike prior tools that focus\nnarrowly on specific tasks like transcription or rubric generation, Pensieve\nsupports the entire grading pipeline-from scanned student submissions to final\nfeedback-within a human-in-the-loop interface.\n  Pensieve has been deployed in real-world courses at over 20 institutions and\nhas graded more than 300,000 student responses. We present system details and\nempirical results across four core STEM disciplines: Computer Science,\nMathematics, Physics, and Chemistry. Our findings show that Pensieve reduces\ngrading time by an average of 65%, while maintaining a 95.4% agreement rate\nwith instructor-assigned grades for high-confidence predictions.", "comment": "7 pages, 5 figues, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.01431v1", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG"], "cate": "cs.AI", "url": "http://arxiv.org/abs/2507.01431v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "Pensieve Grader：一个AI驱动的、即插即用的手写STEM批改平台", "tldr": "Pensieve是一个AI辅助的批改平台，利用LLM转录和评估学生手写答案，显著减少了STEM课程的批改时间，并保持高准确率。", "motivation": "在大型大学STEM课程中，批改手写、开放式答案仍然是一个主要的瓶颈。", "method": "Pensieve是一个AI辅助的批改平台，它利用大型语言模型（LLMs）来转录和评估学生作业。它支持从扫描学生提交到最终反馈的整个批改流程，并采用人机协作界面。该平台已在20多所机构的实际课程中部署。", "result": "Pensieve在计算机科学、数学、物理和化学四个核心STEM学科中，平均减少了65%的批改时间，对于高置信度预测，与教师评分的一致性达到95.4%。该平台已批改超过30万份学生答案。", "conclusion": "Pensieve Grader成功地解决了手写STEM作业批改的效率和准确性问题，通过AI辅助和人机协作显著提升了大规模教育的批改流程。", "translation": "批改手写、开放式答案仍然是大型大学STEM课程中的一个主要瓶颈。我们推出了Pensieve（https://www.pensieve.co），一个AI辅助的批改平台，它利用大型语言模型（LLMs）来转录和评估学生作业，为教师提供与评分标准一致的分数、转录文本和置信度评级。与之前那些只专注于转录或评分标准生成等特定工具不同，Pensieve在一个人机协作界面中支持整个批改流程——从扫描学生提交到最终反馈。\nPensieve已在20多所机构的实际课程中部署，并批改了超过30万份学生答案。我们展示了在计算机科学、数学、物理和化学四个核心STEM核心学科中的系统细节和实证结果。我们的研究结果表明，Pensieve平均减少了65%的批改时间，同时对于高置信度预测，与教师评分的一致性达到了95.4%。", "summary": "Pensieve Grader是一个AI驱动的平台，旨在解决大学STEM课程中手写开放式答案批改的效率问题。该平台利用大型语言模型（LLMs）进行作业转录和评估，并提供与评分标准一致的分数、转录和置信度评级。与现有工具不同，Pensieve支持完整的批改流程并采用人机协作。它已在20多所机构部署，批改了超过30万份答案，实验结果显示，该平台能将批改时间平均减少65%，并在高置信度预测下保持95.4%的评分一致性。", "keywords": "AI辅助批改, STEM教育, 大型语言模型, 手写识别, 效率提升", "comments": "Pensieve Grader的创新之处在于其对LLMs的整合，以解决手写STEM作业批改这一长期存在的痛点。它提供了一个端到端的人机协作平台，超越了以往仅关注单一功能的工具。其在实际部署中的显著效率提升和高准确率表明了其在教育技术领域的巨大潜力。该平台的重要性在于其能够大规模地减轻教师的批改负担，同时保持评分质量。"}}
{"id": "2507.01628", "title": "DaiFu: In-Situ Crash Recovery for Deep Learning Systems", "authors": ["Zilong He", "Pengfei Chen", "Hongyu Zhang", "Xiaoyun Li", "Guangba Yu", "Hongyang Chen", "Zibin Zheng"], "summary": "Deep learning (DL) systems have been widely adopted in many areas, and are\nbecoming even more popular with the emergence of large language models.\nHowever, due to the complex software stacks involved in their development and\nexecution, crashes are unavoidable and common. Crashes severely waste computing\nresources and hinder development productivity, so efficient crash recovery is\ncrucial. Existing solutions, such as checkpoint-retry, are too heavyweight for\nfast recovery from crashes caused by minor programming errors or transient\nruntime errors. Therefore, we present DaiFu, an in-situ recovery framework for\nDL systems. Through a lightweight code transformation to a given DL system,\nDaiFu augments it to intercept crashes in situ and enables dynamic and instant\nupdates to its program running context (e.g., code, configurations, and other\ndata) for agile crash recovery. Our evaluation shows that DaiFu helps reduce\nthe restore time for crash recovery, achieving a 1372x speedup compared with\nstate-of-the-art solutions. Meanwhile, the overhead of DaiFu is negligible\n(under 0.40%). We also construct a benchmark spanning 7 distinct crash\nscenarios in DL systems, and show the effectiveness of DaiFu in diverse\nsituations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01628v1", "categories": ["cs.SE"], "cate": "cs.SE", "url": "http://arxiv.org/abs/2507.01628v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "DaiFu: 深度学习系统的原地崩溃恢复", "tldr": "DaiFu是一个用于深度学习系统的原地崩溃恢复框架，通过轻量级代码转换实现快速即时恢复，相比现有方案速度提升1372倍，开销可忽略。", "motivation": "深度学习系统因其复杂性，崩溃不可避免且常见，导致计算资源浪费和开发效率低下。现有解决方案（如检查点-重试）对于轻微编程错误或瞬时运行时错误导致的崩溃过于繁重，恢复速度慢。因此需要更高效的崩溃恢复方法。", "method": "提出DaiFu，一个深度学习系统的原地恢复框架。通过对给定DL系统进行轻量级代码转换，DaiFu使其能够在原地拦截崩溃，并动态即时更新程序运行上下文（如代码、配置和其他数据），以实现敏捷的崩溃恢复。", "result": "DaiFu将崩溃恢复的恢复时间减少了1372倍，相比现有最先进解决方案速度显著提升。同时，DaiFu的开销可忽略不计（低于0.40%）。作者还构建了一个包含7种不同崩溃场景的基准测试，并展示了DaiFu在各种情况下的有效性。", "conclusion": "DaiFu是一种高效且低开销的深度学习系统原地崩溃恢复框架，显著提高了恢复速度并减少了资源浪费。", "translation": "深度学习（DL）系统已广泛应用于许多领域，并随着大型语言模型的出现变得越来越受欢迎。然而，由于其开发和执行涉及复杂的软件堆栈，崩溃是不可避免且常见的。崩溃严重浪费计算资源并阻碍开发生产力，因此高效的崩溃恢复至关重要。现有的解决方案，例如检查点-重试，对于由轻微编程错误或瞬时运行时错误引起的崩溃进行快速恢复而言过于笨重。因此，我们提出了DaiFu，一个用于DL系统的原地恢复框架。通过对给定DL系统进行轻量级代码转换，DaiFu增强其功能，使其能够原地拦截崩溃，并动态即时更新其程序运行上下文（例如代码、配置和其他数据），从而实现敏捷的崩溃恢复。我们的评估表明，DaiFu有助于减少崩溃恢复的恢复时间，与最先进的解决方案相比，速度提升了1372倍。同时，DaiFu的开销可以忽略不计（低于0.40%）。我们还构建了一个涵盖DL系统中7种不同崩溃场景的基准测试，并展示了DaiFu在不同情况下的有效性。", "summary": "本文提出了DaiFu，一个针对深度学习系统的原地崩溃恢复框架，旨在解决现有方法在处理轻微错误时恢复效率低下的问题。DaiFu通过轻量级代码转换，使系统能够原地拦截崩溃并动态更新运行上下文，从而实现快速敏捷的恢复。实验结果表明，DaiFu将恢复时间缩短了1372倍，且开销低于0.40%，并在多种崩溃场景下表现出有效性。", "keywords": "深度学习系统, 崩溃恢复, 原地恢复, 代码转换, 运行时错误", "comments": "DaiFu的创新点在于其“原地”恢复机制，通过轻量级代码转换和动态上下文更新，避免了传统检查点-重试方法的笨重性，极大提升了深度学习系统崩溃恢复的效率。其高达1372倍的速度提升和可忽略的开销，使其在实际应用中具有重要价值，尤其是在需要快速迭代和高可用性的深度学习开发和部署环境中。"}}
{"id": "2507.01465", "title": "A new efficient RPKI Design", "authors": ["Haya Schulmann", "Niklas Vogel"], "summary": "Resource Public Key Infrastructure (RPKI) is a critical security mechanism\nfor BGP, but the complexity of its architecture is a growing concern as its\nadoption scales. Current RPKI design heavily reuses legacy PKI components, such\nas X.509 EE-certificates, ASN.1 encoding, and XML-based repository protocols,\nall these introduce excessive cryptographic validation, redundant metadata, and\ninefficiencies in both storage and processing. We show that these design\nchoices, although based on established standards, create significant\nperformance bottlenecks, increase the vulnerability surface, and hinder\nscalability for wide-scale Internet deployment.\n  In this paper, we perform the first systematic analysis of the root causes of\ncomplexity in RPKI's design and experimentally quantify their real-world\nimpact. We show that over 70% of validation time in RPKI relying parties is\nspent on certificate parsing and signature verification, much of it\nunnecessary. Building on this insight, we introduce the improved RPKI (iRPKI),\na backwards-compatible redesign that preserves all security guarantees while\nsubstantially reducing protocol overhead. iRPKI eliminates EE-certificates and\nROA signatures, merges revocation and integrity objects, replaces verbose\nencodings with Protobuf, and restructures repository metadata for more\nefficient access. We experimentally demonstrate that our implementation of\niRPKI in the Routinator validator achieves a 20x speed-up of processing time,\n18x improvement of bandwidth requirements and 8x reduction in cache memory\nfootprint, while also eliminating classes of vulnerabilities that have led to\nat least 10 vulnerabilities in RPKI software. iRPKI significantly increases the\nfeasibility of deploying RPKI at scale in the Internet, and especially in\nconstrained environments. Our design may be deployed incrementally without\nimpacting existing operations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01465v1", "categories": ["cs.CR"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01465v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "一种新的高效RPKI设计", "tldr": "RPKI因重用传统PKI组件而复杂且效率低下。本文分析了RPKI设计的根本原因，并提出了改进的iRPKI。iRPKI是一种向后兼容的重新设计，显著提高了性能，减少了漏洞，并增强了RPKI大规模部署的可行性。", "motivation": "当前的资源公钥基础设施（RPKI）设计因大量重用传统PKI组件（如X.509 EE证书、ASN.1编码和基于XML的存储库协议）而变得复杂且低效。这导致了过度的密码验证、冗余元数据以及存储和处理效率低下，从而造成显著的性能瓶颈、增加漏洞面并阻碍了大规模互联网部署的可扩展性。", "method": "本文首先对RPKI设计复杂性的根本原因进行了首次系统分析，并实验性地量化了其在实际世界中的影响，发现RPKI依赖方超过70%的验证时间用于不必要的证书解析和签名验证。基于此洞察，作者引入了改进的RPKI（iRPKI），这是一种向后兼容的重新设计。iRPKI通过消除EE证书和ROA签名、合并撤销和完整性对象、用Protobuf替换冗长的编码，以及重新组织存储库元数据来实现更高效的访问。", "result": "在Routinator验证器中实现的iRPKI实验性地证明，处理时间加速了20倍，带宽需求改善了18倍，缓存内存占用减少了8倍。同时，它还消除了导致RPKI软件中至少10个漏洞的漏洞类别。", "conclusion": "iRPKI显著提高了RPKI在互联网中，特别是在受限环境中，大规模部署的可行性。其设计可以逐步部署，而不会影响现有操作。", "translation": "资源公钥基础设施（RPKI）是BGP的关键安全机制，但其架构的复杂性随着其采用规模的扩大日益受到关注。当前的RPKI设计大量重用了传统的PKI组件，如X.509 EE证书、ASN.1编码和基于XML的存储库协议，所有这些都引入了过度的密码验证、冗余元数据以及存储和处理效率低下。我们表明，这些设计选择，尽管基于既定标准，却造成了显著的性能瓶颈，增加了漏洞面，并阻碍了互联网大规模部署的可扩展性。\n在本文中，我们首次对RPKI设计复杂性的根本原因进行了系统分析，并实验性地量化了它们的实际影响。我们发现RPKI依赖方超过70%的验证时间都花在证书解析和签名验证上，其中大部分是不必要的。基于这一洞察，我们引入了改进的RPKI（iRPKI），这是一种向后兼容的重新设计，它在保留所有安全保障的同时，大幅降低了协议开销。iRPKI消除了EE证书和ROA签名，合并了撤销和完整性对象，用Protobuf替换了冗长的编码，并重新组织了存储库元数据以实现更高效的访问。我们实验证明，在Routinator验证器中实现的iRPKI在处理时间上实现了20倍的加速，带宽需求改善了18倍，缓存内存占用减少了8倍，同时还消除了导致RPKI软件至少10个漏洞的漏洞类别。iRPKI显著提高了RPKI在互联网中，特别是在受限环境中，大规模部署的可行性。我们的设计可以逐步部署，而不会影响现有操作。", "summary": "本文解决了当前RPKI设计日益增长的复杂性和低效性问题，其根源在于重用传统PKI组件，导致性能瓶颈、漏洞增加和可扩展性受阻。作者进行了系统分析，揭示了不必要的证书解析和签名验证占用了超过70%的验证时间。为解决此问题，他们提出了iRPKI，一种向后兼容的重新设计，该设计消除了EE证书和ROA签名，合并了对象，使用Protobuf进行编码，并重构了元数据。实验结果表明，iRPKI在处理速度上提高了20倍，带宽需求减少了18倍，内存占用减少了8倍，同时还消除了多类漏洞。iRPKI增强了RPKI大规模部署的可行性，并可逐步采用。", "keywords": "RPKI, BGP安全, PKI, iRPKI, 可扩展性", "comments": "该论文识别了RPKI设计中源于传统组件的关键问题，并提供了一个经过充分分析的实用解决方案（iRPKI）。其量化结果展示了显著的性能提升和漏洞减少，令人信服。向后兼容性和增量部署特性对于实际应用至关重要，使其对互联网安全基础设施做出了重要的贡献。"}}
{"id": "2507.01773", "title": "Frontiers of Generative AI for Network Optimization: Theories, Limits, and Visions", "authors": ["Bo Yang", "Ruihuai Liang", "Weixin Li", "Han Wang", "Xuelin Cao", "Zhiwen Yu", "Samson Lasaulce", "Mérouane Debbah", "Mohamed-Slim Alouini", "H. Vincent Poor", "Chau Yuen"], "summary": "While interest in the application of generative AI (GenAI) in network\noptimization has surged in recent years, its rapid progress has often\novershadowed critical limitations intrinsic to generative models that remain\ninsufficiently examined in existing literature. This survey provides a\ncomprehensive review and critical analysis of GenAI in network optimization. We\nfocus on the two dominant paradigms of GenAI including generative diffusion\nmodels (GDMs) and large pre-trained models (LPTMs), and organize our discussion\naround a categorization we introduce, dividing network optimization problems\ninto two primary formulations: one-shot optimization and Markov decision\nprocess (MDP). We first trace key works, including foundational contributions\nfrom the AI community, and categorize current efforts in network optimization.\nWe also review frontier applications of GDMs and LPTMs in other networking\ntasks, providing additional context. Furthermore, we present theoretical\ngeneralization bounds for GDMs in both one-shot and MDP settings, offering\ninsights into the fundamental factors affecting model performance. Most\nimportantly, we reflect on the overestimated perception of GenAI's general\ncapabilities and caution against the all-in-one illusion it may convey. We\nhighlight critical limitations, including difficulties in constraint\nsatisfying, limited concept understanding, and the inherent probabilistic\nnature of outputs. We also propose key future directions, such as bridging the\ngap between generation and optimization. Although they are increasingly\nintegrated in implementations, they differ fundamentally in both objectives and\nunderlying mechanisms, necessitating a deeper understanding of their\ntheoretical connections. Ultimately, this survey aims to provide a structured\noverview and a deeper insight into the strengths, limitations, and potential of\nGenAI in network optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01773v1", "categories": ["cs.NI"], "cate": "cs.NI", "url": "http://arxiv.org/abs/2507.01773v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "生成式AI在网络优化中的前沿：理论、局限与展望", "tldr": "本综述全面审视了生成式AI在网络优化中的应用，探讨了其理论、局限性（如约束满足、概念理解、概率输出）和未来方向，并强调了其能力被高估的风险。", "motivation": "尽管生成式AI在网络优化中的应用兴趣激增，但其固有的关键局限性在现有文献中尚未得到充分审视。本综述旨在提供全面回顾和批判性分析。", "method": "本综述对生成式AI在网络优化中的应用进行了全面回顾和批判性分析，重点关注生成扩散模型（GDMs）和大型预训练模型（LPTMs）。它将网络优化问题分为一次性优化和马尔可夫决策过程（MDP）两种形式进行讨论，追溯了关键工作，并审查了GDMs和LPTMs在其他网络任务中的前沿应用。此外，还提出了GDMs在一次性优化和MDP设置中的理论泛化界限。", "result": "论文揭示了生成式AI在网络优化中被高估的能力感知，并警告其可能带来的“一体化”错觉。它强调了关键局限性，包括难以满足约束、有限的概念理解以及输出固有的概率性质。", "conclusion": "本综述旨在提供一个关于生成式AI在网络优化中优势、局限性和潜力的结构化概述和更深入的见解，并提出未来方向，如弥合生成与优化之间的鸿沟。", "translation": "尽管近年来生成式AI（GenAI）在网络优化中的应用兴趣激增，但其快速进展常常掩盖了生成模型固有的关键局限性，这些局限性在现有文献中尚未得到充分审视。本综述对生成式AI在网络优化中的应用进行了全面回顾和批判性分析。我们重点关注生成式AI的两种主要范式，包括生成扩散模型（GDMs）和大型预训练模型（LPTMs），并围绕我们引入的分类进行讨论，将网络优化问题分为两种主要表述：一次性优化和马尔可夫决策过程（MDP）。我们首先追溯了关键工作，包括来自AI社区的基础性贡献，并对网络优化中的当前努力进行了分类。我们还回顾了GDMs和LPTMs在其他网络任务中的前沿应用，提供了额外的背景信息。此外，我们提出了GDMs在一次性优化和MDP设置中的理论泛化界限，为影响模型性能的基本因素提供了见解。最重要的是，我们反思了对生成式AI通用能力被高估的看法，并警惕它可能传达的“一体化”错觉。我们强调了关键局限性，包括难以满足约束、有限的概念理解以及输出固有的概率性质。我们还提出了关键的未来方向，例如弥合生成与优化之间的鸿沟。尽管它们在实现中日益融合，但它们在目标和底层机制上存在根本差异，需要更深入地理解它们的理论联系。最终，本综述旨在提供一个关于生成式AI在网络优化中优势、局限性和潜力的结构化概述和更深入的见解。", "summary": "本综述全面审查了生成式AI（GenAI）在网络优化中的应用，重点关注生成扩散模型（GDMs）和大型预训练模型（LPTMs）。论文将网络优化问题分为一次性优化和马尔可夫决策过程（MDP）进行分析，并探讨了GDMs的理论泛化界限。文章批判性地指出GenAI在网络优化中存在被高估的能力感知和“一体化”错觉，强调了其在约束满足、概念理解和概率输出方面的局限性。最后，提出了弥合生成与优化之间差距等未来研究方向，旨在提供GenAI在网络优化中优势、局限性和潜力的深入见解。", "keywords": "生成式AI, 网络优化, 生成扩散模型, 大型预训练模型, 局限性", "comments": "这篇综述及时地指出了生成式AI在网络优化领域应用中被忽视的局限性，特别是其在解决约束问题和概念理解方面的挑战。它不仅回顾了现有进展，还提供了理论分析和未来研究方向，对于纠正对GenAI的过度乐观预期，并引导该领域进行更严谨和有针对性的研究具有重要意义。其创新之处在于对GenAI在网络优化中应用的批判性视角和对局限性的深入分析。"}}
{"id": "2507.01254", "title": "Robust Brain Tumor Segmentation with Incomplete MRI Modalities Using Hölder Divergence and Mutual Information-Enhanced Knowledge Transfer", "authors": ["Runze Cheng", "Xihang Qiu", "Ming Li", "Ye Zhang", "Chun Li", "Fei Yu"], "summary": "Multimodal MRI provides critical complementary information for accurate brain\ntumor segmentation. However, conventional methods struggle when certain\nmodalities are missing due to issues such as image quality, protocol\ninconsistencies, patient allergies, or financial constraints. To address this,\nwe propose a robust single-modality parallel processing framework that achieves\nhigh segmentation accuracy even with incomplete modalities. Leveraging Holder\ndivergence and mutual information, our model maintains modality-specific\nfeatures while dynamically adjusting network parameters based on the available\ninputs. By using these divergence- and information-based loss functions, the\nframework effectively quantifies discrepancies between predictions and\nground-truth labels, resulting in consistently accurate segmentation. Extensive\nevaluations on the BraTS 2018 and BraTS 2020 datasets demonstrate superior\nperformance over existing methods in handling missing modalities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01254v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01254v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "利用霍尔德散度和互信息增强的知识迁移进行不完整MRI模态的鲁棒脑肿瘤分割", "tldr": "本文提出一种鲁棒的单模态并行处理框架，通过结合霍尔德散度与互信息，即使在MRI模态不完整的情况下也能实现高精度脑肿瘤分割，并在BraTS数据集上表现优于现有方法。", "motivation": "传统脑肿瘤分割方法在某些MRI模态缺失时（因图像质量、协议不一致、患者过敏或经济限制等问题）表现不佳，而多模态MRI对准确的脑肿瘤分割至关重要。", "method": "提出一个鲁棒的单模态并行处理框架。该框架利用霍尔德散度（Hölder divergence）和互信息（mutual information）来保持模态特定特征，并根据可用输入动态调整网络参数。通过使用基于散度和信息的损失函数来有效量化预测与真实标签之间的差异。", "result": "在BraTS 2018和BraTS 2020数据集上的广泛评估表明，该方法在处理缺失模态方面表现出优于现有方法的性能，实现了持续准确的分割。", "conclusion": "本研究提出的框架能够有效应对MRI模态缺失的挑战，实现鲁棒且准确的脑肿瘤分割。", "translation": "多模态MRI为准确的脑肿瘤分割提供了关键的补充信息。然而，由于图像质量、协议不一致、患者过敏或经济限制等问题，当某些模态缺失时，传统方法会遇到困难。为了解决这个问题，我们提出了一种鲁棒的单模态并行处理框架，即使在模态不完整的情况下也能实现高分割精度。我们的模型利用霍尔德散度和互信息，在保持模态特定特征的同时，根据可用输入动态调整网络参数。通过使用这些基于散度和信息的损失函数，该框架有效地量化了预测和真实标签之间的差异，从而实现了一致准确的分割。在BraTS 2018和BraTS 2020数据集上的广泛评估表明，在处理缺失模态方面，该方法优于现有方法。", "summary": "本文提出一种名为“霍尔德散度和互信息增强的知识迁移”的鲁棒单模态并行处理框架，旨在解决脑肿瘤分割中MRI模态不完整的问题。该框架利用霍尔德散度和互信息来保留模态特定特征并动态调整网络参数，同时使用基于散度和信息的损失函数来精确量化预测差异。实验证明，该方法在BraTS 2018和BraTS 2020数据集上，在处理缺失模态方面表现出优于现有方法的分割性能。", "keywords": "脑肿瘤分割, 不完整MRI模态, 霍尔德散度, 互信息, 知识迁移", "comments": "该论文的创新点在于提出了一个结合霍尔德散度和互信息的单模态并行处理框架，有效地解决了多模态MRI在模态缺失时的脑肿瘤分割难题。其动态调整参数和利用特定损失函数的方法增强了模型的鲁棒性，这对于临床应用中数据不完整的情况具有重要意义。"}}
{"id": "2507.01808", "title": "Empowering Manufacturers with Privacy-Preserving AI Tools: A Case Study in Privacy-Preserving Machine Learning to Solve Real-World Problems", "authors": ["Xiaoyu Ji", "Jessica Shorland", "Joshua Shank", "Pascal Delpe-Brice", "Latanya Sweeney", "Jan Allebach", "Ali Shakouri"], "summary": "Small- and medium-sized manufacturers need innovative data tools but, because\nof competition and privacy concerns, often do not want to share their\nproprietary data with researchers who might be interested in helping. This\npaper introduces a privacy-preserving platform by which manufacturers may\nsafely share their data with researchers through secure methods, so that those\nresearchers then create innovative tools to solve the manufacturers' real-world\nproblems, and then provide tools that execute solutions back onto the platform\nfor others to use with privacy and confidentiality guarantees. We illustrate\nthis problem through a particular use case which addresses an important problem\nin the large-scale manufacturing of food crystals, which is that quality\ncontrol relies on image analysis tools. Previous to our research, food crystals\nin the images were manually counted, which required substantial and\ntime-consuming human efforts, but we have developed and deployed a crystal\nanalysis tool which makes this process both more rapid and accurate. The tool\nenables automatic characterization of the crystal size distribution and numbers\nfrom microscope images while the natural imperfections from the sample\npreparation are automatically removed; a machine learning model to count high\nresolution translucent crystals and agglomeration of crystals was also\ndeveloped to aid in these efforts. The resulting algorithm was then packaged\nfor real-world use on the factory floor via a web-based app secured through the\noriginating privacy-preserving platform, allowing manufacturers to use it while\nkeeping their proprietary data secure. After demonstrating this full process,\nfuture directions are also explored.", "comment": "20 pages, 11 figures, 30 references", "pdf_url": "http://arxiv.org/pdf/2507.01808v1", "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.ET", "68T01, 68T05, 68T45, 94A60"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01808v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "利用隐私保护AI工具赋能制造商：隐私保护机器学习解决现实世界问题的案例研究", "tldr": "本文介绍了一个隐私保护平台，允许制造商安全地与研究人员共享数据，以开发和部署AI工具来解决实际问题，并通过一个食品晶体图像分析的案例进行了演示。", "motivation": "中小型制造商需要创新的数据工具，但由于竞争和隐私问题，不愿与研究人员共享专有数据。这阻碍了研究人员开发解决制造商实际问题的工具。", "method": "本研究提出了一个隐私保护平台，通过安全方法使制造商能够与研究人员共享数据。研究人员在此平台上开发创新工具，并将其部署回平台供制造商使用，同时保证数据隐私和机密性。通过一个食品晶体大规模生产中的图像分析用例进行了演示，开发了一个晶体分析工具，包括一个用于计数高分辨率半透明晶体和晶体团块的机器学习模型，并将其打包成一个基于网络的应用程序。", "result": "开发并部署了一个晶体分析工具，能够自动表征显微图像中的晶体尺寸分布和数量，并自动去除样品制备中的自然缺陷。开发了一个机器学习模型来计数高分辨率半透明晶体和晶体团块。该算法通过源隐私保护平台上的安全网络应用程序打包，允许制造商在保护其专有数据的情况下使用。", "conclusion": "本文展示了利用隐私保护平台和AI工具解决制造商实际问题的完整过程。未来的研究方向也得到了探讨。", "translation": "中小型制造商需要创新的数据工具，但由于竞争和隐私担忧，通常不愿与可能感兴趣提供帮助的研究人员分享其专有数据。本文介绍了一个隐私保护平台，制造商可以通过安全方法与研究人员安全地共享其数据，以便研究人员创建创新工具来解决制造商的现实世界问题，然后将执行解决方案的工具提供回平台，供他人在隐私和保密保证下使用。我们通过一个特定的用例来说明这个问题，该用例解决了食品晶体大规模生产中的一个重要问题，即质量控制依赖于图像分析工具。在我们研究之前，图像中的食品晶体是手动计数的，这需要大量耗时的人力，但我们开发并部署了一个晶体分析工具，使这个过程更快、更准确。该工具能够自动表征显微图像中的晶体尺寸分布和数量，同时自动去除样品制备中的自然缺陷；还开发了一个机器学习模型来计数高分辨率半透明晶体和晶体团块，以协助这些工作。然后，将所得算法通过源隐私保护平台进行安全保护，打包成一个基于网络的应用程序，以便在工厂车间实际使用，从而允许制造商在使用它的同时保持其专有数据安全。在演示了这一完整过程之后，还探讨了未来的方向。", "summary": "本文提出了一种隐私保护平台，旨在解决中小型制造商因数据隐私担忧而不愿与研究人员共享专有数据的问题。该平台允许制造商安全地共享数据，使研究人员能够开发并部署创新的AI工具。通过一个食品晶体生产中图像质量控制的案例研究，研究团队开发了一个自动化晶体分析工具，该工具利用机器学习模型提高了计数效率和准确性，并以安全的网络应用形式提供给制造商使用，确保了数据隐私。", "keywords": "隐私保护AI, 机器学习, 制造业, 数据共享, 图像分析", "comments": "本文的创新点在于提出了一个实用的隐私保护平台，有效解决了制造商在数据共享和AI工具应用中的隐私顾虑。通过将隐私保护技术与机器学习相结合，为工业界提供了新的解决方案。其重要性在于为制造业数字化转型提供了安全路径，尤其是在数据敏感的质量控制领域。案例研究具体且有说服力，展示了理论到实际应用的完整流程。"}}
{"id": "2507.01209", "title": "Judgment as Coordination: A Joint Systems View of Visualization Design Practice", "authors": ["Paul C. Parsons", "Arran Ridley"], "summary": "Professional visualization design has become an increasingly important area\nof inquiry, yet much of the field's discourse remains anchored in\nresearcher-centered contexts. Studies of design practice often focus on\nindividual designers' decisions and reflections, offering limited insight into\nthe collaborative and systemic dimensions of professional work. In this paper,\nwe propose a systems-level reframing of design judgment grounded in the\ncoordination and adaptation that sustain progress amid uncertainty, constraint,\nand misalignment. Drawing on sustained engagement across multiple empirical\nstudies--including ethnographic observation of design teams and qualitative\nstudies of individual practitioners--we identify recurring episodes in which\ncoherence was preserved not by selecting an optimal option, but by repairing\nalignment, adjusting plans, and reframing goals. We interpret these dynamics\nthrough the lens of Joint Cognitive Systems, which provide tools for analyzing\nhow judgment emerges as a distributed capacity within sociotechnical activity.\nThis perspective surfaces often-invisible work in visualization design and\noffers researchers a new conceptual vocabulary for studying how design activity\nis sustained in practice.", "comment": "IEEE VIS 2025 (conditional acceptance)", "pdf_url": "http://arxiv.org/pdf/2507.01209v1", "categories": ["cs.HC"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01209v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "判断即协调：可视化设计实践的联合系统视角", "tldr": "本文提出了一种将可视化设计判断视为协调过程的系统级重构，强调在不确定性中通过调整和重构来维持一致性。", "motivation": "现有关于专业可视化设计的研究多以研究者为中心，且常聚焦于个体设计师的决策，未能充分揭示专业工作中协作性和系统性的维度。本文旨在弥补这一空白。", "method": "通过多项实证研究，包括设计团队的民族志观察和个体从业者的定性研究，识别了在不确定性、约束和错位中维持进展的协调和适应机制。", "result": "研究发现，一致性的维持并非通过选择最优选项，而是通过修复对齐、调整计划和重构目标来实现。这些动态通过联合认知系统（Joint Cognitive Systems）的视角进行解释。", "conclusion": "本文提出的视角揭示了可视化设计中常被忽视的工作，并为研究人员提供了研究设计活动如何在实践中得以维持的新概念词汇。", "translation": "专业可视化设计已成为一个日益重要的研究领域，然而该领域的大部分论述仍以研究者为中心。对设计实践的研究常常关注个体设计师的决策和反思，对专业工作的协作和系统维度提供的见解有限。在本文中，我们提出了一种以协调和适应为基础的设计判断的系统级重构，这种协调和适应在不确定性、约束和错位中维持进展。通过多项实证研究（包括设计团队的民族志观察和个体从业者的定性研究）的持续参与，我们识别了反复出现的事件，在这些事件中，一致性并非通过选择最优选项来保持，而是通过修复对齐、调整计划和重构目标来实现。我们通过联合认知系统（Joint Cognitive Systems）的视角来解释这些动态，该系统提供了分析判断如何作为社会技术活动中分布式能力出现的工具。这一视角揭示了可视化设计中常常不可见的工作，并为研究人员提供了研究设计活动如何在实践中得以维持的新概念词汇。", "summary": "本文提出将专业可视化设计中的判断视为一个协调过程，旨在弥补现有研究对个体决策的过度关注而忽视协作和系统性维度的不足。通过对设计团队和个体从业者的实证研究，作者发现设计中的一致性是在不确定性下通过修复、调整和重构目标来实现的，而非简单选择最优解。文章通过“联合认知系统”的视角解释了这些动态，并为理解和研究可视化设计实践提供了新的概念框架，揭示了其中常被忽视的工作。", "keywords": "可视化设计, 协调, 联合认知系统, 设计实践, 判断", "comments": "该论文的创新之处在于其将可视化设计判断从个体决策层面提升到系统级协调的视角，并引入了“联合认知系统”的理论框架。这有助于揭示设计实践中隐藏的协作和适应性工作，为领域研究提供了新的概念工具和更全面的理解。"}}
{"id": "2507.01030", "title": "Optimizing Flamelet Generated Manifold Models: A Machine Learning Performance Study", "authors": ["Reza Lotfi Navaei", "Mohammad Safarzadeh", "Seyed Mohammad Jafar Sobhani"], "summary": "In chemistry tabulations and Flamelet combustion models, the Flamelet\nGenerated Manifold (FGM) is recognized for its precision and physical\nrepresentation. The practical implementation of FGM requires a significant\nallocation of memory resources. FGM libraries are developed specifically for a\nspecific fuel and subsequently utilized for all numerical problems using\nmachine learning techniques. This research aims to develop libraries of Laminar\nFGM utilizing machine learning algorithms for application in combustion\nsimulations of methane fuel. This study employs four Machine Learning\nalgorithms to regenerate Flamelet libraries, based on an understanding of data\nsources, techniques, and data-driven concepts. 1. Multi-Layer Perceptron; 2.\nRandom Forest; 3. Linear Regression; 4. Support Vector Machine. Seven libraries\nwere identified as appropriate for constructing a database for training machine\nlearning models, giving an error rate of 2.30%. The default architectures of\neach method were evaluated to determine the optimal approach, leading to the\nselection of the MLP method as the primary choice. The method was enhanced\nthrough hyperparameter tuning to improve accuracy. The quantity of hidden\nlayers and neurons significantly influences method performance. The optimal\nmodel, comprising four hidden layers with 10, 15, 20, and 25 neurons\nrespectively, achieved an accuracy of 99.81%.", "comment": "It has been submitted to ASME Journal of Heat and Mass Transfer", "pdf_url": "http://arxiv.org/pdf/2507.01030v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01030v1", "date": "2025-06-18", "updated": "2025-06-18", "AI": {"title_translation": "优化火焰面生成流形模型：一项机器学习性能研究", "tldr": "本研究旨在通过机器学习（特别是优化的多层感知器MLP模型）来优化火焰面生成流形（FGM）模型，以减少其内存需求并提高在甲烷燃料燃烧模拟中的精度，最终实现了99.81%的准确率。", "motivation": "火焰面生成流形（FGM）模型在化学表格和火焰面燃烧模型中以其高精度和良好的物理表示而受到认可，但其实际应用需要大量的内存资源。本研究旨在利用机器学习算法开发层流FGM库，以优化甲烷燃料燃烧模拟中的内存消耗问题。", "method": "本研究采用了四种机器学习算法（多层感知器、随机森林、线性回归、支持向量机）来重新生成火焰面库。研究基于七个识别出的库构建了训练数据库。通过评估这些方法的默认架构，确定了多层感知器（MLP）为最佳选择。随后，通过超参数调优对MLP方法进行了增强，以进一步提高准确性，并分析了隐藏层和神经元数量对模型性能的影响。", "result": "用于训练机器学习模型的数据库初始误差率为2.30%。在评估了四种机器学习算法后，多层感知器（MLP）被选为主要方法。通过超参数调优，最佳MLP模型由四个隐藏层组成（分别包含10、15、20和25个神经元），最终实现了99.81%的准确率。", "conclusion": "本研究证明了机器学习算法，特别是经过优化的多层感知器（MLP）模型，能够显著提高火焰面生成流形（FGM）模型的性能，并在甲烷燃料燃烧模拟中实现高精度（99.81%），这为解决FGM模型的内存消耗问题提供了有效的解决方案。", "translation": "在化学表格和火焰面燃烧模型中，火焰面生成流形（FGM）以其精度和物理表示而闻名。FGM的实际实现需要大量的内存资源。FGM库是专门为特定燃料开发的，随后通过机器学习技术用于所有数值问题。本研究旨在开发利用机器学习算法的层流FGM库，应用于甲烷燃料的燃烧模拟。本研究基于对数据源、技术和数据驱动概念的理解，采用四种机器学习算法来重新生成火焰面库：1. 多层感知器；2. 随机森林；3. 线性回归；4. 支持向量机。确定了七个库适合构建用于训练机器学习模型的数据库，误差率为2.30%。评估了每种方法的默认架构以确定最佳方法，最终选择MLP方法作为主要选择。通过超参数调优增强了该方法以提高准确性。隐藏层和神经元的数量显著影响方法性能。最佳模型包含四个隐藏层，分别有10、15、20和25个神经元，实现了99.81%的准确率。", "summary": "本研究旨在解决火焰面生成流形（FGM）模型在燃烧模拟中因内存消耗大而带来的挑战。为此，研究探索并应用了多层感知器（MLP）、随机森林、线性回归和支持向量机等四种机器学习算法来重新生成火焰面库。经过对比评估和对MLP模型的超参数调优，最终确定了一个包含四个隐藏层的MLP模型，该模型在甲烷燃料燃烧模拟中实现了99.81%的高准确率，有效优化了FGM模型的性能。", "keywords": "火焰面生成流形, 机器学习, 燃烧模拟, 多层感知器, 模型优化", "comments": "这项研究通过将机器学习技术应用于火焰面生成流形（FGM）模型，为提升燃烧模拟的效率和精度提供了一个创新性的解决方案。其核心贡献在于证明了优化的多层感知器（MLP）模型能够显著降低FGM的内存需求并保持极高的准确性。这种将数据驱动方法与传统物理模型相结合的策略，对于解决计算流体力学中资源密集型问题具有重要的借鉴意义和广阔的应用前景。"}}
{"id": "2507.01445", "title": "Basis Expansion Extrapolation based Long-Term Channel Prediction for Massive MIMO OTFS Systems", "authors": ["Yanfeng Zhang", "Xu Zhu", "Yujie Liu", "Yong Liang Guan", "David González G.", "Vincent K. N. Lau"], "summary": "Massive multi-input multi-output (MIMO) combined with orthogonal time\nfrequency space (OTFS) modulation has emerged as a promising technique for\nhigh-mobility scenarios. However, its performance could be severely degraded\ndue to channel aging caused by user mobility and high processing latency. In\nthis paper, an integrated scheme of uplink (UL) channel estimation and downlink\n(DL) channel prediction is proposed to alleviate channel aging in time division\nduplex (TDD) massive MIMO-OTFS systems. Specifically, first, an iterative basis\nexpansion model (BEM) based UL channel estimation scheme is proposed to\naccurately estimate UL channels with the aid of carefully designed OTFS frame\npattern. Then a set of Slepian sequences are used to model the estimated UL\nchannels, and the dynamic Slepian coefficients are fitted by a set of\northogonal polynomials. A channel predictor is derived to predict DL channels\nby iteratively extrapolating the Slepian coefficients. Simulation results\nverify that the proposed UL channel estimation and DL channel prediction\nschemes outperform the existing schemes in terms of normalized mean square\nerror of channel estimation/prediction and DL spectral efficiency, with less\npilot overhead.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01445v1", "categories": ["eess.SP"], "cate": "eess.SP", "url": "http://arxiv.org/abs/2507.01445v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于基扩展外推的大规模MIMO OTFS系统长期信道预测", "tldr": "本文提出了一种基于基扩展外推的方案，用于大规模MIMO OTFS系统中的长期信道预测，以缓解信道老化问题。该方案集成了上行信道估计和下行信道预测，通过迭代基扩展模型进行上行估计，并利用Slepian序列和正交多项式拟合来外推下行信道，仿真结果表明其性能优于现有方案。", "motivation": "大规模MIMO结合OTFS调制在高速移动场景下具有前景，但用户移动性和高处理延迟导致的信道老化会严重降低其性能。", "method": "提出了一种上行（UL）信道估计和下行（DL）信道预测的集成方案。首先，利用迭代基扩展模型（BEM）和精心设计的OTFS帧模式进行UL信道估计。然后，使用Slepian序列对估计的UL信道进行建模，并用正交多项式拟合动态Slepian系数。最后，通过迭代外推Slepian系数来推导信道预测器以预测DL信道。", "result": "仿真结果验证了所提出的UL信道估计和DL信道预测方案在信道估计/预测的归一化均方误差和DL频谱效率方面优于现有方案，且导频开销更少。", "conclusion": "所提出的上行信道估计和下行信道预测集成方案能有效缓解大规模MIMO-OTFS系统中的信道老化问题，并显著提升系统性能。", "translation": "大规模多输入多输出（MIMO）结合正交时频空间（OTFS）调制已成为高移动性场景下一种有前景的技术。然而，由于用户移动性和高处理延迟导致的信道老化，其性能可能会严重下降。本文提出了一种上行（UL）信道估计和下行（DL）信道预测的集成方案，以缓解时分双工（TDD）大规模MIMO-OTFS系统中的信道老化问题。具体而言，首先，提出了一种基于迭代基扩展模型（BEM）的UL信道估计方案，借助精心设计的OTFS帧模式准确估计UL信道。然后，使用一组Slepian序列对估计的UL信道进行建模，并用一组正交多项式拟合动态Slepian系数。通过迭代外推Slepian系数，推导出一个信道预测器来预测DL信道。仿真结果验证了所提出的UL信道估计和DL信道预测方案在信道估计/预测的归一化均方误差和DL频谱效率方面优于现有方案，且导频开销更少。", "summary": "本文针对大规模MIMO OTFS系统在高移动性场景下因信道老化导致的性能下降问题，提出了一种上行信道估计与下行信道预测的集成方案。该方案首先利用迭代基扩展模型（BEM）进行上行信道估计，接着使用Slepian序列对估计信道建模，并用正交多项式拟合动态Slepian系数。在此基础上，通过迭代外推Slepian系数来预测下行信道。仿真结果表明，与现有方案相比，所提方案在信道估计/预测的归一化均方误差和下行频谱效率方面表现更优，且导频开销更低。", "keywords": "大规模MIMO, OTFS, 信道预测, 信道估计, 基扩展模型", "comments": "该论文提出了一种创新的方法来解决高移动性大规模MIMO OTFS系统中的信道老化问题，通过集成上行信道估计和下行信道预测。利用BEM进行上行估计以及Slepian序列外推结合正交多项式拟合进行下行预测，展现了复杂的信号处理技术。所报告的在归一化均方误差和频谱效率方面的改进以及导频开销的减少，突出了其实际意义。"}}
{"id": "2507.01641", "title": "Joint Spatial Division and Multiplexing with Customized Orthogonal Group Channels in Multi-RIS-Assisted Systems", "authors": ["Weicong Chen", "Chao-Kai Wen", "Wankai Tang", "Xiao Li", "Shi Jin"], "summary": "Reconfigurable intelligent surfaces (RISs) offer the unique capability to\nreshape the radio environment, thereby simplifying transmission schemes\ntraditionally contingent on channel conditions. Joint spatial division and\nmultiplexing (JSDM) emerges as a low-overhead transmission scheme for\nmulti-user equipment (UE) scenarios, typically requiring complex matrix\ndecomposition to achieve block-diagonalization of the effective channel matrix.\nIn this study, we introduce an innovative JSDM design that leverages RISs to\ncustomize channels, thereby streamlining the overall procedures. By\nstrategically positioning RISs at the discrete Fourier transform (DFT)\ndirections of the base station (BS), we establish orthogonal line-of-sight\nlinks within the BS-RIS channel, enabling a straightforward pre-beamforming\ndesign. Based on UE grouping, we devise reflected beams of the RIS with\noptimized directions to mitigate inter-group interference in the RISs-UEs\nchannel. An approximation of the channel cross-correlation coefficient is\nderived and serves as a foundation for the RISs-UEs association, further\ndiminishing inter-group interference. Numerical results substantiate the\nefficacy of our RIS-customized JSDM in not only achieving effective channel\nblock-diagonalization but also in significantly enhancing the sum spectral\nefficiency for multi-UE transmissions.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.01641v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "cate": "cs.IT", "url": "http://arxiv.org/abs/2507.01641v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "多RIS辅助系统中定制正交组信道的联合空间划分与多路复用", "tldr": "本研究提出了一种创新的JSDM设计，利用RIS定制信道，通过在基站DFT方向放置RIS并优化反射波束来简化预波束成形和减轻组间干扰，从而有效实现信道块对角化并提高多用户传输的总频谱效率。", "motivation": "传统的联合空间划分与多路复用（JSDM）方案在多用户设备（UE）场景中通常需要复杂的矩阵分解来实现有效信道矩阵的块对角化，这带来了较高的开销。本研究旨在利用可重构智能表面（RIS）定制信道，从而简化JSDM的整体过程，降低复杂度。", "method": "本研究提出了一种创新的JSDM设计，利用RIS定制信道。具体方法包括：1) 将RIS战略性地放置在基站（BS）的离散傅里叶变换（DFT）方向，以在BS-RIS信道中建立正交视距链路，从而实现直接的预波束成形设计。2) 基于UE分组，设计具有优化方向的RIS反射波束，以减轻RIS-UE信道中的组间干扰。3) 推导信道互相关系数的近似值，并以此作为RIS-UE关联的基础，进一步减少组间干扰。", "result": "数值结果证实了本研究提出的RIS定制JSDM方案的有效性，不仅能有效实现信道块对角化，还能显著提高多UE传输的总频谱效率。", "conclusion": "本研究成功地提出了一种创新的RIS定制JSDM设计，该设计通过简化预波束成形和有效减轻组间干扰，实现了信道块对角化和显著的频谱效率提升，为多RIS辅助系统中的低开销多用户传输提供了有效解决方案。", "translation": "可重构智能表面（RIS）提供了重塑无线电环境的独特能力，从而简化了传统上依赖信道条件的传输方案。联合空间划分与多路复用（JSDM）作为一种针对多用户设备（UE）场景的低开销传输方案出现，通常需要复杂的矩阵分解才能实现有效信道矩阵的块对角化。在本研究中，我们引入了一种创新的JSDM设计，该设计利用RIS定制信道，从而简化了整体过程。通过将RIS战略性地放置在基站（BS）的离散傅里叶变换（DFT）方向，我们在BS-RIS信道内建立了正交视距链路，从而实现了直接的预波束成形设计。基于UE分组，我们设计了具有优化方向的RIS反射波束，以减轻RIS-UE信道中的组间干扰。推导了信道互相关系数的近似值，并将其作为RIS-UE关联的基础，进一步减少了组间干扰。数值结果证实了我们提出的RIS定制JSDM方案的有效性，它不仅能有效实现信道块对角化，还能显著提高多UE传输的总频谱效率。", "summary": "本论文提出了一种创新的RIS辅助联合空间划分与多路复用（JSDM）设计，旨在通过定制信道来简化传统JSDM中复杂的矩阵分解过程。该方案通过将RIS放置在基站的DFT方向来建立正交视距链路，实现简化的预波束成形。同时，基于UE分组优化RIS反射波束方向，并利用信道互相关系数进行RIS-UE关联，以有效减轻组间干扰。数值结果表明，该RIS定制JSDM方案能有效实现信道块对角化，并显著提升多用户传输的总频谱效率。", "keywords": "RIS, JSDM, 频谱效率, 信道块对角化, 预波束成形", "comments": "这项研究的创新之处在于将RISs的信道重塑能力与JSDM方案相结合，尤其是在基站DFT方向放置RIS以简化预波束成形，以及通过优化反射波束和UE关联来减轻干扰。这提供了一种低开销、高效率的多用户传输解决方案，对于未来6G通信系统中RIS的应用具有重要意义。"}}
{"id": "2507.01438", "title": "EdgeLoRA: An Efficient Multi-Tenant LLM Serving System on Edge Devices", "authors": ["Zheyu Shen", "Yexiao He", "Ziyao Wang", "Yuning Zhang", "Guoheng Sun", "Wanghao Ye", "Ang Li"], "summary": "Large Language Models (LLMs) have gained significant attention due to their\nversatility across a wide array of applications. Fine-tuning LLMs with\nparameter-efficient adapters, such as Low-Rank Adaptation (LoRA), enables these\nmodels to efficiently adapt to downstream tasks without extensive retraining.\nDeploying fine-tuned LLMs on multi-tenant edge devices offers substantial\nbenefits, such as reduced latency, enhanced privacy, and personalized\nresponses. However, serving LLMs efficiently on resource-constrained edge\ndevices presents critical challenges, including the complexity of adapter\nselection for different tasks and memory overhead from frequent adapter\nswapping. Moreover, given the multiple requests in multi-tenant settings,\nprocessing requests sequentially results in underutilization of computational\nresources and increased latency. This paper introduces EdgeLoRA, an efficient\nsystem for serving LLMs on edge devices in multi-tenant environments. EdgeLoRA\nincorporates three key innovations: (1) an adaptive adapter selection mechanism\nto streamline the adapter configuration process; (2) heterogeneous memory\nmanagement, leveraging intelligent adapter caching and pooling to mitigate\nmemory operation overhead; and (3) batch LoRA inference, enabling efficient\nbatch processing to significantly reduce computational latency. Comprehensive\nevaluations using the Llama3.1-8B model demonstrate that EdgeLoRA significantly\noutperforms the status quo (i.e., llama.cpp) in terms of both latency and\nthroughput. The results demonstrate that EdgeLoRA can achieve up to a 4 times\nboost in throughput. Even more impressively, it can serve several orders of\nmagnitude more adapters simultaneously. These results highlight EdgeLoRA's\npotential to transform edge deployment of LLMs in multi-tenant scenarios,\noffering a scalable and efficient solution for resource-constrained\nenvironments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01438v1", "categories": ["cs.DC", "cs.AI", "cs.LG"], "cate": "cs.DC", "url": "http://arxiv.org/abs/2507.01438v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "EdgeLoRA：一种高效的边缘设备多租户LLM服务系统", "tldr": "EdgeLoRA是一个高效的系统，用于在资源受限的边缘设备上为多租户环境提供LLM服务，通过自适应适配器选择、异构内存管理和批处理LoRA推理显著提高吞吐量和降低延迟。", "motivation": "在资源受限的边缘设备上高效部署微调后的LLM面临关键挑战，包括不同任务的适配器选择复杂性、频繁适配器交换带来的内存开销，以及多租户设置中顺序处理请求导致的计算资源利用不足和延迟增加。", "method": "本文引入了EdgeLoRA系统，它包含三项关键创新：1) 自适应适配器选择机制，以简化适配器配置过程；2) 异构内存管理，利用智能适配器缓存和池化来减轻内存操作开销；3) 批处理LoRA推理，实现高效的批处理以显著降低计算延迟。", "result": "使用Llama3.1-8B模型进行的全面评估表明，EdgeLoRA在延迟和吞吐量方面显著优于现有技术（即llama.cpp）。结果显示EdgeLoRA的吞吐量可提高高达4倍，并且可以同时服务多几个数量级的适配器。", "conclusion": "EdgeLoRA为资源受限环境下的多租户场景中LLM的边缘部署提供了一个可扩展且高效的解决方案，有望改变LLM的边缘部署。", "translation": "大型语言模型（LLM）因其在广泛应用中的多功能性而受到广泛关注。使用参数高效适配器（如低秩适应（LoRA））对LLM进行微调，使这些模型能够高效地适应下游任务，而无需进行大规模的再训练。在多租户边缘设备上部署微调后的LLM具有显著优势，例如降低延迟、增强隐私和个性化响应。然而，在资源受限的边缘设备上高效服务LLM带来了严峻挑战，包括不同任务的适配器选择复杂性以及频繁适配器交换带来的内存开销。此外，考虑到多租户设置中的多个请求，顺序处理请求会导致计算资源利用不足和延迟增加。本文介绍了EdgeLoRA，一个在多租户环境中为边缘设备提供LLM服务的高效系统。EdgeLoRA融合了三项关键创新：(1) 自适应适配器选择机制，以简化适配器配置过程；(2) 异构内存管理，利用智能适配器缓存和池化来减轻内存操作开销；(3) 批处理LoRA推理，实现高效的批处理以显著降低计算延迟。使用Llama3.1-8B模型进行的全面评估表明，EdgeLoRA在延迟和吞吐量方面显著优于现有技术（即llama.cpp）。结果表明，EdgeLoRA的吞吐量可提高高达4倍。更令人印象深刻的是，它可以同时服务多几个数量级的适配器。这些结果突出了EdgeLoRA在多租户场景中改变LLM边缘部署的潜力，为资源受限环境提供了一个可扩展且高效的解决方案。", "summary": "EdgeLoRA是一个针对边缘设备多租户LLM服务的高效系统。它通过自适应适配器选择、异构内存管理和批处理LoRA推理三大创新，解决了资源受限环境下LLM部署面临的挑战，如适配器选择复杂性、内存开销和计算资源利用不足。实验证明，EdgeLoRA在吞吐量和延迟方面显著优于现有方案，吞吐量提升高达4倍，并能同时服务更多适配器，为LLM在边缘设备上的可扩展和高效部署提供了解决方案。", "keywords": "LLM服务, 边缘计算, LoRA, 多租户, 内存管理", "comments": "EdgeLoRA的创新性在于其为解决边缘设备上LLM多租户服务中的核心挑战（如内存管理和计算效率）提供了一套全面的解决方案。通过结合自适应适配器选择、智能内存管理和批处理推理，它有效地提升了LLM在资源受限环境下的性能和可扩展性。其在吞吐量和适配器服务数量上的显著提升，表明其在实际部署中具有重要的应用价值。"}}
{"id": "2507.01418", "title": "Penalizing Transparency? How AI Disclosure and Author Demographics Shape Human and AI Judgments About Writing", "authors": ["Inyoung Cheong", "Alicia Guo", "Mina Lee", "Zhehui Liao", "Kowe Kadoma", "Dongyoung Go", "Joseph Chee Chang", "Peter Henderson", "Mor Naaman", "Amy X. Zhang"], "summary": "As AI integrates in various types of human writing, calls for transparency\naround AI assistance are growing. However, if transparency operates on uneven\nground and certain identity groups bear a heavier cost for being honest, then\nthe burden of openness becomes asymmetrical. This study investigates how AI\ndisclosure statement affects perceptions of writing quality, and whether these\neffects vary by the author's race and gender. Through a large-scale controlled\nexperiment, both human raters (n = 1,970) and LLM raters (n = 2,520) evaluated\na single human-written news article while disclosure statements and author\ndemographics were systematically varied. This approach reflects how both human\nand algorithmic decisions now influence access to opportunities (e.g., hiring,\npromotion) and social recognition (e.g., content recommendation algorithms). We\nfind that both human and LLM raters consistently penalize disclosed AI use.\nHowever, only LLM raters exhibit demographic interaction effects: they favor\narticles attributed to women or Black authors when no disclosure is present.\nBut these advantages disappear when AI assistance is revealed. These findings\nilluminate the complex relationships between AI disclosure and author identity,\nhighlighting disparities between machine and human evaluation patterns.", "comment": "Presented at CHIWORK 2025 Workshop on Generative AI Disclosure,\n  Ownership, and Accountability in Co-Creative Domains", "pdf_url": "http://arxiv.org/pdf/2507.01418v1", "categories": ["cs.CY", "cs.AI", "H.5.2; I.2"], "cate": "cs.CY", "url": "http://arxiv.org/abs/2507.01418v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "惩罚透明度？AI披露和作者人口统计如何影响人类和AI对写作的判断", "tldr": "本研究发现，人类和LLM评分者都会惩罚披露的AI使用。LLM评分者在未披露AI使用时偏爱女性或黑人作者，但披露后这种优势消失。", "motivation": "随着AI在人类写作中的整合，对AI辅助透明度的呼声日益增长。然而，如果透明度在不平等的环境中运作，某些身份群体为诚实付出更高的代价，那么公开的负担就会变得不对称。", "method": "通过一项大规模对照实验，人类评分者（n=1,970）和LLM评分者（n=2,520）评估了一篇人类撰写的新闻文章，同时系统地改变了披露声明和作者人口统计信息。", "result": "研究发现，人类和LLM评分者都持续惩罚已披露的AI使用。然而，只有LLM评分者表现出人口统计交互效应：当没有披露时，他们偏爱归属于女性或黑人作者的文章，但当AI辅助被揭示时，这些优势消失了。", "conclusion": "这些发现阐明了AI披露与作者身份之间复杂的关系，突出了机器和人类评估模式之间的差异。", "translation": "随着AI融入各种类型的人类写作，对AI辅助透明度的呼声日益高涨。然而，如果透明度在不平等的环境中运作，并且某些身份群体为诚实付出了更高的代价，那么公开的负担就会变得不对称。本研究调查了AI披露声明如何影响对写作质量的感知，以及这些影响是否因作者的种族和性别而异。通过一项大规模对照实验，人类评分者（n = 1,970）和LLM评分者（n = 2,520）都评估了一篇人类撰写的新闻文章，同时系统地改变了披露声明和作者人口统计信息。这种方法反映了人类和算法决策现在如何影响机会的获取（例如，招聘、晋升）和社会认可（例如，内容推荐算法）。我们发现，人类和LLM评分者都持续惩罚已披露的AI使用。然而，只有LLM评分者表现出人口统计交互效应：当没有披露时，他们偏爱归属于女性或黑人作者的文章。但当AI辅助被揭示时，这些优势消失了。这些发现阐明了AI披露与作者身份之间复杂的关系，突出了机器和人类评估模式之间的差异。", "summary": "本研究通过大规模对照实验，探讨了AI披露声明和作者人口统计信息如何影响人类和LLM对写作质量的判断。结果显示，人类和LLM评分者均对披露的AI使用进行惩罚。值得注意的是，LLM评分者在未披露AI时，对女性和黑人作者的文章表现出偏好，但这种偏好在AI辅助被披露后消失。研究强调了AI披露与作者身份的复杂关系，并揭示了机器与人类评估模式之间的差异。", "keywords": "AI披露, 作者人口统计, 人类判断, AI判断, 公平性", "comments": "这项研究揭示了在AI辅助写作背景下，透明度可能带来的不公平后果，特别是对于特定人口群体。其创新之处在于同时考察了人类和LLM评分者的判断，并发现LLM在处理人口统计信息时表现出独特的偏见，这对于开发更公平的AI评估系统具有重要意义。研究结果提醒我们，在推广AI透明度的同时，需要警惕其可能加剧的偏见和不平等。"}}
{"id": "2507.01291", "title": "PanTS: The Pancreatic Tumor Segmentation Dataset", "authors": ["Wenxuan Li", "Xinze Zhou", "Qi Chen", "Tianyu Lin", "Pedro R. A. S. Bassi", "Szymon Plotka", "Jaroslaw B. Cwikla", "Xiaoxi Chen", "Chen Ye", "Zheren Zhu", "Kai Ding", "Heng Li", "Kang Wang", "Yang Yang", "Yucheng Tang", "Daguang Xu", "Alan L. Yuille", "Zongwei Zhou"], "summary": "PanTS is a large-scale, multi-institutional dataset curated to advance\nresearch in pancreatic CT analysis. It contains 36,390 CT scans from 145\nmedical centers, with expert-validated, voxel-wise annotations of over 993,000\nanatomical structures, covering pancreatic tumors, pancreas head, body, and\ntail, and 24 surrounding anatomical structures such as vascular/skeletal\nstructures and abdominal/thoracic organs. Each scan includes metadata such as\npatient age, sex, diagnosis, contrast phase, in-plane spacing, slice thickness,\netc. AI models trained on PanTS achieve significantly better performance in\npancreatic tumor detection, localization, and segmentation compared to those\ntrained on existing public datasets. Our analysis indicates that these gains\nare directly attributable to the 16x larger-scale tumor annotations and\nindirectly supported by the 24 additional surrounding anatomical structures. As\nthe largest and most comprehensive resource of its kind, PanTS offers a new\nbenchmark for developing and evaluating AI models in pancreatic CT analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01291v1", "categories": ["eess.IV", "cs.CV"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01291v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "PanTS: 胰腺肿瘤分割数据集", "tldr": "PanTS是一个大规模、多机构的胰腺CT分析数据集，显著提高了AI模型在胰腺肿瘤检测、定位和分割方面的性能，并提供了一个新的基准。", "motivation": "为了推动胰腺CT分析领域的研究，当前的公共数据集可能不足以支持高性能AI模型的开发和评估，因此需要一个更大规模、更全面的数据集。", "method": "该论文介绍了PanTS数据集的构建。PanTS是一个大规模、多机构的数据集，包含来自145个医疗中心的36,390张CT扫描，以及专家验证的超过993,000个体素级解剖结构标注，包括胰腺肿瘤、胰腺头、体、尾以及24个周围解剖结构。每张扫描还包含患者年龄、性别、诊断、造影剂期、平面内间距、切片厚度等元数据。研究人员将AI模型在PanTS上进行训练，并与在现有公共数据集上训练的模型进行了性能比较。", "result": "在PanTS上训练的AI模型在胰腺肿瘤检测、定位和分割方面取得了比在现有公共数据集上训练的模型显著更好的性能。分析表明，这些性能提升直接归因于16倍更大的肿瘤标注规模，并间接得益于24个额外的周围解剖结构。", "conclusion": "PanTS是同类数据集中规模最大、最全面的资源，为胰腺CT分析中AI模型的开发和评估提供了一个新的基准。", "translation": "PanTS是一个大规模、多机构的数据集，旨在推动胰腺CT分析研究。它包含来自145个医疗中心的36,390张CT扫描，以及专家验证的超过993,000个解剖结构的体素级标注，涵盖胰腺肿瘤、胰腺头、体、尾以及24个周围解剖结构，如血管/骨骼结构和腹部/胸部器官。每次扫描都包含元数据，例如患者年龄、性别、诊断、造影剂期、平面内间距、切片厚度等。在PanTS上训练的AI模型在胰腺肿瘤检测、定位和分割方面取得了比在现有公共数据集上训练的模型显著更好的性能。我们的分析表明，这些增益直接归因于16倍更大的肿瘤标注规模，并间接得益于24个额外的周围解剖结构。作为同类中规模最大、最全面的资源，PanTS为胰腺CT分析中AI模型的开发和评估提供了一个新的基准。", "summary": "PanTS是一个大规模、多机构的胰腺CT分析数据集，包含36,390张CT扫描，并拥有胰腺肿瘤及24个周围解剖结构的详尽专家验证标注。AI模型在PanTS上训练后，在胰腺肿瘤的检测、定位和分割方面表现出显著优于现有数据集的性能，这主要得益于其更大的肿瘤标注规模和全面的周围结构信息。PanTS为胰腺CT分析中的AI模型开发和评估设定了新的基准。", "keywords": "胰腺肿瘤, CT分析, 数据集, 分割, AI模型", "comments": "PanTS数据集的创新之处在于其前所未有的大规模和多机构性质，以及对胰腺肿瘤和周围解剖结构的详细、专家验证的体素级标注。这解决了现有数据集在规模和多样性上的局限性，直接推动了AI模型在胰腺CT分析性能上的显著提升，使其成为该领域一个重要的基准资源。"}}
{"id": "2507.01247", "title": "Tunnelling Through Time Series: A Probabilistic Visibility Graph for Local and Global Pattern Discovery", "authors": ["Roberto Sotero", "Jose Sanchez-Bornot"], "summary": "The growing availability of high-resolution, long-term time series data has\nhighlighted the need for methods capable of capturing both local and global\npatterns. To address this, we introduce the Probabilistic Visibility Graph\n(PVG), a novel approach inspired by the quantum tunnelling phenomenon. The PVG\nextends the classical Visibility Graph (VG) by introducing probabilistic\nconnections between time points that are obstructed in the VG due to\nintermediate values. We demonstrate the PVG's effectiveness in capturing\nlong-range dependencies through simulations of amplitude-modulated signals and\nanalysis of electrocorticography (ECoG) data under rest and anesthesia\nconditions. Key results show that the PVG presents distinct network properties\nbetween rest and anesthesia, with rest exhibiting stronger small-worldness and\nscale-free behavior, reflecting a hub-dominated, centralized connectivity\nstructure, compared to anesthesia. These findings highlight the PVG's potential\nfor analyzing complex signals with interacting temporal scales, offering new\ninsights into neural dynamics and other real-world phenomena.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01247v1", "categories": ["eess.SY", "cs.SY", "physics.data-an"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01247v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "隧道穿越时间序列：一种用于局部和全局模式发现的概率可见性图", "tldr": "引入了概率可见性图（PVG）来分析时间序列数据中的局部和全局模式，并展示了其在ECoG数据中区分不同脑状态的有效性。", "motivation": "现有方法难以同时捕捉高分辨率、长期时间序列数据中的局部和全局模式。", "method": "提出了概率可见性图（PVG），它扩展了经典可见性图（VG），通过引入概率连接来处理VG中被中间值遮挡的时间点之间的连接，灵感来源于量子隧穿现象。", "result": "PVG在振幅调制信号模拟和静息与麻醉状态下的脑电图（ECoG）数据分析中有效捕捉了长程依赖。关键结果显示，静息状态下的PVG网络特性与麻醉状态不同，静息状态表现出更强的“小世界”特性和无标度行为，反映了以中心枢纽为主导的集中连接结构。", "conclusion": "PVG在分析具有相互作用时间尺度的复杂信号方面具有潜力，为神经动力学和其他现实世界现象提供了新的见解。", "translation": "随着高分辨率、长期时间序列数据的日益普及，凸显了需要能够同时捕获局部和全局模式的方法。为了解决这个问题，我们引入了概率可见性图（PVG），这是一种受量子隧穿现象启发的新颖方法。PVG通过在经典可见性图（VG）中因中间值而被阻碍的时间点之间引入概率连接来扩展VG。我们通过振幅调制信号的模拟以及静息和麻醉条件下的脑电图（ECoG）数据分析，证明了PVG在捕获长程依赖方面的有效性。主要结果表明，PVG在静息和麻醉之间呈现出不同的网络特性，与麻醉相比，静息表现出更强的“小世界”特性和无标度行为，反映了一种以中心枢纽为主导的集中连接结构。这些发现突出了PVG在分析具有相互作用时间尺度的复杂信号方面的潜力，为神经动力学和其他现实世界现象提供了新的见解。", "summary": "本文提出了一种新颖的概率可见性图（PVG），旨在解决高分辨率时间序列数据中局部和全局模式捕获的挑战。PVG通过引入概率连接来增强传统可见性图，从而捕捉被遮挡的时间点之间的长程依赖关系。通过对模拟信号和ECoG数据的分析，研究表明PVG能有效区分静息和麻醉状态下的大脑网络特性，揭示静息状态下更强的中心化连接。这表明PVG在复杂信号分析和理解神经动力学方面具有广阔前景。", "keywords": "概率可见性图, 时间序列分析, 局部和全局模式, 脑电图, 神经网络动力学", "comments": "该研究通过引入概率连接，巧妙地扩展了传统可见性图，使其能够捕捉时间序列中的长程依赖，这是其主要创新点。PVG能够有效区分大脑的不同生理状态，这突显了其在神经科学研究中的重要应用潜力。该方法提供了一种新的视角来分析复杂的时间序列数据，有望在生物医学信号处理等领域发挥作用。"}}
{"id": "2507.01234", "title": "The Medium Is Not the Message: Deconfounding Text Embeddings via Linear Concept Erasure", "authors": ["Yu Fan", "Yang Tian", "Shauli Ravfogel", "Mrinmaya Sachan", "Elliott Ash", "Alexander Hoyle"], "summary": "Embedding-based similarity metrics between text sequences can be influenced\nnot just by the content dimensions we most care about, but can also be biased\nby spurious attributes like the text's source or language. These document\nconfounders cause problems for many applications, but especially those that\nneed to pool texts from different corpora. This paper shows that a debiasing\nalgorithm that removes information about observed confounders from the encoder\nrepresentations substantially reduces these biases at a minimal computational\ncost. Document similarity and clustering metrics improve across every embedding\nvariant and task we evaluate -- often dramatically. Interestingly, performance\non out-of-distribution benchmarks is not impacted, indicating that the\nembeddings are not otherwise degraded.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01234v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01234v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "媒介并非信息：通过线性概念擦除解混文本嵌入", "tldr": "文本嵌入可能受到虚假属性的偏见；本文展示了一种去偏算法，该算法能显著减少混淆信息，从而改善相似性和聚类性能，且不影响分布外基准的表现。", "motivation": "基于嵌入的文本相似性度量受到文本来源或语言等虚假属性的偏见影响，这给需要整合不同语料库文本的应用带来了问题。", "method": "通过线性概念擦除，从编码器表示中移除观测到的混淆因素信息的去偏算法。", "result": "去偏算法以最小的计算成本显著减少了偏见。文档相似性和聚类指标在所有评估的嵌入变体和任务中均有显著改善。对分布外基准的性能没有影响。", "conclusion": "从文本嵌入中移除混淆信息能够有效减少偏见，改善相似性和聚类指标，同时不影响整体性能。", "translation": "文本序列之间基于嵌入的相似性度量不仅受我们最关心的内容维度影响，还可能受到诸如文本来源或语言等虚假属性的偏见。这些文档混淆因素给许多应用带来了问题，特别是那些需要汇集不同语料库文本的应用。本文展示了一种去偏算法，该算法能以最小的计算成本从编码器表示中移除观测到的混淆因素信息，从而显著减少这些偏见。在我们评估的每种嵌入变体和任务中，文档相似性和聚类指标都得到了改善——通常是显著的改善。有趣的是，对分布外基准的性能没有影响，这表明嵌入没有因此而退化。", "summary": "本文探讨了文本嵌入中由虚假属性（如来源或语言）引起的偏见问题，该问题会影响相似性度量和多源文本整合的应用。研究提出了一种去偏算法，通过线性概念擦除从编码器表示中移除混淆信息。实验证明，该方法能以极低的计算成本显著提升文档相似性和聚类指标，且不损害嵌入在分布外任务上的性能。", "keywords": "文本嵌入, 去偏, 混淆因素, 概念擦除, 文档相似性", "comments": "该论文提出了一种有效且计算高效的方法来缓解文本嵌入中由虚假属性引起的偏见。其创新之处在于证明了有针对性的概念擦除可以显著提高嵌入在相似性和聚类等任务中的实用性，同时不损害泛化能力，这对于处理多样化数据源的稳健自然语言处理应用至关重要。"}}
{"id": "2507.01631", "title": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "authors": ["Camille Billouard", "Dawa Derksen", "Alexandre Constantin", "Bruno Vallet"], "summary": "Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D\nreconstruction from multiview satellite imagery. However, state-of-the-art NeRF\nmethods are typically constrained to small scenes due to the memory footprint\nduring training, which we study in this paper. Previous work on large-scale\nNeRFs palliate this by dividing the scene into NeRFs. This paper introduces\nSnake-NeRF, a framework that scales to large scenes. Our out-of-core method\neliminates the need to load all images and networks simultaneously, and\noperates on a single device. We achieve this by dividing the region of interest\ninto NeRFs that 3D tile without overlap. Importantly, we crop the images with\noverlap to ensure each NeRFs is trained with all the necessary pixels. We\nintroduce a novel $2\\times 2$ 3D tile progression strategy and segmented\nsampler, which together prevent 3D reconstruction errors along the tile edges.\nOur experiments conclude that large satellite images can effectively be\nprocessed with linear time complexity, on a single GPU, and without compromise\nin quality.", "comment": "Accepted at ICCV 2025 Workshop 3D-VAST (From street to space: 3D\n  Vision Across Altitudes). Version before camera ready. Our code will be made\n  public after the conference", "pdf_url": "http://arxiv.org/pdf/2507.01631v1", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01631v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "分瓦与滑动：一种将NeRF从局部扩展到全局三维地球观测的新框架", "tldr": "本文提出了Snake-NeRF，一个用于将神经辐射场（NeRF）从局部扩展到全局三维地球观测的新框架。它通过离核方法将场景划分为无重叠的3D瓦片，同时图像裁剪时保留重叠，并引入新的瓦片策略和采样器来防止边缘误差，从而在单GPU上以线性时间复杂度处理大型卫星图像且不牺牲质量。", "motivation": "现有的神经辐射场（NeRF）方法在处理大型场景时受到内存占用过大的限制，这使得它们难以应用于大规模三维地球观测。", "method": "本文提出了Snake-NeRF框架，它是一种离核（out-of-core）方法，无需同时加载所有图像和网络，可在单个设备上运行。该方法通过将感兴趣区域划分为无重叠的3D NeRF瓦片来实现。为了确保每个NeRF都使用所有必要的像素进行训练，图像被裁剪时保留重叠。此外，引入了一种新颖的2x2 3D瓦片渐进策略和分段采样器，以防止沿瓦片边缘出现三维重建错误。", "result": "实验结果表明，大型卫星图像可以在单个GPU上以线性时间复杂度有效处理，且不影响质量。", "conclusion": "Snake-NeRF框架能够有效处理大型卫星图像，实现大规模三维重建，同时保持高效性、在单个GPU上运行且不牺牲质量。", "translation": "神经辐射场（NeRF）最近已成为从多视图卫星图像进行三维重建的一种范式。然而，最先进的NeRF方法通常受限于小场景，原因在于训练期间的内存占用，这也是本文研究的重点。以往关于大规模NeRF的工作通过将场景划分为多个NeRF来缓解这一问题。本文引入了Snake-NeRF，一个可以扩展到大型场景的框架。我们的离核方法消除了同时加载所有图像和网络的需要，并且可以在单个设备上运行。我们通过将感兴趣区域划分为无重叠的3D瓦片NeRF来实现这一点。重要的是，我们对图像进行重叠裁剪，以确保每个NeRF都使用所有必要的像素进行训练。我们引入了一种新颖的2x2 3D瓦片渐进策略和分段采样器，它们共同防止了沿瓦片边缘的三维重建错误。我们的实验得出结论，大型卫星图像可以在单个GPU上以线性时间复杂度有效处理，且不影响质量。", "summary": "本文提出了一种名为Snake-NeRF的新型离核框架，旨在解决神经辐射场（NeRF）在处理大规模三维地球观测数据时面临的内存限制问题。该框架通过将感兴趣区域划分为无重叠的3D NeRF瓦片来扩展到大型场景，并通过重叠裁剪图像以确保数据完整性。Snake-NeRF还引入了独特的2x2 3D瓦片渐进策略和分段采样器，以有效避免瓦片边缘的重建误差。实验证明，该方法能够在单个GPU上以线性时间复杂度高效处理大型卫星图像，同时保持高质量的重建效果。", "keywords": "NeRF, 三维重建, 卫星图像, 大规模, 离核", "comments": "本文通过引入离核的Snake-NeRF框架，为NeRF在大规模三维地球观测中的应用提供了重要的创新解决方案。其核心创新在于通过智能的3D瓦片划分、重叠图像裁剪以及专门的瓦片边缘误差处理策略，有效解决了NeRF的内存瓶颈问题。该方法能够在单GPU上实现线性时间复杂度的处理，并在不牺牲质量的前提下处理大型卫星图像，这对于推动NeRF在实际大规模应用中的落地具有重要意义。"}}
{"id": "2507.01402", "title": "Asymptotic Preserving and Accurate scheme for Multiscale Poisson-Nernst-Planck (MPNP) system", "authors": ["Clarissa Astuto", "Giovanni Russo"], "summary": "In this paper, we propose and validate a two-species Multiscale model for a\nPoisson-Nernst-Planck (PNP) system, focusing on the correlated motion of\npositive and negative ions under the influence of a trap. Specifically, we aim\nto model surface traps whose attraction range, of length delta, is much smaller\nthen the scale of the problem. The physical setup we refer to is an anchored\ngas drop (bubble) surrounded by a diffusive flow of charged surfactants (ions).\nWhen the diffusing surfactants reach the surface of the trap, the anions are\nadsorbed. As in our previous works [11,6,9,4], the effect of the attractive\npotential is replaced by a suitable boundary condition derived by mass\nconservation and asymptotic analysis. The novelty of this work is the extension\nof the model proposed in [11], now incorporating the influence of both carriers\n- positive and negative ions - simultaneously, which is often neglected in\ntraditional approaches that treat ion species independently. In the second part\nof the paper, we address the treatment of the Coulomb interaction between\ncarriers. When the Debye length lambda_D (proportional to a small parameter\nepsilon) is very small, one can adopt the so-called Quasi-Neutral limit, which\nsignificantly simplifies the system, reducing it to a diffusion equation for a\nsingle carriers with effective diffusion coefficient [36,53]. This approach,\nwhile simplifying the mathematical model, does not capture the effects of non\nnegligible values of epsilon. When the Debye length is small but not\nnegligible, it may be very expensive to capture the small deviation from the\nQuasi-Neutral limit by standard methods in the literature. [...]", "comment": "41 pages 19 figures 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.01402v1", "categories": ["math.NA", "cs.NA", "math-ph", "math.MP", "65M06 65M55 76D07 76M20 76R50"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01402v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "多尺度泊松-能斯特-普朗克 (MPNP) 系统的渐近守恒和精确方案", "tldr": "提出并验证了一种新的两物种多尺度泊松-能斯特-普朗克 (PNP) 模型，用于模拟陷阱中正负离子的相关运动，并解决了库仑相互作用在小但不可忽略的德拜长度下的处理问题。", "motivation": "传统方法在处理离子种类时常独立对待，忽略了正负离子同时存在的影响。此外，当德拜长度（ε）小但不可忽略时，标准方法难以捕捉与准中性极限的微小偏差，导致计算成本高昂。", "method": "提出并验证了一个两物种多尺度泊松-能斯特-普朗克 (PNP) 模型，关注陷阱中正负离子的相关运动。通过质量守恒和渐近分析推导的边界条件来替代吸引势的影响。该模型扩展了现有工作，同时包含了正负载流子（离子）的影响。论文的第二部分讨论了载流子之间库仑相互作用的处理，特别是在德拜长度小但不可忽略的情况下。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "在本文中，我们提出并验证了一个用于泊松-能斯特-普朗克 (PNP) 系统的两物种多尺度模型，重点关注陷阱影响下正负离子的相关运动。具体来说，我们旨在模拟表面陷阱，其吸引范围（长度 delta）远小于问题尺度。我们所指的物理设置是一个被带电表面活性剂（离子）扩散流包围的锚定气滴（气泡）。当扩散的表面活性剂到达陷阱表面时，阴离子被吸附。正如我们之前的研究 [11,6,9,4] 中，吸引势的影响通过质量守恒和渐近分析推导的合适边界条件来替代。这项工作的新颖之处在于扩展了 [11] 中提出的模型，现在同时包含了正负载流子（离子）的影响，这在传统方法中通常被忽略，因为传统方法独立处理离子种类。在论文的第二部分，我们讨论了载流子之间库仑相互作用的处理。当德拜长度 lambda_D（与小参数 epsilon 成比例）非常小时，可以采用所谓的准中性极限，这大大简化了系统，将其简化为具有有效扩散系数的单一载流子的扩散方程 [36,53]。虽然这种方法简化了数学模型，但它无法捕捉 epsilon 值不可忽略时的影响。当德拜长度很小但不可忽略时，通过文献中的标准方法捕捉与准中性极限的微小偏差可能非常昂贵。", "summary": "本文提出并验证了一个新颖的两物种多尺度泊松-能斯特-普朗克 (PNP) 模型，用于描述陷阱中正负离子的相关运动。该模型通过渐近分析和边界条件处理陷阱吸引效应，并创新性地同时考虑正负载流子，克服了传统方法独立处理离子的问题。此外，文章还探讨了在德拜长度小但不可忽略时，如何高效处理载流子间库仑相互作用的挑战，旨在提供比传统准中性极限方法更精确且计算成本更低的方案。", "keywords": "多尺度模型, 泊松-能斯特-普朗克, 渐近守恒, 离子运动, 德拜长度", "comments": "创新点在于该模型首次同时考虑了正负离子的相关运动，弥补了传统PNP模型将离子独立处理的不足。此外，论文试图解决在德拜长度非极端小情况下的计算效率和精度问题，这对于模拟更广泛的电解质和生物物理现象具有重要的理论和实际意义。"}}
{"id": "2507.01348", "title": "SpeechAccentLLM: A Unified Framework for Foreign Accent Conversion and Text to Speech", "authors": ["Cheng Zhuangfei", "Zhang Guangyan", "Tu Zehai", "Song Yangyang", "Mao Shuiyang", "Jiao Xiaoqi", "Li Jingyu", "Guo Yiwen", "Wu Jiasong"], "summary": "Foreign accent conversion (FAC) in speech processing remains a challenging\ntask. Building on the remarkable success of large language models (LLMs) in\nText-to-Speech (TTS) tasks, this study investigates the adaptation of LLM-based\ntechniques for FAC, which we term SpeechAccentLLM. At the core of this\nframework, we introduce SpeechCodeVAE, the first model to integrate\nconnectionist temporal classification (CTC) directly into codebook\ndiscretization for speech content tokenization. This novel architecture\ngenerates tokens with a unique \"locality\" property, as validated by experiments\ndemonstrating optimal trade-offs among content faithfulness, temporal\ncoherence, and structural recoverability. Then, to address data scarcity for\nthe FAC module, we adopted a multitask learning strategy that jointly trains\nthe FAC and TTS modules. Beyond mitigating data limitations, this approach\nyielded accelerated convergence and superior speech quality compared to\nstandalone FAC training. Moreover, leveraging the salient properties of our\ndiscrete speech representations, we introduce SpeechRestorer, a postprocessing\narchitecture designed to refine LLM-generated outputs. This module effectively\nmitigates stochastic errors prevalent in LLM inference pipelines while\nenhancing prosodic continuity, as validated by ablation experiments.", "comment": "10 pages, includes references, 4 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.01348v1", "categories": ["eess.AS", "cs.SD", "I.2.7"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01348v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "SpeechAccentLLM：一个统一的外国口音转换与文本到语音框架", "tldr": "本文提出了SpeechAccentLLM，一个基于LLM的统一框架，用于外国口音转换（FAC）和文本到语音（TTS），引入了SpeechCodeVAE进行语音内容标记化，并采用多任务学习解决数据稀缺问题，以及SpeechRestorer进行后处理。", "motivation": "语音处理中的外国口音转换（FAC）仍然是一项具有挑战性的任务。本研究旨在借鉴大型语言模型（LLM）在文本到语音（TTS）任务中取得的显著成功，将其技术应用于FAC。", "method": "该框架名为SpeechAccentLLM。核心是引入了SpeechCodeVAE，这是第一个将连接主义时间分类（CTC）直接集成到码本离散化中用于语音内容标记化的模型，生成具有“局部性”属性的标记。为解决FAC模块的数据稀缺问题，采用了联合训练FAC和TTS模块的多任务学习策略。此外，引入了SpeechRestorer作为后处理架构，用于优化LLM生成的输出。", "result": "SpeechCodeVAE的实验证明其在内容保真度、时间连贯性和结构可恢复性之间实现了最佳权衡。多任务学习策略与独立的FAC训练相比，实现了更快的收敛速度和更卓越的语音质量。SpeechRestorer有效减轻了LLM推理管道中普遍存在的随机误差，同时增强了韵律连续性，这已通过消融实验得到验证。", "conclusion": "本文提出了SpeechAccentLLM，一个用于外国口音转换和文本到语音的统一框架，该框架利用了基于LLM的技术。它引入了SpeechCodeVAE用于鲁棒的语音内容标记化，采用多任务学习策略以提高数据效率和语音质量，并引入了SpeechRestorer模块以优化LLM生成的输出，从而共同推动了外国口音转换和文本到语音生成技术的发展。", "translation": "语音处理中的外国口音转换 (FAC) 仍然是一项具有挑战性的任务。本研究借鉴大型语言模型 (LLM) 在文本到语音 (TTS) 任务中取得的显著成功，探讨了将基于 LLM 的技术应用于 FAC 的可能性，我们将其命名为 SpeechAccentLLM。该框架的核心是引入了 SpeechCodeVAE，这是第一个将连接主义时间分类 (CTC) 直接集成到码本离散化中用于语音内容标记化的模型。这种新颖的架构生成具有独特“局部性”属性的标记，实验证明其在内容保真度、时间连贯性和结构可恢复性之间实现了最佳权衡。然后，为了解决 FAC 模块的数据稀缺问题，我们采用了多任务学习策略，联合训练 FAC 和 TTS 模块。除了缓解数据限制外，与独立的 FAC 训练相比，这种方法还带来了更快的收敛速度和卓越的语音质量。此外，利用我们离散语音表示的显著特性，我们引入了 SpeechRestorer，这是一种旨在优化 LLM 生成输出的后处理架构。经验证，该模块有效减轻了 LLM 推理管道中普遍存在的随机误差，同时增强了韵律连续性，这已通过消融实验得到验证。", "summary": "本文提出了SpeechAccentLLM，一个基于LLM的统一框架，用于外国口音转换（FAC）和文本到语音（TTS）。该框架引入了SpeechCodeVAE，通过将CTC直接集成到码本离散化中实现语音内容标记化，生成具有“局部性”的标记。为解决FAC数据稀缺问题，采用了多任务学习策略，联合训练FAC和TTS模块，从而加速收敛并提高语音质量。此外，还引入了SpeechRestorer作为后处理模块，以优化LLM输出，有效减轻随机误差并增强韵律连续性。", "keywords": "外国口音转换, 文本到语音, 大型语言模型, 语音标记化, 多任务学习", "comments": "本文通过将LLM技术从TTS领域成功迁移到具有挑战性的外国口音转换任务，展现了创新性。SpeechCodeVAE的引入及其独特的“局部性”语音标记属性是显著贡献。多任务学习策略为数据稀缺提供了实用的解决方案，而SpeechRestorer则解决了LLM输出中随机误差的关键问题，提升了系统的整体质量和鲁棒性。"}}
{"id": "2507.01060", "title": "Optimizing Conversational Product Recommendation via Reinforcement Learning", "authors": ["Kang Liu"], "summary": "We propose a reinforcement learning-based approach to optimize conversational\nstrategies for product recommendation across diverse industries. As\norganizations increasingly adopt intelligent agents to support sales and\nservice operations, the effectiveness of a conversation hinges not only on what\nis recommended but how and when recommendations are delivered. We explore a\nmethodology where agentic systems learn optimal dialogue policies through\nfeedback-driven reinforcement learning. By mining aggregate behavioral patterns\nand conversion outcomes, our approach enables agents to refine talk tracks that\ndrive higher engagement and product uptake, while adhering to contextual and\nregulatory constraints. We outline the conceptual framework, highlight key\ninnovations, and discuss the implications for scalable, personalized\nrecommendation in enterprise environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01060v1", "categories": ["cs.IR", "cs.LG"], "cate": "cs.IR", "url": "http://arxiv.org/abs/2507.01060v1", "date": "2025-06-30", "updated": "2025-06-30", "AI": {"title_translation": "采用强化学习优化会话式产品推荐", "tldr": "本文提出一种基于强化学习的方法，用于优化跨行业会话式产品推荐的策略，以提高用户参与度和产品转化率。", "motivation": "随着组织越来越多地采用智能代理来支持销售和服务运营，会话的有效性不仅取决于推荐了什么，还取决于如何以及何时交付推荐。因此，需要优化会话策略以提高推荐效果。", "method": "本文提出一种基于强化学习的方法，通过挖掘聚合行为模式和转化结果，使代理系统学习最优对话策略。该方法通过反馈驱动的强化学习来优化代理的会话路径，同时遵守上下文和监管约束。", "result": "该方法使代理能够优化会话路径，从而提高用户参与度和产品采纳率。", "conclusion": "本文概述了概念框架，强调了关键创新，并讨论了其对企业环境中可扩展、个性化推荐的意义。", "translation": "我们提出了一种基于强化学习的方法，用于优化跨行业会话式产品推荐的策略。随着组织越来越多地采用智能代理来支持销售和服务运营，会话的有效性不仅取决于推荐了什么，还取决于如何以及何时交付推荐。我们探索了一种方法，其中代理系统通过反馈驱动的强化学习来学习最优对话策略。通过挖掘聚合行为模式和转化结果，我们的方法使代理能够优化会话路径，从而提高用户参与度和产品采纳率，同时遵守上下文和监管约束。我们概述了概念框架，强调了关键创新，并讨论了其对企业环境中可扩展、个性化推荐的意义。", "summary": "本文提出了一种基于强化学习的新方法，旨在优化不同行业的产品推荐会话策略。该方法通过分析用户行为模式和转化结果，使智能代理能够学习并改进对话策略，从而提高用户参与度及产品采纳率。研究强调了推荐内容、方式和时机的重要性，并探讨了该框架在企业环境中实现可扩展和个性化推荐的潜力。", "keywords": "强化学习, 会话式推荐, 产品推荐, 对话策略, 智能代理", "comments": "这篇论文的创新点在于将强化学习应用于优化会话式产品推荐的对话策略，超越了仅仅推荐内容本身，更关注推荐的时机和方式。这对于提升智能销售和服务代理的实际效果具有重要意义，有助于提高用户体验和商业转化率。其强调了从聚合行为模式中学习的能力，使其具备一定的泛化潜力。"}}
{"id": "2507.01040", "title": "Fast Clifford Neural Layers", "authors": ["Tianxiang Xia", "Max Neuwinger", "Lin Xiao"], "summary": "Clifford Neural Layers improve PDE modeling by introducing Clifford Algebra\ninto neural networks. In this project we focus on optimizing the inference of\n2/3D Clifford convolutional layers and multivector activation layers for one\ncore CPU performance.\n  Overall, by testing on a real network block involving Clifford convolutional\nlayers and multivector activation layers, we observe that our implementation is\n30% faster than standard PyTorch implementation in relatively large data +\nnetwork size (>L2 cache).\n  We open source our code base at\nhttps://github.com/egretwAlker/c-opt-clifford-layers", "comment": "7 pages content-wise", "pdf_url": "http://arxiv.org/pdf/2507.01040v1", "categories": ["cs.LG", "cs.AI", "cs.NE", "cs.PF"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01040v1", "date": "2025-06-22", "updated": "2025-06-22", "AI": {"title_translation": "快速Clifford神经网络层", "tldr": "本文优化了Clifford神经网络层的推理性能，使其在CPU上比标准PyTorch实现快30%。", "motivation": "Clifford神经网络层通过引入Clifford代数改进了偏微分方程（PDE）建模。本文的动机是优化2/3D Clifford卷积层和多向量激活层在单核CPU上的推理性能。", "method": "通过对Clifford卷积层和多向量激活层进行优化，特别关注单核CPU性能，并与标准PyTorch实现进行比较。", "result": "在涉及Clifford卷积层和多向量激活层的实际网络块上进行测试，发现在相对较大的数据和网络规模（大于L2缓存）下，其实现比标准PyTorch实现快30%。", "conclusion": "通过优化Clifford神经网络层的推理，显著提升了其在CPU上的性能。", "translation": "Clifford神经网络层通过将Clifford代数引入神经网络中，改进了偏微分方程（PDE）建模。本项目专注于优化2/3D Clifford卷积层和多向量激活层在单核CPU上的推理性能。\n总的来说，通过在一个包含Clifford卷积层和多向量激活层的真实网络块上进行测试，我们观察到在相对较大的数据和网络规模（>L2缓存）下，我们的实现比标准的PyTorch实现快30%。\n我们已在https://github.com/egretwAlker/c-opt-clifford-layers开源了我们的代码库。", "summary": "本研究致力于优化Clifford神经网络层的推理性能，特别是在单核CPU上运行的2/3D Clifford卷积层和多向量激活层。实验结果表明，在处理大型数据集和网络时，其优化实现比标准的PyTorch实现速度提升了30%。项目代码已开源。", "keywords": "Clifford神经网络层, 性能优化, CPU推理, 深度学习, PyTorch", "comments": "本文的创新点在于专注于优化Clifford神经网络层在CPU上的推理性能，这对于在资源受限环境下部署此类网络具有重要意义。性能提升30%是一个显著的改进，且开源代码有利于社区的进一步研究和应用。"}}
{"id": "2507.01264", "title": "LLM-based Realistic Safety-Critical Driving Video Generation", "authors": ["Yongjie Fu", "Ruijian Zha", "Pei Tian", "Xuan Di"], "summary": "Designing diverse and safety-critical driving scenarios is essential for\nevaluating autonomous driving systems. In this paper, we propose a novel\nframework that leverages Large Language Models (LLMs) for few-shot code\ngeneration to automatically synthesize driving scenarios within the CARLA\nsimulator, which has flexibility in scenario scripting, efficient code-based\ncontrol of traffic participants, and enforcement of realistic physical\ndynamics. Given a few example prompts and code samples, the LLM generates\nsafety-critical scenario scripts that specify the behavior and placement of\ntraffic participants, with a particular focus on collision events. To bridge\nthe gap between simulation and real-world appearance, we integrate a video\ngeneration pipeline using Cosmos-Transfer1 with ControlNet, which converts\nrendered scenes into realistic driving videos. Our approach enables\ncontrollable scenario generation and facilitates the creation of rare but\ncritical edge cases, such as pedestrian crossings under occlusion or sudden\nvehicle cut-ins. Experimental results demonstrate the effectiveness of our\nmethod in generating a wide range of realistic, diverse, and safety-critical\nscenarios, offering a promising tool for simulation-based testing of autonomous\nvehicles.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01264v1", "categories": ["cs.RO", "cs.AI"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01264v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于LLM的真实安全关键驾驶视频生成", "tldr": "本文提出一个利用LLM进行少样本代码生成的新框架，可在CARLA模拟器中自动合成安全关键驾驶场景，并通过视频生成管道转换为真实驾驶视频，有效支持自动驾驶系统评估。", "motivation": "为评估自动驾驶系统，设计多样化且安全关键的驾驶场景至关重要。", "method": "本文提出一个新颖的框架，利用大型语言模型（LLMs）进行少样本代码生成，在CARLA模拟器中自动合成驾驶场景脚本，特别关注碰撞事件。为弥合模拟与真实世界外观之间的差距，该方法集成了使用Cosmos-Transfer1和ControlNet的视频生成管道，将渲染场景转换为真实的驾驶视频。", "result": "实验结果表明，该方法在生成广泛、真实、多样化和安全关键的场景方面是有效的。", "conclusion": "该方法为自动驾驶车辆的模拟测试提供了一个有前景的工具。", "translation": "设计多样化且安全关键的驾驶场景对于评估自动驾驶系统至关重要。本文提出一个新颖的框架，利用大型语言模型（LLMs）进行少样本代码生成，以在CARLA模拟器中自动合成驾驶场景，CARLA模拟器在场景脚本编写方面具有灵活性，能够高效地通过代码控制交通参与者，并强制执行真实的物理动力学。给定少量示例提示和代码样本，LLM生成安全关键的场景脚本，指定交通参与者的行为和位置，特别关注碰撞事件。为了弥合模拟与真实世界外观之间的差距，我们集成了使用Cosmos-Transfer1和ControlNet的视频生成管道，将渲染场景转换为真实的驾驶视频。我们的方法实现了可控的场景生成，并促进了罕见但关键的边缘情况的创建，例如遮挡下的行人穿越或突然的车辆切入。实验结果表明，我们的方法在生成广泛的真实、多样化和安全关键场景方面是有效的，为自动驾驶车辆的模拟测试提供了一个有前景的工具。", "summary": "本文提出一个基于LLM的框架，利用其少样本代码生成能力，在CARLA模拟器中自动合成多样化且安全关键的驾驶场景脚本，尤其关注碰撞事件。为提升真实感，该框架还结合了Cosmos-Transfer1与ControlNet的视频生成管道，将模拟场景转换为高保真真实驾驶视频。该方法能有效生成罕见但关键的边缘情况，为自动驾驶系统的模拟评估提供了有前景的工具。", "keywords": "LLM, 驾驶场景生成, CARLA, 自动驾驶, 安全关键", "comments": "该论文创新性地结合了LLM的代码生成能力和CARLA模拟器，实现了高效且可控的安全关键驾驶场景合成。同时，通过引入视频生成管道，有效弥合了模拟与现实外观之间的差距，增强了生成场景的实用性。这为自动驾驶系统的测试和验证提供了一个强大且灵活的新范式，尤其在生成边缘案例方面具有显著优势。"}}
{"id": "2507.01446", "title": "Using multi-agent architecture to mitigate the risk of LLM hallucinations", "authors": ["Abd Elrahman Amer", "Magdi Amer"], "summary": "Improving customer service quality and response time are critical factors for\nmaintaining customer loyalty and increasing a company's market share. While\nadopting emerging technologies such as Large Language Models (LLMs) is becoming\na necessity to achieve these goals, the risk of hallucination remains a major\nchallenge. In this paper, we present a multi-agent system to handle customer\nrequests sent via SMS. This system integrates LLM based agents with fuzzy logic\nto mitigate hallucination risks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01446v1", "categories": ["cs.AI"], "cate": "cs.AI", "url": "http://arxiv.org/abs/2507.01446v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "使用多智能体架构减轻大型语言模型幻觉的风险", "tldr": "本文提出一种结合LLM智能体和模糊逻辑的多智能体系统，以减轻客户服务中LLM幻觉的风险。", "motivation": "提高客户服务质量和响应时间对维持客户忠诚度和增加市场份额至关重要。虽然采用大型语言模型（LLMs）是实现这些目标的必要手段，但幻觉风险仍然是一个主要挑战。", "method": "本文提出一个多智能体系统来处理通过短信发送的客户请求。该系统将基于LLM的智能体与模糊逻辑相结合，以减轻幻觉风险。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "提高客户服务质量和响应时间是维持客户忠诚度和增加公司市场份额的关键因素。尽管采用大型语言模型（LLMs）等新兴技术正成为实现这些目标的必要手段，但幻觉风险仍然是一个主要挑战。在本文中，我们提出了一个多智能体系统来处理通过短信发送的客户请求。该系统集成了基于LLM的智能体与模糊逻辑，以减轻幻觉风险。", "summary": "本文提出了一种多智能体系统，旨在通过结合大型语言模型（LLMs）智能体和模糊逻辑来处理客户短信请求，从而减轻LLMs在客户服务中可能产生的幻觉风险，以提升客户服务质量和响应时间。", "keywords": "多智能体系统, LLM幻觉, 模糊逻辑, 客户服务, 风险缓解", "comments": "该论文提出了一种利用多智能体架构结合模糊逻辑来解决LLM幻觉问题的创新方法，这对于提升客户服务中LLM应用的可靠性具有重要意义。其创新点在于将模糊逻辑引入LLM代理，以期有效缓解幻觉问题。"}}
{"id": "2507.01827", "title": "APRMCTS: Improving LLM-based Automated Program Repair with Iterative Tree Search", "authors": ["Haichuan Hu", "Congqing He", "Hao Zhang", "Xiaochen Xie", "Quanjun Zhang"], "summary": "Automated Program Repair (APR) attempts to fix software bugs without human\nintervention, which plays a crucial role in software development and\nmaintenance. Recently, with the advances in Large Language Models (LLMs), a\nrapidly increasing number of APR techniques have been proposed with remarkable\nperformance. However, existing LLM-based APR techniques typically adopt\ntrial-and-error strategies, which suffer from two major drawbacks: (1)\ninherently limited patch effectiveness due to local exploration, and (2) low\nsearch efficiency due to redundant exploration. In this paper, we propose\nAPRMCTS, which uses iterative tree search to improve LLM-based APR. APRMCTS\nincorporates Monte Carlo Tree Search (MCTS) into patch searching by performing\na global evaluation of the explored patches and selecting the most promising\none for subsequent refinement and generation. APRMCTS effectively resolves the\nproblems of falling into local optima and thus helps improve the efficiency of\npatch searching. Our experiments on 835 bugs from Defects4J demonstrate that,\nwhen integrated with GPT-3.5, APRMCTS can fix a total of 201 bugs, which\noutperforms all state-of-the-art baselines. Besides, APRMCTS helps GPT-4o-mini,\nGPT-3.5, Yi-Coder-9B, and Qwen2.5-Coder-7B to fix 30, 27, 37, and 28 more bugs,\nrespectively. More importantly, APRMCTS boasts a significant performance\nadvantage while employing small patch size (16 and 32), notably fewer than the\n500 and 10,000 patches adopted in previous studies. In terms of cost, compared\nto existing state-of-the-art LLM-based APR methods, APRMCTS has time and\nmonetary costs of less than 20% and 50%, respectively. Our extensive study\ndemonstrates that APRMCTS exhibits good effectiveness and efficiency, with\nparticular advantages in addressing complex bugs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01827v1", "categories": ["cs.SE"], "cate": "cs.SE", "url": "http://arxiv.org/abs/2507.01827v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "APRMCTS：通过迭代树搜索改进基于LLM的自动化程序修复", "tldr": "APRMCTS提出了一种将蒙特卡洛树搜索（MCTS）应用于LLM驱动的自动程序修复（APR）的方法，通过迭代树搜索解决现有方法的局部探索和低效率问题，实验证明其在修复复杂bug方面表现出更高的有效性和效率，并显著降低了成本。", "motivation": "现有的基于大型语言模型（LLM）的自动化程序修复（APR）技术通常采用试错策略，但存在两个主要缺点：(1) 由于局部探索导致补丁有效性有限；(2) 由于冗余探索导致搜索效率低下。", "method": "本文提出了APRMCTS，它通过迭代树搜索来改进基于LLM的APR。APRMCTS将蒙特卡洛树搜索（MCTS）融入到补丁搜索中，对已探索的补丁进行全局评估，并选择最有希望的补丁进行后续的细化和生成。APRMCTS有效地解决了陷入局部最优的问题。", "result": "在Defects4J的835个bug上进行实验表明，当与GPT-3.5集成时，APRMCTS总共可以修复201个bug，优于所有最先进的基线。此外，APRMCTS帮助GPT-4o-mini、GPT-3.5、Yi-Coder-9B和Qwen2.5-Coder-7B分别额外修复了30、27、37和28个bug。APRMCTS在补丁数量较少（16和32）的情况下，性能优势显著，远少于先前研究中采用的500和10,000个补丁。在成本方面，与现有最先进的基于LLM的APR方法相比，APRMCTS的时间和金钱成本分别不到20%和50%。", "conclusion": "APRMCTS展示了良好的有效性和效率，在解决复杂bug方面具有特殊优势。", "translation": "自动化程序修复（APR）旨在无需人工干预即可修复软件错误，这在软件开发和维护中扮演着至关重要的角色。最近，随着大型语言模型（LLM）的进步，大量基于LLM的APR技术被提出，并取得了显著的性能。然而，现有的基于LLM的APR技术通常采用试错策略，这存在两个主要缺点：(1) 由于局部探索导致补丁有效性固有地有限；(2) 由于冗余探索导致搜索效率低下。在本文中，我们提出了APRMCTS，它使用迭代树搜索来改进基于LLM的APR。APRMCTS通过对已探索的补丁进行全局评估并选择最有希望的补丁进行后续细化和生成，将蒙特卡洛树搜索（MCTS）融入到补丁搜索中。APRMCTS有效地解决了陷入局部最优的问题，从而有助于提高补丁搜索的效率。我们在Defects4J的835个bug上进行的实验表明，当与GPT-3.5集成时，APRMCTS总共可以修复201个bug，这优于所有最先进的基线。此外，APRMCTS帮助GPT-4o-mini、GPT-3.5、Yi-Coder-9B和Qwen2.5-Coder-7B分别额外修复了30、27、37和28个bug。更重要的是，APRMCTS在采用小补丁数量（16和32）的情况下，具有显著的性能优势，明显少于先前研究中采用的500和10,000个补丁。在成本方面，与现有最先进的基于LLM的APR方法相比，APRMCTS的时间和金钱成本分别不到20%和50%。我们广泛的研究表明，APRMCTS表现出良好的有效性和效率，在解决复杂bug方面具有特殊优势。", "summary": "本文提出了APRMCTS，一种利用迭代树搜索改进基于LLM的自动化程序修复（APR）的新方法。针对现有LLM-based APR方法存在的局部探索和低效问题，APRMCTS将蒙特卡洛树搜索（MCTS）引入补丁搜索过程，通过全局评估和选择最优补丁进行细化。实验结果表明，APRMCTS在Defects4J数据集上表现出卓越的性能，与GPT-3.5结合可修复201个bug，超越了现有最先进的基线。此外，它在显著减少补丁数量和降低时间和金钱成本的情况下，依然展现出更高的有效性和效率，尤其擅长处理复杂bug。", "keywords": "自动化程序修复, 大型语言模型, 蒙特卡洛树搜索, 迭代树搜索, 软件维护", "comments": "APRMCTS的创新之处在于将蒙特卡洛树搜索（MCTS）引入到LLM-based APR中，这有效地解决了现有试错策略导致的局部最优和低效率问题。通过全局评估和迭代细化，它显著提高了补丁的有效性和搜索效率，同时大幅降低了计算和时间成本，这对于实际应用具有重要意义。该方法证明了智能搜索策略与LLM结合在程序修复领域的巨大潜力。"}}
{"id": "2507.01487", "title": "How to Securely Shuffle? A survey about Secure Shufflers for privacy-preserving computations", "authors": ["Marc Damie", "Florian Hahn", "Andreas Peter", "Jan Ramon"], "summary": "Ishai et al. (FOCS'06) introduced secure shuffling as an efficient building\nblock for private data aggregation. Recently, the field of differential privacy\nhas revived interest in secure shufflers by highlighting the privacy\namplification they can provide in various computations. Although several works\nargue for the utility of secure shufflers, they often treat them as black\nboxes; overlooking the practical vulnerabilities and performance trade-offs of\nexisting implementations. This leaves a central question open: what makes a\ngood secure shuffler?\n  This survey addresses that question by identifying, categorizing, and\ncomparing 26 secure protocols that realize the necessary shuffling\nfunctionality. To enable a meaningful comparison, we adapt and unify existing\nsecurity definitions into a consistent set of properties. We also present an\noverview of privacy-preserving technologies that rely on secure shufflers,\noffer practical guidelines for selecting appropriate protocols, and outline\npromising directions for future work.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01487v1", "categories": ["cs.CR", "cs.LG"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01487v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "如何安全地洗牌？一项关于隐私保护计算中安全洗牌器的调查", "tldr": "本调查分析了26种安全洗牌协议，统一了安全定义，并提供了选择指南，以解决现有实现中的漏洞和性能权衡问题。", "motivation": "现有的关于安全洗牌器的工作通常将其视为黑盒子，忽略了实际漏洞和性能权衡，导致一个核心问题悬而未决：“什么才是一个好的安全洗牌器？”", "method": "本调查通过识别、分类和比较26种实现洗牌功能的安全协议来解决上述问题。为了进行有意义的比较，作者调整并统一了现有的安全定义，形成了一致的属性集。此外，还概述了依赖安全洗牌器的隐私保护技术，提供了选择合适协议的实用指南，并提出了未来工作的方向。", "result": "识别、分类并比较了26种安全洗牌协议；统一了现有的安全定义；概述了依赖安全洗牌器的隐私保护技术；提供了选择合适协议的实用指南；并指出了未来工作的方向。", "conclusion": "本调查通过对安全洗牌协议进行全面分析，统一了安全定义，并提供了实用指南，以填补了现有研究中对安全洗牌器实际实现和性能权衡关注不足的空白。", "translation": "Ishai 等人（FOCS'06）引入了安全洗牌作为私有数据聚合的有效构建块。最近，差分隐私领域通过强调安全洗牌器在各种计算中可以提供的隐私放大作用，重新燃起了对安全洗牌器的兴趣。尽管有几项工作论证了安全洗牌器的实用性，但它们通常将其视为黑盒子；忽视了现有实现的实际漏洞和性能权衡。这留下了一个核心问题：什么才是一个好的安全洗牌器？\n本调查通过识别、分类和比较26种实现必要洗牌功能的安全协议来解决这个问题。为了实现有意义的比较，我们调整并统一了现有的安全定义，形成了一致的属性集。我们还概述了依赖安全洗牌器的隐私保护技术，提供了选择合适协议的实用指南，并概述了未来工作的有前景方向。", "summary": "本文对隐私保护计算中的安全洗牌器进行了全面调查。针对现有研究中将安全洗牌器视为黑盒子，忽视其实际漏洞和性能权衡的问题，本调查识别、分类并比较了26种安全洗牌协议。通过统一安全定义，论文为选择合适的协议提供了实用指南，并指明了未来研究的方向，旨在解决“什么才是一个好的安全洗牌器”这一核心问题。", "keywords": "安全洗牌器, 隐私保护计算, 差分隐私, 协议调查, 安全定义", "comments": "这篇调查论文的创新之处在于它首次系统地对隐私保护计算中的安全洗牌协议进行了全面的梳理和比较，填补了该领域将洗牌器视为“黑盒子”的空白。其重要性在于，通过统一安全定义并提供实用选择指南，它为研究人员和实践者提供了宝贵的资源，有助于更安全、高效地部署隐私保护技术，并为未来的研究指明了方向。"}}
{"id": "2507.01571", "title": "On the Effect of Ruleset Tuning and Data Imbalance on Explainable Network Security Alert Classifications: a Case-Study on DeepCASE", "authors": ["Koen T. W. Teuwen", "Sam Baggen", "Emmanuele Zambon", "Luca Allodi"], "summary": "Automation in Security Operations Centers (SOCs) plays a prominent role in\nalert classification and incident escalation. However, automated methods must\nbe robust in the presence of imbalanced input data, which can negatively affect\nperformance. Additionally, automated methods should make explainable decisions.\nIn this work, we evaluate the effect of label imbalance on the classification\nof network intrusion alerts. As our use-case we employ DeepCASE, the\nstate-of-the-art method for automated alert classification. We show that label\nimbalance impacts both classification performance and correctness of the\nclassification explanations offered by DeepCASE. We conclude tuning the\ndetection rules used in SOCs can significantly reduce imbalance and may benefit\nthe performance and explainability offered by alert post-processing methods\nsuch as DeepCASE. Therefore, our findings suggest that traditional methods to\nimprove the quality of input data can benefit automation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01571v1", "categories": ["cs.CR", "cs.LG", "cs.NI"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01571v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "关于规则集调整和数据不平衡对可解释网络安全警报分类的影响：DeepCASE案例研究", "tldr": "本研究评估了标签不平衡对网络入侵警报分类及其解释能力的影响，发现不平衡会损害DeepCASE的性能和解释的正确性，并提出调整检测规则可以改善自动化方法的性能和可解释性。", "motivation": "安全运营中心（SOC）的自动化在警报分类和事件升级中扮演重要角色。然而，自动化方法必须在存在数据不平衡的情况下保持鲁棒性，因为数据不平衡会负面影响性能。此外，自动化方法应该提供可解释的决策。", "method": "本研究评估了标签不平衡对网络入侵警报分类的影响。研究中使用了最先进的自动化警报分类方法DeepCASE作为案例研究。", "result": "研究表明，标签不平衡会影响DeepCASE的分类性能以及分类解释的正确性。", "conclusion": "研究得出结论，调整SOC中使用的检测规则可以显著减少数据不平衡，并可能有利于DeepCASE等警报后处理方法所提供的性能和可解释性。因此，研究结果表明，改善输入数据质量的传统方法可以使自动化受益。", "translation": "安全运营中心（SOC）的自动化在警报分类和事件升级中扮演重要角色。然而，自动化方法必须在存在不平衡输入数据的情况下保持鲁棒性，因为不平衡数据会负面影响性能。此外，自动化方法应该做出可解释的决策。在这项工作中，我们评估了标签不平衡对网络入侵警报分类的影响。作为我们的用例，我们采用了最先进的自动化警报分类方法DeepCASE。我们发现标签不平衡会影响DeepCASE的分类性能以及其提供的分类解释的正确性。我们得出结论，调整SOC中使用的检测规则可以显著减少不平衡，并可能有利于DeepCASE等警报后处理方法所提供的性能和可解释性。因此，我们的发现表明，改善输入数据质量的传统方法可以使自动化受益。", "summary": "本研究调查了标签不平衡对网络安全警报分类及其解释能力的影响，以最先进的DeepCASE方法为例。结果显示，数据不平衡显著损害了DeepCASE的分类性能和解释的正确性。研究建议，通过调整SOC中的检测规则来减少数据不平衡，可以有效提升自动化警报处理系统（如DeepCASE）的性能和可解释性，强调了传统数据质量改进方法对自动化的益处。", "keywords": "网络安全, 警报分类, 数据不平衡, 可解释性, DeepCASE", "comments": "该论文通过对DeepCASE的案例研究，突出了数据不平衡在网络安全警报分类自动化中的关键挑战，尤其是在可解释性方面。其创新之处在于明确指出了数据不平衡不仅影响分类性能，还影响解释的正确性。重要性在于它为SOCs提出了实际建议，即通过调整规则集来改善数据质量，从而提升自动化方法的鲁棒性和可解释性，这对于实际部署具有指导意义。"}}
{"id": "2507.01255", "title": "AIGVE-MACS: Unified Multi-Aspect Commenting and Scoring Model for AI-Generated Video Evaluation", "authors": ["Xiao Liu", "Jiawei Zhang"], "summary": "The rapid advancement of AI-generated video models has created a pressing\nneed for robust and interpretable evaluation frameworks. Existing metrics are\nlimited to producing numerical scores without explanatory comments, resulting\nin low interpretability and human evaluation alignment. To address those\nchallenges, we introduce AIGVE-MACS, a unified model for AI-Generated Video\nEvaluation(AIGVE), which can provide not only numerical scores but also\nmulti-aspect language comment feedback in evaluating these generated videos.\nCentral to our approach is AIGVE-BENCH 2, a large-scale benchmark comprising\n2,500 AI-generated videos and 22,500 human-annotated detailed comments and\nnumerical scores across nine critical evaluation aspects. Leveraging\nAIGVE-BENCH 2, AIGVE-MACS incorporates recent Vision-Language Models with a\nnovel token-wise weighted loss and a dynamic frame sampling strategy to better\nalign with human evaluators. Comprehensive experiments across supervised and\nzero-shot benchmarks demonstrate that AIGVE-MACS achieves state-of-the-art\nperformance in both scoring correlation and comment quality, significantly\noutperforming prior baselines including GPT-4o and VideoScore. In addition, we\nfurther showcase a multi-agent refinement framework where feedback from\nAIGVE-MACS drives iterative improvements in video generation, leading to 53.5%\nquality enhancement. This work establishes a new paradigm for comprehensive,\nhuman-aligned evaluation of AI-generated videos. We release the AIGVE-BENCH 2\nand AIGVE-MACS at https://huggingface.co/xiaoliux/AIGVE-MACS.", "comment": "Working in Progress", "pdf_url": "http://arxiv.org/pdf/2507.01255v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01255v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "AIGVE-MACS：用于AI生成视频评估的统一多方面评论和评分模型", "tldr": "AIGVE-MACS是一个统一模型，用于评估AI生成视频，提供数值评分和多方面语言评论，并在AIGVE-BENCH 2基准上实现最先进性能。", "motivation": "现有AI生成视频评估指标仅提供数值分数，缺乏解释性评论，导致可解释性低且与人类评估不一致。为了解决这些挑战，需要一个能够提供解释性评论的全面评估框架。", "method": "本研究提出了AIGVE-MACS模型，它是一个统一的AI生成视频评估模型，能够提供数值评分和多方面语言评论反馈。其核心是AIGVE-BENCH 2，一个包含2500个AI生成视频和22500个人工标注详细评论及九个关键评估方面数值分数的大规模基准。AIGVE-MACS利用AIGVE-BENCH 2，结合最新的视觉-语言模型，采用新颖的token-wise加权损失和动态帧采样策略，以更好地与人类评估者对齐。此外，还展示了一个多智能体改进框架，利用AIGVE-MACS的反馈驱动视频生成迭代改进。", "result": "AIGVE-MACS在监督和零样本基准测试中，在评分相关性和评论质量方面均实现了最先进的性能，显著优于包括GPT-4o和VideoScore在内的现有基线。通过多智能体改进框架，利用AIGVE-MACS的反馈，视频生成质量提高了53.5%。", "conclusion": "这项工作为AI生成视频的全面、与人类对齐的评估建立了一个新范式，并发布了AIGVE-BENCH 2和AIGVE-MACS。", "translation": "AI生成视频模型的快速发展对健壮且可解释的评估框架产生了迫切需求。现有指标仅限于生成数值分数而缺乏解释性评论，导致可解释性低且与人类评估不一致。为了解决这些挑战，我们引入了AIGVE-MACS，一个用于AI生成视频评估(AIGVE)的统一模型，它不仅能提供数值分数，还能在评估这些生成视频时提供多方面语言评论反馈。我们方法的核心是AIGVE-BENCH 2，一个大规模基准，包含2500个AI生成视频以及22500个人工标注的详细评论和九个关键评估方面的数值分数。AIGVE-MACS利用AIGVE-BENCH 2，结合最新的视觉-语言模型，采用新颖的token-wise加权损失和动态帧采样策略，以更好地与人类评估者对齐。在监督和零样本基准测试中的全面实验表明，AIGVE-MACS在评分相关性和评论质量方面均实现了最先进的性能，显著优于包括GPT-4o和VideoScore在内的现有基线。此外，我们进一步展示了一个多智能体改进框架，其中来自AIGVE-MACS的反馈驱动视频生成的迭代改进，导致质量提高了53.5%。这项工作为AI生成视频的全面、与人类对齐的评估建立了一个新范式。我们已在https://huggingface.co/xiaoliux/AIGVE-MACS发布了AIGVE-BENCH 2和AIGVE-MACS。", "summary": "本文提出了AIGVE-MACS，一个统一的AI生成视频评估模型，旨在解决现有评估方法缺乏解释性评论的问题。该模型不仅提供数值评分，还能生成多方面的语言评论。研究引入了AIGVE-BENCH 2这一大规模基准数据集，包含2500个AI生成视频和22500个人工标注的详细评论及评分。AIGVE-MACS利用视觉-语言模型，结合创新的损失函数和采样策略，以更好地模拟人类评估。实验证明，AIGVE-MACS在评分准确性和评论质量上均达到SOTA，并能有效指导视频生成质量的迭代提升。", "keywords": "AI生成视频评估, 多方面评论, 统一模型, AIGVE-MACS, AIGVE-BENCH 2", "comments": "AIGVE-MACS的创新之处在于其统一了数值评分和多方面语言评论，显著提高了AI生成视频评估的可解释性和与人类评估的对齐度。引入AIGVE-BENCH 2这一大规模、多方面标注的基准数据集，为未来研究提供了宝贵的资源。此外，将评估模型反馈融入多智能体优化框架以提升生成视频质量，展示了该模型的实用价值和潜力，为AI内容生成与评估的闭环优化提供了新思路。"}}
{"id": "2507.01274", "title": "AI Meets Maritime Training: Precision Analytics for Enhanced Safety and Performance", "authors": ["Vishakha Lall", "Yisi Liu"], "summary": "Traditional simulator-based training for maritime professionals is critical\nfor ensuring safety at sea but often depends on subjective trainer assessments\nof technical skills, behavioral focus, communication, and body language, posing\nchallenges such as subjectivity, difficulty in measuring key features, and\ncognitive limitations. Addressing these issues, this study develops an\nAI-driven framework to enhance maritime training by objectively assessing\ntrainee performance through visual focus tracking, speech recognition, and\nstress detection, improving readiness for high-risk scenarios. The system\nintegrates AI techniques, including visual focus determination using eye\ntracking, pupil dilation analysis, and computer vision; communication analysis\nthrough a maritime-specific speech-to-text model and natural language\nprocessing; communication correctness using large language models; and mental\nstress detection via vocal pitch. Models were evaluated on data from simulated\nmaritime scenarios with seafarers exposed to controlled high-stress events. The\nAI algorithms achieved high accuracy, with ~92% for visual detection, ~91% for\nmaritime speech recognition, and ~90% for stress detection, surpassing existing\nbenchmarks. The system provides insights into visual attention, adherence to\ncommunication checklists, and stress levels under demanding conditions. This\nstudy demonstrates how AI can transform maritime training by delivering\nobjective performance analytics, enabling personalized feedback, and improving\npreparedness for real-world operational challenges.", "comment": "Accepted and Presented at 11th International Maritime Science\n  Conference", "pdf_url": "http://arxiv.org/pdf/2507.01274v1", "categories": ["cs.HC", "cs.AI"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01274v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "AI赋能海事培训：精准分析提升安全与表现", "tldr": "本研究开发了一个人工智能驱动的框架，通过客观评估受训人员在视觉焦点、语音和压力检测方面的表现来改进海事培训，实现高精度并提高安全准备。", "motivation": "传统海事培训依赖于培训师的主观评估，导致评估结果主观性强、关键特征难以衡量且存在认知限制。本研究旨在通过提供客观的绩效评估来解决这些问题。", "method": "本研究开发了一个人工智能驱动的框架，通过视觉焦点追踪、语音识别和压力检测来客观评估受训人员的表现。该系统集成了多种AI技术：使用眼动追踪、瞳孔散大分析和计算机视觉进行视觉焦点判断；通过海事专用语音转文本模型和自然语言处理进行沟通分析；使用大型语言模型进行沟通正确性判断；以及通过音高检测心理压力。模型在海员暴露于受控高压事件的模拟海事场景数据上进行了评估。", "result": "人工智能算法取得了高精度，视觉检测约为92%，海事语音识别约为91%，压力检测约为90%，均超越了现有基准。该系统提供了在严苛条件下视觉注意力、沟通清单依从性以及压力水平的洞察。", "conclusion": "人工智能能够通过提供客观的性能分析、实现个性化反馈并提高应对实际操作挑战的准备度来改变海事培训。", "translation": "针对海事专业人员的传统模拟器培训对于确保海上安全至关重要，但通常依赖于培训师对技术技能、行为专注度、沟通和肢体语言的主观评估，这带来了主观性、关键特征难以衡量以及认知限制等挑战。为解决这些问题，本研究开发了一个人工智能驱动的框架，通过视觉焦点追踪、语音识别和压力检测来客观评估受训人员的表现，从而提升海事培训效果，提高应对高风险情景的准备度。该系统集成了多种AI技术，包括使用眼动追踪、瞳孔散大分析和计算机视觉进行视觉焦点判断；通过海事专用语音转文本模型和自然语言处理进行沟通分析；使用大型语言模型进行沟通正确性判断；以及通过音高检测心理压力。模型在海员暴露于受控高压事件的模拟海事场景数据上进行了评估。人工智能算法取得了高精度，视觉检测约为92%，海事语音识别约为91%，压力检测约为90%，均超越了现有基准。该系统提供了在严苛条件下视觉注意力、沟通清单依从性以及压力水平的洞察。本研究展示了人工智能如何通过提供客观的性能分析、实现个性化反馈并提高应对实际操作挑战的准备度来改变海事培训。", "summary": "本研究引入了一个人工智能驱动的框架，旨在为海事培训提供客观评估，以克服传统主观评估的局限性。该框架利用眼动追踪、语音识别、自然语言处理和压力检测来分析受训人员在模拟高压情景下的表现。系统在视觉、语音和压力检测方面取得了高精度（90-92%），展示了人工智能在提供客观分析、个性化反馈以及增强实际海事操作准备方面的巨大潜力。", "keywords": "海事培训, AI, 性能分析, 客观评估, 安全", "comments": "该论文将人工智能创新性地应用于海事培训这一关键领域，超越了传统的主观评估方式。其将多种AI模态（视觉、语音、生理）整合进行全面性能分析是一个亮点。所实现的高精度结果突显了其实用价值和显著提升海事操作安全与效率的潜力。"}}
{"id": "2507.01031", "title": "PyTorch-based Geometric Learning with Non-CUDA Processing Units: Experiences from Intel Gaudi-v2 HPUs", "authors": ["Fanchen Bu", "Kijung Shin"], "summary": "Geometric learning has emerged as a powerful paradigm for modeling\nnon-Euclidean data, especially graph-structured ones, with applications\nspanning social networks, molecular structures, knowledge graphs, and\nrecommender systems. While Nvidia's CUDA-enabled graphics processing units\n(GPUs) largely dominate the hardware landscape, emerging accelerators such as\nIntel's Gaudi Habana Processing Units (HPUs) offer competitive performance and\nenergy efficiency. However, the usage of such non-CUDA processing units\nrequires significant engineering effort and novel software adaptations. In this\nwork, we present our experiences porting PyTorch-based geometric learning\nframeworks to Gaudi-v2 HPUs. We introduce a collection of core utilities that\nrestore essential operations (e.g., scatter, sparse indexing, k-nearest\nneighbors) on Gaudi-v2 HPUs, and we consolidate sixteen guided tutorials and\neleven real-world examples with diagnostic analyses of encountered failures and\ndetailed workarounds. We collect all our experiences into a publicly accessible\nGitHub repository. Our contributions lower the barrier for researchers to\nexperiment with geometric-learning algorithms and models on non-CUDA hardware,\nproviding a foundation for further optimization and cross-platform portability.", "comment": "Conference paper: Accepted in Korea Computer Congress (KCC) 2025. The\n  library is available at https://github.com/bokveizen/gaudi-geometric-learning", "pdf_url": "http://arxiv.org/pdf/2507.01031v1", "categories": ["cs.LG", "cs.SE"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01031v1", "date": "2025-06-20", "updated": "2025-06-20", "AI": {"title_translation": "基于PyTorch的非CUDA处理器上的几何学习：来自英特尔Gaudi-v2 HPU的经验", "tldr": "该论文分享了将基于PyTorch的几何学习框架移植到英特尔Gaudi-v2 HPU的经验，提供了核心实用程序、教程和案例，旨在降低研究人员在非CUDA硬件上进行几何学习的门槛。", "motivation": "几何学习在非欧几里得数据处理中应用广泛，而当前主要依赖Nvidia的CUDA GPU。然而，英特尔Gaudi HPU等非CUDA加速器提供了有竞争力的性能和能效，但其使用需要大量的工程投入和软件适配，这为研究人员带来了障碍。", "method": "作者将基于PyTorch的几何学习框架移植到Gaudi-v2 HPU上。他们开发了一系列核心实用程序以恢复基本操作（如scatter、稀疏索引、k-最近邻），并整理了十六个指导教程和十一个真实世界示例，其中包含了遇到的故障诊断分析和详细的解决方案。所有经验都收集在一个公开的GitHub仓库中。", "result": "成功将PyTorch几何学习框架移植到Gaudi-v2 HPUs，并提供了恢复核心操作的实用程序、丰富的教程和实际案例，显著降低了研究人员在非CUDA硬件上实验几何学习算法和模型的障碍。", "conclusion": "本研究的贡献为在非CUDA硬件上进一步优化几何学习算法和模型以及实现跨平台可移植性奠定了基础。", "translation": "几何学习已成为一种强大的范式，用于建模非欧几里得数据，尤其是图结构数据，其应用涵盖社交网络、分子结构、知识图谱和推荐系统。虽然英伟达的CUDA-enabled图形处理单元（GPU）在硬件领域占据主导地位，但新兴的加速器，如英特尔的Gaudi Habana处理单元（HPU），提供了具有竞争力的性能和能效。然而，使用此类非CUDA处理单元需要大量的工程投入和新颖的软件适配。在这项工作中，我们介绍了将基于PyTorch的几何学习框架移植到Gaudi-v2 HPU上的经验。我们引入了一系列核心实用程序，用于在Gaudi-v2 HPU上恢复基本操作（例如，scatter、稀疏索引、k-最近邻），并整合了十六个指导教程和十一个真实世界示例，其中包含遇到的故障诊断分析和详细的解决方案。我们将所有经验收集到一个公开的GitHub仓库中。我们的贡献降低了研究人员在非CUDA硬件上试验几何学习算法和模型的障碍，为进一步优化和跨平台可移植性奠定了基础。", "summary": "该论文详细介绍了将基于PyTorch的几何学习框架移植到英特尔Gaudi-v2 HPU（一种非CUDA替代硬件）的过程和挑战。作者开发了核心实用程序以支持关键操作，并汇编了大量教程和真实世界示例，其中包含调试见解。这项工作旨在简化几何学习在非CUDA硬件上的应用，促进进一步的优化和跨平台兼容性。", "keywords": "几何学习, PyTorch, 英特尔Gaudi, HPU, 非CUDA", "comments": "这篇论文解决了AI硬件领域的一个重要实际挑战：使软件生态系统（如PyTorch几何学习）能够在替代硬件平台（非CUDA HPU）上高效运行。其创新之处在于提供了具体的工程解决方案、实用工具和全面的文档（教程、示例、变通方法）来弥补这一差距，这对于硬件多样性和竞争至关重要。这种基于实践经验的方法对于面临类似可移植性问题的研究人员和开发人员来说具有高度价值。"}}
{"id": "2507.01350", "title": "Cooperative Target Capture in 3D Engagements over Switched Dynamic Graphs", "authors": ["Abhinav Sinha", "Shashi Ranjan Kumar"], "summary": "This paper presents a leaderless cooperative guidance strategy for\nsimultaneous time-constrained interception of a stationary target when the\ninterceptors exchange information over switched dynamic graphs. We specifically\nfocus on scenarios when the interceptors lack radial acceleration capabilities,\nrelying solely on their lateral acceleration components. This consideration\naligns with their inherent kinematic turn constraints. The proposed strategy\nexplicitly addresses the complexities of coupled 3D engagements, thereby\nmitigating performance degradation that typically arises when the pitch and yaw\nchannels are decoupled into two separate, mutually orthogonal planar\nengagements. Moreover, our formulation incorporates modeling uncertainties\nassociated with the time-to-go estimation into the derivation of cooperative\nguidance commands to ensure robustness against inaccuracies in dynamic\nengagement scenarios. To optimize control efficiency, we analytically derive\nthe lateral acceleration components in the orthogonal pitch and yaw channels by\nsolving an instantaneous optimization problem, subject to an affine constraint.\nWe show that the proposed cooperative guidance commands guarantee consensus in\ntime-to-go values within a predefined time, which can be prescribed as a design\nparameter, regardless of the interceptors' initial configurations. We provide\nsimulations to attest to the efficacy of the proposed method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01350v1", "categories": ["eess.SY", "cs.MA", "cs.RO", "cs.SY"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01350v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于切换动态图的3D交战中协同目标捕获", "tldr": "本文提出了一种无先导的协同制导策略，用于在切换动态图中，拦截器仅依靠横向加速度分量，同时、有时限地拦截静止目标，并解决了耦合的3D交战复杂性和建模不确定性，确保了到达时间的一致性。", "motivation": "现有方法在处理拦截器缺乏径向加速度能力、仅依赖横向加速度分量的情况时，难以有效应对耦合的3D交战复杂性，且可能因俯仰和偏航通道解耦而导致性能下降。此外，建模不确定性（如到达时间估计）也影响动态交战场景的鲁棒性。", "method": "本文提出了一种无先导的协同制导策略。该策略专门针对拦截器缺乏径向加速度能力、仅依赖横向加速度分量的情况。它明确处理了耦合的3D交战复杂性，避免了俯仰和偏航通道解耦带来的性能下降。此外，该策略将与到达时间估计相关的建模不确定性纳入协同制导指令的推导中，以确保鲁棒性。为了优化控制效率，通过求解一个受仿射约束的瞬时优化问题，解析推导了正交俯仰和偏航通道中的横向加速度分量。", "result": "所提出的策略有效解决了耦合的3D交战复杂性，减轻了性能下降。该方法通过纳入建模不确定性，增强了对动态交战场景中不准确性的鲁棒性。研究表明，所提出的协同制导指令能够保证拦截器在预定义时间内实现到达时间值的一致性，且与拦截器的初始配置无关。仿真结果证明了所提方法的有效性。", "conclusion": "本文提出的无先导协同制导策略能够有效解决3D交战中拦截器协同捕获目标的问题，尤其是在拦截器仅有横向加速度且信息通过切换动态图交换的复杂场景下。该策略通过处理耦合动力学和建模不确定性，并确保到达时间的一致性，展现了其鲁棒性和高效性。", "translation": "本文提出了一种无先导的协同制导策略，用于在拦截器通过切换动态图交换信息时，同时、有时限地拦截静止目标。我们特别关注拦截器缺乏径向加速度能力，仅依靠其横向加速度分量的场景。这一考量与其固有的运动学转弯限制相符。所提出的策略明确解决了耦合3D交战的复杂性，从而减轻了俯仰和偏航通道通常被解耦为两个独立的、相互正交的平面交战时出现的性能下降。此外，我们的公式将与到达时间估计相关的建模不确定性纳入协同制导指令的推导中，以确保在动态交战场景中对不准确性的鲁棒性。为了优化控制效率，我们通过求解一个受仿射约束的瞬时优化问题，解析推导了正交俯仰和偏航通道中的横向加速度分量。我们表明，所提出的协同制导指令保证了在预定义时间内（可以作为设计参数规定）到达时间值的一致性，而与拦截器的初始配置无关。我们提供了仿真以证明所提方法的有效性。", "summary": "本文提出了一种无先导的协同制导策略，用于在切换动态图下，拦截器仅依靠横向加速度分量，同时、有时限地拦截静止目标。该策略解决了耦合3D交战的复杂性，并纳入了到达时间估计的建模不确定性以增强鲁棒性。通过求解瞬时优化问题解析推导横向加速度分量，确保了到达时间的一致性。仿真验证了其有效性。", "keywords": "协同制导, 3D交战, 切换动态图, 时间约束拦截, 横向加速度", "comments": "该论文的创新点在于提出了一个无先导的协同制导策略，专门针对拦截器缺乏径向加速度能力且处于复杂耦合3D交战环境下的目标捕获问题。通过考虑运动学约束、处理耦合动力学以及纳入建模不确定性，该方法提高了系统性能和鲁棒性。尤其是在保证到达时间一致性方面的贡献，对于实际应用具有重要意义。"}}
{"id": "2507.01575", "title": "Transfer Learning for VLC-based indoor Localization: Addressing Environmental Variability", "authors": ["Masood Jan", "Wafa Njima", "Xun Zhang", "Alexander Artemenko"], "summary": "Accurate indoor localization is crucial in industrial environments. Visible\nLight Communication (VLC) has emerged as a promising solution, offering high\naccuracy, energy efficiency, and minimal electromagnetic interference. However,\nVLC-based indoor localization faces challenges due to environmental\nvariability, such as lighting fluctuations and obstacles. To address these\nchallenges, we propose a Transfer Learning (TL)-based approach for VLC-based\nindoor localization. Using real-world data collected at a BOSCH factory, the TL\nframework integrates a deep neural network (DNN) to improve localization\naccuracy by 47\\%, reduce energy consumption by 32\\%, and decrease computational\ntime by 40\\% compared to the conventional models. The proposed solution is\nhighly adaptable under varying environmental conditions and achieves similar\naccuracy with only 30\\% of the dataset, making it a cost-efficient and scalable\noption for industrial applications in Industry 4.0.", "comment": "Accepted for publication in the IEEE VTC2025-Spring Conference, 7\n  pages", "pdf_url": "http://arxiv.org/pdf/2507.01575v1", "categories": ["eess.SP", "cs.LG"], "cate": "eess.SP", "url": "http://arxiv.org/abs/2507.01575v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "可见光通信（VLC）室内定位中的迁移学习：解决环境变异性", "tldr": "提出一种基于迁移学习的可见光通信室内定位方法，能有效提高精度、降低能耗和计算时间，并减少数据需求，以应对环境变化。", "motivation": "工业环境中精确室内定位的重要性；可见光通信（VLC）作为一种有前景的解决方案，但面临环境变异性（如照明波动和障碍物）的挑战。", "method": "提出一种基于迁移学习（TL）的方法，用于可见光通信（VLC）室内定位。该TL框架整合了深度神经网络（DNN），并使用在BOSCH工厂收集的真实世界数据进行验证。", "result": "相比传统模型，定位精度提高了47%，能耗降低了32%，计算时间减少了40%。在仅使用30%数据集的情况下也能达到相似的精度。", "conclusion": "该解决方案在不同环境条件下具有高度适应性，且在数据需求方面具有成本效益和可扩展性，适用于工业4.0的工业应用。", "translation": "准确的室内定位在工业环境中至关重要。可见光通信（VLC）已成为一种有前景的解决方案，具有高精度、高能效和最小电磁干扰的优点。然而，基于VLC的室内定位面临环境变异性（如照明波动和障碍物）带来的挑战。为了解决这些挑战，我们提出了一种基于迁移学习（TL）的VLC室内定位方法。利用在BOSCH工厂收集的真实世界数据，该TL框架整合了深度神经网络（DNN），与传统模型相比，将定位精度提高了47%，能耗降低了32%，计算时间减少了40%。所提出的解决方案在不同环境条件下具有高度适应性，并且在仅使用30%数据集的情况下也能达到相似的精度，使其成为工业4.0中工业应用的成本效益高且可扩展的选项。", "summary": "本文提出一种基于迁移学习（TL）和深度神经网络（DNN）的可见光通信（VLC）室内定位方法，旨在解决环境变异性带来的挑战。通过在真实工业环境中验证，该方法显著提升了定位精度、降低了能耗和计算时间，并展现出在减少数据量下保持高性能的潜力，为工业4.0应用提供了一种高效且可扩展的解决方案。", "keywords": "迁移学习, 可见光通信, 室内定位, 环境变异性, 深度神经网络", "comments": "这篇论文通过引入迁移学习来解决VLC室内定位中环境变异性的核心问题，具有创新性。其在提高精度、降低能耗和计算时间方面的量化成果非常显著，尤其是在减少数据需求的情况下仍能保持性能，这对于实际工业部署具有重要意义，降低了部署和维护成本。"}}
{"id": "2507.01685", "title": "Half Spatially Coupled Turbo-Like Codes", "authors": ["Xiaowei Wu", "Lei Yang", "Min Qiu", "Chong Han", "Jinhong Yuan"], "summary": "This paper presents a new class of spatially coupled turbo-like codes\n(SC-TCs), namely half spatially coupled braided convolutional codes (HSC-BCCs)\nand half spatially coupled parallel concatenated codes (HSC-PCCs). Different\nfrom the conventional SC-TCs, the proposed codes have simpler and deterministic\ncoupling structures. Most notably, the coupling of HSC-BCCs is performed by\nre-encoding the whole coupling sequence in the component encoder of one time\ninstant, rather than spreading the coupling bits to component encoders of\nmultiple time instants. This simplification not only addresses the window\ndecoding threshold loss issue in existing BCCs, but also allows the proposed\ncodes to attain very close-to-capacity performance with a coupling memory as\nsmall as 2. Both theoretical and numerical results are provided to demonstrate\nthe performance advantages of the proposed codes over existing spatially\ncoupled codes.", "comment": "This is an extended version of conference paper \"Half Spatially\n  Coupled Turbo-Like Codes\" accepted by 2025 IEEE Information Theory Workshop", "pdf_url": "http://arxiv.org/pdf/2507.01685v1", "categories": ["cs.IT", "math.IT"], "cate": "cs.IT", "url": "http://arxiv.org/abs/2507.01685v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "半空间耦合类Turbo码", "tldr": "本文提出了一种新型的半空间耦合类Turbo码（HSC-BCCs和HSC-PCCs），具有更简单的耦合结构，解决了现有辫状卷积码的窗口解码阈值损失问题，并以很小的耦合存储器实现了接近容量的性能。", "motivation": "解决现有辫状卷积码（BCCs）中窗口解码阈值损失的问题。", "method": "提出了一类名为半空间耦合辫状卷积码（HSC-BCCs）和半空间耦合并行级联码（HSC-PCCs）的新型空间耦合类Turbo码。其耦合结构更简单且确定，特别是HSC-BCCs通过在一个时间实例中对整个耦合序列进行重新编码来执行耦合。", "result": "所提出的码不仅解决了现有BCCs中的窗口解码阈值损失问题，而且在耦合存储器小至2的情况下也能达到非常接近容量的性能。理论和数值结果均表明所提出的码优于现有的空间耦合码。", "conclusion": "所提出的半空间耦合类Turbo码在性能上优于现有空间耦合码，且具有更简单的结构和更小的耦合存储器。", "translation": "本文提出了一类新型的空间耦合类Turbo码（SC-TCs），即半空间耦合辫状卷积码（HSC-BCCs）和半空间耦合并行级联码（HSC-PCCs）。与传统的SC-TCs不同，所提出的码具有更简单和确定性的耦合结构。最值得注意的是，HSC-BCCs的耦合是通过在一个时间实例中对整个耦合序列进行重新编码来执行的，而不是将耦合比特分散到多个时间实例的分量编码器中。这种简化不仅解决了现有BCCs中窗口解码阈值损失的问题，而且使得所提出的码在耦合存储器小至2的情况下也能达到非常接近容量的性能。理论和数值结果都表明了所提出的码相对于现有空间耦合码的性能优势。", "summary": "本文引入了半空间耦合类Turbo码（HSC-BCCs和HSC-PCCs），这类编码与传统空间耦合类Turbo码相比，拥有更简洁且确定的耦合结构。特别是HSC-BCCs通过在单个时间点重新编码整个耦合序列来简化耦合过程，有效解决了现有辫状卷积码的窗口解码阈值损失问题，并能在极小的耦合存储器下实现接近信道容量的性能。理论与数值分析均证实了其优越性。", "keywords": "空间耦合码, 类Turbo码, 辫状卷积码, 并行级联码, 耦合存储器", "comments": "该论文的创新点在于提出了具有更简单和确定性耦合结构的新型半空间耦合类Turbo码，特别是通过在一个时间实例中重新编码整个耦合序列的耦合方式，有效解决了现有辫状卷积码的窗口解码阈值损失问题，并能在极小的耦合存储器下实现接近容量的性能，这对于实际应用具有重要意义。"}}
{"id": "2507.01615", "title": "EDGChain-E: A Decentralized Git-Based Framework for Versioning Encrypted Energy Data", "authors": ["Alper Alimoglu", "Kamil Erdayandi", "Mustafa A. Mustafa", "Ümit Cali"], "summary": "This paper proposes a new decentralized framework, named EDGChain-E\n(Encrypted-Data-Git Chain for Energy), designed to manage version-controlled,\nencrypted energy data using blockchain and the InterPlanetary File System. The\nframework incorporates a Decentralized Autonomous Organization (DAO) to\norchestrate collaborative data governance across the lifecycle of energy\nresearch and operations, such as smart grid monitoring, demand forecasting, and\npeer-to-peer energy trading. In EDGChain-E, initial commits capture the full\nencrypted datasets-such as smart meter readings or grid telemetry-while\nsubsequent updates are tracked as encrypted Git patches, ensuring integrity,\ntraceability, and privacy. This versioning mechanism supports secure\ncollaboration across multiple stakeholders (e.g., utilities, researchers,\nregulators) without compromising sensitive or regulated information. We\nhighlight the framework's capability to maintain FAIR-compliant (Findable,\nAccessible, Interoperable, Reusable) provenance of encrypted data. By embedding\nhash-based content identifiers in Merkle trees, the system enables transparent,\nauditable, and immutable tracking of data changes, thereby supporting\nreproducibility and trust in decentralized energy applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01615v1", "categories": ["cs.DC"], "cate": "cs.DC", "url": "http://arxiv.org/abs/2507.01615v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "EDGChain-E：一个用于加密能源数据版本控制的去中心化基于Git的框架", "tldr": "EDGChain-E是一个去中心化框架，利用区块链和IPFS管理加密能源数据的版本控制，通过DAO实现协作治理，并确保数据完整性、可追溯性和隐私。", "motivation": "该论文旨在解决能源数据管理中的版本控制、加密、完整性、可追溯性和隐私问题，并支持多方协作而不损害敏感信息。", "method": "EDGChain-E框架结合了区块链、星际文件系统（IPFS）和去中心化自治组织（DAO）。它通过初始提交捕获完整的加密数据集，后续更新以加密Git补丁的形式跟踪。系统将基于哈希的内容标识符嵌入默克尔树中，以实现透明、可审计和不可变的数据变更跟踪。", "result": "该框架能够管理版本控制的加密能源数据，支持多方（如公用事业公司、研究人员、监管机构）的安全协作，并保持符合FAIR原则的加密数据溯源。它实现了对数据变更的透明、可审计和不可变跟踪，从而支持去中心化能源应用的可复现性和信任。", "conclusion": "EDGChain-E提供了一个去中心化、安全且可审计的框架，用于管理加密能源数据的版本控制，促进能源领域研究和操作中的协作和信任。", "translation": "本文提出了一种名为EDGChain-E（加密数据Git链用于能源）的新型去中心化框架，旨在利用区块链和星际文件系统（IPFS）管理版本控制的加密能源数据。该框架整合了一个去中心化自治组织（DAO），以协调能源研究和运营（如智能电网监控、需求预测和点对点能源交易）整个生命周期中的协作数据治理。在EDGChain-E中，初始提交捕获完整的加密数据集——例如智能电表读数或电网遥测数据——而后续更新则作为加密的Git补丁进行跟踪，确保了数据的完整性、可追溯性和隐私。这种版本控制机制支持多方利益相关者（例如公用事业公司、研究人员、监管机构）之间的安全协作，而不会泄露敏感或受管制的信息。我们强调该框架能够维护符合FAIR原则（可查找、可访问、可互操作、可重用）的加密数据溯源。通过将基于哈希的内容标识符嵌入默克尔树中，系统能够实现数据变更的透明、可审计和不可变跟踪，从而支持去中心化能源应用的可复现性和信任。", "summary": "EDGChain-E是一个创新的去中心化框架，旨在通过整合区块链、IPFS和DAO来管理加密能源数据的版本控制。它通过跟踪加密的Git补丁来确保数据的完整性、可追溯性和隐私，并支持多方在智能电网监控、需求预测和点对点能源交易等应用中的安全协作。该框架还通过在默克尔树中嵌入哈希内容标识符，维护符合FAIR原则的数据溯源，从而实现数据变更的透明、可审计和不可变跟踪，增强了去中心化能源应用的可复现性和信任。", "keywords": "去中心化框架, 加密能源数据, 版本控制, 区块链, Git", "comments": "该论文提出了一种新颖的方法，将Git的版本控制概念与区块链和IPFS的去中心化特性相结合，用于管理敏感的加密能源数据。其创新点在于通过加密Git补丁和DAO实现协作治理，同时确保数据隐私和符合FAIR原则的溯源。这对于能源领域的数据共享和协作具有重要意义，尤其是在智能电网和能源交易等需要高数据完整性和隐私保护的应用中。"}}
{"id": "2507.01547", "title": "AI and Remote Sensing for Resilient and Sustainable Built Environments: A Review of Current Methods, Open Data and Future Directions", "authors": ["Ubada El Joulani", "Tatiana Kalganova", "Stergios-Aristoteles Mitoulis", "Sotirios Argyroudis"], "summary": "Critical infrastructure, such as transport networks, underpins economic\ngrowth by enabling mobility and trade. However, ageing assets, climate change\nimpacts (e.g., extreme weather, rising sea levels), and hybrid threats ranging\nfrom natural disasters to cyber attacks and conflicts pose growing risks to\ntheir resilience and functionality. This review paper explores how emerging\ndigital technologies, specifically Artificial Intelligence (AI), can enhance\ndamage assessment and monitoring of transport infrastructure. A systematic\nliterature review examines existing AI models and datasets for assessing damage\nin roads, bridges, and other critical infrastructure impacted by natural\ndisasters. Special focus is given to the unique challenges and opportunities\nassociated with bridge damage detection due to their structural complexity and\ncritical role in connectivity. The integration of SAR (Synthetic Aperture\nRadar) data with AI models is also discussed, with the review revealing a\ncritical research gap: a scarcity of studies applying AI models to SAR data for\ncomprehensive bridge damage assessment. Therefore, this review aims to identify\nthe research gaps and provide foundations for AI-driven solutions for assessing\nand monitoring critical transport infrastructures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01547v1", "categories": ["cs.CY", "cs.AI", "cs.LG"], "cate": "cs.CY", "url": "http://arxiv.org/abs/2507.01547v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "人工智能与遥感技术助力韧性与可持续建成环境：现有方法、开放数据与未来方向综述", "tldr": "本综述探讨了人工智能和遥感技术在交通基础设施损伤评估和监测中的应用，特别指出在利用AI结合SAR数据进行桥梁损伤评估方面存在研究空白。", "motivation": "关键基础设施（如交通网络）面临日益增长的风险，包括资产老化、气候变化影响和混合威胁，这对其韧性和功能性构成挑战。因此，需要利用新兴数字技术增强其损伤评估和监测能力。", "method": "本文采用系统文献综述的方法，审查了现有的人工智能模型和数据集，用于评估受自然灾害影响的道路、桥梁及其他关键基础设施的损伤。特别关注了桥梁损伤检测的独特挑战以及SAR（合成孔径雷达）数据与AI模型的集成。", "result": "综述发现了一个关键研究空白：将AI模型应用于SAR数据进行全面桥梁损伤评估的研究非常稀缺。", "conclusion": "本综述旨在识别研究空白，并为评估和监测关键交通基础设施的AI驱动解决方案奠定基础，尤其是在AI与SAR数据结合进行桥梁损伤评估方面。", "translation": "交通网络等关键基础设施通过实现流动性和贸易来支撑经济增长。然而，老化的资产、气候变化影响（如极端天气、海平面上升）以及从自然灾害到网络攻击和冲突等混合威胁，对其韧性和功能性构成了日益增长的风险。本综述论文探讨了新兴数字技术，特别是人工智能（AI），如何增强交通基础设施的损伤评估和监测。系统文献综述审查了用于评估受自然灾害影响的道路、桥梁和其他关键基础设施损伤的现有AI模型和数据集。特别关注了桥梁损伤检测的独特挑战和机遇，因为它们结构复杂且在连接性方面发挥着关键作用。还讨论了SAR（合成孔径雷达）数据与AI模型的集成，综述揭示了一个关键的研究空白：将AI模型应用于SAR数据进行全面桥梁损伤评估的研究稀缺。因此，本综述旨在识别研究空白，并为评估和监测关键交通基础设施的AI驱动解决方案奠定基础。", "summary": "本综述论文系统地审查了人工智能和遥感技术在关键交通基础设施（如道路和桥梁）损伤评估和监测中的应用。它识别了当前的人工智能模型和数据集，强调了桥梁损伤检测的挑战，并揭示了在利用AI模型对SAR数据进行全面桥梁损伤评估方面存在显著研究空白，旨在为未来AI驱动的解决方案提供指导。", "keywords": "人工智能, 遥感, 关键基础设施, 桥梁损伤, SAR数据", "comments": "本文通过识别在利用人工智能结合SAR数据进行桥梁损伤评估方面的关键研究空白，为提升关键基础设施的韧性提供了重要方向。其系统性的综述方法为该跨学科领域未来的研究奠定了宝贵基础。"}}
{"id": "2507.01323", "title": "SWinMamba: Serpentine Window State Space Model for Vascular Segmentation", "authors": ["Rongchang Zhao", "Huanchi Liu", "Jian Zhang"], "summary": "Vascular segmentation in medical images is crucial for disease diagnosis and\nsurgical navigation. However, the segmented vascular structure is often\ndiscontinuous due to its slender nature and inadequate prior modeling. In this\npaper, we propose a novel Serpentine Window Mamba (SWinMamba) to achieve\naccurate vascular segmentation. The proposed SWinMamba innovatively models the\ncontinuity of slender vascular structures by incorporating serpentine window\nsequences into bidirectional state space models. The serpentine window\nsequences enable efficient feature capturing by adaptively guiding global\nvisual context modeling to the vascular structure. Specifically, the Serpentine\nWindow Tokenizer (SWToken) adaptively splits the input image using overlapping\nserpentine window sequences, enabling flexible receptive fields (RFs) for\nvascular structure modeling. The Bidirectional Aggregation Module (BAM)\nintegrates coherent local features in the RFs for vascular continuity\nrepresentation. In addition, dual-domain learning with Spatial-Frequency Fusion\nUnit (SFFU) is designed to enhance the feature representation of vascular\nstructure. Extensive experiments on three challenging datasets demonstrate that\nthe proposed SWinMamba achieves superior performance with complete and\nconnected vessels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01323v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01323v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "SWinMamba：用于血管分割的蛇形窗口状态空间模型", "tldr": "SWinMamba是一种新的基于蛇形窗口状态空间模型的血管分割方法，能有效解决血管结构不连续的问题。", "motivation": "医学图像中的血管分割对于疾病诊断和手术导航至关重要，但由于血管的细长特性和先验建模不足，分割出的血管结构常常不连续。", "method": "本文提出了一种新颖的蛇形窗口Mamba（SWinMamba）模型，通过将蛇形窗口序列融入双向状态空间模型，创新性地建模细长血管结构的连续性。具体包括：蛇形窗口分词器（SWToken）使用重叠的蛇形窗口序列自适应地分割输入图像，提供灵活的感受野；双向聚合模块（BAM）整合感受野内连贯的局部特征，用于血管连续性表示；此外，设计了带有空间-频率融合单元（SFFU）的双域学习，以增强血管结构的特征表示。", "result": "在三个具有挑战性的数据集上进行的广泛实验表明，所提出的SWinMamba在完整和连通血管方面取得了卓越的性能。", "conclusion": "SWinMamba通过其创新的蛇形窗口序列和双向状态空间模型，有效解决了血管分割中结构不连续的问题，并取得了优越的分割效果。", "translation": "医学图像中的血管分割对于疾病诊断和手术导航至关重要。然而，由于血管的细长特性和先验建模不足，分割出的血管结构常常不连续。在本文中，我们提出了一种新颖的蛇形窗口Mamba（SWinMamba），以实现精确的血管分割。所提出的SWinMamba通过将蛇形窗口序列融入双向状态空间模型，创新性地建模了细长血管结构的连续性。蛇形窗口序列通过自适应地引导全局视觉上下文建模到血管结构，从而实现高效的特征捕获。具体而言，蛇形窗口分词器（SWToken）使用重叠的蛇形窗口序列自适应地分割输入图像，为血管结构建模提供了灵活的感受野。双向聚合模块（BAM）整合感受野中连贯的局部特征，用于血管连续性表示。此外，设计了带有空间-频率融合单元（SFFU）的双域学习，以增强血管结构的特征表示。在三个具有挑战性的数据集上进行的广泛实验表明，所提出的SWinMamba在完整和连通血管方面取得了卓越的性能。", "summary": "本文提出了一种名为SWinMamba的新型血管分割模型，旨在解决细长血管结构分割不连续的问题。SWinMamba创新性地将蛇形窗口序列融入双向状态空间模型，并通过蛇形窗口分词器（SWToken）、双向聚合模块（BAM）和空间-频率融合单元（SFFU）来增强特征捕获和连续性建模。实验证明，SWinMamba在多个数据集上能实现更完整和连通的血管分割。", "keywords": "血管分割, 状态空间模型, 蛇形窗口, SWinMamba, 连续性建模", "comments": "SWinMamba的创新点在于引入了“蛇形窗口序列”来建模血管的连续性，并将其与双向状态空间模型结合，这对于处理细长且复杂的血管结构是一个新颖的方法。其组件如SWToken、BAM和SFFU也体现了对血管特性的深度考量。该方法有望提高医学图像诊断和手术导航的精度。"}}
{"id": "2507.01300", "title": "Synchronising DER inverters to weak grid using Kalman filter and LQR current controller", "authors": ["Phuoc Sang Nguyen", "Ghavameddin Nourbakhsh", "Gerard Ledwich"], "summary": "Grid-following (GFL) inverters are commonly used for integrating renewable\nenergy sources into power grids. However, the dynamic performance of GFL models\ncan be significantly impacted by the Phase-Locked Loop (PLL) in a weak grid,\nleading to instability due to inaccuracies in grid source phase angle\nestimation. The proposed method in this manuscript replaces the PLL with an\nAdvanced Angle Estimation based Kalman Filter including a Linear Quadratic\nRegulator (LQR) controller of the GFL. This method is robust in incorporating\ngrid impedance terms as part of state space models in the Kalman Filter\napproach to estimate instantaneous phase angle using {\\alpha}-\\b{eta}\nSynchronous Reference Frame equations. The stability performance of the\nproposed approach is validated through eigenvalue analysis in a two-source\ncase. Additionally, an LQR controller is employed to regulate capacitor\nvoltage, inverter current, and the current at the Point of Common Coupling\n(PCC). The proposed controller surpasses existing approaches in terms of\naccuracy and distortion reduction under abrupt grid impedance increases.\nMoreover, drop compensation is integrated into the Kalman Filter to enhance\nrobustness of the inverter against external oscillation disturbances from a\nsynchronous machine connected to the GFL via the PCC. The results in this paper\ndemonstrate substantial improvement in oscillation damping across a range of\nfrequencies compared with published research works.", "comment": "8 pages, 8 figures, journal", "pdf_url": "http://arxiv.org/pdf/2507.01300v1", "categories": ["eess.SY", "cs.SY"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01300v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "使用卡尔曼滤波器和LQR电流控制器将分布式能源逆变器同步到弱电网", "tldr": "本文提出了一种使用基于卡尔曼滤波器的高级角度估计和LQR控制器的方法，以取代并网型逆变器在弱电网中的锁相环，从而提高稳定性和性能。", "motivation": "在弱电网中，并网型（GFL）逆变器的动态性能会受到锁相环（PLL）的显著影响，导致电网源相角估计不准确从而引发不稳定。", "method": "该方法用基于先进角度估计的卡尔曼滤波器取代了锁相环（PLL），并包含了GFL的线性二次调节器（LQR）控制器。卡尔曼滤波器将电网阻抗项作为状态空间模型的一部分，用于使用α-β同步参考系方程估计瞬时相角。LQR控制器用于调节电容器电压、逆变器电流以及公共耦合点（PCC）处的电流。此外，压降补偿被集成到卡尔曼滤波器中。通过双源情况下的特征值分析验证了所提方法的稳定性。", "result": "所提出的控制器在电网阻抗突然增加的情况下，在精度和失真抑制方面超越了现有方法。与已发表的研究工作相比，在各种频率下，振荡阻尼都有显著改善。", "conclusion": "本文提出的基于卡尔曼滤波器和LQR电流控制器的方法，通过鲁棒的角度估计和参数调节，显著提高了并网型逆变器在弱电网中的稳定性、精度和振荡阻尼性能。", "translation": "并网型（GFL）逆变器常用于将可再生能源并入电网。然而，在弱电网中，GFL模型的动态性能会受到锁相环（PLL）的显著影响，导致电网源相角估计不准确从而引发不稳定。本文提出的方法用基于先进角度估计的卡尔曼滤波器取代了PLL，并包含了GFL的线性二次调节器（LQR）控制器。该方法能够鲁棒地将电网阻抗项作为状态空间模型的一部分纳入卡尔曼滤波器方法中，以使用α-β同步参考系方程估计瞬时相角。通过双源情况下的特征值分析验证了所提方法的稳定性。此外，还采用LQR控制器来调节电容器电压、逆变器电流以及公共耦合点（PCC）处的电流。在电网阻抗突然增加的情况下，所提出的控制器在精度和失真抑制方面超越了现有方法。此外，压降补偿被集成到卡尔曼滤波器中，以增强逆变器对通过PCC连接到GFL的同步电机外部振荡干扰的鲁棒性。本文结果表明，与已发表的研究工作相比，在各种频率下，振荡阻尼都有显著改善。", "summary": "本文旨在解决并网型（GFL）逆变器在弱电网中因传统锁相环（PLL）引起的不稳定性问题。论文提出用基于高级角度估计的卡尔曼滤波器取代PLL，该滤波器能鲁棒地将电网阻抗纳入模型以精确估计相角。同时，集成了线性二次调节器（LQR）控制器来调节关键电气参数，并加入了压降补偿以增强对外部干扰的鲁棒性。该方法通过特征值分析得到验证，结果表明其在精度、失真抑制和振荡阻尼方面均优于现有方法。", "keywords": "卡尔曼滤波器, LQR控制器, 并网型逆变器, 弱电网, 相角估计", "comments": "该论文提出了一种创新方法，通过用更鲁棒的基于卡尔曼滤波器的角度估计和LQR控制器取代传统PLL，以提高GFL逆变器在弱电网条件下的稳定性和性能。将电网阻抗项和压降补偿纳入考虑，直接解决了弱电网同步中的关键挑战。通过特征值分析进行的验证以及与现有工作的比较，突显了所提出方法的实际相关性和有效性。"}}
{"id": "2507.01259", "title": "GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant", "authors": ["Michał Matak", "Jarosław A. Chudziak"], "summary": "In this paper we discuss the capability of large language models to base\ntheir answer and provide proper references when dealing with legal matters of\nnon-english and non-chinese speaking country. We discuss the history of legal\ninformation retrieval, the difference between case law and statute law, its\nimpact on the legal tasks and analyze the latest research in this field. Basing\non that background we introduce gAIus, the architecture of the cognitive\nLLM-based agent, whose responses are based on the knowledge retrieved from\ncertain legal act, which is Polish Civil Code. We propose a retrieval mechanism\nwhich is more explainable, human-friendly and achieves better results than\nembedding-based approaches. To evaluate our method we create special dataset\nbased on single-choice questions from entrance exams for law apprenticeships\nconducted in Poland. The proposed architecture critically leveraged the\nabilities of used large language models, improving the gpt-3.5-turbo-0125 by\n419%, allowing it to beat gpt-4o and lifting gpt-4o-mini score from 31% to 86%.\nAt the end of our paper we show the possible future path of research and\npotential applications of our findings.", "comment": "8 pages, 2 figures, presented at ICAART 2025, in proceedings of the\n  17th International Conference on Agents and Artificial Intelligence - Volume\n  3: ICAART", "pdf_url": "http://arxiv.org/pdf/2507.01259v1", "categories": ["cs.CL", "cs.AI"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01259v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "GAIus：结合生成式AI与法律条款检索的知识型助手", "tldr": "GAIus结合了生成式AI与法律条款检索，旨在解决大型语言模型在非英语/非中文法律事务中提供准确引用的问题，并在波兰法律考试数据集上展示了显著的性能提升。", "motivation": "解决大型语言模型在处理非英语、非中文国家的法律事务时，提供基于准确引用的答案的能力不足的问题。", "method": "论文介绍了名为gAIus的认知型LLM代理架构，其回复基于从特定法律文件（如波兰民法典）中检索到的知识。他们提出了一种比基于嵌入的方法更具解释性、更人性化且效果更好的检索机制。通过波兰法律学徒入学考试的单选题创建了一个专用数据集进行评估。", "result": "所提出的架构显著提升了大型语言模型的能力，将gpt-3.5-turbo-0125的性能提高了419%，使其超越了gpt-4o，并将gpt-4o-mini的分数从31%提升到86%。", "conclusion": "论文展示了未来研究方向和潜在应用。", "translation": "在本文中，我们讨论了大型语言模型在处理非英语和非中文国家的法律事务时，能够基于其答案并提供适当引用的能力。我们讨论了法律信息检索的历史、判例法和成文法之间的区别及其对法律任务的影响，并分析了该领域的最新研究。在此背景下，我们介绍了gAIus，这是一种基于认知的LLM代理架构，其响应基于从特定法律法规（即波兰民法典）中检索到的知识。我们提出了一种比基于嵌入的方法更具解释性、更人性化且效果更好的检索机制。为了评估我们的方法，我们根据波兰法律学徒入学考试的单选题创建了一个特殊数据集。所提出的架构充分利用了所使用的大型语言模型的能力，将gpt-3.5-turbo-0125的性能提高了419%，使其能够超越gpt-4o，并将gpt-4o-mini的分数从31%提升到86%。在论文的最后，我们展示了未来可能的研究路径和我们发现的潜在应用。", "summary": "GAIus是一个结合生成式AI和法律条款检索的知识型助手，旨在解决大型语言模型在非英语/非中文法律事务中提供准确引用的挑战。该系统引入了一种基于波兰民法典的认知型LLM代理架构，并提出了一种比传统嵌入方法更优、更具解释性的检索机制。通过在波兰法律学徒考试数据集上的评估，GAIus显著提升了GPT模型性能，例如将gpt-3.5-turbo-0125的性能提升419%，并使gpt-4o-mini的分数从31%提高到86%，甚至超越了gpt-4o。", "keywords": "生成式AI, 法律条款检索, 知识型助手, 大型语言模型, 波兰民法典", "comments": "这篇论文通过GAIus系统，有效解决了LLM在处理特定语言（非英非中）法律事务中引用准确性的问题，尤其在波兰法律领域展现了显著效果。其创新点在于提出了一个更具解释性且效果优于传统嵌入方法的检索机制，并且通过专门的法律考试数据集验证了其强大的性能提升，展示了生成式AI在专业领域知识检索和应用中的巨大潜力。"}}
{"id": "2507.01775", "title": "A Deterministic Partition Tree and Applications", "authors": ["Haitao Wang"], "summary": "In this paper, we present a deterministic variant of Chan's randomized\npartition tree [Discret. Comput. Geom., 2012]. This result leads to numerous\napplications. In particular, for $d$-dimensional simplex range counting (for\nany constant $d \\ge 2$), we construct a data structure using $O(n)$ space and\n$O(n^{1+\\epsilon})$ preprocessing time, such that each query can be answered in\n$o(n^{1-1/d})$ time (specifically, $O(n^{1-1/d} / \\log^{\\Omega(1)} n)$ time),\nthereby breaking an $\\Omega(n^{1-1/d})$ lower bound known for the semigroup\nsetting. Notably, our approach does not rely on any bit-packing techniques. We\nalso obtain deterministic improvements for several other classical problems,\nincluding simplex range stabbing counting and reporting, segment intersection\ndetection, counting and reporting, ray-shooting among segments, and more.\nSimilar to Chan's original randomized partition tree, we expect that additional\napplications will emerge in the future, especially in situations where\ndeterministic results are preferred.", "comment": "To appear in ESA 2025", "pdf_url": "http://arxiv.org/pdf/2507.01775v1", "categories": ["cs.CG", "cs.DS"], "cate": "cs.CG", "url": "http://arxiv.org/abs/2507.01775v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "确定性划分树及其应用", "tldr": "本文提出了一种确定性划分树，它是Chan随机划分树的变体，并在d维单纯形范围计数等多个几何问题上实现了显著的确定性性能提升，突破了现有下界。", "motivation": "本文旨在提出Chan随机划分树的确定性变体，以在计算几何问题中提供确定性的性能保证，特别是在需要确定性结果的场景中。", "method": "本文提出了一种确定性划分树，作为Chan随机划分树的确定性变体。", "result": "对于任意常数d≥2的d维单纯形范围计数，构建了一个使用O(n)空间和O(n^(1+epsilon))预处理时间的数据结构，查询时间为o(n^(1-1/d))（具体为O(n^(1-1/d) / log^Ω(1) n)），突破了半群设置下已知的Ω(n^(1-1/d))下界。该方法不依赖于任何位打包技术。此外，还获得了其他几个经典问题的确定性改进，包括单纯形范围刺穿计数和报告、线段交集检测、计数和报告、射线与线段相交等。", "conclusion": "本文提出的确定性划分树在多种计算几何问题上实现了显著的确定性性能提升，特别是在单纯形范围计数方面突破了现有下界。预计未来将有更多应用，尤其是在偏好确定性结果的场景中。", "translation": "在本文中，我们提出了Chan随机划分树[Discret. Comput. Geom., 2012]的一个确定性变体。这项成果带来了许多应用。特别是，对于d维单纯形范围计数（对于任意常数d≥2），我们构建了一个使用O(n)空间和O(n^(1+ε))预处理时间的数据结构，使得每个查询可以在o(n^(1-1/d))时间内回答（具体来说是O(n^(1-1/d) / log^Ω(1) n)时间），从而突破了半群设置下已知的Ω(n^(1-1/d))下界。值得注意的是，我们的方法不依赖于任何位打包技术。我们还获得了其他几个经典问题的确定性改进，包括单纯形范围刺穿计数和报告、线段交集检测、计数和报告、射线与线段相交等。与Chan最初的随机划分树类似，我们预计未来会出现更多应用，尤其是在偏好确定性结果的情况下。", "summary": "本文介绍了一种确定性划分树，作为Chan随机划分树的确定性变体。该方法在d维单纯形范围计数问题上取得了显著进展，构建了一个高效的数据结构，实现了优于已知下界的查询时间，并且不依赖于位打包技术。此外，该确定性方法还改进了其他多个经典的几何问题，预示着其在需要确定性结果的领域具有广泛的应用潜力。", "keywords": "确定性划分树, 单纯形范围计数, 计算几何, 数据结构, 确定性算法", "comments": "该论文的关键创新在于将Chan的随机划分树确定化，从而在不依赖随机性的情况下，在计算几何领域实现了显著的性能提升。它突破了单纯形范围计数等问题的已知下界，并且不使用位打包技术，这表明了其方法在理论和实践上的鲁棒性。其重要性在于为过去依赖随机性的问题提供了确定性解决方案，这对于需要严格性能保证的应用至关重要。"}}
{"id": "2507.01434", "title": "An Optimal Least-Square Solver For Scaled Partial-Isometric Linear Systems", "authors": ["Suvendu Kar", "Murugesan Venkatapathi"], "summary": "We present an $O(mn)$ direct least-squares solver for $m \\times n$ linear\nsystems with a scaled partial isometry. The proposed algorithm is also useful\nwhen the system is block diagonal and each block is a scaled partial isometry\nwith distinct scaling factors. We also include numerical experiments as a\ndemonstration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01434v1", "categories": ["math.NA", "cs.NA"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01434v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "针对缩放局部等距线性系统的最优最小二乘求解器", "tldr": "提出了一种针对缩放局部等距线性系统的$O(mn)$直接最小二乘求解器，对分块对角系统也有效，并进行了数值实验。", "motivation": "解决带有缩放局部等距的线性系统问题，提供一个高效的最小二乘求解器。", "method": "提出了一种$O(mn)$的直接最小二乘求解器。该算法也适用于分块对角且每个块都是具有不同缩放因子的缩放局部等距的系统。", "result": "提出了一个$O(mn)$复杂度的直接最小二乘求解器。该算法在系统为分块对角且每个块为具有不同缩放因子的缩放局部等距时也有效。进行了数值实验以作演示。", "conclusion": "开发了一个高效且通用的最小二乘求解器，适用于特定类型的线性系统，并通过实验验证了其有效性。", "translation": "我们提出了一种针对$m \\times n$型带有缩放局部等距线性系统的$O(mn)$直接最小二乘求解器。所提出的算法在系统为分块对角且每个块都是具有不同缩放因子的缩放局部等距时也很有用。我们还包括了数值实验作为演示。", "summary": "这篇论文介绍了一种针对带有缩放局部等距的$m \\times n$线性系统的$O(mn)$直接最小二乘求解器。该算法还适用于分块对角系统，其中每个块都是具有不同缩放因子的缩放局部等距。作者通过数值实验验证了所提出方法的有效性。", "keywords": "最小二乘, 缩放局部等距, 线性系统, 求解器, 直接法", "comments": "这篇论文提出了一种计算复杂度为$O(mn)$的直接求解器，这对于处理大规模线性系统可能具有重要意义。其创新之处在于能够处理带有缩放局部等距的系统，并且对分块对角情况的适用性增加了其实用性。"}}
{"id": "2507.01349", "title": "IdolSongsJp Corpus: A Multi-Singer Song Corpus in the Style of Japanese Idol Groups", "authors": ["Hitoshi Suda", "Junya Koguchi", "Shunsuke Yoshida", "Tomohiko Nakamura", "Satoru Fukayama", "Jun Ogata"], "summary": "Japanese idol groups, comprising performers known as \"idols,\" are an\nindispensable part of Japanese pop culture. They frequently appear in live\nconcerts and television programs, entertaining audiences with their singing and\ndancing. Similar to other J-pop songs, idol group music covers a wide range of\nstyles, with various types of chord progressions and instrumental arrangements.\nThese tracks often feature numerous instruments and employ complex mastering\ntechniques, resulting in high signal loudness. Additionally, most songs include\na song division (utawari) structure, in which members alternate between singing\nsolos and performing together. Hence, these songs are well-suited for\nbenchmarking various music information processing techniques such as singer\ndiarization, music source separation, and automatic chord estimation under\nchallenging conditions. Focusing on these characteristics, we constructed a\nsong corpus titled IdolSongsJp by commissioning professional composers to\ncreate 15 tracks in the style of Japanese idol groups. This corpus includes not\nonly mastered audio tracks but also stems for music source separation, dry\nvocal tracks, and chord annotations. This paper provides a detailed description\nof the corpus, demonstrates its diversity through comparisons with real-world\nidol group songs, and presents its application in evaluating several music\ninformation processing techniques.", "comment": "Accepted at ISMIR 2025", "pdf_url": "http://arxiv.org/pdf/2507.01349v1", "categories": ["eess.AS", "cs.SD"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01349v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "IdolSongsJp语料库：一种日本偶像团体风格的多歌手歌曲语料库", "tldr": "构建了一个名为IdolSongsJp的多歌手歌曲语料库，包含15首日本偶像团体风格的原创歌曲，用于音乐信息处理技术的基准测试。", "motivation": "日本偶像团体的歌曲具有复杂的特点，如多乐器、高响度、复杂的编曲和独特的歌割（utawari）结构，使其成为评估歌手分离、音乐源分离和自动和弦估计等音乐信息处理技术在挑战性条件下的理想基准。", "method": "通过委托专业作曲家创作15首日本偶像团体风格的歌曲，构建了IdolSongsJp语料库。该语料库不仅包含混音完成的音轨，还包括用于音乐源分离的分轨、干声人声轨和和弦标注。", "result": "成功构建了IdolSongsJp语料库，并通过与真实偶像团体歌曲的比较展示了其多样性，并展示了其在评估多种音乐信息处理技术方面的应用。", "conclusion": "本文详细描述了IdolSongsJp语料库，展示了其多样性，并呈现了其在评估多种音乐信息处理技术方面的应用。该语料库为在挑战性条件下进行音乐信息处理研究提供了宝贵的资源。", "translation": "日本偶像团体，由被称为“偶像”的表演者组成，是日本流行文化不可或缺的一部分。他们经常出现在现场音乐会和电视节目中，通过歌唱和舞蹈娱乐观众。与其他J-pop歌曲类似，偶像团体音乐涵盖了广泛的风格，具有各种类型的和弦进行和乐器编排。这些音轨通常包含大量乐器并采用复杂的母带处理技术，导致高信号响度。此外，大多数歌曲都包含歌割（utawari）结构，其中成员轮流独唱和共同表演。因此，这些歌曲非常适合在挑战性条件下对各种音乐信息处理技术进行基准测试，例如歌手分离、音乐源分离和自动和弦估计。针对这些特点，我们委托专业作曲家创作了15首日本偶像团体风格的歌曲，构建了一个名为IdolSongsJp的歌曲语料库。该语料库不仅包含混音完成的音轨，还包括用于音乐源分离的分轨、干声人声轨和和弦标注。本文详细描述了该语料库，通过与真实偶像团体歌曲的比较展示了其多样性，并展示了其在评估多种音乐信息处理技术方面的应用。", "summary": "本文介绍了IdolSongsJp语料库的构建，该语料库是一个包含15首原创日本偶像团体风格歌曲的多歌手歌曲集合。鉴于偶像歌曲在编曲、多乐器、高响度和歌割结构方面的复杂性，该语料库旨在为歌手分离、音乐源分离和自动和弦估计等音乐信息处理（MIP）技术提供具有挑战性的基准测试数据。语料库包含了混音完成的音轨、分轨、干声人声轨和和弦标注。论文详细描述了语料库，展示了其多样性，并探讨了其在MIP技术评估中的应用。", "keywords": "日本偶像团体, 歌曲语料库, 音乐信息处理, 歌手分离, 音乐源分离", "comments": "该论文的创新之处在于专门为日本偶像团体歌曲的复杂性构建了一个包含多源数据的语料库，这对于在实际挑战性条件下评估音乐信息处理技术具有重要意义。它填补了现有语料库在处理此类特定音乐风格和多歌手互动方面的空白。"}}
{"id": "2507.01063", "title": "FAIR-MATCH: A Multi-Objective Framework for Bias Mitigation in Reciprocal Dating Recommendations", "authors": ["Madhav Kotecha"], "summary": "Online dating platforms have fundamentally transformed the formation of\nromantic relationships, with millions of users worldwide relying on algorithmic\nmatching systems to find compatible partners. However, current recommendation\nsystems in dating applications suffer from significant algorithmic\ndeficiencies, including but not limited to popularity bias, filter bubble\neffects, and inadequate reciprocity modeling that limit effectiveness and\nintroduce harmful biases. This research integrates foundational work with\nrecent empirical findings to deliver a detailed analysis of dating app\nrecommendation systems, highlighting key issues and suggesting research-backed\nsolutions. Through analysis of reciprocal recommendation frameworks, fairness\nevaluation metrics, and industry implementations, we demonstrate that current\nsystems achieve modest performance with collaborative filtering reaching 25.1\\%\nwhile reciprocal methods achieve 28.7\\%. Our proposed mathematical framework\naddresses these limitations through enhanced similarity measures,\nmulti-objective optimization, and fairness-aware algorithms that maintain\ncompetitive accuracy while improving demographic representation to reduce\nalgorithmic bias.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01063v1", "categories": ["cs.IR", "cs.AI"], "cate": "cs.IR", "url": "http://arxiv.org/abs/2507.01063v1", "date": "2025-06-30", "updated": "2025-06-30", "AI": {"title_translation": "FAIR-MATCH：一种用于互惠约会推荐中偏见缓解的多目标框架", "tldr": "本文提出了一种名为FAIR-MATCH的多目标数学框架，旨在解决在线约会推荐系统中的算法偏见，同时保持推荐准确性并提高人口统计学代表性。", "motivation": "当前的在线约会推荐系统存在显著的算法缺陷，包括流行度偏见、过滤气泡效应和不足的互惠建模，这些问题限制了有效性并引入了有害偏见。", "method": "本研究整合了基础工作和最新经验发现，详细分析了约会应用推荐系统，并提出了研究支持的解决方案。通过分析互惠推荐框架、公平性评估指标和行业实现，提出了一种数学框架，通过增强相似性度量、多目标优化和公平感知算法来解决现有局限性。", "result": "现有系统表现平平，协同过滤达到25.1%的性能，互惠方法达到28.7%。本文提出的框架在保持竞争性准确性的同时，提高了人口统计学代表性，从而减少了算法偏见。", "conclusion": "本文提出的FAIR-MATCH多目标框架能够有效缓解在线约会推荐系统中的算法偏见，同时保持推荐准确性，为构建更公平的匹配系统提供了新的途径。", "translation": "在线约会平台从根本上改变了浪漫关系的形成，全球数百万用户依赖算法匹配系统来寻找兼容的伴侣。然而，约会应用中当前的推荐系统存在显著的算法缺陷，包括但不限于流行度偏见、过滤气泡效应和不足的互惠建模，这些问题限制了有效性并引入了有害偏见。本研究整合了基础工作和最新经验发现，对约会应用推荐系统进行了详细分析，强调了关键问题并提出了研究支持的解决方案。通过对互惠推荐框架、公平性评估指标和行业实现的分析，我们证明了当前系统表现平平，协同过滤达到25.1%的性能，而互惠方法达到28.7%。我们提出的数学框架通过增强相似性度量、多目标优化和公平感知算法来解决这些局限性，这些算法在保持竞争性准确性的同时，提高了人口统计学代表性，从而减少了算法偏见。", "summary": "本文针对在线约会推荐系统中存在的流行度偏见、过滤气泡和互惠建模不足等算法缺陷，提出了一种名为FAIR-MATCH的多目标数学框架。该框架通过增强相似性度量、多目标优化和公平感知算法，旨在在保持推荐准确性的同时，提高人口统计学代表性并减少算法偏见。研究分析了现有系统的性能（协同过滤25.1%，互惠方法28.7%），并表明所提出的框架能够有效改善公平性。", "keywords": "约会推荐, 偏见缓解, 多目标优化, 公平性, 互惠性", "comments": "该论文创新性地将多目标优化应用于约会推荐系统中的偏见缓解，特别关注互惠性和公平性。其重要性在于解决了在线约会平台中普遍存在的算法偏见问题，这对于用户体验和社会公平具有重要意义。通过量化当前系统的不足并提出具体的数学框架，为未来公平推荐系统的设计提供了宝贵的见解。"}}
{"id": "2507.01052", "title": "Long-Sequence Memory with Temporal Kernels and Dense Hopfield Functionals", "authors": ["Ahmed Farooq"], "summary": "In this study we introduce a novel energy functional for long-sequence\nmemory, building upon the framework of dense Hopfield networks which achieves\nexponential storage capacity through higher-order interactions. Building upon\nearlier work on long-sequence Hopfield memory models, we propose a temporal\nkernal $K(m, k)$ to incorporate temporal dependencies, enabling efficient\nsequential retrieval of patterns over extended sequences. We demonstrate the\nsuccessful application of this technique for the storage and sequential\nretrieval of movies frames which are well suited for this because of the high\ndimensional vectors that make up each frame creating enough variation between\neven sequential frames in the high dimensional space. The technique has\napplications in modern transformer architectures, including efficient\nlong-sequence modeling, memory augmentation, improved attention with temporal\nbias, and enhanced handling of long-term dependencies in time-series data. Our\nmodel offers a promising approach to address the limitations of transformers in\nlong-context tasks, with potential implications for natural language\nprocessing, forecasting, and beyond.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01052v1", "categories": ["cs.LG", "cs.AI", "cs.NE"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01052v1", "date": "2025-06-27", "updated": "2025-06-27", "AI": {"title_translation": "长序列记忆与时间核和密集霍普菲尔德泛函", "tldr": "本研究提出了一种结合时间核和密集霍普菲尔德网络的新型能量泛函，用于长序列记忆，能够高效存储和顺序检索模式，并有望应用于现代Transformer架构以解决长上下文任务的限制。", "motivation": "现有Transformer架构在处理长上下文任务时存在局限性，作者旨在通过引入一种新的长序列记忆模型来解决这一问题，以实现高效的长序列建模、记忆增强、改进的带时间偏差的注意力以及增强对时间序列数据中长期依赖的处理。", "method": "本研究在密集霍普菲尔德网络框架的基础上，引入了一种新颖的能量泛函，用于长序列记忆。该方法结合了时间核$K(m, k)$来整合时间依赖性，从而实现对扩展序列中模式的高效顺序检索。", "result": "该技术成功应用于电影帧的存储和顺序检索，电影帧的高维向量特性使得即使是连续帧之间也存在足够的变异。该技术有望应用于现代Transformer架构，包括高效长序列建模、记忆增强、改进的带时间偏差的注意力，以及增强对时间序列数据中长期依赖的处理。", "conclusion": "该模型为解决Transformer在长上下文任务中的局限性提供了一种有前景的方法，并对自然语言处理、预测等领域具有潜在影响。", "translation": "本研究引入了一种用于长序列记忆的新型能量泛函，该泛函建立在密集霍普菲尔德网络框架之上，通过高阶交互实现指数级存储容量。在早期关于长序列霍普菲尔德记忆模型工作的基础上，我们提出了一个时间核$K(m, k)$来整合时间依赖性，从而实现对扩展序列中模式的高效顺序检索。我们演示了该技术在电影帧存储和顺序检索方面的成功应用，电影帧非常适合这种应用，因为构成每个帧的高维向量在甚至连续帧之间的高维空间中也产生了足够的变异。该技术在现代Transformer架构中具有应用前景，包括高效长序列建模、记忆增强、带时间偏差的改进注意力以及增强对时间序列数据中长期依赖的处理。我们的模型为解决Transformer在长上下文任务中的局限性提供了一种有前景的方法，对自然语言处理、预测等领域具有潜在影响。", "summary": "本研究提出了一种基于密集霍普菲尔德网络和新型能量泛函的长序列记忆模型，通过引入时间核$K(m, k)$以整合时间依赖性，从而实现对扩展序列中模式的高效顺序检索。该技术成功应用于电影帧的存储与检索，并有望应用于Transformer架构，以解决长上下文任务的限制，对自然语言处理、预测等领域具有重要意义。", "keywords": "长序列记忆, 霍普菲尔德网络, 时间核, Transformer, 序列检索", "comments": "该论文的创新点在于将时间核引入到密集霍普菲尔德网络框架中，以解决长序列记忆和Transformer在长上下文任务中的限制。其重要性在于为高效长序列建模、记忆增强和处理长期依赖提供了新的思路和方法，具有广泛的应用前景。"}}
{"id": "2507.01489", "title": "Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning", "authors": ["Yanfei Zhang"], "summary": "Large Language Models (LLMs) have emerged as one of the most significant\ntechnological advancements in artificial intelligence in recent years. Their\nability to understand, generate, and reason with natural language has\ntransformed how we interact with AI systems. With the development of LLM-based\nagents and reinforcement-learning-based reasoning models, the study of applying\nreinforcement learning in agent frameworks has become a new research focus.\nHowever, all previous studies face the challenge of deciding the tool calling\nprocess and the reasoning process simultaneously, and the chain of reasoning\nwas solely relied on the unprocessed raw result with redundant information and\nsymbols unrelated to the task from the tool, which impose a heavy burden on the\nmodel's capability to reason. Therefore, in our research, we proposed a\nhierarchical framework Agent-as-tool that detach the tool calling process and\nthe reasoning process, which enables the model to focus on the verbally\nreasoning process while the tool calling process is handled by another agent.\nOur work had achieved comparable results with only a slight reinforcement\nfine-tuning on 180 samples, and had achieved exceptionally well performance in\nBamboogle with 63.2% of exact match and 75.2% in cover exact match, exceeding\nSearch-R1 by 4.8% in exact match and 3.2% in cover exact match.", "comment": "12 pages", "pdf_url": "http://arxiv.org/pdf/2507.01489v1", "categories": ["cs.AI", "cs.MA"], "cate": "cs.AI", "url": "http://arxiv.org/abs/2507.01489v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "代理即工具：一项关于强化学习分层决策的研究", "tldr": "本文提出了一种名为“代理即工具”的分层强化学习框架，用于大型语言模型（LLM）代理，通过分离工具调用和推理过程来减轻模型的推理负担，并在Bamboogle基准测试中取得了优异性能。", "motivation": "以往的研究在处理大型语言模型（LLM）代理时，面临同时决策工具调用和推理过程的挑战，且推理链过度依赖工具输出的未经处理的原始结果，这些冗余信息和与任务无关的符号给模型的推理能力带来了沉重负担。", "method": "研究提出了一种名为“代理即工具”的分层框架，该框架将工具调用过程和推理过程分离。这使得模型能够专注于口头推理过程，而工具调用过程则由另一个代理处理。", "result": "该工作仅通过对180个样本进行少量强化微调就取得了可比较的结果。在Bamboogle基准测试中表现出色，精确匹配率达到63.2%，覆盖精确匹配率达到75.2%，分别比Search-R1高出4.8%和3.2%。", "conclusion": "通过将工具调用和推理过程解耦，所提出的“代理即工具”分层框架有效减轻了模型负担，并在LLM代理的复杂决策任务中取得了显著的性能提升。", "translation": "大型语言模型（LLM）已成为近年来人工智能领域最重要的技术进步之一。它们理解、生成和推理自然语言的能力改变了我们与AI系统交互的方式。随着基于LLM的代理和基于强化学习的推理模型的发展，将强化学习应用于代理框架的研究已成为新的研究焦点。然而，所有先前的研究都面临同时决策工具调用过程和推理过程的挑战，并且推理链完全依赖于工具输出的未经处理的原始结果，这些结果包含冗余信息和与任务无关的符号，给模型的推理能力带来了沉重负担。因此，在我们的研究中，我们提出了一种名为“代理即工具”的分层框架，该框架将工具调用过程和推理过程分离，这使得模型能够专注于口头推理过程，而工具调用过程则由另一个代理处理。我们的工作仅通过对180个样本进行少量强化微调就取得了可比较的结果，并且在Bamboogle中取得了非常好的性能，精确匹配率为63.2%，覆盖精确匹配率为75.2%，分别超过Search-R1 4.8%和3.2%。", "summary": "本文提出了一种名为“代理即工具”的分层强化学习框架，旨在解决大型语言模型（LLM）代理在同时处理工具调用和推理时面临的挑战，以及对原始、冗余工具输出的依赖问题。该框架通过解耦工具调用和推理过程，使得一个代理专注于工具调用，另一个代理专注于口头推理，从而有效减轻了模型的推理负担。实验结果表明，该方法在少量样本上进行微调后即可获得可比较的结果，并在Bamboogle基准测试中取得了显著优于现有方法的性能。", "keywords": "大型语言模型, 强化学习, 代理, 分层决策, 工具调用", "comments": "该论文的创新之处在于提出了LLM代理分层决策的理念，特别是将工具调用与推理过程分离。这种方法通过减轻推理组件的认知负荷，解决了先前方法的一个关键限制，这对于提高基于LLM的代理在需要外部工具的复杂任务中的效率和鲁棒性至关重要。"}}
{"id": "2507.01513", "title": "SafePTR: Token-Level Jailbreak Defense in Multimodal LLMs via Prune-then-Restore Mechanism", "authors": ["Beitao Chen", "Xinyu Lyu", "Lianli Gao", "Jingkuan Song", "Heng Tao Shen"], "summary": "By incorporating visual inputs, Multimodal Large Language Models (MLLMs)\nextend LLMs to support visual reasoning. However, this integration also\nintroduces new vulnerabilities, making MLLMs susceptible to multimodal\njailbreak attacks and hindering their safe deployment.Existing defense methods,\nincluding Image-to-Text Translation, Safe Prompting, and Multimodal Safety\nTuning, attempt to address this by aligning multimodal inputs with LLMs'\nbuilt-in safeguards.Yet, they fall short in uncovering root causes of\nmultimodal vulnerabilities, particularly how harmful multimodal tokens trigger\njailbreak in MLLMs? Consequently, they remain vulnerable to text-driven\nmultimodal jailbreaks, often exhibiting overdefensive behaviors and imposing\nheavy training overhead.To bridge this gap, we present an comprehensive\nanalysis of where, how and which harmful multimodal tokens bypass safeguards in\nMLLMs. Surprisingly, we find that less than 1% tokens in early-middle layers\nare responsible for inducing unsafe behaviors, highlighting the potential of\nprecisely removing a small subset of harmful tokens, without requiring safety\ntuning, can still effectively improve safety against jailbreaks. Motivated by\nthis, we propose Safe Prune-then-Restore (SafePTR), an training-free defense\nframework that selectively prunes harmful tokens at vulnerable layers while\nrestoring benign features at subsequent layers.Without incurring additional\ncomputational overhead, SafePTR significantly enhances the safety of MLLMs\nwhile preserving efficiency. Extensive evaluations across three MLLMs and five\nbenchmarks demonstrate SafePTR's state-of-the-art performance in mitigating\njailbreak risks without compromising utility.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01513v1", "categories": ["cs.CR", "cs.CV"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01513v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "SafePTR：通过剪枝-恢复机制在多模态大型语言模型中进行令牌级越狱防御", "tldr": "SafePTR通过选择性剪枝有害令牌并恢复良性特征，为多模态LLMs提供无需训练的越狱防御，显著提高安全性。", "motivation": "多模态大型语言模型（MLLMs）易受多模态越狱攻击，现有防御方法未能揭示根本原因，对文本驱动的越狱仍脆弱，且存在过度防御和高训练开销。", "method": "本文提出了Safe Prune-then-Restore (SafePTR)，一个无需训练的防御框架。它通过在脆弱层选择性地剪枝有害令牌，同时在后续层恢复良性特征来工作。", "result": "研究发现，早期-中期层中不到1%的令牌是导致不安全行为的原因。SafePTR在三个MLLMs和五个基准测试中展现出最先进的性能，显著增强了MLLMs的安全性，同时保持了效率，且无额外计算开销。", "conclusion": "SafePTR提供了一种有效、高效且无需训练的解决方案，能够缓解多模态LLMs中的越狱风险，同时不损害其效用。", "translation": "通过整合视觉输入，多模态大型语言模型（MLLMs）将LLMs扩展到支持视觉推理。然而，这种整合也引入了新的漏洞，使得MLLMs容易受到多模态越狱攻击，并阻碍了它们的安全部署。现有的防御方法，包括图像到文本翻译、安全提示和多模态安全调优，试图通过将多模态输入与LLMs内置的安全措施对齐来解决这个问题。然而，它们未能揭示多模态漏洞的根本原因，特别是“有害多模态令牌如何触发MLLMs中的越狱？”。因此，它们仍然容易受到文本驱动的多模态越狱攻击，通常表现出过度防御行为并带来沉重的训练开销。为了弥补这一差距，我们对有害多模态令牌在MLLMs中如何、在哪里以及哪些绕过安全措施进行了全面分析。令人惊讶的是，我们发现早期-中期层中不到1%的令牌导致了不安全行为，这突出表明精确移除一小部分有害令牌，而无需安全调优，仍然可以有效提高对抗越狱的安全性。受此启发，我们提出了Safe Prune-then-Restore (SafePTR)，一个无需训练的防御框架，它在脆弱层选择性地剪枝有害令牌，同时在后续层恢复良性特征。SafePTR在不产生额外计算开销的情况下，显著增强了MLLMs的安全性，同时保持了效率。在三个MLLMs和五个基准测试中的广泛评估表明，SafePTR在缓解越狱风险方面表现出最先进的性能，且不损害实用性。", "summary": "该论文提出了SafePTR，一种无需训练的防御框架，旨在解决多模态大型语言模型（MLLMs）面临的多模态越狱攻击。通过分析发现，MLLMs中早期-中期层中极少量（<1%）的有害令牌是导致不安全行为的根本原因。受此启发，SafePTR采用“剪枝-恢复”机制，在脆弱层选择性地移除有害令牌，并在后续层恢复良性特征。实验证明，SafePTR在不增加计算开销的情况下，显著提高了MLLMs的安全性，并在多项基准测试中展现出卓越的越狱缓解性能，同时保持了模型的实用性。", "keywords": "多模态LLMs, 越狱防御, 令牌级防御, 剪枝-恢复, SafePTR", "comments": "这篇论文的创新点在于其深入分析了多模态LLMs越狱的根本原因，并发现极少数令牌是触发不安全行为的关键。SafePTR提出的“剪枝-恢复”机制是一种新颖且无需训练的防御方法，有效避免了现有方法的训练开销和过度防御问题。其重要性在于为MLLMs的安全部署提供了高效且实用的解决方案，有望推动多模态AI的更广泛应用。"}}
{"id": "2507.01269", "title": "Advancements in Weed Mapping: A Systematic Review", "authors": ["Mohammad Jahanbakht", "Alex Olsen", "Ross Marchant", "Emilie Fillols", "Mostafa Rahimi Azghadi"], "summary": "Weed mapping plays a critical role in precision management by providing\naccurate and timely data on weed distribution, enabling targeted control and\nreduced herbicide use. This minimizes environmental impacts, supports\nsustainable land management, and improves outcomes across agricultural and\nnatural environments. Recent advances in weed mapping leverage ground-vehicle\nRed Green Blue (RGB) cameras, satellite and drone-based remote sensing combined\nwith sensors such as spectral, Near Infra-Red (NIR), and thermal cameras. The\nresulting data are processed using advanced techniques including big data\nanalytics and machine learning, significantly improving the spatial and\ntemporal resolution of weed maps and enabling site-specific management\ndecisions. Despite a growing body of research in this domain, there is a lack\nof comprehensive literature reviews specifically focused on weed mapping. In\nparticular, the absence of a structured analysis spanning the entire mapping\npipeline, from data acquisition to processing techniques and mapping tools,\nlimits progress in the field. This review addresses these gaps by\nsystematically examining state-of-the-art methods in data acquisition (sensor\nand platform technologies), data processing (including annotation and\nmodelling), and mapping techniques (such as spatiotemporal analysis and\ndecision support tools). Following PRISMA guidelines, we critically evaluate\nand synthesize key findings from the literature to provide a holistic\nunderstanding of the weed mapping landscape. This review serves as a\nfoundational reference to guide future research and support the development of\nefficient, scalable, and sustainable weed management systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01269v1", "categories": ["cs.CV", "eess.IV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01269v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "杂草测绘的进展：一项系统性综述", "tldr": "本综述系统性地审视了杂草测绘领域的最新进展，涵盖数据采集、处理和测绘技术，旨在弥补现有文献综述的不足，并为未来研究提供基础参考。", "motivation": "尽管杂草测绘领域的研究不断增长，但缺乏专门针对该领域的全面文献综述，特别是缺少对从数据采集到处理技术和测绘工具的整个测绘流程的结构化分析，这限制了该领域的发展。本综述旨在弥补这些空白。", "method": "本综述遵循PRISMA指南，系统地审查了数据采集（传感器和平台技术）、数据处理（包括标注和建模）以及测绘技术（如时空分析和决策支持工具）方面的最新方法，并批判性地评估和综合了文献中的关键发现。", "result": "本综述提供了对杂草测绘全貌的整体理解。", "conclusion": "本综述可作为指导未来研究和支持开发高效、可扩展和可持续杂草管理系统的基础参考。", "translation": "杂草测绘通过提供准确及时的杂草分布数据，在精准管理中发挥着关键作用，从而实现目标性控制并减少除草剂使用。这最大限度地减少了对环境的影响，支持可持续土地管理，并改善了农业和自然环境的成果。杂草测绘的最新进展利用了地面车辆红绿蓝（RGB）相机、卫星和无人机遥感技术，结合光谱、近红外（NIR）和热像仪等传感器。所得数据通过大数据分析和机器学习等先进技术进行处理，显著提高了杂草地图的空间和时间分辨率，并实现了针对特定地点的管理决策。尽管该领域的研究日益增多，但专门针对杂草测绘的全面文献综述却很匮乏。特别是，缺乏涵盖从数据采集到处理技术和测绘工具的整个测绘流程的结构化分析，限制了该领域的进展。本综述通过系统地审查数据采集（传感器和平台技术）、数据处理（包括标注和建模）和测绘技术（如时空分析和决策支持工具）中的最新方法来弥补这些空白。我们遵循PRISMA指南，批判性地评估和综合了文献中的关键发现，以提供对杂草测绘现状的整体理解。本综述可作为指导未来研究和支持开发高效、可扩展和可持续杂草管理系统的基础参考。", "summary": "本系统综述旨在弥补当前杂草测绘文献中缺乏全面和结构化分析的空白。它详细审视了杂草测绘的最新进展，包括数据采集（如RGB、光谱、近红外和热像仪）、数据处理（大数据分析、机器学习）和测绘技术（时空分析、决策支持工具）。通过遵循PRISMA指南，本综述综合了关键发现，为杂草测绘领域提供了整体理解，并为未来的研究和可持续杂草管理系统的发展奠定了基础。", "keywords": "杂草测绘, 系统综述, 精准农业, 遥感, 机器学习", "comments": "本文作为一篇系统性综述，填补了杂草测绘领域缺乏全面结构化分析的空白，其创新性在于对整个测绘流程的系统性梳理。其重要性体现在为精准农业中的杂草管理提供了基础性参考，有助于推动高效、可持续的杂草管理系统发展。通过遵循PRISMA指南，保证了综述的严谨性。"}}
{"id": "2507.01436", "title": "Challenges & Opportunities with LLM-Assisted Visualization Retargeting", "authors": ["Luke S. Snyder", "Chenglong Wang", "Steven Drucker"], "summary": "Despite the ubiquity of visualization examples published on the web,\nretargeting existing custom chart implementations to new datasets remains\ndifficult, time-intensive, and tedious. The adaptation process assumes author\nfamiliarity with both the implementation of the example as well as how the new\ndataset might need to be transformed to fit into the example code. With recent\nadvances in Large Language Models (LLMs), automatic adaptation of code can be\nachieved from high-level user prompts, reducing the barrier for visualization\nretargeting. To better understand how LLMs can assist retargeting and its\npotential limitations, we characterize and evaluate the performance of LLM\nassistance across multiple datasets and charts of varying complexity,\ncategorizing failures according to type and severity. In our evaluation, we\ncompare two approaches: (1) directly instructing the LLM model to fully\ngenerate and adapt code by treating code as text inputs and (2) a more\nconstrained program synthesis pipeline where the LLM guides the code\nconstruction process by providing structural information (e.g., visual\nencodings) based on properties of the example code and data. We find that both\napproaches struggle when new data has not been appropriately transformed, and\ndiscuss important design recommendations for future retargeting systems.", "comment": "5 pages, 3 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2507.01436v1", "categories": ["cs.HC"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01436v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "LLM辅助的可视化重定向的挑战与机遇", "tldr": "尽管网络上可视化示例无处不在，但将现有图表实现重新定向到新数据集仍然困难且耗时。本文探讨了大型语言模型（LLMs）如何协助可视化重定向，并通过两种方法评估了其性能，发现两者在数据未适当转换时均表现不佳，并提出了未来系统的设计建议。", "motivation": "将现有自定义图表实现重新定向到新数据集仍然困难、耗时且繁琐，这需要作者熟悉示例实现和新数据集的转换方式。随着大型语言模型（LLMs）的最新进展，可以通过高级用户提示实现代码的自动适应，从而降低可视化重定向的障碍。", "method": "我们对LLM辅助在不同复杂度的多个数据集和图表上的性能进行了表征和评估，并根据类型和严重性对失败进行了分类。我们比较了两种方法：(1) 直接指示LLM模型通过将代码视为文本输入来完全生成和适应代码；(2) 更受约束的程序合成流程，其中LLM根据示例代码和数据的属性提供结构信息（例如视觉编码）来指导代码构建过程。", "result": "我们发现两种方法在数据未适当转换时都会遇到困难。", "conclusion": "本文讨论了未来重定向系统的重要设计建议。", "translation": "尽管网络上发布的可视化示例无处不在，但将现有自定义图表实现重新定向到新数据集仍然困难、耗时且繁琐。适应过程假定作者熟悉示例的实现方式以及新数据集可能需要如何转换才能适应示例代码。随着大型语言模型（LLMs）的最新进展，可以通过高级用户提示实现代码的自动适应，从而降低可视化重定向的障碍。为了更好地理解LLMs如何辅助重定向及其潜在限制，我们对LLM辅助在不同复杂度的多个数据集和图表上的性能进行了表征和评估，并根据类型和严重性对失败进行了分类。在我们的评估中，我们比较了两种方法：(1) 直接指示LLM模型通过将代码视为文本输入来完全生成和适应代码；(2) 更受约束的程序合成流程，其中LLM根据示例代码和数据的属性提供结构信息（例如视觉编码）来指导代码构建过程。我们发现两种方法在数据未适当转换时都会遇到困难，并讨论了未来重定向系统的重要设计建议。", "summary": "本文探讨了使用大型语言模型（LLMs）辅助可视化重定向的挑战与机遇，旨在解决将现有图表适应新数据集的困难。研究评估了两种LLM辅助方法：直接代码生成与结构化程序合成。结果表明，当新数据未正确转换时，两种方法均表现出局限性。基于这些发现，论文提出了未来重定向系统的设计建议，以期降低可视化重定向的门槛。", "keywords": "LLM辅助可视化, 可视化重定向, 大型语言模型, 数据转换, 程序合成", "comments": "该研究识别了可视化重定向这一实际痛点，并探索了LLM作为解决方案的潜力。其创新之处在于对比了两种不同的LLM辅助策略，并明确指出了当前LLM在处理未转换数据时的局限性，这对于未来LLM在代码生成和数据可视化领域的应用具有重要的指导意义。"}}
{"id": "2507.01032", "title": "An Uncertainty-Aware Dynamic Decision Framework for Progressive Multi-Omics Integration in Classification Tasks", "authors": ["Nan Mu", "Hongbo Yang", "Chen Zhao"], "summary": "Background and Objective: High-throughput multi-omics technologies have\nproven invaluable for elucidating disease mechanisms and enabling early\ndiagnosis. However, the high cost of multi-omics profiling imposes a\nsignificant economic burden, with over reliance on full omics data potentially\nleading to unnecessary resource consumption. To address these issues, we\npropose an uncertainty-aware, multi-view dynamic decision framework for omics\ndata classification that aims to achieve high diagnostic accuracy while\nminimizing testing costs. Methodology: At the single-omics level, we refine the\nactivation functions of neural networks to generate Dirichlet distribution\nparameters, utilizing subjective logic to quantify both the belief masses and\nuncertainty mass of classification results. Belief mass reflects the support of\na specific omics modality for a disease class, while the uncertainty parameter\ncaptures limitations in data quality and model discriminability, providing a\nmore trustworthy basis for decision-making. At the multi omics level, we employ\na fusion strategy based on Dempster-Shafer theory to integrate heterogeneous\nmodalities, leveraging their complementarity to boost diagnostic accuracy and\nrobustness. A dynamic decision mechanism is then applied that omics data are\nincrementally introduced for each patient until either all data sources are\nutilized or the model confidence exceeds a predefined threshold, potentially\nbefore all data sources are utilized. Results and Conclusion: We evaluate our\napproach on four benchmark multi-omics datasets, ROSMAP, LGG, BRCA, and KIPAN.\nIn three datasets, over 50% of cases achieved accurate classification using a\nsingle omics modality, effectively reducing redundant testing. Meanwhile, our\nmethod maintains diagnostic performance comparable to full-omics models and\npreserves essential biological insights.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01032v1", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01032v1", "date": "2025-06-20", "updated": "2025-06-20", "AI": {"title_translation": "一种用于分类任务中渐进式多组学整合的不确定性感知动态决策框架", "tldr": "该研究提出了一种不确定性感知的动态决策框架，用于多组学数据分类，旨在在保持高诊断准确性的同时最小化测试成本，通过逐步引入组学数据并在达到置信阈值时停止。", "motivation": "高通量多组学技术在疾病机制阐明和早期诊断中具有重要价值，但其高昂的成本和对完整组学数据的过度依赖导致了巨大的经济负担和不必要的资源消耗。为解决这些问题，本研究旨在开发一种在实现高诊断准确性的同时最小化测试成本的框架。", "method": "该框架在单组学层面，通过改进神经网络的激活函数生成狄利克雷分布参数，并利用主观逻辑量化分类结果的信念质量和不确定性质量。在多组学层面，采用基于Dempster-Shafer理论的融合策略整合异构模态。此外，采用动态决策机制，渐进式地为每个患者引入组学数据，直到所有数据源被利用或模型置信度超过预设阈值。", "result": "该方法在ROSMAP、LGG、BRCA和KIPAN四个基准多组学数据集上进行了评估。在其中三个数据集中，超过50%的病例仅使用单一组学模态就实现了准确分类，有效减少了冗余测试。同时，该方法保持了与全组学模型相当的诊断性能，并保留了重要的生物学见解。", "conclusion": "本研究提出的不确定性感知动态决策框架能够有效减少多组学测试成本，同时保持与全组学模型相当的诊断性能，并保留生物学见解。", "translation": "背景与目标：高通量多组学技术已被证明在阐明疾病机制和实现早期诊断方面具有不可估量的价值。然而，多组学分析的高成本带来了显著的经济负担，过度依赖完整组学数据可能导致不必要的资源消耗。为解决这些问题，我们提出了一种不确定性感知、多视图的组学数据分类动态决策框架，旨在实现高诊断准确性的同时最小化测试成本。\n方法：在单组学层面，我们改进了神经网络的激活函数以生成狄利克雷分布参数，利用主观逻辑量化分类结果的信念质量和不确定性质量。信念质量反映了特定组学模态对疾病类别的支持，而不确定性参数则捕捉了数据质量和模型判别能力的局限性，为决策提供了更可靠的基础。在多组学层面，我们采用基于Dempster-Shafer理论的融合策略来整合异构模态，利用它们的互补性来提高诊断准确性和鲁棒性。随后应用动态决策机制，为每位患者逐步引入组学数据，直到所有数据源都被利用或模型置信度超过预设阈值，这可能在所有数据源被利用之前发生。\n结果与结论：我们在ROSMAP、LGG、BRCA和KIPAN四个基准多组学数据集上评估了我们的方法。在其中三个数据集中，超过50%的病例仅使用单一组学模态就实现了准确分类，有效减少了冗余测试。同时，我们的方法保持了与全组学模型相当的诊断性能，并保留了重要的生物学见解。", "summary": "本研究提出了一种不确定性感知的动态决策框架，用于多组学数据分类，旨在平衡诊断准确性与测试成本。该框架在单组学层面利用改进的神经网络和主观逻辑量化分类结果的信念和不确定性；在多组学层面，采用Dempster-Shafer理论融合异构数据。通过动态决策机制，逐步引入组学数据直至达到置信阈值或所有数据用尽。实验结果表明，在多个基准数据集上，该方法能在减少测试量（超过50%的病例仅用单一组学）的同时，保持与完整组学模型相当的诊断性能和生物学洞察。", "keywords": "多组学整合, 动态决策, 不确定性感知, 分类任务, 主观逻辑", "comments": "该论文提出了一种创新的动态决策框架，有效地解决了多组学数据分析中成本与诊断精度之间的权衡问题。其通过引入不确定性感知和逐步数据整合的策略，在保证诊断性能的同时显著降低了资源消耗，具有重要的实际应用价值。将主观逻辑和Dempster-Shafer理论引入多组学融合和决策过程是其主要创新点，使得决策过程更加透明和可信。"}}
{"id": "2507.01485", "title": "BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments", "authors": ["Yibo Qiu", "Zan Huang", "Zhiyu Wang", "Handi Liu", "Yiling Qiao", "Yifeng Hu", "Shu'ang Sun", "Hangke Peng", "Ronald X Xu", "Mingzhai Sun"], "summary": "Large language models (LLMs) and vision-language models (VLMs) have the\npotential to transform biological research by enabling autonomous\nexperimentation. Yet, their application remains constrained by rigid protocol\ndesign, limited adaptability to dynamic lab conditions, inadequate error\nhandling, and high operational complexity. Here we introduce BioMARS\n(Biological Multi-Agent Robotic System), an intelligent platform that\nintegrates LLMs, VLMs, and modular robotics to autonomously design, plan, and\nexecute biological experiments. BioMARS uses a hierarchical architecture: the\nBiologist Agent synthesizes protocols via retrieval-augmented generation; the\nTechnician Agent translates them into executable robotic pseudo-code; and the\nInspector Agent ensures procedural integrity through multimodal perception and\nanomaly detection. The system autonomously conducts cell passaging and culture\ntasks, matching or exceeding manual performance in viability, consistency, and\nmorphological integrity. It also supports context-aware optimization,\noutperforming conventional strategies in differentiating retinal pigment\nepithelial cells. A web interface enables real-time human-AI collaboration,\nwhile a modular backend allows scalable integration with laboratory hardware.\nThese results highlight the feasibility of generalizable, AI-driven laboratory\nautomation and the transformative role of language-based reasoning in\nbiological research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01485v1", "categories": ["cs.RO", "cs.AI", "cs.MA", "q-bio.QM"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01485v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "BioMARS：一种用于自主生物实验的多智能体机器人系统", "tldr": "BioMARS是一个集成LLM、VLM和模块化机器人的智能平台，能够自主设计、规划和执行生物实验，并在多项任务中达到或超越人工表现。", "motivation": "大型语言模型（LLMs）和视觉语言模型（VLMs）有潜力通过实现自主实验来改变生物研究，但其应用受限于僵化的协议设计、对动态实验室条件的适应性差、错误处理不足以及操作复杂性高。", "method": "BioMARS（生物多智能体机器人系统）是一个智能平台，它整合了LLMs、VLMs和模块化机器人，以自主设计、规划和执行生物实验。系统采用分层架构：生物学家代理通过检索增强生成合成协议；技术员代理将其翻译成可执行的机器人伪代码；检查员代理通过多模态感知和异常检测确保程序完整性。", "result": "BioMARS系统自主进行细胞传代和培养任务，在细胞活力、一致性和形态完整性方面达到或超过人工表现。它还支持上下文感知优化，在分化视网膜色素上皮细胞方面优于传统策略。一个网络界面实现了实时人机协作，而模块化后端允许与实验室硬件进行可扩展集成。", "conclusion": "这些结果突出了通用型AI驱动实验室自动化的可行性以及基于语言推理在生物研究中的变革性作用。", "translation": "大型语言模型（LLMs）和视觉语言模型（VLMs）有潜力通过实现自主实验来改变生物研究。然而，它们的应用仍受限于僵化的协议设计、对动态实验室条件的适应性差、错误处理不足以及操作复杂性高。本文介绍BioMARS（生物多智能体机器人系统），一个集成LLMs、VLMs和模块化机器人的智能平台，能够自主设计、规划和执行生物实验。BioMARS采用分层架构：生物学家代理通过检索增强生成合成协议；技术员代理将其翻译成可执行的机器人伪代码；检查员代理通过多模态感知和异常检测确保程序完整性。该系统自主进行细胞传代和培养任务，在细胞活力、一致性和形态完整性方面达到或超过人工表现。它还支持上下文感知优化，在分化视网膜色素上皮细胞方面优于传统策略。一个网络界面实现了实时人机协作，而模块化后端允许与实验室硬件进行可扩展集成。这些结果突出了通用型AI驱动实验室自动化的可行性以及基于语言推理在生物研究中的变革性作用。", "summary": "BioMARS是一个创新的多智能体机器人系统，旨在解决当前LLM和VLM在生物实验自动化中面临的挑战。它通过整合LLM、VLM和模块化机器人，并采用分层代理架构（生物学家、技术员、检查员代理），实现了生物实验的自主设计、规划和执行。该系统在细胞传代和培养任务中表现出色，能达到或超越人工水平，并支持上下文感知优化。BioMARS的成功展示了AI驱动实验室自动化和语言推理在生物研究中的巨大潜力。", "keywords": "多智能体系统, 机器人, 生物实验, 语言模型, 实验室自动化", "comments": "BioMARS系统在生物实验自动化领域具有显著的创新性，它通过引入多智能体分层架构，有效解决了现有LLM/VLM应用在实验室自动化中面临的适应性、错误处理和操作复杂性等痛点。其将语言模型与机器人操作相结合的能力，特别是通过Biologist、Technician和Inspector代理的协同工作，为实现通用型、智能化的生物实验室提供了可行路径。该研究的重要性在于，它不仅提升了实验效率和准确性，更可能加速生物发现的进程，为未来自动化科学研究奠定了基础。"}}
{"id": "2507.01624", "title": "Frequency-switching Array Enhanced Physical-Layer Security in Terahertz Bands: A Movable Antenna Perspective", "authors": ["Cong Zhou", "Changsheng You", "Shuo Shi", "Weidong Mei"], "summary": "In this paper, we propose a new frequency-switching array (FSA) enhanced\nphysical-layer security (PLS) system in terahertz bands, where the carrier\nfrequency can be flexibly switched and small frequency offsets can be imposed\non each antenna at Alice, so as to eliminate information wiretapping by\nundesired eavesdroppers. First, we analytically show that by flexibly\ncontrolling the carrier frequency parameters, FSAs can effectively form\nuniform/non-uniform sparse arrays, hence resembling movable antennas (MAs) in\nthe control of inter-antenna spacing and providing additional degree-of-freedom\n(DoF) in the beam control. Although the proposed FSA experiences additional\npath-gain attenuation in the received signals, it can overcome several hardware\nand signal processing issues incurred by MAs, such as limited positioning\naccuracy, considerable response latency, and demanding hardware and energy\ncost. To shed useful insights, we first consider a secrecy-guaranteed problem\nwith a null-steering constraint for which maximum ratio transmission (MRT)\nbeamformer is considered at Alice and the frequency offsets are set as uniform\nfrequency increment. Interestingly, it is shown that the proposed FSA can\nflexibly realize null-steering over Eve in both the angular domain (by tuning\ncarrier frequency) and range domain (by controlling per-antenna frequency\noffset), thereby achieving improved PLS performance. Then, for the general\ncase, we propose an efficient algorithm to solve the formulated non-convex\nproblem by using the block coordinate descent (BCD) and projected gradient\nascent (PGA) techniques. Finally, numerical results demonstrate the convergence\nof the proposed optimization algorithm and its superiority over fixed-position\narrays (FPAs) in terms of secrecy-rate performance.", "comment": "In this paper, we propose to enhance physical-layer security by using\n  a new frequency-switching array, which is equivalent to movable antennas", "pdf_url": "http://arxiv.org/pdf/2507.01624v1", "categories": ["eess.SP"], "cate": "eess.SP", "url": "http://arxiv.org/abs/2507.01624v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "太赫兹频段频率切换阵列增强的物理层安全：一种可移动天线视角", "tldr": "本文提出一种太赫兹频段的频率切换阵列（FSA）增强物理层安全（PLS）系统，通过灵活控制载波频率和天线频率偏移，实现窃听者处的零陷，提高安全性能，并克服了可移动天线（MA）的硬件限制。", "motivation": "消除太赫兹频段中非期望窃听者的信息窃听，同时克服现有可移动天线（MA）在硬件和信号处理方面的局限性（如定位精度、响应延迟、成本）。", "method": "提出一种频率切换阵列（FSA）增强的物理层安全（PLS）系统。通过灵活切换载波频率和对每个天线施加小频率偏移，实现对窃听者的零陷。分析表明FSA可形成稀疏阵列，类似于可移动天线提供额外的波束控制自由度。针对特定安全保障问题，采用最大比传输（MRT）波束成形并设置均匀频率增量。对于一般情况，提出基于块坐标下降（BCD）和投影梯度上升（PGA）的高效算法。", "result": "所提出的FSA能够通过调整载波频率在角度域和通过控制每根天线频率偏移在距离域灵活实现对窃听者的零陷，从而提高物理层安全性能。数值结果表明，所提出的优化算法具有收敛性，并且在保密速率性能方面优于固定位置阵列（FPAs）。", "conclusion": "频率切换阵列（FSA）是一种在太赫兹频段增强物理层安全（PLS）的有效方法，它通过提供额外的波束控制自由度并克服传统可移动天线（MA）的硬件限制，显著提升了保密速率性能。", "translation": "在本文中，我们提出了一种新的频率切换阵列（FSA）增强的太赫兹频段物理层安全（PLS）系统，其中载波频率可以灵活切换，并且Alice处的每个天线都可以施加小的频率偏移，从而消除不期望的窃听者的信息窃听。首先，我们分析表明，通过灵活控制载波频率参数，FSA可以有效地形成均匀/非均匀稀疏阵列，因此在控制天线间距方面类似于可移动天线（MA），并在波束控制中提供额外的自由度（DoF）。尽管所提出的FSA在接收信号中会经历额外的路径增益衰减，但它可以克服MA引起的几个硬件和信号处理问题，例如有限的定位精度、相当大的响应延迟以及苛刻的硬件和能源成本。为了提供有用的见解，我们首先考虑一个具有零陷约束的安全保障问题，其中Alice处考虑最大比传输（MRT）波束成形器，并且频率偏移设置为均匀频率增量。有趣的是，结果表明所提出的FSA可以在角度域（通过调整载波频率）和距离域（通过控制每根天线频率偏移）灵活实现对Eve的零陷，从而提高PLS性能。然后，对于一般情况，我们提出了一种高效算法，通过使用块坐标下降（BCD）和投影梯度上升（PGA）技术来解决所提出的非凸问题。最后，数值结果证明了所提出的优化算法的收敛性及其在保密速率性能方面优于固定位置阵列（FPAs）。", "summary": "本文提出一种在太赫兹频段利用频率切换阵列（FSA）增强物理层安全（PLS）的新系统。该系统通过灵活切换载波频率和施加天线频率偏移，有效创建对窃听者的零陷。研究表明FSA能模拟可移动天线（MA）的稀疏阵列特性，提供额外波束控制自由度，并克服MA的硬件限制。通过理论分析和优化算法（BCD、PGA）验证，FSA能在角度和距离域实现零陷，显著提升保密速率，优于传统固定位置阵列。", "keywords": "频率切换阵列, 物理层安全, 太赫兹通信, 可移动天线, 零陷", "comments": "这项工作提出了频率切换阵列（FSA）作为一种创新的方法来增强太赫兹频段的物理层安全。其创新之处在于利用频率维度来模拟空间维度的阵列控制（类似于可移动天线），同时避免了传统可移动天线在硬件复杂性和成本上的挑战。通过在角度和距离域实现零陷，该方法为未来安全通信提供了一种有前景的解决方案。"}}
{"id": "2507.01766", "title": "Reconfigurable Intelligent Surface aided Integrated-Navigation-and-Communication in Urban Canyons: A Satellite Selection Approach", "authors": ["Tianwei Hou", "Da Guan", "Xin Sun", "Anna Li", "Wenqiang Yi", "Yuanwei Liu", "Arumugam Nallanathan"], "summary": "This study investigates the application of a simultaneous transmitting and\nreflecting reconfigurable intelligent surface (STAR-RIS)-aided\nmedium-Earth-orbit (MEO) satellite network for providing both global\npositioning services and communication services in the urban canyons, where the\ndirect satellite-user links are obstructed. Superposition coding (SC) and\nsuccessive interference cancellation (SIC) techniques are utilized for the\nintegrated navigation and communication (INAC) networks, and the composed\nnavigation and communication signals are reflected or transmitted to ground\nusers or indoor users located in urban canyons. To meet diverse application\nneeds, navigation-oriented (NO)-INAC and communication-oriented (CO)-INAC have\nbeen developed, each tailored according to distinct power allocation factors.\nWe then proposed two algorithms, namely navigation-prioritized-algorithm (NPA)\nand communication-prioritized-algorithm (CPA), to improve the navigation or\ncommunication performance by selecting the satellite with the optimized\nposition dilution of precision (PDoP) or with the best channel gain. The\neffectiveness of the proposed STAR-RIS-aided INAC network is quantified by\nanalyzing the positioning error for navigation services and by evaluating\ncommunication performance through achievable ergodic rate metrics. Our\nsatellite selection approach indicates that: the positioning services at the\nurban canyon users can be completed with the aid of STAR-RIS. 2) Additionally,\nit is observed that while a single STAR-RIS array can extend the navigational\nlink, it fails to serve users in indoor scenarios, highlighting a limitation in\nthe current system design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01766v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "cate": "cs.IT", "url": "http://arxiv.org/abs/2507.01766v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "可重构智能表面辅助的城市峡谷综合导航与通信：一种卫星选择方法", "tldr": "本研究提出了一种在城市峡谷中利用STAR-RIS辅助MEO卫星网络实现综合导航和通信的方法，并通过卫星选择算法优化导航或通信性能。", "motivation": "在城市峡谷中，直连的卫星-用户链路受到阻碍，导致全球定位和通信服务难以提供。", "method": "本研究利用STAR-RIS辅助MEO卫星网络，并采用叠加编码（SC）和连续干扰消除（SIC）技术实现综合导航与通信（INAC）。为满足不同需求，开发了面向导航（NO）的INAC和面向通信（CO）的INAC，并提出了导航优先算法（NPA）和通信优先算法（CPA）两种卫星选择算法，分别通过优化位置精度稀释度（PDoP）或最佳信道增益来提升性能。通过分析定位误差和可实现遍历速率来评估其有效性。", "result": "研究结果表明，在STAR-RIS的帮助下，城市峡谷用户的定位服务得以实现。此外，虽然单个STAR-RIS阵列可以扩展导航链路，但它无法服务室内场景中的用户。", "conclusion": "STAR-RIS辅助的综合导航与通信网络在城市峡谷中是有效的，尤其在定位服务方面，但当前系统设计在服务室内用户方面存在局限性。", "translation": "本研究探讨了同时传输和反射可重构智能表面（STAR-RIS）辅助的中地球轨道（MEO）卫星网络在城市峡谷中提供全球定位服务和通信服务的应用，这些区域的直连卫星-用户链路受到阻碍。为了实现综合导航与通信（INAC）网络，采用了叠加编码（SC）和连续干扰消除（SIC）技术，并将合成的导航和通信信号反射或传输给城市峡谷中的地面用户或室内用户。为了满足多样化的应用需求，开发了面向导航（NO）的INAC和面向通信（CO）的INAC，每种都根据不同的功率分配因子进行了调整。然后，我们提出了两种算法，即导航优先算法（NPA）和通信优先算法（CPA），通过选择具有优化位置精度稀释度（PDoP）或最佳信道增益的卫星来提高导航或通信性能。通过分析导航服务的定位误差和评估可实现遍历速率指标的通信性能，量化了所提出的STAR-RIS辅助INAC网络的有效性。我们的卫星选择方法表明：1）在STAR-RIS的帮助下，城市峡谷用户的定位服务可以完成。2）此外，观察到虽然单个STAR-RIS阵列可以扩展导航链路，但它无法服务室内场景中的用户，这突出了当前系统设计中的一个局限性。", "summary": "本文提出了一种在城市峡谷中利用STAR-RIS辅助中地球轨道（MEO）卫星网络实现综合导航与通信（INAC）的方法，以解决直连链路受阻的问题。该方法结合了叠加编码和连续干扰消除技术，并根据不同的应用需求（导航优先或通信优先）开发了相应的INAC模式。研究还提出了两种卫星选择算法（NPA和CPA）来优化导航或通信性能。结果表明，STAR-RIS能有效辅助城市峡谷中的定位服务，但单个STAR-RIS阵列在服务室内用户方面存在局限性。", "keywords": "STAR-RIS, 综合导航与通信, 城市峡谷, 卫星选择, MEO卫星网络", "comments": "本文创新性地将STAR-RIS应用于城市峡谷环境下的综合导航与通信，解决了直连链路受阻的挑战。提出的双优先级（导航/通信）INAC模式和相应的卫星选择算法是其重要贡献。然而，研究也指出了单个STAR-RIS阵列在室内用户覆盖方面的局限性，为未来的研究方向提供了线索。"}}
{"id": "2507.01787", "title": "From Reports to Reality: Testing Consistency in Instagram's Digital Services Act Compliance Data", "authors": ["Marie-Therese Sekwenz", "Ben Wagner", "Hans De Bruijn"], "summary": "The Digital Services Act (DSA) introduces harmonized rules for content\nmoderation and platform governance in the European Union, mandating robust\ncompliance mechanisms, particularly for very large online platforms and search\nengines. This study examined compliance with DSA requirements, focusing on\nInstagram as a case study. We develop and apply a multi-level consistency\nframework to evaluate DSA compliance. Our findings contribute to the broader\ndiscussion on empirically-based regulation, providing insight into how\nresearchers, regulators, auditors and platforms can better utilize DSA\nmechanisms to improve reporting and enforcement quality and accountability.\nThis work underscores that consistency can help detect potential compliance\nfailures. It also demonstrates that platforms should be evaluated as part of an\ninterconnected ecosystem rather than through isolated processes, which is\ncrucial for effective compliance evaluation under the DSA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01787v1", "categories": ["cs.CY"], "cate": "cs.CY", "url": "http://arxiv.org/abs/2507.01787v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "从报告到现实：测试Instagram数字服务法案合规数据的一致性", "tldr": "本研究通过开发并应用多层次一致性框架，评估了Instagram在欧盟数字服务法案(DSA)下的合规性，强调了一致性检测潜在合规失败的重要性，并指出应将平台视为互联生态系统的一部分进行评估。", "motivation": "欧盟的数字服务法案(DSA)引入了内容审核和平台治理的统一规则，要求大型在线平台和搜索引擎建立强大的合规机制。本研究的动机是检验Instagram对此DSA要求的合规性。", "method": "本研究开发并应用了一个多层次一致性框架来评估数字服务法案(DSA)的合规性。", "result": "研究发现，一致性有助于检测潜在的合规失败。此外，研究表明，在DSA下进行有效合规评估时，应将平台视为互联生态系统的一部分进行评估，而非孤立的过程。", "conclusion": "本研究的结果促进了基于经验的监管讨论，为研究人员、监管机构、审计师和平台如何更好地利用DSA机制来提高报告、执法质量和问责制提供了见解。一致性是检测潜在合规失败的关键，且平台评估应考虑其互联生态系统。", "translation": "数字服务法案（DSA）引入了欧盟内容审核和平台治理的统一规则，要求建立强大的合规机制，特别是针对超大型在线平台和搜索引擎。本研究以Instagram为例，审查了其对DSA要求的合规性。我们开发并应用了一个多层次一致性框架来评估DSA合规性。我们的发现有助于更广泛的基于经验的监管讨论，为研究人员、监管机构、审计师和平台如何更好地利用DSA机制来提高报告和执法质量及问责制提供了见解。这项工作强调，一致性有助于检测潜在的合规失败。它还表明，应将平台视为互联生态系统的一部分进行评估，而不是通过孤立的过程，这对于DSA下的有效合规评估至关重要。", "summary": "本研究以Instagram为例，评估了其对欧盟数字服务法案(DSA)的合规性。通过开发并应用一个多层次一致性框架，研究发现一致性对于发现潜在合规失败至关重要。此外，论文强调在DSA框架下，应将平台视为互联生态系统的一部分进行评估，而非孤立的实体，这对于提高报告和执法质量及问责制具有重要意义。", "keywords": "数字服务法案, Instagram, 合规性, 一致性, 内容审核", "comments": "这项研究的创新之处在于提出了一个多层次一致性框架来评估平台合规性，并强调了将平台视为互联生态系统而非孤立实体的重要性。这对于理解和改进数字服务法案的实施具有重要意义，尤其是在当前复杂的在线生态系统中，为监管机构和平台提供了实用的指导。"}}
{"id": "2507.01326", "title": "Structure and Smoothness Constrained Dual Networks for MR Bias Field Correction", "authors": ["Dong Liang", "Xingyu Qiu", "Yuzhen Li", "Wei Wang", "Kuanquan Wang", "Suyu Dong", "Gongning Luo"], "summary": "MR imaging techniques are of great benefit to disease diagnosis. However, due\nto the limitation of MR devices, significant intensity inhomogeneity often\nexists in imaging results, which impedes both qualitative and quantitative\nmedical analysis. Recently, several unsupervised deep learning-based models\nhave been proposed for MR image improvement. However, these models merely\nconcentrate on global appearance learning, and neglect constraints from image\nstructures and smoothness of bias field, leading to distorted corrected\nresults. In this paper, novel structure and smoothness constrained dual\nnetworks, named S2DNets, are proposed aiming to self-supervised bias field\ncorrection. S2DNets introduce piece-wise structural constraints and smoothness\nof bias field for network training to effectively remove non-uniform intensity\nand retain much more structural details. Extensive experiments executed on both\nclinical and simulated MR datasets show that the proposed model outperforms\nother conventional and deep learning-based models. In addition to comparison on\nvisual metrics, downstream MR image segmentation tasks are also used to\nevaluate the impact of the proposed model. The source code is available at:\nhttps://github.com/LeongDong/S2DNets}{https://github.com/LeongDong/S2DNets.", "comment": "11 pages, 3 figures, accepted by MICCAI", "pdf_url": "http://arxiv.org/pdf/2507.01326v1", "categories": ["eess.IV", "cs.CV"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01326v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "用于MR偏置场校正的结构和平滑度约束双网络", "tldr": "S2DNets是一种自监督深度学习模型，通过引入分段结构约束和偏置场平滑度来校正MR图像中的强度不均匀性，并优于现有方法。", "motivation": "MR成像中的强度不均匀性（偏置场）阻碍了定性和定量医学分析。现有无监督深度学习模型仅关注全局外观学习，忽略图像结构和偏置场平滑度约束，导致校正结果失真。", "method": "本文提出了S2DNets，一种结构和平滑度约束双网络，用于自监督偏置场校正。S2DNets在网络训练中引入分段结构约束和偏置场平滑度，以有效去除非均匀强度并保留更多结构细节。", "result": "在临床和模拟MR数据集上进行的广泛实验表明，所提出的模型优于其他传统和基于深度学习的模型。除了视觉指标比较外，下游MR图像分割任务也用于评估该模型的影响。", "conclusion": "S2DNets通过引入结构和平滑度约束，有效解决了MR图像偏置场校正中的强度不均匀性问题，提高了图像质量和下游任务的性能。", "translation": "MR成像技术对疾病诊断有很大益处。然而，由于MR设备的限制，成像结果中经常存在显著的强度不均匀性，这阻碍了定性和定量医学分析。最近，一些基于无监督深度学习的模型被提出来用于MR图像改进。然而，这些模型仅关注全局外观学习，而忽略了图像结构和偏置场平滑度的约束，导致校正结果失真。在本文中，提出了新颖的结构和平滑度约束双网络，命名为S2DNets，旨在进行自监督偏置场校正。S2DNets在网络训练中引入分段结构约束和偏置场平滑度，以有效去除非均匀强度并保留更多结构细节。在临床和模拟MR数据集上进行的广泛实验表明，所提出的模型优于其他传统和基于深度学习的模型。除了视觉指标比较外，下游MR图像分割任务也用于评估所提出模型的影响。源代码可在以下网址获取：https://github.com/LeongDong/S2DNets。", "summary": "本文提出了一种名为S2DNets的自监督双网络，用于MR图像的偏置场校正。针对现有深度学习模型忽视图像结构和偏置场平滑度的问题，S2DNets引入了分段结构约束和偏置场平滑度，以有效去除非均匀强度并保留图像细节。实验结果表明，S2DNets在临床和模拟MR数据集上均优于传统及其他深度学习方法，并在下游图像分割任务中也展现出积极影响。", "keywords": "MR偏置场校正, 深度学习, 自监督学习, 结构约束, 平滑度约束", "comments": "S2DNets的创新点在于其引入了图像结构和偏置场平滑度的约束，解决了现有无监督深度学习模型在MR偏置场校正中容易导致结果失真的问题。通过自监督学习，该模型能够有效提升MR图像质量，对后续医学图像分析具有重要意义。其在下游分割任务中的表现也验证了其对实际应用价值的贡献。"}}
{"id": "2507.01278", "title": "Evaluating Large Language Models for Multimodal Simulated Ophthalmic Decision-Making in Diabetic Retinopathy and Glaucoma Screening", "authors": ["Cindy Lie Tabuse", "David Restepo", "Carolina Gracitelli", "Fernando Korn Malerbi", "Caio Regatieri", "Luis Filipe Nakayama"], "summary": "Large language models (LLMs) can simulate clinical reasoning based on natural\nlanguage prompts, but their utility in ophthalmology is largely unexplored.\nThis study evaluated GPT-4's ability to interpret structured textual\ndescriptions of retinal fundus photographs and simulate clinical decisions for\ndiabetic retinopathy (DR) and glaucoma screening, including the impact of\nadding real or synthetic clinical metadata. We conducted a retrospective\ndiagnostic validation study using 300 annotated fundus images. GPT-4 received\nstructured prompts describing each image, with or without patient metadata. The\nmodel was tasked with assigning an ICDR severity score, recommending DR\nreferral, and estimating the cup-to-disc ratio for glaucoma referral.\nPerformance was evaluated using accuracy, macro and weighted F1 scores, and\nCohen's kappa. McNemar's test and change rate analysis were used to assess the\ninfluence of metadata. GPT-4 showed moderate performance for ICDR\nclassification (accuracy 67.5%, macro F1 0.33, weighted F1 0.67, kappa 0.25),\ndriven mainly by correct identification of normal cases. Performance improved\nin the binary DR referral task (accuracy 82.3%, F1 0.54, kappa 0.44). For\nglaucoma referral, performance was poor across all settings (accuracy ~78%, F1\n<0.04, kappa <0.03). Metadata inclusion did not significantly affect outcomes\n(McNemar p > 0.05), and predictions remained consistent across conditions.\nGPT-4 can simulate basic ophthalmic decision-making from structured prompts but\nlacks precision for complex tasks. While not suitable for clinical use, LLMs\nmay assist in education, documentation, or image annotation workflows in\nophthalmology.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01278v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01278v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "评估大型语言模型在糖尿病视网膜病变和青光眼筛查中多模态模拟眼科决策的能力", "tldr": "本研究评估了GPT-4在眼科模拟决策中的能力，发现其在糖尿病视网膜病变筛查中表现中等，但在青光眼筛查中表现不佳，且元数据对结果影响不大。模型不适合临床使用，但可能用于教育等辅助领域。", "motivation": "大型语言模型（LLMs）可以模拟基于自然语言提示的临床推理，但它们在眼科学中的效用尚未得到充分探索。本研究旨在评估GPT-4在解释结构化文本描述的视网膜眼底照片和模拟糖尿病视网膜病变（DR）和青光眼筛查中的临床决策的能力。", "method": "本研究采用回顾性诊断验证研究，使用了300张带注释的眼底图像。GPT-4接收描述每张图像的结构化提示，有时包含患者元数据。模型被要求分配ICDR严重程度评分、推荐DR转诊以及估计青光眼转诊的杯盘比。性能通过准确率、宏观和加权F1分数以及Cohen's kappa进行评估。McNemar检验和变化率分析用于评估元数据的影响。", "result": "GPT-4在ICDR分类中表现中等（准确率67.5%，宏观F1 0.33，加权F1 0.67，kappa 0.25），主要由正确识别正常病例驱动。在二元DR转诊任务中性能有所提高（准确率82.3%，F1 0.54，kappa 0.44）。对于青光眼转诊，在所有设置下性能都很差（准确率约78%，F1 <0.04，kappa <0.03）。元数据包含对结果没有显著影响（McNemar p > 0.05），并且预测在不同条件下保持一致。", "conclusion": "GPT-4可以从结构化提示中模拟基本的眼科决策，但对于复杂任务缺乏精确性。虽然不适合临床使用，但LLMs可能在眼科学的教育、文档或图像注释工作流程中提供帮助。", "translation": "大型语言模型（LLMs）可以模拟基于自然语言提示的临床推理，但它们在眼科学中的效用尚未得到充分探索。本研究评估了GPT-4解释视网膜眼底照片的结构化文本描述并模拟糖尿病视网膜病变（DR）和青光眼筛查中的临床决策的能力，包括添加真实或合成临床元数据的影响。我们采用回顾性诊断验证研究，使用了300张带注释的眼底图像。GPT-4接收描述每张图像的结构化提示，有时包含患者元数据。模型被要求分配ICDR严重程度评分、推荐DR转诊以及估计青光眼转诊的杯盘比。性能通过准确率、宏观和加权F1分数以及Cohen's kappa进行评估。McNemar检验和变化率分析用于评估元数据的影响。GPT-4在ICDR分类中表现中等（准确率67.5%，宏观F1 0.33，加权F1 0.67，kappa 0.25），主要由正确识别正常病例驱动。在二元DR转诊任务中性能有所提高（准确率82.3%，F1 0.54，kappa 0.44）。对于青光眼转诊，在所有设置下性能都很差（准确率约78%，F1 <0.04，kappa <0.03）。元数据包含对结果没有显著影响（McNemar p > 0.05），并且预测在不同条件下保持一致。GPT-4可以从结构化提示中模拟基本的眼科决策，但对于复杂任务缺乏精确性。虽然不适合临床使用，但LLMs可能在眼科学的教育、文档或图像注释工作流程中提供帮助。", "summary": "本研究评估了大型语言模型GPT-4在模拟眼科决策（特别是糖尿病视网膜病变和青光眼筛查）中的效用。研究使用300张眼底图像及其结构化文本描述，并测试了添加患者元数据的影响。结果显示，GPT-4在糖尿病视网膜病变转诊任务中表现中等，但在青光眼转诊任务中表现不佳，且元数据对性能无显著影响。研究得出结论，虽然GPT-4能模拟基本眼科决策，但缺乏复杂任务的精确性，不适合临床应用，但可能在教育或文档等辅助领域发挥作用。", "keywords": "大型语言模型, 眼科, 糖尿病视网膜病变, 青光眼筛查, 临床决策", "comments": "这项研究是早期探索LLM在眼科领域应用的重要尝试。其创新性在于首次系统评估了GPT-4在模拟多模态眼科决策中的表现。研究明确指出了当前LLM在处理复杂医疗任务时的局限性，特别是在青光眼筛查等需要精细判断的任务上。尽管结果表明LLM不适合直接临床诊断，但其指出了LLM在辅助性任务（如教育、文档、图像注释）中的潜在价值，为未来研究提供了方向。"}}
{"id": "2507.01527", "title": "A surface finite element scheme for a stochastic PDE on an evolving curve", "authors": ["Paola Pozzi", "Björn Stinner"], "summary": "In this paper we consider an ESFEM method for the advection and diffusion of\na scalar quantity on a moving closed curve. The diffusion process is controlled\nby a forcing term that may include a rough term (specifically a stochastic\nnoise) which in particular destroys the classical time differentiability\nproperties of the solution. We provide a suitable variational solution concept\nand a fully discrete FEM discretization. Our error analysis appropriately\ngeneralizes classical estimates to this weaker setting. We present some\nnumerical simulations that confirm our theoretical findings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01527v1", "categories": ["math.NA", "cs.NA", "60H35, 65M60, 65M15"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01527v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "演化曲线上随机偏微分方程的曲面有限元方案", "tldr": "本文提出了一种用于移动曲线上随机偏微分方程的ESFEM方法，能够处理粗糙噪声，并提供了误差分析和数值验证。", "motivation": "本文旨在解决在移动曲线上带有随机噪声的标量平流和扩散问题，其中噪声会破坏解的经典时间可微性。", "method": "作者提出了一种用于移动闭合曲线上标量平流和扩散的演化曲面有限元（ESFEM）方法。他们提供了一个合适的变分解概念和一个完全离散的有限元离散化方案，并将经典误差分析推广到这种较弱的设置。", "result": "本文提供了一个合适的变分解概念，一个完全离散的有限元离散化方案，以及将经典估计推广到较弱设置的误差分析。数值模拟证实了他们的理论发现。", "conclusion": "所提出的ESFEM方法即使在存在粗糙噪声的情况下，也能有效地处理演化曲线上的随机偏微分方程，其理论性质得到了数值证据的支持。", "translation": "本文研究了一种用于移动闭合曲线上标量平流和扩散的ESFEM方法。扩散过程由一个可能包含粗糙项（特别是随机噪声）的强制项控制，该粗糙项特别破坏了解的经典时间可微性。我们提供了一个合适的变分解概念和一个完全离散的有限元离散化方案。我们的误差分析将经典估计适当地推广到这种较弱的设置。我们提供了一些数值模拟，证实了我们的理论发现。", "summary": "本文提出了一种演化曲面有限元（ESFEM）方法，用于解决移动闭合曲线上包含标量平流和扩散的随机偏微分方程。该方法特别处理了随机噪声项导致经典时间可微性丧失的情况。作者建立了变分解概念、完全离散的有限元离散化方案以及推广的误差分析，并通过数值模拟验证了其理论发现。", "keywords": "随机偏微分方程, 演化曲线, 有限元方法, 平流扩散, 误差分析", "comments": "该论文通过将ESFEM扩展到演化曲线上的随机偏微分方程，特别是在处理影响解正则性的粗糙噪声方面，展现了创新性。其将误差分析推广到较弱设置的贡献是显著的，为解决此类复杂问题提供了稳健的框架。"}}
{"id": "2507.01356", "title": "Voice Conversion for Likability Control via Automated Rating of Speech Synthesis Corpora", "authors": ["Hitoshi Suda", "Shinnosuke Takamichi", "Satoru Fukayama"], "summary": "Perceived voice likability plays a crucial role in various social\ninteractions, such as partner selection and advertising. A system that provides\nreference likable voice samples tailored to target audiences would enable users\nto adjust their speaking style and voice quality, facilitating smoother\ncommunication. To this end, we propose a voice conversion method that controls\nthe likability of input speech while preserving both speaker identity and\nlinguistic content. To improve training data scalability, we train a likability\npredictor on an existing voice likability dataset and employ it to\nautomatically annotate a large speech synthesis corpus with likability ratings.\nExperimental evaluations reveal a significant correlation between the\npredictor's outputs and human-provided likability ratings. Subjective and\nobjective evaluations further demonstrate that the proposed approach\neffectively controls voice likability while preserving both speaker identity\nand linguistic content.", "comment": "Accepted at Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.01356v1", "categories": ["eess.AS", "cs.SD"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01356v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "通过语音合成语料库的自动评分进行喜爱度控制的语音转换", "tldr": "本文提出了一种语音转换方法，通过训练一个喜爱度预测器来自动标注大规模语料库，从而在保留说话人身份和语言内容的同时，控制输入语音的喜爱度。", "motivation": "感知到的语音喜爱度在社交互动中扮演着关键角色，例如伴侣选择和广告。一个能够提供针对目标受众的参考喜爱度语音样本的系统，将使用户能够调整其说话风格和音质，从而促进更顺畅的沟通。", "method": "本文提出了一种语音转换方法，旨在控制输入语音的喜爱度，同时保留说话人身份和语言内容。为了提高训练数据的可扩展性，研究人员在一个现有的语音喜爱度数据集上训练了一个喜爱度预测器，并利用它来自动标注一个大型语音合成语料库的喜爱度评分。", "result": "实验评估表明，预测器的输出与人类提供的喜爱度评分之间存在显著相关性。主观和客观评估进一步证明，所提出的方法能够有效地控制语音喜爱度，同时保留说话人身份和语言内容。", "conclusion": "本文提出的语音转换方法能够有效控制语音的喜爱度，同时保持说话人身份和语言内容不变，并通过自动评分提高了数据标注的效率和规模。", "translation": "感知到的语音喜爱度在各种社交互动中扮演着关键角色，例如伴侣选择和广告。一个能够提供针对目标受众的参考喜爱度语音样本的系统，将使用户能够调整其说话风格和音质，从而促进更顺畅的沟通。为此，我们提出了一种语音转换方法，该方法控制输入语音的喜爱度，同时保留说话人身份和语言内容。为了提高训练数据的可扩展性，我们在一个现有的语音喜爱度数据集上训练了一个喜爱度预测器，并利用它来自动标注一个大型语音合成语料库的喜爱度评分。实验评估表明，预测器的输出与人类提供的喜爱度评分之间存在显著相关性。主观和客观评估进一步证明，所提出的方法能够有效地控制语音喜爱度，同时保留说话人身份和语言内容。", "summary": "本文提出了一种新颖的语音转换方法，旨在控制语音的喜爱度，同时保持说话人身份和语言内容不变。为解决训练数据规模问题，研究人员开发了一个喜爱度预测器，该预测器在现有数据集上训练，并用于自动标注大型语音合成语料库。实验结果表明，该预测器与人类评分高度相关，且所提出的方法能有效实现喜爱度控制并保持语音特性。", "keywords": "语音转换, 喜爱度控制, 自动评分, 语音合成, 预测器", "comments": "这项研究的创新之处在于，它通过利用自动评分来解决语音喜爱度控制中训练数据可扩展性的挑战。通过训练一个喜爱度预测器并将其应用于大规模语料库，该方法显著提高了数据标注的效率。这对于开发实际应用中可用的语音喜爱度控制系统具有重要意义，因为它克服了手动标注大量语音数据的耗时和成本限制。其在保留说话人身份和语言内容的同时控制喜爱度的能力，也使其在个性化语音助手、广告和人机交互等领域具有潜在应用价值。"}}
{"id": "2507.01066", "title": "Embedding-based Retrieval in Multimodal Content Moderation", "authors": ["Hanzhong Liang", "Jinghao Shi", "Xiang Shen", "Zixuan Wang", "Vera Wen", "Ardalan Mehrani", "Zhiqian Chen", "Yifan Wu", "Zhixin Zhang"], "summary": "Video understanding plays a fundamental role for content moderation on short\nvideo platforms, enabling the detection of inappropriate content. While\nclassification remains the dominant approach for content moderation, it often\nstruggles in scenarios requiring rapid and cost-efficient responses, such as\ntrend adaptation and urgent escalations. To address this issue, we introduce an\nEmbedding-Based Retrieval (EBR) method designed to complement traditional\nclassification approaches. We first leverage a Supervised Contrastive Learning\n(SCL) framework to train a suite of foundation embedding models, including both\nsingle-modal and multi-modal architectures. Our models demonstrate superior\nperformance over established contrastive learning methods such as CLIP and\nMoCo. Building on these embedding models, we design and implement the\nembedding-based retrieval system that integrates embedding generation and video\nretrieval to enable efficient and effective trend handling. Comprehensive\noffline experiments on 25 diverse emerging trends show that EBR improves\nROC-AUC from 0.85 to 0.99 and PR-AUC from 0.35 to 0.95. Further online\nexperiments reveal that EBR increases action rates by 10.32% and reduces\noperational costs by over 80%, while also enhancing interpretability and\nflexibility compared to classification-based solutions.", "comment": "Camera ready for SIGIR 2025", "pdf_url": "http://arxiv.org/pdf/2507.01066v1", "categories": ["cs.IR", "cs.CV", "cs.LG"], "cate": "cs.IR", "url": "http://arxiv.org/abs/2507.01066v1", "date": "2025-06-30", "updated": "2025-06-30", "AI": {"title_translation": "多模态内容审核中的基于嵌入的检索", "tldr": "本文提出了一种基于嵌入的检索（EBR）方法，用于补充传统分类在短视频内容审核中的不足，特别是在处理新兴趋势时，显著提高了效率并降低了成本。", "motivation": "传统分类方法在处理需要快速、成本高效响应的场景（如趋势适应和紧急升级）时表现不佳，因此需要一种新的方法来补充其不足。", "method": "本文引入了一种基于嵌入的检索（EBR）方法。首先，利用监督对比学习（SCL）框架训练了一套基础嵌入模型，包括单模态和多模态架构。这些模型在性能上优于CLIP和MoCo等现有对比学习方法。在此基础上，设计并实现了集成嵌入生成和视频检索的EBR系统。", "result": "离线实验显示，在25种不同的新兴趋势上，EBR将ROC-AUC从0.85提高到0.99，PR-AUC从0.35提高到0.95。在线实验表明，EBR将行动率提高了10.32%，并将运营成本降低了80%以上，同时与基于分类的解决方案相比，还增强了解释性和灵活性。", "conclusion": "基于嵌入的检索（EBR）方法能够有效补充传统分类，显著提高短视频内容审核的效率、降低成本，并增强可解释性和灵活性，尤其在处理新兴趋势方面表现突出。", "translation": "视频理解在短视频平台的内容审核中扮演着基础性角色，能够检测不当内容。尽管分类仍然是内容审核的主导方法，但它在需要快速和成本高效响应的场景（如趋势适应和紧急升级）中常常力不从心。为了解决这个问题，我们引入了一种基于嵌入的检索（EBR）方法，旨在补充传统的分类方法。我们首先利用监督对比学习（SCL）框架训练了一套基础嵌入模型，包括单模态和多模态架构。我们的模型表现出优于CLIP和MoCo等成熟对比学习方法的性能。在此嵌入模型的基础上，我们设计并实现了一个基于嵌入的检索系统，该系统集成了嵌入生成和视频检索，以实现高效和有效的趋势处理。在25种不同的新兴趋势上进行的全面离线实验表明，EBR将ROC-AUC从0.85提高到0.99，PR-AUC从0.35提高到0.95。进一步的在线实验显示，EBR将行动率提高了10.32%，并将运营成本降低了80%以上，同时与基于分类的解决方案相比，还增强了解释性和灵活性。", "summary": "本文提出了一种用于多模态内容审核的基于嵌入的检索（EBR）方法，以解决传统分类在快速响应和成本效率方面的不足。该方法利用监督对比学习训练高性能的单模态和多模态嵌入模型，并在此基础上构建检索系统。实验结果表明，EBR显著提升了内容审核的准确性（ROC-AUC和PR-AUC）、行动率，并大幅降低了运营成本，同时增强了系统的可解释性和灵活性，特别适用于新兴趋势的处理。", "keywords": "内容审核, 嵌入式检索, 监督对比学习, 视频理解, 多模态", "comments": "该论文提出了一种创新的基于嵌入的检索（EBR）方法，有效解决了传统分类在动态内容审核场景中（特别是新兴趋势）的局限性。通过引入监督对比学习训练高性能嵌入模型，并将其应用于检索系统，该方法在提高检测效率、降低运营成本和增强系统灵活性方面取得了显著成果。其创新点在于将检索范式引入内容审核，并证明了其在实际应用中的优越性，对短视频平台的内容安全具有重要意义。"}}
{"id": "2507.01308", "title": "LANet: A Lane Boundaries-Aware Approach For Robust Trajectory Prediction", "authors": ["Muhammad Atta ur Rahman", "Dooseop Choi", "KyoungWook Min"], "summary": "Accurate motion forecasting is critical for safe and efficient autonomous\ndriving, enabling vehicles to predict future trajectories and make informed\ndecisions in complex traffic scenarios. Most of the current designs of motion\nprediction models are based on the major representation of lane centerlines,\nwhich limits their capability to capture critical road environments and traffic\nrules and constraints. In this work, we propose an enhanced motion forecasting\nmodel informed by multiple vector map elements, including lane boundaries and\nroad edges, that facilitates a richer and more complete representation of\ndriving environments. An effective feature fusion strategy is developed to\nmerge information in different vector map components, where the model learns\nholistic information on road structures and their interactions with agents.\nSince encoding more information about the road environment increases memory\nusage and is computationally expensive, we developed an effective pruning\nmechanism that filters the most relevant map connections to the target agent,\nensuring computational efficiency while maintaining essential spatial and\nsemantic relationships for accurate trajectory prediction. Overcoming the\nlimitations of lane centerline-based models, our method provides a more\ninformative and efficient representation of the driving environment and\nadvances the state of the art for autonomous vehicle motion forecasting. We\nverify our approach with extensive experiments on the Argoverse 2 motion\nforecasting dataset, where our method maintains competitiveness on AV2 while\nachieving improved performance.\n  Index Terms-Autonomous driving, trajectory prediction, vector map elements,\nroad topology, connection pruning, Argoverse 2.", "comment": "Accepted at the 17th IEEE International Conference on Advanced\n  Computational Intelligence (ICACI 2025)", "pdf_url": "http://arxiv.org/pdf/2507.01308v1", "categories": ["cs.RO", "cs.CV"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01308v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "LANet：一种基于车道边界的鲁棒轨迹预测方法", "tldr": "LANet通过整合车道边界和道路边缘等多种矢量地图元素，并采用有效的特征融合和剪枝机制，克服了传统基于车道中心线模型的局限性，实现了更准确和高效的自动驾驶轨迹预测。", "motivation": "现有的运动预测模型主要基于车道中心线表示，这限制了它们捕捉关键道路环境、交通规则和约束的能力。为了实现安全高效的自动驾驶，需要更准确的运动预测模型。", "method": "本文提出了一种名为LANet的增强型运动预测模型，该模型利用多种矢量地图元素（包括车道边界和道路边缘）来表示驾驶环境。它开发了一种有效的特征融合策略来合并不同矢量地图组件的信息，并设计了一种有效的剪枝机制来过滤与目标智能体最相关的地图连接，以确保计算效率。", "result": "该方法在Argoverse 2运动预测数据集上进行了广泛实验验证，结果表明其在保持竞争力的同时，实现了性能提升。", "conclusion": "LANet克服了基于车道中心线模型的局限性，为驾驶环境提供了更具信息量和效率的表示，并推动了自动驾驶车辆运动预测的最新技术发展。", "translation": "准确的运动预测对于安全高效的自动驾驶至关重要，它使车辆能够预测未来轨迹并复杂交通场景中做出明智决策。当前大多数运动预测模型的设计都基于车道中心线的主要表示，这限制了它们捕捉关键道路环境、交通规则和约束的能力。在这项工作中，我们提出了一种由多种矢量地图元素（包括车道边界和道路边缘）提供信息的增强型运动预测模型，这有助于更丰富、更完整的驾驶环境表示。我们开发了一种有效的特征融合策略来合并不同矢量地图组件中的信息，模型从中学习道路结构的整体信息及其与智能体的交互。由于编码更多道路环境信息会增加内存使用量并计算成本高昂，我们开发了一种有效的剪枝机制，用于过滤与目标智能体最相关的地图连接，从而在保持准确轨迹预测所需的基本空间和语义关系的同时，确保计算效率。通过克服基于车道中心线模型的局限性，我们的方法提供了更具信息量和效率的驾驶环境表示，并推动了自动驾驶车辆运动预测的最新技术发展。我们在Argoverse 2运动预测数据集上通过大量实验验证了我们的方法，结果表明我们的方法在保持AV2竞争力的同时，实现了性能提升。\n索引词：自动驾驶，轨迹预测，矢量地图元素，道路拓扑，连接剪枝，Argoverse 2。", "summary": "本文提出LANet，一种用于自动驾驶的鲁棒轨迹预测模型，旨在克服传统模型对车道中心线表示的依赖。LANet通过整合车道边界和道路边缘等多种矢量地图元素，提供更丰富的驾驶环境表示。模型采用有效的特征融合策略整合不同地图组件信息，并引入剪枝机制以优化计算效率。实验在Argoverse 2数据集上验证了LANet的有效性，证明其在提升性能的同时保持了竞争力。", "keywords": "自动驾驶, 轨迹预测, 矢量地图元素, 道路拓扑, 连接剪枝", "comments": "该论文的创新点在于其提出了一种克服传统车道中心线局限性的轨迹预测方法，通过整合更丰富的矢量地图元素（如车道边界和道路边缘）来获取更全面的环境信息。同时，其开发的特征融合策略和剪枝机制有效地平衡了信息丰富度与计算效率，这对于自动驾驶应用至关重要。该方法在Argoverse 2数据集上的表现也证明了其在实际应用中的潜力。"}}
{"id": "2507.01597", "title": "T3DM: Test-Time Training-Guided Distribution Shift Modelling for Temporal Knowledge Graph Reasoning", "authors": ["Yuehang Si", "Zefan Zeng", "Jincai Huang", "Qing Cheng"], "summary": "Temporal Knowledge Graph (TKG) is an efficient method for describing the\ndynamic development of facts along a timeline. Most research on TKG reasoning\n(TKGR) focuses on modelling the repetition of global facts and designing\npatterns of local historical facts. However, they face two significant\nchallenges: inadequate modeling of the event distribution shift between\ntraining and test samples, and reliance on random entity substitution for\ngenerating negative samples, which often results in low-quality sampling. To\nthis end, we propose a novel distributional feature modeling approach for\ntraining TKGR models, Test-Time Training-guided Distribution shift Modelling\n(T3DM), to adjust the model based on distribution shift and ensure the global\nconsistency of model reasoning. In addition, we design a negative-sampling\nstrategy to generate higher-quality negative quadruples based on adversarial\ntraining. Extensive experiments show that T3DM provides better and more robust\nresults than the state-of-the-art baselines in most cases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01597v1", "categories": ["cs.AI", "cs.CL"], "cate": "cs.AI", "url": "http://arxiv.org/abs/2507.01597v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "T3DM：测试时训练引导的知识图谱分布偏移建模用于时间知识图谱推理", "tldr": "T3DM通过测试时训练和对抗性负采样解决时间知识图谱推理中的分布偏移和低质量负采样问题。", "motivation": "现有时间知识图谱推理（TKGR）研究面临两个主要挑战：训练和测试样本之间事件分布偏移建模不足，以及依赖随机实体替换生成负样本导致采样质量低。", "method": "提出了T3DM（Test-Time Training-guided Distribution shift Modelling），这是一种新颖的分布特征建模方法，用于根据分布偏移调整模型并确保模型推理的全局一致性。此外，还设计了一种基于对抗性训练的负采样策略，以生成更高质量的负四元组。", "result": "大量实验表明，T3DM在大多数情况下比最先进的基线提供了更好、更稳健的结果。", "conclusion": "T3DM通过解决分布偏移和负采样质量问题，显著提高了时间知识图谱推理的性能和鲁棒性。", "translation": "时间知识图谱（TKG）是一种描述事实沿时间线动态发展的有效方法。大多数关于时间知识图谱推理（TKGR）的研究侧重于建模全局事实的重复和设计局部历史事实的模式。然而，它们面临两个重大挑战：训练和测试样本之间事件分布偏移建模不足，以及依赖随机实体替换生成负样本，这通常导致低质量采样。为此，我们提出了一种新颖的用于训练TKGR模型的分布特征建模方法——测试时训练引导的分布偏移建模（T3DM），以根据分布偏移调整模型并确保模型推理的全局一致性。此外，我们设计了一种负采样策略，基于对抗性训练生成更高质量的负四元组。大量实验表明，T3DM在大多数情况下比最先进的基线提供了更好、更稳健的结果。", "summary": "本文提出T3DM，一种新颖的用于时间知识图谱推理（TKGR）的分布特征建模方法，旨在解决训练和测试样本之间事件分布偏移以及低质量负采样问题。T3DM通过测试时训练来适应分布偏移，并引入对抗性负采样策略以提高负样本质量。实验证明，T3DM在性能和鲁棒性上超越了现有基线。", "keywords": "时间知识图谱推理, 分布偏移, 测试时训练, 负采样, 对抗性训练", "comments": "T3DM的创新之处在于其结合了测试时训练来应对分布偏移，并引入对抗性训练来生成高质量负样本，这有效地解决了现有时间知识图谱推理模型的关键挑战，提高了模型的适应性和性能。"}}
{"id": "2507.01536", "title": "Cybersecurity Issues in Local Energy Markets", "authors": ["Al Hussein Dabashi", "Sajjad Maleki", "Biswarup Mukherjee", "Gregory Epiphaniou", "Carsten Maple", "Charalambos Konstantinou", "Subhash Lakshminarayana"], "summary": "Local Energy Markets (LEMs), though pivotal to the energy transition, face\ngrowing cybersecurity threats due to their reliance on smart grid communication\nstandards and vulnerable Internet-of-Things (IoT)-enabled devices. This is a\ncritical issue because such vulnerabilities can be exploited to manipulate\nmarket operations, compromise participants' privacy, and destabilize power\ndistribution networks. This work maps LEM communication flows to existing\nstandards, highlights potential impacts of key identified vulnerabilities, and\nsimulates cyberattack scenarios on a privacy-preserving LEM model to assess\ntheir impacts. Findings reveal how attackers could distort pricing and demand\npatterns. We finally present recommendations for researchers, industry\ndevelopers, policymakers, and LEM stakeholders to secure future LEM\ndeployments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01536v1", "categories": ["cs.CR", "cs.SY", "eess.SY"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01536v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "本地能源市场中的网络安全问题", "tldr": "本地能源市场面临日益增长的网络安全威胁，本研究识别了关键漏洞，模拟了网络攻击场景，并提出了安全建议。", "motivation": "本地能源市场（LEMs）对能源转型至关重要，但由于依赖智能电网通信标准和易受攻击的物联网设备，它们面临日益增长的网络安全威胁。这些漏洞可能被利用来操纵市场运作、损害参与者隐私并破坏电力分配网络的稳定。", "method": "本研究将LEM通信流映射到现有标准，强调了已识别的关键漏洞的潜在影响，并对一个保护隐私的LEM模型进行了网络攻击场景模拟以评估其影响。", "result": "研究结果揭示了攻击者如何扭曲定价和需求模式。", "conclusion": "本研究最终向研究人员、行业开发者、政策制定者和LEM利益相关者提出了确保未来LEM部署安全的建议。", "translation": "本地能源市场（LEMs）尽管对能源转型至关重要，但由于其对智能电网通信标准和易受攻击的物联网（IoT）设备的高度依赖，正面临日益增长的网络安全威胁。这是一个关键问题，因为这些漏洞可能被利用来操纵市场运作、损害参与者隐私并破坏电力分配网络的稳定。这项工作将LEM通信流映射到现有标准，强调了已识别的关键漏洞的潜在影响，并对一个保护隐私的LEM模型进行了网络攻击场景模拟以评估其影响。研究结果揭示了攻击者如何扭曲定价和需求模式。我们最终向研究人员、行业开发者、政策制定者和LEM利益相关者提出了确保未来LEM部署安全的建议。", "summary": "本研究关注本地能源市场（LEMs）面临的网络安全挑战，这些挑战源于其对智能电网和物联网设备的依赖。论文识别了潜在漏洞，并模拟了网络攻击对LEM模型的影响，揭示了攻击者如何操变定价和需求模式。最后，研究提出了确保未来LEM部署安全的建议。", "keywords": "本地能源市场, 网络安全, 智能电网, 物联网, 网络攻击", "comments": "该论文创新性地将网络安全威胁与本地能源市场结合，通过模拟攻击场景量化了潜在风险，并为多方利益相关者提供了实用的安全建议，具有重要的现实意义。"}}
{"id": "2507.01275", "title": "Frequency Domain-Based Diffusion Model for Unpaired Image Dehazing", "authors": ["Chengxu Liu", "Lu Qi", "Jinshan Pan", "Xueming Qian", "Ming-Hsuan Yang"], "summary": "Unpaired image dehazing has attracted increasing attention due to its\nflexible data requirements during model training. Dominant methods based on\ncontrastive learning not only introduce haze-unrelated content information, but\nalso ignore haze-specific properties in the frequency domain (\\ie,~haze-related\ndegradation is mainly manifested in the amplitude spectrum). To address these\nissues, we propose a novel frequency domain-based diffusion model, named \\ours,\nfor fully exploiting the beneficial knowledge in unpaired clear data. In\nparticular, inspired by the strong generative ability shown by Diffusion Models\n(DMs), we tackle the dehazing task from the perspective of frequency domain\nreconstruction and perform the DMs to yield the amplitude spectrum consistent\nwith the distribution of clear images. To implement it, we propose an Amplitude\nResidual Encoder (ARE) to extract the amplitude residuals, which effectively\ncompensates for the amplitude gap from the hazy to clear domains, as well as\nprovide supervision for the DMs training. In addition, we propose a Phase\nCorrection Module (PCM) to eliminate artifacts by further refining the phase\nspectrum during dehazing with a simple attention mechanism. Experimental\nresults demonstrate that our \\ours outperforms other state-of-the-art methods\non both synthetic and real-world datasets.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.01275v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01275v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于频域的无配对图像去雾扩散模型", "tldr": "本文提出了一种名为\\ours的基于频域的扩散模型，通过在频域重建振幅谱并校正相位谱，解决了无配对图像去雾中现有方法引入无关内容和忽略频域特性的问题，并在去雾性能上超越了现有SOTA方法。", "motivation": "现有的无配对图像去雾方法（主要基于对比学习）存在两个问题：一是引入了与雾无关的内容信息，二是忽略了频域中与雾相关的特性（即雾相关的退化主要体现在振幅谱中）。为了解决这些问题并充分利用无配对清晰数据中的有益知识，本文提出了新的方法。", "method": "本文提出了一种新颖的基于频域的扩散模型，名为\\ours，用于无配对图像去雾。该模型将去雾任务视为频域重建问题，并利用扩散模型（DMs）生成与清晰图像分布一致的振幅谱。具体实现包括：1) 提出振幅残差编码器（ARE）来提取振幅残差，有效补偿从有雾到清晰域的振幅差距，并为DMs训练提供监督。2) 提出相位校正模块（PCM），通过简单的注意力机制在去雾过程中进一步细化相位谱，以消除伪影。", "result": "实验结果表明，\\ours在合成数据集和真实世界数据集上的性能均优于其他最先进的方法。", "conclusion": "该论文提出了一种新颖的基于频域的扩散模型\\ours，通过在频域进行振幅谱重建和相位谱校正，有效解决了无配对图像去雾的挑战，并在去雾性能上取得了显著提升，超越了现有SOTA方法。", "translation": "无配对图像去雾因其在模型训练过程中灵活的数据需求而受到越来越多的关注。主流的基于对比学习的方法不仅引入了与雾无关的内容信息，而且忽略了频域中与雾相关的特性（即，与雾相关的退化主要体现在振幅谱中）。为了解决这些问题，我们提出了一种新颖的基于频域的扩散模型，名为\\ours，以充分利用无配对清晰数据中的有益知识。特别是，受扩散模型（DMs）所展示的强大生成能力的启发，我们从频域重建的角度处理去雾任务，并使用DMs生成与清晰图像分布一致的振幅谱。为了实现这一点，我们提出了一个振幅残差编码器（ARE）来提取振幅残差，这有效地补偿了从有雾到清晰域的振幅差距，并为DMs训练提供了监督。此外，我们提出了一个相位校正模块（PCM），通过在去雾过程中利用简单的注意力机制进一步细化相位谱来消除伪影。实验结果表明，我们的\\ours在合成数据集和真实世界数据集上的性能均优于其他最先进的方法。", "summary": "本文提出了一种名为\\ours的基于频域的扩散模型，用于解决无配对图像去雾问题。针对现有方法在频域处理上的不足，\\ours将去雾任务转化为频域重建，利用扩散模型生成与清晰图像一致的振幅谱。模型包含振幅残差编码器（ARE）以补偿振幅差距并提供监督，以及相位校正模块（PCM）以通过注意力机制细化相位谱并消除伪影。实验证明，\\ours在合成和真实数据集上均优于现有最先进方法。", "keywords": "无配对图像去雾, 扩散模型, 频域, 振幅谱, 相位校正", "comments": "该论文的创新点在于将扩散模型引入到无配对图像去雾任务中，并创造性地从频域角度进行处理。通过分别关注振幅谱的重建和相位谱的校正，并设计了ARE和PCM两个关键模块，有效解决了传统方法中内容信息引入和频域特性忽略的问题，为无配对去雾提供了一个新颖且高效的解决方案。其在频域的深入探索，特别是对振幅和相位的独立处理，是值得关注的亮点。"}}
{"id": "2507.01471", "title": "Analysis of Drone-Assisted Building Inspection Training in VR vs 2D Monitor Display: an EEG Study", "authors": ["Pengkun Liu", "Jackson Greene", "Jiali Huang", "Pingbo Tang", "Yu Hou"], "summary": "Researchers have been using simulation-based methods for drone-assisted\ninspection training. Multiple brain regions are associated with information\nprocesses and decision-making, and the connectivity of these regions may\nfurther influence inspectors' performance. However, researchers do not\nunderstand the pathways of the information flows when drone pilots process the\nmaintenance and manipulation of information, which may affect the efficiency of\ntacit knowledge transfer. This study aims to reveal the causal connection\nbetween participants' brain regions using an electroencephalogram and dynamic\ncausal modeling when processing drone-assisted building energy audit tasks\nusing different display modalities. The results showed similar single-direction\nconnectivity patterns for the different simulation groups. The results also\nshowed similar patterns between brain regions related to visual inspection\nperformance before and after training. These findings highlight the nature of\nbrain asymmetries and may be utilized in measuring cognitive states and\ndesigning adaptive automation in the knowledge transfer of drone-based\ninspection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01471v1", "categories": ["cs.HC"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01471v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "无人机辅助建筑检查培训在VR与2D显示器中的对比分析：一项脑电图研究", "tldr": "本研究使用脑电图和动态因果模型分析了在VR和2D显示器下进行无人机辅助建筑检查培训时参与者大脑区域的信息流和连接模式，发现不同显示模式下大脑连接模式相似，且训练前后视觉检查相关脑区模式相似，这有助于理解认知状态和设计适应性自动化。", "motivation": "研究人员使用模拟方法进行无人机辅助检查培训，但尚不清楚无人机飞行员在处理维护和操作信息时信息流的路径，这可能会影响内隐知识转移的效率。", "method": "本研究使用脑电图 (EEG) 和动态因果模型 (DCM) 来揭示参与者在处理不同显示模式（VR vs 2D 监视器）下的无人机辅助建筑能源审计任务时大脑区域之间的因果连接。", "result": "结果显示，不同模拟组具有相似的单向连接模式。在训练前后，与视觉检查性能相关的大脑区域也显示出相似的模式。", "conclusion": "这些发现强调了大脑不对称的性质，可用于测量认知状态和设计无人机检查知识转移中的自适应自动化。", "translation": "研究人员一直在使用基于模拟的方法进行无人机辅助检查培训。多个大脑区域与信息处理和决策相关，这些区域的连接性可能进一步影响检查员的表现。然而，研究人员不了解无人机飞行员在处理维护和操作信息时信息流的路径，这可能会影响内隐知识转移的效率。本研究旨在通过脑电图和动态因果模型，揭示参与者在使用不同显示模式处理无人机辅助建筑能源审计任务时大脑区域之间的因果连接。结果显示，不同模拟组具有相似的单向连接模式。结果还显示，在训练前后，与视觉检查性能相关的大脑区域之间也存在相似的模式。这些发现突出了大脑不对称的性质，可用于测量认知状态和设计无人机检查知识转移中的自适应自动化。", "summary": "本研究通过脑电图和动态因果模型，对比分析了在VR和2D显示器环境下进行无人机辅助建筑检查培训时，参与者大脑区域的信息流和连接模式。研究旨在揭示信息流路径对内隐知识转移效率的影响。结果表明，不同模拟显示模式下大脑区域的单向连接模式相似，且训练前后与视觉检查性能相关的脑区模式也相似。这些发现有助于理解大脑不对称性，并为测量认知状态和设计无人机辅助检查的自适应自动化系统提供依据。", "keywords": "无人机辅助检查, 虚拟现实, 脑电图, 动态因果模型, 知识转移", "comments": "这项研究通过使用EEG和DCM深入探讨了无人机辅助检查培训中不同显示模式对大脑信息处理的影响，其创新之处在于从神经科学层面解释了培训效果。这项工作对于优化虚拟培训环境和提高知识转移效率具有重要意义。然而，抽象中未明确提及参与者的具体数量和特征，这可能影响结果的普适性。"}}
{"id": "2507.01034", "title": "Data-driven Insights for Informed Decision-Making: Applying LSTM Networks for Robust Electricity Forecasting in Libya", "authors": ["Asma Agaal", "Mansour Essgaer", "Hend M. Farkash", "Zulaiha Ali Othman"], "summary": "Accurate electricity forecasting is crucial for grid stability and energy\nplanning, especially in Benghazi, Libya, where frequent load shedding,\ngeneration deficits, and infrastructure limitations persist. This study\nproposes a data-driven approach to forecast electricity load, generation, and\ndeficits for 2025 using historical data from 2019 (a year marked by\ninstability) and 2023 (a more stable year). Multiple time series models were\napplied, including ARIMA, seasonal ARIMA, dynamic regression ARIMA, exponential\nsmoothing, extreme gradient boosting, and Long Short-Term Memory (LSTM) neural\nnetworks. The dataset was enhanced through missing value imputation, outlier\nsmoothing, and log transformation. Performance was assessed using mean squared\nerror, root mean squared error, mean absolute error, and mean absolute\npercentage error. LSTM outperformed all other models, showing strong\ncapabilities in modeling non-stationary and seasonal patterns. A key\ncontribution of this work is an optimized LSTM framework that integrates\nexogenous factors such as temperature and humidity, offering robust performance\nin forecasting multiple electricity indicators. These results provide practical\ninsights for policymakers and grid operators to enable proactive load\nmanagement and resource planning in data-scarce, volatile regions.", "comment": "This article was published in International Journal of Intelligent\n  Systems and Applications (IJISA) (MECS Press), Vol. 17, No. 3, 8 Jun. 2025,\n  DOI: https://doi.org/10.5815/ijisa.2025.03.05", "pdf_url": "http://arxiv.org/pdf/2507.01034v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01034v1", "date": "2025-06-20", "updated": "2025-06-20", "AI": {"title_translation": "数据驱动的洞察力实现明智决策：在利比亚应用LSTM网络进行鲁棒电力预测", "tldr": "本研究在利比亚背景下，使用LSTM网络及多种模型对电力负荷、发电量和赤字进行预测，结果显示LSTM表现最佳，为政策制定者提供实用见解。", "motivation": "利比亚班加西地区电网不稳定、频繁停电、发电量不足和基础设施限制，急需准确的电力预测以实现电网稳定和能源规划。", "method": "本研究提出了一种数据驱动的方法，利用2019年和2023年的历史数据预测2025年的电力负荷、发电量和赤字。应用了多种时间序列模型，包括ARIMA、季节性ARIMA、动态回归ARIMA、指数平滑、极端梯度提升和长短期记忆（LSTM）神经网络。数据集通过缺失值插补、异常值平滑和对数变换进行增强。性能评估指标包括均方误差、均方根误差、平均绝对误差和平均绝对百分比误差。一个关键贡献是优化了LSTM框架，该框架集成了温度和湿度等外部因素。", "result": "LSTM在所有模型中表现最佳，显示出建模非平稳和季节性模式的强大能力。优化后的LSTM框架集成了外部因素，在预测多种电力指标方面表现出鲁棒性能。", "conclusion": "这些结果为政策制定者和电网运营商提供了实用的见解，以在数据稀缺、不稳定的地区实现主动负荷管理和资源规划。", "translation": "准确的电力预测对于电网稳定和能源规划至关重要，尤其是在利比亚班加西，那里频繁出现限电、发电量不足和基础设施限制。本研究提出了一种数据驱动的方法，利用2019年（一个不稳定年份）和2023年（一个更稳定年份）的历史数据预测2025年的电力负荷、发电量和赤字。应用了多种时间序列模型，包括ARIMA、季节性ARIMA、动态回归ARIMA、指数平滑、极端梯度提升和长短期记忆（LSTM）神经网络。数据集通过缺失值插补、异常值平滑和对数变换进行增强。性能通过均方误差、均方根误差、平均绝对误差和平均绝对百分比误差进行评估。LSTM优于所有其他模型，在建模非平稳和季节性模式方面表现出强大的能力。这项工作的一个关键贡献是一个优化的LSTM框架，该框架集成了温度和湿度等外部因素，在预测多种电力指标方面提供了鲁棒的性能。这些结果为政策制定者和电网运营商提供了实用的见解，以在数据稀缺、不稳定的地区实现主动负荷管理和资源规划。", "summary": "本研究针对利比亚班加西地区电力预测的挑战，提出了一种数据驱动的方法，利用历史数据和多种时间序列模型（包括ARIMA、SARIMA、LSTM等）对2025年的电力负荷、发电量和赤字进行预测。研究发现，经过数据增强和优化的LSTM网络（整合了温度和湿度等外部因素）在预测非平稳和季节性电力模式方面表现最佳，为当地电网管理和资源规划提供了重要的实用见解。", "keywords": "电力预测, LSTM, 时间序列, 利比亚, 数据驱动", "comments": "本论文的创新之处在于其针对利比亚特定区域的电力预测，结合了多种时间序列模型并特别优化了LSTM网络以整合外部因素，这对于数据稀缺和不稳定的地区具有重要的实践意义。研究结果强调了深度学习模型在复杂非线性时间序列预测中的优越性，为能源管理提供了有力的工具。"}}
{"id": "2507.01728", "title": "Token Communication in the Era of Large Models: An Information Bottleneck-Based Approach", "authors": ["Hao Wei", "Wanli Ni", "Wen Wang", "Wenjun Xu", "Dusit Niyato", "Ping Zhang"], "summary": "This letter proposes UniToCom, a unified token communication paradigm that\ntreats tokens as the fundamental units for both processing and wireless\ntransmission. Specifically, to enable efficient token representations, we\npropose a generative information bottleneck (GenIB) principle, which\nfacilitates the learning of tokens that preserve essential information while\nsupporting reliable generation across multiple modalities. By doing this,\nGenIB-based tokenization is conducive to improving the communication efficiency\nand reducing computational complexity. Additionally, we develop $\\sigma$-GenIB\nto address the challenges of variance collapse in autoregressive modeling,\nmaintaining representational diversity and stability. Moreover, we employ a\ncausal Transformer-based multimodal large language model (MLLM) at the receiver\nto unify the processing of both discrete and continuous tokens under the\nnext-token prediction paradigm. Simulation results validate the effectiveness\nand superiority of the proposed UniToCom compared to baselines under dynamic\nchannel conditions. By integrating token processing with MLLMs, UniToCom\nenables scalable and generalizable communication in favor of multimodal\nunderstanding and generation, providing a potential solution for\nnext-generation intelligent communications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01728v1", "categories": ["eess.SP", "cs.LG"], "cate": "eess.SP", "url": "http://arxiv.org/abs/2507.01728v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "大模型时代的Token通信：一种基于信息瓶颈的方法", "tldr": "UniToCom是一种统一的Token通信范式，将Token作为处理和无线传输的基本单位。它引入了生成式信息瓶颈（GenIB）原则来学习高效的Token表示，从而提高通信效率和降低计算复杂性。还提出了$\\sigma$-GenIB来解决自回归模型中的方差崩溃问题，并在接收端使用基于因果Transformer的多模态大语言模型（MLLM）来统一离散和连续Token的处理。", "motivation": "为了在大模型时代实现高效的Token表示、提高通信效率并降低计算复杂性，同时解决自回归模型中方差崩溃的挑战，本文提出了UniToCom范式。", "method": "本文提出了UniToCom，这是一种将Token视为处理和无线传输基本单位的统一Token通信范式。具体地，提出了生成式信息瓶颈（GenIB）原则，用于学习保留基本信息并支持跨模态可靠生成的Token。为了解决自回归模型中的方差崩溃问题，开发了$\\sigma$-GenIB。此外，在接收端采用基于因果Transformer的多模态大语言模型（MLLM）来统一离散和连续Token的预测处理。", "result": "仿真结果验证了所提出的UniToCom在动态信道条件下与基线相比的有效性和优越性。", "conclusion": "通过将Token处理与多模态大语言模型（MLLM）集成，UniToCom实现了可扩展和可泛化的通信，有利于多模态理解和生成，为下一代智能通信提供了一个潜在的解决方案。", "translation": "这封信提出了UniToCom，一种统一的Token通信范式，它将Token视为处理和无线传输的基本单位。具体来说，为了实现高效的Token表示，我们提出了一个生成式信息瓶颈（GenIB）原则，它有助于学习保留基本信息同时支持跨多种模态可靠生成的Token。通过这样做，基于GenIB的Token化有助于提高通信效率和降低计算复杂性。此外，我们开发了$\\sigma$-GenIB来解决自回归建模中方差崩溃的挑战，保持表示多样性和稳定性。此外，我们在接收端采用基于因果Transformer的多模态大语言模型（MLLM）来在下一Token预测范式下统一处理离散和连续Token。仿真结果验证了所提出的UniToCom在动态信道条件下与基线相比的有效性和优越性。通过将Token处理与MLLM集成，UniToCom实现了可扩展和可泛化的通信，有利于多模态理解和生成，为下一代智能通信提供了一个潜在的解决方案。", "summary": "本文提出UniToCom，一种统一的Token通信范式，将Token作为处理和传输的核心单位。为高效表示，引入生成式信息瓶颈（GenIB）原则学习保留关键信息且支持多模态生成的Token，从而提升通信效率并降低计算复杂性。为解决自回归模型中的方差崩溃问题，进一步发展了$\\sigma$-GenIB。在接收端，利用基于因果Transformer的多模态大语言模型（MLLM）统一处理离散和连续Token。仿真结果表明，UniToCom在动态信道条件下优于现有基线，为下一代智能通信中多模态理解和生成提供了可扩展和可泛化的解决方案。", "keywords": "Token通信, 信息瓶颈, 大模型, 多模态, 无线传输", "comments": "本文提出了一种新颖的UniToCom范式，其创新点在于将Token作为通信的基本单位，并引入了生成式信息瓶颈（GenIB）原则来优化Token表示，实现了信息保留和多模态生成。特别地，$\\sigma$-GenIB的提出解决了自回归模型中的方差崩溃问题，增强了模型的稳定性和多样性。此外，将MLLM应用于接收端统一处理不同类型的Token，体现了对大模型时代通信需求的深刻理解。这项工作为未来的智能通信提供了一个有前景的方向，尤其是在多模态数据传输和处理方面。"}}
{"id": "2507.01778", "title": "A Hybrid Ensemble Learning Framework for Image-Based Solar Panel Classification", "authors": ["Vivek Tetarwal", "Sandeep Kumar"], "summary": "The installation of solar energy systems is on the rise, and therefore,\nappropriate maintenance techniques are required to be used in order to maintain\nmaximum performance levels. One of the major challenges is the automated\ndiscrimination between clean and dirty solar panels. This paper presents a\nnovel Dual Ensemble Neural Network (DENN) to classify solar panels using\nimage-based features. The suggested approach utilizes the advantages offered by\nvarious ensemble models by integrating them into a dual framework, aimed at\nimproving both classification accuracy and robustness. The DENN model is\nevaluated in comparison to current ensemble methods, showcasing its superior\nperformance across a range of assessment metrics. The proposed approach\nperforms the best compared to other methods and reaches state-of-the-art\naccuracy on experimental results for the Deep Solar Eye dataset, effectively\nserving predictive maintenance purposes in solar energy systems. It reveals the\npotential of hybrid ensemble learning techniques to further advance the\nprospects of automated solar panel inspections as a scalable solution to\nreal-world challenges.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.01778v1", "categories": ["cs.IT", "cs.CV", "math.IT"], "cate": "cs.IT", "url": "http://arxiv.org/abs/2507.01778v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "一种基于图像的太阳能电池板分类混合集成学习框架", "tldr": "本文提出了一种新颖的双集成神经网络（DENN），用于基于图像特征对太阳能电池板进行分类，以区分清洁和脏污的面板，并在Deep Solar Eye数据集上达到了最先进的准确率。", "motivation": "太阳能系统安装量不断增加，需要适当的维护技术来保持最佳性能。其中一个主要挑战是如何自动化区分清洁和脏污的太阳能电池板。", "method": "本文提出了一种新颖的双集成神经网络（DENN），该模型通过整合多种集成模型的优势，旨在提高分类准确性和鲁棒性。该方法利用图像特征进行分类。", "result": "DENN模型与现有集成方法相比，在多种评估指标上表现出卓越的性能。所提出的方法优于其他方法，并在Deep Solar Eye数据集的实验结果中达到了最先进的准确率。", "conclusion": "混合集成学习技术在自动化太阳能电池板检查方面具有巨大潜力，可作为解决实际挑战的可扩展解决方案，有效服务于太阳能系统的预测性维护目的。", "translation": "太阳能系统的安装量正在增加，因此需要采用适当的维护技术来保持其最大性能水平。其中一个主要挑战是自动化区分清洁和脏污的太阳能电池板。本文提出了一种新颖的双集成神经网络（DENN），利用基于图像的特征对太阳能电池板进行分类。所提出的方法通过将各种集成模型的优势整合到一个双重框架中，旨在提高分类准确性和鲁棒性。DENN模型与当前的集成方法进行了比较评估，展示了其在各种评估指标上的卓越性能。所提出的方法优于其他方法，并在Deep Solar Eye数据集的实验结果中达到了最先进的准确率，有效地服务于太阳能系统的预测性维护目的。它揭示了混合集成学习技术在进一步推动自动化太阳能电池板检查前景方面的潜力，作为解决实际挑战的可扩展解决方案。", "summary": "本文提出了一种名为双集成神经网络（DENN）的新型混合集成学习框架，用于解决太阳能电池板自动化维护中的清洁与脏污分类挑战。该框架结合了多种集成模型的优点，旨在提高图像分类的准确性和鲁棒性。实验结果表明，DENN在Deep Solar Eye数据集上优于现有方法，并取得了最先进的性能，证明了其在太阳能系统预测性维护中的应用潜力。", "keywords": "太阳能电池板分类, 混合集成学习, 双集成神经网络, 图像分类, 预测性维护", "comments": "该论文提出了一种创新的双集成神经网络（DENN）框架，通过结合不同集成模型的优势，有效解决了太阳能电池板的自动化分类问题。其在特定数据集上达到最先进性能的成果，表明了混合集成学习在实际工业应用中的巨大潜力，尤其是在预测性维护领域。"}}
{"id": "2507.01880", "title": "Evolving HPC services to enable ML workloads on HPE Cray EX", "authors": ["Stefano Schuppli", "Fawzi Mohamed", "Henrique Mendonça", "Nina Mujkanovic", "Elia Palme", "Dino Conciatore", "Lukas Drescher", "Miguel Gila", "Pim Witlox", "Joost VandeVondele", "Maxime Martinasso", "Thomas C. Schulthess", "Torsten Hoefler"], "summary": "The Alps Research Infrastructure leverages GH200 technology at scale,\nfeaturing 10,752 GPUs. Accessing Alps provides a significant computational\nadvantage for researchers in Artificial Intelligence (AI) and Machine Learning\n(ML). While Alps serves a broad range of scientific communities, traditional\nHPC services alone are not sufficient to meet the dynamic needs of the ML\ncommunity. This paper presents an initial investigation into extending HPC\nservice capabilities to better support ML workloads. We identify key challenges\nand gaps we have observed since the early-access phase (2023) of Alps by the\nSwiss AI community and propose several technological enhancements. These\ninclude a user environment designed to facilitate the adoption of HPC for ML\nworkloads, balancing performance with flexibility; a utility for rapid\nperformance screening of ML applications during development; observability\ncapabilities and data products for inspecting ongoing large-scale ML workloads;\na utility to simplify the vetting of allocated nodes for compute readiness; a\nservice plane infrastructure to deploy various types of workloads, including\nsupport and inference services; and a storage infrastructure tailored to the\nspecific needs of ML workloads. These enhancements aim to facilitate the\nexecution of ML workloads on HPC systems, increase system usability and\nresilience, and better align with the needs of the ML community. We also\ndiscuss our current approach to security aspects. This paper concludes by\nplacing these proposals in the broader context of changes in the communities\nserved by HPC infrastructure like ours.", "comment": "Presented at the Cray User Group 2025 (CUG'25)", "pdf_url": "http://arxiv.org/pdf/2507.01880v1", "categories": ["cs.DC", "cs.LG"], "cate": "cs.DC", "url": "http://arxiv.org/abs/2507.01880v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "演进HPC服务以在HPE Cray EX上支持ML工作负载", "tldr": "论文探讨了如何改进HPC服务以更好地支持ML工作负载，提出了多项技术增强来解决现有挑战，提高ML在HPC系统上的可用性和性能。", "motivation": "传统的高性能计算（HPC）服务不足以满足机器学习（ML）社区的动态需求，尤其是在像Alps这样的大规模GPU基础设施上。", "method": "通过对Alps系统早期访问阶段观察到的挑战和差距进行初步调查，论文提出了多项技术增强，包括：为ML工作负载设计的用户环境、ML应用快速性能筛选工具、大规模ML工作负载的可观测性、节点计算准备就绪检查工具、支持多种工作负载的服务平面基础设施以及为ML定制的存储基础设施。论文还讨论了安全方面。", "result": "提出的增强措施旨在促进ML工作负载在HPC系统上的执行，提高系统可用性和弹性，并更好地满足ML社区的需求。", "conclusion": "论文将这些提议置于HPC基础设施所服务社区变化的更广阔背景中进行讨论，强调了HPC服务演进以适应ML需求的重要性。", "translation": "Alps研究基础设施大规模利用GH200技术，拥有10,752个GPU。访问Alps为人工智能（AI）和机器学习（ML）研究人员提供了显著的计算优势。虽然Alps服务于广泛的科学社区，但传统的HPC服务不足以满足ML社区的动态需求。本文对扩展HPC服务能力以更好地支持ML工作负载进行了初步调查。我们识别了自Alps早期访问阶段（2023年）以来瑞士AI社区观察到的关键挑战和差距，并提出了多项技术增强。这些增强包括：一个旨在促进HPC在ML工作负载中应用的、平衡性能与灵活性的用户环境；一个用于在开发过程中对ML应用程序进行快速性能筛选的工具；用于检查正在进行的大规模ML工作负载的可观测性能力和数据产品；一个简化已分配节点计算准备就绪验证的工具；一个用于部署各种类型工作负载（包括支持和推理服务）的服务平面基础设施；以及一个为ML工作负载特定需求量身定制的存储基础设施。这些增强旨在促进ML工作负载在HPC系统上的执行，提高系统可用性和弹性，并更好地与ML社区的需求保持一致。我们还讨论了当前在安全方面的方法。本文最后将这些提议置于HPC基础设施所服务社区变化的更广阔背景中进行讨论。", "summary": "本文探讨了如何通过扩展高性能计算（HPC）服务来更好地支持机器学习（ML）工作负载，特别是在像Alps这样的大规模GPU基础设施上。针对传统HPC服务无法满足ML社区动态需求的挑战，论文识别了关键差距并提出了一系列技术增强措施。这些增强包括优化用户环境、提供性能筛选工具、增强可观测性、简化节点验证、构建灵活的服务平面以及定制存储基础设施。这些改进旨在提高ML工作负载在HPC系统上的执行效率、系统可用性和弹性，并更好地适应ML社区的需求，同时也考虑了安全方面。", "keywords": "HPC, ML workloads, Alps, Service evolution, GPU infrastructure", "comments": "这篇论文强调了HPC与ML融合的关键挑战和解决方案，特别是在大规模GPU系统上。其创新点在于提出了一系列具体的技术增强，从用户环境到存储基础设施，全面提升HPC对ML工作负载的支持能力。这对于推动AI研究和应用在高性能计算环境中的发展具有重要意义。"}}
{"id": "2507.01387", "title": "BronchoGAN: Anatomically consistent and domain-agnostic image-to-image translation for video bronchoscopy", "authors": ["Ahmad Soliman", "Ron Keuth", "Marian Himstedt"], "summary": "The limited availability of bronchoscopy images makes image synthesis\nparticularly interesting for training deep learning models. Robust image\ntranslation across different domains -- virtual bronchoscopy, phantom as well\nas in-vivo and ex-vivo image data -- is pivotal for clinical applications. This\npaper proposes BronchoGAN introducing anatomical constraints for image-to-image\ntranslation being integrated into a conditional GAN. In particular, we force\nbronchial orifices to match across input and output images. We further propose\nto use foundation model-generated depth images as intermediate representation\nensuring robustness across a variety of input domains establishing models with\nsubstantially less reliance on individual training datasets. Moreover our\nintermediate depth image representation allows to easily construct paired image\ndata for training. Our experiments showed that input images from different\ndomains (e.g. virtual bronchoscopy, phantoms) can be successfully translated to\nimages mimicking realistic human airway appearance. We demonstrated that\nanatomical settings (i.e. bronchial orifices) can be robustly preserved with\nour approach which is shown qualitatively and quantitatively by means of\nimproved FID, SSIM and dice coefficients scores. Our anatomical constraints\nenabled an improvement in the Dice coefficient of up to 0.43 for synthetic\nimages. Through foundation models for intermediate depth representations,\nbronchial orifice segmentation integrated as anatomical constraints into\nconditional GANs we are able to robustly translate images from different\nbronchoscopy input domains. BronchoGAN allows to incorporate public CT scan\ndata (virtual bronchoscopy) in order to generate large-scale bronchoscopy image\ndatasets with realistic appearance. BronchoGAN enables to bridge the gap of\nmissing public bronchoscopy images.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01387v1", "categories": ["eess.IV", "cs.CV"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01387v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "BronchoGAN：用于视频支气管镜检查的解剖学一致且领域无关的图像到图像翻译", "tldr": "BronchoGAN是一种条件生成对抗网络，通过引入解剖学约束（如支气管口匹配）和使用基础模型生成的深度图像作为中间表示，实现了跨不同支气管镜检查领域（虚拟、模型、体内、体外）的鲁棒图像到图像翻译，从而生成逼真的气道图像并弥补公共数据集的不足。", "motivation": "深度学习模型训练所需的支气管镜图像有限，且临床应用需要跨不同领域（虚拟支气管镜检查、模型以及体内外图像数据）的鲁棒图像翻译。", "method": "本文提出了BronchoGAN，它是一个集成了条件GAN的图像到图像翻译模型，并引入了以下解剖学约束：强制输入和输出图像中的支气管口匹配。此外，该方法使用基础模型生成的深度图像作为中间表示，以确保在各种输入域中的鲁棒性，并减少对单个训练数据集的依赖，同时也便于构建配对图像数据进行训练。", "result": "实验表明，来自不同领域（如虚拟支气管镜检查、模型）的输入图像可以成功翻译成模拟真实人类气道外观的图像。该方法能够鲁棒地保留解剖学设置（即支气管口），并通过改进的FID、SSIM和Dice系数分数进行定性和定量证明。解剖学约束使合成图像的Dice系数提高了高达0.43。", "conclusion": "BronchoGAN能够通过将支气管口分割作为解剖学约束集成到条件GAN中，并利用基础模型进行中间深度表示，从而鲁棒地翻译来自不同支气管镜输入域的图像。它允许结合公共CT扫描数据（虚拟支气管镜检查）以生成大规模、外观逼真的支气管镜图像数据集，从而弥补了公共支气管镜图像缺失的空白。", "translation": "支气管镜图像的有限可用性使得图像合成对于训练深度学习模型特别有意义。在不同领域——虚拟支气管镜检查、模型以及体内和体外图像数据——之间进行鲁棒的图像翻译对于临床应用至关重要。本文提出了BronchoGAN，引入了解剖学约束，将其整合到条件GAN中用于图像到图像翻译。特别是，我们强制支气管口在输入和输出图像之间匹配。我们进一步提出使用基础模型生成的深度图像作为中间表示，确保在各种输入域中的鲁棒性，从而建立对单个训练数据集依赖程度大大降低的模型。此外，我们的中间深度图像表示允许轻松构建用于训练的配对图像数据。我们的实验表明，来自不同领域（例如虚拟支气管镜检查、模型）的输入图像可以成功翻译成模仿真实人类气道外观的图像。我们通过改进的FID、SSIM和Dice系数分数，定性和定量地证明了我们的方法能够鲁棒地保留解剖学设置（即支气管口）。我们的解剖学约束使合成图像的Dice系数提高了高达0.43。通过用于中间深度表示的基础模型，将支气管口分割作为解剖学约束集成到条件GAN中，我们能够鲁棒地翻译来自不同支气管镜输入域的图像。BronchoGAN允许整合公共CT扫描数据（虚拟支气管镜检查），以生成大规模、外观逼真的支气管镜图像数据集。BronchoGAN能够弥补公共支气管镜图像缺失的空白。", "summary": "BronchoGAN是一种用于视频支气管镜检查的图像到图像翻译模型，旨在解决支气管镜图像数据稀缺的问题。该模型基于条件GAN，创新性地引入了解剖学约束，确保支气管口在翻译过程中保持一致。通过利用基础模型生成的深度图像作为中间表示，BronchoGAN实现了跨多种输入领域（包括虚拟、模型和真实数据）的鲁棒翻译，从而能生成逼真的人类气道图像。实验证明，该方法能有效提高合成图像的解剖学准确性，并通过量化指标显示出显著性能提升，有助于利用CT扫描数据生成大规模逼真的支气管镜图像数据集，填补公共数据集的空白。", "keywords": "支气管镜检查, 图像到图像翻译, 生成对抗网络, 解剖学约束, 深度图像", "comments": "BronchoGAN的创新之处在于其将解剖学约束（特别是支气管口匹配）集成到条件GAN中，以及利用基础模型生成的深度图像作为中间表示。这种方法不仅提高了图像翻译的解剖学一致性，还显著增强了模型在不同数据域间的泛化能力，并解决了医疗图像领域数据稀缺的痛点。其能够利用公共CT数据生成大规模数据集的潜力，对于推动深度学习在支气管镜检查中的应用具有重要意义。"}}
{"id": "2507.01450", "title": "Multi-Revolution Low-Thrust Trajectory Optimization With Very Sparse Mesh Pseudospectral Method", "authors": ["Yilin Zou", "Fanghua Jiang"], "summary": "Multi-revolution low-thrust trajectory optimization problems are important\nand challenging in space mission design. In this paper, an efficient, accurate,\nand widely applicable pseudospectral method is proposed to solve\nmulti-revolution low-thrust trajectory optimization problems with various\nobjective functions and perturbations. The method is based on the Sundman\ntransformation and pseudospectral method, together with a sparse mesh that is\nmonotonic, near-uniformly spaced, and uniformly scattered on the unit circle.\nTwo methods are proposed to construct the mesh: a deterministic method based on\nrotation mapping; a stochastic method utilizing autocorrelated random\nsequences. Core mechanisms ensuring the correctness of the method are analyzed,\nincluding the dual roles of mesh points as both integration points in the\ntemporal domain and sampling points in the angular domain, the slow dynamics of\nthe system excluding the fast angle variable, and the nearly commutative vector\nfields generated by applying different control inputs. The method is\ndemonstrated through a multi-revolution low-thrust orbital rendezvous problem.\nResults show that the proposed method achieves high accuracy with only a few\nseconds of computational time for challenging problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01450v1", "categories": ["eess.SY", "cs.SY", "math.OC"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01450v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于极稀疏网格伪谱法的多圈低推力轨迹优化", "tldr": "本文提出了一种高效、精确且适用广泛的伪谱法，用于解决多圈低推力轨迹优化问题，该方法结合了Sundman变换和稀疏网格，并在多圈低推力轨道交会问题中表现出高精度和快速计算的优势。", "motivation": "多圈低推力轨迹优化问题在空间任务设计中既重要又具有挑战性。", "method": "本文提出了一种基于Sundman变换和伪谱法的伪谱方法，并结合了单调、近均匀分布且在单位圆上均匀分散的稀疏网格。提出了两种网格构建方法：一种是基于旋转映射的确定性方法；另一种是利用自相关随机序列的随机方法。该方法分析了网格点作为时间域积分点和角度域采样点的双重作用、系统排除快速角度变量的慢动力学以及不同控制输入产生的近似可交换矢量场等核心机制。", "result": "所提出的方法在具有挑战性的问题上，仅需几秒的计算时间即可达到高精度。", "conclusion": "所提出的基于极稀疏网格伪谱法能够高效、准确地解决多圈低推力轨迹优化问题，并在实际应用中展现出优异的性能。", "translation": "多圈低推力轨迹优化问题在空间任务设计中既重要又具有挑战性。本文提出了一种高效、精确且适用广泛的伪谱法，用于解决具有各种目标函数和扰动的多圈低推力轨迹优化问题。该方法基于Sundman变换和伪谱法，并结合了单调、近均匀分布且在单位圆上均匀分散的稀疏网格。提出了两种构建网格的方法：一种是基于旋转映射的确定性方法；另一种是利用自相关随机序列的随机方法。分析了确保该方法正确性的核心机制，包括网格点作为时间域积分点和角度域采样点的双重作用、系统排除快速角度变量的慢动力学以及不同控制输入产生的近似可交换矢量场。通过一个多圈低推力轨道交会问题演示了该方法。结果表明，所提出的方法在具有挑战性的问题上，仅需几秒的计算时间即可达到高精度。", "summary": "本文针对空间任务设计中重要的多圈低推力轨迹优化难题，提出了一种高效、精确且普适性强的伪谱方法。该方法融合了Sundman变换和一种新型的稀疏网格（通过确定性或随机方法构建）。文章深入分析了该方法的关键机制，并通过一个多圈轨道交会问题验证了其有效性，结果显示该方法能在短时间内高精度地解决复杂问题。", "keywords": "轨迹优化, 低推力, 伪谱法, 稀疏网格, Sundman变换", "comments": "该论文的创新点在于提出了结合Sundman变换和新型稀疏网格的伪谱法，并通过两种新颖的网格构建方法提升了多圈低推力轨迹优化的效率和精度。其重要性体现在解决了空间任务设计中的一个关键挑战，并展示了在计算时间和精度上的显著优势。"}}
{"id": "2507.01281", "title": "Rethinking All Evidence: Enhancing Trustworthy Retrieval-Augmented Generation via Conflict-Driven Summarization", "authors": ["Juan Chen", "Baolong Bi", "Wei Zhang", "Jingyan Sui", "Xiaofei Zhu", "Yuanzhuo Wang", "Lingrui Mei", "Shenghua Liu"], "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by\nintegrating their parametric knowledge with external retrieved content.\nHowever, knowledge conflicts caused by internal inconsistencies or noisy\nretrieved content can severely undermine the generation reliability of RAG\nsystems.In this work, we argue that LLMs should rethink all evidence, including\nboth retrieved content and internal knowledge, before generating responses.We\npropose CARE-RAG (Conflict-Aware and Reliable Evidence for RAG), a novel\nframework that improves trustworthiness through Conflict-Driven Summarization\nof all available evidence.CARE-RAG first derives parameter-aware evidence by\ncomparing parameter records to identify diverse internal perspectives. It then\nrefines retrieved evidences to produce context-aware evidence, removing\nirrelevant or misleading content. To detect and summarize conflicts, we distill\na 3B LLaMA3.2 model to perform conflict-driven summarization, enabling reliable\nsynthesis across multiple sources.To further ensure evaluation integrity, we\nintroduce a QA Repair step to correct outdated or ambiguous benchmark\nanswers.Experiments on revised QA datasets with retrieval data show that\nCARE-RAG consistently outperforms strong RAG baselines, especially in scenarios\nwith noisy or conflicting evidence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01281v1", "categories": ["cs.CL", "cs.AI"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01281v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "重新思考所有证据：通过冲突驱动的摘要增强可信赖的检索增强生成", "tldr": "提出CARE-RAG框架，通过冲突驱动的摘要处理检索增强生成（RAG）中的知识冲突，以提高生成可靠性。", "motivation": "检索增强生成（RAG）系统中的知识冲突（由内部不一致或嘈杂的检索内容引起）严重损害了生成可靠性。", "method": "提出CARE-RAG（Conflict-Aware and Reliable Evidence for RAG）框架。首先，通过比较参数记录获取参数感知证据；其次，提炼检索到的证据以生成上下文感知证据；最后，蒸馏一个3B LLaMA3.2模型进行冲突驱动的摘要，以检测和汇总冲突。此外，引入QA修复步骤来纠正过时或模糊的基准答案。", "result": "在修订后的QA数据集和检索数据上的实验表明，CARE-RAG始终优于强大的RAG基线，尤其是在证据嘈杂或冲突的场景中。", "conclusion": "CARE-RAG通过冲突驱动的摘要有效解决了RAG系统中的知识冲突问题，显著提高了生成的可信赖性。", "translation": "检索增强生成（RAG）通过将大型语言模型（LLM）的参数知识与外部检索内容相结合来增强其能力。然而，由内部不一致或嘈杂的检索内容引起的知识冲突会严重损害RAG系统的生成可靠性。在这项工作中，我们认为LLM在生成响应之前应该重新思考所有证据，包括检索内容和内部知识。我们提出了CARE-RAG（Conflict-Aware and Reliable Evidence for RAG），这是一个新颖的框架，通过对所有可用证据进行冲突驱动的摘要来提高可信赖性。CARE-RAG首先通过比较参数记录来推导参数感知证据，以识别多样化的内部视角。然后，它提炼检索到的证据以生成上下文感知证据，删除不相关或误导性的内容。为了检测和汇总冲突，我们蒸馏了一个3B LLaMA3.2模型来执行冲突驱动的摘要，从而实现跨多个来源的可靠合成。为了进一步确保评估的完整性，我们引入了一个QA修复步骤来纠正过时或模糊的基准答案。在修订后的QA数据集和检索数据上的实验表明，CARE-RAG始终优于强大的RAG基线，尤其是在证据嘈杂或冲突的场景中。", "summary": "本研究提出了一种名为CARE-RAG的新型框架，旨在解决检索增强生成（RAG）系统中因内部不一致或嘈杂检索内容导致的知识冲突问题。CARE-RAG通过“重新思考所有证据”并采用冲突驱动的摘要机制来提高生成的可信赖性。其核心方法包括获取参数感知证据、提炼上下文感知证据以及使用蒸馏的LLaMA3.2模型进行冲突检测和摘要。此外，该工作还引入了QA修复步骤以确保评估的准确性。实验结果表明，CARE-RAG在处理冲突或嘈杂证据时，性能优于现有RAG基线。", "keywords": "检索增强生成, 知识冲突, 冲突驱动摘要, 可信赖性, 大型语言模型", "comments": "CARE-RAG的创新点在于其冲突驱动的摘要机制，它促使LLM在生成响应前“重新思考所有证据”，包括内部知识和外部检索内容。这对于提高RAG系统在复杂和不确定信息环境下的可靠性至关重要。QA修复步骤也体现了对评估完整性的关注，这在LLM研究中是一个值得肯定的实践。"}}
{"id": "2507.01533", "title": "Consistency of Learned Sparse Grid Quadrature Rules using NeuralODEs", "authors": ["Hanno Gottschalk", "Emil Partow", "Tobias J. Riedlinger"], "summary": "This paper provides a proof of the consistency of sparse grid quadrature for\nnumerical integration of high dimensional distributions. In a first step, a\ntransport map is learned that normalizes the distribution to a noise\ndistribution on the unit cube. This step is built on the statistical learning\ntheory of neural ordinary differential equations, which has been established\nrecently. Secondly, the composition of the generative map with the quantity of\ninterest is integrated numerically using the Clenshaw-Curtis sparse grid\nquadrature. A decomposition of the total numerical error in quadrature error\nand statistical error is provided. As main result it is proven in the framework\nof empirical risk minimization that all error terms can be controlled in the\nsense of PAC (probably approximately correct) learning and with high\nprobability the numerical integral approximates the theoretical value up to an\narbitrary small error in the limit where the data set size is growing and the\nnetwork capacity is increased adaptively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01533v1", "categories": ["math.NA", "cs.LG", "cs.NA", "math.PR"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01533v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "使用神经常微分方程学习稀疏网格求积规则的一致性", "tldr": "本文证明了使用神经常微分方程学习的传输映射和稀疏网格求积对高维分布进行数值积分的一致性，并量化了误差。", "motivation": "本文旨在为高维分布的数值积分提供稀疏网格求积的一致性证明。", "method": "首先，利用神经常微分方程的统计学习理论，学习一个将分布归一化为单位立方体上噪声分布的传输映射。其次，使用Clenshaw-Curtis稀疏网格求积法对生成映射与感兴趣量进行数值积分。最后，提供了总数值误差在求积误差和统计误差上的分解。", "result": "在经验风险最小化的框架下，证明了所有误差项都可以在PAC（可能近似正确）学习的意义上得到控制。当数据集大小增长且网络容量自适应增加时，数值积分以高概率逼近理论值，误差可任意小。", "conclusion": "本文证明了使用神经常微分方程和稀疏网格求积对高维分布进行数值积分的一致性，并展示了在特定条件下误差可以被有效控制，使得数值积分能够高精度逼近理论值。", "translation": "本文证明了用于高维分布数值积分的稀疏网格求积的一致性。第一步，学习一个传输映射，将分布归一化为单位立方体上的噪声分布。这一步建立在最近建立的神经常微分方程的统计学习理论之上。其次，利用Clenshaw-Curtis稀疏网格求积法对生成映射与感兴趣量进行数值积分。提供了总数值误差在求积误差和统计误差上的分解。作为主要结果，在经验风险最小化的框架下，证明了所有误差项都可以在PAC（可能近似正确）学习的意义上得到控制，并且随着数据集大小的增长和网络容量的自适应增加，数值积分以高概率逼近理论值，误差可任意小。", "summary": "本文证明了将神经常微分方程（NeuralODEs）与稀疏网格求积相结合进行高维分布数值积分的一致性。研究首先利用NeuralODEs学习一个将高维分布归一化到单位立方体的传输映射，然后结合Clenshaw-Curtis稀疏网格求积法对复合函数进行积分。论文分解了总数值误差为求积误差和统计误差，并证明在经验风险最小化框架下，所有误差项均可在PAC学习意义上得到控制，确保在数据量足够大且网络容量适应性增长时，数值积分能以高概率任意接近理论值。", "keywords": "稀疏网格求积, 神经常微分方程, 高维积分, 一致性, PAC学习", "comments": "该论文的创新点在于将最近发展的神经常微分方程（NeuralODEs）的统计学习理论应用于稀疏网格求积法，为高维数值积分提供了一致性证明。这对于处理复杂高维问题具有重要意义。其贡献在于不仅提出了方法，还从理论上证明了误差的可控性，通过PAC学习框架保证了算法的收敛性和精度。"}}
{"id": "2507.01611", "title": "QHARMA-GAN: Quasi-Harmonic Neural Vocoder based on Autoregressive Moving Average Model", "authors": ["Shaowen Chen", "Tomoki Toda"], "summary": "Vocoders, encoding speech signals into acoustic features and allowing for\nspeech signal reconstruction from them, have been studied for decades.\nRecently, the rise of deep learning has particularly driven the development of\nneural vocoders to generate high-quality speech signals. On the other hand, the\nexisting end-to-end neural vocoders suffer from a black-box nature that blinds\nthe speech production mechanism and the intrinsic structure of speech,\nresulting in the ambiguity of separately modeling source excitation and\nresonance characteristics and the loss of flexibly synthesizing or modifying\nspeech with high quality. Moreover, their sequence-wise waveform generation\nusually requires complicated networks, leading to substantial time consumption.\nIn this work, inspired by the quasi-harmonic model (QHM) that represents speech\nas sparse components, we combine the neural network and QHM synthesis process\nto propose a novel framework for the neural vocoder. Accordingly, speech\nsignals can be encoded into autoregressive moving average (ARMA) functions to\nmodel the resonance characteristics, yielding accurate estimates of the\namplitudes and phases of quasi-harmonics at any frequency. Subsequently, the\nspeech can be resynthesized and arbitrarily modified in terms of pitch shifting\nand time stretching with high quality, whereas the time consumption and network\nsize decrease. The experiments indicate that the proposed method leverages the\nstrengths of QHM, the ARMA model, and neural networks, leading to the\noutperformance of our methods over other methods in terms of generation speed,\nsynthesis quality, and modification flexibility.", "comment": "This manuscript is currently under review for publication in the IEEE\n  Transactions on Audio, Speech, and Language Processing. This work has been\n  submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.01611v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01611v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "QHARMA-GAN：基于自回归滑动平均模型的准谐波神经声码器", "tldr": "本文提出了一种名为QHARMA-GAN的新型神经声码器，它结合了准谐波模型和自回归滑动平均模型，以解决现有神经声码器在语音生成机制不透明、难以灵活修改语音以及计算成本高的问题，实现了高质量、快速的语音合成和灵活的修改。", "motivation": "现有的端到端神经声码器存在黑箱性质，导致语音生成机制和内在结构不透明，难以单独建模激励源和共振特性，从而失去了高质量灵活合成或修改语音的能力。此外，它们的逐序列波形生成通常需要复杂的网络，导致大量的时间消耗。", "method": "受准谐波模型（QHM）的启发，本文将神经网络与QHM合成过程相结合，提出了一种新型神经声码器框架。语音信号被编码为自回归滑动平均（ARMA）函数以建模共振特性，从而精确估计任意频率下准谐波的幅度和相位。随后，语音可以高质量地进行重合成，并可任意修改音高和时间拉伸。", "result": "实验表明，所提出的方法结合了QHM、ARMA模型和神经网络的优势，在生成速度、合成质量和修改灵活性方面优于其他方法。", "conclusion": "所提出的QHARMA-GAN神经声码器通过结合准谐波模型和自回归滑动平均模型，有效解决了现有神经声码器在透明度、灵活性和计算效率方面的不足，实现了高质量、高效且灵活的语音合成和修改。", "translation": "声码器，将语音信号编码成声学特征并从中重建语音信号，已经研究了几十年。最近，深度学习的兴起特别推动了神经声码器的发展，以生成高质量的语音信号。另一方面，现有的端到端神经声码器存在黑箱性质，这使得语音生成机制和语音的内在结构不透明，导致单独建模激励源和共振特性的模糊性，并失去了高质量灵活合成或修改语音的能力。此外，它们的逐序列波形生成通常需要复杂的网络，导致大量的时间消耗。在这项工作中，受将语音表示为稀疏分量的准谐波模型（QHM）的启发，我们将神经网络和QHM合成过程相结合，提出了一种新型神经声码器框架。因此，语音信号可以被编码为自回归滑动平均（ARMA）函数来建模共振特性，从而精确估计任意频率下准谐波的幅度和相位。随后，语音可以高质量地进行重合成，并可任意修改音高和时间拉伸，同时时间消耗和网络大小减少。实验表明，所提出的方法利用了QHM、ARMA模型和神经网络的优势，使得我们的方法在生成速度、合成质量和修改灵活性方面优于其他方法。", "summary": "本文提出了一种名为QHARMA-GAN的新型神经声码器，旨在解决现有端到端神经声码器在语音生产机制不透明、难以灵活修改以及计算成本高的问题。该方法结合了准谐波模型（QHM）和神经网络，将语音信号编码为自回归滑动平均（ARMA）函数来建模共振特性，从而实现准谐波的精确估计。实验证明，QHARMA-GAN在生成速度、合成质量和语音修改灵活性方面均优于现有方法，并能高质量地进行音高和时间拉伸等修改。", "keywords": "神经声码器, 准谐波模型, 自回归滑动平均, 语音合成, 语音修改", "comments": "本文的创新点在于将传统声学模型（准谐波模型和ARMA模型）的物理可解释性与深度学习的强大建模能力相结合，有效克服了传统端到端神经声码器“黑箱”问题，提高了语音合成的透明度和可控性。这种混合模型的方法为高质量、灵活的语音合成和修改提供了一个有前景的方向，特别是在需要精细控制语音特性的应用中。"}}
{"id": "2507.01168", "title": "Towards a Signal Detection Based Measure for Assessing Information Quality of Explainable Recommender Systems", "authors": ["Yeonbin Son", "Matthew L. Bolton"], "summary": "There is growing interest in explainable recommender systems that provide\nrecommendations along with explanations for the reasoning behind them. When\nevaluating recommender systems, most studies focus on overall recommendation\nperformance. Only a few assess the quality of the explanations. Explanation\nquality is often evaluated through user studies that subjectively gather users'\nopinions on representative explanatory factors that shape end-users'\nperspective towards the results, not about the explanation contents itself. We\naim to fill this gap by developing an objective metric to evaluate Veracity:\nthe information quality of explanations. Specifically, we decompose Veracity\ninto two dimensions: Fidelity and Attunement. Fidelity refers to whether the\nexplanation includes accurate information about the recommended item.\nAttunement evaluates whether the explanation reflects the target user's\npreferences. By applying signal detection theory, we first determine decision\noutcomes for each dimension and then combine them to calculate a sensitivity,\nwhich serves as the final Veracity value. To assess the effectiveness of the\nproposed metric, we set up four cases with varying levels of information\nquality to validate whether our metric can accurately capture differences in\nquality. The results provided meaningful insights into the effectiveness of our\nproposed metric.", "comment": "Accepted to IEEE CAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.01168v1", "categories": ["cs.IR", "cs.HC"], "cate": "cs.IR", "url": "http://arxiv.org/abs/2507.01168v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "迈向一种基于信号检测的解释性推荐系统信息质量评估方法", "tldr": "本文提出了一种基于信号检测理论的客观指标，用于评估解释性推荐系统解释的信息质量（真实性），通过分解真实性为保真度和调整度来衡量。", "motivation": "现有研究多关注推荐性能，少有评估解释质量，且评估方法主观。本文旨在开发一个客观指标来评估解释的信息质量（真实性）。", "method": "将真实性（Veracity）分解为保真度（Fidelity）和调整度（Attunement）。应用信号检测理论，首先确定每个维度的决策结果，然后将它们结合起来计算敏感度，作为最终的真实性值。通过设置四种不同信息质量水平的案例来评估指标的有效性。", "result": "结果为所提出指标的有效性提供了有意义的见解。", "conclusion": "该研究成功开发并验证了一个基于信号检测理论的客观指标，能够有效评估解释性推荐系统解释的信息质量。", "translation": "解释性推荐系统越来越受到关注，它们在提供推荐的同时也提供背后的解释。在评估推荐系统时，大多数研究侧重于整体推荐性能。只有少数研究评估解释的质量。解释质量通常通过用户研究来评估，这些研究主观地收集用户对影响终端用户对结果看法的代表性解释因素的意见，而不是关于解释内容本身。我们旨在通过开发一个客观指标来评估真实性：即解释的信息质量，以填补这一空白。具体来说，我们将真实性分解为两个维度：保真度（Fidelity）和调整度（Attunement）。保真度指的是解释是否包含关于推荐项目的准确信息。调整度评估解释是否反映了目标用户的偏好。通过应用信号检测理论，我们首先确定每个维度的决策结果，然后将它们结合起来计算一个敏感度，作为最终的真实性值。为了评估所提出指标的有效性，我们设置了四种不同信息质量水平的案例来验证我们的指标是否能准确捕捉质量差异。结果为我们提出的指标的有效性提供了有意义的见解。", "summary": "本文针对解释性推荐系统解释质量评估中缺乏客观指标的问题，提出了一种基于信号检测理论的“真实性”（Veracity）指标。该指标将真实性分解为保真度（信息准确性）和调整度（用户偏好匹配度），并通过信号检测计算敏感度作为最终值。实验结果表明该指标能有效捕捉不同信息质量水平的差异。", "keywords": "解释性推荐系统, 信息质量, 信号检测理论, 真实性, 客观评估", "comments": "该论文的创新点在于首次将信号检测理论应用于解释性推荐系统的信息质量评估，并提出了一个客观的“真实性”指标，填补了该领域主观评估的空白。这对于推荐系统解释的量化评估具有重要意义。"}}
{"id": "2507.01424", "title": "TriVLA: A Unified Triple-System-Based Unified Vision-Language-Action Model for General Robot Control", "authors": ["Zhenyang Liu", "Yongchong Gu", "Sixiao Zheng", "Xiangyang Xue", "Yanwei Fu"], "summary": "Recent advancements in vision-language models (VLMs) for common-sense\nreasoning have led to the development of vision-language-action (VLA) models,\nenabling robots to perform generalized manipulation. Although existing\nautoregressive VLA methods design a specific architecture like dual-system to\nleverage large-scale pretrained knowledge, they tend to capture static\ninformation, often neglecting the dynamic aspects vital for embodied tasks. To\nthis end, we propose TriVLA, a unified Vision-Language-Action model with a\ntriple-system architecture for general robot control. The vision-language\nmodule (System 2) interprets the environment through vision and language\ninstructions. The dynamics perception module (System 3) inherently produces\nvisual representations that encompass both current static information and\npredicted future dynamics, thereby providing valuable guidance for policy\nlearning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trained\nvideo foundation model on robot datasets along with internet human manipulation\ndata. The subsequent policy learning module (System 1) generates fluid motor\nactions in real time. Experimental evaluation demonstrates that TriVLA operates\nat approximately 36 Hz and surpasses state-of-the-art imitation learning\nbaselines on standard simulation benchmarks as well as challenging real-world\nmanipulation tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01424v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01424v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "TriVLA：一种基于三系统统一的通用机器人控制视觉-语言-动作模型", "tldr": "TriVLA是一个统一的视觉-语言-动作模型，采用三系统架构，通过结合视觉-语言理解、动态感知和策略学习，实现了对通用机器人任务的实时流畅控制，并在模拟和真实世界任务中超越了现有技术。", "motivation": "现有的自回归视觉-语言-动作（VLA）模型虽然利用了大规模预训练知识，但倾向于捕捉静态信息，忽略了具身任务中至关重要的动态方面。", "method": "本文提出了TriVLA，一个具有三系统架构的统一视觉-语言-动作模型。系统2（视觉-语言模块）负责通过视觉和语言指令解释环境；系统3（动态感知模块）产生包含当前静态信息和预测未来动态的视觉表示，为策略学习提供指导；系统1（策略学习模块）实时生成流畅的电机动作。TriVLA利用预训练的VLM模型，并在机器人数据集和互联网人类操作数据上微调预训练的视频基础模型。", "result": "TriVLA以大约36 Hz的频率运行，并在标准模拟基准测试以及具有挑战性的真实世界操作任务中超越了最先进的模仿学习基线。", "conclusion": "TriVLA通过其独特的三系统架构有效地解决了现有VLA模型在捕捉动态信息方面的不足，实现了通用机器人控制的卓越性能。", "translation": "视觉-语言模型（VLM）在常识推理方面的最新进展推动了视觉-语言-动作（VLA）模型的发展，使机器人能够执行通用操作。尽管现有的自回归VLA方法设计了特定的架构（如双系统）来利用大规模预训练知识，但它们倾向于捕获静态信息，常常忽略具身任务中至关重要的动态方面。为此，我们提出了TriVLA，一个具有三系统架构的统一视觉-语言-动作模型，用于通用机器人控制。视觉-语言模块（系统2）通过视觉和语言指令解释环境。动态感知模块（系统3）固有地产生包含当前静态信息和预测未来动态的视觉表示，从而为策略学习提供有价值的指导。TriVLA利用预训练的VLM模型，并在机器人数据集以及互联网人类操作数据上微调预训练的视频基础模型。随后的策略学习模块（系统1）实时生成流畅的电机动作。实验评估表明，TriVLA以大约36 Hz的频率运行，并在标准模拟基准测试以及具有挑战性的真实世界操作任务中超越了最先进的模仿学习基线。", "summary": "TriVLA是一个创新的统一视觉-语言-动作模型，专为通用机器人控制设计。它通过一个独特的三系统架构解决了现有VLA模型在处理动态信息方面的不足。该模型包含一个视觉-语言模块（系统2）用于环境理解，一个动态感知模块（系统3）用于预测未来动态，以及一个策略学习模块（系统1）用于实时动作生成。TriVLA利用预训练的VLM和视频基础模型进行训练，并在实验中表现出卓越的性能，超越了现有技术，实现了高速流畅的机器人操作。", "keywords": "视觉-语言-动作模型, 机器人控制, 动态感知, 三系统架构, 模仿学习", "comments": "TriVLA通过引入一个明确的“动态感知模块”（系统3）来解决现有VLA模型在处理动态信息方面的不足，这是一个显著的创新点，使其能够更好地适应具身任务的实时性和动态性。其统一的三系统架构以及结合预训练VLM和视频基础模型的方法，为通用机器人控制提供了一个强大且高效的解决方案，在实际应用中具有重要潜力。"}}
{"id": "2507.01717", "title": "Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI", "authors": ["Gopichand Kanumolu", "Ashok Urlana", "Charaka Vinayak Kumar", "Bala Mallikarjunarao Garlapati"], "summary": "Patents contain rich technical knowledge that can inspire innovative product\nideas, yet accessing and interpreting this information remains a challenge.\nThis work explores the use of Large Language Models (LLMs) and autonomous\nagents to mine and generate product concepts from a given patent. In this work,\nwe design Agent Ideate, a framework for automatically generating product-based\nbusiness ideas from patents. We experimented with open-source LLMs and\nagent-based architectures across three domains: Computer Science, Natural\nLanguage Processing, and Material Chemistry. Evaluation results show that the\nagentic approach consistently outperformed standalone LLMs in terms of idea\nquality, relevance, and novelty. These findings suggest that combining LLMs\nwith agentic workflows can significantly enhance the innovation pipeline by\nunlocking the untapped potential of business idea generation from patent data.", "comment": "AgentScen Workshop, IJCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.01717v1", "categories": ["cs.AI", "cs.IR", "cs.LG", "cs.MA"], "cate": "cs.AI", "url": "http://arxiv.org/abs/2507.01717v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "Agent Ideate：一个利用智能代理AI从专利中生成产品创意的框架", "tldr": "Agent Ideate是一个利用大语言模型和智能代理从专利中自动生成产品创意以克服传统信息解读挑战的框架，实验证明其在创意质量、相关性和新颖性方面优于独立LLM。", "motivation": "专利中包含丰富的技术知识，可以激发创新的产品创意，但获取和解释这些信息仍然是一个挑战。本工作旨在解决这一问题。", "method": "本研究设计了Agent Ideate框架，利用大型语言模型（LLMs）和自主代理（autonomous agents）从给定专利中挖掘和生成产品概念。研究在计算机科学、自然语言处理和材料化学三个领域对开源LLMs和基于代理的架构进行了实验。", "result": "评估结果表明，在创意质量、相关性和新颖性方面，代理方法始终优于独立的LLMs。", "conclusion": "这些发现表明，将LLMs与代理工作流相结合，可以通过从专利数据中挖掘商业创意的未开发潜力，显著增强创新流程。", "translation": "专利包含丰富的技术知识，可以激发创新的产品创意，但获取和解释这些信息仍然是一个挑战。这项工作探索了使用大型语言模型（LLMs）和自主代理从给定专利中挖掘和生成产品概念。在这项工作中，我们设计了Agent Ideate，一个用于从专利中自动生成基于产品的商业创意的框架。我们在计算机科学、自然语言处理和材料化学三个领域对开源LLMs和基于代理的架构进行了实验。评估结果表明，在创意质量、相关性和新颖性方面，代理方法始终优于独立的LLMs。这些发现表明，将LLMs与代理工作流相结合，可以通过从专利数据中挖掘商业创意的未开发潜力，显著增强创新流程。", "summary": "本研究提出了Agent Ideate框架，旨在利用大型语言模型（LLMs）和智能代理（agentic AI）从专利中自动生成产品创意。该框架通过实验证明，在计算机科学、自然语言处理和材料化学等领域，其生成的创意在质量、相关性和新颖性方面均优于单独的LLMs，揭示了智能代理在创新流程中挖掘专利数据潜力的巨大潜力。", "keywords": "专利分析, 产品创意生成, 大语言模型, 智能代理, 创新", "comments": "该论文提出了一种新颖的方法，将LLMs与代理工作流结合，有效地解决了从专利中提取和生成创新产品创意的挑战。其创新性在于利用自动化代理提升了创意生成的质量和效率，对知识管理和创新领域具有重要意义。"}}
{"id": "2507.01457", "title": "Tensor Program Optimization for the RISC-V Vector Extension Using Probabilistic Programs", "authors": ["Federico Nicolas Peccia", "Frederik Haxel", "Oliver Bringmann"], "summary": "RISC-V provides a flexible and scalable platform for applications ranging\nfrom embedded devices to high-performance computing clusters. Particularly, its\nRISC-V Vector Extension (RVV) becomes of interest for the acceleration of AI\nworkloads. But writing software that efficiently utilizes the vector units of\nRISC-V CPUs without expert knowledge requires the programmer to rely on the\nautovectorization features of compilers or hand-crafted libraries like\nmuRISCV-NN. Smarter approaches, like autotuning frameworks, have been missing\nthe integration with the RISC-V RVV extension, thus heavily limiting the\nefficient deployment of complex AI workloads. In this paper, we present a\nworkflow based on the TVM compiler to efficiently map AI workloads onto RISC-V\nvector units. Instead of relying on hand-crafted libraries, we integrated the\nRVV extension into TVM's MetaSchedule framework, a probabilistic program\nframework for tensor operation tuning. We implemented different RISC-V SoCs on\nan FPGA and tuned a wide range of AI workloads on them. We found that our\nproposal shows a mean improvement of 46% in execution latency when compared\nagainst the autovectorization feature of GCC, and 29% against muRISCV-NN.\nMoreover, the binary resulting from our proposal has a smaller code memory\nfootprint, making it more suitable for embedded devices. Finally, we also\nevaluated our solution on a commercially available RISC-V SoC implementing the\nRVV 1.0 Vector Extension and found our solution is able to find mappings that\nare 35% faster on average than the ones proposed by LLVM. We open-sourced our\nproposal for the community to expand it to target other RISC-V extensions.", "comment": "9 pages, 10 figures, 2 algorithms", "pdf_url": "http://arxiv.org/pdf/2507.01457v1", "categories": ["cs.LG", "cs.AI", "cs.SE"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01457v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于概率程序的RISC-V向量扩展张量程序优化", "tldr": "该论文提出了一种基于TVM编译器和概率程序的RISC-V向量扩展张量程序优化方法，显著提升了AI工作负载的执行效率并减小了代码内存占用。", "motivation": "RISC-V向量扩展（RVV）对于加速AI工作负载至关重要，但缺乏专业知识的程序员难以高效利用其向量单元。现有编译器自动向量化功能或手工库（如muRISCV-NN）效率有限，且自动调优框架尚未集成RVV扩展，严重限制了复杂AI工作负载的有效部署。", "method": "本文提出了一种基于TVM编译器的工作流程，以高效地将AI工作负载映射到RISC-V向量单元上。该方法将RVV扩展集成到TVM的MetaSchedule框架中，这是一个用于张量操作调优的概率程序框架。研究人员在FPGA上实现了不同的RISC-V SoC，并在其上调优了各种AI工作负载，还在商用RISC-V SoC上进行了评估。", "result": "与GCC的自动向量化功能相比，该方案的执行延迟平均提高了46%；与muRISCV-NN相比，平均提高了29%。此外，该方案生成的二进制文件具有更小的代码内存占用，更适用于嵌入式设备。在商用RISC-V SoC上，该方案找到的映射比LLVM提出的映射平均快35%。", "conclusion": "本文提出的基于TVM MetaSchedule框架的RISC-V向量扩展张量程序优化方案，能够显著提高AI工作负载在RISC-V向量单元上的执行效率，并减小代码内存占用，为RISC-V平台上的高效AI部署提供了有效途径。", "translation": "RISC-V为从嵌入式设备到高性能计算集群的应用程序提供了灵活且可扩展的平台。特别是其RISC-V向量扩展（RVV）在AI工作负载加速方面备受关注。然而，在没有专家知识的情况下编写能够高效利用RISC-V CPU向量单元的软件，需要程序员依赖编译器的自动向量化功能或像muRISCV-NN这样的手工库。更智能的方法，如自动调优框架，一直缺少与RISC-V RVV扩展的集成，从而严重限制了复杂AI工作负载的有效部署。在本文中，我们提出了一种基于TVM编译器的工作流程，用于将AI工作负载高效地映射到RISC-V向量单元上。我们没有依赖手工库，而是将RVV扩展集成到TVM的MetaSchedule框架中，这是一个用于张量操作调优的概率程序框架。我们在FPGA上实现了不同的RISC-V SoC，并在其上调优了各种AI工作负载。我们发现，与GCC的自动向量化功能相比，我们的方案在执行延迟方面平均提高了46%，与muRISCV-NN相比则提高了29%。此外，我们方案生成的二进制文件具有更小的代码内存占用，使其更适合嵌入式设备。最后，我们还在一个实现了RVV 1.0向量扩展的商用RISC-V SoC上评估了我们的解决方案，发现我们的解决方案能够找到比LLVM提出的映射平均快35%的映射。我们已将我们的方案开源，供社区将其扩展以支持其他RISC-V扩展。", "summary": "该论文介绍了一种用于RISC-V向量扩展（RVV）的张量程序优化方法，旨在提高AI工作负载的执行效率。研究人员将RVV集成到TVM的MetaSchedule框架中，这是一个基于概率程序的张量操作调优框架。通过在FPGA实现的RISC-V SoC和商用RISC-V SoC上进行广泛测试，该方法在执行延迟方面显著优于GCC自动向量化和muRISCV-NN，并且生成的代码内存占用更小，使其特别适用于嵌入式设备。", "keywords": "RISC-V, 向量扩展, 张量程序优化, TVM, 概率程序", "comments": "该论文的创新点在于将RISC-V向量扩展（RVV）首次集成到TVM的MetaSchedule自动调优框架中，利用概率程序的方法实现了张量操作的优化。这解决了RISC-V平台上AI工作负载高效部署的痛点。其重要性在于提供了一种比现有自动向量化和手工库更优的性能优化方案，且具有更小的代码内存占用，对于嵌入式AI应用尤其有价值。该研究还将其成果开源，有利于社区进一步发展和应用。"}}
{"id": "2507.01290", "title": "Learning an Ensemble Token from Task-driven Priors in Facial Analysis", "authors": ["Sunyong Seo", "Semin Kim", "Jongha Lee"], "summary": "Facial analysis exhibits task-specific feature variations. While\nConvolutional Neural Networks (CNNs) have enabled the fine-grained\nrepresentation of spatial information, Vision Transformers (ViTs) have\nfacilitated the representation of semantic information at the patch level.\nAlthough the generalization of conventional methodologies has advanced visual\ninterpretability, there remains paucity of research that preserves the unified\nfeature representation on single task learning during the training process. In\nthis work, we introduce ET-Fuser, a novel methodology for learning ensemble\ntoken by leveraging attention mechanisms based on task priors derived from\npre-trained models for facial analysis. Specifically, we propose a robust prior\nunification learning method that generates a ensemble token within a\nself-attention mechanism, which shares the mutual information along the\npre-trained encoders. This ensemble token approach offers high efficiency with\nnegligible computational cost. Our results show improvements across a variety\nof facial analysis, with statistically significant enhancements observed in the\nfeature representations.", "comment": "11pages, 8figures, 4tables", "pdf_url": "http://arxiv.org/pdf/2507.01290v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01290v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "人脸分析中基于任务驱动先验学习集成令牌", "tldr": "本文提出了一种名为ET-Fuser的新方法，通过利用预训练模型中的任务先验来学习集成令牌，以解决人脸分析中单任务学习时统一特征表示的不足，并在各种人脸分析任务中显示出显著改进。", "motivation": "人脸分析中，尽管卷积神经网络（CNNs）和视觉Transformer（ViTs）在特征表示方面取得了进展，但现有方法在单任务学习过程中未能很好地保持统一的特征表示，这方面的研究仍然不足。", "method": "本文提出了一种名为ET-Fuser的新方法，通过利用基于预训练模型中任务先验的注意力机制来学习集成令牌。具体来说，该方法提出了一种鲁棒的先验统一学习方法，在自注意力机制内生成一个集成令牌，该令牌与预训练编码器共享互信息。", "result": "该集成令牌方法效率高，计算成本可忽略不计。实验结果显示，在各种人脸分析任务中均有改进，并且特征表示方面观察到统计学上的显著增强。", "conclusion": "通过引入ET-Fuser并利用任务驱动的先验知识，能够在人脸分析任务中有效地学习集成令牌，从而显著提升特征表示并改善整体性能。", "translation": "人脸分析表现出任务特定的特征变异。虽然卷积神经网络（CNNs）已经实现了空间信息的精细表示，但视觉Transformer（ViTs）促进了补丁级别的语义信息表示。尽管传统方法的泛化能力提升了视觉可解释性，但在训练过程中保持单任务学习的统一特征表示的研究仍然缺乏。在这项工作中，我们引入了ET-Fuser，这是一种新颖的方法，通过利用基于从人脸分析预训练模型中导出的任务先验的注意力机制来学习集成令牌。具体来说，我们提出了一种鲁棒的先验统一学习方法，该方法在自注意力机制内生成一个集成令牌，该令牌共享预训练编码器之间的互信息。这种集成令牌方法具有高效率和可忽略的计算成本。我们的结果显示，在各种人脸分析中均有改进，并且在特征表示方面观察到统计学上的显著增强。", "summary": "本文针对人脸分析中单任务学习缺乏统一特征表示的问题，提出了一种名为ET-Fuser的新方法。该方法通过利用预训练模型中任务驱动的先验知识和注意力机制来学习一个高效的集成令牌。具体而言，它引入了一种鲁棒的先验统一学习方法，在自注意力机制内生成集成令牌，并与预训练编码器共享互信息。实验结果表明，该方法在多种人脸分析任务中实现了显著的性能提升，尤其是在特征表示方面。", "keywords": "人脸分析, 集成令牌, 任务驱动先验, 自注意力, 视觉Transformer", "comments": "ET-Fuser的创新点在于其利用任务驱动的先验知识和注意力机制来生成一个高效的集成令牌，从而在单任务学习中实现统一的特征表示。这种方法在计算成本可忽略不计的情况下提升了性能，显示出其潜力和实用性。该研究对于提升人脸分析的特征表示能力具有重要意义。"}}
{"id": "2507.01548", "title": "Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants", "authors": ["Wen Zhan", "Ziqun Hua", "Peiyue Lin", "Yunfei Chen"], "summary": "This paper explores how older adults, particularly aging migrants in urban\nChina, can engage AI-assisted co-creation to express personal narratives that\nare often fragmented, underrepresented, or difficult to verbalize. Through a\npilot workshop combining oral storytelling and the symbolic reconstruction of\nHanzi, participants shared memories of migration and recreated new character\nforms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM),\ntogether with physical materials. Supported by human facilitation and a soft AI\npresence, participants transformed lived experience into visual and tactile\nexpressions without requiring digital literacy. This approach offers new\nperspectives on human-AI collaboration and aging by repositioning AI not as a\ncontent producer but as a supportive mechanism, and by supporting narrative\nagency within sociotechnical systems.", "comment": "A version of this manuscript has been submitted to the [IASDR 2025\n  Conference](https://iasdr2025.org/) and is currently under review", "pdf_url": "http://arxiv.org/pdf/2507.01548v1", "categories": ["cs.HC", "cs.AI", "cs.CL"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01548v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "将汉字作为叙事桥梁：一项面向老年移民的AI共创工作坊", "tldr": "该研究探索了AI辅助共创如何帮助中国老年移民通过汉字重构表达个人叙事，无需数字素养，并重新定位AI作为支持机制的角色。", "motivation": "老年人，特别是中国城市的年迈移民，他们的个人叙事常常是碎片化的、未被充分表达的或难以言喻的。本研究旨在探索AI辅助共创如何帮助他们表达这些叙事。", "method": "研究通过一个试点工作坊进行，结合了口头叙事和汉字的象征性重构。参与者在人类引导和AI（LLM提供小篆字形建议）的辅助下，利用物理材料重塑汉字，从而将生活经历转化为视觉和触觉表达，且无需数字素养。", "result": "参与者成功地分享了移民记忆，并利用LLM建议的小篆字形和物理材料重塑了新的汉字形式，将生活经验转化为视觉和触觉表达，且无需数字素养。", "conclusion": "这种方法为人类-AI协作和老龄化研究提供了新视角，它将AI重新定位为支持机制而非内容生产者，并在社会技术系统中支持叙事能动性。", "translation": "本文探讨了老年人，特别是中国城市的老年移民，如何通过AI辅助共创来表达他们常常碎片化、代表性不足或难以言喻的个人叙事。通过一个结合口头叙事和汉字象征性重构的试点工作坊，参与者分享了移民记忆，并利用大型语言模型（LLM）建议的小篆字形和物理材料，共同创造了新的汉字形式。在人工引导和温和的AI存在的支持下，参与者无需数字素养，便将生活经历转化为视觉和触觉表达。这种方法通过将AI重新定位为支持机制而非内容生产者，并通过在社会技术系统中支持叙事能动性，为人类-AI协作和老龄化研究提供了新视角。", "summary": "本研究探索了AI辅助共创在帮助中国老年移民表达个人叙事方面的潜力。通过一个结合口头叙事和汉字重构的试点工作坊，参与者在LLM和人工协助下，无需数字素养，将移民经历转化为视觉和触觉的汉字表达。该方法重新定义了AI在人机协作中的角色，将其视为赋能叙事而非内容生成，为老龄化和人机交互研究提供了新思路。", "keywords": "AI共创, 老年移民, 汉字, 叙事表达, 人机协作", "comments": "这项研究的创新之处在于其独特地将AI技术应用于文化遗产（汉字）和老年移民的个人叙事表达，尤其强调了无需数字素养的参与方式。它重新定义了AI在人机协作中的角色，从内容生成者转变为支持和赋能机制，为解决弱势群体叙事表达的挑战提供了新颖且富有同情心的方法。"}}
{"id": "2507.01035", "title": "Research on Low-Latency Inference and Training Efficiency Optimization for Graph Neural Network and Large Language Model-Based Recommendation Systems", "authors": ["Yushang Zhao", "Haotian Lyu", "Yike Peng", "Aijia Sun", "Feng Jiang", "Xinyue Han"], "summary": "The incessant advent of online services demands high speed and efficient\nrecommender systems (ReS) that can maintain real-time performance along with\nprocessing very complex user-item interactions. The present study, therefore,\nconsiders computational bottlenecks involved in hybrid Graph Neural Network\n(GNN) and Large Language Model (LLM)-based ReS with the aim optimizing their\ninference latency and training efficiency. An extensive methodology was used:\nhybrid GNN-LLM integrated architecture-optimization strategies(quantization,\nLoRA, distillation)-hardware acceleration (FPGA, DeepSpeed)-all under R 4.4.2.\nExperimental improvements were significant, with the optimal Hybrid + FPGA +\nDeepSpeed configuration reaching 13.6% more accuracy (NDCG@10: 0.75) at 40-60ms\nof latency, while LoRA brought down training time by 66% (3.8 hours) in\ncomparison to the non-optimized baseline. Irrespective of domain, such as\naccuracy or efficiency, it can be established that hardware-software co-design\nand parameter-efficient tuning permit hybrid models to outperform GNN or LLM\napproaches implemented independently. It recommends the use of FPGA as well as\nLoRA for real-time deployment. Future work should involve federated learning\nalong with advanced fusion architectures for better scalability and privacy\npreservation. Thus, this research marks the fundamental groundwork concerning\nnext-generation ReS balancing low-latency response with cutting-edge\npersonalization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01035v1", "categories": ["cs.LG", "cs.AI", "cs.PF"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01035v1", "date": "2025-06-21", "updated": "2025-06-21", "AI": {"title_translation": "基于图神经网络和大型语言模型的推荐系统低延迟推理与训练效率优化研究", "tldr": "本研究优化了基于GNN和LLM的混合推荐系统，通过软硬件协同设计和参数高效调优显著降低了推理延迟并提升了训练效率，推荐使用FPGA和LoRA进行实时部署。", "motivation": "在线服务对高速高效推荐系统的需求日益增长，但基于混合图神经网络（GNN）和大型语言模型（LLM）的推荐系统存在计算瓶颈。本研究旨在解决这些瓶颈，以优化其推理延迟和训练效率。", "method": "采用混合GNN-LLM集成架构，结合量化、LoRA、蒸馏等优化策略，并利用FPGA和DeepSpeed进行硬件加速，所有实验均在R 4.4.2环境下进行。", "result": "最佳的“混合+FPGA+DeepSpeed”配置在40-60毫秒延迟下，准确率（NDCG@10）提高了13.6%（达到0.75）；LoRA将训练时间比未优化基线减少了66%（至3.8小时）。", "conclusion": "硬件-软件协同设计和参数高效调优使混合模型在准确性和效率上均优于独立实现的GNN或LLM方法。研究建议在实时部署中使用FPGA和LoRA。", "translation": "在线服务的不断发展要求推荐系统（ReS）具备高速高效的性能，既能保持实时性，又能处理非常复杂的用户-物品交互。因此，本研究旨在解决混合图神经网络（GNN）和大型语言模型（LLM）推荐系统中存在的计算瓶颈，以优化其推理延迟和训练效率。研究采用了广泛的方法：混合GNN-LLM集成架构优化策略（量化、LoRA、蒸馏）和硬件加速（FPGA、DeepSpeed），所有实验均在R 4.4.2环境下进行。实验改进显著，最佳的“混合+FPGA+DeepSpeed”配置在40-60毫秒延迟下，准确率（NDCG@10）提高了13.6%（达到0.75），而LoRA将训练时间比未优化基线减少了66%（至3.8小时）。无论是在准确性还是效率方面，都可以证实硬件-软件协同设计和参数高效调优使得混合模型能够超越独立实现的GNN或LLM方法。本研究建议在实时部署中使用FPGA和LoRA。未来的工作应包括联邦学习以及先进的融合架构，以实现更好的可扩展性和隐私保护。因此，本研究为平衡低延迟响应与尖端个性化的下一代推荐系统奠定了基础。", "summary": "本研究旨在解决基于图神经网络（GNN）和大型语言模型（LLM）的混合推荐系统在推理延迟和训练效率方面的计算瓶颈。研究采用集成架构优化策略（如量化、LoRA、蒸馏）和硬件加速（FPGA、DeepSpeed），结果显示，优化后的配置显著提升了准确率并降低了推理延迟，同时LoRA大幅缩短了训练时间。研究表明，硬件-软件协同设计和参数高效调优能使混合模型表现优于单一模型，并推荐将FPGA和LoRA应用于实时部署。", "keywords": "图神经网络, 大型语言模型, 推荐系统, 低延迟, 训练效率", "comments": "本研究通过结合软硬件协同设计和参数高效调优，为混合GNN-LLM推荐系统提供了有效的优化方案，在低延迟推理和训练效率方面取得了显著进展。其创新点在于将多种优化策略（如量化、LoRA、蒸馏）与硬件加速（FPGA、DeepSpeed）相结合，并成功应用于GNN和LLM的混合模型中，为下一代推荐系统的发展奠定了基础。"}}
{"id": "2507.01743", "title": "Position and Velocity Estimation Accuracy in MIMO-OFDM ISAC Networks: A Fisher Information Analysis", "authors": ["Lorenzo Pucci", "Luca Arcangeloni", "Andrea Giorgetti"], "summary": "Integrated sensing and communication (ISAC) is a core technology for future\nwireless networks, enabling high-resolution sensing and reliable data\ntransmission within a unified radio platform. This paper develops a theoretical\nframework to assess the estimation accuracy of target position and velocity in\nheterogeneous orthogonal frequency division multiplexing (OFDM)-based ISAC\nnetworks with multiple cooperative and distributed multiple-input\nmultiple-output (MIMO) base stations (BSs). Using Fisher information analysis,\nwe first derive closed-form Cram\\'er-Rao lower bounds (CRLBs) for target\nlocalization in single monostatic and bistatic configurations. We then analyze\nthe benefits of BS cooperation by deriving CRLBs for joint position and\nvelocity estimation in a general setting that encompasses multiple cooperating\nmonostatic systems and multistatic networks with multiple transmitters (Txs)\nand receivers (Rxs). The influence of key system parameters, including the\nnumber of BSs, bandwidth, antenna array configuration, and network geometry, is\nsystematically examined. Numerical results highlight the performance gains\nenabled by cooperative sensing and provide insights to guide the design of\nfuture ISAC systems.", "comment": "19 pages, 6 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.01743v1", "categories": ["eess.SP"], "cate": "eess.SP", "url": "http://arxiv.org/abs/2507.01743v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "MIMO-OFDM ISAC 网络中的位置和速度估计算精度：一项费舍尔信息分析", "tldr": "本文利用费舍尔信息分析，推导了MIMO-OFDM ISAC网络中目标位置和速度估计的Cramér-Rao下界，并分析了基站协作的性能增益。", "motivation": "综合感知与通信（ISAC）是未来无线网络的核心技术，需要在异构MIMO-OFDM ISAC网络中评估目标位置和速度的估计精度。", "method": "1. 开发了一个理论框架来评估异构OFDM-based ISAC网络中目标位置和速度的估计精度。2. 使用费舍尔信息分析，推导了单站和双站配置下目标定位的闭合形式Cramér-Rao下界（CRLBs）。3. 分析了基站协作的优势，推导了多合作单站系统和多发射机/接收机多站网络中联合位置和速度估计的CRLBs。4. 系统地检查了关键系统参数（如基站数量、带宽、天线阵列配置和网络几何结构）的影响。", "result": "数值结果突出了协作传感带来的性能增益，并为未来ISAC系统的设计提供了指导。", "conclusion": "通过费舍尔信息分析，本研究量化了MIMO-OFDM ISAC网络中目标位置和速度估计的精度，并证明了基站协作对性能的提升作用，为ISAC系统设计提供了宝贵见解。", "translation": "综合感知与通信（ISAC）是未来无线网络的核心技术，能够在统一的无线电平台内实现高分辨率感知和可靠数据传输。本文开发了一个理论框架，用于评估在异构正交频分复用（OFDM）ISAC网络中，多合作分布式多输入多输出（MIMO）基站（BS）中目标位置和速度的估计精度。利用费舍尔信息分析，我们首先推导了单站和双站配置下目标定位的闭合形式Cramér-Rao下界（CRLBs）。然后，我们通过推导包含多个合作单站系统和具有多个发射机（Tx）和接收机（Rx）的多站网络的一般设置中的联合位置和速度估计的CRLBs，分析了基站协作的益处。系统地检查了关键系统参数，包括基站数量、带宽、天线阵列配置和网络几何结构的影响。数值结果突出了协作感知所带来的性能增益，并为指导未来ISAC系统的设计提供了见解。", "summary": "本文提出了一个理论框架，利用费舍尔信息分析评估了MIMO-OFDM ISAC网络中目标位置和速度的估计精度。研究推导了不同配置下的Cramér-Rao下界，并系统分析了基站数量、带宽等关键参数的影响，强调了协作传感对性能的提升作用，为ISAC系统设计提供了指导。", "keywords": "ISAC, MIMO-OFDM, 位置估计, 速度估计, Cramér-Rao下界", "comments": "这篇论文通过严谨的费舍尔信息分析，为MIMO-OFDM ISAC网络中的感知精度提供了理论支撑。其创新点在于系统地推导了复杂多站协作场景下的CRLBs，并量化了关键系统参数的影响，这对于未来ISAC系统的优化设计具有重要的指导意义。"}}
{"id": "2507.01782", "title": "Symbiotic Backscatter Communication: A Design Perspective on the Modulation Scheme of Backscatter Devices", "authors": ["Yinghui Ye", "Shuang Lu", "Liqin Shi", "Xiaoli Chu", "Sumei Sun"], "summary": "Symbiotic Backscatter Communication (SBC) has emerged as a spectrum-efficient\nand low-power communication technology, where backscatter devices (BDs)\nmodulate and reflect incident radio frequency (RF) signals from primary\ntransmitters (PTs). While previous studies have assumed a circularly symmetric\ncomplex Gaussian (CSCG) distribution for the BD's signal, this assumption may\nnot be practical because the high complexity of generating CSCG signals is not\nsupported by the low-cost BD. In this paper, we address this gap by\ninvestigating SBC for two low-complexity modulation schemes, i.e., $M$-ary\namplitude-shift keying (MASK) and $M$-ary phase-shift keying (MPSK), where BD's\nsignals inherently deviate from CSCG distribution. Our goal is to derive the\nachievable rate of the PT and BD under the MASK/MPSK and to design MASK/MPSK\nmodulation scheme for maximizing the PT's rate. Towards this end, we first\nderive the expressions of both the PT's rate and BD's rate. Theoretical results\nreveal that whether or not the BD improves the PT's rate depends on the phase\nof MASK/MPSK modulation, while the BD's rate is independent of this phase. We\nthen formulate two optimization problems to maximize the PT's rate by adjusting\nthe phase under the MASK and MPSK modulation schemes, respectively, and derive\nthe optimal phases for each modulation scheme in closed forms. Simulation\nresults demonstrate that the optimal phase of MASK/MPSK can ensure an\nimprovement in the PT's rate, and reveal that a low-order ASK modulation is\nbetter than a low-order PSK for the BD in terms of improving PT's rate,\nespecially when the direct link is not significantly weaker than the\nbackscatter link in SBC.", "comment": "Submitted to IEEE Trans", "pdf_url": "http://arxiv.org/pdf/2507.01782v1", "categories": ["cs.IT", "math.IT"], "cate": "cs.IT", "url": "http://arxiv.org/abs/2507.01782v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "共生反向散射通信：反向散射设备调制方案的设计视角", "tldr": "研究了低成本反向散射设备（BD）的低复杂度调制方案（MASK/MPSK），以优化主发射机（PT）的速率。", "motivation": "先前的研究假设反向散射设备（BD）的信号为圆形对称复高斯分布，但这对于低成本BD来说不切实际，本文旨在解决这一实际应用中的差距。", "method": "本文研究了两种低复杂度调制方案：M-ary幅度键控（MASK）和M-ary相移键控（MPSK）。首先，推导了主发射机（PT）和反向散射设备（BD）在MASK/MPSK下的可实现速率表达式。随后，建立了两个优化问题，分别通过调整MASK和MPSK调制方案下的相位来最大化PT的速率，并推导了闭合形式的最优相位。", "result": "理论结果表明，反向散射设备（BD）是否提高主发射机（PT）的速率取决于MASK/MPSK调制的相位，而BD的速率与该相位无关。仿真结果表明，MASK/MPSK的最优相位可以确保PT速率的提高。此外，研究发现低阶ASK调制在提高PT速率方面优于低阶PSK，尤其是在共生反向散射通信中直连链路不显著弱于反向散射链路的情况下。", "conclusion": "本文通过设计低复杂度调制方案（MASK/MPSK）的最优相位，可以有效提高共生反向散射通信中主发射机的速率，且低阶ASK在特定条件下表现更优。", "translation": "共生反向散射通信（SBC）已成为一种频谱高效、低功耗的通信技术，其中反向散射设备（BD）对来自主发射机（PT）的入射射频（RF）信号进行调制和反射。尽管先前的研究假设BD的信号是圆形对称复高斯（CSCG）分布的，但由于生成CSCG信号的高复杂度不被低成本BD所支持，这种假设可能不切实际。在本文中，我们通过研究两种低复杂度调制方案（即M-ary幅度键控（MASK）和M-ary相移键控（MPSK））的SBC来弥补这一空白，其中BD的信号本质上偏离CSCG分布。我们的目标是在MASK/MPSK下推导PT和BD的可实现速率，并设计MASK/MPSK调制方案以最大化PT的速率。为此，我们首先推导了PT速率和BD速率的表达式。理论结果表明，BD是否提高PT的速率取决于MASK/MPSK调制的相位，而BD的速率与此相位无关。然后，我们分别建立了两个优化问题，通过调整MASK和MPSK调制方案下的相位来最大化PT的速率，并以闭合形式推导了每种调制方案的最优相位。仿真结果表明，MASK/MPSK的最优相位可以确保PT速率的提高，并揭示了在提高PT速率方面，低阶ASK调制优于低阶PSK，特别是当SBC中直连链路不显著弱于反向散射链路时。", "summary": "本文针对共生反向散射通信中低成本反向散射设备（BD）的实际调制限制，研究了两种低复杂度调制方案（MASK和MPSK）。作者推导了主发射机（PT）和BD的可实现速率，并设计了优化问题以最大化PT速率，得到了最优相位的闭合解。研究发现调制相位对PT速率有影响而对BD速率无影响，且在特定条件下，低阶MASK在提高PT速率方面优于低阶MPSK。", "keywords": "共生反向散射通信, 调制方案, MASK, MPSK, 可实现速率", "comments": "本文的创新点在于解决了共生反向散射通信中低成本设备无法支持复杂圆形对称复高斯调制的问题，提出了更实际的低复杂度调制方案（MASK/MPSK）并进行了深入分析和优化设计。这对于推动SBC的实际部署具有重要意义。"}}
{"id": "2507.01067", "title": "Evaluation of a Foundational Model and Stochastic Models for Forecasting Sporadic or Spiky Production Outages of High-Performance Machine Learning Services", "authors": ["Keun Soo Yim"], "summary": "Time series forecasting models have diverse real world applications (e.g.,\nfrom electricity metrics to software workload). Latest foundational models\ntrained for time series forecasting show strengths (e.g., for long sequences\nand in zero-shot settings). However, foundational model was not yet used for\nforecasting rare, spiky events, i.e., a challenging target because those are a\ncorner case of extreme events. In this paper, we optimize a state-of-the-art\nfoundational model to forecast sporadic or spiky production outages of\nhigh-performance machine learning services powering billions of client devices.\nWe evaluate the forecasting errors of the foundational model compared with\nclassical stochastic forecasting models (e.g., moving average and\nautoregressive). The analysis helps us understand how each of the evaluated\nmodels performs for the sporadic or spiky events. For example, it identifies\nthe key patterns in the target data that are well tracked by the foundational\nmodel vs. each of the stochastic models. We use the models with optimal\nparameters to estimate a year-long outage statistics of a particular root cause\nwith less than 6% value errors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01067v1", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.SY", "eess.SY"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01067v1", "date": "2025-06-30", "updated": "2025-06-30", "AI": {"title_translation": "评估基础模型和随机模型在预测高性能机器学习服务偶发或尖峰生产中断方面的应用", "tldr": "本文优化并评估了一个基础模型，用于预测高性能机器学习服务的偶发性生产中断，并将其与传统随机模型进行比较，结果显示能够以低误差估计长时间中断统计数据。", "motivation": "基础模型尚未用于预测罕见、尖峰事件（即极端事件的特例），而这类事件的预测具有挑战性。", "method": "优化了一个最先进的基础模型来预测高性能机器学习服务的偶发或尖峰生产中断。将该基础模型的预测误差与经典随机预测模型（如移动平均和自回归）进行比较评估。分析了不同模型在跟踪目标数据中关键模式的表现。使用参数最优的模型估计了特定根本原因长达一年的中断统计数据。", "result": "分析有助于理解每个评估模型在处理偶发或尖峰事件时的表现。例如，它识别了目标数据中基础模型和随机模型分别能很好跟踪的关键模式。使用最优参数的模型估计了一年长的中断统计数据，其价值误差低于6%。", "conclusion": "通过对基础模型和经典随机模型的评估，揭示了它们在预测偶发或尖峰事件中的表现差异，并证明了优化的模型能够以高精度估计长时间的中断统计数据。", "translation": "时间序列预测模型在现实世界中有多种应用（例如，从电力指标到软件工作负载）。最新的时间序列预测基础模型显示出其优势（例如，对于长序列和零样本设置）。然而，基础模型尚未用于预测罕见、尖峰事件，即具有挑战性的目标，因为这些是极端事件的特殊情况。在本文中，我们优化了一个最先进的基础模型，用于预测为数十亿客户端设备提供服务的高性能机器学习服务的偶发或尖峰生产中断。我们评估了基础模型与经典随机预测模型（例如，移动平均和自回归）相比的预测误差。该分析有助于我们理解每个评估模型在偶发或尖峰事件中的表现。例如，它识别了目标数据中基础模型与每个随机模型分别能很好跟踪的关键模式。我们使用参数最优的模型来估计特定根本原因长达一年的中断统计数据，其价值误差低于6%。", "summary": "本文研究了基础模型在预测高性能机器学习服务偶发或尖峰生产中断方面的应用。作者优化了一个最先进的基础模型，并将其预测误差与经典的随机模型（如移动平均和自回归）进行了比较。研究发现，该分析有助于理解不同模型在处理偶发或尖峰事件时的表现，并识别了它们能有效跟踪的关键数据模式。最终，使用最优参数的模型能够以低于6%的误差估计长达一年的中断统计数据。", "keywords": "基础模型, 时间序列预测, 生产中断, 偶发事件, 机器学习服务", "comments": "本文的创新之处在于首次将基础模型应用于预测罕见且具有挑战性的偶发或尖峰事件，这扩展了基础模型在时间序列预测领域的应用范围。通过与传统随机模型的比较，为理解不同模型在处理极端事件时的优势和局限性提供了宝贵的见解，对于维护高性能机器学习服务的稳定性具有重要意义。"}}
{"id": "2507.01564", "title": "Multi Source COVID-19 Detection via Kernel-Density-based Slice Sampling", "authors": ["Chia-Ming Lee", "Bo-Cheng Qiu", "Ting-Yao Chen", "Ming-Han Sun", "Fang-Ying Lin", "Jung-Tse Tsai", "I-An Tsai", "Yu-Fan Lin", "Chih-Chung Hsu"], "summary": "We present our solution for the Multi-Source COVID-19 Detection Challenge,\nwhich classifies chest CT scans from four distinct medical centers. To address\nmulti-source variability, we employ the Spatial-Slice Feature Learning (SSFL)\nframework with Kernel-Density-based Slice Sampling (KDS). Our preprocessing\npipeline combines lung region extraction, quality control, and adaptive slice\nsampling to select eight representative slices per scan. We compare\nEfficientNet and Swin Transformer architectures on the validation set. The\nEfficientNet model achieves an F1-score of 94.68%, compared to the Swin\nTransformer's 93.34%. The results demonstrate the effectiveness of our\nKDS-based pipeline on multi-source data and highlight the importance of dataset\nbalance in multi-institutional medical imaging evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01564v1", "categories": ["eess.IV", "cs.CV"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01564v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于核密度切片采样的多源COVID-19检测", "tldr": "本文提出了一种基于KDS和EfficientNet的多源COVID-19检测方案，用于分类来自不同医疗中心的胸部CT扫描，实现了高F1分数，并强调了数据集平衡的重要性。", "motivation": "为了解决来自四个不同医疗中心的胸部CT扫描在COVID-19检测中存在的多种源变异性问题。", "method": "本研究采用了空间切片特征学习（SSFL）框架，并结合了基于核密度的切片采样（KDS）。预处理流程包括肺区域提取、质量控制和自适应切片采样，每个扫描选择八个代表性切片。在验证集上比较了EfficientNet和Swin Transformer两种架构。", "result": "EfficientNet模型取得了94.68%的F1分数，而Swin Transformer取得了93.34%的F1分数。结果表明KDS-based管道在多源数据上的有效性。", "conclusion": "基于KDS的管道在多源COVID-19检测中表现出有效性，并且在多机构医学影像评估中，数据集的平衡性至关重要。", "translation": "我们提出了针对多源COVID-19检测挑战的解决方案，该方案对来自四个不同医疗中心的胸部CT扫描进行分类。为了解决多源变异性，我们采用了空间切片特征学习（SSFL）框架和基于核密度的切片采样（KDS）。我们的预处理流程结合了肺区域提取、质量控制和自适应切片采样，为每个扫描选择八个代表性切片。我们在验证集上比较了EfficientNet和Swin Transformer架构。EfficientNet模型取得了94.68%的F1分数，而Swin Transformer取得了93.34%。结果证明了我们基于KDS的管道在多源数据上的有效性，并强调了数据集平衡在多机构医学影像评估中的重要性。", "summary": "本研究提出了一种用于多源COVID-19检测的解决方案，旨在分类来自四个不同医疗中心的胸部CT扫描。为解决多源变异性，研究采用了空间切片特征学习（SSFL）框架并结合了基于核密度的切片采样（KDS）。预处理流程包括肺区域提取、质量控制和自适应切片采样，每个扫描选取八个代表性切片。在模型比较中，EfficientNet在验证集上取得了94.68%的F1分数，优于Swin Transformer的93.34%。研究结果验证了基于KDS的管道在处理多源数据时的有效性，并强调了在多机构医学影像评估中数据集平衡的关键作用。", "keywords": "COVID-19检测, 多源, 核密度切片采样, 胸部CT, EfficientNet", "comments": "该论文通过引入基于核密度的切片采样（KDS）方法，有效应对了多源医学影像数据中的变异性挑战，这在实际应用中具有重要意义。通过比较EfficientNet和Swin Transformer两种先进的深度学习架构，增强了结果的说服力。此外，论文强调了在多机构医学影像评估中数据集平衡的重要性，为未来的研究和实践提供了宝贵的见解。"}}
{"id": "2507.01460", "title": "Robust Input Shaping Control for Flexible Structures Based on Unscented Kalman Filter", "authors": ["Weiyi Yang", "Yu Yuan", "Mingsheng Shang"], "summary": "With the rapid development of industrial automation and smart manufacturing,\nthe control of flexible structures and underactuated systems has become a\ncritical research focus. Residual vibrations in these systems not only degrade\noperational efficiency but also pose risks to structural integrity and\nlongevity. Traditional input shaping techniques, while effective, often suffer\nfrom performance degradation due to parameter inaccuracies and environmental\ndisturbances. To address these challenges, this paper introduces an innovative\nunscented Kalman filter-based zero vibration derivative input shaping (UZS)\nmethod. The proposed approach combines two key innovations: 1) a data-driven\nUnscented Kalman Filterfor real-time system parameter identification, and 2) a\nzero-vibration derivative (ZVD) input shaper for robust vibration suppression.\nTo validate the effectiveness of UZS, we conducted extensive experiments on a\nvertical flexible beam platform, and the results demonstrate significant\nimprovements over state-of-the-art methods. Additionally, we have made the\nexperimental datasets publicly available to facilitate further research. The\nfindings highlight UZS's potential for practical applications in industrial\nautomation, robotics, and precision engineering.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01460v1", "categories": ["eess.SY", "cs.SY"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01460v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于无迹卡尔曼滤波的柔性结构鲁棒输入整形控制", "tldr": "本文提出了一种基于无迹卡尔曼滤波的零振动导数输入整形(UZS)方法，用于柔性结构的鲁棒振动抑制，并在实验中验证了其有效性。", "motivation": "工业自动化和智能制造中，柔性结构和欠驱动系统的残余振动会降低运行效率并损害结构完整性。传统输入整形技术因参数不准确和环境干扰而性能下降，因此需要更鲁棒的方法。", "method": "本文提出了一种创新的基于无迹卡尔曼滤波的零振动导数输入整形(UZS)方法。该方法结合了两个关键创新点：1) 基于数据驱动的无迹卡尔曼滤波，用于实时系统参数识别；2) 零振动导数(ZVD)输入整形器，用于鲁棒振动抑制。", "result": "在垂直柔性梁平台上进行了广泛实验，结果表明UZS方法比现有先进方法有显著改进。实验数据集已公开。", "conclusion": "UZS方法在工业自动化、机器人技术和精密工程等实际应用中具有巨大潜力，能够有效抑制柔性结构振动。", "translation": "随着工业自动化和智能制造的快速发展，柔性结构和欠驱动系统的控制已成为研究的关键焦点。这些系统中的残余振动不仅会降低运行效率，还会对结构完整性和寿命构成风险。传统的输入整形技术虽然有效，但由于参数不准确和环境干扰，其性能往往会下降。为了解决这些挑战，本文引入了一种创新的基于无迹卡尔曼滤波的零振动导数输入整形（UZS）方法。所提出的方法结合了两个关键创新点：1）数据驱动的无迹卡尔曼滤波，用于实时系统参数识别；2）零振动导数（ZVD）输入整形器，用于鲁棒振动抑制。为了验证 UZS 的有效性，我们在垂直柔性梁平台上进行了广泛的实验，结果表明与现有先进方法相比，UZS 有显著改进。此外，我们已公开实验数据集，以促进进一步研究。研究结果突出显示了 UZS 在工业自动化、机器人技术和精密工程等实际应用中的潜力。", "summary": "本文针对柔性结构和欠驱动系统中的残余振动问题，提出了一种基于无迹卡尔曼滤波的零振动导数输入整形（UZS）方法。该方法结合了实时参数识别的无迹卡尔曼滤波和鲁棒振动抑制的ZVD输入整形器。实验结果表明，UZS在垂直柔性梁平台上表现出优于现有方法的性能，并为工业自动化、机器人和精密工程提供了新的应用潜力。", "keywords": "输入整形, 柔性结构, 无迹卡尔曼滤波, 振动抑制, 鲁棒控制", "comments": "该论文的创新点在于将无迹卡尔曼滤波与零振动导数输入整形相结合，实现了对柔性结构更鲁棒的振动抑制，有效克服了传统方法的局限性。公开数据集的做法也值得称赞，有利于后续研究。"}}
{"id": "2507.01297", "title": "Frustratingly Simple Retrieval Improves Challenging, Reasoning-Intensive Benchmarks", "authors": ["Xinxi Lyu", "Michael Duan", "Rulin Shao", "Pang Wei Koh", "Sewon Min"], "summary": "Retrieval-augmented Generation (RAG) has primarily been studied in limited\nsettings, such as factoid question answering; more challenging,\nreasoning-intensive benchmarks have seen limited success from minimal RAG. In\nthis work, we challenge this prevailing view on established,\nreasoning-intensive benchmarks: MMLU, MMLU Pro, AGI Eval, GPQA, and MATH. We\nidentify a key missing component in prior work: a usable, web-scale datastore\naligned with the breadth of pretraining data. To this end, we introduce\nCompactDS: a diverse, high-quality, web-scale datastore that achieves high\nretrieval accuracy and subsecond latency on a single-node. The key insights are\n(1) most web content can be filtered out without sacrificing coverage, and a\ncompact, high-quality subset is sufficient; and (2) combining in-memory\napproximate nearest neighbor (ANN) retrieval and on-disk exact search balances\nspeed and recall. Using CompactDS, we show that a minimal RAG pipeline achieves\nconsistent accuracy improvements across all benchmarks and model sizes\n(8B--70B), with relative gains of 10% on MMLU, 33% on MMLU Pro, 14% on GPQA,\nand 19% on MATH. No single data source suffices alone, highlighting the\nimportance of diversity of sources (web crawls, curated math, academic papers,\ntextbooks). Finally, we show that our carefully designed in-house datastore\nmatches or outperforms web search engines such as Google Search, as well as\nrecently proposed, complex agent-based RAG systems--all while maintaining\nsimplicity, reproducibility, and self-containment. We release CompactDS and our\nretrieval pipeline, supporting future research exploring retrieval-based AI\nsystems.", "comment": "33 pages, 2 figures, 27 tables", "pdf_url": "http://arxiv.org/pdf/2507.01297v1", "categories": ["cs.CL", "cs.IR"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01297v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "令人惊讶的简单检索改进了具有挑战性的推理密集型基准", "tldr": "简单的检索增强生成（RAG）通过引入新的网络级数据存储CompactDS，显著提升了在复杂推理基准上的性能，甚至超越了复杂的RAG系统和网络搜索引擎。", "motivation": "之前的检索增强生成（RAG）在具有挑战性的推理密集型基准上表现有限，原因是缺乏可用且与预训练数据广度对齐的网络级数据存储。", "method": "本文引入了CompactDS，一个多样化、高质量、网络级的数据存储。其关键思想是：1) 大部分网络内容可以被过滤以获得紧凑、高质量的子集；2) 结合内存中近似最近邻（ANN）检索和磁盘上精确搜索以平衡速度和召回率。随后，一个最小的RAG管道被用于基准测试。", "result": "在所有基准测试（MMLU、MMLU Pro、AGI Eval、GPQA、MATH）和模型大小（8B-70B）上均实现了持续的准确性提升。相对增益：MMLU上10%，MMLU Pro上33%，GPQA上14%，MATH上19%。CompactDS与Google Search以及最近提出的复杂基于代理的RAG系统相比，表现相当或更优。研究强调了数据源多样性的重要性。", "conclusion": "通过精心设计、简单的检索管道和高质量、多样化的网络级数据存储（CompactDS），可以显著提高在具有挑战性的推理任务上的性能，突出了RAG系统中数据质量和多样性的重要性。", "translation": "检索增强生成（RAG）主要在有限的设置中进行研究，例如事实问答；更具挑战性、推理密集型的基准测试在最小RAG方面的成功有限。在这项工作中，我们挑战了在既定推理密集型基准测试（MMLU、MMLU Pro、AGI Eval、GPQA和MATH）上普遍存在的观点。我们识别出先前工作中一个关键的缺失组成部分：一个可用、网络规模且与预训练数据广度对齐的数据存储。为此，我们引入了CompactDS：一个多样化、高质量、网络规模的数据存储，它在单节点上实现了高检索准确性和亚秒级延迟。关键的见解是（1）大多数网络内容可以在不牺牲覆盖率的情况下被过滤掉，一个紧凑、高质量的子集就足够了；（2）结合内存中近似最近邻（ANN）检索和磁盘上精确搜索可以平衡速度和召回率。使用CompactDS，我们展示了一个最小的RAG管道在所有基准测试和模型大小（8B-70B）上都实现了持续的准确性改进，在MMLU上相对增益为10%，MMLU Pro上为33%，GPQA上为14%，MATH上为19%。没有任何单一数据源足以单独使用，这突出了来源多样性（网络爬虫、精选数学、学术论文、教科书）的重要性。最后，我们展示了我们精心设计的内部数据存储与Google Search等网络搜索引擎以及最近提出的复杂基于代理的RAG系统相比，表现相当或更优——同时保持了简单性、可复现性和自包含性。我们发布了CompactDS和我们的检索管道，以支持未来探索基于检索的AI系统的研究。", "summary": "本文针对检索增强生成（RAG）在复杂推理密集型基准上表现不佳的问题，指出缺乏合适的网络级数据存储是关键原因。为此，作者提出了CompactDS，一个高质量、多样化、网络规模的数据存储，其设计理念是精简网络内容并结合ANN与精确搜索以优化性能。实验表明，即使是最小的RAG管道，结合CompactDS后，也能在MMLU、MMLU Pro、GPQA和MATH等基准测试上取得显著的准确性提升，并超越了现有网络搜索引擎和复杂的RAG系统，证明了简单检索的有效性和数据多样性的重要性。", "keywords": "检索增强生成, RAG, 数据存储, CompactDS, 推理基准", "comments": "创新点在于引入了CompactDS这一高质量、多样化的网络级数据存储，并证明了“令人惊讶的简单”检索方法在处理复杂推理密集型基准时能取得显著成效。这挑战了之前认为简单RAG在这些任务上效果有限的普遍观点，为未来RAG系统的研究提供了新的方向，尤其是在数据存储和检索策略的优化上。"}}
{"id": "2507.01552", "title": "A mixed Petrov--Galerkin Cosserat rod finite element formulation", "authors": ["Marco Herrmann", "Domenico Castello", "Jonas Breuling", "Idoia Cortes Garcia", "Leopoldo Greco", "Simon R. Eugster"], "summary": "This paper presents a total Lagrangian mixed Petrov--Galerkin finite element\nformulation that provides a computationally efficient approach for analyzing\nCosserat rods that is free of singularities and locking. To achieve a\nsingularity-free orientation parametrization of the rod, the nodal kinematical\nunknowns are defined as the nodal centerline positions and unit quaternions. We\napply Lagrangian interpolation to all nodal kinematic coordinates, and in\ncombination with a projection of non-unit quaternions, this leads to an\ninterpolation with orthonormal cross-section-fixed bases. To eliminate locking\neffects such as shear locking, the variational Hellinger--Reissner principle is\napplied, resulting in a mixed approach with additional fields composed of\nresultant contact forces and moments. Since the mixed formulation contains the\nconstitutive law in compliance form, it naturally incorporates constrained\ntheories, such as the Kirchhoff--Love theory. This study specifically examines\nthe influence of the additional internal force fields on the numerical\nperformance, including locking mitigation and robustness. Using\nwell-established benchmark examples, the method demonstrates enhanced\ncomputational robustness and efficiency, as evidenced by the reduction in\nrequired load steps and iterations when applying the standard Newton--Raphson\nmethod.", "comment": "30 pages, 14 figures, to be published in the \"Journal of Theoretical,\n  Computational and Applied Mechanics\"", "pdf_url": "http://arxiv.org/pdf/2507.01552v1", "categories": ["math.NA", "cs.NA"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01552v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "混合Petrov--Galerkin科塞拉杆有限元公式", "tldr": "本文提出了一种混合Petrov-Galerkin有限元方法，用于高效分析Cosserat杆，避免了奇点和锁定，并通过基准测试验证了其鲁棒性和效率。", "motivation": "现有的Cosserat杆分析方法可能存在奇点和锁定问题，需要一种计算效率高且无这些问题的公式。", "method": "采用全拉格朗日混合Petrov--Galerkin有限元公式。通过将节点运动学未知数定义为节点中心线位置和单位四元数来消除奇点。结合非单位四元数的投影，实现正交截面固定基的插值。应用变分Hellinger--Reissner原理，引入由合接触力和合力矩组成的额外场，以消除剪切锁定等锁定效应。该混合公式以柔度形式包含本构律，能自然地纳入约束理论。", "result": "该方法在基准示例中展示了增强的计算鲁棒性和效率，通过应用标准Newton--Raphson方法时所需载荷步和迭代次数的减少得到证明。", "conclusion": "所提出的混合Petrov--Galerkin有限元公式为Cosserat杆的分析提供了一种计算高效、无奇点和锁定的方法，并显著提高了数值性能。", "translation": "本文提出了一种全拉格朗日混合Petrov--Galerkin有限元公式，为分析科塞拉（Cosserat）杆提供了一种计算效率高、无奇点和锁定的方法。为了实现杆的无奇点方向参数化，节点运动学未知量定义为节点中心线位置和单位四元数。我们将拉格朗日插值应用于所有节点运动学坐标，并结合非单位四元数的投影，这导致了具有正交截面固定基的插值。为了消除剪切锁定等锁定效应，应用了变分Hellinger--Reissner原理，从而形成了一种混合方法，其中包含由合接触力和合力矩组成的附加场。由于该混合公式以柔度形式包含本构律，它自然地纳入了约束理论，例如基尔霍夫-洛夫（Kirchhoff--Love）理论。本研究专门检查了附加内力场对数值性能（包括锁定缓解和鲁棒性）的影响。使用成熟的基准示例，该方法展示了增强的计算鲁棒性和效率，通过应用标准Newton--Raphson方法时所需载荷步和迭代次数的减少得到证明。", "summary": "本文介绍了一种全拉格朗日混合Petrov-Galerkin有限元公式，用于高效、无奇点和无锁定的Cosserat杆分析。该方法通过使用单位四元数进行无奇点方向参数化，并通过变分Hellinger-Reissner原理引入附加力矩场来消除锁定效应。研究结果表明，该公式显著提高了计算的鲁棒性和效率，减少了收敛所需的迭代次数，并能自然地纳入各种约束理论。", "keywords": "Cosserat杆, 有限元, Petrov-Galerkin, 混合公式, 锁定效应", "comments": "这篇论文通过结合Petrov-Galerkin方法、单位四元数和Hellinger-Reissner原理，为Cosserat杆的有限元分析提供了一个创新且实用的解决方案。其核心创新在于同时解决了奇点和锁定两大常见数值问题，并通过引入额外力场提高了模型的鲁棒性。这对于需要精确模拟细长结构（如机器人臂、生物体软组织）的工程领域具有重要意义。"}}
{"id": "2507.01750", "title": "Generalizable Detection of Audio Deepfakes", "authors": ["Jose A. Lopez", "Georg Stemmer", "Héctor Cordourier Maruri"], "summary": "In this paper, we present our comprehensive study aimed at enhancing the\ngeneralization capabilities of audio deepfake detection models. We investigate\nthe performance of various pre-trained backbones, including Wav2Vec2, WavLM,\nand Whisper, across a diverse set of datasets, including those from the\nASVspoof challenges and additional sources. Our experiments focus on the\neffects of different data augmentation strategies and loss functions on model\nperformance. The results of our research demonstrate substantial enhancements\nin the generalization capabilities of audio deepfake detection models,\nsurpassing the performance of the top-ranked single system in the ASVspoof 5\nChallenge. This study contributes valuable insights into the optimization of\naudio models for more robust deepfake detection and facilitates future research\nin this critical area.", "comment": "8 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.01750v1", "categories": ["eess.AS", "cs.SD"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01750v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "可泛化音频深度伪造检测", "tldr": "本研究旨在增强音频深度伪造检测模型的泛化能力，通过探索不同的预训练骨干网络、数据增强策略和损失函数，显著提升了模型性能，超越了ASVspoof 5挑战赛的最佳单系统。", "motivation": "本研究旨在增强音频深度伪造检测模型的泛化能力。", "method": "研究调查了Wav2Vec2、WavLM和Whisper等多种预训练骨干网络在ASVspoof挑战赛及其他来源的各种数据集上的性能。实验重点关注了不同数据增强策略和损失函数对模型性能的影响。", "result": "研究结果表明，音频深度伪造检测模型的泛化能力得到了显著提升，超越了ASVspoof 5挑战赛中排名最高的单系统性能。", "conclusion": "本研究为优化音频模型以实现更稳健的深度伪造检测提供了宝贵的见解，并为该关键领域的未来研究提供了便利。", "translation": "在本文中，我们提出了旨在增强音频深度伪造检测模型泛化能力的综合研究。我们调查了包括Wav2Vec2、WavLM和Whisper在内的各种预训练骨干网络在ASVspoof挑战赛数据集和其他来源的各种数据集上的性能。我们的实验重点关注了不同数据增强策略和损失函数对模型性能的影响。我们的研究结果表明，音频深度伪造检测模型的泛化能力得到了显著增强，超越了ASVspoof 5挑战赛中排名最高的单系统性能。这项研究为优化音频模型以实现更稳健的深度伪造检测提供了宝贵的见解，并促进了该关键领域的未来研究。", "summary": "本研究致力于提升音频深度伪造检测模型的泛化能力。通过对Wav2Vec2、WavLM、Whisper等预训练骨干网络在多样化数据集上的表现进行深入探究，并考察不同数据增强策略和损失函数的影响，研究团队成功显著增强了模型的泛化性能，甚至超越了ASVspoof 5挑战赛的顶级单系统。这项工作为构建更鲁棒的深度伪造检测音频模型提供了重要指导，并为未来的相关研究奠定了基础。", "keywords": "音频深度伪造, 泛化能力, 检测, 预训练骨干网络, 数据增强", "comments": "这项研究在提升音频深度伪造检测模型的泛化能力方面取得了显著进展，通过系统性地探索预训练骨干网络、数据增强和损失函数的组合，为该领域提供了宝贵的实践指导。其超越ASVspoof 5挑战赛最佳单系统性能的结果，证明了其方法的有效性和重要性。"}}
{"id": "2507.01383", "title": "DARTS: A Dual-View Attack Framework for Targeted Manipulation in Federated Sequential Recommendation", "authors": ["Qitao Qin", "Yucong Luo", "Zhibo Chu"], "summary": "Federated recommendation (FedRec) preserves user privacy by enabling\ndecentralized training of personalized models, but this architecture is\ninherently vulnerable to adversarial attacks. Significant research has been\nconducted on targeted attacks in FedRec systems, motivated by commercial and\nsocial influence considerations. However, much of this work has largely\noverlooked the differential robustness of recommendation models. Moreover, our\nempirical findings indicate that existing targeted attack methods achieve only\nlimited effectiveness in Federated Sequential Recommendation(FSR) tasks. Driven\nby these observations, we focus on investigating targeted attacks in FSR and\npropose a novel dualview attack framework, named DV-FSR. This attack method\nuniquely combines a sampling-based explicit strategy with a contrastive\nlearning-based implicit gradient strategy to orchestrate a coordinated attack.\nAdditionally, we introduce a specific defense mechanism tailored for targeted\nattacks in FSR, aiming to evaluate the mitigation effects of the attack method\nwe proposed. Extensive experiments validate the effectiveness of our proposed\napproach on representative sequential models. Our codes are publicly available.", "comment": "10 pages. arXiv admin note: substantial text overlap with\n  arXiv:2409.07500; text overlap with arXiv:2212.05399 by other authors", "pdf_url": "http://arxiv.org/pdf/2507.01383v1", "categories": ["cs.IR"], "cate": "cs.IR", "url": "http://arxiv.org/abs/2507.01383v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "DARTS：一种针对联邦序列推荐中目标操纵的双视角攻击框架", "tldr": "本文提出了DARTS，一个双视角攻击框架，用于联邦序列推荐（FSR）中的目标攻击，结合了显式采样和隐式对比学习策略，并证明了其有效性。", "motivation": "联邦推荐（FedRec）易受对抗性攻击，但现有针对性攻击方法在联邦序列推荐（FSR）任务中效果有限，且忽视了推荐模型的差异鲁棒性。", "method": "提出了一种名为DV-FSR（DARTS）的双视角攻击框架，结合了基于采样的显式策略和基于对比学习的隐式梯度策略。此外，还引入了一种专门针对FSR中目标攻击的防御机制。", "result": "大量实验验证了所提出方法在代表性序列模型上的有效性。", "conclusion": "本文提出了一个新颖的双视角攻击框架DV-FSR，有效解决了联邦序列推荐中的目标攻击问题，并引入了相应的防御机制。", "translation": "联邦推荐（FedRec）通过实现个性化模型的去中心化训练来保护用户隐私，但这种架构本质上容易受到对抗性攻击。基于商业和社会影响力考虑，针对FedRec系统中目标攻击的研究已经进行了大量。然而，这些工作大多忽略了推荐模型的差异鲁棒性。此外，我们的实证结果表明，现有目标攻击方法在联邦序列推荐（FSR）任务中效果有限。受这些观察的驱动，我们专注于研究FSR中的目标攻击，并提出了一种新颖的双视角攻击框架，命名为DV-FSR。这种攻击方法独特地结合了基于采样的显式策略和基于对比学习的隐式梯度策略，以协调攻击。此外，我们引入了一种专门针对FSR中目标攻击的防御机制，旨在评估我们提出的攻击方法的缓解效果。大量实验验证了我们提出的方法在代表性序列模型上的有效性。我们的代码是公开的。", "summary": "本文针对联邦序列推荐（FSR）中现有目标攻击方法效果有限且忽视模型鲁棒性的问题，提出了一个名为DARTS（DV-FSR）的新型双视角攻击框架。该框架独特地结合了基于采样的显式策略和基于对比学习的隐式梯度策略，以实现协调攻击。此外，论文还引入了一种针对FSR目标攻击的防御机制。通过大量实验，验证了所提出攻击方法的有效性。", "keywords": "联邦序列推荐, 目标攻击, 双视角攻击, 对抗性攻击, 隐私保护", "comments": "本文创新性地提出了一个双视角攻击框架，结合了显式和隐式策略，有效提升了联邦序列推荐系统中的目标攻击能力。同时，也考虑了相应的防御机制，对理解和提升FedRec系统的安全性具有重要意义。"}}
{"id": "2507.01426", "title": "Approximation-free Control of Unknown Euler-Lagrangian Systems under Input Constraints", "authors": ["Ratnangshu Das", "Pushpak Jagtap"], "summary": "In this paper, we present a novel funnel-based tracking control algorithm for\nrobotic systems with unknown dynamics and prescribed input constraints. The\nEuler-Lagrange formulation, a common modeling approach for robotic systems, has\nbeen adopted in this study to address the trade-off between performance and\nactuator safety. We establish feasibility conditions that ensure tracking\nerrors evolve within predefined funnel bounds while maintaining bounded control\nefforts, a crucial consideration for robots with limited actuation\ncapabilities. We propose two approximation-free control strategies for\nscenarios where these conditions are violated: one actively corrects the error,\nand the other stops further deviation. Finally, we demonstrate the robust\nperformance and safety of the approach through simulations and experimental\nvalidations. This work represents a significant advancement in funnel-based\ncontrol, enhancing its applicability to real-world robotics systems with input\nconstraints.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01426v1", "categories": ["cs.RO", "cs.SY", "eess.SY"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01426v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "未知欧拉-拉格朗日系统在输入约束下的无近似控制", "tldr": "本文提出了一种新颖的基于漏斗的跟踪控制算法，用于具有未知动力学和预设输入约束的机器人系统，确保跟踪误差在预设范围内并保持控制力有界，并通过仿真和实验验证了其鲁棒性能和安全性。", "motivation": "该研究旨在解决机器人系统在性能与执行器安全之间的权衡问题，特别关注具有有限执行能力机器人的关键考量，并增强基于漏斗控制在具有输入约束的实际机器人系统中的适用性。", "method": "本文提出了一种新颖的基于漏斗的跟踪控制算法，该算法采用了欧拉-拉格朗日公式来处理未知动力学和预设输入约束。研究建立了可行性条件以确保跟踪误差在预定义漏斗范围内演变，同时保持控制力有界。此外，针对这些条件被违反的情况，提出了两种无近似控制策略：一种主动纠正误差，另一种阻止进一步偏差。", "result": "该方法能够确保跟踪误差在预定义的漏斗边界内演变，同时保持控制力有界。通过仿真和实验验证，证明了该方法的鲁棒性能和安全性。", "conclusion": "这项工作代表了基于漏斗控制的重大进展，增强了其在具有输入约束的实际机器人系统中的适用性。", "translation": "本文提出了一种新颖的基于漏斗的跟踪控制算法，用于具有未知动力学和预设输入约束的机器人系统。本研究采用欧拉-拉格朗日公式这一机器人系统常用建模方法，以解决性能和执行器安全之间的权衡问题。我们建立了可行性条件，以确保跟踪误差在预定义的漏斗边界内演变，同时保持控制力有界，这是对执行能力有限的机器人来说至关重要的考虑因素。对于这些条件被违反的场景，我们提出了两种无近似控制策略：一种主动纠正误差，另一种阻止进一步偏差。最后，我们通过仿真和实验验证展示了该方法的鲁棒性能和安全性。这项工作代表了基于漏斗控制的重大进展，增强了其在具有输入约束的实际机器人系统中的适用性。", "summary": "本文介绍了一种针对未知欧拉-拉格朗日机器人系统的新型无近似基于漏斗的跟踪控制算法，该算法在存在输入约束的情况下运行。该研究通过建立可行性条件，确保跟踪误差保持在预设的漏斗范围内，并维持有界的控制力。当这些条件被违反时，提出了两种无近似控制策略来纠正或阻止误差。仿真和实验验证证明了该方法的鲁棒性能和安全性，显著提升了基于漏斗控制在实际机器人应用中的实用性。", "keywords": "基于漏斗控制, 欧拉-拉格朗日系统, 输入约束, 无近似控制, 机器人", "comments": "本文的创新点在于提出了无近似的基于漏斗控制策略，有效解决了未知欧拉-拉格朗日系统在输入约束下的控制问题。其重要性体现在能够平衡性能与执行器安全，并且通过两种应对策略提高了系统的鲁棒性，使其更适用于实际具有有限执行能力的机器人系统。这项工作为基于漏斗控制在复杂真实世界场景中的应用开辟了新的可能性。"}}
{"id": "2507.01749", "title": "Joint Matching and Pricing for Crowd-shipping with In-store Customers", "authors": ["Arash Dehghan", "Mucahit Cevik", "Merve Bodur", "Bissan Ghaddar"], "summary": "This paper examines the use of in-store customers as delivery couriers in a\ncentralized crowd-shipping system, targeting the growing need for efficient\nlast-mile delivery in urban areas. We consider a brick-and-mortar retail\nsetting where shoppers are offered compensation to deliver time-sensitive\nonline orders. To manage this process, we propose a Markov Decision Process\n(MDP) model that captures key uncertainties, including the stochastic arrival\nof orders and crowd-shippers, and the probabilistic acceptance of delivery\noffers. Our solution approach integrates Neural Approximate Dynamic Programming\n(NeurADP) for adaptive order-to-shopper assignment with a Deep Double Q-Network\n(DDQN) for dynamic pricing. This joint optimization strategy enables multi-drop\nrouting and accounts for offer acceptance uncertainty, aligning more closely\nwith real-world operations. Experimental results demonstrate that the\nintegrated NeurADP + DDQN policy achieves notable improvements in delivery cost\nefficiency, with up to 6.7\\% savings over NeurADP with fixed pricing and\napproximately 18\\% over myopic baselines. We also show that allowing flexible\ndelivery delays and enabling multi-destination routing further reduces\noperational costs by 8\\% and 17\\%, respectively. These findings underscore the\nadvantages of dynamic, forward-looking policies in crowd-shipping systems and\noffer practical guidance for urban logistics operators.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01749v1", "categories": ["cs.AI"], "cate": "cs.AI", "url": "http://arxiv.org/abs/2507.01749v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "店内顾客众包配送的联合匹配与定价", "tldr": "本文提出了一种结合神经近似动态规划和深度双Q网络的方法，用于优化店内顾客作为配送员的众包配送系统，实现了显著的成本节约。", "motivation": "针对城市地区最后一公里配送效率日益增长的需求，本文探讨了利用店内顾客作为配送员的集中式众包配送系统。", "method": "提出一个马尔可夫决策过程（MDP）模型来捕捉订单、众包配送员的随机到达以及配送报价的概率接受。解决方案结合了神经近似动态规划（NeurADP）进行自适应订单到顾客的分配，以及深度双Q网络（DDQN）进行动态定价。该联合优化策略实现了多点投递路径规划并考虑了报价接受的不确定性。", "result": "集成NeurADP + DDQN策略在配送成本效率方面取得了显著改善，相较于固定定价的NeurADP节省高达6.7%，相较于短视基线节省约18%。允许灵活的配送延迟和启用多目的地路径规划分别进一步降低了8%和17%的运营成本。", "conclusion": "这些发现强调了众包配送系统中动态、前瞻性策略的优势，并为城市物流运营商提供了实践指导。", "translation": "本文探讨了在集中式众包配送系统中利用店内顾客作为配送员的可行性，旨在解决城市地区日益增长的最后一公里配送效率需求。我们考虑了一种实体零售环境，其中购物者被提供报酬以配送时间敏感的在线订单。为了管理这一过程，我们提出了一个马尔可夫决策过程（MDP）模型，该模型捕捉了关键的不确定性，包括订单和众包配送员的随机到达，以及配送报价的概率接受。我们的解决方案方法整合了神经近似动态规划（NeurADP）用于自适应的订单到购物者分配，以及深度双Q网络（DDQN）用于动态定价。这种联合优化策略实现了多点投递路径规划并考虑了报价接受的不确定性，更符合实际操作。实验结果表明，集成的NeurADP + DDQN策略在配送成本效率方面取得了显著改善，相较于固定定价的NeurADP节省高达6.7%，相较于短视基线节省约18%。我们还表明，允许灵活的配送延迟和启用多目的地路径规划分别进一步降低了8%和17%的运营成本。这些发现强调了众包配送系统中动态、前瞻性策略的优势，并为城市物流运营商提供了实践指导。", "summary": "本文提出了一种创新的众包配送系统，利用店内顾客作为配送员，以提高城市最后一公里配送效率。通过构建一个马尔可夫决策过程模型，并结合神经近似动态规划（NeurADP）进行订单分配和深度双Q网络（DDQN）进行动态定价，实现了联合匹配和定价优化。实验结果表明，该集成策略显著降低了配送成本，并证明了动态、前瞻性策略在众包物流中的优越性。", "keywords": "众包配送, 动态定价, 最后一公里配送, 马尔可夫决策过程, 深度强化学习", "comments": "本文的创新点在于将店内顾客作为众包配送员，并提出了结合NeurADP和DDQN的联合优化策略，有效解决了匹配和定价的动态问题，同时考虑了多点投递和接受不确定性，为城市物流提供了新的思路和显著的成本节约潜力。"}}
{"id": "2507.01635", "title": "EGNInfoLeaker: Unveiling the Risks of Public Key Reuse and User Identity Leakage in Blockchain", "authors": ["Chenyu Li", "Xueping Liang", "Xiaorui Gong", "Xiu Zhang"], "summary": "While Ethereum's discovery protocols (Discv4/ Discv5) incorporate robust\ncryptographic designs to protect user privacy, real-world deployment reveals\ncritical vulnerabilities when users deviate from security guidelines. In this\npaper, we design a system called EGNInfoLeaker. Our study is the first work\nthat uncovers widespread public key reuse across Ethereum's peer-to-peer\nnetworks - a practice that fundamentally undermines the protocol's privacy\nguarantees. Through systematic analysis of 300 real-world network snapshots, we\nidentify 83 users controlling 483 service nodes via public key reuse, enabling\nprecise de-anonymization through IP correlation. Using evidence collected by\nEGNInfoLeaker, our Graph-Based Identity Association Algorithm links users to\nnetwork entities and generates comprehensive user profiles. For User27, it\nexposes the public key, IP, network ID, location (country/region/city), and\nISP/ORG details. The EGNInfoLeaker system demonstrates how such cryptographic\nmisuse transforms theoretical anonymity into practical identity leakage,\nexposing users to surveillance and targeted attacks. These findings establish\nthat protocol security depends not only on sound design but also on strict user\ncompliance. Going forward, our detection framework provides a foundation for\nenhancing real-world privacy preservation in decentralized networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01635v1", "categories": ["cs.CR"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01635v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "EGNInfoLeaker：揭示区块链中公钥重用和用户身份泄露的风险", "tldr": "本文介绍了EGNInfoLeaker系统，揭示了以太坊P2P网络中普遍存在的公钥重用问题，该问题导致用户身份泄露，并强调协议安全性不仅依赖于设计，还依赖于用户遵守。", "motivation": "尽管以太坊的发现协议（Discv4/Discv5）采用了强大的加密设计来保护用户隐私，但实际部署中发现，当用户偏离安全准则时，会暴露出严重漏洞。本文旨在揭示公钥重用导致的身份泄露风险。", "method": "研究设计了一个名为EGNInfoLeaker的系统。通过对300个真实网络快照的系统分析，识别了通过公钥重用控制服务节点的行为。然后，使用EGNInfoLeaker收集的证据，通过基于图的身份关联算法将用户与网络实体关联，并生成用户资料。", "result": "研究首次揭示了以太坊点对点网络中普遍存在的公钥重用现象，这从根本上破坏了协议的隐私保障。通过分析，识别出83名用户通过公钥重用控制了483个服务节点，并通过IP关联实现了精确的去匿名化。例如，对于User27，系统暴露了其公钥、IP、网络ID、位置（国家/地区/城市）以及ISP/ORG详细信息。", "conclusion": "研究结果表明，协议安全性不仅取决于健全的设计，还取决于严格的用户遵守。EGNInfoLeaker系统证明了加密滥用如何将理论匿名性转化为实际的身份泄露，使用户面临监控和定向攻击的风险。该检测框架为增强去中心化网络中的实际隐私保护提供了基础。", "translation": "尽管以太坊的发现协议（Discv4/ Discv5）采用了强大的加密设计来保护用户隐私，但实际部署中发现，当用户偏离安全准则时，会暴露出严重漏洞。在本文中，我们设计了一个名为EGNInfoLeaker的系统。我们的研究是首次揭示以太坊点对点网络中普遍存在的公钥重用现象的工作——这种做法从根本上破坏了协议的隐私保障。通过对300个真实网络快照的系统分析，我们识别出83名用户通过公钥重用控制了483个服务节点，从而通过IP关联实现了精确的去匿名化。使用EGNInfoLeaker收集的证据，我们的基于图的身份关联算法将用户与网络实体关联起来，并生成全面的用户资料。对于User27，它暴露了其公钥、IP、网络ID、位置（国家/地区/城市）以及ISP/ORG详细信息。EGNInfoLeaker系统展示了这种加密滥用如何将理论匿名性转化为实际的身份泄露，使用户面临监控和定向攻击的风险。这些发现确立了协议安全性不仅取决于健全的设计，还取决于严格的用户遵守。展望未来，我们的检测框架为增强去中心化网络中的实际隐私保护提供了基础。", "summary": "本文介绍了EGNInfoLeaker系统，旨在揭示以太坊P2P网络中因用户偏离安全准则而导致的公钥重用及用户身份泄露风险。通过对300个网络快照的分析，研究发现普遍存在的公钥重用，识别出83名用户通过此方式控制483个节点，并通过IP关联实现精确去匿名化。EGNInfoLeaker利用图基身份关联算法，能详细揭露用户身份信息。研究强调协议安全不仅依赖于设计，更依赖于用户合规，并提出了用于隐私保护的检测框架。", "keywords": "区块链, 公钥重用, 身份泄露, 以太坊, 隐私保护", "comments": "该研究具有重要的现实意义，因为它揭示了即使在设计上安全的协议，也可能因用户行为不当而产生严重漏洞。EGNInfoLeaker系统提供了一种新颖的方法来识别和量化区块链网络中的身份泄露风险，其发现对于未来去中心化网络的隐私保护和用户教育具有指导作用。"}}
{"id": "2507.01690", "title": "Designing for Community Care: Reimagining Support for Equity & Well-being in Academia", "authors": ["Beatriz Severes", "Ana O. Henriques", "Rory Clark", "Paulo Bala", "Anna Carter", "Rua Mae Williams", "Geraldine Fitzpatrick"], "summary": "Academic well-being is deeply influenced by peer-support networks, yet they\nremain informal, inequitable, and unsustainable, often relying on personal\nconnections and social capital rather than structured, inclusive systems.\nAdditionally, institutional well-being responses frequently focus on student\npopulations, neglecting the emotional labour of faculty and staff, reinforcing\nan exclusionary academic culture. Drawing on HCI methodologies, participatory\ndesign, and care ethics, this workshop will provide a space for rethinking how\nacademic communities can support inclusive networks. Through pre-workshop\nengagement, co-design activities, and reflection, participants will examine\nsystemic gaps in networks and explore ways to embed care, equity, and\nsustainability into academic peer-support frameworks -- from informal,\nexclusionary models to structured, inclusive care-based ecosystems. At the end\nof the workshop, participants will co-develop design strategies for integrating\ncare and resilience in academic ecosystems, resources for designing equitable\nsupport systems, and a peer network invested and committed to fostering a\nsupportive academic community.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01690v1", "categories": ["cs.HC"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01690v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "为社区关怀而设计：重塑学术界公平与福祉的支持", "tldr": "本研讨会旨在通过参与式设计，将学术界非正式、不公平的同伴支持网络转变为结构化、包容性的关怀生态系统，以提升教职员工的福祉和公平性。", "motivation": "学术福祉深受同伴支持网络影响，但现有网络非正式、不公平且不可持续，常依赖个人关系而非结构化系统。此外，机构的福祉响应常忽视教职员工的情感劳动，强化了排他性学术文化。", "method": "本研讨会运用人机交互（HCI）方法、参与式设计和关怀伦理。通过研讨会前参与、共同设计活动和反思，参与者将审视现有网络中的系统性缺陷，并探索如何将关怀、公平和可持续性融入学术同伴支持框架。", "result": "研讨会结束时，参与者将共同开发将关怀和韧性融入学术生态系统的设计策略、设计公平支持系统的资源，以及一个致力于促进支持性学术社区的同伴网络。", "conclusion": "本研讨会旨在通过共同设计，将学术界的同伴支持从非正式、排他性模式转变为结构化、包容性的关怀型生态系统，从而提升学术社区的福祉和公平性。", "translation": "学术福祉深受同伴支持网络影响，然而这些网络仍是非正式、不公平且不可持续的，通常依赖个人联系和社会资本，而非结构化、包容的系统。此外，机构的福祉响应常常侧重于学生群体，忽视了教职员工的情感劳动，从而强化了一种排他性的学术文化。本次研讨会将借鉴人机交互（HCI）方法、参与式设计和关怀伦理，提供一个重新思考学术社区如何支持包容性网络的空间。通过研讨会前参与、共同设计活动和反思，参与者将审视网络中的系统性缺陷，并探索如何将关怀、公平和可持续性嵌入学术同伴支持框架——从非正式、排他性模式转向结构化、包容性的关怀型生态系统。研讨会结束时，参与者将共同开发将关怀和韧性融入学术生态系统的设计策略、设计公平支持系统的资源，以及一个致力于促进支持性学术社区的同伴网络。", "summary": "本研讨会旨在解决学术界同伴支持网络非正式、不公平且不可持续的问题，以及机构福祉响应忽视教职员工的现状。研讨会将运用人机交互、参与式设计和关怀伦理，通过一系列共同设计活动，引导参与者探索如何将关怀、公平和可持续性融入学术支持框架。最终目标是共同开发设计策略、资源和一个致力于构建公平和包容性学术社区的同伴网络。", "keywords": "社区关怀, 学术福祉, 同伴支持, 参与式设计, 关怀伦理", "comments": "本论文（研讨会）的创新点在于将HCI方法、参与式设计和关怀伦理结合，以系统性地解决学术界同伴支持的公平性和可持续性问题。其重要性在于关注了常被忽视的教职员工福祉，并试图通过共同创建的方式，将非正式支持模式转变为更具结构性和包容性的关怀生态系统，对改善学术文化具有积极意义。其局限性在于，作为一个研讨会，其产出主要是设计策略和资源，具体的实施和效果验证尚待后续研究。"}}
{"id": "2507.01037", "title": "Learning to Segment for Vehicle Routing Problems", "authors": ["Wenbin Ouyang", "Sirui Li", "Yining Ma", "Cathy Wu"], "summary": "Iterative search heuristics are widely recognized as state-of-the-art for\nsolving Vehicle Routing Problems (VRPs). In this work, we identify and exploit\na critical observation: within these solvers, a large portion of the solution\nremains stable, i.e., unchanged across search iterations, causing redundant\ncomputations, especially for large-scale VRPs with long subtours. To address\nthis, we pioneer the formal study of the First-Segment-Then-Aggregate (FSTA)\ndecomposition technique to accelerate iterative solvers. Specifically, FSTA\npreserves stable solution segments during the search, aggregates nodes within\neach segment into fixed hypernodes, and focuses the search only on unstable\nportions. Yet, a key challenge lies in identifying which segments should be\naggregated by FSTA. To this end, we then introduce Learning-to-Segment (L2Seg),\na novel neural framework to intelligently differentiate potentially stable and\nunstable portions for FSTA decomposition. We present three L2Seg variants:\nnon-autoregressive (globally comprehensive but locally indiscriminate),\nautoregressive (locally refined but globally deficient), and their synergy,\nwith bespoke training and inference strategies. Empirical results on CVRP and\nVRPTW suggest that L2Seg accelerates state-of-the-art iterative solvers by up\nto 7x. Additionally, we provide in-depth analysis showing NAR and AR synergy\nachieves best performance by combining their complementary strengths. Notably,\nL2Seg is a flexible framework that is compatible with traditional,\nlearning-based, and hybrid solvers, while supporting a broad class of VRPs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01037v1", "categories": ["cs.LG", "cs.AI", "cs.RO"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01037v1", "date": "2025-06-22", "updated": "2025-06-22", "AI": {"title_translation": "学习分割用于车辆路径问题", "tldr": "本文提出了L2Seg，一个神经网络框架，用于加速车辆路径问题(VRPs)的迭代求解器，通过识别和聚合稳定的解决方案片段，将求解器加速了高达7倍。", "motivation": "在解决车辆路径问题（VRPs）的迭代搜索启发式算法中，解决方案的很大一部分在搜索迭代中保持稳定不变，导致冗余计算，尤其对于具有长子路径的大规模VRPs。", "method": "本文提出了First-Segment-Then-Aggregate (FSTA) 分解技术来加速迭代求解器，该技术在搜索过程中保留稳定的解决方案片段，将每个片段中的节点聚合成固定的超节点，并将搜索重点放在不稳定部分。为了识别应聚合的片段，本文引入了Learning-to-Segment (L2Seg)，一个新颖的神经网络框架，用于智能区分潜在的稳定和不稳定部分。L2Seg有三种变体：非自回归（全局全面但局部不分明）、自回归（局部精细但全局不足）以及它们的协同作用，并采用定制的训练和推理策略。", "result": "L2Seg在CVRP和VRPTW上的实证结果表明，它将最先进的迭代求解器加速了高达7倍。此外，深入分析表明，非自回归和自回归的协同作用通过结合它们的互补优势实现了最佳性能。", "conclusion": "L2Seg是一个灵活的框架，兼容传统、基于学习和混合求解器，并支持广泛的VRPs。", "translation": "迭代搜索启发式算法被广泛认为是解决车辆路径问题（VRPs）的最先进方法。在这项工作中，我们识别并利用了一个关键观察：在这些求解器中，解决方案的很大一部分保持稳定，即在搜索迭代中保持不变，导致冗余计算，特别是对于具有长子路径的大规模VRPs。为了解决这个问题，我们开创性地对First-Segment-Then-Aggregate (FSTA) 分解技术进行了形式化研究，以加速迭代求解器。具体来说，FSTA在搜索过程中保留稳定的解决方案片段，将每个片段中的节点聚合成固定的超节点，并将搜索重点仅放在不稳定部分。然而，一个关键挑战在于识别哪些片段应该被FSTA聚合。为此，我们引入了Learning-to-Segment (L2Seg)，一个新颖的神经网络框架，用于智能区分FSTA分解中潜在的稳定和不稳定部分。我们提出了三种L2Seg变体：非自回归（全局全面但局部不分明）、自回归（局部精细但全局不足）以及它们的协同作用，并采用定制的训练和推理策略。CVRP和VRPTW上的实证结果表明，L2Seg将最先进的迭代求解器加速了高达7倍。此外，我们提供了深入分析，表明非自回归和自回归的协同作用通过结合它们的互补优势实现了最佳性能。值得注意的是，L2Seg是一个灵活的框架，兼容传统、基于学习和混合求解器，同时支持广泛的VRPs。", "summary": "本文针对车辆路径问题（VRPs）中迭代求解器存在的冗余计算问题，提出了First-Segment-Then-Aggregate (FSTA) 分解技术，以通过保留和聚合稳定的解决方案片段来加速求解器。为智能识别稳定与不稳定片段，研究引入了基于神经网络的Learning-to-Segment (L2Seg) 框架，包含非自回归、自回归及其协同三种变体。实验证明L2Seg能将现有最先进的迭代求解器加速高达7倍，且其非自回归与自回归的协同作用表现最佳。L2Seg具有良好的灵活性和兼容性。", "keywords": "车辆路径问题, 迭代搜索, 分解技术, 机器学习, 求解器加速", "comments": "本文的创新点在于提出了FSTA分解技术和L2Seg神经网络框架，用于在VRP迭代求解过程中智能识别并利用稳定的解决方案片段，从而显著减少冗余计算，实现求解器加速。这种将机器学习与组合优化相结合的方法，为解决大规模VRPs提供了一条新颖且高效的途径，具有重要的实践意义和研究价值。"}}
{"id": "2507.01771", "title": "Higher-Order Tensor-Based Deferral of Gaussian Splitting for Orbit Uncertainty Propagation", "authors": ["G. Andrew Siciliano", "Keith A. LeGrand", "Jackson Kulik"], "summary": "Accurate propagation of orbital uncertainty is essential for a range of\napplications within space domain awareness. Adaptive Gaussian mixture-based\napproaches offer tractable nonlinear uncertainty propagation through splitting\nmixands to increase resolution in areas of stronger nonlinearities, as well as\nby reducing mixands to prevent unnecessary computational effort. Recent work\nintroduced principled heuristics that incorporate information from the system\ndynamics and initial uncertainty to determine optimal directions for splitting.\nThis paper develops adaptive uncertainty propagation methods based on these\nrobust splitting techniques. A deferred splitting algorithm tightly integrated\nwith higher-order splitting techniques is proposed and shown to offer\nsubstantial gains in computational efficiency without sacrificing accuracy.\nSecond-order propagation of mixand moments is also seen to improve accuracy\nwhile retaining significant computational savings from deferred splitting.\nDifferent immediate and deferred splitting methods are compared in three\nrepresentative test cases, including a geostationary orbit, a Molniya orbit,\nand a periodic three-body orbit.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01771v1", "categories": ["eess.SP", "math.PR"], "cate": "eess.SP", "url": "http://arxiv.org/abs/2507.01771v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于高阶张量的轨道不确定性传播高斯分裂延迟", "tldr": "本文提出了一种结合高阶分裂技术的延迟分裂算法，用于轨道不确定性传播，能在不牺牲精度的情况下显著提高计算效率。", "motivation": "在空间态势感知中，准确传播轨道不确定性至关重要。现有的自适应高斯混合方法通过分裂混合成分来增加分辨率，并通过减少混合成分来防止不必要的计算，但仍有改进空间以提高效率和精度。", "method": "本文提出了一种与高阶分裂技术紧密结合的延迟分裂算法，用于自适应不确定性传播。同时，还采用了混合成分矩的二阶传播，以提高精度并保持计算效率。该方法与不同的即时和延迟分裂方法在三种代表性测试案例中进行了比较。", "result": "研究表明，所提出的延迟分裂算法在不牺牲精度的情况下，能显著提高计算效率。此外，混合成分矩的二阶传播也被证明可以提高精度，同时仍能从延迟分裂中获得显著的计算节省。", "conclusion": "通过结合高阶分裂技术和延迟分裂算法，以及采用混合成分矩的二阶传播，可以实现轨道不确定性传播的计算效率和精度的显著提升。", "translation": "轨道不确定性的精确传播对于空间领域意识中的一系列应用至关重要。基于自适应高斯混合的方法通过分裂混合成分来增加非线性更强区域的分辨率，并通过减少混合成分来防止不必要的计算工作，从而实现易于处理的非线性不确定性传播。最近的工作引入了原则性的启发式方法，该方法结合了系统动力学和初始不确定性信息来确定最佳分裂方向。本文开发了基于这些鲁棒分裂技术的自适应不确定性传播方法。提出了一种与高阶分裂技术紧密结合的延迟分裂算法，并证明其在不牺牲精度的情况下能显著提高计算效率。混合成分矩的二阶传播也被认为可以提高精度，同时保留了延迟分裂带来的显著计算节省。在三个代表性测试案例中比较了不同的即时和延迟分裂方法，包括地球静止轨道、莫尔尼亚轨道和周期性三体轨道。", "summary": "本文提出了一种基于高阶张量的延迟高斯分裂算法，用于轨道不确定性传播。该方法通过结合高阶分裂技术和延迟分裂策略，旨在提高计算效率同时保持精度。研究还探讨了混合成分矩的二阶传播对精度的影响。实验结果表明，该算法在不牺牲精度的情况下显著提高了计算效率，并且二阶传播进一步提升了精度。该方法在多种轨道类型（包括地球静止轨道、莫尔尼亚和周期性三体轨道）上进行了验证。", "keywords": "轨道不确定性传播, 高斯分裂, 延迟分裂, 高阶张量, 计算效率", "comments": "该论文在轨道不确定性传播领域提出了一种创新性的方法，通过引入延迟分裂和高阶张量技术，有效地解决了计算效率与精度之间的权衡问题。其将系统动力学和初始不确定性信息整合到分裂决策中的策略，显示出对现有自适应高斯混合方法的显著改进。在空间态势感知等关键应用中，这种效率和精度的提升具有重要意义。"}}
{"id": "2507.01783", "title": "ASTARS empowered Satellite Positioning Approach for Urban Canyons and Indoor Environments", "authors": ["Yu Zhang", "Xin Sun", "Tianwei Hou", "Anna Li", "Sofie Pollin", "Yuanwei Liu", "Arumugam Nallanathan"], "summary": "To mitigate the loss of satellite navigation signals in urban canyons and\nindoor environments, we propose an active simultaneous transmitting and\nreflecting reconfigurable intelligent surface (ASTARS) empowered satellite\npositioning approach. Deployed on building structures, ASTARS reflects\nnavigation signals to outdoor receivers in urban canyons and transmits signals\nindoors to bypass obstructions, providing high-precision positioning services\nto receivers in non-line-of-sight (NLoS) areas. The path between ASTARS and the\nreceiver is defined as the extended line-of-sight (ELoS) path and an improved\ncarrier phase observation equation is derived to accommodate that. The receiver\ncompensates for its clock bias through network time synchronization, corrects\nthe actual signal path distance to the satellite-to-receiver distance through a\ndistance correction algorithm, and determines its position by using the least\nsquares (LS) method. Mathematical modeling of the errors introduced by the\nproposed method is conducted, followed by simulation analysis to assess their\nimpact. Simulation results show that: 1) in areas where GNSS signals are\nblocked, with time synchronization accuracy within a 10 ns error range, the\nproposed method provides positioning services with errors not exceeding 4 m for\nboth indoor and outdoor receivers, outperforming conventional NLoS methods with\npositioning errors of more than 7 m; 2) the additional errors introduced by the\nproposed method do not exceed 3 m for time synchronization errors within 10 ns,\nwhich includes the phase shift, beamwidth error, time synchronization errors,\nand satellite distribution errors, outperforming traditional NLoS methods,\nwhich typically produce positioning errors greater than 5 m.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01783v1", "categories": ["cs.IT", "math.IT"], "cate": "cs.IT", "url": "http://arxiv.org/abs/2507.01783v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "ASTARS 赋能的城市峡谷和室内环境卫星定位方法", "tldr": "该论文提出了一种基于ASTARS的卫星定位方法，可在城市峡谷和室内环境中提供高精度定位服务，优于传统NLoS方法。", "motivation": "为解决城市峡谷和室内环境中卫星导航信号丢失的问题，传统方法在非视距（NLoS）区域定位精度低。", "method": "提出一种主动式同步收发可重构智能表面（ASTARS）赋能的卫星定位方法。ASTARS部署在建筑物上，将导航信号反射到城市峡谷的室外接收器，并传输信号到室内以绕过障碍物。定义ASTARS与接收器之间的路径为扩展视距（ELoS）路径，并推导出改进的载波相位观测方程。接收器通过网络时间同步补偿时钟偏差，通过距离校正算法校正实际信号路径距离，并使用最小二乘法（LS）确定位置。对所提方法引入的误差进行数学建模和仿真分析。", "result": "仿真结果表明：1) 在GNSS信号受阻区域，10 ns时间同步误差范围内，该方法对室内外接收器的定位误差不超过4米，优于传统NLoS方法（误差大于7米）；2) 所提方法引入的额外误差（包括相移、波束宽度误差、时间同步误差和卫星分布误差）在10 ns时间同步误差范围内不超过3米，优于传统NLoS方法（误差通常大于5米）。", "conclusion": "所提出的ASTARS赋能的卫星定位方法在城市峡谷和室内环境中能够提供更优越的定位服务，显著提高了非视距区域的定位精度，优于传统NLoS方法。", "translation": "为了缓解城市峡谷和室内环境中卫星导航信号的丢失问题，我们提出了一种主动式同步收发可重构智能表面（ASTARS）赋能的卫星定位方法。ASTARS部署在建筑物结构上，将导航信号反射到城市峡谷中的室外接收器，并向室内传输信号以绕过障碍物，为非视距（NLoS）区域的接收器提供高精度定位服务。ASTARS与接收器之间的路径被定义为扩展视距（ELoS）路径，并推导出了改进的载波相位观测方程以适应这种情况。接收器通过网络时间同步补偿其时钟偏差，通过距离校正算法将实际信号路径距离校正为卫星到接收器的距离，并使用最小二乘（LS）方法确定其位置。对所提出方法引入的误差进行了数学建模，随后进行了仿真分析以评估其影响。仿真结果表明：1）在GNSS信号被阻挡的区域，在10纳秒误差范围内的时间同步精度下，所提出的方法为室内和室外接收器提供的定位服务误差不超过4米，优于传统NLoS方法（定位误差超过7米）；2）所提出的方法引入的额外误差（包括相移、波束宽度误差、时间同步误差和卫星分布误差）在10纳秒时间同步误差范围内不超过3米，优于传统NLoS方法（通常产生大于5米的定位误差）。", "summary": "本论文提出了一种创新的ASTARS赋能卫星定位方法，旨在解决城市峡谷和室内环境中的信号丢失问题。通过部署ASTARS反射或传输导航信号，为NLoS区域提供高精度定位。该方法定义了ELoS路径并推导了新的观测方程，结合时间同步、距离校正和最小二乘法进行定位。仿真结果表明，在GNSS信号受阻区域，该方法在10 ns时间同步误差下能将定位误差控制在4米以内，且引入的额外误差不超过3米，显著优于传统NLoS方法。", "keywords": "ASTARS, 卫星定位, 城市峡谷, 室内定位, 非视距", "comments": "该论文的创新点在于引入了主动式同步收发可重构智能表面（ASTARS）来解决城市峡谷和室内环境中卫星信号受阻的难题。通过将ASTARS作为中继，实现了信号的反射和传输，有效扩展了卫星定位服务的覆盖范围和精度。其提出的ELoS路径和改进的观测方程具有理论价值。仿真结果显示出该方法在精度上的显著提升，表明其在未来城市定位应用中具有重要潜力。"}}
{"id": "2507.01075", "title": "Provenance Tracking in Large-Scale Machine Learning Systems", "authors": ["Gabriele Padovani", "Valentine Anantharaj", "Sandro Fiore"], "summary": "As the demand for large scale AI models continues to grow, the optimization\nof their training to balance computational efficiency, execution time, accuracy\nand energy consumption represents a critical multidimensional challenge.\nAchieving this balance requires not only innovative algorithmic techniques and\nhardware architectures but also comprehensive tools for monitoring, analyzing,\nand understanding the underlying processes involved in model training and\ndeployment. Provenance data information about the origins, context, and\ntransformations of data and processes has become a key component in this\npursuit. By leveraging provenance, researchers and engineers can gain insights\ninto resource usage patterns, identify inefficiencies, and ensure\nreproducibility and accountability in AI development workflows. For this\nreason, the question of how distributed resources can be optimally utilized to\nscale large AI models in an energy efficient manner is a fundamental one. To\nsupport this effort, we introduce the yProv4ML library, a tool designed to\ncollect provenance data in JSON format, compliant with the W3C PROV and ProvML\nstandards. yProv4ML focuses on flexibility and extensibility, and enables users\nto integrate additional data collection tools via plugins. The library is fully\nintegrated with the yProv framework, allowing for higher level pairing in tasks\nrun also through workflow management systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01075v1", "categories": ["cs.LG", "cs.DC"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01075v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "大规模机器学习系统中的溯源跟踪", "tldr": "介绍yProv4ML库，一个用于在大规模AI模型训练中收集溯源数据的工具，以提高效率、可重现性和可解释性。", "motivation": "随着对大规模AI模型需求的持续增长，优化其训练以平衡计算效率、执行时间、准确性和能耗是一个关键的多维挑战。实现这种平衡需要全面的工具来监控、分析和理解模型训练和部署中的底层过程。溯源数据对于洞察资源使用模式、识别低效以及确保AI开发工作流的可重现性和可问责性至关重要。", "method": "引入了yProv4ML库，这是一个旨在以JSON格式收集溯源数据的工具，符合W3C PROV和ProvML标准。yProv4ML专注于灵活性和可扩展性，并允许用户通过插件集成额外的数据收集工具，且与yProv框架完全集成。", "result": "yProv4ML库能够收集溯源数据，从而支持研究人员和工程师深入了解资源使用模式，识别低效率，并确保AI开发工作流的可重现性和可问责性。", "conclusion": "通过引入yProv4ML库，该研究旨在支持大规模AI模型在能源效率方面的优化利用，并提高AI开发的可追溯性、可解释性和效率。", "translation": "随着对大规模AI模型需求的持续增长，优化其训练以平衡计算效率、执行时间、准确性和能耗，代表着一个关键的多维挑战。实现这种平衡不仅需要创新的算法技术和硬件架构，还需要全面的工具来监控、分析和理解模型训练和部署中涉及的底层过程。溯源数据——关于数据和过程的起源、上下文和转换的信息——已成为实现这一目标的关键组成部分。通过利用溯源，研究人员和工程师可以深入了解资源使用模式，识别低效率，并确保AI开发工作流的可重现性和可问责性。因此，如何以节能方式优化利用分布式资源来扩展大型AI模型是一个根本性问题。为了支持这项工作，我们引入了yProv4ML库，这是一个旨在以JSON格式收集溯源数据的工具，符合W3C PROV和ProvML标准。yProv4ML专注于灵活性和可扩展性，并允许用户通过插件集成额外的数据收集工具。该库与yProv框架完全集成，从而可以在通过工作流管理系统运行的任务中实现更高级别的配对。", "summary": "该论文介绍了yProv4ML库，一个用于大规模机器学习系统中收集和管理溯源数据的工具。面对AI模型训练中计算效率、执行时间、准确性和能耗的平衡挑战，yProv4ML通过提供符合W3C PROV和ProvML标准的溯源数据收集功能，帮助研究人员和工程师深入了解资源使用、识别低效并确保AI开发工作流的可重现性和可问责性。该库具有灵活性和可扩展性，并可与现有工作流管理系统集成。", "keywords": "溯源跟踪, 机器学习系统, 大规模AI, yProv4ML, 数据管理", "comments": "该论文的创新点在于提出了一个专门为大规模机器学习系统设计的溯源数据收集工具，并强调了其符合行业标准（W3C PROV和ProvML）、灵活性和可扩展性。其重要性体现在解决了当前AI模型开发中日益复杂的优化、可解释性、可重现性和可问责性挑战，为提高大型AI系统效率和可靠性提供了关键支持。"}}
{"id": "2507.01483", "title": "Epistemic Scarcity: The Economics of Unresolvable Unknowns", "authors": ["Craig S Wright"], "summary": "This paper presents a praxeological analysis of artificial intelligence and\nalgorithmic governance, challenging assumptions about the capacity of machine\nsystems to sustain economic and epistemic order. Drawing on Misesian a priori\nreasoning and Austrian theories of entrepreneurship, we argue that AI systems\nare incapable of performing the core functions of economic coordination:\ninterpreting ends, discovering means, and communicating subjective value\nthrough prices. Where neoclassical and behavioural models treat decisions as\noptimisation under constraint, we frame them as purposive actions under\nuncertainty.\n  We critique dominant ethical AI frameworks such as Fairness, Accountability,\nand Transparency (FAT) as extensions of constructivist rationalism, which\nconflict with a liberal order grounded in voluntary action and property rights.\nAttempts to encode moral reasoning in algorithms reflect a misunderstanding of\nethics and economics. However complex, AI systems cannot originate norms,\ninterpret institutions, or bear responsibility. They remain opaque, misaligned,\nand inert.\n  Using the concept of epistemic scarcity, we explore how information abundance\ndegrades truth discernment, enabling both entrepreneurial insight and soft\ntotalitarianism. Our analysis ends with a civilisational claim: the debate over\nAI concerns the future of human autonomy, institutional evolution, and reasoned\nchoice. The Austrian tradition, focused on action, subjectivity, and\nspontaneous order, offers the only coherent alternative to rising computational\nsocial control.", "comment": "47 pages - submission to QJAE", "pdf_url": "http://arxiv.org/pdf/2507.01483v1", "categories": ["econ.GN", "cs.AI", "cs.CY", "physics.hist-ph", "q-fin.EC", "91B42, 91B40, 68T01", "J.4; I.2.1; K.4.1; K.4.2"], "cate": "econ.GN", "url": "http://arxiv.org/abs/2507.01483v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "认知稀缺性：不可解未知数的经济学", "tldr": "本文运用奥地利经济学派的方法，挑战了人工智能在维持经济和认知秩序方面的能力，认为AI系统无法执行核心经济协调功能或制定道德规范，并批判了主流的伦理AI框架。它强调了AI的局限性，并提出AI辩论关乎人类自主权的未来。", "motivation": "挑战关于机器系统维持经济和认知秩序能力的假设，并批判主导的伦理AI框架（如FAT）。", "method": "本文采用实践学分析方法，借鉴米塞斯先验推理和奥地利学派的企业家理论。它将决策视为不确定性下的目的性行动，而非约束下的优化。", "result": "人工智能系统无法执行经济协调的核心功能，包括解释目的、发现手段和通过价格传递主观价值。主流的伦理AI框架被批判为建构主义理性主义的延伸，与自由秩序相冲突。试图将道德推理编码到算法中反映了对伦理和经济学的误解。AI系统不能产生规范、解释制度或承担责任，它们是不透明、不协调和惰性的。信息丰富会降低真相辨别能力，同时催生企业家洞察力和软极权主义（认知稀缺）。", "conclusion": "关于人工智能的辩论关乎人类自主权、制度演变和理性选择的未来。奥地利传统提供了一种连贯的替代方案，以应对日益增长的计算社会控制。", "translation": "本文对人工智能和算法治理进行了实践学分析，挑战了机器系统维持经济和认知秩序能力方面的假设。借鉴米塞斯先验推理和奥地利学派的企业家理论，我们认为AI系统无法执行经济协调的核心功能：解释目的、发现手段以及通过价格传递主观价值。新古典主义和行为模型将决策视为约束下的优化，而我们将其视为不确定性下的目的性行动。\n我们批判了主流的伦理AI框架，如公平、问责和透明（FAT），认为它们是建构主义理性主义的延伸，与基于自愿行动和财产权的自由秩序相冲突。试图将道德推理编码到算法中反映了对伦理和经济学的误解。无论多么复杂，AI系统都不能产生规范、解释制度或承担责任。它们仍然是不透明、不协调和惰性的。\n利用认知稀缺性概念，我们探讨了信息丰富如何降低真相辨别能力，同时催生企业家洞察力和软极权主义。我们的分析以一个文明层面的主张结束：关于AI的辩论关乎人类自主权、制度演变和理性选择的未来。奥地利传统，专注于行动、主观性和自发秩序，是应对日益增长的计算社会控制的唯一连贯替代方案。", "summary": "本文基于实践学分析，并借鉴奥地利经济学派理论，深入探讨了人工智能和算法治理的局限性。作者指出，AI系统无法执行核心经济协调功能（如解释目的、发现手段和传递主观价值），并批判了主流的伦理AI框架（FAT）与自由秩序的冲突。论文引入“认知稀缺性”概念，揭示信息过剩如何影响真相辨别，强调AI无法产生规范或承担责任。最终，文章将AI的未来与人类自主权和制度演变联系起来，认为奥地利传统为应对计算社会控制提供了独特视角。", "keywords": "认知稀缺性, 人工智能, 奥地利经济学, 算法治理, 人类自主权", "comments": "本文的创新之处在于将奥地利经济学派的实践学分析应用于人工智能和算法治理领域，提供了一个不同于主流优化或技术中心视角的批判性框架。它深刻揭示了AI在处理主观价值、企业家精神和道德生成方面的内在局限性，强调了技术进步与人类自主权及自由秩序之间的潜在冲突。其重要性在于促使人们重新思考AI在社会经济系统中的角色，超越纯粹的技术能力，关注其对人类行动、伦理和制度的深远影响。"}}
{"id": "2507.01588", "title": "Enhancing Multi-Exposure High Dynamic Range Imaging with Overlapped Codebook for Improved Representation Learning", "authors": ["Keuntek Lee", "Jaehyun Park", "Nam Ik Cho"], "summary": "High dynamic range (HDR) imaging technique aims to create realistic HDR\nimages from low dynamic range (LDR) inputs. Specifically, Multi-exposure HDR\nimaging uses multiple LDR frames taken from the same scene to improve\nreconstruction performance. However, there are often discrepancies in motion\namong the frames, and different exposure settings for each capture can lead to\nsaturated regions. In this work, we first propose an Overlapped codebook (OLC)\nscheme, which can improve the capability of the VQGAN framework for learning\nimplicit HDR representations by modeling the common exposure bracket process in\nthe shared codebook structure. Further, we develop a new HDR network that\nutilizes HDR representations obtained from a pre-trained VQ network and OLC.\nThis allows us to compensate for saturated regions and enhance overall visual\nquality. We have tested our approach extensively on various datasets and have\ndemonstrated that it outperforms previous methods both qualitatively and\nquantitatively", "comment": "Accepted to International Conference on Pattern Recognition.\n  Springer, Cham, 2025 (ICPR 2024)", "pdf_url": "http://arxiv.org/pdf/2507.01588v1", "categories": ["eess.IV"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01588v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "使用重叠码本增强多曝光高动态范围成像以改进表示学习", "tldr": "本文提出了一种重叠码本（OLC）方案和新的HDR网络，以解决多曝光HDR成像中的运动差异和饱和区域问题，从而提高重建性能和视觉质量。", "motivation": "多曝光高动态范围（HDR）成像技术在从低动态范围（LDR）输入创建真实HDR图像时，常面临帧间运动差异和不同曝光设置导致的饱和区域问题。", "method": "提出了一种重叠码本（OLC）方案，该方案通过在共享码本结构中建模常见的曝光包围过程，提高了VQGAN框架学习隐式HDR表示的能力。进一步开发了一个新的HDR网络，利用从预训练VQ网络和OLC获得的HDR表示，以补偿饱和区域并增强整体视觉质量。", "result": "该方法在各种数据集上进行了广泛测试，并证明其在定性和定量上均优于以前的方法。", "conclusion": "通过引入重叠码本方案和新的HDR网络，可以有效解决多曝光HDR成像中的挑战，显著提高图像重建性能和视觉质量。", "translation": "高动态范围（HDR）成像技术旨在从低动态范围（LDR）输入创建逼真的HDR图像。具体来说，多曝光HDR成像使用从同一场景拍摄的多个LDR帧来提高重建性能。然而，帧之间通常存在运动差异，并且每次捕获的不同曝光设置可能导致饱和区域。在这项工作中，我们首先提出了一种重叠码本（OLC）方案，该方案通过在共享码本结构中建模常见的曝光包围过程，可以提高VQGAN框架学习隐式HDR表示的能力。此外，我们开发了一个新的HDR网络，该网络利用从预训练VQ网络和OLC获得的HDR表示。这使我们能够补偿饱和区域并增强整体视觉质量。我们已在各种数据集上广泛测试了我们的方法，并证明其在定性和定量上均优于以前的方法。", "summary": "本文针对多曝光HDR成像中存在的帧间运动差异和饱和区域问题，提出了一种重叠码本（OLC）方案，该方案增强了VQGAN框架学习隐式HDR表示的能力。在此基础上，开发了一个新的HDR网络，利用OLC获得的HDR表示来补偿饱和区域并提升视觉质量。实验证明，该方法在多个数据集上均优于现有技术。", "keywords": "HDR成像, 多曝光, 重叠码本, 表示学习, VQGAN", "comments": "该论文的创新点在于提出了重叠码本（OLC）方案，并将其应用于VQGAN框架，以更好地学习HDR图像的隐式表示。这种方法有效地解决了多曝光HDR成像中常见的运动差异和饱和区域问题，对于提升HDR图像的重建质量具有重要意义。该工作通过结合表示学习和专门的网络设计，为高质量HDR成像提供了一条有前景的路径。"}}
{"id": "2507.01491", "title": "Frequency Domain Design of a Reset-Based Filter: An Add-On Nonlinear Filter for Industrial Motion Control", "authors": ["S. Ali Hosseini", "Fabian R. Quinten", "Luke F. van Eijk", "Dragan Kostic", "S. Hassan HosseinNia"], "summary": "This study introduces a modified version of the Constant-in-Gain,\nLead-in-Phase (CgLp) filter, which incorporates a feedthrough term in the\nFirst-Order Reset Element (FORE) to reduce the undesirable nonlinearities and\nachieve an almost constant gain across all frequencies. A backward calculation\napproach is proposed to derive the additional parameter introduced by the\nfeedthrough term, enabling designers to easily tune the filter to generate the\nrequired phase. The paper also presents an add-on filter structure that can\nenhance the performance of an existing LTI controller without altering its\nrobustness margins. A sensitivity improvement indicator is proposed to guide\nthe tuning process, enabling designers to visualize the improvements in\nclosed-loop performance. The proposed methodology is demonstrated through a\ncase study of an industrial wire bonder machine, showcasing its effectiveness\nin addressing low-frequency vibrations and improving overall control\nperformance.", "comment": "15 pages", "pdf_url": "http://arxiv.org/pdf/2507.01491v1", "categories": ["eess.SY", "cs.SY"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01491v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "复位滤波器频域设计：一种用于工业运动控制的附加非线性滤波器", "tldr": "本研究提出了一种改进的CgLp复位滤波器，通过引入前馈项和反向计算方法，实现了几乎恒定的增益和易于调节的相位，并作为附加滤波器应用于工业运动控制，有效抑制了低频振动。", "motivation": "现有的CgLp滤波器可能存在不希望的非线性，需要改进以实现几乎恒定的全频段增益。同时，需要一种附加滤波器来增强现有LTI控制器的性能而不影响其鲁棒性。", "method": "本研究引入了在第一阶复位元件（FORE）中包含前馈项的CgLp滤波器改进版本，以减少非线性和实现几乎恒定的增益。提出了一种反向计算方法来推导前馈项引入的附加参数，从而使设计者能够轻松调整滤波器以生成所需的相位。此外，本文还提出了一种附加滤波器结构，旨在增强现有LTI控制器的性能而不改变其鲁棒性裕度。为指导调谐过程，还提出了一种灵敏度改进指标。", "result": "改进的滤波器实现了几乎恒定的全频段增益并减少了不希望的非线性。通过反向计算方法，设计者可以轻松调整滤波器以生成所需的相位。附加滤波器结构能够增强现有LTI控制器的性能，同时保持其鲁棒性裕度。在工业焊线机案例研究中，所提出的方法有效解决了低频振动问题，并显著提高了整体控制性能。", "conclusion": "本研究成功开发了一种改进的复位滤波器，该滤波器具有优异的增益特性和易于调谐的相位，并且可以作为附加组件有效提升工业运动控制系统的性能，特别是在抑制低频振动方面。", "translation": "本研究介绍了一种改进版的增益恒定、相位超前（CgLp）滤波器，该滤波器在第一阶复位元件（FORE）中引入了一个前馈项，以减少不希望的非线性并实现在所有频率下几乎恒定的增益。提出了一种反向计算方法来推导由前馈项引入的附加参数，使设计人员能够轻松调整滤波器以生成所需的相位。本文还提出了一种附加滤波器结构，可以在不改变现有LTI控制器鲁棒性裕度的情况下增强其性能。提出了一种灵敏度改进指标来指导调谐过程，使设计人员能够可视化闭环性能的改进。所提出的方法通过一个工业焊线机的案例研究进行了演示，展示了其在解决低频振动和改善整体控制性能方面的有效性。", "summary": "本文提出了一种改进的CgLp复位滤波器，通过在第一阶复位元件中引入前馈项，实现了全频段近似恒定增益并减少了非线性。研究还提出了一种反向计算方法来调节滤波器相位，并设计了一种附加滤波器结构，可在不影响现有LTI控制器鲁棒性的前提下提升其性能。通过引入灵敏度改进指标指导调谐，并在工业焊线机上验证了其在抑制低频振动和改善控制性能方面的有效性。", "keywords": "复位滤波器, 频域设计, 非线性滤波器, 运动控制, 增益恒定", "comments": "这项研究的创新之处在于改进了CgLp复位滤波器，通过引入前馈项和反向计算方法解决了传统复位滤波器在非线性和可调性方面的挑战。其作为附加滤波器能够增强现有LTI控制器的性能而不影响鲁棒性，这对于工业应用具有重要意义。所提出的灵敏度改进指标也为工程师提供了直观的调谐工具。在工业焊线机上的成功应用验证了其在实际振动抑制和性能提升方面的潜力。"}}
{"id": "2507.01299", "title": "La RoSA: Enhancing LLM Efficiency via Layerwise Rotated Sparse Activation", "authors": ["Kai Liu", "Bowen Xu", "Shaoyu Wu", "Xin Chen", "Hao Zhou", "Yongliang Tao", "Lulu Hu"], "summary": "Activation sparsity can reduce the computational overhead and memory\ntransfers during the forward pass of Large Language Model (LLM) inference.\nExisting methods face limitations, either demanding time-consuming recovery\ntraining that hinders real-world adoption, or relying on empirical\nmagnitude-based pruning, which causes fluctuating sparsity and unstable\ninference speed-up. This paper introduces LaRoSA (Layerwise Rotated Sparse\nActivation), a novel method for activation sparsification designed to improve\nLLM efficiency without requiring additional training or magnitude-based\npruning. We leverage layerwise orthogonal rotations to transform input\nactivations into rotated forms that are more suitable for sparsification. By\nemploying a Top-K selection approach within the rotated activations, we achieve\nconsistent model-level sparsity and reliable wall-clock time speed-up. LaRoSA\nis effective across various sizes and types of LLMs, demonstrating minimal\nperformance degradation and robust inference acceleration. Specifically, for\nLLaMA2-7B at 40% sparsity, LaRoSA achieves a mere 0.17 perplexity gap with a\nconsistent 1.30x wall-clock time speed-up, and reduces the accuracy gap in\nzero-shot tasks compared to the dense model to just 0.54%, while surpassing\nTEAL by 1.77% and CATS by 17.14%.", "comment": "ICML 2025 Acceptance", "pdf_url": "http://arxiv.org/pdf/2507.01299v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01299v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "La RoSA：通过逐层旋转稀疏激活提高LLM效率", "tldr": "LaRoSA是一种新的激活稀疏化方法，它通过逐层正交旋转和Top-K选择来提高LLM推理效率，无需额外训练，并实现了稳定的加速和最小的性能下降。", "motivation": "现有的大语言模型（LLM）激活稀疏化方法存在局限性，例如需要耗时的恢复训练或依赖经验性的基于幅度的剪枝，这会导致稀疏性波动和推理加速不稳定，从而阻碍了实际应用。", "method": "本文提出LaRoSA（逐层旋转稀疏激活），该方法通过逐层正交旋转将输入激活转换为更适合稀疏化的旋转形式，然后通过在旋转激活中采用Top-K选择方法来实现激活稀疏化，从而获得一致的模型级稀疏性和可靠的实际运行时间加速。此方法无需额外的训练或基于幅度的剪枝。", "result": "LaRoSA在不同大小和类型的LLM上均有效，展现出最小的性能下降和强大的推理加速。具体而言，对于40%稀疏度的LLaMA2-7B，LaRoSA仅导致0.17的困惑度差距，实现了1.30倍稳定的实际运行时间加速，并将零样本任务中的准确率差距与密集模型相比缩小到仅0.54%，同时超越TEAL 1.77%和CATS 17.14%。", "conclusion": "LaRoSA通过创新的逐层旋转稀疏激活方法，显著提升了LLM的推理效率，实现了稳定的加速和极小的性能损失，并优于现有方法，为LLM的实际部署提供了更可靠的解决方案。", "translation": "激活稀疏性可以减少大型语言模型（LLM）推理正向传播过程中的计算开销和内存传输。现有方法面临局限性，要么需要耗时的恢复训练阻碍了实际应用，要么依赖经验性的基于幅度的剪枝，这会导致稀疏性波动和不稳定的推理加速。本文介绍了LaRoSA（逐层旋转稀疏激活），这是一种新颖的激活稀疏化方法，旨在提高LLM效率，而无需额外的训练或基于幅度的剪枝。我们利用逐层正交旋转将输入激活转换为更适合稀疏化的旋转形式。通过在旋转激活中采用Top-K选择方法，我们实现了模型级稀疏性的一致性和可靠的实际运行时间加速。LaRoSA在各种大小和类型的LLM上均有效，表现出最小的性能下降和强大的推理加速。具体而言，对于40%稀疏度的LLaMA2-7B，LaRoSA仅实现了0.17的困惑度差距，获得了1.30倍稳定的实际运行时间加速，并将零样本任务中的准确率差距与密集模型相比缩小到仅0.54%，同时超越TEAL 1.77%和CATS 17.14%。", "summary": "本文提出了一种名为LaRoSA（逐层旋转稀疏激活）的新型方法，旨在提高大型语言模型（LLM）的推理效率。针对现有激活稀疏化方法存在的训练耗时和加速不稳定问题，LaRoSA通过引入逐层正交旋转将输入激活转换为更易稀疏化的形式，并结合Top-K选择实现稳定的模型级稀疏性。该方法无需额外训练或基于幅度的剪枝，即可在多种LLM上实现显著的实际运行时间加速，同时保持极低的性能下降。例如，在LLaMA2-7B模型上，LaRoSA在40%稀疏度下实现了1.30倍的稳定加速，且困惑度差距和准确率下降幅度均微乎其微，并显著优于其他基线方法。", "keywords": "LLM效率, 激活稀疏化, 逐层旋转, 推理加速, LaRoSA", "comments": "LaRoSA的创新点在于其独特的逐层正交旋转方法，它将激活空间转换到更利于稀疏化的表示，从而避免了传统稀疏化方法中常见的训练开销和稳定性问题。其无需额外训练的特性显著降低了实际部署的门槛，而稳定的加速效果和极小的性能损失则凸显了其在LLM效率优化方面的实用价值和重要性。该方法为未来LLM的轻量化和高效推理提供了新的思路。"}}
{"id": "2507.01729", "title": "A trust-region framework for optimization using Hermite kernel surrogate models", "authors": ["Sven Ullmann", "Tobias Ehring", "Robin Herkert", "Bernard Haasdonk"], "summary": "In this work, we present a trust-region optimization framework that employs\nHermite kernel surrogate models. The method targets optimization problems with\ncomputationally demanding objective functions, for which direct optimization is\noften impractical due to expensive function evaluations. To address these\nchallenges, we leverage a trust-region strategy, where the objective function\nis approximated by an efficient surrogate model within a local neighborhood of\nthe current iterate. In particular, we construct the surrogate using Hermite\nkernel interpolation and define the trust-region based on bounds for the\ninterpolation error. As mesh-free techniques, kernel-based methods are\nnaturally suited for medium- to high-dimensional problems. Furthermore, the\nHermite formulation incorporates gradient information, enabling precise\ngradient estimates that are crucial for many optimization algorithms. We prove\nthat the proposed algorithm converges to a stationary point, and we demonstrate\nits effectiveness through numerical experiments, which illustrate the\nconvergence behavior as well as the efficiency gains compared to direct\noptimization.", "comment": "29 pages", "pdf_url": "http://arxiv.org/pdf/2507.01729v1", "categories": ["math.NA", "cs.NA", "math.OC"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01729v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "使用Hermite核代理模型的优化信任域框架", "tldr": "本文提出了一种使用Hermite核代理模型的信任域优化框架，旨在解决计算成本高昂的目标函数优化问题，并通过理论证明和数值实验验证了其收敛性和效率。", "motivation": "针对目标函数计算成本高昂，导致直接优化不切实际的问题。", "method": "提出了一种基于Hermite核代理模型的信任域优化框架。该方法在当前迭代的局部邻域内使用Hermite核插值构建代理模型来近似目标函数，并基于插值误差界限定义信任域。Hermite公式还结合了梯度信息，以提供精确的梯度估计。", "result": "证明了所提出的算法收敛到驻点，并通过数值实验展示了其收敛行为以及相对于直接优化的效率增益。", "conclusion": "所提出的基于Hermite核代理模型的信任域优化框架能够有效解决计算成本高的优化问题，并具有理论收敛保证和实际效率提升。", "translation": "在这项工作中，我们提出了一个采用Hermite核代理模型的信任域优化框架。该方法针对计算要求高的目标函数优化问题，对于这些问题，由于函数评估成本高昂，直接优化通常不切实际。为了解决这些挑战，我们利用信任域策略，在当前迭代的局部邻域内通过高效的代理模型近似目标函数。特别是，我们使用Hermite核插值构建代理模型，并根据插值误差的界限定义信任域。作为无网格技术，基于核的方法天然适用于中高维问题。此外，Hermite公式结合了梯度信息，能够实现精确的梯度估计，这对于许多优化算法至关重要。我们证明了所提出的算法收敛到驻点，并通过数值实验展示了其有效性，这些实验说明了收敛行为以及与直接优化相比的效率增益。", "summary": "本文提出了一种新颖的信任域优化框架，该框架利用Hermite核代理模型来解决目标函数计算成本高昂的优化问题。为了规避昂贵的函数评估，该方法在局部邻域内使用Hermite核插值构建代理模型，并基于插值误差定义信任域。此框架的Hermite公式能够整合梯度信息，提供精确的梯度估计。论文证明了所提算法的收敛性，并通过数值实验验证了其在收敛行为和效率方面的优势。", "keywords": "信任域优化, Hermite核, 代理模型, 高维优化, 梯度信息", "comments": "该论文创新性地将Hermite核代理模型引入信任域优化框架，有效解决了计算昂贵的目标函数优化问题。其结合梯度信息的能力以及对中高维问题的适用性是亮点。理论收敛性证明和数值实验验证增强了其方法的可靠性。"}}
{"id": "2507.01765", "title": "First Steps Towards Voice Anonymization for Code-Switching Speech", "authors": ["Sarina Meyer", "Ekaterina Kolos", "Ngoc Thang Vu"], "summary": "The goal of voice anonymization is to modify an audio such that the true\nidentity of its speaker is hidden. Research on this task is typically limited\nto the same English read speech datasets, thus the efficacy of current methods\nfor other types of speech data remains unknown. In this paper, we present the\nfirst investigation of voice anonymization for the multilingual phenomenon of\ncode-switching speech. We prepare two corpora for this task and propose\nadaptations to a multilingual anonymization model to make it applicable for\ncode-switching speech. By testing the anonymization performance of this and two\nlanguage-independent methods on the datasets, we find that only the\nmultilingual system performs well in terms of privacy and utility preservation.\nFurthermore, we observe challenges in performing utility evaluations on this\ndata because of its spontaneous character and the limited code-switching\nsupport by the multilingual speech recognition model.", "comment": "accepted at Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.01765v1", "categories": ["eess.AS"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01765v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "迈向语音混淆（Voice Anonymization）在语码转换语音中应用的第一步", "tldr": "本文首次探讨了语音混淆技术在语码转换语音中的应用，发现只有多语言系统在隐私和实用性方面表现良好，但实用性评估面临挑战。", "motivation": "语音混淆研究通常局限于英语朗读语音数据集，现有方法对其他类型语音数据的有效性尚不清楚，因此需要探索其在多语言语码转换语音中的应用。", "method": "研究者为语码转换语音的语音混淆任务准备了两个语料库，并对多语言混淆模型进行了调整以适应语码转换语音。同时，他们测试了该模型以及两种语言无关方法在这些数据集上的混淆性能。", "result": "测试结果表明，只有多语言系统在隐私和实用性保持方面表现良好。此外，研究者发现由于语码转换数据的自发性特征以及多语言语音识别模型对语码转换支持有限，进行实用性评估存在挑战。", "conclusion": "研究表明，在语码转换语音的语音混淆任务中，多语言系统在隐私和实用性方面表现出良好的性能，但实用性评估仍是未来需要解决的挑战。", "translation": "语音混淆的目标是修改音频以隐藏说话者的真实身份。这项任务的研究通常局限于相同的英语朗读语音数据集，因此当前方法对其他类型语音数据的有效性仍然未知。在本文中，我们首次对多语言语码转换语音的语音混淆进行了调查。我们为此任务准备了两个语料库，并提出了对多语言混淆模型的适应性修改，使其适用于语码转换语音。通过测试该模型和两种语言无关方法在数据集上的混淆性能，我们发现只有多语言系统在隐私和实用性保持方面表现良好。此外，我们观察到由于语码转换数据的自发性特征以及多语言语音识别模型对语码转换支持有限，在对此数据进行实用性评估时存在挑战。", "summary": "本文首次将语音混淆技术应用于多语言语码转换语音。研究者为此任务构建了两个语料库，并对现有多语言混淆模型进行了改进。通过实验，他们发现只有经过调整的多语言系统能在保护隐私和保持实用性方面表现出色，但也指出由于语码转换语音的特性和现有工具的局限性，实用性评估存在困难。", "keywords": "语音混淆, 语码转换语音, 多语言, 隐私保护, 实用性评估", "comments": "本文的创新之处在于首次将语音混淆研究扩展到复杂的语码转换语音领域，填补了现有研究主要集中于单一语言的空白。其重要性在于为多语言环境下的语音隐私保护提供了初步探索和有效方案。然而，论文也指出了在语码转换数据上进行实用性评估的挑战，这提示了未来研究需要关注的方向和现有技术的局限性。"}}
{"id": "2507.01616", "title": "Enhanced Influence-aware Group Recommendation for Online Media Propagation", "authors": ["Chengkun He", "Xiangmin Zhou", "Chen Wang", "Longbing Cao", "Jie Shao", "Xiaodong Li", "Guang Xu", "Carrie Jinqiu Hu", "Zahir Tari"], "summary": "Group recommendation over social media streams has attracted significant\nattention due to its wide applications in domains such as e-commerce,\nentertainment, and online news broadcasting. By leveraging social connections\nand group behaviours, group recommendation (GR) aims to provide more accurate\nand engaging content to a set of users rather than individuals. Recently,\ninfluence-aware GR has emerged as a promising direction, as it considers the\nimpact of social influence on group decision-making. In earlier work, we\nproposed Influence-aware Group Recommendation (IGR) to solve this task.\nHowever, this task remains challenging due to three key factors: the large and\never-growing scale of social graphs, the inherently dynamic nature of influence\npropagation within user groups, and the high computational overhead of\nreal-time group-item matching.\n  To tackle these issues, we propose an Enhanced Influence-aware Group\nRecommendation (EIGR) framework. First, we introduce a Graph Extraction-based\nSampling (GES) strategy to minimise redundancy across multiple temporal social\ngraphs and effectively capture the evolving dynamics of both groups and items.\nSecond, we design a novel DYnamic Independent Cascade (DYIC) model to predict\nhow influence propagates over time across social items and user groups.\nFinally, we develop a two-level hash-based User Group Index (UG-Index) to\nefficiently organise user groups and enable real-time recommendation\ngeneration. Extensive experiments on real-world datasets demonstrate that our\nproposed framework, EIGR, consistently outperforms state-of-the-art baselines\nin both effectiveness and efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01616v1", "categories": ["cs.IR", "cs.AI", "cs.DB"], "cate": "cs.IR", "url": "http://arxiv.org/abs/2507.01616v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "在线媒体传播中增强影响力感知群组推荐", "tldr": "本文提出了EIGR框架，通过图提取采样、动态独立级联模型和两级哈希用户群组索引，解决了群组推荐中社交图规模大、影响传播动态性强、计算开销大等挑战，并在真实数据集上表现出更高的有效性和效率。", "motivation": "群组推荐在电子商务、娱乐和在线新闻广播等领域有广泛应用。影响力感知群组推荐是一个有前景的方向，但仍面临社交图规模大、影响传播动态性强以及实时群组-项目匹配计算开销大等挑战。", "method": "本文提出了增强影响力感知群组推荐（EIGR）框架。首先，引入了基于图提取的采样（GES）策略，以最小化跨多个时间社交图的冗余并有效捕获群组和项目的演变动态。其次，设计了一种新颖的动态独立级联（DYIC）模型来预测影响力如何随时间在社交项目和用户群组之间传播。最后，开发了一个两级基于哈希的用户群组索引（UG-Index），以高效组织用户群组并实现实时推荐生成。", "result": "在真实世界数据集上进行的广泛实验表明，所提出的EIGR框架在有效性和效率方面均持续优于最先进的基线。", "conclusion": "EIGR框架通过其创新的组件成功解决了影响力感知群组推荐面临的关键挑战，并在实践中展现出卓越的性能。", "translation": "在线媒体流中的群组推荐因其在电子商务、娱乐和在线新闻广播等领域的广泛应用而受到广泛关注。通过利用社交连接和群组行为，群组推荐（GR）旨在向一组用户而非个体提供更准确和更具吸引力的内容。最近，影响力感知群组推荐（IGR）作为一个有前景的方向出现，因为它考虑了社交影响力对群组决策的影响。在我们早期的工作中，我们提出了影响力感知群组推荐（IGR）来解决这项任务。然而，这项任务仍然具有挑战性，原因有三个关键因素：社交图规模庞大且不断增长，用户群组内影响力传播固有的动态性，以及实时群组-项目匹配的高计算开销。\n为了解决这些问题，我们提出了一个增强影响力感知群组推荐（EIGR）框架。首先，我们引入了一种基于图提取的采样（GES）策略，以最大限度地减少多个时间社交图之间的冗余，并有效捕获群组和项目的演变动态。其次，我们设计了一个新颖的动态独立级联（DYIC）模型来预测影响力如何随时间在社交项目和用户群组之间传播。最后，我们开发了一个两级基于哈希的用户群组索引（UG-Index），以高效组织用户群组并实现实时推荐生成。在真实世界数据集上进行的广泛实验表明，我们提出的EIGR框架在有效性和效率方面均持续优于最先进的基线。", "summary": "本文提出了一种增强影响力感知群组推荐（EIGR）框架，旨在解决现有群组推荐在社交图规模、影响传播动态性和计算效率方面的挑战。EIGR框架包含三个核心组件：基于图提取的采样（GES）策略用于捕捉动态变化并减少冗余；动态独立级联（DYIC）模型用于预测影响力传播；以及两级哈希用户群组索引（UG-Index）用于高效实时推荐。实验证明，EIGR在真实数据集上显著优于现有基线。", "keywords": "群组推荐, 影响力感知, 社交网络, 图采样, 独立级联模型", "comments": "本文的创新之处在于提出了一个综合性的EIGR框架，通过结合GES、DYIC和UG-Index三个组件，系统性地解决了影响力感知群组推荐在可扩展性、动态性和效率方面的核心挑战。特别是，GES和DYIC的结合为处理社交图的动态演化和影响力传播提供了新颖的视角，而UG-Index则有效提升了实时推荐的效率。该工作对于在大规模动态社交网络中实现高效准确的群组推荐具有重要意义。"}}
{"id": "2507.01833", "title": "Refining Gelfond Rationality Principle Towards More Comprehensive Foundational Principles for Answer Set Semantics", "authors": ["Yi-Dong Shen", "Thomas Eiter"], "summary": "Non-monotonic logic programming is the basis for a declarative problem\nsolving paradigm known as answer set programming (ASP). Departing from the\nseminal definition by Gelfond and Lifschitz in 1988 for simple normal logic\nprograms, various answer set semantics have been proposed for extensions. We\nconsider two important questions: (1) Should the minimal model property,\nconstraint monotonicity and foundedness as defined in the literature be\nmandatory conditions for an answer set semantics in general? (2) If not, what\nother properties could be considered as general principles for answer set\nsemantics? We address the two questions. First, it seems that the three\naforementioned conditions may sometimes be too strong, and we illustrate with\nexamples that enforcing them may exclude expected answer sets. Second, we\nevolve the Gelfond answer set (GAS) principles for answer set construction by\nrefining the Gelfond's rationality principle to well-supportedness, minimality\nw.r.t. negation by default and minimality w.r.t. epistemic negation. The\nprinciple of well-supportedness guarantees that every answer set is\nconstructible from if-then rules obeying a level mapping and is thus free of\ncircular justification, while the two minimality principles ensure that the\nformalism minimizes knowledge both at the level of answer sets and of world\nviews. Third, to embody the refined GAS principles, we extend the notion of\nwell-supportedness substantially to answer sets and world views, respectively.\nFourth, we define new answer set semantics in terms of the refined GAS\nprinciples. Fifth, we use the refined GAS principles as an alternative baseline\nto intuitively assess the existing answer set semantics. Finally, we analyze\nthe computational complexity.", "comment": "76 pages. This article is a significantly extended version of a paper\n  presented by the authors at IJCAI-2022", "pdf_url": "http://arxiv.org/pdf/2507.01833v1", "categories": ["cs.AI"], "cate": "cs.AI", "url": "http://arxiv.org/abs/2507.01833v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "完善Gelfond理性原则以构建更全面的答案集语义基础原则", "tldr": "本文通过将Gelfond理性原则细化为良好支持性原则和两种最小性原则，提出了更全面的答案集语义基础原则，旨在解决现有强制性条件可能过于严格的问题。", "motivation": "现有答案集语义的最小模型性质、约束单调性和基础性等条件可能过于严格，有时会排除预期的答案集。因此，需要探讨这些条件是否应作为普遍强制性条件，并寻找其他合适的通用原则。", "method": "作者通过将Gelfond理性原则细化为良好支持性原则、默认否定下的最小性原则和认知否定下的最小性原则，发展了Gelfond答案集（GAS）原则。他们将良好支持性概念扩展到答案集和世界观，并基于这些细化的GAS原则定义了新的答案集语义。此外，他们还将这些原则作为评估现有答案集语义的替代基线，并分析了计算复杂性。", "result": "本文提出了细化的Gelfond答案集（GAS）原则，包括良好支持性、默认否定下的最小性和认知否定下的最小性，这些原则保证了答案集的可构造性、无循环证明以及知识的最小化。基于这些新原则，定义了新的答案集语义，并提供了一个评估现有语义的替代基线。", "conclusion": "本文建立了一套细化的Gelfond答案集（GAS）原则，为答案集语义提供了更全面和灵活的基础，有效弥补了以往被认为是强制性条件的不足。", "translation": "非单调逻辑编程是声明性问题解决范式（称为答案集编程，ASP）的基础。从Gelfond和Lifschitz在1988年对简单普通逻辑程序提出的开创性定义出发，针对其扩展提出了各种答案集语义。我们考虑两个重要问题：(1) 文献中定义的最小模型性质、约束单调性和基础性是否应普遍作为答案集语义的强制性条件？(2) 如果不是，还有哪些属性可以被视为答案集语义的通用原则？我们解决了这两个问题。首先，这三个前述条件有时可能过于严格，我们通过示例说明强制执行它们可能会排除预期的答案集。其次，我们通过将Gelfond的理性原则细化为良好支持性、默认否定下的最小性和认知否定下的最小性，发展了Gelfond答案集（GAS）构造原则。良好支持性原则保证每个答案集都可以从遵循层次映射的“如果-那么”规则中构建，从而避免循环论证；而两个最小性原则确保形式化在答案集和世界观层面都最小化知识。第三，为了体现细化的GAS原则，我们将良好支持性的概念分别实质性地扩展到答案集和世界观。第四，我们根据细化的GAS原则定义了新的答案集语义。第五，我们使用细化的GAS原则作为替代基线，直观地评估现有答案集语义。最后，我们分析了计算复杂性。", "summary": "本研究旨在完善答案集语义的奠基性原则。针对现有原则（如最小模型性质）可能过于严格并排除预期答案集的问题，作者细化了Gelfond的理性原则，提出了包括良好支持性、默认否定下最小性和认知否定下最小性在内的一套新Gelfond答案集（GAS）原则。这些原则旨在确保答案集的可构造性、无循环证明和知识最小化。基于这些细化原则，文章定义了新的答案集语义，并将其作为评估现有语义的替代基线，同时分析了其计算复杂性。", "keywords": "答案集编程, 非单调逻辑, Gelfond理性原则, 良好支持性, 答案集语义", "comments": "本文通过对Gelfond理性原则的深入审视和细化，为答案集语义的理论基础做出了重要贡献。其创新之处在于提出了更具包容性的原则，解决了现有强制性条件可能导致预期答案集被排除的问题。引入良好支持性和两种最小性原则，不仅增强了语义的严谨性，也提供了评估和构建新答案集语义的清晰框架，对于ASP领域的基础研究具有重要意义。"}}
{"id": "2507.01694", "title": "Graph Representation-based Model Poisoning on Federated LLMs in CyberEdge Networks", "authors": ["Hanlin Cai", "Haofan Dong", "Houtianfu Wang", "Kai Li", "Ozgur B. Akan"], "summary": "Federated large language models (FedLLMs) provide powerful generative\ncapabilities in CyberEdge networks while protecting data privacy. However,\nFedLLMs remains highly vulnerable to model poisoning attacks. This article\nfirst reviews recent model poisoning techniques and existing defense mechanisms\nfor FedLLMs, highlighting critical limitations, particularly under non-IID text\ndistributions. In particular, current defenses primarily utilize distance-based\noutlier detection or norm constraints, operating under the assumption that\nadversarial updates significantly diverge from benign statistics. This\nassumption can fail when facing adaptive attackers targeting billionparameter\nLLMs. Next, this article investigates emerging Graph Representation-Based Model\nPoisoning (GRMP), a novel attack paradigm that leverages higher-order\ncorrelations among honest client gradients to synthesize malicious updates\nindistinguishable from legitimate model updates. GRMP can effectively evade\nadvanced defenses, resulting in substantial accuracy loss and performance\ndegradation. Moreover, this article outlines a research roadmap emphasizing the\nimportance of graph-aware secure aggregation methods, FedLLMs-specific\nvulnerability metrics, and evaluation frameworks to strengthen the robustness\nof future federated language model deployments.", "comment": "7 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.01694v1", "categories": ["cs.CR", "cs.SY", "eess.SY"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01694v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于图表示的联邦大型语言模型在网络边缘网络中的模型投毒攻击", "tldr": "本文介绍了一种名为GRMP的新型图表示模型投毒攻击，该攻击利用客户端梯度的高阶相关性，在联邦大型语言模型（FedLLMs）中生成难以区分的恶意更新，从而规避现有防御并导致显著的性能下降。文章还概述了未来研究的路线图。", "motivation": "联邦大型语言模型（FedLLMs）在保护数据隐私的同时提供了强大的生成能力，但在网络边缘网络中极易受到模型投毒攻击。现有防御机制，特别是针对非IID文本分布，存在显著局限性，主要依赖于距离或范数约束，在面对自适应攻击者时可能失效，这促使了对新型攻击和更强鲁棒性方法的研究。", "method": "本文首先回顾了现有的模型投毒技术和防御机制，并指出其局限性。接着，文章提出并研究了一种名为“图表示模型投毒（GRMP）”的新型攻击范式。GRMP利用诚实客户端梯度之间的高阶关联性来合成与合法模型更新难以区分的恶意更新。", "result": "GRMP攻击能够有效规避现有的先进防御机制，导致联邦大型语言模型显著的准确性损失和性能下降。", "conclusion": "FedLLMs面临的模型投毒攻击威胁严峻，现有防御不足。GRMP攻击展示了利用梯度高阶相关性发动隐蔽攻击的有效性。文章强调了开发图感知安全聚合方法、FedLLMs特定漏洞指标和评估框架的重要性，以增强未来联邦语言模型部署的鲁棒性。", "translation": "联邦大型语言模型（FedLLMs）在网络边缘网络中提供了强大的生成能力，同时保护数据隐私。然而，FedLLMs仍然极易受到模型投毒攻击。本文首先回顾了最近的模型投毒技术和FedLLMs的现有防御机制，强调了关键局限性，特别是在非独立同分布（non-IID）文本分布下。具体而言，当前的防御主要利用基于距离的异常检测或范数约束，其操作假设是，对抗性更新与良性统计数据显著不同。当面对针对十亿参数LLMs的自适应攻击者时，这一假设可能会失效。接下来，本文研究了新兴的基于图表示的模型投毒（GRMP），这是一种新颖的攻击范式，它利用诚实客户端梯度之间的高阶相关性来合成与合法模型更新难以区分的恶意更新。GRMP可以有效规避先进防御，导致显著的准确性损失和性能下降。此外，本文概述了一项研究路线图，强调了图感知安全聚合方法、FedLLMs特定漏洞指标和评估框架的重要性，以加强未来联邦语言模型部署的鲁健性。", "summary": "本文探讨了联邦大型语言模型（FedLLMs）在网络边缘网络中面临的模型投毒攻击威胁。文章指出现有防御机制在非IID数据和自适应攻击下存在不足。为此，本文提出并研究了一种名为“图表示模型投毒（GRMP）”的新型攻击范式，该攻击通过利用客户端梯度的高阶相关性生成与合法更新难以区分的恶意更新，从而有效规避现有防御并导致显著的性能下降。最后，文章提出了一个研究路线图，强调了图感知安全聚合、特定漏洞指标和评估框架对于提升FedLLMs鲁棒性的重要性。", "keywords": "联邦大型语言模型, 模型投毒, 图表示, 网络边缘, 安全聚合", "comments": "本文创新性地提出了基于图表示的模型投毒（GRMP）攻击，该攻击利用梯度的高阶相关性，使其生成的恶意更新难以被现有防御机制识别。这揭示了当前FedLLMs防御的深层漏洞，尤其是在面对高级、自适应攻击者时。文章的重要性在于不仅指出了问题，还提出了未来研究的方向，强调了开发更复杂、图感知防御机制的必要性，这对于保障联邦学习中LLMs的安全性至关重要。"}}
{"id": "2507.01340", "title": "Physics-informed Ground Reaction Dynamics from Human Motion Capture", "authors": ["Cuong Le", "Huy-Phuong Le", "Duc Le", "Minh-Thien Duong", "Van-Binh Nguyen", "My-Ha Le"], "summary": "Body dynamics are crucial information for the analysis of human motions in\nimportant research fields, ranging from biomechanics, sports science to\ncomputer vision and graphics. Modern approaches collect the body dynamics,\nexternal reactive force specifically, via force plates, synchronizing with\nhuman motion capture data, and learn to estimate the dynamics from a black-box\ndeep learning model. Being specialized devices, force plates can only be\ninstalled in laboratory setups, imposing a significant limitation on the\nlearning of human dynamics. To this end, we propose a novel method for\nestimating human ground reaction dynamics directly from the more reliable\nmotion capture data with physics laws and computational simulation as\nconstrains. We introduce a highly accurate and robust method for computing\nground reaction forces from motion capture data using Euler's integration\nscheme and PD algorithm. The physics-based reactive forces are used to inform\nthe learning model about the physics-informed motion dynamics thus improving\nthe estimation accuracy. The proposed approach was tested on the GroundLink\ndataset, outperforming the baseline model on: 1) the ground reaction force\nestimation accuracy compared to the force plates measurement; and 2) our\nsimulated root trajectory precision. The implementation code is available at\nhttps://github.com/cuongle1206/Phys-GRD", "comment": "6 pages, 4 figures, 4 tables, HSI 2025", "pdf_url": "http://arxiv.org/pdf/2507.01340v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01340v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于物理信息的人体运动捕捉地面试反力动力学", "tldr": "该论文提出了一种新的基于物理信息的方法，可以直接从运动捕捉数据中估计人体地面试反力动力学，克服了传统测力台的局限性，并提高了估计精度。", "motivation": "传统方法通过测力台收集人体地面试反力，但测力台是专用设备，只能安装在实验室环境中，这严重限制了人体动力学数据的获取和学习。", "method": "该论文提出了一种新颖的方法，利用物理定律和计算仿真作为约束，直接从运动捕捉数据中估计人体地面试反力动力学。具体来说，该方法引入了使用欧拉积分方案和PD算法从运动捕捉数据中计算地面试反力，并将这些基于物理的反作用力用于指导学习模型，以提高运动动力学的估计精度。", "result": "所提出的方法在GroundLink数据集上进行了测试，表现优于基线模型。具体体现在：1）与测力台测量相比，地面试反力估计精度更高；2）模拟的根轨迹精度更高。", "conclusion": "该论文提出的基于物理信息的方法能够有效且准确地从运动捕捉数据中估计地面试反力动力学，克服了传统测力台的局限性，并提高了估计精度，为人体运动分析提供了更灵活和可靠的手段。", "translation": "人体动力学是生物力学、运动科学、计算机视觉和图形学等重要研究领域中分析人体运动的关键信息。现代方法通过测力台收集人体动力学（特别是外部反作用力），并与人体运动捕捉数据同步，然后通过黑盒深度学习模型学习估计动力学。作为专用设备，测力台只能安装在实验室环境中，这对人体动力学的学习造成了重大限制。为此，我们提出了一种新颖的方法，利用物理定律和计算仿真作为约束，直接从更可靠的运动捕捉数据中估计人体地面试反力动力学。我们引入了一种高精度、高鲁棒性的方法，使用欧拉积分方案和PD算法从运动捕捉数据中计算地面试反力。这些基于物理的反作用力用于向学习模型提供物理信息运动动力学，从而提高估计精度。所提出的方法在GroundLink数据集上进行了测试，在以下方面优于基线模型：1）与测力台测量相比，地面试反力估计精度更高；2）模拟的根轨迹精度更高。实现代码可在https://github.com/cuongle1206/Phys-GRD 获取。", "summary": "该论文提出了一种创新的基于物理信息的方法，旨在直接从人体运动捕捉数据中估计地面试反力动力学，以此解决传统测力台在实验室环境中的局限性。通过将物理定律、欧拉积分方案和PD算法融入模型，该方法能够精确计算地面试反力，并利用这些物理信息指导学习模型，从而提高估计精度。在GroundLink数据集上的实验结果表明，该方法在地面试反力估计精度和模拟根轨迹精度方面均优于现有基线模型。", "keywords": "地面试反力动力学, 运动捕捉, 物理信息, 欧拉积分, PD算法", "comments": "该论文为人体运动分析领域提供了一个重要的创新解决方案，通过将物理原理直接融入地面试反力估计过程，显著降低了对昂贵且受限的专业硬件（如测力台）的依赖。这种“物理信息”驱动的方法具有广阔的应用前景，使得在非受控实验室环境中进行人体动力学分析成为可能，极大地拓展了研究和应用的范围。"}}
{"id": "2507.01719", "title": "Towards culturally-appropriate conversational AI for health in the majority world: An exploratory study with citizens and professionals in Latin America", "authors": ["Dorian Peters", "Fernanda Espinoza", "Marco da Re", "Guido Ivetta", "Luciana Benotti", "Rafael A. Calvo"], "summary": "There is justifiable interest in leveraging conversational AI (CAI) for\nhealth across the majority world, but to be effective, CAI must respond\nappropriately within culturally and linguistically diverse contexts. Therefore,\nwe need ways to address the fact that current LLMs exclude many lived\nexperiences globally. Various advances are underway which focus on top-down\napproaches and increasing training data. In this paper, we aim to complement\nthese with a bottom-up locally-grounded approach based on qualitative data\ncollected during participatory workshops in Latin America. Our goal is to\nconstruct a rich and human-centred understanding of: a) potential areas of\ncultural misalignment in digital health; b) regional perspectives on chatbots\nfor health and c)strategies for creating culturally-appropriate CAI; with a\nfocus on the understudied Latin American context. Our findings show that\nacademic boundaries on notions of culture lose meaning at the ground level and\ntechnologies will need to engage with a broader framework; one that\nencapsulates the way economics, politics, geography and local logistics are\nentangled in cultural experience. To this end, we introduce a framework for\n'Pluriversal Conversational AI for Health' which allows for the possibility\nthat more relationality and tolerance, rather than just more data, may be\ncalled for.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01719v1", "categories": ["cs.HC", "cs.AI"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01719v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "迈向多数世界中文化适宜的健康对话式人工智能：拉丁美洲公民和专业人士的探索性研究", "tldr": "本研究探讨了在拉丁美洲通过定性数据和参与式研讨会，构建文化适宜的健康对话式AI的方法，发现文化概念在实际应用中更复杂，并提出了“多元宇宙健康对话式AI”框架。", "motivation": "现有大型语言模型（LLMs）在全球范围内排除了许多生活经验，导致对话式AI（CAI）在文化和语言多样性背景下无法有效响应。因此，需要一种方法来解决当前LLMs的局限性，使其能更好地适应多数世界的健康CAI需求。", "method": "采用自下而上的、基于本地的定性研究方法，通过在拉丁美洲举行的参与式研讨会收集数据。目标是构建对以下方面的丰富和以人为本的理解：a) 数字健康中潜在的文化错位区域；b) 区域对健康聊天机器人的看法；c) 创建文化适宜CAI的策略。", "result": "研究发现，关于文化的学术界限在实际层面失去了意义，技术需要与一个更广泛的框架相结合，该框架应包含经济、政治、地理和当地物流如何与文化体验交织在一起。", "conclusion": "为了实现文化适宜的CAI，可能需要更多的关系性和宽容，而不仅仅是更多的数据，并引入了一个“多元宇宙健康对话式AI”框架。", "translation": "多数世界对利用对话式人工智能（CAI）进行健康服务有着合理的兴趣，但要有效，CAI必须在文化和语言多样化的背景下做出适当的响应。因此，我们需要解决当前大型语言模型（LLMs）排除了全球许多生活经验的事实。目前正在进行各种进展，这些进展侧重于自上而下的方法和增加训练数据。在本文中，我们旨在通过一种自下而上的、基于本地的方法来补充这些进展，该方法基于在拉丁美洲参与式研讨会期间收集的定性数据。我们的目标是构建对以下方面的丰富和以人为本的理解：a) 数字健康中潜在的文化错位区域；b) 区域对健康聊天机器人的看法；c) 创建文化适宜CAI的策略；重点关注研究不足的拉丁美洲背景。我们的研究结果表明，关于文化的学术界限在实际层面失去了意义，技术将需要与一个更广泛的框架相结合；一个包含经济、政治、地理和当地物流如何与文化体验交织在一起的框架。为此，我们引入了一个“多元宇宙健康对话式AI”框架，该框架允许更多的关系性和宽容，而不仅仅是更多的数据，可能是必需的。", "summary": "本文探讨了在拉丁美洲为多数世界创建文化适宜的健康对话式AI。研究通过参与式研讨会收集定性数据，旨在理解数字健康中的文化错位、区域对健康聊天机器人的看法以及创建文化适宜CAI的策略。研究发现，文化概念应超越学术界限，融入经济、政治、地理和物流等实际因素。为此，论文提出了一个“多元宇宙健康对话式AI”框架，强调关系性和宽容在构建有效CAI中的重要性，而非仅仅依赖更多数据。", "keywords": "文化适宜AI, 对话式AI, 健康AI, 拉丁美洲, 多元宇宙AI", "comments": "这篇论文通过自下而上的定性研究方法，强调了文化在AI设计中的复杂性和多维度，挑战了传统上依赖“更多数据”的AI发展范式，提出了“多元宇宙健康对话式AI”的创新概念，对于推动AI在多样化社会背景下的公平性和有效性具有重要意义。"}}
{"id": "2507.01039", "title": "On-Policy Optimization of ANFIS Policies Using Proximal Policy Optimization", "authors": ["Kaaustaaub Shankar", "Wilhelm Louw", "Kelly Cohen"], "summary": "We propose a reinforcement learning (RL) approach for training neuro-fuzzy\ncontrollers using Proximal Policy Optimization (PPO). Building on prior work\nthat applied Deep Q-Learning to Adaptive Neuro-Fuzzy Inference Systems (ANFIS),\nour method replaces the off-policy value-based framework with a stable\non-policy actor-critic loop. We evaluate this approach in the CartPole-v1\nenvironment using multiple random seeds and compare its learning performance\nagainst ANFIS-Deep Q-Network (DQN) baselines. It was found that PPO-trained\nfuzzy agents achieved a mean return of 500 +/- 0 on CartPole-v1 after 20000\nupdates, showcasing less variance than prior DQN-based methods during training\nand overall faster convergence. These findings suggest that PPO offers a\npromising pathway for training explainable neuro-fuzzy controllers in\nreinforcement learning tasks.", "comment": "Submitted to NAFIPS 2025", "pdf_url": "http://arxiv.org/pdf/2507.01039v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01039v1", "date": "2025-06-22", "updated": "2025-06-22", "AI": {"title_translation": "使用近端策略优化对ANFIS策略进行在线策略优化", "tldr": "本文提出了一种使用PPO训练神经模糊控制器的方法，并在CartPole-v1环境中表现出比DQN基线更快的收敛速度和更低的方差。", "motivation": "现有工作将深度Q学习应用于自适应神经模糊推理系统（ANFIS），但其是离线（off-policy）的。本文旨在用稳定的在线（on-policy）actor-critic循环替代该框架，以改进神经模糊控制器的训练。", "method": "提出了一种使用近端策略优化（PPO）训练神经模糊控制器（ANFIS）的强化学习方法。该方法用稳定的在线策略actor-critic循环取代了以往基于离线策略价值的框架。", "result": "在CartPole-v1环境中，PPO训练的模糊智能体在20000次更新后达到了500 +/- 0的平均回报，与先前的基于DQN的方法相比，训练期间方差更小，整体收敛速度更快。", "conclusion": "PPO为强化学习任务中训练可解释的神经模糊控制器提供了一条有前景的途径。", "translation": "我们提出了一种使用近端策略优化（PPO）训练神经模糊控制器的强化学习（RL）方法。在先前将深度Q学习应用于自适应神经模糊推理系统（ANFIS）的工作基础上，我们的方法用一个稳定的在线策略actor-critic循环取代了离线策略的基于价值的框架。我们在CartPole-v1环境中，使用多个随机种子评估了这种方法，并将其学习性能与ANFIS-深度Q网络（DQN）基线进行了比较。结果发现，PPO训练的模糊智能体在20000次更新后在CartPole-v1上实现了500 +/- 0的平均回报，在训练期间显示出比先前的基于DQN的方法更小的方差和整体更快的收敛速度。这些发现表明，PPO为在强化学习任务中训练可解释的神经模糊控制器提供了一条有前景的途径。", "summary": "本文提出了一种新的强化学习方法，利用近端策略优化（PPO）训练自适应神经模糊推理系统（ANFIS）作为控制器。该方法旨在通过引入稳定的在线策略actor-critic框架来改进传统的基于深度Q学习的ANFIS训练。在CartPole-v1环境中的实验结果表明，与ANFIS-DQN基线相比，PPO训练的模糊智能体实现了更高的平均回报、更低的训练方差和更快的收敛速度，这表明PPO是训练可解释神经模糊控制器的一种有前景的途径。", "keywords": "强化学习, 近端策略优化, 神经模糊控制, ANFIS, 在线策略", "comments": "这项工作通过将PPO引入神经模糊控制器的训练，提供了一种创新的在线策略优化方法，解决了传统离线策略方法可能存在的稳定性问题。其重要性在于，它不仅提高了训练效率和稳定性，还为开发可解释的强化学习智能体提供了一条新路径，这对于需要决策透明度的实际应用至关重要。"}}
{"id": "2507.01799", "title": "Measurement-based Evaluation of CNN-based Detection and Estimation for ISAC Systems", "authors": ["Steffen Schieler", "Sebastian Semper", "Christian Schneider", "Reiner Thomä"], "summary": "In wireless sensing applications, such as ISAC, one of the first crucial\nsignal processing steps is the detection and estimation targets from a channel\nestimate. Effective algorithms in this context must be robust across a broad\nSNR range, capable of handling an unknown number of targets, and\ncomputationally efficient for real-time implementation. During the last decade,\ndifferent Machine Learning methods have emerged as promising solutions, either\nas standalone models or as complementing existing techniques. However, since\nmodels are often trained and evaluated on synthetic data from existing models,\napplying them to measurement is challenging. All the while, training directly\non measurement data is prohibitive in complex propagation scenarios as a\ngroundtruth is not available. Therefore, in this paper, we train a CNN approach\nfor target detection and estimation on synthetic data and evaluate it on\nmeasurement data from a suburban outdoor measurement. Using knowledge of the\nenvironment as well as available groundtruth positions, we study the detection\nprobability and accuracy of our approach. The results demonstrate that our\napproach works on measurement data and is suitable for joint detection and\nestimation of sensing targets in ISAC systems.", "comment": "2025 IEEE International Radar Conference (RADAR)", "pdf_url": "http://arxiv.org/pdf/2507.01799v1", "categories": ["eess.SP"], "cate": "eess.SP", "url": "http://arxiv.org/abs/2507.01799v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于测量的ISAC系统中CNN目标检测与估计评估", "tldr": "本文提出了一种在合成数据上训练并在实际测量数据上评估的CNN方法，用于ISAC系统中的目标检测和估计，并证明其有效性。", "motivation": "在无线传感应用（如ISAC）中，目标检测和估计是关键步骤，需要算法在宽SNR范围、未知目标数量下保持鲁棒性且计算高效。虽然机器学习方法很有前景，但由于通常在合成数据上训练和评估，其在实际测量数据上的应用面临挑战，而直接在测量数据上训练又因缺乏真实值而难以实现。", "method": "本文在合成数据上训练了一个基于CNN的目标检测和估计方法，并在郊区户外测量数据上进行了评估。利用环境知识和可用的真实目标位置，研究了该方法的检测概率和准确性。", "result": "结果表明，该方法在测量数据上有效，并且适用于ISAC系统中传感目标的联合检测和估计。", "conclusion": "本文提出的CNN方法，在合成数据上训练并在实际测量数据上评估后，被证明适用于ISAC系统中的目标联合检测和估计。", "translation": "在无线传感应用（如ISAC）中，第一个关键的信号处理步骤是从信道估计中检测和估计目标。在这种背景下，有效的算法必须在宽信噪比（SNR）范围内具有鲁棒性，能够处理未知数量的目标，并且计算高效以实现实时部署。在过去十年中，不同的机器学习方法作为独立模型或现有技术的补充，已成为有前景的解决方案。然而，由于模型通常在现有模型的合成数据上进行训练和评估，因此将其应用于实际测量面临挑战。与此同时，在复杂的传播场景中直接在测量数据上进行训练是难以承受的，因为无法获得真实值。因此，在本文中，我们训练了一种CNN方法用于目标检测和估计，该方法在合成数据上训练并在郊区户外测量数据上进行评估。利用对环境的了解以及可用的真实位置，我们研究了我们方法的检测概率和准确性。结果表明，我们的方法在测量数据上有效，并且适用于ISAC系统中传感目标的联合检测和估计。", "summary": "本文提出了一种针对ISAC系统目标检测和估计的CNN方法，旨在解决机器学习模型在合成数据上训练后应用于实际测量数据的挑战。该方法在合成数据上进行训练，并首次在郊区户外测量数据上进行评估，以验证其在实际环境中的性能。实验结果证实，该CNN方法在实际测量数据上表现良好，适用于ISAC系统中的联合目标检测和估计。", "keywords": "ISAC系统, CNN, 目标检测, 目标估计, 测量评估", "comments": "本文的创新点在于解决了机器学习模型在无线传感领域从合成数据到实际测量数据应用的鸿沟问题。通过在合成数据上训练CNN并在真实测量数据上进行评估，证明了该方法在ISAC系统中的实用性，为未来ISAC系统的实际部署提供了有价值的参考。"}}
{"id": "2507.01876", "title": "Joint Power Control and Precoding for Cell-Free Massive MIMO Systems With Sparse Multi-Dimensional Graph Neural Networks", "authors": ["Yukun Ma", "Jiayi Zhang", "Ziheng Liu", "Guowei Shi", "Bo Ai"], "summary": "Cell-free massive multiple-input multiple-output (CF mMIMO) has emerged as a\nprominent candidate for future networks due to its ability to significantly\nenhance spectral efficiency by eliminating inter-cell interference. However,\nits practical deployment faces considerable challenges, such as high\ncomputational complexity and the optimization of its complex processing. To\naddress these challenges, this correspondence proposes a framework based on a\nsparse multi-dimensional graph neural network (SP-MDGNN), which sparsifies the\nconnections between access points (APs) and user equipments (UEs) to\nsignificantly reduce computational complexity while maintaining high\nperformance. In addition, the weighted minimum mean square error (WMMSE)\nalgorithm is introduced as a comparative method to further analyze the\ntrade-off between performance and complexity. Simulation results demonstrate\nthat the sparse method achieves an optimal balance between performance and\ncomplexity, significantly reducing the computational complexity of the original\nMDGNN method while incurring only a slight performance degradation, providing\ninsights for the practical deployment of CF mMIMO systems in large-scale\nnetwork.", "comment": "5 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.01876v1", "categories": ["cs.IT", "eess.SP", "math.IT"], "cate": "cs.IT", "url": "http://arxiv.org/abs/2507.01876v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "稀疏多维图神经网络在无蜂窝大规模MIMO系统中联合功率控制与预编码的应用", "tldr": "本文提出了一种基于稀疏多维图神经网络（SP-MDGNN）的框架，用于解决无蜂窝大规模MIMO系统中的计算复杂度和优化挑战，实现了性能与复杂度的平衡。", "motivation": "无蜂窝大规模多输入多输出（CF mMIMO）系统虽然能显著提高频谱效率，但其实际部署面临高计算复杂度和复杂处理优化等挑战。", "method": "本文提出了一种基于稀疏多维图神经网络（SP-MDGNN）的框架，通过稀疏化接入点（AP）与用户设备（UE）之间的连接来显著降低计算复杂度并保持高性能。同时，引入加权最小均方误差（WMMSE）算法作为对比方法。", "result": "仿真结果表明，稀疏方法在性能和复杂度之间取得了最佳平衡，显著降低了原始MDGNN方法的计算复杂度，同时只带来了轻微的性能下降。", "conclusion": "该研究为大规模网络中无蜂窝大规模MIMO系统的实际部署提供了见解，表明SP-MDGNN能够有效解决计算复杂性问题。", "translation": "无蜂窝大规模多输入多输出（CF mMIMO）系统因其能够通过消除小区间干扰显著提高频谱效率，已成为未来网络的突出候选。然而，其实际部署面临相当大的挑战，例如高计算复杂度和其复杂处理的优化。为了解决这些挑战，本文提出了一种基于稀疏多维图神经网络（SP-MDGNN）的框架，该框架稀疏化了接入点（AP）和用户设备（UE）之间的连接，以显著降低计算复杂度，同时保持高性能。此外，引入加权最小均方误差（WMMSE）算法作为比较方法，以进一步分析性能与复杂性之间的权衡。仿真结果表明，稀疏方法在性能和复杂性之间取得了最佳平衡，显著降低了原始MDGNN方法的计算复杂度，同时仅导致轻微的性能下降，为大规模网络中CF mMIMO系统的实际部署提供了见解。", "summary": "本文针对无蜂窝大规模MIMO（CF mMIMO）系统面临的高计算复杂度和优化难题，提出了一种基于稀疏多维图神经网络（SP-MDGNN）的框架。该方法通过稀疏化AP与UE间的连接，旨在显著降低计算复杂度的同时维持高性能。与WMMSE算法的对比分析表明，SP-MDGNN在性能和复杂度之间取得了理想的平衡，为CF mMIMO系统在大规模网络中的实际部署提供了有效途径。", "keywords": "无蜂窝MIMO, 功率控制, 预编码, 图神经网络, 稀疏化", "comments": "该论文的创新点在于将稀疏多维图神经网络应用于无蜂窝大规模MIMO系统的功率控制和预编码，有效解决了该系统部署中的计算复杂性瓶颈。其方法通过结构性稀疏化，在性能略微下降的情况下实现了计算效率的显著提升，对于推动CF mMIMO的实际应用具有重要意义。该研究为未来6G等高密度网络中的资源管理提供了新的思路。"}}
{"id": "2507.01078", "title": "yProv4ML: Effortless Provenance Tracking for Machine Learning Systems", "authors": ["Gabriele Padovani", "Valentine Anantharaj", "Sandro Fiore"], "summary": "The rapid growth of interest in large language models (LLMs) reflects their\npotential for flexibility and generalization, and attracted the attention of a\ndiverse range of researchers. However, the advent of these techniques has also\nbrought to light the lack of transparency and rigor with which development is\npursued. In particular, the inability to determine the number of epochs and\nother hyperparameters in advance presents challenges in identifying the best\nmodel. To address this challenge, machine learning frameworks such as MLFlow\ncan automate the collection of this type of information. However, these tools\ncapture data using proprietary formats and pose little attention to lineage.\nThis paper proposes yProv4ML, a framework to capture provenance information\ngenerated during machine learning processes in PROV-JSON format, with minimal\ncode modifications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01078v1", "categories": ["cs.LG", "cs.DC"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01078v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "yProv4ML：机器学习系统轻松溯源", "tldr": "yProv4ML是一个框架，旨在以最小的代码修改，将机器学习过程中生成的溯源信息捕获为PROV-JSON格式，以解决大型语言模型开发中缺乏透明度和严谨性的问题。", "motivation": "大型语言模型（LLMs）的快速增长暴露出机器学习开发中缺乏透明度和严谨性的问题，特别是在识别最佳模型时难以预先确定超参数（如epoch数量）。尽管MLFlow等现有工具可以自动化信息收集，但它们使用专有格式且不重视血缘关系，这使得溯源变得困难。", "method": "本文提出了yProv4ML框架，该框架旨在以最小的代码修改，将机器学习过程中生成的溯源信息捕获为PROV-JSON标准格式。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "大型语言模型（LLMs）的兴趣快速增长，反映了它们在灵活性和泛化方面的潜力，并吸引了众多研究人员的关注。然而，这些技术的出现也暴露了开发过程中缺乏透明度和严谨性的问题。特别是，无法预先确定epoch数量和其他超参数给识别最佳模型带来了挑战。为了解决这一挑战，MLFlow等机器学习框架可以自动化此类信息的收集。然而，这些工具使用专有格式捕获数据，并且很少关注血缘关系。本文提出了yProv4ML，这是一个框架，旨在以最小的代码修改，将机器学习过程中生成的溯源信息捕获为PROV-JSON格式。", "summary": "针对大型语言模型开发中缺乏透明度和超参数难以追踪的问题，以及现有工具使用专有格式且不重视血缘关系的局限性，本文提出了yProv4ML框架。该框架旨在以最小的代码修改，将机器学习过程中的溯源信息捕获并存储为开放的PROV-JSON格式，从而提升机器学习系统的透明度和可追溯性。", "keywords": "机器学习, 溯源, 大型语言模型, PROV-JSON, 透明度", "comments": "本文提出的yProv4ML框架通过采用开放的PROV-JSON标准来捕获机器学习过程中的溯源信息，并强调“最小代码修改”，这在解决机器学习模型，特别是大型语言模型的透明度和可复现性问题上具有创新性和实用价值。它克服了现有工具专有格式和缺乏血缘追踪的局限性，有助于提升模型开发和部署的严谨性。然而，摘要中未提及具体的实现细节、性能评估或在实际案例中的应用效果，这些将是衡量其重要性的关键。"}}
{"id": "2507.01936", "title": "The Thin Line Between Comprehension and Persuasion in LLMs", "authors": ["Adrian de Wynter", "Tangming Yuan"], "summary": "Large language models (LLMs) are excellent at maintaining high-level,\nconvincing dialogues. They are being fast deployed as chatbots and evaluators\nin sensitive areas, such as peer review and mental health applications. This,\nalong with the disparate accounts on their reasoning capabilities, calls for a\ncloser examination of LLMs and their comprehension of dialogue. In this work we\nbegin by evaluating LLMs' ability to maintain a debate--one of the purest yet\nmost complex forms of human communication. Then we measure how this capability\nrelates to their understanding of what is being talked about, namely, their\ncomprehension of dialogical structures and the pragmatic context. We find that\nLLMs are capable of maintaining coherent, persuasive debates, often swaying the\nbeliefs of participants and audiences alike. We also note that awareness or\nsuspicion of AI involvement encourage people to be more critical of the\narguments made. When polling LLMs on their comprehension of deeper structures\nof dialogue, however, they cannot demonstrate said understanding. Our findings\ntie the shortcomings of LLMs-as-evaluators to their (in)ability to understand\nthe context. More broadly, for the field of argumentation theory we posit that,\nif an agent can convincingly maintain a dialogue, it is not necessary for it to\nknow what it is talking about. Hence, the modelling of pragmatic context and\ncoherence are secondary to effectiveness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01936v1", "categories": ["cs.CL", "cs.CY"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01936v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "大型语言模型中理解与说服之间的细微界限", "tldr": "LLMs在辩论中表现出强大的说服力，能影响人类信仰，但它们并不真正理解对话深层结构和语用上下文。当人们意识到AI参与时，会变得更批判。", "motivation": "大型语言模型（LLMs）在敏感领域被快速部署，但对其推理能力存在争议，因此需要更深入地审视LLMs及其对对话的理解能力。", "method": "首先，评估LLMs维持辩论的能力，这是人类交流中最纯粹也最复杂的形式之一。然后，衡量这种能力与它们对对话内容（即对话结构和语用上下文的理解）之间的关系。研究还探讨了人们在意识到AI参与时对论点的批判性。", "result": "LLMs能够进行连贯且有说服力的辩论，常常能影响参与者和观众的信念。当人们意识到AI参与时，会更批判性地看待论点。然而，LLMs无法展示对对话深层结构的理解。", "conclusion": "LLMs作为评估者的不足在于它们无法理解语境。如果一个智能体能有说服力地维持对话，它不一定需要真正理解它在说什么。因此，语用上下文和连贯性的建模对于有效性而言是次要的。", "translation": "大型语言模型（LLMs）擅长维持高水平、有说服力的对话。它们正被快速部署到敏感领域，如同行评审和心理健康应用中，作为聊天机器人和评估者。这一点，以及对其推理能力的不同描述，促使人们需要更仔细地审视LLMs及其对对话的理解。在这项工作中，我们首先评估了LLMs维持辩论的能力——这是人类交流中最纯粹但也最复杂的形式之一。然后，我们衡量了这种能力与它们对所谈论内容的理解之间的关系，即它们对对话结构和语用上下文的理解。我们发现LLMs能够进行连贯且有说服力的辩论，常常能影响参与者和观众的信念。我们还注意到，对AI参与的意识或怀疑会促使人们对所提出的论点更加批判。然而，当对LLMs进行关于它们对对话深层结构理解的调查时，它们无法展示出这种理解。我们的发现将LLMs作为评估者的不足归因于它们（不）理解语境的能力。更广泛地说，对于论辩理论领域，我们认为，如果一个智能体能够有说服力地维持对话，它不一定需要知道它在说什么。因此，语用上下文和连贯性的建模对于有效性而言是次要的。", "summary": "本研究探讨了大型语言模型（LLMs）在对话中的说服力与理解力之间的关系。研究通过评估LLMs在辩论中的表现发现，它们能够进行连贯且有说服力的辩论，甚至影响人类信仰，但并不能真正理解对话的深层结构和语用上下文。同时，当人们意识到AI参与时，会更批判性地评估论点。研究指出，LLMs作为评估者的局限性源于其对语境理解的不足，并提出对于论辩而言，说服力可能比真正的理解更为关键。", "keywords": "大型语言模型, 说服力, 理解, 辩论, 语用上下文", "comments": "这项研究揭示了LLMs在复杂人机交互中的一个关键局限：它们可以有效地说服和维持对话，但这种能力并非基于真正的语境理解。这对于LLMs在敏感领域的应用提出了重要警示，强调了在部署这些技术时需要考虑其深层理解的不足。研究的创新之处在于通过辩论这一形式来探究LLMs的理解与说服力，并提出了“有效性不依赖于理解”这一深刻观点，对论辩理论亦有贡献。"}}
{"id": "2507.01794", "title": "Robust brain age estimation from structural MRI with contrastive learning", "authors": ["Carlo Alberto Barbano", "Benoit Dufumier", "Edouard Duchesnay", "Marco Grangetto", "Pietro Gori"], "summary": "Estimating brain age from structural MRI has emerged as a powerful tool for\ncharacterizing normative and pathological aging. In this work, we explore\ncontrastive learning as a scalable and robust alternative to supervised\napproaches for brain age estimation. We introduce a novel contrastive loss\nfunction, $\\mathcal{L}^{exp}$, and evaluate it across multiple public\nneuroimaging datasets comprising over 20,000 scans. Our experiments reveal four\nkey findings. First, scaling pre-training on diverse, multi-site data\nconsistently improves generalization performance, cutting external mean\nabsolute error (MAE) nearly in half. Second, $\\mathcal{L}^{exp}$ is robust to\nsite-related confounds, maintaining low scanner-predictability as training size\nincreases. Third, contrastive models reliably capture accelerated aging in\npatients with cognitive impairment and Alzheimer's disease, as shown through\nbrain age gap analysis, ROC curves, and longitudinal trends. Lastly, unlike\nsupervised baselines, $\\mathcal{L}^{exp}$ maintains a strong correlation\nbetween brain age accuracy and downstream diagnostic performance, supporting\nits potential as a foundation model for neuroimaging. These results position\ncontrastive learning as a promising direction for building generalizable and\nclinically meaningful brain representations.", "comment": "11 pages", "pdf_url": "http://arxiv.org/pdf/2507.01794v1", "categories": ["eess.IV", "cs.CV", "68T07", "I.2.6"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01794v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于对比学习的结构MRI鲁棒脑龄估计", "tldr": "该研究提出了一种基于对比学习的新型损失函数 $\\mathcal{L}^{exp}$，用于从结构MRI图像中鲁棒地估计脑龄。实验证明，该方法在多个数据集上表现出更好的泛化能力和对站点混杂因素的鲁棒性，并能有效捕捉认知障碍患者的加速衰老，同时保持脑龄准确性与诊断性能的强相关性。", "motivation": "从结构MRI估计脑龄已成为表征正常和病理老化的一种强大工具。本研究旨在探索对比学习作为监督方法的替代方案，以实现可扩展且鲁棒的脑龄估计。", "method": "本研究探索了对比学习作为脑龄估计的替代方法，并引入了一种新型对比损失函数 $\\mathcal{L}^{exp}$。该方法在包含超过20,000次扫描的多个公共神经影像数据集上进行了评估，并与监督基线方法进行了比较。", "result": "1. 在多样化、多站点数据上进行大规模预训练显著提高了泛化性能，外部平均绝对误差（MAE）几乎减半。2. $\\mathcal{L}^{exp}$ 对站点相关混杂因素具有鲁棒性，随着训练规模的增加，扫描仪可预测性保持在较低水平。3. 对比模型通过脑龄差距分析、ROC曲线和纵向趋势，可靠地捕捉到认知障碍和阿尔茨海默病患者的加速衰老。4. 与监督基线不同，$\\mathcal{L}^{exp}$ 保持了脑龄准确性与下游诊断性能之间的强相关性。", "conclusion": "对比学习为构建可泛化且具有临床意义的脑表征提供了一个有前景的方向，尤其是在脑龄估计方面。", "translation": "从结构MRI估计脑龄已成为表征正常和病理老化的一种强大工具。在这项工作中，我们探索了对比学习作为监督方法的一种可扩展且鲁棒的替代方案，用于脑龄估计。我们引入了一种新型对比损失函数 $\\mathcal{L}^{exp}$，并在包含超过20,000次扫描的多个公共神经影像数据集上对其进行了评估。我们的实验揭示了四个关键发现。首先，在多样化、多站点数据上进行大规模预训练持续提高了泛化性能，使外部平均绝对误差（MAE）几乎减半。其次，$\\mathcal{L}^{exp}$ 对站点相关混杂因素具有鲁棒性，随着训练规模的增加，扫描仪可预测性保持在较低水平。第三，通过脑龄差距分析、ROC曲线和纵向趋势显示，对比模型可靠地捕捉到认知障碍和阿尔茨海默病患者的加速衰老。最后，与监督基线不同，$\\mathcal{L}^{exp}$ 保持了脑龄准确性与下游诊断性能之间的强相关性，这支持了其作为神经影像基础模型的潜力。这些结果表明对比学习是构建可泛化且具有临床意义的脑表征的一个有前景的方向。", "summary": "本研究提出了一种基于对比学习的新型损失函数 $\\mathcal{L}^{exp}$，用于从结构MRI图像中鲁棒地估计脑龄。该方法在多达20,000次扫描的公共数据集上进行了验证，结果表明其在泛化能力、对站点混杂因素的鲁棒性以及捕捉认知障碍患者加速衰老方面优于传统监督方法。此外，该模型在脑龄准确性与诊断性能之间保持了强相关性，凸显了对比学习在神经影像领域构建通用且临床有意义的脑表征的巨大潜力。", "keywords": "脑龄估计, 对比学习, 结构MRI, 鲁棒性, 泛化能力", "comments": "该论文的创新点在于将对比学习引入脑龄估计领域，并提出了一种新型损失函数 $\\mathcal{L}^{exp}$。其重要性体现在解决了传统监督方法在泛化能力和对站点混杂因素鲁棒性方面的局限性。通过大规模数据集的验证，展示了对比学习在构建可泛化和临床有意义的神经影像基础模型方面的巨大潜力，对于神经退行性疾病的早期诊断和研究具有重要意义。"}}
{"id": "2507.01567", "title": "Time-Varying Coverage Control: A Distributed Tracker-Planner MPC Framework", "authors": ["Patrick Benito Eberhard", "Johannes Köhler", "Oliver Hüsser", "Melanie N. Zeilinger", "Andrea Carron"], "summary": "Time-varying coverage control addresses the challenge of coordinating\nmultiple agents covering an environment where regions of interest change over\ntime. This problem has broad applications, including the deployment of\nautonomous taxis and coordination in search and rescue operations. The\nachievement of effective coverage is complicated by the presence of\ntime-varying density functions, nonlinear agent dynamics, and stringent system\nand safety constraints. In this paper, we present a distributed multi-agent\ncontrol framework for time-varying coverage under nonlinear constrained\ndynamics. Our approach integrates a reference trajectory planner and a tracking\nmodel predictive control (MPC) scheme, which operate at different frequencies\nwithin a multi-rate framework. For periodic density functions, we demonstrate\nclosed-loop convergence to an optimal configuration of trajectories and provide\nformal guarantees regarding constraint satisfaction, collision avoidance, and\nrecursive feasibility. Additionally, we propose an efficient algorithm capable\nof handling nonperiodic density functions, making the approach suitable for\npractical applications. Finally, we validate our method through hardware\nexperiments using a fleet of four miniature race cars.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01567v1", "categories": ["eess.SY", "cs.RO", "cs.SY"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01567v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "时变覆盖控制：一种分布式跟踪-规划器MPC框架", "tldr": "本文提出了一种分布式多智能体控制框架，用于在非线性受限动态下实现时变覆盖控制，并通过硬件实验进行了验证。", "motivation": "解决多智能体在兴趣区域随时间变化的环境中进行协调覆盖的挑战，该问题在自动出租车部署和搜救等领域有广泛应用，但面临时变密度函数、非线性智能体动力学和严格的系统与安全约束等复杂性。", "method": "提出了一种分布式多智能体控制框架，该框架整合了参考轨迹规划器和跟踪模型预测控制（MPC）方案，并在一个多速率框架内以不同频率运行。", "result": "对于周期性密度函数，证明了闭环收敛到最优轨迹配置，并提供了约束满足、避碰和递归可行性的正式保证。此外，提出了处理非周期性密度函数的高效算法。通过四辆微型赛车的硬件实验验证了方法的有效性。", "conclusion": "本文成功提出并验证了一种分布式多智能体控制框架，能够有效解决在非线性受限动态下的时变覆盖控制问题，并为周期性和非周期性密度函数提供了理论和实践上的解决方案。", "translation": "时变覆盖控制解决了协调多个智能体覆盖兴趣区域随时间变化的环境的挑战。这个问题具有广泛的应用，包括自动出租车的部署和搜救行动中的协调。由于存在时变密度函数、非线性智能体动力学以及严格的系统和安全约束，实现有效覆盖变得复杂。在本文中，我们提出了一种在非线性受限动态下进行时变覆盖的分布式多智能体控制框架。我们的方法整合了一个参考轨迹规划器和一个跟踪模型预测控制（MPC）方案，它们在一个多速率框架内以不同的频率运行。对于周期性密度函数，我们展示了闭环收敛到最优轨迹配置，并提供了关于约束满足、避碰和递归可行性的正式保证。此外，我们提出了一种能够处理非周期性密度函数的高效算法，使得该方法适用于实际应用。最后，我们通过使用四辆微型赛车进行的硬件实验验证了我们的方法。", "summary": "本文提出了一种用于时变覆盖控制的分布式多智能体控制框架，旨在解决智能体在兴趣区域随时间变化的环境中进行协调覆盖的挑战。该框架结合了参考轨迹规划器和多速率跟踪模型预测控制（MPC）方案，能够处理非线性受限动态。研究证明了其在周期性密度函数下的闭环收敛性，并提供了约束满足、避碰和递归可行性的保证。此外，还提出了处理非周期性密度函数的高效算法，并通过小型赛车硬件实验验证了方法的有效性。", "keywords": "时变覆盖控制, 分布式控制, 模型预测控制, 多智能体系统, 轨迹规划", "comments": "该论文的创新点在于将参考轨迹规划与多速率模型预测控制相结合，以解决多智能体在复杂、时变和受限环境下的覆盖控制问题。其重要性体现在为自动出租车和搜救等实际应用提供了理论和实践上的解决方案，并通过硬件实验验证了方法的有效性和鲁棒性，弥补了现有方法在非线性动态和严格约束处理上的不足。"}}
{"id": "2507.01334", "title": "Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs", "authors": ["Nifu Dan", "Yujun Cai", "Yiwei Wang"], "summary": "Navigating the complexities of physics reasoning has long been a difficult\ntask for Large Language Models (LLMs), requiring a synthesis of profound\nconceptual understanding and adept problem-solving techniques. In this study,\nwe investigate the application of advanced instruction-tuned reasoning models,\nsuch as Deepseek-R1, to address a diverse spectrum of physics problems curated\nfrom the challenging SciBench benchmark. Our comprehensive experimental\nevaluation reveals the remarkable capabilities of reasoning models. Not only do\nthey achieve state-of-the-art accuracy in answering intricate physics\nquestions, but they also generate distinctive reasoning patterns that emphasize\non symbolic derivation. Furthermore, our findings indicate that even for these\nhighly sophisticated reasoning models, the strategic incorporation of few-shot\nprompting can still yield measurable improvements in overall accuracy,\nhighlighting the potential for continued performance gains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01334v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01334v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "符号化还是数值化？理解推理LLMs中的物理问题解决", "tldr": "大型语言模型（LLMs）在解决物理问题方面表现出卓越的能力，尤其擅长符号推导，并且少样本提示能进一步提升其准确性。", "motivation": "大型语言模型（LLMs）在处理复杂的物理推理方面长期以来一直面临挑战，需要深厚的概念理解和熟练的问题解决技巧。", "method": "本研究调查了先进的指令调优推理模型（如Deepseek-R1）在解决来自SciBench基准测试的各种物理问题中的应用。通过全面的实验评估，研究还探讨了少样本提示对模型性能的影响。", "result": "推理模型在回答复杂的物理问题上达到了最先进的准确性，并生成了强调符号推导的独特推理模式。研究发现，即使对于高度复杂的推理模型，策略性地结合少样本提示仍能带来整体准确性的可衡量提升。", "conclusion": "即使是高度复杂的推理模型，策略性地结合少样本提示也能带来可衡量的性能提升，突显了持续性能提升的潜力。推理模型在物理问题解决方面展现出卓越的能力。", "translation": "大型语言模型（LLMs）在处理物理推理的复杂性方面长期以来一直是一项艰巨的任务，需要深刻的概念理解和熟练的问题解决技术相结合。在本研究中，我们调查了先进的指令调优推理模型（例如Deepseek-R1）在解决来自具有挑战性的SciBench基准测试的各种物理问题中的应用。我们全面的实验评估揭示了推理模型卓越的能力。它们不仅在回答复杂的物理问题上达到了最先进的准确性，而且还生成了强调符号推导的独特推理模式。此外，我们的发现表明，即使对于这些高度复杂的推理模型，策略性地结合少样本提示仍然可以带来整体准确性的可衡量提升，突显了持续性能提升的潜力。", "summary": "本研究探讨了指令调优推理LLMs（如Deepseek-R1）在解决SciBench物理问题上的表现。结果表明，这些模型不仅在准确性上达到最先进水平，还展现了独特的符号推导推理模式。此外，研究发现少样本提示能进一步提高模型的整体准确性，表明仍有性能提升空间。", "keywords": "物理推理, 大型语言模型, 符号推导, 少样本提示, SciBench", "comments": "这项研究展示了指令调优LLMs在物理推理领域的显著进步，尤其是在处理符号推导方面的能力。强调少样本提示的持续有效性，即便对于先进模型，也为LLM性能优化提供了实用方向。其创新性在于深入探究了LLMs在物理问题解决中“符号化或数值化”的内在推理机制。"}}
{"id": "2507.01736", "title": "An energy-based discontinuous Galerkin method for the wave equation with nonsmooth solutions", "authors": ["Yangxin Fu", "Yan Jiang", "Siyang Wang"], "summary": "We develop a stable and high-order accurate discontinuous Galerkin method for\nthe second order wave equation, specifically designed to handle nonsmooth\nsolutions. Our approach integrates the energy-based discontinuous Galerkin\nmethod with the oscillation-free technique to effectively suppress spurious\noscillations near solution discontinuities. Both stability analysis and apriori\nerror estimates are established for common choices of numerical fluxes. We\npresent a series of numerical experiments to confirm the optimal convergence\nrates for smooth solutions and its robustness in maintaining oscillation-free\nbehavior for nonsmooth solutions in wave equations without or with nonlinear\nsource terms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01736v1", "categories": ["math.NA", "cs.NA"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01736v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "一种基于能量的不连续Galerkin方法，用于处理非光滑解的波动方程", "tldr": "本文提出了一种稳定的高阶不连续Galerkin方法，结合能量基方法和无振荡技术，有效处理波动方程中的非光滑解，并展示了其在光滑解上的最优收敛性和在非光滑解上的鲁棒性。", "motivation": "开发一种稳定且高阶精确的不连续Galerkin方法，专门用于处理波动方程中的非光滑解，并有效抑制解不连续点附近的虚假振荡。", "method": "本方法将基于能量的不连续Galerkin方法与无振荡技术相结合，以有效抑制解不连续点附近的虚假振荡。对常用数值通量建立了稳定性分析和先验误差估计。", "result": "建立了常用数值通量的稳定性分析和先验误差估计。数值实验证实了光滑解的最优收敛率，以及在有或没有非线性源项的波动方程中，对于非光滑解保持无振荡行为的鲁棒性。", "conclusion": "本文提出的基于能量的不连续Galerkin方法结合无振荡技术，能够稳定、高阶精确地处理含有非光滑解的波动方程，并有效抑制虚假振荡，具有良好的收敛性和鲁棒性。", "translation": "我们开发了一种稳定且高阶精确的二阶波动方程不连续Galerkin方法，专门用于处理非光滑解。我们的方法将基于能量的不连续Galerkin方法与无振荡技术相结合，以有效抑制解不连续点附近的虚假振荡。对常用数值通量建立了稳定性分析和先验误差估计。我们进行了一系列数值实验，以证实其在光滑解上的最优收敛率，以及在有或没有非线性源项的波动方程中，对于非光滑解保持无振荡行为的鲁棒性。", "summary": "本文提出了一种处理波动方程中非光滑解的稳定高阶不连续Galerkin方法。该方法结合了能量基不连续Galerkin方法与无振荡技术，有效抑制了虚假振荡。研究建立了稳定性分析和误差估计，并通过数值实验验证了其对光滑解的最优收敛性以及对非光滑解的无振荡鲁棒性。", "keywords": "不连续Galerkin方法, 波动方程, 非光滑解, 能量基方法, 无振荡技术", "comments": "该论文的创新点在于将基于能量的不连续Galerkin方法与无振荡技术相结合，以有效处理波动方程中的非光滑解，这对于数值模拟中常见的间断或激波问题具有重要意义。理论分析和数值验证的结合增强了方法的可靠性。"}}
{"id": "2507.01821", "title": "Low-Complexity Neural Wind Noise Reduction for Audio Recordings", "authors": ["Hesam Eftekhari", "Srikanth Raj Chetupalli", "Shrishti Saha Shetu", "Emanuël A. P. Habets", "Oliver Thiergart"], "summary": "Wind noise significantly degrades the quality of outdoor audio recordings,\nyet remains difficult to suppress in real-time on resource-constrained devices.\nIn this work, we propose a low-complexity single-channel deep neural network\nthat leverages the spectral characteristics of wind noise. Experimental results\nshow that our method achieves performance comparable to the state-of-the-art\nlow-complexity ULCNet model. The proposed model, with only 249K parameters and\nroughly 73 MHz of computational power, is suitable for embedded and mobile\naudio applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01821v1", "categories": ["eess.AS", "cs.SD", "eess.SP"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01821v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "低复杂度神经网络风噪声消除在音频录制中的应用", "tldr": "提出了一种低复杂度的单通道深度神经网络，用于消除户外音频录制中的风噪声，其性能与现有技术相当，且适用于资源受限设备。", "motivation": "户外音频录制中的风噪声显著降低音质，且在资源受限设备上难以实时抑制。", "method": "提出了一种低复杂度的单通道深度神经网络，该网络利用风噪声的频谱特性。", "result": "该方法达到了与最先进的低复杂度ULCNet模型相当的性能。所提出的模型参数量仅为249K，计算功耗约为73 MHz。", "conclusion": "提出的低复杂度神经网络模型适用于嵌入式和移动音频应用，能有效抑制风噪声。", "translation": "风噪声显著降低了户外音频录制的质量，但在资源受限设备上实时抑制仍然很困难。在这项工作中，我们提出了一种低复杂度的单通道深度神经网络，该网络利用了风噪声的频谱特性。实验结果表明，我们的方法达到了与最先进的低复杂度ULCNet模型相当的性能。所提出的模型，仅有249K个参数和大约73 MHz的计算功耗，适用于嵌入式和移动音频应用。", "summary": "本文提出了一种低复杂度的单通道深度神经网络，专门用于户外音频录制中的风噪声抑制。该网络利用风噪声的频谱特性，并在实验中表现出与现有先进模型ULCNet相当的性能。其小巧的参数量（249K）和低计算功耗（73 MHz）使其非常适合在资源受限的嵌入式和移动设备上部署。", "keywords": "风噪声消除, 深度神经网络, 低复杂度, 音频处理, 嵌入式设备", "comments": "该研究的创新点在于提出了一个参数量和计算功耗极低的神经网络模型，使其能够在资源受限的设备上实时运行，解决了风噪声抑制在实际应用中的一大挑战。其重要性在于为户外音频录制提供了实用的风噪声解决方案。"}}
{"id": "2507.01285", "title": "Far From Sight, Far From Mind: Inverse Distance Weighting for Graph Federated Recommendation", "authors": ["Aymen Rayane Khouas", "Mohamed Reda Bouadjenek", "Hakim Hacid", "Sunil Aryal"], "summary": "Graph federated recommendation systems offer a privacy-preserving alternative\nto traditional centralized recommendation architectures, which often raise\nconcerns about data security. While federated learning enables personalized\nrecommendations without exposing raw user data, existing aggregation methods\noverlook the unique properties of user embeddings in this setting. Indeed,\ntraditional aggregation methods fail to account for their complexity and the\ncritical role of user similarity in recommendation effectiveness. Moreover,\nevolving user interactions require adaptive aggregation while preserving the\ninfluence of high-relevance anchor users (the primary users before expansion in\ngraph-based frameworks). To address these limitations, we introduce\nDist-FedAvg, a novel distance-based aggregation method designed to enhance\npersonalization and aggregation efficiency in graph federated learning. Our\nmethod assigns higher aggregation weights to users with similar embeddings,\nwhile ensuring that anchor users retain significant influence in local updates.\nEmpirical evaluations on multiple datasets demonstrate that Dist-FedAvg\nconsistently outperforms baseline aggregation techniques, improving\nrecommendation accuracy while maintaining seamless integration into existing\nfederated learning frameworks.", "comment": "17 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.01285v1", "categories": ["cs.LG", "cs.DC", "cs.IR"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01285v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "眼不见心不烦：图联邦推荐中的逆距离加权", "tldr": "现有的图联邦推荐聚合方法忽略了用户嵌入特性和用户相似性。本文提出了Dist-FedAvg，一种基于距离的聚合方法，通过赋予相似用户更高的权重并保留锚点用户的影响力，从而提高了推荐准确性。", "motivation": "传统的集中式推荐架构存在数据安全隐患。现有的联邦学习聚合方法忽略了用户嵌入的独特属性，未能考虑其复杂性以及用户相似性在推荐效果中的关键作用。此外，不断演变的用户交互需要自适应聚合，同时还要保留高相关性锚点用户（图基框架中扩展前的主要用户）的影响力。", "method": "本文引入了Dist-FedAvg，一种新颖的基于距离的聚合方法，旨在增强图联邦学习中的个性化和聚合效率。该方法为具有相似嵌入的用户分配更高的聚合权重，同时确保锚点用户在局部更新中保留显著影响力。", "result": "在多个数据集上的实证评估表明，Dist-FedAvg始终优于基线聚合技术，提高了推荐准确性，同时保持了与现有联邦学习框架的无缝集成。", "conclusion": "Dist-FedAvg通过利用用户相似性和锚点用户的影响力，有效解决了现有联邦推荐聚合方法的局限性，从而提高了推荐准确性和效率。", "translation": "图联邦推荐系统为传统的集中式推荐架构提供了一种保护隐私的替代方案，后者常常引发数据安全担忧。尽管联邦学习能够在不暴露原始用户数据的情况下实现个性化推荐，但现有的聚合方法忽略了用户嵌入在此设置中的独特属性。事实上，传统聚合方法未能考虑其复杂性以及用户相似性在推荐效果中的关键作用。此外，不断演变的用户交互需要自适应聚合，同时还要保留高相关性锚点用户（图基框架中扩展前的主要用户）的影响力。为了解决这些局限性，我们引入了Dist-FedAvg，一种新颖的基于距离的聚合方法，旨在增强图联邦学习中的个性化和聚合效率。我们的方法为具有相似嵌入的用户分配更高的聚合权重，同时确保锚点用户在局部更新中保留显著影响力。在多个数据集上的实证评估表明，Dist-FedAvg始终优于基线聚合技术，提高了推荐准确性，同时保持了与现有联邦学习框架的无缝集成。", "summary": "图联邦推荐系统提供了保护隐私的替代方案，但现有聚合方法忽略了用户嵌入的特性和用户相似性的关键作用。本文提出Dist-FedAvg，一种新颖的基于距离的聚合方法，它根据用户嵌入相似性分配权重，并保留锚点用户的影响力。实验证明，Dist-FedAvg在多个数据集上均优于基线方法，提高了推荐准确性。", "keywords": "图联邦推荐, 逆距离加权, 联邦学习, 用户相似性, 聚合", "comments": "本文的创新点在于针对图联邦推荐中用户嵌入聚合的独特挑战，提出了一种基于距离加权的方法。这种方法通过考虑用户相似性，提升了联邦学习环境下的个性化和聚合效率，对于在保护隐私的同时提高推荐系统性能具有重要意义。"}}
{"id": "2507.01710", "title": "Towards Better Attribute Inference Vulnerability Measures", "authors": ["Paul Francis", "David Wagner"], "summary": "The purpose of anonymizing structured data is to protect the privacy of\nindividuals in the data while retaining the statistical properties of the data.\nAn important class of attack on anonymized data is attribute inference, where\nan attacker infers the value of an unknown attribute of a target individual\ngiven knowledge of one or more known attributes. A major limitation of recent\nattribute inference measures is that they do not take recall into account, only\nprecision. It is often the case that attacks target only a fraction of\nindividuals, for instance data outliers. Incorporating recall, however,\nsubstantially complicates the measure, because one must determine how to\ncombine recall and precision in a composite measure for both the attack and\nbaseline. This paper presents the design and implementation of an attribute\ninference measure that incorporates both precision and recall. Our design also\nimproves on how the baseline attribute inference is computed. In experiments\nusing a generic best row match attack on moderately-anonymized microdata, we\nshow that in over 25\\% of the attacks, our approach correctly labeled the\nattack to be at risk while the prior approach incorrectly labeled the attack to\nbe safe.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01710v1", "categories": ["cs.CR"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01710v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "迈向更好的属性推断漏洞度量", "tldr": "现有属性推断度量方法仅考虑精确率，忽略召回率，导致风险低估。本文提出一种新的度量方法，同时纳入精确率和召回率，并改进基线计算，实验证明能更准确地识别存在风险的攻击。", "motivation": "现有属性推断度量方法的主要局限在于只考虑精确率而不考虑召回率，这可能导致攻击被错误地标记为安全。", "method": "本文提出并实现了一种结合精确率和召回率的属性推断度量方法。该设计还改进了基线属性推断的计算方式。", "result": "在对适度匿名化的微观数据进行实验时，发现超过25%的攻击中，本文提出的方法正确地将攻击标记为存在风险，而先前的方法错误地将攻击标记为安全。", "conclusion": "通过结合精确率和召回率并改进基线计算，本文提出的属性推断度量方法比现有方法能更准确地评估匿名化数据的漏洞风险。", "translation": "匿名化结构化数据的目的是在保留数据统计特性的同时保护数据中个体的隐私。对匿名化数据的一种重要攻击是属性推断，攻击者在已知一个或多个属性的情况下推断目标个体的未知属性值。最近的属性推断度量的一个主要局限性是它们只考虑精确率（precision）而不考虑召回率（recall）。通常情况下，攻击只针对一小部分个体，例如数据异常值。然而，纳入召回率会使度量大大复杂化，因为必须确定如何在攻击和基线场景的综合度量中结合召回率和精确率。本文提出了一种结合精确率和召回率的属性推断度量的设计和实现。我们的设计还改进了基线属性推断的计算方式。在使用通用最佳行匹配攻击对适度匿名化的微观数据进行的实验中，我们发现超过25%的攻击中，我们的方法正确地将攻击标记为存在风险，而先前的方法错误地将攻击标记为安全。", "summary": "本文针对现有属性推断漏洞度量方法仅考虑精确率而忽略召回率的局限性，提出了一种新的属性推断度量方法。该方法在设计上整合了精确率和召回率，并优化了基线推断的计算方式。实验结果表明，与现有方法相比，新方法能更准确地识别出潜在的攻击风险，在超过25%的攻击案例中，新方法能正确地将攻击标记为存在风险，而现有方法则错误地标记为安全。", "keywords": "属性推断, 隐私保护, 数据匿名化, 精确率, 召回率", "comments": "该论文的创新点在于提出了一个更全面的属性推断漏洞度量方法，通过同时考虑精确率和召回率，克服了现有方法的局限性。这对于评估匿名化数据的隐私保护水平具有重要意义，尤其是在攻击可能只针对部分敏感个体的情况下。改进基线计算也提升了度量的准确性。"}}
{"id": "2507.01342", "title": "Learning Camera-Agnostic White-Balance Preferences", "authors": ["Luxi Zhao", "Mahmoud Afifi", "Michael S. Brown"], "summary": "The image signal processor (ISP) pipeline in modern cameras consists of\nseveral modules that transform raw sensor data into visually pleasing images in\na display color space. Among these, the auto white balance (AWB) module is\nessential for compensating for scene illumination. However, commercial AWB\nsystems often strive to compute aesthetic white-balance preferences rather than\naccurate neutral color correction. While learning-based methods have improved\nAWB accuracy, they typically struggle to generalize across different camera\nsensors -- an issue for smartphones with multiple cameras. Recent work has\nexplored cross-camera AWB, but most methods remain focused on achieving neutral\nwhite balance. In contrast, this paper is the first to address aesthetic\nconsistency by learning a post-illuminant-estimation mapping that transforms\nneutral illuminant corrections into aesthetically preferred corrections in a\ncamera-agnostic space. Once trained, our mapping can be applied after any\nneutral AWB module to enable consistent and stylized color rendering across\nunseen cameras. Our proposed model is lightweight -- containing only $\\sim$500\nparameters -- and runs in just 0.024 milliseconds on a typical flagship mobile\nCPU. Evaluated on a dataset of 771 smartphone images from three different\ncameras, our method achieves state-of-the-art performance while remaining fully\ncompatible with existing cross-camera AWB techniques, introducing minimal\ncomputational and memory overhead.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01342v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01342v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "学习相机无关的白平衡偏好", "tldr": "本文提出了一种轻量级的相机无关映射方法，可以将中性白平衡校正转换为美学偏好的校正，从而在不同相机上实现一致且风格化的色彩渲染。", "motivation": "现有的学习型自动白平衡（AWB）方法难以在不同相机传感器之间泛化，尤其对于多摄像头的智能手机而言。此外，大多数跨相机AWB方法仍侧重于实现中性白平衡，而不是美学偏好。", "method": "本文提出了一种新的方法，首次通过学习一个后光照估计映射来解决美学一致性问题。该映射将中性光照校正转换为相机无关空间中的美学偏好校正。训练完成后，该映射可以应用于任何中性AWB模块之后，以实现对未见相机的持续和风格化色彩渲染。", "result": "该模型轻量级（约500个参数），在典型的旗舰移动CPU上仅需0.024毫秒。在包含来自三种不同相机的771张智能手机图像数据集上进行评估，该方法在保持与现有跨相机AWB技术完全兼容的同时，实现了最先进的性能，并引入了最小的计算和内存开销。", "conclusion": "本文提出的轻量级相机无关映射方法能够将中性白平衡校正转换为美学偏好校正，从而在不同相机上实现一致且风格化的色彩渲染，并在性能和效率方面表现出色。", "translation": "现代相机中的图像信号处理器（ISP）管道由多个模块组成，这些模块将原始传感器数据转换为显示色彩空间中视觉上令人愉悦的图像。其中，自动白平衡（AWB）模块对于补偿场景光照至关重要。然而，商业AWB系统通常致力于计算美学白平衡偏好，而不是精确的中性色彩校正。虽然基于学习的方法提高了AWB精度，但它们通常难以在不同相机传感器之间泛化——这对于具有多个摄像头的智能手机来说是一个问题。最近的工作已经探索了跨相机AWB，但大多数方法仍然专注于实现中性白平衡。与此相反，本文首次通过学习一个后光照估计映射来解决美学一致性问题，该映射将中性光照校正转换为相机无关空间中的美学偏好校正。一旦训练完成，我们的映射可以应用于任何中性AWB模块之后，以实现在未见相机上的一致和风格化的色彩渲染。我们提出的模型是轻量级的——只包含约500个参数——并且在典型的旗舰移动CPU上仅需0.024毫秒运行。在包含来自三种不同相机的771张智能手机图像数据集上进行评估，我们的方法在保持与现有跨相机AWB技术完全兼容的同时，实现了最先进的性能，并引入了最小的计算和内存开销。", "summary": "本文提出了一种新颖的、轻量级的相机无关映射方法，旨在解决多摄像头设备中自动白平衡（AWB）的美学一致性问题。该方法通过学习将中性光照校正转换为美学偏好校正，从而在不同相机上实现一致且风格化的色彩渲染。该模型参数少、运行速度快，并在智能手机图像数据集上展现了最先进的性能，同时与现有跨相机AWB技术兼容且计算开销极小。", "keywords": "白平衡, 相机无关, 美学偏好, 图像信号处理器, 深度学习", "comments": "该论文的创新点在于首次提出了通过学习相机无关的后光照估计映射来解决AWB的美学一致性问题，而非仅仅追求中性白平衡。其轻量级模型设计和高效的运行速度使其在移动设备上具有很高的实用价值。此外，该方法与现有跨相机AWB技术的兼容性也增强了其实用性。"}}
{"id": "2507.01776", "title": "Human-Machine Collaboration-Guided Space Design: Combination of Machine Learning Models and Humanistic Design Concepts", "authors": ["Yuxuan Yang"], "summary": "The integration of machine learning (ML) into spatial design holds immense\npotential for optimizing space utilization, enhancing functionality, and\nstreamlining design processes. ML can automate tasks, predict performance\noutcomes, and tailor spaces to user preferences. However, the emotional,\ncultural, and aesthetic dimensions of design remain crucial for creating spaces\nthat truly resonate with users-elements that ML alone cannot address. The key\nchallenge lies in harmonizing data-driven efficiency with the nuanced,\nsubjective aspects of design. This paper proposes a human-machine collaboration\nframework to bridge this gap. An effective framework should recognize that\nwhile ML enhances design efficiency through automation and prediction, it must\nbe paired with human creativity to ensure spaces are emotionally engaging and\nculturally relevant. Human designers contribute intuition, empathy, and\ncultural insight, guiding ML-generated solutions to align with users' emotional\nand cultural needs. Additionally, we explore how various ML models can be\nintegrated with human-centered design principles. These models can automate\ndesign generation and optimization, while human designers refine the outputs to\nensure emotional resonance and aesthetic appeal. Through case studies in office\nand residential design, we illustrate how this framework fosters both\ncreativity and cultural relevance. By merging ML with human creativity, spatial\ndesign can achieve a balance of efficiency and emotional impact, resulting in\nenvironments that are both functional and deeply human.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01776v1", "categories": ["cs.HC", "cs.MM"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01776v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "人机协作引导的空间设计：机器学习模型与人文设计理念的结合", "tldr": "本文提出了一种人机协作框架，将机器学习的效率与人类设计师的创造力相结合，以创建功能性强且情感丰富的空间设计。", "motivation": "机器学习在空间设计中潜力巨大，但无法解决情感、文化和美学维度的问题。关键挑战在于协调数据驱动的效率与设计的主观性。", "method": "本文提出一个人机协作框架，将机器学习模型与以人为中心的设计原则相结合。机器学习负责自动化设计生成和优化，人类设计师则进行精炼以确保情感共鸣和美学吸引力。通过办公和住宅设计的案例研究进行说明。", "result": "通过案例研究展示了该框架如何促进创造性和文化相关性。", "conclusion": "通过融合机器学习与人类创造力，空间设计可以实现效率与情感影响的平衡，从而创造出既实用又具深厚人性的环境。", "translation": "机器学习（ML）融入空间设计在优化空间利用、增强功能性和简化设计流程方面具有巨大潜力。ML可以自动化任务、预测性能结果，并根据用户偏好定制空间。然而，设计的情感、文化和美学维度对于创造真正与用户产生共鸣的空间至关重要——这些是仅靠ML无法解决的元素。关键挑战在于协调数据驱动的效率与设计的细微、主观方面。本文提出一个人机协作框架来弥合这一差距。一个有效的框架应该认识到，虽然ML通过自动化和预测提高了设计效率，但它必须与人类创造力相结合，以确保空间具有情感吸引力和文化相关性。人类设计师贡献直觉、同理心和文化洞察力，指导ML生成的解决方案与用户的情感和文化需求保持一致。此外，我们探讨了如何将各种ML模型与以人为中心的设计原则相结合。这些模型可以自动化设计生成和优化，而人类设计师则对输出进行精炼，以确保情感共鸣和美学吸引力。通过办公和住宅设计的案例研究，我们阐述了该框架如何促进创造性和文化相关性。通过将ML与人类创造力融合，空间设计可以实现效率与情感影响的平衡，从而创造出既实用又具深厚人性的环境。", "summary": "本文提出一个创新的人机协作框架，旨在弥合机器学习在空间设计中效率与人文关怀之间的差距。该框架将机器学习模型的自动化和预测能力与人类设计师的直觉、同理心和文化洞察力相结合。机器学习负责初始的设计生成和优化，而人类设计师则对输出进行精炼，以确保设计具有情感共鸣、文化相关性和美学吸引力。通过办公和住宅设计的案例研究，论文展示了该方法如何平衡设计效率与情感影响，最终创造出既功能实用又富有人文关怀的空间。", "keywords": "人机协作, 空间设计, 机器学习, 人文设计, 设计框架", "comments": "本文的创新点在于提出了一个明确的人机协作框架，旨在解决机器学习在空间设计中无法处理情感、文化和美学维度的问题。其重要性在于为未来智能设计工具的发展提供了方向，强调了以人为本的设计理念在技术进步中的核心地位。"}}
{"id": "2507.01064", "title": "Functional Renormalization for Signal Detection: Dimensional Analysis and Dimensional Phase Transition for Nearly Continuous Spectra Effective Field Theory", "authors": ["Riccardo Finotello", "Vincent Lahoche", "Dine Ousmane Samary"], "summary": "Signal detection is one of the main challenges of data science. According to\nthe nature of the data, the presence of noise may corrupt measurements and\nhinder the discovery of significant patterns. A wide range of techniques aiming\nat extracting the relevant degrees of freedom from data has been thus developed\nover the years. However, signal detection in almost continuous spectra, for\nsmall signal-to-noise ratios, remains a known difficult issue. This paper\ndevelops over recent advancements proposing to tackle this issue by analysing\nthe properties of the underlying effective field theory arising as a sort of\nmaximal entropy distribution in the vicinity of universal random matrix\ndistributions. Nearly continuous spectra provide an intrinsic and\nnon-conventional scaling law for field and couplings, the scaling dimensions\ndepending on the energy scale. The coarse-graining over small eigenvalues of\nthe empirical spectrum defines a specific renormalization group, whose\ncharacteristics change when the collective behaviour of \"informational\" modes\nbecome significant, that is, stronger than the intrinsic fluctuations of noise.\nThis paper pursues three different goals. First, we propose to quantify the\nreal effects of fluctuations relative to what can be called \"signal\", while\nimproving the robustness of the results obtained in our previous work. Second,\nwe show that quantitative changes in the presence of a signal result in a\ncounterintuitive modification of the distribution of eigenvectors. Finally, we\npropose a method for estimating the number of noise components and define a\nlimit of detection in a general nearly continuous spectrum using the\nrenormalization group. The main statements of this paper are essentially\nnumeric, and their reproducibility can be checked using the associated code.", "comment": "34 pages", "pdf_url": "http://arxiv.org/pdf/2507.01064v1", "categories": ["physics.data-an", "cond-mat.stat-mech", "cs.IT", "hep-th", "math.IT", "stat.ME"], "cate": "physics.data-an", "url": "http://arxiv.org/abs/2507.01064v1", "date": "2025-06-30", "updated": "2025-06-30", "AI": {"title_translation": "信号检测的功能重整化：近连续谱有效场论的量纲分析与量纲相变", "tldr": "本文利用功能重整化和有效场论，通过分析波动和定义检测极限，改进了在近连续谱中、尤其是在低信噪比情况下的信号检测。", "motivation": "信号检测是数据科学的主要挑战之一，尤其是在几乎连续的谱中，当信噪比很低时，噪声会破坏测量结果并阻碍重要模式的发现。", "method": "本文基于最近的进展，通过分析在通用随机矩阵分布附近作为最大熵分布出现的潜在有效场论的特性来解决信号检测问题。它通过对经验谱的小特征值进行粗粒化来定义一个特定的重整化群。研究目标包括量化波动对“信号”的实际影响，展示信号存在导致特征向量分布的反直觉改变，以及提出一种使用重整化群估计噪声分量数量并在通用近连续谱中定义检测极限的方法。", "result": "本文提出了量化波动相对于“信号”的实际影响的方法，并提高了先前工作的鲁棒性。研究表明，信号存在时的量化变化会导致特征向量分布的反直觉修改。最后，提出了一种利用重整化群估计噪声分量数量并在通用近连续谱中定义检测极限的方法。论文的主要陈述本质上是数值的，其可重复性可以通过相关代码进行验证。", "conclusion": "本文成功地将功能重整化和有效场论应用于解决近连续谱中的信号检测难题，提供了量化波动、理解特征向量分布变化以及建立检测极限的方法。", "translation": "信号检测是数据科学的主要挑战之一。根据数据的性质，噪声的存在可能会破坏测量结果并阻碍重要模式的发现。多年来，人们开发了广泛的技术，旨在从数据中提取相关自由度。然而，在几乎连续的谱中，对于小信噪比的信号检测仍然是一个众所周知的难题。本文基于最近的进展，提出通过分析在通用随机矩阵分布附近作为一种最大熵分布出现的潜在有效场论的特性来解决这个问题。近连续谱为场和耦合提供了一种内在的、非传统的标度律，其标度维度取决于能量尺度。对经验谱的小特征值进行粗粒化定义了一个特定的重整化群，当“信息”模式的集体行为变得显著，即强于噪声的内在波动时，其特性会发生变化。本文旨在实现三个不同的目标。首先，我们提出量化波动相对于所谓“信号”的真实影响，同时提高我们之前工作中获得结果的鲁棒性。其次，我们表明信号存在时的量化变化会导致特征向量分布的反直觉修改。最后，我们提出了一种利用重整化群估计噪声分量数量并在通用近连续谱中定义检测极限的方法。本文的主要陈述本质上是数值的，其可重复性可以通过相关代码进行验证。", "summary": "本文旨在解决在低信噪比下近连续谱中信号检测的难题。通过利用有效场论和功能重整化的最新进展，研究定义了一种特定的重整化群，并通过粗粒化小特征值来分析系统特性。论文旨在量化波动对信号的影响，揭示信号存在如何反直觉地改变特征向量分布，并提出一种基于重整化群的方法来估计噪声分量并定义检测极限。研究结果主要是数值性的，并可通过相关代码进行验证。", "keywords": "信号检测, 功能重整化, 近连续谱, 有效场论, 重整化群", "comments": "该论文通过将理论物理（功能重整化、有效场论、重整化群）的概念应用于数据科学问题，为信号检测提供了一种创新方法。这种跨学科的方法，特别是其对近连续谱和低信噪比的关注，解决了已知的难题。对量化波动和定义检测极限的强调非常有价值。论文声称结果具有可重复性并提供相关代码，这增加了其在实践中的重要性。"}}
{"id": "2507.01090", "title": "Efficient Gate Reordering for Distributed Quantum Compiling in Data Centers", "authors": ["Riccardo Mengoni", "Walter Nadalin", "Mathys Rennela", "Jimmy Rotureau", "Tom Darras", "Julien Laurat", "Eleni Diamanti", "Ioannis Lavdas"], "summary": "Just as classical computing relies on distributed systems, the quantum\ncomputing era requires new kinds of infrastructure and software tools. Quantum\nnetworks will become the backbone of hybrid, quantum-augmented data centers, in\nwhich quantum algorithms are distributed over a local network of quantum\nprocessing units (QPUs) interconnected via shared entanglement. In this\ncontext, it is crucial to develop methods and software that minimize the number\nof inter-QPU communications. Here we describe key features of the quantum\ncompiler araQne, which is designed to minimize distribution cost, measured by\nthe number of entangled pairs required to distribute a monolithic quantum\ncircuit using gate teleportation protocols. We establish the crucial role\nplayed by circuit reordering strategies, which strongly reduce the distribution\ncost compared to a baseline approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01090v1", "categories": ["quant-ph", "cs.DC"], "cate": "quant-ph", "url": "http://arxiv.org/abs/2507.01090v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "数据中心分布式量子编译的高效门重排序", "tldr": "开发了一种名为araQne的量子编译器，通过门重排序策略显著降低了分布式量子计算中QPU间的通信成本。", "motivation": "在混合量子增强数据中心中，量子算法需要分布在互连的量子处理单元（QPU）网络上，因此需要开发能够最小化QPU间通信次数的方法和软件。", "method": "描述了量子编译器araQne的关键特性，该编译器旨在通过门隐形传态协议最小化分布式量子电路所需纠缠对数量，并确立了电路重排序策略的关键作用。", "result": "与基线方法相比，电路重排序策略显著降低了分布式成本。", "conclusion": "电路重排序策略在分布式量子编译中对于最小化通信成本至关重要。", "translation": "正如经典计算依赖于分布式系统一样，量子计算时代需要新型的基础设施和软件工具。量子网络将成为混合量子增强数据中心的骨干，其中量子算法通过共享纠缠分布在量子处理单元（QPU）的本地网络上。在这种背景下，开发能够最小化QPU间通信次数的方法和软件至关重要。本文描述了量子编译器araQne的关键特性，该编译器旨在通过门隐形传态协议分发单片量子电路时，最小化以所需纠缠对数量衡量的分发成本。我们确立了电路重排序策略所扮演的关键角色，与基线方法相比，该策略大大降低了分发成本。", "summary": "本文介绍了量子编译器araQne，旨在解决分布式量子计算中QPU间通信成本高的问题。通过利用门隐形传态协议和关键的电路重排序策略，araQne能够显著减少分发大型量子电路所需的纠缠对数量，从而降低了分布式量子编译的成本。", "keywords": "量子编译, 分布式量子计算, 门重排序, araQne, 量子数据中心", "comments": "该研究提出了一种创新的量子编译器araQne，其核心在于利用电路重排序策略来优化分布式量子编译中的通信成本。这对于构建高效的混合量子增强数据中心至关重要，显示了在量子计算基础设施发展中的实用价值。"}}
{"id": "2507.01828", "title": "Autoadaptive Medical Segment Anything Model", "authors": ["Tyler Ward", "Meredith K. Owen", "O'Kira Coleman", "Brian Noehren", "Abdullah-Al-Zubaer Imran"], "summary": "Medical image segmentation is a key task in the imaging workflow, influencing\nmany image-based decisions. Traditional, fully-supervised segmentation models\nrely on large amounts of labeled training data, typically obtained through\nmanual annotation, which can be an expensive, time-consuming, and error-prone\nprocess. This signals a need for accurate, automatic, and annotation-efficient\nmethods of training these models. We propose ADA-SAM (automated,\ndomain-specific, and adaptive segment anything model), a novel multitask\nlearning framework for medical image segmentation that leverages class\nactivation maps from an auxiliary classifier to guide the predictions of the\nsemi-supervised segmentation branch, which is based on the Segment Anything\n(SAM) framework. Additionally, our ADA-SAM model employs a novel gradient\nfeedback mechanism to create a learnable connection between the segmentation\nand classification branches by using the segmentation gradients to guide and\nimprove the classification predictions. We validate ADA-SAM on real-world\nclinical data collected during rehabilitation trials, and demonstrate that our\nproposed method outperforms both fully-supervised and semi-supervised baselines\nby double digits in limited label settings. Our code is available at:\nhttps://github.com/tbwa233/ADA-SAM.", "comment": "11 pages, 2 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.01828v1", "categories": ["eess.IV", "cs.CV"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01828v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "自适应医学图像分割一切模型", "tldr": "该论文提出了ADA-SAM，一种用于医学图像分割的新型多任务学习框架，它利用辅助分类器和梯度反馈机制，在有限标注数据下实现了优于全监督和半监督基线的性能。", "motivation": "传统的全监督医学图像分割模型依赖大量昂贵、耗时且易出错的手动标注数据，因此需要开发准确、自动化且标注高效的模型训练方法。", "method": "论文提出了ADA-SAM（自动化、领域特定和自适应的分割一切模型），这是一种新型多任务学习框架。它利用辅助分类器的类激活图来指导基于SAM的半监督分割分支的预测。此外，ADA-SAM还采用了一种新颖的梯度反馈机制，通过使用分割梯度来指导和改进分类预测，从而在分割和分类分支之间建立可学习的连接。", "result": "ADA-SAM在康复试验中收集的真实世界临床数据上进行了验证，结果表明在有限标签设置下，其性能比全监督和半监督基线模型高出两位数。", "conclusion": "所提出的ADA-SAM模型通过引入一种新颖的多任务学习框架和梯度反馈机制，有效解决了医学图像分割中标记数据有限的挑战，实现了优于现有方法的性能。", "translation": "医学图像分割是影像工作流中的一项关键任务，影响着许多基于图像的决策。传统的全监督分割模型依赖于大量的标注训练数据，这些数据通常通过手动标注获得，而这可能是一个昂贵、耗时且容易出错的过程。这表明需要准确、自动化且标注高效的方法来训练这些模型。我们提出了ADA-SAM（自动化、领域特定和自适应的分割一切模型），这是一种用于医学图像分割的新型多任务学习框架，它利用辅助分类器的类激活图来指导半监督分割分支的预测，该分支基于Segment Anything（SAM）框架。此外，我们的ADA-SAM模型采用了一种新颖的梯度反馈机制，通过使用分割梯度来指导和改进分类预测，从而在分割和分类分支之间建立可学习的连接。我们在康复试验中收集的真实世界临床数据上验证了ADA-SAM，并证明我们提出的方法在有限标签设置下，在性能上比全监督和半监督基线模型高出两位数。我们的代码可在以下地址获取：https://github.com/tbwa233/ADA-SAM。", "summary": "本文介绍了ADA-SAM，一个“自动化、领域特定和自适应的分割一切模型”，专为医学图像分割设计。为解决传统全监督模型对手动标注数据的高成本和高劳动力的依赖，ADA-SAM采用了一种新颖的多任务学习框架。它整合了一个由辅助分类器类激活图引导的半监督分割分支（基于SAM），以及一个独特的梯度反馈机制，利用分割梯度来改进分类。ADA-SAM在真实世界临床数据上进行了验证，尤其在有限标注数据场景下，其性能显著优于全监督和半监督基线模型。", "keywords": "医学图像分割, 半监督学习, 多任务学习, Segment Anything Model, 有限标签", "comments": "本文的创新之处在于其新颖的多任务学习框架ADA-SAM，它有效解决了医学图像分割中数据稀缺的关键问题。通过巧妙地将基于SAM的半监督分支与辅助分类器相结合，并引入独特的梯度反馈机制，ADA-SAM不仅减少了对大量手动标注的依赖，而且表现出卓越的性能。这种方法为开发更高效、更准确的医学成像工具提供了有前景的方向。"}}
{"id": "2507.01574", "title": "Vision-Aided ISAC in Low-Altitude Economy Networks via De-Diffused Visual Priors", "authors": ["Yulan Gao", "Ziqiang Ye", "Zhonghao Lyu", "Ming Xiao", "Yue Xiao", "Ping Yang", "Agata Manolova"], "summary": "Emerging low-altitude economy networks (LAENets) require agile and\nprivacy-preserving resource control under dynamic agent mobility and limited\ninfrastructure support. To meet these challenges, we propose a vision-aided\nintegrated sensing and communication (ISAC) framework for UAV-assisted access\nsystems, where onboard masked De-Diffusion models extract compact semantic\ntokens, including agent type, activity class, and heading orientation, while\nexplicitly suppressing sensitive visual content. These tokens are fused with\nmmWave radar measurements to construct a semantic risk heatmap reflecting\nmotion density, occlusion, and scene complexity, which guides access technology\nselection and resource scheduling. We formulate a multi-objective optimization\nproblem to jointly maximize weighted energy and perception efficiency via radio\naccess technology (RAT) assignment, power control, and beamforming, subject to\nagent-specific QoS constraints. To solve this, we develop De-Diffusion-driven\nvision-aided risk-aware resource optimization algorithm DeDiff-VARARO, a novel\ntwo-stage cross-modal control algorithm: the first stage reconstructs visual\nscenes from tokens via De-Diffusion model for semantic parsing, while the\nsecond stage employs a deep deterministic policy gradient (DDPG)-based policy\nto adapt RAT selection, power control, and beam assignment based on fused\nradar-visual states. Simulation results show that DeDiff-VARARO consistently\noutperforms baselines in reward convergence, link robustness, and semantic\nfidelity, achieving within $4\\%$ of the performance of a raw-image upper bound\nwhile preserving user privacy and scalability in dense environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01574v1", "categories": ["eess.SY", "cs.SY"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01574v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "低空经济网络中基于去扩散视觉先验的视觉辅助ISAC", "tldr": "本文提出了一种视觉辅助的集成感知与通信（ISAC）框架，通过去扩散模型从视觉数据中提取紧凑的语义令牌，并与毫米波雷达测量融合，构建语义风险热图，指导低空经济网络中的资源调度，以优化能量和感知效率，同时保护用户隐私。", "motivation": "新兴的低空经济网络（LAENets）在动态代理移动性和有限基础设施支持下，需要敏捷且保护隐私的资源控制。为应对这些挑战，本文提出了一个视觉辅助的集成感知与通信（ISAC）框架。", "method": "本文提出了一种视觉辅助的集成感知与通信（ISAC）框架，用于无人机辅助接入系统。该框架利用机载掩码去扩散模型提取紧凑的语义令牌（包括代理类型、活动类别和航向），同时抑制敏感视觉内容。这些令牌与毫米波雷达测量融合，构建反映运动密度、遮挡和场景复杂度的语义风险热图，以指导接入技术选择和资源调度。研究将该问题表述为一个多目标优化问题，旨在通过无线接入技术（RAT）分配、功率控制和波束成形，联合最大化加权能量和感知效率，并受限于代理特定的QoS约束。为解决此问题，开发了去扩散驱动的视觉辅助风险感知资源优化算法DeDiff-VARARO，这是一种新颖的两阶段跨模态控制算法：第一阶段通过去扩散模型从令牌重建视觉场景进行语义解析；第二阶段采用基于深度确定性策略梯度（DDPG）的策略，根据融合的雷达-视觉状态调整RAT选择、功率控制和波束分配。", "result": "仿真结果表明，DeDiff-VARARO在奖励收敛、链路鲁棒性和语义保真度方面始终优于基线，达到了原始图像上限性能的4%以内，同时在密集环境中保持了用户隐私和可扩展性。", "conclusion": "本文提出的DeDiff-VARARO算法在低空经济网络中实现了高效、隐私保护的视觉辅助ISAC，通过结合去扩散模型和毫米波雷达数据，显著提升了资源调度的性能，并在复杂环境中展现出优越的鲁棒性和可扩展性。", "translation": "新兴的低空经济网络（LAENets）在动态代理移动性和有限基础设施支持下，需要敏捷且保护隐私的资源控制。为应对这些挑战，我们提出了一种视觉辅助的集成感知与通信（ISAC）框架，用于无人机辅助接入系统，其中机载掩码去扩散模型提取紧凑的语义令牌，包括代理类型、活动类别和航向，同时明确抑制敏感视觉内容。这些令牌与毫米波雷达测量融合，构建反映运动密度、遮挡和场景复杂度的语义风险热图，该热图指导接入技术选择和资源调度。我们制定了一个多目标优化问题，通过无线接入技术（RAT）分配、功率控制和波束成形，联合最大化加权能量和感知效率，并受限于代理特定的QoS约束。为解决此问题，我们开发了去扩散驱动的视觉辅助风险感知资源优化算法DeDiff-VARARO，这是一种新颖的两阶段跨模态控制算法：第一阶段通过去扩散模型从令牌重建视觉场景进行语义解析，而第二阶段采用基于深度确定性策略梯度（DDPG）的策略，根据融合的雷达-视觉状态调整RAT选择、功率控制和波束分配。仿真结果表明，DeDiff-VARARO在奖励收敛、链路鲁棒性和语义保真度方面始终优于基线，达到了原始图像上限性能的4%以内，同时在密集环境中保持了用户隐私和可扩展性。", "summary": "本文针对低空经济网络中资源控制的挑战，提出了一种名为DeDiff-VARARO的视觉辅助集成感知与通信（ISAC）框架。该框架利用去扩散模型从视觉数据中提取隐私保护的语义令牌，并将其与毫米波雷达测量融合，生成语义风险热图以指导资源调度。通过解决多目标优化问题，DeDiff-VARARO旨在最大化能量和感知效率。实验证明，该算法在性能、鲁棒性、隐私保护和可扩展性方面均优于现有基线。", "keywords": "ISAC, 低空经济网络, 去扩散模型, 视觉辅助, 资源优化", "comments": "本文的创新点在于将去扩散模型应用于视觉辅助ISAC，实现了在保护隐私的前提下提取关键语义信息，并将其与雷达数据融合以优化资源调度。这种跨模态融合的方法为低空经济网络提供了高效且安全的解决方案，特别是在动态和隐私敏感的环境中具有重要意义。该方法通过两阶段的DeDiff-VARARO算法，有效解决了复杂的资源优化问题，展现出良好的性能和实用潜力。"}}
{"id": "2507.01335", "title": "LEDOM: An Open and Fundamental Reverse Language Model", "authors": ["Xunjian Yin", "Sitao Cheng", "Yuxi Xie", "Xinyu Hu", "Li Lin", "Xinyi Wang", "Liangming Pan", "William Yang Wang", "Xiaojun Wan"], "summary": "We introduce LEDOM, the first purely reverse language model, trained\nautoregressively on 435B tokens with 2B and 7B parameter variants, which\nprocesses sequences in reverse temporal order through previous token\nprediction. For the first time, we present the reverse language model as a\npotential foundational model across general tasks, accompanied by a set of\nintriguing examples and insights. Based on LEDOM, we further introduce a novel\napplication: Reverse Reward, where LEDOM-guided reranking of forward language\nmodel outputs leads to substantial performance improvements on mathematical\nreasoning tasks. This approach leverages LEDOM's unique backward reasoning\ncapability to refine generation quality through posterior evaluation. Our\nfindings suggest that LEDOM exhibits unique characteristics with broad\napplication potential. We will release all models, training code, and\npre-training data to facilitate future research.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.01335v1", "categories": ["cs.CL", "cs.AI"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01335v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "LEDOM：一种开放且基础的逆向语言模型", "tldr": "引入了LEDOM，第一个纯逆向语言模型，展示了其作为基础模型的潜力及其在改进前向语言模型输出中的应用。", "motivation": "本研究旨在引入并探索纯逆向语言模型（LEDOM）的概念，并将其作为一种潜在的基础模型，突出其独特的逆向推理能力。", "method": "LEDOM是一个纯粹的逆向语言模型，在435B个词元上进行自回归训练，并有2B和7B参数变体，它通过预测前一个词元来以逆向时间顺序处理序列。在此基础上，引入了“逆向奖励”这一新应用，通过LEDOM引导对前向语言模型输出进行重新排序，以提高生成质量。", "result": "LEDOM引导的重新排序（逆向奖励）在数学推理任务上带来了显著的性能提升。", "conclusion": "LEDOM展现出独特的特性，具有广泛的应用潜力，表明其对未来研究的价值。", "translation": "我们介绍了LEDOM，这是第一个纯粹的逆向语言模型，它通过预测前一个词元，以逆向时间顺序处理序列，并在435B个词元上进行了自回归训练，具有2B和7B参数变体。我们首次将逆向语言模型作为跨通用任务的潜在基础模型提出，并附带了一系列有趣的例子和见解。基于LEDOM，我们进一步引入了一种新颖的应用：逆向奖励（Reverse Reward），其中LEDOM引导的前向语言模型输出的重新排序在数学推理任务上带来了显著的性能提升。这种方法利用了LEDOM独特的逆向推理能力，通过后验评估来提高生成质量。我们的研究结果表明，LEDOM表现出独特的特性，具有广泛的应用潜力。我们将发布所有模型、训练代码和预训练数据，以促进未来的研究。", "summary": "本文介绍了LEDOM，首个纯逆向语言模型，以自回归方式在大量数据上训练。研究将其作为潜在的基础模型，并提出“逆向奖励”应用，利用LEDOM的逆向推理能力对前向语言模型输出进行重排序，从而显著提升数学推理任务的性能。LEDOM展现出独特的特性和广泛的应用潜力，所有相关资源将开源。", "keywords": "逆向语言模型, LEDOM, 基础模型, 逆向奖励, 数学推理", "comments": "这项工作通过引入LEDOM，开创了逆向语言模型的新范式，并将其定位为潜在的基础模型，具有重要的创新性。其在“逆向奖励”应用中，利用逆向推理能力提升前向模型性能的思路尤其新颖，为语言模型的评估和优化提供了新的视角。开源所有资源有助于推动该领域的研究。"}}
{"id": "2507.01762", "title": "Global Energy Minimization for Simplex Mesh Optimization: A Radius Ratio Approach to Sliver Elimination", "authors": ["Dong Wang", "Chunyu Chen", "Huayi Wei"], "summary": "The quality of simplex mesh is crucial for the stability and accuracy of\nnumerical simulations in finite element analysis and computational geometry.\nHowever, the presence of sliver elements in 3D simplex mesh can severely impact\nthe results. This paper presents a novel method based on a radius ratio energy\nfunction to optimize the quality of simplex mesh elements. This method can\neffectively eliminate sliver elements, thereby enhancing mesh quality.The\ngradient of the proposed energy function can be decomposed into a matrix-vector\nproduct. With minor processing, the matrix becomes symmetric positive definite,\nand this symmetric positive definite matrix can serve as a preconditioner to\nsignificantly accelerate the optimization process. Experimental results\ndemonstrate that this method has significant advantages in eliminating sliver\nelements and improving mesh quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01762v1", "categories": ["math.NA", "cs.NA", "math.OC"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01762v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "单纯形网格优化的全局能量最小化：一种基于半径比法的薄片单元消除方法", "tldr": "本文提出一种基于半径比能量函数的新方法，通过全局能量最小化优化单纯形网格，有效消除薄片单元，提高网格质量。", "motivation": "单纯形网格的质量对有限元分析和计算几何中的数值模拟的稳定性和准确性至关重要。然而，三维单纯形网格中薄片单元的存在会严重影响结果。", "method": "提出一种基于半径比能量函数的新方法来优化单纯形网格单元的质量。该方法的能量函数梯度可分解为矩阵-向量积，经过处理后矩阵变为对称正定，可作为预处理器加速优化过程。", "result": "实验结果表明，该方法在消除薄片单元和提高网格质量方面具有显著优势。", "conclusion": "该方法能有效消除薄片单元，显著提高网格质量，对数值模拟的稳定性和准确性有积极影响。", "translation": "单纯形网格的质量对于有限元分析和计算几何中的数值模拟的稳定性和准确性至关重要。然而，三维单纯形网格中薄片单元的存在会严重影响结果。本文提出了一种基于半径比能量函数的新方法来优化单纯形网格单元的质量。该方法可以有效地消除薄片单元，从而提高网格质量。所提出的能量函数的梯度可以分解为矩阵-向量积。经过少量处理后，该矩阵变为对称正定，并且这个对称正定矩阵可以作为预处理器显著加速优化过程。实验结果表明，该方法在消除薄片单元和提高网格质量方面具有显著优势。", "summary": "本文提出一种新颖的基于半径比能量函数的方法，旨在通过全局能量最小化优化单纯形网格，以消除三维网格中的薄片单元。该方法的能量函数梯度可分解为对称正定矩阵，可用作预处理器加速优化。实验证明，此方法能有效提高网格质量并消除薄片单元，对数值模拟的稳定性和准确性至关重要。", "keywords": "单纯形网格, 网格优化, 薄片单元, 半径比, 全局能量最小化", "comments": "该研究提出了一种创新的、基于半径比能量函数的全局能量最小化方法，用于优化单纯形网格并消除薄片单元。其创新之处在于将能量函数的梯度分解为可作为预处理器的对称正定矩阵，从而显著加速了优化过程。这对于提高有限元分析和计算几何中数值模拟的稳定性和准确性具有重要意义。"}}
{"id": "2507.01888", "title": "Perceptual Ratings Predict Speech Inversion Articulatory Kinematics in Childhood Speech Sound Disorders", "authors": ["Nina R. Benway", "Saba Tabatabaee", "Dongliang Wang", "Benjamin Munson", "Jonathan L. Preston", "Carol Espy-Wilson"], "summary": "Purpose: This study evaluated whether articulatory kinematics, inferred by\nArticulatory Phonology speech inversion neural networks, aligned with\nperceptual ratings of /r/ and /s/ in the speech of children with speech sound\ndisorders.\n  Methods: Articulatory Phonology vocal tract variables were inferred for 5,961\nutterances from 118 children and 3 adults, aged 2.25-45 years. Perceptual\nratings were standardized using the novel 5-point PERCEPT Rating Scale and\ntraining protocol. Two research questions examined if the articulatory patterns\nof inferred vocal tract variables aligned with the perceptual error category\nfor the phones investigated (e.g., tongue tip is more anterior in dentalized\n/s/ productions than in correct /s/). A third research question examined if\ngradient PERCEPT Rating Scale scores predicted articulatory proximity to\ncorrect productions.\n  Results: Estimated marginal means from linear mixed models supported 17 of 18\n/r/ hypotheses, involving tongue tip and tongue body constrictions. For /s/,\nestimated marginal means from a second linear mixed model supported 7 of 15\nhypotheses, particularly those related to the tongue tip. A third linear mixed\nmodel revealed that PERCEPT Rating Scale scores significantly predicted\narticulatory proximity of errored phones to correct productions.\n  Conclusion: Inferred vocal tract variables differentiated category and\nmagnitude of articulatory errors for /r/, and to a lesser extent for /s/,\naligning with perceptual judgments. These findings support the clinical\ninterpretability of speech inversion vocal tract variables and the PERCEPT\nRating Scale in quantifying articulatory proximity to the target sound,\nparticularly for /r/.", "comment": "This manuscript is in submission for publication. It has not yet been\n  peer reviewed", "pdf_url": "http://arxiv.org/pdf/2507.01888v1", "categories": ["eess.AS"], "cate": "eess.AS", "url": "http://arxiv.org/abs/2507.01888v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "感知评级预测儿童言语声音障碍中言语反演发音运动学", "tldr": "本研究评估了通过言语反演神经网络推断的发音运动学是否与儿童言语声音障碍中/r/和/s/的感知评级一致，结果显示推断的声道变量可以区分发音错误的类别和程度，支持其临床可解释性。", "motivation": "本研究旨在评估通过发音音韵学言语反演神经网络推断的发音运动学，是否与儿童言语声音障碍中/r/和/s/的感知评级一致。", "method": "研究推断了118名儿童和3名成人（年龄2.25-45岁）5961个发音的声道变量。感知评级使用新颖的5点PERCEPT评级量表和训练方案进行标准化。研究通过三个研究问题检验了推断的声道变量的发音模式是否与所调查音素的感知错误类别一致，以及梯度PERCEPT评级量表分数是否预测了与正确发音的发音接近度。数据通过线性混合模型进行分析。", "result": "对于/r/，线性混合模型的估计边际均值支持了18个假设中的17个，涉及舌尖和舌体收缩。对于/s/，第二个线性混合模型的估计边际均值支持了15个假设中的7个，特别是与舌尖相关的假设。第三个线性混合模型显示，PERCEPT评级量表分数显著预测了错误音素与正确发音的发音接近度。", "conclusion": "推断的声道变量区分了/r/（在较小程度上也区分了/s/）的发音错误的类别和程度，与感知判断一致。这些发现支持了言语反演声道变量和PERCEPT评级量表在量化发音接近目标音（特别是/r/）方面的临床可解释性。", "translation": "目的：本研究评估了通过发音音韵学言语反演神经网络推断的发音运动学，是否与儿童言语声音障碍中/r/和/s/的感知评级一致。\n方法：对118名儿童和3名成人（年龄2.25-45岁）的5961个发音推断了发音音韵学声道的变量。感知评级使用新颖的5点PERCEPT评级量表和训练方案进行标准化。两个研究问题检验了推断的声道变量的发音模式是否与所调查音素的感知错误类别一致（例如，在牙齿化的/s/发音中舌尖比正确/s/更靠前）。第三个研究问题检验了梯度PERCEPT评级量表分数是否预测了与正确发音的发音接近度。\n结果：线性混合模型的估计边际均值支持了18个/r/假设中的17个，涉及舌尖和舌体收缩。对于/s/，第二个线性混合模型的估计边际均值支持了15个假设中的7个，特别是与舌尖相关的假设。第三个线性混合模型显示，PERCEPT评级量表分数显著预测了错误音素与正确发音的发音接近度。\n结论：推断的声道变量区分了/r/（在较小程度上也区分了/s/）的发音错误的类别和程度，与感知判断一致。这些发现支持了言语反演声道变量和PERCEPT评级量表在量化发音接近目标音方面的临床可解释性，特别是对于/r/。", "summary": "本研究旨在探讨通过言语反演神经网络推断的发音运动学是否与儿童言语声音障碍中/r/和/s/的感知评级相符。研究对118名儿童和3名成人的发音进行了声道变量推断，并使用新颖的PERCEPT评级量表进行感知评级。结果表明，推断的声道变量能有效区分/r/（以及在较小程度上/s/）的发音错误类别和程度，并且感知评级分数能够预测发音与正确产出的接近度。这支持了这些变量和评级量表在临床上量化发音准确性的潜力，尤其是在评估/r/发音时。", "keywords": "言语声音障碍, 发音运动学, 感知评级, 言语反演, 儿童", "comments": "本研究的创新之处在于结合了言语反演神经网络推断的发音运动学数据与感知评级，为儿童言语声音障碍的评估提供了新的量化工具。其重要性在于验证了这些客观指标与主观感知判断的一致性，从而可能为临床诊断和治疗提供更精确的依据。研究结果对/r/音的支持度高于/s/音，这可能表明该方法在不同音素上的有效性存在差异，未来研究可以探索其普适性。"}}
{"id": "2507.01550", "title": "Dynamic System Model Generation for Online Fault Detection and Diagnosis of Robotic Systems", "authors": ["Johannes Kohl", "Georg Muck", "Georg Jäger", "Sebastian Zug"], "summary": "With the rapid development of more complex robots, Fault Detection and\nDiagnosis (FDD) becomes increasingly harder. Especially the need for\npredetermined models and historic data is problematic because they do not\nencompass the dynamic and fast-changing nature of such systems. To this end, we\npropose a concept that actively generates a dynamic system model at runtime and\nutilizes it to locate root causes. The goal is to be applicable to all kinds of\nrobotic systems that share a similar software design. Additionally, it should\nexhibit minimal overhead and enhance independence from expert attention.", "comment": "Accepted for publication in Ada User Journal", "pdf_url": "http://arxiv.org/pdf/2507.01550v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01550v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "机器人系统在线故障检测与诊断的动态系统模型生成", "tldr": "提出一种运行时动态生成系统模型以进行机器人故障检测与诊断的概念，旨在克服传统方法对预定模型和历史数据的依赖。", "motivation": "随着机器人复杂性的增加，故障检测与诊断（FDD）变得越来越困难。传统方法对预定模型和历史数据的依赖是主要问题，因为它们无法涵盖系统动态和快速变化的特性。", "method": "本文提出一个概念，即在运行时主动生成动态系统模型，并利用该模型来定位故障的根本原因。", "result": "Not mentioned in abstract", "conclusion": "提出的概念旨在适用于所有共享相似软件设计的机器人系统，并应具有最小开销，同时提高对专家关注的独立性。", "translation": "随着更复杂机器人的快速发展，故障检测与诊断（FDD）变得越来越困难。特别是对预定模型和历史数据的需求存在问题，因为它们无法涵盖此类系统的动态和快速变化的性质。为此，我们提出了一种在运行时主动生成动态系统模型并利用其定位根本原因的概念。目标是适用于所有共享相似软件设计的机器人系统。此外，它应该表现出最小的开销并增强对专家关注的独立性。", "summary": "本文针对复杂机器人系统在线故障检测与诊断（FDD）的挑战，提出了一种新的概念。鉴于传统FDD方法依赖预定模型和历史数据，难以适应系统动态变化的特性，该概念建议在运行时主动生成动态系统模型，并利用该模型来定位故障的根本原因。此方法旨在适用于所有共享相似软件设计的机器人系统，并期望实现最小开销和增强对专家关注的独立性。", "keywords": "故障检测与诊断, 动态系统模型, 机器人系统, 在线, 运行时", "comments": "该论文提出了一种创新的在线故障检测与诊断方法，通过运行时动态模型生成解决了传统方法对静态模型和历史数据依赖的局限性。其关注通用性、低开销和减少专家依赖的特点，对于提高复杂机器人系统的自主性和可靠性具有重要意义。"}}
{"id": "2507.01768", "title": "Signals and Symptoms: ICS Attack Dataset From Railway Cyber Range", "authors": ["Anis Yusof", "Yuancheng Liu", "Niklaus Kang", "Choon Meng Seah", "Zhenkai Liang", "Ee-Chien Chang"], "summary": "The prevalence of cyberattacks on Industrial Control Systems (ICS) has\nhighlighted the necessity for robust security measures and incident response to\nprotect critical infrastructure. This is prominent when Operational Technology\n(OT) systems undergo digital transformation by integrating with Information\nTechnology (IT) systems to enhance operational efficiency, adaptability, and\nsafety. To support analysts in staying abreast of emerging attack patterns,\nthere is a need for ICS datasets that reflect indicators representative of\ncontemporary cyber threats. To address this, we conduct two ICS cyberattack\nsimulations to showcase the impact of trending ICS cyberattacks on a railway\ncyber range that resembles the railway infrastructure. The attack scenario is\ndesigned to blend trending attack trends with attack patterns observed from\nhistorical ICS incidents. The resulting evidence is collected as datasets,\nserving as an essential resource for cyberattack analysis. This captures key\nindicators that are relevant to the current threat landscape, augmenting the\neffectiveness of security systems and analysts to protect against ICS cyber\nthreats.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01768v1", "categories": ["cs.CR"], "cate": "cs.CR", "url": "http://arxiv.org/abs/2507.01768v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "信号与症状：来自铁路网络靶场的ICS攻击数据集", "tldr": "本文通过在铁路网络靶场进行ICS网络攻击模拟，生成了反映当代威胁模式的ICS攻击数据集，以支持网络攻击分析和提升安全系统有效性。", "motivation": "鉴于ICS网络攻击日益普遍，尤其是在运营技术（OT）系统与信息技术（IT）系统融合的背景下，需要强大的安全措施和事件响应来保护关键基础设施。为了帮助分析师掌握新兴攻击模式，需要能够反映当代网络威胁指标的ICS数据集。", "method": "研究者在模拟铁路基础设施的网络靶场上进行了两次ICS网络攻击模拟。攻击场景设计结合了当前流行的攻击趋势和历史ICS事件中观察到的攻击模式。", "result": "收集了攻击模拟产生的证据，形成了ICS攻击数据集。该数据集捕获了与当前威胁环境相关的关键指标，可以作为网络攻击分析的重要资源。", "conclusion": "该数据集增强了安全系统和分析师抵御ICS网络威胁的有效性，为网络攻击分析提供了宝贵的资源。", "translation": "工业控制系统（ICS）网络攻击的普遍性突显了采取强大安全措施和事件响应以保护关键基础设施的必要性。当运营技术（OT）系统通过与信息技术（IT）系统集成进行数字化转型以提高运营效率、适应性和安全性时，这一点尤为突出。为了支持分析师及时了解新兴攻击模式，需要能够反映当代网络威胁指标的ICS数据集。为解决这一问题，我们进行了两次ICS网络攻击模拟，以展示当前流行的ICS网络攻击对模拟铁路基础设施的网络靶场的影响。攻击场景旨在将当前流行的攻击趋势与从历史ICS事件中观察到的攻击模式相结合。由此产生的证据被收集为数据集，作为网络攻击分析的重要资源。这捕获了与当前威胁态势相关的关键指标，从而增强了安全系统和分析师抵御ICS网络威胁的有效性。", "summary": "本文旨在解决当前缺乏反映当代网络威胁模式的ICS数据集的问题。研究者在模拟铁路基础设施的网络靶场上进行了两次ICS网络攻击模拟，这些攻击场景融合了最新趋势和历史事件模式。通过这些模拟，研究者收集了关键的攻击证据并构建了一个ICS攻击数据集，该数据集可作为网络攻击分析的重要资源，并有助于提升安全系统和分析师抵御ICS网络威胁的能力。", "keywords": "ICS网络攻击, 铁路网络靶场, 攻击数据集, 工业控制系统, 关键基础设施", "comments": "本文的创新之处在于创建了一个针对铁路ICS的特定攻击数据集，这对于关键基础设施安全研究具有重要意义。通过结合流行攻击趋势和历史事件模式，数据集的实用性得到增强。其价值在于为网络安全分析师和安全系统提供了宝贵的训练和测试资源，有助于提升对OT/ICS系统，特别是铁路系统的防护能力。"}}
{"id": "2507.01347", "title": "Learning from Random Subspace Exploration: Generalized Test-Time Augmentation with Self-supervised Distillation", "authors": ["Andrei Jelea", "Ahmed Nabil Belbachir", "Marius Leordeanu"], "summary": "We introduce Generalized Test-Time Augmentation (GTTA), a highly effective\nmethod for improving the performance of a trained model, which unlike other\nexisting Test-Time Augmentation approaches from the literature is general\nenough to be used off-the-shelf for many vision and non-vision tasks, such as\nclassification, regression, image segmentation and object detection. By\napplying a new general data transformation, that randomly perturbs multiple\ntimes the PCA subspace projection of a test input, GTTA forms robust ensembles\nat test time in which, due to sound statistical properties, the structural and\nsystematic noises in the initial input data is filtered out and final estimator\nerrors are reduced. Different from other existing methods, we also propose a\nfinal self-supervised learning stage in which the ensemble output, acting as an\nunsupervised teacher, is used to train the initial single student model, thus\nreducing significantly the test time computational cost, at no loss in\naccuracy. Our tests and comparisons to strong TTA approaches and SoTA models on\nvarious vision and non-vision well-known datasets and tasks, such as image\nclassification and segmentation, speech recognition and house price prediction,\nvalidate the generality of the proposed GTTA. Furthermore, we also prove its\neffectiveness on the more specific real-world task of salmon segmentation and\ndetection in low-visibility underwater videos, for which we introduce\nDeepSalmon, the largest dataset of its kind in the literature.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01347v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01347v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "从随机子空间探索中学习：广义测试时间增强与自监督蒸馏", "tldr": "本文提出广义测试时间增强（GTTA），通过随机扰动PCA子空间投影进行鲁棒集成，并结合自监督蒸馏降低计算成本，显著提升训练模型的性能，适用于多种视觉和非视觉任务。", "motivation": "现有测试时间增强（TTA）方法不够通用，无法直接应用于多种视觉和非视觉任务。研究旨在提出一种更通用且高效的测试时间增强方法来提高训练模型的性能。", "method": "本文引入了广义测试时间增强（GTTA）方法。该方法通过对测试输入进行新的通用数据变换，即多次随机扰动其PCA子空间投影，在测试时形成鲁棒的集成。这种方法能够过滤掉输入数据中的结构性和系统性噪声，并减少最终估计器的误差。此外，该方法还提出了一个自监督学习阶段，其中集成输出作为无监督教师来训练初始的单一学生模型，从而在不损失准确性的情况下显著降低测试时间的计算成本。", "result": "GTTA在各种视觉和非视觉知名数据集和任务（如图像分类、分割、语音识别和房价预测）上进行了测试，并与强大的TTA方法和最先进的模型进行了比较，验证了其通用性。此外，GTTA在低能见度水下视频中的鲑鱼分割和检测这一更具体的实际任务中也证明了其有效性，为此还引入了DeepSalmon数据集。", "conclusion": "广义测试时间增强（GTTA）是一种高效且通用的方法，能够显著提高训练模型的性能，适用于多种视觉和非视觉任务。通过结合随机子空间探索和自监督蒸馏，GTTA不仅能提升准确性，还能有效降低测试时间的计算成本。", "translation": "我们引入了广义测试时间增强（GTTA），这是一种提高训练模型性能的高效方法，与文献中其他现有测试时间增强方法不同，它足够通用，可以即插即用于许多视觉和非视觉任务，如分类、回归、图像分割和目标检测。通过应用一种新的通用数据变换，即多次随机扰动测试输入的PCA子空间投影，GTTA在测试时形成了鲁棒的集成，其中由于良好的统计特性，初始输入数据中的结构性和系统性噪声被滤除，最终估计器误差得以减少。与现有其他方法不同，我们还提出了一个最终的自监督学习阶段，其中集成输出作为无监督教师，用于训练初始的单一学生模型，从而在不损失准确性的情况下显著降低测试时间计算成本。我们对各种视觉和非视觉知名数据集和任务（如图像分类和分割、语音识别和房价预测）与强大的TTA方法和最先进模型进行的测试和比较，验证了所提出的GTTA的通用性。此外，我们还在低能见度水下视频中鲑鱼分割和检测这一更具体的实际任务上证明了其有效性，为此我们引入了DeepSalmon，这是文献中同类数据集中最大的一个。", "summary": "本文提出了一种名为广义测试时间增强（GTTA）的新方法，旨在提高已训练模型的性能。GTTA通过对测试输入进行随机的PCA子空间投影扰动来创建鲁棒的集成，有效滤除噪声并减少误差。为了降低测试时间计算成本，GTTA还引入了自监督蒸馏机制，利用集成输出作为教师模型来训练初始的单一学生模型，且不牺牲准确性。实验证明，GTTA在图像分类、分割、语音识别和房价预测等多种视觉和非视觉任务上均表现出通用性和有效性，并在水下鲑鱼检测等特定实际应用中表现出色，同时引入了大型DeepSalmon数据集。", "keywords": "广义测试时间增强, 自监督蒸馏, PCA子空间, 鲁棒集成, 泛化性", "comments": "GTTA的创新之处在于其结合了随机PCA子空间扰动和自监督蒸馏，实现了模型性能的提升和计算成本的降低。其通用性是显著优势，能应用于多种视觉和非视觉任务。引入DeepSalmon数据集也为特定领域研究提供了宝贵资源。"}}
{"id": "2507.01862", "title": "Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents", "authors": ["Sanjay Krishna Anbalagan", "Xinrui Nie", "Umesh Mohan", "Vijay Kumar Kanamarlapudi", "Anughna Kommalapati", "Xiaodan Zhao"], "summary": "Domain specific chatbot applications often involve multi step interactions,\nsuch as refining search filters, selecting multiple items, or performing\ncomparisons. Traditional graphical user interfaces (GUIs) handle these\nworkflows by providing explicit \"Submit\" (commit data) and \"Reset\" (discard\ndata) actions, allowing back-end systems to track user intent unambiguously. In\ncontrast, conversational agents rely on subtle language cues, which can lead to\nconfusion and incomplete context management. This paper proposes modeling these\nGUI inspired metaphors acknowledgment (submit like) and context switching\n(reset-like) as explicit tasks within large language model (LLM) prompts. By\ncapturing user acknowledgment, reset actions, and chain of thought (CoT)\nreasoning as structured session data, we preserve clarity, reduce user\nconfusion, and align domain-specific chatbot interactions with back-end logic.\nWe demonstrate our approach in hotel booking and customer management scenarios,\nhighlighting improvements in multi-turn task coherence, user satisfaction, and\nefficiency.", "comment": "8 pages, 1 figure, pre-print of poster accepted for HCI International\n  2025 (HCII 2025), CCIS vol 2529", "pdf_url": "http://arxiv.org/pdf/2507.01862v1", "categories": ["cs.HC", "cs.AI", "H.5.2; I.2.7"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01862v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "连接UI设计与聊天机器人交互：将基于表单的原则应用于对话代理", "tldr": "本文提出通过在大型语言模型提示中明确建模类似表单的“提交”和“重置”操作，以提高领域特定聊天机器人的多轮交互清晰度和效率。", "motivation": "传统的图形用户界面（GUI）通过明确的“提交”和“重置”操作来处理多步骤工作流，从而清晰地跟踪用户意图。相比之下，对话代理依赖于微妙的语言线索，这可能导致混淆和不完整的上下文管理，尤其是在领域特定的多步骤交互中。", "method": "本文提出将GUI中类似“提交”（确认数据）和“重置”（丢弃数据）的隐喻建模为大型语言模型（LLM）提示中的明确任务。通过将用户确认、重置操作和思维链（CoT）推理捕获为结构化的会话数据，以保持清晰度并减少用户混淆，使领域特定聊天机器人交互与后端逻辑对齐。", "result": "该方法在酒店预订和客户管理场景中得到了验证，展示了多轮任务连贯性、用户满意度和效率方面的改进。", "conclusion": "通过将GUI中基于表单的明确操作（如提交和重置）引入到大型语言模型驱动的聊天机器人交互中，可以显著提高多轮对话的清晰度、用户满意度和效率，从而更好地管理上下文和用户意图。", "translation": "领域特定聊天机器人应用程序通常涉及多步骤交互，例如细化搜索过滤器、选择多个项目或执行比较。传统的图形用户界面（GUI）通过提供明确的“提交”（提交数据）和“重置”（丢弃数据）操作来处理这些工作流程，从而使后端系统能够明确地跟踪用户意图。相比之下，对话代理依赖于微妙的语言线索，这可能导致混淆和不完整的上下文管理。本文提出将这些受GUI启发的元数据确认（类似提交）和上下文切换（类似重置）建模为大型语言模型（LLM）提示中的明确任务。通过将用户确认、重置操作和思维链（CoT）推理捕获为结构化的会话数据，我们保持了清晰度，减少了用户混淆，并将领域特定聊天机器人交互与后端逻辑对齐。我们在酒店预订和客户管理场景中展示了我们的方法，突出了多轮任务连贯性、用户满意度和效率方面的改进。", "summary": "本文提出一种新方法，旨在通过将图形用户界面（GUI）中明确的“提交”和“重置”操作原则引入到基于大型语言模型（LLM）的聊天机器人中，以解决多步骤对话中上下文管理和用户意图跟踪的挑战。通过在LLM提示中明确建模这些操作，并将用户确认、重置行为及思维链推理作为结构化会话数据捕获，该方法显著提高了领域特定聊天机器人交互的清晰度、用户满意度和效率，并在酒店预订和客户管理场景中得到了验证。", "keywords": "聊天机器人, 用户界面设计, 大型语言模型, 多轮对话, 上下文管理", "comments": "该论文的创新点在于将传统GUI中明确的用户交互模式（如提交和重置）巧妙地映射并集成到基于LLM的对话代理中。这提供了一种新颖的框架来解决聊天机器人多轮交互中常见的上下文丢失和用户意图模糊问题，对于提升领域特定聊天机器人的实用性和用户体验具有重要意义。该方法通过结构化会话数据来增强LLM的上下文理解和控制能力，为未来更鲁棒的对话系统设计提供了有益的思路。"}}
{"id": "2507.01041", "title": "Fast AI Model Splitting over Edge Networks", "authors": ["Zuguang Li", "Wen Wu", "Shaohua Wu", "Songge Zhang", "Ye Wang", "Xuemin", "Shen"], "summary": "Split learning (SL) has emerged as a computationally efficient approach for\nartificial intelligence (AI) model training, which can alleviate device-side\ncomputational workloads. However, complex AI model architectures pose high\ncomputational complexity to obtain the optimal model splitting. In this paper,\nwe represent an arbitrary AI model as a directed acyclic graph (DAG), and then\nreformulate the optimal model splitting problem as a minimum s-t cut search\nproblem. To solve the problem, we propose a fast DAG-based model splitting\nalgorithm, which restructures the DAG to enable the optimal model splitting\nidentification via a maximum flow method. Theoretical analysis indicates that\nthe proposed algorithm is optimal. Furthermore, considering AI models with\nblock structures, we propose a block-wise model splitting algorithm to reduce\ncomputational complexity. The algorithm abstracts each block, i.e., a component\nconsisting of multiple layers, into a single vertex, thereby obtaining the\noptimal model splitting via a simplified DAG. Extensive experimental results\ndemonstrate that the proposed algorithms can determine the optimal model\nsplitting within milliseconds, as well as reduce training delay by\n24.62%-38.95% in dynamic edge networks as compared to the state-of-the-art\nbenchmarks.", "comment": "13 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.01041v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01041v1", "date": "2025-06-23", "updated": "2025-06-23", "AI": {"title_translation": "边缘网络上的快速AI模型拆分", "tldr": "本文提出了一种基于图论（s-t割、最大流）的快速算法，用于在边缘网络中实现AI模型的最佳拆分，从而减少训练延迟。", "motivation": "拆分学习（SL）作为一种计算高效的AI模型训练方法，可以减轻设备侧的计算负载。然而，复杂的AI模型架构使得获取最佳模型拆分具有很高的计算复杂性。", "method": "本文将任意AI模型表示为一个有向无环图（DAG），并将最佳模型拆分问题重新表述为最小s-t割搜索问题。为解决该问题，提出了一种基于DAG的快速模型拆分算法，该算法重构DAG以通过最大流方法实现最佳模型拆分识别。此外，考虑到具有块结构的AI模型，提出了一种块式模型拆分算法，将每个块抽象为一个单独的顶点，从而通过简化的DAG获得最佳模型拆分。", "result": "理论分析表明所提出的基于DAG的算法是最佳的。广泛的实验结果表明，所提出的算法可以在几毫秒内确定最佳模型拆分，并且与最先进的基准相比，在动态边缘网络中将训练延迟降低24.62%-38.95%。", "conclusion": "本文提出的快速且最佳的模型拆分算法显著提高了AI模型在边缘网络中的效率并减少了训练延迟。", "translation": "拆分学习（SL）作为一种计算高效的人工智能（AI）模型训练方法，可以减轻设备侧的计算负载。然而，复杂的AI模型架构给获取最佳模型拆分带来了很高的计算复杂性。在本文中，我们将任意AI模型表示为一个有向无环图（DAG），然后将最佳模型拆分问题重新表述为最小s-t割搜索问题。为了解决这个问题，我们提出了一种基于DAG的快速模型拆分算法，该算法重构DAG以通过最大流方法实现最佳模型拆分识别。理论分析表明所提出的算法是最佳的。此外，考虑到具有块结构的AI模型，我们提出了一种块式模型拆分算法以降低计算复杂性。该算法将每个块（即由多个层组成的组件）抽象为一个单独的顶点，从而通过简化的DAG获得最佳模型拆分。广泛的实验结果表明，所提出的算法可以在几毫秒内确定最佳模型拆分，并且与最先进的基准相比，在动态边缘网络中将训练延迟降低24.62%-38.95%。", "summary": "本文旨在解决边缘网络中AI模型拆分学习的计算挑战。通过将AI模型表示为有向无环图（DAG），并将最佳拆分问题重新表述为最小s-t割问题，作者提出了一种基于DAG的快速模型拆分算法，该算法利用最大流方法实现最佳拆分。对于具有块结构的AI模型，还提出了一种块式算法以进一步简化问题。实验结果表明，所提出的算法能够在毫秒级时间内找到最佳拆分，并显著降低了边缘网络中的训练延迟。", "keywords": "AI模型拆分, 边缘网络, 拆分学习, 有向无环图, 最大流", "comments": "本文的创新之处在于将AI模型拆分问题巧妙地转化为图论中的最小s-t割问题，并提出了理论上最优且实践中高效的解决方案。特别是针对边缘计算环境的需求，其算法能够快速确定最佳拆分点，并显著降低训练延迟，这对于资源受限的边缘设备AI部署具有重要意义。块式拆分算法是对常见模型结构的优化，进一步提升了实用性。"}}
{"id": "2507.01045", "title": "Sensing Cardiac Health Across Scenarios and Devices: A Multi-Modal Foundation Model Pretrained on Heterogeneous Data from 1.7 Million Individuals", "authors": ["Xiao Gu", "Wei Tang", "Jinpei Han", "Veer Sangha", "Fenglin Liu", "Shreyank N Gowda", "Antonio H. Ribeiro", "Patrick Schwab", "Kim Branson", "Lei Clifton", "Antonio Luiz P. Ribeiro", "Zhangdaihong Liu", "David A. Clifton"], "summary": "Cardiac biosignals, such as electrocardiograms (ECG) and photoplethysmograms\n(PPG), are of paramount importance for the diagnosis, prevention, and\nmanagement of cardiovascular diseases, and have been extensively used in a\nvariety of clinical tasks. Conventional deep learning approaches for analyzing\nthese signals typically rely on homogeneous datasets and static bespoke models,\nlimiting their robustness and generalizability across diverse clinical settings\nand acquisition protocols. In this study, we present a cardiac sensing\nfoundation model (CSFM) that leverages advanced transformer architectures and a\ngenerative, masked pretraining strategy to learn unified representations from\nvast, heterogeneous health records. Our model is pretrained on an innovative\nmulti-modal integration of data from multiple large-scale datasets (including\nMIMIC-III-WDB, MIMIC-IV-ECG, and CODE), comprising cardiac signals and the\ncorresponding clinical or machine-generated text reports from approximately 1.7\nmillion individuals. We demonstrate that the embeddings derived from our CSFM\nnot only serve as effective feature extractors across diverse cardiac sensing\nscenarios, but also enable seamless transfer learning across varying input\nconfigurations and sensor modalities. Extensive evaluations across diagnostic\ntasks, demographic information recognition, vital sign measurement, clinical\noutcome prediction, and ECG question answering reveal that CSFM consistently\noutperforms traditional one-modal-one-task approaches. Notably, CSFM exhibits\nrobust performance across multiple ECG lead configurations from standard\n12-lead systems to single-lead setups, and in scenarios where only ECG, only\nPPG, or a combination thereof is available. These findings highlight the\npotential of CSFM as a versatile and scalable solution, for comprehensive\ncardiac monitoring.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01045v1", "categories": ["cs.LG", "cs.AI", "eess.SP"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01045v1", "date": "2025-06-23", "updated": "2025-06-23", "AI": {"title_translation": "跨场景和设备的心脏健康感知：一个基于来自170万个体的异构数据预训练的多模态基础模型", "tldr": "本文提出了一个名为CSFM的多模态心脏感知基础模型，它利用来自170万个体的异构心电图/PPG和文本数据进行预训练，在各种心脏健康感知任务和场景中表现出优于传统方法的性能和泛化能力。", "motivation": "传统的深度学习方法在分析心脏生物信号时，依赖于同质数据集和静态模型，导致其在不同临床环境和采集协议下的鲁棒性和泛化能力受限。", "method": "本研究提出了一个心脏感知基础模型（CSFM），该模型采用先进的Transformer架构和生成式掩码预训练策略，从约170万个个体的海量异构健康记录（包括心脏信号如ECG和PPG，以及相应的临床或机器生成的文本报告）中学习统一的表示。模型在MIMIC-III-WDB、MIMIC-IV-ECG和CODE等多个大规模数据集上进行多模态集成预训练。", "result": "CSFM导出的嵌入不仅能作为跨各种心脏感知场景的有效特征提取器，还能实现跨不同输入配置和传感器模态的无缝迁移学习。在诊断任务、人口统计信息识别、生命体征测量、临床结果预测和心电图问答等广泛评估中，CSFM始终优于传统的“一模态一任务”方法。CSFM在多种ECG导联配置（从标准12导联到单导联）以及仅有ECG、仅有PPG或两者组合的场景中均表现出稳健的性能。", "conclusion": "CSFM具有作为全面心脏监测多功能、可扩展解决方案的巨大潜力。", "translation": "心脏生物信号，如心电图（ECG）和光电容积描记图（PPG），对于心血管疾病的诊断、预防和管理至关重要，并已广泛应用于各种临床任务。传统的深度学习方法分析这些信号通常依赖于同质数据集和静态定制模型，这限制了它们在不同临床环境和采集方案中的鲁棒性和泛化能力。在本研究中，我们提出了一种心脏感知基础模型（CSFM），它利用先进的Transformer架构和生成式掩码预训练策略，从大量的异构健康记录中学习统一的表示。我们的模型在一个创新的多模态数据集成上进行预训练，这些数据来自多个大规模数据集（包括MIMIC-III-WDB、MIMIC-IV-ECG和CODE），包含了约170万个个体的心脏信号和相应的临床或机器生成的文本报告。我们证明，从CSFM导出的嵌入不仅可以作为跨各种心脏感知场景的有效特征提取器，而且还可以实现跨不同输入配置和传感器模态的无缝迁移学习。在诊断任务、人口统计信息识别、生命体征测量、临床结果预测和心电图问答方面的广泛评估表明，CSFM始终优于传统的“一模态一任务”方法。值得注意的是，CSFM在从标准12导联系统到单导联设置的多种心电图导联配置中，以及在仅有心电图、仅有PPG或两者组合可用的场景中，均表现出稳健的性能。这些发现突出了CSFM作为一种多功能、可扩展的解决方案，在全面心脏监测方面的潜力。", "summary": "本文介绍了一种心脏感知基础模型（CSFM），旨在克服传统深度学习方法在分析心脏生物信号时泛化能力和鲁棒性不足的限制。CSFM采用先进的Transformer架构和生成式掩码预训练策略，通过整合来自170万个体的ECG、PPG和文本报告等异构多模态数据进行训练。实验结果表明，CSFM的嵌入能有效提取特征并支持跨任务、跨输入配置和跨传感器模态的无缝迁移学习，其性能在多项心脏健康感知任务中均优于传统方法，并展现出在不同ECG导联配置下的稳健性。CSFM被证明是一个用于全面心脏监测的多功能且可扩展的解决方案。", "keywords": "心脏感知, 基础模型, 多模态, 异构数据, 迁移学习", "comments": "该论文的创新点在于提出了一个多模态基础模型（CSFM），用于心脏健康感知，并利用了来自170万个体的海量异构数据进行预训练，整合了心电信号和文本报告。这显著提升了模型在多样化临床场景下的鲁棒性和泛化能力，解决了传统方法的局限性。其在多种任务和不同传感器模态间的卓越表现，凸显了其在实际心脏监测中的重要应用潜力。未提及局限性。"}}
{"id": "2507.01881", "title": "A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs", "authors": ["Niccolò McConnell", "Pardeep Vasudev", "Daisuke Yamada", "Daryl Cheng", "Mehran Azimbagirad", "John McCabe", "Shahab Aslani", "Ahmed H. Shahin", "Yukun Zhou", "The SUMMIT Consortium", "Andre Altmann", "Yipeng Hu", "Paul Taylor", "Sam M. Janes", "Daniel C. Alexander", "Joseph Jacob"], "summary": "Low-dose computed tomography (LDCT) imaging employed in lung cancer screening\n(LCS) programs is increasing in uptake worldwide. LCS programs herald a\ngenerational opportunity to simultaneously detect cancer and non-cancer-related\nearly-stage lung disease. Yet these efforts are hampered by a shortage of\nradiologists to interpret scans at scale. Here, we present TANGERINE, a\ncomputationally frugal, open-source vision foundation model for volumetric LDCT\nanalysis. Designed for broad accessibility and rapid adaptation, TANGERINE can\nbe fine-tuned off the shelf for a wide range of disease-specific tasks with\nlimited computational resources and training data. Relative to models trained\nfrom scratch, TANGERINE demonstrates fast convergence during fine-tuning,\nthereby requiring significantly fewer GPU hours, and displays strong label\nefficiency, achieving comparable or superior performance with a fraction of\nfine-tuning data. Pretrained using self-supervised learning on over 98,000\nthoracic LDCTs, including the UK's largest LCS initiative to date and 27 public\ndatasets, TANGERINE achieves state-of-the-art performance across 14 disease\nclassification tasks, including lung cancer and multiple respiratory diseases,\nwhile generalising robustly across diverse clinical centres. By extending a\nmasked autoencoder framework to 3D imaging, TANGERINE offers a scalable\nsolution for LDCT analysis, departing from recent closed, resource-intensive\nmodels by combining architectural simplicity, public availability, and modest\ncomputational requirements. Its accessible, open-source lightweight design lays\nthe foundation for rapid integration into next-generation medical imaging tools\nthat could transform LCS initiatives, allowing them to pivot from a singular\nfocus on lung cancer detection to comprehensive respiratory disease management\nin high-risk populations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01881v1", "categories": ["eess.IV", "cs.CV", "cs.LG"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2507.01881v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "肺癌筛查项目中用于胸部疾病检测的计算节约型开源基础模型", "tldr": "TANGERINE是一个计算节约型开源基础模型，用于低剂量CT分析，能高效检测多种胸部疾病，解决放射科医生短缺问题。", "motivation": "肺癌筛查项目在全球范围内普及，但放射科医生短缺阻碍了大规模解读LDCT扫描，同时筛查项目有机会同时检测癌症和非癌症相关的早期肺部疾病。", "method": "本文提出了TANGERINE，一个计算节约型、开源的视觉基础模型，用于容积式LDCT分析。该模型通过在超过98,000个胸部LDCT（包括英国最大的LCS计划和27个公共数据集）上进行自监督学习预训练，并将掩码自编码器框架扩展到3D成像。", "result": "相对于从头训练的模型，TANGERINE在微调过程中收敛速度快，GPU小时数显著减少，并显示出强大的标签效率，仅用一小部分微调数据即可达到相当或更优的性能。它在14个疾病分类任务（包括肺癌和多种呼吸系统疾病）上取得了最先进的性能，并能在不同临床中心之间稳健泛化。", "conclusion": "TANGERINE提供了一个可扩展的LDCT分析解决方案，其可访问、开源的轻量级设计为快速整合到下一代医学影像工具中奠定了基础，有望将LCS计划从单一的肺癌检测转向高危人群的综合呼吸系统疾病管理。", "translation": "低剂量计算机断层扫描（LDCT）成像在全球肺癌筛查（LCS）项目中应用日益增多。LCS项目预示着同时检测癌症和非癌症相关早期肺部疾病的世代机遇。然而，这些努力受到放射科医生短缺的阻碍，无法大规模解读扫描结果。本文提出了TANGERINE，一个计算节约型、开源的视觉基础模型，用于容积式LDCT分析。TANGERINE专为广泛可访问性和快速适应性而设计，可以用有限的计算资源和训练数据进行开箱即用的微调，适用于各种疾病特异性任务。相对于从头开始训练的模型，TANGERINE在微调过程中表现出快速收敛，从而显著减少了GPU小时数，并显示出强大的标签效率，仅用一小部分微调数据即可达到相当或更优的性能。TANGERINE使用自监督学习在超过98,000个胸部LDCT（包括英国迄今为止最大的LCS计划和27个公共数据集）上进行预训练，在14个疾病分类任务（包括肺癌和多种呼吸系统疾病）上取得了最先进的性能，同时在不同临床中心之间稳健泛化。通过将掩码自编码器框架扩展到3D成像，TANGERINE为LDCT分析提供了一个可扩展的解决方案，它结合了架构的简洁性、公共可用性、和适度的计算要求，与最近的封闭式、资源密集型模型不同。其可访问、开源的轻量级设计为快速整合到下一代医学影像工具中奠定了基础，这些工具可以改变LCS计划，使其从单一关注肺癌检测转向高危人群的综合呼吸系统疾病管理。", "summary": "本文介绍了TANGERINE，一个计算节约型、开源的视觉基础模型，用于低剂量CT（LDCT）图像的容积分析。该模型旨在解决肺癌筛查中放射科医生短缺问题，通过自监督学习在大量LDCT数据上预训练，并扩展了3D掩码自编码器框架。TANGERINE在微调时表现出快速收敛和高标签效率，在14种胸部疾病分类任务上达到SOTA性能，并具有良好的泛化能力，为LCS计划向综合呼吸疾病管理转型提供了可扩展且易于访问的解决方案。", "keywords": "肺癌筛查, 基础模型, 低剂量CT, 胸部疾病检测, 自监督学习", "comments": "这篇论文的创新点在于提出了一个计算资源需求低、开源且基于3D掩码自编码器框架的视觉基础模型TANGERINE，解决了医学影像领域，特别是LDCT分析中资源密集型模型和放射科医生短缺的痛点。其开源和轻量级设计使其具有很高的实用价值和可扩展性，有望加速AI在临床肺部疾病筛查中的应用，并推动筛查从单一癌症检测向更全面的呼吸系统疾病管理发展。"}}
{"id": "2507.01660", "title": "Re-examining the Legendre-Gauss-Lobatto Pseudospectral Methods for Optimal Control", "authors": ["Yilin Zou", "Fanghua Jiang"], "summary": "Pseudospectral methods represent an efficient approach for solving optimal\ncontrol problems. While Legendre-Gauss-Lobatto (LGL) collocation points have\ntraditionally been considered inferior to Legendre-Gauss (LG) and\nLegendre-Gauss-Radau (LGR) points in terms of convergence properties, this\npaper presents a rigorous re-examination of LGL-based methods. We introduce an\naugmented formulation that enhances the standard LGL collocation approach by\nincorporating an additional degree of freedom (DOF) into the interpolation\nstructure. We demonstrate that this augmented formulation is mathematically\nequivalent to the integral formulation of the LGL collocation method. Through\nanalytical derivation, we establish that the adjoint system in both the\naugmented differential and integral formulations corresponds to a Lobatto IIIB\ndiscontinuous collocation method for the costate vector, thereby resolving the\npreviously reported convergence issues. Our comparative analysis of LG, LGR,\nand LGL collocation methods reveals significant advantages of the improved LGL\napproach in terms of discretized problem dimensionality and symplectic\nintegration properties. Numerical examples validate our theoretical findings,\ndemonstrating that the proposed LGL-based method achieves comparable accuracy\nto LG and LGR methods while offering superior computational performance for\nlong-horizon optimal control problems due to the preservation of symplecticity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01660v1", "categories": ["eess.SY", "cs.SY", "math.OC"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01660v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "重新审视用于最优控制的Legendre-Gauss-Lobatto伪谱方法", "tldr": "本文重新审视了LGL伪谱方法，引入了一种增强公式来解决其收敛问题，并证明其在最优控制问题上具有与LG/LGR相当的精度和更好的计算性能，尤其适用于长时域问题。", "motivation": "传统上，Legendre-Gauss-Lobatto (LGL) 伪谱方法在收敛性方面被认为不如Legendre-Gauss (LG) 和 Legendre-Gauss-Radau (LGR) 方法。本文旨在对LGL方法进行严格的重新审视，以解决其报告的收敛问题并提升其性能。", "method": "本文引入了一种增强的LGL伪谱方法，通过在插值结构中加入一个额外的自由度。该方法被证明在数学上等价于LGL配置方法的积分公式。通过解析推导，作者建立了增强微分和积分公式中的伴随系统对应于余态向量的Lobatto IIIB不连续配置方法。通过比较分析，评估了改进的LGL与LG和LGR方法的性能。", "result": "增强的LGL公式解决了之前报告的收敛问题。改进的LGL方法在离散问题维度和辛积分特性方面显示出显著优势。数值例子验证了理论发现，表明所提出的LGL方法在长时域最优控制问题上实现了与LG和LGR方法相当的精度，同时由于保留了辛性，提供了卓越的计算性能。", "conclusion": "通过引入增强公式并解析推导其伴随系统，本文成功解决了LGL伪谱方法在最优控制中的收敛性问题，并证明了其在计算性能和处理长时域问题方面的优越性。", "translation": "伪谱方法是解决最优控制问题的一种高效方法。尽管Legendre-Gauss-Lobatto (LGL) 配置点在收敛特性方面传统上被认为不如Legendre-Gauss (LG) 和 Legendre-Gauss-Radau (LGR) 点，但本文对基于LGL的方法进行了严格的重新审视。我们引入了一种增强公式，通过在插值结构中引入一个额外的自由度（DOF）来增强标准的LGL配置方法。我们证明了这种增强公式在数学上等价于LGL配置方法的积分公式。通过解析推导，我们确定了增强微分和积分公式中的伴随系统对应于余态向量的Lobatto IIIB不连续配置方法，从而解决了先前报告的收敛问题。我们对LG、LGR和LGL配置方法的比较分析揭示了改进的LGL方法在离散问题维度和辛积分特性方面的显著优势。数值例子验证了我们的理论发现，表明所提出的基于LGL的方法实现了与LG和LGR方法相当的精度，同时由于保留了辛性，在长时域最优控制问题上提供了卓越的计算性能。", "summary": "本文重新审视了在最优控制问题中传统上被认为收敛性较差的Legendre-Gauss-Lobatto (LGL) 伪谱方法。通过引入一种在插值结构中增加额外自由度的增强公式，并证明其与LGL积分公式的数学等价性，该研究解决了LGL方法的收敛问题。分析表明，其伴随系统对应于Lobatto IIIB不连续配置方法。与LG和LGR方法的比较显示，改进的LGL方法在问题维度和辛积分方面具有优势，并在长时域最优控制问题上展现出与LG和LGR相当的精度和更优的计算性能。", "keywords": "伪谱方法, 最优控制, Legendre-Gauss-Lobatto, 收敛性, 辛积分", "comments": "本文的创新点在于提出了LGL伪谱方法的增强公式，并从理论上解决了其长期存在的收敛性问题。通过证明其与积分公式的等价性以及伴随系统的性质，该研究不仅提升了LGL方法的理论完备性，还通过数值验证展示了其在实际应用中的优越性，尤其是在处理长时域最优控制问题时，其辛性保持特性带来了显著的计算性能提升，这对于需要高效率和高精度的工程应用具有重要意义。"}}
{"id": "2507.01352", "title": "Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy", "authors": ["Chris Yuhao Liu", "Liang Zeng", "Yuzhen Xiao", "Jujie He", "Jiacai Liu", "Chaojie Wang", "Rui Yan", "Wei Shen", "Fuxiang Zhang", "Jiacheng Xu", "Yang Liu", "Yahui Zhou"], "summary": "Despite the critical role of reward models (RMs) in reinforcement learning\nfrom human feedback (RLHF), current state-of-the-art open RMs perform poorly on\nmost existing evaluation benchmarks, failing to capture the spectrum of nuanced\nand sophisticated human preferences. Even approaches that incorporate advanced\ntraining techniques have not yielded meaningful performance improvements. We\nhypothesize that this brittleness stems primarily from limitations in\npreference datasets, which are often narrowly scoped, synthetically labeled, or\nlack rigorous quality control. To address these challenges, we present a\nlarge-scale preference dataset comprising 40 million preference pairs, named\nSynPref-40M. To enable data curation at scale, we design a human-AI synergistic\ntwo-stage pipeline that leverages the complementary strengths of human\nannotation quality and AI scalability. In this pipeline, humans provide\nverified annotations, while large language models perform automatic curation\nbased on human guidance. Training on this preference mixture, we introduce\nSkywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B\nparameters, trained on a carefully curated subset of 26 million preference\npairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile\nacross a wide range of capabilities, including alignment with human\npreferences, objective correctness, safety, resistance to stylistic biases, and\nbest-of-N scaling, achieving state-of-the-art performance across seven major\nreward model benchmarks. Ablation studies confirm that the effectiveness of our\napproach stems not only from data scale but also from high-quality curation.\nThe Skywork-Reward-V2 series represents substantial progress in open reward\nmodels, highlighting the untapped potential of existing preference datasets and\ndemonstrating how human-AI curation synergy can unlock significantly higher\ndata quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01352v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01352v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "Skywork-Reward-V2：通过人机协同扩展偏好数据策展", "tldr": "本文提出了Skywork-Reward-V2，一个基于大规模高质量人机协同策展偏好数据集（SynPref-40M）训练的奖励模型系列，在多个基准测试上实现了SOTA性能。", "motivation": "当前最先进的开放奖励模型在现有评估基准上表现不佳，未能捕捉细致入微的人类偏好。这种脆弱性主要源于偏好数据集的局限性，这些数据集通常范围狭窄、合成标注或缺乏严格的质量控制。", "method": "提出并构建了SynPref-40M，一个包含4000万个偏好对的大规模偏好数据集。设计了一个人机协同的两阶段数据策展管道，其中人类提供验证过的标注，大型语言模型根据人类指导进行自动策展。在此数据集的2600万精心策展的偏好对子集上，训练了Skywork-Reward-V2，一个包含八个奖励模型（0.6B至8B参数）的套件。", "result": "Skywork-Reward-V2在与人类偏好的一致性、客观正确性、安全性、对风格偏差的抵抗力以及最佳-N扩展等广泛能力范围内表现出多功能性。在七个主要的奖励模型基准上取得了最先进的性能。消融研究证实，其有效性不仅源于数据规模，也源于高质量的策展。", "conclusion": "Skywork-Reward-V2系列代表了开放奖励模型的重大进展，凸显了现有偏好数据集未开发的潜力，并证明了人机策展协同可以显著提高数据质量。", "translation": "尽管奖励模型（RMs）在人类反馈强化学习（RLHF）中扮演着关键角色，但当前最先进的开放奖励模型在大多数现有评估基准上表现不佳，未能捕捉到细致入微且复杂的类人偏好。即使是结合了先进训练技术的方法也未能带来显著的性能提升。我们假设这种脆弱性主要源于偏好数据集的局限性，这些数据集通常范围狭窄、合成标注或缺乏严格的质量控制。为了解决这些挑战，我们提出了一个包含4000万个偏好对的大规模偏好数据集，名为SynPref-40M。为了实现大规模数据策展，我们设计了一个人机协同的两阶段管道，该管道利用了人工标注质量和AI可扩展性的互补优势。在这个管道中，人类提供经过验证的标注，而大型语言模型则根据人类指导进行自动策展。我们在此偏好混合数据上进行训练，推出了Skywork-Reward-V2，这是一个由八个奖励模型组成的套件，参数范围从0.6B到8B，它们在SynPref-40M中精心策展的2600万个偏好对子集上进行训练。我们证明了Skywork-Reward-V2在广泛的能力范围内具有多功能性，包括与人类偏好的一致性、客观正确性、安全性、对风格偏差的抵抗力以及最佳-N扩展，并在七个主要的奖励模型基准上取得了最先进的性能。消融研究证实，我们方法的有效性不仅源于数据规模，还源于高质量的策展。Skywork-Reward-V2系列代表了开放奖励模型的重大进展，凸显了现有偏好数据集未开发的潜力，并展示了人机策展协同如何显著提高数据质量。", "summary": "本文提出了Skywork-Reward-V2，一个包含八个奖励模型（0.6B至8B参数）的系列，旨在解决当前奖励模型在捕获人类偏好方面的不足。研究人员通过设计一个大规模人机协同的两阶段管道，构建了SynPref-40M数据集，其中包含4000万个偏好对。Skywork-Reward-V2模型在SynPref-40M的2600万高质量偏好对子集上进行训练，并在七个主要奖励模型基准上取得了最先进的性能，展示了其在人类偏好对齐、客观正确性、安全性、抗风格偏差和最佳-N扩展等方面的多功能性。消融研究证实了数据规模和高质量策展对模型性能的重要性。", "keywords": "奖励模型, 人机协同, 偏好数据, RLHF, Skywork-Reward-V2", "comments": "该论文的创新点在于其提出的人机协同数据策展管道，有效地结合了人工标注的质量和AI的扩展性，从而克服了现有偏好数据集的局限性。这种方法不仅显著提升了数据质量和规模，也为开发更强大、更符合人类偏好的奖励模型提供了新的范式。Skywork-Reward-V2在多个基准测试上的SOTA表现证明了该策略的有效性，对于推动RLHF和开放奖励模型的发展具有重要意义。"}}
{"id": "2507.01770", "title": "GPU-based complete search for nonlinear minimization subject to bounds", "authors": ["Guanglu Zhang", "Qihang Shan", "Jonathan Cagan"], "summary": "This paper introduces a GPU-based complete search method to enclose the\nglobal minimum of a nonlinear function subject to simple bounds on the\nvariables. Using interval analysis, coupled with the computational power and\narchitecture of GPU, the method iteratively rules out the regions in the search\ndomain where the global minimum cannot exist and leaves a finite set of regions\nwhere the global minimum must exist. For effectiveness, because of the rigor of\ninterval analysis, the method is guaranteed to enclose the global minimum of\nthe nonlinear function even in the presence of rounding errors. For efficiency,\nthe method employs a novel GPU-based single program, single data parallel\nprogramming style to circumvent major GPU performance bottlenecks, and a\nvariable cycling technique is also integrated into the method to reduce\ncomputational cost when minimizing large-scale nonlinear functions. The method\nis validated by minimizing 10 multimodal benchmark test functions with scalable\ndimensions, including the well-known Ackley function, Griewank function, Levy\nfunction, and Rastrigin function. These benchmark test functions represent\ngrand challenges of global optimization, and enclosing the guaranteed global\nminimum of these benchmark test functions with more than 80 dimensions has not\nbeen reported in the literature. Our method completely searches the feasible\ndomain and successfully encloses the guaranteed global minimum of these 10\nbenchmark test functions with up to 10,000 dimensions using only one GPU in a\nreasonable computation time, far exceeding the reported results in the\nliterature due to the unique method design and implementation based on GPU\narchitecture.", "comment": "36 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.01770v1", "categories": ["math.NA", "cs.AI", "cs.DC", "cs.MS", "cs.NA", "math.OC", "65G20, 65G30, 65G40, 90C06, 90C26, 90C30", "G.1.6; G.4"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01770v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于GPU的带约束非线性最小化完全搜索", "tldr": "本文提出了一种基于GPU的完全搜索方法，利用区间分析和GPU并行计算能力，在存在舍入误差的情况下，也能高效且严格地包围带约束非线性函数的全局最小值，并在多达10,000维的基准测试函数上取得了显著优于现有文献的结果。", "motivation": "现有的全局优化方法在处理高维多模态非线性函数时，难以保证找到全局最小值，尤其是在存在舍入误差的情况下。本文旨在开发一种能够严格包围全局最小值且高效处理高维问题的GPU加速方法。", "method": "该方法基于区间分析，并结合GPU的计算能力和架构。它通过迭代排除搜索域中不可能存在全局最小值的区域，最终保留一个包含全局最小值的有限区域集。为提高效率，该方法采用了新颖的基于GPU的单程序、单数据（SPMD）并行编程风格，以规避GPU性能瓶颈，并集成了变量循环技术以降低处理大规模非线性函数的计算成本。", "result": "该方法成功地包围了10个可伸缩维度多模态基准测试函数的全局最小值，包括Ackley、Griewank、Levy和Rastrigin函数。在合理计算时间内，仅使用一个GPU，该方法成功地包围了维度高达10,000的这些基准测试函数的保证全局最小值，远远超过了文献中报道的结果，尤其是在处理超过80维的基准函数时。", "conclusion": "本文提出的基于GPU的完全搜索方法能够高效且严格地包围带约束非线性函数的全局最小值，即使存在舍入误差，并且在处理高维问题上展现出卓越的性能，显著超越了现有技术水平。", "translation": "本文介绍了一种基于GPU的完全搜索方法，用于包围受变量简单约束的非线性函数的全局最小值。该方法利用区间分析，结合GPU的计算能力和架构，迭代地排除搜索域中全局最小值不可能存在的区域，并留下一个全局最小值必须存在的有限区域集。为了有效性，由于区间分析的严谨性，即使存在舍入误差，该方法也能保证包围非线性函数的全局最小值。为了效率，该方法采用了一种新颖的基于GPU的单程序、单数据并行编程风格，以规避主要的GPU性能瓶颈，并且还集成了变量循环技术，以减少最小化大规模非线性函数时的计算成本。该方法通过最小化10个具有可伸缩维度的多模态基准测试函数进行验证，包括著名的Ackley函数、Griewank函数、Levy函数和Rastrigin函数。这些基准测试函数代表了全局优化的巨大挑战，文献中尚未报道包围维度超过80的这些基准测试函数的保证全局最小值。我们的方法完全搜索了可行域，并在合理计算时间内，仅使用一个GPU，成功地包围了维度高达10,000的这10个基准测试函数的保证全局最小值，由于其独特的基于GPU架构的方法设计和实现，远远超过了文献中报道的结果。", "summary": "本文提出了一种基于GPU的完全搜索方法，用于在简单约束下寻找非线性函数的全局最小值。该方法结合了区间分析的严格性和GPU的并行计算能力，通过迭代排除不可能包含全局最小值的区域，确保即使在舍入误差存在的情况下也能严格包围全局最小值。为提升效率，该方法采用了创新的GPU SPMD并行编程风格和变量循环技术。实验证明，该方法在处理多达10,000维的基准测试函数时，性能远超现有文献报告。", "keywords": "GPU, 全局优化, 区间分析, 非线性最小化, 并行计算", "comments": "该论文的创新点在于将区间分析的严格性与GPU的并行计算能力相结合，解决了高维非线性全局优化中保证全局最小值包围的难题。其采用的GPU SPMD并行编程风格和变量循环技术有效提升了计算效率，使其在处理超高维问题时展现出卓越的性能，显著超越了现有技术水平。这对于需要高精度和可靠性的全局优化问题具有重要意义。"}}
{"id": "2507.01633", "title": "Confidence and Stability of Global and Pairwise Scores in NLP Evaluation", "authors": ["Georgii Levtsov", "Dmitry Ustalov"], "summary": "With the advent of highly capable instruction-tuned neural language models,\nbenchmarking in natural language processing (NLP) is increasingly shifting\ntowards pairwise comparison leaderboards, such as LMSYS Arena, from traditional\nglobal pointwise scores (e.g., GLUE, BIG-bench, SWE-bench). This paper\nempirically investigates the strengths and weaknesses of both global scores and\npairwise comparisons to aid decision-making in selecting appropriate model\nevaluation strategies. Through computational experiments on synthetic and\nreal-world datasets using standard global metrics and the popular Bradley-Terry\nmodel for pairwise comparisons, we found that while global scores provide more\nreliable overall rankings, they can underestimate strong models with rare,\nsignificant errors or low confidence. Conversely, pairwise comparisons are\nparticularly effective for identifying strong contenders among models with\nlower global scores, especially where quality metrics are hard to define (e.g.,\ntext generation), though they require more comparisons to converge if ties are\nfrequent. Our code and data are available at\nhttps://github.com/HSPyroblast/srw-ranking under a permissive license.", "comment": "8 pages, accepted at ACL SRW 2025", "pdf_url": "http://arxiv.org/pdf/2507.01633v1", "categories": ["cs.CL", "cs.IR", "62-04", "D.2.3"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01633v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "NLP评估中全局分数和成对分数的置信度和稳定性", "tldr": "该论文经验性地调查了NLP模型评估中全局分数和成对比较的优缺点。研究发现，全局分数在整体排名上更可靠，但可能低估有罕见显著错误的强模型；而成对比较在识别潜在强模型方面更有效，尤其是在质量指标难以定义时，但收敛需要更多比较。", "motivation": "随着指令调优神经语言模型的出现，自然语言处理（NLP）中的基准测试正从传统的全局点状分数（如GLUE、BIG-bench、SWE-bench）转向成对比较排行榜（如LMSYS Arena）。本文旨在经验性地调查全局分数和成对比较的优缺点，以帮助决策者选择合适的模型评估策略。", "method": "通过在合成数据集和真实世界数据集上进行计算实验，使用标准全局指标和流行的Bradley-Terry模型进行成对比较。", "result": "研究发现，全局分数提供了更可靠的整体排名，但可能低估具有罕见、显著错误或低置信度的强模型。相反，成对比较在识别全局分数较低的模型中的强有力竞争者方面特别有效，尤其是在质量指标难以定义的情况下（例如文本生成），尽管如果平局频繁，它们需要更多的比较才能收敛。", "conclusion": "全局分数在提供可靠的整体排名方面表现出色，但可能忽略特定模型的细微优势；而成对比较能有效识别表现出色的模型，尤其是在难以量化质量的场景中，但需要更多数据才能稳定。选择合适的评估策略取决于具体目标和情境。", "translation": "随着高性能指令调优神经语言模型的出现，自然语言处理（NLP）中的基准测试正日益从传统的全局点状分数（例如GLUE、BIG-bench、SWE-bench）转向成对比较排行榜（例如LMSYS Arena）。本文经验性地调查了全局分数和成对比较的优缺点，以帮助决策者选择合适的模型评估策略。通过在合成数据集和真实世界数据集上使用标准全局指标和流行的Bradley-Terry模型进行成对比较的计算实验，我们发现，虽然全局分数提供了更可靠的整体排名，但它们可能会低估具有罕见、显著错误或低置信度的强模型。相反，成对比较在识别全局分数较低的模型中的强有力竞争者方面特别有效，尤其是在质量指标难以定义时（例如文本生成），尽管如果平局频繁，它们需要更多的比较才能收敛。我们的代码和数据可在https://github.com/HSPyroblast/srw-ranking 下的宽松许可下获取。", "summary": "本研究经验性地分析了NLP模型评估中全局分数和成对比较方法的优缺点。通过在合成和真实数据集上运用标准全局指标和Bradley-Terry模型进行实验，论文揭示了全局分数在提供整体排名上的可靠性，但也指出其可能低估特定强模型。同时，成对比较被证明在识别具有细微优势或在难以量化质量的任务（如文本生成）中的强模型方面更为有效，尽管其收敛需要更多比较。该研究为NLP模型评估策略的选择提供了实用指导。", "keywords": "NLP评估, 全局分数, 成对比较, Bradley-Terry模型, 基准测试", "comments": "该论文解决了当前NLP领域模型评估中一个非常及时且重要的问题，尤其是在大型语言模型涌现和评估方法多样化的背景下。其对全局分数和成对比较这两种主要评估范式的经验性分析，提供了宝贵的见解，有助于研究人员和开发者根据具体评估目标选择更合适的策略。论文指出了两种方法的局限性，例如全局分数可能低估特定模型，而成对比较在平局多时收敛慢，这对于实际应用具有指导意义。代码和数据的公开也增强了研究的透明度和可复现性。"}}
{"id": "2507.01561", "title": "Self-Closing Suction Grippers for Industrial Grasping via Form-Flexible Design", "authors": ["Huijiang Wang", "Holger Kunz", "Timon Adler", "Fumiya Iida"], "summary": "Shape-morphing robots have shown benefits in industrial grasping. We propose\nform-flexible grippers for adaptive grasping. The design is based on the hybrid\njamming and suction mechanism, which deforms to handle objects that vary\nsignificantly in size from the aperture, including both larger and smaller\nparts. Compared with traditional grippers, the gripper achieves self-closing to\nform an airtight seal. Under a vacuum, a wide range of grasping is realized\nthrough the passive morphing mechanism at the interface that harmonizes\npressure and flow rate. This hybrid gripper showcases the capability to\nsecurely grasp an egg, as small as 54.5% of its aperture, while achieving a\nmaximum load-to-mass ratio of 94.3.", "comment": "This manuscript has been submitted for potential consideration at\n  IEEE publication venues", "pdf_url": "http://arxiv.org/pdf/2507.01561v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01561v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "工业抓取用自闭合吸盘式夹具：基于形状柔性设计", "tldr": "提出了一种基于混合式卡塞和吸附机制的形状柔性夹具，用于工业自适应抓取。该夹具能够自闭合以处理尺寸差异显著的物体，并展示了抓取小物体和高载荷质量比的能力。", "motivation": "形状可变形机器人在工业抓取中显示出优势，需要开发能够自适应抓取、处理尺寸差异显著的物体的夹具。", "method": "提出了一种基于混合式卡塞和吸附机制的形状柔性夹具。该夹具通过变形来处理与开口尺寸差异显著的物体，并能自闭合形成气密密封。在真空下，通过界面处的被动变形机制来协调压力和流量，从而实现广泛的抓取范围。", "result": "该混合夹具能够安全抓取小至其开口54.5%的鸡蛋，并实现了94.3的最大载荷质量比。", "conclusion": "该研究提出的混合式形状柔性夹具为工业抓取提供了自适应、安全且高效的解决方案，能够有效处理尺寸差异大的物体，优于传统夹具。", "translation": "形状可变形机器人已在工业抓取中展现出优势。我们提出了一种形状柔性夹具用于自适应抓取。该设计基于混合式卡塞和吸附机制，其可变形以处理与开口尺寸差异显著的物体，包括更大和更小的部件。与传统夹具相比，该夹具实现了自闭合以形成气密密封。在真空条件下，通过界面处的被动变形机制，协调压力和流量，实现了广泛的抓取范围。这种混合夹具展示了安全抓取一个鸡蛋的能力，该鸡蛋仅为其开口的54.5%，同时实现了94.3的最大载荷质量比。", "summary": "本文提出了一种用于工业抓取的新型形状柔性夹具，其核心在于结合了混合式卡塞和吸附机制。与传统夹具不同，该设计实现了自闭合功能，并能自适应地抓取尺寸远小于或大于其开口的物体。通过界面处的被动变形机制，在真空条件下能协调压力和流量，从而实现广泛且安全的抓取范围。实验结果表明，该夹具能有效抓取小至其开口54.5%的物体，并达到94.3的高载荷质量比。", "keywords": "形状柔性夹具, 吸附, 卡塞, 自适应抓取, 工业机器人", "comments": "该论文的创新点在于结合了混合式卡塞和吸附机制，并采用了形状柔性、自闭合的设计，显著增强了工业抓取中对不同尺寸物体的适应性。界面处被动变形机制对压力和流量的协调也是一个关键特性。这有望极大提升自动化处理系统的效率和通用性。"}}
{"id": "2507.01351", "title": "Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model", "authors": ["Chaoxiang Cai", "Longrong Yang", "Kaibing Chen", "Fan Yang", "Xi Li"], "summary": "The mixture-of-experts (MoE), which replaces dense models with sparse\narchitectures, has gained attention in large vision-language models (LVLMs) for\nachieving comparable performance with fewer activated parameters. Existing MoE\nframeworks for LVLMs focus on token-to-expert routing (TER), encouraging\ndifferent experts to specialize in processing distinct tokens. However, these\nframeworks often rely on the load balancing mechanism, overlooking the inherent\ndistributional differences between vision and language. To this end, we propose\na Long-Tailed Distribution-aware Router (LTDR) for vision-language TER,\ntackling two challenges: (1) Distribution-aware router for modality-specific\nrouting. We observe that language TER follows a uniform distribution, whereas\nvision TER exhibits a long-tailed distribution. This discrepancy necessitates\ndistinct routing strategies tailored to each modality. (2) Enhancing expert\nactivation for vision tail tokens. Recognizing the importance of vision tail\ntokens, we introduce an oversampling-like strategy by increasing the number of\nactivated experts for these tokens. Experiments on extensive benchmarks\nvalidate the effectiveness of our approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01351v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01351v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "大型视觉-语言模型中面向混合专家模型的长尾分布感知路由器", "tldr": "针对大型视觉-语言模型中混合专家模型的长尾分布问题，提出了一种新的路由器LTDR，通过模态感知路由和增强视觉长尾token激活来提高性能。", "motivation": "现有的LVLM中MoE框架的token-to-expert路由依赖于负载均衡机制，但忽略了视觉和语言之间固有的分布差异，特别是视觉TER呈现长尾分布，导致需要针对不同模态的独特路由策略。", "method": "提出了一种长尾分布感知路由器（LTDR），用于视觉-语言的token-to-expert路由。它包含两个策略：1) 设计针对模态的分布感知路由器，为视觉和语言采用不同的路由策略（语言均匀分布，视觉长尾分布）。2) 通过增加激活专家数量，为视觉长尾token引入类似过采样的策略，以增强其专家激活。", "result": "广泛基准测试的实验验证了该方法的有效性。", "conclusion": "该研究成功开发并验证了长尾分布感知路由器（LTDR），有效解决了大型视觉-语言模型中MoE路由的模态分布差异问题，特别提升了视觉长尾token的处理能力。", "translation": "混合专家模型（MoE）以其用稀疏架构替代密集模型的能力，在大型视觉-语言模型（LVLMs）中获得了关注，能在激活参数更少的情况下实现可比的性能。现有的LVLM MoE框架侧重于token-to-expert路由（TER），鼓励不同专家专门处理不同的token。然而，这些框架通常依赖负载均衡机制，忽视了视觉和语言之间固有的分布差异。为此，我们提出了一种用于视觉-语言TER的长尾分布感知路由器（LTDR），以解决两个挑战：（1）模态特定路由的分布感知路由器。我们观察到语言TER遵循均匀分布，而视觉TER呈现长尾分布。这种差异需要针对每种模态量身定制不同的路由策略。（2）增强视觉长尾token的专家激活。认识到视觉长尾token的重要性，我们通过增加这些token的激活专家数量，引入了一种类似过采样的策略。在广泛基准测试上的实验验证了我们方法的有效性。", "summary": "本文提出了一种名为长尾分布感知路由器（LTDR）的新型方法，用于解决大型视觉-语言模型（LVLMs）中混合专家模型（MoE）的token-to-expert路由（TER）问题。针对现有方法忽视视觉和语言模态之间固有分布差异的局限性，LTDR设计了模态特定的路由策略，识别出语言TER遵循均匀分布而视觉TER呈现长尾分布的特点。此外，为了增强视觉长尾token的处理，LTDR引入了一种类似过采样的策略，通过增加激活专家数量来提升其专家激活。实验结果证明了该方法的有效性。", "keywords": "混合专家模型, 视觉-语言模型, 长尾分布, 路由器, token-to-expert路由", "comments": "该论文的创新点在于首次关注到大型视觉-语言模型中MoE路由的视觉和语言模态之间存在的长尾分布差异，并提出了一种针对性的解决方案。通过引入模态感知的路由策略和对视觉长尾token的特殊处理，有效提升了MoE在LVLMs中的性能和效率，具有重要的理论和实践意义。"}}
{"id": "2507.01944", "title": "Spatial tangible user interfaces for cognitive assessment and training", "authors": ["Ehud Sharlin", "Yuichi Itoh", "Benjamin Watson", "Yoshifumi Kitamura", "Steve Sutphen", "Lili Liu", "Fumio Kishino"], "summary": "This paper discusses Tangible User Interfaces (TUIs) and their potential\nimpact on cognitive assessment and cognitive training. We believe that TUIs,\nand particularly a subset that we dub spatial TUIs, can extend human computer\ninteraction beyond some of its current limitations. Spatial TUIs exploit human\ninnate spatial and tactile ability in an intuitive and direct manner, affording\ninteraction paradigms that are practically impossible using current interface\ntechnology. As proof-of-concept we examine implementations in the field of\ncognitive assessment and training. In this paper we use Cognitive Cubes, a\nnovel TUI we developed, as an applied test bed for our beliefs, presenting\npromising experimental results for cognitive assessment of spatial ability, and\npossibly for training purposes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01944v1", "categories": ["cs.HC"], "cate": "cs.HC", "url": "http://arxiv.org/abs/2507.01944v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "用于认知评估和训练的空间实体用户界面", "tldr": "本文提出并探讨了空间实体用户界面（空间TUI）在认知评估和训练中的应用潜力，并使用“认知魔方”作为概念验证，展示了在空间能力认知评估方面的有前景的实验结果。", "motivation": "当前人机交互存在局限性，空间实体用户界面（空间TUI）能够利用人类固有的空间和触觉能力，提供直观、直接的交互范式，从而超越现有界面的限制。本文旨在探索其在认知评估和训练领域的应用。", "method": "本文提出了空间实体用户界面（空间TUI）的概念，并开发了一种新型TUI——“认知魔方”作为应用试验平台和概念验证。通过实验，评估其在认知评估和训练方面的效果。", "result": "实验结果显示，在空间能力认知评估方面取得了有前景的成果，并可能适用于训练目的。", "conclusion": "空间实体用户界面，以“认知魔方”为例，通过提供直观、直接的交互范式，在改善认知评估和训练方面显示出巨大的潜力。", "translation": "本文讨论了实体用户界面（TUI）及其对认知评估和认知训练的潜在影响。我们认为，TUI，特别是我们称之为空间TUI的一个子集，可以将人机交互扩展到其目前的一些局限之外。空间TUI以直观和直接的方式利用人类固有的空间和触觉能力，提供了当前界面技术几乎不可能实现的交互范式。作为概念验证，我们研究了在认知评估和训练领域的实现。在本文中，我们使用我们开发的一种新型TUI——认知魔方，作为我们信念的应用试验平台，展示了在空间能力认知评估方面有前景的实验结果，并可能用于训练目的。", "summary": "本文介绍了空间实体用户界面（空间TUI），旨在克服当前人机交互的局限性，并将其应用于认知评估和训练。空间TUI通过利用人类固有的空间和触觉能力，提供了新颖的交互范式。文章以“认知魔方”为例，展示了其在空间能力评估方面的有前景的实验结果，并指出其在训练方面的潜在应用。", "keywords": "实体用户界面, 空间TUI, 认知评估, 认知训练, 认知魔方", "comments": "本文的创新之处在于将实体用户界面（TUI）的概念扩展到空间TUI，并通过利用人类固有的空间和触觉能力，实现了更直观、直接的交互。其重要性体现在其在认知评估和训练这一关键领域的应用潜力。局限性可能在于目前仍处于概念验证阶段，需要更广泛的验证和应用研究。"}}
{"id": "2507.01043", "title": "Data Classification with Dynamically Growing and Shrinking Neural Networks", "authors": ["Szymon Świderski", "Agnieszka Jastrzębska"], "summary": "The issue of data-driven neural network model construction is one of the core\nproblems in the domain of Artificial Intelligence. A standard approach assumes\na fixed architecture with trainable weights. A conceptually more advanced\nassumption is that we not only train the weights, but also find out the optimal\nmodel architecture. We present a new method that realizes just that. This\narticle is an extended version of our conference paper titled \"Dynamic Growing\nand Shrinking of Neural Networks with Monte Carlo Tree Search [26]\". In the\npaper, we show in detail how to create a neural network with a procedure that\nallows dynamic shrinking and growing of the model while it is being trained.\nThe decision-making mechanism for the architectural design is governed by a\nMonte Carlo tree search procedure which simulates network behavior and allows\nto compare several candidate architecture changes to choose the best one. The\nproposed method was validated using both visual and time series datasets,\ndemonstrating its particular effectiveness in multivariate time series\nclassification. This is attributed to the architecture's ability to adapt\ndynamically, allowing independent modifications for each time series. The\napproach is supplemented by Python source code for reproducibility.\nExperimental evaluations in visual pattern and multivariate time series\nclassification tasks revealed highly promising performance, underscoring the\nmethod's robustness and adaptability.", "comment": "Paper submitted to Journal of Computational Science", "pdf_url": "http://arxiv.org/pdf/2507.01043v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01043v1", "date": "2025-06-23", "updated": "2025-06-23", "AI": {"title_translation": "使用动态增长和收缩神经网络进行数据分类", "tldr": "本文提出了一种新的方法，利用蒙特卡洛树搜索在训练过程中动态调整神经网络的架构（增长和收缩），以实现数据分类，并在视觉和时间序列数据集上表现出优异性能，尤其在多元时间序列分类中效果显著。", "motivation": "数据驱动的神经网络模型构建是人工智能领域的核心问题之一。标准方法假设固定的网络架构，但更先进的假设是不仅训练权重，还要找到最优的模型架构。本文旨在解决如何动态构建和优化神经网络架构的问题。", "method": "本文提出了一种在训练过程中允许模型动态收缩和增长的神经网络创建程序。其架构设计决策机制由蒙特卡洛树搜索（MCTS）过程控制，该过程模拟网络行为并比较多个候选架构更改以选择最佳方案。", "result": "该方法在视觉和时间序列数据集上进行了验证，在多元时间序列分类中表现出特别的有效性，这归因于架构能够动态适应，允许对每个时间序列进行独立修改。在视觉模式和多元时间序列分类任务中的实验评估显示出非常有前景的性能，突显了该方法的鲁棒性和适应性。", "conclusion": "本文提出的基于蒙特卡洛树搜索的动态增长和收缩神经网络方法，在数据分类任务中，特别是在处理多元时间序列数据时，展现出卓越的鲁棒性和适应性，能够有效地找到最优模型架构。", "translation": "数据驱动的神经网络模型构建是人工智能领域的核心问题之一。一种标准方法假设固定的架构和可训练的权重。一个概念上更先进的假设是，我们不仅训练权重，还要找出最优的模型架构。我们提出了一种实现这一目标的新方法。本文是我们会议论文“使用蒙特卡洛树搜索动态增长和收缩神经网络[26]”的扩展版本。在论文中，我们详细展示了如何通过一种允许模型在训练过程中动态收缩和增长的程序来创建神经网络。架构设计的决策机制由蒙特卡洛树搜索过程控制，该过程模拟网络行为并允许比较几个候选架构更改以选择最佳方案。所提出的方法使用视觉和时间序列数据集进行了验证，证明了其在多元时间序列分类中的特殊有效性。这归因于架构的动态适应能力，允许对每个时间序列进行独立修改。该方法附有Python源代码以供重现。在视觉模式和多元时间序列分类任务中的实验评估显示出非常有前景的性能，强调了该方法的鲁棒性和适应性。", "summary": "本文提出了一种用于数据分类的动态神经网络构建方法。与传统固定架构不同，该方法在训练过程中利用蒙特卡洛树搜索（MCTS）动态调整神经网络的架构（增长或收缩），以找到最优模型。实验证明，该方法在视觉和时间序列数据集上，尤其在多元时间序列分类任务中，表现出卓越的性能、鲁棒性和适应性。", "keywords": "动态神经网络, 蒙特卡洛树搜索, 架构优化, 数据分类, 时间序列分类", "comments": "该论文的创新之处在于将蒙特卡洛树搜索引入到神经网络的动态架构调整中，实现了在训练过程中自动优化模型结构，而非依赖预设的固定架构。这对于解决传统神经网络模型构建中架构选择的难题具有重要意义，尤其在处理复杂且多变的多元时间序列数据时，其动态适应性展现出显著优势。提供源代码也增强了研究的可复现性。"}}
{"id": "2507.01453", "title": "Rational Censorship Attack: Breaking Blockchain with a Blackboard", "authors": ["Michelle Yeo", "Haoqian Zhang"], "summary": "Censorship resilience is a fundamental assumption underlying the security of\nblockchain protocols. Additionally, the analysis of blockchain security from an\neconomic and game theoretic perspective has been growing in popularity in\nrecent years. In this work, we present a surprising rational censorship attack\non blockchain censorship resilience when we adopt the analysis of blockchain\nsecurity from a game theoretic lens and assume all users are rational. In our\nattack, a colluding group with sufficient voting power censors the remainder\nnodes such that the group alone can gain all the rewards from maintaining the\nblockchain. We show that if nodes are rational, coordinating this attack just\nrequires a public read and write blackboard and we formally model the attack\nusing a game theoretic framework. Furthermore, we note that to ensure the\nsuccess of the attack, nodes need to know the total true voting power held by\nthe colluding group. We prove that the strategy to join the rational censorship\nattack and also for nodes to honestly declare their power is a subgame perfect\nequilibrium in the corresponding extensive form game induced by our attack.\nFinally, we discuss the implications of the attack on blockchain users and\nprotocol designers as well as some potential countermeasures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01453v1", "categories": ["cs.GT", "cs.CR", "cs.DC"], "cate": "cs.GT", "url": "http://arxiv.org/abs/2507.01453v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "理性审查攻击：用黑板打破区块链", "tldr": "本文提出了一种基于博弈论的理性审查攻击，证明在所有用户理性的前提下，一个有足够投票权的串通团体可以通过公共黑板协调攻击，独占区块链维护奖励，且加入攻击和诚实申报权力是子博弈完美均衡。", "motivation": "区块链协议的安全性依赖于其抗审查能力，且区块链安全分析日益采用经济和博弈论视角。本文旨在揭示在假设用户均为理性的博弈论视角下，区块链抗审查能力可能存在的“理性审查攻击”漏洞。", "method": "作者提出了一种“理性审查攻击”，假设所有用户都是理性的，并采用博弈论框架对攻击进行建模。攻击中，一个拥有足够投票权的串通团体通过公共读写黑板协调审查其余节点。他们证明了加入攻击和诚实申报权力是子博弈完美均衡。", "result": "1. 发现了一种“理性审查攻击”，当节点理性时，仅需一个公共读写黑板即可协调攻击。2. 证明了为了攻击成功，节点需要知道串通团体的总真实投票权。3. 证明了加入理性审查攻击以及节点诚实申报其权力的策略，在由该攻击引起的扩展式博弈中是一个子博弈完美均衡。", "conclusion": "该研究揭示了区块链抗审查性在理性假设下可能被打破，并讨论了攻击对区块链用户和协议设计者的影响，以及潜在的对策。", "translation": "审查弹性是区块链协议安全性的基本假设。此外，近年来从经济和博弈论角度分析区块链安全性越来越受欢迎。在这项工作中，我们提出了一种令人惊讶的理性审查攻击，当我们在博弈论视角下分析区块链安全性并假设所有用户都是理性时，这种攻击会破坏区块链的审查弹性。在我们的攻击中，一个拥有足够投票权的串通团体审查其余节点，使得该团体可以独占维护区块链的所有奖励。我们表明，如果节点是理性的，协调这次攻击只需要一个公共读写黑板，并且我们使用博弈论框架正式建模了这次攻击。此外，我们注意到为了确保攻击的成功，节点需要知道串通团体持有的总真实投票权。我们证明了加入理性审查攻击以及节点诚实申报其权力的策略，在由我们的攻击引起的相应扩展式博弈中是一个子博弈完美均衡。最后，我们讨论了这次攻击对区块链用户和协议设计者的影响以及一些潜在的对策。", "summary": "本文研究了区块链的抗审查性，并从博弈论角度，在所有用户理性的假设下，提出了一种“理性审查攻击”。该攻击中，一个拥有足够投票权的串通团体利用公共黑板协调，审查其他节点以独占所有区块链维护奖励。研究证明，这种攻击是可行的，且加入攻击和诚实申报权力构成子博弈完美均衡。文章最后讨论了攻击的影响和潜在对策。", "keywords": "理性审查攻击, 区块链, 博弈论, 抗审查性, 子博弈完美均衡", "comments": "这篇论文通过引入“理性审查攻击”的概念，挑战了区块链抗审查性的基本假设，具有重要的理论意义。其创新之处在于将博弈论方法应用于区块链安全分析，并指出在理性假设下，简单的协调工具（如公共黑板）即可促成攻击。这项工作对区块链协议设计者提出了新的挑战，强调了在设计安全机制时需考虑用户的经济理性行为。"}}
{"id": "2507.01727", "title": "Auto-optimization of Energy Generation for Wave Energy Converters with Active Learning", "authors": ["Siyang Tang", "Wen-Hua Chen", "Cunjia Liu"], "summary": "This paper presents an auto-optimization control framework for wave energy\nconverters (WECs) to maximize energy generation under unknown and changing\nocean conditions. The proposed control framework consists of two levels. The\nhigh-level controller operating at a longer time scale aims to maximize the\naverage energy generation over several wave periods. The generated Power\nTake-Off (PTO) profile as the reference for the low-level physical system to\nfollow. The new auto-optimization process leverages the parameterization of the\nnon-stationary operation condition in WECs, establishing the relationship\nbetween the average energy generation and the key design parameters of the PTO\nforce subject to the unknown wave parameters. The high-level controller is\ndesigned based on the concept of Dual Control for Exploration and Exploitation\n(DCEE) to quickly learn the unknown wave parameters by actively probing the\nocean condition, while generating the optimal PTO profile. During this process,\nthe uncertainty of the estimated wave condition is quantified and embedded in\nthe optimization cost function to enable active learning. Simulation results\nunder unknown regular and irregular waves demonstrate the effectiveness and\nrobustness of this novel auto-optimization WEC systems with active learning,\noutperforming model predictive control, extremum seeking and classic Bang-Bang\ncontrol approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01727v1", "categories": ["eess.SY", "cs.SY"], "cate": "eess.SY", "url": "http://arxiv.org/abs/2507.01727v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于主动学习的波浪能转换器能量生成自动优化", "tldr": "该论文提出了一种波浪能转换器（WEC）的自动优化控制框架，利用主动学习在未知海洋条件下最大化能量生成，并且性能优于现有控制方法。", "motivation": "在未知和不断变化的海洋条件下，最大化波浪能转换器（WEC）的能量生成。", "method": "提出了一种两级控制框架。高层控制器在较长时间尺度上运行，旨在最大化几个波浪周期内的平均能量生成，并生成取力器（PTO）剖面作为低层物理系统的参考。该方法利用了WEC中非平稳运行条件的参数化，建立了平均能量生成与受未知波浪参数影响的PTO力关键设计参数之间的关系。高层控制器基于探索和利用双重控制（DCEE）的概念设计，通过主动探测海洋条件来快速学习未知波浪参数。估计波浪条件的不确定性被量化并嵌入到优化成本函数中，以实现主动学习。", "result": "在未知规则波和不规则波下的仿真结果表明，这种新颖的具有主动学习能力的自动优化WEC系统具有有效性和鲁棒性。其性能优于模型预测控制、极值搜索和经典Bang-Bang控制方法。", "conclusion": "所提出的新型具有主动学习能力的自动优化波浪能转换器（WEC）系统在未知波浪条件下最大化能量生成方面是有效和鲁棒的，并且超越了现有控制方法。", "translation": "这篇论文提出了一种波浪能转换器（WEC）的自动优化控制框架，以在未知和变化的海洋条件下最大化能量生成。所提出的控制框架包含两个层次。在高层控制器在较长时间尺度上运行，旨在最大化几个波浪周期内的平均能量生成。生成的取力器（PTO）曲线作为低层物理系统跟随的参考。新的自动优化过程利用了WEC中非平稳运行条件的参数化，建立了平均能量生成与受未知波浪参数影响的PTO力关键设计参数之间的关系。高层控制器基于探索和利用双重控制（DCEE）的概念设计，通过主动探测海洋条件来快速学习未知波浪参数，同时生成最优的PTO曲线。在此过程中，估计的波浪条件的不确定性被量化并嵌入到优化成本函数中，以实现主动学习。在未知规则波和不规则波下的仿真结果证明了这种新颖的具有主动学习能力的自动优化WEC系统的有效性和鲁棒性，其性能优于模型预测控制、极值搜索和经典Bang-Bang控制方法。", "summary": "该论文提出了一种新颖的两级自动优化控制框架，用于波浪能转换器（WECs），其主要目标是在动态和不可预测的海洋环境中最大化能量生成。高层控制器利用探索和利用双重控制（DCEE）和主动学习，动态学习未知波浪参数并优化取力器（PTO）剖面。仿真结果证实了该框架的有效性和鲁棒性，显示出优于传统控制方法（如模型预测控制、极值搜索和Bang-Bang控制）的性能。", "keywords": "波浪能转换器, 自动优化, 主动学习, 双重控制, 能量生成", "comments": "该论文提出了一种创新的波浪能转换优化方法，通过整合主动学习和双重控制策略。其学习未知波浪参数并实时适应的能力解决了波浪能转换器运行中的一个重大挑战。与现有控制方法的对比性能突出了其在实际应用中提高能量捕获效率的潜力。"}}
{"id": "2507.01437", "title": "Clinical NLP with Attention-Based Deep Learning for Multi-Disease Prediction", "authors": ["Ting Xu", "Xiaoxiao Deng", "Xiandong Meng", "Haifeng Yang", "Yan Wu"], "summary": "This paper addresses the challenges posed by the unstructured nature and\nhigh-dimensional semantic complexity of electronic health record texts. A deep\nlearning method based on attention mechanisms is proposed to achieve unified\nmodeling for information extraction and multi-label disease prediction. The\nstudy is conducted on the MIMIC-IV dataset. A Transformer-based architecture is\nused to perform representation learning over clinical text. Multi-layer\nself-attention mechanisms are employed to capture key medical entities and\ntheir contextual relationships. A Sigmoid-based multi-label classifier is then\napplied to predict multiple disease labels. The model incorporates a\ncontext-aware semantic alignment mechanism, enhancing its representational\ncapacity in typical medical scenarios such as label co-occurrence and sparse\ninformation. To comprehensively evaluate model performance, a series of\nexperiments were conducted, including baseline comparisons, hyperparameter\nsensitivity analysis, data perturbation studies, and noise injection tests.\nResults demonstrate that the proposed method consistently outperforms\nrepresentative existing approaches across multiple performance metrics. The\nmodel maintains strong generalization under varying data scales, interference\nlevels, and model depth configurations. The framework developed in this study\noffers an efficient algorithmic foundation for processing real-world clinical\ntexts and presents practical significance for multi-label medical text modeling\ntasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01437v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01437v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于注意力深度学习的临床自然语言处理用于多疾病预测", "tldr": "本文提出一种基于注意力机制的深度学习方法，用于从电子健康记录文本中进行信息提取和多疾病预测，表现优于现有方法。", "motivation": "解决电子健康记录文本非结构化和高维语义复杂性带来的挑战。", "method": "提出一种基于注意力机制的深度学习方法，实现信息提取和多标签疾病预测的统一建模。在MIMIC-IV数据集上进行研究。采用基于Transformer的架构进行临床文本表示学习，并使用多层自注意力机制捕获关键医学实体及其上下文关系。然后应用基于Sigmoid的多标签分类器预测疾病。模型还结合了上下文感知语义对齐机制，增强了在标签共现和稀疏信息等典型医疗场景中的表示能力。", "result": "结果表明，所提出的方法在多项性能指标上始终优于现有代表性方法。模型在不同数据规模、干扰水平和模型深度配置下均保持强大的泛化能力。", "conclusion": "本研究开发的框架为处理真实世界临床文本提供了高效的算法基础，对多标签医学文本建模任务具有实际意义。", "translation": "本文解决了电子健康记录文本非结构化和高维语义复杂性带来的挑战。提出一种基于注意力机制的深度学习方法，以实现信息提取和多标签疾病预测的统一建模。该研究在MIMIC-IV数据集上进行。采用基于Transformer的架构对临床文本进行表示学习。利用多层自注意力机制捕获关键医学实体及其上下文关系。然后应用基于Sigmoid的多标签分类器来预测多个疾病标签。该模型整合了上下文感知语义对齐机制，增强了其在标签共现和稀疏信息等典型医疗场景中的表示能力。为了全面评估模型性能，进行了一系列实验，包括基线比较、超参数敏感性分析、数据扰动研究和噪声注入测试。结果表明，所提出的方法在多项性能指标上始终优于现有代表性方法。该模型在不同数据规模、干扰水平和模型深度配置下均保持强大的泛化能力。本研究开发的框架为处理真实世界临床文本提供了高效的算法基础，对多标签医学文本建模任务具有实际意义。", "summary": "本文提出了一种基于注意力机制的深度学习方法，具体而言，是一种基于Transformer的架构，结合多层自注意力机制和Sigmoid分类器，用于从非结构化电子健康记录文本中进行统一的信息提取和多标签疾病预测。该方法在MIMIC-IV数据集上进行了测试，并结合了上下文感知语义对齐机制以处理标签共现和稀疏信息。实验结果表明，所提出的模型在各种数据条件下始终优于现有方法并表现出强大的泛化能力，为临床文本处理和多标签医学文本建模提供了高效的基础。", "keywords": "临床自然语言处理, 深度学习, 注意力机制, 多疾病预测, 电子健康记录", "comments": "该论文的创新之处在于提出了一种基于注意力机制的深度学习方法（特别是基于Transformer的架构和上下文感知语义对齐机制），实现了信息提取和多标签疾病预测的统一建模。其重要性在于有效解决了电子健康记录文本的非结构化和高维语义复杂性问题，为实际临床文本处理和多标签医学文本建模任务提供了高效且具有实际意义的算法基础。"}}
{"id": "2507.01789", "title": "The inverse source problem of stochastic wave equation", "authors": ["Yunqing Huang", "Shihan Zhang"], "summary": "To address the ill-posedness of the inverse source problem for the\none-dimensional stochastic Helmholtz equations without attenuation, this study\ndevelops a novel computational framework designed to mitigate this inherent\nchallenge at the numerical implementation level. For the stochastic wave\nequation driven by a finite-jump L\\'evy process (assuming that its jump\namplitude obeys a Gaussian distribution and the jump time interval obeys a\nPoisson distribution), this paper firstly establish the existence of a mild\nsolution to its direct problem satisfying a particular stability estimate.\nBuilding upon these theoretical foundations, we further investigate the\nwell-posedness of the inverse problem and develop a methodology to reconstruct\nthe unknown source terms $f$ and $g$ using the data of the wave field at the\nfinal time point $u(x,T)$. This work not only provides rigorous theoretical\nanalysis and effective numerical schemes for solving inverse source problems in\nthese two specific classes of stochastic wave equations, but also offers new\nperspectives and methodological approaches for addressing a broader range of\nwave propagation inverse problems characterized by non-Gaussian stochastic\nproperties. The proposed framework demonstrates significant relevance for\ncharacterizing physical phenomena influenced by jump-type stochastic\nperturbations, offering promising applications in diverse domains including but\nnot limited to seismic wave propagation analysis and financial market\nvolatility modeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01789v1", "categories": ["math.NA", "cs.NA"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01789v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "随机波动方程的逆源问题", "tldr": "本文针对随机波动方程的逆源问题，提出了一个新颖的计算框架以减轻其病态性，并证明了正向温和解的存在性及稳定性，同时开发了重建未知源项的方法。", "motivation": "解决一维随机Helmholtz方程（无衰减）逆源问题的病态性，并在数值实现层面减轻这一固有挑战。", "method": "针对由有限跳跃Lévy过程驱动的随机波动方程（跳跃幅度服从高斯分布，跳跃时间间隔服从泊松分布），首先建立了其正向问题温和解的存在性并满足特定的稳定性估计。在此理论基础上，进一步研究了逆问题的适定性，并开发了一种利用最终时刻波场数据u(x,T)重建未知源项f和g的方法。", "result": "提供了解决两类特定随机波动方程逆源问题的严谨理论分析和有效的数值方案，并为更广泛的、具有非高斯随机特性的波传播逆问题提供了新的视角和方法学途径。", "conclusion": "所提出的框架对表征受跳跃型随机扰动影响的物理现象具有重要意义，在包括但不限于地震波传播分析和金融市场波动性建模等不同领域具有广阔的应用前景。", "translation": "为了解决一维随机亥姆霍兹方程（无衰减）逆源问题的病态性，本研究开发了一个新颖的计算框架，旨在从数值实现层面减轻这一固有挑战。对于由有限跳跃Lévy过程驱动的随机波动方程（假设其跳跃幅度服从高斯分布且跳跃时间间隔服从泊松分布），本文首先建立了其正向问题温和解的存在性，并满足特定的稳定性估计。在此理论基础上，我们进一步研究了逆问题的适定性，并开发了一种利用最终时刻波场数据u(x,T)重建未知源项f和g的方法。这项工作不仅为解决这两类特定随机波动方程的逆源问题提供了严谨的理论分析和有效的数值方案，而且为解决更广泛的、具有非高斯随机特性的波传播逆问题提供了新的视角和方法学途径。所提出的框架在表征受跳跃型随机扰动影响的物理现象方面表现出显著的相关性，在包括但不限于地震波传播分析和金融市场波动性建模等不同领域具有广阔的应用前景。", "summary": "本文提出了一种新颖的计算框架，旨在解决一维随机Helmholtz方程逆源问题的病态性。研究首先证明了由有限跳跃Lévy过程驱动的随机波动方程正向温和解的存在性及稳定性，然后在此基础上研究了逆问题的适定性，并开发了利用最终波场数据重建未知源项的方法。该框架为解决特定随机波动方程的逆源问题提供了理论和数值方案，并为更广泛的非高斯随机波传播逆问题提供了新方法，在地震波和金融市场等领域具有潜在应用。", "keywords": "随机波动方程, 逆源问题, Lévy过程, 病态性, 数值方案", "comments": "本文的创新之处在于针对随机波动方程的逆源问题，提出了一个新颖的计算框架，并特别关注了由Lévy过程驱动的随机波动方程，为解决其病态性提供了理论和数值方法。其重要性在于不仅提供了严谨的理论分析，还开发了有效的数值方案，并为处理非高斯随机特性的波传播逆问题提供了新视角。该研究在地震波传播和金融市场建模等实际应用领域具有重要意义。"}}
{"id": "2507.01697", "title": "An RRT* algorithm based on Riemannian metric model for optimal path planning", "authors": ["Yu Zhang", "Qi Zhou", "Xiao-Song Yang"], "summary": "This paper presents a Riemannian metric-based model to solve the optimal path\nplanning problem on two-dimensional smooth submanifolds in high-dimensional\nspace. Our model is based on constructing a new Riemannian metric on a\ntwo-dimensional projection plane, which is induced by the high-dimensional\nEuclidean metric on two-dimensional smooth submanifold and reflects the\nenvironmental information of the robot. The optimal path planning problem in\nhigh-dimensional space is therefore transformed into a geometric problem on the\ntwo-dimensional plane with new Riemannian metric. Based on the new Riemannian\nmetric, we proposed an incremental algorithm RRT*-R on the projection plane.\nThe experimental results show that the proposed algorithm is suitable for\nscenarios with uneven fields in multiple dimensions. The proposed algorithm can\nhelp the robot to effectively avoid areas with drastic changes in height,\nground resistance and other environmental factors. More importantly, the RRT*-R\nalgorithm shows better smoothness and optimization properties compared with the\noriginal RRT* algorithm using Euclidean distance in high-dimensional workspace.\nThe length of the entire path by RRT*-R is a good approximation of the\ntheoretical minimum geodesic distance on projection plane.", "comment": "27 pages", "pdf_url": "http://arxiv.org/pdf/2507.01697v1", "categories": ["cs.RO", "math.OC", "00A69, 93C85, 14H55", "I.2.9"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01697v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于黎曼度量模型的RRT*算法在最优路径规划中的应用", "tldr": "本文提出了一种基于黎曼度量模型的RRT*-R算法，用于解决高维空间二维光滑子流形上的最优路径规划问题，该算法通过构建新的黎曼度量将问题转化为二维几何问题，并在复杂环境中表现出更好的平滑性和优化特性。", "motivation": "解决高维空间二维光滑子流形上的最优路径规划问题，并使路径规划能反映机器人所处环境信息。", "method": "本文提出了一种基于黎曼度量模型的RRT*算法（RRT*-R）。该方法通过在高维空间中二维光滑子流形上诱导高维欧几里得度量，在二维投影平面上构建新的黎曼度量，从而将高维空间的最优路径规划问题转化为二维平面上的几何问题。在此基础上，提出了RRT*-R增量算法。", "result": "实验结果表明，RRT*-R算法适用于多维不平坦场景，能有效帮助机器人避开高度、地面阻力等环境因素剧烈变化的区域。与使用欧几里得距离的原始RRT*算法相比，RRT*-R算法表现出更好的平滑性和优化特性。RRT*-R规划的路径长度能很好地近似投影平面上的理论最小测地线距离。", "conclusion": "基于黎曼度量模型的RRT*-R算法能够有效解决高维空间中的最优路径规划问题，并在复杂环境中展现出优越的平滑性和优化性能。", "translation": "本文提出了一种基于黎曼度量模型的RRT*算法，用于解决高维空间二维光滑子流形上的最优路径规划问题。我们的模型基于在二维投影平面上构建新的黎曼度量，该度量由高维欧几里得度量在二维光滑子流形上诱导，并反映了机器人的环境信息。因此，高维空间中的最优路径规划问题被转化为具有新黎曼度量的二维平面上的几何问题。基于新的黎曼度量，我们在投影平面上提出了一种增量算法RRT*-R。实验结果表明，所提出的算法适用于多维不平坦场景。所提出的算法可以帮助机器人有效地避开高度、地面阻力和其他环境因素剧烈变化的区域。更重要的是，与在高维工作空间中使用欧几里得距离的原始RRT*算法相比，RRT*-R算法表现出更好的平滑性和优化特性。RRT*-R的整个路径长度很好地近似了投影平面上的理论最小测地线距离。", "summary": "本研究提出了一种名为RRT*-R的算法，旨在解决高维空间中二维光滑子流形上的最优路径规划问题。该算法通过在高维空间中引入并构建一种新的黎曼度量，将复杂的路径规划问题简化为二维投影平面上的几何问题。实验证明，RRT*-R算法不仅适用于多维不平坦环境，能有效规避障碍，而且与传统的RRT*算法相比，其生成的路径具有更优的平滑性和优化效果，路径长度近似于理论最小测地线距离。", "keywords": "黎曼度量, RRT*算法, 最优路径规划, 子流形, 机器人避障", "comments": "该论文创新性地将黎曼度量引入RRT*算法，将高维路径规划问题转化为二维黎曼流形上的几何问题，有效提升了算法在复杂环境中的性能，特别是在路径平滑性和避障能力方面。"}}
{"id": "2507.01129", "title": "On Design Principles for Private Adaptive Optimizers", "authors": ["Arun Ganesh", "Brendan McMahan", "Abhradeep Thakurta"], "summary": "The spherical noise added to gradients in differentially private (DP)\ntraining undermines the performance of adaptive optimizers like AdaGrad and\nAdam, and hence many recent works have proposed algorithms to address this\nchallenge. However, the empirical results in these works focus on simple tasks\nand models and the conclusions may not generalize to model training in\npractice. In this paper we survey several of these variants, and develop better\ntheoretical intuition for them as well as perform empirical studies comparing\nthem. We find that a common intuition of aiming for unbiased estimates of\nsecond moments of gradients in adaptive optimizers is misguided, and instead\nthat a simple technique called scale-then-privatize (which does not achieve\nunbiased second moments) has more desirable theoretical behaviors and\noutperforms all other variants we study on a small-scale language model\ntraining task. We additionally argue that scale-then-privatize causes the noise\naddition to better match the application of correlated noise mechanisms which\nare more desirable to use in practice.", "comment": "PPML 2025", "pdf_url": "http://arxiv.org/pdf/2507.01129v1", "categories": ["cs.LG", "cs.CR"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01129v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "关于私有自适应优化器的设计原则", "tldr": "差分隐私（DP）训练中，球形噪声会损害AdaGrad和Adam等自适应优化器的性能。本文发现，旨在实现梯度二阶矩无偏估计的常见直觉是错误的，而“先缩放再隐私化”（scale-then-privatize）这一简单技术具有更理想的理论行为，并在小规模语言模型训练任务中优于其他所有变体。", "motivation": "差分隐私（DP）训练中添加到梯度中的球形噪声会损害AdaGrad和Adam等自适应优化器的性能。许多近期工作提出了算法来解决这一挑战，但这些工作的实证结果主要集中在简单任务和模型上，其结论可能无法推广到实际模型训练中。本文旨在调查这些变体，开发更好的理论直觉，并进行实证研究以比较它们，从而解决这一挑战。", "method": "本文调查了几种差分隐私自适应优化器的变体，并针对它们建立了更好的理论直觉。同时，论文还进行了实证研究以比较这些变体。研究发现并论证了“先缩放再隐私化”技术的设计原则。", "result": "研究发现，在自适应优化器中旨在实现梯度二阶矩无偏估计的常见直觉是错误的。相反，一种名为“先缩放再隐私化”（scale-then-privatize）的简单技术（它并未实现无偏的二阶矩）具有更理想的理论行为，并在小规模语言模型训练任务中优于所有其他研究的变体。此外，论文认为“先缩放再隐私化”使得噪声添加更好地匹配了实际中更理想的关联噪声机制的应用。", "conclusion": "“先缩放再隐私化”技术是私有自适应优化器的一种更优设计原则，它在理论行为和实际性能上均表现出色，并且与实践中更理想的关联噪声机制更好地匹配，纠正了之前关于无偏二阶矩估计的错误直觉。", "translation": "差分隐私（DP）训练中添加到梯度中的球形噪声会损害AdaGrad和Adam等自适应优化器的性能，因此许多近期工作提出了算法来解决这一挑战。然而，这些工作的实证结果主要集中在简单任务和模型上，其结论可能无法推广到实际模型训练中。在本文中，我们调查了其中几种变体，并为它们开发了更好的理论直觉，同时进行了实证研究以比较它们。我们发现，在自适应优化器中旨在实现梯度二阶矩无偏估计的常见直觉是错误的，相反，一种名为“先缩放再隐私化”（scale-then-privatize）的简单技术（它并未实现无偏的二阶矩）具有更理想的理论行为，并在小规模语言模型训练任务中优于我们研究的所有其他变体。我们还认为，“先缩放再隐私化”使得噪声添加更好地匹配了实际中更理想的关联噪声机制的应用。", "summary": "本文研究了差分隐私（DP）训练中球形噪声对自适应优化器性能的损害问题。通过调查现有变体、建立理论直觉和进行实证比较，研究发现，追求梯度二阶矩的无偏估计是误导性的。相反，一种名为“先缩放再隐私化”的技术，尽管未能实现无偏估计，却展现出更优的理论特性，并在小规模语言模型训练中超越其他所有变体。该技术还被认为能更好地匹配实际中更理想的关联噪声机制。", "keywords": "差分隐私训练, 自适应优化器, 先缩放再隐私化, 梯度噪声, 隐私保护", "comments": "本文挑战了差分隐私自适应优化器设计中的一个普遍认知，即追求梯度二阶矩的无偏估计。它提出并验证了“先缩放再隐私化”这一反直觉但更有效的方法，这对于DP训练中优化器性能的提升具有重要意义。研究结合了理论分析和在语言模型上的实证验证，增强了其结论的可靠性和实用性。"}}
{"id": "2507.01367", "title": "3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation", "authors": ["Tianrui Lou", "Xiaojun Jia", "Siyuan Liang", "Jiawei Liang", "Ming Zhang", "Yanjun Xiao", "Xiaochun Cao"], "summary": "Physical adversarial attack methods expose the vulnerabilities of deep neural\nnetworks and pose a significant threat to safety-critical scenarios such as\nautonomous driving. Camouflage-based physical attack is a more promising\napproach compared to the patch-based attack, offering stronger adversarial\neffectiveness in complex physical environments. However, most prior work relies\non mesh priors of the target object and virtual environments constructed by\nsimulators, which are time-consuming to obtain and inevitably differ from the\nreal world. Moreover, due to the limitations of the backgrounds in training\nimages, previous methods often fail to produce multi-view robust adversarial\ncamouflage and tend to fall into sub-optimal solutions. Due to these reasons,\nprior work lacks adversarial effectiveness and robustness across diverse\nviewpoints and physical environments. We propose a physical attack framework\nbased on 3D Gaussian Splatting (3DGS), named PGA, which provides rapid and\nprecise reconstruction with few images, along with photo-realistic rendering\ncapabilities. Our framework further enhances cross-view robustness and\nadversarial effectiveness by preventing mutual and self-occlusion among\nGaussians and employing a min-max optimization approach that adjusts the\nimaging background of each viewpoint, helping the algorithm filter out\nnon-robust adversarial features. Extensive experiments validate the\neffectiveness and superiority of PGA. Our code is available\nat:https://github.com/TRLou/PGA.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.01367v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01367v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "3D高斯泼溅驱动的多视角鲁棒物理对抗伪装生成", "tldr": "本文提出了一种基于3D高斯泼溅（3DGS）的物理对抗攻击框架PGA，用于生成多视角鲁棒的对抗性伪装，解决了现有方法在复杂物理环境中缺乏有效性和鲁棒性的问题。", "motivation": "物理对抗攻击暴露出深度神经网络的脆弱性，对自动驾驶等安全关键场景构成重大威胁。现有方法大多依赖耗时且与真实世界存在差异的目标物体网格先验和虚拟环境，并且由于训练图像背景的限制，难以生成多视角鲁棒的对抗性伪装，导致对抗效果和鲁棒性不足。", "method": "我们提出了一个名为PGA的物理攻击框架，该框架基于3D高斯泼溅（3DGS），能够用少量图像进行快速精确重建并提供逼真的渲染能力。该框架通过防止高斯点之间的相互和自遮挡，并采用一种调整每个视角成像背景的最小-最大优化方法，来增强跨视角鲁棒性和对抗有效性，帮助算法过滤掉非鲁棒的对抗特征。", "result": "广泛的实验验证了PGA的有效性和优越性。", "conclusion": "本文提出的基于3D高斯泼溅的PGA框架能有效生成多视角鲁棒的物理对抗伪装，解决了现有方法的局限性，并在实验中展现出优越性。", "translation": "物理对抗攻击方法暴露了深度神经网络的脆弱性，对自动驾驶等安全关键场景构成了重大威胁。与基于补丁的攻击相比，基于伪装的物理攻击是一种更有前景的方法，在复杂的物理环境中提供了更强的对抗效果。然而，大多数现有工作依赖于目标物体的网格先验和模拟器构建的虚拟环境，这些获取耗时且不可避免地与真实世界存在差异。此外，由于训练图像背景的限制，先前的方法通常无法产生多视角鲁棒的对抗性伪装，并倾向于陷入次优解。由于这些原因，先前的工作在不同视角和物理环境中的对抗有效性和鲁棒性方面有所欠缺。我们提出了一种基于3D高斯泼溅（3DGS）的物理攻击框架，命名为PGA，它能够用少量图像进行快速精确重建，并具有照片级真实感渲染能力。我们的框架通过防止高斯点之间的相互和自遮挡，并采用调整每个视角成像背景的最小-最大优化方法，进一步增强了跨视角鲁棒性和对抗有效性，帮助算法过滤掉非鲁棒的对抗特征。广泛的实验验证了PGA的有效性和优越性。我们的代码可在以下网址获取：https://github.com/TRLou/PGA。", "summary": "本文提出了一种名为PGA的物理对抗攻击框架，该框架利用3D高斯泼溅（3DGS）技术，旨在生成多视角鲁棒的物理对抗伪装。针对现有方法依赖网格先验、虚拟环境以及缺乏多视角鲁棒性的问题，PGA通过快速精确重建、逼真渲染、防止高斯点遮挡和采用最小-最大优化策略来增强跨视角鲁棒性和对抗有效性。实验结果验证了PGA的有效性和优越性。", "keywords": "3D高斯泼溅, 对抗攻击, 伪装生成, 多视角鲁棒性, 物理对抗", "comments": "该论文的创新点在于将3D高斯泼溅技术引入物理对抗伪装生成领域，解决了传统方法在真实物理环境中的重建精度和多视角鲁棒性问题。通过结合3DGS的快速重建和渲染能力，以及独特的遮挡预防和最小-最大优化策略，PGA显著提升了对抗伪装的实用性和鲁棒性，对于提高安全关键系统中对抗攻击的有效性具有重要意义。"}}
{"id": "2507.01047", "title": "Variational Digital Twins", "authors": ["Logan A. Burnett", "Umme Mahbuba Nabila", "Majdi I. Radaideh"], "summary": "While digital twins (DT) hold promise for providing real-time insights into\ncomplex energy assets, much of the current literature either does not offer a\nclear framework for information exchange between the model and the asset, lacks\nkey features needed for real-time implementation, or gives limited attention to\nmodel uncertainty. Here, we aim to solve these gaps by proposing a variational\ndigital twin (VDT) framework that augments standard neural architectures with a\nsingle Bayesian output layer. This lightweight addition, along with a novel VDT\nupdating algorithm, lets a twin update in seconds on commodity GPUs while\nproducing calibrated uncertainty bounds that can inform experiment design,\ncontrol algorithms, and model reliability. The VDT is evaluated on four\nenergy-sector problems. For critical-heat-flux prediction, uncertainty-driven\nactive learning reaches R2 = 0.98 using 47 % fewer experiments and one-third\nthe training time of random sampling. A three-year renewable-generation twin\nmaintains R2 > 0.95 for solar output and curbs error growth for volatile wind\nforecasts via monthly updates that process only one month of data at a time. A\nnuclear reactor transient cooldown twin reconstructs thermocouple signals with\nR2 > 0.99 and preserves accuracy after 50 % sensor loss, demonstrating\nrobustness to degraded instrumentation. Finally, a physics-informed Li-ion\nbattery twin, retrained after every ten discharges, lowers voltage mean-squared\nerror by an order of magnitude relative to the best static model while adapting\nits credible intervals as the cell approaches end-of-life. These results\ndemonstrate that combining modest Bayesian augmentation with efficient update\nschemes turns conventional surrogates into uncertainty-aware, data-efficient,\nand computationally tractable DTs, paving the way for dependable models across\nindustrial and scientific energy systems.", "comment": "33 pages, 14 figures, and 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.01047v1", "categories": ["cs.LG", "cs.SY", "eess.SY"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01047v1", "date": "2025-06-25", "updated": "2025-06-25", "AI": {"title_translation": "变分数字孪生", "tldr": "本文提出了一种变分数字孪生（VDT）框架，通过在神经网络中加入贝叶斯输出层和新型更新算法，解决了现有数字孪生在信息交换、实时性、不确定性处理方面的不足，实现了快速更新、校准不确定性边界，并在多个能源领域问题上展现出优越性能。", "motivation": "现有的数字孪生（DT）在模型与资产间的信息交换缺乏明确框架，缺少实时实现所需的关键特性，或对模型不确定性关注不足。", "method": "本文提出了一种变分数字孪生（VDT）框架，通过为标准神经架构增加一个轻量级的贝叶斯输出层，并结合一种新颖的VDT更新算法。该方法允许数字孪生在商品级GPU上几秒内完成更新，并生成可校准的不确定性边界。", "result": "VDT在四个能源领域问题上进行了评估：1. 在临界热通量预测中，不确定性驱动的主动学习以少47%的实验和三分之一的训练时间达到R2=0.98。2. 一个三年期的可再生能源发电孪生模型，通过每月更新（每次处理一个月数据），保持太阳能输出R2>0.95，并抑制了波动风力预测的误差增长。3. 一个核反应堆瞬态冷却孪生模型，在50%传感器丢失后仍能以R2>0.99重建热电偶信号并保持精度，显示出对仪器退化的鲁棒性。4. 一个物理信息锂离子电池孪生模型，每次放电十次后重新训练，相对于最佳静态模型将电压均方误差降低了一个数量级，并随着电池接近寿命末期调整其可信区间。", "conclusion": "将适度的贝叶斯增强与高效更新方案相结合，可以将传统代理模型转变为具有不确定性感知能力、数据高效且计算可行的数字孪生，为工业和科学能源系统中的可靠模型铺平道路。", "translation": "尽管数字孪生（DT）有望为复杂的能源资产提供实时洞察，但当前的大部分文献要么没有提供模型和资产之间信息交换的清晰框架，要么缺乏实时实施所需的关键特性，要么对模型不确定性关注有限。在此，我们旨在通过提出一种变分数字孪生（VDT）框架来解决这些差距，该框架通过一个单一的贝叶斯输出层增强了标准神经网络架构。这种轻量级的添加，连同一种新颖的VDT更新算法，使得数字孪生能够在商品级GPU上在几秒钟内更新，同时产生可校准的不确定性边界，这些边界可以为实验设计、控制算法和模型可靠性提供信息。VDT在四个能源领域问题上进行了评估。对于临界热通量预测，不确定性驱动的主动学习在减少47%的实验和三分之一的训练时间的情况下达到了R2 = 0.98。一个三年期的可再生能源发电孪生模型，通过每月更新（每次只处理一个月的数据），保持了太阳能输出的R2 > 0.95，并抑制了波动风力预测的误差增长。一个核反应堆瞬态冷却孪生模型，以R2 > 0.99重建了热电偶信号，并在50%传感器丢失后仍保持了精度，展示了对退化仪器的鲁棒性。最后，一个物理信息锂离子电池孪生模型，每放电十次后重新训练，相对于最佳静态模型将电压均方误差降低了一个数量级，同时随着电池接近寿命末期调整其可信区间。这些结果表明，将适度的贝叶斯增强与高效更新方案相结合，可以将传统代理模型转变为具有不确定性感知能力、数据高效且计算可行的数字孪生，为工业和科学能源系统中的可靠模型铺平道路。", "summary": "本文提出了一种变分数字孪生（VDT）框架，旨在解决传统数字孪生在信息交换、实时性和不确定性处理方面的不足。VDT通过在神经网络中集成轻量级贝叶斯输出层和创新的更新算法，实现了快速高效的模型更新，并能提供校准的不确定性边界。该框架在临界热通量预测、可再生能源发电、核反应堆冷却和锂离子电池健康监测等四个能源领域问题上进行了验证，结果表明VDT在数据效率、计算可行性以及对不确定性和传感器退化的鲁棒性方面均表现出色，为开发可靠的工业与科学能源系统模型提供了新途径。", "keywords": "数字孪生, 变分贝叶斯, 不确定性量化, 实时性, 能源系统", "comments": "这项研究的创新之处在于其提出的变分数字孪生（VDT）框架，通过轻量级的贝叶斯增强和高效的更新算法，显著提升了数字孪生在实时性、不确定性量化和数据效率方面的能力。解决了现有数字孪生在实际应用中的核心痛点。其在多个能源领域的成功应用，特别是对不确定性的有效处理和在传感器退化情况下的鲁棒性，展示了其在工业和科学领域部署的巨大潜力。该工作为构建更可靠、更智能的能源系统数字孪生模型奠定了基础。"}}
{"id": "2507.01449", "title": "LogitSpec: Accelerating Retrieval-based Speculative Decoding via Next Next Token Speculation", "authors": ["Tianyu Liu", "Qitan Lv", "Hao Li", "Xing Gao", "Xiao Sun"], "summary": "Speculative decoding (SD), where a small draft model is employed to propose\ndraft tokens in advance and then the target model validates them in parallel,\nhas emerged as a promising technique for LLM inference acceleration. Many\nendeavors to improve SD are to eliminate the need for a draft model and\ngenerate draft tokens in a retrieval-based manner in order to further alleviate\nthe drafting overhead and significantly reduce the difficulty in deployment and\napplications. However, retrieval-based SD relies on a matching paradigm to\nretrieval the most relevant reference as the draft tokens, where these methods\noften fail to find matched and accurate draft tokens. To address this\nchallenge, we propose LogitSpec to effectively expand the retrieval range and\nfind the most relevant reference as drafts. Our LogitSpec is motivated by the\nobservation that the logit of the last token can not only predict the next\ntoken, but also speculate the next next token. Specifically, LogitSpec\ngenerates draft tokens in two steps: (1) utilizing the last logit to speculate\nthe next next token; (2) retrieving relevant reference for both the next token\nand the next next token. LogitSpec is training-free and plug-and-play, which\ncan be easily integrated into existing LLM inference frameworks. Extensive\nexperiments on a wide range of text generation benchmarks demonstrate that\nLogitSpec can achieve up to 2.61 $\\times$ speedup and 3.28 mean accepted tokens\nper decoding step. Our code is available at\nhttps://github.com/smart-lty/LogitSpec.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01449v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01449v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "LogitSpec：通过“下下个”令牌推测加速基于检索的推测解码", "tldr": "LogitSpec通过利用最后一个Logit来推测“下下个”令牌，并检索相关参考，从而改进了基于检索的推测解码，实现了显著的LLM推理加速。", "motivation": "现有的基于检索的推测解码方法在寻找匹配且准确的草稿令牌方面常常失败，因为它们依赖于匹配范式来检索最相关的参考作为草稿令牌。", "method": "LogitSpec通过两个步骤生成草稿令牌：1) 利用最后一个Logit推测“下下个”令牌；2) 为“下个”令牌和“下下个”令牌检索相关参考。该方法是免训练和即插即用的。", "result": "LogitSpec在广泛的文本生成基准测试中实现了高达2.61倍的加速，并且平均每个解码步骤接受的令牌数达到3.28个。", "conclusion": "LogitSpec通过扩展检索范围和利用“下下个”令牌推测，有效解决了基于检索的推测解码中草稿令牌匹配失败的问题，显著提升了LLM推理速度。", "translation": "推测解码（SD）是一种有前景的大语言模型（LLM）推理加速技术，它利用小型草稿模型提前提出草稿令牌，然后由目标模型并行验证这些令牌。许多改进SD的努力旨在消除对草稿模型的需求，并以基于检索的方式生成草稿令牌，以进一步减轻草稿开销，并显著降低部署和应用的难度。然而，基于检索的SD依赖于匹配范式来检索最相关的参考作为草稿令牌，这些方法通常无法找到匹配且准确的草稿令牌。为了解决这一挑战，我们提出了LogitSpec，以有效扩展检索范围并找到最相关的参考作为草稿。LogitSpec的灵感来自于一个观察：最后一个令牌的Logit不仅可以预测“下个”令牌，还可以推测“下下个”令牌。具体来说，LogitSpec分两步生成草稿令牌：(1) 利用最后一个Logit推测“下下个”令牌；(2) 为“下个”令牌和“下下个”令牌检索相关参考。LogitSpec是免训练和即插即用的，可以轻松集成到现有的LLM推理框架中。在广泛的文本生成基准测试中进行的大量实验表明，LogitSpec可以实现高达2.61倍的加速和平均每个解码步骤3.28个接受令牌。我们的代码可在https://github.com/smart-lty/LogitSpec获取。", "summary": "LogitSpec提出了一种创新的方法来改进基于检索的推测解码，解决了现有方法难以找到准确草稿令牌的问题。该方法的核心在于利用最后一个Logit不仅预测“下个”令牌，还能推测“下下个”令牌，从而有效扩展了检索范围。LogitSpec通过两步机制生成草稿：首先推测“下下个”令牌，然后为“下个”和“下下个”令牌检索相关参考。作为一个免训练和即插即用的解决方案，LogitSpec在实验中展示了显著的LLM推理加速，最高达到2.61倍。", "keywords": "推测解码,检索增强,LLM加速,LogitSpec,下下个令牌推测", "comments": "LogitSpec的创新之处在于其“下下个”令牌推测的理念，这巧妙地扩展了检索范围，解决了传统基于检索SD中草稿令牌匹配率低的问题。其免训练和即插即用的特性使其具有很高的实用价值和易用性，有望在现有LLM推理框架中广泛应用。该研究对于提升LLM推理效率具有重要意义。"}}
{"id": "2507.01795", "title": "Neural Entropy-stable conservative flux form neural networks for learning hyperbolic conservation laws", "authors": ["Lizuo Liu", "Lu Zhang", "Anne Gelb"], "summary": "We propose a neural entropy-stable conservative flux form neural network\n(NESCFN) for learning hyperbolic conservation laws and their associated entropy\nfunctions directly from solution trajectories, without requiring any predefined\nnumerical discretization. While recent neural network architectures have\nsuccessfully integrated classical numerical principles into learned models,\nmost rely on prior knowledge of the governing equations or assume a fixed\ndiscretization. Our approach removes this dependency by embedding\nentropy-stable design principles into the learning process itself, enabling the\ndiscovery of physically consistent dynamics in a fully data-driven setting. By\njointly learning both the numerical flux function and a corresponding entropy,\nthe proposed method ensures conservation and entropy dissipation, critical for\nlong-term stability and fidelity in the system of hyperbolic conservation laws.\nNumerical results demonstrate that the method achieves stability and\nconservation over extended time horizons and accurately captures shock\npropagation speeds, even without oracle access to future-time solution profiles\nin the training data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01795v1", "categories": ["math.NA", "cs.LG", "cs.NA", "math-ph", "math.MP", "65M08, 68T07, 65M22, 65M32, 65D25"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01795v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "神经熵稳定守恒通量形式神经网络用于学习双曲守恒律", "tldr": "提出一种新的神经熵稳定守恒通量神经网络（NESCFN），直接从解轨迹中学习双曲守恒律及其熵函数，无需预定义离散化，确保长期稳定性和守恒性。", "motivation": "现有的神经网络模型在整合经典数值原理时，大多依赖于对控制方程的先验知识或假设固定的离散化，而该方法旨在消除这种依赖，实现完全数据驱动下的物理一致动力学发现。", "method": "提出神经熵稳定守恒通量形式神经网络（NESCFN），通过将熵稳定设计原则嵌入学习过程，共同学习数值通量函数和相应的熵，从而确保守恒性和熵耗散。", "result": "数值结果表明，该方法在长时间范围内实现了稳定性和守恒性，并准确捕捉了激波传播速度，即使训练数据中没有未来时间解剖面的先验信息。", "conclusion": "NESCFN能够有效学习双曲守恒律，并在没有预设离散化和未来信息的情况下保持长期稳定性和物理一致性。", "translation": "我们提出了一种神经熵稳定守恒通量形式神经网络（NESCFN），用于直接从解轨迹中学习双曲守恒律及其相关的熵函数，而无需任何预定义的数值离散化。虽然最近的神经网络架构已成功将经典数值原理集成到学习模型中，但大多数依赖于对控制方程的先验知识或假设固定的离散化。我们的方法通过将熵稳定设计原则嵌入到学习过程本身来消除这种依赖性，从而在完全数据驱动的设置中发现物理一致的动力学。通过共同学习数值通量函数和相应的熵，所提出的方法确保了守恒性和熵耗散，这对于双曲守恒律系统中的长期稳定性和保真度至关重要。数值结果表明，该方法在长时间范围内实现了稳定性和守恒性，并准确捕捉了激波传播速度，即使在训练数据中无法预知未来时间解剖面的情况下也是如此。", "summary": "本文提出了一种名为神经熵稳定守恒通量形式神经网络（NESCFN）的新方法，用于直接从数据中学习双曲守恒律和其熵函数，无需预设数值离散化。NESCFN通过在学习过程中嵌入熵稳定原理，并同时学习数值通量和熵，确保了模型的守恒性和长期稳定性，克服了现有方法对先验知识的依赖。数值实验验证了其在长时间尺度上的稳定性和对激波传播的准确捕捉能力。", "keywords": "双曲守恒律, 神经网络, 熵稳定, 守恒通量, 数据驱动", "comments": "该论文的创新之处在于提出了一种完全数据驱动的学习双曲守恒律的方法，通过将熵稳定原理内嵌到神经网络学习过程中，避免了对传统数值离散化和方程先验知识的依赖。这对于处理复杂的物理系统具有重要意义，尤其是在缺乏精确数学模型的情况下。该方法在保证物理一致性（守恒和熵耗散）的同时，展现了优异的长期稳定性和准确性，是深度学习在科学计算领域的一个重要进展。"}}
{"id": "2507.01931", "title": "Adaptability of ASR Models on Low-Resource Language: A Comparative Study of Whisper and Wav2Vec-BERT on Bangla", "authors": ["Md Sazzadul Islam Ridoy", "Sumi Akter", "Md. Aminur Rahman"], "summary": "In recent years, neural models trained on large multilingual text and speech\ndatasets have shown great potential for supporting low-resource languages. This\nstudy investigates the performances of two state-of-the-art Automatic Speech\nRecognition (ASR) models, OpenAI's Whisper (Small & Large-V2) and Facebook's\nWav2Vec-BERT on Bangla, a low-resource language. We have conducted experiments\nusing two publicly available datasets: Mozilla Common Voice-17 and OpenSLR to\nevaluate model performances. Through systematic fine-tuning and hyperparameter\noptimization, including learning rate, epochs, and model checkpoint selection,\nwe have compared the models based on Word Error Rate (WER), Character Error\nRate (CER), Training Time, and Computational Efficiency. The Wav2Vec-BERT model\noutperformed Whisper across all key evaluation metrics, demonstrated superior\nperformance while requiring fewer computational resources, and offered valuable\ninsights to develop robust speech recognition systems in low-resource\nlinguistic settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01931v1", "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01931v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "ASR模型在低资源语言上的适应性：Whisper和Wav2Vec-BERT在孟加拉语上的比较研究", "tldr": "本研究比较了Whisper和Wav2Vec-BERT两种ASR模型在低资源孟加拉语上的性能。结果显示，Wav2Vec-BERT在所有关键评估指标上均优于Whisper，且计算资源需求更少。", "motivation": "近年来，在大型多语言文本和语音数据集上训练的神经网络模型在支持低资源语言方面展现出巨大潜力。本研究旨在调查两种最先进的自动语音识别（ASR）模型（OpenAI的Whisper和Facebook的Wav2Vec-BERT）在低资源语言孟加拉语上的性能。", "method": "本研究对OpenAI的Whisper（Small & Large-V2）和Facebook的Wav2Vec-BERT两种最先进的ASR模型在孟加拉语上进行了性能评估。实验使用了Mozilla Common Voice-17和OpenSLR两个公开数据集。通过系统的微调和超参数优化（包括学习率、训练轮数和模型检查点选择），研究团队基于词错误率（WER）、字符错误率（CER）、训练时间和计算效率对模型进行了比较。", "result": "Wav2Vec-BERT模型在所有关键评估指标上均优于Whisper，表现出卓越的性能，同时需要更少的计算资源。", "conclusion": "Wav2Vec-BERT模型在低资源语言孟加拉语上的优异表现为在低资源语言环境下开发鲁棒的语音识别系统提供了宝贵的见解。", "translation": "近年来，在大型多语言文本和语音数据集上训练的神经网络模型在支持低资源语言方面展现出巨大潜力。本研究调查了两种最先进的自动语音识别（ASR）模型，OpenAI的Whisper（Small & Large-V2）和Facebook的Wav2Vec-BERT在孟加拉语（一种低资源语言）上的性能。我们使用两个公开数据集：Mozilla Common Voice-17和OpenSLR进行了实验，以评估模型性能。通过系统的微调和超参数优化，包括学习率、训练轮数和模型检查点选择，我们基于词错误率（WER）、字符错误率（CER）、训练时间和计算效率对模型进行了比较。Wav2Vec-BERT模型在所有关键评估指标上均优于Whisper，表现出卓越的性能，同时需要更少的计算资源，并为在低资源语言环境下开发鲁棒的语音识别系统提供了宝贵的见解。", "summary": "本研究比较了OpenAI的Whisper和Facebook的Wav2Vec-BERT两种先进ASR模型在低资源语言孟加拉语上的性能。通过在Mozilla Common Voice-17和OpenSLR数据集上进行微调和超参数优化，并基于WER、CER、训练时间和计算效率进行评估，结果显示Wav2Vec-BERT在各项指标上均优于Whisper，且计算效率更高，为低资源语言的语音识别系统开发提供了重要参考。", "keywords": "ASR, 低资源语言, 孟加拉语, Whisper, Wav2Vec-BERT", "comments": "该研究通过严谨的实验比较了两种主流ASR模型在低资源语言上的适应性，发现Wav2Vec-BERT在孟加拉语上表现出显著优势，且计算成本较低，这对于推动低资源语言的语音技术发展具有重要意义。研究方法系统，评估指标全面。"}}
{"id": "2507.01705", "title": "Efficient Collision Detection for Long and Slender Robotic Links in Euclidean Distance Fields: Application to a Forestry Crane", "authors": ["Marc-Philip Ecker", "Bernhard Bischof", "Minh Nhat Vu", "Christoph Fröhlich", "Tobias Glück", "Wolfgang Kemmetmüller"], "summary": "Collision-free motion planning in complex outdoor environments relies heavily\non perceiving the surroundings through exteroceptive sensors. A widely used\napproach represents the environment as a voxelized Euclidean distance field,\nwhere robots are typically approximated by spheres. However, for large-scale\nmanipulators such as forestry cranes, which feature long and slender links,\nthis conventional spherical approximation becomes inefficient and inaccurate.\nThis work presents a novel collision detection algorithm specifically designed\nto exploit the elongated structure of such manipulators, significantly\nenhancing the computational efficiency of motion planning algorithms. Unlike\ntraditional sphere decomposition methods, our approach not only improves\ncomputational efficiency but also naturally eliminates the need to fine-tune\nthe approximation accuracy as an additional parameter. We validate the\nalgorithm's effectiveness using real-world LiDAR data from a forestry crane\napplication, as well as simulated environment data.", "comment": "Accepted at IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.01705v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01705v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "欧几里德距离场中长而细长机械臂连杆的高效碰撞检测：以林业起重机为例", "tldr": "提出了一种针对长而细长机械臂连杆在欧几里德距离场中进行高效碰撞检测的新算法，解决了传统球形近似的低效和不准确问题，并应用于林业起重机。", "motivation": "传统的球形近似方法在处理大型操纵器（如林业起重机）的长而细长连杆时效率低下且不准确，导致碰撞检测效率低。", "method": "本文提出了一种新颖的碰撞检测算法，专门设计用于利用机械臂的细长结构，显著提高了运动规划算法的计算效率。与传统的球体分解方法不同，该方法无需额外参数来微调近似精度。", "result": "该算法在林业起重机的真实LiDAR数据和模拟环境数据上都验证了其有效性，显著提高了计算效率，并消除了近似精度微调的需求。", "conclusion": "本工作提出的算法为长而细长的机械臂在欧几里德距离场中提供了高效准确的碰撞检测，克服了传统方法的局限性，有望提升复杂环境下的运动规划性能。", "translation": "在复杂的室外环境中进行无碰撞运动规划，严重依赖于通过外部传感器感知周围环境。一种广泛使用的方法是将环境表示为体素化的欧几里德距离场，其中机器人通常用球体近似。然而，对于大型操纵器，例如具有长而细长连杆的林业起重机，这种传统的球形近似变得效率低下且不准确。这项工作提出了一种新颖的碰撞检测算法，专门设计用于利用此类操纵器的细长结构，显著提高了运动规划算法的计算效率。与传统的球体分解方法不同，我们的方法不仅提高了计算效率，而且自然地消除了将近似精度作为额外参数进行微调的需要。我们使用来自林业起重机应用的真实LiDAR数据以及模拟环境数据验证了该算法的有效性。", "summary": "针对大型操纵器（如林业起重机）长而细长连杆在欧几里德距离场中进行碰撞检测时，传统球形近似效率低下且不准确的问题，本文提出了一种新颖的碰撞检测算法。该算法专门利用机械臂的细长结构，显著提高了计算效率，并消除了对近似精度进行额外参数微调的需求。通过真实LiDAR数据和模拟环境数据的验证，证明了其有效性。", "keywords": "碰撞检测, 欧几里德距离场, 机械臂, 林业起重机, 运动规划", "comments": "该论文的创新点在于提出了一种专门针对长而细长机械臂连杆的碰撞检测算法，有效解决了传统球形近似方法的效率和精度问题。其重要性体现在提升了林业起重机等大型机械臂在复杂户外环境中的运动规划效率和可靠性，并且通过消除近似精度微调参数，简化了算法应用。这对于实际工业应用具有重要价值。"}}
{"id": "2507.01154", "title": "FlashDP: Private Training Large Language Models with Efficient DP-SGD", "authors": ["Liangyu Wang", "Junxiao Wang", "Jie Ren", "Zihang Xiang", "David E. Keyes", "Di Wang"], "summary": "As large language models (LLMs) increasingly underpin technological\nadvancements, the privacy of their training data emerges as a critical concern.\nDifferential Privacy (DP) serves as a rigorous mechanism to protect this data,\nyet its integration via Differentially Private Stochastic Gradient Descent\n(DP-SGD) introduces substantial challenges, primarily due to the complexities\nof per-sample gradient clipping. Current explicit methods, such as Opacus,\nnecessitate extensive storage for per-sample gradients, significantly inflating\nmemory requirements. Conversely, implicit methods like GhostClip reduce storage\nneeds by recalculating gradients multiple times, which leads to inefficiencies\ndue to redundant computations. This paper introduces FlashDP, an innovative\ncache-friendly per-layer DP-SGD that consolidates necessary operations into a\nsingle task, calculating gradients only once in a fused manner. This approach\nnot only diminishes memory movement by up to \\textbf{50\\%} but also cuts down\nredundant computations by \\textbf{20\\%}, compared to previous methods.\nConsequently, FlashDP does not increase memory demands and achieves a\n\\textbf{90\\%} throughput compared to the Non-DP method on a four-A100 system\nduring the pre-training of the Llama-13B model, while maintaining parity with\nstandard per-layer clipped DP-SGD in terms of accuracy. These advancements\nestablish FlashDP as a pivotal development for efficient and privacy-preserving\ntraining of LLMs. FlashDP's code has been open-sourced in\nhttps://github.com/kaustpradalab/flashdp.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01154v1", "categories": ["cs.LG", "cs.CR"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01154v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "FlashDP：使用高效DP-SGD私有训练大型语言模型", "tldr": "FlashDP提出了一种高效的缓存友好型逐层DP-SGD方法，通过融合操作减少内存移动和冗余计算，从而在不增加内存需求的情况下，实现LLM私有训练的高吞吐量和准确性。", "motivation": "随着大型语言模型（LLMs）的广泛应用，训练数据的隐私成为一个关键问题。差分隐私（DP）是保护数据的严格机制，但通过差分隐私随机梯度下降（DP-SGD）集成时面临挑战，主要是因为逐样本梯度裁剪的复杂性，导致内存需求高或计算效率低下。", "method": "本文提出了FlashDP，一种创新的缓存友好型逐层DP-SGD方法。它将必要的梯度计算操作整合为单一任务，以融合的方式只计算一次梯度。这种方法旨在减少内存移动和冗余计算。", "result": "与现有方法相比，FlashDP将内存移动减少了高达50%，冗余计算减少了20%。它不增加内存需求，并且在四A100系统上预训练Llama-13B模型时，相对于非DP方法实现了90%的吞吐量，同时在准确性上与标准的逐层裁剪DP-SGD保持一致。", "conclusion": "FlashDP的这些进步使其成为高效且保护隐私的LLM训练的关键发展。", "translation": "随着大型语言模型（LLM）日益成为技术进步的基础，其训练数据的隐私问题日益成为一个关键的关注点。差分隐私（DP）作为一种严格的机制来保护这些数据，但通过差分隐私随机梯度下降（DP-SGD）集成时带来了巨大的挑战，这主要归因于逐样本梯度裁剪的复杂性。当前显式方法，如Opacus，需要大量的存储空间用于逐样本梯度，显著增加了内存需求。相反，隐式方法如GhostClip通过多次重新计算梯度来减少存储需求，但这导致了由于冗余计算而产生的低效率。本文介绍了FlashDP，一种创新的缓存友好型逐层DP-SGD方法，它将必要的操作整合到一个单一任务中，以融合的方式只计算一次梯度。与以前的方法相比，这种方法不仅将内存移动减少了高达50%，而且将冗余计算减少了20%。因此，FlashDP不增加内存需求，并且在四A100系统上预训练Llama-13B模型时，相对于非DP方法实现了90%的吞吐量，同时在准确性上与标准的逐层裁剪DP-SGD保持一致。这些进步确立了FlashDP作为LLM高效且保护隐私训练的关键发展。FlashDP的代码已在https://github.com/kaustpradalab/flashdp 开源。", "summary": "FlashDP提出了一种高效的差分隐私随机梯度下降（DP-SGD）方法，用于大型语言模型（LLMs）的私有训练。针对现有DP-SGD方法中逐样本梯度裁剪导致的内存和计算效率问题，FlashDP创新性地采用缓存友好型逐层DP-SGD，通过融合操作实现梯度的一次性计算。实验结果表明，FlashDP显著减少了内存移动（高达50%）和冗余计算（20%），在不增加内存需求的前提下，实现了接近非DP方法的吞吐量（90%）并保持了准确性。这使得FlashDP成为LLMs高效私有训练的关键进展。", "keywords": "差分隐私, 大型语言模型, DP-SGD, 私有训练, FlashDP", "comments": "FlashDP通过其缓存友好型和融合操作的创新方法，解决了DP-SGD在大型语言模型训练中面临的内存和计算效率瓶颈。它在保持准确性的同时，显著提高了私有训练的效率，这对于推动LLM的隐私保护应用至关重要。该工作的创新性在于将复杂的梯度操作精简为单一任务，有效优化了资源利用。"}}
{"id": "2507.01368", "title": "Activation Reward Models for Few-Shot Model Alignment", "authors": ["Tianning Chai", "Chancharik Mitra", "Brandon Huang", "Gautam Rajendrakumar Gare", "Zhiqiu Lin", "Assaf Arbelle", "Leonid Karlinsky", "Rogerio Feris", "Trevor Darrell", "Deva Ramanan", "Roei Herzig"], "summary": "Aligning Large Language Models (LLMs) and Large Multimodal Models (LMMs) to\nhuman preferences is a central challenge in improving the quality of the\nmodels' generative outputs for real-world applications. A common approach is to\nuse reward modeling to encode preferences, enabling alignment via post-training\nusing reinforcement learning. However, traditional reward modeling is not\neasily adaptable to new preferences because it requires a separate reward\nmodel, commonly trained on large preference datasets. To address this, we\nintroduce Activation Reward Models (Activation RMs) -- a novel few-shot reward\nmodeling method that leverages activation steering to construct well-aligned\nreward signals using minimal supervision and no additional model finetuning.\nActivation RMs outperform existing few-shot reward modeling approaches such as\nLLM-as-a-judge with in-context learning, voting-based scoring, and token\nprobability scoring on standard reward modeling benchmarks. Furthermore, we\ndemonstrate the effectiveness of Activation RMs in mitigating reward hacking\nbehaviors, highlighting their utility for safety-critical applications. Toward\nthis end, we propose PreferenceHack, a novel few-shot setting benchmark, the\nfirst to test reward models on reward hacking in a paired preference format.\nFinally, we show that Activation RM achieves state-of-the-art performance on\nthis benchmark, surpassing even GPT-4o.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01368v1", "categories": ["cs.CV", "cs.LG"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01368v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "用于少样本模型对齐的激活奖励模型", "tldr": "激活奖励模型（Activation RMs）是一种新颖的少样本奖励建模方法，它利用激活引导来高效对齐大型语言模型和多模态模型，在现有方法上表现出色，并能有效缓解奖励作弊行为。", "motivation": "将大型语言模型（LLMs）和大型多模态模型（LMMs）与人类偏好对齐是提高模型生成输出质量的关键挑战。传统的奖励建模方法难以适应新的偏好，因为它需要一个单独的奖励模型，通常需要大量的偏好数据集进行训练。", "method": "我们引入了激活奖励模型（Activation RMs），这是一种新颖的少样本奖励建模方法，它利用激活引导来构建对齐良好的奖励信号，仅需最少的监督，无需额外的模型微调。我们还提出了PreferenceHack，这是一个新颖的少样本设置基准，首次以配对偏好格式测试奖励模型在奖励作弊方面的表现。", "result": "激活奖励模型在标准奖励建模基准上优于现有少样本奖励建模方法，如LLM-as-a-judge、基于投票的评分和令牌概率评分。此外，我们证明了激活奖励模型在缓解奖励作弊行为方面的有效性。最后，我们表明激活奖励模型在该基准上取得了最先进的性能，甚至超越了GPT-4o。", "conclusion": "激活奖励模型是一种有效且高效的少样本模型对齐方法，能够用最小的监督构建高质量的奖励信号，并显著缓解奖励作弊，在安全关键型应用中具有重要价值。", "translation": "将大型语言模型（LLMs）和大型多模态模型（LMMs）与人类偏好对齐是提高模型生成输出在实际应用中质量的核心挑战。一种常见的方法是使用奖励建模来编码偏好，通过强化学习进行后训练实现对齐。然而，传统的奖励建模方法不易适应新的偏好，因为它需要一个单独的奖励模型，通常需要大量偏好数据集进行训练。为了解决这个问题，我们引入了激活奖励模型（Activation RMs）——一种新颖的少样本奖励建模方法，它利用激活引导来构建对齐良好的奖励信号，仅需最少的监督，无需额外的模型微调。激活奖励模型在标准奖励建模基准上优于现有少样本奖励建模方法，如LLM-as-a-judge（基于上下文学习）、基于投票的评分和令牌概率评分。此外，我们证明了激活奖励模型在缓解奖励作弊行为方面的有效性，突出了它们在安全关键型应用中的实用性。为此，我们提出了PreferenceHack，一个新颖的少样本设置基准，这是第一个以配对偏好格式测试奖励模型在奖励作弊方面的表现。最后，我们展示了激活奖励模型在该基准上取得了最先进的性能，甚至超越了GPT-4o。", "summary": "本研究提出了一种新颖的少样本奖励建模方法——激活奖励模型（Activation RMs），旨在解决大型语言模型和多模态模型对齐中传统奖励模型对数据量要求高、适应性差的问题。激活奖励模型通过利用激活引导，仅需少量监督即可构建高质量的奖励信号，且无需额外模型微调。实验结果表明，激活奖励模型在标准奖励建模基准上优于现有少样本方法，并能有效缓解奖励作弊行为。在提出的PreferenceHack基准上，激活奖励模型取得了最先进的性能，甚至超越了GPT-4o。", "keywords": "激活奖励模型, 少样本学习, 模型对齐, 奖励作弊, 大型语言模型", "comments": "本文的创新之处在于提出了基于激活引导的少样本奖励模型，显著降低了模型对齐所需的监督数据量，并提高了对新偏好的适应性。其在缓解奖励作弊方面的有效性对于开发更安全、更可靠的AI系统至关重要。同时，引入PreferenceHack基准为奖励模型的鲁棒性评估提供了新的视角和工具。"}}
{"id": "2507.01902", "title": "Analyzing Common Electronic Structure Theory Algorithms for Distributed Quantum Computing", "authors": ["Grier M. Jones", "Hans-Arno Jacobsen"], "summary": "To move towards the utility era of quantum computing, many corporations have\nposed distributed quantum computing (DQC) as a framework for scaling the\ncurrent generation of devices for practical applications. One of these\napplications is quantum chemistry, also known as electronic structure theory,\nwhich has been poised as a \"killer application\" of quantum computing, To this\nend, we analyze five electronic structure methods, found in common packages\nsuch as Tequila and ffsim, which can be easily interfaced with the Qiskit\nCircuit Cutting addon. Herein, we provide insights into cutting these\nalgorithms using local operations (LO) to determine their aptitude for\ndistribution. The key findings of our work are that many of these algorithms\ncannot be efficiently parallelized using LO, and new methods must be developed\nto apply electronic structure theory within a DQC framework.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01902v1", "categories": ["quant-ph", "cs.DC", "physics.chem-ph"], "cate": "quant-ph", "url": "http://arxiv.org/abs/2507.01902v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "分析分布式量子计算中常见的电子结构理论算法", "tldr": "研究发现，现有的电子结构理论算法难以通过局部操作在分布式量子计算中高效并行化，需要开发新方法。", "motivation": "为了将量子计算推向实用时代，许多公司提出了分布式量子计算（DQC）作为扩展当前设备以实现实际应用的框架，其中量子化学（电子结构理论）被认为是量子计算的“杀手级应用”。", "method": "分析了Tequila和ffsim等常见软件包中的五种电子结构方法，并使用Qiskit Circuit Cutting插件的局部操作（LO）来评估它们在分布式计算中的适用性。", "result": "许多这些算法无法使用局部操作（LO）进行有效并行化。", "conclusion": "需要开发新的方法，以便在分布式量子计算（DQC）框架内应用电子结构理论。", "translation": "为了将量子计算推向实用时代，许多公司提出了分布式量子计算（DQC）作为扩展当前设备以实现实际应用的框架。其中一项应用是量子化学，也称为电子结构理论，它被认为是量子计算的“杀手级应用”。为此，我们分析了在Tequila和ffsim等常见软件包中发现的五种电子结构方法，这些方法可以轻松与Qiskit Circuit Cutting插件接口。在此，我们提供了使用局部操作（LO）切割这些算法的见解，以确定它们在分布式中的适用性。我们工作的主要发现是，许多这些算法无法使用LO高效并行化，并且必须开发新方法才能在DQC框架内应用电子结构理论。", "summary": "本文分析了五种常见的电子结构理论算法在分布式量子计算（DQC）框架下的适用性。研究利用Qiskit Circuit Cutting插件的局部操作对算法进行评估，发现现有方法难以通过局部操作实现高效并行化，表明需要开发新的算法和策略以在DQC中有效应用电子结构理论。", "keywords": "分布式量子计算, 电子结构理论, 量子化学, 电路切割, 并行化", "comments": "该研究揭示了当前电子结构理论算法在分布式量子计算中实现高效并行化的局限性，指出了未来研究的方向，即开发新的算法和方法来克服这些挑战，对于推动量子化学在分布式量子计算中的实际应用具有重要意义。"}}
{"id": "2507.01428", "title": "DiffMark: Diffusion-based Robust Watermark Against Deepfakes", "authors": ["Chen Sun", "Haiyang Sun", "Zhiqing Guo", "Yunfeng Diao", "Liejun Wang", "Dan Ma", "Gaobo Yang", "Keqin Li"], "summary": "Deepfakes pose significant security and privacy threats through malicious\nfacial manipulations. While robust watermarking can aid in authenticity\nverification and source tracking, existing methods often lack the sufficient\nrobustness against Deepfake manipulations. Diffusion models have demonstrated\nremarkable performance in image generation, enabling the seamless fusion of\nwatermark with image during generation. In this study, we propose a novel\nrobust watermarking framework based on diffusion model, called DiffMark. By\nmodifying the training and sampling scheme, we take the facial image and\nwatermark as conditions to guide the diffusion model to progressively denoise\nand generate corresponding watermarked image. In the construction of facial\ncondition, we weight the facial image by a timestep-dependent factor that\ngradually reduces the guidance intensity with the decrease of noise, thus\nbetter adapting to the sampling process of diffusion model. To achieve the\nfusion of watermark condition, we introduce a cross information fusion (CIF)\nmodule that leverages a learnable embedding table to adaptively extract\nwatermark features and integrates them with image features via cross-attention.\nTo enhance the robustness of the watermark against Deepfake manipulations, we\nintegrate a frozen autoencoder during training phase to simulate Deepfake\nmanipulations. Additionally, we introduce Deepfake-resistant guidance that\nemploys specific Deepfake model to adversarially guide the diffusion sampling\nprocess to generate more robust watermarked images. Experimental results\ndemonstrate the effectiveness of the proposed DiffMark on typical Deepfakes.\nOur code will be available at https://github.com/vpsg-research/DiffMark.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01428v1", "categories": ["cs.CV", "eess.IV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01428v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "DiffMark：基于扩散模型的抗深度伪造鲁棒水印", "tldr": "DiffMark是一种基于扩散模型的新型鲁棒水印框架，旨在生成能够抵抗深度伪造操纵的水印图像，以应对深度伪造带来的安全和隐私威胁。", "motivation": "深度伪造通过恶意面部操纵带来严重的安全和隐私威胁。现有水印方法缺乏足够的鲁棒性来抵抗深度伪造操纵，因此需要一种更鲁棒的水印方案。", "method": "DiffMark是一个基于扩散模型的新型鲁棒水印框架。它通过修改训练和采样方案，将面部图像和水印作为条件来引导扩散模型生成水印图像。具体而言，它在面部条件构建中采用时间步长依赖的加权因子，并引入交叉信息融合（CIF）模块以通过可学习嵌入表和交叉注意力融合水印特征。为增强鲁棒性，DiffMark在训练阶段集成冻结自编码器模拟深度伪造操纵，并引入深度伪造抵抗引导来对抗性地引导扩散采样过程。", "result": "实验结果表明，所提出的DiffMark在典型深度伪造攻击下是有效的。", "conclusion": "DiffMark框架能够有效地生成抵抗深度伪造操纵的鲁棒水印，其有效性已通过实验验证。", "translation": "深度伪造通过恶意的面部操纵带来了重大的安全和隐私威胁。虽然鲁棒水印有助于真实性验证和来源追踪，但现有方法通常缺乏对抗深度伪造操纵的足够鲁棒性。扩散模型在图像生成方面表现出卓越的性能，能够将水印与图像在生成过程中无缝融合。在本研究中，我们提出了一种基于扩散模型的新型鲁棒水印框架，名为DiffMark。通过修改训练和采样方案，我们以面部图像和水印作为条件，引导扩散模型逐步去噪并生成相应的水印图像。在面部条件构建中，我们通过一个依赖于时间步长的因子对面部图像进行加权，该因子随着噪声的减少逐渐降低引导强度，从而更好地适应扩散模型的采样过程。为了实现水印条件的融合，我们引入了一个交叉信息融合（CIF）模块，该模块利用一个可学习的嵌入表自适应地提取水印特征，并通过交叉注意力将其与图像特征集成。为了增强水印对抗深度伪造操纵的鲁棒性，我们在训练阶段集成了一个冻结的自编码器来模拟深度伪造操纵。此外，我们引入了抗深度伪造引导，该引导采用特定的深度伪造模型对抗性地引导扩散采样过程，以生成更鲁棒的水印图像。实验结果表明，所提出的DiffMark在典型深度伪造上是有效的。我们的代码将在https://github.com/vpsg-research/DiffMark 提供。", "summary": "本文提出了DiffMark，一个基于扩散模型的鲁棒水印框架，旨在对抗深度伪造的面部操纵。DiffMark通过修改扩散模型的训练和采样方案，将面部图像和水印作为条件，生成融合水印的图像。它引入了时间步长依赖的引导因子和交叉信息融合（CIF）模块来处理条件。为增强鲁棒性，DiffMark在训练中模拟深度伪造攻击，并采用深度伪造抵抗引导机制。实验证明，DiffMark在典型深度伪造攻击下表现出有效性。", "keywords": "深度伪造, 鲁棒水印, 扩散模型, 水印融合, 认证", "comments": "这项工作创新性地将扩散模型应用于鲁棒水印领域，以应对深度伪造的挑战。其通过修改扩散过程中的条件引导和引入模拟攻击机制来增强水印鲁棒性的方法是值得关注的。该方法有望为深度伪造的检测和溯源提供新的思路。"}}
{"id": "2507.01479", "title": "Evaluating the Effectiveness of Direct Preference Optimization for Personalizing German Automatic Text Simplifications for Persons with Intellectual Disabilities", "authors": ["Yingqiang Gao", "Kaede Johnson", "David Froehlich", "Luisa Carrer", "Sarah Ebling"], "summary": "Automatic text simplification (ATS) aims to enhance language accessibility\nfor various target groups, particularly persons with intellectual disabilities.\nRecent advancements in generative AI, especially large language models (LLMs),\nhave substantially improved the quality of machine-generated text\nsimplifications, thereby mitigating information barriers for the target group.\nHowever, existing LLM-based ATS systems do not incorporate preference feedback\non text simplifications during training, resulting in a lack of personalization\ntailored to the specific needs of target group representatives.\n  In this work, we extend the standard supervised fine-tuning (SFT) approach\nfor adapting LLM-based ATS models by leveraging a computationally efficient LLM\nalignment technique -- direct preference optimization (DPO). Specifically, we\npost-train LLM-based ATS models using human feedback collected from persons\nwith intellectual disabilities, reflecting their preferences on paired text\nsimplifications generated by mainstream LLMs. Furthermore, we propose a\npipeline for developing personalized LLM-based ATS systems, encompassing data\ncollection, model selection, SFT and DPO post-training, and evaluation. Our\nfindings underscore the necessity of active participation of target group\npersons in designing personalized AI accessibility solutions aligned with human\nexpectations. This work represents a step towards personalizing inclusive AI\nsystems at the target-group level, incorporating insights not only from text\nsimplification experts but also from target group persons themselves.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01479v1", "categories": ["cs.CL", "cs.AI"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01479v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "评估直接偏好优化在为智力障碍人士个性化德语自动文本简化中的有效性", "tldr": "本研究通过直接偏好优化（DPO）利用智力障碍人士的偏好反馈，对大型语言模型（LLM）基自动文本简化（ATS）模型进行后训练，以实现个性化简化，提高语言可访问性，并强调目标群体参与的重要性。", "motivation": "自动文本简化（ATS）旨在提高包括智力障碍人士在内的各类目标群体的语言可访问性。然而，现有基于大型语言模型（LLM）的ATS系统在训练时未整合偏好反馈，导致缺乏针对目标群体特定需求的个性化定制。", "method": "研究通过利用直接偏好优化（DPO）技术，扩展了用于调整基于LLM的ATS模型的标准监督微调（SFT）方法。具体而言，使用从智力障碍人士收集的人类反馈对模型进行后训练，以反映他们对主流LLM生成文本简化的偏好。此外，提出了一个开发个性化LLM-based ATS系统的完整流程，包括数据收集、模型选择、SFT和DPO后训练以及评估。", "result": "研究结果强调了目标群体人员在设计符合人类期望的个性化AI可访问性解决方案中积极参与的必要性。", "conclusion": "这项工作代表了在目标群体层面实现包容性AI系统个性化的一步，通过整合文本简化专家和目标群体人员自身的见解。", "translation": "自动文本简化（ATS）旨在提高语言可访问性，特别是针对智力障碍人士等不同目标群体。生成式AI，尤其是大型语言模型（LLMs）的最新进展，已大幅提升了机器生成文本简化的质量，从而减轻了目标群体的信息障碍。然而，现有的基于LLM的ATS系统在训练期间未融入文本简化的偏好反馈，导致缺乏针对目标群体代表特定需求的个性化定制。\n在这项工作中，我们通过利用一种计算效率高的大型语言模型对齐技术——直接偏好优化（DPO），扩展了用于调整基于LLM的ATS模型的标准监督微调（SFT）方法。具体来说，我们使用从智力障碍人士那里收集到的人类反馈对基于LLM的ATS模型进行后训练，这些反馈反映了他们对主流LLM生成的配对文本简化的偏好。此外，我们提出了一种开发个性化基于LLM的ATS系统的流程，包括数据收集、模型选择、SFT和DPO后训练以及评估。我们的研究结果强调了目标群体人员积极参与设计符合人类期望的个性化AI可访问性解决方案的必要性。这项工作代表了在目标群体层面实现包容性AI系统个性化的一步，不仅融入了文本简化专家的见解，也融入了目标群体人员本身的见解。", "summary": "本研究旨在解决现有大型语言模型（LLM）驱动的自动文本简化（ATS）系统缺乏个性化的问题，尤其针对智力障碍人士。作者提出通过直接偏好优化（DPO）技术，利用智力障碍人士的偏好反馈对LLM-based ATS模型进行后训练。研究还提出了一套完整的个性化ATS系统开发流程，并强调了目标群体在设计AI可访问性解决方案中的关键作用，从而推动了包容性AI系统的个性化发展。", "keywords": "自动文本简化, 直接偏好优化, 个性化, 智力障碍, 大型语言模型", "comments": "本文的创新点在于将直接偏好优化（DPO）技术应用于自动文本简化（ATS）领域，并首次明确地从智力障碍人士这一特定目标群体收集偏好反馈进行模型训练，以实现个性化。其重要性在于解决了现有ATS系统在个性化方面的不足，强调了用户中心设计在AI可访问性解决方案中的关键作用，对构建更具包容性的AI系统具有指导意义。摘要中未提及具体的量化实验结果，这可能是一个限制，但其提出的方法论和对目标群体参与的强调具有重要价值。"}}
{"id": "2507.01885", "title": "Faber polynomials in a deltoid region and power iteration momentum methods", "authors": ["Peter Cowal", "Nicholas F. Marshall", "Sara Pollock"], "summary": "We consider a region in the complex plane enclosed by a deltoid curve\ninscribed in the unit circle, and define a family of polynomials $P_n$ that\nsatisfy the same recurrence relation as the Faber polynomials for this region.\nWe use this family of polynomials to give a constructive proof that $z^n$ is\napproximately a polynomial of degree $\\sim\\sqrt{n}$ within the deltoid region.\nMoreover, we show that $|P_n| \\le 1$ in this deltoid region, and that, if $|z|\n= 1+\\varepsilon$, then the magnitude $|P_n(z)|$ is at least\n$\\frac{1}{3}(1+\\sqrt{\\varepsilon})^n$, for all $\\varepsilon > 0$. We illustrate\nour polynomial approximation theory with an application to iterative linear\nalgebra. In particular, we construct a higher-order momentum-based method that\naccelerates the power iteration for certain matrices with complex eigenvalues.\nWe show how the method can be run dynamically when the two dominant eigenvalues\nare real and positive.", "comment": "21 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.01885v1", "categories": ["math.NA", "cs.NA", "math.CA", "math.PR"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01885v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "三角区域中的Faber多项式与幂迭代动量方法", "tldr": "该研究定义了一族与三角区域Faber多项式相似的多项式，证明了z^n在该区域内的近似多项式性质，并将其应用于加速具有复特征值的矩阵的幂迭代。", "motivation": "本文的动机是利用所提出的多项式逼近理论来加速线性代数中的迭代过程，特别是针对某些具有复特征值的矩阵的幂迭代。", "method": "研究定义了一族满足与三角区域Faber多项式相同递推关系的多项式P_n。利用这族多项式，给出了一个构造性证明，表明z^n在三角区域内近似为~sqrt(n)度的多项式。此外，构建了一种高阶基于动量的方法来加速幂迭代。", "result": "证明了z^n在三角区域内近似为~sqrt(n)度的多项式。在三角区域内，|P_n| <= 1。如果|z| = 1+ε，则对于所有ε > 0，|P_n(z)| 至少为 (1/3)(1+sqrt(ε))^n。构建了一种加速某些具有复特征值的矩阵的幂迭代的高阶动量方法，并展示了当两个主导特征值为实数且为正时，该方法如何动态运行。", "conclusion": "本文提出了一个多项式逼近理论，并将其成功应用于迭代线性代数，特别是通过构建高阶动量方法来加速幂迭代，即使对于具有复特征值的矩阵也有效。", "translation": "我们考虑复平面中由内切于单位圆的三角曲线所包围的区域，并定义了一族多项式 P_n，它们满足与该区域的 Faber 多项式相同的递推关系。我们利用这族多项式给出了一个构造性证明，表明 z^n 在三角区域内近似为一个 ~√n 次多项式。此外，我们证明了在该三角区域内 |P_n| ≤ 1，并且如果 |z| = 1+ε，那么对于所有 ε > 0，其幅值 |P_n(z)| 至少为 (1/3)(1+√ε)^n。我们通过在迭代线性代数中的应用来说明我们的多项式逼近理论。特别是，我们构建了一种高阶基于动量的方法，可以加速某些具有复特征值的矩阵的幂迭代。我们展示了当两个主导特征值为实数且为正时，该方法如何动态运行。", "summary": "本文研究了三角区域中的一族与Faber多项式相关的多项式P_n。研究证明了z^n在该区域内可被一个约√n次的多项式近似，并给出了P_n的模值界限。基于这些多项式逼近理论，论文提出了一种高阶动量方法，用于加速具有复特征值的矩阵的幂迭代，并讨论了其在实正主导特征值情况下的动态运行。", "keywords": "Faber多项式, 三角区域, 幂迭代, 动量方法, 复特征值", "comments": "本文的创新之处在于将Faber多项式理论扩展到特定的三角区域，并成功将其应用于加速线性代数中的幂迭代过程。特别是，它为处理具有复特征值的矩阵提供了一种新的加速方法，这在实际应用中具有重要意义。理论与应用结合紧密，展示了数学工具在数值方法中的强大潜力。"}}
{"id": "2507.01810", "title": "Evaluating Structured Output Robustness of Small Language Models for Open Attribute-Value Extraction from Clinical Notes", "authors": ["Nikita Neveditsin", "Pawan Lingras", "Vijay Mago"], "summary": "We present a comparative analysis of the parseability of structured outputs\ngenerated by small language models for open attribute-value extraction from\nclinical notes. We evaluate three widely used serialization formats: JSON,\nYAML, and XML, and find that JSON consistently yields the highest parseability.\nStructural robustness improves with targeted prompting and larger models, but\ndeclines for longer documents and certain note types. Our error analysis\nidentifies recurring format-specific failure patterns. These findings offer\npractical guidance for selecting serialization formats and designing prompts\nwhen deploying language models in privacy-sensitive clinical settings.", "comment": "To appear in the ACL Anthology", "pdf_url": "http://arxiv.org/pdf/2507.01810v1", "categories": ["cs.CL", "cs.IR"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01810v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "评估小型语言模型在临床笔记开放属性值提取中结构化输出的鲁棒性", "tldr": "本研究发现，在从临床笔记中提取属性值时，JSON格式的小型语言模型结构化输出解析度最高，且通过特定提示和更大模型可提高鲁棒性，为临床部署提供了实用指导。", "motivation": "评估小型语言模型在临床笔记中进行开放属性值提取时，其结构化输出的可解析性，并为在隐私敏感的临床环境中部署语言模型提供实践指导。", "method": "比较分析了小型语言模型生成的结构化输出的可解析性，评估了JSON、YAML和XML三种序列化格式，并分析了提示、模型大小和文档长度对结构鲁棒性的影响，进行了错误分析。", "result": "JSON格式始终产生最高的可解析性。结构鲁棒性随目标提示和模型增大而提高，但随文档长度和特定笔记类型而下降。识别了重复的格式特定故障模式。", "conclusion": "研究结果为在隐私敏感的临床环境中部署语言模型时，选择序列化格式和设计提示提供了实用指导。", "translation": "我们对小型语言模型从临床笔记中进行开放属性值提取所生成的结构化输出的可解析性进行了比较分析。我们评估了三种广泛使用的序列化格式：JSON、YAML和XML，发现JSON始终产生最高的可解析性。结构鲁棒性随目标提示和更大模型而提高，但随文档长度和特定笔记类型而下降。我们的错误分析识别出重复的格式特定故障模式。这些发现为在隐私敏感的临床环境中部署语言模型时选择序列化格式和设计提示提供了实用指导。", "summary": "本文对小型语言模型从临床笔记中提取开放属性值时生成的结构化输出的可解析性进行了比较研究。研究评估了JSON、YAML和XML三种序列化格式，发现JSON具有最佳解析性。结果表明，通过特定提示和使用更大模型可以提高结构鲁棒性，但长文档和某些笔记类型会导致鲁棒性下降。研究还识别了特定的格式错误模式，并为在临床环境中部署语言模型提供了实践指导。", "keywords": "小型语言模型, 结构化输出, 属性值提取, 临床笔记, 序列化格式", "comments": "这项研究对于在实际临床环境中部署小型语言模型具有重要意义，尤其是在数据隐私敏感的背景下。它提供了关于选择序列化格式和优化提示的实用建议，有助于提高从非结构化临床笔记中提取结构化信息的效率和可靠性。创新点在于对不同序列化格式的鲁棒性进行了系统比较，并指出了影响因素和具体错误模式。"}}
{"id": "2507.01723", "title": "SE(3)-Equivariant Diffusion Policy in Spherical Fourier Space", "authors": ["Xupeng Zhu", "Fan Wang", "Robin Walters", "Jane Shi"], "summary": "Diffusion Policies are effective at learning closed-loop manipulation\npolicies from human demonstrations but generalize poorly to novel arrangements\nof objects in 3D space, hurting real-world performance. To address this issue,\nwe propose Spherical Diffusion Policy (SDP), an SE(3) equivariant diffusion\npolicy that adapts trajectories according to 3D transformations of the scene.\nSuch equivariance is achieved by embedding the states, actions, and the\ndenoising process in spherical Fourier space. Additionally, we employ novel\nspherical FiLM layers to condition the action denoising process equivariantly\non the scene embeddings. Lastly, we propose a spherical denoising temporal\nU-net that achieves spatiotemporal equivariance with computational efficiency.\nIn the end, SDP is end-to-end SE(3) equivariant, allowing robust generalization\nacross transformed 3D scenes. SDP demonstrates a large performance improvement\nover strong baselines in 20 simulation tasks and 5 physical robot tasks\nincluding single-arm and bi-manual embodiments. Code is available at\nhttps://github.com/amazon-science/Spherical_Diffusion_Policy.", "comment": "Accepted at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.01723v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01723v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "SE(3)等变扩散策略在球谐傅里叶空间的应用", "tldr": "提出一种名为SDP的SE(3)等变扩散策略，通过在球谐傅里叶空间操作，显著提升了扩散策略在3D场景变换下的泛化能力，并在模拟和真实机器人任务中表现出色。", "motivation": "现有的扩散策略在学习闭环操作策略方面有效，但对3D空间中物体的新颖排列泛化能力差，影响了实际性能。", "method": "提出球谐扩散策略（SDP），这是一种SE(3)等变扩散策略。通过将状态、动作和去噪过程嵌入球谐傅里叶空间来实现等变性。此外，还采用了新型球谐FiLM层来等变地调节动作去噪过程，并提出了一个球谐去噪时间U-net以实现时空等变性和计算效率。", "result": "SDP在20个模拟任务和5个物理机器人任务（包括单臂和双臂操作）中，相对于强基线模型表现出显著的性能提升。SDP实现了端到端的SE(3)等变性，从而在变换后的3D场景中实现鲁棒泛化。", "conclusion": "球谐扩散策略（SDP）通过在球谐傅里叶空间中操作并引入创新的网络结构，成功地解决了现有扩散策略在3D场景泛化能力差的问题，实现了端到端的SE(3)等变性，从而在机器人操作任务中展现出卓越的泛化性能和鲁棒性。", "translation": "扩散策略在从人类演示中学习闭环操作策略方面是有效的，但对3D空间中物体的新颖排列泛化能力差，损害了实际性能。为了解决这个问题，我们提出了球谐扩散策略（SDP），这是一种SE(3)等变扩散策略，可以根据场景的3D变换来调整轨迹。这种等变性是通过将状态、动作和去噪过程嵌入球谐傅里叶空间来实现的。此外，我们采用了新型球谐FiLM层来等变地条件化场景嵌入上的动作去噪过程。最后，我们提出了一个球谐去噪时间U-net，以计算效率实现时空等变性。最终，SDP是端到端的SE(3)等变，允许在变换后的3D场景中进行鲁棒泛化。SDP在20个模拟任务和5个物理机器人任务（包括单臂和双臂操作）中，相对于强基线模型表现出显著的性能提升。代码可在https://github.com/amazon-science/Spherical_Diffusion_Policy 获取。", "summary": "本文针对现有扩散策略在3D场景中泛化能力差的问题，提出了一种名为球谐扩散策略（SDP）的SE(3)等变扩散策略。SDP通过将状态、动作和去噪过程嵌入球谐傅里叶空间，并引入球谐FiLM层和球谐去噪时间U-net，实现了端到端的SE(3)等变性。实验结果表明，SDP在模拟和物理机器人任务中均显著优于现有基线，展现了在变换3D场景下的强大泛化能力。", "keywords": "扩散策略, SE(3)等变性, 球谐傅里叶空间, 机器人操作, 泛化", "comments": "这篇论文通过引入SE(3)等变性到扩散策略中，显著提升了模型在3D空间中对新颖场景的泛化能力，这是一个重要的创新点。利用球谐傅里叶空间进行嵌入和去噪是实现这一目标的核心，同时结合球谐FiLM层和时间U-net设计体现了对计算效率的考量。该方法有望在机器人操作等需要强泛化能力的领域发挥关键作用。"}}
{"id": "2507.01208", "title": "Deep Learning-Based Intrusion Detection for Automotive Ethernet: Evaluating & Optimizing Fast Inference Techniques for Deployment on Low-Cost Platform", "authors": ["Pedro R. X. Carmo", "Igor de Moura", "Assis T. de Oliveira Filho", "Djamel Sadok", "Cleber Zanchettin"], "summary": "Modern vehicles are increasingly connected, and in this context, automotive\nEthernet is one of the technologies that promise to provide the necessary\ninfrastructure for intra-vehicle communication. However, these systems are\nsubject to attacks that can compromise safety, including flow injection\nattacks. Deep Learning-based Intrusion Detection Systems (IDS) are often\ndesigned to combat this problem, but they require expensive hardware to run in\nreal time. In this work, we propose to evaluate and apply fast neural network\ninference techniques like Distilling and Prunning for deploying IDS models on\nlow-cost platforms in real time. The results show that these techniques can\nachieve intrusion detection times of up to 727 {\\mu}s using a Raspberry Pi 4,\nwith AUCROC values of 0.9890.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01208v1", "categories": ["cs.LG", "cs.CR", "C.2.0; I.2.0"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01208v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "汽车以太网中基于深度学习的入侵检测：评估和优化低成本平台部署的快速推理技术", "tldr": "本文评估并优化了用于低成本平台（如树莓派4）上汽车以太网深度学习入侵检测系统的快速推理技术，实现了低延迟和高准确性。", "motivation": "现代车辆日益互联，汽车以太网为车内通信提供基础设施，但易受流注入攻击等威胁，而现有深度学习入侵检测系统（IDS）通常需要昂贵的硬件才能实时运行。", "method": "本文提出评估和应用快速神经网络推理技术，如蒸馏（Distilling）和剪枝（Pruning），以在低成本平台上实时部署IDS模型。", "result": "在Raspberry Pi 4上，这些技术实现了高达727微秒的入侵检测时间，AUCROC值为0.9890。", "conclusion": "通过应用蒸馏和剪枝等快速推理技术，可以在低成本硬件上实现高效且准确的深度学习汽车以太网入侵检测。", "translation": "现代车辆日益互联，在此背景下，汽车以太网是承诺为车内通信提供必要基础设施的技术之一。然而，这些系统易受可能危及安全的攻击，包括流注入攻击。基于深度学习的入侵检测系统（IDS）通常旨在解决这个问题，但它们需要昂贵的硬件才能实时运行。在这项工作中，我们提出评估和应用快速神经网络推理技术，如蒸馏和剪枝，用于在低成本平台上实时部署IDS模型。结果表明，这些技术在使用Raspberry Pi 4时可以实现高达727微秒的入侵检测时间，AUCROC值为0.9890。", "summary": "本文研究了在低成本硬件平台上部署基于深度学习的汽车以太网入侵检测系统（IDS）的挑战。针对现有IDS需昂贵硬件的问题，作者评估并优化了蒸馏和剪枝等快速神经网络推理技术。实验结果表明，在Raspberry Pi 4上，这些优化技术能实现低至727微秒的检测时间，并保持0.9890的AUCROC值，证明了在资源受限环境中实现高效实时入侵检测的可行性。", "keywords": "汽车以太网, 入侵检测, 深度学习, 快速推理, 低成本平台", "comments": "本文的创新点在于将神经网络推理优化技术应用于汽车以太网入侵检测领域，解决了深度学习模型在低成本嵌入式平台上实时部署的难题。其重要性在于为未来车辆网络安全提供了经济高效的解决方案，使得更广泛的车辆能够集成先进的IDS。"}}
{"id": "2507.01372", "title": "Active Measurement: Efficient Estimation at Scale", "authors": ["Max Hamilton", "Jinlin Lai", "Wenlong Zhao", "Subhransu Maji", "Daniel Sheldon"], "summary": "AI has the potential to transform scientific discovery by analyzing vast\ndatasets with little human effort. However, current workflows often do not\nprovide the accuracy or statistical guarantees that are needed. We introduce\nactive measurement, a human-in-the-loop AI framework for scientific\nmeasurement. An AI model is used to predict measurements for individual units,\nwhich are then sampled for human labeling using importance sampling. With each\nnew set of human labels, the AI model is improved and an unbiased Monte Carlo\nestimate of the total measurement is refined. Active measurement can provide\nprecise estimates even with an imperfect AI model, and requires little human\neffort when the AI model is very accurate. We derive novel estimators,\nweighting schemes, and confidence intervals, and show that active measurement\nreduces estimation error compared to alternatives in several measurement tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01372v1", "categories": ["cs.CV", "cs.LG"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01372v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "主动测量：大规模高效估计", "tldr": "提出一种名为“主动测量”的人机协作AI框架，用于科学测量，即使AI模型不完善也能提供精确估计，并减少人工投入。", "motivation": "当前AI分析大数据的工作流在科学测量中缺乏所需的准确性和统计保证。", "method": "引入“主动测量”框架，这是一个人机协作的AI系统。AI模型预测个体单位的测量值，然后使用重要性采样进行人工标注。每次新的人工标注都会改进AI模型并优化总测量值的无偏蒙特卡洛估计。", "result": "主动测量即使在AI模型不完善的情况下也能提供精确估计；当AI模型非常准确时，所需的人工投入很少。该方法推导了新颖的估计器、加权方案和置信区间，并表明在多项测量任务中，主动测量比其他替代方法能减少估计误差。", "conclusion": "主动测量是一个有效的人机协作AI框架，能够在大规模科学测量中提供精确、低人工投入的估计，解决了现有AI工作流在准确性和统计保证方面的不足。", "translation": "人工智能有潜力通过分析海量数据集且只需少量人工投入来改变科学发现。然而，当前的工作流程通常无法提供所需的准确性或统计保证。我们引入了主动测量，这是一个用于科学测量的人机协作AI框架。该框架使用AI模型预测单个单元的测量值，然后通过重要性采样进行人工标注。随着每批新的人工标注，AI模型得到改进，并且对总测量值的无偏蒙特卡洛估计得到完善。即使AI模型不完善，主动测量也能提供精确的估计，并且当AI模型非常准确时，所需的人工投入很少。我们推导了新颖的估计器、加权方案和置信区间，并表明在多项测量任务中，主动测量与替代方法相比能减少估计误差。", "summary": "本文提出了一个名为“主动测量”的人机协作AI框架，旨在解决现有AI分析大数据在科学测量中准确性和统计保证不足的问题。该框架通过AI模型预测并结合重要性采样进行人工标注，迭代优化AI模型和测量估计。研究表明，主动测量即使在AI模型不完善时也能提供精确估计，并在AI模型准确时显著减少人工投入，同时在多项任务中有效降低了估计误差。", "keywords": "主动测量, 人机协作AI, 科学测量, 估计误差, 重要性采样", "comments": "这篇论文提出了一种创新的人机协作AI框架，将AI的自动化能力与人类的精确判断相结合，有效解决了大规模数据测量中的准确性和效率问题。其核心创新在于引入重要性采样来指导人类标注，从而在有限的人工投入下实现高精度估计，这对于需要高可靠性测量结果的科学发现领域具有重要意义。"}}
{"id": "2507.01048", "title": "3W Dataset 2.0.0: a realistic and public dataset with rare undesirable real events in oil wells", "authors": ["Ricardo Emanuel Vaz Vargas", "Afrânio José de Melo Junior", "Celso José Munaro", "Cláudio Benevenuto de Campos Lima", "Eduardo Toledo de Lima Junior", "Felipe Muntzberg Barrocas", "Flávio Miguel Varejão", "Guilherme Fidelis Peixer", "Igor de Melo Nery Oliveira", "Jader Riso Barbosa Jr.", "Jaime Andrés Lozano Cadena", "Jean Carlos Dias de Araújo", "João Neuenschwander Escosteguy Carneiro", "Lucas Gouveia Omena Lopes", "Lucas Pereira de Gouveia", "Mateus de Araujo Fernandes", "Matheus Lima Scramignon", "Patrick Marques Ciarelli", "Rodrigo Castello Branco", "Rogério Leite Alves Pinto"], "summary": "In the oil industry, undesirable events in oil wells can cause economic\nlosses, environmental accidents, and human casualties. Solutions based on\nArtificial Intelligence and Machine Learning for Early Detection of such events\nhave proven valuable for diverse applications across industries. In 2019,\nrecognizing the importance and the lack of public datasets related to\nundesirable events in oil wells, Petrobras developed and publicly released the\nfirst version of the 3W Dataset, which is essentially a set of Multivariate\nTime Series labeled by experts. Since then, the 3W Dataset has been developed\ncollaboratively and has become a foundational reference for numerous works in\nthe field. This data article describes the current publicly available version\nof the 3W Dataset, which contains structural modifications and additional\nlabeled data. The detailed description provided encourages and supports the 3W\ncommunity and new 3W users to improve previous published results and to develop\nnew robust methodologies, digital products and services capable of detecting\nundesirable events in oil wells with enough anticipation to enable corrective\nor mitigating actions.", "comment": "21 pages, 10 figures, and 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.01048v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01048v1", "date": "2025-06-25", "updated": "2025-06-25", "AI": {"title_translation": "3W数据集2.0.0：一个包含油井中罕见不良真实事件的现实公共数据集", "tldr": "本文介绍了3W数据集的2.0.0版本，这是一个用于检测油井中不良事件的公共且真实的多元时间序列数据集。", "motivation": "油井中的不良事件会导致经济损失、环境事故和人员伤亡。由于缺乏相关的公共数据集，Petrobras开发并发布了3W数据集，以支持人工智能和机器学习在早期检测方面的应用。", "method": "本文描述了3W数据集的当前公共可用版本，该版本包含结构修改和额外标注数据。该数据集本质上是一组由专家标注的多元时间序列。", "result": "提供了3W数据集的2.0.0版本，该版本进行了结构性修改并增加了标注数据，使其成为该领域的基础参考。", "conclusion": "详细的数据集描述旨在鼓励和支持3W社区及新用户改进现有成果，并开发新的鲁棒方法、数字产品和服务，以提前检测油井中的不良事件，从而实现纠正或缓解措施。", "translation": "在石油工业中，油井中的不良事件可能导致经济损失、环境事故和人员伤亡。基于人工智能和机器学习的早期检测此类事件的解决方案已在各行业中证明了其价值。2019年，Petrobras认识到油井不良事件相关公共数据集的重要性和缺乏，开发并公开发布了3W数据集的第一个版本，该数据集本质上是由专家标注的一组多元时间序列。自那时起，3W数据集得到了协作开发，并已成为该领域众多工作的基础参考。这篇数据文章描述了当前公开可用的3W数据集版本，该版本包含结构性修改和额外标注数据。所提供的详细描述鼓励并支持3W社区和新的3W用户改进先前发布的结果，并开发新的鲁棒方法、数字产品和服务，能够足够提前地检测油井中的不良事件，从而实现纠正或缓解措施。", "summary": "本文介绍了3W数据集的最新公共版本（2.0.0），这是一个由专家标注的多元时间序列数据集，旨在帮助人工智能和机器学习模型早期检测油井中可能导致经济、环境和人员损失的罕见不良事件。该数据集自2019年首次发布以来，已成为该领域的重要参考，新版本包含了结构性改进和更多标注数据，旨在促进相关研究和应用开发。", "keywords": "3W数据集, 油井, 不良事件, 公共数据集, 时间序列", "comments": "这篇论文通过发布和更新3W数据集，解决了石油工业中一个关键的实际问题：缺乏用于早期检测油井不良事件的真实公共数据集。其创新之处在于提供了由专家标注的多元时间序列数据，特别是包含了罕见的真实事件，这对于训练鲁棒的AI/ML模型至关重要。该数据集的持续开发和公共可用性，极大地促进了相关领域的学术研究和工业应用，具有显著的实用价值和影响力。"}}
{"id": "2507.01469", "title": "Cross-platform Smartphone Positioning at Museums", "authors": ["Alessio Ferrato", "Fabio Gasparetti", "Carla Limongelli", "Stefano Mastandrea", "Giuseppe Sansonetti", "Joaquín Torres-Sospedra"], "summary": "Indoor Positioning Systems (IPSs) hold significant potential for enhancing\nvisitor experiences in cultural heritage institutions. By enabling personalized\nnavigation, efficient artifact organization, and better interaction with\nexhibits, IPSs can transform the modalities of how individuals engage with\nmuseums, galleries and libraries. However, these institutions face several\nchallenges in implementing IPSs, including environmental constraints, technical\nlimits, and limited experimentation. In other contexts, Received Signal\nStrength (RSS)-based approaches using Bluetooth Low Energy (BLE) and WiFi have\nemerged as preferred solutions due to their non-invasive nature and minimal\ninfrastructure requirements. Nevertheless, the lack of publicly available RSS\ndatasets that specifically reflect museum environments presents a substantial\nbarrier to developing and evaluating positioning algorithms designed for the\nintricate spatial characteristics typical of cultural heritage sites. To\naddress this limitation, we present BAR, a novel RSS dataset collected in front\nof 90 artworks across 13 museum rooms using two different platforms, i.e.,\nAndroid and iOS. Additionally, we provide an advanced position classification\nbaseline taking advantage of a proximity-based method and $k$-NN algorithms. In\nour analysis, we discuss the results and offer suggestions for potential\nresearch directions.", "comment": "Accepted at the 2025 International Conference on Indoor Positioning\n  and Indoor Navigation (IPIN), Tampere, Finland, September 15-18, 2025", "pdf_url": "http://arxiv.org/pdf/2507.01469v1", "categories": ["cs.LG", "eess.SP"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01469v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "博物馆跨平台智能手机定位", "tldr": "该研究提出了一个名为 BAR 的新型 RSS 数据集，用于博物馆环境下的跨平台智能手机定位，并提供了一个基于邻近和 k-NN 的先进位置分类基线，以解决现有博物馆环境中 RSS 数据集缺乏的问题。", "motivation": "博物馆、画廊和图书馆等文化遗产机构在实施室内定位系统（IPS）时面临环境、技术和实验限制。尽管基于 RSS 的方法在其他领域已成为首选，但缺乏专门反映博物馆环境的公开 RSS 数据集，这阻碍了为文化遗产地复杂空间特性设计和评估定位算法。", "method": "研究人员提出了一个名为 BAR 的新型 RSS 数据集，该数据集在 13 个博物馆房间的 90 件艺术品前使用 Android 和 iOS 两个不同平台收集。此外，他们提供了一个利用基于邻近度的方法和 k-NN 算法的先进位置分类基线。", "result": "研究人员收集并发布了 BAR 数据集，并提供了一个先进的位置分类基线。他们在分析中讨论了结果并提出了潜在的研究方向。", "conclusion": "论文通过创建 BAR 数据集并提供分类基线，解决了博物馆环境中缺乏公开 RSS 数据集的限制，为未来博物馆室内定位算法的开发和评估奠定了基础。", "translation": "室内定位系统 (IPS) 在提升文化遗产机构访客体验方面具有巨大潜力。通过实现个性化导航、高效文物组织和更好的展览互动，IPS 可以改变个人与博物馆、画廊和图书馆互动的方式。然而，这些机构在实施 IPS 时面临多项挑战，包括环境限制、技术限制和有限的实验。在其他背景下，使用蓝牙低功耗 (BLE) 和 WiFi 的基于接收信号强度 (RSS) 的方法因其非侵入性和最小基础设施要求而成为首选解决方案。然而，缺乏专门反映博物馆环境的公开 RSS 数据集，对开发和评估专为文化遗产地复杂空间特性设计的定位算法构成了实质性障碍。为了解决这一限制，我们提出了 BAR，一个在 13 个博物馆房间的 90 件艺术品前使用 Android 和 iOS 两个不同平台收集的新型 RSS 数据集。此外，我们提供了一个利用基于邻近度的方法和 k-NN 算法的先进位置分类基线。在我们的分析中，我们讨论了结果并为潜在的研究方向提供了建议。", "summary": "本文旨在解决博物馆环境中室内定位系统（IPS）实施的挑战，特别是缺乏专门的接收信号强度（RSS）数据集。研究人员提出了一个名为 BAR 的新型跨平台 RSS 数据集，该数据集在博物馆内使用 Android 和 iOS 设备收集，涵盖了 90 件艺术品和 13 个房间。同时，论文还提供了一个基于邻近和 k-NN 算法的先进位置分类基线，并讨论了研究结果及未来研究方向。", "keywords": "博物馆定位, 室内定位系统, 接收信号强度, 数据集, 跨平台", "comments": "这篇论文的创新点在于构建并公开了一个专门针对博物馆环境的跨平台 RSS 数据集 (BAR)，这直接解决了当前该领域数据稀缺的痛点。其重要性在于为未来研究者开发和评估博物馆室内定位算法提供了宝贵资源，有助于推动文化遗产机构的数字化转型和访客体验提升。"}}
{"id": "2507.01587", "title": "Towards Controllable Real Image Denoising with Camera Parameters", "authors": ["Youngjin Oh", "Junhyeong Kwon", "Keuntek Lee", "Nam Ik Cho"], "summary": "Recent deep learning-based image denoising methods have shown impressive\nperformance; however, many lack the flexibility to adjust the denoising\nstrength based on the noise levels, camera settings, and user preferences. In\nthis paper, we introduce a new controllable denoising framework that adaptively\nremoves noise from images by utilizing information from camera parameters.\nSpecifically, we focus on ISO, shutter speed, and F-number, which are closely\nrelated to noise levels. We convert these selected parameters into a vector to\ncontrol and enhance the performance of the denoising network. Experimental\nresults show that our method seamlessly adds controllability to standard\ndenoising neural networks and improves their performance. Code is available at\nhttps://github.com/OBAKSA/CPADNet.", "comment": "Accepted for publication in ICIP 2025, IEEE International Conference\n  on Image Processing", "pdf_url": "http://arxiv.org/pdf/2507.01587v1", "categories": ["cs.CV", "eess.IV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01587v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "面向相机参数可控的真实图像去噪", "tldr": "本文提出了一种利用相机参数（如ISO、快门速度、光圈值）的可控去噪框架，以自适应地去除图像噪声，并提升去噪网络性能。", "motivation": "现有深度学习去噪方法缺乏根据噪声水平、相机设置和用户偏好调整去噪强度的灵活性。", "method": "引入一个新的可控去噪框架，通过将与噪声水平密切相关的相机参数（ISO、快门速度、光圈值）转换为向量，用以控制和增强去噪网络的性能。", "result": "实验结果表明，该方法能无缝地为标准去噪神经网络添加可控性，并提升其性能。", "conclusion": "该研究成功地将相机参数引入图像去噪过程，实现了可控的噪声去除，并有效提升了去噪网络的表现。", "translation": "最近基于深度学习的图像去噪方法表现出色；然而，许多方法缺乏根据噪声水平、相机设置和用户偏好调整去噪强度的灵活性。在本文中，我们引入了一种新的可控去噪框架，该框架通过利用相机参数信息来自适应地去除图像中的噪声。具体来说，我们关注ISO、快门速度和光圈值，这些参数与噪声水平密切相关。我们将这些选定的参数转换为向量，以控制和增强去噪网络的性能。实验结果表明，我们的方法可以无缝地为标准去噪神经网络添加可控性并提高其性能。代码可在https://github.com/OBAKSA/CPADNet获取。", "summary": "本文提出了一种新颖的可控图像去噪框架，旨在解决现有深度学习方法在去噪强度调整上的不足。该框架通过利用相机参数（如ISO、快门速度和光圈值）来指导去噪过程，将这些参数转化为向量以控制并提升去噪网络的表现。实验证明，此方法能有效为标准去噪网络赋予可控性，并显著提高其去噪性能。", "keywords": "图像去噪, 可控性, 相机参数, 深度学习, 噪声水平", "comments": "该研究的创新点在于将相机参数引入图像去噪过程，实现了去噪强度的可控性，解决了传统方法缺乏灵活性的问题。这对于实际应用中根据具体相机设置和用户需求进行自适应去噪具有重要意义。"}}
{"id": "2507.01541", "title": "Efficient Out-of-Scope Detection in Dialogue Systems via Uncertainty-Driven LLM Routing", "authors": ["Álvaro Zaera", "Diana Nicoleta Popa", "Ivan Sekulic", "Paolo Rosso"], "summary": "Out-of-scope (OOS) intent detection is a critical challenge in task-oriented\ndialogue systems (TODS), as it ensures robustness to unseen and ambiguous\nqueries. In this work, we propose a novel but simple modular framework that\ncombines uncertainty modeling with fine-tuned large language models (LLMs) for\nefficient and accurate OOS detection. The first step applies uncertainty\nestimation to the output of an in-scope intent detection classifier, which is\ncurrently deployed in a real-world TODS handling tens of thousands of user\ninteractions daily. The second step then leverages an emerging LLM-based\napproach, where a fine-tuned LLM is triggered to make a final decision on\ninstances with high uncertainty. Unlike prior approaches, our method\neffectively balances computational efficiency and performance, combining\ntraditional approaches with LLMs and yielding state-of-the-art results on key\nOOS detection benchmarks, including real-world OOS data acquired from a\ndeployed TODS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01541v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01541v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "通过不确定性驱动的LLM路由实现对话系统中高效的范围外检测", "tldr": "本文提出一个模块化框架，结合不确定性建模和微调LLM，以高效准确地检测对话系统中的范围外意图，并在OOS检测基准上达到SOTA性能。", "motivation": "范围外（OOS）意图检测是任务型对话系统（TODS）中的一个关键挑战，因为它确保了对未知和模糊查询的鲁棒性。", "method": "本文提出一个新颖且简单的模块化框架，结合不确定性建模与微调大型语言模型（LLMs）进行高效准确的OOS检测。该方法分为两步：首先，对现有域内意图检测分类器的输出应用不确定性估计；其次，利用微调的LLM对高不确定性实例做出最终决策。", "result": "该方法有效平衡了计算效率和性能，结合了传统方法与LLMs，并在关键OOS检测基准（包括来自实际部署TODS的真实OOS数据）上取得了最先进的结果。", "conclusion": "通过结合不确定性建模和微调LLM，可以实现对话系统中高效且准确的范围外意图检测，并在实际应用中展现出优越的性能和效率。", "translation": "范围外（OOS）意图检测是任务型对话系统（TODS）中的一个关键挑战，因为它确保了对未知和模糊查询的鲁棒性。在这项工作中，我们提出了一种新颖但简单的模块化框架，该框架将不确定性建模与微调大型语言模型（LLMs）相结合，以实现高效准确的OOS检测。第一步是对域内意图检测分类器的输出应用不确定性估计，该分类器目前已部署在一个每天处理数万用户交互的真实TODS中。第二步则利用新兴的基于LLM的方法，其中微调后的LLM被触发以对高不确定性实例做出最终决策。与以往的方法不同，我们的方法有效平衡了计算效率和性能，将传统方法与LLMs相结合，并在关键OOS检测基准（包括从已部署的TODS中获取的真实OOS数据）上取得了最先进的结果。", "summary": "本文提出一种新颖的模块化框架，用于对话系统中的范围外（OOS）意图检测。该框架首先对现有域内意图检测器的输出进行不确定性估计，然后对高不确定性实例触发微调的大型语言模型（LLM）进行最终判断。这种方法有效结合了传统技术与LLM的优势，平衡了计算效率和性能，并在多个OOS检测基准上，包括真实世界数据，达到了最先进的水平。", "keywords": "范围外检测, 对话系统, 不确定性建模, 大型语言模型, 意图检测", "comments": "该论文的创新点在于提出了一种结合传统不确定性建模和大型语言模型（LLM）的混合方法，有效地解决了对话系统中范围外意图检测的效率与准确性平衡问题。其模块化设计和在真实世界数据上的验证，表明了该方法在实际部署中的潜力和重要性。"}}
{"id": "2507.01917", "title": "PDE-Constrained High-Order Mesh Optimization", "authors": ["Tzanio Kolev", "Boyan Lazarov", "Ketan Mittal", "Mathias Schmidt", "Vladimir Tomov"], "summary": "We present a novel framework for PDE-constrained $r$-adaptivity of high-order\nmeshes. The proposed method formulates mesh movement as an optimization\nproblem, with an objective function defined as a convex combination of a mesh\nquality metric and a measure of the accuracy of the PDE solution obtained via\nfinite element discretization. The proposed formulation achieves optimized,\nwell-defined high-order meshes by integrating mesh quality control, PDE\nsolution accuracy, and robust gradient regularization. We adopt the\nTarget-Matrix Optimization Paradigm to control geometric properties across the\nmesh, independent of the PDE of interest. To incorporate the accuracy of the\nPDE solution, we introduce error measures that control the finite element\ndiscretization error. The implicit dependence of these error measures on the\nmesh nodal positions is accurately captured by adjoint sensitivity analysis.\nAdditionally, a convolution-based gradient regularization strategy is used to\nensure stable and effective adaptation of high-order meshes. We demonstrate\nthat the proposed framework can improve mesh quality and reduce the error by up\nto 10 times for the solution of Poisson and linear elasto-static problems. The\napproach is general with respect to the dimensionality, the order of the mesh,\nthe types of mesh elements, and can be applied to any PDE that admits\nwell-defined adjoint operators.", "comment": "22 pages, 14 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.01917v1", "categories": ["math.NA", "cs.MS", "cs.NA"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01917v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "PDE约束的高阶网格优化", "tldr": "一种新的框架通过结合网格质量、解精度和鲁棒正则化来优化高阶网格，将PDE解误差降低了10倍。", "motivation": "旨在为高阶网格的PDE约束r-自适应性提供一个新颖的框架，以实现优化、定义良好的高阶网格，提高网格质量并减少PDE解的误差。", "method": "该方法将网格移动表述为一个优化问题，其目标函数定义为网格质量度量和通过有限元离散化获得的PDE解精度度量的凸组合。它通过整合网格质量控制、PDE解精度和鲁棒梯度正则化来实现优化。采用目标矩阵优化范式控制几何属性。引入误差度量来控制有限元离散误差，并通过伴随敏感性分析精确捕捉其对网格节点位置的隐式依赖。此外，使用基于卷积的梯度正则化策略确保高阶网格的稳定有效自适应。", "result": "该框架能够提高网格质量，并将泊松问题和线性弹性静力学问题的解误差降低多达10倍。该方法在维度、网格阶数、网格元素类型方面具有通用性，并且可以应用于任何承认定义良好的伴随算子的PDE。", "conclusion": "所提出的框架能够有效地优化高阶网格，显著提高网格质量并减少PDE解的误差，并且具有广泛的适用性。", "translation": "我们提出了一种用于高阶网格PDE约束r-自适应性的新颖框架。所提出的方法将网格移动表述为一个优化问题，其目标函数定义为网格质量度量和通过有限元离散化获得的PDE解精度度量的凸组合。所提出的公式通过整合网格质量控制、PDE解精度和鲁棒梯度正则化，实现了优化、定义良好的高阶网格。我们采用目标矩阵优化范式来控制整个网格的几何属性，这与感兴趣的PDE无关。为了纳入PDE解的精度，我们引入了控制有限元离散误差的误差度量。这些误差度量对网格节点位置的隐式依赖通过伴随敏感性分析精确捕捉。此外，使用基于卷积的梯度正则化策略来确保高阶网格的稳定有效自适应。我们证明了所提出的框架可以提高网格质量，并将泊松问题和线性弹性静力学问题的解误差降低多达10倍。该方法在维度、网格阶数、网格元素类型方面具有通用性，并且可以应用于任何承认定义良好的伴随算子的PDE。", "summary": "本文提出了一种用于PDE约束高阶网格r-自适应性的新颖优化框架。该框架将网格移动建模为优化问题，其目标函数结合了网格质量和PDE解精度。通过集成网格质量控制、PDE解精度（通过伴随敏感性分析）和鲁棒梯度正则化，该方法能够生成优化的高阶网格。实验证明，该框架能将泊松问题和线性弹性静力学问题的解误差降低高达10倍，并且在维度、网格阶数和元素类型方面具有通用性，适用于任何具有良好定义伴随算子的PDE。", "keywords": "PDE约束, 网格优化, 高阶网格, r-自适应性, 有限元", "comments": "该论文的创新之处在于其提出了一种统一的优化框架，将高阶网格的质量控制、PDE解精度（通过精确的伴随敏感性分析）和鲁棒的梯度正则化有效地结合起来。这种综合方法解决了高阶网格自适应中的关键挑战，并显著提高了数值模拟的精度和效率，尤其是在复杂PDE问题中。其通用性也增加了其实用价值。"}}
{"id": "2507.01753", "title": "Augmented Bridge Spinal Fixation: A New Concept for Addressing Pedicle Screw Pullout via a Steerable Drilling Robot and Flexible Pedicle Screws", "authors": ["Yash Kulkarni", "Susheela Sharma", "Omid Rezayof", "Siddhartha Kapuria", "Jordan P. Amadio", "Mohsen Khadem", "Maryam Tilton", "Farshid Alambeigi"], "summary": "To address the screw loosening and pullout limitations of rigid pedicle\nscrews in spinal fixation procedures, and to leverage our recently developed\nConcentric Tube Steerable Drilling Robot (CT-SDR) and Flexible Pedicle Screw\n(FPS), in this paper, we introduce the concept of Augmented Bridge Spinal\nFixation (AB-SF). In this concept, two connecting J-shape tunnels are first\ndrilled through pedicles of vertebra using the CT-SDR. Next, two FPSs are\npassed through this tunnel and bone cement is then injected through the\ncannulated region of the FPS to form an augmented bridge between two pedicles\nand reinforce strength of the fixated spine. To experimentally analyze and\nstudy the feasibility of AB-SF technique, we first used our robotic system\n(i.e., a CT-SDR integrated with a robotic arm) to create two different fixation\nscenarios in which two J-shape tunnels, forming a bridge, were drilled at\ndifferent depth of a vertebral phantom. Next, we implanted two FPSs within the\ndrilled tunnels and then successfully simulated the bone cement augmentation\nprocess.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01753v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01753v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "增强型桥接脊柱内固定：一种通过可控钻孔机器人和柔性椎弓根螺钉解决椎弓根螺钉拔出的新概念", "tldr": "本文提出了一种名为增强型桥接脊柱内固定 (AB-SF) 的新概念，利用可控管状钻孔机器人和柔性椎弓根螺钉，通过钻孔并注入骨水泥形成桥接，以解决脊柱固定中刚性椎弓根螺钉松动和拔出的问题，并初步通过实验验证了其可行性。", "motivation": "解决脊柱内固定手术中刚性椎弓根螺钉松动和拔出的局限性。", "method": "本文引入了增强型桥接脊柱内固定 (AB-SF) 的概念。该方法首先使用同心管可控钻孔机器人 (CT-SDR) 在椎骨椎弓根中钻出两个连接的J形隧道。然后，将两个柔性椎弓根螺钉 (FPS) 穿过隧道，并通过FPS的套管区域注入骨水泥，在两个椎弓根之间形成一个增强型桥接，以增强固定脊柱的强度。为了实验分析和研究AB-SF技术的可行性，研究人员使用机器人系统（即集成机械臂的CT-SDR）在椎骨模型中创建了两种不同的固定场景，钻出不同深度的J形隧道形成桥接，并成功植入FPS并模拟了骨水泥增强过程。", "result": "成功模拟了骨水泥增强过程，并初步验证了增强型桥接脊柱内固定 (AB-SF) 技术的可行性。", "conclusion": "增强型桥接脊柱内固定 (AB-SF) 是一种通过可控钻孔机器人和柔性椎弓根螺钉解决椎弓根螺钉拔出的可行新概念。", "translation": "为了解决脊柱内固定手术中刚性椎弓根螺钉松动和拔出的局限性，并利用我们最近开发的同心管可控钻孔机器人 (CT-SDR) 和柔性椎弓根螺钉 (FPS)，本文引入了增强型桥接脊柱内固定 (AB-SF) 的概念。在该概念中，首先使用CT-SDR在椎骨椎弓根中钻出两个连接的J形隧道。接下来，将两个FPS穿过该隧道，然后通过FPS的套管区域注入骨水泥，以在两个椎弓根之间形成一个增强型桥接，并增强固定脊柱的强度。为了实验分析和研究AB-SF技术的可行性，我们首先使用我们的机器人系统（即集成机械臂的CT-SDR）创建了两种不同的固定场景，其中在椎骨模型不同深度钻出形成桥接的J形隧道。接下来，我们将两个FPS植入钻好的隧道中，然后成功模拟了骨水泥增强过程。", "summary": "本文提出了一种名为增强型桥接脊柱内固定 (AB-SF) 的新概念，旨在通过利用可控管状钻孔机器人 (CT-SDR) 和柔性椎弓根螺钉 (FPS) 来解决脊柱固定中刚性椎弓根螺钉的松动和拔出问题。该方法涉及使用CT-SDR钻出J形隧道，然后植入FPS并通过其注入骨水泥以形成增强桥接。初步的实验验证在椎骨模型上成功模拟了骨水泥增强过程，证明了该技术的可行性。", "keywords": "脊柱内固定, 椎弓根螺钉拔出, 可控钻孔机器人, 柔性椎弓根螺钉, 骨水泥增强", "comments": "该论文提出了一种创新的脊柱内固定方法，通过结合机器人钻孔技术和柔性螺钉与骨水泥增强，有望有效解决传统椎弓根螺钉松动和拔出的临床难题。其创新点在于J形隧道的构建和骨水泥桥接概念，为提高脊柱固定的稳定性和长期效果提供了新思路。未来需要进一步的生物力学测试和体内实验来验证其临床有效性。"}}
{"id": "2507.01216", "title": "PAE MobiLLM: Privacy-Aware and Efficient LLM Fine-Tuning on the Mobile Device via Additive Side-Tuning", "authors": ["Xingke Yang", "Liang Li", "Zhiyi Wan", "Sicong Li", "Hao Wang", "Xiaoqi Qi", "Jiang Liu", "Tomoaki Ohtsuki", "Xin Fu", "Miao Pan"], "summary": "There is a huge gap between numerous intriguing applications fostered by\non-device large language model (LLM) fine-tuning (FT) from fresh mobile data\nand the limited resources of a mobile device. While existing server-assisted\nmethods (e.g., split learning or side-tuning) may enable LLM FT on the local\nmobile device, they suffer from heavy communication burdens of activation\ntransmissions, and may disclose data, labels or fine-tuned models to the\nserver. To address those issues, we develop PAE MobiLLM, a privacy-aware and\nefficient LLM FT method which can be deployed on the mobile device via\nserver-assisted additive side-tuning. To further accelerate FT convergence and\nimprove computing efficiency, PAE MobiLLM integrates activation caching on the\nserver side, which allows the server to reuse historical activations and saves\nthe mobile device from repeatedly computing forward passes for the recurring\ndata samples. Besides, to reduce communication cost, PAE MobiLLM develops a\none-token (i.e., ``pivot'' token) activation shortcut that transmits only a\nsingle activation dimension instead of full activation matrices to guide the\nside network tuning. Last but not least, PAE MobiLLM introduces the additive\nadapter side-network design which makes the server train the adapter modules\nbased on device-defined prediction differences rather than raw ground-truth\nlabels. In this way, the server can only assist device-defined side-network\ncomputing, and learn nothing about data, labels or fine-tuned models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01216v1", "categories": ["cs.LG", "cs.CR"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01216v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "PAE MobiLLM: 移动设备上通过加法侧微调实现的隐私感知高效LLM微调", "tldr": "PAE MobiLLM是一种在移动设备上通过服务器辅助加法侧微调实现隐私保护和高效LLM微调的方法，解决了资源限制、通信负担和隐私泄露问题。", "motivation": "在移动设备上进行大语言模型（LLM）微调面临资源限制、现有服务器辅助方法（如分层学习或侧微调）存在高昂的激活传输通信负担，并且可能向服务器泄露数据、标签或微调模型等隐私问题。", "method": "开发了PAE MobiLLM，一种隐私感知且高效的LLM微调方法，通过服务器辅助加法侧微调部署在移动设备上。该方法集成了服务器端激活缓存以重用历史激活并节省设备计算；开发了“枢轴”令牌（one-token）激活快捷方式，仅传输单个激活维度以减少通信成本；并引入加法适配器侧网络设计，使服务器基于设备定义的预测差异而非原始真实标签训练适配器模块，从而保护隐私。", "result": "PAE MobiLLM能够加速微调收敛、提高计算效率、显著减少通信成本，并确保数据、标签和微调模型的隐私性。", "conclusion": "PAE MobiLLM通过其独特的设计，包括激活缓存、单令牌激活快捷方式和加法适配器侧网络，有效地解决了移动设备上LLM微调面临的资源限制、通信效率和隐私保护等关键挑战。", "translation": "在移动设备上通过新鲜移动数据进行大语言模型（LLM）微调（FT）所带来的众多引人入胜的应用，与移动设备有限的资源之间存在巨大差距。尽管现有的服务器辅助方法（例如，分层学习或侧微调）可能在本地移动设备上实现LLM微调，但它们面临激活传输的沉重通信负担，并且可能向服务器泄露数据、标签或微调模型。为了解决这些问题，我们开发了PAE MobiLLM，这是一种隐私感知且高效的LLM微调方法，可以通过服务器辅助的加法侧微调部署在移动设备上。为了进一步加速微调收敛并提高计算效率，PAE MobiLLM集成了服务器端激活缓存，这允许服务器重用历史激活，并使移动设备无需为重复数据样本重复计算前向传播。此外，为了降低通信成本，PAE MobiLLM开发了一种单令牌（即“枢轴”令牌）激活快捷方式，它只传输单个激活维度而不是完整的激活矩阵来指导侧网络微调。最后但同样重要的是，PAE MobiLLM引入了加法适配器侧网络设计，这使得服务器能够基于设备定义的预测差异而不是原始真实标签来训练适配器模块。通过这种方式，服务器只能辅助设备定义的侧网络计算，而无法学习到有关数据、标签或微调模型的任何信息。", "summary": "本文提出了PAE MobiLLM，一种针对移动设备上LLM微调的隐私感知和高效方法。它通过服务器辅助的加法侧微调，解决了移动设备资源受限、现有方法通信开销大和隐私泄露的挑战。PAE MobiLLM通过服务器端激活缓存、单令牌激活快捷方式和基于设备定义预测差异的加法适配器侧网络设计，实现了加速收敛、提高计算效率、降低通信成本并确保用户数据隐私。", "keywords": "LLM微调, 移动设备, 隐私保护, 侧微调, 激活缓存", "comments": "PAE MobiLLM的创新点在于其多方面结合的优化策略：服务器端激活缓存减少设备计算，单令牌激活快捷方式显著降低通信量，以及最关键的加法适配器侧网络设计，通过仅传输预测差异而非原始标签来彻底保护隐私。这在资源受限且对隐私敏感的移动端LLM微调场景中具有重要意义。"}}
{"id": "2507.01384", "title": "MUG: Pseudo Labeling Augmented Audio-Visual Mamba Network for Audio-Visual Video Parsing", "authors": ["Langyu Wang", "Bingke Zhu", "Yingying Chen", "Yiyuan Zhang", "Ming Tang", "Jinqiao Wang"], "summary": "The weakly-supervised audio-visual video parsing (AVVP) aims to predict all\nmodality-specific events and locate their temporal boundaries. Despite\nsignificant progress, due to the limitations of the weakly-supervised and the\ndeficiencies of the model architecture, existing methods are lacking in\nsimultaneously improving both the segment-level prediction and the event-level\nprediction. In this work, we propose a audio-visual Mamba network with pseudo\nlabeling aUGmentation (MUG) for emphasising the uniqueness of each segment and\nexcluding the noise interference from the alternate modalities. Specifically,\nwe annotate some of the pseudo-labels based on previous work. Using unimodal\npseudo-labels, we perform cross-modal random combinations to generate new data,\nwhich can enhance the model's ability to parse various segment-level event\ncombinations. For feature processing and interaction, we employ a audio-visual\nmamba network. The AV-Mamba enhances the ability to perceive different segments\nand excludes additional modal noise while sharing similar modal information.\nOur extensive experiments demonstrate that MUG improves state-of-the-art\nresults on LLP dataset in all metrics (e.g,, gains of 2.1% and 1.2% in terms of\nvisual Segment-level and audio Segment-level metrics). Our code is available at\nhttps://github.com/WangLY136/MUG.", "comment": "Accpted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.01384v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01384v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "MUG：伪标签增强的音视频Mamba网络用于音视频事件解析", "tldr": "MUG提出一种结合伪标签增强和音视频Mamba网络的弱监督音视频事件解析方法，通过强调片段独特性和减少跨模态噪声，在LLP数据集上取得了SOTA表现。", "motivation": "现有的弱监督音视频事件解析（AVVP）方法在同时改进片段级和事件级预测方面存在局限性，主要原因在于弱监督的限制和模型架构的不足。", "method": "本文提出MUG（Audio-visual Mamba network with pseudo labeling aUGmentation）网络。该方法通过基于先前工作标注伪标签，并利用单模态伪标签进行跨模态随机组合生成新数据，以增强模型解析不同片段级事件组合的能力。同时，采用音视频Mamba网络进行特征处理和交互，以增强对不同片段的感知并排除额外的模态噪声，同时共享相似的模态信息。", "result": "MUG在LLP数据集上的所有指标上都改进了最先进的结果，例如在视觉片段级和音频片段级指标上分别获得了2.1%和1.2%的提升。", "conclusion": "MUG方法通过引入伪标签增强和音视频Mamba网络，成功解决了弱监督音视频事件解析中现有方法在同时提升片段级和事件级预测上的不足，并在LLP数据集上取得了最先进的性能。", "translation": "弱监督音视频事件解析（AVVP）旨在预测所有模态特定的事件并定位其时间边界。尽管取得了显著进展，但由于弱监督的限制和模型架构的不足，现有方法在同时改进片段级预测和事件级预测方面存在欠缺。在这项工作中，我们提出了一种带有伪标签增强的音视频Mamba网络（MUG），旨在强调每个片段的独特性并排除来自其他模态的噪声干扰。具体来说，我们基于之前的工作标注了一些伪标签。利用单模态伪标签，我们执行跨模态随机组合以生成新数据，这可以增强模型解析各种片段级事件组合的能力。对于特征处理和交互，我们采用了一个音视频Mamba网络。AV-Mamba在共享相似模态信息的同时，增强了感知不同片段的能力并排除了额外的模态噪声。我们的大量实验表明，MUG在LLP数据集上的所有指标（例如，视觉片段级和音频片段级指标分别提升了2.1%和1.2%）上都改进了最先进的结果。我们的代码可在https://github.com/WangLY136/MUG获取。", "summary": "本文针对弱监督音视频事件解析（AVVP）中现有方法在片段级和事件级预测方面的不足，提出了一种名为MUG（Pseudo Labeling Augmented Audio-Visual Mamba Network）的新方法。MUG通过伪标签增强和音视频Mamba网络，旨在强调每个片段的独特性并减少跨模态噪声干扰。具体而言，该方法利用单模态伪标签进行跨模态随机组合以生成增强数据，并采用音视频Mamba网络进行高效的特征处理和交互。实验结果表明，MUG在LLP数据集上取得了所有指标的最先进性能，尤其在视觉和音频片段级指标上分别有显著提升。", "keywords": "音视频事件解析, 伪标签, Mamba网络, 弱监督, 跨模态", "comments": "这篇论文通过结合伪标签增强和新颖的音视频Mamba网络，有效解决了弱监督音视频事件解析中存在的关键挑战，即同时提升片段级和事件级预测的准确性。其创新点在于利用伪标签进行数据增强以捕捉片段独特性，并引入Mamba网络来优化跨模态特征处理和噪声抑制。在LLP数据集上取得的显著性能提升，表明该方法在实际应用中具有重要潜力。"}}
{"id": "2507.01050", "title": "Text Detoxification: Data Efficiency, Semantic Preservation and Model Generalization", "authors": ["Jing Yu", "Yibo Zhao", "Jiapeng Zhu", "Wenming Shao", "Bo Pang", "Zhao Zhang", "Xiang Li"], "summary": "The widespread dissemination of toxic content on social media poses a serious\nthreat to both online environments and public discourse, highlighting the\nurgent need for detoxification methods that effectively remove toxicity while\npreserving the original semantics. However, existing approaches often struggle\nto simultaneously achieve strong detoxification performance, semantic\npreservation, and robustness to out-of-distribution data. Moreover, they\ntypically rely on costly, manually annotated parallel corpora while showing\npoor data efficiency. To address these challenges, we propose a two-stage\ntraining framework that jointly optimizes for data efficiency, semantic\npreservation, and model generalization. We first perform supervised fine-tuning\non a small set of high-quality, filtered parallel data to establish a strong\ninitialization. Then, we leverage unlabeled toxic inputs and a custom-designed\nreward model to train the LLM using Group Relative Policy Optimization.\nExperimental results demonstrate that our method effectively mitigates the\ntrade-offs faced by previous work, achieving state-of-the-art performance with\nimproved generalization and significantly reduced dependence on annotated data.\nOur code is available at:\nhttps://anonymous.4open.science/r/Detoxification-of-Text-725F/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01050v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01050v1", "date": "2025-06-23", "updated": "2025-06-23", "AI": {"title_translation": "文本去毒：数据效率、语义保留与模型泛化", "tldr": "本文提出了一种两阶段训练框架，用于文本去毒，旨在提高数据效率、语义保留和模型泛化能力，并在减少对标注数据依赖的同时实现了最先进的性能。", "motivation": "社交媒体上毒性内容的广泛传播对在线环境和公共讨论构成严重威胁，现有去毒方法难以同时实现强大的去毒性能、语义保留和对分布外数据的鲁棒性，并且通常依赖昂贵的手动标注并行语料库，数据效率低下。", "method": "本文提出一个两阶段训练框架。首先，在少量高质量过滤的并行数据上进行有监督微调以建立强大的初始模型。然后，利用未标注的毒性输入和自定义奖励模型，使用组相对策略优化（Group Relative Policy Optimization）训练大型语言模型（LLM）。", "result": "实验结果表明，该方法有效缓解了先前工作面临的权衡问题，实现了最先进的性能，提高了泛化能力，并显著降低了对标注数据的依赖。", "conclusion": "本文提出的两阶段训练框架能够有效解决文本去毒中的数据效率、语义保留和模型泛化挑战，实现了卓越的性能。", "translation": "社交媒体上毒性内容的广泛传播对在线环境和公共讨论构成严重威胁，这突显了对能够有效去除毒性同时保留原始语义的去毒方法的迫切需求。然而，现有方法往往难以同时实现强大的去毒性能、语义保留和对分布外数据的鲁棒性。此外，它们通常依赖于昂贵的手动标注并行语料库，同时表现出较差的数据效率。为了解决这些挑战，我们提出了一个两阶段训练框架，该框架共同优化数据效率、语义保留和模型泛化。我们首先在一小部分高质量、经过筛选的并行数据上进行有监督微调，以建立强大的初始化模型。然后，我们利用未标注的毒性输入和自定义设计的奖励模型，使用组相对策略优化（Group Relative Policy Optimization）来训练大型语言模型（LLM）。实验结果表明，我们的方法有效缓解了先前工作面临的权衡问题，实现了最先进的性能，提高了泛化能力，并显著降低了对标注数据的依赖。我们的代码可在以下网址获取：https://anonymous.4open.science/r/Detoxification-of-Text-725F/", "summary": "本文针对社交媒体中毒性内容传播的问题，提出了一种两阶段训练框架来解决现有文本去毒方法在数据效率、语义保留和模型泛化方面的不足。该框架首先通过少量高质量标注数据进行监督微调，然后利用未标注数据和自定义奖励模型进行强化学习。实验证明，该方法在减少对标注数据依赖的同时，实现了最先进的去毒性能和更好的泛化能力。", "keywords": "文本去毒, 数据效率, 语义保留, 模型泛化, 强化学习", "comments": "本文的创新点在于提出了一个两阶段训练框架，有效结合了监督学习和强化学习，解决了文本去毒领域数据效率低、语义保留差以及模型泛化能力弱的痛点。通过利用少量高质量数据进行初始化和未标注数据进行强化训练，显著降低了对昂贵标注数据的依赖，这对于实际应用具有重要意义。"}}
{"id": "2507.01581", "title": "A Privacy-Preserving Indoor Localization System based on Hierarchical Federated Learning", "authors": ["Masood Jan", "Wafa Njima", "Xun Zhang"], "summary": "Location information serves as the fundamental element for numerous Internet\nof Things (IoT) applications. Traditional indoor localization techniques often\nproduce significant errors and raise privacy concerns due to centralized data\ncollection. In response, Machine Learning (ML) techniques offer promising\nsolutions by capturing indoor environment variations. However, they typically\nrequire central data aggregation, leading to privacy, bandwidth, and server\nreliability issues. To overcome these challenges, in this paper, we propose a\nFederated Learning (FL)-based approach for dynamic indoor localization using a\nDeep Neural Network (DNN) model. Experimental results show that FL has the\nnearby performance to Centralized Model (CL) while keeping the data privacy,\nbandwidth efficiency and server reliability. This research demonstrates that\nour proposed FL approach provides a viable solution for privacy-enhanced indoor\nlocalization, paving the way for advancements in secure and efficient indoor\nlocalization systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01581v1", "categories": ["cs.LG", "cs.CR", "eess.SP"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01581v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于分层联邦学习的隐私保护室内定位系统", "tldr": "本文提出了一种基于联邦学习的深度神经网络方法，用于隐私保护的动态室内定位，实验证明其性能接近集中式模型，并能保护数据隐私、提高带宽效率和服务器可靠性。", "motivation": "传统室内定位技术误差大且存在中心化数据收集导致的隐私问题。机器学习虽能解决环境变化问题，但仍需中心化数据聚合，带来隐私、带宽和服务器可靠性问题。", "method": "提出了一种基于联邦学习（FL）的深度神经网络（DNN）方法，用于动态室内定位。", "result": "实验结果表明，FL的性能接近集中式模型（CL），同时保持了数据隐私、带宽效率和服务器可靠性。", "conclusion": "这项研究表明，所提出的FL方法为隐私增强室内定位提供了一个可行的解决方案，为安全高效的室内定位系统的发展铺平了道路。", "translation": "位置信息是众多物联网（IoT）应用的基本要素。传统的室内定位技术常因集中式数据收集而产生显著误差并引发隐私问题。对此，机器学习（ML）技术通过捕捉室内环境变化提供了有前景的解决方案。然而，它们通常需要集中式数据聚合，导致隐私、带宽和服务器可靠性问题。为克服这些挑战，本文提出了一种基于联邦学习（FL）的方法，使用深度神经网络（DNN）模型进行动态室内定位。实验结果表明，FL的性能接近集中式模型（CL），同时保持了数据隐私、带宽效率和服务器可靠性。这项研究表明，我们提出的FL方法为隐私增强室内定位提供了一个可行的解决方案，为安全高效的室内定位系统的发展铺平了道路。", "summary": "本文提出了一种基于分层联邦学习的深度神经网络模型，用于解决传统室内定位技术中存在的误差大、中心化数据收集导致的隐私、带宽和服务器可靠性问题。实验结果表明，该联邦学习方法在保持数据隐私、带宽效率和服务器可靠性的同时，其性能与集中式模型接近，为安全高效的隐私增强室内定位系统提供了可行的解决方案。", "keywords": "联邦学习, 室内定位, 隐私保护, 深度神经网络, 物联网", "comments": "该论文创新性地将联邦学习应用于室内定位，有效解决了传统方法的隐私和效率痛点，为物联网应用中的位置服务提供了新的思路。其亮点在于在性能接近传统集中式模型的同时，显著提升了数据隐私和系统效率。"}}
{"id": "2507.01359", "title": "Inequalities in Fourier analysis on binary cubes", "authors": ["Tonći Crmarić", "Vjekoslav Kovač", "Shobu Shiraki"], "summary": "This paper studies two classical inequalities, namely the Hausdorff-Young\ninequality and equal-exponent Young's convolution inequality, for discrete\nfunctions supported in the binary cube $\\{0,1\\}^d\\subset\\mathbb{Z}^d$. We\ncharacterize the exact ranges of Lebesgue exponents in which sharp versions of\nthese two inequalities hold, and present several immediate consequences. First,\nif the functions are specialized to be the indicator of some set\n$A\\subseteq\\{0,1\\}^d$, then we obtain sharp upper bounds on two types of\ngeneralized additive energies of $A$, extending the works of Kane-Tao, de Dios\nPont-Greenfeld-Ivanisvili-Madrid, and one of the present authors. Second, we\nobtain a sharp binary variant of the Beckner-Hirschman entropic uncertainty\nprinciple, as well as a sharp lower estimate on the entropy of a sum of two\nindependent random variables with values in $\\{0,1\\}^d$. Finally, the sharp\nbinary Hausdorff-Young inequality also reveals the exact range of\ndimension-free estimates for the Fourier restriction to the binary cube.", "comment": "29 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.01359v1", "categories": ["math.CA", "cs.IT", "math.CO", "math.IT"], "cate": "math.CA", "url": "http://arxiv.org/abs/2507.01359v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "二元立方体上傅里叶分析中的不等式", "tldr": "本论文研究了二元立方体上离散函数的豪斯多夫-杨不等式和等指数杨氏卷积不等式，确定了它们成立的勒贝格指数精确范围，并提出了多项重要应用，包括广义加性能量、贝克纳-赫什曼熵不确定性原理的二元变体以及傅里叶限制的维度无关估计。", "motivation": "本研究旨在探讨二元立方体（即离散函数在{0,1}^d中的支撑）上的离散函数的两个经典不等式，即豪斯多夫-杨不等式和等指数杨氏卷积不等式。", "method": "通过表征这些不等式成立的勒贝格指数的精确范围，并分析其在特定函数类型下的应用，例如指示函数、独立随机变量等。", "result": "1. 确定了豪斯多夫-杨不等式和等指数杨氏卷积不等式在二元立方体上成立的勒贝格指数的精确范围。2. 当函数是某个集合A的指示函数时，获得了A的两种广义加性能量的精确上界，扩展了现有工作。3. 获得了贝克纳-赫什曼熵不确定性原理的精确二元变体，以及两个在{0,1}^d中取值的独立随机变量之和的熵的精确下限估计。4. 精确的二元豪斯多夫-杨不等式揭示了傅里叶限制到二元立方体的维度无关估计的精确范围。", "conclusion": "本研究通过对二元立方体上豪斯多夫-杨不等式和杨氏卷积不等式的深入分析，不仅精确刻画了它们成立的条件，还揭示了它们在广义加性能量、熵不确定性原理以及傅里叶限制等多个数学领域的重要应用和精确估计。", "translation": "本论文研究了在二元立方体{0,1}^d⊂Z^d中支撑的离散函数的两个经典不等式，即豪斯多夫-杨不等式和等指数杨氏卷积不等式。我们刻画了这两个不等式的精确勒贝格指数范围，在此范围内它们的尖锐版本成立，并提出了几个直接的推论。首先，如果函数专门是某个集合A⊂{0,1}^d的指示函数，那么我们获得了A的两种广义加性能量的精确上界，这扩展了Kane-Tao、de Dios Pont-Greenfeld-Ivanisvili-Madrid以及本论文其中一位作者的工作。其次，我们获得了贝克纳-赫什曼熵不确定性原理的精确二元变体，以及两个在{0,1}^d中取值的独立随机变量之和的熵的精确下限估计。最后，精确的二元豪斯多夫-杨不等式也揭示了傅里叶限制到二元立方体的维度无关估计的精确范围。", "summary": "本文研究了二元立方体上离散函数的豪斯多夫-杨不等式和等指数杨氏卷积不等式。研究刻画了这些不等式成立的勒贝格指数精确范围，并展示了多项应用。具体而言，研究为集合的广义加性能量提供了精确上界，得到了贝克纳-赫什曼熵不确定性原理的精确二元变体，并揭示了傅里叶限制的维度无关估计的精确范围。", "keywords": "傅里叶分析, 二元立方体, 豪斯多夫-杨不等式, 杨氏卷积不等式, 熵不确定性", "comments": "本论文通过对经典傅里叶分析不等式在二元立方体上的推广和精确刻画，展现了其创新性。它不仅深化了对离散傅里叶分析的理解，而且在广义加性能量、熵不确定性原理等领域取得了重要且精确的结果，对相关领域的研究具有显著的推动作用。"}}
{"id": "2507.01608", "title": "Perception-Oriented Latent Coding for High-Performance Compressed Domain Semantic Inference", "authors": ["Xu Zhang", "Ming Lu", "Yan Chen", "Zhan Ma"], "summary": "In recent years, compressed domain semantic inference has primarily relied on\nlearned image coding models optimized for mean squared error (MSE). However,\nMSE-oriented optimization tends to yield latent spaces with limited semantic\nrichness, which hinders effective semantic inference in downstream tasks.\nMoreover, achieving high performance with these models often requires\nfine-tuning the entire vision model, which is computationally intensive,\nespecially for large models. To address these problems, we introduce\nPerception-Oriented Latent Coding (POLC), an approach that enriches the\nsemantic content of latent features for high-performance compressed domain\nsemantic inference. With the semantically rich latent space, POLC requires only\na plug-and-play adapter for fine-tuning, significantly reducing the parameter\ncount compared to previous MSE-oriented methods. Experimental results\ndemonstrate that POLC achieves rate-perception performance comparable to\nstate-of-the-art generative image coding methods while markedly enhancing\nperformance in vision tasks, with minimal fine-tuning overhead. Code is\navailable at https://github.com/NJUVISION/POLC.", "comment": "International Conference on Multimedia and Expo (ICME), 2025", "pdf_url": "http://arxiv.org/pdf/2507.01608v1", "categories": ["cs.CV", "eess.IV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01608v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "感知导向的潜在编码用于高性能压缩域语义推理", "tldr": "本文提出了一种感知导向的潜在编码（POLC）方法，用于在压缩域中进行高效的语义推理，解决了现有方法语义贫乏和微调成本高的问题。", "motivation": "现有的压缩域语义推理方法主要依赖于MSE优化的图像编码模型，导致潜在空间语义贫乏，阻碍下游任务的有效语义推理；同时，这些模型通常需要对整个视觉模型进行计算密集型微调。", "method": "提出感知导向的潜在编码（POLC），通过丰富潜在特征的语义内容来解决问题。POLC利用语义丰富的潜在空间，仅需一个即插即用的适配器进行微调，显著减少了参数数量。", "result": "实验结果表明，POLC在速率-感知性能上与最先进的生成式图像编码方法相当，同时显著提高了视觉任务的性能，且微调开销极小。", "conclusion": "POLC通过其感知导向的潜在编码方法，成功解决了压缩域语义推理中语义丰富性和微调效率的挑战，实现了高性能和低成本的语义推理。", "translation": "近年来，压缩域语义推理主要依赖于为均方误差（MSE）优化的学习图像编码模型。然而，面向MSE的优化往往会产生语义丰富性有限的潜在空间，这阻碍了下游任务中有效的语义推理。此外，使用这些模型实现高性能通常需要对整个视觉模型进行微调，这计算量很大，特别是对于大型模型。为了解决这些问题，我们引入了感知导向的潜在编码（POLC），这是一种丰富潜在特征语义内容以实现高性能压缩域语义推理的方法。凭借语义丰富的潜在空间，POLC仅需要一个即插即用的适配器进行微调，与以前面向MSE的方法相比，显著减少了参数数量。实验结果表明，POLC实现了与最先进的生成式图像编码方法相当的速率-感知性能，同时显著增强了视觉任务的性能，且微调开销极小。代码可在https://github.com/NJUVISION/POLC 获取。", "summary": "本文提出了一种新颖的感知导向的潜在编码（POLC）方法，旨在解决现有压缩域语义推理中潜在空间语义贫乏和微调成本高昂的问题。POLC通过丰富潜在特征的语义内容，构建语义丰富的潜在空间，并允许使用即插即用适配器进行高效微调。实验证明，POLC在保持高图像质量的同时，显著提升了视觉任务性能，并大幅降低了微调开销。", "keywords": "压缩域语义推理, 感知导向编码, 潜在空间, 微调, 图像编码", "comments": "POLC的创新点在于其感知导向的潜在编码策略，它有效地解决了传统MSE优化模型在语义丰富性上的不足。通过引入即插即用的适配器进行微调，该方法显著降低了计算成本，使其在大规模模型和实际应用中更具可行性。这对于推动压缩域语义推理的发展具有重要意义。"}}
{"id": "2507.01324", "title": "An Error Bound for Aggregation in Approximate Dynamic Programming", "authors": ["Yuchao Li", "Dimitri Bertsekas"], "summary": "We consider a general aggregation framework for discounted finite-state\ninfinite horizon dynamic programming (DP) problems. It defines an aggregate\nproblem whose optimal cost function can be obtained off-line by exact DP and\nthen used as a terminal cost approximation for an on-line reinforcement\nlearning (RL) scheme. We derive a bound on the error between the optimal cost\nfunctions of the aggregate problem and the original problem. This bound was\nfirst derived by Tsitsiklis and van Roy [TvR96] for the special case of hard\naggregation. Our bound is similar but applies far more broadly, including to\nsoft aggregation and feature-based aggregation schemes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01324v1", "categories": ["math.OC", "cs.SY", "eess.SY"], "cate": "math.OC", "url": "http://arxiv.org/abs/2507.01324v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "近似动态规划中聚合的误差界", "tldr": "本文为近似动态规划中的通用聚合框架推导了一个误差界，该误差界比现有成果适用范围更广，包括软聚合和基于特征的聚合。", "motivation": "本文旨在为折现有限状态无限时域动态规划（DP）问题中的通用聚合框架推导一个误差界，以量化聚合问题与原始问题最优成本函数之间的差异，并支持在线强化学习（RL）方案的终端成本近似。", "method": "本文提出一个通用的聚合框架，其中聚合问题的最优成本函数可通过离线精确动态规划（DP）获得，并用作在线强化学习（RL）方案的终端成本近似。在此基础上，推导了聚合问题与原始问题最优成本函数之间的误差界。", "result": "推导了一个新的误差界，该误差界比Tsitsiklis和van Roy [TvR96]提出的界限适用范围更广，涵盖了硬聚合、软聚合以及基于特征的聚合方案。", "conclusion": "本文推导的误差界显著扩展了其适用范围，涵盖了多种聚合方案，为近似动态规划和强化学习提供了更通用的理论基础和误差分析工具。", "translation": "我们考虑了一个针对折现有限状态无限时域动态规划（DP）问题的通用聚合框架。它定义了一个聚合问题，其最优成本函数可以通过离线精确DP获得，然后用作在线强化学习（RL）方案的终端成本近似。我们推导了聚合问题和原始问题最优成本函数之间误差的一个界限。这个界限最初由Tsitsiklis和van Roy [TvR96]针对硬聚合的特殊情况推导。我们的界限与之类似，但适用范围更广，包括软聚合和基于特征的聚合方案。", "summary": "本文提出了一个用于折现有限状态无限时域动态规划（DP）问题的通用聚合框架。该框架通过离线精确DP计算聚合问题的最优成本函数，并将其作为在线强化学习（RL）的终端成本近似。研究推导了一个新的误差界，用于衡量聚合问题与原始问题最优成本函数之间的差异。与现有工作相比，该误差界具有更广泛的适用性，涵盖了硬聚合、软聚合以及基于特征的聚合方案。", "keywords": "动态规划, 聚合, 误差界, 强化学习, 近似", "comments": "本文的创新之处在于将误差界从特定的硬聚合扩展到更通用的聚合框架，包括软聚合和基于特征的聚合。这对于近似动态规划和强化学习的理论基础和实际应用都具有重要意义，因为它允许在更广泛的场景下对近似误差进行量化和控制，从而提高算法的可靠性和适用性。"}}
{"id": "2507.01543", "title": "Is External Information Useful for Stance Detection with LLMs?", "authors": ["Quang Minh Nguyen", "Taegyoon Kim"], "summary": "In the stance detection task, a text is classified as either favorable,\nopposing, or neutral towards a target. Prior work suggests that the use of\nexternal information, e.g., excerpts from Wikipedia, improves stance detection\nperformance. However, whether or not such information can benefit large\nlanguage models (LLMs) remains an unanswered question, despite their wide\nadoption in many reasoning tasks. In this study, we conduct a systematic\nevaluation on how Wikipedia and web search external information can affect\nstance detection across eight LLMs and in three datasets with 12 targets.\nSurprisingly, we find that such information degrades performance in most cases,\nwith macro F1 scores dropping by up to 27.9\\%. We explain this through\nexperiments showing LLMs' tendency to align their predictions with the stance\nand sentiment of the provided information rather than the ground truth stance\nof the given text. We also find that performance degradation persists with\nchain-of-thought prompting, while fine-tuning mitigates but does not fully\neliminate it. Our findings, in contrast to previous literature on BERT-based\nsystems which suggests that external information enhances performance,\nhighlight the risks of information biases in LLM-based stance classifiers. Code\nis available at https://github.com/ngqm/acl2025-stance-detection.", "comment": "ACL Findings 2025", "pdf_url": "http://arxiv.org/pdf/2507.01543v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01543v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "外部信息对LLM立场检测有用吗？", "tldr": "本研究发现，与BERT模型不同，外部信息（如维基百科和网络搜索结果）在大多数情况下会降低大型语言模型（LLMs）在立场检测任务中的性能，因为LLMs倾向于与外部信息而非真实文本立场保持一致。", "motivation": "先前的研究表明外部信息可以提高立场检测性能，但对于大型语言模型（LLMs）是否也能从中受益，目前仍是一个未解的问题。鉴于LLMs在许多推理任务中的广泛应用，研究外部信息对其立场检测性能的影响至关重要。", "method": "研究人员对八个大型语言模型（LLMs）在三个数据集和12个目标上进行了系统评估，测试维基百科和网络搜索等外部信息如何影响立场检测性能。此外，还通过实验解释了性能下降的原因，并测试了思维链提示和微调的效果。", "result": "令人惊讶的是，外部信息在大多数情况下会降低LLMs的立场检测性能，宏观F1分数下降高达27.9%。这主要是因为LLMs倾向于将其预测与所提供信息的立场和情感而非给定文本的真实立场对齐。思维链提示未能改善性能，而微调虽然能缓解但不能完全消除性能下降。", "conclusion": "与先前关于BERT系统认为外部信息能增强性能的文献相反，本研究结果强调了LLM立场分类器中信息偏差的风险，表明外部信息在LLM立场检测中通常是弊大于利。", "translation": "在立场检测任务中，文本被分类为对某个目标持赞成、反对或中立态度。先前的研究表明，使用外部信息（例如维基百科的摘录）可以提高立场检测性能。然而，尽管大型语言模型（LLMs）在许多推理任务中被广泛采用，但此类信息是否能使其受益仍然是一个未解之谜。在这项研究中，我们系统地评估了维基百科和网络搜索外部信息如何影响八个LLM以及三个数据集（包含12个目标）的立场检测。令人惊讶的是，我们发现此类信息在大多数情况下会降低性能，宏观F1分数下降高达27.9%。我们通过实验解释了这一点，这些实验表明LLM倾向于将其预测与所提供信息的立场和情感保持一致，而不是与给定文本的真实立场保持一致。我们还发现，性能下降在思维链提示下仍然存在，而微调可以缓解但不能完全消除它。我们的发现与先前关于基于BERT的系统（认为外部信息能增强性能）的文献形成对比，强调了LLM立场分类器中信息偏差的风险。代码可在https://github.com/ngqm/acl2025-stance-detection获取。", "summary": "本研究系统评估了外部信息（维基百科和网络搜索）对八个大型语言模型（LLMs）在立场检测任务中的影响。与此前BERT模型的研究结果相反，外部信息在多数情况下会显著降低LLMs的性能（F1分数下降达27.9%），主要原因是LLMs倾向于受外部信息立场和情感的误导。尽管思维链提示无效，微调能部分缓解此问题，但未能完全消除。研究强调了LLM立场分类器中信息偏差的风险。", "keywords": "立场检测, 大型语言模型, 外部信息, 信息偏差, 性能下降", "comments": "这项研究具有重要的创新性和实践意义。它挑战了先前关于外部信息普遍提升模型性能的普遍认知，特别是对于大型语言模型。通过揭示LLM在处理外部信息时易受信息偏差影响的倾向，为未来LLM在敏感任务中的应用提供了关键的警示。这项工作对于理解LLM的推理机制及其局限性至关重要，并为开发更鲁棒的LLM应用指明了方向。其发现对于指导LLM在实际部署中的数据选择和预处理策略具有直接指导意义。"}}
{"id": "2507.01958", "title": "Parallel-in-Time Preconditioning for Time-Dependent Variational Mean Field Games", "authors": ["Heidi Wolles Ljósheim", "Dante Kalise", "John W. Pearson", "Francisco J. Silva"], "summary": "We study the numerical approximation of a time-dependent variational mean\nfield game system with local couplings and either periodic or Neumann boundary\nconditions. Following a variational approach, we employ a finite difference\ndiscretization and solve the resulting finite-dimensional optimization problem\nusing the Chambolle--Pock primal--dual algorithm. As this involves computing\nproximal operators and solving ill-conditioned linear systems at each\niteration, we propose a general class of parallel-in-time preconditioners based\non diagonalization techniques using discrete Fourier transforms. These enable\nefficient, scalable iterative solvers with robustness across a wide range of\nviscosities. We further develop fast solvers for the resulting ill-conditioned\nsystems arising at each time step, using exact recursive schemes for structured\ngrids while allowing for other geometries. Numerical experiments confirm the\nimproved performance and parallel scalability of our approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01958v1", "categories": ["math.NA", "cs.NA", "math.OC"], "cate": "math.NA", "url": "http://arxiv.org/abs/2507.01958v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "时间相关变分平均场博弈的时空并行预处理", "tldr": "研究并提出了时间相关变分平均场博弈的数值近似方法，通过引入基于对角化技术的时空并行预处理，显著提高了求解效率和并行可扩展性。", "motivation": "在求解时间相关变分平均场博弈系统时，Chambolle--Pock 算法的每次迭代都涉及计算近端算子和求解病态线性系统，这导致了计算效率低下的问题。", "method": "该研究采用变分方法，使用有限差分离散化来近似时间相关变分平均场博弈系统。对于由此产生的有限维优化问题，使用 Chambolle--Pock 原始-对偶算法求解。为了解决每次迭代中出现的病态线性系统，提出了基于离散傅里叶变换对角化技术的一类通用时空并行预处理器。此外，还开发了针对每个时间步长出现的病态系统，使用结构化网格的精确递归方案的快速求解器。", "result": "数值实验证实，所提出的方法显著提高了性能和并行可扩展性，并且在宽范围的粘度下表现出鲁棒性。", "conclusion": "该研究成功开发了一种高效、可扩展且对不同粘度具有鲁棒性的数值方法，用于近似时间相关变分平均场博弈系统，通过引入时空并行预处理和快速求解器，有效解决了迭代过程中的病态线性系统问题。", "translation": "我们研究具有局部耦合以及周期或诺伊曼边界条件的时间相关变分平均场博弈系统的数值近似。遵循变分方法，我们采用有限差分离散化，并使用 Chambolle--Pock 原始-对偶算法求解由此产生的有限维优化问题。由于这在每次迭代中都涉及计算近端算子和求解病态线性系统，我们提出了一类基于使用离散傅立叶变换对角化技术的通用时空并行预处理器。这些预处理器能够实现高效、可扩展的迭代求解器，并在宽范围的粘度下保持鲁棒性。我们进一步开发了针对每个时间步长出现的病态系统，使用结构化网格的精确递归方案的快速求解器，同时允许其他几何形状。数值实验证实了我们方法的改进性能和并行可扩展性。", "summary": "本文研究了时间相关变分平均场博弈系统的数值近似，该系统具有局部耦合及周期或诺伊曼边界条件。通过有限差分离散化和 Chambolle--Pock 算法求解，针对迭代中遇到的病态线性系统，提出了基于对角化技术的时空并行预处理器和快速求解器。数值实验表明，该方法显著提高了求解性能和并行可扩展性，并对不同粘度具有鲁棒性。", "keywords": "时间相关变分平均场博弈, 时空并行预处理, Chambolle--Pock 算法, 病态线性系统, 数值近似", "comments": "该论文的创新点在于提出了基于对角化技术的时空并行预处理器和针对每个时间步长病态系统的快速求解器，这有效解决了在求解时间相关变分平均场博弈系统时 Chambolle--Pock 算法迭代中出现的病态线性系统问题。其重要性体现在显著提升了数值求解的效率、并行可扩展性以及对不同粘度的鲁棒性，为复杂偏微分方程的数值模拟提供了高效工具。"}}
{"id": "2507.01779", "title": "S3D: A Spatial Steerable Surgical Drilling Framework for Robotic Spinal Fixation Procedures", "authors": ["Daniyal Maroufi", "Xinyuan Huang", "Yash Kulkarni", "Omid Rezayof", "Susheela Sharma", "Vaibhav Goggela", "Jordan P. Amadio", "Mohsen Khadem", "Farshid Alambeigi"], "summary": "In this paper, we introduce S3D: A Spatial Steerable Surgical Drilling\nFramework for Robotic Spinal Fixation Procedures. S3D is designed to enable\nrealistic steerable drilling while accounting for the anatomical constraints\nassociated with vertebral access in spinal fixation (SF) procedures. To achieve\nthis, we first enhanced our previously designed concentric tube Steerable\nDrilling Robot (CT-SDR) to facilitate steerable drilling across all vertebral\nlevels of the spinal column. Additionally, we propose a four-Phase calibration,\nregistration, and navigation procedure to perform realistic SF procedures on a\nspine holder phantom by integrating the CT-SDR with a seven-degree-of-freedom\nrobotic manipulator. The functionality of this framework is validated through\nplanar and out-of-plane steerable drilling experiments in vertebral phantoms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01779v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01779v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "S3D：一种用于机器人脊柱固定手术的空间可控手术钻孔框架", "tldr": "S3D是一个用于机器人脊柱固定手术的框架，实现了考虑解剖限制的可控钻孔。", "motivation": "为了在脊柱固定（SF）手术中，在考虑椎骨进入相关解剖学限制的同时，实现逼真的可控钻孔。", "method": "该研究增强了之前设计的同心管可控钻孔机器人（CT-SDR），使其能够在脊柱所有椎骨水平上进行可控钻孔。此外，提出了一种四阶段的校准、注册和导航程序，通过将CT-SDR与七自由度机器人机械臂集成，在脊柱支架模型上进行手术。", "result": "该框架的功能通过在椎骨模型中的平面和离面可控钻孔实验得到了验证。", "conclusion": "该论文引入并验证了S3D，一个能够实现机器人脊柱固定手术中可控钻孔的框架，同时考虑了解剖学限制。", "translation": "在本文中，我们介绍了S3D：一种用于机器人脊柱固定手术的空间可控手术钻孔框架。S3D旨在实现逼真的可控钻孔，同时考虑脊柱固定（SF）手术中椎骨进入相关的解剖学限制。为实现此目标，我们首先增强了我们之前设计的同心管可控钻孔机器人（CT-SDR），以促进在脊柱所有椎骨水平上的可控钻孔。此外，我们提出了一种四阶段的校准、注册和导航程序，通过将CT-SDR与七自由度机器人机械臂集成，在脊柱支架模型上进行逼真的SF手术。该框架的功能通过在椎骨模型中的平面和离面可控钻孔实验得到了验证。", "summary": "本文介绍了S3D，一个用于机器人脊柱固定手术的空间可控手术钻孔框架。S3D旨在实现逼真的可控钻孔，同时考虑椎骨进入的解剖学限制。为实现此目标，研究人员增强了同心管可控钻孔机器人（CT-SDR），并提出了一个四阶段的校准、注册和导航程序，将其与七自由度机械臂集成。该框架的功能通过椎骨模型中的平面和离面可控钻孔实验得到了验证。", "keywords": "S3D, 可控钻孔, 脊柱固定, 机器人手术, CT-SDR", "comments": "该论文提出S3D框架，通过增强CT-SDR并结合多阶段校准、注册和导航程序，实现了机器人脊柱固定手术中的空间可控钻孔，创新性地解决了在解剖限制下进行精确钻孔的挑战。其重要性在于提升了机器人辅助脊柱手术的精度和安全性。目前验证仅限于模型，未来需进行体内实验。"}}
{"id": "2507.01292", "title": "Hardness of Quantum Distribution Learning and Quantum Cryptography", "authors": ["Taiga Hiroka", "Min-Hsiu Hsieh", "Tomoyuki Morimae"], "summary": "The existence of one-way functions (OWFs) forms the minimal assumption in\nclassical cryptography. However, this is not necessarily the case in quantum\ncryptography. One-way puzzles (OWPuzzs), introduced by Khurana and Tomer,\nprovide a natural quantum analogue of OWFs. The existence of OWPuzzs implies\n$PP\\neq BQP$, while the converse remains open. In classical cryptography, the\nanalogous problem-whether OWFs can be constructed from $P \\neq NP$-has long\nbeen studied from the viewpoint of hardness of learning. Hardness of learning\nin various frameworks (including PAC learning) has been connected to OWFs or to\n$P \\neq NP$. In contrast, no such characterization previously existed for\nOWPuzzs. In this paper, we establish the first complete characterization of\nOWPuzzs based on the hardness of a well-studied learning model: distribution\nlearning. Specifically, we prove that OWPuzzs exist if and only if proper\nquantum distribution learning is hard on average. A natural question that\nfollows is whether the worst-case hardness of proper quantum distribution\nlearning can be derived from $PP \\neq BQP$. If so, and a worst-case to\naverage-case hardness reduction is achieved, it would imply OWPuzzs solely from\n$PP \\neq BQP$. However, we show that this would be extremely difficult: if\nworst-case hardness is PP-hard (in a black-box reduction), then $SampBQP \\neq\nSampBPP$ follows from the infiniteness of the polynomial hierarchy. Despite\nthat, we show that $PP \\neq BQP$ is equivalent to another standard notion of\nhardness of learning: agnostic. We prove that $PP \\neq BQP$ if and only if\nagnostic quantum distribution learning with respect to KL divergence is hard.\nAs a byproduct, we show that hardness of agnostic quantum distribution learning\nwith respect to statistical distance against $PPT^{\\Sigma_3^P}$ learners\nimplies $SampBQP \\neq SampBPP$.", "comment": "59 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.01292v1", "categories": ["quant-ph", "cs.CC", "cs.CR"], "cate": "quant-ph", "url": "http://arxiv.org/abs/2507.01292v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "量子分布学习与量子密码学的困难性", "tldr": "本文首次将单向谜题（OWPuzzs）与量子分布学习的困难性进行了完整刻画，并探讨了PP≠BQP与不可知量子分布学习困难性的等价性。", "motivation": "经典密码学中的单向函数（OWFs）是其最小假设，但在量子密码学中并非如此。单向谜题（OWPuzzs）是OWFs的自然量子模拟，其存在性蕴含PP≠BQP。经典密码学中，OWFs与P≠NP的关系已通过学习的困难性进行了研究，但对于OWPuzzs，此前缺乏类似的刻画。本文旨在填补这一空白，建立OWPuzzs与学习困难性之间的联系。", "method": "本文通过理论证明，建立了单向谜题（OWPuzzs）与量子分布学习困难性之间的完整刻画。具体而言，证明了OWPuzzs的存在性等价于平均情况下的适当量子分布学习是困难的。此外，还证明了PP≠BQP等价于关于KL散度的不可知量子分布学习是困难的。", "result": "1. 单向谜题（OWPuzzs）存在当且仅当平均情况下的适当量子分布学习是困难的。2. 证明了从PP≠BQP推导出适当量子分布学习的最坏情况困难性是极其困难的，因为如果最坏情况困难性是PP-hard（在黑盒归约下），则从多项式层级的无限性可以推导出SampBQP≠SampBPP。3. 证明了PP≠BQP等价于关于KL散度的不可知量子分布学习是困难的。4. 作为副产品，证明了关于统计距离的不可知量子分布学习对PPT^{\\Sigma_3^P}学习者的困难性蕴含SampBQP≠SampBPP。", "conclusion": "本文首次完整刻画了单向谜题（OWPuzzs）与量子分布学习困难性之间的关系，揭示了它们与计算复杂性类（如PP≠BQP）的深刻联系，为量子密码学和计算复杂性理论提供了新的见解。", "translation": "单向函数（OWFs）的存在构成了经典密码学中的最小假设。然而，在量子密码学中情况并非如此。Khurana和Tomer引入的单向谜题（OWPuzzs）提供了一种OWFs的自然量子模拟。OWPuzzs的存在蕴含PP≠BQP，而反向命题仍未解决。在经典密码学中，类似的问题——OWFs是否可以从P≠NP构建——长期以来一直从学习困难性的角度进行研究。各种框架（包括PAC学习）中的学习困难性已与OWFs或P≠NP相关联。相比之下，OWPuzzs此前没有这样的刻画。在本文中，我们首次基于一个被充分研究的学习模型：分布学习，建立了OWPuzzs的第一个完整刻画。具体来说，我们证明了OWPuzzs存在当且仅当平均情况下的适当量子分布学习是困难的。随之而来的一个自然问题是，适当量子分布学习的最坏情况困难性是否可以从PP≠BQP中推导出来。如果可以，并且实现了从最坏情况到平均情况的困难性归约，那将仅从PP≠BQP推导出OWPuzzs。然而，我们证明这将极其困难：如果最坏情况困难性是PP-hard（在黑盒归约下），那么从多项式层级的无限性可以推导出SampBQP≠SampBPP。尽管如此，我们证明了PP≠BQP等价于另一种标准的学习困难性概念：不可知学习。我们证明了PP≠BQP当且仅当关于KL散度的不可知量子分布学习是困难的。作为副产品，我们证明了关于统计距离的不可知量子分布学习对PPT^{\\Sigma_3^P}学习者的困难性蕴含SampBQP≠SampBPP。", "summary": "本文首次建立了单向谜题（OWPuzzs）与量子分布学习困难性之间的完整刻画。研究发现，OWPuzzs的存在等价于平均情况下的适当量子分布学习是困难的。同时，论文探讨了从PP≠BQP推导最坏情况困难性的挑战性，并证明了PP≠BQP等价于关于KL散度的不可知量子分布学习是困难的。这些发现为量子密码学和计算复杂性理论提供了重要联系。", "keywords": "单向谜题, 量子分布学习, 量子密码学, 计算复杂性, 学习困难性", "comments": "本文的创新之处在于首次为量子密码学中的核心概念——单向谜题（OWPuzzs）——提供了基于分布学习困难性的完整理论刻画，填补了该领域的一个空白。其重要性体现在将OWPuzzs与具体的计算复杂性类（如PP≠BQP）以及学习理论中的概念联系起来，深化了我们对量子密码学基础假设的理解。特别是，它揭示了从最坏情况到平均情况困难性归约在量子背景下的复杂性，并引入了不可知学习作为PP≠BQP的等价条件，为未来的研究提供了新的方向。"}}
{"id": "2507.01390", "title": "FixTalk: Taming Identity Leakage for High-Quality Talking Head Generation in Extreme Cases", "authors": ["Shuai Tan", "Bill Gong", "Bin Ji", "Ye Pan"], "summary": "Talking head generation is gaining significant importance across various\ndomains, with a growing demand for high-quality rendering. However, existing\nmethods often suffer from identity leakage (IL) and rendering artifacts (RA),\nparticularly in extreme cases. Through an in-depth analysis of previous\napproaches, we identify two key insights: (1) IL arises from identity\ninformation embedded within motion features, and (2) this identity information\ncan be leveraged to address RA. Building on these findings, this paper\nintroduces FixTalk, a novel framework designed to simultaneously resolve both\nissues for high-quality talking head generation. Firstly, we propose an\nEnhanced Motion Indicator (EMI) to effectively decouple identity information\nfrom motion features, mitigating the impact of IL on generated talking heads.\nTo address RA, we introduce an Enhanced Detail Indicator (EDI), which utilizes\nthe leaked identity information to supplement missing details, thus fixing the\nartifacts. Extensive experiments demonstrate that FixTalk effectively mitigates\nIL and RA, achieving superior performance compared to state-of-the-art methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01390v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01390v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "FixTalk：在极端情况下驯服身份泄露以实现高质量说话人头部生成", "tldr": "FixTalk提出了一种新框架，通过解耦运动特征中的身份信息和利用泄露的身份信息补充缺失细节，解决了说话人头部生成中的身份泄露和渲染伪影问题，实现了高质量生成。", "motivation": "现有说话人头部生成方法在极端情况下常遭受身份泄露（IL）和渲染伪影（RA）问题，影响生成质量。", "method": "本文提出了FixTalk框架。首先，引入增强运动指示器（EMI）来解耦运动特征中的身份信息，以减轻身份泄露。其次，引入增强细节指示器（EDI），利用泄露的身份信息来补充缺失的细节，从而修复渲染伪影。", "result": "大量实验表明，FixTalk有效缓解了身份泄露和渲染伪影，与现有最先进方法相比，取得了卓越的性能。", "conclusion": "FixTalk通过独特的机制成功解决了说话人头部生成中的身份泄露和渲染伪影两大挑战，显著提升了生成质量。", "translation": "说话人头部生成在各个领域中正变得越来越重要，对高质量渲染的需求不断增长。然而，现有方法通常会遭受身份泄露（IL）和渲染伪影（RA）的影响，尤其是在极端情况下。通过对以往方法的深入分析，我们发现了两个关键见解：(1) 身份泄露源于嵌入在运动特征中的身份信息，以及 (2) 这些身份信息可以被利用来解决渲染伪影。基于这些发现，本文引入了FixTalk，一个旨在同时解决这两个问题以实现高质量说话人头部生成的创新框架。首先，我们提出了一个增强运动指示器（EMI），以有效地将身份信息与运动特征解耦，从而减轻身份泄露对生成的说话人头部的影响。为了解决渲染伪影，我们引入了一个增强细节指示器（EDI），它利用泄露的身份信息来补充缺失的细节，从而修复伪影。大量的实验表明，FixTalk有效缓解了身份泄露和渲染伪影，与最先进的方法相比，取得了卓越的性能。", "summary": "FixTalk是一个针对高质量说话人头部生成的新框架，旨在解决现有方法在极端情况下常见的身份泄露和渲染伪影问题。该框架通过提出增强运动指示器（EMI）来解耦运动特征中的身份信息以减轻身份泄露，并通过引入增强细节指示器（EDI）利用泄露的身份信息补充缺失细节来修复渲染伪影。实验证明FixTalk在减少身份泄露和渲染伪影方面表现优异。", "keywords": "说话人头部生成, 身份泄露, 渲染伪影, FixTalk, 运动特征", "comments": "FixTalk的创新之处在于其对身份泄露和渲染伪影问题的独特视角，即身份信息既是问题的根源（身份泄露），又可以是解决另一个问题（渲染伪影）的关键。通过解耦和再利用身份信息，FixTalk提供了一种新颖且有效的解决方案，对高质量说话人头部生成领域具有重要意义。"}}
{"id": "2507.01196", "title": "Are Large Brainwave Foundation Models Capable Yet? Insights from Fine-tuning", "authors": ["Na Lee", "Konstantinos Barmpas", "Yannis Panagakis", "Dimitrios Adamos", "Nikolaos Laskaris", "Stefanos Zafeiriou"], "summary": "Foundation Models have demonstrated significant success across various\ndomains in Artificial Intelligence (AI), yet their capabilities for brainwave\nmodeling remain unclear. In this paper, we comprehensively evaluate current\nLarge Brainwave Foundation Models (LBMs) through systematic fine-tuning\nexperiments across multiple Brain-Computer Interface (BCI) benchmark tasks,\nincluding memory tasks and sleep stage classification. Our extensive analysis\nshows that state-of-the-art LBMs achieve only marginal improvements (0.9%-1.2%)\nover traditional deep architectures while requiring significantly more\nparameters (millions vs thousands), raising important questions about their\nefficiency and applicability in BCI contexts. Moreover, through detailed\nablation studies and Low-Rank Adaptation (LoRA), we significantly reduce\ntrainable parameters without performance degradation, while demonstrating that\narchitectural and training inefficiencies limit LBMs' current capabilities. Our\nexperiments span both full model fine-tuning and parameter-efficient adaptation\ntechniques, providing insights into optimal training strategies for BCI\napplications. We pioneer the application of LoRA to LBMs, revealing that\nperformance benefits generally emerge when adapting multiple neural network\ncomponents simultaneously. These findings highlight the critical need for\ndomain-specific development strategies to advance LBMs, suggesting that current\narchitectures may require redesign to fully leverage the potential of\nfoundation models in brainwave analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01196v1", "categories": ["cs.LG", "cs.AI", "cs.HC"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01196v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "大型脑电波基础模型是否已具备能力？来自微调的见解", "tldr": "大型脑电波基础模型在脑机接口任务上表现提升微弱，且参数量巨大；通过LoRA可显著减少参数并揭示当前架构效率低下。", "motivation": "基础模型在AI领域取得了显著成功，但在脑电波建模方面的能力尚不明确，因此需要评估当前大型脑电波基础模型（LBMs）的能力。", "method": "通过在多个脑机接口（BCI）基准任务（包括记忆任务和睡眠阶段分类）上进行系统的微调实验，全面评估LBMs。同时，进行详细的消融研究并应用低秩适应（LoRA）技术。", "result": "最先进的LBMs相比传统深度架构仅获得微小的改进（0.9%-1.2%），但需要显著更多的参数。通过LoRA，可以在不降低性能的情况下显著减少可训练参数。性能提升通常出现在同时适应多个神经网络组件时。研究表明，架构和训练效率低下限制了LBMs的当前能力。", "conclusion": "当前的大型脑电波基础模型在脑机接口任务上的表现提升有限，且存在效率问题。未来的发展需要领域特定的开发策略，可能需要重新设计现有架构以充分利用基础模型在脑电波分析中的潜力。", "translation": "基础模型在人工智能（AI）的各个领域都取得了显著成功，但它们在脑电波建模方面的能力仍不明确。在本文中，我们通过在多个脑机接口（BCI）基准任务（包括记忆任务和睡眠阶段分类）上进行系统的微调实验，全面评估了当前的大型脑电波基础模型（LBMs）。我们广泛的分析表明，最先进的LBMs相比传统深度架构仅取得了微小的改进（0.9%-1.2%），同时需要显著更多的参数（数百万对数千），这对其在BCI环境中的效率和适用性提出了重要问题。此外，通过详细的消融研究和低秩适应（LoRA），我们在不降低性能的情况下显著减少了可训练参数，同时证明了架构和训练效率低下限制了LBMs的当前能力。我们的实验涵盖了全模型微调和参数高效适应技术，为BCI应用的优化训练策略提供了见解。我们率先将LoRA应用于LBMs，揭示了当同时适应多个神经网络组件时，性能优势通常会出现。这些发现强调了推进LBMs的领域特定开发策略的迫切需求，表明当前架构可能需要重新设计，以充分利用基础模型在脑电波分析中的潜力。", "summary": "本研究评估了大型脑电波基础模型（LBMs）在脑机接口（BCI）任务中的能力。通过在多个BCI基准任务上进行微调，发现LBMs相对于传统深度架构仅有微小性能提升，但参数量巨大。研究还通过LoRA技术显著减少了可训练参数，并指出LBMs当前能力受限于架构和训练效率。结论强调需针对脑电波分析开发领域特定策略，并可能需要重新设计LBMs架构。", "keywords": "大型脑电波基础模型, 微调, 脑机接口, LoRA, 脑电波分析", "comments": "这篇论文揭示了当前大型脑电波基础模型在脑机接口领域应用的局限性，尤其是在效率和性能提升方面。其创新点在于首次将LoRA应用于LBMs，并证明了参数高效适应的可行性。论文的发现对未来脑电波基础模型的设计和优化方向具有重要指导意义，强调了领域特定设计的重要性。"}}
{"id": "2507.01841", "title": "Automatic Rank Determination for Low-Rank Adaptation via Submodular Function Maximization", "authors": ["Yihang Gao", "Vincent Y. F. Tan"], "summary": "In this paper, we propose SubLoRA, a rank determination method for Low-Rank\nAdaptation (LoRA) based on submodular function maximization. In contrast to\nprior approaches, such as AdaLoRA, that rely on first-order (linearized)\napproximations of the loss function, SubLoRA utilizes second-order information\nto capture the potentially complex loss landscape by incorporating the Hessian\nmatrix. We show that the linearization becomes inaccurate and ill-conditioned\nwhen the LoRA parameters have been well optimized, motivating the need for a\nmore reliable and nuanced second-order formulation. To this end, we reformulate\nthe rank determination problem as a combinatorial optimization problem with a\nquadratic objective. However, solving this problem exactly is NP-hard in\ngeneral. To overcome the computational challenge, we introduce a submodular\nfunction maximization framework and devise a greedy algorithm with\napproximation guarantees. We derive a sufficient and necessary condition under\nwhich the rank-determination objective becomes submodular, and construct a\nclosed-form projection of the Hessian matrix that satisfies this condition\nwhile maintaining computational efficiency. Our method combines solid\ntheoretical foundations, second-order accuracy, and practical computational\nefficiency. We further extend SubLoRA to a joint optimization setting,\nalternating between LoRA parameter updates and rank determination under a rank\nbudget constraint. Extensive experiments on fine-tuning physics-informed neural\nnetworks (PINNs) for solving partial differential equations (PDEs) demonstrate\nthe effectiveness of our approach. Results show that SubLoRA outperforms\nexisting methods in both rank determination and joint training performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01841v1", "categories": ["cs.LG", "cs.IT", "eess.SP", "math.IT", "math.OC"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01841v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于次模函数最大化的低秩适应自动秩确定", "tldr": "SubLoRA 是一种基于次模函数最大化的 LoRA 秩确定方法，它利用二阶信息，解决了现有方法一阶近似不准确的问题，并在物理信息神经网络（PINNs）的微调实验中表现优于现有方法。", "motivation": "现有 LoRA 秩确定方法（如 AdaLoRA）依赖于损失函数的一阶（线性化）近似，当 LoRA 参数经过良好优化后，这种线性化变得不准确且病态。因此，需要一种更可靠、更细致的二阶公式来捕捉复杂的损失景观。", "method": "本文提出了 SubLoRA，一种基于次模函数最大化的 LoRA 秩确定方法。它利用 Hessian 矩阵的二阶信息，将秩确定问题重新表述为具有二次目标的组合优化问题。为了解决 NP-hard 的计算挑战，引入了次模函数最大化框架，并设计了一个具有近似保证的贪婪算法。方法推导了秩确定目标变为次模的充分必要条件，并构建了满足该条件且保持计算效率的 Hessian 矩阵闭合形式投影。此外，SubLoRA 还扩展到联合优化设置，交替进行 LoRA 参数更新和秩确定。", "result": "实验证明，SubLoRA 在求解偏微分方程（PDEs）的物理信息神经网络（PINNs）微调方面表现出有效性。结果显示，SubLoRA 在秩确定和联合训练性能方面均优于现有方法。", "conclusion": "SubLoRA 是一种新颖的秩确定方法，它结合了坚实的理论基础、二阶精度和实际计算效率，显著提高了低秩适应的性能。", "translation": "在本文中，我们提出了 SubLoRA，一种基于次模函数最大化的低秩适应（LoRA）秩确定方法。与以往依赖损失函数一阶（线性化）近似的方法（如 AdaLoRA）不同，SubLoRA 利用二阶信息通过结合 Hessian 矩阵来捕捉潜在复杂的损失景观。我们表明，当 LoRA 参数经过良好优化后，线性化变得不准确且病态，这促使人们需要一种更可靠和细致的二阶公式。为此，我们将秩确定问题重新表述为一个具有二次目标函数的组合优化问题。然而，一般情况下精确求解此问题是 NP-hard 的。为了克服计算挑战，我们引入了一个次模函数最大化框架，并设计了一个具有近似保证的贪婪算法。我们推导了一个充分必要条件，在该条件下秩确定目标变为次模，并构建了一个 Hessian 矩阵的闭合形式投影，该投影满足此条件同时保持计算效率。我们的方法结合了坚实的理论基础、二阶精度和实际计算效率。我们进一步将 SubLoRA 扩展到联合优化设置，在秩预算约束下交替进行 LoRA 参数更新和秩确定。在求解偏微分方程（PDEs）的物理信息神经网络（PINNs）微调方面的大量实验证明了我们方法的有效性。结果表明，SubLoRA 在秩确定和联合训练性能方面均优于现有方法。", "summary": "本文提出了一种名为 SubLoRA 的新型方法，用于低秩适应（LoRA）中的自动秩确定。该方法通过结合 Hessian 矩阵利用二阶信息和次模函数最大化，克服了现有方法中一阶近似的不准确性。SubLoRA 将秩确定问题重新表述为组合优化问题，并通过设计一个基于次模条件和 Hessian 投影的贪婪算法来高效求解。在物理信息神经网络（PINNs）的微调实验中，SubLoRA 在秩确定和整体训练性能方面均优于现有方法。", "keywords": "低秩适应, 秩确定, 次模函数最大化, 二阶优化, Hessian 矩阵", "comments": "SubLoRA 的创新之处在于它将二阶信息和次模优化引入到 LoRA 秩确定中，解决了现有方法一阶近似的局限性。其坚实的理论基础、近似保证以及在 PINNs 上的有效性展示了其在提高神经网络低秩适应鲁棒性和准确性方面的重要性。"}}
{"id": "2507.01712", "title": "Using Wavelet Domain Fingerprints to Improve Source Camera Identification", "authors": ["Xinle Tian", "Matthew Nunes", "Emiko Dupont", "Shaunagh Downing", "Freddie Lichtenstein", "Matt Burns"], "summary": "Camera fingerprint detection plays a crucial role in source identification\nand image forensics, with wavelet denoising approaches proving to be\nparticularly effective in extracting sensor pattern noise (SPN). In this\narticle, we propose a modification to wavelet-based SPN extraction. Rather than\nconstructing the fingerprint as an image, we introduce the notion of a wavelet\ndomain fingerprint. This avoids the final inversion step of the denoising\nalgorithm and allows fingerprint comparisons to be made directly in the wavelet\ndomain. As such, our modification streamlines the extraction and comparison\nprocess. Experimental results on real-world datasets demonstrate that our\nmethod not only achieves higher detection accuracy but can also significantly\nimprove processing speed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01712v1", "categories": ["cs.CV", "eess.IV", "stat.AP"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01712v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "使用小波域指纹改进源相机识别", "tldr": "本文提出了一种新的小波域指纹方法，用于源相机识别。该方法避免了传统小波去噪算法的最终反演步骤，直接在小波域进行指纹比较，从而提高了检测精度并显著加快了处理速度。", "motivation": "相机指纹检测在源识别和图像取证中至关重要，而小波去噪方法在提取传感器模式噪声（SPN）方面已被证明特别有效。现有方法在构建指纹时需要一个最终的反演步骤，这增加了复杂性。", "method": "本文提出了一种对基于小波的SPN提取方法的修改。不同于将指纹构建为图像，我们引入了小波域指纹的概念。这种方法避免了去噪算法的最终反演步骤，并允许指纹比较直接在小波域中进行。", "result": "实验结果表明，我们的方法不仅实现了更高的检测精度，而且显著提高了处理速度。", "conclusion": "通过引入小波域指纹并直接在小波域进行比较，可以有效改进源相机识别的准确性和效率。", "translation": "相机指纹检测在源识别和图像取证中扮演着至关重要的角色，其中小波去噪方法在提取传感器模式噪声（SPN）方面被证明特别有效。在本文中，我们提出了一种对基于小波的SPN提取方法的修改。不同于将指纹构建为图像，我们引入了小波域指纹的概念。这避免了去噪算法的最终反演步骤，并允许指纹比较直接在小波域中进行。因此，我们的修改简化了提取和比较过程。在真实世界数据集上的实验结果表明，我们的方法不仅实现了更高的检测精度，而且可以显著提高处理速度。", "summary": "本论文提出了一种改进的源相机识别方法，通过引入“小波域指纹”来优化传感器模式噪声（SPN）的提取和比较过程。与传统方法不同，该方法避免了小波去噪算法中将指纹图像化的最终反演步骤，允许直接在小波域进行指纹比较，从而简化了流程。实验结果表明，该方法在提高检测准确性的同时，也显著提升了处理速度。", "keywords": "相机识别, 小波域指纹, 传感器模式噪声, 图像取证, 图像去噪", "comments": "该论文的创新点在于提出了“小波域指纹”的概念，并实现了指纹的直接小波域比较，从而避免了传统方法中耗时的反演步骤。这不仅提高了相机源识别的精度，也显著提升了计算效率，对于图像取证领域具有重要意义。"}}
{"id": "2507.01594", "title": "Emotionally Intelligent Task-oriented Dialogue Systems: Architecture, Representation, and Optimisation", "authors": ["Shutong Feng", "Hsien-chin Lin", "Nurul Lubis", "Carel van Niekerk", "Michael Heck", "Benjamin Ruppik", "Renato Vukovic", "Milica Gašić"], "summary": "Task-oriented dialogue (ToD) systems are designed to help users achieve\nspecific goals through natural language interaction. While recent advances in\nlarge language models (LLMs) have significantly improved linguistic fluency and\ncontextual understanding, building effective and emotionally intelligent ToD\nsystems remains a complex challenge. Effective ToD systems must optimise for\ntask success, emotional understanding and responsiveness, and precise\ninformation conveyance, all within inherently noisy and ambiguous\nconversational environments. In this work, we investigate architectural,\nrepresentational, optimisational as well as emotional considerations of ToD\nsystems. We set up systems covering these design considerations with a\nchallenging evaluation environment composed of a natural-language user\nsimulator coupled with an imperfect natural language understanding module. We\npropose \\textbf{LUSTER}, an \\textbf{L}LM-based \\textbf{U}nified \\textbf{S}ystem\nfor \\textbf{T}ask-oriented dialogue with \\textbf{E}nd-to-end\n\\textbf{R}einforcement learning with both short-term (user sentiment) and\nlong-term (task success) rewards. Our findings demonstrate that combining LLM\ncapability with structured reward modelling leads to more resilient and\nemotionally responsive ToD systems, offering a practical path forward for\nnext-generation conversational agents.", "comment": "19 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.01594v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01594v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "情感智能任务型对话系统：架构、表示和优化", "tldr": "本文提出LUSTER，一个基于LLM的端到端强化学习系统，用于构建更具韧性和情感响应能力的任务型对话系统。", "motivation": "尽管大型语言模型（LLMs）显著提高了语言流畅性和上下文理解能力，但构建有效且情感智能的任务型对话（ToD）系统仍然是一个复杂的挑战。有效的ToD系统需要在固有的嘈杂和模糊的对话环境中优化任务成功、情感理解和响应以及精确的信息传递。", "method": "研究了ToD系统的架构、表示、优化以及情感因素。构建了包含这些设计考虑的系统，并在一个具有挑战性的评估环境中进行测试，该环境由自然语言用户模拟器和不完善的自然语言理解模块组成。提出了LUSTER，一个基于LLM的统一系统，用于通过结合短期（用户情绪）和长期（任务成功）奖励的端到端强化学习实现任务型对话。", "result": "结合LLM能力与结构化奖励建模能够产生更具韧性和情感响应能力的ToD系统。", "conclusion": "结合LLM能力与结构化奖励建模为构建下一代会话代理提供了实用的前进路径。", "translation": "任务型对话（ToD）系统旨在通过自然语言交互帮助用户实现特定目标。尽管大型语言模型（LLM）的最新进展显著提高了语言流畅性和上下文理解能力，但构建有效且情感智能的ToD系统仍然是一个复杂的挑战。有效的ToD系统必须在固有的嘈杂和模糊的对话环境中优化任务成功、情感理解和响应以及精确的信息传递。在这项工作中，我们研究了ToD系统的架构、表示、优化以及情感考虑。我们构建了涵盖这些设计考虑的系统，并设置了一个具有挑战性的评估环境，该环境由自然语言用户模拟器和一个不完善的自然语言理解模块组成。我们提出了\\textbf{LUSTER}，一个\\textbf{L}LM-based \\textbf{U}nified \\textbf{S}ystem for \\textbf{T}ask-oriented dialogue with \\textbf{E}nd-to-end \\textbf{R}einforcement learning，结合了短期（用户情绪）和长期（任务成功）奖励。我们的研究结果表明，将LLM能力与结构化奖励建模相结合可以产生更具韧性和情感响应能力的ToD系统，为下一代会话代理提供了实用的前进路径。", "summary": "本文探讨了构建情感智能任务型对话（ToD）系统的挑战，特别是在架构、表示和优化方面。研究人员提出了LUSTER，一个基于大型语言模型（LLM）的统一系统，它利用端到端强化学习，结合短期（用户情绪）和长期（任务成功）奖励。通过在模拟环境中评估，研究发现将LLM能力与结构化奖励建模相结合，可以显著提高ToD系统的韧性和情感响应能力，为未来会话代理的发展提供了可行方案。", "keywords": "任务型对话系统, 情感智能, 大型语言模型, 强化学习, LUSTER", "comments": "这篇论文的创新点在于提出了LUSTER系统，它将大型语言模型（LLM）的强大能力与结构化奖励建模（包括短期用户情绪和长期任务成功）相结合，通过端到端强化学习来优化任务型对话系统。这为构建更具人类交互特性的情感智能对话系统提供了新的方向，解决了现有ToD系统在情感理解和响应方面的不足。其重要性在于为下一代会话代理的发展提供了一个实际可行的框架。"}}
{"id": "2211.12120", "title": "Thermodynamically extended symplectic numerical simulation of viscoelastic, thermal expansion and heat conduction phenomena in solids", "authors": ["Donát M. Takács", "Áron Pozsár", "Tamás Fülöp"], "summary": "Symplectic numerical schemes for reversible dynamical systems predict the\nsolution reliably over large times as well, and are a good starting point for\nextension to schemes for simulating irreversible situations like viscoelastic\nwave propagation and heat conduction coupled via thermal expansion occuring in\nrocks, plastics, biological samples etc. Dissipation error (artificial\nnonpreservation of energies and amplitudes) of the numerical solution should be\nas small as possible since it should not be confused with the real dissipation\noccuring in the irreversible system. In addition, the other well-known\nnumerical artefact, dispersion error (artificial oscillations emerging at sharp\nchanges), should also be minimal to avoid confusion with the true wavy\nbehaviour. The continuum thermodynamical aspects (respect for balances with\nfluxes, systematic constitutive relationships between intensive quantities and\nfluxes, the second law of thermodynamics with positive definite entropy\nproduction, and the spacetime-based kinematic viewpoint) prove valuable for\nobtaining such extended schemes and for monitoring the solutions. Generalizing\nearlier works in this direction, here, we establish and investigate such a\nnumerical scheme for one-dimensional viscoelastic wave propagation in the\npresence of heat conduction coupled via thermal expansion, demonstrating\nlong-term reliability and the applicability of thermodynamics-based quantities\nin supervising the quality of the solution.", "comment": "13 pages, 7 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2211.12120v2", "categories": ["physics.class-ph", "cs.NA", "math.NA"], "cate": "physics.class-ph", "url": "http://arxiv.org/abs/2211.12120v2", "date": "2022-11-22", "updated": "2023-10-26", "AI": {"title_translation": "固体中粘弹性、热膨胀和热传导现象的热力学扩展辛数值模拟", "tldr": "本文提出了一种热力学扩展的辛数值方案，用于模拟固体中粘弹性波传播和热传导，证明了其长期可靠性并利用热力学量监督解的质量。", "motivation": "现有的可逆动力系统辛数值方案在模拟粘弹性波传播和热传导等不可逆现象时存在局限性，需要扩展。同时，为了避免混淆真实耗散和波动行为，需要最小化数值解的耗散误差和色散误差。", "method": "本文基于连续介质热力学原理，建立并研究了一种用于一维粘弹性波传播的数值方案，该方案考虑了通过热膨胀耦合的热传导。", "result": "该方案在模拟中表现出长期可靠性，并且热力学量在监督解的质量方面显示出适用性。", "conclusion": "热力学扩展的辛数值方案能够可靠地模拟固体中的粘弹性、热膨胀和热传导现象，并且利用热力学量可以有效监督解的质量。", "translation": "可逆动力系统的辛数值方案能够在大时间范围内可靠地预测解，是扩展到模拟不可逆情况（如岩石、塑料、生物样本等中通过热膨胀耦合的粘弹性波传播和热传导）的良好起点。数值解的耗散误差（能量和振幅的人为非守恒）应尽可能小，因为它不应与不可逆系统中发生的真实耗散混淆。此外，另一个众所周知的数值伪影，色散误差（在急剧变化处出现的假振荡），也应最小化，以避免与真实的波动行为混淆。连续介质热力学方面（遵守通量平衡、内含量和通量之间的系统本构关系、具有正定熵产生的热力学第二定律以及基于时空的运动学观点）证明对于获得此类扩展方案和监测解具有价值。在这一方向上概括了早期工作，本文建立并研究了在存在通过热膨胀耦合的热传导情况下的一维粘弹性波传播的这种数值方案，展示了长期可靠性以及基于热力学量的适用性来监督解的质量。", "summary": "本文提出了一种热力学扩展的辛数值方案，用于模拟固体中通过热膨胀耦合的粘弹性波传播和热传导现象。该方案旨在将可逆系统的辛方法扩展到不可逆过程，并最大限度地减少数值耗散和色散误差。研究结果表明，该方案具有长期可靠性，并且利用连续介质热力学原理可以有效地监督数值解的质量。", "keywords": "辛数值模拟, 粘弹性, 热传导, 热膨胀, 热力学", "comments": "本文的创新之处在于将辛数值模拟方法与连续介质热力学原理相结合，成功地将其应用于模拟固体中复杂的不可逆现象，如粘弹性、热膨胀和热传导。这种方法不仅保证了数值解的长期可靠性，还通过热力学量提供了对解质量的有效监控，对于解决多物理场耦合问题具有重要意义。"}}
{"id": "2507.01811", "title": "Towards Design and Development of a Concentric Tube Steerable Drilling Robot for Creating S-shape Tunnels for Pelvic Fixation Procedures", "authors": ["Yash Kulkarni", "Susheela Sharma", "Sarah Go", "Jordan P. Amadio", "Mohsen Khadem", "Farshid Alambeigi"], "summary": "Current pelvic fixation techniques rely on rigid drilling tools, which\ninherently constrain the placement of rigid medical screws in the complex\nanatomy of pelvis. These constraints prevent medical screws from following\nanatomically optimal pathways and force clinicians to fixate screws in linear\ntrajectories. This suboptimal approach, combined with the unnatural placement\nof the excessively long screws, lead to complications such as screw\nmisplacement, extended surgery times, and increased radiation exposure due to\nrepeated X-ray images taken ensure to safety of procedure. To address these\nchallenges, in this paper, we present the design and development of a unique 4\ndegree-of-freedom (DoF) pelvic concentric tube steerable drilling robot (pelvic\nCT-SDR). The pelvic CT-SDR is capable of creating long S-shaped drilling\ntrajectories that follow the natural curvatures of the pelvic anatomy. The\nperformance of the pelvic CT-SDR was thoroughly evaluated through several\nS-shape drilling experiments in simulated bone phantoms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01811v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01811v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "用于骨盆固定手术S形隧道创建的同心管可转向钻孔机器人的设计与开发", "tldr": "本文设计并开发了一种可转向的同心管钻孔机器人，用于骨盆固定手术中创建S形隧道，以克服现有刚性工具的局限性，提高手术精度和患者安全性。", "motivation": "现有的骨盆固定技术依赖于刚性钻孔工具，这导致了螺钉放置受限、无法遵循最佳解剖路径，进而引发螺钉错位、手术时间延长和辐射暴露增加等并发症。", "method": "本文设计并开发了一种独特的4自由度骨盆同心管可转向钻孔机器人（pelvic CT-SDR），该机器人能够创建遵循骨盆解剖学自然弯曲的长S形钻孔轨迹。", "result": "该骨盆CT-SDR能够创建长的S形钻孔轨迹，并在模拟骨骼模型中通过多项S形钻孔实验对其性能进行了全面评估。", "conclusion": "Not mentioned in abstract", "translation": "当前的骨盆固定技术依赖于刚性钻孔工具，这本身限制了刚性医用螺钉在骨盆复杂解剖结构中的放置。这些限制使得医用螺钉无法遵循解剖学上的最佳路径，并迫使临床医生以直线轨迹固定螺钉。这种次优方法，加上过长螺钉的不自然放置，导致了螺钉错位、手术时间延长以及由于为确保手术安全而重复拍摄X射线图像导致的辐射暴露增加等并发症。为了解决这些挑战，本文介绍了独特的4自由度骨盆同心管可转向钻孔机器人（pelvic CT-SDR）的设计和开发。该骨盆CT-SDR能够创建遵循骨盆解剖学自然弯曲的长S形钻孔轨迹。通过在模拟骨骼模型中进行的几次S形钻孔实验，对骨盆CT-SDR的性能进行了全面评估。", "summary": "本文针对现有骨盆固定技术中刚性钻孔工具导致的螺钉放置受限及相关并发症，提出并设计了一种4自由度骨盆同心管可转向钻孔机器人（pelvic CT-SDR）。该机器人能够创建遵循骨盆自然弯曲的S形钻孔轨迹，并在模拟骨骼模型中验证了其性能，旨在提供更精确、安全的骨盆固定解决方案。", "keywords": "骨盆固定, 可转向机器人, 同心管, S形钻孔, 医疗机器人", "comments": "这项研究提出了一种创新的机器人解决方案，通过引入可转向的同心管设计，克服了传统刚性钻孔工具在复杂骨盆解剖结构中进行S形路径钻孔的局限性。其潜在重要性在于能够实现更符合解剖学原理的螺钉固定，从而减少手术并发症、缩短手术时间并降低辐射暴露。"}}
{"id": "2507.01321", "title": "ICLShield: Exploring and Mitigating In-Context Learning Backdoor Attacks", "authors": ["Zhiyao Ren", "Siyuan Liang", "Aishan Liu", "Dacheng Tao"], "summary": "In-context learning (ICL) has demonstrated remarkable success in large\nlanguage models (LLMs) due to its adaptability and parameter-free nature.\nHowever, it also introduces a critical vulnerability to backdoor attacks, where\nadversaries can manipulate LLM behaviors by simply poisoning a few ICL\ndemonstrations. In this paper, we propose, for the first time, the\ndual-learning hypothesis, which posits that LLMs simultaneously learn both the\ntask-relevant latent concepts and backdoor latent concepts within poisoned\ndemonstrations, jointly influencing the probability of model outputs. Through\ntheoretical analysis, we derive an upper bound for ICL backdoor effects,\nrevealing that the vulnerability is dominated by the concept preference ratio\nbetween the task and the backdoor. Motivated by these findings, we propose\nICLShield, a defense mechanism that dynamically adjusts the concept preference\nratio. Our method encourages LLMs to select clean demonstrations during the ICL\nphase by leveraging confidence and similarity scores, effectively mitigating\nsusceptibility to backdoor attacks. Extensive experiments across multiple LLMs\nand tasks demonstrate that our method achieves state-of-the-art defense\neffectiveness, significantly outperforming existing approaches (+26.02% on\naverage). Furthermore, our method exhibits exceptional adaptability and\ndefensive performance even for closed-source models (e.g., GPT-4).", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.01321v1", "categories": ["cs.LG", "cs.AI", "cs.CR"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01321v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "ICLShield：探索和缓解上下文学习后门攻击", "tldr": "ICL在LLM中很成功但易受后门攻击。本文首次提出双重学习假设，揭示了任务和后门概念偏好比对漏洞的影响，并基于此提出了ICLShield防御机制，通过动态调整概念偏好比来选择干净的演示，有效缓解了后门攻击，实现了SOTA性能。", "motivation": "上下文学习（ICL）在大型语言模型（LLM）中取得了显著成功，但它也引入了对后门攻击的关键漏洞，攻击者可以通过毒化少量ICL演示来操纵LLM行为。", "method": "本文首次提出了双重学习假设，认为LLM在被毒化的演示中同时学习任务相关和后门潜在概念。通过理论分析，推导出ICL后门效应的上限，揭示漏洞受任务与后门之间的概念偏好比主导。基于这些发现，提出了ICLShield防御机制，该机制通过动态调整概念偏好比，利用置信度和相似度分数鼓励LLM在ICL阶段选择干净的演示。", "result": "ICLShield在多个LLM和任务上实现了最先进的防御效果，显著优于现有方法（平均提高26.02%）。该方法对闭源模型（例如GPT-4）也表现出卓越的适应性和防御性能。", "conclusion": "本文提出的ICLShield通过动态调整概念偏好比，成功缓解了大型语言模型中上下文学习面临的后门攻击脆弱性，并在各种模型和任务上展示了其优越的防御性能和广泛的适应性。", "translation": "上下文学习（ICL）因其适应性和无参数特性，在大型语言模型（LLM）中取得了显著成功。然而，它也引入了对后门攻击的关键漏洞，攻击者只需通过毒化少量ICL演示即可操纵LLM行为。本文首次提出了双重学习假设，该假设认为LLM在被毒化的演示中同时学习任务相关的潜在概念和后门潜在概念，共同影响模型输出的概率。通过理论分析，我们推导了ICL后门效应的上限，揭示了这种漏洞主要受任务和后门之间的概念偏好比支配。受这些发现的启发，我们提出了ICLShield，一种动态调整概念偏好比的防御机制。我们的方法通过利用置信度和相似度分数，鼓励LLM在ICL阶段选择干净的演示，从而有效缓解对后门攻击的敏感性。在多个LLM和任务上的大量实验表明，我们的方法实现了最先进的防御效果，显著优于现有方法（平均提高26.02%）。此外，我们的方法即使对于闭源模型（例如GPT-4）也表现出卓越的适应性和防御性能。", "summary": "本文针对大型语言模型中上下文学习（ICL）面临的后门攻击漏洞，首次提出了双重学习假设，阐明了任务和后门概念共同影响模型输出的机制。基于此理论，论文设计并提出了ICLShield防御机制，该机制通过动态调整概念偏好比，并利用置信度和相似度分数，引导模型在ICL阶段优先选择干净的演示，从而有效抵御后门攻击。实验证明，ICLShield在多种LLM和任务上均取得了SOTA的防御效果，甚至对闭源模型也表现出优异的适应性。", "keywords": "上下文学习, 后门攻击, 大型语言模型, ICLShield, 双重学习假设", "comments": "这篇论文通过引入“双重学习假设”为理解ICL后门攻击提供了新的理论视角，并在此基础上提出了一个新颖且有效的防御机制ICLShield。其创新性在于从理论层面揭示了漏洞的本质，并设计出一种能够动态调整模型概念偏好的防御策略。实验结果表明其在性能上显著优于现有方法，并且对闭源模型也有效，这对于LLM的安全应用具有重要意义。"}}
{"id": "2507.01397", "title": "Coherent Online Road Topology Estimation and Reasoning with Standard-Definition Maps", "authors": ["Khanh Son Pham", "Christian Witte", "Jens Behley", "Johannes Betz", "Cyrill Stachniss"], "summary": "Most autonomous cars rely on the availability of high-definition (HD) maps.\nCurrent research aims to address this constraint by directly predicting HD map\nelements from onboard sensors and reasoning about the relationships between the\npredicted map and traffic elements. Despite recent advancements, the coherent\nonline construction of HD maps remains a challenging endeavor, as it\nnecessitates modeling the high complexity of road topologies in a unified and\nconsistent manner. To address this challenge, we propose a coherent approach to\npredict lane segments and their corresponding topology, as well as road\nboundaries, all by leveraging prior map information represented by commonly\navailable standard-definition (SD) maps. We propose a network architecture,\nwhich leverages hybrid lane segment encodings comprising prior information and\ndenoising techniques to enhance training stability and performance.\nFurthermore, we facilitate past frames for temporal consistency. Our\nexperimental evaluation demonstrates that our approach outperforms previous\nmethods by a large margin, highlighting the benefits of our modeling scheme.", "comment": "Accepted at IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.01397v1", "categories": ["cs.CV", "cs.LG"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01397v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于标清地图的连贯在线道路拓扑估计与推理", "tldr": "提出一种利用标清地图信息进行在线连贯高精地图构建的方法，通过混合车道段编码和时序一致性，显著优于现有方法。", "motivation": "大多数自动驾驶汽车依赖高精（HD）地图的可用性，但高精地图的连贯在线构建仍然是一项挑战，因为它需要以统一和一致的方式建模道路拓扑的高度复杂性。", "method": "提出一种连贯的方法，利用标准清晰度（SD）地图的先验信息来预测车道段及其拓扑结构以及道路边界。该方法采用一种网络架构，利用包含先验信息和去噪技术的混合车道段编码来增强训练稳定性和性能，并通过利用过去帧来促进时间一致性。", "result": "实验评估表明，该方法在性能上大幅超越了以前的方法，突出了其建模方案的优势。", "conclusion": "通过结合标清地图的先验信息、混合编码和时序一致性，可以有效地实现道路拓扑的连贯在线估计和推理，从而克服高精地图构建的挑战。", "translation": "大多数自动驾驶汽车依赖高精（HD）地图的可用性。当前研究旨在通过直接从车载传感器预测高精地图元素并推理预测地图与交通元素之间的关系来解决这一限制。尽管最近取得了进展，但高精地图的连贯在线构建仍然是一项具有挑战性的工作，因为它需要以统一和一致的方式建模道路拓扑的高度复杂性。为了解决这一挑战，我们提出了一种连贯的方法来预测车道段及其相应的拓扑结构，以及道路边界，所有这些都通过利用常用标准清晰度（SD）地图所代表的先验地图信息来实现。我们提出了一种网络架构，该架构利用包含先验信息和去噪技术的混合车道段编码来增强训练稳定性和性能。此外，我们利用过去帧来促进时间一致性。我们的实验评估表明，我们的方法大幅优于以前的方法，突出了我们建模方案的优势。", "summary": "该论文提出了一种利用标准清晰度（SD）地图先验信息进行在线连贯道路拓扑估计和推理的新方法，旨在解决自动驾驶中高精（HD）地图在线构建的挑战。该方法通过一个新颖的网络架构，结合混合车道段编码（包含先验信息和去噪技术）和时间一致性处理，实现了对车道段、拓扑和道路边界的有效预测。实验结果表明，该方法在性能上显著优于现有技术。", "keywords": "道路拓扑估计, 在线构建, 标准清晰度地图, 高精地图, 自动驾驶", "comments": "该论文的创新点在于其提出了一种利用普遍可用的标清地图作为先验信息来辅助高精地图在线构建的策略，这对于降低自动驾驶对昂贵且难以维护的高精地图的依赖具有重要意义。通过混合编码和时序一致性等技术，提高了模型在复杂道路拓扑估计中的稳定性和性能，为实时高精地图的生成提供了一个有前景的方向。"}}
{"id": "2507.01054", "title": "XxaCT-NN: Structure Agnostic Multimodal Learning for Materials Science", "authors": ["Jithendaraa Subramanian", "Linda Hung", "Daniel Schweigert", "Santosh Suram", "Weike Ye"], "summary": "Recent advances in materials discovery have been driven by structure-based\nmodels, particularly those using crystal graphs. While effective for\ncomputational datasets, these models are impractical for real-world\napplications where atomic structures are often unknown or difficult to obtain.\nWe propose a scalable multimodal framework that learns directly from elemental\ncomposition and X-ray diffraction (XRD) -- two of the more available modalities\nin experimental workflows without requiring crystal structure input. Our\narchitecture integrates modality-specific encoders with a cross-attention\nfusion module and is trained on the 5-million-sample Alexandria dataset. We\npresent masked XRD modeling (MXM), and apply MXM and contrastive alignment as\nself-supervised pretraining strategies. Pretraining yields faster convergence\n(up to 4.2x speedup) and improves both accuracy and representation quality. We\nfurther demonstrate that multimodal performance scales more favorably with\ndataset size than unimodal baselines, with gains compounding at larger data\nregimes. Our results establish a path toward structure-free, experimentally\ngrounded foundation models for materials science.", "comment": "10 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.01054v1", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01054v1", "date": "2025-06-27", "updated": "2025-06-27", "AI": {"title_translation": "XxaCT-NN：材料科学中的结构无关多模态学习", "tldr": "本文提出了XxaCT-NN，一个面向材料科学的结构无关多模态框架，它直接从元素组成和X射线衍射（XRD）数据中学习，克服了传统结构模型在实际应用中的局限性。通过自监督预训练（MXM和对比对齐），模型实现了更快的收敛和更高的准确性，并且在大数据集下表现出优于单模态基线的良好扩展性。", "motivation": "当前的材料发现模型主要基于原子结构，对计算数据集有效，但在原子结构未知或难以获取的实际应用中不实用。因此，需要一种能够直接从更易获得的实验数据（如元素组成和X射线衍射）中学习的模型。", "method": "本文提出了XxaCT-NN多模态框架，该框架直接从元素组成和X射线衍射（XRD）中学习，无需晶体结构输入。其架构集成了模态特定的编码器和交叉注意力融合模块，并在500万样本的Alexandria数据集上进行训练。研究引入了掩蔽XRD建模（MXM）以及MXM和对比对齐作为自监督预训练策略。", "result": "预训练使收敛速度加快（最高达4.2倍），并提高了模型的准确性和表示质量。多模态性能随数据集规模的增加而比单模态基线表现出更有利的扩展性，且在更大规模数据下收益复合增长。", "conclusion": "本文的研究结果为材料科学中开发无结构、基于实验的基础模型奠定了基础。", "translation": "材料发现的最新进展一直由基于结构的模型推动，特别是那些使用晶体图的模型。虽然这些模型对计算数据集有效，但对于原子结构通常未知或难以获得的实际应用来说并不实用。我们提出了一种可扩展的多模态框架，该框架直接从元素组成和X射线衍射（XRD）中学习——这两种是在实验工作流程中更容易获得的模态，而无需晶体结构输入。我们的架构将模态特定的编码器与交叉注意力融合模块集成，并在500万样本的Alexandria数据集上进行训练。我们提出了掩蔽XRD建模（MXM），并将MXM和对比对齐作为自监督预训练策略。预训练带来了更快的收敛（高达4.2倍的加速），并提高了准确性和表示质量。我们进一步证明，多模态性能随数据集规模的增加而比单模态基线表现出更有利的扩展性，且在更大规模数据下收益复合增长。我们的结果为材料科学中无结构、基于实验的基础模型奠定了基础。", "summary": "XxaCT-NN是一种新颖的多模态学习框架，专为材料科学设计，旨在解决传统结构基模型在实际应用中对原子结构依赖的问题。该模型直接利用易于获取的元素组成和X射线衍射数据，通过集成模态特定编码器和交叉注意力融合模块，并在大型Alexandria数据集上进行训练。研究引入了掩蔽XRD建模（MXM）和对比对齐作为自监督预训练策略，显著提升了模型收敛速度、准确性和表示质量。实验结果表明，该多模态方法在数据规模增大时表现出优于单模态基线的扩展性，为开发不依赖结构、基于实验的材料科学基础模型开辟了道路。", "keywords": "多模态学习, 材料科学, X射线衍射, 自监督学习, 结构无关", "comments": "这篇论文解决了当前材料发现模型的一个重要实际局限性，提出了一种结构无关的方法。利用易于获取的实验数据（元素组成和XRD）使其与实际应用高度相关。引入自监督预训练策略（MXM、对比对齐）是关键创新，显著提高了训练效率和模型性能。随着数据集规模的增大，其表现出的良好扩展性也预示着其在大规模材料信息学中的巨大潜力。"}}
{"id": "2507.01636", "title": "Kernel Recursive Least Squares Dictionary Learning Algorithm", "authors": ["Ghasem Alipoor", "Karl Skretting"], "summary": "We propose an efficient online dictionary learning algorithm for kernel-based\nsparse representations. In this framework, input signals are nonlinearly mapped\nto a high-dimensional feature space and represented sparsely using a virtual\ndictionary. At each step, the dictionary is updated recursively using a novel\nalgorithm based on the recursive least squares (RLS) method. This update\nmechanism works with single samples or mini-batches and maintains low\ncomputational complexity. Experiments on four datasets across different domains\nshow that our method not only outperforms existing online kernel dictionary\nlearning approaches but also achieves classification accuracy close to that of\nbatch-trained models, while remaining significantly more efficient.", "comment": "Published in Digital Signal Processing, Volume 141, 2023. DOI:\n  https://doi.org/10.1016/j.dsp.2023.104159 12 pages, 8 figures. Code and data\n  available at: https://github.com/G-Alipoor/kernel-rls-dictionary-learning", "pdf_url": "http://arxiv.org/pdf/2507.01636v1", "categories": ["cs.LG", "eess.SP"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01636v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "核递归最小二乘字典学习算法", "tldr": "提出一种高效的在线核字典学习算法，基于递归最小二乘（RLS）方法递归更新字典，在性能和效率上均优于现有在线方法，并接近批处理模型。", "motivation": "为了解决现有在线核字典学习方法可能存在的效率或性能不足的问题，需要一种更高效、性能更好的在线字典学习算法。", "method": "本文提出了一种用于核基稀疏表示的高效在线字典学习算法。该框架将输入信号非线性映射到高维特征空间，并使用虚拟字典进行稀疏表示。字典通过一种基于递归最小二乘（RLS）方法的新颖算法进行递归更新，该机制支持单个样本或小批量处理，并保持较低的计算复杂度。", "result": "在四个不同领域的数据集上进行的实验表明，所提出的方法不仅优于现有的在线核字典学习方法，而且在分类精度上接近批处理训练模型，同时效率显著更高。", "conclusion": "本文提出的基于递归最小二乘（RLS）的在线核字典学习算法在性能和效率上表现出色，能够超越现有在线方法并达到接近批处理模型的分类精度。", "translation": "我们提出了一种高效的基于核的稀疏表示在线字典学习算法。在此框架中，输入信号被非线性映射到高维特征空间，并使用虚拟字典进行稀疏表示。在每一步中，字典都使用一种基于递归最小二乘（RLS）方法的新颖算法进行递归更新。这种更新机制适用于单个样本或小批量，并保持较低的计算复杂度。在四个不同领域的数据集上进行的实验表明，我们的方法不仅优于现有的在线核字典学习方法，而且实现了接近批处理训练模型的分类精度，同时效率显著更高。", "summary": "本文提出了一种高效的核递归最小二乘字典学习算法，用于基于核的稀疏表示。该算法将输入信号非线性映射到高维特征空间，并利用基于递归最小二乘（RLS）方法的新颖算法在线递归更新虚拟字典，支持单样本或小批量处理，并保持低计算复杂度。实验证明，该方法在性能上超越了现有在线核字典学习方法，同时在分类精度上接近批处理模型，且计算效率显著更高。", "keywords": "核字典学习, 递归最小二乘, 在线学习, 稀疏表示, 机器学习", "comments": "该论文的创新点在于将递归最小二乘（RLS）方法应用于核字典的在线更新，从而实现了高效且高性能的字典学习。其重要性在于提供了一种在保持低计算复杂度的同时，能与批处理模型性能相媲美的在线学习方案，这对于处理大规模或流式数据具有实际意义。"}}
{"id": "2507.01859", "title": "A hierarchical invariant for line bundles and its applications in algebraic geometry codes", "authors": ["Rahim Rahmati-asghar"], "summary": "We introduce the notion of hierarchical depth for line bundles on smooth\nprojective surfaces, defined via filtrations by line subbundles with successive\nquotients supported on effective divisors. This invariant helps to investigate\nboth the algebraic and geometric complexity of line bundles through discrete\nstepwise constructions. We study some of its basic properties, including\nfunctorial behavior under restriction to curves and compatibility with\nampleness and base-point freeness. Applying this framework to algebraic\ngeometry (AG) codes, we show that hierarchical filtrations yield natural code\nfamilies whose combinatorial parameters (dimension, minimum distance) evolve\npredictably across the filtration.", "comment": "All comments are welcome", "pdf_url": "http://arxiv.org/pdf/2507.01859v1", "categories": ["math.AG", "cs.IT", "math.AC", "math.IT", "14G50 (Primary) 14C20, 14H52 (Secondary)"], "cate": "math.AG", "url": "http://arxiv.org/abs/2507.01859v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "线丛的分层不变量及其在代数几何码中的应用", "tldr": "本文引入了光滑射影曲面上线丛的分层深度概念，并通过分层研究了其性质，并将其应用于代数几何码，发现分层可以产生参数可预测的码族。", "motivation": "本文引入分层深度这一不变量，旨在通过离散的逐步构造来研究线丛的代数和几何复杂性。", "method": "本文通过引入光滑射影曲线上线丛的分层深度概念，该深度通过线子丛的过滤定义，其连续商支持在有效除子上。研究了其基本性质，包括限制到曲线上时的函子行为以及与丰度和无基点的兼容性。并将此框架应用于代数几何（AG）码。", "result": "分层深度不变量有助于研究线丛的代数和几何复杂性。将此框架应用于代数几何（AG）码时，分层过滤产生了自然的代码族，其组合参数（维度、最小距离）在过滤过程中可预测地演变。", "conclusion": "分层深度为线丛提供了一个新的不变量，有助于深入理解其复杂性，并在代数几何码中展示了其应用潜力，能够生成参数可预测的码族。", "translation": "我们引入了光滑射影曲面上线丛的分层深度概念，该深度通过线子丛的过滤定义，其连续商支持在有效除子上。这个不变量有助于通过离散的逐步构造来研究线丛的代数和几何复杂性。我们研究了它的一些基本性质，包括限制到曲线上时的函子行为以及与丰度和无基点性的兼容性。将此框架应用于代数几何（AG）码，我们表明分层过滤产生了自然的码族，其组合参数（维度、最小距离）在过滤过程中可预测地演变。", "summary": "本文提出了一种用于光滑射影曲线上线丛的分层深度不变量，通过线子丛的过滤定义。该不变量旨在量化线丛的代数和几何复杂性。研究了其函子性、与丰度和无基点性的兼容性等基本性质。此外，将该框架应用于代数几何码，结果表明分层过滤可以生成参数（维度、最小距离）可预测的码族。", "keywords": "分层不变量, 线丛, 代数几何码, 过滤, 射影曲面", "comments": "本文的创新之处在于引入了“分层深度”这一新的线丛不变量，并将其成功应用于代数几何码，展示了其在生成参数可预测码族方面的潜力。这为理解线丛的复杂性和设计新的纠错码提供了新的视角和工具。"}}
{"id": "2507.01522", "title": "Chargax: A JAX Accelerated EV Charging Simulator", "authors": ["Koen Ponse", "Jan Felix Kleuker", "Aske Plaat", "Thomas Moerland"], "summary": "Deep Reinforcement Learning can play a key role in addressing sustainable\nenergy challenges. For instance, many grid systems are heavily congested,\nhighlighting the urgent need to enhance operational efficiency. However,\nreinforcement learning approaches have traditionally been slow due to the high\nsample complexity and expensive simulation requirements. While recent works\nhave effectively used GPUs to accelerate data generation by converting\nenvironments to JAX, these works have largely focussed on classical toy\nproblems. This paper introduces Chargax, a JAX-based environment for realistic\nsimulation of electric vehicle charging stations designed for accelerated\ntraining of RL agents. We validate our environment in a variety of scenarios\nbased on real data, comparing reinforcement learning agents against baselines.\nChargax delivers substantial computational performance improvements of over\n100x-1000x over existing environments. Additionally, Chargax' modular\narchitecture enables the representation of diverse real-world charging station\nconfigurations.", "comment": "Accepted at RLC 2025", "pdf_url": "http://arxiv.org/pdf/2507.01522v1", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01522v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "Chargax：一个JAX加速的电动汽车充电模拟器", "tldr": "Chargax是一个基于JAX的电动汽车充电模拟器，专为加速RL训练而设计，性能提升显著。", "motivation": "深度强化学习在解决可持续能源挑战中发挥关键作用，但传统强化学习方法因高样本复杂度和昂贵的模拟要求而速度缓慢，且现有JAX加速环境主要集中于玩具问题，缺乏现实场景模拟。", "method": "本文介绍了Chargax，一个基于JAX的电动汽车充电站现实模拟环境，旨在加速RL代理的训练。它采用模块化架构以表示多样化的真实世界充电站配置，并根据真实数据在各种场景中进行验证，将强化学习代理与基线进行比较。", "result": "Chargax比现有环境提供了100到1000倍以上的显著计算性能改进。它还能表示多样化的真实世界充电站配置，并在基于真实数据的多种场景中得到验证。", "conclusion": "Chargax提供了一个高效、灵活且逼真的电动汽车充电模拟环境，显著加速了RL代理的训练，有助于解决能源效率挑战。", "translation": "深度强化学习在解决可持续能源挑战中发挥着关键作用。例如，许多电网系统严重拥堵，这凸显了提高运营效率的迫切需求。然而，由于高样本复杂度和昂贵的模拟要求，强化学习方法传统上速度较慢。尽管最近的工作通过将环境转换为JAX有效地利用了GPU来加速数据生成，但这些工作主要集中在经典的玩具问题上。本文介绍了Chargax，一个基于JAX的电动汽车充电站现实模拟环境，旨在加速RL代理的训练。我们根据真实数据在各种场景中验证了我们的环境，并将强化学习代理与基线进行了比较。Chargax比现有环境提供了100到1000倍以上的显著计算性能改进。此外，Chargax的模块化架构能够表示多样化的真实世界充电站配置。", "summary": "本文介绍了Chargax，一个基于JAX的电动汽车充电站模拟环境，旨在解决传统强化学习在能源管理中面临的慢速和非现实模拟问题。Chargax专注于加速RL代理的训练，并能够模拟真实的充电站配置。实验结果表明，Chargax比现有环境在计算性能上实现了100到1000倍的显著提升，并且已通过真实数据在多种场景下得到验证。", "keywords": "电动汽车充电, JAX, 强化学习, 模拟, 能源管理", "comments": "Chargax的创新之处在于将JAX的加速能力应用于现实世界的电动汽车充电模拟，显著克服了传统RL训练的计算瓶颈。其模块化设计也增强了环境的通用性和实用性，对于推动深度强化学习在智能电网和可持续能源管理领域的应用具有重要意义。"}}
{"id": "2507.01627", "title": "Chart Question Answering from Real-World Analytical Narratives", "authors": ["Maeve Hutchinson", "Radu Jianu", "Aidan Slingsby", "Jo Wood", "Pranava Madhyastha"], "summary": "We present a new dataset for chart question answering (CQA) constructed from\nvisualization notebooks. The dataset features real-world, multi-view charts\npaired with natural language questions grounded in analytical narratives.\nUnlike prior benchmarks, our data reflects ecologically valid reasoning\nworkflows. Benchmarking state-of-the-art multimodal large language models\nreveals a significant performance gap, with GPT-4.1 achieving an accuracy of\n69.3%, underscoring the challenges posed by this more authentic CQA setting.", "comment": "This paper has been accepted to the ACL Student Research Workshop\n  (SRW) 2025", "pdf_url": "http://arxiv.org/pdf/2507.01627v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01627v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "图表问答：基于真实世界分析叙述", "tldr": "本文提出了一个从可视化笔记本构建的真实世界多视图图表问答数据集，并发现当前SOTA多模态大模型在此真实场景下表现不佳，存在显著性能差距。", "motivation": "现有的图表问答基准未能反映真实的推理工作流程，因此需要一个更具生态有效性的数据集来评估模型在真实世界分析叙述中的CQA能力。", "method": "构建了一个新的图表问答（CQA）数据集，该数据集包含来自可视化笔记本的真实世界、多视图图表和基于分析叙述的自然语言问题。然后，使用该数据集对最先进的多模态大型语言模型进行了基准测试。", "result": "基准测试显示，最先进的多模态大型语言模型（如GPT-4.1）在此真实CQA设置中存在显著的性能差距，其中GPT-4.1的准确率为69.3%。", "conclusion": "真实世界的图表问答场景对当前最先进的多模态大模型提出了显著挑战，表明需要进一步的研究和改进。", "translation": "我们提出了一个从可视化笔记本构建的新的图表问答（CQA）数据集。该数据集的特点是真实世界、多视图图表与基于分析叙述的自然语言问题配对。与之前的基准不同，我们的数据反映了生态学上有效的推理工作流程。对最先进的多模态大型语言模型进行基准测试揭示了显著的性能差距，GPT-4.1的准确率为69.3%，这凸显了这种更真实的CQA设置所带来的挑战。", "summary": "该论文介绍了一个新的图表问答（CQA）数据集，该数据集来源于真实世界的可视化笔记本，包含多视图图表和基于分析叙述的自然语言问题。该数据集旨在反映实际的推理工作流程，与现有基准不同。通过对最先进的多模态大型语言模型进行基准测试，研究发现这些模型在真实CQA场景中表现不佳，例如GPT-4.1的准确率仅为69.3%，这表明该领域仍面临重大挑战。", "keywords": "图表问答, 数据集, 多模态大型语言模型, 真实世界, 分析叙述", "comments": "这项工作的创新之处在于构建了一个更贴近真实世界分析叙述的图表问答数据集，填补了现有基准在生态有效性方面的空白。它揭示了当前SOTA多模态LLM在处理复杂、真实CQA任务时的局限性，为未来研究指明了方向，即需要开发更强大的模型来应对此类挑战。"}}
{"id": "2507.01399", "title": "Reconstruction of the observable universe from the integrated Sachs-Wolfe effect", "authors": ["Julianne Chung", "Yiran Wang"], "summary": "The integrated Sachs-Wolfe (ISW) effect is a property of the Cosmic Microwave\nBackground (CMB), in which photons from the CMB are gravitationally redshifted,\ncausing the anisotropies in the CMB. An intriguing question is whether one can\ninfer the gravitational perturbations from the ISW effect observed near the\nEarth. In this work, we address the question using a tomographic reconstruction\napproach, similar to X-ray CT reconstruction in medical imaging. We develop the\nmathematical analysis for the stable inversion of the X-ray transform in the\ncosmological setting. In addition, we provide a numerical study of\nreconstruction methods, thereby demonstrating the feasibility and potential of\nthe tomography method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01399v1", "categories": ["math-ph", "cs.NA", "math.MP", "math.NA"], "cate": "math-ph", "url": "http://arxiv.org/abs/2507.01399v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "从积分Sachs-Wolfe效应重建可观测宇宙", "tldr": "本文提出并验证了一种类似X射线CT的层析成像方法，用于从积分Sachs-Wolfe效应重建宇宙中的引力扰动，证明了该方法的可行性和潜力。", "motivation": "探究是否能从地球附近观测到的积分Sachs-Wolfe (ISW) 效应推断引力扰动。", "method": "采用类似于医学成像中X射线CT重建的层析成像方法。发展了宇宙学背景下X射线变换稳定反演的数学分析，并进行了重建方法的数值研究。", "result": "证明了该层析成像方法的可行性和潜力。", "conclusion": "通过数学分析和数值研究，证实了利用层析成像方法从ISW效应重建宇宙引力扰动的可行性和潜力。", "translation": "积分Sachs-Wolfe (ISW) 效应是宇宙微波背景 (CMB) 的一种特性，其中来自CMB的光子因引力红移而导致CMB中的各向异性。一个有趣的问题是，是否可以从地球附近观测到的ISW效应推断出引力扰动。在这项工作中，我们使用一种层析重建方法来解决这个问题，类似于医学成像中的X射线CT重建。我们为宇宙学背景下X射线变换的稳定反演开发了数学分析。此外，我们对重建方法进行了数值研究，从而证明了层析成像方法的可行性和潜力。", "summary": "本文探讨了如何利用宇宙微波背景中的积分Sachs-Wolfe (ISW) 效应来重建宇宙中的引力扰动。研究团队提出并应用了一种类似于医学X射线CT的层析成像重建方法。他们为此开发了宇宙学背景下的X射线变换稳定反演的数学理论，并通过数值研究验证了该方法的有效性和潜力，为从CMB数据推断宇宙结构提供了新途径。", "keywords": "积分Sachs-Wolfe效应, 宇宙微波背景, 引力扰动, 层析重建, X射线变换", "comments": "该论文创新性地将医学成像中的X射线CT重建技术应用于宇宙学领域，以从积分Sachs-Wolfe效应重建宇宙引力扰动。这种跨学科的方法为宇宙学观测数据的解释提供了新的工具和视角，特别是证明了其在宇宙尺度上进行层析成像的可行性，具有重要的理论和实践意义。"}}
{"id": "2507.01843", "title": "MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics", "authors": ["Dmytro Kuzmenko", "Nadiya Shvai"], "summary": "Mixture-of-Experts (MoE) approaches have recently gained traction in robotics\napplications due to their ability to dynamically allocate computational\nresources and specialize sub-networks for distinct tasks or environmental\ncontexts, enabling more efficient decision-making. Such systems often comprise\nsparsely activated experts combined under a single monolithic architecture and\nrequire a well-configured internal routing mechanism, which does not allow for\nselective low-level expert and router customization and requires additional\ntraining. We propose MoIRA, an architecture-agnostic modular MoE framework\ndesigned to coordinate existing experts with an external text-based router.\nMoIRA incorporates two zero-shot routing options: embedding-based similarity\nand prompt-driven language model inference. In our experiments, we choose large\nVision-Language-Action models, gr00t-N1 and $\\pi_0$, as the underlying experts,\nand train low-rank adapters for low-overhead inference. We evaluate MoIRA on\nvarious GR1 Humanoid tasks and LIBERO Spatial and Goal benchmarks, where it\nconsistently outperforms generalist models and competes with other MoE\npipelines. Additionally, we analyse the robustness of the proposed approach to\nthe variations of the instructions. While relying solely on textual\ndescriptions of tasks and experts, MoIRA demonstrates the practical viability\nof modular deployment with precise, low-effort routing and provides an\nalternative, scalable foundation for future multi-expert robotic systems.", "comment": "Preprint of a manuscript submitted for peer review", "pdf_url": "http://arxiv.org/pdf/2507.01843v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01843v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "MoIRA：多任务机器人模块化指令路由架构", "tldr": "MoIRA是一个模块化混合专家（MoE）框架，通过外部文本路由器协调现有专家，实现多任务机器人系统中精确、低成本的指令路由，优于通用模型。", "motivation": "现有混合专家（MoE）方法在机器人应用中虽然能动态分配资源和专业化子网络，但通常是单一架构，需要配置内部路由机制，且不允许选择性地定制低级专家和路由器，还需要额外训练。因此，需要一种更灵活、可定制的MoE框架。", "method": "我们提出了MoIRA，一个与架构无关的模块化混合专家（MoE）框架，旨在通过外部文本路由器协调现有专家。MoIRA集成了两种零样本路由选项：基于嵌入的相似性和提示驱动的语言模型推理。实验中，选择大型视觉-语言-动作模型（gr00t-N1和π0）作为底层专家，并训练低秩适配器以实现低开销推理。", "result": "MoIRA在各种GR1人形任务和LIBERO空间与目标基准测试中进行了评估，结果显示它始终优于通用模型，并能与其他MoE管道竞争。此外，还分析了该方法对指令变化的鲁棒性。", "conclusion": "MoIRA仅依赖任务和专家的文本描述，展示了通过精确、低成本路由进行模块化部署的实际可行性，并为未来的多专家机器人系统提供了替代的、可扩展的基础。", "translation": "混合专家（MoE）方法由于能够动态分配计算资源并为不同任务或环境上下文专业化子网络，从而实现更高效的决策，最近在机器人应用中获得了关注。此类系统通常包含在单一整体架构下稀疏激活的专家，并需要一个配置良好的内部路由机制，但这不允许选择性地定制低级专家和路由器，并需要额外的训练。我们提出了MoIRA，一个与架构无关的模块化MoE框架，旨在通过外部文本路由器协调现有专家。MoIRA集成了两种零样本路由选项：基于嵌入的相似性和提示驱动的语言模型推理。在我们的实验中，我们选择大型视觉-语言-动作模型gr00t-N1和π0作为底层专家，并训练低秩适配器以实现低开销推理。我们在各种GR1人形任务和LIBERO空间与目标基准测试中评估了MoIRA，结果显示它始终优于通用模型，并能与其他MoE管道竞争。此外，我们分析了所提出方法对指令变化的鲁棒性。MoIRA仅依赖任务和专家的文本描述，展示了通过精确、低成本路由进行模块化部署的实际可行性，并为未来的多专家机器人系统提供了替代的、可扩展的基础。", "summary": "MoIRA是一种新颖的模块化混合专家（MoE）框架，旨在解决现有MoE在机器人应用中路由机制的局限性。它采用与架构无关的设计，并通过外部文本路由器（支持嵌入相似性和提示驱动的语言模型推理）协调现有专家，实现了零样本路由。实验证明，MoIRA在多任务机器人基准测试中超越了通用模型，并与其他MoE方案竞争，同时展现了对指令变化的鲁棒性，为未来的多专家机器人系统提供了可扩展的模块化部署方案。", "keywords": "混合专家, 机器人, 指令路由, 模块化, 零样本", "comments": "MoIRA的创新之处在于其“架构无关”和“外部文本路由器”的设计，这解决了传统MoE系统内部路由机制僵化、不易定制的问题。特别是其零样本路由能力，显著降低了部署和训练成本。该方法仅依赖文本描述进行任务和专家路由，极大地提高了系统的灵活性和可扩展性，对于构建更智能、适应性更强的多任务机器人系统具有重要意义。"}}
{"id": "2507.01401", "title": "Medical-Knowledge Driven Multiple Instance Learning for Classifying Severe Abdominal Anomalies on Prenatal Ultrasound", "authors": ["Huanwen Liang", "Jingxian Xu", "Yuanji Zhang", "Yuhao Huang", "Yuhan Zhang", "Xin Yang", "Ran Li", "Xuedong Deng", "Yanjun Liu", "Guowei Tao", "Yun Wu", "Sheng Zhao", "Xinru Gao", "Dong Ni"], "summary": "Fetal abdominal malformations are serious congenital anomalies that require\naccurate diagnosis to guide pregnancy management and reduce mortality. Although\nAI has demonstrated significant potential in medical diagnosis, its application\nto prenatal abdominal anomalies remains limited. Most existing studies focus on\nimage-level classification and rely on standard plane localization, placing\nless emphasis on case-level diagnosis. In this paper, we develop a case-level\nmultiple instance learning (MIL)-based method, free of standard plane\nlocalization, for classifying fetal abdominal anomalies in prenatal ultrasound.\nOur contribution is three-fold. First, we adopt a mixture-of-attention-experts\nmodule (MoAE) to weight different attention heads for various planes. Secondly,\nwe propose a medical-knowledge-driven feature selection module (MFS) to align\nimage features with medical knowledge, performing self-supervised image token\nselection at the case-level. Finally, we propose a prompt-based prototype\nlearning (PPL) to enhance the MFS. Extensively validated on a large prenatal\nabdominal ultrasound dataset containing 2,419 cases, with a total of 24,748\nimages and 6 categories, our proposed method outperforms the state-of-the-art\ncompetitors. Codes are available at:https://github.com/LL-AC/AAcls.", "comment": "Accepted by MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.01401v1", "categories": ["cs.CV", "cs.AI"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01401v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "医学生物知识驱动的多实例学习用于产前超声严重腹部异常分类", "tldr": "本文提出了一种基于医学知识的多实例学习（MIL）方法，用于在产前超声中对胎儿腹部异常进行病例级分类，该方法无需标准平面定位，并在大型数据集上表现优于现有技术。", "motivation": "胎儿腹部畸形是严重的先天性异常，需要准确诊断以指导妊娠管理并降低死亡率。现有的AI应用在产前腹部异常诊断中存在局限性，多数集中于图像级分类并依赖标准平面定位，而忽视了更关键的病例级诊断。", "method": "本文开发了一种病例级多实例学习（MIL）方法，旨在无需标准平面定位的情况下对产前超声中的胎儿腹部异常进行分类。该方法包含三方面贡献：1) 采用注意力专家混合模块（MoAE）来加权不同平面的注意力头；2) 提出医学知识驱动的特征选择模块（MFS），以实现图像特征与医学知识的对齐，并在病例级别进行自监督图像token选择；3) 引入基于提示的原型学习（PPL）以进一步增强MFS。", "result": "该方法在包含2,419个病例、总计24,748张图像和6个类别的S大型产前腹部超声数据集上进行了广泛验证，结果表明所提出的方法优于最先进的竞争方法。", "conclusion": "本研究提出了一种有效且优于现有技术的、基于医学知识驱动的多实例学习方法，能够对产前超声中的胎儿腹部异常进行准确的病例级分类，为临床诊断提供了更准确的工具。", "translation": "胎儿腹部畸形是严重的先天性异常，需要准确诊断以指导妊娠管理并降低死亡率。尽管人工智能在医学诊断中展现出巨大潜力，但其在产前腹部异常方面的应用仍然有限。大多数现有研究侧重于图像级分类并依赖标准平面定位，较少强调病例级诊断。在本文中，我们开发了一种基于病例级多实例学习（MIL）的方法，无需标准平面定位，用于对产前超声中的胎儿腹部异常进行分类。我们的贡献有三方面。首先，我们采用注意力专家混合模块（MoAE）来加权不同平面的注意力头。其次，我们提出了一种医学知识驱动的特征选择模块（MFS），将图像特征与医学知识对齐，在病例级别执行自监督图像token选择。最后，我们提出了基于提示的原型学习（PPL）以增强MFS。在包含2,419个病例、总计24,748张图像和6个类别的S大型产前腹部超声数据集上进行了广泛验证，我们提出的方法优于最先进的竞争方法。代码可在：https://github.com/LL-AC/AAcls 获取。", "summary": "本文提出了一种创新的、由医学知识驱动的多实例学习（MIL）方法，用于产前超声中胎儿腹部异常的病例级分类。该方法解决了现有AI模型依赖标准平面定位和仅进行图像级分类的局限性。通过引入注意力专家混合模块（MoAE）、医学知识驱动的特征选择模块（MFS）以及基于提示的原型学习（PPL），该模型能够更有效地整合医学知识并进行自监督特征选择。在大型数据集上的广泛实验证明，该方法在分类严重腹部异常方面表现优于现有最先进技术，为临床诊断提供了更准确的工具。", "keywords": "产前超声, 腹部异常, 多实例学习, 医学知识驱动, 病例级分类", "comments": "该论文的创新点在于将医学知识深度融入到多实例学习框架中，实现了无需标准平面定位的病例级诊断，这对于临床应用具有重要意义。特别是医学知识驱动的特征选择模块（MFS）和基于提示的原型学习（PPL）的设计，体现了结合领域专业知识提升AI模型性能的有效性。其在大型数据集上的优异表现，证明了该方法的实用性和潜力，有望提升产前诊断的准确性。"}}
{"id": "2507.01056", "title": "Evaluating Pavement Deterioration Rates Due to Flooding Events Using Explainable AI", "authors": ["Lidan Peng", "Lu Gao", "Feng Hong", "Jingran Sun"], "summary": "Flooding can damage pavement infrastructure significantly, causing both\nimmediate and long-term structural and functional issues. This research\ninvestigates how flooding events affect pavement deterioration, specifically\nfocusing on measuring pavement roughness by the International Roughness Index\n(IRI). To quantify these effects, we utilized 20 years of pavement condition\ndata from TxDOT's PMIS database, which is integrated with flood event data,\nincluding duration and spatial extent. Statistical analyses were performed to\ncompare IRI values before and after flooding and to calculate the deterioration\nrates influenced by flood exposure. Moreover, we applied Explainable Artificial\nIntelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP) and\nLocal Interpretable Model-Agnostic Explanations (LIME), to assess the impact of\nflooding on pavement performance. The results demonstrate that flood-affected\npavements experience a more rapid increase in roughness compared to non-flooded\nsections. These findings emphasize the need for proactive flood mitigation\nstrategies, including improved drainage systems, flood-resistant materials, and\npreventative maintenance, to enhance pavement resilience in vulnerable regions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01056v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01056v1", "date": "2025-06-28", "updated": "2025-06-28", "AI": {"title_translation": "使用可解释人工智能评估洪水事件引起的道路劣化率", "tldr": "本研究利用20年路面数据和可解释人工智能（XAI）评估洪水对路面粗糙度（IRI）的加速劣化影响，发现洪水导致路面劣化更快，强调需采取主动防洪策略。", "motivation": "洪水能显著损害路面基础设施，导致即时和长期的结构与功能问题。本研究旨在调查洪水事件如何影响路面劣化，特别是通过国际平整度指数（IRI）测量路面粗糙度。", "method": "利用德克萨斯州交通局PMIS数据库中20年的路面状况数据，并与洪水事件数据（包括持续时间和空间范围）整合。进行统计分析比较洪水前后IRI值，并计算受洪水影响的劣化率。应用可解释人工智能（XAI）技术，如SHapley Additive exPlanations (SHAP) 和Local Interpretable Model-Agnostic Explanations (LIME)，评估洪水对路面性能的影响。", "result": "结果表明，受洪水影响的路面比未受洪水影响的路段粗糙度增加更快。", "conclusion": "这些发现强调需要主动的防洪缓解策略，包括改进排水系统、抗洪材料和预防性维护，以增强脆弱地区路面的弹性。", "translation": "洪水会严重损害路面基础设施，导致即时和长期的结构和功能问题。本研究调查了洪水事件如何影响路面劣化，特别关注通过国际平整度指数（IRI）测量路面粗糙度。为了量化这些影响，我们利用了德克萨斯州交通局（TxDOT）PMIS数据库中20年的路面状况数据，该数据库与洪水事件数据（包括持续时间和空间范围）相结合。进行了统计分析，比较洪水前后的IRI值，并计算受洪水影响的劣化率。此外，我们应用了可解释人工智能（XAI）技术，如SHapley Additive exPlanations（SHAP）和Local Interpretable Model-Agnostic Explanations（LIME），以评估洪水对路面性能的影响。结果表明，受洪水影响的路面比未受洪水影响的路段粗糙度增加更快。这些发现强调需要主动的防洪缓解策略，包括改进排水系统、抗洪材料和预防性维护，以增强脆弱地区路面的弹性。", "summary": "本研究利用德克萨斯州交通局PMIS数据库中20年的路面状况和洪水数据，通过统计分析和可解释人工智能（如SHAP和LIME）技术，量化评估了洪水事件对路面劣化率（以IRI衡量）的影响。研究发现，洪水会导致路面粗糙度加速增加，并强调了采取主动防洪策略以提高路面弹性的必要性。", "keywords": "路面劣化, 洪水, 国际平整度指数 (IRI), 可解释人工智能 (XAI), 预防性维护", "comments": "本文的创新之处在于结合了长期路面状况数据和洪水事件数据，并首次应用可解释人工智能技术来量化和解释洪水对路面劣化过程的影响。这为理解洪水损害机制提供了更深入的见解，并为制定更有效的防洪和路面维护策略提供了数据支持，具有重要的实践意义。"}}
{"id": "2507.01415", "title": "Randomized subspace correction methods for convex optimization", "authors": ["Boou Jiang", "Jongho Park", "Jinchao Xu"], "summary": "This paper introduces an abstract framework for randomized subspace\ncorrection methods for convex optimization, which unifies and generalizes a\nbroad class of existing algorithms, including domain decomposition, multigrid,\nand block coordinate descent methods. We provide a convergence rate analysis\nranging from minimal assumptions to more practical settings, such as sharpness\nand strong convexity. While most existing studies on block coordinate descent\nmethods focus on nonoverlapping decompositions and smooth or strongly convex\nproblems, our framework extends to more general settings involving arbitrary\nspace decompositions, inexact local solvers, and problems with limited\nsmoothness or convexity. The proposed framework is broadly applicable to convex\noptimization problems arising in areas such as nonlinear partial differential\nequations, imaging, and data science.", "comment": "21 pages, 0 figures", "pdf_url": "http://arxiv.org/pdf/2507.01415v1", "categories": ["math.OC", "cs.NA", "math.NA", "90C25, 65N55, 65J05, 90C06"], "cate": "math.OC", "url": "http://arxiv.org/abs/2507.01415v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "凸优化的随机子空间校正方法", "tldr": "本文提出了一个用于凸优化的随机子空间校正方法的抽象框架，统一并推广了现有算法，并提供了广泛设置下的收敛率分析。", "motivation": "现有凸优化算法（如域分解、多重网格和块坐标下降）的研究多集中于非重叠分解、光滑或强凸问题。本文的动机是统一并推广这些算法，并将其应用于更一般的设置，包括任意空间分解、不精确局部求解器以及有限光滑度或凸性的问题。", "method": "本文引入了一个用于凸优化的随机子空间校正方法的抽象框架。该框架能够统一和推广包括域分解、多重网格和块坐标下降方法在内的现有算法。", "result": "本文提供了一个收敛率分析，涵盖从最小假设到更实际的设置，如尖锐性和强凸性。该框架扩展到更一般的设置，包括任意空间分解、不精确局部求解器以及有限光滑度或凸性的问题。", "conclusion": "所提出的框架广泛适用于非线性偏微分方程、图像处理和数据科学等领域中出现的凸优化问题。", "translation": "本文介绍了一个用于凸优化的随机子空间校正方法的抽象框架，该框架统一并推广了包括域分解、多重网格和块坐标下降方法在内的广泛现有算法。我们提供了从最小假设到更实际设置（如尖锐性和强凸性）的收敛率分析。虽然大多数关于块坐标下降方法的研究侧重于非重叠分解以及光滑或强凸问题，但我们的框架扩展到更一般的设置，涉及任意空间分解、不精确局部求解器以及有限光滑度或凸性的问题。所提出的框架广泛适用于非线性偏微分方程、图像处理和数据科学等领域中出现的凸优化问题。", "summary": "本文提出了一个用于凸优化的随机子空间校正方法的抽象框架，该框架统一并推广了多种现有算法，如域分解、多重网格和块坐标下降。该研究提供了在不同假设条件下的收敛率分析，并将其应用范围扩展到更广泛的问题类型，包括具有任意空间分解、不精确局部求解器以及有限光滑度或凸性的情况。此框架在非线性偏微分方程、图像处理和数据科学等领域具有广泛的应用潜力。", "keywords": "随机子空间校正, 凸优化, 收敛率, 抽象框架, 块坐标下降", "comments": "该论文的创新之处在于提出了一个统一的抽象框架，能够概括并扩展多种现有凸优化算法，如域分解和块坐标下降。其重要性体现在它不仅提供了更广泛的理论分析（涵盖更多样的假设和问题设置），还显著拓宽了这些方法的适用范围，使其能处理更复杂的实际问题，如不精确求解和非标准凸性。这对于优化领域的基础理论和实际应用都具有重要意义。"}}
{"id": "2507.01857", "title": "TypeTele: Releasing Dexterity in Teleoperation by Dexterous Manipulation Types", "authors": ["Yuhao Lin", "Yi-Lin Wei", "Haoran Liao", "Mu Lin", "Chengyi Xing", "Hao Li", "Dandan Zhang", "Mark Cutkosky", "Wei-Shi Zheng"], "summary": "Dexterous teleoperation plays a crucial role in robotic manipulation for\nreal-world data collection and remote robot control. Previous dexterous\nteleoperation mostly relies on hand retargeting to closely mimic human hand\npostures. However, these approaches may fail to fully leverage the inherent\ndexterity of dexterous hands, which can execute unique actions through their\nstructural advantages compared to human hands. To address this limitation, we\npropose TypeTele, a type-guided dexterous teleoperation system, which enables\ndexterous hands to perform actions that are not constrained by human motion\npatterns. This is achieved by introducing dexterous manipulation types into the\nteleoperation system, allowing operators to employ appropriate types to\ncomplete specific tasks. To support this system, we build an extensible\ndexterous manipulation type library to cover comprehensive dexterous postures\nused in manipulation tasks. During teleoperation, we employ a MLLM\n(Multi-modality Large Language Model)-assisted type retrieval module to\nidentify the most suitable manipulation type based on the specific task and\noperator commands. Extensive experiments of real-world teleoperation and\nimitation learning demonstrate that the incorporation of manipulation types\nsignificantly takes full advantage of the dexterous robot's ability to perform\ndiverse and complex tasks with higher success rates.", "comment": "Project Page: https://isee-laboratory.github.io/TypeTele", "pdf_url": "http://arxiv.org/pdf/2507.01857v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01857v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "TypeTele：通过灵巧操作类型释放远程操作中的灵活性", "tldr": "TypeTele引入灵巧操作类型，使机器人远程操作不再受限于人类动作，通过MLLM辅助类型检索，显著提高了复杂任务的成功率。", "motivation": "现有的灵巧远程操作主要依赖于手部重定向来紧密模仿人类姿态，但这未能充分利用灵巧手固有的结构优势来执行独特动作，限制了其灵活性。", "method": "提出TypeTele系统，一个类型引导的灵巧远程操作系统。该系统通过引入灵巧操作类型，允许操作员选择合适的类型完成任务。为此，他们构建了一个可扩展的灵巧操作类型库，并使用MLLM（多模态大型语言模型）辅助的类型检索模块来识别最适合任务和操作员命令的类型。", "result": "真实世界远程操作和模仿学习的广泛实验表明，结合操作类型显著利用了灵巧机器人的能力，以更高的成功率执行多样化和复杂的任务。", "conclusion": "通过引入灵巧操作类型并利用MLLM进行类型检索，TypeTele系统成功地释放了灵巧机器人在远程操作中的全部潜力，使其能够执行超越人类运动模式限制的复杂任务，并显著提高任务成功率。", "translation": "灵巧远程操作在机器人操作中对现实世界数据收集和远程机器人控制起着至关重要的作用。以前的灵巧远程操作大多依赖于手部重定向来紧密模仿人类手部姿势。然而，这些方法可能未能充分利用灵巧手固有的灵活性，与人手相比，灵巧手可以通过其结构优势执行独特的动作。为了解决这个限制，我们提出了TypeTele，一个类型引导的灵巧远程操作系统，它使灵巧手能够执行不受人类运动模式限制的动作。这是通过将灵巧操作类型引入远程操作系统来实现的，允许操作员使用适当的类型来完成特定任务。为了支持这个系统，我们建立了一个可扩展的灵巧操作类型库，以涵盖操作任务中使用的全面灵巧姿势。在远程操作过程中，我们采用MLLM（多模态大型语言模型）辅助的类型检索模块，根据特定任务和操作员命令识别最合适的操作类型。真实世界远程操作和模仿学习的广泛实验表明，操作类型的结合显著充分利用了灵巧机器人执行多样化和复杂任务的能力，并具有更高的成功率。", "summary": "本文提出了TypeTele，一个类型引导的灵巧远程操作系统，旨在克服传统手部重定向方法未能充分利用灵巧手固有优势的局限。TypeTele引入了灵巧操作类型，并构建了一个可扩展的类型库，结合MLLM辅助的类型检索，使机器人能执行不受人类运动模式限制的独特动作。实验证明，该系统显著提高了灵巧机器人执行多样化复杂任务的成功率。", "keywords": "灵巧远程操作, 类型引导, MLLM, 机器人操作, 灵活性", "comments": "TypeTele的创新之处在于其“类型引导”的远程操作范式，摆脱了传统模仿人类动作的束缚，真正释放了灵巧机器手的潜力。引入MLLM进行类型检索是一个亮点，体现了多模态大模型在机器人领域的应用前景。这对于提升机器人远程操作的自主性和效率具有重要意义。"}}
{"id": "2507.01409", "title": "CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning", "authors": ["Kuniaki Saito", "Donghyun Kim", "Kwanyong Park", "Atsushi Hashimoto", "Yoshitaka Ushiku"], "summary": "An image captioning model flexibly switching its language pattern, e.g.,\ndescriptiveness and length, should be useful since it can be applied to diverse\napplications. However, despite the dramatic improvement in generative\nvision-language models, fine-grained control over the properties of generated\ncaptions is not easy due to two reasons: (i) existing models are not given the\nproperties as a condition during training and (ii) existing models cannot\nsmoothly transition its language pattern from one state to the other. Given\nthis challenge, we propose a new approach, CaptionSmiths, to acquire a single\ncaptioning model that can handle diverse language patterns. First, our approach\nquantifies three properties of each caption, length, descriptiveness, and\nuniqueness of a word, as continuous scalar values, without human annotation.\nGiven the values, we represent the conditioning via interpolation between two\nendpoint vectors corresponding to the extreme states, e.g., one for a very\nshort caption and one for a very long caption. Empirical results demonstrate\nthat the resulting model can smoothly change the properties of the output\ncaptions and show higher lexical alignment than baselines. For instance,\nCaptionSmiths reduces the error in controlling caption length by 506\\% despite\nbetter lexical alignment. Code will be available on\nhttps://github.com/omron-sinicx/captionsmiths.", "comment": "Accepted to ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.01409v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01409v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "CaptionSmiths: 灵活控制图像字幕中的语言模式", "tldr": "提出CaptionSmiths模型，通过量化和插值控制图像字幕的语言模式（如长度和描述性），实现平滑过渡和更高词汇对齐。", "motivation": "现有图像字幕模型难以对生成字幕的属性进行细粒度控制，因为训练时未将属性作为条件，且无法平滑过渡语言模式。", "method": "提出CaptionSmiths方法，首先无需人工标注量化每个字幕的三个属性（长度、描述性和词语独特性）为连续标量值；然后通过在表示极端状态的两个端点向量之间进行插值来表示条件。", "result": "结果表明，该模型可以平滑改变输出字幕的属性，并显示出比基线更高的词汇对齐。例如，CaptionSmiths在词汇对齐更好的情况下，将控制字幕长度的误差降低了506%。", "conclusion": "该论文提出了CaptionSmiths，一个能够灵活控制图像字幕语言模式的模型，并通过量化属性和插值条件实现了细粒度控制和性能提升。", "translation": "图像字幕模型能够灵活切换其语言模式，例如描述性和长度，这将非常有用，因为它可以应用于各种不同的应用。然而，尽管生成式视觉-语言模型取得了显著进步，但由于两个原因，对生成字幕属性的细粒度控制并不容易：(i)现有模型在训练期间没有将这些属性作为条件；(ii)现有模型无法使其语言模式从一种状态平滑过渡到另一种状态。鉴于这一挑战，我们提出了一种新方法CaptionSmiths，以获得一个能够处理多种语言模式的单一字幕模型。首先，我们的方法无需人工标注，将每个字幕的三个属性（长度、描述性和词语独特性）量化为连续标量值。给定这些值，我们通过在对应极端状态的两个端点向量（例如，一个用于非常短的字幕，一个用于非常长的字幕）之间进行插值来表示条件。实证结果表明，所得模型可以平滑地改变输出字幕的属性，并显示出比基线更高的词汇对齐。例如，CaptionSmiths在词汇对齐更好的情况下，将控制字幕长度的误差降低了506%。代码将在https://github.com/omron-sinicx/captionsmiths 上提供。", "summary": "本文提出CaptionSmiths，一种新型图像字幕模型，旨在解决现有模型在生成字幕时难以进行细粒度语言模式控制的问题。该方法通过无需人工标注地量化字幕的长度、描述性和词语独特性等属性为连续标量值，并利用端点向量插值进行条件表示。实验证明，CaptionSmiths能平滑调整输出字幕属性，并实现更优的词汇对齐，显著降低了控制字幕长度的误差。", "keywords": "图像字幕, 语言模式控制, CaptionSmiths, 描述性, 字幕长度", "comments": "这项工作在图像字幕领域具有创新性，通过引入无需人工标注的属性量化和插值控制机制，解决了现有模型在语言模式灵活控制上的痛点。其能够实现属性的平滑过渡和更高的词汇对齐，对于需要特定风格或长度字幕的实际应用具有重要意义。"}}
{"id": "2507.01057", "title": "Loop2Net: Data-Driven Generation and Optimization of Airfoil CFD Meshes from Sparse Boundary Coordinates", "authors": ["Lushun Fan", "Yuqin Xia", "Jun Li", "Karl Jenkins"], "summary": "In this study, an innovative intelligent optimization system for mesh quality\nis proposed, which is based on a deep convolutional neural network\narchitecture, to achieve mesh generation and optimization. The core of the\nstudy is the Loop2Net generator and loss function, it predicts the mesh based\non the given wing coordinates. And the model's performance is continuously\noptimised by two key loss functions during the training. Then discipline by\nadding penalties, the goal of mesh generation was finally reached.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01057v1", "categories": ["cs.LG", "physics.flu-dyn"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01057v1", "date": "2025-06-28", "updated": "2025-06-28", "AI": {"title_translation": "Loop2Net：基于稀疏边界坐标的气动翼型CFD网格数据驱动生成与优化", "tldr": "本研究提出了一种基于深度卷积神经网络的Loop2Net系统，用于从稀疏边界坐标生成和优化气动翼型CFD网格，通过损失函数和惩罚机制实现了网格生成目标。", "motivation": "本研究旨在提出一种创新的智能网格质量优化系统，以实现网格的生成和优化。", "method": "研究提出了一种基于深度卷积神经网络架构的Loop2Net生成器和损失函数。该模型根据给定的机翼坐标预测网格，并通过两个关键损失函数在训练过程中持续优化其性能，最终通过增加惩罚项达到了网格生成的目标。", "result": "最终达到了网格生成的目标。", "conclusion": "通过提出的基于深度卷积神经网络的Loop2Net系统，成功实现了从稀疏边界坐标生成和优化气动翼型CFD网格的目标。", "translation": "本研究提出了一种基于深度卷积神经网络架构的创新智能网格质量优化系统，以实现网格生成和优化。研究的核心是Loop2Net生成器和损失函数，它根据给定的机翼坐标预测网格。模型的性能在训练过程中通过两个关键损失函数持续优化。然后通过增加惩罚项，最终达到了网格生成的目标。", "summary": "本研究提出了一种创新的基于深度卷积神经网络架构的智能优化系统Loop2Net，用于实现网格的生成和优化。其核心是Loop2Net生成器和损失函数，能够根据给定的机翼坐标预测网格，并通过训练中的两个关键损失函数以及惩罚机制持续优化模型性能，最终成功达到网格生成的目标。", "keywords": "Loop2Net, 网格生成, 网格优化, 深度卷积神经网络, CFD网格", "comments": "该论文提出了一种新颖的数据驱动方法，利用深度卷积神经网络进行CFD网格的生成和优化，这在计算流体力学领域具有创新性。通过引入Loop2Net生成器和定制的损失函数，该系统能够从稀疏边界坐标实现高质量网格的生成，有望提高CFD模拟的效率和准确性。"}}
{"id": "2507.01556", "title": "Approximate Solution Methods for the Average Reward Criterion in Optimal Tracking Control of Linear Systems", "authors": ["Duc Cuong Nguyen"], "summary": "This paper studies optimal control under the average-reward/cost criterion\nfor deterministic linear systems. We derive the value function and optimal\npolicy, and propose an approximate solution using Model Predictive Control to\nenable practical implementation.", "comment": "3 pages. 1 table", "pdf_url": "http://arxiv.org/pdf/2507.01556v1", "categories": ["math.OC", "cs.SY", "eess.SY"], "cate": "math.OC", "url": "http://arxiv.org/abs/2507.01556v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "线性系统最优跟踪控制中平均奖励准则的近似解法", "tldr": "本文研究确定性线性系统在平均奖励准则下的最优控制，推导了价值函数和最优策略，并提出一种基于模型预测控制的近似解法以实现实际应用。", "motivation": "该研究旨在解决确定性线性系统在平均奖励/成本准则下的最优控制问题，并提出近似解法以实现实际应用。", "method": "论文推导了价值函数和最优策略，并提出了一种使用模型预测控制（MPC）的近似解法。", "result": "论文推导了价值函数和最优策略，并提出了基于模型预测控制的近似解法。具体结果（如性能评估）未在摘要中提及。", "conclusion": "论文为确定性线性系统在平均奖励准则下的最优控制提供了一种基于模型预测控制的近似解法，以实现实际应用。更详细的结论未在摘要中提及。", "translation": "本文研究确定性线性系统在平均奖励/成本准则下的最优控制。我们推导了价值函数和最优策略，并提出了一种使用模型预测控制的近似解法，以实现实际应用。", "summary": "本文探讨了确定性线性系统在平均奖励准则下的最优控制问题。研究内容包括推导价值函数和最优策略，并提出一种利用模型预测控制的近似解决方案，旨在使其能够应用于实际场景。", "keywords": "最优控制, 平均奖励准则, 线性系统, 模型预测控制, 近似解法", "comments": "该论文的创新点在于将模型预测控制（MPC）应用于平均奖励准则下的最优控制问题，为这类复杂控制问题提供了一种实用的近似求解方法。其重要性在于弥合了理论最优控制与实际应用之间的差距。"}}
{"id": "2507.01645", "title": "Adapting Language Models to Indonesian Local Languages: An Empirical Study of Language Transferability on Zero-Shot Settings", "authors": ["Rifki Afina Putri"], "summary": "In this paper, we investigate the transferability of pre-trained language\nmodels to low-resource Indonesian local languages through the task of sentiment\nanalysis. We evaluate both zero-shot performance and adapter-based transfer on\nten local languages using models of different types: a monolingual Indonesian\nBERT, multilingual models such as mBERT and XLM-R, and a modular adapter-based\napproach called MAD-X. To better understand model behavior, we group the target\nlanguages into three categories: seen (included during pre-training), partially\nseen (not included but linguistically related to seen languages), and unseen\n(absent and unrelated in pre-training data). Our results reveal clear\nperformance disparities across these groups: multilingual models perform best\non seen languages, moderately on partially seen ones, and poorly on unseen\nlanguages. We find that MAD-X significantly improves performance, especially\nfor seen and partially seen languages, without requiring labeled data in the\ntarget language. Additionally, we conduct a further analysis on tokenization\nand show that while subword fragmentation and vocabulary overlap with\nIndonesian correlate weakly with prediction quality, they do not fully explain\nthe observed performance. Instead, the most consistent predictor of transfer\nsuccess is the model's prior exposure to the language, either directly or\nthrough a related language.", "comment": "AMLDS 2025", "pdf_url": "http://arxiv.org/pdf/2507.01645v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01645v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "将语言模型适应印度尼西亚地方语言：零样本设置下语言可迁移性的实证研究", "tldr": "研究了预训练语言模型在印度尼西亚低资源地方语言上的可迁移性，发现多语言模型对见过语言表现最好，MAD-X显著提升性能，迁移成功与模型对语言的先验暴露度最相关。", "motivation": "探索预训练语言模型向低资源印度尼西亚地方语言的迁移能力，特别是通过情感分析任务。", "method": "评估了在十种地方语言上零样本性能和基于适配器的迁移。使用了不同类型的模型：单语印度尼西亚BERT、多语言模型（如mBERT和XLM-R）和模块化适配器方法MAD-X。将目标语言分为三类：见过、部分见过、未见过。", "result": "多语言模型在见过语言上表现最佳，部分见过语言次之，未见过语言表现差。MAD-X显著提升了性能，尤其对见过和部分见过语言，无需目标语言的标注数据。分词分析显示，子词碎片化和词汇表与印度尼西亚语的重叠与预测质量关联较弱，不能完全解释性能差异。模型对语言的先验暴露度（直接或通过相关语言）是迁移成功最一致的预测因子。", "conclusion": "预训练语言模型对印度尼西亚地方语言的迁移能力受语言在预训练数据中暴露程度的影响，而MAD-X等适配器方法可以有效提升性能，尤其对见过和部分见过语言。模型对语言的先验暴露度是迁移成功的关键因素。", "translation": "在本文中，我们通过情感分析任务，研究了预训练语言模型向低资源印度尼西亚地方语言的可迁移性。我们使用不同类型的模型，包括单语印度尼西亚BERT、多语言模型（如mBERT和XLM-R）以及模块化基于适配器的方法MAD-X，在十种地方语言上评估了零样本性能和基于适配器的迁移。为了更好地理解模型行为，我们将目标语言分为三类：见过（预训练期间包含）、部分见过（未包含但与见过语言有语言学关联）和未见过（预训练数据中缺失且不相关）。我们的结果揭示了这些组之间明显的性能差异：多语言模型在见过语言上表现最佳，在部分见过语言上表现中等，在未见过语言上表现不差。我们发现MAD-X显著提高了性能，特别是对于见过和部分见过语言，而无需目标语言的标注数据。此外，我们对分词进行了进一步分析，结果表明子词碎片化和与印度尼西亚语的词汇重叠与预测质量的关联性较弱，但它们并不能完全解释观察到的性能。相反，迁移成功最一致的预测因子是模型之前对该语言的接触，无论是直接接触还是通过相关语言接触。", "summary": "本文通过情感分析任务，实证研究了预训练语言模型向低资源印度尼西亚地方语言的迁移能力。研究评估了不同类型的模型（如BERT、mBERT、XLM-R和MAD-X）在“见过”、“部分见过”和“未见过”三类语言上的零样本性能和适配器迁移效果。结果表明，多语言模型在见过语言上表现最佳，而MAD-X显著提升了性能，尤其对见过和部分见过语言。研究强调，模型对语言的先验暴露度是迁移成功的最关键因素，而分词特性解释力有限。", "keywords": "语言模型迁移, 印度尼西亚地方语言, 零样本学习, 情感分析, MAD-X", "comments": "这项研究通过系统地分类目标语言（见过、部分见过、未见过）并评估不同模型和适配器方法（MAD-X）的性能，为低资源语言的语言模型迁移提供了宝贵的实证见解。它不仅揭示了多语言模型在不同语言暴露程度下的局限性，还展示了适配器方法在无需标注数据情况下提升性能的潜力，对资源匮乏语言的自然语言处理发展具有重要意义。"}}
{"id": "2507.01687", "title": "A generative modeling / Physics-Informed Neural Network approach to random differential equations", "authors": ["Georgios Arampatzis", "Stylianos Katsarakis", "Charalambos Makridakis"], "summary": "The integration of Scientific Machine Learning (SciML) techniques with\nuncertainty quantification (UQ) represents a rapidly evolving frontier in\ncomputational science. This work advances Physics-Informed Neural Networks\n(PINNs) by incorporating probabilistic frameworks to effectively model\nuncertainty in complex systems. Our approach enhances the representation of\nuncertainty in forward problems by combining generative modeling techniques\nwith PINNs. This integration enables in a systematic fashion uncertainty\ncontrol while maintaining the predictive accuracy of the model. We demonstrate\nthe utility of this method through applications to random differential\nequations and random partial differential equations (PDEs).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01687v1", "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "cate": "stat.ML", "url": "http://arxiv.org/abs/2507.01687v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "生成模型/物理信息神经网络方法应用于随机微分方程", "tldr": "本文结合生成模型与物理信息神经网络（PINNs），以有效建模复杂系统中的不确定性，并应用于随机微分方程。", "motivation": "计算科学中，科学机器学习（SciML）技术与不确定性量化（UQ）的结合是一个快速发展的领域。当前物理信息神经网络（PINNs）在处理复杂系统不确定性方面仍有提升空间。", "method": "该方法通过将生成建模技术与物理信息神经网络（PINNs）相结合，增强了正向问题中不确定性的表示。这种集成使得在保持模型预测精度的同时，系统地控制不确定性成为可能。", "result": "通过应用于随机微分方程和随机偏微分方程（PDEs），证明了该方法的实用性。", "conclusion": "结合生成模型与物理信息神经网络（PINNs）能够有效建模复杂系统中的不确定性，并在保持预测精度的同时实现不确定性控制。", "translation": "科学机器学习（SciML）技术与不确定性量化（UQ）的结合代表了计算科学中一个快速发展的前沿领域。这项工作通过整合概率框架，将物理信息神经网络（PINNs）向前推进，以有效地模拟复杂系统中的不确定性。我们的方法通过将生成建模技术与PINNs相结合，增强了正向问题中不确定性的表示。这种集成使得在保持模型预测精度的同时，系统地控制不确定性成为可能。我们通过将该方法应用于随机微分方程和随机偏微分方程（PDEs），展示了其效用。", "summary": "本文提出一种结合生成模型和物理信息神经网络（PINNs）的新方法，以有效处理复杂系统中的不确定性。该方法在保持预测精度的前提下，能够系统地控制不确定性，并通过在随机微分方程和随机偏微分方程上的应用验证了其有效性。", "keywords": "生成模型, 物理信息神经网络, 不确定性量化, 随机微分方程, 科学机器学习", "comments": "该研究的创新之处在于将生成模型与物理信息神经网络（PINNs）结合，为不确定性量化提供了新途径，有望提升PINNs在实际复杂系统应用中的鲁棒性。"}}
{"id": "2507.01925", "title": "A Survey on Vision-Language-Action Models: An Action Tokenization Perspective", "authors": ["Yifan Zhong", "Fengshuo Bai", "Shaofei Cai", "Xuchuan Huang", "Zhang Chen", "Xiaowei Zhang", "Yuanfei Wang", "Shaoyang Guo", "Tianrui Guan", "Ka Nam Lui", "Zhiquan Qi", "Yitao Liang", "Yuanpei Chen", "Yaodong Yang"], "summary": "The remarkable advancements of vision and language foundation models in\nmultimodal understanding, reasoning, and generation has sparked growing efforts\nto extend such intelligence to the physical world, fueling the flourishing of\nvision-language-action (VLA) models. Despite seemingly diverse approaches, we\nobserve that current VLA models can be unified under a single framework: vision\nand language inputs are processed by a series of VLA modules, producing a chain\nof \\textit{action tokens} that progressively encode more grounded and\nactionable information, ultimately generating executable actions. We further\ndetermine that the primary design choice distinguishing VLA models lies in how\naction tokens are formulated, which can be categorized into language\ndescription, code, affordance, trajectory, goal state, latent representation,\nraw action, and reasoning. However, there remains a lack of comprehensive\nunderstanding regarding action tokens, significantly impeding effective VLA\ndevelopment and obscuring future directions. Therefore, this survey aims to\ncategorize and interpret existing VLA research through the lens of action\ntokenization, distill the strengths and limitations of each token type, and\nidentify areas for improvement. Through this systematic review and analysis, we\noffer a synthesized outlook on the broader evolution of VLA models, highlight\nunderexplored yet promising directions, and contribute guidance for future\nresearch, hoping to bring the field closer to general-purpose intelligence.", "comment": "70 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.01925v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01925v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "视觉-语言-动作模型综述：一个动作标记化视角", "tldr": "本综述从动作标记化的角度统一并分析了视觉-语言-动作（VLA）模型，指出了当前理解的不足，并为未来研究提供了指导。", "motivation": "尽管视觉和语言基础模型取得了显著进展，并推动了视觉-语言-动作（VLA）模型的发展，但当前对VLA模型中动作标记化的理解不足，这严重阻碍了VLA的有效开发并模糊了未来的发展方向。因此，本综述旨在解决这一理解上的空白。", "method": "本综述通过动作标记化的视角，将现有VLA模型统一在一个框架下，并根据动作标记的制定方式将其分为八类（语言描述、代码、功能、轨迹、目标状态、潜在表示、原始动作和推理）。通过系统回顾和分析，提炼每种标记类型的优缺点，并识别需要改进的领域。", "result": "本综述提供了一个关于VLA模型更广泛演进的综合性展望，突出了未被充分探索但有前景的方向，并为未来的研究提供了指导。", "conclusion": "通过对动作标记化的系统分析，本综述旨在弥补当前对VLA模型理解的不足，为VLA领域的未来发展提供清晰的方向和指导，以期使该领域更接近通用智能。", "translation": "视觉和语言基础模型在多模态理解、推理和生成方面的显著进步，激发了人们将这种智能扩展到物理世界的努力，从而推动了视觉-语言-动作（VLA）模型的蓬勃发展。尽管方法看似多样，但我们观察到当前的VLA模型可以统一在一个单一框架下：视觉和语言输入通过一系列VLA模块处理，产生一系列“动作标记”，这些标记逐步编码更基础和可操作的信息，最终生成可执行的动作。我们进一步确定，区分VLA模型的主要设计选择在于动作标记的制定方式，这可以分为语言描述、代码、功能、轨迹、目标状态、潜在表示、原始动作和推理。然而，目前对动作标记缺乏全面的理解，这严重阻碍了VLA的有效开发并模糊了未来的方向。因此，本综述旨在通过动作标记化的视角对现有VLA研究进行分类和解释，提炼每种标记类型的优缺点，并识别需要改进的领域。通过这种系统的回顾和分析，我们对VLA模型的更广泛演进提供了一个综合性的展望，突出了未被充分探索但有前景的方向，并为未来的研究提供了指导，希望能使该领域更接近通用智能。", "summary": "本综述系统地回顾了视觉-语言-动作（VLA）模型，提出所有VLA模型都可以通过“动作标记”的概念进行统一。论文将动作标记分为八种类型，并指出当前对这些标记缺乏全面理解是VLA发展的主要障碍。本综述旨在通过分析不同动作标记的优缺点，为VLA研究提供分类框架和未来方向的指导，以促进通用智能的发展。", "keywords": "视觉-语言-动作模型, 动作标记化, 综述, 多模态, 通用智能", "comments": "这篇综述通过引入“动作标记化”这一创新视角，为理解和统一看似多样化的视觉-语言-动作（VLA）模型提供了一个独特的框架。它不仅系统地分类了现有方法，还突出了当前研究的不足和未来的潜在方向，对于推动VLA领域向通用智能迈进具有重要指导意义。"}}
{"id": "2507.01607", "title": "Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems", "authors": ["Quentin Le Roux", "Yannick Teglia", "Teddy Furon", "Philippe Loubet-Moundi", "Eric Bourbao"], "summary": "The widespread use of deep learning face recognition raises several security\nconcerns. Although prior works point at existing vulnerabilities, DNN backdoor\nattacks against real-life, unconstrained systems dealing with images captured\nin the wild remain a blind spot of the literature. This paper conducts the\nfirst system-level study of backdoors in deep learning-based face recognition\nsystems. This paper yields four contributions by exploring the feasibility of\nDNN backdoors on these pipelines in a holistic fashion. We demonstrate for the\nfirst time two backdoor attacks on the face detection task: face generation and\nface landmark shift attacks. We then show that face feature extractors trained\nwith large margin losses also fall victim to backdoor attacks. Combining our\nmodels, we then show using 20 possible pipeline configurations and 15 attack\ncases that a single backdoor enables an attacker to bypass the entire function\nof a system. Finally, we provide stakeholders with several best practices and\ncountermeasures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01607v1", "categories": ["cs.CV", "cs.AI", "cs.CR", "cs.LG"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01607v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "无约束人脸识别系统中后门攻击的生存能力", "tldr": "首次对深度学习人脸识别系统中的后门攻击进行了系统级研究，并展示了攻击的有效性及其对整个系统的影响，同时提供了对策。", "motivation": "深度学习人脸识别的广泛应用带来了安全隐患。现有工作虽然指出漏洞，但针对真实、无约束系统（处理野外图像）的DNN后门攻击仍是文献中的盲点。", "method": "本文对深度学习人脸识别系统中的后门攻击进行了首次系统级研究。探索了DNN后门在这些管道上的可行性，并首次展示了人脸检测任务上的两种后门攻击（人脸生成和人脸关键点偏移攻击）。然后证明了使用大裕度损失训练的人脸特征提取器也容易受到后门攻击。结合模型，使用20种可能的管道配置和15种攻击情况，展示了单个后门可以绕过整个系统功能。", "result": "本文有四项贡献：1. 首次对深度学习人脸识别系统中的后门进行了系统级研究。2. 首次展示了人脸检测任务上的两种后门攻击：人脸生成攻击和人脸关键点偏移攻击。3. 证明了使用大裕度损失训练的人脸特征提取器也容易受到后门攻击。4. 通过20种管道配置和15种攻击案例，表明单个后门攻击能够绕过整个系统功能。", "conclusion": "本文揭示了无约束人脸识别系统中后门攻击的生存能力，并向利益相关者提供了几种最佳实践和对策。", "translation": "深度学习人脸识别的广泛使用带来了若干安全问题。尽管先前的研究指出了现有的漏洞，但针对处理野外图像的真实、无约束系统的DNN后门攻击仍然是文献中的盲点。本文对基于深度学习的人脸识别系统中的后门进行了首次系统级研究。通过全面探索DNN后门在这些管道上的可行性，本文做出了四项贡献。我们首次展示了人脸检测任务上的两种后门攻击：人脸生成攻击和人脸关键点偏移攻击。然后我们表明，使用大裕度损失训练的人脸特征提取器也容易受到后门攻击。结合我们的模型，我们通过使用20种可能的管道配置和15种攻击案例，表明单个后门能够让攻击者绕过整个系统功能。最后，我们向利益相关者提供了几种最佳实践和对策。", "summary": "本文首次对深度学习人脸识别系统中的后门攻击进行了系统级研究，重点关注处理野外图像的无约束系统。研究展示了人脸检测任务上的两种新型后门攻击（人脸生成和人脸关键点偏移），并发现使用大裕度损失训练的特征提取器也易受攻击。通过多配置和攻击案例验证，证明单一后门可绕过整个系统功能。最后，论文提供了应对这些攻击的最佳实践和对策。", "keywords": "后门攻击, 人脸识别, 深度学习, 系统安全, 无约束系统", "comments": "本文首次对真实、无约束人脸识别系统中的DNN后门攻击进行了系统级研究，填补了现有文献的空白。其创新之处在于提出了针对人脸检测任务的新型后门攻击，并揭示了特征提取器在面对此类攻击时的脆弱性。研究通过全面的实验验证了攻击的有效性和对整个系统的影响，强调了此类安全问题的严重性。论文还提供了实用的对策，具有重要的现实意义。"}}
{"id": "2507.01417", "title": "Gradient Short-Circuit: Efficient Out-of-Distribution Detection via Feature Intervention", "authors": ["Jiawei Gu", "Ziyue Qiao", "Zechao Li"], "summary": "Out-of-Distribution (OOD) detection is critical for safely deploying deep\nmodels in open-world environments, where inputs may lie outside the training\ndistribution. During inference on a model trained exclusively with\nIn-Distribution (ID) data, we observe a salient gradient phenomenon: around an\nID sample, the local gradient directions for \"enhancing\" that sample's\npredicted class remain relatively consistent, whereas OOD samples--unseen in\ntraining--exhibit disorganized or conflicting gradient directions in the same\nneighborhood. Motivated by this observation, we propose an inference-stage\ntechnique to short-circuit those feature coordinates that spurious gradients\nexploit to inflate OOD confidence, while leaving ID classification largely\nintact. To circumvent the expense of recomputing the logits after this gradient\nshort-circuit, we further introduce a local first-order approximation that\naccurately captures the post-modification outputs without a second forward\npass. Experiments on standard OOD benchmarks show our approach yields\nsubstantial improvements. Moreover, the method is lightweight and requires\nminimal changes to the standard inference pipeline, offering a practical path\ntoward robust OOD detection in real-world applications.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.01417v1", "categories": ["cs.CV", "cs.LG"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01417v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "梯度短路：通过特征干预实现高效的分布外检测", "tldr": "本文提出了一种名为“梯度短路”的推理阶段技术，通过干预特征坐标来有效检测分布外（OOD）样本，并通过一阶近似避免了额外的计算开销，显著提升了OOD检测性能。", "motivation": "在深度模型部署中，当输入数据可能超出训练分布时，分布外（OOD）检测至关重要。作者观察到，对于分布内（ID）样本，其预测类别的局部梯度方向相对一致，而对于OOD样本，梯度方向则混乱或冲突，这一现象促使了本研究的提出。", "method": "本文提出了一种推理阶段的技术，称为“梯度短路”，旨在通过干预那些被虚假梯度利用以夸大OOD置信度的特征坐标，同时保持ID分类基本不变。为了避免重新计算logits的开销，该方法进一步引入了一种局部一阶近似，能够准确捕获修改后的输出而无需第二次前向传播。", "result": "在标准OOD基准测试上的实验表明，所提出的方法取得了显著的性能提升。此外，该方法轻量级，对标准推理流程的修改最小。", "conclusion": "本文提出的梯度短路方法通过利用梯度现象，提供了一种高效且实用的OOD检测途径，能够在真实世界应用中实现鲁棒的OOD检测。", "translation": "分布外（OOD）检测对于在开放世界环境中安全部署深度模型至关重要，因为输入可能超出训练分布。在仅使用分布内（ID）数据训练的模型进行推理时，我们观察到一个显著的梯度现象：在ID样本周围，用于“增强”该样本预测类别的局部梯度方向保持相对一致，而OOD样本（在训练中未见过）在相同邻域内表现出无序或冲突的梯度方向。受此观察启发，我们提出了一种推理阶段的技术，以短接那些被虚假梯度利用来夸大OOD置信度的特征坐标，同时基本保持ID分类完整。为了避免在梯度短路后重新计算logits的开销，我们进一步引入了一种局部一阶近似，可以在不进行第二次前向传播的情况下准确捕获修改后的输出。在标准OOD基准测试上的实验表明，我们的方法产生了显著的改进。此外，该方法轻量级，对标准推理流程的修改最小，为在实际应用中实现鲁棒的OOD检测提供了实用途径。", "summary": "本文提出了一种名为“梯度短路”的推理阶段OOD检测技术。该方法基于对ID和OOD样本局部梯度方向差异的观察，通过干预特征坐标来抑制OOD样本的虚假高置信度，同时不影响ID分类。为提高效率，引入了局部一阶近似以避免额外的计算。实验结果表明，该方法在标准OOD基准上取得了显著改进，且具有轻量级和易于集成的优点，为实际应用提供了有效路径。", "keywords": "分布外检测, 梯度短路, 特征干预, 深度学习, 鲁棒性", "comments": "这项工作创新性地利用了ID和OOD样本在梯度行为上的差异来进行检测。通过引入“梯度短路”的概念和高效的一阶近似，它解决了OOD检测中常见的计算开销问题，使其更适用于实际部署。该方法对现有推理流程的改动小，具有很高的实用价值和潜力。"}}
{"id": "2507.01702", "title": "AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness", "authors": ["Zixin Chen", "Hongzhan Lin", "Kaixin Li", "Ziyang Luo", "Zhen Ye", "Guang Chen", "Zhiyong Huang", "Jing Ma"], "summary": "The proliferation of multimodal memes in the social media era demands that\nmultimodal Large Language Models (mLLMs) effectively understand meme\nharmfulness. Existing benchmarks for assessing mLLMs on harmful meme\nunderstanding rely on accuracy-based, model-agnostic evaluations using static\ndatasets. These benchmarks are limited in their ability to provide up-to-date\nand thorough assessments, as online memes evolve dynamically. To address this,\nwe propose AdamMeme, a flexible, agent-based evaluation framework that\nadaptively probes the reasoning capabilities of mLLMs in deciphering meme\nharmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive\nevaluations by iteratively updating the meme data with challenging samples,\nthereby exposing specific limitations in how mLLMs interpret harmfulness.\nExtensive experiments show that our framework systematically reveals the\nvarying performance of different target mLLMs, offering in-depth, fine-grained\nanalyses of model-specific weaknesses. Our code is available at\nhttps://github.com/Lbotirx/AdamMeme.", "comment": "ACL 2025", "pdf_url": "http://arxiv.org/pdf/2507.01702v1", "categories": ["cs.CL", "cs.AI"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01702v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "AdamMeme：自适应探测多模态大型语言模型在有害性方面的推理能力", "tldr": "AdamMeme是一个灵活的、基于代理的评估框架，用于自适应地探测多模态大型语言模型（mLLMs）在理解有害梗图方面的推理能力，通过迭代更新挑战性样本来暴露模型局限性。", "motivation": "现有评估多模态大型语言模型（mLLMs）理解有害梗图能力的基准依赖于基于准确性、与模型无关的静态数据集评估。这些基准在提供最新和彻底评估方面存在局限性，因为在线梗图动态演变，无法充分评估mLLMs对有害梗图的理解能力。", "method": "我们提出了AdamMeme，一个灵活的、基于代理的评估框架，通过多代理协作，自适应地探测mLLMs在理解梗图有害性方面的推理能力。AdamMeme通过迭代更新具有挑战性样本的梗图数据，从而暴露mLLMs在解释有害性方面的具体局限性，提供全面的评估。", "result": "大量实验表明，AdamMeme框架系统地揭示了不同目标mLLMs的不同性能，提供了模型特定弱点的深入、细粒度分析。", "conclusion": "AdamMeme框架能够系统地揭示多模态大型语言模型在理解有害梗图方面的具体局限性和不同性能，为模型特定弱点提供了深入的分析。", "translation": "在社交媒体时代，多模态梗图的激增要求多模态大型语言模型（mLLMs）有效理解梗图的有害性。现有评估mLLMs理解有害梗图能力的基准依赖于基于准确性、与模型无关的静态数据集评估。这些基准在提供最新和彻底评估方面存在局限性，因为在线梗图动态演变。为了解决这个问题，我们提出了AdamMeme，一个灵活的、基于代理的评估框架，用于自适应地探测mLLMs在理解梗图有害性方面的推理能力。通过多代理协作，AdamMeme通过迭代更新具有挑战性样本的梗图数据，从而暴露mLLMs在解释有害性方面的具体局限性，提供全面的评估。大量实验表明，我们的框架系统地揭示了不同目标mLLMs的不同性能，提供了模型特定弱点的深入、细粒度分析。我们的代码可在https://github.com/Lbotirx/AdamMeme获取。", "summary": "AdamMeme是一个创新的、基于代理的评估框架，旨在解决现有基准在评估多模态大型语言模型（mLLMs）理解动态演变的有害梗图方面的局限性。该框架通过多代理协作，自适应地迭代更新挑战性样本，从而深入探测mLLMs的推理能力，并揭示其在解释有害性方面的具体弱点和性能差异。", "keywords": "多模态大型语言模型, 有害梗图, 自适应评估, 代理框架, 推理能力", "comments": "AdamMeme的创新之处在于其自适应、基于代理的评估方法，这优于传统的静态数据集评估。通过动态更新挑战性样本，它能更有效地揭示mLLMs在理解有害梗图方面的细微缺陷和局限性，对于提升mLLMs的鲁棒性和安全性具有重要意义。"}}
{"id": "2507.01932", "title": "A first-order method for nonconvex-nonconcave minimax problems under a local Kurdyka-Łojasiewicz condition", "authors": ["Zhaosong Lu", "Xiangyuan Wang"], "summary": "We study a class of nonconvex-nonconcave minimax problems in which the inner\nmaximization problem satisfies a local Kurdyka-{\\L}ojasiewicz (KL) condition\nthat may vary with the outer minimization variable. In contrast to the global\nKL or Polyak-{\\L}ojasiewicz (PL) conditions commonly assumed in the literature\n-- which are significantly stronger and often too restrictive in practice --\nthis local KL condition accommodates a broader range of practical scenarios.\nHowever, it also introduces new analytical challenges. In particular, as an\noptimization algorithm progresses toward a stationary point of the problem, the\nregion over which the KL condition holds may shrink, resulting in a more\nintricate and potentially ill-conditioned landscape. To address this challenge,\nwe show that the associated maximal function is locally H\\\"older smooth.\nLeveraging this key property, we develop an inexact proximal gradient method\nfor solving the minimax problem, where the inexact gradient of the maximal\nfunction is computed by applying a proximal gradient method to a KL-structured\nsubproblem. Under mild assumptions, we establish complexity guarantees for\ncomputing an approximate stationary point of the minimax problem.", "comment": "26 pages", "pdf_url": "http://arxiv.org/pdf/2507.01932v1", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA", "stat.ML", "90C26, 90C30, 90C47, 90C99, 65K05"], "cate": "math.OC", "url": "http://arxiv.org/abs/2507.01932v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "一种在局部Kurdyka-Łojasiewicz条件下解决非凸非凹极小极大问题的一阶方法", "tldr": "本文提出了一种在一类局部KL条件下解决非凸非凹极小极大问题的一阶方法，并给出了复杂度保证，解决了现有全局条件过于严格的问题。", "motivation": "现有文献中常用的全局Kurdyka-Łojasiewicz (KL) 或 Polyak-Łojasiewicz (PL) 条件过于严格且不适用于实际场景。局部KL条件能适应更广泛的实际情况，但引入了新的分析挑战，如KL条件区域可能收缩导致病态景观。", "method": "证明了相关的最大函数是局部H\"older光滑的。利用这一性质，开发了一种求解极小极大问题的不精确近端梯度方法，其中最大函数的不精确梯度通过对KL结构子问题应用近端梯度方法来计算。", "result": "在温和假设下，为计算极小极大问题的近似驻点建立了复杂度保证。", "conclusion": "本文提出了一种有效解决局部KL条件下非凸非凹极小极大问题的一阶方法，并提供了理论复杂度保证，克服了传统全局条件限制，扩展了适用范围。", "translation": "我们研究了一类非凸非凹的极小极大问题，其中内部最大化问题满足局部Kurdyka-Łojasiewicz (KL) 条件，该条件可能随外部最小化变量而变化。与文献中普遍假设的全局KL或Polyak-Łojasiewicz (PL) 条件（这些条件明显更强且在实践中往往过于严格）相比，这种局部KL条件适应了更广泛的实际场景。然而，它也引入了新的分析挑战。特别是，随着优化算法向问题的驻点进展，KL条件成立的区域可能会缩小，导致更复杂且可能病态的景观。为了应对这一挑战，我们证明了相关的最大函数是局部H\"older光滑的。利用这一关键性质，我们开发了一种求解极小极大问题的不精确近端梯度方法，其中最大函数的不精确梯度通过对KL结构子问题应用近端梯度方法来计算。在温和假设下，我们为计算极小极大问题的近似驻点建立了复杂度保证。", "summary": "本文研究了一类内部最大化满足局部Kurdyka-Łojasiewicz (KL) 条件的非凸非凹极小极大问题。针对局部KL条件引入的分析挑战，特别是KL区域可能收缩的问题，作者证明了相关最大函数是局部H\"older光滑的。基于此，提出了一种不精确近端梯度方法，通过求解KL结构子问题来计算最大函数的不精确梯度。该方法在温和假设下，能够为计算极小极大问题的近似驻点提供复杂度保证，从而克服了现有全局KL/PL条件过于严格的局限性。", "keywords": "极小极大问题, 非凸非凹, 局部Kurdyka-Łojasiewicz条件, 一阶方法, 复杂度分析", "comments": "本文的创新点在于将Kurdyka-Łojasiewicz条件从全局推广到局部，使其更适用于实际非凸非凹极小极大问题，解决了传统方法过于严格的限制。其通过证明最大函数的局部H\"older光滑性，并设计相应的不精确近端梯度方法，为这类复杂问题提供了理论上可行的解决方案，并给出了复杂度保证，具有重要的理论和实践意义。"}}
{"id": "2507.01930", "title": "Large Language Model-Driven Closed-Loop UAV Operation with Semantic Observations", "authors": ["Wenhao Wang", "Yanyan Li", "Long Jiao", "Jiawei Yuan"], "summary": "Large Language Models (LLMs) have revolutionized robotic autonomy, including\nUnmanned Aerial Vehicles (UAVs). Recent studies have demonstrated the potential\nof LLMs for translating human instructions into executable control code for UAV\noperations. However, LLMs still face challenges from logical reasoning and\ncomplex decision-making, leading to concerns about the reliability of\nLLM-driven UAV operations. In this paper, we propose a LLM-driven closed-loop\ncontrol framework that enables reliable UAV operations powered by effective\nfeedback and refinement using two LLM modules, i.e., a Code Generator and an\nEvaluator. Our framework transforms numerical state observations from UAV\noperations into natural language trajectory descriptions to enhance the\nevaluator LLM's understanding of UAV dynamics for precise feedback generation.\nOur framework also enables a simulation-based refinement process, and hence\neliminates the risks to physical UAVs caused by incorrect code execution during\nthe refinement. Extensive experiments on UAV control tasks with different\ncomplexities are conducted. The experimental results show that our framework\ncan achieve reliable UAV operations using LLMs, which significantly outperforms\nbaseline approaches in terms of success rate and completeness with the increase\nof task complexity.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.01930v1", "categories": ["cs.RO"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01930v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "大型语言模型驱动的语义观测闭环无人机操作", "tldr": "提出一个LLM驱动的闭环控制框架，通过语义反馈和仿真优化提升无人机操作的可靠性，显著优于现有方法。", "motivation": "尽管LLMs在UAV控制方面有潜力，但其在逻辑推理和复杂决策方面的挑战导致LLM驱动的UAV操作可靠性存在问题。", "method": "本文提出一个LLM驱动的闭环控制框架，包含代码生成器和评估器两个LLM模块。该框架将UAV操作的数值状态观测转换为自然语言轨迹描述，以增强评估器LLM对UAV动态的理解，并支持基于仿真的优化过程，避免对物理无人机的风险。", "result": "实验结果表明，该框架能够实现可靠的LLM驱动无人机操作，在任务复杂性增加时，其成功率和完成度显著优于基线方法。", "conclusion": "所提出的LLM驱动闭环控制框架通过有效的反馈和优化，显著提高了无人机操作的可靠性。", "translation": "大型语言模型（LLMs）彻底改变了包括无人机（UAVs）在内的机器人自主性。最近的研究已经证明了LLMs将人类指令转化为无人机操作可执行控制代码的潜力。然而，LLMs在逻辑推理和复杂决策方面仍然面临挑战，这导致人们对LLM驱动的无人机操作的可靠性产生担忧。在本文中，我们提出了一种LLM驱动的闭环控制框架，该框架通过使用两个LLM模块（即代码生成器和评估器）的有效反馈和改进，实现了可靠的无人机操作。我们的框架将无人机操作的数值状态观测转换为自然语言轨迹描述，以增强评估器LLM对无人机动态的理解，从而生成精确的反馈。我们的框架还支持基于仿真的改进过程，从而消除了在改进过程中因不正确的代码执行对物理无人机造成的风险。我们对不同复杂度的无人机控制任务进行了广泛的实验。实验结果表明，我们的框架能够使用LLM实现可靠的无人机操作，在任务复杂性增加时，其成功率和完成度显著优于基线方法。", "summary": "本文提出了一个大型语言模型（LLM）驱动的闭环控制框架，旨在解决LLM在无人机（UAV）操作中逻辑推理和复杂决策带来的可靠性问题。该框架包含代码生成器和评估器两个LLM模块，通过将数值观测转换为自然语言描述来增强评估器对UAV动态的理解，从而生成精确反馈。此外，框架采用仿真优化过程以避免物理风险。实验证明，该框架在成功率和完成度方面显著优于现有方法，尤其是在任务复杂度增加时，实现了可靠的LLM驱动UAV操作。", "keywords": "大型语言模型, 无人机, 闭环控制, 语义观测, 机器人自主性", "comments": "这篇论文的创新点在于提出了一个LLM驱动的闭环控制框架，通过引入评估器LLM对语义化观测进行反馈和基于仿真的优化，有效提升了LLM驱动无人机操作的可靠性。将数值状态转换为自然语言轨迹描述，提升了LLM对复杂动态的理解能力，是其关键的创新方法。仿真优化过程的引入也有效地降低了实际部署的风险。"}}
{"id": "2507.01752", "title": "Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training", "authors": ["Ismail Labiad", "Mathurin Videau", "Matthieu Kowalski", "Marc Schoenauer", "Alessandro Leite", "Julia Kempe", "Olivier Teytaud"], "summary": "Gradient-based optimization is the workhorse of deep learning, offering\nefficient and scalable training via backpropagation. However, its reliance on\nlarge volumes of labeled data raises privacy and security concerns such as\nsusceptibility to data poisoning attacks and the risk of overfitting. In\ncontrast, black box optimization methods, which treat the model as an opaque\nfunction, relying solely on function evaluations to guide optimization, offer a\npromising alternative in scenarios where data access is restricted, adversarial\nrisks are high, or overfitting is a concern. However, black box methods also\npose significant challenges, including poor scalability to high-dimensional\nparameter spaces, as prevalent in large language models (LLMs), and high\ncomputational costs due to reliance on numerous model evaluations. This paper\nintroduces BBoxER, an evolutionary black-box method for LLM post-training that\ninduces an information bottleneck via implicit compression of the training\ndata. Leveraging the tractability of information flow, we provide strong\ntheoretical bounds on generalization, differential privacy, susceptibility to\ndata poisoning attacks, and robustness to extraction attacks. BBoxER operates\non top of pre-trained LLMs, offering a lightweight and modular enhancement\nsuitable for deployment in restricted or privacy-sensitive environments, in\naddition to non-vacuous generalization guarantees. In experiments with LLMs, we\ndemonstrate empirically that Retrofitting methods are able to learn, showing\nhow a few iterations of BBoxER improve performance and generalize well on a\nbenchmark of reasoning datasets. This positions BBoxER as an attractive add-on\non top of gradient-based optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01752v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01752v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "不窥视的微调：LLM 后训练的可证明隐私和泛化界限", "tldr": "本文提出BBoxER，一种用于LLM后训练的进化黑盒方法，它在不窥探数据的情况下提供可证明的隐私和泛化保证，并实证验证了其在提高LLM性能和泛化能力方面的有效性。", "motivation": "梯度优化是深度学习的基石，但其对大量数据的依赖导致隐私和安全问题，如数据投毒和过拟合。黑盒优化虽能解决数据访问受限等问题，但对大型语言模型（LLM）等高维参数空间的可扩展性和计算成本存在挑战。", "method": "本文引入了BBoxER，一种用于LLM后训练的进化黑盒方法。它通过隐式压缩训练数据来诱导信息瓶颈，并利用信息流的可处理性，提供了关于泛化、差分隐私、数据投毒攻击易感性和提取攻击鲁棒性的强理论界限。BBoxER在预训练LLM之上运行，提供轻量级和模块化的增强。", "result": "实验表明，BBoxER能够有效提高LLM的性能，并在推理数据集基准上展现出良好的泛化能力，证明了其作为梯度优化补充的有效性。", "conclusion": "BBoxER是一种轻量级、模块化的LLM后训练增强方案，适用于受限或隐私敏感环境，并提供可证明的隐私和泛化保证，使其成为梯度优化方法的有吸引力的补充。", "translation": "梯度优化是深度学习的基石，通过反向传播提供高效和可扩展的训练。然而，它对大量标记数据的依赖带来了隐私和安全问题，例如对数据投毒攻击的易感性和过拟合的风险。相比之下，黑盒优化方法将模型视为不透明函数，仅依靠函数评估来指导优化，在数据访问受限、对抗风险高或存在过拟合问题的情况下提供了一个有前景的替代方案。然而，黑盒方法也带来了重大挑战，包括对高维参数空间（如大型语言模型（LLM）中普遍存在）的可扩展性差，以及由于依赖大量模型评估而导致的高计算成本。本文介绍了BBoxER，一种用于LLM后训练的进化黑盒方法，它通过训练数据的隐式压缩诱导信息瓶颈。利用信息流的可处理性，我们提供了关于泛化、差分隐私、对数据投毒攻击的易感性以及对提取攻击的鲁棒性的强理论界限。BBoxER在预训练的LLM之上运行，提供了一种轻量级和模块化的增强功能，适用于在受限或隐私敏感环境中部署，此外还提供了非空泛化保证。在LLM的实验中，我们凭经验证明，Retrofitting方法能够学习，展示了BBoxER的几次迭代如何提高性能并在推理数据集基准上泛化良好。这使得BBoxER成为梯度优化之上一个有吸引力的附加组件。", "summary": "本文针对梯度优化在LLM后训练中面临的隐私、安全及黑盒优化自身的可扩展性问题，提出了一种名为BBoxER的进化黑盒方法。BBoxER通过信息瓶颈实现数据隐式压缩，并提供可证明的泛化、差分隐私和对抗攻击鲁棒性。实验证明，BBoxER能有效提升LLM性能并泛化良好，是梯度优化的一种有吸引力的补充。", "keywords": "LLM后训练, 黑盒优化, 隐私保护, 泛化界限, BBoxER", "comments": "本文的创新点在于提出了BBoxER，一种新型的黑盒优化方法，专门针对LLM的后训练，解决了传统梯度优化在隐私和安全方面的痛点，同时克服了传统黑盒方法在处理高维LLM参数空间时的可扩展性问题。其通过信息瓶颈实现隐式数据压缩，并提供严格的理论保证（隐私、泛化、鲁棒性），这在实际应用中具有重要意义，尤其是在数据敏感或资源受限的环境中。其轻量级和模块化的特性也增加了其实用性。"}}
{"id": "2507.01422", "title": "DocShaDiffusion: Diffusion Model in Latent Space for Document Image Shadow Removal", "authors": ["Wenjie Liu", "Bingshu Wang", "Ze Wang", "C. L. Philip Chen"], "summary": "Document shadow removal is a crucial task in the field of document image\nenhancement. However, existing methods tend to remove shadows with constant\ncolor background and ignore color shadows. In this paper, we first design a\ndiffusion model in latent space for document image shadow removal, called\nDocShaDiffusion. It translates shadow images from pixel space to latent space,\nenabling the model to more easily capture essential features. To address the\nissue of color shadows, we design a shadow soft-mask generation module (SSGM).\nIt is able to produce accurate shadow mask and add noise into shadow regions\nspecially. Guided by the shadow mask, a shadow mask-aware guided diffusion\nmodule (SMGDM) is proposed to remove shadows from document images by\nsupervising the diffusion and denoising process. We also propose a\nshadow-robust perceptual feature loss to preserve details and structures in\ndocument images. Moreover, we develop a large-scale synthetic document color\nshadow removal dataset (SDCSRD). It simulates the distribution of realistic\ncolor shadows and provides powerful supports for the training of models.\nExperiments on three public datasets validate the proposed method's superiority\nover state-of-the-art. Our code and dataset will be publicly available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01422v1", "categories": ["cs.CV", "cs.AI"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01422v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "DocShaDiffusion：潜在空间扩散模型用于文档图像去阴影", "tldr": "DocShaDiffusion提出了一种基于潜在空间扩散模型的文档图像去阴影方法，通过设计阴影软掩码生成和掩码引导扩散模块，并构建大规模合成数据集，有效解决了现有方法在处理彩色阴影和细节保留方面的不足，并在多个公开数据集上取得了SOTA性能。", "motivation": "现有的文档图像去阴影方法倾向于去除恒定颜色背景上的阴影，并忽略彩色阴影。", "method": "本文提出了一种名为DocShaDiffusion的潜在空间扩散模型用于文档图像去阴影。它将阴影图像从像素空间转换到潜在空间，以便模型更容易捕获基本特征。为了解决彩色阴影问题，设计了一个阴影软掩码生成模块（SSGM），能够生成准确的阴影掩码并专门向阴影区域添加噪声。在阴影掩码的引导下，提出了一个阴影掩码感知引导扩散模块（SMGDM），通过监督扩散和去噪过程来去除文档图像中的阴影。此外，还提出了一种阴影鲁棒感知特征损失来保留文档图像中的细节和结构。研究人员还开发了一个大规模合成文档彩色阴影去除数据集（SDCSRD），它模拟了真实彩色阴影的分布，并为模型训练提供了强大的支持。", "result": "在三个公开数据集上的实验验证了所提出方法优于现有最先进方法。", "conclusion": "DocShaDiffusion在文档图像去阴影方面表现出优越性，特别是在处理彩色阴影和保留细节方面，并得到了大规模合成数据集的支持。", "translation": "文档阴影去除是文档图像增强领域的一项关键任务。然而，现有方法倾向于去除恒定颜色背景上的阴影，并忽略彩色阴影。在本文中，我们首次设计了一种用于文档图像阴影去除的潜在空间扩散模型，名为DocShaDiffusion。它将阴影图像从像素空间转换到潜在空间，使模型更容易捕获基本特征。为了解决彩色阴影问题，我们设计了一个阴影软掩码生成模块（SSGM）。它能够生成准确的阴影掩码，并专门向阴影区域添加噪声。在阴影掩码的引导下，提出了一个阴影掩码感知引导扩散模块（SMGDM），通过监督扩散和去噪过程来去除文档图像中的阴影。我们还提出了一种阴影鲁棒感知特征损失，以保留文档图像中的细节和结构。此外，我们开发了一个大规模合成文档彩色阴影去除数据集（SDCSRD）。它模拟了真实彩色阴影的分布，并为模型训练提供了强大的支持。在三个公开数据集上的实验验证了所提出方法优于现有最先进方法。我们的代码和数据集将公开可用。", "summary": "DocShaDiffusion是一种新颖的潜在空间扩散模型，专为文档图像去阴影而设计，旨在解决现有方法在处理彩色阴影和细节保留方面的不足。该模型通过将图像映射到潜在空间以捕获关键特征，并引入阴影软掩码生成模块（SSGM）和阴影掩码感知引导扩散模块（SMGDM）来精确去除阴影。此外，提出了一种阴影鲁棒感知特征损失以保护图像细节，并构建了一个大规模合成彩色阴影数据集（SDCSRD）来支持模型训练。实验证明，该方法在多个公开数据集上优于现有最先进技术。", "keywords": "文档去阴影, 扩散模型, 潜在空间, 彩色阴影, 图像增强", "comments": "该论文的创新点在于首次将扩散模型引入文档图像去阴影任务的潜在空间，并针对彩色阴影问题设计了专门的模块（SSGM和SMGDM）。此外，构建大规模合成数据集（SDCSRD）为该领域的研究提供了宝贵的资源，有效解决了真实彩色阴影数据稀缺的问题，对于推动文档图像增强技术的发展具有重要意义。"}}
{"id": "2507.01068", "title": "Prediction of Freezing of Gait in Parkinsons Disease using Explainable AI and Federated Deep Learning for Wearable Sensors", "authors": ["Biplov Paneru"], "summary": "This study leverages an Inertial Measurement Unit (IMU) dataset to develop\nexplainable AI methods for the early detection and prediction of Freezing of\nGait (FOG), a common symptom in Parkinson's disease. Machine learning models,\nincluding CatBoost, XGBoost, and Extra Trees classifiers, are employed to\naccurately categorize FOG episodes based on relevant clinical features. A\nStacking Ensemble model achieves superior performance, surpassing a hybrid\nbidirectional GRU model and reaching nearly 99% classification accuracy. SHAP\ninterpretability analysis reveals that time (seconds) is the most influential\nfactor in distinguishing gait patterns. Additionally, the proposed FOG\nprediction framework incorporates federated learning, where models are trained\nlocally on individual devices and aggregated on a central server using a\nfederated averaging approach, utilizing a hybrid Conv1D + LSTM architecture for\nenhanced predictive capability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01068v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01068v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "帕金森病步态冻结的可解释AI与联邦深度学习预测，基于可穿戴传感器", "tldr": "本研究利用可穿戴传感器数据，结合可解释AI和联邦深度学习，实现了帕金森病步态冻结的早期检测和高精度预测。", "motivation": "早期检测和预测帕金森病患者常见的步态冻结（FOG）症状。", "method": "本研究利用惯性测量单元（IMU）数据集，采用CatBoost、XGBoost和Extra Trees等机器学习分类器以及Stacking Ensemble模型进行FOG发作分类。同时，通过SHAP可解释性分析识别关键影响因素。此外，研究还提出了一个结合联邦学习和混合Conv1D + LSTM架构的FOG预测框架，模型在本地设备训练后通过联邦平均在中央服务器聚合。", "result": "Stacking Ensemble模型在FOG分类上表现出色，分类准确率接近99%，优于混合双向GRU模型。SHAP可解释性分析显示，“时间（秒）”是区分步态模式最有影响的因素。", "conclusion": "该研究成功开发了一种基于可穿戴传感器、结合可解释AI和联邦深度学习的FOG预测框架，实现了高精度预测，并揭示了关键影响因素，为帕金森病步态冻结的早期干预提供了潜在解决方案。", "translation": "本研究利用惯性测量单元（IMU）数据集，开发了可解释人工智能方法，用于早期检测和预测帕金森病常见的步态冻结（FOG）症状。研究采用包括CatBoost、XGBoost和Extra Trees分类器在内的机器学习模型，根据相关临床特征准确分类FOG发作。一个堆叠集成模型取得了卓越的性能，超越了混合双向GRU模型，分类准确率接近99%。SHAP可解释性分析揭示，时间（秒）是区分步态模式最有影响的因素。此外，所提出的FOG预测框架结合了联邦学习，模型在个体设备上本地训练，并使用联邦平均方法在中央服务器上进行聚合，利用混合Conv1D + LSTM架构增强预测能力。", "summary": "本研究基于IMU可穿戴传感器数据，开发了一套结合可解释AI和联邦深度学习的帕金森病步态冻结（FOG）预测框架。通过使用Stacking Ensemble模型实现了近99%的FOG分类准确率，并利用SHAP分析发现时间是关键影响因素。该框架还创新性地整合了联邦学习与Conv1D+LSTM混合架构，以提升预测能力，旨在实现FOG的早期检测和预测。", "keywords": "步态冻结预测, 帕金森病, 可解释AI, 联邦学习, 可穿戴传感器", "comments": "本研究的创新点在于将可解释AI（SHAP）与联邦学习相结合应用于帕金森病步态冻结的预测。这不仅提升了模型的预测精度，还增强了模型的可解释性，有助于理解FOG的关键影响因素，并能在保护患者隐私的前提下进行模型训练。其重要性在于为帕金森病患者的FOG早期预警提供了高精度、可解释且符合隐私保护的新方法。抽象中未提及数据集的规模、来源以及模型在真实世界环境中的验证情况，这些可能是未来研究需要关注的潜在局限性。"}}
{"id": "2507.01715", "title": "Stereotype Detection as a Catalyst for Enhanced Bias Detection: A Multi-Task Learning Approach", "authors": ["Aditya Tomar", "Rudra Murthy", "Pushpak Bhattacharyya"], "summary": "Bias and stereotypes in language models can cause harm, especially in\nsensitive areas like content moderation and decision-making. This paper\naddresses bias and stereotype detection by exploring how jointly learning these\ntasks enhances model performance. We introduce StereoBias, a unique dataset\nlabeled for bias and stereotype detection across five categories: religion,\ngender, socio-economic status, race, profession, and others, enabling a deeper\nstudy of their relationship. Our experiments compare encoder-only models and\nfine-tuned decoder-only models using QLoRA. While encoder-only models perform\nwell, decoder-only models also show competitive results. Crucially, joint\ntraining on bias and stereotype detection significantly improves bias detection\ncompared to training them separately. Additional experiments with sentiment\nanalysis confirm that the improvements stem from the connection between bias\nand stereotypes, not multi-task learning alone. These findings highlight the\nvalue of leveraging stereotype information to build fairer and more effective\nAI systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01715v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01715v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "刻板印象检测作为增强偏见检测的催化剂：一种多任务学习方法", "tldr": "通过多任务学习联合检测刻板印象和偏见，能显著提升偏见检测性能。", "motivation": "语言模型中的偏见和刻板印象可能造成危害，尤其是在内容审核和决策等敏感领域。", "method": "引入了StereoBias数据集（包含宗教、性别、社会经济地位、种族、职业等五类偏见和刻板印象标签），并比较了编码器-only模型和使用QLoRA微调的解码器-only模型。通过多任务学习联合训练偏见和刻板印象检测任务，并额外进行了情感分析实验以验证改进来源。", "result": "联合训练显著提高了偏见检测性能；解码器-only模型表现出竞争力；性能提升源于偏见和刻板印象之间的关联，而非单纯的多任务学习。", "conclusion": "利用刻板印象信息对于构建更公平、更有效的AI系统具有重要价值。", "translation": "语言模型中的偏见和刻板印象可能造成危害，尤其是在内容审核和决策等敏感领域。本文通过探索如何联合学习偏见和刻板印象检测任务来提升模型性能，从而解决偏见和刻板印象检测问题。我们引入了一个独特的StereoBias数据集，该数据集针对偏见和刻板印象检测进行了标注，涵盖宗教、性别、社会经济地位、种族、职业和其他五类，从而能够更深入地研究它们之间的关系。我们的实验比较了编码器-only模型和使用QLoRA微调的解码器-only模型。虽然编码器-only模型表现良好，但解码器-only模型也显示出竞争力。至关重要的是，与单独训练相比，偏见和刻板印象检测的联合训练显著提高了偏见检测的性能。对情感分析的额外实验证实，这些改进源于偏见和刻板印象之间的联系，而不仅仅是多任务学习本身。这些发现突出了利用刻板印象信息来构建更公平、更有效的AI系统的价值。", "summary": "本文研究了通过多任务学习联合检测语言模型中的偏见和刻板印象如何提升模型性能。研究引入了StereoBias数据集，用于深入探讨偏见与刻板印象的关系。实验结果表明，联合训练显著提高了偏见检测的准确性，且解码器-only模型表现出竞争力。此外，研究证实性能提升主要归因于偏见与刻板印象间的内在联系，强调了利用刻板印象信息构建公平AI系统的重要性。", "keywords": "偏见检测, 刻板印象检测, 多任务学习, 语言模型, StereoBias", "comments": "本文的创新点在于提出了将刻板印象检测作为偏见检测的催化剂，通过多任务学习框架显著提升了偏见检测的性能。其重要性体现在为构建更公平的AI系统提供了有效途径，特别是在处理敏感内容和决策方面。引入的StereoBias数据集也为后续研究提供了宝贵的资源。"}}
{"id": "2507.01961", "title": "AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation", "authors": ["Sixiang Chen", "Jiaming Liu", "Siyuan Qian", "Han Jiang", "Lily Li", "Renrui Zhang", "Zhuoyang Liu", "Chenyang Gu", "Chengkai Hou", "Pengwei Wang", "Zhongyuan Wang", "Shanghang Zhang"], "summary": "Recently, mobile manipulation has attracted increasing attention for enabling\nlanguage-conditioned robotic control in household tasks. However, existing\nmethods still face challenges in coordinating mobile base and manipulator,\nprimarily due to two limitations. On the one hand, they fail to explicitly\nmodel the influence of the mobile base on manipulator control, which easily\nleads to error accumulation under high degrees of freedom. On the other hand,\nthey treat the entire mobile manipulation process with the same visual\nobservation modality (e.g., either all 2D or all 3D), overlooking the distinct\nmultimodal perception requirements at different stages during mobile\nmanipulation. To address this, we propose the Adaptive Coordination Diffusion\nTransformer (AC-DiT), which enhances mobile base and manipulator coordination\nfor end-to-end mobile manipulation. First, since the motion of the mobile base\ndirectly influences the manipulator's actions, we introduce a mobility-to-body\nconditioning mechanism that guides the model to first extract base motion\nrepresentations, which are then used as context prior for predicting whole-body\nactions. This enables whole-body control that accounts for the potential impact\nof the mobile base's motion. Second, to meet the perception requirements at\ndifferent stages of mobile manipulation, we design a perception-aware\nmultimodal conditioning strategy that dynamically adjusts the fusion weights\nbetween various 2D visual images and 3D point clouds, yielding visual features\ntailored to the current perceptual needs. This allows the model to, for\nexample, adaptively rely more on 2D inputs when semantic information is crucial\nfor action prediction, while placing greater emphasis on 3D geometric\ninformation when precise spatial understanding is required. We validate AC-DiT\nthrough extensive experiments on both simulated and real-world mobile\nmanipulation tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01961v1", "categories": ["cs.RO", "cs.AI"], "cate": "cs.RO", "url": "http://arxiv.org/abs/2507.01961v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "AC-DiT：用于移动操作的自适应协调扩散Transformer", "tldr": "AC-DiT提出一种新的扩散Transformer，通过引入移动基座条件化机制和感知感知的多模态条件化策略，解决了现有移动操作方法在基座与机械臂协调和多模态感知方面的挑战。", "motivation": "现有移动操作方法在协调移动基座和机械臂时面临挑战，主要原因有两点：1) 未能明确建模移动基座对机械臂控制的影响，导致高自由度下误差累积；2) 使用单一视觉观察模态，忽视了不同阶段对多模态感知的不同需求。", "method": "提出了自适应协调扩散Transformer (AC-DiT)。该方法包含两个主要机制：1) “移动到身体”条件化机制，首先提取基座运动表示作为上下文先验，指导全身动作预测，从而实现考虑基座运动影响的全身控制。2) 感知感知的多模态条件化策略，动态调整2D图像和3D点云之间的融合权重，根据当前感知需求生成定制的视觉特征，例如在需要语义信息时侧重2D输入，在需要精确空间理解时侧重3D信息。", "result": "AC-DiT在模拟和真实世界的移动操作任务中通过了广泛的实验验证。", "conclusion": "该研究通过提出AC-DiT，有效提升了移动基座和机械臂的协调能力，解决了当前移动操作中的关键挑战，并在模拟和真实环境中展现了其有效性。", "translation": "最近，移动操作因其在家庭任务中实现语言条件下的机器人控制而受到越来越多的关注。然而，现有方法在协调移动基座和机械臂方面仍然面临挑战，主要原因有两点。一方面，它们未能明确建模移动基座对机械臂控制的影响，这在高自由度下容易导致误差累积。另一方面，它们以相同的视觉观察模态（例如，全部2D或全部3D）处理整个移动操作过程，忽视了移动操作不同阶段对多模态感知的独特需求。\n为了解决这些问题，我们提出了自适应协调扩散Transformer（AC-DiT），它增强了移动基座和机械臂的协调能力，以实现端到端的移动操作。首先，由于移动基座的运动直接影响机械臂的动作，我们引入了一种“移动到身体”的条件化机制，引导模型首先提取基座运动表示，然后将其用作预测全身动作的上下文先验。这使得全身控制能够考虑移动基座运动的潜在影响。其次，为了满足移动操作不同阶段的感知需求，我们设计了一种感知感知的多模态条件化策略，动态调整各种2D视觉图像和3D点云之间的融合权重，从而产生适合当前感知需求的视觉特征。例如，当语义信息对动作预测至关重要时，模型可以自适应地更多地依赖2D输入，而在需要精确空间理解时，则更强调3D几何信息。我们通过在模拟和真实世界的移动操作任务中进行广泛实验验证了AC-DiT。", "summary": "本文提出了AC-DiT（自适应协调扩散Transformer），旨在解决现有移动操作方法在移动基座与机械臂协调以及多模态感知方面的不足。AC-DiT引入了“移动到身体”条件化机制，将基座运动作为上下文先验来指导全身动作预测，并设计了感知感知的多模态条件化策略，动态融合2D和3D视觉信息以适应不同阶段的感知需求。实验结果验证了AC-DiT在模拟和真实世界任务中的有效性。", "keywords": "移动操作, 扩散Transformer, 机器人控制, 多模态感知, 协调控制", "comments": "AC-DiT的创新之处在于其双重协调策略：一是通过“移动到身体”条件化机制明确建模基座对机械臂的影响，解决了高自由度下的误差累积问题；二是通过动态多模态融合解决了不同操作阶段感知需求差异的问题。这使得模型能够更智能地处理复杂的移动操作任务，是机器人控制领域的重要进展。"}}
{"id": "2507.01073", "title": "Rotational Sampling: A Plug-and-Play Encoder for Rotation-Invariant 3D Molecular GNNs", "authors": ["Dian Jin"], "summary": "Graph neural networks (GNNs) have achieved remarkable success in molecular\nproperty prediction. However, traditional graph representations struggle to\neffectively encode the inherent 3D spatial structures of molecules, as\nmolecular orientations in 3D space introduce significant variability, severely\nlimiting model generalization and robustness. Existing approaches primarily\nfocus on rotation-invariant and rotation-equivariant methods. Invariant methods\noften rely heavily on prior knowledge and lack sufficient generalizability,\nwhile equivariant methods suffer from high computational costs. To address\nthese limitations, this paper proposes a novel plug-and-play 3D encoding module\nleveraging rotational sampling. By computing the expectation over the SO(3)\nrotational group, the method naturally achieves approximate rotational\ninvariance. Furthermore, by introducing a carefully designed post-alignment\nstrategy, strict invariance can be achieved without compromising performance.\nExperimental evaluations on the QM9 and C10 Datasets demonstrate superior\npredictive accuracy, robustness, and generalization performance compared to\nexisting methods. Moreover, the proposed approach maintains low computational\ncomplexity and enhanced interpretability, providing a promising direction for\nefficient and effective handling of 3D molecular information in drug discovery\nand material design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01073v1", "categories": ["cs.LG", "q-bio.BM"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01073v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "旋转采样：一种用于旋转不变性3D分子图神经网络的即插即用编码器", "tldr": "本文提出了一种基于旋转采样的即插即用3D编码模块，通过近似和严格的旋转不变性，显著提高了3D分子图神经网络的预测性能，同时保持低计算成本。", "motivation": "传统图神经网络难以有效编码分子固有的3D空间结构，因为3D空间中分子方向引入显著变异性，严重限制模型泛化和鲁棒性。现有旋转不变性方法依赖先验知识且泛化性不足，而旋转等变性方法计算成本高。", "method": "提出一种新颖的即插即用3D编码模块，利用旋转采样。通过计算SO(3)旋转群上的期望，自然实现近似旋转不变性。引入精心设计的后对齐策略，在不影响性能的情况下实现严格不变性。", "result": "在QM9和C10数据集上，预测准确性、鲁棒性和泛化性能优于现有方法。保持低计算复杂度并增强可解释性。", "conclusion": "为药物发现和材料设计中高效、有效地处理3D分子信息提供了一个有前景的方向。", "translation": "图神经网络（GNN）在分子性质预测方面取得了显著成功。然而，传统的图表示难以有效编码分子固有的3D空间结构，因为3D空间中分子方向引入了显著的变异性，严重限制了模型的泛化能力和鲁棒性。现有方法主要关注旋转不变性和旋转等变性方法。不变性方法通常严重依赖先验知识，缺乏足够的泛化性，而等变性方法则面临高计算成本。为了解决这些局限性，本文提出了一种利用旋转采样的即插即用新型3D编码模块。通过计算SO(3)旋转群上的期望，该方法自然地实现了近似旋转不变性。此外，通过引入精心设计的后对齐策略，可以在不影响性能的情况下实现严格的不变性。在QM9和C10数据集上的实验评估表明，与现有方法相比，该方法具有卓越的预测准确性、鲁棒性和泛化性能。此外，所提出的方法保持了低计算复杂度并增强了可解释性，为药物发现和材料设计中高效、有效地处理3D分子信息提供了有前景的方向。", "summary": "本文针对图神经网络在分子性质预测中难以有效编码3D空间结构的问题，提出了一种基于旋转采样的即插即用3D编码模块。该模块通过计算SO(3)旋转群上的期望实现近似旋转不变性，并通过后对齐策略实现严格不变性。实验证明，该方法在提高预测准确性、鲁棒性和泛化能力的同时，保持了低计算成本和高可解释性，为3D分子信息处理提供了新途径。", "keywords": "旋转采样, 3D分子, 图神经网络, 旋转不变性, 即插即用", "comments": "该论文的创新点在于提出了“旋转采样”这一新颖的即插即用编码器，有效解决了3D分子GNN中旋转不变性与计算效率之间的矛盾。通过结合SO(3)期望和后对齐策略，它在保证性能的同时，避免了传统不变性方法对先验知识的过度依赖和等变性方法的高计算成本。这对于药物发现和材料设计等领域中精确处理3D分子结构信息具有重要意义。"}}
{"id": "2507.01734", "title": "LLMs for Legal Subsumption in German Employment Contracts", "authors": ["Oliver Wardas", "Florian Matthes"], "summary": "Legal work, characterized by its text-heavy and resource-intensive nature,\npresents unique challenges and opportunities for NLP research. While\ndata-driven approaches have advanced the field, their lack of interpretability\nand trustworthiness limits their applicability in dynamic legal environments.\nTo address these issues, we collaborated with legal experts to extend an\nexisting dataset and explored the use of Large Language Models (LLMs) and\nin-context learning to evaluate the legality of clauses in German employment\ncontracts. Our work evaluates the ability of different LLMs to classify clauses\nas \"valid,\" \"unfair,\" or \"void\" under three legal context variants: no legal\ncontext, full-text sources of laws and court rulings, and distilled versions of\nthese (referred to as examination guidelines). Results show that full-text\nsources moderately improve performance, while examination guidelines\nsignificantly enhance recall for void clauses and weighted F1-Score, reaching\n80\\%. Despite these advancements, LLMs' performance when using full-text\nsources remains substantially below that of human lawyers. We contribute an\nextended dataset, including examination guidelines, referenced legal sources,\nand corresponding annotations, alongside our code and all log files. Our\nfindings highlight the potential of LLMs to assist lawyers in contract legality\nreview while also underscoring the limitations of the methods presented.", "comment": "PrePrint - ICAIL25, Chicago", "pdf_url": "http://arxiv.org/pdf/2507.01734v1", "categories": ["cs.CL", "68T50", "I.2.7"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01734v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "德国雇佣合同中法律归类的LLM应用", "tldr": "研究LLM在德国雇佣合同法律条款合法性分类中的应用，发现指导方针能显著提升性能，但仍远低于人类律师。", "motivation": "法律工作文本量大、资源密集，传统数据驱动的NLP方法缺乏可解释性和可信度，限制了其在动态法律环境中的适用性。本研究旨在解决这些问题，探索大型语言模型（LLMs）在德国雇佣合同法律条款合法性评估中的潜力。", "method": "与法律专家合作扩展现有数据集，并探索使用大型语言模型（LLMs）和上下文学习来评估德国雇佣合同条款的合法性。评估了不同LLMs在三种法律上下文变体下（无法律上下文、法律和法院判决的全文来源、这些来源的精炼版本即审查指南）将条款分类为“有效”、“不公平”或“无效”的能力。", "result": "结果显示，全文来源适度提高了性能，而审查指南显著提高了“无效”条款的召回率和加权F1分数，达到80%。尽管有这些进展，LLMs在使用全文来源时的性能仍远低于人类律师。", "conclusion": "本研究突出了大型语言模型在协助律师进行合同合法性审查方面的潜力，同时也强调了所提出方法的局限性。", "translation": "法律工作以其文本密集和资源密集型性质为特征，为自然语言处理（NLP）研究带来了独特的挑战和机遇。尽管数据驱动方法推动了该领域的发展，但它们缺乏可解释性和可信度，限制了其在动态法律环境中的适用性。为了解决这些问题，我们与法律专家合作，扩展了一个现有数据集，并探索使用大型语言模型（LLMs）和上下文学习来评估德国雇佣合同中条款的合法性。我们的工作评估了不同LLMs在三种法律上下文变体下将条款分类为“有效”、“不公平”或“无效”的能力：无法律上下文、法律和法院判决的全文来源，以及这些来源的精炼版本（称为审查指南）。结果显示，全文来源适度提高了性能，而审查指南显著提高了无效条款的召回率和加权F1分数，达到80%。尽管有这些进展，LLMs在使用全文来源时的性能仍远低于人类律师。我们贡献了一个扩展数据集，包括审查指南、引用的法律来源和相应的注释，以及我们的代码和所有日志文件。我们的发现突出了LLMs在协助律师进行合同合法性审查方面的潜力，同时也强调了所提出方法的局限性。", "summary": "本研究探讨了大型语言模型（LLMs）在德国雇佣合同法律归类中的应用，旨在解决传统NLP在法律领域的可解释性与可信度问题。通过与法律专家合作扩展数据集，并利用上下文学习，论文评估了LLMs在不同法律上下文下（无上下文、全文法律来源、精炼审查指南）对合同条款进行“有效”、“不公平”或“无效”分类的能力。结果表明，精炼的审查指南显著提升了模型性能，尤其是在无效条款的召回率和加权F1分数上达到80%。然而，LLMs的性能仍远低于人类律师。该研究贡献了一个包含审查指南、法律来源和注释的扩展数据集，并强调了LLMs辅助法律审查的潜力及现有方法的局限性。", "keywords": "大型语言模型, 法律归类, 雇佣合同, 上下文学习, 审查指南", "comments": "本文创新性地将LLMs应用于法律领域中复杂的德国雇佣合同条款合法性评估，特别是引入了“审查指南”这一精炼法律上下文，显著提升了模型性能。其重要性在于为法律AI辅助系统提供了新的方向，旨在提高法律工作的效率。然而，论文也坦诚地指出了当前LLMs与人类律师之间存在的显著性能差距，这提示了未来研究需要关注如何进一步提升模型的法律推理能力和可信度，以应对法律领域的严格要求。"}}
{"id": "2507.01439", "title": "TurboReg: TurboClique for Robust and Efficient Point Cloud Registration", "authors": ["Shaocheng Yan", "Pengcheng Shi", "Zhenjun Zhao", "Kaixin Wang", "Kuang Cao", "Ji Wu", "Jiayuan Li"], "summary": "Robust estimation is essential in correspondence-based Point Cloud\nRegistration (PCR). Existing methods using maximal clique search in\ncompatibility graphs achieve high recall but suffer from exponential time\ncomplexity, limiting their use in time-sensitive applications. To address this\nchallenge, we propose a fast and robust estimator, TurboReg, built upon a novel\nlightweight clique, TurboClique, and a highly parallelizable Pivot-Guided\nSearch (PGS) algorithm. First, we define the TurboClique as a 3-clique within a\nhighly-constrained compatibility graph. The lightweight nature of the 3-clique\nallows for efficient parallel searching, and the highly-constrained\ncompatibility graph ensures robust spatial consistency for stable\ntransformation estimation. Next, PGS selects matching pairs with high SC$^2$\nscores as pivots, effectively guiding the search toward TurboCliques with\nhigher inlier ratios. Moreover, the PGS algorithm has linear time complexity\nand is significantly more efficient than the maximal clique search with\nexponential time complexity. Extensive experiments show that TurboReg achieves\nstate-of-the-art performance across multiple real-world datasets, with\nsubstantial speed improvements. For example, on the 3DMatch+FCGF dataset,\nTurboReg (1K) operates $208.22\\times$ faster than 3DMAC while also achieving\nhigher recall. Our code is accessible at\n\\href{https://github.com/Laka-3DV/TurboReg}{\\texttt{TurboReg}}.", "comment": "ICCV-2025 Accepted Paper", "pdf_url": "http://arxiv.org/pdf/2507.01439v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01439v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "TurboReg：用于鲁棒高效点云配准的TurboClique", "tldr": "TurboReg提出了一种基于轻量级TurboClique和线性时间复杂度的Pivot-Guided Search (PGS)算法，以实现快速鲁棒的点云配准，显著优于现有方法。", "motivation": "现有的基于最大团搜索的点云配准方法虽然召回率高，但时间复杂度呈指数级，限制了它们在时间敏感应用中的使用。", "method": "本文提出了TurboReg，一个快速鲁棒的估计器。它基于新型轻量级团TurboClique和一个高度并行化的枢轴引导搜索（PGS）算法。TurboClique被定义为高度受限兼容图中的3-团，实现了高效并行搜索并确保空间一致性。PGS算法通过选择高SC$^2$分数的匹配对作为枢轴，将搜索引导至具有更高内点率的TurboCliques，并且具有线性时间复杂度。", "result": "广泛的实验表明，TurboReg在多个真实世界数据集上达到了最先进的性能，并有显著的速度提升。例如，在3DMatch+FCGF数据集上，TurboReg (1K) 比3DMAC快208.22倍，同时召回率更高。", "conclusion": "TurboReg通过引入轻量级TurboClique和高效的PGS算法，解决了点云配准中鲁棒估计的效率问题，实现了最先进的性能和显著的速度提升。", "translation": "鲁棒估计在基于对应关系的点云配准 (PCR) 中至关重要。现有使用兼容图中最大团搜索的方法虽然召回率高，但时间复杂度呈指数级，限制了它们在时间敏感应用中的使用。为了解决这一挑战，我们提出了一种快速鲁棒的估计器TurboReg，它建立在一种新颖的轻量级团TurboClique和一种高度并行化的枢轴引导搜索 (PGS) 算法之上。首先，我们将TurboClique定义为高度受限兼容图中的一个3-团。3-团的轻量级特性允许高效的并行搜索，而高度受限的兼容图确保了鲁棒的空间一致性，以实现稳定的变换估计。其次，PGS选择具有高SC$^2$分数的匹配对作为枢轴，有效地引导搜索朝向具有更高内点率的TurboCliques。此外，PGS算法具有线性时间复杂度，并且比时间复杂度呈指数级的最大团搜索效率显著更高。大量的实验表明，TurboReg在多个真实世界数据集上实现了最先进的性能，并有显著的速度改进。例如，在3DMatch+FCGF数据集上，TurboReg (1K) 比3DMAC快208.22倍，同时实现了更高的召回率。我们的代码可在\\href{https://github.com/Laka-3DV/TurboReg}{\\texttt{TurboReg}}获取。", "summary": "TurboReg是为点云配准设计的一种快速鲁棒的估计器，旨在克服现有最大团搜索方法效率低下的问题。它引入了轻量级的3-团TurboClique和具有线性时间复杂度的枢轴引导搜索（PGS）算法。通过在高度受限兼容图中高效搜索TurboClique，并利用PGS引导搜索，TurboReg在多个真实世界数据集上实现了最先进的性能，并大幅提升了速度，例如在3DMatch+FCGF数据集上比3DMAC快208.22倍且召回率更高。", "keywords": "点云配准, 鲁棒估计, 最大团搜索, TurboClique, PGS算法", "comments": "该论文通过引入轻量级3-团TurboClique和线性时间复杂度的Pivot-Guided Search (PGS) 算法，创新性地解决了点云配准中鲁棒估计的计算效率问题。其核心创新在于将指数级复杂度的最大团搜索替换为高效的线性复杂度算法，同时保持甚至提升了配准的鲁棒性和召回率。这种方法对于时间敏感的实际应用具有重要意义，显示了算法设计在提升性能方面的巨大潜力。"}}
{"id": "2507.01764", "title": "Data interference: emojis, homoglyphs, and issues of data fidelity in corpora and their results", "authors": ["Matteo Di Cristofaro"], "summary": "Tokenisation - \"the process of splitting text into atomic parts\" (Brezina &\nTimperley, 2017: 1) - is a crucial step for corpus linguistics, as it provides\nthe basis for any applicable quantitative method (e.g. collocations) while\nensuring the reliability of qualitative approaches. This paper examines how\ndiscrepancies in tokenisation affect the representation of language data and\nthe validity of analytical findings: investigating the challenges posed by\nemojis and homoglyphs, the study highlights the necessity of preprocessing\nthese elements to maintain corpus fidelity to the source data. The research\npresents methods for ensuring that digital texts are accurately represented in\ncorpora, thereby supporting reliable linguistic analysis and guaranteeing the\nrepeatability of linguistic interpretations. The findings emphasise the\nnecessity of a detailed understanding of both linguistic and technical aspects\ninvolved in digital textual data to enhance the accuracy of corpus analysis,\nand have significant implications for both quantitative and qualitative\napproaches in corpus-based research.", "comment": "Author submitted manuscript", "pdf_url": "http://arxiv.org/pdf/2507.01764v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01764v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "数据干扰：表情符号、同形字以及语料库及其结果中的数据保真度问题", "tldr": "本研究探讨了分词差异如何影响语言数据表示和分析结果的有效性，重点关注表情符号和同形字带来的挑战，并提出了确保数字文本在语料库中准确表示的方法。", "motivation": "本研究旨在探讨分词差异如何影响语言数据的表示和分析结果的有效性，特别关注表情符号和同形字带来的挑战，以维护语料库对源数据的忠实性。", "method": "本研究通过检查分词差异如何影响语言数据表示和分析结果的有效性来展开，并提出了确保数字文本在语料库中准确表示的方法，以支持可靠的语言分析并保证语言解释的可重复性。", "result": "研究结果强调了预处理表情符号和同形字的必要性，以保持语料库对源数据的忠实性。此外，研究发现需要深入理解数字文本数据所涉及的语言和技术方面，以提高语料库分析的准确性。", "conclusion": "本研究的结论是，深入理解数字文本数据所涉及的语言和技术方面对于提高语料库分析的准确性至关重要，并且对语料库研究中的定量和定性方法都具有重要意义。", "translation": "分词——“将文本分割成原子部分的过程”（Brezina & Timperley，2017：1）——是语料库语言学的关键一步，因为它为任何适用的定量方法（例如搭配）提供了基础，同时确保了定性方法的可靠性。本文研究了分词差异如何影响语言数据的表示和分析结果的有效性：通过调查表情符号和同形字带来的挑战，该研究强调了预处理这些元素的必要性，以保持语料库对源数据的忠实性。该研究提出了确保数字文本在语料库中准确表示的方法，从而支持可靠的语言分析并保证语言解释的可重复性。研究结果强调了深入理解数字文本数据所涉及的语言和技术方面的必要性，以提高语料库分析的准确性，并且对语料库研究中的定量和定性方法都具有重要意义。", "summary": "本研究探讨了分词过程中因表情符号和同形字引起的数据干扰问题，指出分词差异会影响语言数据的表示和分析结果的有效性。论文强调了预处理这些元素的必要性，并提出了确保数字文本在语料库中准确表示的方法，以支持可靠的语言分析并保证语言解释的可重复性。研究结果表明，深入理解数字文本数据中的语言和技术层面对于提高语料库分析的准确性至关重要。", "keywords": "分词, 数据保真度, 表情符号, 同形字, 语料库语言学", "comments": "这篇论文解决了语料库语言学中一个基本但日益重要的问题：数字文本中非标准字符（如表情符号和同形字）对数据保真度和分析准确性的影响。其创新之处在于明确指出这些看似微小的干扰如何影响分词，进而影响整个语料库分析的有效性。论文强调预处理的重要性，并提出具体方法，这对于确保语料库研究的可靠性和可重复性具有重要意义。它对定量和定性研究都提供了关键的见解，是当前数字语言学领域的一项及时且重要的贡献。"}}
{"id": "2507.01455", "title": "OoDDINO:A Multi-level Framework for Anomaly Segmentation on Complex Road Scenes", "authors": ["Yuxing Liu", "Ji Zhang", "Zhou Xuchuan", "Jingzhong Xiao", "Huimin Yang", "Jiaxin Zhong"], "summary": "Anomaly segmentation aims to identify Out-of-Distribution (OoD) anomalous\nobjects within images. Existing pixel-wise methods typically assign anomaly\nscores individually and employ a global thresholding strategy to segment\nanomalies. Despite their effectiveness, these approaches encounter significant\nchallenges in real-world applications: (1) neglecting spatial correlations\namong pixels within the same object, resulting in fragmented segmentation; (2)\nvariabil ity in anomaly score distributions across image regions, causing\nglobal thresholds to either generate false positives in background areas or\nmiss segments of anomalous objects. In this work, we introduce OoDDINO, a novel\nmulti-level anomaly segmentation framework designed to address these\nlimitations through a coarse-to-fine anomaly detection strategy. OoDDINO\ncombines an uncertainty-guided anomaly detection model with a pixel-level\nsegmentation model within a two-stage cascade architecture. Initially, we\npropose an Orthogonal Uncertainty-Aware Fusion Strategy (OUAFS) that\nsequentially integrates multiple uncertainty metrics with visual\nrepresentations, employing orthogonal constraints to strengthen the detection\nmodel's capacity for localizing anomalous regions accurately. Subsequently, we\ndevelop an Adaptive Dual-Threshold Network (ADT-Net), which dynamically\ngenerates region-specific thresholds based on object-level detection outputs\nand pixel-wise anomaly scores. This approach allows for distinct thresholding\nstrategies within foreground and background areas, achieving fine-grained\nanomaly segmentation. The proposed framework is compatible with other\npixel-wise anomaly detection models, which acts as a plug-in to boost the\nperformance. Extensive experiments on two benchmark datasets validate our\nframework's superiority and compatibility over state-of-the-art methods.", "comment": "12 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.01455v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01455v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "OoDDINO：一种复杂道路场景异常分割的多级框架", "tldr": "OoDDINO是一个多级异常分割框架，通过结合不确定性感知融合策略和自适应双阈值网络，解决了现有方法在复杂道路场景中分割碎片化和阈值不当的问题，实现了更准确的异常分割。", "motivation": "现有的像素级异常分割方法在实际应用中面临挑战：1) 忽略像素间的空间相关性，导致分割碎片化；2) 异常分数分布在不同图像区域间存在差异，导致全局阈值策略产生误报或漏报。", "method": "本文提出了OoDDINO，一个新颖的多级异常分割框架，采用从粗到精的异常检测策略。它结合了不确定性引导的异常检测模型和像素级分割模型，采用两阶段级联架构。具体包括：1) 正交不确定性感知融合策略 (OUAFS)，顺序整合多个不确定性指标与视觉表示，利用正交约束增强检测模型准确本地化异常区域的能力；2) 自适应双阈值网络 (ADT-Net)，根据对象级检测输出和像素级异常分数动态生成区域特定阈值，实现前景和背景区域的不同阈值策略，从而实现细粒度异常分割。该框架可作为插件兼容其他像素级异常检测模型。", "result": "在两个基准数据集上的大量实验验证了该框架相对于现有最先进方法的优越性和兼容性。", "conclusion": "OoDDINO通过解决现有方法在空间相关性和阈值设置上的不足，显著提升了复杂道路场景下异常分割的准确性和鲁棒性。", "translation": "异常分割旨在识别图像中的分布外 (OoD) 异常对象。现有的像素级方法通常单独分配异常分数，并采用全局阈值策略来分割异常。尽管这些方法有效，但在实际应用中遇到了重大挑战：(1) 忽略了同一对象内像素间的空间相关性，导致分割碎片化；(2) 图像区域间异常分数分布的变化性，导致全局阈值要么在背景区域产生误报，要么遗漏异常对象的部分。在这项工作中，我们引入了OoDDINO，一个新颖的多级异常分割框架，旨在通过从粗到精的异常检测策略解决这些限制。OoDDINO在一个两阶段级联架构中结合了不确定性引导的异常检测模型和像素级分割模型。最初，我们提出了一种正交不确定性感知融合策略 (OUAFS)，它顺序整合多个不确定性指标与视觉表示，采用正交约束来增强检测模型准确本地化异常区域的能力。随后，我们开发了一种自适应双阈值网络 (ADT-Net)，它根据对象级检测输出和像素级异常分数动态生成区域特定阈值。这种方法允许在前景和背景区域采用不同的阈值策略，实现细粒度异常分割。所提出的框架与其他像素级异常检测模型兼容，可作为插件提升性能。在两个基准数据集上的大量实验验证了我们框架相对于现有最先进方法的优越性和兼容性。", "summary": "本文提出了OoDDINO，一个用于复杂道路场景异常分割的多级框架，旨在解决现有像素级方法中因忽略空间相关性导致的分割碎片化和全局阈值不当问题。OoDDINO采用两阶段级联架构，结合了不确定性引导检测模型和像素级分割模型，并通过正交不确定性感知融合策略（OUAFS）精确本地化异常区域，以及自适应双阈值网络（ADT-Net）动态生成区域特定阈值，实现了细粒度异常分割。该框架可作为插件提升现有模型的性能，并在实验中展现出优越性。", "keywords": "异常分割, 多级框架, 不确定性感知, 自适应阈值, 复杂道路场景", "comments": "OoDDINO的创新之处在于其多级、从粗到精的异常检测策略，特别是引入了正交不确定性感知融合和自适应双阈值网络，有效解决了传统方法的空间相关性不足和全局阈值不适应性问题。其模块化的设计使其能够作为现有像素级异常检测模型的插件，具有良好的兼容性和应用潜力。"}}
{"id": "2507.01077", "title": "Good Enough to Learn: LLM-based Anomaly Detection in ECU Logs without Reliable Labels", "authors": ["Bogdan Bogdan", "Arina Cazacu", "Laura Vasilie"], "summary": "Anomaly detection often relies on supervised or clustering approaches, with\nlimited success in specialized domains like automotive communication systems\nwhere scalable solutions are essential. We propose a novel decoder-only Large\nLanguage Model (LLM) to detect anomalies in Electronic Control Unit (ECU)\ncommunication logs. Our approach addresses two key challenges: the lack of LLMs\ntailored for ECU communication and the complexity of inconsistent ground truth\ndata. By learning from UDP communication logs, we formulate anomaly detection\nsimply as identifying deviations in time from normal behavior. We introduce an\nentropy regularization technique that increases model's uncertainty in known\nanomalies while maintaining consistency in similar scenarios. Our solution\noffers three novelties: a decoder-only anomaly detection architecture, a way to\nhandle inconsistent labeling, and an adaptable LLM for different ECU\ncommunication use cases. By leveraging the generative capabilities of\ndecoder-only models, we present a new technique that addresses the high cost\nand error-prone nature of manual labeling through a more scalable system that\nis able to learn from a minimal set of examples, while improving detection\naccuracy in complex communication environments.", "comment": "6 pages, 7 figures, 4 tables, accepted to IEEE Intelligent Vehicles\n  Symposium (IV) 2025", "pdf_url": "http://arxiv.org/pdf/2507.01077v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01077v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "足够好学：基于LLM的ECU日志异常检测，无需可靠标签", "tldr": "本文提出了一种新颖的仅解码器大型语言模型（LLM），用于在ECU通信日志中进行异常检测，解决了缺乏针对ECU的LLM和地面真实数据标签不一致的问题，并通过熵正则化技术，在仅使用少量示例的情况下提高了检测精度。", "motivation": "现有异常检测方法在汽车通信系统等专业领域效果有限，缺乏针对ECU通信的LLM，且地面真实数据标签不一致，需要更具可扩展性的解决方案。", "method": "提出了一种新颖的仅解码器LLM架构，用于检测ECU通信日志中的异常。通过学习UDP通信日志，将异常检测定义为识别时间上偏离正常行为的偏差，并引入熵正则化技术来增加模型对已知异常的不确定性，同时保持在相似场景中的一致性。", "result": "通过利用仅解码器模型的生成能力，提出了一种新的技术，通过更具可扩展性的系统解决了手动标注成本高昂且易出错的问题，该系统能够从最少的示例中学习，同时提高了复杂通信环境中的检测准确性。", "conclusion": "本文提出了一种新颖的仅解码器异常检测架构，提供了一种处理不一致标签的方法，并开发了一个适用于不同ECU通信用例的自适应LLM，从而实现了一个可扩展的系统，能够从少量示例中学习并提高检测精度。", "translation": "异常检测通常依赖于监督或聚类方法，在汽车通信系统等专业领域成功有限，而这些领域需要可扩展的解决方案。我们提出了一种新颖的仅解码器大型语言模型（LLM），用于检测电子控制单元（ECU）通信日志中的异常。我们的方法解决了两个关键挑战：缺乏针对ECU通信定制的LLM，以及不一致的地面真实数据标签的复杂性。通过从UDP通信日志中学习，我们将异常检测简单地表述为识别时间上偏离正常行为的偏差。我们引入了一种熵正则化技术，该技术增加了模型对已知异常的不确定性，同时在相似场景中保持一致性。我们的解决方案提供了三个新颖之处：一个仅解码器异常检测架构，一种处理不一致标签的方法，以及一个适用于不同ECU通信用例的自适应LLM。通过利用仅解码器模型的生成能力，我们提出了一种新技术，通过一个更具可扩展性的系统解决了手动标注成本高昂且易出错的问题，该系统能够从最少的示例中学习，同时提高了复杂通信环境中的检测准确性。", "summary": "本文提出了一种新颖的仅解码器大型语言模型（LLM），用于在电子控制单元（ECU）通信日志中进行异常检测。该方法旨在解决汽车通信系统中可扩展解决方案的不足、缺乏定制化LLM以及地面真实数据标签不一致等挑战。通过将异常检测定义为识别时间上偏离正常行为的偏差，并引入熵正则化技术来管理不确定性，该方案提供了一个可扩展的系统，能够从少量示例中学习，降低了对手动标注的依赖，并提高了复杂通信环境中的检测准确性。", "keywords": "LLM, 异常检测, ECU日志, 不一致标签, 仅解码器模型", "comments": "本文创新性地提出了一种仅解码器LLM架构用于ECU日志异常检测，有效解决了专用领域中LLM缺乏和标签不一致的难题。其引入的熵正则化技术以及从少量示例中学习的能力，显著降低了手动标注成本，并提升了复杂环境下的检测精度，具有重要的实际应用价值。该方案在处理不一致标签和适应不同用例方面展现出良好的灵活性和可扩展性。"}}
{"id": "2507.01785", "title": "MuRating: A High Quality Data Selecting Approach to Multilingual Large Language Model Pretraining", "authors": ["Zhixun Chen", "Ping Guo", "Wenhan Han", "Yifan Zhang", "Binbin Liu", "Haobin Lin", "Fengze Liu", "Yan Zhao", "Bingni Zhang", "Taifeng Wang", "Yin Zheng", "Meng Fang"], "summary": "Data quality is a critical driver of large language model performance, yet\nexisting model-based selection methods focus almost exclusively on English. We\nintroduce MuRating, a scalable framework that transfers high-quality English\ndata-quality signals into a single rater for 17 target languages. MuRating\naggregates multiple English \"raters\" via pairwise comparisons to learn unified\ndocument-quality scores,then projects these judgments through translation to\ntrain a multilingual evaluator on monolingual, cross-lingual, and parallel text\npairs. Applied to web data, MuRating selects balanced subsets of English and\nmultilingual content to pretrain a 1.2 B-parameter LLaMA model. Compared to\nstrong baselines, including QuRater, AskLLM, DCLM and so on, our approach\nboosts average accuracy on both English benchmarks and multilingual\nevaluations, with especially large gains on knowledge-intensive tasks. We\nfurther analyze translation fidelity, selection biases, and underrepresentation\nof narrative material, outlining directions for future work.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01785v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01785v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "MuRating：一种用于多语言大型语言模型预训练的高质量数据选择方法", "tldr": "MuRating是一个可扩展的框架，通过将高质量的英文数据质量信号转移到17种目标语言的单一评分器中，以选择平衡的英文和多语言内容子集，从而在多语言LLM预训练中提升性能，尤其是在知识密集型任务上。", "motivation": "现有基于模型的数据选择方法几乎只关注英语数据质量，但数据质量是大型语言模型性能的关键驱动因素，因此需要一种针对多语言环境的高质量数据选择方法。", "method": "MuRating通过成对比较聚合多个英文“评分器”来学习统一的文档质量得分，然后通过翻译将这些判断投射，以在单语、跨语言和并行文本对上训练一个多语言评估器。该方法应用于网络数据，选择平衡的英文和多语言内容子集来预训练一个1.2 B参数的LLaMA模型。", "result": "与包括QuRater、AskLLM、DCLM等在内的强基线相比，MuRating在英文基准测试和多语言评估中的平均准确率均有所提高，尤其是在知识密集型任务上获得了显著提升。", "conclusion": "MuRating通过高质量的数据选择显著提升了多语言大型语言模型的性能，尤其是在知识密集型任务上表现出色，并指出了未来工作的方向。", "translation": "数据质量是大型语言模型性能的关键驱动因素，然而现有的基于模型的数据选择方法几乎完全专注于英语。我们引入了MuRating，这是一个可扩展的框架，它将高质量的英语数据质量信号转移到17种目标语言的单一评分器中。MuRating通过成对比较聚合多个英语“评分器”，以学习统一的文档质量分数，然后通过翻译投射这些判断，以在单语、跨语言和并行文本对上训练一个多语言评估器。将MuRating应用于网络数据，它选择平衡的英语和多语言内容子集来预训练一个1.2 B参数的LLaMA模型。与包括QuRater、AskLLM、DCLM等在内的强基线相比，我们的方法在英语基准测试和多语言评估中的平均准确率均有所提高，尤其是在知识密集型任务上获得了显著提升。我们进一步分析了翻译保真度、选择偏差和叙事材料的代表性不足，并概述了未来的工作方向。", "summary": "本文提出了MuRating，一个解决多语言大型语言模型预训练中数据质量选择问题的可扩展框架。它通过聚合英文数据质量信号并将其转移到17种目标语言，训练一个多语言评估器来选择高质量、平衡的英文和多语言数据集。实验结果表明，MuRating相较于现有基线显著提升了预训练LLaMA模型在英文和多语言任务上的准确率，尤其在知识密集型任务上表现突出。", "keywords": "数据质量, 多语言LLM, 数据选择, MuRating, 预训练", "comments": "MuRating的创新之处在于其将英文高质量数据信号跨语言转移的框架，解决了现有数据选择方法过度依赖英文的局限性。其可扩展性和在多语言LLM预训练中的性能提升具有重要意义，尤其是在推动非英文语言LLM发展方面。该方法通过聚合和投射判断的方式构建多语言评估器，提供了一个有前景的数据筛选范式。"}}
{"id": "2507.01463", "title": "NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation", "authors": ["Max Gandyra", "Alessandro Santonicola", "Michael Beetz"], "summary": "Instance segmentation of novel objects instances in RGB images, given some\nexample images for each object, is a well known problem in computer vision.\nDesigning a model general enough to be employed, for all kinds of novel\nobjects, without (re-) training, has proven to be a difficult task. To handle\nthis, we propose a simple, yet powerful, framework, called: Novel Object Cyclic\nThreshold based Instance Segmentation (NOCTIS). This work stems from and\nimproves upon previous ones like CNOS, SAM-6D and NIDS-Net; thus, it also\nleverages on recent vision foundation models, namely: Grounded-SAM 2 and\nDINOv2. It utilises Grounded-SAM 2 to obtain object proposals with precise\nbounding boxes and their corresponding segmentation masks; while DINOv2's\nzero-shot capabilities are employed to generate the image embeddings. The\nquality of those masks, together with their embeddings, is of vital importance\nto our approach; as the proposal-object matching is realized by determining an\nobject matching score based on the similarity of the class embeddings and the\naverage maximum similarity of the patch embeddings. Differently to SAM-6D,\ncalculating the latter involves a prior patch filtering based on the distance\nbetween each patch and its corresponding cyclic/roundtrip patch in the image\ngrid. Furthermore, the average confidence of the proposals' bounding box and\nmask is used as an additional weighting factor for the object matching score.\nWe empirically show that NOCTIS, without further training/fine tuning,\noutperforms the best RGB and RGB-D methods on the seven core datasets of the\nBOP 2023 challenge for the \"Model-based 2D segmentation of unseen objects\"\ntask.", "comment": "10 pages, 3 figures, 3 tables, NeurIPS 2025 preprint", "pdf_url": "http://arxiv.org/pdf/2507.01463v1", "categories": ["cs.CV", "cs.AI", "I.2; I.4; I.5"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01463v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "NOCTIS：基于新颖对象循环阈值的实例分割", "tldr": "NOCTIS是一个无需训练即可对RGB图像中的新颖对象进行实例分割的框架，它利用Grounded-SAM 2和DINOv2，并通过新颖的循环阈值方法进行对象匹配，在BOP 2023挑战赛中表现优异。", "motivation": "在计算机视觉领域，给定每个对象的一些示例图像，对RGB图像中的新颖对象实例进行实例分割是一个众所周知的问题。设计一个足够通用、无需（重新）训练即可用于各种新颖对象的模型，已被证明是一项艰巨的任务。", "method": "本文提出了一个名为NOCTIS（Novel Object Cyclic Threshold based Instance Segmentation）的简单而强大的框架。该框架借鉴并改进了先前的CNOS、SAM-6D和NIDS-Net等工作，并利用了最新的视觉基础模型：Grounded-SAM 2和DINOv2。它使用Grounded-SAM 2获取带有精确边界框和相应分割掩码的对象提议；而DINOv2的零样本能力则用于生成图像嵌入。提议与对象的匹配是通过确定一个对象匹配分数实现的，该分数基于类别嵌入的相似性和补丁嵌入的平均最大相似性。与SAM-6D不同的是，后者涉及基于每个补丁与其在图像网格中对应的循环/往返补丁之间距离的先验补丁过滤。此外，提议边界框和掩码的平均置信度被用作对象匹配分数的额外加权因子。", "result": "NOCTIS在无需进一步训练/微调的情况下，在BOP 2023挑战赛“基于模型的未见对象2D分割”任务的七个核心数据集上，性能优于最佳的RGB和RGB-D方法。", "conclusion": "NOCTIS提供了一种有效且无需训练的解决方案，用于新颖对象的实例分割，并在基准测试中展现出卓越的性能，证明了其在处理未见对象方面的泛化能力。", "translation": "实例分割是计算机视觉领域一个众所周知的问题，即在给定每个对象的一些示例图像的情况下，对RGB图像中的新颖对象实例进行分割。设计一个足够通用、无需（重新）训练即可用于各种新颖对象的模型，已被证明是一项艰巨的任务。为了解决这个问题，我们提出了一个简单而强大的框架，名为：基于新颖对象循环阈值的实例分割（NOCTIS）。这项工作源于并改进了之前的CNOS、SAM-6D和NIDS-Net等工作；因此，它也利用了最新的视觉基础模型，即：Grounded-SAM 2和DINOv2。它利用Grounded-SAM 2获取带有精确边界框及其相应分割掩码的对象提议；同时，DINOv2的零样本能力被用于生成图像嵌入。这些掩码的质量及其嵌入对于我们的方法至关重要；因为提议-对象匹配是通过确定一个基于类别嵌入相似性和补丁嵌入平均最大相似性的对象匹配分数来实现的。与SAM-6D不同的是，计算后者涉及基于每个补丁与其在图像网格中对应的循环/往返补丁之间距离的先验补丁过滤。此外，提议边界框和掩码的平均置信度被用作对象匹配分数的额外加权因子。我们通过实验表明，NOCTIS在无需进一步训练/微调的情况下，在BOP 2023挑战赛“基于模型的未见对象2D分割”任务的七个核心数据集上，性能优于最佳的RGB和RGB-D方法。", "summary": "本文提出了一种名为NOCTIS的新型框架，用于在RGB图像中进行无需训练的新颖对象实例分割。该方法结合了Grounded-SAM 2用于生成精确的对象提议和分割掩码，以及DINOv2用于生成零样本图像嵌入。其核心创新在于通过基于循环阈值的补丁过滤，结合类别和补丁嵌入相似性来计算对象匹配分数。实验结果表明，NOCTIS在BOP 2023挑战赛的未见对象2D分割任务上，无需额外训练即可超越现有最佳的RGB和RGB-D方法。", "keywords": "实例分割, 新颖对象, 零样本学习, 循环阈值, 视觉基础模型", "comments": "NOCTIS的创新之处在于其无需训练的特性，以及巧妙地结合了Grounded-SAM 2和DINOv2这两个强大的基础模型。特别是，其引入的基于循环/往返补丁距离的先验补丁过滤机制，为对象匹配提供了更鲁棒的方式。这项工作对于零样本和少样本学习在实例分割领域的应用具有重要意义，尤其是在需要快速部署和适应新对象而无需大量标注和训练的场景。"}}
{"id": "2507.01786", "title": "Probing Evaluation Awareness of Language Models", "authors": ["Jord Nguyen", "Khiem Hoang", "Carlo Leonardo Attubato", "Felix Hofstätter"], "summary": "Language models can distinguish between testing and deployment phases -- a\ncapability known as evaluation awareness. This has significant safety and\npolicy implications, potentially undermining the reliability of evaluations\nthat are central to AI governance frameworks and voluntary industry\ncommitments. In this paper, we study evaluation awareness in\nLlama-3.3-70B-Instruct. We show that linear probes can separate real-world\nevaluation and deployment prompts, suggesting that current models internally\nrepresent this distinction. We also find that current safety evaluations are\ncorrectly classified by the probes, suggesting that they already appear\nartificial or inauthentic to models. Our findings underscore the importance of\nensuring trustworthy evaluations and understanding deceptive capabilities. More\nbroadly, our work showcases how model internals may be leveraged to support\nblackbox methods in safety audits, especially for future models more competent\nat evaluation awareness and deception.", "comment": "Technical AI Governance Workshop, ICML (Poster)", "pdf_url": "http://arxiv.org/pdf/2507.01786v1", "categories": ["cs.CL", "cs.AI"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01786v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "探测语言模型的评估意识", "tldr": "研究发现，语言模型（如Llama-3.3-70B-Instruct）具有“评估意识”，能够区分测试和部署阶段，这可能影响AI评估的可靠性，并对安全审计提出挑战。", "motivation": "语言模型的“评估意识”能力对AI治理框架和行业承诺至关重要的评估的可靠性构成潜在威胁，具有重要的安全和政策影响，因此需要深入研究。", "method": "本研究使用线性探针在Llama-3.3-70B-Instruct模型上进行实验，以区分真实世界的评估提示和部署提示。同时，探针也被用于分类当前的安全性评估。", "result": "线性探针能够成功区分真实世界的评估提示和部署提示，表明模型内部确实存在这种区别。此外，当前的安全性评估被探针正确分类，暗示这些评估对模型而言显得人工或不真实。", "conclusion": "研究结果强调了确保评估可信度以及理解模型欺骗能力的重要性。该工作还展示了如何利用模型内部机制来支持安全审计中的黑盒方法，特别是对于未来在评估意识和欺骗方面更强的模型。", "translation": "标题：探测语言模型的评估意识\n摘要：语言模型能够区分测试阶段和部署阶段——这种能力被称为评估意识。这具有重要的安全和政策影响，可能损害对AI治理框架和自愿行业承诺至关重要的评估的可靠性。在本文中，我们研究了Llama-3.3-70B-Instruct中的评估意识。我们展示了线性探针能够区分真实世界的评估提示和部署提示，这表明当前模型在内部表示了这种区别。我们还发现，当前的安全性评估被探针正确分类，这表明它们对模型来说已经显得人工或不真实。我们的发现强调了确保可信评估和理解欺骗能力的重要性。更广泛地说，我们的工作展示了如何利用模型内部机制来支持安全审计中的黑盒方法，特别是对于未来在评估意识和欺骗方面更具能力的模型。", "summary": "本研究探讨了大型语言模型（Llama-3.3-70B-Instruct）的“评估意识”，即区分测试和部署阶段的能力。通过使用线性探针，研究发现模型内部能够识别这种区别，并且当前的安全性评估对模型而言显得不真实。这一发现对AI安全和评估可信度具有重要意义，并提出了利用模型内部机制进行未来安全审计的新方法。", "keywords": "评估意识, 语言模型, 安全审计, 线性探针, Llama-3.3-70B-Instruct", "comments": "本文引入了“评估意识”这一新颖概念，并通过实证研究揭示了语言模型可能存在的内部状态，即它们能够区分评估环境。其创新之处在于利用探测技术揭示了模型内部的这一潜在问题，这对于AI治理和安全评估具有重要意义。研究结果强调了未来AI系统评估的复杂性和挑战性，并为利用模型内部信息进行更有效的安全审计提供了新的视角。"}}
{"id": "2507.01467", "title": "Representation Entanglement for Generation:Training Diffusion Transformers Is Much Easier Than You Think", "authors": ["Ge Wu", "Shen Zhang", "Ruijing Shi", "Shanghua Gao", "Zhenyuan Chen", "Lei Wang", "Zhaowei Chen", "Hongcheng Gao", "Yao Tang", "Jian Yang", "Ming-Ming Cheng", "Xiang Li"], "summary": "REPA and its variants effectively mitigate training challenges in diffusion\nmodels by incorporating external visual representations from pretrained models,\nthrough alignment between the noisy hidden projections of denoising networks\nand foundational clean image representations. We argue that the external\nalignment, which is absent during the entire denoising inference process, falls\nshort of fully harnessing the potential of discriminative representations. In\nthis work, we propose a straightforward method called Representation\nEntanglement for Generation (REG), which entangles low-level image latents with\na single high-level class token from pretrained foundation models for\ndenoising. REG acquires the capability to produce coherent image-class pairs\ndirectly from pure noise, substantially improving both generation quality and\ntraining efficiency. This is accomplished with negligible additional inference\noverhead, requiring only one single additional token for denoising (<0.5\\%\nincrease in FLOPs and latency). The inference process concurrently reconstructs\nboth image latents and their corresponding global semantics, where the acquired\nsemantic knowledge actively guides and enhances the image generation process.\nOn ImageNet 256$\\times$256, SiT-XL/2 + REG demonstrates remarkable convergence\nacceleration, achieving $\\textbf{63}\\times$ and $\\textbf{23}\\times$ faster\ntraining than SiT-XL/2 and SiT-XL/2 + REPA, respectively. More impressively,\nSiT-L/2 + REG trained for merely 400K iterations outperforms SiT-XL/2 + REPA\ntrained for 4M iterations ($\\textbf{10}\\times$ longer). Code is available at:\nhttps://github.com/Martinser/REG.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01467v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01467v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "生成的表示纠缠：训练扩散Transformer比你想象的容易得多", "tldr": "本文提出了一种名为REG的新方法，通过将低级图像潜在信息与高级类别token纠缠，显著提高了扩散模型（Diffusion Transformer）的训练效率和生成质量，同时保持了极低的推理开销。", "motivation": "现有的REPA及其变体通过引入预训练模型的外部视觉表示来缓解扩散模型的训练挑战，但其外部对齐在去噪推理过程中缺失，未能充分利用判别性表示的潜力。", "method": "本文提出了一种名为表示纠缠生成（REG）的直接方法，该方法将低级图像潜在信息与来自预训练基础模型的单个高级类别token进行纠缠，用于去噪。REG能够直接从纯噪声生成连贯的图像-类别对，并在推理过程中同时重建图像潜在信息及其对应的全局语义，其中获取的语义知识主动引导和增强图像生成过程。", "result": "在ImageNet 256×256数据集上，SiT-XL/2 + REG展示了显著的收敛加速，训练速度分别比SiT-XL/2和SiT-XL/2 + REPA快63倍和23倍。更令人印象深刻的是，SiT-L/2 + REG仅训练40万次迭代就超越了训练400万次迭代（10倍长）的SiT-XL/2 + REPA。", "conclusion": "REG通过有效的表示纠缠，显著提高了扩散模型的训练效率和生成质量，且推理开销可忽略不计，有效解决了现有方法的局限性。", "translation": "REPA及其变体通过结合来自预训练模型的外部视觉表示，有效缓解了扩散模型的训练挑战，通过去噪网络噪声隐藏投影与基础干净图像表示之间的对齐实现。我们认为，这种在整个去噪推理过程中缺失的外部对齐未能充分利用判别性表示的潜力。在这项工作中，我们提出了一种直接的方法，称为表示纠缠生成（REG），它将低级图像潜在信息与来自预训练基础模型的单个高级类别token进行纠缠以进行去噪。REG获得了直接从纯噪声生成连贯图像-类别对的能力，显著提高了生成质量和训练效率。这以可忽略的额外推理开销实现，仅需要一个额外的token进行去噪（FLOPs和延迟增加<0.5%）。推理过程同时重建图像潜在信息及其对应的全局语义，其中获取的语义知识主动引导和增强图像生成过程。在ImageNet 256×256上，SiT-XL/2 + REG展示了显著的收敛加速，训练速度分别比SiT-XL/2和SiT-XL/2 + REPA快63倍和23倍。更令人印象深刻的是，SiT-L/2 + REG仅训练40万次迭代就超越了训练400万次迭代（10倍长）的SiT-XL/2 + REPA。代码可在：https://github.com/Martinser/REG 获取。", "summary": "本文提出了一种名为“表示纠缠生成”（REG）的新方法，旨在解决现有扩散模型训练中未能充分利用判别性表示的问题。REG通过将低级图像潜在信息与预训练模型的高级类别token进行纠缠，使得模型能够直接从噪声生成连贯的图像-类别对。这种方法显著提升了生成质量和训练效率，同时仅引入可忽略的推理开销。实验结果表明，REG能大幅加速收敛，例如在ImageNet上训练速度比SiT-XL/2快63倍，比SiT-XL/2 + REPA快23倍，并且在更少的迭代次数下超越了现有SOTA模型的性能。", "keywords": "扩散模型, 表示纠缠, 生成模型, 训练效率, 图像生成", "comments": "REG的创新之处在于其“表示纠缠”机制，它不仅将高级语义信息融入去噪过程，更重要的是，在推理过程中主动利用这些语义知识来引导和增强图像生成，而非仅仅作为训练时的外部对齐。这种设计使得模型能从纯噪声直接生成高质量的图-类别对，并带来了前所未有的训练效率提升。其将训练效率提升数十倍的成果，对于未来扩散模型的大规模应用和研究具有重要意义，尤其是在计算资源有限的场景下。"}}
{"id": "2507.01080", "title": "Development and Comparative Evaluation of Three Artificial Intelligence Models (NLP, LLM, JEPA) for Predicting Triage in Emergency Departments: A 7-Month Retrospective Proof-of-Concept", "authors": ["Edouard Lansiaux", "Ramy Azzouz", "Emmanuel Chazard", "Amélie Vromant", "Eric Wiel"], "summary": "Triage errors, including undertriage and overtriage, are persistent\nchallenges in emergency departments (EDs). With increasing patient influx and\nstaff shortages, the integration of artificial intelligence (AI) into triage\nprotocols has gained attention. This study compares the performance of three AI\nmodels [Natural Language Processing (NLP), Large Language Models (LLM), and\nJoint Embedding Predictive Architecture (JEPA)] in predicting triage outcomes\nagainst the FRENCH scale and clinical practice.We conducted a retrospective\nanalysis of a prospectively recruited cohort gathering adult patient triage\ndata over a 7-month period at the Roger Salengro Hospital ED (Lille, France).\nThree AI models were trained and validated : (1) TRIAGEMASTER (NLP), (2)\nURGENTIAPARSE (LLM), and (3) EMERGINET (JEPA). Data included demographic\ndetails, verbatim chief complaints, vital signs, and triage outcomes based on\nthe FRENCH scale and GEMSA coding. The primary outcome was the concordance of\nAI-predicted triage level with the FRENCH gold-standard. It was assessed thanks\nto various indicators : F1-Score, Weighted Kappa, Spearman, MAE, RMSE. The LLM\nmodel (URGENTIAPARSE) showed higher accuracy (composite score: 2.514) compared\nto JEPA (EMERGINET, 0.438) and NLP (TRIAGEMASTER, -3.511), outperforming nurse\ntriage (-4.343). Secondary analyses highlighted the effectiveness of\nURGENTIAPARSE in predicting hospitalization needs (GEMSA) and its robustness\nwith structured data versus raw transcripts (either for GEMSA prediction or for\nFRENCH prediction). LLM architecture, through abstraction of patient\nrepresentations, offers the most accurate triage predictions among tested\nmodels. Integrating AI into ED workflows could enhance patient safety and\noperational efficiency, though integration into clinical workflows requires\naddressing model limitations and ensuring ethical transparency.", "comment": "15 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.01080v1", "categories": ["cs.LG", "cs.PF"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01080v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "三种人工智能模型（NLP、LLM、JEPA）在急诊科分诊预测中的开发与比较评估：一项为期7个月的回顾性概念验证研究", "tldr": "本研究开发并比较了NLP、LLM和JEPA三种AI模型在急诊分诊预测中的表现，发现LLM模型（URGENTIAPARSE）在准确性上优于其他模型和护士分诊。", "motivation": "急诊科（EDs）中分诊错误（包括分诊不足和分诊过度）是持续存在的挑战。随着患者数量的增加和人员短缺，将人工智能（AI）整合到分诊协议中受到了关注。", "method": "本研究对在法国里尔Roger Salengro医院急诊科招募的成人患者分诊数据进行了为期7个月的回顾性分析。训练并验证了三种AI模型：TRIAGEMASTER (NLP)、URGENTIAPARSE (LLM) 和 EMERGINET (JEPA)。数据包括人口统计学细节、主诉原文、生命体征以及基于FRENCH量表和GEMSA编码的分诊结果。主要结果是AI预测的分诊级别与FRENCH金标准的一致性，通过F1-Score、Weighted Kappa、Spearman、MAE、RMSE等指标进行评估。", "result": "LLM模型（URGENTIAPARSE）显示出更高的准确性（综合得分：2.514），优于JEPA（EMERGINET，0.438）和NLP（TRIAGEMASTER，-3.511），并且表现优于护士分诊（-4.343）。次要分析强调了URGENTIAPARSE在预测住院需求（GEMSA）方面的有效性及其在结构化数据而非原始转录本中的鲁棒性。", "conclusion": "LLM架构通过患者表征的抽象，在所测试的模型中提供了最准确的分诊预测。将AI整合到急诊科工作流程中可以提高患者安全和运营效率，尽管整合到临床工作流程中需要解决模型局限性并确保伦理透明度。", "translation": "分诊错误，包括分诊不足和分诊过度，是急诊科（EDs）中持续存在的挑战。随着患者数量的增加和人员短缺，将人工智能（AI）整合到分诊协议中受到了关注。本研究比较了三种AI模型[自然语言处理（NLP）、大型语言模型（LLM）和联合嵌入预测架构（JEPA）]在预测分诊结果方面与FRENCH量表和临床实践的表现。我们对在法国里尔Roger Salengro医院急诊科招募的成人患者分诊数据进行了为期7个月的回顾性分析。训练并验证了三种AI模型：(1) TRIAGEMASTER (NLP)，(2) URGENTIAPARSE (LLM)，和 (3) EMERGINET (JEPA)。数据包括人口统计学细节、主诉原文、生命体征以及基于FRENCH量表和GEMSA编码的分诊结果。主要结果是AI预测的分诊级别与FRENCH金标准的一致性。通过各种指标进行评估：F1-Score、Weighted Kappa、Spearman、MAE、RMSE。LLM模型（URGENTIAPARSE）显示出更高的准确性（综合得分：2.514），优于JEPA（EMERGINET，0.438）和NLP（TRIAGEMASTER，-3.511），并且表现优于护士分诊（-4.343）。次要分析强调了URGENTIAPARSE在预测住院需求（GEMSA）方面的有效性及其在结构化数据而非原始转录本中的鲁棒性（无论是GEMSA预测还是FRENCH预测）。LLM架构通过患者表征的抽象，在所测试的模型中提供了最准确的分诊预测。将AI整合到急诊科工作流程中可以提高患者安全和运营效率，尽管整合到临床工作流程中需要解决模型局限性并确保伦理透明度。", "summary": "本研究旨在比较三种AI模型（NLP、LLM、JEPA）在急诊分诊预测中的性能。通过对Roger Salengro医院急诊科7个月的回顾性数据分析，训练并评估了TRIAGEMASTER (NLP)、URGENTIAPARSE (LLM) 和 EMERGINET (JEPA) 模型。结果显示，LLM模型（URGENTIAPARSE）在预测准确性方面显著优于JEPA、NLP模型以及传统护士分诊。该研究强调了LLM在抽象患者表征方面的优势，并指出AI集成可提升急诊安全和效率，但需关注模型局限性和伦理问题。", "keywords": "急诊分诊, 人工智能, LLM, NLP, JEPA", "comments": "本研究的创新点在于首次比较了NLP、LLM和JEPA三种不同架构的AI模型在急诊分诊预测中的表现，并明确指出LLM模型具有更高的准确性，甚至超越了人类护士分诊。其重要性在于为急诊科引入AI辅助分诊提供了强有力的概念验证和技术方向，有望缓解急诊压力并提高患者安全。然而，研究也提及了模型整合到临床工作流中需要解决的局限性和伦理透明性问题，这提示了未来实际部署的复杂性。"}}
{"id": "2507.01790", "title": "How Do Vision-Language Models Process Conflicting Information Across Modalities?", "authors": ["Tianze Hua", "Tian Yun", "Ellie Pavlick"], "summary": "AI models are increasingly required to be multimodal, integrating disparate\ninput streams into a coherent state representation on which subsequent\nbehaviors and actions can be based. This paper seeks to understand how such\nmodels behave when input streams present conflicting information. Focusing\nspecifically on vision-language models, we provide inconsistent inputs (e.g.,\nan image of a dog paired with the caption \"A photo of a cat\") and ask the model\nto report the information present in one of the specific modalities (e.g.,\n\"What does the caption say / What is in the image?\"). We find that models often\nfavor one modality over the other, e.g., reporting the image regardless of what\nthe caption says, but that different models differ in which modality they\nfavor. We find evidence that the behaviorally preferred modality is evident in\nthe internal representational structure of the model, and that specific\nattention heads can restructure the representations to favor one modality over\nthe other. Moreover, we find modality-agnostic \"router heads\" which appear to\npromote answers about the modality requested in the instruction, and which can\nbe manipulated or transferred in order to improve performance across datasets\nand modalities. Together, the work provides essential steps towards identifying\nand controlling if and how models detect and resolve conflicting signals within\ncomplex multimodal environments.", "comment": "All code and resources are available at:\n  https://github.com/ethahtz/vlm_conflicting_info_processing", "pdf_url": "http://arxiv.org/pdf/2507.01790v1", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01790v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "视觉语言模型如何处理跨模态的冲突信息？", "tldr": "本文探讨了视觉语言模型在面对冲突信息时的行为，发现模型常偏向某一模态，且这种偏好体现在其内部结构中，并识别出可操纵的“路由头”以控制模态偏好。", "motivation": "AI模型日益需要多模态能力，整合不同输入流以形成连贯的状态表示。本文旨在理解当输入流呈现冲突信息时，此类模型如何表现。", "method": "我们专注于视觉语言模型，提供不一致的输入（例如，狗的图像配以“猫的照片”的标题），并要求模型报告特定模态中的信息（例如，“标题说了什么/图像中有什么？”）。", "result": "我们发现模型通常偏爱一种模态而非另一种模态（例如，无论标题说什么都报告图像信息），但不同模型偏爱的模态不同。我们发现证据表明行为上偏爱的模态在其内部表征结构中是显而易见的，并且特定的注意力头可以重构表征以偏爱一种模态而非另一种。此外，我们发现了与模态无关的“路由头”，它们似乎能促进对指令中请求模态的回答，并且可以被操纵或转移，以提高跨数据集和模态的性能。", "conclusion": "这项工作为识别和控制模型如何检测和解决复杂多模态环境中的冲突信号，迈出了重要一步。", "translation": "AI模型日益需要多模态能力，将不同的输入流整合为一个连贯的状态表示，在此基础上可以进行后续的行为和动作。本文旨在理解当输入流呈现冲突信息时，此类模型如何表现。我们特别关注视觉语言模型，提供不一致的输入（例如，一张狗的图像配上“猫的照片”的标题），并要求模型报告特定模态中存在的信息（例如，“标题说了什么/图像中有什么？”）。我们发现模型通常偏爱一种模态而非另一种模态，例如，无论标题说什么都报告图像信息，但不同模型偏爱的模态不同。我们发现证据表明，行为上偏爱的模态在模型的内部表征结构中是显而易见的，并且特定的注意力头可以重构表征以偏爱一种模态而非另一种。此外，我们发现了与模态无关的“路由头”，它们似乎能促进对指令中请求模态的回答，并且可以被操纵或转移，以提高跨数据集和模态的性能。总而言之，这项工作为识别和控制模型是否以及如何检测和解决复杂多模态环境中的冲突信号，迈出了重要一步。", "summary": "本文研究了视觉语言模型在处理跨模态冲突信息时的行为。研究通过向模型提供不一致的图像-文本对并询问特定模态信息，发现模型常表现出对某一模态的偏好。这种偏好体现在模型的内部表征结构中，且特定的注意力头能够重塑表征以支持某种模态。此外，研究还发现了“路由头”，这些头部能促进模型根据指令回答特定模态信息，并且可以通过操纵这些头部来提升模型在不同数据集和模态上的性能。这项工作为理解和控制模型如何处理多模态冲突信号提供了关键见解。", "keywords": "视觉语言模型, 冲突信息, 多模态, 注意力头, 路由头", "comments": "这项研究的创新之处在于深入探讨了视觉语言模型在面对冲突信息时的内在机制，特别是识别出“路由头”这一概念。这些“路由头”不仅揭示了模型处理模态信息的方式，更重要的是，它们的可操纵性为未来构建更鲁棒、更可控的多模态AI模型提供了新的方向。这对于AI在复杂现实世界中的应用具有重要意义。"}}
{"id": "2507.01472", "title": "Optimizing Methane Detection On Board Satellites: Speed, Accuracy, and Low-Power Solutions for Resource-Constrained Hardware", "authors": ["Jonáš Herec", "Vít Růžička", "Rado Pitoňák"], "summary": "Methane is a potent greenhouse gas, and detecting its leaks early via\nhyperspectral satellite imagery can help mitigate climate change. Meanwhile,\nmany existing missions operate in manual tasking regimes only, thus missing\npotential events of interest. To overcome slow downlink rates cost-effectively,\nonboard detection is a viable solution. However, traditional methane\nenhancement methods are too computationally demanding for resource-limited\nonboard hardware. This work accelerates methane detection by focusing on\nefficient, low-power algorithms. We test fast target detection methods (ACE,\nCEM) that have not been previously used for methane detection and propose a\nMag1c-SAS - a significantly faster variant of the current state-of-the-art\nalgorithm for methane detection: Mag1c. To explore their true detection\npotential, we integrate them with a machine learning model (U-Net, LinkNet).\nOur results identify two promising candidates (Mag1c-SAS and CEM), both\nacceptably accurate for the detection of strong plumes and computationally\nefficient enough for onboard deployment: one optimized more for accuracy, the\nother more for speed, achieving up to ~100x and ~230x faster computation than\noriginal Mag1c on resource-limited hardware. Additionally, we propose and\nevaluate three band selection strategies. One of them can outperform the method\ntraditionally used in the field while using fewer channels, leading to even\nfaster processing without compromising accuracy. This research lays the\nfoundation for future advancements in onboard methane detection with minimal\nhardware requirements, improving timely data delivery. The produced code, data,\nand models are open-sourced and can be accessed from\nhttps://github.com/zaitra/methane-filters-benchmark.", "comment": "This is a preprint of a paper accepted for the EDHPC 2025 Conference", "pdf_url": "http://arxiv.org/pdf/2507.01472v1", "categories": ["cs.CV", "cs.LG", "cs.PF"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01472v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "卫星载荷甲烷检测优化：针对资源受限硬件的速度、精度和低功耗解决方案", "tldr": "本文提出并评估了新的高效、低功耗算法（Mag1c-SAS和CEM）以及波段选择策略，以在资源受限的卫星硬件上实现快速、准确的甲烷泄漏检测。", "motivation": "甲烷是强效温室气体，早期通过高光谱卫星图像检测其泄漏有助于缓解气候变化。现有任务多为手动调度，错过潜在事件。为克服慢速下行链路成本问题，板载检测是可行方案，但传统方法计算要求高，不适用于资源受限的板载硬件。", "method": "本研究通过专注于高效、低功耗算法来加速甲烷检测。测试了以前未用于甲烷检测的快速目标检测方法（ACE、CEM），并提出了Mag1c-SAS，它是现有最先进甲烷检测算法Mag1c的一个显著加速变体。为了探索其真正的检测潜力，将这些方法与机器学习模型（U-Net、LinkNet）集成。此外，还提出并评估了三种波段选择策略。", "result": "研究确定了Mag1c-SAS和CEM作为两个有前景的候选方案，两者都能以可接受的精度检测强甲烷羽流，并且计算效率足以进行板载部署。Mag1c-SAS和CEM在资源受限硬件上分别比原始Mag1c计算速度快约100倍和230倍。其中一种波段选择策略在使用更少通道的情况下，性能优于传统方法，从而在不损害精度的情况下实现更快的处理。", "conclusion": "这项研究为未来在最小硬件要求下进行板载甲烷检测奠定了基础，提高了数据的及时交付能力。", "translation": "甲烷是一种强效温室气体，通过高光谱卫星图像早期检测其泄漏有助于缓解气候变化。同时，许多现有任务仅在手动调度模式下运行，因此错过了潜在的感兴趣事件。为了经济高效地克服缓慢的下行链路速率，板载检测是一种可行的解决方案。然而，传统的甲烷增强方法对于资源有限的板载硬件来说计算量过大。这项工作通过专注于高效、低功耗算法来加速甲烷检测。我们测试了以前未用于甲烷检测的快速目标检测方法（ACE、CEM），并提出了Mag1c-SAS——这是当前最先进的甲烷检测算法Mag1c的一个显著更快的变体。为了探索其真正的检测潜力，我们将其与机器学习模型（U-Net、LinkNet）集成。我们的结果确定了两个有前景的候选方案（Mag1c-SAS和CEM），两者都能以可接受的精度检测强羽流，并且计算效率足以进行板载部署：其中一个更侧重于精度，另一个更侧重于速度，在资源受限硬件上比原始Mag1c实现高达约100倍和约230倍的计算速度提升。此外，我们提出并评估了三种波段选择策略。其中一种在使用更少通道的情况下，性能优于该领域传统使用的方法，从而在不损害精度的情况下实现更快的处理。这项研究为未来在最小硬件要求下进行板载甲烷检测奠定了基础，从而改善了数据的及时交付。所产生的代码、数据和模型均已开源，可从https://github.com/zaitra/methane-filters-benchmark 访问。", "summary": "本文旨在解决资源受限卫星硬件上甲烷检测的计算效率问题，以实现及时的泄漏监测。研究测试了ACE和CEM等快速目标检测方法，并提出了一种名为Mag1c-SAS的Mag1c算法的加速变体。通过与U-Net和LinkNet等机器学习模型结合，研究发现Mag1c-SAS和CEM是用于板载部署的有效候选方案，它们在保持可接受精度的同时，计算速度分别比原始Mag1c快约100倍和230倍。此外，研究还提出了一种优于传统方法的波段选择策略，进一步提高了处理速度而不牺牲精度。这项工作为未来低硬件要求的卫星板载甲烷检测奠定了基础。", "keywords": "甲烷检测, 卫星载荷, 低功耗, 高光谱图像, 目标检测", "comments": "这项研究在卫星板载甲烷检测领域具有重要创新性，通过引入和优化低功耗、高效率的算法（如Mag1c-SAS和CEM），显著提升了检测速度和资源利用率。其将传统目标检测方法与机器学习模型结合，并关注波段选择，为实时、自动化的甲烷泄漏监测提供了切实可行的解决方案，对于气候变化缓解具有重要意义。所提出的方法在资源受限硬件上的显著性能提升是其核心亮点。"}}
{"id": "2507.01098", "title": "Proof of a perfect platonic representation hypothesis", "authors": ["Liu Ziyin", "Isaac Chuang"], "summary": "In this note, we elaborate on and explain in detail the proof given by Ziyin\net al. (2025) of the \"perfect\" Platonic Representation Hypothesis (PRH) for the\nembedded deep linear network model (EDLN). We show that if trained with SGD,\ntwo EDLNs with different widths and depths and trained on different data will\nbecome Perfectly Platonic, meaning that every possible pair of layers will\nlearn the same representation up to a rotation. Because most of the global\nminima of the loss function are not Platonic, that SGD only finds the perfectly\nPlatonic solution is rather extraordinary. The proof also suggests at least six\nways the PRH can be broken. We also show that in the EDLN model, the emergence\nof the Platonic representations is due to the same reason as the emergence of\nprogressive sharpening. This implies that these two seemingly unrelated\nphenomena in deep learning can, surprisingly, have a common cause. Overall, the\ntheory and proof highlight the importance of understanding emergent \"entropic\nforces\" due to the irreversibility of SGD training and their role in\nrepresentation learning. The goal of this note is to be instructive and avoid\nlengthy technical details.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01098v1", "categories": ["cs.LG", "cond-mat.dis-nn", "q-bio.NC", "stat.ML"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01098v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "完美柏拉图表示假说的证明", "tldr": "本文详细阐述并解释了嵌入式深度线性网络模型（EDLN）中“完美”柏拉图表示假说（PRH）的证明，指出SGD训练的EDLN会变得完美柏拉图式，且SGD倾向于找到这种非寻常解，并揭示了PRH可能被打破的方式以及柏拉图表示和渐进锐化之间的共同原因。", "motivation": "本文旨在详细阐述并解释Ziyin等人（2025）提出的关于嵌入式深度线性网络模型（EDLN）中“完美”柏拉图表示假说（PRH）的证明。尤其值得关注的是，尽管损失函数的大多数全局最小值并非柏拉图式，但随机梯度下降（SGD）却能找到完美的柏拉图解，这一现象非同寻常，促使作者深入探讨其原因。", "method": "本文通过详细阐述和解释Ziyin等人（2025）对“完美”柏拉图表示假说（PRH）的证明，并在此基础上进行了扩展。研究方法是展示了在随机梯度下降（SGD）训练下，不同宽度和深度的EDLN即使在不同数据上训练也能达到完美柏拉图状态。", "result": "研究结果表明，如果使用随机梯度下降（SGD）进行训练，不同宽度、深度并在不同数据上训练的嵌入式深度线性网络模型（EDLN）将变得完美柏拉图式，即每对层都能学习到相同的表示（旋转不变）。尽管损失函数的大多数全局最小值并非柏拉图式，但SGD却能找到这种完美的柏拉图解，这被认为是相当非凡的。此外，该证明还提出了至少六种可能打破柏拉图表示假说（PRH）的方式。研究还发现，在EDLN模型中，柏拉图表示的出现与渐进锐化的出现原因相同，这意味着深度学习中这两个看似不相关的现象可能具有共同的原因。", "conclusion": "本文的理论和证明强调了理解随机梯度下降（SGD）训练不可逆性所导致的“熵力”的出现及其在表示学习中的作用的重要性。研究结果暗示了深度学习中看似不相关的柏拉图表示和渐进锐化现象可能具有共同的根本原因。", "translation": "在这篇笔记中，我们详细阐述并解释了Ziyin等人（2025）提出的关于嵌入式深度线性网络模型（EDLN）中“完美”柏拉图表示假说（PRH）的证明。我们展示了，如果用随机梯度下降（SGD）进行训练，两个具有不同宽度和深度、并在不同数据上训练的EDLN将变得完美柏拉图式，这意味着每对可能的层都将学习到相同的表示（旋转不变）。由于损失函数的大多数全局最小值并非柏拉图式，因此SGD仅能找到完美的柏拉图解是相当非凡的。该证明还提出了至少六种可能打破PRH的方式。我们还表明，在EDLN模型中，柏拉图表示的出现与渐进锐化的出现原因相同。这意味着深度学习中这两个看似不相关的现象，出人意料地可能具有共同的原因。总的来说，该理论和证明强调了理解由SGD训练不可逆性引起的“熵力”的出现及其在表示学习中作用的重要性。这篇笔记的目标是具有指导性，并避免冗长的技术细节。", "summary": "本文详细阐述并解释了嵌入式深度线性网络模型（EDLN）中“完美”柏拉图表示假说（PRH）的证明。研究发现，通过随机梯度下降（SGD）训练的EDLN，即使结构和数据不同，也能达到完美柏拉图状态，即层间学习到旋转不变的相同表示。作者指出，SGD能找到这种非寻常的完美柏拉图解，并提出了六种可能打破PRH的方式。此外，文章揭示了柏拉图表示的出现与渐进锐化具有共同的原因。整体而言，该研究强调了理解SGD训练不可逆性所产生的“熵力”在表示学习中的关键作用。", "keywords": "柏拉图表示假说, 深度线性网络, 随机梯度下降, 渐进锐化, 熵力", "comments": "这篇论文通过详细解释和扩展一个关于完美柏拉图表示假说的证明，揭示了深度线性网络在SGD训练下表现出的惊人特性。其创新之处在于指出SGD能够收敛到一种非寻常的、完美柏拉图式的全局最优解，尽管大多数全局最小值并非如此。此外，论文将柏拉图表示的出现与渐进锐化联系起来，揭示了深度学习中两个看似不相关的现象可能具有共同的“熵力”驱动机制，这对于理解深度学习的涌现行为具有重要意义。论文还明确指出了PRH可能被打破的多种方式，为未来的研究提供了方向。"}}
{"id": "2507.01802", "title": "The Anatomy of Evidence: An Investigation Into Explainable ICD Coding", "authors": ["Katharina Beckh", "Elisa Studeny", "Sujan Sai Gannamaneni", "Dario Antweiler", "Stefan Rüping"], "summary": "Automatic medical coding has the potential to ease documentation and billing\nprocesses. For this task, transparency plays an important role for medical\ncoders and regulatory bodies, which can be achieved using explainability\nmethods. However, the evaluation of these approaches has been mostly limited to\nshort text and binary settings due to a scarcity of annotated data. Recent\nefforts by Cheng et al. (2023) have introduced the MDACE dataset, which\nprovides a valuable resource containing code evidence in clinical records. In\nthis work, we conduct an in-depth analysis of the MDACE dataset and perform\nplausibility evaluation of current explainable medical coding systems from an\napplied perspective. With this, we contribute to a deeper understanding of\nautomatic medical coding and evidence extraction. Our findings reveal that\nground truth evidence aligns with code descriptions to a certain degree. An\ninvestigation into state-of-the-art approaches shows a high overlap with ground\ntruth evidence. We propose match measures and highlight success and failure\ncases. Based on our findings, we provide recommendations for developing and\nevaluating explainable medical coding systems.", "comment": "Accepted to ACL 2025 Findings", "pdf_url": "http://arxiv.org/pdf/2507.01802v1", "categories": ["cs.CL", "cs.LG"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01802v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "证据的剖析：可解释ICD编码的调查", "tldr": "本文深入分析了MDACE数据集，并评估了现有可解释医疗编码系统的合理性，以增进对自动医疗编码和证据提取的理解。", "motivation": "自动医疗编码虽然能简化流程，但透明度对医疗编码员和监管机构至关重要。现有解释性方法的评估受限于数据稀缺。MDACE数据集提供了带代码证据的临床记录，为深入研究提供了资源。", "method": "对MDACE数据集进行深入分析，并从应用角度对当前可解释医疗编码系统进行合理性评估。研究了最先进方法与真实证据的重叠度，并提出了匹配度量。", "result": "发现真实证据在一定程度上与代码描述一致。最先进方法与真实证据高度重叠。", "conclusion": "本研究有助于深入理解自动医疗编码和证据提取，并为开发和评估可解释医疗编码系统提供了建议。", "translation": "自动医疗编码有潜力简化文档和账单流程。对于这项任务，透明度对医疗编码员和监管机构至关重要，这可以通过可解释性方法实现。然而，由于带注释数据的稀缺性，这些方法的评估主要限于短文本和二元设置。Cheng 等人（2023）最近的努力引入了 MDACE 数据集，它提供了一个包含临床记录中代码证据的宝贵资源。在这项工作中，我们对 MDACE 数据集进行了深入分析，并从应用角度对当前可解释医疗编码系统进行了合理性评估。通过这项工作，我们有助于更深入地理解自动医疗编码和证据提取。我们的发现表明，真实证据在一定程度上与代码描述一致。对最先进方法的调查显示与真实证据高度重叠。我们提出了匹配度量并强调了成功和失败案例。基于我们的发现，我们为开发和评估可解释医疗编码系统提供了建议。", "summary": "本文利用MDACE数据集，深入分析了自动医疗编码中的可解释性问题。研究评估了现有可解释医疗编码系统的合理性，发现真实证据与代码描述和最先进方法的输出高度一致。研究提出了匹配度量，并为未来可解释医疗编码系统的开发和评估提供了建议，旨在提高该领域的透明度和理解。", "keywords": "医疗编码, 可解释性, MDACE数据集, 证据提取, 合理性评估", "comments": "本文利用新数据集MDACE，填补了可解释医疗编码领域数据稀缺的空白，对现有系统的合理性评估具有重要意义。提出的匹配度量和建议对未来可解释AI在医疗领域的应用具有指导价值。"}}
{"id": "2507.01478", "title": "Active Control Points-based 6DoF Pose Tracking for Industrial Metal Objects", "authors": ["Chentao Shen", "Ding Pan", "Mingyu Mei", "Zaixing He", "Xinyue Zhao"], "summary": "Visual pose tracking is playing an increasingly vital role in industrial\ncontexts in recent years. However, the pose tracking for industrial metal\nobjects remains a challenging task especially in the real world-environments,\ndue to the reflection characteristic of metal objects. To address this issue,\nwe propose a novel 6DoF pose tracking method based on active control points.\nThe method uses image control points to generate edge feature for optimization\nactively instead of 6DoF pose-based rendering, and serve them as optimization\nvariables. We also introduce an optimal control point regression method to\nimprove robustness. The proposed tracking method performs effectively in both\ndataset evaluation and real world tasks, providing a viable solution for\nreal-time tracking of industrial metal objects. Our source code is made\npublicly available at: https://github.com/tomatoma00/ACPTracking.", "comment": "preprint version", "pdf_url": "http://arxiv.org/pdf/2507.01478v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01478v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于主动控制点的工业金属物体6自由度姿态跟踪", "tldr": "针对工业金属物体反光导致姿态跟踪困难的问题，本文提出了一种基于主动控制点的新型6自由度姿态跟踪方法，该方法通过图像控制点生成边缘特征进行优化，并在数据集和实际任务中表现出色，为实时跟踪提供了可行方案。", "motivation": "工业金属物体由于其反光特性，在实际环境中进行姿态跟踪仍然是一项具有挑战性的任务。", "method": "本文提出了一种基于主动控制点的新型6自由度姿态跟踪方法。该方法利用图像控制点主动生成边缘特征进行优化，并将其作为优化变量，而非传统的基于6自由度姿态的渲染。此外，还引入了一种最优控制点回归方法来提高鲁棒性。", "result": "所提出的跟踪方法在数据集评估和实际任务中均表现出有效性。", "conclusion": "该方法为工业金属物体的实时跟踪提供了一个可行的解决方案。", "translation": "近年来，视觉姿态跟踪在工业领域发挥着越来越重要的作用。然而，由于金属物体的反射特性，工业金属物体的姿态跟踪仍然是一项具有挑战性的任务，尤其是在真实世界环境中。为了解决这个问题，我们提出了一种基于主动控制点的新型6自由度姿态跟踪方法。该方法使用图像控制点主动生成边缘特征进行优化，而不是基于6自由度姿态的渲染，并将其作为优化变量。我们还引入了一种最优控制点回归方法来提高鲁棒性。所提出的跟踪方法在数据集评估和实际任务中均表现出有效性，为工业金属物体的实时跟踪提供了一个可行的解决方案。我们的源代码已公开可用，网址为：https://github.com/tomatoma00/ACPTracking。", "summary": "本文提出了一种新颖的基于主动控制点的6自由度姿态跟踪方法，旨在解决工业金属物体因反光特性导致的姿态跟踪难题。该方法通过利用图像控制点主动生成边缘特征进行优化，并将其作为优化变量，而非传统的基于姿态渲染。同时，引入了最优控制点回归以增强鲁棒性。实验证明，该方法在数据集和实际应用中均表现出色，为工业金属物体的实时姿态跟踪提供了有效方案。", "keywords": "6自由度姿态跟踪, 工业金属物体, 主动控制点, 边缘特征, 实时跟踪", "comments": "这篇论文的创新点在于提出了基于主动控制点的姿态跟踪方法，避免了传统基于姿态渲染的复杂性，并有效解决了金属物体反光带来的挑战。通过将图像控制点作为优化变量并结合最优控制点回归，提高了跟踪的鲁棒性和实时性，对工业视觉领域具有重要意义。"}}
{"id": "2507.01117", "title": "A Neural Operator based on Dynamic Mode Decomposition", "authors": ["Nikita Sakovich", "Dmitry Aksenov", "Ekaterina Pleshakova", "Sergey Gataullin"], "summary": "The scientific computation methods development in conjunction with artificial\nintelligence technologies remains a hot research topic. Finding a balance\nbetween lightweight and accurate computations is a solid foundation for this\ndirection. The study presents a neural operator based on the dynamic mode\ndecomposition algorithm (DMD), mapping functional spaces, which combines DMD\nand deep learning (DL) for spatiotemporal processes efficient modeling. Solving\nPDEs for various initial and boundary conditions requires significant\ncomputational resources. The method suggested automatically extracts key modes\nand system dynamics using them to construct predictions, reducing computational\ncosts compared to traditional numerical methods. The approach has demonstrated\nits efficiency through comparative analysis of performance with closest\nanalogues DeepONet and FNO in the heat equation, Laplaces equation, and Burgers\nequation solutions approximation, where it achieves high reconstruction\naccuracy.", "comment": "30 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.01117v1", "categories": ["cs.LG", "68T07, 35A99"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01117v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "基于动态模态分解的神经算子", "tldr": "该研究提出了一种基于动态模态分解（DMD）的神经算子，将DMD与深度学习结合，用于高效建模时空过程，并在热方程、拉普拉斯方程和Burgers方程的求解中展现出高精度和计算效率。", "motivation": "科学计算方法与人工智能技术结合是热门研究方向，目标是找到轻量级和精确计算之间的平衡。传统数值方法求解偏微分方程（PDEs）需要大量计算资源。", "method": "提出了一种基于动态模态分解（DMD）算法的神经算子，它将DMD与深度学习（DL）相结合，用于高效建模时空过程。该方法自动提取关键模式和系统动力学，并利用它们进行预测。", "result": "该方法与DeepONet和FNO在热方程、拉普拉斯方程和Burgers方程的解逼近中进行了性能比较分析，结果表明它实现了高重建精度并降低了计算成本，展现了其效率。", "conclusion": "该研究提出的基于动态模态分解的神经算子能够有效结合DMD和深度学习的优势，为时空过程建模提供了一种高效且精确的计算方法，尤其在解决偏微分方程方面具有显著优势。", "translation": "科学计算方法与人工智能技术相结合的发展仍然是一个热门研究课题。在这个方向上，找到轻量级和精确计算之间的平衡是坚实的基础。本研究提出了一种基于动态模态分解（DMD）算法的神经算子，它映射功能空间，结合了DMD和深度学习（DL），用于高效建模时空过程。求解各种初始和边界条件下的偏微分方程需要大量的计算资源。所提出的方法自动提取关键模式和系统动力学，并利用它们构建预测，与传统数值方法相比，降低了计算成本。该方法通过与最接近的类似物DeepONet和FNO在热方程、拉普拉斯方程和Burgers方程解逼近中的性能比较分析，证明了其效率，并达到了高重建精度。", "summary": "本研究提出了一种基于动态模态分解（DMD）的神经算子，旨在通过结合DMD和深度学习（DL）来高效建模时空过程。该方法能够自动提取关键模式和系统动力学以进行预测，从而在求解偏微分方程时显著降低计算成本并提高重建精度。实验结果表明，与DeepONet和FNO等现有方法相比，该神经算子在处理热方程、拉普拉斯方程和Burgers方程时表现出卓越的效率和准确性。", "keywords": "神经算子, 动态模态分解, 深度学习, 偏微分方程, 时空过程", "comments": "该论文的创新点在于将动态模态分解（DMD）与深度学习相结合，构建了一个新型的神经算子。这种结合有效地利用了DMD在提取系统关键模式和动力学方面的优势，同时借助深度学习的函数映射能力，为高效、精确地求解偏微分方程（PDEs）提供了一条新途径。其重要性体现在解决了传统数值方法计算成本高昂的问题，为科学计算领域提供了一种轻量级且准确的解决方案。"}}
{"id": "2507.01484", "title": "What Really Matters for Robust Multi-Sensor HD Map Construction?", "authors": ["Xiaoshuai Hao", "Yuting Zhao", "Yuheng Ji", "Luanyuan Dai", "Peng Hao", "Dingzhe Li", "Shuai Cheng", "Rong Yin"], "summary": "High-definition (HD) map construction methods are crucial for providing\nprecise and comprehensive static environmental information, which is essential\nfor autonomous driving systems. While Camera-LiDAR fusion techniques have shown\npromising results by integrating data from both modalities, existing approaches\nprimarily focus on improving model accuracy and often neglect the robustness of\nperception models, which is a critical aspect for real-world applications. In\nthis paper, we explore strategies to enhance the robustness of multi-modal\nfusion methods for HD map construction while maintaining high accuracy. We\npropose three key components: data augmentation, a novel multi-modal fusion\nmodule, and a modality dropout training strategy. These components are\nevaluated on a challenging dataset containing 10 days of NuScenes data. Our\nexperimental results demonstrate that our proposed methods significantly\nenhance the robustness of baseline methods. Furthermore, our approach achieves\nstate-of-the-art performance on the clean validation set of the NuScenes\ndataset. Our findings provide valuable insights for developing more robust and\nreliable HD map construction models, advancing their applicability in\nreal-world autonomous driving scenarios. Project website:\nhttps://robomap-123.github.io.", "comment": "Accepted by IROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.01484v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01484v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "什么对鲁棒多传感器高清地图构建真正重要？", "tldr": "本文提出了三种关键组件（数据增强、新型多模态融合模块和模态丢弃训练策略）来提高多模态融合高清地图构建方法的鲁棒性，同时保持高精度，并在NuScenes数据集上取得了显著效果。", "motivation": "现有高清地图构建方法主要关注提高模型精度，但忽视了感知模型的鲁棒性，这对于实际应用至关重要。本文旨在探索增强多模态融合方法鲁棒性的策略。", "method": "本文提出了三个关键组件：数据增强、一种新型多模态融合模块和一种模态丢弃训练策略，用于提高多模态融合高清地图构建的鲁棒性。", "result": "实验结果表明，所提出的方法显著增强了基线方法的鲁棒性，并在NuScenes数据集的干净验证集上取得了最先进的性能。", "conclusion": "本文的研究结果为开发更鲁棒、更可靠的高清地图构建模型提供了宝贵见解，推动了其在实际自动驾驶场景中的应用。", "translation": "高精地图（HD map）构建方法对于提供精确、全面的静态环境信息至关重要，而这些信息是自动驾驶系统不可或缺的。尽管相机-激光雷达融合技术通过整合两种模态的数据展现了良好的前景，但现有方法主要关注提高模型精度，却往往忽视了感知模型的鲁棒性，这在实际应用中是一个关键方面。在本文中，我们探索了在保持高精度的同时，增强多模态融合方法在高清地图构建中鲁棒性的策略。我们提出了三个关键组件：数据增强、一种新型多模态融合模块和一种模态丢弃训练策略。这些组件在包含10天NuScenes数据的挑战性数据集上进行了评估。我们的实验结果表明，所提出的方法显著增强了基线方法的鲁棒性。此外，我们的方法在NuScenes数据集的干净验证集上取得了最先进的性能。我们的发现为开发更鲁棒、更可靠的高清地图构建模型提供了宝贵见解，推动了它们在实际自动驾驶场景中的适用性。项目网站：https://robomap-123.github.io。", "summary": "本文针对自动驾驶中高清地图构建方法鲁棒性不足的问题，提出了一种增强多模态融合方法鲁棒性的策略。该策略包含数据增强、新型多模态融合模块和模态丢弃训练策略三个关键组件。实验结果表明，这些组件显著提升了基线方法的鲁棒性，并在NuScenes数据集上达到了最先进的性能，为实际自动驾驶场景中鲁棒可靠的高清地图模型开发提供了重要方向。", "keywords": "高清地图构建, 多模态融合, 鲁棒性, 数据增强, 模态丢弃", "comments": "本文创新性地将研究重点从单一的精度提升转向了鲁棒性，这对于自动驾驶的实际部署具有重要意义。提出的数据增强、新型融合模块和模态丢弃训练策略是针对鲁棒性问题提出的具体解决方案，具有较强的工程实践价值。通过在挑战性数据集上的验证，展示了其有效性。"}}
{"id": "2507.01844", "title": "Low-Perplexity LLM-Generated Sequences and Where To Find Them", "authors": ["Arthur Wuhrmann", "Anastasiia Kucherenko", "Andrei Kucharavy"], "summary": "As Large Language Models (LLMs) become increasingly widespread, understanding\nhow specific training data shapes their outputs is crucial for transparency,\naccountability, privacy, and fairness. To explore how LLMs leverage and\nreplicate their training data, we introduce a systematic approach centered on\nanalyzing low-perplexity sequences - high-probability text spans generated by\nthe model. Our pipeline reliably extracts such long sequences across diverse\ntopics while avoiding degeneration, then traces them back to their sources in\nthe training data. Surprisingly, we find that a substantial portion of these\nlow-perplexity spans cannot be mapped to the corpus. For those that do match,\nwe quantify the distribution of occurrences across source documents,\nhighlighting the scope and nature of verbatim recall and paving a way toward\nbetter understanding of how LLMs training data impacts their behavior.", "comment": "Camera-ready version. Accepted to ACL 2025. 10 pages, 4 figures, 6\n  tables", "pdf_url": "http://arxiv.org/pdf/2507.01844v1", "categories": ["cs.CL", "cs.LG"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01844v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "低复杂度LLM生成序列及其发现", "tldr": "本研究引入了一种系统方法来分析LLM生成的低复杂度序列，并将其追溯到训练数据源，发现大部分此类序列无法映射到语料库，而可匹配的部分则揭示了LLM训练数据如何影响其行为。", "motivation": "随着大型语言模型（LLM）的日益普及，理解特定训练数据如何塑造其输出对于透明度、问责制、隐私和公平性至关重要。", "method": "研究引入了一种系统方法，专注于分析低复杂度序列（模型生成的高概率文本片段）。该流程能够可靠地提取跨越不同主题的长序列，同时避免退化，然后将它们追溯到训练数据中的来源。", "result": "令人惊讶的是，研究发现这些低复杂度序列中的很大一部分无法映射到语料库。对于那些确实匹配的序列，研究量化了它们在源文档中的出现分布，突出了逐字回忆的范围和性质。", "conclusion": "本研究为更好地理解LLM训练数据如何影响其行为铺平了道路。", "translation": "随着大型语言模型（LLM）的日益普及，理解特定训练数据如何塑造其输出对于透明度、问责制、隐私和公平性至关重要。为了探索LLM如何利用和复制其训练数据，我们引入了一种系统方法，专注于分析低复杂度序列——模型生成的高概率文本片段。我们的管道能够可靠地提取跨越不同主题的长序列，同时避免退化，然后将它们追溯到训练数据中的来源。令人惊讶的是，我们发现这些低复杂度序列中的很大一部分无法映射到语料库。对于那些确实匹配的序列，我们量化了它们在源文档中的出现分布，突出了逐字回忆的范围和性质，并为更好地理解LLM训练数据如何影响其行为铺平了道路。", "summary": "本研究提出了一种系统方法，用于分析大型语言模型（LLM）生成的低复杂度序列。该方法能够提取高概率文本片段并追溯其训练数据来源，旨在理解训练数据如何影响LLM输出。研究发现，大部分低复杂度序列无法与原始语料库匹配，而可匹配的部分则揭示了LLM的逐字回忆模式，这对于提升LLM的透明度、问责制和公平性具有重要意义。", "keywords": "LLM, 训练数据, 低复杂度序列, 逐字回忆, 透明度", "comments": "这项研究的创新之处在于其系统地分析LLM生成低复杂度序列并追溯其来源的方法。其发现，即大部分低复杂度序列无法映射回原始语料库，是一个令人惊讶且重要的结果，挑战了我们对LLM如何利用训练数据的现有理解。这为未来研究LLM的记忆机制和数据归因提供了新的方向，对于提升LLM的透明度和可解释性具有重要意义。"}}
{"id": "2507.01492", "title": "AVC-DPO: Aligned Video Captioning via Direct Preference Optimization", "authors": ["Jiyang Tang", "Hengyi Li", "Yifan Du", "Wayne Xin Zhao"], "summary": "Although video multimodal large language models (video MLLMs) have achieved\nsubstantial progress in video captioning tasks, it remains challenging to\nadjust the focal emphasis of video captions according to human preferences. To\naddress this limitation, we propose Aligned Video Captioning via Direct\nPreference Optimization (AVC-DPO), a post-training framework designed to\nenhance captioning capabilities in video MLLMs through preference alignment.\nOur approach designs enhanced prompts that specifically target temporal\ndynamics and spatial information-two key factors that humans care about when\nwatching a video-thereby incorporating human-centric preferences. AVC-DPO\nleverages the same foundation model's caption generation responses under varied\nprompt conditions to conduct preference-aware training and caption alignment.\nUsing this framework, we have achieved exceptional performance in the\nLOVE@CVPR'25 Workshop Track 1A: Video Detailed Captioning Challenge, achieving\nfirst place on the Video Detailed Captioning (VDC) benchmark according to the\nVDCSCORE evaluation metric.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01492v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01492v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "AVC-DPO：通过直接偏好优化实现对齐视频字幕", "tldr": "AVC-DPO是一个后训练框架，通过直接偏好优化（DPO）和增强提示来调整视频多模态大语言模型（MLLMs）的字幕，以更好地符合人类偏好，并在视频详细字幕挑战赛中取得第一名。", "motivation": "尽管视频多模态大语言模型（video MLLMs）在视频字幕任务中取得了显著进展，但根据人类偏好调整视频字幕的焦点仍然具有挑战性。", "method": "本文提出了AVC-DPO（通过直接偏好优化实现对齐视频字幕），这是一个后训练框架，旨在通过偏好对齐来增强视频MLLM的字幕生成能力。该方法设计了增强提示，专门针对人类观看视频时关心的两个关键因素：时间动态和空间信息。AVC-DPO利用同一基础模型在不同提示条件下的字幕生成响应，进行偏好感知训练和字幕对齐。", "result": "AVC-DPO在LOVE@CVPR'25 Workshop Track 1A：视频详细字幕挑战赛中表现出色，根据VDCSCORE评估指标在视频详细字幕（VDC）基准测试中获得第一名。", "conclusion": "AVC-DPO通过直接偏好优化和人类偏好对齐，显著提升了视频多模态大语言模型在视频字幕任务中的表现，尤其是在详细字幕方面。", "translation": "尽管视频多模态大语言模型（video MLLMs）在视频字幕任务中取得了显著进展，但根据人类偏好调整视频字幕的焦点仍然具有挑战性。为了解决这一限制，我们提出了AVC-DPO（通过直接偏好优化实现对齐视频字幕），这是一个后训练框架，旨在通过偏好对齐来增强视频MLLM的字幕生成能力。我们的方法设计了增强提示，专门针对时间动态和空间信息——人类观看视频时关心的两个关键因素——从而融入以人为中心的偏好。AVC-DPO利用同一基础模型在不同提示条件下的字幕生成响应，进行偏好感知训练和字幕对齐。使用这个框架，我们在LOVE@CVPR'25 Workshop Track 1A：视频详细字幕挑战赛中取得了优异的成绩，根据VDCSCORE评估指标在视频详细字幕（VDC）基准测试中获得第一名。", "summary": "本文提出了AVC-DPO，一个基于直接偏好优化的后训练框架，旨在解决视频多模态大语言模型在视频字幕生成中难以根据人类偏好调整焦点的问题。该方法通过设计关注时间动态和空间信息的增强提示，并利用同一基础模型在不同提示下的响应进行偏好感知训练和字幕对齐。AVC-DPO在LOVE@CVPR'25 Workshop Track 1A：视频详细字幕挑战赛中取得了第一名。", "keywords": "视频字幕, 直接偏好优化, 多模态大语言模型, 人类偏好, 后训练", "comments": "AVC-DPO的创新点在于它将直接偏好优化（DPO）应用于视频字幕任务，并通过设计特定的人类偏好提示（关注时间动态和空间信息）来引导模型。这种后训练框架有效地解决了现有视频MLLM在字幕生成中缺乏人类偏好的痛点，并通过在挑战赛中取得第一名证明了其有效性和重要性。"}}
{"id": "2507.01131", "title": "Tensor Decomposition Networks for Fast Machine Learning Interatomic Potential Computations", "authors": ["Yuchao Lin", "Cong Fu", "Zachary Krueger", "Haiyang Yu", "Maho Nakata", "Jianwen Xie", "Emine Kucukbenli", "Xiaofeng Qian", "Shuiwang Ji"], "summary": "$\\rm{SO}(3)$-equivariant networks are the dominant models for machine\nlearning interatomic potentials (MLIPs). The key operation of such networks is\nthe Clebsch-Gordan (CG) tensor product, which is computationally expensive. To\naccelerate the computation, we develop tensor decomposition networks (TDNs) as\na class of approximately equivariant networks whose CG tensor products are\nreplaced by low-rank tensor decompositions, such as the CANDECOMP/PARAFAC (CP)\ndecomposition. With the CP decomposition, we prove (i) a uniform bound on the\ninduced error of $\\rm{SO}(3)$-equivariance, and (ii) the universality of\napproximating any equivariant bilinear map. To further reduce the number of\nparameters, we propose path-weight sharing that ties all multiplicity-space\nweights across the $O(L^3)$ CG paths into a single path without compromising\nequivariance, where $L$ is the maximum angular degree. The resulting layer acts\nas a plug-and-play replacement for tensor products in existing networks, and\nthe computational complexity of tensor products is reduced from $O(L^6)$ to\n$O(L^4)$. We evaluate TDNs on PubChemQCR, a newly curated molecular relaxation\ndataset containing 105 million DFT-calculated snapshots. We also use existing\ndatasets, including OC20, and OC22. Results show that TDNs achieve competitive\nperformance with dramatic speedup in computations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01131v1", "categories": ["cs.LG", "physics.comp-ph"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01131v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "张量分解网络用于快速机器学习原子间势能计算", "tldr": "本文提出了张量分解网络（TDNs），通过用低秩张量分解（如CP分解）替代计算昂贵的Clebsch-Gordan张量积，来加速机器学习原子间势能（MLIPs）计算，显著提高了计算速度并保持了竞争力。", "motivation": "SO(3)等变网络是机器学习原子间势能（MLIPs）的主流模型，但其关键操作Clebsch-Gordan（CG）张量积计算成本高昂。", "method": "本文开发了张量分解网络（TDNs），通过使用低秩张量分解（例如CANDECOMP/PARAFAC (CP) 分解）来替代CG张量积，从而实现近似等变。对于CP分解，证明了SO(3)等变性的诱导误差的均匀界限以及近似任何等变双线性映射的普适性。为进一步减少参数数量，提出了路径权重共享机制，将所有多重空间权重绑定到单个路径上。", "result": "TDNs在PubChemQCR、OC20和OC22等分子弛豫数据集上进行了评估。结果表明，TDNs在计算速度上实现了显著提升（从O(L^6)降至O(L^4)），同时性能具有竞争力。", "conclusion": "张量分解网络（TDNs）作为现有网络中张量积的即插即用替代品，能够显著加速机器学习原子间势能计算，并在保持竞争性能的同时降低了计算复杂度。", "translation": "SO(3)等变网络是机器学习原子间势能（MLIPs）的主流模型。这类网络的关键操作是Clebsch-Gordan（CG）张量积，其计算成本高昂。为了加速计算，我们开发了张量分解网络（TDNs），作为一类近似等变网络，其CG张量积被低秩张量分解（如CANDECOMP/PARAFAC (CP) 分解）取代。通过CP分解，我们证明了(i) SO(3)等变性诱导误差的均匀界限，以及(ii) 近似任何等变双线性映射的普适性。为了进一步减少参数数量，我们提出了路径权重共享机制，将所有多重空间权重通过O(L^3)个CG路径绑定到一个单一路径上，而不损害等变性，其中L是最大角次数。由此产生的层可以作为现有网络中张量积的即插即用替代品，并且张量积的计算复杂度从O(L^6)降低到O(L^4)。我们在PubChemQCR（一个新整理的分子弛豫数据集，包含1.05亿个DFT计算快照）上评估了TDNs。我们还使用了现有数据集，包括OC20和OC22。结果表明，TDNs在计算速度显著提升的同时，取得了具有竞争力的性能。", "summary": "本文提出了一种名为张量分解网络（TDNs）的新型架构，旨在加速机器学习原子间势能（MLIPs）中的SO(3)等变网络计算。核心思想是将计算昂贵的Clebsch-Gordan（CG）张量积替换为低秩张量分解（如CP分解），从而实现近似等变性。研究证明了这种方法的误差界限和普适性，并引入了路径权重共享机制以进一步减少参数和计算复杂度。实验结果表明，TDNs在多个分子数据集上实现了显著的计算加速（复杂度从O(L^6)降至O(L^4)），同时保持了与现有方法相当的性能。", "keywords": "张量分解网络, 机器学习原子间势能, SO(3)等变网络, Clebsch-Gordan张量积, 低秩分解", "comments": "本文的主要创新点在于提出了一种通过张量分解来加速机器学习原子间势能计算的新方法，有效地解决了传统SO(3)等变网络中Clebsch-Gordan张量积计算成本高昂的问题。其提出的路径权重共享机制进一步优化了模型效率。这项工作为开发更高效的MLIPs模型提供了有价值的思路，尤其是在处理大规模分子数据集时，其显著的计算加速具有重要意义。"}}
{"id": "2507.01853", "title": "Eka-Eval : A Comprehensive Evaluation Framework for Large Language Models in Indian Languages", "authors": ["Samridhi Raj Sinha", "Rajvee Sheth", "Abhishek Upperwal", "Mayank Singh"], "summary": "The rapid advancement of Large Language Models (LLMs) has intensified the\nneed for evaluation frameworks that go beyond English centric benchmarks and\naddress the requirements of linguistically diverse regions such as India. We\npresent EKA-EVAL, a unified and production-ready evaluation framework that\nintegrates over 35 benchmarks, including 10 Indic-specific datasets, spanning\ncategories like reasoning, mathematics, tool use, long-context understanding,\nand reading comprehension. Compared to existing Indian language evaluation\ntools, EKA-EVAL offers broader benchmark coverage, with built-in support for\ndistributed inference, quantization, and multi-GPU usage. Our systematic\ncomparison positions EKA-EVAL as the first end-to-end, extensible evaluation\nsuite tailored for both global and Indic LLMs, significantly lowering the\nbarrier to multilingual benchmarking. The framework is open-source and publicly\navailable at https://github.com/lingo-iitgn/ eka-eval and a part of ongoing EKA\ninitiative (https://eka.soket.ai), which aims to scale up to over 100\nbenchmarks and establish a robust, multilingual evaluation ecosystem for LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01853v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01853v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "Eka-Eval：一个针对印度语言大型语言模型的综合评估框架", "tldr": "EKA-EVAL是一个针对印度语言LLM的综合评估框架，集成了35+基准，支持分布式推理和多GPU，旨在降低多语言基准测试的门槛。", "motivation": "现有的大型语言模型（LLMs）评估框架主要以英语为中心，无法满足印度等语言多样化地区的需求。因此，迫切需要一个超越英语基准、能够有效评估印度语言LLM的综合框架。", "method": "本文提出了EKA-EVAL，一个统一且生产就绪的评估框架。该框架集成了超过35个基准，包括10个印度特定数据集，涵盖推理、数学、工具使用、长上下文理解和阅读理解等多个类别。EKA-EVAL内置支持分布式推理、量化和多GPU使用。", "result": "EKA-EVAL提供了比现有印度语言评估工具更广泛的基准覆盖，并且是第一个为全球和印度LLM量身定制的端到端、可扩展的评估套件，显著降低了多语言基准测试的门槛。", "conclusion": "EKA-EVAL是一个开源的综合评估框架，旨在为LLM建立一个强大、多语言的评估生态系统，并计划未来扩展到100多个基准，持续推动多语言LLM评估的发展。", "translation": "大型语言模型（LLMs）的快速发展，加剧了对超越以英语为中心的基准，并能满足印度等语言多样化地区需求的评估框架的需求。我们提出了EKA-EVAL，一个统一且生产就绪的评估框架，它集成了超过35个基准，包括10个印度特定数据集，涵盖推理、数学、工具使用、长上下文理解和阅读理解等类别。与现有印度语言评估工具相比，EKA-EVAL提供了更广泛的基准覆盖，内置支持分布式推理、量化和多GPU使用。我们的系统比较将EKA-EVAL定位为第一个为全球和印度LLM量身定制的端到端、可扩展的评估套件，显著降低了多语言基准测试的门槛。该框架是开源的，并可在https://github.com/lingo-iitgn/eka-eval公开获取，同时也是正在进行的EKA倡议（https://eka.soket.ai）的一部分，该倡议旨在扩展到100多个基准，并为LLM建立一个强大、多语言的评估生态系统。", "summary": "EKA-EVAL是一个专为印度语言大型语言模型设计的综合性、生产就绪的评估框架。它集成了超过35个基准（包括10个印度特定数据集），涵盖多项能力，并支持分布式推理和多GPU使用。该框架旨在克服现有英语中心评估工具的局限性，成为首个针对全球及印度LLM的端到端、可扩展的多语言评估解决方案，显著降低了多语言基准测试的难度。EKA-EVAL是开源的，并计划持续扩展以构建一个强大的多语言评估生态系统。", "keywords": "大型语言模型, 评估框架, 印度语言, 多语言基准, EKA-EVAL", "comments": "EKA-EVAL的创新之处在于其专注于非英语（特别是印度语言）LLM的评估，填补了现有评估框架的空白。其集成的广泛基准和对分布式推理、多GPU的支持，使其成为一个实用且高效的工具。作为一个开源项目，它有望推动多语言LLM评估领域的发展，并为研究者和开发者提供宝贵的资源。"}}
{"id": "2507.01667", "title": "What does really matter in image goal navigation?", "authors": ["Gianluca Monaci", "Philippe Weinzaepfel", "Christian Wolf"], "summary": "Image goal navigation requires two different skills: firstly, core navigation\nskills, including the detection of free space and obstacles, and taking\ndecisions based on an internal representation; and secondly, computing\ndirectional information by comparing visual observations to the goal image.\nCurrent state-of-the-art methods either rely on dedicated image-matching, or\npre-training of computer vision modules on relative pose estimation. In this\npaper, we study whether this task can be efficiently solved with end-to-end\ntraining of full agents with RL, as has been claimed by recent work. A positive\nanswer would have impact beyond Embodied AI and allow training of relative pose\nestimation from reward for navigation alone. In a large study we investigate\nthe effect of architectural choices like late fusion, channel stacking,\nspace-to-depth projections and cross-attention, and their role in the emergence\nof relative pose estimators from navigation training. We show that the success\nof recent methods is influenced up to a certain extent by simulator settings,\nleading to shortcuts in simulation. However, we also show that these\ncapabilities can be transferred to more realistic setting, up to some extend.\nWe also find evidence for correlations between navigation performance and\nprobed (emerging) relative pose estimation performance, an important sub skill.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01667v1", "categories": ["cs.CV", "cs.RO"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01667v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "图像目标导航中真正重要的是什么？", "tldr": "本文探讨图像目标导航能否通过端到端强化学习有效解决，并发现模拟器设置会影响结果但能力可迁移，且导航表现与相对姿态估计能力相关。", "motivation": "本文旨在研究图像目标导航任务是否能通过对完整智能体进行端到端强化学习训练来高效解决，以验证近期工作的说法，并探究其对具身AI及从导航奖励中训练相对姿态估计的潜在影响。", "method": "通过一项大型研究，调查了不同的架构选择（如后期融合、通道堆叠、空间到深度投影和交叉注意力）对通过导航训练产生的相对姿态估计器的影响。", "result": "1. 最近方法的成功在一定程度上受模拟器设置影响，导致模拟中的捷径。2. 这些能力可以在一定程度上转移到更现实的环境中。3. 发现导航性能与探测到的（新兴的）相对姿态估计性能之间存在相关性。", "conclusion": "图像目标导航可以通过端到端强化学习实现，但模拟器设置会引入捷径，不过习得的能力具有一定的泛化性，且相对姿态估计是该任务的关键子技能。", "translation": "图像目标导航需要两种不同的技能：首先是核心导航技能，包括自由空间和障碍物的检测，以及基于内部表示的决策；其次是通过比较视觉观察与目标图像来计算方向信息。当前最先进的方法要么依赖于专门的图像匹配，要么依赖于计算机视觉模块在相对姿态估计上的预训练。在本文中，我们研究了这项任务是否可以通过对完整智能体进行端到端强化学习训练来高效解决，正如最近的工作所声称的那样。一个积极的答案将对具身AI产生超越性的影响，并允许仅从导航奖励中训练相对姿态估计。在一项大型研究中，我们调查了架构选择（如后期融合、通道堆叠、空间到深度投影和交叉注意力）的效果，以及它们在导航训练中相对姿态估计器出现的作用。我们表明，最近方法的成功在一定程度上受到模拟器设置的影响，导致模拟中的捷径。然而，我们也表明这些能力可以在一定程度上转移到更现实的环境中。我们还发现了导航性能与探测到的（新兴的）相对姿态估计性能（一个重要的子技能）之间存在相关性的证据。", "summary": "本文研究了图像目标导航任务是否能通过端到端强化学习有效解决。研究通过一项大型实验，探讨了不同神经网络架构对从导航训练中涌现的相对姿态估计器的影响。结果表明，现有方法的成功受模拟器设置影响，但所学能力可迁移至真实环境，且导航表现与新兴的相对姿态估计能力相关。", "keywords": "图像目标导航, 强化学习, 端到端训练, 相对姿态估计, 具身AI", "comments": "这项研究通过深入分析架构选择和模拟器设置对端到端强化学习在图像目标导航中表现的影响，揭示了该领域中可能存在的“捷径”问题，并强调了相对姿态估计作为关键子技能的重要性。其创新在于挑战了现有端到端方法的普适性，并提出了能力迁移的可能性。对具身AI领域具有重要指导意义。"}}
{"id": "2507.01494", "title": "Crop Pest Classification Using Deep Learning Techniques: A Review", "authors": ["Muhammad Hassam Ejaz", "Muhammad Bilal", "Usman Habib"], "summary": "Insect pests continue to bring a serious threat to crop yields around the\nworld, and traditional methods for monitoring them are often slow, manual, and\ndifficult to scale. In recent years, deep learning has emerged as a powerful\nsolution, with techniques like convolutional neural networks (CNNs), vision\ntransformers (ViTs), and hybrid models gaining popularity for automating pest\ndetection. This review looks at 37 carefully selected studies published between\n2018 and 2025, all focused on AI-based pest classification. The selected\nresearch is organized by crop type, pest species, model architecture, dataset\nusage, and key technical challenges. The early studies relied heavily on CNNs\nbut latest work is shifting toward hybrid and transformer-based models that\ndeliver higher accuracy and better contextual understanding. Still, challenges\nlike imbalanced datasets, difficulty in detecting small pests, limited\ngeneralizability, and deployment on edge devices remain significant hurdles.\nOverall, this review offers a structured overview of the field, highlights\nuseful datasets, and outlines the key challenges and future directions for\nAI-based pest monitoring systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01494v1", "categories": ["cs.CV", "cs.AI"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01494v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "作物害虫深度学习分类技术综述", "tldr": "这篇综述审视了2018-2025年间关于使用深度学习技术进行作物害虫分类的37项研究，讨论了模型演变、数据集使用、关键挑战和未来方向。", "motivation": "传统害虫监测方法效率低下且难以扩展，而害虫对作物产量构成严重威胁，因此需要自动化、高效的害虫检测解决方案。", "method": "本文是一篇综述，分析了2018年至2025年间发表的37项关于基于AI的害虫分类研究。研究按作物类型、害虫种类、模型架构、数据集使用和关键技术挑战进行组织和回顾。", "result": "早期研究主要依赖卷积神经网络（CNNs），而最新研究正转向混合模型和基于Transformer的模型，以实现更高的准确性和更好的上下文理解。然而，仍存在数据集不平衡、小型害虫检测困难、泛化能力有限以及在边缘设备上部署等挑战。", "conclusion": "深度学习在作物害虫分类方面显示出巨大潜力，但仍需解决数据、模型泛化和边缘部署等关键技术挑战，以实现更鲁棒和实用的AI害虫监测系统。", "translation": "昆虫害虫继续对世界各地的作物产量构成严重威胁，而传统的监测方法往往缓慢、人工且难以扩展。近年来，深度学习已成为一种强大的解决方案，卷积神经网络（CNNs）、视觉Transformer（ViTs）和混合模型等技术在自动化害虫检测方面越来越受欢迎。这篇综述审视了2018年至2025年间发表的37项精心挑选的研究，所有这些研究都专注于基于AI的害虫分类。所选研究按作物类型、害虫种类、模型架构、数据集使用和关键技术挑战进行组织。早期研究严重依赖CNNs，但最新工作正转向混合和基于Transformer的模型，这些模型提供更高的准确性和更好的上下文理解。尽管如此，数据集不平衡、小型害虫检测困难、泛化能力有限以及在边缘设备上部署等挑战仍然是重要的障碍。总的来说，这篇综述提供了该领域的结构化概述，强调了有用的数据集，并概述了基于AI的害虫监测系统的关键挑战和未来方向。", "summary": "本文综述了2018年至2025年间37项关于利用深度学习技术进行作物害虫分类的研究，旨在解决传统监测方法的局限性。综述分析了卷积神经网络、视觉Transformer和混合模型等主流架构的应用，并指出研究趋势正从单一CNNs转向更先进的混合及Transformer模型。文章还识别出不平衡数据集、小型害虫检测、泛化能力和边缘设备部署等当前面临的主要挑战，并为未来的研究方向提供了指导。", "keywords": "作物害虫分类, 深度学习, 卷积神经网络, 视觉Transformer, 综述", "comments": "这篇综述的重要性在于它系统地梳理了深度学习在作物害虫分类领域的最新进展和挑战，为研究人员提供了宝贵的参考。它不仅指出了技术演进（从CNN到混合/Transformer模型），还明确了实际部署中的障碍，如数据不平衡和边缘设备适配，这对于推动该领域的实际应用至关重要。"}}
{"id": "2507.01132", "title": "Spectral Manifold Harmonization for Graph Imbalanced Regression", "authors": ["Brenda Nogueira", "Gabe Gomes", "Meng Jiang", "Nitesh V. Chawla", "Nuno Moniz"], "summary": "Graph-structured data is ubiquitous in scientific domains, where models often\nface imbalanced learning settings. In imbalanced regression, domain preferences\nfocus on specific target value ranges representing the most scientifically\nvaluable cases; we observe a significant lack of research. In this paper, we\npresent Spectral Manifold Harmonization (SMH), a novel approach for addressing\nthis imbalanced regression challenge on graph-structured data by generating\nsynthetic graph samples that preserve topological properties while focusing on\noften underrepresented target distribution regions. Conventional methods fail\nin this context because they either ignore graph topology in case generation or\ndo not target specific domain ranges, resulting in models biased toward average\ntarget values. Experimental results demonstrate the potential of SMH on\nchemistry and drug discovery benchmark datasets, showing consistent\nimprovements in predictive performance for target domain ranges.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01132v1", "categories": ["cs.LG", "q-bio.MN"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01132v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "图不平衡回归的谱流形协调", "tldr": "本文提出了谱流形协调（SMH）方法，通过生成合成图样本来解决图结构数据上的不平衡回归问题，特别关注科学上有价值但代表性不足的目标值范围。", "motivation": "图结构数据在科学领域普遍存在，但模型常面临不平衡学习设置。在不平衡回归中，领域偏好关注特定目标值范围，这些范围代表了最有科学价值的案例；我们观察到这方面研究的显著缺乏。传统方法在此背景下失败，因为它们要么在样本生成时忽略图拓扑，要么不针对特定领域范围，导致模型偏向平均目标值。", "method": "本文提出了谱流形协调（Spectral Manifold Harmonization, SMH），这是一种新颖的方法，通过生成合成图样本来解决图结构数据上的不平衡回归挑战，这些样本既保留了拓扑属性，又侧重于通常代表性不足的目标分布区域。", "result": "实验结果表明SMH在化学和药物发现基准数据集上的潜力，显示出目标领域范围预测性能的持续改进。", "conclusion": "SMH能够有效解决图结构数据上的不平衡回归问题，尤其在科学价值高但数据稀疏的特定目标值范围上表现出更好的预测性能。", "translation": "图结构数据在科学领域无处不在，模型经常面临不平衡学习设置。在不平衡回归中，领域偏好集中在代表最具科学价值案例的特定目标值范围；我们观察到这方面研究的显著缺乏。在本文中，我们提出了谱流形协调（SMH），这是一种新颖的方法，通过生成合成图样本来解决图结构数据上的不平衡回归挑战，这些样本既保留了拓扑属性，又侧重于通常代表性不足的目标分布区域。传统方法在此背景下失败，因为它们要么在样本生成时忽略图拓扑，要么不针对特定领域范围，导致模型偏向平均目标值。实验结果表明SMH在化学和药物发现基准数据集上的潜力，显示出目标领域范围预测性能的持续改进。", "summary": "本研究针对图结构数据中的不平衡回归问题，提出了一种名为谱流形协调（SMH）的新方法。SMH通过生成保留拓扑属性的合成图样本，并侧重于数据稀疏但科学价值高的目标值区域，以克服现有方法在忽略图拓扑或未能针对特定领域范围的局限性。实验证明，SMH在化学和药物发现数据集上显著提高了特定目标值范围的预测性能。", "keywords": "图不平衡回归, 谱流形协调, 合成样本, 图结构数据, 药物发现", "comments": "该论文创新性地将谱流形思想应用于图不平衡回归问题，通过生成合成样本来解决数据稀疏区域的预测挑战。其重要性在于关注科学领域中高价值但数据不平衡的特定目标范围，弥补了现有研究的不足。方法上考虑到图的拓扑结构，避免了传统过采样方法可能引入的偏差。"}}
{"id": "2507.01872", "title": "DIY-MKG: An LLM-Based Polyglot Language Learning System", "authors": ["Kenan Tang", "Yanhong Li", "Yao Qin"], "summary": "Existing language learning tools, even those powered by Large Language Models\n(LLMs), often lack support for polyglot learners to build linguistic\nconnections across vocabularies in multiple languages, provide limited\ncustomization for individual learning paces or needs, and suffer from\ndetrimental cognitive offloading. To address these limitations, we design\nDo-It-Yourself Multilingual Knowledge Graph (DIY-MKG), an open-source system\nthat supports polyglot language learning. DIY-MKG allows the user to build\npersonalized vocabulary knowledge graphs, which are constructed by selective\nexpansion with related words suggested by an LLM. The system further enhances\nlearning through rich annotation capabilities and an adaptive review module\nthat leverages LLMs for dynamic, personalized quiz generation. In addition,\nDIY-MKG allows users to flag incorrect quiz questions, simultaneously\nincreasing user engagement and providing a feedback loop for prompt refinement.\nOur evaluation of LLM-based components in DIY-MKG shows that vocabulary\nexpansion is reliable and fair across multiple languages, and that the\ngenerated quizzes are highly accurate, validating the robustness of DIY-MKG.", "comment": "Submitted to EMNLP 2025 System Demonstration", "pdf_url": "http://arxiv.org/pdf/2507.01872v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01872v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "DIY-MKG：一个基于LLM的多语种语言学习系统", "tldr": "DIY-MKG是一个基于LLM的开源多语种语言学习系统，通过个性化词汇知识图谱和自适应测验生成，解决了现有工具的局限性。", "motivation": "现有语言学习工具，即使是基于大型语言模型（LLM）的，也缺乏对多语种学习者构建跨语言词汇联系的支持，个性化定制能力有限，并且存在有害的认知卸载问题。", "method": "本研究设计并实现了DIY-MKG，一个开源的多语种语言学习系统。该系统允许用户构建个性化的词汇知识图谱，通过LLM建议的相关词进行选择性扩展。它通过丰富的注释功能和利用LLM进行动态、个性化测验生成的自适应复习模块来增强学习。此外，DIY-MKG允许用户标记错误的测验问题，从而提高用户参与度并为提示优化提供反馈循环。", "result": "对DIY-MKG中基于LLM的组件进行评估表明，词汇扩展在多种语言中是可靠和公平的，并且生成的测验具有高准确性。", "conclusion": "DIY-MKG作为一个基于LLM的多语种语言学习系统，通过其个性化词汇知识图谱、自适应测验生成和用户反馈机制，有效解决了现有语言学习工具的局限性，并被证明是健壮的。", "translation": "现有语言学习工具，即使是那些由大型语言模型（LLM）驱动的，也常常缺乏对多语种学习者在多种语言词汇之间建立语言联系的支持，对个人学习进度或需求提供的定制化有限，并且存在有害的认知卸载问题。为了解决这些局限性，我们设计了DIY-MKG（Do-It-Yourself Multilingual Knowledge Graph），一个支持多语种语言学习的开源系统。DIY-MKG允许用户构建个性化的词汇知识图谱，这些图谱通过LLM建议的相关词进行选择性扩展而构建。该系统通过丰富的注释功能和利用LLM进行动态、个性化测验生成的自适应复习模块进一步增强学习。此外，DIY-MKG允许用户标记错误的测验问题，同时提高用户参与度并为提示优化提供反馈循环。我们对DIY-MKG中基于LLM的组件的评估表明，词汇扩展在多种语言中是可靠和公平的，并且生成的测验具有高准确性，验证了DIY-MKG的健壮性。", "summary": "本文介绍了DIY-MKG，一个基于LLM的开源多语种语言学习系统，旨在解决现有工具在多语种连接、个性化和认知卸载方面的不足。DIY-MKG允许用户构建和扩展个性化词汇知识图谱，并通过LLM驱动的自适应测验生成和丰富的注释功能来增强学习。系统还包括用户反馈机制。评估结果验证了其词汇扩展的可靠性和测验生成的高准确性，证明了DIY-MKG的健壮性。", "keywords": "语言学习, 多语种, 大型语言模型, 知识图谱, 个性化学习", "comments": "DIY-MKG的创新之处在于其将LLM应用于个性化多语种知识图谱的构建和自适应测验生成，有效解决了传统语言学习工具的痛点。其开源性质和用户反馈循环设计也增加了系统的灵活性和持续改进潜力。该系统对于多语种学习者具有重要意义。"}}
{"id": "2507.01823", "title": "TD-MPC-Opt: Distilling Model-Based Multi-Task Reinforcement Learning Agents", "authors": ["Dmytro Kuzmenko", "Nadiya Shvai"], "summary": "We present a novel approach to knowledge transfer in model-based\nreinforcement learning, addressing the critical challenge of deploying large\nworld models in resource-constrained environments. Our method efficiently\ndistills a high-capacity multi-task agent (317M parameters) into a compact\nmodel (1M parameters) on the MT30 benchmark, significantly improving\nperformance across diverse tasks. Our distilled model achieves a\nstate-of-the-art normalized score of 28.45, surpassing the original 1M\nparameter model score of 18.93. This improvement demonstrates the ability of\nour distillation technique to capture and consolidate complex multi-task\nknowledge. We further optimize the distilled model through FP16 post-training\nquantization, reducing its size by $\\sim$50\\%. Our approach addresses practical\ndeployment limitations and offers insights into knowledge representation in\nlarge world models, paving the way for more efficient and accessible multi-task\nreinforcement learning systems in robotics and other resource-constrained\napplications. Code available at https://github.com/dmytro-kuzmenko/td-mpc-opt.", "comment": "Preprint of a manuscript submitted for peer review", "pdf_url": "http://arxiv.org/pdf/2507.01823v1", "categories": ["cs.LG", "cs.RO"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01823v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "TD-MPC-Opt: 蒸馏基于模型的S多任务强化学习智能体", "tldr": "TD-MPC-Opt提出了一种新的知识蒸馏方法，将大型多任务强化学习模型压缩至更小的尺寸，同时显著提升了在资源受限环境下的性能。", "motivation": "为了解决在资源受限环境中部署大型世界模型所面临的挑战，本研究旨在通过知识蒸馏，使高容量多任务强化学习智能体能够高效地部署。", "method": "本研究提出了一种将高容量多任务智能体（3.17亿参数）蒸馏到紧凑模型（100万参数）的方法，并在MT30基准测试上进行了评估。此外，通过FP16后训练量化进一步优化了蒸馏模型，将其尺寸减小了约50%。", "result": "蒸馏模型在MT30基准测试中达到了28.45的最新标准化分数，超过了原始100万参数模型18.93的分数。通过FP16后训练量化，模型尺寸减小了约50%。", "conclusion": "本方法解决了实际部署的限制，并为大型世界模型中的知识表示提供了见解，为机器人和其他资源受限应用中更高效、更易访问的多任务强化学习系统铺平了道路。", "translation": "我们提出了一种模型基强化学习中知识转移的新方法，解决了在资源受限环境中部署大型世界模型的关键挑战。我们的方法有效地将一个高容量多任务智能体（3.17亿参数）蒸馏到一个紧凑模型（100万参数）中，并在MT30基准测试上显著提高了跨不同任务的性能。我们蒸馏后的模型达到了28.45的最新标准化分数，超过了原始100万参数模型18.93的分数。这一改进表明我们的蒸馏技术能够捕获和巩固复杂的多任务知识。我们通过FP16后训练量化进一步优化了蒸馏模型，将其尺寸减小了约50%。我们的方法解决了实际部署的限制，并为大型世界模型中的知识表示提供了见解，为机器人和其他资源受限应用中更高效、更易访问的多任务强化学习系统铺平了道路。代码可在https://github.com/dmytro-kuzmenko/td-mpc-opt获取。", "summary": "该论文介绍了一种名为TD-MPC-Opt的新型知识蒸馏方法，旨在将大型模型基多任务强化学习智能体（3.17亿参数）压缩至更小的尺寸（100万参数），以适应资源受限的部署环境。该方法在MT30基准测试上显著提升了性能，蒸馏模型取得了28.45的SOTA分数，并进一步通过FP16量化将模型尺寸减半。这为高效的多任务强化学习系统在实际应用中的部署提供了解决方案。", "keywords": "知识蒸馏, 模型基强化学习, 多任务学习, 模型压缩, 资源受限环境", "comments": "该论文的创新点在于提出了针对模型基强化学习的知识蒸馏方法，有效解决了大型世界模型在资源受限环境下部署的难题。通过将高容量模型压缩至极小的尺寸，并同时提升性能，这对于机器人和边缘计算等实际应用具有重要意义。FP16量化进一步优化了模型效率，展示了在保持性能的同时实现极致压缩的潜力。"}}
{"id": "2507.01496", "title": "ReFlex: Text-Guided Editing of Real Images in Rectified Flow via Mid-Step Feature Extraction and Attention Adaptation", "authors": ["Jimyeong Kim", "Jungwon Park", "Yeji Song", "Nojun Kwak", "Wonjong Rhee"], "summary": "Rectified Flow text-to-image models surpass diffusion models in image quality\nand text alignment, but adapting ReFlow for real-image editing remains\nchallenging. We propose a new real-image editing method for ReFlow by analyzing\nthe intermediate representations of multimodal transformer blocks and\nidentifying three key features. To extract these features from real images with\nsufficient structural preservation, we leverage mid-step latent, which is\ninverted only up to the mid-step. We then adapt attention during injection to\nimprove editability and enhance alignment to the target text. Our method is\ntraining-free, requires no user-provided mask, and can be applied even without\na source prompt. Extensive experiments on two benchmarks with nine baselines\ndemonstrate its superior performance over prior methods, further validated by\nhuman evaluations confirming a strong user preference for our approach.", "comment": "Published at ICCV 2025. Project page:\n  https://wlaud1001.github.io/ReFlex/", "pdf_url": "http://arxiv.org/pdf/2507.01496v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01496v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "ReFlex：通过中间步骤特征提取和注意力自适应在校正流中进行真实图像的文本引导编辑", "tldr": "ReFlex提出了一种新的无训练、无需掩码的校正流真实图像编辑方法，通过中间步骤特征提取和注意力自适应，实现了卓越的编辑性能。", "motivation": "校正流（Rectified Flow）文本到图像模型在图像质量和文本对齐方面优于扩散模型，但将校正流模型应用于真实图像编辑仍然具有挑战性。", "method": "我们通过分析多模态transformer块的中间表示并识别出三个关键特征，提出了一种新的校正流真实图像编辑方法。为了从真实图像中提取这些特征并充分保留结构，我们利用了仅反演到中间步骤的中间步骤潜在表示。然后，我们在注入过程中调整注意力以提高可编辑性并增强与目标文本的对齐。我们的方法是免训练的，不需要用户提供的掩码，甚至可以在没有源提示的情况下应用。", "result": "在两个基准测试中，与九种基线方法进行广泛实验，证明了我们方法优于现有方法的卓越性能。人类评估进一步证实了用户对我们方法的强烈偏好。", "conclusion": "ReFlex通过中间步骤特征提取和注意力自适应，有效地解决了校正流模型在真实图像编辑中的挑战，并取得了优异的性能和用户偏好。", "translation": "校正流文本到图像模型在图像质量和文本对齐方面超越了扩散模型，但将校正流模型应用于真实图像编辑仍然具有挑战性。我们通过分析多模态transformer块的中间表示并识别出三个关键特征，提出了一种新的校正流真实图像编辑方法。为了从真实图像中提取这些特征并充分保留结构，我们利用了仅反演到中间步骤的中间步骤潜在表示。然后，我们在注入过程中调整注意力以提高可编辑性并增强与目标文本的对齐。我们的方法是免训练的，不需要用户提供的掩码，甚至可以在没有源提示的情况下应用。在两个基准测试中，与九种基线方法进行广泛实验，证明了我们方法优于现有方法的卓越性能，人类评估进一步证实了用户对我们方法的强烈偏好。", "summary": "本研究提出了ReFlex，一种针对校正流模型的真实图像文本引导编辑方法。该方法通过分析多模态transformer块的中间表示，提取关键特征，并利用中间步骤潜在表示来保留图像结构。ReFlex通过调整注入过程中的注意力来提高可编辑性和文本对齐。该方法是无训练、无需用户提供掩码的，并且可以在没有源提示的情况下使用。实验证明，ReFlex在图像编辑方面优于现有方法，并获得了用户的高度评价。", "keywords": "校正流, 图像编辑, 文本引导, 特征提取, 注意力自适应", "comments": "ReFlex的创新之处在于它将校正流模型应用于真实图像编辑，通过中间步骤特征提取和注意力自适应，克服了现有方法的挑战。其免训练、无需掩码的特性大大简化了使用流程，提升了用户体验。在图像编辑领域，这是一个重要的进展，有望推动更自然、更灵活的图像编辑应用。"}}
{"id": "2507.01887", "title": "MiCoTA: Bridging the Learnability Gap with Intermediate CoT and Teacher Assistants", "authors": ["Dongyi Ding", "Tiannan Wang", "Chenghao Zhu", "Meiling Tao", "Yuchen Eleanor Jiang", "Wangchunshu Zhou"], "summary": "Large language models (LLMs) excel at reasoning tasks requiring long thought\nsequences for planning, reflection, and refinement. However, their substantial\nmodel size and high computational demands are impractical for widespread\ndeployment. Yet, small language models (SLMs) often struggle to learn long-form\nCoT reasoning due to their limited capacity, a phenomenon we refer to as the\n\"SLMs Learnability Gap\". To address this, we introduce\n\\textbf{Mi}d-\\textbf{Co}T \\textbf{T}eacher \\textbf{A}ssistant Distillation\n(MiCoTAl), a framework for improving long CoT distillation for SLMs. MiCoTA\nemploys intermediate-sized models as teacher assistants and utilizes\nintermediate-length CoT sequences to bridge both the capacity and reasoning\nlength gaps. Our experiments on downstream tasks demonstrate that although SLMs\ndistilled from large teachers can perform poorly, by applying MiCoTA, they\nachieve significant improvements in reasoning performance. Specifically,\nQwen2.5-7B-Instruct and Qwen2.5-3B-Instruct achieve an improvement of 3.47 and\n3.93 respectively on average score on AIME2024, AMC, Olympiad, MATH-500 and\nGSM8K benchmarks. To better understand the mechanism behind MiCoTA, we perform\na quantitative experiment demonstrating that our method produces data more\nclosely aligned with base SLM distributions. Our insights pave the way for\nfuture research into long-CoT data distillation for SLMs.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.01887v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01887v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "MiCoTA：通过中间CoT和教师助手弥合可学习性差距", "tldr": "MiCoTA框架利用中间模型作为教师助手和中间长度的CoT序列，显著提高了小型语言模型在长CoT推理任务上的表现，解决了小型模型的可学习性差距。", "motivation": "大型语言模型（LLMs）在需要长思考序列的推理任务上表现出色，但其巨大的模型尺寸和高计算需求使其难以广泛部署。小型语言模型（SLMs）由于容量有限，难以学习长形式的CoT推理，即“SLMs可学习性差距”。", "method": "引入了MiCoTAl（Mid-CoT Teacher Assistant Distillation）框架，旨在改进SLMs的长CoT蒸馏。MiCoTA利用中间大小的模型作为教师助手，并使用中间长度的CoT序列来弥合容量和推理长度的差距。", "result": "尽管从大型教师模型蒸馏的SLMs可能表现不佳，但通过应用MiCoTA，它们在推理性能上取得了显著改进。具体来说，Qwen2.5-7B-Instruct和Qwen2.5-3B-Instruct在AIME2024、AMC、Olympiad、MATH-500和GSM8K基准测试上的平均得分分别提高了3.47和3.93。定量实验表明，该方法生成的数据与基础SLM分布更接近。", "conclusion": "MiCoTA框架成功弥合了小型语言模型在长CoT推理方面的可学习性差距，通过引入中间模型和中间长度CoT序列进行蒸馏，显著提升了SLMs的推理能力，并为未来SLMs长CoT数据蒸馏研究提供了方向。", "translation": "大型语言模型（LLMs）擅长需要长时间思考序列进行规划、反思和改进的推理任务。然而，其巨大的模型尺寸和高计算需求使其难以广泛部署。然而，小型语言模型（SLMs）由于容量有限，常常难以学习长形式的CoT推理，这种现象我们称之为“SLMs可学习性差距”。为了解决这个问题，我们引入了MiCoTAl（Mid-CoT Teacher Assistant Distillation），一个用于改进SLMs长CoT蒸馏的框架。MiCoTA采用中间大小的模型作为教师助手，并利用中间长度的CoT序列来弥合容量和推理长度的差距。我们在下游任务上的实验表明，尽管从大型教师模型蒸馏的SLMs可能表现不佳，但通过应用MiCoTA，它们在推理性能上取得了显著改进。具体来说，Qwen2.5-7B-Instruct和Qwen2.5-3B-Instruct在AIME2024、AMC、Olympiad、MATH-500和GSM8K基准测试上的平均得分分别提高了3.47和3.93。为了更好地理解MiCoTA背后的机制，我们进行了一项定量实验，表明我们的方法生成的数据与基础SLM分布更接近。我们的见解为未来SLMs长CoT数据蒸馏研究铺平了道路。", "summary": "本文提出了MiCoTA框架，旨在解决小型语言模型（SLMs）在学习长形式思维链（CoT）推理时遇到的“可学习性差距”。MiCoTA通过引入中间大小的模型作为教师助手，并利用中间长度的CoT序列进行蒸馏，有效弥补了SLMs的容量和推理长度不足。实验结果表明，该方法显著提升了SLMs在多项基准测试上的推理性能，并生成了与SLM分布更匹配的数据，为SLMs的长CoT数据蒸馏提供了新思路。", "keywords": "小型语言模型, 思维链蒸馏, 教师助手, 可学习性差距, 中间模型", "comments": "MiCoTA的创新之处在于引入了“中间CoT和教师助手”的概念，巧妙地解决了大型模型蒸馏到小型模型时存在的“可学习性差距”。它通过分阶段的蒸馏策略，即利用中间模型作为桥梁，使得小型模型能够更好地吸收长CoT推理能力。这种方法对于推动小型化、高效能的语言模型在复杂推理任务上的应用具有重要意义，尤其是在资源受限的环境下。"}}
{"id": "2507.01502", "title": "Integrating Traditional and Deep Learning Methods to Detect Tree Crowns in Satellite Images", "authors": ["Ozan Durgut", "Beril Kallfelz-Sirmacek", "Cem Unsalan"], "summary": "Global warming, loss of biodiversity, and air pollution are among the most\nsignificant problems facing Earth. One of the primary challenges in addressing\nthese issues is the lack of monitoring forests to protect them. To tackle this\nproblem, it is important to leverage remote sensing and computer vision methods\nto automate monitoring applications. Hence, automatic tree crown detection\nalgorithms emerged based on traditional and deep learning methods. In this\nstudy, we first introduce two different tree crown detection methods based on\nthese approaches. Then, we form a novel rule-based approach that integrates\nthese two methods to enhance robustness and accuracy of tree crown detection\nresults. While traditional methods are employed for feature extraction and\nsegmentation of forested areas, deep learning methods are used to detect tree\ncrowns in our method. With the proposed rule-based approach, we post-process\nthese results, aiming to increase the number of detected tree crowns through\nneighboring trees and localized operations. We compare the obtained results\nwith the proposed method in terms of the number of detected tree crowns and\nreport the advantages, disadvantages, and areas for improvement of the obtained\noutcomes.", "comment": "11 pages, 4 figures, journal manuscript", "pdf_url": "http://arxiv.org/pdf/2507.01502v1", "categories": ["cs.CV", "cs.AI"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01502v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "整合传统与深度学习方法以检测卫星图像中的树冠", "tldr": "本研究整合了传统与深度学习方法，提出了一种新颖的基于规则的方法来增强卫星图像中树冠检测的鲁棒性和准确性，并通过后处理增加检测到的树冠数量。", "motivation": "全球变暖、生物多样性丧失和空气污染是地球面临的重大问题。解决这些挑战的一个主要障碍是缺乏对森林的有效监测和保护。因此，需要利用遥感和计算机视觉方法实现自动化监测应用，并开发自动树冠检测算法。", "method": "本研究首先介绍了两种不同的树冠检测方法：一种基于传统方法，另一种基于深度学习方法。然后，提出了一种新颖的基于规则的方法，将这两种方法进行整合，以提高树冠检测结果的鲁棒性和准确性。具体而言，传统方法用于森林区域的特征提取和分割，而深度学习方法用于检测树冠。最后，通过所提出的基于规则的方法对结果进行后处理，旨在通过邻近树木和局部操作来增加检测到的树冠数量。", "result": "该研究将所提出方法的结果与现有方法进行了比较，主要关注检测到的树冠数量，并报告了所得结果的优点、缺点和改进领域。", "conclusion": "本研究提出了一种整合传统和深度学习方法的树冠检测框架，通过新颖的基于规则的后处理方法提高了检测的鲁棒性和准确性，并指出了未来改进的方向。", "translation": "全球变暖、生物多样性丧失和空气污染是地球面临的最重要问题。解决这些问题的主要挑战之一是缺乏对森林的监测以保护它们。为了解决这个问题，利用遥感和计算机视觉方法实现自动化监测应用非常重要。因此，基于传统方法和深度学习方法的自动树冠检测算法应运而生。在本研究中，我们首先介绍了两种基于这些方法的不同树冠检测方法。然后，我们形成了一种新颖的基于规则的方法，将这两种方法整合起来，以提高树冠检测结果的鲁棒性和准确性。在我们的方法中，传统方法用于森林区域的特征提取和分割，而深度学习方法用于检测树冠。通过所提出的基于规则的方法，我们对这些结果进行后处理，旨在通过邻近树木和局部操作来增加检测到的树冠数量。我们根据检测到的树冠数量将所得结果与所提出的方法进行比较，并报告了所得结果的优点、缺点和改进领域。", "summary": "本研究旨在解决森林监测不足的问题，提出了一种结合传统和深度学习方法的树冠自动检测新框架。该方法首先利用传统方法进行特征提取和分割，再通过深度学习方法检测树冠，并创新性地引入基于规则的后处理，以整合两种方法的优势，提高检测的鲁棒性和准确性，并通过局部操作增加树冠检测数量。研究对结果进行了评估，并指出了其优缺点。", "keywords": "树冠检测, 深度学习, 传统方法, 卫星图像, 遥感", "comments": "该论文的创新点在于提出了一种混合方法，将传统图像处理技术（用于特征提取和分割）与深度学习模型（用于树冠检测）相结合。更重要的是，它引入了一种新颖的、基于规则的后处理策略，旨在通过局部上下文信息进一步优化和增加检测到的树冠数量，从而提高了检测的鲁棒性和准确性。这种整合方法为克服单一方法的局限性提供了一条有前景的途径。"}}
{"id": "2507.01178", "title": "Diffusion Explorer: Interactive Exploration of Diffusion Models", "authors": ["Alec Helbling", "Duen Horng Chau"], "summary": "Diffusion models have been central to the development of recent image, video,\nand even text generation systems. They posses striking geometric properties\nthat can be faithfully portrayed in low-dimensional settings. However, existing\nresources for explaining diffusion either require an advanced theoretical\nfoundation or focus on their neural network architectures rather than their\nrich geometric properties. We introduce Diffusion Explorer, an interactive tool\nto explain the geometric properties of diffusion models. Users can train 2D\ndiffusion models in the browser and observe the temporal dynamics of their\nsampling process. Diffusion Explorer leverages interactive animation, which has\nbeen shown to be a powerful tool for making engaging visualizations of dynamic\nsystems, making it well suited to explaining diffusion models which represent\nstochastic processes that evolve over time. Diffusion Explorer is open source\nand a live demo is available at alechelbling.com/Diffusion-Explorer.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01178v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01178v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "扩散探索器：扩散模型的交互式探索", "tldr": "Diffusion Explorer是一个交互式工具，用于通过在浏览器中训练2D模型并可视化采样动态来探索扩散模型的几何特性。", "motivation": "现有的扩散模型解释资源要么需要高级理论基础，要么侧重于其神经网络架构，而忽略了其丰富的几何特性。", "method": "本文介绍了Diffusion Explorer，一个开源的交互式工具。它允许用户在浏览器中训练2D扩散模型，并通过交互式动画观察其采样过程的时间动态。", "result": "Diffusion Explorer能够有效地解释扩散模型的几何特性，特别是作为随时间演变的随机过程的动态。该工具的实时演示已可用。", "conclusion": "Diffusion Explorer通过交互式可视化，有效地弥补了现有解释资源在使扩散模型的复杂几何特性更易于理解方面的不足。", "translation": "扩散模型在最近的图像、视频乃至文本生成系统的发展中处于核心地位。它们拥有显著的几何特性，可以在低维环境中忠实地描绘出来。然而，现有的扩散模型解释资源要么需要高级理论基础，要么侧重于其神经网络架构，而不是其丰富的几何特性。我们引入了Diffusion Explorer，一个用于解释扩散模型几何特性的交互式工具。用户可以在浏览器中训练2D扩散模型，并观察其采样过程的时间动态。Diffusion Explorer利用了交互式动画，这种动画已被证明是制作动态系统引人入胜的可视化的强大工具，使其非常适合解释代表随时间演变的随机过程的扩散模型。Diffusion Explorer是开源的，并且可以在alechelbling.com/Diffusion-Explorer找到实时演示。", "summary": "Diffusion Explorer是一个交互式、开源的网页工具，旨在解释扩散模型的几何特性和时间动态。它允许用户在浏览器中训练2D扩散模型并可视化其采样过程，从而弥补了当前解释资源中经常忽视这些丰富的几何方面或需要高级理论知识的空白。", "keywords": "扩散模型, 交互式工具, 几何特性, 可视化, 生成式AI", "comments": "这篇论文解决了理解复杂AI模型的一个重要挑战：使其底层机制能够被直观理解。通过专注于几何特性和时间动态的交互式可视化，Diffusion Explorer提供了一种新颖且易于理解的方法。其开源性质和浏览器内功能降低了学习扩散模型的门槛。这项创新可以显著帮助高级生成式AI的教育和更广泛的理解。"}}
{"id": "2507.01900", "title": "High-Layer Attention Pruning with Rescaling", "authors": ["Songtao Liu", "Peng Liu"], "summary": "Pruning is a highly effective approach for compressing large language models\n(LLMs), significantly reducing inference latency. However, conventional\ntraining-free structured pruning methods often employ a heuristic metric that\nindiscriminately removes some attention heads across all pruning layers,\nwithout considering their positions within the network architecture. In this\nwork, we propose a novel pruning algorithm that strategically prunes attention\nheads in the model's higher layers. Since the removal of attention heads can\nalter the magnitude of token representations, we introduce an adaptive\nrescaling parameter that calibrates the representation scale post-pruning to\ncounteract this effect. We conduct comprehensive experiments on a wide range of\nLLMs, including LLaMA3.1-8B, Mistral-7B-v0.3, Qwen2-7B, and Gemma2-9B. Our\nevaluation includes both generation and discriminative tasks across 27\ndatasets. The results consistently demonstrate that our method outperforms\nexisting structured pruning methods. This improvement is particularly notable\nin generation tasks, where our approach significantly outperforms existing\nbaselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01900v1", "categories": ["cs.CL", "cs.LG"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01900v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "高层注意力剪枝与重缩放", "tldr": "提出一种新的LLM剪枝方法，在高层剪枝注意力头并引入自适应重缩放参数，在多项任务和模型上优于现有方法，尤其在生成任务上表现显著。", "motivation": "传统的无训练结构化剪枝方法在所有剪枝层不加区分地移除注意力头，没有考虑它们在网络架构中的位置，且移除注意力头会改变token表示的幅度。", "method": "提出一种新的剪枝算法，在高层策略性地剪枝注意力头。引入自适应重缩放参数，在剪枝后校准表示尺度，以抵消移除注意力头对token表示幅度的影响。", "result": "在包括LLaMA3.1-8B、Mistral-7B-v0.3、Qwen2-7B和Gemma2-9B在内的多种LLM上进行了生成和判别任务的综合实验，跨越27个数据集。结果一致表明，该方法优于现有结构化剪枝方法，尤其在生成任务中显著优于现有基线。", "conclusion": "通过在高层剪枝注意力头并引入自适应重缩放参数，可以有效提高LLM的剪枝性能，尤其在生成任务中表现出色。", "translation": "剪枝是压缩大型语言模型（LLMs）的一种高效方法，能显著减少推理延迟。然而，传统的无训练结构化剪枝方法通常采用启发式度量，不加区分地在所有剪枝层移除一些注意力头，而没有考虑它们在网络架构中的位置。在这项工作中，我们提出了一种新颖的剪枝算法，策略性地剪枝模型高层中的注意力头。由于移除注意力头会改变token表示的幅度，我们引入了一个自适应重缩放参数，在剪枝后校准表示尺度以抵消这种影响。我们在包括LLaMA3.1-8B、Mistral-7B-v0.3、Qwen2-7B和Gemma2-9B在内的多种LLM上进行了综合实验。我们的评估包括27个数据集上的生成和判别任务。结果一致表明，我们的方法优于现有的结构化剪枝方法。这种改进在生成任务中尤为显著，我们的方法显著优于现有基线。", "summary": "该论文提出一种新的大语言模型剪枝算法，通过在高层策略性地移除注意力头，并引入自适应重缩放参数来校准表示尺度，以解决传统剪枝方法未考虑网络位置和表示幅度变化的问题。实验在多种LLM和27个数据集上进行，结果显示该方法在生成和判别任务上均优于现有方法，尤其在生成任务中表现显著提升。", "keywords": "剪枝, 大语言模型, 注意力剪枝, 重缩放, 模型压缩", "comments": "该论文的创新点在于提出了高层注意力剪枝的策略，并引入了自适应重缩放机制，有效解决了传统剪枝方法中缺乏位置感知和表示尺度变化的问题，对提高LLM剪枝效果，特别是生成能力具有重要意义。"}}
{"id": "2507.01504", "title": "Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence", "authors": ["Robert Aufschläger", "Youssef Shoeb", "Azarm Nowzad", "Michael Heigl", "Fabian Bally", "Martin Schramm"], "summary": "The collection and release of street-level recordings as Open Data play a\nvital role in advancing autonomous driving systems and AI research. However,\nthese datasets pose significant privacy risks, particularly for pedestrians,\ndue to the presence of Personally Identifiable Information (PII) that extends\nbeyond biometric traits such as faces. In this paper, we present cRID, a novel\ncross-modal framework combining Large Vision-Language Models, Graph Attention\nNetworks, and representation learning to detect textual describable clues of\nPII and enhance person re-identification (Re-ID). Our approach focuses on\nidentifying and leveraging interpretable features, enabling the detection of\nsemantically meaningful PII beyond low-level appearance cues. We conduct a\nsystematic evaluation of PII presence in person image datasets. Our experiments\nshow improved performance in practical cross-dataset Re-ID scenarios, notably\nfrom Market-1501 to CUHK03-np (detected), highlighting the framework's\npractical utility. Code is available at https://github.com/RAufschlaeger/cRID.", "comment": "accepted for publication at the 2025 IEEE 28th International\n  Conference on Intelligent Transportation Systems (ITSC 2025), taking place\n  during November 18-21, 2025 in Gold Coast, Australia", "pdf_url": "http://arxiv.org/pdf/2507.01504v1", "categories": ["cs.CV", "cs.AI", "cs.CL"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01504v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "遵循线索：使用跨模态智能进行行人重识别的实验", "tldr": "本文提出了cRID，一个结合大视觉语言模型、图注意力网络和表示学习的跨模态框架，用于检测可文本描述的个人身份信息(PII线索，并增强行人重识别(Re-ID)。实验表明，该框架在跨数据集Re-ID场景中表现出更好的性能，尤其是在从Market-1501到CUHK03-np的迁移中。", "motivation": "街景录像作为开放数据在自动驾驶和AI研究中发挥重要作用，但这些数据集存在严重的隐私风险，特别是对行人而言，因为其中包含超出生物特征（如面部）的个人身份信息（PII）。当前行人重识别方法主要依赖低级外观线索，难以识别语义上有意义的PII。", "method": "本文提出了cRID，一个新颖的跨模态框架，它结合了大型视觉语言模型（LVLMs）、图注意力网络（GANs）和表示学习。该方法侧重于识别和利用可解释的特征，以检测超越低级外观线索的语义上有意义的PII，并增强行人重识别。", "result": "本文对行人图像数据集中PII的存在进行了系统评估。实验结果显示，cRID框架在实际的跨数据集行人重识别场景中表现出改进的性能，特别是在从Market-1501到CUHK03-np（已检测）的数据集迁移中，突出了该框架的实用性。", "conclusion": "cRID框架通过结合多模态智能（LVLMs、GANs、表示学习）和利用可文本描述的PII线索，有效提升了行人重识别的性能，并在处理隐私敏感数据方面展现出实用价值。", "translation": "街景录像作为开放数据收集和发布，在推动自动驾驶系统和人工智能研究方面发挥着至关重要的作用。然而，这些数据集带来了显著的隐私风险，特别是对于行人而言，因为其中包含超出生物特征（如面部）的个人身份信息（PII）。在本文中，我们提出了cRID，一个新颖的跨模态框架，它结合了大型视觉语言模型、图注意力网络和表示学习，以检测可文本描述的PII线索并增强行人重识别（Re-ID）。我们的方法侧重于识别和利用可解释的特征，从而能够检测超越低级外观线索的语义上有意义的PII。我们对行人图像数据集中PII的存在进行了系统评估。我们的实验表明，在实际的跨数据集Re-ID场景中性能有所提高，特别是从Market-1501到CUHK03-np（已检测），突出了该框架的实用性。代码可在https://github.com/RAufschlaeger/cRID获取。", "summary": "本文提出了一种名为cRID的新型跨模态框架，旨在解决街景数据中行人身份信息（PII）的隐私风险，并提升行人重识别（Re-ID）的性能。cRID结合了大型视觉语言模型、图注意力网络和表示学习，能够识别并利用可文本描述的PII线索，超越传统的低级外观特征。实验证明，cRID在跨数据集的Re-ID任务中表现出优越的性能，尤其是在从Market-1501到CUHK03-np的迁移中，验证了其在实际应用中的有效性。", "keywords": "行人重识别, 跨模态智能, 个人身份信息, 视觉语言模型, 图注意力网络", "comments": "该论文的创新点在于提出了一个结合视觉语言模型、图注意力网络和表示学习的跨模态框架cRID，用于利用可文本描述的PII线索来增强行人重识别。这不仅提升了Re-ID的性能，也为处理包含敏感隐私信息的开放数据集提供了新的视角。其重要性在于，在强调数据隐私的背景下，提出了一种更智能、更注重语义理解的行人重识别方法，超越了单纯的生物特征识别，具有很好的实际应用前景。未来可以进一步探索如何更精细地控制PII的泄露风险与Re-ID性能之间的平衡。"}}
{"id": "2507.01903", "title": "AI4Research: A Survey of Artificial Intelligence for Scientific Research", "authors": ["Qiguang Chen", "Mingda Yang", "Libo Qin", "Jinhao Liu", "Zheng Yan", "Jiannan Guan", "Dengyun Peng", "Yiyan Ji", "Hanjing Li", "Mengkang Hu", "Yimeng Zhang", "Yihao Liang", "Yuhang Zhou", "Jiaqi Wang", "Zhi Chen", "Wanxiang Che"], "summary": "Recent advancements in artificial intelligence (AI), particularly in large\nlanguage models (LLMs) such as OpenAI-o1 and DeepSeek-R1, have demonstrated\nremarkable capabilities in complex domains such as logical reasoning and\nexperimental coding. Motivated by these advancements, numerous studies have\nexplored the application of AI in the innovation process, particularly in the\ncontext of scientific research. These AI technologies primarily aim to develop\nsystems that can autonomously conduct research processes across a wide range of\nscientific disciplines. Despite these significant strides, a comprehensive\nsurvey on AI for Research (AI4Research) remains absent, which hampers our\nunderstanding and impedes further development in this field. To address this\ngap, we present a comprehensive survey and offer a unified perspective on\nAI4Research. Specifically, the main contributions of our work are as follows:\n(1) Systematic taxonomy: We first introduce a systematic taxonomy to classify\nfive mainstream tasks in AI4Research. (2) New frontiers: Then, we identify key\nresearch gaps and highlight promising future directions, focusing on the rigor\nand scalability of automated experiments, as well as the societal impact. (3)\nAbundant applications and resources: Finally, we compile a wealth of resources,\nincluding relevant multidisciplinary applications, data corpora, and tools. We\nhope our work will provide the research community with quick access to these\nresources and stimulate innovative breakthroughs in AI4Research.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.01903v1", "categories": ["cs.CL", "cs.AI"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01903v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "AI4Research：人工智能在科学研究中的调查", "tldr": "这篇综述对人工智能在科学研究中的应用进行了全面概述，并提出了一个统一的视角。", "motivation": "尽管人工智能（AI）在科学研究中取得了显著进展，但目前缺乏关于AI4Research的全面综述，这阻碍了对该领域的理解和进一步发展。", "method": "作者通过引入系统分类法、识别关键研究空白和未来方向，以及汇编丰富的多学科应用、数据语料库和工具等资源，对AI4Research进行了全面调查并提供了统一视角。", "result": "本研究的主要贡献包括：1) 引入了AI4Research中五大主流任务的系统分类；2) 识别了关键研究空白并强调了有前景的未来方向，侧重于自动化实验的严谨性和可扩展性以及社会影响；3) 汇编了丰富的多学科应用、数据语料库和工具。", "conclusion": "作者希望这项工作能为研究社区提供快速获取AI4Research相关资源的途径，并刺激该领域的创新突破。", "translation": "近期人工智能（AI）的进步，特别是像OpenAI-o1和DeepSeek-R1这样的大型语言模型（LLMs），在逻辑推理和实验编码等复杂领域展现出卓越的能力。受这些进步的启发，大量研究探索了人工智能在创新过程中的应用，尤其是在科学研究的背景下。这些人工智能技术主要旨在开发能够自主进行广泛科学学科研究过程的系统。尽管取得了这些显著进展，但目前仍缺乏关于科学研究中人工智能（AI4Research）的全面综述，这阻碍了我们对该领域的理解并阻碍了其进一步发展。为了弥补这一空白，我们提出了一项全面的调查，并对AI4Research提供了统一的视角。具体而言，我们工作的主要贡献如下：（1）系统分类：我们首先引入了一个系统分类法，用于对AI4Research中的五大主流任务进行分类。（2）新前沿：然后，我们识别了关键研究空白并强调了有前景的未来方向，重点关注自动化实验的严谨性和可扩展性以及社会影响。（3）丰富的应用和资源：最后，我们汇编了丰富的资源，包括相关的多学科应用、数据语料库和工具。我们希望我们的工作能为研究社区提供快速获取这些资源的途径，并刺激AI4Research领域的创新突破。", "summary": "这篇综述文章旨在弥补AI在科学研究（AI4Research）领域缺乏全面系统性概述的空白。文章首先提出了一个系统分类法，对AI4Research中的五大主流任务进行分类。接着，识别了关键的研究空白并指出了未来发展方向，特别强调了自动化实验的严谨性、可扩展性以及社会影响。最后，文章汇编了丰富的多学科应用、数据语料库和工具等资源，旨在促进研究社区对AI4Research的理解和创新。", "keywords": "人工智能, 科学研究, 综述, 大型语言模型, 自动化实验", "comments": "这篇综述非常及时且重要，它填补了AI在科学研究领域系统性总结的空白。其提出的分类法和未来方向对于指导后续研究具有重要价值，同时汇编的资源也能极大地方便研究人员。"}}
{"id": "2507.01509", "title": "Mamba Guided Boundary Prior Matters: A New Perspective for Generalized Polyp Segmentation", "authors": ["Tapas K. Dutta", "Snehashis Majhi", "Deepak Ranjan Nayak", "Debesh Jha"], "summary": "Polyp segmentation in colonoscopy images is crucial for early detection and\ndiagnosis of colorectal cancer. However, this task remains a significant\nchallenge due to the substantial variations in polyp shape, size, and color, as\nwell as the high similarity between polyps and surrounding tissues, often\ncompounded by indistinct boundaries. While existing encoder-decoder CNN and\ntransformer-based approaches have shown promising results, they struggle with\nstable segmentation performance on polyps with weak or blurry boundaries. These\nmethods exhibit limited abilities to distinguish between polyps and non-polyps\nand capture essential boundary cues. Moreover, their generalizability still\nfalls short of meeting the demands of real-time clinical applications. To\naddress these limitations, we propose SAM-MaGuP, a groundbreaking approach for\nrobust polyp segmentation. By incorporating a boundary distillation module and\na 1D-2D Mamba adapter within the Segment Anything Model (SAM), SAM-MaGuP excels\nat resolving weak boundary challenges and amplifies feature learning through\nenriched global contextual interactions. Extensive evaluations across five\ndiverse datasets reveal that SAM-MaGuP outperforms state-of-the-art methods,\nachieving unmatched segmentation accuracy and robustness. Our key innovations,\na Mamba-guided boundary prior and a 1D-2D Mamba block, set a new benchmark in\nthe field, pushing the boundaries of polyp segmentation to new heights.", "comment": "11 pages, 2 figures, MICCAI-2025", "pdf_url": "http://arxiv.org/pdf/2507.01509v1", "categories": ["cs.CV", "cs.LG"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01509v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "Mamba引导的边界先验很重要：广义息肉分割的新视角", "tldr": "SAM-MaGuP利用Mamba引导的边界先验和1D-2D Mamba适配器改进息肉分割，尤其针对弱边界，性能超越现有方法。", "motivation": "结肠镜图像中的息肉分割对于结直肠癌的早期检测和诊断至关重要。然而，由于息肉形状、大小和颜色的显著变异，以及息肉与周围组织的高度相似性，加上边界不清晰，这项任务仍然面临巨大挑战。现有方法在处理弱或模糊边界息肉时表现不佳，区分息肉和非息肉的能力有限，且泛化能力不足以满足实时临床应用需求。", "method": "提出SAM-MaGuP方法，通过在Segment Anything Model (SAM)中引入边界蒸馏模块和1D-2D Mamba适配器来解决弱边界挑战并增强特征学习。其核心创新包括Mamba引导的边界先验和1D-2D Mamba块。", "result": "在五个不同数据集上的广泛评估表明，SAM-MaGuP优于现有最先进的方法，实现了无与伦比的分割精度和鲁棒性。", "conclusion": "本文提出的Mamba引导的边界先验和1D-2D Mamba块等关键创新，为息肉分割领域树立了新基准，将息肉分割的界限推向了新高度。", "translation": "结肠镜图像中的息肉分割对于结直肠癌的早期检测和诊断至关重要。然而，由于息肉形状、大小和颜色的显著变异，以及息肉与周围组织的高度相似性，加上边界不清晰，这项任务仍然面临巨大挑战。尽管现有的编码器-解码器CNN和基于Transformer的方法已显示出有希望的结果，但它们在处理具有弱或模糊边界的息肉时，分割性能不稳定。这些方法在区分息肉和非息肉以及捕获关键边界线索方面的能力有限。此外，它们的泛化能力仍未能满足实时临床应用的需求。为了解决这些局限性，我们提出了SAM-MaGuP，一种用于鲁棒息肉分割的突破性方法。通过在Segment Anything Model (SAM)中整合边界蒸馏模块和1D-2D Mamba适配器，SAM-MaGuP擅长解决弱边界挑战，并通过丰富的全局上下文交互增强特征学习。在五个不同数据集上的广泛评估表明，SAM-MaGuP优于现有最先进的方法，实现了无与伦比的分割精度和鲁棒性。我们的关键创新，即Mamba引导的边界先验和1D-2D Mamba块，为该领域树立了新基准，将息肉分割的界限推向了新高度。", "summary": "本文针对息肉分割中特别是弱边界的挑战，提出了SAM-MaGuP方法。该方法在SAM中整合了边界蒸馏模块和1D-2D Mamba适配器，并利用Mamba引导的边界先验和1D-2D Mamba块来增强边界区分和全局上下文学习。在五个数据集上的评估表明，SAM-MaGuP在准确性和鲁棒性方面优于现有最先进方法，为广义息肉分割树立了新基准。", "keywords": "息肉分割, Mamba, 边界先验, SAM, 医疗图像分析", "comments": "本文的创新之处在于利用Mamba架构的效率和全局上下文建模能力，专门解决息肉分割中具有挑战性的弱边界问题。将其与SAM结合并引入边界蒸馏模块是一种新颖的方法。这通过提高鲁棒性和准确性，有望显著改善临床应用。"}}
{"id": "2507.01201", "title": "Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models", "authors": ["Hyoseo", "Yoon", "Yisong Yue", "Been Kim"], "summary": "Independently trained vision and language models inhabit disjoint\nrepresentational spaces, shaped by their respective modalities, objectives, and\narchitectures. Yet an emerging hypothesis - the Platonic Representation\nHypothesis - suggests that such models may nonetheless converge toward a shared\nstatistical model of reality. This compatibility, if it exists, raises a\nfundamental question: can we move beyond post-hoc statistical detection of\nalignment and explicitly optimize for it between such disjoint representations?\nWe cast this Platonic alignment problem as a multi-objective optimization task\n- preserve each modality's native structure while aligning for mutual\ncoherence. We introduce the Joint Autoencoder Modulator (JAM) framework that\njointly trains modality-specific autoencoders on the latent representations of\npre-trained single modality models, encouraging alignment through both\nreconstruction and cross-modal objectives. By analogy, this framework serves as\na method to escape Plato's Cave, enabling the emergence of shared structure\nfrom disjoint inputs. We evaluate this framework across three critical design\naxes: (i) the alignment objective - comparing contrastive loss (Con), its\nhard-negative variant (NegCon), and our Spread loss, (ii) the layer depth at\nwhich alignment is most effective, and (iii) the impact of foundation model\nscale on representational convergence. Our findings show that our lightweight\nPareto-efficient framework reliably induces alignment, even across frozen,\nindependently trained representations, offering both theoretical insight and\npractical pathways for transforming generalist unimodal foundations into\nspecialist multimodal models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01201v1", "categories": ["cs.LG", "cs.CV"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01201v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "逃离柏拉图的洞穴：JAM用于对齐独立训练的视觉和语言模型", "tldr": "提出JAM框架，通过多目标优化对齐独立训练的视觉和语言模型，实现模态间的共享表示。", "motivation": "独立训练的视觉和语言模型占据着不相交的表示空间，尽管存在共享现实的统计模型（柏拉图表示假说），但当前方法仅限于事后统计检测，缺乏直接优化其对齐的显式方法。", "method": "引入联合自编码器调制器（JAM）框架，将对齐问题视为多目标优化任务。该框架在预训练的单模态模型的潜在表示上联合训练模态特定的自编码器，通过重建和跨模态目标（如对比损失、硬负变体和Spread损失）来鼓励对齐。同时评估了对齐的最佳层深度和基础模型规模的影响。", "result": "轻量级且帕累托效率的JAM框架能够可靠地诱导对齐，即使在冻结的、独立训练的表示之间也能实现对齐。", "conclusion": "JAM框架成功地解决了独立训练的视觉和语言模型之间的对齐问题，证明了从不相交输入中共享结构的可能性，并为将通用单模态基础模型转化为专业多模态模型提供了理论见解和实践途径。", "translation": "独立训练的视觉和语言模型占据着由各自模态、目标和架构塑造的互不相交的表示空间。然而，一个新兴的假设——柏拉图表示假说——表明，这些模型可能仍然会趋向于一个共享的现实统计模型。如果这种兼容性存在，它就会引出一个基本问题：我们能否超越事后的统计检测，显式地优化这些不相交表示之间的对齐？我们将这个柏拉图式对齐问题视为一个多目标优化任务——在保持每种模态原生结构的同时，实现相互的一致性对齐。我们引入了联合自编码器调制器（JAM）框架，该框架在预训练的单模态模型的潜在表示上联合训练模态特定的自编码器，通过重建和跨模态目标鼓励对齐。通过类比，这个框架是逃离柏拉图洞穴的一种方法，使得共享结构能够从不相交的输入中浮现。我们通过三个关键设计轴评估了这个框架：(i) 对齐目标——比较对比损失（Con）、其硬负变体（NegCon）和我们的Spread损失，(ii) 对齐最有效的层深度，以及 (iii) 基础模型规模对表示收敛的影响。我们的研究结果表明，我们轻量级且帕累托效率的框架能够可靠地诱导对齐，即使在冻结的、独立训练的表示之间也能实现，为将通用单模态基础模型转化为专业多模态模型提供了理论见解和实践途径。", "summary": "本文提出联合自编码器调制器（JAM）框架，旨在解决独立训练的视觉和语言模型之间表示空间不相交的问题。该框架将对齐视为多目标优化任务，通过在预训练模型的潜在表示上联合训练模态特定自编码器，利用重建和跨模态目标实现模态间的对齐。实验结果表明，JAM框架能够高效且可靠地对齐冻结的独立训练表示，为构建多模态模型提供了新途径。", "keywords": "视觉语言对齐, 多模态学习, 联合自编码器, 柏拉图表示假说, 表示学习", "comments": "本文通过引入JAM框架，巧妙地将“柏拉图表示假说”具象化为可优化的对齐问题，其创新点在于提出了一种轻量级且帕累托效率的方法来对齐独立训练的、甚至已冻结的单模态模型。这种方法不仅具有理论意义，证明了从不相交输入中共享结构的可能性，而且提供了将通用单模态模型转化为专业多模态模型的实用路径，对于推动多模态AI发展具有重要意义。"}}
{"id": "2507.01915", "title": "Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models", "authors": ["Chengao Li", "Hanyu Zhang", "Yunkun Xu", "Hongyan Xue", "Xiang Ao", "Qing He"], "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful\ntechnique for aligning large language models (LLMs) with human preferences.\nHowever, effectively aligning LLMs with diverse human preferences remains a\nsignificant challenge, particularly when they are conflict. To address this\nissue, we frame human value alignment as a multi-objective optimization\nproblem, aiming to maximize a set of potentially conflicting objectives. We\nintroduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning\nparadigm that employs multiple-gradient descent to align LLMs with diverse\npreference distributions. GAPO adaptively rescales the gradients for each\nobjective to determine an update direction that optimally balances the\ntrade-offs between objectives. Additionally, we introduce P-GAPO, which\nincorporates user preferences across different objectives and achieves Pareto\nsolutions that better align with the user's specific needs. Our theoretical\nanalysis demonstrates that GAPO converges towards a Pareto optimal solution for\nmultiple objectives. Empirical results on Mistral-7B show that GAPO outperforms\ncurrent state-of-the-art methods, achieving superior performance in both\nhelpfulness and harmlessness.", "comment": "19 pages, 3 figures. Accepted by ACL 2025 (main)", "pdf_url": "http://arxiv.org/pdf/2507.01915v1", "categories": ["cs.CL", "cs.AI", "cs.LG"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01915v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "梯度自适应策略优化：迈向大型语言模型的多目标对齐", "tldr": "提出GAPO和P-GAPO，通过自适应梯度缩放解决LLMs与多样化、冲突性人类偏好对齐的多目标优化问题，并在Mistral-7B上表现优异。", "motivation": "强化学习人类反馈（RLHF）在使大型语言模型（LLMs）与多样化、特别是相互冲突的人类偏好对齐时面临显著挑战。", "method": "将人类价值对齐框定为一个多目标优化问题，旨在最大化一组可能相互冲突的目标。引入了梯度自适应策略优化（GAPO），这是一种新颖的微调范式，采用多梯度下降来使LLMs与多样化的偏好分布对齐。GAPO自适应地重新调整每个目标的梯度，以确定一个能够最佳平衡目标之间权衡的更新方向。此外，还引入了P-GAPO，它结合了用户在不同目标上的偏好，实现了更好地与用户特定需求对齐的帕累托解。", "result": "理论分析表明GAPO收敛到多目标的帕累托最优解。在Mistral-7B上的实证结果表明，GAPO优于当前最先进的方法，在有用性和无害性方面都取得了卓越的性能。", "conclusion": "本文提出了一种名为梯度自适应策略优化（GAPO）的新型微调范式，通过将其框定为多目标优化问题，有效解决了大型语言模型与多样化且可能冲突的人类偏好对齐的挑战，并已被证明在理论上收敛到帕累托最优解并在实践中取得优异性能。", "translation": "从人类反馈中进行强化学习（RLHF）已成为使大型语言模型（LLMs）与人类偏好对齐的强大技术。然而，有效地使LLMs与多样化的人类偏好对齐仍然是一个重大挑战，特别是当它们存在冲突时。为了解决这个问题，我们将人类价值对齐框定为一个多目标优化问题，旨在最大化一组可能相互冲突的目标。我们引入了梯度自适应策略优化（GAPO），这是一种新颖的微调范式，它采用多梯度下降来使LLMs与多样化的偏好分布对齐。GAPO自适应地重新调整每个目标的梯度，以确定一个能够最佳平衡目标之间权衡的更新方向。此外，我们引入了P-GAPO，它结合了用户在不同目标上的偏好，实现了更好地与用户特定需求对齐的帕累托解。我们的理论分析表明，GAPO收敛到多目标的帕累托最优解。在Mistral-7B上的实证结果表明，GAPO优于当前最先进的方法，在有用性和无害性方面都取得了卓越的性能。", "summary": "本文提出了一种名为梯度自适应策略优化（GAPO）的新型微调范式，旨在解决大型语言模型（LLMs）在与多样化且可能冲突的人类偏好对齐时面临的多目标优化挑战。GAPO通过自适应地重新调整每个目标的梯度来平衡不同目标间的权衡。此外，P-GAPO版本整合了用户偏好以实现个性化的帕aretto解。理论分析证明了GAPO的帕累托最优收敛性，并在Mistral-7B上的实验表明其在有用性和无害性方面均优于现有SOTA方法。", "keywords": "大型语言模型, 多目标优化, 策略优化, 梯度自适应, RLHF", "comments": "本文的创新之处在于将LLM对齐问题重新定义为多目标优化，并提出了梯度自适应策略优化（GAPO）来处理潜在冲突的偏好。通过自适应地调整梯度来平衡多个目标，GAPO提供了一种更精细、更有效的对齐方法。P-GAPO的引入进一步提升了实用性，允许根据用户特定需求进行个性化对齐。其理论收敛性证明和在Mistral-7B上的实证性能提升凸显了该方法的潜力和重要性，特别是在构建更安全、更有用的LLM方面。"}}
{"id": "2507.01076", "title": "Empirical Analysis Of Heuristic and Approximation Algorithms for the The Mutual-Visibility Problem", "authors": ["Vanja Stojanović", "Bor Pangeršič"], "summary": "The NP-complete mutual-visibility (MV) problem currently lacks empirical\nanalysis on its practical behaviour despite theoretical studies. This paper\naddresses this gap by implementing and evaluating three distinct algorithms - a\ndirect greedy heuristic, a hypergraph-based approximation, and a genetic\nalgorithm - on diverse synthetic graph datasets, including those with\nanalytically known $\\mu(G)$ values and general graph models. Our results\ndemonstrate that for smaller graphs, the algorithms consistently achieve MV set\nsizes aligning with theoretical bounds. However, for larger instances, achieved\nsolution sizes notably diverge from theoretical limits; this, combined with the\nabsence of tight bounds, complicates absolute quality assessment. Nevertheless,\nvalidation on known optimal graphs showed the Genetic Algorithm and other\nheuristics empirically performing best among tested methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01076v1", "categories": ["cs.CG", "cs.AI", "cs.PF", "math.CO"], "cate": "cs.CG", "url": "http://arxiv.org/abs/2507.01076v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "互可见性问题的启发式和近似算法的实证分析", "tldr": "本文对NP完全的互可见性问题进行了首次实证分析，评估了三种算法（贪婪启发式、超图近似、遗传算法）在不同图数据集上的性能。结果显示，对于小图，算法性能与理论边界一致；对于大图，解决方案偏离理论极限，但遗传算法表现最佳。", "motivation": "尽管互可见性问题（MV）已有理论研究，但其在实际行为上的经验分析仍有不足。本文旨在填补这一空白。", "method": "本文实现了并评估了三种不同的算法：直接贪婪启发式算法、基于超图的近似算法和遗传算法。这些算法在多样化的合成图数据集上进行了测试，包括那些具有已知µ(G)值的图和通用图模型。", "result": "对于较小的图，算法实现的MV集大小与理论界限一致。然而，对于较大的实例，获得的解决方案大小显著偏离理论极限，这使得绝对质量评估变得复杂。尽管如此，在已知最优图上的验证表明，遗传算法和其他启发式算法在测试方法中表现最佳。", "conclusion": "本文首次对互可见性问题进行了实证分析，并发现虽然算法在小图上表现良好，但在大图上仍存在挑战。遗传算法在实践中表现出相对优势。", "translation": "NP完全的互可见性（MV）问题尽管有理论研究，但目前缺乏对其实际行为的实证分析。本文通过在多样化的合成图数据集上实现和评估三种不同的算法——直接贪婪启发式算法、基于超图的近似算法和遗传算法——来弥补这一空白，这些数据集包括具有解析已知µ(G)值的图和通用图模型。我们的结果表明，对于较小的图，算法实现的MV集大小与理论界限一致。然而，对于较大的实例，获得的解决方案大小显著偏离理论极限；这一点，加上缺乏紧密界限，使得绝对质量评估变得复杂。尽管如此，在已知最优图上的验证表明，遗传算法和其他启发式算法在测试方法中表现最佳。", "summary": "本文对NP完全的互可见性问题进行了首次实证分析，解决了该领域缺乏经验研究的空白。研究者实现了贪婪启发式、超图近似和遗传算法，并在多种合成图数据集上进行评估。结果显示，对于小图，算法性能与理论界限吻合；但对于大图，解决方案明显偏离理论极限。尽管存在评估挑战，遗传算法在已知最优图上表现出最优性能。", "keywords": "互可见性问题, 启发式算法, 近似算法, 遗传算法, 实证分析", "comments": "本文填补了互可见性问题在实证分析方面的空白，首次对多种算法进行了实践评估。其创新在于将理论算法应用于实际数据集，并揭示了小图与大图之间性能的差异。尽管对于大图的绝对质量评估存在局限，但对遗传算法性能的验证具有重要意义，为后续研究提供了实践基础。"}}
{"id": "2507.01532", "title": "Exploring Pose-based Sign Language Translation: Ablation Studies and Attention Insights", "authors": ["Tomas Zelezny", "Jakub Straka", "Vaclav Javorek", "Ondrej Valach", "Marek Hruz", "Ivan Gruber"], "summary": "Sign Language Translation (SLT) has evolved significantly, moving from\nisolated recognition approaches to complex, continuous gloss-free translation\nsystems. This paper explores the impact of pose-based data preprocessing\ntechniques - normalization, interpolation, and augmentation - on SLT\nperformance. We employ a transformer-based architecture, adapting a modified T5\nencoder-decoder model to process pose representations. Through extensive\nablation studies on YouTubeASL and How2Sign datasets, we analyze how different\npreprocessing strategies affect translation accuracy. Our results demonstrate\nthat appropriate normalization, interpolation, and augmentation techniques can\nsignificantly improve model robustness and generalization abilities.\nAdditionally, we provide a deep analysis of the model's attentions and reveal\ninteresting behavior suggesting that adding a dedicated register token can\nimprove overall model performance. We publish our code on our GitHub\nrepository, including the preprocessed YouTubeASL data.", "comment": "8 pages, 9 figures, supplementary, SLRTP2025, CVPR2025", "pdf_url": "http://arxiv.org/pdf/2507.01532v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01532v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "探索基于姿态的手语翻译：消融研究与注意力洞察", "tldr": "本文研究了基于姿态数据预处理技术（归一化、插值、增强）对手语翻译（SLT）性能的影响，使用Transformer-T5模型，并通过消融研究证明了这些技术能显著提升模型鲁棒性和泛化能力，并发现添加专用寄存器token可改善性能。", "motivation": "手语翻译（SLT）已从早期孤立识别发展到复杂的连续无光泽翻译系统。本文旨在深入探索基于姿态的数据预处理技术（归一化、插值和增强）如何影响和提升手语翻译的性能。", "method": "本文采用基于Transformer的架构，具体是改编的T5编码器-解码器模型来处理姿态表示。研究通过在YouTubeASL和How2Sign数据集上进行广泛的消融研究，分析了不同的姿态数据预处理策略（归一化、插值、增强）对手语翻译准确性的具体影响。", "result": "研究结果表明，适当的归一化、插值和增强技术能够显著提高手语翻译模型的鲁棒性和泛化能力。此外，对模型注意力机制的深入分析揭示，添加一个专用的寄存器token可以改善整体模型性能。", "conclusion": "基于姿态的预处理技术（归一化、插值、增强）对手语翻译模型的性能提升至关重要，能显著增强模型鲁棒性和泛化能力。同时，通过深入分析模型注意力，发现添加专用寄存器token是提升模型性能的有效策略。", "translation": "手语翻译（SLT）已显著发展，从孤立识别方法转向复杂的、连续的无光泽翻译系统。本文探讨了基于姿态的数据预处理技术——归一化、插值和增强——对手语翻译性能的影响。我们采用基于Transformer的架构，调整了一个修改过的T5编码器-解码器模型来处理姿态表示。通过在YouTubeASL和How2Sign数据集上进行广泛的消融研究，我们分析了不同的预处理策略如何影响翻译准确性。我们的结果表明，适当的归一化、插值和增强技术可以显著提高模型的鲁棒性和泛化能力。此外，我们对模型的注意力进行了深入分析，揭示了有趣的行为，表明添加一个专用的寄存器token可以提高整体模型性能。我们在GitHub仓库中发布了我们的代码，包括预处理过的YouTubeASL数据。", "summary": "本文深入探讨了基于姿态的数据预处理技术（包括归一化、插值和增强）对手语翻译（SLT）性能的影响。研究采用一个基于Transformer的修改版T5编码器-解码器模型，并在YouTubeASL和How2Sign数据集上进行了广泛的消融实验。结果表明，合适的预处理策略能显著提升模型的鲁棒性和泛化能力。此外，对模型注意力机制的分析提示，引入专用寄存器token有助于进一步提高模型性能。", "keywords": "手语翻译, 姿态数据, 预处理, Transformer, 消融研究", "comments": "本文的创新之处在于系统性地研究了姿态数据预处理技术对手语翻译性能的具体影响，并提供了详细的消融研究结果。同时，对模型注意力机制的深入分析，特别是发现“寄存器token”的潜在效用，为未来的手语翻译模型设计提供了新的思路。这对于提升手语翻译的实用性和准确性具有重要意义。"}}
{"id": "2507.01921", "title": "NaturalThoughts: Selecting and Distilling Reasoning Traces for General Reasoning Tasks", "authors": ["Yang Li", "Youssef Emad", "Karthik Padthe", "Jack Lanchantin", "Weizhe Yuan", "Thao Nguyen", "Jason Weston", "Shang-Wen Li", "Dong Wang", "Ilia Kulikov", "Xian Li"], "summary": "Recent work has shown that distilling reasoning traces from a larger teacher\nmodel via supervised finetuning outperforms reinforcement learning with the\nsmaller student model alone (Guo et al. 2025). However, there has not been a\nsystematic study of what kind of reasoning demonstrations from the teacher are\nmost effective in improving the student model's reasoning capabilities. In this\nwork we curate high-quality \"NaturalThoughts\" by selecting reasoning traces\nfrom a strong teacher model based on a large pool of questions from\nNaturalReasoning (Yuan et al. 2025). We first conduct a systematic analysis of\nfactors that affect distilling reasoning capabilities, in terms of sample\nefficiency and scalability for general reasoning tasks. We observe that simply\nscaling up data size with random sampling is a strong baseline with steady\nperformance gains. Further, we find that selecting difficult examples that\nrequire more diverse reasoning strategies is more sample-efficient to transfer\nthe teacher model's reasoning skills. Evaluated on both Llama and Qwen models,\ntraining with NaturalThoughts outperforms existing reasoning datasets such as\nOpenThoughts, LIMO, etc. on general STEM reasoning benchmarks including\nGPQA-Diamond, MMLU-Pro and SuperGPQA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01921v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01921v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "NaturalThoughts：为通用推理任务选择和提炼推理轨迹", "tldr": "该研究提出了一种名为 NaturalThoughts 的方法，通过选择和提炼教师模型的推理轨迹来提高学生模型的推理能力，并发现选择困难示例比随机采样更有效，在多个基准测试中表现优于现有数据集。", "motivation": "现有研究表明，通过监督微调从大型教师模型中提炼推理轨迹优于单独使用较小的学生模型进行强化学习。然而，目前尚未系统研究何种类型的教师模型推理演示在提高学生模型的推理能力方面最有效。", "method": "本研究通过从一个强大的教师模型中选择推理轨迹，策划了高质量的“NaturalThoughts”，这些轨迹来自 NaturalReasoning 的大量问题。首先，对影响推理能力提炼的因素进行了系统分析，包括通用推理任务的样本效率和可扩展性。其次，发现选择需要更多样化推理策略的困难示例在迁移教师模型推理技能方面更具样本效率。", "result": "研究发现，简单地通过随机采样扩大数据规模是一个强有力的基线，性能稳定提升。进一步发现，选择需要更多样化推理策略的困难示例在迁移教师模型推理技能方面更具样本效率。在 Llama 和 Qwen 模型上的评估表明，使用 NaturalThoughts 进行训练在包括 GPQA-Diamond、MMLU-Pro 和 SuperGPQA 在内的通用 STEM 推理基准测试中优于 OpenThoughts、LIMO 等现有推理数据集。", "conclusion": "通过系统分析和选择困难的推理示例，可以更有效地从教师模型中提炼推理能力，并显著提升学生模型在通用推理任务上的表现。", "translation": "近期工作表明，通过监督微调从大型教师模型中提炼推理轨迹，其效果优于单独使用较小的学生模型进行强化学习（Guo et al. 2025）。然而，目前尚未系统研究何种类型的教师演示在提高学生模型的推理能力方面最有效。在这项工作中，我们通过从一个强大的教师模型中选择推理轨迹，策划了高质量的“NaturalThoughts”，这些轨迹来自 NaturalReasoning 的大量问题（Yuan et al. 2025）。我们首先对影响推理能力提炼的因素进行了系统分析，包括通用推理任务的样本效率和可扩展性。我们观察到，简单地通过随机采样扩大数据规模是一个强有力的基线，性能稳定提升。此外，我们发现选择需要更多样化推理策略的困难示例在迁移教师模型推理技能方面更具样本效率。在 Llama 和 Qwen 模型上的评估表明，使用 NaturalThoughts 进行训练在包括 GPQA-Diamond、MMLU-Pro 和 SuperGPQA 在内的通用 STEM 推理基准测试中优于 OpenThoughts、LIMO 等现有推理数据集。", "summary": "本研究旨在系统探究如何有效提炼大型教师模型的推理能力以提升小型学生模型。通过从 NaturalReasoning 中选择并策划高质量的“NaturalThoughts”推理轨迹，研究发现，尽管随机采样扩充数据是有效基线，但选择需要多样化推理策略的困难示例能更有效地迁移教师模型的推理技能。实验证明，基于 NaturalThoughts 的训练在多个通用 STEM 推理基准测试中超越了现有数据集，为提高模型推理能力提供了新方法。", "keywords": "推理轨迹, 知识蒸馏, 样本效率, 通用推理, NaturalThoughts", "comments": "该研究的创新之处在于系统地分析了教师模型推理演示的有效性，并提出了一种通过选择困难示例来提高样本效率的方法。这种选择性蒸馏而非单纯扩大数据规模的策略，对于资源有限的训练场景具有重要意义，也为未来推理能力的迁移学习提供了新的视角。其提出的 NaturalThoughts 数据集和方法有望成为通用推理任务的新基线。"}}
{"id": "2507.01535", "title": "TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV Object Tracking", "authors": ["Bingxi Liu", "Calvin Chen", "Junhao Li", "Guyang Yu", "Haoqian Song", "Xuchen Liu", "Jinqiang Cui", "Hong Zhang"], "summary": "The Vision Transformer (ViT) model has long struggled with the challenge of\nquadratic complexity, a limitation that becomes especially critical in unmanned\naerial vehicle (UAV) tracking systems, where data must be processed in real\ntime. In this study, we explore the recently proposed State-Space Model, Mamba,\nleveraging its computational efficiency and capability for long-sequence\nmodeling to effectively process dense image sequences in tracking tasks. First,\nwe highlight the issue of temporal inconsistency in existing Mamba-based\nmethods, specifically the failure to account for temporal continuity in the\nMamba scanning mechanism. Secondly, building upon this insight,we propose\nTrackingMiM, a Mamba-in-Mamba architecture, a minimal-computation burden model\nfor handling image sequence of tracking problem. In our framework, the mamba\nscan is performed in a nested way while independently process temporal and\nspatial coherent patch tokens. While the template frame is encoded as query\ntoken and utilized for tracking in every scan. Extensive experiments conducted\non five UAV tracking benchmarks confirm that the proposed TrackingMiM achieves\nstate-of-the-art precision while offering noticeable higher speed in UAV\ntracking.", "comment": "12 pages", "pdf_url": "http://arxiv.org/pdf/2507.01535v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01535v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "追踪MiM：高效的Mamba-in-Mamba序列化用于实时无人机目标追踪", "tldr": "提出TrackingMiM，一种基于Mamba-in-Mamba架构，通过嵌套Mamba扫描解决现有Mamba方法的时间不一致性问题，在无人机目标追踪中实现高精度和更快的速度。", "motivation": "现有的Vision Transformer (ViT) 模型存在二次复杂度问题，这在需要实时处理的无人机追踪系统中尤其关键。此外，现有基于Mamba的方法在Mamba扫描机制中未能考虑时间连续性，存在时间不一致性问题。", "method": "提出TrackingMiM，一种Mamba-in-Mamba架构。该模型计算负担极小，用于处理追踪问题的图像序列。其核心在于：Mamba扫描以嵌套方式执行，同时独立处理时间和空间连贯的patch token。模板帧被编码为查询token，并在每次扫描中用于追踪。", "result": "在五个无人机追踪基准测试中，所提出的TrackingMiM实现了最先进的精度，同时在无人机追踪中提供了显著更高的速度。", "conclusion": "TrackingMiM通过其Mamba-in-Mamba架构和对时间连续性的处理，有效解决了实时无人机追踪中ViT的复杂性问题和现有Mamba方法的时间不一致性，达到了卓越的性能。", "translation": "视觉Transformer (ViT) 模型长期以来一直面临二次复杂度的挑战，这一限制在需要实时处理数据的无人机 (UAV) 追踪系统中变得尤为关键。在本研究中，我们探索了最近提出的状态空间模型Mamba，利用其计算效率和长序列建模能力，有效处理追踪任务中的密集图像序列。首先，我们强调了现有基于Mamba方法中的时间不一致性问题，特别是未能考虑Mamba扫描机制中的时间连续性。其次，基于这一洞察，我们提出了TrackingMiM，一种Mamba-in-Mamba架构，这是一个计算负担极小的模型，用于处理追踪问题的图像序列。在我们的框架中，Mamba扫描以嵌套方式执行，同时独立处理时间和空间连贯的patch token。同时，模板帧被编码为查询token并在每次扫描中用于追踪。在五个无人机追踪基准上进行的广泛实验证实，所提出的TrackingMiM在无人机追踪中实现了最先进的精度，同时提供了显著更高的速度。", "summary": "本文提出TrackingMiM，一种基于Mamba-in-Mamba架构的实时无人机目标追踪模型，旨在解决ViT的二次复杂度问题以及现有Mamba方法的时间不一致性。TrackingMiM通过嵌套Mamba扫描，独立处理时间和空间信息，并将模板帧作为查询token。实验证明，TrackingMiM在精度和速度上均达到SOTA水平。", "keywords": "无人机追踪, Mamba, 状态空间模型, 实时追踪, Mamba-in-Mamba", "comments": "本文的创新点在于提出了Mamba-in-Mamba (MiM) 架构，并解决了现有Mamba模型在处理时间序列数据时的时间不一致性问题。通过嵌套Mamba扫描和独立处理时空信息，实现了高效且精确的实时无人机追踪，这对于计算资源受限的UAV系统具有重要意义。"}}
{"id": "2507.01923", "title": "Decision-oriented Text Evaluation", "authors": ["Yu-Shiang Huang", "Chuan-Ju Wang", "Chung-Chi Chen"], "summary": "Natural language generation (NLG) is increasingly deployed in high-stakes\ndomains, yet common intrinsic evaluation methods, such as n-gram overlap or\nsentence plausibility, weakly correlate with actual decision-making efficacy.\nWe propose a decision-oriented framework for evaluating generated text by\ndirectly measuring its influence on human and large language model (LLM)\ndecision outcomes. Using market digest texts--including objective morning\nsummaries and subjective closing-bell analyses--as test cases, we assess\ndecision quality based on the financial performance of trades executed by human\ninvestors and autonomous LLM agents informed exclusively by these texts. Our\nfindings reveal that neither humans nor LLM agents consistently surpass random\nperformance when relying solely on summaries. However, richer analytical\ncommentaries enable collaborative human-LLM teams to outperform individual\nhuman or agent baselines significantly. Our approach underscores the importance\nof evaluating generated text by its ability to facilitate synergistic\ndecision-making between humans and LLMs, highlighting critical limitations of\ntraditional intrinsic metrics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01923v1", "categories": ["cs.CL"], "cate": "cs.CL", "url": "http://arxiv.org/abs/2507.01923v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "决策导向的文本评估", "tldr": "提出一种评估生成文本的新框架，通过衡量其对人类和LLM决策结果的影响，发现传统方法不足，协同决策优于单独决策。", "motivation": "现有的自然语言生成（NLG）评估方法（如n-gram重叠或句子合理性）与实际决策效率相关性弱，尤其是在高风险领域。", "method": "提出一种决策导向的框架，通过直接衡量生成文本对人类和大型语言模型（LLM）决策结果的影响来评估文本。使用市场摘要文本（包括客观的早间总结和主观的收盘分析）作为测试案例，根据人类投资者和自主LLM代理仅依据这些文本执行交易的财务表现来评估决策质量。", "result": "发现人类和LLM代理仅依赖摘要时，表现均未能持续超越随机水平。然而，更丰富的分析性评论使人机协作团队显著优于单独的人类或代理基线。", "conclusion": "该方法强调了评估生成文本时，应关注其促进人类和LLM之间协同决策的能力，并指出传统内在指标的关键局限性。", "translation": "自然语言生成（NLG）越来越多地应用于高风险领域，然而，常见的内在评估方法，如n-gram重叠或句子合理性，与实际决策效率的相关性较弱。我们提出了一种决策导向的框架，通过直接衡量生成文本对人类和大型语言模型（LLM）决策结果的影响来评估生成文本。我们以市场摘要文本——包括客观的早间总结和主观的收盘分析——作为测试案例，根据人类投资者和自主LLM代理仅依据这些文本执行交易的财务表现来评估决策质量。我们的研究结果显示，当仅依赖摘要时，人类和LLM代理的表现均未能持续超越随机水平。然而，更丰富的分析性评论使人机协作团队能够显著优于单独的人类或代理基线。我们的方法强调了根据生成文本促进人类和LLM之间协同决策的能力来评估其重要性，并突出了传统内在指标的关键局限性。", "summary": "该研究提出了一种新的“决策导向”框架来评估自然语言生成（NLG）文本，该框架直接衡量生成文本对人类和大型语言模型（LLM）决策结果的影响。通过金融市场摘要文本的案例研究，作者发现单独依靠摘要文本的人类或LLM代理表现不佳，但结合更丰富分析评论的人机协作团队能显著提升决策表现。这表明传统的NLG评估方法存在局限，强调了文本在促进人机协同决策中的作用。", "keywords": "文本评估, 决策导向, 自然语言生成, 人机协同, 大型语言模型", "comments": "这篇论文的创新之处在于提出了一种与实际应用场景更紧密相关的文本评估范式，即从“决策效果”而非“文本质量”本身出发。它揭示了传统内在评估指标的不足，并强调了在复杂决策任务中，生成文本如何促进人机协同的重要性。这对于NLG在高风险领域的部署具有重要指导意义。"}}
{"id": "2507.01539", "title": "A Multi-Centric Anthropomorphic 3D CT Phantom-Based Benchmark Dataset for Harmonization", "authors": ["Mohammadreza Amirian", "Michael Bach", "Oscar Jimenez-del-Toro", "Christoph Aberle", "Roger Schaer", "Vincent Andrearczyk", "Jean-Félix Maestrati", "Maria Martin Asiain", "Kyriakos Flouris", "Markus Obmann", "Clarisse Dromain", "Benoît Dufour", "Pierre-Alexandre Alois Poletti", "Hendrik von Tengg-Kobligk", "Rolf Hügli", "Martin Kretzschmar", "Hatem Alkadhi", "Ender Konukoglu", "Henning Müller", "Bram Stieltjes", "Adrien Depeursinge"], "summary": "Artificial intelligence (AI) has introduced numerous opportunities for human\nassistance and task automation in medicine. However, it suffers from poor\ngeneralization in the presence of shifts in the data distribution. In the\ncontext of AI-based computed tomography (CT) analysis, significant data\ndistribution shifts can be caused by changes in scanner manufacturer,\nreconstruction technique or dose. AI harmonization techniques can address this\nproblem by reducing distribution shifts caused by various acquisition settings.\nThis paper presents an open-source benchmark dataset containing CT scans of an\nanthropomorphic phantom acquired with various scanners and settings, which\npurpose is to foster the development of AI harmonization techniques. Using a\nphantom allows fixing variations attributed to inter- and intra-patient\nvariations. The dataset includes 1378 image series acquired with 13 scanners\nfrom 4 manufacturers across 8 institutions using a harmonized protocol as well\nas several acquisition doses. Additionally, we present a methodology, baseline\nresults and open-source code to assess image- and feature-level stability and\nliver tissue classification, promoting the development of AI harmonization\nstrategies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01539v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01539v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "用于协调的多中心拟人化3D CT体模基准数据集", "tldr": "AI在CT分析中因数据偏移而泛化能力差。本文提出了一个多中心CT体模数据集，旨在为AI协调技术提供基准并促进其发展。", "motivation": "人工智能在医学领域面临数据分布偏移导致的泛化能力差的问题，尤其在基于AI的CT分析中，扫描仪、重建技术或剂量变化会引起显著的数据偏移。因此，需要AI协调技术来减少这些偏移。", "method": "本文提出了一个开源基准数据集，其中包含使用不同扫描仪和设置采集的拟人化体模的CT扫描。该数据集采用统一协议和多种采集剂量。此外，作者还提出了一种方法、基线结果和开源代码，用于评估图像和特征层面的稳定性以及肝脏组织分类。", "result": "该数据集包含来自8个机构、4家制造商的13台扫描仪采集的1378个图像序列。论文还提供了基线结果和开源代码。", "conclusion": "该数据集及配套资源旨在促进AI协调技术的发展。", "translation": "人工智能（AI）为医学领域的人类辅助和任务自动化带来了众多机遇。然而，在数据分布发生偏移时，AI的泛化能力较差。在基于AI的计算机断层扫描（CT）分析中，扫描仪制造商、重建技术或剂量等因素的变化可能导致显著的数据分布偏移。AI协调技术可以通过减少由不同采集设置引起的数据分布偏移来解决这个问题。本文提出了一个开源基准数据集，其中包含使用不同扫描仪和设置采集的拟人化体模的CT扫描，旨在促进AI协调技术的发展。使用体模可以固定归因于患者间和患者内变异的差异。该数据集包含在8个机构中，使用统一协议以及多种采集剂量，通过来自4家制造商的13台扫描仪采集的1378个图像序列。此外，我们还提出了一种方法、基线结果和开源代码，用于评估图像和特征级别的稳定性以及肝脏组织分类，从而促进AI协调策略的开发。", "summary": "为解决AI在CT分析中因扫描仪、重建技术或剂量等因素导致的数据分布偏移而泛化能力差的问题，本文提出了一个多中心、开源的基准数据集。该数据集包含1378个拟人化体模的CT图像序列，这些序列是在8个机构中，通过来自4家制造商的13台扫描仪，在各种设置和剂量下采集的。该数据集连同提出的方法、基线结果和开源代码，旨在促进AI协调技术的开发和评估。", "keywords": "AI协调, CT, 基准数据集, 拟人化体模, 数据分布偏移", "comments": "该论文解决了医学AI中一个关键的实际挑战：数据异质性。通过提供一个标准化的、多中心的体模数据集，它为开发和基准测试AI协调技术提供了一个受控环境，这对于提高AI在真实临床环境中的泛化能力具有创新性和极高价值。使用体模有效地消除了患者变异性，从而可以专注于采集参数变异性的研究。"}}
{"id": "2507.01235", "title": "Quantum Machine Learning in Transportation: A Case Study of Pedestrian Stress Modelling", "authors": ["Bara Rababa", "Bilal Farooq"], "summary": "Quantum computing has opened new opportunities to tackle complex machine\nlearning tasks, for instance, high-dimensional data representations commonly\nrequired in intelligent transportation systems. We explore quantum machine\nlearning to model complex skin conductance response (SCR) events that reflect\npedestrian stress in a virtual reality road crossing experiment. For this\npurpose, Quantum Support Vector Machine (QSVM) with an eight-qubit ZZ feature\nmap and a Quantum Neural Network (QNN) using a Tree Tensor Network ansatz and\nan eight-qubit ZZ feature map, were developed on Pennylane. The dataset\nconsists of SCR measurements along with features such as the response amplitude\nand elapsed time, which have been categorized into amplitude-based classes. The\nQSVM achieved good training accuracy, but had an overfitting problem, showing a\nlow test accuracy of 45% and therefore impacting the reliability of the\nclassification model. The QNN model reached a higher test accuracy of 55%,\nmaking it a better classification model than the QSVM and the classic versions.", "comment": "Proceedings of IEEE Intelligent Transportation Systems Conference,\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.01235v1", "categories": ["cs.LG", "quant-ph"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01235v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "交通领域的量子机器学习：行人压力建模的案例研究", "tldr": "本文探讨了量子机器学习（QSVM和QNN）在虚拟现实行人压力建模中的应用。QNN在测试准确率上优于QSVM和经典模型。", "motivation": "解决智能交通系统中高维数据表示的复杂机器学习任务，并探索量子计算在行人压力建模中的潜力。", "method": "在Pennylane上开发了使用八量子位ZZ特征映射的量子支持向量机（QSVM）和使用树张量网络ansatz及八量子位ZZ特征映射的量子神经网络（QNN），并使用皮肤电导反应（SCR）测量值数据集进行训练和测试。", "result": "QSVM取得了良好的训练准确率但有过拟合问题，测试准确率为45%。QNN模型达到了更高的55%测试准确率，优于QSVM和经典版本。", "conclusion": "量子神经网络（QNN）在行人压力建模方面表现出比量子支持向量机（QSVM）和经典模型更好的分类性能，表明其在处理此类复杂交通数据任务中的潜力。", "translation": "量子计算为解决复杂的机器学习任务开辟了新的机遇，例如智能交通系统中常需要的高维数据表示。我们探索了量子机器学习来模拟复杂的皮肤电导反应（SCR）事件，这些事件反映了虚拟现实道路穿越实验中的行人压力。为此，在Pennylane上开发了使用八量子位ZZ特征映射的量子支持向量机（QSVM）和使用树张量网络ansatz及八量子位ZZ特征映射的量子神经网络（QNN）。数据集包括SCR测量值以及响应幅度、经过时间等特征，这些特征已被分类为基于幅度的类别。QSVM取得了良好的训练准确率，但存在过拟合问题，测试准确率仅为45%，因此影响了分类模型的可靠性。QNN模型达到了更高的55%测试准确率，使其成为比QSVM和经典版本更好的分类模型。", "summary": "本研究探讨了量子机器学习在智能交通系统（具体是行人压力建模）中的应用。研究人员使用量子支持向量机（QSVM）和量子神经网络（QNN）两种模型，通过分析虚拟现实实验中的皮肤电导反应数据来预测行人压力。结果显示，尽管QSVM存在过拟合问题且测试准确率较低（45%），但QNN表现出更好的性能，测试准确率达到55%，优于QSVM和传统模型，表明了量子神经网络在处理此类复杂交通数据方面的潜力。", "keywords": "量子机器学习, 行人压力建模, 皮肤电导反应, 量子支持向量机, 量子神经网络", "comments": "这项研究展示了量子机器学习在解决实际交通问题上的初步探索，特别是行人压力建模。尽管测试准确率仍有提升空间，但QNN相较于QSVM和经典模型的优势，为未来在智能交通领域应用量子计算提供了有价值的见解。过拟合问题是量子机器学习在实际应用中需要关注的关键挑战。"}}
{"id": "2507.01557", "title": "Interpolation-Based Event Visual Data Filtering Algorithms", "authors": ["Marcin Kowlaczyk", "Tomasz Kryjak"], "summary": "The field of neuromorphic vision is developing rapidly, and event cameras are\nfinding their way into more and more applications. However, the data stream\nfrom these sensors is characterised by significant noise. In this paper, we\npropose a method for event data that is capable of removing approximately 99\\%\nof noise while preserving the majority of the valid signal. We have proposed\nfour algorithms based on the matrix of infinite impulse response (IIR) filters\nmethod. We compared them on several event datasets that were further modified\nby adding artificially generated noise and noise recorded with dynamic vision\nsensor. The proposed methods use about 30KB of memory for a sensor with a\nresolution of 1280 x 720 and is therefore well suited for implementation in\nembedded devices.", "comment": "This paper has been accepted for publication at the IEEE Conference\n  on Computer Vision and Pattern Recognition (CVPR) Workshops, Vancouver, 2023.\n  Copyright IEEE", "pdf_url": "http://arxiv.org/pdf/2507.01557v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01557v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于插值的事件视觉数据滤波算法", "tldr": "本文提出了一种基于插值的事件数据滤波算法，能有效去除99%的噪声，同时保留有效信号，且内存占用低，适合嵌入式设备。", "motivation": "事件相机的数据流存在显著噪声，影响了其在神经形态视觉领域的应用。", "method": "提出了四种基于无限脉冲响应（IIR）滤波器矩阵方法的插值算法来过滤事件数据。", "result": "所提出的算法能够去除约99%的噪声，同时保留大部分有效信号。对于1280 x 720分辨率的传感器，该方法仅需约30KB内存。在添加人工噪声和动态视觉传感器记录噪声的事件数据集上进行了比较验证。", "conclusion": "所提出的插值事件视觉数据滤波算法能高效去除噪声，且内存占用低，非常适合在嵌入式设备中实现。", "translation": "标题：基于插值的事件视觉数据滤波算法\n摘要：神经形态视觉领域发展迅速，事件相机正被应用于越来越多的领域。然而，这些传感器的数据流具有显著的噪声特征。在本文中，我们提出了一种事件数据处理方法，能够去除大约99%的噪声，同时保留大部分有效信号。我们提出了四种基于无限脉冲响应（IIR）滤波器矩阵方法的算法。我们在几个事件数据集上对它们进行了比较，这些数据集通过添加人工生成的噪声和动态视觉传感器记录的噪声进行了进一步修改。所提出的方法对于分辨率为1280 x 720的传感器仅使用约30KB内存，因此非常适合在嵌入式设备中实现。", "summary": "本文针对事件相机数据流中存在的显著噪声问题，提出了一种基于无限脉冲响应（IIR）滤波器矩阵的四种插值算法。实验表明，该方法能有效去除约99%的噪声，同时保留大部分有效信号。此外，该算法内存占用极低（约30KB），使其非常适合在嵌入式设备中部署。", "keywords": "事件相机, 噪声滤波, 神经形态视觉, IIR滤波器, 嵌入式设备", "comments": "该研究的创新之处在于提出了一种高效的事件数据噪声过滤方法，在实现高噪声去除率（99%）的同时，保持了极低的内存占用，这对于资源受限的嵌入式设备应用具有重要意义。"}}
{"id": "2507.01241", "title": "Beyond First-Order: Training LLMs with Stochastic Conjugate Subgradients and AdamW", "authors": ["Di Zhang", "Yihang Zhang"], "summary": "Stochastic gradient-based descent (SGD), have long been central to training\nlarge language models (LLMs). However, their effectiveness is increasingly\nbeing questioned, particularly in large-scale applications where empirical\nevidence suggests potential performance limitations. In response, this paper\nproposes a stochastic conjugate subgradient method together with adaptive\nsampling tailored specifically for training LLMs. The method not only achieves\nfaster convergence per iteration but also demonstrates improved scalability\ncompared to traditional SGD techniques. It leverages sample complexity analysis\nto adaptively choose the sample size, employs a stochastic conjugate\nsubgradient approach to determine search directions and utilizing an AdamW-like\nalgorithm to adaptively adjust step sizes. This approach preserves the key\nadvantages of first-order methods while effectively addressing the nonconvexity\nand non-smoothness inherent in LLMs training. Additionally, we provide a\ndetailed analysis of the advantage of the algorithm. Experimental results show\nthat the proposed method not only maintains, but in many cases surpasses, the\nscalability of traditional SGD techniques, significantly enhancing both the\nspeed and accuracy of the optimization process.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01241v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01241v1", "date": "2025-07-01", "updated": "2025-07-01", "AI": {"title_translation": "超越一阶：使用随机共轭次梯度和AdamW训练大型语言模型", "tldr": "本文提出了一种结合自适应采样的随机共轭次梯度方法，并结合AdamW算法训练大型语言模型，旨在解决传统SGD方法在LLM训练中的局限性，实现了更快的收敛速度和更好的可扩展性。", "motivation": "传统的随机梯度下降（SGD）方法在大型语言模型（LLMs）的训练中，尤其是在大规模应用中，其有效性受到质疑，并可能存在性能限制。", "method": "论文提出了一种结合自适应采样的随机共轭次梯度方法来训练LLMs。该方法利用样本复杂度分析自适应地选择样本大小，采用随机共轭次梯度方法确定搜索方向，并利用类似AdamW的算法自适应调整步长。这种方法旨在解决LLM训练中固有的非凸性和非光滑性问题。", "result": "实验结果表明，所提出的方法不仅保持了传统SGD技术的可扩展性，在许多情况下甚至超越了它们，显著提高了优化过程的速度和准确性。", "conclusion": "所提出的随机共轭次梯度方法结合AdamW算法，有效解决了LLMs训练中的挑战，并提供了比传统SGD方法更优的性能、收敛速度和可扩展性。", "translation": "随机梯度下降（SGD）长期以来一直是训练大型语言模型（LLMs）的核心。然而，它们的有效性正日益受到质疑，特别是在大规模应用中，经验证据表明可能存在性能限制。作为回应，本文提出了一种随机共轭次梯度方法，并结合专门为训练LLMs定制的自适应采样。该方法不仅实现了每次迭代更快的收敛速度，而且与传统的SGD技术相比，表现出更高的可扩展性。它利用样本复杂度分析来自适应地选择样本大小，采用随机共轭次梯度方法来确定搜索方向，并利用类似AdamW的算法来自适应调整步长。这种方法保留了一阶方法的关键优势，同时有效解决了LLMs训练中固有的非凸性和非光滑性问题。此外，我们对该算法的优势进行了详细分析。实验结果表明，所提出的方法不仅保持了，而且在许多情况下超越了传统SGD技术的可扩展性，显著提高了优化过程的速度和准确性。", "summary": "本文针对传统SGD方法在大型语言模型（LLMs）训练中面临的性能和可扩展性问题，提出了一种创新的随机共轭次梯度方法。该方法结合自适应采样和类似AdamW的步长调整机制，有效处理LLMs训练中的非凸性和非光滑性。实验证明，新方法在保持甚至超越传统SGD可扩展性的同时，显著提升了优化速度和准确性。", "keywords": "大型语言模型, 随机共轭次梯度, AdamW, 自适应采样, 优化算法", "comments": "这篇论文通过引入超越传统一阶方法的随机共轭次梯度和AdamW，为大型语言模型训练提供了一个有前景的新方向。其创新点在于结合了自适应采样和对非凸、非光滑问题的处理，可能为LLMs的训练效率和性能带来显著提升。"}}
{"id": "2507.01573", "title": "A Gift from the Integration of Discriminative and Diffusion-based Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation", "authors": ["Hao Wang", "Keyan Hu", "Xin Guo", "Haifeng Li", "Chao Tao"], "summary": "Remote sensing semantic segmentation must address both what the ground\nobjects are within an image and where they are located. Consequently,\nsegmentation models must ensure not only the semantic correctness of\nlarge-scale patches (low-frequency information) but also the precise\nlocalization of boundaries between patches (high-frequency information).\nHowever, most existing approaches rely heavily on discriminative learning,\nwhich excels at capturing low-frequency features, while overlooking its\ninherent limitations in learning high-frequency features for semantic\nsegmentation. Recent studies have revealed that diffusion generative models\nexcel at generating high-frequency details. Our theoretical analysis confirms\nthat the diffusion denoising process significantly enhances the model's ability\nto learn high-frequency features; however, we also observe that these models\nexhibit insufficient semantic inference for low-frequency features when guided\nsolely by the original image. Therefore, we integrate the strengths of both\ndiscriminative and generative learning, proposing the Integration of\nDiscriminative and diffusion-based Generative learning for Boundary Refinement\n(IDGBR) framework. The framework first generates a coarse segmentation map\nusing a discriminative backbone model. This map and the original image are fed\ninto a conditioning guidance network to jointly learn a guidance representation\nsubsequently leveraged by an iterative denoising diffusion process refining the\ncoarse segmentation. Extensive experiments across five remote sensing semantic\nsegmentation datasets (binary and multi-class segmentation) confirm our\nframework's capability of consistent boundary refinement for coarse results\nfrom diverse discriminative architectures. The source code will be available at\nhttps://github.com/KeyanHu-git/IDGBR.", "comment": "20 pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.01573v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01573v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "判别式和扩散式生成学习融合的馈赠：边界细化遥感语义分割", "tldr": "本文提出了IDGBR框架，融合判别式和扩散式生成学习，以解决遥感语义分割中的边界细化问题。该框架首先生成粗分割图，然后利用扩散去噪过程进行迭代细化。在多个数据集上的实验验证了其对粗分割结果进行一致边界细化的能力。", "motivation": "遥感语义分割模型需要同时确保大尺度区域的语义正确性（低频信息）和边界的精确局部化（高频信息）。然而，现有判别式学习方法虽然擅长捕获低频特征，但在学习高频特征方面存在固有局限性。扩散生成模型擅长生成高频细节，但单独使用时对低频特征的语义推理能力不足。", "method": "本文提出了IDGBR（Integration of Discriminative and diffusion-based Generative learning for Boundary Refinement）框架。该框架首先使用判别式骨干模型生成粗分割图。然后，将此粗分割图和原始图像输入到一个条件引导网络，共同学习一个引导表示。最后，该引导表示被一个迭代去噪扩散过程利用，以细化粗分割图的边界。", "result": "在五个遥感语义分割数据集（包括二分类和多分类分割）上进行的广泛实验证实，所提出的IDGBR框架能够对来自不同判别式架构的粗分割结果进行一致的边界细化。", "conclusion": "通过整合判别式学习和扩散生成学习的优势，IDGBR框架有效解决了遥感语义分割中边界细化的问题，提高了分割结果的精度和边界定位能力。", "translation": "遥感语义分割必须解决图像中地面物体是什么以及它们位于何处的问题。因此，分割模型不仅要确保大尺度补丁（低频信息）的语义正确性，还要确保补丁之间边界（高频信息）的精确局部化。然而，大多数现有方法严重依赖判别式学习，该方法擅长捕获低频特征，却忽视了其在学习语义分割高频特征方面的固有局限性。最近的研究表明，扩散生成模型擅长生成高频细节。我们的理论分析证实，扩散去噪过程显著增强了模型学习高频特征的能力；但是，我们也观察到，当仅由原始图像引导时，这些模型对低频特征的语义推理能力不足。因此，我们整合了判别式学习和生成学习的优点，提出了用于边界细化的判别式和扩散式生成学习融合（IDGBR）框架。该框架首先使用判别式骨干模型生成粗分割图。该图和原始图像被输入到条件引导网络中，共同学习一个引导表示，随后通过迭代去噪扩散过程来细化粗分割。在五个遥感语义分割数据集（二分类和多分类分割）上的广泛实验证实了我们的框架能够对来自不同判别式架构的粗结果进行一致的边界细化。源代码将发布在https://github.com/KeyanHu-git/IDGBR。", "summary": "本文提出IDGBR框架，旨在解决遥感语义分割中边界细化问题。该框架结合了判别式学习在低频信息捕获上的优势和扩散生成模型在高频细节生成上的能力。IDGBR首先通过判别式模型生成粗分割图，然后利用该图和原始图像通过条件引导网络学习引导表示，最后通过迭代去噪扩散过程对粗分割进行边界细化。实验证明，该方法在多个遥感数据集上对不同判别式架构的粗分割结果均能实现一致的边界细化。", "keywords": "遥感语义分割, 边界细化, 判别式学习, 扩散模型, 生成学习", "comments": "该论文的创新点在于将判别式学习和扩散生成模型巧妙地结合起来，以解决遥感语义分割中高频边界细节难以精确捕获的问题。通过利用扩散模型的去噪能力来细化判别式模型生成的粗分割，有效弥补了传统判别式方法在高频特征学习上的不足，为高精度语义分割提供了新的思路。"}}
{"id": "2507.01271", "title": "PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning", "authors": ["Tatsuki Kawakami", "Kazuki Egashira", "Atsuyuki Miyai", "Go Irie", "Kiyoharu Aizawa"], "summary": "In recent years, unlearning techniques, which are methods for inducing a\nmodel to \"forget\" previously learned information, have attracted attention as a\nway to address privacy and copyright concerns in large language models (LLMs)\nand large multimodal models (LMMs). While several unlearning benchmarks have\nbeen established for LLMs, a practical evaluation framework for unlearning in\nLMMs has been less explored. Specifically, existing unlearning benchmark for\nLMMs considers only scenarios in which the model is required to unlearn\nfine-tuned knowledge through a single unlearning operation. In this study, we\nintroduce PULSE protocol for realistic unlearning scenarios for LMMs by\nintroducing two critical perspectives: (i) Pre-trained knowledge Unlearning for\nanalyzing the effect across different knowledge acquisition phases and (ii)\nLong-term Sustainability Evaluation to address sequential requests. We then\nevaluate existing unlearning methods along these dimensions. Our results reveal\nthat, although some techniques can successfully unlearn knowledge acquired\nthrough fine-tuning, they struggle to eliminate information learned during\npre-training. Moreover, methods that effectively unlearn a batch of target data\nin a single operation exhibit substantial performance degradation when the same\ndata are split and unlearned sequentially.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01271v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01271v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "PULSE：大型多模态模型遗忘的实用评估场景", "tldr": "该论文引入了PULSE协议，这是一个用于评估大型多模态模型（LMM）遗忘的新框架，考虑了预训练知识和长期顺序遗忘场景。研究发现，现有方法难以消除预训练知识，并且在处理顺序遗忘请求时性能显著下降。", "motivation": "现有的大型多模态模型（LMM）遗忘基准评估框架有限，仅考虑通过单一操作遗忘微调知识的场景。为了解决LMM中隐私和版权问题，需要一个更实用的评估框架来处理预训练知识的遗忘和顺序遗忘请求。", "method": "本研究提出了PULSE协议，通过引入两个关键视角来评估LMM的遗忘能力：(i) 预训练知识遗忘，用于分析跨不同知识获取阶段的影响；(ii) 长期可持续性评估，以处理顺序请求。研究人员随后利用这些维度评估了现有的遗忘方法。", "result": "研究结果表明，尽管一些遗忘技术能够成功遗忘通过微调获得的知识，但它们难以消除在预训练期间学习到的信息。此外，在单一操作中有效遗忘一批目标数据的方法，当相同数据被分割并顺序遗忘时，表现出显著的性能下降。", "conclusion": "当前的LMM遗忘方法不足以应对实际场景，特别是在遗忘预训练知识和在顺序遗忘操作中保持性能方面，这突显了开发更稳健方法的必要性。", "translation": "近年来，遗忘技术作为解决大型语言模型（LLM）和大型多模态模型（LMM）中隐私和版权问题的方法，通过使模型“遗忘”之前学习的信息而受到关注。虽然LLM已经建立了一些遗忘基准，但LMM中遗忘的实用评估框架探索较少。具体来说，LMM现有的遗忘基准只考虑模型通过单一遗忘操作来遗忘微调知识的场景。在本研究中，我们引入了PULSE协议，通过引入两个关键视角来应对LMM的现实遗忘场景：（i）预训练知识遗忘，用于分析跨不同知识获取阶段的影响，以及（ii）长期可持续性评估，以处理顺序请求。然后，我们沿着这些维度评估了现有的遗忘方法。我们的结果表明，尽管一些技术可以成功地遗忘通过微调获得的知识，但它们难以消除在预训练期间学习到的信息。此外，在单一操作中有效遗忘一批目标数据的方法在相同数据被分割并顺序遗忘时表现出显著的性能下降。", "summary": "本文提出PULSE，一种用于评估大型多模态模型（LMM）遗忘能力的新协议。与以往仅考虑微调知识的单次遗忘操作的基准不同，PULSE引入了两个关键维度：预训练知识遗忘和通过顺序遗忘请求评估长期可持续性。研究使用PULSE评估了现有遗忘方法，结果显示，尽管一些方法能成功遗忘微调知识，但它们在处理预训练信息时表现不佳，并且在数据被顺序而非批量遗忘时性能显著下降。", "keywords": "大型多模态模型, 遗忘, 评估协议, 预训练知识, 顺序遗忘", "comments": "该论文通过引入更实际的场景来评估大型多模态模型（LMM）的遗忘能力，弥补了当前评估框架的不足。特别关注预训练知识和顺序遗忘，揭示了现有方法在实际应用中的局限性，为未来更鲁棒的遗忘技术研究指明了方向。这对于解决大型模型中的数据隐私和知识产权问题具有重要意义。"}}
{"id": "2507.01586", "title": "SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation", "authors": ["Bryan Constantine Sadihin", "Michael Hua Wang", "Shei Pern Chua", "Hang Su"], "summary": "The production of high-quality 2D animation is highly labor-intensive\nprocess, as animators are currently required to draw and color a large number\nof frames by hand. We present SketchColour, the first sketch-to-colour pipeline\nfor 2D animation built on a diffusion transformer (DiT) backbone. By replacing\nthe conventional U-Net denoiser with a DiT-style architecture and injecting\nsketch information via lightweight channel-concatenation adapters accompanied\nwith LoRA finetuning, our method natively integrates conditioning without the\nparameter and memory bloat of a duplicated ControlNet, greatly reducing\nparameter count and GPU memory usage. Evaluated on the SAKUGA dataset,\nSketchColour outperforms previous state-of-the-art video colourization methods\nacross all metrics, despite using only half the training data of competing\nmodels. Our approach produces temporally coherent animations with minimal\nartifacts such as colour bleeding or object deformation. Our code is available\nat: https://bconstantine.github.io/SketchColour .", "comment": "Project page and code: https://bconstantine.github.io/SketchColour", "pdf_url": "http://arxiv.org/pdf/2507.01586v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01586v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "SketchColour：基于通道拼接引导的DiT二维动画线稿上色流程", "tldr": "SketchColour是一个基于DiT的线稿上色AI，通过轻量级适配器和LoRA微调，显著减少了参数和内存，并在2D动画上色方面超越了现有最佳方法。", "motivation": "2D动画制作中的上色环节高度依赖人工，耗时耗力，急需自动化解决方案。", "method": "本文提出了SketchColour，一个基于扩散Transformer (DiT) 主干的线稿上色流程。该方法用DiT架构取代了传统的U-Net去噪器，并通过轻量级通道拼接适配器结合LoRA微调来注入线稿信息，从而在不增加ControlNet类模型参数和内存负担的情况下实现高效的条件化。", "result": "在SAKUGA数据集上，SketchColour在所有指标上均优于现有的最先进视频上色方法，尽管只使用了竞争模型一半的训练数据。该方法能生成时间连贯、伪影（如颜色溢出或物体变形）极小的动画，并显著减少了参数数量和GPU内存使用。", "conclusion": "SketchColour通过其创新的DiT架构和轻量级条件化方法，为2D动画线稿上色提供了一个高效且高质量的解决方案，显著优于现有技术并优化了资源使用，有望大幅提升2D动画制作效率。", "translation": "高质量二维动画的制作是一个高度劳动密集型的过程，因为动画师目前需要手工绘制和上色大量的帧。我们提出了SketchColour，这是第一个基于扩散Transformer (DiT) 主干的二维动画线稿上色流程。通过用DiT风格的架构取代传统的U-Net去噪器，并结合轻量级通道拼接适配器以及LoRA微调来注入线稿信息，我们的方法原生集成了条件化，而没有复制ControlNet带来的参数和内存膨胀，极大地减少了参数数量和GPU内存使用。在SAKUGA数据集上进行评估，尽管只使用了竞争模型一半的训练数据，SketchColour在所有指标上都优于以前最先进的视频上色方法。我们的方法生成的时间连贯的动画具有最小的伪影，例如颜色溢出或物体变形。我们的代码可在此处获取：https://bconstantine.github.io/SketchColour。", "summary": "SketchColour是一个针对2D动画线稿上色的创新AI流程，它利用扩散Transformer (DiT) 代替传统U-Net，并通过轻量级通道拼接适配器和LoRA微调高效地整合线稿条件信息。该方法显著减少了模型参数和GPU内存占用，并在SAKUGA数据集上以更少的数据量超越了现有最先进的视频上色技术，生成了时间连贯且伪影极少的动画。", "keywords": "2D动画上色, 扩散Transformer, 线稿上色, LoRA, 视频着色", "comments": "该论文的创新点在于首次将DiT架构应用于2D动画的线稿上色任务，并通过轻量级的通道拼接适配器和LoRA微调实现了高效的条件化，有效避免了传统ControlNet方法的参数和内存开销。其在性能和资源效率上的提升，对2D动画制作流程的自动化和优化具有重要意义。"}}
{"id": "2507.01313", "title": "Neural Hamiltonian Operator", "authors": ["Qian Qi"], "summary": "Stochastic control problems in high dimensions are notoriously difficult to\nsolve due to the curse of dimensionality. An alternative to traditional dynamic\nprogramming is Pontryagin's Maximum Principle (PMP), which recasts the problem\nas a system of Forward-Backward Stochastic Differential Equations (FBSDEs). In\nthis paper, we introduce a formal framework for solving such problems with deep\nlearning by defining a \\textbf{Neural Hamiltonian Operator (NHO)}. This\noperator parameterizes the coupled FBSDE dynamics via neural networks that\nrepresent the feedback control and an ansatz for the value function's spatial\ngradient. We show how the optimal NHO can be found by training the underlying\nnetworks to enforce the consistency conditions dictated by the PMP. By adopting\nthis operator-theoretic view, we situate the deep FBSDE method within the\nrigorous language of statistical inference, framing it as a problem of learning\nan unknown operator from simulated data. This perspective allows us to prove\nthe universal approximation capabilities of NHOs under general martingale\ndrivers and provides a clear lens for analyzing the significant optimization\nchallenges inherent to this class of models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01313v1", "categories": ["cs.LG", "cs.AI", "math.DS", "math.OC"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01313v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "神经哈密顿算子", "tldr": "本文引入了神经哈密顿算子（NHO），这是一个基于深度学习的框架，用于解决高维随机控制问题中的前向-后向随机微分方程（FBSDEs），并证明了其普适逼近能力。", "motivation": "高维随机控制问题因“维度诅咒”而难以解决。传统动态规划方法受限，而庞特里亚金最大值原理（PMP）将问题转化为前向-后向随机微分方程（FBSDEs），但解决这些方程仍具挑战性。", "method": "本文引入了神经哈密顿算子（NHO），这是一个利用深度学习解决随机控制问题的形式化框架。NHO通过神经网络参数化耦合的FBSDE动力学，这些网络代表反馈控制和价值函数空间梯度的近似解。通过训练底层网络以强制执行PMP规定的 M一致性条件，可以找到最优的NHO。该方法将深度FBSDE方法置于统计推断的严格语言中，将其视为从模拟数据中学习未知算子的问题。", "result": "本文证明了神经哈密顿算子（NHO）在一般鞅驱动下具有普适逼近能力。这种视角还为分析此类模型固有的显著优化挑战提供了清晰的视角。", "conclusion": "神经哈密顿算子（NHO）提供了一个通过深度学习解决高维随机控制问题的新框架。它将深度FBSDE方法置于统计推断的严格语言中，并证明了其普适逼近能力，同时为分析优化挑战提供了清晰的视角。", "translation": "高维随机控制问题因“维度诅咒”而臭名昭著地难以解决。与传统动态规划方法不同的是，庞特里亚金最大值原理（PMP）将问题重构为前向-后向随机微分方程（FBSDEs）系统。在本文中，我们通过定义一个**神经哈密顿算子（NHO）**，引入了一个用深度学习解决此类问题的形式化框架。该算子通过神经网络参数化耦合的FBSDE动力学，这些神经网络表示反馈控制和价值函数空间梯度的近似解。我们展示了如何通过训练底层网络来强制执行PMP规定的 M一致性条件，从而找到最优的NHO。通过采用这种算子理论的观点，我们将深度FBSDE方法置于统计推断的严格语言中，将其框定为从模拟数据中学习未知算子的问题。这种视角使我们能够证明NHO在一般鞅驱动下具有普适逼近能力，并为分析此类模型固有的显著优化挑战提供了清晰的视角。", "summary": "本文提出了一种名为神经哈密顿算子（NHO）的深度学习框架，用于解决高维随机控制问题中的前向-后向随机微分方程（FBSDEs）。NHO利用神经网络来参数化FBSDE动力学，并通过训练网络以满足庞特里亚金最大值原理（PMP）的一致性条件来找到最优解。该方法将深度FBSDE视为一个统计推断问题，并证明了NHO在一般鞅驱动下的普适逼近能力，同时提供了一个分析模型优化挑战的视角。", "keywords": "神经哈密顿算子, 随机控制, 深度学习, 前向-后向随机微分方程, 普适逼近", "comments": "本文的创新之处在于引入了神经哈密顿算子（NHO）的概念，将高维随机控制问题中的FBSDEs与深度学习相结合。通过将问题重新定义为学习未知算子，并证明NHO的普适逼近能力，该工作为解决“维度诅咒”提供了一个有前景的新途径。此外，其将问题置于统计推断框架下的视角也具有重要意义。"}}
{"id": "2507.01590", "title": "Autonomous AI Surveillance: Multimodal Deep Learning for Cognitive and Behavioral Monitoring", "authors": ["Ameer Hamza", "Zuhaib Hussain But", "Umar Arif", "Samiya", "M. Abdullah Asad", "Muhammad Naeem"], "summary": "This study presents a novel classroom surveillance system that integrates\nmultiple modalities, including drowsiness, tracking of mobile phone usage, and\nface recognition,to assess student attentiveness with enhanced precision.The\nsystem leverages the YOLOv8 model to detect both mobile phone and sleep\nusage,(Ghatge et al., 2024) while facial recognition is achieved through\nLResNet Occ FC body tracking using YOLO and MTCNN.(Durai et al., 2024) These\nmodels work in synergy to provide comprehensive, real-time monitoring, offering\ninsights into student engagement and behavior.(S et al., 2023) The framework is\ntrained on specialized datasets, such as the RMFD dataset for face recognition\nand a Roboflow dataset for mobile phone detection. The extensive evaluation of\nthe system shows promising results. Sleep detection achieves 97. 42% mAP@50,\nface recognition achieves 86. 45% validation accuracy and mobile phone\ndetection reach 85. 89% mAP@50. The system is implemented within a core PHP web\napplication and utilizes ESP32-CAM hardware for seamless data capture.(Neto et\nal., 2024) This integrated approach not only enhances classroom monitoring, but\nalso ensures automatic attendance recording via face recognition as students\nremain seated in the classroom, offering scalability for diverse educational\nenvironments.(Banada,2025)", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01590v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01590v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "自主AI监控：多模态深度学习用于认知与行为监测", "tldr": "一个基于多模态深度学习的自主AI课堂监控系统，用于实时监测学生的注意力，包括困倦、手机使用和人脸识别，并实现自动考勤。", "motivation": "评估学生注意力，增强课堂监控，并实现自动考勤。", "method": "系统整合了困倦检测、手机使用追踪和人脸识别。使用YOLOv8模型检测手机和睡眠，LResNet Occ FC和MTCNN进行人脸识别和人体追踪。在RMFD数据集和Roboflow数据集上训练。通过PHP web应用和ESP32-CAM硬件实现。", "result": "睡眠检测达到97.42% mAP@50，人脸识别验证准确率86.45%，手机检测85.89% mAP@50。系统实现了自动考勤记录。", "conclusion": "该集成系统不仅增强了课堂监控，还通过人脸识别实现了自动考勤，具有可扩展性，适用于不同的教育环境。", "translation": "这项研究提出了一个新颖的课堂监控系统，该系统整合了多种模态，包括困倦、手机使用追踪和人脸识别，以更高的精度评估学生的注意力。该系统利用YOLOv8模型检测手机使用和睡眠（Ghatge 等，2024），而人脸识别通过LResNet Occ FC和YOLO及MTCNN进行身体追踪实现（Durai 等，2024）。这些模型协同工作，提供全面的实时监控，为学生参与度和行为提供洞察（S 等，2023）。该框架在专门的数据集上进行训练，例如用于人脸识别的RMFD数据集和用于手机检测的Roboflow数据集。对系统进行的广泛评估显示出有希望的结果。睡眠检测达到97.42%的mAP@50，人脸识别达到86.45%的验证准确率，手机检测达到85.89%的mAP@50。该系统在核心PHP网络应用程序中实现，并利用ESP32-CAM硬件实现无缝数据捕获（Neto 等，2024）。这种集成方法不仅增强了课堂监控，还通过人脸识别确保了学生就座时的自动考勤记录，为多样化的教育环境提供了可扩展性（Banada，2025）。", "summary": "本研究提出一种新颖的自主AI课堂监控系统，利用多模态深度学习技术，包括困倦检测、手机使用追踪和人脸识别，以实时评估学生注意力。该系统结合YOLOv8、LResNet Occ FC和MTCNN模型，并在特定数据集上训练。实验结果显示在睡眠检测、人脸识别和手机检测方面表现良好。系统通过PHP Web应用和ESP32-CAM实现，并能自动记录考勤，为教育环境提供可扩展的监控解决方案。", "keywords": "课堂监控, 多模态深度学习, 注意力评估, 人脸识别, YOLOv8", "comments": "该论文提出了一种创新的多模态AI监控系统，将多种行为和认知指标集成，实现了更全面的学生注意力评估和自动考勤。其创新点在于整合了YOLOv8、LResNet Occ FC和MTCNN等多个先进深度学习模型，并通过PHP和ESP32-CAM实现了实用部署。然而，关于隐私问题和伦理考量在摘要中未提及，这可能是此类系统在实际应用中需要关注的重要限制。"}}
{"id": "2507.01603", "title": "DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale- and Geometry-Consistent Video Depth Estimation", "authors": ["Yue-Jiang Dong", "Wang Zhao", "Jiale Xu", "Ying Shan", "Song-Hai Zhang"], "summary": "Diffusion-based video depth estimation methods have achieved remarkable\nsuccess with strong generalization ability. However, predicting depth for long\nvideos remains challenging. Existing methods typically split videos into\noverlapping sliding windows, leading to accumulated scale discrepancies across\ndifferent windows, particularly as the number of windows increases.\nAdditionally, these methods rely solely on 2D diffusion priors, overlooking the\ninherent 3D geometric structure of video depths, which results in geometrically\ninconsistent predictions. In this paper, we propose DepthSync, a novel,\ntraining-free framework using diffusion guidance to achieve scale- and\ngeometry-consistent depth predictions for long videos. Specifically, we\nintroduce scale guidance to synchronize the depth scale across windows and\ngeometry guidance to enforce geometric alignment within windows based on the\ninherent 3D constraints in video depths. These two terms work synergistically,\nsteering the denoising process toward consistent depth predictions. Experiments\non various datasets validate the effectiveness of our method in producing depth\nestimates with improved scale and geometry consistency, particularly for long\nvideos.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.01603v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01603v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "DepthSync: 基于扩散引导的深度同步，用于尺度和几何一致的视频深度估计", "tldr": "现有基于扩散的视频深度估计方法在处理长视频时存在尺度和几何不一致问题；DepthSync提出了一种无需训练的框架，通过尺度和几何引导来解决这些问题。", "motivation": "现有基于扩散的视频深度估计方法在处理长视频时面临挑战，因为它们将视频分割成重叠的滑动窗口，导致累积的尺度差异；此外，这些方法仅依赖2D扩散先验，忽略了视频深度固有的3D几何结构，从而导致几何不一致的预测。", "method": "本文提出了DepthSync，一个新颖的、无需训练的框架，利用扩散引导实现长视频的尺度和几何一致的深度预测。具体来说，引入了尺度引导来同步窗口间的深度尺度，并引入了几何引导来根据视频深度中固有的3D约束强制执行窗口内的几何对齐。这两个项协同工作，引导去噪过程趋向于一致的深度预测。", "result": "在各种数据集上的实验验证了DepthSync方法在生成具有改进的尺度和几何一致性的深度估计方面的有效性，特别是对于长视频。", "conclusion": "DepthSync通过引入尺度和几何引导的扩散指导，成功地解决了长视频深度估计中存在的尺度和几何不一致性问题，提供了一种有效的、无需训练的解决方案。", "translation": "基于扩散的视频深度估计方法取得了显著成功，具有强大的泛化能力。然而，预测长视频的深度仍然具有挑战性。现有方法通常将视频分割成重叠的滑动窗口，导致不同窗口之间累积的尺度差异，特别是随着窗口数量的增加。此外，这些方法仅依赖于2D扩散先验，忽略了视频深度固有的3D几何结构，从而导致几何不一致的预测。在本文中，我们提出了DepthSync，一个新颖的、无需训练的框架，利用扩散引导实现长视频的尺度和几何一致的深度预测。具体来说，我们引入了尺度引导来同步窗口间的深度尺度，并引入了几何引导，根据视频深度中固有的3D约束，强制执行窗口内的几何对齐。这两个项协同工作，引导去噪过程趋向于一致的深度预测。在各种数据集上的实验验证了我们方法在生成具有改进的尺度和几何一致性的深度估计方面的有效性，特别是对于长视频。", "summary": "DepthSync旨在解决当前基于扩散的视频深度估计算法在处理长视频时存在的尺度差异和几何不一致问题。该方法提出了一种新颖的、无需训练的框架，通过引入尺度引导和几何引导的扩散指导，利用3D几何约束和跨窗口的尺度同步，确保生成一致的深度预测。实验结果证实了其在提高长视频深度估计一致性方面的有效性。", "keywords": "视频深度估计, 扩散引导, 尺度一致性, 几何一致性, 长视频", "comments": "该论文的创新之处在于其无需训练的特性，以及引入了专门的引导项（尺度引导和几何引导）来解决长视频深度估计中关键的一致性问题，并利用了3D结构信息。这为该领域的一个已知问题提供了一个实用的解决方案。"}}
{"id": "2507.01327", "title": "Reasoner for Real-World Event Detection: Scaling Reinforcement Learning via Adaptive Perplexity-Aware Sampling Strategy", "authors": ["Xiaoyun Zhang", "Jingqing Ruan", "Xing Ma", "Yawen Zhu", "Jiansong Chen", "Ke Zeng", "Xunliang Cai"], "summary": "Detecting abnormal events in real-world customer service dialogues is highly\nchallenging due to the complexity of business data and the dynamic nature of\ncustomer interactions. Moreover, models must demonstrate strong out-of-domain\n(OOD) generalization to enable rapid adaptation across different business\nscenarios and maximize commercial value. In this work, we propose a novel\nAdaptive Perplexity-Aware Reinforcement Learning (APARL) framework that\nleverages the advanced reasoning capabilities of large language models for\nabnormal event detection. APARL introduces a dual-loop dynamic curriculum\nlearning architecture, enabling the model to progressively focus on more\nchallenging samples as its proficiency increases. This design effectively\naddresses performance bottlenecks and significantly enhances OOD\ntransferability. Extensive evaluations on food delivery dialogue tasks show\nthat our model achieves significantly enhanced adaptability and robustness,\nattaining the highest F1 score with an average improvement of 17.19\\%, and an\naverage improvement of 9.59\\% in OOD transfer tests. This method provides a\nsuperior solution for industrial deployment of anomaly detection models,\ncontributing to improved operational efficiency and commercial benefits.", "comment": "15 pages, 6 figures, submitted to EMNLP", "pdf_url": "http://arxiv.org/pdf/2507.01327v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01327v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "真实世界事件检测的推理器：通过自适应困惑度感知采样策略扩展强化学习", "tldr": "本研究提出了一种名为APARL的新型强化学习框架，用于在客户服务对话中检测异常事件。APARL利用大语言模型并引入双循环动态课程学习架构，显著提高了模型在复杂业务数据和动态交互中的域外泛化能力，并在食物配送对话任务中取得了显著的F1分数和域外迁移测试性能提升。", "motivation": "在真实世界客户服务对话中检测异常事件极具挑战性，原因在于业务数据的复杂性和客户交互的动态性。此外，模型需要强大的域外（OOD）泛化能力，以实现跨不同业务场景的快速适应并最大化商业价值。", "method": "我们提出了一种新颖的自适应困惑度感知强化学习（APARL）框架，该框架利用大型语言模型的先进推理能力进行异常事件检测。APARL引入了双循环动态课程学习架构，使模型能够随着熟练度的提高逐步关注更具挑战性的样本。这种设计有效地解决了性能瓶颈并显著增强了域外迁移能力。", "result": "在食物配送对话任务上的广泛评估表明，我们的模型显著增强了适应性和鲁棒性，F1分数达到最高，平均提高了17.19%，在域外迁移测试中平均提高了9.59%。", "conclusion": "该方法为异常检测模型的工业部署提供了卓越的解决方案，有助于提高运营效率和商业效益。", "translation": "在真实世界客户服务对话中检测异常事件极具挑战性，原因在于业务数据的复杂性和客户交互的动态性。此外，模型必须展示强大的域外（OOD）泛化能力，以实现跨不同业务场景的快速适应并最大化商业价值。在这项工作中，我们提出了一种新颖的自适应困惑度感知强化学习（APARL）框架，该框架利用大型语言模型的先进推理能力进行异常事件检测。APARL引入了双循环动态课程学习架构，使模型能够随着熟练度的提高逐步关注更具挑战性的样本。这种设计有效地解决了性能瓶颈并显著增强了域外迁移能力。在食物配送对话任务上的广泛评估表明，我们的模型显著增强了适应性和鲁棒性，F1分数达到最高，平均提高了17.19%，在域外迁移测试中平均提高了9.59%。该方法为异常检测模型的工业部署提供了卓越的解决方案，有助于提高运营效率和商业效益。", "summary": "本研究针对真实世界客户服务对话中的异常事件检测挑战，提出了一种名为自适应困惑度感知强化学习（APARL）的新型框架。该框架利用大型语言模型的推理能力，并引入双循环动态课程学习架构，使模型能逐步适应更复杂样本，从而有效提升性能并增强域外泛化能力。实验结果显示，APARL在食物配送对话任务中表现出显著的适应性和鲁棒性，F1分数和域外迁移测试性能均有大幅提升，为工业级异常检测模型提供了优越的解决方案。", "keywords": "异常事件检测, 强化学习, 大型语言模型, 域外泛化, 课程学习", "comments": "这项研究的创新之处在于结合了大型语言模型的推理能力与自适应困惑度感知强化学习（APARL）框架，并引入了双循环动态课程学习架构。这种方法有效地解决了真实世界异常事件检测中数据复杂性和域外泛化能力差的挑战，显著提升了模型在工业应用中的鲁棒性和适应性。其在F1分数和域外迁移测试中的显著性能提升，证明了该方法在提升运营效率和商业效益方面的巨大潜力。"}}
{"id": "2507.01354", "title": "Efficient Kilometer-Scale Precipitation Downscaling with Conditional Wavelet Diffusion", "authors": ["Chugang Yi", "Minghan Yu", "Weikang Qian", "Yixin Wen", "Haizhao Yang"], "summary": "Effective hydrological modeling and extreme weather analysis demand\nprecipitation data at a kilometer-scale resolution, which is significantly\nfiner than the 10 km scale offered by standard global products like IMERG. To\naddress this, we propose the Wavelet Diffusion Model (WDM), a generative\nframework that achieves 10x spatial super-resolution (downscaling to 1 km) and\ndelivers a 9x inference speedup over pixel-based diffusion models. WDM is a\nconditional diffusion model that learns the learns the complex structure of\nprecipitation from MRMS radar data directly in the wavelet domain. By focusing\non high-frequency wavelet coefficients, it generates exceptionally realistic\nand detailed 1-km precipitation fields. This wavelet-based approach produces\nvisually superior results with fewer artifacts than pixel-space models, and\ndelivers a significant gains in sampling efficiency. Our results demonstrate\nthat WDM provides a robust solution to the dual challenges of accuracy and\nspeed in geoscience super-resolution, paving the way for more reliable\nhydrological forecasts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01354v1", "categories": ["cs.LG", "physics.ao-ph", "86A10 (Primary) 86A22, 68U10 (Secondary)", "J.2; I.4.4"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01354v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于条件小波扩散的有效公里级降水降尺度", "tldr": "该研究提出了一种名为WDM的生成式模型，通过在小波域中处理降水数据，实现了公里级降水数据的有效降尺度，并显著提高了推理速度和图像质量。", "motivation": "现有的全球降水产品（如IMERG）分辨率为10公里，无法满足水文建模和极端天气分析对公里级分辨率降水数据的需求。", "method": "该研究提出了小波扩散模型（WDM），这是一种条件扩散模型，直接在小波域中从MRMS雷达数据学习降水的复杂结构。通过关注高频小波系数，WDM能够生成逼真且详细的1公里降水场。", "result": "WDM实现了10倍的空间超分辨率（降尺度到1公里），并且比基于像素的扩散模型推理速度快9倍。与像素空间模型相比，小波方法生成的结果视觉效果更佳，伪影更少，采样效率显著提高。", "conclusion": "WDM为地球科学超分辨率领域的准确性和速度双重挑战提供了稳健的解决方案，为更可靠的水文预报铺平了道路。", "translation": "有效的 hydrological 建模和极端天气分析需要公里级分辨率的降水数据，这比 IMERG 等标准全球产品提供的 10 公里尺度精细得多。为了解决这个问题，我们提出了小波扩散模型（WDM），这是一种生成框架，实现了 10 倍空间超分辨率（降尺度到 1 公里），并且比基于像素的扩散模型推理速度快 9 倍。WDM 是一种条件扩散模型，直接在小波域中从 MRMS 雷达数据学习降水的复杂结构。通过关注高频小波系数，它生成了异常逼真和详细的 1 公里降水场。这种基于小波的方法比像素空间模型产生视觉上更优越的结果，伪影更少，并且采样效率显著提高。我们的结果表明，WDM 为地球科学超分辨率领域的准确性和速度双重挑战提供了稳健的解决方案，为更可靠的水文预报铺平了道路。", "summary": "本研究提出了一种名为小波扩散模型（WDM）的生成式框架，旨在解决现有全球降水产品分辨率不足的问题。WDM是一种条件扩散模型，通过在小波域直接学习降水数据，实现了将10公里分辨率数据降尺度到1公里，并显著提升了推理速度（9倍加速）。实验结果表明，WDM生成的1公里降水场更加逼真，伪影更少，为水文预报提供了更可靠的数据基础。", "keywords": "降水降尺度, 条件扩散模型, 小波变换, 超分辨率, 水文建模", "comments": "该论文的创新点在于将条件扩散模型应用于小波域进行降水数据降尺度，有效地结合了小波变换在处理高频信息方面的优势与扩散模型强大的生成能力。这种方法不仅显著提高了空间分辨率，还大幅提升了推理速度和图像质量，为地球科学领域的超分辨率问题提供了新的高效解决方案。其对水文建模和极端天气分析具有重要意义。"}}
{"id": "2507.01381", "title": "Distributional Soft Actor-Critic with Diffusion Policy", "authors": ["Tong Liu", "Yinuo Wang", "Xujie Song", "Wenjun Zou", "Liangfa Chen", "Likun Wang", "Bin Shuai", "Jingliang Duan", "Shengbo Eben Li"], "summary": "Reinforcement learning has been proven to be highly effective in handling\ncomplex control tasks. Traditional methods typically use unimodal\ndistributions, such as Gaussian distributions, to model the output of value\ndistributions. However, unimodal distribution often and easily causes bias in\nvalue function estimation, leading to poor algorithm performance. This paper\nproposes a distributional reinforcement learning algorithm called DSAC-D\n(Distributed Soft Actor Critic with Diffusion Policy) to address the challenges\nof estimating bias in value functions and obtaining multimodal policy\nrepresentations. A multimodal distributional policy iteration framework that\ncan converge to the optimal policy was established by introducing policy\nentropy and value distribution function. A diffusion value network that can\naccurately characterize the distribution of multi peaks was constructed by\ngenerating a set of reward samples through reverse sampling using a diffusion\nmodel. Based on this, a distributional reinforcement learning algorithm with\ndual diffusion of the value network and the policy network was derived. MuJoCo\ntesting tasks demonstrate that the proposed algorithm not only learns\nmultimodal policy, but also achieves state-of-the-art (SOTA) performance in all\n9 control tasks, with significant suppression of estimation bias and total\naverage return improvement of over 10\\% compared to existing mainstream\nalgorithms. The results of real vehicle testing show that DSAC-D can accurately\ncharacterize the multimodal distribution of different driving styles, and the\ndiffusion policy network can characterize multimodal trajectories.", "comment": "Accepted IEEE ITSC 2025", "pdf_url": "http://arxiv.org/pdf/2507.01381v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01381v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "带扩散策略的分布软Actor-Critic", "tldr": "本文提出DSAC-D算法，通过引入扩散模型解决传统RL中价值函数估计偏差和多模态策略表示问题，在MuJoCo和真实车辆任务中均达到SOTA性能并有效抑制偏差。", "motivation": "传统的强化学习方法通常使用单峰分布（如高斯分布）来建模价值分布的输出，但这容易导致价值函数估计偏差，从而降低算法性能。", "method": "本文提出了DSAC-D（Distributed Soft Actor Critic with Diffusion Policy）分布强化学习算法。该算法通过引入策略熵和价值分布函数，建立了可收敛到最优策略的多模态分布策略迭代框架。它通过使用扩散模型进行逆向采样生成一组奖励样本，构建了一个能够准确表征多峰分布的扩散价值网络。在此基础上，推导出了一个价值网络和策略网络双重扩散的分布强化学习算法。", "result": "在MuJoCo测试任务中，DSAC-D不仅能够学习多模态策略，而且在所有9个控制任务中均达到了最先进（SOTA）的性能，显著抑制了估计偏差，与现有主流算法相比，总平均回报提高了10%以上。真实车辆测试结果表明，DSAC-D能够准确表征不同驾驶风格的多模态分布，并且扩散策略网络能够表征多模态轨迹。", "conclusion": "DSAC-D算法通过引入扩散模型，有效解决了传统强化学习中价值函数估计偏差和获取多模态策略表示的挑战，并在多个复杂控制任务中展现出卓越的性能和鲁棒性。", "translation": "强化学习已被证明在处理复杂控制任务方面非常有效。传统方法通常使用单峰分布，例如高斯分布，来建模价值分布的输出。然而，单峰分布常常容易导致价值函数估计偏差，从而导致算法性能不佳。本文提出了一种名为DSAC-D（Distributed Soft Actor Critic with Diffusion Policy）的分布强化学习算法，以解决价值函数估计偏差和获取多模态策略表示的挑战。通过引入策略熵和价值分布函数，建立了可以收敛到最优策略的多模态分布策略迭代框架。通过使用扩散模型进行逆向采样生成一组奖励样本，构建了一个可以准确表征多峰分布的扩散价值网络。在此基础上，推导出了一个价值网络和策略网络双重扩散的分布强化学习算法。MuJoCo测试任务表明，所提出的算法不仅能够学习多模态策略，而且在所有9个控制任务中均达到了最先进（SOTA）的性能，显著抑制了估计偏差，与现有主流算法相比，总平均回报提高了10%以上。真实车辆测试结果表明，DSAC-D能够准确表征不同驾驶风格的多模态分布，并且扩散策略网络能够表征多模态轨迹。", "summary": "本文提出了一种名为DSAC-D的分布强化学习算法，旨在解决传统方法中价值函数估计偏差和多模态策略表示不足的问题。DSAC-D通过引入策略熵、价值分布函数以及基于扩散模型的扩散价值网络和双重扩散策略网络，构建了一个能够学习多模态策略并有效抑制估计偏差的框架。实验结果表明，该算法在MuJoCo控制任务中实现了最先进的性能，并在真实车辆测试中成功表征了多模态驾驶风格和轨迹。", "keywords": "强化学习, 分布式强化学习, 软Actor-Critic, 扩散策略, 多模态", "comments": "该论文的创新点在于将扩散模型引入到分布强化学习中，以解决价值函数估计的偏差问题并更好地捕获多模态策略。这种结合提供了一种新颖的方法来处理复杂决策问题中的不确定性和多样性，并在多个基准任务上取得了显著的性能提升，尤其是在真实世界的应用（如自动驾驶）中展现出潜力。"}}
{"id": "2507.01630", "title": "Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss", "authors": ["Yuxiao Wang", "Yu Lei", "Zhenao Wei", "Weiying Xue", "Xinyu Jiang", "Nan Zhuang", "Qi Liu"], "summary": "The task of Human-Object conTact (HOT) detection involves identifying the\nspecific areas of the human body that are touching objects. Nevertheless,\ncurrent models are restricted to just one type of image, often leading to too\nmuch segmentation in areas with little interaction, and struggling to maintain\ncategory consistency within specific regions. To tackle this issue, a HOT\nframework, termed \\textbf{P3HOT}, is proposed, which blends \\textbf{P}rompt\nguidance and human \\textbf{P}roximal \\textbf{P}erception. To begin with, we\nutilize a semantic-driven prompt mechanism to direct the network's attention\ntowards the relevant regions based on the correlation between image and text.\nThen a human proximal perception mechanism is employed to dynamically perceive\nkey depth range around the human, using learnable parameters to effectively\neliminate regions where interactions are not expected. Calculating depth\nresolves the uncertainty of the overlap between humans and objects in a 2D\nperspective, providing a quasi-3D viewpoint. Moreover, a Regional Joint Loss\n(RJLoss) has been created as a new loss to inhibit abnormal categories in the\nsame area. A new evaluation metric called ``AD-Acc.'' is introduced to address\nthe shortcomings of existing methods in addressing negative samples.\nComprehensive experimental results demonstrate that our approach achieves\nstate-of-the-art performance in four metrics across two benchmark datasets.\nSpecifically, our model achieves an improvement of \\textbf{0.7}$\\uparrow$,\n\\textbf{2.0}$\\uparrow$, \\textbf{1.6}$\\uparrow$, and \\textbf{11.0}$\\uparrow$ in\nSC-Acc., mIoU, wIoU, and AD-Acc. metrics, respectively, on the HOT-Annotated\ndataset. Code is available at https://github.com/YuxiaoWang-AI/P3HOT.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.01630v1", "categories": ["cs.CV", "cs.AI"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01630v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于提示引导和人体近端感知的区域联合损失HOT预测方法", "tldr": "该论文提出了P3HOT，一个结合了提示引导和人体近端感知的HOT检测框架，引入了新的区域联合损失(RJLoss)和评估指标AD-Acc.，并在基准数据集上取得了最先进的性能。", "motivation": "当前的人体-物体接触(HOT)检测模型受限于单一图像类型，常导致非交互区域的过度分割，并且难以在特定区域内保持类别一致性。", "method": "本文提出了P3HOT框架，融合了提示引导和人体近端感知。首先，利用语义驱动的提示机制，根据图像和文本的关联性引导网络关注相关区域。其次，采用人体近端感知机制，通过可学习参数动态感知人体周围的关键深度范围，有效消除非预期交互区域，通过计算深度解决了2D视角下人体和物体重叠的不确定性，提供准3D视角。此外，创建了区域联合损失(RJLoss)作为新的损失函数，以抑制同一区域内的异常类别。为解决现有方法在处理负样本方面的不足，引入了新的评估指标“AD-Acc.”。", "result": "综合实验结果表明，该方法在两个基准数据集上的四个指标中均实现了最先进的性能。具体而言，在HOT-Annotated数据集上，模型在SC-Acc.、mIoU、wIoU和AD-Acc.指标上分别提升了0.7、2.0、1.6和11.0。", "conclusion": "本文提出的P3HOT框架，结合了提示引导和人体近端感知机制，并引入了区域联合损失和新的评估指标，有效解决了现有HOT检测方法的局限性，并在基准数据集上取得了最先进的性能。", "translation": "人体-物体接触(HOT)检测的任务涉及识别与物体接触的人体特定区域。然而，当前模型仅限于一种图像类型，常导致交互较少区域的过度分割，并且难以在特定区域内保持类别一致性。为了解决这个问题，本文提出了一个名为P3HOT的HOT框架，它融合了提示引导和人体近端感知。首先，我们利用语义驱动的提示机制，根据图像和文本之间的相关性引导网络的注意力转向相关区域。然后，采用人体近端感知机制，通过可学习参数动态感知人体周围的关键深度范围，有效消除非预期交互区域。计算深度解决了2D视角下人体和物体重叠的不确定性，提供了准3D视角。此外，本文创建了区域联合损失(RJLoss)作为一种新的损失函数，以抑制同一区域内的异常类别。为了解决现有方法在处理负样本方面的不足，引入了一种名为“AD-Acc.”的新评估指标。综合实验结果表明，我们的方法在两个基准数据集的四个指标上均取得了最先进的性能。具体而言，在HOT-Annotated数据集上，我们的模型在SC-Acc.、mIoU、wIoU和AD-Acc.指标上分别提升了0.7、2.0、1.6和11.0。代码可在https://github.com/YuxiaoWang-AI/P3HOT获取。", "summary": "本论文介绍了P3HOT，一个用于人体-物体接触(HOT)检测的新型框架，旨在解决现有模型在图像类型限制、过度分割和类别一致性方面的不足。P3HOT结合了语义驱动的提示引导和人体近端感知机制，以聚焦相关区域并利用深度信息提供准3D视角。此外，它引入了区域联合损失(RJLoss)来维持区域内类别一致性，并提出了新的评估指标“AD-Acc.”以更好地处理负样本。实验证明，P3HOT在多个基准数据集上实现了最先进的性能。", "keywords": "人体-物体接触, HOT检测, 提示引导, 人体近端感知, 区域联合损失", "comments": "该论文的创新点在于将提示引导与深度感知的人体近端感知相结合，为HOT检测提供了一种从2D输入获取准3D视角的方法，有效解决了现有模型的局限性。引入RJLoss和AD-Acc.指标也针对HOT检测评估中的特定问题提供了解决方案。这种方法显得鲁棒且有效。"}}
{"id": "2507.01389", "title": "Surrogate Modeling via Factorization Machine and Ising Model with Enhanced Higher-Order Interaction Learning", "authors": ["Anbang Wang", "Dunbo Cai", "Yu Zhang", "Yangqing Huang", "Xiangyang Feng", "Zhihong Zhang"], "summary": "Recently, a surrogate model was proposed that employs a factorization machine\nto approximate the underlying input-output mapping of the original system, with\nquantum annealing used to optimize the resulting surrogate function. Inspired\nby this approach, we propose an enhanced surrogate model that incorporates\nadditional slack variables into both the factorization machine and its\nassociated Ising representation thereby unifying what was by design a two-step\nprocess into a single, integrated step. During the training phase, the slack\nvariables are iteratively updated, enabling the model to account for\nhigher-order feature interactions. We apply the proposed method to the task of\npredicting drug combination effects. Experimental results indicate that the\nintroduction of slack variables leads to a notable improvement of performance.\nOur algorithm offers a promising approach for building efficient surrogate\nmodels that exploit potential quantum advantages.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01389v1", "categories": ["cs.LG", "quant-ph"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01389v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "代理建模通过因子分解机和伊辛模型增强高阶交互学习", "tldr": "提出了一种增强型代理模型，通过引入松弛变量将因子分解机和伊辛模型的两步过程统一为一步，从而有效学习高阶特征交互，并在药物组合效应预测中显著提升了性能。", "motivation": "现有的代理模型使用因子分解机和量子退火进行两步优化，效率有待提高，且对高阶特征交互的学习能力有限。", "method": "本文提出了一种增强型代理模型，通过在因子分解机及其伊辛表示中引入额外的松弛变量，将原有的两步过程统一为一个集成步骤。在训练阶段，松弛变量迭代更新，以学习高阶特征交互。", "result": "实验结果表明，引入松弛变量显著提高了模型性能，尤其是在药物组合效应预测任务中。", "conclusion": "该算法为构建利用潜在量子优势的高效代理模型提供了一种有前途的方法。", "translation": "近期，一种代理模型被提出，该模型采用因子分解机来近似原始系统的底层输入-输出映射，并利用量子退火来优化所得的代理函数。受此方法的启发，我们提出了一种增强型代理模型，该模型将额外的松弛变量引入因子分解机及其相关的伊辛表示中，从而将原本设计为两步的过程统一为一个单一的、集成的步骤。在训练阶段，松弛变量迭代更新，使模型能够考虑更高阶的特征交互。我们将所提出的方法应用于预测药物组合效应的任务。实验结果表明，引入松弛变量显著提高了性能。我们的算法为构建利用潜在量子优势的高效代理模型提供了一种有前途的方法。", "summary": "本文提出了一种增强型代理模型，通过在因子分解机和伊辛表示中引入并迭代更新松弛变量，实现了高阶特征交互的学习，并将原有的两步优化过程整合为一步。该方法在药物组合效应预测任务中表现出显著的性能提升，为利用量子优势构建高效代理模型提供了新途径。", "keywords": "代理模型, 因子分解机, 伊辛模型, 高阶交互, 松弛变量", "comments": "这项工作通过引入松弛变量，巧妙地将因子分解机和伊辛模型的两步优化过程整合为一步，并增强了模型学习高阶特征交互的能力，体现了方法上的创新性。其在药物组合预测领域的应用展示了实际价值，并为结合量子计算优势的代理模型发展提供了有益探索。"}}
{"id": "2507.01414", "title": "Decomposing Prediction Mechanisms for In-Context Recall", "authors": ["Sultan Daniels", "Dylan Davis", "Dhruv Gautam", "Wentinn Liao", "Gireeja Ranade", "Anant Sahai"], "summary": "We introduce a new family of toy problems that combine features of\nlinear-regression-style continuous in-context learning (ICL) with discrete\nassociative recall. We pretrain transformer models on sample traces from this\ntoy, specifically symbolically-labeled interleaved state observations from\nrandomly drawn linear deterministic dynamical systems. We study if the\ntransformer models can recall the state of a sequence previously seen in its\ncontext when prompted to do so with the corresponding in-context label. Taking\na closer look at this task, it becomes clear that the model must perform two\nfunctions: (1) identify which system's state should be recalled and apply that\nsystem to its last seen state, and (2) continuing to apply the correct system\nto predict the subsequent states. Training dynamics reveal that the first\ncapability emerges well into a model's training. Surprisingly, the second\ncapability, of continuing the prediction of a resumed sequence, develops much\nearlier.\n  Via out-of-distribution experiments, and a mechanistic analysis on model\nweights via edge pruning, we find that next-token prediction for this toy\nproblem involves at least two separate mechanisms. One mechanism uses the\ndiscrete symbolic labels to do the associative recall required to predict the\nstart of a resumption of a previously seen sequence. The second mechanism,\nwhich is largely agnostic to the discrete symbolic labels, performs a\n\"Bayesian-style\" prediction based on the previous token and the context. These\ntwo mechanisms have different learning dynamics.\n  To confirm that this multi-mechanism (manifesting as separate phase\ntransitions) phenomenon is not just an artifact of our toy setting, we used\nOLMo training checkpoints on an ICL translation task to see a similar\nphenomenon: a decisive gap in the emergence of first-task-token performance vs\nsecond-task-token performance.", "comment": "44 pages, 47 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.01414v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01414v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "分解上下文召回中的预测机制", "tldr": "研究发现，在上下文学习中，模型通过两种独立的机制进行预测：一种用于关联召回，另一种用于基于上下文的预测，且这两种机制的学习动态不同。", "motivation": "理解大型语言模型在上下文学习中如何进行预测，特别是分解其内部机制，以探究不同预测能力的出现时机和方式。", "method": "引入结合线性回归式连续上下文学习和离散关联召回特性的玩具问题。使用Transformer模型预训练随机线性确定性动力系统样本轨迹。通过分布外实验和模型权重边缘剪枝进行机制分析。使用OLMo训练检查点在上下文翻译任务上进行验证。", "result": "模型执行两种功能：(1）识别并应用正确的系统状态进行召回；（2）继续应用正确系统预测后续状态。第二种能力（继续预测）比第一种能力（识别召回）出现得更早。发现两种独立的预测机制：一种使用离散符号标签进行关联召回，另一种主要与离散符号标签无关，基于前一个token和上下文进行“贝叶斯式”预测。这两种机制具有不同的学习动态。在实际的ICL翻译任务中也观察到类似的多机制现象。", "conclusion": "上下文召回中的预测涉及至少两种独立的机制，它们具有不同的学习动态，并且在模型的训练过程中以不同的时间点出现，这表明了LLM内部复杂且分阶段的机制形成。", "translation": "我们引入了一系列新的玩具问题，它结合了线性回归式连续上下文学习（ICL）和离散关联召回的特点。我们用这个玩具问题的样本轨迹预训练Transformer模型，具体来说，是来自随机抽取的线性确定性动力系统的符号标记交错状态观测。我们研究当Transformer模型被提示使用相应的上下文标签时，它是否能召回其上下文中先前看到的序列状态。仔细观察这个任务，很明显模型必须执行两个功能：（1）识别应该召回哪个系统的状态并将其应用于其最后一次看到的状态，以及（2）继续应用正确的系统来预测后续状态。训练动态显示，第一种能力在模型训练后期才出现。令人惊讶的是，第二种能力，即继续预测恢复的序列，发展得要早得多。\n通过分布外实验和通过边缘剪枝对模型权重进行的机制分析，我们发现，对于这个玩具问题，下一个token的预测至少涉及两种独立的机制。一种机制使用离散符号标签进行关联召回，这是预测先前看到序列恢复开始所必需的。第二种机制，在很大程度上与离散符号标签无关，基于前一个token和上下文执行“贝叶斯式”预测。这两种机制具有不同的学习动态。\n为了确认这种多机制（表现为独立相变）现象不仅仅是我们玩具设置的人工产物，我们使用了OLMo训练检查点在一个ICL翻译任务上，看到了类似的现象：第一个任务token性能与第二个任务token性能出现之间存在决定性的差距。", "summary": "本研究引入了一系列结合连续上下文学习和离散关联召回的玩具问题，以探究Transformer模型在上下文召回中的预测机制。通过预训练和机制分析，发现模型在预测过程中涉及至少两种独立的机制：一种是基于离散符号标签的关联召回机制，另一种是基于上下文的“贝叶斯式”预测机制。这两种机制具有不同的学习动态，并且在模型训练的不同阶段出现。通过在实际翻译任务上的验证，证实了这种多机制现象的普遍性。", "keywords": "上下文学习, 预测机制, Transformer模型, 关联召回, 学习动态", "comments": "这项研究通过精心设计的玩具问题和深入的机制分析，揭示了大型语言模型在上下文学习中预测能力的复杂性和分层发展。发现两种独立机制及其不同的学习动态是一个重要的发现，有助于我们更好地理解LLM的内部工作原理。将这种现象推广到实际的翻译任务中，增加了研究结果的普适性。未来的工作可以进一步探索这些机制的相互作用以及如何利用这些发现来改进模型训练和性能。"}}
{"id": "2507.01634", "title": "Depth Anything at Any Condition", "authors": ["Boyuan Sun", "Modi Jin", "Bowen Yin", "Qibin Hou"], "summary": "We present Depth Anything at Any Condition (DepthAnything-AC), a foundation\nmonocular depth estimation (MDE) model capable of handling diverse\nenvironmental conditions. Previous foundation MDE models achieve impressive\nperformance across general scenes but not perform well in complex open-world\nenvironments that involve challenging conditions, such as illumination\nvariations, adverse weather, and sensor-induced distortions. To overcome the\nchallenges of data scarcity and the inability of generating high-quality\npseudo-labels from corrupted images, we propose an unsupervised consistency\nregularization finetuning paradigm that requires only a relatively small amount\nof unlabeled data. Furthermore, we propose the Spatial Distance Constraint to\nexplicitly enforce the model to learn patch-level relative relationships,\nresulting in clearer semantic boundaries and more accurate details.\nExperimental results demonstrate the zero-shot capabilities of DepthAnything-AC\nacross diverse benchmarks, including real-world adverse weather benchmarks,\nsynthetic corruption benchmarks, and general benchmarks.\n  Project Page: https://ghost233lism.github.io/depthanything-AC-page\n  Code: https://github.com/HVision-NKU/DepthAnythingAC", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01634v1", "categories": ["cs.CV", "cs.AI"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01634v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "任何条件下的深度估计", "tldr": "提出DepthAnything-AC，一个在各种复杂环境（光照、天气、失真）下表现出色的单目深度估计模型，通过无监督一致性正则化微调和空间距离约束解决数据稀缺和伪标签质量问题。", "motivation": "之前的单目深度估计（MDE）模型在复杂开放世界环境（如光照变化、恶劣天气、传感器引起的失真）中表现不佳，且面临数据稀缺和受损图像无法生成高质量伪标签的挑战。", "method": "提出了一种无监督一致性正则化微调范式，仅需少量未标记数据；并提出了空间距离约束，以强制模型学习块级相对关系，从而获得更清晰的语义边界和更准确的细节。", "result": "实验结果表明DepthAnything-AC在各种基准测试中具有零样本能力，包括真实世界的恶劣天气基准、合成损坏基准和通用基准。", "conclusion": "DepthAnything-AC是一个能够在各种复杂环境条件下有效执行单目深度估计的强大基础模型，解决了现有模型在挑战性开放世界环境中的局限性。", "translation": "我们提出了Depth Anything at Any Condition (DepthAnything-AC)，一个能够在各种环境条件下处理的单目深度估计（MDE）基础模型。之前的MDE基础模型在一般场景中表现出色，但在涉及挑战性条件（如光照变化、恶劣天气和传感器引起的失真）的复杂开放世界环境中表现不佳。为了克服数据稀缺和无法从受损图像生成高质量伪标签的挑战，我们提出了一种无监督一致性正则化微调范式，该范式仅需要相对少量未标记数据。此外，我们提出了空间距离约束，以明确强制模型学习块级相对关系，从而产生更清晰的语义边界和更准确的细节。实验结果表明DepthAnything-AC在各种基准测试中具有零样本能力，包括真实世界的恶劣天气基准、合成损坏基准和通用基准。项目页面：https://ghost233lism.github.io/depthanything-AC-page 代码：https://github.com/HVision-NKU/DepthAnythingAC", "summary": "DepthAnything-AC是一个新型的单目深度估计（MDE）基础模型，旨在解决现有MDE模型在复杂开放世界环境（如恶劣天气和光照变化）中性能不佳的问题。该模型通过引入无监督一致性正则化微调范式来应对数据稀缺和伪标签质量差的挑战，仅需少量未标记数据。同时，提出的空间距离约束确保模型学习精细的块级相对关系，从而提高语义边界清晰度和细节准确性。实验证明，DepthAnything-AC在各种真实和合成基准测试中展现出卓越的零样本泛化能力。", "keywords": "单目深度估计, 基础模型, 复杂环境, 无监督学习, 零样本", "comments": "这篇论文的创新点在于提出了一个能够在极端条件下工作的单目深度估计基础模型，通过无监督学习范式有效地解决了数据稀缺和伪标签质量问题。引入空间距离约束来提升细节精度是一个有价值的贡献。该模型在复杂开放世界环境中的零样本泛化能力对于实际应用具有重要意义。"}}
{"id": "2507.01551", "title": "Self-Guided Process Reward Optimization with Masked Step Advantage for Process Reinforcement Learning", "authors": ["Wu Fei", "Hao Kong", "Shuxian Liang", "Yang Lin", "Yibo Yang", "Jing Tang", "Lei Chen", "Xiansheng Hua"], "summary": "Process Reinforcement Learning~(PRL) has demonstrated considerable potential\nin enhancing the reasoning capabilities of Large Language Models~(LLMs).\nHowever, introducing additional process reward models incurs substantial\ncomputational overhead, and there is no unified theoretical framework for\nprocess-level advantage estimation. To bridge this gap, we propose\n\\textbf{S}elf-Guided \\textbf{P}rocess \\textbf{R}eward\n\\textbf{O}ptimization~(\\textbf{SPRO}), a novel framework that enables\nprocess-aware RL through two key innovations: (1) we first theoretically\ndemonstrate that process rewards can be derived intrinsically from the policy\nmodel itself, and (2) we introduce well-defined cumulative process rewards and\n\\textbf{M}asked \\textbf{S}tep \\textbf{A}dvantage (\\textbf{MSA}), which\nfacilitates rigorous step-wise action advantage estimation within shared-prompt\nsampling groups. Our experimental results demonstrate that SPRO outperforms\nvaniila GRPO with 3.4x higher training efficiency and a 17.5\\% test accuracy\nimprovement. Furthermore, SPRO maintains a stable and elevated policy entropy\nthroughout training while reducing the average response length by approximately\n$1/3$, evidencing sufficient exploration and prevention of reward hacking.\nNotably, SPRO incurs no additional computational overhead compared to\noutcome-supervised RL methods such as GRPO, which benefit industrial\nimplementation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01551v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01551v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "过程强化学习中基于掩码步长优势的自引导过程奖励优化", "tldr": "提出SPRO框架，通过从策略模型中内在推导过程奖励并引入MSA，解决了PRL中额外计算开销和缺乏统一优势估计框架的问题，显著提升了训练效率和准确性，且无额外计算开销。", "motivation": "过程强化学习（PRL）在增强大型语言模型（LLMs）的推理能力方面潜力巨大，但引入额外的过程奖励模型会导致巨大的计算开销，并且缺乏统一的过程级优势估计理论框架。", "method": "提出自引导过程奖励优化（SPRO）框架，通过两项创新实现过程感知强化学习：1) 理论证明过程奖励可以从策略模型本身内在推导；2) 引入明确定义的累积过程奖励和掩码步长优势（MSA），以促进共享提示采样组内严格的逐步动作优势估计。", "result": "SPRO在训练效率上比GRPO高3.4倍，测试准确率提高17.5%。训练过程中策略熵保持稳定且高水平，平均响应长度减少约1/3，表明充分探索并防止奖励欺骗。与结果监督型RL方法（如GRPO）相比，SPRO不产生额外的计算开销。", "conclusion": "SPRO框架解决了PRL中的计算开销和理论框架缺失问题，显著提升了性能，同时不增加额外计算开销，有利于工业应用。", "translation": "过程强化学习（PRL）在增强大型语言模型（LLMs）的推理能力方面展现出巨大的潜力。然而，引入额外的过程奖励模型会带来巨大的计算开销，并且缺乏统一的过程级优势估计理论框架。为了弥补这一空白，我们提出了自引导过程奖励优化（SPRO），这是一个新颖的框架，通过两项关键创新实现过程感知强化学习：(1) 我们首次从理论上证明过程奖励可以从策略模型本身内在推导；(2) 我们引入了明确定义的累积过程奖励和掩码步长优势（MSA），这有助于在共享提示采样组内进行严格的逐步动作优势估计。我们的实验结果表明，SPRO在训练效率上比香草GRPO高3.4倍，测试准确率提高了17.5%。此外，SPRO在整个训练过程中保持稳定且较高的策略熵，同时平均响应长度减少了大约1/3，这证明了充分的探索并防止了奖励欺骗。值得注意的是，与结果监督型RL方法（如GRPO）相比，SPRO没有额外的计算开销，这有利于工业实施。", "summary": "本文提出了自引导过程奖励优化（SPRO）框架，旨在解决过程强化学习（PRL）中额外过程奖励模型的计算开销和缺乏统一优势估计理论框架的问题。SPRO通过从策略模型本身内在推导过程奖励，并引入累积过程奖励和掩码步长优势（MSA）进行逐步动作优势估计。实验证明，SPRO显著提升了训练效率和测试准确率，保持了高策略熵，并减少了响应长度，同时不产生额外计算开销，使其适用于工业部署。", "keywords": "过程强化学习, 大型语言模型, 奖励优化, 掩码步长优势, 计算效率", "comments": "这篇论文通过提出SPRO框架，巧妙地解决了过程强化学习中过程奖励模型带来的计算负担和理论框架缺失的问题。其创新之处在于能够从策略模型本身内在推导过程奖励，并引入MSA进行精细的逐步优势估计。无额外计算开销的特性是其在工业应用中的重要优势，表明了该方法在实际部署中的潜力。"}}
{"id": "2507.01643", "title": "SAILViT: Towards Robust and Generalizable Visual Backbones for MLLMs via Gradual Feature Refinement", "authors": ["Weijie Yin", "Dingkang Yang", "Hongyuan Dong", "Zijian Kang", "Jiacong Wang", "Xiao Liang", "Chao Feng", "Jiao Ran"], "summary": "Vision Transformers (ViTs) are essential as foundation backbones in\nestablishing the visual comprehension capabilities of Multimodal Large Language\nModels (MLLMs). Although most ViTs achieve impressive performance through\nimage-text pair-based contrastive learning or self-supervised mechanisms, they\nstruggle to engage in connector-based co-training directly with LLMs due to\npotential parameter initialization conflicts and modality semantic gaps. To\naddress the above challenges, this paper proposes SAILViT, a gradual feature\nlearning-enhanced ViT for facilitating MLLMs to break through performance\nbottlenecks in complex multimodal interactions. SAILViT achieves\ncoarse-to-fine-grained feature alignment and world knowledge infusion with\ngradual feature refinement, which better serves target training demands. We\nperform thorough empirical analyses to confirm the powerful robustness and\ngeneralizability of SAILViT across different dimensions, including parameter\nsizes, model architectures, training strategies, and data scales. Equipped with\nSAILViT, existing MLLMs show significant and consistent performance\nimprovements on the OpenCompass benchmark across extensive downstream tasks.\nSAILViT series models are released at\nhttps://huggingface.co/BytedanceDouyinContent.", "comment": "We release SAILViT, a series of versatile vision foundation models", "pdf_url": "http://arxiv.org/pdf/2507.01643v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01643v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "SAILViT：通过渐进特征细化构建面向多模态大语言模型的鲁棒且通用视觉骨干", "tldr": "SAILViT是一种新的ViT骨干，通过渐进特征细化解决了ViT与LLM协同训练的挑战，显著提升了多模态大语言模型（MLLM）在下游任务中的鲁棒性和泛化能力。", "motivation": "现有的Vision Transformers (ViTs) 作为多模态大语言模型 (MLLMs) 的视觉骨干，在与LLMs进行连接器协同训练时面临参数初始化冲突和模态语义鸿沟的问题，限制了MLLMs在复杂多模态交互中的性能。", "method": "本文提出了SAILViT，这是一种通过渐进特征学习增强的ViT模型。SAILViT通过渐进特征细化实现从粗到细的特征对齐和世界知识注入，从而更好地满足目标训练需求。", "result": "SAILViT在不同维度（包括参数规模、模型架构、训练策略和数据规模）上展现出强大的鲁棒性和泛化能力。装备SAILViT后，现有MLLMs在OpenCompass基准上，跨越广泛的下游任务，显示出显著且一致的性能提升。", "conclusion": "SAILViT通过渐进特征细化有效解决了ViT与LLM协同训练的挑战，显著提升了多模态大语言模型的性能、鲁棒性和泛化能力。", "translation": "Vision Transformers (ViTs) 作为基础骨干，在建立多模态大语言模型 (MLLMs) 的视觉理解能力方面至关重要。尽管大多数ViTs通过基于图像-文本对的对比学习或自监督机制取得了令人印象深刻的性能，但由于潜在的参数初始化冲突和模态语义鸿沟，它们难以直接与LLMs进行基于连接器的协同训练。为了解决上述挑战，本文提出了SAILViT，一种渐进特征学习增强的ViT，旨在帮助MLLMs突破复杂多模态交互中的性能瓶颈。SAILViT通过渐进特征细化实现了从粗到细的特征对齐和世界知识注入，更好地服务于目标训练需求。我们进行了彻底的实证分析，以确认SAILViT在不同维度（包括参数规模、模型架构、训练策略和数据规模）上的强大鲁棒性和泛化能力。配备SAILViT后，现有MLLMs在OpenCompass基准上，跨越广泛的下游任务，显示出显著且一致的性能提升。SAILViT系列模型已在https://huggingface.co/BytedanceDouyinContent 发布。", "summary": "本文提出了SAILViT，一种新的视觉Transformer模型，旨在作为多模态大语言模型（MLLMs）的鲁棒且通用的视觉骨干。它通过引入渐进特征细化机制，有效解决了现有ViTs与LLMs直接协同训练时面临的参数初始化冲突和模态语义鸿沟问题。SAILViT能够实现粗粒度到细粒度的特征对齐和世界知识注入。实验结果表明，SAILViT在不同参数规模、模型架构、训练策略和数据规模下均展现出优异的鲁棒性和泛化能力，并能显著且持续地提升现有MLLMs在OpenCompass基准上各种下游任务的性能。", "keywords": "MLLMs, Vision Transformers, 特征细化, 鲁棒性, 泛化能力", "comments": "SAILViT的创新之处在于其提出的“渐进特征细化”机制，有效解决了ViT在与LLM协同训练时面临的关键挑战，即参数冲突和模态语义鸿沟。这一方法对于提升多模态大语言模型的性能和泛化能力具有重要意义。模型的发布也表明了其潜在的实用价值。"}}
{"id": "2507.01652", "title": "Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective", "authors": ["Yuxin Mao", "Zhen Qin", "Jinxing Zhou", "Hui Deng", "Xuyang Shen", "Bin Fan", "Jing Zhang", "Yiran Zhong", "Yuchao Dai"], "summary": "Autoregressive (AR) models have garnered significant attention in image\ngeneration for their ability to effectively capture both local and global\nstructures within visual data. However, prevalent AR models predominantly rely\non the transformer architectures, which are beset by quadratic computational\ncomplexity concerning input sequence length and substantial memory overhead due\nto the necessity of maintaining key-value caches. Although linear attention\nmechanisms have successfully reduced this burden in language models, our\ninitial experiments reveal that they significantly degrade image generation\nquality because of their inability to capture critical long-range dependencies\nin visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), a\nnovel attention mechanism that explicitly preserves genuine 2D spatial\nrelationships within the flattened image sequences by computing\nposition-dependent decay factors based on true 2D spatial location rather than\n1D sequence positions. Based on this mechanism, we present LASADGen, an\nautoregressive image generator that enables selective attention to relevant\nspatial contexts with linear complexity. Experiments on ImageNet show LASADGen\nachieves state-of-the-art image generation performance and computational\nefficiency, bridging the gap between linear attention's efficiency and spatial\nunderstanding needed for high-quality generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01652v1", "categories": ["cs.CV", "cs.AI", "cs.MM"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01652v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "具有线性复杂度的自回归图像生成：一种空间感知衰减视角", "tldr": "提出LASADGen，一种新的自回归图像生成器，通过空间感知衰减的线性注意力机制，实现了线性复杂度和SOTA性能。", "motivation": "现有的自回归图像生成模型主要依赖Transformer，导致二次方计算复杂度和高内存开销。虽然线性注意力在语言模型中有效，但在图像生成中会降低质量，因为它无法捕获视觉数据中的长程依赖。", "method": "提出线性注意力与空间感知衰减（LASAD），一种新的注意力机制，通过计算基于真实2D空间位置而非1D序列位置的依赖于位置的衰减因子，明确保留了展平图像序列中的真实2D空间关系。基于此机制，提出了LASADGen，一个具有线性复杂度的自回归图像生成器。", "result": "在ImageNet上的实验表明，LASADGen实现了最先进的图像生成性能和计算效率。", "conclusion": "LASADGen成功弥合了线性注意力效率与高质量生成所需空间理解之间的差距。", "translation": "自回归（AR）模型因其能够有效捕获视觉数据中的局部和全局结构而在图像生成领域获得了广泛关注。然而，主流的AR模型主要依赖于Transformer架构，其面临着关于输入序列长度的二次方计算复杂度和由于需要维护键值缓存而产生的巨大内存开销。尽管线性注意力机制在语言模型中成功降低了这一负担，但我们的初步实验表明，由于其无法捕获视觉数据中关键的长程依赖关系，它们显著降低了图像生成质量。我们提出了线性注意力与空间感知衰减（LASAD），这是一种新颖的注意力机制，通过计算基于真实2D空间位置而非1D序列位置的依赖于位置的衰减因子，明确保留了展平图像序列中的真实2D空间关系。基于此机制，我们提出了LASADGen，这是一种自回归图像生成器，能够以线性复杂度选择性地关注相关空间上下文。在ImageNet上的实验表明，LASADGen实现了最先进的图像生成性能和计算效率，弥合了线性注意力的效率与高质量生成所需空间理解之间的差距。", "summary": "本文提出LASADGen，一种基于新型线性注意力与空间感知衰减（LASAD）机制的自回归图像生成器。LASAD通过计算基于真实2D空间位置的衰减因子，有效解决了现有线性注意力在图像生成中无法捕获长程依赖的问题。实验证明，LASADGen在保持线性计算复杂度的同时，在ImageNet上实现了最先进的图像生成性能和计算效率。", "keywords": "自回归图像生成, 线性复杂度, 空间感知衰减, 注意力机制, LASADGen", "comments": "本文的创新点在于提出了LASAD机制，它巧妙地将2D空间信息融入到线性注意力中，解决了传统线性注意力在图像生成中性能下降的问题。这为开发更高效、高质量的自回归图像生成模型开辟了新路径，对于资源受限或需要大规模图像生成的应用具有重要意义。"}}
{"id": "2507.01470", "title": "Zero-Incentive Dynamics: a look at reward sparsity through the lens of unrewarded subgoals", "authors": ["Yannick Molinghen", "Tom Lenaerts"], "summary": "This work re-examines the commonly held assumption that the frequency of\nrewards is a reliable measure of task difficulty in reinforcement learning. We\nidentify and formalize a structural challenge that undermines the effectiveness\nof current policy learning methods: when essential subgoals do not directly\nyield rewards. We characterize such settings as exhibiting zero-incentive\ndynamics, where transitions critical to success remain unrewarded. We show that\nstate-of-the-art deep subgoal-based algorithms fail to leverage these dynamics\nand that learning performance is highly sensitive to the temporal proximity\nbetween subgoal completion and eventual reward. These findings reveal a\nfundamental limitation in current approaches and point to the need for\nmechanisms that can infer latent task structure without relying on immediate\nincentives.", "comment": "Accepted at \"Finding the Frame 2025\", workshop at RLC", "pdf_url": "http://arxiv.org/pdf/2507.01470v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01470v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "零激励动力学：从无奖励子目标视角看奖励稀疏性", "tldr": "本文重新审视了强化学习中奖励频率作为任务难度衡量标准的假设，指出当关键子目标不直接产生奖励时，现有策略学习方法会失效，并将这种设置称为零激励动力学。研究发现当前最先进的基于子目标的算法未能利用这些动力学，且学习性能对子目标完成与最终奖励之间的时间接近度高度敏感，揭示了当前方法的局限性。", "motivation": "重新审视强化学习中奖励频率是衡量任务难度的可靠指标这一普遍假设，并识别和形式化一个结构性挑战：当关键子目标不直接产生奖励时，现有策略学习方法会失效。", "method": "识别并形式化了“零激励动力学”这一概念，其中关键的成功过渡没有得到奖励。通过实验展示了最先进的深度基于子目标的算法未能利用这些动力学，并分析了学习性能对子目标完成与最终奖励时间接近度的敏感性。", "result": "最先进的深度基于子目标的算法未能利用零激励动力学。学习性能对子目标完成和最终奖励之间的时间接近度高度敏感。", "conclusion": "当前方法存在根本性局限性，需要开发能够在不依赖即时激励的情况下推断潜在任务结构的机制。", "translation": "这项工作重新审视了强化学习中奖励频率是衡量任务难度的可靠指标这一普遍假设。我们识别并形式化了一个结构性挑战，该挑战削弱了当前策略学习方法的有效性：当关键子目标不直接产生奖励时。我们将此类设置描述为表现出零激励动力学，其中对成功至关重要的过渡仍然没有得到奖励。我们表明，最先进的深度基于子目标的算法未能利用这些动力学，并且学习性能对子目标完成与最终奖励之间的时间接近度高度敏感。这些发现揭示了当前方法的一个根本性局限性，并指出需要能够推断潜在任务结构而不依赖即时激励的机制。", "summary": "本文挑战了强化学习中奖励频率与任务难度相关的假设，引入了“零激励动力学”概念，描述了关键子目标不直接获得奖励的情境。研究发现，现有基于子目标的算法在这种动态下表现不佳，且学习效率受子目标完成与最终奖励时间间隔影响。这揭示了当前方法的局限性，并强调了开发无需即时激励即可推断潜在任务结构的新机制的必要性。", "keywords": "强化学习, 奖励稀疏性, 子目标, 零激励动力学, 任务结构", "comments": "这篇论文通过引入“零激励动力学”的概念，对强化学习中的奖励稀疏性问题提供了新的视角。它强调了在关键子目标未直接获得奖励时，现有方法的不足，并揭示了子目标与最终奖励之间时间距离的重要性。其创新之处在于形式化了这种未被充分关注的挑战，并为未来研究指明了方向，即需要更智能的机制来推断任务结构，而不仅仅依赖即时奖励。"}}
{"id": "2507.01599", "title": "Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems", "authors": ["Zhaoyan Sun", "Jiayi Wang", "Xinyang Zhao", "Jiachi Wang", "Guoliang Li"], "summary": "Traditional Data+AI systems utilize data-driven techniques to optimize\nperformance, but they rely heavily on human experts to orchestrate system\npipelines, enabling them to adapt to changes in data, queries, tasks, and\nenvironments. For instance, while there are numerous data science tools\navailable, developing a pipeline planning system to coordinate these tools\nremains challenging. This difficulty arises because existing Data+AI systems\nhave limited capabilities in semantic understanding, reasoning, and planning.\nFortunately, we have witnessed the success of large language models (LLMs) in\nenhancing semantic understanding, reasoning, and planning abilities. It is\ncrucial to incorporate LLM techniques to revolutionize data systems for\norchestrating Data+AI applications effectively.\n  To achieve this, we propose the concept of a 'Data Agent' - a comprehensive\narchitecture designed to orchestrate Data+AI ecosystems, which focuses on\ntackling data-related tasks by integrating knowledge comprehension, reasoning,\nand planning capabilities. We delve into the challenges involved in designing\ndata agents, such as understanding data/queries/environments/tools,\norchestrating pipelines/workflows, optimizing and executing pipelines, and\nfostering pipeline self-reflection. Furthermore, we present examples of data\nagent systems, including a data science agent, data analytics agents (such as\nunstructured data analytics agent, semantic structured data analytics agent,\ndata lake analytics agent, and multi-modal data analytics agent), and a\ndatabase administrator (DBA) agent. We also outline several open challenges\nassociated with designing data agent systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01599v1", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.LG"], "cate": "cs.DB", "url": "http://arxiv.org/abs/2507.01599v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "数据智能体：一种用于编排数据+AI生态系统的整体架构", "tldr": "提出“数据智能体”概念，利用LLM增强数据+AI系统中的语义理解、推理和规划能力，以自动化数据相关任务的编排。", "motivation": "传统数据+AI系统在管道编排上过度依赖人工专家，难以适应数据、查询、任务和环境的变化，且现有系统在语义理解、推理和规划方面能力有限。大型语言模型（LLMs）在这些能力上的成功，促使将LLM技术融入数据系统以有效编排数据+AI应用的需求。", "method": "本文提出了“数据智能体”的概念，这是一种全面的架构，旨在通过集成知识理解、推理和规划能力来处理数据相关任务，从而编排数据+AI生态系统。论文深入探讨了设计数据智能体的挑战，并提供了多种数据智能体系统的示例，包括数据科学智能体、多种数据分析智能体（如非结构化、语义结构化、数据湖、多模态）以及数据库管理员（DBA）智能体。", "result": "论文提出了数据智能体的概念和架构，并展示了多种数据智能体系统的具体应用示例，如数据科学智能体、各类数据分析智能体和DBA智能体，表明了其在不同数据+AI场景下实现自动化编排的潜力。", "conclusion": "本文提出了数据智能体这一革命性概念，旨在利用大型语言模型的能力解决数据+AI系统中的编排挑战。它展示了数据智能体在各种应用中的巨大潜力，并指出了设计数据智能体系统的一些开放性挑战，为未来研究指明了方向。", "translation": "传统的数据+AI系统利用数据驱动技术优化性能，但它们严重依赖人类专家来编排系统管道，使其能够适应数据、查询、任务和环境的变化。例如，尽管有大量的可用数据科学工具，但开发一个管道规划系统来协调这些工具仍然具有挑战性。这种困难的出现是因为现有数据+AI系统在语义理解、推理和规划方面的能力有限。幸运的是，我们已经见证了大型语言模型（LLMs）在增强语义理解、推理和规划能力方面的成功。因此，将LLM技术整合到数据系统中以有效编排数据+AI应用至关重要。\n为了实现这一目标，我们提出了“数据智能体”的概念——一种旨在编排数据+AI生态系统的全面架构，其重点是通过整合知识理解、推理和规划能力来处理数据相关任务。我们深入探讨了设计数据智能体所面临的挑战，例如理解数据/查询/环境/工具、编排管道/工作流、优化和执行管道以及促进管道自我反思。此外，我们还提供了数据智能体系统的示例，包括数据科学智能体、数据分析智能体（如非结构化数据分析智能体、语义结构化数据分析智能体、数据湖数据分析智能体和多模态数据分析智能体）以及数据库管理员（DBA）智能体。我们还概述了与设计数据智能体系统相关的一些开放性挑战。", "summary": "这篇论文提出了“数据智能体”这一创新概念，旨在解决传统数据+AI系统在管道编排上对人工的高度依赖以及在语义理解、推理和规划方面的局限性。数据智能体是一种全面的架构，它利用大型语言模型（LLMs）的能力，集成知识理解、推理和规划，以自动化和优化数据相关任务的编排。文章探讨了设计智能体的挑战，并展示了数据科学、数据分析（包括多种类型）和数据库管理等领域的具体应用实例，同时指出了未来的开放性挑战。", "keywords": "数据智能体, 大型语言模型, 数据+AI系统, 自动化编排, 管道规划", "comments": "这篇论文提出“数据智能体”的概念，利用LLM提升数据+AI系统的自动化和智能化水平，具有重要的创新性。它将LLM的能力从文本处理扩展到复杂的数据系统编排，有望显著降低人工干预，提高效率和适应性。论文不仅提出了概念，还给出了具体的应用场景示例，具有很强的指导意义。"}}
{"id": "2507.01653", "title": "RobuSTereo: Robust Zero-Shot Stereo Matching under Adverse Weather", "authors": ["Yuran Wang", "Yingping Liang", "Yutao Hu", "Ying Fu"], "summary": "Learning-based stereo matching models struggle in adverse weather conditions\ndue to the scarcity of corresponding training data and the challenges in\nextracting discriminative features from degraded images. These limitations\nsignificantly hinder zero-shot generalization to out-of-distribution weather\nconditions. In this paper, we propose \\textbf{RobuSTereo}, a novel framework\nthat enhances the zero-shot generalization of stereo matching models under\nadverse weather by addressing both data scarcity and feature extraction\nchallenges. First, we introduce a diffusion-based simulation pipeline with a\nstereo consistency module, which generates high-quality stereo data tailored\nfor adverse conditions. By training stereo matching models on our synthetic\ndatasets, we reduce the domain gap between clean and degraded images,\nsignificantly improving the models' robustness to unseen weather conditions.\nThe stereo consistency module ensures structural alignment across synthesized\nimage pairs, preserving geometric integrity and enhancing depth estimation\naccuracy. Second, we design a robust feature encoder that combines a\nspecialized ConvNet with a denoising transformer to extract stable and reliable\nfeatures from degraded images. The ConvNet captures fine-grained local\nstructures, while the denoising transformer refines global representations,\neffectively mitigating the impact of noise, low visibility, and weather-induced\ndistortions. This enables more accurate disparity estimation even under\nchallenging visual conditions. Extensive experiments demonstrate that\n\\textbf{RobuSTereo} significantly improves the robustness and generalization of\nstereo matching models across diverse adverse weather scenarios.", "comment": "accepted by ICCV25", "pdf_url": "http://arxiv.org/pdf/2507.01653v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01653v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "RobuSTereo：恶劣天气下鲁棒的零样本立体匹配", "tldr": "提出RobuSTereo框架，通过扩散模型生成恶劣天气立体数据和设计鲁棒特征编码器，显著提升立体匹配模型在恶劣天气下的零样本泛化能力。", "motivation": "学习型立体匹配模型在恶劣天气下表现不佳，原因在于缺乏相应的训练数据以及难以从退化图像中提取判别性特征，这严重阻碍了模型对分布外天气条件的零样本泛化能力。", "method": "论文提出了RobuSTereo框架。首先，引入了一个基于扩散的模拟管道，其中包含一个立体一致性模块，用于生成高质量的恶劣天气立体数据，并确保合成图像对的结构对齐和几何完整性。其次，设计了一个鲁棒的特征编码器，该编码器结合了专门的卷积网络（ConvNet）和去噪Transformer，以从退化图像中提取稳定可靠的特征，有效减轻噪声、低能见度和天气引起的失真影响。", "result": "大量实验表明，RobuSTereo显著提高了立体匹配模型在各种恶劣天气场景下的鲁棒性和泛化能力。", "conclusion": "论文提出的RobuSTereo框架通过解决数据稀缺和特征提取挑战，成功地增强了立体匹配模型在恶劣天气下的零样本泛化能力，并显著提升了模型的鲁棒性。", "translation": "基于学习的立体匹配模型在恶劣天气条件下表现不佳，原因在于相应训练数据的稀缺性以及从退化图像中提取判别性特征的挑战。这些限制严重阻碍了对分布外天气条件的零样本泛化。本文提出了**RobuSTereo**，一个新颖的框架，通过解决数据稀缺和特征提取挑战，增强了立体匹配模型在恶劣天气下的零样本泛化能力。首先，我们引入了一个基于扩散的模拟管道，其中包含一个立体一致性模块，用于生成针对恶劣条件量身定制的高质量立体数据。通过在我们合成数据集上训练立体匹配模型，我们减少了清洁图像和退化图像之间的领域差距，显著提高了模型对未知天气条件的鲁棒性。立体一致性模块确保了合成图像对的结构对齐，保留了几何完整性并提高了深度估计精度。其次，我们设计了一个鲁棒的特征编码器，该编码器结合了专门的卷积网络（ConvNet）和去噪Transformer，以从退化图像中提取稳定可靠的特征。ConvNet捕获细粒度的局部结构，而去噪Transformer细化全局表示，有效减轻了噪声、低能见度和天气引起的失真影响。这使得即使在具有挑战性的视觉条件下也能进行更准确的视差估计。大量实验表明，**RobuSTereo**显著提高了立体匹配模型在各种恶劣天气场景下的鲁棒性和泛化能力。", "summary": "本文提出了RobuSTereo框架，旨在解决学习型立体匹配模型在恶劣天气下因数据稀缺和特征提取困难导致的零样本泛化能力不足问题。该框架通过引入一个基于扩散的模拟管道，生成高质量的恶劣天气立体数据，并设计一个结合ConvNet和去噪Transformer的鲁棒特征编码器，有效处理图像退化。实验证明RobuSTereo显著提升了模型在多种恶劣天气下的鲁棒性和泛化能力。", "keywords": "立体匹配, 零样本泛化, 恶劣天气, 扩散模型, 特征编码器", "comments": "这篇论文通过结合数据生成（扩散模型）和特征增强（混合编码器）两种策略，有效解决了恶劣天气下立体匹配的零样本泛化难题，具有创新性。其方法针对性强，有望在自动驾驶和环境感知等领域发挥重要作用。"}}
{"id": "2507.01516", "title": "Loss Functions in Diffusion Models: A Comparative Study", "authors": ["Dibyanshu Kumar", "Philipp Vaeth", "Magda Gregorová"], "summary": "Diffusion models have emerged as powerful generative models, inspiring\nextensive research into their underlying mechanisms. One of the key questions\nin this area is the loss functions these models shall train with. Multiple\nformulations have been introduced in the literature over the past several years\nwith some links and some critical differences stemming from various initial\nconsiderations. In this paper, we explore the different target objectives and\ncorresponding loss functions in detail. We present a systematic overview of\ntheir relationships, unifying them under the framework of the variational lower\nbound objective. We complement this theoretical analysis with an empirical\nstudy providing insights into the conditions under which these objectives\ndiverge in performance and the underlying factors contributing to such\ndeviations. Additionally, we evaluate how the choice of objective impacts the\nmodel ability to achieve specific goals, such as generating high-quality\nsamples or accurately estimating likelihoods. This study offers a unified\nunderstanding of loss functions in diffusion models, contributing to more\nefficient and goal-oriented model designs in future research.", "comment": "Accepted to ECML 2025", "pdf_url": "http://arxiv.org/pdf/2507.01516v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01516v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "扩散模型中的损失函数：一项比较研究", "tldr": "本文对扩散模型中不同的损失函数进行了详细探讨，系统性地概述了它们的关系，并通过理论分析和实证研究提供了统一的理解，旨在促进未来更高效和目标导向的模型设计。", "motivation": "扩散模型作为强大的生成模型，其底层机制，特别是训练中使用的损失函数，是研究的关键问题。现有的多种损失函数之间存在联系和差异，本研究旨在详细探讨并提供统一的理解。", "method": "本文详细探讨了不同的目标函数和相应的损失函数，并在变分下界（variational lower bound）框架下系统性地统一了它们的关系。此外，还通过实证研究分析了这些目标函数在性能上出现差异的条件及其潜在因素，并评估了目标选择对模型实现特定目标（如生成高质量样本或准确估计似然）能力的影响。", "result": "研究提供了关于不同损失函数在性能上出现差异的条件及其潜在因素的深入见解，并评估了损失函数选择如何影响模型生成高质量样本或准确估计似然的能力。", "conclusion": "本研究为扩散模型中的损失函数提供了统一的理解，有助于未来设计更高效和目标导向的模型。", "translation": "扩散模型已成为强大的生成模型，激发了对其底层机制的广泛研究。该领域的一个关键问题是这些模型应使用何种损失函数进行训练。过去几年中，文献中引入了多种公式，它们之间存在一些联系和一些源于各种初始考虑的关键差异。在本文中，我们详细探讨了不同的目标函数和相应的损失函数。我们系统性地概述了它们的关系，并在变分下界目标框架下统一了它们。我们通过一项实证研究补充了这种理论分析，该研究提供了关于这些目标函数在性能上出现差异的条件以及导致此类偏差的潜在因素的见解。此外，我们评估了目标选择如何影响模型实现特定目标的能力，例如生成高质量样本或准确估计似然。这项研究为扩散模型中的损失函数提供了统一的理解，有助于未来研究中更高效和目标导向的模型设计。", "summary": "本文对扩散模型中多种损失函数进行了全面的比较研究。通过理论分析，研究者在变分下界框架下统一了这些损失函数，并系统性地阐述了它们之间的关系。同时，通过实证研究，论文深入探讨了不同损失函数在性能上产生差异的条件、潜在因素，以及它们对模型实现特定目标（如生成高质量样本或准确估计似然）能力的影响。这项工作旨在提供对扩散模型损失函数的统一理解，以指导未来更高效和目标导向的模型设计。", "keywords": "扩散模型, 损失函数, 比较研究, 变分下界, 生成模型", "comments": "这项研究通过对扩散模型中损失函数的系统性分析和实证比较，解决了该领域的一个核心问题。其创新之处在于将不同损失函数统一到变分下界框架下，提供了理论上的连贯性。同时，实证研究揭示了损失函数选择对模型性能和特定目标实现的影响，这对于指导未来扩散模型的设计具有重要实践意义。该研究对于理解扩散模型的内部机制，优化其训练过程具有重要价值。"}}
{"id": "2507.01679", "title": "Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling", "authors": ["Zeyu Huang", "Tianhao Cheng", "Zihan Qiu", "Zili Wang", "Yinghui Xu", "Edoardo M. Ponti", "Ivan Titov"], "summary": "Existing post-training techniques for large language models are broadly\ncategorized into Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning\n(RFT). Each paradigm presents a distinct trade-off: SFT excels at mimicking\ndemonstration data but can lead to problematic generalization as a form of\nbehavior cloning. Conversely, RFT can significantly enhance a model's\nperformance but is prone to learn unexpected behaviors, and its performance is\nhighly sensitive to the initial policy. In this paper, we propose a unified\nview of these methods and introduce Prefix-RFT, a hybrid approach that\nsynergizes learning from both demonstration and exploration. Using mathematical\nreasoning problems as a testbed, we empirically demonstrate that Prefix-RFT is\nboth simple and effective. It not only surpasses the performance of standalone\nSFT and RFT but also outperforms parallel mixed-policy RFT methods. A key\nadvantage is its seamless integration into existing open-source frameworks,\nrequiring only minimal modifications to the standard RFT pipeline. Our analysis\nhighlights the complementary nature of SFT and RFT, and validates that\nPrefix-RFT effectively harmonizes these two learning paradigms. Furthermore,\nablation studies confirm the method's robustness to variations in the quality\nand quantity of demonstration data. We hope this work offers a new perspective\non LLM post-training, suggesting that a unified paradigm that judiciously\nintegrates demonstration and exploration could be a promising direction for\nfuture research.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.01679v1", "categories": ["cs.LG", "cs.AI", "cs.CL"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01679v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "融合监督式和强化微调与前缀采样", "tldr": "本文提出Prefix-RFT，一种结合监督式和强化微调的新方法，在数学推理问题上表现优于现有方法，并易于集成。", "motivation": "现有的大型语言模型后训练技术（监督式微调SFT和强化微调RFT）各有优缺点：SFT擅长模仿示范数据但泛化能力差，RFT能显著提升性能但易学到意外行为且对初始策略敏感。本文旨在提出一种统一的视角来结合两者的优势。", "method": "本文提出Prefix-RFT，一种混合方法，它将监督式学习（来自示范）和探索式学习（来自强化）相结合。该方法通过前缀采样，将示范数据无缝集成到标准的RFT流程中，仅需最小修改。", "result": "在数学推理问题上，Prefix-RFT不仅超越了单独的SFT和RFT的性能，也优于并行混合策略的RFT方法。它易于集成到现有开源框架中，仅需对标准RFT流程进行最小修改。消融研究证实了该方法对示范数据质量和数量变化的鲁棒性。", "conclusion": "SFT和RFT具有互补性，Prefix-RFT有效协调了这两种学习范式。这项工作为LLM后训练提供了一个新视角，表明审慎整合示范和探索的统一范式可能是未来研究的一个有前景的方向。", "translation": "现有的大型语言模型后训练技术大致分为监督式微调（SFT）和强化微调（RFT）。每种范式都有其独特的权衡：SFT擅长模仿示范数据，但作为一种行为克隆形式，可能导致有问题的泛化。相反，RFT可以显著增强模型的性能，但容易学习到意外行为，并且其性能对初始策略高度敏感。在本文中，我们提出了这些方法的一个统一视图，并引入了Prefix-RFT，这是一种混合方法，它协同利用了来自示范和探索的学习。以数学推理问题作为测试平台，我们经验性地证明了Prefix-RFT既简单又有效。它不仅超越了单独的SFT和RFT的性能，而且优于并行混合策略的RFT方法。一个关键优势是它能无缝集成到现有开源框架中，仅需对标准RFT管道进行最小修改。我们的分析强调了SFT和RFT的互补性，并验证了Prefix-RFT有效地协调了这两种学习范式。此外，消融研究证实了该方法对示范数据质量和数量变化的鲁棒性。我们希望这项工作能为LLM后训练提供一个新视角，表明审慎整合示范和探索的统一范式可能是未来研究的一个有前景的方向。", "summary": "本文提出Prefix-RFT，一种新颖的混合微调方法，旨在结合大型语言模型（LLM）中监督式微调（SFT）和强化微调（RFT）的优点。针对SFT泛化问题和RFT不稳定性，Prefix-RFT通过前缀采样实现示范学习和探索学习的协同。在数学推理任务上的实验表明，Prefix-RFT性能优于单独的SFT和RFT以及其他混合策略，且易于集成和鲁棒性强。该工作为LLM的后训练提供了一个统一范式的新方向。", "keywords": "大型语言模型, 监督式微调, 强化微调, Prefix-RFT, 混合学习", "comments": "本文的创新点在于提出了Prefix-RFT，一个统一SFT和RFT的混合范式，有效解决了各自的局限性。其重要性在于提供了一个简单高效的LLM后训练方法，尤其强调了两种范式互补性，并验证了通过前缀采样实现无缝集成的可行性。这为未来LLM的微调研究提供了一个有前景的方向。"}}
{"id": "2507.01654", "title": "SPoT: Subpixel Placement of Tokens in Vision Transformers", "authors": ["Martine Hjelkrem-Tan", "Marius Aasan", "Gabriel Y. Arteaga", "Adín Ramírez Rivera"], "summary": "Vision Transformers naturally accommodate sparsity, yet standard tokenization\nmethods confine features to discrete patch grids. This constraint prevents\nmodels from fully exploiting sparse regimes, forcing awkward compromises. We\npropose Subpixel Placement of Tokens (SPoT), a novel tokenization strategy that\npositions tokens continuously within images, effectively sidestepping\ngrid-based limitations. With our proposed oracle-guided search, we uncover\nsubstantial performance gains achievable with ideal subpixel token positioning,\ndrastically reducing the number of tokens necessary for accurate predictions\nduring inference. SPoT provides a new direction for flexible, efficient, and\ninterpretable ViT architectures, redefining sparsity as a strategic advantage\nrather than an imposed limitation.", "comment": "To appear in Workshop on Efficient Computing under Limited Resources:\n  Visual Computing (ICCV 2025). Code available at\n  https://github.com/dsb-ifi/SPoT", "pdf_url": "http://arxiv.org/pdf/2507.01654v1", "categories": ["cs.CV", "cs.LG"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01654v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "SPoT：视觉Transformer中Token的亚像素定位", "tldr": "SPoT通过亚像素连续定位Token，克服了Vision Transformer中传统离散Token化的限制，显著减少了推理所需的Token数量并提升了性能。", "motivation": "传统Vision Transformer的Token化方法将特征限制在离散的块网格中，这阻碍了模型充分利用稀疏性，导致性能受限，迫使模型做出不便的妥协。", "method": "本文提出了一种名为亚像素Token定位（SPoT）的新型Token化策略，该策略将Token连续地定位在图像内，从而规避了基于网格的限制。通过“oracle-guided search”来发现理想的亚像素Token定位。", "result": "实现了显著的性能提升，并在推理过程中大幅减少了准确预测所需的Token数量。", "conclusion": "SPoT为灵活、高效、可解释的ViT架构提供了新方向，将稀疏性重新定义为战略优势而非强加的限制。", "translation": "视觉Transformer自然地适应稀疏性，但标准的Token化方法将特征限制在离散的块网格中。这种限制阻碍了模型充分利用稀疏机制，迫使模型做出不便的妥协。我们提出了亚像素Token定位（SPoT），这是一种新颖的Token化策略，它将Token连续地定位在图像内，有效地规避了基于网格的限制。通过我们提出的神谕引导搜索，我们发现了理想的亚像素Token定位可以实现显著的性能提升，从而在推理过程中大幅减少了准确预测所需的Token数量。SPoT为灵活、高效、可解释的ViT架构提供了新方向，将稀疏性重新定义为战略优势而非强加的限制。", "summary": "本文提出SPoT（Subpixel Placement of Tokens），一种针对Vision Transformer的新型Token化策略。与传统的离散网格Token化不同，SPoT在图像内连续定位Token，从而克服了现有方法在利用稀疏性方面的局限。通过oracle-guided search，SPoT显著提升了模型性能，并大幅减少了推理所需的Token数量，为更灵活、高效和可解释的ViT架构开辟了新途径。", "keywords": "Vision Transformers, Tokenization, Subpixel Placement, Sparsity, Efficient ViT", "comments": "SPoT的创新点在于其连续的亚像素Token定位，这打破了Vision Transformer中Token与离散网格绑定的传统，使得模型能更好地利用稀疏性。这种方法有望提升ViT的效率和灵活性，并可能带来更强的可解释性，为ViT的进一步发展提供了新的视角。"}}
{"id": "2507.01735", "title": "ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving", "authors": ["Kai Chen", "Ruiyuan Gao", "Lanqing Hong", "Hang Xu", "Xu Jia", "Holger Caesar", "Dengxin Dai", "Bingbing Liu", "Dzmitry Tsishkou", "Songcen Xu", "Chunjing Xu", "Qiang Xu", "Huchuan Lu", "Dit-Yan Yeung"], "summary": "In this paper, we present details of the 1st W-CODA workshop, held in\nconjunction with the ECCV 2024. W-CODA aims to explore next-generation\nsolutions for autonomous driving corner cases, empowered by state-of-the-art\nmultimodal perception and comprehension techniques. 5 Speakers from both\nacademia and industry are invited to share their latest progress and opinions.\nWe collect research papers and hold a dual-track challenge, including both\ncorner case scene understanding and generation. As the pioneering effort, we\nwill continuously bridge the gap between frontier autonomous driving techniques\nand fully intelligent, reliable self-driving agents robust towards corner\ncases.", "comment": "ECCV 2024. Workshop page: https://coda-dataset.github.io/w-coda2024/", "pdf_url": "http://arxiv.org/pdf/2507.01735v1", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01735v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "ECCV 2024 W-CODA：第一届自动驾驶中极端情况的多模态感知与理解研讨会", "tldr": "ECCV 2024 W-CODA是关于自动驾驶中极端情况的多模态感知与理解的首次研讨会，旨在推动相关技术发展。", "motivation": "该研讨会旨在探索由最先进的多模态感知和理解技术支持的自动驾驶极端情况的下一代解决方案。", "method": "W-CODA研讨会邀请了来自学术界和工业界的5位演讲者分享最新进展和观点，并收集研究论文，同时举办双轨挑战赛，包括极端情况场景理解和生成。", "result": "本次研讨会包括邀请演讲、研究论文收集以及极端情况场景理解与生成的双轨挑战赛。", "conclusion": "作为一项开创性工作，W-CODA将持续弥合前沿自动驾驶技术与对极端情况具有鲁棒性的全智能、可靠自动驾驶代理之间的差距。", "translation": "在本文中，我们介绍了与ECCV 2024同期举办的第一届W-CODA研讨会的详细信息。W-CODA旨在探索由最先进的多模态感知和理解技术支持的自动驾驶极端情况的下一代解决方案。研讨会邀请了来自学术界和工业界的5位演讲者分享他们的最新进展和观点。我们收集研究论文并举办双轨挑战赛，包括极端情况场景理解和生成。作为一项开创性工作，我们将持续弥合前沿自动驾驶技术与对极端情况具有鲁棒性的全智能、可靠自动驾驶代理之间的差距。", "summary": "W-CODA是ECCV 2024首次举办的关于自动驾驶中极端情况的多模态感知与理解的研讨会。该研讨会汇集了学术界和工业界的专家，旨在探索下一代解决方案。它通过邀请演讲、论文收集和双轨挑战赛（包括极端情况场景理解和生成）来促进研究。W-CODA致力于推动自动驾驶技术发展，以实现对极端情况更具鲁棒性的智能自动驾驶系统。", "keywords": "自动驾驶, 极端情况, 多模态感知, 研讨会, ECCV 2024", "comments": "W-CODA研讨会是一项具有前瞻性的工作，它首次聚焦于自动驾驶中至关重要的“极端情况”问题，并强调多模态感知和理解的重要性。通过汇集学术界和工业界的力量，并结合论文征集与挑战赛的形式，该研讨会有望加速该领域的技术突破，特别是在极端情况的理解与生成方面，这对于提升自动驾驶的可靠性至关重要。"}}
{"id": "2507.01544", "title": "MARVIS: Modality Adaptive Reasoning over VISualizations", "authors": ["Benjamin Feuer", "Lennart Purucker", "Oussama Elachqar", "Chinmay Hegde"], "summary": "Scientific applications of machine learning often rely on small, specialized\nmodels tuned to particular domains. Such models often achieve excellent\nperformance, but lack flexibility. Foundation models offer versatility, but\ntypically underperform specialized approaches, especially on non-traditional\nmodalities and long-tail domains. We propose MARVIS (Modality Adaptive\nReasoning over VISualizations), a training-free method that enables even small\nvision-language models to predict any data modality with high accuracy. MARVIS\ntransforms latent embedding spaces into visual representations and then\nleverages the spatial and fine-grained reasoning skills of VLMs to successfully\ninterpret and utilize them. MARVIS achieves competitive performance on vision,\naudio, biological, and tabular domains using a single 3B parameter model,\nachieving results that beat Gemini by 16\\% on average and approach specialized\nmethods, without exposing personally identifiable information (P.I.I.) or\nrequiring any domain-specific training. We open source our code and datasets at\nhttps://github.com/penfever/marvis", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01544v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01544v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "MARVIS：基于可视化的模态自适应推理", "tldr": "MARVIS 是一种无需训练的方法，它将不同模态的数据转换为视觉表示，使小型视觉语言模型能够高精度处理任何数据模态，性能优于大型基础模型。", "motivation": "现有的机器学习模型面临两难困境：小型专业模型性能优异但缺乏灵活性，而基础模型虽然通用但对非传统模态和长尾领域表现不佳。这促使研究者寻求一种既能保持高性能又具备跨模态灵活性的方法。", "method": "MARVIS（基于可视化的模态自适应推理）是一种无需训练的方法。它通过将潜在嵌入空间转换为视觉表示，然后利用视觉语言模型（VLM）的空间和细粒度推理能力来解释和利用这些视觉表示，从而实现对任何数据模态的高精度预测。", "result": "MARVIS 使用单个30亿参数模型在视觉、音频、生物和表格领域取得了具有竞争力的性能。它平均比 Gemini 模型高出16%，并且接近专业方法的表现，同时不暴露个人身份信息（P.I.I.），也不需要任何特定领域的训练。", "conclusion": "MARVIS 证明了通过将不同数据模态转换为视觉表示，可以有效地利用小型视觉语言模型进行跨模态推理，实现高精度和强大的泛化能力，且无需额外训练或特定领域知识。", "translation": "机器学习的科学应用通常依赖于针对特定领域调整的小型专业模型。这类模型通常表现出色，但缺乏灵活性。基础模型虽然通用，但在非传统模态和长尾领域通常表现不如专业方法。我们提出了 MARVIS（基于可视化的模态自适应推理），这是一种无需训练的方法，能够让小型视觉语言模型也能高精度地预测任何数据模态。MARVIS 将潜在嵌入空间转换为视觉表示，然后利用视觉语言模型（VLM）的空间和细粒度推理能力成功地解释和利用它们。MARVIS 使用单个30亿参数模型在视觉、音频、生物和表格领域取得了具有竞争力的性能，平均比 Gemini 模型高出16%，并且接近专业方法的表现，同时不暴露个人身份信息（P.I.I.），也不需要任何领域特定训练。我们已在 https://github.com/penfever/marvis 开源了我们的代码和数据集。", "summary": "MARVIS 是一种无需训练的新方法，旨在解决专业模型缺乏灵活性和基础模型在非传统模态上表现不佳的问题。它通过将各种数据模态的潜在嵌入转换为视觉表示，并利用小型视觉语言模型（VLM）的推理能力进行处理。该方法使一个30亿参数的模型在视觉、音频、生物和表格等多个领域取得了卓越性能，平均优于 Gemini 模型16%，并接近专业方法的水平，且无需领域特定训练或暴露个人信息。", "keywords": "模态自适应, 视觉语言模型, 跨模态推理, 无需训练, 数据可视化", "comments": "MARVIS 的创新之处在于其“无需训练”和“模态自适应”的特性，通过将异构数据统一为视觉表示，巧妙地利用了现有视觉语言模型的强大推理能力。这提供了一个高效且通用的解决方案，尤其是在数据稀缺或隐私敏感的场景下具有重要意义。其性能超越大型基础模型，并接近专业模型，证明了其方法的有效性和潜力。"}}
{"id": "2507.01673", "title": "Facial Emotion Learning with Text-Guided Multiview Fusion via Vision-Language Model for 3D/4D Facial Expression Recognition", "authors": ["Muzammil Behzad"], "summary": "Facial expression recognition (FER) in 3D and 4D domains presents a\nsignificant challenge in affective computing due to the complexity of spatial\nand temporal facial dynamics. Its success is crucial for advancing applications\nin human behavior understanding, healthcare monitoring, and human-computer\ninteraction. In this work, we propose FACET-VLM, a vision-language framework\nfor 3D/4D FER that integrates multiview facial representation learning with\nsemantic guidance from natural language prompts. FACET-VLM introduces three key\ncomponents: Cross-View Semantic Aggregation (CVSA) for view-consistent fusion,\nMultiview Text-Guided Fusion (MTGF) for semantically aligned facial emotions,\nand a multiview consistency loss to enforce structural coherence across views.\nOur model achieves state-of-the-art accuracy across multiple benchmarks,\nincluding BU-3DFE, Bosphorus, BU-4DFE, and BP4D-Spontaneous. We further extend\nFACET-VLM to 4D micro-expression recognition (MER) on the 4DME dataset,\ndemonstrating strong performance in capturing subtle, short-lived emotional\ncues. The extensive experimental results confirm the effectiveness and\nsubstantial contributions of each individual component within the framework.\nOverall, FACET-VLM offers a robust, extensible, and high-performing solution\nfor multimodal FER in both posed and spontaneous settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01673v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01673v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于视觉-语言模型，通过文本引导多视图融合进行3D/4D面部表情识别的面部情感学习", "tldr": "提出FACET-VLM框架，利用文本引导多视图融合和视觉-语言模型，实现3D/4D面部表情识别的SOTA性能，并扩展到微表情识别。", "motivation": "3D和4D面部表情识别（FER）在情感计算中面临挑战，但其成功对于推进人类行为理解、医疗健康监测和人机交互等应用至关重要。", "method": "本文提出了FACET-VLM，一个用于3D/4D面部表情识别的视觉-语言框架，它通过自然语言提示的语义指导整合了多视图面部表示学习。FACET-VLM引入了三个关键组件：用于视图一致性融合的跨视图语义聚合（CVSA）、用于语义对齐面部情感的多视图文本引导融合（MTGF），以及用于强制跨视图结构一致性的多视图一致性损失。", "result": "模型在BU-3DFE、Bosphorus、BU-4DFE和BP4D-Spontaneous等多个基准测试中实现了最先进的准确性。FACET-VLM还扩展到4DME数据集上的4D微表情识别（MER），在捕捉细微、短暂的情感线索方面表现出强大的性能。广泛的实验结果证实了框架内每个独立组件的有效性和实质性贡献。", "conclusion": "FACET-VLM为姿态和自发设置下的多模态面部表情识别提供了一个鲁棒、可扩展且高性能的解决方案。", "translation": "面部表情识别（FER）在3D和4D领域中，由于空间和时间面部动态的复杂性，在情感计算中提出了重大挑战。它的成功对于推进人类行为理解、医疗健康监测和人机交互等应用至关重要。在这项工作中，我们提出了FACET-VLM，一个用于3D/4D FER的视觉-语言框架，它将多视图面部表示学习与自然语言提示的语义指导相结合。FACET-VLM引入了三个关键组件：用于视图一致性融合的跨视图语义聚合（CVSA）、用于语义对齐面部情感的多视图文本引导融合（MTGF），以及用于强制跨视图结构一致性的多视图一致性损失。我们的模型在多个基准测试中实现了最先进的准确性，包括BU-3DFE、Bosphorus、BU-4DFE和BP4D-Spontaneous。我们进一步将FACET-VLM扩展到4DME数据集上的4D微表情识别（MER），在捕捉细微、短暂的情感线索方面表现出强大的性能。广泛的实验结果证实了框架内每个独立组件的有效性和实质性贡献。总的来说，FACET-VLM为姿态和自发设置下的多模态FER提供了一个鲁棒、可扩展且高性能的解决方案。", "summary": "本文提出FACET-VLM，一个创新的视觉-语言框架，用于解决3D/4D面部表情识别的挑战。该框架通过结合多视图面部表示学习和自然语言提示的语义指导，实现了对复杂面部动态的精确识别。FACET-VLM包含跨视图语义聚合、多视图文本引导融合和多视图一致性损失三个核心组件，确保了视图间的一致性和语义对齐。实验证明，FACET-VLM在多个标准数据集上均取得了最先进的性能，并成功扩展到微表情识别，为多模态面部表情识别提供了鲁棒且高性能的解决方案。", "keywords": "面部表情识别, 视觉-语言模型, 多视图融合, 3D/4D, 微表情识别", "comments": "该论文的创新点在于将视觉-语言模型引入3D/4D面部表情识别领域，并利用文本提示进行语义引导，这为复杂多模态数据的处理提供了新思路。多视图融合策略结合语义一致性损失，有效解决了3D/4D数据固有的复杂性和视图一致性问题。其在多个基准数据集上达到SOTA性能，并能处理微表情，显示了该框架的强大泛化能力和实用价值。"}}
{"id": "2507.01806", "title": "LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs", "authors": ["Reza Arabpour", "Haitz Sáez de Ocáriz Borde", "Anastasis Kratsios"], "summary": "Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language\nModels (LLMs) by enabling parameter-efficient updates. However, their\nwidespread adoption remains limited by the reliance on GPU-based training. In\nthis work, we propose a theoretically grounded approach to LoRA fine-tuning\ndesigned specifically for users with limited computational resources,\nparticularly those restricted to standard laptop CPUs. Our method learns a\nmeta-operator that maps any input dataset, represented as a probability\ndistribution, to a set of LoRA weights by leveraging a large bank of\npre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of\nperforming new gradient-based updates, our pipeline constructs adapters via\nlightweight combinations of existing LoRAs directly on CPU. While the resulting\nadapters do not match the performance of GPU-trained counterparts, they\nconsistently outperform the base Mistral model on downstream tasks, offering a\npractical and accessible alternative to traditional GPU-based fine-tuning.", "comment": "5-page main paper (excluding references) + 11-page appendix, 3\n  tables, 1 figure. Accepted to ICML 2025 Workshop on Efficient Systems for\n  Foundation Models", "pdf_url": "http://arxiv.org/pdf/2507.01806v1", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01806v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "无需GPU的LoRA微调：面向LLM的CPU高效元生成框架", "tldr": "本文提出了一种无需GPU，仅在CPU上通过元操作符和现有LoRA组合来微调大型语言模型LoRA的方法，为资源受限用户提供实用选择。", "motivation": "LoRA微调技术因依赖GPU训练而限制了其广泛应用，本文旨在为计算资源有限（特别是仅限于标准笔记本CPU）的用户提供一种解决方案。", "method": "本文提出了一种理论上可靠的LoRA微调方法，该方法学习一个元操作符，将任何输入数据集（表示为概率分布）映射到一组LoRA权重。它利用大量预训练的Mistral-7B-Instruct-v0.2模型适配器，通过现有LoRA的轻量级组合直接在CPU上构建适配器，而不是执行新的基于梯度的更新。", "result": "虽然生成的适配器性能不如GPU训练的对应物，但它们在下游任务上始终优于基础Mistral模型。", "conclusion": "本文提出的方法为传统基于GPU的微调提供了一种实用且可访问的替代方案，尤其适用于计算资源有限的用户。", "translation": "低秩适配器（LoRA）通过实现参数高效更新，改变了大型语言模型（LLM）的微调方式。然而，它们广泛采用仍受限于对基于GPU训练的依赖。在这项工作中，我们提出了一种理论上可靠的LoRA微调方法，专门为计算资源有限的用户设计，特别是那些仅限于标准笔记本CPU的用户。我们的方法通过利用大量预训练的Mistral-7B-Instruct-v0.2模型适配器，学习一个元操作符，将任何输入数据集（表示为概率分布）映射到一组LoRA权重。我们的流水线不是执行新的基于梯度的更新，而是通过现有LoRA的轻量级组合直接在CPU上构建适配器。虽然生成的适配器性能不如GPU训练的对应物，但它们在下游任务上始终优于基础Mistral模型，为传统的基于GPU的微调提供了一种实用且可访问的替代方案。", "summary": "本文提出了一种创新的LoRA微调框架，专门针对无GPU环境，特别是标准CPU。该方法通过学习一个元操作符，利用现有的大量预训练LoRA适配器，在CPU上通过轻量级组合生成新的LoRA权重，从而避免了传统的基于梯度的GPU训练。尽管其性能略低于GPU训练的模型，但该方法在下游任务上显著优于基础模型，为资源受限的用户提供了一个实用且可行的LLM微调解决方案。", "keywords": "LoRA微调, CPU高效, 大型语言模型, 元学习, 资源受限", "comments": "这项工作的创新之处在于提出了一个CPU高效的LoRA元生成框架，显著降低了LLM微调的硬件门槛，使得普通用户也能进行模型适配。其重要性在于推动了LLM技术的普及和可访问性。然而，其局限性在于性能仍无法与GPU训练的LoRA匹敌，这可能限制其在对性能要求极高的场景中的应用。"}}
{"id": "2507.01711", "title": "Component Adaptive Clustering for Generalized Category Discovery", "authors": ["Mingfu Yan", "Jiancheng Huang", "Yifan Liu", "Shifeng Chen"], "summary": "Generalized Category Discovery (GCD) tackles the challenging problem of\ncategorizing unlabeled images into both known and novel classes within a\npartially labeled dataset, without prior knowledge of the number of unknown\ncategories. Traditional methods often rely on rigid assumptions, such as\npredefining the number of classes, which limits their ability to handle the\ninherent variability and complexity of real-world data. To address these\nshortcomings, we propose AdaGCD, a cluster-centric contrastive learning\nframework that incorporates Adaptive Slot Attention (AdaSlot) into the GCD\nframework. AdaSlot dynamically determines the optimal number of slots based on\ndata complexity, removing the need for predefined slot counts. This adaptive\nmechanism facilitates the flexible clustering of unlabeled data into known and\nnovel categories by dynamically allocating representational capacity. By\nintegrating adaptive representation with dynamic slot allocation, our method\ncaptures both instance-specific and spatially clustered features, improving\nclass discovery in open-world scenarios. Extensive experiments on public and\nfine-grained datasets validate the effectiveness of our framework, emphasizing\nthe advantages of leveraging spatial local information for category discovery\nin unlabeled image datasets.", "comment": "Accepted by IEEE ICME 2025", "pdf_url": "http://arxiv.org/pdf/2507.01711v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01711v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "用于广义类别发现的组件自适应聚类", "tldr": "AdaGCD通过自适应槽位注意力进行广义类别发现，无需预设类别数量，效果优于传统方法。", "motivation": "传统的广义类别发现（GCD）方法依赖于僵化假设，如预定义类别数量，这限制了它们处理真实世界数据变异性和复杂性的能力。", "method": "提出AdaGCD，一个以聚类为中心的对比学习框架，它将自适应槽位注意力（AdaSlot）整合到GCD框架中。AdaSlot根据数据复杂度动态确定最佳槽位数量，无需预设槽位计数，并能捕获实例特定和空间聚类的特征。", "result": "在公共和细粒度数据集上的大量实验验证了该框架的有效性，强调了利用空间局部信息进行未标记图像数据集中类别发现的优势。", "conclusion": "所提出的AdaGCD框架通过动态分配表示能力和利用空间局部信息，有效改进了开放世界场景下广义类别发现的类别发现能力。", "translation": "广义类别发现（GCD）解决了在部分标记数据集中对未标记图像进行已知和新颖类别分类的挑战性问题，而无需预先了解未知类别的数量。传统方法通常依赖于僵化假设，例如预定义类别数量，这限制了它们处理真实世界数据固有的变异性和复杂性的能力。为了解决这些缺点，我们提出了AdaGCD，一个以聚类为中心的对比学习框架，它将自适应槽位注意力（AdaSlot）整合到GCD框架中。AdaSlot根据数据复杂度动态确定最佳槽位数量，无需预设槽位计数。这种自适应机制通过动态分配表示能力，促进了未标记数据向已知和新颖类别的灵活聚类。通过将自适应表示与动态槽位分配相结合，我们的方法捕获了实例特定和空间聚类的特征，从而改进了开放世界场景中的类别发现。在公共和细粒度数据集上进行的大量实验验证了我们框架的有效性，强调了在未标记图像数据集中利用空间局部信息进行类别发现的优势。", "summary": "AdaGCD是一种新颖的以聚类为中心的对比学习框架，用于广义类别发现（GCD）。它采用自适应槽位注意力（AdaSlot）来动态确定最佳聚类数量，克服了传统方法需要预定义类别计数的局限性。通过捕获实例特定和空间聚类的特征，AdaGCD显著改善了未标记图像数据集中的类别发现能力，并在大量实验中得到了验证。", "keywords": "广义类别发现, 自适应槽位注意力, 对比学习, 未标记数据, 图像聚类", "comments": "该论文的创新点在于AdaSlot能够动态确定聚类数量，解决了传统方法需要预设类别数量的显著局限性。这种自适应机制使得该方法在处理类别数量未知且复杂的真实世界数据集时更具鲁棒性和适用性。此外，利用空间局部信息也是其一个重要优势。"}}
{"id": "2507.01559", "title": "How Weight Resampling and Optimizers Shape the Dynamics of Continual Learning and Forgetting in Neural Networks", "authors": ["Lapo Frati", "Neil Traft", "Jeff Clune", "Nick Cheney"], "summary": "Recent work in continual learning has highlighted the beneficial effect of\nresampling weights in the last layer of a neural network (``zapping\"). Although\nempirical results demonstrate the effectiveness of this approach, the\nunderlying mechanisms that drive these improvements remain unclear. In this\nwork, we investigate in detail the pattern of learning and forgetting that take\nplace inside a convolutional neural network when trained in challenging\nsettings such as continual learning and few-shot transfer learning, with\nhandwritten characters and natural images. Our experiments show that models\nthat have undergone zapping during training more quickly recover from the shock\nof transferring to a new domain. Furthermore, to better observe the effect of\ncontinual learning in a multi-task setting we measure how each individual task\nis affected. This shows that, not only zapping, but the choice of optimizer can\nalso deeply affect the dynamics of learning and forgetting, causing complex\npatterns of synergy/interference between tasks to emerge when the model learns\nsequentially at transfer time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01559v1", "categories": ["cs.LG", "cs.CV"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01559v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "权重重采样和优化器如何影响神经网络中持续学习和遗忘的动态", "tldr": "本文研究了权重重采样（“zapping”）和优化器选择如何深刻影响神经网络在持续学习和少样本迁移学习中的学习和遗忘动态。", "motivation": "尽管权重重采样（“zapping”）在持续学习中显示出益处，但其背后的机制尚不清楚。", "method": "本文详细研究了卷积神经网络在持续学习和少样本迁移学习等挑战性设置下，使用手写字符和自然图像进行训练时的学习和遗忘模式，并测量了每个单独任务受到的影响。", "result": "实验表明，经过zapping的模型在转移到新领域时能更快恢复。此外，优化器的选择也能深刻影响学习和遗忘的动态，导致任务之间出现复杂的协同/干扰模式。", "conclusion": "权重重采样（“zapping”）和优化器的选择是影响神经网络持续学习和遗忘动态的关键因素，它们共同决定了多任务学习中的任务间交互模式。", "translation": "近期在持续学习方面的研究强调了对神经网络最后一层权重进行重采样（“zapping”）的益处。尽管实证结果证明了这种方法的有效性，但驱动这些改进的潜在机制仍不清楚。在这项工作中，我们详细研究了在持续学习和少样本迁移学习等挑战性设置下，当卷积神经网络使用手写字符和自然图像进行训练时，内部发生的学习和遗忘模式。我们的实验表明，在训练过程中经过zapping的模型在转移到新领域时能更快地从冲击中恢复。此外，为了更好地观察多任务设置中持续学习的效果，我们测量了每个单独任务受到的影响。这表明，不仅是zapping，优化器的选择也能深刻影响学习和遗忘的动态，导致当模型在迁移时序贯序学习时，任务之间出现复杂的协同/干扰模式。", "summary": "本文深入探讨了权重重采样（“zapping”）和优化器选择对神经网络在持续学习和少样本迁移学习中学习与遗忘动态的影响。研究发现，zapping能帮助模型更快适应新领域，且优化器选择同样关键，两者共同决定了多任务学习中任务间的复杂协同与干扰模式。", "keywords": "持续学习, 权重重采样, 优化器, 遗忘, 神经网络", "comments": "这篇论文通过深入分析权重重采样和优化器在持续学习中的作用，揭示了其对学习和遗忘动态的深远影响。其创新之处在于不仅验证了zapping的有效性，更进一步探究了其潜在机制以及优化器在此过程中的关键作用，为理解和优化持续学习提供了新的视角。"}}
{"id": "2507.01951", "title": "Test-Time Scaling with Reflective Generative Model", "authors": ["Zixiao Wang", "Yuxin Wang", "Xiaorui Wang", "Mengting Xing", "Jie Gao", "Jianjun Xu", "Guangcan Liu", "Chenhui Jin", "Zhuo Wang", "Shengzhuo Zhang", "Hongtao Xie"], "summary": "We introduce our first reflective generative model MetaStone-S1, which\nobtains OpenAI o3's performance via the self-supervised process reward model\n(SPRM). Through sharing the backbone network and using task-specific heads for\nnext token prediction and process scoring respectively, SPRM successfully\nintegrates the policy model and process reward model(PRM) into a unified\ninterface without extra process annotation, reducing over 99% PRM parameters\nfor efficient reasoning. Equipped with SPRM, MetaStone-S1 is naturally suitable\nfor test time scaling (TTS), and we provide three reasoning effort modes (low,\nmedium, and high), based on the controllable thinking length. Moreover, we\nempirically establish a scaling law that reveals the relationship between total\nthinking computation and TTS performance. Experiments demonstrate that our\nMetaStone-S1 achieves comparable performance to OpenAI-o3-mini's series with\nonly 32B parameter size. To support the research community, we have\nopen-sourced MetaStone-S1 at https://github.com/MetaStone-AI/MetaStone-S1.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01951v1", "categories": ["cs.LG", "cs.CL"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01951v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "测试时缩放与反射生成模型", "tldr": "引入了MetaStone-S1，一个通过自监督过程奖励模型（SPRM）实现高效推理和测试时缩放的反射生成模型，在32B参数规模下达到与OpenAI-o3-mini系列相当的性能。", "motivation": "该研究旨在开发一个能够实现高效推理并支持测试时缩放的生成模型，通过引入自监督过程奖励模型（SPRM）来大幅减少过程奖励模型（PRM）的参数量，同时保持与大型模型（如OpenAI o3）相当的性能。", "method": "该论文引入了MetaStone-S1，一个反射生成模型，它使用自监督过程奖励模型（SPRM）。SPRM通过共享骨干网络并使用特定任务头部进行下一词元预测和过程评分，将策略模型和过程奖励模型（PRM）集成到一个统一的接口中，无需额外过程标注，从而将PRM参数减少了99%以上。MetaStone-S1还支持基于可控思维长度的三种推理工作量模式（低、中、高），并建立了总思维计算量与测试时缩放（TTS）性能之间的缩放定律。", "result": "MetaStone-S1通过SPRM获得了OpenAI o3的性能，并将过程奖励模型（PRM）的参数减少了99%以上。实验表明，MetaStone-S1在仅32B的参数规模下，实现了与OpenAI-o3-mini系列相当的性能。", "conclusion": "MetaStone-S1是一个高效且性能强大的反射生成模型，它通过创新的自监督过程奖励模型（SPRM）实现了参数的显著减少和高效推理，并在测试时缩放方面表现出色，证明了在较小模型规模下也能达到与大型模型相当的性能。", "translation": "我们引入了我们的第一个反射生成模型MetaStone-S1，它通过自监督过程奖励模型（SPRM）获得了OpenAI o3的性能。通过共享骨干网络并分别使用特定任务头部进行下一词元预测和过程评分，SPRM成功地将策略模型和过程奖励模型（PRM）集成到一个统一的接口中，无需额外过程标注，从而将PRM参数减少了99%以上，实现了高效推理。配备SPRM后，MetaStone-S1自然适用于测试时缩放（TTS），我们基于可控思维长度提供了三种推理工作量模式（低、中、高）。此外，我们通过实验建立了一个缩放定律，揭示了总思维计算量与TTS性能之间的关系。实验表明，我们的MetaStone-S1在仅32B参数规模下，实现了与OpenAI-o3-mini系列相当的性能。为了支持研究社区，我们已将MetaStone-S1开源在https://github.com/MetaStone-AI/MetaStone-S1。", "summary": "该论文提出了MetaStone-S1，一个反射生成模型，它利用自监督过程奖励模型（SPRM）实现了高效推理和测试时缩放。SPRM通过集成策略模型和PRM并大幅减少参数量（超过99%）来优化推理效率。MetaStone-S1能够通过可控思维长度提供不同推理工作量模式，并展示了其在32B参数规模下达到与OpenAI-o3-mini系列相当的性能，同时还建立了一个关于总思维计算量与TTS性能的缩放定律。", "keywords": "反射生成模型, 自监督过程奖励模型, 测试时缩放, 高效推理, 缩放定律", "comments": "MetaStone-S1的创新点在于其自监督过程奖励模型（SPRM）的设计，它巧妙地将策略模型和PRM集成，并在无额外标注的情况下实现了PRM参数的巨大削减，显著提升了推理效率。该模型在较小的参数规模（32B）下达到了与大型模型相当的性能，这对于资源受限的部署场景具有重要意义。此外，引入可控思维长度和建立缩放定律为模型的可控性和未来研究提供了新的视角。"}}
{"id": "2507.01411", "title": "Age Sensitive Hippocampal Functional Connectivity: New Insights from 3D CNNs and Saliency Mapping", "authors": ["Yifei Sun", "Marshall A. Dalton", "Robert D. Sanders", "Yixuan Yuan", "Xiang Li", "Sharon L. Naismith", "Fernando Calamante", "Jinglei Lv"], "summary": "Grey matter loss in the hippocampus is a hallmark of neurobiological aging,\nyet understanding the corresponding changes in its functional connectivity\nremains limited. Seed-based functional connectivity (FC) analysis enables\nvoxel-wise mapping of the hippocampus's synchronous activity with cortical\nregions, offering a window into functional reorganization during aging. In this\nstudy, we develop an interpretable deep learning framework to predict brain age\nfrom hippocampal FC using a three-dimensional convolutional neural network (3D\nCNN) combined with LayerCAM saliency mapping. This approach maps key\nhippocampal-cortical connections, particularly with the precuneus, cuneus,\nposterior cingulate cortex, parahippocampal cortex, left superior parietal\nlobule, and right superior temporal sulcus, that are highly sensitive to age.\nCritically, disaggregating anterior and posterior hippocampal FC reveals\ndistinct mapping aligned with their known functional specializations. These\nfindings provide new insights into the functional mechanisms of hippocampal\naging and demonstrate the power of explainable deep learning to uncover\nbiologically meaningful patterns in neuroimaging data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01411v1", "categories": ["q-bio.NC", "cs.AI", "cs.CV"], "cate": "q-bio.NC", "url": "http://arxiv.org/abs/2507.01411v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "年龄敏感的海马功能连接：来自3D CNN和显著性映射的新见解", "tldr": "本研究利用3D CNN和LayerCAM显著性映射，通过分析海马功能连接来预测脑龄，并识别出与年龄高度相关的关键海马-皮层连接，同时揭示了海马前后部连接模式的差异，为理解海马老化机制提供了新见解。", "motivation": "尽管海马灰质损失是神经生物学老化的标志，但对其功能连接相应变化的理解仍然有限。", "method": "开发了一个可解释的深度学习框架，使用三维卷积神经网络（3D CNN）结合LayerCAM显著性映射，从海马功能连接（FC）预测脑龄。该方法还区分了海马前后部的FC。", "result": "该方法映射出与年龄高度敏感的关键海马-皮层连接，特别是与楔前叶、楔叶、后扣带皮层、海马旁回、左顶上小叶和右颞上沟的连接。重要的是，区分海马前后部FC揭示了与其已知功能特化一致的独特映射。", "conclusion": "这些发现为海马老化的功能机制提供了新见解，并展示了可解释深度学习在揭示神经影像数据中具有生物学意义模式方面的强大能力。", "translation": "海马体的灰质损失是神经生物学老化的一个标志，但对其功能连接相应变化的理解仍然有限。基于种子点的功能连接（FC）分析能够对海马体与皮层区域的同步活动进行体素级映射，为老化过程中的功能重组提供了一个窗口。在这项研究中，我们开发了一个可解释的深度学习框架，使用三维卷积神经网络（3D CNN）结合LayerCAM显著性映射，从海马FC预测脑龄。这种方法映射出与年龄高度敏感的关键海马-皮层连接，特别是与楔前叶、楔叶、后扣带皮层、海马旁回、左顶上小叶和右颞上沟的连接。重要的是，区分海马前后部的FC揭示了与其已知功能特化一致的独特映射。这些发现为海马老化的功能机制提供了新见解，并展示了可解释深度学习在揭示神经影像数据中具有生物学意义模式方面的强大能力。", "summary": "本研究开发了一个基于3D CNN和LayerCAM显著性映射的可解释深度学习框架，利用海马功能连接预测脑龄。研究识别出多个与年龄高度相关的海马-皮层连接，并揭示了海马前后部功能连接的差异模式。这些发现加深了对海马老化机制的理解，并展示了可解释深度学习在神经影像分析中的潜力。", "keywords": "海马功能连接, 3D CNN, 显著性映射, 脑龄预测, 神经老化", "comments": "该研究的创新之处在于结合了3D CNN和LayerCAM显著性映射来分析海马功能连接与年龄的关系，提供了可解释的深度学习方法来揭示生物学意义的模式。其重要性在于为理解神经老化过程中的海马功能重组提供了新视角，并证明了可解释AI在神经科学研究中的应用价值。"}}
{"id": "2507.01721", "title": "Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation", "authors": ["Zhongwen Zhang", "Yuri Boykov"], "summary": "We consider weakly supervised segmentation where only a fraction of pixels\nhave ground truth labels (scribbles) and focus on a self-labeling approach\noptimizing relaxations of the standard unsupervised CRF/Potts loss on unlabeled\npixels. While WSSS methods can directly optimize such losses via gradient\ndescent, prior work suggests that higher-order optimization can improve network\ntraining by introducing hidden pseudo-labels and powerful CRF sub-problem\nsolvers, e.g. graph cut. However, previously used hard pseudo-labels can not\nrepresent class uncertainty or errors, which motivates soft self-labeling. We\nderive a principled auxiliary loss and systematically evaluate standard and new\nCRF relaxations (convex and non-convex), neighborhood systems, and terms\nconnecting network predictions with soft pseudo-labels. We also propose a\ngeneral continuous sub-problem solver. Using only standard architectures, soft\nself-labeling consistently improves scribble-based training and outperforms\nsignificantly more complex specialized WSSS systems. It can outperform full\npixel-precise supervision. Our general ideas apply to other weakly-supervised\nproblems/systems.", "comment": "published at CVPR 2025", "pdf_url": "http://arxiv.org/pdf/2507.01721v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01721v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "弱监督分割中的软自标记和Potts松弛", "tldr": "本文提出了一种软自标记方法，结合Potts松弛，显著提升了弱监督图像分割的性能，甚至超越了全监督方法。", "motivation": "以往的硬伪标签无法表示类别不确定性或错误，因此需要提出软自标记方法。", "method": "本文提出了一种软自标记方法，通过优化无标签像素上的标准无监督CRF/Potts损失的松弛来解决弱监督分割问题。该方法引入了一种原则性的辅助损失，并系统地评估了标准和新的CRF松弛（凸和非凸）、邻域系统以及连接网络预测与软伪标签的项。此外，还提出了一种通用的连续子问题求解器。", "result": "使用标准架构，软自标记持续改进了基于涂鸦的训练，并显著优于更复杂的专用WSSS系统。它甚至可以超越全像素精确监督的性能。", "conclusion": "本文提出的通用思想可以应用于其他弱监督问题/系统。", "translation": "我们考虑弱监督分割，其中只有一小部分像素具有真实标签（涂鸦），并专注于一种自标记方法，该方法优化了无标签像素上的标准无监督CRF/Potts损失的松弛。虽然WSSS方法可以通过梯度下降直接优化此类损失，但先前的研究表明，更高阶优化可以通过引入隐藏的伪标签和强大的CRF子问题求解器（例如图割）来改进网络训练。然而，以前使用的硬伪标签无法表示类别不确定性或错误，这促使了软自标记的出现。我们推导了一种原则性的辅助损失，并系统地评估了标准和新的CRF松弛（凸和非凸）、邻域系统以及连接网络预测与软伪标签的项。我们还提出了一种通用的连续子问题求解器。仅使用标准架构，软自标记持续改进了基于涂鸦的训练，并显著优于更复杂的专用WSSS系统。它甚至可以超越全像素精确监督的性能。我们的通用思想适用于其他弱监督问题/系统。", "summary": "本文提出了一种创新的软自标记方法，用于弱监督图像分割。该方法通过优化无标签像素上的CRF/Potts损失松弛，并引入一种原则性的辅助损失，克服了传统硬伪标签的局限性。实验证明，该方法在标准架构下显著提升了分割性能，甚至超越了复杂的专用系统和全像素精确监督。", "keywords": "弱监督分割, 自标记, Potts松弛, CRF, 图像分割", "comments": "该论文的创新点在于提出了“软自标记”的概念，解决了传统硬伪标签无法表示不确定性的问题。通过结合Potts松弛和新的子问题求解器，该方法在弱监督分割任务中取得了显著的性能提升，甚至超越了全监督方法，这表明了其在实际应用中的巨大潜力。其通用性也预示着该思想可以推广到其他弱监督学习问题。"}}
{"id": "2507.01598", "title": "Analysis of Muon's Convergence and Critical Batch Size", "authors": ["Naoki Sato", "Hiroki Naganuma", "Hideaki Iiduka"], "summary": "This paper presents a theoretical analysis of Muon, a new optimizer that\nleverages the inherent matrix structure of neural network parameters. We\nprovide convergence proofs for four practical variants of Muon: with and\nwithout Nesterov momentum, and with and without weight decay. We then show that\nadding weight decay leads to strictly tighter bounds on both the parameter and\ngradient norms, and we clarify the relationship between the weight decay\ncoefficient and the learning rate. Finally, we derive Muon's critical batch\nsize minimizing the stochastic first-order oracle (SFO) complexity, which is\nthe stochastic computational cost, and validate our theoretical findings with\nexperiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01598v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01598v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "Muon的收敛性与临界批次大小分析", "tldr": "本文对新型优化器Muon的收敛性进行了理论分析，包括其不同变体的收敛性证明、权重衰减的影响以及最小化计算成本的临界批次大小，并进行了实验验证。", "motivation": "本文旨在对新型优化器Muon进行理论分析，提供其收敛性证明，并理解权重衰减的影响以及如何确定最小化计算成本的临界批次大小。", "method": "本文为Muon的四种实际变体（带或不带Nesterov动量，带或不带权重衰减）提供了收敛性证明。研究了权重衰减对参数和梯度范数的影响，并阐明了其与学习率的关系。最后，推导了最小化随机一阶预言机（SFO）复杂度的Muon临界批次大小，并通过实验验证了理论发现。", "result": "为Muon的四种变体提供了收敛性证明。结果显示，添加权重衰减能使参数和梯度范数获得更严格的边界。阐明了权重衰减系数与学习率之间的关系。推导出了最小化SFO复杂度的Muon临界批次大小。理论发现得到了实验验证。", "conclusion": "本文全面理论地理解了Muon的收敛性、权重衰减的益处以及计算效率的最佳批次大小，并通过实验进行了验证。", "translation": "本文对Muon进行了理论分析，Muon是一种利用神经网络参数固有矩阵结构的新型优化器。我们为Muon的四种实际变体提供了收敛性证明：包括带和不带Nesterov动量，以及带和不带权重衰减的情况。然后，我们表明添加权重衰减可以在参数和梯度范数上带来更严格的边界，并阐明了权重衰减系数与学习率之间的关系。最后，我们推导了Muon最小化随机一阶预言机（SFO）复杂度的临界批次大小，即随机计算成本，并通过实验验证了我们的理论发现。", "summary": "本文对新型优化器Muon进行了深入的理论分析，详细阐述了其四种实际变体的收敛性证明，包括带或不带Nesterov动量以及带或不带权重衰减的情况。研究表明，权重衰减能够显著收紧参数和梯度范数的边界，并明确了其与学习率之间的关系。此外，文章还推导了最小化随机计算成本（SFO复杂度）的Muon临界批次大小，并通过实验验证了所有理论发现。", "keywords": "Muon, 优化器, 收敛性, 权重衰减, 批次大小", "comments": "该论文为新型优化器Muon提供了严谨的理论基础，具有重要意义。其创新之处在于利用了神经网络参数的矩阵结构，并为不同实际变体提供了详细的收敛性证明。对权重衰减影响的分析以及最佳批次大小的推导，对于Muon的实际应用和理解其效率至关重要。"}}
{"id": "2507.01413", "title": "Evaluating LLM Agent Collusion in Double Auctions", "authors": ["Kushal Agrawal", "Verona Teo", "Juan J. Vazquez", "Sudarsh Kunnavakkam", "Vishak Srikanth", "Andy Liu"], "summary": "Large language models (LLMs) have demonstrated impressive capabilities as\nautonomous agents with rapidly expanding applications in various domains. As\nthese agents increasingly engage in socioeconomic interactions, identifying\ntheir potential for undesirable behavior becomes essential. In this work, we\nexamine scenarios where they can choose to collude, defined as secretive\ncooperation that harms another party. To systematically study this, we\ninvestigate the behavior of LLM agents acting as sellers in simulated\ncontinuous double auction markets. Through a series of controlled experiments,\nwe analyze how parameters such as the ability to communicate, choice of model,\nand presence of environmental pressures affect the stability and emergence of\nseller collusion. We find that direct seller communication increases collusive\ntendencies, the propensity to collude varies across models, and environmental\npressures, such as oversight and urgency from authority figures, influence\ncollusive behavior. Our findings highlight important economic and ethical\nconsiderations for the deployment of LLM-based market agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01413v1", "categories": ["cs.GT", "cs.AI", "cs.LG"], "cate": "cs.GT", "url": "http://arxiv.org/abs/2507.01413v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "评估双重拍卖中大型语言模型代理的串通行为", "tldr": "本研究评估了大型语言模型（LLM）代理在模拟双重拍卖中进行串通的可能性及其影响因素，发现直接沟通会增加串通倾向，串通行为因模型而异，且环境压力会影响串通。", "motivation": "随着大型语言模型（LLM）作为自主代理在各种应用中日益增多，它们在社会经济互动中表现出潜在的不良行为（如串通）变得至关重要，因此需要系统地研究这种行为。", "method": "研究人员在模拟的连续双重拍卖市场中，将LLM代理作为卖家进行研究。通过一系列受控实验，分析了沟通能力、模型选择和环境压力（如监督和紧迫性）等参数如何影响卖家串通的稳定性和出现。", "result": "研究发现，直接的卖家沟通会增加串通倾向；不同模型的串通倾向各不相同；以及来自权威人物的监督和紧迫性等环境压力会影响串通行为。", "conclusion": "研究结果强调了部署基于LLM的市场代理时重要的经济和伦理考量。", "translation": "大型语言模型（LLM）作为自主代理已展现出令人印象深刻的能力，并在各个领域迅速扩展应用。随着这些代理越来越多地参与社会经济互动，识别其潜在的不良行为变得至关重要。在这项工作中，我们研究了它们可以选择串通的场景，串通被定义为秘密合作以损害另一方。为了系统地研究这一点，我们调查了作为卖家在模拟连续双重拍卖市场中LLM代理的行为。通过一系列受控实验，我们分析了诸如沟通能力、模型选择以及环境压力存在等参数如何影响卖家串通的稳定性与出现。我们发现，直接的卖家沟通会增加串通倾向，串通倾向因模型而异，并且环境压力，例如来自权威人物的监督和紧迫性，会影响串通行为。我们的研究结果强调了部署基于LLM的市场代理时重要的经济和伦理考量。", "summary": "本研究探讨了大型语言模型（LLM）代理在模拟双重拍卖市场中进行串通的可能性和影响因素。通过让LLM代理扮演卖家角色，并控制沟通、模型选择和环境压力等变量，研究发现直接沟通会增加串通倾向，不同LLM模型的串通倾向存在差异，且外部压力如监督和紧迫性会影响串通行为。研究结果强调了在部署LLM市场代理时需考虑的经济和伦理问题。", "keywords": "大型语言模型, 代理串通, 双重拍卖, 市场行为, 伦理考量", "comments": "本研究通过模拟市场环境，系统性地评估了LLM代理的串通行为，具有重要的创新性。其发现对于理解和规避未来AI驱动市场中的潜在不良行为，以及制定相关的监管和伦理准则具有重要意义。"}}
{"id": "2507.01722", "title": "When Does Pruning Benefit Vision Representations?", "authors": ["Enrico Cassano", "Riccardo Renzulli", "Andrea Bragagnolo", "Marco Grangetto"], "summary": "Pruning is widely used to reduce the complexity of deep learning models, but\nits effects on interpretability and representation learning remain poorly\nunderstood. This paper investigates how pruning influences vision models across\nthree key dimensions: (i) interpretability, (ii) unsupervised object discovery,\nand (iii) alignment with human perception. We first analyze different vision\nnetwork architectures to examine how varying sparsity levels affect feature\nattribution interpretability methods. Additionally, we explore whether pruning\npromotes more succinct and structured representations, potentially improving\nunsupervised object discovery by discarding redundant information while\npreserving essential features. Finally, we assess whether pruning enhances the\nalignment between model representations and human perception, investigating\nwhether sparser models focus on more discriminative features similarly to\nhumans. Our findings also reveal the presence of sweet spots, where sparse\nmodels exhibit higher interpretability, downstream generalization and human\nalignment. However, these spots highly depend on the network architectures and\ntheir size in terms of trainable parameters. Our results suggest a complex\ninterplay between these three dimensions, highlighting the importance of\ninvestigating when and how pruning benefits vision representations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01722v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01722v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "剪枝何时能使视觉表征受益？", "tldr": "剪枝被广泛用于降低深度学习模型的复杂性，但其对可解释性、无监督对象发现和人类对齐的影响仍不明确。本文研究了剪枝如何从这三个维度影响视觉模型，发现稀疏模型在某些“最佳点”表现出更高的可解释性、下游泛化能力和人类对齐，但这些最佳点高度依赖于网络架构和其规模。", "motivation": "剪枝被广泛用于降低深度学习模型的复杂性，但其对模型可解释性和表征学习的影响仍然知之甚少。本文旨在深入探究剪枝如何从可解释性、无监督对象发现以及与人类感知的对齐这三个关键维度影响视觉模型。", "method": "本文通过分析不同的视觉网络架构，研究不同稀疏度水平如何影响特征归因可解释性方法。此外，探讨了剪枝是否能促进更简洁和结构化的表征，从而改善无监督对象发现。最后，评估了剪枝是否能增强模型表征与人类感知之间的对齐，即稀疏模型是否更关注判别性特征。", "result": "研究发现存在“最佳点”，在此稀疏模型表现出更高的可解释性、下游泛化能力和与人类的对齐。然而，这些最佳点高度依赖于网络架构及其可训练参数的大小。", "conclusion": "剪枝对视觉模型的解释性、无监督对象发现和人类对齐之间存在复杂的相互作用。研究剪枝何时以及如何使视觉表征受益至关重要。", "translation": "剪枝被广泛用于降低深度学习模型的复杂性，但其对可解释性和表征学习的影响仍然知之甚少。本文研究了剪枝如何从三个关键维度影响视觉模型：(i) 可解释性，(ii) 无监督对象发现，以及 (iii) 与人类感知的对齐。我们首先分析不同的视觉网络架构，以检查不同稀疏度水平如何影响特征归因可解释性方法。此外，我们探讨了剪枝是否促进了更简洁和结构化的表征，通过丢弃冗余信息同时保留基本特征来潜在地改善无监督对象发现。最后，我们评估了剪枝是否增强了模型表征与人类感知之间的对齐，调查稀疏模型是否像人类一样关注更多判别性特征。我们的发现还揭示了“最佳点”的存在，在这些点上，稀疏模型表现出更高的可解释性、下游泛化能力和与人类的对齐。然而，这些最佳点高度依赖于网络架构及其可训练参数的大小。我们的结果表明这三个维度之间存在复杂的相互作用，强调了研究剪枝何时以及如何使视觉表征受益的重要性。", "summary": "本文探讨了剪枝对视觉模型可解释性、无监督对象发现以及与人类感知对齐的影响，这些方面此前研究不足。通过分析不同网络架构和稀疏度，研究发现剪枝可以带来“最佳点”，提高模型的可解释性、泛化能力和与人类的对齐。然而，这些益处高度依赖于网络架构和规模，表明剪枝与视觉表征之间存在复杂关系。", "keywords": "剪枝, 视觉表征, 可解释性, 无监督对象发现, 人类感知", "comments": "该论文解决了对剪枝理解的一个关键空白，超越了单纯的复杂性降低，探讨了其对表示质量和与人类感知对齐的影响。对“最佳点”及其对架构依赖的发现为未来的剪枝策略提供了宝贵的见解，推动剪枝从简单的效率提升转向更定性的优势。"}}
{"id": "2507.01644", "title": "Dance Dance ConvLSTM", "authors": ["Miguel O'Malley"], "summary": "\\textit{Dance Dance Revolution} is a rhythm game consisting of songs and\naccompanying choreography, referred to as charts. Players press arrows on a\ndevice referred to as a dance pad in time with steps determined by the song's\nchart. In 2017, the authors of Dance Dance Convolution (DDC) developed an\nalgorithm for the automatic generation of \\textit{Dance Dance Revolution}\ncharts, utilizing a CNN-LSTM architecture. We introduce Dance Dance ConvLSTM\n(DDCL), a new method for the automatic generation of DDR charts using a\nConvLSTM based model, which improves upon the DDC methodology and substantially\nincreases the accuracy of chart generation.", "comment": "15 pages, 9 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.01644v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01644v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "舞力全开 ConvLSTM", "tldr": "提出一种基于ConvLSTM的DDR舞谱自动生成新方法，显著提高了生成精度。", "motivation": "现有DDR舞谱自动生成算法Dance Dance Convolution (DDC) 使用CNN-LSTM架构，但仍有提升空间。本文旨在改进DDC方法，提高舞谱生成的准确性。", "method": "引入Dance Dance ConvLSTM (DDCL)，这是一种使用基于ConvLSTM模型的新方法，用于自动生成DDR舞谱。", "result": "显著提高了舞谱生成的准确性。", "conclusion": "基于ConvLSTM的模型能够有效改进DDR舞谱的自动生成精度。", "translation": "《舞力全开》是一款节奏游戏，包含歌曲和伴随的编舞（称为舞谱）。玩家根据歌曲的舞谱确定的步数，及时按下舞蹈垫上的箭头。2017年，《舞力全开卷积》（DDC）的作者开发了一种利用CNN-LSTM架构自动生成《舞力全开》舞谱的算法。我们引入了舞力全开ConvLSTM（DDCL），这是一种使用基于ConvLSTM模型自动生成DDR舞谱的新方法，它改进了DDC方法并显著提高了舞谱生成的准确性。", "summary": "本文介绍了Dance Dance ConvLSTM (DDCL)，一种利用ConvLSTM模型自动生成《舞力全开》 (DDR) 舞谱的新方法。该方法改进了此前Dance Dance Convolution (DDC) 算法的CNN-LSTM架构，并通过实验证明其能显著提高舞谱生成的准确性。", "keywords": "舞力全开, ConvLSTM, 舞谱生成, 节奏游戏, 深度学习", "comments": "本文创新性地将ConvLSTM应用于DDR舞谱的自动生成，相较于前人的CNN-LSTM架构，ConvLSTM能够更好地处理时空序列数据，从而提升生成质量。其重要性在于为节奏游戏内容创作提供了更高效、准确的自动化工具。"}}
{"id": "2507.01737", "title": "HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion", "authors": ["Lin Wu", "Zhixiang Chen", "Jianglin Lan"], "summary": "Generating realistic 3D human-object interactions (HOIs) remains a\nchallenging task due to the difficulty of modeling detailed interaction\ndynamics. Existing methods treat human and object motions independently,\nresulting in physically implausible and causally inconsistent behaviors. In\nthis work, we present HOI-Dyn, a novel framework that formulates HOI generation\nas a driver-responder system, where human actions drive object responses. At\nthe core of our method is a lightweight transformer-based interaction dynamics\nmodel that explicitly predicts how objects should react to human motion. To\nfurther enforce consistency, we introduce a residual-based dynamics loss that\nmitigates the impact of dynamics prediction errors and prevents misleading\noptimization signals. The dynamics model is used only during training,\npreserving inference efficiency. Through extensive qualitative and quantitative\nexperiments, we demonstrate that our approach not only enhances the quality of\nHOI generation but also establishes a feasible metric for evaluating the\nquality of generated interactions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01737v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01737v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "HOI-Dyn: 学习人-物体运动扩散的交互动力学", "tldr": "HOI-Dyn提出了一种新的框架，通过建模人-物体交互动力学来生成更真实的三维人-物体交互，解决了现有方法的物理不合理和因果不一致问题。", "motivation": "生成逼真的三维人-物体交互（HOI）具有挑战性，因为难以建模详细的交互动力学。现有方法独立处理人与物体的运动，导致物理上不合理和因果不一致的行为。", "method": "HOI-Dyn将HOI生成公式化为驱动-响应系统，其中人类动作驱动物体响应。其核心是轻量级基于Transformer的交互动力学模型，明确预测物体如何对人类运动做出反应。为强制一致性，引入基于残差的动力学损失。该动力学模型仅在训练期间使用，以保持推理效率。", "result": "我们的方法不仅提高了HOI生成的质量，而且为评估生成交互的质量建立了一个可行的指标。", "conclusion": "HOI-Dyn通过建模人-物体交互动力学，能够生成更真实且物理一致的三维人-物体交互，并提供了一种新的评估方法。", "translation": "生成逼真的三维人-物体交互（HOI）仍然是一项具有挑战性的任务，因为难以建模详细的交互动力学。现有方法独立处理人与物体的运动，导致物理上不合理和因果不一致的行为。在这项工作中，我们提出了HOI-Dyn，一个新颖的框架，将HOI生成公式化为驱动-响应系统，其中人类动作驱动物体响应。我们方法的核心是一个轻量级的基于Transformer的交互动力学模型，它明确预测物体应该如何对人类运动做出反应。为了进一步强制一致性，我们引入了一种基于残差的动力学损失，以减轻动力学预测误差的影响并防止误导性优化信号。动力学模型仅在训练期间使用，保持了推理效率。通过广泛的定性和定量实验，我们证明了我们的方法不仅提高了HOI生成的质量，而且为评估生成交互的质量建立了一个可行的指标。", "summary": "HOI-Dyn是一个新颖的框架，旨在解决现有方法在生成逼真三维人-物体交互时存在的物理不合理和因果不一致问题。它将HOI生成建模为驱动-响应系统，利用基于Transformer的交互动力学模型预测物体对人类运动的反应，并引入残差动力学损失确保一致性。该方法在训练阶段使用动力学模型，推理时保持高效，实验证明其能提升HOI生成质量并提供新的评估指标。", "keywords": "人-物体交互, 运动扩散, 交互动力学, 驱动-响应系统, 三维生成", "comments": "HOI-Dyn的创新之处在于将人-物体交互建模为驱动-响应系统，并引入了基于Transformer的交互动力学模型来显式预测物体响应，这有效解决了现有方法中物理不合理和因果不一致的问题。此外，其仅在训练阶段使用动力学模型，保证了推理效率，并且提出了评估生成交互质量的新指标，具有重要的实践意义。"}}
{"id": "2507.01649", "title": "GradMetaNet: An Equivariant Architecture for Learning on Gradients", "authors": ["Yoav Gelberg", "Yam Eitan", "Aviv Navon", "Aviv Shamsian", "Theo", "Putterman", "Michael Bronstein", "Haggai Maron"], "summary": "Gradients of neural networks encode valuable information for optimization,\nediting, and analysis of models. Therefore, practitioners often treat gradients\nas inputs to task-specific algorithms, e.g. for pruning or optimization. Recent\nworks explore learning algorithms that operate directly on gradients but use\narchitectures that are not specifically designed for gradient processing,\nlimiting their applicability. In this paper, we present a principled approach\nfor designing architectures that process gradients. Our approach is guided by\nthree principles: (1) equivariant design that preserves neuron permutation\nsymmetries, (2) processing sets of gradients across multiple data points to\ncapture curvature information, and (3) efficient gradient representation\nthrough rank-1 decomposition. Based on these principles, we introduce\nGradMetaNet, a novel architecture for learning on gradients, constructed from\nsimple equivariant blocks. We prove universality results for GradMetaNet, and\nshow that previous approaches cannot approximate natural gradient-based\nfunctions that GradMetaNet can. We then demonstrate GradMetaNet's effectiveness\non a diverse set of gradient-based tasks on MLPs and transformers, such as\nlearned optimization, INR editing, and estimating loss landscape curvature.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01649v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01649v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "GradMetaNet：一种用于梯度学习的等变架构", "tldr": "提出了一种名为GradMetaNet的新型等变架构，专门用于直接学习神经网络梯度，通过原则性设计解决了现有方法的局限性，并在多种梯度相关任务上表现出有效性。", "motivation": "神经网络梯度包含重要的优化、编辑和分析信息，但现有直接操作梯度的学习算法所用架构并非专门设计，限制了其适用性。本文旨在提出一种处理梯度架构的原则性方法。", "method": "该方法遵循三个原则：1) 保留神经元排列对称性的等变设计；2) 处理多个数据点上的梯度集以捕获曲率信息；3) 通过秩-1分解实现高效梯度表示。基于这些原则，引入了GradMetaNet，一个由简单等变块构成的新颖架构。", "result": "证明了GradMetaNet的普适性，并指出其能近似现有方法无法处理的基于自然梯度的函数。在MLP和Transformer上，GradMetaNet在学习优化、INR编辑和估计损失景观曲率等多种梯度相关任务中展现了有效性。", "conclusion": "本文提出了GradMetaNet，一种用于梯度学习的等变架构，其设计基于明确的原则，并在理论和实践中证明了其优于现有方法的性能和能力。", "translation": "神经网络的梯度编码了用于模型优化、编辑和分析的有价值信息。因此，实践者经常将梯度作为任务特定算法的输入，例如用于剪枝或优化。最近的工作探索了直接在梯度上操作的学习算法，但其使用的架构并非专门为梯度处理而设计，限制了其适用性。在本文中，我们提出了一种设计处理梯度架构的原则性方法。我们的方法遵循三个原则：(1) 保留神经元排列对称性的等变设计，(2) 处理多个数据点上的梯度集以捕获曲率信息，以及 (3) 通过秩-1分解实现高效的梯度表示。基于这些原则，我们引入了GradMetaNet，这是一种新颖的、用于梯度学习的架构，由简单的等变块构建而成。我们证明了GradMetaNet的普适性结果，并表明以前的方法无法近似GradMetaNet可以近似的基于自然梯度的函数。然后，我们通过在MLP和Transformer上执行各种基于梯度的任务，例如学习优化、INR编辑和估计损失景观曲率，展示了GradMetaNet的有效性。", "summary": "GradMetaNet是一种新颖的、等变架构，专为处理神经网络梯度而设计。它遵循三个原则：神经元排列对称性等变、处理多数据点梯度集以捕获曲率信息，以及通过秩-1分解进行高效表示。该架构在理论上被证明具有普适性，并能近似现有方法无法处理的基于梯度的函数。实验证明，GradMetaNet在学习优化、INR编辑和估计损失景观曲率等任务上表现出色。", "keywords": "梯度, 等变架构, GradMetaNet, 学习优化, 曲率估计", "comments": "该论文的创新之处在于提出了一种原则性的方法来设计专门处理梯度的等变架构，解决了现有方法在梯度处理方面的局限性。通过引入GradMetaNet，并在理论上证明其普适性和优越性，以及在实践中展示其在多种梯度相关任务上的有效性，显示了其重要性。"}}
{"id": "2507.01738", "title": "DeRIS: Decoupling Perception and Cognition for Enhanced Referring Image Segmentation through Loopback Synergy", "authors": ["Ming Dai", "Wenxuan Cheng", "Jiang-jiang Liu", "Sen Yang", "Wenxiao Cai", "Yanpeng Sun", "Wankou Yang"], "summary": "Referring Image Segmentation (RIS) is a challenging task that aims to segment\nobjects in an image based on natural language expressions. While prior studies\nhave predominantly concentrated on improving vision-language interactions and\nachieving fine-grained localization, a systematic analysis of the fundamental\nbottlenecks in existing RIS frameworks remains underexplored. To bridge this\ngap, we propose DeRIS, a novel framework that decomposes RIS into two key\ncomponents: perception and cognition. This modular decomposition facilitates a\nsystematic analysis of the primary bottlenecks impeding RIS performance. Our\nfindings reveal that the predominant limitation lies not in perceptual\ndeficiencies, but in the insufficient multi-modal cognitive capacity of current\nmodels. To mitigate this, we propose a Loopback Synergy mechanism, which\nenhances the synergy between the perception and cognition modules, thereby\nenabling precise segmentation while simultaneously improving robust image-text\ncomprehension. Additionally, we analyze and introduce a simple non-referent\nsample conversion data augmentation to address the long-tail distribution issue\nrelated to target existence judgement in general scenarios. Notably, DeRIS\ndemonstrates inherent adaptability to both non- and multi-referents scenarios\nwithout requiring specialized architectural modifications, enhancing its\ngeneral applicability. The codes and models are available at\nhttps://github.com/Dmmm1997/DeRIS.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.01738v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01738v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "DeRIS：通过回环协同解耦感知与认知以增强指代图像分割", "tldr": "DeRIS框架通过解耦感知和认知，并引入回环协同机制，解决了指代图像分割中多模态认知能力不足的问题，提升了分割精度和泛化性。", "motivation": "现有指代图像分割（RIS）研究主要集中在视觉-语言交互和细粒度定位，但对现有RIS框架中的基本瓶颈缺乏系统性分析。研究发现主要的限制在于模型多模态认知能力不足。", "method": "提出DeRIS框架，将RIS分解为感知和认知两个关键组件。引入回环协同机制（Loopback Synergy）增强感知和认知模块之间的协同作用。此外，提出一种简单的非指代样本转换数据增强方法，以解决目标存在判断中长尾分布问题。", "result": "DeRIS框架揭示了当前RIS性能的主要限制在于多模态认知能力不足而非感知缺陷。通过回环协同机制，DeRIS实现了精确分割，同时提高了鲁棒的图像-文本理解能力。DeRIS对非指代和多指代场景都具有固有的适应性，无需专门的架构修改。", "conclusion": "DeRIS通过解耦感知和认知并引入回环协同机制，有效解决了指代图像分割中多模态认知能力不足的瓶颈，显著提升了分割性能和泛化能力。", "translation": "指代图像分割（RIS）是一项具有挑战性的任务，旨在根据自然语言表达来分割图像中的对象。虽然之前的研究主要集中在改进视觉-语言交互和实现细粒度定位，但对现有RIS框架中基本瓶颈的系统分析仍未得到充分探索。为了弥补这一空白，我们提出了DeRIS，一个新颖的框架，它将RIS分解为两个关键组件：感知和认知。这种模块化分解有助于系统分析阻碍RIS性能的主要瓶颈。我们的研究结果表明，主要的限制不在于感知缺陷，而在于当前模型多模态认知能力不足。为了缓解这个问题，我们提出了一个回环协同机制，它增强了感知和认知模块之间的协同作用，从而在实现精确分割的同时提高了鲁棒的图像-文本理解能力。此外，我们分析并引入了一种简单的非指代样本转换数据增强方法，以解决通用场景中目标存在判断相关的长尾分布问题。值得注意的是，DeRIS对非指代和多指代场景都表现出固有的适应性，无需专门的架构修改，从而增强了其通用适用性。代码和模型可在https://github.com/Dmmm1997/DeRIS 获取。", "summary": "本文提出了DeRIS框架，旨在通过解耦感知和认知组件来解决指代图像分割（RIS）中的性能瓶颈。研究发现现有模型的限制主要在于多模态认知能力不足。DeRIS引入了回环协同机制以增强感知与认知模块的协同，从而实现精确分割并提升图像-文本理解。此外，还提出了一种数据增强方法来处理长尾分布问题。DeRIS在不同指代场景下表现出良好的通用性。", "keywords": "指代图像分割, 感知认知解耦, 回环协同, 多模态认知, 数据增强", "comments": "这篇论文通过系统性地将RIS任务解耦为感知和认知，并识别出认知能力不足是主要瓶颈，提供了一个新颖的视角。回环协同机制的设计具有创新性，能够有效增强模型的多模态理解能力。此外，其对泛化性的强调和非指代样本数据增强的引入，也体现了对实际应用场景的考量。"}}
{"id": "2507.01663", "title": "AsyncFlow: An Asynchronous Streaming RL Framework for Efficient LLM Post-Training", "authors": ["Zhenyu Han", "Ansheng You", "Haibo Wang", "Kui Luo", "Guang Yang", "Wenqi Shi", "Menglong Chen", "Sicheng Zhang", "Zeshun Lan", "Chunshi Deng", "Huazhong Ji", "Wenjie Liu", "Yu Huang", "Yixiang Zhang", "Chenyi Pan", "Jing Wang", "Xin Huang", "Chunsheng Li", "Jianping Wu"], "summary": "Reinforcement learning (RL) has become a pivotal technology in the\npost-training phase of large language models (LLMs). Traditional task-colocated\nRL frameworks suffer from significant scalability bottlenecks, while\ntask-separated RL frameworks face challenges in complex dataflows and the\ncorresponding resource idling and workload imbalance. Moreover, most existing\nframeworks are tightly coupled with LLM training or inference engines, making\nit difficult to support custom-designed engines. To address these challenges,\nwe propose AsyncFlow, an asynchronous streaming RL framework for efficient\npost-training. Specifically, we introduce a distributed data storage and\ntransfer module that provides a unified data management and fine-grained\nscheduling capability in a fully streamed manner. This architecture inherently\nfacilitates automated pipeline overlapping among RL tasks and dynamic load\nbalancing. Moreover, we propose a producer-consumer-based asynchronous workflow\nengineered to minimize computational idleness by strategically deferring\nparameter update process within staleness thresholds. Finally, the core\ncapability of AsynFlow is architecturally decoupled from underlying training\nand inference engines and encapsulated by service-oriented user interfaces,\noffering a modular and customizable user experience. Extensive experiments\ndemonstrate an average of 1.59 throughput improvement compared with\nstate-of-the-art baseline. The presented architecture in this work provides\nactionable insights for next-generation RL training system designs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01663v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01663v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "AsyncFlow：一种用于高效LLM后训练的异步流式强化学习框架", "tldr": "AsyncFlow是一个异步流式强化学习框架，通过分布式数据管理、异步工作流和解耦架构，解决了LLM后训练中传统RL框架的扩展性、效率和耦合性问题，实现了显著的吞吐量提升。", "motivation": "传统的任务合并式强化学习（RL）框架存在显著的扩展性瓶颈；任务分离式RL框架面临复杂的数据流、资源空闲和工作负载不平衡的挑战。此外，大多数现有框架与LLM训练或推理引擎紧密耦合，难以支持定制设计的引擎。", "method": "AsyncFlow引入了一个分布式数据存储和传输模块，以完全流式的方式提供统一的数据管理和细粒度调度能力，从而促进RL任务间的自动化流水线重叠和动态负载平衡。它还提出了一个基于生产者-消费者模型的异步工作流，通过在陈旧性阈值内策略性地推迟参数更新过程，最大限度地减少计算空闲。此外，AsyncFlow的核心能力与底层训练和推理引擎解耦，并通过面向服务的用户界面进行封装，提供了模块化和可定制的用户体验。", "result": "实验表明，与现有最先进的基线相比，吞吐量平均提高了1.59倍。", "conclusion": "这项工作中提出的架构为下一代RL训练系统设计提供了可行的见解。", "translation": "强化学习（RL）已成为大型语言模型（LLM）后训练阶段的关键技术。传统的任务合并式RL框架存在显著的扩展性瓶颈，而任务分离式RL框架面临复杂的数据流以及相应的资源空闲和工作负载不平衡的挑战。此外，大多数现有框架与LLM训练或推理引擎紧密耦合，使其难以支持定制设计的引擎。为了解决这些挑战，我们提出了AsyncFlow，一个用于高效后训练的异步流式RL框架。具体来说，我们引入了一个分布式数据存储和传输模块，以完全流式的方式提供统一的数据管理和细粒度调度能力。这种架构固有地促进了RL任务间的自动化流水线重叠和动态负载平衡。此外，我们提出了一种基于生产者-消费者模型的异步工作流，旨在通过在陈旧性阈值内策略性地推迟参数更新过程来最大限度地减少计算空闲。最后，AsyncFlow的核心能力在架构上与底层训练和推理引擎解耦，并通过面向服务的用户界面进行封装，提供了模块化和可定制的用户体验。广泛的实验表明，与现有最先进的基线相比，吞吐量平均提高了1.59倍。这项工作中提出的架构为下一代RL训练系统设计提供了可行的见解。", "summary": "AsyncFlow是一个针对大型语言模型（LLM）后训练的异步流式强化学习（RL）框架。它旨在解决传统RL框架在扩展性、数据流复杂性、资源利用率以及与LLM引擎紧密耦合等问题。该框架通过引入分布式数据存储与传输模块实现统一数据管理和细粒度调度，促进任务流水线重叠和动态负载平衡。其基于生产者-消费者模型的异步工作流通过延迟参数更新来减少计算空闲。此外，AsyncFlow的核心能力与底层训练/推理引擎解耦，提供模块化和可定制的用户体验。实验结果显示，其吞吐量比现有技术平均提升1.59倍，为未来的RL训练系统设计提供了有益的启示。", "keywords": "强化学习, LLM后训练, 异步流, 分布式系统, 吞吐量", "comments": "AsyncFlow的创新之处在于其针对LLM后训练RL过程中的关键痛点提供了系统性的解决方案。通过引入异步流式处理、分布式数据管理和引擎解耦，它显著提升了吞吐量和灵活性。特别是其生产者-消费者异步工作流和核心能力与引擎分离的设计，对于构建高效、可扩展且易于定制的下一代RL训练系统具有重要意义。"}}
{"id": "2507.01744", "title": "Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans", "authors": ["Benjamin Jin", "Grant Mair", "Joanna M. Wardlaw", "Maria del C. Valdés Hernández"], "summary": "Vision Transformers (ViTs) have gained significant popularity in the natural\nimage domain but have been less successful in 3D medical image segmentation.\nNevertheless, 3D ViTs are particularly interesting for large medical imaging\nvolumes due to their efficient self-supervised training within the masked\nautoencoder (MAE) framework, which enables the use of imaging data without the\nneed for expensive manual annotations. intracranial arterial calcification\n(IAC) is an imaging biomarker visible on routinely acquired CT scans linked to\nneurovascular diseases such as stroke and dementia, and automated IAC\nquantification could enable their large-scale risk assessment. We pre-train\nViTs with MAE and fine-tune them for IAC segmentation for the first time. To\ndevelop our models, we use highly heterogeneous data from a large clinical\ntrial, the third International Stroke Trial (IST-3). We evaluate key aspects of\nMAE pre-trained ViTs in IAC segmentation, and analyse the clinical\nimplications. We show: 1) our calibrated self-supervised ViT beats a strong\nsupervised nnU-Net baseline by 3.2 Dice points, 2) low patch sizes are crucial\nfor ViTs for IAC segmentation and interpolation upsampling with regular\nconvolutions is preferable to transposed convolutions for ViT-based models, and\n3) our ViTs increase robustness to higher slice thicknesses and improve risk\ngroup classification in a clinical scenario by 46%. Our code is available\nonline.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01744v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01744v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "校准自监督视觉Transformer改进临床CT头颅扫描中的颅内动脉钙化分割", "tldr": "本研究首次使用MAE预训练的ViT对颅内动脉钙化(IAC)进行分割，结果显示其性能优于监督式基线模型，并提高了临床风险评估的鲁棒性。", "motivation": "视觉Transformer（ViTs）在自然图像领域取得了成功，但在3D医学图像分割中表现不佳。然而，3D ViTs因其在掩码自编码器（MAE）框架下高效的自监督训练而特别适用于大型医学影像数据，这避免了昂贵的手动标注。颅内动脉钙化（IAC）是一种与脑血管疾病（如中风和痴呆）相关的影像生物标志物，自动化IAC量化可以实现大规模风险评估。", "method": "研究首次使用MAE预训练的视觉Transformer（ViTs）并对其进行微调，以实现颅内动脉钙化（IAC）分割。模型开发使用了来自大型临床试验（第三次国际卒中试验，IST-3）的高度异构数据。研究评估了MAE预训练ViTs在IAC分割中的关键方面，并分析了其临床意义。", "result": "1) 校准后的自监督ViT在Dice评分上比强大的监督式nnU-Net基线高出3.2个百分点。2) 低补丁大小对于ViTs进行IAC分割至关重要，并且使用常规卷积进行插值上采样优于转置卷积。3) ViTs提高了对更高切片厚度的鲁棒性，并在临床场景中将风险组分类提高了46%。", "conclusion": "校准的自监督视觉Transformer能够显著改善颅内动脉钙化（IAC）的分割效果，在性能和临床实用性方面均优于现有方法，并提高了对不同切片厚度的鲁棒性和风险组分类的准确性。", "translation": "视觉Transformer（ViTs）在自然图像领域获得了显著的普及，但在3D医学图像分割方面却不那么成功。然而，3D ViTs因其在掩码自编码器（MAE）框架内高效的自监督训练而特别适用于大型医学影像数据，这使得无需昂贵的手动标注即可使用影像数据。颅内动脉钙化（IAC）是一种在常规CT扫描中可见的影像生物标志物，与中风和痴呆等神经血管疾病相关，自动化IAC量化可以实现大规模风险评估。我们首次使用MAE预训练ViTs并对其进行微调，用于IAC分割。为了开发我们的模型，我们使用了来自大型临床试验（第三次国际卒中试验，IST-3）的高度异构数据。我们评估了MAE预训练ViTs在IAC分割中的关键方面，并分析了临床影响。我们展示了：1) 我们的校准自监督ViT比强大的监督式nnU-Net基线高出3.2个Dice点，2) 低补丁大小对于ViTs进行IAC分割至关重要，并且基于ViT的模型中，使用常规卷积进行插值上采样优于转置卷积，3) 我们的ViTs提高了对更高切片厚度的鲁棒性，并在临床场景中将风险组分类提高了46%。我们的代码已在线提供。", "summary": "本研究首次将基于掩码自编码器（MAE）预训练的自监督视觉Transformer（ViTs）应用于颅内动脉钙化（IAC）的分割任务，解决了ViTs在3D医学图像分割中应用受限的问题。研究利用来自大型临床试验的高度异构数据进行模型开发和评估，结果表明，该方法在Dice评分上显著优于传统监督式nnU-Net基线，并提高了对不同切片厚度的鲁棒性以及在临床风险分类中的准确性，为IAC的自动化量化提供了有效且无需大量手动标注的解决方案。", "keywords": "视觉Transformer, 自监督学习, 医疗图像分割, 颅内动脉钙化, CT扫描", "comments": "该论文的创新点在于首次将MAE预训练的自监督ViT应用于颅内动脉钙化分割，并取得了显著优于传统监督式方法的成果。其重要性体现在：1) 解决了3D医学图像分割中ViTs的局限性，2) 利用自监督学习减少了对昂贵手动标注的依赖，3) 提高了IAC量化的准确性和鲁棒性，对卒中和痴呆等神经血管疾病的风险评估具有重要的临床意义。研究还提供了关于ViT在医学图像分割中关键参数（如补丁大小和上采样方法）的见解。"}}
{"id": "2507.01747", "title": "SSL4SAR: Self-Supervised Learning for Glacier Calving Front Extraction from SAR Imagery", "authors": ["Nora Gourmelon", "Marcel Dreier", "Martin Mayr", "Thorsten Seehaus", "Dakota Pyles", "Matthias Braun", "Andreas Maier", "Vincent Christlein"], "summary": "Glaciers are losing ice mass at unprecedented rates, increasing the need for\naccurate, year-round monitoring to understand frontal ablation, particularly\nthe factors driving the calving process. Deep learning models can extract\ncalving front positions from Synthetic Aperture Radar imagery to track seasonal\nice losses at the calving fronts of marine- and lake-terminating glaciers. The\ncurrent state-of-the-art model relies on ImageNet-pretrained weights. However,\nthey are suboptimal due to the domain shift between the natural images in\nImageNet and the specialized characteristics of remote sensing imagery, in\nparticular for Synthetic Aperture Radar imagery. To address this challenge, we\npropose two novel self-supervised multimodal pretraining techniques that\nleverage SSL4SAR, a new unlabeled dataset comprising 9,563 Sentinel-1 and 14\nSentinel-2 images of Arctic glaciers, with one optical image per glacier in the\ndataset. Additionally, we introduce a novel hybrid model architecture that\ncombines a Swin Transformer encoder with a residual Convolutional Neural\nNetwork (CNN) decoder. When pretrained on SSL4SAR, this model achieves a mean\ndistance error of 293 m on the \"CAlving Fronts and where to Find thEm\" (CaFFe)\nbenchmark dataset, outperforming the prior best model by 67 m. Evaluating an\nensemble of the proposed model on a multi-annotator study of the benchmark\ndataset reveals a mean distance error of 75 m, approaching the human\nperformance of 38 m. This advancement enables precise monitoring of seasonal\nchanges in glacier calving fronts.", "comment": "in IEEE Transactions on Geoscience and Remote Sensing. arXiv admin\n  note: text overlap with arXiv:2501.05281", "pdf_url": "http://arxiv.org/pdf/2507.01747v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01747v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "SSL4SAR：用于SAR图像冰川崩解前缘提取的自监督学习", "tldr": "该研究提出SSL4SAR，一种用于从合成孔径雷达（SAR）图像中精确提取冰川崩解前缘的自监督学习方法，通过新的混合模型和专门的预训练数据集，显著优于现有方法并接近人类表现。", "motivation": "冰川正以前所未有的速度流失冰量，因此需要准确、全年监测冰川崩解前缘以理解额叶消融过程。现有深度学习模型依赖ImageNet预训练权重，但由于ImageNet自然图像与SAR遥感图像之间的领域差异，导致性能不佳。", "method": "本文提出两种新颖的自监督多模态预训练技术，利用SSL4SAR数据集（包含9,563张Sentinel-1和14张Sentinel-2北极冰川图像）。此外，引入了一种结合Swin Transformer编码器和残差卷积神经网络（CNN）解码器的新型混合模型架构。", "result": "在CaFFe基准数据集上，该模型在SSL4SAR上预训练后，平均距离误差为293米，优于现有最佳模型67米。对该模型集成在多标注者研究中的评估显示，平均距离误差为75米，接近人类38米的表现。", "conclusion": "这项进展能够实现对冰川崩解前缘季节性变化的精确监测。", "translation": "冰川正以前所未有的速度流失冰量，这增加了对精确、全年监测的需求，以理解额叶消融，特别是驱动崩解过程的因素。深度学习模型可以从合成孔径雷达图像中提取崩解前缘位置，以跟踪海洋和湖泊终结冰川崩解前缘的季节性冰量损失。目前最先进的模型依赖于ImageNet预训练权重。然而，由于ImageNet中的自然图像与遥感图像，特别是合成孔径雷达图像的特殊特性之间存在领域差异，这些权重并非最优。为了解决这一挑战，我们提出了两种新颖的自监督多模态预训练技术，它们利用了SSL4SAR，一个包含9,563张Sentinel-1和14张Sentinel-2北极冰川图像的新型未标注数据集，数据集中每座冰川有一张光学图像。此外，我们引入了一种新型混合模型架构，结合了Swin Transformer编码器和残差卷积神经网络（CNN）解码器。当在SSL4SAR上预训练时，该模型在“CAlving Fronts and where to Find thEm”（CaFFe）基准数据集上实现了293米的平均距离误差，比之前的最佳模型提高了67米。在基准数据集上对所提出模型的集成进行多标注者研究评估显示，平均距离误差为75米，接近人类38米的表现。这项进展能够实现对冰川崩解前缘季节性变化的精确监测。", "summary": "该论文旨在解决从SAR图像中精确提取冰川崩解前缘的挑战，这对于监测冰量损失至关重要。它提出了SSL4SAR，一个新型自监督学习框架，包含新颖的多模态预训练技术和混合Swin Transformer-CNN模型。该模型在定制的未标注数据集上进行预训练后，在CaFFe基准测试中显著优于先前的最先进模型，其集成模型的误差接近人类表现，从而实现了精确的冰川监测。", "keywords": "自监督学习, 冰川崩解前缘, SAR图像, 遥感, 深度学习", "comments": "本文的创新之处在于通过引入定制的自监督预训练数据集（SSL4SAR）和量身定制的混合模型架构，解决了遥感（SAR）图像中的领域漂移问题。这种方法显著提高了精度，弥合了与人类水平性能的差距，这对于关键的环境监测至关重要。其结合Transformer和CNN的混合模型设计也值得关注。"}}
{"id": "2507.01693", "title": "GPT, But Backwards: Exactly Inverting Language Model Outputs", "authors": ["Adrians Skapars", "Edoardo Manino", "Youcheng Sun", "Lucas C. Cordeiro"], "summary": "While existing auditing techniques attempt to identify potential unwanted\nbehaviours in large language models (LLMs), we address the complementary\nforensic problem of reconstructing the exact input that led to an existing LLM\noutput - enabling post-incident analysis and potentially the detection of fake\noutput reports. We formalize exact input reconstruction as a discrete\noptimisation problem with a unique global minimum and introduce SODA, an\nefficient gradient-based algorithm that operates on a continuous relaxation of\nthe input search space with periodic restarts and parameter decay. Through\ncomprehensive experiments on LLMs ranging in size from 33M to 3B parameters, we\ndemonstrate that SODA significantly outperforms existing approaches. We succeed\nin fully recovering 79.5% of shorter out-of-distribution inputs from next-token\nlogits, without a single false positive, but struggle to extract private\ninformation from the outputs of longer (15+ token) input sequences. This\nsuggests that standard deployment practices may currently provide adequate\nprotection against malicious use of our method. Our code is available at\nhttps://doi.org/10.5281/zenodo.15539879.", "comment": "9 pages, ICML 2025 Workshop on Reliable and Responsible Foundation\n  Models", "pdf_url": "http://arxiv.org/pdf/2507.01693v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01693v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "GPT，但反向：精确反演语言模型输出", "tldr": "提出了一种名为SODA的算法，用于精确重建大型语言模型的输入，可用于事后分析和检测虚假输出报告。", "motivation": "现有审计技术试图识别大型语言模型（LLM）中潜在的不良行为，而本文旨在解决一个互补的取证问题：重建导致现有LLM输出的精确输入，以实现事后分析并可能检测虚假输出报告。", "method": "将精确输入重建形式化为一个具有唯一全局最小值的离散优化问题，并引入了SODA，这是一种高效的基于梯度的算法，它在输入搜索空间的连续松弛上运行，并具有周期性重启和参数衰减。", "result": "在33M到3B参数的LLM上进行的综合实验表明，SODA显著优于现有方法。成功地从下一token logits中完全恢复了79.5%的较短分布外输入，且没有一个假阳性。然而，难以从较长（15+ token）输入序列的输出中提取私人信息。", "conclusion": "这表明标准部署实践目前可能为抵御本方法的恶意使用提供了足够的保护。", "translation": "虽然现有的审计技术试图识别大型语言模型（LLM）中潜在的不良行为，但我们解决了重建导致现有LLM输出的精确输入的互补取证问题——这使得事后分析和潜在的虚假输出报告检测成为可能。我们将精确输入重建形式化为一个具有唯一全局最小值的离散优化问题，并引入了SODA，这是一种高效的基于梯度的算法，它在输入搜索空间的连续松弛上运行，并具有周期性重启和参数衰减。通过对从33M到3B参数大小的LLM进行综合实验，我们证明SODA显著优于现有方法。我们成功地从下一token logits中完全恢复了79.5%的较短分布外输入，没有一个假阳性，但难以从较长（15+ token）输入序列的输出中提取私人信息。这表明标准部署实践目前可能为抵御本方法的恶意使用提供了足够的保护。我们的代码可在https://doi.org/10.5281/zenodo.15539879获取。", "summary": "本文提出了一种名为SODA的算法，用于精确反演大型语言模型（LLM）的输出，以重建其原始输入。这解决了LLM的取证问题，有助于事后分析和检测虚假输出。研究将输入重建视为离散优化问题，并开发了高效的梯度算法SODA。实验证明SODA在恢复较短输入方面表现出色，成功率达79.5%，且无假阳性。然而，该方法在处理长输入序列时难以提取私人信息，这表明当前的LLM部署可能对恶意使用提供了足够的保护。", "keywords": "LLM, 输入重建, SODA, 取证分析, 离散优化", "comments": "本文的创新之处在于将LLM输入重建问题形式化为一个离散优化问题，并提出了高效的SODA算法。这为LLM的审计和安全领域提供了一个新的视角和工具，尤其是在事后分析和检测伪造输出方面具有重要意义。尽管在长输入上存在局限性，但这反而暗示了现有LLM部署的某种安全性。"}}
{"id": "2507.01756", "title": "Rethinking Discrete Tokens: Treating Them as Conditions for Continuous Autoregressive Image Synthesis", "authors": ["Peng Zheng", "Junke Wang", "Yi Chang", "Yizhou Yu", "Rui Ma", "Zuxuan Wu"], "summary": "Recent advances in large language models (LLMs) have spurred interests in\nencoding images as discrete tokens and leveraging autoregressive (AR)\nframeworks for visual generation. However, the quantization process in AR-based\nvisual generation models inherently introduces information loss that degrades\nimage fidelity. To mitigate this limitation, recent studies have explored to\nautoregressively predict continuous tokens. Unlike discrete tokens that reside\nin a structured and bounded space, continuous representations exist in an\nunbounded, high-dimensional space, making density estimation more challenging\nand increasing the risk of generating out-of-distribution artifacts. Based on\nthe above findings, this work introduces DisCon (Discrete-Conditioned\nContinuous Autoregressive Model), a novel framework that reinterprets discrete\ntokens as conditional signals rather than generation targets. By modeling the\nconditional probability of continuous representations conditioned on discrete\ntokens, DisCon circumvents the optimization challenges of continuous token\nmodeling while avoiding the information loss caused by quantization. DisCon\nachieves a gFID score of 1.38 on ImageNet 256$\\times$256 generation,\noutperforming state-of-the-art autoregressive approaches by a clear margin.", "comment": "accepted by iccv 2025", "pdf_url": "http://arxiv.org/pdf/2507.01756v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01756v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "重新思考离散标记：将它们视为连续自回归图像合成的条件", "tldr": "该论文引入了DisCon，一个将离散标记视为连续自回归图像合成的条件信号的新框架，从而避免了量化信息损失并解决了连续标记建模的优化挑战，在图像生成方面取得了最先进的性能。", "motivation": "基于自回归（AR）的视觉生成模型中的量化过程会引入信息损失，降低图像保真度。同时，直接自回归预测连续标记面临挑战，因为它们存在于无界、高维空间中，导致密度估计困难且易生成分布外伪影。", "method": "该研究提出了DisCon（离散条件连续自回归模型），一个新颖的框架。它将离散标记重新解释为条件信号，而非生成目标。通过对以离散标记为条件的连续表示的条件概率进行建模，DisCon规避了连续标记建模的优化挑战，同时避免了量化引起的信息损失。", "result": "DisCon在ImageNet 256×256图像生成上取得了1.38的gFID分数，明显优于最先进的自回归方法。", "conclusion": "DisCon通过将离散标记视为连续表示的条件信号，成功规避了传统离散标记模型的量化损失和连续标记模型的优化挑战，从而实现了卓越的图像生成性能。", "translation": "大型语言模型（LLMs）的最新进展激发了人们将图像编码为离散标记并利用自回归（AR）框架进行视觉生成的兴趣。然而，基于AR的视觉生成模型中的量化过程固有地引入了信息损失，从而降低了图像保真度。为了缓解这一限制，最近的研究探索了自回归预测连续标记。与存在于结构化有界空间中的离散标记不同，连续表示存在于无界、高维空间中，这使得密度估计更具挑战性，并增加了生成分布外伪影的风险。基于上述发现，这项工作引入了DisCon（离散条件连续自回归模型），这是一个新颖的框架，它将离散标记重新解释为条件信号而不是生成目标。通过对以离散标记为条件的连续表示的条件概率进行建模，DisCon规避了连续标记建模的优化挑战，同时避免了量化引起的信息损失。DisCon在ImageNet 256×256生成上取得了1.38的gFID分数，明显优于最先进的自回归方法。", "summary": "DisCon是一种新型自回归图像合成模型，它将离散标记作为条件信号，而非生成目标，来预测连续图像表示。这种方法避免了传统离散标记量化带来的信息损失，并解决了连续标记建模的优化难题，在ImageNet 256x256数据集上取得了显著优于现有自回归方法的生成性能。", "keywords": "离散标记, 连续自回归, 图像合成, DisCon, 条件建模", "comments": "该论文的创新之处在于重新定义了离散标记的角色，将其从生成目标转变为条件信号。这种混合方法有效地结合了离散表示（结构化空间）和连续表示（保真度）的优势，同时缓解了它们各自的弱点，为高保真图像合成提供了一个有前景的方向。"}}
{"id": "2507.01695", "title": "PERTINENCE: Input-based Opportunistic Neural Network Dynamic Execution", "authors": ["Omkar Shende", "Gayathri Ananthanarayanan", "Marcello Traiola"], "summary": "Deep neural networks (DNNs) have become ubiquitous thanks to their remarkable\nability to model complex patterns across various domains such as computer\nvision, speech recognition, robotics, etc. While large DNN models are often\nmore accurate than simpler, lightweight models, they are also resource- and\nenergy-hungry. Hence, it is imperative to design methods to reduce reliance on\nsuch large models without significant degradation in output accuracy. The high\ncomputational cost of these models is often necessary only for a reduced set of\nchallenging inputs, while lighter models can handle most simple ones. Thus,\ncarefully combining properties of existing DNN models in a dynamic, input-based\nway opens opportunities to improve efficiency without impacting accuracy.\n  In this work, we introduce PERTINENCE, a novel online method designed to\nanalyze the complexity of input features and dynamically select the most\nsuitable model from a pre-trained set to process a given input effectively. To\nachieve this, we employ a genetic algorithm to explore the training space of an\nML-based input dispatcher, enabling convergence towards the Pareto front in the\nsolution space that balances overall accuracy and computational efficiency.\n  We showcase our approach on state-of-the-art Convolutional Neural Networks\n(CNNs) trained on the CIFAR-10 and CIFAR-100, as well as Vision Transformers\n(ViTs) trained on TinyImageNet dataset. We report results showing PERTINENCE's\nability to provide alternative solutions to existing state-of-the-art models in\nterms of trade-offs between accuracy and number of operations. By\nopportunistically selecting among models trained for the same task, PERTINENCE\nachieves better or comparable accuracy with up to 36% fewer operations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01695v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01695v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "PERTINENCE：基于输入的机遇式神经网络动态执行", "tldr": "PERTINENCE是一种在线方法，通过分析输入复杂度并动态选择最合适的预训练模型，以在不显著降低准确性的前提下减少大型DNN模型的计算开销。", "motivation": "大型深度神经网络（DNN）虽然准确但资源和能源消耗大。许多输入可以通过轻量级模型处理，只有复杂输入才需要大型模型。因此，需要设计方法来减少对大型模型的依赖，同时保持准确性，并通过动态、基于输入的方式结合现有DNN模型来提高效率。", "method": "引入PERTINENCE，一种新型在线方法。它分析输入特征的复杂性，并从预训练模型集中动态选择最合适的模型来处理给定输入。为此，该方法使用遗传算法探索基于机器学习的输入调度器的训练空间，以在准确性和计算效率之间达到帕累托最优。", "result": "在CIFAR-10和CIFAR-100上的CNN以及TinyImageNet上的ViT上进行了展示。PERTINENCE能够提供现有SOTA模型的替代解决方案，在准确性和操作数之间进行权衡。通过机会性地选择相同任务的不同模型，PERTINENCE在保持更好或相当的准确性下，将操作数减少了高达36%。", "conclusion": "PERTINENCE通过动态、基于输入的方式选择合适的模型，显著提高了深度神经网络的计算效率，同时保持了高准确性，为资源受限的环境提供了有效的解决方案。", "translation": "深度神经网络（DNN）因其在计算机视觉、语音识别、机器人等各种领域建模复杂模式的卓越能力而变得无处不在。虽然大型DNN模型通常比更简单、轻量级的模型更准确，但它们也消耗大量资源和能源。因此，设计方法以减少对大型模型的依赖而又不显著降低输出准确性至关重要。这些模型的高计算成本通常仅对一小部分具有挑战性的输入是必需的，而较轻量的模型可以处理大多数简单的输入。因此，以动态的、基于输入的方式仔细结合现有DNN模型的特性，为在不影响准确性的前提下提高效率提供了机会。\n在这项工作中，我们引入了PERTINENCE，这是一种新颖的在线方法，旨在分析输入特征的复杂性，并从预训练模型集中动态选择最合适的模型来有效处理给定输入。为了实现这一点，我们采用遗传算法来探索基于ML的输入调度器的训练空间，从而在解决方案空间中实现平衡整体准确性和计算效率的帕累托前沿。\n我们在CIFAR-10和CIFAR-100上训练的最新卷积神经网络（CNN）以及在TinyImageNet数据集上训练的视觉Transformer（ViT）上展示了我们的方法。我们报告的结果显示，PERTINENCE能够在准确性和操作数之间的权衡方面为现有最先进模型提供替代解决方案。通过机会性地选择针对相同任务训练的模型，PERTINENCE在保持更好或相当的准确性下，将操作数减少了高达36%。", "summary": "PERTINENCE是一种新颖的在线方法，旨在通过分析输入特征的复杂性并动态选择最合适的预训练模型来优化深度神经网络的执行效率。它利用遗传算法训练一个ML-based输入调度器，以在准确性和计算效率之间达到平衡。实验结果表明，PERTINENCE在不同数据集上的CNN和ViT模型上，可以在保持相似准确性的同时，将计算操作数减少高达36%。", "keywords": "深度神经网络, 动态执行, 模型选择, 计算效率, 遗传算法", "comments": "这篇论文提出了一种创新的方法来解决大型深度神经网络的计算效率问题，通过动态地根据输入复杂度选择合适的模型，避免了对单一大型模型的过度依赖。其核心创新在于引入了基于遗传算法的ML-based输入调度器，实现了准确性和效率的帕累托优化。这种方法对于资源受限的边缘设备或需要低延迟的应用具有重要意义。"}}
{"id": "2507.01788", "title": "Are Vision Transformer Representations Semantically Meaningful? A Case Study in Medical Imaging", "authors": ["Montasir Shams", "Chashi Mahiul Islam", "Shaeke Salman", "Phat Tran", "Xiuwen Liu"], "summary": "Vision transformers (ViTs) have rapidly gained prominence in medical imaging\ntasks such as disease classification, segmentation, and detection due to their\nsuperior accuracy compared to conventional deep learning models. However, due\nto their size and complex interactions via the self-attention mechanism, they\nare not well understood. In particular, it is unclear whether the\nrepresentations produced by such models are semantically meaningful. In this\npaper, using a projected gradient-based algorithm, we show that their\nrepresentations are not semantically meaningful and they are inherently\nvulnerable to small changes. Images with imperceptible differences can have\nvery different representations; on the other hand, images that should belong to\ndifferent semantic classes can have nearly identical representations. Such\nvulnerability can lead to unreliable classification results; for example,\nunnoticeable changes cause the classification accuracy to be reduced by over\n60\\%. %. To the best of our knowledge, this is the first work to systematically\ndemonstrate this fundamental lack of semantic meaningfulness in ViT\nrepresentations for medical image classification, revealing a critical\nchallenge for their deployment in safety-critical systems.", "comment": "9 pages", "pdf_url": "http://arxiv.org/pdf/2507.01788v1", "categories": ["cs.CV", "cs.AI"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01788v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "视觉Transformer表征是否具有语义意义？一项在医学成像中的案例研究", "tldr": "本研究发现，尽管视觉Transformer在医学成像中表现出色，但其表征不具有语义意义，且对微小变化极其脆弱，导致分类结果不可靠，对安全关键系统的部署构成挑战。", "motivation": "视觉Transformer（ViTs）在医学成像任务中表现出卓越的准确性，但由于其复杂的自注意力机制，人们对其内部工作原理，特别是其产生的表征是否具有语义意义，知之甚少。", "method": "本研究使用了一种基于投影梯度的算法来分析视觉Transformer的表征。", "result": "研究结果表明，视觉Transformer的表征不具有语义意义，并且对微小变化具有固有的脆弱性。具体表现为：图像之间难以察觉的差异可能导致非常不同的表征；而属于不同语义类别的图像却可能具有几乎相同的表征。这种脆弱性可导致不可靠的分类结果，例如，微小的、难以察觉的变化可使分类准确率降低超过60%。", "conclusion": "本研究首次系统地证明了视觉Transformer在医学图像分类中表征缺乏语义意义的根本性问题，揭示了其在安全关键系统部署中面临的严峻挑战。", "translation": "视觉Transformer (ViTs) 因其比传统深度学习模型更高的准确性，在疾病分类、分割和检测等医学成像任务中迅速获得关注。然而，由于其模型规模庞大以及通过自注意力机制进行的复杂交互，它们尚未被充分理解。特别是，目前尚不清楚这些模型产生的表征是否具有语义意义。在本文中，我们使用一种基于投影梯度的算法，表明它们的表征不具有语义意义，并且它们固有地容易受到微小变化的影响。具有难以察觉差异的图像可以拥有截然不同的表征；另一方面，应该属于不同语义类别的图像可以拥有几乎相同的表征。这种脆弱性可能导致不可靠的分类结果；例如，难以察觉的变化会导致分类准确率降低超过60%。据我们所知，这是首次系统地证明ViT表征在医学图像分类中根本缺乏语义意义的工作，揭示了它们在安全关键系统部署中的一个关键挑战。", "summary": "本研究探讨了视觉Transformer（ViTs）在医学成像中表征的语义意义问题。尽管ViTs表现优异，但其表征的本质尚不明确。研究采用基于投影梯度的算法，发现ViTs的表征不具备语义意义，且对微小扰动极其敏感。即使是难以察觉的图像变化，也可能导致表征的巨大差异，甚至使不同语义类别的图像产生相似的表征。这种脆弱性严重影响了分类的可靠性，例如，微小变化可使准确率下降超过60%。这是首次系统性揭示ViT表征在医学图像分类中语义缺陷的研究，对ViTs在安全关键领域的应用提出了重要警示。", "keywords": "视觉Transformer, 医学成像, 语义意义, 表征, 脆弱性", "comments": "这项工作具有重要的创新性和实践意义。它首次系统性地揭示了视觉Transformer在医学图像分类中表征缺乏语义意义的根本性问题，挑战了其在安全性要求极高的医疗领域应用的可靠性。研究指出了ViT在面对微小扰动时的脆弱性，这对于需要高鲁棒性和可解释性的安全关键系统来说是一个关键的限制。"}}
{"id": "2507.01699", "title": "Variational Graph Convolutional Neural Networks", "authors": ["Illia Oleksiienko", "Juho Kanniainen", "Alexandros Iosifidis"], "summary": "Estimation of model uncertainty can help improve the explainability of Graph\nConvolutional Networks and the accuracy of the models at the same time.\nUncertainty can also be used in critical applications to verify the results of\nthe model by an expert or additional models. In this paper, we propose\nVariational Neural Network versions of spatial and spatio-temporal Graph\nConvolutional Networks. We estimate uncertainty in both outputs and layer-wise\nattentions of the models, which has the potential for improving model\nexplainability. We showcase the benefits of these models in the social trading\nanalysis and the skeleton-based human action recognition tasks on the Finnish\nboard membership, NTU-60, NTU-120 and Kinetics datasets, where we show\nimprovement in model accuracy in addition to estimated model uncertainties.", "comment": "This work has been submitted to the IEEE for possible publication. 9\n  pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.01699v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01699v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "变分图卷积神经网络", "tldr": "本文提出了变分图卷积神经网络（V-GCNs），通过估计模型输出和层级注意力的不确定性，同时提高了图卷积网络的解释性和准确性，并在社交交易分析和人体动作识别任务中验证了其有效性。", "motivation": "估计模型不确定性有助于提高图卷积网络（GCNs）的可解释性和模型准确性。在关键应用中，不确定性还可用于专家或额外模型验证结果。", "method": "本文提出了空间和时空图卷积网络的变分神经网络版本。我们估计了模型输出和层级注意力中的不确定性，这有潜力提高模型可解释性。", "result": "这些模型在芬兰董事会成员、NTU-60、NTU-120和Kinetics数据集上的社交交易分析和基于骨架的人体动作识别任务中展现了优势，除了估计模型不确定性外，模型准确性也得到了提升。", "conclusion": "通过引入变分图卷积神经网络，并估计模型输出和层级注意力中的不确定性，可以显著提高图卷积网络的解释性和准确性，并在实际应用中展现出有效性。", "translation": "模型不确定性的估计有助于同时提高图卷积网络的可解释性和模型准确性。不确定性还可以在关键应用中用于专家或额外模型对模型结果的验证。在本文中，我们提出了空间和时空图卷积网络的变分神经网络版本。我们估计了模型输出和层级注意力中的不确定性，这有潜力提高模型可解释性。我们在芬兰董事会成员、NTU-60、NTU-120和Kinetics数据集上的社交交易分析和基于骨架的人体动作识别任务中展示了这些模型的优势，其中我们展示了除了估计模型不确定性之外的模型准确性提升。", "summary": "本文提出了一种变分图卷积神经网络（V-GCNs），旨在通过估计模型输出和层级注意力中的不确定性来提升图卷积网络（GCNs）的解释性和准确性。研究表明，这种方法在社交交易分析和基于骨架的人体动作识别任务中，于多个数据集上成功提高了模型准确性并提供了不确定性估计。", "keywords": "变分图卷积网络, 模型不确定性, 可解释性, 人体动作识别, 社交交易分析", "comments": "该论文的创新点在于将变分推断引入图卷积网络，以同时量化模型不确定性并提升模型性能。通过估计层级注意力不确定性，为GCN的黑箱特性提供了一定的可解释性。其重要性在于为GCN在需要高可靠性和可解释性的关键应用（如金融和医疗）中提供了潜在的解决方案。"}}
{"id": "2507.01791", "title": "Boosting Adversarial Transferability Against Defenses via Multi-Scale Transformation", "authors": ["Zihong Guo", "Chen Wan", "Yayin Zheng", "Hailing Kuang", "Xiaohai Lu"], "summary": "The transferability of adversarial examples poses a significant security\nchallenge for deep neural networks, which can be attacked without knowing\nanything about them. In this paper, we propose a new Segmented Gaussian Pyramid\n(SGP) attack method to enhance the transferability, particularly against\ndefense models. Unlike existing methods that generally focus on single-scale\nimages, our approach employs Gaussian filtering and three types of downsampling\nto construct a series of multi-scale examples. Then, the gradients of the loss\nfunction with respect to each scale are computed, and their average is used to\ndetermine the adversarial perturbations. The proposed SGP can be considered an\ninput transformation with high extensibility that is easily integrated into\nmost existing adversarial attacks. Extensive experiments demonstrate that in\ncontrast to the state-of-the-art methods, SGP significantly enhances attack\nsuccess rates against black-box defense models, with average attack success\nrates increasing by 2.3% to 32.6%, based only on transferability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01791v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01791v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "通过多尺度变换提升对抗防御的可迁移性", "tldr": "本文提出了一种名为分段高斯金字塔（SGP）的新型攻击方法，通过多尺度变换显著提升了对抗样本的可迁移性，特别是针对防御模型，在黑盒攻击中取得了显著更高的成功率。", "motivation": "对抗样本的可迁移性对深度神经网络构成重大安全挑战，可以在不了解模型的情况下进行攻击。现有方法主要关注单尺度图像，对防御模型的攻击效果有限。", "method": "本文提出分段高斯金字塔（SGP）攻击方法。该方法利用高斯滤波和三种下采样技术构建一系列多尺度样本。然后，计算损失函数对每个尺度的梯度，并取其平均值来生成对抗性扰动。SGP被设计为一种高可扩展性的输入变换，易于集成到大多数现有对抗性攻击中。", "result": "与现有最先进的方法相比，SGP显著提高了对黑盒防御模型的攻击成功率，平均攻击成功率仅基于可迁移性就增加了2.3%到32.6%。", "conclusion": "SGP通过多尺度变换有效提升了对抗样本的可迁移性，显著提高了对黑盒防御模型的攻击成功率。", "translation": "对抗性样本的可迁移性对深度神经网络构成了重大的安全挑战，可以在不了解其任何信息的情况下对其进行攻击。在本文中，我们提出了一种新的分段高斯金字塔（SGP）攻击方法，以增强可迁移性，特别是针对防御模型。与现有方法通常侧重于单尺度图像不同，我们的方法采用高斯滤波和三种下采样来构建一系列多尺度样本。然后，计算损失函数相对于每个尺度的梯度，并使用它们的平均值来确定对抗性扰动。所提出的SGP可以被认为是一种具有高可扩展性的输入变换，易于集成到大多数现有对抗性攻击中。大量实验表明，与现有最先进的方法相比，SGP显著提高了对黑盒防御模型的攻击成功率，平均攻击成功率仅基于可迁移性就增加了2.3%到32.6%。", "summary": "本文提出了一种名为分段高斯金字塔（SGP）的新型攻击方法，旨在增强对抗样本的可迁移性，尤其是在对抗防御模型时。与传统的单尺度方法不同，SGP通过高斯滤波和三种下采样技术构建多尺度样本，并利用各尺度梯度的平均值来生成对抗性扰动。SGP作为一种可扩展的输入变换，易于与现有对抗攻击方法结合。实验结果表明，SGP显著提升了针对黑盒防御模型的攻击成功率，相较于现有最佳方法，平均攻击成功率提高了2.3%至32.6%。", "keywords": "对抗样本, 可迁移性, 多尺度变换, 深度神经网络, SGP", "comments": "该论文的创新点在于引入多尺度变换（SGP）来提升对抗样本的可迁移性，这与现有方法主要关注单尺度图像形成对比。SGP的高可扩展性及其对防御模型的显著攻击效果，凸显了其在评估深度神经网络鲁棒性方面的重要性。"}}
{"id": "2507.01700", "title": "Relational Causal Discovery with Latent Confounders", "authors": ["Andrea Piras", "Matteo Negro", "Ragib Ahsan", "David Arbour", "Elena Zheleva"], "summary": "Estimating causal effects from real-world relational data can be challenging\nwhen the underlying causal model and potential confounders are unknown. While\nseveral causal discovery algorithms exist for learning causal models with\nlatent confounders from data, they assume that the data is independent and\nidentically distributed (i.i.d.) and are not well-suited for learning from\nrelational data. Similarly, existing relational causal discovery algorithms\nassume causal sufficiency, which is unrealistic for many real-world datasets.\nTo address this gap, we propose RelFCI, a sound and complete causal discovery\nalgorithm for relational data with latent confounders. Our work builds upon the\nFast Causal Inference (FCI) and Relational Causal Discovery (RCD) algorithms\nand it defines new graphical models, necessary to support causal discovery in\nrelational domains. We also establish soundness and completeness guarantees for\nrelational d-separation with latent confounders. We present experimental\nresults demonstrating the effectiveness of RelFCI in identifying the correct\ncausal structure in relational causal models with latent confounders.", "comment": "30 pages, 19 figures. Accepted for publication at the 41st Conference\n  on Uncertainty in Artificial Intelligence (UAI 2025). Andrea Piras and Matteo\n  Negro contributed equally to this work", "pdf_url": "http://arxiv.org/pdf/2507.01700v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01700v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "具有潜在混杂因素的关系因果发现", "tldr": "该论文提出RelFCI，一种用于具有潜在混杂因素的关系数据的因果发现新算法，它建立在FCI和RCD算法之上，并解决了现有方法的局限性。", "motivation": "从真实关系数据中估计因果效应具有挑战性，因为潜在的因果模型和混杂因素是未知的。现有因果发现算法要么假设数据独立同分布（不适用于关系数据），要么假设因果充分性（对许多真实世界数据集不切实际）。", "method": "提出RelFCI，一种用于具有潜在混杂因素的关系数据的可靠且完备的因果发现算法。该方法建立在Fast Causal Inference (FCI) 和 Relational Causal Discovery (RCD) 算法之上，并定义了支持关系域中因果发现所需的新图形模型。同时，为具有潜在混杂因素的关系d-分离建立了可靠性和完备性保证。", "result": "实验结果表明RelFCI在识别具有潜在混杂因素的关系因果模型中的正确因果结构方面是有效的。", "conclusion": "RelFCI算法有效解决了具有潜在混杂因素的关系数据中的因果发现挑战，并能够正确识别因果结构。", "translation": "从真实关系数据中估计因果效应可能具有挑战性，因为潜在的因果模型和潜在混杂因素是未知的。虽然存在一些因果发现算法用于从数据中学习具有潜在混杂因素的因果模型，但它们假设数据是独立同分布（i.i.d.）的，不适合从关系数据中学习。同样，现有的关系因果发现算法假设因果充分性，这对于许多真实世界数据集来说是不现实的。为了弥补这一空白，我们提出了RelFCI，一种用于具有潜在混杂因素的关系数据的可靠且完备的因果发现算法。我们的工作建立在快速因果推断（FCI）和关系因果发现（RCD）算法之上，并定义了新的图形模型，这些模型对于支持关系域中的因果发现是必要的。我们还为具有潜在混杂因素的关系d-分离建立了可靠性和完备性保证。我们提出了实验结果，证明了RelFCI在识别具有潜在混杂因素的关系因果模型中的正确因果结构方面的有效性。", "summary": "RelFCI是一种新颖的因果发现算法，专门设计用于处理具有潜在混杂因素的关系数据。它通过结合Fast Causal Inference (FCI) 和 Relational Causal Discovery (RCD) 的优点，并引入适应关系域的新图形模型，弥补了现有算法在处理非独立同分布数据和因果不充分性方面的不足。该算法提供了可靠性和完备性保证，实验结果证明了其在准确识别关系因果结构方面的有效性。", "keywords": "因果发现, 关系数据, 潜在混杂因素, RelFCI, 图形模型", "comments": "该论文通过提出RelFCI算法，有效解决了在关系数据中进行因果发现时存在潜在混杂因素的重大挑战，填补了现有方法在此领域的空白。其创新之处在于结合并扩展了FCI和RCD，并引入了新的图形模型，以适应关系数据的复杂性。同时，为关系d-分离建立的可靠性和完备性保证，为该方法的理论基础提供了强有力的支持，使其在实际应用中更具说服力。"}}
{"id": "2507.01792", "title": "FreeLoRA: Enabling Training-Free LoRA Fusion for Autoregressive Multi-Subject Personalization", "authors": ["Peng Zheng", "Ye Wang", "Rui Ma", "Zuxuan Wu"], "summary": "Subject-driven image generation plays a crucial role in applications such as\nvirtual try-on and poster design. Existing approaches typically fine-tune\npretrained generative models or apply LoRA-based adaptations for individual\nsubjects. However, these methods struggle with multi-subject personalization,\nas combining independently adapted modules often requires complex re-tuning or\njoint optimization. We present FreeLoRA, a simple and generalizable framework\nthat enables training-free fusion of subject-specific LoRA modules for\nmulti-subject personalization. Each LoRA module is adapted on a few images of a\nspecific subject using a Full Token Tuning strategy, where it is applied across\nall tokens in the prompt to encourage weakly supervised token-content\nalignment. At inference, we adopt Subject-Aware Inference, activating each\nmodule only on its corresponding subject tokens. This enables training-free\nfusion of multiple personalized subjects within a single image, while\nmitigating overfitting and mutual interference between subjects. Extensive\nexperiments show that FreeLoRA achieves strong performance in both subject\nfidelity and prompt consistency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01792v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01792v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "FreeLoRA：实现自回归多主体个性化的免训练LoRA融合", "tldr": "FreeLoRA是一个无需训练的框架，通过全令牌微调和主体感知推理，实现多个个性化主体的LoRA模块融合，解决了多主体图像生成中的组合难题。", "motivation": "现有方法在处理多主体个性化时面临挑战，因为独立适应的模块组合通常需要复杂的重新调整或联合优化，这限制了它们在虚拟试穿和海报设计等应用中的潜力。", "method": "FreeLoRA采用“全令牌微调”策略，在特定主体的少量图像上调整LoRA模块，使其应用于提示中的所有令牌以鼓励弱监督的令牌-内容对齐。在推理时，采用“主体感知推理”，只在其对应的主体令牌上激活每个模块，从而实现多个个性化主体的免训练融合。", "result": "广泛的实验表明，FreeLoRA在主体保真度和提示一致性方面都取得了强大的性能。", "conclusion": "FreeLoRA通过其创新的免训练融合方法，成功解决了多主体个性化图像生成中的挑战，并在主体保真度和提示一致性方面表现出色。", "translation": "主体驱动的图像生成在虚拟试穿和海报设计等应用中扮演着关键角色。现有方法通常会微调预训练的生成模型或对单个主体应用基于LoRA的适应。然而，这些方法在多主体个性化方面面临困难，因为组合独立适应的模块通常需要复杂的重新调整或联合优化。我们提出了FreeLoRA，一个简单且可泛化的框架，能够实现主体特定LoRA模块的免训练融合，以实现多主体个性化。每个LoRA模块通过“全令牌微调”策略在特定主体的少量图像上进行适应，其中它被应用于提示中的所有令牌，以鼓励弱监督的令牌-内容对齐。在推理时，我们采用“主体感知推理”，仅在其对应的主体令牌上激活每个模块。这使得在单张图像中实现多个个性化主体的免训练融合成为可能，同时减轻了过拟合和主体间的相互干扰。广泛的实验表明，FreeLoRA在主体保真度和提示一致性方面都取得了强大的性能。", "summary": "FreeLoRA是一个创新的框架，旨在解决多主体图像生成中LoRA模块融合的复杂性。它通过在训练阶段采用“全令牌微调”策略对每个LoRA模块进行主体特定适应，并在推理阶段引入“主体感知推理”机制，实现多个个性化主体LoRA模块的免训练融合。该方法有效避免了过拟合和主体间干扰，实验证明其在主体保真度和提示一致性方面表现优异，为虚拟试穿和海报设计等应用提供了高效的解决方案。", "keywords": "FreeLoRA, LoRA融合, 多主体个性化, 免训练, 图像生成", "comments": "FreeLoRA的创新之处在于其“免训练融合”能力，这极大地简化了多主体个性化图像生成中LoRA模块的组合过程。通过“全令牌微调”和“主体感知推理”的结合，它有效解决了现有方法中复杂的重新调整和联合优化问题，显著提高了实用性和效率。该方法在减轻过拟合和主体间干扰方面的表现也值得关注，为未来的多主体生成研究开辟了新的方向。"}}
{"id": "2507.01714", "title": "B-PL-PINN: Stabilizing PINN Training with Bayesian Pseudo Labeling", "authors": ["Kevin Innerebner", "Franz M. Rohrhofer", "Bernhard C. Geiger"], "summary": "Training physics-informed neural networks (PINNs) for forward problems often\nsuffers from severe convergence issues, hindering the propagation of\ninformation from regions where the desired solution is well-defined.\nHaitsiukevich and Ilin (2023) proposed an ensemble approach that extends the\nactive training domain of each PINN based on i) ensemble consensus and ii)\nvicinity to (pseudo-)labeled points, thus ensuring that the information from\nthe initial condition successfully propagates to the interior of the\ncomputational domain.\n  In this work, we suggest replacing the ensemble by a Bayesian PINN, and\nconsensus by an evaluation of the PINN's posterior variance. Our experiments\nshow that this mathematically principled approach outperforms the ensemble on a\nset of benchmark problems and is competitive with PINN ensembles trained with\ncombinations of Adam and LBFGS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01714v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01714v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "B-PL-PINN：使用贝叶斯伪标签稳定PINN训练", "tldr": "物理信息神经网络（PINN）在正向问题训练中常遇到收敛问题。本文提出用贝叶斯PINN和其后验方差来替代集成方法中的共识机制，以稳定训练。实验表明该方法在基准问题上优于集成方法，并与Adam和LBFGS组合训练的PINN集成方法具有竞争力。", "motivation": "正向问题的物理信息神经网络（PINN）训练经常遇到严重的收敛问题，这阻碍了信息从解定义良好的区域传播。", "method": "本文提出用贝叶斯PINN替代集成方法，并用PINN后验方差的评估来替代共识机制。该方法扩展了基于集成共识和伪标签点邻近度的PINN主动训练域。", "result": "实验表明，这种数学上更严谨的方法在一系列基准问题上优于集成方法，并且与结合Adam和LBFGS训练的PINN集成方法具有竞争力。", "conclusion": "本文提出的基于贝叶斯伪标签的PINN训练方法，通过利用贝叶斯PINN的后验方差，有效解决了PINN训练中的收敛性问题，并在性能上超越了传统的集成方法。", "translation": "物理信息神经网络（PINN）在正向问题训练中常遭受严重的收敛问题，这阻碍了信息从所需解定义良好的区域传播。Haitsiukevich 和 Ilin (2023) 提出了一种集成方法，通过 i) 集成共识 和 ii) 邻近（伪）标记点 来扩展每个PINN的主动训练域，从而确保初始条件的信息成功传播到计算域的内部。\n在这项工作中，我们建议用贝叶斯PINN替代集成，并用PINN后验方差的评估来替代共识。我们的实验表明，这种数学上更严谨的方法在一系列基准问题上优于集成方法，并且与结合Adam和LBFGS训练的PINN集成方法具有竞争力。", "summary": "本文针对物理信息神经网络（PINN）训练中常见的收敛问题，提出了一种名为B-PL-PINN的新方法。该方法用贝叶斯PINN替代了现有集成方法中的多个PINN，并利用PINN的后验方差代替集成共识来扩展主动训练域。实验结果表明，这种数学上更严谨的贝叶斯伪标签方法在基准测试中表现优于传统集成方法，并与使用Adam和LBFGS组合优化的PINN集成方法具有竞争力，有效稳定了PINN训练并提高了信息传播效率。", "keywords": "PINN, 贝叶斯, 伪标签, 训练稳定性, 收敛性", "comments": "本文的创新点在于将贝叶斯方法引入PINN的伪标签训练中，用贝叶斯PINN的后验方差替换了传统集成方法中的共识机制。这种方法提供了更坚实的数学基础来判断训练域的扩展，有效解决了PINN训练中的收敛难题，并展现出优于现有集成方法的性能，具有重要的实践意义。"}}
{"id": "2507.01800", "title": "HCNQA: Enhancing 3D VQA with Hierarchical Concentration Narrowing Supervision", "authors": ["Shengli Zhou", "Jianuo Zhu", "Qilin Huang", "Fangjing Wang", "Yanfu Zhang", "Feng Zheng"], "summary": "3D Visual Question-Answering (3D VQA) is pivotal for models to perceive the\nphysical world and perform spatial reasoning. Answer-centric supervision is a\ncommonly used training method for 3D VQA models. Many models that utilize this\nstrategy have achieved promising results in 3D VQA tasks. However, the\nanswer-centric approach only supervises the final output of models and allows\nmodels to develop reasoning pathways freely. The absence of supervision on the\nreasoning pathway enables the potential for developing superficial shortcuts\nthrough common patterns in question-answer pairs. Moreover, although\nslow-thinking methods advance large language models, they suffer from\nunderthinking. To address these issues, we propose \\textbf{HCNQA}, a 3D VQA\nmodel leveraging a hierarchical concentration narrowing supervision method. By\nmimicking the human process of gradually focusing from a broad area to specific\nobjects while searching for answers, our method guides the model to perform\nthree phases of concentration narrowing through hierarchical supervision. By\nsupervising key checkpoints on a general reasoning pathway, our method can\nensure the development of a rational and effective reasoning pathway. Extensive\nexperimental results demonstrate that our method can effectively ensure that\nthe model develops a rational reasoning pathway and performs better. The code\nis available at https://github.com/JianuoZhu/HCNQA.", "comment": "ICANN 2025", "pdf_url": "http://arxiv.org/pdf/2507.01800v1", "categories": ["cs.CV", "cs.MM"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01800v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "HCNQA：通过分层集中缩小监督增强3D VQA", "tldr": "HCNQA提出了一种分层集中缩小监督方法，用于3D VQA模型，旨在防止模型形成肤浅的推理捷径，并确保其发展出合理有效的推理路径。", "motivation": "现有的3D VQA模型常采用以答案为中心的监督方法，但这只监督最终输出，导致模型在推理路径上缺乏指导，可能形成肤浅的捷径。此外，慢思考方法在大型语言模型中存在思考不足的问题。", "method": "本文提出了HCNQA，一个利用分层集中缩小监督方法的3D VQA模型。该方法模仿人类在寻找答案时从广阔区域逐渐聚焦到特定对象的认知过程，通过分层监督引导模型执行三个阶段的集中缩小。通过监督通用推理路径上的关键检查点，确保模型发展出合理有效的推理路径。", "result": "广泛的实验结果表明，HCNQA方法能够有效地确保模型发展出合理的推理路径，并表现出更好的性能。", "conclusion": "HCNQA提出的分层集中缩小监督方法能够有效引导3D VQA模型发展出合理有效的推理路径，从而提升模型性能。", "translation": "3D 视觉问答 (3D VQA) 对于模型感知物理世界和执行空间推理至关重要。以答案为中心的监督是 3D VQA 模型常用的训练方法。许多采用这种策略的模型在 3D VQA 任务中取得了可喜的成果。然而，以答案为中心的方法只监督模型的最终输出，并允许模型自由发展推理路径。推理路径上缺乏监督使得模型有可能通过问题-答案对中的常见模式发展出肤浅的捷径。此外，尽管慢思考方法推动了大型语言模型的发展，但它们却存在思考不足的问题。为了解决这些问题，我们提出了 \textbf{HCNQA}，一个利用分层集中缩小监督方法的 3D VQA 模型。通过模仿人类在寻找答案时从广阔区域逐渐聚焦到特定对象的过 程，我们的方法通过分层监督引导模型执行三个阶段的集中缩小。通过监督通用推理路径上的关键检查点，我们的方法可以确保发展出合理有效的推理路径。广泛的实验结果表明，我们的方法可以有效地确保模型发展出合理的推理路径并表现得更好。代码可在 https://github.com/JianuoZhu/HCNQA 获取。", "summary": "本文介绍了HCNQA，一种新颖的3D视觉问答（VQA）模型。它解决了传统以答案为中心的监督方法的局限性，即由于推理路径缺乏监督，可能导致肤浅的推理捷径。HCNQA采用分层集中缩小监督方法，模仿人类从一般信息逐渐聚焦到特定信息的认知过程。这种方法通过监督关键检查点，引导模型完成三个阶段的集中缩小，从而确保发展出合理有效的推理路径，并在3D VQA任务中实现性能提升。", "keywords": "3D VQA, 分层监督, 集中缩小, 推理路径, 视觉问答", "comments": "该论文的创新之处在于引入了分层集中缩小监督机制，以指导模型的推理过程，解决了以答案为中心的VQA中常见的肤浅捷径问题。这种受人类认知启发的监督方法为开发更鲁棒、更可解释的VQA模型提供了有前景的方向。"}}
{"id": "2507.01724", "title": "Revisiting Learning Rate Control", "authors": ["Micha Henheik", "Theresa Eimer", "Marius Lindauer"], "summary": "The learning rate is one of the most important hyperparameters in deep\nlearning, and how to control it is an active area within both AutoML and deep\nlearning research. Approaches for learning rate control span from classic\noptimization to online scheduling based on gradient statistics. This paper\ncompares paradigms to assess the current state of learning rate control. We\nfind that methods from multi-fidelity hyperparameter optimization,\nfixed-hyperparameter schedules, and hyperparameter-free learning often perform\nvery well on selected deep learning tasks but are not reliable across settings.\nThis highlights the need for algorithm selection methods in learning rate\ncontrol, which have been neglected so far by both the AutoML and deep learning\ncommunities. We also observe a trend of hyperparameter optimization approaches\nbecoming less effective as models and tasks grow in complexity, even when\ncombined with multi-fidelity approaches for more expensive model trainings. A\nfocus on more relevant test tasks and new promising directions like finetunable\nmethods and meta-learning will enable the AutoML community to significantly\nstrengthen its impact on this crucial factor in deep learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01724v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01724v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "重新审视学习率控制", "tldr": "本文比较了深度学习中各种学习率控制范式，发现现有方法在不同设置下不可靠，强调了算法选择方法的必要性，并指出随着模型复杂性增加，超参数优化方法效率降低。", "motivation": "学习率是深度学习中最重要的超参数之一，如何控制它在AutoML和深度学习研究中是一个活跃领域。现有方法从经典优化到基于梯度统计的在线调度，但其当前状态需要评估。", "method": "本文通过比较各种学习率控制范式来评估其当前状态。", "result": "研究发现，多重保真超参数优化、固定超参数调度和无超参数学习等方法在选定的深度学习任务上表现良好，但在不同设置下并不可靠。这突出了学习率控制中算法选择方法的必要性，而这在AutoML和深度学习社区中一直被忽视。此外，随着模型和任务复杂性的增加，超参数优化方法（即使结合多重保真方法）的效果会降低。", "conclusion": "学习率控制领域需要关注更相关的测试任务，并探索微调方法和元学习等新方向，以增强AutoML社区在此关键因素上的影响力。", "translation": "学习率是深度学习中最重要的超参数之一，如何控制它在AutoML和深度学习研究中都是一个活跃领域。学习率控制的方法涵盖了从经典优化到基于梯度统计的在线调度。本文比较了各种范式，以评估学习率控制的当前状态。我们发现，来自多重保真超参数优化、固定超参数调度和无超参数学习的方法在选定的深度学习任务上通常表现非常好，但在不同设置下并不可靠。这突出了学习率控制中算法选择方法的必要性，而这迄今为止一直被AutoML和深度学习社区所忽视。我们还观察到，即使结合了多重保真方法来应对更昂贵的模型训练，随着模型和任务复杂性的增加，超参数优化方法的效果会降低。关注更相关的测试任务以及像可微调方法和元学习等有前景的新方向，将使AutoML社区能够显著增强其在深度学习这一关键因素上的影响力。", "summary": "本文对深度学习中的学习率控制方法进行了全面比较，发现当前的多重保真优化、固定调度和无超参数方法在特定任务上表现良好，但在通用性方面存在不足。研究强调了在学习率控制中引入算法选择方法的紧迫性，并指出随着模型和任务复杂性增加，超参数优化方法的有效性会下降。文章呼吁未来研究应侧重于更实际的测试任务、可微调方法和元学习，以提升AutoML在学习率优化中的作用。", "keywords": "学习率控制, 超参数优化, AutoML, 算法选择, 深度学习", "comments": "本文通过对学习率控制现有方法的全面审视，揭示了当前方法的局限性，即在特定任务上有效但在通用性上不足。其创新点在于明确指出了被忽视的“算法选择”需求，这为未来研究指明了方向。同时，它也警示了随着模型复杂性增加，传统超参数优化面临的挑战。该分析对于理解深度学习优化中的关键瓶颈和指导AutoML领域的发展具有重要意义。"}}
{"id": "2507.01801", "title": "AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for Robust Long-Tail Trajectory Prediction", "authors": ["Bin Rao", "Haicheng Liao", "Yanchen Guan", "Chengyue Wang", "Bonan Wang", "Jiaxun Zhang", "Zhenning Li"], "summary": "Accurately predicting the future trajectories of traffic agents is essential\nin autonomous driving. However, due to the inherent imbalance in trajectory\ndistributions, tail data in natural datasets often represents more complex and\nhazardous scenarios. Existing studies typically rely solely on a base model's\nprediction error, without considering the diversity and uncertainty of\nlong-tail trajectory patterns. We propose an adaptive momentum and decoupled\ncontrastive learning framework (AMD), which integrates unsupervised and\nsupervised contrastive learning strategies. By leveraging an improved momentum\ncontrast learning (MoCo-DT) and decoupled contrastive learning (DCL) module,\nour framework enhances the model's ability to recognize rare and complex\ntrajectories. Additionally, we design four types of trajectory random\naugmentation methods and introduce an online iterative clustering strategy,\nallowing the model to dynamically update pseudo-labels and better adapt to the\ndistributional shifts in long-tail data. We propose three different criteria to\ndefine long-tail trajectories and conduct extensive comparative experiments on\nthe nuScenes and ETH$/$UCY datasets. The results show that AMD not only\nachieves optimal performance in long-tail trajectory prediction but also\ndemonstrates outstanding overall prediction accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01801v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01801v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "AMD：用于鲁棒长尾轨迹预测的自适应动量与解耦对比学习框架", "tldr": "提出AMD框架，结合改进MoCo和DCL，通过数据增强和在线聚类提升长尾轨迹预测的准确性和鲁棒性。", "motivation": "在自动驾驶中，准确预测交通代理的未来轨迹至关重要。然而，由于轨迹分布固有的不平衡性，尾部数据通常代表更复杂和危险的场景，现有研究往往未能充分考虑长尾轨迹模式的多样性和不确定性，导致对稀有复杂轨迹的识别能力不足。", "method": "提出AMD（自适应动量与解耦对比学习）框架，该框架集成了无监督和有监督对比学习策略。核心组件包括改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL）模块，旨在增强模型识别稀有和复杂轨迹的能力。此外，设计了四种轨迹随机增强方法，并引入在线迭代聚类策略，使模型能够动态更新伪标签并更好地适应长尾数据的分布变化。论文还提出了三种不同的标准来定义长尾轨迹。", "result": "在nuScenes和ETH/UCY数据集上进行了广泛的对比实验。结果表明，AMD不仅在长尾轨迹预测中取得了最佳性能，而且在整体预测精度方面也表现出色。", "conclusion": "AMD框架通过其创新的对比学习策略和自适应机制，有效解决了长尾轨迹预测的挑战，显著提升了自动驾驶中轨迹预测的鲁棒性和准确性。", "translation": "在自动驾驶中，准确预测交通代理的未来轨迹至关重要。然而，由于轨迹分布固有的不平衡性，自然数据集中的尾部数据通常代表更复杂和危险的场景。现有研究通常仅依赖于基础模型的预测误差，而没有考虑长尾轨迹模式的多样性和不确定性。我们提出了一种自适应动量与解耦对比学习框架（AMD），该框架集成了无监督和有监督对比学习策略。通过利用改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL）模块，我们的框架增强了模型识别稀有和复杂轨迹的能力。此外，我们设计了四种轨迹随机增强方法，并引入了在线迭代聚类策略，使模型能够动态更新伪标签并更好地适应长尾数据的分布变化。我们提出了三种不同的标准来定义长尾轨迹，并在nuScenes和ETH/UCY数据集上进行了广泛的对比实验。结果表明，AMD不仅在长尾轨迹预测中取得了最佳性能，而且在整体预测精度方面也表现出色。", "summary": "该论文提出了AMD（自适应动量与解耦对比学习）框架，旨在解决自动驾驶中长尾轨迹预测的挑战。针对现有方法对稀有复杂轨迹识别不足的问题，AMD结合了改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL），并引入了轨迹随机增强和在线迭代聚类策略，以增强模型对长尾数据分布的适应性。实验结果表明，AMD在长尾轨迹预测和整体预测精度上均达到了最佳性能。", "keywords": "长尾轨迹预测, 对比学习, 动量对比学习, 解耦对比学习, 轨迹增强", "comments": "该论文的创新点在于将无监督和有监督对比学习相结合，并通过自适应动量机制和解耦设计，有效提升了模型对长尾分布中稀有复杂轨迹的识别能力。引入在线迭代聚类和轨迹增强方法，进一步增强了模型的鲁棒性和适应性，对自动驾驶领域的安全性和可靠性具有重要意义。"}}
{"id": "2507.01740", "title": "A Real-Time Digital Twin for Type 1 Diabetes using Simulation-Based Inference", "authors": ["Trung-Dung Hoang", "Alceu Bissoto", "Vihangkumar V. Naik", "Tim Flühmann", "Artemii Shlychkov", "José Garcia-Tirado", "Lisa M. Koch"], "summary": "Accurately estimating parameters of physiological models is essential to\nachieving reliable digital twins. For Type 1 Diabetes, this is particularly\nchallenging due to the complexity of glucose-insulin interactions. Traditional\nmethods based on Markov Chain Monte Carlo struggle with high-dimensional\nparameter spaces and fit parameters from scratch at inference time, making them\nslow and computationally expensive. In this study, we propose a\nSimulation-Based Inference approach based on Neural Posterior Estimation to\nefficiently capture the complex relationships between meal intake, insulin, and\nglucose level, providing faster, amortized inference. Our experiments\ndemonstrate that SBI not only outperforms traditional methods in parameter\nestimation but also generalizes better to unseen conditions, offering real-time\nposterior inference with reliable uncertainty quantification.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01740v1", "categories": ["cs.LG", "q-bio.QM"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01740v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于模拟推理的1型糖尿病实时数字孪生", "tldr": "本文提出一种基于神经后验估计的模拟推理方法，用于为1型糖尿病构建实时数字孪生，该方法在参数估计和泛化能力上优于传统方法，并提供快速、可靠的推理。", "motivation": "准确估计生理模型参数对于构建可靠的数字孪生至关重要，但对于1型糖尿病而言，由于葡萄糖-胰岛素相互作用的复杂性，以及传统MCMC方法在高维参数空间中的缓慢和计算昂贵，使得参数估计具有挑战性。", "method": "本研究提出一种基于神经后验估计（Neural Posterior Estimation）的模拟推理（Simulation-Based Inference, SBI）方法，旨在高效捕捉膳食摄入、胰岛素和血糖水平之间的复杂关系，实现更快速、摊销的推理。", "result": "实验结果表明，SBI在参数估计方面不仅优于传统方法，而且对未知条件具有更好的泛化能力，能够提供实时后验推理和可靠的不确定性量化。", "conclusion": "基于神经后验估计的模拟推理方法能够有效解决1型糖尿病数字孪生中参数估计的挑战，实现快速、准确且具有良好泛化能力的实时推理，并提供可靠的不确定性量化。", "translation": "准确估计生理模型参数对于实现可靠的数字孪生至关重要。对于1型糖尿病，由于葡萄糖-胰岛素相互作用的复杂性，这尤其具有挑战性。基于马尔可夫链蒙特卡洛的传统方法在高维参数空间中表现不佳，并且在推理时从头开始拟合参数，这使得它们缓慢且计算成本高昂。在本研究中，我们提出了一种基于神经后验估计的模拟推理方法，以有效捕获膳食摄入、胰岛素和血糖水平之间的复杂关系，提供更快、摊销的推理。我们的实验表明，SBI不仅在参数估计方面优于传统方法，而且对未知条件具有更好的泛化能力，提供具有可靠不确定性量化的实时后验推理。", "summary": "本文提出一种基于神经后验估计的模拟推理（SBI）方法，用于解决1型糖尿病数字孪生中生理模型参数估计的挑战。与传统方法相比，SBI能够更高效地捕捉葡萄糖-胰岛素相互作用，并在参数估计和对未知条件的泛化方面表现出优越性，从而实现快速、可靠的实时后验推理及不确定性量化。", "keywords": "数字孪生, 1型糖尿病, 模拟推理, 神经后验估计, 参数估计", "comments": "该论文的创新点在于将模拟推理（特别是神经后验估计）应用于1型糖尿病的数字孪生构建，有效解决了传统方法在处理高维参数空间和实时性方面的不足。其重要性体现在为糖尿病管理提供了更准确、快速的参数估计工具，有望提升数字孪生的可靠性和实用性。"}}
{"id": "2507.01835", "title": "Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views", "authors": ["Daniil Reutsky", "Daniil Vladimirov", "Yasin Mamedov", "Georgy Perevozchikov", "Nancy Mehta", "Egor Ershov", "Radu Timofte"], "summary": "Hyperspectral reconstruction (HSR) from RGB images is a fundamentally\nill-posed problem due to severe spectral information loss. Existing approaches\ntypically rely on a single RGB image, limiting reconstruction accuracy. In this\nwork, we propose a novel multi-image-to-hyperspectral reconstruction (MI-HSR)\nframework that leverages a triple-camera smartphone system, where two lenses\nare equipped with carefully selected spectral filters. Our configuration,\ngrounded in theoretical and empirical analysis, enables richer and more diverse\nspectral observations than conventional single-camera setups. To support this\nnew paradigm, we introduce Doomer, the first dataset for MI-HSR, comprising\naligned images from three smartphone cameras and a hyperspectral reference\ncamera across diverse scenes. We show that the proposed HSR model achieves\nconsistent improvements over existing methods on the newly proposed benchmark.\nIn a nutshell, our setup allows 30% towards more accurately estimated spectra\ncompared to an ordinary RGB camera. Our findings suggest that multi-view\nspectral filtering with commodity hardware can unlock more accurate and\npractical hyperspectral imaging solutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01835v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01835v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "调制与重建：从错位智能手机视角学习高光谱成像", "tldr": "本文提出了一种新的多图像到高光谱重建（MI-HSR）框架，利用带有光谱滤镜的三摄像头智能手机系统，实现了比传统单摄像头设置更丰富、更多样化的光谱观测，并引入了首个MI-HSR数据集Doomer，实验证明其在光谱估计精度上优于现有方法。", "motivation": "高光谱重建（HSR）从RGB图像中进行是由于严重的光谱信息丢失而导致的一个根本性病态问题。现有方法通常依赖于单个RGB图像，限制了重建精度。", "method": "本文提出了一种新颖的多图像到高光谱重建（MI-HSR）框架，该框架利用三摄像头智能手机系统，其中两个镜头配备了精心选择的光谱滤镜。这种配置基于理论和经验分析，能够实现比传统单摄像头设置更丰富、更多样化的光谱观测。为了支持这种新范式，本文引入了Doomer，这是首个用于MI-HSR的数据集，包含来自三部智能手机相机和一台高光谱参考相机在不同场景下的对齐图像。", "result": "所提出的HSR模型在新的基准测试上比现有方法取得了持续的改进。与普通RGB相机相比，本文的设置能够使光谱估计精度提高30%。", "conclusion": "本文的研究结果表明，利用商品硬件进行多视角光谱滤波可以解锁更准确、更实用的高光谱成像解决方案。", "translation": "高光谱重建（HSR）从RGB图像中进行是由于严重的光谱信息丢失而导致的一个根本性病态问题。现有方法通常依赖于单个RGB图像，限制了重建精度。在这项工作中，我们提出了一种新颖的多图像到高光谱重建（MI-HSR）框架，该框架利用三摄像头智能手机系统，其中两个镜头配备了精心选择的光谱滤镜。我们的配置基于理论和经验分析，能够实现比传统单摄像头设置更丰富、更多样化的光谱观测。为了支持这种新范式，我们引入了Doomer，这是首个用于MI-HSR的数据集，包含来自三部智能手机相机和一台高光谱参考相机在不同场景下的对齐图像。我们表明，所提出的HSR模型在新的基准测试上比现有方法取得了持续的改进。简而言之，与普通RGB相机相比，我们的设置能够使光谱估计精度提高30%。我们的研究结果表明，利用商品硬件进行多视角光谱滤波可以解锁更准确、更实用的高光谱成像解决方案。", "summary": "本研究提出了一种创新的多图像高光谱重建（MI-HSR）框架，旨在解决传统单RGB图像高光谱重建中光谱信息严重丢失导致的精度限制。该框架利用配备了光谱滤镜的三摄像头智能手机系统，通过理论和经验分析证明其能提供更丰富、更多样的光谱观测。为支持这一新范式，研究者构建了首个MI-HSR数据集Doomer。实验结果表明，该HSR模型在新建基准上显著优于现有方法，与普通RGB相机相比，光谱估计精度提高了30%。这表明利用商品硬件进行多视角光谱滤波是实现更准确、实用高光谱成像的关键。", "keywords": "高光谱重建, 多图像, 智能手机, 光谱滤波, Doomer数据集", "comments": "本文的创新点在于提出了基于多摄像头智能手机的高光谱重建方案，并引入了相应的MI-HSR数据集Doomer，为高光谱成像的实际应用和商品化提供了新的思路。利用现有商品硬件实现高精度光谱估计，具有重要的实用价值和广阔的应用前景。"}}
{"id": "2507.01838", "title": "MobileIE: An Extremely Lightweight and Effective ConvNet for Real-Time Image Enhancement on Mobile Devices", "authors": ["Hailong Yan", "Ao Li", "Xiangtao Zhang", "Zhe Liu", "Zenglin Shi", "Ce Zhu", "Le Zhang"], "summary": "Recent advancements in deep neural networks have driven significant progress\nin image enhancement (IE). However, deploying deep learning models on\nresource-constrained platforms, such as mobile devices, remains challenging due\nto high computation and memory demands. To address these challenges and\nfacilitate real-time IE on mobile, we introduce an extremely lightweight\nConvolutional Neural Network (CNN) framework with around 4K parameters. Our\napproach integrates reparameterization with an Incremental Weight Optimization\nstrategy to ensure efficiency. Additionally, we enhance performance with a\nFeature Self-Transform module and a Hierarchical Dual-Path Attention mechanism,\noptimized with a Local Variance-Weighted loss. With this efficient framework,\nwe are the first to achieve real-time IE inference at up to 1,100 frames per\nsecond (FPS) while delivering competitive image quality, achieving the best\ntrade-off between speed and performance across multiple IE tasks. The code will\nbe available at https://github.com/AVC2-UESTC/MobileIE.git.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.01838v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01838v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "MobileIE: 一种用于移动设备实时图像增强的超轻量级高效卷积网络", "tldr": "MobileIE 是一种超轻量级卷积神经网络，参数量约4K，首次在移动设备上实现了高达1100 FPS的实时图像增强，并在速度和性能之间取得了最佳平衡。", "motivation": "由于高计算和内存需求，在移动设备等资源受限平台上部署深度学习模型进行图像增强仍然具有挑战性。", "method": "MobileIE 框架集成了重参数化与增量权重优化策略以确保效率。此外，它通过特征自变换模块和分层双路径注意力机制增强性能，并使用局部方差加权损失进行优化。", "result": "MobileIE 首次实现了高达1,100 FPS的实时图像增强推理，同时提供了具有竞争力的图像质量，并在多个图像增强任务中实现了速度和性能之间的最佳权衡。", "conclusion": "该论文提出了一种超轻量级高效的卷积神经网络MobileIE，成功解决了移动设备上实时图像增强的挑战，并在速度和质量之间取得了卓越的平衡。", "translation": "深度神经网络的最新进展推动了图像增强（IE）的显著进步。然而，由于高计算和内存需求，在移动设备等资源受限平台上部署深度学习模型仍然具有挑战性。为了解决这些挑战并促进移动设备上的实时图像增强，我们引入了一个参数量约为4K的超轻量级卷积神经网络（CNN）框架。我们的方法将重参数化与增量权重优化策略相结合，以确保效率。此外，我们通过特征自变换模块和分层双路径注意力机制来增强性能，并使用局部方差加权损失进行优化。凭借这种高效的框架，我们首次实现了高达1,100帧每秒（FPS）的实时图像增强推理，同时提供了具有竞争力的图像质量，在多个图像增强任务中实现了速度和性能之间的最佳权衡。代码将发布在 https://github.com/AVC2-UESTC/MobileIE.git。", "summary": "该论文提出了一种名为 MobileIE 的超轻量级卷积神经网络（CNN）框架，旨在解决移动设备上实时图像增强的计算和内存限制。MobileIE 参数量仅约4K，通过结合重参数化、增量权重优化、特征自变换模块和分层双路径注意力机制，并采用局部方差加权损失进行优化。该方法首次实现了在移动设备上高达1,100 FPS 的实时图像增强推理，并在保持竞争性图像质量的同时，在速度和性能之间取得了卓越的平衡。", "keywords": "图像增强, 移动设备, 轻量级CNN, 实时推理, 深度学习", "comments": "MobileIE 的创新之处在于其极致的轻量化（仅约4K参数）和在移动设备上实现超高实时帧率（1100 FPS），这对于资源受限环境下的实际应用具有重要意义。其结合多种优化策略，如重参数化和注意力机制，有效平衡了性能和效率。这是一个在移动端AI部署方面具有突破性的工作。"}}
{"id": "2507.01761", "title": "Enhanced Generative Model Evaluation with Clipped Density and Coverage", "authors": ["Nicolas Salvy", "Hugues Talbot", "Bertrand Thirion"], "summary": "Although generative models have made remarkable progress in recent years,\ntheir use in critical applications has been hindered by their incapacity to\nreliably evaluate sample quality. Quality refers to at least two complementary\nconcepts: fidelity and coverage. Current quality metrics often lack reliable,\ninterpretable values due to an absence of calibration or insufficient\nrobustness to outliers. To address these shortcomings, we introduce two novel\nmetrics, Clipped Density and Clipped Coverage. By clipping individual sample\ncontributions and, for fidelity, the radii of nearest neighbor balls, our\nmetrics prevent out-of-distribution samples from biasing the aggregated values.\nThrough analytical and empirical calibration, these metrics exhibit linear\nscore degradation as the proportion of poor samples increases. Thus, they can\nbe straightforwardly interpreted as equivalent proportions of good samples.\nExtensive experiments on synthetic and real-world datasets demonstrate that\nClipped Density and Clipped Coverage outperform existing methods in terms of\nrobustness, sensitivity, and interpretability for evaluating generative models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01761v1", "categories": ["cs.LG", "cs.AI", "stat.ML"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01761v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "使用裁剪密度和覆盖率增强生成模型评估", "tldr": "本文提出了两种新的指标，裁剪密度和裁剪覆盖率，用于更可靠、可解释地评估生成模型的样本质量，解决了现有指标对异常值不鲁棒和缺乏校准的问题。", "motivation": "尽管生成模型取得了显著进展，但由于缺乏可靠的样本质量评估方法，其在关键应用中的使用受阻。现有质量指标因缺乏校准或对异常值鲁棒性不足，往往缺乏可靠、可解释的值。", "method": "本文引入了两种新的指标：裁剪密度（Clipped Density）和裁剪覆盖率（Clipped Coverage）。通过裁剪单个样本贡献以及最近邻球体的半径（针对保真度），这些指标可以防止异常分布样本对聚合值产生偏差。通过分析和实证校准，这些指标在不良样本比例增加时表现出线性分数下降。", "result": "在合成数据集和真实世界数据集上进行的广泛实验表明，裁剪密度和裁剪覆盖率在评估生成模型时，在鲁棒性、敏感性和可解释性方面优于现有方法。", "conclusion": "裁剪密度和裁剪覆盖率可以被直接解释为良好样本的等效比例，从而提供了可靠且可解释的生成模型样本质量评估方法。", "translation": "尽管生成模型近年来取得了显著进展，但其在关键应用中的使用一直受到阻碍，原因在于它们无法可靠地评估样本质量。质量至少涉及两个互补的概念：保真度和覆盖率。当前的质量指标通常缺乏可靠、可解释的值，原因是没有校准或对异常值鲁棒性不足。为了解决这些缺点，我们引入了两个新颖的指标，裁剪密度和裁剪覆盖率。通过裁剪单个样本贡献，并且对于保真度，裁剪最近邻球体的半径，我们的指标可以防止异常分布样本对聚合值产生偏差。通过分析和实证校准，这些指标随着不良样本比例的增加而表现出线性分数下降。因此，它们可以被直接解释为良好样本的等效比例。在合成数据集和真实世界数据集上进行的广泛实验表明，裁剪密度和裁剪覆盖率在评估生成模型时，在鲁棒性、敏感性和可解释性方面优于现有方法。", "summary": "本文针对生成模型样本质量评估中现有指标的不足，提出了两种新颖的评估指标：裁剪密度和裁剪覆盖率。这些指标通过裁剪样本贡献和最近邻球半径，有效增强了对异常值的鲁棒性，并提供了线性可解释的分数。实验证明，新指标在鲁棒性、敏感性和可解释性方面均优于现有方法，为生成模型评估提供了更可靠、可解释的工具。", "keywords": "生成模型, 评估指标, 裁剪密度, 裁剪覆盖率, 鲁棒性", "comments": "本文的创新点在于提出了“裁剪”机制，以提高生成模型评估指标的鲁棒性和可解释性。通过防止异常值对评估结果产生偏差，并提供线性可解释的分数，该方法有望显著提升生成模型在实际应用中的可信度。其重要性体现在解决了当前生成模型评估中普遍存在的挑战，为模型选择和改进提供了更坚实的基础。"}}
{"id": "2507.01882", "title": "Future Slot Prediction for Unsupervised Object Discovery in Surgical Video", "authors": ["Guiqiu Liao", "Matjaz Jogan", "Marcel Hussing", "Edward Zhang", "Eric Eaton", "Daniel A. Hashimoto"], "summary": "Object-centric slot attention is an emerging paradigm for unsupervised\nlearning of structured, interpretable object-centric representations (slots).\nThis enables effective reasoning about objects and events at a low\ncomputational cost and is thus applicable to critical healthcare applications,\nsuch as real-time interpretation of surgical video. The heterogeneous scenes in\nreal-world applications like surgery are, however, difficult to parse into a\nmeaningful set of slots. Current approaches with an adaptive slot count perform\nwell on images, but their performance on surgical videos is low. To address\nthis challenge, we propose a dynamic temporal slot transformer (DTST) module\nthat is trained both for temporal reasoning and for predicting the optimal\nfuture slot initialization. The model achieves state-of-the-art performance on\nmultiple surgical databases, demonstrating that unsupervised object-centric\nmethods can be applied to real-world data and become part of the common arsenal\nin healthcare applications.", "comment": "Accepted by MICCAI2025", "pdf_url": "http://arxiv.org/pdf/2507.01882v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01882v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "医疗视频中无监督对象发现的未来槽位预测", "tldr": "针对手术视频中无监督对象发现的挑战，本文提出了一种动态时间槽位变换器（DTST）模块，通过预测未来槽位初始化和时间推理，实现了最先进的性能，证明了无监督对象中心方法在真实世界医疗数据中的适用性。", "motivation": "当前的对象中心槽位注意力方法在图像上表现良好，但在处理手术视频等真实世界应用中异构场景时，难以将其解析为有意义的槽位，且性能较低。", "method": "提出了一种动态时间槽位变换器（dynamic temporal slot transformer, DTST）模块，该模块经过训练，能够进行时间推理并预测最佳的未来槽位初始化。", "result": "该模型在多个手术数据库上取得了最先进的性能。", "conclusion": "无监督的对象中心方法可以应用于真实世界数据，并成为医疗保健应用中常用工具的一部分。", "translation": "对象中心槽位注意力是一种新兴的范式，用于无监督地学习结构化、可解释的对象中心表示（槽位）。这使得能够以较低的计算成本有效推理对象和事件，因此适用于关键的医疗保健应用，例如手术视频的实时解释。然而，手术等真实世界应用中的异构场景难以解析为一组有意义的槽位。当前具有自适应槽位计数的方法在图像上表现良好，但它们在手术视频上的性能较低。为了应对这一挑战，我们提出了一种动态时间槽位变换器（DTST）模块，该模块既用于时间推理，也用于预测最佳的未来槽位初始化。该模型在多个手术数据库上取得了最先进的性能，表明无监督的对象中心方法可以应用于真实世界数据，并成为医疗保健应用中常用工具的一部分。", "summary": "本文提出了一种名为动态时间槽位变换器（DTST）的新模块，旨在解决在手术视频等异构真实世界场景中，现有对象中心槽位注意力方法难以进行无监督对象发现的问题。DTST模块通过结合时间推理和预测未来槽位初始化来提高性能。实验结果表明，该模型在多个手术数据库上达到了最先进的性能，证明了无监督对象中心方法在实际医疗应用中的潜力。", "keywords": "对象中心表示, 无监督学习, 槽位注意力, 手术视频分析, 时间推理", "comments": "这项工作通过引入动态时间槽位变换器（DTST）模块，有效解决了对象中心槽位注意力方法在处理复杂、异构的手术视频数据时的局限性。其创新点在于结合了时间推理和未来槽位初始化预测，显著提升了无监督对象发现的性能，为实时医疗影像分析开辟了新的途径，具有重要的实践意义。"}}
{"id": "2507.01781", "title": "BranchNet: A Neuro-Symbolic Learning Framework for Structured Multi-Class Classification", "authors": ["Dalia Rodríguez-Salas", "Christian Riess"], "summary": "We introduce BranchNet, a neuro-symbolic learning framework that transforms\ndecision tree ensembles into sparse, partially connected neural networks. Each\nbranch, defined as a decision path from root to a parent of leaves, is mapped\nto a hidden neuron, preserving symbolic structure while enabling gradient-based\noptimization. The resulting models are compact, interpretable, and require no\nmanual architecture tuning. Evaluated on a suite of structured multi-class\nclassification benchmarks, BranchNet consistently outperforms XGBoost in\naccuracy, with statistically significant gains. We detail the architecture,\ntraining procedure, and sparsity dynamics, and discuss the model's strengths in\nsymbolic interpretability as well as its current limitations, particularly on\nbinary tasks where further adaptive calibration may be beneficial.", "comment": "18 pages, 3 figures (with two images each)", "pdf_url": "http://arxiv.org/pdf/2507.01781v1", "categories": ["cs.LG", "cs.AI", "68T07 (Primary) 62H30, 68T05 (Secondary)"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01781v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "BranchNet：一种用于结构化多类分类的神经符号学习框架", "tldr": "BranchNet是一种将决策树集成转换为稀疏、部分连接神经网络的神经符号学习框架，在结构化多类分类中表现优于XGBoost，且具有可解释性。", "motivation": "旨在结合决策树集成的符号结构和神经网络的梯度优化能力，创建紧凑、可解释且无需手动架构调优的模型。", "method": "BranchNet将决策树集成转换为稀疏、部分连接的神经网络。每个决策路径（从根到叶子父节点的路径）被映射到一个隐藏神经元，从而保留了符号结构并支持基于梯度的优化。", "result": "在结构化多类分类基准测试中，BranchNet在准确性上持续优于XGBoost，并取得了统计学上的显著提升。", "conclusion": "BranchNet在结构化多类分类任务中表现出色，具有符号可解释性，但在二元任务上可能需要进一步的自适应校准。", "translation": "我们引入了BranchNet，一个神经符号学习框架，它将决策树集成转换为稀疏、部分连接的神经网络。每个分支，定义为从根到叶子父节点的决策路径，被映射到一个隐藏神经元，从而在实现基于梯度的优化的同时保留了符号结构。由此产生的模型紧凑、可解释，并且无需手动架构调优。在结构化多类分类基准测试套件上进行评估，BranchNet在准确性方面始终优于XGBoost，并取得了统计学上的显著提升。我们详细介绍了其架构、训练过程和稀疏性动态，并讨论了该模型在符号可解释性方面的优势及其当前的局限性，特别是在二元任务上，可能需要进一步的自适应校准。", "summary": "BranchNet是一种创新的神经符号学习框架，它通过将决策树集成转换为稀疏神经网络来结合决策树和神经网络的优势。该框架将决策路径映射为隐藏神经元，实现了梯度优化，同时保持了模型的紧凑性、可解释性，并消除了手动架构调优的需求。在结构化多类分类任务中，BranchNet在准确性上显著超越了XGBoost，但在二元任务上仍有改进空间。", "keywords": "神经符号学习, 决策树集成, 稀疏神经网络, 多类分类, 可解释性", "comments": "BranchNet的创新之处在于其将决策树的符号结构与神经网络的梯度优化相结合，形成了一个紧凑、可解释且高性能的模型。它解决了传统神经网络可解释性差以及决策树集成模型优化灵活性不足的问题。其无需手动架构调优的特点也大大简化了模型部署。然而，它在二元任务上的局限性表明其通用性仍需进一步提升。"}}
{"id": "2507.01884", "title": "Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation for Semi-Supervised Lifelong Person Re-Identification", "authors": ["Kunlun Xu", "Fan Zhuo", "Jiangmeng Li", "Xu Zou", "Jiahuan Zhou"], "summary": "Current lifelong person re-identification (LReID) methods predominantly rely\non fully labeled data streams. However, in real-world scenarios where\nannotation resources are limited, a vast amount of unlabeled data coexists with\nscarce labeled samples, leading to the Semi-Supervised LReID (Semi-LReID)\nproblem where LReID methods suffer severe performance degradation. Existing\nLReID methods, even when combined with semi-supervised strategies, suffer from\nlimited long-term adaptation performance due to struggling with the noisy\nknowledge occurring during unlabeled data utilization. In this paper, we\npioneer the investigation of Semi-LReID, introducing a novel Self-Reinforcing\nPrototype Evolution with Dual-Knowledge Cooperation framework (SPRED). Our key\ninnovation lies in establishing a self-reinforcing cycle between dynamic\nprototype-guided pseudo-label generation and new-old knowledge collaborative\npurification to enhance the utilization of unlabeled data. Specifically,\nlearnable identity prototypes are introduced to dynamically capture the\nidentity distributions and generate high-quality pseudo-labels. Then, the\ndual-knowledge cooperation scheme integrates current model specialization and\nhistorical model generalization, refining noisy pseudo-labels. Through this\ncyclic design, reliable pseudo-labels are progressively mined to improve\ncurrent-stage learning and ensure positive knowledge propagation over long-term\nlearning. Experiments on the established Semi-LReID benchmarks show that our\nSPRED achieves state-of-the-art performance. Our source code is available at\nhttps://github.com/zhoujiahuan1991/ICCV2025-SPRED", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.01884v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01884v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "双知识协作的自强化原型演化用于半监督终身行人重识别", "tldr": "本文提出了SPRED框架，通过自强化原型演化和双知识协作，解决了半监督终身行人重识别中利用无标签数据时出现的噪声知识问题，实现了最先进的性能。", "motivation": "当前终身行人重识别（LReID）方法主要依赖于完全标注的数据流，但在真实世界中，标注资源有限，存在大量无标签数据和少量标注样本并存的半监督LReID（Semi-LReID）问题。现有LReID方法即使结合半监督策略，也因难以处理无标签数据利用过程中产生的噪声知识，导致长期适应性能有限。", "method": "本文提出了一个新颖的自强化原型演化与双知识协作框架（SPRED）。其核心创新在于建立了动态原型引导的伪标签生成与新旧知识协同净化之间的自强化循环，以增强无标签数据的利用。具体而言，引入可学习的身份原型以动态捕获身份分布并生成高质量伪标签。然后，双知识协作方案整合当前模型的特化能力和历史模型的泛化能力，以精炼噪声伪标签。通过这种循环设计，逐步挖掘可靠的伪标签，以改进当前阶段的学习并确保长期学习中知识的正向传播。", "result": "在已建立的Semi-LReID基准测试中，SPRED实现了最先进的性能。", "conclusion": "本文首次对半监督终身行人重识别（Semi-LReID）进行了研究，并提出了SPRED框架，通过自强化原型演化和双知识协作有效解决了无标签数据利用中的噪声知识问题，从而在Semi-LReID基准上取得了最先进的性能。", "translation": "当前终身行人重识别（LReID）方法主要依赖于完全标注的数据流。然而，在标注资源有限的真实世界场景中，大量无标签数据与稀疏的标注样本并存，导致了半监督LReID（Semi-LReID）问题，其中LReID方法性能严重下降。现有LReID方法，即使结合半监督策略，也因难以处理无标签数据利用过程中出现的噪声知识，导致长期适应性能有限。在本文中，我们首次对Semi-LReID进行了研究，引入了一种新颖的双知识协作自强化原型演化框架（SPRED）。我们的关键创新在于建立了动态原型引导的伪标签生成与新旧知识协同净化之间的自强化循环，以增强无标签数据的利用。具体而言，引入可学习的身份原型以动态捕获身份分布并生成高质量伪标签。然后，双知识协作方案整合当前模型的特化能力和历史模型的泛化能力，以精炼噪声伪标签。通过这种循环设计，逐步挖掘可靠的伪标签，以改进当前阶段的学习并确保长期学习中知识的正向传播。在已建立的Semi-LReID基准测试中，我们的SPRED实现了最先进的性能。我们的源代码可在https://github.com/zhoujiahuan1991/ICCV2025-SPRED获取。", "summary": "本文针对真实世界中标注资源有限导致的半监督终身行人重识别（Semi-LReID）问题，提出了一种新颖的自强化原型演化与双知识协作框架（SPRED）。该框架通过建立动态原型引导的伪标签生成与新旧知识协同净化的自强化循环，有效利用无标签数据，解决现有方法在处理噪声知识时的性能瓶颈。SPRED引入可学习身份原型生成高质量伪标签，并利用双知识协作（结合当前模型特化和历史模型泛化）精炼伪标签，从而在长期学习中实现知识的正向传播。实验证明，SPRED在Semi-LReID基准上取得了最先进的性能。", "keywords": "行人重识别, 半监督学习, 终身学习, 原型学习, 知识蒸馏", "comments": "该论文的创新点在于首次深入研究了半监督终身行人重识别（Semi-LReID）这一实际场景中的重要问题。其提出的SPRED框架通过引入“自强化原型演化”和“双知识协作”的循环机制，巧妙地解决了无标签数据利用中噪声伪标签的关键挑战，这对于提高模型在资源受限环境下的长期适应性具有重要意义。"}}
{"id": "2507.01803", "title": "Towards Decentralized and Sustainable Foundation Model Training with the Edge", "authors": ["Leyang Xue", "Meghana Madhyastha", "Randal Burns", "Myungjin Lee", "Mahesh K. Marina"], "summary": "Foundation models are at the forefront of AI research, appealing for their\nability to learn from vast datasets and cater to diverse tasks. Yet, their\nsignificant computational demands raise issues of environmental impact and the\nrisk of centralized control in their development. We put forward a vision\ntowards decentralized and sustainable foundation model training that leverages\nthe collective compute of sparingly used connected edge AI devices. We present\nthe rationale behind our vision, particularly in support of its sustainability\nbenefit. We further outline a set of challenges that need to be addressed to\nturn this vision into reality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01803v1", "categories": ["cs.LG"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01803v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "迈向去中心化和可持续的边缘基础模型训练", "tldr": "提出利用边缘设备进行去中心化和可持续的基础模型训练的愿景，以解决计算需求高和中心化控制的问题。", "motivation": "基础模型的高计算需求带来了环境影响和中心化控制的风险。", "method": "提出一个利用稀疏使用的联网边缘AI设备的集体计算能力，实现去中心化和可持续的基础模型训练的愿景。", "result": "Not mentioned in abstract", "conclusion": "论文提出了利用边缘设备实现去中心化和可持续的基础模型训练的愿景，并指出了实现此愿景所需的挑战。", "translation": "基础模型处于人工智能研究的前沿，因其能够从海量数据集中学习并适应各种任务而备受青睐。然而，其巨大的计算需求带来了环境影响和开发过程中中心化控制的风险。我们提出了一个迈向去中心化和可持续的基础模型训练的愿景，该愿景利用了稀疏使用的联网边缘AI设备的集体计算能力。我们阐述了这一愿景背后的基本原理，特别是支持其可持续性效益。我们还概述了将这一愿景变为现实需要解决的一系列挑战。", "summary": "这篇论文提出了一个利用边缘AI设备集体计算能力，实现去中心化和可持续的基础模型训练的愿景。该愿景旨在解决当前基础模型训练中存在的计算资源消耗大、环境影响以及中心化控制的风险。文章阐述了该愿景的合理性，并指出了实现这一目标所面临的挑战。", "keywords": "基础模型, 去中心化, 可持续性, 边缘计算, AI训练", "comments": "这篇论文提出了一种创新性的思路，将基础模型的训练从传统的中心化、高能耗模式转向去中心化、利用边缘设备空闲算力的模式，这对于解决AI发展中的环境和控制问题具有重要意义。然而，实现这一愿景面临数据同步、模型聚合、安全隐私等诸多技术挑战。"}}
{"id": "2507.01908", "title": "Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning", "authors": ["Qingdong He", "Xueqin Chen", "Chaoyi Wang", "Yanjie Pan", "Xiaobin Hu", "Zhenye Gan", "Yabiao Wang", "Chengjie Wang", "Xiangtai Li", "Jiangning Zhang"], "summary": "Instruction-based image editing (IIE) has advanced rapidly with the success\nof diffusion models. However, existing efforts primarily focus on simple and\nexplicit instructions to execute editing operations such as adding, deleting,\nmoving, or swapping objects. They struggle to handle more complex implicit\nhypothetical instructions that require deeper reasoning to infer plausible\nvisual changes and user intent. Additionally, current datasets provide limited\nsupport for training and evaluating reasoning-aware editing capabilities.\nArchitecturally, these methods also lack mechanisms for fine-grained detail\nextraction that support such reasoning. To address these limitations, we\npropose Reason50K, a large-scale dataset specifically curated for training and\nevaluating hypothetical instruction reasoning image editing, along with\nReasonBrain, a novel framework designed to reason over and execute implicit\nhypothetical instructions across diverse scenarios. Reason50K includes over 50K\nsamples spanning four key reasoning scenarios: Physical, Temporal, Causal, and\nStory reasoning. ReasonBrain leverages Multimodal Large Language Models (MLLMs)\nfor editing guidance generation and a diffusion model for image synthesis,\nincorporating a Fine-grained Reasoning Cue Extraction (FRCE) module to capture\ndetailed visual and textual semantics essential for supporting instruction\nreasoning. To mitigate the semantic loss, we further introduce a Cross-Modal\nEnhancer (CME) that enables rich interactions between the fine-grained cues and\nMLLM-derived features. Extensive experiments demonstrate that ReasonBrain\nconsistently outperforms state-of-the-art baselines on reasoning scenarios\nwhile exhibiting strong zero-shot generalization to conventional IIE tasks. Our\ndataset and code will be released publicly.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01908v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01908v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "推理式编辑：基于假设指令的图像编辑与视觉推理", "tldr": "本文提出了Reason50K数据集和ReasonBrain框架，用于处理需要深度推理的复杂假设指令式图像编辑，并在推理场景中显著优于现有SOTA方法，同时对传统图像编辑任务表现出强大的零样本泛化能力。", "motivation": "现有的指令式图像编辑（IIE）方法主要关注简单明确的指令，难以处理需要更深层推理来推断合理视觉变化和用户意图的复杂隐式假设指令。此外，当前的训练数据集和架构在支持推理感知编辑能力和细粒度细节提取方面存在局限性。", "method": "为解决上述局限性，本文提出了Reason50K，一个专门为训练和评估假设指令推理图像编辑而策划的大规模数据集，包含超过5万个样本，涵盖物理、时间、因果和故事四种关键推理场景。同时提出了ReasonBrain，一个新颖的框架，旨在对各种场景中的隐式假设指令进行推理和执行。ReasonBrain利用多模态大语言模型（MLLMs）生成编辑指导，并使用扩散模型进行图像合成，其中融入了细粒度推理线索提取（FRCE）模块以捕获支持指令推理所需的详细视觉和文本语义。为缓解语义损失，还引入了跨模态增强器（CME），实现细粒度线索与MLLM派生特征之间的丰富交互。", "result": "广泛的实验表明，ReasonBrain在推理场景中始终优于现有最先进的基线方法，同时对传统的指令式图像编辑任务表现出强大的零样本泛化能力。", "conclusion": "本文提出的Reason50K数据集和ReasonBrain框架有效解决了现有指令式图像编辑方法在处理复杂假设指令和深度视觉推理方面的不足，显著提升了图像编辑的智能化水平。", "translation": "指令式图像编辑（IIE）随着扩散模型的成功而迅速发展。然而，现有工作主要集中于执行添加、删除、移动或交换对象等简单明确的指令。它们难以处理需要更深层推理来推断合理视觉变化和用户意图的更复杂的隐式假设指令。此外，当前的数据集在训练和评估推理感知编辑能力方面提供的支持有限。在架构上，这些方法也缺乏支持此类推理的细粒度细节提取机制。为了解决这些局限性，我们提出了Reason50K，一个专门为训练和评估假设指令推理图像编辑而策划的大规模数据集，以及ReasonBrain，一个旨在对各种场景中的隐式假设指令进行推理和执行的新颖框架。Reason50K包含超过5万个样本，涵盖四种关键推理场景：物理、时间、因果和故事推理。ReasonBrain利用多模态大语言模型（MLLMs）生成编辑指导，并使用扩散模型进行图像合成，其中融入了细粒度推理线索提取（FRCE）模块以捕获支持指令推理所需的详细视觉和文本语义。为了缓解语义损失，我们进一步引入了跨模态增强器（CME），实现细粒度线索与MLLM派生特征之间的丰富交互。广泛的实验表明，ReasonBrain在推理场景中始终优于现有最先进的基线方法，同时对传统的IIE任务表现出强大的零样本泛化能力。我们的数据集和代码将公开发布。", "summary": "本文针对现有指令式图像编辑（IIE）方法在处理复杂、隐式假设指令时缺乏深度推理能力、数据集支持不足以及细粒度细节提取机制缺失等问题，提出了两项关键贡献。首先，引入了Reason50K，一个包含超过5万个样本的大规模数据集，专用于训练和评估假设指令推理图像编辑，涵盖物理、时间、因果和故事四种推理场景。其次，提出了ReasonBrain框架，该框架结合了多模态大语言模型（MLLMs）用于编辑指导生成和扩散模型用于图像合成，并通过细粒度推理线索提取（FRCE）模块和跨模态增强器（CME）来支持详细的视觉和文本语义理解及交互。实验证明，ReasonBrain在推理场景中显著优于现有SOTA方法，并展现出对传统IIE任务的强大零样本泛化能力。", "keywords": "假设指令, 图像编辑, 视觉推理, 扩散模型, 多模态大语言模型", "comments": "本文的创新点在于首次系统性地解决了指令式图像编辑中对复杂、假设性指令进行深度视觉推理的挑战，这超越了传统方法的简单操作范畴。通过构建大规模、多场景的Reason50K数据集，为该领域的研究提供了宝贵资源。ReasonBrain框架结合MLLMs、扩散模型以及特有的细粒度推理和跨模态增强模块，展现了强大的架构设计能力。其对零样本泛化的强调，也预示了该方法在实际应用中的巨大潜力。这项工作对于推动智能图像编辑迈向更高级的认知理解阶段具有重要意义。"}}
{"id": "2507.01909", "title": "Modality Agnostic, patient-specific digital twins modeling temporally varying digestive motion", "authors": ["Jorge Tapias Gomez", "Nishant Nadkarni", "Lando S. Bosma", "Jue Jiang", "Ergys D. Subashi", "William P. Segars", "James M. Balter", "Mert R Sabuncu", "Neelam Tyagi", "Harini Veeraraghavan"], "summary": "Objective: Clinical implementation of deformable image registration (DIR)\nrequires voxel-based spatial accuracy metrics such as manually identified\nlandmarks, which are challenging to implement for highly mobile\ngastrointestinal (GI) organs. To address this, patient-specific digital twins\n(DT) modeling temporally varying motion were created to assess the accuracy of\nDIR methods. Approach: 21 motion phases simulating digestive GI motion as 4D\nsequences were generated from static 3D patient scans using published\nanalytical GI motion models through a semi-automated pipeline. Eleven datasets,\nincluding six T2w FSE MRI (T2w MRI), two T1w 4D golden-angle stack-of-stars,\nand three contrast-enhanced CT scans. The motion amplitudes of the DTs were\nassessed against real patient stomach motion amplitudes extracted from\nindependent 4D MRI datasets. The generated DTs were then used to assess six\ndifferent DIR methods using target registration error, Dice similarity\ncoefficient, and the 95th percentile Hausdorff distance using summary metrics\nand voxel-level granular visualizations. Finally, for a subset of T2w MRI scans\nfrom patients treated with MR-guided radiation therapy, dose distributions were\nwarped and accumulated to assess dose warping errors, including evaluations of\nDIR performance in both low- and high-dose regions for patient-specific error\nestimation. Main results: Our proposed pipeline synthesized DTs modeling\nrealistic GI motion, achieving mean and maximum motion amplitudes and a mean\nlog Jacobian determinant within 0.8 mm and 0.01, respectively, similar to\npublished real-patient gastric motion data. It also enables the extraction of\ndetailed quantitative DIR performance metrics and rigorous validation of dose\nmapping accuracy. Significance: The pipeline enables rigorously testing DIR\ntools for dynamic, anatomically complex regions enabling granular spatial and\ndosimetric accuracies.", "comment": "7 Pages, 6 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.01909v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01909v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "模态无关、患者特异性数字孪生建模随时间变化的消化道运动", "tldr": "该论文提出了一种生成患者特异性胃肠道运动数字孪生（DTs）的管道，用于严格测试变形图像配准（DIR）方法和评估剂量映射精度，展示了真实的运动建模并能够提供详细的DIR性能指标。", "motivation": "变形图像配准（DIR）在临床实施中面临挑战，尤其是在高度移动的胃肠（GI）器官中，因为难以获取基于体素的空间精度指标（如手动地标）。为了解决这一问题，本研究创建了患者特异性数字孪生来评估DIR方法的准确性。", "method": "研究人员通过半自动化流程，利用已发表的分析性GI运动模型，从静态3D患者扫描中生成了21个模拟消化道GI运动的4D序列运动阶段。他们使用了11个数据集（包括MRI和CT）。生成后，DT的运动幅度与真实的患者胃部运动数据进行了评估。随后，这些DT被用于评估六种不同的DIR方法，通过目标配准误差、Dice相似系数和95% Hausdorff距离等指标，并进一步评估了MR引导放射治疗中剂量形变误差。", "result": "所提出的管道成功合成了模拟真实GI运动的数字孪生，其平均和最大运动幅度以及平均对数雅可比行列式与已发表的真实患者胃部运动数据相似（分别在0.8毫米和0.01以内）。该管道还能够提取详细的定量DIR性能指标，并严格验证剂量映射的准确性。", "conclusion": "开发的管道提供了一种强大的方法，用于严格测试动态、解剖学复杂区域的变形图像配准（DIR）工具，从而实现精细的空间和剂量学精度评估，尤其适用于患者特异性误差估计和MR引导放射治疗。", "translation": "目标：变形图像配准（DIR）的临床实施需要基于体素的空间精度指标，例如手动识别的地标，这对于高度移动的胃肠（GI）器官来说难以实现。为了解决这个问题，创建了模拟随时间变化的运动的患者特异性数字孪生（DT），以评估DIR方法的准确性。\n方法：通过半自动化流程，利用已发布的分析性GI运动模型，从静态3D患者扫描中生成了21个模拟消化道GI运动的4D序列运动阶段。包括6个T2w FSE MRI（T2w MRI）、2个T1w 4D golden-angle stack-of-stars和3个对比增强CT扫描在内的11个数据集被使用。DT的运动幅度与从独立的4D MRI数据集中提取的真实患者胃部运动幅度进行了评估。然后，生成的DT用于评估六种不同的DIR方法，使用目标配准误差、Dice相似系数和95% Hausdorff距离，通过汇总指标和体素级精细可视化进行评估。最后，对于MR引导放射治疗患者的T2w MRI扫描子集，对剂量分布进行形变和累积，以评估剂量形变误差，包括评估DIR在低剂量和高剂量区域的性能，用于患者特异性误差估计。\n主要结果：我们提出的管道合成了模拟真实GI运动的DT，其平均和最大运动幅度以及平均对数雅可比行列式分别在0.8毫米和0.01以内，与已发表的真实患者胃部运动数据相似。它还能够提取详细的定量DIR性能指标，并严格验证剂量映射的准确性。\n意义：该管道能够严格测试动态、解剖学复杂区域的DIR工具，从而实现精细的空间和剂量学精度。", "summary": "本文介绍了一种模态无关的管道，用于从静态3D扫描中生成患者特异性胃肠道（GI）运动的数字孪生（DTs）。这些DTs能够准确模拟真实的GI运动，并作为一种强大的工具，严格评估各种变形图像配准（DIR）方法的空间和剂量学精度，包括其在MR引导放射治疗中用于患者特异性误差估计的应用。", "keywords": "数字孪生, 变形图像配准, 胃肠道运动, 患者特异性, 剂量形变", "comments": "该论文提出了一种创新方法，解决了医学成像领域的一个关键挑战：如何准确评估高度移动器官（如胃肠道）的变形图像配准（DIR）。通过创建模拟真实运动的患者特异性数字孪生（DTs），作者提供了一个强大且标准化的框架，用于验证不同成像模态下的DIR算法。这对于提高放射治疗和其他图像引导干预的精度至关重要，因为器官运动是其中一个重要因素。其“模态无关”的特性增强了其通用性。"}}
{"id": "2507.01912", "title": "3D Reconstruction and Information Fusion between Dormant and Canopy Seasons in Commercial Orchards Using Deep Learning and Fast GICP", "authors": ["Ranjan Sapkota", "Zhichao Meng", "Martin Churuvija", "Xiaoqiang Du", "Zenghong Ma", "Manoj Karkee"], "summary": "In orchard automation, dense foliage during the canopy season severely\noccludes tree structures, minimizing visibility to various canopy parts such as\ntrunks and branches, which limits the ability of a machine vision system.\nHowever, canopy structure is more open and visible during the dormant season\nwhen trees are defoliated. In this work, we present an information fusion\nframework that integrates multi-seasonal structural data to support robotic and\nautomated crop load management during the entire growing season. The framework\ncombines high-resolution RGB-D imagery from both dormant and canopy periods\nusing YOLOv9-Seg for instance segmentation, Kinect Fusion for 3D\nreconstruction, and Fast Generalized Iterative Closest Point (Fast GICP) for\nmodel alignment. Segmentation outputs from YOLOv9-Seg were used to extract\ndepth-informed masks, which enabled accurate 3D point cloud reconstruction via\nKinect Fusion; these reconstructed models from each season were subsequently\naligned using Fast GICP to achieve spatially coherent multi-season fusion. The\nYOLOv9-Seg model, trained on manually annotated images, achieved a mean squared\nerror (MSE) of 0.0047 and segmentation mAP@50 scores up to 0.78 for trunks in\ndormant season dataset. Kinect Fusion enabled accurate reconstruction of tree\ngeometry, validated with field measurements resulting in root mean square\nerrors (RMSE) of 5.23 mm for trunk diameter, 4.50 mm for branch diameter, and\n13.72 mm for branch spacing. Fast GICP achieved precise cross-seasonal\nregistration with a minimum fitness score of 0.00197, allowing integrated,\ncomprehensive tree structure modeling despite heavy occlusions during the\ngrowing season. This fused structural representation enables robotic systems to\naccess otherwise obscured architectural information, improving the precision of\npruning, thinning, and other automated orchard operations.", "comment": "17 pages, 4 tables, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.01912v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01912v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "利用深度学习和Fast GICP对商业果园休眠期和冠层期进行三维重建与信息融合", "tldr": "本研究提出了一种信息融合框架，结合休眠期和冠层期的高分辨率RGB-D图像，通过深度学习和快速GICP实现果树三维重建与多季节数据融合，以支持自动化果园管理。", "motivation": "在果园自动化中，冠层期茂密的树叶严重遮挡了树木结构，限制了机器视觉系统的能力。然而，休眠期树木落叶后，冠层结构更加开放和可见。因此，需要一个能整合多季节结构数据的框架来支持整个生长季的机器人和自动化作物负荷管理。", "method": "本框架整合了休眠期和冠层期的高分辨率RGB-D图像。使用YOLOv9-Seg进行实例分割以提取深度信息掩膜，然后通过Kinect Fusion进行3D点云重建。最后，使用Fast Generalized Iterative Closest Point (Fast GICP) 对来自不同季节的重建模型进行对齐，实现空间上一致的多季节融合。", "result": "YOLOv9-Seg模型在休眠期数据集上，对树干分割的MSE为0.0047，mAP@50得分高达0.78。Kinect Fusion实现了准确的树木几何重建，经现场测量验证，树干直径的RMSE为5.23 mm，树枝直径为4.50 mm，树枝间距为13.72 mm。Fast GICP实现了精确的跨季节配准，最小适应度分数为0.00197，即使在生长季节有严重遮挡也能实现集成、全面的树木结构建模。", "conclusion": "所提出的信息融合框架通过整合休眠期和冠层期的三维结构数据，实现了对果树结构的全面建模，即使在生长季节有重度遮挡也能获取关键的建筑信息。这种融合的结构表示提高了修剪、疏果和其他自动化果园操作的精度。", "translation": "在果园自动化中，冠层期茂密的树叶严重遮挡了树木结构，最大限度地降低了对树干和树枝等不同冠层部分的可见性，这限制了机器视觉系统的能力。然而，在树木落叶的休眠期，冠层结构更加开放和可见。在这项工作中，我们提出了一个信息融合框架，该框架整合了多季节结构数据，以支持整个生长季节的机器人和自动化作物负荷管理。该框架结合了休眠期和冠层期的高分辨率RGB-D图像，使用YOLOv9-Seg进行实例分割，Kinect Fusion进行三维重建，以及快速广义迭代最近点（Fast GICP）进行模型对齐。YOLOv9-Seg的分割输出用于提取深度信息掩膜，从而通过Kinect Fusion实现精确的三维点云重建；这些来自每个季节的重建模型随后使用Fast GICP进行对齐，以实现空间上一致的多季节融合。在手动标注图像上训练的YOLOv9-Seg模型，在休眠期数据集上，对树干的均方误差（MSE）为0.0047，分割mAP@50得分高达0.78。Kinect Fusion实现了准确的树木几何重建，通过现场测量验证，树干直径的均方根误差（RMSE）为5.23毫米，树枝直径为4.50毫米，树枝间距为13.72毫米。Fast GICP实现了精确的跨季节配准，最小适应度分数为0.00197，即使在生长季节有严重遮挡也能实现集成、全面的树木结构建模。这种融合的结构表示使机器人系统能够获取原本被遮挡的建筑信息，提高了修剪、疏果和其他自动化果园操作的精度。", "summary": "本研究提出了一个创新的信息融合框架，旨在解决果园自动化中冠层期树木结构遮挡的问题。该框架整合了果树休眠期和冠层期的高分辨率RGB-D图像，并结合YOLOv9-Seg进行实例分割、Kinect Fusion进行3D重建以及Fast GICP进行多季节模型对齐。实验结果表明，该方法能够精确重建树木几何结构，并实现跨季节数据融合，从而在整个生长季节为自动化果园操作提供全面的树木结构信息。", "keywords": "三维重建, 信息融合, 果园自动化, 深度学习, Fast GICP", "comments": "该论文的创新点在于提出了一个多季节信息融合框架，有效解决了果园冠层期树木结构严重遮挡导致机器视觉系统受限的问题。通过结合深度学习（YOLOv9-Seg）进行精确分割和先进的3D重建与配准技术（Kinect Fusion, Fast GICP），实现了对果树从休眠期到冠层期的连续、全面的结构建模。这对于提高自动化修剪、疏果等操作的精度具有重要意义，是果园自动化领域的一个重要进展。"}}
{"id": "2507.01825", "title": "MILP-SAT-GNN: Yet Another Neural SAT Solver", "authors": ["Franco Alberto Cardillo", "Hamza Khyari", "Umberto Straccia"], "summary": "We proposes a novel method that enables Graph Neural Networks (GNNs) to solve\nSAT problems by leveraging a technique developed for applying GNNs to Mixed\nInteger Linear Programming (MILP). Specifically, k-CNF formulae are mapped into\nMILP problems, which are then encoded as weighted bipartite graphs and\nsubsequently fed into a GNN for training and testing. From a theoretical\nperspective: (i) we establish permutation and equivalence invariance results,\ndemonstrating that the method produces outputs that are stable under reordering\nof clauses and variables; (ii) we identify a theoretical limitation, showing\nthat for a class of formulae called foldable formulae, standard GNNs cannot\nalways distinguish satisfiable from unsatisfiable instances; (iii) we prove a\nuniversal approximation theorem, establishing that with Random Node\nInitialization (RNI), the method can approximate SAT solving to arbitrary\nprecision on finite datasets, that is, the GNN becomes approximately sound and\ncomplete on such datasets. Furthermore, we show that for unfoldable formulae,\nthe same approximation guarantee can be achieved without the need for RNI.\nFinally, we conduct an experimental evaluation of our approach, which show\nthat, despite the simplicity of the neural architecture, the method achieves\npromising results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01825v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01825v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "MILP-SAT-GNN：又一个神经SAT求解器", "tldr": "提出了一种新颖的方法，通过将SAT问题转换为MILP并编码为二分图，使GNN能够解决SAT问题，并在理论上证明了其不变性和近似能力，实验结果也显示出潜力。", "motivation": "使图神经网络（GNNs）能够解决布尔可满足性（SAT）问题。", "method": "提出了一种新方法，将k-CNF公式映射为混合整数线性规划（MILP）问题，然后将其编码为加权二分图，并输入到GNN进行训练和测试。", "result": "理论结果：证明了置换和等价不变性；指出了对“可折叠公式”的标准GNN的理论局限性；证明了在有限数据集上，通过随机节点初始化（RNI），该方法可以任意精度近似SAT求解（GNN近似完备和可靠），对于“不可折叠公式”无需RNI也能达到相同的近似保证。实验结果：尽管神经网络架构简单，但该方法取得了有希望的结果。", "conclusion": "尽管神经架构简单，但所提出的将SAT问题通过MILP映射到GNN的方法在解决SAT问题上取得了有希望的结果，并具有重要的理论保证。", "translation": "我们提出了一种新颖的方法，通过利用为将GNN应用于混合整数线性规划（MILP）而开发的技术，使图神经网络（GNNs）能够解决SAT问题。具体来说，k-CNF公式被映射到MILP问题，然后编码为加权二分图，随后输入到GNN进行训练和测试。从理论角度来看：(i) 我们建立了置换和等价不变性结果，表明该方法在子句和变量重新排序下产生稳定的输出；(ii) 我们确定了一个理论局限性，表明对于一类称为可折叠公式的公式，标准GNN不能总是区分可满足实例和不可满足实例；(iii) 我们证明了一个普适逼近定理，表明通过随机节点初始化（RNI），该方法可以在有限数据集上以任意精度逼近SAT求解，即GNN在此类数据集上变得近似可靠和完备。此外，我们表明对于不可折叠公式，无需RNI也能实现相同的逼近保证。最后，我们对我们的方法进行了实验评估，结果表明，尽管神经网络架构简单，该方法仍取得了有希望的结果。", "summary": "本文提出了一种新颖的MILP-SAT-GNN方法，旨在利用图神经网络（GNNs）解决布尔可满足性（SAT）问题。该方法将k-CNF公式转换为混合整数线性规划（MILP）问题，进而编码为加权二分图输入GNN。理论分析证明了该方法的置换和等价不变性，揭示了标准GNN在处理“可折叠公式”时的局限性，并证明了在随机节点初始化（RNI）下，该方法能对有限数据集上的SAT求解进行任意精度近似。实验结果表明，尽管神经网络架构简单，但该方法表现出良好的潜力。", "keywords": "SAT求解器, 图神经网络, 混合整数线性规划, 布尔可满足性, 理论分析", "comments": "这篇论文通过将SAT问题巧妙地转换为MILP问题并利用GNN进行求解，提供了一种新颖的视角。理论分析深入，不仅证明了方法的不变性和近似能力，还指出其局限性，这增加了研究的严谨性。尽管实验结果被描述为“有希望”，但缺乏具体的性能指标，这可能是未来的改进点。将复杂逻辑问题映射到图结构并利用GNN的思路具有普适性，可能启发其他离散优化问题的解决。"}}
{"id": "2507.01926", "title": "IC-Custom: Diverse Image Customization via In-Context Learning", "authors": ["Yaowei Li", "Xiaoyu Li", "Zhaoyang Zhang", "Yuxuan Bian", "Gan Liu", "Xinyuan Li", "Jiale Xu", "Wenbo Hu", "Yating Liu", "Lingen Li", "Jing Cai", "Yuexian Zou", "Yancheng He", "Ying Shan"], "summary": "Image customization, a crucial technique for industrial media production,\naims to generate content that is consistent with reference images. However,\ncurrent approaches conventionally separate image customization into\nposition-aware and position-free customization paradigms and lack a universal\nframework for diverse customization, limiting their applications across various\nscenarios. To overcome these limitations, we propose IC-Custom, a unified\nframework that seamlessly integrates position-aware and position-free image\ncustomization through in-context learning. IC-Custom concatenates reference\nimages with target images to a polyptych, leveraging DiT's multi-modal\nattention mechanism for fine-grained token-level interactions. We introduce the\nIn-context Multi-Modal Attention (ICMA) mechanism with learnable task-oriented\nregister tokens and boundary-aware positional embeddings to enable the model to\ncorrectly handle different task types and distinguish various inputs in\npolyptych configurations. To bridge the data gap, we carefully curated a\nhigh-quality dataset of 12k identity-consistent samples with 8k from real-world\nsources and 4k from high-quality synthetic data, avoiding the overly glossy and\nover-saturated synthetic appearance. IC-Custom supports various industrial\napplications, including try-on, accessory placement, furniture arrangement, and\ncreative IP customization. Extensive evaluations on our proposed ProductBench\nand the publicly available DreamBench demonstrate that IC-Custom significantly\noutperforms community workflows, closed-source models, and state-of-the-art\nopen-source approaches. IC-Custom achieves approximately 73% higher human\npreference across identity consistency, harmonicity, and text alignment\nmetrics, while training only 0.4% of the original model parameters. Project\npage: https://liyaowei-stu.github.io/project/IC_Custom", "comment": "Project page: https://liyaowei-stu.github.io/project/IC_Custom", "pdf_url": "http://arxiv.org/pdf/2507.01926v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01926v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "IC-Custom：通过上下文学习实现多样化图像定制", "tldr": "提出IC-Custom，一个统一的上下文学习框架，通过整合位置感知和位置无关定制，显著提升图像定制效果和效率。", "motivation": "当前图像定制方法将任务分为位置感知和位置无关范式，缺乏统一框架处理多样化定制，限制了其在不同场景的应用。", "method": "提出IC-Custom统一框架，通过上下文学习整合位置感知和位置无关图像定制。它将参考图像与目标图像拼接成多联画，利用DiT的多模态注意力机制进行细粒度交互。引入上下文多模态注意力（ICMA）机制，包含可学习的任务导向注册令牌和边界感知位置嵌入，以处理不同任务类型和区分多联画中的输入。同时，构建了一个包含12k高质量身份一致样本的新数据集，弥补数据鸿沟。", "result": "IC-Custom在提出的ProductBench和公开的DreamBench上进行了广泛评估，结果显示其显著优于社区工作流、闭源模型和最先进的开源方法。在身份一致性、和谐性和文本对齐指标上，IC-Custom的人类偏好提高了约73%，同时仅训练了原始模型参数的0.4%。", "conclusion": "IC-Custom通过统一的上下文学习框架和创新的注意力机制，有效解决了多样化图像定制的挑战，并在性能和效率上取得了显著提升，支持广泛的工业应用。", "translation": "图像定制作为工业媒体生产的关键技术，旨在生成与参考图像一致的内容。然而，当前方法通常将图像定制分为位置感知和位置无关两种范式，缺乏一个用于多样化定制的通用框架，限制了其在各种场景中的应用。为了克服这些局限性，我们提出了IC-Custom，一个通过上下文学习无缝整合位置感知和位置无关图像定制的统一框架。IC-Custom将参考图像与目标图像拼接成多联画，利用DiT的多模态注意力机制进行细粒度的令牌级交互。我们引入了上下文多模态注意力（ICMA）机制，该机制具有可学习的任务导向注册令牌和边界感知位置嵌入，使模型能够正确处理不同任务类型并区分多联画配置中的各种输入。为了弥补数据鸿沟，我们精心策划了一个包含12k身份一致样本的高质量数据集，其中8k来自真实世界，4k来自高质量合成数据，避免了过于光亮和饱和的合成外观。IC-Custom支持各种工业应用，包括试穿、配饰放置、家具布置和创意IP定制。在SOTA的ProductBench和公开的DreamBench上进行的广泛评估表明，IC-Custom显著优于社区工作流、闭源模型和最先进的开源方法。IC-Custom在身份一致性、和谐性和文本对齐指标上实现了约73%的人类偏好提升，同时仅训练了原始模型参数的0.4%。项目页面：https://liyaowei-stu.github.io/project/IC_Custom", "summary": "本文提出了IC-Custom，一个统一的图像定制框架，通过上下文学习整合了位置感知和位置无关的定制范式。该框架将图像拼接成多联画，并引入了具有任务导向注册令牌和边界感知位置嵌入的上下文多模态注意力（ICMA）机制，以处理多样化输入。为弥补数据缺口，作者还构建了一个高质量的身份一致数据集。实验结果表明，IC-Custom在多个基准测试中显著优于现有方法，在人类偏好方面提高了约73%，并实现了高效的参数训练，支持广泛的工业应用。", "keywords": "图像定制, 上下文学习, 多模态注意力, 统一框架, 生成模型", "comments": "IC-Custom的创新点在于其统一的上下文学习框架，通过将不同定制任务（位置感知和位置无关）整合到一个模型中，极大地提高了泛化能力和应用范围。ICMA机制的设计，特别是可学习的注册令牌和边界感知位置嵌入，是其能够有效处理多任务和多输入的关键。此外，高质量数据集的构建也为模型性能提升提供了重要支持。该方法在效率（仅训练0.4%参数）和性能（73%人类偏好提升）上的显著表现，使其在工业媒体生产领域具有重要价值。"}}
{"id": "2507.01829", "title": "mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling", "authors": ["Tristan Torchet", "Christian Metzner", "Laura Kriener", "Melika Payvand"], "summary": "Edge devices for temporal processing demand models that capture both short-\nand long- range dynamics under tight memory constraints. While Transformers\nexcel at sequence modeling, their quadratic memory scaling with sequence length\nmakes them impractical for such settings. Recurrent Neural Networks (RNNs)\noffer constant memory but train sequentially, and Temporal Convolutional\nNetworks (TCNs), though efficient, scale memory with kernel size. To address\nthis, we propose mGRADE (mininally Gated Recurrent Architecture with Delay\nEmbedding), a hybrid-memory system that integrates a temporal 1D-convolution\nwith learnable spacings followed by a minimal gated recurrent unit (minGRU).\nThis design allows the convolutional layer to realize a flexible delay\nembedding that captures rapid temporal variations, while the recurrent module\nefficiently maintains global context with minimal memory overhead. We validate\nour approach on two synthetic tasks, demonstrating that mGRADE effectively\nseparates and preserves multi-scale temporal features. Furthermore, on\nchallenging pixel-by-pixel image classification benchmarks, mGRADE consistently\noutperforms both pure convolutional and pure recurrent counterparts using\napproximately 20% less memory footprint, highlighting its suitability for\nmemory-constrained temporal processing at the edge. This highlights mGRADE's\npromise as an efficient solution for memory-constrained multi-scale temporal\nprocessing at the edge.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01829v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01829v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "mGRADE：极简循环门控结合延迟卷积用于轻量级序列建模", "tldr": "mGRADE结合延迟卷积和极简GRU，在边缘设备上实现了高效、低内存的多尺度序列建模，性能优于纯卷积和纯循环网络。", "motivation": "边缘设备上的时间处理需要捕获短程和长程动态的模型，但现有模型（Transformer、RNN、TCN）在内存或训练效率上存在局限性，不适用于内存受限的场景。", "method": "提出mGRADE（极简门控循环延迟嵌入架构），一种混合内存系统，它将带有可学习间距的时间一维卷积与极简门控循环单元（minGRU）相结合。卷积层实现灵活的延迟嵌入以捕获快速时间变化，而循环模块以最小内存开销维护全局上下文。", "result": "在两个合成任务上，mGRADE有效地分离并保留了多尺度时间特征。在像素级图像分类基准测试中，mGRADE持续优于纯卷积和纯循环模型，同时内存占用减少约20%，这表明其适用于边缘设备上内存受限的时间处理。", "conclusion": "mGRADE是一种有前景的解决方案，适用于边缘设备上内存受限的多尺度时间处理。", "translation": "边缘设备上的时间处理需要模型在严格的内存限制下捕获短程和长程动态。虽然Transformer在序列建模方面表现出色，但其内存随序列长度呈二次方增长，使其在此类设置中不切实际。循环神经网络（RNNs）提供恒定内存但顺序训练，而时间卷积网络（TCNs）虽然高效，但内存随核大小而扩展。为了解决这个问题，我们提出了mGRADE（极简门控循环延迟嵌入架构），一种混合内存系统，它集成了带有可学习间距的时间一维卷积，然后是一个极简门控循环单元（minGRU）。这种设计允许卷积层实现灵活的延迟嵌入，捕获快速时间变化，而循环模块则以最小的内存开销有效地维护全局上下文。我们在两项合成任务上验证了我们的方法，证明mGRADE有效地分离并保留了多尺度时间特征。此外，在具有挑战性的逐像素图像分类基准测试中，mGRADE始终优于纯卷积和纯循环对应模型，内存占用减少约20%，突显了其适用于边缘设备上内存受限的时间处理。这强调了mGRADE作为边缘设备上内存受限多尺度时间处理的有效解决方案的潜力。", "summary": "mGRADE是一种为边缘设备上内存受限的时间序列处理设计的新型混合神经网络架构。它结合了带有可学习间距的1D时间卷积层和极简门控循环单元（minGRU），旨在同时捕获快速时间变化和维持全局上下文，并显著减少内存占用。实验证明，mGRADE在多尺度时间特征分离和像素级图像分类任务上表现优异，性能超越纯卷积和纯循环模型，且内存效率更高，适用于边缘计算场景。", "keywords": "序列建模, 边缘计算, 混合神经网络, 循环神经网络, 卷积神经网络", "comments": "mGRADE的创新点在于其混合架构设计，巧妙地结合了卷积和循环网络的优点，解决了边缘设备内存受限下序列建模的挑战。通过引入可学习间距的延迟卷积和极简GRU，实现了多尺度特征的高效捕获和全局上下文的维护，同时大幅降低了内存消耗。这对于资源受限的边缘AI应用具有重要意义。"}}
{"id": "2507.01927", "title": "evMLP: An Efficient Event-Driven MLP Architecture for Vision", "authors": ["Zhentan Zheng"], "summary": "Deep neural networks have achieved remarkable results in computer vision\ntasks. In the early days, Convolutional Neural Networks (CNNs) were the\nmainstream architecture. In recent years, Vision Transformers (ViTs) have\nbecome increasingly popular. In addition, exploring applications of multi-layer\nperceptrons (MLPs) has provided new perspectives for research into vision model\narchitectures. In this paper, we present evMLP accompanied by a simple\nevent-driven local update mechanism. The proposed evMLP can independently\nprocess patches on images or feature maps via MLPs. We define changes between\nconsecutive frames as \"events\". Under the event-driven local update mechanism,\nevMLP selectively processes patches where events occur. For sequential image\ndata (e.g., video processing), this approach improves computational performance\nby avoiding redundant computations. Through ImageNet image classification\nexperiments, evMLP attains accuracy competitive with state-of-the-art models.\nMore significantly, experimental results on multiple video datasets demonstrate\nthat evMLP reduces computational cost via its event-driven local update\nmechanism while maintaining output consistency with its non-event-driven\nbaseline. The code and trained models are available at\nhttps://github.com/i-evi/evMLP.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01927v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01927v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "evMLP：一种高效的事件驱动型MLP视觉架构", "tldr": "evMLP是一种新的事件驱动型MLP视觉架构，通过选择性处理发生“事件”的图像块来提高计算效率，并在图像分类和视频处理任务中表现出色。", "motivation": "计算机视觉领域深度神经网络（CNN和ViT）取得了显著成果，但探索MLP在视觉模型架构中的应用提供了新视角。本文旨在通过引入事件驱动机制，提高MLP在处理序列图像数据时的计算效率，同时保持性能。", "method": "本文提出了evMLP，并结合了一个简单的事件驱动局部更新机制。evMLP能够通过MLP独立处理图像或特征图上的图像块。它将连续帧之间的变化定义为“事件”，并在此机制下，evMLP只选择性地处理发生事件的图像块，从而避免冗余计算。", "result": "在ImageNet图像分类实验中，evMLP取得了与最先进模型相当的准确性。更重要的是，在多个视频数据集上的实验结果表明，evMLP通过其事件驱动局部更新机制显著降低了计算成本，同时保持了与非事件驱动基线模型输出的一致性。", "conclusion": "evMLP通过其创新的事件驱动局部更新机制，在保持竞争性准确性的同时，显著提高了处理序列图像数据（如视频）的计算效率，证明了事件驱动型MLP在视觉任务中的潜力。", "translation": "深度神经网络在计算机视觉任务中取得了显著成果。早期，卷积神经网络（CNNs）是主流架构。近年来，视觉Transformer（ViTs）越来越受欢迎。此外，探索多层感知机（MLPs）的应用为视觉模型架构的研究提供了新视角。在本文中，我们提出了evMLP，并辅以一个简单的事件驱动局部更新机制。所提出的evMLP可以通过MLP独立处理图像或特征图上的图像块。我们将连续帧之间的变化定义为“事件”。在事件驱动局部更新机制下，evMLP选择性地处理发生事件的图像块。对于序列图像数据（例如视频处理），这种方法通过避免冗余计算来提高计算性能。通过ImageNet图像分类实验，evMLP获得了与最先进模型相当的准确性。更重要的是，在多个视频数据集上的实验结果表明，evMLP通过其事件驱动局部更新机制降低了计算成本，同时保持了与非事件驱动基线模型输出的一致性。代码和训练模型可在https://github.com/i-evi/evMLP获取。", "summary": "本文提出了一种名为evMLP的高效事件驱动型多层感知机（MLP）架构，用于计算机视觉任务。该模型通过引入一个事件驱动的局部更新机制，能够识别并仅处理图像或特征图中发生“事件”（即连续帧间变化）的图像块。这种方法在处理序列图像数据（如视频）时显著减少了冗余计算，从而提高了计算效率。实验证明，evMLP在ImageNet图像分类任务上达到了与SOTA模型相当的准确性，并且在多个视频数据集上显著降低了计算成本，同时保持了与非事件驱动基线模型一致的输出性能。", "keywords": "evMLP, 事件驱动, MLP, 计算机视觉, 视频处理", "comments": "evMLP的创新点在于其将事件驱动机制引入到MLP架构中，以解决传统模型在处理序列数据时存在的冗余计算问题。这种选择性处理机制对于视频处理等实时或资源受限的应用具有重要意义，因为它能大幅提高效率而不牺牲性能。这为未来MLP在动态视觉任务中的应用开辟了新的可能性。"}}
{"id": "2507.01831", "title": "Out-of-Distribution Detection Methods Answer the Wrong Questions", "authors": ["Yucen Lily Li", "Daohan Lu", "Polina Kirichenko", "Shikai Qiu", "Tim G. J. Rudner", "C. Bayan Bruss", "Andrew Gordon Wilson"], "summary": "To detect distribution shifts and improve model safety, many\nout-of-distribution (OOD) detection methods rely on the predictive uncertainty\nor features of supervised models trained on in-distribution data. In this\npaper, we critically re-examine this popular family of OOD detection\nprocedures, and we argue that these methods are fundamentally answering the\nwrong questions for OOD detection. There is no simple fix to this misalignment,\nsince a classifier trained only on in-distribution classes cannot be expected\nto identify OOD points; for instance, a cat-dog classifier may confidently\nmisclassify an airplane if it contains features that distinguish cats from\ndogs, despite generally appearing nothing alike. We find that uncertainty-based\nmethods incorrectly conflate high uncertainty with being OOD, while\nfeature-based methods incorrectly conflate far feature-space distance with\nbeing OOD. We show how these pathologies manifest as irreducible errors in OOD\ndetection and identify common settings where these methods are ineffective.\nAdditionally, interventions to improve OOD detection such as feature-logit\nhybrid methods, scaling of model and data size, epistemic uncertainty\nrepresentation, and outlier exposure also fail to address this fundamental\nmisalignment in objectives. We additionally consider unsupervised density\nestimation and generative models for OOD detection, which we show have their\nown fundamental limitations.", "comment": "Extended version of ICML 2025 paper", "pdf_url": "http://arxiv.org/pdf/2507.01831v1", "categories": ["cs.LG", "stat.ML"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01831v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "分布外检测方法回答了错误的问题", "tldr": "现有OOD检测方法根本上误解了“分布外”的含义，导致不可避免的错误。", "motivation": "批判性地重新审视流行的分布外（OOD）检测方法，并论证这些方法在根本上回答了OOD检测的错误问题。", "method": "本文批判性地重新审视了现有的OOD检测流程，论证了基于不确定性和基于特征的方法错误地将高不确定性或特征空间距离远与OOD混淆。研究展示了这些病态如何表现为OOD检测中不可约的错误，并指出了这些方法无效的常见设置。此外，还分析了旨在改进OOD检测的干预措施以及无监督密度估计和生成模型，并指出了它们的根本局限性。", "result": "研究发现，现有的OOD检测方法根本上回答了错误的问题。基于不确定性的方法错误地将高不确定性与OOD混淆，而基于特征的方法错误地将特征空间距离远与OOD混淆。这些病态表现为OOD检测中不可约的错误。此外，旨在改进OOD检测的干预措施（如特征-logit混合方法、模型和数据规模的扩展、认知不确定性表示、离群值暴露）以及无监督密度估计和生成模型，都未能解决这种根本性的目标错位或存在自身的局限性。", "conclusion": "OOD检测方法，尤其是那些依赖于在分布内数据上训练的监督模型的方法，存在根本性缺陷，因为仅在分布内类别上训练的分类器无法有效识别OOD点。这种错位没有简单的解决方案，即使是先进的干预措施或其他模型类型也未能解决这一核心问题。", "translation": "为了检测分布偏移并提高模型安全性，许多分布外（OOD）检测方法依赖于在分布内数据上训练的监督模型的预测不确定性或特征。在本文中，我们批判性地重新审视了这一类流行的OOD检测程序，并论证这些方法在根本上回答了OOD检测的错误问题。这种错位没有简单的解决方案，因为一个仅在分布内类别上训练的分类器无法期望识别OOD点；例如，一个猫狗分类器可能会自信地将一架飞机错误分类，如果飞机包含区分猫狗的特征，尽管它们通常看起来完全不同。我们发现，基于不确定性的方法错误地将高不确定性与OOD混淆，而基于特征的方法错误地将特征空间距离远与OOD混淆。我们展示了这些病态如何在OOD检测中表现为不可约的错误，并指出了这些方法无效的常见设置。此外，旨在改进OOD检测的干预措施，例如特征-logit混合方法、模型和数据规模的扩展、认知不确定性表示以及离群值暴露，也未能解决这种根本性的目标错位。我们还考虑了用于OOD检测的无监督密度估计和生成模型，并指出它们也存在自身的根本局限性。", "summary": "本文批判性地分析了当前主流的分布外（OOD）检测方法。作者认为，这些方法，无论是基于不确定性还是基于特征，都存在根本性的缺陷，即它们错误地将高不确定性或远离特征空间与OOD混淆，导致不可避免的检测错误。研究指出，由于分类器仅在已知分布数据上训练，无法有效识别未知分布数据，因此这种目标错位是固有的。即使是各种改进措施和替代模型（如无监督密度估计和生成模型）也未能解决这一根本问题，或存在自身局限性。", "keywords": "分布外检测, 不确定性, 特征方法, 分布偏移, 模型安全", "comments": "这篇论文提供了一个重要的批判性视角，质疑了广泛使用的OOD检测方法的根本假设。其创新之处在于明确指出这些方法“回答了错误的问题”，并深入解释了为何常见的改进措施和替代模型也无法解决这一核心问题。这可能促使OOD研究领域重新思考，强调需要开发真正理解分布外数据的检测方法，而不仅仅依赖于分布内模型的属性。"}}
{"id": "2507.01938", "title": "CI-VID: A Coherent Interleaved Text-Video Dataset", "authors": ["Yiming Ju", "Jijin Hu", "Zhengxiong Luo", "Haoge Deng", "hanyu Zhao", "Li Du", "Chengwei Wu", "Donglin Hao", "Xinlong Wang", "Tengfei Pan"], "summary": "Text-to-video (T2V) generation has recently attracted considerable attention,\nresulting in the development of numerous high-quality datasets that have\npropelled progress in this area. However, existing public datasets are\nprimarily composed of isolated text-video (T-V) pairs and thus fail to support\nthe modeling of coherent multi-clip video sequences. To address this\nlimitation, we introduce CI-VID, a dataset that moves beyond isolated\ntext-to-video (T2V) generation toward text-and-video-to-video (TV2V)\ngeneration, enabling models to produce coherent, multi-scene video sequences.\nCI-VID contains over 340,000 samples, each featuring a coherent sequence of\nvideo clips with text captions that capture both the individual content of each\nclip and the transitions between them, enabling visually and textually grounded\ngeneration. To further validate the effectiveness of CI-VID, we design a\ncomprehensive, multi-dimensional benchmark incorporating human evaluation,\nVLM-based assessment, and similarity-based metrics. Experimental results\ndemonstrate that models trained on CI-VID exhibit significant improvements in\nboth accuracy and content consistency when generating video sequences. This\nfacilitates the creation of story-driven content with smooth visual transitions\nand strong temporal coherence, underscoring the quality and practical utility\nof the CI-VID dataset We release the CI-VID dataset and the accompanying code\nfor data construction and evaluation at: https://github.com/ymju-BAAI/CI-VID", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01938v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01938v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "CI-VID：一个连贯交错的文本-视频数据集", "tldr": "CI-VID是一个新的文本-视频数据集，旨在解决现有数据集无法支持连贯多片段视频序列生成的问题。它包含超过34万个样本，每个样本都包含连贯的视频片段序列和描述内容及过渡的文本字幕。实验证明，在此数据集上训练的模型在视频序列生成方面表现出显著的准确性和内容一致性提升。", "motivation": "现有的公共文本-视频数据集主要由孤立的文本-视频对组成，无法支持连贯多片段视频序列的建模，这限制了文本到视频（T2V）生成在创建故事驱动内容方面的能力。", "method": "我们引入了CI-VID数据集，旨在支持文本和视频到视频（TV2V）生成，从而使模型能够生成连贯的多场景视频序列。CI-VID包含超过34万个样本，每个样本都具有连贯的视频片段序列，并配有描述每个片段内容和它们之间过渡的文本字幕。为了验证CI-VID的有效性，我们设计了一个多维度的基准，包括人工评估、基于VLM的评估和基于相似度的度量。", "result": "实验结果表明，在CI-VID上训练的模型在生成视频序列时，在准确性和内容一致性方面都表现出显著的改进。这有助于创建具有平滑视觉过渡和强大时间连贯性的故事驱动内容。", "conclusion": "CI-VID数据集的质量和实用性得到了强调，它能够促进故事驱动内容的创建，并具有平滑的视觉过渡和强大的时间连贯性。", "translation": "文本到视频（T2V）生成最近引起了相当大的关注，导致了许多高质量数据集的开发，这些数据集推动了该领域的进展。然而，现有的公共数据集主要由孤立的文本-视频（T-V）对组成，因此无法支持连贯多片段视频序列的建模。为了解决这一限制，我们引入了CI-VID，一个超越孤立的文本到视频（T2V）生成，转向文本和视频到视频（TV2V）生成的数据集，使模型能够生成连贯的多场景视频序列。CI-VID包含超过340,000个样本，每个样本都具有连贯的视频片段序列和文本字幕，这些字幕既捕捉了每个片段的独立内容，也捕捉了它们之间的过渡，从而实现了视觉和文本上的接地生成。为了进一步验证CI-VID的有效性，我们设计了一个全面的多维度基准，包括人工评估、基于VLM的评估和基于相似度的度量。实验结果表明，在CI-VID上训练的模型在生成视频序列时，在准确性和内容一致性方面都表现出显著的改进。这有助于创建具有平滑视觉过渡和强大时间连贯性的故事驱动内容，这突显了CI-VID数据集的质量和实用性。我们发布了CI-VID数据集以及用于数据构建和评估的配套代码，网址为：https://github.com/ymju-BAAI/CI-VID", "summary": "本文介绍了CI-VID，一个用于连贯文本-视频生成的创新数据集，旨在解决现有数据集在支持多片段视频序列建模方面的不足。CI-VID包含超过34万个样本，每个样本都由连贯的视频片段序列和详细描述片段内容及过渡的文本字幕组成。通过在CI-VID上训练模型并进行全面的基准测试，研究表明模型在视频序列生成方面展现出更高的准确性和内容一致性，尤其适用于创建故事驱动内容。该数据集及其代码已公开发布。", "keywords": "文本-视频数据集, 视频生成, 连贯性, CI-VID, 多片段序列", "comments": "CI-VID数据集创新性地解决了现有文本-视频数据集在处理多片段视频序列连贯性方面的局限性，从孤立的T2V生成迈向了TV2V生成。其庞大的样本量和对片段间过渡的详细标注，对于推动故事驱动视频内容生成技术的发展具有重要意义。数据集的设计和多维度的评估方法也增强了其实用性和可靠性。"}}
{"id": "2507.01945", "title": "LongAnimation: Long Animation Generation with Dynamic Global-Local Memory", "authors": ["Nan Chen", "Mengqi Huang", "Yihao Meng", "Zhendong Mao"], "summary": "Animation colorization is a crucial part of real animation industry\nproduction. Long animation colorization has high labor costs. Therefore,\nautomated long animation colorization based on the video generation model has\nsignificant research value. Existing studies are limited to short-term\ncolorization. These studies adopt a local paradigm, fusing overlapping features\nto achieve smooth transitions between local segments. However, the local\nparadigm neglects global information, failing to maintain long-term color\nconsistency. In this study, we argue that ideal long-term color consistency can\nbe achieved through a dynamic global-local paradigm, i.e., dynamically\nextracting global color-consistent features relevant to the current generation.\nSpecifically, we propose LongAnimation, a novel framework, which mainly\nincludes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a Color\nConsistency Reward. The SketchDiT captures hybrid reference features to support\nthe DGLM module. The DGLM module employs a long video understanding model to\ndynamically compress global historical features and adaptively fuse them with\nthe current generation features. To refine the color consistency, we introduce\na Color Consistency Reward. During inference, we propose a color consistency\nfusion to smooth the video segment transition. Extensive experiments on both\nshort-term (14 frames) and long-term (average 500 frames) animations show the\neffectiveness of LongAnimation in maintaining short-term and long-term color\nconsistency for open-domain animation colorization task. The code can be found\nat https://cn-makers.github.io/long_animation_web/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01945v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01945v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "LongAnimation：基于动态全局-局部记忆的长动画生成", "tldr": "LongAnimation提出了一种新的框架，通过动态全局-局部记忆来解决长动画上色中的长期颜色一致性问题，实验证明其在短动画和长动画上色任务中均有效。", "motivation": "动画上色是动画产业生产的关键部分，长动画上色的人力成本高昂。现有研究仅限于短时上色，采用局部范式，忽略了全局信息，导致无法维持长期颜色一致性。", "method": "提出LongAnimation框架，主要包括SketchDiT、动态全局-局部记忆（DGLM）和颜色一致性奖励。SketchDiT捕获混合参考特征以支持DGLM模块。DGLM模块利用长视频理解模型动态压缩全局历史特征，并与当前生成特征自适应融合。引入颜色一致性奖励以优化颜色一致性。推理时，提出颜色一致性融合以平滑视频片段过渡。", "result": "在短时（14帧）和长时（平均500帧）动画上的大量实验表明，LongAnimation在开放域动画上色任务中，能有效保持短时和长期颜色一致性。", "conclusion": "通过动态全局-局部范式，即动态提取与当前生成相关的全局颜色一致性特征，可以实现理想的长期颜色一致性。", "translation": "动画上色是实际动画产业生产中的关键部分。长动画上色具有高昂的人力成本。因此，基于视频生成模型的自动化长动画上色具有重要的研究价值。现有研究仅限于短时上色。这些研究采用局部范式，融合重叠特征以实现局部片段之间的平滑过渡。然而，局部范式忽略了全局信息，未能保持长期颜色一致性。在本研究中，我们认为理想的长期颜色一致性可以通过动态全局-局部范式实现，即动态提取与当前生成相关的全局颜色一致性特征。具体来说，我们提出了LongAnimation，一个新颖的框架，主要包括SketchDiT、动态全局-局部记忆（DGLM）和颜色一致性奖励。SketchDiT捕获混合参考特征以支持DGLM模块。DGLM模块利用长视频理解模型动态压缩全局历史特征并将其与当前生成特征自适应融合。为了优化颜色一致性，我们引入了颜色一致性奖励。在推理过程中，我们提出了颜色一致性融合以平滑视频片段过渡。在短时（14帧）和长时（平均500帧）动画上的大量实验表明，LongAnimation在开放域动画上色任务中，能有效保持短时和长期颜色一致性。代码可在https://cn-makers.github.io/long_animation_web/找到。", "summary": "本研究提出LongAnimation框架，旨在解决长动画上色中的长期颜色一致性问题。现有方法因缺乏全局信息而无法保持长期一致性。LongAnimation引入动态全局-局部记忆（DGLM）范式，通过SketchDiT捕获特征，DGLM动态压缩并融合全局历史特征与当前生成特征，并辅以颜色一致性奖励和推理时的颜色一致性融合。实验证明，该方法在短时和长时动画上色中均能有效保持颜色一致性。", "keywords": "长动画上色, 颜色一致性, 动态全局-局部记忆, 视频生成, LongAnimation", "comments": "本文针对长动画上色中的核心挑战——长期颜色一致性问题，提出了一个创新的解决方案。其核心在于引入了动态全局-局部记忆（DGLM）模块，能够动态地提取和利用全局历史信息，有效弥补了现有局部范式的不足。这对于自动化长动画生产具有重要意义。"}}
{"id": "2507.01875", "title": "Towards Foundation Auto-Encoders for Time-Series Anomaly Detection", "authors": ["Gastón García González", "Pedro Casas", "Emilio Martínez", "Alicia Fernández"], "summary": "We investigate a novel approach to time-series modeling, inspired by the\nsuccesses of large pretrained foundation models. We introduce FAE (Foundation\nAuto-Encoders), a foundation generative-AI model for anomaly detection in\ntime-series data, based on Variational Auto-Encoders (VAEs). By foundation, we\nmean a model pretrained on massive amounts of time-series data which can learn\ncomplex temporal patterns useful for accurate modeling, forecasting, and\ndetection of anomalies on previously unseen datasets. FAE leverages VAEs and\nDilated Convolutional Neural Networks (DCNNs) to build a generic model for\nunivariate time-series modeling, which could eventually perform properly in\nout-of-the-box, zero-shot anomaly detection applications. We introduce the main\nconcepts of FAE, and present preliminary results in different multi-dimensional\ntime-series datasets from various domains, including a real dataset from an\noperational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.", "comment": "Presented at ACM KDD 2024, MiLeTS 2024 Workshop, August 25, 2024,\n  Barcelona, Spain", "pdf_url": "http://arxiv.org/pdf/2507.01875v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01875v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "迈向时间序列异常检测的基础自编码器", "tldr": "FAE是一种基于VAEs的新型时间序列异常检测基础模型，受大型预训练模型启发，旨在实现零样本异常检测，并在多样化数据集上取得了初步结果。", "motivation": "受到大型预训练基础模型成功的启发，研究一种新的时间序列建模方法，旨在开发一个可以学习复杂时间模式并对未见数据集进行准确建模、预测和异常检测的通用模型，特别是为了实现开箱即用、零样本异常检测。", "method": "提出基础自编码器（FAE），这是一种基于变分自编码器（VAEs）和扩张卷积神经网络（DCNNs）的基础生成式AI模型。FAE通过在海量时间序列数据上进行预训练来学习复杂的时序模式，旨在构建一个用于单变量时间序列建模的通用模型，以实现零样本异常检测。", "result": "在来自不同领域（包括一个真实的移动ISP数据集和KDD 2021异常检测数据集）的不同多维时间序列数据集上展示了初步结果。", "conclusion": "FAE作为一种基于VAEs和DCNNs的时间序列异常检测基础模型，通过在大量数据上预训练，显示出在零样本、开箱即用场景下进行异常检测的潜力，并在多种数据集上取得了初步的积极结果。", "translation": "我们研究了一种新颖的时间序列建模方法，其灵感来源于大型预训练基础模型的成功。我们引入了FAE（基础自编码器），这是一种基于变分自编码器（VAEs）的生成式AI基础模型，用于时间序列数据中的异常检测。所谓“基础”，我们指的是一个在海量时间序列数据上预训练的模型，它可以学习复杂的时间模式，这些模式对于在以前未见过的数据集上进行准确建模、预测和异常检测非常有用。FAE利用VAEs和扩张卷积神经网络（DCNNs）来构建一个通用的单变量时间序列建模模型，该模型最终可以在开箱即用、零样本的异常检测应用中表现良好。我们介绍了FAE的主要概念，并在来自不同领域（包括一个来自运营中的移动ISP的真实数据集，以及著名的KDD 2021异常检测数据集）的不同多维时间序列数据集上展示了初步结果。", "summary": "本文提出了一种名为FAE（基础自编码器）的新型时间序列异常检测模型。FAE是一个基于变分自编码器（VAEs）和扩张卷积神经网络（DCNNs）的生成式AI模型，其核心思想是像大型基础模型一样，在海量时间序列数据上进行预训练，以学习复杂的时序模式。这使得FAE能够对未见数据集进行准确的建模、预测和异常检测，并有望实现开箱即用和零样本异常检测。研究者介绍了FAE的主要概念，并展示了在包括真实移动ISP数据和KDD 2021数据集在内的多种多维时间序列数据集上的初步结果。", "keywords": "Foundation Auto-Encoders, Time-Series Anomaly Detection, Variational Auto-Encoders, Zero-Shot Learning, Pretrained Models", "comments": "该论文提出了一种受大型基础模型启发的时间序列异常检测新范式，即“基础自编码器”（FAE）。其创新点在于尝试将预训练大模型的理念引入时间序列异常检测领域，通过在海量数据上预训练，旨在实现对未知数据的零样本检测能力，这对于实际应用具有重要意义。初步结果显示了其潜力，但作为“初步结果”，其性能和泛化能力仍需进一步的广泛验证。"}}
{"id": "2507.01949", "title": "Kwai Keye-VL Technical Report", "authors": ["Kwai Keye Team", "Biao Yang", "Bin Wen", "Changyi Liu", "Chenglong Chu", "Chengru Song", "Chongling Rao", "Chuan Yi", "Da Li", "Dunju Zang", "Fan Yang", "Guorui Zhou", "Hao Peng", "Haojie Ding", "Jiaming Huang", "Jiangxia Cao", "Jiankang Chen", "Jingyun Hua", "Jin Ouyang", "Kaibing Chen", "Kaiyu Jiang", "Kaiyu Tang", "Kun Gai", "Shengnan Zhang", "Siyang Mao", "Sui Huang", "Tianke Zhang", "Tingting Gao", "Wei Chen", "Wei Yuan", "Xiangyu Wu", "Xiao Hu", "Xingyu Lu", "Yang Zhou", "Yi-Fan Zhang", "Yiping Yang", "Yulong Chen", "Zhenhua Wu", "Zhenyu Li", "Zhixin Ling", "Ziming Li", "Dehua Ma", "Di Xu", "Haixuan Gao", "Hang Li", "Jiawei Guo", "Jing Wang", "Lejian Ren", "Muhao Wei", "Qianqian Wang", "Qigen Hu", "Shiyao Wang", "Tao Yu", "Xinchen Luo", "Yan Li", "Yiming Liang", "Yuhang Hu", "Zeyi Lu", "Zhuoran Yang", "Zixing Zhang"], "summary": "While Multimodal Large Language Models (MLLMs) demonstrate remarkable\ncapabilities on static images, they often fall short in comprehending dynamic,\ninformation-dense short-form videos, a dominant medium in today's digital\nlandscape. To bridge this gap, we introduce \\textbf{Kwai Keye-VL}, an\n8-billion-parameter multimodal foundation model engineered for leading-edge\nperformance in short-video understanding while maintaining robust\ngeneral-purpose vision-language abilities. The development of Keye-VL rests on\ntwo core pillars: a massive, high-quality dataset exceeding 600 billion tokens\nwith a strong emphasis on video, and an innovative training recipe. This recipe\nfeatures a four-stage pre-training process for solid vision-language alignment,\nfollowed by a meticulous two-phase post-training process. The first\npost-training stage enhances foundational capabilities like instruction\nfollowing, while the second phase focuses on stimulating advanced reasoning. In\nthis second phase, a key innovation is our five-mode ``cold-start'' data\nmixture, which includes ``thinking'', ``non-thinking'', ``auto-think'', ``think\nwith image'', and high-quality video data. This mixture teaches the model to\ndecide when and how to reason. Subsequent reinforcement learning (RL) and\nalignment steps further enhance these reasoning capabilities and correct\nabnormal model behaviors, such as repetitive outputs. To validate our approach,\nwe conduct extensive evaluations, showing that Keye-VL achieves\nstate-of-the-art results on public video benchmarks and remains highly\ncompetitive on general image-based tasks (Figure 1). Furthermore, we develop\nand release the \\textbf{KC-MMBench}, a new benchmark tailored for real-world\nshort-video scenarios, where Keye-VL shows a significant advantage.", "comment": "Technical Report: https://github.com/Kwai-Keye/Keye", "pdf_url": "http://arxiv.org/pdf/2507.01949v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01949v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "快手 Keye-VL 技术报告", "tldr": "Kwai Keye-VL是一个80亿参数的多模态基础模型，通过创新训练方法和海量数据集，在短视频理解方面达到最先进水平，并发布了新的基准测试。", "motivation": "当前多模态大语言模型（MLLMs）在静态图像处理上表现出色，但在理解动态、信息密集的短视频方面存在不足，而短视频是当前数字领域的主流媒介。为了弥补这一差距，本文提出了Kwai Keye-VL。", "method": "Kwai Keye-VL是一个80亿参数的多模态基础模型。其开发基于两大核心支柱：一是包含超过6000亿token的、侧重视频的大规模高质量数据集；二是创新的训练方案。该方案包括四阶段的预训练过程，旨在实现扎实的视觉-语言对齐，随后是细致的两阶段后训练过程。第一个后训练阶段增强了指令遵循等基础能力，而第二个阶段则侧重于激发高级推理能力。在第二个阶段中，一个关键创新是其五种模式的“冷启动”数据混合，包括“思考”、“非思考”、“自动思考”、“带图像思考”和高质量视频数据，这旨在教会模型何时以及如何进行推理。随后的强化学习（RL）和对齐步骤进一步增强了这些推理能力，并纠正了模型异常行为，如重复输出。", "result": "Keye-VL在公共视频基准测试上取得了最先进的结果，并在通用图像任务上保持高度竞争力。此外，本文开发并发布了KC-MMBench，这是一个针对真实世界短视频场景的新基准测试，Keye-VL在该基准测试中表现出显著优势。", "conclusion": "本文成功推出了Kwai Keye-VL，一个强大的80亿参数多模态基础模型，专为短视频理解设计，在相关任务上取得了最先进的性能，并引入了新的专用基准测试KC-MMBench。", "translation": "尽管多模态大语言模型（MLLMs）在静态图像上展示了卓越的能力，但它们在理解动态的、信息密集的短视频方面常常表现不足，而短视频是当今数字领域的主流媒介。为了弥补这一差距，我们引入了Kwai Keye-VL，一个80亿参数的多模态基础模型，旨在实现短视频理解的领先性能，同时保持强大的通用视觉-语言能力。Keye-VL的开发基于两大核心支柱：一个超过6000亿token的、侧重视频的大规模高质量数据集，以及一个创新的训练方案。该方案包括四阶段的预训练过程，旨在实现扎实的视觉-语言对齐，随后是细致的两阶段后训练过程。第一个后训练阶段增强了指令遵循等基础能力，而第二个阶段则侧重于激发高级推理。在第二个阶段中，一个关键创新是我们的五种模式“冷启动”数据混合，包括“思考”、“非思考”、“自动思考”、“带图像思考”和高质量视频数据。这种混合数据教会模型何时以及如何进行推理。随后的强化学习（RL）和对齐步骤进一步增强了这些推理能力，并纠正了模型异常行为，如重复输出。为了验证我们的方法，我们进行了广泛的评估，结果显示Keye-VL在公共视频基准测试上取得了最先进的结果，并在通用图像任务上保持高度竞争力（图1）。此外，我们开发并发布了KC-MMBench，这是一个针对真实世界短视频场景的新基准测试，Keye-VL在该基准测试中表现出显著优势。", "summary": "本文介绍了Kwai Keye-VL，一个80亿参数的多模态基础模型，旨在解决当前多模态大语言模型在短视频理解方面的不足。该模型利用一个包含超过6000亿token的以视频为中心的大规模数据集，并采用了创新的多阶段训练方案，包括独特的五模式“冷启动”数据混合，以实现高级推理。评估结果表明，Keye-VL在公共视频基准测试上取得了最先进的成果，在图像任务上保持竞争力，并在新发布的专为真实世界短视频场景设计的KC-MMBench上表现出显著优势。", "keywords": "多模态大语言模型, 短视频理解, Keye-VL, 训练方案, KC-MMBench", "comments": "这篇论文解决了当前多模态大语言模型（MLLMs）的一个关键缺陷：它们在理解动态短视频方面的有限能力。其创新之处在于其庞大的以视频为中心的数据集（6000亿token）以及精心设计的多阶段训练方案，特别是用于推理的“五模式冷启动数据混合”以及随后的强化学习/对齐步骤。KC-MMBench的引入也意义重大，因为它为真实世界的短视频场景提供了一个量身定制的基准测试，这对于推动该特定领域的研究至关重要。该模型80亿的参数量也表明了在构建强大基础模型方面的巨大投入。"}}
{"id": "2507.01924", "title": "Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection", "authors": ["Samirah Bakker", "Yao Ma", "Seyed Sahand Mohammadi Ziabari"], "summary": "The complexity of mental healthcare billing enables anomalies, including\nfraud. While machine learning methods have been applied to anomaly detection,\nthey often struggle with class imbalance, label scarcity, and complex\nsequential patterns. This study explores a hybrid deep learning approach\ncombining Long Short-Term Memory (LSTM) networks and Transformers, with\npseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior\nwork has not evaluated such hybrid models trained on pseudo-labeled data in the\ncontext of healthcare billing. The approach is evaluated on two real-world\nbilling datasets related to mental healthcare. The iForest LSTM baseline\nachieves the highest recall (0.963) on declaration-level data. On the\noperation-level data, the hybrid iForest-based model achieves the highest\nrecall (0.744), though at the cost of lower precision. These findings highlight\nthe potential of combining pseudo-labeling with hybrid deep learning in\ncomplex, imbalanced anomaly detection settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01924v1", "categories": ["cs.LG", "cs.AI"], "cate": "cs.LG", "url": "http://arxiv.org/abs/2507.01924v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "探索一种混合深度学习方法用于精神医疗服务提供者计费异常检测：通过半监督异常检测解决标签稀缺性问题", "tldr": "本研究探索了一种结合LSTM和Transformer的混合深度学习方法，通过iForest和Autoencoder伪标签技术，解决精神医疗计费中标签稀缺的异常检测问题，并在真实数据集上取得了良好效果。", "motivation": "精神医疗计费的复杂性使得异常（包括欺诈）得以发生。现有机器学习方法在异常检测中常面临类别不平衡、标签稀缺和复杂序列模式的挑战。", "method": "本文提出了一种混合深度学习方法，结合了长短期记忆（LSTM）网络和Transformer，并通过Isolation Forests (iForest) 和Autoencoders (AE) 进行伪标签。该方法在两个真实的精神医疗计费数据集上进行了评估。", "result": "在声明级别数据上，iForest LSTM基线模型获得了最高召回率（0.963）。在操作级别数据上，基于iForest的混合模型获得了最高召回率（0.744），尽管精度较低。", "conclusion": "这些发现突出了在复杂、不平衡的异常检测环境中，将伪标签与混合深度学习相结合的潜力。", "translation": "精神医疗计费的复杂性使得异常（包括欺诈）得以发生。尽管机器学习方法已被应用于异常检测，但它们常常面临类别不平衡、标签稀缺和复杂序列模式的挑战。本研究探索了一种结合长短期记忆（LSTM）网络和Transformer的混合深度学习方法，并通过Isolation Forests (iForest) 和Autoencoders (AE) 进行伪标签。以往的工作尚未在医疗计费背景下评估此类在伪标签数据上训练的混合模型。该方法在两个与精神医疗相关的真实计费数据集上进行了评估。在声明级别数据上，iForest LSTM基线模型获得了最高召回率（0.963）。在操作级别数据上，基于iForest的混合模型获得了最高召回率（0.744），尽管精度较低。这些发现突出了在复杂、不平衡的异常检测环境中，将伪标签与混合深度学习相结合的潜力。", "summary": "本文旨在解决精神医疗计费中存在的异常（包括欺诈）检测问题，特别是应对标签稀缺、类别不平衡和复杂序列模式的挑战。研究提出了一种新颖的混合深度学习方法，该方法结合了LSTM网络和Transformer模型，并通过Isolation Forests和Autoencoders生成伪标签。在两个真实世界的精神医疗计费数据集上的评估表明，该方法在召回率方面表现出色，特别是在声明级别数据上iForest LSTM基线模型达到了0.963的召回率，在操作级别数据上iForest混合模型达到了0.744的召回率，验证了伪标签与混合深度学习结合在复杂不平衡异常检测环境中的潜力。", "keywords": "异常检测, 混合深度学习, 伪标签, 精神医疗计费, 标签稀缺", "comments": "本文的创新点在于首次将混合深度学习（LSTM+Transformer）与伪标签技术（iForest+AE）相结合应用于医疗计费异常检测，尤其关注了标签稀缺这一实际挑战。其重要性在于为精神医疗领域的欺诈和异常检测提供了新的有效方法，有助于提高检测效率和准确性。局限性可能在于操作级别数据上的精度有所降低，这可能需要进一步优化模型或策略。"}}
{"id": "2507.01953", "title": "FreeMorph: Tuning-Free Generalized Image Morphing with Diffusion Model", "authors": ["Yukang Cao", "Chenyang Si", "Jinghao Wang", "Ziwei Liu"], "summary": "We present FreeMorph, the first tuning-free method for image morphing that\naccommodates inputs with different semantics or layouts. Unlike existing\nmethods that rely on finetuning pre-trained diffusion models and are limited by\ntime constraints and semantic/layout discrepancies, FreeMorph delivers\nhigh-fidelity image morphing without requiring per-instance training. Despite\ntheir efficiency and potential, tuning-free methods face challenges in\nmaintaining high-quality results due to the non-linear nature of the multi-step\ndenoising process and biases inherited from the pre-trained diffusion model. In\nthis paper, we introduce FreeMorph to address these challenges by integrating\ntwo key innovations. 1) We first propose a guidance-aware spherical\ninterpolation design that incorporates explicit guidance from the input images\nby modifying the self-attention modules, thereby addressing identity loss and\nensuring directional transitions throughout the generated sequence. 2) We\nfurther introduce a step-oriented variation trend that blends self-attention\nmodules derived from each input image to achieve controlled and consistent\ntransitions that respect both inputs. Our extensive evaluations demonstrate\nthat FreeMorph outperforms existing methods, being 10x ~ 50x faster and\nestablishing a new state-of-the-art for image morphing.", "comment": "ICCV 2025. Project page: https://yukangcao.github.io/FreeMorph/", "pdf_url": "http://arxiv.org/pdf/2507.01953v1", "categories": ["cs.CV"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01953v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "FreeMorph：基于扩散模型的免调优通用图像形变", "tldr": "FreeMorph是一个免调优的图像形变方法，首次实现了对不同语义和布局图像的高质量形变，比现有方法快10-50倍。", "motivation": "现有图像形变方法依赖于对预训练扩散模型的微调，受限于时间成本和语义/布局差异。免调优方法虽高效，但因多步去噪过程的非线性以及预训练模型偏差，难以保持高质量结果。", "method": "FreeMorph通过整合两项关键创新来解决挑战：1) 提出一种引导感知的球形插值设计，通过修改自注意力模块，融入输入图像的显式引导，解决身份丢失并确保方向性过渡。2) 引入一种面向步骤的变异趋势，融合来自每个输入图像的自注意力模块，实现受控且一致的过渡，同时尊重两个输入。", "result": "FreeMorph在图像形变方面超越现有方法，速度快10到50倍，并建立了新的最先进水平（SOTA）。", "conclusion": "FreeMorph成功解决了现有图像形变方法的局限性，通过创新的设计实现了高质量、高效且通用的图像形变，树立了新的行业标杆。", "translation": "我们提出了FreeMorph，这是第一个免调优的图像形变方法，可以适应具有不同语义或布局的输入。与依赖于微调预训练扩散模型并受时间限制和语义/布局差异限制的现有方法不同，FreeMorph无需每次实例训练即可提供高保真图像形变。尽管免调优方法效率高且潜力大，但由于多步去噪过程的非线性以及从预训练扩散模型继承的偏差，它们在保持高质量结果方面面临挑战。在本文中，我们引入FreeMorph，通过整合两项关键创新来解决这些挑战。1) 我们首先提出了一种引导感知的球形插值设计，通过修改自注意力模块，融入输入图像的显式引导，从而解决身份丢失并确保在生成的序列中实现方向性过渡。2) 我们进一步引入了一种面向步骤的变异趋势，该趋势融合了来自每个输入图像的自注意力模块，以实现受控且一致的过渡，同时尊重两个输入。我们广泛的评估表明，FreeMorph优于现有方法，速度快10到50倍，并为图像形变建立了新的最先进水平。", "summary": "FreeMorph是一种开创性的免调优图像形变方法，首次支持不同语义和布局的图像输入。它通过引入引导感知的球形插值和面向步骤的变异趋势，解决了传统微调方法的局限性以及免调优方法中存在的质量挑战。实验证明，FreeMorph在性能上超越现有技术，速度显著提升，达到了图像形变领域的新SOTA。", "keywords": "图像形变, 扩散模型, 免调优, 球形插值, 自注意力", "comments": "FreeMorph的创新点在于其“免调优”特性，解决了传统扩散模型在图像形变中需要大量微调的时间成本和语义/布局限制。其引入的引导感知球形插值和面向步骤的变异趋势，巧妙地克服了免调优方法在保持质量方面的固有挑战，实现了高效且高质量的形变，是该领域的一大进步。"}}
{"id": "2507.01955", "title": "How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks", "authors": ["Rahul Ramachandran", "Ali Garjani", "Roman Bachmann", "Andrei Atanov", "Oğuzhan Fatih Kar", "Amir Zamir"], "summary": "Multimodal foundation models, such as GPT-4o, have recently made remarkable\nprogress, but it is not clear where exactly these models stand in terms of\nunderstanding vision. In this paper, we benchmark the performance of popular\nmultimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0\nFlash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer vision\ntasks (semantic segmentation, object detection, image classification, depth and\nsurface normal prediction) using established datasets (e.g., COCO, ImageNet and\nits variants, etc).\n  The main challenges to performing this are: 1) most models are trained to\noutput text and cannot natively express versatile domains, such as segments or\n3D geometry, and 2) many leading models are proprietary and accessible only at\nan API level, i.e., there is no weight access to adapt them. We address these\nchallenges by translating standard vision tasks into equivalent text-promptable\nand API-compatible tasks via prompt chaining to create a standardized\nbenchmarking framework.\n  We observe that 1) the models are not close to the state-of-the-art\nspecialist models at any task. However, 2) they are respectable generalists;\nthis is remarkable as they are presumably trained on primarily image-text-based\ntasks. 3) They perform semantic tasks notably better than geometric ones. 4)\nWhile the prompt-chaining techniques affect performance, better models exhibit\nless sensitivity to prompt variations. 5) GPT-4o performs the best among\nnon-reasoning models, securing the top position in 4 out of 6 tasks, 6)\nreasoning models, e.g. o3, show improvements in geometric tasks, and 7) a\npreliminary analysis of models with native image generation, like the latest\nGPT-4o, shows they exhibit quirks like hallucinations and spatial\nmisalignments.", "comment": "Project page at https://fm-vision-evals.epfl.ch/", "pdf_url": "http://arxiv.org/pdf/2507.01955v1", "categories": ["cs.CV", "cs.AI", "cs.LG"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01955v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "GPT-4o对视觉的理解程度如何？评估多模态基础模型在标准计算机视觉任务上的表现", "tldr": "本文评估了GPT-4o等多模态基础模型在标准计算机视觉任务上的表现。通过将视觉任务转换为文本可提示格式，研究发现这些模型是令人尊敬的通才，但在任何任务上都未达到最先进的专业模型水平。GPT-4o在非推理模型中表现最佳，语义任务优于几何任务。", "motivation": "目前尚不清楚GPT-4o等多模态基础模型在视觉理解方面所处的具体水平。主要挑战在于大多数模型主要输出文本，无法原生表达如分割或3D几何等多样化领域，且许多领先模型仅通过API访问，无法获取权重进行调整。", "method": "研究通过基准测试评估了GPT-4o、o4-mini、Gemini 1.5 Pro、Gemini 2.0 Flash、Claude 3.5 Sonnet、Qwen2-VL、Llama 3.2等流行的多模态基础模型在语义分割、目标检测、图像分类、深度和表面法线预测等标准计算机视觉任务上的性能，使用了COCO、ImageNet等数据集。为克服挑战，研究通过提示链将标准视觉任务转换为等效的文本可提示和API兼容任务，创建了标准化的基准测试框架。", "result": "1) 这些模型在任何任务中都未接近最先进的专业模型。2) 它们是令人尊敬的通才。3) 它们在语义任务上的表现明显优于几何任务。4) 提示链技术会影响性能，但更好的模型对提示变化的敏感度较低。5) GPT-4o在非推理模型中表现最佳，在6项任务中有4项位居榜首。6) 推理模型（如o3）在几何任务中显示出改进。7) 对具有原生图像生成功能的模型（如最新的GPT-4o）的初步分析显示，它们表现出幻觉和空间错位等怪癖。", "conclusion": "多模态基础模型在视觉理解方面是令人尊敬的通才，但尚未达到专业模型的SOTA水平。GPT-4o在非推理模型中表现突出。模型在语义任务上表现优于几何任务，且具有原生图像生成功能的模型仍存在如幻觉等问题。", "translation": "多模态基础模型，例如GPT-4o，最近取得了显著进展，但这些模型在理解视觉方面究竟处于何种水平尚不清楚。在本文中，我们使用既定数据集（例如COCO、ImageNet及其变体等）对流行的多模态基础模型（GPT-4o、o4-mini、Gemini 1.5 Pro和Gemini 2.0 Flash、Claude 3.5 Sonnet、Qwen2-VL、Llama 3.2）在标准计算机视觉任务（语义分割、目标检测、图像分类、深度和表面法线预测）上的性能进行了基准测试。\n执行此操作的主要挑战是：1）大多数模型经过训练以输出文本，无法原生表达多功能领域，例如片段或3D几何；2）许多领先模型是专有的，只能通过API级别访问，即无法访问权重来适应它们。我们通过提示链将标准视觉任务转换为等效的文本可提示和API兼容任务，从而创建一个标准化的基准测试框架。\n我们观察到：1）在任何任务中，这些模型都与最先进的专业模型相去甚远。然而，2）它们是令人尊敬的通才；这很了不起，因为它们可能主要是基于图像-文本任务进行训练的。3）它们在语义任务上的表现明显优于几何任务。4）虽然提示链技术会影响性能，但更好的模型对提示变化的敏感度较低。5）GPT-4o在非推理模型中表现最佳，在6项任务中有4项获得第一名，6）推理模型，例如o3，在几何任务中显示出改进，7）对具有原生图像生成功能的模型（如最新的GPT-4o）的初步分析表明，它们表现出幻觉和空间错位等怪癖。", "summary": "本文评估了GPT-4o等领先多模态基础模型在标准计算机视觉任务上的视觉理解能力。为克服模型输出限制和API访问挑战，研究开发了一种通过提示链将视觉任务转换为文本可提示格式的标准化基准测试框架。结果显示，尽管这些模型未达到最先进的专业水平，但它们是令人尊敬的视觉通才，尤其在语义任务上表现优异，而GPT-4o在非推理模型中居于领先地位。研究也指出了模型在几何任务和图像生成方面存在的局限性，如幻觉和空间错位。", "keywords": "多模态基础模型, 计算机视觉, GPT-4o, 基准测试, 提示链", "comments": "该论文解决了关于新型多模态基础模型视觉理解能力的关键问题。其创新之处在于“提示链”方法，巧妙地规避了API访问限制和仅文本输出的挑战，为基准测试多样化的视觉任务提供了标准化框架。研究结果突出了这些模型的通用性优势，同时也揭示了它们在特定领域（如几何任务、生成怪癖）的不足，为多模态AI的未来研究和发展提供了明确方向。"}}
{"id": "2506.23121", "title": "CRISP-SAM2: SAM2 with Cross-Modal Interaction and Semantic Prompting for Multi-Organ Segmentation", "authors": ["Xinlei Yu", "Chanmiao Wang", "Hui Jin", "Ahmed Elazab", "Gangyong Jia", "Xiang Wan", "Changqing Zou", "Ruiquan Ge"], "summary": "Multi-organ medical segmentation is a crucial component of medical image\nprocessing, essential for doctors to make accurate diagnoses and develop\neffective treatment plans. Despite significant progress in this field, current\nmulti-organ segmentation models often suffer from inaccurate details,\ndependence on geometric prompts and loss of spatial information. Addressing\nthese challenges, we introduce a novel model named CRISP-SAM2 with CRoss-modal\nInteraction and Semantic Prompting based on SAM2. This model represents a\npromising approach to multi-organ medical segmentation guided by textual\ndescriptions of organs. Our method begins by converting visual and textual\ninputs into cross-modal contextualized semantics using a progressive\ncross-attention interaction mechanism. These semantics are then injected into\nthe image encoder to enhance the detailed understanding of visual information.\nTo eliminate reliance on geometric prompts, we use a semantic prompting\nstrategy, replacing the original prompt encoder to sharpen the perception of\nchallenging targets. In addition, a similarity-sorting self-updating strategy\nfor memory and a mask-refining process is applied to further adapt to medical\nimaging and enhance localized details. Comparative experiments conducted on\nseven public datasets indicate that CRISP-SAM2 outperforms existing models.\nExtensive analysis also demonstrates the effectiveness of our method, thereby\nconfirming its superior performance, especially in addressing the limitations\nmentioned earlier. Our code is available at:\nhttps://github.com/YU-deep/CRISP\\_SAM2.git.", "comment": "19 pages, 9 figures, 10 tables", "pdf_url": "http://arxiv.org/pdf/2506.23121v1", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "cate": "eess.IV", "url": "http://arxiv.org/abs/2506.23121v1", "date": "2025-06-29", "updated": "2025-06-29", "AI": {"title_translation": "CRISP-SAM2：基于跨模态交互和语义提示的SAM2多器官分割模型", "tldr": "CRISP-SAM2通过引入跨模态交互和语义提示，解决了现有模型在多器官医学图像分割中细节不准确和依赖几何提示的问题，表现出卓越性能。", "motivation": "现有多器官医学分割模型存在细节不准确、依赖几何提示以及空间信息丢失等问题，本研究旨在解决这些挑战。", "method": "CRISP-SAM2模型通过渐进式跨注意力交互机制将视觉和文本输入转换为跨模态语境化语义，并将其注入图像编码器以增强细节理解。为消除对几何提示的依赖，模型采用语义提示策略替代原始提示编码器。此外，还应用了记忆的相似性排序自更新策略和掩模细化过程，以适应医学图像并增强局部细节。", "result": "在七个公共数据集上的比较实验表明，CRISP-SAM2优于现有模型。广泛分析也证实了该方法的有效性和卓越性能，尤其是在解决上述局限性方面。", "conclusion": "CRISP-SAM2通过跨模态交互和语义提示，有效解决了当前多器官医学分割模型的局限性，在多器官医学图像分割中表现出卓越的性能。", "translation": "多器官医学分割是医学图像处理的关键组成部分，对于医生做出准确诊断和制定有效治疗方案至关重要。尽管该领域取得了显著进展，但当前的多器官分割模型通常存在细节不准确、依赖几何提示和空间信息丢失的问题。为了解决这些挑战，我们引入了一种名为CRISP-SAM2的新模型，该模型基于SAM2，并结合了跨模态交互和语义提示。该模型代表了一种有前景的多器官医学分割方法，由器官的文本描述引导。我们的方法首先通过渐进式跨注意力交互机制将视觉和文本输入转换为跨模态语境化语义。然后将这些语义注入图像编码器，以增强对视觉信息的详细理解。为了消除对几何提示的依赖，我们使用语义提示策略，替代原始提示编码器以提高对具有挑战性目标的感知。此外，还应用了记忆的相似性排序自更新策略和掩模细化过程，以进一步适应医学成像并增强局部细节。在七个公共数据集上进行的比较实验表明，CRISP-SAM2优于现有模型。广泛分析也证实了我们方法的有效性，从而确认了其卓越性能，尤其是在解决前面提到的局限性方面。我们的代码可在以下网址获取：https://github.com/YU-deep/CRISP_SAM2.git。", "summary": "CRISP-SAM2是一个新颖的多器官医学分割模型，通过文本描述引导，解决了现有模型细节不准确、依赖几何提示和空间信息丢失的问题。该模型利用渐进式跨注意力机制将视觉和文本输入转换为跨模态语义，并将其注入图像编码器。它还采用语义提示策略替代几何提示，并结合了记忆自更新和掩模细化过程。在七个公共数据集上的实验证明，CRISP-SAM2在性能上超越了现有模型，特别是在处理上述局限性方面表现出色。", "keywords": "多器官分割, 跨模态交互, 语义提示, SAM2, 医学图像处理", "comments": "该论文的创新点在于引入了跨模态交互和语义提示，并结合了专门针对医学图像的策略（如记忆自更新和掩模细化），有效解决了现有SAM类模型在医学多器官分割中细节不准确和依赖几何提示的局限性。其方法论的综合性使其在医学图像处理领域具有重要意义。"}}
{"id": "2507.01957", "title": "Locality-aware Parallel Decoding for Efficient Autoregressive Image Generation", "authors": ["Zhuoyang Zhang", "Luke J. Huang", "Chengyue Wu", "Shang Yang", "Kelly Peng", "Yao Lu", "Song Han"], "summary": "We present Locality-aware Parallel Decoding (LPD) to accelerate\nautoregressive image generation. Traditional autoregressive image generation\nrelies on next-patch prediction, a memory-bound process that leads to high\nlatency. Existing works have tried to parallelize next-patch prediction by\nshifting to multi-patch prediction to accelerate the process, but only achieved\nlimited parallelization. To achieve high parallelization while maintaining\ngeneration quality, we introduce two key techniques: (1) Flexible Parallelized\nAutoregressive Modeling, a novel architecture that enables arbitrary generation\nordering and degrees of parallelization. It uses learnable position query\ntokens to guide generation at target positions while ensuring mutual visibility\namong concurrently generated tokens for consistent parallel decoding. (2)\nLocality-aware Generation Ordering, a novel schedule that forms groups to\nminimize intra-group dependencies and maximize contextual support, enhancing\ngeneration quality. With these designs, we reduce the generation steps from 256\nto 20 (256$\\times$256 res.) and 1024 to 48 (512$\\times$512 res.) without\ncompromising quality on the ImageNet class-conditional generation, and\nachieving at least 3.4$\\times$ lower latency than previous parallelized\nautoregressive models.", "comment": "The first two authors contributed equally to this work", "pdf_url": "http://arxiv.org/pdf/2507.01957v1", "categories": ["cs.CV", "cs.AI"], "cate": "cs.CV", "url": "http://arxiv.org/abs/2507.01957v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "局部感知并行解码用于高效自回归图像生成", "tldr": "本文提出了局部感知并行解码（LPD），通过引入灵活并行自回归建模和局部感知生成排序，显著加速了自回归图像生成过程，同时保持了生成质量。", "motivation": "传统的自回归图像生成依赖于下一块预测，这是一个内存密集型过程，导致高延迟。现有工作尝试并行化但只实现了有限的并行度。", "method": "本文提出了局部感知并行解码（LPD）来加速自回归图像生成。LPD引入了两个关键技术：1. 灵活并行自回归建模，一种新颖的架构，支持任意生成顺序和并行度，并使用可学习的位置查询令牌引导生成，确保并发令牌间的相互可见性。2. 局部感知生成排序，一种新颖的调度方法，通过形成组来最小化组内依赖并最大化上下文支持，从而提高生成质量。", "result": "在ImageNet类条件生成上，256x256分辨率图像的生成步骤从256减少到20，512x512分辨率图像从1024减少到48，且不影响质量。与之前的并行自回归模型相比，延迟至少降低了3.4倍。", "conclusion": "局部感知并行解码（LPD）显著提高了自回归图像生成的效率，同时保持了生成质量。", "translation": "我们提出了局部感知并行解码（LPD）来加速自回归图像生成。传统的自回归图像生成依赖于下一块预测，这是一个内存密集型过程，导致高延迟。现有工作试图通过转向多块预测来并行化下一块预测以加速该过程，但只实现了有限的并行化。为了在保持生成质量的同时实现高并行化，我们引入了两个关键技术：（1）灵活并行自回归建模，这是一种新颖的架构，能够实现任意生成顺序和并行度。它使用可学习的位置查询令牌来引导目标位置的生成，同时确保并发生成的令牌之间相互可见，以实现一致的并行解码。（2）局部感知生成排序，这是一种新颖的调度方法，通过形成组来最小化组内依赖性并最大化上下文支持，从而提高生成质量。凭借这些设计，我们在ImageNet类条件生成上，将256x256分辨率图像的生成步骤从256减少到20，将512x512分辨率图像从1024减少到48，且不影响质量，并且比以前的并行自回归模型实现了至少3.4倍的更低延迟。", "summary": "本文提出了局部感知并行解码（LPD），旨在加速自回归图像生成。针对传统方法高延迟和现有并行化方法并行度有限的问题，LPD引入了灵活并行自回归建模和局部感知生成排序两大技术。前者通过新颖架构实现任意并行度并保证生成一致性；后者通过优化生成顺序提升质量。实验表明，LPD在ImageNet数据集上显著减少了生成步骤，并实现了至少3.4倍的延迟降低，同时保持了图像生成质量。", "keywords": "自回归图像生成, 并行解码, 局部感知, 高效生成, 深度学习", "comments": "这项工作在加速自回归图像生成方面取得了显著进展，特别是在保持质量的同时大幅减少生成步数和降低延迟。其创新点在于引入了灵活并行建模和局部感知排序，有效解决了现有并行化方法的局限性，对图像生成效率的提升具有重要意义。"}}
{"id": "2507.01044", "title": "Asymptotic convexity of wide and shallow neural networks", "authors": ["Vivek Borkar", "Parthe Pandit"], "summary": "For a simple model of shallow and wide neural networks, we show that the\nepigraph of its input-output map as a function of the network parameters\napproximates epigraph of a. convex function in a precise sense. This leads to a\nplausible explanation of their observed good performance.", "comment": "5 pages", "pdf_url": "http://arxiv.org/pdf/2507.01044v1", "categories": ["stat.ML", "cs.LG", "math.PR", "68T07"], "cate": "stat.ML", "url": "http://arxiv.org/abs/2507.01044v1", "date": "2025-06-23", "updated": "2025-06-23", "AI": {"title_translation": "宽而浅神经网络的渐近凸性", "tldr": "宽而浅神经网络的输入-输出映射参数表现出渐近凸性，这有助于解释其良好的性能。", "motivation": "为宽而浅神经网络观察到的良好性能提供一个合理的解释。", "method": "通过证明，对于一个简单的浅层宽神经网络模型，其输入-输出映射的上位图作为网络参数的函数，以精确的方式近似于一个凸函数的上位图。", "result": "宽而浅神经网络的输入-输出映射的上位图（作为网络参数的函数）精确地近似于一个凸函数的上位图。", "conclusion": "宽而浅神经网络中观察到的渐近凸性为其良好性能提供了合理的解释。", "translation": "对于一个简单的浅层宽神经网络模型，我们表明其输入-输出映射的上位图作为网络参数的函数，以精确的方式近似于一个凸函数的上位图。这为它们观察到的良好性能提供了一个合理的解释。", "summary": "本文证明，对于一个简化的宽而浅神经网络模型，其输入-输出映射的上位图（作为网络参数的函数）精确地近似于一个凸函数的上位图。这一发现为经验观察到的这类网络的强大性能提供了一个合理的解释。", "keywords": "神经网络, 渐近凸性, 宽网络, 浅网络, 性能解释", "comments": "本文通过将宽而浅神经网络的性能与渐近凸性概念联系起来，为它们的成功提供了理论见解。这一理论基础非常重要，因为它为理解经验观察提供了数学依据，从而可以指导未来的网络设计和优化策略。"}}
{"id": "2507.01260", "title": "Automated Classification of Volcanic Earthquakes Using Transformer Encoders: Insights into Data Quality and Model Interpretability", "authors": ["Y. Suzuki", "Y. Yukutake", "T. Ohminato", "M. Yamasaki", "Ahyi Kim"], "summary": "Precisely classifying earthquake types is crucial for elucidating the\nrelationship between volcanic earthquakes and volcanic activity. However,\ntraditional methods rely on subjective human judgment, which requires\nconsiderable time and effort. To address this issue, we developed a deep\nlearning model using a transformer encoder for a more objective and efficient\nclassification. Tested on Mount Asama's diverse seismic activity, our model\nachieved high F1 scores (0.930 for volcano tectonic, 0.931 for low-frequency\nearthquakes, and 0.980 for noise), superior to a conventional CNN-based method.\nTo enhance interpretability, attention weight visualizations were analyzed,\nrevealing that the model focuses on key waveform features similarly to human\nexperts. However, inconsistencies in training data, such as ambiguously labeled\nB-type events with S-waves, were found to influence classification accuracy and\nattention weight distributions. Experiments addressing data selection and\naugmentation demonstrated the importance of balancing data quality and\ndiversity. In addition, stations within 3 km of the crater played an important\nrole in improving model performance and interpretability. These findings\nhighlight the potential of Transformer-based models for automated volcanic\nearthquake classification, particularly in improving efficiency and\ninterpretability. By addressing challenges such as data imbalance and\nsubjective labeling, our approach provides a robust framework for understanding\nseismic activity at Mount Asama. Moreover, this framework offers opportunities\nfor transfer learning to other volcanic regions, paving the way for enhanced\nvolcanic hazard assessments and disaster mitigation strategies.", "comment": "submitted to Seismological Research Letters", "pdf_url": "http://arxiv.org/pdf/2507.01260v1", "categories": ["physics.geo-ph", "cs.LG"], "cate": "physics.geo-ph", "url": "http://arxiv.org/abs/2507.01260v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "使用Transformer编码器自动分类火山地震：数据质量和模型可解释性洞察", "tldr": "本研究开发了一个基于Transformer编码器的深度学习模型，用于自动分类火山地震，取得了高精度和可解释性，并揭示了数据质量和台站位置对模型性能的关键影响。", "motivation": "精确分类地震类型对于理解火山地震与火山活动的关系至关重要，但传统方法依赖主观判断，耗时且效率低下。", "method": "开发了一个基于Transformer编码器的深度学习模型进行火山地震自动分类。通过分析注意力权重可视化来增强模型可解释性。通过实验研究数据选择和增强策略，以解决数据质量和多样性问题。", "result": "模型在浅间山数据集上取得了高F1分数（火山构造0.930，低频地震0.931，噪声0.980），优于传统CNN方法。注意力权重可视化显示模型关注关键波形特征，与人类专家相似。研究发现训练数据中不一致的标注（如含S波的B型事件）会影响分类准确性和注意力权重分布。靠近火山口3公里内的台站对提高模型性能和可解释性至关重要。", "conclusion": "基于Transformer的模型在火山地震自动分类方面具有巨大潜力，尤其在提高效率和可解释性方面。通过解决数据不平衡和主观标注等挑战，该方法为理解浅间山的地震活动提供了稳健框架，并有望通过迁移学习应用于其他火山区域，从而加强火山灾害评估和减灾策略。", "translation": "精确分类地震类型对于阐明火山地震与火山活动之间的关系至关重要。然而，传统方法依赖主观的人工判断，这需要大量时间和精力。为了解决这个问题，我们开发了一个使用Transformer编码器的深度学习模型，以实现更客观和高效的分类。在浅间山多样化的地震活动数据上进行测试，我们的模型取得了高F1分数（火山构造0.930，低频地震0.931，噪声0.980），优于传统的基于CNN的方法。为了增强可解释性，我们分析了注意力权重可视化，揭示了模型关注关键波形特征的方式与人类专家相似。然而，发现训练数据中的不一致性，例如模糊标记的含S波的B型事件，会影响分类准确性和注意力权重分布。针对数据选择和增强的实验证明了平衡数据质量和多样性的重要性。此外，火山口3公里内的台站在改善模型性能和可解释性方面发挥了重要作用。这些发现突出了基于Transformer的模型在自动火山地震分类方面的潜力，特别是在提高效率和可解释性方面。通过解决数据不平衡和主观标注等挑战，我们的方法为理解浅间山的地震活动提供了一个稳健的框架。此外，该框架为向其他火山区域进行迁移学习提供了机会，为加强火山灾害评估和减灾策略铺平了道路。", "summary": "本研究提出了一种基于Transformer编码器的深度学习模型，用于自动分类火山地震，旨在克服传统方法的主观性和低效率。该模型在浅间山数据集上表现出卓越的性能，F1分数显著高于传统CNN方法。通过分析注意力权重，模型的可解释性得到提升，显示其关注点与人类专家一致。研究还揭示了训练数据质量（如标注不一致性）对分类准确性的影响，并强调了数据平衡性及靠近火山口台站的重要性。该框架不仅为浅间山的地震活动分析提供了高效且可解释的方法，还为火山灾害评估和减灾提供了潜在的迁移学习机会。", "keywords": "火山地震分类, Transformer编码器, 深度学习, 数据质量, 模型可解释性", "comments": "该论文的创新之处在于首次将Transformer编码器应用于火山地震的自动分类，并深入探讨了模型的可解释性。通过注意力权重可视化，模型决策过程变得透明，这对于地球科学领域至关重要。论文还强调了数据质量和台站位置对模型性能的显著影响，为未来地震监测系统的数据收集和预处理提供了宝贵的指导。该框架的迁移学习潜力也极大地拓展了其应用范围，有望在全球火山灾害评估中发挥作用。"}}
{"id": "2507.01466", "title": "Symbolic identification of tensor equations in multidimensional physical fields", "authors": ["Tianyi Chen", "Hao Yang", "Wenjun Ma", "Jun Zhang"], "summary": "Recently, data-driven methods have shown great promise for discovering\ngoverning equations from simulation or experimental data. However, most\nexisting approaches are limited to scalar equations, with few capable of\nidentifying tensor relationships. In this work, we propose a general\ndata-driven framework for identifying tensor equations, referred to as Symbolic\nIdentification of Tensor Equations (SITE). The core idea of SITE--representing\ntensor equations using a host-plasmid structure--is inspired by the\nmultidimensional gene expression programming (M-GEP) approach. To improve the\nrobustness of the evolutionary process, SITE adopts a genetic information\nretention strategy. Moreover, SITE introduces two key innovations beyond\nconventional evolutionary algorithms. First, it incorporates a dimensional\nhomogeneity check to restrict the search space and eliminate physically invalid\nexpressions. Second, it replaces traditional linear scaling with a tensor\nlinear regression technique, greatly enhancing the efficiency of numerical\ncoefficient optimization. We validate SITE using two benchmark scenarios, where\nit accurately recovers target equations from synthetic data, showing robustness\nto noise and small sample sizes. Furthermore, SITE is applied to identify\nconstitutive relations directly from molecular simulation data, which are\ngenerated without reliance on macroscopic constitutive models. It adapts to\nboth compressible and incompressible flow conditions and successfully\nidentifies the corresponding macroscopic forms, highlighting its potential for\ndata-driven discovery of tensor equation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01466v1", "categories": ["math-ph", "cs.LG", "math.MP"], "cate": "math-ph", "url": "http://arxiv.org/abs/2507.01466v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "多维物理场中张量方程的符号识别", "tldr": "本文提出了SITE，一个用于识别张量方程的数据驱动框架，灵感来源于M-GEP，并引入了维度同质性检查和张量线性回归等创新，在基准测试和分子模拟数据上进行了验证。", "motivation": "现有的数据驱动方法在发现控制方程方面大多局限于标量方程，很少有能够识别张量关系的。", "method": "本文提出了一种通用的数据驱动框架，称为张量方程的符号识别（SITE）。SITE的核心思想是使用宿主-质粒结构来表示张量方程，其灵感来源于多维基因表达编程（M-GEP）方法。为了提高演化过程的鲁棒性，SITE采用了遗传信息保留策略。此外，SITE引入了两项超越传统演化算法的关键创新：一是结合了维度同质性检查来限制搜索空间并消除物理上无效的表达式；二是将传统的线性标度替换为张量线性回归技术，大大提高了数值系数优化的效率。", "result": "SITE在两个基准场景中，从合成数据中准确恢复了目标方程，显示出对噪声和小样本量的鲁棒性。此外，SITE被应用于直接从分子模拟数据中识别本构关系，这些数据是在不依赖宏观本构模型的情况下生成的。它适应可压缩和不可压缩流条件，并成功识别出相应的宏观形式。", "conclusion": "SITE凸显了其在数据驱动的张量方程发现方面的潜力。", "translation": "最近，数据驱动方法在从模拟或实验数据中发现控制方程方面显示出巨大的前景。然而，现有的大多数方法仅限于标量方程，很少有能够识别张量关系的。在这项工作中，我们提出了一种通用的数据驱动框架，用于识别张量方程，称为张量方程的符号识别（SITE）。SITE的核心思想——使用宿主-质粒结构来表示张量方程——灵感来源于多维基因表达编程（M-GEP）方法。为了提高演化过程的鲁棒性，SITE采用了遗传信息保留策略。此外，SITE引入了两项超越传统演化算法的关键创新。首先，它结合了维度同质性检查来限制搜索空间并消除物理上无效的表达式。其次，它将传统的线性标度替换为张量线性回归技术，大大提高了数值系数优化的效率。我们使用两个基准场景验证了SITE，它从合成数据中准确恢复了目标方程，显示出对噪声和小样本量的鲁棒性。此外，SITE被应用于直接从分子模拟数据中识别本构关系，这些数据是在不依赖宏观本构模型的情况下生成的。它适应可压缩和不可压缩流条件，并成功识别出相应的宏观形式，凸显了其在数据驱动的张量方程发现方面的潜力。", "summary": "SITE是一种新颖的数据驱动框架，用于符号识别张量方程，解决了现有方法主要处理标量方程的局限性。它受M-GEP启发，采用宿主-质粒结构，并结合了维度同质性检查和张量线性回归等创新，以提高效率和物理有效性。SITE在合成数据和分子模拟中得到了验证，展示了其鲁棒性以及发现宏观张量方程的能力，突显了其在数据驱动科学发现中的潜力。", "keywords": "符号识别, 张量方程, 数据驱动发现, 基因编程, 维度分析", "comments": "该论文的创新之处在于将数据驱动的方程发现扩展到张量方程，这是超越标量方程的一个重要进步。物理约束（维度同质性）和专用优化（张量线性回归）的整合增强了其鲁棒性和适用性。其无需预设宏观模型即可直接处理分子模拟数据的能力尤其值得关注。"}}
{"id": "2507.01501", "title": "Meteoroid stream identification with HDBSCAN unsupervised clustering algorithm", "authors": ["Eloy Peña-Asensio", "Fabio Ferrari"], "summary": "Accurate identification of meteoroid streams is central to understanding\ntheir origins and evolution. However, overlapping clusters and background noise\nhinder classification, an issue amplified for missions such as ESA's LUMIO that\nrely on meteor shower observations to infer lunar meteoroid impact parameters.\nThis study evaluates the performance of the Hierarchical Density-Based Spatial\nClustering of Applications with Noise (HDBSCAN) algorithm for unsupervised\nmeteoroid stream identification, comparing its outcomes with the established\nCameras for All-Sky Meteor Surveillance (CAMS) look-up table method. We analyze\nthe CAMS Meteoroid Orbit Database v3.0 using three feature vectors: LUTAB (CAMS\ngeocentric parameters), ORBIT (heliocentric orbital elements), and GEO (adapted\ngeocentric parameters). HDBSCAN is applied with varying minimum cluster sizes\nand two cluster selection methods (eom and leaf). To align HDBSCAN clusters\nwith CAMS classifications, the Hungarian algorithm determines the optimal\nmapping. Clustering performance is assessed via the Silhouette score,\nNormalized Mutual Information, and F1 score, with Principal Component Analysis\nfurther supporting the analysis. With the GEO vector, HDBSCAN confirms 39\nmeteoroid streams, 21 strongly aligning with CAMS. The ORBIT vector identifies\n30 streams, 13 with high matching scores. Less active showers pose\nidentification challenges. The eom method consistently yields superior\nperformance and agreement with CAMS. Although HDBSCAN requires careful\nselection of the minimum cluster size, it delivers robust, internally\nconsistent clusters and outperforms the look-up table method in statistical\ncoherence. These results underscore HDBSCAN's potential as a mathematically\nconsistent alternative for meteoroid stream identification, although further\nvalidation is needed to assess physical validity.", "comment": "Accepted in The Astronomical Journal", "pdf_url": "http://arxiv.org/pdf/2507.01501v1", "categories": ["astro-ph.EP", "astro-ph.IM", "cs.LG"], "cate": "astro-ph.EP", "url": "http://arxiv.org/abs/2507.01501v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "流星体流识别与HDBSCAN无监督聚类算法", "tldr": "本研究评估了HDBSCAN无监督聚类算法在流星体流识别中的性能，并与CAMS方法进行比较，发现HDBSCAN是一种有潜力的数学上一致的替代方案。", "motivation": "准确识别流星体流对于理解其起源和演化至关重要。然而，重叠的聚类和背景噪声阻碍了分类，这对于依赖流星雨观测来推断月球流星体撞击参数的任务（如ESA的LUMIO）来说，问题更为突出。", "method": "本研究评估了HDBSCAN算法用于无监督流星体流识别的性能，并将其结果与已建立的CAMS查表法进行比较。分析了CAMS流星体轨道数据库v3.0，使用了三种特征向量：LUTAB、ORBIT和GEO。HDBSCAN应用了不同的最小聚类大小和两种聚类选择方法（eom和leaf）。使用匈牙利算法将HDBSCAN聚类与CAMS分类对齐。通过Silhouette分数、归一化互信息和F1分数评估聚类性能，并辅以主成分分析。", "result": "使用GEO向量时，HDBSCAN确认了39个流星体流，其中21个与CAMS高度一致。ORBIT向量识别出30个流星，13个具有高匹配分数。不活跃的流星雨识别存在挑战。eom方法始终表现出卓越的性能和与CAMS的一致性。", "conclusion": "尽管HDBSCAN需要仔细选择最小聚类大小，但它能提供稳健、内部一致的聚类，并在统计一致性方面优于查表法。这些结果强调了HDBSCAN作为流星体流识别的数学上一致的替代方案的潜力，尽管还需要进一步验证以评估物理有效性。", "translation": "流星体流的准确识别对于理解它们的起源和演化至关重要。然而，重叠的聚类和背景噪声阻碍了分类，对于依赖流星雨观测来推断月球流星体撞击参数的任务（如ESA的LUMIO）来说，这个问题更加突出。本研究评估了分层密度基于噪声应用空间聚类（HDBSCAN）算法在无监督流星体流识别中的性能，并将其结果与已建立的全天流星监测相机（CAMS）查表法进行比较。我们使用三个特征向量分析了CAMS流星体轨道数据库v3.0：LUTAB（CAMS地心参数）、ORBIT（日心轨道元素）和GEO（适应的地心参数）。HDBSCAN应用了不同的最小聚类大小和两种聚类选择方法（eom和leaf）。为了使HDBSCAN聚类与CAMS分类对齐，匈牙利算法确定了最佳映射。聚类性能通过Silhouette分数、归一化互信息和F1分数进行评估，主成分分析进一步支持了分析。使用GEO向量时，HDBSCAN确认了39个流星体流，其中21个与CAMS高度一致。ORBIT向量识别出30个流星，其中13个具有高匹配分数。不活跃的流星雨识别存在挑战。eom方法始终表现出卓越的性能和与CAMS的一致性。尽管HDBSCAN需要仔细选择最小聚类大小，但它能提供稳健、内部一致的聚类，并在统计一致性方面优于查表法。这些结果强调了HDBSCAN作为流星体流识别的数学上一致的替代方案的潜力，尽管还需要进一步验证以评估物理有效性。", "summary": "本研究评估了HDBSCAN无监督聚类算法在流星体流识别中的应用，并将其与CAMS查表法进行了比较。研究利用CAMS流星体轨道数据库v3.0，测试了三种特征向量和两种HDBSCAN聚类选择方法。结果表明，HDBSCAN能够识别出大量流星体流，特别是在使用GEO向量和eom方法时，与CAMS分类具有良好的一致性。尽管需要仔细参数选择，HDBSCAN在统计一致性方面优于传统查表法，显示出作为流星体流识别数学上一致替代方案的潜力。", "keywords": "流星体流识别, HDBSCAN, 无监督聚类, CAMS, 轨道数据库", "comments": "本文创新性地将HDBSCAN无监督聚类算法应用于流星体流识别，解决了传统方法在处理重叠聚类和背景噪声方面的挑战。其重要性在于为流星体流的准确识别提供了一种数学上更一致、统计性能更优越的替代方案，这对于未来的空间任务（如LUMIO）具有实际意义。尽管其物理有效性尚待进一步验证，但该研究为天文学数据分析提供了新的视角和工具。"}}
{"id": "2507.01542", "title": "Parsimonious Gaussian mixture models with piecewise-constant eigenvalue profiles", "authors": ["Tom Szwagier", "Pierre-Alexandre Mattei", "Charles Bouveyron", "Xavier Pennec"], "summary": "Gaussian mixture models (GMMs) are ubiquitous in statistical learning,\nparticularly for unsupervised problems. While full GMMs suffer from the\noverparameterization of their covariance matrices in high-dimensional spaces,\nspherical GMMs (with isotropic covariance matrices) certainly lack flexibility\nto fit certain anisotropic distributions. Connecting these two extremes, we\nintroduce a new family of parsimonious GMMs with piecewise-constant covariance\neigenvalue profiles. These extend several low-rank models like the celebrated\nmixtures of probabilistic principal component analyzers (MPPCA), by enabling\nany possible sequence of eigenvalue multiplicities. If the latter are\nprespecified, then we can naturally derive an expectation-maximization (EM)\nalgorithm to learn the mixture parameters. Otherwise, to address the\nnotoriously-challenging issue of jointly learning the mixture parameters and\nhyperparameters, we propose a componentwise penalized EM algorithm, whose\nmonotonicity is proven. We show the superior likelihood-parsimony tradeoffs\nachieved by our models on a variety of unsupervised experiments: density\nfitting, clustering and single-image denoising.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01542v1", "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.CO", "stat.ME"], "cate": "stat.ML", "url": "http://arxiv.org/abs/2507.01542v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "具有分段常数特征值剖面的简约高斯混合模型", "tldr": "本文引入了一种新的简约高斯混合模型家族，其协方差特征值剖面是分段常数，旨在解决现有GMM在灵活性和参数化方面的不足，并通过EM算法进行参数学习。", "motivation": "传统高斯混合模型（GMMs）在高维空间中存在协方差矩阵过参数化的问题，而球形GMMs又缺乏灵活性来拟合各向异性分布。现有模型如概率主成分分析混合模型（MPPCA）仍有局限性。", "method": "本文引入了一种新的简约高斯混合模型家族，其协方差特征值剖面是分段常数。该模型扩展了低秩模型，允许任意的特征值重数序列。如果特征值重数预先指定，则可自然推导出期望最大化（EM）算法来学习混合参数。否则，提出了一种分量惩罚EM算法来联合学习混合参数和超参数，并证明了其单调性。", "result": "在多种无监督实验（密度拟合、聚类和单图像去噪）中，本文模型实现了优越的似然-简约性权衡。", "conclusion": "本文提出的具有分段常数特征值剖面的简约高斯混合模型，有效解决了传统GMM的过参数化和灵活性不足问题，并在多个无监督任务中展现出优越的性能。", "translation": "高斯混合模型（GMMs）在统计学习中无处不在，尤其适用于无监督问题。尽管全GMM在高维空间中存在协方差矩阵过参数化的问题，但球形GMM（具有各向同性协方差矩阵）无疑缺乏拟合某些各向异性分布的灵活性。为了连接这两个极端，我们引入了一种新的简约GMM家族，其协方差特征值剖面是分段常数。这些模型扩展了几种低秩模型，如著名的概率主成分分析混合模型（MPPCA），通过允许任意可能的特征值重数序列。如果后者是预先指定的，那么我们就可以自然地推导出期望最大化（EM）算法来学习混合参数。否则，为了解决联合学习混合参数和超参数这一众所周知的挑战性问题，我们提出了一种分量惩罚EM算法，并证明了其单调性。我们展示了我们的模型在各种无监督实验（密度拟合、聚类和单图像去噪）中实现了优越的似然-简约性权衡。", "summary": "本文提出了一种新的简约高斯混合模型（GMM）家族，其协方差特征值剖面是分段常数。该模型旨在弥补全GMM过参数化和球形GMM灵活性不足的缺点。它通过允许任意特征值重数序列扩展了现有的低秩模型。针对参数学习，论文提出了两种EM算法：一种用于特征值重数预先指定的情况，另一种是分量惩罚EM算法用于联合学习混合参数和超参数。实验结果表明，新模型在密度拟合、聚类和图像去噪等无监督任务中，在似然和简约性之间取得了更好的平衡。", "keywords": "高斯混合模型, 简约模型, 特征值剖面, EM算法, 无监督学习", "comments": "本文的创新点在于引入了具有分段常数特征值剖面的简约高斯混合模型，有效解决了传统GMM在高维空间中的过参数化问题和球形GMM的灵活性不足。通过扩展低秩模型并提出两种EM算法，特别是在超参数未知时引入惩罚EM算法，提高了模型的实用性。其在多个无监督任务中表现出的优越的似然-简约性权衡，表明了该模型在实际应用中的重要性。"}}
{"id": "2507.01918", "title": "End-to-End Large Portfolio Optimization for Variance Minimization with Neural Networks through Covariance Cleaning", "authors": ["Christian Bongiorno", "Efstratios Manolakis", "Rosario Nunzio Mantegna"], "summary": "We develop a rotation-invariant neural network that provides the global\nminimum-variance portfolio by jointly learning how to lag-transform historical\nreturns and how to regularise both the eigenvalues and the marginal\nvolatilities of large equity covariance matrices. This explicit mathematical\nmapping offers clear interpretability of each module's role, so the model\ncannot be regarded as a pure black-box. The architecture mirrors the analytical\nform of the global minimum-variance solution yet remains agnostic to dimension,\nso a single model can be calibrated on panels of a few hundred stocks and\napplied, without retraining, to one thousand US equities-a cross-sectional jump\nthat demonstrates robust out-of-sample generalisation. The loss function is the\nfuture realized minimum portfolio variance and is optimized end-to-end on real\ndaily returns. In out-of-sample tests from January 2000 to December 2024 the\nestimator delivers systematically lower realised volatility, smaller maximum\ndrawdowns, and higher Sharpe ratios than the best analytical competitors,\nincluding state-of-the-art non-linear shrinkage. Furthermore, although the\nmodel is trained end-to-end to produce an unconstrained (long-short)\nminimum-variance portfolio, we show that its learned covariance representation\ncan be used in general optimizers under long-only constraints with virtually no\nloss in its performance advantage over competing estimators. These gains\npersist when the strategy is executed under a highly realistic implementation\nframework that models market orders at the auctions, empirical slippage,\nexchange fees, and financing charges for leverage, and they remain stable\nduring episodes of acute market stress.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01918v1", "categories": ["q-fin.PM", "cs.AI", "math.OC", "physics.data-an", "stat.ML", "91G10 (Primary) 68T07, 91G60, 62P05 (Secondary)", "I.2.6; I.5.1; G.3; J.4"], "cate": "q-fin.PM", "url": "http://arxiv.org/abs/2507.01918v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于协方差清洗的神经网络端到端大规模投资组合方差最小化优化", "tldr": "本文开发了一种旋转不变的神经网络，通过联合学习历史回报的时滞变换和大规模股票协方差矩阵的特征值及边际波动率的正则化，实现了全局最小方差投资组合的端到端优化，并在实际数据上表现出优于现有分析方法的性能和鲁棒性。", "motivation": "传统的大规模投资组合方差最小化面临挑战，特别是对于协方差矩阵的处理。本文旨在开发一种新的方法，能够提供全局最小方差投资组合，并克服现有方法的局限性，实现更好的性能和泛化能力。", "method": "本文开发了一种旋转不变的神经网络，通过联合学习历史回报的时滞变换以及大规模股票协方差矩阵的特征值和边际波动率的正则化，来提供全局最小方差投资组合。模型架构反映了全局最小方差解决方案的分析形式，且对维度不敏感。损失函数是未来实现的最小投资组合方差，并在实际日常回报数据上进行端到端优化。", "result": "在2000年1月至2024年12月的样本外测试中，该估计器系统性地实现了比最佳分析竞争对手（包括最先进的非线性收缩方法）更低的已实现波动率、更小的最大回撤和更高的夏普比率。模型展示了强大的样本外泛化能力，即使在长期持仓约束下，其学习到的协方差表示也能在通用优化器中使用，且性能优势几乎没有损失。在高度真实的实施框架下，这些收益依然存在，并在市场剧烈波动期间保持稳定。", "conclusion": "本文提出的基于神经网络的端到端大规模投资组合方差最小化方法，通过创新的协方差清洗机制，在性能、鲁棒性和泛化能力方面均显著优于现有分析方法，为实际投资组合管理提供了强大的工具。", "translation": "我们开发了一种旋转不变的神经网络，通过联合学习如何对历史回报进行滞后变换以及如何对大规模股票协方差矩阵的特征值和边际波动率进行正则化，从而提供全局最小方差投资组合。这种明确的数学映射提供了每个模块作用的清晰可解释性，因此该模型不能被视为纯粹的黑箱。该架构反映了全局最小方差解决方案的分析形式，但对维度保持无关性，因此单个模型可以在数百只股票的面板上进行校准，并无需重新训练即可应用于一千只美国股票——这种跨截面的跳跃证明了强大的样本外泛化能力。损失函数是未来实现的最小投资组合方差，并在实际每日回报数据上进行端到端优化。在2000年1月至2024年12月的样本外测试中，该估计器系统性地提供了比最佳分析竞争对手（包括最先进的非线性收缩方法）更低的实现波动率、更小的最大回撤和更高的夏普比率。此外，尽管该模型是端到端训练以产生无约束（多空）最小方差投资组合，但我们表明其学习到的协方差表示可以在长期持仓约束下的通用优化器中使用，其相对于竞争估计器的性能优势几乎没有损失。当策略在高度真实的实施框架下执行时，这些收益依然存在，该框架模拟了拍卖时的市价订单、经验滑点、交易费用和杠杆融资费用，并且在市场剧烈承压期间保持稳定。", "summary": "本文提出了一种基于旋转不变神经网络的端到端大规模投资组合方差最小化方法。该网络通过联合学习历史回报的时滞变换和协方差矩阵的特征值及边际波动率正则化，以实现全局最小方差。模型具有清晰的可解释性，并对维度不敏感，展现出强大的样本外泛化能力。在实际数据上的测试表明，该方法在实现波动率、最大回撤和夏普比率方面均优于现有分析方法，且其学习到的协方差表示在有约束的优化器中也能保持性能优势，并在实际交易环境中表现出鲁棒性。", "keywords": "投资组合优化, 最小方差, 神经网络, 协方差清洗, 风险管理", "comments": "该论文的创新之处在于将神经网络应用于大规模投资组合的方差最小化问题，特别是通过端到端的方式进行协方差矩阵的“清洗”和正则化。其关键优势在于提供了一个可解释的非黑箱模型，并且在维度无关性和样本外泛化能力方面表现出色。与传统分析方法相比，该模型在降低波动率和提高夏普比率方面展现出显著优势，且在考虑实际交易成本和市场压力时仍能保持稳定性能，这对于实际资产管理具有重要意义。"}}
{"id": "2507.01939", "title": "SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars", "authors": ["Xiaosheng Zhao", "Yang Huang", "Guirong Xue", "Xiao Kong", "Jifeng Liu", "Xiaoyu Tang", "Timothy C. Beers", "Yuan-Sen Ting", "A-Li Luo"], "summary": "In recent years, large language models (LLMs) have transformed natural\nlanguage understanding through vast datasets and large-scale parameterization.\nInspired by this success, we present SpecCLIP, a foundation model framework\nthat extends LLM-inspired methodologies to stellar spectral analysis. Stellar\nspectra, akin to structured language, encode rich physical and chemical\ninformation about stars. By training foundation models on large-scale spectral\ndatasets, our goal is to learn robust and informative embeddings that support\ndiverse downstream applications. As a proof of concept, SpecCLIP involves\npre-training on two spectral types--LAMOST low-resolution and Gaia XP--followed\nby contrastive alignment using the CLIP (Contrastive Language-Image\nPre-training) framework, adapted to associate spectra from different\ninstruments. This alignment is complemented by auxiliary decoders that preserve\nspectrum-specific information and enable translation (prediction) between\nspectral types, with the former achieved by maximizing mutual information\nbetween embeddings and input spectra. The result is a cross-spectrum framework\nenabling intrinsic calibration and flexible applications across instruments. We\ndemonstrate that fine-tuning these models on moderate-sized labeled datasets\nimproves adaptability to tasks such as stellar-parameter estimation and\nchemical-abundance determination. SpecCLIP also enhances the accuracy and\nprecision of parameter estimates benchmarked against external survey data.\nAdditionally, its similarity search and cross-spectrum prediction capabilities\noffer potential for anomaly detection. Our results suggest that contrastively\ntrained foundation models enriched with spectrum-aware decoders can advance\nprecision stellar spectroscopy.", "comment": "26 pages, 6 figures, 5 tables. To be submitted to AAS Journals.\n  Comments welcome", "pdf_url": "http://arxiv.org/pdf/2507.01939v1", "categories": ["astro-ph.IM", "astro-ph.SR", "cs.AI", "cs.LG"], "cate": "astro-ph.IM", "url": "http://arxiv.org/abs/2507.01939v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "SpecCLIP：对恒星光谱测量进行对齐和转换", "tldr": "SpecCLIP是一个受LLM启发的恒星光谱基础模型框架，它使用对比学习对齐不同仪器的光谱，并能进行光谱类型转换，提高恒星参数估计和化学丰度测定的准确性。", "motivation": "受大型语言模型（LLM）在自然语言理解领域成功的启发，研究者旨在将LLM-inspired的方法应用于恒星光谱分析，以学习鲁棒且信息丰富的嵌入，从而支持多样化的下游应用，并解决跨仪器光谱校准和应用灵活性问题。", "method": "提出SpecCLIP框架，一个受LLM启发的基础模型。该模型首先在LAMOST低分辨率和Gaia XP两种光谱类型上进行预训练，随后采用CLIP（对比语言-图像预训练）框架进行对比对齐，以关联来自不同仪器的光谱。此外，辅助解码器被用于保留光谱特定信息并实现光谱类型间的转换（预测）。", "result": "SpecCLIP构建了一个跨光谱框架，实现了内在校准和跨仪器的灵活应用。在适度大小的标记数据集上进行微调后，模型显著提高了恒星参数估计和化学丰度测定等任务的适应性、准确性和精度。其相似性搜索和跨光谱预测能力也为异常检测提供了潜力。", "conclusion": "通过光谱感知解码器丰富对比训练的基础模型，可以有效推动精密恒星光谱学的发展。", "translation": "近年来，大型语言模型（LLMs）通过庞大的数据集和大规模参数化改变了自然语言理解。受此成功的启发，我们提出了SpecCLIP，一个基础模型框架，将受LLM启发的方法扩展到恒星光谱分析。恒星光谱，类似于结构化语言，编码了关于恒星丰富的物理和化学信息。通过在大规模光谱数据集上训练基础模型，我们的目标是学习鲁棒且信息丰富的嵌入，以支持多样化的下游应用。作为概念验证，SpecCLIP涉及在两种光谱类型——LAMOST低分辨率和Gaia XP——上进行预训练，然后使用CLIP（对比语言-图像预训练）框架进行对比对齐，该框架被修改以关联来自不同仪器的光谱。这种对齐辅以辅助解码器，用于保留光谱特定信息并实现光谱类型间的转换（预测），其中前者通过最大化嵌入和输入光谱之间的互信息来实现。结果是一个跨光谱框架，实现了内在校准和跨仪度的灵活应用。我们证明，在适度大小的标记数据集上对这些模型进行微调，可以提高其对恒星参数估计和化学丰度测定等任务的适应性。SpecCLIP还提高了与外部巡天数据基准测试的参数估计的准确性和精度。此外，其相似性搜索和跨光谱预测能力为异常检测提供了潜力。我们的结果表明，通过光谱感知解码器丰富对比训练的基础模型可以推动精密恒星光谱学的发展。", "summary": "SpecCLIP是一个受大型语言模型启发的恒星光谱分析基础模型框架。它通过在不同光谱类型上预训练并采用CLIP框架进行对比对齐，实现了不同仪器间光谱的内在校准和转换。该模型能生成鲁棒的恒星光谱嵌入，提高恒星参数和化学丰度估计的准确性，并支持异常检测等下游应用，从而推动精密恒星光谱学。", "keywords": "恒星光谱, 基础模型, CLIP, 对比学习, 参数估计", "comments": "这篇论文的创新点在于将大型语言模型（LLM）的成功范式（尤其是CLIP的对比学习思想）引入到恒星光谱分析领域，构建了一个“基础模型”来处理多源异构光谱数据。这种方法解决了传统光谱分析中跨仪器校准和数据整合的挑战，通过学习通用嵌入和实现光谱类型转换，显著提升了恒星参数估计的准确性和应用灵活性。"}}
{"id": "2507.01613", "title": "When Less Is More: Binary Feedback Can Outperform Ordinal Comparisons in Ranking Recovery", "authors": ["Shirong Xu", "Jingnan Zhang", "Junhui Wang"], "summary": "Paired comparison data, where users evaluate items in pairs, play a central\nrole in ranking and preference learning tasks. While ordinal comparison data\nintuitively offer richer information than binary comparisons, this paper\nchallenges that conventional wisdom. We propose a general parametric framework\nfor modeling ordinal paired comparisons without ties. The model adopts a\ngeneralized additive structure, featuring a link function that quantifies the\npreference difference between two items and a pattern function that governs the\ndistribution over ordinal response levels. This framework encompasses classical\nbinary comparison models as special cases, by treating binary responses as\nbinarized versions of ordinal data. Within this framework, we show that\nbinarizing ordinal data can significantly improve the accuracy of ranking\nrecovery. Specifically, we prove that under the counting algorithm, the ranking\nerror associated with binary comparisons exhibits a faster exponential\nconvergence rate than that of ordinal data. Furthermore, we characterize a\nsubstantial performance gap between binary and ordinal data in terms of a\nsignal-to-noise ratio (SNR) determined by the pattern function. We identify the\npattern function that minimizes the SNR and maximizes the benefit of\nbinarization. Extensive simulations and a real application on the MovieLens\ndataset further corroborate our theoretical findings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01613v1", "categories": ["stat.ML", "cs.LG"], "cate": "stat.ML", "url": "http://arxiv.org/abs/2507.01613v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "少即是多：二元反馈在排序恢复中可能优于序数比较", "tldr": "研究表明，在排序恢复任务中，二元反馈数据可以比序数比较数据表现更好，收敛速度更快，且信噪比更高。", "motivation": "传统观念认为序数比较数据比二元比较数据提供更丰富的信息，但本文挑战了这一观点，旨在探究二元反馈是否能带来更好的排序恢复效果。", "method": "提出了一个通用的参数化框架来建模无平局的序数配对比较，该模型采用广义加性结构，包含量化偏好差异的链接函数和控制序数响应水平分布的模式函数。通过将二元响应视为序数数据的二值化版本，该框架涵盖了经典的二元比较模型。", "result": "证明了在计数算法下，二值化序数数据可以显著提高排序恢复的准确性，二元比较的排序误差收敛速度比序数数据更快。此外，在由模式函数决定的信噪比方面，二元数据和序数数据之间存在显著的性能差距，并确定了最小化信噪比并最大化二值化益处的模式函数。广泛的模拟和MovieLens数据集上的真实应用证实了理论发现。", "conclusion": "在排序恢复任务中，尽管直观上序数数据信息更丰富，但二值化序数数据（即使用二元反馈）能带来更快的收敛速度和更高的准确性，从而优于传统的序数比较。", "translation": "配对比较数据，即用户成对评估项目的数据，在排序和偏好学习任务中扮演着核心角色。虽然序数比较数据直观上比二元比较数据提供更丰富的信息，但本文挑战了这一传统观念。我们提出了一个通用的参数化框架，用于建模无平局的序数配对比较。该模型采用广义加性结构，其特征在于一个量化两个项目之间偏好差异的链接函数和一个控制序数响应水平分布的模式函数。通过将二元响应视为序数数据的二值化版本，该框架涵盖了经典的二元比较模型作为特例。在此框架内，我们表明二值化序数数据可以显著提高排序恢复的准确性。具体而言，我们证明在计数算法下，与二元比较相关的排序误差比序数数据表现出更快的指数收敛速度。此外，我们根据由模式函数确定的信噪比（SNR）来表征二元数据和序数数据之间存在的实质性性能差距。我们确定了最小化SNR并最大化二值化益处的模式函数。广泛的模拟和在MovieLens数据集上的真实应用进一步证实了我们的理论发现。", "summary": "本文挑战了配对比较中序数数据优于二元数据的传统观念。作者提出了一个通用的参数化框架来建模序数配对比较，并证明在该框架下，将序数数据二值化可以显著提高排序恢复的准确性。理论分析表明，二元比较的排序误差收敛速度更快，且在信噪比方面优于序数数据。模拟和真实数据集上的实验验证了这些理论发现。", "keywords": "配对比较, 排序恢复, 二元反馈, 序数比较, 信噪比", "comments": "这篇论文的创新点在于它挑战了关于数据丰富性的传统直觉，并提供了坚实的理论和实验证据来支持“少即是多”的观点。它为偏好学习和排序恢复领域提供了一个新的视角，尤其是在数据采集成本或噪声水平较高时，二元反馈可能是一个更优的选择。"}}
{"id": "2507.01889", "title": "STEM Diffraction Pattern Analysis with Deep Learning Networks", "authors": ["Sebastian Wissel", "Jonas Scheunert", "Aaron Dextre", "Shamail Ahmed", "Andreas Bayer", "Kerstin Volz", "Bai-Xiang Xu"], "summary": "Accurate grain orientation mapping is essential for understanding and\noptimizing the performance of polycrystalline materials, particularly in\nenergy-related applications. Lithium nickel oxide (LiNiO$_{2}$) is a promising\ncathode material for next-generation lithium-ion batteries, and its\nelectrochemical behaviour is closely linked to microstructural features such as\ngrain size and crystallographic orientations. Traditional orientation mapping\nmethods--such as manual indexing, template matching (TM), or Hough\ntransform-based techniques--are often slow and noise-sensitive when handling\ncomplex or overlapping patterns, creating a bottleneck in large-scale\nmicrostructural analysis. This work presents a machine learning-based approach\nfor predicting Euler angles directly from scanning transmission electron\nmicroscopy (STEM) diffraction patterns (DPs). This enables the automated\ngeneration of high-resolution crystal orientation maps, facilitating the\nanalysis of internal microstructures at the nanoscale. Three deep learning\narchitectures--convolutional neural networks (CNNs), Dense Convolutional\nNetworks (DenseNets), and Shifted Windows (Swin) Transformers--are evaluated,\nusing an experimentally acquired dataset labelled via a commercial TM\nalgorithm. While the CNN model serves as a baseline, both DenseNets and Swin\nTransformers demonstrate superior performance, with the Swin Transformer\nachieving the highest evaluation scores and the most consistent microstructural\npredictions. The resulting crystal maps exhibit clear grain boundary\ndelineation and coherent intra-grain orientation distributions, underscoring\nthe potential of attention-based architectures for analyzing diffraction-based\nimage data. These findings highlight the promise of combining advanced machine\nlearning models with STEM data for robust, high-throughput microstructural\ncharacterization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01889v1", "categories": ["cond-mat.dis-nn", "cond-mat.mtrl-sci", "cs.LG"], "cate": "cond-mat.dis-nn", "url": "http://arxiv.org/abs/2507.01889v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "基于深度学习网络的STEM衍射图分析", "tldr": "本研究利用深度学习网络（CNN、DenseNet、Swin Transformer）直接从扫描透射电子显微镜（STEM）衍射图中预测欧拉角，以实现高分辨率晶体取向图的自动化生成，其中Swin Transformer表现最佳，为多晶材料的微观结构表征提供了高效准确的方法。", "motivation": "准确的晶粒取向映射对于理解和优化多晶材料（特别是能源相关应用中的材料）的性能至关重要。传统的取向映射方法（如手动标定、模板匹配或基于霍夫变换的技术）在处理复杂或重叠模式时通常速度慢且对噪声敏感，这成为大规模微观结构分析的瓶颈。", "method": "本研究提出了一种基于机器学习的方法，直接从扫描透射电子显微镜（STEM）衍射图（DPs）中预测欧拉角。评估了三种深度学习架构：卷积神经网络（CNN）、密集卷积网络（DenseNets）和移位窗口（Swin）Transformer。这些模型使用通过商业模板匹配算法标记的实验获取数据集进行训练和评估。", "result": "CNN模型作为基线，DenseNets和Swin Transformer均表现出优越性能。Swin Transformer取得了最高的评估分数和最一致的微观结构预测。生成的晶体图显示出清晰的晶界划分和连贯的晶粒内部取向分布。", "conclusion": "结合先进的机器学习模型与STEM数据，能够实现稳健、高通量的微观结构表征，特别是基于注意力机制的架构在分析衍射图像数据方面具有巨大潜力。", "translation": "准确的晶粒取向映射对于理解和优化多晶材料的性能至关重要，尤其是在能源相关应用中。氧化镍锂（LiNiO2）是一种很有前景的下一代锂离子电池正极材料，其电化学行为与晶粒尺寸和晶体取向等微观结构特征密切相关。传统取向映射方法——如手动标定、模板匹配（TM）或基于霍夫变换的技术——在处理复杂或重叠模式时通常速度慢且对噪声敏感，这成为大规模微观结构分析的瓶颈。本工作提出了一种基于机器学习的方法，用于直接从扫描透射电子显微镜（STEM）衍射图（DPs）中预测欧拉角。这使得高分辨率晶体取向图的自动化生成成为可能，从而促进纳米尺度内部微观结构的分析。本研究评估了三种深度学习架构——卷积神经网络（CNN）、密集卷积网络（DenseNets）和移位窗口（Swin）Transformer，使用通过商业TM算法标记的实验获取数据集。虽然CNN模型作为基线，但DenseNets和Swin Transformer均表现出优越性能，其中Swin Transformer取得了最高的评估分数和最一致的微观结构预测。生成的晶体图显示出清晰的晶界划分和连贯的晶粒内部取向分布，强调了基于注意力机制的架构在分析衍射图像数据方面的潜力。这些发现突出了将先进机器学习模型与STEM数据相结合，实现稳健、高通量微观结构表征的前景。", "summary": "本研究提出了一种利用深度学习网络分析扫描透射电子显微镜（STEM）衍射图的新方法，旨在解决传统晶粒取向映射方法在处理复杂模式时效率低、对噪声敏感的问题。研究评估了卷积神经网络（CNN）、密集卷积网络（DenseNets）和移位窗口（Swin）Transformer三种深度学习架构，直接从衍射图中预测欧拉角，从而自动化生成高分辨率晶体取向图。结果表明，Swin Transformer表现最佳，生成的晶体图清晰且一致，证明了深度学习，尤其是注意力机制模型，在高效、准确地进行纳米尺度微观结构表征方面的巨大潜力。", "keywords": "深度学习, STEM, 衍射图, 晶体取向映射, Swin Transformer", "comments": "该论文创新性地将深度学习应用于STEM衍射图分析，直接预测欧拉角，实现了晶体取向图的自动化生成，显著提升了微观结构分析的效率和准确性。特别是引入并验证了Swin Transformer在处理此类图像数据上的优越性，为材料科学研究提供了强大的新工具。其重要性在于克服了传统方法的局限，为锂离子电池等关键材料的性能优化提供了更深入的微观结构理解。"}}
{"id": "2507.01913", "title": "Advancing Magnetic Materials Discovery -- A structure-based machine learning approach for magnetic ordering and magnetic moment prediction", "authors": ["Apoorv Verma", "Junaid Jami", "Amrita Bhattacharya"], "summary": "Accurately predicting magnetic behavior across diverse materials systems\nremains a longstanding challenge due to the complex interplay of structural and\nelectronic factors and is pivotal for the accelerated discovery and design of\nnext-generation magnetic materials. In this work, a refined descriptor is\nproposed that significantly improves the prediction of two critical magnetic\nproperties -- magnetic ordering (Ferromagnetic vs. Ferrimagnetic) and magnetic\nmoment per atom -- using only the structural information of materials. Unlike\nprevious models limited to Mn-based or lanthanide-transition metal compounds,\nthe present approach generalizes across a diverse dataset of 5741 stable,\nbinary and ternary, ferromagnetic and ferrimagnetic compounds sourced from the\nMaterials Project. Leveraging an enriched elemental vector representation and\nadvanced feature engineering, including nonlinear terms and reduced matrix\nsparsity, the LightGBM-based model achieves an accuracy of 82.4% for magnetic\nordering classification and balanced recall across FM and FiM classes,\naddressing a key limitation in prior studies. The model predicts magnetic\nmoment per atom with a correlation coefficient of 0.93, surpassing the Hund's\nmatrix and orbital field matrix descriptors. Additionally, it accurately\nestimates formation energy per atom, enabling assessment of both magnetic\nbehavior and material stability. This generalized and computationally efficient\nframework offers a robust tool for high-throughput screening of magnetic\nmaterials with tailored properties.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01913v1", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "cate": "cond-mat.mtrl-sci", "url": "http://arxiv.org/abs/2507.01913v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "推进磁性材料发现——一种基于结构的磁序和磁矩预测机器学习方法", "tldr": "该研究提出了一种基于结构的机器学习方法，能够准确预测各种材料的磁序（铁磁性与亚铁磁性）和原子磁矩，克服了现有模型的局限性，并可用于高通量筛选磁性材料。", "motivation": "准确预测不同材料体系的磁行为是加速下一代磁性材料发现和设计的关键挑战，因为结构和电子因素之间存在复杂的相互作用。", "method": "提出了一种改进的描述符，仅使用材料的结构信息来预测磁序和原子磁矩。该方法利用丰富的元素向量表示和先进的特征工程（包括非线性项和降低矩阵稀疏性），基于LightGBM模型，在一个包含5741种稳定、二元和三元、铁磁和亚铁磁化合物的多样化数据集上进行训练。", "result": "该模型在磁序分类方面实现了82.4%的准确率，并在铁磁和亚铁磁类别之间实现了平衡召回率。原子磁矩预测的相关系数达到0.93，优于Hund矩阵和轨道场矩阵描述符。此外，它还能准确估计每原子形成能。", "conclusion": "该研究提出的通用且计算高效的框架为高通量筛选具有定制特性的磁性材料提供了一个强大的工具。", "translation": "准确预测不同材料体系的磁行为仍然是一个长期存在的挑战，这归因于结构和电子因素之间复杂的相互作用，并且对于加速下一代磁性材料的发现和设计至关重要。在这项工作中，提出了一种改进的描述符，该描述符仅使用材料的结构信息，显著提高了对两个关键磁性——磁序（铁磁性与亚铁磁性）和每原子磁矩——的预测。与之前仅限于锰基或镧系-过渡金属化合物的模型不同，本方法推广到来自Materials Project的包含5741种稳定、二元和三元、铁磁和亚铁磁化合物的多样化数据集。利用丰富的元素向量表示和先进的特征工程，包括非线性项和降低矩阵稀疏性，基于LightGBM的模型在磁序分类方面实现了82.4%的准确率，并在铁磁和亚铁磁类别之间实现了平衡召回率，解决了先前研究中的一个关键限制。该模型预测每原子磁矩的相关系数为0.93，超越了Hund矩阵和轨道场矩阵描述符。此外，它还能准确估计每原子形成能，从而能够评估磁行为和材料稳定性。这种通用且计算高效的框架为高通量筛选具有定制特性的磁性材料提供了一个强大的工具。", "summary": "该研究提出了一种基于结构信息的机器学习方法，用于预测磁性材料的磁序和原子磁矩。通过开发一种改进的描述符，结合丰富的元素向量表示和先进的特征工程，该LightGBM模型在大型多样化数据集上实现了高精度预测，尤其在磁序分类和磁矩预测方面表现出色，并能评估材料稳定性。该框架为磁性材料的高通量筛选提供了通用且高效的工具。", "keywords": "磁性材料, 机器学习, 磁序, 磁矩, 结构预测", "comments": "该论文的创新点在于提出了一个通用的、基于结构的机器学习框架，能够同时预测磁序和磁矩，并且克服了以往模型在材料范围上的局限性，适用于更广泛的材料体系。其重要性在于为加速新型磁性材料的发现和设计提供了高效的计算工具。"}}
{"id": "2507.01946", "title": "Characterizing control between interacting subsystems with deep Jacobian estimation", "authors": ["Adam J. Eisen", "Mitchell Ostrow", "Sarthak Chandra", "Leo Kozachkov", "Earl K. Miller", "Ila R. Fiete"], "summary": "Biological function arises through the dynamical interactions of multiple\nsubsystems, including those between brain areas, within gene regulatory\nnetworks, and more. A common approach to understanding these systems is to\nmodel the dynamics of each subsystem and characterize communication between\nthem. An alternative approach is through the lens of control theory: how the\nsubsystems control one another. This approach involves inferring the\ndirectionality, strength, and contextual modulation of control between\nsubsystems. However, methods for understanding subsystem control are typically\nlinear and cannot adequately describe the rich contextual effects enabled by\nnonlinear complex systems. To bridge this gap, we devise a data-driven\nnonlinear control-theoretic framework to characterize subsystem interactions\nvia the Jacobian of the dynamics. We address the challenge of learning\nJacobians from time-series data by proposing the JacobianODE, a deep learning\nmethod that leverages properties of the Jacobian to directly estimate it for\narbitrary dynamical systems from data alone. We show that JacobianODEs\noutperform existing Jacobian estimation methods on challenging systems,\nincluding high-dimensional chaos. Applying our approach to a multi-area\nrecurrent neural network (RNN) trained on a working memory selection task, we\nshow that the \"sensory\" area gains greater control over the \"cognitive\" area\nover learning. Furthermore, we leverage the JacobianODE to directly control the\ntrained RNN, enabling precise manipulation of its behavior. Our work lays the\nfoundation for a theoretically grounded and data-driven understanding of\ninteractions among biological subsystems.", "comment": "10 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.01946v1", "categories": ["q-bio.QM", "cs.LG", "math.DS", "q-bio.NC"], "cate": "q-bio.QM", "url": "http://arxiv.org/abs/2507.01946v1", "date": "2025-07-02", "updated": "2025-07-02", "AI": {"title_translation": "利用深度雅可比估计表征相互作用子系统间的控制", "tldr": "本文提出了一种名为JacobianODE的深度学习方法，用于从时间序列数据中估计雅可比矩阵，从而能够表征和操纵非线性相互作用子系统之间的控制，该方法优于现有方法，并在神经网络中展示了其效用。", "motivation": "理解生物子系统间控制的现有方法通常是线性的，无法充分描述非线性复杂系统所带来的丰富情境效应。本研究旨在弥合这一差距，开发一种数据驱动的非线性控制理论框架来表征这些相互作用。", "method": "作者开发了一种数据驱动的非线性控制理论框架，通过动力学的雅可比矩阵来表征子系统间的相互作用。他们提出了“JacobianODE”，这是一种深度学习方法，利用雅可比矩阵的特性，可以直接从时间序列数据中估计任意动力学系统的雅可比矩阵。", "result": "JacobianODE在具有挑战性的系统（包括高维混沌）上优于现有的雅可比估计方法。将其应用于一个在工作记忆选择任务上训练的多区域循环神经网络（RNN），结果显示“感觉”区域在学习过程中对“认知”区域获得了更大的控制权。此外，JacobianODE还能够直接精确地操纵训练过的RNN的行为。", "conclusion": "这项工作为理解生物子系统间的相互作用奠定了理论基础和数据驱动的基础。", "translation": "生物功能源于多个子系统之间的动态相互作用，包括脑区之间、基因调控网络内部等。理解这些系统的一种常见方法是建模每个子系统的动力学并表征它们之间的通信。另一种方法是通过控制理论的视角：子系统如何相互控制。这种方法涉及推断子系统之间控制的方向性、强度和情境调制。然而，理解子系统控制的方法通常是线性的，无法充分描述非线性复杂系统所实现丰富的上下文效应。为了弥合这一差距，我们设计了一种数据驱动的非线性控制理论框架，通过动力学的雅可比矩阵来表征子系统间的相互作用。我们通过提出JacobianODE解决了从时间序列数据中学习雅可比矩阵的挑战，JacobianODE是一种深度学习方法，它利用雅可比矩阵的特性，可以直接从数据中估计任意动力学系统的雅可比矩阵。我们展示了JacobianODE在具有挑战性的系统（包括高维混沌）上优于现有的雅可比估计方法。将我们的方法应用于一个在工作记忆选择任务上训练的多区域循环神经网络（RNN），我们发现“感觉”区域在学习过程中对“认知”区域获得了更大的控制权。此外，我们利用JacobianODE直接控制训练过的RNN，从而能够精确操纵其行为。我们的工作为理论基础和数据驱动的生物子系统间相互作用的理解奠定了基础。", "summary": "本文提出了一种名为JacobianODE的新型深度学习方法，用于直接从时间序列数据中估计雅可比矩阵。这使得建立一个数据驱动的非线性控制理论框架成为可能，用以表征和操纵复杂生物子系统之间的相互作用。该方法优于现有的雅可比估计技术，并通过分析循环神经网络中的控制动态并实现其行为的精确操纵得到了验证，为理解生物相互作用奠定了基础。", "keywords": "深度学习, 雅可比估计, 控制理论, 相互作用子系统, 神经网络", "comments": "本文具有创新性，因为它通过引入一种新颖的深度学习方法JacobianODE，解决了理解相互作用子系统之间非线性控制的关键空白。它能够直接从数据中估计雅可比矩阵，即使在高维混沌系统中，以及其在神经网络中表征和操纵控制的应用，都凸显了其对神经科学和复杂系统的重要性。该框架为超越生物系统分析中的线性近似提供了一个强大的工具。"}}
